{
  "module_name": "zfs_fletcher_sse.c",
  "hash_id": "9b9bfb5ad7885c04531e52ada0e2bfd762d9b70af4188092fae2cb029f84bbe2",
  "original_prompt": "Ingested from zfs-2.2.2/module/zcommon/zfs_fletcher_sse.c",
  "human_readable_source": " \n\n#if defined(HAVE_SSE2)\n\n#include <sys/simd.h>\n#include <sys/spa_checksum.h>\n#include <sys/string.h>\n#include <sys/byteorder.h>\n#include <zfs_fletcher.h>\n\nstatic void\nfletcher_4_sse2_init(fletcher_4_ctx_t *ctx)\n{\n\tmemset(ctx->sse, 0, 4 * sizeof (zfs_fletcher_sse_t));\n}\n\nstatic void\nfletcher_4_sse2_fini(fletcher_4_ctx_t *ctx, zio_cksum_t *zcp)\n{\n\tuint64_t A, B, C, D;\n\n\t \n\tA = ctx->sse[0].v[0] + ctx->sse[0].v[1];\n\tB = 2 * ctx->sse[1].v[0] + 2 * ctx->sse[1].v[1] - ctx->sse[0].v[1];\n\tC = 4 * ctx->sse[2].v[0] - ctx->sse[1].v[0] + 4 * ctx->sse[2].v[1] -\n\t    3 * ctx->sse[1].v[1];\n\tD = 8 * ctx->sse[3].v[0] - 4 * ctx->sse[2].v[0] + 8 * ctx->sse[3].v[1] -\n\t    8 * ctx->sse[2].v[1] + ctx->sse[1].v[1];\n\n\tZIO_SET_CHECKSUM(zcp, A, B, C, D);\n}\n\n#define\tFLETCHER_4_SSE_RESTORE_CTX(ctx)\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tasm volatile(\"movdqu %0, %%xmm0\" :: \"m\" ((ctx)->sse[0]));\t\\\n\tasm volatile(\"movdqu %0, %%xmm1\" :: \"m\" ((ctx)->sse[1]));\t\\\n\tasm volatile(\"movdqu %0, %%xmm2\" :: \"m\" ((ctx)->sse[2]));\t\\\n\tasm volatile(\"movdqu %0, %%xmm3\" :: \"m\" ((ctx)->sse[3]));\t\\\n}\n\n#define\tFLETCHER_4_SSE_SAVE_CTX(ctx)\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tasm volatile(\"movdqu %%xmm0, %0\" : \"=m\" ((ctx)->sse[0]));\t\\\n\tasm volatile(\"movdqu %%xmm1, %0\" : \"=m\" ((ctx)->sse[1]));\t\\\n\tasm volatile(\"movdqu %%xmm2, %0\" : \"=m\" ((ctx)->sse[2]));\t\\\n\tasm volatile(\"movdqu %%xmm3, %0\" : \"=m\" ((ctx)->sse[3]));\t\\\n}\n\nstatic void\nfletcher_4_sse2_native(fletcher_4_ctx_t *ctx, const void *buf, uint64_t size)\n{\n\tconst uint64_t *ip = buf;\n\tconst uint64_t *ipend = (uint64_t *)((uint8_t *)ip + size);\n\n\tFLETCHER_4_SSE_RESTORE_CTX(ctx);\n\n\tasm volatile(\"pxor %xmm4, %xmm4\");\n\n\tdo {\n\t\tasm volatile(\"movdqu %0, %%xmm5\" :: \"m\"(*ip));\n\t\tasm volatile(\"movdqa %xmm5, %xmm6\");\n\t\tasm volatile(\"punpckldq %xmm4, %xmm5\");\n\t\tasm volatile(\"punpckhdq %xmm4, %xmm6\");\n\t\tasm volatile(\"paddq %xmm5, %xmm0\");\n\t\tasm volatile(\"paddq %xmm0, %xmm1\");\n\t\tasm volatile(\"paddq %xmm1, %xmm2\");\n\t\tasm volatile(\"paddq %xmm2, %xmm3\");\n\t\tasm volatile(\"paddq %xmm6, %xmm0\");\n\t\tasm volatile(\"paddq %xmm0, %xmm1\");\n\t\tasm volatile(\"paddq %xmm1, %xmm2\");\n\t\tasm volatile(\"paddq %xmm2, %xmm3\");\n\t} while ((ip += 2) < ipend);\n\n\tFLETCHER_4_SSE_SAVE_CTX(ctx);\n}\n\nstatic void\nfletcher_4_sse2_byteswap(fletcher_4_ctx_t *ctx, const void *buf, uint64_t size)\n{\n\tconst uint32_t *ip = buf;\n\tconst uint32_t *ipend = (uint32_t *)((uint8_t *)ip + size);\n\n\tFLETCHER_4_SSE_RESTORE_CTX(ctx);\n\n\tdo {\n\t\tuint32_t scratch1 = BSWAP_32(ip[0]);\n\t\tuint32_t scratch2 = BSWAP_32(ip[1]);\n\t\tasm volatile(\"movd %0, %%xmm5\" :: \"r\"(scratch1));\n\t\tasm volatile(\"movd %0, %%xmm6\" :: \"r\"(scratch2));\n\t\tasm volatile(\"punpcklqdq %xmm6, %xmm5\");\n\t\tasm volatile(\"paddq %xmm5, %xmm0\");\n\t\tasm volatile(\"paddq %xmm0, %xmm1\");\n\t\tasm volatile(\"paddq %xmm1, %xmm2\");\n\t\tasm volatile(\"paddq %xmm2, %xmm3\");\n\t} while ((ip += 2) < ipend);\n\n\tFLETCHER_4_SSE_SAVE_CTX(ctx);\n}\n\nstatic boolean_t fletcher_4_sse2_valid(void)\n{\n\treturn (kfpu_allowed() && zfs_sse2_available());\n}\n\nconst fletcher_4_ops_t fletcher_4_sse2_ops = {\n\t.init_native = fletcher_4_sse2_init,\n\t.fini_native = fletcher_4_sse2_fini,\n\t.compute_native = fletcher_4_sse2_native,\n\t.init_byteswap = fletcher_4_sse2_init,\n\t.fini_byteswap = fletcher_4_sse2_fini,\n\t.compute_byteswap = fletcher_4_sse2_byteswap,\n\t.valid = fletcher_4_sse2_valid,\n\t.uses_fpu = B_TRUE,\n\t.name = \"sse2\"\n};\n\n#endif  \n\n#if defined(HAVE_SSE2) && defined(HAVE_SSSE3)\nstatic void\nfletcher_4_ssse3_byteswap(fletcher_4_ctx_t *ctx, const void *buf, uint64_t size)\n{\n\tstatic const zfs_fletcher_sse_t mask = {\n\t\t.v = { 0x0405060700010203, 0x0C0D0E0F08090A0B }\n\t};\n\n\tconst uint64_t *ip = buf;\n\tconst uint64_t *ipend = (uint64_t *)((uint8_t *)ip + size);\n\n\tFLETCHER_4_SSE_RESTORE_CTX(ctx);\n\n\tasm volatile(\"movdqu %0, %%xmm7\"::\"m\" (mask));\n\tasm volatile(\"pxor %xmm4, %xmm4\");\n\n\tdo {\n\t\tasm volatile(\"movdqu %0, %%xmm5\"::\"m\" (*ip));\n\t\tasm volatile(\"pshufb %xmm7, %xmm5\");\n\t\tasm volatile(\"movdqa %xmm5, %xmm6\");\n\t\tasm volatile(\"punpckldq %xmm4, %xmm5\");\n\t\tasm volatile(\"punpckhdq %xmm4, %xmm6\");\n\t\tasm volatile(\"paddq %xmm5, %xmm0\");\n\t\tasm volatile(\"paddq %xmm0, %xmm1\");\n\t\tasm volatile(\"paddq %xmm1, %xmm2\");\n\t\tasm volatile(\"paddq %xmm2, %xmm3\");\n\t\tasm volatile(\"paddq %xmm6, %xmm0\");\n\t\tasm volatile(\"paddq %xmm0, %xmm1\");\n\t\tasm volatile(\"paddq %xmm1, %xmm2\");\n\t\tasm volatile(\"paddq %xmm2, %xmm3\");\n\t} while ((ip += 2) < ipend);\n\n\tFLETCHER_4_SSE_SAVE_CTX(ctx);\n}\n\nstatic boolean_t fletcher_4_ssse3_valid(void)\n{\n\treturn (kfpu_allowed() && zfs_sse2_available() &&\n\t    zfs_ssse3_available());\n}\n\nconst fletcher_4_ops_t fletcher_4_ssse3_ops = {\n\t.init_native = fletcher_4_sse2_init,\n\t.fini_native = fletcher_4_sse2_fini,\n\t.compute_native = fletcher_4_sse2_native,\n\t.init_byteswap = fletcher_4_sse2_init,\n\t.fini_byteswap = fletcher_4_sse2_fini,\n\t.compute_byteswap = fletcher_4_ssse3_byteswap,\n\t.valid = fletcher_4_ssse3_valid,\n\t.uses_fpu = B_TRUE,\n\t.name = \"ssse3\"\n};\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}