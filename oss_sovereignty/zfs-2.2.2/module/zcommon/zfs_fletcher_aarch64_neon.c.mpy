{
  "module_name": "zfs_fletcher_aarch64_neon.c",
  "hash_id": "d1922d8a717e36380343a985b442a8fd48181d0fa2b295d2e0b5a0892556f749",
  "original_prompt": "Ingested from zfs-2.2.2/module/zcommon/zfs_fletcher_aarch64_neon.c",
  "human_readable_source": " \n\n#if defined(__aarch64__)\n\n#include <sys/simd.h>\n#include <sys/spa_checksum.h>\n#include <sys/string.h>\n#include <zfs_fletcher.h>\n\nstatic void\nfletcher_4_aarch64_neon_init(fletcher_4_ctx_t *ctx)\n{\n\tmemset(ctx->aarch64_neon, 0, 4 * sizeof (zfs_fletcher_aarch64_neon_t));\n}\n\nstatic void\nfletcher_4_aarch64_neon_fini(fletcher_4_ctx_t *ctx, zio_cksum_t *zcp)\n{\n\tuint64_t A, B, C, D;\n\tA = ctx->aarch64_neon[0].v[0] + ctx->aarch64_neon[0].v[1];\n\tB = 2 * ctx->aarch64_neon[1].v[0] + 2 * ctx->aarch64_neon[1].v[1] -\n\t    ctx->aarch64_neon[0].v[1];\n\tC = 4 * ctx->aarch64_neon[2].v[0] - ctx->aarch64_neon[1].v[0] +\n\t    4 * ctx->aarch64_neon[2].v[1] - 3 * ctx->aarch64_neon[1].v[1];\n\tD = 8 * ctx->aarch64_neon[3].v[0] - 4 * ctx->aarch64_neon[2].v[0] +\n\t    8 * ctx->aarch64_neon[3].v[1] - 8 * ctx->aarch64_neon[2].v[1] +\n\t    ctx->aarch64_neon[1].v[1];\n\tZIO_SET_CHECKSUM(zcp, A, B, C, D);\n}\n\n#define\tNEON_INIT_LOOP()\t\t\t\\\n\tasm(\"eor %[ZERO].16b,%[ZERO].16b,%[ZERO].16b\\n\"\t\\\n\t\"ld1 { %[ACC0].4s }, %[CTX0]\\n\"\t\t\\\n\t\"ld1 { %[ACC1].4s }, %[CTX1]\\n\"\t\t\\\n\t\"ld1 { %[ACC2].4s }, %[CTX2]\\n\"\t\t\\\n\t\"ld1 { %[ACC3].4s }, %[CTX3]\\n\"\t\t\\\n\t: [ZERO] \"=w\" (ZERO),\t\t\t\\\n\t[ACC0] \"=w\" (ACC0), [ACC1] \"=w\" (ACC1),\t\\\n\t[ACC2] \"=w\" (ACC2), [ACC3] \"=w\" (ACC3)\t\\\n\t: [CTX0] \"Q\" (ctx->aarch64_neon[0]),\t\\\n\t[CTX1] \"Q\" (ctx->aarch64_neon[1]),\t\\\n\t[CTX2] \"Q\" (ctx->aarch64_neon[2]),\t\\\n\t[CTX3] \"Q\" (ctx->aarch64_neon[3]))\n\n#define\tNEON_DO_REVERSE \"rev32 %[SRC].16b, %[SRC].16b\\n\"\n\n#define\tNEON_DONT_REVERSE \"\"\n\n#define\tNEON_MAIN_LOOP(REVERSE)\t\t\t\t\\\n\tasm(\"ld1 { %[SRC].4s }, %[IP]\\n\"\t\t\\\n\tREVERSE\t\t\t\t\t\t\\\n\t\"zip1 %[TMP1].4s, %[SRC].4s, %[ZERO].4s\\n\"\t\\\n\t\"zip2 %[TMP2].4s, %[SRC].4s, %[ZERO].4s\\n\"\t\\\n\t\"add %[ACC0].2d, %[ACC0].2d, %[TMP1].2d\\n\"\t\\\n\t\"add %[ACC1].2d, %[ACC1].2d, %[ACC0].2d\\n\"\t\\\n\t\"add %[ACC2].2d, %[ACC2].2d, %[ACC1].2d\\n\"\t\\\n\t\"add %[ACC3].2d, %[ACC3].2d, %[ACC2].2d\\n\"\t\\\n\t\"add %[ACC0].2d, %[ACC0].2d, %[TMP2].2d\\n\"\t\\\n\t\"add %[ACC1].2d, %[ACC1].2d, %[ACC0].2d\\n\"\t\\\n\t\"add %[ACC2].2d, %[ACC2].2d, %[ACC1].2d\\n\"\t\\\n\t\"add %[ACC3].2d, %[ACC3].2d, %[ACC2].2d\\n\"\t\\\n\t: [SRC] \"=&w\" (SRC),\t\t\t\t\\\n\t[TMP1] \"=&w\" (TMP1), [TMP2] \"=&w\" (TMP2),\t\\\n\t[ACC0] \"+w\" (ACC0), [ACC1] \"+w\" (ACC1),\t\t\\\n\t[ACC2] \"+w\" (ACC2), [ACC3] \"+w\" (ACC3)\t\t\\\n\t: [ZERO] \"w\" (ZERO), [IP] \"Q\" (*ip))\n\n#define\tNEON_FINI_LOOP()\t\t\t\\\n\tasm(\"st1 { %[ACC0].4s },%[DST0]\\n\"\t\\\n\t\"st1 { %[ACC1].4s },%[DST1]\\n\"\t\t\\\n\t\"st1 { %[ACC2].4s },%[DST2]\\n\"\t\t\\\n\t\"st1 { %[ACC3].4s },%[DST3]\\n\"\t\t\\\n\t: [DST0] \"=Q\" (ctx->aarch64_neon[0]),\t\\\n\t[DST1] \"=Q\" (ctx->aarch64_neon[1]),\t\\\n\t[DST2] \"=Q\" (ctx->aarch64_neon[2]),\t\\\n\t[DST3] \"=Q\" (ctx->aarch64_neon[3])\t\\\n\t: [ACC0] \"w\" (ACC0), [ACC1] \"w\" (ACC1),\t\\\n\t[ACC2] \"w\" (ACC2), [ACC3] \"w\" (ACC3))\n\nstatic void\nfletcher_4_aarch64_neon_native(fletcher_4_ctx_t *ctx,\n    const void *buf, uint64_t size)\n{\n\tconst uint64_t *ip = buf;\n\tconst uint64_t *ipend = (uint64_t *)((uint8_t *)ip + size);\n#if defined(_KERNEL)\nregister unsigned char ZERO asm(\"v0\") __attribute__((vector_size(16)));\nregister unsigned char ACC0 asm(\"v1\") __attribute__((vector_size(16)));\nregister unsigned char ACC1 asm(\"v2\") __attribute__((vector_size(16)));\nregister unsigned char ACC2 asm(\"v3\") __attribute__((vector_size(16)));\nregister unsigned char ACC3 asm(\"v4\") __attribute__((vector_size(16)));\nregister unsigned char TMP1 asm(\"v5\") __attribute__((vector_size(16)));\nregister unsigned char TMP2 asm(\"v6\") __attribute__((vector_size(16)));\nregister unsigned char SRC asm(\"v7\") __attribute__((vector_size(16)));\n#else\nunsigned char ZERO __attribute__((vector_size(16)));\nunsigned char ACC0 __attribute__((vector_size(16)));\nunsigned char ACC1 __attribute__((vector_size(16)));\nunsigned char ACC2 __attribute__((vector_size(16)));\nunsigned char ACC3 __attribute__((vector_size(16)));\nunsigned char TMP1 __attribute__((vector_size(16)));\nunsigned char TMP2 __attribute__((vector_size(16)));\nunsigned char SRC __attribute__((vector_size(16)));\n#endif\n\n\tNEON_INIT_LOOP();\n\n\tdo {\n\t\tNEON_MAIN_LOOP(NEON_DONT_REVERSE);\n\t} while ((ip += 2) < ipend);\n\n\tNEON_FINI_LOOP();\n}\n\nstatic void\nfletcher_4_aarch64_neon_byteswap(fletcher_4_ctx_t *ctx,\n    const void *buf, uint64_t size)\n{\n\tconst uint64_t *ip = buf;\n\tconst uint64_t *ipend = (uint64_t *)((uint8_t *)ip + size);\n#if defined(_KERNEL)\nregister unsigned char ZERO asm(\"v0\") __attribute__((vector_size(16)));\nregister unsigned char ACC0 asm(\"v1\") __attribute__((vector_size(16)));\nregister unsigned char ACC1 asm(\"v2\") __attribute__((vector_size(16)));\nregister unsigned char ACC2 asm(\"v3\") __attribute__((vector_size(16)));\nregister unsigned char ACC3 asm(\"v4\") __attribute__((vector_size(16)));\nregister unsigned char TMP1 asm(\"v5\") __attribute__((vector_size(16)));\nregister unsigned char TMP2 asm(\"v6\") __attribute__((vector_size(16)));\nregister unsigned char SRC asm(\"v7\") __attribute__((vector_size(16)));\n#else\nunsigned char ZERO __attribute__((vector_size(16)));\nunsigned char ACC0 __attribute__((vector_size(16)));\nunsigned char ACC1 __attribute__((vector_size(16)));\nunsigned char ACC2 __attribute__((vector_size(16)));\nunsigned char ACC3 __attribute__((vector_size(16)));\nunsigned char TMP1 __attribute__((vector_size(16)));\nunsigned char TMP2 __attribute__((vector_size(16)));\nunsigned char SRC __attribute__((vector_size(16)));\n#endif\n\n\tNEON_INIT_LOOP();\n\n\tdo {\n\t\tNEON_MAIN_LOOP(NEON_DO_REVERSE);\n\t} while ((ip += 2) < ipend);\n\n\tNEON_FINI_LOOP();\n}\n\nstatic boolean_t fletcher_4_aarch64_neon_valid(void)\n{\n\treturn (kfpu_allowed());\n}\n\nconst fletcher_4_ops_t fletcher_4_aarch64_neon_ops = {\n\t.init_native = fletcher_4_aarch64_neon_init,\n\t.compute_native = fletcher_4_aarch64_neon_native,\n\t.fini_native = fletcher_4_aarch64_neon_fini,\n\t.init_byteswap = fletcher_4_aarch64_neon_init,\n\t.compute_byteswap = fletcher_4_aarch64_neon_byteswap,\n\t.fini_byteswap = fletcher_4_aarch64_neon_fini,\n\t.valid = fletcher_4_aarch64_neon_valid,\n\t.uses_fpu = B_TRUE,\n\t.name = \"aarch64_neon\"\n};\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}