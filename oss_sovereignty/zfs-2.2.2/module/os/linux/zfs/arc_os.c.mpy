{
  "module_name": "arc_os.c",
  "hash_id": "e6de7e59de785adfd03581c804fd6b207774ed0565d8b8613225dd174c9e0c03",
  "original_prompt": "Ingested from zfs-2.2.2/module/os/linux/zfs/arc_os.c",
  "human_readable_source": " \n \n\n#include <sys/spa.h>\n#include <sys/zio.h>\n#include <sys/spa_impl.h>\n#include <sys/zio_compress.h>\n#include <sys/zio_checksum.h>\n#include <sys/zfs_context.h>\n#include <sys/arc.h>\n#include <sys/zfs_refcount.h>\n#include <sys/vdev.h>\n#include <sys/vdev_trim.h>\n#include <sys/vdev_impl.h>\n#include <sys/dsl_pool.h>\n#include <sys/multilist.h>\n#include <sys/abd.h>\n#include <sys/zil.h>\n#include <sys/fm/fs/zfs.h>\n#ifdef _KERNEL\n#include <sys/shrinker.h>\n#include <sys/vmsystm.h>\n#include <sys/zpl.h>\n#include <linux/page_compat.h>\n#include <linux/notifier.h>\n#include <linux/memory.h>\n#endif\n#include <sys/callb.h>\n#include <sys/kstat.h>\n#include <sys/zthr.h>\n#include <zfs_fletcher.h>\n#include <sys/arc_impl.h>\n#include <sys/trace_zfs.h>\n#include <sys/aggsum.h>\n\n \nint zfs_arc_shrinker_limit = 10000;\n\n#ifdef CONFIG_MEMORY_HOTPLUG\nstatic struct notifier_block arc_hotplug_callback_mem_nb;\n#endif\n\n \nuint64_t\narc_default_max(uint64_t min, uint64_t allmem)\n{\n\t \n\treturn (MAX(allmem / 2, min));\n}\n\n#ifdef _KERNEL\n \nuint64_t\narc_all_memory(void)\n{\n#ifdef CONFIG_HIGHMEM\n\treturn (ptob(zfs_totalram_pages - zfs_totalhigh_pages));\n#else\n\treturn (ptob(zfs_totalram_pages));\n#endif  \n}\n\n \nuint64_t\narc_free_memory(void)\n{\n#ifdef CONFIG_HIGHMEM\n\tstruct sysinfo si;\n\tsi_meminfo(&si);\n\treturn (ptob(si.freeram - si.freehigh));\n#else\n\treturn (ptob(nr_free_pages() +\n\t    nr_inactive_file_pages()));\n#endif  \n}\n\n \nint64_t\narc_available_memory(void)\n{\n\treturn (arc_free_memory() - arc_sys_free);\n}\n\nstatic uint64_t\narc_evictable_memory(void)\n{\n\tint64_t asize = aggsum_value(&arc_sums.arcstat_size);\n\tuint64_t arc_clean =\n\t    zfs_refcount_count(&arc_mru->arcs_esize[ARC_BUFC_DATA]) +\n\t    zfs_refcount_count(&arc_mru->arcs_esize[ARC_BUFC_METADATA]) +\n\t    zfs_refcount_count(&arc_mfu->arcs_esize[ARC_BUFC_DATA]) +\n\t    zfs_refcount_count(&arc_mfu->arcs_esize[ARC_BUFC_METADATA]);\n\tuint64_t arc_dirty = MAX((int64_t)asize - (int64_t)arc_clean, 0);\n\n\t \n\tuint64_t min = (ptob(nr_file_pages()) / 100) * zfs_arc_pc_percent;\n\tmin = MAX(arc_c_min, MIN(arc_c_max, min));\n\n\tif (arc_dirty >= min)\n\t\treturn (arc_clean);\n\n\treturn (MAX((int64_t)asize - (int64_t)min, 0));\n}\n\n \nstatic unsigned long\narc_shrinker_count(struct shrinker *shrink, struct shrink_control *sc)\n{\n\t \n\tif (!(sc->gfp_mask & __GFP_FS)) {\n\t\treturn (0);\n\t}\n\n\t \n\tint64_t limit = zfs_arc_shrinker_limit != 0 ?\n\t    zfs_arc_shrinker_limit : INT64_MAX;\n\treturn (MIN(limit, btop((int64_t)arc_evictable_memory())));\n}\n\nstatic unsigned long\narc_shrinker_scan(struct shrinker *shrink, struct shrink_control *sc)\n{\n\tASSERT((sc->gfp_mask & __GFP_FS) != 0);\n\n\t \n\tif (unlikely(arc_warm == B_FALSE))\n\t\tarc_warm = B_TRUE;\n\n\t \n\tarc_reduce_target_size(ptob(sc->nr_to_scan));\n\tarc_wait_for_eviction(ptob(sc->nr_to_scan), B_FALSE);\n\tif (current->reclaim_state != NULL)\n#ifdef\tHAVE_RECLAIM_STATE_RECLAIMED\n\t\tcurrent->reclaim_state->reclaimed += sc->nr_to_scan;\n#else\n\t\tcurrent->reclaim_state->reclaimed_slab += sc->nr_to_scan;\n#endif\n\n\t \n\tarc_no_grow = B_TRUE;\n\n\t \n\tif (current_is_kswapd()) {\n\t\tARCSTAT_BUMP(arcstat_memory_indirect_count);\n\t} else {\n\t\tARCSTAT_BUMP(arcstat_memory_direct_count);\n\t}\n\n\treturn (sc->nr_to_scan);\n}\n\nSPL_SHRINKER_DECLARE(arc_shrinker,\n    arc_shrinker_count, arc_shrinker_scan, DEFAULT_SEEKS);\n\nint\narc_memory_throttle(spa_t *spa, uint64_t reserve, uint64_t txg)\n{\n\tuint64_t free_memory = arc_free_memory();\n\n\tif (free_memory > arc_all_memory() * arc_lotsfree_percent / 100)\n\t\treturn (0);\n\n\tif (txg > spa->spa_lowmem_last_txg) {\n\t\tspa->spa_lowmem_last_txg = txg;\n\t\tspa->spa_lowmem_page_load = 0;\n\t}\n\t \n\tif (current_is_kswapd()) {\n\t\tif (spa->spa_lowmem_page_load >\n\t\t    MAX(arc_sys_free / 4, free_memory) / 4) {\n\t\t\tDMU_TX_STAT_BUMP(dmu_tx_memory_reclaim);\n\t\t\treturn (SET_ERROR(ERESTART));\n\t\t}\n\t\t \n\t\tatomic_add_64(&spa->spa_lowmem_page_load, reserve / 8);\n\t\treturn (0);\n\t} else if (spa->spa_lowmem_page_load > 0 && arc_reclaim_needed()) {\n\t\t \n\t\tARCSTAT_INCR(arcstat_memory_throttle_count, 1);\n\t\tDMU_TX_STAT_BUMP(dmu_tx_memory_reclaim);\n\t\treturn (SET_ERROR(EAGAIN));\n\t}\n\tspa->spa_lowmem_page_load = 0;\n\treturn (0);\n}\n\nstatic void\narc_set_sys_free(uint64_t allmem)\n{\n\t \n\n\t \n\tlong wmark = 4 * int_sqrt(allmem/1024) * 1024;\n\n\t \n\twmark = MAX(wmark, 128 * 1024);\n\twmark = MIN(wmark, 64 * 1024 * 1024);\n\n\t \n\twmark += wmark * 150 / 100;\n\n\t \n\tarc_sys_free = wmark * 3 + allmem / 32;\n}\n\nvoid\narc_lowmem_init(void)\n{\n\tuint64_t allmem = arc_all_memory();\n\n\t \n\tspl_register_shrinker(&arc_shrinker);\n\tarc_set_sys_free(allmem);\n}\n\nvoid\narc_lowmem_fini(void)\n{\n\tspl_unregister_shrinker(&arc_shrinker);\n}\n\nint\nparam_set_arc_u64(const char *buf, zfs_kernel_param_t *kp)\n{\n\tint error;\n\n\terror = spl_param_set_u64(buf, kp);\n\tif (error < 0)\n\t\treturn (SET_ERROR(error));\n\n\tarc_tuning_update(B_TRUE);\n\n\treturn (0);\n}\n\nint\nparam_set_arc_min(const char *buf, zfs_kernel_param_t *kp)\n{\n\treturn (param_set_arc_u64(buf, kp));\n}\n\nint\nparam_set_arc_max(const char *buf, zfs_kernel_param_t *kp)\n{\n\treturn (param_set_arc_u64(buf, kp));\n}\n\nint\nparam_set_arc_int(const char *buf, zfs_kernel_param_t *kp)\n{\n\tint error;\n\n\terror = param_set_int(buf, kp);\n\tif (error < 0)\n\t\treturn (SET_ERROR(error));\n\n\tarc_tuning_update(B_TRUE);\n\n\treturn (0);\n}\n\n#ifdef CONFIG_MEMORY_HOTPLUG\nstatic int\narc_hotplug_callback(struct notifier_block *self, unsigned long action,\n    void *arg)\n{\n\t(void) self, (void) arg;\n\tuint64_t allmem = arc_all_memory();\n\tif (action != MEM_ONLINE)\n\t\treturn (NOTIFY_OK);\n\n\tarc_set_limits(allmem);\n\n#ifdef __LP64__\n\tif (zfs_dirty_data_max_max == 0)\n\t\tzfs_dirty_data_max_max = MIN(4ULL * 1024 * 1024 * 1024,\n\t\t    allmem * zfs_dirty_data_max_max_percent / 100);\n#else\n\tif (zfs_dirty_data_max_max == 0)\n\t\tzfs_dirty_data_max_max = MIN(1ULL * 1024 * 1024 * 1024,\n\t\t    allmem * zfs_dirty_data_max_max_percent / 100);\n#endif\n\n\tarc_set_sys_free(allmem);\n\treturn (NOTIFY_OK);\n}\n#endif\n\nvoid\narc_register_hotplug(void)\n{\n#ifdef CONFIG_MEMORY_HOTPLUG\n\tarc_hotplug_callback_mem_nb.notifier_call = arc_hotplug_callback;\n\t \n\tarc_hotplug_callback_mem_nb.priority = 100;\n\tregister_memory_notifier(&arc_hotplug_callback_mem_nb);\n#endif\n}\n\nvoid\narc_unregister_hotplug(void)\n{\n#ifdef CONFIG_MEMORY_HOTPLUG\n\tunregister_memory_notifier(&arc_hotplug_callback_mem_nb);\n#endif\n}\n#else  \nint64_t\narc_available_memory(void)\n{\n\tint64_t lowest = INT64_MAX;\n\n\t \n\tif (random_in_range(100) == 0)\n\t\tlowest = -1024;\n\n\treturn (lowest);\n}\n\nint\narc_memory_throttle(spa_t *spa, uint64_t reserve, uint64_t txg)\n{\n\t(void) spa, (void) reserve, (void) txg;\n\treturn (0);\n}\n\nuint64_t\narc_all_memory(void)\n{\n\treturn (ptob(physmem) / 2);\n}\n\nuint64_t\narc_free_memory(void)\n{\n\treturn (random_in_range(arc_all_memory() * 20 / 100));\n}\n\nvoid\narc_register_hotplug(void)\n{\n}\n\nvoid\narc_unregister_hotplug(void)\n{\n}\n#endif  \n\nZFS_MODULE_PARAM(zfs_arc, zfs_arc_, shrinker_limit, INT, ZMOD_RW,\n\t\"Limit on number of pages that ARC shrinker can reclaim at once\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}