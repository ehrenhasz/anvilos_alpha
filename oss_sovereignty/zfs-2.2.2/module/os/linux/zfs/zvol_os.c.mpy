{
  "module_name": "zvol_os.c",
  "hash_id": "982a6ab830aae05c1b7a168c79a8e70a4e06d5469be3157e6643a6aec99c07d2",
  "original_prompt": "Ingested from zfs-2.2.2/module/os/linux/zfs/zvol_os.c",
  "human_readable_source": " \n \n\n#include <sys/dataset_kstats.h>\n#include <sys/dbuf.h>\n#include <sys/dmu_traverse.h>\n#include <sys/dsl_dataset.h>\n#include <sys/dsl_prop.h>\n#include <sys/dsl_dir.h>\n#include <sys/zap.h>\n#include <sys/zfeature.h>\n#include <sys/zil_impl.h>\n#include <sys/dmu_tx.h>\n#include <sys/zio.h>\n#include <sys/zfs_rlock.h>\n#include <sys/spa_impl.h>\n#include <sys/zvol.h>\n#include <sys/zvol_impl.h>\n\n#include <linux/blkdev_compat.h>\n#include <linux/task_io_accounting_ops.h>\n\n#ifdef HAVE_BLK_MQ\n#include <linux/blk-mq.h>\n#endif\n\nstatic void zvol_request_impl(zvol_state_t *zv, struct bio *bio,\n    struct request *rq, boolean_t force_sync);\n\nstatic unsigned int zvol_major = ZVOL_MAJOR;\nstatic unsigned int zvol_request_sync = 0;\nstatic unsigned int zvol_prefetch_bytes = (128 * 1024);\nstatic unsigned long zvol_max_discard_blocks = 16384;\n\n#ifndef HAVE_BLKDEV_GET_ERESTARTSYS\nstatic unsigned int zvol_open_timeout_ms = 1000;\n#endif\n\nstatic unsigned int zvol_threads = 0;\n#ifdef HAVE_BLK_MQ\nstatic unsigned int zvol_blk_mq_threads = 0;\nstatic unsigned int zvol_blk_mq_actual_threads;\nstatic boolean_t zvol_use_blk_mq = B_FALSE;\n\n \nstatic unsigned int zvol_blk_mq_blocks_per_thread = 8;\n#endif\n\n#ifndef\tBLKDEV_DEFAULT_RQ\n \n#define\tBLKDEV_DEFAULT_RQ BLKDEV_MAX_RQ\n#endif\n\n \n#ifdef\tHAVE_BLK_MQ\n#define\tEND_IO(zv, bio, rq, error)  do { \\\n\tif (bio) { \\\n\t\tBIO_END_IO(bio, error); \\\n\t} else { \\\n\t\tblk_mq_end_request(rq, errno_to_bi_status(error)); \\\n\t} \\\n} while (0)\n#else\n#define\tEND_IO(zv, bio, rq, error)\tBIO_END_IO(bio, error)\n#endif\n\n#ifdef HAVE_BLK_MQ\nstatic unsigned int zvol_blk_mq_queue_depth = BLKDEV_DEFAULT_RQ;\nstatic unsigned int zvol_actual_blk_mq_queue_depth;\n#endif\n\nstruct zvol_state_os {\n\tstruct gendisk\t\t*zvo_disk;\t \n\tstruct request_queue\t*zvo_queue;\t \n\tdev_t\t\t\tzvo_dev;\t \n\n#ifdef HAVE_BLK_MQ\n\tstruct blk_mq_tag_set tag_set;\n#endif\n\n\t \n\tboolean_t use_blk_mq;\n};\n\nstatic taskq_t *zvol_taskq;\nstatic struct ida zvol_ida;\n\ntypedef struct zv_request_stack {\n\tzvol_state_t\t*zv;\n\tstruct bio\t*bio;\n\tstruct request *rq;\n} zv_request_t;\n\ntypedef struct zv_work {\n\tstruct request  *rq;\n\tstruct work_struct work;\n} zv_work_t;\n\ntypedef struct zv_request_task {\n\tzv_request_t zvr;\n\ttaskq_ent_t\tent;\n} zv_request_task_t;\n\nstatic zv_request_task_t *\nzv_request_task_create(zv_request_t zvr)\n{\n\tzv_request_task_t *task;\n\ttask = kmem_alloc(sizeof (zv_request_task_t), KM_SLEEP);\n\ttaskq_init_ent(&task->ent);\n\ttask->zvr = zvr;\n\treturn (task);\n}\n\nstatic void\nzv_request_task_free(zv_request_task_t *task)\n{\n\tkmem_free(task, sizeof (*task));\n}\n\n#ifdef HAVE_BLK_MQ\n\n \nstatic blk_status_t zvol_mq_queue_rq(struct blk_mq_hw_ctx *hctx,\n    const struct blk_mq_queue_data *bd)\n{\n\tstruct request *rq = bd->rq;\n\tzvol_state_t *zv = rq->q->queuedata;\n\n\t \n\tblk_mq_start_request(rq);\n\n\tif (blk_rq_is_passthrough(rq)) {\n\t\t \n\t\tblk_mq_end_request(rq, BLK_STS_IOERR);\n\t\treturn (BLK_STS_IOERR);\n\t}\n\n\tzvol_request_impl(zv, NULL, rq, 0);\n\n\t \n\treturn (BLK_STS_OK);\n}\n\nstatic struct blk_mq_ops zvol_blk_mq_queue_ops = {\n\t.queue_rq = zvol_mq_queue_rq,\n};\n\n \nstatic int zvol_blk_mq_alloc_tag_set(zvol_state_t *zv)\n{\n\tstruct zvol_state_os *zso = zv->zv_zso;\n\n\tmemset(&zso->tag_set, 0, sizeof (zso->tag_set));\n\n\t \n\tzso->tag_set.ops = &zvol_blk_mq_queue_ops;\n\tzso->tag_set.nr_hw_queues = zvol_blk_mq_actual_threads;\n\tzso->tag_set.queue_depth = zvol_actual_blk_mq_queue_depth;\n\tzso->tag_set.numa_node = NUMA_NO_NODE;\n\tzso->tag_set.cmd_size = 0;\n\n\t \n\tzso->tag_set.flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_BLOCKING;\n\tzso->tag_set.driver_data = zv;\n\n\treturn (blk_mq_alloc_tag_set(&zso->tag_set));\n}\n#endif  \n\n \nboolean_t\nzvol_os_is_zvol(const char *path)\n{\n\tdev_t dev = 0;\n\n\tif (vdev_lookup_bdev(path, &dev) != 0)\n\t\treturn (B_FALSE);\n\n\tif (MAJOR(dev) == zvol_major)\n\t\treturn (B_TRUE);\n\n\treturn (B_FALSE);\n}\n\nstatic void\nzvol_write(zv_request_t *zvr)\n{\n\tstruct bio *bio = zvr->bio;\n\tstruct request *rq = zvr->rq;\n\tint error = 0;\n\tzfs_uio_t uio;\n\tzvol_state_t *zv = zvr->zv;\n\tstruct request_queue *q;\n\tstruct gendisk *disk;\n\tunsigned long start_time = 0;\n\tboolean_t acct = B_FALSE;\n\n\tASSERT3P(zv, !=, NULL);\n\tASSERT3U(zv->zv_open_count, >, 0);\n\tASSERT3P(zv->zv_zilog, !=, NULL);\n\n\tq = zv->zv_zso->zvo_queue;\n\tdisk = zv->zv_zso->zvo_disk;\n\n\t \n\tif (io_is_flush(bio, rq))\n\t\tzil_commit(zv->zv_zilog, ZVOL_OBJ);\n\n\t \n\tif (io_size(bio, rq) == 0) {\n\t\trw_exit(&zv->zv_suspend_lock);\n\t\tEND_IO(zv, bio, rq, 0);\n\t\treturn;\n\t}\n\n\tzfs_uio_bvec_init(&uio, bio, rq);\n\n\tssize_t start_resid = uio.uio_resid;\n\n\t \n\tif (bio) {\n\t\tacct = blk_queue_io_stat(q);\n\t\tif (acct) {\n\t\t\tstart_time = blk_generic_start_io_acct(q, disk, WRITE,\n\t\t\t    bio);\n\t\t}\n\t}\n\n\tboolean_t sync =\n\t    io_is_fua(bio, rq) || zv->zv_objset->os_sync == ZFS_SYNC_ALWAYS;\n\n\tzfs_locked_range_t *lr = zfs_rangelock_enter(&zv->zv_rangelock,\n\t    uio.uio_loffset, uio.uio_resid, RL_WRITER);\n\n\tuint64_t volsize = zv->zv_volsize;\n\twhile (uio.uio_resid > 0 && uio.uio_loffset < volsize) {\n\t\tuint64_t bytes = MIN(uio.uio_resid, DMU_MAX_ACCESS >> 1);\n\t\tuint64_t off = uio.uio_loffset;\n\t\tdmu_tx_t *tx = dmu_tx_create(zv->zv_objset);\n\n\t\tif (bytes > volsize - off)\t \n\t\t\tbytes = volsize - off;\n\n\t\tdmu_tx_hold_write_by_dnode(tx, zv->zv_dn, off, bytes);\n\n\t\t \n\t\terror = dmu_tx_assign(tx, TXG_WAIT);\n\t\tif (error) {\n\t\t\tdmu_tx_abort(tx);\n\t\t\tbreak;\n\t\t}\n\t\terror = dmu_write_uio_dnode(zv->zv_dn, &uio, bytes, tx);\n\t\tif (error == 0) {\n\t\t\tzvol_log_write(zv, tx, off, bytes, sync);\n\t\t}\n\t\tdmu_tx_commit(tx);\n\n\t\tif (error)\n\t\t\tbreak;\n\t}\n\tzfs_rangelock_exit(lr);\n\n\tint64_t nwritten = start_resid - uio.uio_resid;\n\tdataset_kstats_update_write_kstats(&zv->zv_kstat, nwritten);\n\ttask_io_account_write(nwritten);\n\n\tif (sync)\n\t\tzil_commit(zv->zv_zilog, ZVOL_OBJ);\n\n\trw_exit(&zv->zv_suspend_lock);\n\n\tif (bio && acct) {\n\t\tblk_generic_end_io_acct(q, disk, WRITE, bio, start_time);\n\t}\n\n\tEND_IO(zv, bio, rq, -error);\n}\n\nstatic void\nzvol_write_task(void *arg)\n{\n\tzv_request_task_t *task = arg;\n\tzvol_write(&task->zvr);\n\tzv_request_task_free(task);\n}\n\nstatic void\nzvol_discard(zv_request_t *zvr)\n{\n\tstruct bio *bio = zvr->bio;\n\tstruct request *rq = zvr->rq;\n\tzvol_state_t *zv = zvr->zv;\n\tuint64_t start = io_offset(bio, rq);\n\tuint64_t size = io_size(bio, rq);\n\tuint64_t end = start + size;\n\tboolean_t sync;\n\tint error = 0;\n\tdmu_tx_t *tx;\n\tstruct request_queue *q = zv->zv_zso->zvo_queue;\n\tstruct gendisk *disk = zv->zv_zso->zvo_disk;\n\tunsigned long start_time = 0;\n\tboolean_t acct = B_FALSE;\n\n\tASSERT3P(zv, !=, NULL);\n\tASSERT3U(zv->zv_open_count, >, 0);\n\tASSERT3P(zv->zv_zilog, !=, NULL);\n\n\tif (bio) {\n\t\tacct = blk_queue_io_stat(q);\n\t\tif (acct) {\n\t\t\tstart_time = blk_generic_start_io_acct(q, disk, WRITE,\n\t\t\t    bio);\n\t\t}\n\t}\n\n\tsync = io_is_fua(bio, rq) || zv->zv_objset->os_sync == ZFS_SYNC_ALWAYS;\n\n\tif (end > zv->zv_volsize) {\n\t\terror = SET_ERROR(EIO);\n\t\tgoto unlock;\n\t}\n\n\t \n\tif (!io_is_secure_erase(bio, rq)) {\n\t\tstart = P2ROUNDUP(start, zv->zv_volblocksize);\n\t\tend = P2ALIGN(end, zv->zv_volblocksize);\n\t\tsize = end - start;\n\t}\n\n\tif (start >= end)\n\t\tgoto unlock;\n\n\tzfs_locked_range_t *lr = zfs_rangelock_enter(&zv->zv_rangelock,\n\t    start, size, RL_WRITER);\n\n\ttx = dmu_tx_create(zv->zv_objset);\n\tdmu_tx_mark_netfree(tx);\n\terror = dmu_tx_assign(tx, TXG_WAIT);\n\tif (error != 0) {\n\t\tdmu_tx_abort(tx);\n\t} else {\n\t\tzvol_log_truncate(zv, tx, start, size, B_TRUE);\n\t\tdmu_tx_commit(tx);\n\t\terror = dmu_free_long_range(zv->zv_objset,\n\t\t    ZVOL_OBJ, start, size);\n\t}\n\tzfs_rangelock_exit(lr);\n\n\tif (error == 0 && sync)\n\t\tzil_commit(zv->zv_zilog, ZVOL_OBJ);\n\nunlock:\n\trw_exit(&zv->zv_suspend_lock);\n\n\tif (bio && acct) {\n\t\tblk_generic_end_io_acct(q, disk, WRITE, bio,\n\t\t    start_time);\n\t}\n\n\tEND_IO(zv, bio, rq, -error);\n}\n\nstatic void\nzvol_discard_task(void *arg)\n{\n\tzv_request_task_t *task = arg;\n\tzvol_discard(&task->zvr);\n\tzv_request_task_free(task);\n}\n\nstatic void\nzvol_read(zv_request_t *zvr)\n{\n\tstruct bio *bio = zvr->bio;\n\tstruct request *rq = zvr->rq;\n\tint error = 0;\n\tzfs_uio_t uio;\n\tboolean_t acct = B_FALSE;\n\tzvol_state_t *zv = zvr->zv;\n\tstruct request_queue *q;\n\tstruct gendisk *disk;\n\tunsigned long start_time = 0;\n\n\tASSERT3P(zv, !=, NULL);\n\tASSERT3U(zv->zv_open_count, >, 0);\n\n\tzfs_uio_bvec_init(&uio, bio, rq);\n\n\tq = zv->zv_zso->zvo_queue;\n\tdisk = zv->zv_zso->zvo_disk;\n\n\tssize_t start_resid = uio.uio_resid;\n\n\t \n\tif (bio) {\n\t\tacct = blk_queue_io_stat(q);\n\t\tif (acct)\n\t\t\tstart_time = blk_generic_start_io_acct(q, disk, READ,\n\t\t\t    bio);\n\t}\n\n\tzfs_locked_range_t *lr = zfs_rangelock_enter(&zv->zv_rangelock,\n\t    uio.uio_loffset, uio.uio_resid, RL_READER);\n\n\tuint64_t volsize = zv->zv_volsize;\n\n\twhile (uio.uio_resid > 0 && uio.uio_loffset < volsize) {\n\t\tuint64_t bytes = MIN(uio.uio_resid, DMU_MAX_ACCESS >> 1);\n\n\t\t \n\t\tif (bytes > volsize - uio.uio_loffset)\n\t\t\tbytes = volsize - uio.uio_loffset;\n\n\t\terror = dmu_read_uio_dnode(zv->zv_dn, &uio, bytes);\n\t\tif (error) {\n\t\t\t \n\t\t\tif (error == ECKSUM)\n\t\t\t\terror = SET_ERROR(EIO);\n\t\t\tbreak;\n\t\t}\n\t}\n\tzfs_rangelock_exit(lr);\n\n\tint64_t nread = start_resid - uio.uio_resid;\n\tdataset_kstats_update_read_kstats(&zv->zv_kstat, nread);\n\ttask_io_account_read(nread);\n\n\trw_exit(&zv->zv_suspend_lock);\n\n\tif (bio && acct) {\n\t\tblk_generic_end_io_acct(q, disk, READ, bio, start_time);\n\t}\n\n\tEND_IO(zv, bio, rq, -error);\n}\n\nstatic void\nzvol_read_task(void *arg)\n{\n\tzv_request_task_t *task = arg;\n\tzvol_read(&task->zvr);\n\tzv_request_task_free(task);\n}\n\n\n \nstatic void\nzvol_request_impl(zvol_state_t *zv, struct bio *bio, struct request *rq,\n    boolean_t force_sync)\n{\n\tfstrans_cookie_t cookie = spl_fstrans_mark();\n\tuint64_t offset = io_offset(bio, rq);\n\tuint64_t size = io_size(bio, rq);\n\tint rw = io_data_dir(bio, rq);\n\n\tif (zvol_request_sync)\n\t\tforce_sync = 1;\n\n\tzv_request_t zvr = {\n\t\t.zv = zv,\n\t\t.bio = bio,\n\t\t.rq = rq,\n\t};\n\n\tif (io_has_data(bio, rq) && offset + size > zv->zv_volsize) {\n\t\tprintk(KERN_INFO \"%s: bad access: offset=%llu, size=%lu\\n\",\n\t\t    zv->zv_zso->zvo_disk->disk_name,\n\t\t    (long long unsigned)offset,\n\t\t    (long unsigned)size);\n\n\t\tEND_IO(zv, bio, rq, -SET_ERROR(EIO));\n\t\tgoto out;\n\t}\n\n\tzv_request_task_t *task;\n\n\tif (rw == WRITE) {\n\t\tif (unlikely(zv->zv_flags & ZVOL_RDONLY)) {\n\t\t\tEND_IO(zv, bio, rq, -SET_ERROR(EROFS));\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\trw_enter(&zv->zv_suspend_lock, RW_READER);\n\n\t\t \n\t\tif (zv->zv_zilog == NULL) {\n\t\t\trw_exit(&zv->zv_suspend_lock);\n\t\t\trw_enter(&zv->zv_suspend_lock, RW_WRITER);\n\t\t\tif (zv->zv_zilog == NULL) {\n\t\t\t\tzv->zv_zilog = zil_open(zv->zv_objset,\n\t\t\t\t    zvol_get_data, &zv->zv_kstat.dk_zil_sums);\n\t\t\t\tzv->zv_flags |= ZVOL_WRITTEN_TO;\n\t\t\t\t \n\t\t\t\tVERIFY0((zv->zv_zilog->zl_header->zh_flags &\n\t\t\t\t    ZIL_REPLAY_NEEDED));\n\t\t\t}\n\t\t\trw_downgrade(&zv->zv_suspend_lock);\n\t\t}\n\n\t\t \n\t\tif (io_is_discard(bio, rq) || io_is_secure_erase(bio, rq)) {\n\t\t\tif (force_sync) {\n\t\t\t\tzvol_discard(&zvr);\n\t\t\t} else {\n\t\t\t\ttask = zv_request_task_create(zvr);\n\t\t\t\ttaskq_dispatch_ent(zvol_taskq,\n\t\t\t\t    zvol_discard_task, task, 0, &task->ent);\n\t\t\t}\n\t\t} else {\n\t\t\tif (force_sync) {\n\t\t\t\tzvol_write(&zvr);\n\t\t\t} else {\n\t\t\t\ttask = zv_request_task_create(zvr);\n\t\t\t\ttaskq_dispatch_ent(zvol_taskq,\n\t\t\t\t    zvol_write_task, task, 0, &task->ent);\n\t\t\t}\n\t\t}\n\t} else {\n\t\t \n\t\tif (size == 0) {\n\t\t\tEND_IO(zv, bio, rq, 0);\n\t\t\tgoto out;\n\t\t}\n\n\t\trw_enter(&zv->zv_suspend_lock, RW_READER);\n\n\t\t \n\t\tif (force_sync) {\n\t\t\tzvol_read(&zvr);\n\t\t} else {\n\t\t\ttask = zv_request_task_create(zvr);\n\t\t\ttaskq_dispatch_ent(zvol_taskq,\n\t\t\t    zvol_read_task, task, 0, &task->ent);\n\t\t}\n\t}\n\nout:\n\tspl_fstrans_unmark(cookie);\n}\n\n#ifdef HAVE_SUBMIT_BIO_IN_BLOCK_DEVICE_OPERATIONS\n#ifdef HAVE_BDEV_SUBMIT_BIO_RETURNS_VOID\nstatic void\nzvol_submit_bio(struct bio *bio)\n#else\nstatic blk_qc_t\nzvol_submit_bio(struct bio *bio)\n#endif\n#else\nstatic MAKE_REQUEST_FN_RET\nzvol_request(struct request_queue *q, struct bio *bio)\n#endif\n{\n#ifdef HAVE_SUBMIT_BIO_IN_BLOCK_DEVICE_OPERATIONS\n#if defined(HAVE_BIO_BDEV_DISK)\n\tstruct request_queue *q = bio->bi_bdev->bd_disk->queue;\n#else\n\tstruct request_queue *q = bio->bi_disk->queue;\n#endif\n#endif\n\tzvol_state_t *zv = q->queuedata;\n\n\tzvol_request_impl(zv, bio, NULL, 0);\n#if defined(HAVE_MAKE_REQUEST_FN_RET_QC) || \\\n\tdefined(HAVE_SUBMIT_BIO_IN_BLOCK_DEVICE_OPERATIONS) && \\\n\t!defined(HAVE_BDEV_SUBMIT_BIO_RETURNS_VOID)\n\treturn (BLK_QC_T_NONE);\n#endif\n}\n\nstatic int\n#ifdef HAVE_BLK_MODE_T\nzvol_open(struct gendisk *disk, blk_mode_t flag)\n#else\nzvol_open(struct block_device *bdev, fmode_t flag)\n#endif\n{\n\tzvol_state_t *zv;\n\tint error = 0;\n\tboolean_t drop_suspend = B_FALSE;\n#ifndef HAVE_BLKDEV_GET_ERESTARTSYS\n\thrtime_t timeout = MSEC2NSEC(zvol_open_timeout_ms);\n\thrtime_t start = gethrtime();\n\nretry:\n#endif\n\trw_enter(&zvol_state_lock, RW_READER);\n\t \n#ifdef HAVE_BLK_MODE_T\n\tzv = disk->private_data;\n#else\n\tzv = bdev->bd_disk->private_data;\n#endif\n\tif (zv == NULL) {\n\t\trw_exit(&zvol_state_lock);\n\t\treturn (SET_ERROR(-ENXIO));\n\t}\n\n\tmutex_enter(&zv->zv_state_lock);\n\t \n\tif (zv->zv_open_count == 0) {\n\t\tif (!rw_tryenter(&zv->zv_suspend_lock, RW_READER)) {\n\t\t\tmutex_exit(&zv->zv_state_lock);\n\t\t\trw_enter(&zv->zv_suspend_lock, RW_READER);\n\t\t\tmutex_enter(&zv->zv_state_lock);\n\t\t\t \n\t\t\tif (zv->zv_open_count != 0) {\n\t\t\t\trw_exit(&zv->zv_suspend_lock);\n\t\t\t} else {\n\t\t\t\tdrop_suspend = B_TRUE;\n\t\t\t}\n\t\t} else {\n\t\t\tdrop_suspend = B_TRUE;\n\t\t}\n\t}\n\trw_exit(&zvol_state_lock);\n\n\tASSERT(MUTEX_HELD(&zv->zv_state_lock));\n\n\tif (zv->zv_open_count == 0) {\n\t\tboolean_t drop_namespace = B_FALSE;\n\n\t\tASSERT(RW_READ_HELD(&zv->zv_suspend_lock));\n\n\t\t \n\t\tif (!mutex_owned(&spa_namespace_lock)) {\n\t\t\tif (!mutex_tryenter(&spa_namespace_lock)) {\n\t\t\t\tmutex_exit(&zv->zv_state_lock);\n\t\t\t\trw_exit(&zv->zv_suspend_lock);\n\n#ifdef HAVE_BLKDEV_GET_ERESTARTSYS\n\t\t\t\tschedule();\n\t\t\t\treturn (SET_ERROR(-ERESTARTSYS));\n#else\n\t\t\t\tif ((gethrtime() - start) > timeout)\n\t\t\t\t\treturn (SET_ERROR(-ERESTARTSYS));\n\n\t\t\t\tschedule_timeout(MSEC_TO_TICK(10));\n\t\t\t\tgoto retry;\n#endif\n\t\t\t} else {\n\t\t\t\tdrop_namespace = B_TRUE;\n\t\t\t}\n\t\t}\n\n\t\terror = -zvol_first_open(zv, !(blk_mode_is_open_write(flag)));\n\n\t\tif (drop_namespace)\n\t\t\tmutex_exit(&spa_namespace_lock);\n\t}\n\n\tif (error == 0) {\n\t\tif ((blk_mode_is_open_write(flag)) &&\n\t\t    (zv->zv_flags & ZVOL_RDONLY)) {\n\t\t\tif (zv->zv_open_count == 0)\n\t\t\t\tzvol_last_close(zv);\n\n\t\t\terror = SET_ERROR(-EROFS);\n\t\t} else {\n\t\t\tzv->zv_open_count++;\n\t\t}\n\t}\n\n\tmutex_exit(&zv->zv_state_lock);\n\tif (drop_suspend)\n\t\trw_exit(&zv->zv_suspend_lock);\n\n\tif (error == 0)\n#ifdef HAVE_BLK_MODE_T\n\t\tdisk_check_media_change(disk);\n#else\n\t\tzfs_check_media_change(bdev);\n#endif\n\n\treturn (error);\n}\n\nstatic void\n#ifdef HAVE_BLOCK_DEVICE_OPERATIONS_RELEASE_1ARG\nzvol_release(struct gendisk *disk)\n#else\nzvol_release(struct gendisk *disk, fmode_t unused)\n#endif\n{\n#if !defined(HAVE_BLOCK_DEVICE_OPERATIONS_RELEASE_1ARG)\n\t(void) unused;\n#endif\n\tzvol_state_t *zv;\n\tboolean_t drop_suspend = B_TRUE;\n\n\trw_enter(&zvol_state_lock, RW_READER);\n\tzv = disk->private_data;\n\n\tmutex_enter(&zv->zv_state_lock);\n\tASSERT3U(zv->zv_open_count, >, 0);\n\t \n\tif (zv->zv_open_count == 1) {\n\t\tif (!rw_tryenter(&zv->zv_suspend_lock, RW_READER)) {\n\t\t\tmutex_exit(&zv->zv_state_lock);\n\t\t\trw_enter(&zv->zv_suspend_lock, RW_READER);\n\t\t\tmutex_enter(&zv->zv_state_lock);\n\t\t\t \n\t\t\tif (zv->zv_open_count != 1) {\n\t\t\t\trw_exit(&zv->zv_suspend_lock);\n\t\t\t\tdrop_suspend = B_FALSE;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tdrop_suspend = B_FALSE;\n\t}\n\trw_exit(&zvol_state_lock);\n\n\tASSERT(MUTEX_HELD(&zv->zv_state_lock));\n\n\tzv->zv_open_count--;\n\tif (zv->zv_open_count == 0) {\n\t\tASSERT(RW_READ_HELD(&zv->zv_suspend_lock));\n\t\tzvol_last_close(zv);\n\t}\n\n\tmutex_exit(&zv->zv_state_lock);\n\n\tif (drop_suspend)\n\t\trw_exit(&zv->zv_suspend_lock);\n}\n\nstatic int\nzvol_ioctl(struct block_device *bdev, fmode_t mode,\n    unsigned int cmd, unsigned long arg)\n{\n\tzvol_state_t *zv = bdev->bd_disk->private_data;\n\tint error = 0;\n\n\tASSERT3U(zv->zv_open_count, >, 0);\n\n\tswitch (cmd) {\n\tcase BLKFLSBUF:\n#ifdef HAVE_FSYNC_BDEV\n\t\tfsync_bdev(bdev);\n#elif defined(HAVE_SYNC_BLOCKDEV)\n\t\tsync_blockdev(bdev);\n#else\n#error \"Neither fsync_bdev() nor sync_blockdev() found\"\n#endif\n\t\tinvalidate_bdev(bdev);\n\t\trw_enter(&zv->zv_suspend_lock, RW_READER);\n\n\t\tif (!(zv->zv_flags & ZVOL_RDONLY))\n\t\t\ttxg_wait_synced(dmu_objset_pool(zv->zv_objset), 0);\n\n\t\trw_exit(&zv->zv_suspend_lock);\n\t\tbreak;\n\n\tcase BLKZNAME:\n\t\tmutex_enter(&zv->zv_state_lock);\n\t\terror = copy_to_user((void *)arg, zv->zv_name, MAXNAMELEN);\n\t\tmutex_exit(&zv->zv_state_lock);\n\t\tbreak;\n\n\tdefault:\n\t\terror = -ENOTTY;\n\t\tbreak;\n\t}\n\n\treturn (SET_ERROR(error));\n}\n\n#ifdef CONFIG_COMPAT\nstatic int\nzvol_compat_ioctl(struct block_device *bdev, fmode_t mode,\n    unsigned cmd, unsigned long arg)\n{\n\treturn (zvol_ioctl(bdev, mode, cmd, arg));\n}\n#else\n#define\tzvol_compat_ioctl\tNULL\n#endif\n\nstatic unsigned int\nzvol_check_events(struct gendisk *disk, unsigned int clearing)\n{\n\tunsigned int mask = 0;\n\n\trw_enter(&zvol_state_lock, RW_READER);\n\n\tzvol_state_t *zv = disk->private_data;\n\tif (zv != NULL) {\n\t\tmutex_enter(&zv->zv_state_lock);\n\t\tmask = zv->zv_changed ? DISK_EVENT_MEDIA_CHANGE : 0;\n\t\tzv->zv_changed = 0;\n\t\tmutex_exit(&zv->zv_state_lock);\n\t}\n\n\trw_exit(&zvol_state_lock);\n\n\treturn (mask);\n}\n\nstatic int\nzvol_revalidate_disk(struct gendisk *disk)\n{\n\trw_enter(&zvol_state_lock, RW_READER);\n\n\tzvol_state_t *zv = disk->private_data;\n\tif (zv != NULL) {\n\t\tmutex_enter(&zv->zv_state_lock);\n\t\tset_capacity(zv->zv_zso->zvo_disk,\n\t\t    zv->zv_volsize >> SECTOR_BITS);\n\t\tmutex_exit(&zv->zv_state_lock);\n\t}\n\n\trw_exit(&zvol_state_lock);\n\n\treturn (0);\n}\n\nint\nzvol_os_update_volsize(zvol_state_t *zv, uint64_t volsize)\n{\n\tstruct gendisk *disk = zv->zv_zso->zvo_disk;\n\n#if defined(HAVE_REVALIDATE_DISK_SIZE)\n\trevalidate_disk_size(disk, zvol_revalidate_disk(disk) == 0);\n#elif defined(HAVE_REVALIDATE_DISK)\n\trevalidate_disk(disk);\n#else\n\tzvol_revalidate_disk(disk);\n#endif\n\treturn (0);\n}\n\nvoid\nzvol_os_clear_private(zvol_state_t *zv)\n{\n\t \n\tzv->zv_zso->zvo_disk->private_data = NULL;\n}\n\n \nstatic int\nzvol_getgeo(struct block_device *bdev, struct hd_geometry *geo)\n{\n\tzvol_state_t *zv = bdev->bd_disk->private_data;\n\tsector_t sectors;\n\n\tASSERT3U(zv->zv_open_count, >, 0);\n\n\tsectors = get_capacity(zv->zv_zso->zvo_disk);\n\n\tif (sectors > 2048) {\n\t\tgeo->heads = 16;\n\t\tgeo->sectors = 63;\n\t} else {\n\t\tgeo->heads = 2;\n\t\tgeo->sectors = 4;\n\t}\n\n\tgeo->start = 0;\n\tgeo->cylinders = sectors / (geo->heads * geo->sectors);\n\n\treturn (0);\n}\n\n \nstatic const struct block_device_operations zvol_ops_blk_mq = {\n\t.open\t\t\t= zvol_open,\n\t.release\t\t= zvol_release,\n\t.ioctl\t\t\t= zvol_ioctl,\n\t.compat_ioctl\t\t= zvol_compat_ioctl,\n\t.check_events\t\t= zvol_check_events,\n#ifdef HAVE_BLOCK_DEVICE_OPERATIONS_REVALIDATE_DISK\n\t.revalidate_disk\t= zvol_revalidate_disk,\n#endif\n\t.getgeo\t\t\t= zvol_getgeo,\n\t.owner\t\t\t= THIS_MODULE,\n};\n\nstatic const struct block_device_operations zvol_ops = {\n\t.open\t\t\t= zvol_open,\n\t.release\t\t= zvol_release,\n\t.ioctl\t\t\t= zvol_ioctl,\n\t.compat_ioctl\t\t= zvol_compat_ioctl,\n\t.check_events\t\t= zvol_check_events,\n#ifdef HAVE_BLOCK_DEVICE_OPERATIONS_REVALIDATE_DISK\n\t.revalidate_disk\t= zvol_revalidate_disk,\n#endif\n\t.getgeo\t\t\t= zvol_getgeo,\n\t.owner\t\t\t= THIS_MODULE,\n#ifdef HAVE_SUBMIT_BIO_IN_BLOCK_DEVICE_OPERATIONS\n\t.submit_bio\t\t= zvol_submit_bio,\n#endif\n};\n\nstatic int\nzvol_alloc_non_blk_mq(struct zvol_state_os *zso)\n{\n#if defined(HAVE_SUBMIT_BIO_IN_BLOCK_DEVICE_OPERATIONS)\n#if defined(HAVE_BLK_ALLOC_DISK)\n\tzso->zvo_disk = blk_alloc_disk(NUMA_NO_NODE);\n\tif (zso->zvo_disk == NULL)\n\t\treturn (1);\n\n\tzso->zvo_disk->minors = ZVOL_MINORS;\n\tzso->zvo_queue = zso->zvo_disk->queue;\n#else\n\tzso->zvo_queue = blk_alloc_queue(NUMA_NO_NODE);\n\tif (zso->zvo_queue == NULL)\n\t\treturn (1);\n\n\tzso->zvo_disk = alloc_disk(ZVOL_MINORS);\n\tif (zso->zvo_disk == NULL) {\n\t\tblk_cleanup_queue(zso->zvo_queue);\n\t\treturn (1);\n\t}\n\n\tzso->zvo_disk->queue = zso->zvo_queue;\n#endif  \n#else\n\tzso->zvo_queue = blk_generic_alloc_queue(zvol_request, NUMA_NO_NODE);\n\tif (zso->zvo_queue == NULL)\n\t\treturn (1);\n\n\tzso->zvo_disk = alloc_disk(ZVOL_MINORS);\n\tif (zso->zvo_disk == NULL) {\n\t\tblk_cleanup_queue(zso->zvo_queue);\n\t\treturn (1);\n\t}\n\n\tzso->zvo_disk->queue = zso->zvo_queue;\n#endif  \n\treturn (0);\n\n}\n\nstatic int\nzvol_alloc_blk_mq(zvol_state_t *zv)\n{\n#ifdef HAVE_BLK_MQ\n\tstruct zvol_state_os *zso = zv->zv_zso;\n\n\t \n\tif (zvol_blk_mq_alloc_tag_set(zv) != 0)\n\t\treturn (1);\n\n#if defined(HAVE_BLK_ALLOC_DISK)\n\tzso->zvo_disk = blk_mq_alloc_disk(&zso->tag_set, zv);\n\tif (zso->zvo_disk == NULL) {\n\t\tblk_mq_free_tag_set(&zso->tag_set);\n\t\treturn (1);\n\t}\n\tzso->zvo_queue = zso->zvo_disk->queue;\n\tzso->zvo_disk->minors = ZVOL_MINORS;\n#else\n\tzso->zvo_disk = alloc_disk(ZVOL_MINORS);\n\tif (zso->zvo_disk == NULL) {\n\t\tblk_cleanup_queue(zso->zvo_queue);\n\t\tblk_mq_free_tag_set(&zso->tag_set);\n\t\treturn (1);\n\t}\n\t \n\tzso->zvo_queue = blk_mq_init_queue(&zso->tag_set);\n\tif (IS_ERR(zso->zvo_queue)) {\n\t\tblk_mq_free_tag_set(&zso->tag_set);\n\t\treturn (1);\n\t}\n\n\t \n\tzso->zvo_disk->queue = zso->zvo_queue;\n\n#endif\n#endif\n\treturn (0);\n}\n\n \nstatic zvol_state_t *\nzvol_alloc(dev_t dev, const char *name)\n{\n\tzvol_state_t *zv;\n\tstruct zvol_state_os *zso;\n\tuint64_t volmode;\n\tint ret;\n\n\tif (dsl_prop_get_integer(name, \"volmode\", &volmode, NULL) != 0)\n\t\treturn (NULL);\n\n\tif (volmode == ZFS_VOLMODE_DEFAULT)\n\t\tvolmode = zvol_volmode;\n\n\tif (volmode == ZFS_VOLMODE_NONE)\n\t\treturn (NULL);\n\n\tzv = kmem_zalloc(sizeof (zvol_state_t), KM_SLEEP);\n\tzso = kmem_zalloc(sizeof (struct zvol_state_os), KM_SLEEP);\n\tzv->zv_zso = zso;\n\tzv->zv_volmode = volmode;\n\n\tlist_link_init(&zv->zv_next);\n\tmutex_init(&zv->zv_state_lock, NULL, MUTEX_DEFAULT, NULL);\n\n#ifdef HAVE_BLK_MQ\n\tzv->zv_zso->use_blk_mq = zvol_use_blk_mq;\n#endif\n\n\t \n\tif (zv->zv_zso->use_blk_mq) {\n\t\tret = zvol_alloc_blk_mq(zv);\n\t\tzso->zvo_disk->fops = &zvol_ops_blk_mq;\n\t} else {\n\t\tret = zvol_alloc_non_blk_mq(zso);\n\t\tzso->zvo_disk->fops = &zvol_ops;\n\t}\n\tif (ret != 0)\n\t\tgoto out_kmem;\n\n\tblk_queue_set_write_cache(zso->zvo_queue, B_TRUE, B_TRUE);\n\n\t \n\tblk_queue_set_read_ahead(zso->zvo_queue, 1);\n\n\tif (!zv->zv_zso->use_blk_mq) {\n\t\t \n\t\tblk_queue_flag_set(QUEUE_FLAG_NOMERGES, zso->zvo_queue);\n\t}\n\n\t \n\tblk_queue_flag_set(QUEUE_FLAG_IO_STAT, zso->zvo_queue);\n\n\tzso->zvo_queue->queuedata = zv;\n\tzso->zvo_dev = dev;\n\tzv->zv_open_count = 0;\n\tstrlcpy(zv->zv_name, name, MAXNAMELEN);\n\n\tzfs_rangelock_init(&zv->zv_rangelock, NULL, NULL);\n\trw_init(&zv->zv_suspend_lock, NULL, RW_DEFAULT, NULL);\n\n\tzso->zvo_disk->major = zvol_major;\n\tzso->zvo_disk->events = DISK_EVENT_MEDIA_CHANGE;\n\n\t \n\tif (volmode == ZFS_VOLMODE_DEV) {\n\t\tzso->zvo_disk->minors = 1;\n\t\tzso->zvo_disk->flags &= ~ZFS_GENHD_FL_EXT_DEVT;\n\t\tzso->zvo_disk->flags |= ZFS_GENHD_FL_NO_PART;\n\t}\n\n\tzso->zvo_disk->first_minor = (dev & MINORMASK);\n\tzso->zvo_disk->private_data = zv;\n\tsnprintf(zso->zvo_disk->disk_name, DISK_NAME_LEN, \"%s%d\",\n\t    ZVOL_DEV_NAME, (dev & MINORMASK));\n\n\treturn (zv);\n\nout_kmem:\n\tkmem_free(zso, sizeof (struct zvol_state_os));\n\tkmem_free(zv, sizeof (zvol_state_t));\n\treturn (NULL);\n}\n\n \nvoid\nzvol_os_free(zvol_state_t *zv)\n{\n\n\tASSERT(!RW_LOCK_HELD(&zv->zv_suspend_lock));\n\tASSERT(!MUTEX_HELD(&zv->zv_state_lock));\n\tASSERT0(zv->zv_open_count);\n\tASSERT3P(zv->zv_zso->zvo_disk->private_data, ==, NULL);\n\n\trw_destroy(&zv->zv_suspend_lock);\n\tzfs_rangelock_fini(&zv->zv_rangelock);\n\n\tdel_gendisk(zv->zv_zso->zvo_disk);\n#if defined(HAVE_SUBMIT_BIO_IN_BLOCK_DEVICE_OPERATIONS) && \\\n\tdefined(HAVE_BLK_ALLOC_DISK)\n#if defined(HAVE_BLK_CLEANUP_DISK)\n\tblk_cleanup_disk(zv->zv_zso->zvo_disk);\n#else\n\tput_disk(zv->zv_zso->zvo_disk);\n#endif\n#else\n\tblk_cleanup_queue(zv->zv_zso->zvo_queue);\n\tput_disk(zv->zv_zso->zvo_disk);\n#endif\n\n#ifdef HAVE_BLK_MQ\n\tif (zv->zv_zso->use_blk_mq)\n\t\tblk_mq_free_tag_set(&zv->zv_zso->tag_set);\n#endif\n\n\tida_simple_remove(&zvol_ida,\n\t    MINOR(zv->zv_zso->zvo_dev) >> ZVOL_MINOR_BITS);\n\n\tmutex_destroy(&zv->zv_state_lock);\n\tdataset_kstats_destroy(&zv->zv_kstat);\n\n\tkmem_free(zv->zv_zso, sizeof (struct zvol_state_os));\n\tkmem_free(zv, sizeof (zvol_state_t));\n}\n\nvoid\nzvol_wait_close(zvol_state_t *zv)\n{\n}\n\n \nint\nzvol_os_create_minor(const char *name)\n{\n\tzvol_state_t *zv;\n\tobjset_t *os;\n\tdmu_object_info_t *doi;\n\tuint64_t volsize;\n\tuint64_t len;\n\tunsigned minor = 0;\n\tint error = 0;\n\tint idx;\n\tuint64_t hash = zvol_name_hash(name);\n\tbool replayed_zil = B_FALSE;\n\n\tif (zvol_inhibit_dev)\n\t\treturn (0);\n\n\tidx = ida_simple_get(&zvol_ida, 0, 0, kmem_flags_convert(KM_SLEEP));\n\tif (idx < 0)\n\t\treturn (SET_ERROR(-idx));\n\tminor = idx << ZVOL_MINOR_BITS;\n\n\tzv = zvol_find_by_name_hash(name, hash, RW_NONE);\n\tif (zv) {\n\t\tASSERT(MUTEX_HELD(&zv->zv_state_lock));\n\t\tmutex_exit(&zv->zv_state_lock);\n\t\tida_simple_remove(&zvol_ida, idx);\n\t\treturn (SET_ERROR(EEXIST));\n\t}\n\n\tdoi = kmem_alloc(sizeof (dmu_object_info_t), KM_SLEEP);\n\n\terror = dmu_objset_own(name, DMU_OST_ZVOL, B_TRUE, B_TRUE, FTAG, &os);\n\tif (error)\n\t\tgoto out_doi;\n\n\terror = dmu_object_info(os, ZVOL_OBJ, doi);\n\tif (error)\n\t\tgoto out_dmu_objset_disown;\n\n\terror = zap_lookup(os, ZVOL_ZAP_OBJ, \"size\", 8, 1, &volsize);\n\tif (error)\n\t\tgoto out_dmu_objset_disown;\n\n\tzv = zvol_alloc(MKDEV(zvol_major, minor), name);\n\tif (zv == NULL) {\n\t\terror = SET_ERROR(EAGAIN);\n\t\tgoto out_dmu_objset_disown;\n\t}\n\tzv->zv_hash = hash;\n\n\tif (dmu_objset_is_snapshot(os))\n\t\tzv->zv_flags |= ZVOL_RDONLY;\n\n\tzv->zv_volblocksize = doi->doi_data_block_size;\n\tzv->zv_volsize = volsize;\n\tzv->zv_objset = os;\n\n\tset_capacity(zv->zv_zso->zvo_disk, zv->zv_volsize >> 9);\n\n\tblk_queue_max_hw_sectors(zv->zv_zso->zvo_queue,\n\t    (DMU_MAX_ACCESS / 4) >> 9);\n\n\tif (zv->zv_zso->use_blk_mq) {\n\t\t \n\n\t\t \n#ifdef HAVE_BLK_MQ\n\t\tif (zvol_blk_mq_blocks_per_thread != 0) {\n\t\t\tunsigned int chunks;\n\t\t\tchunks = MIN(zvol_blk_mq_blocks_per_thread, UINT16_MAX);\n\n\t\t\tblk_queue_max_segment_size(zv->zv_zso->zvo_queue,\n\t\t\t    PAGE_SIZE);\n\t\t\tblk_queue_max_segments(zv->zv_zso->zvo_queue,\n\t\t\t    (zv->zv_volblocksize * chunks) / PAGE_SIZE);\n\t\t} else {\n\t\t\t \n\t\t\tblk_queue_max_segments(zv->zv_zso->zvo_queue,\n\t\t\t    UINT16_MAX);\n\t\t\tblk_queue_max_segment_size(zv->zv_zso->zvo_queue,\n\t\t\t    UINT_MAX);\n\t\t}\n#endif\n\t} else {\n\t\tblk_queue_max_segments(zv->zv_zso->zvo_queue, UINT16_MAX);\n\t\tblk_queue_max_segment_size(zv->zv_zso->zvo_queue, UINT_MAX);\n\t}\n\n\tblk_queue_physical_block_size(zv->zv_zso->zvo_queue,\n\t    zv->zv_volblocksize);\n\tblk_queue_io_opt(zv->zv_zso->zvo_queue, zv->zv_volblocksize);\n\tblk_queue_max_discard_sectors(zv->zv_zso->zvo_queue,\n\t    (zvol_max_discard_blocks * zv->zv_volblocksize) >> 9);\n\tblk_queue_discard_granularity(zv->zv_zso->zvo_queue,\n\t    zv->zv_volblocksize);\n#ifdef QUEUE_FLAG_DISCARD\n\tblk_queue_flag_set(QUEUE_FLAG_DISCARD, zv->zv_zso->zvo_queue);\n#endif\n#ifdef QUEUE_FLAG_NONROT\n\tblk_queue_flag_set(QUEUE_FLAG_NONROT, zv->zv_zso->zvo_queue);\n#endif\n#ifdef QUEUE_FLAG_ADD_RANDOM\n\tblk_queue_flag_clear(QUEUE_FLAG_ADD_RANDOM, zv->zv_zso->zvo_queue);\n#endif\n\t \n#ifdef QUEUE_FLAG_SCSI_PASSTHROUGH\n\tblk_queue_flag_set(QUEUE_FLAG_SCSI_PASSTHROUGH, zv->zv_zso->zvo_queue);\n#endif\n\n\tASSERT3P(zv->zv_kstat.dk_kstats, ==, NULL);\n\terror = dataset_kstats_create(&zv->zv_kstat, zv->zv_objset);\n\tif (error)\n\t\tgoto out_dmu_objset_disown;\n\tASSERT3P(zv->zv_zilog, ==, NULL);\n\tzv->zv_zilog = zil_open(os, zvol_get_data, &zv->zv_kstat.dk_zil_sums);\n\tif (spa_writeable(dmu_objset_spa(os))) {\n\t\tif (zil_replay_disable)\n\t\t\treplayed_zil = zil_destroy(zv->zv_zilog, B_FALSE);\n\t\telse\n\t\t\treplayed_zil = zil_replay(os, zv, zvol_replay_vector);\n\t}\n\tif (replayed_zil)\n\t\tzil_close(zv->zv_zilog);\n\tzv->zv_zilog = NULL;\n\n\t \n\tlen = MIN(zvol_prefetch_bytes, SPA_MAXBLOCKSIZE);\n\tif (len > 0) {\n\t\tdmu_prefetch(os, ZVOL_OBJ, 0, 0, len, ZIO_PRIORITY_SYNC_READ);\n\t\tdmu_prefetch(os, ZVOL_OBJ, 0, volsize - len, len,\n\t\t    ZIO_PRIORITY_SYNC_READ);\n\t}\n\n\tzv->zv_objset = NULL;\nout_dmu_objset_disown:\n\tdmu_objset_disown(os, B_TRUE, FTAG);\nout_doi:\n\tkmem_free(doi, sizeof (dmu_object_info_t));\n\n\t \n\tif (error == 0) {\n\t\trw_enter(&zvol_state_lock, RW_WRITER);\n\t\tzvol_insert(zv);\n\t\trw_exit(&zvol_state_lock);\n#ifdef HAVE_ADD_DISK_RET\n\t\terror = add_disk(zv->zv_zso->zvo_disk);\n#else\n\t\tadd_disk(zv->zv_zso->zvo_disk);\n#endif\n\t} else {\n\t\tida_simple_remove(&zvol_ida, idx);\n\t}\n\n\treturn (error);\n}\n\nvoid\nzvol_os_rename_minor(zvol_state_t *zv, const char *newname)\n{\n\tint readonly = get_disk_ro(zv->zv_zso->zvo_disk);\n\n\tASSERT(RW_LOCK_HELD(&zvol_state_lock));\n\tASSERT(MUTEX_HELD(&zv->zv_state_lock));\n\n\tstrlcpy(zv->zv_name, newname, sizeof (zv->zv_name));\n\n\t \n\tzv->zv_hash = zvol_name_hash(zv->zv_name);\n\thlist_del(&zv->zv_hlink);\n\thlist_add_head(&zv->zv_hlink, ZVOL_HT_HEAD(zv->zv_hash));\n\n\t \n\tset_disk_ro(zv->zv_zso->zvo_disk, !readonly);\n\tset_disk_ro(zv->zv_zso->zvo_disk, readonly);\n}\n\nvoid\nzvol_os_set_disk_ro(zvol_state_t *zv, int flags)\n{\n\n\tset_disk_ro(zv->zv_zso->zvo_disk, flags);\n}\n\nvoid\nzvol_os_set_capacity(zvol_state_t *zv, uint64_t capacity)\n{\n\n\tset_capacity(zv->zv_zso->zvo_disk, capacity);\n}\n\nint\nzvol_init(void)\n{\n\tint error;\n\n\t \n\tstatic unsigned int zvol_actual_threads;\n\n\tif (zvol_threads == 0) {\n\t\t \n\t\tzvol_actual_threads = MAX(num_online_cpus(), 32);\n\t} else {\n\t\tzvol_actual_threads = MIN(MAX(zvol_threads, 1), 1024);\n\t}\n\n\terror = register_blkdev(zvol_major, ZVOL_DRIVER);\n\tif (error) {\n\t\tprintk(KERN_INFO \"ZFS: register_blkdev() failed %d\\n\", error);\n\t\treturn (error);\n\t}\n\n#ifdef HAVE_BLK_MQ\n\tif (zvol_blk_mq_queue_depth == 0) {\n\t\tzvol_actual_blk_mq_queue_depth = BLKDEV_DEFAULT_RQ;\n\t} else {\n\t\tzvol_actual_blk_mq_queue_depth =\n\t\t    MAX(zvol_blk_mq_queue_depth, BLKDEV_MIN_RQ);\n\t}\n\n\tif (zvol_blk_mq_threads == 0) {\n\t\tzvol_blk_mq_actual_threads = num_online_cpus();\n\t} else {\n\t\tzvol_blk_mq_actual_threads = MIN(MAX(zvol_blk_mq_threads, 1),\n\t\t    1024);\n\t}\n#endif\n\tzvol_taskq = taskq_create(ZVOL_DRIVER, zvol_actual_threads, maxclsyspri,\n\t    zvol_actual_threads, INT_MAX, TASKQ_PREPOPULATE | TASKQ_DYNAMIC);\n\tif (zvol_taskq == NULL) {\n\t\tunregister_blkdev(zvol_major, ZVOL_DRIVER);\n\t\treturn (-ENOMEM);\n\t}\n\n\tzvol_init_impl();\n\tida_init(&zvol_ida);\n\treturn (0);\n}\n\nvoid\nzvol_fini(void)\n{\n\tzvol_fini_impl();\n\tunregister_blkdev(zvol_major, ZVOL_DRIVER);\n\ttaskq_destroy(zvol_taskq);\n\tida_destroy(&zvol_ida);\n}\n\n \nmodule_param(zvol_inhibit_dev, uint, 0644);\nMODULE_PARM_DESC(zvol_inhibit_dev, \"Do not create zvol device nodes\");\n\nmodule_param(zvol_major, uint, 0444);\nMODULE_PARM_DESC(zvol_major, \"Major number for zvol device\");\n\nmodule_param(zvol_threads, uint, 0444);\nMODULE_PARM_DESC(zvol_threads, \"Number of threads to handle I/O requests. Set\"\n    \"to 0 to use all active CPUs\");\n\nmodule_param(zvol_request_sync, uint, 0644);\nMODULE_PARM_DESC(zvol_request_sync, \"Synchronously handle bio requests\");\n\nmodule_param(zvol_max_discard_blocks, ulong, 0444);\nMODULE_PARM_DESC(zvol_max_discard_blocks, \"Max number of blocks to discard\");\n\nmodule_param(zvol_prefetch_bytes, uint, 0644);\nMODULE_PARM_DESC(zvol_prefetch_bytes, \"Prefetch N bytes at zvol start+end\");\n\nmodule_param(zvol_volmode, uint, 0644);\nMODULE_PARM_DESC(zvol_volmode, \"Default volmode property value\");\n\n#ifdef HAVE_BLK_MQ\nmodule_param(zvol_blk_mq_queue_depth, uint, 0644);\nMODULE_PARM_DESC(zvol_blk_mq_queue_depth, \"Default blk-mq queue depth\");\n\nmodule_param(zvol_use_blk_mq, uint, 0644);\nMODULE_PARM_DESC(zvol_use_blk_mq, \"Use the blk-mq API for zvols\");\n\nmodule_param(zvol_blk_mq_blocks_per_thread, uint, 0644);\nMODULE_PARM_DESC(zvol_blk_mq_blocks_per_thread,\n    \"Process volblocksize blocks per thread\");\n#endif\n\n#ifndef HAVE_BLKDEV_GET_ERESTARTSYS\nmodule_param(zvol_open_timeout_ms, uint, 0644);\nMODULE_PARM_DESC(zvol_open_timeout_ms, \"Timeout for ZVOL open retries\");\n#endif\n\n \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}