{
  "module_name": "abd_os.c",
  "hash_id": "520d54f1cff1a883aac448f89e649aa28f16d56bafa5dadd64ac6814ffb477fa",
  "original_prompt": "Ingested from zfs-2.2.2/module/os/linux/zfs/abd_os.c",
  "human_readable_source": " \n \n\n \n\n#include <sys/abd_impl.h>\n#include <sys/param.h>\n#include <sys/zio.h>\n#include <sys/arc.h>\n#include <sys/zfs_context.h>\n#include <sys/zfs_znode.h>\n#ifdef _KERNEL\n#include <linux/kmap_compat.h>\n#include <linux/scatterlist.h>\n#else\n#define\tMAX_ORDER\t1\n#endif\n\ntypedef struct abd_stats {\n\tkstat_named_t abdstat_struct_size;\n\tkstat_named_t abdstat_linear_cnt;\n\tkstat_named_t abdstat_linear_data_size;\n\tkstat_named_t abdstat_scatter_cnt;\n\tkstat_named_t abdstat_scatter_data_size;\n\tkstat_named_t abdstat_scatter_chunk_waste;\n\tkstat_named_t abdstat_scatter_orders[MAX_ORDER];\n\tkstat_named_t abdstat_scatter_page_multi_chunk;\n\tkstat_named_t abdstat_scatter_page_multi_zone;\n\tkstat_named_t abdstat_scatter_page_alloc_retry;\n\tkstat_named_t abdstat_scatter_sg_table_retry;\n} abd_stats_t;\n\nstatic abd_stats_t abd_stats = {\n\t \n\t{ \"struct_size\",\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"linear_cnt\",\t\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"linear_data_size\",\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"scatter_cnt\",\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"scatter_data_size\",\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"scatter_chunk_waste\",\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ { \"scatter_order_N\",\t\t\tKSTAT_DATA_UINT64 } },\n\t \n\t{ \"scatter_page_multi_chunk\",\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"scatter_page_multi_zone\",\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"scatter_page_alloc_retry\",\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"scatter_sg_table_retry\",\t\tKSTAT_DATA_UINT64 },\n};\n\nstatic struct {\n\twmsum_t abdstat_struct_size;\n\twmsum_t abdstat_linear_cnt;\n\twmsum_t abdstat_linear_data_size;\n\twmsum_t abdstat_scatter_cnt;\n\twmsum_t abdstat_scatter_data_size;\n\twmsum_t abdstat_scatter_chunk_waste;\n\twmsum_t abdstat_scatter_orders[MAX_ORDER];\n\twmsum_t abdstat_scatter_page_multi_chunk;\n\twmsum_t abdstat_scatter_page_multi_zone;\n\twmsum_t abdstat_scatter_page_alloc_retry;\n\twmsum_t abdstat_scatter_sg_table_retry;\n} abd_sums;\n\n#define\tabd_for_each_sg(abd, sg, n, i)\t\\\n\tfor_each_sg(ABD_SCATTER(abd).abd_sgl, sg, n, i)\n\n \nstatic int zfs_abd_scatter_min_size = 512 * 3;\n\n \nabd_t *abd_zero_scatter = NULL;\n\nstruct page;\n \nstatic struct page *abd_zero_page = NULL;\n\nstatic kmem_cache_t *abd_cache = NULL;\nstatic kstat_t *abd_ksp;\n\nstatic uint_t\nabd_chunkcnt_for_bytes(size_t size)\n{\n\treturn (P2ROUNDUP(size, PAGESIZE) / PAGESIZE);\n}\n\nabd_t *\nabd_alloc_struct_impl(size_t size)\n{\n\t \n\t(void) size;\n\tabd_t *abd = kmem_cache_alloc(abd_cache, KM_PUSHPAGE);\n\tASSERT3P(abd, !=, NULL);\n\tABDSTAT_INCR(abdstat_struct_size, sizeof (abd_t));\n\n\treturn (abd);\n}\n\nvoid\nabd_free_struct_impl(abd_t *abd)\n{\n\tkmem_cache_free(abd_cache, abd);\n\tABDSTAT_INCR(abdstat_struct_size, -(int)sizeof (abd_t));\n}\n\n#ifdef _KERNEL\nstatic unsigned zfs_abd_scatter_max_order = MAX_ORDER - 1;\n\n \n#ifdef _LP64\n#define\tABD_FILE_CACHE_PAGE\t0x2F5ABDF11ECAC4E\n\nstatic inline void\nabd_mark_zfs_page(struct page *page)\n{\n\tget_page(page);\n\tSetPagePrivate(page);\n\tset_page_private(page, ABD_FILE_CACHE_PAGE);\n}\n\nstatic inline void\nabd_unmark_zfs_page(struct page *page)\n{\n\tset_page_private(page, 0UL);\n\tClearPagePrivate(page);\n\tput_page(page);\n}\n#else\n#define\tabd_mark_zfs_page(page)\n#define\tabd_unmark_zfs_page(page)\n#endif  \n\n#ifndef CONFIG_HIGHMEM\n\n#ifndef __GFP_RECLAIM\n#define\t__GFP_RECLAIM\t\t__GFP_WAIT\n#endif\n\n \nvoid\nabd_alloc_chunks(abd_t *abd, size_t size)\n{\n\tstruct list_head pages;\n\tstruct sg_table table;\n\tstruct scatterlist *sg;\n\tstruct page *page, *tmp_page = NULL;\n\tgfp_t gfp = __GFP_NOWARN | GFP_NOIO;\n\tgfp_t gfp_comp = (gfp | __GFP_NORETRY | __GFP_COMP) & ~__GFP_RECLAIM;\n\tunsigned int max_order = MIN(zfs_abd_scatter_max_order, MAX_ORDER - 1);\n\tunsigned int nr_pages = abd_chunkcnt_for_bytes(size);\n\tunsigned int chunks = 0, zones = 0;\n\tsize_t remaining_size;\n\tint nid = NUMA_NO_NODE;\n\tunsigned int alloc_pages = 0;\n\n\tINIT_LIST_HEAD(&pages);\n\n\tASSERT3U(alloc_pages, <, nr_pages);\n\n\twhile (alloc_pages < nr_pages) {\n\t\tunsigned int chunk_pages;\n\t\tunsigned int order;\n\n\t\torder = MIN(highbit64(nr_pages - alloc_pages) - 1, max_order);\n\t\tchunk_pages = (1U << order);\n\n\t\tpage = alloc_pages_node(nid, order ? gfp_comp : gfp, order);\n\t\tif (page == NULL) {\n\t\t\tif (order == 0) {\n\t\t\t\tABDSTAT_BUMP(abdstat_scatter_page_alloc_retry);\n\t\t\t\tschedule_timeout_interruptible(1);\n\t\t\t} else {\n\t\t\t\tmax_order = MAX(0, order - 1);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tlist_add_tail(&page->lru, &pages);\n\n\t\tif ((nid != NUMA_NO_NODE) && (page_to_nid(page) != nid))\n\t\t\tzones++;\n\n\t\tnid = page_to_nid(page);\n\t\tABDSTAT_BUMP(abdstat_scatter_orders[order]);\n\t\tchunks++;\n\t\talloc_pages += chunk_pages;\n\t}\n\n\tASSERT3S(alloc_pages, ==, nr_pages);\n\n\twhile (sg_alloc_table(&table, chunks, gfp)) {\n\t\tABDSTAT_BUMP(abdstat_scatter_sg_table_retry);\n\t\tschedule_timeout_interruptible(1);\n\t}\n\n\tsg = table.sgl;\n\tremaining_size = size;\n\tlist_for_each_entry_safe(page, tmp_page, &pages, lru) {\n\t\tsize_t sg_size = MIN(PAGESIZE << compound_order(page),\n\t\t    remaining_size);\n\t\tsg_set_page(sg, page, sg_size, 0);\n\t\tabd_mark_zfs_page(page);\n\t\tremaining_size -= sg_size;\n\n\t\tsg = sg_next(sg);\n\t\tlist_del(&page->lru);\n\t}\n\n\t \n\tASSERT(!PageHighMem(sg_page(table.sgl)));\n\tASSERT0(ABD_SCATTER(abd).abd_offset);\n\n\tif (table.nents == 1) {\n\t\t \n\t\tabd->abd_flags |= ABD_FLAG_LINEAR;\n\t\tabd->abd_flags |= ABD_FLAG_LINEAR_PAGE;\n\t\tabd->abd_u.abd_linear.abd_sgl = table.sgl;\n\t\tABD_LINEAR_BUF(abd) = page_address(sg_page(table.sgl));\n\t} else if (table.nents > 1) {\n\t\tABDSTAT_BUMP(abdstat_scatter_page_multi_chunk);\n\t\tabd->abd_flags |= ABD_FLAG_MULTI_CHUNK;\n\n\t\tif (zones) {\n\t\t\tABDSTAT_BUMP(abdstat_scatter_page_multi_zone);\n\t\t\tabd->abd_flags |= ABD_FLAG_MULTI_ZONE;\n\t\t}\n\n\t\tABD_SCATTER(abd).abd_sgl = table.sgl;\n\t\tABD_SCATTER(abd).abd_nents = table.nents;\n\t}\n}\n#else\n\n \nvoid\nabd_alloc_chunks(abd_t *abd, size_t size)\n{\n\tstruct scatterlist *sg = NULL;\n\tstruct sg_table table;\n\tstruct page *page;\n\tgfp_t gfp = __GFP_NOWARN | GFP_NOIO;\n\tint nr_pages = abd_chunkcnt_for_bytes(size);\n\tint i = 0;\n\n\twhile (sg_alloc_table(&table, nr_pages, gfp)) {\n\t\tABDSTAT_BUMP(abdstat_scatter_sg_table_retry);\n\t\tschedule_timeout_interruptible(1);\n\t}\n\n\tASSERT3U(table.nents, ==, nr_pages);\n\tABD_SCATTER(abd).abd_sgl = table.sgl;\n\tABD_SCATTER(abd).abd_nents = nr_pages;\n\n\tabd_for_each_sg(abd, sg, nr_pages, i) {\n\t\twhile ((page = __page_cache_alloc(gfp)) == NULL) {\n\t\t\tABDSTAT_BUMP(abdstat_scatter_page_alloc_retry);\n\t\t\tschedule_timeout_interruptible(1);\n\t\t}\n\n\t\tABDSTAT_BUMP(abdstat_scatter_orders[0]);\n\t\tsg_set_page(sg, page, PAGESIZE, 0);\n\t\tabd_mark_zfs_page(page);\n\t}\n\n\tif (nr_pages > 1) {\n\t\tABDSTAT_BUMP(abdstat_scatter_page_multi_chunk);\n\t\tabd->abd_flags |= ABD_FLAG_MULTI_CHUNK;\n\t}\n}\n#endif  \n\n \nstatic void\nabd_free_sg_table(abd_t *abd)\n{\n\tstruct sg_table table;\n\n\ttable.sgl = ABD_SCATTER(abd).abd_sgl;\n\ttable.nents = table.orig_nents = ABD_SCATTER(abd).abd_nents;\n\tsg_free_table(&table);\n}\n\nvoid\nabd_free_chunks(abd_t *abd)\n{\n\tstruct scatterlist *sg = NULL;\n\tstruct page *page;\n\tint nr_pages = ABD_SCATTER(abd).abd_nents;\n\tint order, i = 0;\n\n\tif (abd->abd_flags & ABD_FLAG_MULTI_ZONE)\n\t\tABDSTAT_BUMPDOWN(abdstat_scatter_page_multi_zone);\n\n\tif (abd->abd_flags & ABD_FLAG_MULTI_CHUNK)\n\t\tABDSTAT_BUMPDOWN(abdstat_scatter_page_multi_chunk);\n\n\tabd_for_each_sg(abd, sg, nr_pages, i) {\n\t\tpage = sg_page(sg);\n\t\tabd_unmark_zfs_page(page);\n\t\torder = compound_order(page);\n\t\t__free_pages(page, order);\n\t\tASSERT3U(sg->length, <=, PAGE_SIZE << order);\n\t\tABDSTAT_BUMPDOWN(abdstat_scatter_orders[order]);\n\t}\n\tabd_free_sg_table(abd);\n}\n\n \nstatic void\nabd_alloc_zero_scatter(void)\n{\n\tstruct scatterlist *sg = NULL;\n\tstruct sg_table table;\n\tgfp_t gfp = __GFP_NOWARN | GFP_NOIO;\n\tint nr_pages = abd_chunkcnt_for_bytes(SPA_MAXBLOCKSIZE);\n\tint i = 0;\n\n#if defined(HAVE_ZERO_PAGE_GPL_ONLY)\n\tgfp_t gfp_zero_page = gfp | __GFP_ZERO;\n\twhile ((abd_zero_page = __page_cache_alloc(gfp_zero_page)) == NULL) {\n\t\tABDSTAT_BUMP(abdstat_scatter_page_alloc_retry);\n\t\tschedule_timeout_interruptible(1);\n\t}\n\tabd_mark_zfs_page(abd_zero_page);\n#else\n\tabd_zero_page = ZERO_PAGE(0);\n#endif  \n\n\twhile (sg_alloc_table(&table, nr_pages, gfp)) {\n\t\tABDSTAT_BUMP(abdstat_scatter_sg_table_retry);\n\t\tschedule_timeout_interruptible(1);\n\t}\n\tASSERT3U(table.nents, ==, nr_pages);\n\n\tabd_zero_scatter = abd_alloc_struct(SPA_MAXBLOCKSIZE);\n\tabd_zero_scatter->abd_flags |= ABD_FLAG_OWNER;\n\tABD_SCATTER(abd_zero_scatter).abd_offset = 0;\n\tABD_SCATTER(abd_zero_scatter).abd_sgl = table.sgl;\n\tABD_SCATTER(abd_zero_scatter).abd_nents = nr_pages;\n\tabd_zero_scatter->abd_size = SPA_MAXBLOCKSIZE;\n\tabd_zero_scatter->abd_flags |= ABD_FLAG_MULTI_CHUNK | ABD_FLAG_ZEROS;\n\n\tabd_for_each_sg(abd_zero_scatter, sg, nr_pages, i) {\n\t\tsg_set_page(sg, abd_zero_page, PAGESIZE, 0);\n\t}\n\n\tABDSTAT_BUMP(abdstat_scatter_cnt);\n\tABDSTAT_INCR(abdstat_scatter_data_size, PAGESIZE);\n\tABDSTAT_BUMP(abdstat_scatter_page_multi_chunk);\n}\n\n#else  \n\n#ifndef PAGE_SHIFT\n#define\tPAGE_SHIFT (highbit64(PAGESIZE)-1)\n#endif\n\n#define\tzfs_kmap_atomic(chunk)\t\t((void *)chunk)\n#define\tzfs_kunmap_atomic(addr)\t\tdo { (void)(addr); } while (0)\n#define\tlocal_irq_save(flags)\t\tdo { (void)(flags); } while (0)\n#define\tlocal_irq_restore(flags)\tdo { (void)(flags); } while (0)\n#define\tnth_page(pg, i) \\\n\t((struct page *)((void *)(pg) + (i) * PAGESIZE))\n\nstruct scatterlist {\n\tstruct page *page;\n\tint length;\n\tint end;\n};\n\nstatic void\nsg_init_table(struct scatterlist *sg, int nr)\n{\n\tmemset(sg, 0, nr * sizeof (struct scatterlist));\n\tsg[nr - 1].end = 1;\n}\n\n \nstatic void\nabd_free_sg_table(abd_t *abd)\n{\n\tint nents = ABD_SCATTER(abd).abd_nents;\n\tvmem_free(ABD_SCATTER(abd).abd_sgl,\n\t    nents * sizeof (struct scatterlist));\n}\n\n#define\tfor_each_sg(sgl, sg, nr, i)\t\\\n\tfor ((i) = 0, (sg) = (sgl); (i) < (nr); (i)++, (sg) = sg_next(sg))\n\nstatic inline void\nsg_set_page(struct scatterlist *sg, struct page *page, unsigned int len,\n    unsigned int offset)\n{\n\t \n\tASSERT(offset == 0);\n\tsg->page = page;\n\tsg->length = len;\n}\n\nstatic inline struct page *\nsg_page(struct scatterlist *sg)\n{\n\treturn (sg->page);\n}\n\nstatic inline struct scatterlist *\nsg_next(struct scatterlist *sg)\n{\n\tif (sg->end)\n\t\treturn (NULL);\n\n\treturn (sg + 1);\n}\n\nvoid\nabd_alloc_chunks(abd_t *abd, size_t size)\n{\n\tunsigned nr_pages = abd_chunkcnt_for_bytes(size);\n\tstruct scatterlist *sg;\n\tint i;\n\n\tABD_SCATTER(abd).abd_sgl = vmem_alloc(nr_pages *\n\t    sizeof (struct scatterlist), KM_SLEEP);\n\tsg_init_table(ABD_SCATTER(abd).abd_sgl, nr_pages);\n\n\tabd_for_each_sg(abd, sg, nr_pages, i) {\n\t\tstruct page *p = umem_alloc_aligned(PAGESIZE, 64, KM_SLEEP);\n\t\tsg_set_page(sg, p, PAGESIZE, 0);\n\t}\n\tABD_SCATTER(abd).abd_nents = nr_pages;\n}\n\nvoid\nabd_free_chunks(abd_t *abd)\n{\n\tint i, n = ABD_SCATTER(abd).abd_nents;\n\tstruct scatterlist *sg;\n\n\tabd_for_each_sg(abd, sg, n, i) {\n\t\tstruct page *p = nth_page(sg_page(sg), 0);\n\t\tumem_free_aligned(p, PAGESIZE);\n\t}\n\tabd_free_sg_table(abd);\n}\n\nstatic void\nabd_alloc_zero_scatter(void)\n{\n\tunsigned nr_pages = abd_chunkcnt_for_bytes(SPA_MAXBLOCKSIZE);\n\tstruct scatterlist *sg;\n\tint i;\n\n\tabd_zero_page = umem_alloc_aligned(PAGESIZE, 64, KM_SLEEP);\n\tmemset(abd_zero_page, 0, PAGESIZE);\n\tabd_zero_scatter = abd_alloc_struct(SPA_MAXBLOCKSIZE);\n\tabd_zero_scatter->abd_flags |= ABD_FLAG_OWNER;\n\tabd_zero_scatter->abd_flags |= ABD_FLAG_MULTI_CHUNK | ABD_FLAG_ZEROS;\n\tABD_SCATTER(abd_zero_scatter).abd_offset = 0;\n\tABD_SCATTER(abd_zero_scatter).abd_nents = nr_pages;\n\tabd_zero_scatter->abd_size = SPA_MAXBLOCKSIZE;\n\tABD_SCATTER(abd_zero_scatter).abd_sgl = vmem_alloc(nr_pages *\n\t    sizeof (struct scatterlist), KM_SLEEP);\n\n\tsg_init_table(ABD_SCATTER(abd_zero_scatter).abd_sgl, nr_pages);\n\n\tabd_for_each_sg(abd_zero_scatter, sg, nr_pages, i) {\n\t\tsg_set_page(sg, abd_zero_page, PAGESIZE, 0);\n\t}\n\n\tABDSTAT_BUMP(abdstat_scatter_cnt);\n\tABDSTAT_INCR(abdstat_scatter_data_size, PAGESIZE);\n\tABDSTAT_BUMP(abdstat_scatter_page_multi_chunk);\n}\n\n#endif  \n\nboolean_t\nabd_size_alloc_linear(size_t size)\n{\n\treturn (!zfs_abd_scatter_enabled || size < zfs_abd_scatter_min_size);\n}\n\nvoid\nabd_update_scatter_stats(abd_t *abd, abd_stats_op_t op)\n{\n\tASSERT(op == ABDSTAT_INCR || op == ABDSTAT_DECR);\n\tint waste = P2ROUNDUP(abd->abd_size, PAGESIZE) - abd->abd_size;\n\tif (op == ABDSTAT_INCR) {\n\t\tABDSTAT_BUMP(abdstat_scatter_cnt);\n\t\tABDSTAT_INCR(abdstat_scatter_data_size, abd->abd_size);\n\t\tABDSTAT_INCR(abdstat_scatter_chunk_waste, waste);\n\t\tarc_space_consume(waste, ARC_SPACE_ABD_CHUNK_WASTE);\n\t} else {\n\t\tABDSTAT_BUMPDOWN(abdstat_scatter_cnt);\n\t\tABDSTAT_INCR(abdstat_scatter_data_size, -(int)abd->abd_size);\n\t\tABDSTAT_INCR(abdstat_scatter_chunk_waste, -waste);\n\t\tarc_space_return(waste, ARC_SPACE_ABD_CHUNK_WASTE);\n\t}\n}\n\nvoid\nabd_update_linear_stats(abd_t *abd, abd_stats_op_t op)\n{\n\tASSERT(op == ABDSTAT_INCR || op == ABDSTAT_DECR);\n\tif (op == ABDSTAT_INCR) {\n\t\tABDSTAT_BUMP(abdstat_linear_cnt);\n\t\tABDSTAT_INCR(abdstat_linear_data_size, abd->abd_size);\n\t} else {\n\t\tABDSTAT_BUMPDOWN(abdstat_linear_cnt);\n\t\tABDSTAT_INCR(abdstat_linear_data_size, -(int)abd->abd_size);\n\t}\n}\n\nvoid\nabd_verify_scatter(abd_t *abd)\n{\n\tsize_t n;\n\tint i = 0;\n\tstruct scatterlist *sg = NULL;\n\n\tASSERT3U(ABD_SCATTER(abd).abd_nents, >, 0);\n\tASSERT3U(ABD_SCATTER(abd).abd_offset, <,\n\t    ABD_SCATTER(abd).abd_sgl->length);\n\tn = ABD_SCATTER(abd).abd_nents;\n\tabd_for_each_sg(abd, sg, n, i) {\n\t\tASSERT3P(sg_page(sg), !=, NULL);\n\t}\n}\n\nstatic void\nabd_free_zero_scatter(void)\n{\n\tABDSTAT_BUMPDOWN(abdstat_scatter_cnt);\n\tABDSTAT_INCR(abdstat_scatter_data_size, -(int)PAGESIZE);\n\tABDSTAT_BUMPDOWN(abdstat_scatter_page_multi_chunk);\n\n\tabd_free_sg_table(abd_zero_scatter);\n\tabd_free_struct(abd_zero_scatter);\n\tabd_zero_scatter = NULL;\n\tASSERT3P(abd_zero_page, !=, NULL);\n#if defined(_KERNEL)\n#if defined(HAVE_ZERO_PAGE_GPL_ONLY)\n\tabd_unmark_zfs_page(abd_zero_page);\n\t__free_page(abd_zero_page);\n#endif  \n#else\n\tumem_free_aligned(abd_zero_page, PAGESIZE);\n#endif  \n}\n\nstatic int\nabd_kstats_update(kstat_t *ksp, int rw)\n{\n\tabd_stats_t *as = ksp->ks_data;\n\n\tif (rw == KSTAT_WRITE)\n\t\treturn (EACCES);\n\tas->abdstat_struct_size.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_struct_size);\n\tas->abdstat_linear_cnt.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_linear_cnt);\n\tas->abdstat_linear_data_size.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_linear_data_size);\n\tas->abdstat_scatter_cnt.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_scatter_cnt);\n\tas->abdstat_scatter_data_size.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_scatter_data_size);\n\tas->abdstat_scatter_chunk_waste.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_scatter_chunk_waste);\n\tfor (int i = 0; i < MAX_ORDER; i++) {\n\t\tas->abdstat_scatter_orders[i].value.ui64 =\n\t\t    wmsum_value(&abd_sums.abdstat_scatter_orders[i]);\n\t}\n\tas->abdstat_scatter_page_multi_chunk.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_scatter_page_multi_chunk);\n\tas->abdstat_scatter_page_multi_zone.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_scatter_page_multi_zone);\n\tas->abdstat_scatter_page_alloc_retry.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_scatter_page_alloc_retry);\n\tas->abdstat_scatter_sg_table_retry.value.ui64 =\n\t    wmsum_value(&abd_sums.abdstat_scatter_sg_table_retry);\n\treturn (0);\n}\n\nvoid\nabd_init(void)\n{\n\tint i;\n\n\tabd_cache = kmem_cache_create(\"abd_t\", sizeof (abd_t),\n\t    0, NULL, NULL, NULL, NULL, NULL, 0);\n\n\twmsum_init(&abd_sums.abdstat_struct_size, 0);\n\twmsum_init(&abd_sums.abdstat_linear_cnt, 0);\n\twmsum_init(&abd_sums.abdstat_linear_data_size, 0);\n\twmsum_init(&abd_sums.abdstat_scatter_cnt, 0);\n\twmsum_init(&abd_sums.abdstat_scatter_data_size, 0);\n\twmsum_init(&abd_sums.abdstat_scatter_chunk_waste, 0);\n\tfor (i = 0; i < MAX_ORDER; i++)\n\t\twmsum_init(&abd_sums.abdstat_scatter_orders[i], 0);\n\twmsum_init(&abd_sums.abdstat_scatter_page_multi_chunk, 0);\n\twmsum_init(&abd_sums.abdstat_scatter_page_multi_zone, 0);\n\twmsum_init(&abd_sums.abdstat_scatter_page_alloc_retry, 0);\n\twmsum_init(&abd_sums.abdstat_scatter_sg_table_retry, 0);\n\n\tabd_ksp = kstat_create(\"zfs\", 0, \"abdstats\", \"misc\", KSTAT_TYPE_NAMED,\n\t    sizeof (abd_stats) / sizeof (kstat_named_t), KSTAT_FLAG_VIRTUAL);\n\tif (abd_ksp != NULL) {\n\t\tfor (i = 0; i < MAX_ORDER; i++) {\n\t\t\tsnprintf(abd_stats.abdstat_scatter_orders[i].name,\n\t\t\t    KSTAT_STRLEN, \"scatter_order_%d\", i);\n\t\t\tabd_stats.abdstat_scatter_orders[i].data_type =\n\t\t\t    KSTAT_DATA_UINT64;\n\t\t}\n\t\tabd_ksp->ks_data = &abd_stats;\n\t\tabd_ksp->ks_update = abd_kstats_update;\n\t\tkstat_install(abd_ksp);\n\t}\n\n\tabd_alloc_zero_scatter();\n}\n\nvoid\nabd_fini(void)\n{\n\tabd_free_zero_scatter();\n\n\tif (abd_ksp != NULL) {\n\t\tkstat_delete(abd_ksp);\n\t\tabd_ksp = NULL;\n\t}\n\n\twmsum_fini(&abd_sums.abdstat_struct_size);\n\twmsum_fini(&abd_sums.abdstat_linear_cnt);\n\twmsum_fini(&abd_sums.abdstat_linear_data_size);\n\twmsum_fini(&abd_sums.abdstat_scatter_cnt);\n\twmsum_fini(&abd_sums.abdstat_scatter_data_size);\n\twmsum_fini(&abd_sums.abdstat_scatter_chunk_waste);\n\tfor (int i = 0; i < MAX_ORDER; i++)\n\t\twmsum_fini(&abd_sums.abdstat_scatter_orders[i]);\n\twmsum_fini(&abd_sums.abdstat_scatter_page_multi_chunk);\n\twmsum_fini(&abd_sums.abdstat_scatter_page_multi_zone);\n\twmsum_fini(&abd_sums.abdstat_scatter_page_alloc_retry);\n\twmsum_fini(&abd_sums.abdstat_scatter_sg_table_retry);\n\n\tif (abd_cache) {\n\t\tkmem_cache_destroy(abd_cache);\n\t\tabd_cache = NULL;\n\t}\n}\n\nvoid\nabd_free_linear_page(abd_t *abd)\n{\n\t \n\tstruct scatterlist *sg = abd->abd_u.abd_linear.abd_sgl;\n\tabd->abd_flags &= ~ABD_FLAG_LINEAR;\n\tabd->abd_flags &= ~ABD_FLAG_LINEAR_PAGE;\n\tABD_SCATTER(abd).abd_nents = 1;\n\tABD_SCATTER(abd).abd_offset = 0;\n\tABD_SCATTER(abd).abd_sgl = sg;\n\tabd_free_chunks(abd);\n\n\tabd_update_scatter_stats(abd, ABDSTAT_DECR);\n}\n\n \nabd_t *\nabd_alloc_for_io(size_t size, boolean_t is_metadata)\n{\n\treturn (abd_alloc(size, is_metadata));\n}\n\nabd_t *\nabd_get_offset_scatter(abd_t *abd, abd_t *sabd, size_t off,\n    size_t size)\n{\n\t(void) size;\n\tint i = 0;\n\tstruct scatterlist *sg = NULL;\n\n\tabd_verify(sabd);\n\tASSERT3U(off, <=, sabd->abd_size);\n\n\tsize_t new_offset = ABD_SCATTER(sabd).abd_offset + off;\n\n\tif (abd == NULL)\n\t\tabd = abd_alloc_struct(0);\n\n\t \n\n\tabd_for_each_sg(sabd, sg, ABD_SCATTER(sabd).abd_nents, i) {\n\t\tif (new_offset < sg->length)\n\t\t\tbreak;\n\t\tnew_offset -= sg->length;\n\t}\n\n\tABD_SCATTER(abd).abd_sgl = sg;\n\tABD_SCATTER(abd).abd_offset = new_offset;\n\tABD_SCATTER(abd).abd_nents = ABD_SCATTER(sabd).abd_nents - i;\n\n\treturn (abd);\n}\n\n \nvoid\nabd_iter_init(struct abd_iter *aiter, abd_t *abd)\n{\n\tASSERT(!abd_is_gang(abd));\n\tabd_verify(abd);\n\taiter->iter_abd = abd;\n\taiter->iter_mapaddr = NULL;\n\taiter->iter_mapsize = 0;\n\taiter->iter_pos = 0;\n\tif (abd_is_linear(abd)) {\n\t\taiter->iter_offset = 0;\n\t\taiter->iter_sg = NULL;\n\t} else {\n\t\taiter->iter_offset = ABD_SCATTER(abd).abd_offset;\n\t\taiter->iter_sg = ABD_SCATTER(abd).abd_sgl;\n\t}\n}\n\n \nboolean_t\nabd_iter_at_end(struct abd_iter *aiter)\n{\n\treturn (aiter->iter_pos == aiter->iter_abd->abd_size);\n}\n\n \nvoid\nabd_iter_advance(struct abd_iter *aiter, size_t amount)\n{\n\tASSERT3P(aiter->iter_mapaddr, ==, NULL);\n\tASSERT0(aiter->iter_mapsize);\n\n\t \n\tif (abd_iter_at_end(aiter))\n\t\treturn;\n\n\taiter->iter_pos += amount;\n\taiter->iter_offset += amount;\n\tif (!abd_is_linear(aiter->iter_abd)) {\n\t\twhile (aiter->iter_offset >= aiter->iter_sg->length) {\n\t\t\taiter->iter_offset -= aiter->iter_sg->length;\n\t\t\taiter->iter_sg = sg_next(aiter->iter_sg);\n\t\t\tif (aiter->iter_sg == NULL) {\n\t\t\t\tASSERT0(aiter->iter_offset);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nvoid\nabd_iter_map(struct abd_iter *aiter)\n{\n\tvoid *paddr;\n\tsize_t offset = 0;\n\n\tASSERT3P(aiter->iter_mapaddr, ==, NULL);\n\tASSERT0(aiter->iter_mapsize);\n\n\t \n\tif (abd_iter_at_end(aiter))\n\t\treturn;\n\n\tif (abd_is_linear(aiter->iter_abd)) {\n\t\tASSERT3U(aiter->iter_pos, ==, aiter->iter_offset);\n\t\toffset = aiter->iter_offset;\n\t\taiter->iter_mapsize = aiter->iter_abd->abd_size - offset;\n\t\tpaddr = ABD_LINEAR_BUF(aiter->iter_abd);\n\t} else {\n\t\toffset = aiter->iter_offset;\n\t\taiter->iter_mapsize = MIN(aiter->iter_sg->length - offset,\n\t\t    aiter->iter_abd->abd_size - aiter->iter_pos);\n\n\t\tpaddr = zfs_kmap_atomic(sg_page(aiter->iter_sg));\n\t}\n\n\taiter->iter_mapaddr = (char *)paddr + offset;\n}\n\n \nvoid\nabd_iter_unmap(struct abd_iter *aiter)\n{\n\t \n\tif (abd_iter_at_end(aiter))\n\t\treturn;\n\n\tif (!abd_is_linear(aiter->iter_abd)) {\n\t\t \n\t\tzfs_kunmap_atomic(aiter->iter_mapaddr - aiter->iter_offset);\n\t}\n\n\tASSERT3P(aiter->iter_mapaddr, !=, NULL);\n\tASSERT3U(aiter->iter_mapsize, >, 0);\n\n\taiter->iter_mapaddr = NULL;\n\taiter->iter_mapsize = 0;\n}\n\nvoid\nabd_cache_reap_now(void)\n{\n}\n\n#if defined(_KERNEL)\n \nunsigned long\nabd_nr_pages_off(abd_t *abd, unsigned int size, size_t off)\n{\n\tunsigned long pos;\n\n\tif (abd_is_gang(abd)) {\n\t\tunsigned long count = 0;\n\n\t\tfor (abd_t *cabd = abd_gang_get_offset(abd, &off);\n\t\t    cabd != NULL && size != 0;\n\t\t    cabd = list_next(&ABD_GANG(abd).abd_gang_chain, cabd)) {\n\t\t\tASSERT3U(off, <, cabd->abd_size);\n\t\t\tint mysize = MIN(size, cabd->abd_size - off);\n\t\t\tcount += abd_nr_pages_off(cabd, mysize, off);\n\t\t\tsize -= mysize;\n\t\t\toff = 0;\n\t\t}\n\t\treturn (count);\n\t}\n\n\tif (abd_is_linear(abd))\n\t\tpos = (unsigned long)abd_to_buf(abd) + off;\n\telse\n\t\tpos = ABD_SCATTER(abd).abd_offset + off;\n\n\treturn (((pos + size + PAGESIZE - 1) >> PAGE_SHIFT) -\n\t    (pos >> PAGE_SHIFT));\n}\n\nstatic unsigned int\nbio_map(struct bio *bio, void *buf_ptr, unsigned int bio_size)\n{\n\tunsigned int offset, size, i;\n\tstruct page *page;\n\n\toffset = offset_in_page(buf_ptr);\n\tfor (i = 0; i < bio->bi_max_vecs; i++) {\n\t\tsize = PAGE_SIZE - offset;\n\n\t\tif (bio_size <= 0)\n\t\t\tbreak;\n\n\t\tif (size > bio_size)\n\t\t\tsize = bio_size;\n\n\t\tif (is_vmalloc_addr(buf_ptr))\n\t\t\tpage = vmalloc_to_page(buf_ptr);\n\t\telse\n\t\t\tpage = virt_to_page(buf_ptr);\n\n\t\t \n\t\tASSERT3S(page_count(page), >, 0);\n\n\t\tif (bio_add_page(bio, page, size, offset) != size)\n\t\t\tbreak;\n\n\t\tbuf_ptr += size;\n\t\tbio_size -= size;\n\t\toffset = 0;\n\t}\n\n\treturn (bio_size);\n}\n\n \nstatic unsigned int\nabd_gang_bio_map_off(struct bio *bio, abd_t *abd,\n    unsigned int io_size, size_t off)\n{\n\tASSERT(abd_is_gang(abd));\n\n\tfor (abd_t *cabd = abd_gang_get_offset(abd, &off);\n\t    cabd != NULL;\n\t    cabd = list_next(&ABD_GANG(abd).abd_gang_chain, cabd)) {\n\t\tASSERT3U(off, <, cabd->abd_size);\n\t\tint size = MIN(io_size, cabd->abd_size - off);\n\t\tint remainder = abd_bio_map_off(bio, cabd, size, off);\n\t\tio_size -= (size - remainder);\n\t\tif (io_size == 0 || remainder > 0)\n\t\t\treturn (io_size);\n\t\toff = 0;\n\t}\n\tASSERT0(io_size);\n\treturn (io_size);\n}\n\n \nunsigned int\nabd_bio_map_off(struct bio *bio, abd_t *abd,\n    unsigned int io_size, size_t off)\n{\n\tstruct abd_iter aiter;\n\n\tASSERT3U(io_size, <=, abd->abd_size - off);\n\tif (abd_is_linear(abd))\n\t\treturn (bio_map(bio, ((char *)abd_to_buf(abd)) + off, io_size));\n\n\tASSERT(!abd_is_linear(abd));\n\tif (abd_is_gang(abd))\n\t\treturn (abd_gang_bio_map_off(bio, abd, io_size, off));\n\n\tabd_iter_init(&aiter, abd);\n\tabd_iter_advance(&aiter, off);\n\n\tfor (int i = 0; i < bio->bi_max_vecs; i++) {\n\t\tstruct page *pg;\n\t\tsize_t len, sgoff, pgoff;\n\t\tstruct scatterlist *sg;\n\n\t\tif (io_size <= 0)\n\t\t\tbreak;\n\n\t\tsg = aiter.iter_sg;\n\t\tsgoff = aiter.iter_offset;\n\t\tpgoff = sgoff & (PAGESIZE - 1);\n\t\tlen = MIN(io_size, PAGESIZE - pgoff);\n\t\tASSERT(len > 0);\n\n\t\tpg = nth_page(sg_page(sg), sgoff >> PAGE_SHIFT);\n\t\tif (bio_add_page(bio, pg, len, pgoff) != len)\n\t\t\tbreak;\n\n\t\tio_size -= len;\n\t\tabd_iter_advance(&aiter, len);\n\t}\n\n\treturn (io_size);\n}\n\n \nmodule_param(zfs_abd_scatter_enabled, int, 0644);\nMODULE_PARM_DESC(zfs_abd_scatter_enabled,\n\t\"Toggle whether ABD allocations must be linear.\");\nmodule_param(zfs_abd_scatter_min_size, int, 0644);\nMODULE_PARM_DESC(zfs_abd_scatter_min_size,\n\t\"Minimum size of scatter allocations.\");\n \nmodule_param(zfs_abd_scatter_max_order, uint, 0644);\nMODULE_PARM_DESC(zfs_abd_scatter_max_order,\n\t\"Maximum order allocation used for a scatter ABD.\");\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}