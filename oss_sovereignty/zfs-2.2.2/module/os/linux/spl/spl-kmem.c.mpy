{
  "module_name": "spl-kmem.c",
  "hash_id": "75dfb1e2bd89d904e209ee129f74d4358c5751d239e3ebfeed01834c559719c3",
  "original_prompt": "Ingested from zfs-2.2.2/module/os/linux/spl/spl-kmem.c",
  "human_readable_source": " \n\n#include <sys/debug.h>\n#include <sys/sysmacros.h>\n#include <sys/kmem.h>\n#include <sys/vmem.h>\n\n \n \nunsigned int spl_kmem_alloc_warn = MIN(16 * PAGE_SIZE, 64 * 1024);\nmodule_param(spl_kmem_alloc_warn, uint, 0644);\nMODULE_PARM_DESC(spl_kmem_alloc_warn,\n\t\"Warning threshold in bytes for a kmem_alloc()\");\nEXPORT_SYMBOL(spl_kmem_alloc_warn);\n\n \nunsigned int spl_kmem_alloc_max = (KMALLOC_MAX_SIZE >> 2);\nmodule_param(spl_kmem_alloc_max, uint, 0644);\nMODULE_PARM_DESC(spl_kmem_alloc_max,\n\t\"Maximum size in bytes for a kmem_alloc()\");\nEXPORT_SYMBOL(spl_kmem_alloc_max);\n \n\nint\nkmem_debugging(void)\n{\n\treturn (0);\n}\nEXPORT_SYMBOL(kmem_debugging);\n\nchar *\nkmem_vasprintf(const char *fmt, va_list ap)\n{\n\tva_list aq;\n\tchar *ptr;\n\n\tdo {\n\t\tva_copy(aq, ap);\n\t\tptr = kvasprintf(kmem_flags_convert(KM_SLEEP), fmt, aq);\n\t\tva_end(aq);\n\t} while (ptr == NULL);\n\n\treturn (ptr);\n}\nEXPORT_SYMBOL(kmem_vasprintf);\n\nchar *\nkmem_asprintf(const char *fmt, ...)\n{\n\tva_list ap;\n\tchar *ptr;\n\n\tdo {\n\t\tva_start(ap, fmt);\n\t\tptr = kvasprintf(kmem_flags_convert(KM_SLEEP), fmt, ap);\n\t\tva_end(ap);\n\t} while (ptr == NULL);\n\n\treturn (ptr);\n}\nEXPORT_SYMBOL(kmem_asprintf);\n\nstatic char *\n__strdup(const char *str, int flags)\n{\n\tchar *ptr;\n\tint n;\n\n\tn = strlen(str);\n\tptr = kmalloc(n + 1, kmem_flags_convert(flags));\n\tif (ptr)\n\t\tmemcpy(ptr, str, n + 1);\n\n\treturn (ptr);\n}\n\nchar *\nkmem_strdup(const char *str)\n{\n\treturn (__strdup(str, KM_SLEEP));\n}\nEXPORT_SYMBOL(kmem_strdup);\n\nvoid\nkmem_strfree(char *str)\n{\n\tkfree(str);\n}\nEXPORT_SYMBOL(kmem_strfree);\n\nvoid *\nspl_kvmalloc(size_t size, gfp_t lflags)\n{\n#ifdef HAVE_KVMALLOC\n\t \n\tif ((lflags & GFP_KERNEL) == GFP_KERNEL)\n\t\treturn (kvmalloc(size, lflags));\n#endif\n\n\tgfp_t kmalloc_lflags = lflags;\n\n\tif (size > PAGE_SIZE) {\n\t\t \n\t\tkmalloc_lflags |= __GFP_NOWARN;\n\n\t\t \n\t\tif (!(kmalloc_lflags & __GFP_RETRY_MAYFAIL) ||\n\t\t    (size <= PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {\n\t\t\tkmalloc_lflags |= __GFP_NORETRY;\n\t\t}\n\t}\n\n\t \n\tvoid *ptr = kmalloc_node(size, kmalloc_lflags, NUMA_NO_NODE);\n\tif (ptr || size <= PAGE_SIZE ||\n\t    (lflags & __GFP_RECLAIM) != __GFP_RECLAIM) {\n\t\treturn (ptr);\n\t}\n\n\treturn (spl_vmalloc(size, lflags | __GFP_HIGHMEM));\n}\n\n \ninline void *\nspl_kmem_alloc_impl(size_t size, int flags, int node)\n{\n\tgfp_t lflags = kmem_flags_convert(flags);\n\tvoid *ptr;\n\n\t \n\tif ((spl_kmem_alloc_warn > 0) && (size > spl_kmem_alloc_warn) &&\n\t    !(flags & KM_VMEM)) {\n\t\tprintk(KERN_WARNING\n\t\t    \"Large kmem_alloc(%lu, 0x%x), please file an issue at:\\n\"\n\t\t    \"https://github.com/openzfs/zfs/issues/new\\n\",\n\t\t    (unsigned long)size, flags);\n\t\tdump_stack();\n\t}\n\n\t \n\tdo {\n\t\t \n\t\tif (size > spl_kmem_alloc_max) {\n\t\t\tif (flags & KM_VMEM) {\n\t\t\t\tptr = spl_vmalloc(size, lflags | __GFP_HIGHMEM);\n\t\t\t} else {\n\t\t\t\treturn (NULL);\n\t\t\t}\n\t\t} else {\n\t\t\t \n#ifdef CONFIG_HIGHMEM\n\t\t\tif (flags & KM_VMEM) {\n#else\n\t\t\tif ((flags & KM_VMEM) || !(flags & KM_NOSLEEP)) {\n#endif\n\t\t\t\tptr = spl_kvmalloc(size, lflags);\n\t\t\t} else {\n\t\t\t\tptr = kmalloc_node(size, lflags, node);\n\t\t\t}\n\t\t}\n\n\t\tif (likely(ptr) || (flags & KM_NOSLEEP))\n\t\t\treturn (ptr);\n\n\t\t \n\t\tif ((lflags & GFP_KERNEL) == GFP_KERNEL)\n\t\t\tlflags |= __GFP_RETRY_MAYFAIL;\n\n\t\t \n\t\tcond_resched();\n\t} while (1);\n\n\treturn (NULL);\n}\n\ninline void\nspl_kmem_free_impl(const void *buf, size_t size)\n{\n\tif (is_vmalloc_addr(buf))\n\t\tvfree(buf);\n\telse\n\t\tkfree(buf);\n}\n\n \n#ifdef DEBUG_KMEM\n\n \n#ifdef HAVE_ATOMIC64_T\natomic64_t kmem_alloc_used = ATOMIC64_INIT(0);\nunsigned long long kmem_alloc_max = 0;\n#else   \natomic_t kmem_alloc_used = ATOMIC_INIT(0);\nunsigned long long kmem_alloc_max = 0;\n#endif  \n\nEXPORT_SYMBOL(kmem_alloc_used);\nEXPORT_SYMBOL(kmem_alloc_max);\n\ninline void *\nspl_kmem_alloc_debug(size_t size, int flags, int node)\n{\n\tvoid *ptr;\n\n\tptr = spl_kmem_alloc_impl(size, flags, node);\n\tif (ptr) {\n\t\tkmem_alloc_used_add(size);\n\t\tif (unlikely(kmem_alloc_used_read() > kmem_alloc_max))\n\t\t\tkmem_alloc_max = kmem_alloc_used_read();\n\t}\n\n\treturn (ptr);\n}\n\ninline void\nspl_kmem_free_debug(const void *ptr, size_t size)\n{\n\tkmem_alloc_used_sub(size);\n\tspl_kmem_free_impl(ptr, size);\n}\n\n \n#ifdef DEBUG_KMEM_TRACKING\n\n#include <linux/hash.h>\n#include <linux/ctype.h>\n\n#define\tKMEM_HASH_BITS\t\t10\n#define\tKMEM_TABLE_SIZE\t\t(1 << KMEM_HASH_BITS)\n\ntypedef struct kmem_debug {\n\tstruct hlist_node kd_hlist;\t \n\tstruct list_head kd_list;\t \n\tvoid *kd_addr;\t\t\t \n\tsize_t kd_size;\t\t\t \n\tconst char *kd_func;\t\t \n\tint kd_line;\t\t\t \n} kmem_debug_t;\n\nstatic spinlock_t kmem_lock;\nstatic struct hlist_head kmem_table[KMEM_TABLE_SIZE];\nstatic struct list_head kmem_list;\n\nstatic kmem_debug_t *\nkmem_del_init(spinlock_t *lock, struct hlist_head *table,\n    int bits, const void *addr)\n{\n\tstruct hlist_head *head;\n\tstruct hlist_node *node = NULL;\n\tstruct kmem_debug *p;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(lock, flags);\n\n\thead = &table[hash_ptr((void *)addr, bits)];\n\thlist_for_each(node, head) {\n\t\tp = list_entry(node, struct kmem_debug, kd_hlist);\n\t\tif (p->kd_addr == addr) {\n\t\t\thlist_del_init(&p->kd_hlist);\n\t\t\tlist_del_init(&p->kd_list);\n\t\t\tspin_unlock_irqrestore(lock, flags);\n\t\t\treturn (p);\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(lock, flags);\n\n\treturn (NULL);\n}\n\ninline void *\nspl_kmem_alloc_track(size_t size, int flags,\n    const char *func, int line, int node)\n{\n\tvoid *ptr = NULL;\n\tkmem_debug_t *dptr;\n\tunsigned long irq_flags;\n\n\tdptr = kmalloc(sizeof (kmem_debug_t), kmem_flags_convert(flags));\n\tif (dptr == NULL)\n\t\treturn (NULL);\n\n\tdptr->kd_func = __strdup(func, flags);\n\tif (dptr->kd_func == NULL) {\n\t\tkfree(dptr);\n\t\treturn (NULL);\n\t}\n\n\tptr = spl_kmem_alloc_debug(size, flags, node);\n\tif (ptr == NULL) {\n\t\tkfree(dptr->kd_func);\n\t\tkfree(dptr);\n\t\treturn (NULL);\n\t}\n\n\tINIT_HLIST_NODE(&dptr->kd_hlist);\n\tINIT_LIST_HEAD(&dptr->kd_list);\n\n\tdptr->kd_addr = ptr;\n\tdptr->kd_size = size;\n\tdptr->kd_line = line;\n\n\tspin_lock_irqsave(&kmem_lock, irq_flags);\n\thlist_add_head(&dptr->kd_hlist,\n\t    &kmem_table[hash_ptr(ptr, KMEM_HASH_BITS)]);\n\tlist_add_tail(&dptr->kd_list, &kmem_list);\n\tspin_unlock_irqrestore(&kmem_lock, irq_flags);\n\n\treturn (ptr);\n}\n\ninline void\nspl_kmem_free_track(const void *ptr, size_t size)\n{\n\tkmem_debug_t *dptr;\n\n\t \n\tif (ptr == NULL)\n\t\treturn;\n\n\t \n\tdptr = kmem_del_init(&kmem_lock, kmem_table, KMEM_HASH_BITS, ptr);\n\tASSERT3P(dptr, !=, NULL);\n\tASSERT3S(dptr->kd_size, ==, size);\n\n\tkfree(dptr->kd_func);\n\tkfree(dptr);\n\n\tspl_kmem_free_debug(ptr, size);\n}\n#endif  \n#endif  \n\n \nvoid *\nspl_kmem_alloc(size_t size, int flags, const char *func, int line)\n{\n\tASSERT0(flags & ~KM_PUBLIC_MASK);\n\n#if !defined(DEBUG_KMEM)\n\treturn (spl_kmem_alloc_impl(size, flags, NUMA_NO_NODE));\n#elif !defined(DEBUG_KMEM_TRACKING)\n\treturn (spl_kmem_alloc_debug(size, flags, NUMA_NO_NODE));\n#else\n\treturn (spl_kmem_alloc_track(size, flags, func, line, NUMA_NO_NODE));\n#endif\n}\nEXPORT_SYMBOL(spl_kmem_alloc);\n\nvoid *\nspl_kmem_zalloc(size_t size, int flags, const char *func, int line)\n{\n\tASSERT0(flags & ~KM_PUBLIC_MASK);\n\n\tflags |= KM_ZERO;\n\n#if !defined(DEBUG_KMEM)\n\treturn (spl_kmem_alloc_impl(size, flags, NUMA_NO_NODE));\n#elif !defined(DEBUG_KMEM_TRACKING)\n\treturn (spl_kmem_alloc_debug(size, flags, NUMA_NO_NODE));\n#else\n\treturn (spl_kmem_alloc_track(size, flags, func, line, NUMA_NO_NODE));\n#endif\n}\nEXPORT_SYMBOL(spl_kmem_zalloc);\n\nvoid\nspl_kmem_free(const void *buf, size_t size)\n{\n#if !defined(DEBUG_KMEM)\n\treturn (spl_kmem_free_impl(buf, size));\n#elif !defined(DEBUG_KMEM_TRACKING)\n\treturn (spl_kmem_free_debug(buf, size));\n#else\n\treturn (spl_kmem_free_track(buf, size));\n#endif\n}\nEXPORT_SYMBOL(spl_kmem_free);\n\n#if defined(DEBUG_KMEM) && defined(DEBUG_KMEM_TRACKING)\nstatic char *\nspl_sprintf_addr(kmem_debug_t *kd, char *str, int len, int min)\n{\n\tint size = ((len - 1) < kd->kd_size) ? (len - 1) : kd->kd_size;\n\tint i, flag = 1;\n\n\tASSERT(str != NULL && len >= 17);\n\tmemset(str, 0, len);\n\n\t \n\tfor (i = 0; i < size; i++) {\n\t\tstr[i] = ((char *)(kd->kd_addr))[i];\n\t\tif (isprint(str[i])) {\n\t\t\tcontinue;\n\t\t} else {\n\t\t\t \n\t\t\tif (i > min)\n\t\t\t\tbreak;\n\n\t\t\tflag = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!flag) {\n\t\tsprintf(str, \"%02x%02x%02x%02x%02x%02x%02x%02x\",\n\t\t    *((uint8_t *)kd->kd_addr),\n\t\t    *((uint8_t *)kd->kd_addr + 2),\n\t\t    *((uint8_t *)kd->kd_addr + 4),\n\t\t    *((uint8_t *)kd->kd_addr + 6),\n\t\t    *((uint8_t *)kd->kd_addr + 8),\n\t\t    *((uint8_t *)kd->kd_addr + 10),\n\t\t    *((uint8_t *)kd->kd_addr + 12),\n\t\t    *((uint8_t *)kd->kd_addr + 14));\n\t}\n\n\treturn (str);\n}\n\nstatic int\nspl_kmem_init_tracking(struct list_head *list, spinlock_t *lock, int size)\n{\n\tint i;\n\n\tspin_lock_init(lock);\n\tINIT_LIST_HEAD(list);\n\n\tfor (i = 0; i < size; i++)\n\t\tINIT_HLIST_HEAD(&kmem_table[i]);\n\n\treturn (0);\n}\n\nstatic void\nspl_kmem_fini_tracking(struct list_head *list, spinlock_t *lock)\n{\n\tunsigned long flags;\n\tkmem_debug_t *kd = NULL;\n\tchar str[17];\n\n\tspin_lock_irqsave(lock, flags);\n\tif (!list_empty(list))\n\t\tprintk(KERN_WARNING \"%-16s %-5s %-16s %s:%s\\n\", \"address\",\n\t\t    \"size\", \"data\", \"func\", \"line\");\n\n\tlist_for_each_entry(kd, list, kd_list) {\n\t\tprintk(KERN_WARNING \"%p %-5d %-16s %s:%d\\n\", kd->kd_addr,\n\t\t    (int)kd->kd_size, spl_sprintf_addr(kd, str, 17, 8),\n\t\t    kd->kd_func, kd->kd_line);\n\t}\n\n\tspin_unlock_irqrestore(lock, flags);\n}\n#endif  \n\nint\nspl_kmem_init(void)\n{\n\n#ifdef DEBUG_KMEM\n\tkmem_alloc_used_set(0);\n\n\n\n#ifdef DEBUG_KMEM_TRACKING\n\tspl_kmem_init_tracking(&kmem_list, &kmem_lock, KMEM_TABLE_SIZE);\n#endif  \n#endif  \n\n\treturn (0);\n}\n\nvoid\nspl_kmem_fini(void)\n{\n#ifdef DEBUG_KMEM\n\t \n\tif (kmem_alloc_used_read() != 0)\n\t\tprintk(KERN_WARNING \"kmem leaked %ld/%llu bytes\\n\",\n\t\t    (unsigned long)kmem_alloc_used_read(), kmem_alloc_max);\n\n#ifdef DEBUG_KMEM_TRACKING\n\tspl_kmem_fini_tracking(&kmem_list, &kmem_lock);\n#endif  \n#endif  \n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}