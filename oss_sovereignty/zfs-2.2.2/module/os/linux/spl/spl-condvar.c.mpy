{
  "module_name": "spl-condvar.c",
  "hash_id": "37b111657586e70cbc4d82c46ebbdd6c2fd93ea05d8c50db17160364b14bd8c0",
  "original_prompt": "Ingested from zfs-2.2.2/module/os/linux/spl/spl-condvar.c",
  "human_readable_source": " \n\n#include <sys/condvar.h>\n#include <sys/time.h>\n#include <sys/sysmacros.h>\n#include <linux/hrtimer.h>\n#include <linux/compiler_compat.h>\n#include <linux/mod_compat.h>\n\n#include <linux/sched.h>\n\n#ifdef HAVE_SCHED_SIGNAL_HEADER\n#include <linux/sched/signal.h>\n#endif\n\n#define\tMAX_HRTIMEOUT_SLACK_US\t1000\nstatic unsigned int spl_schedule_hrtimeout_slack_us = 0;\n\nstatic int\nparam_set_hrtimeout_slack(const char *buf, zfs_kernel_param_t *kp)\n{\n\tunsigned long val;\n\tint error;\n\n\terror = kstrtoul(buf, 0, &val);\n\tif (error)\n\t\treturn (error);\n\n\tif (val > MAX_HRTIMEOUT_SLACK_US)\n\t\treturn (-EINVAL);\n\n\terror = param_set_uint(buf, kp);\n\tif (error < 0)\n\t\treturn (error);\n\n\treturn (0);\n}\n\nmodule_param_call(spl_schedule_hrtimeout_slack_us, param_set_hrtimeout_slack,\n\tparam_get_uint, &spl_schedule_hrtimeout_slack_us, 0644);\nMODULE_PARM_DESC(spl_schedule_hrtimeout_slack_us,\n\t\"schedule_hrtimeout_range() delta/slack value in us, default(0)\");\n\nvoid\n__cv_init(kcondvar_t *cvp, char *name, kcv_type_t type, void *arg)\n{\n\tASSERT(cvp);\n\tASSERT(name == NULL);\n\tASSERT(type == CV_DEFAULT);\n\tASSERT(arg == NULL);\n\n\tcvp->cv_magic = CV_MAGIC;\n\tinit_waitqueue_head(&cvp->cv_event);\n\tinit_waitqueue_head(&cvp->cv_destroy);\n\tatomic_set(&cvp->cv_waiters, 0);\n\tatomic_set(&cvp->cv_refs, 1);\n\tcvp->cv_mutex = NULL;\n}\nEXPORT_SYMBOL(__cv_init);\n\nstatic int\ncv_destroy_wakeup(kcondvar_t *cvp)\n{\n\tif (!atomic_read(&cvp->cv_waiters) && !atomic_read(&cvp->cv_refs)) {\n\t\tASSERT(cvp->cv_mutex == NULL);\n\t\tASSERT(!waitqueue_active(&cvp->cv_event));\n\t\treturn (1);\n\t}\n\n\treturn (0);\n}\n\nvoid\n__cv_destroy(kcondvar_t *cvp)\n{\n\tASSERT(cvp);\n\tASSERT(cvp->cv_magic == CV_MAGIC);\n\n\tcvp->cv_magic = CV_DESTROY;\n\tatomic_dec(&cvp->cv_refs);\n\n\t \n\twhile (cv_destroy_wakeup(cvp) == 0)\n\t\twait_event_timeout(cvp->cv_destroy, cv_destroy_wakeup(cvp), 1);\n\n\tASSERT3P(cvp->cv_mutex, ==, NULL);\n\tASSERT3S(atomic_read(&cvp->cv_refs), ==, 0);\n\tASSERT3S(atomic_read(&cvp->cv_waiters), ==, 0);\n\tASSERT3S(waitqueue_active(&cvp->cv_event), ==, 0);\n}\nEXPORT_SYMBOL(__cv_destroy);\n\nstatic void\ncv_wait_common(kcondvar_t *cvp, kmutex_t *mp, int state, int io)\n{\n\tDEFINE_WAIT(wait);\n\tkmutex_t *m;\n\n\tASSERT(cvp);\n\tASSERT(mp);\n\tASSERT(cvp->cv_magic == CV_MAGIC);\n\tASSERT(mutex_owned(mp));\n\tatomic_inc(&cvp->cv_refs);\n\n\tm = READ_ONCE(cvp->cv_mutex);\n\tif (!m)\n\t\tm = xchg(&cvp->cv_mutex, mp);\n\t \n\tASSERT(m == NULL || m == mp);\n\n\tprepare_to_wait_exclusive(&cvp->cv_event, &wait, state);\n\tatomic_inc(&cvp->cv_waiters);\n\n\t \n\tmutex_exit(mp);\n\tif (io)\n\t\tio_schedule();\n\telse\n\t\tschedule();\n\n\t \n\tif (atomic_dec_and_test(&cvp->cv_waiters)) {\n\t\t \n\t\tcvp->cv_mutex = NULL;\n\t\twake_up(&cvp->cv_destroy);\n\t}\n\n\tfinish_wait(&cvp->cv_event, &wait);\n\tatomic_dec(&cvp->cv_refs);\n\n\t \n\tmutex_enter(mp);\n}\n\nvoid\n__cv_wait(kcondvar_t *cvp, kmutex_t *mp)\n{\n\tcv_wait_common(cvp, mp, TASK_UNINTERRUPTIBLE, 0);\n}\nEXPORT_SYMBOL(__cv_wait);\n\nvoid\n__cv_wait_io(kcondvar_t *cvp, kmutex_t *mp)\n{\n\tcv_wait_common(cvp, mp, TASK_UNINTERRUPTIBLE, 1);\n}\nEXPORT_SYMBOL(__cv_wait_io);\n\nint\n__cv_wait_io_sig(kcondvar_t *cvp, kmutex_t *mp)\n{\n\tcv_wait_common(cvp, mp, TASK_INTERRUPTIBLE, 1);\n\n\treturn (signal_pending(current) ? 0 : 1);\n}\nEXPORT_SYMBOL(__cv_wait_io_sig);\n\nint\n__cv_wait_sig(kcondvar_t *cvp, kmutex_t *mp)\n{\n\tcv_wait_common(cvp, mp, TASK_INTERRUPTIBLE, 0);\n\n\treturn (signal_pending(current) ? 0 : 1);\n}\nEXPORT_SYMBOL(__cv_wait_sig);\n\nvoid\n__cv_wait_idle(kcondvar_t *cvp, kmutex_t *mp)\n{\n\tsigset_t blocked, saved;\n\n\tsigfillset(&blocked);\n\t(void) sigprocmask(SIG_BLOCK, &blocked, &saved);\n\tcv_wait_common(cvp, mp, TASK_INTERRUPTIBLE, 0);\n\t(void) sigprocmask(SIG_SETMASK, &saved, NULL);\n}\nEXPORT_SYMBOL(__cv_wait_idle);\n\n#if defined(HAVE_IO_SCHEDULE_TIMEOUT)\n#define\tspl_io_schedule_timeout(t)\tio_schedule_timeout(t)\n#else\n\nstruct spl_task_timer {\n\tstruct timer_list timer;\n\tstruct task_struct *task;\n};\n\nstatic void\n__cv_wakeup(spl_timer_list_t t)\n{\n\tstruct timer_list *tmr = (struct timer_list *)t;\n\tstruct spl_task_timer *task_timer = from_timer(task_timer, tmr, timer);\n\n\twake_up_process(task_timer->task);\n}\n\nstatic long\nspl_io_schedule_timeout(long time_left)\n{\n\tlong expire_time = jiffies + time_left;\n\tstruct spl_task_timer task_timer;\n\tstruct timer_list *timer = &task_timer.timer;\n\n\ttask_timer.task = current;\n\n\ttimer_setup(timer, __cv_wakeup, 0);\n\n\ttimer->expires = expire_time;\n\tadd_timer(timer);\n\n\tio_schedule();\n\n\tdel_timer_sync(timer);\n\n\ttime_left = expire_time - jiffies;\n\n\treturn (time_left < 0 ? 0 : time_left);\n}\n#endif\n\n \nstatic clock_t\n__cv_timedwait_common(kcondvar_t *cvp, kmutex_t *mp, clock_t expire_time,\n    int state, int io)\n{\n\tDEFINE_WAIT(wait);\n\tkmutex_t *m;\n\tclock_t time_left;\n\n\tASSERT(cvp);\n\tASSERT(mp);\n\tASSERT(cvp->cv_magic == CV_MAGIC);\n\tASSERT(mutex_owned(mp));\n\n\t \n\ttime_left = expire_time - jiffies;\n\tif (time_left <= 0)\n\t\treturn (-1);\n\n\tatomic_inc(&cvp->cv_refs);\n\tm = READ_ONCE(cvp->cv_mutex);\n\tif (!m)\n\t\tm = xchg(&cvp->cv_mutex, mp);\n\t \n\tASSERT(m == NULL || m == mp);\n\n\tprepare_to_wait_exclusive(&cvp->cv_event, &wait, state);\n\tatomic_inc(&cvp->cv_waiters);\n\n\t \n\tmutex_exit(mp);\n\tif (io)\n\t\ttime_left = spl_io_schedule_timeout(time_left);\n\telse\n\t\ttime_left = schedule_timeout(time_left);\n\n\t \n\tif (atomic_dec_and_test(&cvp->cv_waiters)) {\n\t\t \n\t\tcvp->cv_mutex = NULL;\n\t\twake_up(&cvp->cv_destroy);\n\t}\n\n\tfinish_wait(&cvp->cv_event, &wait);\n\tatomic_dec(&cvp->cv_refs);\n\n\t \n\tmutex_enter(mp);\n\treturn (time_left > 0 ? 1 : -1);\n}\n\nint\n__cv_timedwait(kcondvar_t *cvp, kmutex_t *mp, clock_t exp_time)\n{\n\treturn (__cv_timedwait_common(cvp, mp, exp_time,\n\t    TASK_UNINTERRUPTIBLE, 0));\n}\nEXPORT_SYMBOL(__cv_timedwait);\n\nint\n__cv_timedwait_io(kcondvar_t *cvp, kmutex_t *mp, clock_t exp_time)\n{\n\treturn (__cv_timedwait_common(cvp, mp, exp_time,\n\t    TASK_UNINTERRUPTIBLE, 1));\n}\nEXPORT_SYMBOL(__cv_timedwait_io);\n\nint\n__cv_timedwait_sig(kcondvar_t *cvp, kmutex_t *mp, clock_t exp_time)\n{\n\tint rc;\n\n\trc = __cv_timedwait_common(cvp, mp, exp_time, TASK_INTERRUPTIBLE, 0);\n\treturn (signal_pending(current) ? 0 : rc);\n}\nEXPORT_SYMBOL(__cv_timedwait_sig);\n\nint\n__cv_timedwait_idle(kcondvar_t *cvp, kmutex_t *mp, clock_t exp_time)\n{\n\tsigset_t blocked, saved;\n\tint rc;\n\n\tsigfillset(&blocked);\n\t(void) sigprocmask(SIG_BLOCK, &blocked, &saved);\n\trc = __cv_timedwait_common(cvp, mp, exp_time,\n\t    TASK_INTERRUPTIBLE, 0);\n\t(void) sigprocmask(SIG_SETMASK, &saved, NULL);\n\n\treturn (rc);\n}\nEXPORT_SYMBOL(__cv_timedwait_idle);\n \nstatic clock_t\n__cv_timedwait_hires(kcondvar_t *cvp, kmutex_t *mp, hrtime_t expire_time,\n    hrtime_t res, int state)\n{\n\tDEFINE_WAIT(wait);\n\tkmutex_t *m;\n\thrtime_t time_left;\n\tktime_t ktime_left;\n\tu64 slack = 0;\n\tint rc;\n\n\tASSERT(cvp);\n\tASSERT(mp);\n\tASSERT(cvp->cv_magic == CV_MAGIC);\n\tASSERT(mutex_owned(mp));\n\n\ttime_left = expire_time - gethrtime();\n\tif (time_left <= 0)\n\t\treturn (-1);\n\n\tatomic_inc(&cvp->cv_refs);\n\tm = READ_ONCE(cvp->cv_mutex);\n\tif (!m)\n\t\tm = xchg(&cvp->cv_mutex, mp);\n\t \n\tASSERT(m == NULL || m == mp);\n\n\tprepare_to_wait_exclusive(&cvp->cv_event, &wait, state);\n\tatomic_inc(&cvp->cv_waiters);\n\n\t \n\tmutex_exit(mp);\n\n\tktime_left = ktime_set(0, time_left);\n\tslack = MIN(MAX(res, spl_schedule_hrtimeout_slack_us * NSEC_PER_USEC),\n\t    MAX_HRTIMEOUT_SLACK_US * NSEC_PER_USEC);\n\trc = schedule_hrtimeout_range(&ktime_left, slack, HRTIMER_MODE_REL);\n\n\t \n\tif (atomic_dec_and_test(&cvp->cv_waiters)) {\n\t\t \n\t\tcvp->cv_mutex = NULL;\n\t\twake_up(&cvp->cv_destroy);\n\t}\n\n\tfinish_wait(&cvp->cv_event, &wait);\n\tatomic_dec(&cvp->cv_refs);\n\n\tmutex_enter(mp);\n\treturn (rc == -EINTR ? 1 : -1);\n}\n\n \nstatic int\ncv_timedwait_hires_common(kcondvar_t *cvp, kmutex_t *mp, hrtime_t tim,\n    hrtime_t res, int flag, int state)\n{\n\tif (!(flag & CALLOUT_FLAG_ABSOLUTE))\n\t\ttim += gethrtime();\n\n\treturn (__cv_timedwait_hires(cvp, mp, tim, res, state));\n}\n\nint\ncv_timedwait_hires(kcondvar_t *cvp, kmutex_t *mp, hrtime_t tim, hrtime_t res,\n    int flag)\n{\n\treturn (cv_timedwait_hires_common(cvp, mp, tim, res, flag,\n\t    TASK_UNINTERRUPTIBLE));\n}\nEXPORT_SYMBOL(cv_timedwait_hires);\n\nint\ncv_timedwait_sig_hires(kcondvar_t *cvp, kmutex_t *mp, hrtime_t tim,\n    hrtime_t res, int flag)\n{\n\tint rc;\n\n\trc = cv_timedwait_hires_common(cvp, mp, tim, res, flag,\n\t    TASK_INTERRUPTIBLE);\n\treturn (signal_pending(current) ? 0 : rc);\n}\nEXPORT_SYMBOL(cv_timedwait_sig_hires);\n\nint\ncv_timedwait_idle_hires(kcondvar_t *cvp, kmutex_t *mp, hrtime_t tim,\n    hrtime_t res, int flag)\n{\n\tsigset_t blocked, saved;\n\tint rc;\n\n\tsigfillset(&blocked);\n\t(void) sigprocmask(SIG_BLOCK, &blocked, &saved);\n\trc = cv_timedwait_hires_common(cvp, mp, tim, res, flag,\n\t    TASK_INTERRUPTIBLE);\n\t(void) sigprocmask(SIG_SETMASK, &saved, NULL);\n\n\treturn (rc);\n}\nEXPORT_SYMBOL(cv_timedwait_idle_hires);\n\nvoid\n__cv_signal(kcondvar_t *cvp)\n{\n\tASSERT(cvp);\n\tASSERT(cvp->cv_magic == CV_MAGIC);\n\tatomic_inc(&cvp->cv_refs);\n\n\t \n\tif (atomic_read(&cvp->cv_waiters) > 0)\n\t\twake_up(&cvp->cv_event);\n\n\tatomic_dec(&cvp->cv_refs);\n}\nEXPORT_SYMBOL(__cv_signal);\n\nvoid\n__cv_broadcast(kcondvar_t *cvp)\n{\n\tASSERT(cvp);\n\tASSERT(cvp->cv_magic == CV_MAGIC);\n\tatomic_inc(&cvp->cv_refs);\n\n\t \n\tif (atomic_read(&cvp->cv_waiters) > 0)\n\t\twake_up_all(&cvp->cv_event);\n\n\tatomic_dec(&cvp->cv_refs);\n}\nEXPORT_SYMBOL(__cv_broadcast);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}