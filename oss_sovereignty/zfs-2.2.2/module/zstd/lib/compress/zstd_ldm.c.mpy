{
  "module_name": "zstd_ldm.c",
  "hash_id": "d5e67792f6e7eb0b3e8d3b59179f38235c9adc91d1655b34c231128addee644b",
  "original_prompt": "Ingested from zfs-2.2.2/module/zstd/lib/compress/zstd_ldm.c",
  "human_readable_source": " \n\n#include \"zstd_ldm.h\"\n\n#include \"../common/debug.h\"\n#include \"zstd_fast.h\"           \n#include \"zstd_double_fast.h\"    \n\n#define LDM_BUCKET_SIZE_LOG 3\n#define LDM_MIN_MATCH_LENGTH 64\n#define LDM_HASH_RLOG 7\n#define LDM_HASH_CHAR_OFFSET 10\n\nvoid ZSTD_ldm_adjustParameters(ldmParams_t* params,\n                               ZSTD_compressionParameters const* cParams)\n{\n    params->windowLog = cParams->windowLog;\n    ZSTD_STATIC_ASSERT(LDM_BUCKET_SIZE_LOG <= ZSTD_LDM_BUCKETSIZELOG_MAX);\n    DEBUGLOG(4, \"ZSTD_ldm_adjustParameters\");\n    if (!params->bucketSizeLog) params->bucketSizeLog = LDM_BUCKET_SIZE_LOG;\n    if (!params->minMatchLength) params->minMatchLength = LDM_MIN_MATCH_LENGTH;\n    if (cParams->strategy >= ZSTD_btopt) {\n       \n      U32 const minMatch = MAX(cParams->targetLength, params->minMatchLength);\n      assert(minMatch >= ZSTD_LDM_MINMATCH_MIN);\n      assert(minMatch <= ZSTD_LDM_MINMATCH_MAX);\n      params->minMatchLength = minMatch;\n    }\n    if (params->hashLog == 0) {\n        params->hashLog = MAX(ZSTD_HASHLOG_MIN, params->windowLog - LDM_HASH_RLOG);\n        assert(params->hashLog <= ZSTD_HASHLOG_MAX);\n    }\n    if (params->hashRateLog == 0) {\n        params->hashRateLog = params->windowLog < params->hashLog\n                                   ? 0\n                                   : params->windowLog - params->hashLog;\n    }\n    params->bucketSizeLog = MIN(params->bucketSizeLog, params->hashLog);\n}\n\nsize_t ZSTD_ldm_getTableSize(ldmParams_t params)\n{\n    size_t const ldmHSize = ((size_t)1) << params.hashLog;\n    size_t const ldmBucketSizeLog = MIN(params.bucketSizeLog, params.hashLog);\n    size_t const ldmBucketSize = ((size_t)1) << (params.hashLog - ldmBucketSizeLog);\n    size_t const totalSize = ZSTD_cwksp_alloc_size(ldmBucketSize)\n                           + ZSTD_cwksp_alloc_size(ldmHSize * sizeof(ldmEntry_t));\n    return params.enableLdm ? totalSize : 0;\n}\n\nsize_t ZSTD_ldm_getMaxNbSeq(ldmParams_t params, size_t maxChunkSize)\n{\n    return params.enableLdm ? (maxChunkSize / params.minMatchLength) : 0;\n}\n\n \nstatic U32 ZSTD_ldm_getSmallHash(U64 value, U32 numBits)\n{\n    assert(numBits <= 32);\n    return numBits == 0 ? 0 : (U32)(value >> (64 - numBits));\n}\n\n \nstatic U32 ZSTD_ldm_getChecksum(U64 hash, U32 numBitsToDiscard)\n{\n    assert(numBitsToDiscard <= 32);\n    return (hash >> (64 - 32 - numBitsToDiscard)) & 0xFFFFFFFF;\n}\n\n \nstatic U32 ZSTD_ldm_getTag(U64 hash, U32 hbits, U32 numTagBits)\n{\n    assert(numTagBits < 32 && hbits <= 32);\n    if (32 - hbits < numTagBits) {\n        return hash & (((U32)1 << numTagBits) - 1);\n    } else {\n        return (hash >> (32 - hbits - numTagBits)) & (((U32)1 << numTagBits) - 1);\n    }\n}\n\n \nstatic ldmEntry_t* ZSTD_ldm_getBucket(\n        ldmState_t* ldmState, size_t hash, ldmParams_t const ldmParams)\n{\n    return ldmState->hashTable + (hash << ldmParams.bucketSizeLog);\n}\n\n \nstatic void ZSTD_ldm_insertEntry(ldmState_t* ldmState,\n                                 size_t const hash, const ldmEntry_t entry,\n                                 ldmParams_t const ldmParams)\n{\n    BYTE* const bucketOffsets = ldmState->bucketOffsets;\n    *(ZSTD_ldm_getBucket(ldmState, hash, ldmParams) + bucketOffsets[hash]) = entry;\n    bucketOffsets[hash]++;\n    bucketOffsets[hash] &= ((U32)1 << ldmParams.bucketSizeLog) - 1;\n}\n\n \nstatic void ZSTD_ldm_makeEntryAndInsertByTag(ldmState_t* ldmState,\n                                             U64 const rollingHash,\n                                             U32 const hBits,\n                                             U32 const offset,\n                                             ldmParams_t const ldmParams)\n{\n    U32 const tag = ZSTD_ldm_getTag(rollingHash, hBits, ldmParams.hashRateLog);\n    U32 const tagMask = ((U32)1 << ldmParams.hashRateLog) - 1;\n    if (tag == tagMask) {\n        U32 const hash = ZSTD_ldm_getSmallHash(rollingHash, hBits);\n        U32 const checksum = ZSTD_ldm_getChecksum(rollingHash, hBits);\n        ldmEntry_t entry;\n        entry.offset = offset;\n        entry.checksum = checksum;\n        ZSTD_ldm_insertEntry(ldmState, hash, entry, ldmParams);\n    }\n}\n\n \nstatic size_t ZSTD_ldm_countBackwardsMatch(\n            const BYTE* pIn, const BYTE* pAnchor,\n            const BYTE* pMatch, const BYTE* pBase)\n{\n    size_t matchLength = 0;\n    while (pIn > pAnchor && pMatch > pBase && pIn[-1] == pMatch[-1]) {\n        pIn--;\n        pMatch--;\n        matchLength++;\n    }\n    return matchLength;\n}\n\n \nstatic size_t ZSTD_ldm_fillFastTables(ZSTD_matchState_t* ms,\n                                      void const* end)\n{\n    const BYTE* const iend = (const BYTE*)end;\n\n    switch(ms->cParams.strategy)\n    {\n    case ZSTD_fast:\n        ZSTD_fillHashTable(ms, iend, ZSTD_dtlm_fast);\n        break;\n\n    case ZSTD_dfast:\n        ZSTD_fillDoubleHashTable(ms, iend, ZSTD_dtlm_fast);\n        break;\n\n    case ZSTD_greedy:\n    case ZSTD_lazy:\n    case ZSTD_lazy2:\n    case ZSTD_btlazy2:\n    case ZSTD_btopt:\n    case ZSTD_btultra:\n    case ZSTD_btultra2:\n        break;\n    default:\n        assert(0);   \n    }\n\n    return 0;\n}\n\n \nstatic U64 ZSTD_ldm_fillLdmHashTable(ldmState_t* state,\n                                     U64 lastHash, const BYTE* lastHashed,\n                                     const BYTE* iend, const BYTE* base,\n                                     U32 hBits, ldmParams_t const ldmParams)\n{\n    U64 rollingHash = lastHash;\n    const BYTE* cur = lastHashed + 1;\n\n    while (cur < iend) {\n        rollingHash = ZSTD_rollingHash_rotate(rollingHash, cur[-1],\n                                              cur[ldmParams.minMatchLength-1],\n                                              state->hashPower);\n        ZSTD_ldm_makeEntryAndInsertByTag(state,\n                                         rollingHash, hBits,\n                                         (U32)(cur - base), ldmParams);\n        ++cur;\n    }\n    return rollingHash;\n}\n\nvoid ZSTD_ldm_fillHashTable(\n            ldmState_t* state, const BYTE* ip,\n            const BYTE* iend, ldmParams_t const* params)\n{\n    DEBUGLOG(5, \"ZSTD_ldm_fillHashTable\");\n    if ((size_t)(iend - ip) >= params->minMatchLength) {\n        U64 startingHash = ZSTD_rollingHash_compute(ip, params->minMatchLength);\n        ZSTD_ldm_fillLdmHashTable(\n            state, startingHash, ip, iend - params->minMatchLength, state->window.base,\n            params->hashLog - params->bucketSizeLog,\n            *params);\n    }\n}\n\n\n \nstatic void ZSTD_ldm_limitTableUpdate(ZSTD_matchState_t* ms, const BYTE* anchor)\n{\n    U32 const current = (U32)(anchor - ms->window.base);\n    if (current > ms->nextToUpdate + 1024) {\n        ms->nextToUpdate =\n            current - MIN(512, current - ms->nextToUpdate - 1024);\n    }\n}\n\nstatic size_t ZSTD_ldm_generateSequences_internal(\n        ldmState_t* ldmState, rawSeqStore_t* rawSeqStore,\n        ldmParams_t const* params, void const* src, size_t srcSize)\n{\n     \n    int const extDict = ZSTD_window_hasExtDict(ldmState->window);\n    U32 const minMatchLength = params->minMatchLength;\n    U64 const hashPower = ldmState->hashPower;\n    U32 const hBits = params->hashLog - params->bucketSizeLog;\n    U32 const ldmBucketSize = 1U << params->bucketSizeLog;\n    U32 const hashRateLog = params->hashRateLog;\n    U32 const ldmTagMask = (1U << params->hashRateLog) - 1;\n     \n    U32 const dictLimit = ldmState->window.dictLimit;\n    U32 const lowestIndex = extDict ? ldmState->window.lowLimit : dictLimit;\n    BYTE const* const base = ldmState->window.base;\n    BYTE const* const dictBase = extDict ? ldmState->window.dictBase : NULL;\n    BYTE const* const dictStart = extDict ? dictBase + lowestIndex : NULL;\n    BYTE const* const dictEnd = extDict ? dictBase + dictLimit : NULL;\n    BYTE const* const lowPrefixPtr = base + dictLimit;\n     \n    BYTE const* const istart = (BYTE const*)src;\n    BYTE const* const iend = istart + srcSize;\n    BYTE const* const ilimit = iend - MAX(minMatchLength, HASH_READ_SIZE);\n     \n    BYTE const* anchor = istart;\n    BYTE const* ip = istart;\n     \n    BYTE const* lastHashed = NULL;\n    U64 rollingHash = 0;\n\n    while (ip <= ilimit) {\n        size_t mLength;\n        U32 const current = (U32)(ip - base);\n        size_t forwardMatchLength = 0, backwardMatchLength = 0;\n        ldmEntry_t* bestEntry = NULL;\n        if (ip != istart) {\n            rollingHash = ZSTD_rollingHash_rotate(rollingHash, lastHashed[0],\n                                                  lastHashed[minMatchLength],\n                                                  hashPower);\n        } else {\n            rollingHash = ZSTD_rollingHash_compute(ip, minMatchLength);\n        }\n        lastHashed = ip;\n\n         \n        if (ZSTD_ldm_getTag(rollingHash, hBits, hashRateLog) != ldmTagMask) {\n           ip++;\n           continue;\n        }\n\n         \n        {\n            ldmEntry_t* const bucket =\n                ZSTD_ldm_getBucket(ldmState,\n                                   ZSTD_ldm_getSmallHash(rollingHash, hBits),\n                                   *params);\n            ldmEntry_t* cur;\n            size_t bestMatchLength = 0;\n            U32 const checksum = ZSTD_ldm_getChecksum(rollingHash, hBits);\n\n            for (cur = bucket; cur < bucket + ldmBucketSize; ++cur) {\n                size_t curForwardMatchLength, curBackwardMatchLength,\n                       curTotalMatchLength;\n                if (cur->checksum != checksum || cur->offset <= lowestIndex) {\n                    continue;\n                }\n                if (extDict) {\n                    BYTE const* const curMatchBase =\n                        cur->offset < dictLimit ? dictBase : base;\n                    BYTE const* const pMatch = curMatchBase + cur->offset;\n                    BYTE const* const matchEnd =\n                        cur->offset < dictLimit ? dictEnd : iend;\n                    BYTE const* const lowMatchPtr =\n                        cur->offset < dictLimit ? dictStart : lowPrefixPtr;\n\n                    curForwardMatchLength = ZSTD_count_2segments(\n                                                ip, pMatch, iend,\n                                                matchEnd, lowPrefixPtr);\n                    if (curForwardMatchLength < minMatchLength) {\n                        continue;\n                    }\n                    curBackwardMatchLength =\n                        ZSTD_ldm_countBackwardsMatch(ip, anchor, pMatch,\n                                                     lowMatchPtr);\n                    curTotalMatchLength = curForwardMatchLength +\n                                          curBackwardMatchLength;\n                } else {  \n                    BYTE const* const pMatch = base + cur->offset;\n                    curForwardMatchLength = ZSTD_count(ip, pMatch, iend);\n                    if (curForwardMatchLength < minMatchLength) {\n                        continue;\n                    }\n                    curBackwardMatchLength =\n                        ZSTD_ldm_countBackwardsMatch(ip, anchor, pMatch,\n                                                     lowPrefixPtr);\n                    curTotalMatchLength = curForwardMatchLength +\n                                          curBackwardMatchLength;\n                }\n\n                if (curTotalMatchLength > bestMatchLength) {\n                    bestMatchLength = curTotalMatchLength;\n                    forwardMatchLength = curForwardMatchLength;\n                    backwardMatchLength = curBackwardMatchLength;\n                    bestEntry = cur;\n                }\n            }\n        }\n\n         \n        if (bestEntry == NULL) {\n            ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash,\n                                             hBits, current,\n                                             *params);\n            ip++;\n            continue;\n        }\n\n         \n        mLength = forwardMatchLength + backwardMatchLength;\n        ip -= backwardMatchLength;\n\n        {\n             \n            U32 const matchIndex = bestEntry->offset;\n            U32 const offset = current - matchIndex;\n            rawSeq* const seq = rawSeqStore->seq + rawSeqStore->size;\n\n             \n            if (rawSeqStore->size == rawSeqStore->capacity)\n                return ERROR(dstSize_tooSmall);\n            seq->litLength = (U32)(ip - anchor);\n            seq->matchLength = (U32)mLength;\n            seq->offset = offset;\n            rawSeqStore->size++;\n        }\n\n         \n        ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash, hBits,\n                                         (U32)(lastHashed - base),\n                                         *params);\n\n        assert(ip + backwardMatchLength == lastHashed);\n\n         \n         \n        if (ip + mLength <= ilimit) {\n            rollingHash = ZSTD_ldm_fillLdmHashTable(\n                              ldmState, rollingHash, lastHashed,\n                              ip + mLength, base, hBits, *params);\n            lastHashed = ip + mLength - 1;\n        }\n        ip += mLength;\n        anchor = ip;\n    }\n    return iend - anchor;\n}\n\n \nstatic void ZSTD_ldm_reduceTable(ldmEntry_t* const table, U32 const size,\n                                 U32 const reducerValue)\n{\n    U32 u;\n    for (u = 0; u < size; u++) {\n        if (table[u].offset < reducerValue) table[u].offset = 0;\n        else table[u].offset -= reducerValue;\n    }\n}\n\nsize_t ZSTD_ldm_generateSequences(\n        ldmState_t* ldmState, rawSeqStore_t* sequences,\n        ldmParams_t const* params, void const* src, size_t srcSize)\n{\n    U32 const maxDist = 1U << params->windowLog;\n    BYTE const* const istart = (BYTE const*)src;\n    BYTE const* const iend = istart + srcSize;\n    size_t const kMaxChunkSize = 1 << 20;\n    size_t const nbChunks = (srcSize / kMaxChunkSize) + ((srcSize % kMaxChunkSize) != 0);\n    size_t chunk;\n    size_t leftoverSize = 0;\n\n    assert(ZSTD_CHUNKSIZE_MAX >= kMaxChunkSize);\n     \n    assert(ldmState->window.nextSrc >= (BYTE const*)src + srcSize);\n     \n    assert(sequences->pos <= sequences->size);\n    assert(sequences->size <= sequences->capacity);\n    for (chunk = 0; chunk < nbChunks && sequences->size < sequences->capacity; ++chunk) {\n        BYTE const* const chunkStart = istart + chunk * kMaxChunkSize;\n        size_t const remaining = (size_t)(iend - chunkStart);\n        BYTE const *const chunkEnd =\n            (remaining < kMaxChunkSize) ? iend : chunkStart + kMaxChunkSize;\n        size_t const chunkSize = chunkEnd - chunkStart;\n        size_t newLeftoverSize;\n        size_t const prevSize = sequences->size;\n\n        assert(chunkStart < iend);\n         \n        if (ZSTD_window_needOverflowCorrection(ldmState->window, chunkEnd)) {\n            U32 const ldmHSize = 1U << params->hashLog;\n            U32 const correction = ZSTD_window_correctOverflow(\n                &ldmState->window,   0, maxDist, chunkStart);\n            ZSTD_ldm_reduceTable(ldmState->hashTable, ldmHSize, correction);\n             \n            ldmState->loadedDictEnd = 0;\n        }\n         \n        ZSTD_window_enforceMaxDist(&ldmState->window, chunkEnd, maxDist, &ldmState->loadedDictEnd, NULL);\n         \n        newLeftoverSize = ZSTD_ldm_generateSequences_internal(\n            ldmState, sequences, params, chunkStart, chunkSize);\n        if (ZSTD_isError(newLeftoverSize))\n            return newLeftoverSize;\n         \n         \n        if (prevSize < sequences->size) {\n            sequences->seq[prevSize].litLength += (U32)leftoverSize;\n            leftoverSize = newLeftoverSize;\n        } else {\n            assert(newLeftoverSize == chunkSize);\n            leftoverSize += chunkSize;\n        }\n    }\n    return 0;\n}\n\nvoid ZSTD_ldm_skipSequences(rawSeqStore_t* rawSeqStore, size_t srcSize, U32 const minMatch) {\n    while (srcSize > 0 && rawSeqStore->pos < rawSeqStore->size) {\n        rawSeq* seq = rawSeqStore->seq + rawSeqStore->pos;\n        if (srcSize <= seq->litLength) {\n             \n            seq->litLength -= (U32)srcSize;\n            return;\n        }\n        srcSize -= seq->litLength;\n        seq->litLength = 0;\n        if (srcSize < seq->matchLength) {\n             \n            seq->matchLength -= (U32)srcSize;\n            if (seq->matchLength < minMatch) {\n                 \n                if (rawSeqStore->pos + 1 < rawSeqStore->size) {\n                    seq[1].litLength += seq[0].matchLength;\n                }\n                rawSeqStore->pos++;\n            }\n            return;\n        }\n        srcSize -= seq->matchLength;\n        seq->matchLength = 0;\n        rawSeqStore->pos++;\n    }\n}\n\n \nstatic rawSeq maybeSplitSequence(rawSeqStore_t* rawSeqStore,\n                                 U32 const remaining, U32 const minMatch)\n{\n    rawSeq sequence = rawSeqStore->seq[rawSeqStore->pos];\n    assert(sequence.offset > 0);\n     \n    if (remaining >= sequence.litLength + sequence.matchLength) {\n        rawSeqStore->pos++;\n        return sequence;\n    }\n     \n    if (remaining <= sequence.litLength) {\n        sequence.offset = 0;\n    } else if (remaining < sequence.litLength + sequence.matchLength) {\n        sequence.matchLength = remaining - sequence.litLength;\n        if (sequence.matchLength < minMatch) {\n            sequence.offset = 0;\n        }\n    }\n     \n    ZSTD_ldm_skipSequences(rawSeqStore, remaining, minMatch);\n    return sequence;\n}\n\nsize_t ZSTD_ldm_blockCompress(rawSeqStore_t* rawSeqStore,\n    ZSTD_matchState_t* ms, seqStore_t* seqStore, U32 rep[ZSTD_REP_NUM],\n    void const* src, size_t srcSize)\n{\n    const ZSTD_compressionParameters* const cParams = &ms->cParams;\n    unsigned const minMatch = cParams->minMatch;\n    ZSTD_blockCompressor const blockCompressor =\n        ZSTD_selectBlockCompressor(cParams->strategy, ZSTD_matchState_dictMode(ms));\n     \n    BYTE const* const istart = (BYTE const*)src;\n    BYTE const* const iend = istart + srcSize;\n     \n    BYTE const* ip = istart;\n\n    DEBUGLOG(5, \"ZSTD_ldm_blockCompress: srcSize=%zu\", srcSize);\n    assert(rawSeqStore->pos <= rawSeqStore->size);\n    assert(rawSeqStore->size <= rawSeqStore->capacity);\n     \n    while (rawSeqStore->pos < rawSeqStore->size && ip < iend) {\n         \n        rawSeq const sequence = maybeSplitSequence(rawSeqStore,\n                                                   (U32)(iend - ip), minMatch);\n        int i;\n         \n        if (sequence.offset == 0)\n            break;\n\n        assert(ip + sequence.litLength + sequence.matchLength <= iend);\n\n         \n        ZSTD_ldm_limitTableUpdate(ms, ip);\n        ZSTD_ldm_fillFastTables(ms, ip);\n         \n        DEBUGLOG(5, \"pos %u : calling block compressor on segment of size %u\", (unsigned)(ip-istart), sequence.litLength);\n        {\n            size_t const newLitLength =\n                blockCompressor(ms, seqStore, rep, ip, sequence.litLength);\n            ip += sequence.litLength;\n             \n            for (i = ZSTD_REP_NUM - 1; i > 0; i--)\n                rep[i] = rep[i-1];\n            rep[0] = sequence.offset;\n             \n            ZSTD_storeSeq(seqStore, newLitLength, ip - newLitLength, iend,\n                          sequence.offset + ZSTD_REP_MOVE,\n                          sequence.matchLength - MINMATCH);\n            ip += sequence.matchLength;\n        }\n    }\n     \n    ZSTD_ldm_limitTableUpdate(ms, ip);\n    ZSTD_ldm_fillFastTables(ms, ip);\n     \n    return blockCompressor(ms, seqStore, rep, ip, iend - ip);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}