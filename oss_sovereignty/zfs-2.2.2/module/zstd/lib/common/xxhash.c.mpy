{
  "module_name": "xxhash.c",
  "hash_id": "5ee8be5a194ca298150a5a6e5937b4a751309f3fa6a689ea85b9e6f5c2ab08a4",
  "original_prompt": "Ingested from zfs-2.2.2/module/zstd/lib/common/xxhash.c",
  "human_readable_source": " \n\n\n \n \n#ifndef XXH_FORCE_MEMORY_ACCESS    \n#  if defined(__GNUC__) && ( defined(__ARM_ARCH_6__) || defined(__ARM_ARCH_6J__) || defined(__ARM_ARCH_6K__) || defined(__ARM_ARCH_6Z__) || defined(__ARM_ARCH_6ZK__) || defined(__ARM_ARCH_6T2__) )\n#    define XXH_FORCE_MEMORY_ACCESS 2\n#  elif (defined(__INTEL_COMPILER) && !defined(WIN32)) || \\\n  (defined(__GNUC__) && ( defined(__ARM_ARCH_7__) || defined(__ARM_ARCH_7A__) || defined(__ARM_ARCH_7R__) || defined(__ARM_ARCH_7M__) || defined(__ARM_ARCH_7S__) )) || \\\n  defined(__ICCARM__)\n#    define XXH_FORCE_MEMORY_ACCESS 1\n#  endif\n#endif\n\n \n \n\n \n#ifndef XXH_FORCE_NATIVE_FORMAT    \n#  define XXH_FORCE_NATIVE_FORMAT 0\n#endif\n\n \n#ifndef XXH_FORCE_ALIGN_CHECK  \n#  if defined(__i386) || defined(_M_IX86) || defined(__x86_64__) || defined(_M_X64)\n#    define XXH_FORCE_ALIGN_CHECK 0\n#  else\n#    define XXH_FORCE_ALIGN_CHECK 1\n#  endif\n#endif\n\n\n \n \n \n#include <stdlib.h>\n#include <stddef.h>      \nstatic void* XXH_malloc(size_t s) { return malloc(s); }\nstatic void  XXH_free  (void* p)  { free(p); }\n \n#include <string.h>\nstatic void* XXH_memcpy(void* dest, const void* src, size_t size) { return memcpy(dest,src,size); }\n\n#ifndef XXH_STATIC_LINKING_ONLY\n#  define XXH_STATIC_LINKING_ONLY\n#endif\n#include \"xxhash.h\"\n\n\n \n#if (defined(__GNUC__) && !defined(__STRICT_ANSI__)) || defined(__cplusplus) || defined(__STDC_VERSION__) && __STDC_VERSION__ >= 199901L    \n#  define INLINE_KEYWORD inline\n#else\n#  define INLINE_KEYWORD\n#endif\n\n#if defined(__GNUC__) || defined(__ICCARM__)\n#  define FORCE_INLINE_ATTR __attribute__((always_inline))\n#elif defined(_MSC_VER)\n#  define FORCE_INLINE_ATTR __forceinline\n#else\n#  define FORCE_INLINE_ATTR\n#endif\n\n#define FORCE_INLINE_TEMPLATE static INLINE_KEYWORD FORCE_INLINE_ATTR\n\n\n#ifdef _MSC_VER\n#  pragma warning(disable : 4127)       \n#endif\n\n\n \n#ifndef MEM_MODULE\n# define MEM_MODULE\n# if !defined (__VMS) && (defined (__cplusplus) || (defined (__STDC_VERSION__) && (__STDC_VERSION__ >= 199901L)  ) )\n#   include <stdint.h>\n    typedef uint8_t  BYTE;\n    typedef uint16_t U16;\n    typedef uint32_t U32;\n    typedef  int32_t S32;\n    typedef uint64_t U64;\n#  else\n    typedef unsigned char      BYTE;\n    typedef unsigned short     U16;\n    typedef unsigned int       U32;\n    typedef   signed int       S32;\n    typedef unsigned long long U64;    \n#  endif\n#endif\n\n\n#if (defined(XXH_FORCE_MEMORY_ACCESS) && (XXH_FORCE_MEMORY_ACCESS==2))\n\n \nstatic U32 XXH_read32(const void* memPtr) { return *(const U32*) memPtr; }\nstatic U64 XXH_read64(const void* memPtr) { return *(const U64*) memPtr; }\n\n#elif (defined(XXH_FORCE_MEMORY_ACCESS) && (XXH_FORCE_MEMORY_ACCESS==1))\n\n \n \ntypedef union { U32 u32; U64 u64; } __attribute__((packed)) unalign;\n\nstatic U32 XXH_read32(const void* ptr) { return ((const unalign*)ptr)->u32; }\nstatic U64 XXH_read64(const void* ptr) { return ((const unalign*)ptr)->u64; }\n\n#else\n\n \n\nstatic U32 XXH_read32(const void* memPtr)\n{\n    U32 val;\n    memcpy(&val, memPtr, sizeof(val));\n    return val;\n}\n\nstatic U64 XXH_read64(const void* memPtr)\n{\n    U64 val;\n    memcpy(&val, memPtr, sizeof(val));\n    return val;\n}\n\n#endif    \n\n\n \n#define GCC_VERSION (__GNUC__ * 100 + __GNUC_MINOR__)\n\n \n#if defined(_MSC_VER)\n#  define XXH_rotl32(x,r) _rotl(x,r)\n#  define XXH_rotl64(x,r) _rotl64(x,r)\n#else\n#if defined(__ICCARM__)\n#  include <intrinsics.h>\n#  define XXH_rotl32(x,r) __ROR(x,(32 - r))\n#else\n#  define XXH_rotl32(x,r) ((x << r) | (x >> (32 - r)))\n#endif\n#  define XXH_rotl64(x,r) ((x << r) | (x >> (64 - r)))\n#endif\n\n#if defined(_MSC_VER)      \n#  define XXH_swap32 _byteswap_ulong\n#  define XXH_swap64 _byteswap_uint64\n#elif GCC_VERSION >= 403\n#  define XXH_swap32 __builtin_bswap32\n#  define XXH_swap64 __builtin_bswap64\n#else\nstatic U32 XXH_swap32 (U32 x)\n{\n    return  ((x << 24) & 0xff000000 ) |\n            ((x <<  8) & 0x00ff0000 ) |\n            ((x >>  8) & 0x0000ff00 ) |\n            ((x >> 24) & 0x000000ff );\n}\nstatic U64 XXH_swap64 (U64 x)\n{\n    return  ((x << 56) & 0xff00000000000000ULL) |\n            ((x << 40) & 0x00ff000000000000ULL) |\n            ((x << 24) & 0x0000ff0000000000ULL) |\n            ((x << 8)  & 0x000000ff00000000ULL) |\n            ((x >> 8)  & 0x00000000ff000000ULL) |\n            ((x >> 24) & 0x0000000000ff0000ULL) |\n            ((x >> 40) & 0x000000000000ff00ULL) |\n            ((x >> 56) & 0x00000000000000ffULL);\n}\n#endif\n\n\n \ntypedef enum { XXH_bigEndian=0, XXH_littleEndian=1 } XXH_endianess;\n\n \n#ifndef XXH_CPU_LITTLE_ENDIAN\n    static const int g_one = 1;\n#   define XXH_CPU_LITTLE_ENDIAN   (*(const char*)(&g_one))\n#endif\n\n\n \ntypedef enum { XXH_aligned, XXH_unaligned } XXH_alignment;\n\nFORCE_INLINE_TEMPLATE U32 XXH_readLE32_align(const void* ptr, XXH_endianess endian, XXH_alignment align)\n{\n    if (align==XXH_unaligned)\n        return endian==XXH_littleEndian ? XXH_read32(ptr) : XXH_swap32(XXH_read32(ptr));\n    else\n        return endian==XXH_littleEndian ? *(const U32*)ptr : XXH_swap32(*(const U32*)ptr);\n}\n\nFORCE_INLINE_TEMPLATE U32 XXH_readLE32(const void* ptr, XXH_endianess endian)\n{\n    return XXH_readLE32_align(ptr, endian, XXH_unaligned);\n}\n\nstatic U32 XXH_readBE32(const void* ptr)\n{\n    return XXH_CPU_LITTLE_ENDIAN ? XXH_swap32(XXH_read32(ptr)) : XXH_read32(ptr);\n}\n\nFORCE_INLINE_TEMPLATE U64 XXH_readLE64_align(const void* ptr, XXH_endianess endian, XXH_alignment align)\n{\n    if (align==XXH_unaligned)\n        return endian==XXH_littleEndian ? XXH_read64(ptr) : XXH_swap64(XXH_read64(ptr));\n    else\n        return endian==XXH_littleEndian ? *(const U64*)ptr : XXH_swap64(*(const U64*)ptr);\n}\n\nFORCE_INLINE_TEMPLATE U64 XXH_readLE64(const void* ptr, XXH_endianess endian)\n{\n    return XXH_readLE64_align(ptr, endian, XXH_unaligned);\n}\n\nstatic U64 XXH_readBE64(const void* ptr)\n{\n    return XXH_CPU_LITTLE_ENDIAN ? XXH_swap64(XXH_read64(ptr)) : XXH_read64(ptr);\n}\n\n\n \n#define XXH_STATIC_ASSERT(c)   { enum { XXH_static_assert = 1/(int)(!!(c)) }; }     \n\n\n \nstatic const U32 PRIME32_1 = 2654435761U;\nstatic const U32 PRIME32_2 = 2246822519U;\nstatic const U32 PRIME32_3 = 3266489917U;\nstatic const U32 PRIME32_4 =  668265263U;\nstatic const U32 PRIME32_5 =  374761393U;\n\nstatic const U64 PRIME64_1 = 11400714785074694791ULL;\nstatic const U64 PRIME64_2 = 14029467366897019727ULL;\nstatic const U64 PRIME64_3 =  1609587929392839161ULL;\nstatic const U64 PRIME64_4 =  9650029242287828579ULL;\nstatic const U64 PRIME64_5 =  2870177450012600261ULL;\n\nXXH_PUBLIC_API unsigned XXH_versionNumber (void) { return XXH_VERSION_NUMBER; }\n\n\n \nXXH_PUBLIC_API void XXH32_copyState(XXH32_state_t* restrict dstState, const XXH32_state_t* restrict srcState)\n{\n    memcpy(dstState, srcState, sizeof(*dstState));\n}\n\nXXH_PUBLIC_API void XXH64_copyState(XXH64_state_t* restrict dstState, const XXH64_state_t* restrict srcState)\n{\n    memcpy(dstState, srcState, sizeof(*dstState));\n}\n\n\n \n\nstatic U32 XXH32_round(U32 seed, U32 input)\n{\n    seed += input * PRIME32_2;\n    seed  = XXH_rotl32(seed, 13);\n    seed *= PRIME32_1;\n    return seed;\n}\n\nFORCE_INLINE_TEMPLATE U32 XXH32_endian_align(const void* input, size_t len, U32 seed, XXH_endianess endian, XXH_alignment align)\n{\n    const BYTE* p = (const BYTE*)input;\n    const BYTE* bEnd = p + len;\n    U32 h32;\n#define XXH_get32bits(p) XXH_readLE32_align(p, endian, align)\n\n#ifdef XXH_ACCEPT_NULL_INPUT_POINTER\n    if (p==NULL) {\n        len=0;\n        bEnd=p=(const BYTE*)(size_t)16;\n    }\n#endif\n\n    if (len>=16) {\n        const BYTE* const limit = bEnd - 16;\n        U32 v1 = seed + PRIME32_1 + PRIME32_2;\n        U32 v2 = seed + PRIME32_2;\n        U32 v3 = seed + 0;\n        U32 v4 = seed - PRIME32_1;\n\n        do {\n            v1 = XXH32_round(v1, XXH_get32bits(p)); p+=4;\n            v2 = XXH32_round(v2, XXH_get32bits(p)); p+=4;\n            v3 = XXH32_round(v3, XXH_get32bits(p)); p+=4;\n            v4 = XXH32_round(v4, XXH_get32bits(p)); p+=4;\n        } while (p<=limit);\n\n        h32 = XXH_rotl32(v1, 1) + XXH_rotl32(v2, 7) + XXH_rotl32(v3, 12) + XXH_rotl32(v4, 18);\n    } else {\n        h32  = seed + PRIME32_5;\n    }\n\n    h32 += (U32) len;\n\n    while (p+4<=bEnd) {\n        h32 += XXH_get32bits(p) * PRIME32_3;\n        h32  = XXH_rotl32(h32, 17) * PRIME32_4 ;\n        p+=4;\n    }\n\n    while (p<bEnd) {\n        h32 += (*p) * PRIME32_5;\n        h32 = XXH_rotl32(h32, 11) * PRIME32_1 ;\n        p++;\n    }\n\n    h32 ^= h32 >> 15;\n    h32 *= PRIME32_2;\n    h32 ^= h32 >> 13;\n    h32 *= PRIME32_3;\n    h32 ^= h32 >> 16;\n\n    return h32;\n}\n\n\nXXH_PUBLIC_API unsigned int XXH32 (const void* input, size_t len, unsigned int seed)\n{\n#if 0\n     \n    XXH32_CREATESTATE_STATIC(state);\n    XXH32_reset(state, seed);\n    XXH32_update(state, input, len);\n    return XXH32_digest(state);\n#else\n    XXH_endianess endian_detected = (XXH_endianess)XXH_CPU_LITTLE_ENDIAN;\n\n    if (XXH_FORCE_ALIGN_CHECK) {\n        if ((((size_t)input) & 3) == 0) {    \n            if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)\n                return XXH32_endian_align(input, len, seed, XXH_littleEndian, XXH_aligned);\n            else\n                return XXH32_endian_align(input, len, seed, XXH_bigEndian, XXH_aligned);\n    }   }\n\n    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)\n        return XXH32_endian_align(input, len, seed, XXH_littleEndian, XXH_unaligned);\n    else\n        return XXH32_endian_align(input, len, seed, XXH_bigEndian, XXH_unaligned);\n#endif\n}\n\n\nstatic U64 XXH64_round(U64 acc, U64 input)\n{\n    acc += input * PRIME64_2;\n    acc  = XXH_rotl64(acc, 31);\n    acc *= PRIME64_1;\n    return acc;\n}\n\nstatic U64 XXH64_mergeRound(U64 acc, U64 val)\n{\n    val  = XXH64_round(0, val);\n    acc ^= val;\n    acc  = acc * PRIME64_1 + PRIME64_4;\n    return acc;\n}\n\nFORCE_INLINE_TEMPLATE U64 XXH64_endian_align(const void* input, size_t len, U64 seed, XXH_endianess endian, XXH_alignment align)\n{\n    const BYTE* p = (const BYTE*)input;\n    const BYTE* const bEnd = p + len;\n    U64 h64;\n#define XXH_get64bits(p) XXH_readLE64_align(p, endian, align)\n\n#ifdef XXH_ACCEPT_NULL_INPUT_POINTER\n    if (p==NULL) {\n        len=0;\n        bEnd=p=(const BYTE*)(size_t)32;\n    }\n#endif\n\n    if (len>=32) {\n        const BYTE* const limit = bEnd - 32;\n        U64 v1 = seed + PRIME64_1 + PRIME64_2;\n        U64 v2 = seed + PRIME64_2;\n        U64 v3 = seed + 0;\n        U64 v4 = seed - PRIME64_1;\n\n        do {\n            v1 = XXH64_round(v1, XXH_get64bits(p)); p+=8;\n            v2 = XXH64_round(v2, XXH_get64bits(p)); p+=8;\n            v3 = XXH64_round(v3, XXH_get64bits(p)); p+=8;\n            v4 = XXH64_round(v4, XXH_get64bits(p)); p+=8;\n        } while (p<=limit);\n\n        h64 = XXH_rotl64(v1, 1) + XXH_rotl64(v2, 7) + XXH_rotl64(v3, 12) + XXH_rotl64(v4, 18);\n        h64 = XXH64_mergeRound(h64, v1);\n        h64 = XXH64_mergeRound(h64, v2);\n        h64 = XXH64_mergeRound(h64, v3);\n        h64 = XXH64_mergeRound(h64, v4);\n\n    } else {\n        h64  = seed + PRIME64_5;\n    }\n\n    h64 += (U64) len;\n\n    while (p+8<=bEnd) {\n        U64 const k1 = XXH64_round(0, XXH_get64bits(p));\n        h64 ^= k1;\n        h64  = XXH_rotl64(h64,27) * PRIME64_1 + PRIME64_4;\n        p+=8;\n    }\n\n    if (p+4<=bEnd) {\n        h64 ^= (U64)(XXH_get32bits(p)) * PRIME64_1;\n        h64 = XXH_rotl64(h64, 23) * PRIME64_2 + PRIME64_3;\n        p+=4;\n    }\n\n    while (p<bEnd) {\n        h64 ^= (*p) * PRIME64_5;\n        h64 = XXH_rotl64(h64, 11) * PRIME64_1;\n        p++;\n    }\n\n    h64 ^= h64 >> 33;\n    h64 *= PRIME64_2;\n    h64 ^= h64 >> 29;\n    h64 *= PRIME64_3;\n    h64 ^= h64 >> 32;\n\n    return h64;\n}\n\n\nXXH_PUBLIC_API unsigned long long XXH64 (const void* input, size_t len, unsigned long long seed)\n{\n#if 0\n     \n    XXH64_CREATESTATE_STATIC(state);\n    XXH64_reset(state, seed);\n    XXH64_update(state, input, len);\n    return XXH64_digest(state);\n#else\n    XXH_endianess endian_detected = (XXH_endianess)XXH_CPU_LITTLE_ENDIAN;\n\n    if (XXH_FORCE_ALIGN_CHECK) {\n        if ((((size_t)input) & 7)==0) {   \n            if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)\n                return XXH64_endian_align(input, len, seed, XXH_littleEndian, XXH_aligned);\n            else\n                return XXH64_endian_align(input, len, seed, XXH_bigEndian, XXH_aligned);\n    }   }\n\n    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)\n        return XXH64_endian_align(input, len, seed, XXH_littleEndian, XXH_unaligned);\n    else\n        return XXH64_endian_align(input, len, seed, XXH_bigEndian, XXH_unaligned);\n#endif\n}\n\n\n \n\nXXH_PUBLIC_API XXH32_state_t* XXH32_createState(void)\n{\n    return (XXH32_state_t*)XXH_malloc(sizeof(XXH32_state_t));\n}\nXXH_PUBLIC_API XXH_errorcode XXH32_freeState(XXH32_state_t* statePtr)\n{\n    XXH_free(statePtr);\n    return XXH_OK;\n}\n\nXXH_PUBLIC_API XXH64_state_t* XXH64_createState(void)\n{\n    return (XXH64_state_t*)XXH_malloc(sizeof(XXH64_state_t));\n}\nXXH_PUBLIC_API XXH_errorcode XXH64_freeState(XXH64_state_t* statePtr)\n{\n    XXH_free(statePtr);\n    return XXH_OK;\n}\n\n\n \n\nXXH_PUBLIC_API XXH_errorcode XXH32_reset(XXH32_state_t* statePtr, unsigned int seed)\n{\n    XXH32_state_t state;    \n    memset(&state, 0, sizeof(state)-4);    \n    state.v1 = seed + PRIME32_1 + PRIME32_2;\n    state.v2 = seed + PRIME32_2;\n    state.v3 = seed + 0;\n    state.v4 = seed - PRIME32_1;\n    memcpy(statePtr, &state, sizeof(state));\n    return XXH_OK;\n}\n\n\nXXH_PUBLIC_API XXH_errorcode XXH64_reset(XXH64_state_t* statePtr, unsigned long long seed)\n{\n    XXH64_state_t state;    \n    memset(&state, 0, sizeof(state)-8);    \n    state.v1 = seed + PRIME64_1 + PRIME64_2;\n    state.v2 = seed + PRIME64_2;\n    state.v3 = seed + 0;\n    state.v4 = seed - PRIME64_1;\n    memcpy(statePtr, &state, sizeof(state));\n    return XXH_OK;\n}\n\n\nFORCE_INLINE_TEMPLATE XXH_errorcode XXH32_update_endian (XXH32_state_t* state, const void* input, size_t len, XXH_endianess endian)\n{\n    const BYTE* p = (const BYTE*)input;\n    const BYTE* const bEnd = p + len;\n\n#ifdef XXH_ACCEPT_NULL_INPUT_POINTER\n    if (input==NULL) return XXH_ERROR;\n#endif\n\n    state->total_len_32 += (unsigned)len;\n    state->large_len |= (len>=16) | (state->total_len_32>=16);\n\n    if (state->memsize + len < 16)  {    \n        XXH_memcpy((BYTE*)(state->mem32) + state->memsize, input, len);\n        state->memsize += (unsigned)len;\n        return XXH_OK;\n    }\n\n    if (state->memsize) {    \n        XXH_memcpy((BYTE*)(state->mem32) + state->memsize, input, 16-state->memsize);\n        {   const U32* p32 = state->mem32;\n            state->v1 = XXH32_round(state->v1, XXH_readLE32(p32, endian)); p32++;\n            state->v2 = XXH32_round(state->v2, XXH_readLE32(p32, endian)); p32++;\n            state->v3 = XXH32_round(state->v3, XXH_readLE32(p32, endian)); p32++;\n            state->v4 = XXH32_round(state->v4, XXH_readLE32(p32, endian)); p32++;\n        }\n        p += 16-state->memsize;\n        state->memsize = 0;\n    }\n\n    if (p <= bEnd-16) {\n        const BYTE* const limit = bEnd - 16;\n        U32 v1 = state->v1;\n        U32 v2 = state->v2;\n        U32 v3 = state->v3;\n        U32 v4 = state->v4;\n\n        do {\n            v1 = XXH32_round(v1, XXH_readLE32(p, endian)); p+=4;\n            v2 = XXH32_round(v2, XXH_readLE32(p, endian)); p+=4;\n            v3 = XXH32_round(v3, XXH_readLE32(p, endian)); p+=4;\n            v4 = XXH32_round(v4, XXH_readLE32(p, endian)); p+=4;\n        } while (p<=limit);\n\n        state->v1 = v1;\n        state->v2 = v2;\n        state->v3 = v3;\n        state->v4 = v4;\n    }\n\n    if (p < bEnd) {\n        XXH_memcpy(state->mem32, p, (size_t)(bEnd-p));\n        state->memsize = (unsigned)(bEnd-p);\n    }\n\n    return XXH_OK;\n}\n\nXXH_PUBLIC_API XXH_errorcode XXH32_update (XXH32_state_t* state_in, const void* input, size_t len)\n{\n    XXH_endianess endian_detected = (XXH_endianess)XXH_CPU_LITTLE_ENDIAN;\n\n    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)\n        return XXH32_update_endian(state_in, input, len, XXH_littleEndian);\n    else\n        return XXH32_update_endian(state_in, input, len, XXH_bigEndian);\n}\n\n\n\nFORCE_INLINE_TEMPLATE U32 XXH32_digest_endian (const XXH32_state_t* state, XXH_endianess endian)\n{\n    const BYTE * p = (const BYTE*)state->mem32;\n    const BYTE* const bEnd = (const BYTE*)(state->mem32) + state->memsize;\n    U32 h32;\n\n    if (state->large_len) {\n        h32 = XXH_rotl32(state->v1, 1) + XXH_rotl32(state->v2, 7) + XXH_rotl32(state->v3, 12) + XXH_rotl32(state->v4, 18);\n    } else {\n        h32 = state->v3   + PRIME32_5;\n    }\n\n    h32 += state->total_len_32;\n\n    while (p+4<=bEnd) {\n        h32 += XXH_readLE32(p, endian) * PRIME32_3;\n        h32  = XXH_rotl32(h32, 17) * PRIME32_4;\n        p+=4;\n    }\n\n    while (p<bEnd) {\n        h32 += (*p) * PRIME32_5;\n        h32  = XXH_rotl32(h32, 11) * PRIME32_1;\n        p++;\n    }\n\n    h32 ^= h32 >> 15;\n    h32 *= PRIME32_2;\n    h32 ^= h32 >> 13;\n    h32 *= PRIME32_3;\n    h32 ^= h32 >> 16;\n\n    return h32;\n}\n\n\nXXH_PUBLIC_API unsigned int XXH32_digest (const XXH32_state_t* state_in)\n{\n    XXH_endianess endian_detected = (XXH_endianess)XXH_CPU_LITTLE_ENDIAN;\n\n    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)\n        return XXH32_digest_endian(state_in, XXH_littleEndian);\n    else\n        return XXH32_digest_endian(state_in, XXH_bigEndian);\n}\n\n\n\n \n\nFORCE_INLINE_TEMPLATE XXH_errorcode XXH64_update_endian (XXH64_state_t* state, const void* input, size_t len, XXH_endianess endian)\n{\n    const BYTE* p = (const BYTE*)input;\n    const BYTE* const bEnd = p + len;\n\n#ifdef XXH_ACCEPT_NULL_INPUT_POINTER\n    if (input==NULL) return XXH_ERROR;\n#endif\n\n    state->total_len += len;\n\n    if (state->memsize + len < 32) {   \n        if (input != NULL) {\n            XXH_memcpy(((BYTE*)state->mem64) + state->memsize, input, len);\n        }\n        state->memsize += (U32)len;\n        return XXH_OK;\n    }\n\n    if (state->memsize) {    \n        XXH_memcpy(((BYTE*)state->mem64) + state->memsize, input, 32-state->memsize);\n        state->v1 = XXH64_round(state->v1, XXH_readLE64(state->mem64+0, endian));\n        state->v2 = XXH64_round(state->v2, XXH_readLE64(state->mem64+1, endian));\n        state->v3 = XXH64_round(state->v3, XXH_readLE64(state->mem64+2, endian));\n        state->v4 = XXH64_round(state->v4, XXH_readLE64(state->mem64+3, endian));\n        p += 32-state->memsize;\n        state->memsize = 0;\n    }\n\n    if (p+32 <= bEnd) {\n        const BYTE* const limit = bEnd - 32;\n        U64 v1 = state->v1;\n        U64 v2 = state->v2;\n        U64 v3 = state->v3;\n        U64 v4 = state->v4;\n\n        do {\n            v1 = XXH64_round(v1, XXH_readLE64(p, endian)); p+=8;\n            v2 = XXH64_round(v2, XXH_readLE64(p, endian)); p+=8;\n            v3 = XXH64_round(v3, XXH_readLE64(p, endian)); p+=8;\n            v4 = XXH64_round(v4, XXH_readLE64(p, endian)); p+=8;\n        } while (p<=limit);\n\n        state->v1 = v1;\n        state->v2 = v2;\n        state->v3 = v3;\n        state->v4 = v4;\n    }\n\n    if (p < bEnd) {\n        XXH_memcpy(state->mem64, p, (size_t)(bEnd-p));\n        state->memsize = (unsigned)(bEnd-p);\n    }\n\n    return XXH_OK;\n}\n\nXXH_PUBLIC_API XXH_errorcode XXH64_update (XXH64_state_t* state_in, const void* input, size_t len)\n{\n    XXH_endianess endian_detected = (XXH_endianess)XXH_CPU_LITTLE_ENDIAN;\n\n    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)\n        return XXH64_update_endian(state_in, input, len, XXH_littleEndian);\n    else\n        return XXH64_update_endian(state_in, input, len, XXH_bigEndian);\n}\n\n\n\nFORCE_INLINE_TEMPLATE U64 XXH64_digest_endian (const XXH64_state_t* state, XXH_endianess endian)\n{\n    const BYTE * p = (const BYTE*)state->mem64;\n    const BYTE* const bEnd = (const BYTE*)state->mem64 + state->memsize;\n    U64 h64;\n\n    if (state->total_len >= 32) {\n        U64 const v1 = state->v1;\n        U64 const v2 = state->v2;\n        U64 const v3 = state->v3;\n        U64 const v4 = state->v4;\n\n        h64 = XXH_rotl64(v1, 1) + XXH_rotl64(v2, 7) + XXH_rotl64(v3, 12) + XXH_rotl64(v4, 18);\n        h64 = XXH64_mergeRound(h64, v1);\n        h64 = XXH64_mergeRound(h64, v2);\n        h64 = XXH64_mergeRound(h64, v3);\n        h64 = XXH64_mergeRound(h64, v4);\n    } else {\n        h64  = state->v3 + PRIME64_5;\n    }\n\n    h64 += (U64) state->total_len;\n\n    while (p+8<=bEnd) {\n        U64 const k1 = XXH64_round(0, XXH_readLE64(p, endian));\n        h64 ^= k1;\n        h64  = XXH_rotl64(h64,27) * PRIME64_1 + PRIME64_4;\n        p+=8;\n    }\n\n    if (p+4<=bEnd) {\n        h64 ^= (U64)(XXH_readLE32(p, endian)) * PRIME64_1;\n        h64  = XXH_rotl64(h64, 23) * PRIME64_2 + PRIME64_3;\n        p+=4;\n    }\n\n    while (p<bEnd) {\n        h64 ^= (*p) * PRIME64_5;\n        h64  = XXH_rotl64(h64, 11) * PRIME64_1;\n        p++;\n    }\n\n    h64 ^= h64 >> 33;\n    h64 *= PRIME64_2;\n    h64 ^= h64 >> 29;\n    h64 *= PRIME64_3;\n    h64 ^= h64 >> 32;\n\n    return h64;\n}\n\n\nXXH_PUBLIC_API unsigned long long XXH64_digest (const XXH64_state_t* state_in)\n{\n    XXH_endianess endian_detected = (XXH_endianess)XXH_CPU_LITTLE_ENDIAN;\n\n    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)\n        return XXH64_digest_endian(state_in, XXH_littleEndian);\n    else\n        return XXH64_digest_endian(state_in, XXH_bigEndian);\n}\n\n\n \n\n \n\nXXH_PUBLIC_API void XXH32_canonicalFromHash(XXH32_canonical_t* dst, XXH32_hash_t hash)\n{\n    XXH_STATIC_ASSERT(sizeof(XXH32_canonical_t) == sizeof(XXH32_hash_t));\n    if (XXH_CPU_LITTLE_ENDIAN) hash = XXH_swap32(hash);\n    memcpy(dst, &hash, sizeof(*dst));\n}\n\nXXH_PUBLIC_API void XXH64_canonicalFromHash(XXH64_canonical_t* dst, XXH64_hash_t hash)\n{\n    XXH_STATIC_ASSERT(sizeof(XXH64_canonical_t) == sizeof(XXH64_hash_t));\n    if (XXH_CPU_LITTLE_ENDIAN) hash = XXH_swap64(hash);\n    memcpy(dst, &hash, sizeof(*dst));\n}\n\nXXH_PUBLIC_API XXH32_hash_t XXH32_hashFromCanonical(const XXH32_canonical_t* src)\n{\n    return XXH_readBE32(src);\n}\n\nXXH_PUBLIC_API XXH64_hash_t XXH64_hashFromCanonical(const XXH64_canonical_t* src)\n{\n    return XXH_readBE64(src);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}