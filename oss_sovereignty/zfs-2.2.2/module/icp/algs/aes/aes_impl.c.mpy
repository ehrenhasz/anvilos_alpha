{
  "module_name": "aes_impl.c",
  "hash_id": "63112f49aae22a4980e2c431b5024ab278b4961fc78bfae854453da951079b54",
  "original_prompt": "Ingested from zfs-2.2.2/module/icp/algs/aes/aes_impl.c",
  "human_readable_source": " \n \n\n#include <sys/zfs_context.h>\n#include <sys/crypto/icp.h>\n#include <sys/crypto/spi.h>\n#include <sys/simd.h>\n#include <modes/modes.h>\n#include <aes/aes_impl.h>\n\n \nvoid\naes_init_keysched(const uint8_t *cipherKey, uint_t keyBits, void *keysched)\n{\n\tconst aes_impl_ops_t *ops = aes_impl_get_ops();\n\taes_key_t *newbie = keysched;\n\tuint_t keysize, i, j;\n\tunion {\n\t\tuint64_t\tka64[4];\n\t\tuint32_t\tka32[8];\n\t} keyarr;\n\n\tswitch (keyBits) {\n\tcase 128:\n\t\tnewbie->nr = 10;\n\t\tbreak;\n\n\tcase 192:\n\t\tnewbie->nr = 12;\n\t\tbreak;\n\n\tcase 256:\n\t\tnewbie->nr = 14;\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\treturn;\n\t}\n\tkeysize = CRYPTO_BITS2BYTES(keyBits);\n\n\t \n\tif (!ops->needs_byteswap) {\n\t\t \n\t\tif (IS_P2ALIGNED(cipherKey, sizeof (uint64_t))) {\n\t\t\tfor (i = 0, j = 0; j < keysize; i++, j += 8) {\n\t\t\t\t \n\t\t\t\tkeyarr.ka64[i] = *((uint64_t *)&cipherKey[j]);\n\t\t\t}\n\t\t} else {\n\t\t\tmemcpy(keyarr.ka32, cipherKey, keysize);\n\t\t}\n\t} else {\n\t\t \n\t\tfor (i = 0, j = 0; j < keysize; i++, j += 4) {\n\t\t\tkeyarr.ka32[i] =\n\t\t\t    htonl(*(uint32_t *)(void *)&cipherKey[j]);\n\t\t}\n\t}\n\n\tops->generate(newbie, keyarr.ka32, keyBits);\n\tnewbie->ops = ops;\n\n\t \n\tnewbie->type = AES_32BIT_KS;\n}\n\n\n \nint\naes_encrypt_block(const void *ks, const uint8_t *pt, uint8_t *ct)\n{\n\taes_key_t\t*ksch = (aes_key_t *)ks;\n\tconst aes_impl_ops_t\t*ops = ksch->ops;\n\n\tif (IS_P2ALIGNED2(pt, ct, sizeof (uint32_t)) && !ops->needs_byteswap) {\n\t\t \n\t\tops->encrypt(&ksch->encr_ks.ks32[0], ksch->nr,\n\t\t     \n\t\t    (uint32_t *)pt, (uint32_t *)ct);\n\t} else {\n\t\tuint32_t buffer[AES_BLOCK_LEN / sizeof (uint32_t)];\n\n\t\t \n\t\tif (ops->needs_byteswap) {\n\t\t\tbuffer[0] = htonl(*(uint32_t *)(void *)&pt[0]);\n\t\t\tbuffer[1] = htonl(*(uint32_t *)(void *)&pt[4]);\n\t\t\tbuffer[2] = htonl(*(uint32_t *)(void *)&pt[8]);\n\t\t\tbuffer[3] = htonl(*(uint32_t *)(void *)&pt[12]);\n\t\t} else\n\t\t\tmemcpy(&buffer, pt, AES_BLOCK_LEN);\n\n\t\tops->encrypt(&ksch->encr_ks.ks32[0], ksch->nr, buffer, buffer);\n\n\t\t \n\t\tif (ops->needs_byteswap) {\n\t\t\t*(uint32_t *)(void *)&ct[0] = htonl(buffer[0]);\n\t\t\t*(uint32_t *)(void *)&ct[4] = htonl(buffer[1]);\n\t\t\t*(uint32_t *)(void *)&ct[8] = htonl(buffer[2]);\n\t\t\t*(uint32_t *)(void *)&ct[12] = htonl(buffer[3]);\n\t\t} else\n\t\t\tmemcpy(ct, &buffer, AES_BLOCK_LEN);\n\t}\n\treturn (CRYPTO_SUCCESS);\n}\n\n\n \nint\naes_decrypt_block(const void *ks, const uint8_t *ct, uint8_t *pt)\n{\n\taes_key_t\t*ksch = (aes_key_t *)ks;\n\tconst aes_impl_ops_t\t*ops = ksch->ops;\n\n\tif (IS_P2ALIGNED2(ct, pt, sizeof (uint32_t)) && !ops->needs_byteswap) {\n\t\t \n\t\tops->decrypt(&ksch->decr_ks.ks32[0], ksch->nr,\n\t\t     \n\t\t    (uint32_t *)ct, (uint32_t *)pt);\n\t} else {\n\t\tuint32_t buffer[AES_BLOCK_LEN / sizeof (uint32_t)];\n\n\t\t \n\t\tif (ops->needs_byteswap) {\n\t\t\tbuffer[0] = htonl(*(uint32_t *)(void *)&ct[0]);\n\t\t\tbuffer[1] = htonl(*(uint32_t *)(void *)&ct[4]);\n\t\t\tbuffer[2] = htonl(*(uint32_t *)(void *)&ct[8]);\n\t\t\tbuffer[3] = htonl(*(uint32_t *)(void *)&ct[12]);\n\t\t} else\n\t\t\tmemcpy(&buffer, ct, AES_BLOCK_LEN);\n\n\t\tops->decrypt(&ksch->decr_ks.ks32[0], ksch->nr, buffer, buffer);\n\n\t\t \n\t\tif (ops->needs_byteswap) {\n\t\t\t*(uint32_t *)(void *)&pt[0] = htonl(buffer[0]);\n\t\t\t*(uint32_t *)(void *)&pt[4] = htonl(buffer[1]);\n\t\t\t*(uint32_t *)(void *)&pt[8] = htonl(buffer[2]);\n\t\t\t*(uint32_t *)(void *)&pt[12] = htonl(buffer[3]);\n\t\t} else\n\t\t\tmemcpy(pt, &buffer, AES_BLOCK_LEN);\n\t}\n\treturn (CRYPTO_SUCCESS);\n}\n\n\n \nvoid *\naes_alloc_keysched(size_t *size, int kmflag)\n{\n\taes_key_t *keysched;\n\n\tkeysched = kmem_alloc(sizeof (aes_key_t), kmflag);\n\tif (keysched != NULL) {\n\t\t*size = sizeof (aes_key_t);\n\t\treturn (keysched);\n\t}\n\treturn (NULL);\n}\n\n \nstatic aes_impl_ops_t aes_fastest_impl = {\n\t.name = \"fastest\"\n};\n\n \nstatic const aes_impl_ops_t *aes_all_impl[] = {\n\t&aes_generic_impl,\n#if defined(__x86_64)\n\t&aes_x86_64_impl,\n#endif\n#if defined(__x86_64) && defined(HAVE_AES)\n\t&aes_aesni_impl,\n#endif\n};\n\n \nstatic boolean_t aes_impl_initialized = B_FALSE;\n\n \n#define\tIMPL_FASTEST\t(UINT32_MAX)\n#define\tIMPL_CYCLE\t(UINT32_MAX-1)\n\n#define\tAES_IMPL_READ(i) (*(volatile uint32_t *) &(i))\n\nstatic uint32_t icp_aes_impl = IMPL_FASTEST;\nstatic uint32_t user_sel_impl = IMPL_FASTEST;\n\n \nstatic size_t aes_supp_impl_cnt = 0;\nstatic aes_impl_ops_t *aes_supp_impl[ARRAY_SIZE(aes_all_impl)];\n\n \nconst aes_impl_ops_t *\naes_impl_get_ops(void)\n{\n\tif (!kfpu_allowed())\n\t\treturn (&aes_generic_impl);\n\n\tconst aes_impl_ops_t *ops = NULL;\n\tconst uint32_t impl = AES_IMPL_READ(icp_aes_impl);\n\n\tswitch (impl) {\n\tcase IMPL_FASTEST:\n\t\tASSERT(aes_impl_initialized);\n\t\tops = &aes_fastest_impl;\n\t\tbreak;\n\tcase IMPL_CYCLE:\n\t\t \n\t\tASSERT(aes_impl_initialized);\n\t\tASSERT3U(aes_supp_impl_cnt, >, 0);\n\t\tstatic size_t cycle_impl_idx = 0;\n\t\tsize_t idx = (++cycle_impl_idx) % aes_supp_impl_cnt;\n\t\tops = aes_supp_impl[idx];\n\t\tbreak;\n\tdefault:\n\t\tASSERT3U(impl, <, aes_supp_impl_cnt);\n\t\tASSERT3U(aes_supp_impl_cnt, >, 0);\n\t\tif (impl < ARRAY_SIZE(aes_all_impl))\n\t\t\tops = aes_supp_impl[impl];\n\t\tbreak;\n\t}\n\n\tASSERT3P(ops, !=, NULL);\n\n\treturn (ops);\n}\n\n \nvoid\naes_impl_init(void)\n{\n\taes_impl_ops_t *curr_impl;\n\tint i, c;\n\n\t \n\tfor (i = 0, c = 0; i < ARRAY_SIZE(aes_all_impl); i++) {\n\t\tcurr_impl = (aes_impl_ops_t *)aes_all_impl[i];\n\n\t\tif (curr_impl->is_supported())\n\t\t\taes_supp_impl[c++] = (aes_impl_ops_t *)curr_impl;\n\t}\n\taes_supp_impl_cnt = c;\n\n\t \n#if defined(__x86_64)\n#if defined(HAVE_AES)\n\tif (aes_aesni_impl.is_supported()) {\n\t\tmemcpy(&aes_fastest_impl, &aes_aesni_impl,\n\t\t    sizeof (aes_fastest_impl));\n\t} else\n#endif\n\t{\n\t\tmemcpy(&aes_fastest_impl, &aes_x86_64_impl,\n\t\t    sizeof (aes_fastest_impl));\n\t}\n#else\n\tmemcpy(&aes_fastest_impl, &aes_generic_impl,\n\t    sizeof (aes_fastest_impl));\n#endif\n\n\tstrlcpy(aes_fastest_impl.name, \"fastest\", AES_IMPL_NAME_MAX);\n\n\t \n\tatomic_swap_32(&icp_aes_impl, user_sel_impl);\n\taes_impl_initialized = B_TRUE;\n}\n\nstatic const struct {\n\tconst char *name;\n\tuint32_t sel;\n} aes_impl_opts[] = {\n\t\t{ \"cycle\",\tIMPL_CYCLE },\n\t\t{ \"fastest\",\tIMPL_FASTEST },\n};\n\n \nint\naes_impl_set(const char *val)\n{\n\tint err = -EINVAL;\n\tchar req_name[AES_IMPL_NAME_MAX];\n\tuint32_t impl = AES_IMPL_READ(user_sel_impl);\n\tsize_t i;\n\n\t \n\ti = strnlen(val, AES_IMPL_NAME_MAX);\n\tif (i == 0 || i >= AES_IMPL_NAME_MAX)\n\t\treturn (err);\n\n\tstrlcpy(req_name, val, AES_IMPL_NAME_MAX);\n\twhile (i > 0 && isspace(req_name[i-1]))\n\t\ti--;\n\treq_name[i] = '\\0';\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(aes_impl_opts); i++) {\n\t\tif (strcmp(req_name, aes_impl_opts[i].name) == 0) {\n\t\t\timpl = aes_impl_opts[i].sel;\n\t\t\terr = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (err != 0 && aes_impl_initialized) {\n\t\t \n\t\tfor (i = 0; i < aes_supp_impl_cnt; i++) {\n\t\t\tif (strcmp(req_name, aes_supp_impl[i]->name) == 0) {\n\t\t\t\timpl = i;\n\t\t\t\terr = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (err == 0) {\n\t\tif (aes_impl_initialized)\n\t\t\tatomic_swap_32(&icp_aes_impl, impl);\n\t\telse\n\t\t\tatomic_swap_32(&user_sel_impl, impl);\n\t}\n\n\treturn (err);\n}\n\n#if defined(_KERNEL) && defined(__linux__)\n\nstatic int\nicp_aes_impl_set(const char *val, zfs_kernel_param_t *kp)\n{\n\treturn (aes_impl_set(val));\n}\n\nstatic int\nicp_aes_impl_get(char *buffer, zfs_kernel_param_t *kp)\n{\n\tint i, cnt = 0;\n\tchar *fmt;\n\tconst uint32_t impl = AES_IMPL_READ(icp_aes_impl);\n\n\tASSERT(aes_impl_initialized);\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(aes_impl_opts); i++) {\n\t\tfmt = (impl == aes_impl_opts[i].sel) ? \"[%s] \" : \"%s \";\n\t\tcnt += kmem_scnprintf(buffer + cnt, PAGE_SIZE - cnt, fmt,\n\t\t    aes_impl_opts[i].name);\n\t}\n\n\t \n\tfor (i = 0; i < aes_supp_impl_cnt; i++) {\n\t\tfmt = (i == impl) ? \"[%s] \" : \"%s \";\n\t\tcnt += kmem_scnprintf(buffer + cnt, PAGE_SIZE - cnt, fmt,\n\t\t    aes_supp_impl[i]->name);\n\t}\n\n\treturn (cnt);\n}\n\nmodule_param_call(icp_aes_impl, icp_aes_impl_set, icp_aes_impl_get,\n    NULL, 0644);\nMODULE_PARM_DESC(icp_aes_impl, \"Select aes implementation.\");\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}