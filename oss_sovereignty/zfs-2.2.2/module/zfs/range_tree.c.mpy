{
  "module_name": "range_tree.c",
  "hash_id": "3a48d12201b07508bde0b3ff20107f8017578b11f2d68e7f98e52b459304ce84",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/range_tree.c",
  "human_readable_source": " \n \n \n\n#include <sys/zfs_context.h>\n#include <sys/spa.h>\n#include <sys/dmu.h>\n#include <sys/dnode.h>\n#include <sys/zio.h>\n#include <sys/range_tree.h>\n\n \n\nstatic inline void\nrs_copy(range_seg_t *src, range_seg_t *dest, range_tree_t *rt)\n{\n\tASSERT3U(rt->rt_type, <, RANGE_SEG_NUM_TYPES);\n\tsize_t size = 0;\n\tswitch (rt->rt_type) {\n\tcase RANGE_SEG32:\n\t\tsize = sizeof (range_seg32_t);\n\t\tbreak;\n\tcase RANGE_SEG64:\n\t\tsize = sizeof (range_seg64_t);\n\t\tbreak;\n\tcase RANGE_SEG_GAP:\n\t\tsize = sizeof (range_seg_gap_t);\n\t\tbreak;\n\tdefault:\n\t\t__builtin_unreachable();\n\t}\n\tmemcpy(dest, src, size);\n}\n\nvoid\nrange_tree_stat_verify(range_tree_t *rt)\n{\n\trange_seg_t *rs;\n\tzfs_btree_index_t where;\n\tuint64_t hist[RANGE_TREE_HISTOGRAM_SIZE] = { 0 };\n\tint i;\n\n\tfor (rs = zfs_btree_first(&rt->rt_root, &where); rs != NULL;\n\t    rs = zfs_btree_next(&rt->rt_root, &where, &where)) {\n\t\tuint64_t size = rs_get_end(rs, rt) - rs_get_start(rs, rt);\n\t\tint idx\t= highbit64(size) - 1;\n\n\t\thist[idx]++;\n\t\tASSERT3U(hist[idx], !=, 0);\n\t}\n\n\tfor (i = 0; i < RANGE_TREE_HISTOGRAM_SIZE; i++) {\n\t\tif (hist[i] != rt->rt_histogram[i]) {\n\t\t\tzfs_dbgmsg(\"i=%d, hist=%px, hist=%llu, rt_hist=%llu\",\n\t\t\t    i, hist, (u_longlong_t)hist[i],\n\t\t\t    (u_longlong_t)rt->rt_histogram[i]);\n\t\t}\n\t\tVERIFY3U(hist[i], ==, rt->rt_histogram[i]);\n\t}\n}\n\nstatic void\nrange_tree_stat_incr(range_tree_t *rt, range_seg_t *rs)\n{\n\tuint64_t size = rs_get_end(rs, rt) - rs_get_start(rs, rt);\n\tint idx = highbit64(size) - 1;\n\n\tASSERT(size != 0);\n\tASSERT3U(idx, <,\n\t    sizeof (rt->rt_histogram) / sizeof (*rt->rt_histogram));\n\n\trt->rt_histogram[idx]++;\n\tASSERT3U(rt->rt_histogram[idx], !=, 0);\n}\n\nstatic void\nrange_tree_stat_decr(range_tree_t *rt, range_seg_t *rs)\n{\n\tuint64_t size = rs_get_end(rs, rt) - rs_get_start(rs, rt);\n\tint idx = highbit64(size) - 1;\n\n\tASSERT(size != 0);\n\tASSERT3U(idx, <,\n\t    sizeof (rt->rt_histogram) / sizeof (*rt->rt_histogram));\n\n\tASSERT3U(rt->rt_histogram[idx], !=, 0);\n\trt->rt_histogram[idx]--;\n}\n\n__attribute__((always_inline)) inline\nstatic int\nrange_tree_seg32_compare(const void *x1, const void *x2)\n{\n\tconst range_seg32_t *r1 = x1;\n\tconst range_seg32_t *r2 = x2;\n\n\tASSERT3U(r1->rs_start, <=, r1->rs_end);\n\tASSERT3U(r2->rs_start, <=, r2->rs_end);\n\n\treturn ((r1->rs_start >= r2->rs_end) - (r1->rs_end <= r2->rs_start));\n}\n\n__attribute__((always_inline)) inline\nstatic int\nrange_tree_seg64_compare(const void *x1, const void *x2)\n{\n\tconst range_seg64_t *r1 = x1;\n\tconst range_seg64_t *r2 = x2;\n\n\tASSERT3U(r1->rs_start, <=, r1->rs_end);\n\tASSERT3U(r2->rs_start, <=, r2->rs_end);\n\n\treturn ((r1->rs_start >= r2->rs_end) - (r1->rs_end <= r2->rs_start));\n}\n\n__attribute__((always_inline)) inline\nstatic int\nrange_tree_seg_gap_compare(const void *x1, const void *x2)\n{\n\tconst range_seg_gap_t *r1 = x1;\n\tconst range_seg_gap_t *r2 = x2;\n\n\tASSERT3U(r1->rs_start, <=, r1->rs_end);\n\tASSERT3U(r2->rs_start, <=, r2->rs_end);\n\n\treturn ((r1->rs_start >= r2->rs_end) - (r1->rs_end <= r2->rs_start));\n}\n\nZFS_BTREE_FIND_IN_BUF_FUNC(range_tree_seg32_find_in_buf, range_seg32_t,\n    range_tree_seg32_compare)\n\nZFS_BTREE_FIND_IN_BUF_FUNC(range_tree_seg64_find_in_buf, range_seg64_t,\n    range_tree_seg64_compare)\n\nZFS_BTREE_FIND_IN_BUF_FUNC(range_tree_seg_gap_find_in_buf, range_seg_gap_t,\n    range_tree_seg_gap_compare)\n\nrange_tree_t *\nrange_tree_create_gap(const range_tree_ops_t *ops, range_seg_type_t type,\n    void *arg, uint64_t start, uint64_t shift, uint64_t gap)\n{\n\trange_tree_t *rt = kmem_zalloc(sizeof (range_tree_t), KM_SLEEP);\n\n\tASSERT3U(shift, <, 64);\n\tASSERT3U(type, <=, RANGE_SEG_NUM_TYPES);\n\tsize_t size;\n\tint (*compare) (const void *, const void *);\n\tbt_find_in_buf_f bt_find;\n\tswitch (type) {\n\tcase RANGE_SEG32:\n\t\tsize = sizeof (range_seg32_t);\n\t\tcompare = range_tree_seg32_compare;\n\t\tbt_find = range_tree_seg32_find_in_buf;\n\t\tbreak;\n\tcase RANGE_SEG64:\n\t\tsize = sizeof (range_seg64_t);\n\t\tcompare = range_tree_seg64_compare;\n\t\tbt_find = range_tree_seg64_find_in_buf;\n\t\tbreak;\n\tcase RANGE_SEG_GAP:\n\t\tsize = sizeof (range_seg_gap_t);\n\t\tcompare = range_tree_seg_gap_compare;\n\t\tbt_find = range_tree_seg_gap_find_in_buf;\n\t\tbreak;\n\tdefault:\n\t\tpanic(\"Invalid range seg type %d\", type);\n\t}\n\tzfs_btree_create(&rt->rt_root, compare, bt_find, size);\n\n\trt->rt_ops = ops;\n\trt->rt_gap = gap;\n\trt->rt_arg = arg;\n\trt->rt_type = type;\n\trt->rt_start = start;\n\trt->rt_shift = shift;\n\n\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_create != NULL)\n\t\trt->rt_ops->rtop_create(rt, rt->rt_arg);\n\n\treturn (rt);\n}\n\nrange_tree_t *\nrange_tree_create(const range_tree_ops_t *ops, range_seg_type_t type,\n    void *arg, uint64_t start, uint64_t shift)\n{\n\treturn (range_tree_create_gap(ops, type, arg, start, shift, 0));\n}\n\nvoid\nrange_tree_destroy(range_tree_t *rt)\n{\n\tVERIFY0(rt->rt_space);\n\n\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_destroy != NULL)\n\t\trt->rt_ops->rtop_destroy(rt, rt->rt_arg);\n\n\tzfs_btree_destroy(&rt->rt_root);\n\tkmem_free(rt, sizeof (*rt));\n}\n\nvoid\nrange_tree_adjust_fill(range_tree_t *rt, range_seg_t *rs, int64_t delta)\n{\n\tif (delta < 0 && delta * -1 >= rs_get_fill(rs, rt)) {\n\t\tzfs_panic_recover(\"zfs: attempting to decrease fill to or \"\n\t\t    \"below 0; probable double remove in segment [%llx:%llx]\",\n\t\t    (longlong_t)rs_get_start(rs, rt),\n\t\t    (longlong_t)rs_get_end(rs, rt));\n\t}\n\tif (rs_get_fill(rs, rt) + delta > rs_get_end(rs, rt) -\n\t    rs_get_start(rs, rt)) {\n\t\tzfs_panic_recover(\"zfs: attempting to increase fill beyond \"\n\t\t    \"max; probable double add in segment [%llx:%llx]\",\n\t\t    (longlong_t)rs_get_start(rs, rt),\n\t\t    (longlong_t)rs_get_end(rs, rt));\n\t}\n\n\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_remove != NULL)\n\t\trt->rt_ops->rtop_remove(rt, rs, rt->rt_arg);\n\trs_set_fill(rs, rt, rs_get_fill(rs, rt) + delta);\n\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_add != NULL)\n\t\trt->rt_ops->rtop_add(rt, rs, rt->rt_arg);\n}\n\nstatic void\nrange_tree_add_impl(void *arg, uint64_t start, uint64_t size, uint64_t fill)\n{\n\trange_tree_t *rt = arg;\n\tzfs_btree_index_t where;\n\trange_seg_t *rs_before, *rs_after, *rs;\n\trange_seg_max_t tmp, rsearch;\n\tuint64_t end = start + size, gap = rt->rt_gap;\n\tuint64_t bridge_size = 0;\n\tboolean_t merge_before, merge_after;\n\n\tASSERT3U(size, !=, 0);\n\tASSERT3U(fill, <=, size);\n\tASSERT3U(start + size, >, start);\n\n\trs_set_start(&rsearch, rt, start);\n\trs_set_end(&rsearch, rt, end);\n\trs = zfs_btree_find(&rt->rt_root, &rsearch, &where);\n\n\t \n\tif (rs != NULL) {\n\t\tif (gap == 0) {\n\t\t\tzfs_panic_recover(\"zfs: adding existent segment to \"\n\t\t\t    \"range tree (offset=%llx size=%llx)\",\n\t\t\t    (longlong_t)start, (longlong_t)size);\n\t\t\treturn;\n\t\t}\n\t\tuint64_t rstart = rs_get_start(rs, rt);\n\t\tuint64_t rend = rs_get_end(rs, rt);\n\t\tif (rstart <= start && rend >= end) {\n\t\t\trange_tree_adjust_fill(rt, rs, fill);\n\t\t\treturn;\n\t\t}\n\n\t\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_remove != NULL)\n\t\t\trt->rt_ops->rtop_remove(rt, rs, rt->rt_arg);\n\n\t\trange_tree_stat_decr(rt, rs);\n\t\trt->rt_space -= rend - rstart;\n\n\t\tfill += rs_get_fill(rs, rt);\n\t\tstart = MIN(start, rstart);\n\t\tend = MAX(end, rend);\n\t\tsize = end - start;\n\n\t\tzfs_btree_remove(&rt->rt_root, rs);\n\t\trange_tree_add_impl(rt, start, size, fill);\n\t\treturn;\n\t}\n\n\tASSERT3P(rs, ==, NULL);\n\n\t \n\tzfs_btree_index_t where_before, where_after;\n\trs_before = zfs_btree_prev(&rt->rt_root, &where, &where_before);\n\trs_after = zfs_btree_next(&rt->rt_root, &where, &where_after);\n\n\tmerge_before = (rs_before != NULL && rs_get_end(rs_before, rt) >=\n\t    start - gap);\n\tmerge_after = (rs_after != NULL && rs_get_start(rs_after, rt) <= end +\n\t    gap);\n\n\tif (merge_before && gap != 0)\n\t\tbridge_size += start - rs_get_end(rs_before, rt);\n\tif (merge_after && gap != 0)\n\t\tbridge_size += rs_get_start(rs_after, rt) - end;\n\n\tif (merge_before && merge_after) {\n\t\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_remove != NULL) {\n\t\t\trt->rt_ops->rtop_remove(rt, rs_before, rt->rt_arg);\n\t\t\trt->rt_ops->rtop_remove(rt, rs_after, rt->rt_arg);\n\t\t}\n\n\t\trange_tree_stat_decr(rt, rs_before);\n\t\trange_tree_stat_decr(rt, rs_after);\n\n\t\trs_copy(rs_after, &tmp, rt);\n\t\tuint64_t before_start = rs_get_start_raw(rs_before, rt);\n\t\tuint64_t before_fill = rs_get_fill(rs_before, rt);\n\t\tuint64_t after_fill = rs_get_fill(rs_after, rt);\n\t\tzfs_btree_remove_idx(&rt->rt_root, &where_before);\n\n\t\t \n\t\trs_after = zfs_btree_find(&rt->rt_root, &tmp, &where_after);\n\t\tASSERT3P(rs_after, !=, NULL);\n\t\trs_set_start_raw(rs_after, rt, before_start);\n\t\trs_set_fill(rs_after, rt, after_fill + before_fill + fill);\n\t\trs = rs_after;\n\t} else if (merge_before) {\n\t\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_remove != NULL)\n\t\t\trt->rt_ops->rtop_remove(rt, rs_before, rt->rt_arg);\n\n\t\trange_tree_stat_decr(rt, rs_before);\n\n\t\tuint64_t before_fill = rs_get_fill(rs_before, rt);\n\t\trs_set_end(rs_before, rt, end);\n\t\trs_set_fill(rs_before, rt, before_fill + fill);\n\t\trs = rs_before;\n\t} else if (merge_after) {\n\t\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_remove != NULL)\n\t\t\trt->rt_ops->rtop_remove(rt, rs_after, rt->rt_arg);\n\n\t\trange_tree_stat_decr(rt, rs_after);\n\n\t\tuint64_t after_fill = rs_get_fill(rs_after, rt);\n\t\trs_set_start(rs_after, rt, start);\n\t\trs_set_fill(rs_after, rt, after_fill + fill);\n\t\trs = rs_after;\n\t} else {\n\t\trs = &tmp;\n\n\t\trs_set_start(rs, rt, start);\n\t\trs_set_end(rs, rt, end);\n\t\trs_set_fill(rs, rt, fill);\n\t\tzfs_btree_add_idx(&rt->rt_root, rs, &where);\n\t}\n\n\tif (gap != 0) {\n\t\tASSERT3U(rs_get_fill(rs, rt), <=, rs_get_end(rs, rt) -\n\t\t    rs_get_start(rs, rt));\n\t} else {\n\t\tASSERT3U(rs_get_fill(rs, rt), ==, rs_get_end(rs, rt) -\n\t\t    rs_get_start(rs, rt));\n\t}\n\n\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_add != NULL)\n\t\trt->rt_ops->rtop_add(rt, rs, rt->rt_arg);\n\n\trange_tree_stat_incr(rt, rs);\n\trt->rt_space += size + bridge_size;\n}\n\nvoid\nrange_tree_add(void *arg, uint64_t start, uint64_t size)\n{\n\trange_tree_add_impl(arg, start, size, size);\n}\n\nstatic void\nrange_tree_remove_impl(range_tree_t *rt, uint64_t start, uint64_t size,\n    boolean_t do_fill)\n{\n\tzfs_btree_index_t where;\n\trange_seg_t *rs;\n\trange_seg_max_t rsearch, rs_tmp;\n\tuint64_t end = start + size;\n\tboolean_t left_over, right_over;\n\n\tVERIFY3U(size, !=, 0);\n\tVERIFY3U(size, <=, rt->rt_space);\n\tif (rt->rt_type == RANGE_SEG64)\n\t\tASSERT3U(start + size, >, start);\n\n\trs_set_start(&rsearch, rt, start);\n\trs_set_end(&rsearch, rt, end);\n\trs = zfs_btree_find(&rt->rt_root, &rsearch, &where);\n\n\t \n\tif (rs == NULL) {\n\t\tzfs_panic_recover(\"zfs: removing nonexistent segment from \"\n\t\t    \"range tree (offset=%llx size=%llx)\",\n\t\t    (longlong_t)start, (longlong_t)size);\n\t\treturn;\n\t}\n\n\t \n\tif (rt->rt_gap != 0) {\n\t\tif (do_fill) {\n\t\t\tif (rs_get_fill(rs, rt) == size) {\n\t\t\t\tstart = rs_get_start(rs, rt);\n\t\t\t\tend = rs_get_end(rs, rt);\n\t\t\t\tsize = end - start;\n\t\t\t} else {\n\t\t\t\trange_tree_adjust_fill(rt, rs, -size);\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else if (rs_get_start(rs, rt) != start ||\n\t\t    rs_get_end(rs, rt) != end) {\n\t\t\tzfs_panic_recover(\"zfs: freeing partial segment of \"\n\t\t\t    \"gap tree (offset=%llx size=%llx) of \"\n\t\t\t    \"(offset=%llx size=%llx)\",\n\t\t\t    (longlong_t)start, (longlong_t)size,\n\t\t\t    (longlong_t)rs_get_start(rs, rt),\n\t\t\t    (longlong_t)rs_get_end(rs, rt) - rs_get_start(rs,\n\t\t\t    rt));\n\t\t\treturn;\n\t\t}\n\t}\n\n\tVERIFY3U(rs_get_start(rs, rt), <=, start);\n\tVERIFY3U(rs_get_end(rs, rt), >=, end);\n\n\tleft_over = (rs_get_start(rs, rt) != start);\n\tright_over = (rs_get_end(rs, rt) != end);\n\n\trange_tree_stat_decr(rt, rs);\n\n\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_remove != NULL)\n\t\trt->rt_ops->rtop_remove(rt, rs, rt->rt_arg);\n\n\tif (left_over && right_over) {\n\t\trange_seg_max_t newseg;\n\t\trs_set_start(&newseg, rt, end);\n\t\trs_set_end_raw(&newseg, rt, rs_get_end_raw(rs, rt));\n\t\trs_set_fill(&newseg, rt, rs_get_end(rs, rt) - end);\n\t\trange_tree_stat_incr(rt, &newseg);\n\n\t\t \n\t\trs_set_end(rs, rt, start);\n\n\t\trs_copy(rs, &rs_tmp, rt);\n\t\tif (zfs_btree_next(&rt->rt_root, &where, &where) != NULL)\n\t\t\tzfs_btree_add_idx(&rt->rt_root, &newseg, &where);\n\t\telse\n\t\t\tzfs_btree_add(&rt->rt_root, &newseg);\n\n\t\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_add != NULL)\n\t\t\trt->rt_ops->rtop_add(rt, &newseg, rt->rt_arg);\n\t} else if (left_over) {\n\t\t \n\t\trs_set_end(rs, rt, start);\n\t\trs_copy(rs, &rs_tmp, rt);\n\t} else if (right_over) {\n\t\t \n\t\trs_set_start(rs, rt, end);\n\t\trs_copy(rs, &rs_tmp, rt);\n\t} else {\n\t\tzfs_btree_remove_idx(&rt->rt_root, &where);\n\t\trs = NULL;\n\t}\n\n\tif (rs != NULL) {\n\t\t \n\t\trs_set_fill_raw(rs, rt, rs_get_end_raw(rs, rt) -\n\t\t    rs_get_start_raw(rs, rt));\n\t\trange_tree_stat_incr(rt, &rs_tmp);\n\n\t\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_add != NULL)\n\t\t\trt->rt_ops->rtop_add(rt, &rs_tmp, rt->rt_arg);\n\t}\n\n\trt->rt_space -= size;\n}\n\nvoid\nrange_tree_remove(void *arg, uint64_t start, uint64_t size)\n{\n\trange_tree_remove_impl(arg, start, size, B_FALSE);\n}\n\nvoid\nrange_tree_remove_fill(range_tree_t *rt, uint64_t start, uint64_t size)\n{\n\trange_tree_remove_impl(rt, start, size, B_TRUE);\n}\n\nvoid\nrange_tree_resize_segment(range_tree_t *rt, range_seg_t *rs,\n    uint64_t newstart, uint64_t newsize)\n{\n\tint64_t delta = newsize - (rs_get_end(rs, rt) - rs_get_start(rs, rt));\n\n\trange_tree_stat_decr(rt, rs);\n\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_remove != NULL)\n\t\trt->rt_ops->rtop_remove(rt, rs, rt->rt_arg);\n\n\trs_set_start(rs, rt, newstart);\n\trs_set_end(rs, rt, newstart + newsize);\n\n\trange_tree_stat_incr(rt, rs);\n\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_add != NULL)\n\t\trt->rt_ops->rtop_add(rt, rs, rt->rt_arg);\n\n\trt->rt_space += delta;\n}\n\nstatic range_seg_t *\nrange_tree_find_impl(range_tree_t *rt, uint64_t start, uint64_t size)\n{\n\trange_seg_max_t rsearch;\n\tuint64_t end = start + size;\n\n\tVERIFY(size != 0);\n\n\trs_set_start(&rsearch, rt, start);\n\trs_set_end(&rsearch, rt, end);\n\treturn (zfs_btree_find(&rt->rt_root, &rsearch, NULL));\n}\n\nrange_seg_t *\nrange_tree_find(range_tree_t *rt, uint64_t start, uint64_t size)\n{\n\tif (rt->rt_type == RANGE_SEG64)\n\t\tASSERT3U(start + size, >, start);\n\n\trange_seg_t *rs = range_tree_find_impl(rt, start, size);\n\tif (rs != NULL && rs_get_start(rs, rt) <= start &&\n\t    rs_get_end(rs, rt) >= start + size) {\n\t\treturn (rs);\n\t}\n\treturn (NULL);\n}\n\nvoid\nrange_tree_verify_not_present(range_tree_t *rt, uint64_t off, uint64_t size)\n{\n\trange_seg_t *rs = range_tree_find(rt, off, size);\n\tif (rs != NULL)\n\t\tpanic(\"segment already in tree; rs=%p\", (void *)rs);\n}\n\nboolean_t\nrange_tree_contains(range_tree_t *rt, uint64_t start, uint64_t size)\n{\n\treturn (range_tree_find(rt, start, size) != NULL);\n}\n\n \nboolean_t\nrange_tree_find_in(range_tree_t *rt, uint64_t start, uint64_t size,\n    uint64_t *ostart, uint64_t *osize)\n{\n\tif (rt->rt_type == RANGE_SEG64)\n\t\tASSERT3U(start + size, >, start);\n\n\trange_seg_max_t rsearch;\n\trs_set_start(&rsearch, rt, start);\n\trs_set_end_raw(&rsearch, rt, rs_get_start_raw(&rsearch, rt) + 1);\n\n\tzfs_btree_index_t where;\n\trange_seg_t *rs = zfs_btree_find(&rt->rt_root, &rsearch, &where);\n\tif (rs != NULL) {\n\t\t*ostart = start;\n\t\t*osize = MIN(size, rs_get_end(rs, rt) - start);\n\t\treturn (B_TRUE);\n\t}\n\n\trs = zfs_btree_next(&rt->rt_root, &where, &where);\n\tif (rs == NULL || rs_get_start(rs, rt) > start + size)\n\t\treturn (B_FALSE);\n\n\t*ostart = rs_get_start(rs, rt);\n\t*osize = MIN(start + size, rs_get_end(rs, rt)) -\n\t    rs_get_start(rs, rt);\n\treturn (B_TRUE);\n}\n\n \nvoid\nrange_tree_clear(range_tree_t *rt, uint64_t start, uint64_t size)\n{\n\trange_seg_t *rs;\n\n\tif (size == 0)\n\t\treturn;\n\n\tif (rt->rt_type == RANGE_SEG64)\n\t\tASSERT3U(start + size, >, start);\n\n\twhile ((rs = range_tree_find_impl(rt, start, size)) != NULL) {\n\t\tuint64_t free_start = MAX(rs_get_start(rs, rt), start);\n\t\tuint64_t free_end = MIN(rs_get_end(rs, rt), start + size);\n\t\trange_tree_remove(rt, free_start, free_end - free_start);\n\t}\n}\n\nvoid\nrange_tree_swap(range_tree_t **rtsrc, range_tree_t **rtdst)\n{\n\trange_tree_t *rt;\n\n\tASSERT0(range_tree_space(*rtdst));\n\tASSERT0(zfs_btree_numnodes(&(*rtdst)->rt_root));\n\n\trt = *rtsrc;\n\t*rtsrc = *rtdst;\n\t*rtdst = rt;\n}\n\nvoid\nrange_tree_vacate(range_tree_t *rt, range_tree_func_t *func, void *arg)\n{\n\tif (rt->rt_ops != NULL && rt->rt_ops->rtop_vacate != NULL)\n\t\trt->rt_ops->rtop_vacate(rt, rt->rt_arg);\n\n\tif (func != NULL) {\n\t\trange_seg_t *rs;\n\t\tzfs_btree_index_t *cookie = NULL;\n\n\t\twhile ((rs = zfs_btree_destroy_nodes(&rt->rt_root, &cookie)) !=\n\t\t    NULL) {\n\t\t\tfunc(arg, rs_get_start(rs, rt), rs_get_end(rs, rt) -\n\t\t\t    rs_get_start(rs, rt));\n\t\t}\n\t} else {\n\t\tzfs_btree_clear(&rt->rt_root);\n\t}\n\n\tmemset(rt->rt_histogram, 0, sizeof (rt->rt_histogram));\n\trt->rt_space = 0;\n}\n\nvoid\nrange_tree_walk(range_tree_t *rt, range_tree_func_t *func, void *arg)\n{\n\tzfs_btree_index_t where;\n\tfor (range_seg_t *rs = zfs_btree_first(&rt->rt_root, &where);\n\t    rs != NULL; rs = zfs_btree_next(&rt->rt_root, &where, &where)) {\n\t\tfunc(arg, rs_get_start(rs, rt), rs_get_end(rs, rt) -\n\t\t    rs_get_start(rs, rt));\n\t}\n}\n\nrange_seg_t *\nrange_tree_first(range_tree_t *rt)\n{\n\treturn (zfs_btree_first(&rt->rt_root, NULL));\n}\n\nuint64_t\nrange_tree_space(range_tree_t *rt)\n{\n\treturn (rt->rt_space);\n}\n\nuint64_t\nrange_tree_numsegs(range_tree_t *rt)\n{\n\treturn ((rt == NULL) ? 0 : zfs_btree_numnodes(&rt->rt_root));\n}\n\nboolean_t\nrange_tree_is_empty(range_tree_t *rt)\n{\n\tASSERT(rt != NULL);\n\treturn (range_tree_space(rt) == 0);\n}\n\n \nvoid\nrange_tree_remove_xor_add_segment(uint64_t start, uint64_t end,\n    range_tree_t *removefrom, range_tree_t *addto)\n{\n\tzfs_btree_index_t where;\n\trange_seg_max_t starting_rs;\n\trs_set_start(&starting_rs, removefrom, start);\n\trs_set_end_raw(&starting_rs, removefrom, rs_get_start_raw(&starting_rs,\n\t    removefrom) + 1);\n\n\trange_seg_t *curr = zfs_btree_find(&removefrom->rt_root,\n\t    &starting_rs, &where);\n\n\tif (curr == NULL)\n\t\tcurr = zfs_btree_next(&removefrom->rt_root, &where, &where);\n\n\trange_seg_t *next;\n\tfor (; curr != NULL; curr = next) {\n\t\tif (start == end)\n\t\t\treturn;\n\t\tVERIFY3U(start, <, end);\n\n\t\t \n\t\tif (end <= rs_get_start(curr, removefrom)) {\n\t\t\trange_tree_add(addto, start, end - start);\n\t\t\treturn;\n\t\t}\n\n\t\tuint64_t overlap_start = MAX(rs_get_start(curr, removefrom),\n\t\t    start);\n\t\tuint64_t overlap_end = MIN(rs_get_end(curr, removefrom),\n\t\t    end);\n\t\tuint64_t overlap_size = overlap_end - overlap_start;\n\t\tASSERT3S(overlap_size, >, 0);\n\t\trange_seg_max_t rs;\n\t\trs_copy(curr, &rs, removefrom);\n\n\t\trange_tree_remove(removefrom, overlap_start, overlap_size);\n\n\t\tif (start < overlap_start)\n\t\t\trange_tree_add(addto, start, overlap_start - start);\n\n\t\tstart = overlap_end;\n\t\tnext = zfs_btree_find(&removefrom->rt_root, &rs, &where);\n\t\t \n\t\tif (next != NULL) {\n\t\t\tASSERT(start == end || start == rs_get_end(&rs,\n\t\t\t    removefrom));\n\t\t}\n\n\t\tnext = zfs_btree_next(&removefrom->rt_root, &where, &where);\n\t}\n\tVERIFY3P(curr, ==, NULL);\n\n\tif (start != end) {\n\t\tVERIFY3U(start, <, end);\n\t\trange_tree_add(addto, start, end - start);\n\t} else {\n\t\tVERIFY3U(start, ==, end);\n\t}\n}\n\n \nvoid\nrange_tree_remove_xor_add(range_tree_t *rt, range_tree_t *removefrom,\n    range_tree_t *addto)\n{\n\tzfs_btree_index_t where;\n\tfor (range_seg_t *rs = zfs_btree_first(&rt->rt_root, &where); rs;\n\t    rs = zfs_btree_next(&rt->rt_root, &where, &where)) {\n\t\trange_tree_remove_xor_add_segment(rs_get_start(rs, rt),\n\t\t    rs_get_end(rs, rt), removefrom, addto);\n\t}\n}\n\nuint64_t\nrange_tree_min(range_tree_t *rt)\n{\n\trange_seg_t *rs = zfs_btree_first(&rt->rt_root, NULL);\n\treturn (rs != NULL ? rs_get_start(rs, rt) : 0);\n}\n\nuint64_t\nrange_tree_max(range_tree_t *rt)\n{\n\trange_seg_t *rs = zfs_btree_last(&rt->rt_root, NULL);\n\treturn (rs != NULL ? rs_get_end(rs, rt) : 0);\n}\n\nuint64_t\nrange_tree_span(range_tree_t *rt)\n{\n\treturn (range_tree_max(rt) - range_tree_min(rt));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}