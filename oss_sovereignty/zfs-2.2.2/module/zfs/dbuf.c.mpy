{
  "module_name": "dbuf.c",
  "hash_id": "39182b19bc7919a93cdbdb27b5a0994d11ca5905faa5c483029dc096d8666394",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/dbuf.c",
  "human_readable_source": " \n \n\n#include <sys/zfs_context.h>\n#include <sys/arc.h>\n#include <sys/dmu.h>\n#include <sys/dmu_send.h>\n#include <sys/dmu_impl.h>\n#include <sys/dbuf.h>\n#include <sys/dmu_objset.h>\n#include <sys/dsl_dataset.h>\n#include <sys/dsl_dir.h>\n#include <sys/dmu_tx.h>\n#include <sys/spa.h>\n#include <sys/zio.h>\n#include <sys/dmu_zfetch.h>\n#include <sys/sa.h>\n#include <sys/sa_impl.h>\n#include <sys/zfeature.h>\n#include <sys/blkptr.h>\n#include <sys/range_tree.h>\n#include <sys/trace_zfs.h>\n#include <sys/callb.h>\n#include <sys/abd.h>\n#include <sys/brt.h>\n#include <sys/vdev.h>\n#include <cityhash.h>\n#include <sys/spa_impl.h>\n#include <sys/wmsum.h>\n#include <sys/vdev_impl.h>\n\nstatic kstat_t *dbuf_ksp;\n\ntypedef struct dbuf_stats {\n\t \n\tkstat_named_t cache_count;\n\tkstat_named_t cache_size_bytes;\n\tkstat_named_t cache_size_bytes_max;\n\t \n\tkstat_named_t cache_target_bytes;\n\tkstat_named_t cache_lowater_bytes;\n\tkstat_named_t cache_hiwater_bytes;\n\t \n\tkstat_named_t cache_total_evicts;\n\t \n\tkstat_named_t cache_levels[DN_MAX_LEVELS];\n\tkstat_named_t cache_levels_bytes[DN_MAX_LEVELS];\n\t \n\tkstat_named_t hash_hits;\n\tkstat_named_t hash_misses;\n\tkstat_named_t hash_collisions;\n\tkstat_named_t hash_elements;\n\tkstat_named_t hash_elements_max;\n\t \n\tkstat_named_t hash_chains;\n\tkstat_named_t hash_chain_max;\n\t \n\tkstat_named_t hash_insert_race;\n\t \n\tkstat_named_t hash_table_count;\n\tkstat_named_t hash_mutex_count;\n\t \n\tkstat_named_t metadata_cache_count;\n\tkstat_named_t metadata_cache_size_bytes;\n\tkstat_named_t metadata_cache_size_bytes_max;\n\t \n\tkstat_named_t metadata_cache_overflow;\n} dbuf_stats_t;\n\ndbuf_stats_t dbuf_stats = {\n\t{ \"cache_count\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"cache_size_bytes\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"cache_size_bytes_max\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"cache_target_bytes\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"cache_lowater_bytes\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"cache_hiwater_bytes\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"cache_total_evicts\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ { \"cache_levels_N\",\t\t\tKSTAT_DATA_UINT64 } },\n\t{ { \"cache_levels_bytes_N\",\t\tKSTAT_DATA_UINT64 } },\n\t{ \"hash_hits\",\t\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"hash_misses\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"hash_collisions\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"hash_elements\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"hash_elements_max\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"hash_chains\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"hash_chain_max\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"hash_insert_race\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"hash_table_count\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"hash_mutex_count\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"metadata_cache_count\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"metadata_cache_size_bytes\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"metadata_cache_size_bytes_max\",\tKSTAT_DATA_UINT64 },\n\t{ \"metadata_cache_overflow\",\t\tKSTAT_DATA_UINT64 }\n};\n\nstruct {\n\twmsum_t cache_count;\n\twmsum_t cache_total_evicts;\n\twmsum_t cache_levels[DN_MAX_LEVELS];\n\twmsum_t cache_levels_bytes[DN_MAX_LEVELS];\n\twmsum_t hash_hits;\n\twmsum_t hash_misses;\n\twmsum_t hash_collisions;\n\twmsum_t hash_chains;\n\twmsum_t hash_insert_race;\n\twmsum_t metadata_cache_count;\n\twmsum_t metadata_cache_overflow;\n} dbuf_sums;\n\n#define\tDBUF_STAT_INCR(stat, val)\t\\\n\twmsum_add(&dbuf_sums.stat, val);\n#define\tDBUF_STAT_DECR(stat, val)\t\\\n\tDBUF_STAT_INCR(stat, -(val));\n#define\tDBUF_STAT_BUMP(stat)\t\t\\\n\tDBUF_STAT_INCR(stat, 1);\n#define\tDBUF_STAT_BUMPDOWN(stat)\t\\\n\tDBUF_STAT_INCR(stat, -1);\n#define\tDBUF_STAT_MAX(stat, v) {\t\t\t\t\t\\\n\tuint64_t _m;\t\t\t\t\t\t\t\\\n\twhile ((v) > (_m = dbuf_stats.stat.value.ui64) &&\t\t\\\n\t    (_m != atomic_cas_64(&dbuf_stats.stat.value.ui64, _m, (v))))\\\n\t\tcontinue;\t\t\t\t\t\t\\\n}\n\nstatic void dbuf_write(dbuf_dirty_record_t *dr, arc_buf_t *data, dmu_tx_t *tx);\nstatic void dbuf_sync_leaf_verify_bonus_dnode(dbuf_dirty_record_t *dr);\nstatic int dbuf_read_verify_dnode_crypt(dmu_buf_impl_t *db, uint32_t flags);\n\n \nstatic kmem_cache_t *dbuf_kmem_cache;\nstatic taskq_t *dbu_evict_taskq;\n\nstatic kthread_t *dbuf_cache_evict_thread;\nstatic kmutex_t dbuf_evict_lock;\nstatic kcondvar_t dbuf_evict_cv;\nstatic boolean_t dbuf_evict_thread_exit;\n\n \ntypedef struct dbuf_cache {\n\tmultilist_t cache;\n\tzfs_refcount_t size ____cacheline_aligned;\n} dbuf_cache_t;\ndbuf_cache_t dbuf_caches[DB_CACHE_MAX];\n\n \nstatic uint64_t dbuf_cache_max_bytes = UINT64_MAX;\nstatic uint64_t dbuf_metadata_cache_max_bytes = UINT64_MAX;\n\n \nstatic uint_t dbuf_cache_shift = 5;\nstatic uint_t dbuf_metadata_cache_shift = 6;\n\n \nstatic uint_t dbuf_mutex_cache_shift = 0;\n\nstatic unsigned long dbuf_cache_target_bytes(void);\nstatic unsigned long dbuf_metadata_cache_target_bytes(void);\n\n \n\n \nstatic uint_t dbuf_cache_hiwater_pct = 10;\nstatic uint_t dbuf_cache_lowater_pct = 10;\n\nstatic int\ndbuf_cons(void *vdb, void *unused, int kmflag)\n{\n\t(void) unused, (void) kmflag;\n\tdmu_buf_impl_t *db = vdb;\n\tmemset(db, 0, sizeof (dmu_buf_impl_t));\n\n\tmutex_init(&db->db_mtx, NULL, MUTEX_DEFAULT, NULL);\n\trw_init(&db->db_rwlock, NULL, RW_DEFAULT, NULL);\n\tcv_init(&db->db_changed, NULL, CV_DEFAULT, NULL);\n\tmultilist_link_init(&db->db_cache_link);\n\tzfs_refcount_create(&db->db_holds);\n\n\treturn (0);\n}\n\nstatic void\ndbuf_dest(void *vdb, void *unused)\n{\n\t(void) unused;\n\tdmu_buf_impl_t *db = vdb;\n\tmutex_destroy(&db->db_mtx);\n\trw_destroy(&db->db_rwlock);\n\tcv_destroy(&db->db_changed);\n\tASSERT(!multilist_link_active(&db->db_cache_link));\n\tzfs_refcount_destroy(&db->db_holds);\n}\n\n \nstatic dbuf_hash_table_t dbuf_hash_table;\n\n \nstatic uint64_t\ndbuf_hash(void *os, uint64_t obj, uint8_t lvl, uint64_t blkid)\n{\n\treturn (cityhash4((uintptr_t)os, obj, (uint64_t)lvl, blkid));\n}\n\n#define\tDTRACE_SET_STATE(db, why) \\\n\tDTRACE_PROBE2(dbuf__state_change, dmu_buf_impl_t *, db,\t\\\n\t    const char *, why)\n\n#define\tDBUF_EQUAL(dbuf, os, obj, level, blkid)\t\t\\\n\t((dbuf)->db.db_object == (obj) &&\t\t\\\n\t(dbuf)->db_objset == (os) &&\t\t\t\\\n\t(dbuf)->db_level == (level) &&\t\t\t\\\n\t(dbuf)->db_blkid == (blkid))\n\ndmu_buf_impl_t *\ndbuf_find(objset_t *os, uint64_t obj, uint8_t level, uint64_t blkid,\n    uint64_t *hash_out)\n{\n\tdbuf_hash_table_t *h = &dbuf_hash_table;\n\tuint64_t hv;\n\tuint64_t idx;\n\tdmu_buf_impl_t *db;\n\n\thv = dbuf_hash(os, obj, level, blkid);\n\tidx = hv & h->hash_table_mask;\n\n\tmutex_enter(DBUF_HASH_MUTEX(h, idx));\n\tfor (db = h->hash_table[idx]; db != NULL; db = db->db_hash_next) {\n\t\tif (DBUF_EQUAL(db, os, obj, level, blkid)) {\n\t\t\tmutex_enter(&db->db_mtx);\n\t\t\tif (db->db_state != DB_EVICTING) {\n\t\t\t\tmutex_exit(DBUF_HASH_MUTEX(h, idx));\n\t\t\t\treturn (db);\n\t\t\t}\n\t\t\tmutex_exit(&db->db_mtx);\n\t\t}\n\t}\n\tmutex_exit(DBUF_HASH_MUTEX(h, idx));\n\tif (hash_out != NULL)\n\t\t*hash_out = hv;\n\treturn (NULL);\n}\n\nstatic dmu_buf_impl_t *\ndbuf_find_bonus(objset_t *os, uint64_t object)\n{\n\tdnode_t *dn;\n\tdmu_buf_impl_t *db = NULL;\n\n\tif (dnode_hold(os, object, FTAG, &dn) == 0) {\n\t\trw_enter(&dn->dn_struct_rwlock, RW_READER);\n\t\tif (dn->dn_bonus != NULL) {\n\t\t\tdb = dn->dn_bonus;\n\t\t\tmutex_enter(&db->db_mtx);\n\t\t}\n\t\trw_exit(&dn->dn_struct_rwlock);\n\t\tdnode_rele(dn, FTAG);\n\t}\n\treturn (db);\n}\n\n \nstatic dmu_buf_impl_t *\ndbuf_hash_insert(dmu_buf_impl_t *db)\n{\n\tdbuf_hash_table_t *h = &dbuf_hash_table;\n\tobjset_t *os = db->db_objset;\n\tuint64_t obj = db->db.db_object;\n\tint level = db->db_level;\n\tuint64_t blkid, idx;\n\tdmu_buf_impl_t *dbf;\n\tuint32_t i;\n\n\tblkid = db->db_blkid;\n\tASSERT3U(dbuf_hash(os, obj, level, blkid), ==, db->db_hash);\n\tidx = db->db_hash & h->hash_table_mask;\n\n\tmutex_enter(DBUF_HASH_MUTEX(h, idx));\n\tfor (dbf = h->hash_table[idx], i = 0; dbf != NULL;\n\t    dbf = dbf->db_hash_next, i++) {\n\t\tif (DBUF_EQUAL(dbf, os, obj, level, blkid)) {\n\t\t\tmutex_enter(&dbf->db_mtx);\n\t\t\tif (dbf->db_state != DB_EVICTING) {\n\t\t\t\tmutex_exit(DBUF_HASH_MUTEX(h, idx));\n\t\t\t\treturn (dbf);\n\t\t\t}\n\t\t\tmutex_exit(&dbf->db_mtx);\n\t\t}\n\t}\n\n\tif (i > 0) {\n\t\tDBUF_STAT_BUMP(hash_collisions);\n\t\tif (i == 1)\n\t\t\tDBUF_STAT_BUMP(hash_chains);\n\n\t\tDBUF_STAT_MAX(hash_chain_max, i);\n\t}\n\n\tmutex_enter(&db->db_mtx);\n\tdb->db_hash_next = h->hash_table[idx];\n\th->hash_table[idx] = db;\n\tmutex_exit(DBUF_HASH_MUTEX(h, idx));\n\tuint64_t he = atomic_inc_64_nv(&dbuf_stats.hash_elements.value.ui64);\n\tDBUF_STAT_MAX(hash_elements_max, he);\n\n\treturn (NULL);\n}\n\n \nstatic boolean_t\ndbuf_include_in_metadata_cache(dmu_buf_impl_t *db)\n{\n\tDB_DNODE_ENTER(db);\n\tdmu_object_type_t type = DB_DNODE(db)->dn_type;\n\tDB_DNODE_EXIT(db);\n\n\t \n\tif (DMU_OT_IS_METADATA_CACHED(type)) {\n\t\t \n\t\tASSERT(DMU_OT_IS_METADATA(type));\n\n\t\t \n\t\tif (zfs_refcount_count(\n\t\t    &dbuf_caches[DB_DBUF_METADATA_CACHE].size) >\n\t\t    dbuf_metadata_cache_target_bytes()) {\n\t\t\tDBUF_STAT_BUMP(metadata_cache_overflow);\n\t\t\treturn (B_FALSE);\n\t\t}\n\n\t\treturn (B_TRUE);\n\t}\n\n\treturn (B_FALSE);\n}\n\n \nstatic void\ndbuf_hash_remove(dmu_buf_impl_t *db)\n{\n\tdbuf_hash_table_t *h = &dbuf_hash_table;\n\tuint64_t idx;\n\tdmu_buf_impl_t *dbf, **dbp;\n\n\tASSERT3U(dbuf_hash(db->db_objset, db->db.db_object, db->db_level,\n\t    db->db_blkid), ==, db->db_hash);\n\tidx = db->db_hash & h->hash_table_mask;\n\n\t \n\tASSERT(zfs_refcount_is_zero(&db->db_holds));\n\tASSERT(db->db_state == DB_EVICTING);\n\tASSERT(!MUTEX_HELD(&db->db_mtx));\n\n\tmutex_enter(DBUF_HASH_MUTEX(h, idx));\n\tdbp = &h->hash_table[idx];\n\twhile ((dbf = *dbp) != db) {\n\t\tdbp = &dbf->db_hash_next;\n\t\tASSERT(dbf != NULL);\n\t}\n\t*dbp = db->db_hash_next;\n\tdb->db_hash_next = NULL;\n\tif (h->hash_table[idx] &&\n\t    h->hash_table[idx]->db_hash_next == NULL)\n\t\tDBUF_STAT_BUMPDOWN(hash_chains);\n\tmutex_exit(DBUF_HASH_MUTEX(h, idx));\n\tatomic_dec_64(&dbuf_stats.hash_elements.value.ui64);\n}\n\ntypedef enum {\n\tDBVU_EVICTING,\n\tDBVU_NOT_EVICTING\n} dbvu_verify_type_t;\n\nstatic void\ndbuf_verify_user(dmu_buf_impl_t *db, dbvu_verify_type_t verify_type)\n{\n#ifdef ZFS_DEBUG\n\tint64_t holds;\n\n\tif (db->db_user == NULL)\n\t\treturn;\n\n\t \n\tASSERT(db->db_level == 0);\n\n\t \n\tASSERT(db->db.db_data != NULL);\n\tASSERT3U(db->db_state, ==, DB_CACHED);\n\n\tholds = zfs_refcount_count(&db->db_holds);\n\tif (verify_type == DBVU_EVICTING) {\n\t\t \n\t\tASSERT3U(holds, >=, db->db_dirtycnt);\n\t} else {\n\t\tif (db->db_user_immediate_evict == TRUE)\n\t\t\tASSERT3U(holds, >=, db->db_dirtycnt);\n\t\telse\n\t\t\tASSERT3U(holds, >, 0);\n\t}\n#endif\n}\n\nstatic void\ndbuf_evict_user(dmu_buf_impl_t *db)\n{\n\tdmu_buf_user_t *dbu = db->db_user;\n\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\n\tif (dbu == NULL)\n\t\treturn;\n\n\tdbuf_verify_user(db, DBVU_EVICTING);\n\tdb->db_user = NULL;\n\n#ifdef ZFS_DEBUG\n\tif (dbu->dbu_clear_on_evict_dbufp != NULL)\n\t\t*dbu->dbu_clear_on_evict_dbufp = NULL;\n#endif\n\n\t \n\tboolean_t has_async = (dbu->dbu_evict_func_async != NULL);\n\n\tif (dbu->dbu_evict_func_sync != NULL)\n\t\tdbu->dbu_evict_func_sync(dbu);\n\n\tif (has_async) {\n\t\ttaskq_dispatch_ent(dbu_evict_taskq, dbu->dbu_evict_func_async,\n\t\t    dbu, 0, &dbu->dbu_tqent);\n\t}\n}\n\nboolean_t\ndbuf_is_metadata(dmu_buf_impl_t *db)\n{\n\t \n\tif (db->db_level > 0 || db->db_blkid == DMU_SPILL_BLKID) {\n\t\treturn (B_TRUE);\n\t} else {\n\t\tboolean_t is_metadata;\n\n\t\tDB_DNODE_ENTER(db);\n\t\tis_metadata = DMU_OT_IS_METADATA(DB_DNODE(db)->dn_type);\n\t\tDB_DNODE_EXIT(db);\n\n\t\treturn (is_metadata);\n\t}\n}\n\n \nboolean_t\ndbuf_is_l2cacheable(dmu_buf_impl_t *db)\n{\n\tif (db->db_objset->os_secondary_cache == ZFS_CACHE_ALL ||\n\t    (db->db_objset->os_secondary_cache ==\n\t    ZFS_CACHE_METADATA && dbuf_is_metadata(db))) {\n\t\tif (l2arc_exclude_special == 0)\n\t\t\treturn (B_TRUE);\n\n\t\tblkptr_t *bp = db->db_blkptr;\n\t\tif (bp == NULL || BP_IS_HOLE(bp))\n\t\t\treturn (B_FALSE);\n\t\tuint64_t vdev = DVA_GET_VDEV(bp->blk_dva);\n\t\tvdev_t *rvd = db->db_objset->os_spa->spa_root_vdev;\n\t\tvdev_t *vd = NULL;\n\n\t\tif (vdev < rvd->vdev_children)\n\t\t\tvd = rvd->vdev_child[vdev];\n\n\t\tif (vd == NULL)\n\t\t\treturn (B_TRUE);\n\n\t\tif (vd->vdev_alloc_bias != VDEV_BIAS_SPECIAL &&\n\t\t    vd->vdev_alloc_bias != VDEV_BIAS_DEDUP)\n\t\t\treturn (B_TRUE);\n\t}\n\treturn (B_FALSE);\n}\n\nstatic inline boolean_t\ndnode_level_is_l2cacheable(blkptr_t *bp, dnode_t *dn, int64_t level)\n{\n\tif (dn->dn_objset->os_secondary_cache == ZFS_CACHE_ALL ||\n\t    (dn->dn_objset->os_secondary_cache == ZFS_CACHE_METADATA &&\n\t    (level > 0 ||\n\t    DMU_OT_IS_METADATA(dn->dn_handle->dnh_dnode->dn_type)))) {\n\t\tif (l2arc_exclude_special == 0)\n\t\t\treturn (B_TRUE);\n\n\t\tif (bp == NULL || BP_IS_HOLE(bp))\n\t\t\treturn (B_FALSE);\n\t\tuint64_t vdev = DVA_GET_VDEV(bp->blk_dva);\n\t\tvdev_t *rvd = dn->dn_objset->os_spa->spa_root_vdev;\n\t\tvdev_t *vd = NULL;\n\n\t\tif (vdev < rvd->vdev_children)\n\t\t\tvd = rvd->vdev_child[vdev];\n\n\t\tif (vd == NULL)\n\t\t\treturn (B_TRUE);\n\n\t\tif (vd->vdev_alloc_bias != VDEV_BIAS_SPECIAL &&\n\t\t    vd->vdev_alloc_bias != VDEV_BIAS_DEDUP)\n\t\t\treturn (B_TRUE);\n\t}\n\treturn (B_FALSE);\n}\n\n\n \nstatic unsigned int\ndbuf_cache_multilist_index_func(multilist_t *ml, void *obj)\n{\n\tdmu_buf_impl_t *db = obj;\n\n\t \n\treturn ((unsigned int)dbuf_hash(db->db_objset, db->db.db_object,\n\t    db->db_level, db->db_blkid) %\n\t    multilist_get_num_sublists(ml));\n}\n\n \nstatic inline unsigned long\ndbuf_cache_target_bytes(void)\n{\n\treturn (MIN(dbuf_cache_max_bytes,\n\t    arc_target_bytes() >> dbuf_cache_shift));\n}\n\n \nstatic inline unsigned long\ndbuf_metadata_cache_target_bytes(void)\n{\n\treturn (MIN(dbuf_metadata_cache_max_bytes,\n\t    arc_target_bytes() >> dbuf_metadata_cache_shift));\n}\n\nstatic inline uint64_t\ndbuf_cache_hiwater_bytes(void)\n{\n\tuint64_t dbuf_cache_target = dbuf_cache_target_bytes();\n\treturn (dbuf_cache_target +\n\t    (dbuf_cache_target * dbuf_cache_hiwater_pct) / 100);\n}\n\nstatic inline uint64_t\ndbuf_cache_lowater_bytes(void)\n{\n\tuint64_t dbuf_cache_target = dbuf_cache_target_bytes();\n\treturn (dbuf_cache_target -\n\t    (dbuf_cache_target * dbuf_cache_lowater_pct) / 100);\n}\n\nstatic inline boolean_t\ndbuf_cache_above_lowater(void)\n{\n\treturn (zfs_refcount_count(&dbuf_caches[DB_DBUF_CACHE].size) >\n\t    dbuf_cache_lowater_bytes());\n}\n\n \nstatic void\ndbuf_evict_one(void)\n{\n\tint idx = multilist_get_random_index(&dbuf_caches[DB_DBUF_CACHE].cache);\n\tmultilist_sublist_t *mls = multilist_sublist_lock(\n\t    &dbuf_caches[DB_DBUF_CACHE].cache, idx);\n\n\tASSERT(!MUTEX_HELD(&dbuf_evict_lock));\n\n\tdmu_buf_impl_t *db = multilist_sublist_tail(mls);\n\twhile (db != NULL && mutex_tryenter(&db->db_mtx) == 0) {\n\t\tdb = multilist_sublist_prev(mls, db);\n\t}\n\n\tDTRACE_PROBE2(dbuf__evict__one, dmu_buf_impl_t *, db,\n\t    multilist_sublist_t *, mls);\n\n\tif (db != NULL) {\n\t\tmultilist_sublist_remove(mls, db);\n\t\tmultilist_sublist_unlock(mls);\n\t\t(void) zfs_refcount_remove_many(\n\t\t    &dbuf_caches[DB_DBUF_CACHE].size, db->db.db_size, db);\n\t\tDBUF_STAT_BUMPDOWN(cache_levels[db->db_level]);\n\t\tDBUF_STAT_BUMPDOWN(cache_count);\n\t\tDBUF_STAT_DECR(cache_levels_bytes[db->db_level],\n\t\t    db->db.db_size);\n\t\tASSERT3U(db->db_caching_status, ==, DB_DBUF_CACHE);\n\t\tdb->db_caching_status = DB_NO_CACHE;\n\t\tdbuf_destroy(db);\n\t\tDBUF_STAT_BUMP(cache_total_evicts);\n\t} else {\n\t\tmultilist_sublist_unlock(mls);\n\t}\n}\n\n \nstatic __attribute__((noreturn)) void\ndbuf_evict_thread(void *unused)\n{\n\t(void) unused;\n\tcallb_cpr_t cpr;\n\n\tCALLB_CPR_INIT(&cpr, &dbuf_evict_lock, callb_generic_cpr, FTAG);\n\n\tmutex_enter(&dbuf_evict_lock);\n\twhile (!dbuf_evict_thread_exit) {\n\t\twhile (!dbuf_cache_above_lowater() && !dbuf_evict_thread_exit) {\n\t\t\tCALLB_CPR_SAFE_BEGIN(&cpr);\n\t\t\t(void) cv_timedwait_idle_hires(&dbuf_evict_cv,\n\t\t\t    &dbuf_evict_lock, SEC2NSEC(1), MSEC2NSEC(1), 0);\n\t\t\tCALLB_CPR_SAFE_END(&cpr, &dbuf_evict_lock);\n\t\t}\n\t\tmutex_exit(&dbuf_evict_lock);\n\n\t\t \n\t\twhile (dbuf_cache_above_lowater() && !dbuf_evict_thread_exit) {\n\t\t\tdbuf_evict_one();\n\t\t}\n\n\t\tmutex_enter(&dbuf_evict_lock);\n\t}\n\n\tdbuf_evict_thread_exit = B_FALSE;\n\tcv_broadcast(&dbuf_evict_cv);\n\tCALLB_CPR_EXIT(&cpr);\t \n\tthread_exit();\n}\n\n \nstatic void\ndbuf_evict_notify(uint64_t size)\n{\n\t \n\tif (size > dbuf_cache_target_bytes()) {\n\t\tif (size > dbuf_cache_hiwater_bytes())\n\t\t\tdbuf_evict_one();\n\t\tcv_signal(&dbuf_evict_cv);\n\t}\n}\n\nstatic int\ndbuf_kstat_update(kstat_t *ksp, int rw)\n{\n\tdbuf_stats_t *ds = ksp->ks_data;\n\tdbuf_hash_table_t *h = &dbuf_hash_table;\n\n\tif (rw == KSTAT_WRITE)\n\t\treturn (SET_ERROR(EACCES));\n\n\tds->cache_count.value.ui64 =\n\t    wmsum_value(&dbuf_sums.cache_count);\n\tds->cache_size_bytes.value.ui64 =\n\t    zfs_refcount_count(&dbuf_caches[DB_DBUF_CACHE].size);\n\tds->cache_target_bytes.value.ui64 = dbuf_cache_target_bytes();\n\tds->cache_hiwater_bytes.value.ui64 = dbuf_cache_hiwater_bytes();\n\tds->cache_lowater_bytes.value.ui64 = dbuf_cache_lowater_bytes();\n\tds->cache_total_evicts.value.ui64 =\n\t    wmsum_value(&dbuf_sums.cache_total_evicts);\n\tfor (int i = 0; i < DN_MAX_LEVELS; i++) {\n\t\tds->cache_levels[i].value.ui64 =\n\t\t    wmsum_value(&dbuf_sums.cache_levels[i]);\n\t\tds->cache_levels_bytes[i].value.ui64 =\n\t\t    wmsum_value(&dbuf_sums.cache_levels_bytes[i]);\n\t}\n\tds->hash_hits.value.ui64 =\n\t    wmsum_value(&dbuf_sums.hash_hits);\n\tds->hash_misses.value.ui64 =\n\t    wmsum_value(&dbuf_sums.hash_misses);\n\tds->hash_collisions.value.ui64 =\n\t    wmsum_value(&dbuf_sums.hash_collisions);\n\tds->hash_chains.value.ui64 =\n\t    wmsum_value(&dbuf_sums.hash_chains);\n\tds->hash_insert_race.value.ui64 =\n\t    wmsum_value(&dbuf_sums.hash_insert_race);\n\tds->hash_table_count.value.ui64 = h->hash_table_mask + 1;\n\tds->hash_mutex_count.value.ui64 = h->hash_mutex_mask + 1;\n\tds->metadata_cache_count.value.ui64 =\n\t    wmsum_value(&dbuf_sums.metadata_cache_count);\n\tds->metadata_cache_size_bytes.value.ui64 = zfs_refcount_count(\n\t    &dbuf_caches[DB_DBUF_METADATA_CACHE].size);\n\tds->metadata_cache_overflow.value.ui64 =\n\t    wmsum_value(&dbuf_sums.metadata_cache_overflow);\n\treturn (0);\n}\n\nvoid\ndbuf_init(void)\n{\n\tuint64_t hmsize, hsize = 1ULL << 16;\n\tdbuf_hash_table_t *h = &dbuf_hash_table;\n\n\t \n\twhile (hsize * zfs_arc_average_blocksize < arc_all_memory() / 8)\n\t\thsize <<= 1;\n\n\th->hash_table = NULL;\n\twhile (h->hash_table == NULL) {\n\t\th->hash_table_mask = hsize - 1;\n\n\t\th->hash_table = vmem_zalloc(hsize * sizeof (void *), KM_SLEEP);\n\t\tif (h->hash_table == NULL)\n\t\t\thsize >>= 1;\n\n\t\tASSERT3U(hsize, >=, 1ULL << 10);\n\t}\n\n\t \n\tif (dbuf_mutex_cache_shift == 0)\n\t\thmsize = MAX(hsize >> 7, 1ULL << 13);\n\telse\n\t\thmsize = 1ULL << MIN(dbuf_mutex_cache_shift, 24);\n\n\th->hash_mutexes = NULL;\n\twhile (h->hash_mutexes == NULL) {\n\t\th->hash_mutex_mask = hmsize - 1;\n\n\t\th->hash_mutexes = vmem_zalloc(hmsize * sizeof (kmutex_t),\n\t\t    KM_SLEEP);\n\t\tif (h->hash_mutexes == NULL)\n\t\t\thmsize >>= 1;\n\t}\n\n\tdbuf_kmem_cache = kmem_cache_create(\"dmu_buf_impl_t\",\n\t    sizeof (dmu_buf_impl_t),\n\t    0, dbuf_cons, dbuf_dest, NULL, NULL, NULL, 0);\n\n\tfor (int i = 0; i < hmsize; i++)\n\t\tmutex_init(&h->hash_mutexes[i], NULL, MUTEX_DEFAULT, NULL);\n\n\tdbuf_stats_init(h);\n\n\t \n\tdbu_evict_taskq = taskq_create(\"dbu_evict\", 1, defclsyspri, 0, 0, 0);\n\n\tfor (dbuf_cached_state_t dcs = 0; dcs < DB_CACHE_MAX; dcs++) {\n\t\tmultilist_create(&dbuf_caches[dcs].cache,\n\t\t    sizeof (dmu_buf_impl_t),\n\t\t    offsetof(dmu_buf_impl_t, db_cache_link),\n\t\t    dbuf_cache_multilist_index_func);\n\t\tzfs_refcount_create(&dbuf_caches[dcs].size);\n\t}\n\n\tdbuf_evict_thread_exit = B_FALSE;\n\tmutex_init(&dbuf_evict_lock, NULL, MUTEX_DEFAULT, NULL);\n\tcv_init(&dbuf_evict_cv, NULL, CV_DEFAULT, NULL);\n\tdbuf_cache_evict_thread = thread_create(NULL, 0, dbuf_evict_thread,\n\t    NULL, 0, &p0, TS_RUN, minclsyspri);\n\n\twmsum_init(&dbuf_sums.cache_count, 0);\n\twmsum_init(&dbuf_sums.cache_total_evicts, 0);\n\tfor (int i = 0; i < DN_MAX_LEVELS; i++) {\n\t\twmsum_init(&dbuf_sums.cache_levels[i], 0);\n\t\twmsum_init(&dbuf_sums.cache_levels_bytes[i], 0);\n\t}\n\twmsum_init(&dbuf_sums.hash_hits, 0);\n\twmsum_init(&dbuf_sums.hash_misses, 0);\n\twmsum_init(&dbuf_sums.hash_collisions, 0);\n\twmsum_init(&dbuf_sums.hash_chains, 0);\n\twmsum_init(&dbuf_sums.hash_insert_race, 0);\n\twmsum_init(&dbuf_sums.metadata_cache_count, 0);\n\twmsum_init(&dbuf_sums.metadata_cache_overflow, 0);\n\n\tdbuf_ksp = kstat_create(\"zfs\", 0, \"dbufstats\", \"misc\",\n\t    KSTAT_TYPE_NAMED, sizeof (dbuf_stats) / sizeof (kstat_named_t),\n\t    KSTAT_FLAG_VIRTUAL);\n\tif (dbuf_ksp != NULL) {\n\t\tfor (int i = 0; i < DN_MAX_LEVELS; i++) {\n\t\t\tsnprintf(dbuf_stats.cache_levels[i].name,\n\t\t\t    KSTAT_STRLEN, \"cache_level_%d\", i);\n\t\t\tdbuf_stats.cache_levels[i].data_type =\n\t\t\t    KSTAT_DATA_UINT64;\n\t\t\tsnprintf(dbuf_stats.cache_levels_bytes[i].name,\n\t\t\t    KSTAT_STRLEN, \"cache_level_%d_bytes\", i);\n\t\t\tdbuf_stats.cache_levels_bytes[i].data_type =\n\t\t\t    KSTAT_DATA_UINT64;\n\t\t}\n\t\tdbuf_ksp->ks_data = &dbuf_stats;\n\t\tdbuf_ksp->ks_update = dbuf_kstat_update;\n\t\tkstat_install(dbuf_ksp);\n\t}\n}\n\nvoid\ndbuf_fini(void)\n{\n\tdbuf_hash_table_t *h = &dbuf_hash_table;\n\n\tdbuf_stats_destroy();\n\n\tfor (int i = 0; i < (h->hash_mutex_mask + 1); i++)\n\t\tmutex_destroy(&h->hash_mutexes[i]);\n\n\tvmem_free(h->hash_table, (h->hash_table_mask + 1) * sizeof (void *));\n\tvmem_free(h->hash_mutexes, (h->hash_mutex_mask + 1) *\n\t    sizeof (kmutex_t));\n\n\tkmem_cache_destroy(dbuf_kmem_cache);\n\ttaskq_destroy(dbu_evict_taskq);\n\n\tmutex_enter(&dbuf_evict_lock);\n\tdbuf_evict_thread_exit = B_TRUE;\n\twhile (dbuf_evict_thread_exit) {\n\t\tcv_signal(&dbuf_evict_cv);\n\t\tcv_wait(&dbuf_evict_cv, &dbuf_evict_lock);\n\t}\n\tmutex_exit(&dbuf_evict_lock);\n\n\tmutex_destroy(&dbuf_evict_lock);\n\tcv_destroy(&dbuf_evict_cv);\n\n\tfor (dbuf_cached_state_t dcs = 0; dcs < DB_CACHE_MAX; dcs++) {\n\t\tzfs_refcount_destroy(&dbuf_caches[dcs].size);\n\t\tmultilist_destroy(&dbuf_caches[dcs].cache);\n\t}\n\n\tif (dbuf_ksp != NULL) {\n\t\tkstat_delete(dbuf_ksp);\n\t\tdbuf_ksp = NULL;\n\t}\n\n\twmsum_fini(&dbuf_sums.cache_count);\n\twmsum_fini(&dbuf_sums.cache_total_evicts);\n\tfor (int i = 0; i < DN_MAX_LEVELS; i++) {\n\t\twmsum_fini(&dbuf_sums.cache_levels[i]);\n\t\twmsum_fini(&dbuf_sums.cache_levels_bytes[i]);\n\t}\n\twmsum_fini(&dbuf_sums.hash_hits);\n\twmsum_fini(&dbuf_sums.hash_misses);\n\twmsum_fini(&dbuf_sums.hash_collisions);\n\twmsum_fini(&dbuf_sums.hash_chains);\n\twmsum_fini(&dbuf_sums.hash_insert_race);\n\twmsum_fini(&dbuf_sums.metadata_cache_count);\n\twmsum_fini(&dbuf_sums.metadata_cache_overflow);\n}\n\n \n\n#ifdef ZFS_DEBUG\nstatic void\ndbuf_verify(dmu_buf_impl_t *db)\n{\n\tdnode_t *dn;\n\tdbuf_dirty_record_t *dr;\n\tuint32_t txg_prev;\n\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\n\tif (!(zfs_flags & ZFS_DEBUG_DBUF_VERIFY))\n\t\treturn;\n\n\tASSERT(db->db_objset != NULL);\n\tDB_DNODE_ENTER(db);\n\tdn = DB_DNODE(db);\n\tif (dn == NULL) {\n\t\tASSERT(db->db_parent == NULL);\n\t\tASSERT(db->db_blkptr == NULL);\n\t} else {\n\t\tASSERT3U(db->db.db_object, ==, dn->dn_object);\n\t\tASSERT3P(db->db_objset, ==, dn->dn_objset);\n\t\tASSERT3U(db->db_level, <, dn->dn_nlevels);\n\t\tASSERT(db->db_blkid == DMU_BONUS_BLKID ||\n\t\t    db->db_blkid == DMU_SPILL_BLKID ||\n\t\t    !avl_is_empty(&dn->dn_dbufs));\n\t}\n\tif (db->db_blkid == DMU_BONUS_BLKID) {\n\t\tASSERT(dn != NULL);\n\t\tASSERT3U(db->db.db_size, >=, dn->dn_bonuslen);\n\t\tASSERT3U(db->db.db_offset, ==, DMU_BONUS_BLKID);\n\t} else if (db->db_blkid == DMU_SPILL_BLKID) {\n\t\tASSERT(dn != NULL);\n\t\tASSERT0(db->db.db_offset);\n\t} else {\n\t\tASSERT3U(db->db.db_offset, ==, db->db_blkid * db->db.db_size);\n\t}\n\n\tif ((dr = list_head(&db->db_dirty_records)) != NULL) {\n\t\tASSERT(dr->dr_dbuf == db);\n\t\ttxg_prev = dr->dr_txg;\n\t\tfor (dr = list_next(&db->db_dirty_records, dr); dr != NULL;\n\t\t    dr = list_next(&db->db_dirty_records, dr)) {\n\t\t\tASSERT(dr->dr_dbuf == db);\n\t\t\tASSERT(txg_prev > dr->dr_txg);\n\t\t\ttxg_prev = dr->dr_txg;\n\t\t}\n\t}\n\n\t \n\tif (db->db_level == 0 && db->db.db_object == DMU_META_DNODE_OBJECT) {\n\t\tdr = db->db_data_pending;\n\t\t \n\t\tASSERT(dr == NULL || dr->dt.dl.dr_data == db->db_buf);\n\t}\n\n\t \n\tif (db->db_blkptr) {\n\t\tif (db->db_parent == dn->dn_dbuf) {\n\t\t\t \n\t\t\t \n\t\t\tif (DMU_OBJECT_IS_SPECIAL(db->db.db_object))\n\t\t\t\tASSERT(db->db_parent == NULL);\n\t\t\telse\n\t\t\t\tASSERT(db->db_parent != NULL);\n\t\t\tif (db->db_blkid != DMU_SPILL_BLKID)\n\t\t\t\tASSERT3P(db->db_blkptr, ==,\n\t\t\t\t    &dn->dn_phys->dn_blkptr[db->db_blkid]);\n\t\t} else {\n\t\t\t \n\t\t\tint epb __maybe_unused = db->db_parent->db.db_size >>\n\t\t\t    SPA_BLKPTRSHIFT;\n\t\t\tASSERT3U(db->db_parent->db_level, ==, db->db_level+1);\n\t\t\tASSERT3U(db->db_parent->db.db_object, ==,\n\t\t\t    db->db.db_object);\n\t\t\t \n\t\t\tif (RW_LOCK_HELD(&db->db_parent->db_rwlock)) {\n\t\t\t\tASSERT3P(db->db_blkptr, ==,\n\t\t\t\t    ((blkptr_t *)db->db_parent->db.db_data +\n\t\t\t\t    db->db_blkid % epb));\n\t\t\t}\n\t\t}\n\t}\n\tif ((db->db_blkptr == NULL || BP_IS_HOLE(db->db_blkptr)) &&\n\t    (db->db_buf == NULL || db->db_buf->b_data) &&\n\t    db->db.db_data && db->db_blkid != DMU_BONUS_BLKID &&\n\t    db->db_state != DB_FILL && (dn == NULL || !dn->dn_free_txg)) {\n\t\t \n\t\tif (db->db_dirtycnt == 0) {\n\t\t\tif (db->db_level == 0) {\n\t\t\t\tuint64_t *buf = db->db.db_data;\n\t\t\t\tint i;\n\n\t\t\t\tfor (i = 0; i < db->db.db_size >> 3; i++) {\n\t\t\t\t\tASSERT(buf[i] == 0);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tblkptr_t *bps = db->db.db_data;\n\t\t\t\tASSERT3U(1 << DB_DNODE(db)->dn_indblkshift, ==,\n\t\t\t\t    db->db.db_size);\n\t\t\t\t \n\t\t\t\tfor (int i = 0;\n\t\t\t\t    i < db->db.db_size / sizeof (blkptr_t);\n\t\t\t\t    i++) {\n\t\t\t\t\tblkptr_t *bp = &bps[i];\n\t\t\t\t\tASSERT(ZIO_CHECKSUM_IS_ZERO(\n\t\t\t\t\t    &bp->blk_cksum));\n\t\t\t\t\tASSERT(\n\t\t\t\t\t    DVA_IS_EMPTY(&bp->blk_dva[0]) &&\n\t\t\t\t\t    DVA_IS_EMPTY(&bp->blk_dva[1]) &&\n\t\t\t\t\t    DVA_IS_EMPTY(&bp->blk_dva[2]));\n\t\t\t\t\tASSERT0(bp->blk_fill);\n\t\t\t\t\tASSERT0(bp->blk_pad[0]);\n\t\t\t\t\tASSERT0(bp->blk_pad[1]);\n\t\t\t\t\tASSERT(!BP_IS_EMBEDDED(bp));\n\t\t\t\t\tASSERT(BP_IS_HOLE(bp));\n\t\t\t\t\tASSERT0(bp->blk_phys_birth);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tDB_DNODE_EXIT(db);\n}\n#endif\n\nstatic void\ndbuf_clear_data(dmu_buf_impl_t *db)\n{\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\tdbuf_evict_user(db);\n\tASSERT3P(db->db_buf, ==, NULL);\n\tdb->db.db_data = NULL;\n\tif (db->db_state != DB_NOFILL) {\n\t\tdb->db_state = DB_UNCACHED;\n\t\tDTRACE_SET_STATE(db, \"clear data\");\n\t}\n}\n\nstatic void\ndbuf_set_data(dmu_buf_impl_t *db, arc_buf_t *buf)\n{\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\tASSERT(buf != NULL);\n\n\tdb->db_buf = buf;\n\tASSERT(buf->b_data != NULL);\n\tdb->db.db_data = buf->b_data;\n}\n\nstatic arc_buf_t *\ndbuf_alloc_arcbuf(dmu_buf_impl_t *db)\n{\n\tspa_t *spa = db->db_objset->os_spa;\n\n\treturn (arc_alloc_buf(spa, db, DBUF_GET_BUFC_TYPE(db), db->db.db_size));\n}\n\n \narc_buf_t *\ndbuf_loan_arcbuf(dmu_buf_impl_t *db)\n{\n\tarc_buf_t *abuf;\n\n\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\tmutex_enter(&db->db_mtx);\n\tif (arc_released(db->db_buf) || zfs_refcount_count(&db->db_holds) > 1) {\n\t\tint blksz = db->db.db_size;\n\t\tspa_t *spa = db->db_objset->os_spa;\n\n\t\tmutex_exit(&db->db_mtx);\n\t\tabuf = arc_loan_buf(spa, B_FALSE, blksz);\n\t\tmemcpy(abuf->b_data, db->db.db_data, blksz);\n\t} else {\n\t\tabuf = db->db_buf;\n\t\tarc_loan_inuse_buf(abuf, db);\n\t\tdb->db_buf = NULL;\n\t\tdbuf_clear_data(db);\n\t\tmutex_exit(&db->db_mtx);\n\t}\n\treturn (abuf);\n}\n\n \nuint64_t\ndbuf_whichblock(const dnode_t *dn, const int64_t level, const uint64_t offset)\n{\n\tif (dn->dn_datablkshift != 0 && dn->dn_indblkshift != 0) {\n\t\t \n\n\t\tconst unsigned exp = dn->dn_datablkshift +\n\t\t    level * (dn->dn_indblkshift - SPA_BLKPTRSHIFT);\n\n\t\tif (exp >= 8 * sizeof (offset)) {\n\t\t\t \n\t\t\tASSERT3U(level, ==, dn->dn_nlevels - 1);\n\t\t\treturn (0);\n\t\t}\n\n\t\tASSERT3U(exp, <, 8 * sizeof (offset));\n\n\t\treturn (offset >> exp);\n\t} else {\n\t\tASSERT3U(offset, <, dn->dn_datablksz);\n\t\treturn (0);\n\t}\n}\n\n \ndb_lock_type_t\ndmu_buf_lock_parent(dmu_buf_impl_t *db, krw_t rw, const void *tag)\n{\n\tenum db_lock_type ret = DLT_NONE;\n\tif (db->db_parent != NULL) {\n\t\trw_enter(&db->db_parent->db_rwlock, rw);\n\t\tret = DLT_PARENT;\n\t} else if (dmu_objset_ds(db->db_objset) != NULL) {\n\t\trrw_enter(&dmu_objset_ds(db->db_objset)->ds_bp_rwlock, rw,\n\t\t    tag);\n\t\tret = DLT_OBJSET;\n\t}\n\t \n\treturn (ret);\n}\n\n \nvoid\ndmu_buf_unlock_parent(dmu_buf_impl_t *db, db_lock_type_t type, const void *tag)\n{\n\tif (type == DLT_PARENT)\n\t\trw_exit(&db->db_parent->db_rwlock);\n\telse if (type == DLT_OBJSET)\n\t\trrw_exit(&dmu_objset_ds(db->db_objset)->ds_bp_rwlock, tag);\n}\n\nstatic void\ndbuf_read_done(zio_t *zio, const zbookmark_phys_t *zb, const blkptr_t *bp,\n    arc_buf_t *buf, void *vdb)\n{\n\t(void) zb, (void) bp;\n\tdmu_buf_impl_t *db = vdb;\n\n\tmutex_enter(&db->db_mtx);\n\tASSERT3U(db->db_state, ==, DB_READ);\n\t \n\tASSERT(zfs_refcount_count(&db->db_holds) > 0);\n\tASSERT(db->db_buf == NULL);\n\tASSERT(db->db.db_data == NULL);\n\tif (buf == NULL) {\n\t\t \n\t\tASSERT(zio == NULL || zio->io_error != 0);\n\t\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\t\tASSERT3P(db->db_buf, ==, NULL);\n\t\tdb->db_state = DB_UNCACHED;\n\t\tDTRACE_SET_STATE(db, \"i/o error\");\n\t} else if (db->db_level == 0 && db->db_freed_in_flight) {\n\t\t \n\t\tASSERT(zio == NULL || zio->io_error == 0);\n\t\tarc_release(buf, db);\n\t\tmemset(buf->b_data, 0, db->db.db_size);\n\t\tarc_buf_freeze(buf);\n\t\tdb->db_freed_in_flight = FALSE;\n\t\tdbuf_set_data(db, buf);\n\t\tdb->db_state = DB_CACHED;\n\t\tDTRACE_SET_STATE(db, \"freed in flight\");\n\t} else {\n\t\t \n\t\tASSERT(zio == NULL || zio->io_error == 0);\n\t\tdbuf_set_data(db, buf);\n\t\tdb->db_state = DB_CACHED;\n\t\tDTRACE_SET_STATE(db, \"successful read\");\n\t}\n\tcv_broadcast(&db->db_changed);\n\tdbuf_rele_and_unlock(db, NULL, B_FALSE);\n}\n\n \nstatic int\ndbuf_read_bonus(dmu_buf_impl_t *db, dnode_t *dn, uint32_t flags)\n{\n\tint bonuslen, max_bonuslen, err;\n\n\terr = dbuf_read_verify_dnode_crypt(db, flags);\n\tif (err)\n\t\treturn (err);\n\n\tbonuslen = MIN(dn->dn_bonuslen, dn->dn_phys->dn_bonuslen);\n\tmax_bonuslen = DN_SLOTS_TO_BONUSLEN(dn->dn_num_slots);\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\tASSERT(DB_DNODE_HELD(db));\n\tASSERT3U(bonuslen, <=, db->db.db_size);\n\tdb->db.db_data = kmem_alloc(max_bonuslen, KM_SLEEP);\n\tarc_space_consume(max_bonuslen, ARC_SPACE_BONUS);\n\tif (bonuslen < max_bonuslen)\n\t\tmemset(db->db.db_data, 0, max_bonuslen);\n\tif (bonuslen)\n\t\tmemcpy(db->db.db_data, DN_BONUS(dn->dn_phys), bonuslen);\n\tdb->db_state = DB_CACHED;\n\tDTRACE_SET_STATE(db, \"bonus buffer filled\");\n\treturn (0);\n}\n\nstatic void\ndbuf_handle_indirect_hole(dmu_buf_impl_t *db, dnode_t *dn, blkptr_t *dbbp)\n{\n\tblkptr_t *bps = db->db.db_data;\n\tuint32_t indbs = 1ULL << dn->dn_indblkshift;\n\tint n_bps = indbs >> SPA_BLKPTRSHIFT;\n\n\tfor (int i = 0; i < n_bps; i++) {\n\t\tblkptr_t *bp = &bps[i];\n\n\t\tASSERT3U(BP_GET_LSIZE(dbbp), ==, indbs);\n\t\tBP_SET_LSIZE(bp, BP_GET_LEVEL(dbbp) == 1 ?\n\t\t    dn->dn_datablksz : BP_GET_LSIZE(dbbp));\n\t\tBP_SET_TYPE(bp, BP_GET_TYPE(dbbp));\n\t\tBP_SET_LEVEL(bp, BP_GET_LEVEL(dbbp) - 1);\n\t\tBP_SET_BIRTH(bp, dbbp->blk_birth, 0);\n\t}\n}\n\n \nstatic int\ndbuf_read_hole(dmu_buf_impl_t *db, dnode_t *dn, blkptr_t *bp)\n{\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\n\tint is_hole = bp == NULL || BP_IS_HOLE(bp);\n\t \n\tif (!is_hole && db->db_level == 0)\n\t\tis_hole = dnode_block_freed(dn, db->db_blkid) || BP_IS_HOLE(bp);\n\n\tif (is_hole) {\n\t\tdbuf_set_data(db, dbuf_alloc_arcbuf(db));\n\t\tmemset(db->db.db_data, 0, db->db.db_size);\n\n\t\tif (bp != NULL && db->db_level > 0 && BP_IS_HOLE(bp) &&\n\t\t    bp->blk_birth != 0) {\n\t\t\tdbuf_handle_indirect_hole(db, dn, bp);\n\t\t}\n\t\tdb->db_state = DB_CACHED;\n\t\tDTRACE_SET_STATE(db, \"hole read satisfied\");\n\t\treturn (0);\n\t}\n\treturn (ENOENT);\n}\n\n \nstatic int\ndbuf_read_verify_dnode_crypt(dmu_buf_impl_t *db, uint32_t flags)\n{\n\tint err = 0;\n\tobjset_t *os = db->db_objset;\n\tarc_buf_t *dnode_abuf;\n\tdnode_t *dn;\n\tzbookmark_phys_t zb;\n\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\n\tif ((flags & DB_RF_NO_DECRYPT) != 0 ||\n\t    !os->os_encrypted || os->os_raw_receive)\n\t\treturn (0);\n\n\tDB_DNODE_ENTER(db);\n\tdn = DB_DNODE(db);\n\tdnode_abuf = (dn->dn_dbuf != NULL) ? dn->dn_dbuf->db_buf : NULL;\n\n\tif (dnode_abuf == NULL || !arc_is_encrypted(dnode_abuf)) {\n\t\tDB_DNODE_EXIT(db);\n\t\treturn (0);\n\t}\n\n\tSET_BOOKMARK(&zb, dmu_objset_id(os),\n\t    DMU_META_DNODE_OBJECT, 0, dn->dn_dbuf->db_blkid);\n\terr = arc_untransform(dnode_abuf, os->os_spa, &zb, B_TRUE);\n\n\t \n\tif (err == EACCES && ((db->db_blkid != DMU_BONUS_BLKID &&\n\t    !DMU_OT_IS_ENCRYPTED(dn->dn_type)) ||\n\t    (db->db_blkid == DMU_BONUS_BLKID &&\n\t    !DMU_OT_IS_ENCRYPTED(dn->dn_bonustype))))\n\t\terr = 0;\n\n\tDB_DNODE_EXIT(db);\n\n\treturn (err);\n}\n\n \nstatic int\ndbuf_read_impl(dmu_buf_impl_t *db, zio_t *zio, uint32_t flags,\n    db_lock_type_t dblt, const void *tag)\n{\n\tdnode_t *dn;\n\tzbookmark_phys_t zb;\n\tuint32_t aflags = ARC_FLAG_NOWAIT;\n\tint err, zio_flags;\n\tblkptr_t bp, *bpp;\n\n\tDB_DNODE_ENTER(db);\n\tdn = DB_DNODE(db);\n\tASSERT(!zfs_refcount_is_zero(&db->db_holds));\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\tASSERT(db->db_state == DB_UNCACHED || db->db_state == DB_NOFILL);\n\tASSERT(db->db_buf == NULL);\n\tASSERT(db->db_parent == NULL ||\n\t    RW_LOCK_HELD(&db->db_parent->db_rwlock));\n\n\tif (db->db_blkid == DMU_BONUS_BLKID) {\n\t\terr = dbuf_read_bonus(db, dn, flags);\n\t\tgoto early_unlock;\n\t}\n\n\tif (db->db_state == DB_UNCACHED) {\n\t\tif (db->db_blkptr == NULL) {\n\t\t\tbpp = NULL;\n\t\t} else {\n\t\t\tbp = *db->db_blkptr;\n\t\t\tbpp = &bp;\n\t\t}\n\t} else {\n\t\tdbuf_dirty_record_t *dr;\n\n\t\tASSERT3S(db->db_state, ==, DB_NOFILL);\n\n\t\t \n\t\tdr = list_head(&db->db_dirty_records);\n\t\tif (dr == NULL || !dr->dt.dl.dr_brtwrite) {\n\t\t\terr = EIO;\n\t\t\tgoto early_unlock;\n\t\t}\n\t\tbp = dr->dt.dl.dr_overridden_by;\n\t\tbpp = &bp;\n\t}\n\n\terr = dbuf_read_hole(db, dn, bpp);\n\tif (err == 0)\n\t\tgoto early_unlock;\n\n\tASSERT(bpp != NULL);\n\n\t \n\tif (BP_IS_REDACTED(bpp)) {\n\t\tASSERT(dsl_dataset_feature_is_active(\n\t\t    db->db_objset->os_dsl_dataset,\n\t\t    SPA_FEATURE_REDACTED_DATASETS));\n\t\terr = SET_ERROR(EIO);\n\t\tgoto early_unlock;\n\t}\n\n\tSET_BOOKMARK(&zb, dmu_objset_id(db->db_objset),\n\t    db->db.db_object, db->db_level, db->db_blkid);\n\n\t \n\tif (db->db_objset->os_encrypted && !BP_USES_CRYPT(bpp)) {\n\t\tspa_log_error(db->db_objset->os_spa, &zb, &bpp->blk_birth);\n\t\tzfs_panic_recover(\"unencrypted block in encrypted \"\n\t\t    \"object set %llu\", dmu_objset_id(db->db_objset));\n\t\terr = SET_ERROR(EIO);\n\t\tgoto early_unlock;\n\t}\n\n\terr = dbuf_read_verify_dnode_crypt(db, flags);\n\tif (err != 0)\n\t\tgoto early_unlock;\n\n\tDB_DNODE_EXIT(db);\n\n\tdb->db_state = DB_READ;\n\tDTRACE_SET_STATE(db, \"read issued\");\n\tmutex_exit(&db->db_mtx);\n\n\tif (!DBUF_IS_CACHEABLE(db))\n\t\taflags |= ARC_FLAG_UNCACHED;\n\telse if (dbuf_is_l2cacheable(db))\n\t\taflags |= ARC_FLAG_L2CACHE;\n\n\tdbuf_add_ref(db, NULL);\n\n\tzio_flags = (flags & DB_RF_CANFAIL) ?\n\t    ZIO_FLAG_CANFAIL : ZIO_FLAG_MUSTSUCCEED;\n\n\tif ((flags & DB_RF_NO_DECRYPT) && BP_IS_PROTECTED(db->db_blkptr))\n\t\tzio_flags |= ZIO_FLAG_RAW;\n\t \n\tdmu_buf_unlock_parent(db, dblt, tag);\n\t(void) arc_read(zio, db->db_objset->os_spa, bpp,\n\t    dbuf_read_done, db, ZIO_PRIORITY_SYNC_READ, zio_flags,\n\t    &aflags, &zb);\n\treturn (err);\nearly_unlock:\n\tDB_DNODE_EXIT(db);\n\tmutex_exit(&db->db_mtx);\n\tdmu_buf_unlock_parent(db, dblt, tag);\n\treturn (err);\n}\n\n \nstatic void\ndbuf_fix_old_data(dmu_buf_impl_t *db, uint64_t txg)\n{\n\tdbuf_dirty_record_t *dr = list_head(&db->db_dirty_records);\n\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\tASSERT(db->db.db_data != NULL);\n\tASSERT(db->db_level == 0);\n\tASSERT(db->db.db_object != DMU_META_DNODE_OBJECT);\n\n\tif (dr == NULL ||\n\t    (dr->dt.dl.dr_data !=\n\t    ((db->db_blkid  == DMU_BONUS_BLKID) ? db->db.db_data : db->db_buf)))\n\t\treturn;\n\n\t \n\tASSERT3U(dr->dr_txg, >=, txg - 2);\n\tif (db->db_blkid == DMU_BONUS_BLKID) {\n\t\tdnode_t *dn = DB_DNODE(db);\n\t\tint bonuslen = DN_SLOTS_TO_BONUSLEN(dn->dn_num_slots);\n\t\tdr->dt.dl.dr_data = kmem_alloc(bonuslen, KM_SLEEP);\n\t\tarc_space_consume(bonuslen, ARC_SPACE_BONUS);\n\t\tmemcpy(dr->dt.dl.dr_data, db->db.db_data, bonuslen);\n\t} else if (zfs_refcount_count(&db->db_holds) > db->db_dirtycnt) {\n\t\tdnode_t *dn = DB_DNODE(db);\n\t\tint size = arc_buf_size(db->db_buf);\n\t\tarc_buf_contents_t type = DBUF_GET_BUFC_TYPE(db);\n\t\tspa_t *spa = db->db_objset->os_spa;\n\t\tenum zio_compress compress_type =\n\t\t    arc_get_compression(db->db_buf);\n\t\tuint8_t complevel = arc_get_complevel(db->db_buf);\n\n\t\tif (arc_is_encrypted(db->db_buf)) {\n\t\t\tboolean_t byteorder;\n\t\t\tuint8_t salt[ZIO_DATA_SALT_LEN];\n\t\t\tuint8_t iv[ZIO_DATA_IV_LEN];\n\t\t\tuint8_t mac[ZIO_DATA_MAC_LEN];\n\n\t\t\tarc_get_raw_params(db->db_buf, &byteorder, salt,\n\t\t\t    iv, mac);\n\t\t\tdr->dt.dl.dr_data = arc_alloc_raw_buf(spa, db,\n\t\t\t    dmu_objset_id(dn->dn_objset), byteorder, salt, iv,\n\t\t\t    mac, dn->dn_type, size, arc_buf_lsize(db->db_buf),\n\t\t\t    compress_type, complevel);\n\t\t} else if (compress_type != ZIO_COMPRESS_OFF) {\n\t\t\tASSERT3U(type, ==, ARC_BUFC_DATA);\n\t\t\tdr->dt.dl.dr_data = arc_alloc_compressed_buf(spa, db,\n\t\t\t    size, arc_buf_lsize(db->db_buf), compress_type,\n\t\t\t    complevel);\n\t\t} else {\n\t\t\tdr->dt.dl.dr_data = arc_alloc_buf(spa, db, type, size);\n\t\t}\n\t\tmemcpy(dr->dt.dl.dr_data->b_data, db->db.db_data, size);\n\t} else {\n\t\tdb->db_buf = NULL;\n\t\tdbuf_clear_data(db);\n\t}\n}\n\nint\ndbuf_read(dmu_buf_impl_t *db, zio_t *zio, uint32_t flags)\n{\n\tint err = 0;\n\tboolean_t prefetch;\n\tdnode_t *dn;\n\n\t \n\tASSERT(!zfs_refcount_is_zero(&db->db_holds));\n\n\tDB_DNODE_ENTER(db);\n\tdn = DB_DNODE(db);\n\n\tprefetch = db->db_level == 0 && db->db_blkid != DMU_BONUS_BLKID &&\n\t    (flags & DB_RF_NOPREFETCH) == 0 && dn != NULL;\n\n\tmutex_enter(&db->db_mtx);\n\tif (flags & DB_RF_PARTIAL_FIRST)\n\t\tdb->db_partial_read = B_TRUE;\n\telse if (!(flags & DB_RF_PARTIAL_MORE))\n\t\tdb->db_partial_read = B_FALSE;\n\tif (db->db_state == DB_CACHED) {\n\t\t \n\t\terr = dbuf_read_verify_dnode_crypt(db, flags);\n\n\t\t \n\t\tif (err == 0 && db->db_buf != NULL &&\n\t\t    (flags & DB_RF_NO_DECRYPT) == 0 &&\n\t\t    (arc_is_encrypted(db->db_buf) ||\n\t\t    arc_is_unauthenticated(db->db_buf) ||\n\t\t    arc_get_compression(db->db_buf) != ZIO_COMPRESS_OFF)) {\n\t\t\tspa_t *spa = dn->dn_objset->os_spa;\n\t\t\tzbookmark_phys_t zb;\n\n\t\t\tSET_BOOKMARK(&zb, dmu_objset_id(db->db_objset),\n\t\t\t    db->db.db_object, db->db_level, db->db_blkid);\n\t\t\tdbuf_fix_old_data(db, spa_syncing_txg(spa));\n\t\t\terr = arc_untransform(db->db_buf, spa, &zb, B_FALSE);\n\t\t\tdbuf_set_data(db, db->db_buf);\n\t\t}\n\t\tmutex_exit(&db->db_mtx);\n\t\tif (err == 0 && prefetch) {\n\t\t\tdmu_zfetch(&dn->dn_zfetch, db->db_blkid, 1, B_TRUE,\n\t\t\t    B_FALSE, flags & DB_RF_HAVESTRUCT);\n\t\t}\n\t\tDB_DNODE_EXIT(db);\n\t\tDBUF_STAT_BUMP(hash_hits);\n\t} else if (db->db_state == DB_UNCACHED || db->db_state == DB_NOFILL) {\n\t\tboolean_t need_wait = B_FALSE;\n\n\t\tdb_lock_type_t dblt = dmu_buf_lock_parent(db, RW_READER, FTAG);\n\n\t\tif (zio == NULL && (db->db_state == DB_NOFILL ||\n\t\t    (db->db_blkptr != NULL && !BP_IS_HOLE(db->db_blkptr)))) {\n\t\t\tspa_t *spa = dn->dn_objset->os_spa;\n\t\t\tzio = zio_root(spa, NULL, NULL, ZIO_FLAG_CANFAIL);\n\t\t\tneed_wait = B_TRUE;\n\t\t}\n\t\terr = dbuf_read_impl(db, zio, flags, dblt, FTAG);\n\t\t \n\t\tif (!err && prefetch) {\n\t\t\tdmu_zfetch(&dn->dn_zfetch, db->db_blkid, 1, B_TRUE,\n\t\t\t    db->db_state != DB_CACHED,\n\t\t\t    flags & DB_RF_HAVESTRUCT);\n\t\t}\n\n\t\tDB_DNODE_EXIT(db);\n\t\tDBUF_STAT_BUMP(hash_misses);\n\n\t\t \n\t\tif (need_wait) {\n\t\t\tif (err == 0)\n\t\t\t\terr = zio_wait(zio);\n\t\t\telse\n\t\t\t\tVERIFY0(zio_wait(zio));\n\t\t}\n\t} else {\n\t\t \n\t\tmutex_exit(&db->db_mtx);\n\t\tif (prefetch) {\n\t\t\tdmu_zfetch(&dn->dn_zfetch, db->db_blkid, 1, B_TRUE,\n\t\t\t    B_TRUE, flags & DB_RF_HAVESTRUCT);\n\t\t}\n\t\tDB_DNODE_EXIT(db);\n\t\tDBUF_STAT_BUMP(hash_misses);\n\n\t\t \n\t\tif ((flags & DB_RF_NEVERWAIT) == 0) {\n\t\t\tmutex_enter(&db->db_mtx);\n\t\t\twhile (db->db_state == DB_READ ||\n\t\t\t    db->db_state == DB_FILL) {\n\t\t\t\tASSERT(db->db_state == DB_READ ||\n\t\t\t\t    (flags & DB_RF_HAVESTRUCT) == 0);\n\t\t\t\tDTRACE_PROBE2(blocked__read, dmu_buf_impl_t *,\n\t\t\t\t    db, zio_t *, zio);\n\t\t\t\tcv_wait(&db->db_changed, &db->db_mtx);\n\t\t\t}\n\t\t\tif (db->db_state == DB_UNCACHED)\n\t\t\t\terr = SET_ERROR(EIO);\n\t\t\tmutex_exit(&db->db_mtx);\n\t\t}\n\t}\n\n\treturn (err);\n}\n\nstatic void\ndbuf_noread(dmu_buf_impl_t *db)\n{\n\tASSERT(!zfs_refcount_is_zero(&db->db_holds));\n\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\tmutex_enter(&db->db_mtx);\n\twhile (db->db_state == DB_READ || db->db_state == DB_FILL)\n\t\tcv_wait(&db->db_changed, &db->db_mtx);\n\tif (db->db_state == DB_UNCACHED) {\n\t\tASSERT(db->db_buf == NULL);\n\t\tASSERT(db->db.db_data == NULL);\n\t\tdbuf_set_data(db, dbuf_alloc_arcbuf(db));\n\t\tdb->db_state = DB_FILL;\n\t\tDTRACE_SET_STATE(db, \"assigning filled buffer\");\n\t} else if (db->db_state == DB_NOFILL) {\n\t\tdbuf_clear_data(db);\n\t} else {\n\t\tASSERT3U(db->db_state, ==, DB_CACHED);\n\t}\n\tmutex_exit(&db->db_mtx);\n}\n\nvoid\ndbuf_unoverride(dbuf_dirty_record_t *dr)\n{\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\tblkptr_t *bp = &dr->dt.dl.dr_overridden_by;\n\tuint64_t txg = dr->dr_txg;\n\tboolean_t release;\n\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\t \n\tASSERT(dr->dt.dl.dr_override_state != DR_IN_DMU_SYNC);\n\tASSERT(db->db_level == 0);\n\n\tif (db->db_blkid == DMU_BONUS_BLKID ||\n\t    dr->dt.dl.dr_override_state == DR_NOT_OVERRIDDEN)\n\t\treturn;\n\n\tASSERT(db->db_data_pending != dr);\n\n\t \n\tif (!BP_IS_HOLE(bp) && !dr->dt.dl.dr_nopwrite)\n\t\tzio_free(db->db_objset->os_spa, txg, bp);\n\n\trelease = !dr->dt.dl.dr_brtwrite;\n\tdr->dt.dl.dr_override_state = DR_NOT_OVERRIDDEN;\n\tdr->dt.dl.dr_nopwrite = B_FALSE;\n\tdr->dt.dl.dr_brtwrite = B_FALSE;\n\tdr->dt.dl.dr_has_raw_params = B_FALSE;\n\n\t \n\tif (release)\n\t\tarc_release(dr->dt.dl.dr_data, db);\n}\n\n \nvoid\ndbuf_free_range(dnode_t *dn, uint64_t start_blkid, uint64_t end_blkid,\n    dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db_search;\n\tdmu_buf_impl_t *db, *db_next;\n\tuint64_t txg = tx->tx_txg;\n\tavl_index_t where;\n\tdbuf_dirty_record_t *dr;\n\n\tif (end_blkid > dn->dn_maxblkid &&\n\t    !(start_blkid == DMU_SPILL_BLKID || end_blkid == DMU_SPILL_BLKID))\n\t\tend_blkid = dn->dn_maxblkid;\n\tdprintf_dnode(dn, \"start=%llu end=%llu\\n\", (u_longlong_t)start_blkid,\n\t    (u_longlong_t)end_blkid);\n\n\tdb_search = kmem_alloc(sizeof (dmu_buf_impl_t), KM_SLEEP);\n\tdb_search->db_level = 0;\n\tdb_search->db_blkid = start_blkid;\n\tdb_search->db_state = DB_SEARCH;\n\n\tmutex_enter(&dn->dn_dbufs_mtx);\n\tdb = avl_find(&dn->dn_dbufs, db_search, &where);\n\tASSERT3P(db, ==, NULL);\n\n\tdb = avl_nearest(&dn->dn_dbufs, where, AVL_AFTER);\n\n\tfor (; db != NULL; db = db_next) {\n\t\tdb_next = AVL_NEXT(&dn->dn_dbufs, db);\n\t\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\n\t\tif (db->db_level != 0 || db->db_blkid > end_blkid) {\n\t\t\tbreak;\n\t\t}\n\t\tASSERT3U(db->db_blkid, >=, start_blkid);\n\n\t\t \n\t\tmutex_enter(&db->db_mtx);\n\t\tif (dbuf_undirty(db, tx)) {\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\n\t\tif (db->db_state == DB_UNCACHED ||\n\t\t    db->db_state == DB_NOFILL ||\n\t\t    db->db_state == DB_EVICTING) {\n\t\t\tASSERT(db->db.db_data == NULL);\n\t\t\tmutex_exit(&db->db_mtx);\n\t\t\tcontinue;\n\t\t}\n\t\tif (db->db_state == DB_READ || db->db_state == DB_FILL) {\n\t\t\t \n\t\t\tdb->db_freed_in_flight = TRUE;\n\t\t\tmutex_exit(&db->db_mtx);\n\t\t\tcontinue;\n\t\t}\n\t\tif (zfs_refcount_count(&db->db_holds) == 0) {\n\t\t\tASSERT(db->db_buf);\n\t\t\tdbuf_destroy(db);\n\t\t\tcontinue;\n\t\t}\n\t\t \n\n\t\tdr = list_head(&db->db_dirty_records);\n\t\tif (dr != NULL) {\n\t\t\tif (dr->dr_txg == txg) {\n\t\t\t\t \n\t\t\t\tif (db->db_blkid != DMU_SPILL_BLKID &&\n\t\t\t\t    db->db_blkid > dn->dn_maxblkid)\n\t\t\t\t\tdn->dn_maxblkid = db->db_blkid;\n\t\t\t\tdbuf_unoverride(dr);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tdbuf_fix_old_data(db, txg);\n\t\t\t}\n\t\t}\n\t\t \n\t\tif (db->db_state == DB_CACHED) {\n\t\t\tASSERT(db->db.db_data != NULL);\n\t\t\tarc_release(db->db_buf, db);\n\t\t\trw_enter(&db->db_rwlock, RW_WRITER);\n\t\t\tmemset(db->db.db_data, 0, db->db.db_size);\n\t\t\trw_exit(&db->db_rwlock);\n\t\t\tarc_buf_freeze(db->db_buf);\n\t\t}\n\n\t\tmutex_exit(&db->db_mtx);\n\t}\n\n\tmutex_exit(&dn->dn_dbufs_mtx);\n\tkmem_free(db_search, sizeof (dmu_buf_impl_t));\n}\n\nvoid\ndbuf_new_size(dmu_buf_impl_t *db, int size, dmu_tx_t *tx)\n{\n\tarc_buf_t *buf, *old_buf;\n\tdbuf_dirty_record_t *dr;\n\tint osize = db->db.db_size;\n\tarc_buf_contents_t type = DBUF_GET_BUFC_TYPE(db);\n\tdnode_t *dn;\n\n\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\n\tDB_DNODE_ENTER(db);\n\tdn = DB_DNODE(db);\n\n\t \n\tdmu_buf_will_dirty(&db->db, tx);\n\n\t \n\tbuf = arc_alloc_buf(dn->dn_objset->os_spa, db, type, size);\n\n\t \n\told_buf = db->db_buf;\n\tmemcpy(buf->b_data, old_buf->b_data, MIN(osize, size));\n\t \n\tif (size > osize)\n\t\tmemset((uint8_t *)buf->b_data + osize, 0, size - osize);\n\n\tmutex_enter(&db->db_mtx);\n\tdbuf_set_data(db, buf);\n\tarc_buf_destroy(old_buf, db);\n\tdb->db.db_size = size;\n\n\tdr = list_head(&db->db_dirty_records);\n\t \n\tVERIFY(dr != NULL);\n\tif (db->db_level == 0)\n\t\tdr->dt.dl.dr_data = buf;\n\tASSERT3U(dr->dr_txg, ==, tx->tx_txg);\n\tASSERT3U(dr->dr_accounted, ==, osize);\n\tdr->dr_accounted = size;\n\tmutex_exit(&db->db_mtx);\n\n\tdmu_objset_willuse_space(dn->dn_objset, size - osize, tx);\n\tDB_DNODE_EXIT(db);\n}\n\nvoid\ndbuf_release_bp(dmu_buf_impl_t *db)\n{\n\tobjset_t *os __maybe_unused = db->db_objset;\n\n\tASSERT(dsl_pool_sync_context(dmu_objset_pool(os)));\n\tASSERT(arc_released(os->os_phys_buf) ||\n\t    list_link_active(&os->os_dsl_dataset->ds_synced_link));\n\tASSERT(db->db_parent == NULL || arc_released(db->db_parent->db_buf));\n\n\t(void) arc_release(db->db_buf, db);\n}\n\n \nstatic void\ndbuf_redirty(dbuf_dirty_record_t *dr)\n{\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\n\tif (db->db_level == 0 && db->db_blkid != DMU_BONUS_BLKID) {\n\t\t \n\t\tdbuf_unoverride(dr);\n\t\tif (db->db.db_object != DMU_META_DNODE_OBJECT &&\n\t\t    db->db_state != DB_NOFILL) {\n\t\t\t \n\t\t\tASSERT(arc_released(db->db_buf));\n\t\t\tarc_buf_thaw(db->db_buf);\n\t\t}\n\t}\n}\n\ndbuf_dirty_record_t *\ndbuf_dirty_lightweight(dnode_t *dn, uint64_t blkid, dmu_tx_t *tx)\n{\n\trw_enter(&dn->dn_struct_rwlock, RW_READER);\n\tIMPLY(dn->dn_objset->os_raw_receive, dn->dn_maxblkid >= blkid);\n\tdnode_new_blkid(dn, blkid, tx, B_TRUE, B_FALSE);\n\tASSERT(dn->dn_maxblkid >= blkid);\n\n\tdbuf_dirty_record_t *dr = kmem_zalloc(sizeof (*dr), KM_SLEEP);\n\tlist_link_init(&dr->dr_dirty_node);\n\tlist_link_init(&dr->dr_dbuf_node);\n\tdr->dr_dnode = dn;\n\tdr->dr_txg = tx->tx_txg;\n\tdr->dt.dll.dr_blkid = blkid;\n\tdr->dr_accounted = dn->dn_datablksz;\n\n\t \n\tASSERT3P(NULL, ==, dbuf_find(dn->dn_objset, dn->dn_object, 0, blkid,\n\t    NULL));\n\n\tmutex_enter(&dn->dn_mtx);\n\tint txgoff = tx->tx_txg & TXG_MASK;\n\tif (dn->dn_free_ranges[txgoff] != NULL) {\n\t\trange_tree_clear(dn->dn_free_ranges[txgoff], blkid, 1);\n\t}\n\n\tif (dn->dn_nlevels == 1) {\n\t\tASSERT3U(blkid, <, dn->dn_nblkptr);\n\t\tlist_insert_tail(&dn->dn_dirty_records[txgoff], dr);\n\t\tmutex_exit(&dn->dn_mtx);\n\t\trw_exit(&dn->dn_struct_rwlock);\n\t\tdnode_setdirty(dn, tx);\n\t} else {\n\t\tmutex_exit(&dn->dn_mtx);\n\n\t\tint epbs = dn->dn_indblkshift - SPA_BLKPTRSHIFT;\n\t\tdmu_buf_impl_t *parent_db = dbuf_hold_level(dn,\n\t\t    1, blkid >> epbs, FTAG);\n\t\trw_exit(&dn->dn_struct_rwlock);\n\t\tif (parent_db == NULL) {\n\t\t\tkmem_free(dr, sizeof (*dr));\n\t\t\treturn (NULL);\n\t\t}\n\t\tint err = dbuf_read(parent_db, NULL,\n\t\t    (DB_RF_NOPREFETCH | DB_RF_CANFAIL));\n\t\tif (err != 0) {\n\t\t\tdbuf_rele(parent_db, FTAG);\n\t\t\tkmem_free(dr, sizeof (*dr));\n\t\t\treturn (NULL);\n\t\t}\n\n\t\tdbuf_dirty_record_t *parent_dr = dbuf_dirty(parent_db, tx);\n\t\tdbuf_rele(parent_db, FTAG);\n\t\tmutex_enter(&parent_dr->dt.di.dr_mtx);\n\t\tASSERT3U(parent_dr->dr_txg, ==, tx->tx_txg);\n\t\tlist_insert_tail(&parent_dr->dt.di.dr_children, dr);\n\t\tmutex_exit(&parent_dr->dt.di.dr_mtx);\n\t\tdr->dr_parent = parent_dr;\n\t}\n\n\tdmu_objset_willuse_space(dn->dn_objset, dr->dr_accounted, tx);\n\n\treturn (dr);\n}\n\ndbuf_dirty_record_t *\ndbuf_dirty(dmu_buf_impl_t *db, dmu_tx_t *tx)\n{\n\tdnode_t *dn;\n\tobjset_t *os;\n\tdbuf_dirty_record_t *dr, *dr_next, *dr_head;\n\tint txgoff = tx->tx_txg & TXG_MASK;\n\tboolean_t drop_struct_rwlock = B_FALSE;\n\n\tASSERT(tx->tx_txg != 0);\n\tASSERT(!zfs_refcount_is_zero(&db->db_holds));\n\tDMU_TX_DIRTY_BUF(tx, db);\n\n\tDB_DNODE_ENTER(db);\n\tdn = DB_DNODE(db);\n\t \n#ifdef ZFS_DEBUG\n\tif (dn->dn_objset->os_dsl_dataset != NULL) {\n\t\trrw_enter(&dn->dn_objset->os_dsl_dataset->ds_bp_rwlock,\n\t\t    RW_READER, FTAG);\n\t}\n\tASSERT(!dmu_tx_is_syncing(tx) ||\n\t    BP_IS_HOLE(dn->dn_objset->os_rootbp) ||\n\t    DMU_OBJECT_IS_SPECIAL(dn->dn_object) ||\n\t    dn->dn_objset->os_dsl_dataset == NULL);\n\tif (dn->dn_objset->os_dsl_dataset != NULL)\n\t\trrw_exit(&dn->dn_objset->os_dsl_dataset->ds_bp_rwlock, FTAG);\n#endif\n\t \n\tASSERT(dn->dn_object == DMU_META_DNODE_OBJECT ||\n\t    dn->dn_dirtyctx == DN_UNDIRTIED || dn->dn_dirtyctx ==\n\t    (dmu_tx_is_syncing(tx) ? DN_DIRTY_SYNC : DN_DIRTY_OPEN));\n\n\tmutex_enter(&db->db_mtx);\n\t \n\tASSERT(db->db_level != 0 ||\n\t    db->db_state == DB_CACHED || db->db_state == DB_FILL ||\n\t    db->db_state == DB_NOFILL);\n\n\tmutex_enter(&dn->dn_mtx);\n\tdnode_set_dirtyctx(dn, tx, db);\n\tif (tx->tx_txg > dn->dn_dirty_txg)\n\t\tdn->dn_dirty_txg = tx->tx_txg;\n\tmutex_exit(&dn->dn_mtx);\n\n\tif (db->db_blkid == DMU_SPILL_BLKID)\n\t\tdn->dn_have_spill = B_TRUE;\n\n\t \n\tdr_head = list_head(&db->db_dirty_records);\n\tASSERT(dr_head == NULL || dr_head->dr_txg <= tx->tx_txg ||\n\t    db->db.db_object == DMU_META_DNODE_OBJECT);\n\tdr_next = dbuf_find_dirty_lte(db, tx->tx_txg);\n\tif (dr_next && dr_next->dr_txg == tx->tx_txg) {\n\t\tDB_DNODE_EXIT(db);\n\n\t\tdbuf_redirty(dr_next);\n\t\tmutex_exit(&db->db_mtx);\n\t\treturn (dr_next);\n\t}\n\n\t \n\tASSERT(dn->dn_object == 0 ||\n\t    dn->dn_dirtyctx == DN_UNDIRTIED || dn->dn_dirtyctx ==\n\t    (dmu_tx_is_syncing(tx) ? DN_DIRTY_SYNC : DN_DIRTY_OPEN));\n\n\tASSERT3U(dn->dn_nlevels, >, db->db_level);\n\n\t \n\tos = dn->dn_objset;\n\tVERIFY3U(tx->tx_txg, <=, spa_final_dirty_txg(os->os_spa));\n#ifdef ZFS_DEBUG\n\tif (dn->dn_objset->os_dsl_dataset != NULL)\n\t\trrw_enter(&os->os_dsl_dataset->ds_bp_rwlock, RW_READER, FTAG);\n\tASSERT(!dmu_tx_is_syncing(tx) || DMU_OBJECT_IS_SPECIAL(dn->dn_object) ||\n\t    os->os_dsl_dataset == NULL || BP_IS_HOLE(os->os_rootbp));\n\tif (dn->dn_objset->os_dsl_dataset != NULL)\n\t\trrw_exit(&os->os_dsl_dataset->ds_bp_rwlock, FTAG);\n#endif\n\tASSERT(db->db.db_size != 0);\n\n\tdprintf_dbuf(db, \"size=%llx\\n\", (u_longlong_t)db->db.db_size);\n\n\tif (db->db_blkid != DMU_BONUS_BLKID && db->db_state != DB_NOFILL) {\n\t\tdmu_objset_willuse_space(os, db->db.db_size, tx);\n\t}\n\n\t \n\tdr = kmem_zalloc(sizeof (dbuf_dirty_record_t), KM_SLEEP);\n\tlist_link_init(&dr->dr_dirty_node);\n\tlist_link_init(&dr->dr_dbuf_node);\n\tdr->dr_dnode = dn;\n\tif (db->db_level == 0) {\n\t\tvoid *data_old = db->db_buf;\n\n\t\tif (db->db_state != DB_NOFILL) {\n\t\t\tif (db->db_blkid == DMU_BONUS_BLKID) {\n\t\t\t\tdbuf_fix_old_data(db, tx->tx_txg);\n\t\t\t\tdata_old = db->db.db_data;\n\t\t\t} else if (db->db.db_object != DMU_META_DNODE_OBJECT) {\n\t\t\t\t \n\t\t\t\tarc_release(db->db_buf, db);\n\t\t\t\tdbuf_fix_old_data(db, tx->tx_txg);\n\t\t\t\tdata_old = db->db_buf;\n\t\t\t}\n\t\t\tASSERT(data_old != NULL);\n\t\t}\n\t\tdr->dt.dl.dr_data = data_old;\n\t} else {\n\t\tmutex_init(&dr->dt.di.dr_mtx, NULL, MUTEX_NOLOCKDEP, NULL);\n\t\tlist_create(&dr->dt.di.dr_children,\n\t\t    sizeof (dbuf_dirty_record_t),\n\t\t    offsetof(dbuf_dirty_record_t, dr_dirty_node));\n\t}\n\tif (db->db_blkid != DMU_BONUS_BLKID && db->db_state != DB_NOFILL) {\n\t\tdr->dr_accounted = db->db.db_size;\n\t}\n\tdr->dr_dbuf = db;\n\tdr->dr_txg = tx->tx_txg;\n\tlist_insert_before(&db->db_dirty_records, dr_next, dr);\n\n\t \n\tif (db->db_level == 0 && db->db_blkid != DMU_BONUS_BLKID &&\n\t    db->db_blkid != DMU_SPILL_BLKID) {\n\t\tmutex_enter(&dn->dn_mtx);\n\t\tif (dn->dn_free_ranges[txgoff] != NULL) {\n\t\t\trange_tree_clear(dn->dn_free_ranges[txgoff],\n\t\t\t    db->db_blkid, 1);\n\t\t}\n\t\tmutex_exit(&dn->dn_mtx);\n\t\tdb->db_freed_in_flight = FALSE;\n\t}\n\n\t \n\tdbuf_add_ref(db, (void *)(uintptr_t)tx->tx_txg);\n\tdb->db_dirtycnt += 1;\n\tASSERT3U(db->db_dirtycnt, <=, 3);\n\n\tmutex_exit(&db->db_mtx);\n\n\tif (db->db_blkid == DMU_BONUS_BLKID ||\n\t    db->db_blkid == DMU_SPILL_BLKID) {\n\t\tmutex_enter(&dn->dn_mtx);\n\t\tASSERT(!list_link_active(&dr->dr_dirty_node));\n\t\tlist_insert_tail(&dn->dn_dirty_records[txgoff], dr);\n\t\tmutex_exit(&dn->dn_mtx);\n\t\tdnode_setdirty(dn, tx);\n\t\tDB_DNODE_EXIT(db);\n\t\treturn (dr);\n\t}\n\n\tif (!RW_WRITE_HELD(&dn->dn_struct_rwlock)) {\n\t\trw_enter(&dn->dn_struct_rwlock, RW_READER);\n\t\tdrop_struct_rwlock = B_TRUE;\n\t}\n\n\t \n\tif (db->db_blkptr != NULL) {\n\t\tdb_lock_type_t dblt = dmu_buf_lock_parent(db, RW_READER, FTAG);\n\t\tddt_prefetch(os->os_spa, db->db_blkptr);\n\t\tdmu_buf_unlock_parent(db, dblt, FTAG);\n\t}\n\n\t \n\tASSERT((dn->dn_phys->dn_nlevels == 0 && db->db_level == 0) ||\n\t    dn->dn_phys->dn_nlevels > db->db_level ||\n\t    dn->dn_next_nlevels[txgoff] > db->db_level ||\n\t    dn->dn_next_nlevels[(tx->tx_txg-1) & TXG_MASK] > db->db_level ||\n\t    dn->dn_next_nlevels[(tx->tx_txg-2) & TXG_MASK] > db->db_level);\n\n\n\tif (db->db_level == 0) {\n\t\tASSERT(!db->db_objset->os_raw_receive ||\n\t\t    dn->dn_maxblkid >= db->db_blkid);\n\t\tdnode_new_blkid(dn, db->db_blkid, tx,\n\t\t    drop_struct_rwlock, B_FALSE);\n\t\tASSERT(dn->dn_maxblkid >= db->db_blkid);\n\t}\n\n\tif (db->db_level+1 < dn->dn_nlevels) {\n\t\tdmu_buf_impl_t *parent = db->db_parent;\n\t\tdbuf_dirty_record_t *di;\n\t\tint parent_held = FALSE;\n\n\t\tif (db->db_parent == NULL || db->db_parent == dn->dn_dbuf) {\n\t\t\tint epbs = dn->dn_indblkshift - SPA_BLKPTRSHIFT;\n\t\t\tparent = dbuf_hold_level(dn, db->db_level + 1,\n\t\t\t    db->db_blkid >> epbs, FTAG);\n\t\t\tASSERT(parent != NULL);\n\t\t\tparent_held = TRUE;\n\t\t}\n\t\tif (drop_struct_rwlock)\n\t\t\trw_exit(&dn->dn_struct_rwlock);\n\t\tASSERT3U(db->db_level + 1, ==, parent->db_level);\n\t\tdi = dbuf_dirty(parent, tx);\n\t\tif (parent_held)\n\t\t\tdbuf_rele(parent, FTAG);\n\n\t\tmutex_enter(&db->db_mtx);\n\t\t \n\t\tif (list_head(&db->db_dirty_records) == dr ||\n\t\t    dn->dn_object == DMU_META_DNODE_OBJECT) {\n\t\t\tmutex_enter(&di->dt.di.dr_mtx);\n\t\t\tASSERT3U(di->dr_txg, ==, tx->tx_txg);\n\t\t\tASSERT(!list_link_active(&dr->dr_dirty_node));\n\t\t\tlist_insert_tail(&di->dt.di.dr_children, dr);\n\t\t\tmutex_exit(&di->dt.di.dr_mtx);\n\t\t\tdr->dr_parent = di;\n\t\t}\n\t\tmutex_exit(&db->db_mtx);\n\t} else {\n\t\tASSERT(db->db_level + 1 == dn->dn_nlevels);\n\t\tASSERT(db->db_blkid < dn->dn_nblkptr);\n\t\tASSERT(db->db_parent == NULL || db->db_parent == dn->dn_dbuf);\n\t\tmutex_enter(&dn->dn_mtx);\n\t\tASSERT(!list_link_active(&dr->dr_dirty_node));\n\t\tlist_insert_tail(&dn->dn_dirty_records[txgoff], dr);\n\t\tmutex_exit(&dn->dn_mtx);\n\t\tif (drop_struct_rwlock)\n\t\t\trw_exit(&dn->dn_struct_rwlock);\n\t}\n\n\tdnode_setdirty(dn, tx);\n\tDB_DNODE_EXIT(db);\n\treturn (dr);\n}\n\nstatic void\ndbuf_undirty_bonus(dbuf_dirty_record_t *dr)\n{\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\n\tif (dr->dt.dl.dr_data != db->db.db_data) {\n\t\tstruct dnode *dn = dr->dr_dnode;\n\t\tint max_bonuslen = DN_SLOTS_TO_BONUSLEN(dn->dn_num_slots);\n\n\t\tkmem_free(dr->dt.dl.dr_data, max_bonuslen);\n\t\tarc_space_return(max_bonuslen, ARC_SPACE_BONUS);\n\t}\n\tdb->db_data_pending = NULL;\n\tASSERT(list_next(&db->db_dirty_records, dr) == NULL);\n\tlist_remove(&db->db_dirty_records, dr);\n\tif (dr->dr_dbuf->db_level != 0) {\n\t\tmutex_destroy(&dr->dt.di.dr_mtx);\n\t\tlist_destroy(&dr->dt.di.dr_children);\n\t}\n\tkmem_free(dr, sizeof (dbuf_dirty_record_t));\n\tASSERT3U(db->db_dirtycnt, >, 0);\n\tdb->db_dirtycnt -= 1;\n}\n\n \nboolean_t\ndbuf_undirty(dmu_buf_impl_t *db, dmu_tx_t *tx)\n{\n\tuint64_t txg = tx->tx_txg;\n\tboolean_t brtwrite;\n\n\tASSERT(txg != 0);\n\n\t \n\tASSERT(db->db_objset ==\n\t    dmu_objset_pool(db->db_objset)->dp_meta_objset ||\n\t    txg != spa_syncing_txg(dmu_objset_spa(db->db_objset)));\n\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\tASSERT0(db->db_level);\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\n\t \n\tdbuf_dirty_record_t *dr = dbuf_find_dirty_eq(db, txg);\n\tif (dr == NULL)\n\t\treturn (B_FALSE);\n\tASSERT(dr->dr_dbuf == db);\n\n\tbrtwrite = dr->dt.dl.dr_brtwrite;\n\tif (brtwrite) {\n\t\t \n\t\tbrt_pending_remove(dmu_objset_spa(db->db_objset),\n\t\t    &dr->dt.dl.dr_overridden_by, tx);\n\t}\n\n\tdnode_t *dn = dr->dr_dnode;\n\n\tdprintf_dbuf(db, \"size=%llx\\n\", (u_longlong_t)db->db.db_size);\n\n\tASSERT(db->db.db_size != 0);\n\n\tdsl_pool_undirty_space(dmu_objset_pool(dn->dn_objset),\n\t    dr->dr_accounted, txg);\n\n\tlist_remove(&db->db_dirty_records, dr);\n\n\t \n\tif (dr->dr_parent) {\n\t\tmutex_enter(&dr->dr_parent->dt.di.dr_mtx);\n\t\tlist_remove(&dr->dr_parent->dt.di.dr_children, dr);\n\t\tmutex_exit(&dr->dr_parent->dt.di.dr_mtx);\n\t} else if (db->db_blkid == DMU_SPILL_BLKID ||\n\t    db->db_level + 1 == dn->dn_nlevels) {\n\t\tASSERT(db->db_blkptr == NULL || db->db_parent == dn->dn_dbuf);\n\t\tmutex_enter(&dn->dn_mtx);\n\t\tlist_remove(&dn->dn_dirty_records[txg & TXG_MASK], dr);\n\t\tmutex_exit(&dn->dn_mtx);\n\t}\n\n\tif (db->db_state != DB_NOFILL && !brtwrite) {\n\t\tdbuf_unoverride(dr);\n\n\t\tASSERT(db->db_buf != NULL);\n\t\tASSERT(dr->dt.dl.dr_data != NULL);\n\t\tif (dr->dt.dl.dr_data != db->db_buf)\n\t\t\tarc_buf_destroy(dr->dt.dl.dr_data, db);\n\t}\n\n\tkmem_free(dr, sizeof (dbuf_dirty_record_t));\n\n\tASSERT(db->db_dirtycnt > 0);\n\tdb->db_dirtycnt -= 1;\n\n\tif (zfs_refcount_remove(&db->db_holds, (void *)(uintptr_t)txg) == 0) {\n\t\tASSERT(db->db_state == DB_NOFILL || brtwrite ||\n\t\t    arc_released(db->db_buf));\n\t\tdbuf_destroy(db);\n\t\treturn (B_TRUE);\n\t}\n\n\treturn (B_FALSE);\n}\n\nstatic void\ndmu_buf_will_dirty_impl(dmu_buf_t *db_fake, int flags, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\tboolean_t undirty = B_FALSE;\n\n\tASSERT(tx->tx_txg != 0);\n\tASSERT(!zfs_refcount_is_zero(&db->db_holds));\n\n\t \n\tmutex_enter(&db->db_mtx);\n\n\tif (db->db_state == DB_CACHED || db->db_state == DB_NOFILL) {\n\t\tdbuf_dirty_record_t *dr = dbuf_find_dirty_eq(db, tx->tx_txg);\n\t\t \n\t\tif (dr != NULL) {\n\t\t\tif (dr->dt.dl.dr_brtwrite) {\n\t\t\t\t \n\t\t\t\tundirty = B_TRUE;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tdbuf_redirty(dr);\n\t\t\t\tmutex_exit(&db->db_mtx);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\tmutex_exit(&db->db_mtx);\n\n\tDB_DNODE_ENTER(db);\n\tif (RW_WRITE_HELD(&DB_DNODE(db)->dn_struct_rwlock))\n\t\tflags |= DB_RF_HAVESTRUCT;\n\tDB_DNODE_EXIT(db);\n\n\t \n\t(void) dbuf_read(db, NULL, flags);\n\tif (undirty) {\n\t\tmutex_enter(&db->db_mtx);\n\t\tVERIFY(!dbuf_undirty(db, tx));\n\t\tmutex_exit(&db->db_mtx);\n\t}\n\t(void) dbuf_dirty(db, tx);\n}\n\nvoid\ndmu_buf_will_dirty(dmu_buf_t *db_fake, dmu_tx_t *tx)\n{\n\tdmu_buf_will_dirty_impl(db_fake,\n\t    DB_RF_MUST_SUCCEED | DB_RF_NOPREFETCH, tx);\n}\n\nboolean_t\ndmu_buf_is_dirty(dmu_buf_t *db_fake, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\tdbuf_dirty_record_t *dr;\n\n\tmutex_enter(&db->db_mtx);\n\tdr = dbuf_find_dirty_eq(db, tx->tx_txg);\n\tmutex_exit(&db->db_mtx);\n\treturn (dr != NULL);\n}\n\nvoid\ndmu_buf_will_clone(dmu_buf_t *db_fake, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\n\t \n\tmutex_enter(&db->db_mtx);\n\tDBUF_VERIFY(db);\n\tVERIFY(!dbuf_undirty(db, tx));\n\tASSERT3P(dbuf_find_dirty_eq(db, tx->tx_txg), ==, NULL);\n\tif (db->db_buf != NULL) {\n\t\tarc_buf_destroy(db->db_buf, db);\n\t\tdb->db_buf = NULL;\n\t\tdbuf_clear_data(db);\n\t}\n\n\tdb->db_state = DB_NOFILL;\n\tDTRACE_SET_STATE(db, \"allocating NOFILL buffer for clone\");\n\n\tDBUF_VERIFY(db);\n\tmutex_exit(&db->db_mtx);\n\n\tdbuf_noread(db);\n\t(void) dbuf_dirty(db, tx);\n}\n\nvoid\ndmu_buf_will_not_fill(dmu_buf_t *db_fake, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\n\tmutex_enter(&db->db_mtx);\n\tdb->db_state = DB_NOFILL;\n\tDTRACE_SET_STATE(db, \"allocating NOFILL buffer\");\n\tmutex_exit(&db->db_mtx);\n\n\tdbuf_noread(db);\n\t(void) dbuf_dirty(db, tx);\n}\n\nvoid\ndmu_buf_will_fill(dmu_buf_t *db_fake, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\n\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\tASSERT(tx->tx_txg != 0);\n\tASSERT(db->db_level == 0);\n\tASSERT(!zfs_refcount_is_zero(&db->db_holds));\n\n\tASSERT(db->db.db_object != DMU_META_DNODE_OBJECT ||\n\t    dmu_tx_private_ok(tx));\n\n\tmutex_enter(&db->db_mtx);\n\tif (db->db_state == DB_NOFILL) {\n\t\t \n\t\tVERIFY(!dbuf_undirty(db, tx));\n\t\tdb->db_state = DB_UNCACHED;\n\t}\n\tmutex_exit(&db->db_mtx);\n\n\tdbuf_noread(db);\n\t(void) dbuf_dirty(db, tx);\n}\n\n \nvoid\ndmu_buf_set_crypt_params(dmu_buf_t *db_fake, boolean_t byteorder,\n    const uint8_t *salt, const uint8_t *iv, const uint8_t *mac, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\tdbuf_dirty_record_t *dr;\n\n\t \n\tASSERT3U(db->db.db_object, ==, DMU_META_DNODE_OBJECT);\n\tASSERT3U(db->db_level, ==, 0);\n\tASSERT(db->db_objset->os_raw_receive);\n\n\tdmu_buf_will_dirty_impl(db_fake,\n\t    DB_RF_MUST_SUCCEED | DB_RF_NOPREFETCH | DB_RF_NO_DECRYPT, tx);\n\n\tdr = dbuf_find_dirty_eq(db, tx->tx_txg);\n\n\tASSERT3P(dr, !=, NULL);\n\n\tdr->dt.dl.dr_has_raw_params = B_TRUE;\n\tdr->dt.dl.dr_byteorder = byteorder;\n\tmemcpy(dr->dt.dl.dr_salt, salt, ZIO_DATA_SALT_LEN);\n\tmemcpy(dr->dt.dl.dr_iv, iv, ZIO_DATA_IV_LEN);\n\tmemcpy(dr->dt.dl.dr_mac, mac, ZIO_DATA_MAC_LEN);\n}\n\nstatic void\ndbuf_override_impl(dmu_buf_impl_t *db, const blkptr_t *bp, dmu_tx_t *tx)\n{\n\tstruct dirty_leaf *dl;\n\tdbuf_dirty_record_t *dr;\n\n\tdr = list_head(&db->db_dirty_records);\n\tASSERT3P(dr, !=, NULL);\n\tASSERT3U(dr->dr_txg, ==, tx->tx_txg);\n\tdl = &dr->dt.dl;\n\tdl->dr_overridden_by = *bp;\n\tdl->dr_override_state = DR_OVERRIDDEN;\n\tdl->dr_overridden_by.blk_birth = dr->dr_txg;\n}\n\nvoid\ndmu_buf_fill_done(dmu_buf_t *dbuf, dmu_tx_t *tx)\n{\n\t(void) tx;\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)dbuf;\n\tdbuf_states_t old_state;\n\tmutex_enter(&db->db_mtx);\n\tDBUF_VERIFY(db);\n\n\told_state = db->db_state;\n\tdb->db_state = DB_CACHED;\n\tif (old_state == DB_FILL) {\n\t\tif (db->db_level == 0 && db->db_freed_in_flight) {\n\t\t\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\t\t\t \n\t\t\t \n\t\t\tmemset(db->db.db_data, 0, db->db.db_size);\n\t\t\tdb->db_freed_in_flight = FALSE;\n\t\t\tDTRACE_SET_STATE(db,\n\t\t\t    \"fill done handling freed in flight\");\n\t\t} else {\n\t\t\tDTRACE_SET_STATE(db, \"fill done\");\n\t\t}\n\t\tcv_broadcast(&db->db_changed);\n\t}\n\tmutex_exit(&db->db_mtx);\n}\n\nvoid\ndmu_buf_write_embedded(dmu_buf_t *dbuf, void *data,\n    bp_embedded_type_t etype, enum zio_compress comp,\n    int uncompressed_size, int compressed_size, int byteorder,\n    dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)dbuf;\n\tstruct dirty_leaf *dl;\n\tdmu_object_type_t type;\n\tdbuf_dirty_record_t *dr;\n\n\tif (etype == BP_EMBEDDED_TYPE_DATA) {\n\t\tASSERT(spa_feature_is_active(dmu_objset_spa(db->db_objset),\n\t\t    SPA_FEATURE_EMBEDDED_DATA));\n\t}\n\n\tDB_DNODE_ENTER(db);\n\ttype = DB_DNODE(db)->dn_type;\n\tDB_DNODE_EXIT(db);\n\n\tASSERT0(db->db_level);\n\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\n\tdmu_buf_will_not_fill(dbuf, tx);\n\n\tdr = list_head(&db->db_dirty_records);\n\tASSERT3P(dr, !=, NULL);\n\tASSERT3U(dr->dr_txg, ==, tx->tx_txg);\n\tdl = &dr->dt.dl;\n\tencode_embedded_bp_compressed(&dl->dr_overridden_by,\n\t    data, comp, uncompressed_size, compressed_size);\n\tBPE_SET_ETYPE(&dl->dr_overridden_by, etype);\n\tBP_SET_TYPE(&dl->dr_overridden_by, type);\n\tBP_SET_LEVEL(&dl->dr_overridden_by, 0);\n\tBP_SET_BYTEORDER(&dl->dr_overridden_by, byteorder);\n\n\tdl->dr_override_state = DR_OVERRIDDEN;\n\tdl->dr_overridden_by.blk_birth = dr->dr_txg;\n}\n\nvoid\ndmu_buf_redact(dmu_buf_t *dbuf, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)dbuf;\n\tdmu_object_type_t type;\n\tASSERT(dsl_dataset_feature_is_active(db->db_objset->os_dsl_dataset,\n\t    SPA_FEATURE_REDACTED_DATASETS));\n\n\tDB_DNODE_ENTER(db);\n\ttype = DB_DNODE(db)->dn_type;\n\tDB_DNODE_EXIT(db);\n\n\tASSERT0(db->db_level);\n\tdmu_buf_will_not_fill(dbuf, tx);\n\n\tblkptr_t bp = { { { {0} } } };\n\tBP_SET_TYPE(&bp, type);\n\tBP_SET_LEVEL(&bp, 0);\n\tBP_SET_BIRTH(&bp, tx->tx_txg, 0);\n\tBP_SET_REDACTED(&bp);\n\tBPE_SET_LSIZE(&bp, dbuf->db_size);\n\n\tdbuf_override_impl(db, &bp, tx);\n}\n\n \nvoid\ndbuf_assign_arcbuf(dmu_buf_impl_t *db, arc_buf_t *buf, dmu_tx_t *tx)\n{\n\tASSERT(!zfs_refcount_is_zero(&db->db_holds));\n\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\tASSERT(db->db_level == 0);\n\tASSERT3U(dbuf_is_metadata(db), ==, arc_is_metadata(buf));\n\tASSERT(buf != NULL);\n\tASSERT3U(arc_buf_lsize(buf), ==, db->db.db_size);\n\tASSERT(tx->tx_txg != 0);\n\n\tarc_return_buf(buf, db);\n\tASSERT(arc_released(buf));\n\n\tmutex_enter(&db->db_mtx);\n\n\twhile (db->db_state == DB_READ || db->db_state == DB_FILL)\n\t\tcv_wait(&db->db_changed, &db->db_mtx);\n\n\tASSERT(db->db_state == DB_CACHED || db->db_state == DB_UNCACHED);\n\n\tif (db->db_state == DB_CACHED &&\n\t    zfs_refcount_count(&db->db_holds) - 1 > db->db_dirtycnt) {\n\t\t \n\t\tASSERT(!arc_is_encrypted(buf));\n\t\tmutex_exit(&db->db_mtx);\n\t\t(void) dbuf_dirty(db, tx);\n\t\tmemcpy(db->db.db_data, buf->b_data, db->db.db_size);\n\t\tarc_buf_destroy(buf, db);\n\t\treturn;\n\t}\n\n\tif (db->db_state == DB_CACHED) {\n\t\tdbuf_dirty_record_t *dr = list_head(&db->db_dirty_records);\n\n\t\tASSERT(db->db_buf != NULL);\n\t\tif (dr != NULL && dr->dr_txg == tx->tx_txg) {\n\t\t\tASSERT(dr->dt.dl.dr_data == db->db_buf);\n\n\t\t\tif (!arc_released(db->db_buf)) {\n\t\t\t\tASSERT(dr->dt.dl.dr_override_state ==\n\t\t\t\t    DR_OVERRIDDEN);\n\t\t\t\tarc_release(db->db_buf, db);\n\t\t\t}\n\t\t\tdr->dt.dl.dr_data = buf;\n\t\t\tarc_buf_destroy(db->db_buf, db);\n\t\t} else if (dr == NULL || dr->dt.dl.dr_data != db->db_buf) {\n\t\t\tarc_release(db->db_buf, db);\n\t\t\tarc_buf_destroy(db->db_buf, db);\n\t\t}\n\t\tdb->db_buf = NULL;\n\t}\n\tASSERT(db->db_buf == NULL);\n\tdbuf_set_data(db, buf);\n\tdb->db_state = DB_FILL;\n\tDTRACE_SET_STATE(db, \"filling assigned arcbuf\");\n\tmutex_exit(&db->db_mtx);\n\t(void) dbuf_dirty(db, tx);\n\tdmu_buf_fill_done(&db->db, tx);\n}\n\nvoid\ndbuf_destroy(dmu_buf_impl_t *db)\n{\n\tdnode_t *dn;\n\tdmu_buf_impl_t *parent = db->db_parent;\n\tdmu_buf_impl_t *dndb;\n\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\tASSERT(zfs_refcount_is_zero(&db->db_holds));\n\n\tif (db->db_buf != NULL) {\n\t\tarc_buf_destroy(db->db_buf, db);\n\t\tdb->db_buf = NULL;\n\t}\n\n\tif (db->db_blkid == DMU_BONUS_BLKID) {\n\t\tint slots = DB_DNODE(db)->dn_num_slots;\n\t\tint bonuslen = DN_SLOTS_TO_BONUSLEN(slots);\n\t\tif (db->db.db_data != NULL) {\n\t\t\tkmem_free(db->db.db_data, bonuslen);\n\t\t\tarc_space_return(bonuslen, ARC_SPACE_BONUS);\n\t\t\tdb->db_state = DB_UNCACHED;\n\t\t\tDTRACE_SET_STATE(db, \"buffer cleared\");\n\t\t}\n\t}\n\n\tdbuf_clear_data(db);\n\n\tif (multilist_link_active(&db->db_cache_link)) {\n\t\tASSERT(db->db_caching_status == DB_DBUF_CACHE ||\n\t\t    db->db_caching_status == DB_DBUF_METADATA_CACHE);\n\n\t\tmultilist_remove(&dbuf_caches[db->db_caching_status].cache, db);\n\t\t(void) zfs_refcount_remove_many(\n\t\t    &dbuf_caches[db->db_caching_status].size,\n\t\t    db->db.db_size, db);\n\n\t\tif (db->db_caching_status == DB_DBUF_METADATA_CACHE) {\n\t\t\tDBUF_STAT_BUMPDOWN(metadata_cache_count);\n\t\t} else {\n\t\t\tDBUF_STAT_BUMPDOWN(cache_levels[db->db_level]);\n\t\t\tDBUF_STAT_BUMPDOWN(cache_count);\n\t\t\tDBUF_STAT_DECR(cache_levels_bytes[db->db_level],\n\t\t\t    db->db.db_size);\n\t\t}\n\t\tdb->db_caching_status = DB_NO_CACHE;\n\t}\n\n\tASSERT(db->db_state == DB_UNCACHED || db->db_state == DB_NOFILL);\n\tASSERT(db->db_data_pending == NULL);\n\tASSERT(list_is_empty(&db->db_dirty_records));\n\n\tdb->db_state = DB_EVICTING;\n\tDTRACE_SET_STATE(db, \"buffer eviction started\");\n\tdb->db_blkptr = NULL;\n\n\t \n\tmutex_exit(&db->db_mtx);\n\n\tDB_DNODE_ENTER(db);\n\tdn = DB_DNODE(db);\n\tdndb = dn->dn_dbuf;\n\tif (db->db_blkid != DMU_BONUS_BLKID) {\n\t\tboolean_t needlock = !MUTEX_HELD(&dn->dn_dbufs_mtx);\n\t\tif (needlock)\n\t\t\tmutex_enter_nested(&dn->dn_dbufs_mtx,\n\t\t\t    NESTED_SINGLE);\n\t\tavl_remove(&dn->dn_dbufs, db);\n\t\tmembar_producer();\n\t\tDB_DNODE_EXIT(db);\n\t\tif (needlock)\n\t\t\tmutex_exit(&dn->dn_dbufs_mtx);\n\t\t \n\t\tmutex_enter(&dn->dn_mtx);\n\t\tdnode_rele_and_unlock(dn, db, B_TRUE);\n\t\tdb->db_dnode_handle = NULL;\n\n\t\tdbuf_hash_remove(db);\n\t} else {\n\t\tDB_DNODE_EXIT(db);\n\t}\n\n\tASSERT(zfs_refcount_is_zero(&db->db_holds));\n\n\tdb->db_parent = NULL;\n\n\tASSERT(db->db_buf == NULL);\n\tASSERT(db->db.db_data == NULL);\n\tASSERT(db->db_hash_next == NULL);\n\tASSERT(db->db_blkptr == NULL);\n\tASSERT(db->db_data_pending == NULL);\n\tASSERT3U(db->db_caching_status, ==, DB_NO_CACHE);\n\tASSERT(!multilist_link_active(&db->db_cache_link));\n\n\t \n\tif (parent && parent != dndb) {\n\t\tmutex_enter(&parent->db_mtx);\n\t\tdbuf_rele_and_unlock(parent, db, B_TRUE);\n\t}\n\n\tkmem_cache_free(dbuf_kmem_cache, db);\n\tarc_space_return(sizeof (dmu_buf_impl_t), ARC_SPACE_DBUF);\n}\n\n \n__attribute__((always_inline))\nstatic inline int\ndbuf_findbp(dnode_t *dn, int level, uint64_t blkid, int fail_sparse,\n    dmu_buf_impl_t **parentp, blkptr_t **bpp)\n{\n\t*parentp = NULL;\n\t*bpp = NULL;\n\n\tASSERT(blkid != DMU_BONUS_BLKID);\n\n\tif (blkid == DMU_SPILL_BLKID) {\n\t\tmutex_enter(&dn->dn_mtx);\n\t\tif (dn->dn_have_spill &&\n\t\t    (dn->dn_phys->dn_flags & DNODE_FLAG_SPILL_BLKPTR))\n\t\t\t*bpp = DN_SPILL_BLKPTR(dn->dn_phys);\n\t\telse\n\t\t\t*bpp = NULL;\n\t\tdbuf_add_ref(dn->dn_dbuf, NULL);\n\t\t*parentp = dn->dn_dbuf;\n\t\tmutex_exit(&dn->dn_mtx);\n\t\treturn (0);\n\t}\n\n\tint nlevels =\n\t    (dn->dn_phys->dn_nlevels == 0) ? 1 : dn->dn_phys->dn_nlevels;\n\tint epbs = dn->dn_indblkshift - SPA_BLKPTRSHIFT;\n\n\tASSERT3U(level * epbs, <, 64);\n\tASSERT(RW_LOCK_HELD(&dn->dn_struct_rwlock));\n\t \n\tASSERT(level >= nlevels ||\n\t    ((nlevels - level - 1) * epbs) +\n\t    highbit64(dn->dn_phys->dn_nblkptr) <= 64);\n\tif (level >= nlevels ||\n\t    blkid >= ((uint64_t)dn->dn_phys->dn_nblkptr <<\n\t    ((nlevels - level - 1) * epbs)) ||\n\t    (fail_sparse &&\n\t    blkid > (dn->dn_phys->dn_maxblkid >> (level * epbs)))) {\n\t\t \n\t\treturn (SET_ERROR(ENOENT));\n\t} else if (level < nlevels-1) {\n\t\t \n\t\tint err;\n\n\t\terr = dbuf_hold_impl(dn, level + 1,\n\t\t    blkid >> epbs, fail_sparse, FALSE, NULL, parentp);\n\n\t\tif (err)\n\t\t\treturn (err);\n\t\terr = dbuf_read(*parentp, NULL,\n\t\t    (DB_RF_HAVESTRUCT | DB_RF_NOPREFETCH | DB_RF_CANFAIL));\n\t\tif (err) {\n\t\t\tdbuf_rele(*parentp, NULL);\n\t\t\t*parentp = NULL;\n\t\t\treturn (err);\n\t\t}\n\t\trw_enter(&(*parentp)->db_rwlock, RW_READER);\n\t\t*bpp = ((blkptr_t *)(*parentp)->db.db_data) +\n\t\t    (blkid & ((1ULL << epbs) - 1));\n\t\tif (blkid > (dn->dn_phys->dn_maxblkid >> (level * epbs)))\n\t\t\tASSERT(BP_IS_HOLE(*bpp));\n\t\trw_exit(&(*parentp)->db_rwlock);\n\t\treturn (0);\n\t} else {\n\t\t \n\t\tASSERT3U(level, ==, nlevels-1);\n\t\tASSERT(dn->dn_phys->dn_nblkptr == 0 ||\n\t\t    blkid < dn->dn_phys->dn_nblkptr);\n\t\tif (dn->dn_dbuf) {\n\t\t\tdbuf_add_ref(dn->dn_dbuf, NULL);\n\t\t\t*parentp = dn->dn_dbuf;\n\t\t}\n\t\t*bpp = &dn->dn_phys->dn_blkptr[blkid];\n\t\treturn (0);\n\t}\n}\n\nstatic dmu_buf_impl_t *\ndbuf_create(dnode_t *dn, uint8_t level, uint64_t blkid,\n    dmu_buf_impl_t *parent, blkptr_t *blkptr, uint64_t hash)\n{\n\tobjset_t *os = dn->dn_objset;\n\tdmu_buf_impl_t *db, *odb;\n\n\tASSERT(RW_LOCK_HELD(&dn->dn_struct_rwlock));\n\tASSERT(dn->dn_type != DMU_OT_NONE);\n\n\tdb = kmem_cache_alloc(dbuf_kmem_cache, KM_SLEEP);\n\n\tlist_create(&db->db_dirty_records, sizeof (dbuf_dirty_record_t),\n\t    offsetof(dbuf_dirty_record_t, dr_dbuf_node));\n\n\tdb->db_objset = os;\n\tdb->db.db_object = dn->dn_object;\n\tdb->db_level = level;\n\tdb->db_blkid = blkid;\n\tdb->db_dirtycnt = 0;\n\tdb->db_dnode_handle = dn->dn_handle;\n\tdb->db_parent = parent;\n\tdb->db_blkptr = blkptr;\n\tdb->db_hash = hash;\n\n\tdb->db_user = NULL;\n\tdb->db_user_immediate_evict = FALSE;\n\tdb->db_freed_in_flight = FALSE;\n\tdb->db_pending_evict = FALSE;\n\n\tif (blkid == DMU_BONUS_BLKID) {\n\t\tASSERT3P(parent, ==, dn->dn_dbuf);\n\t\tdb->db.db_size = DN_SLOTS_TO_BONUSLEN(dn->dn_num_slots) -\n\t\t    (dn->dn_nblkptr-1) * sizeof (blkptr_t);\n\t\tASSERT3U(db->db.db_size, >=, dn->dn_bonuslen);\n\t\tdb->db.db_offset = DMU_BONUS_BLKID;\n\t\tdb->db_state = DB_UNCACHED;\n\t\tDTRACE_SET_STATE(db, \"bonus buffer created\");\n\t\tdb->db_caching_status = DB_NO_CACHE;\n\t\t \n\t\tarc_space_consume(sizeof (dmu_buf_impl_t), ARC_SPACE_DBUF);\n\t\treturn (db);\n\t} else if (blkid == DMU_SPILL_BLKID) {\n\t\tdb->db.db_size = (blkptr != NULL) ?\n\t\t    BP_GET_LSIZE(blkptr) : SPA_MINBLOCKSIZE;\n\t\tdb->db.db_offset = 0;\n\t} else {\n\t\tint blocksize =\n\t\t    db->db_level ? 1 << dn->dn_indblkshift : dn->dn_datablksz;\n\t\tdb->db.db_size = blocksize;\n\t\tdb->db.db_offset = db->db_blkid * blocksize;\n\t}\n\n\t \n\tmutex_enter(&dn->dn_dbufs_mtx);\n\tdb->db_state = DB_EVICTING;  \n\tif ((odb = dbuf_hash_insert(db)) != NULL) {\n\t\t \n\t\tmutex_exit(&dn->dn_dbufs_mtx);\n\t\tkmem_cache_free(dbuf_kmem_cache, db);\n\t\tDBUF_STAT_BUMP(hash_insert_race);\n\t\treturn (odb);\n\t}\n\tavl_add(&dn->dn_dbufs, db);\n\n\tdb->db_state = DB_UNCACHED;\n\tDTRACE_SET_STATE(db, \"regular buffer created\");\n\tdb->db_caching_status = DB_NO_CACHE;\n\tmutex_exit(&dn->dn_dbufs_mtx);\n\tarc_space_consume(sizeof (dmu_buf_impl_t), ARC_SPACE_DBUF);\n\n\tif (parent && parent != dn->dn_dbuf)\n\t\tdbuf_add_ref(parent, db);\n\n\tASSERT(dn->dn_object == DMU_META_DNODE_OBJECT ||\n\t    zfs_refcount_count(&dn->dn_holds) > 0);\n\t(void) zfs_refcount_add(&dn->dn_holds, db);\n\n\tdprintf_dbuf(db, \"db=%p\\n\", db);\n\n\treturn (db);\n}\n\n \nint\ndbuf_dnode_findbp(dnode_t *dn, uint64_t level, uint64_t blkid,\n    blkptr_t *bp, uint16_t *datablkszsec, uint8_t *indblkshift)\n{\n\tdmu_buf_impl_t *dbp = NULL;\n\tblkptr_t *bp2;\n\tint err = 0;\n\tASSERT(RW_LOCK_HELD(&dn->dn_struct_rwlock));\n\n\terr = dbuf_findbp(dn, level, blkid, B_FALSE, &dbp, &bp2);\n\tif (err == 0) {\n\t\tASSERT3P(bp2, !=, NULL);\n\t\t*bp = *bp2;\n\t\tif (dbp != NULL)\n\t\t\tdbuf_rele(dbp, NULL);\n\t\tif (datablkszsec != NULL)\n\t\t\t*datablkszsec = dn->dn_phys->dn_datablkszsec;\n\t\tif (indblkshift != NULL)\n\t\t\t*indblkshift = dn->dn_phys->dn_indblkshift;\n\t}\n\n\treturn (err);\n}\n\ntypedef struct dbuf_prefetch_arg {\n\tspa_t *dpa_spa;\t \n\tzbookmark_phys_t dpa_zb;  \n\tint dpa_epbs;  \n\tint dpa_curlevel;  \n\tdnode_t *dpa_dnode;  \n\tzio_priority_t dpa_prio;  \n\tzio_t *dpa_zio;  \n\tarc_flags_t dpa_aflags;  \n\tdbuf_prefetch_fn dpa_cb;  \n\tvoid *dpa_arg;  \n} dbuf_prefetch_arg_t;\n\nstatic void\ndbuf_prefetch_fini(dbuf_prefetch_arg_t *dpa, boolean_t io_done)\n{\n\tif (dpa->dpa_cb != NULL) {\n\t\tdpa->dpa_cb(dpa->dpa_arg, dpa->dpa_zb.zb_level,\n\t\t    dpa->dpa_zb.zb_blkid, io_done);\n\t}\n\tkmem_free(dpa, sizeof (*dpa));\n}\n\nstatic void\ndbuf_issue_final_prefetch_done(zio_t *zio, const zbookmark_phys_t *zb,\n    const blkptr_t *iobp, arc_buf_t *abuf, void *private)\n{\n\t(void) zio, (void) zb, (void) iobp;\n\tdbuf_prefetch_arg_t *dpa = private;\n\n\tif (abuf != NULL)\n\t\tarc_buf_destroy(abuf, private);\n\n\tdbuf_prefetch_fini(dpa, B_TRUE);\n}\n\n \nstatic void\ndbuf_issue_final_prefetch(dbuf_prefetch_arg_t *dpa, blkptr_t *bp)\n{\n\tASSERT(!BP_IS_REDACTED(bp) ||\n\t    dsl_dataset_feature_is_active(\n\t    dpa->dpa_dnode->dn_objset->os_dsl_dataset,\n\t    SPA_FEATURE_REDACTED_DATASETS));\n\n\tif (BP_IS_HOLE(bp) || BP_IS_EMBEDDED(bp) || BP_IS_REDACTED(bp))\n\t\treturn (dbuf_prefetch_fini(dpa, B_FALSE));\n\n\tint zio_flags = ZIO_FLAG_CANFAIL | ZIO_FLAG_SPECULATIVE;\n\tarc_flags_t aflags =\n\t    dpa->dpa_aflags | ARC_FLAG_NOWAIT | ARC_FLAG_PREFETCH |\n\t    ARC_FLAG_NO_BUF;\n\n\t \n\tif (BP_GET_TYPE(bp) == DMU_OT_DNODE && BP_IS_PROTECTED(bp) &&\n\t    dpa->dpa_curlevel == 0)\n\t\tzio_flags |= ZIO_FLAG_RAW;\n\n\tASSERT3U(dpa->dpa_curlevel, ==, BP_GET_LEVEL(bp));\n\tASSERT3U(dpa->dpa_curlevel, ==, dpa->dpa_zb.zb_level);\n\tASSERT(dpa->dpa_zio != NULL);\n\t(void) arc_read(dpa->dpa_zio, dpa->dpa_spa, bp,\n\t    dbuf_issue_final_prefetch_done, dpa,\n\t    dpa->dpa_prio, zio_flags, &aflags, &dpa->dpa_zb);\n}\n\n \nstatic void\ndbuf_prefetch_indirect_done(zio_t *zio, const zbookmark_phys_t *zb,\n    const blkptr_t *iobp, arc_buf_t *abuf, void *private)\n{\n\t(void) zb, (void) iobp;\n\tdbuf_prefetch_arg_t *dpa = private;\n\n\tASSERT3S(dpa->dpa_zb.zb_level, <, dpa->dpa_curlevel);\n\tASSERT3S(dpa->dpa_curlevel, >, 0);\n\n\tif (abuf == NULL) {\n\t\tASSERT(zio == NULL || zio->io_error != 0);\n\t\tdbuf_prefetch_fini(dpa, B_TRUE);\n\t\treturn;\n\t}\n\tASSERT(zio == NULL || zio->io_error == 0);\n\n\t \n\tif (zio != NULL) {\n\t\tASSERT3S(BP_GET_LEVEL(zio->io_bp), ==, dpa->dpa_curlevel);\n\t\tif (zio->io_flags & ZIO_FLAG_RAW_COMPRESS) {\n\t\t\tASSERT3U(BP_GET_PSIZE(zio->io_bp), ==, zio->io_size);\n\t\t} else {\n\t\t\tASSERT3U(BP_GET_LSIZE(zio->io_bp), ==, zio->io_size);\n\t\t}\n\t\tASSERT3P(zio->io_spa, ==, dpa->dpa_spa);\n\n\t\tdpa->dpa_dnode = NULL;\n\t} else if (dpa->dpa_dnode != NULL) {\n\t\tuint64_t curblkid = dpa->dpa_zb.zb_blkid >>\n\t\t    (dpa->dpa_epbs * (dpa->dpa_curlevel -\n\t\t    dpa->dpa_zb.zb_level));\n\t\tdmu_buf_impl_t *db = dbuf_hold_level(dpa->dpa_dnode,\n\t\t    dpa->dpa_curlevel, curblkid, FTAG);\n\t\tif (db == NULL) {\n\t\t\tarc_buf_destroy(abuf, private);\n\t\t\tdbuf_prefetch_fini(dpa, B_TRUE);\n\t\t\treturn;\n\t\t}\n\t\t(void) dbuf_read(db, NULL,\n\t\t    DB_RF_MUST_SUCCEED | DB_RF_NOPREFETCH | DB_RF_HAVESTRUCT);\n\t\tdbuf_rele(db, FTAG);\n\t}\n\n\tdpa->dpa_curlevel--;\n\tuint64_t nextblkid = dpa->dpa_zb.zb_blkid >>\n\t    (dpa->dpa_epbs * (dpa->dpa_curlevel - dpa->dpa_zb.zb_level));\n\tblkptr_t *bp = ((blkptr_t *)abuf->b_data) +\n\t    P2PHASE(nextblkid, 1ULL << dpa->dpa_epbs);\n\n\tASSERT(!BP_IS_REDACTED(bp) || (dpa->dpa_dnode &&\n\t    dsl_dataset_feature_is_active(\n\t    dpa->dpa_dnode->dn_objset->os_dsl_dataset,\n\t    SPA_FEATURE_REDACTED_DATASETS)));\n\tif (BP_IS_HOLE(bp) || BP_IS_REDACTED(bp)) {\n\t\tarc_buf_destroy(abuf, private);\n\t\tdbuf_prefetch_fini(dpa, B_TRUE);\n\t\treturn;\n\t} else if (dpa->dpa_curlevel == dpa->dpa_zb.zb_level) {\n\t\tASSERT3U(nextblkid, ==, dpa->dpa_zb.zb_blkid);\n\t\tdbuf_issue_final_prefetch(dpa, bp);\n\t} else {\n\t\tarc_flags_t iter_aflags = ARC_FLAG_NOWAIT;\n\t\tzbookmark_phys_t zb;\n\n\t\t \n\t\tif (dpa->dpa_aflags & ARC_FLAG_L2CACHE)\n\t\t\titer_aflags |= ARC_FLAG_L2CACHE;\n\n\t\tASSERT3U(dpa->dpa_curlevel, ==, BP_GET_LEVEL(bp));\n\n\t\tSET_BOOKMARK(&zb, dpa->dpa_zb.zb_objset,\n\t\t    dpa->dpa_zb.zb_object, dpa->dpa_curlevel, nextblkid);\n\n\t\t(void) arc_read(dpa->dpa_zio, dpa->dpa_spa,\n\t\t    bp, dbuf_prefetch_indirect_done, dpa,\n\t\t    ZIO_PRIORITY_SYNC_READ,\n\t\t    ZIO_FLAG_CANFAIL | ZIO_FLAG_SPECULATIVE,\n\t\t    &iter_aflags, &zb);\n\t}\n\n\tarc_buf_destroy(abuf, private);\n}\n\n \nint\ndbuf_prefetch_impl(dnode_t *dn, int64_t level, uint64_t blkid,\n    zio_priority_t prio, arc_flags_t aflags, dbuf_prefetch_fn cb,\n    void *arg)\n{\n\tblkptr_t bp;\n\tint epbs, nlevels, curlevel;\n\tuint64_t curblkid;\n\n\tASSERT(blkid != DMU_BONUS_BLKID);\n\tASSERT(RW_LOCK_HELD(&dn->dn_struct_rwlock));\n\n\tif (blkid > dn->dn_maxblkid)\n\t\tgoto no_issue;\n\n\tif (level == 0 && dnode_block_freed(dn, blkid))\n\t\tgoto no_issue;\n\n\t \n\tnlevels = dn->dn_phys->dn_nlevels;\n\tif (level >= nlevels || dn->dn_phys->dn_nblkptr == 0)\n\t\tgoto no_issue;\n\n\tepbs = dn->dn_phys->dn_indblkshift - SPA_BLKPTRSHIFT;\n\tif (dn->dn_phys->dn_maxblkid < blkid << (epbs * level))\n\t\tgoto no_issue;\n\n\tdmu_buf_impl_t *db = dbuf_find(dn->dn_objset, dn->dn_object,\n\t    level, blkid, NULL);\n\tif (db != NULL) {\n\t\tmutex_exit(&db->db_mtx);\n\t\t \n\t\tgoto no_issue;\n\t}\n\n\t \n\tcurlevel = level;\n\tcurblkid = blkid;\n\twhile (curlevel < nlevels - 1) {\n\t\tint parent_level = curlevel + 1;\n\t\tuint64_t parent_blkid = curblkid >> epbs;\n\t\tdmu_buf_impl_t *db;\n\n\t\tif (dbuf_hold_impl(dn, parent_level, parent_blkid,\n\t\t    FALSE, TRUE, FTAG, &db) == 0) {\n\t\t\tblkptr_t *bpp = db->db_buf->b_data;\n\t\t\tbp = bpp[P2PHASE(curblkid, 1 << epbs)];\n\t\t\tdbuf_rele(db, FTAG);\n\t\t\tbreak;\n\t\t}\n\n\t\tcurlevel = parent_level;\n\t\tcurblkid = parent_blkid;\n\t}\n\n\tif (curlevel == nlevels - 1) {\n\t\t \n\t\tASSERT3U(curblkid, <, dn->dn_phys->dn_nblkptr);\n\t\tbp = dn->dn_phys->dn_blkptr[curblkid];\n\t}\n\tASSERT(!BP_IS_REDACTED(&bp) ||\n\t    dsl_dataset_feature_is_active(dn->dn_objset->os_dsl_dataset,\n\t    SPA_FEATURE_REDACTED_DATASETS));\n\tif (BP_IS_HOLE(&bp) || BP_IS_REDACTED(&bp))\n\t\tgoto no_issue;\n\n\tASSERT3U(curlevel, ==, BP_GET_LEVEL(&bp));\n\n\tzio_t *pio = zio_root(dmu_objset_spa(dn->dn_objset), NULL, NULL,\n\t    ZIO_FLAG_CANFAIL);\n\n\tdbuf_prefetch_arg_t *dpa = kmem_zalloc(sizeof (*dpa), KM_SLEEP);\n\tdsl_dataset_t *ds = dn->dn_objset->os_dsl_dataset;\n\tSET_BOOKMARK(&dpa->dpa_zb, ds != NULL ? ds->ds_object : DMU_META_OBJSET,\n\t    dn->dn_object, level, blkid);\n\tdpa->dpa_curlevel = curlevel;\n\tdpa->dpa_prio = prio;\n\tdpa->dpa_aflags = aflags;\n\tdpa->dpa_spa = dn->dn_objset->os_spa;\n\tdpa->dpa_dnode = dn;\n\tdpa->dpa_epbs = epbs;\n\tdpa->dpa_zio = pio;\n\tdpa->dpa_cb = cb;\n\tdpa->dpa_arg = arg;\n\n\tif (!DNODE_LEVEL_IS_CACHEABLE(dn, level))\n\t\tdpa->dpa_aflags |= ARC_FLAG_UNCACHED;\n\telse if (dnode_level_is_l2cacheable(&bp, dn, level))\n\t\tdpa->dpa_aflags |= ARC_FLAG_L2CACHE;\n\n\t \n\tif (curlevel == level) {\n\t\tASSERT3U(curblkid, ==, blkid);\n\t\tdbuf_issue_final_prefetch(dpa, &bp);\n\t} else {\n\t\tarc_flags_t iter_aflags = ARC_FLAG_NOWAIT;\n\t\tzbookmark_phys_t zb;\n\n\t\t \n\t\tif (dnode_level_is_l2cacheable(&bp, dn, level))\n\t\t\titer_aflags |= ARC_FLAG_L2CACHE;\n\n\t\tSET_BOOKMARK(&zb, ds != NULL ? ds->ds_object : DMU_META_OBJSET,\n\t\t    dn->dn_object, curlevel, curblkid);\n\t\t(void) arc_read(dpa->dpa_zio, dpa->dpa_spa,\n\t\t    &bp, dbuf_prefetch_indirect_done, dpa,\n\t\t    ZIO_PRIORITY_SYNC_READ,\n\t\t    ZIO_FLAG_CANFAIL | ZIO_FLAG_SPECULATIVE,\n\t\t    &iter_aflags, &zb);\n\t}\n\t \n\tzio_nowait(pio);\n\treturn (1);\nno_issue:\n\tif (cb != NULL)\n\t\tcb(arg, level, blkid, B_FALSE);\n\treturn (0);\n}\n\nint\ndbuf_prefetch(dnode_t *dn, int64_t level, uint64_t blkid, zio_priority_t prio,\n    arc_flags_t aflags)\n{\n\n\treturn (dbuf_prefetch_impl(dn, level, blkid, prio, aflags, NULL, NULL));\n}\n\n \nnoinline static void\ndbuf_hold_copy(dnode_t *dn, dmu_buf_impl_t *db)\n{\n\tdbuf_dirty_record_t *dr = db->db_data_pending;\n\tarc_buf_t *data = dr->dt.dl.dr_data;\n\tenum zio_compress compress_type = arc_get_compression(data);\n\tuint8_t complevel = arc_get_complevel(data);\n\n\tif (arc_is_encrypted(data)) {\n\t\tboolean_t byteorder;\n\t\tuint8_t salt[ZIO_DATA_SALT_LEN];\n\t\tuint8_t iv[ZIO_DATA_IV_LEN];\n\t\tuint8_t mac[ZIO_DATA_MAC_LEN];\n\n\t\tarc_get_raw_params(data, &byteorder, salt, iv, mac);\n\t\tdbuf_set_data(db, arc_alloc_raw_buf(dn->dn_objset->os_spa, db,\n\t\t    dmu_objset_id(dn->dn_objset), byteorder, salt, iv, mac,\n\t\t    dn->dn_type, arc_buf_size(data), arc_buf_lsize(data),\n\t\t    compress_type, complevel));\n\t} else if (compress_type != ZIO_COMPRESS_OFF) {\n\t\tdbuf_set_data(db, arc_alloc_compressed_buf(\n\t\t    dn->dn_objset->os_spa, db, arc_buf_size(data),\n\t\t    arc_buf_lsize(data), compress_type, complevel));\n\t} else {\n\t\tdbuf_set_data(db, arc_alloc_buf(dn->dn_objset->os_spa, db,\n\t\t    DBUF_GET_BUFC_TYPE(db), db->db.db_size));\n\t}\n\n\trw_enter(&db->db_rwlock, RW_WRITER);\n\tmemcpy(db->db.db_data, data->b_data, arc_buf_size(data));\n\trw_exit(&db->db_rwlock);\n}\n\n \nint\ndbuf_hold_impl(dnode_t *dn, uint8_t level, uint64_t blkid,\n    boolean_t fail_sparse, boolean_t fail_uncached,\n    const void *tag, dmu_buf_impl_t **dbp)\n{\n\tdmu_buf_impl_t *db, *parent = NULL;\n\tuint64_t hv;\n\n\t \n\tspa_t *spa = dn->dn_objset->os_spa;\n\tdsl_pool_t *dp = spa->spa_dsl_pool;\n\tif (dp != NULL) {\n\t\tASSERT(!MUTEX_HELD(&dp->dp_tx.tx_sync_lock));\n\t}\n\n\tASSERT(blkid != DMU_BONUS_BLKID);\n\tASSERT(RW_LOCK_HELD(&dn->dn_struct_rwlock));\n\tASSERT3U(dn->dn_nlevels, >, level);\n\n\t*dbp = NULL;\n\n\t \n\tdb = dbuf_find(dn->dn_objset, dn->dn_object, level, blkid, &hv);\n\n\tif (db == NULL) {\n\t\tblkptr_t *bp = NULL;\n\t\tint err;\n\n\t\tif (fail_uncached)\n\t\t\treturn (SET_ERROR(ENOENT));\n\n\t\tASSERT3P(parent, ==, NULL);\n\t\terr = dbuf_findbp(dn, level, blkid, fail_sparse, &parent, &bp);\n\t\tif (fail_sparse) {\n\t\t\tif (err == 0 && bp && BP_IS_HOLE(bp))\n\t\t\t\terr = SET_ERROR(ENOENT);\n\t\t\tif (err) {\n\t\t\t\tif (parent)\n\t\t\t\t\tdbuf_rele(parent, NULL);\n\t\t\t\treturn (err);\n\t\t\t}\n\t\t}\n\t\tif (err && err != ENOENT)\n\t\t\treturn (err);\n\t\tdb = dbuf_create(dn, level, blkid, parent, bp, hv);\n\t}\n\n\tif (fail_uncached && db->db_state != DB_CACHED) {\n\t\tmutex_exit(&db->db_mtx);\n\t\treturn (SET_ERROR(ENOENT));\n\t}\n\n\tif (db->db_buf != NULL) {\n\t\tarc_buf_access(db->db_buf);\n\t\tASSERT3P(db->db.db_data, ==, db->db_buf->b_data);\n\t}\n\n\tASSERT(db->db_buf == NULL || arc_referenced(db->db_buf));\n\n\t \n\tif (db->db_level == 0 && db->db_blkid != DMU_BONUS_BLKID &&\n\t    dn->dn_object != DMU_META_DNODE_OBJECT &&\n\t    db->db_state == DB_CACHED && db->db_data_pending) {\n\t\tdbuf_dirty_record_t *dr = db->db_data_pending;\n\t\tif (dr->dt.dl.dr_data == db->db_buf) {\n\t\t\tASSERT3P(db->db_buf, !=, NULL);\n\t\t\tdbuf_hold_copy(dn, db);\n\t\t}\n\t}\n\n\tif (multilist_link_active(&db->db_cache_link)) {\n\t\tASSERT(zfs_refcount_is_zero(&db->db_holds));\n\t\tASSERT(db->db_caching_status == DB_DBUF_CACHE ||\n\t\t    db->db_caching_status == DB_DBUF_METADATA_CACHE);\n\n\t\tmultilist_remove(&dbuf_caches[db->db_caching_status].cache, db);\n\t\t(void) zfs_refcount_remove_many(\n\t\t    &dbuf_caches[db->db_caching_status].size,\n\t\t    db->db.db_size, db);\n\n\t\tif (db->db_caching_status == DB_DBUF_METADATA_CACHE) {\n\t\t\tDBUF_STAT_BUMPDOWN(metadata_cache_count);\n\t\t} else {\n\t\t\tDBUF_STAT_BUMPDOWN(cache_levels[db->db_level]);\n\t\t\tDBUF_STAT_BUMPDOWN(cache_count);\n\t\t\tDBUF_STAT_DECR(cache_levels_bytes[db->db_level],\n\t\t\t    db->db.db_size);\n\t\t}\n\t\tdb->db_caching_status = DB_NO_CACHE;\n\t}\n\t(void) zfs_refcount_add(&db->db_holds, tag);\n\tDBUF_VERIFY(db);\n\tmutex_exit(&db->db_mtx);\n\n\t \n\tif (parent)\n\t\tdbuf_rele(parent, NULL);\n\n\tASSERT3P(DB_DNODE(db), ==, dn);\n\tASSERT3U(db->db_blkid, ==, blkid);\n\tASSERT3U(db->db_level, ==, level);\n\t*dbp = db;\n\n\treturn (0);\n}\n\ndmu_buf_impl_t *\ndbuf_hold(dnode_t *dn, uint64_t blkid, const void *tag)\n{\n\treturn (dbuf_hold_level(dn, 0, blkid, tag));\n}\n\ndmu_buf_impl_t *\ndbuf_hold_level(dnode_t *dn, int level, uint64_t blkid, const void *tag)\n{\n\tdmu_buf_impl_t *db;\n\tint err = dbuf_hold_impl(dn, level, blkid, FALSE, FALSE, tag, &db);\n\treturn (err ? NULL : db);\n}\n\nvoid\ndbuf_create_bonus(dnode_t *dn)\n{\n\tASSERT(RW_WRITE_HELD(&dn->dn_struct_rwlock));\n\n\tASSERT(dn->dn_bonus == NULL);\n\tdn->dn_bonus = dbuf_create(dn, 0, DMU_BONUS_BLKID, dn->dn_dbuf, NULL,\n\t    dbuf_hash(dn->dn_objset, dn->dn_object, 0, DMU_BONUS_BLKID));\n}\n\nint\ndbuf_spill_set_blksz(dmu_buf_t *db_fake, uint64_t blksz, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\n\tif (db->db_blkid != DMU_SPILL_BLKID)\n\t\treturn (SET_ERROR(ENOTSUP));\n\tif (blksz == 0)\n\t\tblksz = SPA_MINBLOCKSIZE;\n\tASSERT3U(blksz, <=, spa_maxblocksize(dmu_objset_spa(db->db_objset)));\n\tblksz = P2ROUNDUP(blksz, SPA_MINBLOCKSIZE);\n\n\tdbuf_new_size(db, blksz, tx);\n\n\treturn (0);\n}\n\nvoid\ndbuf_rm_spill(dnode_t *dn, dmu_tx_t *tx)\n{\n\tdbuf_free_range(dn, DMU_SPILL_BLKID, DMU_SPILL_BLKID, tx);\n}\n\n#pragma weak dmu_buf_add_ref = dbuf_add_ref\nvoid\ndbuf_add_ref(dmu_buf_impl_t *db, const void *tag)\n{\n\tint64_t holds = zfs_refcount_add(&db->db_holds, tag);\n\tVERIFY3S(holds, >, 1);\n}\n\n#pragma weak dmu_buf_try_add_ref = dbuf_try_add_ref\nboolean_t\ndbuf_try_add_ref(dmu_buf_t *db_fake, objset_t *os, uint64_t obj, uint64_t blkid,\n    const void *tag)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\tdmu_buf_impl_t *found_db;\n\tboolean_t result = B_FALSE;\n\n\tif (blkid == DMU_BONUS_BLKID)\n\t\tfound_db = dbuf_find_bonus(os, obj);\n\telse\n\t\tfound_db = dbuf_find(os, obj, 0, blkid, NULL);\n\n\tif (found_db != NULL) {\n\t\tif (db == found_db && dbuf_refcount(db) > db->db_dirtycnt) {\n\t\t\t(void) zfs_refcount_add(&db->db_holds, tag);\n\t\t\tresult = B_TRUE;\n\t\t}\n\t\tmutex_exit(&found_db->db_mtx);\n\t}\n\treturn (result);\n}\n\n \nvoid\ndbuf_rele(dmu_buf_impl_t *db, const void *tag)\n{\n\tmutex_enter(&db->db_mtx);\n\tdbuf_rele_and_unlock(db, tag, B_FALSE);\n}\n\nvoid\ndmu_buf_rele(dmu_buf_t *db, const void *tag)\n{\n\tdbuf_rele((dmu_buf_impl_t *)db, tag);\n}\n\n \nvoid\ndbuf_rele_and_unlock(dmu_buf_impl_t *db, const void *tag, boolean_t evicting)\n{\n\tint64_t holds;\n\tuint64_t size;\n\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\tDBUF_VERIFY(db);\n\n\t \n\tholds = zfs_refcount_remove(&db->db_holds, tag);\n\tASSERT(holds >= 0);\n\n\t \n\tif (db->db_buf != NULL &&\n\t    holds == (db->db_level == 0 ? db->db_dirtycnt : 0)) {\n\t\tarc_buf_freeze(db->db_buf);\n\t}\n\n\tif (holds == db->db_dirtycnt &&\n\t    db->db_level == 0 && db->db_user_immediate_evict)\n\t\tdbuf_evict_user(db);\n\n\tif (holds == 0) {\n\t\tif (db->db_blkid == DMU_BONUS_BLKID) {\n\t\t\tdnode_t *dn;\n\t\t\tboolean_t evict_dbuf = db->db_pending_evict;\n\n\t\t\t \n\t\t\tDB_DNODE_ENTER(db);\n\n\t\t\tdn = DB_DNODE(db);\n\t\t\tatomic_dec_32(&dn->dn_dbufs_count);\n\n\t\t\t \n\t\t\tDB_DNODE_EXIT(db);\n\n\t\t\t \n\t\t\tmutex_exit(&db->db_mtx);\n\n\t\t\tif (evict_dbuf)\n\t\t\t\tdnode_evict_bonus(dn);\n\n\t\t\tdnode_rele(dn, db);\n\t\t} else if (db->db_buf == NULL) {\n\t\t\t \n\t\t\tASSERT(db->db_state == DB_UNCACHED ||\n\t\t\t    db->db_state == DB_NOFILL);\n\t\t\tdbuf_destroy(db);\n\t\t} else if (arc_released(db->db_buf)) {\n\t\t\t \n\t\t\tdbuf_destroy(db);\n\t\t} else if (!(DBUF_IS_CACHEABLE(db) || db->db_partial_read) ||\n\t\t    db->db_pending_evict) {\n\t\t\tdbuf_destroy(db);\n\t\t} else if (!multilist_link_active(&db->db_cache_link)) {\n\t\t\tASSERT3U(db->db_caching_status, ==, DB_NO_CACHE);\n\n\t\t\tdbuf_cached_state_t dcs =\n\t\t\t    dbuf_include_in_metadata_cache(db) ?\n\t\t\t    DB_DBUF_METADATA_CACHE : DB_DBUF_CACHE;\n\t\t\tdb->db_caching_status = dcs;\n\n\t\t\tmultilist_insert(&dbuf_caches[dcs].cache, db);\n\t\t\tuint64_t db_size = db->db.db_size;\n\t\t\tsize = zfs_refcount_add_many(\n\t\t\t    &dbuf_caches[dcs].size, db_size, db);\n\t\t\tuint8_t db_level = db->db_level;\n\t\t\tmutex_exit(&db->db_mtx);\n\n\t\t\tif (dcs == DB_DBUF_METADATA_CACHE) {\n\t\t\t\tDBUF_STAT_BUMP(metadata_cache_count);\n\t\t\t\tDBUF_STAT_MAX(metadata_cache_size_bytes_max,\n\t\t\t\t    size);\n\t\t\t} else {\n\t\t\t\tDBUF_STAT_BUMP(cache_count);\n\t\t\t\tDBUF_STAT_MAX(cache_size_bytes_max, size);\n\t\t\t\tDBUF_STAT_BUMP(cache_levels[db_level]);\n\t\t\t\tDBUF_STAT_INCR(cache_levels_bytes[db_level],\n\t\t\t\t    db_size);\n\t\t\t}\n\n\t\t\tif (dcs == DB_DBUF_CACHE && !evicting)\n\t\t\t\tdbuf_evict_notify(size);\n\t\t}\n\t} else {\n\t\tmutex_exit(&db->db_mtx);\n\t}\n\n}\n\n#pragma weak dmu_buf_refcount = dbuf_refcount\nuint64_t\ndbuf_refcount(dmu_buf_impl_t *db)\n{\n\treturn (zfs_refcount_count(&db->db_holds));\n}\n\nuint64_t\ndmu_buf_user_refcount(dmu_buf_t *db_fake)\n{\n\tuint64_t holds;\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\n\tmutex_enter(&db->db_mtx);\n\tASSERT3U(zfs_refcount_count(&db->db_holds), >=, db->db_dirtycnt);\n\tholds = zfs_refcount_count(&db->db_holds) - db->db_dirtycnt;\n\tmutex_exit(&db->db_mtx);\n\n\treturn (holds);\n}\n\nvoid *\ndmu_buf_replace_user(dmu_buf_t *db_fake, dmu_buf_user_t *old_user,\n    dmu_buf_user_t *new_user)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\n\tmutex_enter(&db->db_mtx);\n\tdbuf_verify_user(db, DBVU_NOT_EVICTING);\n\tif (db->db_user == old_user)\n\t\tdb->db_user = new_user;\n\telse\n\t\told_user = db->db_user;\n\tdbuf_verify_user(db, DBVU_NOT_EVICTING);\n\tmutex_exit(&db->db_mtx);\n\n\treturn (old_user);\n}\n\nvoid *\ndmu_buf_set_user(dmu_buf_t *db_fake, dmu_buf_user_t *user)\n{\n\treturn (dmu_buf_replace_user(db_fake, NULL, user));\n}\n\nvoid *\ndmu_buf_set_user_ie(dmu_buf_t *db_fake, dmu_buf_user_t *user)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\n\tdb->db_user_immediate_evict = TRUE;\n\treturn (dmu_buf_set_user(db_fake, user));\n}\n\nvoid *\ndmu_buf_remove_user(dmu_buf_t *db_fake, dmu_buf_user_t *user)\n{\n\treturn (dmu_buf_replace_user(db_fake, user, NULL));\n}\n\nvoid *\ndmu_buf_get_user(dmu_buf_t *db_fake)\n{\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)db_fake;\n\n\tdbuf_verify_user(db, DBVU_NOT_EVICTING);\n\treturn (db->db_user);\n}\n\nvoid\ndmu_buf_user_evict_wait(void)\n{\n\ttaskq_wait(dbu_evict_taskq);\n}\n\nblkptr_t *\ndmu_buf_get_blkptr(dmu_buf_t *db)\n{\n\tdmu_buf_impl_t *dbi = (dmu_buf_impl_t *)db;\n\treturn (dbi->db_blkptr);\n}\n\nobjset_t *\ndmu_buf_get_objset(dmu_buf_t *db)\n{\n\tdmu_buf_impl_t *dbi = (dmu_buf_impl_t *)db;\n\treturn (dbi->db_objset);\n}\n\ndnode_t *\ndmu_buf_dnode_enter(dmu_buf_t *db)\n{\n\tdmu_buf_impl_t *dbi = (dmu_buf_impl_t *)db;\n\tDB_DNODE_ENTER(dbi);\n\treturn (DB_DNODE(dbi));\n}\n\nvoid\ndmu_buf_dnode_exit(dmu_buf_t *db)\n{\n\tdmu_buf_impl_t *dbi = (dmu_buf_impl_t *)db;\n\tDB_DNODE_EXIT(dbi);\n}\n\nstatic void\ndbuf_check_blkptr(dnode_t *dn, dmu_buf_impl_t *db)\n{\n\t \n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\n\tif (db->db_blkptr != NULL)\n\t\treturn;\n\n\tif (db->db_blkid == DMU_SPILL_BLKID) {\n\t\tdb->db_blkptr = DN_SPILL_BLKPTR(dn->dn_phys);\n\t\tBP_ZERO(db->db_blkptr);\n\t\treturn;\n\t}\n\tif (db->db_level == dn->dn_phys->dn_nlevels-1) {\n\t\t \n\t\tASSERT(db->db_blkid < dn->dn_phys->dn_nblkptr);\n\t\tASSERT(db->db_parent == NULL);\n\t\tdb->db_parent = dn->dn_dbuf;\n\t\tdb->db_blkptr = &dn->dn_phys->dn_blkptr[db->db_blkid];\n\t\tDBUF_VERIFY(db);\n\t} else {\n\t\tdmu_buf_impl_t *parent = db->db_parent;\n\t\tint epbs = dn->dn_phys->dn_indblkshift - SPA_BLKPTRSHIFT;\n\n\t\tASSERT(dn->dn_phys->dn_nlevels > 1);\n\t\tif (parent == NULL) {\n\t\t\tmutex_exit(&db->db_mtx);\n\t\t\trw_enter(&dn->dn_struct_rwlock, RW_READER);\n\t\t\tparent = dbuf_hold_level(dn, db->db_level + 1,\n\t\t\t    db->db_blkid >> epbs, db);\n\t\t\trw_exit(&dn->dn_struct_rwlock);\n\t\t\tmutex_enter(&db->db_mtx);\n\t\t\tdb->db_parent = parent;\n\t\t}\n\t\tdb->db_blkptr = (blkptr_t *)parent->db.db_data +\n\t\t    (db->db_blkid & ((1ULL << epbs) - 1));\n\t\tDBUF_VERIFY(db);\n\t}\n}\n\nstatic void\ndbuf_sync_bonus(dbuf_dirty_record_t *dr, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\tvoid *data = dr->dt.dl.dr_data;\n\n\tASSERT0(db->db_level);\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\tASSERT(db->db_blkid == DMU_BONUS_BLKID);\n\tASSERT(data != NULL);\n\n\tdnode_t *dn = dr->dr_dnode;\n\tASSERT3U(DN_MAX_BONUS_LEN(dn->dn_phys), <=,\n\t    DN_SLOTS_TO_BONUSLEN(dn->dn_phys->dn_extra_slots + 1));\n\tmemcpy(DN_BONUS(dn->dn_phys), data, DN_MAX_BONUS_LEN(dn->dn_phys));\n\n\tdbuf_sync_leaf_verify_bonus_dnode(dr);\n\n\tdbuf_undirty_bonus(dr);\n\tdbuf_rele_and_unlock(db, (void *)(uintptr_t)tx->tx_txg, B_FALSE);\n}\n\n \nstatic void\ndbuf_prepare_encrypted_dnode_leaf(dbuf_dirty_record_t *dr)\n{\n\tint err;\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\n\tASSERT(MUTEX_HELD(&db->db_mtx));\n\tASSERT3U(db->db.db_object, ==, DMU_META_DNODE_OBJECT);\n\tASSERT3U(db->db_level, ==, 0);\n\n\tif (!db->db_objset->os_raw_receive && arc_is_encrypted(db->db_buf)) {\n\t\tzbookmark_phys_t zb;\n\n\t\t \n\t\tSET_BOOKMARK(&zb, dmu_objset_id(db->db_objset),\n\t\t    db->db.db_object, db->db_level, db->db_blkid);\n\t\terr = arc_untransform(db->db_buf, db->db_objset->os_spa,\n\t\t    &zb, B_TRUE);\n\t\tif (err)\n\t\t\tpanic(\"Invalid dnode block MAC\");\n\t} else if (dr->dt.dl.dr_has_raw_params) {\n\t\t(void) arc_release(dr->dt.dl.dr_data, db);\n\t\tarc_convert_to_raw(dr->dt.dl.dr_data,\n\t\t    dmu_objset_id(db->db_objset),\n\t\t    dr->dt.dl.dr_byteorder, DMU_OT_DNODE,\n\t\t    dr->dt.dl.dr_salt, dr->dt.dl.dr_iv, dr->dt.dl.dr_mac);\n\t}\n}\n\n \nnoinline static void\ndbuf_sync_indirect(dbuf_dirty_record_t *dr, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\tdnode_t *dn = dr->dr_dnode;\n\n\tASSERT(dmu_tx_is_syncing(tx));\n\n\tdprintf_dbuf_bp(db, db->db_blkptr, \"blkptr=%p\", db->db_blkptr);\n\n\tmutex_enter(&db->db_mtx);\n\n\tASSERT(db->db_level > 0);\n\tDBUF_VERIFY(db);\n\n\t \n\tif (db->db_buf == NULL) {\n\t\tmutex_exit(&db->db_mtx);\n\t\t(void) dbuf_read(db, NULL, DB_RF_MUST_SUCCEED);\n\t\tmutex_enter(&db->db_mtx);\n\t}\n\tASSERT3U(db->db_state, ==, DB_CACHED);\n\tASSERT(db->db_buf != NULL);\n\n\t \n\tASSERT3U(db->db.db_size, ==, 1<<dn->dn_phys->dn_indblkshift);\n\tdbuf_check_blkptr(dn, db);\n\n\t \n\tdb->db_data_pending = dr;\n\n\tmutex_exit(&db->db_mtx);\n\n\tdbuf_write(dr, db->db_buf, tx);\n\n\tzio_t *zio = dr->dr_zio;\n\tmutex_enter(&dr->dt.di.dr_mtx);\n\tdbuf_sync_list(&dr->dt.di.dr_children, db->db_level - 1, tx);\n\tASSERT(list_head(&dr->dt.di.dr_children) == NULL);\n\tmutex_exit(&dr->dt.di.dr_mtx);\n\tzio_nowait(zio);\n}\n\n \nstatic void\ndbuf_sync_leaf_verify_bonus_dnode(dbuf_dirty_record_t *dr)\n{\n#ifdef ZFS_DEBUG\n\tdnode_t *dn = dr->dr_dnode;\n\n\t \n\tif (DMU_OT_IS_ENCRYPTED(dn->dn_bonustype))\n\t\treturn;\n\n\tuint16_t bonuslen = dn->dn_phys->dn_bonuslen;\n\tuint16_t maxbonuslen = DN_SLOTS_TO_BONUSLEN(dn->dn_num_slots);\n\tASSERT3U(bonuslen, <=, maxbonuslen);\n\n\tarc_buf_t *datap = dr->dt.dl.dr_data;\n\tchar *datap_end = ((char *)datap) + bonuslen;\n\tchar *datap_max = ((char *)datap) + maxbonuslen;\n\n\t \n\tfor (; datap_end < datap_max; datap_end++)\n\t\tASSERT(*datap_end == 0);\n#endif\n}\n\nstatic blkptr_t *\ndbuf_lightweight_bp(dbuf_dirty_record_t *dr)\n{\n\t \n\tASSERT3P(dr->dr_dbuf, ==, NULL);\n\tdnode_t *dn = dr->dr_dnode;\n\n\tif (dn->dn_phys->dn_nlevels == 1) {\n\t\tVERIFY3U(dr->dt.dll.dr_blkid, <, dn->dn_phys->dn_nblkptr);\n\t\treturn (&dn->dn_phys->dn_blkptr[dr->dt.dll.dr_blkid]);\n\t} else {\n\t\tdmu_buf_impl_t *parent_db = dr->dr_parent->dr_dbuf;\n\t\tint epbs = dn->dn_indblkshift - SPA_BLKPTRSHIFT;\n\t\tVERIFY3U(parent_db->db_level, ==, 1);\n\t\tVERIFY3P(parent_db->db_dnode_handle->dnh_dnode, ==, dn);\n\t\tVERIFY3U(dr->dt.dll.dr_blkid >> epbs, ==, parent_db->db_blkid);\n\t\tblkptr_t *bp = parent_db->db.db_data;\n\t\treturn (&bp[dr->dt.dll.dr_blkid & ((1 << epbs) - 1)]);\n\t}\n}\n\nstatic void\ndbuf_lightweight_ready(zio_t *zio)\n{\n\tdbuf_dirty_record_t *dr = zio->io_private;\n\tblkptr_t *bp = zio->io_bp;\n\n\tif (zio->io_error != 0)\n\t\treturn;\n\n\tdnode_t *dn = dr->dr_dnode;\n\n\tblkptr_t *bp_orig = dbuf_lightweight_bp(dr);\n\tspa_t *spa = dmu_objset_spa(dn->dn_objset);\n\tint64_t delta = bp_get_dsize_sync(spa, bp) -\n\t    bp_get_dsize_sync(spa, bp_orig);\n\tdnode_diduse_space(dn, delta);\n\n\tuint64_t blkid = dr->dt.dll.dr_blkid;\n\tmutex_enter(&dn->dn_mtx);\n\tif (blkid > dn->dn_phys->dn_maxblkid) {\n\t\tASSERT0(dn->dn_objset->os_raw_receive);\n\t\tdn->dn_phys->dn_maxblkid = blkid;\n\t}\n\tmutex_exit(&dn->dn_mtx);\n\n\tif (!BP_IS_EMBEDDED(bp)) {\n\t\tuint64_t fill = BP_IS_HOLE(bp) ? 0 : 1;\n\t\tBP_SET_FILL(bp, fill);\n\t}\n\n\tdmu_buf_impl_t *parent_db;\n\tEQUIV(dr->dr_parent == NULL, dn->dn_phys->dn_nlevels == 1);\n\tif (dr->dr_parent == NULL) {\n\t\tparent_db = dn->dn_dbuf;\n\t} else {\n\t\tparent_db = dr->dr_parent->dr_dbuf;\n\t}\n\trw_enter(&parent_db->db_rwlock, RW_WRITER);\n\t*bp_orig = *bp;\n\trw_exit(&parent_db->db_rwlock);\n}\n\nstatic void\ndbuf_lightweight_done(zio_t *zio)\n{\n\tdbuf_dirty_record_t *dr = zio->io_private;\n\n\tVERIFY0(zio->io_error);\n\n\tobjset_t *os = dr->dr_dnode->dn_objset;\n\tdmu_tx_t *tx = os->os_synctx;\n\n\tif (zio->io_flags & (ZIO_FLAG_IO_REWRITE | ZIO_FLAG_NOPWRITE)) {\n\t\tASSERT(BP_EQUAL(zio->io_bp, &zio->io_bp_orig));\n\t} else {\n\t\tdsl_dataset_t *ds = os->os_dsl_dataset;\n\t\t(void) dsl_dataset_block_kill(ds, &zio->io_bp_orig, tx, B_TRUE);\n\t\tdsl_dataset_block_born(ds, zio->io_bp, tx);\n\t}\n\n\tdsl_pool_undirty_space(dmu_objset_pool(os), dr->dr_accounted,\n\t    zio->io_txg);\n\n\tabd_free(dr->dt.dll.dr_abd);\n\tkmem_free(dr, sizeof (*dr));\n}\n\nnoinline static void\ndbuf_sync_lightweight(dbuf_dirty_record_t *dr, dmu_tx_t *tx)\n{\n\tdnode_t *dn = dr->dr_dnode;\n\tzio_t *pio;\n\tif (dn->dn_phys->dn_nlevels == 1) {\n\t\tpio = dn->dn_zio;\n\t} else {\n\t\tpio = dr->dr_parent->dr_zio;\n\t}\n\n\tzbookmark_phys_t zb = {\n\t\t.zb_objset = dmu_objset_id(dn->dn_objset),\n\t\t.zb_object = dn->dn_object,\n\t\t.zb_level = 0,\n\t\t.zb_blkid = dr->dt.dll.dr_blkid,\n\t};\n\n\t \n\tdr->dr_bp_copy = *dbuf_lightweight_bp(dr);\n\n\tdr->dr_zio = zio_write(pio, dmu_objset_spa(dn->dn_objset),\n\t    dmu_tx_get_txg(tx), &dr->dr_bp_copy, dr->dt.dll.dr_abd,\n\t    dn->dn_datablksz, abd_get_size(dr->dt.dll.dr_abd),\n\t    &dr->dt.dll.dr_props, dbuf_lightweight_ready, NULL,\n\t    dbuf_lightweight_done, dr, ZIO_PRIORITY_ASYNC_WRITE,\n\t    ZIO_FLAG_MUSTSUCCEED | dr->dt.dll.dr_flags, &zb);\n\n\tzio_nowait(dr->dr_zio);\n}\n\n \nnoinline static void\ndbuf_sync_leaf(dbuf_dirty_record_t *dr, dmu_tx_t *tx)\n{\n\tarc_buf_t **datap = &dr->dt.dl.dr_data;\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\tdnode_t *dn = dr->dr_dnode;\n\tobjset_t *os;\n\tuint64_t txg = tx->tx_txg;\n\n\tASSERT(dmu_tx_is_syncing(tx));\n\n\tdprintf_dbuf_bp(db, db->db_blkptr, \"blkptr=%p\", db->db_blkptr);\n\n\tmutex_enter(&db->db_mtx);\n\t \n\tif (db->db_state == DB_UNCACHED) {\n\t\t \n\t\tASSERT(db->db.db_data == NULL);\n\t} else if (db->db_state == DB_FILL) {\n\t\t \n\t\tASSERT(db->db.db_data != dr->dt.dl.dr_data);\n\t} else if (db->db_state == DB_READ) {\n\t\t \n\t\tASSERT(dr->dt.dl.dr_brtwrite &&\n\t\t    dr->dt.dl.dr_override_state == DR_OVERRIDDEN);\n\t} else {\n\t\tASSERT(db->db_state == DB_CACHED || db->db_state == DB_NOFILL);\n\t}\n\tDBUF_VERIFY(db);\n\n\tif (db->db_blkid == DMU_SPILL_BLKID) {\n\t\tmutex_enter(&dn->dn_mtx);\n\t\tif (!(dn->dn_phys->dn_flags & DNODE_FLAG_SPILL_BLKPTR)) {\n\t\t\t \n\t\t\tdb->db_blkptr = NULL;\n\t\t}\n\t\tdn->dn_phys->dn_flags |= DNODE_FLAG_SPILL_BLKPTR;\n\t\tmutex_exit(&dn->dn_mtx);\n\t}\n\n\t \n\tif (db->db_blkid == DMU_BONUS_BLKID) {\n\t\tASSERT(dr->dr_dbuf == db);\n\t\tdbuf_sync_bonus(dr, tx);\n\t\treturn;\n\t}\n\n\tos = dn->dn_objset;\n\n\t \n\tdbuf_check_blkptr(dn, db);\n\n\t \n\twhile (dr->dt.dl.dr_override_state == DR_IN_DMU_SYNC) {\n\t\tASSERT(dn->dn_object != DMU_META_DNODE_OBJECT);\n\t\tcv_wait(&db->db_changed, &db->db_mtx);\n\t}\n\n\t \n\tif (os->os_encrypted && dn->dn_object == DMU_META_DNODE_OBJECT)\n\t\tdbuf_prepare_encrypted_dnode_leaf(dr);\n\n\tif (db->db_state != DB_NOFILL &&\n\t    dn->dn_object != DMU_META_DNODE_OBJECT &&\n\t    zfs_refcount_count(&db->db_holds) > 1 &&\n\t    dr->dt.dl.dr_override_state != DR_OVERRIDDEN &&\n\t    *datap == db->db_buf) {\n\t\t \n\t\tint psize = arc_buf_size(*datap);\n\t\tint lsize = arc_buf_lsize(*datap);\n\t\tarc_buf_contents_t type = DBUF_GET_BUFC_TYPE(db);\n\t\tenum zio_compress compress_type = arc_get_compression(*datap);\n\t\tuint8_t complevel = arc_get_complevel(*datap);\n\n\t\tif (arc_is_encrypted(*datap)) {\n\t\t\tboolean_t byteorder;\n\t\t\tuint8_t salt[ZIO_DATA_SALT_LEN];\n\t\t\tuint8_t iv[ZIO_DATA_IV_LEN];\n\t\t\tuint8_t mac[ZIO_DATA_MAC_LEN];\n\n\t\t\tarc_get_raw_params(*datap, &byteorder, salt, iv, mac);\n\t\t\t*datap = arc_alloc_raw_buf(os->os_spa, db,\n\t\t\t    dmu_objset_id(os), byteorder, salt, iv, mac,\n\t\t\t    dn->dn_type, psize, lsize, compress_type,\n\t\t\t    complevel);\n\t\t} else if (compress_type != ZIO_COMPRESS_OFF) {\n\t\t\tASSERT3U(type, ==, ARC_BUFC_DATA);\n\t\t\t*datap = arc_alloc_compressed_buf(os->os_spa, db,\n\t\t\t    psize, lsize, compress_type, complevel);\n\t\t} else {\n\t\t\t*datap = arc_alloc_buf(os->os_spa, db, type, psize);\n\t\t}\n\t\tmemcpy((*datap)->b_data, db->db.db_data, psize);\n\t}\n\tdb->db_data_pending = dr;\n\n\tmutex_exit(&db->db_mtx);\n\n\tdbuf_write(dr, *datap, tx);\n\n\tASSERT(!list_link_active(&dr->dr_dirty_node));\n\tif (dn->dn_object == DMU_META_DNODE_OBJECT) {\n\t\tlist_insert_tail(&dn->dn_dirty_records[txg & TXG_MASK], dr);\n\t} else {\n\t\tzio_nowait(dr->dr_zio);\n\t}\n}\n\nvoid\ndbuf_sync_list(list_t *list, int level, dmu_tx_t *tx)\n{\n\tdbuf_dirty_record_t *dr;\n\n\twhile ((dr = list_head(list))) {\n\t\tif (dr->dr_zio != NULL) {\n\t\t\t \n\t\t\tASSERT3U(dr->dr_dbuf->db.db_object, ==,\n\t\t\t    DMU_META_DNODE_OBJECT);\n\t\t\tbreak;\n\t\t}\n\t\tlist_remove(list, dr);\n\t\tif (dr->dr_dbuf == NULL) {\n\t\t\tdbuf_sync_lightweight(dr, tx);\n\t\t} else {\n\t\t\tif (dr->dr_dbuf->db_blkid != DMU_BONUS_BLKID &&\n\t\t\t    dr->dr_dbuf->db_blkid != DMU_SPILL_BLKID) {\n\t\t\t\tVERIFY3U(dr->dr_dbuf->db_level, ==, level);\n\t\t\t}\n\t\t\tif (dr->dr_dbuf->db_level > 0)\n\t\t\t\tdbuf_sync_indirect(dr, tx);\n\t\t\telse\n\t\t\t\tdbuf_sync_leaf(dr, tx);\n\t\t}\n\t}\n}\n\nstatic void\ndbuf_write_ready(zio_t *zio, arc_buf_t *buf, void *vdb)\n{\n\t(void) buf;\n\tdmu_buf_impl_t *db = vdb;\n\tdnode_t *dn;\n\tblkptr_t *bp = zio->io_bp;\n\tblkptr_t *bp_orig = &zio->io_bp_orig;\n\tspa_t *spa = zio->io_spa;\n\tint64_t delta;\n\tuint64_t fill = 0;\n\tint i;\n\n\tASSERT3P(db->db_blkptr, !=, NULL);\n\tASSERT3P(&db->db_data_pending->dr_bp_copy, ==, bp);\n\n\tDB_DNODE_ENTER(db);\n\tdn = DB_DNODE(db);\n\tdelta = bp_get_dsize_sync(spa, bp) - bp_get_dsize_sync(spa, bp_orig);\n\tdnode_diduse_space(dn, delta - zio->io_prev_space_delta);\n\tzio->io_prev_space_delta = delta;\n\n\tif (bp->blk_birth != 0) {\n\t\tASSERT((db->db_blkid != DMU_SPILL_BLKID &&\n\t\t    BP_GET_TYPE(bp) == dn->dn_type) ||\n\t\t    (db->db_blkid == DMU_SPILL_BLKID &&\n\t\t    BP_GET_TYPE(bp) == dn->dn_bonustype) ||\n\t\t    BP_IS_EMBEDDED(bp));\n\t\tASSERT(BP_GET_LEVEL(bp) == db->db_level);\n\t}\n\n\tmutex_enter(&db->db_mtx);\n\n#ifdef ZFS_DEBUG\n\tif (db->db_blkid == DMU_SPILL_BLKID) {\n\t\tASSERT(dn->dn_phys->dn_flags & DNODE_FLAG_SPILL_BLKPTR);\n\t\tASSERT(!(BP_IS_HOLE(bp)) &&\n\t\t    db->db_blkptr == DN_SPILL_BLKPTR(dn->dn_phys));\n\t}\n#endif\n\n\tif (db->db_level == 0) {\n\t\tmutex_enter(&dn->dn_mtx);\n\t\tif (db->db_blkid > dn->dn_phys->dn_maxblkid &&\n\t\t    db->db_blkid != DMU_SPILL_BLKID) {\n\t\t\tASSERT0(db->db_objset->os_raw_receive);\n\t\t\tdn->dn_phys->dn_maxblkid = db->db_blkid;\n\t\t}\n\t\tmutex_exit(&dn->dn_mtx);\n\n\t\tif (dn->dn_type == DMU_OT_DNODE) {\n\t\t\ti = 0;\n\t\t\twhile (i < db->db.db_size) {\n\t\t\t\tdnode_phys_t *dnp =\n\t\t\t\t    (void *)(((char *)db->db.db_data) + i);\n\n\t\t\t\ti += DNODE_MIN_SIZE;\n\t\t\t\tif (dnp->dn_type != DMU_OT_NONE) {\n\t\t\t\t\tfill++;\n\t\t\t\t\tfor (int j = 0; j < dnp->dn_nblkptr;\n\t\t\t\t\t    j++) {\n\t\t\t\t\t\t(void) zfs_blkptr_verify(spa,\n\t\t\t\t\t\t    &dnp->dn_blkptr[j],\n\t\t\t\t\t\t    BLK_CONFIG_SKIP,\n\t\t\t\t\t\t    BLK_VERIFY_HALT);\n\t\t\t\t\t}\n\t\t\t\t\tif (dnp->dn_flags &\n\t\t\t\t\t    DNODE_FLAG_SPILL_BLKPTR) {\n\t\t\t\t\t\t(void) zfs_blkptr_verify(spa,\n\t\t\t\t\t\t    DN_SPILL_BLKPTR(dnp),\n\t\t\t\t\t\t    BLK_CONFIG_SKIP,\n\t\t\t\t\t\t    BLK_VERIFY_HALT);\n\t\t\t\t\t}\n\t\t\t\t\ti += dnp->dn_extra_slots *\n\t\t\t\t\t    DNODE_MIN_SIZE;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif (BP_IS_HOLE(bp)) {\n\t\t\t\tfill = 0;\n\t\t\t} else {\n\t\t\t\tfill = 1;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tblkptr_t *ibp = db->db.db_data;\n\t\tASSERT3U(db->db.db_size, ==, 1<<dn->dn_phys->dn_indblkshift);\n\t\tfor (i = db->db.db_size >> SPA_BLKPTRSHIFT; i > 0; i--, ibp++) {\n\t\t\tif (BP_IS_HOLE(ibp))\n\t\t\t\tcontinue;\n\t\t\t(void) zfs_blkptr_verify(spa, ibp,\n\t\t\t    BLK_CONFIG_SKIP, BLK_VERIFY_HALT);\n\t\t\tfill += BP_GET_FILL(ibp);\n\t\t}\n\t}\n\tDB_DNODE_EXIT(db);\n\n\tif (!BP_IS_EMBEDDED(bp))\n\t\tBP_SET_FILL(bp, fill);\n\n\tmutex_exit(&db->db_mtx);\n\n\tdb_lock_type_t dblt = dmu_buf_lock_parent(db, RW_WRITER, FTAG);\n\t*db->db_blkptr = *bp;\n\tdmu_buf_unlock_parent(db, dblt, FTAG);\n}\n\n \nstatic void\ndbuf_write_children_ready(zio_t *zio, arc_buf_t *buf, void *vdb)\n{\n\t(void) zio, (void) buf;\n\tdmu_buf_impl_t *db = vdb;\n\tdnode_t *dn;\n\tblkptr_t *bp;\n\tunsigned int epbs, i;\n\n\tASSERT3U(db->db_level, >, 0);\n\tDB_DNODE_ENTER(db);\n\tdn = DB_DNODE(db);\n\tepbs = dn->dn_phys->dn_indblkshift - SPA_BLKPTRSHIFT;\n\tASSERT3U(epbs, <, 31);\n\n\t \n\tfor (i = 0, bp = db->db.db_data; i < 1ULL << epbs; i++, bp++) {\n\t\tif (!BP_IS_HOLE(bp))\n\t\t\tbreak;\n\t}\n\n\t \n\tif (i == 1ULL << epbs) {\n\t\t \n\t\trw_enter(&db->db_rwlock, RW_WRITER);\n\t\tmemset(db->db.db_data, 0, db->db.db_size);\n\t\trw_exit(&db->db_rwlock);\n\t}\n\tDB_DNODE_EXIT(db);\n}\n\nstatic void\ndbuf_write_done(zio_t *zio, arc_buf_t *buf, void *vdb)\n{\n\t(void) buf;\n\tdmu_buf_impl_t *db = vdb;\n\tblkptr_t *bp_orig = &zio->io_bp_orig;\n\tblkptr_t *bp = db->db_blkptr;\n\tobjset_t *os = db->db_objset;\n\tdmu_tx_t *tx = os->os_synctx;\n\n\tASSERT0(zio->io_error);\n\tASSERT(db->db_blkptr == bp);\n\n\t \n\tif (zio->io_flags & (ZIO_FLAG_IO_REWRITE | ZIO_FLAG_NOPWRITE)) {\n\t\tASSERT(BP_EQUAL(bp, bp_orig));\n\t} else {\n\t\tdsl_dataset_t *ds = os->os_dsl_dataset;\n\t\t(void) dsl_dataset_block_kill(ds, bp_orig, tx, B_TRUE);\n\t\tdsl_dataset_block_born(ds, bp, tx);\n\t}\n\n\tmutex_enter(&db->db_mtx);\n\n\tDBUF_VERIFY(db);\n\n\tdbuf_dirty_record_t *dr = db->db_data_pending;\n\tdnode_t *dn = dr->dr_dnode;\n\tASSERT(!list_link_active(&dr->dr_dirty_node));\n\tASSERT(dr->dr_dbuf == db);\n\tASSERT(list_next(&db->db_dirty_records, dr) == NULL);\n\tlist_remove(&db->db_dirty_records, dr);\n\n#ifdef ZFS_DEBUG\n\tif (db->db_blkid == DMU_SPILL_BLKID) {\n\t\tASSERT(dn->dn_phys->dn_flags & DNODE_FLAG_SPILL_BLKPTR);\n\t\tASSERT(!(BP_IS_HOLE(db->db_blkptr)) &&\n\t\t    db->db_blkptr == DN_SPILL_BLKPTR(dn->dn_phys));\n\t}\n#endif\n\n\tif (db->db_level == 0) {\n\t\tASSERT(db->db_blkid != DMU_BONUS_BLKID);\n\t\tASSERT(dr->dt.dl.dr_override_state == DR_NOT_OVERRIDDEN);\n\t\tif (db->db_state != DB_NOFILL) {\n\t\t\tif (dr->dt.dl.dr_data != NULL &&\n\t\t\t    dr->dt.dl.dr_data != db->db_buf) {\n\t\t\t\tarc_buf_destroy(dr->dt.dl.dr_data, db);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tASSERT(list_head(&dr->dt.di.dr_children) == NULL);\n\t\tASSERT3U(db->db.db_size, ==, 1 << dn->dn_phys->dn_indblkshift);\n\t\tif (!BP_IS_HOLE(db->db_blkptr)) {\n\t\t\tint epbs __maybe_unused = dn->dn_phys->dn_indblkshift -\n\t\t\t    SPA_BLKPTRSHIFT;\n\t\t\tASSERT3U(db->db_blkid, <=,\n\t\t\t    dn->dn_phys->dn_maxblkid >> (db->db_level * epbs));\n\t\t\tASSERT3U(BP_GET_LSIZE(db->db_blkptr), ==,\n\t\t\t    db->db.db_size);\n\t\t}\n\t\tmutex_destroy(&dr->dt.di.dr_mtx);\n\t\tlist_destroy(&dr->dt.di.dr_children);\n\t}\n\n\tcv_broadcast(&db->db_changed);\n\tASSERT(db->db_dirtycnt > 0);\n\tdb->db_dirtycnt -= 1;\n\tdb->db_data_pending = NULL;\n\tdbuf_rele_and_unlock(db, (void *)(uintptr_t)tx->tx_txg, B_FALSE);\n\n\tdsl_pool_undirty_space(dmu_objset_pool(os), dr->dr_accounted,\n\t    zio->io_txg);\n\n\tkmem_free(dr, sizeof (dbuf_dirty_record_t));\n}\n\nstatic void\ndbuf_write_nofill_ready(zio_t *zio)\n{\n\tdbuf_write_ready(zio, NULL, zio->io_private);\n}\n\nstatic void\ndbuf_write_nofill_done(zio_t *zio)\n{\n\tdbuf_write_done(zio, NULL, zio->io_private);\n}\n\nstatic void\ndbuf_write_override_ready(zio_t *zio)\n{\n\tdbuf_dirty_record_t *dr = zio->io_private;\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\n\tdbuf_write_ready(zio, NULL, db);\n}\n\nstatic void\ndbuf_write_override_done(zio_t *zio)\n{\n\tdbuf_dirty_record_t *dr = zio->io_private;\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\tblkptr_t *obp = &dr->dt.dl.dr_overridden_by;\n\n\tmutex_enter(&db->db_mtx);\n\tif (!BP_EQUAL(zio->io_bp, obp)) {\n\t\tif (!BP_IS_HOLE(obp))\n\t\t\tdsl_free(spa_get_dsl(zio->io_spa), zio->io_txg, obp);\n\t\tarc_release(dr->dt.dl.dr_data, db);\n\t}\n\tmutex_exit(&db->db_mtx);\n\n\tdbuf_write_done(zio, NULL, db);\n\n\tif (zio->io_abd != NULL)\n\t\tabd_free(zio->io_abd);\n}\n\ntypedef struct dbuf_remap_impl_callback_arg {\n\tobjset_t\t*drica_os;\n\tuint64_t\tdrica_blk_birth;\n\tdmu_tx_t\t*drica_tx;\n} dbuf_remap_impl_callback_arg_t;\n\nstatic void\ndbuf_remap_impl_callback(uint64_t vdev, uint64_t offset, uint64_t size,\n    void *arg)\n{\n\tdbuf_remap_impl_callback_arg_t *drica = arg;\n\tobjset_t *os = drica->drica_os;\n\tspa_t *spa = dmu_objset_spa(os);\n\tdmu_tx_t *tx = drica->drica_tx;\n\n\tASSERT(dsl_pool_sync_context(spa_get_dsl(spa)));\n\n\tif (os == spa_meta_objset(spa)) {\n\t\tspa_vdev_indirect_mark_obsolete(spa, vdev, offset, size, tx);\n\t} else {\n\t\tdsl_dataset_block_remapped(dmu_objset_ds(os), vdev, offset,\n\t\t    size, drica->drica_blk_birth, tx);\n\t}\n}\n\nstatic void\ndbuf_remap_impl(dnode_t *dn, blkptr_t *bp, krwlock_t *rw, dmu_tx_t *tx)\n{\n\tblkptr_t bp_copy = *bp;\n\tspa_t *spa = dmu_objset_spa(dn->dn_objset);\n\tdbuf_remap_impl_callback_arg_t drica;\n\n\tASSERT(dsl_pool_sync_context(spa_get_dsl(spa)));\n\n\tdrica.drica_os = dn->dn_objset;\n\tdrica.drica_blk_birth = bp->blk_birth;\n\tdrica.drica_tx = tx;\n\tif (spa_remap_blkptr(spa, &bp_copy, dbuf_remap_impl_callback,\n\t    &drica)) {\n\t\t \n\t\tif (dn->dn_objset != spa_meta_objset(spa)) {\n\t\t\tdsl_dataset_t *ds = dmu_objset_ds(dn->dn_objset);\n\t\t\tif (dsl_deadlist_is_open(&ds->ds_dir->dd_livelist) &&\n\t\t\t    bp->blk_birth > ds->ds_dir->dd_origin_txg) {\n\t\t\t\tASSERT(!BP_IS_EMBEDDED(bp));\n\t\t\t\tASSERT(dsl_dir_is_clone(ds->ds_dir));\n\t\t\t\tASSERT(spa_feature_is_enabled(spa,\n\t\t\t\t    SPA_FEATURE_LIVELIST));\n\t\t\t\tbplist_append(&ds->ds_dir->dd_pending_frees,\n\t\t\t\t    bp);\n\t\t\t\tbplist_append(&ds->ds_dir->dd_pending_allocs,\n\t\t\t\t    &bp_copy);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (rw != NULL)\n\t\t\trw_enter(rw, RW_WRITER);\n\t\t*bp = bp_copy;\n\t\tif (rw != NULL)\n\t\t\trw_exit(rw);\n\t}\n}\n\n \nstatic void\ndbuf_remap(dnode_t *dn, dmu_buf_impl_t *db, dmu_tx_t *tx)\n{\n\tspa_t *spa = dmu_objset_spa(db->db_objset);\n\tASSERT(dsl_pool_sync_context(spa_get_dsl(spa)));\n\n\tif (!spa_feature_is_active(spa, SPA_FEATURE_DEVICE_REMOVAL))\n\t\treturn;\n\n\tif (db->db_level > 0) {\n\t\tblkptr_t *bp = db->db.db_data;\n\t\tfor (int i = 0; i < db->db.db_size >> SPA_BLKPTRSHIFT; i++) {\n\t\t\tdbuf_remap_impl(dn, &bp[i], &db->db_rwlock, tx);\n\t\t}\n\t} else if (db->db.db_object == DMU_META_DNODE_OBJECT) {\n\t\tdnode_phys_t *dnp = db->db.db_data;\n\t\tASSERT3U(db->db_dnode_handle->dnh_dnode->dn_type, ==,\n\t\t    DMU_OT_DNODE);\n\t\tfor (int i = 0; i < db->db.db_size >> DNODE_SHIFT;\n\t\t    i += dnp[i].dn_extra_slots + 1) {\n\t\t\tfor (int j = 0; j < dnp[i].dn_nblkptr; j++) {\n\t\t\t\tkrwlock_t *lock = (dn->dn_dbuf == NULL ? NULL :\n\t\t\t\t    &dn->dn_dbuf->db_rwlock);\n\t\t\t\tdbuf_remap_impl(dn, &dnp[i].dn_blkptr[j], lock,\n\t\t\t\t    tx);\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n \nstatic void\ndbuf_write(dbuf_dirty_record_t *dr, arc_buf_t *data, dmu_tx_t *tx)\n{\n\tdmu_buf_impl_t *db = dr->dr_dbuf;\n\tdnode_t *dn = dr->dr_dnode;\n\tobjset_t *os;\n\tdmu_buf_impl_t *parent = db->db_parent;\n\tuint64_t txg = tx->tx_txg;\n\tzbookmark_phys_t zb;\n\tzio_prop_t zp;\n\tzio_t *pio;  \n\tint wp_flag = 0;\n\n\tASSERT(dmu_tx_is_syncing(tx));\n\n\tos = dn->dn_objset;\n\n\tif (db->db_state != DB_NOFILL) {\n\t\tif (db->db_level > 0 || dn->dn_type == DMU_OT_DNODE) {\n\t\t\t \n\t\t\tif (BP_IS_HOLE(db->db_blkptr)) {\n\t\t\t\tarc_buf_thaw(data);\n\t\t\t} else {\n\t\t\t\tdbuf_release_bp(db);\n\t\t\t}\n\t\t\tdbuf_remap(dn, db, tx);\n\t\t}\n\t}\n\n\tif (parent != dn->dn_dbuf) {\n\t\t \n\t\t \n\t\tASSERT(parent && parent->db_data_pending);\n\t\t \n\t\tASSERT(db->db_level == parent->db_level-1);\n\t\t \n\t\tASSERT(arc_released(parent->db_buf));\n\t\tpio = parent->db_data_pending->dr_zio;\n\t} else {\n\t\t \n\t\tASSERT((db->db_level == dn->dn_phys->dn_nlevels-1 &&\n\t\t    db->db_blkid != DMU_SPILL_BLKID) ||\n\t\t    (db->db_blkid == DMU_SPILL_BLKID && db->db_level == 0));\n\t\tif (db->db_blkid != DMU_SPILL_BLKID)\n\t\t\tASSERT3P(db->db_blkptr, ==,\n\t\t\t    &dn->dn_phys->dn_blkptr[db->db_blkid]);\n\t\tpio = dn->dn_zio;\n\t}\n\n\tASSERT(db->db_level == 0 || data == db->db_buf);\n\tASSERT3U(db->db_blkptr->blk_birth, <=, txg);\n\tASSERT(pio);\n\n\tSET_BOOKMARK(&zb, os->os_dsl_dataset ?\n\t    os->os_dsl_dataset->ds_object : DMU_META_OBJSET,\n\t    db->db.db_object, db->db_level, db->db_blkid);\n\n\tif (db->db_blkid == DMU_SPILL_BLKID)\n\t\twp_flag = WP_SPILL;\n\twp_flag |= (db->db_state == DB_NOFILL) ? WP_NOFILL : 0;\n\n\tdmu_write_policy(os, dn, db->db_level, wp_flag, &zp);\n\n\t \n\tdr->dr_bp_copy = *db->db_blkptr;\n\n\tif (db->db_level == 0 &&\n\t    dr->dt.dl.dr_override_state == DR_OVERRIDDEN) {\n\t\t \n\t\tabd_t *contents = (data != NULL) ?\n\t\t    abd_get_from_buf(data->b_data, arc_buf_size(data)) : NULL;\n\n\t\tdr->dr_zio = zio_write(pio, os->os_spa, txg, &dr->dr_bp_copy,\n\t\t    contents, db->db.db_size, db->db.db_size, &zp,\n\t\t    dbuf_write_override_ready, NULL,\n\t\t    dbuf_write_override_done,\n\t\t    dr, ZIO_PRIORITY_ASYNC_WRITE, ZIO_FLAG_MUSTSUCCEED, &zb);\n\t\tmutex_enter(&db->db_mtx);\n\t\tdr->dt.dl.dr_override_state = DR_NOT_OVERRIDDEN;\n\t\tzio_write_override(dr->dr_zio, &dr->dt.dl.dr_overridden_by,\n\t\t    dr->dt.dl.dr_copies, dr->dt.dl.dr_nopwrite,\n\t\t    dr->dt.dl.dr_brtwrite);\n\t\tmutex_exit(&db->db_mtx);\n\t} else if (db->db_state == DB_NOFILL) {\n\t\tASSERT(zp.zp_checksum == ZIO_CHECKSUM_OFF ||\n\t\t    zp.zp_checksum == ZIO_CHECKSUM_NOPARITY);\n\t\tdr->dr_zio = zio_write(pio, os->os_spa, txg,\n\t\t    &dr->dr_bp_copy, NULL, db->db.db_size, db->db.db_size, &zp,\n\t\t    dbuf_write_nofill_ready, NULL,\n\t\t    dbuf_write_nofill_done, db,\n\t\t    ZIO_PRIORITY_ASYNC_WRITE,\n\t\t    ZIO_FLAG_MUSTSUCCEED | ZIO_FLAG_NODATA, &zb);\n\t} else {\n\t\tASSERT(arc_released(data));\n\n\t\t \n\t\tarc_write_done_func_t *children_ready_cb = NULL;\n\t\tif (db->db_level != 0)\n\t\t\tchildren_ready_cb = dbuf_write_children_ready;\n\n\t\tdr->dr_zio = arc_write(pio, os->os_spa, txg,\n\t\t    &dr->dr_bp_copy, data, !DBUF_IS_CACHEABLE(db),\n\t\t    dbuf_is_l2cacheable(db), &zp, dbuf_write_ready,\n\t\t    children_ready_cb, dbuf_write_done, db,\n\t\t    ZIO_PRIORITY_ASYNC_WRITE, ZIO_FLAG_MUSTSUCCEED, &zb);\n\t}\n}\n\nEXPORT_SYMBOL(dbuf_find);\nEXPORT_SYMBOL(dbuf_is_metadata);\nEXPORT_SYMBOL(dbuf_destroy);\nEXPORT_SYMBOL(dbuf_loan_arcbuf);\nEXPORT_SYMBOL(dbuf_whichblock);\nEXPORT_SYMBOL(dbuf_read);\nEXPORT_SYMBOL(dbuf_unoverride);\nEXPORT_SYMBOL(dbuf_free_range);\nEXPORT_SYMBOL(dbuf_new_size);\nEXPORT_SYMBOL(dbuf_release_bp);\nEXPORT_SYMBOL(dbuf_dirty);\nEXPORT_SYMBOL(dmu_buf_set_crypt_params);\nEXPORT_SYMBOL(dmu_buf_will_dirty);\nEXPORT_SYMBOL(dmu_buf_is_dirty);\nEXPORT_SYMBOL(dmu_buf_will_clone);\nEXPORT_SYMBOL(dmu_buf_will_not_fill);\nEXPORT_SYMBOL(dmu_buf_will_fill);\nEXPORT_SYMBOL(dmu_buf_fill_done);\nEXPORT_SYMBOL(dmu_buf_rele);\nEXPORT_SYMBOL(dbuf_assign_arcbuf);\nEXPORT_SYMBOL(dbuf_prefetch);\nEXPORT_SYMBOL(dbuf_hold_impl);\nEXPORT_SYMBOL(dbuf_hold);\nEXPORT_SYMBOL(dbuf_hold_level);\nEXPORT_SYMBOL(dbuf_create_bonus);\nEXPORT_SYMBOL(dbuf_spill_set_blksz);\nEXPORT_SYMBOL(dbuf_rm_spill);\nEXPORT_SYMBOL(dbuf_add_ref);\nEXPORT_SYMBOL(dbuf_rele);\nEXPORT_SYMBOL(dbuf_rele_and_unlock);\nEXPORT_SYMBOL(dbuf_refcount);\nEXPORT_SYMBOL(dbuf_sync_list);\nEXPORT_SYMBOL(dmu_buf_set_user);\nEXPORT_SYMBOL(dmu_buf_set_user_ie);\nEXPORT_SYMBOL(dmu_buf_get_user);\nEXPORT_SYMBOL(dmu_buf_get_blkptr);\n\nZFS_MODULE_PARAM(zfs_dbuf_cache, dbuf_cache_, max_bytes, U64, ZMOD_RW,\n\t\"Maximum size in bytes of the dbuf cache.\");\n\nZFS_MODULE_PARAM(zfs_dbuf_cache, dbuf_cache_, hiwater_pct, UINT, ZMOD_RW,\n\t\"Percentage over dbuf_cache_max_bytes for direct dbuf eviction.\");\n\nZFS_MODULE_PARAM(zfs_dbuf_cache, dbuf_cache_, lowater_pct, UINT, ZMOD_RW,\n\t\"Percentage below dbuf_cache_max_bytes when dbuf eviction stops.\");\n\nZFS_MODULE_PARAM(zfs_dbuf, dbuf_, metadata_cache_max_bytes, U64, ZMOD_RW,\n\t\"Maximum size in bytes of dbuf metadata cache.\");\n\nZFS_MODULE_PARAM(zfs_dbuf, dbuf_, cache_shift, UINT, ZMOD_RW,\n\t\"Set size of dbuf cache to log2 fraction of arc size.\");\n\nZFS_MODULE_PARAM(zfs_dbuf, dbuf_, metadata_cache_shift, UINT, ZMOD_RW,\n\t\"Set size of dbuf metadata cache to log2 fraction of arc size.\");\n\nZFS_MODULE_PARAM(zfs_dbuf, dbuf_, mutex_cache_shift, UINT, ZMOD_RD,\n\t\"Set size of dbuf cache mutex array as log2 shift.\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}