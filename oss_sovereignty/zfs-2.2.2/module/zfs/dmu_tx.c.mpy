{
  "module_name": "dmu_tx.c",
  "hash_id": "5e4900e194127fd97a1a21338bed77ebb9d3addd640724de6537c236a350c3ba",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/dmu_tx.c",
  "human_readable_source": " \n \n\n#include <sys/dmu.h>\n#include <sys/dmu_impl.h>\n#include <sys/dbuf.h>\n#include <sys/dmu_tx.h>\n#include <sys/dmu_objset.h>\n#include <sys/dsl_dataset.h>\n#include <sys/dsl_dir.h>\n#include <sys/dsl_pool.h>\n#include <sys/zap_impl.h>\n#include <sys/spa.h>\n#include <sys/sa.h>\n#include <sys/sa_impl.h>\n#include <sys/zfs_context.h>\n#include <sys/trace_zfs.h>\n\ntypedef void (*dmu_tx_hold_func_t)(dmu_tx_t *tx, struct dnode *dn,\n    uint64_t arg1, uint64_t arg2);\n\ndmu_tx_stats_t dmu_tx_stats = {\n\t{ \"dmu_tx_assigned\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_delay\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_error\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_suspended\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_group\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_memory_reserve\",\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_memory_reclaim\",\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_dirty_throttle\",\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_dirty_delay\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_dirty_over_max\",\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_dirty_frees_delay\",\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_wrlog_delay\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"dmu_tx_quota\",\t\tKSTAT_DATA_UINT64 },\n};\n\nstatic kstat_t *dmu_tx_ksp;\n\ndmu_tx_t *\ndmu_tx_create_dd(dsl_dir_t *dd)\n{\n\tdmu_tx_t *tx = kmem_zalloc(sizeof (dmu_tx_t), KM_SLEEP);\n\ttx->tx_dir = dd;\n\tif (dd != NULL)\n\t\ttx->tx_pool = dd->dd_pool;\n\tlist_create(&tx->tx_holds, sizeof (dmu_tx_hold_t),\n\t    offsetof(dmu_tx_hold_t, txh_node));\n\tlist_create(&tx->tx_callbacks, sizeof (dmu_tx_callback_t),\n\t    offsetof(dmu_tx_callback_t, dcb_node));\n\ttx->tx_start = gethrtime();\n\treturn (tx);\n}\n\ndmu_tx_t *\ndmu_tx_create(objset_t *os)\n{\n\tdmu_tx_t *tx = dmu_tx_create_dd(os->os_dsl_dataset->ds_dir);\n\ttx->tx_objset = os;\n\treturn (tx);\n}\n\ndmu_tx_t *\ndmu_tx_create_assigned(struct dsl_pool *dp, uint64_t txg)\n{\n\tdmu_tx_t *tx = dmu_tx_create_dd(NULL);\n\n\tTXG_VERIFY(dp->dp_spa, txg);\n\ttx->tx_pool = dp;\n\ttx->tx_txg = txg;\n\ttx->tx_anyobj = TRUE;\n\n\treturn (tx);\n}\n\nint\ndmu_tx_is_syncing(dmu_tx_t *tx)\n{\n\treturn (tx->tx_anyobj);\n}\n\nint\ndmu_tx_private_ok(dmu_tx_t *tx)\n{\n\treturn (tx->tx_anyobj);\n}\n\nstatic dmu_tx_hold_t *\ndmu_tx_hold_dnode_impl(dmu_tx_t *tx, dnode_t *dn, enum dmu_tx_hold_type type,\n    uint64_t arg1, uint64_t arg2)\n{\n\tdmu_tx_hold_t *txh;\n\n\tif (dn != NULL) {\n\t\t(void) zfs_refcount_add(&dn->dn_holds, tx);\n\t\tif (tx->tx_txg != 0) {\n\t\t\tmutex_enter(&dn->dn_mtx);\n\t\t\t \n\t\t\tASSERT(dn->dn_assigned_txg == 0);\n\t\t\tdn->dn_assigned_txg = tx->tx_txg;\n\t\t\t(void) zfs_refcount_add(&dn->dn_tx_holds, tx);\n\t\t\tmutex_exit(&dn->dn_mtx);\n\t\t}\n\t}\n\n\ttxh = kmem_zalloc(sizeof (dmu_tx_hold_t), KM_SLEEP);\n\ttxh->txh_tx = tx;\n\ttxh->txh_dnode = dn;\n\tzfs_refcount_create(&txh->txh_space_towrite);\n\tzfs_refcount_create(&txh->txh_memory_tohold);\n\ttxh->txh_type = type;\n\ttxh->txh_arg1 = arg1;\n\ttxh->txh_arg2 = arg2;\n\tlist_insert_tail(&tx->tx_holds, txh);\n\n\treturn (txh);\n}\n\nstatic dmu_tx_hold_t *\ndmu_tx_hold_object_impl(dmu_tx_t *tx, objset_t *os, uint64_t object,\n    enum dmu_tx_hold_type type, uint64_t arg1, uint64_t arg2)\n{\n\tdnode_t *dn = NULL;\n\tdmu_tx_hold_t *txh;\n\tint err;\n\n\tif (object != DMU_NEW_OBJECT) {\n\t\terr = dnode_hold(os, object, FTAG, &dn);\n\t\tif (err != 0) {\n\t\t\ttx->tx_err = err;\n\t\t\treturn (NULL);\n\t\t}\n\t}\n\ttxh = dmu_tx_hold_dnode_impl(tx, dn, type, arg1, arg2);\n\tif (dn != NULL)\n\t\tdnode_rele(dn, FTAG);\n\treturn (txh);\n}\n\nvoid\ndmu_tx_add_new_object(dmu_tx_t *tx, dnode_t *dn)\n{\n\t \n\tif (!dmu_tx_is_syncing(tx))\n\t\t(void) dmu_tx_hold_dnode_impl(tx, dn, THT_NEWOBJECT, 0, 0);\n}\n\n \nstatic int\ndmu_tx_check_ioerr(zio_t *zio, dnode_t *dn, int level, uint64_t blkid)\n{\n\tint err;\n\tdmu_buf_impl_t *db;\n\n\trw_enter(&dn->dn_struct_rwlock, RW_READER);\n\terr = dbuf_hold_impl(dn, level, blkid, TRUE, FALSE, FTAG, &db);\n\trw_exit(&dn->dn_struct_rwlock);\n\tif (err == ENOENT)\n\t\treturn (0);\n\tif (err != 0)\n\t\treturn (err);\n\t \n\terr = dbuf_read(db, zio, DB_RF_CANFAIL | DB_RF_NOPREFETCH |\n\t    (level == 0 ? DB_RF_PARTIAL_FIRST : 0));\n\tdbuf_rele(db, FTAG);\n\treturn (err);\n}\n\nstatic void\ndmu_tx_count_write(dmu_tx_hold_t *txh, uint64_t off, uint64_t len)\n{\n\tdnode_t *dn = txh->txh_dnode;\n\tint err = 0;\n\n\tif (len == 0)\n\t\treturn;\n\n\t(void) zfs_refcount_add_many(&txh->txh_space_towrite, len, FTAG);\n\n\tif (dn == NULL)\n\t\treturn;\n\n\t \n\tif (dn->dn_maxblkid == 0) {\n\t\tif (off < dn->dn_datablksz &&\n\t\t    (off > 0 || len < dn->dn_datablksz)) {\n\t\t\terr = dmu_tx_check_ioerr(NULL, dn, 0, 0);\n\t\t\tif (err != 0) {\n\t\t\t\ttxh->txh_tx->tx_err = err;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tzio_t *zio = zio_root(dn->dn_objset->os_spa,\n\t\t    NULL, NULL, ZIO_FLAG_CANFAIL);\n\n\t\t \n\t\tuint64_t start = off >> dn->dn_datablkshift;\n\t\tif (P2PHASE(off, dn->dn_datablksz) || len < dn->dn_datablksz) {\n\t\t\terr = dmu_tx_check_ioerr(zio, dn, 0, start);\n\t\t\tif (err != 0) {\n\t\t\t\ttxh->txh_tx->tx_err = err;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tuint64_t end = (off + len - 1) >> dn->dn_datablkshift;\n\t\tif (end != start && end <= dn->dn_maxblkid &&\n\t\t    P2PHASE(off + len, dn->dn_datablksz)) {\n\t\t\terr = dmu_tx_check_ioerr(zio, dn, 0, end);\n\t\t\tif (err != 0) {\n\t\t\t\ttxh->txh_tx->tx_err = err;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (dn->dn_nlevels > 1) {\n\t\t\tint shft = dn->dn_indblkshift - SPA_BLKPTRSHIFT;\n\t\t\tfor (uint64_t i = (start >> shft) + 1;\n\t\t\t    i < end >> shft; i++) {\n\t\t\t\terr = dmu_tx_check_ioerr(zio, dn, 1, i);\n\t\t\t\tif (err != 0) {\n\t\t\t\t\ttxh->txh_tx->tx_err = err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\terr = zio_wait(zio);\n\t\tif (err != 0) {\n\t\t\ttxh->txh_tx->tx_err = err;\n\t\t}\n\t}\n}\n\nstatic void\ndmu_tx_count_append(dmu_tx_hold_t *txh, uint64_t off, uint64_t len)\n{\n\tdnode_t *dn = txh->txh_dnode;\n\tint err = 0;\n\n\tif (len == 0)\n\t\treturn;\n\n\t(void) zfs_refcount_add_many(&txh->txh_space_towrite, len, FTAG);\n\n\tif (dn == NULL)\n\t\treturn;\n\n\t \n\tif (dn->dn_maxblkid == 0) {\n\t\tif (off < dn->dn_datablksz &&\n\t\t    (off > 0 || len < dn->dn_datablksz)) {\n\t\t\terr = dmu_tx_check_ioerr(NULL, dn, 0, 0);\n\t\t\tif (err != 0) {\n\t\t\t\ttxh->txh_tx->tx_err = err;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tzio_t *zio = zio_root(dn->dn_objset->os_spa,\n\t\t    NULL, NULL, ZIO_FLAG_CANFAIL);\n\n\t\t \n\t\tuint64_t start = off >> dn->dn_datablkshift;\n\t\tif (P2PHASE(off, dn->dn_datablksz) || len < dn->dn_datablksz) {\n\t\t\terr = dmu_tx_check_ioerr(zio, dn, 0, start);\n\t\t\tif (err != 0) {\n\t\t\t\ttxh->txh_tx->tx_err = err;\n\t\t\t}\n\t\t}\n\n\t\terr = zio_wait(zio);\n\t\tif (err != 0) {\n\t\t\ttxh->txh_tx->tx_err = err;\n\t\t}\n\t}\n}\n\nstatic void\ndmu_tx_count_dnode(dmu_tx_hold_t *txh)\n{\n\t(void) zfs_refcount_add_many(&txh->txh_space_towrite,\n\t    DNODE_MIN_SIZE, FTAG);\n}\n\nvoid\ndmu_tx_hold_write(dmu_tx_t *tx, uint64_t object, uint64_t off, int len)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT0(tx->tx_txg);\n\tASSERT3U(len, <=, DMU_MAX_ACCESS);\n\tASSERT(len == 0 || UINT64_MAX - off >= len - 1);\n\n\ttxh = dmu_tx_hold_object_impl(tx, tx->tx_objset,\n\t    object, THT_WRITE, off, len);\n\tif (txh != NULL) {\n\t\tdmu_tx_count_write(txh, off, len);\n\t\tdmu_tx_count_dnode(txh);\n\t}\n}\n\nvoid\ndmu_tx_hold_write_by_dnode(dmu_tx_t *tx, dnode_t *dn, uint64_t off, int len)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT0(tx->tx_txg);\n\tASSERT3U(len, <=, DMU_MAX_ACCESS);\n\tASSERT(len == 0 || UINT64_MAX - off >= len - 1);\n\n\ttxh = dmu_tx_hold_dnode_impl(tx, dn, THT_WRITE, off, len);\n\tif (txh != NULL) {\n\t\tdmu_tx_count_write(txh, off, len);\n\t\tdmu_tx_count_dnode(txh);\n\t}\n}\n\n \nvoid\ndmu_tx_hold_append(dmu_tx_t *tx, uint64_t object, uint64_t off, int len)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT0(tx->tx_txg);\n\tASSERT3U(len, <=, DMU_MAX_ACCESS);\n\n\ttxh = dmu_tx_hold_object_impl(tx, tx->tx_objset,\n\t    object, THT_APPEND, off, DMU_OBJECT_END);\n\tif (txh != NULL) {\n\t\tdmu_tx_count_append(txh, off, len);\n\t\tdmu_tx_count_dnode(txh);\n\t}\n}\n\nvoid\ndmu_tx_hold_append_by_dnode(dmu_tx_t *tx, dnode_t *dn, uint64_t off, int len)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT0(tx->tx_txg);\n\tASSERT3U(len, <=, DMU_MAX_ACCESS);\n\n\ttxh = dmu_tx_hold_dnode_impl(tx, dn, THT_APPEND, off, DMU_OBJECT_END);\n\tif (txh != NULL) {\n\t\tdmu_tx_count_append(txh, off, len);\n\t\tdmu_tx_count_dnode(txh);\n\t}\n}\n\n \nvoid\ndmu_tx_mark_netfree(dmu_tx_t *tx)\n{\n\ttx->tx_netfree = B_TRUE;\n}\n\nstatic void\ndmu_tx_count_free(dmu_tx_hold_t *txh, uint64_t off, uint64_t len)\n{\n\tdmu_tx_t *tx = txh->txh_tx;\n\tdnode_t *dn = txh->txh_dnode;\n\tint err;\n\n\tASSERT(tx->tx_txg == 0);\n\n\tif (off >= (dn->dn_maxblkid + 1) * dn->dn_datablksz)\n\t\treturn;\n\tif (len == DMU_OBJECT_END)\n\t\tlen = (dn->dn_maxblkid + 1) * dn->dn_datablksz - off;\n\n\t \n\tif (dn->dn_datablkshift == 0) {\n\t\tif (off != 0 || len < dn->dn_datablksz)\n\t\t\tdmu_tx_count_write(txh, 0, dn->dn_datablksz);\n\t} else {\n\t\t \n\t\tif (!IS_P2ALIGNED(off, 1 << dn->dn_datablkshift))\n\t\t\tdmu_tx_count_write(txh, off, 1);\n\t\t \n\t\tif (!IS_P2ALIGNED(off + len, 1 << dn->dn_datablkshift))\n\t\t\tdmu_tx_count_write(txh, off + len, 1);\n\t}\n\n\t \n\tif (dn->dn_nlevels > 1) {\n\t\tint shift = dn->dn_datablkshift + dn->dn_indblkshift -\n\t\t    SPA_BLKPTRSHIFT;\n\t\tuint64_t start = off >> shift;\n\t\tuint64_t end = (off + len) >> shift;\n\n\t\tASSERT(dn->dn_indblkshift != 0);\n\n\t\t \n\t\tif (dn->dn_datablkshift == 0)\n\t\t\tstart = end = 0;\n\n\t\tzio_t *zio = zio_root(tx->tx_pool->dp_spa,\n\t\t    NULL, NULL, ZIO_FLAG_CANFAIL);\n\t\tfor (uint64_t i = start; i <= end; i++) {\n\t\t\tuint64_t ibyte = i << shift;\n\t\t\terr = dnode_next_offset(dn, 0, &ibyte, 2, 1, 0);\n\t\t\ti = ibyte >> shift;\n\t\t\tif (err == ESRCH || i > end)\n\t\t\t\tbreak;\n\t\t\tif (err != 0) {\n\t\t\t\ttx->tx_err = err;\n\t\t\t\t(void) zio_wait(zio);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t(void) zfs_refcount_add_many(&txh->txh_memory_tohold,\n\t\t\t    1 << dn->dn_indblkshift, FTAG);\n\n\t\t\terr = dmu_tx_check_ioerr(zio, dn, 1, i);\n\t\t\tif (err != 0) {\n\t\t\t\ttx->tx_err = err;\n\t\t\t\t(void) zio_wait(zio);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\terr = zio_wait(zio);\n\t\tif (err != 0) {\n\t\t\ttx->tx_err = err;\n\t\t\treturn;\n\t\t}\n\t}\n}\n\nvoid\ndmu_tx_hold_free(dmu_tx_t *tx, uint64_t object, uint64_t off, uint64_t len)\n{\n\tdmu_tx_hold_t *txh;\n\n\ttxh = dmu_tx_hold_object_impl(tx, tx->tx_objset,\n\t    object, THT_FREE, off, len);\n\tif (txh != NULL) {\n\t\tdmu_tx_count_dnode(txh);\n\t\tdmu_tx_count_free(txh, off, len);\n\t}\n}\n\nvoid\ndmu_tx_hold_free_by_dnode(dmu_tx_t *tx, dnode_t *dn, uint64_t off, uint64_t len)\n{\n\tdmu_tx_hold_t *txh;\n\n\ttxh = dmu_tx_hold_dnode_impl(tx, dn, THT_FREE, off, len);\n\tif (txh != NULL) {\n\t\tdmu_tx_count_dnode(txh);\n\t\tdmu_tx_count_free(txh, off, len);\n\t}\n}\n\nstatic void\ndmu_tx_count_clone(dmu_tx_hold_t *txh, uint64_t off, uint64_t len)\n{\n\n\t \n\tdmu_tx_count_free(txh, off, len);\n}\n\nvoid\ndmu_tx_hold_clone_by_dnode(dmu_tx_t *tx, dnode_t *dn, uint64_t off, int len)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT0(tx->tx_txg);\n\tASSERT(len == 0 || UINT64_MAX - off >= len - 1);\n\n\ttxh = dmu_tx_hold_dnode_impl(tx, dn, THT_CLONE, off, len);\n\tif (txh != NULL) {\n\t\tdmu_tx_count_dnode(txh);\n\t\tdmu_tx_count_clone(txh, off, len);\n\t}\n}\n\nstatic void\ndmu_tx_hold_zap_impl(dmu_tx_hold_t *txh, const char *name)\n{\n\tdmu_tx_t *tx = txh->txh_tx;\n\tdnode_t *dn = txh->txh_dnode;\n\tint err;\n\textern int zap_micro_max_size;\n\n\tASSERT(tx->tx_txg == 0);\n\n\tdmu_tx_count_dnode(txh);\n\n\t \n\t(void) zfs_refcount_add_many(&txh->txh_space_towrite,\n\t    zap_micro_max_size, FTAG);\n\n\tif (dn == NULL)\n\t\treturn;\n\n\tASSERT3U(DMU_OT_BYTESWAP(dn->dn_type), ==, DMU_BSWAP_ZAP);\n\n\tif (dn->dn_maxblkid == 0 || name == NULL) {\n\t\t \n\t\terr = dmu_tx_check_ioerr(NULL, dn, 0, 0);\n\t\tif (err != 0) {\n\t\t\ttx->tx_err = err;\n\t\t}\n\t} else {\n\t\t \n\t\terr = zap_lookup_by_dnode(dn, name, 8, 0, NULL);\n\t\tif (err == EIO || err == ECKSUM || err == ENXIO) {\n\t\t\ttx->tx_err = err;\n\t\t}\n\t}\n}\n\nvoid\ndmu_tx_hold_zap(dmu_tx_t *tx, uint64_t object, int add, const char *name)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT0(tx->tx_txg);\n\n\ttxh = dmu_tx_hold_object_impl(tx, tx->tx_objset,\n\t    object, THT_ZAP, add, (uintptr_t)name);\n\tif (txh != NULL)\n\t\tdmu_tx_hold_zap_impl(txh, name);\n}\n\nvoid\ndmu_tx_hold_zap_by_dnode(dmu_tx_t *tx, dnode_t *dn, int add, const char *name)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT0(tx->tx_txg);\n\tASSERT(dn != NULL);\n\n\ttxh = dmu_tx_hold_dnode_impl(tx, dn, THT_ZAP, add, (uintptr_t)name);\n\tif (txh != NULL)\n\t\tdmu_tx_hold_zap_impl(txh, name);\n}\n\nvoid\ndmu_tx_hold_bonus(dmu_tx_t *tx, uint64_t object)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT(tx->tx_txg == 0);\n\n\ttxh = dmu_tx_hold_object_impl(tx, tx->tx_objset,\n\t    object, THT_BONUS, 0, 0);\n\tif (txh)\n\t\tdmu_tx_count_dnode(txh);\n}\n\nvoid\ndmu_tx_hold_bonus_by_dnode(dmu_tx_t *tx, dnode_t *dn)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT0(tx->tx_txg);\n\n\ttxh = dmu_tx_hold_dnode_impl(tx, dn, THT_BONUS, 0, 0);\n\tif (txh)\n\t\tdmu_tx_count_dnode(txh);\n}\n\nvoid\ndmu_tx_hold_space(dmu_tx_t *tx, uint64_t space)\n{\n\tdmu_tx_hold_t *txh;\n\n\tASSERT(tx->tx_txg == 0);\n\n\ttxh = dmu_tx_hold_object_impl(tx, tx->tx_objset,\n\t    DMU_NEW_OBJECT, THT_SPACE, space, 0);\n\tif (txh) {\n\t\t(void) zfs_refcount_add_many(\n\t\t    &txh->txh_space_towrite, space, FTAG);\n\t}\n}\n\n#ifdef ZFS_DEBUG\nvoid\ndmu_tx_dirty_buf(dmu_tx_t *tx, dmu_buf_impl_t *db)\n{\n\tboolean_t match_object = B_FALSE;\n\tboolean_t match_offset = B_FALSE;\n\n\tDB_DNODE_ENTER(db);\n\tdnode_t *dn = DB_DNODE(db);\n\tASSERT(tx->tx_txg != 0);\n\tASSERT(tx->tx_objset == NULL || dn->dn_objset == tx->tx_objset);\n\tASSERT3U(dn->dn_object, ==, db->db.db_object);\n\n\tif (tx->tx_anyobj) {\n\t\tDB_DNODE_EXIT(db);\n\t\treturn;\n\t}\n\n\t \n\tif (db->db.db_object == DMU_META_DNODE_OBJECT) {\n\t\tDB_DNODE_EXIT(db);\n\t\treturn;\n\t}\n\n\tfor (dmu_tx_hold_t *txh = list_head(&tx->tx_holds); txh != NULL;\n\t    txh = list_next(&tx->tx_holds, txh)) {\n\t\tASSERT3U(dn->dn_assigned_txg, ==, tx->tx_txg);\n\t\tif (txh->txh_dnode == dn && txh->txh_type != THT_NEWOBJECT)\n\t\t\tmatch_object = TRUE;\n\t\tif (txh->txh_dnode == NULL || txh->txh_dnode == dn) {\n\t\t\tint datablkshift = dn->dn_datablkshift ?\n\t\t\t    dn->dn_datablkshift : SPA_MAXBLOCKSHIFT;\n\t\t\tint epbs = dn->dn_indblkshift - SPA_BLKPTRSHIFT;\n\t\t\tint shift = datablkshift + epbs * db->db_level;\n\t\t\tuint64_t beginblk = shift >= 64 ? 0 :\n\t\t\t    (txh->txh_arg1 >> shift);\n\t\t\tuint64_t endblk = shift >= 64 ? 0 :\n\t\t\t    ((txh->txh_arg1 + txh->txh_arg2 - 1) >> shift);\n\t\t\tuint64_t blkid = db->db_blkid;\n\n\t\t\t \n\n\t\t\tdprintf(\"found txh type %x beginblk=%llx endblk=%llx\\n\",\n\t\t\t    txh->txh_type, (u_longlong_t)beginblk,\n\t\t\t    (u_longlong_t)endblk);\n\n\t\t\tswitch (txh->txh_type) {\n\t\t\tcase THT_WRITE:\n\t\t\t\tif (blkid >= beginblk && blkid <= endblk)\n\t\t\t\t\tmatch_offset = TRUE;\n\t\t\t\t \n\t\t\t\tif (blkid == DMU_BONUS_BLKID ||\n\t\t\t\t    blkid == DMU_SPILL_BLKID)\n\t\t\t\t\tmatch_offset = TRUE;\n\t\t\t\t \n\t\t\t\tif (blkid == 0)\n\t\t\t\t\tmatch_offset = TRUE;\n\t\t\t\tbreak;\n\t\t\tcase THT_APPEND:\n\t\t\t\tif (blkid >= beginblk && (blkid <= endblk ||\n\t\t\t\t    txh->txh_arg2 == DMU_OBJECT_END))\n\t\t\t\t\tmatch_offset = TRUE;\n\n\t\t\t\t \n\t\t\t\tASSERT(blkid != DMU_BONUS_BLKID &&\n\t\t\t\t    blkid != DMU_SPILL_BLKID);\n\n\t\t\t\t \n\t\t\t\tif (blkid == 0)\n\t\t\t\t\tmatch_offset = TRUE;\n\t\t\t\tbreak;\n\t\t\tcase THT_FREE:\n\t\t\t\t \n\t\t\t\tif (blkid >= beginblk && (blkid <= endblk ||\n\t\t\t\t    txh->txh_arg2 == DMU_OBJECT_END))\n\t\t\t\t\tmatch_offset = TRUE;\n\t\t\t\tbreak;\n\t\t\tcase THT_SPILL:\n\t\t\t\tif (blkid == DMU_SPILL_BLKID)\n\t\t\t\t\tmatch_offset = TRUE;\n\t\t\t\tbreak;\n\t\t\tcase THT_BONUS:\n\t\t\t\tif (blkid == DMU_BONUS_BLKID)\n\t\t\t\t\tmatch_offset = TRUE;\n\t\t\t\tbreak;\n\t\t\tcase THT_ZAP:\n\t\t\t\tmatch_offset = TRUE;\n\t\t\t\tbreak;\n\t\t\tcase THT_NEWOBJECT:\n\t\t\t\tmatch_object = TRUE;\n\t\t\t\tbreak;\n\t\t\tcase THT_CLONE:\n\t\t\t\tif (blkid >= beginblk && blkid <= endblk)\n\t\t\t\t\tmatch_offset = TRUE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tcmn_err(CE_PANIC, \"bad txh_type %d\",\n\t\t\t\t    txh->txh_type);\n\t\t\t}\n\t\t}\n\t\tif (match_object && match_offset) {\n\t\t\tDB_DNODE_EXIT(db);\n\t\t\treturn;\n\t\t}\n\t}\n\tDB_DNODE_EXIT(db);\n\tpanic(\"dirtying dbuf obj=%llx lvl=%u blkid=%llx but not tx_held\\n\",\n\t    (u_longlong_t)db->db.db_object, db->db_level,\n\t    (u_longlong_t)db->db_blkid);\n}\n#endif\n\n \nstatic const hrtime_t zfs_delay_max_ns = 100 * MICROSEC;  \n\n \nstatic void\ndmu_tx_delay(dmu_tx_t *tx, uint64_t dirty)\n{\n\tdsl_pool_t *dp = tx->tx_pool;\n\tuint64_t delay_min_bytes, wrlog;\n\thrtime_t wakeup, tx_time = 0, now;\n\n\t \n\tdelay_min_bytes =\n\t    zfs_dirty_data_max * zfs_delay_min_dirty_percent / 100;\n\tif (dirty > delay_min_bytes) {\n\t\t \n\t\tASSERT3U(dirty, <, zfs_dirty_data_max);\n\n\t\ttx_time = zfs_delay_scale * (dirty - delay_min_bytes) /\n\t\t    (zfs_dirty_data_max - dirty);\n\t}\n\n\t \n\twrlog = aggsum_upper_bound(&dp->dp_wrlog_total);\n\tdelay_min_bytes =\n\t    zfs_wrlog_data_max * zfs_delay_min_dirty_percent / 100;\n\tif (wrlog >= zfs_wrlog_data_max) {\n\t\ttx_time = zfs_delay_max_ns;\n\t} else if (wrlog > delay_min_bytes) {\n\t\ttx_time = MAX(zfs_delay_scale * (wrlog - delay_min_bytes) /\n\t\t    (zfs_wrlog_data_max - wrlog), tx_time);\n\t}\n\n\tif (tx_time == 0)\n\t\treturn;\n\n\ttx_time = MIN(tx_time, zfs_delay_max_ns);\n\tnow = gethrtime();\n\tif (now > tx->tx_start + tx_time)\n\t\treturn;\n\n\tDTRACE_PROBE3(delay__mintime, dmu_tx_t *, tx, uint64_t, dirty,\n\t    uint64_t, tx_time);\n\n\tmutex_enter(&dp->dp_lock);\n\twakeup = MAX(tx->tx_start + tx_time, dp->dp_last_wakeup + tx_time);\n\tdp->dp_last_wakeup = wakeup;\n\tmutex_exit(&dp->dp_lock);\n\n\tzfs_sleep_until(wakeup);\n}\n\n \nstatic int\ndmu_tx_try_assign(dmu_tx_t *tx, uint64_t txg_how)\n{\n\tspa_t *spa = tx->tx_pool->dp_spa;\n\n\tASSERT0(tx->tx_txg);\n\n\tif (tx->tx_err) {\n\t\tDMU_TX_STAT_BUMP(dmu_tx_error);\n\t\treturn (tx->tx_err);\n\t}\n\n\tif (spa_suspended(spa)) {\n\t\tDMU_TX_STAT_BUMP(dmu_tx_suspended);\n\n\t\t \n\t\tif (spa_get_failmode(spa) == ZIO_FAILURE_MODE_CONTINUE &&\n\t\t    !(txg_how & TXG_WAIT))\n\t\t\treturn (SET_ERROR(EIO));\n\n\t\treturn (SET_ERROR(ERESTART));\n\t}\n\n\tif (!tx->tx_dirty_delayed &&\n\t    dsl_pool_need_wrlog_delay(tx->tx_pool)) {\n\t\ttx->tx_wait_dirty = B_TRUE;\n\t\tDMU_TX_STAT_BUMP(dmu_tx_wrlog_delay);\n\t\treturn (SET_ERROR(ERESTART));\n\t}\n\n\tif (!tx->tx_dirty_delayed &&\n\t    dsl_pool_need_dirty_delay(tx->tx_pool)) {\n\t\ttx->tx_wait_dirty = B_TRUE;\n\t\tDMU_TX_STAT_BUMP(dmu_tx_dirty_delay);\n\t\treturn (SET_ERROR(ERESTART));\n\t}\n\n\ttx->tx_txg = txg_hold_open(tx->tx_pool, &tx->tx_txgh);\n\ttx->tx_needassign_txh = NULL;\n\n\t \n\n\tuint64_t towrite = 0;\n\tuint64_t tohold = 0;\n\tfor (dmu_tx_hold_t *txh = list_head(&tx->tx_holds); txh != NULL;\n\t    txh = list_next(&tx->tx_holds, txh)) {\n\t\tdnode_t *dn = txh->txh_dnode;\n\t\tif (dn != NULL) {\n\t\t\t \n\t\t\tASSERT(!RW_WRITE_HELD(&dn->dn_struct_rwlock));\n\n\t\t\tmutex_enter(&dn->dn_mtx);\n\t\t\tif (dn->dn_assigned_txg == tx->tx_txg - 1) {\n\t\t\t\tmutex_exit(&dn->dn_mtx);\n\t\t\t\ttx->tx_needassign_txh = txh;\n\t\t\t\tDMU_TX_STAT_BUMP(dmu_tx_group);\n\t\t\t\treturn (SET_ERROR(ERESTART));\n\t\t\t}\n\t\t\tif (dn->dn_assigned_txg == 0)\n\t\t\t\tdn->dn_assigned_txg = tx->tx_txg;\n\t\t\tASSERT3U(dn->dn_assigned_txg, ==, tx->tx_txg);\n\t\t\t(void) zfs_refcount_add(&dn->dn_tx_holds, tx);\n\t\t\tmutex_exit(&dn->dn_mtx);\n\t\t}\n\t\ttowrite += zfs_refcount_count(&txh->txh_space_towrite);\n\t\ttohold += zfs_refcount_count(&txh->txh_memory_tohold);\n\t}\n\n\t \n\tuint64_t asize = spa_get_worst_case_asize(tx->tx_pool->dp_spa, towrite);\n\t \n\tuint64_t memory = towrite + tohold;\n\n\tif (tx->tx_dir != NULL && asize != 0) {\n\t\tint err = dsl_dir_tempreserve_space(tx->tx_dir, memory,\n\t\t    asize, tx->tx_netfree, &tx->tx_tempreserve_cookie, tx);\n\t\tif (err != 0)\n\t\t\treturn (err);\n\t}\n\n\tDMU_TX_STAT_BUMP(dmu_tx_assigned);\n\n\treturn (0);\n}\n\nstatic void\ndmu_tx_unassign(dmu_tx_t *tx)\n{\n\tif (tx->tx_txg == 0)\n\t\treturn;\n\n\ttxg_rele_to_quiesce(&tx->tx_txgh);\n\n\t \n\tfor (dmu_tx_hold_t *txh = list_head(&tx->tx_holds);\n\t    txh && txh != tx->tx_needassign_txh;\n\t    txh = list_next(&tx->tx_holds, txh)) {\n\t\tdnode_t *dn = txh->txh_dnode;\n\n\t\tif (dn == NULL)\n\t\t\tcontinue;\n\t\tmutex_enter(&dn->dn_mtx);\n\t\tASSERT3U(dn->dn_assigned_txg, ==, tx->tx_txg);\n\n\t\tif (zfs_refcount_remove(&dn->dn_tx_holds, tx) == 0) {\n\t\t\tdn->dn_assigned_txg = 0;\n\t\t\tcv_broadcast(&dn->dn_notxholds);\n\t\t}\n\t\tmutex_exit(&dn->dn_mtx);\n\t}\n\n\ttxg_rele_to_sync(&tx->tx_txgh);\n\n\ttx->tx_lasttried_txg = tx->tx_txg;\n\ttx->tx_txg = 0;\n}\n\n \nint\ndmu_tx_assign(dmu_tx_t *tx, uint64_t txg_how)\n{\n\tint err;\n\n\tASSERT(tx->tx_txg == 0);\n\tASSERT0(txg_how & ~(TXG_WAIT | TXG_NOTHROTTLE));\n\tASSERT(!dsl_pool_sync_context(tx->tx_pool));\n\n\t \n\tIMPLY((txg_how & TXG_WAIT), !dsl_pool_config_held(tx->tx_pool));\n\n\tif ((txg_how & TXG_NOTHROTTLE))\n\t\ttx->tx_dirty_delayed = B_TRUE;\n\n\twhile ((err = dmu_tx_try_assign(tx, txg_how)) != 0) {\n\t\tdmu_tx_unassign(tx);\n\n\t\tif (err != ERESTART || !(txg_how & TXG_WAIT))\n\t\t\treturn (err);\n\n\t\tdmu_tx_wait(tx);\n\t}\n\n\ttxg_rele_to_quiesce(&tx->tx_txgh);\n\n\treturn (0);\n}\n\nvoid\ndmu_tx_wait(dmu_tx_t *tx)\n{\n\tspa_t *spa = tx->tx_pool->dp_spa;\n\tdsl_pool_t *dp = tx->tx_pool;\n\thrtime_t before;\n\n\tASSERT(tx->tx_txg == 0);\n\tASSERT(!dsl_pool_config_held(tx->tx_pool));\n\n\tbefore = gethrtime();\n\n\tif (tx->tx_wait_dirty) {\n\t\tuint64_t dirty;\n\n\t\t \n\t\tmutex_enter(&dp->dp_lock);\n\t\tif (dp->dp_dirty_total >= zfs_dirty_data_max)\n\t\t\tDMU_TX_STAT_BUMP(dmu_tx_dirty_over_max);\n\t\twhile (dp->dp_dirty_total >= zfs_dirty_data_max)\n\t\t\tcv_wait(&dp->dp_spaceavail_cv, &dp->dp_lock);\n\t\tdirty = dp->dp_dirty_total;\n\t\tmutex_exit(&dp->dp_lock);\n\n\t\tdmu_tx_delay(tx, dirty);\n\n\t\ttx->tx_wait_dirty = B_FALSE;\n\n\t\t \n\t\ttx->tx_dirty_delayed = B_TRUE;\n\t} else if (spa_suspended(spa) || tx->tx_lasttried_txg == 0) {\n\t\t \n\t\ttxg_wait_synced(dp, spa_last_synced_txg(spa) + 1);\n\t} else if (tx->tx_needassign_txh) {\n\t\tdnode_t *dn = tx->tx_needassign_txh->txh_dnode;\n\n\t\tmutex_enter(&dn->dn_mtx);\n\t\twhile (dn->dn_assigned_txg == tx->tx_lasttried_txg - 1)\n\t\t\tcv_wait(&dn->dn_notxholds, &dn->dn_mtx);\n\t\tmutex_exit(&dn->dn_mtx);\n\t\ttx->tx_needassign_txh = NULL;\n\t} else {\n\t\t \n\t\ttxg_wait_synced(dp, spa_last_synced_txg(spa) + 1);\n\t}\n\n\tspa_tx_assign_add_nsecs(spa, gethrtime() - before);\n}\n\nstatic void\ndmu_tx_destroy(dmu_tx_t *tx)\n{\n\tdmu_tx_hold_t *txh;\n\n\twhile ((txh = list_head(&tx->tx_holds)) != NULL) {\n\t\tdnode_t *dn = txh->txh_dnode;\n\n\t\tlist_remove(&tx->tx_holds, txh);\n\t\tzfs_refcount_destroy_many(&txh->txh_space_towrite,\n\t\t    zfs_refcount_count(&txh->txh_space_towrite));\n\t\tzfs_refcount_destroy_many(&txh->txh_memory_tohold,\n\t\t    zfs_refcount_count(&txh->txh_memory_tohold));\n\t\tkmem_free(txh, sizeof (dmu_tx_hold_t));\n\t\tif (dn != NULL)\n\t\t\tdnode_rele(dn, tx);\n\t}\n\n\tlist_destroy(&tx->tx_callbacks);\n\tlist_destroy(&tx->tx_holds);\n\tkmem_free(tx, sizeof (dmu_tx_t));\n}\n\nvoid\ndmu_tx_commit(dmu_tx_t *tx)\n{\n\tASSERT(tx->tx_txg != 0);\n\n\t \n\tfor (dmu_tx_hold_t *txh = list_head(&tx->tx_holds); txh != NULL;\n\t    txh = list_next(&tx->tx_holds, txh)) {\n\t\tdnode_t *dn = txh->txh_dnode;\n\n\t\tif (dn == NULL)\n\t\t\tcontinue;\n\n\t\tmutex_enter(&dn->dn_mtx);\n\t\tASSERT3U(dn->dn_assigned_txg, ==, tx->tx_txg);\n\n\t\tif (zfs_refcount_remove(&dn->dn_tx_holds, tx) == 0) {\n\t\t\tdn->dn_assigned_txg = 0;\n\t\t\tcv_broadcast(&dn->dn_notxholds);\n\t\t}\n\t\tmutex_exit(&dn->dn_mtx);\n\t}\n\n\tif (tx->tx_tempreserve_cookie)\n\t\tdsl_dir_tempreserve_clear(tx->tx_tempreserve_cookie, tx);\n\n\tif (!list_is_empty(&tx->tx_callbacks))\n\t\ttxg_register_callbacks(&tx->tx_txgh, &tx->tx_callbacks);\n\n\tif (tx->tx_anyobj == FALSE)\n\t\ttxg_rele_to_sync(&tx->tx_txgh);\n\n\tdmu_tx_destroy(tx);\n}\n\nvoid\ndmu_tx_abort(dmu_tx_t *tx)\n{\n\tASSERT(tx->tx_txg == 0);\n\n\t \n\tif (!list_is_empty(&tx->tx_callbacks))\n\t\tdmu_tx_do_callbacks(&tx->tx_callbacks, SET_ERROR(ECANCELED));\n\n\tdmu_tx_destroy(tx);\n}\n\nuint64_t\ndmu_tx_get_txg(dmu_tx_t *tx)\n{\n\tASSERT(tx->tx_txg != 0);\n\treturn (tx->tx_txg);\n}\n\ndsl_pool_t *\ndmu_tx_pool(dmu_tx_t *tx)\n{\n\tASSERT(tx->tx_pool != NULL);\n\treturn (tx->tx_pool);\n}\n\nvoid\ndmu_tx_callback_register(dmu_tx_t *tx, dmu_tx_callback_func_t *func, void *data)\n{\n\tdmu_tx_callback_t *dcb;\n\n\tdcb = kmem_alloc(sizeof (dmu_tx_callback_t), KM_SLEEP);\n\n\tdcb->dcb_func = func;\n\tdcb->dcb_data = data;\n\n\tlist_insert_tail(&tx->tx_callbacks, dcb);\n}\n\n \nvoid\ndmu_tx_do_callbacks(list_t *cb_list, int error)\n{\n\tdmu_tx_callback_t *dcb;\n\n\twhile ((dcb = list_remove_tail(cb_list)) != NULL) {\n\t\tdcb->dcb_func(dcb->dcb_data, error);\n\t\tkmem_free(dcb, sizeof (dmu_tx_callback_t));\n\t}\n}\n\n \n\n \nstatic void\ndmu_tx_sa_registration_hold(sa_os_t *sa, dmu_tx_t *tx)\n{\n\tif (!sa->sa_need_attr_registration)\n\t\treturn;\n\n\tfor (int i = 0; i != sa->sa_num_attrs; i++) {\n\t\tif (!sa->sa_attr_table[i].sa_registered) {\n\t\t\tif (sa->sa_reg_attr_obj)\n\t\t\t\tdmu_tx_hold_zap(tx, sa->sa_reg_attr_obj,\n\t\t\t\t    B_TRUE, sa->sa_attr_table[i].sa_name);\n\t\t\telse\n\t\t\t\tdmu_tx_hold_zap(tx, DMU_NEW_OBJECT,\n\t\t\t\t    B_TRUE, sa->sa_attr_table[i].sa_name);\n\t\t}\n\t}\n}\n\nvoid\ndmu_tx_hold_spill(dmu_tx_t *tx, uint64_t object)\n{\n\tdmu_tx_hold_t *txh;\n\n\ttxh = dmu_tx_hold_object_impl(tx, tx->tx_objset, object,\n\t    THT_SPILL, 0, 0);\n\tif (txh != NULL)\n\t\t(void) zfs_refcount_add_many(&txh->txh_space_towrite,\n\t\t    SPA_OLD_MAXBLOCKSIZE, FTAG);\n}\n\nvoid\ndmu_tx_hold_sa_create(dmu_tx_t *tx, int attrsize)\n{\n\tsa_os_t *sa = tx->tx_objset->os_sa;\n\n\tdmu_tx_hold_bonus(tx, DMU_NEW_OBJECT);\n\n\tif (tx->tx_objset->os_sa->sa_master_obj == 0)\n\t\treturn;\n\n\tif (tx->tx_objset->os_sa->sa_layout_attr_obj) {\n\t\tdmu_tx_hold_zap(tx, sa->sa_layout_attr_obj, B_TRUE, NULL);\n\t} else {\n\t\tdmu_tx_hold_zap(tx, sa->sa_master_obj, B_TRUE, SA_LAYOUTS);\n\t\tdmu_tx_hold_zap(tx, sa->sa_master_obj, B_TRUE, SA_REGISTRY);\n\t\tdmu_tx_hold_zap(tx, DMU_NEW_OBJECT, B_TRUE, NULL);\n\t\tdmu_tx_hold_zap(tx, DMU_NEW_OBJECT, B_TRUE, NULL);\n\t}\n\n\tdmu_tx_sa_registration_hold(sa, tx);\n\n\tif (attrsize <= DN_OLD_MAX_BONUSLEN && !sa->sa_force_spill)\n\t\treturn;\n\n\t(void) dmu_tx_hold_object_impl(tx, tx->tx_objset, DMU_NEW_OBJECT,\n\t    THT_SPILL, 0, 0);\n}\n\n \nvoid\ndmu_tx_hold_sa(dmu_tx_t *tx, sa_handle_t *hdl, boolean_t may_grow)\n{\n\tuint64_t object;\n\tsa_os_t *sa = tx->tx_objset->os_sa;\n\n\tASSERT(hdl != NULL);\n\n\tobject = sa_handle_object(hdl);\n\n\tdmu_buf_impl_t *db = (dmu_buf_impl_t *)hdl->sa_bonus;\n\tDB_DNODE_ENTER(db);\n\tdmu_tx_hold_bonus_by_dnode(tx, DB_DNODE(db));\n\tDB_DNODE_EXIT(db);\n\n\tif (tx->tx_objset->os_sa->sa_master_obj == 0)\n\t\treturn;\n\n\tif (tx->tx_objset->os_sa->sa_reg_attr_obj == 0 ||\n\t    tx->tx_objset->os_sa->sa_layout_attr_obj == 0) {\n\t\tdmu_tx_hold_zap(tx, sa->sa_master_obj, B_TRUE, SA_LAYOUTS);\n\t\tdmu_tx_hold_zap(tx, sa->sa_master_obj, B_TRUE, SA_REGISTRY);\n\t\tdmu_tx_hold_zap(tx, DMU_NEW_OBJECT, B_TRUE, NULL);\n\t\tdmu_tx_hold_zap(tx, DMU_NEW_OBJECT, B_TRUE, NULL);\n\t}\n\n\tdmu_tx_sa_registration_hold(sa, tx);\n\n\tif (may_grow && tx->tx_objset->os_sa->sa_layout_attr_obj)\n\t\tdmu_tx_hold_zap(tx, sa->sa_layout_attr_obj, B_TRUE, NULL);\n\n\tif (sa->sa_force_spill || may_grow || hdl->sa_spill) {\n\t\tASSERT(tx->tx_txg == 0);\n\t\tdmu_tx_hold_spill(tx, object);\n\t} else {\n\t\tdnode_t *dn;\n\n\t\tDB_DNODE_ENTER(db);\n\t\tdn = DB_DNODE(db);\n\t\tif (dn->dn_have_spill) {\n\t\t\tASSERT(tx->tx_txg == 0);\n\t\t\tdmu_tx_hold_spill(tx, object);\n\t\t}\n\t\tDB_DNODE_EXIT(db);\n\t}\n}\n\nvoid\ndmu_tx_init(void)\n{\n\tdmu_tx_ksp = kstat_create(\"zfs\", 0, \"dmu_tx\", \"misc\",\n\t    KSTAT_TYPE_NAMED, sizeof (dmu_tx_stats) / sizeof (kstat_named_t),\n\t    KSTAT_FLAG_VIRTUAL);\n\n\tif (dmu_tx_ksp != NULL) {\n\t\tdmu_tx_ksp->ks_data = &dmu_tx_stats;\n\t\tkstat_install(dmu_tx_ksp);\n\t}\n}\n\nvoid\ndmu_tx_fini(void)\n{\n\tif (dmu_tx_ksp != NULL) {\n\t\tkstat_delete(dmu_tx_ksp);\n\t\tdmu_tx_ksp = NULL;\n\t}\n}\n\n#if defined(_KERNEL)\nEXPORT_SYMBOL(dmu_tx_create);\nEXPORT_SYMBOL(dmu_tx_hold_write);\nEXPORT_SYMBOL(dmu_tx_hold_write_by_dnode);\nEXPORT_SYMBOL(dmu_tx_hold_append);\nEXPORT_SYMBOL(dmu_tx_hold_append_by_dnode);\nEXPORT_SYMBOL(dmu_tx_hold_free);\nEXPORT_SYMBOL(dmu_tx_hold_free_by_dnode);\nEXPORT_SYMBOL(dmu_tx_hold_zap);\nEXPORT_SYMBOL(dmu_tx_hold_zap_by_dnode);\nEXPORT_SYMBOL(dmu_tx_hold_bonus);\nEXPORT_SYMBOL(dmu_tx_hold_bonus_by_dnode);\nEXPORT_SYMBOL(dmu_tx_abort);\nEXPORT_SYMBOL(dmu_tx_assign);\nEXPORT_SYMBOL(dmu_tx_wait);\nEXPORT_SYMBOL(dmu_tx_commit);\nEXPORT_SYMBOL(dmu_tx_mark_netfree);\nEXPORT_SYMBOL(dmu_tx_get_txg);\nEXPORT_SYMBOL(dmu_tx_callback_register);\nEXPORT_SYMBOL(dmu_tx_do_callbacks);\nEXPORT_SYMBOL(dmu_tx_hold_spill);\nEXPORT_SYMBOL(dmu_tx_hold_sa_create);\nEXPORT_SYMBOL(dmu_tx_hold_sa);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}