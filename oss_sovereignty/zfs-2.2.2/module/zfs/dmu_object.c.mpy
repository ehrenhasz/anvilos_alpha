{
  "module_name": "dmu_object.c",
  "hash_id": "70712811aa3d2778f9b49ef87efe4487389a82283aad8536192450369acb2df2",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/dmu_object.c",
  "human_readable_source": " \n \n\n#include <sys/dbuf.h>\n#include <sys/dmu.h>\n#include <sys/dmu_impl.h>\n#include <sys/dmu_objset.h>\n#include <sys/dmu_tx.h>\n#include <sys/dnode.h>\n#include <sys/zap.h>\n#include <sys/zfeature.h>\n#include <sys/dsl_dataset.h>\n\n \nuint_t dmu_object_alloc_chunk_shift = 7;\n\nstatic uint64_t\ndmu_object_alloc_impl(objset_t *os, dmu_object_type_t ot, int blocksize,\n    int indirect_blockshift, dmu_object_type_t bonustype, int bonuslen,\n    int dnodesize, dnode_t **allocated_dnode, const void *tag, dmu_tx_t *tx)\n{\n\tuint64_t object;\n\tuint64_t L1_dnode_count = DNODES_PER_BLOCK <<\n\t    (DMU_META_DNODE(os)->dn_indblkshift - SPA_BLKPTRSHIFT);\n\tdnode_t *dn = NULL;\n\tint dn_slots = dnodesize >> DNODE_SHIFT;\n\tboolean_t restarted = B_FALSE;\n\tuint64_t *cpuobj = NULL;\n\tuint_t dnodes_per_chunk = 1 << dmu_object_alloc_chunk_shift;\n\tint error;\n\n\tcpuobj = &os->os_obj_next_percpu[CPU_SEQID_UNSTABLE %\n\t    os->os_obj_next_percpu_len];\n\n\tif (dn_slots == 0) {\n\t\tdn_slots = DNODE_MIN_SLOTS;\n\t} else {\n\t\tASSERT3S(dn_slots, >=, DNODE_MIN_SLOTS);\n\t\tASSERT3S(dn_slots, <=, DNODE_MAX_SLOTS);\n\t}\n\n\t \n\tif (dnodes_per_chunk < DNODES_PER_BLOCK)\n\t\tdnodes_per_chunk = DNODES_PER_BLOCK;\n\tif (dnodes_per_chunk > L1_dnode_count)\n\t\tdnodes_per_chunk = L1_dnode_count;\n\n\t \n\tif (allocated_dnode != NULL) {\n\t\tASSERT3P(tag, !=, NULL);\n\t} else {\n\t\tASSERT3P(tag, ==, NULL);\n\t\ttag = FTAG;\n\t}\n\n\tobject = *cpuobj;\n\tfor (;;) {\n\t\t \n\t\tif ((P2PHASE(object, dnodes_per_chunk) == 0) ||\n\t\t    (P2PHASE(object + dn_slots - 1, dnodes_per_chunk) <\n\t\t    dn_slots)) {\n\t\t\tDNODE_STAT_BUMP(dnode_alloc_next_chunk);\n\t\t\tmutex_enter(&os->os_obj_lock);\n\t\t\tASSERT0(P2PHASE(os->os_obj_next_chunk,\n\t\t\t    dnodes_per_chunk));\n\t\t\tobject = os->os_obj_next_chunk;\n\n\t\t\t \n\t\t\tif (P2PHASE(object, L1_dnode_count) == 0) {\n\t\t\t\tuint64_t offset;\n\t\t\t\tuint64_t blkfill;\n\t\t\t\tint minlvl;\n\t\t\t\tif (os->os_rescan_dnodes) {\n\t\t\t\t\toffset = 0;\n\t\t\t\t\tos->os_rescan_dnodes = B_FALSE;\n\t\t\t\t} else {\n\t\t\t\t\toffset = object << DNODE_SHIFT;\n\t\t\t\t}\n\t\t\t\tblkfill = restarted ? 1 : DNODES_PER_BLOCK >> 2;\n\t\t\t\tminlvl = restarted ? 1 : 2;\n\t\t\t\trestarted = B_TRUE;\n\t\t\t\terror = dnode_next_offset(DMU_META_DNODE(os),\n\t\t\t\t    DNODE_FIND_HOLE, &offset, minlvl,\n\t\t\t\t    blkfill, 0);\n\t\t\t\tif (error == 0) {\n\t\t\t\t\tobject = offset >> DNODE_SHIFT;\n\t\t\t\t}\n\t\t\t}\n\t\t\t \n\t\t\tos->os_obj_next_chunk =\n\t\t\t    P2ALIGN(object, dnodes_per_chunk) +\n\t\t\t    dnodes_per_chunk;\n\t\t\t(void) atomic_swap_64(cpuobj, object);\n\t\t\tmutex_exit(&os->os_obj_lock);\n\t\t}\n\n\t\t \n\t\tobject = atomic_add_64_nv(cpuobj, dn_slots) - dn_slots;\n\n\t\t \n\t\terror = dnode_hold_impl(os, object, DNODE_MUST_BE_FREE,\n\t\t    dn_slots, tag, &dn);\n\t\tif (error == 0) {\n\t\t\trw_enter(&dn->dn_struct_rwlock, RW_WRITER);\n\t\t\t \n\t\t\tif (dn->dn_type == DMU_OT_NONE) {\n\t\t\t\tdnode_allocate(dn, ot, blocksize,\n\t\t\t\t    indirect_blockshift, bonustype,\n\t\t\t\t    bonuslen, dn_slots, tx);\n\t\t\t\trw_exit(&dn->dn_struct_rwlock);\n\t\t\t\tdmu_tx_add_new_object(tx, dn);\n\n\t\t\t\t \n\t\t\t\tif (allocated_dnode != NULL)\n\t\t\t\t\t*allocated_dnode = dn;\n\t\t\t\telse\n\t\t\t\t\tdnode_rele(dn, tag);\n\n\t\t\t\treturn (object);\n\t\t\t}\n\t\t\trw_exit(&dn->dn_struct_rwlock);\n\t\t\tdnode_rele(dn, tag);\n\t\t\tDNODE_STAT_BUMP(dnode_alloc_race);\n\t\t}\n\n\t\t \n\t\tif (dmu_object_next(os, &object, B_TRUE, 0) != 0) {\n\t\t\tobject = P2ROUNDUP(object + 1, DNODES_PER_BLOCK);\n\t\t\tDNODE_STAT_BUMP(dnode_alloc_next_block);\n\t\t}\n\t\t(void) atomic_swap_64(cpuobj, object);\n\t}\n}\n\nuint64_t\ndmu_object_alloc(objset_t *os, dmu_object_type_t ot, int blocksize,\n    dmu_object_type_t bonustype, int bonuslen, dmu_tx_t *tx)\n{\n\treturn dmu_object_alloc_impl(os, ot, blocksize, 0, bonustype,\n\t    bonuslen, 0, NULL, NULL, tx);\n}\n\nuint64_t\ndmu_object_alloc_ibs(objset_t *os, dmu_object_type_t ot, int blocksize,\n    int indirect_blockshift, dmu_object_type_t bonustype, int bonuslen,\n    dmu_tx_t *tx)\n{\n\treturn dmu_object_alloc_impl(os, ot, blocksize, indirect_blockshift,\n\t    bonustype, bonuslen, 0, NULL, NULL, tx);\n}\n\nuint64_t\ndmu_object_alloc_dnsize(objset_t *os, dmu_object_type_t ot, int blocksize,\n    dmu_object_type_t bonustype, int bonuslen, int dnodesize, dmu_tx_t *tx)\n{\n\treturn (dmu_object_alloc_impl(os, ot, blocksize, 0, bonustype,\n\t    bonuslen, dnodesize, NULL, NULL, tx));\n}\n\n \nuint64_t\ndmu_object_alloc_hold(objset_t *os, dmu_object_type_t ot, int blocksize,\n    int indirect_blockshift, dmu_object_type_t bonustype, int bonuslen,\n    int dnodesize, dnode_t **allocated_dnode, const void *tag, dmu_tx_t *tx)\n{\n\treturn (dmu_object_alloc_impl(os, ot, blocksize, indirect_blockshift,\n\t    bonustype, bonuslen, dnodesize, allocated_dnode, tag, tx));\n}\n\nint\ndmu_object_claim(objset_t *os, uint64_t object, dmu_object_type_t ot,\n    int blocksize, dmu_object_type_t bonustype, int bonuslen, dmu_tx_t *tx)\n{\n\treturn (dmu_object_claim_dnsize(os, object, ot, blocksize, bonustype,\n\t    bonuslen, 0, tx));\n}\n\nint\ndmu_object_claim_dnsize(objset_t *os, uint64_t object, dmu_object_type_t ot,\n    int blocksize, dmu_object_type_t bonustype, int bonuslen,\n    int dnodesize, dmu_tx_t *tx)\n{\n\tdnode_t *dn;\n\tint dn_slots = dnodesize >> DNODE_SHIFT;\n\tint err;\n\n\tif (dn_slots == 0)\n\t\tdn_slots = DNODE_MIN_SLOTS;\n\tASSERT3S(dn_slots, >=, DNODE_MIN_SLOTS);\n\tASSERT3S(dn_slots, <=, DNODE_MAX_SLOTS);\n\n\tif (object == DMU_META_DNODE_OBJECT && !dmu_tx_private_ok(tx))\n\t\treturn (SET_ERROR(EBADF));\n\n\terr = dnode_hold_impl(os, object, DNODE_MUST_BE_FREE, dn_slots,\n\t    FTAG, &dn);\n\tif (err)\n\t\treturn (err);\n\n\tdnode_allocate(dn, ot, blocksize, 0, bonustype, bonuslen, dn_slots, tx);\n\tdmu_tx_add_new_object(tx, dn);\n\n\tdnode_rele(dn, FTAG);\n\n\treturn (0);\n}\n\nint\ndmu_object_reclaim(objset_t *os, uint64_t object, dmu_object_type_t ot,\n    int blocksize, dmu_object_type_t bonustype, int bonuslen, dmu_tx_t *tx)\n{\n\treturn (dmu_object_reclaim_dnsize(os, object, ot, blocksize, bonustype,\n\t    bonuslen, DNODE_MIN_SIZE, B_FALSE, tx));\n}\n\nint\ndmu_object_reclaim_dnsize(objset_t *os, uint64_t object, dmu_object_type_t ot,\n    int blocksize, dmu_object_type_t bonustype, int bonuslen, int dnodesize,\n    boolean_t keep_spill, dmu_tx_t *tx)\n{\n\tdnode_t *dn;\n\tint dn_slots = dnodesize >> DNODE_SHIFT;\n\tint err;\n\n\tif (dn_slots == 0)\n\t\tdn_slots = DNODE_MIN_SLOTS;\n\n\tif (object == DMU_META_DNODE_OBJECT)\n\t\treturn (SET_ERROR(EBADF));\n\n\terr = dnode_hold_impl(os, object, DNODE_MUST_BE_ALLOCATED, 0,\n\t    FTAG, &dn);\n\tif (err)\n\t\treturn (err);\n\n\tdnode_reallocate(dn, ot, blocksize, bonustype, bonuslen, dn_slots,\n\t    keep_spill, tx);\n\n\tdnode_rele(dn, FTAG);\n\treturn (err);\n}\n\nint\ndmu_object_rm_spill(objset_t *os, uint64_t object, dmu_tx_t *tx)\n{\n\tdnode_t *dn;\n\tint err;\n\n\terr = dnode_hold_impl(os, object, DNODE_MUST_BE_ALLOCATED, 0,\n\t    FTAG, &dn);\n\tif (err)\n\t\treturn (err);\n\n\trw_enter(&dn->dn_struct_rwlock, RW_WRITER);\n\tif (dn->dn_phys->dn_flags & DNODE_FLAG_SPILL_BLKPTR) {\n\t\tdbuf_rm_spill(dn, tx);\n\t\tdnode_rm_spill(dn, tx);\n\t}\n\trw_exit(&dn->dn_struct_rwlock);\n\n\tdnode_rele(dn, FTAG);\n\treturn (err);\n}\n\nint\ndmu_object_free(objset_t *os, uint64_t object, dmu_tx_t *tx)\n{\n\tdnode_t *dn;\n\tint err;\n\n\tASSERT(object != DMU_META_DNODE_OBJECT || dmu_tx_private_ok(tx));\n\n\terr = dnode_hold_impl(os, object, DNODE_MUST_BE_ALLOCATED, 0,\n\t    FTAG, &dn);\n\tif (err)\n\t\treturn (err);\n\n\tASSERT(dn->dn_type != DMU_OT_NONE);\n\t \n\tdnode_free_range(dn, 0, DMU_OBJECT_END, tx);\n\tdnode_free(dn, tx);\n\tdnode_rele(dn, FTAG);\n\n\treturn (0);\n}\n\n \nint\ndmu_object_next(objset_t *os, uint64_t *objectp, boolean_t hole, uint64_t txg)\n{\n\tuint64_t offset;\n\tuint64_t start_obj;\n\tstruct dsl_dataset *ds = os->os_dsl_dataset;\n\tint error;\n\n\tif (*objectp == 0) {\n\t\tstart_obj = 1;\n\t} else if (ds && dsl_dataset_feature_is_active(ds,\n\t    SPA_FEATURE_LARGE_DNODE)) {\n\t\tuint64_t i = *objectp + 1;\n\t\tuint64_t last_obj = *objectp | (DNODES_PER_BLOCK - 1);\n\t\tdmu_object_info_t doi;\n\n\t\t \n\t\twhile (i <= last_obj) {\n\t\t\tif (i == 0)\n\t\t\t\treturn (SET_ERROR(ESRCH));\n\t\t\terror = dmu_object_info(os, i, &doi);\n\t\t\tif (error == ENOENT) {\n\t\t\t\tif (hole) {\n\t\t\t\t\t*objectp = i;\n\t\t\t\t\treturn (0);\n\t\t\t\t} else {\n\t\t\t\t\ti++;\n\t\t\t\t}\n\t\t\t} else if (error == EEXIST) {\n\t\t\t\ti++;\n\t\t\t} else if (error == 0) {\n\t\t\t\tif (hole) {\n\t\t\t\t\ti += doi.doi_dnodesize >> DNODE_SHIFT;\n\t\t\t\t} else {\n\t\t\t\t\t*objectp = i;\n\t\t\t\t\treturn (0);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn (error);\n\t\t\t}\n\t\t}\n\n\t\tstart_obj = i;\n\t} else {\n\t\tstart_obj = *objectp + 1;\n\t}\n\n\toffset = start_obj << DNODE_SHIFT;\n\n\terror = dnode_next_offset(DMU_META_DNODE(os),\n\t    (hole ? DNODE_FIND_HOLE : 0), &offset, 0, DNODES_PER_BLOCK, txg);\n\n\t*objectp = offset >> DNODE_SHIFT;\n\n\treturn (error);\n}\n\n \nvoid\ndmu_object_zapify(objset_t *mos, uint64_t object, dmu_object_type_t old_type,\n    dmu_tx_t *tx)\n{\n\tdnode_t *dn;\n\n\tASSERT(dmu_tx_is_syncing(tx));\n\n\tVERIFY0(dnode_hold(mos, object, FTAG, &dn));\n\tif (dn->dn_type == DMU_OTN_ZAP_METADATA) {\n\t\tdnode_rele(dn, FTAG);\n\t\treturn;\n\t}\n\tASSERT3U(dn->dn_type, ==, old_type);\n\tASSERT0(dn->dn_maxblkid);\n\n\t \n\tmzap_create_impl(dn, 0, 0, tx);\n\n\tdn->dn_next_type[tx->tx_txg & TXG_MASK] = dn->dn_type =\n\t    DMU_OTN_ZAP_METADATA;\n\tdnode_setdirty(dn, tx);\n\tdnode_rele(dn, FTAG);\n\n\tspa_feature_incr(dmu_objset_spa(mos),\n\t    SPA_FEATURE_EXTENSIBLE_DATASET, tx);\n}\n\nvoid\ndmu_object_free_zapified(objset_t *mos, uint64_t object, dmu_tx_t *tx)\n{\n\tdnode_t *dn;\n\tdmu_object_type_t t;\n\n\tASSERT(dmu_tx_is_syncing(tx));\n\n\tVERIFY0(dnode_hold(mos, object, FTAG, &dn));\n\tt = dn->dn_type;\n\tdnode_rele(dn, FTAG);\n\n\tif (t == DMU_OTN_ZAP_METADATA) {\n\t\tspa_feature_decr(dmu_objset_spa(mos),\n\t\t    SPA_FEATURE_EXTENSIBLE_DATASET, tx);\n\t}\n\tVERIFY0(dmu_object_free(mos, object, tx));\n}\n\nEXPORT_SYMBOL(dmu_object_alloc);\nEXPORT_SYMBOL(dmu_object_alloc_ibs);\nEXPORT_SYMBOL(dmu_object_alloc_dnsize);\nEXPORT_SYMBOL(dmu_object_alloc_hold);\nEXPORT_SYMBOL(dmu_object_claim);\nEXPORT_SYMBOL(dmu_object_claim_dnsize);\nEXPORT_SYMBOL(dmu_object_reclaim);\nEXPORT_SYMBOL(dmu_object_reclaim_dnsize);\nEXPORT_SYMBOL(dmu_object_rm_spill);\nEXPORT_SYMBOL(dmu_object_free);\nEXPORT_SYMBOL(dmu_object_next);\nEXPORT_SYMBOL(dmu_object_zapify);\nEXPORT_SYMBOL(dmu_object_free_zapified);\n\n \nZFS_MODULE_PARAM(zfs, , dmu_object_alloc_chunk_shift, UINT, ZMOD_RW,\n\t\"CPU-specific allocator grabs 2^N objects at once\");\n \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}