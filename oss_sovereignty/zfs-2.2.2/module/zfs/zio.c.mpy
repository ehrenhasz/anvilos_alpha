{
  "module_name": "zio.c",
  "hash_id": "f89aa555d93dfe4258827218a6fae976fc982e7fc91a1f7d8d6d4d2a46965798",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/zio.c",
  "human_readable_source": " \n \n\n#include <sys/sysmacros.h>\n#include <sys/zfs_context.h>\n#include <sys/fm/fs/zfs.h>\n#include <sys/spa.h>\n#include <sys/txg.h>\n#include <sys/spa_impl.h>\n#include <sys/vdev_impl.h>\n#include <sys/vdev_trim.h>\n#include <sys/zio_impl.h>\n#include <sys/zio_compress.h>\n#include <sys/zio_checksum.h>\n#include <sys/dmu_objset.h>\n#include <sys/arc.h>\n#include <sys/brt.h>\n#include <sys/ddt.h>\n#include <sys/blkptr.h>\n#include <sys/zfeature.h>\n#include <sys/dsl_scan.h>\n#include <sys/metaslab_impl.h>\n#include <sys/time.h>\n#include <sys/trace_zfs.h>\n#include <sys/abd.h>\n#include <sys/dsl_crypt.h>\n#include <cityhash.h>\n\n \nconst char *const zio_type_name[ZIO_TYPES] = {\n\t \n\t\"z_null\", \"z_rd\", \"z_wr\", \"z_fr\", \"z_cl\", \"z_ioctl\", \"z_trim\"\n};\n\nint zio_dva_throttle_enabled = B_TRUE;\nstatic int zio_deadman_log_all = B_FALSE;\n\n \nstatic kmem_cache_t *zio_cache;\nstatic kmem_cache_t *zio_link_cache;\nkmem_cache_t *zio_buf_cache[SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT];\nkmem_cache_t *zio_data_buf_cache[SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT];\n#if defined(ZFS_DEBUG) && !defined(_KERNEL)\nstatic uint64_t zio_buf_cache_allocs[SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT];\nstatic uint64_t zio_buf_cache_frees[SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT];\n#endif\n\n \nstatic uint_t zio_slow_io_ms = (30 * MILLISEC);\n\n#define\tBP_SPANB(indblkshift, level) \\\n\t(((uint64_t)1) << ((level) * ((indblkshift) - SPA_BLKPTRSHIFT)))\n#define\tCOMPARE_META_LEVEL\t0x80000000ul\n \n\n \nuint_t zfs_sync_pass_deferred_free = 2;\n\n \nstatic uint_t zfs_sync_pass_dont_compress = 8;\n\n \nstatic uint_t zfs_sync_pass_rewrite = 2;\n\n \n#define\tIO_IS_ALLOCATING(zio) ((zio)->io_orig_pipeline & ZIO_STAGE_DVA_ALLOCATE)\n\n \nint zio_exclude_metadata = 0;\nstatic int zio_requeue_io_start_cut_in_line = 1;\n\n#ifdef ZFS_DEBUG\nstatic const int zio_buf_debug_limit = 16384;\n#else\nstatic const int zio_buf_debug_limit = 0;\n#endif\n\nstatic inline void __zio_execute(zio_t *zio);\n\nstatic void zio_taskq_dispatch(zio_t *, zio_taskq_type_t, boolean_t);\n\nvoid\nzio_init(void)\n{\n\tsize_t c;\n\n\tzio_cache = kmem_cache_create(\"zio_cache\",\n\t    sizeof (zio_t), 0, NULL, NULL, NULL, NULL, NULL, 0);\n\tzio_link_cache = kmem_cache_create(\"zio_link_cache\",\n\t    sizeof (zio_link_t), 0, NULL, NULL, NULL, NULL, NULL, 0);\n\n\t \n\tfor (c = 0; c < SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT; c++) {\n\t\tsize_t size = (c + 1) << SPA_MINBLOCKSHIFT;\n\t\tsize_t p2 = size;\n\t\tsize_t align = 0;\n\t\tsize_t data_cflags, cflags;\n\n\t\tdata_cflags = KMC_NODEBUG;\n\t\tcflags = (zio_exclude_metadata || size > zio_buf_debug_limit) ?\n\t\t    KMC_NODEBUG : 0;\n\n\t\twhile (!ISP2(p2))\n\t\t\tp2 &= p2 - 1;\n\n#ifndef _KERNEL\n\t\t \n\t\tif (arc_watch && !IS_P2ALIGNED(size, PAGESIZE))\n\t\t\tcontinue;\n\t\t \n\t\talign = 8 * SPA_MINBLOCKSIZE;\n#else\n\t\tif (size < PAGESIZE) {\n\t\t\talign = SPA_MINBLOCKSIZE;\n\t\t} else if (IS_P2ALIGNED(size, p2 >> 2)) {\n\t\t\talign = PAGESIZE;\n\t\t}\n#endif\n\n\t\tif (align != 0) {\n\t\t\tchar name[36];\n\t\t\tif (cflags == data_cflags) {\n\t\t\t\t \n\t\t\t\t(void) snprintf(name, sizeof (name),\n\t\t\t\t    \"zio_buf_comb_%lu\", (ulong_t)size);\n\t\t\t\tzio_buf_cache[c] = kmem_cache_create(name,\n\t\t\t\t    size, align, NULL, NULL, NULL, NULL, NULL,\n\t\t\t\t    cflags);\n\t\t\t\tzio_data_buf_cache[c] = zio_buf_cache[c];\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t(void) snprintf(name, sizeof (name), \"zio_buf_%lu\",\n\t\t\t    (ulong_t)size);\n\t\t\tzio_buf_cache[c] = kmem_cache_create(name, size,\n\t\t\t    align, NULL, NULL, NULL, NULL, NULL, cflags);\n\n\t\t\t(void) snprintf(name, sizeof (name), \"zio_data_buf_%lu\",\n\t\t\t    (ulong_t)size);\n\t\t\tzio_data_buf_cache[c] = kmem_cache_create(name, size,\n\t\t\t    align, NULL, NULL, NULL, NULL, NULL, data_cflags);\n\t\t}\n\t}\n\n\twhile (--c != 0) {\n\t\tASSERT(zio_buf_cache[c] != NULL);\n\t\tif (zio_buf_cache[c - 1] == NULL)\n\t\t\tzio_buf_cache[c - 1] = zio_buf_cache[c];\n\n\t\tASSERT(zio_data_buf_cache[c] != NULL);\n\t\tif (zio_data_buf_cache[c - 1] == NULL)\n\t\t\tzio_data_buf_cache[c - 1] = zio_data_buf_cache[c];\n\t}\n\n\tzio_inject_init();\n\n\tlz4_init();\n}\n\nvoid\nzio_fini(void)\n{\n\tsize_t n = SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT;\n\n#if defined(ZFS_DEBUG) && !defined(_KERNEL)\n\tfor (size_t i = 0; i < n; i++) {\n\t\tif (zio_buf_cache_allocs[i] != zio_buf_cache_frees[i])\n\t\t\t(void) printf(\"zio_fini: [%d] %llu != %llu\\n\",\n\t\t\t    (int)((i + 1) << SPA_MINBLOCKSHIFT),\n\t\t\t    (long long unsigned)zio_buf_cache_allocs[i],\n\t\t\t    (long long unsigned)zio_buf_cache_frees[i]);\n\t}\n#endif\n\n\t \n\tfor (size_t i = 0; i < n; i++) {\n\t\tkmem_cache_t *cache = zio_buf_cache[i];\n\t\tif (cache == NULL)\n\t\t\tcontinue;\n\t\tfor (size_t j = i; j < n; j++) {\n\t\t\tif (cache == zio_buf_cache[j])\n\t\t\t\tzio_buf_cache[j] = NULL;\n\t\t\tif (cache == zio_data_buf_cache[j])\n\t\t\t\tzio_data_buf_cache[j] = NULL;\n\t\t}\n\t\tkmem_cache_destroy(cache);\n\t}\n\n\tfor (size_t i = 0; i < n; i++) {\n\t\tkmem_cache_t *cache = zio_data_buf_cache[i];\n\t\tif (cache == NULL)\n\t\t\tcontinue;\n\t\tfor (size_t j = i; j < n; j++) {\n\t\t\tif (cache == zio_data_buf_cache[j])\n\t\t\t\tzio_data_buf_cache[j] = NULL;\n\t\t}\n\t\tkmem_cache_destroy(cache);\n\t}\n\n\tfor (size_t i = 0; i < n; i++) {\n\t\tVERIFY3P(zio_buf_cache[i], ==, NULL);\n\t\tVERIFY3P(zio_data_buf_cache[i], ==, NULL);\n\t}\n\n\tkmem_cache_destroy(zio_link_cache);\n\tkmem_cache_destroy(zio_cache);\n\n\tzio_inject_fini();\n\n\tlz4_fini();\n}\n\n \n\n \nvoid *\nzio_buf_alloc(size_t size)\n{\n\tsize_t c = (size - 1) >> SPA_MINBLOCKSHIFT;\n\n\tVERIFY3U(c, <, SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT);\n#if defined(ZFS_DEBUG) && !defined(_KERNEL)\n\tatomic_add_64(&zio_buf_cache_allocs[c], 1);\n#endif\n\n\treturn (kmem_cache_alloc(zio_buf_cache[c], KM_PUSHPAGE));\n}\n\n \nvoid *\nzio_data_buf_alloc(size_t size)\n{\n\tsize_t c = (size - 1) >> SPA_MINBLOCKSHIFT;\n\n\tVERIFY3U(c, <, SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT);\n\n\treturn (kmem_cache_alloc(zio_data_buf_cache[c], KM_PUSHPAGE));\n}\n\nvoid\nzio_buf_free(void *buf, size_t size)\n{\n\tsize_t c = (size - 1) >> SPA_MINBLOCKSHIFT;\n\n\tVERIFY3U(c, <, SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT);\n#if defined(ZFS_DEBUG) && !defined(_KERNEL)\n\tatomic_add_64(&zio_buf_cache_frees[c], 1);\n#endif\n\n\tkmem_cache_free(zio_buf_cache[c], buf);\n}\n\nvoid\nzio_data_buf_free(void *buf, size_t size)\n{\n\tsize_t c = (size - 1) >> SPA_MINBLOCKSHIFT;\n\n\tVERIFY3U(c, <, SPA_MAXBLOCKSIZE >> SPA_MINBLOCKSHIFT);\n\n\tkmem_cache_free(zio_data_buf_cache[c], buf);\n}\n\nstatic void\nzio_abd_free(void *abd, size_t size)\n{\n\t(void) size;\n\tabd_free((abd_t *)abd);\n}\n\n \nvoid\nzio_push_transform(zio_t *zio, abd_t *data, uint64_t size, uint64_t bufsize,\n    zio_transform_func_t *transform)\n{\n\tzio_transform_t *zt = kmem_alloc(sizeof (zio_transform_t), KM_SLEEP);\n\n\tzt->zt_orig_abd = zio->io_abd;\n\tzt->zt_orig_size = zio->io_size;\n\tzt->zt_bufsize = bufsize;\n\tzt->zt_transform = transform;\n\n\tzt->zt_next = zio->io_transform_stack;\n\tzio->io_transform_stack = zt;\n\n\tzio->io_abd = data;\n\tzio->io_size = size;\n}\n\nvoid\nzio_pop_transforms(zio_t *zio)\n{\n\tzio_transform_t *zt;\n\n\twhile ((zt = zio->io_transform_stack) != NULL) {\n\t\tif (zt->zt_transform != NULL)\n\t\t\tzt->zt_transform(zio,\n\t\t\t    zt->zt_orig_abd, zt->zt_orig_size);\n\n\t\tif (zt->zt_bufsize != 0)\n\t\t\tabd_free(zio->io_abd);\n\n\t\tzio->io_abd = zt->zt_orig_abd;\n\t\tzio->io_size = zt->zt_orig_size;\n\t\tzio->io_transform_stack = zt->zt_next;\n\n\t\tkmem_free(zt, sizeof (zio_transform_t));\n\t}\n}\n\n \nstatic void\nzio_subblock(zio_t *zio, abd_t *data, uint64_t size)\n{\n\tASSERT(zio->io_size > size);\n\n\tif (zio->io_type == ZIO_TYPE_READ)\n\t\tabd_copy(data, zio->io_abd, size);\n}\n\nstatic void\nzio_decompress(zio_t *zio, abd_t *data, uint64_t size)\n{\n\tif (zio->io_error == 0) {\n\t\tvoid *tmp = abd_borrow_buf(data, size);\n\t\tint ret = zio_decompress_data(BP_GET_COMPRESS(zio->io_bp),\n\t\t    zio->io_abd, tmp, zio->io_size, size,\n\t\t    &zio->io_prop.zp_complevel);\n\t\tabd_return_buf_copy(data, tmp, size);\n\n\t\tif (zio_injection_enabled && ret == 0)\n\t\t\tret = zio_handle_fault_injection(zio, EINVAL);\n\n\t\tif (ret != 0)\n\t\t\tzio->io_error = SET_ERROR(EIO);\n\t}\n}\n\nstatic void\nzio_decrypt(zio_t *zio, abd_t *data, uint64_t size)\n{\n\tint ret;\n\tvoid *tmp;\n\tblkptr_t *bp = zio->io_bp;\n\tspa_t *spa = zio->io_spa;\n\tuint64_t dsobj = zio->io_bookmark.zb_objset;\n\tuint64_t lsize = BP_GET_LSIZE(bp);\n\tdmu_object_type_t ot = BP_GET_TYPE(bp);\n\tuint8_t salt[ZIO_DATA_SALT_LEN];\n\tuint8_t iv[ZIO_DATA_IV_LEN];\n\tuint8_t mac[ZIO_DATA_MAC_LEN];\n\tboolean_t no_crypt = B_FALSE;\n\n\tASSERT(BP_USES_CRYPT(bp));\n\tASSERT3U(size, !=, 0);\n\n\tif (zio->io_error != 0)\n\t\treturn;\n\n\t \n\tif (BP_HAS_INDIRECT_MAC_CKSUM(bp)) {\n\t\tzio_crypt_decode_mac_bp(bp, mac);\n\n\t\tif (BP_GET_COMPRESS(bp) != ZIO_COMPRESS_OFF) {\n\t\t\t \n\t\t\ttmp = zio_buf_alloc(lsize);\n\t\t\tret = zio_decompress_data(BP_GET_COMPRESS(bp),\n\t\t\t    zio->io_abd, tmp, zio->io_size, lsize,\n\t\t\t    &zio->io_prop.zp_complevel);\n\t\t\tif (ret != 0) {\n\t\t\t\tret = SET_ERROR(EIO);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tret = zio_crypt_do_indirect_mac_checksum(B_FALSE,\n\t\t\t    tmp, lsize, BP_SHOULD_BYTESWAP(bp), mac);\n\t\t\tzio_buf_free(tmp, lsize);\n\t\t} else {\n\t\t\tret = zio_crypt_do_indirect_mac_checksum_abd(B_FALSE,\n\t\t\t    zio->io_abd, size, BP_SHOULD_BYTESWAP(bp), mac);\n\t\t}\n\t\tabd_copy(data, zio->io_abd, size);\n\n\t\tif (zio_injection_enabled && ot != DMU_OT_DNODE && ret == 0) {\n\t\t\tret = zio_handle_decrypt_injection(spa,\n\t\t\t    &zio->io_bookmark, ot, ECKSUM);\n\t\t}\n\t\tif (ret != 0)\n\t\t\tgoto error;\n\n\t\treturn;\n\t}\n\n\t \n\tif (BP_IS_AUTHENTICATED(bp)) {\n\t\tif (ot == DMU_OT_OBJSET) {\n\t\t\tret = spa_do_crypt_objset_mac_abd(B_FALSE, spa,\n\t\t\t    dsobj, zio->io_abd, size, BP_SHOULD_BYTESWAP(bp));\n\t\t} else {\n\t\t\tzio_crypt_decode_mac_bp(bp, mac);\n\t\t\tret = spa_do_crypt_mac_abd(B_FALSE, spa, dsobj,\n\t\t\t    zio->io_abd, size, mac);\n\t\t\tif (zio_injection_enabled && ret == 0) {\n\t\t\t\tret = zio_handle_decrypt_injection(spa,\n\t\t\t\t    &zio->io_bookmark, ot, ECKSUM);\n\t\t\t}\n\t\t}\n\t\tabd_copy(data, zio->io_abd, size);\n\n\t\tif (ret != 0)\n\t\t\tgoto error;\n\n\t\treturn;\n\t}\n\n\tzio_crypt_decode_params_bp(bp, salt, iv);\n\n\tif (ot == DMU_OT_INTENT_LOG) {\n\t\ttmp = abd_borrow_buf_copy(zio->io_abd, sizeof (zil_chain_t));\n\t\tzio_crypt_decode_mac_zil(tmp, mac);\n\t\tabd_return_buf(zio->io_abd, tmp, sizeof (zil_chain_t));\n\t} else {\n\t\tzio_crypt_decode_mac_bp(bp, mac);\n\t}\n\n\tret = spa_do_crypt_abd(B_FALSE, spa, &zio->io_bookmark, BP_GET_TYPE(bp),\n\t    BP_GET_DEDUP(bp), BP_SHOULD_BYTESWAP(bp), salt, iv, mac, size, data,\n\t    zio->io_abd, &no_crypt);\n\tif (no_crypt)\n\t\tabd_copy(data, zio->io_abd, size);\n\n\tif (ret != 0)\n\t\tgoto error;\n\n\treturn;\n\nerror:\n\t \n\tASSERT(ret != EACCES || (zio->io_flags & ZIO_FLAG_SPECULATIVE));\n\n\t \n\tif (ret == ECKSUM) {\n\t\tzio->io_error = SET_ERROR(EIO);\n\t\tif ((zio->io_flags & ZIO_FLAG_SPECULATIVE) == 0) {\n\t\t\tspa_log_error(spa, &zio->io_bookmark,\n\t\t\t    &zio->io_bp->blk_birth);\n\t\t\t(void) zfs_ereport_post(FM_EREPORT_ZFS_AUTHENTICATION,\n\t\t\t    spa, NULL, &zio->io_bookmark, zio, 0);\n\t\t}\n\t} else {\n\t\tzio->io_error = ret;\n\t}\n}\n\n \nzio_t *\nzio_walk_parents(zio_t *cio, zio_link_t **zl)\n{\n\tlist_t *pl = &cio->io_parent_list;\n\n\t*zl = (*zl == NULL) ? list_head(pl) : list_next(pl, *zl);\n\tif (*zl == NULL)\n\t\treturn (NULL);\n\n\tASSERT((*zl)->zl_child == cio);\n\treturn ((*zl)->zl_parent);\n}\n\nzio_t *\nzio_walk_children(zio_t *pio, zio_link_t **zl)\n{\n\tlist_t *cl = &pio->io_child_list;\n\n\tASSERT(MUTEX_HELD(&pio->io_lock));\n\n\t*zl = (*zl == NULL) ? list_head(cl) : list_next(cl, *zl);\n\tif (*zl == NULL)\n\t\treturn (NULL);\n\n\tASSERT((*zl)->zl_parent == pio);\n\treturn ((*zl)->zl_child);\n}\n\nzio_t *\nzio_unique_parent(zio_t *cio)\n{\n\tzio_link_t *zl = NULL;\n\tzio_t *pio = zio_walk_parents(cio, &zl);\n\n\tVERIFY3P(zio_walk_parents(cio, &zl), ==, NULL);\n\treturn (pio);\n}\n\nvoid\nzio_add_child(zio_t *pio, zio_t *cio)\n{\n\t \n\tASSERT3S(cio->io_child_type, <=, pio->io_child_type);\n\n\tzio_link_t *zl = kmem_cache_alloc(zio_link_cache, KM_SLEEP);\n\tzl->zl_parent = pio;\n\tzl->zl_child = cio;\n\n\tmutex_enter(&pio->io_lock);\n\tmutex_enter(&cio->io_lock);\n\n\tASSERT(pio->io_state[ZIO_WAIT_DONE] == 0);\n\n\tuint64_t *countp = pio->io_children[cio->io_child_type];\n\tfor (int w = 0; w < ZIO_WAIT_TYPES; w++)\n\t\tcountp[w] += !cio->io_state[w];\n\n\tlist_insert_head(&pio->io_child_list, zl);\n\tlist_insert_head(&cio->io_parent_list, zl);\n\n\tmutex_exit(&cio->io_lock);\n\tmutex_exit(&pio->io_lock);\n}\n\nvoid\nzio_add_child_first(zio_t *pio, zio_t *cio)\n{\n\t \n\tASSERT3S(cio->io_child_type, <=, pio->io_child_type);\n\n\tzio_link_t *zl = kmem_cache_alloc(zio_link_cache, KM_SLEEP);\n\tzl->zl_parent = pio;\n\tzl->zl_child = cio;\n\n\tASSERT(list_is_empty(&cio->io_parent_list));\n\tlist_insert_head(&cio->io_parent_list, zl);\n\n\tmutex_enter(&pio->io_lock);\n\n\tASSERT(pio->io_state[ZIO_WAIT_DONE] == 0);\n\n\tuint64_t *countp = pio->io_children[cio->io_child_type];\n\tfor (int w = 0; w < ZIO_WAIT_TYPES; w++)\n\t\tcountp[w] += !cio->io_state[w];\n\n\tlist_insert_head(&pio->io_child_list, zl);\n\n\tmutex_exit(&pio->io_lock);\n}\n\nstatic void\nzio_remove_child(zio_t *pio, zio_t *cio, zio_link_t *zl)\n{\n\tASSERT(zl->zl_parent == pio);\n\tASSERT(zl->zl_child == cio);\n\n\tmutex_enter(&pio->io_lock);\n\tmutex_enter(&cio->io_lock);\n\n\tlist_remove(&pio->io_child_list, zl);\n\tlist_remove(&cio->io_parent_list, zl);\n\n\tmutex_exit(&cio->io_lock);\n\tmutex_exit(&pio->io_lock);\n\tkmem_cache_free(zio_link_cache, zl);\n}\n\nstatic boolean_t\nzio_wait_for_children(zio_t *zio, uint8_t childbits, enum zio_wait_type wait)\n{\n\tboolean_t waiting = B_FALSE;\n\n\tmutex_enter(&zio->io_lock);\n\tASSERT(zio->io_stall == NULL);\n\tfor (int c = 0; c < ZIO_CHILD_TYPES; c++) {\n\t\tif (!(ZIO_CHILD_BIT_IS_SET(childbits, c)))\n\t\t\tcontinue;\n\n\t\tuint64_t *countp = &zio->io_children[c][wait];\n\t\tif (*countp != 0) {\n\t\t\tzio->io_stage >>= 1;\n\t\t\tASSERT3U(zio->io_stage, !=, ZIO_STAGE_OPEN);\n\t\t\tzio->io_stall = countp;\n\t\t\twaiting = B_TRUE;\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_exit(&zio->io_lock);\n\treturn (waiting);\n}\n\n__attribute__((always_inline))\nstatic inline void\nzio_notify_parent(zio_t *pio, zio_t *zio, enum zio_wait_type wait,\n    zio_t **next_to_executep)\n{\n\tuint64_t *countp = &pio->io_children[zio->io_child_type][wait];\n\tint *errorp = &pio->io_child_error[zio->io_child_type];\n\n\tmutex_enter(&pio->io_lock);\n\tif (zio->io_error && !(zio->io_flags & ZIO_FLAG_DONT_PROPAGATE))\n\t\t*errorp = zio_worst_error(*errorp, zio->io_error);\n\tpio->io_reexecute |= zio->io_reexecute;\n\tASSERT3U(*countp, >, 0);\n\n\t(*countp)--;\n\n\tif (*countp == 0 && pio->io_stall == countp) {\n\t\tzio_taskq_type_t type =\n\t\t    pio->io_stage < ZIO_STAGE_VDEV_IO_START ? ZIO_TASKQ_ISSUE :\n\t\t    ZIO_TASKQ_INTERRUPT;\n\t\tpio->io_stall = NULL;\n\t\tmutex_exit(&pio->io_lock);\n\n\t\t \n\t\tif (next_to_executep != NULL && *next_to_executep == NULL &&\n\t\t    pio->io_type == zio->io_type) {\n\t\t\t*next_to_executep = pio;\n\t\t} else {\n\t\t\tzio_taskq_dispatch(pio, type, B_FALSE);\n\t\t}\n\t} else {\n\t\tmutex_exit(&pio->io_lock);\n\t}\n}\n\nstatic void\nzio_inherit_child_errors(zio_t *zio, enum zio_child c)\n{\n\tif (zio->io_child_error[c] != 0 && zio->io_error == 0)\n\t\tzio->io_error = zio->io_child_error[c];\n}\n\nint\nzio_bookmark_compare(const void *x1, const void *x2)\n{\n\tconst zio_t *z1 = x1;\n\tconst zio_t *z2 = x2;\n\n\tif (z1->io_bookmark.zb_objset < z2->io_bookmark.zb_objset)\n\t\treturn (-1);\n\tif (z1->io_bookmark.zb_objset > z2->io_bookmark.zb_objset)\n\t\treturn (1);\n\n\tif (z1->io_bookmark.zb_object < z2->io_bookmark.zb_object)\n\t\treturn (-1);\n\tif (z1->io_bookmark.zb_object > z2->io_bookmark.zb_object)\n\t\treturn (1);\n\n\tif (z1->io_bookmark.zb_level < z2->io_bookmark.zb_level)\n\t\treturn (-1);\n\tif (z1->io_bookmark.zb_level > z2->io_bookmark.zb_level)\n\t\treturn (1);\n\n\tif (z1->io_bookmark.zb_blkid < z2->io_bookmark.zb_blkid)\n\t\treturn (-1);\n\tif (z1->io_bookmark.zb_blkid > z2->io_bookmark.zb_blkid)\n\t\treturn (1);\n\n\tif (z1 < z2)\n\t\treturn (-1);\n\tif (z1 > z2)\n\t\treturn (1);\n\n\treturn (0);\n}\n\n \nstatic zio_t *\nzio_create(zio_t *pio, spa_t *spa, uint64_t txg, const blkptr_t *bp,\n    abd_t *data, uint64_t lsize, uint64_t psize, zio_done_func_t *done,\n    void *private, zio_type_t type, zio_priority_t priority,\n    zio_flag_t flags, vdev_t *vd, uint64_t offset,\n    const zbookmark_phys_t *zb, enum zio_stage stage,\n    enum zio_stage pipeline)\n{\n\tzio_t *zio;\n\n\tIMPLY(type != ZIO_TYPE_TRIM, psize <= SPA_MAXBLOCKSIZE);\n\tASSERT(P2PHASE(psize, SPA_MINBLOCKSIZE) == 0);\n\tASSERT(P2PHASE(offset, SPA_MINBLOCKSIZE) == 0);\n\n\tASSERT(!vd || spa_config_held(spa, SCL_STATE_ALL, RW_READER));\n\tASSERT(!bp || !(flags & ZIO_FLAG_CONFIG_WRITER));\n\tASSERT(vd || stage == ZIO_STAGE_OPEN);\n\n\tIMPLY(lsize != psize, (flags & ZIO_FLAG_RAW_COMPRESS) != 0);\n\n\tzio = kmem_cache_alloc(zio_cache, KM_SLEEP);\n\tmemset(zio, 0, sizeof (zio_t));\n\n\tmutex_init(&zio->io_lock, NULL, MUTEX_NOLOCKDEP, NULL);\n\tcv_init(&zio->io_cv, NULL, CV_DEFAULT, NULL);\n\n\tlist_create(&zio->io_parent_list, sizeof (zio_link_t),\n\t    offsetof(zio_link_t, zl_parent_node));\n\tlist_create(&zio->io_child_list, sizeof (zio_link_t),\n\t    offsetof(zio_link_t, zl_child_node));\n\tmetaslab_trace_init(&zio->io_alloc_list);\n\n\tif (vd != NULL)\n\t\tzio->io_child_type = ZIO_CHILD_VDEV;\n\telse if (flags & ZIO_FLAG_GANG_CHILD)\n\t\tzio->io_child_type = ZIO_CHILD_GANG;\n\telse if (flags & ZIO_FLAG_DDT_CHILD)\n\t\tzio->io_child_type = ZIO_CHILD_DDT;\n\telse\n\t\tzio->io_child_type = ZIO_CHILD_LOGICAL;\n\n\tif (bp != NULL) {\n\t\tif (type != ZIO_TYPE_WRITE ||\n\t\t    zio->io_child_type == ZIO_CHILD_DDT) {\n\t\t\tzio->io_bp_copy = *bp;\n\t\t\tzio->io_bp = &zio->io_bp_copy;\t \n\t\t} else {\n\t\t\tzio->io_bp = (blkptr_t *)bp;\n\t\t}\n\t\tzio->io_bp_orig = *bp;\n\t\tif (zio->io_child_type == ZIO_CHILD_LOGICAL)\n\t\t\tzio->io_logical = zio;\n\t\tif (zio->io_child_type > ZIO_CHILD_GANG && BP_IS_GANG(bp))\n\t\t\tpipeline |= ZIO_GANG_STAGES;\n\t}\n\n\tzio->io_spa = spa;\n\tzio->io_txg = txg;\n\tzio->io_done = done;\n\tzio->io_private = private;\n\tzio->io_type = type;\n\tzio->io_priority = priority;\n\tzio->io_vd = vd;\n\tzio->io_offset = offset;\n\tzio->io_orig_abd = zio->io_abd = data;\n\tzio->io_orig_size = zio->io_size = psize;\n\tzio->io_lsize = lsize;\n\tzio->io_orig_flags = zio->io_flags = flags;\n\tzio->io_orig_stage = zio->io_stage = stage;\n\tzio->io_orig_pipeline = zio->io_pipeline = pipeline;\n\tzio->io_pipeline_trace = ZIO_STAGE_OPEN;\n\n\tzio->io_state[ZIO_WAIT_READY] = (stage >= ZIO_STAGE_READY);\n\tzio->io_state[ZIO_WAIT_DONE] = (stage >= ZIO_STAGE_DONE);\n\n\tif (zb != NULL)\n\t\tzio->io_bookmark = *zb;\n\n\tif (pio != NULL) {\n\t\tzio->io_metaslab_class = pio->io_metaslab_class;\n\t\tif (zio->io_logical == NULL)\n\t\t\tzio->io_logical = pio->io_logical;\n\t\tif (zio->io_child_type == ZIO_CHILD_GANG)\n\t\t\tzio->io_gang_leader = pio->io_gang_leader;\n\t\tzio_add_child_first(pio, zio);\n\t}\n\n\ttaskq_init_ent(&zio->io_tqent);\n\n\treturn (zio);\n}\n\nvoid\nzio_destroy(zio_t *zio)\n{\n\tmetaslab_trace_fini(&zio->io_alloc_list);\n\tlist_destroy(&zio->io_parent_list);\n\tlist_destroy(&zio->io_child_list);\n\tmutex_destroy(&zio->io_lock);\n\tcv_destroy(&zio->io_cv);\n\tkmem_cache_free(zio_cache, zio);\n}\n\nzio_t *\nzio_null(zio_t *pio, spa_t *spa, vdev_t *vd, zio_done_func_t *done,\n    void *private, zio_flag_t flags)\n{\n\tzio_t *zio;\n\n\tzio = zio_create(pio, spa, 0, NULL, NULL, 0, 0, done, private,\n\t    ZIO_TYPE_NULL, ZIO_PRIORITY_NOW, flags, vd, 0, NULL,\n\t    ZIO_STAGE_OPEN, ZIO_INTERLOCK_PIPELINE);\n\n\treturn (zio);\n}\n\nzio_t *\nzio_root(spa_t *spa, zio_done_func_t *done, void *private, zio_flag_t flags)\n{\n\treturn (zio_null(NULL, spa, NULL, done, private, flags));\n}\n\nstatic int\nzfs_blkptr_verify_log(spa_t *spa, const blkptr_t *bp,\n    enum blk_verify_flag blk_verify, const char *fmt, ...)\n{\n\tva_list adx;\n\tchar buf[256];\n\n\tva_start(adx, fmt);\n\t(void) vsnprintf(buf, sizeof (buf), fmt, adx);\n\tva_end(adx);\n\n\tzfs_dbgmsg(\"bad blkptr at %px: \"\n\t    \"DVA[0]=%#llx/%#llx \"\n\t    \"DVA[1]=%#llx/%#llx \"\n\t    \"DVA[2]=%#llx/%#llx \"\n\t    \"prop=%#llx \"\n\t    \"pad=%#llx,%#llx \"\n\t    \"phys_birth=%#llx \"\n\t    \"birth=%#llx \"\n\t    \"fill=%#llx \"\n\t    \"cksum=%#llx/%#llx/%#llx/%#llx\",\n\t    bp,\n\t    (long long)bp->blk_dva[0].dva_word[0],\n\t    (long long)bp->blk_dva[0].dva_word[1],\n\t    (long long)bp->blk_dva[1].dva_word[0],\n\t    (long long)bp->blk_dva[1].dva_word[1],\n\t    (long long)bp->blk_dva[2].dva_word[0],\n\t    (long long)bp->blk_dva[2].dva_word[1],\n\t    (long long)bp->blk_prop,\n\t    (long long)bp->blk_pad[0],\n\t    (long long)bp->blk_pad[1],\n\t    (long long)bp->blk_phys_birth,\n\t    (long long)bp->blk_birth,\n\t    (long long)bp->blk_fill,\n\t    (long long)bp->blk_cksum.zc_word[0],\n\t    (long long)bp->blk_cksum.zc_word[1],\n\t    (long long)bp->blk_cksum.zc_word[2],\n\t    (long long)bp->blk_cksum.zc_word[3]);\n\tswitch (blk_verify) {\n\tcase BLK_VERIFY_HALT:\n\t\tzfs_panic_recover(\"%s: %s\", spa_name(spa), buf);\n\t\tbreak;\n\tcase BLK_VERIFY_LOG:\n\t\tzfs_dbgmsg(\"%s: %s\", spa_name(spa), buf);\n\t\tbreak;\n\tcase BLK_VERIFY_ONLY:\n\t\tbreak;\n\t}\n\n\treturn (1);\n}\n\n \nboolean_t\nzfs_blkptr_verify(spa_t *spa, const blkptr_t *bp,\n    enum blk_config_flag blk_config, enum blk_verify_flag blk_verify)\n{\n\tint errors = 0;\n\n\tif (!DMU_OT_IS_VALID(BP_GET_TYPE(bp))) {\n\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t    \"blkptr at %px has invalid TYPE %llu\",\n\t\t    bp, (longlong_t)BP_GET_TYPE(bp));\n\t}\n\tif (BP_GET_CHECKSUM(bp) >= ZIO_CHECKSUM_FUNCTIONS) {\n\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t    \"blkptr at %px has invalid CHECKSUM %llu\",\n\t\t    bp, (longlong_t)BP_GET_CHECKSUM(bp));\n\t}\n\tif (BP_GET_COMPRESS(bp) >= ZIO_COMPRESS_FUNCTIONS) {\n\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t    \"blkptr at %px has invalid COMPRESS %llu\",\n\t\t    bp, (longlong_t)BP_GET_COMPRESS(bp));\n\t}\n\tif (BP_GET_LSIZE(bp) > SPA_MAXBLOCKSIZE) {\n\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t    \"blkptr at %px has invalid LSIZE %llu\",\n\t\t    bp, (longlong_t)BP_GET_LSIZE(bp));\n\t}\n\tif (BP_GET_PSIZE(bp) > SPA_MAXBLOCKSIZE) {\n\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t    \"blkptr at %px has invalid PSIZE %llu\",\n\t\t    bp, (longlong_t)BP_GET_PSIZE(bp));\n\t}\n\n\tif (BP_IS_EMBEDDED(bp)) {\n\t\tif (BPE_GET_ETYPE(bp) >= NUM_BP_EMBEDDED_TYPES) {\n\t\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t\t    \"blkptr at %px has invalid ETYPE %llu\",\n\t\t\t    bp, (longlong_t)BPE_GET_ETYPE(bp));\n\t\t}\n\t}\n\n\t \n\tif (!spa->spa_trust_config)\n\t\treturn (errors == 0);\n\n\tswitch (blk_config) {\n\tcase BLK_CONFIG_HELD:\n\t\tASSERT(spa_config_held(spa, SCL_VDEV, RW_WRITER));\n\t\tbreak;\n\tcase BLK_CONFIG_NEEDED:\n\t\tspa_config_enter(spa, SCL_VDEV, bp, RW_READER);\n\t\tbreak;\n\tcase BLK_CONFIG_SKIP:\n\t\treturn (errors == 0);\n\tdefault:\n\t\tpanic(\"invalid blk_config %u\", blk_config);\n\t}\n\n\t \n\tfor (int i = 0; i < BP_GET_NDVAS(bp); i++) {\n\t\tconst dva_t *dva = &bp->blk_dva[i];\n\t\tuint64_t vdevid = DVA_GET_VDEV(dva);\n\n\t\tif (vdevid >= spa->spa_root_vdev->vdev_children) {\n\t\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t\t    \"blkptr at %px DVA %u has invalid VDEV %llu\",\n\t\t\t    bp, i, (longlong_t)vdevid);\n\t\t\tcontinue;\n\t\t}\n\t\tvdev_t *vd = spa->spa_root_vdev->vdev_child[vdevid];\n\t\tif (vd == NULL) {\n\t\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t\t    \"blkptr at %px DVA %u has invalid VDEV %llu\",\n\t\t\t    bp, i, (longlong_t)vdevid);\n\t\t\tcontinue;\n\t\t}\n\t\tif (vd->vdev_ops == &vdev_hole_ops) {\n\t\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t\t    \"blkptr at %px DVA %u has hole VDEV %llu\",\n\t\t\t    bp, i, (longlong_t)vdevid);\n\t\t\tcontinue;\n\t\t}\n\t\tif (vd->vdev_ops == &vdev_missing_ops) {\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\t\tuint64_t offset = DVA_GET_OFFSET(dva);\n\t\tuint64_t asize = DVA_GET_ASIZE(dva);\n\t\tif (DVA_GET_GANG(dva))\n\t\t\tasize = vdev_gang_header_asize(vd);\n\t\tif (offset + asize > vd->vdev_asize) {\n\t\t\terrors += zfs_blkptr_verify_log(spa, bp, blk_verify,\n\t\t\t    \"blkptr at %px DVA %u has invalid OFFSET %llu\",\n\t\t\t    bp, i, (longlong_t)offset);\n\t\t}\n\t}\n\tif (blk_config == BLK_CONFIG_NEEDED)\n\t\tspa_config_exit(spa, SCL_VDEV, bp);\n\n\treturn (errors == 0);\n}\n\nboolean_t\nzfs_dva_valid(spa_t *spa, const dva_t *dva, const blkptr_t *bp)\n{\n\t(void) bp;\n\tuint64_t vdevid = DVA_GET_VDEV(dva);\n\n\tif (vdevid >= spa->spa_root_vdev->vdev_children)\n\t\treturn (B_FALSE);\n\n\tvdev_t *vd = spa->spa_root_vdev->vdev_child[vdevid];\n\tif (vd == NULL)\n\t\treturn (B_FALSE);\n\n\tif (vd->vdev_ops == &vdev_hole_ops)\n\t\treturn (B_FALSE);\n\n\tif (vd->vdev_ops == &vdev_missing_ops) {\n\t\treturn (B_FALSE);\n\t}\n\n\tuint64_t offset = DVA_GET_OFFSET(dva);\n\tuint64_t asize = DVA_GET_ASIZE(dva);\n\n\tif (DVA_GET_GANG(dva))\n\t\tasize = vdev_gang_header_asize(vd);\n\tif (offset + asize > vd->vdev_asize)\n\t\treturn (B_FALSE);\n\n\treturn (B_TRUE);\n}\n\nzio_t *\nzio_read(zio_t *pio, spa_t *spa, const blkptr_t *bp,\n    abd_t *data, uint64_t size, zio_done_func_t *done, void *private,\n    zio_priority_t priority, zio_flag_t flags, const zbookmark_phys_t *zb)\n{\n\tzio_t *zio;\n\n\tzio = zio_create(pio, spa, BP_PHYSICAL_BIRTH(bp), bp,\n\t    data, size, size, done, private,\n\t    ZIO_TYPE_READ, priority, flags, NULL, 0, zb,\n\t    ZIO_STAGE_OPEN, (flags & ZIO_FLAG_DDT_CHILD) ?\n\t    ZIO_DDT_CHILD_READ_PIPELINE : ZIO_READ_PIPELINE);\n\n\treturn (zio);\n}\n\nzio_t *\nzio_write(zio_t *pio, spa_t *spa, uint64_t txg, blkptr_t *bp,\n    abd_t *data, uint64_t lsize, uint64_t psize, const zio_prop_t *zp,\n    zio_done_func_t *ready, zio_done_func_t *children_ready,\n    zio_done_func_t *done, void *private, zio_priority_t priority,\n    zio_flag_t flags, const zbookmark_phys_t *zb)\n{\n\tzio_t *zio;\n\n\tASSERT(zp->zp_checksum >= ZIO_CHECKSUM_OFF &&\n\t    zp->zp_checksum < ZIO_CHECKSUM_FUNCTIONS &&\n\t    zp->zp_compress >= ZIO_COMPRESS_OFF &&\n\t    zp->zp_compress < ZIO_COMPRESS_FUNCTIONS &&\n\t    DMU_OT_IS_VALID(zp->zp_type) &&\n\t    zp->zp_level < 32 &&\n\t    zp->zp_copies > 0 &&\n\t    zp->zp_copies <= spa_max_replication(spa));\n\n\tzio = zio_create(pio, spa, txg, bp, data, lsize, psize, done, private,\n\t    ZIO_TYPE_WRITE, priority, flags, NULL, 0, zb,\n\t    ZIO_STAGE_OPEN, (flags & ZIO_FLAG_DDT_CHILD) ?\n\t    ZIO_DDT_CHILD_WRITE_PIPELINE : ZIO_WRITE_PIPELINE);\n\n\tzio->io_ready = ready;\n\tzio->io_children_ready = children_ready;\n\tzio->io_prop = *zp;\n\n\t \n\tif (data == NULL &&\n\t    (zio->io_prop.zp_dedup_verify || zio->io_prop.zp_encrypt)) {\n\t\tzio->io_prop.zp_dedup = zio->io_prop.zp_dedup_verify = B_FALSE;\n\t}\n\n\treturn (zio);\n}\n\nzio_t *\nzio_rewrite(zio_t *pio, spa_t *spa, uint64_t txg, blkptr_t *bp, abd_t *data,\n    uint64_t size, zio_done_func_t *done, void *private,\n    zio_priority_t priority, zio_flag_t flags, zbookmark_phys_t *zb)\n{\n\tzio_t *zio;\n\n\tzio = zio_create(pio, spa, txg, bp, data, size, size, done, private,\n\t    ZIO_TYPE_WRITE, priority, flags | ZIO_FLAG_IO_REWRITE, NULL, 0, zb,\n\t    ZIO_STAGE_OPEN, ZIO_REWRITE_PIPELINE);\n\n\treturn (zio);\n}\n\nvoid\nzio_write_override(zio_t *zio, blkptr_t *bp, int copies, boolean_t nopwrite,\n    boolean_t brtwrite)\n{\n\tASSERT(zio->io_type == ZIO_TYPE_WRITE);\n\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\tASSERT(zio->io_stage == ZIO_STAGE_OPEN);\n\tASSERT(zio->io_txg == spa_syncing_txg(zio->io_spa));\n\tASSERT(!brtwrite || !nopwrite);\n\n\t \n\tzio->io_prop.zp_dedup = nopwrite ? B_FALSE : zio->io_prop.zp_dedup;\n\tzio->io_prop.zp_nopwrite = nopwrite;\n\tzio->io_prop.zp_brtwrite = brtwrite;\n\tzio->io_prop.zp_copies = copies;\n\tzio->io_bp_override = bp;\n}\n\nvoid\nzio_free(spa_t *spa, uint64_t txg, const blkptr_t *bp)\n{\n\n\t(void) zfs_blkptr_verify(spa, bp, BLK_CONFIG_NEEDED, BLK_VERIFY_HALT);\n\n\t \n\tif (BP_IS_EMBEDDED(bp))\n\t\treturn;\n\n\t \n\tif (BP_IS_GANG(bp) ||\n\t    BP_GET_DEDUP(bp) ||\n\t    txg != spa->spa_syncing_txg ||\n\t    (spa_sync_pass(spa) >= zfs_sync_pass_deferred_free &&\n\t    !spa_feature_is_active(spa, SPA_FEATURE_LOG_SPACEMAP)) ||\n\t    brt_maybe_exists(spa, bp)) {\n\t\tmetaslab_check_free(spa, bp);\n\t\tbplist_append(&spa->spa_free_bplist[txg & TXG_MASK], bp);\n\t} else {\n\t\tVERIFY3P(zio_free_sync(NULL, spa, txg, bp, 0), ==, NULL);\n\t}\n}\n\n \nzio_t *\nzio_free_sync(zio_t *pio, spa_t *spa, uint64_t txg, const blkptr_t *bp,\n    zio_flag_t flags)\n{\n\tASSERT(!BP_IS_HOLE(bp));\n\tASSERT(spa_syncing_txg(spa) == txg);\n\n\tif (BP_IS_EMBEDDED(bp))\n\t\treturn (NULL);\n\n\tmetaslab_check_free(spa, bp);\n\tarc_freed(spa, bp);\n\tdsl_scan_freed(spa, bp);\n\n\tif (BP_IS_GANG(bp) ||\n\t    BP_GET_DEDUP(bp) ||\n\t    brt_maybe_exists(spa, bp)) {\n\t\t \n\t\tenum zio_stage stage =\n\t\t    ZIO_FREE_PIPELINE | ZIO_STAGE_ISSUE_ASYNC;\n\n\t\treturn (zio_create(pio, spa, txg, bp, NULL, BP_GET_PSIZE(bp),\n\t\t    BP_GET_PSIZE(bp), NULL, NULL,\n\t\t    ZIO_TYPE_FREE, ZIO_PRIORITY_NOW,\n\t\t    flags, NULL, 0, NULL, ZIO_STAGE_OPEN, stage));\n\t} else {\n\t\tmetaslab_free(spa, bp, txg, B_FALSE);\n\t\treturn (NULL);\n\t}\n}\n\nzio_t *\nzio_claim(zio_t *pio, spa_t *spa, uint64_t txg, const blkptr_t *bp,\n    zio_done_func_t *done, void *private, zio_flag_t flags)\n{\n\tzio_t *zio;\n\n\t(void) zfs_blkptr_verify(spa, bp, (flags & ZIO_FLAG_CONFIG_WRITER) ?\n\t    BLK_CONFIG_HELD : BLK_CONFIG_NEEDED, BLK_VERIFY_HALT);\n\n\tif (BP_IS_EMBEDDED(bp))\n\t\treturn (zio_null(pio, spa, NULL, NULL, NULL, 0));\n\n\t \n\tASSERT3U(spa->spa_uberblock.ub_rootbp.blk_birth, <,\n\t    spa_min_claim_txg(spa));\n\tASSERT(txg == spa_min_claim_txg(spa) || txg == 0);\n\tASSERT(!BP_GET_DEDUP(bp) || !spa_writeable(spa));\t \n\n\tzio = zio_create(pio, spa, txg, bp, NULL, BP_GET_PSIZE(bp),\n\t    BP_GET_PSIZE(bp), done, private, ZIO_TYPE_CLAIM, ZIO_PRIORITY_NOW,\n\t    flags, NULL, 0, NULL, ZIO_STAGE_OPEN, ZIO_CLAIM_PIPELINE);\n\tASSERT0(zio->io_queued_timestamp);\n\n\treturn (zio);\n}\n\nzio_t *\nzio_ioctl(zio_t *pio, spa_t *spa, vdev_t *vd, int cmd,\n    zio_done_func_t *done, void *private, zio_flag_t flags)\n{\n\tzio_t *zio;\n\tint c;\n\n\tif (vd->vdev_children == 0) {\n\t\tzio = zio_create(pio, spa, 0, NULL, NULL, 0, 0, done, private,\n\t\t    ZIO_TYPE_IOCTL, ZIO_PRIORITY_NOW, flags, vd, 0, NULL,\n\t\t    ZIO_STAGE_OPEN, ZIO_IOCTL_PIPELINE);\n\n\t\tzio->io_cmd = cmd;\n\t} else {\n\t\tzio = zio_null(pio, spa, NULL, NULL, NULL, flags);\n\n\t\tfor (c = 0; c < vd->vdev_children; c++)\n\t\t\tzio_nowait(zio_ioctl(zio, spa, vd->vdev_child[c], cmd,\n\t\t\t    done, private, flags));\n\t}\n\n\treturn (zio);\n}\n\nzio_t *\nzio_trim(zio_t *pio, vdev_t *vd, uint64_t offset, uint64_t size,\n    zio_done_func_t *done, void *private, zio_priority_t priority,\n    zio_flag_t flags, enum trim_flag trim_flags)\n{\n\tzio_t *zio;\n\n\tASSERT0(vd->vdev_children);\n\tASSERT0(P2PHASE(offset, 1ULL << vd->vdev_ashift));\n\tASSERT0(P2PHASE(size, 1ULL << vd->vdev_ashift));\n\tASSERT3U(size, !=, 0);\n\n\tzio = zio_create(pio, vd->vdev_spa, 0, NULL, NULL, size, size, done,\n\t    private, ZIO_TYPE_TRIM, priority, flags | ZIO_FLAG_PHYSICAL,\n\t    vd, offset, NULL, ZIO_STAGE_OPEN, ZIO_TRIM_PIPELINE);\n\tzio->io_trim_flags = trim_flags;\n\n\treturn (zio);\n}\n\nzio_t *\nzio_read_phys(zio_t *pio, vdev_t *vd, uint64_t offset, uint64_t size,\n    abd_t *data, int checksum, zio_done_func_t *done, void *private,\n    zio_priority_t priority, zio_flag_t flags, boolean_t labels)\n{\n\tzio_t *zio;\n\n\tASSERT(vd->vdev_children == 0);\n\tASSERT(!labels || offset + size <= VDEV_LABEL_START_SIZE ||\n\t    offset >= vd->vdev_psize - VDEV_LABEL_END_SIZE);\n\tASSERT3U(offset + size, <=, vd->vdev_psize);\n\n\tzio = zio_create(pio, vd->vdev_spa, 0, NULL, data, size, size, done,\n\t    private, ZIO_TYPE_READ, priority, flags | ZIO_FLAG_PHYSICAL, vd,\n\t    offset, NULL, ZIO_STAGE_OPEN, ZIO_READ_PHYS_PIPELINE);\n\n\tzio->io_prop.zp_checksum = checksum;\n\n\treturn (zio);\n}\n\nzio_t *\nzio_write_phys(zio_t *pio, vdev_t *vd, uint64_t offset, uint64_t size,\n    abd_t *data, int checksum, zio_done_func_t *done, void *private,\n    zio_priority_t priority, zio_flag_t flags, boolean_t labels)\n{\n\tzio_t *zio;\n\n\tASSERT(vd->vdev_children == 0);\n\tASSERT(!labels || offset + size <= VDEV_LABEL_START_SIZE ||\n\t    offset >= vd->vdev_psize - VDEV_LABEL_END_SIZE);\n\tASSERT3U(offset + size, <=, vd->vdev_psize);\n\n\tzio = zio_create(pio, vd->vdev_spa, 0, NULL, data, size, size, done,\n\t    private, ZIO_TYPE_WRITE, priority, flags | ZIO_FLAG_PHYSICAL, vd,\n\t    offset, NULL, ZIO_STAGE_OPEN, ZIO_WRITE_PHYS_PIPELINE);\n\n\tzio->io_prop.zp_checksum = checksum;\n\n\tif (zio_checksum_table[checksum].ci_flags & ZCHECKSUM_FLAG_EMBEDDED) {\n\t\t \n\t\tabd_t *wbuf = abd_alloc_sametype(data, size);\n\t\tabd_copy(wbuf, data, size);\n\n\t\tzio_push_transform(zio, wbuf, size, size, NULL);\n\t}\n\n\treturn (zio);\n}\n\n \nzio_t *\nzio_vdev_child_io(zio_t *pio, blkptr_t *bp, vdev_t *vd, uint64_t offset,\n    abd_t *data, uint64_t size, int type, zio_priority_t priority,\n    zio_flag_t flags, zio_done_func_t *done, void *private)\n{\n\tenum zio_stage pipeline = ZIO_VDEV_CHILD_PIPELINE;\n\tzio_t *zio;\n\n\t \n\tASSERT((flags & ZIO_FLAG_OPTIONAL) || (flags & ZIO_FLAG_IO_REPAIR) ||\n\t    done != NULL);\n\n\tif (type == ZIO_TYPE_READ && bp != NULL) {\n\t\t \n\t\tpipeline |= ZIO_STAGE_CHECKSUM_VERIFY;\n\t\tpio->io_pipeline &= ~ZIO_STAGE_CHECKSUM_VERIFY;\n\t}\n\n\tif (vd->vdev_ops->vdev_op_leaf) {\n\t\tASSERT0(vd->vdev_children);\n\t\toffset += VDEV_LABEL_START_SIZE;\n\t}\n\n\tflags |= ZIO_VDEV_CHILD_FLAGS(pio);\n\n\t \n\tif (flags & ZIO_FLAG_IO_REPAIR)\n\t\tflags &= ~ZIO_FLAG_SPECULATIVE;\n\n\t \n\tif (flags & ZIO_FLAG_IO_ALLOCATING &&\n\t    (vd != vd->vdev_top || (flags & ZIO_FLAG_IO_RETRY))) {\n\t\tASSERT(pio->io_metaslab_class != NULL);\n\t\tASSERT(pio->io_metaslab_class->mc_alloc_throttle_enabled);\n\t\tASSERT(type == ZIO_TYPE_WRITE);\n\t\tASSERT(priority == ZIO_PRIORITY_ASYNC_WRITE);\n\t\tASSERT(!(flags & ZIO_FLAG_IO_REPAIR));\n\t\tASSERT(!(pio->io_flags & ZIO_FLAG_IO_REWRITE) ||\n\t\t    pio->io_child_type == ZIO_CHILD_GANG);\n\n\t\tflags &= ~ZIO_FLAG_IO_ALLOCATING;\n\t}\n\n\tzio = zio_create(pio, pio->io_spa, pio->io_txg, bp, data, size, size,\n\t    done, private, type, priority, flags, vd, offset, &pio->io_bookmark,\n\t    ZIO_STAGE_VDEV_IO_START >> 1, pipeline);\n\tASSERT3U(zio->io_child_type, ==, ZIO_CHILD_VDEV);\n\n\treturn (zio);\n}\n\nzio_t *\nzio_vdev_delegated_io(vdev_t *vd, uint64_t offset, abd_t *data, uint64_t size,\n    zio_type_t type, zio_priority_t priority, zio_flag_t flags,\n    zio_done_func_t *done, void *private)\n{\n\tzio_t *zio;\n\n\tASSERT(vd->vdev_ops->vdev_op_leaf);\n\n\tzio = zio_create(NULL, vd->vdev_spa, 0, NULL,\n\t    data, size, size, done, private, type, priority,\n\t    flags | ZIO_FLAG_CANFAIL | ZIO_FLAG_DONT_RETRY | ZIO_FLAG_DELEGATED,\n\t    vd, offset, NULL,\n\t    ZIO_STAGE_VDEV_IO_START >> 1, ZIO_VDEV_CHILD_PIPELINE);\n\n\treturn (zio);\n}\n\nvoid\nzio_flush(zio_t *zio, vdev_t *vd)\n{\n\tzio_nowait(zio_ioctl(zio, zio->io_spa, vd, DKIOCFLUSHWRITECACHE,\n\t    NULL, NULL,\n\t    ZIO_FLAG_CANFAIL | ZIO_FLAG_DONT_PROPAGATE | ZIO_FLAG_DONT_RETRY));\n}\n\nvoid\nzio_shrink(zio_t *zio, uint64_t size)\n{\n\tASSERT3P(zio->io_executor, ==, NULL);\n\tASSERT3U(zio->io_orig_size, ==, zio->io_size);\n\tASSERT3U(size, <=, zio->io_size);\n\n\t \n\tASSERT(BP_GET_COMPRESS(zio->io_bp) == ZIO_COMPRESS_OFF);\n\tif (!BP_IS_RAIDZ(zio->io_bp)) {\n\t\t \n\t\tASSERT3U(zio->io_size, ==, zio->io_lsize);\n\t\tzio->io_orig_size = zio->io_size = zio->io_lsize = size;\n\t}\n}\n\n \nstatic uint64_t\nzio_roundup_alloc_size(spa_t *spa, uint64_t size)\n{\n\tif (size > spa->spa_min_alloc)\n\t\treturn (roundup(size, spa->spa_gcd_alloc));\n\treturn (spa->spa_min_alloc);\n}\n\n \n\nstatic zio_t *\nzio_read_bp_init(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\tuint64_t psize =\n\t    BP_IS_EMBEDDED(bp) ? BPE_GET_PSIZE(bp) : BP_GET_PSIZE(bp);\n\n\tASSERT3P(zio->io_bp, ==, &zio->io_bp_copy);\n\n\tif (BP_GET_COMPRESS(bp) != ZIO_COMPRESS_OFF &&\n\t    zio->io_child_type == ZIO_CHILD_LOGICAL &&\n\t    !(zio->io_flags & ZIO_FLAG_RAW_COMPRESS)) {\n\t\tzio_push_transform(zio, abd_alloc_sametype(zio->io_abd, psize),\n\t\t    psize, psize, zio_decompress);\n\t}\n\n\tif (((BP_IS_PROTECTED(bp) && !(zio->io_flags & ZIO_FLAG_RAW_ENCRYPT)) ||\n\t    BP_HAS_INDIRECT_MAC_CKSUM(bp)) &&\n\t    zio->io_child_type == ZIO_CHILD_LOGICAL) {\n\t\tzio_push_transform(zio, abd_alloc_sametype(zio->io_abd, psize),\n\t\t    psize, psize, zio_decrypt);\n\t}\n\n\tif (BP_IS_EMBEDDED(bp) && BPE_GET_ETYPE(bp) == BP_EMBEDDED_TYPE_DATA) {\n\t\tint psize = BPE_GET_PSIZE(bp);\n\t\tvoid *data = abd_borrow_buf(zio->io_abd, psize);\n\n\t\tzio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\t\tdecode_embedded_bp_compressed(bp, data);\n\t\tabd_return_buf_copy(zio->io_abd, data, psize);\n\t} else {\n\t\tASSERT(!BP_IS_EMBEDDED(bp));\n\t}\n\n\tif (BP_GET_DEDUP(bp) && zio->io_child_type == ZIO_CHILD_LOGICAL)\n\t\tzio->io_pipeline = ZIO_DDT_READ_PIPELINE;\n\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_write_bp_init(zio_t *zio)\n{\n\tif (!IO_IS_ALLOCATING(zio))\n\t\treturn (zio);\n\n\tASSERT(zio->io_child_type != ZIO_CHILD_DDT);\n\n\tif (zio->io_bp_override) {\n\t\tblkptr_t *bp = zio->io_bp;\n\t\tzio_prop_t *zp = &zio->io_prop;\n\n\t\tASSERT(bp->blk_birth != zio->io_txg);\n\n\t\t*bp = *zio->io_bp_override;\n\t\tzio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\n\t\tif (zp->zp_brtwrite)\n\t\t\treturn (zio);\n\n\t\tASSERT(!BP_GET_DEDUP(zio->io_bp_override));\n\n\t\tif (BP_IS_EMBEDDED(bp))\n\t\t\treturn (zio);\n\n\t\t \n\t\tif (!BP_IS_HOLE(bp) && zp->zp_nopwrite) {\n\t\t\tASSERT(!zp->zp_dedup);\n\t\t\tASSERT3U(BP_GET_CHECKSUM(bp), ==, zp->zp_checksum);\n\t\t\tzio->io_flags |= ZIO_FLAG_NOPWRITE;\n\t\t\treturn (zio);\n\t\t}\n\n\t\tASSERT(!zp->zp_nopwrite);\n\n\t\tif (BP_IS_HOLE(bp) || !zp->zp_dedup)\n\t\t\treturn (zio);\n\n\t\tASSERT((zio_checksum_table[zp->zp_checksum].ci_flags &\n\t\t    ZCHECKSUM_FLAG_DEDUP) || zp->zp_dedup_verify);\n\n\t\tif (BP_GET_CHECKSUM(bp) == zp->zp_checksum &&\n\t\t    !zp->zp_encrypt) {\n\t\t\tBP_SET_DEDUP(bp, 1);\n\t\t\tzio->io_pipeline |= ZIO_STAGE_DDT_WRITE;\n\t\t\treturn (zio);\n\t\t}\n\n\t\t \n\t\tzio->io_bp_override = NULL;\n\t\t*bp = zio->io_bp_orig;\n\t\tzio->io_pipeline = zio->io_orig_pipeline;\n\t}\n\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_write_compress(zio_t *zio)\n{\n\tspa_t *spa = zio->io_spa;\n\tzio_prop_t *zp = &zio->io_prop;\n\tenum zio_compress compress = zp->zp_compress;\n\tblkptr_t *bp = zio->io_bp;\n\tuint64_t lsize = zio->io_lsize;\n\tuint64_t psize = zio->io_size;\n\tuint32_t pass = 1;\n\n\t \n\tif (zio_wait_for_children(zio, ZIO_CHILD_LOGICAL_BIT |\n\t    ZIO_CHILD_GANG_BIT, ZIO_WAIT_READY)) {\n\t\treturn (NULL);\n\t}\n\n\tif (!IO_IS_ALLOCATING(zio))\n\t\treturn (zio);\n\n\tif (zio->io_children_ready != NULL) {\n\t\t \n\t\tASSERT3U(zp->zp_level, >, 0);\n\t\tzio->io_children_ready(zio);\n\t}\n\n\tASSERT(zio->io_child_type != ZIO_CHILD_DDT);\n\tASSERT(zio->io_bp_override == NULL);\n\n\tif (!BP_IS_HOLE(bp) && bp->blk_birth == zio->io_txg) {\n\t\t \n\t\tpass = spa_sync_pass(spa);\n\n\t\tASSERT(zio->io_txg == spa_syncing_txg(spa));\n\t\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\t\tASSERT(!BP_GET_DEDUP(bp));\n\n\t\tif (pass >= zfs_sync_pass_dont_compress)\n\t\t\tcompress = ZIO_COMPRESS_OFF;\n\n\t\t \n\t\tASSERT(BP_IS_EMBEDDED(bp) || BP_IS_GANG(bp) ||\n\t\t    MIN(zp->zp_copies, spa_max_replication(spa))\n\t\t    == BP_GET_NDVAS(bp));\n\t}\n\n\t \n\tif (compress != ZIO_COMPRESS_OFF &&\n\t    !(zio->io_flags & ZIO_FLAG_RAW_COMPRESS)) {\n\t\tvoid *cbuf = NULL;\n\t\tpsize = zio_compress_data(compress, zio->io_abd, &cbuf, lsize,\n\t\t    zp->zp_complevel);\n\t\tif (psize == 0) {\n\t\t\tcompress = ZIO_COMPRESS_OFF;\n\t\t} else if (psize >= lsize) {\n\t\t\tcompress = ZIO_COMPRESS_OFF;\n\t\t\tif (cbuf != NULL)\n\t\t\t\tzio_buf_free(cbuf, lsize);\n\t\t} else if (!zp->zp_dedup && !zp->zp_encrypt &&\n\t\t    psize <= BPE_PAYLOAD_SIZE &&\n\t\t    zp->zp_level == 0 && !DMU_OT_HAS_FILL(zp->zp_type) &&\n\t\t    spa_feature_is_enabled(spa, SPA_FEATURE_EMBEDDED_DATA)) {\n\t\t\tencode_embedded_bp_compressed(bp,\n\t\t\t    cbuf, compress, lsize, psize);\n\t\t\tBPE_SET_ETYPE(bp, BP_EMBEDDED_TYPE_DATA);\n\t\t\tBP_SET_TYPE(bp, zio->io_prop.zp_type);\n\t\t\tBP_SET_LEVEL(bp, zio->io_prop.zp_level);\n\t\t\tzio_buf_free(cbuf, lsize);\n\t\t\tbp->blk_birth = zio->io_txg;\n\t\t\tzio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\t\t\tASSERT(spa_feature_is_active(spa,\n\t\t\t    SPA_FEATURE_EMBEDDED_DATA));\n\t\t\treturn (zio);\n\t\t} else {\n\t\t\t \n\t\t\tsize_t rounded = (size_t)zio_roundup_alloc_size(spa,\n\t\t\t    psize);\n\t\t\tif (rounded >= lsize) {\n\t\t\t\tcompress = ZIO_COMPRESS_OFF;\n\t\t\t\tzio_buf_free(cbuf, lsize);\n\t\t\t\tpsize = lsize;\n\t\t\t} else {\n\t\t\t\tabd_t *cdata = abd_get_from_buf(cbuf, lsize);\n\t\t\t\tabd_take_ownership_of_buf(cdata, B_TRUE);\n\t\t\t\tabd_zero_off(cdata, psize, rounded - psize);\n\t\t\t\tpsize = rounded;\n\t\t\t\tzio_push_transform(zio, cdata,\n\t\t\t\t    psize, lsize, NULL);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tzio->io_bp_override = NULL;\n\t\t*bp = zio->io_bp_orig;\n\t\tzio->io_pipeline = zio->io_orig_pipeline;\n\n\t} else if ((zio->io_flags & ZIO_FLAG_RAW_ENCRYPT) != 0 &&\n\t    zp->zp_type == DMU_OT_DNODE) {\n\t\t \n\t\tpsize = zio_compress_data(ZIO_COMPRESS_EMPTY,\n\t\t    zio->io_abd, NULL, lsize, zp->zp_complevel);\n\t\tif (psize == 0 || psize >= lsize)\n\t\t\tcompress = ZIO_COMPRESS_OFF;\n\t} else if (zio->io_flags & ZIO_FLAG_RAW_COMPRESS &&\n\t    !(zio->io_flags & ZIO_FLAG_RAW_ENCRYPT)) {\n\t\t \n\t\tsize_t rounded = MIN((size_t)zio_roundup_alloc_size(spa, psize),\n\t\t    lsize);\n\n\t\tif (rounded != psize) {\n\t\t\tabd_t *cdata = abd_alloc_linear(rounded, B_TRUE);\n\t\t\tabd_zero_off(cdata, psize, rounded - psize);\n\t\t\tabd_copy_off(cdata, zio->io_abd, 0, 0, psize);\n\t\t\tpsize = rounded;\n\t\t\tzio_push_transform(zio, cdata,\n\t\t\t    psize, rounded, NULL);\n\t\t}\n\t} else {\n\t\tASSERT3U(psize, !=, 0);\n\t}\n\n\t \n\tif (!BP_IS_HOLE(bp) && bp->blk_birth == zio->io_txg &&\n\t    BP_GET_PSIZE(bp) == psize &&\n\t    pass >= zfs_sync_pass_rewrite) {\n\t\tVERIFY3U(psize, !=, 0);\n\t\tenum zio_stage gang_stages = zio->io_pipeline & ZIO_GANG_STAGES;\n\n\t\tzio->io_pipeline = ZIO_REWRITE_PIPELINE | gang_stages;\n\t\tzio->io_flags |= ZIO_FLAG_IO_REWRITE;\n\t} else {\n\t\tBP_ZERO(bp);\n\t\tzio->io_pipeline = ZIO_WRITE_PIPELINE;\n\t}\n\n\tif (psize == 0) {\n\t\tif (zio->io_bp_orig.blk_birth != 0 &&\n\t\t    spa_feature_is_active(spa, SPA_FEATURE_HOLE_BIRTH)) {\n\t\t\tBP_SET_LSIZE(bp, lsize);\n\t\t\tBP_SET_TYPE(bp, zp->zp_type);\n\t\t\tBP_SET_LEVEL(bp, zp->zp_level);\n\t\t\tBP_SET_BIRTH(bp, zio->io_txg, 0);\n\t\t}\n\t\tzio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\t} else {\n\t\tASSERT(zp->zp_checksum != ZIO_CHECKSUM_GANG_HEADER);\n\t\tBP_SET_LSIZE(bp, lsize);\n\t\tBP_SET_TYPE(bp, zp->zp_type);\n\t\tBP_SET_LEVEL(bp, zp->zp_level);\n\t\tBP_SET_PSIZE(bp, psize);\n\t\tBP_SET_COMPRESS(bp, compress);\n\t\tBP_SET_CHECKSUM(bp, zp->zp_checksum);\n\t\tBP_SET_DEDUP(bp, zp->zp_dedup);\n\t\tBP_SET_BYTEORDER(bp, ZFS_HOST_BYTEORDER);\n\t\tif (zp->zp_dedup) {\n\t\t\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\t\t\tASSERT(!(zio->io_flags & ZIO_FLAG_IO_REWRITE));\n\t\t\tASSERT(!zp->zp_encrypt ||\n\t\t\t    DMU_OT_IS_ENCRYPTED(zp->zp_type));\n\t\t\tzio->io_pipeline = ZIO_DDT_WRITE_PIPELINE;\n\t\t}\n\t\tif (zp->zp_nopwrite) {\n\t\t\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\t\t\tASSERT(!(zio->io_flags & ZIO_FLAG_IO_REWRITE));\n\t\t\tzio->io_pipeline |= ZIO_STAGE_NOP_WRITE;\n\t\t}\n\t}\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_free_bp_init(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\n\tif (zio->io_child_type == ZIO_CHILD_LOGICAL) {\n\t\tif (BP_GET_DEDUP(bp))\n\t\t\tzio->io_pipeline = ZIO_DDT_FREE_PIPELINE;\n\t}\n\n\tASSERT3P(zio->io_bp, ==, &zio->io_bp_copy);\n\n\treturn (zio);\n}\n\n \n\nstatic void\nzio_taskq_dispatch(zio_t *zio, zio_taskq_type_t q, boolean_t cutinline)\n{\n\tspa_t *spa = zio->io_spa;\n\tzio_type_t t = zio->io_type;\n\tint flags = (cutinline ? TQ_FRONT : 0);\n\n\t \n\tif (zio->io_flags & (ZIO_FLAG_CONFIG_WRITER | ZIO_FLAG_PROBE))\n\t\tt = ZIO_TYPE_NULL;\n\n\t \n\tif (t == ZIO_TYPE_WRITE && zio->io_vd && zio->io_vd->vdev_aux)\n\t\tt = ZIO_TYPE_NULL;\n\n\t \n\tif ((zio->io_priority == ZIO_PRIORITY_NOW ||\n\t    zio->io_priority == ZIO_PRIORITY_SYNC_WRITE) &&\n\t    spa->spa_zio_taskq[t][q + 1].stqs_count != 0)\n\t\tq++;\n\n\tASSERT3U(q, <, ZIO_TASKQ_TYPES);\n\n\t \n\tASSERT(taskq_empty_ent(&zio->io_tqent));\n\tspa_taskq_dispatch_ent(spa, t, q, zio_execute, zio, flags,\n\t    &zio->io_tqent);\n}\n\nstatic boolean_t\nzio_taskq_member(zio_t *zio, zio_taskq_type_t q)\n{\n\tspa_t *spa = zio->io_spa;\n\n\ttaskq_t *tq = taskq_of_curthread();\n\n\tfor (zio_type_t t = 0; t < ZIO_TYPES; t++) {\n\t\tspa_taskqs_t *tqs = &spa->spa_zio_taskq[t][q];\n\t\tuint_t i;\n\t\tfor (i = 0; i < tqs->stqs_count; i++) {\n\t\t\tif (tqs->stqs_taskq[i] == tq)\n\t\t\t\treturn (B_TRUE);\n\t\t}\n\t}\n\n\treturn (B_FALSE);\n}\n\nstatic zio_t *\nzio_issue_async(zio_t *zio)\n{\n\tzio_taskq_dispatch(zio, ZIO_TASKQ_ISSUE, B_FALSE);\n\n\treturn (NULL);\n}\n\nvoid\nzio_interrupt(void *zio)\n{\n\tzio_taskq_dispatch(zio, ZIO_TASKQ_INTERRUPT, B_FALSE);\n}\n\nvoid\nzio_delay_interrupt(zio_t *zio)\n{\n\t \n\n#ifdef _KERNEL\n\t \n\tif (zio->io_target_timestamp != 0) {\n\t\thrtime_t now = gethrtime();\n\n\t\tif (now >= zio->io_target_timestamp) {\n\t\t\t \n\n\t\t\tDTRACE_PROBE2(zio__delay__miss, zio_t *, zio,\n\t\t\t    hrtime_t, now);\n\n\t\t\tzio_interrupt(zio);\n\t\t} else {\n\t\t\ttaskqid_t tid;\n\t\t\thrtime_t diff = zio->io_target_timestamp - now;\n\t\t\tclock_t expire_at_tick = ddi_get_lbolt() +\n\t\t\t    NSEC_TO_TICK(diff);\n\n\t\t\tDTRACE_PROBE3(zio__delay__hit, zio_t *, zio,\n\t\t\t    hrtime_t, now, hrtime_t, diff);\n\n\t\t\tif (NSEC_TO_TICK(diff) == 0) {\n\t\t\t\t \n\t\t\t\tzfs_sleep_until(zio->io_target_timestamp);\n\t\t\t\tzio_interrupt(zio);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\ttid = taskq_dispatch_delay(system_taskq,\n\t\t\t\t    zio_interrupt, zio, TQ_NOSLEEP,\n\t\t\t\t    expire_at_tick);\n\t\t\t\tif (tid == TASKQID_INVALID) {\n\t\t\t\t\t \n\t\t\t\t\tzio_interrupt(zio);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn;\n\t}\n#endif\n\tDTRACE_PROBE1(zio__delay__skip, zio_t *, zio);\n\tzio_interrupt(zio);\n}\n\nstatic void\nzio_deadman_impl(zio_t *pio, int ziodepth)\n{\n\tzio_t *cio, *cio_next;\n\tzio_link_t *zl = NULL;\n\tvdev_t *vd = pio->io_vd;\n\n\tif (zio_deadman_log_all || (vd != NULL && vd->vdev_ops->vdev_op_leaf)) {\n\t\tvdev_queue_t *vq = vd ? &vd->vdev_queue : NULL;\n\t\tzbookmark_phys_t *zb = &pio->io_bookmark;\n\t\tuint64_t delta = gethrtime() - pio->io_timestamp;\n\t\tuint64_t failmode = spa_get_deadman_failmode(pio->io_spa);\n\n\t\tzfs_dbgmsg(\"slow zio[%d]: zio=%px timestamp=%llu \"\n\t\t    \"delta=%llu queued=%llu io=%llu \"\n\t\t    \"path=%s \"\n\t\t    \"last=%llu type=%d \"\n\t\t    \"priority=%d flags=0x%llx stage=0x%x \"\n\t\t    \"pipeline=0x%x pipeline-trace=0x%x \"\n\t\t    \"objset=%llu object=%llu \"\n\t\t    \"level=%llu blkid=%llu \"\n\t\t    \"offset=%llu size=%llu \"\n\t\t    \"error=%d\",\n\t\t    ziodepth, pio, pio->io_timestamp,\n\t\t    (u_longlong_t)delta, pio->io_delta, pio->io_delay,\n\t\t    vd ? vd->vdev_path : \"NULL\",\n\t\t    vq ? vq->vq_io_complete_ts : 0, pio->io_type,\n\t\t    pio->io_priority, (u_longlong_t)pio->io_flags,\n\t\t    pio->io_stage, pio->io_pipeline, pio->io_pipeline_trace,\n\t\t    (u_longlong_t)zb->zb_objset, (u_longlong_t)zb->zb_object,\n\t\t    (u_longlong_t)zb->zb_level, (u_longlong_t)zb->zb_blkid,\n\t\t    (u_longlong_t)pio->io_offset, (u_longlong_t)pio->io_size,\n\t\t    pio->io_error);\n\t\t(void) zfs_ereport_post(FM_EREPORT_ZFS_DEADMAN,\n\t\t    pio->io_spa, vd, zb, pio, 0);\n\n\t\tif (failmode == ZIO_FAILURE_MODE_CONTINUE &&\n\t\t    taskq_empty_ent(&pio->io_tqent)) {\n\t\t\tzio_interrupt(pio);\n\t\t}\n\t}\n\n\tmutex_enter(&pio->io_lock);\n\tfor (cio = zio_walk_children(pio, &zl); cio != NULL; cio = cio_next) {\n\t\tcio_next = zio_walk_children(pio, &zl);\n\t\tzio_deadman_impl(cio, ziodepth + 1);\n\t}\n\tmutex_exit(&pio->io_lock);\n}\n\n \nvoid\nzio_deadman(zio_t *pio, const char *tag)\n{\n\tspa_t *spa = pio->io_spa;\n\tchar *name = spa_name(spa);\n\n\tif (!zfs_deadman_enabled || spa_suspended(spa))\n\t\treturn;\n\n\tzio_deadman_impl(pio, 0);\n\n\tswitch (spa_get_deadman_failmode(spa)) {\n\tcase ZIO_FAILURE_MODE_WAIT:\n\t\tzfs_dbgmsg(\"%s waiting for hung I/O to pool '%s'\", tag, name);\n\t\tbreak;\n\n\tcase ZIO_FAILURE_MODE_CONTINUE:\n\t\tzfs_dbgmsg(\"%s restarting hung I/O for pool '%s'\", tag, name);\n\t\tbreak;\n\n\tcase ZIO_FAILURE_MODE_PANIC:\n\t\tfm_panic(\"%s determined I/O to pool '%s' is hung.\", tag, name);\n\t\tbreak;\n\t}\n}\n\n \nstatic zio_pipe_stage_t *zio_pipeline[];\n\n \nvoid\nzio_execute(void *zio)\n{\n\tfstrans_cookie_t cookie;\n\n\tcookie = spl_fstrans_mark();\n\t__zio_execute(zio);\n\tspl_fstrans_unmark(cookie);\n}\n\n \nstatic boolean_t\nzio_execute_stack_check(zio_t *zio)\n{\n#if !defined(HAVE_LARGE_STACKS)\n\tdsl_pool_t *dp = spa_get_dsl(zio->io_spa);\n\n\t \n\tif (dp && curthread == dp->dp_tx.tx_sync_thread)\n\t\treturn (B_TRUE);\n\n\t \n\tif (dp && spa_is_initializing(dp->dp_spa) &&\n\t    !zio_taskq_member(zio, ZIO_TASKQ_ISSUE) &&\n\t    !zio_taskq_member(zio, ZIO_TASKQ_ISSUE_HIGH))\n\t\treturn (B_TRUE);\n#else\n\t(void) zio;\n#endif  \n\n\treturn (B_FALSE);\n}\n\n__attribute__((always_inline))\nstatic inline void\n__zio_execute(zio_t *zio)\n{\n\tASSERT3U(zio->io_queued_timestamp, >, 0);\n\n\twhile (zio->io_stage < ZIO_STAGE_DONE) {\n\t\tenum zio_stage pipeline = zio->io_pipeline;\n\t\tenum zio_stage stage = zio->io_stage;\n\n\t\tzio->io_executor = curthread;\n\n\t\tASSERT(!MUTEX_HELD(&zio->io_lock));\n\t\tASSERT(ISP2(stage));\n\t\tASSERT(zio->io_stall == NULL);\n\n\t\tdo {\n\t\t\tstage <<= 1;\n\t\t} while ((stage & pipeline) == 0);\n\n\t\tASSERT(stage <= ZIO_STAGE_DONE);\n\n\t\t \n\t\tif ((stage & ZIO_BLOCKING_STAGES) && zio->io_vd == NULL &&\n\t\t    zio_taskq_member(zio, ZIO_TASKQ_INTERRUPT)) {\n\t\t\tboolean_t cut = (stage == ZIO_STAGE_VDEV_IO_START) ?\n\t\t\t    zio_requeue_io_start_cut_in_line : B_FALSE;\n\t\t\tzio_taskq_dispatch(zio, ZIO_TASKQ_ISSUE, cut);\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tif (zio_execute_stack_check(zio)) {\n\t\t\tboolean_t cut = (stage == ZIO_STAGE_VDEV_IO_START) ?\n\t\t\t    zio_requeue_io_start_cut_in_line : B_FALSE;\n\t\t\tzio_taskq_dispatch(zio, ZIO_TASKQ_ISSUE, cut);\n\t\t\treturn;\n\t\t}\n\n\t\tzio->io_stage = stage;\n\t\tzio->io_pipeline_trace |= zio->io_stage;\n\n\t\t \n\t\tzio = zio_pipeline[highbit64(stage) - 1](zio);\n\n\t\tif (zio == NULL)\n\t\t\treturn;\n\t}\n}\n\n\n \nint\nzio_wait(zio_t *zio)\n{\n\t \n\tif (zio == NULL)\n\t\treturn (0);\n\n\tlong timeout = MSEC_TO_TICK(zfs_deadman_ziotime_ms);\n\tint error;\n\n\tASSERT3S(zio->io_stage, ==, ZIO_STAGE_OPEN);\n\tASSERT3P(zio->io_executor, ==, NULL);\n\n\tzio->io_waiter = curthread;\n\tASSERT0(zio->io_queued_timestamp);\n\tzio->io_queued_timestamp = gethrtime();\n\n\t__zio_execute(zio);\n\n\tmutex_enter(&zio->io_lock);\n\twhile (zio->io_executor != NULL) {\n\t\terror = cv_timedwait_io(&zio->io_cv, &zio->io_lock,\n\t\t    ddi_get_lbolt() + timeout);\n\n\t\tif (zfs_deadman_enabled && error == -1 &&\n\t\t    gethrtime() - zio->io_queued_timestamp >\n\t\t    spa_deadman_ziotime(zio->io_spa)) {\n\t\t\tmutex_exit(&zio->io_lock);\n\t\t\ttimeout = MSEC_TO_TICK(zfs_deadman_checktime_ms);\n\t\t\tzio_deadman(zio, FTAG);\n\t\t\tmutex_enter(&zio->io_lock);\n\t\t}\n\t}\n\tmutex_exit(&zio->io_lock);\n\n\terror = zio->io_error;\n\tzio_destroy(zio);\n\n\treturn (error);\n}\n\nvoid\nzio_nowait(zio_t *zio)\n{\n\t \n\tif (zio == NULL)\n\t\treturn;\n\n\tASSERT3P(zio->io_executor, ==, NULL);\n\n\tif (zio->io_child_type == ZIO_CHILD_LOGICAL &&\n\t    list_is_empty(&zio->io_parent_list)) {\n\t\tzio_t *pio;\n\n\t\t \n\t\tspa_t *spa = zio->io_spa;\n\t\tpio = spa->spa_async_zio_root[CPU_SEQID_UNSTABLE];\n\n\t\tzio_add_child(pio, zio);\n\t}\n\n\tASSERT0(zio->io_queued_timestamp);\n\tzio->io_queued_timestamp = gethrtime();\n\t__zio_execute(zio);\n}\n\n \n\nstatic void\nzio_reexecute(void *arg)\n{\n\tzio_t *pio = arg;\n\tzio_t *cio, *cio_next;\n\n\tASSERT(pio->io_child_type == ZIO_CHILD_LOGICAL);\n\tASSERT(pio->io_orig_stage == ZIO_STAGE_OPEN);\n\tASSERT(pio->io_gang_leader == NULL);\n\tASSERT(pio->io_gang_tree == NULL);\n\n\tpio->io_flags = pio->io_orig_flags;\n\tpio->io_stage = pio->io_orig_stage;\n\tpio->io_pipeline = pio->io_orig_pipeline;\n\tpio->io_reexecute = 0;\n\tpio->io_flags |= ZIO_FLAG_REEXECUTED;\n\tpio->io_pipeline_trace = 0;\n\tpio->io_error = 0;\n\tfor (int w = 0; w < ZIO_WAIT_TYPES; w++)\n\t\tpio->io_state[w] = 0;\n\tfor (int c = 0; c < ZIO_CHILD_TYPES; c++)\n\t\tpio->io_child_error[c] = 0;\n\n\tif (IO_IS_ALLOCATING(pio))\n\t\tBP_ZERO(pio->io_bp);\n\n\t \n\tzio_link_t *zl = NULL;\n\tmutex_enter(&pio->io_lock);\n\tfor (cio = zio_walk_children(pio, &zl); cio != NULL; cio = cio_next) {\n\t\tcio_next = zio_walk_children(pio, &zl);\n\t\tfor (int w = 0; w < ZIO_WAIT_TYPES; w++)\n\t\t\tpio->io_children[cio->io_child_type][w]++;\n\t\tmutex_exit(&pio->io_lock);\n\t\tzio_reexecute(cio);\n\t\tmutex_enter(&pio->io_lock);\n\t}\n\tmutex_exit(&pio->io_lock);\n\n\t \n\tif (!(pio->io_flags & ZIO_FLAG_GODFATHER)) {\n\t\tpio->io_queued_timestamp = gethrtime();\n\t\t__zio_execute(pio);\n\t}\n}\n\nvoid\nzio_suspend(spa_t *spa, zio_t *zio, zio_suspend_reason_t reason)\n{\n\tif (spa_get_failmode(spa) == ZIO_FAILURE_MODE_PANIC)\n\t\tfm_panic(\"Pool '%s' has encountered an uncorrectable I/O \"\n\t\t    \"failure and the failure mode property for this pool \"\n\t\t    \"is set to panic.\", spa_name(spa));\n\n\tcmn_err(CE_WARN, \"Pool '%s' has encountered an uncorrectable I/O \"\n\t    \"failure and has been suspended.\\n\", spa_name(spa));\n\n\t(void) zfs_ereport_post(FM_EREPORT_ZFS_IO_FAILURE, spa, NULL,\n\t    NULL, NULL, 0);\n\n\tmutex_enter(&spa->spa_suspend_lock);\n\n\tif (spa->spa_suspend_zio_root == NULL)\n\t\tspa->spa_suspend_zio_root = zio_root(spa, NULL, NULL,\n\t\t    ZIO_FLAG_CANFAIL | ZIO_FLAG_SPECULATIVE |\n\t\t    ZIO_FLAG_GODFATHER);\n\n\tspa->spa_suspended = reason;\n\n\tif (zio != NULL) {\n\t\tASSERT(!(zio->io_flags & ZIO_FLAG_GODFATHER));\n\t\tASSERT(zio != spa->spa_suspend_zio_root);\n\t\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\t\tASSERT(zio_unique_parent(zio) == NULL);\n\t\tASSERT(zio->io_stage == ZIO_STAGE_DONE);\n\t\tzio_add_child(spa->spa_suspend_zio_root, zio);\n\t}\n\n\tmutex_exit(&spa->spa_suspend_lock);\n}\n\nint\nzio_resume(spa_t *spa)\n{\n\tzio_t *pio;\n\n\t \n\tmutex_enter(&spa->spa_suspend_lock);\n\tspa->spa_suspended = ZIO_SUSPEND_NONE;\n\tcv_broadcast(&spa->spa_suspend_cv);\n\tpio = spa->spa_suspend_zio_root;\n\tspa->spa_suspend_zio_root = NULL;\n\tmutex_exit(&spa->spa_suspend_lock);\n\n\tif (pio == NULL)\n\t\treturn (0);\n\n\tzio_reexecute(pio);\n\treturn (zio_wait(pio));\n}\n\nvoid\nzio_resume_wait(spa_t *spa)\n{\n\tmutex_enter(&spa->spa_suspend_lock);\n\twhile (spa_suspended(spa))\n\t\tcv_wait(&spa->spa_suspend_cv, &spa->spa_suspend_lock);\n\tmutex_exit(&spa->spa_suspend_lock);\n}\n\n \n\nstatic void\nzio_gang_issue_func_done(zio_t *zio)\n{\n\tabd_free(zio->io_abd);\n}\n\nstatic zio_t *\nzio_read_gang(zio_t *pio, blkptr_t *bp, zio_gang_node_t *gn, abd_t *data,\n    uint64_t offset)\n{\n\tif (gn != NULL)\n\t\treturn (pio);\n\n\treturn (zio_read(pio, pio->io_spa, bp, abd_get_offset(data, offset),\n\t    BP_GET_PSIZE(bp), zio_gang_issue_func_done,\n\t    NULL, pio->io_priority, ZIO_GANG_CHILD_FLAGS(pio),\n\t    &pio->io_bookmark));\n}\n\nstatic zio_t *\nzio_rewrite_gang(zio_t *pio, blkptr_t *bp, zio_gang_node_t *gn, abd_t *data,\n    uint64_t offset)\n{\n\tzio_t *zio;\n\n\tif (gn != NULL) {\n\t\tabd_t *gbh_abd =\n\t\t    abd_get_from_buf(gn->gn_gbh, SPA_GANGBLOCKSIZE);\n\t\tzio = zio_rewrite(pio, pio->io_spa, pio->io_txg, bp,\n\t\t    gbh_abd, SPA_GANGBLOCKSIZE, zio_gang_issue_func_done, NULL,\n\t\t    pio->io_priority, ZIO_GANG_CHILD_FLAGS(pio),\n\t\t    &pio->io_bookmark);\n\t\t \n\t\tif (gn != pio->io_gang_leader->io_gang_tree) {\n\t\t\tabd_t *buf = abd_get_offset(data, offset);\n\n\t\t\tzio_checksum_compute(zio, BP_GET_CHECKSUM(bp),\n\t\t\t    buf, BP_GET_PSIZE(bp));\n\n\t\t\tabd_free(buf);\n\t\t}\n\t\t \n\t\tif (pio->io_gang_leader->io_flags & ZIO_FLAG_INDUCE_DAMAGE)\n\t\t\tzio->io_pipeline &= ~ZIO_VDEV_IO_STAGES;\n\t} else {\n\t\tzio = zio_rewrite(pio, pio->io_spa, pio->io_txg, bp,\n\t\t    abd_get_offset(data, offset), BP_GET_PSIZE(bp),\n\t\t    zio_gang_issue_func_done, NULL, pio->io_priority,\n\t\t    ZIO_GANG_CHILD_FLAGS(pio), &pio->io_bookmark);\n\t}\n\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_free_gang(zio_t *pio, blkptr_t *bp, zio_gang_node_t *gn, abd_t *data,\n    uint64_t offset)\n{\n\t(void) gn, (void) data, (void) offset;\n\n\tzio_t *zio = zio_free_sync(pio, pio->io_spa, pio->io_txg, bp,\n\t    ZIO_GANG_CHILD_FLAGS(pio));\n\tif (zio == NULL) {\n\t\tzio = zio_null(pio, pio->io_spa,\n\t\t    NULL, NULL, NULL, ZIO_GANG_CHILD_FLAGS(pio));\n\t}\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_claim_gang(zio_t *pio, blkptr_t *bp, zio_gang_node_t *gn, abd_t *data,\n    uint64_t offset)\n{\n\t(void) gn, (void) data, (void) offset;\n\treturn (zio_claim(pio, pio->io_spa, pio->io_txg, bp,\n\t    NULL, NULL, ZIO_GANG_CHILD_FLAGS(pio)));\n}\n\nstatic zio_gang_issue_func_t *zio_gang_issue_func[ZIO_TYPES] = {\n\tNULL,\n\tzio_read_gang,\n\tzio_rewrite_gang,\n\tzio_free_gang,\n\tzio_claim_gang,\n\tNULL\n};\n\nstatic void zio_gang_tree_assemble_done(zio_t *zio);\n\nstatic zio_gang_node_t *\nzio_gang_node_alloc(zio_gang_node_t **gnpp)\n{\n\tzio_gang_node_t *gn;\n\n\tASSERT(*gnpp == NULL);\n\n\tgn = kmem_zalloc(sizeof (*gn), KM_SLEEP);\n\tgn->gn_gbh = zio_buf_alloc(SPA_GANGBLOCKSIZE);\n\t*gnpp = gn;\n\n\treturn (gn);\n}\n\nstatic void\nzio_gang_node_free(zio_gang_node_t **gnpp)\n{\n\tzio_gang_node_t *gn = *gnpp;\n\n\tfor (int g = 0; g < SPA_GBH_NBLKPTRS; g++)\n\t\tASSERT(gn->gn_child[g] == NULL);\n\n\tzio_buf_free(gn->gn_gbh, SPA_GANGBLOCKSIZE);\n\tkmem_free(gn, sizeof (*gn));\n\t*gnpp = NULL;\n}\n\nstatic void\nzio_gang_tree_free(zio_gang_node_t **gnpp)\n{\n\tzio_gang_node_t *gn = *gnpp;\n\n\tif (gn == NULL)\n\t\treturn;\n\n\tfor (int g = 0; g < SPA_GBH_NBLKPTRS; g++)\n\t\tzio_gang_tree_free(&gn->gn_child[g]);\n\n\tzio_gang_node_free(gnpp);\n}\n\nstatic void\nzio_gang_tree_assemble(zio_t *gio, blkptr_t *bp, zio_gang_node_t **gnpp)\n{\n\tzio_gang_node_t *gn = zio_gang_node_alloc(gnpp);\n\tabd_t *gbh_abd = abd_get_from_buf(gn->gn_gbh, SPA_GANGBLOCKSIZE);\n\n\tASSERT(gio->io_gang_leader == gio);\n\tASSERT(BP_IS_GANG(bp));\n\n\tzio_nowait(zio_read(gio, gio->io_spa, bp, gbh_abd, SPA_GANGBLOCKSIZE,\n\t    zio_gang_tree_assemble_done, gn, gio->io_priority,\n\t    ZIO_GANG_CHILD_FLAGS(gio), &gio->io_bookmark));\n}\n\nstatic void\nzio_gang_tree_assemble_done(zio_t *zio)\n{\n\tzio_t *gio = zio->io_gang_leader;\n\tzio_gang_node_t *gn = zio->io_private;\n\tblkptr_t *bp = zio->io_bp;\n\n\tASSERT(gio == zio_unique_parent(zio));\n\tASSERT(list_is_empty(&zio->io_child_list));\n\n\tif (zio->io_error)\n\t\treturn;\n\n\t \n\tif (BP_SHOULD_BYTESWAP(bp))\n\t\tbyteswap_uint64_array(abd_to_buf(zio->io_abd), zio->io_size);\n\n\tASSERT3P(abd_to_buf(zio->io_abd), ==, gn->gn_gbh);\n\tASSERT(zio->io_size == SPA_GANGBLOCKSIZE);\n\tASSERT(gn->gn_gbh->zg_tail.zec_magic == ZEC_MAGIC);\n\n\tabd_free(zio->io_abd);\n\n\tfor (int g = 0; g < SPA_GBH_NBLKPTRS; g++) {\n\t\tblkptr_t *gbp = &gn->gn_gbh->zg_blkptr[g];\n\t\tif (!BP_IS_GANG(gbp))\n\t\t\tcontinue;\n\t\tzio_gang_tree_assemble(gio, gbp, &gn->gn_child[g]);\n\t}\n}\n\nstatic void\nzio_gang_tree_issue(zio_t *pio, zio_gang_node_t *gn, blkptr_t *bp, abd_t *data,\n    uint64_t offset)\n{\n\tzio_t *gio = pio->io_gang_leader;\n\tzio_t *zio;\n\n\tASSERT(BP_IS_GANG(bp) == !!gn);\n\tASSERT(BP_GET_CHECKSUM(bp) == BP_GET_CHECKSUM(gio->io_bp));\n\tASSERT(BP_GET_LSIZE(bp) == BP_GET_PSIZE(bp) || gn == gio->io_gang_tree);\n\n\t \n\tzio = zio_gang_issue_func[gio->io_type](pio, bp, gn, data, offset);\n\n\tif (gn != NULL) {\n\t\tASSERT(gn->gn_gbh->zg_tail.zec_magic == ZEC_MAGIC);\n\n\t\tfor (int g = 0; g < SPA_GBH_NBLKPTRS; g++) {\n\t\t\tblkptr_t *gbp = &gn->gn_gbh->zg_blkptr[g];\n\t\t\tif (BP_IS_HOLE(gbp))\n\t\t\t\tcontinue;\n\t\t\tzio_gang_tree_issue(zio, gn->gn_child[g], gbp, data,\n\t\t\t    offset);\n\t\t\toffset += BP_GET_PSIZE(gbp);\n\t\t}\n\t}\n\n\tif (gn == gio->io_gang_tree)\n\t\tASSERT3U(gio->io_size, ==, offset);\n\n\tif (zio != pio)\n\t\tzio_nowait(zio);\n}\n\nstatic zio_t *\nzio_gang_assemble(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\n\tASSERT(BP_IS_GANG(bp) && zio->io_gang_leader == NULL);\n\tASSERT(zio->io_child_type > ZIO_CHILD_GANG);\n\n\tzio->io_gang_leader = zio;\n\n\tzio_gang_tree_assemble(zio, bp, &zio->io_gang_tree);\n\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_gang_issue(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\n\tif (zio_wait_for_children(zio, ZIO_CHILD_GANG_BIT, ZIO_WAIT_DONE)) {\n\t\treturn (NULL);\n\t}\n\n\tASSERT(BP_IS_GANG(bp) && zio->io_gang_leader == zio);\n\tASSERT(zio->io_child_type > ZIO_CHILD_GANG);\n\n\tif (zio->io_child_error[ZIO_CHILD_GANG] == 0)\n\t\tzio_gang_tree_issue(zio, zio->io_gang_tree, bp, zio->io_abd,\n\t\t    0);\n\telse\n\t\tzio_gang_tree_free(&zio->io_gang_tree);\n\n\tzio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\n\treturn (zio);\n}\n\nstatic void\nzio_write_gang_member_ready(zio_t *zio)\n{\n\tzio_t *pio = zio_unique_parent(zio);\n\tdva_t *cdva = zio->io_bp->blk_dva;\n\tdva_t *pdva = pio->io_bp->blk_dva;\n\tuint64_t asize;\n\tzio_t *gio __maybe_unused = zio->io_gang_leader;\n\n\tif (BP_IS_HOLE(zio->io_bp))\n\t\treturn;\n\n\tASSERT(BP_IS_HOLE(&zio->io_bp_orig));\n\n\tASSERT(zio->io_child_type == ZIO_CHILD_GANG);\n\tASSERT3U(zio->io_prop.zp_copies, ==, gio->io_prop.zp_copies);\n\tASSERT3U(zio->io_prop.zp_copies, <=, BP_GET_NDVAS(zio->io_bp));\n\tASSERT3U(pio->io_prop.zp_copies, <=, BP_GET_NDVAS(pio->io_bp));\n\tVERIFY3U(BP_GET_NDVAS(zio->io_bp), <=, BP_GET_NDVAS(pio->io_bp));\n\n\tmutex_enter(&pio->io_lock);\n\tfor (int d = 0; d < BP_GET_NDVAS(zio->io_bp); d++) {\n\t\tASSERT(DVA_GET_GANG(&pdva[d]));\n\t\tasize = DVA_GET_ASIZE(&pdva[d]);\n\t\tasize += DVA_GET_ASIZE(&cdva[d]);\n\t\tDVA_SET_ASIZE(&pdva[d], asize);\n\t}\n\tmutex_exit(&pio->io_lock);\n}\n\nstatic void\nzio_write_gang_done(zio_t *zio)\n{\n\t \n\tif (zio->io_abd != NULL)\n\t\tabd_free(zio->io_abd);\n}\n\nstatic zio_t *\nzio_write_gang_block(zio_t *pio, metaslab_class_t *mc)\n{\n\tspa_t *spa = pio->io_spa;\n\tblkptr_t *bp = pio->io_bp;\n\tzio_t *gio = pio->io_gang_leader;\n\tzio_t *zio;\n\tzio_gang_node_t *gn, **gnpp;\n\tzio_gbh_phys_t *gbh;\n\tabd_t *gbh_abd;\n\tuint64_t txg = pio->io_txg;\n\tuint64_t resid = pio->io_size;\n\tuint64_t lsize;\n\tint copies = gio->io_prop.zp_copies;\n\tzio_prop_t zp;\n\tint error;\n\tboolean_t has_data = !(pio->io_flags & ZIO_FLAG_NODATA);\n\n\t \n\tint gbh_copies = copies;\n\tif (gbh_copies == 1) {\n\t\tgbh_copies = MIN(2, spa_max_replication(spa));\n\t}\n\n\tint flags = METASLAB_HINTBP_FAVOR | METASLAB_GANG_HEADER;\n\tif (pio->io_flags & ZIO_FLAG_IO_ALLOCATING) {\n\t\tASSERT(pio->io_priority == ZIO_PRIORITY_ASYNC_WRITE);\n\t\tASSERT(has_data);\n\n\t\tflags |= METASLAB_ASYNC_ALLOC;\n\t\tVERIFY(zfs_refcount_held(&mc->mc_allocator[pio->io_allocator].\n\t\t    mca_alloc_slots, pio));\n\n\t\t \n\t\tVERIFY(metaslab_class_throttle_reserve(mc, gbh_copies - copies,\n\t\t    pio->io_allocator, pio, flags));\n\t}\n\n\terror = metaslab_alloc(spa, mc, SPA_GANGBLOCKSIZE,\n\t    bp, gbh_copies, txg, pio == gio ? NULL : gio->io_bp, flags,\n\t    &pio->io_alloc_list, pio, pio->io_allocator);\n\tif (error) {\n\t\tif (pio->io_flags & ZIO_FLAG_IO_ALLOCATING) {\n\t\t\tASSERT(pio->io_priority == ZIO_PRIORITY_ASYNC_WRITE);\n\t\t\tASSERT(has_data);\n\n\t\t\t \n\t\t\tmetaslab_class_throttle_unreserve(mc,\n\t\t\t    gbh_copies - copies, pio->io_allocator, pio);\n\t\t}\n\n\t\tpio->io_error = error;\n\t\treturn (pio);\n\t}\n\n\tif (pio == gio) {\n\t\tgnpp = &gio->io_gang_tree;\n\t} else {\n\t\tgnpp = pio->io_private;\n\t\tASSERT(pio->io_ready == zio_write_gang_member_ready);\n\t}\n\n\tgn = zio_gang_node_alloc(gnpp);\n\tgbh = gn->gn_gbh;\n\tmemset(gbh, 0, SPA_GANGBLOCKSIZE);\n\tgbh_abd = abd_get_from_buf(gbh, SPA_GANGBLOCKSIZE);\n\n\t \n\tzio = zio_rewrite(pio, spa, txg, bp, gbh_abd, SPA_GANGBLOCKSIZE,\n\t    zio_write_gang_done, NULL, pio->io_priority,\n\t    ZIO_GANG_CHILD_FLAGS(pio), &pio->io_bookmark);\n\n\t \n\tfor (int g = 0; resid != 0; resid -= lsize, g++) {\n\t\tlsize = P2ROUNDUP(resid / (SPA_GBH_NBLKPTRS - g),\n\t\t    SPA_MINBLOCKSIZE);\n\t\tASSERT(lsize >= SPA_MINBLOCKSIZE && lsize <= resid);\n\n\t\tzp.zp_checksum = gio->io_prop.zp_checksum;\n\t\tzp.zp_compress = ZIO_COMPRESS_OFF;\n\t\tzp.zp_complevel = gio->io_prop.zp_complevel;\n\t\tzp.zp_type = DMU_OT_NONE;\n\t\tzp.zp_level = 0;\n\t\tzp.zp_copies = gio->io_prop.zp_copies;\n\t\tzp.zp_dedup = B_FALSE;\n\t\tzp.zp_dedup_verify = B_FALSE;\n\t\tzp.zp_nopwrite = B_FALSE;\n\t\tzp.zp_encrypt = gio->io_prop.zp_encrypt;\n\t\tzp.zp_byteorder = gio->io_prop.zp_byteorder;\n\t\tmemset(zp.zp_salt, 0, ZIO_DATA_SALT_LEN);\n\t\tmemset(zp.zp_iv, 0, ZIO_DATA_IV_LEN);\n\t\tmemset(zp.zp_mac, 0, ZIO_DATA_MAC_LEN);\n\n\t\tzio_t *cio = zio_write(zio, spa, txg, &gbh->zg_blkptr[g],\n\t\t    has_data ? abd_get_offset(pio->io_abd, pio->io_size -\n\t\t    resid) : NULL, lsize, lsize, &zp,\n\t\t    zio_write_gang_member_ready, NULL,\n\t\t    zio_write_gang_done, &gn->gn_child[g], pio->io_priority,\n\t\t    ZIO_GANG_CHILD_FLAGS(pio), &pio->io_bookmark);\n\n\t\tif (pio->io_flags & ZIO_FLAG_IO_ALLOCATING) {\n\t\t\tASSERT(pio->io_priority == ZIO_PRIORITY_ASYNC_WRITE);\n\t\t\tASSERT(has_data);\n\n\t\t\t \n\t\t\tVERIFY(metaslab_class_throttle_reserve(mc,\n\t\t\t    zp.zp_copies, cio->io_allocator, cio, flags));\n\t\t}\n\t\tzio_nowait(cio);\n\t}\n\n\t \n\tpio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\n\tzio_nowait(zio);\n\n\treturn (pio);\n}\n\n \nstatic zio_t *\nzio_nop_write(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\tblkptr_t *bp_orig = &zio->io_bp_orig;\n\tzio_prop_t *zp = &zio->io_prop;\n\n\tASSERT(BP_IS_HOLE(bp));\n\tASSERT(BP_GET_LEVEL(bp) == 0);\n\tASSERT(!(zio->io_flags & ZIO_FLAG_IO_REWRITE));\n\tASSERT(zp->zp_nopwrite);\n\tASSERT(!zp->zp_dedup);\n\tASSERT(zio->io_bp_override == NULL);\n\tASSERT(IO_IS_ALLOCATING(zio));\n\n\t \n\tif (BP_IS_HOLE(bp_orig) ||\n\t    !(zio_checksum_table[BP_GET_CHECKSUM(bp)].ci_flags &\n\t    ZCHECKSUM_FLAG_NOPWRITE) ||\n\t    BP_IS_ENCRYPTED(bp) || BP_IS_ENCRYPTED(bp_orig) ||\n\t    BP_GET_CHECKSUM(bp) != BP_GET_CHECKSUM(bp_orig) ||\n\t    BP_GET_COMPRESS(bp) != BP_GET_COMPRESS(bp_orig) ||\n\t    BP_GET_DEDUP(bp) != BP_GET_DEDUP(bp_orig) ||\n\t    zp->zp_copies != BP_GET_NDVAS(bp_orig))\n\t\treturn (zio);\n\n\t \n\tif (ZIO_CHECKSUM_EQUAL(bp->blk_cksum, bp_orig->blk_cksum)) {\n\t\tASSERT(zio_checksum_table[zp->zp_checksum].ci_flags &\n\t\t    ZCHECKSUM_FLAG_NOPWRITE);\n\t\tASSERT3U(BP_GET_PSIZE(bp), ==, BP_GET_PSIZE(bp_orig));\n\t\tASSERT3U(BP_GET_LSIZE(bp), ==, BP_GET_LSIZE(bp_orig));\n\t\tASSERT(zp->zp_compress != ZIO_COMPRESS_OFF);\n\t\tASSERT3U(bp->blk_prop, ==, bp_orig->blk_prop);\n\n\t\t \n\t\tspa_config_enter(zio->io_spa, SCL_VDEV, FTAG, RW_READER);\n\t\tfor (int d = 0; d < BP_GET_NDVAS(bp_orig); d++) {\n\t\t\tvdev_t *tvd = vdev_lookup_top(zio->io_spa,\n\t\t\t    DVA_GET_VDEV(&bp_orig->blk_dva[d]));\n\t\t\tif (tvd->vdev_ops == &vdev_indirect_ops) {\n\t\t\t\tspa_config_exit(zio->io_spa, SCL_VDEV, FTAG);\n\t\t\t\treturn (zio);\n\t\t\t}\n\t\t}\n\t\tspa_config_exit(zio->io_spa, SCL_VDEV, FTAG);\n\n\t\t*bp = *bp_orig;\n\t\tzio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\t\tzio->io_flags |= ZIO_FLAG_NOPWRITE;\n\t}\n\n\treturn (zio);\n}\n\n \nstatic zio_t *\nzio_brt_free(zio_t *zio)\n{\n\tblkptr_t *bp;\n\n\tbp = zio->io_bp;\n\n\tif (BP_GET_LEVEL(bp) > 0 ||\n\t    BP_IS_METADATA(bp) ||\n\t    !brt_maybe_exists(zio->io_spa, bp)) {\n\t\treturn (zio);\n\t}\n\n\tif (!brt_entry_decref(zio->io_spa, bp)) {\n\t\t \n\t\tzio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\t}\n\n\treturn (zio);\n}\n\n \nstatic void\nzio_ddt_child_read_done(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\tddt_entry_t *dde = zio->io_private;\n\tddt_phys_t *ddp;\n\tzio_t *pio = zio_unique_parent(zio);\n\n\tmutex_enter(&pio->io_lock);\n\tddp = ddt_phys_select(dde, bp);\n\tif (zio->io_error == 0)\n\t\tddt_phys_clear(ddp);\t \n\n\tif (zio->io_error == 0 && dde->dde_repair_abd == NULL)\n\t\tdde->dde_repair_abd = zio->io_abd;\n\telse\n\t\tabd_free(zio->io_abd);\n\tmutex_exit(&pio->io_lock);\n}\n\nstatic zio_t *\nzio_ddt_read_start(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\n\tASSERT(BP_GET_DEDUP(bp));\n\tASSERT(BP_GET_PSIZE(bp) == zio->io_size);\n\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\n\tif (zio->io_child_error[ZIO_CHILD_DDT]) {\n\t\tddt_t *ddt = ddt_select(zio->io_spa, bp);\n\t\tddt_entry_t *dde = ddt_repair_start(ddt, bp);\n\t\tddt_phys_t *ddp = dde->dde_phys;\n\t\tddt_phys_t *ddp_self = ddt_phys_select(dde, bp);\n\t\tblkptr_t blk;\n\n\t\tASSERT(zio->io_vsd == NULL);\n\t\tzio->io_vsd = dde;\n\n\t\tif (ddp_self == NULL)\n\t\t\treturn (zio);\n\n\t\tfor (int p = 0; p < DDT_PHYS_TYPES; p++, ddp++) {\n\t\t\tif (ddp->ddp_phys_birth == 0 || ddp == ddp_self)\n\t\t\t\tcontinue;\n\t\t\tddt_bp_create(ddt->ddt_checksum, &dde->dde_key, ddp,\n\t\t\t    &blk);\n\t\t\tzio_nowait(zio_read(zio, zio->io_spa, &blk,\n\t\t\t    abd_alloc_for_io(zio->io_size, B_TRUE),\n\t\t\t    zio->io_size, zio_ddt_child_read_done, dde,\n\t\t\t    zio->io_priority, ZIO_DDT_CHILD_FLAGS(zio) |\n\t\t\t    ZIO_FLAG_DONT_PROPAGATE, &zio->io_bookmark));\n\t\t}\n\t\treturn (zio);\n\t}\n\n\tzio_nowait(zio_read(zio, zio->io_spa, bp,\n\t    zio->io_abd, zio->io_size, NULL, NULL, zio->io_priority,\n\t    ZIO_DDT_CHILD_FLAGS(zio), &zio->io_bookmark));\n\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_ddt_read_done(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\n\tif (zio_wait_for_children(zio, ZIO_CHILD_DDT_BIT, ZIO_WAIT_DONE)) {\n\t\treturn (NULL);\n\t}\n\n\tASSERT(BP_GET_DEDUP(bp));\n\tASSERT(BP_GET_PSIZE(bp) == zio->io_size);\n\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\n\tif (zio->io_child_error[ZIO_CHILD_DDT]) {\n\t\tddt_t *ddt = ddt_select(zio->io_spa, bp);\n\t\tddt_entry_t *dde = zio->io_vsd;\n\t\tif (ddt == NULL) {\n\t\t\tASSERT(spa_load_state(zio->io_spa) != SPA_LOAD_NONE);\n\t\t\treturn (zio);\n\t\t}\n\t\tif (dde == NULL) {\n\t\t\tzio->io_stage = ZIO_STAGE_DDT_READ_START >> 1;\n\t\t\tzio_taskq_dispatch(zio, ZIO_TASKQ_ISSUE, B_FALSE);\n\t\t\treturn (NULL);\n\t\t}\n\t\tif (dde->dde_repair_abd != NULL) {\n\t\t\tabd_copy(zio->io_abd, dde->dde_repair_abd,\n\t\t\t    zio->io_size);\n\t\t\tzio->io_child_error[ZIO_CHILD_DDT] = 0;\n\t\t}\n\t\tddt_repair_done(ddt, dde);\n\t\tzio->io_vsd = NULL;\n\t}\n\n\tASSERT(zio->io_vsd == NULL);\n\n\treturn (zio);\n}\n\nstatic boolean_t\nzio_ddt_collision(zio_t *zio, ddt_t *ddt, ddt_entry_t *dde)\n{\n\tspa_t *spa = zio->io_spa;\n\tboolean_t do_raw = !!(zio->io_flags & ZIO_FLAG_RAW);\n\n\tASSERT(!(zio->io_bp_override && do_raw));\n\n\t \n\n\tfor (int p = DDT_PHYS_SINGLE; p <= DDT_PHYS_TRIPLE; p++) {\n\t\tzio_t *lio = dde->dde_lead_zio[p];\n\n\t\tif (lio != NULL && do_raw) {\n\t\t\treturn (lio->io_size != zio->io_size ||\n\t\t\t    abd_cmp(zio->io_abd, lio->io_abd) != 0);\n\t\t} else if (lio != NULL) {\n\t\t\treturn (lio->io_orig_size != zio->io_orig_size ||\n\t\t\t    abd_cmp(zio->io_orig_abd, lio->io_orig_abd) != 0);\n\t\t}\n\t}\n\n\tfor (int p = DDT_PHYS_SINGLE; p <= DDT_PHYS_TRIPLE; p++) {\n\t\tddt_phys_t *ddp = &dde->dde_phys[p];\n\n\t\tif (ddp->ddp_phys_birth != 0 && do_raw) {\n\t\t\tblkptr_t blk = *zio->io_bp;\n\t\t\tuint64_t psize;\n\t\t\tabd_t *tmpabd;\n\t\t\tint error;\n\n\t\t\tddt_bp_fill(ddp, &blk, ddp->ddp_phys_birth);\n\t\t\tpsize = BP_GET_PSIZE(&blk);\n\n\t\t\tif (psize != zio->io_size)\n\t\t\t\treturn (B_TRUE);\n\n\t\t\tddt_exit(ddt);\n\n\t\t\ttmpabd = abd_alloc_for_io(psize, B_TRUE);\n\n\t\t\terror = zio_wait(zio_read(NULL, spa, &blk, tmpabd,\n\t\t\t    psize, NULL, NULL, ZIO_PRIORITY_SYNC_READ,\n\t\t\t    ZIO_FLAG_CANFAIL | ZIO_FLAG_SPECULATIVE |\n\t\t\t    ZIO_FLAG_RAW, &zio->io_bookmark));\n\n\t\t\tif (error == 0) {\n\t\t\t\tif (abd_cmp(tmpabd, zio->io_abd) != 0)\n\t\t\t\t\terror = SET_ERROR(ENOENT);\n\t\t\t}\n\n\t\t\tabd_free(tmpabd);\n\t\t\tddt_enter(ddt);\n\t\t\treturn (error != 0);\n\t\t} else if (ddp->ddp_phys_birth != 0) {\n\t\t\tarc_buf_t *abuf = NULL;\n\t\t\tarc_flags_t aflags = ARC_FLAG_WAIT;\n\t\t\tblkptr_t blk = *zio->io_bp;\n\t\t\tint error;\n\n\t\t\tddt_bp_fill(ddp, &blk, ddp->ddp_phys_birth);\n\n\t\t\tif (BP_GET_LSIZE(&blk) != zio->io_orig_size)\n\t\t\t\treturn (B_TRUE);\n\n\t\t\tddt_exit(ddt);\n\n\t\t\terror = arc_read(NULL, spa, &blk,\n\t\t\t    arc_getbuf_func, &abuf, ZIO_PRIORITY_SYNC_READ,\n\t\t\t    ZIO_FLAG_CANFAIL | ZIO_FLAG_SPECULATIVE,\n\t\t\t    &aflags, &zio->io_bookmark);\n\n\t\t\tif (error == 0) {\n\t\t\t\tif (abd_cmp_buf(zio->io_orig_abd, abuf->b_data,\n\t\t\t\t    zio->io_orig_size) != 0)\n\t\t\t\t\terror = SET_ERROR(ENOENT);\n\t\t\t\tarc_buf_destroy(abuf, &abuf);\n\t\t\t}\n\n\t\t\tddt_enter(ddt);\n\t\t\treturn (error != 0);\n\t\t}\n\t}\n\n\treturn (B_FALSE);\n}\n\nstatic void\nzio_ddt_child_write_ready(zio_t *zio)\n{\n\tint p = zio->io_prop.zp_copies;\n\tddt_t *ddt = ddt_select(zio->io_spa, zio->io_bp);\n\tddt_entry_t *dde = zio->io_private;\n\tddt_phys_t *ddp = &dde->dde_phys[p];\n\tzio_t *pio;\n\n\tif (zio->io_error)\n\t\treturn;\n\n\tddt_enter(ddt);\n\n\tASSERT(dde->dde_lead_zio[p] == zio);\n\n\tddt_phys_fill(ddp, zio->io_bp);\n\n\tzio_link_t *zl = NULL;\n\twhile ((pio = zio_walk_parents(zio, &zl)) != NULL)\n\t\tddt_bp_fill(ddp, pio->io_bp, zio->io_txg);\n\n\tddt_exit(ddt);\n}\n\nstatic void\nzio_ddt_child_write_done(zio_t *zio)\n{\n\tint p = zio->io_prop.zp_copies;\n\tddt_t *ddt = ddt_select(zio->io_spa, zio->io_bp);\n\tddt_entry_t *dde = zio->io_private;\n\tddt_phys_t *ddp = &dde->dde_phys[p];\n\n\tddt_enter(ddt);\n\n\tASSERT(ddp->ddp_refcnt == 0);\n\tASSERT(dde->dde_lead_zio[p] == zio);\n\tdde->dde_lead_zio[p] = NULL;\n\n\tif (zio->io_error == 0) {\n\t\tzio_link_t *zl = NULL;\n\t\twhile (zio_walk_parents(zio, &zl) != NULL)\n\t\t\tddt_phys_addref(ddp);\n\t} else {\n\t\tddt_phys_clear(ddp);\n\t}\n\n\tddt_exit(ddt);\n}\n\nstatic zio_t *\nzio_ddt_write(zio_t *zio)\n{\n\tspa_t *spa = zio->io_spa;\n\tblkptr_t *bp = zio->io_bp;\n\tuint64_t txg = zio->io_txg;\n\tzio_prop_t *zp = &zio->io_prop;\n\tint p = zp->zp_copies;\n\tzio_t *cio = NULL;\n\tddt_t *ddt = ddt_select(spa, bp);\n\tddt_entry_t *dde;\n\tddt_phys_t *ddp;\n\n\tASSERT(BP_GET_DEDUP(bp));\n\tASSERT(BP_GET_CHECKSUM(bp) == zp->zp_checksum);\n\tASSERT(BP_IS_HOLE(bp) || zio->io_bp_override);\n\tASSERT(!(zio->io_bp_override && (zio->io_flags & ZIO_FLAG_RAW)));\n\n\tddt_enter(ddt);\n\tdde = ddt_lookup(ddt, bp, B_TRUE);\n\tddp = &dde->dde_phys[p];\n\n\tif (zp->zp_dedup_verify && zio_ddt_collision(zio, ddt, dde)) {\n\t\t \n\t\tif (!(zio_checksum_table[zp->zp_checksum].ci_flags &\n\t\t    ZCHECKSUM_FLAG_DEDUP)) {\n\t\t\tzp->zp_checksum = spa_dedup_checksum(spa);\n\t\t\tzio_pop_transforms(zio);\n\t\t\tzio->io_stage = ZIO_STAGE_OPEN;\n\t\t\tBP_ZERO(bp);\n\t\t} else {\n\t\t\tzp->zp_dedup = B_FALSE;\n\t\t\tBP_SET_DEDUP(bp, B_FALSE);\n\t\t}\n\t\tASSERT(!BP_GET_DEDUP(bp));\n\t\tzio->io_pipeline = ZIO_WRITE_PIPELINE;\n\t\tddt_exit(ddt);\n\t\treturn (zio);\n\t}\n\n\tif (ddp->ddp_phys_birth != 0 || dde->dde_lead_zio[p] != NULL) {\n\t\tif (ddp->ddp_phys_birth != 0)\n\t\t\tddt_bp_fill(ddp, bp, txg);\n\t\tif (dde->dde_lead_zio[p] != NULL)\n\t\t\tzio_add_child(zio, dde->dde_lead_zio[p]);\n\t\telse\n\t\t\tddt_phys_addref(ddp);\n\t} else if (zio->io_bp_override) {\n\t\tASSERT(bp->blk_birth == txg);\n\t\tASSERT(BP_EQUAL(bp, zio->io_bp_override));\n\t\tddt_phys_fill(ddp, bp);\n\t\tddt_phys_addref(ddp);\n\t} else {\n\t\tcio = zio_write(zio, spa, txg, bp, zio->io_orig_abd,\n\t\t    zio->io_orig_size, zio->io_orig_size, zp,\n\t\t    zio_ddt_child_write_ready, NULL,\n\t\t    zio_ddt_child_write_done, dde, zio->io_priority,\n\t\t    ZIO_DDT_CHILD_FLAGS(zio), &zio->io_bookmark);\n\n\t\tzio_push_transform(cio, zio->io_abd, zio->io_size, 0, NULL);\n\t\tdde->dde_lead_zio[p] = cio;\n\t}\n\n\tddt_exit(ddt);\n\n\tzio_nowait(cio);\n\n\treturn (zio);\n}\n\nstatic ddt_entry_t *freedde;  \n\nstatic zio_t *\nzio_ddt_free(zio_t *zio)\n{\n\tspa_t *spa = zio->io_spa;\n\tblkptr_t *bp = zio->io_bp;\n\tddt_t *ddt = ddt_select(spa, bp);\n\tddt_entry_t *dde;\n\tddt_phys_t *ddp;\n\n\tASSERT(BP_GET_DEDUP(bp));\n\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\n\tddt_enter(ddt);\n\tfreedde = dde = ddt_lookup(ddt, bp, B_TRUE);\n\tif (dde) {\n\t\tddp = ddt_phys_select(dde, bp);\n\t\tif (ddp)\n\t\t\tddt_phys_decref(ddp);\n\t}\n\tddt_exit(ddt);\n\n\treturn (zio);\n}\n\n \n\nstatic zio_t *\nzio_io_to_allocate(spa_t *spa, int allocator)\n{\n\tzio_t *zio;\n\n\tASSERT(MUTEX_HELD(&spa->spa_allocs[allocator].spaa_lock));\n\n\tzio = avl_first(&spa->spa_allocs[allocator].spaa_tree);\n\tif (zio == NULL)\n\t\treturn (NULL);\n\n\tASSERT(IO_IS_ALLOCATING(zio));\n\n\t \n\tASSERT3U(zio->io_allocator, ==, allocator);\n\tif (!metaslab_class_throttle_reserve(zio->io_metaslab_class,\n\t    zio->io_prop.zp_copies, allocator, zio, 0)) {\n\t\treturn (NULL);\n\t}\n\n\tavl_remove(&spa->spa_allocs[allocator].spaa_tree, zio);\n\tASSERT3U(zio->io_stage, <, ZIO_STAGE_DVA_ALLOCATE);\n\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_dva_throttle(zio_t *zio)\n{\n\tspa_t *spa = zio->io_spa;\n\tzio_t *nio;\n\tmetaslab_class_t *mc;\n\n\t \n\tmc = spa_preferred_class(spa, zio->io_size, zio->io_prop.zp_type,\n\t    zio->io_prop.zp_level, zio->io_prop.zp_zpl_smallblk);\n\n\tif (zio->io_priority == ZIO_PRIORITY_SYNC_WRITE ||\n\t    !mc->mc_alloc_throttle_enabled ||\n\t    zio->io_child_type == ZIO_CHILD_GANG ||\n\t    zio->io_flags & ZIO_FLAG_NODATA) {\n\t\treturn (zio);\n\t}\n\n\tASSERT(zio->io_type == ZIO_TYPE_WRITE);\n\tASSERT(zio->io_child_type > ZIO_CHILD_GANG);\n\tASSERT3U(zio->io_queued_timestamp, >, 0);\n\tASSERT(zio->io_stage == ZIO_STAGE_DVA_THROTTLE);\n\n\tzbookmark_phys_t *bm = &zio->io_bookmark;\n\t \n\tint allocator = (uint_t)cityhash4(bm->zb_objset, bm->zb_object,\n\t    bm->zb_level, bm->zb_blkid >> 20) % spa->spa_alloc_count;\n\tzio->io_allocator = allocator;\n\tzio->io_metaslab_class = mc;\n\tmutex_enter(&spa->spa_allocs[allocator].spaa_lock);\n\tavl_add(&spa->spa_allocs[allocator].spaa_tree, zio);\n\tnio = zio_io_to_allocate(spa, allocator);\n\tmutex_exit(&spa->spa_allocs[allocator].spaa_lock);\n\treturn (nio);\n}\n\nstatic void\nzio_allocate_dispatch(spa_t *spa, int allocator)\n{\n\tzio_t *zio;\n\n\tmutex_enter(&spa->spa_allocs[allocator].spaa_lock);\n\tzio = zio_io_to_allocate(spa, allocator);\n\tmutex_exit(&spa->spa_allocs[allocator].spaa_lock);\n\tif (zio == NULL)\n\t\treturn;\n\n\tASSERT3U(zio->io_stage, ==, ZIO_STAGE_DVA_THROTTLE);\n\tASSERT0(zio->io_error);\n\tzio_taskq_dispatch(zio, ZIO_TASKQ_ISSUE, B_TRUE);\n}\n\nstatic zio_t *\nzio_dva_allocate(zio_t *zio)\n{\n\tspa_t *spa = zio->io_spa;\n\tmetaslab_class_t *mc;\n\tblkptr_t *bp = zio->io_bp;\n\tint error;\n\tint flags = 0;\n\n\tif (zio->io_gang_leader == NULL) {\n\t\tASSERT(zio->io_child_type > ZIO_CHILD_GANG);\n\t\tzio->io_gang_leader = zio;\n\t}\n\n\tASSERT(BP_IS_HOLE(bp));\n\tASSERT0(BP_GET_NDVAS(bp));\n\tASSERT3U(zio->io_prop.zp_copies, >, 0);\n\tASSERT3U(zio->io_prop.zp_copies, <=, spa_max_replication(spa));\n\tASSERT3U(zio->io_size, ==, BP_GET_PSIZE(bp));\n\n\tif (zio->io_flags & ZIO_FLAG_NODATA)\n\t\tflags |= METASLAB_DONT_THROTTLE;\n\tif (zio->io_flags & ZIO_FLAG_GANG_CHILD)\n\t\tflags |= METASLAB_GANG_CHILD;\n\tif (zio->io_priority == ZIO_PRIORITY_ASYNC_WRITE)\n\t\tflags |= METASLAB_ASYNC_ALLOC;\n\n\t \n\tmc = zio->io_metaslab_class;\n\tif (mc == NULL) {\n\t\tmc = spa_preferred_class(spa, zio->io_size,\n\t\t    zio->io_prop.zp_type, zio->io_prop.zp_level,\n\t\t    zio->io_prop.zp_zpl_smallblk);\n\t\tzio->io_metaslab_class = mc;\n\t}\n\n\t \n\terror = metaslab_alloc(spa, mc, zio->io_size, bp,\n\t    zio->io_prop.zp_copies, zio->io_txg, NULL, flags,\n\t    &zio->io_alloc_list, zio, zio->io_allocator);\n\n\t \n\tif (error == ENOSPC && mc != spa_normal_class(spa)) {\n\t\t \n\t\tif (mc->mc_alloc_throttle_enabled &&\n\t\t    (zio->io_flags & ZIO_FLAG_IO_ALLOCATING)) {\n\t\t\tmetaslab_class_throttle_unreserve(mc,\n\t\t\t    zio->io_prop.zp_copies, zio->io_allocator, zio);\n\t\t\tzio->io_flags &= ~ZIO_FLAG_IO_ALLOCATING;\n\n\t\t\tVERIFY(metaslab_class_throttle_reserve(\n\t\t\t    spa_normal_class(spa),\n\t\t\t    zio->io_prop.zp_copies, zio->io_allocator, zio,\n\t\t\t    flags | METASLAB_MUST_RESERVE));\n\t\t}\n\t\tzio->io_metaslab_class = mc = spa_normal_class(spa);\n\t\tif (zfs_flags & ZFS_DEBUG_METASLAB_ALLOC) {\n\t\t\tzfs_dbgmsg(\"%s: metaslab allocation failure, \"\n\t\t\t    \"trying normal class: zio %px, size %llu, error %d\",\n\t\t\t    spa_name(spa), zio, (u_longlong_t)zio->io_size,\n\t\t\t    error);\n\t\t}\n\n\t\terror = metaslab_alloc(spa, mc, zio->io_size, bp,\n\t\t    zio->io_prop.zp_copies, zio->io_txg, NULL, flags,\n\t\t    &zio->io_alloc_list, zio, zio->io_allocator);\n\t}\n\n\tif (error == ENOSPC && zio->io_size > SPA_MINBLOCKSIZE) {\n\t\tif (zfs_flags & ZFS_DEBUG_METASLAB_ALLOC) {\n\t\t\tzfs_dbgmsg(\"%s: metaslab allocation failure, \"\n\t\t\t    \"trying ganging: zio %px, size %llu, error %d\",\n\t\t\t    spa_name(spa), zio, (u_longlong_t)zio->io_size,\n\t\t\t    error);\n\t\t}\n\t\treturn (zio_write_gang_block(zio, mc));\n\t}\n\tif (error != 0) {\n\t\tif (error != ENOSPC ||\n\t\t    (zfs_flags & ZFS_DEBUG_METASLAB_ALLOC)) {\n\t\t\tzfs_dbgmsg(\"%s: metaslab allocation failure: zio %px, \"\n\t\t\t    \"size %llu, error %d\",\n\t\t\t    spa_name(spa), zio, (u_longlong_t)zio->io_size,\n\t\t\t    error);\n\t\t}\n\t\tzio->io_error = error;\n\t}\n\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_dva_free(zio_t *zio)\n{\n\tmetaslab_free(zio->io_spa, zio->io_bp, zio->io_txg, B_FALSE);\n\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_dva_claim(zio_t *zio)\n{\n\tint error;\n\n\terror = metaslab_claim(zio->io_spa, zio->io_bp, zio->io_txg);\n\tif (error)\n\t\tzio->io_error = error;\n\n\treturn (zio);\n}\n\n \nstatic void\nzio_dva_unallocate(zio_t *zio, zio_gang_node_t *gn, blkptr_t *bp)\n{\n\tASSERT(bp->blk_birth == zio->io_txg || BP_IS_HOLE(bp));\n\tASSERT(zio->io_bp_override == NULL);\n\n\tif (!BP_IS_HOLE(bp))\n\t\tmetaslab_free(zio->io_spa, bp, bp->blk_birth, B_TRUE);\n\n\tif (gn != NULL) {\n\t\tfor (int g = 0; g < SPA_GBH_NBLKPTRS; g++) {\n\t\t\tzio_dva_unallocate(zio, gn->gn_child[g],\n\t\t\t    &gn->gn_gbh->zg_blkptr[g]);\n\t\t}\n\t}\n}\n\n \nint\nzio_alloc_zil(spa_t *spa, objset_t *os, uint64_t txg, blkptr_t *new_bp,\n    uint64_t size, boolean_t *slog)\n{\n\tint error = 1;\n\tzio_alloc_list_t io_alloc_list;\n\n\tASSERT(txg > spa_syncing_txg(spa));\n\n\tmetaslab_trace_init(&io_alloc_list);\n\n\t \n\tBP_SET_TYPE(new_bp, DMU_OT_INTENT_LOG);\n\tBP_SET_PSIZE(new_bp, size);\n\tBP_SET_LEVEL(new_bp, 0);\n\n\t \n\tint flags = METASLAB_ZIL;\n\tint allocator = (uint_t)cityhash4(0, 0, 0,\n\t    os->os_dsl_dataset->ds_object) % spa->spa_alloc_count;\n\terror = metaslab_alloc(spa, spa_log_class(spa), size, new_bp, 1,\n\t    txg, NULL, flags, &io_alloc_list, NULL, allocator);\n\t*slog = (error == 0);\n\tif (error != 0) {\n\t\terror = metaslab_alloc(spa, spa_embedded_log_class(spa), size,\n\t\t    new_bp, 1, txg, NULL, flags,\n\t\t    &io_alloc_list, NULL, allocator);\n\t}\n\tif (error != 0) {\n\t\terror = metaslab_alloc(spa, spa_normal_class(spa), size,\n\t\t    new_bp, 1, txg, NULL, flags,\n\t\t    &io_alloc_list, NULL, allocator);\n\t}\n\tmetaslab_trace_fini(&io_alloc_list);\n\n\tif (error == 0) {\n\t\tBP_SET_LSIZE(new_bp, size);\n\t\tBP_SET_PSIZE(new_bp, size);\n\t\tBP_SET_COMPRESS(new_bp, ZIO_COMPRESS_OFF);\n\t\tBP_SET_CHECKSUM(new_bp,\n\t\t    spa_version(spa) >= SPA_VERSION_SLIM_ZIL\n\t\t    ? ZIO_CHECKSUM_ZILOG2 : ZIO_CHECKSUM_ZILOG);\n\t\tBP_SET_TYPE(new_bp, DMU_OT_INTENT_LOG);\n\t\tBP_SET_LEVEL(new_bp, 0);\n\t\tBP_SET_DEDUP(new_bp, 0);\n\t\tBP_SET_BYTEORDER(new_bp, ZFS_HOST_BYTEORDER);\n\n\t\t \n\t\tif (os->os_encrypted) {\n\t\t\tuint8_t iv[ZIO_DATA_IV_LEN];\n\t\t\tuint8_t salt[ZIO_DATA_SALT_LEN];\n\n\t\t\tBP_SET_CRYPT(new_bp, B_TRUE);\n\t\t\tVERIFY0(spa_crypt_get_salt(spa,\n\t\t\t    dmu_objset_id(os), salt));\n\t\t\tVERIFY0(zio_crypt_generate_iv(iv));\n\n\t\t\tzio_crypt_encode_params_bp(new_bp, salt, iv);\n\t\t}\n\t} else {\n\t\tzfs_dbgmsg(\"%s: zil block allocation failure: \"\n\t\t    \"size %llu, error %d\", spa_name(spa), (u_longlong_t)size,\n\t\t    error);\n\t}\n\n\treturn (error);\n}\n\n \n\n \nstatic zio_t *\nzio_vdev_io_start(zio_t *zio)\n{\n\tvdev_t *vd = zio->io_vd;\n\tuint64_t align;\n\tspa_t *spa = zio->io_spa;\n\n\tzio->io_delay = 0;\n\n\tASSERT(zio->io_error == 0);\n\tASSERT(zio->io_child_error[ZIO_CHILD_VDEV] == 0);\n\n\tif (vd == NULL) {\n\t\tif (!(zio->io_flags & ZIO_FLAG_CONFIG_WRITER))\n\t\t\tspa_config_enter(spa, SCL_ZIO, zio, RW_READER);\n\n\t\t \n\t\tvdev_mirror_ops.vdev_op_io_start(zio);\n\t\treturn (NULL);\n\t}\n\n\tASSERT3P(zio->io_logical, !=, zio);\n\tif (zio->io_type == ZIO_TYPE_WRITE) {\n\t\tASSERT(spa->spa_trust_config);\n\n\t\t \n\t\tif (zio->io_vd->vdev_noalloc) {\n\t\t\tASSERT(zio->io_flags &\n\t\t\t    (ZIO_FLAG_PHYSICAL | ZIO_FLAG_SELF_HEAL |\n\t\t\t    ZIO_FLAG_RESILVER | ZIO_FLAG_INDUCE_DAMAGE));\n\t\t}\n\t}\n\n\talign = 1ULL << vd->vdev_top->vdev_ashift;\n\n\tif (!(zio->io_flags & ZIO_FLAG_PHYSICAL) &&\n\t    P2PHASE(zio->io_size, align) != 0) {\n\t\t \n\t\tuint64_t asize = P2ROUNDUP(zio->io_size, align);\n\t\tabd_t *abuf = abd_alloc_sametype(zio->io_abd, asize);\n\t\tASSERT(vd == vd->vdev_top);\n\t\tif (zio->io_type == ZIO_TYPE_WRITE) {\n\t\t\tabd_copy(abuf, zio->io_abd, zio->io_size);\n\t\t\tabd_zero_off(abuf, zio->io_size, asize - zio->io_size);\n\t\t}\n\t\tzio_push_transform(zio, abuf, asize, asize, zio_subblock);\n\t}\n\n\t \n\tif (!(zio->io_flags & ZIO_FLAG_PHYSICAL)) {\n\t\tASSERT0(P2PHASE(zio->io_offset, align));\n\t\tASSERT0(P2PHASE(zio->io_size, align));\n\t} else {\n\t\t \n\t\tASSERT0(P2PHASE(zio->io_offset, SPA_MINBLOCKSIZE));\n\t\tASSERT0(P2PHASE(zio->io_size, SPA_MINBLOCKSIZE));\n\t}\n\n\tVERIFY(zio->io_type != ZIO_TYPE_WRITE || spa_writeable(spa));\n\n\t \n\tif ((zio->io_flags & ZIO_FLAG_IO_REPAIR) &&\n\t    !(zio->io_flags & ZIO_FLAG_SELF_HEAL) &&\n\t    zio->io_txg != 0 &&\t \n\t    vd->vdev_ops != &vdev_indirect_ops &&\n\t    vd->vdev_top->vdev_ops != &vdev_draid_ops &&\n\t    !vdev_dtl_contains(vd, DTL_PARTIAL, zio->io_txg, 1)) {\n\t\tASSERT(zio->io_type == ZIO_TYPE_WRITE);\n\t\tzio_vdev_io_bypass(zio);\n\t\treturn (zio);\n\t}\n\n\t \n\tif (vd->vdev_ops->vdev_op_leaf &&\n\t    vd->vdev_ops != &vdev_draid_spare_ops &&\n\t    (zio->io_type == ZIO_TYPE_READ ||\n\t    zio->io_type == ZIO_TYPE_WRITE ||\n\t    zio->io_type == ZIO_TYPE_TRIM)) {\n\n\t\tif ((zio = vdev_queue_io(zio)) == NULL)\n\t\t\treturn (NULL);\n\n\t\tif (!vdev_accessible(vd, zio)) {\n\t\t\tzio->io_error = SET_ERROR(ENXIO);\n\t\t\tzio_interrupt(zio);\n\t\t\treturn (NULL);\n\t\t}\n\t\tzio->io_delay = gethrtime();\n\t}\n\n\tvd->vdev_ops->vdev_op_io_start(zio);\n\treturn (NULL);\n}\n\nstatic zio_t *\nzio_vdev_io_done(zio_t *zio)\n{\n\tvdev_t *vd = zio->io_vd;\n\tvdev_ops_t *ops = vd ? vd->vdev_ops : &vdev_mirror_ops;\n\tboolean_t unexpected_error = B_FALSE;\n\n\tif (zio_wait_for_children(zio, ZIO_CHILD_VDEV_BIT, ZIO_WAIT_DONE)) {\n\t\treturn (NULL);\n\t}\n\n\tASSERT(zio->io_type == ZIO_TYPE_READ ||\n\t    zio->io_type == ZIO_TYPE_WRITE || zio->io_type == ZIO_TYPE_TRIM);\n\n\tif (zio->io_delay)\n\t\tzio->io_delay = gethrtime() - zio->io_delay;\n\n\tif (vd != NULL && vd->vdev_ops->vdev_op_leaf &&\n\t    vd->vdev_ops != &vdev_draid_spare_ops) {\n\t\tvdev_queue_io_done(zio);\n\n\t\tif (zio_injection_enabled && zio->io_error == 0)\n\t\t\tzio->io_error = zio_handle_device_injections(vd, zio,\n\t\t\t    EIO, EILSEQ);\n\n\t\tif (zio_injection_enabled && zio->io_error == 0)\n\t\t\tzio->io_error = zio_handle_label_injection(zio, EIO);\n\n\t\tif (zio->io_error && zio->io_type != ZIO_TYPE_TRIM) {\n\t\t\tif (!vdev_accessible(vd, zio)) {\n\t\t\t\tzio->io_error = SET_ERROR(ENXIO);\n\t\t\t} else {\n\t\t\t\tunexpected_error = B_TRUE;\n\t\t\t}\n\t\t}\n\t}\n\n\tops->vdev_op_io_done(zio);\n\n\tif (unexpected_error && vd->vdev_remove_wanted == B_FALSE)\n\t\tVERIFY(vdev_probe(vd, zio) == NULL);\n\n\treturn (zio);\n}\n\n \nvoid\nzio_change_priority(zio_t *pio, zio_priority_t priority)\n{\n\tzio_t *cio, *cio_next;\n\tzio_link_t *zl = NULL;\n\n\tASSERT3U(priority, <, ZIO_PRIORITY_NUM_QUEUEABLE);\n\n\tif (pio->io_vd != NULL && pio->io_vd->vdev_ops->vdev_op_leaf) {\n\t\tvdev_queue_change_io_priority(pio, priority);\n\t} else {\n\t\tpio->io_priority = priority;\n\t}\n\n\tmutex_enter(&pio->io_lock);\n\tfor (cio = zio_walk_children(pio, &zl); cio != NULL; cio = cio_next) {\n\t\tcio_next = zio_walk_children(pio, &zl);\n\t\tzio_change_priority(cio, priority);\n\t}\n\tmutex_exit(&pio->io_lock);\n}\n\n \nstatic void\nzio_vsd_default_cksum_finish(zio_cksum_report_t *zcr,\n    const abd_t *good_buf)\n{\n\t \n\tzfs_ereport_finish_checksum(zcr, good_buf, zcr->zcr_cbdata, B_FALSE);\n}\n\nvoid\nzio_vsd_default_cksum_report(zio_t *zio, zio_cksum_report_t *zcr)\n{\n\tvoid *abd = abd_alloc_sametype(zio->io_abd, zio->io_size);\n\n\tabd_copy(abd, zio->io_abd, zio->io_size);\n\n\tzcr->zcr_cbinfo = zio->io_size;\n\tzcr->zcr_cbdata = abd;\n\tzcr->zcr_finish = zio_vsd_default_cksum_finish;\n\tzcr->zcr_free = zio_abd_free;\n}\n\nstatic zio_t *\nzio_vdev_io_assess(zio_t *zio)\n{\n\tvdev_t *vd = zio->io_vd;\n\n\tif (zio_wait_for_children(zio, ZIO_CHILD_VDEV_BIT, ZIO_WAIT_DONE)) {\n\t\treturn (NULL);\n\t}\n\n\tif (vd == NULL && !(zio->io_flags & ZIO_FLAG_CONFIG_WRITER))\n\t\tspa_config_exit(zio->io_spa, SCL_ZIO, zio);\n\n\tif (zio->io_vsd != NULL) {\n\t\tzio->io_vsd_ops->vsd_free(zio);\n\t\tzio->io_vsd = NULL;\n\t}\n\n\tif (zio_injection_enabled && zio->io_error == 0)\n\t\tzio->io_error = zio_handle_fault_injection(zio, EIO);\n\n\t \n\tif (zio->io_error && vd == NULL &&\n\t    !(zio->io_flags & (ZIO_FLAG_DONT_RETRY | ZIO_FLAG_IO_RETRY))) {\n\t\tASSERT(!(zio->io_flags & ZIO_FLAG_DONT_QUEUE));\t \n\t\tASSERT(!(zio->io_flags & ZIO_FLAG_IO_BYPASS));\t \n\t\tzio->io_error = 0;\n\t\tzio->io_flags |= ZIO_FLAG_IO_RETRY | ZIO_FLAG_DONT_AGGREGATE;\n\t\tzio->io_stage = ZIO_STAGE_VDEV_IO_START >> 1;\n\t\tzio_taskq_dispatch(zio, ZIO_TASKQ_ISSUE,\n\t\t    zio_requeue_io_start_cut_in_line);\n\t\treturn (NULL);\n\t}\n\n\t \n\tif (zio->io_error && vd != NULL && vd->vdev_ops->vdev_op_leaf &&\n\t    !vdev_accessible(vd, zio))\n\t\tzio->io_error = SET_ERROR(ENXIO);\n\n\t \n\tif (zio->io_error == ENXIO && zio->io_type == ZIO_TYPE_WRITE &&\n\t    vd != NULL && !vd->vdev_ops->vdev_op_leaf) {\n\t\tvdev_dbgmsg(vd, \"zio_vdev_io_assess(zio=%px) setting \"\n\t\t    \"cant_write=TRUE due to write failure with ENXIO\",\n\t\t    zio);\n\t\tvd->vdev_cant_write = B_TRUE;\n\t}\n\n\t \n\tif ((zio->io_error == ENOTSUP || zio->io_error == ENOTTY) &&\n\t    zio->io_type == ZIO_TYPE_IOCTL &&\n\t    zio->io_cmd == DKIOCFLUSHWRITECACHE && vd != NULL)\n\t\tvd->vdev_nowritecache = B_TRUE;\n\n\tif (zio->io_error)\n\t\tzio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\n\treturn (zio);\n}\n\nvoid\nzio_vdev_io_reissue(zio_t *zio)\n{\n\tASSERT(zio->io_stage == ZIO_STAGE_VDEV_IO_START);\n\tASSERT(zio->io_error == 0);\n\n\tzio->io_stage >>= 1;\n}\n\nvoid\nzio_vdev_io_redone(zio_t *zio)\n{\n\tASSERT(zio->io_stage == ZIO_STAGE_VDEV_IO_DONE);\n\n\tzio->io_stage >>= 1;\n}\n\nvoid\nzio_vdev_io_bypass(zio_t *zio)\n{\n\tASSERT(zio->io_stage == ZIO_STAGE_VDEV_IO_START);\n\tASSERT(zio->io_error == 0);\n\n\tzio->io_flags |= ZIO_FLAG_IO_BYPASS;\n\tzio->io_stage = ZIO_STAGE_VDEV_IO_ASSESS >> 1;\n}\n\n \n\n\n \nstatic zio_t *\nzio_encrypt(zio_t *zio)\n{\n\tzio_prop_t *zp = &zio->io_prop;\n\tspa_t *spa = zio->io_spa;\n\tblkptr_t *bp = zio->io_bp;\n\tuint64_t psize = BP_GET_PSIZE(bp);\n\tuint64_t dsobj = zio->io_bookmark.zb_objset;\n\tdmu_object_type_t ot = BP_GET_TYPE(bp);\n\tvoid *enc_buf = NULL;\n\tabd_t *eabd = NULL;\n\tuint8_t salt[ZIO_DATA_SALT_LEN];\n\tuint8_t iv[ZIO_DATA_IV_LEN];\n\tuint8_t mac[ZIO_DATA_MAC_LEN];\n\tboolean_t no_crypt = B_FALSE;\n\n\t \n\tif (zio->io_child_type == ZIO_CHILD_GANG)\n\t\treturn (zio);\n\n\t \n\tif (!IO_IS_ALLOCATING(zio) && ot != DMU_OT_INTENT_LOG)\n\t\treturn (zio);\n\n\tif (!(zp->zp_encrypt || BP_IS_ENCRYPTED(bp))) {\n\t\tBP_SET_CRYPT(bp, B_FALSE);\n\t\treturn (zio);\n\t}\n\n\t \n\tif (zio->io_flags & ZIO_FLAG_RAW_ENCRYPT) {\n\t\tASSERT0(BP_GET_LEVEL(bp));\n\t\tBP_SET_CRYPT(bp, B_TRUE);\n\t\tBP_SET_BYTEORDER(bp, zp->zp_byteorder);\n\t\tif (ot != DMU_OT_OBJSET)\n\t\t\tzio_crypt_encode_mac_bp(bp, zp->zp_mac);\n\n\t\t \n\t\tif (zp->zp_byteorder != ZFS_HOST_BYTEORDER &&\n\t\t    ot == DMU_OT_DNODE) {\n\t\t\tvoid *bswap_buf = zio_buf_alloc(psize);\n\t\t\tabd_t *babd = abd_get_from_buf(bswap_buf, psize);\n\n\t\t\tASSERT3U(BP_GET_COMPRESS(bp), ==, ZIO_COMPRESS_OFF);\n\t\t\tabd_copy_to_buf(bswap_buf, zio->io_abd, psize);\n\t\t\tdmu_ot_byteswap[DMU_OT_BYTESWAP(ot)].ob_func(bswap_buf,\n\t\t\t    psize);\n\n\t\t\tabd_take_ownership_of_buf(babd, B_TRUE);\n\t\t\tzio_push_transform(zio, babd, psize, psize, NULL);\n\t\t}\n\n\t\tif (DMU_OT_IS_ENCRYPTED(ot))\n\t\t\tzio_crypt_encode_params_bp(bp, zp->zp_salt, zp->zp_iv);\n\t\treturn (zio);\n\t}\n\n\t \n\tif (BP_GET_LEVEL(bp) > 0) {\n\t\tBP_SET_CRYPT(bp, B_TRUE);\n\t\tVERIFY0(zio_crypt_do_indirect_mac_checksum_abd(B_TRUE,\n\t\t    zio->io_orig_abd, BP_GET_LSIZE(bp), BP_SHOULD_BYTESWAP(bp),\n\t\t    mac));\n\t\tzio_crypt_encode_mac_bp(bp, mac);\n\t\treturn (zio);\n\t}\n\n\t \n\tif (ot == DMU_OT_OBJSET) {\n\t\tASSERT0(DMU_OT_IS_ENCRYPTED(ot));\n\t\tASSERT3U(BP_GET_COMPRESS(bp), ==, ZIO_COMPRESS_OFF);\n\t\tBP_SET_CRYPT(bp, B_TRUE);\n\t\tVERIFY0(spa_do_crypt_objset_mac_abd(B_TRUE, spa, dsobj,\n\t\t    zio->io_abd, psize, BP_SHOULD_BYTESWAP(bp)));\n\t\treturn (zio);\n\t}\n\n\t \n\tif (!DMU_OT_IS_ENCRYPTED(ot)) {\n\t\tBP_SET_CRYPT(bp, B_TRUE);\n\t\tVERIFY0(spa_do_crypt_mac_abd(B_TRUE, spa, dsobj,\n\t\t    zio->io_abd, psize, mac));\n\t\tzio_crypt_encode_mac_bp(bp, mac);\n\t\treturn (zio);\n\t}\n\n\t \n\tASSERT(IO_IS_ALLOCATING(zio) || ot == DMU_OT_INTENT_LOG);\n\tASSERT(BP_GET_LEVEL(bp) == 0 || ot == DMU_OT_INTENT_LOG);\n\tASSERT(spa_feature_is_active(spa, SPA_FEATURE_ENCRYPTION));\n\tASSERT3U(psize, !=, 0);\n\n\tenc_buf = zio_buf_alloc(psize);\n\teabd = abd_get_from_buf(enc_buf, psize);\n\tabd_take_ownership_of_buf(eabd, B_TRUE);\n\n\t \n\tif (ot == DMU_OT_INTENT_LOG) {\n\t\tzio_crypt_decode_params_bp(bp, salt, iv);\n\t} else {\n\t\tBP_SET_CRYPT(bp, B_TRUE);\n\t}\n\n\t \n\tVERIFY0(spa_do_crypt_abd(B_TRUE, spa, &zio->io_bookmark,\n\t    BP_GET_TYPE(bp), BP_GET_DEDUP(bp), BP_SHOULD_BYTESWAP(bp),\n\t    salt, iv, mac, psize, zio->io_abd, eabd, &no_crypt));\n\n\t \n\tif (ot == DMU_OT_INTENT_LOG) {\n\t\t \n\t\tzio_crypt_encode_mac_zil(enc_buf, mac);\n\t\tzio_push_transform(zio, eabd, psize, psize, NULL);\n\t} else {\n\t\tBP_SET_CRYPT(bp, B_TRUE);\n\t\tzio_crypt_encode_params_bp(bp, salt, iv);\n\t\tzio_crypt_encode_mac_bp(bp, mac);\n\n\t\tif (no_crypt) {\n\t\t\tASSERT3U(ot, ==, DMU_OT_DNODE);\n\t\t\tabd_free(eabd);\n\t\t} else {\n\t\t\tzio_push_transform(zio, eabd, psize, psize, NULL);\n\t\t}\n\t}\n\n\treturn (zio);\n}\n\n \nstatic zio_t *\nzio_checksum_generate(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\tenum zio_checksum checksum;\n\n\tif (bp == NULL) {\n\t\t \n\t\tchecksum = zio->io_prop.zp_checksum;\n\n\t\tif (checksum == ZIO_CHECKSUM_OFF)\n\t\t\treturn (zio);\n\n\t\tASSERT(checksum == ZIO_CHECKSUM_LABEL);\n\t} else {\n\t\tif (BP_IS_GANG(bp) && zio->io_child_type == ZIO_CHILD_GANG) {\n\t\t\tASSERT(!IO_IS_ALLOCATING(zio));\n\t\t\tchecksum = ZIO_CHECKSUM_GANG_HEADER;\n\t\t} else {\n\t\t\tchecksum = BP_GET_CHECKSUM(bp);\n\t\t}\n\t}\n\n\tzio_checksum_compute(zio, checksum, zio->io_abd, zio->io_size);\n\n\treturn (zio);\n}\n\nstatic zio_t *\nzio_checksum_verify(zio_t *zio)\n{\n\tzio_bad_cksum_t info;\n\tblkptr_t *bp = zio->io_bp;\n\tint error;\n\n\tASSERT(zio->io_vd != NULL);\n\n\tif (bp == NULL) {\n\t\t \n\t\tif (zio->io_prop.zp_checksum == ZIO_CHECKSUM_OFF)\n\t\t\treturn (zio);\n\n\t\tASSERT3U(zio->io_prop.zp_checksum, ==, ZIO_CHECKSUM_LABEL);\n\t}\n\n\tif ((error = zio_checksum_error(zio, &info)) != 0) {\n\t\tzio->io_error = error;\n\t\tif (error == ECKSUM &&\n\t\t    !(zio->io_flags & ZIO_FLAG_SPECULATIVE)) {\n\t\t\tmutex_enter(&zio->io_vd->vdev_stat_lock);\n\t\t\tzio->io_vd->vdev_stat.vs_checksum_errors++;\n\t\t\tmutex_exit(&zio->io_vd->vdev_stat_lock);\n\t\t\t(void) zfs_ereport_start_checksum(zio->io_spa,\n\t\t\t    zio->io_vd, &zio->io_bookmark, zio,\n\t\t\t    zio->io_offset, zio->io_size, &info);\n\t\t}\n\t}\n\n\treturn (zio);\n}\n\n \nvoid\nzio_checksum_verified(zio_t *zio)\n{\n\tzio->io_pipeline &= ~ZIO_STAGE_CHECKSUM_VERIFY;\n}\n\n \nint\nzio_worst_error(int e1, int e2)\n{\n\tstatic int zio_error_rank[] = { 0, ENXIO, ECKSUM, EIO };\n\tint r1, r2;\n\n\tfor (r1 = 0; r1 < sizeof (zio_error_rank) / sizeof (int); r1++)\n\t\tif (e1 == zio_error_rank[r1])\n\t\t\tbreak;\n\n\tfor (r2 = 0; r2 < sizeof (zio_error_rank) / sizeof (int); r2++)\n\t\tif (e2 == zio_error_rank[r2])\n\t\t\tbreak;\n\n\treturn (r1 > r2 ? e1 : e2);\n}\n\n \nstatic zio_t *\nzio_ready(zio_t *zio)\n{\n\tblkptr_t *bp = zio->io_bp;\n\tzio_t *pio, *pio_next;\n\tzio_link_t *zl = NULL;\n\n\tif (zio_wait_for_children(zio, ZIO_CHILD_LOGICAL_BIT |\n\t    ZIO_CHILD_GANG_BIT | ZIO_CHILD_DDT_BIT, ZIO_WAIT_READY)) {\n\t\treturn (NULL);\n\t}\n\n\tif (zio->io_ready) {\n\t\tASSERT(IO_IS_ALLOCATING(zio));\n\t\tASSERT(bp->blk_birth == zio->io_txg || BP_IS_HOLE(bp) ||\n\t\t    (zio->io_flags & ZIO_FLAG_NOPWRITE));\n\t\tASSERT(zio->io_children[ZIO_CHILD_GANG][ZIO_WAIT_READY] == 0);\n\n\t\tzio->io_ready(zio);\n\t}\n\n#ifdef ZFS_DEBUG\n\tif (bp != NULL && bp != &zio->io_bp_copy)\n\t\tzio->io_bp_copy = *bp;\n#endif\n\n\tif (zio->io_error != 0) {\n\t\tzio->io_pipeline = ZIO_INTERLOCK_PIPELINE;\n\n\t\tif (zio->io_flags & ZIO_FLAG_IO_ALLOCATING) {\n\t\t\tASSERT(IO_IS_ALLOCATING(zio));\n\t\t\tASSERT(zio->io_priority == ZIO_PRIORITY_ASYNC_WRITE);\n\t\t\tASSERT(zio->io_metaslab_class != NULL);\n\n\t\t\t \n\t\t\tmetaslab_class_throttle_unreserve(\n\t\t\t    zio->io_metaslab_class, zio->io_prop.zp_copies,\n\t\t\t    zio->io_allocator, zio);\n\t\t\tzio_allocate_dispatch(zio->io_spa, zio->io_allocator);\n\t\t}\n\t}\n\n\tmutex_enter(&zio->io_lock);\n\tzio->io_state[ZIO_WAIT_READY] = 1;\n\tpio = zio_walk_parents(zio, &zl);\n\tmutex_exit(&zio->io_lock);\n\n\t \n\tfor (; pio != NULL; pio = pio_next) {\n\t\tpio_next = zio_walk_parents(zio, &zl);\n\t\tzio_notify_parent(pio, zio, ZIO_WAIT_READY, NULL);\n\t}\n\n\tif (zio->io_flags & ZIO_FLAG_NODATA) {\n\t\tif (bp != NULL && BP_IS_GANG(bp)) {\n\t\t\tzio->io_flags &= ~ZIO_FLAG_NODATA;\n\t\t} else {\n\t\t\tASSERT((uintptr_t)zio->io_abd < SPA_MAXBLOCKSIZE);\n\t\t\tzio->io_pipeline &= ~ZIO_VDEV_IO_STAGES;\n\t\t}\n\t}\n\n\tif (zio_injection_enabled &&\n\t    zio->io_spa->spa_syncing_txg == zio->io_txg)\n\t\tzio_handle_ignored_writes(zio);\n\n\treturn (zio);\n}\n\n \nstatic void\nzio_dva_throttle_done(zio_t *zio)\n{\n\tzio_t *lio __maybe_unused = zio->io_logical;\n\tzio_t *pio = zio_unique_parent(zio);\n\tvdev_t *vd = zio->io_vd;\n\tint flags = METASLAB_ASYNC_ALLOC;\n\n\tASSERT3P(zio->io_bp, !=, NULL);\n\tASSERT3U(zio->io_type, ==, ZIO_TYPE_WRITE);\n\tASSERT3U(zio->io_priority, ==, ZIO_PRIORITY_ASYNC_WRITE);\n\tASSERT3U(zio->io_child_type, ==, ZIO_CHILD_VDEV);\n\tASSERT(vd != NULL);\n\tASSERT3P(vd, ==, vd->vdev_top);\n\tASSERT(zio_injection_enabled || !(zio->io_flags & ZIO_FLAG_IO_RETRY));\n\tASSERT(!(zio->io_flags & ZIO_FLAG_IO_REPAIR));\n\tASSERT(zio->io_flags & ZIO_FLAG_IO_ALLOCATING);\n\tASSERT(!(lio->io_flags & ZIO_FLAG_IO_REWRITE));\n\tASSERT(!(lio->io_orig_flags & ZIO_FLAG_NODATA));\n\n\t \n\tif (pio->io_child_type == ZIO_CHILD_GANG) {\n\t\t \n\t\tif (pio->io_flags & ZIO_FLAG_IO_REWRITE)\n\t\t\tpio = zio_unique_parent(pio);\n\t\tflags |= METASLAB_GANG_CHILD;\n\t}\n\n\tASSERT(IO_IS_ALLOCATING(pio));\n\tASSERT3P(zio, !=, zio->io_logical);\n\tASSERT(zio->io_logical != NULL);\n\tASSERT(!(zio->io_flags & ZIO_FLAG_IO_REPAIR));\n\tASSERT0(zio->io_flags & ZIO_FLAG_NOPWRITE);\n\tASSERT(zio->io_metaslab_class != NULL);\n\n\tmutex_enter(&pio->io_lock);\n\tmetaslab_group_alloc_decrement(zio->io_spa, vd->vdev_id, pio, flags,\n\t    pio->io_allocator, B_TRUE);\n\tmutex_exit(&pio->io_lock);\n\n\tmetaslab_class_throttle_unreserve(zio->io_metaslab_class, 1,\n\t    pio->io_allocator, pio);\n\n\t \n\tzio_allocate_dispatch(zio->io_spa, pio->io_allocator);\n}\n\nstatic zio_t *\nzio_done(zio_t *zio)\n{\n\t \n\tconst uint64_t psize = zio->io_size;\n\tzio_t *pio, *pio_next;\n\tzio_link_t *zl = NULL;\n\n\t \n\tif (zio_wait_for_children(zio, ZIO_CHILD_ALL_BITS, ZIO_WAIT_DONE)) {\n\t\treturn (NULL);\n\t}\n\n\t \n\tif (zio->io_flags & ZIO_FLAG_IO_ALLOCATING &&\n\t    zio->io_child_type == ZIO_CHILD_VDEV) {\n\t\tASSERT(zio->io_metaslab_class != NULL);\n\t\tASSERT(zio->io_metaslab_class->mc_alloc_throttle_enabled);\n\t\tzio_dva_throttle_done(zio);\n\t}\n\n\t \n\tif (zio->io_flags & ZIO_FLAG_IO_ALLOCATING) {\n\t\tASSERT(zio->io_type == ZIO_TYPE_WRITE);\n\t\tASSERT(zio->io_priority == ZIO_PRIORITY_ASYNC_WRITE);\n\t\tASSERT(zio->io_bp != NULL);\n\n\t\tmetaslab_group_alloc_verify(zio->io_spa, zio->io_bp, zio,\n\t\t    zio->io_allocator);\n\t\tVERIFY(zfs_refcount_not_held(&zio->io_metaslab_class->\n\t\t    mc_allocator[zio->io_allocator].mca_alloc_slots, zio));\n\t}\n\n\n\tfor (int c = 0; c < ZIO_CHILD_TYPES; c++)\n\t\tfor (int w = 0; w < ZIO_WAIT_TYPES; w++)\n\t\t\tASSERT(zio->io_children[c][w] == 0);\n\n\tif (zio->io_bp != NULL && !BP_IS_EMBEDDED(zio->io_bp)) {\n\t\tASSERT(zio->io_bp->blk_pad[0] == 0);\n\t\tASSERT(zio->io_bp->blk_pad[1] == 0);\n\t\tASSERT(memcmp(zio->io_bp, &zio->io_bp_copy,\n\t\t    sizeof (blkptr_t)) == 0 ||\n\t\t    (zio->io_bp == zio_unique_parent(zio)->io_bp));\n\t\tif (zio->io_type == ZIO_TYPE_WRITE && !BP_IS_HOLE(zio->io_bp) &&\n\t\t    zio->io_bp_override == NULL &&\n\t\t    !(zio->io_flags & ZIO_FLAG_IO_REPAIR)) {\n\t\t\tASSERT3U(zio->io_prop.zp_copies, <=,\n\t\t\t    BP_GET_NDVAS(zio->io_bp));\n\t\t\tASSERT(BP_COUNT_GANG(zio->io_bp) == 0 ||\n\t\t\t    (BP_COUNT_GANG(zio->io_bp) ==\n\t\t\t    BP_GET_NDVAS(zio->io_bp)));\n\t\t}\n\t\tif (zio->io_flags & ZIO_FLAG_NOPWRITE)\n\t\t\tVERIFY(BP_EQUAL(zio->io_bp, &zio->io_bp_orig));\n\t}\n\n\t \n\tzio_inherit_child_errors(zio, ZIO_CHILD_VDEV);\n\tzio_inherit_child_errors(zio, ZIO_CHILD_GANG);\n\tzio_inherit_child_errors(zio, ZIO_CHILD_DDT);\n\n\t \n\tif (zio->io_error == 0) {\n\t\twhile (zio->io_cksum_report != NULL) {\n\t\t\tzio_cksum_report_t *zcr = zio->io_cksum_report;\n\t\t\tuint64_t align = zcr->zcr_align;\n\t\t\tuint64_t asize = P2ROUNDUP(psize, align);\n\t\t\tabd_t *adata = zio->io_abd;\n\n\t\t\tif (adata != NULL && asize != psize) {\n\t\t\t\tadata = abd_alloc(asize, B_TRUE);\n\t\t\t\tabd_copy(adata, zio->io_abd, psize);\n\t\t\t\tabd_zero_off(adata, psize, asize - psize);\n\t\t\t}\n\n\t\t\tzio->io_cksum_report = zcr->zcr_next;\n\t\t\tzcr->zcr_next = NULL;\n\t\t\tzcr->zcr_finish(zcr, adata);\n\t\t\tzfs_ereport_free_checksum(zcr);\n\n\t\t\tif (adata != NULL && asize != psize)\n\t\t\t\tabd_free(adata);\n\t\t}\n\t}\n\n\tzio_pop_transforms(zio);\t \n\n\tvdev_stat_update(zio, psize);\n\n\t \n\tif (zio->io_delay >= MSEC2NSEC(zio_slow_io_ms)) {\n\t\tif (zio->io_vd != NULL && !vdev_is_dead(zio->io_vd)) {\n\t\t\t \n\t\t\tif (zfs_ereport_is_valid(FM_EREPORT_ZFS_DELAY,\n\t\t\t    zio->io_spa, zio->io_vd, zio)) {\n\t\t\t\tmutex_enter(&zio->io_vd->vdev_stat_lock);\n\t\t\t\tzio->io_vd->vdev_stat.vs_slow_ios++;\n\t\t\t\tmutex_exit(&zio->io_vd->vdev_stat_lock);\n\n\t\t\t\t(void) zfs_ereport_post(FM_EREPORT_ZFS_DELAY,\n\t\t\t\t    zio->io_spa, zio->io_vd, &zio->io_bookmark,\n\t\t\t\t    zio, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (zio->io_error) {\n\t\t \n\t\tif (zio->io_error != ECKSUM && zio->io_vd != NULL &&\n\t\t    !vdev_is_dead(zio->io_vd)) {\n\t\t\tint ret = zfs_ereport_post(FM_EREPORT_ZFS_IO,\n\t\t\t    zio->io_spa, zio->io_vd, &zio->io_bookmark, zio, 0);\n\t\t\tif (ret != EALREADY) {\n\t\t\t\tmutex_enter(&zio->io_vd->vdev_stat_lock);\n\t\t\t\tif (zio->io_type == ZIO_TYPE_READ)\n\t\t\t\t\tzio->io_vd->vdev_stat.vs_read_errors++;\n\t\t\t\telse if (zio->io_type == ZIO_TYPE_WRITE)\n\t\t\t\t\tzio->io_vd->vdev_stat.vs_write_errors++;\n\t\t\t\tmutex_exit(&zio->io_vd->vdev_stat_lock);\n\t\t\t}\n\t\t}\n\n\t\tif ((zio->io_error == EIO || !(zio->io_flags &\n\t\t    (ZIO_FLAG_SPECULATIVE | ZIO_FLAG_DONT_PROPAGATE))) &&\n\t\t    zio == zio->io_logical) {\n\t\t\t \n\t\t\tspa_log_error(zio->io_spa, &zio->io_bookmark,\n\t\t\t    &zio->io_bp->blk_birth);\n\t\t\t(void) zfs_ereport_post(FM_EREPORT_ZFS_DATA,\n\t\t\t    zio->io_spa, NULL, &zio->io_bookmark, zio, 0);\n\t\t}\n\t}\n\n\tif (zio->io_error && zio == zio->io_logical) {\n\t\t \n\t\tASSERT(zio->io_vd == NULL && zio->io_bp != NULL);\n\t\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\n\t\tif (IO_IS_ALLOCATING(zio) &&\n\t\t    !(zio->io_flags & ZIO_FLAG_CANFAIL)) {\n\t\t\tif (zio->io_error != ENOSPC)\n\t\t\t\tzio->io_reexecute |= ZIO_REEXECUTE_NOW;\n\t\t\telse\n\t\t\t\tzio->io_reexecute |= ZIO_REEXECUTE_SUSPEND;\n\t\t}\n\n\t\tif ((zio->io_type == ZIO_TYPE_READ ||\n\t\t    zio->io_type == ZIO_TYPE_FREE) &&\n\t\t    !(zio->io_flags & ZIO_FLAG_SCAN_THREAD) &&\n\t\t    zio->io_error == ENXIO &&\n\t\t    spa_load_state(zio->io_spa) == SPA_LOAD_NONE &&\n\t\t    spa_get_failmode(zio->io_spa) != ZIO_FAILURE_MODE_CONTINUE)\n\t\t\tzio->io_reexecute |= ZIO_REEXECUTE_SUSPEND;\n\n\t\tif (!(zio->io_flags & ZIO_FLAG_CANFAIL) && !zio->io_reexecute)\n\t\t\tzio->io_reexecute |= ZIO_REEXECUTE_SUSPEND;\n\n\t\t \n\t}\n\n\t \n\tzio_inherit_child_errors(zio, ZIO_CHILD_LOGICAL);\n\n\tif ((zio->io_error || zio->io_reexecute) &&\n\t    IO_IS_ALLOCATING(zio) && zio->io_gang_leader == zio &&\n\t    !(zio->io_flags & (ZIO_FLAG_IO_REWRITE | ZIO_FLAG_NOPWRITE)))\n\t\tzio_dva_unallocate(zio, zio->io_gang_tree, zio->io_bp);\n\n\tzio_gang_tree_free(&zio->io_gang_tree);\n\n\t \n\tif ((zio->io_flags & ZIO_FLAG_GODFATHER) &&\n\t    (zio->io_reexecute & ZIO_REEXECUTE_SUSPEND))\n\t\tzio->io_reexecute &= ~ZIO_REEXECUTE_SUSPEND;\n\n\tif (zio->io_reexecute) {\n\t\t \n\t\tASSERT(zio->io_child_type == ZIO_CHILD_LOGICAL);\n\n\t\tzio->io_gang_leader = NULL;\n\n\t\tmutex_enter(&zio->io_lock);\n\t\tzio->io_state[ZIO_WAIT_DONE] = 1;\n\t\tmutex_exit(&zio->io_lock);\n\n\t\t \n\t\tzl = NULL;\n\t\tfor (pio = zio_walk_parents(zio, &zl); pio != NULL;\n\t\t    pio = pio_next) {\n\t\t\tzio_link_t *remove_zl = zl;\n\t\t\tpio_next = zio_walk_parents(zio, &zl);\n\n\t\t\tif ((pio->io_flags & ZIO_FLAG_GODFATHER) &&\n\t\t\t    (zio->io_reexecute & ZIO_REEXECUTE_SUSPEND)) {\n\t\t\t\tzio_remove_child(pio, zio, remove_zl);\n\t\t\t\t \n\t\t\t\tzio_notify_parent(pio, zio, ZIO_WAIT_DONE,\n\t\t\t\t    NULL);\n\t\t\t}\n\t\t}\n\n\t\tif ((pio = zio_unique_parent(zio)) != NULL) {\n\t\t\t \n\t\t\tASSERT(!(zio->io_flags & ZIO_FLAG_GODFATHER));\n\t\t\tzio->io_flags |= ZIO_FLAG_DONT_PROPAGATE;\n\t\t\t \n\t\t\tzio_notify_parent(pio, zio, ZIO_WAIT_DONE, NULL);\n\t\t} else if (zio->io_reexecute & ZIO_REEXECUTE_SUSPEND) {\n\t\t\t \n\t\t\tzio_suspend(zio->io_spa, zio, ZIO_SUSPEND_IOERR);\n\t\t} else {\n\t\t\t \n\t\t\tASSERT(taskq_empty_ent(&zio->io_tqent));\n\t\t\tspa_taskq_dispatch_ent(zio->io_spa,\n\t\t\t    ZIO_TYPE_CLAIM, ZIO_TASKQ_ISSUE,\n\t\t\t    zio_reexecute, zio, 0, &zio->io_tqent);\n\t\t}\n\t\treturn (NULL);\n\t}\n\n\tASSERT(list_is_empty(&zio->io_child_list));\n\tASSERT(zio->io_reexecute == 0);\n\tASSERT(zio->io_error == 0 || (zio->io_flags & ZIO_FLAG_CANFAIL));\n\n\t \n\twhile (zio->io_cksum_report != NULL) {\n\t\tzio_cksum_report_t *zcr = zio->io_cksum_report;\n\t\tzio->io_cksum_report = zcr->zcr_next;\n\t\tzcr->zcr_next = NULL;\n\t\tzcr->zcr_finish(zcr, NULL);\n\t\tzfs_ereport_free_checksum(zcr);\n\t}\n\n\t \n\tif (zio->io_done)\n\t\tzio->io_done(zio);\n\n\tmutex_enter(&zio->io_lock);\n\tzio->io_state[ZIO_WAIT_DONE] = 1;\n\tmutex_exit(&zio->io_lock);\n\n\t \n\tzio_t *next_to_execute = NULL;\n\tzl = NULL;\n\tfor (pio = zio_walk_parents(zio, &zl); pio != NULL; pio = pio_next) {\n\t\tzio_link_t *remove_zl = zl;\n\t\tpio_next = zio_walk_parents(zio, &zl);\n\t\tzio_remove_child(pio, zio, remove_zl);\n\t\tzio_notify_parent(pio, zio, ZIO_WAIT_DONE, &next_to_execute);\n\t}\n\n\tif (zio->io_waiter != NULL) {\n\t\tmutex_enter(&zio->io_lock);\n\t\tzio->io_executor = NULL;\n\t\tcv_broadcast(&zio->io_cv);\n\t\tmutex_exit(&zio->io_lock);\n\t} else {\n\t\tzio_destroy(zio);\n\t}\n\n\treturn (next_to_execute);\n}\n\n \nstatic zio_pipe_stage_t *zio_pipeline[] = {\n\tNULL,\n\tzio_read_bp_init,\n\tzio_write_bp_init,\n\tzio_free_bp_init,\n\tzio_issue_async,\n\tzio_write_compress,\n\tzio_encrypt,\n\tzio_checksum_generate,\n\tzio_nop_write,\n\tzio_brt_free,\n\tzio_ddt_read_start,\n\tzio_ddt_read_done,\n\tzio_ddt_write,\n\tzio_ddt_free,\n\tzio_gang_assemble,\n\tzio_gang_issue,\n\tzio_dva_throttle,\n\tzio_dva_allocate,\n\tzio_dva_free,\n\tzio_dva_claim,\n\tzio_ready,\n\tzio_vdev_io_start,\n\tzio_vdev_io_done,\n\tzio_vdev_io_assess,\n\tzio_checksum_verify,\n\tzio_done\n};\n\n\n\n\n \nint\nzbookmark_compare(uint16_t dbss1, uint8_t ibs1, uint16_t dbss2, uint8_t ibs2,\n    const zbookmark_phys_t *zb1, const zbookmark_phys_t *zb2)\n{\n\t \n\tuint64_t zb1obj, zb2obj;\n\tuint64_t zb1L0, zb2L0;\n\tuint64_t zb1level, zb2level;\n\n\tif (zb1->zb_object == zb2->zb_object &&\n\t    zb1->zb_level == zb2->zb_level &&\n\t    zb1->zb_blkid == zb2->zb_blkid)\n\t\treturn (0);\n\n\tIMPLY(zb1->zb_level > 0, ibs1 >= SPA_MINBLOCKSHIFT);\n\tIMPLY(zb2->zb_level > 0, ibs2 >= SPA_MINBLOCKSHIFT);\n\n\t \n\tzb1L0 = (zb1->zb_blkid) * BP_SPANB(ibs1, zb1->zb_level);\n\tzb2L0 = (zb2->zb_blkid) * BP_SPANB(ibs2, zb2->zb_level);\n\n\tif (zb1->zb_object == DMU_META_DNODE_OBJECT) {\n\t\tzb1obj = zb1L0 * (dbss1 << (SPA_MINBLOCKSHIFT - DNODE_SHIFT));\n\t\tzb1L0 = 0;\n\t\tzb1level = zb1->zb_level + COMPARE_META_LEVEL;\n\t} else {\n\t\tzb1obj = zb1->zb_object;\n\t\tzb1level = zb1->zb_level;\n\t}\n\n\tif (zb2->zb_object == DMU_META_DNODE_OBJECT) {\n\t\tzb2obj = zb2L0 * (dbss2 << (SPA_MINBLOCKSHIFT - DNODE_SHIFT));\n\t\tzb2L0 = 0;\n\t\tzb2level = zb2->zb_level + COMPARE_META_LEVEL;\n\t} else {\n\t\tzb2obj = zb2->zb_object;\n\t\tzb2level = zb2->zb_level;\n\t}\n\n\t \n\tif (zb1obj != zb2obj)\n\t\treturn (zb1obj < zb2obj ? -1 : 1);\n\telse if (zb1L0 != zb2L0)\n\t\treturn (zb1L0 < zb2L0 ? -1 : 1);\n\telse if (zb1level != zb2level)\n\t\treturn (zb1level > zb2level ? -1 : 1);\n\t \n\treturn (0);\n}\n\n \nboolean_t\nzbookmark_subtree_completed(const dnode_phys_t *dnp,\n    const zbookmark_phys_t *subtree_root, const zbookmark_phys_t *last_block)\n{\n\tzbookmark_phys_t mod_zb = *subtree_root;\n\tmod_zb.zb_blkid++;\n\tASSERT0(last_block->zb_level);\n\n\t \n\tif (dnp == NULL)\n\t\treturn (B_FALSE);\n\n\t \n\treturn (zbookmark_compare(dnp->dn_datablkszsec, dnp->dn_indblkshift,\n\t    1ULL << (DNODE_BLOCK_SHIFT - SPA_MINBLOCKSHIFT), 0, &mod_zb,\n\t    last_block) <= 0);\n}\n\n \nboolean_t\nzbookmark_subtree_tbd(const dnode_phys_t *dnp,\n    const zbookmark_phys_t *subtree_root, const zbookmark_phys_t *last_block)\n{\n\tASSERT0(last_block->zb_level);\n\tif (dnp == NULL)\n\t\treturn (B_FALSE);\n\treturn (zbookmark_compare(dnp->dn_datablkszsec, dnp->dn_indblkshift,\n\t    1ULL << (DNODE_BLOCK_SHIFT - SPA_MINBLOCKSHIFT), 0, subtree_root,\n\t    last_block) >= 0);\n}\n\nEXPORT_SYMBOL(zio_type_name);\nEXPORT_SYMBOL(zio_buf_alloc);\nEXPORT_SYMBOL(zio_data_buf_alloc);\nEXPORT_SYMBOL(zio_buf_free);\nEXPORT_SYMBOL(zio_data_buf_free);\n\nZFS_MODULE_PARAM(zfs_zio, zio_, slow_io_ms, INT, ZMOD_RW,\n\t\"Max I/O completion time (milliseconds) before marking it as slow\");\n\nZFS_MODULE_PARAM(zfs_zio, zio_, requeue_io_start_cut_in_line, INT, ZMOD_RW,\n\t\"Prioritize requeued I/O\");\n\nZFS_MODULE_PARAM(zfs, zfs_, sync_pass_deferred_free,  UINT, ZMOD_RW,\n\t\"Defer frees starting in this pass\");\n\nZFS_MODULE_PARAM(zfs, zfs_, sync_pass_dont_compress, UINT, ZMOD_RW,\n\t\"Don't compress starting in this pass\");\n\nZFS_MODULE_PARAM(zfs, zfs_, sync_pass_rewrite, UINT, ZMOD_RW,\n\t\"Rewrite new bps starting in this pass\");\n\nZFS_MODULE_PARAM(zfs_zio, zio_, dva_throttle_enabled, INT, ZMOD_RW,\n\t\"Throttle block allocations in the ZIO pipeline\");\n\nZFS_MODULE_PARAM(zfs_zio, zio_, deadman_log_all, INT, ZMOD_RW,\n\t\"Log all slow ZIOs, not just those with vdevs\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}