{
  "module_name": "vdev_mirror.c",
  "hash_id": "cdfe2d05a4a746cc60c37f2d0375c0538e33b6bb3cdac5f16969e63c0fcf7b12",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/vdev_mirror.c",
  "human_readable_source": " \n \n\n \n\n#include <sys/zfs_context.h>\n#include <sys/spa.h>\n#include <sys/spa_impl.h>\n#include <sys/dsl_pool.h>\n#include <sys/dsl_scan.h>\n#include <sys/vdev_impl.h>\n#include <sys/vdev_draid.h>\n#include <sys/zio.h>\n#include <sys/zio_checksum.h>\n#include <sys/abd.h>\n#include <sys/fs/zfs.h>\n\n \nstatic kstat_t *mirror_ksp = NULL;\n\ntypedef struct mirror_stats {\n\tkstat_named_t vdev_mirror_stat_rotating_linear;\n\tkstat_named_t vdev_mirror_stat_rotating_offset;\n\tkstat_named_t vdev_mirror_stat_rotating_seek;\n\tkstat_named_t vdev_mirror_stat_non_rotating_linear;\n\tkstat_named_t vdev_mirror_stat_non_rotating_seek;\n\n\tkstat_named_t vdev_mirror_stat_preferred_found;\n\tkstat_named_t vdev_mirror_stat_preferred_not_found;\n} mirror_stats_t;\n\nstatic mirror_stats_t mirror_stats = {\n\t \n\t{ \"rotating_linear\",\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"rotating_offset\",\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"rotating_seek\",\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"non_rotating_linear\",\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"non_rotating_seek\",\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"preferred_found\",\t\t\tKSTAT_DATA_UINT64 },\n\t \n\t{ \"preferred_not_found\",\t\tKSTAT_DATA_UINT64 },\n\n};\n\n#define\tMIRROR_STAT(stat)\t\t(mirror_stats.stat.value.ui64)\n#define\tMIRROR_INCR(stat, val) \t\tatomic_add_64(&MIRROR_STAT(stat), val)\n#define\tMIRROR_BUMP(stat)\t\tMIRROR_INCR(stat, 1)\n\nvoid\nvdev_mirror_stat_init(void)\n{\n\tmirror_ksp = kstat_create(\"zfs\", 0, \"vdev_mirror_stats\",\n\t    \"misc\", KSTAT_TYPE_NAMED,\n\t    sizeof (mirror_stats) / sizeof (kstat_named_t), KSTAT_FLAG_VIRTUAL);\n\tif (mirror_ksp != NULL) {\n\t\tmirror_ksp->ks_data = &mirror_stats;\n\t\tkstat_install(mirror_ksp);\n\t}\n}\n\nvoid\nvdev_mirror_stat_fini(void)\n{\n\tif (mirror_ksp != NULL) {\n\t\tkstat_delete(mirror_ksp);\n\t\tmirror_ksp = NULL;\n\t}\n}\n\n \ntypedef struct mirror_child {\n\tvdev_t\t\t*mc_vd;\n\tabd_t\t\t*mc_abd;\n\tuint64_t\tmc_offset;\n\tint\t\tmc_error;\n\tint\t\tmc_load;\n\tuint8_t\t\tmc_tried;\n\tuint8_t\t\tmc_skipped;\n\tuint8_t\t\tmc_speculative;\n\tuint8_t\t\tmc_rebuilding;\n} mirror_child_t;\n\ntypedef struct mirror_map {\n\tint\t\t*mm_preferred;\n\tint\t\tmm_preferred_cnt;\n\tint\t\tmm_children;\n\tboolean_t\tmm_resilvering;\n\tboolean_t\tmm_rebuilding;\n\tboolean_t\tmm_root;\n\tmirror_child_t\tmm_child[];\n} mirror_map_t;\n\nstatic const int vdev_mirror_shift = 21;\n\n \n\n \nstatic int zfs_vdev_mirror_rotating_inc = 0;\nstatic int zfs_vdev_mirror_rotating_seek_inc = 5;\nstatic int zfs_vdev_mirror_rotating_seek_offset = 1 * 1024 * 1024;\n\n \nstatic int zfs_vdev_mirror_non_rotating_inc = 0;\nstatic int zfs_vdev_mirror_non_rotating_seek_inc = 1;\n\nstatic inline size_t\nvdev_mirror_map_size(int children)\n{\n\treturn (offsetof(mirror_map_t, mm_child[children]) +\n\t    sizeof (int) * children);\n}\n\nstatic inline mirror_map_t *\nvdev_mirror_map_alloc(int children, boolean_t resilvering, boolean_t root)\n{\n\tmirror_map_t *mm;\n\n\tmm = kmem_zalloc(vdev_mirror_map_size(children), KM_SLEEP);\n\tmm->mm_children = children;\n\tmm->mm_resilvering = resilvering;\n\tmm->mm_root = root;\n\tmm->mm_preferred = (int *)((uintptr_t)mm +\n\t    offsetof(mirror_map_t, mm_child[children]));\n\n\treturn (mm);\n}\n\nstatic void\nvdev_mirror_map_free(zio_t *zio)\n{\n\tmirror_map_t *mm = zio->io_vsd;\n\n\tkmem_free(mm, vdev_mirror_map_size(mm->mm_children));\n}\n\nstatic const zio_vsd_ops_t vdev_mirror_vsd_ops = {\n\t.vsd_free = vdev_mirror_map_free,\n};\n\nstatic int\nvdev_mirror_load(mirror_map_t *mm, vdev_t *vd, uint64_t zio_offset)\n{\n\tuint64_t last_offset;\n\tint64_t offset_diff;\n\tint load;\n\n\t \n\tif (mm->mm_root)\n\t\treturn (INT_MAX);\n\n\t \n\n\t \n\tif (vd->vdev_ops->vdev_op_leaf)\n\t\tzio_offset += VDEV_LABEL_START_SIZE;\n\n\t \n\tload = vdev_queue_length(vd);\n\tlast_offset = vdev_queue_last_offset(vd);\n\n\tif (vd->vdev_nonrot) {\n\t\t \n\t\tif (last_offset == zio_offset) {\n\t\t\tMIRROR_BUMP(vdev_mirror_stat_non_rotating_linear);\n\t\t\treturn (load + zfs_vdev_mirror_non_rotating_inc);\n\t\t}\n\n\t\t \n\t\tMIRROR_BUMP(vdev_mirror_stat_non_rotating_seek);\n\t\treturn (load + zfs_vdev_mirror_non_rotating_seek_inc);\n\t}\n\n\t \n\tif (last_offset == zio_offset) {\n\t\tMIRROR_BUMP(vdev_mirror_stat_rotating_linear);\n\t\treturn (load + zfs_vdev_mirror_rotating_inc);\n\t}\n\n\t \n\toffset_diff = (int64_t)(last_offset - zio_offset);\n\tif (ABS(offset_diff) < zfs_vdev_mirror_rotating_seek_offset) {\n\t\tMIRROR_BUMP(vdev_mirror_stat_rotating_offset);\n\t\treturn (load + (zfs_vdev_mirror_rotating_seek_inc / 2));\n\t}\n\n\t \n\tMIRROR_BUMP(vdev_mirror_stat_rotating_seek);\n\treturn (load + zfs_vdev_mirror_rotating_seek_inc);\n}\n\nstatic boolean_t\nvdev_mirror_rebuilding(vdev_t *vd)\n{\n\tif (vd->vdev_ops->vdev_op_leaf && vd->vdev_rebuild_txg)\n\t\treturn (B_TRUE);\n\n\tfor (int i = 0; i < vd->vdev_children; i++) {\n\t\tif (vdev_mirror_rebuilding(vd->vdev_child[i])) {\n\t\t\treturn (B_TRUE);\n\t\t}\n\t}\n\n\treturn (B_FALSE);\n}\n\n \nnoinline static mirror_map_t *\nvdev_mirror_map_init(zio_t *zio)\n{\n\tmirror_map_t *mm = NULL;\n\tmirror_child_t *mc;\n\tvdev_t *vd = zio->io_vd;\n\tint c;\n\n\tif (vd == NULL) {\n\t\tdva_t *dva = zio->io_bp->blk_dva;\n\t\tspa_t *spa = zio->io_spa;\n\t\tdsl_scan_t *scn = spa->spa_dsl_pool->dp_scan;\n\t\tdva_t dva_copy[SPA_DVAS_PER_BP];\n\n\t\t \n\t\tif ((zio->io_flags & ZIO_FLAG_SCRUB) &&\n\t\t    !(zio->io_flags & ZIO_FLAG_IO_RETRY) &&\n\t\t    dsl_scan_scrubbing(spa->spa_dsl_pool) &&\n\t\t    scn->scn_is_sorted) {\n\t\t\tc = 1;\n\t\t} else {\n\t\t\tc = BP_GET_NDVAS(zio->io_bp);\n\t\t}\n\n\t\t \n\t\tif (!spa_writeable(spa)) {\n\t\t\tASSERT3U(zio->io_type, ==, ZIO_TYPE_READ);\n\t\t\tint j = 0;\n\t\t\tfor (int i = 0; i < c; i++) {\n\t\t\t\tif (zfs_dva_valid(spa, &dva[i], zio->io_bp))\n\t\t\t\t\tdva_copy[j++] = dva[i];\n\t\t\t}\n\t\t\tif (j == 0) {\n\t\t\t\tzio->io_vsd = NULL;\n\t\t\t\tzio->io_error = ENXIO;\n\t\t\t\treturn (NULL);\n\t\t\t}\n\t\t\tif (j < c) {\n\t\t\t\tdva = dva_copy;\n\t\t\t\tc = j;\n\t\t\t}\n\t\t}\n\n\t\tmm = vdev_mirror_map_alloc(c, B_FALSE, B_TRUE);\n\t\tfor (c = 0; c < mm->mm_children; c++) {\n\t\t\tmc = &mm->mm_child[c];\n\n\t\t\tmc->mc_vd = vdev_lookup_top(spa, DVA_GET_VDEV(&dva[c]));\n\t\t\tmc->mc_offset = DVA_GET_OFFSET(&dva[c]);\n\t\t\tif (mc->mc_vd == NULL) {\n\t\t\t\tkmem_free(mm, vdev_mirror_map_size(\n\t\t\t\t    mm->mm_children));\n\t\t\t\tzio->io_vsd = NULL;\n\t\t\t\tzio->io_error = ENXIO;\n\t\t\t\treturn (NULL);\n\t\t\t}\n\t\t}\n\t} else {\n\t\t \n\t\tboolean_t replacing = (vd->vdev_ops == &vdev_replacing_ops ||\n\t\t    vd->vdev_ops == &vdev_spare_ops) &&\n\t\t    spa_load_state(vd->vdev_spa) == SPA_LOAD_NONE &&\n\t\t    dsl_scan_resilvering(vd->vdev_spa->spa_dsl_pool);\n\t\tmm = vdev_mirror_map_alloc(vd->vdev_children, replacing,\n\t\t    B_FALSE);\n\t\tfor (c = 0; c < mm->mm_children; c++) {\n\t\t\tmc = &mm->mm_child[c];\n\t\t\tmc->mc_vd = vd->vdev_child[c];\n\t\t\tmc->mc_offset = zio->io_offset;\n\n\t\t\tif (vdev_mirror_rebuilding(mc->mc_vd))\n\t\t\t\tmm->mm_rebuilding = mc->mc_rebuilding = B_TRUE;\n\t\t}\n\t}\n\n\treturn (mm);\n}\n\nstatic int\nvdev_mirror_open(vdev_t *vd, uint64_t *asize, uint64_t *max_asize,\n    uint64_t *logical_ashift, uint64_t *physical_ashift)\n{\n\tint numerrors = 0;\n\tint lasterror = 0;\n\n\tif (vd->vdev_children == 0) {\n\t\tvd->vdev_stat.vs_aux = VDEV_AUX_BAD_LABEL;\n\t\treturn (SET_ERROR(EINVAL));\n\t}\n\n\tvdev_open_children(vd);\n\n\tfor (int c = 0; c < vd->vdev_children; c++) {\n\t\tvdev_t *cvd = vd->vdev_child[c];\n\n\t\tif (cvd->vdev_open_error) {\n\t\t\tlasterror = cvd->vdev_open_error;\n\t\t\tnumerrors++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t*asize = MIN(*asize - 1, cvd->vdev_asize - 1) + 1;\n\t\t*max_asize = MIN(*max_asize - 1, cvd->vdev_max_asize - 1) + 1;\n\t\t*logical_ashift = MAX(*logical_ashift, cvd->vdev_ashift);\n\t}\n\tfor (int c = 0; c < vd->vdev_children; c++) {\n\t\tvdev_t *cvd = vd->vdev_child[c];\n\n\t\tif (cvd->vdev_open_error)\n\t\t\tcontinue;\n\t\t*physical_ashift = vdev_best_ashift(*logical_ashift,\n\t\t    *physical_ashift, cvd->vdev_physical_ashift);\n\t}\n\n\tif (numerrors == vd->vdev_children) {\n\t\tif (vdev_children_are_offline(vd))\n\t\t\tvd->vdev_stat.vs_aux = VDEV_AUX_CHILDREN_OFFLINE;\n\t\telse\n\t\t\tvd->vdev_stat.vs_aux = VDEV_AUX_NO_REPLICAS;\n\t\treturn (lasterror);\n\t}\n\n\treturn (0);\n}\n\nstatic void\nvdev_mirror_close(vdev_t *vd)\n{\n\tfor (int c = 0; c < vd->vdev_children; c++)\n\t\tvdev_close(vd->vdev_child[c]);\n}\n\nstatic void\nvdev_mirror_child_done(zio_t *zio)\n{\n\tmirror_child_t *mc = zio->io_private;\n\n\tmc->mc_error = zio->io_error;\n\tmc->mc_tried = 1;\n\tmc->mc_skipped = 0;\n}\n\n \nstatic int\nvdev_mirror_dva_select(zio_t *zio, int p)\n{\n\tdva_t *dva = zio->io_bp->blk_dva;\n\tmirror_map_t *mm = zio->io_vsd;\n\tint preferred;\n\tint c;\n\n\tpreferred = mm->mm_preferred[p];\n\tfor (p--; p >= 0; p--) {\n\t\tc = mm->mm_preferred[p];\n\t\tif (DVA_GET_VDEV(&dva[c]) == DVA_GET_VDEV(&dva[preferred]))\n\t\t\tpreferred = c;\n\t}\n\treturn (preferred);\n}\n\nstatic int\nvdev_mirror_preferred_child_randomize(zio_t *zio)\n{\n\tmirror_map_t *mm = zio->io_vsd;\n\tint p;\n\n\tif (mm->mm_root) {\n\t\tp = random_in_range(mm->mm_preferred_cnt);\n\t\treturn (vdev_mirror_dva_select(zio, p));\n\t}\n\n\t \n\tp = (zio->io_offset >> vdev_mirror_shift) % mm->mm_preferred_cnt;\n\treturn (mm->mm_preferred[p]);\n}\n\nstatic boolean_t\nvdev_mirror_child_readable(mirror_child_t *mc)\n{\n\tvdev_t *vd = mc->mc_vd;\n\n\tif (vd->vdev_top != NULL && vd->vdev_top->vdev_ops == &vdev_draid_ops)\n\t\treturn (vdev_draid_readable(vd, mc->mc_offset));\n\telse\n\t\treturn (vdev_readable(vd));\n}\n\nstatic boolean_t\nvdev_mirror_child_missing(mirror_child_t *mc, uint64_t txg, uint64_t size)\n{\n\tvdev_t *vd = mc->mc_vd;\n\n\tif (vd->vdev_top != NULL && vd->vdev_top->vdev_ops == &vdev_draid_ops)\n\t\treturn (vdev_draid_missing(vd, mc->mc_offset, txg, size));\n\telse\n\t\treturn (vdev_dtl_contains(vd, DTL_MISSING, txg, size));\n}\n\n \nstatic int\nvdev_mirror_child_select(zio_t *zio)\n{\n\tmirror_map_t *mm = zio->io_vsd;\n\tuint64_t txg = zio->io_txg;\n\tint c, lowest_load;\n\n\tASSERT(zio->io_bp == NULL || BP_PHYSICAL_BIRTH(zio->io_bp) == txg);\n\n\tlowest_load = INT_MAX;\n\tmm->mm_preferred_cnt = 0;\n\tfor (c = 0; c < mm->mm_children; c++) {\n\t\tmirror_child_t *mc;\n\n\t\tmc = &mm->mm_child[c];\n\t\tif (mc->mc_tried || mc->mc_skipped)\n\t\t\tcontinue;\n\n\t\tif (mc->mc_vd == NULL ||\n\t\t    !vdev_mirror_child_readable(mc)) {\n\t\t\tmc->mc_error = SET_ERROR(ENXIO);\n\t\t\tmc->mc_tried = 1;\t \n\t\t\tmc->mc_skipped = 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (vdev_mirror_child_missing(mc, txg, 1)) {\n\t\t\tmc->mc_error = SET_ERROR(ESTALE);\n\t\t\tmc->mc_skipped = 1;\n\t\t\tmc->mc_speculative = 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (mc->mc_vd->vdev_ops == &vdev_draid_spare_ops) {\n\t\t\tmm->mm_preferred[0] = c;\n\t\t\tmm->mm_preferred_cnt = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tmc->mc_load = vdev_mirror_load(mm, mc->mc_vd, mc->mc_offset);\n\t\tif (mc->mc_load > lowest_load)\n\t\t\tcontinue;\n\n\t\tif (mc->mc_load < lowest_load) {\n\t\t\tlowest_load = mc->mc_load;\n\t\t\tmm->mm_preferred_cnt = 0;\n\t\t}\n\t\tmm->mm_preferred[mm->mm_preferred_cnt] = c;\n\t\tmm->mm_preferred_cnt++;\n\t}\n\n\tif (mm->mm_preferred_cnt == 1) {\n\t\tMIRROR_BUMP(vdev_mirror_stat_preferred_found);\n\t\treturn (mm->mm_preferred[0]);\n\t}\n\n\tif (mm->mm_preferred_cnt > 1) {\n\t\tMIRROR_BUMP(vdev_mirror_stat_preferred_not_found);\n\t\treturn (vdev_mirror_preferred_child_randomize(zio));\n\t}\n\n\t \n\tfor (c = 0; c < mm->mm_children; c++) {\n\t\tif (!mm->mm_child[c].mc_tried)\n\t\t\treturn (c);\n\t}\n\n\t \n\treturn (-1);\n}\n\nstatic void\nvdev_mirror_io_start(zio_t *zio)\n{\n\tmirror_map_t *mm;\n\tmirror_child_t *mc;\n\tint c, children;\n\n\tmm = vdev_mirror_map_init(zio);\n\tzio->io_vsd = mm;\n\tzio->io_vsd_ops = &vdev_mirror_vsd_ops;\n\n\tif (mm == NULL) {\n\t\tASSERT(!spa_trust_config(zio->io_spa));\n\t\tASSERT(zio->io_type == ZIO_TYPE_READ);\n\t\tzio_execute(zio);\n\t\treturn;\n\t}\n\n\tif (zio->io_type == ZIO_TYPE_READ) {\n\t\tif ((zio->io_flags & ZIO_FLAG_SCRUB) && !mm->mm_resilvering) {\n\t\t\t \n\t\t\tboolean_t first = B_TRUE;\n\t\t\tfor (c = 0; c < mm->mm_children; c++) {\n\t\t\t\tmc = &mm->mm_child[c];\n\n\t\t\t\t \n\t\t\t\tif (!vdev_mirror_child_readable(mc)) {\n\t\t\t\t\tmc->mc_error = SET_ERROR(ENXIO);\n\t\t\t\t\tmc->mc_tried = 1;\n\t\t\t\t\tmc->mc_skipped = 1;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tmc->mc_abd = first ? zio->io_abd :\n\t\t\t\t    abd_alloc_sametype(zio->io_abd,\n\t\t\t\t    zio->io_size);\n\t\t\t\tzio_nowait(zio_vdev_child_io(zio, zio->io_bp,\n\t\t\t\t    mc->mc_vd, mc->mc_offset, mc->mc_abd,\n\t\t\t\t    zio->io_size, zio->io_type,\n\t\t\t\t    zio->io_priority, 0,\n\t\t\t\t    vdev_mirror_child_done, mc));\n\t\t\t\tfirst = B_FALSE;\n\t\t\t}\n\t\t\tzio_execute(zio);\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tc = vdev_mirror_child_select(zio);\n\t\tchildren = (c >= 0);\n\t} else {\n\t\tASSERT(zio->io_type == ZIO_TYPE_WRITE);\n\n\t\t \n\t\tc = 0;\n\t\tchildren = mm->mm_children;\n\t}\n\n\twhile (children--) {\n\t\tmc = &mm->mm_child[c];\n\t\tc++;\n\n\t\t \n\t\tif ((zio->io_priority == ZIO_PRIORITY_REBUILD) &&\n\t\t    (zio->io_flags & ZIO_FLAG_IO_REPAIR) &&\n\t\t    !(zio->io_flags & ZIO_FLAG_SCRUB) &&\n\t\t    mm->mm_rebuilding && !mc->mc_rebuilding) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tzio_nowait(zio_vdev_child_io(zio, zio->io_bp,\n\t\t    mc->mc_vd, mc->mc_offset, zio->io_abd, zio->io_size,\n\t\t    zio->io_type, zio->io_priority, 0,\n\t\t    vdev_mirror_child_done, mc));\n\t}\n\n\tzio_execute(zio);\n}\n\nstatic int\nvdev_mirror_worst_error(mirror_map_t *mm)\n{\n\tint error[2] = { 0, 0 };\n\n\tfor (int c = 0; c < mm->mm_children; c++) {\n\t\tmirror_child_t *mc = &mm->mm_child[c];\n\t\tint s = mc->mc_speculative;\n\t\terror[s] = zio_worst_error(error[s], mc->mc_error);\n\t}\n\n\treturn (error[0] ? error[0] : error[1]);\n}\n\nstatic void\nvdev_mirror_io_done(zio_t *zio)\n{\n\tmirror_map_t *mm = zio->io_vsd;\n\tmirror_child_t *mc;\n\tint c;\n\tint good_copies = 0;\n\tint unexpected_errors = 0;\n\tint last_good_copy = -1;\n\n\tif (mm == NULL)\n\t\treturn;\n\n\tfor (c = 0; c < mm->mm_children; c++) {\n\t\tmc = &mm->mm_child[c];\n\n\t\tif (mc->mc_error) {\n\t\t\tif (!mc->mc_skipped)\n\t\t\t\tunexpected_errors++;\n\t\t} else if (mc->mc_tried) {\n\t\t\tlast_good_copy = c;\n\t\t\tgood_copies++;\n\t\t}\n\t}\n\n\tif (zio->io_type == ZIO_TYPE_WRITE) {\n\t\t \n\t\tif (good_copies != mm->mm_children) {\n\t\t\t \n\t\t\tif (good_copies == 0 || zio->io_vd == NULL)\n\t\t\t\tzio->io_error = vdev_mirror_worst_error(mm);\n\t\t}\n\t\treturn;\n\t}\n\n\tASSERT(zio->io_type == ZIO_TYPE_READ);\n\n\t \n\tif (good_copies == 0 && (c = vdev_mirror_child_select(zio)) != -1) {\n\t\tASSERT(c >= 0 && c < mm->mm_children);\n\t\tmc = &mm->mm_child[c];\n\t\tzio_vdev_io_redone(zio);\n\t\tzio_nowait(zio_vdev_child_io(zio, zio->io_bp,\n\t\t    mc->mc_vd, mc->mc_offset, zio->io_abd, zio->io_size,\n\t\t    ZIO_TYPE_READ, zio->io_priority, 0,\n\t\t    vdev_mirror_child_done, mc));\n\t\treturn;\n\t}\n\n\tif (zio->io_flags & ZIO_FLAG_SCRUB && !mm->mm_resilvering) {\n\t\tabd_t *best_abd = NULL;\n\t\tif (last_good_copy >= 0)\n\t\t\tbest_abd = mm->mm_child[last_good_copy].mc_abd;\n\n\t\t \n\t\tif (zio->io_bp == NULL) {\n\t\t\tASSERT(zio->io_vd->vdev_ops == &vdev_replacing_ops ||\n\t\t\t    zio->io_vd->vdev_ops == &vdev_spare_ops);\n\n\t\t\tabd_t *pref_abd = NULL;\n\t\t\tfor (c = 0; c < last_good_copy; c++) {\n\t\t\t\tmc = &mm->mm_child[c];\n\t\t\t\tif (mc->mc_error || !mc->mc_tried)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tif (abd_cmp(mc->mc_abd, best_abd) != 0)\n\t\t\t\t\tzio->io_error = SET_ERROR(ECKSUM);\n\n\t\t\t\t \n\t\t\t\tif (pref_abd == NULL &&\n\t\t\t\t    mc->mc_vd->vdev_ops ==\n\t\t\t\t    &vdev_draid_spare_ops)\n\t\t\t\t\tpref_abd = mc->mc_abd;\n\n\t\t\t\t \n\t\t\t\tif (mc->mc_abd == zio->io_abd)\n\t\t\t\t\tbest_abd = mc->mc_abd;\n\t\t\t}\n\t\t\tif (pref_abd)\n\t\t\t\tbest_abd = pref_abd;\n\t\t} else {\n\n\t\t\t \n\t\t\tfor (c = 0; c < last_good_copy; c++) {\n\t\t\t\tmc = &mm->mm_child[c];\n\t\t\t\tif (mc->mc_error || !mc->mc_tried)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (mc->mc_abd == zio->io_abd) {\n\t\t\t\t\tbest_abd = mc->mc_abd;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (best_abd && best_abd != zio->io_abd)\n\t\t\tabd_copy(zio->io_abd, best_abd, zio->io_size);\n\t\tfor (c = 0; c < mm->mm_children; c++) {\n\t\t\tmc = &mm->mm_child[c];\n\t\t\tif (mc->mc_abd != zio->io_abd)\n\t\t\t\tabd_free(mc->mc_abd);\n\t\t\tmc->mc_abd = NULL;\n\t\t}\n\t}\n\n\tif (good_copies == 0) {\n\t\tzio->io_error = vdev_mirror_worst_error(mm);\n\t\tASSERT(zio->io_error != 0);\n\t}\n\n\tif (good_copies && spa_writeable(zio->io_spa) &&\n\t    (unexpected_errors ||\n\t    (zio->io_flags & ZIO_FLAG_RESILVER) ||\n\t    ((zio->io_flags & ZIO_FLAG_SCRUB) && mm->mm_resilvering))) {\n\t\t \n\t\tfor (c = 0; c < mm->mm_children; c++) {\n\t\t\t \n\t\t\tmc = &mm->mm_child[c];\n\n\t\t\tif (mc->mc_error == 0) {\n\t\t\t\tvdev_ops_t *ops = mc->mc_vd->vdev_ops;\n\n\t\t\t\tif (mc->mc_tried)\n\t\t\t\t\tcontinue;\n\t\t\t\t \n\t\t\t\tif (!(zio->io_flags & ZIO_FLAG_SCRUB) &&\n\t\t\t\t    ops != &vdev_indirect_ops &&\n\t\t\t\t    ops != &vdev_draid_spare_ops &&\n\t\t\t\t    !vdev_dtl_contains(mc->mc_vd, DTL_PARTIAL,\n\t\t\t\t    zio->io_txg, 1))\n\t\t\t\t\tcontinue;\n\t\t\t\tmc->mc_error = SET_ERROR(ESTALE);\n\t\t\t}\n\n\t\t\tzio_nowait(zio_vdev_child_io(zio, zio->io_bp,\n\t\t\t    mc->mc_vd, mc->mc_offset,\n\t\t\t    zio->io_abd, zio->io_size, ZIO_TYPE_WRITE,\n\t\t\t    zio->io_priority == ZIO_PRIORITY_REBUILD ?\n\t\t\t    ZIO_PRIORITY_REBUILD : ZIO_PRIORITY_ASYNC_WRITE,\n\t\t\t    ZIO_FLAG_IO_REPAIR | (unexpected_errors ?\n\t\t\t    ZIO_FLAG_SELF_HEAL : 0), NULL, NULL));\n\t\t}\n\t}\n}\n\nstatic void\nvdev_mirror_state_change(vdev_t *vd, int faulted, int degraded)\n{\n\tif (faulted == vd->vdev_children) {\n\t\tif (vdev_children_are_offline(vd)) {\n\t\t\tvdev_set_state(vd, B_FALSE, VDEV_STATE_OFFLINE,\n\t\t\t    VDEV_AUX_CHILDREN_OFFLINE);\n\t\t} else {\n\t\t\tvdev_set_state(vd, B_FALSE, VDEV_STATE_CANT_OPEN,\n\t\t\t    VDEV_AUX_NO_REPLICAS);\n\t\t}\n\t} else if (degraded + faulted != 0) {\n\t\tvdev_set_state(vd, B_FALSE, VDEV_STATE_DEGRADED, VDEV_AUX_NONE);\n\t} else {\n\t\tvdev_set_state(vd, B_FALSE, VDEV_STATE_HEALTHY, VDEV_AUX_NONE);\n\t}\n}\n\n \nstatic uint64_t\nvdev_mirror_rebuild_asize(vdev_t *vd, uint64_t start, uint64_t asize,\n    uint64_t max_segment)\n{\n\t(void) start;\n\n\tuint64_t psize = MIN(P2ROUNDUP(max_segment, 1 << vd->vdev_ashift),\n\t    SPA_MAXBLOCKSIZE);\n\n\treturn (MIN(asize, vdev_psize_to_asize(vd, psize)));\n}\n\nvdev_ops_t vdev_mirror_ops = {\n\t.vdev_op_init = NULL,\n\t.vdev_op_fini = NULL,\n\t.vdev_op_open = vdev_mirror_open,\n\t.vdev_op_close = vdev_mirror_close,\n\t.vdev_op_asize = vdev_default_asize,\n\t.vdev_op_min_asize = vdev_default_min_asize,\n\t.vdev_op_min_alloc = NULL,\n\t.vdev_op_io_start = vdev_mirror_io_start,\n\t.vdev_op_io_done = vdev_mirror_io_done,\n\t.vdev_op_state_change = vdev_mirror_state_change,\n\t.vdev_op_need_resilver = vdev_default_need_resilver,\n\t.vdev_op_hold = NULL,\n\t.vdev_op_rele = NULL,\n\t.vdev_op_remap = NULL,\n\t.vdev_op_xlate = vdev_default_xlate,\n\t.vdev_op_rebuild_asize = vdev_mirror_rebuild_asize,\n\t.vdev_op_metaslab_init = NULL,\n\t.vdev_op_config_generate = NULL,\n\t.vdev_op_nparity = NULL,\n\t.vdev_op_ndisks = NULL,\n\t.vdev_op_type = VDEV_TYPE_MIRROR,\t \n\t.vdev_op_leaf = B_FALSE\t\t\t \n};\n\nvdev_ops_t vdev_replacing_ops = {\n\t.vdev_op_init = NULL,\n\t.vdev_op_fini = NULL,\n\t.vdev_op_open = vdev_mirror_open,\n\t.vdev_op_close = vdev_mirror_close,\n\t.vdev_op_asize = vdev_default_asize,\n\t.vdev_op_min_asize = vdev_default_min_asize,\n\t.vdev_op_min_alloc = NULL,\n\t.vdev_op_io_start = vdev_mirror_io_start,\n\t.vdev_op_io_done = vdev_mirror_io_done,\n\t.vdev_op_state_change = vdev_mirror_state_change,\n\t.vdev_op_need_resilver = vdev_default_need_resilver,\n\t.vdev_op_hold = NULL,\n\t.vdev_op_rele = NULL,\n\t.vdev_op_remap = NULL,\n\t.vdev_op_xlate = vdev_default_xlate,\n\t.vdev_op_rebuild_asize = vdev_mirror_rebuild_asize,\n\t.vdev_op_metaslab_init = NULL,\n\t.vdev_op_config_generate = NULL,\n\t.vdev_op_nparity = NULL,\n\t.vdev_op_ndisks = NULL,\n\t.vdev_op_type = VDEV_TYPE_REPLACING,\t \n\t.vdev_op_leaf = B_FALSE\t\t\t \n};\n\nvdev_ops_t vdev_spare_ops = {\n\t.vdev_op_init = NULL,\n\t.vdev_op_fini = NULL,\n\t.vdev_op_open = vdev_mirror_open,\n\t.vdev_op_close = vdev_mirror_close,\n\t.vdev_op_asize = vdev_default_asize,\n\t.vdev_op_min_asize = vdev_default_min_asize,\n\t.vdev_op_min_alloc = NULL,\n\t.vdev_op_io_start = vdev_mirror_io_start,\n\t.vdev_op_io_done = vdev_mirror_io_done,\n\t.vdev_op_state_change = vdev_mirror_state_change,\n\t.vdev_op_need_resilver = vdev_default_need_resilver,\n\t.vdev_op_hold = NULL,\n\t.vdev_op_rele = NULL,\n\t.vdev_op_remap = NULL,\n\t.vdev_op_xlate = vdev_default_xlate,\n\t.vdev_op_rebuild_asize = vdev_mirror_rebuild_asize,\n\t.vdev_op_metaslab_init = NULL,\n\t.vdev_op_config_generate = NULL,\n\t.vdev_op_nparity = NULL,\n\t.vdev_op_ndisks = NULL,\n\t.vdev_op_type = VDEV_TYPE_SPARE,\t \n\t.vdev_op_leaf = B_FALSE\t\t\t \n};\n\nZFS_MODULE_PARAM(zfs_vdev_mirror, zfs_vdev_mirror_, rotating_inc, INT, ZMOD_RW,\n\t\"Rotating media load increment for non-seeking I/Os\");\n\nZFS_MODULE_PARAM(zfs_vdev_mirror, zfs_vdev_mirror_, rotating_seek_inc, INT,\n\tZMOD_RW, \"Rotating media load increment for seeking I/Os\");\n\n \nZFS_MODULE_PARAM(zfs_vdev_mirror, zfs_vdev_mirror_, rotating_seek_offset, INT,\n\tZMOD_RW,\n\t\"Offset in bytes from the last I/O which triggers \"\n\t\"a reduced rotating media seek increment\");\n \n\nZFS_MODULE_PARAM(zfs_vdev_mirror, zfs_vdev_mirror_, non_rotating_inc, INT,\n\tZMOD_RW, \"Non-rotating media load increment for non-seeking I/Os\");\n\nZFS_MODULE_PARAM(zfs_vdev_mirror, zfs_vdev_mirror_, non_rotating_seek_inc, INT,\n\tZMOD_RW, \"Non-rotating media load increment for seeking I/Os\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}