{
  "module_name": "dsl_scan.c",
  "hash_id": "e375f0fec1349affbda47a88facfbc31e4e7bcea25659262f85e42ae39fbb276",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/dsl_scan.c",
  "human_readable_source": " \n \n\n#include <sys/dsl_scan.h>\n#include <sys/dsl_pool.h>\n#include <sys/dsl_dataset.h>\n#include <sys/dsl_prop.h>\n#include <sys/dsl_dir.h>\n#include <sys/dsl_synctask.h>\n#include <sys/dnode.h>\n#include <sys/dmu_tx.h>\n#include <sys/dmu_objset.h>\n#include <sys/arc.h>\n#include <sys/arc_impl.h>\n#include <sys/zap.h>\n#include <sys/zio.h>\n#include <sys/zfs_context.h>\n#include <sys/fs/zfs.h>\n#include <sys/zfs_znode.h>\n#include <sys/spa_impl.h>\n#include <sys/vdev_impl.h>\n#include <sys/zil_impl.h>\n#include <sys/zio_checksum.h>\n#include <sys/brt.h>\n#include <sys/ddt.h>\n#include <sys/sa.h>\n#include <sys/sa_impl.h>\n#include <sys/zfeature.h>\n#include <sys/abd.h>\n#include <sys/range_tree.h>\n#include <sys/dbuf.h>\n#ifdef _KERNEL\n#include <sys/zfs_vfsops.h>\n#endif\n\n \n\ntypedef int (scan_cb_t)(dsl_pool_t *, const blkptr_t *,\n    const zbookmark_phys_t *);\n\nstatic scan_cb_t dsl_scan_scrub_cb;\n\nstatic int scan_ds_queue_compare(const void *a, const void *b);\nstatic int scan_prefetch_queue_compare(const void *a, const void *b);\nstatic void scan_ds_queue_clear(dsl_scan_t *scn);\nstatic void scan_ds_prefetch_queue_clear(dsl_scan_t *scn);\nstatic boolean_t scan_ds_queue_contains(dsl_scan_t *scn, uint64_t dsobj,\n    uint64_t *txg);\nstatic void scan_ds_queue_insert(dsl_scan_t *scn, uint64_t dsobj, uint64_t txg);\nstatic void scan_ds_queue_remove(dsl_scan_t *scn, uint64_t dsobj);\nstatic void scan_ds_queue_sync(dsl_scan_t *scn, dmu_tx_t *tx);\nstatic uint64_t dsl_scan_count_data_disks(spa_t *spa);\nstatic void read_by_block_level(dsl_scan_t *scn, zbookmark_phys_t zb);\n\nextern uint_t zfs_vdev_async_write_active_min_dirty_percent;\nstatic int zfs_scan_blkstats = 0;\n\n \nstatic uint_t zfs_scan_report_txgs = 0;\n\n \nstatic int zfs_scan_strict_mem_lim = B_FALSE;\n\n \nstatic uint64_t zfs_scan_vdev_limit = 16 << 20;\n\nstatic uint_t zfs_scan_issue_strategy = 0;\n\n \nstatic int zfs_scan_legacy = B_FALSE;\nstatic uint64_t zfs_scan_max_ext_gap = 2 << 20;  \n\n \nstatic uint_t zfs_scan_fill_weight = 3;\nstatic uint64_t fill_weight;\n\n \nstatic const uint64_t zfs_scan_mem_lim_min = 16 << 20;\t \nstatic const uint64_t zfs_scan_mem_lim_soft_max = 128 << 20;\t \n\n\n \nstatic uint_t zfs_scan_mem_lim_fact = 20;\n\n \nstatic uint_t zfs_scan_mem_lim_soft_fact = 20;\n\n \nstatic uint_t zfs_scrub_min_time_ms = 1000;\n\n \nstatic uint_t zfs_obsolete_min_time_ms = 500;\n\n \nstatic uint_t zfs_free_min_time_ms = 1000;\n\n \nstatic uint_t zfs_resilver_min_time_ms = 3000;\n\nstatic uint_t zfs_scan_checkpoint_intval = 7200;  \nint zfs_scan_suspend_progress = 0;  \nstatic int zfs_no_scrub_io = B_FALSE;  \nstatic int zfs_no_scrub_prefetch = B_FALSE;  \nstatic const enum ddt_class zfs_scrub_ddt_class_max = DDT_CLASS_DUPLICATE;\n \nstatic uint64_t zfs_async_block_max_blocks = UINT64_MAX;\n \nstatic uint64_t zfs_max_async_dedup_frees = 100000;\n\n \nstatic int zfs_resilver_disable_defer = B_FALSE;\n\n \n#define\tSCAN_IMPORT_WAIT_TXGS \t\t5\n\n#define\tDSL_SCAN_IS_SCRUB_RESILVER(scn) \\\n\t((scn)->scn_phys.scn_func == POOL_SCAN_SCRUB || \\\n\t(scn)->scn_phys.scn_func == POOL_SCAN_RESILVER)\n\n \nstatic int zfs_free_bpobj_enabled = 1;\n\n \nstatic uint_t zfs_scrub_error_blocks_per_txg = 1 << 12;\n\n \nstatic scan_cb_t *scan_funcs[POOL_SCAN_FUNCS] = {\n\tNULL,\n\tdsl_scan_scrub_cb,\t \n\tdsl_scan_scrub_cb,\t \n};\n\n \ntypedef struct {\n\tuint64_t\tsds_dsobj;\n\tuint64_t\tsds_txg;\n\tavl_node_t\tsds_node;\n} scan_ds_t;\n\n \ntypedef enum {\n\tSYNC_OPTIONAL,\n\tSYNC_MANDATORY,\n\tSYNC_CACHED\n} state_sync_type_t;\n\n \ntypedef struct scan_io {\n\t \n\tuint64_t\t\tsio_blk_prop;\n\tuint64_t\t\tsio_phys_birth;\n\tuint64_t\t\tsio_birth;\n\tzio_cksum_t\t\tsio_cksum;\n\tuint32_t\t\tsio_nr_dvas;\n\n\t \n\tuint32_t\t\tsio_flags;\n\tzbookmark_phys_t\tsio_zb;\n\n\t \n\tunion {\n\t\tavl_node_t\tsio_addr_node;  \n\t\tlist_node_t\tsio_list_node;  \n\t} sio_nodes;\n\n\t \n\tdva_t\t\t\tsio_dva[];\n} scan_io_t;\n\n#define\tSIO_SET_OFFSET(sio, x)\t\tDVA_SET_OFFSET(&(sio)->sio_dva[0], x)\n#define\tSIO_SET_ASIZE(sio, x)\t\tDVA_SET_ASIZE(&(sio)->sio_dva[0], x)\n#define\tSIO_GET_OFFSET(sio)\t\tDVA_GET_OFFSET(&(sio)->sio_dva[0])\n#define\tSIO_GET_ASIZE(sio)\t\tDVA_GET_ASIZE(&(sio)->sio_dva[0])\n#define\tSIO_GET_END_OFFSET(sio)\t\t\\\n\t(SIO_GET_OFFSET(sio) + SIO_GET_ASIZE(sio))\n#define\tSIO_GET_MUSED(sio)\t\t\\\n\t(sizeof (scan_io_t) + ((sio)->sio_nr_dvas * sizeof (dva_t)))\n\nstruct dsl_scan_io_queue {\n\tdsl_scan_t\t*q_scn;  \n\tvdev_t\t\t*q_vd;  \n\tzio_t\t\t*q_zio;  \n\n\t \n\trange_tree_t\t*q_exts_by_addr;\n\tzfs_btree_t\tq_exts_by_size;\n\tavl_tree_t\tq_sios_by_addr;\n\tuint64_t\tq_sio_memused;\n\tuint64_t\tq_last_ext_addr;\n\n\t \n\tuint64_t\tq_maxinflight_bytes;\n\tuint64_t\tq_inflight_bytes;\n\tkcondvar_t\tq_zio_cv;  \n\n\t \n\tuint64_t\tq_total_seg_size_this_txg;\n\tuint64_t\tq_segs_this_txg;\n\tuint64_t\tq_total_zio_size_this_txg;\n\tuint64_t\tq_zios_this_txg;\n};\n\n \ntypedef struct scan_prefetch_ctx {\n\tzfs_refcount_t spc_refcnt;\t \n\tdsl_scan_t *spc_scn;\t\t \n\tboolean_t spc_root;\t\t \n\tuint8_t spc_indblkshift;\t \n\tuint16_t spc_datablkszsec;\t \n} scan_prefetch_ctx_t;\n\n \ntypedef struct scan_prefetch_issue_ctx {\n\tavl_node_t spic_avl_node;\t \n\tscan_prefetch_ctx_t *spic_spc;\t \n\tblkptr_t spic_bp;\t\t \n\tzbookmark_phys_t spic_zb;\t \n} scan_prefetch_issue_ctx_t;\n\nstatic void scan_exec_io(dsl_pool_t *dp, const blkptr_t *bp, int zio_flags,\n    const zbookmark_phys_t *zb, dsl_scan_io_queue_t *queue);\nstatic void scan_io_queue_insert_impl(dsl_scan_io_queue_t *queue,\n    scan_io_t *sio);\n\nstatic dsl_scan_io_queue_t *scan_io_queue_create(vdev_t *vd);\nstatic void scan_io_queues_destroy(dsl_scan_t *scn);\n\nstatic kmem_cache_t *sio_cache[SPA_DVAS_PER_BP];\n\n \nstatic void\nsio_free(scan_io_t *sio)\n{\n\tASSERT3U(sio->sio_nr_dvas, >, 0);\n\tASSERT3U(sio->sio_nr_dvas, <=, SPA_DVAS_PER_BP);\n\n\tkmem_cache_free(sio_cache[sio->sio_nr_dvas - 1], sio);\n}\n\n \nstatic scan_io_t *\nsio_alloc(unsigned short nr_dvas)\n{\n\tASSERT3U(nr_dvas, >, 0);\n\tASSERT3U(nr_dvas, <=, SPA_DVAS_PER_BP);\n\n\treturn (kmem_cache_alloc(sio_cache[nr_dvas - 1], KM_SLEEP));\n}\n\nvoid\nscan_init(void)\n{\n\t \n\tfill_weight = zfs_scan_fill_weight;\n\n\tfor (int i = 0; i < SPA_DVAS_PER_BP; i++) {\n\t\tchar name[36];\n\n\t\t(void) snprintf(name, sizeof (name), \"sio_cache_%d\", i);\n\t\tsio_cache[i] = kmem_cache_create(name,\n\t\t    (sizeof (scan_io_t) + ((i + 1) * sizeof (dva_t))),\n\t\t    0, NULL, NULL, NULL, NULL, NULL, 0);\n\t}\n}\n\nvoid\nscan_fini(void)\n{\n\tfor (int i = 0; i < SPA_DVAS_PER_BP; i++) {\n\t\tkmem_cache_destroy(sio_cache[i]);\n\t}\n}\n\nstatic inline boolean_t\ndsl_scan_is_running(const dsl_scan_t *scn)\n{\n\treturn (scn->scn_phys.scn_state == DSS_SCANNING);\n}\n\nboolean_t\ndsl_scan_resilvering(dsl_pool_t *dp)\n{\n\treturn (dsl_scan_is_running(dp->dp_scan) &&\n\t    dp->dp_scan->scn_phys.scn_func == POOL_SCAN_RESILVER);\n}\n\nstatic inline void\nsio2bp(const scan_io_t *sio, blkptr_t *bp)\n{\n\tmemset(bp, 0, sizeof (*bp));\n\tbp->blk_prop = sio->sio_blk_prop;\n\tbp->blk_phys_birth = sio->sio_phys_birth;\n\tbp->blk_birth = sio->sio_birth;\n\tbp->blk_fill = 1;\t \n\tbp->blk_cksum = sio->sio_cksum;\n\n\tASSERT3U(sio->sio_nr_dvas, >, 0);\n\tASSERT3U(sio->sio_nr_dvas, <=, SPA_DVAS_PER_BP);\n\n\tmemcpy(bp->blk_dva, sio->sio_dva, sio->sio_nr_dvas * sizeof (dva_t));\n}\n\nstatic inline void\nbp2sio(const blkptr_t *bp, scan_io_t *sio, int dva_i)\n{\n\tsio->sio_blk_prop = bp->blk_prop;\n\tsio->sio_phys_birth = bp->blk_phys_birth;\n\tsio->sio_birth = bp->blk_birth;\n\tsio->sio_cksum = bp->blk_cksum;\n\tsio->sio_nr_dvas = BP_GET_NDVAS(bp);\n\n\t \n\tfor (int i = 0, j = dva_i; i < sio->sio_nr_dvas; i++, j++) {\n\t\tsio->sio_dva[i] = bp->blk_dva[j % sio->sio_nr_dvas];\n\t}\n}\n\nint\ndsl_scan_init(dsl_pool_t *dp, uint64_t txg)\n{\n\tint err;\n\tdsl_scan_t *scn;\n\tspa_t *spa = dp->dp_spa;\n\tuint64_t f;\n\n\tscn = dp->dp_scan = kmem_zalloc(sizeof (dsl_scan_t), KM_SLEEP);\n\tscn->scn_dp = dp;\n\n\t \n\tASSERT(!scn->scn_async_destroying);\n\tscn->scn_async_destroying = spa_feature_is_active(dp->dp_spa,\n\t    SPA_FEATURE_ASYNC_DESTROY);\n\n\t \n\tscn->scn_maxinflight_bytes = MIN(arc_c_max / 4, MAX(1ULL << 20,\n\t    zfs_scan_vdev_limit * dsl_scan_count_data_disks(spa)));\n\n\tavl_create(&scn->scn_queue, scan_ds_queue_compare, sizeof (scan_ds_t),\n\t    offsetof(scan_ds_t, sds_node));\n\tavl_create(&scn->scn_prefetch_queue, scan_prefetch_queue_compare,\n\t    sizeof (scan_prefetch_issue_ctx_t),\n\t    offsetof(scan_prefetch_issue_ctx_t, spic_avl_node));\n\n\terr = zap_lookup(dp->dp_meta_objset, DMU_POOL_DIRECTORY_OBJECT,\n\t    \"scrub_func\", sizeof (uint64_t), 1, &f);\n\tif (err == 0) {\n\t\t \n\t\tscn->scn_restart_txg = txg;\n\t\tzfs_dbgmsg(\"old-style scrub was in progress for %s; \"\n\t\t    \"restarting new-style scrub in txg %llu\",\n\t\t    spa->spa_name,\n\t\t    (longlong_t)scn->scn_restart_txg);\n\n\t\t \n\t\t(void) zap_lookup(dp->dp_meta_objset, DMU_POOL_DIRECTORY_OBJECT,\n\t\t    \"scrub_queue\", sizeof (uint64_t), 1,\n\t\t    &scn->scn_phys.scn_queue_obj);\n\t} else {\n\t\terr = zap_lookup(dp->dp_meta_objset, DMU_POOL_DIRECTORY_OBJECT,\n\t\t    DMU_POOL_ERRORSCRUB, sizeof (uint64_t),\n\t\t    ERRORSCRUB_PHYS_NUMINTS, &scn->errorscrub_phys);\n\n\t\tif (err != 0 && err != ENOENT)\n\t\t\treturn (err);\n\n\t\terr = zap_lookup(dp->dp_meta_objset, DMU_POOL_DIRECTORY_OBJECT,\n\t\t    DMU_POOL_SCAN, sizeof (uint64_t), SCAN_PHYS_NUMINTS,\n\t\t    &scn->scn_phys);\n\n\t\t \n\t\tif (err == EOVERFLOW) {\n\t\t\tuint64_t zaptmp[SCAN_PHYS_NUMINTS + 1];\n\t\t\tVERIFY3S(SCAN_PHYS_NUMINTS, ==, 24);\n\t\t\tVERIFY3S(offsetof(dsl_scan_phys_t, scn_flags), ==,\n\t\t\t    (23 * sizeof (uint64_t)));\n\n\t\t\terr = zap_lookup(dp->dp_meta_objset,\n\t\t\t    DMU_POOL_DIRECTORY_OBJECT, DMU_POOL_SCAN,\n\t\t\t    sizeof (uint64_t), SCAN_PHYS_NUMINTS + 1, &zaptmp);\n\t\t\tif (err == 0) {\n\t\t\t\tuint64_t overflow = zaptmp[SCAN_PHYS_NUMINTS];\n\n\t\t\t\tif (overflow & ~DSL_SCAN_FLAGS_MASK ||\n\t\t\t\t    scn->scn_async_destroying) {\n\t\t\t\t\tspa->spa_errata =\n\t\t\t\t\t    ZPOOL_ERRATA_ZOL_2094_ASYNC_DESTROY;\n\t\t\t\t\treturn (EOVERFLOW);\n\t\t\t\t}\n\n\t\t\t\tmemcpy(&scn->scn_phys, zaptmp,\n\t\t\t\t    SCAN_PHYS_NUMINTS * sizeof (uint64_t));\n\t\t\t\tscn->scn_phys.scn_flags = overflow;\n\n\t\t\t\t \n\t\t\t\tif (scn->scn_phys.scn_state == DSS_FINISHED ||\n\t\t\t\t    scn->scn_phys.scn_state == DSS_CANCELED)\n\t\t\t\t\tspa->spa_errata =\n\t\t\t\t\t    ZPOOL_ERRATA_ZOL_2094_SCRUB;\n\t\t\t}\n\t\t}\n\n\t\tif (err == ENOENT)\n\t\t\treturn (0);\n\t\telse if (err)\n\t\t\treturn (err);\n\n\t\t \n\t\tscn->scn_issued_before_pass = scn->scn_phys.scn_examined -\n\t\t    scn->scn_phys.scn_skipped;\n\n\t\tif (dsl_scan_is_running(scn) &&\n\t\t    spa_prev_software_version(dp->dp_spa) < SPA_VERSION_SCAN) {\n\t\t\t \n\t\t\tscn->scn_restart_txg = txg;\n\t\t\tzfs_dbgmsg(\"new-style scrub for %s was modified \"\n\t\t\t    \"by old software; restarting in txg %llu\",\n\t\t\t    spa->spa_name,\n\t\t\t    (longlong_t)scn->scn_restart_txg);\n\t\t} else if (dsl_scan_resilvering(dp)) {\n\t\t\t \n\t\t\tif (scn->scn_phys.scn_errors > 0) {\n\t\t\t\tscn->scn_restart_txg = txg;\n\t\t\t\tzfs_dbgmsg(\"resilver can't excise DTL_MISSING \"\n\t\t\t\t    \"when finished; restarting on %s in txg \"\n\t\t\t\t    \"%llu\",\n\t\t\t\t    spa->spa_name,\n\t\t\t\t    (u_longlong_t)scn->scn_restart_txg);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tspa->spa_scrub_started = B_TRUE;\n\t\t\t}\n\t\t}\n\t}\n\n\tmemcpy(&scn->scn_phys_cached, &scn->scn_phys, sizeof (scn->scn_phys));\n\n\t \n\tif (scn->scn_phys.scn_queue_obj != 0) {\n\t\tzap_cursor_t zc;\n\t\tzap_attribute_t za;\n\n\t\tfor (zap_cursor_init(&zc, dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj);\n\t\t    zap_cursor_retrieve(&zc, &za) == 0;\n\t\t    (void) zap_cursor_advance(&zc)) {\n\t\t\tscan_ds_queue_insert(scn,\n\t\t\t    zfs_strtonum(za.za_name, NULL),\n\t\t\t    za.za_first_integer);\n\t\t}\n\t\tzap_cursor_fini(&zc);\n\t}\n\n\tspa_scan_stat_init(spa);\n\tvdev_scan_stat_init(spa->spa_root_vdev);\n\n\treturn (0);\n}\n\nvoid\ndsl_scan_fini(dsl_pool_t *dp)\n{\n\tif (dp->dp_scan != NULL) {\n\t\tdsl_scan_t *scn = dp->dp_scan;\n\n\t\tif (scn->scn_taskq != NULL)\n\t\t\ttaskq_destroy(scn->scn_taskq);\n\n\t\tscan_ds_queue_clear(scn);\n\t\tavl_destroy(&scn->scn_queue);\n\t\tscan_ds_prefetch_queue_clear(scn);\n\t\tavl_destroy(&scn->scn_prefetch_queue);\n\n\t\tkmem_free(dp->dp_scan, sizeof (dsl_scan_t));\n\t\tdp->dp_scan = NULL;\n\t}\n}\n\nstatic boolean_t\ndsl_scan_restarting(dsl_scan_t *scn, dmu_tx_t *tx)\n{\n\treturn (scn->scn_restart_txg != 0 &&\n\t    scn->scn_restart_txg <= tx->tx_txg);\n}\n\nboolean_t\ndsl_scan_resilver_scheduled(dsl_pool_t *dp)\n{\n\treturn ((dp->dp_scan && dp->dp_scan->scn_restart_txg != 0) ||\n\t    (spa_async_tasks(dp->dp_spa) & SPA_ASYNC_RESILVER));\n}\n\nboolean_t\ndsl_scan_scrubbing(const dsl_pool_t *dp)\n{\n\tdsl_scan_phys_t *scn_phys = &dp->dp_scan->scn_phys;\n\n\treturn (scn_phys->scn_state == DSS_SCANNING &&\n\t    scn_phys->scn_func == POOL_SCAN_SCRUB);\n}\n\nboolean_t\ndsl_errorscrubbing(const dsl_pool_t *dp)\n{\n\tdsl_errorscrub_phys_t *errorscrub_phys = &dp->dp_scan->errorscrub_phys;\n\n\treturn (errorscrub_phys->dep_state == DSS_ERRORSCRUBBING &&\n\t    errorscrub_phys->dep_func == POOL_SCAN_ERRORSCRUB);\n}\n\nboolean_t\ndsl_errorscrub_is_paused(const dsl_scan_t *scn)\n{\n\treturn (dsl_errorscrubbing(scn->scn_dp) &&\n\t    scn->errorscrub_phys.dep_paused_flags);\n}\n\nboolean_t\ndsl_scan_is_paused_scrub(const dsl_scan_t *scn)\n{\n\treturn (dsl_scan_scrubbing(scn->scn_dp) &&\n\t    scn->scn_phys.scn_flags & DSF_SCRUB_PAUSED);\n}\n\nstatic void\ndsl_errorscrub_sync_state(dsl_scan_t *scn, dmu_tx_t *tx)\n{\n\tscn->errorscrub_phys.dep_cursor =\n\t    zap_cursor_serialize(&scn->errorscrub_cursor);\n\n\tVERIFY0(zap_update(scn->scn_dp->dp_meta_objset,\n\t    DMU_POOL_DIRECTORY_OBJECT,\n\t    DMU_POOL_ERRORSCRUB, sizeof (uint64_t), ERRORSCRUB_PHYS_NUMINTS,\n\t    &scn->errorscrub_phys, tx));\n}\n\nstatic void\ndsl_errorscrub_setup_sync(void *arg, dmu_tx_t *tx)\n{\n\tdsl_scan_t *scn = dmu_tx_pool(tx)->dp_scan;\n\tpool_scan_func_t *funcp = arg;\n\tdsl_pool_t *dp = scn->scn_dp;\n\tspa_t *spa = dp->dp_spa;\n\n\tASSERT(!dsl_scan_is_running(scn));\n\tASSERT(!dsl_errorscrubbing(scn->scn_dp));\n\tASSERT(*funcp > POOL_SCAN_NONE && *funcp < POOL_SCAN_FUNCS);\n\n\tmemset(&scn->errorscrub_phys, 0, sizeof (scn->errorscrub_phys));\n\tscn->errorscrub_phys.dep_func = *funcp;\n\tscn->errorscrub_phys.dep_state = DSS_ERRORSCRUBBING;\n\tscn->errorscrub_phys.dep_start_time = gethrestime_sec();\n\tscn->errorscrub_phys.dep_to_examine = spa_get_last_errlog_size(spa);\n\tscn->errorscrub_phys.dep_examined = 0;\n\tscn->errorscrub_phys.dep_errors = 0;\n\tscn->errorscrub_phys.dep_cursor = 0;\n\tzap_cursor_init_serialized(&scn->errorscrub_cursor,\n\t    spa->spa_meta_objset, spa->spa_errlog_last,\n\t    scn->errorscrub_phys.dep_cursor);\n\n\tvdev_config_dirty(spa->spa_root_vdev);\n\tspa_event_notify(spa, NULL, NULL, ESC_ZFS_ERRORSCRUB_START);\n\n\tdsl_errorscrub_sync_state(scn, tx);\n\n\tspa_history_log_internal(spa, \"error scrub setup\", tx,\n\t    \"func=%u mintxg=%u maxtxg=%llu\",\n\t    *funcp, 0, (u_longlong_t)tx->tx_txg);\n}\n\nstatic int\ndsl_errorscrub_setup_check(void *arg, dmu_tx_t *tx)\n{\n\t(void) arg;\n\tdsl_scan_t *scn = dmu_tx_pool(tx)->dp_scan;\n\n\tif (dsl_scan_is_running(scn) || (dsl_errorscrubbing(scn->scn_dp))) {\n\t\treturn (SET_ERROR(EBUSY));\n\t}\n\n\tif (spa_get_last_errlog_size(scn->scn_dp->dp_spa) == 0) {\n\t\treturn (ECANCELED);\n\t}\n\treturn (0);\n}\n\n \nstatic void\ndsl_scan_sync_state(dsl_scan_t *scn, dmu_tx_t *tx, state_sync_type_t sync_type)\n{\n\tint i;\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\n\tASSERT(sync_type != SYNC_MANDATORY || scn->scn_queues_pending == 0);\n\tif (scn->scn_queues_pending == 0) {\n\t\tfor (i = 0; i < spa->spa_root_vdev->vdev_children; i++) {\n\t\t\tvdev_t *vd = spa->spa_root_vdev->vdev_child[i];\n\t\t\tdsl_scan_io_queue_t *q = vd->vdev_scan_io_queue;\n\n\t\t\tif (q == NULL)\n\t\t\t\tcontinue;\n\n\t\t\tmutex_enter(&vd->vdev_scan_io_queue_lock);\n\t\t\tASSERT3P(avl_first(&q->q_sios_by_addr), ==, NULL);\n\t\t\tASSERT3P(zfs_btree_first(&q->q_exts_by_size, NULL), ==,\n\t\t\t    NULL);\n\t\t\tASSERT3P(range_tree_first(q->q_exts_by_addr), ==, NULL);\n\t\t\tmutex_exit(&vd->vdev_scan_io_queue_lock);\n\t\t}\n\n\t\tif (scn->scn_phys.scn_queue_obj != 0)\n\t\t\tscan_ds_queue_sync(scn, tx);\n\t\tVERIFY0(zap_update(scn->scn_dp->dp_meta_objset,\n\t\t    DMU_POOL_DIRECTORY_OBJECT,\n\t\t    DMU_POOL_SCAN, sizeof (uint64_t), SCAN_PHYS_NUMINTS,\n\t\t    &scn->scn_phys, tx));\n\t\tmemcpy(&scn->scn_phys_cached, &scn->scn_phys,\n\t\t    sizeof (scn->scn_phys));\n\n\t\tif (scn->scn_checkpointing)\n\t\t\tzfs_dbgmsg(\"finish scan checkpoint for %s\",\n\t\t\t    spa->spa_name);\n\n\t\tscn->scn_checkpointing = B_FALSE;\n\t\tscn->scn_last_checkpoint = ddi_get_lbolt();\n\t} else if (sync_type == SYNC_CACHED) {\n\t\tVERIFY0(zap_update(scn->scn_dp->dp_meta_objset,\n\t\t    DMU_POOL_DIRECTORY_OBJECT,\n\t\t    DMU_POOL_SCAN, sizeof (uint64_t), SCAN_PHYS_NUMINTS,\n\t\t    &scn->scn_phys_cached, tx));\n\t}\n}\n\nint\ndsl_scan_setup_check(void *arg, dmu_tx_t *tx)\n{\n\t(void) arg;\n\tdsl_scan_t *scn = dmu_tx_pool(tx)->dp_scan;\n\tvdev_t *rvd = scn->scn_dp->dp_spa->spa_root_vdev;\n\n\tif (dsl_scan_is_running(scn) || vdev_rebuild_active(rvd) ||\n\t    dsl_errorscrubbing(scn->scn_dp))\n\t\treturn (SET_ERROR(EBUSY));\n\n\treturn (0);\n}\n\nvoid\ndsl_scan_setup_sync(void *arg, dmu_tx_t *tx)\n{\n\t(void) arg;\n\tdsl_scan_t *scn = dmu_tx_pool(tx)->dp_scan;\n\tpool_scan_func_t *funcp = arg;\n\tdmu_object_type_t ot = 0;\n\tdsl_pool_t *dp = scn->scn_dp;\n\tspa_t *spa = dp->dp_spa;\n\n\tASSERT(!dsl_scan_is_running(scn));\n\tASSERT(*funcp > POOL_SCAN_NONE && *funcp < POOL_SCAN_FUNCS);\n\tmemset(&scn->scn_phys, 0, sizeof (scn->scn_phys));\n\n\t \n\tmemset(&scn->errorscrub_phys, 0, sizeof (scn->errorscrub_phys));\n\tdsl_errorscrub_sync_state(scn, tx);\n\n\tscn->scn_phys.scn_func = *funcp;\n\tscn->scn_phys.scn_state = DSS_SCANNING;\n\tscn->scn_phys.scn_min_txg = 0;\n\tscn->scn_phys.scn_max_txg = tx->tx_txg;\n\tscn->scn_phys.scn_ddt_class_max = DDT_CLASSES - 1;  \n\tscn->scn_phys.scn_start_time = gethrestime_sec();\n\tscn->scn_phys.scn_errors = 0;\n\tscn->scn_phys.scn_to_examine = spa->spa_root_vdev->vdev_stat.vs_alloc;\n\tscn->scn_issued_before_pass = 0;\n\tscn->scn_restart_txg = 0;\n\tscn->scn_done_txg = 0;\n\tscn->scn_last_checkpoint = 0;\n\tscn->scn_checkpointing = B_FALSE;\n\tspa_scan_stat_init(spa);\n\tvdev_scan_stat_init(spa->spa_root_vdev);\n\n\tif (DSL_SCAN_IS_SCRUB_RESILVER(scn)) {\n\t\tscn->scn_phys.scn_ddt_class_max = zfs_scrub_ddt_class_max;\n\n\t\t \n\t\tvdev_config_dirty(spa->spa_root_vdev);\n\n\t\tif (vdev_resilver_needed(spa->spa_root_vdev,\n\t\t    &scn->scn_phys.scn_min_txg, &scn->scn_phys.scn_max_txg)) {\n\t\t\tnvlist_t *aux = fnvlist_alloc();\n\t\t\tfnvlist_add_string(aux, ZFS_EV_RESILVER_TYPE,\n\t\t\t    \"healing\");\n\t\t\tspa_event_notify(spa, NULL, aux,\n\t\t\t    ESC_ZFS_RESILVER_START);\n\t\t\tnvlist_free(aux);\n\t\t} else {\n\t\t\tspa_event_notify(spa, NULL, NULL, ESC_ZFS_SCRUB_START);\n\t\t}\n\n\t\tspa->spa_scrub_started = B_TRUE;\n\t\t \n\t\tif (scn->scn_phys.scn_min_txg > TXG_INITIAL)\n\t\t\tscn->scn_phys.scn_ddt_class_max = DDT_CLASS_DITTO;\n\n\t\t \n\t\tif (scn->scn_phys.scn_func == POOL_SCAN_RESILVER) {\n\t\t\tvdev_t *rvd = spa->spa_root_vdev;\n\t\t\tfor (uint64_t i = 0; i < rvd->vdev_children; i++) {\n\t\t\t\tvdev_t *vd = rvd->vdev_child[i];\n\t\t\t\tvdev_rebuild_clear_sync(\n\t\t\t\t    (void *)(uintptr_t)vd->vdev_id, tx);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\n\tif (zfs_scan_blkstats) {\n\t\tif (dp->dp_blkstats == NULL) {\n\t\t\tdp->dp_blkstats =\n\t\t\t    vmem_alloc(sizeof (zfs_all_blkstats_t), KM_SLEEP);\n\t\t}\n\t\tmemset(&dp->dp_blkstats->zab_type, 0,\n\t\t    sizeof (dp->dp_blkstats->zab_type));\n\t} else {\n\t\tif (dp->dp_blkstats) {\n\t\t\tvmem_free(dp->dp_blkstats, sizeof (zfs_all_blkstats_t));\n\t\t\tdp->dp_blkstats = NULL;\n\t\t}\n\t}\n\n\tif (spa_version(spa) < SPA_VERSION_DSL_SCRUB)\n\t\tot = DMU_OT_ZAP_OTHER;\n\n\tscn->scn_phys.scn_queue_obj = zap_create(dp->dp_meta_objset,\n\t    ot ? ot : DMU_OT_SCAN_QUEUE, DMU_OT_NONE, 0, tx);\n\n\tmemcpy(&scn->scn_phys_cached, &scn->scn_phys, sizeof (scn->scn_phys));\n\n\tdsl_scan_sync_state(scn, tx, SYNC_MANDATORY);\n\n\tspa_history_log_internal(spa, \"scan setup\", tx,\n\t    \"func=%u mintxg=%llu maxtxg=%llu\",\n\t    *funcp, (u_longlong_t)scn->scn_phys.scn_min_txg,\n\t    (u_longlong_t)scn->scn_phys.scn_max_txg);\n}\n\n \nint\ndsl_scan(dsl_pool_t *dp, pool_scan_func_t func)\n{\n\tspa_t *spa = dp->dp_spa;\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\t \n\tspa_vdev_state_enter(spa, SCL_NONE);\n\tspa->spa_scrub_reopen = B_TRUE;\n\tvdev_reopen(spa->spa_root_vdev);\n\tspa->spa_scrub_reopen = B_FALSE;\n\t(void) spa_vdev_state_exit(spa, NULL, 0);\n\n\tif (func == POOL_SCAN_RESILVER) {\n\t\tdsl_scan_restart_resilver(spa->spa_dsl_pool, 0);\n\t\treturn (0);\n\t}\n\n\tif (func == POOL_SCAN_ERRORSCRUB) {\n\t\tif (dsl_errorscrub_is_paused(dp->dp_scan)) {\n\t\t\t \n\t\t\tint err = dsl_scrub_set_pause_resume(scn->scn_dp,\n\t\t\t    POOL_SCRUB_NORMAL);\n\t\t\tif (err == 0) {\n\t\t\t\tspa_event_notify(spa, NULL, NULL,\n\t\t\t\t    ESC_ZFS_ERRORSCRUB_RESUME);\n\t\t\t\treturn (ECANCELED);\n\t\t\t}\n\t\t\treturn (SET_ERROR(err));\n\t\t}\n\n\t\treturn (dsl_sync_task(spa_name(dp->dp_spa),\n\t\t    dsl_errorscrub_setup_check, dsl_errorscrub_setup_sync,\n\t\t    &func, 0, ZFS_SPACE_CHECK_RESERVED));\n\t}\n\n\tif (func == POOL_SCAN_SCRUB && dsl_scan_is_paused_scrub(scn)) {\n\t\t \n\t\tint err = dsl_scrub_set_pause_resume(scn->scn_dp,\n\t\t    POOL_SCRUB_NORMAL);\n\t\tif (err == 0) {\n\t\t\tspa_event_notify(spa, NULL, NULL, ESC_ZFS_SCRUB_RESUME);\n\t\t\treturn (SET_ERROR(ECANCELED));\n\t\t}\n\t\treturn (SET_ERROR(err));\n\t}\n\n\treturn (dsl_sync_task(spa_name(spa), dsl_scan_setup_check,\n\t    dsl_scan_setup_sync, &func, 0, ZFS_SPACE_CHECK_EXTRA_RESERVED));\n}\n\nstatic void\ndsl_errorscrub_done(dsl_scan_t *scn, boolean_t complete, dmu_tx_t *tx)\n{\n\tdsl_pool_t *dp = scn->scn_dp;\n\tspa_t *spa = dp->dp_spa;\n\n\tif (complete) {\n\t\tspa_event_notify(spa, NULL, NULL, ESC_ZFS_ERRORSCRUB_FINISH);\n\t\tspa_history_log_internal(spa, \"error scrub done\", tx,\n\t\t    \"errors=%llu\", (u_longlong_t)spa_approx_errlog_size(spa));\n\t} else {\n\t\tspa_history_log_internal(spa, \"error scrub canceled\", tx,\n\t\t    \"errors=%llu\", (u_longlong_t)spa_approx_errlog_size(spa));\n\t}\n\n\tscn->errorscrub_phys.dep_state = complete ? DSS_FINISHED : DSS_CANCELED;\n\tspa->spa_scrub_active = B_FALSE;\n\tspa_errlog_rotate(spa);\n\tscn->errorscrub_phys.dep_end_time = gethrestime_sec();\n\tzap_cursor_fini(&scn->errorscrub_cursor);\n\n\tif (spa->spa_errata == ZPOOL_ERRATA_ZOL_2094_SCRUB)\n\t\tspa->spa_errata = 0;\n\n\tASSERT(!dsl_errorscrubbing(scn->scn_dp));\n}\n\nstatic void\ndsl_scan_done(dsl_scan_t *scn, boolean_t complete, dmu_tx_t *tx)\n{\n\tstatic const char *old_names[] = {\n\t\t\"scrub_bookmark\",\n\t\t\"scrub_ddt_bookmark\",\n\t\t\"scrub_ddt_class_max\",\n\t\t\"scrub_queue\",\n\t\t\"scrub_min_txg\",\n\t\t\"scrub_max_txg\",\n\t\t\"scrub_func\",\n\t\t\"scrub_errors\",\n\t\tNULL\n\t};\n\n\tdsl_pool_t *dp = scn->scn_dp;\n\tspa_t *spa = dp->dp_spa;\n\tint i;\n\n\t \n\tfor (i = 0; old_names[i]; i++) {\n\t\t(void) zap_remove(dp->dp_meta_objset,\n\t\t    DMU_POOL_DIRECTORY_OBJECT, old_names[i], tx);\n\t}\n\n\tif (scn->scn_phys.scn_queue_obj != 0) {\n\t\tVERIFY0(dmu_object_free(dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj, tx));\n\t\tscn->scn_phys.scn_queue_obj = 0;\n\t}\n\tscan_ds_queue_clear(scn);\n\tscan_ds_prefetch_queue_clear(scn);\n\n\tscn->scn_phys.scn_flags &= ~DSF_SCRUB_PAUSED;\n\n\t \n\tif (!dsl_scan_is_running(scn)) {\n\t\tASSERT(!scn->scn_is_sorted);\n\t\treturn;\n\t}\n\n\tif (scn->scn_is_sorted) {\n\t\tscan_io_queues_destroy(scn);\n\t\tscn->scn_is_sorted = B_FALSE;\n\n\t\tif (scn->scn_taskq != NULL) {\n\t\t\ttaskq_destroy(scn->scn_taskq);\n\t\t\tscn->scn_taskq = NULL;\n\t\t}\n\t}\n\n\tscn->scn_phys.scn_state = complete ? DSS_FINISHED : DSS_CANCELED;\n\n\tspa_notify_waiters(spa);\n\n\tif (dsl_scan_restarting(scn, tx))\n\t\tspa_history_log_internal(spa, \"scan aborted, restarting\", tx,\n\t\t    \"errors=%llu\", (u_longlong_t)spa_approx_errlog_size(spa));\n\telse if (!complete)\n\t\tspa_history_log_internal(spa, \"scan cancelled\", tx,\n\t\t    \"errors=%llu\", (u_longlong_t)spa_approx_errlog_size(spa));\n\telse\n\t\tspa_history_log_internal(spa, \"scan done\", tx,\n\t\t    \"errors=%llu\", (u_longlong_t)spa_approx_errlog_size(spa));\n\n\tif (DSL_SCAN_IS_SCRUB_RESILVER(scn)) {\n\t\tspa->spa_scrub_active = B_FALSE;\n\n\t\t \n\t\tif (complete &&\n\t\t    !spa_feature_is_active(spa, SPA_FEATURE_POOL_CHECKPOINT)) {\n\t\t\tvdev_dtl_reassess(spa->spa_root_vdev, tx->tx_txg,\n\t\t\t    scn->scn_phys.scn_max_txg, B_TRUE, B_FALSE);\n\n\t\t\tif (scn->scn_phys.scn_min_txg) {\n\t\t\t\tnvlist_t *aux = fnvlist_alloc();\n\t\t\t\tfnvlist_add_string(aux, ZFS_EV_RESILVER_TYPE,\n\t\t\t\t    \"healing\");\n\t\t\t\tspa_event_notify(spa, NULL, aux,\n\t\t\t\t    ESC_ZFS_RESILVER_FINISH);\n\t\t\t\tnvlist_free(aux);\n\t\t\t} else {\n\t\t\t\tspa_event_notify(spa, NULL, NULL,\n\t\t\t\t    ESC_ZFS_SCRUB_FINISH);\n\t\t\t}\n\t\t} else {\n\t\t\tvdev_dtl_reassess(spa->spa_root_vdev, tx->tx_txg,\n\t\t\t    0, B_TRUE, B_FALSE);\n\t\t}\n\t\tspa_errlog_rotate(spa);\n\n\t\t \n\t\tspa->spa_scrub_started = B_FALSE;\n\n\t\t \n\t\tspa_async_request(spa, SPA_ASYNC_RESILVER_DONE);\n\n\t\t \n\t\tif (spa_feature_is_enabled(spa, SPA_FEATURE_RESILVER_DEFER) &&\n\t\t    vdev_clear_resilver_deferred(spa->spa_root_vdev, tx)) {\n\t\t\tspa_history_log_internal(spa,\n\t\t\t    \"starting deferred resilver\", tx, \"errors=%llu\",\n\t\t\t    (u_longlong_t)spa_approx_errlog_size(spa));\n\t\t\tspa_async_request(spa, SPA_ASYNC_RESILVER);\n\t\t}\n\n\t\t \n\t\tif (complete)\n\t\t\tzfs_ereport_clear(spa, NULL);\n\t}\n\n\tscn->scn_phys.scn_end_time = gethrestime_sec();\n\n\tif (spa->spa_errata == ZPOOL_ERRATA_ZOL_2094_SCRUB)\n\t\tspa->spa_errata = 0;\n\n\tASSERT(!dsl_scan_is_running(scn));\n}\n\nstatic int\ndsl_errorscrub_pause_resume_check(void *arg, dmu_tx_t *tx)\n{\n\tpool_scrub_cmd_t *cmd = arg;\n\tdsl_pool_t *dp = dmu_tx_pool(tx);\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\tif (*cmd == POOL_SCRUB_PAUSE) {\n\t\t \n\t\tif (!dsl_errorscrubbing(dp))\n\t\t\treturn (SET_ERROR(ENOENT));\n\n\t\t \n\t\tif (dsl_errorscrub_is_paused(scn))\n\t\t\treturn (SET_ERROR(EBUSY));\n\t} else if (*cmd != POOL_SCRUB_NORMAL) {\n\t\treturn (SET_ERROR(ENOTSUP));\n\t}\n\n\treturn (0);\n}\n\nstatic void\ndsl_errorscrub_pause_resume_sync(void *arg, dmu_tx_t *tx)\n{\n\tpool_scrub_cmd_t *cmd = arg;\n\tdsl_pool_t *dp = dmu_tx_pool(tx);\n\tspa_t *spa = dp->dp_spa;\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\tif (*cmd == POOL_SCRUB_PAUSE) {\n\t\tspa->spa_scan_pass_errorscrub_pause = gethrestime_sec();\n\t\tscn->errorscrub_phys.dep_paused_flags = B_TRUE;\n\t\tdsl_errorscrub_sync_state(scn, tx);\n\t\tspa_event_notify(spa, NULL, NULL, ESC_ZFS_ERRORSCRUB_PAUSED);\n\t} else {\n\t\tASSERT3U(*cmd, ==, POOL_SCRUB_NORMAL);\n\t\tif (dsl_errorscrub_is_paused(scn)) {\n\t\t\t \n\t\t\tspa->spa_scan_pass_errorscrub_spent_paused +=\n\t\t\t    gethrestime_sec() -\n\t\t\t    spa->spa_scan_pass_errorscrub_pause;\n\n\t\t\tspa->spa_scan_pass_errorscrub_pause = 0;\n\t\t\tscn->errorscrub_phys.dep_paused_flags = B_FALSE;\n\n\t\t\tzap_cursor_init_serialized(\n\t\t\t    &scn->errorscrub_cursor,\n\t\t\t    spa->spa_meta_objset, spa->spa_errlog_last,\n\t\t\t    scn->errorscrub_phys.dep_cursor);\n\n\t\t\tdsl_errorscrub_sync_state(scn, tx);\n\t\t}\n\t}\n}\n\nstatic int\ndsl_errorscrub_cancel_check(void *arg, dmu_tx_t *tx)\n{\n\t(void) arg;\n\tdsl_scan_t *scn = dmu_tx_pool(tx)->dp_scan;\n\t \n\tif (!dsl_errorscrubbing(scn->scn_dp))\n\t\treturn (SET_ERROR(ENOENT));\n\treturn (0);\n}\n\nstatic void\ndsl_errorscrub_cancel_sync(void *arg, dmu_tx_t *tx)\n{\n\t(void) arg;\n\tdsl_scan_t *scn = dmu_tx_pool(tx)->dp_scan;\n\n\tdsl_errorscrub_done(scn, B_FALSE, tx);\n\tdsl_errorscrub_sync_state(scn, tx);\n\tspa_event_notify(scn->scn_dp->dp_spa, NULL, NULL,\n\t    ESC_ZFS_ERRORSCRUB_ABORT);\n}\n\nstatic int\ndsl_scan_cancel_check(void *arg, dmu_tx_t *tx)\n{\n\t(void) arg;\n\tdsl_scan_t *scn = dmu_tx_pool(tx)->dp_scan;\n\n\tif (!dsl_scan_is_running(scn))\n\t\treturn (SET_ERROR(ENOENT));\n\treturn (0);\n}\n\nstatic void\ndsl_scan_cancel_sync(void *arg, dmu_tx_t *tx)\n{\n\t(void) arg;\n\tdsl_scan_t *scn = dmu_tx_pool(tx)->dp_scan;\n\n\tdsl_scan_done(scn, B_FALSE, tx);\n\tdsl_scan_sync_state(scn, tx, SYNC_MANDATORY);\n\tspa_event_notify(scn->scn_dp->dp_spa, NULL, NULL, ESC_ZFS_SCRUB_ABORT);\n}\n\nint\ndsl_scan_cancel(dsl_pool_t *dp)\n{\n\tif (dsl_errorscrubbing(dp)) {\n\t\treturn (dsl_sync_task(spa_name(dp->dp_spa),\n\t\t    dsl_errorscrub_cancel_check, dsl_errorscrub_cancel_sync,\n\t\t    NULL, 3, ZFS_SPACE_CHECK_RESERVED));\n\t}\n\treturn (dsl_sync_task(spa_name(dp->dp_spa), dsl_scan_cancel_check,\n\t    dsl_scan_cancel_sync, NULL, 3, ZFS_SPACE_CHECK_RESERVED));\n}\n\nstatic int\ndsl_scrub_pause_resume_check(void *arg, dmu_tx_t *tx)\n{\n\tpool_scrub_cmd_t *cmd = arg;\n\tdsl_pool_t *dp = dmu_tx_pool(tx);\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\tif (*cmd == POOL_SCRUB_PAUSE) {\n\t\t \n\t\tif (!dsl_scan_scrubbing(dp))\n\t\t\treturn (SET_ERROR(ENOENT));\n\n\t\t \n\t\tif (dsl_scan_is_paused_scrub(scn))\n\t\t\treturn (SET_ERROR(EBUSY));\n\t} else if (*cmd != POOL_SCRUB_NORMAL) {\n\t\treturn (SET_ERROR(ENOTSUP));\n\t}\n\n\treturn (0);\n}\n\nstatic void\ndsl_scrub_pause_resume_sync(void *arg, dmu_tx_t *tx)\n{\n\tpool_scrub_cmd_t *cmd = arg;\n\tdsl_pool_t *dp = dmu_tx_pool(tx);\n\tspa_t *spa = dp->dp_spa;\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\tif (*cmd == POOL_SCRUB_PAUSE) {\n\t\t \n\t\tspa->spa_scan_pass_scrub_pause = gethrestime_sec();\n\t\tscn->scn_phys.scn_flags |= DSF_SCRUB_PAUSED;\n\t\tscn->scn_phys_cached.scn_flags |= DSF_SCRUB_PAUSED;\n\t\tdsl_scan_sync_state(scn, tx, SYNC_CACHED);\n\t\tspa_event_notify(spa, NULL, NULL, ESC_ZFS_SCRUB_PAUSED);\n\t\tspa_notify_waiters(spa);\n\t} else {\n\t\tASSERT3U(*cmd, ==, POOL_SCRUB_NORMAL);\n\t\tif (dsl_scan_is_paused_scrub(scn)) {\n\t\t\t \n\t\t\tspa->spa_scan_pass_scrub_spent_paused +=\n\t\t\t    gethrestime_sec() - spa->spa_scan_pass_scrub_pause;\n\t\t\tspa->spa_scan_pass_scrub_pause = 0;\n\t\t\tscn->scn_phys.scn_flags &= ~DSF_SCRUB_PAUSED;\n\t\t\tscn->scn_phys_cached.scn_flags &= ~DSF_SCRUB_PAUSED;\n\t\t\tdsl_scan_sync_state(scn, tx, SYNC_CACHED);\n\t\t}\n\t}\n}\n\n \nint\ndsl_scrub_set_pause_resume(const dsl_pool_t *dp, pool_scrub_cmd_t cmd)\n{\n\tif (dsl_errorscrubbing(dp)) {\n\t\treturn (dsl_sync_task(spa_name(dp->dp_spa),\n\t\t    dsl_errorscrub_pause_resume_check,\n\t\t    dsl_errorscrub_pause_resume_sync, &cmd, 3,\n\t\t    ZFS_SPACE_CHECK_RESERVED));\n\t}\n\treturn (dsl_sync_task(spa_name(dp->dp_spa),\n\t    dsl_scrub_pause_resume_check, dsl_scrub_pause_resume_sync, &cmd, 3,\n\t    ZFS_SPACE_CHECK_RESERVED));\n}\n\n\n \nvoid\ndsl_scan_restart_resilver(dsl_pool_t *dp, uint64_t txg)\n{\n\tif (txg == 0) {\n\t\tdmu_tx_t *tx;\n\t\ttx = dmu_tx_create_dd(dp->dp_mos_dir);\n\t\tVERIFY(0 == dmu_tx_assign(tx, TXG_WAIT));\n\n\t\ttxg = dmu_tx_get_txg(tx);\n\t\tdp->dp_scan->scn_restart_txg = txg;\n\t\tdmu_tx_commit(tx);\n\t} else {\n\t\tdp->dp_scan->scn_restart_txg = txg;\n\t}\n\tzfs_dbgmsg(\"restarting resilver for %s at txg=%llu\",\n\t    dp->dp_spa->spa_name, (longlong_t)txg);\n}\n\nvoid\ndsl_free(dsl_pool_t *dp, uint64_t txg, const blkptr_t *bp)\n{\n\tzio_free(dp->dp_spa, txg, bp);\n}\n\nvoid\ndsl_free_sync(zio_t *pio, dsl_pool_t *dp, uint64_t txg, const blkptr_t *bpp)\n{\n\tASSERT(dsl_pool_sync_context(dp));\n\tzio_nowait(zio_free_sync(pio, dp->dp_spa, txg, bpp, pio->io_flags));\n}\n\nstatic int\nscan_ds_queue_compare(const void *a, const void *b)\n{\n\tconst scan_ds_t *sds_a = a, *sds_b = b;\n\n\tif (sds_a->sds_dsobj < sds_b->sds_dsobj)\n\t\treturn (-1);\n\tif (sds_a->sds_dsobj == sds_b->sds_dsobj)\n\t\treturn (0);\n\treturn (1);\n}\n\nstatic void\nscan_ds_queue_clear(dsl_scan_t *scn)\n{\n\tvoid *cookie = NULL;\n\tscan_ds_t *sds;\n\twhile ((sds = avl_destroy_nodes(&scn->scn_queue, &cookie)) != NULL) {\n\t\tkmem_free(sds, sizeof (*sds));\n\t}\n}\n\nstatic boolean_t\nscan_ds_queue_contains(dsl_scan_t *scn, uint64_t dsobj, uint64_t *txg)\n{\n\tscan_ds_t srch, *sds;\n\n\tsrch.sds_dsobj = dsobj;\n\tsds = avl_find(&scn->scn_queue, &srch, NULL);\n\tif (sds != NULL && txg != NULL)\n\t\t*txg = sds->sds_txg;\n\treturn (sds != NULL);\n}\n\nstatic void\nscan_ds_queue_insert(dsl_scan_t *scn, uint64_t dsobj, uint64_t txg)\n{\n\tscan_ds_t *sds;\n\tavl_index_t where;\n\n\tsds = kmem_zalloc(sizeof (*sds), KM_SLEEP);\n\tsds->sds_dsobj = dsobj;\n\tsds->sds_txg = txg;\n\n\tVERIFY3P(avl_find(&scn->scn_queue, sds, &where), ==, NULL);\n\tavl_insert(&scn->scn_queue, sds, where);\n}\n\nstatic void\nscan_ds_queue_remove(dsl_scan_t *scn, uint64_t dsobj)\n{\n\tscan_ds_t srch, *sds;\n\n\tsrch.sds_dsobj = dsobj;\n\n\tsds = avl_find(&scn->scn_queue, &srch, NULL);\n\tVERIFY(sds != NULL);\n\tavl_remove(&scn->scn_queue, sds);\n\tkmem_free(sds, sizeof (*sds));\n}\n\nstatic void\nscan_ds_queue_sync(dsl_scan_t *scn, dmu_tx_t *tx)\n{\n\tdsl_pool_t *dp = scn->scn_dp;\n\tspa_t *spa = dp->dp_spa;\n\tdmu_object_type_t ot = (spa_version(spa) >= SPA_VERSION_DSL_SCRUB) ?\n\t    DMU_OT_SCAN_QUEUE : DMU_OT_ZAP_OTHER;\n\n\tASSERT0(scn->scn_queues_pending);\n\tASSERT(scn->scn_phys.scn_queue_obj != 0);\n\n\tVERIFY0(dmu_object_free(dp->dp_meta_objset,\n\t    scn->scn_phys.scn_queue_obj, tx));\n\tscn->scn_phys.scn_queue_obj = zap_create(dp->dp_meta_objset, ot,\n\t    DMU_OT_NONE, 0, tx);\n\tfor (scan_ds_t *sds = avl_first(&scn->scn_queue);\n\t    sds != NULL; sds = AVL_NEXT(&scn->scn_queue, sds)) {\n\t\tVERIFY0(zap_add_int_key(dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj, sds->sds_dsobj,\n\t\t    sds->sds_txg, tx));\n\t}\n}\n\n \nstatic boolean_t\ndsl_scan_should_clear(dsl_scan_t *scn)\n{\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\tvdev_t *rvd = scn->scn_dp->dp_spa->spa_root_vdev;\n\tuint64_t alloc, mlim_hard, mlim_soft, mused;\n\n\talloc = metaslab_class_get_alloc(spa_normal_class(spa));\n\talloc += metaslab_class_get_alloc(spa_special_class(spa));\n\talloc += metaslab_class_get_alloc(spa_dedup_class(spa));\n\n\tmlim_hard = MAX((physmem / zfs_scan_mem_lim_fact) * PAGESIZE,\n\t    zfs_scan_mem_lim_min);\n\tmlim_hard = MIN(mlim_hard, alloc / 20);\n\tmlim_soft = mlim_hard - MIN(mlim_hard / zfs_scan_mem_lim_soft_fact,\n\t    zfs_scan_mem_lim_soft_max);\n\tmused = 0;\n\tfor (uint64_t i = 0; i < rvd->vdev_children; i++) {\n\t\tvdev_t *tvd = rvd->vdev_child[i];\n\t\tdsl_scan_io_queue_t *queue;\n\n\t\tmutex_enter(&tvd->vdev_scan_io_queue_lock);\n\t\tqueue = tvd->vdev_scan_io_queue;\n\t\tif (queue != NULL) {\n\t\t\t \n\t\t\tmused += zfs_btree_numnodes(&queue->q_exts_by_size) *\n\t\t\t    ((sizeof (range_seg_gap_t) + sizeof (uint64_t)) *\n\t\t\t    3 / 2) + queue->q_sio_memused;\n\t\t}\n\t\tmutex_exit(&tvd->vdev_scan_io_queue_lock);\n\t}\n\n\tdprintf(\"current scan memory usage: %llu bytes\\n\", (longlong_t)mused);\n\n\tif (mused == 0)\n\t\tASSERT0(scn->scn_queues_pending);\n\n\t \n\tif (mused >= mlim_hard)\n\t\treturn (B_TRUE);\n\telse if (mused < mlim_soft)\n\t\treturn (B_FALSE);\n\telse\n\t\treturn (scn->scn_clearing);\n}\n\nstatic boolean_t\ndsl_scan_check_suspend(dsl_scan_t *scn, const zbookmark_phys_t *zb)\n{\n\t \n\tif (zb && (int64_t)zb->zb_object < 0)\n\t\treturn (B_FALSE);\n\n\tif (scn->scn_suspending)\n\t\treturn (B_TRUE);  \n\n\tif (!ZB_IS_ZERO(&scn->scn_phys.scn_bookmark))\n\t\treturn (B_FALSE);  \n\n\t \n\tif (zb && (zb->zb_level != 0 && zb->zb_level != ZB_ROOT_LEVEL))\n\t\treturn (B_FALSE);\n\n\t \n\tuint64_t curr_time_ns = gethrtime();\n\tuint64_t scan_time_ns = curr_time_ns - scn->scn_sync_start_time;\n\tuint64_t sync_time_ns = curr_time_ns -\n\t    scn->scn_dp->dp_spa->spa_sync_starttime;\n\tuint64_t dirty_min_bytes = zfs_dirty_data_max *\n\t    zfs_vdev_async_write_active_min_dirty_percent / 100;\n\tuint_t mintime = (scn->scn_phys.scn_func == POOL_SCAN_RESILVER) ?\n\t    zfs_resilver_min_time_ms : zfs_scrub_min_time_ms;\n\n\tif ((NSEC2MSEC(scan_time_ns) > mintime &&\n\t    (scn->scn_dp->dp_dirty_total >= dirty_min_bytes ||\n\t    txg_sync_waiting(scn->scn_dp) ||\n\t    NSEC2SEC(sync_time_ns) >= zfs_txg_timeout)) ||\n\t    spa_shutting_down(scn->scn_dp->dp_spa) ||\n\t    (zfs_scan_strict_mem_lim && dsl_scan_should_clear(scn))) {\n\t\tif (zb && zb->zb_level == ZB_ROOT_LEVEL) {\n\t\t\tdprintf(\"suspending at first available bookmark \"\n\t\t\t    \"%llx/%llx/%llx/%llx\\n\",\n\t\t\t    (longlong_t)zb->zb_objset,\n\t\t\t    (longlong_t)zb->zb_object,\n\t\t\t    (longlong_t)zb->zb_level,\n\t\t\t    (longlong_t)zb->zb_blkid);\n\t\t\tSET_BOOKMARK(&scn->scn_phys.scn_bookmark,\n\t\t\t    zb->zb_objset, 0, 0, 0);\n\t\t} else if (zb != NULL) {\n\t\t\tdprintf(\"suspending at bookmark %llx/%llx/%llx/%llx\\n\",\n\t\t\t    (longlong_t)zb->zb_objset,\n\t\t\t    (longlong_t)zb->zb_object,\n\t\t\t    (longlong_t)zb->zb_level,\n\t\t\t    (longlong_t)zb->zb_blkid);\n\t\t\tscn->scn_phys.scn_bookmark = *zb;\n\t\t} else {\n#ifdef ZFS_DEBUG\n\t\t\tdsl_scan_phys_t *scnp = &scn->scn_phys;\n\t\t\tdprintf(\"suspending at at DDT bookmark \"\n\t\t\t    \"%llx/%llx/%llx/%llx\\n\",\n\t\t\t    (longlong_t)scnp->scn_ddt_bookmark.ddb_class,\n\t\t\t    (longlong_t)scnp->scn_ddt_bookmark.ddb_type,\n\t\t\t    (longlong_t)scnp->scn_ddt_bookmark.ddb_checksum,\n\t\t\t    (longlong_t)scnp->scn_ddt_bookmark.ddb_cursor);\n#endif\n\t\t}\n\t\tscn->scn_suspending = B_TRUE;\n\t\treturn (B_TRUE);\n\t}\n\treturn (B_FALSE);\n}\n\nstatic boolean_t\ndsl_error_scrub_check_suspend(dsl_scan_t *scn, const zbookmark_phys_t *zb)\n{\n\t \n\tuint64_t curr_time_ns = gethrtime();\n\tuint64_t error_scrub_time_ns = curr_time_ns - scn->scn_sync_start_time;\n\tuint64_t sync_time_ns = curr_time_ns -\n\t    scn->scn_dp->dp_spa->spa_sync_starttime;\n\tint mintime = zfs_scrub_min_time_ms;\n\n\tif ((NSEC2MSEC(error_scrub_time_ns) > mintime &&\n\t    (txg_sync_waiting(scn->scn_dp) ||\n\t    NSEC2SEC(sync_time_ns) >= zfs_txg_timeout)) ||\n\t    spa_shutting_down(scn->scn_dp->dp_spa)) {\n\t\tif (zb) {\n\t\t\tdprintf(\"error scrub suspending at bookmark \"\n\t\t\t    \"%llx/%llx/%llx/%llx\\n\",\n\t\t\t    (longlong_t)zb->zb_objset,\n\t\t\t    (longlong_t)zb->zb_object,\n\t\t\t    (longlong_t)zb->zb_level,\n\t\t\t    (longlong_t)zb->zb_blkid);\n\t\t}\n\t\treturn (B_TRUE);\n\t}\n\treturn (B_FALSE);\n}\n\ntypedef struct zil_scan_arg {\n\tdsl_pool_t\t*zsa_dp;\n\tzil_header_t\t*zsa_zh;\n} zil_scan_arg_t;\n\nstatic int\ndsl_scan_zil_block(zilog_t *zilog, const blkptr_t *bp, void *arg,\n    uint64_t claim_txg)\n{\n\t(void) zilog;\n\tzil_scan_arg_t *zsa = arg;\n\tdsl_pool_t *dp = zsa->zsa_dp;\n\tdsl_scan_t *scn = dp->dp_scan;\n\tzil_header_t *zh = zsa->zsa_zh;\n\tzbookmark_phys_t zb;\n\n\tASSERT(!BP_IS_REDACTED(bp));\n\tif (BP_IS_HOLE(bp) || bp->blk_birth <= scn->scn_phys.scn_cur_min_txg)\n\t\treturn (0);\n\n\t \n\tif (claim_txg == 0 && bp->blk_birth >= spa_min_claim_txg(dp->dp_spa))\n\t\treturn (0);\n\n\tSET_BOOKMARK(&zb, zh->zh_log.blk_cksum.zc_word[ZIL_ZC_OBJSET],\n\t    ZB_ZIL_OBJECT, ZB_ZIL_LEVEL, bp->blk_cksum.zc_word[ZIL_ZC_SEQ]);\n\n\tVERIFY(0 == scan_funcs[scn->scn_phys.scn_func](dp, bp, &zb));\n\treturn (0);\n}\n\nstatic int\ndsl_scan_zil_record(zilog_t *zilog, const lr_t *lrc, void *arg,\n    uint64_t claim_txg)\n{\n\t(void) zilog;\n\tif (lrc->lrc_txtype == TX_WRITE) {\n\t\tzil_scan_arg_t *zsa = arg;\n\t\tdsl_pool_t *dp = zsa->zsa_dp;\n\t\tdsl_scan_t *scn = dp->dp_scan;\n\t\tzil_header_t *zh = zsa->zsa_zh;\n\t\tconst lr_write_t *lr = (const lr_write_t *)lrc;\n\t\tconst blkptr_t *bp = &lr->lr_blkptr;\n\t\tzbookmark_phys_t zb;\n\n\t\tASSERT(!BP_IS_REDACTED(bp));\n\t\tif (BP_IS_HOLE(bp) ||\n\t\t    bp->blk_birth <= scn->scn_phys.scn_cur_min_txg)\n\t\t\treturn (0);\n\n\t\t \n\t\tif (claim_txg == 0 || bp->blk_birth < claim_txg)\n\t\t\treturn (0);\n\n\t\tASSERT3U(BP_GET_LSIZE(bp), !=, 0);\n\t\tSET_BOOKMARK(&zb, zh->zh_log.blk_cksum.zc_word[ZIL_ZC_OBJSET],\n\t\t    lr->lr_foid, ZB_ZIL_LEVEL,\n\t\t    lr->lr_offset / BP_GET_LSIZE(bp));\n\n\t\tVERIFY(0 == scan_funcs[scn->scn_phys.scn_func](dp, bp, &zb));\n\t}\n\treturn (0);\n}\n\nstatic void\ndsl_scan_zil(dsl_pool_t *dp, zil_header_t *zh)\n{\n\tuint64_t claim_txg = zh->zh_claim_txg;\n\tzil_scan_arg_t zsa = { dp, zh };\n\tzilog_t *zilog;\n\n\tASSERT(spa_writeable(dp->dp_spa));\n\n\t \n\tif (claim_txg == 0)\n\t\treturn;\n\n\tzilog = zil_alloc(dp->dp_meta_objset, zh);\n\n\t(void) zil_parse(zilog, dsl_scan_zil_block, dsl_scan_zil_record, &zsa,\n\t    claim_txg, B_FALSE);\n\n\tzil_free(zilog);\n}\n\n \nstatic int\nscan_prefetch_queue_compare(const void *a, const void *b)\n{\n\tconst scan_prefetch_issue_ctx_t *spic_a = a, *spic_b = b;\n\tconst scan_prefetch_ctx_t *spc_a = spic_a->spic_spc;\n\tconst scan_prefetch_ctx_t *spc_b = spic_b->spic_spc;\n\n\treturn (zbookmark_compare(spc_a->spc_datablkszsec,\n\t    spc_a->spc_indblkshift, spc_b->spc_datablkszsec,\n\t    spc_b->spc_indblkshift, &spic_a->spic_zb, &spic_b->spic_zb));\n}\n\nstatic void\nscan_prefetch_ctx_rele(scan_prefetch_ctx_t *spc, const void *tag)\n{\n\tif (zfs_refcount_remove(&spc->spc_refcnt, tag) == 0) {\n\t\tzfs_refcount_destroy(&spc->spc_refcnt);\n\t\tkmem_free(spc, sizeof (scan_prefetch_ctx_t));\n\t}\n}\n\nstatic scan_prefetch_ctx_t *\nscan_prefetch_ctx_create(dsl_scan_t *scn, dnode_phys_t *dnp, const void *tag)\n{\n\tscan_prefetch_ctx_t *spc;\n\n\tspc = kmem_alloc(sizeof (scan_prefetch_ctx_t), KM_SLEEP);\n\tzfs_refcount_create(&spc->spc_refcnt);\n\tzfs_refcount_add(&spc->spc_refcnt, tag);\n\tspc->spc_scn = scn;\n\tif (dnp != NULL) {\n\t\tspc->spc_datablkszsec = dnp->dn_datablkszsec;\n\t\tspc->spc_indblkshift = dnp->dn_indblkshift;\n\t\tspc->spc_root = B_FALSE;\n\t} else {\n\t\tspc->spc_datablkszsec = 0;\n\t\tspc->spc_indblkshift = 0;\n\t\tspc->spc_root = B_TRUE;\n\t}\n\n\treturn (spc);\n}\n\nstatic void\nscan_prefetch_ctx_add_ref(scan_prefetch_ctx_t *spc, const void *tag)\n{\n\tzfs_refcount_add(&spc->spc_refcnt, tag);\n}\n\nstatic void\nscan_ds_prefetch_queue_clear(dsl_scan_t *scn)\n{\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\tvoid *cookie = NULL;\n\tscan_prefetch_issue_ctx_t *spic = NULL;\n\n\tmutex_enter(&spa->spa_scrub_lock);\n\twhile ((spic = avl_destroy_nodes(&scn->scn_prefetch_queue,\n\t    &cookie)) != NULL) {\n\t\tscan_prefetch_ctx_rele(spic->spic_spc, scn);\n\t\tkmem_free(spic, sizeof (scan_prefetch_issue_ctx_t));\n\t}\n\tmutex_exit(&spa->spa_scrub_lock);\n}\n\nstatic boolean_t\ndsl_scan_check_prefetch_resume(scan_prefetch_ctx_t *spc,\n    const zbookmark_phys_t *zb)\n{\n\tzbookmark_phys_t *last_zb = &spc->spc_scn->scn_prefetch_bookmark;\n\tdnode_phys_t tmp_dnp;\n\tdnode_phys_t *dnp = (spc->spc_root) ? NULL : &tmp_dnp;\n\n\tif (zb->zb_objset != last_zb->zb_objset)\n\t\treturn (B_TRUE);\n\tif ((int64_t)zb->zb_object < 0)\n\t\treturn (B_FALSE);\n\n\ttmp_dnp.dn_datablkszsec = spc->spc_datablkszsec;\n\ttmp_dnp.dn_indblkshift = spc->spc_indblkshift;\n\n\tif (zbookmark_subtree_completed(dnp, zb, last_zb))\n\t\treturn (B_TRUE);\n\n\treturn (B_FALSE);\n}\n\nstatic void\ndsl_scan_prefetch(scan_prefetch_ctx_t *spc, blkptr_t *bp, zbookmark_phys_t *zb)\n{\n\tavl_index_t idx;\n\tdsl_scan_t *scn = spc->spc_scn;\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\tscan_prefetch_issue_ctx_t *spic;\n\n\tif (zfs_no_scrub_prefetch || BP_IS_REDACTED(bp))\n\t\treturn;\n\n\tif (BP_IS_HOLE(bp) || bp->blk_birth <= scn->scn_phys.scn_cur_min_txg ||\n\t    (BP_GET_LEVEL(bp) == 0 && BP_GET_TYPE(bp) != DMU_OT_DNODE &&\n\t    BP_GET_TYPE(bp) != DMU_OT_OBJSET))\n\t\treturn;\n\n\tif (dsl_scan_check_prefetch_resume(spc, zb))\n\t\treturn;\n\n\tscan_prefetch_ctx_add_ref(spc, scn);\n\tspic = kmem_alloc(sizeof (scan_prefetch_issue_ctx_t), KM_SLEEP);\n\tspic->spic_spc = spc;\n\tspic->spic_bp = *bp;\n\tspic->spic_zb = *zb;\n\n\t \n\tmutex_enter(&spa->spa_scrub_lock);\n\tif (avl_find(&scn->scn_prefetch_queue, spic, &idx) != NULL) {\n\t\t \n\t\tkmem_free(spic, sizeof (scan_prefetch_issue_ctx_t));\n\t\tscan_prefetch_ctx_rele(spc, scn);\n\t\tmutex_exit(&spa->spa_scrub_lock);\n\t\treturn;\n\t}\n\n\tavl_insert(&scn->scn_prefetch_queue, spic, idx);\n\tcv_broadcast(&spa->spa_scrub_io_cv);\n\tmutex_exit(&spa->spa_scrub_lock);\n}\n\nstatic void\ndsl_scan_prefetch_dnode(dsl_scan_t *scn, dnode_phys_t *dnp,\n    uint64_t objset, uint64_t object)\n{\n\tint i;\n\tzbookmark_phys_t zb;\n\tscan_prefetch_ctx_t *spc;\n\n\tif (dnp->dn_nblkptr == 0 && !(dnp->dn_flags & DNODE_FLAG_SPILL_BLKPTR))\n\t\treturn;\n\n\tSET_BOOKMARK(&zb, objset, object, 0, 0);\n\n\tspc = scan_prefetch_ctx_create(scn, dnp, FTAG);\n\n\tfor (i = 0; i < dnp->dn_nblkptr; i++) {\n\t\tzb.zb_level = BP_GET_LEVEL(&dnp->dn_blkptr[i]);\n\t\tzb.zb_blkid = i;\n\t\tdsl_scan_prefetch(spc, &dnp->dn_blkptr[i], &zb);\n\t}\n\n\tif (dnp->dn_flags & DNODE_FLAG_SPILL_BLKPTR) {\n\t\tzb.zb_level = 0;\n\t\tzb.zb_blkid = DMU_SPILL_BLKID;\n\t\tdsl_scan_prefetch(spc, DN_SPILL_BLKPTR(dnp), &zb);\n\t}\n\n\tscan_prefetch_ctx_rele(spc, FTAG);\n}\n\nstatic void\ndsl_scan_prefetch_cb(zio_t *zio, const zbookmark_phys_t *zb, const blkptr_t *bp,\n    arc_buf_t *buf, void *private)\n{\n\t(void) zio;\n\tscan_prefetch_ctx_t *spc = private;\n\tdsl_scan_t *scn = spc->spc_scn;\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\n\t \n\tmutex_enter(&spa->spa_scrub_lock);\n\tASSERT3U(spa->spa_scrub_inflight, >=, BP_GET_PSIZE(bp));\n\tspa->spa_scrub_inflight -= BP_GET_PSIZE(bp);\n\tcv_broadcast(&spa->spa_scrub_io_cv);\n\tmutex_exit(&spa->spa_scrub_lock);\n\n\t \n\tif (buf == NULL || scn->scn_prefetch_stop)\n\t\tgoto out;\n\n\tif (BP_GET_LEVEL(bp) > 0) {\n\t\tint i;\n\t\tblkptr_t *cbp;\n\t\tint epb = BP_GET_LSIZE(bp) >> SPA_BLKPTRSHIFT;\n\t\tzbookmark_phys_t czb;\n\n\t\tfor (i = 0, cbp = buf->b_data; i < epb; i++, cbp++) {\n\t\t\tSET_BOOKMARK(&czb, zb->zb_objset, zb->zb_object,\n\t\t\t    zb->zb_level - 1, zb->zb_blkid * epb + i);\n\t\t\tdsl_scan_prefetch(spc, cbp, &czb);\n\t\t}\n\t} else if (BP_GET_TYPE(bp) == DMU_OT_DNODE) {\n\t\tdnode_phys_t *cdnp;\n\t\tint i;\n\t\tint epb = BP_GET_LSIZE(bp) >> DNODE_SHIFT;\n\n\t\tfor (i = 0, cdnp = buf->b_data; i < epb;\n\t\t    i += cdnp->dn_extra_slots + 1,\n\t\t    cdnp += cdnp->dn_extra_slots + 1) {\n\t\t\tdsl_scan_prefetch_dnode(scn, cdnp,\n\t\t\t    zb->zb_objset, zb->zb_blkid * epb + i);\n\t\t}\n\t} else if (BP_GET_TYPE(bp) == DMU_OT_OBJSET) {\n\t\tobjset_phys_t *osp = buf->b_data;\n\n\t\tdsl_scan_prefetch_dnode(scn, &osp->os_meta_dnode,\n\t\t    zb->zb_objset, DMU_META_DNODE_OBJECT);\n\n\t\tif (OBJSET_BUF_HAS_USERUSED(buf)) {\n\t\t\tif (OBJSET_BUF_HAS_PROJECTUSED(buf)) {\n\t\t\t\tdsl_scan_prefetch_dnode(scn,\n\t\t\t\t    &osp->os_projectused_dnode, zb->zb_objset,\n\t\t\t\t    DMU_PROJECTUSED_OBJECT);\n\t\t\t}\n\t\t\tdsl_scan_prefetch_dnode(scn,\n\t\t\t    &osp->os_groupused_dnode, zb->zb_objset,\n\t\t\t    DMU_GROUPUSED_OBJECT);\n\t\t\tdsl_scan_prefetch_dnode(scn,\n\t\t\t    &osp->os_userused_dnode, zb->zb_objset,\n\t\t\t    DMU_USERUSED_OBJECT);\n\t\t}\n\t}\n\nout:\n\tif (buf != NULL)\n\t\tarc_buf_destroy(buf, private);\n\tscan_prefetch_ctx_rele(spc, scn);\n}\n\nstatic void\ndsl_scan_prefetch_thread(void *arg)\n{\n\tdsl_scan_t *scn = arg;\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\tscan_prefetch_issue_ctx_t *spic;\n\n\t \n\twhile (!scn->scn_prefetch_stop) {\n\t\tarc_flags_t flags = ARC_FLAG_NOWAIT |\n\t\t    ARC_FLAG_PRESCIENT_PREFETCH | ARC_FLAG_PREFETCH;\n\t\tint zio_flags = ZIO_FLAG_CANFAIL | ZIO_FLAG_SCAN_THREAD;\n\n\t\tmutex_enter(&spa->spa_scrub_lock);\n\n\t\t \n\t\twhile (!scn->scn_prefetch_stop &&\n\t\t    (avl_numnodes(&scn->scn_prefetch_queue) == 0 ||\n\t\t    spa->spa_scrub_inflight >= scn->scn_maxinflight_bytes)) {\n\t\t\tcv_wait(&spa->spa_scrub_io_cv, &spa->spa_scrub_lock);\n\t\t}\n\n\t\t \n\t\tif (scn->scn_prefetch_stop) {\n\t\t\tmutex_exit(&spa->spa_scrub_lock);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tspic = avl_first(&scn->scn_prefetch_queue);\n\t\tspa->spa_scrub_inflight += BP_GET_PSIZE(&spic->spic_bp);\n\t\tavl_remove(&scn->scn_prefetch_queue, spic);\n\n\t\tmutex_exit(&spa->spa_scrub_lock);\n\n\t\tif (BP_IS_PROTECTED(&spic->spic_bp)) {\n\t\t\tASSERT(BP_GET_TYPE(&spic->spic_bp) == DMU_OT_DNODE ||\n\t\t\t    BP_GET_TYPE(&spic->spic_bp) == DMU_OT_OBJSET);\n\t\t\tASSERT3U(BP_GET_LEVEL(&spic->spic_bp), ==, 0);\n\t\t\tzio_flags |= ZIO_FLAG_RAW;\n\t\t}\n\n\t\t \n\t\tblkptr_t *bp = &spic->spic_bp;\n\t\tif (BP_GET_LEVEL(bp) == 1 && BP_GET_TYPE(bp) != DMU_OT_DNODE &&\n\t\t    BP_GET_TYPE(bp) != DMU_OT_OBJSET)\n\t\t\tflags |= ARC_FLAG_NO_BUF;\n\n\t\t \n\t\t(void) arc_read(scn->scn_zio_root, spa, bp,\n\t\t    dsl_scan_prefetch_cb, spic->spic_spc, ZIO_PRIORITY_SCRUB,\n\t\t    zio_flags, &flags, &spic->spic_zb);\n\n\t\tkmem_free(spic, sizeof (scan_prefetch_issue_ctx_t));\n\t}\n\n\tASSERT(scn->scn_prefetch_stop);\n\n\t \n\tmutex_enter(&spa->spa_scrub_lock);\n\twhile ((spic = avl_first(&scn->scn_prefetch_queue)) != NULL) {\n\t\tavl_remove(&scn->scn_prefetch_queue, spic);\n\t\tscan_prefetch_ctx_rele(spic->spic_spc, scn);\n\t\tkmem_free(spic, sizeof (scan_prefetch_issue_ctx_t));\n\t}\n\tASSERT0(avl_numnodes(&scn->scn_prefetch_queue));\n\tmutex_exit(&spa->spa_scrub_lock);\n}\n\nstatic boolean_t\ndsl_scan_check_resume(dsl_scan_t *scn, const dnode_phys_t *dnp,\n    const zbookmark_phys_t *zb)\n{\n\t \n\tif (!ZB_IS_ZERO(&scn->scn_phys.scn_bookmark) &&\n\t    (int64_t)zb->zb_object >= 0) {\n\t\t \n\t\tif (zbookmark_subtree_completed(dnp, zb,\n\t\t    &scn->scn_phys.scn_bookmark))\n\t\t\treturn (B_TRUE);\n\n\t\t \n\t\tif (zbookmark_subtree_tbd(dnp, zb,\n\t\t    &scn->scn_phys.scn_bookmark)) {\n\t\t\tdprintf(\"resuming at %llx/%llx/%llx/%llx\\n\",\n\t\t\t    (longlong_t)zb->zb_objset,\n\t\t\t    (longlong_t)zb->zb_object,\n\t\t\t    (longlong_t)zb->zb_level,\n\t\t\t    (longlong_t)zb->zb_blkid);\n\t\t\tmemset(&scn->scn_phys.scn_bookmark, 0, sizeof (*zb));\n\t\t}\n\t}\n\treturn (B_FALSE);\n}\n\nstatic void dsl_scan_visitbp(blkptr_t *bp, const zbookmark_phys_t *zb,\n    dnode_phys_t *dnp, dsl_dataset_t *ds, dsl_scan_t *scn,\n    dmu_objset_type_t ostype, dmu_tx_t *tx);\ninline __attribute__((always_inline)) static void dsl_scan_visitdnode(\n    dsl_scan_t *, dsl_dataset_t *ds, dmu_objset_type_t ostype,\n    dnode_phys_t *dnp, uint64_t object, dmu_tx_t *tx);\n\n \ninline __attribute__((always_inline)) static int\ndsl_scan_recurse(dsl_scan_t *scn, dsl_dataset_t *ds, dmu_objset_type_t ostype,\n    dnode_phys_t *dnp, const blkptr_t *bp,\n    const zbookmark_phys_t *zb, dmu_tx_t *tx)\n{\n\tdsl_pool_t *dp = scn->scn_dp;\n\tspa_t *spa = dp->dp_spa;\n\tint zio_flags = ZIO_FLAG_CANFAIL | ZIO_FLAG_SCAN_THREAD;\n\tint err;\n\n\tASSERT(!BP_IS_REDACTED(bp));\n\n\t \n\tif (dnp != NULL &&\n\t    dnp->dn_bonuslen > DN_MAX_BONUS_LEN(dnp)) {\n\t\tscn->scn_phys.scn_errors++;\n\t\tspa_log_error(spa, zb, &bp->blk_birth);\n\t\treturn (SET_ERROR(EINVAL));\n\t}\n\n\tif (BP_GET_LEVEL(bp) > 0) {\n\t\tarc_flags_t flags = ARC_FLAG_WAIT;\n\t\tint i;\n\t\tblkptr_t *cbp;\n\t\tint epb = BP_GET_LSIZE(bp) >> SPA_BLKPTRSHIFT;\n\t\tarc_buf_t *buf;\n\n\t\terr = arc_read(NULL, spa, bp, arc_getbuf_func, &buf,\n\t\t    ZIO_PRIORITY_SCRUB, zio_flags, &flags, zb);\n\t\tif (err) {\n\t\t\tscn->scn_phys.scn_errors++;\n\t\t\treturn (err);\n\t\t}\n\t\tfor (i = 0, cbp = buf->b_data; i < epb; i++, cbp++) {\n\t\t\tzbookmark_phys_t czb;\n\n\t\t\tSET_BOOKMARK(&czb, zb->zb_objset, zb->zb_object,\n\t\t\t    zb->zb_level - 1,\n\t\t\t    zb->zb_blkid * epb + i);\n\t\t\tdsl_scan_visitbp(cbp, &czb, dnp,\n\t\t\t    ds, scn, ostype, tx);\n\t\t}\n\t\tarc_buf_destroy(buf, &buf);\n\t} else if (BP_GET_TYPE(bp) == DMU_OT_DNODE) {\n\t\tarc_flags_t flags = ARC_FLAG_WAIT;\n\t\tdnode_phys_t *cdnp;\n\t\tint i;\n\t\tint epb = BP_GET_LSIZE(bp) >> DNODE_SHIFT;\n\t\tarc_buf_t *buf;\n\n\t\tif (BP_IS_PROTECTED(bp)) {\n\t\t\tASSERT3U(BP_GET_COMPRESS(bp), ==, ZIO_COMPRESS_OFF);\n\t\t\tzio_flags |= ZIO_FLAG_RAW;\n\t\t}\n\n\t\terr = arc_read(NULL, spa, bp, arc_getbuf_func, &buf,\n\t\t    ZIO_PRIORITY_SCRUB, zio_flags, &flags, zb);\n\t\tif (err) {\n\t\t\tscn->scn_phys.scn_errors++;\n\t\t\treturn (err);\n\t\t}\n\t\tfor (i = 0, cdnp = buf->b_data; i < epb;\n\t\t    i += cdnp->dn_extra_slots + 1,\n\t\t    cdnp += cdnp->dn_extra_slots + 1) {\n\t\t\tdsl_scan_visitdnode(scn, ds, ostype,\n\t\t\t    cdnp, zb->zb_blkid * epb + i, tx);\n\t\t}\n\n\t\tarc_buf_destroy(buf, &buf);\n\t} else if (BP_GET_TYPE(bp) == DMU_OT_OBJSET) {\n\t\tarc_flags_t flags = ARC_FLAG_WAIT;\n\t\tobjset_phys_t *osp;\n\t\tarc_buf_t *buf;\n\n\t\terr = arc_read(NULL, spa, bp, arc_getbuf_func, &buf,\n\t\t    ZIO_PRIORITY_SCRUB, zio_flags, &flags, zb);\n\t\tif (err) {\n\t\t\tscn->scn_phys.scn_errors++;\n\t\t\treturn (err);\n\t\t}\n\n\t\tosp = buf->b_data;\n\n\t\tdsl_scan_visitdnode(scn, ds, osp->os_type,\n\t\t    &osp->os_meta_dnode, DMU_META_DNODE_OBJECT, tx);\n\n\t\tif (OBJSET_BUF_HAS_USERUSED(buf)) {\n\t\t\t \n\t\t\tif (OBJSET_BUF_HAS_PROJECTUSED(buf))\n\t\t\t\tdsl_scan_visitdnode(scn, ds, osp->os_type,\n\t\t\t\t    &osp->os_projectused_dnode,\n\t\t\t\t    DMU_PROJECTUSED_OBJECT, tx);\n\t\t\tdsl_scan_visitdnode(scn, ds, osp->os_type,\n\t\t\t    &osp->os_groupused_dnode,\n\t\t\t    DMU_GROUPUSED_OBJECT, tx);\n\t\t\tdsl_scan_visitdnode(scn, ds, osp->os_type,\n\t\t\t    &osp->os_userused_dnode,\n\t\t\t    DMU_USERUSED_OBJECT, tx);\n\t\t}\n\t\tarc_buf_destroy(buf, &buf);\n\t} else if (!zfs_blkptr_verify(spa, bp,\n\t    BLK_CONFIG_NEEDED, BLK_VERIFY_LOG)) {\n\t\t \n\t\tscn->scn_phys.scn_errors++;\n\t\tspa_log_error(spa, zb, &bp->blk_birth);\n\t\treturn (SET_ERROR(EINVAL));\n\t}\n\n\treturn (0);\n}\n\ninline __attribute__((always_inline)) static void\ndsl_scan_visitdnode(dsl_scan_t *scn, dsl_dataset_t *ds,\n    dmu_objset_type_t ostype, dnode_phys_t *dnp,\n    uint64_t object, dmu_tx_t *tx)\n{\n\tint j;\n\n\tfor (j = 0; j < dnp->dn_nblkptr; j++) {\n\t\tzbookmark_phys_t czb;\n\n\t\tSET_BOOKMARK(&czb, ds ? ds->ds_object : 0, object,\n\t\t    dnp->dn_nlevels - 1, j);\n\t\tdsl_scan_visitbp(&dnp->dn_blkptr[j],\n\t\t    &czb, dnp, ds, scn, ostype, tx);\n\t}\n\n\tif (dnp->dn_flags & DNODE_FLAG_SPILL_BLKPTR) {\n\t\tzbookmark_phys_t czb;\n\t\tSET_BOOKMARK(&czb, ds ? ds->ds_object : 0, object,\n\t\t    0, DMU_SPILL_BLKID);\n\t\tdsl_scan_visitbp(DN_SPILL_BLKPTR(dnp),\n\t\t    &czb, dnp, ds, scn, ostype, tx);\n\t}\n}\n\n \nstatic void\ndsl_scan_visitbp(blkptr_t *bp, const zbookmark_phys_t *zb,\n    dnode_phys_t *dnp, dsl_dataset_t *ds, dsl_scan_t *scn,\n    dmu_objset_type_t ostype, dmu_tx_t *tx)\n{\n\tdsl_pool_t *dp = scn->scn_dp;\n\tblkptr_t *bp_toread = NULL;\n\n\tif (dsl_scan_check_suspend(scn, zb))\n\t\treturn;\n\n\tif (dsl_scan_check_resume(scn, dnp, zb))\n\t\treturn;\n\n\tscn->scn_visited_this_txg++;\n\n\tif (BP_IS_HOLE(bp)) {\n\t\tscn->scn_holes_this_txg++;\n\t\treturn;\n\t}\n\n\tif (BP_IS_REDACTED(bp)) {\n\t\tASSERT(dsl_dataset_feature_is_active(ds,\n\t\t    SPA_FEATURE_REDACTED_DATASETS));\n\t\treturn;\n\t}\n\n\t \n\tspa_feature_t f = SPA_FEATURE_LARGE_BLOCKS;\n\tif (BP_GET_LSIZE(bp) > SPA_OLD_MAXBLOCKSIZE)\n\t\tASSERT(dsl_dataset_feature_is_active(ds, f));\n\n\tf = zio_checksum_to_feature(BP_GET_CHECKSUM(bp));\n\tif (f != SPA_FEATURE_NONE)\n\t\tASSERT(dsl_dataset_feature_is_active(ds, f));\n\n\tf = zio_compress_to_feature(BP_GET_COMPRESS(bp));\n\tif (f != SPA_FEATURE_NONE)\n\t\tASSERT(dsl_dataset_feature_is_active(ds, f));\n\n\tif (bp->blk_birth <= scn->scn_phys.scn_cur_min_txg) {\n\t\tscn->scn_lt_min_this_txg++;\n\t\treturn;\n\t}\n\n\tbp_toread = kmem_alloc(sizeof (blkptr_t), KM_SLEEP);\n\t*bp_toread = *bp;\n\n\tif (dsl_scan_recurse(scn, ds, ostype, dnp, bp_toread, zb, tx) != 0)\n\t\tgoto out;\n\n\t \n\tif (ddt_class_contains(dp->dp_spa,\n\t    scn->scn_phys.scn_ddt_class_max, bp)) {\n\t\tscn->scn_ddt_contained_this_txg++;\n\t\tgoto out;\n\t}\n\n\t \n\tif (BP_PHYSICAL_BIRTH(bp) > scn->scn_phys.scn_cur_max_txg) {\n\t\tscn->scn_gt_max_this_txg++;\n\t\tgoto out;\n\t}\n\n\tscan_funcs[scn->scn_phys.scn_func](dp, bp, zb);\n\nout:\n\tkmem_free(bp_toread, sizeof (blkptr_t));\n}\n\nstatic void\ndsl_scan_visit_rootbp(dsl_scan_t *scn, dsl_dataset_t *ds, blkptr_t *bp,\n    dmu_tx_t *tx)\n{\n\tzbookmark_phys_t zb;\n\tscan_prefetch_ctx_t *spc;\n\n\tSET_BOOKMARK(&zb, ds ? ds->ds_object : DMU_META_OBJSET,\n\t    ZB_ROOT_OBJECT, ZB_ROOT_LEVEL, ZB_ROOT_BLKID);\n\n\tif (ZB_IS_ZERO(&scn->scn_phys.scn_bookmark)) {\n\t\tSET_BOOKMARK(&scn->scn_prefetch_bookmark,\n\t\t    zb.zb_objset, 0, 0, 0);\n\t} else {\n\t\tscn->scn_prefetch_bookmark = scn->scn_phys.scn_bookmark;\n\t}\n\n\tscn->scn_objsets_visited_this_txg++;\n\n\tspc = scan_prefetch_ctx_create(scn, NULL, FTAG);\n\tdsl_scan_prefetch(spc, bp, &zb);\n\tscan_prefetch_ctx_rele(spc, FTAG);\n\n\tdsl_scan_visitbp(bp, &zb, NULL, ds, scn, DMU_OST_NONE, tx);\n\n\tdprintf_ds(ds, \"finished scan%s\", \"\");\n}\n\nstatic void\nds_destroyed_scn_phys(dsl_dataset_t *ds, dsl_scan_phys_t *scn_phys)\n{\n\tif (scn_phys->scn_bookmark.zb_objset == ds->ds_object) {\n\t\tif (ds->ds_is_snapshot) {\n\t\t\t \n\t\t\tscn_phys->scn_bookmark.zb_objset =\n\t\t\t    dsl_dataset_phys(ds)->ds_next_snap_obj;\n\t\t\tzfs_dbgmsg(\"destroying ds %llu on %s; currently \"\n\t\t\t    \"traversing; reset zb_objset to %llu\",\n\t\t\t    (u_longlong_t)ds->ds_object,\n\t\t\t    ds->ds_dir->dd_pool->dp_spa->spa_name,\n\t\t\t    (u_longlong_t)dsl_dataset_phys(ds)->\n\t\t\t    ds_next_snap_obj);\n\t\t\tscn_phys->scn_flags |= DSF_VISIT_DS_AGAIN;\n\t\t} else {\n\t\t\tSET_BOOKMARK(&scn_phys->scn_bookmark,\n\t\t\t    ZB_DESTROYED_OBJSET, 0, 0, 0);\n\t\t\tzfs_dbgmsg(\"destroying ds %llu on %s; currently \"\n\t\t\t    \"traversing; reset bookmark to -1,0,0,0\",\n\t\t\t    (u_longlong_t)ds->ds_object,\n\t\t\t    ds->ds_dir->dd_pool->dp_spa->spa_name);\n\t\t}\n\t}\n}\n\n \nvoid\ndsl_scan_ds_destroyed(dsl_dataset_t *ds, dmu_tx_t *tx)\n{\n\tdsl_pool_t *dp = ds->ds_dir->dd_pool;\n\tdsl_scan_t *scn = dp->dp_scan;\n\tuint64_t mintxg;\n\n\tif (!dsl_scan_is_running(scn))\n\t\treturn;\n\n\tds_destroyed_scn_phys(ds, &scn->scn_phys);\n\tds_destroyed_scn_phys(ds, &scn->scn_phys_cached);\n\n\tif (scan_ds_queue_contains(scn, ds->ds_object, &mintxg)) {\n\t\tscan_ds_queue_remove(scn, ds->ds_object);\n\t\tif (ds->ds_is_snapshot)\n\t\t\tscan_ds_queue_insert(scn,\n\t\t\t    dsl_dataset_phys(ds)->ds_next_snap_obj, mintxg);\n\t}\n\n\tif (zap_lookup_int_key(dp->dp_meta_objset, scn->scn_phys.scn_queue_obj,\n\t    ds->ds_object, &mintxg) == 0) {\n\t\tASSERT3U(dsl_dataset_phys(ds)->ds_num_children, <=, 1);\n\t\tVERIFY3U(0, ==, zap_remove_int(dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj, ds->ds_object, tx));\n\t\tif (ds->ds_is_snapshot) {\n\t\t\t \n\t\t\tVERIFY(zap_add_int_key(dp->dp_meta_objset,\n\t\t\t    scn->scn_phys.scn_queue_obj,\n\t\t\t    dsl_dataset_phys(ds)->ds_next_snap_obj,\n\t\t\t    mintxg, tx) == 0);\n\t\t\tzfs_dbgmsg(\"destroying ds %llu on %s; in queue; \"\n\t\t\t    \"replacing with %llu\",\n\t\t\t    (u_longlong_t)ds->ds_object,\n\t\t\t    dp->dp_spa->spa_name,\n\t\t\t    (u_longlong_t)dsl_dataset_phys(ds)->\n\t\t\t    ds_next_snap_obj);\n\t\t} else {\n\t\t\tzfs_dbgmsg(\"destroying ds %llu on %s; in queue; \"\n\t\t\t    \"removing\",\n\t\t\t    (u_longlong_t)ds->ds_object,\n\t\t\t    dp->dp_spa->spa_name);\n\t\t}\n\t}\n\n\t \n\tdsl_scan_sync_state(scn, tx, SYNC_CACHED);\n}\n\nstatic void\nds_snapshotted_bookmark(dsl_dataset_t *ds, zbookmark_phys_t *scn_bookmark)\n{\n\tif (scn_bookmark->zb_objset == ds->ds_object) {\n\t\tscn_bookmark->zb_objset =\n\t\t    dsl_dataset_phys(ds)->ds_prev_snap_obj;\n\t\tzfs_dbgmsg(\"snapshotting ds %llu on %s; currently traversing; \"\n\t\t    \"reset zb_objset to %llu\",\n\t\t    (u_longlong_t)ds->ds_object,\n\t\t    ds->ds_dir->dd_pool->dp_spa->spa_name,\n\t\t    (u_longlong_t)dsl_dataset_phys(ds)->ds_prev_snap_obj);\n\t}\n}\n\n \nvoid\ndsl_scan_ds_snapshotted(dsl_dataset_t *ds, dmu_tx_t *tx)\n{\n\tdsl_pool_t *dp = ds->ds_dir->dd_pool;\n\tdsl_scan_t *scn = dp->dp_scan;\n\tuint64_t mintxg;\n\n\tif (!dsl_scan_is_running(scn))\n\t\treturn;\n\n\tASSERT(dsl_dataset_phys(ds)->ds_prev_snap_obj != 0);\n\n\tds_snapshotted_bookmark(ds, &scn->scn_phys.scn_bookmark);\n\tds_snapshotted_bookmark(ds, &scn->scn_phys_cached.scn_bookmark);\n\n\tif (scan_ds_queue_contains(scn, ds->ds_object, &mintxg)) {\n\t\tscan_ds_queue_remove(scn, ds->ds_object);\n\t\tscan_ds_queue_insert(scn,\n\t\t    dsl_dataset_phys(ds)->ds_prev_snap_obj, mintxg);\n\t}\n\n\tif (zap_lookup_int_key(dp->dp_meta_objset, scn->scn_phys.scn_queue_obj,\n\t    ds->ds_object, &mintxg) == 0) {\n\t\tVERIFY3U(0, ==, zap_remove_int(dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj, ds->ds_object, tx));\n\t\tVERIFY(zap_add_int_key(dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj,\n\t\t    dsl_dataset_phys(ds)->ds_prev_snap_obj, mintxg, tx) == 0);\n\t\tzfs_dbgmsg(\"snapshotting ds %llu on %s; in queue; \"\n\t\t    \"replacing with %llu\",\n\t\t    (u_longlong_t)ds->ds_object,\n\t\t    dp->dp_spa->spa_name,\n\t\t    (u_longlong_t)dsl_dataset_phys(ds)->ds_prev_snap_obj);\n\t}\n\n\tdsl_scan_sync_state(scn, tx, SYNC_CACHED);\n}\n\nstatic void\nds_clone_swapped_bookmark(dsl_dataset_t *ds1, dsl_dataset_t *ds2,\n    zbookmark_phys_t *scn_bookmark)\n{\n\tif (scn_bookmark->zb_objset == ds1->ds_object) {\n\t\tscn_bookmark->zb_objset = ds2->ds_object;\n\t\tzfs_dbgmsg(\"clone_swap ds %llu on %s; currently traversing; \"\n\t\t    \"reset zb_objset to %llu\",\n\t\t    (u_longlong_t)ds1->ds_object,\n\t\t    ds1->ds_dir->dd_pool->dp_spa->spa_name,\n\t\t    (u_longlong_t)ds2->ds_object);\n\t} else if (scn_bookmark->zb_objset == ds2->ds_object) {\n\t\tscn_bookmark->zb_objset = ds1->ds_object;\n\t\tzfs_dbgmsg(\"clone_swap ds %llu on %s; currently traversing; \"\n\t\t    \"reset zb_objset to %llu\",\n\t\t    (u_longlong_t)ds2->ds_object,\n\t\t    ds2->ds_dir->dd_pool->dp_spa->spa_name,\n\t\t    (u_longlong_t)ds1->ds_object);\n\t}\n}\n\n \nvoid\ndsl_scan_ds_clone_swapped(dsl_dataset_t *ds1, dsl_dataset_t *ds2, dmu_tx_t *tx)\n{\n\tdsl_pool_t *dp = ds1->ds_dir->dd_pool;\n\tdsl_scan_t *scn = dp->dp_scan;\n\tuint64_t mintxg1, mintxg2;\n\tboolean_t ds1_queued, ds2_queued;\n\n\tif (!dsl_scan_is_running(scn))\n\t\treturn;\n\n\tds_clone_swapped_bookmark(ds1, ds2, &scn->scn_phys.scn_bookmark);\n\tds_clone_swapped_bookmark(ds1, ds2, &scn->scn_phys_cached.scn_bookmark);\n\n\t \n\tds1_queued = scan_ds_queue_contains(scn, ds1->ds_object, &mintxg1);\n\tds2_queued = scan_ds_queue_contains(scn, ds2->ds_object, &mintxg2);\n\n\t \n\tif (ds1_queued) {\n\t\tASSERT3U(mintxg1, ==, dsl_dataset_phys(ds1)->ds_prev_snap_txg);\n\t\tASSERT3U(mintxg1, ==, dsl_dataset_phys(ds2)->ds_prev_snap_txg);\n\t}\n\tif (ds2_queued) {\n\t\tASSERT3U(mintxg2, ==, dsl_dataset_phys(ds1)->ds_prev_snap_txg);\n\t\tASSERT3U(mintxg2, ==, dsl_dataset_phys(ds2)->ds_prev_snap_txg);\n\t}\n\n\tif (ds1_queued && ds2_queued) {\n\t\t \n\t} else if (ds1_queued) {\n\t\tscan_ds_queue_remove(scn, ds1->ds_object);\n\t\tscan_ds_queue_insert(scn, ds2->ds_object, mintxg1);\n\t} else if (ds2_queued) {\n\t\tscan_ds_queue_remove(scn, ds2->ds_object);\n\t\tscan_ds_queue_insert(scn, ds1->ds_object, mintxg2);\n\t}\n\n\t \n\tds1_queued = zap_lookup_int_key(dp->dp_meta_objset,\n\t    scn->scn_phys.scn_queue_obj, ds1->ds_object, &mintxg1) == 0;\n\tds2_queued = zap_lookup_int_key(dp->dp_meta_objset,\n\t    scn->scn_phys.scn_queue_obj, ds2->ds_object, &mintxg2) == 0;\n\n\t \n\tif (ds1_queued) {\n\t\tASSERT3U(mintxg1, ==, dsl_dataset_phys(ds1)->ds_prev_snap_txg);\n\t\tASSERT3U(mintxg1, ==, dsl_dataset_phys(ds2)->ds_prev_snap_txg);\n\t}\n\tif (ds2_queued) {\n\t\tASSERT3U(mintxg2, ==, dsl_dataset_phys(ds1)->ds_prev_snap_txg);\n\t\tASSERT3U(mintxg2, ==, dsl_dataset_phys(ds2)->ds_prev_snap_txg);\n\t}\n\n\tif (ds1_queued && ds2_queued) {\n\t\t \n\t} else if (ds1_queued) {\n\t\tVERIFY3S(0, ==, zap_remove_int(dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj, ds1->ds_object, tx));\n\t\tVERIFY3S(0, ==, zap_add_int_key(dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj, ds2->ds_object, mintxg1, tx));\n\t\tzfs_dbgmsg(\"clone_swap ds %llu on %s; in queue; \"\n\t\t    \"replacing with %llu\",\n\t\t    (u_longlong_t)ds1->ds_object,\n\t\t    dp->dp_spa->spa_name,\n\t\t    (u_longlong_t)ds2->ds_object);\n\t} else if (ds2_queued) {\n\t\tVERIFY3S(0, ==, zap_remove_int(dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj, ds2->ds_object, tx));\n\t\tVERIFY3S(0, ==, zap_add_int_key(dp->dp_meta_objset,\n\t\t    scn->scn_phys.scn_queue_obj, ds1->ds_object, mintxg2, tx));\n\t\tzfs_dbgmsg(\"clone_swap ds %llu on %s; in queue; \"\n\t\t    \"replacing with %llu\",\n\t\t    (u_longlong_t)ds2->ds_object,\n\t\t    dp->dp_spa->spa_name,\n\t\t    (u_longlong_t)ds1->ds_object);\n\t}\n\n\tdsl_scan_sync_state(scn, tx, SYNC_CACHED);\n}\n\nstatic int\nenqueue_clones_cb(dsl_pool_t *dp, dsl_dataset_t *hds, void *arg)\n{\n\tuint64_t originobj = *(uint64_t *)arg;\n\tdsl_dataset_t *ds;\n\tint err;\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\tif (dsl_dir_phys(hds->ds_dir)->dd_origin_obj != originobj)\n\t\treturn (0);\n\n\terr = dsl_dataset_hold_obj(dp, hds->ds_object, FTAG, &ds);\n\tif (err)\n\t\treturn (err);\n\n\twhile (dsl_dataset_phys(ds)->ds_prev_snap_obj != originobj) {\n\t\tdsl_dataset_t *prev;\n\t\terr = dsl_dataset_hold_obj(dp,\n\t\t    dsl_dataset_phys(ds)->ds_prev_snap_obj, FTAG, &prev);\n\n\t\tdsl_dataset_rele(ds, FTAG);\n\t\tif (err)\n\t\t\treturn (err);\n\t\tds = prev;\n\t}\n\tscan_ds_queue_insert(scn, ds->ds_object,\n\t    dsl_dataset_phys(ds)->ds_prev_snap_txg);\n\tdsl_dataset_rele(ds, FTAG);\n\treturn (0);\n}\n\nstatic void\ndsl_scan_visitds(dsl_scan_t *scn, uint64_t dsobj, dmu_tx_t *tx)\n{\n\tdsl_pool_t *dp = scn->scn_dp;\n\tdsl_dataset_t *ds;\n\n\tVERIFY3U(0, ==, dsl_dataset_hold_obj(dp, dsobj, FTAG, &ds));\n\n\tif (scn->scn_phys.scn_cur_min_txg >=\n\t    scn->scn_phys.scn_max_txg) {\n\t\t \n\t\tchar *dsname = kmem_alloc(ZFS_MAX_DATASET_NAME_LEN, KM_SLEEP);\n\t\tdsl_dataset_name(ds, dsname);\n\t\tzfs_dbgmsg(\"scanning dataset %llu (%s) is unnecessary because \"\n\t\t    \"cur_min_txg (%llu) >= max_txg (%llu)\",\n\t\t    (longlong_t)dsobj, dsname,\n\t\t    (longlong_t)scn->scn_phys.scn_cur_min_txg,\n\t\t    (longlong_t)scn->scn_phys.scn_max_txg);\n\t\tkmem_free(dsname, MAXNAMELEN);\n\n\t\tgoto out;\n\t}\n\n\t \n\tif (!dsl_dataset_is_snapshot(ds) &&\n\t    (dp->dp_origin_snap == NULL ||\n\t    ds->ds_dir != dp->dp_origin_snap->ds_dir)) {\n\t\tobjset_t *os;\n\t\tif (dmu_objset_from_ds(ds, &os) != 0) {\n\t\t\tgoto out;\n\t\t}\n\t\tdsl_scan_zil(dp, &os->os_zil_header);\n\t}\n\n\t \n\tdmu_buf_will_dirty(ds->ds_dbuf, tx);\n\trrw_enter(&ds->ds_bp_rwlock, RW_READER, FTAG);\n\tdsl_scan_visit_rootbp(scn, ds, &dsl_dataset_phys(ds)->ds_bp, tx);\n\trrw_exit(&ds->ds_bp_rwlock, FTAG);\n\n\tchar *dsname = kmem_alloc(ZFS_MAX_DATASET_NAME_LEN, KM_SLEEP);\n\tdsl_dataset_name(ds, dsname);\n\tzfs_dbgmsg(\"scanned dataset %llu (%s) with min=%llu max=%llu; \"\n\t    \"suspending=%u\",\n\t    (longlong_t)dsobj, dsname,\n\t    (longlong_t)scn->scn_phys.scn_cur_min_txg,\n\t    (longlong_t)scn->scn_phys.scn_cur_max_txg,\n\t    (int)scn->scn_suspending);\n\tkmem_free(dsname, ZFS_MAX_DATASET_NAME_LEN);\n\n\tif (scn->scn_suspending)\n\t\tgoto out;\n\n\t \n\n\t \n\tif (scn->scn_phys.scn_flags & DSF_VISIT_DS_AGAIN) {\n\t\tzfs_dbgmsg(\"incomplete pass on %s; visiting again\",\n\t\t    dp->dp_spa->spa_name);\n\t\tscn->scn_phys.scn_flags &= ~DSF_VISIT_DS_AGAIN;\n\t\tscan_ds_queue_insert(scn, ds->ds_object,\n\t\t    scn->scn_phys.scn_cur_max_txg);\n\t\tgoto out;\n\t}\n\n\t \n\tif (dsl_dataset_phys(ds)->ds_next_snap_obj != 0) {\n\t\tscan_ds_queue_insert(scn,\n\t\t    dsl_dataset_phys(ds)->ds_next_snap_obj,\n\t\t    dsl_dataset_phys(ds)->ds_creation_txg);\n\t}\n\tif (dsl_dataset_phys(ds)->ds_num_children > 1) {\n\t\tboolean_t usenext = B_FALSE;\n\t\tif (dsl_dataset_phys(ds)->ds_next_clones_obj != 0) {\n\t\t\tuint64_t count;\n\t\t\t \n\t\t\tint err = zap_count(dp->dp_meta_objset,\n\t\t\t    dsl_dataset_phys(ds)->ds_next_clones_obj, &count);\n\t\t\tif (err == 0 &&\n\t\t\t    count == dsl_dataset_phys(ds)->ds_num_children - 1)\n\t\t\t\tusenext = B_TRUE;\n\t\t}\n\n\t\tif (usenext) {\n\t\t\tzap_cursor_t zc;\n\t\t\tzap_attribute_t za;\n\t\t\tfor (zap_cursor_init(&zc, dp->dp_meta_objset,\n\t\t\t    dsl_dataset_phys(ds)->ds_next_clones_obj);\n\t\t\t    zap_cursor_retrieve(&zc, &za) == 0;\n\t\t\t    (void) zap_cursor_advance(&zc)) {\n\t\t\t\tscan_ds_queue_insert(scn,\n\t\t\t\t    zfs_strtonum(za.za_name, NULL),\n\t\t\t\t    dsl_dataset_phys(ds)->ds_creation_txg);\n\t\t\t}\n\t\t\tzap_cursor_fini(&zc);\n\t\t} else {\n\t\t\tVERIFY0(dmu_objset_find_dp(dp, dp->dp_root_dir_obj,\n\t\t\t    enqueue_clones_cb, &ds->ds_object,\n\t\t\t    DS_FIND_CHILDREN));\n\t\t}\n\t}\n\nout:\n\tdsl_dataset_rele(ds, FTAG);\n}\n\nstatic int\nenqueue_cb(dsl_pool_t *dp, dsl_dataset_t *hds, void *arg)\n{\n\t(void) arg;\n\tdsl_dataset_t *ds;\n\tint err;\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\terr = dsl_dataset_hold_obj(dp, hds->ds_object, FTAG, &ds);\n\tif (err)\n\t\treturn (err);\n\n\twhile (dsl_dataset_phys(ds)->ds_prev_snap_obj != 0) {\n\t\tdsl_dataset_t *prev;\n\t\terr = dsl_dataset_hold_obj(dp,\n\t\t    dsl_dataset_phys(ds)->ds_prev_snap_obj, FTAG, &prev);\n\t\tif (err) {\n\t\t\tdsl_dataset_rele(ds, FTAG);\n\t\t\treturn (err);\n\t\t}\n\n\t\t \n\t\tif (dsl_dataset_phys(prev)->ds_next_snap_obj != ds->ds_object) {\n\t\t\tdsl_dataset_rele(ds, FTAG);\n\t\t\tdsl_dataset_rele(prev, FTAG);\n\t\t\treturn (0);\n\t\t}\n\t\tdsl_dataset_rele(ds, FTAG);\n\t\tds = prev;\n\t}\n\n\tscan_ds_queue_insert(scn, ds->ds_object,\n\t    dsl_dataset_phys(ds)->ds_prev_snap_txg);\n\tdsl_dataset_rele(ds, FTAG);\n\treturn (0);\n}\n\nvoid\ndsl_scan_ddt_entry(dsl_scan_t *scn, enum zio_checksum checksum,\n    ddt_entry_t *dde, dmu_tx_t *tx)\n{\n\t(void) tx;\n\tconst ddt_key_t *ddk = &dde->dde_key;\n\tddt_phys_t *ddp = dde->dde_phys;\n\tblkptr_t bp;\n\tzbookmark_phys_t zb = { 0 };\n\n\tif (!dsl_scan_is_running(scn))\n\t\treturn;\n\n\t \n\tif (scn->scn_done_txg != 0)\n\t\treturn;\n\n\tfor (int p = 0; p < DDT_PHYS_TYPES; p++, ddp++) {\n\t\tif (ddp->ddp_phys_birth == 0 ||\n\t\t    ddp->ddp_phys_birth > scn->scn_phys.scn_max_txg)\n\t\t\tcontinue;\n\t\tddt_bp_create(checksum, ddk, ddp, &bp);\n\n\t\tscn->scn_visited_this_txg++;\n\t\tscan_funcs[scn->scn_phys.scn_func](scn->scn_dp, &bp, &zb);\n\t}\n}\n\n \nstatic void\ndsl_scan_ddt(dsl_scan_t *scn, dmu_tx_t *tx)\n{\n\tddt_bookmark_t *ddb = &scn->scn_phys.scn_ddt_bookmark;\n\tddt_entry_t dde = {{{{0}}}};\n\tint error;\n\tuint64_t n = 0;\n\n\twhile ((error = ddt_walk(scn->scn_dp->dp_spa, ddb, &dde)) == 0) {\n\t\tddt_t *ddt;\n\n\t\tif (ddb->ddb_class > scn->scn_phys.scn_ddt_class_max)\n\t\t\tbreak;\n\t\tdprintf(\"visiting ddb=%llu/%llu/%llu/%llx\\n\",\n\t\t    (longlong_t)ddb->ddb_class,\n\t\t    (longlong_t)ddb->ddb_type,\n\t\t    (longlong_t)ddb->ddb_checksum,\n\t\t    (longlong_t)ddb->ddb_cursor);\n\n\t\t \n\t\tddt = scn->scn_dp->dp_spa->spa_ddt[ddb->ddb_checksum];\n\t\tASSERT(avl_first(&ddt->ddt_tree) == NULL);\n\n\t\tdsl_scan_ddt_entry(scn, ddb->ddb_checksum, &dde, tx);\n\t\tn++;\n\n\t\tif (dsl_scan_check_suspend(scn, NULL))\n\t\t\tbreak;\n\t}\n\n\tzfs_dbgmsg(\"scanned %llu ddt entries on %s with class_max = %u; \"\n\t    \"suspending=%u\", (longlong_t)n, scn->scn_dp->dp_spa->spa_name,\n\t    (int)scn->scn_phys.scn_ddt_class_max, (int)scn->scn_suspending);\n\n\tASSERT(error == 0 || error == ENOENT);\n\tASSERT(error != ENOENT ||\n\t    ddb->ddb_class > scn->scn_phys.scn_ddt_class_max);\n}\n\nstatic uint64_t\ndsl_scan_ds_maxtxg(dsl_dataset_t *ds)\n{\n\tuint64_t smt = ds->ds_dir->dd_pool->dp_scan->scn_phys.scn_max_txg;\n\tif (ds->ds_is_snapshot)\n\t\treturn (MIN(smt, dsl_dataset_phys(ds)->ds_creation_txg));\n\treturn (smt);\n}\n\nstatic void\ndsl_scan_visit(dsl_scan_t *scn, dmu_tx_t *tx)\n{\n\tscan_ds_t *sds;\n\tdsl_pool_t *dp = scn->scn_dp;\n\n\tif (scn->scn_phys.scn_ddt_bookmark.ddb_class <=\n\t    scn->scn_phys.scn_ddt_class_max) {\n\t\tscn->scn_phys.scn_cur_min_txg = scn->scn_phys.scn_min_txg;\n\t\tscn->scn_phys.scn_cur_max_txg = scn->scn_phys.scn_max_txg;\n\t\tdsl_scan_ddt(scn, tx);\n\t\tif (scn->scn_suspending)\n\t\t\treturn;\n\t}\n\n\tif (scn->scn_phys.scn_bookmark.zb_objset == DMU_META_OBJSET) {\n\t\t \n\n\t\tscn->scn_phys.scn_cur_min_txg = scn->scn_phys.scn_min_txg;\n\t\tscn->scn_phys.scn_cur_max_txg = scn->scn_phys.scn_max_txg;\n\t\tdsl_scan_visit_rootbp(scn, NULL,\n\t\t    &dp->dp_meta_rootbp, tx);\n\t\tspa_set_rootblkptr(dp->dp_spa, &dp->dp_meta_rootbp);\n\t\tif (scn->scn_suspending)\n\t\t\treturn;\n\n\t\tif (spa_version(dp->dp_spa) < SPA_VERSION_DSL_SCRUB) {\n\t\t\tVERIFY0(dmu_objset_find_dp(dp, dp->dp_root_dir_obj,\n\t\t\t    enqueue_cb, NULL, DS_FIND_CHILDREN));\n\t\t} else {\n\t\t\tdsl_scan_visitds(scn,\n\t\t\t    dp->dp_origin_snap->ds_object, tx);\n\t\t}\n\t\tASSERT(!scn->scn_suspending);\n\t} else if (scn->scn_phys.scn_bookmark.zb_objset !=\n\t    ZB_DESTROYED_OBJSET) {\n\t\tuint64_t dsobj = scn->scn_phys.scn_bookmark.zb_objset;\n\t\t \n\t\tdsl_scan_visitds(scn, dsobj, tx);\n\t\tif (scn->scn_suspending)\n\t\t\treturn;\n\t}\n\n\t \n\tmemset(&scn->scn_phys.scn_bookmark, 0, sizeof (zbookmark_phys_t));\n\n\t \n\twhile ((sds = avl_first(&scn->scn_queue)) != NULL) {\n\t\tdsl_dataset_t *ds;\n\t\tuint64_t dsobj = sds->sds_dsobj;\n\t\tuint64_t txg = sds->sds_txg;\n\n\t\t \n\t\tscan_ds_queue_remove(scn, dsobj);\n\t\tsds = NULL;\n\n\t\t \n\t\tVERIFY3U(0, ==, dsl_dataset_hold_obj(dp, dsobj, FTAG, &ds));\n\t\tif (txg != 0) {\n\t\t\tscn->scn_phys.scn_cur_min_txg =\n\t\t\t    MAX(scn->scn_phys.scn_min_txg, txg);\n\t\t} else {\n\t\t\tscn->scn_phys.scn_cur_min_txg =\n\t\t\t    MAX(scn->scn_phys.scn_min_txg,\n\t\t\t    dsl_dataset_phys(ds)->ds_prev_snap_txg);\n\t\t}\n\t\tscn->scn_phys.scn_cur_max_txg = dsl_scan_ds_maxtxg(ds);\n\t\tdsl_dataset_rele(ds, FTAG);\n\n\t\tdsl_scan_visitds(scn, dsobj, tx);\n\t\tif (scn->scn_suspending)\n\t\t\treturn;\n\t}\n\n\t \n\tscn->scn_phys.scn_bookmark.zb_objset = ZB_DESTROYED_OBJSET;\n\tASSERT0(scn->scn_suspending);\n}\n\nstatic uint64_t\ndsl_scan_count_data_disks(spa_t *spa)\n{\n\tvdev_t *rvd = spa->spa_root_vdev;\n\tuint64_t i, leaves = 0;\n\n\tfor (i = 0; i < rvd->vdev_children; i++) {\n\t\tvdev_t *vd = rvd->vdev_child[i];\n\t\tif (vd->vdev_islog || vd->vdev_isspare || vd->vdev_isl2cache)\n\t\t\tcontinue;\n\t\tleaves += vdev_get_ndisks(vd) - vdev_get_nparity(vd);\n\t}\n\treturn (leaves);\n}\n\nstatic void\nscan_io_queues_update_zio_stats(dsl_scan_io_queue_t *q, const blkptr_t *bp)\n{\n\tint i;\n\tuint64_t cur_size = 0;\n\n\tfor (i = 0; i < BP_GET_NDVAS(bp); i++) {\n\t\tcur_size += DVA_GET_ASIZE(&bp->blk_dva[i]);\n\t}\n\n\tq->q_total_zio_size_this_txg += cur_size;\n\tq->q_zios_this_txg++;\n}\n\nstatic void\nscan_io_queues_update_seg_stats(dsl_scan_io_queue_t *q, uint64_t start,\n    uint64_t end)\n{\n\tq->q_total_seg_size_this_txg += end - start;\n\tq->q_segs_this_txg++;\n}\n\nstatic boolean_t\nscan_io_queue_check_suspend(dsl_scan_t *scn)\n{\n\t \n\tuint64_t curr_time_ns = gethrtime();\n\tuint64_t scan_time_ns = curr_time_ns - scn->scn_sync_start_time;\n\tuint64_t sync_time_ns = curr_time_ns -\n\t    scn->scn_dp->dp_spa->spa_sync_starttime;\n\tuint64_t dirty_min_bytes = zfs_dirty_data_max *\n\t    zfs_vdev_async_write_active_min_dirty_percent / 100;\n\tuint_t mintime = (scn->scn_phys.scn_func == POOL_SCAN_RESILVER) ?\n\t    zfs_resilver_min_time_ms : zfs_scrub_min_time_ms;\n\n\treturn ((NSEC2MSEC(scan_time_ns) > mintime &&\n\t    (scn->scn_dp->dp_dirty_total >= dirty_min_bytes ||\n\t    txg_sync_waiting(scn->scn_dp) ||\n\t    NSEC2SEC(sync_time_ns) >= zfs_txg_timeout)) ||\n\t    spa_shutting_down(scn->scn_dp->dp_spa));\n}\n\n \nstatic boolean_t\nscan_io_queue_issue(dsl_scan_io_queue_t *queue, list_t *io_list)\n{\n\tdsl_scan_t *scn = queue->q_scn;\n\tscan_io_t *sio;\n\tboolean_t suspended = B_FALSE;\n\n\twhile ((sio = list_head(io_list)) != NULL) {\n\t\tblkptr_t bp;\n\n\t\tif (scan_io_queue_check_suspend(scn)) {\n\t\t\tsuspended = B_TRUE;\n\t\t\tbreak;\n\t\t}\n\n\t\tsio2bp(sio, &bp);\n\t\tscan_exec_io(scn->scn_dp, &bp, sio->sio_flags,\n\t\t    &sio->sio_zb, queue);\n\t\t(void) list_remove_head(io_list);\n\t\tscan_io_queues_update_zio_stats(queue, &bp);\n\t\tsio_free(sio);\n\t}\n\treturn (suspended);\n}\n\n \nstatic boolean_t\nscan_io_queue_gather(dsl_scan_io_queue_t *queue, range_seg_t *rs, list_t *list)\n{\n\tscan_io_t *srch_sio, *sio, *next_sio;\n\tavl_index_t idx;\n\tuint_t num_sios = 0;\n\tint64_t bytes_issued = 0;\n\n\tASSERT(rs != NULL);\n\tASSERT(MUTEX_HELD(&queue->q_vd->vdev_scan_io_queue_lock));\n\n\tsrch_sio = sio_alloc(1);\n\tsrch_sio->sio_nr_dvas = 1;\n\tSIO_SET_OFFSET(srch_sio, rs_get_start(rs, queue->q_exts_by_addr));\n\n\t \n\tsio = avl_find(&queue->q_sios_by_addr, srch_sio, &idx);\n\tsio_free(srch_sio);\n\n\tif (sio == NULL)\n\t\tsio = avl_nearest(&queue->q_sios_by_addr, idx, AVL_AFTER);\n\n\twhile (sio != NULL && SIO_GET_OFFSET(sio) < rs_get_end(rs,\n\t    queue->q_exts_by_addr) && num_sios <= 32) {\n\t\tASSERT3U(SIO_GET_OFFSET(sio), >=, rs_get_start(rs,\n\t\t    queue->q_exts_by_addr));\n\t\tASSERT3U(SIO_GET_END_OFFSET(sio), <=, rs_get_end(rs,\n\t\t    queue->q_exts_by_addr));\n\n\t\tnext_sio = AVL_NEXT(&queue->q_sios_by_addr, sio);\n\t\tavl_remove(&queue->q_sios_by_addr, sio);\n\t\tif (avl_is_empty(&queue->q_sios_by_addr))\n\t\t\tatomic_add_64(&queue->q_scn->scn_queues_pending, -1);\n\t\tqueue->q_sio_memused -= SIO_GET_MUSED(sio);\n\n\t\tbytes_issued += SIO_GET_ASIZE(sio);\n\t\tnum_sios++;\n\t\tlist_insert_tail(list, sio);\n\t\tsio = next_sio;\n\t}\n\n\t \n\tif (sio != NULL && SIO_GET_OFFSET(sio) < rs_get_end(rs,\n\t    queue->q_exts_by_addr)) {\n\t\trange_tree_adjust_fill(queue->q_exts_by_addr, rs,\n\t\t    -bytes_issued);\n\t\trange_tree_resize_segment(queue->q_exts_by_addr, rs,\n\t\t    SIO_GET_OFFSET(sio), rs_get_end(rs,\n\t\t    queue->q_exts_by_addr) - SIO_GET_OFFSET(sio));\n\t\tqueue->q_last_ext_addr = SIO_GET_OFFSET(sio);\n\t\treturn (B_TRUE);\n\t} else {\n\t\tuint64_t rstart = rs_get_start(rs, queue->q_exts_by_addr);\n\t\tuint64_t rend = rs_get_end(rs, queue->q_exts_by_addr);\n\t\trange_tree_remove(queue->q_exts_by_addr, rstart, rend - rstart);\n\t\tqueue->q_last_ext_addr = -1;\n\t\treturn (B_FALSE);\n\t}\n}\n\n \nstatic range_seg_t *\nscan_io_queue_fetch_ext(dsl_scan_io_queue_t *queue)\n{\n\tdsl_scan_t *scn = queue->q_scn;\n\trange_tree_t *rt = queue->q_exts_by_addr;\n\n\tASSERT(MUTEX_HELD(&queue->q_vd->vdev_scan_io_queue_lock));\n\tASSERT(scn->scn_is_sorted);\n\n\tif (!scn->scn_checkpointing && !scn->scn_clearing)\n\t\treturn (NULL);\n\n\t \n\tif ((zfs_scan_issue_strategy < 1 && scn->scn_checkpointing) ||\n\t    zfs_scan_issue_strategy == 1)\n\t\treturn (range_tree_first(rt));\n\n\t \n\tuint64_t start;\n\tuint64_t size = 1ULL << rt->rt_shift;\n\trange_seg_t *addr_rs;\n\tif (queue->q_last_ext_addr != -1) {\n\t\tstart = queue->q_last_ext_addr;\n\t\taddr_rs = range_tree_find(rt, start, size);\n\t\tif (addr_rs != NULL)\n\t\t\treturn (addr_rs);\n\t}\n\n\t \n\tuint64_t *v = zfs_btree_first(&queue->q_exts_by_size, NULL);\n\tif (v == NULL)\n\t\treturn (NULL);\n\tqueue->q_last_ext_addr = start = *v << rt->rt_shift;\n\n\t \n\taddr_rs = range_tree_find(rt, start, size);\n\tASSERT3P(addr_rs, !=, NULL);\n\tASSERT3U(rs_get_start(addr_rs, rt), ==, start);\n\tASSERT3U(rs_get_end(addr_rs, rt), >, start);\n\treturn (addr_rs);\n}\n\nstatic void\nscan_io_queues_run_one(void *arg)\n{\n\tdsl_scan_io_queue_t *queue = arg;\n\tkmutex_t *q_lock = &queue->q_vd->vdev_scan_io_queue_lock;\n\tboolean_t suspended = B_FALSE;\n\trange_seg_t *rs;\n\tscan_io_t *sio;\n\tzio_t *zio;\n\tlist_t sio_list;\n\n\tASSERT(queue->q_scn->scn_is_sorted);\n\n\tlist_create(&sio_list, sizeof (scan_io_t),\n\t    offsetof(scan_io_t, sio_nodes.sio_list_node));\n\tzio = zio_null(queue->q_scn->scn_zio_root, queue->q_scn->scn_dp->dp_spa,\n\t    NULL, NULL, NULL, ZIO_FLAG_CANFAIL);\n\tmutex_enter(q_lock);\n\tqueue->q_zio = zio;\n\n\t \n\tqueue->q_maxinflight_bytes = MAX(1, zfs_scan_vdev_limit *\n\t    (vdev_get_ndisks(queue->q_vd) - vdev_get_nparity(queue->q_vd)));\n\n\t \n\tqueue->q_total_seg_size_this_txg = 0;\n\tqueue->q_segs_this_txg = 0;\n\tqueue->q_total_zio_size_this_txg = 0;\n\tqueue->q_zios_this_txg = 0;\n\n\t \n\twhile ((rs = scan_io_queue_fetch_ext(queue)) != NULL) {\n\t\tuint64_t seg_start = 0, seg_end = 0;\n\t\tboolean_t more_left;\n\n\t\tASSERT(list_is_empty(&sio_list));\n\n\t\t \n\t\tdo {\n\t\t\tscan_io_t *first_sio, *last_sio;\n\n\t\t\t \n\t\t\tmore_left = scan_io_queue_gather(queue, rs, &sio_list);\n\t\t\tASSERT(!list_is_empty(&sio_list));\n\t\t\tfirst_sio = list_head(&sio_list);\n\t\t\tlast_sio = list_tail(&sio_list);\n\n\t\t\tseg_end = SIO_GET_END_OFFSET(last_sio);\n\t\t\tif (seg_start == 0)\n\t\t\t\tseg_start = SIO_GET_OFFSET(first_sio);\n\n\t\t\t \n\t\t\tmutex_exit(q_lock);\n\t\t\tsuspended = scan_io_queue_issue(queue, &sio_list);\n\t\t\tmutex_enter(q_lock);\n\n\t\t\tif (suspended)\n\t\t\t\tbreak;\n\t\t} while (more_left);\n\n\t\t \n\t\tscan_io_queues_update_seg_stats(queue, seg_start, seg_end);\n\n\t\tif (suspended)\n\t\t\tbreak;\n\t}\n\n\t \n\twhile ((sio = list_remove_head(&sio_list)) != NULL)\n\t\tscan_io_queue_insert_impl(queue, sio);\n\n\tqueue->q_zio = NULL;\n\tmutex_exit(q_lock);\n\tzio_nowait(zio);\n\tlist_destroy(&sio_list);\n}\n\n \nstatic void\nscan_io_queues_run(dsl_scan_t *scn)\n{\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\n\tASSERT(scn->scn_is_sorted);\n\tASSERT(spa_config_held(spa, SCL_CONFIG, RW_READER));\n\n\tif (scn->scn_queues_pending == 0)\n\t\treturn;\n\n\tif (scn->scn_taskq == NULL) {\n\t\tint nthreads = spa->spa_root_vdev->vdev_children;\n\n\t\t \n\t\tscn->scn_taskq = taskq_create(\"dsl_scan_iss\", nthreads,\n\t\t    minclsyspri, nthreads, nthreads, TASKQ_PREPOPULATE);\n\t}\n\n\tfor (uint64_t i = 0; i < spa->spa_root_vdev->vdev_children; i++) {\n\t\tvdev_t *vd = spa->spa_root_vdev->vdev_child[i];\n\n\t\tmutex_enter(&vd->vdev_scan_io_queue_lock);\n\t\tif (vd->vdev_scan_io_queue != NULL) {\n\t\t\tVERIFY(taskq_dispatch(scn->scn_taskq,\n\t\t\t    scan_io_queues_run_one, vd->vdev_scan_io_queue,\n\t\t\t    TQ_SLEEP) != TASKQID_INVALID);\n\t\t}\n\t\tmutex_exit(&vd->vdev_scan_io_queue_lock);\n\t}\n\n\t \n\ttaskq_wait(scn->scn_taskq);\n}\n\nstatic boolean_t\ndsl_scan_async_block_should_pause(dsl_scan_t *scn)\n{\n\tuint64_t elapsed_nanosecs;\n\n\tif (zfs_recover)\n\t\treturn (B_FALSE);\n\n\tif (zfs_async_block_max_blocks != 0 &&\n\t    scn->scn_visited_this_txg >= zfs_async_block_max_blocks) {\n\t\treturn (B_TRUE);\n\t}\n\n\tif (zfs_max_async_dedup_frees != 0 &&\n\t    scn->scn_dedup_frees_this_txg >= zfs_max_async_dedup_frees) {\n\t\treturn (B_TRUE);\n\t}\n\n\telapsed_nanosecs = gethrtime() - scn->scn_sync_start_time;\n\treturn (elapsed_nanosecs / NANOSEC > zfs_txg_timeout ||\n\t    (NSEC2MSEC(elapsed_nanosecs) > scn->scn_async_block_min_time_ms &&\n\t    txg_sync_waiting(scn->scn_dp)) ||\n\t    spa_shutting_down(scn->scn_dp->dp_spa));\n}\n\nstatic int\ndsl_scan_free_block_cb(void *arg, const blkptr_t *bp, dmu_tx_t *tx)\n{\n\tdsl_scan_t *scn = arg;\n\n\tif (!scn->scn_is_bptree ||\n\t    (BP_GET_LEVEL(bp) == 0 && BP_GET_TYPE(bp) != DMU_OT_OBJSET)) {\n\t\tif (dsl_scan_async_block_should_pause(scn))\n\t\t\treturn (SET_ERROR(ERESTART));\n\t}\n\n\tzio_nowait(zio_free_sync(scn->scn_zio_root, scn->scn_dp->dp_spa,\n\t    dmu_tx_get_txg(tx), bp, 0));\n\tdsl_dir_diduse_space(tx->tx_pool->dp_free_dir, DD_USED_HEAD,\n\t    -bp_get_dsize_sync(scn->scn_dp->dp_spa, bp),\n\t    -BP_GET_PSIZE(bp), -BP_GET_UCSIZE(bp), tx);\n\tscn->scn_visited_this_txg++;\n\tif (BP_GET_DEDUP(bp))\n\t\tscn->scn_dedup_frees_this_txg++;\n\treturn (0);\n}\n\nstatic void\ndsl_scan_update_stats(dsl_scan_t *scn)\n{\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\tuint64_t i;\n\tuint64_t seg_size_total = 0, zio_size_total = 0;\n\tuint64_t seg_count_total = 0, zio_count_total = 0;\n\n\tfor (i = 0; i < spa->spa_root_vdev->vdev_children; i++) {\n\t\tvdev_t *vd = spa->spa_root_vdev->vdev_child[i];\n\t\tdsl_scan_io_queue_t *queue = vd->vdev_scan_io_queue;\n\n\t\tif (queue == NULL)\n\t\t\tcontinue;\n\n\t\tseg_size_total += queue->q_total_seg_size_this_txg;\n\t\tzio_size_total += queue->q_total_zio_size_this_txg;\n\t\tseg_count_total += queue->q_segs_this_txg;\n\t\tzio_count_total += queue->q_zios_this_txg;\n\t}\n\n\tif (seg_count_total == 0 || zio_count_total == 0) {\n\t\tscn->scn_avg_seg_size_this_txg = 0;\n\t\tscn->scn_avg_zio_size_this_txg = 0;\n\t\tscn->scn_segs_this_txg = 0;\n\t\tscn->scn_zios_this_txg = 0;\n\t\treturn;\n\t}\n\n\tscn->scn_avg_seg_size_this_txg = seg_size_total / seg_count_total;\n\tscn->scn_avg_zio_size_this_txg = zio_size_total / zio_count_total;\n\tscn->scn_segs_this_txg = seg_count_total;\n\tscn->scn_zios_this_txg = zio_count_total;\n}\n\nstatic int\nbpobj_dsl_scan_free_block_cb(void *arg, const blkptr_t *bp, boolean_t bp_freed,\n    dmu_tx_t *tx)\n{\n\tASSERT(!bp_freed);\n\treturn (dsl_scan_free_block_cb(arg, bp, tx));\n}\n\nstatic int\ndsl_scan_obsolete_block_cb(void *arg, const blkptr_t *bp, boolean_t bp_freed,\n    dmu_tx_t *tx)\n{\n\tASSERT(!bp_freed);\n\tdsl_scan_t *scn = arg;\n\tconst dva_t *dva = &bp->blk_dva[0];\n\n\tif (dsl_scan_async_block_should_pause(scn))\n\t\treturn (SET_ERROR(ERESTART));\n\n\tspa_vdev_indirect_mark_obsolete(scn->scn_dp->dp_spa,\n\t    DVA_GET_VDEV(dva), DVA_GET_OFFSET(dva),\n\t    DVA_GET_ASIZE(dva), tx);\n\tscn->scn_visited_this_txg++;\n\treturn (0);\n}\n\nboolean_t\ndsl_scan_active(dsl_scan_t *scn)\n{\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\tuint64_t used = 0, comp, uncomp;\n\tboolean_t clones_left;\n\n\tif (spa->spa_load_state != SPA_LOAD_NONE)\n\t\treturn (B_FALSE);\n\tif (spa_shutting_down(spa))\n\t\treturn (B_FALSE);\n\tif ((dsl_scan_is_running(scn) && !dsl_scan_is_paused_scrub(scn)) ||\n\t    (scn->scn_async_destroying && !scn->scn_async_stalled))\n\t\treturn (B_TRUE);\n\n\tif (spa_version(scn->scn_dp->dp_spa) >= SPA_VERSION_DEADLISTS) {\n\t\t(void) bpobj_space(&scn->scn_dp->dp_free_bpobj,\n\t\t    &used, &comp, &uncomp);\n\t}\n\tclones_left = spa_livelist_delete_check(spa);\n\treturn ((used != 0) || (clones_left));\n}\n\nboolean_t\ndsl_errorscrub_active(dsl_scan_t *scn)\n{\n\tspa_t *spa = scn->scn_dp->dp_spa;\n\tif (spa->spa_load_state != SPA_LOAD_NONE)\n\t\treturn (B_FALSE);\n\tif (spa_shutting_down(spa))\n\t\treturn (B_FALSE);\n\tif (dsl_errorscrubbing(scn->scn_dp))\n\t\treturn (B_TRUE);\n\treturn (B_FALSE);\n}\n\nstatic boolean_t\ndsl_scan_check_deferred(vdev_t *vd)\n{\n\tboolean_t need_resilver = B_FALSE;\n\n\tfor (int c = 0; c < vd->vdev_children; c++) {\n\t\tneed_resilver |=\n\t\t    dsl_scan_check_deferred(vd->vdev_child[c]);\n\t}\n\n\tif (!vdev_is_concrete(vd) || vd->vdev_aux ||\n\t    !vd->vdev_ops->vdev_op_leaf)\n\t\treturn (need_resilver);\n\n\tif (!vd->vdev_resilver_deferred)\n\t\tneed_resilver = B_TRUE;\n\n\treturn (need_resilver);\n}\n\nstatic boolean_t\ndsl_scan_need_resilver(spa_t *spa, const dva_t *dva, size_t psize,\n    uint64_t phys_birth)\n{\n\tvdev_t *vd;\n\n\tvd = vdev_lookup_top(spa, DVA_GET_VDEV(dva));\n\n\tif (vd->vdev_ops == &vdev_indirect_ops) {\n\t\t \n\t\treturn (B_TRUE);\n\t}\n\n\tif (DVA_GET_GANG(dva)) {\n\t\t \n\t\treturn (B_TRUE);\n\t}\n\n\t \n\tif (!vdev_dtl_need_resilver(vd, dva, psize, phys_birth))\n\t\treturn (B_FALSE);\n\n\t \n\tif (!dsl_scan_check_deferred(vd))\n\t\treturn (B_FALSE);\n\n\treturn (B_TRUE);\n}\n\nstatic int\ndsl_process_async_destroys(dsl_pool_t *dp, dmu_tx_t *tx)\n{\n\tdsl_scan_t *scn = dp->dp_scan;\n\tspa_t *spa = dp->dp_spa;\n\tint err = 0;\n\n\tif (spa_suspend_async_destroy(spa))\n\t\treturn (0);\n\n\tif (zfs_free_bpobj_enabled &&\n\t    spa_version(spa) >= SPA_VERSION_DEADLISTS) {\n\t\tscn->scn_is_bptree = B_FALSE;\n\t\tscn->scn_async_block_min_time_ms = zfs_free_min_time_ms;\n\t\tscn->scn_zio_root = zio_root(spa, NULL,\n\t\t    NULL, ZIO_FLAG_MUSTSUCCEED);\n\t\terr = bpobj_iterate(&dp->dp_free_bpobj,\n\t\t    bpobj_dsl_scan_free_block_cb, scn, tx);\n\t\tVERIFY0(zio_wait(scn->scn_zio_root));\n\t\tscn->scn_zio_root = NULL;\n\n\t\tif (err != 0 && err != ERESTART)\n\t\t\tzfs_panic_recover(\"error %u from bpobj_iterate()\", err);\n\t}\n\n\tif (err == 0 && spa_feature_is_active(spa, SPA_FEATURE_ASYNC_DESTROY)) {\n\t\tASSERT(scn->scn_async_destroying);\n\t\tscn->scn_is_bptree = B_TRUE;\n\t\tscn->scn_zio_root = zio_root(spa, NULL,\n\t\t    NULL, ZIO_FLAG_MUSTSUCCEED);\n\t\terr = bptree_iterate(dp->dp_meta_objset,\n\t\t    dp->dp_bptree_obj, B_TRUE, dsl_scan_free_block_cb, scn, tx);\n\t\tVERIFY0(zio_wait(scn->scn_zio_root));\n\t\tscn->scn_zio_root = NULL;\n\n\t\tif (err == EIO || err == ECKSUM) {\n\t\t\terr = 0;\n\t\t} else if (err != 0 && err != ERESTART) {\n\t\t\tzfs_panic_recover(\"error %u from \"\n\t\t\t    \"traverse_dataset_destroyed()\", err);\n\t\t}\n\n\t\tif (bptree_is_empty(dp->dp_meta_objset, dp->dp_bptree_obj)) {\n\t\t\t \n\t\t\tspa_feature_decr(spa, SPA_FEATURE_ASYNC_DESTROY, tx);\n\t\t\tASSERT(!spa_feature_is_active(spa,\n\t\t\t    SPA_FEATURE_ASYNC_DESTROY));\n\t\t\tVERIFY0(zap_remove(dp->dp_meta_objset,\n\t\t\t    DMU_POOL_DIRECTORY_OBJECT,\n\t\t\t    DMU_POOL_BPTREE_OBJ, tx));\n\t\t\tVERIFY0(bptree_free(dp->dp_meta_objset,\n\t\t\t    dp->dp_bptree_obj, tx));\n\t\t\tdp->dp_bptree_obj = 0;\n\t\t\tscn->scn_async_destroying = B_FALSE;\n\t\t\tscn->scn_async_stalled = B_FALSE;\n\t\t} else {\n\t\t\t \n\t\t\tscn->scn_async_stalled =\n\t\t\t    (scn->scn_visited_this_txg == 0);\n\t\t}\n\t}\n\tif (scn->scn_visited_this_txg) {\n\t\tzfs_dbgmsg(\"freed %llu blocks in %llums from \"\n\t\t    \"free_bpobj/bptree on %s in txg %llu; err=%u\",\n\t\t    (longlong_t)scn->scn_visited_this_txg,\n\t\t    (longlong_t)\n\t\t    NSEC2MSEC(gethrtime() - scn->scn_sync_start_time),\n\t\t    spa->spa_name, (longlong_t)tx->tx_txg, err);\n\t\tscn->scn_visited_this_txg = 0;\n\t\tscn->scn_dedup_frees_this_txg = 0;\n\n\t\t \n\t\tddt_sync(spa, tx->tx_txg);\n\t\tbrt_sync(spa, tx->tx_txg);\n\t}\n\tif (err != 0)\n\t\treturn (err);\n\tif (dp->dp_free_dir != NULL && !scn->scn_async_destroying &&\n\t    zfs_free_leak_on_eio &&\n\t    (dsl_dir_phys(dp->dp_free_dir)->dd_used_bytes != 0 ||\n\t    dsl_dir_phys(dp->dp_free_dir)->dd_compressed_bytes != 0 ||\n\t    dsl_dir_phys(dp->dp_free_dir)->dd_uncompressed_bytes != 0)) {\n\t\t \n\t\tif (dp->dp_leak_dir == NULL) {\n\t\t\trrw_enter(&dp->dp_config_rwlock, RW_WRITER, FTAG);\n\t\t\t(void) dsl_dir_create_sync(dp, dp->dp_root_dir,\n\t\t\t    LEAK_DIR_NAME, tx);\n\t\t\tVERIFY0(dsl_pool_open_special_dir(dp,\n\t\t\t    LEAK_DIR_NAME, &dp->dp_leak_dir));\n\t\t\trrw_exit(&dp->dp_config_rwlock, FTAG);\n\t\t}\n\t\tdsl_dir_diduse_space(dp->dp_leak_dir, DD_USED_HEAD,\n\t\t    dsl_dir_phys(dp->dp_free_dir)->dd_used_bytes,\n\t\t    dsl_dir_phys(dp->dp_free_dir)->dd_compressed_bytes,\n\t\t    dsl_dir_phys(dp->dp_free_dir)->dd_uncompressed_bytes, tx);\n\t\tdsl_dir_diduse_space(dp->dp_free_dir, DD_USED_HEAD,\n\t\t    -dsl_dir_phys(dp->dp_free_dir)->dd_used_bytes,\n\t\t    -dsl_dir_phys(dp->dp_free_dir)->dd_compressed_bytes,\n\t\t    -dsl_dir_phys(dp->dp_free_dir)->dd_uncompressed_bytes, tx);\n\t}\n\n\tif (dp->dp_free_dir != NULL && !scn->scn_async_destroying &&\n\t    !spa_livelist_delete_check(spa)) {\n\t\t \n\t\tASSERT0(dsl_dir_phys(dp->dp_free_dir)->dd_used_bytes);\n\t\tASSERT0(dsl_dir_phys(dp->dp_free_dir)->dd_compressed_bytes);\n\t\tASSERT0(dsl_dir_phys(dp->dp_free_dir)->dd_uncompressed_bytes);\n\t}\n\n\tspa_notify_waiters(spa);\n\n\tEQUIV(bpobj_is_open(&dp->dp_obsolete_bpobj),\n\t    0 == zap_contains(dp->dp_meta_objset, DMU_POOL_DIRECTORY_OBJECT,\n\t    DMU_POOL_OBSOLETE_BPOBJ));\n\tif (err == 0 && bpobj_is_open(&dp->dp_obsolete_bpobj)) {\n\t\tASSERT(spa_feature_is_active(dp->dp_spa,\n\t\t    SPA_FEATURE_OBSOLETE_COUNTS));\n\n\t\tscn->scn_is_bptree = B_FALSE;\n\t\tscn->scn_async_block_min_time_ms = zfs_obsolete_min_time_ms;\n\t\terr = bpobj_iterate(&dp->dp_obsolete_bpobj,\n\t\t    dsl_scan_obsolete_block_cb, scn, tx);\n\t\tif (err != 0 && err != ERESTART)\n\t\t\tzfs_panic_recover(\"error %u from bpobj_iterate()\", err);\n\n\t\tif (bpobj_is_empty(&dp->dp_obsolete_bpobj))\n\t\t\tdsl_pool_destroy_obsolete_bpobj(dp, tx);\n\t}\n\treturn (0);\n}\n\nstatic void\nname_to_bookmark(char *buf, zbookmark_phys_t *zb)\n{\n\tzb->zb_objset = zfs_strtonum(buf, &buf);\n\tASSERT(*buf == ':');\n\tzb->zb_object = zfs_strtonum(buf + 1, &buf);\n\tASSERT(*buf == ':');\n\tzb->zb_level = (int)zfs_strtonum(buf + 1, &buf);\n\tASSERT(*buf == ':');\n\tzb->zb_blkid = zfs_strtonum(buf + 1, &buf);\n\tASSERT(*buf == '\\0');\n}\n\nstatic void\nname_to_object(char *buf, uint64_t *obj)\n{\n\t*obj = zfs_strtonum(buf, &buf);\n\tASSERT(*buf == '\\0');\n}\n\nstatic void\nread_by_block_level(dsl_scan_t *scn, zbookmark_phys_t zb)\n{\n\tdsl_pool_t *dp = scn->scn_dp;\n\tdsl_dataset_t *ds;\n\tobjset_t *os;\n\tif (dsl_dataset_hold_obj(dp, zb.zb_objset, FTAG, &ds) != 0)\n\t\treturn;\n\n\tif (dmu_objset_from_ds(ds, &os) != 0) {\n\t\tdsl_dataset_rele(ds, FTAG);\n\t\treturn;\n\t}\n\n\t \n\tif (dsl_dataset_get_keystatus(ds->ds_dir) ==\n\t    ZFS_KEYSTATUS_UNAVAILABLE) {\n\t\tdsl_dataset_rele(ds, FTAG);\n\t\treturn;\n\t}\n\n\tdnode_t *dn;\n\tblkptr_t bp;\n\n\tif (dnode_hold(os, zb.zb_object, FTAG, &dn) != 0) {\n\t\tdsl_dataset_rele(ds, FTAG);\n\t\treturn;\n\t}\n\n\trw_enter(&dn->dn_struct_rwlock, RW_READER);\n\tint error = dbuf_dnode_findbp(dn, zb.zb_level, zb.zb_blkid, &bp, NULL,\n\t    NULL);\n\n\tif (error) {\n\t\trw_exit(&dn->dn_struct_rwlock);\n\t\tdnode_rele(dn, FTAG);\n\t\tdsl_dataset_rele(ds, FTAG);\n\t\treturn;\n\t}\n\n\tif (!error && BP_IS_HOLE(&bp)) {\n\t\trw_exit(&dn->dn_struct_rwlock);\n\t\tdnode_rele(dn, FTAG);\n\t\tdsl_dataset_rele(ds, FTAG);\n\t\treturn;\n\t}\n\n\tint zio_flags = ZIO_FLAG_SCAN_THREAD | ZIO_FLAG_RAW |\n\t    ZIO_FLAG_CANFAIL | ZIO_FLAG_SCRUB;\n\n\t \n\tif (zb.zb_level == ZB_ZIL_LEVEL)\n\t\tzio_flags |= ZIO_FLAG_SPECULATIVE;\n\n\tASSERT(!BP_IS_EMBEDDED(&bp));\n\tscan_exec_io(dp, &bp, zio_flags, &zb, NULL);\n\trw_exit(&dn->dn_struct_rwlock);\n\tdnode_rele(dn, FTAG);\n\tdsl_dataset_rele(ds, FTAG);\n}\n\n \nstatic int\nscrub_filesystem(spa_t *spa, uint64_t fs, zbookmark_err_phys_t *zep,\n    int *count)\n{\n\tdsl_dataset_t *ds;\n\tdsl_pool_t *dp = spa->spa_dsl_pool;\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\tint error = dsl_dataset_hold_obj(dp, fs, FTAG, &ds);\n\tif (error != 0)\n\t\treturn (error);\n\n\tuint64_t latest_txg;\n\tuint64_t txg_to_consider = spa->spa_syncing_txg;\n\tboolean_t check_snapshot = B_TRUE;\n\n\terror = find_birth_txg(ds, zep, &latest_txg);\n\n\t \n\tif (error == 0 && zep->zb_birth == latest_txg) {\n\t\t \n\t\tzbookmark_phys_t zb;\n\t\tzep_to_zb(fs, zep, &zb);\n\t\tscn->scn_zio_root = zio_root(spa, NULL, NULL,\n\t\t    ZIO_FLAG_CANFAIL);\n\t\t \n\t\tread_by_block_level(scn, zb);\n\n\t\t(void) zio_wait(scn->scn_zio_root);\n\t\tscn->scn_zio_root = NULL;\n\n\t\tscn->errorscrub_phys.dep_examined++;\n\t\tscn->errorscrub_phys.dep_to_examine--;\n\t\t(*count)++;\n\t\tif ((*count) == zfs_scrub_error_blocks_per_txg ||\n\t\t    dsl_error_scrub_check_suspend(scn, &zb)) {\n\t\t\tdsl_dataset_rele(ds, FTAG);\n\t\t\treturn (SET_ERROR(EFAULT));\n\t\t}\n\n\t\tcheck_snapshot = B_FALSE;\n\t} else if (error == 0) {\n\t\ttxg_to_consider = latest_txg;\n\t}\n\n\t \n\tuint64_t snap_count = 0;\n\tif (dsl_dataset_phys(ds)->ds_snapnames_zapobj != 0) {\n\n\t\terror = zap_count(spa->spa_meta_objset,\n\t\t    dsl_dataset_phys(ds)->ds_snapnames_zapobj, &snap_count);\n\n\t\tif (error != 0) {\n\t\t\tdsl_dataset_rele(ds, FTAG);\n\t\t\treturn (error);\n\t\t}\n\t}\n\n\tif (snap_count == 0) {\n\t\t \n\t\tdsl_dataset_rele(ds, FTAG);\n\t\treturn (0);\n\t}\n\n\tuint64_t snap_obj = dsl_dataset_phys(ds)->ds_prev_snap_obj;\n\tuint64_t snap_obj_txg = dsl_dataset_phys(ds)->ds_prev_snap_txg;\n\n\tdsl_dataset_rele(ds, FTAG);\n\n\t \n\twhile (snap_obj != 0 && zep->zb_birth < snap_obj_txg &&\n\t    snap_obj_txg <= txg_to_consider) {\n\n\t\terror = dsl_dataset_hold_obj(dp, snap_obj, FTAG, &ds);\n\t\tif (error != 0)\n\t\t\treturn (error);\n\n\t\tif (dsl_dir_phys(ds->ds_dir)->dd_head_dataset_obj != fs) {\n\t\t\tsnap_obj = dsl_dataset_phys(ds)->ds_prev_snap_obj;\n\t\t\tsnap_obj_txg = dsl_dataset_phys(ds)->ds_prev_snap_txg;\n\t\t\tdsl_dataset_rele(ds, FTAG);\n\t\t\tcontinue;\n\t\t}\n\n\t\tboolean_t affected = B_TRUE;\n\t\tif (check_snapshot) {\n\t\t\tuint64_t blk_txg;\n\t\t\terror = find_birth_txg(ds, zep, &blk_txg);\n\n\t\t\t \n\t\t\taffected = (error == 0 && zep->zb_birth == blk_txg) ||\n\t\t\t    (error != 0) || (zep->zb_birth == 0);\n\t\t}\n\n\t\t \n\t\tif (affected) {\n\t\t\tzbookmark_phys_t zb;\n\t\t\tzep_to_zb(snap_obj, zep, &zb);\n\t\t\tscn->scn_zio_root = zio_root(spa, NULL, NULL,\n\t\t\t    ZIO_FLAG_CANFAIL);\n\t\t\t \n\t\t\tread_by_block_level(scn, zb);\n\n\t\t\t(void) zio_wait(scn->scn_zio_root);\n\t\t\tscn->scn_zio_root = NULL;\n\n\t\t\tscn->errorscrub_phys.dep_examined++;\n\t\t\tscn->errorscrub_phys.dep_to_examine--;\n\t\t\t(*count)++;\n\t\t\tif ((*count) == zfs_scrub_error_blocks_per_txg ||\n\t\t\t    dsl_error_scrub_check_suspend(scn, &zb)) {\n\t\t\t\tdsl_dataset_rele(ds, FTAG);\n\t\t\t\treturn (EFAULT);\n\t\t\t}\n\t\t}\n\t\tsnap_obj_txg = dsl_dataset_phys(ds)->ds_prev_snap_txg;\n\t\tsnap_obj = dsl_dataset_phys(ds)->ds_prev_snap_obj;\n\t\tdsl_dataset_rele(ds, FTAG);\n\t}\n\treturn (0);\n}\n\nvoid\ndsl_errorscrub_sync(dsl_pool_t *dp, dmu_tx_t *tx)\n{\n\tspa_t *spa = dp->dp_spa;\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\t \n\n\tif (spa_sync_pass(spa) > 1)\n\t\treturn;\n\n\t \n\tif (spa_shutting_down(spa))\n\t\treturn;\n\n\tif (!dsl_errorscrub_active(scn) || dsl_errorscrub_is_paused(scn)) {\n\t\treturn;\n\t}\n\n\tif (dsl_scan_resilvering(scn->scn_dp)) {\n\t\t \n\t\tdsl_scan_cancel(scn->scn_dp);\n\t\treturn;\n\t}\n\n\tspa->spa_scrub_active = B_TRUE;\n\tscn->scn_sync_start_time = gethrtime();\n\n\t \n\tif (zfs_scan_suspend_progress) {\n\t\tuint64_t scan_time_ns = gethrtime() - scn->scn_sync_start_time;\n\t\tint mintime = zfs_scrub_min_time_ms;\n\n\t\twhile (zfs_scan_suspend_progress &&\n\t\t    !txg_sync_waiting(scn->scn_dp) &&\n\t\t    !spa_shutting_down(scn->scn_dp->dp_spa) &&\n\t\t    NSEC2MSEC(scan_time_ns) < mintime) {\n\t\t\tdelay(hz);\n\t\t\tscan_time_ns = gethrtime() - scn->scn_sync_start_time;\n\t\t}\n\t\treturn;\n\t}\n\n\tint i = 0;\n\tzap_attribute_t *za;\n\tzbookmark_phys_t *zb;\n\tboolean_t limit_exceeded = B_FALSE;\n\n\tza = kmem_zalloc(sizeof (zap_attribute_t), KM_SLEEP);\n\tzb = kmem_zalloc(sizeof (zbookmark_phys_t), KM_SLEEP);\n\n\tif (!spa_feature_is_enabled(spa, SPA_FEATURE_HEAD_ERRLOG)) {\n\t\tfor (; zap_cursor_retrieve(&scn->errorscrub_cursor, za) == 0;\n\t\t    zap_cursor_advance(&scn->errorscrub_cursor)) {\n\t\t\tname_to_bookmark(za->za_name, zb);\n\n\t\t\tscn->scn_zio_root = zio_root(dp->dp_spa, NULL,\n\t\t\t    NULL, ZIO_FLAG_CANFAIL);\n\t\t\tdsl_pool_config_enter(dp, FTAG);\n\t\t\tread_by_block_level(scn, *zb);\n\t\t\tdsl_pool_config_exit(dp, FTAG);\n\n\t\t\t(void) zio_wait(scn->scn_zio_root);\n\t\t\tscn->scn_zio_root = NULL;\n\n\t\t\tscn->errorscrub_phys.dep_examined += 1;\n\t\t\tscn->errorscrub_phys.dep_to_examine -= 1;\n\t\t\ti++;\n\t\t\tif (i == zfs_scrub_error_blocks_per_txg ||\n\t\t\t    dsl_error_scrub_check_suspend(scn, zb)) {\n\t\t\t\tlimit_exceeded = B_TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!limit_exceeded)\n\t\t\tdsl_errorscrub_done(scn, B_TRUE, tx);\n\n\t\tdsl_errorscrub_sync_state(scn, tx);\n\t\tkmem_free(za, sizeof (*za));\n\t\tkmem_free(zb, sizeof (*zb));\n\t\treturn;\n\t}\n\n\tint error = 0;\n\tfor (; zap_cursor_retrieve(&scn->errorscrub_cursor, za) == 0;\n\t    zap_cursor_advance(&scn->errorscrub_cursor)) {\n\n\t\tzap_cursor_t *head_ds_cursor;\n\t\tzap_attribute_t *head_ds_attr;\n\t\tzbookmark_err_phys_t head_ds_block;\n\n\t\thead_ds_cursor = kmem_zalloc(sizeof (zap_cursor_t), KM_SLEEP);\n\t\thead_ds_attr = kmem_zalloc(sizeof (zap_attribute_t), KM_SLEEP);\n\n\t\tuint64_t head_ds_err_obj = za->za_first_integer;\n\t\tuint64_t head_ds;\n\t\tname_to_object(za->za_name, &head_ds);\n\t\tboolean_t config_held = B_FALSE;\n\t\tuint64_t top_affected_fs;\n\n\t\tfor (zap_cursor_init(head_ds_cursor, spa->spa_meta_objset,\n\t\t    head_ds_err_obj); zap_cursor_retrieve(head_ds_cursor,\n\t\t    head_ds_attr) == 0; zap_cursor_advance(head_ds_cursor)) {\n\n\t\t\tname_to_errphys(head_ds_attr->za_name, &head_ds_block);\n\n\t\t\t \n\t\t\tif (!dsl_pool_config_held(dp)) {\n\t\t\t\tdsl_pool_config_enter(dp, FTAG);\n\t\t\t\tconfig_held = B_TRUE;\n\t\t\t}\n\n\t\t\terror = find_top_affected_fs(spa,\n\t\t\t    head_ds, &head_ds_block, &top_affected_fs);\n\t\t\tif (error)\n\t\t\t\tbreak;\n\n\t\t\terror = scrub_filesystem(spa, top_affected_fs,\n\t\t\t    &head_ds_block, &i);\n\n\t\t\tif (error == SET_ERROR(EFAULT)) {\n\t\t\t\tlimit_exceeded = B_TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tzap_cursor_fini(head_ds_cursor);\n\t\tkmem_free(head_ds_cursor, sizeof (*head_ds_cursor));\n\t\tkmem_free(head_ds_attr, sizeof (*head_ds_attr));\n\n\t\tif (config_held)\n\t\t\tdsl_pool_config_exit(dp, FTAG);\n\t}\n\n\tkmem_free(za, sizeof (*za));\n\tkmem_free(zb, sizeof (*zb));\n\tif (!limit_exceeded)\n\t\tdsl_errorscrub_done(scn, B_TRUE, tx);\n\n\tdsl_errorscrub_sync_state(scn, tx);\n}\n\n \nvoid\ndsl_scan_sync(dsl_pool_t *dp, dmu_tx_t *tx)\n{\n\tint err = 0;\n\tdsl_scan_t *scn = dp->dp_scan;\n\tspa_t *spa = dp->dp_spa;\n\tstate_sync_type_t sync_type = SYNC_OPTIONAL;\n\n\tif (spa->spa_resilver_deferred &&\n\t    !spa_feature_is_active(dp->dp_spa, SPA_FEATURE_RESILVER_DEFER))\n\t\tspa_feature_incr(spa, SPA_FEATURE_RESILVER_DEFER, tx);\n\n\t \n\tif (dsl_scan_restarting(scn, tx) ||\n\t    (spa->spa_resilver_deferred && zfs_resilver_disable_defer)) {\n\t\tpool_scan_func_t func = POOL_SCAN_SCRUB;\n\t\tdsl_scan_done(scn, B_FALSE, tx);\n\t\tif (vdev_resilver_needed(spa->spa_root_vdev, NULL, NULL))\n\t\t\tfunc = POOL_SCAN_RESILVER;\n\t\tzfs_dbgmsg(\"restarting scan func=%u on %s txg=%llu\",\n\t\t    func, dp->dp_spa->spa_name, (longlong_t)tx->tx_txg);\n\t\tdsl_scan_setup_sync(&func, tx);\n\t}\n\n\t \n\tif (spa_sync_pass(spa) > 1)\n\t\treturn;\n\n\t \n\tif (spa_shutting_down(spa))\n\t\treturn;\n\n\t \n\tif (!scn->scn_async_stalled && !dsl_scan_active(scn))\n\t\treturn;\n\n\t \n\tscn->scn_visited_this_txg = 0;\n\tscn->scn_dedup_frees_this_txg = 0;\n\tscn->scn_holes_this_txg = 0;\n\tscn->scn_lt_min_this_txg = 0;\n\tscn->scn_gt_max_this_txg = 0;\n\tscn->scn_ddt_contained_this_txg = 0;\n\tscn->scn_objsets_visited_this_txg = 0;\n\tscn->scn_avg_seg_size_this_txg = 0;\n\tscn->scn_segs_this_txg = 0;\n\tscn->scn_avg_zio_size_this_txg = 0;\n\tscn->scn_zios_this_txg = 0;\n\tscn->scn_suspending = B_FALSE;\n\tscn->scn_sync_start_time = gethrtime();\n\tspa->spa_scrub_active = B_TRUE;\n\n\t \n\terr = dsl_process_async_destroys(dp, tx);\n\tif (err != 0)\n\t\treturn;\n\n\tif (!dsl_scan_is_running(scn) || dsl_scan_is_paused_scrub(scn))\n\t\treturn;\n\n\t \n\tif (spa->spa_syncing_txg < spa->spa_first_txg + SCAN_IMPORT_WAIT_TXGS)\n\t\treturn;\n\n\t \n\tif (zfs_scan_suspend_progress) {\n\t\tuint64_t scan_time_ns = gethrtime() - scn->scn_sync_start_time;\n\t\tuint_t mintime = (scn->scn_phys.scn_func ==\n\t\t    POOL_SCAN_RESILVER) ? zfs_resilver_min_time_ms :\n\t\t    zfs_scrub_min_time_ms;\n\n\t\twhile (zfs_scan_suspend_progress &&\n\t\t    !txg_sync_waiting(scn->scn_dp) &&\n\t\t    !spa_shutting_down(scn->scn_dp->dp_spa) &&\n\t\t    NSEC2MSEC(scan_time_ns) < mintime) {\n\t\t\tdelay(hz);\n\t\t\tscan_time_ns = gethrtime() - scn->scn_sync_start_time;\n\t\t}\n\t\treturn;\n\t}\n\n\t \n\tif (zfs_scan_report_txgs != 0 &&\n\t    tx->tx_txg % zfs_scan_report_txgs == 0) {\n\t\tscn->scn_issued_before_pass += spa->spa_scan_pass_issued;\n\t\tspa_scan_stat_init(spa);\n\t}\n\n\t \n\tif (!zfs_scan_legacy) {\n\t\tscn->scn_is_sorted = B_TRUE;\n\t\tif (scn->scn_last_checkpoint == 0)\n\t\t\tscn->scn_last_checkpoint = ddi_get_lbolt();\n\t}\n\n\t \n\tif (scn->scn_is_sorted) {\n\t\t \n\t\tif (scn->scn_checkpointing ||\n\t\t    ddi_get_lbolt() - scn->scn_last_checkpoint >\n\t\t    SEC_TO_TICK(zfs_scan_checkpoint_intval)) {\n\t\t\tif (!scn->scn_checkpointing)\n\t\t\t\tzfs_dbgmsg(\"begin scan checkpoint for %s\",\n\t\t\t\t    spa->spa_name);\n\n\t\t\tscn->scn_checkpointing = B_TRUE;\n\t\t\tscn->scn_clearing = B_TRUE;\n\t\t} else {\n\t\t\tboolean_t should_clear = dsl_scan_should_clear(scn);\n\t\t\tif (should_clear && !scn->scn_clearing) {\n\t\t\t\tzfs_dbgmsg(\"begin scan clearing for %s\",\n\t\t\t\t    spa->spa_name);\n\t\t\t\tscn->scn_clearing = B_TRUE;\n\t\t\t} else if (!should_clear && scn->scn_clearing) {\n\t\t\t\tzfs_dbgmsg(\"finish scan clearing for %s\",\n\t\t\t\t    spa->spa_name);\n\t\t\t\tscn->scn_clearing = B_FALSE;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tASSERT0(scn->scn_checkpointing);\n\t\tASSERT0(scn->scn_clearing);\n\t}\n\n\tif (!scn->scn_clearing && scn->scn_done_txg == 0) {\n\t\t \n\t\tdsl_scan_phys_t *scnp = &scn->scn_phys;\n\t\ttaskqid_t prefetch_tqid;\n\n\t\t \n\t\tscn->scn_maxinflight_bytes = MIN(arc_c_max / 4, MAX(1ULL << 20,\n\t\t    zfs_scan_vdev_limit * dsl_scan_count_data_disks(spa)));\n\n\t\tif (scnp->scn_ddt_bookmark.ddb_class <=\n\t\t    scnp->scn_ddt_class_max) {\n\t\t\tASSERT(ZB_IS_ZERO(&scnp->scn_bookmark));\n\t\t\tzfs_dbgmsg(\"doing scan sync for %s txg %llu; \"\n\t\t\t    \"ddt bm=%llu/%llu/%llu/%llx\",\n\t\t\t    spa->spa_name,\n\t\t\t    (longlong_t)tx->tx_txg,\n\t\t\t    (longlong_t)scnp->scn_ddt_bookmark.ddb_class,\n\t\t\t    (longlong_t)scnp->scn_ddt_bookmark.ddb_type,\n\t\t\t    (longlong_t)scnp->scn_ddt_bookmark.ddb_checksum,\n\t\t\t    (longlong_t)scnp->scn_ddt_bookmark.ddb_cursor);\n\t\t} else {\n\t\t\tzfs_dbgmsg(\"doing scan sync for %s txg %llu; \"\n\t\t\t    \"bm=%llu/%llu/%llu/%llu\",\n\t\t\t    spa->spa_name,\n\t\t\t    (longlong_t)tx->tx_txg,\n\t\t\t    (longlong_t)scnp->scn_bookmark.zb_objset,\n\t\t\t    (longlong_t)scnp->scn_bookmark.zb_object,\n\t\t\t    (longlong_t)scnp->scn_bookmark.zb_level,\n\t\t\t    (longlong_t)scnp->scn_bookmark.zb_blkid);\n\t\t}\n\n\t\tscn->scn_zio_root = zio_root(dp->dp_spa, NULL,\n\t\t    NULL, ZIO_FLAG_CANFAIL);\n\n\t\tscn->scn_prefetch_stop = B_FALSE;\n\t\tprefetch_tqid = taskq_dispatch(dp->dp_sync_taskq,\n\t\t    dsl_scan_prefetch_thread, scn, TQ_SLEEP);\n\t\tASSERT(prefetch_tqid != TASKQID_INVALID);\n\n\t\tdsl_pool_config_enter(dp, FTAG);\n\t\tdsl_scan_visit(scn, tx);\n\t\tdsl_pool_config_exit(dp, FTAG);\n\n\t\tmutex_enter(&dp->dp_spa->spa_scrub_lock);\n\t\tscn->scn_prefetch_stop = B_TRUE;\n\t\tcv_broadcast(&spa->spa_scrub_io_cv);\n\t\tmutex_exit(&dp->dp_spa->spa_scrub_lock);\n\n\t\ttaskq_wait_id(dp->dp_sync_taskq, prefetch_tqid);\n\t\t(void) zio_wait(scn->scn_zio_root);\n\t\tscn->scn_zio_root = NULL;\n\n\t\tzfs_dbgmsg(\"scan visited %llu blocks of %s in %llums \"\n\t\t    \"(%llu os's, %llu holes, %llu < mintxg, \"\n\t\t    \"%llu in ddt, %llu > maxtxg)\",\n\t\t    (longlong_t)scn->scn_visited_this_txg,\n\t\t    spa->spa_name,\n\t\t    (longlong_t)NSEC2MSEC(gethrtime() -\n\t\t    scn->scn_sync_start_time),\n\t\t    (longlong_t)scn->scn_objsets_visited_this_txg,\n\t\t    (longlong_t)scn->scn_holes_this_txg,\n\t\t    (longlong_t)scn->scn_lt_min_this_txg,\n\t\t    (longlong_t)scn->scn_ddt_contained_this_txg,\n\t\t    (longlong_t)scn->scn_gt_max_this_txg);\n\n\t\tif (!scn->scn_suspending) {\n\t\t\tASSERT0(avl_numnodes(&scn->scn_queue));\n\t\t\tscn->scn_done_txg = tx->tx_txg + 1;\n\t\t\tif (scn->scn_is_sorted) {\n\t\t\t\tscn->scn_checkpointing = B_TRUE;\n\t\t\t\tscn->scn_clearing = B_TRUE;\n\t\t\t\tscn->scn_issued_before_pass +=\n\t\t\t\t    spa->spa_scan_pass_issued;\n\t\t\t\tspa_scan_stat_init(spa);\n\t\t\t}\n\t\t\tzfs_dbgmsg(\"scan complete for %s txg %llu\",\n\t\t\t    spa->spa_name,\n\t\t\t    (longlong_t)tx->tx_txg);\n\t\t}\n\t} else if (scn->scn_is_sorted && scn->scn_queues_pending != 0) {\n\t\tASSERT(scn->scn_clearing);\n\n\t\t \n\t\tscn->scn_zio_root = zio_root(dp->dp_spa, NULL,\n\t\t    NULL, ZIO_FLAG_CANFAIL);\n\t\tscan_io_queues_run(scn);\n\t\t(void) zio_wait(scn->scn_zio_root);\n\t\tscn->scn_zio_root = NULL;\n\n\t\t \n\t\t(void) dsl_scan_should_clear(scn);\n\t\tdsl_scan_update_stats(scn);\n\n\t\tzfs_dbgmsg(\"scan issued %llu blocks for %s (%llu segs) \"\n\t\t    \"in %llums (avg_block_size = %llu, avg_seg_size = %llu)\",\n\t\t    (longlong_t)scn->scn_zios_this_txg,\n\t\t    spa->spa_name,\n\t\t    (longlong_t)scn->scn_segs_this_txg,\n\t\t    (longlong_t)NSEC2MSEC(gethrtime() -\n\t\t    scn->scn_sync_start_time),\n\t\t    (longlong_t)scn->scn_avg_zio_size_this_txg,\n\t\t    (longlong_t)scn->scn_avg_seg_size_this_txg);\n\t} else if (scn->scn_done_txg != 0 && scn->scn_done_txg <= tx->tx_txg) {\n\t\t \n\t\tzfs_dbgmsg(\"scan issuing complete txg %llu for %s\",\n\t\t    (longlong_t)tx->tx_txg,\n\t\t    spa->spa_name);\n\t\tASSERT3U(scn->scn_done_txg, !=, 0);\n\t\tASSERT0(spa->spa_scrub_inflight);\n\t\tASSERT0(scn->scn_queues_pending);\n\t\tdsl_scan_done(scn, B_TRUE, tx);\n\t\tsync_type = SYNC_MANDATORY;\n\t}\n\n\tdsl_scan_sync_state(scn, tx, sync_type);\n}\n\nstatic void\ncount_block_issued(spa_t *spa, const blkptr_t *bp, boolean_t all)\n{\n\t \n\tif (BP_IS_EMBEDDED(bp))\n\t\treturn;\n\n\t \n\tatomic_add_64(&spa->spa_scan_pass_issued,\n\t    all ? BP_GET_ASIZE(bp) : DVA_GET_ASIZE(&bp->blk_dva[0]));\n}\n\nstatic void\ncount_block_skipped(dsl_scan_t *scn, const blkptr_t *bp, boolean_t all)\n{\n\tif (BP_IS_EMBEDDED(bp))\n\t\treturn;\n\tatomic_add_64(&scn->scn_phys.scn_skipped,\n\t    all ? BP_GET_ASIZE(bp) : DVA_GET_ASIZE(&bp->blk_dva[0]));\n}\n\nstatic void\ncount_block(zfs_all_blkstats_t *zab, const blkptr_t *bp)\n{\n\t \n\tif (zab == NULL)\n\t\treturn;\n\n\tfor (int i = 0; i < 4; i++) {\n\t\tint l = (i < 2) ? BP_GET_LEVEL(bp) : DN_MAX_LEVELS;\n\t\tint t = (i & 1) ? BP_GET_TYPE(bp) : DMU_OT_TOTAL;\n\n\t\tif (t & DMU_OT_NEWTYPE)\n\t\t\tt = DMU_OT_OTHER;\n\t\tzfs_blkstat_t *zb = &zab->zab_type[l][t];\n\t\tint equal;\n\n\t\tzb->zb_count++;\n\t\tzb->zb_asize += BP_GET_ASIZE(bp);\n\t\tzb->zb_lsize += BP_GET_LSIZE(bp);\n\t\tzb->zb_psize += BP_GET_PSIZE(bp);\n\t\tzb->zb_gangs += BP_COUNT_GANG(bp);\n\n\t\tswitch (BP_GET_NDVAS(bp)) {\n\t\tcase 2:\n\t\t\tif (DVA_GET_VDEV(&bp->blk_dva[0]) ==\n\t\t\t    DVA_GET_VDEV(&bp->blk_dva[1]))\n\t\t\t\tzb->zb_ditto_2_of_2_samevdev++;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tequal = (DVA_GET_VDEV(&bp->blk_dva[0]) ==\n\t\t\t    DVA_GET_VDEV(&bp->blk_dva[1])) +\n\t\t\t    (DVA_GET_VDEV(&bp->blk_dva[0]) ==\n\t\t\t    DVA_GET_VDEV(&bp->blk_dva[2])) +\n\t\t\t    (DVA_GET_VDEV(&bp->blk_dva[1]) ==\n\t\t\t    DVA_GET_VDEV(&bp->blk_dva[2]));\n\t\t\tif (equal == 1)\n\t\t\t\tzb->zb_ditto_2_of_3_samevdev++;\n\t\t\telse if (equal == 3)\n\t\t\t\tzb->zb_ditto_3_of_3_samevdev++;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void\nscan_io_queue_insert_impl(dsl_scan_io_queue_t *queue, scan_io_t *sio)\n{\n\tavl_index_t idx;\n\tdsl_scan_t *scn = queue->q_scn;\n\n\tASSERT(MUTEX_HELD(&queue->q_vd->vdev_scan_io_queue_lock));\n\n\tif (unlikely(avl_is_empty(&queue->q_sios_by_addr)))\n\t\tatomic_add_64(&scn->scn_queues_pending, 1);\n\tif (avl_find(&queue->q_sios_by_addr, sio, &idx) != NULL) {\n\t\t \n\t\tsio_free(sio);\n\t\treturn;\n\t}\n\tavl_insert(&queue->q_sios_by_addr, sio, idx);\n\tqueue->q_sio_memused += SIO_GET_MUSED(sio);\n\trange_tree_add(queue->q_exts_by_addr, SIO_GET_OFFSET(sio),\n\t    SIO_GET_ASIZE(sio));\n}\n\n \nstatic void\nscan_io_queue_insert(dsl_scan_io_queue_t *queue, const blkptr_t *bp, int dva_i,\n    int zio_flags, const zbookmark_phys_t *zb)\n{\n\tscan_io_t *sio = sio_alloc(BP_GET_NDVAS(bp));\n\n\tASSERT0(BP_IS_GANG(bp));\n\tASSERT(MUTEX_HELD(&queue->q_vd->vdev_scan_io_queue_lock));\n\n\tbp2sio(bp, sio, dva_i);\n\tsio->sio_flags = zio_flags;\n\tsio->sio_zb = *zb;\n\n\tqueue->q_last_ext_addr = -1;\n\tscan_io_queue_insert_impl(queue, sio);\n}\n\n \nstatic void\ndsl_scan_enqueue(dsl_pool_t *dp, const blkptr_t *bp, int zio_flags,\n    const zbookmark_phys_t *zb)\n{\n\tspa_t *spa = dp->dp_spa;\n\n\tASSERT(!BP_IS_EMBEDDED(bp));\n\n\t \n\tif (!dp->dp_scan->scn_is_sorted || BP_IS_GANG(bp)) {\n\t\tscan_exec_io(dp, bp, zio_flags, zb, NULL);\n\t\treturn;\n\t}\n\n\tfor (int i = 0; i < BP_GET_NDVAS(bp); i++) {\n\t\tdva_t dva;\n\t\tvdev_t *vdev;\n\n\t\tdva = bp->blk_dva[i];\n\t\tvdev = vdev_lookup_top(spa, DVA_GET_VDEV(&dva));\n\t\tASSERT(vdev != NULL);\n\n\t\tmutex_enter(&vdev->vdev_scan_io_queue_lock);\n\t\tif (vdev->vdev_scan_io_queue == NULL)\n\t\t\tvdev->vdev_scan_io_queue = scan_io_queue_create(vdev);\n\t\tASSERT(dp->dp_scan != NULL);\n\t\tscan_io_queue_insert(vdev->vdev_scan_io_queue, bp,\n\t\t    i, zio_flags, zb);\n\t\tmutex_exit(&vdev->vdev_scan_io_queue_lock);\n\t}\n}\n\nstatic int\ndsl_scan_scrub_cb(dsl_pool_t *dp,\n    const blkptr_t *bp, const zbookmark_phys_t *zb)\n{\n\tdsl_scan_t *scn = dp->dp_scan;\n\tspa_t *spa = dp->dp_spa;\n\tuint64_t phys_birth = BP_PHYSICAL_BIRTH(bp);\n\tsize_t psize = BP_GET_PSIZE(bp);\n\tboolean_t needs_io = B_FALSE;\n\tint zio_flags = ZIO_FLAG_SCAN_THREAD | ZIO_FLAG_RAW | ZIO_FLAG_CANFAIL;\n\n\tcount_block(dp->dp_blkstats, bp);\n\tif (phys_birth <= scn->scn_phys.scn_min_txg ||\n\t    phys_birth >= scn->scn_phys.scn_max_txg) {\n\t\tcount_block_skipped(scn, bp, B_TRUE);\n\t\treturn (0);\n\t}\n\n\t \n\tASSERT(!BP_IS_EMBEDDED(bp));\n\n\tASSERT(DSL_SCAN_IS_SCRUB_RESILVER(scn));\n\tif (scn->scn_phys.scn_func == POOL_SCAN_SCRUB) {\n\t\tzio_flags |= ZIO_FLAG_SCRUB;\n\t\tneeds_io = B_TRUE;\n\t} else {\n\t\tASSERT3U(scn->scn_phys.scn_func, ==, POOL_SCAN_RESILVER);\n\t\tzio_flags |= ZIO_FLAG_RESILVER;\n\t\tneeds_io = B_FALSE;\n\t}\n\n\t \n\tif (zb->zb_level == ZB_ZIL_LEVEL)\n\t\tzio_flags |= ZIO_FLAG_SPECULATIVE;\n\n\tfor (int d = 0; d < BP_GET_NDVAS(bp); d++) {\n\t\tconst dva_t *dva = &bp->blk_dva[d];\n\n\t\t \n\t\tuint64_t asize = DVA_GET_ASIZE(dva);\n\t\tscn->scn_phys.scn_examined += asize;\n\t\tspa->spa_scan_pass_exam += asize;\n\n\t\t \n\t\tif (!needs_io)\n\t\t\tneeds_io = dsl_scan_need_resilver(spa, dva, psize,\n\t\t\t    phys_birth);\n\t}\n\n\tif (needs_io && !zfs_no_scrub_io) {\n\t\tdsl_scan_enqueue(dp, bp, zio_flags, zb);\n\t} else {\n\t\tcount_block_skipped(scn, bp, B_TRUE);\n\t}\n\n\t \n\treturn (0);\n}\n\nstatic void\ndsl_scan_scrub_done(zio_t *zio)\n{\n\tspa_t *spa = zio->io_spa;\n\tblkptr_t *bp = zio->io_bp;\n\tdsl_scan_io_queue_t *queue = zio->io_private;\n\n\tabd_free(zio->io_abd);\n\n\tif (queue == NULL) {\n\t\tmutex_enter(&spa->spa_scrub_lock);\n\t\tASSERT3U(spa->spa_scrub_inflight, >=, BP_GET_PSIZE(bp));\n\t\tspa->spa_scrub_inflight -= BP_GET_PSIZE(bp);\n\t\tcv_broadcast(&spa->spa_scrub_io_cv);\n\t\tmutex_exit(&spa->spa_scrub_lock);\n\t} else {\n\t\tmutex_enter(&queue->q_vd->vdev_scan_io_queue_lock);\n\t\tASSERT3U(queue->q_inflight_bytes, >=, BP_GET_PSIZE(bp));\n\t\tqueue->q_inflight_bytes -= BP_GET_PSIZE(bp);\n\t\tcv_broadcast(&queue->q_zio_cv);\n\t\tmutex_exit(&queue->q_vd->vdev_scan_io_queue_lock);\n\t}\n\n\tif (zio->io_error && (zio->io_error != ECKSUM ||\n\t    !(zio->io_flags & ZIO_FLAG_SPECULATIVE))) {\n\t\tif (dsl_errorscrubbing(spa->spa_dsl_pool) &&\n\t\t    !dsl_errorscrub_is_paused(spa->spa_dsl_pool->dp_scan)) {\n\t\t\tatomic_inc_64(&spa->spa_dsl_pool->dp_scan\n\t\t\t    ->errorscrub_phys.dep_errors);\n\t\t} else {\n\t\t\tatomic_inc_64(&spa->spa_dsl_pool->dp_scan->scn_phys\n\t\t\t    .scn_errors);\n\t\t}\n\t}\n}\n\n \nstatic void\nscan_exec_io(dsl_pool_t *dp, const blkptr_t *bp, int zio_flags,\n    const zbookmark_phys_t *zb, dsl_scan_io_queue_t *queue)\n{\n\tspa_t *spa = dp->dp_spa;\n\tdsl_scan_t *scn = dp->dp_scan;\n\tsize_t size = BP_GET_PSIZE(bp);\n\tabd_t *data = abd_alloc_for_io(size, B_FALSE);\n\tzio_t *pio;\n\n\tif (queue == NULL) {\n\t\tASSERT3U(scn->scn_maxinflight_bytes, >, 0);\n\t\tmutex_enter(&spa->spa_scrub_lock);\n\t\twhile (spa->spa_scrub_inflight >= scn->scn_maxinflight_bytes)\n\t\t\tcv_wait(&spa->spa_scrub_io_cv, &spa->spa_scrub_lock);\n\t\tspa->spa_scrub_inflight += BP_GET_PSIZE(bp);\n\t\tmutex_exit(&spa->spa_scrub_lock);\n\t\tpio = scn->scn_zio_root;\n\t} else {\n\t\tkmutex_t *q_lock = &queue->q_vd->vdev_scan_io_queue_lock;\n\n\t\tASSERT3U(queue->q_maxinflight_bytes, >, 0);\n\t\tmutex_enter(q_lock);\n\t\twhile (queue->q_inflight_bytes >= queue->q_maxinflight_bytes)\n\t\t\tcv_wait(&queue->q_zio_cv, q_lock);\n\t\tqueue->q_inflight_bytes += BP_GET_PSIZE(bp);\n\t\tpio = queue->q_zio;\n\t\tmutex_exit(q_lock);\n\t}\n\n\tASSERT(pio != NULL);\n\tcount_block_issued(spa, bp, queue == NULL);\n\tzio_nowait(zio_read(pio, spa, bp, data, size, dsl_scan_scrub_done,\n\t    queue, ZIO_PRIORITY_SCRUB, zio_flags, zb));\n}\n\n \n__attribute__((always_inline)) inline\nstatic int\next_size_compare(const void *x, const void *y)\n{\n\tconst uint64_t *a = x, *b = y;\n\n\treturn (TREE_CMP(*a, *b));\n}\n\nZFS_BTREE_FIND_IN_BUF_FUNC(ext_size_find_in_buf, uint64_t,\n    ext_size_compare)\n\nstatic void\next_size_create(range_tree_t *rt, void *arg)\n{\n\t(void) rt;\n\tzfs_btree_t *size_tree = arg;\n\n\tzfs_btree_create(size_tree, ext_size_compare, ext_size_find_in_buf,\n\t    sizeof (uint64_t));\n}\n\nstatic void\next_size_destroy(range_tree_t *rt, void *arg)\n{\n\t(void) rt;\n\tzfs_btree_t *size_tree = arg;\n\tASSERT0(zfs_btree_numnodes(size_tree));\n\n\tzfs_btree_destroy(size_tree);\n}\n\nstatic uint64_t\next_size_value(range_tree_t *rt, range_seg_gap_t *rsg)\n{\n\t(void) rt;\n\tuint64_t size = rsg->rs_end - rsg->rs_start;\n\tuint64_t score = rsg->rs_fill + ((((rsg->rs_fill << 7) / size) *\n\t    fill_weight * rsg->rs_fill) >> 7);\n\tASSERT3U(rt->rt_shift, >=, 8);\n\treturn (((uint64_t)(64 - highbit64(score)) << 56) | rsg->rs_start);\n}\n\nstatic void\next_size_add(range_tree_t *rt, range_seg_t *rs, void *arg)\n{\n\tzfs_btree_t *size_tree = arg;\n\tASSERT3U(rt->rt_type, ==, RANGE_SEG_GAP);\n\tuint64_t v = ext_size_value(rt, (range_seg_gap_t *)rs);\n\tzfs_btree_add(size_tree, &v);\n}\n\nstatic void\next_size_remove(range_tree_t *rt, range_seg_t *rs, void *arg)\n{\n\tzfs_btree_t *size_tree = arg;\n\tASSERT3U(rt->rt_type, ==, RANGE_SEG_GAP);\n\tuint64_t v = ext_size_value(rt, (range_seg_gap_t *)rs);\n\tzfs_btree_remove(size_tree, &v);\n}\n\nstatic void\next_size_vacate(range_tree_t *rt, void *arg)\n{\n\tzfs_btree_t *size_tree = arg;\n\tzfs_btree_clear(size_tree);\n\tzfs_btree_destroy(size_tree);\n\n\text_size_create(rt, arg);\n}\n\nstatic const range_tree_ops_t ext_size_ops = {\n\t.rtop_create = ext_size_create,\n\t.rtop_destroy = ext_size_destroy,\n\t.rtop_add = ext_size_add,\n\t.rtop_remove = ext_size_remove,\n\t.rtop_vacate = ext_size_vacate\n};\n\n \nstatic int\nsio_addr_compare(const void *x, const void *y)\n{\n\tconst scan_io_t *a = x, *b = y;\n\n\treturn (TREE_CMP(SIO_GET_OFFSET(a), SIO_GET_OFFSET(b)));\n}\n\n \nstatic dsl_scan_io_queue_t *\nscan_io_queue_create(vdev_t *vd)\n{\n\tdsl_scan_t *scn = vd->vdev_spa->spa_dsl_pool->dp_scan;\n\tdsl_scan_io_queue_t *q = kmem_zalloc(sizeof (*q), KM_SLEEP);\n\n\tq->q_scn = scn;\n\tq->q_vd = vd;\n\tq->q_sio_memused = 0;\n\tq->q_last_ext_addr = -1;\n\tcv_init(&q->q_zio_cv, NULL, CV_DEFAULT, NULL);\n\tq->q_exts_by_addr = range_tree_create_gap(&ext_size_ops, RANGE_SEG_GAP,\n\t    &q->q_exts_by_size, 0, vd->vdev_ashift, zfs_scan_max_ext_gap);\n\tavl_create(&q->q_sios_by_addr, sio_addr_compare,\n\t    sizeof (scan_io_t), offsetof(scan_io_t, sio_nodes.sio_addr_node));\n\n\treturn (q);\n}\n\n \nvoid\ndsl_scan_io_queue_destroy(dsl_scan_io_queue_t *queue)\n{\n\tdsl_scan_t *scn = queue->q_scn;\n\tscan_io_t *sio;\n\tvoid *cookie = NULL;\n\n\tASSERT(MUTEX_HELD(&queue->q_vd->vdev_scan_io_queue_lock));\n\n\tif (!avl_is_empty(&queue->q_sios_by_addr))\n\t\tatomic_add_64(&scn->scn_queues_pending, -1);\n\twhile ((sio = avl_destroy_nodes(&queue->q_sios_by_addr, &cookie)) !=\n\t    NULL) {\n\t\tASSERT(range_tree_contains(queue->q_exts_by_addr,\n\t\t    SIO_GET_OFFSET(sio), SIO_GET_ASIZE(sio)));\n\t\tqueue->q_sio_memused -= SIO_GET_MUSED(sio);\n\t\tsio_free(sio);\n\t}\n\n\tASSERT0(queue->q_sio_memused);\n\trange_tree_vacate(queue->q_exts_by_addr, NULL, queue);\n\trange_tree_destroy(queue->q_exts_by_addr);\n\tavl_destroy(&queue->q_sios_by_addr);\n\tcv_destroy(&queue->q_zio_cv);\n\n\tkmem_free(queue, sizeof (*queue));\n}\n\n \nvoid\ndsl_scan_io_queue_vdev_xfer(vdev_t *svd, vdev_t *tvd)\n{\n\tmutex_enter(&svd->vdev_scan_io_queue_lock);\n\tmutex_enter(&tvd->vdev_scan_io_queue_lock);\n\n\tVERIFY3P(tvd->vdev_scan_io_queue, ==, NULL);\n\ttvd->vdev_scan_io_queue = svd->vdev_scan_io_queue;\n\tsvd->vdev_scan_io_queue = NULL;\n\tif (tvd->vdev_scan_io_queue != NULL)\n\t\ttvd->vdev_scan_io_queue->q_vd = tvd;\n\n\tmutex_exit(&tvd->vdev_scan_io_queue_lock);\n\tmutex_exit(&svd->vdev_scan_io_queue_lock);\n}\n\nstatic void\nscan_io_queues_destroy(dsl_scan_t *scn)\n{\n\tvdev_t *rvd = scn->scn_dp->dp_spa->spa_root_vdev;\n\n\tfor (uint64_t i = 0; i < rvd->vdev_children; i++) {\n\t\tvdev_t *tvd = rvd->vdev_child[i];\n\n\t\tmutex_enter(&tvd->vdev_scan_io_queue_lock);\n\t\tif (tvd->vdev_scan_io_queue != NULL)\n\t\t\tdsl_scan_io_queue_destroy(tvd->vdev_scan_io_queue);\n\t\ttvd->vdev_scan_io_queue = NULL;\n\t\tmutex_exit(&tvd->vdev_scan_io_queue_lock);\n\t}\n}\n\nstatic void\ndsl_scan_freed_dva(spa_t *spa, const blkptr_t *bp, int dva_i)\n{\n\tdsl_pool_t *dp = spa->spa_dsl_pool;\n\tdsl_scan_t *scn = dp->dp_scan;\n\tvdev_t *vdev;\n\tkmutex_t *q_lock;\n\tdsl_scan_io_queue_t *queue;\n\tscan_io_t *srch_sio, *sio;\n\tavl_index_t idx;\n\tuint64_t start, size;\n\n\tvdev = vdev_lookup_top(spa, DVA_GET_VDEV(&bp->blk_dva[dva_i]));\n\tASSERT(vdev != NULL);\n\tq_lock = &vdev->vdev_scan_io_queue_lock;\n\tqueue = vdev->vdev_scan_io_queue;\n\n\tmutex_enter(q_lock);\n\tif (queue == NULL) {\n\t\tmutex_exit(q_lock);\n\t\treturn;\n\t}\n\n\tsrch_sio = sio_alloc(BP_GET_NDVAS(bp));\n\tbp2sio(bp, srch_sio, dva_i);\n\tstart = SIO_GET_OFFSET(srch_sio);\n\tsize = SIO_GET_ASIZE(srch_sio);\n\n\t \n\tsio = avl_find(&queue->q_sios_by_addr, srch_sio, &idx);\n\tsio_free(srch_sio);\n\n\tif (sio != NULL) {\n\t\tblkptr_t tmpbp;\n\n\t\t \n\t\tASSERT3U(start, ==, SIO_GET_OFFSET(sio));\n\t\tASSERT3U(size, ==, SIO_GET_ASIZE(sio));\n\t\tavl_remove(&queue->q_sios_by_addr, sio);\n\t\tif (avl_is_empty(&queue->q_sios_by_addr))\n\t\t\tatomic_add_64(&scn->scn_queues_pending, -1);\n\t\tqueue->q_sio_memused -= SIO_GET_MUSED(sio);\n\n\t\tASSERT(range_tree_contains(queue->q_exts_by_addr, start, size));\n\t\trange_tree_remove_fill(queue->q_exts_by_addr, start, size);\n\n\t\t \n\t\tsio2bp(sio, &tmpbp);\n\t\tcount_block_skipped(scn, &tmpbp, B_FALSE);\n\n\t\tsio_free(sio);\n\t}\n\tmutex_exit(q_lock);\n}\n\n \nvoid\ndsl_scan_freed(spa_t *spa, const blkptr_t *bp)\n{\n\tdsl_pool_t *dp = spa->spa_dsl_pool;\n\tdsl_scan_t *scn = dp->dp_scan;\n\n\tASSERT(!BP_IS_EMBEDDED(bp));\n\tASSERT(scn != NULL);\n\tif (!dsl_scan_is_running(scn))\n\t\treturn;\n\n\tfor (int i = 0; i < BP_GET_NDVAS(bp); i++)\n\t\tdsl_scan_freed_dva(spa, bp, i);\n}\n\n \nvoid\ndsl_scan_assess_vdev(dsl_pool_t *dp, vdev_t *vd)\n{\n\tuint64_t min, max;\n\n\tif (!vdev_resilver_needed(vd, &min, &max))\n\t\treturn;\n\n\tif (!dsl_scan_resilvering(dp)) {\n\t\tspa_async_request(dp->dp_spa, SPA_ASYNC_RESILVER);\n\t\treturn;\n\t}\n\n\tif (max <= dp->dp_scan->scn_phys.scn_max_txg)\n\t\treturn;\n\n\t \n\tif (spa_feature_is_enabled(dp->dp_spa, SPA_FEATURE_RESILVER_DEFER))\n\t\tvdev_defer_resilver(vd);\n\telse\n\t\tspa_async_request(dp->dp_spa, SPA_ASYNC_RESILVER);\n}\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_vdev_limit, U64, ZMOD_RW,\n\t\"Max bytes in flight per leaf vdev for scrubs and resilvers\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scrub_min_time_ms, UINT, ZMOD_RW,\n\t\"Min millisecs to scrub per txg\");\n\nZFS_MODULE_PARAM(zfs, zfs_, obsolete_min_time_ms, UINT, ZMOD_RW,\n\t\"Min millisecs to obsolete per txg\");\n\nZFS_MODULE_PARAM(zfs, zfs_, free_min_time_ms, UINT, ZMOD_RW,\n\t\"Min millisecs to free per txg\");\n\nZFS_MODULE_PARAM(zfs, zfs_, resilver_min_time_ms, UINT, ZMOD_RW,\n\t\"Min millisecs to resilver per txg\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_suspend_progress, INT, ZMOD_RW,\n\t\"Set to prevent scans from progressing\");\n\nZFS_MODULE_PARAM(zfs, zfs_, no_scrub_io, INT, ZMOD_RW,\n\t\"Set to disable scrub I/O\");\n\nZFS_MODULE_PARAM(zfs, zfs_, no_scrub_prefetch, INT, ZMOD_RW,\n\t\"Set to disable scrub prefetching\");\n\nZFS_MODULE_PARAM(zfs, zfs_, async_block_max_blocks, U64, ZMOD_RW,\n\t\"Max number of blocks freed in one txg\");\n\nZFS_MODULE_PARAM(zfs, zfs_, max_async_dedup_frees, U64, ZMOD_RW,\n\t\"Max number of dedup blocks freed in one txg\");\n\nZFS_MODULE_PARAM(zfs, zfs_, free_bpobj_enabled, INT, ZMOD_RW,\n\t\"Enable processing of the free_bpobj\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_blkstats, INT, ZMOD_RW,\n\t\"Enable block statistics calculation during scrub\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_mem_lim_fact, UINT, ZMOD_RW,\n\t\"Fraction of RAM for scan hard limit\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_issue_strategy, UINT, ZMOD_RW,\n\t\"IO issuing strategy during scrubbing. 0 = default, 1 = LBA, 2 = size\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_legacy, INT, ZMOD_RW,\n\t\"Scrub using legacy non-sequential method\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_checkpoint_intval, UINT, ZMOD_RW,\n\t\"Scan progress on-disk checkpointing interval\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_max_ext_gap, U64, ZMOD_RW,\n\t\"Max gap in bytes between sequential scrub / resilver I/Os\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_mem_lim_soft_fact, UINT, ZMOD_RW,\n\t\"Fraction of hard limit used as soft limit\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_strict_mem_lim, INT, ZMOD_RW,\n\t\"Tunable to attempt to reduce lock contention\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_fill_weight, UINT, ZMOD_RW,\n\t\"Tunable to adjust bias towards more filled segments during scans\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scan_report_txgs, UINT, ZMOD_RW,\n\t\"Tunable to report resilver performance over the last N txgs\");\n\nZFS_MODULE_PARAM(zfs, zfs_, resilver_disable_defer, INT, ZMOD_RW,\n\t\"Process all resilvers immediately\");\n\nZFS_MODULE_PARAM(zfs, zfs_, scrub_error_blocks_per_txg, UINT, ZMOD_RW,\n\t\"Error blocks to be scrubbed in one txg\");\n \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}