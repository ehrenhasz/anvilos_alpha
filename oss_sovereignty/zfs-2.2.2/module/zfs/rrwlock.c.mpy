{
  "module_name": "rrwlock.c",
  "hash_id": "5b111008cb91aec8ca5c8943b039329b383bf04f118f1a0d0c974136df6ef4a0",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/rrwlock.c",
  "human_readable_source": " \n \n \n\n#include <sys/rrwlock.h>\n#include <sys/trace_zfs.h>\n\n \n\n \nuint_t rrw_tsd_key;\n\ntypedef struct rrw_node {\n\tstruct rrw_node *rn_next;\n\trrwlock_t *rn_rrl;\n\tconst void *rn_tag;\n} rrw_node_t;\n\nstatic rrw_node_t *\nrrn_find(rrwlock_t *rrl)\n{\n\trrw_node_t *rn;\n\n\tif (zfs_refcount_count(&rrl->rr_linked_rcount) == 0)\n\t\treturn (NULL);\n\n\tfor (rn = tsd_get(rrw_tsd_key); rn != NULL; rn = rn->rn_next) {\n\t\tif (rn->rn_rrl == rrl)\n\t\t\treturn (rn);\n\t}\n\treturn (NULL);\n}\n\n \nstatic void\nrrn_add(rrwlock_t *rrl, const void *tag)\n{\n\trrw_node_t *rn;\n\n\trn = kmem_alloc(sizeof (*rn), KM_SLEEP);\n\trn->rn_rrl = rrl;\n\trn->rn_next = tsd_get(rrw_tsd_key);\n\trn->rn_tag = tag;\n\tVERIFY(tsd_set(rrw_tsd_key, rn) == 0);\n}\n\n \nstatic boolean_t\nrrn_find_and_remove(rrwlock_t *rrl, const void *tag)\n{\n\trrw_node_t *rn;\n\trrw_node_t *prev = NULL;\n\n\tif (zfs_refcount_count(&rrl->rr_linked_rcount) == 0)\n\t\treturn (B_FALSE);\n\n\tfor (rn = tsd_get(rrw_tsd_key); rn != NULL; rn = rn->rn_next) {\n\t\tif (rn->rn_rrl == rrl && rn->rn_tag == tag) {\n\t\t\tif (prev)\n\t\t\t\tprev->rn_next = rn->rn_next;\n\t\t\telse\n\t\t\t\tVERIFY(tsd_set(rrw_tsd_key, rn->rn_next) == 0);\n\t\t\tkmem_free(rn, sizeof (*rn));\n\t\t\treturn (B_TRUE);\n\t\t}\n\t\tprev = rn;\n\t}\n\treturn (B_FALSE);\n}\n\nvoid\nrrw_init(rrwlock_t *rrl, boolean_t track_all)\n{\n\tmutex_init(&rrl->rr_lock, NULL, MUTEX_DEFAULT, NULL);\n\tcv_init(&rrl->rr_cv, NULL, CV_DEFAULT, NULL);\n\trrl->rr_writer = NULL;\n\tzfs_refcount_create(&rrl->rr_anon_rcount);\n\tzfs_refcount_create(&rrl->rr_linked_rcount);\n\trrl->rr_writer_wanted = B_FALSE;\n\trrl->rr_track_all = track_all;\n}\n\nvoid\nrrw_destroy(rrwlock_t *rrl)\n{\n\tmutex_destroy(&rrl->rr_lock);\n\tcv_destroy(&rrl->rr_cv);\n\tASSERT(rrl->rr_writer == NULL);\n\tzfs_refcount_destroy(&rrl->rr_anon_rcount);\n\tzfs_refcount_destroy(&rrl->rr_linked_rcount);\n}\n\nstatic void\nrrw_enter_read_impl(rrwlock_t *rrl, boolean_t prio, const void *tag)\n{\n\tmutex_enter(&rrl->rr_lock);\n#if !defined(ZFS_DEBUG) && defined(_KERNEL)\n\tif (rrl->rr_writer == NULL && !rrl->rr_writer_wanted &&\n\t    !rrl->rr_track_all) {\n\t\trrl->rr_anon_rcount.rc_count++;\n\t\tmutex_exit(&rrl->rr_lock);\n\t\treturn;\n\t}\n\tDTRACE_PROBE(zfs__rrwfastpath__rdmiss);\n#endif\n\tASSERT(rrl->rr_writer != curthread);\n\tASSERT(zfs_refcount_count(&rrl->rr_anon_rcount) >= 0);\n\n\twhile (rrl->rr_writer != NULL || (rrl->rr_writer_wanted &&\n\t    zfs_refcount_is_zero(&rrl->rr_anon_rcount) && !prio &&\n\t    rrn_find(rrl) == NULL))\n\t\tcv_wait(&rrl->rr_cv, &rrl->rr_lock);\n\n\tif (rrl->rr_writer_wanted || rrl->rr_track_all) {\n\t\t \n\t\trrn_add(rrl, tag);\n\t\t(void) zfs_refcount_add(&rrl->rr_linked_rcount, tag);\n\t} else {\n\t\t(void) zfs_refcount_add(&rrl->rr_anon_rcount, tag);\n\t}\n\tASSERT(rrl->rr_writer == NULL);\n\tmutex_exit(&rrl->rr_lock);\n}\n\nvoid\nrrw_enter_read(rrwlock_t *rrl, const void *tag)\n{\n\trrw_enter_read_impl(rrl, B_FALSE, tag);\n}\n\n \nvoid\nrrw_enter_read_prio(rrwlock_t *rrl, const void *tag)\n{\n\trrw_enter_read_impl(rrl, B_TRUE, tag);\n}\n\n\nvoid\nrrw_enter_write(rrwlock_t *rrl)\n{\n\tmutex_enter(&rrl->rr_lock);\n\tASSERT(rrl->rr_writer != curthread);\n\n\twhile (zfs_refcount_count(&rrl->rr_anon_rcount) > 0 ||\n\t    zfs_refcount_count(&rrl->rr_linked_rcount) > 0 ||\n\t    rrl->rr_writer != NULL) {\n\t\trrl->rr_writer_wanted = B_TRUE;\n\t\tcv_wait(&rrl->rr_cv, &rrl->rr_lock);\n\t}\n\trrl->rr_writer_wanted = B_FALSE;\n\trrl->rr_writer = curthread;\n\tmutex_exit(&rrl->rr_lock);\n}\n\nvoid\nrrw_enter(rrwlock_t *rrl, krw_t rw, const void *tag)\n{\n\tif (rw == RW_READER)\n\t\trrw_enter_read(rrl, tag);\n\telse\n\t\trrw_enter_write(rrl);\n}\n\nvoid\nrrw_exit(rrwlock_t *rrl, const void *tag)\n{\n\tmutex_enter(&rrl->rr_lock);\n#if !defined(ZFS_DEBUG) && defined(_KERNEL)\n\tif (!rrl->rr_writer && rrl->rr_linked_rcount.rc_count == 0) {\n\t\trrl->rr_anon_rcount.rc_count--;\n\t\tif (rrl->rr_anon_rcount.rc_count == 0)\n\t\t\tcv_broadcast(&rrl->rr_cv);\n\t\tmutex_exit(&rrl->rr_lock);\n\t\treturn;\n\t}\n\tDTRACE_PROBE(zfs__rrwfastpath__exitmiss);\n#endif\n\tASSERT(!zfs_refcount_is_zero(&rrl->rr_anon_rcount) ||\n\t    !zfs_refcount_is_zero(&rrl->rr_linked_rcount) ||\n\t    rrl->rr_writer != NULL);\n\n\tif (rrl->rr_writer == NULL) {\n\t\tint64_t count;\n\t\tif (rrn_find_and_remove(rrl, tag)) {\n\t\t\tcount = zfs_refcount_remove(\n\t\t\t    &rrl->rr_linked_rcount, tag);\n\t\t} else {\n\t\t\tASSERT(!rrl->rr_track_all);\n\t\t\tcount = zfs_refcount_remove(&rrl->rr_anon_rcount, tag);\n\t\t}\n\t\tif (count == 0)\n\t\t\tcv_broadcast(&rrl->rr_cv);\n\t} else {\n\t\tASSERT(rrl->rr_writer == curthread);\n\t\tASSERT(zfs_refcount_is_zero(&rrl->rr_anon_rcount) &&\n\t\t    zfs_refcount_is_zero(&rrl->rr_linked_rcount));\n\t\trrl->rr_writer = NULL;\n\t\tcv_broadcast(&rrl->rr_cv);\n\t}\n\tmutex_exit(&rrl->rr_lock);\n}\n\n \nboolean_t\nrrw_held(rrwlock_t *rrl, krw_t rw)\n{\n\tboolean_t held;\n\n\tmutex_enter(&rrl->rr_lock);\n\tif (rw == RW_WRITER) {\n\t\theld = (rrl->rr_writer == curthread);\n\t} else {\n\t\theld = (!zfs_refcount_is_zero(&rrl->rr_anon_rcount) ||\n\t\t    rrn_find(rrl) != NULL);\n\t}\n\tmutex_exit(&rrl->rr_lock);\n\n\treturn (held);\n}\n\nvoid\nrrw_tsd_destroy(void *arg)\n{\n\trrw_node_t *rn = arg;\n\tif (rn != NULL) {\n\t\tpanic(\"thread %p terminating with rrw lock %p held\",\n\t\t    (void *)curthread, (void *)rn->rn_rrl);\n\t}\n}\n\n \nvoid\nrrm_init(rrmlock_t *rrl, boolean_t track_all)\n{\n\tint i;\n\n\tfor (i = 0; i < RRM_NUM_LOCKS; i++)\n\t\trrw_init(&rrl->locks[i], track_all);\n}\n\nvoid\nrrm_destroy(rrmlock_t *rrl)\n{\n\tint i;\n\n\tfor (i = 0; i < RRM_NUM_LOCKS; i++)\n\t\trrw_destroy(&rrl->locks[i]);\n}\n\nvoid\nrrm_enter(rrmlock_t *rrl, krw_t rw, const void *tag)\n{\n\tif (rw == RW_READER)\n\t\trrm_enter_read(rrl, tag);\n\telse\n\t\trrm_enter_write(rrl);\n}\n\n \n#define\tRRM_TD_LOCK()\t(((uint32_t)(uintptr_t)(curthread)) % RRM_NUM_LOCKS)\n\nvoid\nrrm_enter_read(rrmlock_t *rrl, const void *tag)\n{\n\trrw_enter_read(&rrl->locks[RRM_TD_LOCK()], tag);\n}\n\nvoid\nrrm_enter_write(rrmlock_t *rrl)\n{\n\tint i;\n\n\tfor (i = 0; i < RRM_NUM_LOCKS; i++)\n\t\trrw_enter_write(&rrl->locks[i]);\n}\n\nvoid\nrrm_exit(rrmlock_t *rrl, const void *tag)\n{\n\tint i;\n\n\tif (rrl->locks[0].rr_writer == curthread) {\n\t\tfor (i = 0; i < RRM_NUM_LOCKS; i++)\n\t\t\trrw_exit(&rrl->locks[i], tag);\n\t} else {\n\t\trrw_exit(&rrl->locks[RRM_TD_LOCK()], tag);\n\t}\n}\n\nboolean_t\nrrm_held(rrmlock_t *rrl, krw_t rw)\n{\n\tif (rw == RW_WRITER) {\n\t\treturn (rrw_held(&rrl->locks[0], rw));\n\t} else {\n\t\treturn (rrw_held(&rrl->locks[RRM_TD_LOCK()], rw));\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}