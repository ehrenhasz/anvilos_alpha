{
  "module_name": "vdev_queue.c",
  "hash_id": "88a4a1c37f0ed5f0de10191c95c55aac9c426ad12f286d70555c10442b0afb7c",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/vdev_queue.c",
  "human_readable_source": " \n \n\n \n\n#include <sys/zfs_context.h>\n#include <sys/vdev_impl.h>\n#include <sys/spa_impl.h>\n#include <sys/zio.h>\n#include <sys/avl.h>\n#include <sys/dsl_pool.h>\n#include <sys/metaslab_impl.h>\n#include <sys/spa.h>\n#include <sys/abd.h>\n\n \n\n \nuint_t zfs_vdev_max_active = 1000;\n\n \nstatic uint_t zfs_vdev_sync_read_min_active = 10;\nstatic uint_t zfs_vdev_sync_read_max_active = 10;\nstatic uint_t zfs_vdev_sync_write_min_active = 10;\nstatic uint_t zfs_vdev_sync_write_max_active = 10;\nstatic uint_t zfs_vdev_async_read_min_active = 1;\n  uint_t zfs_vdev_async_read_max_active = 3;\nstatic uint_t zfs_vdev_async_write_min_active = 2;\n  uint_t zfs_vdev_async_write_max_active = 10;\nstatic uint_t zfs_vdev_scrub_min_active = 1;\nstatic uint_t zfs_vdev_scrub_max_active = 3;\nstatic uint_t zfs_vdev_removal_min_active = 1;\nstatic uint_t zfs_vdev_removal_max_active = 2;\nstatic uint_t zfs_vdev_initializing_min_active = 1;\nstatic uint_t zfs_vdev_initializing_max_active = 1;\nstatic uint_t zfs_vdev_trim_min_active = 1;\nstatic uint_t zfs_vdev_trim_max_active = 2;\nstatic uint_t zfs_vdev_rebuild_min_active = 1;\nstatic uint_t zfs_vdev_rebuild_max_active = 3;\n\n \nuint_t zfs_vdev_async_write_active_min_dirty_percent = 30;\nuint_t zfs_vdev_async_write_active_max_dirty_percent = 60;\n\n \nstatic uint_t zfs_vdev_nia_delay = 5;\n\n \nstatic uint_t zfs_vdev_nia_credit = 5;\n\n \nstatic uint_t zfs_vdev_aggregation_limit = 1 << 20;\nstatic uint_t zfs_vdev_aggregation_limit_non_rotating = SPA_OLD_MAXBLOCKSIZE;\nstatic uint_t zfs_vdev_read_gap_limit = 32 << 10;\nstatic uint_t zfs_vdev_write_gap_limit = 4 << 10;\n\n \n#ifdef _KERNEL\nuint_t zfs_vdev_queue_depth_pct = 1000;\n#else\nuint_t zfs_vdev_queue_depth_pct = 300;\n#endif\n\n \nuint_t zfs_vdev_def_queue_depth = 32;\n\nstatic int\nvdev_queue_offset_compare(const void *x1, const void *x2)\n{\n\tconst zio_t *z1 = (const zio_t *)x1;\n\tconst zio_t *z2 = (const zio_t *)x2;\n\n\tint cmp = TREE_CMP(z1->io_offset, z2->io_offset);\n\n\tif (likely(cmp))\n\t\treturn (cmp);\n\n\treturn (TREE_PCMP(z1, z2));\n}\n\n#define\tVDQ_T_SHIFT 29\n\nstatic int\nvdev_queue_to_compare(const void *x1, const void *x2)\n{\n\tconst zio_t *z1 = (const zio_t *)x1;\n\tconst zio_t *z2 = (const zio_t *)x2;\n\n\tint tcmp = TREE_CMP(z1->io_timestamp >> VDQ_T_SHIFT,\n\t    z2->io_timestamp >> VDQ_T_SHIFT);\n\tint ocmp = TREE_CMP(z1->io_offset, z2->io_offset);\n\tint cmp = tcmp ? tcmp : ocmp;\n\n\tif (likely(cmp | (z1->io_queue_state == ZIO_QS_NONE)))\n\t\treturn (cmp);\n\n\treturn (TREE_PCMP(z1, z2));\n}\n\nstatic inline boolean_t\nvdev_queue_class_fifo(zio_priority_t p)\n{\n\treturn (p == ZIO_PRIORITY_SYNC_READ || p == ZIO_PRIORITY_SYNC_WRITE ||\n\t    p == ZIO_PRIORITY_TRIM);\n}\n\nstatic void\nvdev_queue_class_add(vdev_queue_t *vq, zio_t *zio)\n{\n\tzio_priority_t p = zio->io_priority;\n\tvq->vq_cqueued |= 1U << p;\n\tif (vdev_queue_class_fifo(p)) {\n\t\tlist_insert_tail(&vq->vq_class[p].vqc_list, zio);\n\t\tvq->vq_class[p].vqc_list_numnodes++;\n\t}\n\telse\n\t\tavl_add(&vq->vq_class[p].vqc_tree, zio);\n}\n\nstatic void\nvdev_queue_class_remove(vdev_queue_t *vq, zio_t *zio)\n{\n\tzio_priority_t p = zio->io_priority;\n\tuint32_t empty;\n\tif (vdev_queue_class_fifo(p)) {\n\t\tlist_t *list = &vq->vq_class[p].vqc_list;\n\t\tlist_remove(list, zio);\n\t\tempty = list_is_empty(list);\n\t\tvq->vq_class[p].vqc_list_numnodes--;\n\t} else {\n\t\tavl_tree_t *tree = &vq->vq_class[p].vqc_tree;\n\t\tavl_remove(tree, zio);\n\t\tempty = avl_is_empty(tree);\n\t}\n\tvq->vq_cqueued &= ~(empty << p);\n}\n\nstatic uint_t\nvdev_queue_class_min_active(vdev_queue_t *vq, zio_priority_t p)\n{\n\tswitch (p) {\n\tcase ZIO_PRIORITY_SYNC_READ:\n\t\treturn (zfs_vdev_sync_read_min_active);\n\tcase ZIO_PRIORITY_SYNC_WRITE:\n\t\treturn (zfs_vdev_sync_write_min_active);\n\tcase ZIO_PRIORITY_ASYNC_READ:\n\t\treturn (zfs_vdev_async_read_min_active);\n\tcase ZIO_PRIORITY_ASYNC_WRITE:\n\t\treturn (zfs_vdev_async_write_min_active);\n\tcase ZIO_PRIORITY_SCRUB:\n\t\treturn (vq->vq_ia_active == 0 ? zfs_vdev_scrub_min_active :\n\t\t    MIN(vq->vq_nia_credit, zfs_vdev_scrub_min_active));\n\tcase ZIO_PRIORITY_REMOVAL:\n\t\treturn (vq->vq_ia_active == 0 ? zfs_vdev_removal_min_active :\n\t\t    MIN(vq->vq_nia_credit, zfs_vdev_removal_min_active));\n\tcase ZIO_PRIORITY_INITIALIZING:\n\t\treturn (vq->vq_ia_active == 0 ?zfs_vdev_initializing_min_active:\n\t\t    MIN(vq->vq_nia_credit, zfs_vdev_initializing_min_active));\n\tcase ZIO_PRIORITY_TRIM:\n\t\treturn (zfs_vdev_trim_min_active);\n\tcase ZIO_PRIORITY_REBUILD:\n\t\treturn (vq->vq_ia_active == 0 ? zfs_vdev_rebuild_min_active :\n\t\t    MIN(vq->vq_nia_credit, zfs_vdev_rebuild_min_active));\n\tdefault:\n\t\tpanic(\"invalid priority %u\", p);\n\t\treturn (0);\n\t}\n}\n\nstatic uint_t\nvdev_queue_max_async_writes(spa_t *spa)\n{\n\tuint_t writes;\n\tuint64_t dirty = 0;\n\tdsl_pool_t *dp = spa_get_dsl(spa);\n\tuint64_t min_bytes = zfs_dirty_data_max *\n\t    zfs_vdev_async_write_active_min_dirty_percent / 100;\n\tuint64_t max_bytes = zfs_dirty_data_max *\n\t    zfs_vdev_async_write_active_max_dirty_percent / 100;\n\n\t \n\tif (dp == NULL)\n\t\treturn (zfs_vdev_async_write_max_active);\n\n\t \n\tdirty = dp->dp_dirty_total;\n\tif (dirty > max_bytes || spa_has_pending_synctask(spa))\n\t\treturn (zfs_vdev_async_write_max_active);\n\n\tif (dirty < min_bytes)\n\t\treturn (zfs_vdev_async_write_min_active);\n\n\t \n\twrites = (dirty - min_bytes) *\n\t    (zfs_vdev_async_write_max_active -\n\t    zfs_vdev_async_write_min_active) /\n\t    (max_bytes - min_bytes) +\n\t    zfs_vdev_async_write_min_active;\n\tASSERT3U(writes, >=, zfs_vdev_async_write_min_active);\n\tASSERT3U(writes, <=, zfs_vdev_async_write_max_active);\n\treturn (writes);\n}\n\nstatic uint_t\nvdev_queue_class_max_active(vdev_queue_t *vq, zio_priority_t p)\n{\n\tswitch (p) {\n\tcase ZIO_PRIORITY_SYNC_READ:\n\t\treturn (zfs_vdev_sync_read_max_active);\n\tcase ZIO_PRIORITY_SYNC_WRITE:\n\t\treturn (zfs_vdev_sync_write_max_active);\n\tcase ZIO_PRIORITY_ASYNC_READ:\n\t\treturn (zfs_vdev_async_read_max_active);\n\tcase ZIO_PRIORITY_ASYNC_WRITE:\n\t\treturn (vdev_queue_max_async_writes(vq->vq_vdev->vdev_spa));\n\tcase ZIO_PRIORITY_SCRUB:\n\t\tif (vq->vq_ia_active > 0) {\n\t\t\treturn (MIN(vq->vq_nia_credit,\n\t\t\t    zfs_vdev_scrub_min_active));\n\t\t} else if (vq->vq_nia_credit < zfs_vdev_nia_delay)\n\t\t\treturn (MAX(1, zfs_vdev_scrub_min_active));\n\t\treturn (zfs_vdev_scrub_max_active);\n\tcase ZIO_PRIORITY_REMOVAL:\n\t\tif (vq->vq_ia_active > 0) {\n\t\t\treturn (MIN(vq->vq_nia_credit,\n\t\t\t    zfs_vdev_removal_min_active));\n\t\t} else if (vq->vq_nia_credit < zfs_vdev_nia_delay)\n\t\t\treturn (MAX(1, zfs_vdev_removal_min_active));\n\t\treturn (zfs_vdev_removal_max_active);\n\tcase ZIO_PRIORITY_INITIALIZING:\n\t\tif (vq->vq_ia_active > 0) {\n\t\t\treturn (MIN(vq->vq_nia_credit,\n\t\t\t    zfs_vdev_initializing_min_active));\n\t\t} else if (vq->vq_nia_credit < zfs_vdev_nia_delay)\n\t\t\treturn (MAX(1, zfs_vdev_initializing_min_active));\n\t\treturn (zfs_vdev_initializing_max_active);\n\tcase ZIO_PRIORITY_TRIM:\n\t\treturn (zfs_vdev_trim_max_active);\n\tcase ZIO_PRIORITY_REBUILD:\n\t\tif (vq->vq_ia_active > 0) {\n\t\t\treturn (MIN(vq->vq_nia_credit,\n\t\t\t    zfs_vdev_rebuild_min_active));\n\t\t} else if (vq->vq_nia_credit < zfs_vdev_nia_delay)\n\t\t\treturn (MAX(1, zfs_vdev_rebuild_min_active));\n\t\treturn (zfs_vdev_rebuild_max_active);\n\tdefault:\n\t\tpanic(\"invalid priority %u\", p);\n\t\treturn (0);\n\t}\n}\n\n \nstatic zio_priority_t\nvdev_queue_class_to_issue(vdev_queue_t *vq)\n{\n\tuint32_t cq = vq->vq_cqueued;\n\tzio_priority_t p, p1;\n\n\tif (cq == 0 || vq->vq_active >= zfs_vdev_max_active)\n\t\treturn (ZIO_PRIORITY_NUM_QUEUEABLE);\n\n\t \n\tp1 = vq->vq_last_prio + 1;\n\tif (p1 >= ZIO_PRIORITY_NUM_QUEUEABLE)\n\t\tp1 = 0;\n\tfor (p = p1; p < ZIO_PRIORITY_NUM_QUEUEABLE; p++) {\n\t\tif ((cq & (1U << p)) != 0 && vq->vq_cactive[p] <\n\t\t    vdev_queue_class_min_active(vq, p))\n\t\t\tgoto found;\n\t}\n\tfor (p = 0; p < p1; p++) {\n\t\tif ((cq & (1U << p)) != 0 && vq->vq_cactive[p] <\n\t\t    vdev_queue_class_min_active(vq, p))\n\t\t\tgoto found;\n\t}\n\n\t \n\tfor (p = 0; p < ZIO_PRIORITY_NUM_QUEUEABLE; p++) {\n\t\tif ((cq & (1U << p)) != 0 && vq->vq_cactive[p] <\n\t\t    vdev_queue_class_max_active(vq, p))\n\t\t\tbreak;\n\t}\n\nfound:\n\tvq->vq_last_prio = p;\n\treturn (p);\n}\n\nvoid\nvdev_queue_init(vdev_t *vd)\n{\n\tvdev_queue_t *vq = &vd->vdev_queue;\n\tzio_priority_t p;\n\n\tvq->vq_vdev = vd;\n\n\tfor (p = 0; p < ZIO_PRIORITY_NUM_QUEUEABLE; p++) {\n\t\tif (vdev_queue_class_fifo(p)) {\n\t\t\tlist_create(&vq->vq_class[p].vqc_list,\n\t\t\t    sizeof (zio_t),\n\t\t\t    offsetof(struct zio, io_queue_node.l));\n\t\t} else {\n\t\t\tavl_create(&vq->vq_class[p].vqc_tree,\n\t\t\t    vdev_queue_to_compare, sizeof (zio_t),\n\t\t\t    offsetof(struct zio, io_queue_node.a));\n\t\t}\n\t}\n\tavl_create(&vq->vq_read_offset_tree,\n\t    vdev_queue_offset_compare, sizeof (zio_t),\n\t    offsetof(struct zio, io_offset_node));\n\tavl_create(&vq->vq_write_offset_tree,\n\t    vdev_queue_offset_compare, sizeof (zio_t),\n\t    offsetof(struct zio, io_offset_node));\n\n\tvq->vq_last_offset = 0;\n\tlist_create(&vq->vq_active_list, sizeof (struct zio),\n\t    offsetof(struct zio, io_queue_node.l));\n\tmutex_init(&vq->vq_lock, NULL, MUTEX_DEFAULT, NULL);\n}\n\nvoid\nvdev_queue_fini(vdev_t *vd)\n{\n\tvdev_queue_t *vq = &vd->vdev_queue;\n\n\tfor (zio_priority_t p = 0; p < ZIO_PRIORITY_NUM_QUEUEABLE; p++) {\n\t\tif (vdev_queue_class_fifo(p))\n\t\t\tlist_destroy(&vq->vq_class[p].vqc_list);\n\t\telse\n\t\t\tavl_destroy(&vq->vq_class[p].vqc_tree);\n\t}\n\tavl_destroy(&vq->vq_read_offset_tree);\n\tavl_destroy(&vq->vq_write_offset_tree);\n\n\tlist_destroy(&vq->vq_active_list);\n\tmutex_destroy(&vq->vq_lock);\n}\n\nstatic void\nvdev_queue_io_add(vdev_queue_t *vq, zio_t *zio)\n{\n\tzio->io_queue_state = ZIO_QS_QUEUED;\n\tvdev_queue_class_add(vq, zio);\n\tif (zio->io_type == ZIO_TYPE_READ)\n\t\tavl_add(&vq->vq_read_offset_tree, zio);\n\telse if (zio->io_type == ZIO_TYPE_WRITE)\n\t\tavl_add(&vq->vq_write_offset_tree, zio);\n}\n\nstatic void\nvdev_queue_io_remove(vdev_queue_t *vq, zio_t *zio)\n{\n\tvdev_queue_class_remove(vq, zio);\n\tif (zio->io_type == ZIO_TYPE_READ)\n\t\tavl_remove(&vq->vq_read_offset_tree, zio);\n\telse if (zio->io_type == ZIO_TYPE_WRITE)\n\t\tavl_remove(&vq->vq_write_offset_tree, zio);\n\tzio->io_queue_state = ZIO_QS_NONE;\n}\n\nstatic boolean_t\nvdev_queue_is_interactive(zio_priority_t p)\n{\n\tswitch (p) {\n\tcase ZIO_PRIORITY_SCRUB:\n\tcase ZIO_PRIORITY_REMOVAL:\n\tcase ZIO_PRIORITY_INITIALIZING:\n\tcase ZIO_PRIORITY_REBUILD:\n\t\treturn (B_FALSE);\n\tdefault:\n\t\treturn (B_TRUE);\n\t}\n}\n\nstatic void\nvdev_queue_pending_add(vdev_queue_t *vq, zio_t *zio)\n{\n\tASSERT(MUTEX_HELD(&vq->vq_lock));\n\tASSERT3U(zio->io_priority, <, ZIO_PRIORITY_NUM_QUEUEABLE);\n\tvq->vq_cactive[zio->io_priority]++;\n\tvq->vq_active++;\n\tif (vdev_queue_is_interactive(zio->io_priority)) {\n\t\tif (++vq->vq_ia_active == 1)\n\t\t\tvq->vq_nia_credit = 1;\n\t} else if (vq->vq_ia_active > 0) {\n\t\tvq->vq_nia_credit--;\n\t}\n\tzio->io_queue_state = ZIO_QS_ACTIVE;\n\tlist_insert_tail(&vq->vq_active_list, zio);\n}\n\nstatic void\nvdev_queue_pending_remove(vdev_queue_t *vq, zio_t *zio)\n{\n\tASSERT(MUTEX_HELD(&vq->vq_lock));\n\tASSERT3U(zio->io_priority, <, ZIO_PRIORITY_NUM_QUEUEABLE);\n\tvq->vq_cactive[zio->io_priority]--;\n\tvq->vq_active--;\n\tif (vdev_queue_is_interactive(zio->io_priority)) {\n\t\tif (--vq->vq_ia_active == 0)\n\t\t\tvq->vq_nia_credit = 0;\n\t\telse\n\t\t\tvq->vq_nia_credit = zfs_vdev_nia_credit;\n\t} else if (vq->vq_ia_active == 0)\n\t\tvq->vq_nia_credit++;\n\tlist_remove(&vq->vq_active_list, zio);\n\tzio->io_queue_state = ZIO_QS_NONE;\n}\n\nstatic void\nvdev_queue_agg_io_done(zio_t *aio)\n{\n\tabd_free(aio->io_abd);\n}\n\n \n#define\tIO_SPAN(fio, lio) ((lio)->io_offset + (lio)->io_size - (fio)->io_offset)\n#define\tIO_GAP(fio, lio) (-IO_SPAN(lio, fio))\n\n \nstatic zio_t *\nvdev_queue_aggregate(vdev_queue_t *vq, zio_t *zio)\n{\n\tzio_t *first, *last, *aio, *dio, *mandatory, *nio;\n\tuint64_t maxgap = 0;\n\tuint64_t size;\n\tuint64_t limit;\n\tboolean_t stretch = B_FALSE;\n\tuint64_t next_offset;\n\tabd_t *abd;\n\tavl_tree_t *t;\n\n\t \n\tif (zio->io_type == ZIO_TYPE_TRIM)\n\t\treturn (NULL);\n\n\tif (zio->io_flags & ZIO_FLAG_DONT_AGGREGATE)\n\t\treturn (NULL);\n\n\tif (vq->vq_vdev->vdev_nonrot)\n\t\tlimit = zfs_vdev_aggregation_limit_non_rotating;\n\telse\n\t\tlimit = zfs_vdev_aggregation_limit;\n\tif (limit == 0)\n\t\treturn (NULL);\n\tlimit = MIN(limit, SPA_MAXBLOCKSIZE);\n\n\t \n\tASSERT(vq->vq_vdev->vdev_ops != &vdev_draid_spare_ops);\n\n\tfirst = last = zio;\n\n\tif (zio->io_type == ZIO_TYPE_READ) {\n\t\tmaxgap = zfs_vdev_read_gap_limit;\n\t\tt = &vq->vq_read_offset_tree;\n\t} else {\n\t\tASSERT3U(zio->io_type, ==, ZIO_TYPE_WRITE);\n\t\tt = &vq->vq_write_offset_tree;\n\t}\n\n\t \n\n\t \n\tmandatory = (first->io_flags & ZIO_FLAG_OPTIONAL) ? NULL : first;\n\n\t \n\tzio_flag_t flags = zio->io_flags & ZIO_FLAG_AGG_INHERIT;\n\twhile ((dio = AVL_PREV(t, first)) != NULL &&\n\t    (dio->io_flags & ZIO_FLAG_AGG_INHERIT) == flags &&\n\t    IO_SPAN(dio, last) <= limit &&\n\t    IO_GAP(dio, first) <= maxgap &&\n\t    dio->io_type == zio->io_type) {\n\t\tfirst = dio;\n\t\tif (mandatory == NULL && !(first->io_flags & ZIO_FLAG_OPTIONAL))\n\t\t\tmandatory = first;\n\t}\n\n\t \n\twhile ((first->io_flags & ZIO_FLAG_OPTIONAL) && first != last) {\n\t\tfirst = AVL_NEXT(t, first);\n\t\tASSERT(first != NULL);\n\t}\n\n\n\t \n\twhile ((dio = AVL_NEXT(t, last)) != NULL &&\n\t    (dio->io_flags & ZIO_FLAG_AGG_INHERIT) == flags &&\n\t    (IO_SPAN(first, dio) <= limit ||\n\t    (dio->io_flags & ZIO_FLAG_OPTIONAL)) &&\n\t    IO_SPAN(first, dio) <= SPA_MAXBLOCKSIZE &&\n\t    IO_GAP(last, dio) <= maxgap &&\n\t    dio->io_type == zio->io_type) {\n\t\tlast = dio;\n\t\tif (!(last->io_flags & ZIO_FLAG_OPTIONAL))\n\t\t\tmandatory = last;\n\t}\n\n\t \n\tif (zio->io_type == ZIO_TYPE_WRITE && mandatory != NULL) {\n\t\tzio_t *nio = last;\n\t\twhile ((dio = AVL_NEXT(t, nio)) != NULL &&\n\t\t    IO_GAP(nio, dio) == 0 &&\n\t\t    IO_GAP(mandatory, dio) <= zfs_vdev_write_gap_limit) {\n\t\t\tnio = dio;\n\t\t\tif (!(nio->io_flags & ZIO_FLAG_OPTIONAL)) {\n\t\t\t\tstretch = B_TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (stretch) {\n\t\t \n\t\tdio = AVL_NEXT(t, last);\n\t\tASSERT3P(dio, !=, NULL);\n\t\tdio->io_flags &= ~ZIO_FLAG_OPTIONAL;\n\t} else {\n\t\t \n\t\twhile (last != mandatory && last != first) {\n\t\t\tASSERT(last->io_flags & ZIO_FLAG_OPTIONAL);\n\t\t\tlast = AVL_PREV(t, last);\n\t\t\tASSERT(last != NULL);\n\t\t}\n\t}\n\n\tif (first == last)\n\t\treturn (NULL);\n\n\tsize = IO_SPAN(first, last);\n\tASSERT3U(size, <=, SPA_MAXBLOCKSIZE);\n\n\tabd = abd_alloc_gang();\n\tif (abd == NULL)\n\t\treturn (NULL);\n\n\taio = zio_vdev_delegated_io(first->io_vd, first->io_offset,\n\t    abd, size, first->io_type, zio->io_priority,\n\t    flags | ZIO_FLAG_DONT_QUEUE, vdev_queue_agg_io_done, NULL);\n\taio->io_timestamp = first->io_timestamp;\n\n\tnio = first;\n\tnext_offset = first->io_offset;\n\tdo {\n\t\tdio = nio;\n\t\tnio = AVL_NEXT(t, dio);\n\t\tASSERT3P(dio, !=, NULL);\n\t\tzio_add_child(dio, aio);\n\t\tvdev_queue_io_remove(vq, dio);\n\n\t\tif (dio->io_offset != next_offset) {\n\t\t\t \n\t\t\tASSERT3U(dio->io_type, ==, ZIO_TYPE_READ);\n\t\t\tASSERT3U(dio->io_offset, >, next_offset);\n\t\t\tabd = abd_alloc_for_io(\n\t\t\t    dio->io_offset - next_offset, B_TRUE);\n\t\t\tabd_gang_add(aio->io_abd, abd, B_TRUE);\n\t\t}\n\t\tif (dio->io_abd &&\n\t\t    (dio->io_size != abd_get_size(dio->io_abd))) {\n\t\t\t \n\t\t\tASSERT3U(abd_get_size(dio->io_abd), >, dio->io_size);\n\t\t\tabd = abd_get_offset_size(dio->io_abd, 0, dio->io_size);\n\t\t\tabd_gang_add(aio->io_abd, abd, B_TRUE);\n\t\t} else {\n\t\t\tif (dio->io_flags & ZIO_FLAG_NODATA) {\n\t\t\t\t \n\t\t\t\tASSERT3U(dio->io_type, ==, ZIO_TYPE_WRITE);\n\t\t\t\tASSERT3P(dio->io_abd, ==, NULL);\n\t\t\t\tabd_gang_add(aio->io_abd,\n\t\t\t\t    abd_get_zeros(dio->io_size), B_TRUE);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tabd_gang_add(aio->io_abd, dio->io_abd,\n\t\t\t\t    B_FALSE);\n\t\t\t}\n\t\t}\n\t\tnext_offset = dio->io_offset + dio->io_size;\n\t} while (dio != last);\n\tASSERT3U(abd_get_size(aio->io_abd), ==, aio->io_size);\n\n\t \n\treturn (aio);\n}\n\nstatic zio_t *\nvdev_queue_io_to_issue(vdev_queue_t *vq)\n{\n\tzio_t *zio, *aio;\n\tzio_priority_t p;\n\tavl_index_t idx;\n\tavl_tree_t *tree;\n\nagain:\n\tASSERT(MUTEX_HELD(&vq->vq_lock));\n\n\tp = vdev_queue_class_to_issue(vq);\n\n\tif (p == ZIO_PRIORITY_NUM_QUEUEABLE) {\n\t\t \n\t\treturn (NULL);\n\t}\n\n\tif (vdev_queue_class_fifo(p)) {\n\t\tzio = list_head(&vq->vq_class[p].vqc_list);\n\t} else {\n\t\t \n\t\ttree = &vq->vq_class[p].vqc_tree;\n\t\tzio = aio = avl_first(tree);\n\t\tif (zio->io_offset < vq->vq_last_offset) {\n\t\t\tvq->vq_io_search.io_timestamp = zio->io_timestamp;\n\t\t\tvq->vq_io_search.io_offset = vq->vq_last_offset;\n\t\t\tzio = avl_find(tree, &vq->vq_io_search, &idx);\n\t\t\tif (zio == NULL) {\n\t\t\t\tzio = avl_nearest(tree, idx, AVL_AFTER);\n\t\t\t\tif (zio == NULL ||\n\t\t\t\t    (zio->io_timestamp >> VDQ_T_SHIFT) !=\n\t\t\t\t    (aio->io_timestamp >> VDQ_T_SHIFT))\n\t\t\t\t\tzio = aio;\n\t\t\t}\n\t\t}\n\t}\n\tASSERT3U(zio->io_priority, ==, p);\n\n\taio = vdev_queue_aggregate(vq, zio);\n\tif (aio != NULL) {\n\t\tzio = aio;\n\t} else {\n\t\tvdev_queue_io_remove(vq, zio);\n\n\t\t \n\t\tif (zio->io_flags & ZIO_FLAG_NODATA) {\n\t\t\tmutex_exit(&vq->vq_lock);\n\t\t\tzio_vdev_io_bypass(zio);\n\t\t\tzio_execute(zio);\n\t\t\tmutex_enter(&vq->vq_lock);\n\t\t\tgoto again;\n\t\t}\n\t}\n\n\tvdev_queue_pending_add(vq, zio);\n\tvq->vq_last_offset = zio->io_offset + zio->io_size;\n\n\treturn (zio);\n}\n\nzio_t *\nvdev_queue_io(zio_t *zio)\n{\n\tvdev_queue_t *vq = &zio->io_vd->vdev_queue;\n\tzio_t *dio, *nio;\n\tzio_link_t *zl = NULL;\n\n\tif (zio->io_flags & ZIO_FLAG_DONT_QUEUE)\n\t\treturn (zio);\n\n\t \n\tif (zio->io_type == ZIO_TYPE_READ) {\n\t\tASSERT(zio->io_priority != ZIO_PRIORITY_TRIM);\n\n\t\tif (zio->io_priority != ZIO_PRIORITY_SYNC_READ &&\n\t\t    zio->io_priority != ZIO_PRIORITY_ASYNC_READ &&\n\t\t    zio->io_priority != ZIO_PRIORITY_SCRUB &&\n\t\t    zio->io_priority != ZIO_PRIORITY_REMOVAL &&\n\t\t    zio->io_priority != ZIO_PRIORITY_INITIALIZING &&\n\t\t    zio->io_priority != ZIO_PRIORITY_REBUILD) {\n\t\t\tzio->io_priority = ZIO_PRIORITY_ASYNC_READ;\n\t\t}\n\t} else if (zio->io_type == ZIO_TYPE_WRITE) {\n\t\tASSERT(zio->io_priority != ZIO_PRIORITY_TRIM);\n\n\t\tif (zio->io_priority != ZIO_PRIORITY_SYNC_WRITE &&\n\t\t    zio->io_priority != ZIO_PRIORITY_ASYNC_WRITE &&\n\t\t    zio->io_priority != ZIO_PRIORITY_REMOVAL &&\n\t\t    zio->io_priority != ZIO_PRIORITY_INITIALIZING &&\n\t\t    zio->io_priority != ZIO_PRIORITY_REBUILD) {\n\t\t\tzio->io_priority = ZIO_PRIORITY_ASYNC_WRITE;\n\t\t}\n\t} else {\n\t\tASSERT(zio->io_type == ZIO_TYPE_TRIM);\n\t\tASSERT(zio->io_priority == ZIO_PRIORITY_TRIM);\n\t}\n\n\tzio->io_flags |= ZIO_FLAG_DONT_QUEUE;\n\tzio->io_timestamp = gethrtime();\n\n\tmutex_enter(&vq->vq_lock);\n\tvdev_queue_io_add(vq, zio);\n\tnio = vdev_queue_io_to_issue(vq);\n\tmutex_exit(&vq->vq_lock);\n\n\tif (nio == NULL)\n\t\treturn (NULL);\n\n\tif (nio->io_done == vdev_queue_agg_io_done) {\n\t\twhile ((dio = zio_walk_parents(nio, &zl)) != NULL) {\n\t\t\tASSERT3U(dio->io_type, ==, nio->io_type);\n\t\t\tzio_vdev_io_bypass(dio);\n\t\t\tzio_execute(dio);\n\t\t}\n\t\tzio_nowait(nio);\n\t\treturn (NULL);\n\t}\n\n\treturn (nio);\n}\n\nvoid\nvdev_queue_io_done(zio_t *zio)\n{\n\tvdev_queue_t *vq = &zio->io_vd->vdev_queue;\n\tzio_t *dio, *nio;\n\tzio_link_t *zl = NULL;\n\n\thrtime_t now = gethrtime();\n\tvq->vq_io_complete_ts = now;\n\tvq->vq_io_delta_ts = zio->io_delta = now - zio->io_timestamp;\n\n\tmutex_enter(&vq->vq_lock);\n\tvdev_queue_pending_remove(vq, zio);\n\n\twhile ((nio = vdev_queue_io_to_issue(vq)) != NULL) {\n\t\tmutex_exit(&vq->vq_lock);\n\t\tif (nio->io_done == vdev_queue_agg_io_done) {\n\t\t\twhile ((dio = zio_walk_parents(nio, &zl)) != NULL) {\n\t\t\t\tASSERT3U(dio->io_type, ==, nio->io_type);\n\t\t\t\tzio_vdev_io_bypass(dio);\n\t\t\t\tzio_execute(dio);\n\t\t\t}\n\t\t\tzio_nowait(nio);\n\t\t} else {\n\t\t\tzio_vdev_io_reissue(nio);\n\t\t\tzio_execute(nio);\n\t\t}\n\t\tmutex_enter(&vq->vq_lock);\n\t}\n\n\tmutex_exit(&vq->vq_lock);\n}\n\nvoid\nvdev_queue_change_io_priority(zio_t *zio, zio_priority_t priority)\n{\n\tvdev_queue_t *vq = &zio->io_vd->vdev_queue;\n\n\t \n\tif (zio->io_priority == ZIO_PRIORITY_NOW)\n\t\treturn;\n\n\tASSERT3U(zio->io_priority, <, ZIO_PRIORITY_NUM_QUEUEABLE);\n\tASSERT3U(priority, <, ZIO_PRIORITY_NUM_QUEUEABLE);\n\n\tif (zio->io_type == ZIO_TYPE_READ) {\n\t\tif (priority != ZIO_PRIORITY_SYNC_READ &&\n\t\t    priority != ZIO_PRIORITY_ASYNC_READ &&\n\t\t    priority != ZIO_PRIORITY_SCRUB)\n\t\t\tpriority = ZIO_PRIORITY_ASYNC_READ;\n\t} else {\n\t\tASSERT(zio->io_type == ZIO_TYPE_WRITE);\n\t\tif (priority != ZIO_PRIORITY_SYNC_WRITE &&\n\t\t    priority != ZIO_PRIORITY_ASYNC_WRITE)\n\t\t\tpriority = ZIO_PRIORITY_ASYNC_WRITE;\n\t}\n\n\tmutex_enter(&vq->vq_lock);\n\n\t \n\tif (zio->io_queue_state == ZIO_QS_QUEUED) {\n\t\tvdev_queue_class_remove(vq, zio);\n\t\tzio->io_priority = priority;\n\t\tvdev_queue_class_add(vq, zio);\n\t} else if (zio->io_queue_state == ZIO_QS_NONE) {\n\t\tzio->io_priority = priority;\n\t}\n\n\tmutex_exit(&vq->vq_lock);\n}\n\n \nuint32_t\nvdev_queue_length(vdev_t *vd)\n{\n\treturn (vd->vdev_queue.vq_active);\n}\n\nuint64_t\nvdev_queue_last_offset(vdev_t *vd)\n{\n\treturn (vd->vdev_queue.vq_last_offset);\n}\n\nuint64_t\nvdev_queue_class_length(vdev_t *vd, zio_priority_t p)\n{\n\tvdev_queue_t *vq = &vd->vdev_queue;\n\tif (vdev_queue_class_fifo(p))\n\t\treturn (vq->vq_class[p].vqc_list_numnodes);\n\telse\n\t\treturn (avl_numnodes(&vq->vq_class[p].vqc_tree));\n}\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, aggregation_limit, UINT, ZMOD_RW,\n\t\"Max vdev I/O aggregation size\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, aggregation_limit_non_rotating, UINT,\n\tZMOD_RW, \"Max vdev I/O aggregation size for non-rotating media\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, read_gap_limit, UINT, ZMOD_RW,\n\t\"Aggregate read I/O over gap\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, write_gap_limit, UINT, ZMOD_RW,\n\t\"Aggregate write I/O over gap\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, max_active, UINT, ZMOD_RW,\n\t\"Maximum number of active I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, async_write_active_max_dirty_percent,\n\tUINT, ZMOD_RW, \"Async write concurrency max threshold\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, async_write_active_min_dirty_percent,\n\tUINT, ZMOD_RW, \"Async write concurrency min threshold\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, async_read_max_active, UINT, ZMOD_RW,\n\t\"Max active async read I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, async_read_min_active, UINT, ZMOD_RW,\n\t\"Min active async read I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, async_write_max_active, UINT, ZMOD_RW,\n\t\"Max active async write I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, async_write_min_active, UINT, ZMOD_RW,\n\t\"Min active async write I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, initializing_max_active, UINT, ZMOD_RW,\n\t\"Max active initializing I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, initializing_min_active, UINT, ZMOD_RW,\n\t\"Min active initializing I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, removal_max_active, UINT, ZMOD_RW,\n\t\"Max active removal I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, removal_min_active, UINT, ZMOD_RW,\n\t\"Min active removal I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, scrub_max_active, UINT, ZMOD_RW,\n\t\"Max active scrub I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, scrub_min_active, UINT, ZMOD_RW,\n\t\"Min active scrub I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, sync_read_max_active, UINT, ZMOD_RW,\n\t\"Max active sync read I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, sync_read_min_active, UINT, ZMOD_RW,\n\t\"Min active sync read I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, sync_write_max_active, UINT, ZMOD_RW,\n\t\"Max active sync write I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, sync_write_min_active, UINT, ZMOD_RW,\n\t\"Min active sync write I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, trim_max_active, UINT, ZMOD_RW,\n\t\"Max active trim/discard I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, trim_min_active, UINT, ZMOD_RW,\n\t\"Min active trim/discard I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, rebuild_max_active, UINT, ZMOD_RW,\n\t\"Max active rebuild I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, rebuild_min_active, UINT, ZMOD_RW,\n\t\"Min active rebuild I/Os per vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, nia_credit, UINT, ZMOD_RW,\n\t\"Number of non-interactive I/Os to allow in sequence\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, nia_delay, UINT, ZMOD_RW,\n\t\"Number of non-interactive I/Os before _max_active\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, queue_depth_pct, UINT, ZMOD_RW,\n\t\"Queue depth percentage for each top-level vdev\");\n\nZFS_MODULE_PARAM(zfs_vdev, zfs_vdev_, def_queue_depth, UINT, ZMOD_RW,\n\t\"Default queue depth for each allocator\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}