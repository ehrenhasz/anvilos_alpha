{
  "module_name": "vdev_trim.c",
  "hash_id": "c505b5837e2118dbd198b92758c34f1cb201c4aafda553f4bf2f2e2cce2a5822",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/vdev_trim.c",
  "human_readable_source": " \n\n \n\n#include <sys/spa.h>\n#include <sys/spa_impl.h>\n#include <sys/txg.h>\n#include <sys/vdev_impl.h>\n#include <sys/vdev_trim.h>\n#include <sys/metaslab_impl.h>\n#include <sys/dsl_synctask.h>\n#include <sys/zap.h>\n#include <sys/dmu_tx.h>\n#include <sys/arc_impl.h>\n\n \n\n \nstatic unsigned int zfs_trim_extent_bytes_max = 128 * 1024 * 1024;\n\n \nstatic unsigned int zfs_trim_extent_bytes_min = 32 * 1024;\n\n \nunsigned int zfs_trim_metaslab_skip = 0;\n\n \nstatic unsigned int zfs_trim_queue_limit = 10;\n\n \nstatic unsigned int zfs_trim_txg_batch = 32;\n\n \ntypedef struct trim_args {\n\t \n\tvdev_t\t\t*trim_vdev;\t\t \n\tmetaslab_t\t*trim_msp;\t\t \n\trange_tree_t\t*trim_tree;\t\t \n\ttrim_type_t\ttrim_type;\t\t \n\tuint64_t\ttrim_extent_bytes_max;\t \n\tuint64_t\ttrim_extent_bytes_min;\t \n\tenum trim_flag\ttrim_flags;\t\t \n\n\t \n\thrtime_t\ttrim_start_time;\t \n\tuint64_t\ttrim_bytes_done;\t \n} trim_args_t;\n\n \nstatic boolean_t\nvdev_trim_should_stop(vdev_t *vd)\n{\n\treturn (vd->vdev_trim_exit_wanted || !vdev_writeable(vd) ||\n\t    vd->vdev_detached || vd->vdev_top->vdev_removing);\n}\n\n \nstatic boolean_t\nvdev_autotrim_should_stop(vdev_t *tvd)\n{\n\treturn (tvd->vdev_autotrim_exit_wanted ||\n\t    !vdev_writeable(tvd) || tvd->vdev_removing ||\n\t    spa_get_autotrim(tvd->vdev_spa) == SPA_AUTOTRIM_OFF);\n}\n\n \nstatic boolean_t\nvdev_autotrim_wait_kick(vdev_t *vd, int num_of_kick)\n{\n\tmutex_enter(&vd->vdev_autotrim_lock);\n\tfor (int i = 0; i < num_of_kick; i++) {\n\t\tif (vd->vdev_autotrim_exit_wanted)\n\t\t\tbreak;\n\t\tcv_wait(&vd->vdev_autotrim_kick_cv, &vd->vdev_autotrim_lock);\n\t}\n\tboolean_t exit_wanted = vd->vdev_autotrim_exit_wanted;\n\tmutex_exit(&vd->vdev_autotrim_lock);\n\n\treturn (exit_wanted);\n}\n\n \nstatic void\nvdev_trim_zap_update_sync(void *arg, dmu_tx_t *tx)\n{\n\t \n\tuint64_t guid = *(uint64_t *)arg;\n\tuint64_t txg = dmu_tx_get_txg(tx);\n\tkmem_free(arg, sizeof (uint64_t));\n\n\tvdev_t *vd = spa_lookup_by_guid(tx->tx_pool->dp_spa, guid, B_FALSE);\n\tif (vd == NULL || vd->vdev_top->vdev_removing || !vdev_is_concrete(vd))\n\t\treturn;\n\n\tuint64_t last_offset = vd->vdev_trim_offset[txg & TXG_MASK];\n\tvd->vdev_trim_offset[txg & TXG_MASK] = 0;\n\n\tVERIFY3U(vd->vdev_leaf_zap, !=, 0);\n\n\tobjset_t *mos = vd->vdev_spa->spa_meta_objset;\n\n\tif (last_offset > 0 || vd->vdev_trim_last_offset == UINT64_MAX) {\n\n\t\tif (vd->vdev_trim_last_offset == UINT64_MAX)\n\t\t\tlast_offset = 0;\n\n\t\tvd->vdev_trim_last_offset = last_offset;\n\t\tVERIFY0(zap_update(mos, vd->vdev_leaf_zap,\n\t\t    VDEV_LEAF_ZAP_TRIM_LAST_OFFSET,\n\t\t    sizeof (last_offset), 1, &last_offset, tx));\n\t}\n\n\tif (vd->vdev_trim_action_time > 0) {\n\t\tuint64_t val = (uint64_t)vd->vdev_trim_action_time;\n\t\tVERIFY0(zap_update(mos, vd->vdev_leaf_zap,\n\t\t    VDEV_LEAF_ZAP_TRIM_ACTION_TIME, sizeof (val),\n\t\t    1, &val, tx));\n\t}\n\n\tif (vd->vdev_trim_rate > 0) {\n\t\tuint64_t rate = (uint64_t)vd->vdev_trim_rate;\n\n\t\tif (rate == UINT64_MAX)\n\t\t\trate = 0;\n\n\t\tVERIFY0(zap_update(mos, vd->vdev_leaf_zap,\n\t\t    VDEV_LEAF_ZAP_TRIM_RATE, sizeof (rate), 1, &rate, tx));\n\t}\n\n\tuint64_t partial = vd->vdev_trim_partial;\n\tif (partial == UINT64_MAX)\n\t\tpartial = 0;\n\n\tVERIFY0(zap_update(mos, vd->vdev_leaf_zap, VDEV_LEAF_ZAP_TRIM_PARTIAL,\n\t    sizeof (partial), 1, &partial, tx));\n\n\tuint64_t secure = vd->vdev_trim_secure;\n\tif (secure == UINT64_MAX)\n\t\tsecure = 0;\n\n\tVERIFY0(zap_update(mos, vd->vdev_leaf_zap, VDEV_LEAF_ZAP_TRIM_SECURE,\n\t    sizeof (secure), 1, &secure, tx));\n\n\n\tuint64_t trim_state = vd->vdev_trim_state;\n\tVERIFY0(zap_update(mos, vd->vdev_leaf_zap, VDEV_LEAF_ZAP_TRIM_STATE,\n\t    sizeof (trim_state), 1, &trim_state, tx));\n}\n\n \nstatic void\nvdev_trim_change_state(vdev_t *vd, vdev_trim_state_t new_state,\n    uint64_t rate, boolean_t partial, boolean_t secure)\n{\n\tASSERT(MUTEX_HELD(&vd->vdev_trim_lock));\n\tspa_t *spa = vd->vdev_spa;\n\n\tif (new_state == vd->vdev_trim_state)\n\t\treturn;\n\n\t \n\tuint64_t *guid = kmem_zalloc(sizeof (uint64_t), KM_SLEEP);\n\t*guid = vd->vdev_guid;\n\n\t \n\tif (vd->vdev_trim_state != VDEV_TRIM_SUSPENDED) {\n\t\tvd->vdev_trim_action_time = gethrestime_sec();\n\t}\n\n\t \n\tif (new_state == VDEV_TRIM_ACTIVE) {\n\t\tif (vd->vdev_trim_state == VDEV_TRIM_COMPLETE ||\n\t\t    vd->vdev_trim_state == VDEV_TRIM_CANCELED) {\n\t\t\tvd->vdev_trim_last_offset = UINT64_MAX;\n\t\t\tvd->vdev_trim_rate = UINT64_MAX;\n\t\t\tvd->vdev_trim_partial = UINT64_MAX;\n\t\t\tvd->vdev_trim_secure = UINT64_MAX;\n\t\t}\n\n\t\tif (rate != 0)\n\t\t\tvd->vdev_trim_rate = rate;\n\n\t\tif (partial != 0)\n\t\t\tvd->vdev_trim_partial = partial;\n\n\t\tif (secure != 0)\n\t\t\tvd->vdev_trim_secure = secure;\n\t}\n\n\tvdev_trim_state_t old_state = vd->vdev_trim_state;\n\tboolean_t resumed = (old_state == VDEV_TRIM_SUSPENDED);\n\tvd->vdev_trim_state = new_state;\n\n\tdmu_tx_t *tx = dmu_tx_create_dd(spa_get_dsl(spa)->dp_mos_dir);\n\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT));\n\tdsl_sync_task_nowait(spa_get_dsl(spa), vdev_trim_zap_update_sync,\n\t    guid, tx);\n\n\tswitch (new_state) {\n\tcase VDEV_TRIM_ACTIVE:\n\t\tspa_event_notify(spa, vd, NULL,\n\t\t    resumed ? ESC_ZFS_TRIM_RESUME : ESC_ZFS_TRIM_START);\n\t\tspa_history_log_internal(spa, \"trim\", tx,\n\t\t    \"vdev=%s activated\", vd->vdev_path);\n\t\tbreak;\n\tcase VDEV_TRIM_SUSPENDED:\n\t\tspa_event_notify(spa, vd, NULL, ESC_ZFS_TRIM_SUSPEND);\n\t\tspa_history_log_internal(spa, \"trim\", tx,\n\t\t    \"vdev=%s suspended\", vd->vdev_path);\n\t\tbreak;\n\tcase VDEV_TRIM_CANCELED:\n\t\tif (old_state == VDEV_TRIM_ACTIVE ||\n\t\t    old_state == VDEV_TRIM_SUSPENDED) {\n\t\t\tspa_event_notify(spa, vd, NULL, ESC_ZFS_TRIM_CANCEL);\n\t\t\tspa_history_log_internal(spa, \"trim\", tx,\n\t\t\t    \"vdev=%s canceled\", vd->vdev_path);\n\t\t}\n\t\tbreak;\n\tcase VDEV_TRIM_COMPLETE:\n\t\tspa_event_notify(spa, vd, NULL, ESC_ZFS_TRIM_FINISH);\n\t\tspa_history_log_internal(spa, \"trim\", tx,\n\t\t    \"vdev=%s complete\", vd->vdev_path);\n\t\tbreak;\n\tdefault:\n\t\tpanic(\"invalid state %llu\", (unsigned long long)new_state);\n\t}\n\n\tdmu_tx_commit(tx);\n\n\tif (new_state != VDEV_TRIM_ACTIVE)\n\t\tspa_notify_waiters(spa);\n}\n\n \nstatic void\nvdev_trim_cb(zio_t *zio)\n{\n\tvdev_t *vd = zio->io_vd;\n\n\tmutex_enter(&vd->vdev_trim_io_lock);\n\tif (zio->io_error == ENXIO && !vdev_writeable(vd)) {\n\t\t \n\t\tuint64_t *offset =\n\t\t    &vd->vdev_trim_offset[zio->io_txg & TXG_MASK];\n\t\t*offset = MIN(*offset, zio->io_offset);\n\t} else {\n\t\tif (zio->io_error != 0) {\n\t\t\tvd->vdev_stat.vs_trim_errors++;\n\t\t\tspa_iostats_trim_add(vd->vdev_spa, TRIM_TYPE_MANUAL,\n\t\t\t    0, 0, 0, 0, 1, zio->io_orig_size);\n\t\t} else {\n\t\t\tspa_iostats_trim_add(vd->vdev_spa, TRIM_TYPE_MANUAL,\n\t\t\t    1, zio->io_orig_size, 0, 0, 0, 0);\n\t\t}\n\n\t\tvd->vdev_trim_bytes_done += zio->io_orig_size;\n\t}\n\n\tASSERT3U(vd->vdev_trim_inflight[TRIM_TYPE_MANUAL], >, 0);\n\tvd->vdev_trim_inflight[TRIM_TYPE_MANUAL]--;\n\tcv_broadcast(&vd->vdev_trim_io_cv);\n\tmutex_exit(&vd->vdev_trim_io_lock);\n\n\tspa_config_exit(vd->vdev_spa, SCL_STATE_ALL, vd);\n}\n\n \nstatic void\nvdev_autotrim_cb(zio_t *zio)\n{\n\tvdev_t *vd = zio->io_vd;\n\n\tmutex_enter(&vd->vdev_trim_io_lock);\n\n\tif (zio->io_error != 0) {\n\t\tvd->vdev_stat.vs_trim_errors++;\n\t\tspa_iostats_trim_add(vd->vdev_spa, TRIM_TYPE_AUTO,\n\t\t    0, 0, 0, 0, 1, zio->io_orig_size);\n\t} else {\n\t\tspa_iostats_trim_add(vd->vdev_spa, TRIM_TYPE_AUTO,\n\t\t    1, zio->io_orig_size, 0, 0, 0, 0);\n\t}\n\n\tASSERT3U(vd->vdev_trim_inflight[TRIM_TYPE_AUTO], >, 0);\n\tvd->vdev_trim_inflight[TRIM_TYPE_AUTO]--;\n\tcv_broadcast(&vd->vdev_trim_io_cv);\n\tmutex_exit(&vd->vdev_trim_io_lock);\n\n\tspa_config_exit(vd->vdev_spa, SCL_STATE_ALL, vd);\n}\n\n \nstatic void\nvdev_trim_simple_cb(zio_t *zio)\n{\n\tvdev_t *vd = zio->io_vd;\n\n\tmutex_enter(&vd->vdev_trim_io_lock);\n\n\tif (zio->io_error != 0) {\n\t\tvd->vdev_stat.vs_trim_errors++;\n\t\tspa_iostats_trim_add(vd->vdev_spa, TRIM_TYPE_SIMPLE,\n\t\t    0, 0, 0, 0, 1, zio->io_orig_size);\n\t} else {\n\t\tspa_iostats_trim_add(vd->vdev_spa, TRIM_TYPE_SIMPLE,\n\t\t    1, zio->io_orig_size, 0, 0, 0, 0);\n\t}\n\n\tASSERT3U(vd->vdev_trim_inflight[TRIM_TYPE_SIMPLE], >, 0);\n\tvd->vdev_trim_inflight[TRIM_TYPE_SIMPLE]--;\n\tcv_broadcast(&vd->vdev_trim_io_cv);\n\tmutex_exit(&vd->vdev_trim_io_lock);\n\n\tspa_config_exit(vd->vdev_spa, SCL_STATE_ALL, vd);\n}\n \nstatic uint64_t\nvdev_trim_calculate_rate(trim_args_t *ta)\n{\n\treturn (ta->trim_bytes_done * 1000 /\n\t    (NSEC2MSEC(gethrtime() - ta->trim_start_time) + 1));\n}\n\n \nstatic int\nvdev_trim_range(trim_args_t *ta, uint64_t start, uint64_t size)\n{\n\tvdev_t *vd = ta->trim_vdev;\n\tspa_t *spa = vd->vdev_spa;\n\tvoid *cb;\n\n\tmutex_enter(&vd->vdev_trim_io_lock);\n\n\t \n\tif (ta->trim_type == TRIM_TYPE_MANUAL) {\n\t\twhile (vd->vdev_trim_rate != 0 && !vdev_trim_should_stop(vd) &&\n\t\t    vdev_trim_calculate_rate(ta) > vd->vdev_trim_rate) {\n\t\t\tcv_timedwait_idle(&vd->vdev_trim_io_cv,\n\t\t\t    &vd->vdev_trim_io_lock, ddi_get_lbolt() +\n\t\t\t    MSEC_TO_TICK(10));\n\t\t}\n\t}\n\tta->trim_bytes_done += size;\n\n\t \n\twhile (vd->vdev_trim_inflight[0] + vd->vdev_trim_inflight[1] +\n\t    vd->vdev_trim_inflight[2] >= zfs_trim_queue_limit) {\n\t\tcv_wait(&vd->vdev_trim_io_cv, &vd->vdev_trim_io_lock);\n\t}\n\tvd->vdev_trim_inflight[ta->trim_type]++;\n\tmutex_exit(&vd->vdev_trim_io_lock);\n\n\tdmu_tx_t *tx = dmu_tx_create_dd(spa_get_dsl(spa)->dp_mos_dir);\n\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT));\n\tuint64_t txg = dmu_tx_get_txg(tx);\n\n\tspa_config_enter(spa, SCL_STATE_ALL, vd, RW_READER);\n\tmutex_enter(&vd->vdev_trim_lock);\n\n\tif (ta->trim_type == TRIM_TYPE_MANUAL &&\n\t    vd->vdev_trim_offset[txg & TXG_MASK] == 0) {\n\t\tuint64_t *guid = kmem_zalloc(sizeof (uint64_t), KM_SLEEP);\n\t\t*guid = vd->vdev_guid;\n\n\t\t \n\t\tdsl_sync_task_nowait(spa_get_dsl(spa),\n\t\t    vdev_trim_zap_update_sync, guid, tx);\n\t}\n\n\t \n\tif ((ta->trim_type == TRIM_TYPE_MANUAL &&\n\t    vdev_trim_should_stop(vd)) ||\n\t    (ta->trim_type == TRIM_TYPE_AUTO &&\n\t    vdev_autotrim_should_stop(vd->vdev_top))) {\n\t\tmutex_enter(&vd->vdev_trim_io_lock);\n\t\tvd->vdev_trim_inflight[ta->trim_type]--;\n\t\tmutex_exit(&vd->vdev_trim_io_lock);\n\t\tspa_config_exit(vd->vdev_spa, SCL_STATE_ALL, vd);\n\t\tmutex_exit(&vd->vdev_trim_lock);\n\t\tdmu_tx_commit(tx);\n\t\treturn (SET_ERROR(EINTR));\n\t}\n\tmutex_exit(&vd->vdev_trim_lock);\n\n\tif (ta->trim_type == TRIM_TYPE_MANUAL)\n\t\tvd->vdev_trim_offset[txg & TXG_MASK] = start + size;\n\n\tif (ta->trim_type == TRIM_TYPE_MANUAL) {\n\t\tcb = vdev_trim_cb;\n\t} else if (ta->trim_type == TRIM_TYPE_AUTO) {\n\t\tcb = vdev_autotrim_cb;\n\t} else {\n\t\tcb = vdev_trim_simple_cb;\n\t}\n\n\tzio_nowait(zio_trim(spa->spa_txg_zio[txg & TXG_MASK], vd,\n\t    start, size, cb, NULL, ZIO_PRIORITY_TRIM, ZIO_FLAG_CANFAIL,\n\t    ta->trim_flags));\n\t \n\n\tdmu_tx_commit(tx);\n\n\treturn (0);\n}\n\n \nstatic int\nvdev_trim_ranges(trim_args_t *ta)\n{\n\tvdev_t *vd = ta->trim_vdev;\n\tzfs_btree_t *t = &ta->trim_tree->rt_root;\n\tzfs_btree_index_t idx;\n\tuint64_t extent_bytes_max = ta->trim_extent_bytes_max;\n\tuint64_t extent_bytes_min = ta->trim_extent_bytes_min;\n\tspa_t *spa = vd->vdev_spa;\n\tint error = 0;\n\n\tta->trim_start_time = gethrtime();\n\tta->trim_bytes_done = 0;\n\n\tfor (range_seg_t *rs = zfs_btree_first(t, &idx); rs != NULL;\n\t    rs = zfs_btree_next(t, &idx, &idx)) {\n\t\tuint64_t size = rs_get_end(rs, ta->trim_tree) - rs_get_start(rs,\n\t\t    ta->trim_tree);\n\n\t\tif (extent_bytes_min && size < extent_bytes_min) {\n\t\t\tspa_iostats_trim_add(spa, ta->trim_type,\n\t\t\t    0, 0, 1, size, 0, 0);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tuint64_t writes_required = ((size - 1) / extent_bytes_max) + 1;\n\n\t\tfor (uint64_t w = 0; w < writes_required; w++) {\n\t\t\terror = vdev_trim_range(ta, VDEV_LABEL_START_SIZE +\n\t\t\t    rs_get_start(rs, ta->trim_tree) +\n\t\t\t    (w *extent_bytes_max), MIN(size -\n\t\t\t    (w * extent_bytes_max), extent_bytes_max));\n\t\t\tif (error != 0) {\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\ndone:\n\t \n\tmutex_enter(&vd->vdev_trim_io_lock);\n\twhile (vd->vdev_trim_inflight[0] > 0) {\n\t\tcv_wait(&vd->vdev_trim_io_cv, &vd->vdev_trim_io_lock);\n\t}\n\tmutex_exit(&vd->vdev_trim_io_lock);\n\n\treturn (error);\n}\n\nstatic void\nvdev_trim_xlate_last_rs_end(void *arg, range_seg64_t *physical_rs)\n{\n\tuint64_t *last_rs_end = (uint64_t *)arg;\n\n\tif (physical_rs->rs_end > *last_rs_end)\n\t\t*last_rs_end = physical_rs->rs_end;\n}\n\nstatic void\nvdev_trim_xlate_progress(void *arg, range_seg64_t *physical_rs)\n{\n\tvdev_t *vd = (vdev_t *)arg;\n\n\tuint64_t size = physical_rs->rs_end - physical_rs->rs_start;\n\tvd->vdev_trim_bytes_est += size;\n\n\tif (vd->vdev_trim_last_offset >= physical_rs->rs_end) {\n\t\tvd->vdev_trim_bytes_done += size;\n\t} else if (vd->vdev_trim_last_offset > physical_rs->rs_start &&\n\t    vd->vdev_trim_last_offset <= physical_rs->rs_end) {\n\t\tvd->vdev_trim_bytes_done +=\n\t\t    vd->vdev_trim_last_offset - physical_rs->rs_start;\n\t}\n}\n\n \nstatic void\nvdev_trim_calculate_progress(vdev_t *vd)\n{\n\tASSERT(spa_config_held(vd->vdev_spa, SCL_CONFIG, RW_READER) ||\n\t    spa_config_held(vd->vdev_spa, SCL_CONFIG, RW_WRITER));\n\tASSERT(vd->vdev_leaf_zap != 0);\n\n\tvd->vdev_trim_bytes_est = 0;\n\tvd->vdev_trim_bytes_done = 0;\n\n\tfor (uint64_t i = 0; i < vd->vdev_top->vdev_ms_count; i++) {\n\t\tmetaslab_t *msp = vd->vdev_top->vdev_ms[i];\n\t\tmutex_enter(&msp->ms_lock);\n\n\t\tuint64_t ms_free = (msp->ms_size -\n\t\t    metaslab_allocated_space(msp)) /\n\t\t    vdev_get_ndisks(vd->vdev_top);\n\n\t\t \n\t\trange_seg64_t logical_rs, physical_rs, remain_rs;\n\t\tlogical_rs.rs_start = msp->ms_start;\n\t\tlogical_rs.rs_end = msp->ms_start + msp->ms_size;\n\n\t\t \n\t\tvdev_xlate(vd, &logical_rs, &physical_rs, &remain_rs);\n\t\tif (vd->vdev_trim_last_offset <= physical_rs.rs_start) {\n\t\t\tvd->vdev_trim_bytes_est += ms_free;\n\t\t\tmutex_exit(&msp->ms_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tuint64_t last_rs_end = physical_rs.rs_end;\n\t\tif (!vdev_xlate_is_empty(&remain_rs)) {\n\t\t\tvdev_xlate_walk(vd, &remain_rs,\n\t\t\t    vdev_trim_xlate_last_rs_end, &last_rs_end);\n\t\t}\n\n\t\tif (vd->vdev_trim_last_offset > last_rs_end) {\n\t\t\tvd->vdev_trim_bytes_done += ms_free;\n\t\t\tvd->vdev_trim_bytes_est += ms_free;\n\t\t\tmutex_exit(&msp->ms_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tVERIFY0(metaslab_load(msp));\n\n\t\trange_tree_t *rt = msp->ms_allocatable;\n\t\tzfs_btree_t *bt = &rt->rt_root;\n\t\tzfs_btree_index_t idx;\n\t\tfor (range_seg_t *rs = zfs_btree_first(bt, &idx);\n\t\t    rs != NULL; rs = zfs_btree_next(bt, &idx, &idx)) {\n\t\t\tlogical_rs.rs_start = rs_get_start(rs, rt);\n\t\t\tlogical_rs.rs_end = rs_get_end(rs, rt);\n\n\t\t\tvdev_xlate_walk(vd, &logical_rs,\n\t\t\t    vdev_trim_xlate_progress, vd);\n\t\t}\n\t\tmutex_exit(&msp->ms_lock);\n\t}\n}\n\n \nstatic int\nvdev_trim_load(vdev_t *vd)\n{\n\tint err = 0;\n\tASSERT(spa_config_held(vd->vdev_spa, SCL_CONFIG, RW_READER) ||\n\t    spa_config_held(vd->vdev_spa, SCL_CONFIG, RW_WRITER));\n\tASSERT(vd->vdev_leaf_zap != 0);\n\n\tif (vd->vdev_trim_state == VDEV_TRIM_ACTIVE ||\n\t    vd->vdev_trim_state == VDEV_TRIM_SUSPENDED) {\n\t\terr = zap_lookup(vd->vdev_spa->spa_meta_objset,\n\t\t    vd->vdev_leaf_zap, VDEV_LEAF_ZAP_TRIM_LAST_OFFSET,\n\t\t    sizeof (vd->vdev_trim_last_offset), 1,\n\t\t    &vd->vdev_trim_last_offset);\n\t\tif (err == ENOENT) {\n\t\t\tvd->vdev_trim_last_offset = 0;\n\t\t\terr = 0;\n\t\t}\n\n\t\tif (err == 0) {\n\t\t\terr = zap_lookup(vd->vdev_spa->spa_meta_objset,\n\t\t\t    vd->vdev_leaf_zap, VDEV_LEAF_ZAP_TRIM_RATE,\n\t\t\t    sizeof (vd->vdev_trim_rate), 1,\n\t\t\t    &vd->vdev_trim_rate);\n\t\t\tif (err == ENOENT) {\n\t\t\t\tvd->vdev_trim_rate = 0;\n\t\t\t\terr = 0;\n\t\t\t}\n\t\t}\n\n\t\tif (err == 0) {\n\t\t\terr = zap_lookup(vd->vdev_spa->spa_meta_objset,\n\t\t\t    vd->vdev_leaf_zap, VDEV_LEAF_ZAP_TRIM_PARTIAL,\n\t\t\t    sizeof (vd->vdev_trim_partial), 1,\n\t\t\t    &vd->vdev_trim_partial);\n\t\t\tif (err == ENOENT) {\n\t\t\t\tvd->vdev_trim_partial = 0;\n\t\t\t\terr = 0;\n\t\t\t}\n\t\t}\n\n\t\tif (err == 0) {\n\t\t\terr = zap_lookup(vd->vdev_spa->spa_meta_objset,\n\t\t\t    vd->vdev_leaf_zap, VDEV_LEAF_ZAP_TRIM_SECURE,\n\t\t\t    sizeof (vd->vdev_trim_secure), 1,\n\t\t\t    &vd->vdev_trim_secure);\n\t\t\tif (err == ENOENT) {\n\t\t\t\tvd->vdev_trim_secure = 0;\n\t\t\t\terr = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tvdev_trim_calculate_progress(vd);\n\n\treturn (err);\n}\n\nstatic void\nvdev_trim_xlate_range_add(void *arg, range_seg64_t *physical_rs)\n{\n\ttrim_args_t *ta = arg;\n\tvdev_t *vd = ta->trim_vdev;\n\n\t \n\tif (ta->trim_type == TRIM_TYPE_MANUAL) {\n\n\t\t \n\t\tif (physical_rs->rs_end <= vd->vdev_trim_last_offset)\n\t\t\treturn;\n\n\t\t \n\t\tif (vd->vdev_trim_last_offset > physical_rs->rs_start) {\n\t\t\tASSERT3U(physical_rs->rs_end, >,\n\t\t\t    vd->vdev_trim_last_offset);\n\t\t\tphysical_rs->rs_start = vd->vdev_trim_last_offset;\n\t\t}\n\t}\n\n\tASSERT3U(physical_rs->rs_end, >, physical_rs->rs_start);\n\n\trange_tree_add(ta->trim_tree, physical_rs->rs_start,\n\t    physical_rs->rs_end - physical_rs->rs_start);\n}\n\n \nstatic void\nvdev_trim_range_add(void *arg, uint64_t start, uint64_t size)\n{\n\ttrim_args_t *ta = arg;\n\tvdev_t *vd = ta->trim_vdev;\n\trange_seg64_t logical_rs;\n\tlogical_rs.rs_start = start;\n\tlogical_rs.rs_end = start + size;\n\n\t \n\tif (zfs_flags & ZFS_DEBUG_TRIM) {\n\t\tmetaslab_t *msp = ta->trim_msp;\n\t\tVERIFY0(metaslab_load(msp));\n\t\tVERIFY3B(msp->ms_loaded, ==, B_TRUE);\n\t\tVERIFY(range_tree_contains(msp->ms_allocatable, start, size));\n\t}\n\n\tASSERT(vd->vdev_ops->vdev_op_leaf);\n\tvdev_xlate_walk(vd, &logical_rs, vdev_trim_xlate_range_add, arg);\n}\n\n \nstatic __attribute__((noreturn)) void\nvdev_trim_thread(void *arg)\n{\n\tvdev_t *vd = arg;\n\tspa_t *spa = vd->vdev_spa;\n\ttrim_args_t ta;\n\tint error = 0;\n\n\t \n\ttxg_wait_synced(spa_get_dsl(vd->vdev_spa), 0);\n\n\tASSERT(vdev_is_concrete(vd));\n\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\n\tvd->vdev_trim_last_offset = 0;\n\tvd->vdev_trim_rate = 0;\n\tvd->vdev_trim_partial = 0;\n\tvd->vdev_trim_secure = 0;\n\n\tVERIFY0(vdev_trim_load(vd));\n\n\tta.trim_vdev = vd;\n\tta.trim_extent_bytes_max = zfs_trim_extent_bytes_max;\n\tta.trim_extent_bytes_min = zfs_trim_extent_bytes_min;\n\tta.trim_tree = range_tree_create(NULL, RANGE_SEG64, NULL, 0, 0);\n\tta.trim_type = TRIM_TYPE_MANUAL;\n\tta.trim_flags = 0;\n\n\t \n\tif (vd->vdev_trim_secure) {\n\t\tta.trim_flags |= ZIO_TRIM_SECURE;\n\t\tta.trim_extent_bytes_min = SPA_MINBLOCKSIZE;\n\t}\n\n\tuint64_t ms_count = 0;\n\tfor (uint64_t i = 0; !vd->vdev_detached &&\n\t    i < vd->vdev_top->vdev_ms_count; i++) {\n\t\tmetaslab_t *msp = vd->vdev_top->vdev_ms[i];\n\n\t\t \n\t\tif (vd->vdev_top->vdev_ms_count != ms_count) {\n\t\t\tvdev_trim_calculate_progress(vd);\n\t\t\tms_count = vd->vdev_top->vdev_ms_count;\n\t\t}\n\n\t\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\t\tmetaslab_disable(msp);\n\t\tmutex_enter(&msp->ms_lock);\n\t\tVERIFY0(metaslab_load(msp));\n\n\t\t \n\t\tif (msp->ms_sm == NULL && vd->vdev_trim_partial) {\n\t\t\tmutex_exit(&msp->ms_lock);\n\t\t\tmetaslab_enable(msp, B_FALSE, B_FALSE);\n\t\t\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\t\t\tvdev_trim_calculate_progress(vd);\n\t\t\tcontinue;\n\t\t}\n\n\t\tta.trim_msp = msp;\n\t\trange_tree_walk(msp->ms_allocatable, vdev_trim_range_add, &ta);\n\t\trange_tree_vacate(msp->ms_trim, NULL, NULL);\n\t\tmutex_exit(&msp->ms_lock);\n\n\t\terror = vdev_trim_ranges(&ta);\n\t\tmetaslab_enable(msp, B_TRUE, B_FALSE);\n\t\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\n\t\trange_tree_vacate(ta.trim_tree, NULL, NULL);\n\t\tif (error != 0)\n\t\t\tbreak;\n\t}\n\n\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\n\trange_tree_destroy(ta.trim_tree);\n\n\tmutex_enter(&vd->vdev_trim_lock);\n\tif (!vd->vdev_trim_exit_wanted) {\n\t\tif (vdev_writeable(vd)) {\n\t\t\tvdev_trim_change_state(vd, VDEV_TRIM_COMPLETE,\n\t\t\t    vd->vdev_trim_rate, vd->vdev_trim_partial,\n\t\t\t    vd->vdev_trim_secure);\n\t\t} else if (vd->vdev_faulted) {\n\t\t\tvdev_trim_change_state(vd, VDEV_TRIM_CANCELED,\n\t\t\t    vd->vdev_trim_rate, vd->vdev_trim_partial,\n\t\t\t    vd->vdev_trim_secure);\n\t\t}\n\t}\n\tASSERT(vd->vdev_trim_thread != NULL || vd->vdev_trim_inflight[0] == 0);\n\n\t \n\tmutex_exit(&vd->vdev_trim_lock);\n\ttxg_wait_synced(spa_get_dsl(spa), 0);\n\tmutex_enter(&vd->vdev_trim_lock);\n\n\tvd->vdev_trim_thread = NULL;\n\tcv_broadcast(&vd->vdev_trim_cv);\n\tmutex_exit(&vd->vdev_trim_lock);\n\n\tthread_exit();\n}\n\n \nvoid\nvdev_trim(vdev_t *vd, uint64_t rate, boolean_t partial, boolean_t secure)\n{\n\tASSERT(MUTEX_HELD(&vd->vdev_trim_lock));\n\tASSERT(vd->vdev_ops->vdev_op_leaf);\n\tASSERT(vdev_is_concrete(vd));\n\tASSERT3P(vd->vdev_trim_thread, ==, NULL);\n\tASSERT(!vd->vdev_detached);\n\tASSERT(!vd->vdev_trim_exit_wanted);\n\tASSERT(!vd->vdev_top->vdev_removing);\n\n\tvdev_trim_change_state(vd, VDEV_TRIM_ACTIVE, rate, partial, secure);\n\tvd->vdev_trim_thread = thread_create(NULL, 0,\n\t    vdev_trim_thread, vd, 0, &p0, TS_RUN, maxclsyspri);\n}\n\n \nstatic void\nvdev_trim_stop_wait_impl(vdev_t *vd)\n{\n\tASSERT(MUTEX_HELD(&vd->vdev_trim_lock));\n\n\twhile (vd->vdev_trim_thread != NULL)\n\t\tcv_wait(&vd->vdev_trim_cv, &vd->vdev_trim_lock);\n\n\tASSERT3P(vd->vdev_trim_thread, ==, NULL);\n\tvd->vdev_trim_exit_wanted = B_FALSE;\n}\n\n \nvoid\nvdev_trim_stop_wait(spa_t *spa, list_t *vd_list)\n{\n\t(void) spa;\n\tvdev_t *vd;\n\n\tASSERT(MUTEX_HELD(&spa_namespace_lock));\n\n\twhile ((vd = list_remove_head(vd_list)) != NULL) {\n\t\tmutex_enter(&vd->vdev_trim_lock);\n\t\tvdev_trim_stop_wait_impl(vd);\n\t\tmutex_exit(&vd->vdev_trim_lock);\n\t}\n}\n\n \nvoid\nvdev_trim_stop(vdev_t *vd, vdev_trim_state_t tgt_state, list_t *vd_list)\n{\n\tASSERT(!spa_config_held(vd->vdev_spa, SCL_CONFIG|SCL_STATE, RW_WRITER));\n\tASSERT(MUTEX_HELD(&vd->vdev_trim_lock));\n\tASSERT(vd->vdev_ops->vdev_op_leaf);\n\tASSERT(vdev_is_concrete(vd));\n\n\t \n\tif (vd->vdev_trim_thread == NULL && tgt_state != VDEV_TRIM_CANCELED)\n\t\treturn;\n\n\tvdev_trim_change_state(vd, tgt_state, 0, 0, 0);\n\tvd->vdev_trim_exit_wanted = B_TRUE;\n\n\tif (vd_list == NULL) {\n\t\tvdev_trim_stop_wait_impl(vd);\n\t} else {\n\t\tASSERT(MUTEX_HELD(&spa_namespace_lock));\n\t\tlist_insert_tail(vd_list, vd);\n\t}\n}\n\n \nstatic void\nvdev_trim_stop_all_impl(vdev_t *vd, vdev_trim_state_t tgt_state,\n    list_t *vd_list)\n{\n\tif (vd->vdev_ops->vdev_op_leaf && vdev_is_concrete(vd)) {\n\t\tmutex_enter(&vd->vdev_trim_lock);\n\t\tvdev_trim_stop(vd, tgt_state, vd_list);\n\t\tmutex_exit(&vd->vdev_trim_lock);\n\t\treturn;\n\t}\n\n\tfor (uint64_t i = 0; i < vd->vdev_children; i++) {\n\t\tvdev_trim_stop_all_impl(vd->vdev_child[i], tgt_state,\n\t\t    vd_list);\n\t}\n}\n\n \nvoid\nvdev_trim_stop_all(vdev_t *vd, vdev_trim_state_t tgt_state)\n{\n\tspa_t *spa = vd->vdev_spa;\n\tlist_t vd_list;\n\tvdev_t *vd_l2cache;\n\n\tASSERT(MUTEX_HELD(&spa_namespace_lock));\n\n\tlist_create(&vd_list, sizeof (vdev_t),\n\t    offsetof(vdev_t, vdev_trim_node));\n\n\tvdev_trim_stop_all_impl(vd, tgt_state, &vd_list);\n\n\t \n\tfor (int i = 0; i < spa->spa_l2cache.sav_count; i++) {\n\t\tvd_l2cache = spa->spa_l2cache.sav_vdevs[i];\n\t\tvdev_trim_stop_all_impl(vd_l2cache, tgt_state, &vd_list);\n\t}\n\n\tvdev_trim_stop_wait(spa, &vd_list);\n\n\tif (vd->vdev_spa->spa_sync_on) {\n\t\t \n\t\ttxg_wait_synced(spa_get_dsl(vd->vdev_spa), 0);\n\t}\n\n\tlist_destroy(&vd_list);\n}\n\n \nvoid\nvdev_trim_restart(vdev_t *vd)\n{\n\tASSERT(MUTEX_HELD(&spa_namespace_lock));\n\tASSERT(!spa_config_held(vd->vdev_spa, SCL_ALL, RW_WRITER));\n\n\tif (vd->vdev_leaf_zap != 0) {\n\t\tmutex_enter(&vd->vdev_trim_lock);\n\t\tuint64_t trim_state = VDEV_TRIM_NONE;\n\t\tint err = zap_lookup(vd->vdev_spa->spa_meta_objset,\n\t\t    vd->vdev_leaf_zap, VDEV_LEAF_ZAP_TRIM_STATE,\n\t\t    sizeof (trim_state), 1, &trim_state);\n\t\tASSERT(err == 0 || err == ENOENT);\n\t\tvd->vdev_trim_state = trim_state;\n\n\t\tuint64_t timestamp = 0;\n\t\terr = zap_lookup(vd->vdev_spa->spa_meta_objset,\n\t\t    vd->vdev_leaf_zap, VDEV_LEAF_ZAP_TRIM_ACTION_TIME,\n\t\t    sizeof (timestamp), 1, &timestamp);\n\t\tASSERT(err == 0 || err == ENOENT);\n\t\tvd->vdev_trim_action_time = timestamp;\n\n\t\tif (vd->vdev_trim_state == VDEV_TRIM_SUSPENDED ||\n\t\t    vd->vdev_offline) {\n\t\t\t \n\t\t\tVERIFY0(vdev_trim_load(vd));\n\t\t} else if (vd->vdev_trim_state == VDEV_TRIM_ACTIVE &&\n\t\t    vdev_writeable(vd) && !vd->vdev_top->vdev_removing &&\n\t\t    vd->vdev_trim_thread == NULL) {\n\t\t\tVERIFY0(vdev_trim_load(vd));\n\t\t\tvdev_trim(vd, vd->vdev_trim_rate,\n\t\t\t    vd->vdev_trim_partial, vd->vdev_trim_secure);\n\t\t}\n\n\t\tmutex_exit(&vd->vdev_trim_lock);\n\t}\n\n\tfor (uint64_t i = 0; i < vd->vdev_children; i++) {\n\t\tvdev_trim_restart(vd->vdev_child[i]);\n\t}\n}\n\n \nstatic void\nvdev_trim_range_verify(void *arg, uint64_t start, uint64_t size)\n{\n\ttrim_args_t *ta = arg;\n\tmetaslab_t *msp = ta->trim_msp;\n\n\tVERIFY3B(msp->ms_loaded, ==, B_TRUE);\n\tVERIFY3U(msp->ms_disabled, >, 0);\n\tVERIFY(range_tree_contains(msp->ms_allocatable, start, size));\n}\n\n \nstatic __attribute__((noreturn)) void\nvdev_autotrim_thread(void *arg)\n{\n\tvdev_t *vd = arg;\n\tspa_t *spa = vd->vdev_spa;\n\tint shift = 0;\n\n\tmutex_enter(&vd->vdev_autotrim_lock);\n\tASSERT3P(vd->vdev_top, ==, vd);\n\tASSERT3P(vd->vdev_autotrim_thread, !=, NULL);\n\tmutex_exit(&vd->vdev_autotrim_lock);\n\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\n\twhile (!vdev_autotrim_should_stop(vd)) {\n\t\tint txgs_per_trim = MAX(zfs_trim_txg_batch, 1);\n\t\tuint64_t extent_bytes_max = zfs_trim_extent_bytes_max;\n\t\tuint64_t extent_bytes_min = zfs_trim_extent_bytes_min;\n\n\t\t \n\t\tfor (uint64_t i = shift % txgs_per_trim; i < vd->vdev_ms_count;\n\t\t    i += txgs_per_trim) {\n\t\t\tmetaslab_t *msp = vd->vdev_ms[i];\n\t\t\trange_tree_t *trim_tree;\n\t\t\tboolean_t issued_trim = B_FALSE;\n\t\t\tboolean_t wait_aborted = B_FALSE;\n\n\t\t\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\t\t\tmetaslab_disable(msp);\n\t\t\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\n\t\t\tmutex_enter(&msp->ms_lock);\n\n\t\t\t \n\t\t\tif (msp->ms_sm == NULL ||\n\t\t\t    range_tree_is_empty(msp->ms_trim)) {\n\t\t\t\tmutex_exit(&msp->ms_lock);\n\t\t\t\tmetaslab_enable(msp, B_FALSE, B_FALSE);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (msp->ms_disabled > 1) {\n\t\t\t\tmutex_exit(&msp->ms_lock);\n\t\t\t\tmetaslab_enable(msp, B_FALSE, B_FALSE);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\ttrim_tree = range_tree_create(NULL, RANGE_SEG64, NULL,\n\t\t\t    0, 0);\n\t\t\trange_tree_swap(&msp->ms_trim, &trim_tree);\n\t\t\tASSERT(range_tree_is_empty(msp->ms_trim));\n\n\t\t\t \n\t\t\ttrim_args_t *tap;\n\t\t\tuint64_t children = vd->vdev_children;\n\t\t\tif (children == 0) {\n\t\t\t\tchildren = 1;\n\t\t\t\ttap = kmem_zalloc(sizeof (trim_args_t) *\n\t\t\t\t    children, KM_SLEEP);\n\t\t\t\ttap[0].trim_vdev = vd;\n\t\t\t} else {\n\t\t\t\ttap = kmem_zalloc(sizeof (trim_args_t) *\n\t\t\t\t    children, KM_SLEEP);\n\n\t\t\t\tfor (uint64_t c = 0; c < children; c++) {\n\t\t\t\t\ttap[c].trim_vdev = vd->vdev_child[c];\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor (uint64_t c = 0; c < children; c++) {\n\t\t\t\ttrim_args_t *ta = &tap[c];\n\t\t\t\tvdev_t *cvd = ta->trim_vdev;\n\n\t\t\t\tta->trim_msp = msp;\n\t\t\t\tta->trim_extent_bytes_max = extent_bytes_max;\n\t\t\t\tta->trim_extent_bytes_min = extent_bytes_min;\n\t\t\t\tta->trim_type = TRIM_TYPE_AUTO;\n\t\t\t\tta->trim_flags = 0;\n\n\t\t\t\tif (cvd->vdev_detached ||\n\t\t\t\t    !vdev_writeable(cvd) ||\n\t\t\t\t    !cvd->vdev_has_trim ||\n\t\t\t\t    cvd->vdev_trim_thread != NULL) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tif (!cvd->vdev_ops->vdev_op_leaf)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tta->trim_tree = range_tree_create(NULL,\n\t\t\t\t    RANGE_SEG64, NULL, 0, 0);\n\t\t\t\trange_tree_walk(trim_tree,\n\t\t\t\t    vdev_trim_range_add, ta);\n\t\t\t}\n\n\t\t\tmutex_exit(&msp->ms_lock);\n\t\t\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\n\t\t\t \n\t\t\tfor (uint64_t c = 0; c < children; c++) {\n\t\t\t\ttrim_args_t *ta = &tap[c];\n\n\t\t\t\t \n\t\t\t\tif (ta->trim_tree == NULL ||\n\t\t\t\t    ta->trim_vdev->vdev_trim_thread != NULL) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tissued_trim = B_TRUE;\n\n\t\t\t\tint error = vdev_trim_ranges(ta);\n\t\t\t\tif (error)\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (zfs_flags & ZFS_DEBUG_TRIM) {\n\t\t\t\tmutex_enter(&msp->ms_lock);\n\t\t\t\tVERIFY0(metaslab_load(msp));\n\t\t\t\tVERIFY3P(tap[0].trim_msp, ==, msp);\n\t\t\t\trange_tree_walk(trim_tree,\n\t\t\t\t    vdev_trim_range_verify, &tap[0]);\n\t\t\t\tmutex_exit(&msp->ms_lock);\n\t\t\t}\n\n\t\t\trange_tree_vacate(trim_tree, NULL, NULL);\n\t\t\trange_tree_destroy(trim_tree);\n\n\t\t\t \n\t\t\tif (issued_trim) {\n\t\t\t\twait_aborted = vdev_autotrim_wait_kick(vd,\n\t\t\t\t    TXG_CONCURRENT_STATES + TXG_DEFER_SIZE);\n\t\t\t}\n\n\t\t\tmetaslab_enable(msp, wait_aborted, B_FALSE);\n\t\t\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\n\t\t\tfor (uint64_t c = 0; c < children; c++) {\n\t\t\t\ttrim_args_t *ta = &tap[c];\n\n\t\t\t\tif (ta->trim_tree == NULL)\n\t\t\t\t\tcontinue;\n\n\t\t\t\trange_tree_vacate(ta->trim_tree, NULL, NULL);\n\t\t\t\trange_tree_destroy(ta->trim_tree);\n\t\t\t}\n\n\t\t\tkmem_free(tap, sizeof (trim_args_t) * children);\n\n\t\t\tif (vdev_autotrim_should_stop(vd))\n\t\t\t\tbreak;\n\t\t}\n\n\t\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\n\t\tvdev_autotrim_wait_kick(vd, 1);\n\n\t\tshift++;\n\t\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\t}\n\n\tfor (uint64_t c = 0; c < vd->vdev_children; c++) {\n\t\tvdev_t *cvd = vd->vdev_child[c];\n\t\tmutex_enter(&cvd->vdev_trim_io_lock);\n\n\t\twhile (cvd->vdev_trim_inflight[1] > 0) {\n\t\t\tcv_wait(&cvd->vdev_trim_io_cv,\n\t\t\t    &cvd->vdev_trim_io_lock);\n\t\t}\n\t\tmutex_exit(&cvd->vdev_trim_io_lock);\n\t}\n\n\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\n\t \n\tif (spa_get_autotrim(spa) == SPA_AUTOTRIM_OFF) {\n\t\tfor (uint64_t i = 0; i < vd->vdev_ms_count; i++) {\n\t\t\tmetaslab_t *msp = vd->vdev_ms[i];\n\n\t\t\tmutex_enter(&msp->ms_lock);\n\t\t\trange_tree_vacate(msp->ms_trim, NULL, NULL);\n\t\t\tmutex_exit(&msp->ms_lock);\n\t\t}\n\t}\n\n\tmutex_enter(&vd->vdev_autotrim_lock);\n\tASSERT(vd->vdev_autotrim_thread != NULL);\n\tvd->vdev_autotrim_thread = NULL;\n\tcv_broadcast(&vd->vdev_autotrim_cv);\n\tmutex_exit(&vd->vdev_autotrim_lock);\n\n\tthread_exit();\n}\n\n \nvoid\nvdev_autotrim(spa_t *spa)\n{\n\tvdev_t *root_vd = spa->spa_root_vdev;\n\n\tfor (uint64_t i = 0; i < root_vd->vdev_children; i++) {\n\t\tvdev_t *tvd = root_vd->vdev_child[i];\n\n\t\tmutex_enter(&tvd->vdev_autotrim_lock);\n\t\tif (vdev_writeable(tvd) && !tvd->vdev_removing &&\n\t\t    tvd->vdev_autotrim_thread == NULL) {\n\t\t\tASSERT3P(tvd->vdev_top, ==, tvd);\n\n\t\t\ttvd->vdev_autotrim_thread = thread_create(NULL, 0,\n\t\t\t    vdev_autotrim_thread, tvd, 0, &p0, TS_RUN,\n\t\t\t    maxclsyspri);\n\t\t\tASSERT(tvd->vdev_autotrim_thread != NULL);\n\t\t}\n\t\tmutex_exit(&tvd->vdev_autotrim_lock);\n\t}\n}\n\n \nvoid\nvdev_autotrim_stop_wait(vdev_t *tvd)\n{\n\tmutex_enter(&tvd->vdev_autotrim_lock);\n\tif (tvd->vdev_autotrim_thread != NULL) {\n\t\ttvd->vdev_autotrim_exit_wanted = B_TRUE;\n\t\tcv_broadcast(&tvd->vdev_autotrim_kick_cv);\n\t\tcv_wait(&tvd->vdev_autotrim_cv,\n\t\t    &tvd->vdev_autotrim_lock);\n\n\t\tASSERT3P(tvd->vdev_autotrim_thread, ==, NULL);\n\t\ttvd->vdev_autotrim_exit_wanted = B_FALSE;\n\t}\n\tmutex_exit(&tvd->vdev_autotrim_lock);\n}\n\nvoid\nvdev_autotrim_kick(spa_t *spa)\n{\n\tASSERT(spa_config_held(spa, SCL_CONFIG, RW_READER));\n\n\tvdev_t *root_vd = spa->spa_root_vdev;\n\tvdev_t *tvd;\n\n\tfor (uint64_t i = 0; i < root_vd->vdev_children; i++) {\n\t\ttvd = root_vd->vdev_child[i];\n\n\t\tmutex_enter(&tvd->vdev_autotrim_lock);\n\t\tif (tvd->vdev_autotrim_thread != NULL)\n\t\t\tcv_broadcast(&tvd->vdev_autotrim_kick_cv);\n\t\tmutex_exit(&tvd->vdev_autotrim_lock);\n\t}\n}\n\n \nvoid\nvdev_autotrim_stop_all(spa_t *spa)\n{\n\tvdev_t *root_vd = spa->spa_root_vdev;\n\n\tfor (uint64_t i = 0; i < root_vd->vdev_children; i++)\n\t\tvdev_autotrim_stop_wait(root_vd->vdev_child[i]);\n}\n\n \nvoid\nvdev_autotrim_restart(spa_t *spa)\n{\n\tASSERT(MUTEX_HELD(&spa_namespace_lock));\n\n\tif (spa->spa_autotrim)\n\t\tvdev_autotrim(spa);\n}\n\nstatic __attribute__((noreturn)) void\nvdev_trim_l2arc_thread(void *arg)\n{\n\tvdev_t\t\t*vd = arg;\n\tspa_t\t\t*spa = vd->vdev_spa;\n\tl2arc_dev_t\t*dev = l2arc_vdev_get(vd);\n\ttrim_args_t\tta = {0};\n\trange_seg64_t \tphysical_rs;\n\n\tASSERT(vdev_is_concrete(vd));\n\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\n\tvd->vdev_trim_last_offset = 0;\n\tvd->vdev_trim_rate = 0;\n\tvd->vdev_trim_partial = 0;\n\tvd->vdev_trim_secure = 0;\n\n\tta.trim_vdev = vd;\n\tta.trim_tree = range_tree_create(NULL, RANGE_SEG64, NULL, 0, 0);\n\tta.trim_type = TRIM_TYPE_MANUAL;\n\tta.trim_extent_bytes_max = zfs_trim_extent_bytes_max;\n\tta.trim_extent_bytes_min = SPA_MINBLOCKSIZE;\n\tta.trim_flags = 0;\n\n\tphysical_rs.rs_start = vd->vdev_trim_bytes_done = 0;\n\tphysical_rs.rs_end = vd->vdev_trim_bytes_est =\n\t    vdev_get_min_asize(vd);\n\n\trange_tree_add(ta.trim_tree, physical_rs.rs_start,\n\t    physical_rs.rs_end - physical_rs.rs_start);\n\n\tmutex_enter(&vd->vdev_trim_lock);\n\tvdev_trim_change_state(vd, VDEV_TRIM_ACTIVE, 0, 0, 0);\n\tmutex_exit(&vd->vdev_trim_lock);\n\n\t(void) vdev_trim_ranges(&ta);\n\n\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\tmutex_enter(&vd->vdev_trim_io_lock);\n\twhile (vd->vdev_trim_inflight[TRIM_TYPE_MANUAL] > 0) {\n\t\tcv_wait(&vd->vdev_trim_io_cv, &vd->vdev_trim_io_lock);\n\t}\n\tmutex_exit(&vd->vdev_trim_io_lock);\n\n\trange_tree_vacate(ta.trim_tree, NULL, NULL);\n\trange_tree_destroy(ta.trim_tree);\n\n\tmutex_enter(&vd->vdev_trim_lock);\n\tif (!vd->vdev_trim_exit_wanted && vdev_writeable(vd)) {\n\t\tvdev_trim_change_state(vd, VDEV_TRIM_COMPLETE,\n\t\t    vd->vdev_trim_rate, vd->vdev_trim_partial,\n\t\t    vd->vdev_trim_secure);\n\t}\n\tASSERT(vd->vdev_trim_thread != NULL ||\n\t    vd->vdev_trim_inflight[TRIM_TYPE_MANUAL] == 0);\n\n\t \n\tmutex_exit(&vd->vdev_trim_lock);\n\ttxg_wait_synced(spa_get_dsl(vd->vdev_spa), 0);\n\tmutex_enter(&vd->vdev_trim_lock);\n\n\t \n\tspa_config_enter(vd->vdev_spa, SCL_L2ARC, vd,\n\t    RW_READER);\n\tmemset(dev->l2ad_dev_hdr, 0, dev->l2ad_dev_hdr_asize);\n\tl2arc_dev_hdr_update(dev);\n\tspa_config_exit(vd->vdev_spa, SCL_L2ARC, vd);\n\n\tvd->vdev_trim_thread = NULL;\n\tif (vd->vdev_trim_state == VDEV_TRIM_COMPLETE)\n\t\tdev->l2ad_trim_all = B_FALSE;\n\n\tcv_broadcast(&vd->vdev_trim_cv);\n\tmutex_exit(&vd->vdev_trim_lock);\n\n\tthread_exit();\n}\n\n \nvoid\nvdev_trim_l2arc(spa_t *spa)\n{\n\tASSERT(MUTEX_HELD(&spa_namespace_lock));\n\n\t \n\tfor (int i = 0; i < spa->spa_l2cache.sav_count; i++) {\n\t\tvdev_t *vd = spa->spa_l2cache.sav_vdevs[i];\n\t\tl2arc_dev_t *dev = l2arc_vdev_get(vd);\n\n\t\tif (dev == NULL || !dev->l2ad_trim_all) {\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\n\t\tmutex_enter(&vd->vdev_trim_lock);\n\t\tASSERT(vd->vdev_ops->vdev_op_leaf);\n\t\tASSERT(vdev_is_concrete(vd));\n\t\tASSERT3P(vd->vdev_trim_thread, ==, NULL);\n\t\tASSERT(!vd->vdev_detached);\n\t\tASSERT(!vd->vdev_trim_exit_wanted);\n\t\tASSERT(!vd->vdev_top->vdev_removing);\n\t\tvdev_trim_change_state(vd, VDEV_TRIM_ACTIVE, 0, 0, 0);\n\t\tvd->vdev_trim_thread = thread_create(NULL, 0,\n\t\t    vdev_trim_l2arc_thread, vd, 0, &p0, TS_RUN, maxclsyspri);\n\t\tmutex_exit(&vd->vdev_trim_lock);\n\t}\n}\n\n \nint\nvdev_trim_simple(vdev_t *vd, uint64_t start, uint64_t size)\n{\n\ttrim_args_t ta = {0};\n\trange_seg64_t physical_rs;\n\tint error;\n\tphysical_rs.rs_start = start;\n\tphysical_rs.rs_end = start + size;\n\n\tASSERT(vdev_is_concrete(vd));\n\tASSERT(vd->vdev_ops->vdev_op_leaf);\n\tASSERT(!vd->vdev_detached);\n\tASSERT(!vd->vdev_top->vdev_removing);\n\n\tta.trim_vdev = vd;\n\tta.trim_tree = range_tree_create(NULL, RANGE_SEG64, NULL, 0, 0);\n\tta.trim_type = TRIM_TYPE_SIMPLE;\n\tta.trim_extent_bytes_max = zfs_trim_extent_bytes_max;\n\tta.trim_extent_bytes_min = SPA_MINBLOCKSIZE;\n\tta.trim_flags = 0;\n\n\tASSERT3U(physical_rs.rs_end, >=, physical_rs.rs_start);\n\n\tif (physical_rs.rs_end > physical_rs.rs_start) {\n\t\trange_tree_add(ta.trim_tree, physical_rs.rs_start,\n\t\t    physical_rs.rs_end - physical_rs.rs_start);\n\t} else {\n\t\tASSERT3U(physical_rs.rs_end, ==, physical_rs.rs_start);\n\t}\n\n\terror = vdev_trim_ranges(&ta);\n\n\tmutex_enter(&vd->vdev_trim_io_lock);\n\twhile (vd->vdev_trim_inflight[TRIM_TYPE_SIMPLE] > 0) {\n\t\tcv_wait(&vd->vdev_trim_io_cv, &vd->vdev_trim_io_lock);\n\t}\n\tmutex_exit(&vd->vdev_trim_io_lock);\n\n\trange_tree_vacate(ta.trim_tree, NULL, NULL);\n\trange_tree_destroy(ta.trim_tree);\n\n\treturn (error);\n}\n\nEXPORT_SYMBOL(vdev_trim);\nEXPORT_SYMBOL(vdev_trim_stop);\nEXPORT_SYMBOL(vdev_trim_stop_all);\nEXPORT_SYMBOL(vdev_trim_stop_wait);\nEXPORT_SYMBOL(vdev_trim_restart);\nEXPORT_SYMBOL(vdev_autotrim);\nEXPORT_SYMBOL(vdev_autotrim_stop_all);\nEXPORT_SYMBOL(vdev_autotrim_stop_wait);\nEXPORT_SYMBOL(vdev_autotrim_restart);\nEXPORT_SYMBOL(vdev_trim_l2arc);\nEXPORT_SYMBOL(vdev_trim_simple);\n\nZFS_MODULE_PARAM(zfs_trim, zfs_trim_, extent_bytes_max, UINT, ZMOD_RW,\n\t\"Max size of TRIM commands, larger will be split\");\n\nZFS_MODULE_PARAM(zfs_trim, zfs_trim_, extent_bytes_min, UINT, ZMOD_RW,\n\t\"Min size of TRIM commands, smaller will be skipped\");\n\nZFS_MODULE_PARAM(zfs_trim, zfs_trim_, metaslab_skip, UINT, ZMOD_RW,\n\t\"Skip metaslabs which have never been initialized\");\n\nZFS_MODULE_PARAM(zfs_trim, zfs_trim_, txg_batch, UINT, ZMOD_RW,\n\t\"Min number of txgs to aggregate frees before issuing TRIM\");\n\nZFS_MODULE_PARAM(zfs_trim, zfs_trim_, queue_limit, UINT, ZMOD_RW,\n\t\"Max queued TRIMs outstanding per leaf vdev\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}