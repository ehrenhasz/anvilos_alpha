{
  "module_name": "zil.c",
  "hash_id": "881a545d57def1a390fd1460302d0966fb656e963298c7dc6e1ba2deb84bd3ef",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/zil.c",
  "human_readable_source": " \n \n\n \n\n#include <sys/zfs_context.h>\n#include <sys/spa.h>\n#include <sys/spa_impl.h>\n#include <sys/dmu.h>\n#include <sys/zap.h>\n#include <sys/arc.h>\n#include <sys/stat.h>\n#include <sys/zil.h>\n#include <sys/zil_impl.h>\n#include <sys/dsl_dataset.h>\n#include <sys/vdev_impl.h>\n#include <sys/dmu_tx.h>\n#include <sys/dsl_pool.h>\n#include <sys/metaslab.h>\n#include <sys/trace_zfs.h>\n#include <sys/abd.h>\n#include <sys/brt.h>\n#include <sys/wmsum.h>\n\n \n\n \nstatic uint_t zfs_commit_timeout_pct = 5;\n\n \nstatic uint64_t zil_min_commit_timeout = 5000;\n\n \nstatic zil_kstat_values_t zil_stats = {\n\t{ \"zil_commit_count\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"zil_commit_writer_count\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_count\",\t\t\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_indirect_count\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_indirect_bytes\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_copied_count\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_copied_bytes\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_needcopy_count\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_needcopy_bytes\",\t\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_metaslab_normal_count\",\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_metaslab_normal_bytes\",\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_metaslab_normal_write\",\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_metaslab_normal_alloc\",\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_metaslab_slog_count\",\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_metaslab_slog_bytes\",\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_metaslab_slog_write\",\tKSTAT_DATA_UINT64 },\n\t{ \"zil_itx_metaslab_slog_alloc\",\tKSTAT_DATA_UINT64 },\n};\n\nstatic zil_sums_t zil_sums_global;\nstatic kstat_t *zil_kstats_global;\n\n \nint zil_replay_disable = 0;\n\n \nstatic int zil_nocacheflush = 0;\n\n \nstatic uint64_t zil_slog_bulk = 64 * 1024 * 1024;\n\nstatic kmem_cache_t *zil_lwb_cache;\nstatic kmem_cache_t *zil_zcw_cache;\n\nstatic void zil_lwb_commit(zilog_t *zilog, lwb_t *lwb, itx_t *itx);\nstatic itx_t *zil_itx_clone(itx_t *oitx);\n\nstatic int\nzil_bp_compare(const void *x1, const void *x2)\n{\n\tconst dva_t *dva1 = &((zil_bp_node_t *)x1)->zn_dva;\n\tconst dva_t *dva2 = &((zil_bp_node_t *)x2)->zn_dva;\n\n\tint cmp = TREE_CMP(DVA_GET_VDEV(dva1), DVA_GET_VDEV(dva2));\n\tif (likely(cmp))\n\t\treturn (cmp);\n\n\treturn (TREE_CMP(DVA_GET_OFFSET(dva1), DVA_GET_OFFSET(dva2)));\n}\n\nstatic void\nzil_bp_tree_init(zilog_t *zilog)\n{\n\tavl_create(&zilog->zl_bp_tree, zil_bp_compare,\n\t    sizeof (zil_bp_node_t), offsetof(zil_bp_node_t, zn_node));\n}\n\nstatic void\nzil_bp_tree_fini(zilog_t *zilog)\n{\n\tavl_tree_t *t = &zilog->zl_bp_tree;\n\tzil_bp_node_t *zn;\n\tvoid *cookie = NULL;\n\n\twhile ((zn = avl_destroy_nodes(t, &cookie)) != NULL)\n\t\tkmem_free(zn, sizeof (zil_bp_node_t));\n\n\tavl_destroy(t);\n}\n\nint\nzil_bp_tree_add(zilog_t *zilog, const blkptr_t *bp)\n{\n\tavl_tree_t *t = &zilog->zl_bp_tree;\n\tconst dva_t *dva;\n\tzil_bp_node_t *zn;\n\tavl_index_t where;\n\n\tif (BP_IS_EMBEDDED(bp))\n\t\treturn (0);\n\n\tdva = BP_IDENTITY(bp);\n\n\tif (avl_find(t, dva, &where) != NULL)\n\t\treturn (SET_ERROR(EEXIST));\n\n\tzn = kmem_alloc(sizeof (zil_bp_node_t), KM_SLEEP);\n\tzn->zn_dva = *dva;\n\tavl_insert(t, zn, where);\n\n\treturn (0);\n}\n\nstatic zil_header_t *\nzil_header_in_syncing_context(zilog_t *zilog)\n{\n\treturn ((zil_header_t *)zilog->zl_header);\n}\n\nstatic void\nzil_init_log_chain(zilog_t *zilog, blkptr_t *bp)\n{\n\tzio_cksum_t *zc = &bp->blk_cksum;\n\n\t(void) random_get_pseudo_bytes((void *)&zc->zc_word[ZIL_ZC_GUID_0],\n\t    sizeof (zc->zc_word[ZIL_ZC_GUID_0]));\n\t(void) random_get_pseudo_bytes((void *)&zc->zc_word[ZIL_ZC_GUID_1],\n\t    sizeof (zc->zc_word[ZIL_ZC_GUID_1]));\n\tzc->zc_word[ZIL_ZC_OBJSET] = dmu_objset_id(zilog->zl_os);\n\tzc->zc_word[ZIL_ZC_SEQ] = 1ULL;\n}\n\nstatic int\nzil_kstats_global_update(kstat_t *ksp, int rw)\n{\n\tzil_kstat_values_t *zs = ksp->ks_data;\n\tASSERT3P(&zil_stats, ==, zs);\n\n\tif (rw == KSTAT_WRITE) {\n\t\treturn (SET_ERROR(EACCES));\n\t}\n\n\tzil_kstat_values_update(zs, &zil_sums_global);\n\n\treturn (0);\n}\n\n \nstatic int\nzil_read_log_block(zilog_t *zilog, boolean_t decrypt, const blkptr_t *bp,\n    blkptr_t *nbp, char **begin, char **end, arc_buf_t **abuf)\n{\n\tzio_flag_t zio_flags = ZIO_FLAG_CANFAIL;\n\tarc_flags_t aflags = ARC_FLAG_WAIT;\n\tzbookmark_phys_t zb;\n\tint error;\n\n\tif (zilog->zl_header->zh_claim_txg == 0)\n\t\tzio_flags |= ZIO_FLAG_SPECULATIVE | ZIO_FLAG_SCRUB;\n\n\tif (!(zilog->zl_header->zh_flags & ZIL_CLAIM_LR_SEQ_VALID))\n\t\tzio_flags |= ZIO_FLAG_SPECULATIVE;\n\n\tif (!decrypt)\n\t\tzio_flags |= ZIO_FLAG_RAW;\n\n\tSET_BOOKMARK(&zb, bp->blk_cksum.zc_word[ZIL_ZC_OBJSET],\n\t    ZB_ZIL_OBJECT, ZB_ZIL_LEVEL, bp->blk_cksum.zc_word[ZIL_ZC_SEQ]);\n\n\terror = arc_read(NULL, zilog->zl_spa, bp, arc_getbuf_func,\n\t    abuf, ZIO_PRIORITY_SYNC_READ, zio_flags, &aflags, &zb);\n\n\tif (error == 0) {\n\t\tzio_cksum_t cksum = bp->blk_cksum;\n\n\t\t \n\t\tcksum.zc_word[ZIL_ZC_SEQ]++;\n\n\t\tuint64_t size = BP_GET_LSIZE(bp);\n\t\tif (BP_GET_CHECKSUM(bp) == ZIO_CHECKSUM_ZILOG2) {\n\t\t\tzil_chain_t *zilc = (*abuf)->b_data;\n\t\t\tchar *lr = (char *)(zilc + 1);\n\n\t\t\tif (memcmp(&cksum, &zilc->zc_next_blk.blk_cksum,\n\t\t\t    sizeof (cksum)) ||\n\t\t\t    zilc->zc_nused < sizeof (*zilc) ||\n\t\t\t    zilc->zc_nused > size) {\n\t\t\t\terror = SET_ERROR(ECKSUM);\n\t\t\t} else {\n\t\t\t\t*begin = lr;\n\t\t\t\t*end = lr + zilc->zc_nused - sizeof (*zilc);\n\t\t\t\t*nbp = zilc->zc_next_blk;\n\t\t\t}\n\t\t} else {\n\t\t\tchar *lr = (*abuf)->b_data;\n\t\t\tzil_chain_t *zilc = (zil_chain_t *)(lr + size) - 1;\n\n\t\t\tif (memcmp(&cksum, &zilc->zc_next_blk.blk_cksum,\n\t\t\t    sizeof (cksum)) ||\n\t\t\t    (zilc->zc_nused > (size - sizeof (*zilc)))) {\n\t\t\t\terror = SET_ERROR(ECKSUM);\n\t\t\t} else {\n\t\t\t\t*begin = lr;\n\t\t\t\t*end = lr + zilc->zc_nused;\n\t\t\t\t*nbp = zilc->zc_next_blk;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn (error);\n}\n\n \nstatic int\nzil_read_log_data(zilog_t *zilog, const lr_write_t *lr, void *wbuf)\n{\n\tzio_flag_t zio_flags = ZIO_FLAG_CANFAIL;\n\tconst blkptr_t *bp = &lr->lr_blkptr;\n\tarc_flags_t aflags = ARC_FLAG_WAIT;\n\tarc_buf_t *abuf = NULL;\n\tzbookmark_phys_t zb;\n\tint error;\n\n\tif (BP_IS_HOLE(bp)) {\n\t\tif (wbuf != NULL)\n\t\t\tmemset(wbuf, 0, MAX(BP_GET_LSIZE(bp), lr->lr_length));\n\t\treturn (0);\n\t}\n\n\tif (zilog->zl_header->zh_claim_txg == 0)\n\t\tzio_flags |= ZIO_FLAG_SPECULATIVE | ZIO_FLAG_SCRUB;\n\n\t \n\tif (wbuf == NULL)\n\t\tzio_flags |= ZIO_FLAG_RAW;\n\n\tASSERT3U(BP_GET_LSIZE(bp), !=, 0);\n\tSET_BOOKMARK(&zb, dmu_objset_id(zilog->zl_os), lr->lr_foid,\n\t    ZB_ZIL_LEVEL, lr->lr_offset / BP_GET_LSIZE(bp));\n\n\terror = arc_read(NULL, zilog->zl_spa, bp, arc_getbuf_func, &abuf,\n\t    ZIO_PRIORITY_SYNC_READ, zio_flags, &aflags, &zb);\n\n\tif (error == 0) {\n\t\tif (wbuf != NULL)\n\t\t\tmemcpy(wbuf, abuf->b_data, arc_buf_size(abuf));\n\t\tarc_buf_destroy(abuf, &abuf);\n\t}\n\n\treturn (error);\n}\n\nvoid\nzil_sums_init(zil_sums_t *zs)\n{\n\twmsum_init(&zs->zil_commit_count, 0);\n\twmsum_init(&zs->zil_commit_writer_count, 0);\n\twmsum_init(&zs->zil_itx_count, 0);\n\twmsum_init(&zs->zil_itx_indirect_count, 0);\n\twmsum_init(&zs->zil_itx_indirect_bytes, 0);\n\twmsum_init(&zs->zil_itx_copied_count, 0);\n\twmsum_init(&zs->zil_itx_copied_bytes, 0);\n\twmsum_init(&zs->zil_itx_needcopy_count, 0);\n\twmsum_init(&zs->zil_itx_needcopy_bytes, 0);\n\twmsum_init(&zs->zil_itx_metaslab_normal_count, 0);\n\twmsum_init(&zs->zil_itx_metaslab_normal_bytes, 0);\n\twmsum_init(&zs->zil_itx_metaslab_normal_write, 0);\n\twmsum_init(&zs->zil_itx_metaslab_normal_alloc, 0);\n\twmsum_init(&zs->zil_itx_metaslab_slog_count, 0);\n\twmsum_init(&zs->zil_itx_metaslab_slog_bytes, 0);\n\twmsum_init(&zs->zil_itx_metaslab_slog_write, 0);\n\twmsum_init(&zs->zil_itx_metaslab_slog_alloc, 0);\n}\n\nvoid\nzil_sums_fini(zil_sums_t *zs)\n{\n\twmsum_fini(&zs->zil_commit_count);\n\twmsum_fini(&zs->zil_commit_writer_count);\n\twmsum_fini(&zs->zil_itx_count);\n\twmsum_fini(&zs->zil_itx_indirect_count);\n\twmsum_fini(&zs->zil_itx_indirect_bytes);\n\twmsum_fini(&zs->zil_itx_copied_count);\n\twmsum_fini(&zs->zil_itx_copied_bytes);\n\twmsum_fini(&zs->zil_itx_needcopy_count);\n\twmsum_fini(&zs->zil_itx_needcopy_bytes);\n\twmsum_fini(&zs->zil_itx_metaslab_normal_count);\n\twmsum_fini(&zs->zil_itx_metaslab_normal_bytes);\n\twmsum_fini(&zs->zil_itx_metaslab_normal_write);\n\twmsum_fini(&zs->zil_itx_metaslab_normal_alloc);\n\twmsum_fini(&zs->zil_itx_metaslab_slog_count);\n\twmsum_fini(&zs->zil_itx_metaslab_slog_bytes);\n\twmsum_fini(&zs->zil_itx_metaslab_slog_write);\n\twmsum_fini(&zs->zil_itx_metaslab_slog_alloc);\n}\n\nvoid\nzil_kstat_values_update(zil_kstat_values_t *zs, zil_sums_t *zil_sums)\n{\n\tzs->zil_commit_count.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_commit_count);\n\tzs->zil_commit_writer_count.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_commit_writer_count);\n\tzs->zil_itx_count.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_count);\n\tzs->zil_itx_indirect_count.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_indirect_count);\n\tzs->zil_itx_indirect_bytes.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_indirect_bytes);\n\tzs->zil_itx_copied_count.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_copied_count);\n\tzs->zil_itx_copied_bytes.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_copied_bytes);\n\tzs->zil_itx_needcopy_count.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_needcopy_count);\n\tzs->zil_itx_needcopy_bytes.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_needcopy_bytes);\n\tzs->zil_itx_metaslab_normal_count.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_metaslab_normal_count);\n\tzs->zil_itx_metaslab_normal_bytes.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_metaslab_normal_bytes);\n\tzs->zil_itx_metaslab_normal_write.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_metaslab_normal_write);\n\tzs->zil_itx_metaslab_normal_alloc.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_metaslab_normal_alloc);\n\tzs->zil_itx_metaslab_slog_count.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_metaslab_slog_count);\n\tzs->zil_itx_metaslab_slog_bytes.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_metaslab_slog_bytes);\n\tzs->zil_itx_metaslab_slog_write.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_metaslab_slog_write);\n\tzs->zil_itx_metaslab_slog_alloc.value.ui64 =\n\t    wmsum_value(&zil_sums->zil_itx_metaslab_slog_alloc);\n}\n\n \nint\nzil_parse(zilog_t *zilog, zil_parse_blk_func_t *parse_blk_func,\n    zil_parse_lr_func_t *parse_lr_func, void *arg, uint64_t txg,\n    boolean_t decrypt)\n{\n\tconst zil_header_t *zh = zilog->zl_header;\n\tboolean_t claimed = !!zh->zh_claim_txg;\n\tuint64_t claim_blk_seq = claimed ? zh->zh_claim_blk_seq : UINT64_MAX;\n\tuint64_t claim_lr_seq = claimed ? zh->zh_claim_lr_seq : UINT64_MAX;\n\tuint64_t max_blk_seq = 0;\n\tuint64_t max_lr_seq = 0;\n\tuint64_t blk_count = 0;\n\tuint64_t lr_count = 0;\n\tblkptr_t blk, next_blk = {{{{0}}}};\n\tint error = 0;\n\n\t \n\tif (!(zh->zh_flags & ZIL_CLAIM_LR_SEQ_VALID))\n\t\tclaim_lr_seq = UINT64_MAX;\n\n\t \n\tzil_bp_tree_init(zilog);\n\n\tfor (blk = zh->zh_log; !BP_IS_HOLE(&blk); blk = next_blk) {\n\t\tuint64_t blk_seq = blk.blk_cksum.zc_word[ZIL_ZC_SEQ];\n\t\tint reclen;\n\t\tchar *lrp, *end;\n\t\tarc_buf_t *abuf = NULL;\n\n\t\tif (blk_seq > claim_blk_seq)\n\t\t\tbreak;\n\n\t\terror = parse_blk_func(zilog, &blk, arg, txg);\n\t\tif (error != 0)\n\t\t\tbreak;\n\t\tASSERT3U(max_blk_seq, <, blk_seq);\n\t\tmax_blk_seq = blk_seq;\n\t\tblk_count++;\n\n\t\tif (max_lr_seq == claim_lr_seq && max_blk_seq == claim_blk_seq)\n\t\t\tbreak;\n\n\t\terror = zil_read_log_block(zilog, decrypt, &blk, &next_blk,\n\t\t    &lrp, &end, &abuf);\n\t\tif (error != 0) {\n\t\t\tif (abuf)\n\t\t\t\tarc_buf_destroy(abuf, &abuf);\n\t\t\tif (claimed) {\n\t\t\t\tchar name[ZFS_MAX_DATASET_NAME_LEN];\n\n\t\t\t\tdmu_objset_name(zilog->zl_os, name);\n\n\t\t\t\tcmn_err(CE_WARN, \"ZFS read log block error %d, \"\n\t\t\t\t    \"dataset %s, seq 0x%llx\\n\", error, name,\n\t\t\t\t    (u_longlong_t)blk_seq);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (; lrp < end; lrp += reclen) {\n\t\t\tlr_t *lr = (lr_t *)lrp;\n\t\t\treclen = lr->lrc_reclen;\n\t\t\tASSERT3U(reclen, >=, sizeof (lr_t));\n\t\t\tif (lr->lrc_seq > claim_lr_seq) {\n\t\t\t\tarc_buf_destroy(abuf, &abuf);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\terror = parse_lr_func(zilog, lr, arg, txg);\n\t\t\tif (error != 0) {\n\t\t\t\tarc_buf_destroy(abuf, &abuf);\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tASSERT3U(max_lr_seq, <, lr->lrc_seq);\n\t\t\tmax_lr_seq = lr->lrc_seq;\n\t\t\tlr_count++;\n\t\t}\n\t\tarc_buf_destroy(abuf, &abuf);\n\t}\ndone:\n\tzilog->zl_parse_error = error;\n\tzilog->zl_parse_blk_seq = max_blk_seq;\n\tzilog->zl_parse_lr_seq = max_lr_seq;\n\tzilog->zl_parse_blk_count = blk_count;\n\tzilog->zl_parse_lr_count = lr_count;\n\n\tzil_bp_tree_fini(zilog);\n\n\treturn (error);\n}\n\nstatic int\nzil_clear_log_block(zilog_t *zilog, const blkptr_t *bp, void *tx,\n    uint64_t first_txg)\n{\n\t(void) tx;\n\tASSERT(!BP_IS_HOLE(bp));\n\n\t \n\tif (bp->blk_birth >= first_txg)\n\t\treturn (-1);\n\n\tif (zil_bp_tree_add(zilog, bp) != 0)\n\t\treturn (0);\n\n\tzio_free(zilog->zl_spa, first_txg, bp);\n\treturn (0);\n}\n\nstatic int\nzil_noop_log_record(zilog_t *zilog, const lr_t *lrc, void *tx,\n    uint64_t first_txg)\n{\n\t(void) zilog, (void) lrc, (void) tx, (void) first_txg;\n\treturn (0);\n}\n\nstatic int\nzil_claim_log_block(zilog_t *zilog, const blkptr_t *bp, void *tx,\n    uint64_t first_txg)\n{\n\t \n\tif (BP_IS_HOLE(bp) || bp->blk_birth < first_txg ||\n\t    zil_bp_tree_add(zilog, bp) != 0)\n\t\treturn (0);\n\n\treturn (zio_wait(zio_claim(NULL, zilog->zl_spa,\n\t    tx == NULL ? 0 : first_txg, bp, spa_claim_notify, NULL,\n\t    ZIO_FLAG_CANFAIL | ZIO_FLAG_SPECULATIVE | ZIO_FLAG_SCRUB)));\n}\n\nstatic int\nzil_claim_write(zilog_t *zilog, const lr_t *lrc, void *tx, uint64_t first_txg)\n{\n\tlr_write_t *lr = (lr_write_t *)lrc;\n\tint error;\n\n\tASSERT(lrc->lrc_txtype == TX_WRITE);\n\n\t \n\tif (lr->lr_blkptr.blk_birth >= first_txg) {\n\t\terror = zil_read_log_data(zilog, lr, NULL);\n\t\tif (error != 0)\n\t\t\treturn (error);\n\t}\n\n\treturn (zil_claim_log_block(zilog, &lr->lr_blkptr, tx, first_txg));\n}\n\nstatic int\nzil_claim_clone_range(zilog_t *zilog, const lr_t *lrc, void *tx)\n{\n\tconst lr_clone_range_t *lr = (const lr_clone_range_t *)lrc;\n\tconst blkptr_t *bp;\n\tspa_t *spa;\n\tuint_t ii;\n\n\tASSERT(lrc->lrc_txtype == TX_CLONE_RANGE);\n\n\tif (tx == NULL) {\n\t\treturn (0);\n\t}\n\n\t \n\n\tspa = zilog->zl_spa;\n\n\tfor (ii = 0; ii < lr->lr_nbps; ii++) {\n\t\tbp = &lr->lr_bps[ii];\n\n\t\t \n\t\tif (!BP_IS_HOLE(bp) && !BP_IS_EMBEDDED(bp)) {\n\t\t\tbrt_pending_add(spa, bp, tx);\n\t\t}\n\t}\n\n\treturn (0);\n}\n\nstatic int\nzil_claim_log_record(zilog_t *zilog, const lr_t *lrc, void *tx,\n    uint64_t first_txg)\n{\n\n\tswitch (lrc->lrc_txtype) {\n\tcase TX_WRITE:\n\t\treturn (zil_claim_write(zilog, lrc, tx, first_txg));\n\tcase TX_CLONE_RANGE:\n\t\treturn (zil_claim_clone_range(zilog, lrc, tx));\n\tdefault:\n\t\treturn (0);\n\t}\n}\n\nstatic int\nzil_free_log_block(zilog_t *zilog, const blkptr_t *bp, void *tx,\n    uint64_t claim_txg)\n{\n\t(void) claim_txg;\n\n\tzio_free(zilog->zl_spa, dmu_tx_get_txg(tx), bp);\n\n\treturn (0);\n}\n\nstatic int\nzil_free_write(zilog_t *zilog, const lr_t *lrc, void *tx, uint64_t claim_txg)\n{\n\tlr_write_t *lr = (lr_write_t *)lrc;\n\tblkptr_t *bp = &lr->lr_blkptr;\n\n\tASSERT(lrc->lrc_txtype == TX_WRITE);\n\n\t \n\tif (bp->blk_birth >= claim_txg && zil_bp_tree_add(zilog, bp) == 0 &&\n\t    !BP_IS_HOLE(bp)) {\n\t\tzio_free(zilog->zl_spa, dmu_tx_get_txg(tx), bp);\n\t}\n\n\treturn (0);\n}\n\nstatic int\nzil_free_clone_range(zilog_t *zilog, const lr_t *lrc, void *tx)\n{\n\tconst lr_clone_range_t *lr = (const lr_clone_range_t *)lrc;\n\tconst blkptr_t *bp;\n\tspa_t *spa;\n\tuint_t ii;\n\n\tASSERT(lrc->lrc_txtype == TX_CLONE_RANGE);\n\n\tif (tx == NULL) {\n\t\treturn (0);\n\t}\n\n\tspa = zilog->zl_spa;\n\n\tfor (ii = 0; ii < lr->lr_nbps; ii++) {\n\t\tbp = &lr->lr_bps[ii];\n\n\t\tif (!BP_IS_HOLE(bp)) {\n\t\t\tzio_free(spa, dmu_tx_get_txg(tx), bp);\n\t\t}\n\t}\n\n\treturn (0);\n}\n\nstatic int\nzil_free_log_record(zilog_t *zilog, const lr_t *lrc, void *tx,\n    uint64_t claim_txg)\n{\n\n\tif (claim_txg == 0) {\n\t\treturn (0);\n\t}\n\n\tswitch (lrc->lrc_txtype) {\n\tcase TX_WRITE:\n\t\treturn (zil_free_write(zilog, lrc, tx, claim_txg));\n\tcase TX_CLONE_RANGE:\n\t\treturn (zil_free_clone_range(zilog, lrc, tx));\n\tdefault:\n\t\treturn (0);\n\t}\n}\n\nstatic int\nzil_lwb_vdev_compare(const void *x1, const void *x2)\n{\n\tconst uint64_t v1 = ((zil_vdev_node_t *)x1)->zv_vdev;\n\tconst uint64_t v2 = ((zil_vdev_node_t *)x2)->zv_vdev;\n\n\treturn (TREE_CMP(v1, v2));\n}\n\n \nstatic lwb_t *\nzil_alloc_lwb(zilog_t *zilog, int sz, blkptr_t *bp, boolean_t slog,\n    uint64_t txg, lwb_state_t state)\n{\n\tlwb_t *lwb;\n\n\tlwb = kmem_cache_alloc(zil_lwb_cache, KM_SLEEP);\n\tlwb->lwb_zilog = zilog;\n\tif (bp) {\n\t\tlwb->lwb_blk = *bp;\n\t\tlwb->lwb_slim = (BP_GET_CHECKSUM(bp) == ZIO_CHECKSUM_ZILOG2);\n\t\tsz = BP_GET_LSIZE(bp);\n\t} else {\n\t\tBP_ZERO(&lwb->lwb_blk);\n\t\tlwb->lwb_slim = (spa_version(zilog->zl_spa) >=\n\t\t    SPA_VERSION_SLIM_ZIL);\n\t}\n\tlwb->lwb_slog = slog;\n\tlwb->lwb_error = 0;\n\tif (lwb->lwb_slim) {\n\t\tlwb->lwb_nmax = sz;\n\t\tlwb->lwb_nused = lwb->lwb_nfilled = sizeof (zil_chain_t);\n\t} else {\n\t\tlwb->lwb_nmax = sz - sizeof (zil_chain_t);\n\t\tlwb->lwb_nused = lwb->lwb_nfilled = 0;\n\t}\n\tlwb->lwb_sz = sz;\n\tlwb->lwb_state = state;\n\tlwb->lwb_buf = zio_buf_alloc(sz);\n\tlwb->lwb_child_zio = NULL;\n\tlwb->lwb_write_zio = NULL;\n\tlwb->lwb_root_zio = NULL;\n\tlwb->lwb_issued_timestamp = 0;\n\tlwb->lwb_issued_txg = 0;\n\tlwb->lwb_alloc_txg = txg;\n\tlwb->lwb_max_txg = 0;\n\n\tmutex_enter(&zilog->zl_lock);\n\tlist_insert_tail(&zilog->zl_lwb_list, lwb);\n\tif (state != LWB_STATE_NEW)\n\t\tzilog->zl_last_lwb_opened = lwb;\n\tmutex_exit(&zilog->zl_lock);\n\n\treturn (lwb);\n}\n\nstatic void\nzil_free_lwb(zilog_t *zilog, lwb_t *lwb)\n{\n\tASSERT(MUTEX_HELD(&zilog->zl_lock));\n\tASSERT(lwb->lwb_state == LWB_STATE_NEW ||\n\t    lwb->lwb_state == LWB_STATE_FLUSH_DONE);\n\tASSERT3P(lwb->lwb_child_zio, ==, NULL);\n\tASSERT3P(lwb->lwb_write_zio, ==, NULL);\n\tASSERT3P(lwb->lwb_root_zio, ==, NULL);\n\tASSERT3U(lwb->lwb_alloc_txg, <=, spa_syncing_txg(zilog->zl_spa));\n\tASSERT3U(lwb->lwb_max_txg, <=, spa_syncing_txg(zilog->zl_spa));\n\tVERIFY(list_is_empty(&lwb->lwb_itxs));\n\tVERIFY(list_is_empty(&lwb->lwb_waiters));\n\tASSERT(avl_is_empty(&lwb->lwb_vdev_tree));\n\tASSERT(!MUTEX_HELD(&lwb->lwb_vdev_lock));\n\n\t \n\tif (zilog->zl_last_lwb_opened == lwb)\n\t\tzilog->zl_last_lwb_opened = NULL;\n\n\tkmem_cache_free(zil_lwb_cache, lwb);\n}\n\n \nstatic void\nzilog_dirty(zilog_t *zilog, uint64_t txg)\n{\n\tdsl_pool_t *dp = zilog->zl_dmu_pool;\n\tdsl_dataset_t *ds = dmu_objset_ds(zilog->zl_os);\n\n\tASSERT(spa_writeable(zilog->zl_spa));\n\n\tif (ds->ds_is_snapshot)\n\t\tpanic(\"dirtying snapshot!\");\n\n\tif (txg_list_add(&dp->dp_dirty_zilogs, zilog, txg)) {\n\t\t \n\t\tdmu_buf_add_ref(ds->ds_dbuf, zilog);\n\n\t\tzilog->zl_dirty_max_txg = MAX(txg, zilog->zl_dirty_max_txg);\n\t}\n}\n\n \nstatic boolean_t __maybe_unused\nzilog_is_dirty_in_txg(zilog_t *zilog, uint64_t txg)\n{\n\tdsl_pool_t *dp = zilog->zl_dmu_pool;\n\n\tif (txg_list_member(&dp->dp_dirty_zilogs, zilog, txg & TXG_MASK))\n\t\treturn (B_TRUE);\n\treturn (B_FALSE);\n}\n\n \nstatic boolean_t\nzilog_is_dirty(zilog_t *zilog)\n{\n\tdsl_pool_t *dp = zilog->zl_dmu_pool;\n\n\tfor (int t = 0; t < TXG_SIZE; t++) {\n\t\tif (txg_list_member(&dp->dp_dirty_zilogs, zilog, t))\n\t\t\treturn (B_TRUE);\n\t}\n\treturn (B_FALSE);\n}\n\n \nstatic void\nzil_commit_activate_saxattr_feature(zilog_t *zilog)\n{\n\tdsl_dataset_t *ds = dmu_objset_ds(zilog->zl_os);\n\tuint64_t txg = 0;\n\tdmu_tx_t *tx = NULL;\n\n\tif (spa_feature_is_enabled(zilog->zl_spa, SPA_FEATURE_ZILSAXATTR) &&\n\t    dmu_objset_type(zilog->zl_os) != DMU_OST_ZVOL &&\n\t    !dsl_dataset_feature_is_active(ds, SPA_FEATURE_ZILSAXATTR)) {\n\t\ttx = dmu_tx_create(zilog->zl_os);\n\t\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT));\n\t\tdsl_dataset_dirty(ds, tx);\n\t\ttxg = dmu_tx_get_txg(tx);\n\n\t\tmutex_enter(&ds->ds_lock);\n\t\tds->ds_feature_activation[SPA_FEATURE_ZILSAXATTR] =\n\t\t    (void *)B_TRUE;\n\t\tmutex_exit(&ds->ds_lock);\n\t\tdmu_tx_commit(tx);\n\t\ttxg_wait_synced(zilog->zl_dmu_pool, txg);\n\t}\n}\n\n \nstatic lwb_t *\nzil_create(zilog_t *zilog)\n{\n\tconst zil_header_t *zh = zilog->zl_header;\n\tlwb_t *lwb = NULL;\n\tuint64_t txg = 0;\n\tdmu_tx_t *tx = NULL;\n\tblkptr_t blk;\n\tint error = 0;\n\tboolean_t slog = FALSE;\n\tdsl_dataset_t *ds = dmu_objset_ds(zilog->zl_os);\n\n\n\t \n\ttxg_wait_synced(zilog->zl_dmu_pool, zilog->zl_destroy_txg);\n\n\tASSERT(zh->zh_claim_txg == 0);\n\tASSERT(zh->zh_replay_seq == 0);\n\n\tblk = zh->zh_log;\n\n\t \n\tif (BP_IS_HOLE(&blk) || BP_SHOULD_BYTESWAP(&blk)) {\n\t\ttx = dmu_tx_create(zilog->zl_os);\n\t\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT));\n\t\tdsl_dataset_dirty(dmu_objset_ds(zilog->zl_os), tx);\n\t\ttxg = dmu_tx_get_txg(tx);\n\n\t\tif (!BP_IS_HOLE(&blk)) {\n\t\t\tzio_free(zilog->zl_spa, txg, &blk);\n\t\t\tBP_ZERO(&blk);\n\t\t}\n\n\t\terror = zio_alloc_zil(zilog->zl_spa, zilog->zl_os, txg, &blk,\n\t\t    ZIL_MIN_BLKSZ, &slog);\n\t\tif (error == 0)\n\t\t\tzil_init_log_chain(zilog, &blk);\n\t}\n\n\t \n\tif (error == 0)\n\t\tlwb = zil_alloc_lwb(zilog, 0, &blk, slog, txg, LWB_STATE_NEW);\n\n\t \n\tif (tx != NULL) {\n\t\t \n\t\tif (spa_feature_is_enabled(zilog->zl_spa,\n\t\t    SPA_FEATURE_ZILSAXATTR) && dmu_objset_type(zilog->zl_os) !=\n\t\t    DMU_OST_ZVOL) {\n\t\t\tmutex_enter(&ds->ds_lock);\n\t\t\tds->ds_feature_activation[SPA_FEATURE_ZILSAXATTR] =\n\t\t\t    (void *)B_TRUE;\n\t\t\tmutex_exit(&ds->ds_lock);\n\t\t}\n\n\t\tdmu_tx_commit(tx);\n\t\ttxg_wait_synced(zilog->zl_dmu_pool, txg);\n\t} else {\n\t\t \n\t\tzil_commit_activate_saxattr_feature(zilog);\n\t}\n\tIMPLY(spa_feature_is_enabled(zilog->zl_spa, SPA_FEATURE_ZILSAXATTR) &&\n\t    dmu_objset_type(zilog->zl_os) != DMU_OST_ZVOL,\n\t    dsl_dataset_feature_is_active(ds, SPA_FEATURE_ZILSAXATTR));\n\n\tASSERT(error != 0 || memcmp(&blk, &zh->zh_log, sizeof (blk)) == 0);\n\tIMPLY(error == 0, lwb != NULL);\n\n\treturn (lwb);\n}\n\n \nboolean_t\nzil_destroy(zilog_t *zilog, boolean_t keep_first)\n{\n\tconst zil_header_t *zh = zilog->zl_header;\n\tlwb_t *lwb;\n\tdmu_tx_t *tx;\n\tuint64_t txg;\n\n\t \n\ttxg_wait_synced(zilog->zl_dmu_pool, zilog->zl_destroy_txg);\n\n\tzilog->zl_old_header = *zh;\t\t \n\n\tif (BP_IS_HOLE(&zh->zh_log))\n\t\treturn (B_FALSE);\n\n\ttx = dmu_tx_create(zilog->zl_os);\n\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT));\n\tdsl_dataset_dirty(dmu_objset_ds(zilog->zl_os), tx);\n\ttxg = dmu_tx_get_txg(tx);\n\n\tmutex_enter(&zilog->zl_lock);\n\n\tASSERT3U(zilog->zl_destroy_txg, <, txg);\n\tzilog->zl_destroy_txg = txg;\n\tzilog->zl_keep_first = keep_first;\n\n\tif (!list_is_empty(&zilog->zl_lwb_list)) {\n\t\tASSERT(zh->zh_claim_txg == 0);\n\t\tVERIFY(!keep_first);\n\t\twhile ((lwb = list_remove_head(&zilog->zl_lwb_list)) != NULL) {\n\t\t\tif (lwb->lwb_buf != NULL)\n\t\t\t\tzio_buf_free(lwb->lwb_buf, lwb->lwb_sz);\n\t\t\tif (!BP_IS_HOLE(&lwb->lwb_blk))\n\t\t\t\tzio_free(zilog->zl_spa, txg, &lwb->lwb_blk);\n\t\t\tzil_free_lwb(zilog, lwb);\n\t\t}\n\t} else if (!keep_first) {\n\t\tzil_destroy_sync(zilog, tx);\n\t}\n\tmutex_exit(&zilog->zl_lock);\n\n\tdmu_tx_commit(tx);\n\n\treturn (B_TRUE);\n}\n\nvoid\nzil_destroy_sync(zilog_t *zilog, dmu_tx_t *tx)\n{\n\tASSERT(list_is_empty(&zilog->zl_lwb_list));\n\t(void) zil_parse(zilog, zil_free_log_block,\n\t    zil_free_log_record, tx, zilog->zl_header->zh_claim_txg, B_FALSE);\n}\n\nint\nzil_claim(dsl_pool_t *dp, dsl_dataset_t *ds, void *txarg)\n{\n\tdmu_tx_t *tx = txarg;\n\tzilog_t *zilog;\n\tuint64_t first_txg;\n\tzil_header_t *zh;\n\tobjset_t *os;\n\tint error;\n\n\terror = dmu_objset_own_obj(dp, ds->ds_object,\n\t    DMU_OST_ANY, B_FALSE, B_FALSE, FTAG, &os);\n\tif (error != 0) {\n\t\t \n\t\tif (error != EBUSY) {\n\t\t\tcmn_err(CE_WARN, \"can't open objset for %llu, error %u\",\n\t\t\t    (unsigned long long)ds->ds_object, error);\n\t\t}\n\n\t\treturn (0);\n\t}\n\n\tzilog = dmu_objset_zil(os);\n\tzh = zil_header_in_syncing_context(zilog);\n\tASSERT3U(tx->tx_txg, ==, spa_first_txg(zilog->zl_spa));\n\tfirst_txg = spa_min_claim_txg(zilog->zl_spa);\n\n\t \n\tif (spa_get_log_state(zilog->zl_spa) == SPA_LOG_CLEAR ||\n\t    (zilog->zl_spa->spa_uberblock.ub_checkpoint_txg != 0 &&\n\t    zh->zh_claim_txg == 0)) {\n\t\tif (!BP_IS_HOLE(&zh->zh_log)) {\n\t\t\t(void) zil_parse(zilog, zil_clear_log_block,\n\t\t\t    zil_noop_log_record, tx, first_txg, B_FALSE);\n\t\t}\n\t\tBP_ZERO(&zh->zh_log);\n\t\tif (os->os_encrypted)\n\t\t\tos->os_next_write_raw[tx->tx_txg & TXG_MASK] = B_TRUE;\n\t\tdsl_dataset_dirty(dmu_objset_ds(os), tx);\n\t\tdmu_objset_disown(os, B_FALSE, FTAG);\n\t\treturn (0);\n\t}\n\n\t \n\tASSERT3U(first_txg, ==, spa_first_txg(zilog->zl_spa));\n\n\t \n\tASSERT3U(zh->zh_claim_txg, <=, first_txg);\n\tif (zh->zh_claim_txg == 0 && !BP_IS_HOLE(&zh->zh_log)) {\n\t\t(void) zil_parse(zilog, zil_claim_log_block,\n\t\t    zil_claim_log_record, tx, first_txg, B_FALSE);\n\t\tzh->zh_claim_txg = first_txg;\n\t\tzh->zh_claim_blk_seq = zilog->zl_parse_blk_seq;\n\t\tzh->zh_claim_lr_seq = zilog->zl_parse_lr_seq;\n\t\tif (zilog->zl_parse_lr_count || zilog->zl_parse_blk_count > 1)\n\t\t\tzh->zh_flags |= ZIL_REPLAY_NEEDED;\n\t\tzh->zh_flags |= ZIL_CLAIM_LR_SEQ_VALID;\n\t\tif (os->os_encrypted)\n\t\t\tos->os_next_write_raw[tx->tx_txg & TXG_MASK] = B_TRUE;\n\t\tdsl_dataset_dirty(dmu_objset_ds(os), tx);\n\t}\n\n\tASSERT3U(first_txg, ==, (spa_last_synced_txg(zilog->zl_spa) + 1));\n\tdmu_objset_disown(os, B_FALSE, FTAG);\n\treturn (0);\n}\n\n \nint\nzil_check_log_chain(dsl_pool_t *dp, dsl_dataset_t *ds, void *tx)\n{\n\t(void) dp;\n\tzilog_t *zilog;\n\tobjset_t *os;\n\tblkptr_t *bp;\n\tint error;\n\n\tASSERT(tx == NULL);\n\n\terror = dmu_objset_from_ds(ds, &os);\n\tif (error != 0) {\n\t\tcmn_err(CE_WARN, \"can't open objset %llu, error %d\",\n\t\t    (unsigned long long)ds->ds_object, error);\n\t\treturn (0);\n\t}\n\n\tzilog = dmu_objset_zil(os);\n\tbp = (blkptr_t *)&zilog->zl_header->zh_log;\n\n\tif (!BP_IS_HOLE(bp)) {\n\t\tvdev_t *vd;\n\t\tboolean_t valid = B_TRUE;\n\n\t\t \n\t\tspa_config_enter(os->os_spa, SCL_STATE, FTAG, RW_READER);\n\t\tvd = vdev_lookup_top(os->os_spa, DVA_GET_VDEV(&bp->blk_dva[0]));\n\t\tif (vd->vdev_islog && vdev_is_dead(vd))\n\t\t\tvalid = vdev_log_state_valid(vd);\n\t\tspa_config_exit(os->os_spa, SCL_STATE, FTAG);\n\n\t\tif (!valid)\n\t\t\treturn (0);\n\n\t\t \n\t\tzil_header_t *zh = zil_header_in_syncing_context(zilog);\n\t\tif (zilog->zl_spa->spa_uberblock.ub_checkpoint_txg != 0 &&\n\t\t    zh->zh_claim_txg == 0)\n\t\t\treturn (0);\n\t}\n\n\t \n\terror = zil_parse(zilog, zil_claim_log_block, zil_claim_log_record, tx,\n\t    zilog->zl_header->zh_claim_txg ? -1ULL :\n\t    spa_min_claim_txg(os->os_spa), B_FALSE);\n\n\treturn ((error == ECKSUM || error == ENOENT) ? 0 : error);\n}\n\n \nstatic void\nzil_commit_waiter_skip(zil_commit_waiter_t *zcw)\n{\n\tmutex_enter(&zcw->zcw_lock);\n\tASSERT3B(zcw->zcw_done, ==, B_FALSE);\n\tzcw->zcw_done = B_TRUE;\n\tcv_broadcast(&zcw->zcw_cv);\n\tmutex_exit(&zcw->zcw_lock);\n}\n\n \nstatic void\nzil_commit_waiter_link_lwb(zil_commit_waiter_t *zcw, lwb_t *lwb)\n{\n\t \n\tASSERT(MUTEX_HELD(&lwb->lwb_zilog->zl_issuer_lock));\n\tIMPLY(lwb->lwb_state != LWB_STATE_OPENED,\n\t    MUTEX_HELD(&lwb->lwb_zilog->zl_lock));\n\tASSERT3S(lwb->lwb_state, !=, LWB_STATE_NEW);\n\tASSERT3S(lwb->lwb_state, !=, LWB_STATE_FLUSH_DONE);\n\n\tASSERT(!list_link_active(&zcw->zcw_node));\n\tlist_insert_tail(&lwb->lwb_waiters, zcw);\n\tASSERT3P(zcw->zcw_lwb, ==, NULL);\n\tzcw->zcw_lwb = lwb;\n}\n\n \nstatic void\nzil_commit_waiter_link_nolwb(zil_commit_waiter_t *zcw, list_t *nolwb)\n{\n\tASSERT(!list_link_active(&zcw->zcw_node));\n\tlist_insert_tail(nolwb, zcw);\n\tASSERT3P(zcw->zcw_lwb, ==, NULL);\n}\n\nvoid\nzil_lwb_add_block(lwb_t *lwb, const blkptr_t *bp)\n{\n\tavl_tree_t *t = &lwb->lwb_vdev_tree;\n\tavl_index_t where;\n\tzil_vdev_node_t *zv, zvsearch;\n\tint ndvas = BP_GET_NDVAS(bp);\n\tint i;\n\n\tASSERT3S(lwb->lwb_state, !=, LWB_STATE_WRITE_DONE);\n\tASSERT3S(lwb->lwb_state, !=, LWB_STATE_FLUSH_DONE);\n\n\tif (zil_nocacheflush)\n\t\treturn;\n\n\tmutex_enter(&lwb->lwb_vdev_lock);\n\tfor (i = 0; i < ndvas; i++) {\n\t\tzvsearch.zv_vdev = DVA_GET_VDEV(&bp->blk_dva[i]);\n\t\tif (avl_find(t, &zvsearch, &where) == NULL) {\n\t\t\tzv = kmem_alloc(sizeof (*zv), KM_SLEEP);\n\t\t\tzv->zv_vdev = zvsearch.zv_vdev;\n\t\t\tavl_insert(t, zv, where);\n\t\t}\n\t}\n\tmutex_exit(&lwb->lwb_vdev_lock);\n}\n\nstatic void\nzil_lwb_flush_defer(lwb_t *lwb, lwb_t *nlwb)\n{\n\tavl_tree_t *src = &lwb->lwb_vdev_tree;\n\tavl_tree_t *dst = &nlwb->lwb_vdev_tree;\n\tvoid *cookie = NULL;\n\tzil_vdev_node_t *zv;\n\n\tASSERT3S(lwb->lwb_state, ==, LWB_STATE_WRITE_DONE);\n\tASSERT3S(nlwb->lwb_state, !=, LWB_STATE_WRITE_DONE);\n\tASSERT3S(nlwb->lwb_state, !=, LWB_STATE_FLUSH_DONE);\n\n\t \n\tmutex_enter(&nlwb->lwb_vdev_lock);\n\t \n\twhile ((zv = avl_destroy_nodes(src, &cookie)) != NULL) {\n\t\tavl_index_t where;\n\n\t\tif (avl_find(dst, zv, &where) == NULL) {\n\t\t\tavl_insert(dst, zv, where);\n\t\t} else {\n\t\t\tkmem_free(zv, sizeof (*zv));\n\t\t}\n\t}\n\tmutex_exit(&nlwb->lwb_vdev_lock);\n}\n\nvoid\nzil_lwb_add_txg(lwb_t *lwb, uint64_t txg)\n{\n\tlwb->lwb_max_txg = MAX(lwb->lwb_max_txg, txg);\n}\n\n \nstatic void\nzil_lwb_flush_vdevs_done(zio_t *zio)\n{\n\tlwb_t *lwb = zio->io_private;\n\tzilog_t *zilog = lwb->lwb_zilog;\n\tzil_commit_waiter_t *zcw;\n\titx_t *itx;\n\n\tspa_config_exit(zilog->zl_spa, SCL_STATE, lwb);\n\n\thrtime_t t = gethrtime() - lwb->lwb_issued_timestamp;\n\n\tmutex_enter(&zilog->zl_lock);\n\n\tzilog->zl_last_lwb_latency = (zilog->zl_last_lwb_latency * 7 + t) / 8;\n\n\tlwb->lwb_root_zio = NULL;\n\n\tASSERT3S(lwb->lwb_state, ==, LWB_STATE_WRITE_DONE);\n\tlwb->lwb_state = LWB_STATE_FLUSH_DONE;\n\n\tif (zilog->zl_last_lwb_opened == lwb) {\n\t\t \n\t\tzilog->zl_commit_lr_seq = zilog->zl_lr_seq;\n\t}\n\n\twhile ((itx = list_remove_head(&lwb->lwb_itxs)) != NULL)\n\t\tzil_itx_destroy(itx);\n\n\twhile ((zcw = list_remove_head(&lwb->lwb_waiters)) != NULL) {\n\t\tmutex_enter(&zcw->zcw_lock);\n\n\t\tASSERT3P(zcw->zcw_lwb, ==, lwb);\n\t\tzcw->zcw_lwb = NULL;\n\t\t \n\n\t\tzcw->zcw_zio_error = zio->io_error;\n\n\t\tASSERT3B(zcw->zcw_done, ==, B_FALSE);\n\t\tzcw->zcw_done = B_TRUE;\n\t\tcv_broadcast(&zcw->zcw_cv);\n\n\t\tmutex_exit(&zcw->zcw_lock);\n\t}\n\n\tuint64_t txg = lwb->lwb_issued_txg;\n\n\t \n\tmutex_exit(&zilog->zl_lock);\n\n\tmutex_enter(&zilog->zl_lwb_io_lock);\n\tASSERT3U(zilog->zl_lwb_inflight[txg & TXG_MASK], >, 0);\n\tzilog->zl_lwb_inflight[txg & TXG_MASK]--;\n\tif (zilog->zl_lwb_inflight[txg & TXG_MASK] == 0)\n\t\tcv_broadcast(&zilog->zl_lwb_io_cv);\n\tmutex_exit(&zilog->zl_lwb_io_lock);\n}\n\n \nstatic void\nzil_lwb_flush_wait_all(zilog_t *zilog, uint64_t txg)\n{\n\tASSERT3U(txg, ==, spa_syncing_txg(zilog->zl_spa));\n\n\tmutex_enter(&zilog->zl_lwb_io_lock);\n\twhile (zilog->zl_lwb_inflight[txg & TXG_MASK] > 0)\n\t\tcv_wait(&zilog->zl_lwb_io_cv, &zilog->zl_lwb_io_lock);\n\tmutex_exit(&zilog->zl_lwb_io_lock);\n\n#ifdef ZFS_DEBUG\n\tmutex_enter(&zilog->zl_lock);\n\tmutex_enter(&zilog->zl_lwb_io_lock);\n\tlwb_t *lwb = list_head(&zilog->zl_lwb_list);\n\twhile (lwb != NULL) {\n\t\tif (lwb->lwb_issued_txg <= txg) {\n\t\t\tASSERT(lwb->lwb_state != LWB_STATE_ISSUED);\n\t\t\tASSERT(lwb->lwb_state != LWB_STATE_WRITE_DONE);\n\t\t\tIMPLY(lwb->lwb_issued_txg > 0,\n\t\t\t    lwb->lwb_state == LWB_STATE_FLUSH_DONE);\n\t\t}\n\t\tIMPLY(lwb->lwb_state == LWB_STATE_WRITE_DONE ||\n\t\t    lwb->lwb_state == LWB_STATE_FLUSH_DONE,\n\t\t    lwb->lwb_buf == NULL);\n\t\tlwb = list_next(&zilog->zl_lwb_list, lwb);\n\t}\n\tmutex_exit(&zilog->zl_lwb_io_lock);\n\tmutex_exit(&zilog->zl_lock);\n#endif\n}\n\n \nstatic void\nzil_lwb_write_done(zio_t *zio)\n{\n\tlwb_t *lwb = zio->io_private;\n\tspa_t *spa = zio->io_spa;\n\tzilog_t *zilog = lwb->lwb_zilog;\n\tavl_tree_t *t = &lwb->lwb_vdev_tree;\n\tvoid *cookie = NULL;\n\tzil_vdev_node_t *zv;\n\tlwb_t *nlwb;\n\n\tASSERT3S(spa_config_held(spa, SCL_STATE, RW_READER), !=, 0);\n\n\tabd_free(zio->io_abd);\n\tzio_buf_free(lwb->lwb_buf, lwb->lwb_sz);\n\tlwb->lwb_buf = NULL;\n\n\tmutex_enter(&zilog->zl_lock);\n\tASSERT3S(lwb->lwb_state, ==, LWB_STATE_ISSUED);\n\tlwb->lwb_state = LWB_STATE_WRITE_DONE;\n\tlwb->lwb_child_zio = NULL;\n\tlwb->lwb_write_zio = NULL;\n\n\t \n\tnlwb = list_next(&zilog->zl_lwb_list, lwb);\n\tif (nlwb && nlwb->lwb_state != LWB_STATE_ISSUED)\n\t\tnlwb = NULL;\n\tmutex_exit(&zilog->zl_lock);\n\n\tif (avl_numnodes(t) == 0)\n\t\treturn;\n\n\t \n\tif (zio->io_error != 0) {\n\t\twhile ((zv = avl_destroy_nodes(t, &cookie)) != NULL)\n\t\t\tkmem_free(zv, sizeof (*zv));\n\t\treturn;\n\t}\n\n\t \n\tif (list_is_empty(&lwb->lwb_waiters) && nlwb != NULL) {\n\t\tzil_lwb_flush_defer(lwb, nlwb);\n\t\tASSERT(avl_is_empty(&lwb->lwb_vdev_tree));\n\t\treturn;\n\t}\n\n\twhile ((zv = avl_destroy_nodes(t, &cookie)) != NULL) {\n\t\tvdev_t *vd = vdev_lookup_top(spa, zv->zv_vdev);\n\t\tif (vd != NULL && !vd->vdev_nowritecache) {\n\t\t\t \n\t\t\tzio_flush(lwb->lwb_root_zio, vd);\n\t\t}\n\t\tkmem_free(zv, sizeof (*zv));\n\t}\n}\n\n \nstatic void\nzil_lwb_set_zio_dependency(zilog_t *zilog, lwb_t *lwb)\n{\n\tASSERT(MUTEX_HELD(&zilog->zl_lock));\n\n\tlwb_t *prev_lwb = list_prev(&zilog->zl_lwb_list, lwb);\n\tif (prev_lwb == NULL ||\n\t    prev_lwb->lwb_state == LWB_STATE_FLUSH_DONE)\n\t\treturn;\n\n\t \n\tif (prev_lwb->lwb_state == LWB_STATE_ISSUED) {\n\t\tASSERT3P(prev_lwb->lwb_write_zio, !=, NULL);\n\t\tzio_add_child(lwb->lwb_write_zio, prev_lwb->lwb_write_zio);\n\t} else {\n\t\tASSERT3S(prev_lwb->lwb_state, ==, LWB_STATE_WRITE_DONE);\n\t}\n\n\tASSERT3P(prev_lwb->lwb_root_zio, !=, NULL);\n\tzio_add_child(lwb->lwb_root_zio, prev_lwb->lwb_root_zio);\n}\n\n\n \nstatic void\nzil_lwb_write_open(zilog_t *zilog, lwb_t *lwb)\n{\n\tASSERT(MUTEX_HELD(&zilog->zl_issuer_lock));\n\n\tif (lwb->lwb_state != LWB_STATE_NEW) {\n\t\tASSERT3S(lwb->lwb_state, ==, LWB_STATE_OPENED);\n\t\treturn;\n\t}\n\n\tmutex_enter(&zilog->zl_lock);\n\tlwb->lwb_state = LWB_STATE_OPENED;\n\tzilog->zl_last_lwb_opened = lwb;\n\tmutex_exit(&zilog->zl_lock);\n}\n\n \nstatic const struct {\n\tuint64_t\tlimit;\n\tuint64_t\tblksz;\n} zil_block_buckets[] = {\n\t{ 4096,\t\t4096 },\t\t\t \n\t{ 8192 + 4096,\t8192 + 4096 },\t\t \n\t{ 32768 + 4096,\t32768 + 4096 },\t\t \n\t{ 65536 + 4096,\t65536 + 4096 },\t\t \n\t{ 131072,\t131072 },\t\t \n\t{ 131072 +4096,\t65536 + 4096 },\t\t \n\t{ UINT64_MAX,\tSPA_OLD_MAXBLOCKSIZE},\t \n};\n\n \nstatic uint_t zil_maxblocksize = SPA_OLD_MAXBLOCKSIZE;\n\n \nstatic lwb_t *\nzil_lwb_write_close(zilog_t *zilog, lwb_t *lwb, lwb_state_t state)\n{\n\tint i;\n\n\tASSERT(MUTEX_HELD(&zilog->zl_issuer_lock));\n\tASSERT3S(lwb->lwb_state, ==, LWB_STATE_OPENED);\n\tlwb->lwb_state = LWB_STATE_CLOSED;\n\n\t \n\tif (lwb->lwb_error != 0)\n\t\treturn (NULL);\n\n\t \n\tuint64_t zil_blksz = zilog->zl_cur_used + sizeof (zil_chain_t);\n\tfor (i = 0; zil_blksz > zil_block_buckets[i].limit; i++)\n\t\tcontinue;\n\tzil_blksz = MIN(zil_block_buckets[i].blksz, zilog->zl_max_block_size);\n\tzilog->zl_prev_blks[zilog->zl_prev_rotor] = zil_blksz;\n\tfor (i = 0; i < ZIL_PREV_BLKS; i++)\n\t\tzil_blksz = MAX(zil_blksz, zilog->zl_prev_blks[i]);\n\tDTRACE_PROBE3(zil__block__size, zilog_t *, zilog,\n\t    uint64_t, zil_blksz,\n\t    uint64_t, zilog->zl_prev_blks[zilog->zl_prev_rotor]);\n\tzilog->zl_prev_rotor = (zilog->zl_prev_rotor + 1) & (ZIL_PREV_BLKS - 1);\n\n\treturn (zil_alloc_lwb(zilog, zil_blksz, NULL, 0, 0, state));\n}\n\n \nstatic void\nzil_lwb_write_issue(zilog_t *zilog, lwb_t *lwb)\n{\n\tspa_t *spa = zilog->zl_spa;\n\tzil_chain_t *zilc;\n\tboolean_t slog;\n\tzbookmark_phys_t zb;\n\tzio_priority_t prio;\n\tint error;\n\n\tASSERT3S(lwb->lwb_state, ==, LWB_STATE_CLOSED);\n\n\t \n\tfor (itx_t *itx = list_head(&lwb->lwb_itxs); itx;\n\t    itx = list_next(&lwb->lwb_itxs, itx))\n\t\tzil_lwb_commit(zilog, lwb, itx);\n\tlwb->lwb_nused = lwb->lwb_nfilled;\n\n\tlwb->lwb_root_zio = zio_root(spa, zil_lwb_flush_vdevs_done, lwb,\n\t    ZIO_FLAG_CANFAIL);\n\n\t \n\tmutex_enter(&zilog->zl_lock);\n\tlwb->lwb_state = LWB_STATE_READY;\n\tif (BP_IS_HOLE(&lwb->lwb_blk) && lwb->lwb_error == 0) {\n\t\tmutex_exit(&zilog->zl_lock);\n\t\treturn;\n\t}\n\tmutex_exit(&zilog->zl_lock);\n\nnext_lwb:\n\tif (lwb->lwb_slim)\n\t\tzilc = (zil_chain_t *)lwb->lwb_buf;\n\telse\n\t\tzilc = (zil_chain_t *)(lwb->lwb_buf + lwb->lwb_nmax);\n\tint wsz = lwb->lwb_sz;\n\tif (lwb->lwb_error == 0) {\n\t\tabd_t *lwb_abd = abd_get_from_buf(lwb->lwb_buf, lwb->lwb_sz);\n\t\tif (!lwb->lwb_slog || zilog->zl_cur_used <= zil_slog_bulk)\n\t\t\tprio = ZIO_PRIORITY_SYNC_WRITE;\n\t\telse\n\t\t\tprio = ZIO_PRIORITY_ASYNC_WRITE;\n\t\tSET_BOOKMARK(&zb, lwb->lwb_blk.blk_cksum.zc_word[ZIL_ZC_OBJSET],\n\t\t    ZB_ZIL_OBJECT, ZB_ZIL_LEVEL,\n\t\t    lwb->lwb_blk.blk_cksum.zc_word[ZIL_ZC_SEQ]);\n\t\tlwb->lwb_write_zio = zio_rewrite(lwb->lwb_root_zio, spa, 0,\n\t\t    &lwb->lwb_blk, lwb_abd, lwb->lwb_sz, zil_lwb_write_done,\n\t\t    lwb, prio, ZIO_FLAG_CANFAIL, &zb);\n\t\tzil_lwb_add_block(lwb, &lwb->lwb_blk);\n\n\t\tif (lwb->lwb_slim) {\n\t\t\t \n\t\t\twsz = P2ROUNDUP_TYPED(lwb->lwb_nused, ZIL_MIN_BLKSZ,\n\t\t\t    int);\n\t\t\tASSERT3S(wsz, <=, lwb->lwb_sz);\n\t\t\tzio_shrink(lwb->lwb_write_zio, wsz);\n\t\t\twsz = lwb->lwb_write_zio->io_size;\n\t\t}\n\t\tmemset(lwb->lwb_buf + lwb->lwb_nused, 0, wsz - lwb->lwb_nused);\n\t\tzilc->zc_pad = 0;\n\t\tzilc->zc_nused = lwb->lwb_nused;\n\t\tzilc->zc_eck.zec_cksum = lwb->lwb_blk.blk_cksum;\n\t} else {\n\t\t \n\t\tlwb->lwb_write_zio = zio_null(lwb->lwb_root_zio, spa, NULL,\n\t\t    zil_lwb_write_done, lwb, ZIO_FLAG_CANFAIL);\n\t\tlwb->lwb_write_zio->io_error = lwb->lwb_error;\n\t}\n\tif (lwb->lwb_child_zio)\n\t\tzio_add_child(lwb->lwb_write_zio, lwb->lwb_child_zio);\n\n\t \n\tdmu_tx_t *tx = dmu_tx_create(zilog->zl_os);\n\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT | TXG_NOTHROTTLE));\n\tdsl_dataset_dirty(dmu_objset_ds(zilog->zl_os), tx);\n\tuint64_t txg = dmu_tx_get_txg(tx);\n\n\t \n\tlwb_t *nlwb = list_next(&zilog->zl_lwb_list, lwb);\n\tblkptr_t *bp = &zilc->zc_next_blk;\n\tBP_ZERO(bp);\n\terror = lwb->lwb_error;\n\tif (error == 0) {\n\t\terror = zio_alloc_zil(spa, zilog->zl_os, txg, bp, nlwb->lwb_sz,\n\t\t    &slog);\n\t}\n\tif (error == 0) {\n\t\tASSERT3U(bp->blk_birth, ==, txg);\n\t\tBP_SET_CHECKSUM(bp, nlwb->lwb_slim ? ZIO_CHECKSUM_ZILOG2 :\n\t\t    ZIO_CHECKSUM_ZILOG);\n\t\tbp->blk_cksum = lwb->lwb_blk.blk_cksum;\n\t\tbp->blk_cksum.zc_word[ZIL_ZC_SEQ]++;\n\t}\n\n\t \n\tmutex_enter(&zilog->zl_lwb_io_lock);\n\tlwb->lwb_issued_txg = txg;\n\tzilog->zl_lwb_inflight[txg & TXG_MASK]++;\n\tzilog->zl_lwb_max_issued_txg = MAX(txg, zilog->zl_lwb_max_issued_txg);\n\tmutex_exit(&zilog->zl_lwb_io_lock);\n\tdmu_tx_commit(tx);\n\n\tspa_config_enter(spa, SCL_STATE, lwb, RW_READER);\n\n\t \n\tmutex_enter(&zilog->zl_lock);\n\tzil_lwb_set_zio_dependency(zilog, lwb);\n\tlwb->lwb_state = LWB_STATE_ISSUED;\n\n\tif (nlwb) {\n\t\tnlwb->lwb_blk = *bp;\n\t\tnlwb->lwb_error = error;\n\t\tnlwb->lwb_slog = slog;\n\t\tnlwb->lwb_alloc_txg = txg;\n\t\tif (nlwb->lwb_state != LWB_STATE_READY)\n\t\t\tnlwb = NULL;\n\t}\n\tmutex_exit(&zilog->zl_lock);\n\n\tif (lwb->lwb_slog) {\n\t\tZIL_STAT_BUMP(zilog, zil_itx_metaslab_slog_count);\n\t\tZIL_STAT_INCR(zilog, zil_itx_metaslab_slog_bytes,\n\t\t    lwb->lwb_nused);\n\t\tZIL_STAT_INCR(zilog, zil_itx_metaslab_slog_write,\n\t\t    wsz);\n\t\tZIL_STAT_INCR(zilog, zil_itx_metaslab_slog_alloc,\n\t\t    BP_GET_LSIZE(&lwb->lwb_blk));\n\t} else {\n\t\tZIL_STAT_BUMP(zilog, zil_itx_metaslab_normal_count);\n\t\tZIL_STAT_INCR(zilog, zil_itx_metaslab_normal_bytes,\n\t\t    lwb->lwb_nused);\n\t\tZIL_STAT_INCR(zilog, zil_itx_metaslab_normal_write,\n\t\t    wsz);\n\t\tZIL_STAT_INCR(zilog, zil_itx_metaslab_normal_alloc,\n\t\t    BP_GET_LSIZE(&lwb->lwb_blk));\n\t}\n\tlwb->lwb_issued_timestamp = gethrtime();\n\tif (lwb->lwb_child_zio)\n\t\tzio_nowait(lwb->lwb_child_zio);\n\tzio_nowait(lwb->lwb_write_zio);\n\tzio_nowait(lwb->lwb_root_zio);\n\n\t \n\tlwb = nlwb;\n\tif (lwb)\n\t\tgoto next_lwb;\n}\n\n \nuint64_t\nzil_max_log_data(zilog_t *zilog, size_t hdrsize)\n{\n\treturn (zilog->zl_max_block_size - sizeof (zil_chain_t) - hdrsize);\n}\n\n \nstatic inline uint64_t\nzil_max_waste_space(zilog_t *zilog)\n{\n\treturn (zil_max_log_data(zilog, sizeof (lr_write_t)) / 16);\n}\n\n \nstatic uint_t zil_maxcopied = 7680;\n\nuint64_t\nzil_max_copied_data(zilog_t *zilog)\n{\n\tuint64_t max_data = zil_max_log_data(zilog, sizeof (lr_write_t));\n\treturn (MIN(max_data, zil_maxcopied));\n}\n\n \nstatic lwb_t *\nzil_lwb_assign(zilog_t *zilog, lwb_t *lwb, itx_t *itx, list_t *ilwbs)\n{\n\titx_t *citx;\n\tlr_t *lr, *clr;\n\tlr_write_t *lrw;\n\tuint64_t dlen, dnow, lwb_sp, reclen, max_log_data;\n\n\tASSERT(MUTEX_HELD(&zilog->zl_issuer_lock));\n\tASSERT3P(lwb, !=, NULL);\n\tASSERT3P(lwb->lwb_buf, !=, NULL);\n\n\tzil_lwb_write_open(zilog, lwb);\n\n\tlr = &itx->itx_lr;\n\tlrw = (lr_write_t *)lr;\n\n\t \n\tif (lr->lrc_txtype == TX_COMMIT) {\n\t\tzil_commit_waiter_link_lwb(itx->itx_private, lwb);\n\t\tlist_insert_tail(&lwb->lwb_itxs, itx);\n\t\treturn (lwb);\n\t}\n\n\tif (lr->lrc_txtype == TX_WRITE && itx->itx_wr_state == WR_NEED_COPY) {\n\t\tdlen = P2ROUNDUP_TYPED(\n\t\t    lrw->lr_length, sizeof (uint64_t), uint64_t);\n\t} else {\n\t\tdlen = 0;\n\t}\n\treclen = lr->lrc_reclen;\n\tzilog->zl_cur_used += (reclen + dlen);\n\ncont:\n\t \n\tlwb_sp = lwb->lwb_nmax - lwb->lwb_nused;\n\tmax_log_data = zil_max_log_data(zilog, sizeof (lr_write_t));\n\tif (reclen > lwb_sp || (reclen + dlen > lwb_sp &&\n\t    lwb_sp < zil_max_waste_space(zilog) &&\n\t    (dlen % max_log_data == 0 ||\n\t    lwb_sp < reclen + dlen % max_log_data))) {\n\t\tlist_insert_tail(ilwbs, lwb);\n\t\tlwb = zil_lwb_write_close(zilog, lwb, LWB_STATE_OPENED);\n\t\tif (lwb == NULL)\n\t\t\treturn (NULL);\n\t\tlwb_sp = lwb->lwb_nmax - lwb->lwb_nused;\n\n\t\t \n\t\tASSERT3U(reclen + MIN(dlen, sizeof (uint64_t)), <=, lwb_sp);\n\t}\n\n\tdnow = MIN(dlen, lwb_sp - reclen);\n\tif (dlen > dnow) {\n\t\tASSERT3U(lr->lrc_txtype, ==, TX_WRITE);\n\t\tASSERT3U(itx->itx_wr_state, ==, WR_NEED_COPY);\n\t\tcitx = zil_itx_clone(itx);\n\t\tclr = &citx->itx_lr;\n\t\tlr_write_t *clrw = (lr_write_t *)clr;\n\t\tclrw->lr_length = dnow;\n\t\tlrw->lr_offset += dnow;\n\t\tlrw->lr_length -= dnow;\n\t} else {\n\t\tcitx = itx;\n\t\tclr = lr;\n\t}\n\n\t \n\tclr->lrc_seq = ++zilog->zl_lr_seq;\n\n\tlwb->lwb_nused += reclen + dnow;\n\tASSERT3U(lwb->lwb_nused, <=, lwb->lwb_nmax);\n\tASSERT0(P2PHASE(lwb->lwb_nused, sizeof (uint64_t)));\n\n\tzil_lwb_add_txg(lwb, lr->lrc_txg);\n\tlist_insert_tail(&lwb->lwb_itxs, citx);\n\n\tdlen -= dnow;\n\tif (dlen > 0) {\n\t\tzilog->zl_cur_used += reclen;\n\t\tgoto cont;\n\t}\n\n\tif (lr->lrc_txtype == TX_WRITE &&\n\t    lr->lrc_txg > spa_freeze_txg(zilog->zl_spa))\n\t\ttxg_wait_synced(zilog->zl_dmu_pool, lr->lrc_txg);\n\n\treturn (lwb);\n}\n\n \nstatic void\nzil_lwb_commit(zilog_t *zilog, lwb_t *lwb, itx_t *itx)\n{\n\tlr_t *lr, *lrb;\n\tlr_write_t *lrw, *lrwb;\n\tchar *lr_buf;\n\tuint64_t dlen, reclen;\n\n\tlr = &itx->itx_lr;\n\tlrw = (lr_write_t *)lr;\n\n\tif (lr->lrc_txtype == TX_COMMIT)\n\t\treturn;\n\n\tif (lr->lrc_txtype == TX_WRITE && itx->itx_wr_state == WR_NEED_COPY) {\n\t\tdlen = P2ROUNDUP_TYPED(\n\t\t    lrw->lr_length, sizeof (uint64_t), uint64_t);\n\t} else {\n\t\tdlen = 0;\n\t}\n\treclen = lr->lrc_reclen;\n\tASSERT3U(reclen + dlen, <=, lwb->lwb_nused - lwb->lwb_nfilled);\n\n\tlr_buf = lwb->lwb_buf + lwb->lwb_nfilled;\n\tmemcpy(lr_buf, lr, reclen);\n\tlrb = (lr_t *)lr_buf;\t\t \n\tlrwb = (lr_write_t *)lrb;\t \n\n\tZIL_STAT_BUMP(zilog, zil_itx_count);\n\n\t \n\tif (lr->lrc_txtype == TX_WRITE) {\n\t\tif (itx->itx_wr_state == WR_COPIED) {\n\t\t\tZIL_STAT_BUMP(zilog, zil_itx_copied_count);\n\t\t\tZIL_STAT_INCR(zilog, zil_itx_copied_bytes,\n\t\t\t    lrw->lr_length);\n\t\t} else {\n\t\t\tchar *dbuf;\n\t\t\tint error;\n\n\t\t\tif (itx->itx_wr_state == WR_NEED_COPY) {\n\t\t\t\tdbuf = lr_buf + reclen;\n\t\t\t\tlrb->lrc_reclen += dlen;\n\t\t\t\tZIL_STAT_BUMP(zilog, zil_itx_needcopy_count);\n\t\t\t\tZIL_STAT_INCR(zilog, zil_itx_needcopy_bytes,\n\t\t\t\t    dlen);\n\t\t\t} else {\n\t\t\t\tASSERT3S(itx->itx_wr_state, ==, WR_INDIRECT);\n\t\t\t\tdbuf = NULL;\n\t\t\t\tZIL_STAT_BUMP(zilog, zil_itx_indirect_count);\n\t\t\t\tZIL_STAT_INCR(zilog, zil_itx_indirect_bytes,\n\t\t\t\t    lrw->lr_length);\n\t\t\t\tif (lwb->lwb_child_zio == NULL) {\n\t\t\t\t\tlwb->lwb_child_zio = zio_root(\n\t\t\t\t\t    zilog->zl_spa, NULL, NULL,\n\t\t\t\t\t    ZIO_FLAG_CANFAIL);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t \n\t\t\terror = zilog->zl_get_data(itx->itx_private,\n\t\t\t    itx->itx_gen, lrwb, dbuf, lwb,\n\t\t\t    lwb->lwb_child_zio);\n\t\t\tif (dbuf != NULL && error == 0) {\n\t\t\t\t \n\t\t\t\tmemset((char *)dbuf + lrwb->lr_length, 0,\n\t\t\t\t    dlen - lrwb->lr_length);\n\t\t\t}\n\n\t\t\t \n\t\t\tswitch (error) {\n\t\t\tcase 0:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tcmn_err(CE_WARN, \"zil_lwb_commit() received \"\n\t\t\t\t    \"unexpected error %d from ->zl_get_data()\"\n\t\t\t\t    \". Falling back to txg_wait_synced().\",\n\t\t\t\t    error);\n\t\t\t\tzfs_fallthrough;\n\t\t\tcase EIO:\n\t\t\t\ttxg_wait_synced(zilog->zl_dmu_pool,\n\t\t\t\t    lr->lrc_txg);\n\t\t\t\tzfs_fallthrough;\n\t\t\tcase ENOENT:\n\t\t\t\tzfs_fallthrough;\n\t\t\tcase EEXIST:\n\t\t\t\tzfs_fallthrough;\n\t\t\tcase EALREADY:\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\n\tlwb->lwb_nfilled += reclen + dlen;\n\tASSERT3S(lwb->lwb_nfilled, <=, lwb->lwb_nused);\n\tASSERT0(P2PHASE(lwb->lwb_nfilled, sizeof (uint64_t)));\n}\n\nitx_t *\nzil_itx_create(uint64_t txtype, size_t olrsize)\n{\n\tsize_t itxsize, lrsize;\n\titx_t *itx;\n\n\tlrsize = P2ROUNDUP_TYPED(olrsize, sizeof (uint64_t), size_t);\n\titxsize = offsetof(itx_t, itx_lr) + lrsize;\n\n\titx = zio_data_buf_alloc(itxsize);\n\titx->itx_lr.lrc_txtype = txtype;\n\titx->itx_lr.lrc_reclen = lrsize;\n\titx->itx_lr.lrc_seq = 0;\t \n\tmemset((char *)&itx->itx_lr + olrsize, 0, lrsize - olrsize);\n\titx->itx_sync = B_TRUE;\t\t \n\titx->itx_callback = NULL;\n\titx->itx_callback_data = NULL;\n\titx->itx_size = itxsize;\n\n\treturn (itx);\n}\n\nstatic itx_t *\nzil_itx_clone(itx_t *oitx)\n{\n\titx_t *itx = zio_data_buf_alloc(oitx->itx_size);\n\tmemcpy(itx, oitx, oitx->itx_size);\n\titx->itx_callback = NULL;\n\titx->itx_callback_data = NULL;\n\treturn (itx);\n}\n\nvoid\nzil_itx_destroy(itx_t *itx)\n{\n\tIMPLY(itx->itx_lr.lrc_txtype == TX_COMMIT, itx->itx_callback == NULL);\n\tIMPLY(itx->itx_callback != NULL, itx->itx_lr.lrc_txtype != TX_COMMIT);\n\n\tif (itx->itx_callback != NULL)\n\t\titx->itx_callback(itx->itx_callback_data);\n\n\tzio_data_buf_free(itx, itx->itx_size);\n}\n\n \nstatic void\nzil_itxg_clean(void *arg)\n{\n\titx_t *itx;\n\tlist_t *list;\n\tavl_tree_t *t;\n\tvoid *cookie;\n\titxs_t *itxs = arg;\n\titx_async_node_t *ian;\n\n\tlist = &itxs->i_sync_list;\n\twhile ((itx = list_remove_head(list)) != NULL) {\n\t\t \n\t\tif (itx->itx_lr.lrc_txtype == TX_COMMIT)\n\t\t\tzil_commit_waiter_skip(itx->itx_private);\n\n\t\tzil_itx_destroy(itx);\n\t}\n\n\tcookie = NULL;\n\tt = &itxs->i_async_tree;\n\twhile ((ian = avl_destroy_nodes(t, &cookie)) != NULL) {\n\t\tlist = &ian->ia_list;\n\t\twhile ((itx = list_remove_head(list)) != NULL) {\n\t\t\t \n\t\t\tASSERT3U(itx->itx_lr.lrc_txtype, !=, TX_COMMIT);\n\t\t\tzil_itx_destroy(itx);\n\t\t}\n\t\tlist_destroy(list);\n\t\tkmem_free(ian, sizeof (itx_async_node_t));\n\t}\n\tavl_destroy(t);\n\n\tkmem_free(itxs, sizeof (itxs_t));\n}\n\nstatic int\nzil_aitx_compare(const void *x1, const void *x2)\n{\n\tconst uint64_t o1 = ((itx_async_node_t *)x1)->ia_foid;\n\tconst uint64_t o2 = ((itx_async_node_t *)x2)->ia_foid;\n\n\treturn (TREE_CMP(o1, o2));\n}\n\n \nvoid\nzil_remove_async(zilog_t *zilog, uint64_t oid)\n{\n\tuint64_t otxg, txg;\n\titx_async_node_t *ian;\n\tavl_tree_t *t;\n\tavl_index_t where;\n\tlist_t clean_list;\n\titx_t *itx;\n\n\tASSERT(oid != 0);\n\tlist_create(&clean_list, sizeof (itx_t), offsetof(itx_t, itx_node));\n\n\tif (spa_freeze_txg(zilog->zl_spa) != UINT64_MAX)  \n\t\totxg = ZILTEST_TXG;\n\telse\n\t\totxg = spa_last_synced_txg(zilog->zl_spa) + 1;\n\n\tfor (txg = otxg; txg < (otxg + TXG_CONCURRENT_STATES); txg++) {\n\t\titxg_t *itxg = &zilog->zl_itxg[txg & TXG_MASK];\n\n\t\tmutex_enter(&itxg->itxg_lock);\n\t\tif (itxg->itxg_txg != txg) {\n\t\t\tmutex_exit(&itxg->itxg_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tt = &itxg->itxg_itxs->i_async_tree;\n\t\tian = avl_find(t, &oid, &where);\n\t\tif (ian != NULL)\n\t\t\tlist_move_tail(&clean_list, &ian->ia_list);\n\t\tmutex_exit(&itxg->itxg_lock);\n\t}\n\twhile ((itx = list_remove_head(&clean_list)) != NULL) {\n\t\t \n\t\tASSERT3U(itx->itx_lr.lrc_txtype, !=, TX_COMMIT);\n\t\tzil_itx_destroy(itx);\n\t}\n\tlist_destroy(&clean_list);\n}\n\nvoid\nzil_itx_assign(zilog_t *zilog, itx_t *itx, dmu_tx_t *tx)\n{\n\tuint64_t txg;\n\titxg_t *itxg;\n\titxs_t *itxs, *clean = NULL;\n\n\t \n\tif ((itx->itx_lr.lrc_txtype & ~TX_CI) == TX_RENAME)\n\t\tzil_async_to_sync(zilog, itx->itx_oid);\n\n\tif (spa_freeze_txg(zilog->zl_spa) != UINT64_MAX)\n\t\ttxg = ZILTEST_TXG;\n\telse\n\t\ttxg = dmu_tx_get_txg(tx);\n\n\titxg = &zilog->zl_itxg[txg & TXG_MASK];\n\tmutex_enter(&itxg->itxg_lock);\n\titxs = itxg->itxg_itxs;\n\tif (itxg->itxg_txg != txg) {\n\t\tif (itxs != NULL) {\n\t\t\t \n\t\t\tzfs_dbgmsg(\"zil_itx_assign: missed itx cleanup for \"\n\t\t\t    \"txg %llu\", (u_longlong_t)itxg->itxg_txg);\n\t\t\tclean = itxg->itxg_itxs;\n\t\t}\n\t\titxg->itxg_txg = txg;\n\t\titxs = itxg->itxg_itxs = kmem_zalloc(sizeof (itxs_t),\n\t\t    KM_SLEEP);\n\n\t\tlist_create(&itxs->i_sync_list, sizeof (itx_t),\n\t\t    offsetof(itx_t, itx_node));\n\t\tavl_create(&itxs->i_async_tree, zil_aitx_compare,\n\t\t    sizeof (itx_async_node_t),\n\t\t    offsetof(itx_async_node_t, ia_node));\n\t}\n\tif (itx->itx_sync) {\n\t\tlist_insert_tail(&itxs->i_sync_list, itx);\n\t} else {\n\t\tavl_tree_t *t = &itxs->i_async_tree;\n\t\tuint64_t foid =\n\t\t    LR_FOID_GET_OBJ(((lr_ooo_t *)&itx->itx_lr)->lr_foid);\n\t\titx_async_node_t *ian;\n\t\tavl_index_t where;\n\n\t\tian = avl_find(t, &foid, &where);\n\t\tif (ian == NULL) {\n\t\t\tian = kmem_alloc(sizeof (itx_async_node_t),\n\t\t\t    KM_SLEEP);\n\t\t\tlist_create(&ian->ia_list, sizeof (itx_t),\n\t\t\t    offsetof(itx_t, itx_node));\n\t\t\tian->ia_foid = foid;\n\t\t\tavl_insert(t, ian, where);\n\t\t}\n\t\tlist_insert_tail(&ian->ia_list, itx);\n\t}\n\n\titx->itx_lr.lrc_txg = dmu_tx_get_txg(tx);\n\n\t \n\tzilog_dirty(zilog, dmu_tx_get_txg(tx));\n\tmutex_exit(&itxg->itxg_lock);\n\n\t \n\tif (clean != NULL)\n\t\tzil_itxg_clean(clean);\n}\n\n \nvoid\nzil_clean(zilog_t *zilog, uint64_t synced_txg)\n{\n\titxg_t *itxg = &zilog->zl_itxg[synced_txg & TXG_MASK];\n\titxs_t *clean_me;\n\n\tASSERT3U(synced_txg, <, ZILTEST_TXG);\n\n\tmutex_enter(&itxg->itxg_lock);\n\tif (itxg->itxg_itxs == NULL || itxg->itxg_txg == ZILTEST_TXG) {\n\t\tmutex_exit(&itxg->itxg_lock);\n\t\treturn;\n\t}\n\tASSERT3U(itxg->itxg_txg, <=, synced_txg);\n\tASSERT3U(itxg->itxg_txg, !=, 0);\n\tclean_me = itxg->itxg_itxs;\n\titxg->itxg_itxs = NULL;\n\titxg->itxg_txg = 0;\n\tmutex_exit(&itxg->itxg_lock);\n\t \n\tASSERT3P(zilog->zl_dmu_pool, !=, NULL);\n\tASSERT3P(zilog->zl_dmu_pool->dp_zil_clean_taskq, !=, NULL);\n\ttaskqid_t id = taskq_dispatch(zilog->zl_dmu_pool->dp_zil_clean_taskq,\n\t    zil_itxg_clean, clean_me, TQ_NOSLEEP);\n\tif (id == TASKQID_INVALID)\n\t\tzil_itxg_clean(clean_me);\n}\n\n \nstatic uint64_t\nzil_get_commit_list(zilog_t *zilog)\n{\n\tuint64_t otxg, txg, wtxg = 0;\n\tlist_t *commit_list = &zilog->zl_itx_commit_list;\n\n\tASSERT(MUTEX_HELD(&zilog->zl_issuer_lock));\n\n\tif (spa_freeze_txg(zilog->zl_spa) != UINT64_MAX)  \n\t\totxg = ZILTEST_TXG;\n\telse\n\t\totxg = spa_last_synced_txg(zilog->zl_spa) + 1;\n\n\t \n\tfor (txg = otxg; txg < (otxg + TXG_CONCURRENT_STATES); txg++) {\n\t\titxg_t *itxg = &zilog->zl_itxg[txg & TXG_MASK];\n\n\t\tmutex_enter(&itxg->itxg_lock);\n\t\tif (itxg->itxg_txg != txg) {\n\t\t\tmutex_exit(&itxg->itxg_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tASSERT(zilog_is_dirty_in_txg(zilog, txg) ||\n\t\t    spa_freeze_txg(zilog->zl_spa) != UINT64_MAX);\n\t\tlist_t *sync_list = &itxg->itxg_itxs->i_sync_list;\n\t\tif (unlikely(zilog->zl_suspend > 0)) {\n\t\t\t \n\t\t\tif (!list_is_empty(sync_list))\n\t\t\t\twtxg = MAX(wtxg, txg);\n\t\t} else {\n\t\t\tlist_move_tail(commit_list, sync_list);\n\t\t}\n\n\t\tmutex_exit(&itxg->itxg_lock);\n\t}\n\treturn (wtxg);\n}\n\n \nvoid\nzil_async_to_sync(zilog_t *zilog, uint64_t foid)\n{\n\tuint64_t otxg, txg;\n\titx_async_node_t *ian;\n\tavl_tree_t *t;\n\tavl_index_t where;\n\n\tif (spa_freeze_txg(zilog->zl_spa) != UINT64_MAX)  \n\t\totxg = ZILTEST_TXG;\n\telse\n\t\totxg = spa_last_synced_txg(zilog->zl_spa) + 1;\n\n\t \n\tfor (txg = otxg; txg < (otxg + TXG_CONCURRENT_STATES); txg++) {\n\t\titxg_t *itxg = &zilog->zl_itxg[txg & TXG_MASK];\n\n\t\tmutex_enter(&itxg->itxg_lock);\n\t\tif (itxg->itxg_txg != txg) {\n\t\t\tmutex_exit(&itxg->itxg_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tt = &itxg->itxg_itxs->i_async_tree;\n\t\tif (foid != 0) {\n\t\t\tian = avl_find(t, &foid, &where);\n\t\t\tif (ian != NULL) {\n\t\t\t\tlist_move_tail(&itxg->itxg_itxs->i_sync_list,\n\t\t\t\t    &ian->ia_list);\n\t\t\t}\n\t\t} else {\n\t\t\tvoid *cookie = NULL;\n\n\t\t\twhile ((ian = avl_destroy_nodes(t, &cookie)) != NULL) {\n\t\t\t\tlist_move_tail(&itxg->itxg_itxs->i_sync_list,\n\t\t\t\t    &ian->ia_list);\n\t\t\t\tlist_destroy(&ian->ia_list);\n\t\t\t\tkmem_free(ian, sizeof (itx_async_node_t));\n\t\t\t}\n\t\t}\n\t\tmutex_exit(&itxg->itxg_lock);\n\t}\n}\n\n \nstatic void\nzil_prune_commit_list(zilog_t *zilog)\n{\n\titx_t *itx;\n\n\tASSERT(MUTEX_HELD(&zilog->zl_issuer_lock));\n\n\twhile ((itx = list_head(&zilog->zl_itx_commit_list)) != NULL) {\n\t\tlr_t *lrc = &itx->itx_lr;\n\t\tif (lrc->lrc_txtype != TX_COMMIT)\n\t\t\tbreak;\n\n\t\tmutex_enter(&zilog->zl_lock);\n\n\t\tlwb_t *last_lwb = zilog->zl_last_lwb_opened;\n\t\tif (last_lwb == NULL ||\n\t\t    last_lwb->lwb_state == LWB_STATE_FLUSH_DONE) {\n\t\t\t \n\t\t\tzil_commit_waiter_skip(itx->itx_private);\n\t\t} else {\n\t\t\tzil_commit_waiter_link_lwb(itx->itx_private, last_lwb);\n\t\t}\n\n\t\tmutex_exit(&zilog->zl_lock);\n\n\t\tlist_remove(&zilog->zl_itx_commit_list, itx);\n\t\tzil_itx_destroy(itx);\n\t}\n\n\tIMPLY(itx != NULL, itx->itx_lr.lrc_txtype != TX_COMMIT);\n}\n\nstatic void\nzil_commit_writer_stall(zilog_t *zilog)\n{\n\t \n\tASSERT(MUTEX_HELD(&zilog->zl_issuer_lock));\n\ttxg_wait_synced(zilog->zl_dmu_pool, 0);\n\tASSERT(list_is_empty(&zilog->zl_lwb_list));\n}\n\n \nstatic void\nzil_process_commit_list(zilog_t *zilog, zil_commit_waiter_t *zcw, list_t *ilwbs)\n{\n\tspa_t *spa = zilog->zl_spa;\n\tlist_t nolwb_itxs;\n\tlist_t nolwb_waiters;\n\tlwb_t *lwb, *plwb;\n\titx_t *itx;\n\tboolean_t first = B_TRUE;\n\n\tASSERT(MUTEX_HELD(&zilog->zl_issuer_lock));\n\n\t \n\tif (list_is_empty(&zilog->zl_itx_commit_list))\n\t\treturn;\n\n\tlist_create(&nolwb_itxs, sizeof (itx_t), offsetof(itx_t, itx_node));\n\tlist_create(&nolwb_waiters, sizeof (zil_commit_waiter_t),\n\t    offsetof(zil_commit_waiter_t, zcw_node));\n\n\tlwb = list_tail(&zilog->zl_lwb_list);\n\tif (lwb == NULL) {\n\t\tlwb = zil_create(zilog);\n\t} else {\n\t\t \n\t\tzil_commit_activate_saxattr_feature(zilog);\n\t\tASSERT(lwb->lwb_state == LWB_STATE_NEW ||\n\t\t    lwb->lwb_state == LWB_STATE_OPENED);\n\t\tfirst = (lwb->lwb_state == LWB_STATE_NEW) &&\n\t\t    ((plwb = list_prev(&zilog->zl_lwb_list, lwb)) == NULL ||\n\t\t    plwb->lwb_state == LWB_STATE_FLUSH_DONE);\n\t}\n\n\twhile ((itx = list_remove_head(&zilog->zl_itx_commit_list)) != NULL) {\n\t\tlr_t *lrc = &itx->itx_lr;\n\t\tuint64_t txg = lrc->lrc_txg;\n\n\t\tASSERT3U(txg, !=, 0);\n\n\t\tif (lrc->lrc_txtype == TX_COMMIT) {\n\t\t\tDTRACE_PROBE2(zil__process__commit__itx,\n\t\t\t    zilog_t *, zilog, itx_t *, itx);\n\t\t} else {\n\t\t\tDTRACE_PROBE2(zil__process__normal__itx,\n\t\t\t    zilog_t *, zilog, itx_t *, itx);\n\t\t}\n\n\t\tboolean_t synced = txg <= spa_last_synced_txg(spa);\n\t\tboolean_t frozen = txg > spa_freeze_txg(spa);\n\n\t\t \n\t\tif (frozen || !synced || lrc->lrc_txtype == TX_COMMIT) {\n\t\t\tif (lwb != NULL) {\n\t\t\t\tlwb = zil_lwb_assign(zilog, lwb, itx, ilwbs);\n\t\t\t\tif (lwb == NULL) {\n\t\t\t\t\tlist_insert_tail(&nolwb_itxs, itx);\n\t\t\t\t} else if ((zcw->zcw_lwb != NULL &&\n\t\t\t\t    zcw->zcw_lwb != lwb) || zcw->zcw_done) {\n\t\t\t\t\t \n\t\t\t\t\tfirst = B_FALSE;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (lrc->lrc_txtype == TX_COMMIT) {\n\t\t\t\t\tzil_commit_waiter_link_nolwb(\n\t\t\t\t\t    itx->itx_private, &nolwb_waiters);\n\t\t\t\t}\n\t\t\t\tlist_insert_tail(&nolwb_itxs, itx);\n\t\t\t}\n\t\t} else {\n\t\t\tASSERT3S(lrc->lrc_txtype, !=, TX_COMMIT);\n\t\t\tzil_itx_destroy(itx);\n\t\t}\n\t}\n\n\tif (lwb == NULL) {\n\t\t \n\t\twhile ((lwb = list_remove_head(ilwbs)) != NULL)\n\t\t\tzil_lwb_write_issue(zilog, lwb);\n\t\tzil_commit_writer_stall(zilog);\n\n\t\t \n\t\tzil_commit_waiter_t *zcw;\n\t\twhile ((zcw = list_remove_head(&nolwb_waiters)) != NULL)\n\t\t\tzil_commit_waiter_skip(zcw);\n\n\t\t \n\t\twhile ((itx = list_remove_head(&nolwb_itxs)) != NULL)\n\t\t\tzil_itx_destroy(itx);\n\t} else {\n\t\tASSERT(list_is_empty(&nolwb_waiters));\n\t\tASSERT3P(lwb, !=, NULL);\n\t\tASSERT(lwb->lwb_state == LWB_STATE_NEW ||\n\t\t    lwb->lwb_state == LWB_STATE_OPENED);\n\n\t\t \n\t\tif (lwb->lwb_state == LWB_STATE_OPENED && first) {\n\t\t\thrtime_t sleep = zilog->zl_last_lwb_latency *\n\t\t\t    zfs_commit_timeout_pct / 100;\n\t\t\tif (sleep < zil_min_commit_timeout ||\n\t\t\t    lwb->lwb_nmax - lwb->lwb_nused <\n\t\t\t    lwb->lwb_nmax / 8) {\n\t\t\t\tlist_insert_tail(ilwbs, lwb);\n\t\t\t\tlwb = zil_lwb_write_close(zilog, lwb,\n\t\t\t\t    LWB_STATE_NEW);\n\t\t\t\tzilog->zl_cur_used = 0;\n\t\t\t\tif (lwb == NULL) {\n\t\t\t\t\twhile ((lwb = list_remove_head(ilwbs))\n\t\t\t\t\t    != NULL)\n\t\t\t\t\t\tzil_lwb_write_issue(zilog, lwb);\n\t\t\t\t\tzil_commit_writer_stall(zilog);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic uint64_t\nzil_commit_writer(zilog_t *zilog, zil_commit_waiter_t *zcw)\n{\n\tlist_t ilwbs;\n\tlwb_t *lwb;\n\tuint64_t wtxg = 0;\n\n\tASSERT(!MUTEX_HELD(&zilog->zl_lock));\n\tASSERT(spa_writeable(zilog->zl_spa));\n\n\tlist_create(&ilwbs, sizeof (lwb_t), offsetof(lwb_t, lwb_issue_node));\n\tmutex_enter(&zilog->zl_issuer_lock);\n\n\tif (zcw->zcw_lwb != NULL || zcw->zcw_done) {\n\t\t \n\t\tgoto out;\n\t}\n\n\tZIL_STAT_BUMP(zilog, zil_commit_writer_count);\n\n\twtxg = zil_get_commit_list(zilog);\n\tzil_prune_commit_list(zilog);\n\tzil_process_commit_list(zilog, zcw, &ilwbs);\n\nout:\n\tmutex_exit(&zilog->zl_issuer_lock);\n\twhile ((lwb = list_remove_head(&ilwbs)) != NULL)\n\t\tzil_lwb_write_issue(zilog, lwb);\n\tlist_destroy(&ilwbs);\n\treturn (wtxg);\n}\n\nstatic void\nzil_commit_waiter_timeout(zilog_t *zilog, zil_commit_waiter_t *zcw)\n{\n\tASSERT(!MUTEX_HELD(&zilog->zl_issuer_lock));\n\tASSERT(MUTEX_HELD(&zcw->zcw_lock));\n\tASSERT3B(zcw->zcw_done, ==, B_FALSE);\n\n\tlwb_t *lwb = zcw->zcw_lwb;\n\tASSERT3P(lwb, !=, NULL);\n\tASSERT3S(lwb->lwb_state, !=, LWB_STATE_NEW);\n\n\t \n\tif (lwb->lwb_state != LWB_STATE_OPENED)\n\t\treturn;\n\n\t \n\tmutex_exit(&zcw->zcw_lock);\n\tmutex_enter(&zilog->zl_issuer_lock);\n\tmutex_enter(&zcw->zcw_lock);\n\n\t \n\tif (zcw->zcw_done) {\n\t\tmutex_exit(&zilog->zl_issuer_lock);\n\t\treturn;\n\t}\n\n\tASSERT3P(lwb, ==, zcw->zcw_lwb);\n\n\t \n\tif (lwb->lwb_state != LWB_STATE_OPENED) {\n\t\tmutex_exit(&zilog->zl_issuer_lock);\n\t\treturn;\n\t}\n\n\t \n\tmutex_exit(&zcw->zcw_lock);\n\n\t \n\tlwb_t *nlwb = zil_lwb_write_close(zilog, lwb, LWB_STATE_NEW);\n\n\tASSERT3S(lwb->lwb_state, ==, LWB_STATE_CLOSED);\n\n\t \n\tzilog->zl_cur_used = 0;\n\n\tif (nlwb == NULL) {\n\t\t \n\t\tzil_lwb_write_issue(zilog, lwb);\n\t\tzil_commit_writer_stall(zilog);\n\t\tmutex_exit(&zilog->zl_issuer_lock);\n\t} else {\n\t\tmutex_exit(&zilog->zl_issuer_lock);\n\t\tzil_lwb_write_issue(zilog, lwb);\n\t}\n\tmutex_enter(&zcw->zcw_lock);\n}\n\n \nstatic void\nzil_commit_waiter(zilog_t *zilog, zil_commit_waiter_t *zcw)\n{\n\tASSERT(!MUTEX_HELD(&zilog->zl_lock));\n\tASSERT(!MUTEX_HELD(&zilog->zl_issuer_lock));\n\tASSERT(spa_writeable(zilog->zl_spa));\n\n\tmutex_enter(&zcw->zcw_lock);\n\n\t \n\tint pct = MAX(zfs_commit_timeout_pct, 1);\n\thrtime_t sleep = (zilog->zl_last_lwb_latency * pct) / 100;\n\thrtime_t wakeup = gethrtime() + sleep;\n\tboolean_t timedout = B_FALSE;\n\n\twhile (!zcw->zcw_done) {\n\t\tASSERT(MUTEX_HELD(&zcw->zcw_lock));\n\n\t\tlwb_t *lwb = zcw->zcw_lwb;\n\n\t\t \n\t\tIMPLY(lwb != NULL, lwb->lwb_state != LWB_STATE_NEW);\n\n\t\tif (lwb != NULL && lwb->lwb_state == LWB_STATE_OPENED) {\n\t\t\tASSERT3B(timedout, ==, B_FALSE);\n\n\t\t\t \n\t\t\tint rc = cv_timedwait_hires(&zcw->zcw_cv,\n\t\t\t    &zcw->zcw_lock, wakeup, USEC2NSEC(1),\n\t\t\t    CALLOUT_FLAG_ABSOLUTE);\n\n\t\t\tif (rc != -1 || zcw->zcw_done)\n\t\t\t\tcontinue;\n\n\t\t\ttimedout = B_TRUE;\n\t\t\tzil_commit_waiter_timeout(zilog, zcw);\n\n\t\t\tif (!zcw->zcw_done) {\n\t\t\t\t \n\t\t\t\tASSERT3P(lwb, ==, zcw->zcw_lwb);\n\t\t\t\tASSERT3S(lwb->lwb_state, !=, LWB_STATE_OPENED);\n\t\t\t}\n\t\t} else {\n\t\t\t \n\n\t\t\tIMPLY(lwb != NULL,\n\t\t\t    lwb->lwb_state == LWB_STATE_CLOSED ||\n\t\t\t    lwb->lwb_state == LWB_STATE_READY ||\n\t\t\t    lwb->lwb_state == LWB_STATE_ISSUED ||\n\t\t\t    lwb->lwb_state == LWB_STATE_WRITE_DONE ||\n\t\t\t    lwb->lwb_state == LWB_STATE_FLUSH_DONE);\n\t\t\tcv_wait(&zcw->zcw_cv, &zcw->zcw_lock);\n\t\t}\n\t}\n\n\tmutex_exit(&zcw->zcw_lock);\n}\n\nstatic zil_commit_waiter_t *\nzil_alloc_commit_waiter(void)\n{\n\tzil_commit_waiter_t *zcw = kmem_cache_alloc(zil_zcw_cache, KM_SLEEP);\n\n\tcv_init(&zcw->zcw_cv, NULL, CV_DEFAULT, NULL);\n\tmutex_init(&zcw->zcw_lock, NULL, MUTEX_DEFAULT, NULL);\n\tlist_link_init(&zcw->zcw_node);\n\tzcw->zcw_lwb = NULL;\n\tzcw->zcw_done = B_FALSE;\n\tzcw->zcw_zio_error = 0;\n\n\treturn (zcw);\n}\n\nstatic void\nzil_free_commit_waiter(zil_commit_waiter_t *zcw)\n{\n\tASSERT(!list_link_active(&zcw->zcw_node));\n\tASSERT3P(zcw->zcw_lwb, ==, NULL);\n\tASSERT3B(zcw->zcw_done, ==, B_TRUE);\n\tmutex_destroy(&zcw->zcw_lock);\n\tcv_destroy(&zcw->zcw_cv);\n\tkmem_cache_free(zil_zcw_cache, zcw);\n}\n\n \nstatic void\nzil_commit_itx_assign(zilog_t *zilog, zil_commit_waiter_t *zcw)\n{\n\tdmu_tx_t *tx = dmu_tx_create(zilog->zl_os);\n\n\t \n\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT | TXG_NOTHROTTLE));\n\n\titx_t *itx = zil_itx_create(TX_COMMIT, sizeof (lr_t));\n\titx->itx_sync = B_TRUE;\n\titx->itx_private = zcw;\n\n\tzil_itx_assign(zilog, itx, tx);\n\n\tdmu_tx_commit(tx);\n}\n\n \nvoid\nzil_commit(zilog_t *zilog, uint64_t foid)\n{\n\t \n\tASSERT3B(dmu_objset_is_snapshot(zilog->zl_os), ==, B_FALSE);\n\n\tif (zilog->zl_sync == ZFS_SYNC_DISABLED)\n\t\treturn;\n\n\tif (!spa_writeable(zilog->zl_spa)) {\n\t\t \n\t\tASSERT(list_is_empty(&zilog->zl_lwb_list));\n\t\tASSERT3P(zilog->zl_last_lwb_opened, ==, NULL);\n\t\tfor (int i = 0; i < TXG_SIZE; i++)\n\t\t\tASSERT3P(zilog->zl_itxg[i].itxg_itxs, ==, NULL);\n\t\treturn;\n\t}\n\n\t \n\tif (zilog->zl_suspend > 0) {\n\t\ttxg_wait_synced(zilog->zl_dmu_pool, 0);\n\t\treturn;\n\t}\n\n\tzil_commit_impl(zilog, foid);\n}\n\nvoid\nzil_commit_impl(zilog_t *zilog, uint64_t foid)\n{\n\tZIL_STAT_BUMP(zilog, zil_commit_count);\n\n\t \n\tzil_async_to_sync(zilog, foid);\n\n\t \n\tzil_commit_waiter_t *zcw = zil_alloc_commit_waiter();\n\tzil_commit_itx_assign(zilog, zcw);\n\n\tuint64_t wtxg = zil_commit_writer(zilog, zcw);\n\tzil_commit_waiter(zilog, zcw);\n\n\tif (zcw->zcw_zio_error != 0) {\n\t\t \n\t\tDTRACE_PROBE2(zil__commit__io__error,\n\t\t    zilog_t *, zilog, zil_commit_waiter_t *, zcw);\n\t\ttxg_wait_synced(zilog->zl_dmu_pool, 0);\n\t} else if (wtxg != 0) {\n\t\ttxg_wait_synced(zilog->zl_dmu_pool, wtxg);\n\t}\n\n\tzil_free_commit_waiter(zcw);\n}\n\n \nvoid\nzil_sync(zilog_t *zilog, dmu_tx_t *tx)\n{\n\tzil_header_t *zh = zil_header_in_syncing_context(zilog);\n\tuint64_t txg = dmu_tx_get_txg(tx);\n\tspa_t *spa = zilog->zl_spa;\n\tuint64_t *replayed_seq = &zilog->zl_replayed_seq[txg & TXG_MASK];\n\tlwb_t *lwb;\n\n\t \n\tif (spa_sync_pass(spa) != 1)\n\t\treturn;\n\n\tzil_lwb_flush_wait_all(zilog, txg);\n\n\tmutex_enter(&zilog->zl_lock);\n\n\tASSERT(zilog->zl_stop_sync == 0);\n\n\tif (*replayed_seq != 0) {\n\t\tASSERT(zh->zh_replay_seq < *replayed_seq);\n\t\tzh->zh_replay_seq = *replayed_seq;\n\t\t*replayed_seq = 0;\n\t}\n\n\tif (zilog->zl_destroy_txg == txg) {\n\t\tblkptr_t blk = zh->zh_log;\n\t\tdsl_dataset_t *ds = dmu_objset_ds(zilog->zl_os);\n\n\t\tASSERT(list_is_empty(&zilog->zl_lwb_list));\n\n\t\tmemset(zh, 0, sizeof (zil_header_t));\n\t\tmemset(zilog->zl_replayed_seq, 0,\n\t\t    sizeof (zilog->zl_replayed_seq));\n\n\t\tif (zilog->zl_keep_first) {\n\t\t\t \n\t\t\tzil_init_log_chain(zilog, &blk);\n\t\t\tzh->zh_log = blk;\n\t\t} else {\n\t\t\t \n\t\t\tif (dsl_dataset_feature_is_active(ds,\n\t\t\t    SPA_FEATURE_ZILSAXATTR))\n\t\t\t\tdsl_dataset_deactivate_feature(ds,\n\t\t\t\t    SPA_FEATURE_ZILSAXATTR, tx);\n\t\t}\n\t}\n\n\twhile ((lwb = list_head(&zilog->zl_lwb_list)) != NULL) {\n\t\tzh->zh_log = lwb->lwb_blk;\n\t\tif (lwb->lwb_state != LWB_STATE_FLUSH_DONE ||\n\t\t    lwb->lwb_alloc_txg > txg || lwb->lwb_max_txg > txg)\n\t\t\tbreak;\n\t\tlist_remove(&zilog->zl_lwb_list, lwb);\n\t\tif (!BP_IS_HOLE(&lwb->lwb_blk))\n\t\t\tzio_free(spa, txg, &lwb->lwb_blk);\n\t\tzil_free_lwb(zilog, lwb);\n\n\t\t \n\t\tif (list_is_empty(&zilog->zl_lwb_list))\n\t\t\tBP_ZERO(&zh->zh_log);\n\t}\n\n\tmutex_exit(&zilog->zl_lock);\n}\n\nstatic int\nzil_lwb_cons(void *vbuf, void *unused, int kmflag)\n{\n\t(void) unused, (void) kmflag;\n\tlwb_t *lwb = vbuf;\n\tlist_create(&lwb->lwb_itxs, sizeof (itx_t), offsetof(itx_t, itx_node));\n\tlist_create(&lwb->lwb_waiters, sizeof (zil_commit_waiter_t),\n\t    offsetof(zil_commit_waiter_t, zcw_node));\n\tavl_create(&lwb->lwb_vdev_tree, zil_lwb_vdev_compare,\n\t    sizeof (zil_vdev_node_t), offsetof(zil_vdev_node_t, zv_node));\n\tmutex_init(&lwb->lwb_vdev_lock, NULL, MUTEX_DEFAULT, NULL);\n\treturn (0);\n}\n\nstatic void\nzil_lwb_dest(void *vbuf, void *unused)\n{\n\t(void) unused;\n\tlwb_t *lwb = vbuf;\n\tmutex_destroy(&lwb->lwb_vdev_lock);\n\tavl_destroy(&lwb->lwb_vdev_tree);\n\tlist_destroy(&lwb->lwb_waiters);\n\tlist_destroy(&lwb->lwb_itxs);\n}\n\nvoid\nzil_init(void)\n{\n\tzil_lwb_cache = kmem_cache_create(\"zil_lwb_cache\",\n\t    sizeof (lwb_t), 0, zil_lwb_cons, zil_lwb_dest, NULL, NULL, NULL, 0);\n\n\tzil_zcw_cache = kmem_cache_create(\"zil_zcw_cache\",\n\t    sizeof (zil_commit_waiter_t), 0, NULL, NULL, NULL, NULL, NULL, 0);\n\n\tzil_sums_init(&zil_sums_global);\n\tzil_kstats_global = kstat_create(\"zfs\", 0, \"zil\", \"misc\",\n\t    KSTAT_TYPE_NAMED, sizeof (zil_stats) / sizeof (kstat_named_t),\n\t    KSTAT_FLAG_VIRTUAL);\n\n\tif (zil_kstats_global != NULL) {\n\t\tzil_kstats_global->ks_data = &zil_stats;\n\t\tzil_kstats_global->ks_update = zil_kstats_global_update;\n\t\tzil_kstats_global->ks_private = NULL;\n\t\tkstat_install(zil_kstats_global);\n\t}\n}\n\nvoid\nzil_fini(void)\n{\n\tkmem_cache_destroy(zil_zcw_cache);\n\tkmem_cache_destroy(zil_lwb_cache);\n\n\tif (zil_kstats_global != NULL) {\n\t\tkstat_delete(zil_kstats_global);\n\t\tzil_kstats_global = NULL;\n\t}\n\n\tzil_sums_fini(&zil_sums_global);\n}\n\nvoid\nzil_set_sync(zilog_t *zilog, uint64_t sync)\n{\n\tzilog->zl_sync = sync;\n}\n\nvoid\nzil_set_logbias(zilog_t *zilog, uint64_t logbias)\n{\n\tzilog->zl_logbias = logbias;\n}\n\nzilog_t *\nzil_alloc(objset_t *os, zil_header_t *zh_phys)\n{\n\tzilog_t *zilog;\n\n\tzilog = kmem_zalloc(sizeof (zilog_t), KM_SLEEP);\n\n\tzilog->zl_header = zh_phys;\n\tzilog->zl_os = os;\n\tzilog->zl_spa = dmu_objset_spa(os);\n\tzilog->zl_dmu_pool = dmu_objset_pool(os);\n\tzilog->zl_destroy_txg = TXG_INITIAL - 1;\n\tzilog->zl_logbias = dmu_objset_logbias(os);\n\tzilog->zl_sync = dmu_objset_syncprop(os);\n\tzilog->zl_dirty_max_txg = 0;\n\tzilog->zl_last_lwb_opened = NULL;\n\tzilog->zl_last_lwb_latency = 0;\n\tzilog->zl_max_block_size = zil_maxblocksize;\n\n\tmutex_init(&zilog->zl_lock, NULL, MUTEX_DEFAULT, NULL);\n\tmutex_init(&zilog->zl_issuer_lock, NULL, MUTEX_DEFAULT, NULL);\n\tmutex_init(&zilog->zl_lwb_io_lock, NULL, MUTEX_DEFAULT, NULL);\n\n\tfor (int i = 0; i < TXG_SIZE; i++) {\n\t\tmutex_init(&zilog->zl_itxg[i].itxg_lock, NULL,\n\t\t    MUTEX_DEFAULT, NULL);\n\t}\n\n\tlist_create(&zilog->zl_lwb_list, sizeof (lwb_t),\n\t    offsetof(lwb_t, lwb_node));\n\n\tlist_create(&zilog->zl_itx_commit_list, sizeof (itx_t),\n\t    offsetof(itx_t, itx_node));\n\n\tcv_init(&zilog->zl_cv_suspend, NULL, CV_DEFAULT, NULL);\n\tcv_init(&zilog->zl_lwb_io_cv, NULL, CV_DEFAULT, NULL);\n\n\treturn (zilog);\n}\n\nvoid\nzil_free(zilog_t *zilog)\n{\n\tint i;\n\n\tzilog->zl_stop_sync = 1;\n\n\tASSERT0(zilog->zl_suspend);\n\tASSERT0(zilog->zl_suspending);\n\n\tASSERT(list_is_empty(&zilog->zl_lwb_list));\n\tlist_destroy(&zilog->zl_lwb_list);\n\n\tASSERT(list_is_empty(&zilog->zl_itx_commit_list));\n\tlist_destroy(&zilog->zl_itx_commit_list);\n\n\tfor (i = 0; i < TXG_SIZE; i++) {\n\t\t \n\t\tif (zilog->zl_itxg[i].itxg_itxs)\n\t\t\tzil_itxg_clean(zilog->zl_itxg[i].itxg_itxs);\n\t\tmutex_destroy(&zilog->zl_itxg[i].itxg_lock);\n\t}\n\n\tmutex_destroy(&zilog->zl_issuer_lock);\n\tmutex_destroy(&zilog->zl_lock);\n\tmutex_destroy(&zilog->zl_lwb_io_lock);\n\n\tcv_destroy(&zilog->zl_cv_suspend);\n\tcv_destroy(&zilog->zl_lwb_io_cv);\n\n\tkmem_free(zilog, sizeof (zilog_t));\n}\n\n \nzilog_t *\nzil_open(objset_t *os, zil_get_data_t *get_data, zil_sums_t *zil_sums)\n{\n\tzilog_t *zilog = dmu_objset_zil(os);\n\n\tASSERT3P(zilog->zl_get_data, ==, NULL);\n\tASSERT3P(zilog->zl_last_lwb_opened, ==, NULL);\n\tASSERT(list_is_empty(&zilog->zl_lwb_list));\n\n\tzilog->zl_get_data = get_data;\n\tzilog->zl_sums = zil_sums;\n\n\treturn (zilog);\n}\n\n \nvoid\nzil_close(zilog_t *zilog)\n{\n\tlwb_t *lwb;\n\tuint64_t txg;\n\n\tif (!dmu_objset_is_snapshot(zilog->zl_os)) {\n\t\tzil_commit(zilog, 0);\n\t} else {\n\t\tASSERT(list_is_empty(&zilog->zl_lwb_list));\n\t\tASSERT0(zilog->zl_dirty_max_txg);\n\t\tASSERT3B(zilog_is_dirty(zilog), ==, B_FALSE);\n\t}\n\n\tmutex_enter(&zilog->zl_lock);\n\ttxg = zilog->zl_dirty_max_txg;\n\tlwb = list_tail(&zilog->zl_lwb_list);\n\tif (lwb != NULL) {\n\t\ttxg = MAX(txg, lwb->lwb_alloc_txg);\n\t\ttxg = MAX(txg, lwb->lwb_max_txg);\n\t}\n\tmutex_exit(&zilog->zl_lock);\n\n\t \n\tmutex_enter(&zilog->zl_lwb_io_lock);\n\ttxg = MAX(zilog->zl_lwb_max_issued_txg, txg);\n\tmutex_exit(&zilog->zl_lwb_io_lock);\n\n\t \n\tif (txg != 0)\n\t\ttxg_wait_synced(zilog->zl_dmu_pool, txg);\n\n\tif (zilog_is_dirty(zilog))\n\t\tzfs_dbgmsg(\"zil (%px) is dirty, txg %llu\", zilog,\n\t\t    (u_longlong_t)txg);\n\tif (txg < spa_freeze_txg(zilog->zl_spa))\n\t\tVERIFY(!zilog_is_dirty(zilog));\n\n\tzilog->zl_get_data = NULL;\n\n\t \n\tmutex_enter(&zilog->zl_lock);\n\tlwb = list_remove_head(&zilog->zl_lwb_list);\n\tif (lwb != NULL) {\n\t\tASSERT(list_is_empty(&zilog->zl_lwb_list));\n\t\tASSERT3S(lwb->lwb_state, ==, LWB_STATE_NEW);\n\t\tzio_buf_free(lwb->lwb_buf, lwb->lwb_sz);\n\t\tzil_free_lwb(zilog, lwb);\n\t}\n\tmutex_exit(&zilog->zl_lock);\n}\n\nstatic const char *suspend_tag = \"zil suspending\";\n\n \nint\nzil_suspend(const char *osname, void **cookiep)\n{\n\tobjset_t *os;\n\tzilog_t *zilog;\n\tconst zil_header_t *zh;\n\tint error;\n\n\terror = dmu_objset_hold(osname, suspend_tag, &os);\n\tif (error != 0)\n\t\treturn (error);\n\tzilog = dmu_objset_zil(os);\n\n\tmutex_enter(&zilog->zl_lock);\n\tzh = zilog->zl_header;\n\n\tif (zh->zh_flags & ZIL_REPLAY_NEEDED) {\t\t \n\t\tmutex_exit(&zilog->zl_lock);\n\t\tdmu_objset_rele(os, suspend_tag);\n\t\treturn (SET_ERROR(EBUSY));\n\t}\n\n\t \n\tif (cookiep == NULL && !zilog->zl_suspending &&\n\t    (zilog->zl_suspend > 0 || BP_IS_HOLE(&zh->zh_log))) {\n\t\tmutex_exit(&zilog->zl_lock);\n\t\tdmu_objset_rele(os, suspend_tag);\n\t\treturn (0);\n\t}\n\n\tdsl_dataset_long_hold(dmu_objset_ds(os), suspend_tag);\n\tdsl_pool_rele(dmu_objset_pool(os), suspend_tag);\n\n\tzilog->zl_suspend++;\n\n\tif (zilog->zl_suspend > 1) {\n\t\t \n\n\t\twhile (zilog->zl_suspending)\n\t\t\tcv_wait(&zilog->zl_cv_suspend, &zilog->zl_lock);\n\t\tmutex_exit(&zilog->zl_lock);\n\n\t\tif (cookiep == NULL)\n\t\t\tzil_resume(os);\n\t\telse\n\t\t\t*cookiep = os;\n\t\treturn (0);\n\t}\n\n\t \n\tif (BP_IS_HOLE(&zh->zh_log)) {\n\t\tASSERT(cookiep != NULL);  \n\n\t\t*cookiep = os;\n\t\tmutex_exit(&zilog->zl_lock);\n\t\treturn (0);\n\t}\n\n\t \n\tif (os->os_encrypted &&\n\t    dsl_dataset_create_key_mapping(dmu_objset_ds(os)) != 0) {\n\t\tzilog->zl_suspend--;\n\t\tmutex_exit(&zilog->zl_lock);\n\t\tdsl_dataset_long_rele(dmu_objset_ds(os), suspend_tag);\n\t\tdsl_dataset_rele(dmu_objset_ds(os), suspend_tag);\n\t\treturn (SET_ERROR(EACCES));\n\t}\n\n\tzilog->zl_suspending = B_TRUE;\n\tmutex_exit(&zilog->zl_lock);\n\n\t \n\tzil_commit_impl(zilog, 0);\n\n\t \n\ttxg_wait_synced(zilog->zl_dmu_pool, 0);\n\n\tzil_destroy(zilog, B_FALSE);\n\n\tmutex_enter(&zilog->zl_lock);\n\tzilog->zl_suspending = B_FALSE;\n\tcv_broadcast(&zilog->zl_cv_suspend);\n\tmutex_exit(&zilog->zl_lock);\n\n\tif (os->os_encrypted)\n\t\tdsl_dataset_remove_key_mapping(dmu_objset_ds(os));\n\n\tif (cookiep == NULL)\n\t\tzil_resume(os);\n\telse\n\t\t*cookiep = os;\n\treturn (0);\n}\n\nvoid\nzil_resume(void *cookie)\n{\n\tobjset_t *os = cookie;\n\tzilog_t *zilog = dmu_objset_zil(os);\n\n\tmutex_enter(&zilog->zl_lock);\n\tASSERT(zilog->zl_suspend != 0);\n\tzilog->zl_suspend--;\n\tmutex_exit(&zilog->zl_lock);\n\tdsl_dataset_long_rele(dmu_objset_ds(os), suspend_tag);\n\tdsl_dataset_rele(dmu_objset_ds(os), suspend_tag);\n}\n\ntypedef struct zil_replay_arg {\n\tzil_replay_func_t *const *zr_replay;\n\tvoid\t\t*zr_arg;\n\tboolean_t\tzr_byteswap;\n\tchar\t\t*zr_lr;\n} zil_replay_arg_t;\n\nstatic int\nzil_replay_error(zilog_t *zilog, const lr_t *lr, int error)\n{\n\tchar name[ZFS_MAX_DATASET_NAME_LEN];\n\n\tzilog->zl_replaying_seq--;\t \n\n\tdmu_objset_name(zilog->zl_os, name);\n\n\tcmn_err(CE_WARN, \"ZFS replay transaction error %d, \"\n\t    \"dataset %s, seq 0x%llx, txtype %llu %s\\n\", error, name,\n\t    (u_longlong_t)lr->lrc_seq,\n\t    (u_longlong_t)(lr->lrc_txtype & ~TX_CI),\n\t    (lr->lrc_txtype & TX_CI) ? \"CI\" : \"\");\n\n\treturn (error);\n}\n\nstatic int\nzil_replay_log_record(zilog_t *zilog, const lr_t *lr, void *zra,\n    uint64_t claim_txg)\n{\n\tzil_replay_arg_t *zr = zra;\n\tconst zil_header_t *zh = zilog->zl_header;\n\tuint64_t reclen = lr->lrc_reclen;\n\tuint64_t txtype = lr->lrc_txtype;\n\tint error = 0;\n\n\tzilog->zl_replaying_seq = lr->lrc_seq;\n\n\tif (lr->lrc_seq <= zh->zh_replay_seq)\t \n\t\treturn (0);\n\n\tif (lr->lrc_txg < claim_txg)\t\t \n\t\treturn (0);\n\n\t \n\ttxtype &= ~TX_CI;\n\n\tif (txtype == 0 || txtype >= TX_MAX_TYPE)\n\t\treturn (zil_replay_error(zilog, lr, EINVAL));\n\n\t \n\tif (TX_OOO(txtype)) {\n\t\terror = dmu_object_info(zilog->zl_os,\n\t\t    LR_FOID_GET_OBJ(((lr_ooo_t *)lr)->lr_foid), NULL);\n\t\tif (error == ENOENT || error == EEXIST)\n\t\t\treturn (0);\n\t}\n\n\t \n\tmemcpy(zr->zr_lr, lr, reclen);\n\n\t \n\tif (txtype == TX_WRITE && reclen == sizeof (lr_write_t)) {\n\t\terror = zil_read_log_data(zilog, (lr_write_t *)lr,\n\t\t    zr->zr_lr + reclen);\n\t\tif (error != 0)\n\t\t\treturn (zil_replay_error(zilog, lr, error));\n\t}\n\n\t \n\tif (zr->zr_byteswap)\n\t\tbyteswap_uint64_array(zr->zr_lr, reclen);\n\n\t \n\terror = zr->zr_replay[txtype](zr->zr_arg, zr->zr_lr, zr->zr_byteswap);\n\tif (error != 0) {\n\t\t \n\t\ttxg_wait_synced(spa_get_dsl(zilog->zl_spa), 0);\n\t\terror = zr->zr_replay[txtype](zr->zr_arg, zr->zr_lr, B_FALSE);\n\t\tif (error != 0)\n\t\t\treturn (zil_replay_error(zilog, lr, error));\n\t}\n\treturn (0);\n}\n\nstatic int\nzil_incr_blks(zilog_t *zilog, const blkptr_t *bp, void *arg, uint64_t claim_txg)\n{\n\t(void) bp, (void) arg, (void) claim_txg;\n\n\tzilog->zl_replay_blks++;\n\n\treturn (0);\n}\n\n \nboolean_t\nzil_replay(objset_t *os, void *arg,\n    zil_replay_func_t *const replay_func[TX_MAX_TYPE])\n{\n\tzilog_t *zilog = dmu_objset_zil(os);\n\tconst zil_header_t *zh = zilog->zl_header;\n\tzil_replay_arg_t zr;\n\n\tif ((zh->zh_flags & ZIL_REPLAY_NEEDED) == 0) {\n\t\treturn (zil_destroy(zilog, B_TRUE));\n\t}\n\n\tzr.zr_replay = replay_func;\n\tzr.zr_arg = arg;\n\tzr.zr_byteswap = BP_SHOULD_BYTESWAP(&zh->zh_log);\n\tzr.zr_lr = vmem_alloc(2 * SPA_MAXBLOCKSIZE, KM_SLEEP);\n\n\t \n\ttxg_wait_synced(zilog->zl_dmu_pool, 0);\n\n\tzilog->zl_replay = B_TRUE;\n\tzilog->zl_replay_time = ddi_get_lbolt();\n\tASSERT(zilog->zl_replay_blks == 0);\n\t(void) zil_parse(zilog, zil_incr_blks, zil_replay_log_record, &zr,\n\t    zh->zh_claim_txg, B_TRUE);\n\tvmem_free(zr.zr_lr, 2 * SPA_MAXBLOCKSIZE);\n\n\tzil_destroy(zilog, B_FALSE);\n\ttxg_wait_synced(zilog->zl_dmu_pool, zilog->zl_destroy_txg);\n\tzilog->zl_replay = B_FALSE;\n\n\treturn (B_TRUE);\n}\n\nboolean_t\nzil_replaying(zilog_t *zilog, dmu_tx_t *tx)\n{\n\tif (zilog->zl_sync == ZFS_SYNC_DISABLED)\n\t\treturn (B_TRUE);\n\n\tif (zilog->zl_replay) {\n\t\tdsl_dataset_dirty(dmu_objset_ds(zilog->zl_os), tx);\n\t\tzilog->zl_replayed_seq[dmu_tx_get_txg(tx) & TXG_MASK] =\n\t\t    zilog->zl_replaying_seq;\n\t\treturn (B_TRUE);\n\t}\n\n\treturn (B_FALSE);\n}\n\nint\nzil_reset(const char *osname, void *arg)\n{\n\t(void) arg;\n\n\tint error = zil_suspend(osname, NULL);\n\t \n\tif ((error == EACCES) || (error == EBUSY))\n\t\treturn (SET_ERROR(error));\n\tif (error != 0)\n\t\treturn (SET_ERROR(EEXIST));\n\treturn (0);\n}\n\nEXPORT_SYMBOL(zil_alloc);\nEXPORT_SYMBOL(zil_free);\nEXPORT_SYMBOL(zil_open);\nEXPORT_SYMBOL(zil_close);\nEXPORT_SYMBOL(zil_replay);\nEXPORT_SYMBOL(zil_replaying);\nEXPORT_SYMBOL(zil_destroy);\nEXPORT_SYMBOL(zil_destroy_sync);\nEXPORT_SYMBOL(zil_itx_create);\nEXPORT_SYMBOL(zil_itx_destroy);\nEXPORT_SYMBOL(zil_itx_assign);\nEXPORT_SYMBOL(zil_commit);\nEXPORT_SYMBOL(zil_claim);\nEXPORT_SYMBOL(zil_check_log_chain);\nEXPORT_SYMBOL(zil_sync);\nEXPORT_SYMBOL(zil_clean);\nEXPORT_SYMBOL(zil_suspend);\nEXPORT_SYMBOL(zil_resume);\nEXPORT_SYMBOL(zil_lwb_add_block);\nEXPORT_SYMBOL(zil_bp_tree_add);\nEXPORT_SYMBOL(zil_set_sync);\nEXPORT_SYMBOL(zil_set_logbias);\nEXPORT_SYMBOL(zil_sums_init);\nEXPORT_SYMBOL(zil_sums_fini);\nEXPORT_SYMBOL(zil_kstat_values_update);\n\nZFS_MODULE_PARAM(zfs, zfs_, commit_timeout_pct, UINT, ZMOD_RW,\n\t\"ZIL block open timeout percentage\");\n\nZFS_MODULE_PARAM(zfs_zil, zil_, min_commit_timeout, U64, ZMOD_RW,\n\t\"Minimum delay we care for ZIL block commit\");\n\nZFS_MODULE_PARAM(zfs_zil, zil_, replay_disable, INT, ZMOD_RW,\n\t\"Disable intent logging replay\");\n\nZFS_MODULE_PARAM(zfs_zil, zil_, nocacheflush, INT, ZMOD_RW,\n\t\"Disable ZIL cache flushes\");\n\nZFS_MODULE_PARAM(zfs_zil, zil_, slog_bulk, U64, ZMOD_RW,\n\t\"Limit in bytes slog sync writes per commit\");\n\nZFS_MODULE_PARAM(zfs_zil, zil_, maxblocksize, UINT, ZMOD_RW,\n\t\"Limit in bytes of ZIL log block size\");\n\nZFS_MODULE_PARAM(zfs_zil, zil_, maxcopied, UINT, ZMOD_RW,\n\t\"Limit in bytes WR_COPIED size\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}