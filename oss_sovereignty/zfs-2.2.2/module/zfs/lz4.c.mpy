{
  "module_name": "lz4.c",
  "hash_id": "9e60f5b9a7924a476de5dda1346c942823013200a67c3adad086fb5b4d054e00",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/lz4.c",
  "human_readable_source": " \n\n \n\n#include <sys/zfs_context.h>\n\nint LZ4_uncompress_unknownOutputSize(const char *source, char *dest,\n    int isize, int maxOutputSize);\n\n \n\n \n#define\tCOMPRESSIONLEVEL 12\n\n \n#define\tNOTCOMPRESSIBLE_CONFIRMATION 6\n\n \n#if defined(_ZFS_BIG_ENDIAN)\n#define\tLZ4_BIG_ENDIAN 1\n#else\n \n#undef LZ4_BIG_ENDIAN\n#endif\n\n \n \n#ifndef LZ4_FORCE_MEMORY_ACCESS    \n#  if defined(__GNUC__) && \\\n  ( defined(__ARM_ARCH_6__) || defined(__ARM_ARCH_6J__) || defined(__ARM_ARCH_6K__) \\\n  || defined(__ARM_ARCH_6Z__) || defined(__ARM_ARCH_6ZK__) || defined(__ARM_ARCH_6T2__) )\n#    define LZ4_FORCE_MEMORY_ACCESS 2\n#  elif (defined(__INTEL_COMPILER) && !defined(_WIN32)) || defined(__GNUC__)\n#    define LZ4_FORCE_MEMORY_ACCESS 1\n#  endif\n#endif\n\n \n \n#undef\tLZ4_FORCE_SW_BITCOUNT\n#if defined(__sunos__)\n#define\tLZ4_FORCE_SW_BITCOUNT\n#endif\n\n \n \n#define\trestrict\n\n \n#ifdef GCC_VERSION\n#undef GCC_VERSION\n#endif\n\n#define\tGCC_VERSION (__GNUC__ * 100 + __GNUC_MINOR__)\n\n#ifndef LZ4_FORCE_INLINE\n#  ifdef _MSC_VER     \n#    define LZ4_FORCE_INLINE static __forceinline\n#  else\n#    if defined (__cplusplus) || defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L    \n#      ifdef __GNUC__\n#        define LZ4_FORCE_INLINE static inline __attribute__((always_inline))\n#      else\n#        define LZ4_FORCE_INLINE static inline\n#      endif\n#    else\n#      define LZ4_FORCE_INLINE static\n#    endif  \n#  endif   \n#endif  \n\n \n#if defined(__PPC64__) && defined(__LITTLE_ENDIAN__) && defined(__GNUC__) && !defined(__clang__)\n#  define LZ4_FORCE_O2  __attribute__((optimize(\"O2\")))\n#  undef LZ4_FORCE_INLINE\n#  define LZ4_FORCE_INLINE  static __inline __attribute__((optimize(\"O2\"),always_inline))\n#else\n#  define LZ4_FORCE_O2\n#endif\n\n#ifndef expect\n#if (defined(__GNUC__) && (__GNUC__ >= 3)) || (defined(__INTEL_COMPILER) && (__INTEL_COMPILER >= 800)) || defined(__clang__)\n#  define expect(expr,value)    (__builtin_expect ((expr),(value)) )\n#else\n#  define expect(expr,value)    (expr)\n#endif\n#endif\n\n#ifndef likely\n#define\tlikely(expr)\texpect((expr) != 0, 1)\n#endif\n\n#ifndef unlikely\n#define\tunlikely(expr)\texpect((expr) != 0, 0)\n#endif\n\n#ifndef _KERNEL\n#include <stdlib.h>    \n#include <string.h>    \n#endif\n#define ALLOC(s)          malloc(s)\n#define ALLOC_AND_ZERO(s) calloc(1,s)\n#define FREEMEM(p)        free(p)\n\n#define MEM_INIT(p,v,s)   memset((p),(v),(s))\n\n\n \n#define MINMATCH 4\n\n#define WILDCOPYLENGTH 8\n#define LASTLITERALS   5    \n#define MFLIMIT       12    \n#define MATCH_SAFEGUARD_DISTANCE  ((2*WILDCOPYLENGTH) - MINMATCH)    \n#define FASTLOOP_SAFE_DISTANCE 64\n\n#define KB *(1 <<10)\n#define MB *(1 <<20)\n#define GB *(1U<<30)\n\n#ifndef LZ4_DISTANCE_MAX    \n#  define LZ4_DISTANCE_MAX 65535    \n#endif\n\n#define LZ4_DISTANCE_ABSOLUTE_MAX 65535\n#if (LZ4_DISTANCE_MAX > LZ4_DISTANCE_ABSOLUTE_MAX)    \n#  error \"LZ4_DISTANCE_MAX is too big : must be <= 65535\"\n#endif\n\n#define ML_BITS  4\n#define ML_MASK  ((1U<<ML_BITS)-1)\n#define RUN_BITS (8-ML_BITS)\n#define RUN_MASK ((1U<<RUN_BITS)-1)\n\n#define DEBUGLOG(l, ...) {}     \n\n#ifndef assert\n#define assert ASSERT\n#endif\n\n \n#ifndef _KERNEL\n#include <limits.h>\n#endif\n#if defined(__cplusplus) || (defined (__STDC_VERSION__) && (__STDC_VERSION__ >= 199901L)  )\n#ifndef _KERNEL\n#include <stdint.h>\n#endif\n  typedef  uint8_t BYTE;\n  typedef uint16_t U16;\n  typedef uint32_t U32;\n  typedef  int32_t S32;\n  typedef uint64_t U64;\n  typedef uintptr_t uptrval;\n#else\n# if UINT_MAX != 4294967295UL\n#   error \"LZ4 code (when not C++ or C99) assumes that sizeof(int) == 4\"\n# endif\n  typedef unsigned char       BYTE;\n  typedef unsigned short      U16;\n  typedef unsigned int        U32;\n  typedef   signed int        S32;\n  typedef unsigned long long  U64;\n  typedef size_t              uptrval;    \n#endif\n\n#if defined(__x86_64__)\n  typedef U64    reg_t;    \n#else\n  typedef size_t reg_t;    \n#endif\n\ntypedef enum {\n    notLimited = 0,\n    limitedOutput = 1,\n    fillOutput = 2\n} limitedOutput_directive;\n\n\n \n\n \n#if defined(__GNUC__) && (__GNUC__ >= 4)\n#define LZ4_memcpy(dst, src, size) __builtin_memcpy(dst, src, size)\n#else\n#define LZ4_memcpy(dst, src, size) memcpy(dst, src, size)\n#endif\n\nstatic unsigned LZ4_isLittleEndian(void)\n{\n    const union { U32 u; BYTE c[4]; } one = { 1 };    \n    return one.c[0];\n}\n\n\n#if defined(LZ4_FORCE_MEMORY_ACCESS) && (LZ4_FORCE_MEMORY_ACCESS==2)\n \n\nstatic U16 LZ4_read16(const void* memPtr) { return *(const U16*) memPtr; }\n\nstatic void LZ4_write16(void* memPtr, U16 value) { *(U16*)memPtr = value; }\nstatic void LZ4_write32(void* memPtr, U32 value) { *(U32*)memPtr = value; }\n\n#elif defined(LZ4_FORCE_MEMORY_ACCESS) && (LZ4_FORCE_MEMORY_ACCESS==1)\n\n \n \ntypedef union { U16 u16; U32 u32; reg_t uArch; } __attribute__((packed)) unalign;\n\nstatic U16 LZ4_read16(const void* ptr) { return ((const unalign*)ptr)->u16; }\n\nstatic void LZ4_write32(void* memPtr, U32 value) { ((unalign*)memPtr)->u32 = value; }\n\n#else   \n\nstatic U16 LZ4_read16(const void* memPtr)\n{\n    U16 val; LZ4_memcpy(&val, memPtr, sizeof(val)); return val;\n}\n\nstatic void LZ4_write32(void* memPtr, U32 value)\n{\n    LZ4_memcpy(memPtr, &value, sizeof(value));\n}\n\n#endif  \n\nstatic U16 LZ4_readLE16(const void* memPtr)\n{\n    if (LZ4_isLittleEndian()) {\n        return LZ4_read16(memPtr);\n    } else {\n        const BYTE* p = (const BYTE*)memPtr;\n        return (U16)((U16)p[0] + (p[1]<<8));\n    }\n}\n\n \nLZ4_FORCE_INLINE\nvoid LZ4_wildCopy8(void* dstPtr, const void* srcPtr, void* dstEnd)\n{\n    BYTE* d = (BYTE*)dstPtr;\n    const BYTE* s = (const BYTE*)srcPtr;\n    BYTE* const e = (BYTE*)dstEnd;\n\n    do { LZ4_memcpy(d,s,8); d+=8; s+=8; } while (d<e);\n}\n\nstatic const unsigned inc32table[8] = {0, 1, 2,  1,  0,  4, 4, 4};\nstatic const int      dec64table[8] = {0, 0, 0, -1, -4,  1, 2, 3};\n\n\n#ifndef LZ4_FAST_DEC_LOOP\n#  if defined __i386__ || defined _M_IX86 || defined __x86_64__ || defined _M_X64\n#    define LZ4_FAST_DEC_LOOP 1\n#  elif defined(__aarch64__) && !defined(__clang__)\n      \n#    define LZ4_FAST_DEC_LOOP 1\n#  else\n#    define LZ4_FAST_DEC_LOOP 0\n#  endif\n#endif\n\n#if LZ4_FAST_DEC_LOOP\n\nLZ4_FORCE_INLINE void\nLZ4_memcpy_using_offset_base(BYTE* dstPtr, const BYTE* srcPtr, BYTE* dstEnd, const size_t offset)\n{\n    assert(srcPtr + offset == dstPtr);\n    if (offset < 8) {\n        LZ4_write32(dstPtr, 0);    \n        dstPtr[0] = srcPtr[0];\n        dstPtr[1] = srcPtr[1];\n        dstPtr[2] = srcPtr[2];\n        dstPtr[3] = srcPtr[3];\n        srcPtr += inc32table[offset];\n        LZ4_memcpy(dstPtr+4, srcPtr, 4);\n        srcPtr -= dec64table[offset];\n        dstPtr += 8;\n    } else {\n        LZ4_memcpy(dstPtr, srcPtr, 8);\n        dstPtr += 8;\n        srcPtr += 8;\n    }\n\n    LZ4_wildCopy8(dstPtr, srcPtr, dstEnd);\n}\n\n \nLZ4_FORCE_INLINE void\nLZ4_wildCopy32(void* dstPtr, const void* srcPtr, void* dstEnd)\n{\n    BYTE* d = (BYTE*)dstPtr;\n    const BYTE* s = (const BYTE*)srcPtr;\n    BYTE* const e = (BYTE*)dstEnd;\n\n    do { LZ4_memcpy(d,s,16); LZ4_memcpy(d+16,s+16,16); d+=32; s+=32; } while (d<e);\n}\n\n \nLZ4_FORCE_INLINE void\nLZ4_memcpy_using_offset(BYTE* dstPtr, const BYTE* srcPtr, BYTE* dstEnd, const size_t offset)\n{\n    BYTE v[8];\n\n    assert(dstEnd >= dstPtr + MINMATCH);\n\n    switch(offset) {\n    case 1:\n        MEM_INIT(v, *srcPtr, 8);\n        break;\n    case 2:\n        LZ4_memcpy(v, srcPtr, 2);\n        LZ4_memcpy(&v[2], srcPtr, 2);\n        LZ4_memcpy(&v[4], v, 4);\n        break;\n    case 4:\n        LZ4_memcpy(v, srcPtr, 4);\n        LZ4_memcpy(&v[4], srcPtr, 4);\n        break;\n    default:\n        LZ4_memcpy_using_offset_base(dstPtr, srcPtr, dstEnd, offset);\n        return;\n    }\n\n    LZ4_memcpy(dstPtr, v, 8);\n    dstPtr += 8;\n    while (dstPtr < dstEnd) {\n        LZ4_memcpy(dstPtr, v, 8);\n        dstPtr += 8;\n    }\n}\n#endif\n\n\n \ntypedef enum { clearedTable = 0, byPtr, byU32, byU16 } tableType_t;\n\n \ntypedef enum { noDict = 0, withPrefix64k, usingExtDict, usingDictCtx } dict_directive;\ntypedef enum { noDictIssue = 0, dictSmall } dictIssue_directive;\n\n \n\ntypedef enum { endOnOutputSize = 0, endOnInputSize = 1 } endCondition_directive;\ntypedef enum { decode_full_block = 0, partial_decode = 1 } earlyEnd_directive;\n\ntypedef enum { loop_error = -2, initial_error = -1, ok = 0 } variable_length_error;\n\nLZ4_FORCE_INLINE unsigned\nread_variable_length(const BYTE**ip, const BYTE* lencheck,\n                     int loop_check, int initial_check,\n                     variable_length_error* error)\n{\n    U32 length = 0;\n    U32 s;\n    if (initial_check && unlikely((*ip) >= lencheck)) {     \n        *error = initial_error;\n        return length;\n    }\n    do {\n        s = **ip;\n        (*ip)++;\n        length += s;\n        if (loop_check && unlikely((*ip) >= lencheck)) {     \n            *error = loop_error;\n            return length;\n        }\n    } while (s==255);\n\n    return length;\n}\n\n#define\tLZ4_STATIC_ASSERT(c)\tASSERT(c)\n\n\n \nLZ4_FORCE_INLINE int\nLZ4_decompress_generic(\n                 const char* const src,\n                 char* const dst,\n                 int srcSize,\n                 int outputSize,          \n\n                 endCondition_directive endOnInput,    \n                 earlyEnd_directive partialDecoding,   \n                 dict_directive dict,                  \n                 const BYTE* const lowPrefix,   \n                 const BYTE* const dictStart,   \n                 const size_t dictSize          \n                 )\n{\n    if ((src == NULL) || (outputSize < 0)) { return -1; }\n\n    {   const BYTE* ip = (const BYTE*) src;\n        const BYTE* const iend = ip + srcSize;\n\n        BYTE* op = (BYTE*) dst;\n        BYTE* const oend = op + outputSize;\n        BYTE* cpy;\n\n        const BYTE* const dictEnd = (dictStart == NULL) ? NULL : dictStart + dictSize;\n\n        const int safeDecode = (endOnInput==endOnInputSize);\n        const int checkOffset = ((safeDecode) && (dictSize < (int)(64 KB)));\n\n\n         \n        const BYTE* const shortiend = iend - (endOnInput ? 14 : 8)   - 2  ;\n        const BYTE* const shortoend = oend - (endOnInput ? 14 : 8)   - 18  ;\n\n        const BYTE* match;\n        size_t offset;\n        unsigned token;\n        size_t length;\n\n\n        DEBUGLOG(5, \"LZ4_decompress_generic (srcSize:%i, dstSize:%i)\", srcSize, outputSize);\n\n         \n        assert(lowPrefix <= op);\n        if ((endOnInput) && (unlikely(outputSize==0))) {\n             \n            if (partialDecoding) return 0;\n            return ((srcSize==1) && (*ip==0)) ? 0 : -1;\n        }\n        if ((!endOnInput) && (unlikely(outputSize==0))) { return (*ip==0 ? 1 : -1); }\n        if ((endOnInput) && unlikely(srcSize==0)) { return -1; }\n\n\t \n#if LZ4_FAST_DEC_LOOP\n        if ((oend - op) < FASTLOOP_SAFE_DISTANCE) {\n            DEBUGLOG(6, \"skip fast decode loop\");\n            goto safe_decode;\n        }\n\n         \n        while (1) {\n             \n            assert(oend - op >= FASTLOOP_SAFE_DISTANCE);\n            if (endOnInput) { assert(ip < iend); }\n            token = *ip++;\n            length = token >> ML_BITS;   \n\n            assert(!endOnInput || ip <= iend);  \n\n             \n            if (length == RUN_MASK) {\n                variable_length_error error = ok;\n                length += read_variable_length(&ip, iend-RUN_MASK, (int)endOnInput, (int)endOnInput, &error);\n                if (error == initial_error) { goto _output_error; }\n                if ((safeDecode) && unlikely((uptrval)(op)+length<(uptrval)(op))) { goto _output_error; }  \n                if ((safeDecode) && unlikely((uptrval)(ip)+length<(uptrval)(ip))) { goto _output_error; }  \n\n                 \n                cpy = op+length;\n                LZ4_STATIC_ASSERT(MFLIMIT >= WILDCOPYLENGTH);\n                if (endOnInput) {   \n                    if ((cpy>oend-32) || (ip+length>iend-32)) { goto safe_literal_copy; }\n                    LZ4_wildCopy32(op, ip, cpy);\n                } else {    \n                    if (cpy>oend-8) { goto safe_literal_copy; }\n                    LZ4_wildCopy8(op, ip, cpy);  \n                }\n                ip += length; op = cpy;\n            } else {\n                cpy = op+length;\n                if (endOnInput) {   \n                    DEBUGLOG(7, \"copy %u bytes in a 16-bytes stripe\", (unsigned)length);\n                     \n                    if (ip > iend-(16 + 1 )) { goto safe_literal_copy; }\n                     \n                    LZ4_memcpy(op, ip, 16);\n                } else {   \n                     \n                    LZ4_memcpy(op, ip, 8);\n                    if (length > 8) { LZ4_memcpy(op+8, ip+8, 8); }\n                }\n                ip += length; op = cpy;\n            }\n\n             \n            offset = LZ4_readLE16(ip); ip+=2;\n            match = op - offset;\n            assert(match <= op);\n\n             \n            length = token & ML_MASK;\n\n            if (length == ML_MASK) {\n                variable_length_error error = ok;\n                if ((checkOffset) && (unlikely(match + dictSize < lowPrefix))) { goto _output_error; }  \n                length += read_variable_length(&ip, iend - LASTLITERALS + 1, (int)endOnInput, 0, &error);\n                if (error != ok) { goto _output_error; }\n                if ((safeDecode) && unlikely((uptrval)(op)+length<(uptrval)op)) { goto _output_error; }  \n                length += MINMATCH;\n                if (op + length >= oend - FASTLOOP_SAFE_DISTANCE) {\n                    goto safe_match_copy;\n                }\n            } else {\n                length += MINMATCH;\n                if (op + length >= oend - FASTLOOP_SAFE_DISTANCE) {\n                    goto safe_match_copy;\n                }\n\n                 \n                if ((dict == withPrefix64k) || (match >= lowPrefix)) {\n                    if (offset >= 8) {\n                        assert(match >= lowPrefix);\n                        assert(match <= op);\n                        assert(op + 18 <= oend);\n\n                        LZ4_memcpy(op, match, 8);\n                        LZ4_memcpy(op+8, match+8, 8);\n                        LZ4_memcpy(op+16, match+16, 2);\n                        op += length;\n                        continue;\n            }   }   }\n\n            if (checkOffset && (unlikely(match + dictSize < lowPrefix))) { goto _output_error; }  \n             \n            if ((dict==usingExtDict) && (match < lowPrefix)) {\n                if (unlikely(op+length > oend-LASTLITERALS)) {\n                    if (partialDecoding) {\n                        DEBUGLOG(7, \"partialDecoding: dictionary match, close to dstEnd\");\n                        length = MIN(length, (size_t)(oend-op));\n                    } else {\n                        goto _output_error;   \n                }   }\n\n                if (length <= (size_t)(lowPrefix-match)) {\n                     \n                    memmove(op, dictEnd - (lowPrefix-match), length);\n                    op += length;\n                } else {\n                     \n                    size_t const copySize = (size_t)(lowPrefix - match);\n                    size_t const restSize = length - copySize;\n                    LZ4_memcpy(op, dictEnd - copySize, copySize);\n                    op += copySize;\n                    if (restSize > (size_t)(op - lowPrefix)) {   \n                        BYTE* const endOfMatch = op + restSize;\n                        const BYTE* copyFrom = lowPrefix;\n                        while (op < endOfMatch) { *op++ = *copyFrom++; }\n                    } else {\n                        LZ4_memcpy(op, lowPrefix, restSize);\n                        op += restSize;\n                }   }\n                continue;\n            }\n\n             \n            cpy = op + length;\n\n            assert((op <= oend) && (oend-op >= 32));\n            if (unlikely(offset<16)) {\n                LZ4_memcpy_using_offset(op, match, cpy, offset);\n            } else {\n                LZ4_wildCopy32(op, match, cpy);\n            }\n\n            op = cpy;    \n        }\n    safe_decode:\n#endif\n\n         \n        while (1) {\n            token = *ip++;\n            length = token >> ML_BITS;   \n\n            assert(!endOnInput || ip <= iend);  \n\n             \n            if ( (endOnInput ? length != RUN_MASK : length <= 8)\n                 \n              && likely((endOnInput ? ip < shortiend : 1) & (op <= shortoend)) ) {\n                 \n                LZ4_memcpy(op, ip, endOnInput ? 16 : 8);\n                op += length; ip += length;\n\n                 \n                length = token & ML_MASK;  \n                offset = LZ4_readLE16(ip); ip += 2;\n                match = op - offset;\n                assert(match <= op);  \n\n                 \n                if ( (length != ML_MASK)\n                  && (offset >= 8)\n                  && (dict==withPrefix64k || match >= lowPrefix) ) {\n                     \n                    LZ4_memcpy(op + 0, match + 0, 8);\n                    LZ4_memcpy(op + 8, match + 8, 8);\n                    LZ4_memcpy(op +16, match +16, 2);\n                    op += length + MINMATCH;\n                     \n                    continue;\n                }\n\n                 \n                goto _copy_match;\n            }\n\n             \n            if (length == RUN_MASK) {\n                variable_length_error error = ok;\n                length += read_variable_length(&ip, iend-RUN_MASK, (int)endOnInput, (int)endOnInput, &error);\n                if (error == initial_error) { goto _output_error; }\n                if ((safeDecode) && unlikely((uptrval)(op)+length<(uptrval)(op))) { goto _output_error; }  \n                if ((safeDecode) && unlikely((uptrval)(ip)+length<(uptrval)(ip))) { goto _output_error; }  \n            }\n\n             \n            cpy = op+length;\n#if LZ4_FAST_DEC_LOOP\n        safe_literal_copy:\n#endif\n            LZ4_STATIC_ASSERT(MFLIMIT >= WILDCOPYLENGTH);\n            if ( ((endOnInput) && ((cpy>oend-MFLIMIT) || (ip+length>iend-(2+1+LASTLITERALS))) )\n              || ((!endOnInput) && (cpy>oend-WILDCOPYLENGTH)) )\n            {\n                 \n                if (partialDecoding) {\n                     \n                    assert(endOnInput);\n                    DEBUGLOG(7, \"partialDecoding: copying literals, close to input or output end\")\n                    DEBUGLOG(7, \"partialDecoding: literal length = %u\", (unsigned)length);\n                    DEBUGLOG(7, \"partialDecoding: remaining space in dstBuffer : %i\", (int)(oend - op));\n                    DEBUGLOG(7, \"partialDecoding: remaining space in srcBuffer : %i\", (int)(iend - ip));\n                     \n                    if (ip+length > iend) {\n                        length = (size_t)(iend-ip);\n                        cpy = op + length;\n                    }\n                     \n                    if (cpy > oend) {\n                        cpy = oend;\n                        assert(op<=oend);\n                        length = (size_t)(oend-op);\n                    }\n                } else {\n                     \n                    if ((!endOnInput) && (cpy != oend)) { goto _output_error; }\n                      \n                    if ((endOnInput) && ((ip+length != iend) || (cpy > oend))) {\n                        DEBUGLOG(6, \"should have been last run of literals\")\n                        DEBUGLOG(6, \"ip(%p) + length(%i) = %p != iend (%p)\", ip, (int)length, ip+length, iend);\n                        DEBUGLOG(6, \"or cpy(%p) > oend(%p)\", cpy, oend);\n                        goto _output_error;\n                    }\n                }\n                memmove(op, ip, length);   \n                ip += length;\n                op += length;\n                 \n                if (!partialDecoding || (cpy == oend) || (ip >= (iend-2))) {\n                    break;\n                }\n            } else {\n                LZ4_wildCopy8(op, ip, cpy);    \n                ip += length; op = cpy;\n            }\n\n             \n            offset = LZ4_readLE16(ip); ip+=2;\n            match = op - offset;\n\n             \n            length = token & ML_MASK;\n\n    _copy_match:\n            if (length == ML_MASK) {\n              variable_length_error error = ok;\n              length += read_variable_length(&ip, iend - LASTLITERALS + 1, (int)endOnInput, 0, &error);\n              if (error != ok) goto _output_error;\n                if ((safeDecode) && unlikely((uptrval)(op)+length<(uptrval)op)) goto _output_error;    \n            }\n            length += MINMATCH;\n\n#if LZ4_FAST_DEC_LOOP\n        safe_match_copy:\n#endif\n            if ((checkOffset) && (unlikely(match + dictSize < lowPrefix))) goto _output_error;    \n             \n            if ((dict==usingExtDict) && (match < lowPrefix)) {\n                if (unlikely(op+length > oend-LASTLITERALS)) {\n                    if (partialDecoding) length = MIN(length, (size_t)(oend-op));\n                    else goto _output_error;    \n                }\n\n                if (length <= (size_t)(lowPrefix-match)) {\n                     \n                    memmove(op, dictEnd - (lowPrefix-match), length);\n                    op += length;\n                } else {\n                     \n                    size_t const copySize = (size_t)(lowPrefix - match);\n                    size_t const restSize = length - copySize;\n                    LZ4_memcpy(op, dictEnd - copySize, copySize);\n                    op += copySize;\n                    if (restSize > (size_t)(op - lowPrefix)) {   \n                        BYTE* const endOfMatch = op + restSize;\n                        const BYTE* copyFrom = lowPrefix;\n                        while (op < endOfMatch) *op++ = *copyFrom++;\n                    } else {\n                        LZ4_memcpy(op, lowPrefix, restSize);\n                        op += restSize;\n                }   }\n                continue;\n            }\n            assert(match >= lowPrefix);\n\n             \n            cpy = op + length;\n\n             \n            assert(op<=oend);\n            if (partialDecoding && (cpy > oend-MATCH_SAFEGUARD_DISTANCE)) {\n                size_t const mlen = MIN(length, (size_t)(oend-op));\n                const BYTE* const matchEnd = match + mlen;\n                BYTE* const copyEnd = op + mlen;\n                if (matchEnd > op) {    \n                    while (op < copyEnd) { *op++ = *match++; }\n                } else {\n                    LZ4_memcpy(op, match, mlen);\n                }\n                op = copyEnd;\n                if (op == oend) { break; }\n                continue;\n            }\n\n            if (unlikely(offset<8)) {\n                LZ4_write32(op, 0);    \n                op[0] = match[0];\n                op[1] = match[1];\n                op[2] = match[2];\n                op[3] = match[3];\n                match += inc32table[offset];\n                LZ4_memcpy(op+4, match, 4);\n                match -= dec64table[offset];\n            } else {\n                LZ4_memcpy(op, match, 8);\n                match += 8;\n            }\n            op += 8;\n\n            if (unlikely(cpy > oend-MATCH_SAFEGUARD_DISTANCE)) {\n                BYTE* const oCopyLimit = oend - (WILDCOPYLENGTH-1);\n                if (cpy > oend-LASTLITERALS) { goto _output_error; }  \n                if (op < oCopyLimit) {\n                    LZ4_wildCopy8(op, match, oCopyLimit);\n                    match += oCopyLimit - op;\n                    op = oCopyLimit;\n                }\n                while (op < cpy) { *op++ = *match++; }\n            } else {\n                LZ4_memcpy(op, match, 8);\n                if (length > 16)  { LZ4_wildCopy8(op+8, match+8, cpy); }\n            }\n            op = cpy;    \n        }\n\n         \n        if (endOnInput) {\n            DEBUGLOG(5, \"decoded %i bytes\", (int) (((char*)op)-dst));\n           return (int) (((char*)op)-dst);      \n       } else {\n           return (int) (((const char*)ip)-src);    \n       }\n\n         \n    _output_error:\n        return (int) (-(((const char*)ip)-src))-1;\n    }\n}\n\n \n\n \nint LZ4_uncompress_unknownOutputSize(const char* source, char* dest, int compressedSize, int maxDecompressedSize)\n{\n    return LZ4_decompress_generic(source, dest, compressedSize, maxDecompressedSize,\n                                  endOnInputSize, decode_full_block, noDict,\n                                  (BYTE*)dest, NULL, 0);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}