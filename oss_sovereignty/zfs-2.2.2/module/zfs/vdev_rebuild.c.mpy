{
  "module_name": "vdev_rebuild.c",
  "hash_id": "f106a07e08b1e0d625b769e6cd3e165a3253a8daa11b7167b835710b3ddd3878",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/vdev_rebuild.c",
  "human_readable_source": " \n \n\n#include <sys/vdev_impl.h>\n#include <sys/vdev_draid.h>\n#include <sys/dsl_scan.h>\n#include <sys/spa_impl.h>\n#include <sys/metaslab_impl.h>\n#include <sys/vdev_rebuild.h>\n#include <sys/zio.h>\n#include <sys/dmu_tx.h>\n#include <sys/arc.h>\n#include <sys/arc_impl.h>\n#include <sys/zap.h>\n\n \n\n\n \nstatic uint64_t zfs_rebuild_max_segment = 1024 * 1024;\n\n \nstatic uint64_t zfs_rebuild_vdev_limit = 64 << 20;\n\n \nstatic int zfs_rebuild_scrub_enabled = 1;\n\n \nstatic __attribute__((noreturn)) void vdev_rebuild_thread(void *arg);\nstatic void vdev_rebuild_reset_sync(void *arg, dmu_tx_t *tx);\n\n \nstatic void\nclear_rebuild_bytes(vdev_t *vd)\n{\n\tvdev_stat_t *vs = &vd->vdev_stat;\n\n\tfor (uint64_t i = 0; i < vd->vdev_children; i++)\n\t\tclear_rebuild_bytes(vd->vdev_child[i]);\n\n\tmutex_enter(&vd->vdev_stat_lock);\n\tvs->vs_rebuild_processed = 0;\n\tmutex_exit(&vd->vdev_stat_lock);\n}\n\n \nstatic boolean_t\nvdev_rebuild_should_stop(vdev_t *vd)\n{\n\treturn (!vdev_writeable(vd) || vd->vdev_removing ||\n\t    vd->vdev_rebuild_exit_wanted ||\n\t    vd->vdev_rebuild_cancel_wanted ||\n\t    vd->vdev_rebuild_reset_wanted);\n}\n\n \nstatic boolean_t\nvdev_rebuild_should_cancel(vdev_t *vd)\n{\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\n\tif (!vdev_resilver_needed(vd, &vrp->vrp_min_txg, &vrp->vrp_max_txg))\n\t\treturn (B_TRUE);\n\n\treturn (B_FALSE);\n}\n\n \nstatic void\nvdev_rebuild_update_sync(void *arg, dmu_tx_t *tx)\n{\n\tint vdev_id = (uintptr_t)arg;\n\tspa_t *spa = dmu_tx_pool(tx)->dp_spa;\n\tvdev_t *vd = vdev_lookup_top(spa, vdev_id);\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\tuint64_t txg = dmu_tx_get_txg(tx);\n\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\n\tif (vr->vr_scan_offset[txg & TXG_MASK] > 0) {\n\t\tvrp->vrp_last_offset = vr->vr_scan_offset[txg & TXG_MASK];\n\t\tvr->vr_scan_offset[txg & TXG_MASK] = 0;\n\t}\n\n\tvrp->vrp_scan_time_ms = vr->vr_prev_scan_time_ms +\n\t    NSEC2MSEC(gethrtime() - vr->vr_pass_start_time);\n\n\tVERIFY0(zap_update(vd->vdev_spa->spa_meta_objset, vd->vdev_top_zap,\n\t    VDEV_TOP_ZAP_VDEV_REBUILD_PHYS, sizeof (uint64_t),\n\t    REBUILD_PHYS_ENTRIES, vrp, tx));\n\n\tmutex_exit(&vd->vdev_rebuild_lock);\n}\n\n \nstatic void\nvdev_rebuild_initiate_sync(void *arg, dmu_tx_t *tx)\n{\n\tint vdev_id = (uintptr_t)arg;\n\tspa_t *spa = dmu_tx_pool(tx)->dp_spa;\n\tvdev_t *vd = vdev_lookup_top(spa, vdev_id);\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\n\tASSERT(vd->vdev_rebuilding);\n\n\tspa_feature_incr(vd->vdev_spa, SPA_FEATURE_DEVICE_REBUILD, tx);\n\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\tmemset(vrp, 0, sizeof (uint64_t) * REBUILD_PHYS_ENTRIES);\n\tvrp->vrp_rebuild_state = VDEV_REBUILD_ACTIVE;\n\tvrp->vrp_min_txg = 0;\n\tvrp->vrp_max_txg = dmu_tx_get_txg(tx);\n\tvrp->vrp_start_time = gethrestime_sec();\n\tvrp->vrp_scan_time_ms = 0;\n\tvr->vr_prev_scan_time_ms = 0;\n\n\t \n\tVERIFY(vdev_resilver_needed(vd, &vrp->vrp_min_txg, &vrp->vrp_max_txg));\n\n\tVERIFY0(zap_update(vd->vdev_spa->spa_meta_objset, vd->vdev_top_zap,\n\t    VDEV_TOP_ZAP_VDEV_REBUILD_PHYS, sizeof (uint64_t),\n\t    REBUILD_PHYS_ENTRIES, vrp, tx));\n\n\tspa_history_log_internal(spa, \"rebuild\", tx,\n\t    \"vdev_id=%llu vdev_guid=%llu started\",\n\t    (u_longlong_t)vd->vdev_id, (u_longlong_t)vd->vdev_guid);\n\n\tASSERT3P(vd->vdev_rebuild_thread, ==, NULL);\n\tvd->vdev_rebuild_thread = thread_create(NULL, 0,\n\t    vdev_rebuild_thread, vd, 0, &p0, TS_RUN, maxclsyspri);\n\n\tmutex_exit(&vd->vdev_rebuild_lock);\n}\n\nstatic void\nvdev_rebuild_log_notify(spa_t *spa, vdev_t *vd, const char *name)\n{\n\tnvlist_t *aux = fnvlist_alloc();\n\n\tfnvlist_add_string(aux, ZFS_EV_RESILVER_TYPE, \"sequential\");\n\tspa_event_notify(spa, vd, aux, name);\n\tnvlist_free(aux);\n}\n\n \nstatic void\nvdev_rebuild_initiate(vdev_t *vd)\n{\n\tspa_t *spa = vd->vdev_spa;\n\n\tASSERT(vd->vdev_top == vd);\n\tASSERT(MUTEX_HELD(&vd->vdev_rebuild_lock));\n\tASSERT(!vd->vdev_rebuilding);\n\n\tdmu_tx_t *tx = dmu_tx_create_dd(spa_get_dsl(spa)->dp_mos_dir);\n\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT));\n\n\tvd->vdev_rebuilding = B_TRUE;\n\n\tdsl_sync_task_nowait(spa_get_dsl(spa), vdev_rebuild_initiate_sync,\n\t    (void *)(uintptr_t)vd->vdev_id, tx);\n\tdmu_tx_commit(tx);\n\n\tvdev_rebuild_log_notify(spa, vd, ESC_ZFS_RESILVER_START);\n}\n\n \nstatic void\nvdev_rebuild_complete_sync(void *arg, dmu_tx_t *tx)\n{\n\tint vdev_id = (uintptr_t)arg;\n\tspa_t *spa = dmu_tx_pool(tx)->dp_spa;\n\tvdev_t *vd = vdev_lookup_top(spa, vdev_id);\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\n\t \n\tif (vd->vdev_rebuild_reset_wanted) {\n\t\tmutex_exit(&vd->vdev_rebuild_lock);\n\t\tvdev_rebuild_reset_sync(arg, tx);\n\t\treturn;\n\t}\n\n\tvrp->vrp_rebuild_state = VDEV_REBUILD_COMPLETE;\n\tvrp->vrp_end_time = gethrestime_sec();\n\n\tVERIFY0(zap_update(vd->vdev_spa->spa_meta_objset, vd->vdev_top_zap,\n\t    VDEV_TOP_ZAP_VDEV_REBUILD_PHYS, sizeof (uint64_t),\n\t    REBUILD_PHYS_ENTRIES, vrp, tx));\n\n\tvdev_dtl_reassess(vd, tx->tx_txg, vrp->vrp_max_txg, B_TRUE, B_TRUE);\n\tspa_feature_decr(vd->vdev_spa, SPA_FEATURE_DEVICE_REBUILD, tx);\n\n\tspa_history_log_internal(spa, \"rebuild\",  tx,\n\t    \"vdev_id=%llu vdev_guid=%llu complete\",\n\t    (u_longlong_t)vd->vdev_id, (u_longlong_t)vd->vdev_guid);\n\tvdev_rebuild_log_notify(spa, vd, ESC_ZFS_RESILVER_FINISH);\n\n\t \n\tspa_async_request(spa, SPA_ASYNC_REBUILD_DONE);\n\tvd->vdev_rebuilding = B_FALSE;\n\tmutex_exit(&vd->vdev_rebuild_lock);\n\n\t \n\tpool_scan_func_t func = POOL_SCAN_SCRUB;\n\tif (dsl_scan_setup_check(&func, tx) == 0 &&\n\t    zfs_rebuild_scrub_enabled) {\n\t\tdsl_scan_setup_sync(&func, tx);\n\t}\n\n\tcv_broadcast(&vd->vdev_rebuild_cv);\n\n\t \n\tzfs_ereport_clear(spa, NULL);\n}\n\n \nstatic void\nvdev_rebuild_cancel_sync(void *arg, dmu_tx_t *tx)\n{\n\tint vdev_id = (uintptr_t)arg;\n\tspa_t *spa = dmu_tx_pool(tx)->dp_spa;\n\tvdev_t *vd = vdev_lookup_top(spa, vdev_id);\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\tvrp->vrp_rebuild_state = VDEV_REBUILD_CANCELED;\n\tvrp->vrp_end_time = gethrestime_sec();\n\n\tVERIFY0(zap_update(vd->vdev_spa->spa_meta_objset, vd->vdev_top_zap,\n\t    VDEV_TOP_ZAP_VDEV_REBUILD_PHYS, sizeof (uint64_t),\n\t    REBUILD_PHYS_ENTRIES, vrp, tx));\n\n\tspa_feature_decr(vd->vdev_spa, SPA_FEATURE_DEVICE_REBUILD, tx);\n\n\tspa_history_log_internal(spa, \"rebuild\",  tx,\n\t    \"vdev_id=%llu vdev_guid=%llu canceled\",\n\t    (u_longlong_t)vd->vdev_id, (u_longlong_t)vd->vdev_guid);\n\tvdev_rebuild_log_notify(spa, vd, ESC_ZFS_RESILVER_FINISH);\n\n\tvd->vdev_rebuild_cancel_wanted = B_FALSE;\n\tvd->vdev_rebuilding = B_FALSE;\n\tmutex_exit(&vd->vdev_rebuild_lock);\n\n\tspa_notify_waiters(spa);\n\tcv_broadcast(&vd->vdev_rebuild_cv);\n}\n\n \nstatic void\nvdev_rebuild_reset_sync(void *arg, dmu_tx_t *tx)\n{\n\tint vdev_id = (uintptr_t)arg;\n\tspa_t *spa = dmu_tx_pool(tx)->dp_spa;\n\tvdev_t *vd = vdev_lookup_top(spa, vdev_id);\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\n\tASSERT(vrp->vrp_rebuild_state == VDEV_REBUILD_ACTIVE);\n\tASSERT3P(vd->vdev_rebuild_thread, ==, NULL);\n\n\tvrp->vrp_last_offset = 0;\n\tvrp->vrp_min_txg = 0;\n\tvrp->vrp_max_txg = dmu_tx_get_txg(tx);\n\tvrp->vrp_bytes_scanned = 0;\n\tvrp->vrp_bytes_issued = 0;\n\tvrp->vrp_bytes_rebuilt = 0;\n\tvrp->vrp_bytes_est = 0;\n\tvrp->vrp_scan_time_ms = 0;\n\tvr->vr_prev_scan_time_ms = 0;\n\n\t \n\tVERIFY(vdev_resilver_needed(vd, &vrp->vrp_min_txg, &vrp->vrp_max_txg));\n\n\tVERIFY0(zap_update(vd->vdev_spa->spa_meta_objset, vd->vdev_top_zap,\n\t    VDEV_TOP_ZAP_VDEV_REBUILD_PHYS, sizeof (uint64_t),\n\t    REBUILD_PHYS_ENTRIES, vrp, tx));\n\n\tspa_history_log_internal(spa, \"rebuild\",  tx,\n\t    \"vdev_id=%llu vdev_guid=%llu reset\",\n\t    (u_longlong_t)vd->vdev_id, (u_longlong_t)vd->vdev_guid);\n\n\tvd->vdev_rebuild_reset_wanted = B_FALSE;\n\tASSERT(vd->vdev_rebuilding);\n\n\tvd->vdev_rebuild_thread = thread_create(NULL, 0,\n\t    vdev_rebuild_thread, vd, 0, &p0, TS_RUN, maxclsyspri);\n\n\tmutex_exit(&vd->vdev_rebuild_lock);\n}\n\n \nvoid\nvdev_rebuild_clear_sync(void *arg, dmu_tx_t *tx)\n{\n\tint vdev_id = (uintptr_t)arg;\n\tspa_t *spa = dmu_tx_pool(tx)->dp_spa;\n\tvdev_t *vd = vdev_lookup_top(spa, vdev_id);\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\tobjset_t *mos = spa_meta_objset(spa);\n\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\n\tif (!spa_feature_is_enabled(spa, SPA_FEATURE_DEVICE_REBUILD) ||\n\t    vrp->vrp_rebuild_state == VDEV_REBUILD_ACTIVE) {\n\t\tmutex_exit(&vd->vdev_rebuild_lock);\n\t\treturn;\n\t}\n\n\tclear_rebuild_bytes(vd);\n\tmemset(vrp, 0, sizeof (uint64_t) * REBUILD_PHYS_ENTRIES);\n\n\tif (vd->vdev_top_zap != 0 && zap_contains(mos, vd->vdev_top_zap,\n\t    VDEV_TOP_ZAP_VDEV_REBUILD_PHYS) == 0) {\n\t\tVERIFY0(zap_update(mos, vd->vdev_top_zap,\n\t\t    VDEV_TOP_ZAP_VDEV_REBUILD_PHYS, sizeof (uint64_t),\n\t\t    REBUILD_PHYS_ENTRIES, vrp, tx));\n\t}\n\n\tmutex_exit(&vd->vdev_rebuild_lock);\n}\n\n \nstatic void\nvdev_rebuild_cb(zio_t *zio)\n{\n\tvdev_rebuild_t *vr = zio->io_private;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\tvdev_t *vd = vr->vr_top_vdev;\n\n\tmutex_enter(&vr->vr_io_lock);\n\tif (zio->io_error == ENXIO && !vdev_writeable(vd)) {\n\t\t \n\t\tuint64_t *off = &vr->vr_scan_offset[zio->io_txg & TXG_MASK];\n\t\t*off = MIN(*off, zio->io_offset);\n\t} else if (zio->io_error) {\n\t\tvrp->vrp_errors++;\n\t}\n\n\tabd_free(zio->io_abd);\n\n\tASSERT3U(vr->vr_bytes_inflight, >, 0);\n\tvr->vr_bytes_inflight -= zio->io_size;\n\tcv_broadcast(&vr->vr_io_cv);\n\tmutex_exit(&vr->vr_io_lock);\n\n\tspa_config_exit(vd->vdev_spa, SCL_STATE_ALL, vd);\n}\n\n \nstatic void\nvdev_rebuild_blkptr_init(blkptr_t *bp, vdev_t *vd, uint64_t start,\n    uint64_t asize)\n{\n\tASSERT(vd->vdev_ops == &vdev_draid_ops ||\n\t    vd->vdev_ops == &vdev_mirror_ops ||\n\t    vd->vdev_ops == &vdev_replacing_ops ||\n\t    vd->vdev_ops == &vdev_spare_ops);\n\n\tuint64_t psize = vd->vdev_ops == &vdev_draid_ops ?\n\t    vdev_draid_asize_to_psize(vd, asize) : asize;\n\n\tBP_ZERO(bp);\n\n\tDVA_SET_VDEV(&bp->blk_dva[0], vd->vdev_id);\n\tDVA_SET_OFFSET(&bp->blk_dva[0], start);\n\tDVA_SET_GANG(&bp->blk_dva[0], 0);\n\tDVA_SET_ASIZE(&bp->blk_dva[0], asize);\n\n\tBP_SET_BIRTH(bp, TXG_INITIAL, TXG_INITIAL);\n\tBP_SET_LSIZE(bp, psize);\n\tBP_SET_PSIZE(bp, psize);\n\tBP_SET_COMPRESS(bp, ZIO_COMPRESS_OFF);\n\tBP_SET_CHECKSUM(bp, ZIO_CHECKSUM_OFF);\n\tBP_SET_TYPE(bp, DMU_OT_NONE);\n\tBP_SET_LEVEL(bp, 0);\n\tBP_SET_DEDUP(bp, 0);\n\tBP_SET_BYTEORDER(bp, ZFS_HOST_BYTEORDER);\n}\n\n \nstatic int\nvdev_rebuild_range(vdev_rebuild_t *vr, uint64_t start, uint64_t size)\n{\n\tuint64_t ms_id __maybe_unused = vr->vr_scan_msp->ms_id;\n\tvdev_t *vd = vr->vr_top_vdev;\n\tspa_t *spa = vd->vdev_spa;\n\tblkptr_t blk;\n\n\tASSERT3U(ms_id, ==, start >> vd->vdev_ms_shift);\n\tASSERT3U(ms_id, ==, (start + size - 1) >> vd->vdev_ms_shift);\n\n\tvr->vr_pass_bytes_scanned += size;\n\tvr->vr_rebuild_phys.vrp_bytes_scanned += size;\n\n\t \n\tvdev_rebuild_blkptr_init(&blk, vd, start, size);\n\tuint64_t psize = BP_GET_PSIZE(&blk);\n\n\tif (!vdev_dtl_need_resilver(vd, &blk.blk_dva[0], psize, TXG_UNKNOWN)) {\n\t\tvr->vr_pass_bytes_skipped += size;\n\t\treturn (0);\n\t}\n\n\tmutex_enter(&vr->vr_io_lock);\n\n\t \n\twhile (vr->vr_bytes_inflight >= vr->vr_bytes_inflight_max)\n\t\tcv_wait(&vr->vr_io_cv, &vr->vr_io_lock);\n\n\tvr->vr_bytes_inflight += psize;\n\tmutex_exit(&vr->vr_io_lock);\n\n\tdmu_tx_t *tx = dmu_tx_create_dd(spa_get_dsl(spa)->dp_mos_dir);\n\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT));\n\tuint64_t txg = dmu_tx_get_txg(tx);\n\n\tspa_config_enter(spa, SCL_STATE_ALL, vd, RW_READER);\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\n\t \n\tif (vr->vr_scan_offset[txg & TXG_MASK] == 0) {\n\t\tvr->vr_scan_offset[txg & TXG_MASK] = start;\n\t\tdsl_sync_task_nowait(spa_get_dsl(spa),\n\t\t    vdev_rebuild_update_sync,\n\t\t    (void *)(uintptr_t)vd->vdev_id, tx);\n\t}\n\n\t \n\tif (vdev_rebuild_should_stop(vd)) {\n\t\tmutex_enter(&vr->vr_io_lock);\n\t\tvr->vr_bytes_inflight -= psize;\n\t\tmutex_exit(&vr->vr_io_lock);\n\t\tspa_config_exit(vd->vdev_spa, SCL_STATE_ALL, vd);\n\t\tmutex_exit(&vd->vdev_rebuild_lock);\n\t\tdmu_tx_commit(tx);\n\t\treturn (SET_ERROR(EINTR));\n\t}\n\tmutex_exit(&vd->vdev_rebuild_lock);\n\tdmu_tx_commit(tx);\n\n\tvr->vr_scan_offset[txg & TXG_MASK] = start + size;\n\tvr->vr_pass_bytes_issued += size;\n\tvr->vr_rebuild_phys.vrp_bytes_issued += size;\n\n\tzio_nowait(zio_read(spa->spa_txg_zio[txg & TXG_MASK], spa, &blk,\n\t    abd_alloc(psize, B_FALSE), psize, vdev_rebuild_cb, vr,\n\t    ZIO_PRIORITY_REBUILD, ZIO_FLAG_RAW | ZIO_FLAG_CANFAIL |\n\t    ZIO_FLAG_RESILVER, NULL));\n\n\treturn (0);\n}\n\n \nstatic int\nvdev_rebuild_ranges(vdev_rebuild_t *vr)\n{\n\tvdev_t *vd = vr->vr_top_vdev;\n\tzfs_btree_t *t = &vr->vr_scan_tree->rt_root;\n\tzfs_btree_index_t idx;\n\tint error;\n\n\tfor (range_seg_t *rs = zfs_btree_first(t, &idx); rs != NULL;\n\t    rs = zfs_btree_next(t, &idx, &idx)) {\n\t\tuint64_t start = rs_get_start(rs, vr->vr_scan_tree);\n\t\tuint64_t size = rs_get_end(rs, vr->vr_scan_tree) - start;\n\n\t\t \n\t\twhile (zfs_scan_suspend_progress &&\n\t\t    !vdev_rebuild_should_stop(vd)) {\n\t\t\tdelay(hz);\n\t\t}\n\n\t\twhile (size > 0) {\n\t\t\tuint64_t chunk_size;\n\n\t\t\t \n\t\t\tASSERT3P(vd->vdev_ops, !=, NULL);\n\t\t\tchunk_size = vd->vdev_ops->vdev_op_rebuild_asize(vd,\n\t\t\t    start, size, zfs_rebuild_max_segment);\n\n\t\t\terror = vdev_rebuild_range(vr, start, chunk_size);\n\t\t\tif (error != 0)\n\t\t\t\treturn (error);\n\n\t\t\tsize -= chunk_size;\n\t\t\tstart += chunk_size;\n\t\t}\n\t}\n\n\treturn (0);\n}\n\n \nstatic void\nvdev_rebuild_update_bytes_est(vdev_t *vd, uint64_t ms_id)\n{\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\tuint64_t bytes_est = vrp->vrp_bytes_scanned;\n\n\tif (vrp->vrp_last_offset < vd->vdev_ms[ms_id]->ms_start)\n\t\treturn;\n\n\tfor (uint64_t i = ms_id; i < vd->vdev_ms_count; i++) {\n\t\tmetaslab_t *msp = vd->vdev_ms[i];\n\n\t\tmutex_enter(&msp->ms_lock);\n\t\tbytes_est += metaslab_allocated_space(msp);\n\t\tmutex_exit(&msp->ms_lock);\n\t}\n\n\tvrp->vrp_bytes_est = bytes_est;\n}\n\n \nint\nvdev_rebuild_load(vdev_t *vd)\n{\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\tspa_t *spa = vd->vdev_spa;\n\tint err = 0;\n\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\tvd->vdev_rebuilding = B_FALSE;\n\n\tif (!spa_feature_is_enabled(spa, SPA_FEATURE_DEVICE_REBUILD)) {\n\t\tmemset(vrp, 0, sizeof (uint64_t) * REBUILD_PHYS_ENTRIES);\n\t\tmutex_exit(&vd->vdev_rebuild_lock);\n\t\treturn (SET_ERROR(ENOTSUP));\n\t}\n\n\tASSERT(vd->vdev_top == vd);\n\n\terr = zap_lookup(spa->spa_meta_objset, vd->vdev_top_zap,\n\t    VDEV_TOP_ZAP_VDEV_REBUILD_PHYS, sizeof (uint64_t),\n\t    REBUILD_PHYS_ENTRIES, vrp);\n\n\t \n\tif (err == ENOENT || err == EOVERFLOW || err == ECKSUM) {\n\t\tmemset(vrp, 0, sizeof (uint64_t) * REBUILD_PHYS_ENTRIES);\n\t} else if (err) {\n\t\tmutex_exit(&vd->vdev_rebuild_lock);\n\t\treturn (err);\n\t}\n\n\tvr->vr_prev_scan_time_ms = vrp->vrp_scan_time_ms;\n\tvr->vr_top_vdev = vd;\n\n\tmutex_exit(&vd->vdev_rebuild_lock);\n\n\treturn (0);\n}\n\n \nstatic __attribute__((noreturn)) void\nvdev_rebuild_thread(void *arg)\n{\n\tvdev_t *vd = arg;\n\tspa_t *spa = vd->vdev_spa;\n\tvdev_t *rvd = spa->spa_root_vdev;\n\tint error = 0;\n\n\t \n\tdsl_pool_t *dsl = spa_get_dsl(spa);\n\tif (dsl_scan_scrubbing(dsl))\n\t\tdsl_scan_cancel(dsl);\n\n\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\n\tASSERT3P(vd->vdev_top, ==, vd);\n\tASSERT3P(vd->vdev_rebuild_thread, !=, NULL);\n\tASSERT(vd->vdev_rebuilding);\n\tASSERT(spa_feature_is_active(spa, SPA_FEATURE_DEVICE_REBUILD));\n\tASSERT3B(vd->vdev_rebuild_cancel_wanted, ==, B_FALSE);\n\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\tvr->vr_top_vdev = vd;\n\tvr->vr_scan_msp = NULL;\n\tvr->vr_scan_tree = range_tree_create(NULL, RANGE_SEG64, NULL, 0, 0);\n\tmutex_init(&vr->vr_io_lock, NULL, MUTEX_DEFAULT, NULL);\n\tcv_init(&vr->vr_io_cv, NULL, CV_DEFAULT, NULL);\n\n\tvr->vr_pass_start_time = gethrtime();\n\tvr->vr_pass_bytes_scanned = 0;\n\tvr->vr_pass_bytes_issued = 0;\n\tvr->vr_pass_bytes_skipped = 0;\n\n\tuint64_t update_est_time = gethrtime();\n\tvdev_rebuild_update_bytes_est(vd, 0);\n\n\tclear_rebuild_bytes(vr->vr_top_vdev);\n\n\tmutex_exit(&vd->vdev_rebuild_lock);\n\n\t \n\tfor (uint64_t i = 0; i < vd->vdev_ms_count; i++) {\n\t\tmetaslab_t *msp = vd->vdev_ms[i];\n\t\tvr->vr_scan_msp = msp;\n\n\t\t \n\t\tuint64_t limit = (arc_c_max / 2) / MAX(rvd->vdev_children, 1);\n\t\tvr->vr_bytes_inflight_max = MIN(limit, MAX(1ULL << 20,\n\t\t    zfs_rebuild_vdev_limit * vd->vdev_children));\n\n\t\t \n\t\tif (vdev_rebuild_should_cancel(vd)) {\n\t\t\tvd->vdev_rebuild_cancel_wanted = B_TRUE;\n\t\t\terror = EINTR;\n\t\t\tbreak;\n\t\t}\n\n\t\tASSERT0(range_tree_space(vr->vr_scan_tree));\n\n\t\t \n\t\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\t\tmetaslab_disable(msp);\n\n\t\tmutex_enter(&msp->ms_sync_lock);\n\t\tmutex_enter(&msp->ms_lock);\n\n\t\t \n\t\tfor (int j = 0; j < TXG_SIZE; j++) {\n\t\t\tif (range_tree_space(msp->ms_allocating[j])) {\n\t\t\t\tmutex_exit(&msp->ms_lock);\n\t\t\t\tmutex_exit(&msp->ms_sync_lock);\n\t\t\t\ttxg_wait_synced(dsl, 0);\n\t\t\t\tmutex_enter(&msp->ms_sync_lock);\n\t\t\t\tmutex_enter(&msp->ms_lock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (msp->ms_sm != NULL) {\n\t\t\tVERIFY0(space_map_load(msp->ms_sm,\n\t\t\t    vr->vr_scan_tree, SM_ALLOC));\n\n\t\t\tfor (int i = 0; i < TXG_SIZE; i++) {\n\t\t\t\tASSERT0(range_tree_space(\n\t\t\t\t    msp->ms_allocating[i]));\n\t\t\t}\n\n\t\t\trange_tree_walk(msp->ms_unflushed_allocs,\n\t\t\t    range_tree_add, vr->vr_scan_tree);\n\t\t\trange_tree_walk(msp->ms_unflushed_frees,\n\t\t\t    range_tree_remove, vr->vr_scan_tree);\n\n\t\t\t \n\t\t\trange_tree_clear(vr->vr_scan_tree, 0,\n\t\t\t    vrp->vrp_last_offset);\n\t\t}\n\n\t\tmutex_exit(&msp->ms_lock);\n\t\tmutex_exit(&msp->ms_sync_lock);\n\n\t\t \n\t\tif (gethrtime() > update_est_time + SEC2NSEC(300)) {\n\t\t\tupdate_est_time = gethrtime();\n\t\t\tvdev_rebuild_update_bytes_est(vd, i);\n\t\t}\n\n\t\t \n\t\terror = vdev_rebuild_ranges(vr);\n\t\trange_tree_vacate(vr->vr_scan_tree, NULL, NULL);\n\n\t\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\t\tmetaslab_enable(msp, B_FALSE, B_FALSE);\n\n\t\tif (error != 0)\n\t\t\tbreak;\n\t}\n\n\trange_tree_destroy(vr->vr_scan_tree);\n\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\n\t \n\tmutex_enter(&vr->vr_io_lock);\n\twhile (vr->vr_bytes_inflight > 0)\n\t\tcv_wait(&vr->vr_io_cv, &vr->vr_io_lock);\n\n\tmutex_exit(&vr->vr_io_lock);\n\n\tmutex_destroy(&vr->vr_io_lock);\n\tcv_destroy(&vr->vr_io_cv);\n\n\tspa_config_enter(spa, SCL_CONFIG, FTAG, RW_READER);\n\n\tdsl_pool_t *dp = spa_get_dsl(spa);\n\tdmu_tx_t *tx = dmu_tx_create_dd(dp->dp_mos_dir);\n\tVERIFY0(dmu_tx_assign(tx, TXG_WAIT));\n\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\tif (error == 0) {\n\t\t \n\t\tdsl_sync_task_nowait(dp, vdev_rebuild_complete_sync,\n\t\t    (void *)(uintptr_t)vd->vdev_id, tx);\n\t} else if (vd->vdev_rebuild_cancel_wanted) {\n\t\t \n\t\tdsl_sync_task_nowait(dp, vdev_rebuild_cancel_sync,\n\t\t    (void *)(uintptr_t)vd->vdev_id, tx);\n\t} else if (vd->vdev_rebuild_reset_wanted) {\n\t\t \n\t\tdsl_sync_task_nowait(dp, vdev_rebuild_reset_sync,\n\t\t    (void *)(uintptr_t)vd->vdev_id, tx);\n\t} else {\n\t\t \n\t\tASSERT(vrp->vrp_rebuild_state == VDEV_REBUILD_ACTIVE);\n\t\tvd->vdev_rebuilding = B_FALSE;\n\t}\n\n\tdmu_tx_commit(tx);\n\n\tvd->vdev_rebuild_thread = NULL;\n\tmutex_exit(&vd->vdev_rebuild_lock);\n\tspa_config_exit(spa, SCL_CONFIG, FTAG);\n\n\tcv_broadcast(&vd->vdev_rebuild_cv);\n\n\tthread_exit();\n}\n\n \nboolean_t\nvdev_rebuild_active(vdev_t *vd)\n{\n\tspa_t *spa = vd->vdev_spa;\n\tboolean_t ret = B_FALSE;\n\n\tif (vd == spa->spa_root_vdev) {\n\t\tfor (uint64_t i = 0; i < vd->vdev_children; i++) {\n\t\t\tret = vdev_rebuild_active(vd->vdev_child[i]);\n\t\t\tif (ret)\n\t\t\t\treturn (ret);\n\t\t}\n\t} else if (vd->vdev_top_zap != 0) {\n\t\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\t\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\n\t\tmutex_enter(&vd->vdev_rebuild_lock);\n\t\tret = (vrp->vrp_rebuild_state == VDEV_REBUILD_ACTIVE);\n\t\tmutex_exit(&vd->vdev_rebuild_lock);\n\t}\n\n\treturn (ret);\n}\n\n \nvoid\nvdev_rebuild(vdev_t *vd)\n{\n\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\tvdev_rebuild_phys_t *vrp __maybe_unused = &vr->vr_rebuild_phys;\n\n\tASSERT(vd->vdev_top == vd);\n\tASSERT(vdev_is_concrete(vd));\n\tASSERT(!vd->vdev_removing);\n\tASSERT(spa_feature_is_enabled(vd->vdev_spa,\n\t    SPA_FEATURE_DEVICE_REBUILD));\n\n\tmutex_enter(&vd->vdev_rebuild_lock);\n\tif (vd->vdev_rebuilding) {\n\t\tASSERT3U(vrp->vrp_rebuild_state, ==, VDEV_REBUILD_ACTIVE);\n\n\t\t \n\t\tif (!vd->vdev_rebuild_reset_wanted)\n\t\t\tvd->vdev_rebuild_reset_wanted = B_TRUE;\n\t} else {\n\t\tvdev_rebuild_initiate(vd);\n\t}\n\tmutex_exit(&vd->vdev_rebuild_lock);\n}\n\nstatic void\nvdev_rebuild_restart_impl(vdev_t *vd)\n{\n\tspa_t *spa = vd->vdev_spa;\n\n\tif (vd == spa->spa_root_vdev) {\n\t\tfor (uint64_t i = 0; i < vd->vdev_children; i++)\n\t\t\tvdev_rebuild_restart_impl(vd->vdev_child[i]);\n\n\t} else if (vd->vdev_top_zap != 0) {\n\t\tvdev_rebuild_t *vr = &vd->vdev_rebuild_config;\n\t\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\n\t\tmutex_enter(&vd->vdev_rebuild_lock);\n\t\tif (vrp->vrp_rebuild_state == VDEV_REBUILD_ACTIVE &&\n\t\t    vdev_writeable(vd) && !vd->vdev_rebuilding) {\n\t\t\tASSERT(spa_feature_is_active(spa,\n\t\t\t    SPA_FEATURE_DEVICE_REBUILD));\n\t\t\tvd->vdev_rebuilding = B_TRUE;\n\t\t\tvd->vdev_rebuild_thread = thread_create(NULL, 0,\n\t\t\t    vdev_rebuild_thread, vd, 0, &p0, TS_RUN,\n\t\t\t    maxclsyspri);\n\t\t}\n\t\tmutex_exit(&vd->vdev_rebuild_lock);\n\t}\n}\n\n \nvoid\nvdev_rebuild_restart(spa_t *spa)\n{\n\tASSERT(MUTEX_HELD(&spa_namespace_lock));\n\n\tvdev_rebuild_restart_impl(spa->spa_root_vdev);\n}\n\n \nvoid\nvdev_rebuild_stop_wait(vdev_t *vd)\n{\n\tspa_t *spa = vd->vdev_spa;\n\n\tASSERT(MUTEX_HELD(&spa_namespace_lock));\n\n\tif (vd == spa->spa_root_vdev) {\n\t\tfor (uint64_t i = 0; i < vd->vdev_children; i++)\n\t\t\tvdev_rebuild_stop_wait(vd->vdev_child[i]);\n\n\t} else if (vd->vdev_top_zap != 0) {\n\t\tASSERT(vd == vd->vdev_top);\n\n\t\tmutex_enter(&vd->vdev_rebuild_lock);\n\t\tif (vd->vdev_rebuild_thread != NULL) {\n\t\t\tvd->vdev_rebuild_exit_wanted = B_TRUE;\n\t\t\twhile (vd->vdev_rebuilding) {\n\t\t\t\tcv_wait(&vd->vdev_rebuild_cv,\n\t\t\t\t    &vd->vdev_rebuild_lock);\n\t\t\t}\n\t\t\tvd->vdev_rebuild_exit_wanted = B_FALSE;\n\t\t}\n\t\tmutex_exit(&vd->vdev_rebuild_lock);\n\t}\n}\n\n \nvoid\nvdev_rebuild_stop_all(spa_t *spa)\n{\n\tvdev_rebuild_stop_wait(spa->spa_root_vdev);\n}\n\n \nint\nvdev_rebuild_get_stats(vdev_t *tvd, vdev_rebuild_stat_t *vrs)\n{\n\tspa_t *spa = tvd->vdev_spa;\n\n\tif (!spa_feature_is_enabled(spa, SPA_FEATURE_DEVICE_REBUILD))\n\t\treturn (SET_ERROR(ENOTSUP));\n\n\tif (tvd != tvd->vdev_top || tvd->vdev_top_zap == 0)\n\t\treturn (SET_ERROR(EINVAL));\n\n\tint error = zap_contains(spa_meta_objset(spa),\n\t    tvd->vdev_top_zap, VDEV_TOP_ZAP_VDEV_REBUILD_PHYS);\n\n\tif (error == ENOENT) {\n\t\tmemset(vrs, 0, sizeof (vdev_rebuild_stat_t));\n\t\tvrs->vrs_state = VDEV_REBUILD_NONE;\n\t\terror = 0;\n\t} else if (error == 0) {\n\t\tvdev_rebuild_t *vr = &tvd->vdev_rebuild_config;\n\t\tvdev_rebuild_phys_t *vrp = &vr->vr_rebuild_phys;\n\n\t\tmutex_enter(&tvd->vdev_rebuild_lock);\n\t\tvrs->vrs_state = vrp->vrp_rebuild_state;\n\t\tvrs->vrs_start_time = vrp->vrp_start_time;\n\t\tvrs->vrs_end_time = vrp->vrp_end_time;\n\t\tvrs->vrs_scan_time_ms = vrp->vrp_scan_time_ms;\n\t\tvrs->vrs_bytes_scanned = vrp->vrp_bytes_scanned;\n\t\tvrs->vrs_bytes_issued = vrp->vrp_bytes_issued;\n\t\tvrs->vrs_bytes_rebuilt = vrp->vrp_bytes_rebuilt;\n\t\tvrs->vrs_bytes_est = vrp->vrp_bytes_est;\n\t\tvrs->vrs_errors = vrp->vrp_errors;\n\t\tvrs->vrs_pass_time_ms = NSEC2MSEC(gethrtime() -\n\t\t    vr->vr_pass_start_time);\n\t\tvrs->vrs_pass_bytes_scanned = vr->vr_pass_bytes_scanned;\n\t\tvrs->vrs_pass_bytes_issued = vr->vr_pass_bytes_issued;\n\t\tvrs->vrs_pass_bytes_skipped = vr->vr_pass_bytes_skipped;\n\t\tmutex_exit(&tvd->vdev_rebuild_lock);\n\t}\n\n\treturn (error);\n}\n\nZFS_MODULE_PARAM(zfs, zfs_, rebuild_max_segment, U64, ZMOD_RW,\n\t\"Max segment size in bytes of rebuild reads\");\n\nZFS_MODULE_PARAM(zfs, zfs_, rebuild_vdev_limit, U64, ZMOD_RW,\n\t\"Max bytes in flight per leaf vdev for sequential resilvers\");\n\nZFS_MODULE_PARAM(zfs, zfs_, rebuild_scrub_enabled, INT, ZMOD_RW,\n\t\"Automatically scrub after sequential resilver completes\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}