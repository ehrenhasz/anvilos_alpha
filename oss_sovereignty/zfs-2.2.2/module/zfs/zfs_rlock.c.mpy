{
  "module_name": "zfs_rlock.c",
  "hash_id": "4388d679f9c891cacccd545332f11fb6450889520138d1f6d9819d65ff483616",
  "original_prompt": "Ingested from zfs-2.2.2/module/zfs/zfs_rlock.c",
  "human_readable_source": " \n \n \n\n \n\n#include <sys/zfs_context.h>\n#include <sys/zfs_rlock.h>\n\n\n \nstatic int\nzfs_rangelock_compare(const void *arg1, const void *arg2)\n{\n\tconst zfs_locked_range_t *rl1 = (const zfs_locked_range_t *)arg1;\n\tconst zfs_locked_range_t *rl2 = (const zfs_locked_range_t *)arg2;\n\n\treturn (TREE_CMP(rl1->lr_offset, rl2->lr_offset));\n}\n\n \nvoid\nzfs_rangelock_init(zfs_rangelock_t *rl, zfs_rangelock_cb_t *cb, void *arg)\n{\n\tmutex_init(&rl->rl_lock, NULL, MUTEX_DEFAULT, NULL);\n\tavl_create(&rl->rl_tree, zfs_rangelock_compare,\n\t    sizeof (zfs_locked_range_t), offsetof(zfs_locked_range_t, lr_node));\n\trl->rl_cb = cb;\n\trl->rl_arg = arg;\n}\n\nvoid\nzfs_rangelock_fini(zfs_rangelock_t *rl)\n{\n\tmutex_destroy(&rl->rl_lock);\n\tavl_destroy(&rl->rl_tree);\n}\n\n \nstatic boolean_t\nzfs_rangelock_enter_writer(zfs_rangelock_t *rl, zfs_locked_range_t *new,\n    boolean_t nonblock)\n{\n\tavl_tree_t *tree = &rl->rl_tree;\n\tzfs_locked_range_t *lr;\n\tavl_index_t where;\n\tuint64_t orig_off = new->lr_offset;\n\tuint64_t orig_len = new->lr_length;\n\tzfs_rangelock_type_t orig_type = new->lr_type;\n\n\tfor (;;) {\n\t\t \n\t\tif (rl->rl_cb != NULL) {\n\t\t\trl->rl_cb(new, rl->rl_arg);\n\t\t}\n\n\t\t \n\t\tASSERT3U(new->lr_type, ==, RL_WRITER);\n\n\t\t \n\t\tif (avl_numnodes(tree) == 0) {\n\t\t\tavl_add(tree, new);\n\t\t\treturn (B_TRUE);\n\t\t}\n\n\t\t \n\t\tlr = avl_find(tree, new, &where);\n\t\tif (lr != NULL)\n\t\t\tgoto wait;  \n\n\t\tlr = avl_nearest(tree, where, AVL_AFTER);\n\t\tif (lr != NULL &&\n\t\t    lr->lr_offset < new->lr_offset + new->lr_length)\n\t\t\tgoto wait;\n\n\t\tlr = avl_nearest(tree, where, AVL_BEFORE);\n\t\tif (lr != NULL &&\n\t\t    lr->lr_offset + lr->lr_length > new->lr_offset)\n\t\t\tgoto wait;\n\n\t\tavl_insert(tree, new, where);\n\t\treturn (B_TRUE);\nwait:\n\t\tif (nonblock)\n\t\t\treturn (B_FALSE);\n\t\tif (!lr->lr_write_wanted) {\n\t\t\tcv_init(&lr->lr_write_cv, NULL, CV_DEFAULT, NULL);\n\t\t\tlr->lr_write_wanted = B_TRUE;\n\t\t}\n\t\tcv_wait(&lr->lr_write_cv, &rl->rl_lock);\n\n\t\t \n\t\tnew->lr_offset = orig_off;\n\t\tnew->lr_length = orig_len;\n\t\tnew->lr_type = orig_type;\n\t}\n}\n\n \nstatic zfs_locked_range_t *\nzfs_rangelock_proxify(avl_tree_t *tree, zfs_locked_range_t *lr)\n{\n\tzfs_locked_range_t *proxy;\n\n\tif (lr->lr_proxy)\n\t\treturn (lr);  \n\n\tASSERT3U(lr->lr_count, ==, 1);\n\tASSERT(lr->lr_write_wanted == B_FALSE);\n\tASSERT(lr->lr_read_wanted == B_FALSE);\n\tavl_remove(tree, lr);\n\tlr->lr_count = 0;\n\n\t \n\tproxy = kmem_alloc(sizeof (zfs_locked_range_t), KM_SLEEP);\n\tproxy->lr_offset = lr->lr_offset;\n\tproxy->lr_length = lr->lr_length;\n\tproxy->lr_count = 1;\n\tproxy->lr_type = RL_READER;\n\tproxy->lr_proxy = B_TRUE;\n\tproxy->lr_write_wanted = B_FALSE;\n\tproxy->lr_read_wanted = B_FALSE;\n\tavl_add(tree, proxy);\n\n\treturn (proxy);\n}\n\n \nstatic zfs_locked_range_t *\nzfs_rangelock_split(avl_tree_t *tree, zfs_locked_range_t *lr, uint64_t off)\n{\n\tzfs_locked_range_t *rear;\n\n\tASSERT3U(lr->lr_length, >, 1);\n\tASSERT3U(off, >, lr->lr_offset);\n\tASSERT3U(off, <, lr->lr_offset + lr->lr_length);\n\tASSERT(lr->lr_write_wanted == B_FALSE);\n\tASSERT(lr->lr_read_wanted == B_FALSE);\n\n\t \n\trear = kmem_alloc(sizeof (zfs_locked_range_t), KM_SLEEP);\n\trear->lr_offset = off;\n\trear->lr_length = lr->lr_offset + lr->lr_length - off;\n\trear->lr_count = lr->lr_count;\n\trear->lr_type = RL_READER;\n\trear->lr_proxy = B_TRUE;\n\trear->lr_write_wanted = B_FALSE;\n\trear->lr_read_wanted = B_FALSE;\n\n\tzfs_locked_range_t *front = zfs_rangelock_proxify(tree, lr);\n\tfront->lr_length = off - lr->lr_offset;\n\n\tavl_insert_here(tree, rear, front, AVL_AFTER);\n\treturn (front);\n}\n\n \nstatic void\nzfs_rangelock_new_proxy(avl_tree_t *tree, uint64_t off, uint64_t len)\n{\n\tzfs_locked_range_t *lr;\n\n\tASSERT(len != 0);\n\tlr = kmem_alloc(sizeof (zfs_locked_range_t), KM_SLEEP);\n\tlr->lr_offset = off;\n\tlr->lr_length = len;\n\tlr->lr_count = 1;\n\tlr->lr_type = RL_READER;\n\tlr->lr_proxy = B_TRUE;\n\tlr->lr_write_wanted = B_FALSE;\n\tlr->lr_read_wanted = B_FALSE;\n\tavl_add(tree, lr);\n}\n\nstatic void\nzfs_rangelock_add_reader(avl_tree_t *tree, zfs_locked_range_t *new,\n    zfs_locked_range_t *prev, avl_index_t where)\n{\n\tzfs_locked_range_t *next;\n\tuint64_t off = new->lr_offset;\n\tuint64_t len = new->lr_length;\n\n\t \n\tif (prev != NULL) {\n\t\tif (prev->lr_offset + prev->lr_length <= off) {\n\t\t\tprev = NULL;\n\t\t} else if (prev->lr_offset != off) {\n\t\t\t \n\t\t\tprev = zfs_rangelock_split(tree, prev, off);\n\t\t\tprev = AVL_NEXT(tree, prev);  \n\t\t}\n\t}\n\tASSERT((prev == NULL) || (prev->lr_offset == off));\n\n\tif (prev != NULL)\n\t\tnext = prev;\n\telse\n\t\tnext = avl_nearest(tree, where, AVL_AFTER);\n\n\tif (next == NULL || off + len <= next->lr_offset) {\n\t\t \n\t\tavl_insert(tree, new, where);\n\t\treturn;\n\t}\n\n\tif (off < next->lr_offset) {\n\t\t \n\t\tzfs_rangelock_new_proxy(tree, off, next->lr_offset - off);\n\t}\n\n\tnew->lr_count = 0;  \n\t \n\tfor (prev = NULL; next; prev = next, next = AVL_NEXT(tree, next)) {\n\t\tif (off + len <= next->lr_offset)\n\t\t\tbreak;\n\t\tif (prev != NULL && prev->lr_offset + prev->lr_length <\n\t\t    next->lr_offset) {\n\t\t\t \n\t\t\tASSERT3U(next->lr_offset, >,\n\t\t\t    prev->lr_offset + prev->lr_length);\n\t\t\tzfs_rangelock_new_proxy(tree,\n\t\t\t    prev->lr_offset + prev->lr_length,\n\t\t\t    next->lr_offset -\n\t\t\t    (prev->lr_offset + prev->lr_length));\n\t\t}\n\t\tif (off + len == next->lr_offset + next->lr_length) {\n\t\t\t \n\t\t\tnext = zfs_rangelock_proxify(tree, next);\n\t\t\tnext->lr_count++;\n\t\t\treturn;\n\t\t}\n\t\tif (off + len < next->lr_offset + next->lr_length) {\n\t\t\t \n\t\t\tnext = zfs_rangelock_split(tree, next, off + len);\n\t\t\tnext->lr_count++;\n\t\t\treturn;\n\t\t}\n\t\tASSERT3U(off + len, >, next->lr_offset + next->lr_length);\n\t\tnext = zfs_rangelock_proxify(tree, next);\n\t\tnext->lr_count++;\n\t}\n\n\t \n\tzfs_rangelock_new_proxy(tree, prev->lr_offset + prev->lr_length,\n\t    (off + len) - (prev->lr_offset + prev->lr_length));\n}\n\n \nstatic boolean_t\nzfs_rangelock_enter_reader(zfs_rangelock_t *rl, zfs_locked_range_t *new,\n    boolean_t nonblock)\n{\n\tavl_tree_t *tree = &rl->rl_tree;\n\tzfs_locked_range_t *prev, *next;\n\tavl_index_t where;\n\tuint64_t off = new->lr_offset;\n\tuint64_t len = new->lr_length;\n\n\t \nretry:\n\tprev = avl_find(tree, new, &where);\n\tif (prev == NULL)\n\t\tprev = avl_nearest(tree, where, AVL_BEFORE);\n\n\t \n\tif (prev && (off < prev->lr_offset + prev->lr_length)) {\n\t\tif ((prev->lr_type == RL_WRITER) || (prev->lr_write_wanted)) {\n\t\t\tif (nonblock)\n\t\t\t\treturn (B_FALSE);\n\t\t\tif (!prev->lr_read_wanted) {\n\t\t\t\tcv_init(&prev->lr_read_cv,\n\t\t\t\t    NULL, CV_DEFAULT, NULL);\n\t\t\t\tprev->lr_read_wanted = B_TRUE;\n\t\t\t}\n\t\t\tcv_wait(&prev->lr_read_cv, &rl->rl_lock);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (off + len < prev->lr_offset + prev->lr_length)\n\t\t\tgoto got_lock;\n\t}\n\n\t \n\tif (prev != NULL)\n\t\tnext = AVL_NEXT(tree, prev);\n\telse\n\t\tnext = avl_nearest(tree, where, AVL_AFTER);\n\tfor (; next != NULL; next = AVL_NEXT(tree, next)) {\n\t\tif (off + len <= next->lr_offset)\n\t\t\tgoto got_lock;\n\t\tif ((next->lr_type == RL_WRITER) || (next->lr_write_wanted)) {\n\t\t\tif (nonblock)\n\t\t\t\treturn (B_FALSE);\n\t\t\tif (!next->lr_read_wanted) {\n\t\t\t\tcv_init(&next->lr_read_cv,\n\t\t\t\t    NULL, CV_DEFAULT, NULL);\n\t\t\t\tnext->lr_read_wanted = B_TRUE;\n\t\t\t}\n\t\t\tcv_wait(&next->lr_read_cv, &rl->rl_lock);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (off + len <= next->lr_offset + next->lr_length)\n\t\t\tgoto got_lock;\n\t}\n\ngot_lock:\n\t \n\tzfs_rangelock_add_reader(tree, new, prev, where);\n\treturn (B_TRUE);\n}\n\n \nstatic zfs_locked_range_t *\nzfs_rangelock_enter_impl(zfs_rangelock_t *rl, uint64_t off, uint64_t len,\n    zfs_rangelock_type_t type, boolean_t nonblock)\n{\n\tzfs_locked_range_t *new;\n\n\tASSERT(type == RL_READER || type == RL_WRITER || type == RL_APPEND);\n\n\tnew = kmem_alloc(sizeof (zfs_locked_range_t), KM_SLEEP);\n\tnew->lr_rangelock = rl;\n\tnew->lr_offset = off;\n\tif (len + off < off)\t \n\t\tlen = UINT64_MAX - off;\n\tnew->lr_length = len;\n\tnew->lr_count = 1;  \n\tnew->lr_type = type;\n\tnew->lr_proxy = B_FALSE;\n\tnew->lr_write_wanted = B_FALSE;\n\tnew->lr_read_wanted = B_FALSE;\n\n\tmutex_enter(&rl->rl_lock);\n\tif (type == RL_READER) {\n\t\t \n\t\tif (avl_numnodes(&rl->rl_tree) == 0) {\n\t\t\tavl_add(&rl->rl_tree, new);\n\t\t} else if (!zfs_rangelock_enter_reader(rl, new, nonblock)) {\n\t\t\tkmem_free(new, sizeof (*new));\n\t\t\tnew = NULL;\n\t\t}\n\t} else if (!zfs_rangelock_enter_writer(rl, new, nonblock)) {\n\t\tkmem_free(new, sizeof (*new));\n\t\tnew = NULL;\n\t}\n\tmutex_exit(&rl->rl_lock);\n\treturn (new);\n}\n\nzfs_locked_range_t *\nzfs_rangelock_enter(zfs_rangelock_t *rl, uint64_t off, uint64_t len,\n    zfs_rangelock_type_t type)\n{\n\treturn (zfs_rangelock_enter_impl(rl, off, len, type, B_FALSE));\n}\n\nzfs_locked_range_t *\nzfs_rangelock_tryenter(zfs_rangelock_t *rl, uint64_t off, uint64_t len,\n    zfs_rangelock_type_t type)\n{\n\treturn (zfs_rangelock_enter_impl(rl, off, len, type, B_TRUE));\n}\n\n \nstatic void\nzfs_rangelock_free(zfs_locked_range_t *lr)\n{\n\tif (lr->lr_write_wanted)\n\t\tcv_destroy(&lr->lr_write_cv);\n\n\tif (lr->lr_read_wanted)\n\t\tcv_destroy(&lr->lr_read_cv);\n\n\tkmem_free(lr, sizeof (zfs_locked_range_t));\n}\n\n \nstatic void\nzfs_rangelock_exit_reader(zfs_rangelock_t *rl, zfs_locked_range_t *remove,\n    list_t *free_list)\n{\n\tavl_tree_t *tree = &rl->rl_tree;\n\tuint64_t len;\n\n\t \n\tif (remove->lr_count == 1) {\n\t\tavl_remove(tree, remove);\n\t\tif (remove->lr_write_wanted)\n\t\t\tcv_broadcast(&remove->lr_write_cv);\n\t\tif (remove->lr_read_wanted)\n\t\t\tcv_broadcast(&remove->lr_read_cv);\n\t\tlist_insert_tail(free_list, remove);\n\t} else {\n\t\tASSERT0(remove->lr_count);\n\t\tASSERT0(remove->lr_write_wanted);\n\t\tASSERT0(remove->lr_read_wanted);\n\t\t \n\t\tzfs_locked_range_t *lr = avl_find(tree, remove, NULL);\n\t\tASSERT3P(lr, !=, NULL);\n\t\tASSERT3U(lr->lr_count, !=, 0);\n\t\tASSERT3U(lr->lr_type, ==, RL_READER);\n\t\tzfs_locked_range_t *next = NULL;\n\t\tfor (len = remove->lr_length; len != 0; lr = next) {\n\t\t\tlen -= lr->lr_length;\n\t\t\tif (len != 0) {\n\t\t\t\tnext = AVL_NEXT(tree, lr);\n\t\t\t\tASSERT3P(next, !=, NULL);\n\t\t\t\tASSERT3U(lr->lr_offset + lr->lr_length, ==,\n\t\t\t\t    next->lr_offset);\n\t\t\t\tASSERT3U(next->lr_count, !=, 0);\n\t\t\t\tASSERT3U(next->lr_type, ==, RL_READER);\n\t\t\t}\n\t\t\tlr->lr_count--;\n\t\t\tif (lr->lr_count == 0) {\n\t\t\t\tavl_remove(tree, lr);\n\t\t\t\tif (lr->lr_write_wanted)\n\t\t\t\t\tcv_broadcast(&lr->lr_write_cv);\n\t\t\t\tif (lr->lr_read_wanted)\n\t\t\t\t\tcv_broadcast(&lr->lr_read_cv);\n\t\t\t\tlist_insert_tail(free_list, lr);\n\t\t\t}\n\t\t}\n\t\tkmem_free(remove, sizeof (zfs_locked_range_t));\n\t}\n}\n\n \nvoid\nzfs_rangelock_exit(zfs_locked_range_t *lr)\n{\n\tzfs_rangelock_t *rl = lr->lr_rangelock;\n\tlist_t free_list;\n\tzfs_locked_range_t *free_lr;\n\n\tASSERT(lr->lr_type == RL_WRITER || lr->lr_type == RL_READER);\n\tASSERT(lr->lr_count == 1 || lr->lr_count == 0);\n\tASSERT(!lr->lr_proxy);\n\n\t \n\tlist_create(&free_list, sizeof (zfs_locked_range_t),\n\t    offsetof(zfs_locked_range_t, lr_node));\n\n\tmutex_enter(&rl->rl_lock);\n\tif (lr->lr_type == RL_WRITER) {\n\t\t \n\t\tavl_remove(&rl->rl_tree, lr);\n\t\tif (lr->lr_write_wanted)\n\t\t\tcv_broadcast(&lr->lr_write_cv);\n\t\tif (lr->lr_read_wanted)\n\t\t\tcv_broadcast(&lr->lr_read_cv);\n\t\tlist_insert_tail(&free_list, lr);\n\t} else {\n\t\t \n\t\tzfs_rangelock_exit_reader(rl, lr, &free_list);\n\t}\n\tmutex_exit(&rl->rl_lock);\n\n\twhile ((free_lr = list_remove_head(&free_list)) != NULL)\n\t\tzfs_rangelock_free(free_lr);\n\n\tlist_destroy(&free_list);\n}\n\n \nvoid\nzfs_rangelock_reduce(zfs_locked_range_t *lr, uint64_t off, uint64_t len)\n{\n\tzfs_rangelock_t *rl = lr->lr_rangelock;\n\n\t \n\tASSERT3U(avl_numnodes(&rl->rl_tree), ==, 1);\n\tASSERT3U(lr->lr_offset, ==, 0);\n\tASSERT3U(lr->lr_type, ==, RL_WRITER);\n\tASSERT(!lr->lr_proxy);\n\tASSERT3U(lr->lr_length, ==, UINT64_MAX);\n\tASSERT3U(lr->lr_count, ==, 1);\n\n\tmutex_enter(&rl->rl_lock);\n\tlr->lr_offset = off;\n\tlr->lr_length = len;\n\tmutex_exit(&rl->rl_lock);\n\tif (lr->lr_write_wanted)\n\t\tcv_broadcast(&lr->lr_write_cv);\n\tif (lr->lr_read_wanted)\n\t\tcv_broadcast(&lr->lr_read_cv);\n}\n\n#if defined(_KERNEL)\nEXPORT_SYMBOL(zfs_rangelock_init);\nEXPORT_SYMBOL(zfs_rangelock_fini);\nEXPORT_SYMBOL(zfs_rangelock_enter);\nEXPORT_SYMBOL(zfs_rangelock_tryenter);\nEXPORT_SYMBOL(zfs_rangelock_exit);\nEXPORT_SYMBOL(zfs_rangelock_reduce);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}