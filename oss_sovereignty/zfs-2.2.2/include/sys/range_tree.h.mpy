{
  "module_name": "range_tree.h",
  "hash_id": "fcfd695ea6b27e3c73a77fc515826ba6553addcdb759d25fb1a37736aca6521f",
  "original_prompt": "Ingested from zfs-2.2.2/include/sys/range_tree.h",
  "human_readable_source": " \n \n\n \n\n#ifndef _SYS_RANGE_TREE_H\n#define\t_SYS_RANGE_TREE_H\n\n#include <sys/btree.h>\n#include <sys/dmu.h>\n\n#ifdef\t__cplusplus\nextern \"C\" {\n#endif\n\n#define\tRANGE_TREE_HISTOGRAM_SIZE\t64\n\ntypedef struct range_tree_ops range_tree_ops_t;\n\ntypedef enum range_seg_type {\n\tRANGE_SEG32,\n\tRANGE_SEG64,\n\tRANGE_SEG_GAP,\n\tRANGE_SEG_NUM_TYPES,\n} range_seg_type_t;\n\n \ntypedef struct range_tree {\n\tzfs_btree_t\trt_root;\t \n\tuint64_t\trt_space;\t \n\trange_seg_type_t rt_type;\t \n\t \n\tuint8_t\t\trt_shift;\n\tuint64_t\trt_start;\n\tconst range_tree_ops_t *rt_ops;\n\tvoid\t\t*rt_arg;\n\tuint64_t\trt_gap;\t\t \n\n\t \n\tuint64_t\trt_histogram[RANGE_TREE_HISTOGRAM_SIZE];\n} range_tree_t;\n\ntypedef struct range_seg32 {\n\tuint32_t\trs_start;\t \n\tuint32_t\trs_end;\t\t \n} range_seg32_t;\n\n \ntypedef struct range_seg64 {\n\tuint64_t\trs_start;\t \n\tuint64_t\trs_end;\t\t \n} range_seg64_t;\n\ntypedef struct range_seg_gap {\n\tuint64_t\trs_start;\t \n\tuint64_t\trs_end;\t\t \n\tuint64_t\trs_fill;\t \n} range_seg_gap_t;\n\n \ntypedef range_seg_gap_t range_seg_max_t;\n\n \ntypedef void range_seg_t;\n\nstruct range_tree_ops {\n\tvoid    (*rtop_create)(range_tree_t *rt, void *arg);\n\tvoid    (*rtop_destroy)(range_tree_t *rt, void *arg);\n\tvoid\t(*rtop_add)(range_tree_t *rt, void *rs, void *arg);\n\tvoid    (*rtop_remove)(range_tree_t *rt, void *rs, void *arg);\n\tvoid\t(*rtop_vacate)(range_tree_t *rt, void *arg);\n};\n\nstatic inline uint64_t\nrs_get_start_raw(const range_seg_t *rs, const range_tree_t *rt)\n{\n\tASSERT3U(rt->rt_type, <=, RANGE_SEG_NUM_TYPES);\n\tswitch (rt->rt_type) {\n\tcase RANGE_SEG32:\n\t\treturn (((const range_seg32_t *)rs)->rs_start);\n\tcase RANGE_SEG64:\n\t\treturn (((const range_seg64_t *)rs)->rs_start);\n\tcase RANGE_SEG_GAP:\n\t\treturn (((const range_seg_gap_t *)rs)->rs_start);\n\tdefault:\n\t\tVERIFY(0);\n\t\treturn (0);\n\t}\n}\n\nstatic inline uint64_t\nrs_get_end_raw(const range_seg_t *rs, const range_tree_t *rt)\n{\n\tASSERT3U(rt->rt_type, <=, RANGE_SEG_NUM_TYPES);\n\tswitch (rt->rt_type) {\n\tcase RANGE_SEG32:\n\t\treturn (((const range_seg32_t *)rs)->rs_end);\n\tcase RANGE_SEG64:\n\t\treturn (((const range_seg64_t *)rs)->rs_end);\n\tcase RANGE_SEG_GAP:\n\t\treturn (((const range_seg_gap_t *)rs)->rs_end);\n\tdefault:\n\t\tVERIFY(0);\n\t\treturn (0);\n\t}\n}\n\nstatic inline uint64_t\nrs_get_fill_raw(const range_seg_t *rs, const range_tree_t *rt)\n{\n\tASSERT3U(rt->rt_type, <=, RANGE_SEG_NUM_TYPES);\n\tswitch (rt->rt_type) {\n\tcase RANGE_SEG32: {\n\t\tconst range_seg32_t *r32 = (const range_seg32_t *)rs;\n\t\treturn (r32->rs_end - r32->rs_start);\n\t}\n\tcase RANGE_SEG64: {\n\t\tconst range_seg64_t *r64 = (const range_seg64_t *)rs;\n\t\treturn (r64->rs_end - r64->rs_start);\n\t}\n\tcase RANGE_SEG_GAP:\n\t\treturn (((const range_seg_gap_t *)rs)->rs_fill);\n\tdefault:\n\t\tVERIFY(0);\n\t\treturn (0);\n\t}\n\n}\n\nstatic inline uint64_t\nrs_get_start(const range_seg_t *rs, const range_tree_t *rt)\n{\n\treturn ((rs_get_start_raw(rs, rt) << rt->rt_shift) + rt->rt_start);\n}\n\nstatic inline uint64_t\nrs_get_end(const range_seg_t *rs, const range_tree_t *rt)\n{\n\treturn ((rs_get_end_raw(rs, rt) << rt->rt_shift) + rt->rt_start);\n}\n\nstatic inline uint64_t\nrs_get_fill(const range_seg_t *rs, const range_tree_t *rt)\n{\n\treturn (rs_get_fill_raw(rs, rt) << rt->rt_shift);\n}\n\nstatic inline void\nrs_set_start_raw(range_seg_t *rs, range_tree_t *rt, uint64_t start)\n{\n\tASSERT3U(rt->rt_type, <=, RANGE_SEG_NUM_TYPES);\n\tswitch (rt->rt_type) {\n\tcase RANGE_SEG32:\n\t\tASSERT3U(start, <=, UINT32_MAX);\n\t\t((range_seg32_t *)rs)->rs_start = (uint32_t)start;\n\t\tbreak;\n\tcase RANGE_SEG64:\n\t\t((range_seg64_t *)rs)->rs_start = start;\n\t\tbreak;\n\tcase RANGE_SEG_GAP:\n\t\t((range_seg_gap_t *)rs)->rs_start = start;\n\t\tbreak;\n\tdefault:\n\t\tVERIFY(0);\n\t}\n}\n\nstatic inline void\nrs_set_end_raw(range_seg_t *rs, range_tree_t *rt, uint64_t end)\n{\n\tASSERT3U(rt->rt_type, <=, RANGE_SEG_NUM_TYPES);\n\tswitch (rt->rt_type) {\n\tcase RANGE_SEG32:\n\t\tASSERT3U(end, <=, UINT32_MAX);\n\t\t((range_seg32_t *)rs)->rs_end = (uint32_t)end;\n\t\tbreak;\n\tcase RANGE_SEG64:\n\t\t((range_seg64_t *)rs)->rs_end = end;\n\t\tbreak;\n\tcase RANGE_SEG_GAP:\n\t\t((range_seg_gap_t *)rs)->rs_end = end;\n\t\tbreak;\n\tdefault:\n\t\tVERIFY(0);\n\t}\n}\n\nstatic inline void\nrs_set_fill_raw(range_seg_t *rs, range_tree_t *rt, uint64_t fill)\n{\n\tASSERT3U(rt->rt_type, <=, RANGE_SEG_NUM_TYPES);\n\tswitch (rt->rt_type) {\n\tcase RANGE_SEG32:\n\t\t \n\tcase RANGE_SEG64:\n\t\tASSERT3U(fill, ==, rs_get_end_raw(rs, rt) - rs_get_start_raw(rs,\n\t\t    rt));\n\t\tbreak;\n\tcase RANGE_SEG_GAP:\n\t\t((range_seg_gap_t *)rs)->rs_fill = fill;\n\t\tbreak;\n\tdefault:\n\t\tVERIFY(0);\n\t}\n}\n\nstatic inline void\nrs_set_start(range_seg_t *rs, range_tree_t *rt, uint64_t start)\n{\n\tASSERT3U(start, >=, rt->rt_start);\n\tASSERT(IS_P2ALIGNED(start, 1ULL << rt->rt_shift));\n\trs_set_start_raw(rs, rt, (start - rt->rt_start) >> rt->rt_shift);\n}\n\nstatic inline void\nrs_set_end(range_seg_t *rs, range_tree_t *rt, uint64_t end)\n{\n\tASSERT3U(end, >=, rt->rt_start);\n\tASSERT(IS_P2ALIGNED(end, 1ULL << rt->rt_shift));\n\trs_set_end_raw(rs, rt, (end - rt->rt_start) >> rt->rt_shift);\n}\n\nstatic inline void\nrs_set_fill(range_seg_t *rs, range_tree_t *rt, uint64_t fill)\n{\n\tASSERT(IS_P2ALIGNED(fill, 1ULL << rt->rt_shift));\n\trs_set_fill_raw(rs, rt, fill >> rt->rt_shift);\n}\n\ntypedef void range_tree_func_t(void *arg, uint64_t start, uint64_t size);\n\nrange_tree_t *range_tree_create_gap(const range_tree_ops_t *ops,\n    range_seg_type_t type, void *arg, uint64_t start, uint64_t shift,\n    uint64_t gap);\nrange_tree_t *range_tree_create(const range_tree_ops_t *ops,\n    range_seg_type_t type, void *arg, uint64_t start, uint64_t shift);\nvoid range_tree_destroy(range_tree_t *rt);\nboolean_t range_tree_contains(range_tree_t *rt, uint64_t start, uint64_t size);\nrange_seg_t *range_tree_find(range_tree_t *rt, uint64_t start, uint64_t size);\nboolean_t range_tree_find_in(range_tree_t *rt, uint64_t start, uint64_t size,\n    uint64_t *ostart, uint64_t *osize);\nvoid range_tree_verify_not_present(range_tree_t *rt,\n    uint64_t start, uint64_t size);\nvoid range_tree_resize_segment(range_tree_t *rt, range_seg_t *rs,\n    uint64_t newstart, uint64_t newsize);\nuint64_t range_tree_space(range_tree_t *rt);\nuint64_t range_tree_numsegs(range_tree_t *rt);\nboolean_t range_tree_is_empty(range_tree_t *rt);\nvoid range_tree_swap(range_tree_t **rtsrc, range_tree_t **rtdst);\nvoid range_tree_stat_verify(range_tree_t *rt);\nuint64_t range_tree_min(range_tree_t *rt);\nuint64_t range_tree_max(range_tree_t *rt);\nuint64_t range_tree_span(range_tree_t *rt);\n\nvoid range_tree_add(void *arg, uint64_t start, uint64_t size);\nvoid range_tree_remove(void *arg, uint64_t start, uint64_t size);\nvoid range_tree_remove_fill(range_tree_t *rt, uint64_t start, uint64_t size);\nvoid range_tree_adjust_fill(range_tree_t *rt, range_seg_t *rs, int64_t delta);\nvoid range_tree_clear(range_tree_t *rt, uint64_t start, uint64_t size);\n\nvoid range_tree_vacate(range_tree_t *rt, range_tree_func_t *func, void *arg);\nvoid range_tree_walk(range_tree_t *rt, range_tree_func_t *func, void *arg);\nrange_seg_t *range_tree_first(range_tree_t *rt);\n\nvoid range_tree_remove_xor_add_segment(uint64_t start, uint64_t end,\n    range_tree_t *removefrom, range_tree_t *addto);\nvoid range_tree_remove_xor_add(range_tree_t *rt, range_tree_t *removefrom,\n    range_tree_t *addto);\n\n#ifdef\t__cplusplus\n}\n#endif\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}