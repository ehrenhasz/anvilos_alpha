{
  "module_name": "spa.h",
  "hash_id": "09ce0e4ebfe323102cd20d31fa285889fcc21b4ba6680426953cc6b5625b2e28",
  "original_prompt": "Ingested from zfs-2.2.2/include/sys/spa.h",
  "human_readable_source": " \n \n\n#ifndef _SYS_SPA_H\n#define\t_SYS_SPA_H\n\n#include <sys/avl.h>\n#include <sys/zfs_context.h>\n#include <sys/kstat.h>\n#include <sys/nvpair.h>\n#include <sys/sysmacros.h>\n#include <sys/types.h>\n#include <sys/fs/zfs.h>\n#include <sys/spa_checksum.h>\n#include <sys/dmu.h>\n#include <sys/space_map.h>\n#include <sys/bitops.h>\n\n#ifdef\t__cplusplus\nextern \"C\" {\n#endif\n\n \ntypedef struct spa spa_t;\ntypedef struct vdev vdev_t;\ntypedef struct metaslab metaslab_t;\ntypedef struct metaslab_group metaslab_group_t;\ntypedef struct metaslab_class metaslab_class_t;\ntypedef struct zio zio_t;\ntypedef struct zilog zilog_t;\ntypedef struct spa_aux_vdev spa_aux_vdev_t;\ntypedef struct ddt ddt_t;\ntypedef struct ddt_entry ddt_entry_t;\ntypedef struct zbookmark_phys zbookmark_phys_t;\ntypedef struct zbookmark_err_phys zbookmark_err_phys_t;\n\nstruct bpobj;\nstruct bplist;\nstruct dsl_pool;\nstruct dsl_dataset;\nstruct dsl_crypto_params;\n\n \n#define\tASHIFT_MIN\t\t9\n#define\tASHIFT_MAX\t\t16\n\n \n#define\tSPA_CONFIG_BLOCKSIZE\t(1ULL << 14)\n\n \n#define\tSPA_LSIZEBITS\t\t16\t \n#define\tSPA_PSIZEBITS\t\t16\t \n#define\tSPA_ASIZEBITS\t\t24\t \n\n#define\tSPA_COMPRESSBITS\t7\n#define\tSPA_VDEVBITS\t\t24\n#define\tSPA_COMPRESSMASK\t((1U << SPA_COMPRESSBITS) - 1)\n\n \ntypedef struct dva {\n\tuint64_t\tdva_word[2];\n} dva_t;\n\n\n \ntypedef struct zio_cksum_salt {\n\tuint8_t\t\tzcs_bytes[32];\n} zio_cksum_salt_t;\n\n \n\n \n\n \n\n#define\tBPE_GET_ETYPE(bp)\t\\\n\t(ASSERT(BP_IS_EMBEDDED(bp)), \\\n\tBF64_GET((bp)->blk_prop, 40, 8))\n#define\tBPE_SET_ETYPE(bp, t)\tdo { \\\n\tASSERT(BP_IS_EMBEDDED(bp)); \\\n\tBF64_SET((bp)->blk_prop, 40, 8, t); \\\n} while (0)\n\n#define\tBPE_GET_LSIZE(bp)\t\\\n\t(ASSERT(BP_IS_EMBEDDED(bp)), \\\n\tBF64_GET_SB((bp)->blk_prop, 0, 25, 0, 1))\n#define\tBPE_SET_LSIZE(bp, x)\tdo { \\\n\tASSERT(BP_IS_EMBEDDED(bp)); \\\n\tBF64_SET_SB((bp)->blk_prop, 0, 25, 0, 1, x); \\\n} while (0)\n\n#define\tBPE_GET_PSIZE(bp)\t\\\n\t(ASSERT(BP_IS_EMBEDDED(bp)), \\\n\tBF64_GET_SB((bp)->blk_prop, 25, 7, 0, 1))\n#define\tBPE_SET_PSIZE(bp, x)\tdo { \\\n\tASSERT(BP_IS_EMBEDDED(bp)); \\\n\tBF64_SET_SB((bp)->blk_prop, 25, 7, 0, 1, x); \\\n} while (0)\n\ntypedef enum bp_embedded_type {\n\tBP_EMBEDDED_TYPE_DATA,\n\tBP_EMBEDDED_TYPE_RESERVED,  \n\tBP_EMBEDDED_TYPE_REDACTED,\n\tNUM_BP_EMBEDDED_TYPES\n} bp_embedded_type_t;\n\n#define\tBPE_NUM_WORDS 14\n#define\tBPE_PAYLOAD_SIZE (BPE_NUM_WORDS * sizeof (uint64_t))\n#define\tBPE_IS_PAYLOADWORD(bp, wp) \\\n\t((wp) != &(bp)->blk_prop && (wp) != &(bp)->blk_birth)\n\n#define\tSPA_BLKPTRSHIFT\t7\t\t \n#define\tSPA_DVAS_PER_BP\t3\t\t \n#define\tSPA_SYNC_MIN_VDEVS 3\t\t \n\n \ntypedef struct blkptr {\n\tdva_t\t\tblk_dva[SPA_DVAS_PER_BP];  \n\tuint64_t\tblk_prop;\t \n\tuint64_t\tblk_pad[2];\t \n\tuint64_t\tblk_phys_birth;\t \n\tuint64_t\tblk_birth;\t \n\tuint64_t\tblk_fill;\t \n\tzio_cksum_t\tblk_cksum;\t \n} blkptr_t;\n\n \n\n \n#define\tDVA_GET_ASIZE(dva)\t\\\n\tBF64_GET_SB((dva)->dva_word[0], 0, SPA_ASIZEBITS, SPA_MINBLOCKSHIFT, 0)\n#define\tDVA_SET_ASIZE(dva, x)\t\\\n\tBF64_SET_SB((dva)->dva_word[0], 0, SPA_ASIZEBITS, \\\n\tSPA_MINBLOCKSHIFT, 0, x)\n\n#define\tDVA_GET_GRID(dva)\tBF64_GET((dva)->dva_word[0], 24, 8)\n#define\tDVA_SET_GRID(dva, x)\tBF64_SET((dva)->dva_word[0], 24, 8, x)\n\n#define\tDVA_GET_VDEV(dva)\tBF64_GET((dva)->dva_word[0], 32, SPA_VDEVBITS)\n#define\tDVA_SET_VDEV(dva, x)\t\\\n\tBF64_SET((dva)->dva_word[0], 32, SPA_VDEVBITS, x)\n\n#define\tDVA_GET_OFFSET(dva)\t\\\n\tBF64_GET_SB((dva)->dva_word[1], 0, 63, SPA_MINBLOCKSHIFT, 0)\n#define\tDVA_SET_OFFSET(dva, x)\t\\\n\tBF64_SET_SB((dva)->dva_word[1], 0, 63, SPA_MINBLOCKSHIFT, 0, x)\n\n#define\tDVA_GET_GANG(dva)\tBF64_GET((dva)->dva_word[1], 63, 1)\n#define\tDVA_SET_GANG(dva, x)\tBF64_SET((dva)->dva_word[1], 63, 1, x)\n\n#define\tBP_GET_LSIZE(bp)\t\\\n\t(BP_IS_EMBEDDED(bp) ?\t\\\n\t(BPE_GET_ETYPE(bp) == BP_EMBEDDED_TYPE_DATA ? BPE_GET_LSIZE(bp) : 0): \\\n\tBF64_GET_SB((bp)->blk_prop, 0, SPA_LSIZEBITS, SPA_MINBLOCKSHIFT, 1))\n#define\tBP_SET_LSIZE(bp, x)\tdo { \\\n\tASSERT(!BP_IS_EMBEDDED(bp)); \\\n\tBF64_SET_SB((bp)->blk_prop, \\\n\t    0, SPA_LSIZEBITS, SPA_MINBLOCKSHIFT, 1, x); \\\n} while (0)\n\n#define\tBP_GET_PSIZE(bp)\t\\\n\t(BP_IS_EMBEDDED(bp) ? 0 : \\\n\tBF64_GET_SB((bp)->blk_prop, 16, SPA_PSIZEBITS, SPA_MINBLOCKSHIFT, 1))\n#define\tBP_SET_PSIZE(bp, x)\tdo { \\\n\tASSERT(!BP_IS_EMBEDDED(bp)); \\\n\tBF64_SET_SB((bp)->blk_prop, \\\n\t    16, SPA_PSIZEBITS, SPA_MINBLOCKSHIFT, 1, x); \\\n} while (0)\n\n#define\tBP_GET_COMPRESS(bp)\t\t\\\n\tBF64_GET((bp)->blk_prop, 32, SPA_COMPRESSBITS)\n#define\tBP_SET_COMPRESS(bp, x)\t\t\\\n\tBF64_SET((bp)->blk_prop, 32, SPA_COMPRESSBITS, x)\n\n#define\tBP_IS_EMBEDDED(bp)\t\tBF64_GET((bp)->blk_prop, 39, 1)\n#define\tBP_SET_EMBEDDED(bp, x)\t\tBF64_SET((bp)->blk_prop, 39, 1, x)\n\n#define\tBP_GET_CHECKSUM(bp)\t\t\\\n\t(BP_IS_EMBEDDED(bp) ? ZIO_CHECKSUM_OFF : \\\n\tBF64_GET((bp)->blk_prop, 40, 8))\n#define\tBP_SET_CHECKSUM(bp, x)\t\tdo { \\\n\tASSERT(!BP_IS_EMBEDDED(bp)); \\\n\tBF64_SET((bp)->blk_prop, 40, 8, x); \\\n} while (0)\n\n#define\tBP_GET_TYPE(bp)\t\t\tBF64_GET((bp)->blk_prop, 48, 8)\n#define\tBP_SET_TYPE(bp, x)\t\tBF64_SET((bp)->blk_prop, 48, 8, x)\n\n#define\tBP_GET_LEVEL(bp)\t\tBF64_GET((bp)->blk_prop, 56, 5)\n#define\tBP_SET_LEVEL(bp, x)\t\tBF64_SET((bp)->blk_prop, 56, 5, x)\n\n \n#define\tBP_USES_CRYPT(bp)\t\tBF64_GET((bp)->blk_prop, 61, 1)\n#define\tBP_SET_CRYPT(bp, x)\t\tBF64_SET((bp)->blk_prop, 61, 1, x)\n\n#define\tBP_IS_ENCRYPTED(bp)\t\t\t\\\n\t(BP_USES_CRYPT(bp) &&\t\t\t\\\n\tBP_GET_LEVEL(bp) <= 0 &&\t\t\\\n\tDMU_OT_IS_ENCRYPTED(BP_GET_TYPE(bp)))\n\n#define\tBP_IS_AUTHENTICATED(bp)\t\t\t\\\n\t(BP_USES_CRYPT(bp) &&\t\t\t\\\n\tBP_GET_LEVEL(bp) <= 0 &&\t\t\\\n\t!DMU_OT_IS_ENCRYPTED(BP_GET_TYPE(bp)))\n\n#define\tBP_HAS_INDIRECT_MAC_CKSUM(bp)\t\t\\\n\t(BP_USES_CRYPT(bp) && BP_GET_LEVEL(bp) > 0)\n\n#define\tBP_IS_PROTECTED(bp)\t\t\t\\\n\t(BP_IS_ENCRYPTED(bp) || BP_IS_AUTHENTICATED(bp))\n\n#define\tBP_GET_DEDUP(bp)\t\tBF64_GET((bp)->blk_prop, 62, 1)\n#define\tBP_SET_DEDUP(bp, x)\t\tBF64_SET((bp)->blk_prop, 62, 1, x)\n\n#define\tBP_GET_BYTEORDER(bp)\t\tBF64_GET((bp)->blk_prop, 63, 1)\n#define\tBP_SET_BYTEORDER(bp, x)\t\tBF64_SET((bp)->blk_prop, 63, 1, x)\n\n#define\tBP_GET_FREE(bp)\t\t\tBF64_GET((bp)->blk_fill, 0, 1)\n#define\tBP_SET_FREE(bp, x)\t\tBF64_SET((bp)->blk_fill, 0, 1, x)\n\n#define\tBP_PHYSICAL_BIRTH(bp)\t\t\\\n\t(BP_IS_EMBEDDED(bp) ? 0 : \\\n\t(bp)->blk_phys_birth ? (bp)->blk_phys_birth : (bp)->blk_birth)\n\n#define\tBP_SET_BIRTH(bp, logical, physical)\t\\\n{\t\t\t\t\t\t\\\n\tASSERT(!BP_IS_EMBEDDED(bp));\t\t\\\n\t(bp)->blk_birth = (logical);\t\t\\\n\t(bp)->blk_phys_birth = ((logical) == (physical) ? 0 : (physical)); \\\n}\n\n#define\tBP_GET_FILL(bp)\t\t\t\t\\\n\t((BP_IS_ENCRYPTED(bp)) ? BF64_GET((bp)->blk_fill, 0, 32) : \\\n\t((BP_IS_EMBEDDED(bp)) ? 1 : (bp)->blk_fill))\n\n#define\tBP_SET_FILL(bp, fill)\t\t\t\\\n{\t\t\t\t\t\t\\\n\tif (BP_IS_ENCRYPTED(bp))\t\t\t\\\n\t\tBF64_SET((bp)->blk_fill, 0, 32, fill); \\\n\telse\t\t\t\t\t\\\n\t\t(bp)->blk_fill = fill;\t\t\\\n}\n\n#define\tBP_GET_IV2(bp)\t\t\t\t\\\n\t(ASSERT(BP_IS_ENCRYPTED(bp)),\t\t\\\n\tBF64_GET((bp)->blk_fill, 32, 32))\n#define\tBP_SET_IV2(bp, iv2)\t\t\t\\\n{\t\t\t\t\t\t\\\n\tASSERT(BP_IS_ENCRYPTED(bp));\t\t\\\n\tBF64_SET((bp)->blk_fill, 32, 32, iv2);\t\\\n}\n\n#define\tBP_IS_METADATA(bp)\t\\\n\t(BP_GET_LEVEL(bp) > 0 || DMU_OT_IS_METADATA(BP_GET_TYPE(bp)))\n\n#define\tBP_GET_ASIZE(bp)\t\\\n\t(BP_IS_EMBEDDED(bp) ? 0 : \\\n\tDVA_GET_ASIZE(&(bp)->blk_dva[0]) + \\\n\tDVA_GET_ASIZE(&(bp)->blk_dva[1]) + \\\n\t(DVA_GET_ASIZE(&(bp)->blk_dva[2]) * !BP_IS_ENCRYPTED(bp)))\n\n#define\tBP_GET_UCSIZE(bp)\t\\\n\t(BP_IS_METADATA(bp) ? BP_GET_PSIZE(bp) : BP_GET_LSIZE(bp))\n\n#define\tBP_GET_NDVAS(bp)\t\\\n\t(BP_IS_EMBEDDED(bp) ? 0 : \\\n\t!!DVA_GET_ASIZE(&(bp)->blk_dva[0]) + \\\n\t!!DVA_GET_ASIZE(&(bp)->blk_dva[1]) + \\\n\t(!!DVA_GET_ASIZE(&(bp)->blk_dva[2]) * !BP_IS_ENCRYPTED(bp)))\n\n#define\tBP_COUNT_GANG(bp)\t\\\n\t(BP_IS_EMBEDDED(bp) ? 0 : \\\n\t(DVA_GET_GANG(&(bp)->blk_dva[0]) + \\\n\tDVA_GET_GANG(&(bp)->blk_dva[1]) + \\\n\t(DVA_GET_GANG(&(bp)->blk_dva[2]) * !BP_IS_ENCRYPTED(bp))))\n\n#define\tDVA_EQUAL(dva1, dva2)\t\\\n\t((dva1)->dva_word[1] == (dva2)->dva_word[1] && \\\n\t(dva1)->dva_word[0] == (dva2)->dva_word[0])\n\n#define\tBP_EQUAL(bp1, bp2)\t\\\n\t(BP_PHYSICAL_BIRTH(bp1) == BP_PHYSICAL_BIRTH(bp2) &&\t\\\n\t(bp1)->blk_birth == (bp2)->blk_birth &&\t\t\t\\\n\tDVA_EQUAL(&(bp1)->blk_dva[0], &(bp2)->blk_dva[0]) &&\t\\\n\tDVA_EQUAL(&(bp1)->blk_dva[1], &(bp2)->blk_dva[1]) &&\t\\\n\tDVA_EQUAL(&(bp1)->blk_dva[2], &(bp2)->blk_dva[2]))\n\n\n#define\tDVA_IS_VALID(dva)\t(DVA_GET_ASIZE(dva) != 0)\n\n#define\tBP_IDENTITY(bp)\t\t(ASSERT(!BP_IS_EMBEDDED(bp)), &(bp)->blk_dva[0])\n#define\tBP_IS_GANG(bp)\t\t\\\n\t(BP_IS_EMBEDDED(bp) ? B_FALSE : DVA_GET_GANG(BP_IDENTITY(bp)))\n#define\tDVA_IS_EMPTY(dva)\t((dva)->dva_word[0] == 0ULL &&\t\\\n\t\t\t\t(dva)->dva_word[1] == 0ULL)\n#define\tBP_IS_HOLE(bp) \\\n\t(!BP_IS_EMBEDDED(bp) && DVA_IS_EMPTY(BP_IDENTITY(bp)))\n\n#define\tBP_SET_REDACTED(bp) \\\n{\t\t\t\t\t\t\t\\\n\tBP_SET_EMBEDDED(bp, B_TRUE);\t\t\t\\\n\tBPE_SET_ETYPE(bp, BP_EMBEDDED_TYPE_REDACTED);\t\\\n}\n#define\tBP_IS_REDACTED(bp) \\\n\t(BP_IS_EMBEDDED(bp) && BPE_GET_ETYPE(bp) == BP_EMBEDDED_TYPE_REDACTED)\n\n \n#define\tBP_IS_RAIDZ(bp)\t\t(DVA_GET_ASIZE(&(bp)->blk_dva[0]) > \\\n\t\t\t\tBP_GET_PSIZE(bp))\n\n#define\tBP_ZERO(bp)\t\t\t\t\\\n{\t\t\t\t\t\t\\\n\t(bp)->blk_dva[0].dva_word[0] = 0;\t\\\n\t(bp)->blk_dva[0].dva_word[1] = 0;\t\\\n\t(bp)->blk_dva[1].dva_word[0] = 0;\t\\\n\t(bp)->blk_dva[1].dva_word[1] = 0;\t\\\n\t(bp)->blk_dva[2].dva_word[0] = 0;\t\\\n\t(bp)->blk_dva[2].dva_word[1] = 0;\t\\\n\t(bp)->blk_prop = 0;\t\t\t\\\n\t(bp)->blk_pad[0] = 0;\t\t\t\\\n\t(bp)->blk_pad[1] = 0;\t\t\t\\\n\t(bp)->blk_phys_birth = 0;\t\t\\\n\t(bp)->blk_birth = 0;\t\t\t\\\n\t(bp)->blk_fill = 0;\t\t\t\\\n\tZIO_SET_CHECKSUM(&(bp)->blk_cksum, 0, 0, 0, 0);\t\\\n}\n\n#ifdef _ZFS_BIG_ENDIAN\n#define\tZFS_HOST_BYTEORDER\t(0ULL)\n#else\n#define\tZFS_HOST_BYTEORDER\t(1ULL)\n#endif\n\n#define\tBP_SHOULD_BYTESWAP(bp)\t(BP_GET_BYTEORDER(bp) != ZFS_HOST_BYTEORDER)\n\n#define\tBP_SPRINTF_LEN\t400\n\n \n\n#define\tSNPRINTF_BLKPTR(func, ws, buf, size, bp, type, checksum, compress) \\\n{\t\t\t\t\t\t\t\t\t\\\n\tstatic const char *const copyname[] =\t\t\t\t\\\n\t    { \"zero\", \"single\", \"double\", \"triple\" };\t\t\t\\\n\tint len = 0;\t\t\t\t\t\t\t\\\n\tint copies = 0;\t\t\t\t\t\t\t\\\n\tconst char *crypt_type;\t\t\t\t\t\t\\\n\tif (bp != NULL) {\t\t\t\t\t\t\\\n\t\tif (BP_IS_ENCRYPTED(bp)) {\t\t\t\t\\\n\t\t\tcrypt_type = \"encrypted\";\t\t\t\\\n\t\t\t \t\t\\\n\t\t} else if (BP_IS_AUTHENTICATED(bp)) {\t\t\t\\\n\t\t\tcrypt_type = \"authenticated\";\t\t\t\\\n\t\t} else if (BP_HAS_INDIRECT_MAC_CKSUM(bp)) {\t\t\\\n\t\t\tcrypt_type = \"indirect-MAC\";\t\t\t\\\n\t\t} else {\t\t\t\t\t\t\\\n\t\t\tcrypt_type = \"unencrypted\";\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\tif (bp == NULL) {\t\t\t\t\t\t\\\n\t\tlen += func(buf + len, size - len, \"<NULL>\");\t\t\\\n\t} else if (BP_IS_HOLE(bp)) {\t\t\t\t\t\\\n\t\tlen += func(buf + len, size - len,\t\t\t\\\n\t\t    \"HOLE [L%llu %s] \"\t\t\t\t\t\\\n\t\t    \"size=%llxL birth=%lluL\",\t\t\t\t\\\n\t\t    (u_longlong_t)BP_GET_LEVEL(bp),\t\t\t\\\n\t\t    type,\t\t\t\t\t\t\\\n\t\t    (u_longlong_t)BP_GET_LSIZE(bp),\t\t\t\\\n\t\t    (u_longlong_t)bp->blk_birth);\t\t\t\\\n\t} else if (BP_IS_EMBEDDED(bp)) {\t\t\t\t\\\n\t\tlen = func(buf + len, size - len,\t\t\t\\\n\t\t    \"EMBEDDED [L%llu %s] et=%u %s \"\t\t\t\\\n\t\t    \"size=%llxL/%llxP birth=%lluL\",\t\t\t\\\n\t\t    (u_longlong_t)BP_GET_LEVEL(bp),\t\t\t\\\n\t\t    type,\t\t\t\t\t\t\\\n\t\t    (int)BPE_GET_ETYPE(bp),\t\t\t\t\\\n\t\t    compress,\t\t\t\t\t\t\\\n\t\t    (u_longlong_t)BPE_GET_LSIZE(bp),\t\t\t\\\n\t\t    (u_longlong_t)BPE_GET_PSIZE(bp),\t\t\t\\\n\t\t    (u_longlong_t)bp->blk_birth);\t\t\t\\\n\t} else if (BP_IS_REDACTED(bp)) {\t\t\t\t\\\n\t\tlen += func(buf + len, size - len,\t\t\t\\\n\t\t    \"REDACTED [L%llu %s] size=%llxL birth=%lluL\",\t\\\n\t\t    (u_longlong_t)BP_GET_LEVEL(bp),\t\t\t\\\n\t\t    type,\t\t\t\t\t\t\\\n\t\t    (u_longlong_t)BP_GET_LSIZE(bp),\t\t\t\\\n\t\t    (u_longlong_t)bp->blk_birth);\t\t\t\\\n\t} else {\t\t\t\t\t\t\t\\\n\t\tfor (int d = 0; d < BP_GET_NDVAS(bp); d++) {\t\t\\\n\t\t\tconst dva_t *dva = &bp->blk_dva[d];\t\t\\\n\t\t\tif (DVA_IS_VALID(dva))\t\t\t\t\\\n\t\t\t\tcopies++;\t\t\t\t\\\n\t\t\tlen += func(buf + len, size - len,\t\t\\\n\t\t\t    \"DVA[%d]=<%llu:%llx:%llx>%c\", d,\t\t\\\n\t\t\t    (u_longlong_t)DVA_GET_VDEV(dva),\t\t\\\n\t\t\t    (u_longlong_t)DVA_GET_OFFSET(dva),\t\t\\\n\t\t\t    (u_longlong_t)DVA_GET_ASIZE(dva),\t\t\\\n\t\t\t    ws);\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t\tASSERT3S(copies, >, 0);\t\t\t\t\t\\\n\t\tif (BP_IS_ENCRYPTED(bp)) {\t\t\t\t\\\n\t\t\tlen += func(buf + len, size - len,\t\t\\\n\t\t\t    \"salt=%llx iv=%llx:%llx%c\",\t\t\t\\\n\t\t\t    (u_longlong_t)bp->blk_dva[2].dva_word[0],\t\\\n\t\t\t    (u_longlong_t)bp->blk_dva[2].dva_word[1],\t\\\n\t\t\t    (u_longlong_t)BP_GET_IV2(bp),\t\t\\\n\t\t\t    ws);\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t\tif (BP_IS_GANG(bp) &&\t\t\t\t\t\\\n\t\t    DVA_GET_ASIZE(&bp->blk_dva[2]) <=\t\t\t\\\n\t\t    DVA_GET_ASIZE(&bp->blk_dva[1]) / 2)\t\t\t\\\n\t\t\tcopies--;\t\t\t\t\t\\\n\t\tlen += func(buf + len, size - len,\t\t\t\\\n\t\t    \"[L%llu %s] %s %s %s %s %s %s %s%c\"\t\t\t\\\n\t\t    \"size=%llxL/%llxP birth=%lluL/%lluP fill=%llu%c\"\t\\\n\t\t    \"cksum=%016llx:%016llx:%016llx:%016llx\",\t\t\\\n\t\t    (u_longlong_t)BP_GET_LEVEL(bp),\t\t\t\\\n\t\t    type,\t\t\t\t\t\t\\\n\t\t    checksum,\t\t\t\t\t\t\\\n\t\t    compress,\t\t\t\t\t\t\\\n\t\t    crypt_type,\t\t\t\t\t\t\\\n\t\t    BP_GET_BYTEORDER(bp) == 0 ? \"BE\" : \"LE\",\t\t\\\n\t\t    BP_IS_GANG(bp) ? \"gang\" : \"contiguous\",\t\t\\\n\t\t    BP_GET_DEDUP(bp) ? \"dedup\" : \"unique\",\t\t\\\n\t\t    copyname[copies],\t\t\t\t\t\\\n\t\t    ws,\t\t\t\t\t\t\t\\\n\t\t    (u_longlong_t)BP_GET_LSIZE(bp),\t\t\t\\\n\t\t    (u_longlong_t)BP_GET_PSIZE(bp),\t\t\t\\\n\t\t    (u_longlong_t)bp->blk_birth,\t\t\t\\\n\t\t    (u_longlong_t)BP_PHYSICAL_BIRTH(bp),\t\t\\\n\t\t    (u_longlong_t)BP_GET_FILL(bp),\t\t\t\\\n\t\t    ws,\t\t\t\t\t\t\t\\\n\t\t    (u_longlong_t)bp->blk_cksum.zc_word[0],\t\t\\\n\t\t    (u_longlong_t)bp->blk_cksum.zc_word[1],\t\t\\\n\t\t    (u_longlong_t)bp->blk_cksum.zc_word[2],\t\t\\\n\t\t    (u_longlong_t)bp->blk_cksum.zc_word[3]);\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\tASSERT(len < size);\t\t\t\t\t\t\\\n}\n\n#define\tBP_GET_BUFC_TYPE(bp)\t\t\t\t\t\t\\\n\t(BP_IS_METADATA(bp) ? ARC_BUFC_METADATA : ARC_BUFC_DATA)\n\ntypedef enum spa_import_type {\n\tSPA_IMPORT_EXISTING,\n\tSPA_IMPORT_ASSEMBLE\n} spa_import_type_t;\n\ntypedef enum spa_mode {\n\tSPA_MODE_UNINIT = 0,\n\tSPA_MODE_READ = 1,\n\tSPA_MODE_WRITE = 2,\n} spa_mode_t;\n\n \ntypedef enum {\n\tSPA_AUTOTRIM_OFF = 0,\t \n\tSPA_AUTOTRIM_ON,\n} spa_autotrim_t;\n\n \ntypedef enum trim_type {\n\tTRIM_TYPE_MANUAL = 0,\n\tTRIM_TYPE_AUTO = 1,\n\tTRIM_TYPE_SIMPLE = 2\n} trim_type_t;\n\n \nextern int spa_open(const char *pool, spa_t **, const void *tag);\nextern int spa_open_rewind(const char *pool, spa_t **, const void *tag,\n    nvlist_t *policy, nvlist_t **config);\nextern int spa_get_stats(const char *pool, nvlist_t **config, char *altroot,\n    size_t buflen);\nextern int spa_create(const char *pool, nvlist_t *nvroot, nvlist_t *props,\n    nvlist_t *zplprops, struct dsl_crypto_params *dcp);\nextern int spa_import(char *pool, nvlist_t *config, nvlist_t *props,\n    uint64_t flags);\nextern nvlist_t *spa_tryimport(nvlist_t *tryconfig);\nextern int spa_destroy(const char *pool);\nextern int spa_checkpoint(const char *pool);\nextern int spa_checkpoint_discard(const char *pool);\nextern int spa_export(const char *pool, nvlist_t **oldconfig, boolean_t force,\n    boolean_t hardforce);\nextern int spa_reset(const char *pool);\nextern void spa_async_request(spa_t *spa, int flag);\nextern void spa_async_unrequest(spa_t *spa, int flag);\nextern void spa_async_suspend(spa_t *spa);\nextern void spa_async_resume(spa_t *spa);\nextern int spa_async_tasks(spa_t *spa);\nextern spa_t *spa_inject_addref(char *pool);\nextern void spa_inject_delref(spa_t *spa);\nextern void spa_scan_stat_init(spa_t *spa);\nextern int spa_scan_get_stats(spa_t *spa, pool_scan_stat_t *ps);\nextern int bpobj_enqueue_alloc_cb(void *arg, const blkptr_t *bp, dmu_tx_t *tx);\nextern int bpobj_enqueue_free_cb(void *arg, const blkptr_t *bp, dmu_tx_t *tx);\n\n#define\tSPA_ASYNC_CONFIG_UPDATE\t\t\t0x01\n#define\tSPA_ASYNC_REMOVE\t\t\t0x02\n#define\tSPA_ASYNC_PROBE\t\t\t\t0x04\n#define\tSPA_ASYNC_RESILVER_DONE\t\t\t0x08\n#define\tSPA_ASYNC_RESILVER\t\t\t0x10\n#define\tSPA_ASYNC_AUTOEXPAND\t\t\t0x20\n#define\tSPA_ASYNC_REMOVE_DONE\t\t\t0x40\n#define\tSPA_ASYNC_REMOVE_STOP\t\t\t0x80\n#define\tSPA_ASYNC_INITIALIZE_RESTART\t\t0x100\n#define\tSPA_ASYNC_TRIM_RESTART\t\t\t0x200\n#define\tSPA_ASYNC_AUTOTRIM_RESTART\t\t0x400\n#define\tSPA_ASYNC_L2CACHE_REBUILD\t\t0x800\n#define\tSPA_ASYNC_L2CACHE_TRIM\t\t\t0x1000\n#define\tSPA_ASYNC_REBUILD_DONE\t\t\t0x2000\n#define\tSPA_ASYNC_DETACH_SPARE\t\t\t0x4000\n\n \nextern int spa_vdev_add(spa_t *spa, nvlist_t *nvroot);\nextern int spa_vdev_attach(spa_t *spa, uint64_t guid, nvlist_t *nvroot,\n    int replacing, int rebuild);\nextern int spa_vdev_detach(spa_t *spa, uint64_t guid, uint64_t pguid,\n    int replace_done);\nextern int spa_vdev_alloc(spa_t *spa, uint64_t guid);\nextern int spa_vdev_noalloc(spa_t *spa, uint64_t guid);\nextern boolean_t spa_vdev_remove_active(spa_t *spa);\nextern int spa_vdev_initialize(spa_t *spa, nvlist_t *nv, uint64_t cmd_type,\n    nvlist_t *vdev_errlist);\nextern int spa_vdev_trim(spa_t *spa, nvlist_t *nv, uint64_t cmd_type,\n    uint64_t rate, boolean_t partial, boolean_t secure, nvlist_t *vdev_errlist);\nextern int spa_vdev_setpath(spa_t *spa, uint64_t guid, const char *newpath);\nextern int spa_vdev_setfru(spa_t *spa, uint64_t guid, const char *newfru);\nextern int spa_vdev_split_mirror(spa_t *spa, const char *newname,\n    nvlist_t *config, nvlist_t *props, boolean_t exp);\n\n \nextern void spa_spare_add(vdev_t *vd);\nextern void spa_spare_remove(vdev_t *vd);\nextern boolean_t spa_spare_exists(uint64_t guid, uint64_t *pool, int *refcnt);\nextern void spa_spare_activate(vdev_t *vd);\n\n \nextern void spa_l2cache_add(vdev_t *vd);\nextern void spa_l2cache_remove(vdev_t *vd);\nextern boolean_t spa_l2cache_exists(uint64_t guid, uint64_t *pool);\nextern void spa_l2cache_activate(vdev_t *vd);\nextern void spa_l2cache_drop(spa_t *spa);\n\n \nextern int spa_scan(spa_t *spa, pool_scan_func_t func);\nextern int spa_scan_stop(spa_t *spa);\nextern int spa_scrub_pause_resume(spa_t *spa, pool_scrub_cmd_t flag);\n\n \nextern void spa_sync(spa_t *spa, uint64_t txg);  \nextern void spa_sync_allpools(void);\n\nextern uint_t zfs_sync_pass_deferred_free;\n\n \nextern kmutex_t spa_namespace_lock;\n\n \n\n#define\tSPA_CONFIG_UPDATE_POOL\t0\n#define\tSPA_CONFIG_UPDATE_VDEVS\t1\n\nextern void spa_write_cachefile(spa_t *, boolean_t, boolean_t, boolean_t);\nextern void spa_config_load(void);\nextern int spa_all_configs(uint64_t *generation, nvlist_t **pools);\nextern void spa_config_set(spa_t *spa, nvlist_t *config);\nextern nvlist_t *spa_config_generate(spa_t *spa, vdev_t *vd, uint64_t txg,\n    int getstats);\nextern void spa_config_update(spa_t *spa, int what);\nextern int spa_config_parse(spa_t *spa, vdev_t **vdp, nvlist_t *nv,\n    vdev_t *parent, uint_t id, int atype);\n\n\n \n\n \nextern spa_t *spa_lookup(const char *name);\nextern spa_t *spa_add(const char *name, nvlist_t *config, const char *altroot);\nextern void spa_remove(spa_t *spa);\nextern spa_t *spa_next(spa_t *prev);\n\n \nextern void spa_open_ref(spa_t *spa, const void *tag);\nextern void spa_close(spa_t *spa, const void *tag);\nextern void spa_async_close(spa_t *spa, const void *tag);\nextern boolean_t spa_refcount_zero(spa_t *spa);\n\n#define\tSCL_NONE\t0x00\n#define\tSCL_CONFIG\t0x01\n#define\tSCL_STATE\t0x02\n#define\tSCL_L2ARC\t0x04\t\t \n#define\tSCL_ALLOC\t0x08\n#define\tSCL_ZIO\t\t0x10\n#define\tSCL_FREE\t0x20\n#define\tSCL_VDEV\t0x40\n#define\tSCL_LOCKS\t7\n#define\tSCL_ALL\t\t((1 << SCL_LOCKS) - 1)\n#define\tSCL_STATE_ALL\t(SCL_STATE | SCL_L2ARC | SCL_ZIO)\n\n \ntypedef struct spa_history_kstat {\n\tkmutex_t\t\tlock;\n\tuint64_t\t\tcount;\n\tuint64_t\t\tsize;\n\tkstat_t\t\t\t*kstat;\n\tvoid\t\t\t*priv;\n\tlist_t\t\t\tlist;\n} spa_history_kstat_t;\n\ntypedef struct spa_history_list {\n\tuint64_t\t\tsize;\n\tprocfs_list_t\t\tprocfs_list;\n} spa_history_list_t;\n\ntypedef struct spa_stats {\n\tspa_history_list_t\tread_history;\n\tspa_history_list_t\ttxg_history;\n\tspa_history_kstat_t\ttx_assign_histogram;\n\tspa_history_list_t\tmmp_history;\n\tspa_history_kstat_t\tstate;\t\t \n\tspa_history_kstat_t\tguid;\t\t \n\tspa_history_kstat_t\tiostats;\n} spa_stats_t;\n\ntypedef enum txg_state {\n\tTXG_STATE_BIRTH\t\t= 0,\n\tTXG_STATE_OPEN\t\t= 1,\n\tTXG_STATE_QUIESCED\t= 2,\n\tTXG_STATE_WAIT_FOR_SYNC\t= 3,\n\tTXG_STATE_SYNCED\t= 4,\n\tTXG_STATE_COMMITTED\t= 5,\n} txg_state_t;\n\ntypedef struct txg_stat {\n\tvdev_stat_t\t\tvs1;\n\tvdev_stat_t\t\tvs2;\n\tuint64_t\t\ttxg;\n\tuint64_t\t\tndirty;\n} txg_stat_t;\n\n \ntypedef struct spa_iostats {\n\tkstat_named_t\ttrim_extents_written;\n\tkstat_named_t\ttrim_bytes_written;\n\tkstat_named_t\ttrim_extents_skipped;\n\tkstat_named_t\ttrim_bytes_skipped;\n\tkstat_named_t\ttrim_extents_failed;\n\tkstat_named_t\ttrim_bytes_failed;\n\tkstat_named_t\tautotrim_extents_written;\n\tkstat_named_t\tautotrim_bytes_written;\n\tkstat_named_t\tautotrim_extents_skipped;\n\tkstat_named_t\tautotrim_bytes_skipped;\n\tkstat_named_t\tautotrim_extents_failed;\n\tkstat_named_t\tautotrim_bytes_failed;\n\tkstat_named_t\tsimple_trim_extents_written;\n\tkstat_named_t\tsimple_trim_bytes_written;\n\tkstat_named_t\tsimple_trim_extents_skipped;\n\tkstat_named_t\tsimple_trim_bytes_skipped;\n\tkstat_named_t\tsimple_trim_extents_failed;\n\tkstat_named_t\tsimple_trim_bytes_failed;\n} spa_iostats_t;\n\nextern void spa_stats_init(spa_t *spa);\nextern void spa_stats_destroy(spa_t *spa);\nextern void spa_read_history_add(spa_t *spa, const zbookmark_phys_t *zb,\n    uint32_t aflags);\nextern void spa_txg_history_add(spa_t *spa, uint64_t txg, hrtime_t birth_time);\nextern int spa_txg_history_set(spa_t *spa,  uint64_t txg,\n    txg_state_t completed_state, hrtime_t completed_time);\nextern txg_stat_t *spa_txg_history_init_io(spa_t *, uint64_t,\n    struct dsl_pool *);\nextern void spa_txg_history_fini_io(spa_t *, txg_stat_t *);\nextern void spa_tx_assign_add_nsecs(spa_t *spa, uint64_t nsecs);\nextern int spa_mmp_history_set_skip(spa_t *spa, uint64_t mmp_kstat_id);\nextern int spa_mmp_history_set(spa_t *spa, uint64_t mmp_kstat_id, int io_error,\n    hrtime_t duration);\nextern void spa_mmp_history_add(spa_t *spa, uint64_t txg, uint64_t timestamp,\n    uint64_t mmp_delay, vdev_t *vd, int label, uint64_t mmp_kstat_id,\n    int error);\nextern void spa_iostats_trim_add(spa_t *spa, trim_type_t type,\n    uint64_t extents_written, uint64_t bytes_written,\n    uint64_t extents_skipped, uint64_t bytes_skipped,\n    uint64_t extents_failed, uint64_t bytes_failed);\nextern void spa_import_progress_add(spa_t *spa);\nextern void spa_import_progress_remove(uint64_t spa_guid);\nextern int spa_import_progress_set_mmp_check(uint64_t pool_guid,\n    uint64_t mmp_sec_remaining);\nextern int spa_import_progress_set_max_txg(uint64_t pool_guid,\n    uint64_t max_txg);\nextern int spa_import_progress_set_state(uint64_t pool_guid,\n    spa_load_state_t spa_load_state);\n\n \nextern int spa_config_tryenter(spa_t *spa, int locks, const void *tag,\n    krw_t rw);\nextern void spa_config_enter(spa_t *spa, int locks, const void *tag, krw_t rw);\nextern void spa_config_enter_mmp(spa_t *spa, int locks, const void *tag,\n    krw_t rw);\nextern void spa_config_exit(spa_t *spa, int locks, const void *tag);\nextern int spa_config_held(spa_t *spa, int locks, krw_t rw);\n\n \nextern uint64_t spa_vdev_enter(spa_t *spa);\nextern uint64_t spa_vdev_detach_enter(spa_t *spa, uint64_t guid);\nextern uint64_t spa_vdev_config_enter(spa_t *spa);\nextern void spa_vdev_config_exit(spa_t *spa, vdev_t *vd, uint64_t txg,\n    int error, const char *tag);\nextern int spa_vdev_exit(spa_t *spa, vdev_t *vd, uint64_t txg, int error);\n\n \nextern void spa_vdev_state_enter(spa_t *spa, int oplock);\nextern int spa_vdev_state_exit(spa_t *spa, vdev_t *vd, int error);\n\n \ntypedef enum spa_log_state {\n\tSPA_LOG_UNKNOWN = 0,\t \n\tSPA_LOG_MISSING,\t \n\tSPA_LOG_CLEAR,\t\t \n\tSPA_LOG_GOOD,\t\t \n} spa_log_state_t;\n\nextern spa_log_state_t spa_get_log_state(spa_t *spa);\nextern void spa_set_log_state(spa_t *spa, spa_log_state_t state);\nextern int spa_reset_logs(spa_t *spa);\n\n \nextern void spa_claim_notify(zio_t *zio);\nextern void spa_deadman(void *);\n\n \nextern boolean_t spa_shutting_down(spa_t *spa);\nextern struct dsl_pool *spa_get_dsl(spa_t *spa);\nextern boolean_t spa_is_initializing(spa_t *spa);\nextern boolean_t spa_indirect_vdevs_loaded(spa_t *spa);\nextern blkptr_t *spa_get_rootblkptr(spa_t *spa);\nextern void spa_set_rootblkptr(spa_t *spa, const blkptr_t *bp);\nextern void spa_altroot(spa_t *, char *, size_t);\nextern uint32_t spa_sync_pass(spa_t *spa);\nextern char *spa_name(spa_t *spa);\nextern uint64_t spa_guid(spa_t *spa);\nextern uint64_t spa_load_guid(spa_t *spa);\nextern uint64_t spa_last_synced_txg(spa_t *spa);\nextern uint64_t spa_first_txg(spa_t *spa);\nextern uint64_t spa_syncing_txg(spa_t *spa);\nextern uint64_t spa_final_dirty_txg(spa_t *spa);\nextern uint64_t spa_version(spa_t *spa);\nextern pool_state_t spa_state(spa_t *spa);\nextern spa_load_state_t spa_load_state(spa_t *spa);\nextern uint64_t spa_freeze_txg(spa_t *spa);\nextern uint64_t spa_get_worst_case_asize(spa_t *spa, uint64_t lsize);\nextern uint64_t spa_get_dspace(spa_t *spa);\nextern uint64_t spa_get_checkpoint_space(spa_t *spa);\nextern uint64_t spa_get_slop_space(spa_t *spa);\nextern void spa_update_dspace(spa_t *spa);\nextern uint64_t spa_version(spa_t *spa);\nextern boolean_t spa_deflate(spa_t *spa);\nextern metaslab_class_t *spa_normal_class(spa_t *spa);\nextern metaslab_class_t *spa_log_class(spa_t *spa);\nextern metaslab_class_t *spa_embedded_log_class(spa_t *spa);\nextern metaslab_class_t *spa_special_class(spa_t *spa);\nextern metaslab_class_t *spa_dedup_class(spa_t *spa);\nextern metaslab_class_t *spa_preferred_class(spa_t *spa, uint64_t size,\n    dmu_object_type_t objtype, uint_t level, uint_t special_smallblk);\n\nextern void spa_evicting_os_register(spa_t *, objset_t *os);\nextern void spa_evicting_os_deregister(spa_t *, objset_t *os);\nextern void spa_evicting_os_wait(spa_t *spa);\nextern int spa_max_replication(spa_t *spa);\nextern int spa_prev_software_version(spa_t *spa);\nextern uint64_t spa_get_failmode(spa_t *spa);\nextern uint64_t spa_get_deadman_failmode(spa_t *spa);\nextern void spa_set_deadman_failmode(spa_t *spa, const char *failmode);\nextern boolean_t spa_suspended(spa_t *spa);\nextern uint64_t spa_bootfs(spa_t *spa);\nextern uint64_t spa_delegation(spa_t *spa);\nextern objset_t *spa_meta_objset(spa_t *spa);\nextern space_map_t *spa_syncing_log_sm(spa_t *spa);\nextern uint64_t spa_deadman_synctime(spa_t *spa);\nextern uint64_t spa_deadman_ziotime(spa_t *spa);\nextern uint64_t spa_dirty_data(spa_t *spa);\nextern spa_autotrim_t spa_get_autotrim(spa_t *spa);\n\n \nextern void spa_load_failed(spa_t *spa, const char *fmt, ...)\n    __attribute__((format(printf, 2, 3)));\nextern void spa_load_note(spa_t *spa, const char *fmt, ...)\n    __attribute__((format(printf, 2, 3)));\nextern void spa_activate_mos_feature(spa_t *spa, const char *feature,\n    dmu_tx_t *tx);\nextern void spa_deactivate_mos_feature(spa_t *spa, const char *feature);\nextern spa_t *spa_by_guid(uint64_t pool_guid, uint64_t device_guid);\nextern boolean_t spa_guid_exists(uint64_t pool_guid, uint64_t device_guid);\nextern char *spa_strdup(const char *);\nextern void spa_strfree(char *);\nextern uint64_t spa_generate_guid(spa_t *spa);\nextern void snprintf_blkptr(char *buf, size_t buflen, const blkptr_t *bp);\nextern void spa_freeze(spa_t *spa);\nextern int spa_change_guid(spa_t *spa);\nextern void spa_upgrade(spa_t *spa, uint64_t version);\nextern void spa_evict_all(void);\nextern vdev_t *spa_lookup_by_guid(spa_t *spa, uint64_t guid,\n    boolean_t l2cache);\nextern boolean_t spa_has_l2cache(spa_t *, uint64_t guid);\nextern boolean_t spa_has_spare(spa_t *, uint64_t guid);\nextern uint64_t dva_get_dsize_sync(spa_t *spa, const dva_t *dva);\nextern uint64_t bp_get_dsize_sync(spa_t *spa, const blkptr_t *bp);\nextern uint64_t bp_get_dsize(spa_t *spa, const blkptr_t *bp);\nextern boolean_t spa_has_slogs(spa_t *spa);\nextern boolean_t spa_is_root(spa_t *spa);\nextern boolean_t spa_writeable(spa_t *spa);\nextern boolean_t spa_has_pending_synctask(spa_t *spa);\nextern int spa_maxblocksize(spa_t *spa);\nextern int spa_maxdnodesize(spa_t *spa);\nextern boolean_t spa_has_checkpoint(spa_t *spa);\nextern boolean_t spa_importing_readonly_checkpoint(spa_t *spa);\nextern boolean_t spa_suspend_async_destroy(spa_t *spa);\nextern uint64_t spa_min_claim_txg(spa_t *spa);\nextern boolean_t zfs_dva_valid(spa_t *spa, const dva_t *dva,\n    const blkptr_t *bp);\ntypedef void (*spa_remap_cb_t)(uint64_t vdev, uint64_t offset, uint64_t size,\n    void *arg);\nextern boolean_t spa_remap_blkptr(spa_t *spa, blkptr_t *bp,\n    spa_remap_cb_t callback, void *arg);\nextern uint64_t spa_get_last_removal_txg(spa_t *spa);\nextern boolean_t spa_trust_config(spa_t *spa);\nextern uint64_t spa_missing_tvds_allowed(spa_t *spa);\nextern void spa_set_missing_tvds(spa_t *spa, uint64_t missing);\nextern boolean_t spa_top_vdevs_spacemap_addressable(spa_t *spa);\nextern uint64_t spa_total_metaslabs(spa_t *spa);\nextern boolean_t spa_multihost(spa_t *spa);\nextern uint32_t spa_get_hostid(spa_t *spa);\nextern void spa_activate_allocation_classes(spa_t *, dmu_tx_t *);\nextern boolean_t spa_livelist_delete_check(spa_t *spa);\n\nextern spa_mode_t spa_mode(spa_t *spa);\nextern uint64_t zfs_strtonum(const char *str, char **nptr);\n\nextern char *spa_his_ievent_table[];\n\nextern void spa_history_create_obj(spa_t *spa, dmu_tx_t *tx);\nextern int spa_history_get(spa_t *spa, uint64_t *offset, uint64_t *len_read,\n    char *his_buf);\nextern int spa_history_log(spa_t *spa, const char *his_buf);\nextern int spa_history_log_nvl(spa_t *spa, nvlist_t *nvl);\nextern void spa_history_log_version(spa_t *spa, const char *operation,\n    dmu_tx_t *tx);\nextern void spa_history_log_internal(spa_t *spa, const char *operation,\n    dmu_tx_t *tx, const char *fmt, ...) __printflike(4, 5);\nextern void spa_history_log_internal_ds(struct dsl_dataset *ds, const char *op,\n    dmu_tx_t *tx, const char *fmt, ...)  __printflike(4, 5);\nextern void spa_history_log_internal_dd(dsl_dir_t *dd, const char *operation,\n    dmu_tx_t *tx, const char *fmt, ...) __printflike(4, 5);\n\nextern const char *spa_state_to_name(spa_t *spa);\n\n \nstruct zbookmark_phys;\nextern void spa_log_error(spa_t *spa, const zbookmark_phys_t *zb,\n    const uint64_t *birth);\nextern void spa_remove_error(spa_t *spa, zbookmark_phys_t *zb,\n    const uint64_t *birth);\nextern int zfs_ereport_post(const char *clazz, spa_t *spa, vdev_t *vd,\n    const zbookmark_phys_t *zb, zio_t *zio, uint64_t state);\nextern boolean_t zfs_ereport_is_valid(const char *clazz, spa_t *spa, vdev_t *vd,\n    zio_t *zio);\nextern void zfs_ereport_taskq_fini(void);\nextern void zfs_ereport_clear(spa_t *spa, vdev_t *vd);\nextern nvlist_t *zfs_event_create(spa_t *spa, vdev_t *vd, const char *type,\n    const char *name, nvlist_t *aux);\nextern void zfs_post_remove(spa_t *spa, vdev_t *vd);\nextern void zfs_post_state_change(spa_t *spa, vdev_t *vd, uint64_t laststate);\nextern void zfs_post_autoreplace(spa_t *spa, vdev_t *vd);\nextern uint64_t spa_approx_errlog_size(spa_t *spa);\nextern int spa_get_errlog(spa_t *spa, void *uaddr, uint64_t *count);\nextern uint64_t spa_get_last_errlog_size(spa_t *spa);\nextern void spa_errlog_rotate(spa_t *spa);\nextern void spa_errlog_drain(spa_t *spa);\nextern void spa_errlog_sync(spa_t *spa, uint64_t txg);\nextern void spa_get_errlists(spa_t *spa, avl_tree_t *last, avl_tree_t *scrub);\nextern void spa_delete_dataset_errlog(spa_t *spa, uint64_t ds, dmu_tx_t *tx);\nextern void spa_swap_errlog(spa_t *spa, uint64_t new_head_ds,\n    uint64_t old_head_ds, dmu_tx_t *tx);\nextern void sync_error_list(spa_t *spa, avl_tree_t *t, uint64_t *obj,\n    dmu_tx_t *tx);\nextern void spa_upgrade_errlog(spa_t *spa, dmu_tx_t *tx);\nextern int find_top_affected_fs(spa_t *spa, uint64_t head_ds,\n    zbookmark_err_phys_t *zep, uint64_t *top_affected_fs);\nextern int find_birth_txg(struct dsl_dataset *ds, zbookmark_err_phys_t *zep,\n    uint64_t *birth_txg);\nextern void zep_to_zb(uint64_t dataset, zbookmark_err_phys_t *zep,\n    zbookmark_phys_t *zb);\nextern void name_to_errphys(char *buf, zbookmark_err_phys_t *zep);\n\n \nextern void vdev_mirror_stat_init(void);\nextern void vdev_mirror_stat_fini(void);\n\n \nextern void spa_init(spa_mode_t mode);\nextern void spa_fini(void);\nextern void spa_boot_init(void);\n\n \nextern int spa_prop_set(spa_t *spa, nvlist_t *nvp);\nextern int spa_prop_get(spa_t *spa, nvlist_t **nvp);\nextern void spa_prop_clear_bootfs(spa_t *spa, uint64_t obj, dmu_tx_t *tx);\nextern void spa_configfile_set(spa_t *, nvlist_t *, boolean_t);\n\n \nextern void spa_event_notify(spa_t *spa, vdev_t *vdev, nvlist_t *hist_nvl,\n    const char *name);\nextern void zfs_ereport_zvol_post(const char *subclass, const char *name,\n    const char *device_name, const char *raw_name);\n\n \nextern int spa_wait(const char *pool, zpool_wait_activity_t activity,\n    boolean_t *waited);\nextern int spa_wait_tag(const char *name, zpool_wait_activity_t activity,\n    uint64_t tag, boolean_t *waited);\nextern void spa_notify_waiters(spa_t *spa);\nextern void spa_wake_waiters(spa_t *spa);\n\nextern void spa_import_os(spa_t *spa);\nextern void spa_export_os(spa_t *spa);\nextern void spa_activate_os(spa_t *spa);\nextern void spa_deactivate_os(spa_t *spa);\n\n \nint param_set_deadman_ziotime(ZFS_MODULE_PARAM_ARGS);\nint param_set_deadman_synctime(ZFS_MODULE_PARAM_ARGS);\nint param_set_slop_shift(ZFS_MODULE_PARAM_ARGS);\nint param_set_deadman_failmode(ZFS_MODULE_PARAM_ARGS);\n\n#ifdef ZFS_DEBUG\n#define\tdprintf_bp(bp, fmt, ...) do {\t\t\t\t\\\n\tif (zfs_flags & ZFS_DEBUG_DPRINTF) {\t\t\t\\\n\tchar *__blkbuf = kmem_alloc(BP_SPRINTF_LEN, KM_SLEEP);\t\\\n\tsnprintf_blkptr(__blkbuf, BP_SPRINTF_LEN, (bp));\t\\\n\tdprintf(fmt \" %s\\n\", __VA_ARGS__, __blkbuf);\t\t\\\n\tkmem_free(__blkbuf, BP_SPRINTF_LEN);\t\t\t\\\n\t} \\\n} while (0)\n#else\n#define\tdprintf_bp(bp, fmt, ...)\n#endif\n\nextern spa_mode_t spa_mode_global;\nextern int zfs_deadman_enabled;\nextern uint64_t zfs_deadman_synctime_ms;\nextern uint64_t zfs_deadman_ziotime_ms;\nextern uint64_t zfs_deadman_checktime_ms;\n\nextern kmem_cache_t *zio_buf_cache[];\nextern kmem_cache_t *zio_data_buf_cache[];\n\n#ifdef\t__cplusplus\n}\n#endif\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}