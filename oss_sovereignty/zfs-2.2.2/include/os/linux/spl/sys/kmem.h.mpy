{
  "module_name": "kmem.h",
  "hash_id": "6083238e61a951de2797ec12411ebfa66c83038421a7ea9a034ac3cd0d4bd4dd",
  "original_prompt": "Ingested from zfs-2.2.2/include/os/linux/spl/sys/kmem.h",
  "human_readable_source": " \n\n#ifndef _SPL_KMEM_H\n#define\t_SPL_KMEM_H\n\n#include <sys/debug.h>\n#include <linux/slab.h>\n#include <linux/sched.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n\nextern int kmem_debugging(void);\n__attribute__((format(printf, 1, 0)))\nextern char *kmem_vasprintf(const char *fmt, va_list ap);\n__attribute__((format(printf, 1, 2)))\nextern char *kmem_asprintf(const char *fmt, ...);\nextern char *kmem_strdup(const char *str);\nextern void kmem_strfree(char *str);\n\n#define\tkmem_scnprintf\tscnprintf\n\n#define\tPOINTER_IS_VALID(p)\t(!((uintptr_t)(p) & 0x3))\n#define\tPOINTER_INVALIDATE(pp)\t(*(pp) = (void *)((uintptr_t)(*(pp)) | 0x1))\n\n \n#define\tKM_SLEEP\t0x0000\t \n#define\tKM_NOSLEEP\t0x0001\t \n#define\tKM_PUSHPAGE\t0x0004\t \n#define\tKM_ZERO\t\t0x1000\t \n#define\tKM_VMEM\t\t0x2000\t \n\n#define\tKM_PUBLIC_MASK\t(KM_SLEEP | KM_NOSLEEP | KM_PUSHPAGE)\n\nstatic int spl_fstrans_check(void);\nvoid *spl_kvmalloc(size_t size, gfp_t flags);\n\n \nstatic inline gfp_t\nkmem_flags_convert(int flags)\n{\n\tgfp_t lflags = __GFP_NOWARN | __GFP_COMP;\n\n\tif (flags & KM_NOSLEEP) {\n\t\tlflags |= GFP_ATOMIC | __GFP_NORETRY;\n\t} else {\n\t\tlflags |= GFP_KERNEL;\n\t\tif (spl_fstrans_check())\n\t\t\tlflags &= ~(__GFP_IO|__GFP_FS);\n\t}\n\n\tif (flags & KM_PUSHPAGE)\n\t\tlflags |= __GFP_HIGH;\n\n\tif (flags & KM_ZERO)\n\t\tlflags |= __GFP_ZERO;\n\n\treturn (lflags);\n}\n\ntypedef struct {\n\tstruct task_struct *fstrans_thread;\n\tunsigned int saved_flags;\n} fstrans_cookie_t;\n\n \n#ifdef PF_MEMALLOC_NOIO\n#define\t__SPL_PF_MEMALLOC_NOIO (PF_MEMALLOC_NOIO)\n#else\n#define\t__SPL_PF_MEMALLOC_NOIO (0)\n#endif\n\n \n#ifdef PF_FSTRANS\n#define\t__SPL_PF_FSTRANS (PF_FSTRANS)\n#else\n#define\t__SPL_PF_FSTRANS (0)\n#endif\n\n#define\tSPL_FSTRANS (__SPL_PF_FSTRANS|__SPL_PF_MEMALLOC_NOIO)\n\nstatic inline fstrans_cookie_t\nspl_fstrans_mark(void)\n{\n\tfstrans_cookie_t cookie;\n\n\tBUILD_BUG_ON(SPL_FSTRANS == 0);\n\n\tcookie.fstrans_thread = current;\n\tcookie.saved_flags = current->flags & SPL_FSTRANS;\n\tcurrent->flags |= SPL_FSTRANS;\n\n\treturn (cookie);\n}\n\nstatic inline void\nspl_fstrans_unmark(fstrans_cookie_t cookie)\n{\n\tASSERT3P(cookie.fstrans_thread, ==, current);\n\tASSERT((current->flags & SPL_FSTRANS) == SPL_FSTRANS);\n\n\tcurrent->flags &= ~SPL_FSTRANS;\n\tcurrent->flags |= cookie.saved_flags;\n}\n\nstatic inline int\nspl_fstrans_check(void)\n{\n\treturn (current->flags & SPL_FSTRANS);\n}\n\n \nstatic inline int\n__spl_pf_fstrans_check(void)\n{\n\treturn (current->flags & __SPL_PF_FSTRANS);\n}\n\n \n \n#ifndef __GFP_RETRY_MAYFAIL\n#define\t__GFP_RETRY_MAYFAIL\t__GFP_REPEAT\n#endif\n \n#ifndef __GFP_RECLAIM\n#define\t__GFP_RECLAIM\t\t__GFP_WAIT\n#endif\n\n#ifdef HAVE_ATOMIC64_T\n#define\tkmem_alloc_used_add(size)\tatomic64_add(size, &kmem_alloc_used)\n#define\tkmem_alloc_used_sub(size)\tatomic64_sub(size, &kmem_alloc_used)\n#define\tkmem_alloc_used_read()\t\tatomic64_read(&kmem_alloc_used)\n#define\tkmem_alloc_used_set(size)\tatomic64_set(&kmem_alloc_used, size)\nextern atomic64_t kmem_alloc_used;\nextern unsigned long long kmem_alloc_max;\n#else   \n#define\tkmem_alloc_used_add(size)\tatomic_add(size, &kmem_alloc_used)\n#define\tkmem_alloc_used_sub(size)\tatomic_sub(size, &kmem_alloc_used)\n#define\tkmem_alloc_used_read()\t\tatomic_read(&kmem_alloc_used)\n#define\tkmem_alloc_used_set(size)\tatomic_set(&kmem_alloc_used, size)\nextern atomic_t kmem_alloc_used;\nextern unsigned long long kmem_alloc_max;\n#endif  \n\nextern unsigned int spl_kmem_alloc_warn;\nextern unsigned int spl_kmem_alloc_max;\n\n#define\tkmem_alloc(sz, fl)\tspl_kmem_alloc((sz), (fl), __func__, __LINE__)\n#define\tkmem_zalloc(sz, fl)\tspl_kmem_zalloc((sz), (fl), __func__, __LINE__)\n#define\tkmem_free(ptr, sz)\tspl_kmem_free((ptr), (sz))\n#define\tkmem_cache_reap_active\tspl_kmem_cache_reap_active\n\n__attribute__((malloc, alloc_size(1)))\nextern void *spl_kmem_alloc(size_t sz, int fl, const char *func, int line);\n__attribute__((malloc, alloc_size(1)))\nextern void *spl_kmem_zalloc(size_t sz, int fl, const char *func, int line);\nextern void spl_kmem_free(const void *ptr, size_t sz);\n\n \n#ifdef HAVE_VMALLOC_PAGE_KERNEL\n#define\tspl_vmalloc(size, flags)\t__vmalloc(size, flags, PAGE_KERNEL)\n#else\n#define\tspl_vmalloc(size, flags)\t__vmalloc(size, flags)\n#endif\n\n \nextern void *spl_kmem_alloc_impl(size_t size, int flags, int node);\nextern void *spl_kmem_alloc_debug(size_t size, int flags, int node);\nextern void *spl_kmem_alloc_track(size_t size, int flags,\n    const char *func, int line, int node);\nextern void spl_kmem_free_impl(const void *buf, size_t size);\nextern void spl_kmem_free_debug(const void *buf, size_t size);\nextern void spl_kmem_free_track(const void *buf, size_t size);\n\nextern int spl_kmem_init(void);\nextern void spl_kmem_fini(void);\nextern int spl_kmem_cache_reap_active(void);\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}