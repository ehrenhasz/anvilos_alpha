{
  "module_name": "atomic.h",
  "hash_id": "9b6c1d0929be5651ce42377f7fbab62d3b45bd50f205306c055f1cd762d1d48a",
  "original_prompt": "Ingested from zfs-2.2.2/include/os/freebsd/spl/sys/atomic.h",
  "human_readable_source": " \n\n#ifndef _OPENSOLARIS_SYS_ATOMIC_H_\n#define\t_OPENSOLARIS_SYS_ATOMIC_H_\n\n#ifndef _STANDALONE\n\n#include <sys/types.h>\n#include <machine/atomic.h>\n\n#define\tatomic_sub_64\tatomic_subtract_64\n\n#if defined(__i386__) && (defined(_KERNEL) || defined(KLD_MODULE))\n#define\tI386_HAVE_ATOMIC64\n#endif\n\n#if defined(__i386__) || defined(__amd64__) || defined(__arm__)\n \n#define\tSTRONG_FCMPSET\n#endif\n\n#if !defined(__LP64__) && !defined(__mips_n32) && \\\n\t!defined(ARM_HAVE_ATOMIC64) && !defined(I386_HAVE_ATOMIC64) && \\\n\t!defined(HAS_EMULATED_ATOMIC64)\nextern void atomic_add_64(volatile uint64_t *target, int64_t delta);\nextern void atomic_dec_64(volatile uint64_t *target);\nextern uint64_t atomic_swap_64(volatile uint64_t *a, uint64_t value);\nextern uint64_t atomic_load_64(volatile uint64_t *a);\nextern uint64_t atomic_add_64_nv(volatile uint64_t *target, int64_t delta);\nextern uint64_t atomic_cas_64(volatile uint64_t *target, uint64_t cmp,\n    uint64_t newval);\n#endif\n\n#define\tmembar_consumer()\t\tatomic_thread_fence_acq()\n#define\tmembar_producer()\t\tatomic_thread_fence_rel()\n#define\tmembar_sync()\t\t\tatomic_thread_fence_seq_cst()\n\nstatic __inline uint32_t\natomic_add_32_nv(volatile uint32_t *target, int32_t delta)\n{\n\treturn (atomic_fetchadd_32(target, delta) + delta);\n}\n\nstatic __inline uint_t\natomic_add_int_nv(volatile uint_t *target, int delta)\n{\n\treturn (atomic_add_32_nv(target, delta));\n}\n\nstatic __inline void\natomic_inc_32(volatile uint32_t *target)\n{\n\tatomic_add_32(target, 1);\n}\n\nstatic __inline uint32_t\natomic_inc_32_nv(volatile uint32_t *target)\n{\n\treturn (atomic_add_32_nv(target, 1));\n}\n\nstatic __inline void\natomic_dec_32(volatile uint32_t *target)\n{\n\tatomic_subtract_32(target, 1);\n}\n\nstatic __inline uint32_t\natomic_dec_32_nv(volatile uint32_t *target)\n{\n\treturn (atomic_add_32_nv(target, -1));\n}\n\n#ifndef __sparc64__\nstatic inline uint32_t\natomic_cas_32(volatile uint32_t *target, uint32_t cmp, uint32_t newval)\n{\n#ifdef STRONG_FCMPSET\n\t(void) atomic_fcmpset_32(target, &cmp, newval);\n#else\n\tuint32_t expected = cmp;\n\n\tdo {\n\t\tif (atomic_fcmpset_32(target, &cmp, newval))\n\t\t\tbreak;\n\t} while (cmp == expected);\n#endif\n\treturn (cmp);\n}\n#endif\n\n#if defined(__LP64__) || defined(__mips_n32) || \\\n\tdefined(ARM_HAVE_ATOMIC64) || defined(I386_HAVE_ATOMIC64) || \\\n\tdefined(HAS_EMULATED_ATOMIC64)\nstatic __inline void\natomic_dec_64(volatile uint64_t *target)\n{\n\tatomic_subtract_64(target, 1);\n}\n\nstatic inline uint64_t\natomic_add_64_nv(volatile uint64_t *target, int64_t delta)\n{\n\treturn (atomic_fetchadd_64(target, delta) + delta);\n}\n\n#ifndef __sparc64__\nstatic inline uint64_t\natomic_cas_64(volatile uint64_t *target, uint64_t cmp, uint64_t newval)\n{\n#ifdef STRONG_FCMPSET\n\t(void) atomic_fcmpset_64(target, &cmp, newval);\n#else\n\tuint64_t expected = cmp;\n\n\tdo {\n\t\tif (atomic_fcmpset_64(target, &cmp, newval))\n\t\t\tbreak;\n\t} while (cmp == expected);\n#endif\n\treturn (cmp);\n}\n#endif\n#endif\n\nstatic __inline void\natomic_inc_64(volatile uint64_t *target)\n{\n\tatomic_add_64(target, 1);\n}\n\nstatic __inline uint64_t\natomic_inc_64_nv(volatile uint64_t *target)\n{\n\treturn (atomic_add_64_nv(target, 1));\n}\n\nstatic __inline uint64_t\natomic_dec_64_nv(volatile uint64_t *target)\n{\n\treturn (atomic_add_64_nv(target, -1));\n}\n\n#ifdef __LP64__\nstatic __inline void *\natomic_cas_ptr(volatile void *target, void *cmp,  void *newval)\n{\n\treturn ((void *)atomic_cas_64((volatile uint64_t *)target,\n\t    (uint64_t)cmp, (uint64_t)newval));\n}\n#else\nstatic __inline void *\natomic_cas_ptr(volatile void *target, void *cmp,  void *newval)\n{\n\treturn ((void *)atomic_cas_32((volatile uint32_t *)target,\n\t    (uint32_t)cmp, (uint32_t)newval));\n}\n#endif\t \n\n#else  \n \n#undef atomic_add_64\n#define\tatomic_add_64(ptr, val) *(ptr) += val\n#undef atomic_sub_64\n#define\tatomic_sub_64(ptr, val) *(ptr) -= val\n#endif  \n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}