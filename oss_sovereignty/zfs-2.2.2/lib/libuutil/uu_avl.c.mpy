{
  "module_name": "uu_avl.c",
  "hash_id": "a35439b4434b4c28ba3692a1fc5eee7cdcd662363a589b1c47285123687a80f3",
  "original_prompt": "Ingested from zfs-2.2.2/lib/libuutil/uu_avl.c",
  "human_readable_source": " \n \n\n\n\n#include \"libuutil_common.h\"\n\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <sys/avl.h>\n\nstatic uu_avl_pool_t\tuu_null_apool = { &uu_null_apool, &uu_null_apool };\nstatic pthread_mutex_t\tuu_apool_list_lock = PTHREAD_MUTEX_INITIALIZER;\n\n \n#define\tINDEX_MAX\t\t(sizeof (uintptr_t) - 2)\n#define\tINDEX_NEXT(m)\t\t(((m) == INDEX_MAX)? 2 : ((m) + 2) & INDEX_MAX)\n\n#define\tINDEX_DECODE(i)\t\t((i) & ~INDEX_MAX)\n#define\tINDEX_ENCODE(p, n)\t(((n) & ~INDEX_MAX) | (p)->ua_index)\n#define\tINDEX_VALID(p, i)\t(((i) & INDEX_MAX) == (p)->ua_index)\n#define\tINDEX_CHECK(i)\t\t(((i) & INDEX_MAX) != 0)\n\n \n#define\tNODE_ARRAY(p, n)\t((uintptr_t *)((uintptr_t)(n) + \\\n\t\t\t\t    (pp)->uap_nodeoffset))\n\n#define\tPOOL_TO_MARKER(pp) (((uintptr_t)(pp) | 1))\n\n#define\tDEAD_MARKER\t\t0xc4\n\nuu_avl_pool_t *\nuu_avl_pool_create(const char *name, size_t objsize, size_t nodeoffset,\n    uu_compare_fn_t *compare_func, uint32_t flags)\n{\n\tuu_avl_pool_t *pp, *next, *prev;\n\n\tif (name == NULL ||\n\t    uu_check_name(name, UU_NAME_DOMAIN) == -1 ||\n\t    nodeoffset + sizeof (uu_avl_node_t) > objsize ||\n\t    compare_func == NULL) {\n\t\tuu_set_error(UU_ERROR_INVALID_ARGUMENT);\n\t\treturn (NULL);\n\t}\n\n\tif (flags & ~UU_AVL_POOL_DEBUG) {\n\t\tuu_set_error(UU_ERROR_UNKNOWN_FLAG);\n\t\treturn (NULL);\n\t}\n\n\tpp = uu_zalloc(sizeof (uu_avl_pool_t));\n\tif (pp == NULL) {\n\t\tuu_set_error(UU_ERROR_NO_MEMORY);\n\t\treturn (NULL);\n\t}\n\n\t(void) strlcpy(pp->uap_name, name, sizeof (pp->uap_name));\n\tpp->uap_nodeoffset = nodeoffset;\n\tpp->uap_objsize = objsize;\n\tpp->uap_cmp = compare_func;\n\tif (flags & UU_AVL_POOL_DEBUG)\n\t\tpp->uap_debug = 1;\n\tpp->uap_last_index = 0;\n\n\t(void) pthread_mutex_init(&pp->uap_lock, NULL);\n\n\tpp->uap_null_avl.ua_next = &pp->uap_null_avl;\n\tpp->uap_null_avl.ua_prev = &pp->uap_null_avl;\n\n\t(void) pthread_mutex_lock(&uu_apool_list_lock);\n\tpp->uap_next = next = &uu_null_apool;\n\tpp->uap_prev = prev = next->uap_prev;\n\tnext->uap_prev = pp;\n\tprev->uap_next = pp;\n\t(void) pthread_mutex_unlock(&uu_apool_list_lock);\n\n\treturn (pp);\n}\n\nvoid\nuu_avl_pool_destroy(uu_avl_pool_t *pp)\n{\n\tif (pp->uap_debug) {\n\t\tif (pp->uap_null_avl.ua_next != &pp->uap_null_avl ||\n\t\t    pp->uap_null_avl.ua_prev != &pp->uap_null_avl) {\n\t\t\tuu_panic(\"uu_avl_pool_destroy: Pool \\\"%.*s\\\" (%p) has \"\n\t\t\t    \"outstanding avls, or is corrupt.\\n\",\n\t\t\t    (int)sizeof (pp->uap_name), pp->uap_name,\n\t\t\t    (void *)pp);\n\t\t}\n\t}\n\t(void) pthread_mutex_lock(&uu_apool_list_lock);\n\tpp->uap_next->uap_prev = pp->uap_prev;\n\tpp->uap_prev->uap_next = pp->uap_next;\n\t(void) pthread_mutex_unlock(&uu_apool_list_lock);\n\t(void) pthread_mutex_destroy(&pp->uap_lock);\n\tpp->uap_prev = NULL;\n\tpp->uap_next = NULL;\n\tuu_free(pp);\n}\n\nvoid\nuu_avl_node_init(void *base, uu_avl_node_t *np, uu_avl_pool_t *pp)\n{\n\tuintptr_t *na = (uintptr_t *)np;\n\n\tif (pp->uap_debug) {\n\t\tuintptr_t offset = (uintptr_t)np - (uintptr_t)base;\n\t\tif (offset + sizeof (*np) > pp->uap_objsize) {\n\t\t\tuu_panic(\"uu_avl_node_init(%p, %p, %p (\\\"%s\\\")): \"\n\t\t\t    \"offset %ld doesn't fit in object (size %ld)\\n\",\n\t\t\t    base, (void *)np, (void *)pp, pp->uap_name,\n\t\t\t    (long)offset, (long)pp->uap_objsize);\n\t\t}\n\t\tif (offset != pp->uap_nodeoffset) {\n\t\t\tuu_panic(\"uu_avl_node_init(%p, %p, %p (\\\"%s\\\")): \"\n\t\t\t    \"offset %ld doesn't match pool's offset (%ld)\\n\",\n\t\t\t    base, (void *)np, (void *)pp, pp->uap_name,\n\t\t\t    (long)offset, (long)pp->uap_objsize);\n\t\t}\n\t}\n\n\tna[0] = POOL_TO_MARKER(pp);\n\tna[1] = 0;\n}\n\nvoid\nuu_avl_node_fini(void *base, uu_avl_node_t *np, uu_avl_pool_t *pp)\n{\n\tuintptr_t *na = (uintptr_t *)np;\n\n\tif (pp->uap_debug) {\n\t\tif (na[0] == DEAD_MARKER && na[1] == DEAD_MARKER) {\n\t\t\tuu_panic(\"uu_avl_node_fini(%p, %p, %p (\\\"%s\\\")): \"\n\t\t\t    \"node already finied\\n\",\n\t\t\t    base, (void *)np, (void *)pp, pp->uap_name);\n\t\t}\n\t\tif (na[0] != POOL_TO_MARKER(pp) || na[1] != 0) {\n\t\t\tuu_panic(\"uu_avl_node_fini(%p, %p, %p (\\\"%s\\\")): \"\n\t\t\t    \"node corrupt, in tree, or in different pool\\n\",\n\t\t\t    base, (void *)np, (void *)pp, pp->uap_name);\n\t\t}\n\t}\n\n\tna[0] = DEAD_MARKER;\n\tna[1] = DEAD_MARKER;\n\tna[2] = DEAD_MARKER;\n}\n\nstruct uu_avl_node_compare_info {\n\tuu_compare_fn_t\t*ac_compare;\n\tvoid\t\t*ac_private;\n\tvoid\t\t*ac_right;\n\tvoid\t\t*ac_found;\n};\n\nstatic int\nuu_avl_node_compare(const void *l, const void *r)\n{\n\tstruct uu_avl_node_compare_info *info =\n\t    (struct uu_avl_node_compare_info *)l;\n\n\tint res = info->ac_compare(r, info->ac_right, info->ac_private);\n\n\tif (res == 0) {\n\t\tif (info->ac_found == NULL)\n\t\t\tinfo->ac_found = (void *)r;\n\t\treturn (-1);\n\t}\n\tif (res < 0)\n\t\treturn (1);\n\treturn (-1);\n}\n\nuu_avl_t *\nuu_avl_create(uu_avl_pool_t *pp, void *parent, uint32_t flags)\n{\n\tuu_avl_t *ap, *next, *prev;\n\n\tif (flags & ~UU_AVL_DEBUG) {\n\t\tuu_set_error(UU_ERROR_UNKNOWN_FLAG);\n\t\treturn (NULL);\n\t}\n\n\tap = uu_zalloc(sizeof (*ap));\n\tif (ap == NULL) {\n\t\tuu_set_error(UU_ERROR_NO_MEMORY);\n\t\treturn (NULL);\n\t}\n\n\tap->ua_pool = pp;\n\tap->ua_parent = parent;\n\tap->ua_debug = pp->uap_debug || (flags & UU_AVL_DEBUG);\n\tap->ua_index = (pp->uap_last_index = INDEX_NEXT(pp->uap_last_index));\n\n\tavl_create(&ap->ua_tree, &uu_avl_node_compare, pp->uap_objsize,\n\t    pp->uap_nodeoffset);\n\n\tap->ua_null_walk.uaw_next = &ap->ua_null_walk;\n\tap->ua_null_walk.uaw_prev = &ap->ua_null_walk;\n\n\t(void) pthread_mutex_lock(&pp->uap_lock);\n\tnext = &pp->uap_null_avl;\n\tprev = next->ua_prev;\n\tap->ua_next = next;\n\tap->ua_prev = prev;\n\tnext->ua_prev = ap;\n\tprev->ua_next = ap;\n\t(void) pthread_mutex_unlock(&pp->uap_lock);\n\n\treturn (ap);\n}\n\nvoid\nuu_avl_destroy(uu_avl_t *ap)\n{\n\tuu_avl_pool_t *pp = ap->ua_pool;\n\n\tif (ap->ua_debug) {\n\t\tif (avl_numnodes(&ap->ua_tree) != 0) {\n\t\t\tuu_panic(\"uu_avl_destroy(%p): tree not empty\\n\",\n\t\t\t    (void *)ap);\n\t\t}\n\t\tif (ap->ua_null_walk.uaw_next != &ap->ua_null_walk ||\n\t\t    ap->ua_null_walk.uaw_prev != &ap->ua_null_walk) {\n\t\t\tuu_panic(\"uu_avl_destroy(%p):  outstanding walkers\\n\",\n\t\t\t    (void *)ap);\n\t\t}\n\t}\n\t(void) pthread_mutex_lock(&pp->uap_lock);\n\tap->ua_next->ua_prev = ap->ua_prev;\n\tap->ua_prev->ua_next = ap->ua_next;\n\t(void) pthread_mutex_unlock(&pp->uap_lock);\n\tap->ua_prev = NULL;\n\tap->ua_next = NULL;\n\n\tap->ua_pool = NULL;\n\tavl_destroy(&ap->ua_tree);\n\n\tuu_free(ap);\n}\n\nsize_t\nuu_avl_numnodes(uu_avl_t *ap)\n{\n\treturn (avl_numnodes(&ap->ua_tree));\n}\n\nvoid *\nuu_avl_first(uu_avl_t *ap)\n{\n\treturn (avl_first(&ap->ua_tree));\n}\n\nvoid *\nuu_avl_last(uu_avl_t *ap)\n{\n\treturn (avl_last(&ap->ua_tree));\n}\n\nvoid *\nuu_avl_next(uu_avl_t *ap, void *node)\n{\n\treturn (AVL_NEXT(&ap->ua_tree, node));\n}\n\nvoid *\nuu_avl_prev(uu_avl_t *ap, void *node)\n{\n\treturn (AVL_PREV(&ap->ua_tree, node));\n}\n\nstatic void\n_avl_walk_init(uu_avl_walk_t *wp, uu_avl_t *ap, uint32_t flags)\n{\n\tuu_avl_walk_t *next, *prev;\n\n\tint robust = (flags & UU_WALK_ROBUST);\n\tint direction = (flags & UU_WALK_REVERSE)? -1 : 1;\n\n\t(void) memset(wp, 0, sizeof (*wp));\n\twp->uaw_avl = ap;\n\twp->uaw_robust = robust;\n\twp->uaw_dir = direction;\n\n\tif (direction > 0)\n\t\twp->uaw_next_result = avl_first(&ap->ua_tree);\n\telse\n\t\twp->uaw_next_result = avl_last(&ap->ua_tree);\n\n\tif (ap->ua_debug || robust) {\n\t\twp->uaw_next = next = &ap->ua_null_walk;\n\t\twp->uaw_prev = prev = next->uaw_prev;\n\t\tnext->uaw_prev = wp;\n\t\tprev->uaw_next = wp;\n\t}\n}\n\nstatic void *\n_avl_walk_advance(uu_avl_walk_t *wp, uu_avl_t *ap)\n{\n\tvoid *np = wp->uaw_next_result;\n\n\tavl_tree_t *t = &ap->ua_tree;\n\n\tif (np == NULL)\n\t\treturn (NULL);\n\n\twp->uaw_next_result = (wp->uaw_dir > 0)? AVL_NEXT(t, np) :\n\t    AVL_PREV(t, np);\n\n\treturn (np);\n}\n\nstatic void\n_avl_walk_fini(uu_avl_walk_t *wp)\n{\n\tif (wp->uaw_next != NULL) {\n\t\twp->uaw_next->uaw_prev = wp->uaw_prev;\n\t\twp->uaw_prev->uaw_next = wp->uaw_next;\n\t\twp->uaw_next = NULL;\n\t\twp->uaw_prev = NULL;\n\t}\n\twp->uaw_avl = NULL;\n\twp->uaw_next_result = NULL;\n}\n\nuu_avl_walk_t *\nuu_avl_walk_start(uu_avl_t *ap, uint32_t flags)\n{\n\tuu_avl_walk_t *wp;\n\n\tif (flags & ~(UU_WALK_ROBUST | UU_WALK_REVERSE)) {\n\t\tuu_set_error(UU_ERROR_UNKNOWN_FLAG);\n\t\treturn (NULL);\n\t}\n\n\twp = uu_zalloc(sizeof (*wp));\n\tif (wp == NULL) {\n\t\tuu_set_error(UU_ERROR_NO_MEMORY);\n\t\treturn (NULL);\n\t}\n\n\t_avl_walk_init(wp, ap, flags);\n\treturn (wp);\n}\n\nvoid *\nuu_avl_walk_next(uu_avl_walk_t *wp)\n{\n\treturn (_avl_walk_advance(wp, wp->uaw_avl));\n}\n\nvoid\nuu_avl_walk_end(uu_avl_walk_t *wp)\n{\n\t_avl_walk_fini(wp);\n\tuu_free(wp);\n}\n\nint\nuu_avl_walk(uu_avl_t *ap, uu_walk_fn_t *func, void *private, uint32_t flags)\n{\n\tvoid *e;\n\tuu_avl_walk_t my_walk;\n\n\tint status = UU_WALK_NEXT;\n\n\tif (flags & ~(UU_WALK_ROBUST | UU_WALK_REVERSE)) {\n\t\tuu_set_error(UU_ERROR_UNKNOWN_FLAG);\n\t\treturn (-1);\n\t}\n\n\t_avl_walk_init(&my_walk, ap, flags);\n\twhile (status == UU_WALK_NEXT &&\n\t    (e = _avl_walk_advance(&my_walk, ap)) != NULL)\n\t\tstatus = (*func)(e, private);\n\t_avl_walk_fini(&my_walk);\n\n\tif (status >= 0)\n\t\treturn (0);\n\tuu_set_error(UU_ERROR_CALLBACK_FAILED);\n\treturn (-1);\n}\n\nvoid\nuu_avl_remove(uu_avl_t *ap, void *elem)\n{\n\tuu_avl_walk_t *wp;\n\tuu_avl_pool_t *pp = ap->ua_pool;\n\tuintptr_t *na = NODE_ARRAY(pp, elem);\n\n\tif (ap->ua_debug) {\n\t\t \n\t\tap->ua_index = INDEX_NEXT(ap->ua_index);\n\t}\n\n\t \n\tfor (wp = ap->ua_null_walk.uaw_next; wp != &ap->ua_null_walk;\n\t    wp = wp->uaw_next) {\n\t\tif (wp->uaw_robust) {\n\t\t\tif (elem == wp->uaw_next_result)\n\t\t\t\t(void) _avl_walk_advance(wp, ap);\n\t\t} else if (wp->uaw_next_result != NULL) {\n\t\t\tuu_panic(\"uu_avl_remove(%p, %p): active non-robust \"\n\t\t\t    \"walker\\n\", (void *)ap, elem);\n\t\t}\n\t}\n\n\tavl_remove(&ap->ua_tree, elem);\n\n\tna[0] = POOL_TO_MARKER(pp);\n\tna[1] = 0;\n}\n\nvoid *\nuu_avl_teardown(uu_avl_t *ap, void **cookie)\n{\n\tvoid *elem = avl_destroy_nodes(&ap->ua_tree, cookie);\n\n\tif (elem != NULL) {\n\t\tuu_avl_pool_t *pp = ap->ua_pool;\n\t\tuintptr_t *na = NODE_ARRAY(pp, elem);\n\n\t\tna[0] = POOL_TO_MARKER(pp);\n\t\tna[1] = 0;\n\t}\n\treturn (elem);\n}\n\nvoid *\nuu_avl_find(uu_avl_t *ap, void *elem, void *private, uu_avl_index_t *out)\n{\n\tstruct uu_avl_node_compare_info info;\n\tvoid *result;\n\n\tinfo.ac_compare = ap->ua_pool->uap_cmp;\n\tinfo.ac_private = private;\n\tinfo.ac_right = elem;\n\tinfo.ac_found = NULL;\n\n\tresult = avl_find(&ap->ua_tree, &info, out);\n\tif (out != NULL)\n\t\t*out = INDEX_ENCODE(ap, *out);\n\n\tif (ap->ua_debug && result != NULL)\n\t\tuu_panic(\"uu_avl_find: internal error: avl_find succeeded\\n\");\n\n\treturn (info.ac_found);\n}\n\nvoid\nuu_avl_insert(uu_avl_t *ap, void *elem, uu_avl_index_t idx)\n{\n\tif (ap->ua_debug) {\n\t\tuu_avl_pool_t *pp = ap->ua_pool;\n\t\tuintptr_t *na = NODE_ARRAY(pp, elem);\n\n\t\tif (na[1] != 0)\n\t\t\tuu_panic(\"uu_avl_insert(%p, %p, %p): node already \"\n\t\t\t    \"in tree, or corrupt\\n\",\n\t\t\t    (void *)ap, elem, (void *)idx);\n\t\tif (na[0] == 0)\n\t\t\tuu_panic(\"uu_avl_insert(%p, %p, %p): node not \"\n\t\t\t    \"initialized\\n\",\n\t\t\t    (void *)ap, elem, (void *)idx);\n\t\tif (na[0] != POOL_TO_MARKER(pp))\n\t\t\tuu_panic(\"uu_avl_insert(%p, %p, %p): node from \"\n\t\t\t    \"other pool, or corrupt\\n\",\n\t\t\t    (void *)ap, elem, (void *)idx);\n\n\t\tif (!INDEX_VALID(ap, idx))\n\t\t\tuu_panic(\"uu_avl_insert(%p, %p, %p): %s\\n\",\n\t\t\t    (void *)ap, elem, (void *)idx,\n\t\t\t    INDEX_CHECK(idx)? \"outdated index\" :\n\t\t\t    \"invalid index\");\n\n\t\t \n\t\tap->ua_index = INDEX_NEXT(ap->ua_index);\n\t}\n\tavl_insert(&ap->ua_tree, elem, INDEX_DECODE(idx));\n}\n\nvoid *\nuu_avl_nearest_next(uu_avl_t *ap, uu_avl_index_t idx)\n{\n\tif (ap->ua_debug && !INDEX_VALID(ap, idx))\n\t\tuu_panic(\"uu_avl_nearest_next(%p, %p): %s\\n\",\n\t\t    (void *)ap, (void *)idx, INDEX_CHECK(idx)?\n\t\t    \"outdated index\" : \"invalid index\");\n\treturn (avl_nearest(&ap->ua_tree, INDEX_DECODE(idx), AVL_AFTER));\n}\n\nvoid *\nuu_avl_nearest_prev(uu_avl_t *ap, uu_avl_index_t idx)\n{\n\tif (ap->ua_debug && !INDEX_VALID(ap, idx))\n\t\tuu_panic(\"uu_avl_nearest_prev(%p, %p): %s\\n\",\n\t\t    (void *)ap, (void *)idx, INDEX_CHECK(idx)?\n\t\t    \"outdated index\" : \"invalid index\");\n\treturn (avl_nearest(&ap->ua_tree, INDEX_DECODE(idx), AVL_BEFORE));\n}\n\n \nvoid\nuu_avl_lockup(void)\n{\n\tuu_avl_pool_t *pp;\n\n\t(void) pthread_mutex_lock(&uu_apool_list_lock);\n\tfor (pp = uu_null_apool.uap_next; pp != &uu_null_apool;\n\t    pp = pp->uap_next)\n\t\t(void) pthread_mutex_lock(&pp->uap_lock);\n}\n\nvoid\nuu_avl_release(void)\n{\n\tuu_avl_pool_t *pp;\n\n\tfor (pp = uu_null_apool.uap_next; pp != &uu_null_apool;\n\t    pp = pp->uap_next)\n\t\t(void) pthread_mutex_unlock(&pp->uap_lock);\n\t(void) pthread_mutex_unlock(&uu_apool_list_lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}