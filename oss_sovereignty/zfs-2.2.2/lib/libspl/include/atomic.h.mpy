{
  "module_name": "atomic.h",
  "hash_id": "8262d7832cbcf75460dba55ea7b44019849dc212b025b16af6c72565631f4863",
  "original_prompt": "Ingested from zfs-2.2.2/lib/libspl/include/atomic.h",
  "human_readable_source": " \n\n \n\n#ifndef\t_SYS_ATOMIC_H\n#define\t_SYS_ATOMIC_H\n\n#include <sys/types.h>\n#include <sys/inttypes.h>\n\n#ifdef\t__cplusplus\nextern \"C\" {\n#endif\n\n#if defined(__STDC__)\n \nextern void atomic_inc_8(volatile uint8_t *);\nextern void atomic_inc_uchar(volatile uchar_t *);\nextern void atomic_inc_16(volatile uint16_t *);\nextern void atomic_inc_ushort(volatile ushort_t *);\nextern void atomic_inc_32(volatile uint32_t *);\nextern void atomic_inc_uint(volatile uint_t *);\nextern void atomic_inc_ulong(volatile ulong_t *);\n#if defined(_INT64_TYPE)\nextern void atomic_inc_64(volatile uint64_t *);\n#endif\n\n \nextern void atomic_dec_8(volatile uint8_t *);\nextern void atomic_dec_uchar(volatile uchar_t *);\nextern void atomic_dec_16(volatile uint16_t *);\nextern void atomic_dec_ushort(volatile ushort_t *);\nextern void atomic_dec_32(volatile uint32_t *);\nextern void atomic_dec_uint(volatile uint_t *);\nextern void atomic_dec_ulong(volatile ulong_t *);\n#if defined(_INT64_TYPE)\nextern void atomic_dec_64(volatile uint64_t *);\n#endif\n\n \nextern void atomic_add_8(volatile uint8_t *, int8_t);\nextern void atomic_add_char(volatile uchar_t *, signed char);\nextern void atomic_add_16(volatile uint16_t *, int16_t);\nextern void atomic_add_short(volatile ushort_t *, short);\nextern void atomic_add_32(volatile uint32_t *, int32_t);\nextern void atomic_add_int(volatile uint_t *, int);\nextern void atomic_add_ptr(volatile void *, ssize_t);\nextern void atomic_add_long(volatile ulong_t *, long);\n#if defined(_INT64_TYPE)\nextern void atomic_add_64(volatile uint64_t *, int64_t);\n#endif\n\n \nextern void atomic_sub_8(volatile uint8_t *, int8_t);\nextern void atomic_sub_char(volatile uchar_t *, signed char);\nextern void atomic_sub_16(volatile uint16_t *, int16_t);\nextern void atomic_sub_short(volatile ushort_t *, short);\nextern void atomic_sub_32(volatile uint32_t *, int32_t);\nextern void atomic_sub_int(volatile uint_t *, int);\nextern void atomic_sub_ptr(volatile void *, ssize_t);\nextern void atomic_sub_long(volatile ulong_t *, long);\n#if defined(_INT64_TYPE)\nextern void atomic_sub_64(volatile uint64_t *, int64_t);\n#endif\n\n \nextern void atomic_or_8(volatile uint8_t *, uint8_t);\nextern void atomic_or_uchar(volatile uchar_t *, uchar_t);\nextern void atomic_or_16(volatile uint16_t *, uint16_t);\nextern void atomic_or_ushort(volatile ushort_t *, ushort_t);\nextern void atomic_or_32(volatile uint32_t *, uint32_t);\nextern void atomic_or_uint(volatile uint_t *, uint_t);\nextern void atomic_or_ulong(volatile ulong_t *, ulong_t);\n#if defined(_INT64_TYPE)\nextern void atomic_or_64(volatile uint64_t *, uint64_t);\n#endif\n\n \nextern void atomic_and_8(volatile uint8_t *, uint8_t);\nextern void atomic_and_uchar(volatile uchar_t *, uchar_t);\nextern void atomic_and_16(volatile uint16_t *, uint16_t);\nextern void atomic_and_ushort(volatile ushort_t *, ushort_t);\nextern void atomic_and_32(volatile uint32_t *, uint32_t);\nextern void atomic_and_uint(volatile uint_t *, uint_t);\nextern void atomic_and_ulong(volatile ulong_t *, ulong_t);\n#if defined(_INT64_TYPE)\nextern void atomic_and_64(volatile uint64_t *, uint64_t);\n#endif\n\n \n\n \nextern uint8_t atomic_inc_8_nv(volatile uint8_t *);\nextern uchar_t atomic_inc_uchar_nv(volatile uchar_t *);\nextern uint16_t atomic_inc_16_nv(volatile uint16_t *);\nextern ushort_t atomic_inc_ushort_nv(volatile ushort_t *);\nextern uint32_t atomic_inc_32_nv(volatile uint32_t *);\nextern uint_t atomic_inc_uint_nv(volatile uint_t *);\nextern ulong_t atomic_inc_ulong_nv(volatile ulong_t *);\n#if defined(_INT64_TYPE)\nextern uint64_t atomic_inc_64_nv(volatile uint64_t *);\n#endif\n\n \nextern uint8_t atomic_dec_8_nv(volatile uint8_t *);\nextern uchar_t atomic_dec_uchar_nv(volatile uchar_t *);\nextern uint16_t atomic_dec_16_nv(volatile uint16_t *);\nextern ushort_t atomic_dec_ushort_nv(volatile ushort_t *);\nextern uint32_t atomic_dec_32_nv(volatile uint32_t *);\nextern uint_t atomic_dec_uint_nv(volatile uint_t *);\nextern ulong_t atomic_dec_ulong_nv(volatile ulong_t *);\n#if defined(_INT64_TYPE)\nextern uint64_t atomic_dec_64_nv(volatile uint64_t *);\n#endif\n\n \nextern uint8_t atomic_add_8_nv(volatile uint8_t *, int8_t);\nextern uchar_t atomic_add_char_nv(volatile uchar_t *, signed char);\nextern uint16_t atomic_add_16_nv(volatile uint16_t *, int16_t);\nextern ushort_t atomic_add_short_nv(volatile ushort_t *, short);\nextern uint32_t atomic_add_32_nv(volatile uint32_t *, int32_t);\nextern uint_t atomic_add_int_nv(volatile uint_t *, int);\nextern void *atomic_add_ptr_nv(volatile void *, ssize_t);\nextern ulong_t atomic_add_long_nv(volatile ulong_t *, long);\n#if defined(_INT64_TYPE)\nextern uint64_t atomic_add_64_nv(volatile uint64_t *, int64_t);\n#endif\n\n \nextern uint8_t atomic_sub_8_nv(volatile uint8_t *, int8_t);\nextern uchar_t atomic_sub_char_nv(volatile uchar_t *, signed char);\nextern uint16_t atomic_sub_16_nv(volatile uint16_t *, int16_t);\nextern ushort_t atomic_sub_short_nv(volatile ushort_t *, short);\nextern uint32_t atomic_sub_32_nv(volatile uint32_t *, int32_t);\nextern uint_t atomic_sub_int_nv(volatile uint_t *, int);\nextern void *atomic_sub_ptr_nv(volatile void *, ssize_t);\nextern ulong_t atomic_sub_long_nv(volatile ulong_t *, long);\n#if defined(_INT64_TYPE)\nextern uint64_t atomic_sub_64_nv(volatile uint64_t *, int64_t);\n#endif\n\n \nextern uint8_t atomic_or_8_nv(volatile uint8_t *, uint8_t);\nextern uchar_t atomic_or_uchar_nv(volatile uchar_t *, uchar_t);\nextern uint16_t atomic_or_16_nv(volatile uint16_t *, uint16_t);\nextern ushort_t atomic_or_ushort_nv(volatile ushort_t *, ushort_t);\nextern uint32_t atomic_or_32_nv(volatile uint32_t *, uint32_t);\nextern uint_t atomic_or_uint_nv(volatile uint_t *, uint_t);\nextern ulong_t atomic_or_ulong_nv(volatile ulong_t *, ulong_t);\n#if defined(_INT64_TYPE)\nextern uint64_t atomic_or_64_nv(volatile uint64_t *, uint64_t);\n#endif\n\n \nextern uint8_t atomic_and_8_nv(volatile uint8_t *, uint8_t);\nextern uchar_t atomic_and_uchar_nv(volatile uchar_t *, uchar_t);\nextern uint16_t atomic_and_16_nv(volatile uint16_t *, uint16_t);\nextern ushort_t atomic_and_ushort_nv(volatile ushort_t *, ushort_t);\nextern uint32_t atomic_and_32_nv(volatile uint32_t *, uint32_t);\nextern uint_t atomic_and_uint_nv(volatile uint_t *, uint_t);\nextern ulong_t atomic_and_ulong_nv(volatile ulong_t *, ulong_t);\n#if defined(_INT64_TYPE)\nextern uint64_t atomic_and_64_nv(volatile uint64_t *, uint64_t);\n#endif\n\n \nextern uint8_t atomic_cas_8(volatile uint8_t *, uint8_t, uint8_t);\nextern uchar_t atomic_cas_uchar(volatile uchar_t *, uchar_t, uchar_t);\nextern uint16_t atomic_cas_16(volatile uint16_t *, uint16_t, uint16_t);\nextern ushort_t atomic_cas_ushort(volatile ushort_t *, ushort_t, ushort_t);\nextern uint32_t atomic_cas_32(volatile uint32_t *, uint32_t, uint32_t);\nextern uint_t atomic_cas_uint(volatile uint_t *, uint_t, uint_t);\nextern void *atomic_cas_ptr(volatile void *, void *, void *);\nextern ulong_t atomic_cas_ulong(volatile ulong_t *, ulong_t, ulong_t);\n#if defined(_INT64_TYPE)\nextern uint64_t atomic_cas_64(volatile uint64_t *, uint64_t, uint64_t);\n#endif\n\n \nextern uint8_t atomic_swap_8(volatile uint8_t *, uint8_t);\nextern uchar_t atomic_swap_uchar(volatile uchar_t *, uchar_t);\nextern uint16_t atomic_swap_16(volatile uint16_t *, uint16_t);\nextern ushort_t atomic_swap_ushort(volatile ushort_t *, ushort_t);\nextern uint32_t atomic_swap_32(volatile uint32_t *, uint32_t);\nextern uint_t atomic_swap_uint(volatile uint_t *, uint_t);\nextern void *atomic_swap_ptr(volatile void *, void *);\nextern ulong_t atomic_swap_ulong(volatile ulong_t *, ulong_t);\n#if defined(_INT64_TYPE)\nextern uint64_t atomic_swap_64(volatile uint64_t *, uint64_t);\n#endif\n\n \n#define\tatomic_load_char(p)\t(*(volatile uchar_t *)(p))\n#define\tatomic_load_short(p)\t(*(volatile ushort_t *)(p))\n#define\tatomic_load_int(p)\t(*(volatile uint_t *)(p))\n#define\tatomic_load_long(p)\t(*(volatile ulong_t *)(p))\n#define\tatomic_load_ptr(p)\t(*(volatile __typeof(*p) *)(p))\n#define\tatomic_load_8(p)\t(*(volatile uint8_t *)(p))\n#define\tatomic_load_16(p)\t(*(volatile uint16_t *)(p))\n#define\tatomic_load_32(p)\t(*(volatile uint32_t *)(p))\n#ifdef _LP64\n#define\tatomic_load_64(p)\t(*(volatile uint64_t *)(p))\n#elif defined(_INT64_TYPE)\nextern uint64_t atomic_load_64(volatile uint64_t *);\n#endif\n\n \n#define\tatomic_store_char(p, v)\t\t\\\n\t(*(volatile uchar_t *)(p) = (uchar_t)(v))\n#define\tatomic_store_short(p, v)\t\\\n\t(*(volatile ushort_t *)(p) = (ushort_t)(v))\n#define\tatomic_store_int(p, v)\t\t\\\n\t(*(volatile uint_t *)(p) = (uint_t)(v))\n#define\tatomic_store_long(p, v)\t\t\\\n\t(*(volatile ulong_t *)(p) = (ulong_t)(v))\n#define\tatomic_store_ptr(p, v)\t\t\\\n\t(*(volatile __typeof(*p) *)(p) = (v))\n#define\tatomic_store_8(p, v)\t\t\\\n\t(*(volatile uint8_t *)(p) = (uint8_t)(v))\n#define\tatomic_store_16(p, v)\t\t\\\n\t(*(volatile uint16_t *)(p) = (uint16_t)(v))\n#define\tatomic_store_32(p, v)\t\t\\\n\t(*(volatile uint32_t *)(p) = (uint32_t)(v))\n#ifdef _LP64\n#define\tatomic_store_64(p, v)\t\t\\\n\t(*(volatile uint64_t *)(p) = (uint64_t)(v))\n#elif defined(_INT64_TYPE)\nextern void atomic_store_64(volatile uint64_t *, uint64_t);\n#endif\n\n \nextern int atomic_set_long_excl(volatile ulong_t *, uint_t);\nextern int atomic_clear_long_excl(volatile ulong_t *, uint_t);\n\n \nextern void membar_enter(void);\n\n \nextern void membar_exit(void);\n\n \nextern void membar_sync(void);\n\n \nextern void membar_producer(void);\n\n \nextern void membar_consumer(void);\n#endif   \n\n#ifdef\t__cplusplus\n}\n#endif\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}