{
  "module_name": "dbufstat.in",
  "hash_id": "29a5320e5ecac90508e87d2e83b3283d5f71430c49a239e5d51a495da45b9d1d",
  "original_prompt": "Ingested from zfs-2.2.2/cmd/dbufstat.in",
  "human_readable_source": "#!/usr/bin/env @PYTHON_SHEBANG@\n#\n# Print out statistics for all cached dmu buffers.  This information\n# is available through the dbufs kstat and may be post-processed as\n# needed by the script.\n#\n# CDDL HEADER START\n#\n# The contents of this file are subject to the terms of the\n# Common Development and Distribution License, Version 1.0 only\n# (the \"License\").  You may not use this file except in compliance\n# with the License.\n#\n# You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE\n# or https://opensource.org/licenses/CDDL-1.0.\n# See the License for the specific language governing permissions\n# and limitations under the License.\n#\n# When distributing Covered Code, include this CDDL HEADER in each\n# file and include the License file at usr/src/OPENSOLARIS.LICENSE.\n# If applicable, add the following below this CDDL HEADER, with the\n# fields enclosed by brackets \"[]\" replaced with your own identifying\n# information: Portions Copyright [yyyy] [name of copyright owner]\n#\n# CDDL HEADER END\n#\n# Copyright (C) 2013 Lawrence Livermore National Security, LLC.\n# Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n#\n# This script must remain compatible with and Python 3.6+.\n#\n\nimport sys\nimport getopt\nimport errno\nimport re\n\nbhdr = [\"pool\", \"objset\", \"object\", \"level\", \"blkid\", \"offset\", \"dbsize\"]\nbxhdr = [\"pool\", \"objset\", \"object\", \"level\", \"blkid\", \"offset\", \"dbsize\",\n         \"meta\", \"state\", \"dbholds\", \"dbc\", \"list\", \"atype\", \"flags\",\n         \"count\", \"asize\", \"access\", \"mru\", \"gmru\", \"mfu\", \"gmfu\", \"l2\",\n         \"l2_dattr\", \"l2_asize\", \"l2_comp\", \"aholds\", \"dtype\", \"btype\",\n         \"data_bs\", \"meta_bs\", \"bsize\", \"lvls\", \"dholds\", \"blocks\", \"dsize\"]\nbincompat = [\"cached\", \"direct\", \"indirect\", \"bonus\", \"spill\"]\n\ndhdr = [\"pool\", \"objset\", \"object\", \"dtype\", \"cached\"]\ndxhdr = [\"pool\", \"objset\", \"object\", \"dtype\", \"btype\", \"data_bs\", \"meta_bs\",\n         \"bsize\", \"lvls\", \"dholds\", \"blocks\", \"dsize\", \"cached\", \"direct\",\n         \"indirect\", \"bonus\", \"spill\"]\ndincompat = [\"level\", \"blkid\", \"offset\", \"dbsize\", \"meta\", \"state\", \"dbholds\",\n             \"dbc\", \"list\", \"atype\", \"flags\", \"count\", \"asize\", \"access\",\n             \"mru\", \"gmru\", \"mfu\", \"gmfu\", \"l2\", \"l2_dattr\", \"l2_asize\",\n             \"l2_comp\", \"aholds\"]\n\nthdr = [\"pool\", \"objset\", \"dtype\", \"cached\"]\ntxhdr = [\"pool\", \"objset\", \"dtype\", \"cached\", \"direct\", \"indirect\",\n         \"bonus\", \"spill\"]\ntincompat = [\"object\", \"level\", \"blkid\", \"offset\", \"dbsize\", \"meta\", \"state\",\n             \"dbc\", \"dbholds\", \"list\", \"atype\", \"flags\", \"count\", \"asize\",\n             \"access\", \"mru\", \"gmru\", \"mfu\", \"gmfu\", \"l2\", \"l2_dattr\",\n             \"l2_asize\", \"l2_comp\", \"aholds\", \"btype\", \"data_bs\", \"meta_bs\",\n             \"bsize\", \"lvls\", \"dholds\", \"blocks\", \"dsize\"]\n\ncols = {\n    # hdr:        [size, scale, description]\n    \"pool\":       [15,   -1, \"pool name\"],\n    \"objset\":     [6,    -1, \"dataset identification number\"],\n    \"object\":     [10,   -1, \"object number\"],\n    \"level\":      [5,    -1, \"indirection level of buffer\"],\n    \"blkid\":      [8,    -1, \"block number of buffer\"],\n    \"offset\":     [12, 1024, \"offset in object of buffer\"],\n    \"dbsize\":     [7,  1024, \"size of buffer\"],\n    \"meta\":       [4,    -1, \"is this buffer metadata?\"],\n    \"state\":      [5,    -1, \"state of buffer (read, cached, etc)\"],\n    \"dbholds\":    [7,  1000, \"number of holds on buffer\"],\n    \"dbc\":        [3,    -1, \"in dbuf cache\"],\n    \"list\":       [4,    -1, \"which ARC list contains this buffer\"],\n    \"atype\":      [7,    -1, \"ARC header type (data or metadata)\"],\n    \"flags\":      [9,    -1, \"ARC read flags\"],\n    \"count\":      [5,    -1, \"ARC data count\"],\n    \"asize\":      [7,  1024, \"size of this ARC buffer\"],\n    \"access\":     [10,   -1, \"time this ARC buffer was last accessed\"],\n    \"mru\":        [5,  1000, \"hits while on the ARC's MRU list\"],\n    \"gmru\":       [5,  1000, \"hits while on the ARC's MRU ghost list\"],\n    \"mfu\":        [5,  1000, \"hits while on the ARC's MFU list\"],\n    \"gmfu\":       [5,  1000, \"hits while on the ARC's MFU ghost list\"],\n    \"l2\":         [5,  1000, \"hits while on the L2ARC\"],\n    \"l2_dattr\":   [8,    -1, \"L2ARC disk address/offset\"],\n    \"l2_asize\":   [8,  1024, \"L2ARC alloc'd size (depending on compression)\"],\n    \"l2_comp\":    [21,   -1, \"L2ARC compression algorithm for buffer\"],\n    \"aholds\":     [6,  1000, \"number of holds on this ARC buffer\"],\n    \"dtype\":      [27,   -1, \"dnode type\"],\n    \"btype\":      [27,   -1, \"bonus buffer type\"],\n    \"data_bs\":    [7,  1024, \"data block size\"],\n    \"meta_bs\":    [7,  1024, \"metadata block size\"],\n    \"bsize\":      [6,  1024, \"bonus buffer size\"],\n    \"lvls\":       [6,    -1, \"number of indirection levels\"],\n    \"dholds\":     [6,  1000, \"number of holds on dnode\"],\n    \"blocks\":     [8,  1000, \"number of allocated blocks\"],\n    \"dsize\":      [12, 1024, \"size of dnode\"],\n    \"cached\":     [6,  1024, \"bytes cached for all blocks\"],\n    \"direct\":     [6,  1024, \"bytes cached for direct blocks\"],\n    \"indirect\":   [8,  1024, \"bytes cached for indirect blocks\"],\n    \"bonus\":      [5,  1024, \"bytes cached for bonus buffer\"],\n    \"spill\":      [5,  1024, \"bytes cached for spill block\"],\n}\n\nhdr = None\nxhdr = None\nsep = \"  \"  # Default separator is 2 spaces\ncmd = (\"Usage: dbufstat [-bdhnrtvx] [-i file] [-f fields] [-o file] \"\n       \"[-s string] [-F filter]\\n\")\nraw = 0\n\n\nif sys.platform.startswith(\"freebsd\"):\n    import io\n    # Requires py-sysctl on FreeBSD\n    import sysctl\n\n    def default_ifile():\n        dbufs = sysctl.filter(\"kstat.zfs.misc.dbufs\")[0].value\n        sys.stdin = io.StringIO(dbufs)\n        return \"-\"\n\nelif sys.platform.startswith(\"linux\"):\n    def default_ifile():\n        return \"/proc/spl/kstat/zfs/dbufs\"\n\n\ndef print_incompat_helper(incompat):\n    cnt = 0\n    for key in sorted(incompat):\n        if cnt == 0:\n            sys.stderr.write(\"\\t\")\n        elif cnt > 8:\n            sys.stderr.write(\",\\n\\t\")\n            cnt = 0\n        else:\n            sys.stderr.write(\", \")\n\n        sys.stderr.write(\"%s\" % key)\n        cnt += 1\n\n    sys.stderr.write(\"\\n\\n\")\n\n\ndef detailed_usage():\n    sys.stderr.write(\"%s\\n\" % cmd)\n\n    sys.stderr.write(\"Field definitions incompatible with '-b' option:\\n\")\n    print_incompat_helper(bincompat)\n\n    sys.stderr.write(\"Field definitions incompatible with '-d' option:\\n\")\n    print_incompat_helper(dincompat)\n\n    sys.stderr.write(\"Field definitions incompatible with '-t' option:\\n\")\n    print_incompat_helper(tincompat)\n\n    sys.stderr.write(\"Field definitions are as follows:\\n\")\n    for key in sorted(cols.keys()):\n        sys.stderr.write(\"%11s : %s\\n\" % (key, cols[key][2]))\n    sys.stderr.write(\"\\n\")\n\n    sys.exit(0)\n\n\ndef usage():\n    sys.stderr.write(\"%s\\n\" % cmd)\n    sys.stderr.write(\"\\t -b : Print table of information for each dbuf\\n\")\n    sys.stderr.write(\"\\t -d : Print table of information for each dnode\\n\")\n    sys.stderr.write(\"\\t -h : Print this help message\\n\")\n    sys.stderr.write(\"\\t -n : Exclude header from output\\n\")\n    sys.stderr.write(\"\\t -r : Print raw values\\n\")\n    sys.stderr.write(\"\\t -t : Print table of information for each dnode type\"\n                     \"\\n\")\n    sys.stderr.write(\"\\t -v : List all possible field headers and definitions\"\n                     \"\\n\")\n    sys.stderr.write(\"\\t -x : Print extended stats\\n\")\n    sys.stderr.write(\"\\t -i : Redirect input from the specified file\\n\")\n    sys.stderr.write(\"\\t -f : Specify specific fields to print (see -v)\\n\")\n    sys.stderr.write(\"\\t -o : Redirect output to the specified file\\n\")\n    sys.stderr.write(\"\\t -s : Override default field separator with custom \"\n                     \"character or string\\n\")\n    sys.stderr.write(\"\\t -F : Filter output by value or regex\\n\")\n    sys.stderr.write(\"\\nExamples:\\n\")\n    sys.stderr.write(\"\\tdbufstat -d -o /tmp/d.log\\n\")\n    sys.stderr.write(\"\\tdbufstat -t -s \\\",\\\" -o /tmp/t.log\\n\")\n    sys.stderr.write(\"\\tdbufstat -v\\n\")\n    sys.stderr.write(\"\\tdbufstat -d -f pool,object,objset,dsize,cached\\n\")\n    sys.stderr.write(\"\\tdbufstat -bx -F dbc=1,objset=54,pool=testpool\\n\")\n    sys.stderr.write(\"\\n\")\n\n    sys.exit(1)\n\n\ndef prettynum(sz, scale, num=0):\n    global raw\n\n    suffix = [' ', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']\n    index = 0\n    save = 0\n\n    if raw or scale == -1:\n        return \"%*s\" % (sz, num)\n\n    # Rounding error, return 0\n    elif 0 < num < 1:\n        num = 0\n\n    while num > scale and index < 5:\n        save = num\n        num = num / scale\n        index += 1\n\n    if index == 0:\n        return \"%*d\" % (sz, num)\n\n    if (save / scale) < 10:\n        return \"%*.1f%s\" % (sz - 1, num, suffix[index])\n    else:\n        return \"%*d%s\" % (sz - 1, num, suffix[index])\n\n\ndef print_values(v):\n    global hdr\n    global sep\n\n    try:\n        for col in hdr:\n            sys.stdout.write(\"%s%s\" % (\n                prettynum(cols[col][0], cols[col][1], v[col]), sep))\n        sys.stdout.write(\"\\n\")\n    except IOError as e:\n        if e.errno == errno.EPIPE:\n            sys.exit(1)\n\n\ndef print_header():\n    global hdr\n    global sep\n\n    try:\n        for col in hdr:\n            sys.stdout.write(\"%*s%s\" % (cols[col][0], col, sep))\n        sys.stdout.write(\"\\n\")\n    except IOError as e:\n        if e.errno == errno.EPIPE:\n            sys.exit(1)\n\n\ndef get_typestring(t):\n    ot_strings = [\n                    \"DMU_OT_NONE\",\n                    # general:\n                    \"DMU_OT_OBJECT_DIRECTORY\",\n                    \"DMU_OT_OBJECT_ARRAY\",\n                    \"DMU_OT_PACKED_NVLIST\",\n                    \"DMU_OT_PACKED_NVLIST_SIZE\",\n                    \"DMU_OT_BPOBJ\",\n                    \"DMU_OT_BPOBJ_HDR\",\n                    # spa:\n                    \"DMU_OT_SPACE_MAP_HEADER\",\n                    \"DMU_OT_SPACE_MAP\",\n                    # zil:\n                    \"DMU_OT_INTENT_LOG\",\n                    # dmu:\n                    \"DMU_OT_DNODE\",\n                    \"DMU_OT_OBJSET\",\n                    # dsl:\n                    \"DMU_OT_DSL_DIR\",\n                    \"DMU_OT_DSL_DIR_CHILD_MAP\",\n                    \"DMU_OT_DSL_DS_SNAP_MAP\",\n                    \"DMU_OT_DSL_PROPS\",\n                    \"DMU_OT_DSL_DATASET\",\n                    # zpl:\n                    \"DMU_OT_ZNODE\",\n                    \"DMU_OT_OLDACL\",\n                    \"DMU_OT_PLAIN_FILE_CONTENTS\",\n                    \"DMU_OT_DIRECTORY_CONTENTS\",\n                    \"DMU_OT_MASTER_NODE\",\n                    \"DMU_OT_UNLINKED_SET\",\n                    # zvol:\n                    \"DMU_OT_ZVOL\",\n                    \"DMU_OT_ZVOL_PROP\",\n                    # other; for testing only!\n                    \"DMU_OT_PLAIN_OTHER\",\n                    \"DMU_OT_UINT64_OTHER\",\n                    \"DMU_OT_ZAP_OTHER\",\n                    # new object types:\n                    \"DMU_OT_ERROR_LOG\",\n                    \"DMU_OT_SPA_HISTORY\",\n                    \"DMU_OT_SPA_HISTORY_OFFSETS\",\n                    \"DMU_OT_POOL_PROPS\",\n                    \"DMU_OT_DSL_PERMS\",\n                    \"DMU_OT_ACL\",\n                    \"DMU_OT_SYSACL\",\n                    \"DMU_OT_FUID\",\n                    \"DMU_OT_FUID_SIZE\",\n                    \"DMU_OT_NEXT_CLONES\",\n                    \"DMU_OT_SCAN_QUEUE\",\n                    \"DMU_OT_USERGROUP_USED\",\n                    \"DMU_OT_USERGROUP_QUOTA\",\n                    \"DMU_OT_USERREFS\",\n                    \"DMU_OT_DDT_ZAP\",\n                    \"DMU_OT_DDT_STATS\",\n                    \"DMU_OT_SA\",\n                    \"DMU_OT_SA_MASTER_NODE\",\n                    \"DMU_OT_SA_ATTR_REGISTRATION\",\n                    \"DMU_OT_SA_ATTR_LAYOUTS\",\n                    \"DMU_OT_SCAN_XLATE\",\n                    \"DMU_OT_DEDUP\",\n                    \"DMU_OT_DEADLIST\",\n                    \"DMU_OT_DEADLIST_HDR\",\n                    \"DMU_OT_DSL_CLONES\",\n                    \"DMU_OT_BPOBJ_SUBOBJ\"]\n    otn_strings = {\n                    0x80: \"DMU_OTN_UINT8_DATA\",\n                    0xc0: \"DMU_OTN_UINT8_METADATA\",\n                    0x81: \"DMU_OTN_UINT16_DATA\",\n                    0xc1: \"DMU_OTN_UINT16_METADATA\",\n                    0x82: \"DMU_OTN_UINT32_DATA\",\n                    0xc2: \"DMU_OTN_UINT32_METADATA\",\n                    0x83: \"DMU_OTN_UINT64_DATA\",\n                    0xc3: \"DMU_OTN_UINT64_METADATA\",\n                    0x84: \"DMU_OTN_ZAP_DATA\",\n                    0xc4: \"DMU_OTN_ZAP_METADATA\",\n                    0xa0: \"DMU_OTN_UINT8_ENC_DATA\",\n                    0xe0: \"DMU_OTN_UINT8_ENC_METADATA\",\n                    0xa1: \"DMU_OTN_UINT16_ENC_DATA\",\n                    0xe1: \"DMU_OTN_UINT16_ENC_METADATA\",\n                    0xa2: \"DMU_OTN_UINT32_ENC_DATA\",\n                    0xe2: \"DMU_OTN_UINT32_ENC_METADATA\",\n                    0xa3: \"DMU_OTN_UINT64_ENC_DATA\",\n                    0xe3: \"DMU_OTN_UINT64_ENC_METADATA\",\n                    0xa4: \"DMU_OTN_ZAP_ENC_DATA\",\n                    0xe4: \"DMU_OTN_ZAP_ENC_METADATA\"}\n\n    # If \"-rr\" option is used, don't convert to string representation\n    if raw > 1:\n        return \"%i\" % t\n\n    try:\n        if t < len(ot_strings):\n            return ot_strings[t]\n        else:\n            return otn_strings[t]\n    except (IndexError, KeyError):\n        return \"(UNKNOWN)\"\n\n\ndef get_compstring(c):\n    comp_strings = [\"ZIO_COMPRESS_INHERIT\", \"ZIO_COMPRESS_ON\",\n                    \"ZIO_COMPRESS_OFF\",     \"ZIO_COMPRESS_LZJB\",\n                    \"ZIO_COMPRESS_EMPTY\",   \"ZIO_COMPRESS_GZIP_1\",\n                    \"ZIO_COMPRESS_GZIP_2\",  \"ZIO_COMPRESS_GZIP_3\",\n                    \"ZIO_COMPRESS_GZIP_4\",  \"ZIO_COMPRESS_GZIP_5\",\n                    \"ZIO_COMPRESS_GZIP_6\",  \"ZIO_COMPRESS_GZIP_7\",\n                    \"ZIO_COMPRESS_GZIP_8\",  \"ZIO_COMPRESS_GZIP_9\",\n                    \"ZIO_COMPRESS_ZLE\",     \"ZIO_COMPRESS_LZ4\",\n                    \"ZIO_COMPRESS_ZSTD\",    \"ZIO_COMPRESS_FUNCTION\"]\n\n    # If \"-rr\" option is used, don't convert to string representation\n    if raw > 1:\n        return \"%i\" % c\n\n    try:\n        return comp_strings[c]\n    except IndexError:\n        return \"%i\" % c\n\n\ndef parse_line(line, labels):\n    global hdr\n\n    new = dict()\n    val = None\n    for col in hdr:\n        # These are \"special\" fields computed in the update_dict\n        # function, prevent KeyError exception on labels[col] for these.\n        if col not in ['bonus', 'cached', 'direct', 'indirect', 'spill']:\n            val = line[labels[col]]\n\n        if col in ['pool', 'flags']:\n            new[col] = str(val)\n        elif col in ['dtype', 'btype']:\n            new[col] = get_typestring(int(val))\n        elif col in ['l2_comp']:\n            new[col] = get_compstring(int(val))\n        else:\n            new[col] = int(val)\n\n    return new\n\n\ndef update_dict(d, k, line, labels):\n    pool = line[labels['pool']]\n    objset = line[labels['objset']]\n    key = line[labels[k]]\n\n    dbsize = int(line[labels['dbsize']])\n    blkid = int(line[labels['blkid']])\n    level = int(line[labels['level']])\n\n    if pool not in d:\n        d[pool] = dict()\n\n    if objset not in d[pool]:\n        d[pool][objset] = dict()\n\n    if key not in d[pool][objset]:\n        d[pool][objset][key] = parse_line(line, labels)\n        d[pool][objset][key]['bonus'] = 0\n        d[pool][objset][key]['cached'] = 0\n        d[pool][objset][key]['direct'] = 0\n        d[pool][objset][key]['indirect'] = 0\n        d[pool][objset][key]['spill'] = 0\n\n    d[pool][objset][key]['cached'] += dbsize\n\n    if blkid == -1:\n        d[pool][objset][key]['bonus'] += dbsize\n    elif blkid == -2:\n        d[pool][objset][key]['spill'] += dbsize\n    else:\n        if level == 0:\n            d[pool][objset][key]['direct'] += dbsize\n        else:\n            d[pool][objset][key]['indirect'] += dbsize\n\n    return d\n\n\ndef skip_line(vals, filters):\n    '''\n    Determines if a line should be skipped during printing\n    based on a set of filters\n    '''\n    if len(filters) == 0:\n        return False\n\n    for key in vals:\n        if key in filters:\n            val = prettynum(cols[key][0], cols[key][1], vals[key]).strip()\n            # we want a full match here\n            if re.match(\"(?:\" + filters[key] + r\")\\Z\", val) is None:\n                return True\n\n    return False\n\n\ndef print_dict(d, filters, noheader):\n    if not noheader:\n        print_header()\n    for pool in list(d.keys()):\n        for objset in list(d[pool].keys()):\n            for v in list(d[pool][objset].values()):\n                if not skip_line(v, filters):\n                    print_values(v)\n\n\ndef dnodes_build_dict(filehandle):\n    labels = dict()\n    dnodes = dict()\n\n    # First 3 lines are header information, skip the first two\n    for i in range(2):\n        next(filehandle)\n\n    # The third line contains the labels and index locations\n    for i, v in enumerate(next(filehandle).split()):\n        labels[v] = i\n\n    # The rest of the file is buffer information\n    for line in filehandle:\n        update_dict(dnodes, 'object', line.split(), labels)\n\n    return dnodes\n\n\ndef types_build_dict(filehandle):\n    labels = dict()\n    types = dict()\n\n    # First 3 lines are header information, skip the first two\n    for i in range(2):\n        next(filehandle)\n\n    # The third line contains the labels and index locations\n    for i, v in enumerate(next(filehandle).split()):\n        labels[v] = i\n\n    # The rest of the file is buffer information\n    for line in filehandle:\n        update_dict(types, 'dtype', line.split(), labels)\n\n    return types\n\n\ndef buffers_print_all(filehandle, filters, noheader):\n    labels = dict()\n\n    # First 3 lines are header information, skip the first two\n    for i in range(2):\n        next(filehandle)\n\n    # The third line contains the labels and index locations\n    for i, v in enumerate(next(filehandle).split()):\n        labels[v] = i\n\n    if not noheader:\n        print_header()\n\n    # The rest of the file is buffer information\n    for line in filehandle:\n        vals = parse_line(line.split(), labels)\n        if not skip_line(vals, filters):\n            print_values(vals)\n\n\ndef main():\n    global hdr\n    global sep\n    global raw\n\n    desired_cols = None\n    bflag = False\n    dflag = False\n    hflag = False\n    ifile = None\n    ofile = None\n    tflag = False\n    vflag = False\n    xflag = False\n    nflag = False\n    filters = dict()\n\n    try:\n        opts, args = getopt.getopt(\n            sys.argv[1:],\n            \"bdf:hi:o:rs:tvxF:n\",\n            [\n                \"buffers\",\n                \"dnodes\",\n                \"columns\",\n                \"help\",\n                \"infile\",\n                \"outfile\",\n                \"separator\",\n                \"types\",\n                \"verbose\",\n                \"extended\",\n                \"filter\"\n            ]\n        )\n    except getopt.error:\n        usage()\n        opts = None\n\n    for opt, arg in opts:\n        if opt in ('-b', '--buffers'):\n            bflag = True\n        if opt in ('-d', '--dnodes'):\n            dflag = True\n        if opt in ('-f', '--columns'):\n            desired_cols = arg\n        if opt in ('-h', '--help'):\n            hflag = True\n        if opt in ('-i', '--infile'):\n            ifile = arg\n        if opt in ('-o', '--outfile'):\n            ofile = arg\n        if opt in ('-r', '--raw'):\n            raw += 1\n        if opt in ('-s', '--separator'):\n            sep = arg\n        if opt in ('-t', '--types'):\n            tflag = True\n        if opt in ('-v', '--verbose'):\n            vflag = True\n        if opt in ('-x', '--extended'):\n            xflag = True\n        if opt in ('-n', '--noheader'):\n            nflag = True\n        if opt in ('-F', '--filter'):\n            fils = [x.strip() for x in arg.split(\",\")]\n\n            for fil in fils:\n                f = [x.strip() for x in fil.split(\"=\")]\n\n                if len(f) != 2:\n                    sys.stderr.write(\"Invalid filter '%s'.\\n\" % fil)\n                    sys.exit(1)\n\n                if f[0] not in cols:\n                    sys.stderr.write(\"Invalid field '%s' in filter.\\n\" % f[0])\n                    sys.exit(1)\n\n                if f[0] in filters:\n                    sys.stderr.write(\"Field '%s' specified multiple times in \"\n                                     \"filter.\\n\" % f[0])\n                    sys.exit(1)\n\n                try:\n                    re.compile(\"(?:\" + f[1] + r\")\\Z\")\n                except re.error:\n                    sys.stderr.write(\"Invalid regex for field '%s' in \"\n                                     \"filter.\\n\" % f[0])\n                    sys.exit(1)\n\n                filters[f[0]] = f[1]\n\n    if hflag or (xflag and desired_cols):\n        usage()\n\n    if vflag:\n        detailed_usage()\n\n    # Ensure at most only one of b, d, or t flags are set\n    if (bflag and dflag) or (bflag and tflag) or (dflag and tflag):\n        usage()\n\n    if bflag:\n        hdr = bxhdr if xflag else bhdr\n    elif tflag:\n        hdr = txhdr if xflag else thdr\n    else:  # Even if dflag is False, it's the default if none set\n        dflag = True\n        hdr = dxhdr if xflag else dhdr\n\n    if desired_cols:\n        hdr = desired_cols.split(\",\")\n\n        invalid = []\n        incompat = []\n        for ele in hdr:\n            if ele not in cols:\n                invalid.append(ele)\n            elif ((bflag and bincompat and ele in bincompat) or\n                  (dflag and dincompat and ele in dincompat) or\n                  (tflag and tincompat and ele in tincompat)):\n                    incompat.append(ele)\n\n        if len(invalid) > 0:\n            sys.stderr.write(\"Invalid column definition! -- %s\\n\" % invalid)\n            usage()\n\n        if len(incompat) > 0:\n            sys.stderr.write(\"Incompatible field specified! -- %s\\n\" %\n                             incompat)\n            usage()\n\n    if ofile:\n        try:\n            tmp = open(ofile, \"w\")\n            sys.stdout = tmp\n\n        except IOError:\n            sys.stderr.write(\"Cannot open %s for writing\\n\" % ofile)\n            sys.exit(1)\n\n    if not ifile:\n        ifile = default_ifile()\n\n    if ifile != \"-\":\n        try:\n            tmp = open(ifile, \"r\")\n            sys.stdin = tmp\n        except IOError:\n            sys.stderr.write(\"Cannot open %s for reading\\n\" % ifile)\n            sys.exit(1)\n\n    if bflag:\n        buffers_print_all(sys.stdin, filters, nflag)\n\n    if dflag:\n        print_dict(dnodes_build_dict(sys.stdin), filters, nflag)\n\n    if tflag:\n        print_dict(types_build_dict(sys.stdin), filters, nflag)\n\n\nif __name__ == '__main__':\n    main()\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}