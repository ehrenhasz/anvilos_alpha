{
  "module_name": "pci.h",
  "hash_id": "bff487c71535bb39471ed4f454ce6bf498b4ab9408e2fd6f7c89d254ed721746",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/pci.h",
  "human_readable_source": " \n \n#ifndef LINUX_PCI_H\n#define LINUX_PCI_H\n\n#include <linux/args.h>\n#include <linux/mod_devicetable.h>\n\n#include <linux/types.h>\n#include <linux/init.h>\n#include <linux/ioport.h>\n#include <linux/list.h>\n#include <linux/compiler.h>\n#include <linux/errno.h>\n#include <linux/kobject.h>\n#include <linux/atomic.h>\n#include <linux/device.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/resource_ext.h>\n#include <linux/msi_api.h>\n#include <uapi/linux/pci.h>\n\n#include <linux/pci_ids.h>\n\n#define PCI_STATUS_ERROR_BITS (PCI_STATUS_DETECTED_PARITY  | \\\n\t\t\t       PCI_STATUS_SIG_SYSTEM_ERROR | \\\n\t\t\t       PCI_STATUS_REC_MASTER_ABORT | \\\n\t\t\t       PCI_STATUS_REC_TARGET_ABORT | \\\n\t\t\t       PCI_STATUS_SIG_TARGET_ABORT | \\\n\t\t\t       PCI_STATUS_PARITY)\n\n \n#define PCI_NUM_RESET_METHODS 7\n\n#define PCI_RESET_PROBE\t\ttrue\n#define PCI_RESET_DO_RESET\tfalse\n\n \n#define PCI_DEVID(bus, devfn)\t((((u16)(bus)) << 8) | (devfn))\n \n#define PCI_BUS_NUM(x) (((x) >> 8) & 0xff)\n\n \nstruct pci_slot {\n\tstruct pci_bus\t\t*bus;\t\t \n\tstruct list_head\tlist;\t\t \n\tstruct hotplug_slot\t*hotplug;\t \n\tunsigned char\t\tnumber;\t\t \n\tstruct kobject\t\tkobj;\n};\n\nstatic inline const char *pci_slot_name(const struct pci_slot *slot)\n{\n\treturn kobject_name(&slot->kobj);\n}\n\n \nenum pci_mmap_state {\n\tpci_mmap_io,\n\tpci_mmap_mem\n};\n\n \nenum {\n\t \n\tPCI_STD_RESOURCES,\n\tPCI_STD_RESOURCE_END = PCI_STD_RESOURCES + PCI_STD_NUM_BARS - 1,\n\n\t \n\tPCI_ROM_RESOURCE,\n\n\t \n#ifdef CONFIG_PCI_IOV\n\tPCI_IOV_RESOURCES,\n\tPCI_IOV_RESOURCE_END = PCI_IOV_RESOURCES + PCI_SRIOV_NUM_BARS - 1,\n#endif\n\n \n#define PCI_BRIDGE_IO_WINDOW\t\t(PCI_BRIDGE_RESOURCES + 0)\n#define PCI_BRIDGE_MEM_WINDOW\t\t(PCI_BRIDGE_RESOURCES + 1)\n#define PCI_BRIDGE_PREF_MEM_WINDOW\t(PCI_BRIDGE_RESOURCES + 2)\n\n \n#define PCI_CB_BRIDGE_IO_0_WINDOW\t(PCI_BRIDGE_RESOURCES + 0)\n#define PCI_CB_BRIDGE_IO_1_WINDOW\t(PCI_BRIDGE_RESOURCES + 1)\n#define PCI_CB_BRIDGE_MEM_0_WINDOW\t(PCI_BRIDGE_RESOURCES + 2)\n#define PCI_CB_BRIDGE_MEM_1_WINDOW\t(PCI_BRIDGE_RESOURCES + 3)\n\n \n#define PCI_BRIDGE_RESOURCE_NUM 4\n\n\t \n\tPCI_BRIDGE_RESOURCES,\n\tPCI_BRIDGE_RESOURCE_END = PCI_BRIDGE_RESOURCES +\n\t\t\t\t  PCI_BRIDGE_RESOURCE_NUM - 1,\n\n\t \n\tPCI_NUM_RESOURCES,\n\n\t \n\tDEVICE_COUNT_RESOURCE = PCI_NUM_RESOURCES,\n};\n\n \nenum pci_interrupt_pin {\n\tPCI_INTERRUPT_UNKNOWN,\n\tPCI_INTERRUPT_INTA,\n\tPCI_INTERRUPT_INTB,\n\tPCI_INTERRUPT_INTC,\n\tPCI_INTERRUPT_INTD,\n};\n\n \n#define PCI_NUM_INTX\t4\n\n \n#define PCI_ERROR_RESPONSE\t\t(~0ULL)\n#define PCI_SET_ERROR_RESPONSE(val)\t(*(val) = ((typeof(*(val))) PCI_ERROR_RESPONSE))\n#define PCI_POSSIBLE_ERROR(val)\t\t((val) == ((typeof(val)) PCI_ERROR_RESPONSE))\n\n \ntypedef int __bitwise pci_power_t;\n\n#define PCI_D0\t\t((pci_power_t __force) 0)\n#define PCI_D1\t\t((pci_power_t __force) 1)\n#define PCI_D2\t\t((pci_power_t __force) 2)\n#define PCI_D3hot\t((pci_power_t __force) 3)\n#define PCI_D3cold\t((pci_power_t __force) 4)\n#define PCI_UNKNOWN\t((pci_power_t __force) 5)\n#define PCI_POWER_ERROR\t((pci_power_t __force) -1)\n\n \nextern const char *pci_power_names[];\n\nstatic inline const char *pci_power_name(pci_power_t state)\n{\n\treturn pci_power_names[1 + (__force int) state];\n}\n\n \ntypedef unsigned int __bitwise pci_channel_state_t;\n\nenum {\n\t \n\tpci_channel_io_normal = (__force pci_channel_state_t) 1,\n\n\t \n\tpci_channel_io_frozen = (__force pci_channel_state_t) 2,\n\n\t \n\tpci_channel_io_perm_failure = (__force pci_channel_state_t) 3,\n};\n\ntypedef unsigned int __bitwise pcie_reset_state_t;\n\nenum pcie_reset_state {\n\t \n\tpcie_deassert_reset = (__force pcie_reset_state_t) 1,\n\n\t \n\tpcie_warm_reset = (__force pcie_reset_state_t) 2,\n\n\t \n\tpcie_hot_reset = (__force pcie_reset_state_t) 3\n};\n\ntypedef unsigned short __bitwise pci_dev_flags_t;\nenum pci_dev_flags {\n\t \n\tPCI_DEV_FLAGS_MSI_INTX_DISABLE_BUG = (__force pci_dev_flags_t) (1 << 0),\n\t \n\tPCI_DEV_FLAGS_NO_D3 = (__force pci_dev_flags_t) (1 << 1),\n\t \n\tPCI_DEV_FLAGS_ASSIGNED = (__force pci_dev_flags_t) (1 << 2),\n\t \n\tPCI_DEV_FLAGS_ACS_ENABLED_QUIRK = (__force pci_dev_flags_t) (1 << 3),\n\t \n\tPCI_DEV_FLAG_PCIE_BRIDGE_ALIAS = (__force pci_dev_flags_t) (1 << 5),\n\t \n\tPCI_DEV_FLAGS_NO_BUS_RESET = (__force pci_dev_flags_t) (1 << 6),\n\t \n\tPCI_DEV_FLAGS_NO_PM_RESET = (__force pci_dev_flags_t) (1 << 7),\n\t \n\tPCI_DEV_FLAGS_VPD_REF_F0 = (__force pci_dev_flags_t) (1 << 8),\n\t \n\tPCI_DEV_FLAGS_BRIDGE_XLATE_ROOT = (__force pci_dev_flags_t) (1 << 9),\n\t \n\tPCI_DEV_FLAGS_NO_FLR_RESET = (__force pci_dev_flags_t) (1 << 10),\n\t \n\tPCI_DEV_FLAGS_NO_RELAXED_ORDERING = (__force pci_dev_flags_t) (1 << 11),\n\t \n\tPCI_DEV_FLAGS_HAS_MSI_MASKING = (__force pci_dev_flags_t) (1 << 12),\n};\n\nenum pci_irq_reroute_variant {\n\tINTEL_IRQ_REROUTE_VARIANT = 1,\n\tMAX_IRQ_REROUTE_VARIANTS = 3\n};\n\ntypedef unsigned short __bitwise pci_bus_flags_t;\nenum pci_bus_flags {\n\tPCI_BUS_FLAGS_NO_MSI\t= (__force pci_bus_flags_t) 1,\n\tPCI_BUS_FLAGS_NO_MMRBC\t= (__force pci_bus_flags_t) 2,\n\tPCI_BUS_FLAGS_NO_AERSID\t= (__force pci_bus_flags_t) 4,\n\tPCI_BUS_FLAGS_NO_EXTCFG\t= (__force pci_bus_flags_t) 8,\n};\n\n \nenum pcie_link_width {\n\tPCIE_LNK_WIDTH_RESRV\t= 0x00,\n\tPCIE_LNK_X1\t\t= 0x01,\n\tPCIE_LNK_X2\t\t= 0x02,\n\tPCIE_LNK_X4\t\t= 0x04,\n\tPCIE_LNK_X8\t\t= 0x08,\n\tPCIE_LNK_X12\t\t= 0x0c,\n\tPCIE_LNK_X16\t\t= 0x10,\n\tPCIE_LNK_X32\t\t= 0x20,\n\tPCIE_LNK_WIDTH_UNKNOWN\t= 0xff,\n};\n\n \nenum pci_bus_speed {\n\tPCI_SPEED_33MHz\t\t\t= 0x00,\n\tPCI_SPEED_66MHz\t\t\t= 0x01,\n\tPCI_SPEED_66MHz_PCIX\t\t= 0x02,\n\tPCI_SPEED_100MHz_PCIX\t\t= 0x03,\n\tPCI_SPEED_133MHz_PCIX\t\t= 0x04,\n\tPCI_SPEED_66MHz_PCIX_ECC\t= 0x05,\n\tPCI_SPEED_100MHz_PCIX_ECC\t= 0x06,\n\tPCI_SPEED_133MHz_PCIX_ECC\t= 0x07,\n\tPCI_SPEED_66MHz_PCIX_266\t= 0x09,\n\tPCI_SPEED_100MHz_PCIX_266\t= 0x0a,\n\tPCI_SPEED_133MHz_PCIX_266\t= 0x0b,\n\tAGP_UNKNOWN\t\t\t= 0x0c,\n\tAGP_1X\t\t\t\t= 0x0d,\n\tAGP_2X\t\t\t\t= 0x0e,\n\tAGP_4X\t\t\t\t= 0x0f,\n\tAGP_8X\t\t\t\t= 0x10,\n\tPCI_SPEED_66MHz_PCIX_533\t= 0x11,\n\tPCI_SPEED_100MHz_PCIX_533\t= 0x12,\n\tPCI_SPEED_133MHz_PCIX_533\t= 0x13,\n\tPCIE_SPEED_2_5GT\t\t= 0x14,\n\tPCIE_SPEED_5_0GT\t\t= 0x15,\n\tPCIE_SPEED_8_0GT\t\t= 0x16,\n\tPCIE_SPEED_16_0GT\t\t= 0x17,\n\tPCIE_SPEED_32_0GT\t\t= 0x18,\n\tPCIE_SPEED_64_0GT\t\t= 0x19,\n\tPCI_SPEED_UNKNOWN\t\t= 0xff,\n};\n\nenum pci_bus_speed pcie_get_speed_cap(struct pci_dev *dev);\nenum pcie_link_width pcie_get_width_cap(struct pci_dev *dev);\n\nstruct pci_vpd {\n\tstruct mutex\tlock;\n\tunsigned int\tlen;\n\tu8\t\tcap;\n};\n\nstruct irq_affinity;\nstruct pcie_link_state;\nstruct pci_sriov;\nstruct pci_p2pdma;\nstruct rcec_ea;\n\n \nstruct pci_dev {\n\tstruct list_head bus_list;\t \n\tstruct pci_bus\t*bus;\t\t \n\tstruct pci_bus\t*subordinate;\t \n\n\tvoid\t\t*sysdata;\t \n\tstruct proc_dir_entry *procent;\t \n\tstruct pci_slot\t*slot;\t\t \n\n\tunsigned int\tdevfn;\t\t \n\tunsigned short\tvendor;\n\tunsigned short\tdevice;\n\tunsigned short\tsubsystem_vendor;\n\tunsigned short\tsubsystem_device;\n\tunsigned int\tclass;\t\t \n\tu8\t\trevision;\t \n\tu8\t\thdr_type;\t \n#ifdef CONFIG_PCIEAER\n\tu16\t\taer_cap;\t \n\tstruct aer_stats *aer_stats;\t \n#endif\n#ifdef CONFIG_PCIEPORTBUS\n\tstruct rcec_ea\t*rcec_ea;\t \n\tstruct pci_dev  *rcec;           \n#endif\n\tu32\t\tdevcap;\t\t \n\tu8\t\tpcie_cap;\t \n\tu8\t\tmsi_cap;\t \n\tu8\t\tmsix_cap;\t \n\tu8\t\tpcie_mpss:3;\t \n\tu8\t\trom_base_reg;\t \n\tu8\t\tpin;\t\t \n\tu16\t\tpcie_flags_reg;\t \n\tunsigned long\t*dma_alias_mask; \n\n\tstruct pci_driver *driver;\t \n\tu64\t\tdma_mask;\t \n\n\tstruct device_dma_parameters dma_parms;\n\n\tpci_power_t\tcurrent_state;\t \n\tu8\t\tpm_cap;\t\t \n\tunsigned int\timm_ready:1;\t \n\tunsigned int\tpme_support:5;\t \n\tunsigned int\tpme_poll:1;\t \n\tunsigned int\td1_support:1;\t \n\tunsigned int\td2_support:1;\t \n\tunsigned int\tno_d1d2:1;\t \n\tunsigned int\tno_d3cold:1;\t \n\tunsigned int\tbridge_d3:1;\t \n\tunsigned int\td3cold_allowed:1;\t \n\tunsigned int\tmmio_always_on:1;\t \n\tunsigned int\twakeup_prepared:1;\n\tunsigned int\tskip_bus_pm:1;\t \n\tunsigned int\tignore_hotplug:1;\t \n\tunsigned int\thotplug_user_indicators:1;  \n\tunsigned int\tclear_retrain_link:1;\t \n\tunsigned int\td3hot_delay;\t \n\tunsigned int\td3cold_delay;\t \n\n#ifdef CONFIG_PCIEASPM\n\tstruct pcie_link_state\t*link_state;\t \n\tu16\t\tl1ss;\t\t \n\tunsigned int\tltr_path:1;\t \n#endif\n\tunsigned int\tpasid_no_tlp:1;\t\t \n\tunsigned int\teetlp_prefix_path:1;\t \n\n\tpci_channel_state_t error_state;\t \n\tstruct device\tdev;\t\t\t \n\n\tint\t\tcfg_size;\t\t \n\n\t \n\tunsigned int\tirq;\n\tstruct resource resource[DEVICE_COUNT_RESOURCE];  \n\tstruct resource driver_exclusive_resource;\t  \n\n\tbool\t\tmatch_driver;\t\t \n\n\tunsigned int\ttransparent:1;\t\t \n\tunsigned int\tio_window:1;\t\t \n\tunsigned int\tpref_window:1;\t\t \n\tunsigned int\tpref_64_window:1;\t \n\tunsigned int\tmultifunction:1;\t \n\n\tunsigned int\tis_busmaster:1;\t\t \n\tunsigned int\tno_msi:1;\t\t \n\tunsigned int\tno_64bit_msi:1;\t\t \n\tunsigned int\tblock_cfg_access:1;\t \n\tunsigned int\tbroken_parity_status:1;\t \n\tunsigned int\tirq_reroute_variant:2;\t \n\tunsigned int\tmsi_enabled:1;\n\tunsigned int\tmsix_enabled:1;\n\tunsigned int\tari_enabled:1;\t\t \n\tunsigned int\tats_enabled:1;\t\t \n\tunsigned int\tpasid_enabled:1;\t \n\tunsigned int\tpri_enabled:1;\t\t \n\tunsigned int\tis_managed:1;\t\t \n\tunsigned int\tis_msi_managed:1;\t \n\tunsigned int\tneeds_freset:1;\t\t \n\tunsigned int\tstate_saved:1;\n\tunsigned int\tis_physfn:1;\n\tunsigned int\tis_virtfn:1;\n\tunsigned int\tis_hotplug_bridge:1;\n\tunsigned int\tshpc_managed:1;\t\t \n\tunsigned int\tis_thunderbolt:1;\t \n\t \n\tunsigned int\tuntrusted:1;\n\t \n\tunsigned int\texternal_facing:1;\n\tunsigned int\tbroken_intx_masking:1;\t \n\tunsigned int\tio_window_1k:1;\t\t \n\tunsigned int\tirq_managed:1;\n\tunsigned int\tnon_compliant_bars:1;\t \n\tunsigned int\tis_probed:1;\t\t \n\tunsigned int\tlink_active_reporting:1; \n\tunsigned int\tno_vf_scan:1;\t\t \n\tunsigned int\tno_command_memory:1;\t \n\tunsigned int\trom_bar_overlap:1;\t \n\tunsigned int\trom_attr_enabled:1;\t \n\tpci_dev_flags_t dev_flags;\n\tatomic_t\tenable_cnt;\t \n\n\tspinlock_t\tpcie_cap_lock;\t\t \n\tu32\t\tsaved_config_space[16];  \n\tstruct hlist_head saved_cap_space;\n\tstruct bin_attribute *res_attr[DEVICE_COUNT_RESOURCE];  \n\tstruct bin_attribute *res_attr_wc[DEVICE_COUNT_RESOURCE];  \n\n#ifdef CONFIG_HOTPLUG_PCI_PCIE\n\tunsigned int\tbroken_cmd_compl:1;\t \n#endif\n#ifdef CONFIG_PCIE_PTM\n\tu16\t\tptm_cap;\t\t \n\tunsigned int\tptm_root:1;\n\tunsigned int\tptm_enabled:1;\n\tu8\t\tptm_granularity;\n#endif\n#ifdef CONFIG_PCI_MSI\n\tvoid __iomem\t*msix_base;\n\traw_spinlock_t\tmsi_lock;\n#endif\n\tstruct pci_vpd\tvpd;\n#ifdef CONFIG_PCIE_DPC\n\tu16\t\tdpc_cap;\n\tunsigned int\tdpc_rp_extensions:1;\n\tu8\t\tdpc_rp_log_size;\n#endif\n#ifdef CONFIG_PCI_ATS\n\tunion {\n\t\tstruct pci_sriov\t*sriov;\t\t \n\t\tstruct pci_dev\t\t*physfn;\t \n\t};\n\tu16\t\tats_cap;\t \n\tu8\t\tats_stu;\t \n#endif\n#ifdef CONFIG_PCI_PRI\n\tu16\t\tpri_cap;\t \n\tu32\t\tpri_reqs_alloc;  \n\tunsigned int\tpasid_required:1;  \n#endif\n#ifdef CONFIG_PCI_PASID\n\tu16\t\tpasid_cap;\t \n\tu16\t\tpasid_features;\n#endif\n#ifdef CONFIG_PCI_P2PDMA\n\tstruct pci_p2pdma __rcu *p2pdma;\n#endif\n#ifdef CONFIG_PCI_DOE\n\tstruct xarray\tdoe_mbs;\t \n#endif\n\tu16\t\tacs_cap;\t \n\tphys_addr_t\trom;\t\t \n\tsize_t\t\tromlen;\t\t \n\t \n\tconst char\t*driver_override;\n\n\tunsigned long\tpriv_flags;\t \n\n\t \n\tu8 reset_methods[PCI_NUM_RESET_METHODS];  \n};\n\nstatic inline struct pci_dev *pci_physfn(struct pci_dev *dev)\n{\n#ifdef CONFIG_PCI_IOV\n\tif (dev->is_virtfn)\n\t\tdev = dev->physfn;\n#endif\n\treturn dev;\n}\n\nstruct pci_dev *pci_alloc_dev(struct pci_bus *bus);\n\n#define\tto_pci_dev(n) container_of(n, struct pci_dev, dev)\n#define for_each_pci_dev(d) while ((d = pci_get_device(PCI_ANY_ID, PCI_ANY_ID, d)) != NULL)\n\nstatic inline int pci_channel_offline(struct pci_dev *pdev)\n{\n\treturn (pdev->error_state != pci_channel_io_normal);\n}\n\n \n#define PCI_DOMAIN_NR_NOT_SET (-1)\n\nstruct pci_host_bridge {\n\tstruct device\tdev;\n\tstruct pci_bus\t*bus;\t\t \n\tstruct pci_ops\t*ops;\n\tstruct pci_ops\t*child_ops;\n\tvoid\t\t*sysdata;\n\tint\t\tbusnr;\n\tint\t\tdomain_nr;\n\tstruct list_head windows;\t \n\tstruct list_head dma_ranges;\t \n\tu8 (*swizzle_irq)(struct pci_dev *, u8 *);  \n\tint (*map_irq)(const struct pci_dev *, u8, u8);\n\tvoid (*release_fn)(struct pci_host_bridge *);\n\tvoid\t\t*release_data;\n\tunsigned int\tignore_reset_delay:1;\t \n\tunsigned int\tno_ext_tags:1;\t\t \n\tunsigned int\tno_inc_mrrs:1;\t\t \n\tunsigned int\tnative_aer:1;\t\t \n\tunsigned int\tnative_pcie_hotplug:1;\t \n\tunsigned int\tnative_shpc_hotplug:1;\t \n\tunsigned int\tnative_pme:1;\t\t \n\tunsigned int\tnative_ltr:1;\t\t \n\tunsigned int\tnative_dpc:1;\t\t \n\tunsigned int\tnative_cxl_error:1;\t \n\tunsigned int\tpreserve_config:1;\t \n\tunsigned int\tsize_windows:1;\t\t \n\tunsigned int\tmsi_domain:1;\t\t \n\n\t \n\tresource_size_t (*align_resource)(struct pci_dev *dev,\n\t\t\tconst struct resource *res,\n\t\t\tresource_size_t start,\n\t\t\tresource_size_t size,\n\t\t\tresource_size_t align);\n\tunsigned long\tprivate[] ____cacheline_aligned;\n};\n\n#define\tto_pci_host_bridge(n) container_of(n, struct pci_host_bridge, dev)\n\nstatic inline void *pci_host_bridge_priv(struct pci_host_bridge *bridge)\n{\n\treturn (void *)bridge->private;\n}\n\nstatic inline struct pci_host_bridge *pci_host_bridge_from_priv(void *priv)\n{\n\treturn container_of(priv, struct pci_host_bridge, private);\n}\n\nstruct pci_host_bridge *pci_alloc_host_bridge(size_t priv);\nstruct pci_host_bridge *devm_pci_alloc_host_bridge(struct device *dev,\n\t\t\t\t\t\t   size_t priv);\nvoid pci_free_host_bridge(struct pci_host_bridge *bridge);\nstruct pci_host_bridge *pci_find_host_bridge(struct pci_bus *bus);\n\nvoid pci_set_host_bridge_release(struct pci_host_bridge *bridge,\n\t\t\t\t void (*release_fn)(struct pci_host_bridge *),\n\t\t\t\t void *release_data);\n\nint pcibios_root_bridge_prepare(struct pci_host_bridge *bridge);\n\n \n\n \n#define PCI_SUBTRACTIVE_DECODE\t0x1\n\nstruct pci_bus_resource {\n\tstruct list_head\tlist;\n\tstruct resource\t\t*res;\n\tunsigned int\t\tflags;\n};\n\n#define PCI_REGION_FLAG_MASK\t0x0fU\t \n\nstruct pci_bus {\n\tstruct list_head node;\t\t \n\tstruct pci_bus\t*parent;\t \n\tstruct list_head children;\t \n\tstruct list_head devices;\t \n\tstruct pci_dev\t*self;\t\t \n\tstruct list_head slots;\t\t \n\tstruct resource *resource[PCI_BRIDGE_RESOURCE_NUM];\n\tstruct list_head resources;\t \n\tstruct resource busn_res;\t \n\n\tstruct pci_ops\t*ops;\t\t \n\tvoid\t\t*sysdata;\t \n\tstruct proc_dir_entry *procdir;\t \n\n\tunsigned char\tnumber;\t\t \n\tunsigned char\tprimary;\t \n\tunsigned char\tmax_bus_speed;\t \n\tunsigned char\tcur_bus_speed;\t \n#ifdef CONFIG_PCI_DOMAINS_GENERIC\n\tint\t\tdomain_nr;\n#endif\n\n\tchar\t\tname[48];\n\n\tunsigned short\tbridge_ctl;\t \n\tpci_bus_flags_t bus_flags;\t \n\tstruct device\t\t*bridge;\n\tstruct device\t\tdev;\n\tstruct bin_attribute\t*legacy_io;\t \n\tstruct bin_attribute\t*legacy_mem;\t \n\tunsigned int\t\tis_added:1;\n\tunsigned int\t\tunsafe_warn:1;\t \n};\n\n#define to_pci_bus(n)\tcontainer_of(n, struct pci_bus, dev)\n\nstatic inline u16 pci_dev_id(struct pci_dev *dev)\n{\n\treturn PCI_DEVID(dev->bus->number, dev->devfn);\n}\n\n \nstatic inline bool pci_is_root_bus(struct pci_bus *pbus)\n{\n\treturn !(pbus->parent);\n}\n\n \nstatic inline bool pci_is_bridge(struct pci_dev *dev)\n{\n\treturn dev->hdr_type == PCI_HEADER_TYPE_BRIDGE ||\n\t\tdev->hdr_type == PCI_HEADER_TYPE_CARDBUS;\n}\n\n#define for_each_pci_bridge(dev, bus)\t\t\t\t\\\n\tlist_for_each_entry(dev, &bus->devices, bus_list)\t\\\n\t\tif (!pci_is_bridge(dev)) {} else\n\nstatic inline struct pci_dev *pci_upstream_bridge(struct pci_dev *dev)\n{\n\tdev = pci_physfn(dev);\n\tif (pci_is_root_bus(dev->bus))\n\t\treturn NULL;\n\n\treturn dev->bus->self;\n}\n\n#ifdef CONFIG_PCI_MSI\nstatic inline bool pci_dev_msi_enabled(struct pci_dev *pci_dev)\n{\n\treturn pci_dev->msi_enabled || pci_dev->msix_enabled;\n}\n#else\nstatic inline bool pci_dev_msi_enabled(struct pci_dev *pci_dev) { return false; }\n#endif\n\n \n#define PCIBIOS_SUCCESSFUL\t\t0x00\n#define PCIBIOS_FUNC_NOT_SUPPORTED\t0x81\n#define PCIBIOS_BAD_VENDOR_ID\t\t0x83\n#define PCIBIOS_DEVICE_NOT_FOUND\t0x86\n#define PCIBIOS_BAD_REGISTER_NUMBER\t0x87\n#define PCIBIOS_SET_FAILED\t\t0x88\n#define PCIBIOS_BUFFER_TOO_SMALL\t0x89\n\n \nstatic inline int pcibios_err_to_errno(int err)\n{\n\tif (err <= PCIBIOS_SUCCESSFUL)\n\t\treturn err;  \n\n\tswitch (err) {\n\tcase PCIBIOS_FUNC_NOT_SUPPORTED:\n\t\treturn -ENOENT;\n\tcase PCIBIOS_BAD_VENDOR_ID:\n\t\treturn -ENOTTY;\n\tcase PCIBIOS_DEVICE_NOT_FOUND:\n\t\treturn -ENODEV;\n\tcase PCIBIOS_BAD_REGISTER_NUMBER:\n\t\treturn -EFAULT;\n\tcase PCIBIOS_SET_FAILED:\n\t\treturn -EIO;\n\tcase PCIBIOS_BUFFER_TOO_SMALL:\n\t\treturn -ENOSPC;\n\t}\n\n\treturn -ERANGE;\n}\n\n \n\nstruct pci_ops {\n\tint (*add_bus)(struct pci_bus *bus);\n\tvoid (*remove_bus)(struct pci_bus *bus);\n\tvoid __iomem *(*map_bus)(struct pci_bus *bus, unsigned int devfn, int where);\n\tint (*read)(struct pci_bus *bus, unsigned int devfn, int where, int size, u32 *val);\n\tint (*write)(struct pci_bus *bus, unsigned int devfn, int where, int size, u32 val);\n};\n\n \nint raw_pci_read(unsigned int domain, unsigned int bus, unsigned int devfn,\n\t\t int reg, int len, u32 *val);\nint raw_pci_write(unsigned int domain, unsigned int bus, unsigned int devfn,\n\t\t  int reg, int len, u32 val);\n\n#ifdef CONFIG_ARCH_DMA_ADDR_T_64BIT\ntypedef u64 pci_bus_addr_t;\n#else\ntypedef u32 pci_bus_addr_t;\n#endif\n\nstruct pci_bus_region {\n\tpci_bus_addr_t\tstart;\n\tpci_bus_addr_t\tend;\n};\n\nstruct pci_dynids {\n\tspinlock_t\t\tlock;\t \n\tstruct list_head\tlist;\t \n};\n\n\n \n\ntypedef unsigned int __bitwise pci_ers_result_t;\n\nenum pci_ers_result {\n\t \n\tPCI_ERS_RESULT_NONE = (__force pci_ers_result_t) 1,\n\n\t \n\tPCI_ERS_RESULT_CAN_RECOVER = (__force pci_ers_result_t) 2,\n\n\t \n\tPCI_ERS_RESULT_NEED_RESET = (__force pci_ers_result_t) 3,\n\n\t \n\tPCI_ERS_RESULT_DISCONNECT = (__force pci_ers_result_t) 4,\n\n\t \n\tPCI_ERS_RESULT_RECOVERED = (__force pci_ers_result_t) 5,\n\n\t \n\tPCI_ERS_RESULT_NO_AER_DRIVER = (__force pci_ers_result_t) 6,\n};\n\n \nstruct pci_error_handlers {\n\t \n\tpci_ers_result_t (*error_detected)(struct pci_dev *dev,\n\t\t\t\t\t   pci_channel_state_t error);\n\n\t \n\tpci_ers_result_t (*mmio_enabled)(struct pci_dev *dev);\n\n\t \n\tpci_ers_result_t (*slot_reset)(struct pci_dev *dev);\n\n\t \n\tvoid (*reset_prepare)(struct pci_dev *dev);\n\tvoid (*reset_done)(struct pci_dev *dev);\n\n\t \n\tvoid (*resume)(struct pci_dev *dev);\n\n\t \n\tvoid (*cor_error_detected)(struct pci_dev *dev);\n};\n\n\nstruct module;\n\n \nstruct pci_driver {\n\tstruct list_head\tnode;\n\tconst char\t\t*name;\n\tconst struct pci_device_id *id_table;\t \n\tint  (*probe)(struct pci_dev *dev, const struct pci_device_id *id);\t \n\tvoid (*remove)(struct pci_dev *dev);\t \n\tint  (*suspend)(struct pci_dev *dev, pm_message_t state);\t \n\tint  (*resume)(struct pci_dev *dev);\t \n\tvoid (*shutdown)(struct pci_dev *dev);\n\tint  (*sriov_configure)(struct pci_dev *dev, int num_vfs);  \n\tint  (*sriov_set_msix_vec_count)(struct pci_dev *vf, int msix_vec_count);  \n\tu32  (*sriov_get_vf_total_msix)(struct pci_dev *pf);\n\tconst struct pci_error_handlers *err_handler;\n\tconst struct attribute_group **groups;\n\tconst struct attribute_group **dev_groups;\n\tstruct device_driver\tdriver;\n\tstruct pci_dynids\tdynids;\n\tbool driver_managed_dma;\n};\n\nstatic inline struct pci_driver *to_pci_driver(struct device_driver *drv)\n{\n    return drv ? container_of(drv, struct pci_driver, driver) : NULL;\n}\n\n \n#define PCI_DEVICE(vend,dev) \\\n\t.vendor = (vend), .device = (dev), \\\n\t.subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID\n\n \n#define PCI_DEVICE_DRIVER_OVERRIDE(vend, dev, driver_override) \\\n\t.vendor = (vend), .device = (dev), .subvendor = PCI_ANY_ID, \\\n\t.subdevice = PCI_ANY_ID, .override_only = (driver_override)\n\n \n#define PCI_DRIVER_OVERRIDE_DEVICE_VFIO(vend, dev) \\\n\tPCI_DEVICE_DRIVER_OVERRIDE(vend, dev, PCI_ID_F_VFIO_DRIVER_OVERRIDE)\n\n \n#define PCI_DEVICE_SUB(vend, dev, subvend, subdev) \\\n\t.vendor = (vend), .device = (dev), \\\n\t.subvendor = (subvend), .subdevice = (subdev)\n\n \n#define PCI_DEVICE_CLASS(dev_class,dev_class_mask) \\\n\t.class = (dev_class), .class_mask = (dev_class_mask), \\\n\t.vendor = PCI_ANY_ID, .device = PCI_ANY_ID, \\\n\t.subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID\n\n \n#define PCI_VDEVICE(vend, dev) \\\n\t.vendor = PCI_VENDOR_ID_##vend, .device = (dev), \\\n\t.subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID, 0, 0\n\n \n#define PCI_DEVICE_DATA(vend, dev, data) \\\n\t.vendor = PCI_VENDOR_ID_##vend, .device = PCI_DEVICE_ID_##vend##_##dev, \\\n\t.subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID, 0, 0, \\\n\t.driver_data = (kernel_ulong_t)(data)\n\nenum {\n\tPCI_REASSIGN_ALL_RSRC\t= 0x00000001,\t \n\tPCI_REASSIGN_ALL_BUS\t= 0x00000002,\t \n\tPCI_PROBE_ONLY\t\t= 0x00000004,\t \n\tPCI_CAN_SKIP_ISA_ALIGN\t= 0x00000008,\t \n\tPCI_ENABLE_PROC_DOMAINS\t= 0x00000010,\t \n\tPCI_COMPAT_DOMAIN_0\t= 0x00000020,\t \n\tPCI_SCAN_ALL_PCIE_DEVS\t= 0x00000040,\t \n};\n\n#define PCI_IRQ_LEGACY\t\t(1 << 0)  \n#define PCI_IRQ_MSI\t\t(1 << 1)  \n#define PCI_IRQ_MSIX\t\t(1 << 2)  \n#define PCI_IRQ_AFFINITY\t(1 << 3)  \n\n \n#ifdef CONFIG_PCI\n\nextern unsigned int pci_flags;\n\nstatic inline void pci_set_flags(int flags) { pci_flags = flags; }\nstatic inline void pci_add_flags(int flags) { pci_flags |= flags; }\nstatic inline void pci_clear_flags(int flags) { pci_flags &= ~flags; }\nstatic inline int pci_has_flag(int flag) { return pci_flags & flag; }\n\nvoid pcie_bus_configure_settings(struct pci_bus *bus);\n\nenum pcie_bus_config_types {\n\tPCIE_BUS_TUNE_OFF,\t \n\tPCIE_BUS_DEFAULT,\t \n\tPCIE_BUS_SAFE,\t\t \n\tPCIE_BUS_PERFORMANCE,\t \n\tPCIE_BUS_PEER2PEER,\t \n};\n\nextern enum pcie_bus_config_types pcie_bus_config;\n\nextern struct bus_type pci_bus_type;\n\n \nextern struct list_head pci_root_buses;\t \n \nint no_pci_devices(void);\n\nvoid pcibios_resource_survey_bus(struct pci_bus *bus);\nvoid pcibios_bus_add_device(struct pci_dev *pdev);\nvoid pcibios_add_bus(struct pci_bus *bus);\nvoid pcibios_remove_bus(struct pci_bus *bus);\nvoid pcibios_fixup_bus(struct pci_bus *);\nint __must_check pcibios_enable_device(struct pci_dev *, int mask);\n \nchar *pcibios_setup(char *str);\n\n \nresource_size_t pcibios_align_resource(void *, const struct resource *,\n\t\t\t\tresource_size_t,\n\t\t\t\tresource_size_t);\n\n \nvoid pci_fixup_cardbus(struct pci_bus *);\n\n \n\nvoid pcibios_resource_to_bus(struct pci_bus *bus, struct pci_bus_region *region,\n\t\t\t     struct resource *res);\nvoid pcibios_bus_to_resource(struct pci_bus *bus, struct resource *res,\n\t\t\t     struct pci_bus_region *region);\nvoid pcibios_scan_specific_bus(int busn);\nstruct pci_bus *pci_find_bus(int domain, int busnr);\nvoid pci_bus_add_devices(const struct pci_bus *bus);\nstruct pci_bus *pci_scan_bus(int bus, struct pci_ops *ops, void *sysdata);\nstruct pci_bus *pci_create_root_bus(struct device *parent, int bus,\n\t\t\t\t    struct pci_ops *ops, void *sysdata,\n\t\t\t\t    struct list_head *resources);\nint pci_host_probe(struct pci_host_bridge *bridge);\nint pci_bus_insert_busn_res(struct pci_bus *b, int bus, int busmax);\nint pci_bus_update_busn_res_end(struct pci_bus *b, int busmax);\nvoid pci_bus_release_busn_res(struct pci_bus *b);\nstruct pci_bus *pci_scan_root_bus(struct device *parent, int bus,\n\t\t\t\t  struct pci_ops *ops, void *sysdata,\n\t\t\t\t  struct list_head *resources);\nint pci_scan_root_bus_bridge(struct pci_host_bridge *bridge);\nstruct pci_bus *pci_add_new_bus(struct pci_bus *parent, struct pci_dev *dev,\n\t\t\t\tint busnr);\nstruct pci_slot *pci_create_slot(struct pci_bus *parent, int slot_nr,\n\t\t\t\t const char *name,\n\t\t\t\t struct hotplug_slot *hotplug);\nvoid pci_destroy_slot(struct pci_slot *slot);\n#ifdef CONFIG_SYSFS\nvoid pci_dev_assign_slot(struct pci_dev *dev);\n#else\nstatic inline void pci_dev_assign_slot(struct pci_dev *dev) { }\n#endif\nint pci_scan_slot(struct pci_bus *bus, int devfn);\nstruct pci_dev *pci_scan_single_device(struct pci_bus *bus, int devfn);\nvoid pci_device_add(struct pci_dev *dev, struct pci_bus *bus);\nunsigned int pci_scan_child_bus(struct pci_bus *bus);\nvoid pci_bus_add_device(struct pci_dev *dev);\nvoid pci_read_bridge_bases(struct pci_bus *child);\nstruct resource *pci_find_parent_resource(const struct pci_dev *dev,\n\t\t\t\t\t  struct resource *res);\nu8 pci_swizzle_interrupt_pin(const struct pci_dev *dev, u8 pin);\nint pci_get_interrupt_pin(struct pci_dev *dev, struct pci_dev **bridge);\nu8 pci_common_swizzle(struct pci_dev *dev, u8 *pinp);\nstruct pci_dev *pci_dev_get(struct pci_dev *dev);\nvoid pci_dev_put(struct pci_dev *dev);\nvoid pci_remove_bus(struct pci_bus *b);\nvoid pci_stop_and_remove_bus_device(struct pci_dev *dev);\nvoid pci_stop_and_remove_bus_device_locked(struct pci_dev *dev);\nvoid pci_stop_root_bus(struct pci_bus *bus);\nvoid pci_remove_root_bus(struct pci_bus *bus);\nvoid pci_setup_cardbus(struct pci_bus *bus);\nvoid pcibios_setup_bridge(struct pci_bus *bus, unsigned long type);\nvoid pci_sort_breadthfirst(void);\n#define dev_is_pci(d) ((d)->bus == &pci_bus_type)\n#define dev_is_pf(d) ((dev_is_pci(d) ? to_pci_dev(d)->is_physfn : false))\n\n \n\nu8 pci_bus_find_capability(struct pci_bus *bus, unsigned int devfn, int cap);\nu8 pci_find_capability(struct pci_dev *dev, int cap);\nu8 pci_find_next_capability(struct pci_dev *dev, u8 pos, int cap);\nu8 pci_find_ht_capability(struct pci_dev *dev, int ht_cap);\nu8 pci_find_next_ht_capability(struct pci_dev *dev, u8 pos, int ht_cap);\nu16 pci_find_ext_capability(struct pci_dev *dev, int cap);\nu16 pci_find_next_ext_capability(struct pci_dev *dev, u16 pos, int cap);\nstruct pci_bus *pci_find_next_bus(const struct pci_bus *from);\nu16 pci_find_vsec_capability(struct pci_dev *dev, u16 vendor, int cap);\nu16 pci_find_dvsec_capability(struct pci_dev *dev, u16 vendor, u16 dvsec);\n\nu64 pci_get_dsn(struct pci_dev *dev);\n\nstruct pci_dev *pci_get_device(unsigned int vendor, unsigned int device,\n\t\t\t       struct pci_dev *from);\nstruct pci_dev *pci_get_subsys(unsigned int vendor, unsigned int device,\n\t\t\t       unsigned int ss_vendor, unsigned int ss_device,\n\t\t\t       struct pci_dev *from);\nstruct pci_dev *pci_get_slot(struct pci_bus *bus, unsigned int devfn);\nstruct pci_dev *pci_get_domain_bus_and_slot(int domain, unsigned int bus,\n\t\t\t\t\t    unsigned int devfn);\nstruct pci_dev *pci_get_class(unsigned int class, struct pci_dev *from);\nint pci_dev_present(const struct pci_device_id *ids);\n\nint pci_bus_read_config_byte(struct pci_bus *bus, unsigned int devfn,\n\t\t\t     int where, u8 *val);\nint pci_bus_read_config_word(struct pci_bus *bus, unsigned int devfn,\n\t\t\t     int where, u16 *val);\nint pci_bus_read_config_dword(struct pci_bus *bus, unsigned int devfn,\n\t\t\t      int where, u32 *val);\nint pci_bus_write_config_byte(struct pci_bus *bus, unsigned int devfn,\n\t\t\t      int where, u8 val);\nint pci_bus_write_config_word(struct pci_bus *bus, unsigned int devfn,\n\t\t\t      int where, u16 val);\nint pci_bus_write_config_dword(struct pci_bus *bus, unsigned int devfn,\n\t\t\t       int where, u32 val);\n\nint pci_generic_config_read(struct pci_bus *bus, unsigned int devfn,\n\t\t\t    int where, int size, u32 *val);\nint pci_generic_config_write(struct pci_bus *bus, unsigned int devfn,\n\t\t\t    int where, int size, u32 val);\nint pci_generic_config_read32(struct pci_bus *bus, unsigned int devfn,\n\t\t\t      int where, int size, u32 *val);\nint pci_generic_config_write32(struct pci_bus *bus, unsigned int devfn,\n\t\t\t       int where, int size, u32 val);\n\nstruct pci_ops *pci_bus_set_ops(struct pci_bus *bus, struct pci_ops *ops);\n\nint pci_read_config_byte(const struct pci_dev *dev, int where, u8 *val);\nint pci_read_config_word(const struct pci_dev *dev, int where, u16 *val);\nint pci_read_config_dword(const struct pci_dev *dev, int where, u32 *val);\nint pci_write_config_byte(const struct pci_dev *dev, int where, u8 val);\nint pci_write_config_word(const struct pci_dev *dev, int where, u16 val);\nint pci_write_config_dword(const struct pci_dev *dev, int where, u32 val);\n\nint pcie_capability_read_word(struct pci_dev *dev, int pos, u16 *val);\nint pcie_capability_read_dword(struct pci_dev *dev, int pos, u32 *val);\nint pcie_capability_write_word(struct pci_dev *dev, int pos, u16 val);\nint pcie_capability_write_dword(struct pci_dev *dev, int pos, u32 val);\nint pcie_capability_clear_and_set_word_unlocked(struct pci_dev *dev, int pos,\n\t\t\t\t\t\tu16 clear, u16 set);\nint pcie_capability_clear_and_set_word_locked(struct pci_dev *dev, int pos,\n\t\t\t\t\t      u16 clear, u16 set);\nint pcie_capability_clear_and_set_dword(struct pci_dev *dev, int pos,\n\t\t\t\t\tu32 clear, u32 set);\n\n \nstatic inline int pcie_capability_clear_and_set_word(struct pci_dev *dev,\n\t\t\t\t\t\t     int pos,\n\t\t\t\t\t\t     u16 clear, u16 set)\n{\n\tswitch (pos) {\n\tcase PCI_EXP_LNKCTL:\n\tcase PCI_EXP_RTCTL:\n\t\treturn pcie_capability_clear_and_set_word_locked(dev, pos,\n\t\t\t\t\t\t\t\t clear, set);\n\tdefault:\n\t\treturn pcie_capability_clear_and_set_word_unlocked(dev, pos,\n\t\t\t\t\t\t\t\t   clear, set);\n\t}\n}\n\nstatic inline int pcie_capability_set_word(struct pci_dev *dev, int pos,\n\t\t\t\t\t   u16 set)\n{\n\treturn pcie_capability_clear_and_set_word(dev, pos, 0, set);\n}\n\nstatic inline int pcie_capability_set_dword(struct pci_dev *dev, int pos,\n\t\t\t\t\t    u32 set)\n{\n\treturn pcie_capability_clear_and_set_dword(dev, pos, 0, set);\n}\n\nstatic inline int pcie_capability_clear_word(struct pci_dev *dev, int pos,\n\t\t\t\t\t     u16 clear)\n{\n\treturn pcie_capability_clear_and_set_word(dev, pos, clear, 0);\n}\n\nstatic inline int pcie_capability_clear_dword(struct pci_dev *dev, int pos,\n\t\t\t\t\t      u32 clear)\n{\n\treturn pcie_capability_clear_and_set_dword(dev, pos, clear, 0);\n}\n\n \nint pci_user_read_config_byte(struct pci_dev *dev, int where, u8 *val);\nint pci_user_read_config_word(struct pci_dev *dev, int where, u16 *val);\nint pci_user_read_config_dword(struct pci_dev *dev, int where, u32 *val);\nint pci_user_write_config_byte(struct pci_dev *dev, int where, u8 val);\nint pci_user_write_config_word(struct pci_dev *dev, int where, u16 val);\nint pci_user_write_config_dword(struct pci_dev *dev, int where, u32 val);\n\nint __must_check pci_enable_device(struct pci_dev *dev);\nint __must_check pci_enable_device_io(struct pci_dev *dev);\nint __must_check pci_enable_device_mem(struct pci_dev *dev);\nint __must_check pci_reenable_device(struct pci_dev *);\nint __must_check pcim_enable_device(struct pci_dev *pdev);\nvoid pcim_pin_device(struct pci_dev *pdev);\n\nstatic inline bool pci_intx_mask_supported(struct pci_dev *pdev)\n{\n\t \n\treturn !pdev->broken_intx_masking;\n}\n\nstatic inline int pci_is_enabled(struct pci_dev *pdev)\n{\n\treturn (atomic_read(&pdev->enable_cnt) > 0);\n}\n\nstatic inline int pci_is_managed(struct pci_dev *pdev)\n{\n\treturn pdev->is_managed;\n}\n\nvoid pci_disable_device(struct pci_dev *dev);\n\nextern unsigned int pcibios_max_latency;\nvoid pci_set_master(struct pci_dev *dev);\nvoid pci_clear_master(struct pci_dev *dev);\n\nint pci_set_pcie_reset_state(struct pci_dev *dev, enum pcie_reset_state state);\nint pci_set_cacheline_size(struct pci_dev *dev);\nint __must_check pci_set_mwi(struct pci_dev *dev);\nint __must_check pcim_set_mwi(struct pci_dev *dev);\nint pci_try_set_mwi(struct pci_dev *dev);\nvoid pci_clear_mwi(struct pci_dev *dev);\nvoid pci_disable_parity(struct pci_dev *dev);\nvoid pci_intx(struct pci_dev *dev, int enable);\nbool pci_check_and_mask_intx(struct pci_dev *dev);\nbool pci_check_and_unmask_intx(struct pci_dev *dev);\nint pci_wait_for_pending(struct pci_dev *dev, int pos, u16 mask);\nint pci_wait_for_pending_transaction(struct pci_dev *dev);\nint pcix_get_max_mmrbc(struct pci_dev *dev);\nint pcix_get_mmrbc(struct pci_dev *dev);\nint pcix_set_mmrbc(struct pci_dev *dev, int mmrbc);\nint pcie_get_readrq(struct pci_dev *dev);\nint pcie_set_readrq(struct pci_dev *dev, int rq);\nint pcie_get_mps(struct pci_dev *dev);\nint pcie_set_mps(struct pci_dev *dev, int mps);\nu32 pcie_bandwidth_available(struct pci_dev *dev, struct pci_dev **limiting_dev,\n\t\t\t     enum pci_bus_speed *speed,\n\t\t\t     enum pcie_link_width *width);\nvoid pcie_print_link_status(struct pci_dev *dev);\nint pcie_reset_flr(struct pci_dev *dev, bool probe);\nint pcie_flr(struct pci_dev *dev);\nint __pci_reset_function_locked(struct pci_dev *dev);\nint pci_reset_function(struct pci_dev *dev);\nint pci_reset_function_locked(struct pci_dev *dev);\nint pci_try_reset_function(struct pci_dev *dev);\nint pci_probe_reset_slot(struct pci_slot *slot);\nint pci_probe_reset_bus(struct pci_bus *bus);\nint pci_reset_bus(struct pci_dev *dev);\nvoid pci_reset_secondary_bus(struct pci_dev *dev);\nvoid pcibios_reset_secondary_bus(struct pci_dev *dev);\nvoid pci_update_resource(struct pci_dev *dev, int resno);\nint __must_check pci_assign_resource(struct pci_dev *dev, int i);\nint __must_check pci_reassign_resource(struct pci_dev *dev, int i, resource_size_t add_size, resource_size_t align);\nvoid pci_release_resource(struct pci_dev *dev, int resno);\nstatic inline int pci_rebar_bytes_to_size(u64 bytes)\n{\n\tbytes = roundup_pow_of_two(bytes);\n\n\t \n\treturn max(ilog2(bytes), 20) - 20;\n}\n\nu32 pci_rebar_get_possible_sizes(struct pci_dev *pdev, int bar);\nint __must_check pci_resize_resource(struct pci_dev *dev, int i, int size);\nint pci_select_bars(struct pci_dev *dev, unsigned long flags);\nbool pci_device_is_present(struct pci_dev *pdev);\nvoid pci_ignore_hotplug(struct pci_dev *dev);\nstruct pci_dev *pci_real_dma_dev(struct pci_dev *dev);\nint pci_status_get_and_clear_errors(struct pci_dev *pdev);\n\nint __printf(6, 7) pci_request_irq(struct pci_dev *dev, unsigned int nr,\n\t\tirq_handler_t handler, irq_handler_t thread_fn, void *dev_id,\n\t\tconst char *fmt, ...);\nvoid pci_free_irq(struct pci_dev *dev, unsigned int nr, void *dev_id);\n\n \nint pci_enable_rom(struct pci_dev *pdev);\nvoid pci_disable_rom(struct pci_dev *pdev);\nvoid __iomem __must_check *pci_map_rom(struct pci_dev *pdev, size_t *size);\nvoid pci_unmap_rom(struct pci_dev *pdev, void __iomem *rom);\n\n \nint pci_save_state(struct pci_dev *dev);\nvoid pci_restore_state(struct pci_dev *dev);\nstruct pci_saved_state *pci_store_saved_state(struct pci_dev *dev);\nint pci_load_saved_state(struct pci_dev *dev,\n\t\t\t struct pci_saved_state *state);\nint pci_load_and_free_saved_state(struct pci_dev *dev,\n\t\t\t\t  struct pci_saved_state **state);\nint pci_platform_power_transition(struct pci_dev *dev, pci_power_t state);\nint pci_set_power_state(struct pci_dev *dev, pci_power_t state);\npci_power_t pci_choose_state(struct pci_dev *dev, pm_message_t state);\nbool pci_pme_capable(struct pci_dev *dev, pci_power_t state);\nvoid pci_pme_active(struct pci_dev *dev, bool enable);\nint pci_enable_wake(struct pci_dev *dev, pci_power_t state, bool enable);\nint pci_wake_from_d3(struct pci_dev *dev, bool enable);\nint pci_prepare_to_sleep(struct pci_dev *dev);\nint pci_back_from_sleep(struct pci_dev *dev);\nbool pci_dev_run_wake(struct pci_dev *dev);\nvoid pci_d3cold_enable(struct pci_dev *dev);\nvoid pci_d3cold_disable(struct pci_dev *dev);\nbool pcie_relaxed_ordering_enabled(struct pci_dev *dev);\nvoid pci_resume_bus(struct pci_bus *bus);\nvoid pci_bus_set_current_state(struct pci_bus *bus, pci_power_t state);\n\n \nvoid set_pcie_port_type(struct pci_dev *pdev);\nvoid set_pcie_hotplug_bridge(struct pci_dev *pdev);\n\n \nunsigned int pci_rescan_bus_bridge_resize(struct pci_dev *bridge);\nunsigned int pci_rescan_bus(struct pci_bus *bus);\nvoid pci_lock_rescan_remove(void);\nvoid pci_unlock_rescan_remove(void);\n\n \nssize_t pci_read_vpd(struct pci_dev *dev, loff_t pos, size_t count, void *buf);\nssize_t pci_write_vpd(struct pci_dev *dev, loff_t pos, size_t count, const void *buf);\nssize_t pci_read_vpd_any(struct pci_dev *dev, loff_t pos, size_t count, void *buf);\nssize_t pci_write_vpd_any(struct pci_dev *dev, loff_t pos, size_t count, const void *buf);\n\n \nresource_size_t pcibios_retrieve_fw_addr(struct pci_dev *dev, int idx);\nvoid pci_bus_assign_resources(const struct pci_bus *bus);\nvoid pci_bus_claim_resources(struct pci_bus *bus);\nvoid pci_bus_size_bridges(struct pci_bus *bus);\nint pci_claim_resource(struct pci_dev *, int);\nint pci_claim_bridge_resource(struct pci_dev *bridge, int i);\nvoid pci_assign_unassigned_resources(void);\nvoid pci_assign_unassigned_bridge_resources(struct pci_dev *bridge);\nvoid pci_assign_unassigned_bus_resources(struct pci_bus *bus);\nvoid pci_assign_unassigned_root_bus_resources(struct pci_bus *bus);\nint pci_reassign_bridge_resources(struct pci_dev *bridge, unsigned long type);\nint pci_enable_resources(struct pci_dev *, int mask);\nvoid pci_assign_irq(struct pci_dev *dev);\nstruct resource *pci_find_resource(struct pci_dev *dev, struct resource *res);\n#define HAVE_PCI_REQ_REGIONS\t2\nint __must_check pci_request_regions(struct pci_dev *, const char *);\nint __must_check pci_request_regions_exclusive(struct pci_dev *, const char *);\nvoid pci_release_regions(struct pci_dev *);\nint __must_check pci_request_region(struct pci_dev *, int, const char *);\nvoid pci_release_region(struct pci_dev *, int);\nint pci_request_selected_regions(struct pci_dev *, int, const char *);\nint pci_request_selected_regions_exclusive(struct pci_dev *, int, const char *);\nvoid pci_release_selected_regions(struct pci_dev *, int);\n\nstatic inline __must_check struct resource *\npci_request_config_region_exclusive(struct pci_dev *pdev, unsigned int offset,\n\t\t\t\t    unsigned int len, const char *name)\n{\n\treturn __request_region(&pdev->driver_exclusive_resource, offset, len,\n\t\t\t\tname, IORESOURCE_EXCLUSIVE);\n}\n\nstatic inline void pci_release_config_region(struct pci_dev *pdev,\n\t\t\t\t\t     unsigned int offset,\n\t\t\t\t\t     unsigned int len)\n{\n\t__release_region(&pdev->driver_exclusive_resource, offset, len);\n}\n\n \nvoid pci_add_resource(struct list_head *resources, struct resource *res);\nvoid pci_add_resource_offset(struct list_head *resources, struct resource *res,\n\t\t\t     resource_size_t offset);\nvoid pci_free_resource_list(struct list_head *resources);\nvoid pci_bus_add_resource(struct pci_bus *bus, struct resource *res,\n\t\t\t  unsigned int flags);\nstruct resource *pci_bus_resource_n(const struct pci_bus *bus, int n);\nvoid pci_bus_remove_resources(struct pci_bus *bus);\nvoid pci_bus_remove_resource(struct pci_bus *bus, struct resource *res);\nint devm_request_pci_bus_resources(struct device *dev,\n\t\t\t\t   struct list_head *resources);\n\n \nint pci_bridge_secondary_bus_reset(struct pci_dev *dev);\n\n#define __pci_bus_for_each_res0(bus, res, ...)\t\t\t\t\\\n\tfor (unsigned int __b = 0;\t\t\t\t\t\\\n\t     (res = pci_bus_resource_n(bus, __b)) || __b < PCI_BRIDGE_RESOURCE_NUM; \\\n\t     __b++)\n\n#define __pci_bus_for_each_res1(bus, res, __b)\t\t\t\t\\\n\tfor (__b = 0;\t\t\t\t\t\t\t\\\n\t     (res = pci_bus_resource_n(bus, __b)) || __b < PCI_BRIDGE_RESOURCE_NUM; \\\n\t     __b++)\n\n \n#define pci_bus_for_each_resource(bus, res, ...)\t\t\t\\\n\tCONCATENATE(__pci_bus_for_each_res, COUNT_ARGS(__VA_ARGS__))\t\\\n\t\t    (bus, res, __VA_ARGS__)\n\nint __must_check pci_bus_alloc_resource(struct pci_bus *bus,\n\t\t\tstruct resource *res, resource_size_t size,\n\t\t\tresource_size_t align, resource_size_t min,\n\t\t\tunsigned long type_mask,\n\t\t\tresource_size_t (*alignf)(void *,\n\t\t\t\t\t\t  const struct resource *,\n\t\t\t\t\t\t  resource_size_t,\n\t\t\t\t\t\t  resource_size_t),\n\t\t\tvoid *alignf_data);\n\n\nint pci_register_io_range(struct fwnode_handle *fwnode, phys_addr_t addr,\n\t\t\tresource_size_t size);\nunsigned long pci_address_to_pio(phys_addr_t addr);\nphys_addr_t pci_pio_to_address(unsigned long pio);\nint pci_remap_iospace(const struct resource *res, phys_addr_t phys_addr);\nint devm_pci_remap_iospace(struct device *dev, const struct resource *res,\n\t\t\t   phys_addr_t phys_addr);\nvoid pci_unmap_iospace(struct resource *res);\nvoid __iomem *devm_pci_remap_cfgspace(struct device *dev,\n\t\t\t\t      resource_size_t offset,\n\t\t\t\t      resource_size_t size);\nvoid __iomem *devm_pci_remap_cfg_resource(struct device *dev,\n\t\t\t\t\t  struct resource *res);\n\nstatic inline pci_bus_addr_t pci_bus_address(struct pci_dev *pdev, int bar)\n{\n\tstruct pci_bus_region region;\n\n\tpcibios_resource_to_bus(pdev->bus, &region, &pdev->resource[bar]);\n\treturn region.start;\n}\n\n \nint __must_check __pci_register_driver(struct pci_driver *, struct module *,\n\t\t\t\t       const char *mod_name);\n\n \n#define pci_register_driver(driver)\t\t\\\n\t__pci_register_driver(driver, THIS_MODULE, KBUILD_MODNAME)\n\nvoid pci_unregister_driver(struct pci_driver *dev);\n\n \n#define module_pci_driver(__pci_driver) \\\n\tmodule_driver(__pci_driver, pci_register_driver, pci_unregister_driver)\n\n \n#define builtin_pci_driver(__pci_driver) \\\n\tbuiltin_driver(__pci_driver, pci_register_driver)\n\nstruct pci_driver *pci_dev_driver(const struct pci_dev *dev);\nint pci_add_dynid(struct pci_driver *drv,\n\t\t  unsigned int vendor, unsigned int device,\n\t\t  unsigned int subvendor, unsigned int subdevice,\n\t\t  unsigned int class, unsigned int class_mask,\n\t\t  unsigned long driver_data);\nconst struct pci_device_id *pci_match_id(const struct pci_device_id *ids,\n\t\t\t\t\t struct pci_dev *dev);\nint pci_scan_bridge(struct pci_bus *bus, struct pci_dev *dev, int max,\n\t\t    int pass);\n\nvoid pci_walk_bus(struct pci_bus *top, int (*cb)(struct pci_dev *, void *),\n\t\t  void *userdata);\nint pci_cfg_space_size(struct pci_dev *dev);\nunsigned char pci_bus_max_busnr(struct pci_bus *bus);\nvoid pci_setup_bridge(struct pci_bus *bus);\nresource_size_t pcibios_window_alignment(struct pci_bus *bus,\n\t\t\t\t\t unsigned long type);\n\n#define PCI_VGA_STATE_CHANGE_BRIDGE (1 << 0)\n#define PCI_VGA_STATE_CHANGE_DECODES (1 << 1)\n\nint pci_set_vga_state(struct pci_dev *pdev, bool decode,\n\t\t      unsigned int command_bits, u32 flags);\n\n \n#define PCI_IRQ_VIRTUAL\t\t(1 << 4)\n\n#define PCI_IRQ_ALL_TYPES \\\n\t(PCI_IRQ_LEGACY | PCI_IRQ_MSI | PCI_IRQ_MSIX)\n\n#include <linux/dmapool.h>\n\nstruct msix_entry {\n\tu32\tvector;\t \n\tu16\tentry;\t \n};\n\nstruct msi_domain_template;\n\n#ifdef CONFIG_PCI_MSI\nint pci_msi_vec_count(struct pci_dev *dev);\nvoid pci_disable_msi(struct pci_dev *dev);\nint pci_msix_vec_count(struct pci_dev *dev);\nvoid pci_disable_msix(struct pci_dev *dev);\nvoid pci_restore_msi_state(struct pci_dev *dev);\nint pci_msi_enabled(void);\nint pci_enable_msi(struct pci_dev *dev);\nint pci_enable_msix_range(struct pci_dev *dev, struct msix_entry *entries,\n\t\t\t  int minvec, int maxvec);\nstatic inline int pci_enable_msix_exact(struct pci_dev *dev,\n\t\t\t\t\tstruct msix_entry *entries, int nvec)\n{\n\tint rc = pci_enable_msix_range(dev, entries, nvec, nvec);\n\tif (rc < 0)\n\t\treturn rc;\n\treturn 0;\n}\nint pci_alloc_irq_vectors(struct pci_dev *dev, unsigned int min_vecs,\n\t\t\t  unsigned int max_vecs, unsigned int flags);\nint pci_alloc_irq_vectors_affinity(struct pci_dev *dev, unsigned int min_vecs,\n\t\t\t\t   unsigned int max_vecs, unsigned int flags,\n\t\t\t\t   struct irq_affinity *affd);\n\nbool pci_msix_can_alloc_dyn(struct pci_dev *dev);\nstruct msi_map pci_msix_alloc_irq_at(struct pci_dev *dev, unsigned int index,\n\t\t\t\t     const struct irq_affinity_desc *affdesc);\nvoid pci_msix_free_irq(struct pci_dev *pdev, struct msi_map map);\n\nvoid pci_free_irq_vectors(struct pci_dev *dev);\nint pci_irq_vector(struct pci_dev *dev, unsigned int nr);\nconst struct cpumask *pci_irq_get_affinity(struct pci_dev *pdev, int vec);\nbool pci_create_ims_domain(struct pci_dev *pdev, const struct msi_domain_template *template,\n\t\t\t   unsigned int hwsize, void *data);\nstruct msi_map pci_ims_alloc_irq(struct pci_dev *pdev, union msi_instance_cookie *icookie,\n\t\t\t\t const struct irq_affinity_desc *affdesc);\nvoid pci_ims_free_irq(struct pci_dev *pdev, struct msi_map map);\n\n#else\nstatic inline int pci_msi_vec_count(struct pci_dev *dev) { return -ENOSYS; }\nstatic inline void pci_disable_msi(struct pci_dev *dev) { }\nstatic inline int pci_msix_vec_count(struct pci_dev *dev) { return -ENOSYS; }\nstatic inline void pci_disable_msix(struct pci_dev *dev) { }\nstatic inline void pci_restore_msi_state(struct pci_dev *dev) { }\nstatic inline int pci_msi_enabled(void) { return 0; }\nstatic inline int pci_enable_msi(struct pci_dev *dev)\n{ return -ENOSYS; }\nstatic inline int pci_enable_msix_range(struct pci_dev *dev,\n\t\t\tstruct msix_entry *entries, int minvec, int maxvec)\n{ return -ENOSYS; }\nstatic inline int pci_enable_msix_exact(struct pci_dev *dev,\n\t\t\tstruct msix_entry *entries, int nvec)\n{ return -ENOSYS; }\n\nstatic inline int\npci_alloc_irq_vectors_affinity(struct pci_dev *dev, unsigned int min_vecs,\n\t\t\t       unsigned int max_vecs, unsigned int flags,\n\t\t\t       struct irq_affinity *aff_desc)\n{\n\tif ((flags & PCI_IRQ_LEGACY) && min_vecs == 1 && dev->irq)\n\t\treturn 1;\n\treturn -ENOSPC;\n}\nstatic inline int\npci_alloc_irq_vectors(struct pci_dev *dev, unsigned int min_vecs,\n\t\t      unsigned int max_vecs, unsigned int flags)\n{\n\treturn pci_alloc_irq_vectors_affinity(dev, min_vecs, max_vecs,\n\t\t\t\t\t      flags, NULL);\n}\n\nstatic inline bool pci_msix_can_alloc_dyn(struct pci_dev *dev)\n{ return false; }\nstatic inline struct msi_map pci_msix_alloc_irq_at(struct pci_dev *dev, unsigned int index,\n\t\t\t\t\t\t   const struct irq_affinity_desc *affdesc)\n{\n\tstruct msi_map map = { .index = -ENOSYS, };\n\n\treturn map;\n}\n\nstatic inline void pci_msix_free_irq(struct pci_dev *pdev, struct msi_map map)\n{\n}\n\nstatic inline void pci_free_irq_vectors(struct pci_dev *dev)\n{\n}\n\nstatic inline int pci_irq_vector(struct pci_dev *dev, unsigned int nr)\n{\n\tif (WARN_ON_ONCE(nr > 0))\n\t\treturn -EINVAL;\n\treturn dev->irq;\n}\nstatic inline const struct cpumask *pci_irq_get_affinity(struct pci_dev *pdev,\n\t\tint vec)\n{\n\treturn cpu_possible_mask;\n}\n\nstatic inline bool pci_create_ims_domain(struct pci_dev *pdev,\n\t\t\t\t\t const struct msi_domain_template *template,\n\t\t\t\t\t unsigned int hwsize, void *data)\n{ return false; }\n\nstatic inline struct msi_map pci_ims_alloc_irq(struct pci_dev *pdev,\n\t\t\t\t\t       union msi_instance_cookie *icookie,\n\t\t\t\t\t       const struct irq_affinity_desc *affdesc)\n{\n\tstruct msi_map map = { .index = -ENOSYS, };\n\n\treturn map;\n}\n\nstatic inline void pci_ims_free_irq(struct pci_dev *pdev, struct msi_map map)\n{\n}\n\n#endif\n\n \nstatic inline int pci_irqd_intx_xlate(struct irq_domain *d,\n\t\t\t\t      struct device_node *node,\n\t\t\t\t      const u32 *intspec,\n\t\t\t\t      unsigned int intsize,\n\t\t\t\t      unsigned long *out_hwirq,\n\t\t\t\t      unsigned int *out_type)\n{\n\tconst u32 intx = intspec[0];\n\n\tif (intx < PCI_INTERRUPT_INTA || intx > PCI_INTERRUPT_INTD)\n\t\treturn -EINVAL;\n\n\t*out_hwirq = intx - PCI_INTERRUPT_INTA;\n\treturn 0;\n}\n\n#ifdef CONFIG_PCIEPORTBUS\nextern bool pcie_ports_disabled;\nextern bool pcie_ports_native;\n#else\n#define pcie_ports_disabled\ttrue\n#define pcie_ports_native\tfalse\n#endif\n\n#define PCIE_LINK_STATE_L0S\t\tBIT(0)\n#define PCIE_LINK_STATE_L1\t\tBIT(1)\n#define PCIE_LINK_STATE_CLKPM\t\tBIT(2)\n#define PCIE_LINK_STATE_L1_1\t\tBIT(3)\n#define PCIE_LINK_STATE_L1_2\t\tBIT(4)\n#define PCIE_LINK_STATE_L1_1_PCIPM\tBIT(5)\n#define PCIE_LINK_STATE_L1_2_PCIPM\tBIT(6)\n#define PCIE_LINK_STATE_ALL\t\t(PCIE_LINK_STATE_L0S | PCIE_LINK_STATE_L1 |\\\n\t\t\t\t\t PCIE_LINK_STATE_CLKPM | PCIE_LINK_STATE_L1_1 |\\\n\t\t\t\t\t PCIE_LINK_STATE_L1_2 | PCIE_LINK_STATE_L1_1_PCIPM |\\\n\t\t\t\t\t PCIE_LINK_STATE_L1_2_PCIPM)\n\n#ifdef CONFIG_PCIEASPM\nint pci_disable_link_state(struct pci_dev *pdev, int state);\nint pci_disable_link_state_locked(struct pci_dev *pdev, int state);\nint pci_enable_link_state(struct pci_dev *pdev, int state);\nint pci_enable_link_state_locked(struct pci_dev *pdev, int state);\nvoid pcie_no_aspm(void);\nbool pcie_aspm_support_enabled(void);\nbool pcie_aspm_enabled(struct pci_dev *pdev);\n#else\nstatic inline int pci_disable_link_state(struct pci_dev *pdev, int state)\n{ return 0; }\nstatic inline int pci_disable_link_state_locked(struct pci_dev *pdev, int state)\n{ return 0; }\nstatic inline int pci_enable_link_state(struct pci_dev *pdev, int state)\n{ return 0; }\nstatic inline int pci_enable_link_state_locked(struct pci_dev *pdev, int state)\n{ return 0; }\nstatic inline void pcie_no_aspm(void) { }\nstatic inline bool pcie_aspm_support_enabled(void) { return false; }\nstatic inline bool pcie_aspm_enabled(struct pci_dev *pdev) { return false; }\n#endif\n\n#ifdef CONFIG_PCIEAER\nbool pci_aer_available(void);\n#else\nstatic inline bool pci_aer_available(void) { return false; }\n#endif\n\nbool pci_ats_disabled(void);\n\n#ifdef CONFIG_PCIE_PTM\nint pci_enable_ptm(struct pci_dev *dev, u8 *granularity);\nvoid pci_disable_ptm(struct pci_dev *dev);\nbool pcie_ptm_enabled(struct pci_dev *dev);\n#else\nstatic inline int pci_enable_ptm(struct pci_dev *dev, u8 *granularity)\n{ return -EINVAL; }\nstatic inline void pci_disable_ptm(struct pci_dev *dev) { }\nstatic inline bool pcie_ptm_enabled(struct pci_dev *dev)\n{ return false; }\n#endif\n\nvoid pci_cfg_access_lock(struct pci_dev *dev);\nbool pci_cfg_access_trylock(struct pci_dev *dev);\nvoid pci_cfg_access_unlock(struct pci_dev *dev);\n\nvoid pci_dev_lock(struct pci_dev *dev);\nint pci_dev_trylock(struct pci_dev *dev);\nvoid pci_dev_unlock(struct pci_dev *dev);\n\n \n#ifdef CONFIG_PCI_DOMAINS\nextern int pci_domains_supported;\n#else\nenum { pci_domains_supported = 0 };\nstatic inline int pci_domain_nr(struct pci_bus *bus) { return 0; }\nstatic inline int pci_proc_domain(struct pci_bus *bus) { return 0; }\n#endif  \n\n \n#ifdef CONFIG_PCI_DOMAINS_GENERIC\nstatic inline int pci_domain_nr(struct pci_bus *bus)\n{\n\treturn bus->domain_nr;\n}\n#ifdef CONFIG_ACPI\nint acpi_pci_bus_find_domain_nr(struct pci_bus *bus);\n#else\nstatic inline int acpi_pci_bus_find_domain_nr(struct pci_bus *bus)\n{ return 0; }\n#endif\nint pci_bus_find_domain_nr(struct pci_bus *bus, struct device *parent);\nvoid pci_bus_release_domain_nr(struct pci_bus *bus, struct device *parent);\n#endif\n\n \ntypedef int (*arch_set_vga_state_t)(struct pci_dev *pdev, bool decode,\n\t\t\t\t    unsigned int command_bits, u32 flags);\nvoid pci_register_set_vga_state(arch_set_vga_state_t func);\n\nstatic inline int\npci_request_io_regions(struct pci_dev *pdev, const char *name)\n{\n\treturn pci_request_selected_regions(pdev,\n\t\t\t    pci_select_bars(pdev, IORESOURCE_IO), name);\n}\n\nstatic inline void\npci_release_io_regions(struct pci_dev *pdev)\n{\n\treturn pci_release_selected_regions(pdev,\n\t\t\t    pci_select_bars(pdev, IORESOURCE_IO));\n}\n\nstatic inline int\npci_request_mem_regions(struct pci_dev *pdev, const char *name)\n{\n\treturn pci_request_selected_regions(pdev,\n\t\t\t    pci_select_bars(pdev, IORESOURCE_MEM), name);\n}\n\nstatic inline void\npci_release_mem_regions(struct pci_dev *pdev)\n{\n\treturn pci_release_selected_regions(pdev,\n\t\t\t    pci_select_bars(pdev, IORESOURCE_MEM));\n}\n\n#else  \n\nstatic inline void pci_set_flags(int flags) { }\nstatic inline void pci_add_flags(int flags) { }\nstatic inline void pci_clear_flags(int flags) { }\nstatic inline int pci_has_flag(int flag) { return 0; }\n\n \n#define _PCI_NOP(o, s, t) \\\n\tstatic inline int pci_##o##_config_##s(struct pci_dev *dev, \\\n\t\t\t\t\t\tint where, t val) \\\n\t\t{ return PCIBIOS_FUNC_NOT_SUPPORTED; }\n\n#define _PCI_NOP_ALL(o, x)\t_PCI_NOP(o, byte, u8 x) \\\n\t\t\t\t_PCI_NOP(o, word, u16 x) \\\n\t\t\t\t_PCI_NOP(o, dword, u32 x)\n_PCI_NOP_ALL(read, *)\n_PCI_NOP_ALL(write,)\n\nstatic inline struct pci_dev *pci_get_device(unsigned int vendor,\n\t\t\t\t\t     unsigned int device,\n\t\t\t\t\t     struct pci_dev *from)\n{ return NULL; }\n\nstatic inline struct pci_dev *pci_get_subsys(unsigned int vendor,\n\t\t\t\t\t     unsigned int device,\n\t\t\t\t\t     unsigned int ss_vendor,\n\t\t\t\t\t     unsigned int ss_device,\n\t\t\t\t\t     struct pci_dev *from)\n{ return NULL; }\n\nstatic inline struct pci_dev *pci_get_class(unsigned int class,\n\t\t\t\t\t    struct pci_dev *from)\n{ return NULL; }\n\n\nstatic inline int pci_dev_present(const struct pci_device_id *ids)\n{ return 0; }\n\n#define no_pci_devices()\t(1)\n#define pci_dev_put(dev)\tdo { } while (0)\n\nstatic inline void pci_set_master(struct pci_dev *dev) { }\nstatic inline void pci_clear_master(struct pci_dev *dev) { }\nstatic inline int pci_enable_device(struct pci_dev *dev) { return -EIO; }\nstatic inline void pci_disable_device(struct pci_dev *dev) { }\nstatic inline int pcim_enable_device(struct pci_dev *pdev) { return -EIO; }\nstatic inline int pci_assign_resource(struct pci_dev *dev, int i)\n{ return -EBUSY; }\nstatic inline int __must_check __pci_register_driver(struct pci_driver *drv,\n\t\t\t\t\t\t     struct module *owner,\n\t\t\t\t\t\t     const char *mod_name)\n{ return 0; }\nstatic inline int pci_register_driver(struct pci_driver *drv)\n{ return 0; }\nstatic inline void pci_unregister_driver(struct pci_driver *drv) { }\nstatic inline u8 pci_find_capability(struct pci_dev *dev, int cap)\n{ return 0; }\nstatic inline int pci_find_next_capability(struct pci_dev *dev, u8 post,\n\t\t\t\t\t   int cap)\n{ return 0; }\nstatic inline int pci_find_ext_capability(struct pci_dev *dev, int cap)\n{ return 0; }\n\nstatic inline u64 pci_get_dsn(struct pci_dev *dev)\n{ return 0; }\n\n \nstatic inline int pci_save_state(struct pci_dev *dev) { return 0; }\nstatic inline void pci_restore_state(struct pci_dev *dev) { }\nstatic inline int pci_set_power_state(struct pci_dev *dev, pci_power_t state)\n{ return 0; }\nstatic inline int pci_wake_from_d3(struct pci_dev *dev, bool enable)\n{ return 0; }\nstatic inline pci_power_t pci_choose_state(struct pci_dev *dev,\n\t\t\t\t\t   pm_message_t state)\n{ return PCI_D0; }\nstatic inline int pci_enable_wake(struct pci_dev *dev, pci_power_t state,\n\t\t\t\t  int enable)\n{ return 0; }\n\nstatic inline struct resource *pci_find_resource(struct pci_dev *dev,\n\t\t\t\t\t\t struct resource *res)\n{ return NULL; }\nstatic inline int pci_request_regions(struct pci_dev *dev, const char *res_name)\n{ return -EIO; }\nstatic inline void pci_release_regions(struct pci_dev *dev) { }\n\nstatic inline int pci_register_io_range(struct fwnode_handle *fwnode,\n\t\t\t\t\tphys_addr_t addr, resource_size_t size)\n{ return -EINVAL; }\n\nstatic inline unsigned long pci_address_to_pio(phys_addr_t addr) { return -1; }\n\nstatic inline struct pci_bus *pci_find_next_bus(const struct pci_bus *from)\n{ return NULL; }\nstatic inline struct pci_dev *pci_get_slot(struct pci_bus *bus,\n\t\t\t\t\t\tunsigned int devfn)\n{ return NULL; }\nstatic inline struct pci_dev *pci_get_domain_bus_and_slot(int domain,\n\t\t\t\t\tunsigned int bus, unsigned int devfn)\n{ return NULL; }\n\nstatic inline int pci_domain_nr(struct pci_bus *bus) { return 0; }\nstatic inline struct pci_dev *pci_dev_get(struct pci_dev *dev) { return NULL; }\n\n#define dev_is_pci(d) (false)\n#define dev_is_pf(d) (false)\nstatic inline bool pci_acs_enabled(struct pci_dev *pdev, u16 acs_flags)\n{ return false; }\nstatic inline int pci_irqd_intx_xlate(struct irq_domain *d,\n\t\t\t\t      struct device_node *node,\n\t\t\t\t      const u32 *intspec,\n\t\t\t\t      unsigned int intsize,\n\t\t\t\t      unsigned long *out_hwirq,\n\t\t\t\t      unsigned int *out_type)\n{ return -EINVAL; }\n\nstatic inline const struct pci_device_id *pci_match_id(const struct pci_device_id *ids,\n\t\t\t\t\t\t\t struct pci_dev *dev)\n{ return NULL; }\nstatic inline bool pci_ats_disabled(void) { return true; }\n\nstatic inline int pci_irq_vector(struct pci_dev *dev, unsigned int nr)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int\npci_alloc_irq_vectors_affinity(struct pci_dev *dev, unsigned int min_vecs,\n\t\t\t       unsigned int max_vecs, unsigned int flags,\n\t\t\t       struct irq_affinity *aff_desc)\n{\n\treturn -ENOSPC;\n}\nstatic inline int\npci_alloc_irq_vectors(struct pci_dev *dev, unsigned int min_vecs,\n\t\t      unsigned int max_vecs, unsigned int flags)\n{\n\treturn -ENOSPC;\n}\n#endif  \n\n \n\n#include <asm/pci.h>\n\n \nint pci_mmap_resource_range(struct pci_dev *dev, int bar,\n\t\t\t    struct vm_area_struct *vma,\n\t\t\t    enum pci_mmap_state mmap_state, int write_combine);\n\n#ifndef arch_can_pci_mmap_wc\n#define arch_can_pci_mmap_wc()\t\t0\n#endif\n\n#ifndef arch_can_pci_mmap_io\n#define arch_can_pci_mmap_io()\t\t0\n#define pci_iobar_pfn(pdev, bar, vma) (-EINVAL)\n#else\nint pci_iobar_pfn(struct pci_dev *pdev, int bar, struct vm_area_struct *vma);\n#endif\n\n#ifndef pci_root_bus_fwnode\n#define pci_root_bus_fwnode(bus)\tNULL\n#endif\n\n \n#define pci_resource_n(dev, bar)\t(&(dev)->resource[(bar)])\n#define pci_resource_start(dev, bar)\t(pci_resource_n(dev, bar)->start)\n#define pci_resource_end(dev, bar)\t(pci_resource_n(dev, bar)->end)\n#define pci_resource_flags(dev, bar)\t(pci_resource_n(dev, bar)->flags)\n#define pci_resource_len(dev,bar)\t\t\t\t\t\\\n\t(pci_resource_end((dev), (bar)) ? \t\t\t\t\\\n\t resource_size(pci_resource_n((dev), (bar))) : 0)\n\n#define __pci_dev_for_each_res0(dev, res, ...)\t\t\t\t  \\\n\tfor (unsigned int __b = 0;\t\t\t\t\t  \\\n\t     __b < PCI_NUM_RESOURCES && (res = pci_resource_n(dev, __b)); \\\n\t     __b++)\n\n#define __pci_dev_for_each_res1(dev, res, __b)\t\t\t\t  \\\n\tfor (__b = 0;\t\t\t\t\t\t\t  \\\n\t     __b < PCI_NUM_RESOURCES && (res = pci_resource_n(dev, __b)); \\\n\t     __b++)\n\n#define pci_dev_for_each_resource(dev, res, ...)\t\t\t\\\n\tCONCATENATE(__pci_dev_for_each_res, COUNT_ARGS(__VA_ARGS__)) \t\\\n\t\t    (dev, res, __VA_ARGS__)\n\n \nstatic inline void *pci_get_drvdata(struct pci_dev *pdev)\n{\n\treturn dev_get_drvdata(&pdev->dev);\n}\n\nstatic inline void pci_set_drvdata(struct pci_dev *pdev, void *data)\n{\n\tdev_set_drvdata(&pdev->dev, data);\n}\n\nstatic inline const char *pci_name(const struct pci_dev *pdev)\n{\n\treturn dev_name(&pdev->dev);\n}\n\nvoid pci_resource_to_user(const struct pci_dev *dev, int bar,\n\t\t\t  const struct resource *rsrc,\n\t\t\t  resource_size_t *start, resource_size_t *end);\n\n \n\nstruct pci_fixup {\n\tu16 vendor;\t\t\t \n\tu16 device;\t\t\t \n\tu32 class;\t\t\t \n\tunsigned int class_shift;\t \n#ifdef CONFIG_HAVE_ARCH_PREL32_RELOCATIONS\n\tint hook_offset;\n#else\n\tvoid (*hook)(struct pci_dev *dev);\n#endif\n};\n\nenum pci_fixup_pass {\n\tpci_fixup_early,\t \n\tpci_fixup_header,\t \n\tpci_fixup_final,\t \n\tpci_fixup_enable,\t \n\tpci_fixup_resume,\t \n\tpci_fixup_suspend,\t \n\tpci_fixup_resume_early,  \n\tpci_fixup_suspend_late,\t \n};\n\n#ifdef CONFIG_HAVE_ARCH_PREL32_RELOCATIONS\n#define ___DECLARE_PCI_FIXUP_SECTION(sec, name, vendor, device, class,\t\\\n\t\t\t\t    class_shift, hook)\t\t\t\\\n\t__ADDRESSABLE(hook)\t\t\t\t\t\t\\\n\tasm(\".section \"\t#sec \", \\\"a\\\"\t\t\t\t\\n\"\t\\\n\t    \".balign\t16\t\t\t\t\t\\n\"\t\\\n\t    \".short \"\t#vendor \", \" #device \"\t\t\t\\n\"\t\\\n\t    \".long \"\t#class \", \" #class_shift \"\t\t\\n\"\t\\\n\t    \".long \"\t#hook \" - .\t\t\t\t\\n\"\t\\\n\t    \".previous\t\t\t\t\t\t\\n\");\n\n \n#ifdef CONFIG_LTO_CLANG\n#define __DECLARE_PCI_FIXUP_SECTION(sec, name, vendor, device, class,\t\\\n\t\t\t\t  class_shift, hook, stub)\t\t\\\n\tvoid stub(struct pci_dev *dev);\t\t\t\t\t\\\n\tvoid stub(struct pci_dev *dev)\t\t\t\t\t\\\n\t{ \t\t\t\t\t\t\t\t\\\n\t\thook(dev); \t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\t___DECLARE_PCI_FIXUP_SECTION(sec, name, vendor, device, class,\t\\\n\t\t\t\t  class_shift, stub)\n#else\n#define __DECLARE_PCI_FIXUP_SECTION(sec, name, vendor, device, class,\t\\\n\t\t\t\t  class_shift, hook, stub)\t\t\\\n\t___DECLARE_PCI_FIXUP_SECTION(sec, name, vendor, device, class,\t\\\n\t\t\t\t  class_shift, hook)\n#endif\n\n#define DECLARE_PCI_FIXUP_SECTION(sec, name, vendor, device, class,\t\\\n\t\t\t\t  class_shift, hook)\t\t\t\\\n\t__DECLARE_PCI_FIXUP_SECTION(sec, name, vendor, device, class,\t\\\n\t\t\t\t  class_shift, hook, __UNIQUE_ID(hook))\n#else\n \n#define DECLARE_PCI_FIXUP_SECTION(section, name, vendor, device, class,\t\\\n\t\t\t\t  class_shift, hook)\t\t\t\\\n\tstatic const struct pci_fixup __PASTE(__pci_fixup_##name,__LINE__) __used\t\\\n\t__attribute__((__section__(#section), aligned((sizeof(void *)))))    \\\n\t\t= { vendor, device, class, class_shift, hook };\n#endif\n\n#define DECLARE_PCI_FIXUP_CLASS_EARLY(vendor, device, class,\t\t\\\n\t\t\t\t\t class_shift, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_early,\t\t\t\\\n\t\thook, vendor, device, class, class_shift, hook)\n#define DECLARE_PCI_FIXUP_CLASS_HEADER(vendor, device, class,\t\t\\\n\t\t\t\t\t class_shift, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_header,\t\t\t\\\n\t\thook, vendor, device, class, class_shift, hook)\n#define DECLARE_PCI_FIXUP_CLASS_FINAL(vendor, device, class,\t\t\\\n\t\t\t\t\t class_shift, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_final,\t\t\t\\\n\t\thook, vendor, device, class, class_shift, hook)\n#define DECLARE_PCI_FIXUP_CLASS_ENABLE(vendor, device, class,\t\t\\\n\t\t\t\t\t class_shift, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_enable,\t\t\t\\\n\t\thook, vendor, device, class, class_shift, hook)\n#define DECLARE_PCI_FIXUP_CLASS_RESUME(vendor, device, class,\t\t\\\n\t\t\t\t\t class_shift, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_resume,\t\t\t\\\n\t\tresume##hook, vendor, device, class, class_shift, hook)\n#define DECLARE_PCI_FIXUP_CLASS_RESUME_EARLY(vendor, device, class,\t\\\n\t\t\t\t\t class_shift, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_resume_early,\t\t\\\n\t\tresume_early##hook, vendor, device, class, class_shift, hook)\n#define DECLARE_PCI_FIXUP_CLASS_SUSPEND(vendor, device, class,\t\t\\\n\t\t\t\t\t class_shift, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_suspend,\t\t\t\\\n\t\tsuspend##hook, vendor, device, class, class_shift, hook)\n#define DECLARE_PCI_FIXUP_CLASS_SUSPEND_LATE(vendor, device, class,\t\\\n\t\t\t\t\t class_shift, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_suspend_late,\t\t\\\n\t\tsuspend_late##hook, vendor, device, class, class_shift, hook)\n\n#define DECLARE_PCI_FIXUP_EARLY(vendor, device, hook)\t\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_early,\t\t\t\\\n\t\thook, vendor, device, PCI_ANY_ID, 0, hook)\n#define DECLARE_PCI_FIXUP_HEADER(vendor, device, hook)\t\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_header,\t\t\t\\\n\t\thook, vendor, device, PCI_ANY_ID, 0, hook)\n#define DECLARE_PCI_FIXUP_FINAL(vendor, device, hook)\t\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_final,\t\t\t\\\n\t\thook, vendor, device, PCI_ANY_ID, 0, hook)\n#define DECLARE_PCI_FIXUP_ENABLE(vendor, device, hook)\t\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_enable,\t\t\t\\\n\t\thook, vendor, device, PCI_ANY_ID, 0, hook)\n#define DECLARE_PCI_FIXUP_RESUME(vendor, device, hook)\t\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_resume,\t\t\t\\\n\t\tresume##hook, vendor, device, PCI_ANY_ID, 0, hook)\n#define DECLARE_PCI_FIXUP_RESUME_EARLY(vendor, device, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_resume_early,\t\t\\\n\t\tresume_early##hook, vendor, device, PCI_ANY_ID, 0, hook)\n#define DECLARE_PCI_FIXUP_SUSPEND(vendor, device, hook)\t\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_suspend,\t\t\t\\\n\t\tsuspend##hook, vendor, device, PCI_ANY_ID, 0, hook)\n#define DECLARE_PCI_FIXUP_SUSPEND_LATE(vendor, device, hook)\t\t\\\n\tDECLARE_PCI_FIXUP_SECTION(.pci_fixup_suspend_late,\t\t\\\n\t\tsuspend_late##hook, vendor, device, PCI_ANY_ID, 0, hook)\n\n#ifdef CONFIG_PCI_QUIRKS\nvoid pci_fixup_device(enum pci_fixup_pass pass, struct pci_dev *dev);\n#else\nstatic inline void pci_fixup_device(enum pci_fixup_pass pass,\n\t\t\t\t    struct pci_dev *dev) { }\n#endif\n\nvoid __iomem *pcim_iomap(struct pci_dev *pdev, int bar, unsigned long maxlen);\nvoid pcim_iounmap(struct pci_dev *pdev, void __iomem *addr);\nvoid __iomem * const *pcim_iomap_table(struct pci_dev *pdev);\nint pcim_iomap_regions(struct pci_dev *pdev, int mask, const char *name);\nint pcim_iomap_regions_request_all(struct pci_dev *pdev, int mask,\n\t\t\t\t   const char *name);\nvoid pcim_iounmap_regions(struct pci_dev *pdev, int mask);\n\nextern int pci_pci_problems;\n#define PCIPCI_FAIL\t\t1\t \n#define PCIPCI_TRITON\t\t2\n#define PCIPCI_NATOMA\t\t4\n#define PCIPCI_VIAETBF\t\t8\n#define PCIPCI_VSFX\t\t16\n#define PCIPCI_ALIMAGIK\t\t32\t \n#define PCIAGP_FAIL\t\t64\t \n\nextern unsigned long pci_cardbus_io_size;\nextern unsigned long pci_cardbus_mem_size;\nextern u8 pci_dfl_cache_line_size;\nextern u8 pci_cache_line_size;\n\n \nvoid pcibios_disable_device(struct pci_dev *dev);\nvoid pcibios_set_master(struct pci_dev *dev);\nint pcibios_set_pcie_reset_state(struct pci_dev *dev,\n\t\t\t\t enum pcie_reset_state state);\nint pcibios_device_add(struct pci_dev *dev);\nvoid pcibios_release_device(struct pci_dev *dev);\n#ifdef CONFIG_PCI\nvoid pcibios_penalize_isa_irq(int irq, int active);\n#else\nstatic inline void pcibios_penalize_isa_irq(int irq, int active) {}\n#endif\nint pcibios_alloc_irq(struct pci_dev *dev);\nvoid pcibios_free_irq(struct pci_dev *dev);\nresource_size_t pcibios_default_alignment(void);\n\n#if !defined(HAVE_PCI_MMAP) && !defined(ARCH_GENERIC_PCI_MMAP_RESOURCE)\nextern int pci_create_resource_files(struct pci_dev *dev);\nextern void pci_remove_resource_files(struct pci_dev *dev);\n#endif\n\n#if defined(CONFIG_PCI_MMCONFIG) || defined(CONFIG_ACPI_MCFG)\nvoid __init pci_mmcfg_early_init(void);\nvoid __init pci_mmcfg_late_init(void);\n#else\nstatic inline void pci_mmcfg_early_init(void) { }\nstatic inline void pci_mmcfg_late_init(void) { }\n#endif\n\nint pci_ext_cfg_avail(void);\n\nvoid __iomem *pci_ioremap_bar(struct pci_dev *pdev, int bar);\nvoid __iomem *pci_ioremap_wc_bar(struct pci_dev *pdev, int bar);\n\n#ifdef CONFIG_PCI_IOV\nint pci_iov_virtfn_bus(struct pci_dev *dev, int id);\nint pci_iov_virtfn_devfn(struct pci_dev *dev, int id);\nint pci_iov_vf_id(struct pci_dev *dev);\nvoid *pci_iov_get_pf_drvdata(struct pci_dev *dev, struct pci_driver *pf_driver);\nint pci_enable_sriov(struct pci_dev *dev, int nr_virtfn);\nvoid pci_disable_sriov(struct pci_dev *dev);\n\nint pci_iov_sysfs_link(struct pci_dev *dev, struct pci_dev *virtfn, int id);\nint pci_iov_add_virtfn(struct pci_dev *dev, int id);\nvoid pci_iov_remove_virtfn(struct pci_dev *dev, int id);\nint pci_num_vf(struct pci_dev *dev);\nint pci_vfs_assigned(struct pci_dev *dev);\nint pci_sriov_set_totalvfs(struct pci_dev *dev, u16 numvfs);\nint pci_sriov_get_totalvfs(struct pci_dev *dev);\nint pci_sriov_configure_simple(struct pci_dev *dev, int nr_virtfn);\nresource_size_t pci_iov_resource_size(struct pci_dev *dev, int resno);\nvoid pci_vf_drivers_autoprobe(struct pci_dev *dev, bool probe);\n\n \nint pcibios_sriov_enable(struct pci_dev *pdev, u16 num_vfs);\nint pcibios_sriov_disable(struct pci_dev *pdev);\nresource_size_t pcibios_iov_resource_alignment(struct pci_dev *dev, int resno);\n#else\nstatic inline int pci_iov_virtfn_bus(struct pci_dev *dev, int id)\n{\n\treturn -ENOSYS;\n}\nstatic inline int pci_iov_virtfn_devfn(struct pci_dev *dev, int id)\n{\n\treturn -ENOSYS;\n}\n\nstatic inline int pci_iov_vf_id(struct pci_dev *dev)\n{\n\treturn -ENOSYS;\n}\n\nstatic inline void *pci_iov_get_pf_drvdata(struct pci_dev *dev,\n\t\t\t\t\t   struct pci_driver *pf_driver)\n{\n\treturn ERR_PTR(-EINVAL);\n}\n\nstatic inline int pci_enable_sriov(struct pci_dev *dev, int nr_virtfn)\n{ return -ENODEV; }\n\nstatic inline int pci_iov_sysfs_link(struct pci_dev *dev,\n\t\t\t\t     struct pci_dev *virtfn, int id)\n{\n\treturn -ENODEV;\n}\nstatic inline int pci_iov_add_virtfn(struct pci_dev *dev, int id)\n{\n\treturn -ENOSYS;\n}\nstatic inline void pci_iov_remove_virtfn(struct pci_dev *dev,\n\t\t\t\t\t int id) { }\nstatic inline void pci_disable_sriov(struct pci_dev *dev) { }\nstatic inline int pci_num_vf(struct pci_dev *dev) { return 0; }\nstatic inline int pci_vfs_assigned(struct pci_dev *dev)\n{ return 0; }\nstatic inline int pci_sriov_set_totalvfs(struct pci_dev *dev, u16 numvfs)\n{ return 0; }\nstatic inline int pci_sriov_get_totalvfs(struct pci_dev *dev)\n{ return 0; }\n#define pci_sriov_configure_simple\tNULL\nstatic inline resource_size_t pci_iov_resource_size(struct pci_dev *dev, int resno)\n{ return 0; }\nstatic inline void pci_vf_drivers_autoprobe(struct pci_dev *dev, bool probe) { }\n#endif\n\n#if defined(CONFIG_HOTPLUG_PCI) || defined(CONFIG_HOTPLUG_PCI_MODULE)\nvoid pci_hp_create_module_link(struct pci_slot *pci_slot);\nvoid pci_hp_remove_module_link(struct pci_slot *pci_slot);\n#endif\n\n \nstatic inline int pci_pcie_cap(struct pci_dev *dev)\n{\n\treturn dev->pcie_cap;\n}\n\n \nstatic inline bool pci_is_pcie(struct pci_dev *dev)\n{\n\treturn pci_pcie_cap(dev);\n}\n\n \nstatic inline u16 pcie_caps_reg(const struct pci_dev *dev)\n{\n\treturn dev->pcie_flags_reg;\n}\n\n \nstatic inline int pci_pcie_type(const struct pci_dev *dev)\n{\n\treturn (pcie_caps_reg(dev) & PCI_EXP_FLAGS_TYPE) >> 4;\n}\n\n \nstatic inline struct pci_dev *pcie_find_root_port(struct pci_dev *dev)\n{\n\twhile (dev) {\n\t\tif (pci_is_pcie(dev) &&\n\t\t    pci_pcie_type(dev) == PCI_EXP_TYPE_ROOT_PORT)\n\t\t\treturn dev;\n\t\tdev = pci_upstream_bridge(dev);\n\t}\n\n\treturn NULL;\n}\n\nvoid pci_request_acs(void);\nbool pci_acs_enabled(struct pci_dev *pdev, u16 acs_flags);\nbool pci_acs_path_enabled(struct pci_dev *start,\n\t\t\t  struct pci_dev *end, u16 acs_flags);\nint pci_enable_atomic_ops_to_root(struct pci_dev *dev, u32 cap_mask);\n\n#define PCI_VPD_LRDT\t\t\t0x80\t \n#define PCI_VPD_LRDT_ID(x)\t\t((x) | PCI_VPD_LRDT)\n\n \n#define PCI_VPD_LTIN_ID_STRING\t\t0x02\t \n#define PCI_VPD_LTIN_RO_DATA\t\t0x10\t \n#define PCI_VPD_LTIN_RW_DATA\t\t0x11\t \n\n#define PCI_VPD_LRDT_ID_STRING\t\tPCI_VPD_LRDT_ID(PCI_VPD_LTIN_ID_STRING)\n#define PCI_VPD_LRDT_RO_DATA\t\tPCI_VPD_LRDT_ID(PCI_VPD_LTIN_RO_DATA)\n#define PCI_VPD_LRDT_RW_DATA\t\tPCI_VPD_LRDT_ID(PCI_VPD_LTIN_RW_DATA)\n\n#define PCI_VPD_RO_KEYWORD_PARTNO\t\"PN\"\n#define PCI_VPD_RO_KEYWORD_SERIALNO\t\"SN\"\n#define PCI_VPD_RO_KEYWORD_MFR_ID\t\"MN\"\n#define PCI_VPD_RO_KEYWORD_VENDOR0\t\"V0\"\n#define PCI_VPD_RO_KEYWORD_CHKSUM\t\"RV\"\n\n \nvoid *pci_vpd_alloc(struct pci_dev *dev, unsigned int *size);\n\n \nint pci_vpd_find_id_string(const u8 *buf, unsigned int len, unsigned int *size);\n\n \nint pci_vpd_find_ro_info_keyword(const void *buf, unsigned int len,\n\t\t\t\t const char *kw, unsigned int *size);\n\n \nint pci_vpd_check_csum(const void *buf, unsigned int len);\n\n \n#ifdef CONFIG_OF\nstruct device_node;\nstruct irq_domain;\nstruct irq_domain *pci_host_bridge_of_msi_domain(struct pci_bus *bus);\nbool pci_host_of_has_msi_map(struct device *dev);\n\n \nstruct device_node *pcibios_get_phb_of_node(struct pci_bus *bus);\n\n#else\t \nstatic inline struct irq_domain *\npci_host_bridge_of_msi_domain(struct pci_bus *bus) { return NULL; }\nstatic inline bool pci_host_of_has_msi_map(struct device *dev) { return false; }\n#endif   \n\nstatic inline struct device_node *\npci_device_to_OF_node(const struct pci_dev *pdev)\n{\n\treturn pdev ? pdev->dev.of_node : NULL;\n}\n\nstatic inline struct device_node *pci_bus_to_OF_node(struct pci_bus *bus)\n{\n\treturn bus ? bus->dev.of_node : NULL;\n}\n\n#ifdef CONFIG_ACPI\nstruct irq_domain *pci_host_bridge_acpi_msi_domain(struct pci_bus *bus);\n\nvoid\npci_msi_register_fwnode_provider(struct fwnode_handle *(*fn)(struct device *));\nbool pci_pr3_present(struct pci_dev *pdev);\n#else\nstatic inline struct irq_domain *\npci_host_bridge_acpi_msi_domain(struct pci_bus *bus) { return NULL; }\nstatic inline bool pci_pr3_present(struct pci_dev *pdev) { return false; }\n#endif\n\n#ifdef CONFIG_EEH\nstatic inline struct eeh_dev *pci_dev_to_eeh_dev(struct pci_dev *pdev)\n{\n\treturn pdev->dev.archdata.edev;\n}\n#endif\n\nvoid pci_add_dma_alias(struct pci_dev *dev, u8 devfn_from, unsigned nr_devfns);\nbool pci_devs_are_dma_aliases(struct pci_dev *dev1, struct pci_dev *dev2);\nint pci_for_each_dma_alias(struct pci_dev *pdev,\n\t\t\t   int (*fn)(struct pci_dev *pdev,\n\t\t\t\t     u16 alias, void *data), void *data);\n\n \nstatic inline void pci_set_dev_assigned(struct pci_dev *pdev)\n{\n\tpdev->dev_flags |= PCI_DEV_FLAGS_ASSIGNED;\n}\nstatic inline void pci_clear_dev_assigned(struct pci_dev *pdev)\n{\n\tpdev->dev_flags &= ~PCI_DEV_FLAGS_ASSIGNED;\n}\nstatic inline bool pci_is_dev_assigned(struct pci_dev *pdev)\n{\n\treturn (pdev->dev_flags & PCI_DEV_FLAGS_ASSIGNED) == PCI_DEV_FLAGS_ASSIGNED;\n}\n\n \nstatic inline bool pci_ari_enabled(struct pci_bus *bus)\n{\n\treturn bus->self && bus->self->ari_enabled;\n}\n\n \nstatic inline bool pci_is_thunderbolt_attached(struct pci_dev *pdev)\n{\n\tstruct pci_dev *parent = pdev;\n\n\tif (pdev->is_thunderbolt)\n\t\treturn true;\n\n\twhile ((parent = pci_upstream_bridge(parent)))\n\t\tif (parent->is_thunderbolt)\n\t\t\treturn true;\n\n\treturn false;\n}\n\n#if defined(CONFIG_PCIEPORTBUS) || defined(CONFIG_EEH)\nvoid pci_uevent_ers(struct pci_dev *pdev, enum  pci_ers_result err_type);\n#endif\n\n#include <linux/dma-mapping.h>\n\n#define pci_printk(level, pdev, fmt, arg...) \\\n\tdev_printk(level, &(pdev)->dev, fmt, ##arg)\n\n#define pci_emerg(pdev, fmt, arg...)\tdev_emerg(&(pdev)->dev, fmt, ##arg)\n#define pci_alert(pdev, fmt, arg...)\tdev_alert(&(pdev)->dev, fmt, ##arg)\n#define pci_crit(pdev, fmt, arg...)\tdev_crit(&(pdev)->dev, fmt, ##arg)\n#define pci_err(pdev, fmt, arg...)\tdev_err(&(pdev)->dev, fmt, ##arg)\n#define pci_warn(pdev, fmt, arg...)\tdev_warn(&(pdev)->dev, fmt, ##arg)\n#define pci_warn_once(pdev, fmt, arg...) dev_warn_once(&(pdev)->dev, fmt, ##arg)\n#define pci_notice(pdev, fmt, arg...)\tdev_notice(&(pdev)->dev, fmt, ##arg)\n#define pci_info(pdev, fmt, arg...)\tdev_info(&(pdev)->dev, fmt, ##arg)\n#define pci_dbg(pdev, fmt, arg...)\tdev_dbg(&(pdev)->dev, fmt, ##arg)\n\n#define pci_notice_ratelimited(pdev, fmt, arg...) \\\n\tdev_notice_ratelimited(&(pdev)->dev, fmt, ##arg)\n\n#define pci_info_ratelimited(pdev, fmt, arg...) \\\n\tdev_info_ratelimited(&(pdev)->dev, fmt, ##arg)\n\n#define pci_WARN(pdev, condition, fmt, arg...) \\\n\tWARN(condition, \"%s %s: \" fmt, \\\n\t     dev_driver_string(&(pdev)->dev), pci_name(pdev), ##arg)\n\n#define pci_WARN_ONCE(pdev, condition, fmt, arg...) \\\n\tWARN_ONCE(condition, \"%s %s: \" fmt, \\\n\t\t  dev_driver_string(&(pdev)->dev), pci_name(pdev), ##arg)\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}