{
  "module_name": "cpumask.h",
  "hash_id": "c246a37472cf4f3747d36274398d4d542234f67885060d0108e043ba7ae23baa",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/cpumask.h",
  "human_readable_source": " \n#ifndef __LINUX_CPUMASK_H\n#define __LINUX_CPUMASK_H\n\n \n#include <linux/kernel.h>\n#include <linux/threads.h>\n#include <linux/bitmap.h>\n#include <linux/atomic.h>\n#include <linux/bug.h>\n#include <linux/gfp_types.h>\n#include <linux/numa.h>\n\n \ntypedef struct cpumask { DECLARE_BITMAP(bits, NR_CPUS); } cpumask_t;\n\n \n#define cpumask_bits(maskp) ((maskp)->bits)\n\n \n#define cpumask_pr_args(maskp)\t\tnr_cpu_ids, cpumask_bits(maskp)\n\n#if (NR_CPUS == 1) || defined(CONFIG_FORCE_NR_CPUS)\n#define nr_cpu_ids ((unsigned int)NR_CPUS)\n#else\nextern unsigned int nr_cpu_ids;\n#endif\n\nstatic inline void set_nr_cpu_ids(unsigned int nr)\n{\n#if (NR_CPUS == 1) || defined(CONFIG_FORCE_NR_CPUS)\n\tWARN_ON(nr != nr_cpu_ids);\n#else\n\tnr_cpu_ids = nr;\n#endif\n}\n\n \n#if NR_CPUS <= BITS_PER_LONG\n  #define small_cpumask_bits ((unsigned int)NR_CPUS)\n  #define large_cpumask_bits ((unsigned int)NR_CPUS)\n#elif NR_CPUS <= 4*BITS_PER_LONG\n  #define small_cpumask_bits nr_cpu_ids\n  #define large_cpumask_bits ((unsigned int)NR_CPUS)\n#else\n  #define small_cpumask_bits nr_cpu_ids\n  #define large_cpumask_bits nr_cpu_ids\n#endif\n#define nr_cpumask_bits nr_cpu_ids\n\n \n\nextern struct cpumask __cpu_possible_mask;\nextern struct cpumask __cpu_online_mask;\nextern struct cpumask __cpu_present_mask;\nextern struct cpumask __cpu_active_mask;\nextern struct cpumask __cpu_dying_mask;\n#define cpu_possible_mask ((const struct cpumask *)&__cpu_possible_mask)\n#define cpu_online_mask   ((const struct cpumask *)&__cpu_online_mask)\n#define cpu_present_mask  ((const struct cpumask *)&__cpu_present_mask)\n#define cpu_active_mask   ((const struct cpumask *)&__cpu_active_mask)\n#define cpu_dying_mask    ((const struct cpumask *)&__cpu_dying_mask)\n\nextern atomic_t __num_online_cpus;\n\nextern cpumask_t cpus_booted_once_mask;\n\nstatic __always_inline void cpu_max_bits_warn(unsigned int cpu, unsigned int bits)\n{\n#ifdef CONFIG_DEBUG_PER_CPU_MAPS\n\tWARN_ON_ONCE(cpu >= bits);\n#endif  \n}\n\n \nstatic __always_inline unsigned int cpumask_check(unsigned int cpu)\n{\n\tcpu_max_bits_warn(cpu, small_cpumask_bits);\n\treturn cpu;\n}\n\n \nstatic inline unsigned int cpumask_first(const struct cpumask *srcp)\n{\n\treturn find_first_bit(cpumask_bits(srcp), small_cpumask_bits);\n}\n\n \nstatic inline unsigned int cpumask_first_zero(const struct cpumask *srcp)\n{\n\treturn find_first_zero_bit(cpumask_bits(srcp), small_cpumask_bits);\n}\n\n \nstatic inline\nunsigned int cpumask_first_and(const struct cpumask *srcp1, const struct cpumask *srcp2)\n{\n\treturn find_first_and_bit(cpumask_bits(srcp1), cpumask_bits(srcp2), small_cpumask_bits);\n}\n\n \nstatic inline unsigned int cpumask_last(const struct cpumask *srcp)\n{\n\treturn find_last_bit(cpumask_bits(srcp), small_cpumask_bits);\n}\n\n \nstatic inline\nunsigned int cpumask_next(int n, const struct cpumask *srcp)\n{\n\t \n\tif (n != -1)\n\t\tcpumask_check(n);\n\treturn find_next_bit(cpumask_bits(srcp), small_cpumask_bits, n + 1);\n}\n\n \nstatic inline unsigned int cpumask_next_zero(int n, const struct cpumask *srcp)\n{\n\t \n\tif (n != -1)\n\t\tcpumask_check(n);\n\treturn find_next_zero_bit(cpumask_bits(srcp), small_cpumask_bits, n+1);\n}\n\n#if NR_CPUS == 1\n \nstatic inline unsigned int cpumask_local_spread(unsigned int i, int node)\n{\n\treturn 0;\n}\n\nstatic inline unsigned int cpumask_any_and_distribute(const struct cpumask *src1p,\n\t\t\t\t\t\t      const struct cpumask *src2p)\n{\n\treturn cpumask_first_and(src1p, src2p);\n}\n\nstatic inline unsigned int cpumask_any_distribute(const struct cpumask *srcp)\n{\n\treturn cpumask_first(srcp);\n}\n#else\nunsigned int cpumask_local_spread(unsigned int i, int node);\nunsigned int cpumask_any_and_distribute(const struct cpumask *src1p,\n\t\t\t       const struct cpumask *src2p);\nunsigned int cpumask_any_distribute(const struct cpumask *srcp);\n#endif  \n\n \nstatic inline\nunsigned int cpumask_next_and(int n, const struct cpumask *src1p,\n\t\t     const struct cpumask *src2p)\n{\n\t \n\tif (n != -1)\n\t\tcpumask_check(n);\n\treturn find_next_and_bit(cpumask_bits(src1p), cpumask_bits(src2p),\n\t\tsmall_cpumask_bits, n + 1);\n}\n\n \n#define for_each_cpu(cpu, mask)\t\t\t\t\\\n\tfor_each_set_bit(cpu, cpumask_bits(mask), small_cpumask_bits)\n\n#if NR_CPUS == 1\nstatic inline\nunsigned int cpumask_next_wrap(int n, const struct cpumask *mask, int start, bool wrap)\n{\n\tcpumask_check(start);\n\tif (n != -1)\n\t\tcpumask_check(n);\n\n\t \n\tif (wrap && n >= 0)\n\t\treturn nr_cpumask_bits;\n\n\treturn cpumask_first(mask);\n}\n#else\nunsigned int __pure cpumask_next_wrap(int n, const struct cpumask *mask, int start, bool wrap);\n#endif\n\n \n#define for_each_cpu_wrap(cpu, mask, start)\t\t\t\t\\\n\tfor_each_set_bit_wrap(cpu, cpumask_bits(mask), small_cpumask_bits, start)\n\n \n#define for_each_cpu_and(cpu, mask1, mask2)\t\t\t\t\\\n\tfor_each_and_bit(cpu, cpumask_bits(mask1), cpumask_bits(mask2), small_cpumask_bits)\n\n \n#define for_each_cpu_andnot(cpu, mask1, mask2)\t\t\t\t\\\n\tfor_each_andnot_bit(cpu, cpumask_bits(mask1), cpumask_bits(mask2), small_cpumask_bits)\n\n \n#define for_each_cpu_or(cpu, mask1, mask2)\t\t\t\t\\\n\tfor_each_or_bit(cpu, cpumask_bits(mask1), cpumask_bits(mask2), small_cpumask_bits)\n\n \nstatic inline\nunsigned int cpumask_any_but(const struct cpumask *mask, unsigned int cpu)\n{\n\tunsigned int i;\n\n\tcpumask_check(cpu);\n\tfor_each_cpu(i, mask)\n\t\tif (i != cpu)\n\t\t\tbreak;\n\treturn i;\n}\n\n \nstatic inline unsigned int cpumask_nth(unsigned int cpu, const struct cpumask *srcp)\n{\n\treturn find_nth_bit(cpumask_bits(srcp), small_cpumask_bits, cpumask_check(cpu));\n}\n\n \nstatic inline\nunsigned int cpumask_nth_and(unsigned int cpu, const struct cpumask *srcp1,\n\t\t\t\t\t\t\tconst struct cpumask *srcp2)\n{\n\treturn find_nth_and_bit(cpumask_bits(srcp1), cpumask_bits(srcp2),\n\t\t\t\tsmall_cpumask_bits, cpumask_check(cpu));\n}\n\n \nstatic inline\nunsigned int cpumask_nth_andnot(unsigned int cpu, const struct cpumask *srcp1,\n\t\t\t\t\t\t\tconst struct cpumask *srcp2)\n{\n\treturn find_nth_andnot_bit(cpumask_bits(srcp1), cpumask_bits(srcp2),\n\t\t\t\tsmall_cpumask_bits, cpumask_check(cpu));\n}\n\n \nstatic __always_inline\nunsigned int cpumask_nth_and_andnot(unsigned int cpu, const struct cpumask *srcp1,\n\t\t\t\t\t\t\tconst struct cpumask *srcp2,\n\t\t\t\t\t\t\tconst struct cpumask *srcp3)\n{\n\treturn find_nth_and_andnot_bit(cpumask_bits(srcp1),\n\t\t\t\t\tcpumask_bits(srcp2),\n\t\t\t\t\tcpumask_bits(srcp3),\n\t\t\t\t\tsmall_cpumask_bits, cpumask_check(cpu));\n}\n\n#define CPU_BITS_NONE\t\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\\\n\t[0 ... BITS_TO_LONGS(NR_CPUS)-1] = 0UL\t\t\t\\\n}\n\n#define CPU_BITS_CPU0\t\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\\\n\t[0] =  1UL\t\t\t\t\t\t\\\n}\n\n \nstatic __always_inline void cpumask_set_cpu(unsigned int cpu, struct cpumask *dstp)\n{\n\tset_bit(cpumask_check(cpu), cpumask_bits(dstp));\n}\n\nstatic __always_inline void __cpumask_set_cpu(unsigned int cpu, struct cpumask *dstp)\n{\n\t__set_bit(cpumask_check(cpu), cpumask_bits(dstp));\n}\n\n\n \nstatic __always_inline void cpumask_clear_cpu(int cpu, struct cpumask *dstp)\n{\n\tclear_bit(cpumask_check(cpu), cpumask_bits(dstp));\n}\n\nstatic __always_inline void __cpumask_clear_cpu(int cpu, struct cpumask *dstp)\n{\n\t__clear_bit(cpumask_check(cpu), cpumask_bits(dstp));\n}\n\n \nstatic __always_inline bool cpumask_test_cpu(int cpu, const struct cpumask *cpumask)\n{\n\treturn test_bit(cpumask_check(cpu), cpumask_bits((cpumask)));\n}\n\n \nstatic __always_inline bool cpumask_test_and_set_cpu(int cpu, struct cpumask *cpumask)\n{\n\treturn test_and_set_bit(cpumask_check(cpu), cpumask_bits(cpumask));\n}\n\n \nstatic __always_inline bool cpumask_test_and_clear_cpu(int cpu, struct cpumask *cpumask)\n{\n\treturn test_and_clear_bit(cpumask_check(cpu), cpumask_bits(cpumask));\n}\n\n \nstatic inline void cpumask_setall(struct cpumask *dstp)\n{\n\tif (small_const_nbits(small_cpumask_bits)) {\n\t\tcpumask_bits(dstp)[0] = BITMAP_LAST_WORD_MASK(nr_cpumask_bits);\n\t\treturn;\n\t}\n\tbitmap_fill(cpumask_bits(dstp), nr_cpumask_bits);\n}\n\n \nstatic inline void cpumask_clear(struct cpumask *dstp)\n{\n\tbitmap_zero(cpumask_bits(dstp), large_cpumask_bits);\n}\n\n \nstatic inline bool cpumask_and(struct cpumask *dstp,\n\t\t\t       const struct cpumask *src1p,\n\t\t\t       const struct cpumask *src2p)\n{\n\treturn bitmap_and(cpumask_bits(dstp), cpumask_bits(src1p),\n\t\t\t\t       cpumask_bits(src2p), small_cpumask_bits);\n}\n\n \nstatic inline void cpumask_or(struct cpumask *dstp, const struct cpumask *src1p,\n\t\t\t      const struct cpumask *src2p)\n{\n\tbitmap_or(cpumask_bits(dstp), cpumask_bits(src1p),\n\t\t\t\t      cpumask_bits(src2p), small_cpumask_bits);\n}\n\n \nstatic inline void cpumask_xor(struct cpumask *dstp,\n\t\t\t       const struct cpumask *src1p,\n\t\t\t       const struct cpumask *src2p)\n{\n\tbitmap_xor(cpumask_bits(dstp), cpumask_bits(src1p),\n\t\t\t\t       cpumask_bits(src2p), small_cpumask_bits);\n}\n\n \nstatic inline bool cpumask_andnot(struct cpumask *dstp,\n\t\t\t\t  const struct cpumask *src1p,\n\t\t\t\t  const struct cpumask *src2p)\n{\n\treturn bitmap_andnot(cpumask_bits(dstp), cpumask_bits(src1p),\n\t\t\t\t\t  cpumask_bits(src2p), small_cpumask_bits);\n}\n\n \nstatic inline bool cpumask_equal(const struct cpumask *src1p,\n\t\t\t\tconst struct cpumask *src2p)\n{\n\treturn bitmap_equal(cpumask_bits(src1p), cpumask_bits(src2p),\n\t\t\t\t\t\t small_cpumask_bits);\n}\n\n \nstatic inline bool cpumask_or_equal(const struct cpumask *src1p,\n\t\t\t\t    const struct cpumask *src2p,\n\t\t\t\t    const struct cpumask *src3p)\n{\n\treturn bitmap_or_equal(cpumask_bits(src1p), cpumask_bits(src2p),\n\t\t\t       cpumask_bits(src3p), small_cpumask_bits);\n}\n\n \nstatic inline bool cpumask_intersects(const struct cpumask *src1p,\n\t\t\t\t     const struct cpumask *src2p)\n{\n\treturn bitmap_intersects(cpumask_bits(src1p), cpumask_bits(src2p),\n\t\t\t\t\t\t      small_cpumask_bits);\n}\n\n \nstatic inline bool cpumask_subset(const struct cpumask *src1p,\n\t\t\t\t const struct cpumask *src2p)\n{\n\treturn bitmap_subset(cpumask_bits(src1p), cpumask_bits(src2p),\n\t\t\t\t\t\t  small_cpumask_bits);\n}\n\n \nstatic inline bool cpumask_empty(const struct cpumask *srcp)\n{\n\treturn bitmap_empty(cpumask_bits(srcp), small_cpumask_bits);\n}\n\n \nstatic inline bool cpumask_full(const struct cpumask *srcp)\n{\n\treturn bitmap_full(cpumask_bits(srcp), nr_cpumask_bits);\n}\n\n \nstatic inline unsigned int cpumask_weight(const struct cpumask *srcp)\n{\n\treturn bitmap_weight(cpumask_bits(srcp), small_cpumask_bits);\n}\n\n \nstatic inline unsigned int cpumask_weight_and(const struct cpumask *srcp1,\n\t\t\t\t\t\tconst struct cpumask *srcp2)\n{\n\treturn bitmap_weight_and(cpumask_bits(srcp1), cpumask_bits(srcp2), small_cpumask_bits);\n}\n\n \nstatic inline void cpumask_shift_right(struct cpumask *dstp,\n\t\t\t\t       const struct cpumask *srcp, int n)\n{\n\tbitmap_shift_right(cpumask_bits(dstp), cpumask_bits(srcp), n,\n\t\t\t\t\t       small_cpumask_bits);\n}\n\n \nstatic inline void cpumask_shift_left(struct cpumask *dstp,\n\t\t\t\t      const struct cpumask *srcp, int n)\n{\n\tbitmap_shift_left(cpumask_bits(dstp), cpumask_bits(srcp), n,\n\t\t\t\t\t      nr_cpumask_bits);\n}\n\n \nstatic inline void cpumask_copy(struct cpumask *dstp,\n\t\t\t\tconst struct cpumask *srcp)\n{\n\tbitmap_copy(cpumask_bits(dstp), cpumask_bits(srcp), large_cpumask_bits);\n}\n\n \n#define cpumask_any(srcp) cpumask_first(srcp)\n\n \n#define cpumask_any_and(mask1, mask2) cpumask_first_and((mask1), (mask2))\n\n \n#define cpumask_of(cpu) (get_cpu_mask(cpu))\n\n \nstatic inline int cpumask_parse_user(const char __user *buf, int len,\n\t\t\t\t     struct cpumask *dstp)\n{\n\treturn bitmap_parse_user(buf, len, cpumask_bits(dstp), nr_cpumask_bits);\n}\n\n \nstatic inline int cpumask_parselist_user(const char __user *buf, int len,\n\t\t\t\t     struct cpumask *dstp)\n{\n\treturn bitmap_parselist_user(buf, len, cpumask_bits(dstp),\n\t\t\t\t     nr_cpumask_bits);\n}\n\n \nstatic inline int cpumask_parse(const char *buf, struct cpumask *dstp)\n{\n\treturn bitmap_parse(buf, UINT_MAX, cpumask_bits(dstp), nr_cpumask_bits);\n}\n\n \nstatic inline int cpulist_parse(const char *buf, struct cpumask *dstp)\n{\n\treturn bitmap_parselist(buf, cpumask_bits(dstp), nr_cpumask_bits);\n}\n\n \nstatic inline unsigned int cpumask_size(void)\n{\n\treturn BITS_TO_LONGS(large_cpumask_bits) * sizeof(long);\n}\n\n \n#ifdef CONFIG_CPUMASK_OFFSTACK\ntypedef struct cpumask *cpumask_var_t;\n\n#define this_cpu_cpumask_var_ptr(x)\tthis_cpu_read(x)\n#define __cpumask_var_read_mostly\t__read_mostly\n\nbool alloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags, int node);\n\nstatic inline\nbool zalloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags, int node)\n{\n\treturn alloc_cpumask_var_node(mask, flags | __GFP_ZERO, node);\n}\n\n \nstatic inline\nbool alloc_cpumask_var(cpumask_var_t *mask, gfp_t flags)\n{\n\treturn alloc_cpumask_var_node(mask, flags, NUMA_NO_NODE);\n}\n\nstatic inline\nbool zalloc_cpumask_var(cpumask_var_t *mask, gfp_t flags)\n{\n\treturn alloc_cpumask_var(mask, flags | __GFP_ZERO);\n}\n\nvoid alloc_bootmem_cpumask_var(cpumask_var_t *mask);\nvoid free_cpumask_var(cpumask_var_t mask);\nvoid free_bootmem_cpumask_var(cpumask_var_t mask);\n\nstatic inline bool cpumask_available(cpumask_var_t mask)\n{\n\treturn mask != NULL;\n}\n\n#else\ntypedef struct cpumask cpumask_var_t[1];\n\n#define this_cpu_cpumask_var_ptr(x) this_cpu_ptr(x)\n#define __cpumask_var_read_mostly\n\nstatic inline bool alloc_cpumask_var(cpumask_var_t *mask, gfp_t flags)\n{\n\treturn true;\n}\n\nstatic inline bool alloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags,\n\t\t\t\t\t  int node)\n{\n\treturn true;\n}\n\nstatic inline bool zalloc_cpumask_var(cpumask_var_t *mask, gfp_t flags)\n{\n\tcpumask_clear(*mask);\n\treturn true;\n}\n\nstatic inline bool zalloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags,\n\t\t\t\t\t  int node)\n{\n\tcpumask_clear(*mask);\n\treturn true;\n}\n\nstatic inline void alloc_bootmem_cpumask_var(cpumask_var_t *mask)\n{\n}\n\nstatic inline void free_cpumask_var(cpumask_var_t mask)\n{\n}\n\nstatic inline void free_bootmem_cpumask_var(cpumask_var_t mask)\n{\n}\n\nstatic inline bool cpumask_available(cpumask_var_t mask)\n{\n\treturn true;\n}\n#endif  \n\n \nextern const DECLARE_BITMAP(cpu_all_bits, NR_CPUS);\n#define cpu_all_mask to_cpumask(cpu_all_bits)\n\n \n#define cpu_none_mask to_cpumask(cpu_bit_bitmap[0])\n\n#if NR_CPUS == 1\n \n#define for_each_possible_cpu(cpu)\tfor ((cpu) = 0; (cpu) < 1; (cpu)++)\n#define for_each_online_cpu(cpu)\tfor ((cpu) = 0; (cpu) < 1; (cpu)++)\n#define for_each_present_cpu(cpu)\tfor ((cpu) = 0; (cpu) < 1; (cpu)++)\n#else\n#define for_each_possible_cpu(cpu) for_each_cpu((cpu), cpu_possible_mask)\n#define for_each_online_cpu(cpu)   for_each_cpu((cpu), cpu_online_mask)\n#define for_each_present_cpu(cpu)  for_each_cpu((cpu), cpu_present_mask)\n#endif\n\n \nvoid init_cpu_present(const struct cpumask *src);\nvoid init_cpu_possible(const struct cpumask *src);\nvoid init_cpu_online(const struct cpumask *src);\n\nstatic inline void reset_cpu_possible_mask(void)\n{\n\tbitmap_zero(cpumask_bits(&__cpu_possible_mask), NR_CPUS);\n}\n\nstatic inline void\nset_cpu_possible(unsigned int cpu, bool possible)\n{\n\tif (possible)\n\t\tcpumask_set_cpu(cpu, &__cpu_possible_mask);\n\telse\n\t\tcpumask_clear_cpu(cpu, &__cpu_possible_mask);\n}\n\nstatic inline void\nset_cpu_present(unsigned int cpu, bool present)\n{\n\tif (present)\n\t\tcpumask_set_cpu(cpu, &__cpu_present_mask);\n\telse\n\t\tcpumask_clear_cpu(cpu, &__cpu_present_mask);\n}\n\nvoid set_cpu_online(unsigned int cpu, bool online);\n\nstatic inline void\nset_cpu_active(unsigned int cpu, bool active)\n{\n\tif (active)\n\t\tcpumask_set_cpu(cpu, &__cpu_active_mask);\n\telse\n\t\tcpumask_clear_cpu(cpu, &__cpu_active_mask);\n}\n\nstatic inline void\nset_cpu_dying(unsigned int cpu, bool dying)\n{\n\tif (dying)\n\t\tcpumask_set_cpu(cpu, &__cpu_dying_mask);\n\telse\n\t\tcpumask_clear_cpu(cpu, &__cpu_dying_mask);\n}\n\n \n#define to_cpumask(bitmap)\t\t\t\t\t\t\\\n\t((struct cpumask *)(1 ? (bitmap)\t\t\t\t\\\n\t\t\t    : (void *)sizeof(__check_is_bitmap(bitmap))))\n\nstatic inline int __check_is_bitmap(const unsigned long *bitmap)\n{\n\treturn 1;\n}\n\n \nextern const unsigned long\n\tcpu_bit_bitmap[BITS_PER_LONG+1][BITS_TO_LONGS(NR_CPUS)];\n\nstatic inline const struct cpumask *get_cpu_mask(unsigned int cpu)\n{\n\tconst unsigned long *p = cpu_bit_bitmap[1 + cpu % BITS_PER_LONG];\n\tp -= cpu / BITS_PER_LONG;\n\treturn to_cpumask(p);\n}\n\n#if NR_CPUS > 1\n \nstatic __always_inline unsigned int num_online_cpus(void)\n{\n\treturn raw_atomic_read(&__num_online_cpus);\n}\n#define num_possible_cpus()\tcpumask_weight(cpu_possible_mask)\n#define num_present_cpus()\tcpumask_weight(cpu_present_mask)\n#define num_active_cpus()\tcpumask_weight(cpu_active_mask)\n\nstatic inline bool cpu_online(unsigned int cpu)\n{\n\treturn cpumask_test_cpu(cpu, cpu_online_mask);\n}\n\nstatic inline bool cpu_possible(unsigned int cpu)\n{\n\treturn cpumask_test_cpu(cpu, cpu_possible_mask);\n}\n\nstatic inline bool cpu_present(unsigned int cpu)\n{\n\treturn cpumask_test_cpu(cpu, cpu_present_mask);\n}\n\nstatic inline bool cpu_active(unsigned int cpu)\n{\n\treturn cpumask_test_cpu(cpu, cpu_active_mask);\n}\n\nstatic inline bool cpu_dying(unsigned int cpu)\n{\n\treturn cpumask_test_cpu(cpu, cpu_dying_mask);\n}\n\n#else\n\n#define num_online_cpus()\t1U\n#define num_possible_cpus()\t1U\n#define num_present_cpus()\t1U\n#define num_active_cpus()\t1U\n\nstatic inline bool cpu_online(unsigned int cpu)\n{\n\treturn cpu == 0;\n}\n\nstatic inline bool cpu_possible(unsigned int cpu)\n{\n\treturn cpu == 0;\n}\n\nstatic inline bool cpu_present(unsigned int cpu)\n{\n\treturn cpu == 0;\n}\n\nstatic inline bool cpu_active(unsigned int cpu)\n{\n\treturn cpu == 0;\n}\n\nstatic inline bool cpu_dying(unsigned int cpu)\n{\n\treturn false;\n}\n\n#endif  \n\n#define cpu_is_offline(cpu)\tunlikely(!cpu_online(cpu))\n\n#if NR_CPUS <= BITS_PER_LONG\n#define CPU_BITS_ALL\t\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\\\n\t[BITS_TO_LONGS(NR_CPUS)-1] = BITMAP_LAST_WORD_MASK(NR_CPUS)\t\\\n}\n\n#else  \n\n#define CPU_BITS_ALL\t\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\\\n\t[0 ... BITS_TO_LONGS(NR_CPUS)-2] = ~0UL,\t\t\\\n\t[BITS_TO_LONGS(NR_CPUS)-1] = BITMAP_LAST_WORD_MASK(NR_CPUS)\t\\\n}\n#endif  \n\n \nstatic inline ssize_t\ncpumap_print_to_pagebuf(bool list, char *buf, const struct cpumask *mask)\n{\n\treturn bitmap_print_to_pagebuf(list, buf, cpumask_bits(mask),\n\t\t\t\t      nr_cpu_ids);\n}\n\n \nstatic inline ssize_t\ncpumap_print_bitmask_to_buf(char *buf, const struct cpumask *mask,\n\t\tloff_t off, size_t count)\n{\n\treturn bitmap_print_bitmask_to_buf(buf, cpumask_bits(mask),\n\t\t\t\t   nr_cpu_ids, off, count) - 1;\n}\n\n \nstatic inline ssize_t\ncpumap_print_list_to_buf(char *buf, const struct cpumask *mask,\n\t\tloff_t off, size_t count)\n{\n\treturn bitmap_print_list_to_buf(buf, cpumask_bits(mask),\n\t\t\t\t   nr_cpu_ids, off, count) - 1;\n}\n\n#if NR_CPUS <= BITS_PER_LONG\n#define CPU_MASK_ALL\t\t\t\t\t\t\t\\\n(cpumask_t) { {\t\t\t\t\t\t\t\t\\\n\t[BITS_TO_LONGS(NR_CPUS)-1] = BITMAP_LAST_WORD_MASK(NR_CPUS)\t\\\n} }\n#else\n#define CPU_MASK_ALL\t\t\t\t\t\t\t\\\n(cpumask_t) { {\t\t\t\t\t\t\t\t\\\n\t[0 ... BITS_TO_LONGS(NR_CPUS)-2] = ~0UL,\t\t\t\\\n\t[BITS_TO_LONGS(NR_CPUS)-1] = BITMAP_LAST_WORD_MASK(NR_CPUS)\t\\\n} }\n#endif  \n\n#define CPU_MASK_NONE\t\t\t\t\t\t\t\\\n(cpumask_t) { {\t\t\t\t\t\t\t\t\\\n\t[0 ... BITS_TO_LONGS(NR_CPUS)-1] =  0UL\t\t\t\t\\\n} }\n\n#define CPU_MASK_CPU0\t\t\t\t\t\t\t\\\n(cpumask_t) { {\t\t\t\t\t\t\t\t\\\n\t[0] =  1UL\t\t\t\t\t\t\t\\\n} }\n\n \n#define CPUMAP_FILE_MAX_BYTES  (((NR_CPUS * 9)/32 > PAGE_SIZE) \\\n\t\t\t\t\t? (NR_CPUS * 9)/32 - 1 : PAGE_SIZE)\n#define CPULIST_FILE_MAX_BYTES  (((NR_CPUS * 7)/2 > PAGE_SIZE) ? (NR_CPUS * 7)/2 : PAGE_SIZE)\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}