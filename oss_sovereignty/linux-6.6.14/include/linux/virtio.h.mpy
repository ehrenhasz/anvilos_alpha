{
  "module_name": "virtio.h",
  "hash_id": "d6962349411ef407760cabb498d54a799f4b34dce7c450182d32ff9bde7bf667",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/virtio.h",
  "human_readable_source": " \n#ifndef _LINUX_VIRTIO_H\n#define _LINUX_VIRTIO_H\n \n#include <linux/types.h>\n#include <linux/scatterlist.h>\n#include <linux/spinlock.h>\n#include <linux/device.h>\n#include <linux/mod_devicetable.h>\n#include <linux/gfp.h>\n#include <linux/dma-mapping.h>\n\n \nstruct virtqueue {\n\tstruct list_head list;\n\tvoid (*callback)(struct virtqueue *vq);\n\tconst char *name;\n\tstruct virtio_device *vdev;\n\tunsigned int index;\n\tunsigned int num_free;\n\tunsigned int num_max;\n\tbool reset;\n\tvoid *priv;\n};\n\nint virtqueue_add_outbuf(struct virtqueue *vq,\n\t\t\t struct scatterlist sg[], unsigned int num,\n\t\t\t void *data,\n\t\t\t gfp_t gfp);\n\nint virtqueue_add_inbuf(struct virtqueue *vq,\n\t\t\tstruct scatterlist sg[], unsigned int num,\n\t\t\tvoid *data,\n\t\t\tgfp_t gfp);\n\nint virtqueue_add_inbuf_ctx(struct virtqueue *vq,\n\t\t\t    struct scatterlist sg[], unsigned int num,\n\t\t\t    void *data,\n\t\t\t    void *ctx,\n\t\t\t    gfp_t gfp);\n\nint virtqueue_add_sgs(struct virtqueue *vq,\n\t\t      struct scatterlist *sgs[],\n\t\t      unsigned int out_sgs,\n\t\t      unsigned int in_sgs,\n\t\t      void *data,\n\t\t      gfp_t gfp);\n\nstruct device *virtqueue_dma_dev(struct virtqueue *vq);\n\nbool virtqueue_kick(struct virtqueue *vq);\n\nbool virtqueue_kick_prepare(struct virtqueue *vq);\n\nbool virtqueue_notify(struct virtqueue *vq);\n\nvoid *virtqueue_get_buf(struct virtqueue *vq, unsigned int *len);\n\nvoid *virtqueue_get_buf_ctx(struct virtqueue *vq, unsigned int *len,\n\t\t\t    void **ctx);\n\nvoid virtqueue_disable_cb(struct virtqueue *vq);\n\nbool virtqueue_enable_cb(struct virtqueue *vq);\n\nunsigned virtqueue_enable_cb_prepare(struct virtqueue *vq);\n\nint virtqueue_set_dma_premapped(struct virtqueue *_vq);\n\nbool virtqueue_poll(struct virtqueue *vq, unsigned);\n\nbool virtqueue_enable_cb_delayed(struct virtqueue *vq);\n\nvoid *virtqueue_detach_unused_buf(struct virtqueue *vq);\n\nunsigned int virtqueue_get_vring_size(const struct virtqueue *vq);\n\nbool virtqueue_is_broken(const struct virtqueue *vq);\n\nconst struct vring *virtqueue_get_vring(const struct virtqueue *vq);\ndma_addr_t virtqueue_get_desc_addr(const struct virtqueue *vq);\ndma_addr_t virtqueue_get_avail_addr(const struct virtqueue *vq);\ndma_addr_t virtqueue_get_used_addr(const struct virtqueue *vq);\n\nint virtqueue_resize(struct virtqueue *vq, u32 num,\n\t\t     void (*recycle)(struct virtqueue *vq, void *buf));\nint virtqueue_reset(struct virtqueue *vq,\n\t\t    void (*recycle)(struct virtqueue *vq, void *buf));\n\n \nstruct virtio_device {\n\tint index;\n\tbool failed;\n\tbool config_enabled;\n\tbool config_change_pending;\n\tspinlock_t config_lock;\n\tspinlock_t vqs_list_lock;\n\tstruct device dev;\n\tstruct virtio_device_id id;\n\tconst struct virtio_config_ops *config;\n\tconst struct vringh_config_ops *vringh_config;\n\tstruct list_head vqs;\n\tu64 features;\n\tvoid *priv;\n};\n\n#define dev_to_virtio(_dev)\tcontainer_of_const(_dev, struct virtio_device, dev)\n\nvoid virtio_add_status(struct virtio_device *dev, unsigned int status);\nint register_virtio_device(struct virtio_device *dev);\nvoid unregister_virtio_device(struct virtio_device *dev);\nbool is_virtio_device(struct device *dev);\n\nvoid virtio_break_device(struct virtio_device *dev);\nvoid __virtio_unbreak_device(struct virtio_device *dev);\n\nvoid __virtqueue_break(struct virtqueue *_vq);\nvoid __virtqueue_unbreak(struct virtqueue *_vq);\n\nvoid virtio_config_changed(struct virtio_device *dev);\n#ifdef CONFIG_PM_SLEEP\nint virtio_device_freeze(struct virtio_device *dev);\nint virtio_device_restore(struct virtio_device *dev);\n#endif\nvoid virtio_reset_device(struct virtio_device *dev);\n\nsize_t virtio_max_dma_size(const struct virtio_device *vdev);\n\n#define virtio_device_for_each_vq(vdev, vq) \\\n\tlist_for_each_entry(vq, &vdev->vqs, list)\n\n \nstruct virtio_driver {\n\tstruct device_driver driver;\n\tconst struct virtio_device_id *id_table;\n\tconst unsigned int *feature_table;\n\tunsigned int feature_table_size;\n\tconst unsigned int *feature_table_legacy;\n\tunsigned int feature_table_size_legacy;\n\tint (*validate)(struct virtio_device *dev);\n\tint (*probe)(struct virtio_device *dev);\n\tvoid (*scan)(struct virtio_device *dev);\n\tvoid (*remove)(struct virtio_device *dev);\n\tvoid (*config_changed)(struct virtio_device *dev);\n\tint (*freeze)(struct virtio_device *dev);\n\tint (*restore)(struct virtio_device *dev);\n};\n\nstatic inline struct virtio_driver *drv_to_virtio(struct device_driver *drv)\n{\n\treturn container_of(drv, struct virtio_driver, driver);\n}\n\nint register_virtio_driver(struct virtio_driver *drv);\nvoid unregister_virtio_driver(struct virtio_driver *drv);\n\n \n#define module_virtio_driver(__virtio_driver) \\\n\tmodule_driver(__virtio_driver, register_virtio_driver, \\\n\t\t\tunregister_virtio_driver)\n\ndma_addr_t virtqueue_dma_map_single_attrs(struct virtqueue *_vq, void *ptr, size_t size,\n\t\t\t\t\t  enum dma_data_direction dir, unsigned long attrs);\nvoid virtqueue_dma_unmap_single_attrs(struct virtqueue *_vq, dma_addr_t addr,\n\t\t\t\t      size_t size, enum dma_data_direction dir,\n\t\t\t\t      unsigned long attrs);\nint virtqueue_dma_mapping_error(struct virtqueue *_vq, dma_addr_t addr);\n\nbool virtqueue_dma_need_sync(struct virtqueue *_vq, dma_addr_t addr);\nvoid virtqueue_dma_sync_single_range_for_cpu(struct virtqueue *_vq, dma_addr_t addr,\n\t\t\t\t\t     unsigned long offset, size_t size,\n\t\t\t\t\t     enum dma_data_direction dir);\nvoid virtqueue_dma_sync_single_range_for_device(struct virtqueue *_vq, dma_addr_t addr,\n\t\t\t\t\t\tunsigned long offset, size_t size,\n\t\t\t\t\t\tenum dma_data_direction dir);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}