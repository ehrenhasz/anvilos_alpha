{
  "module_name": "dma-direct.h",
  "hash_id": "b1178fc169bc3a66095450eb596034e4dc4c5173831d6e28e560405f510397ff",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/dma-direct.h",
  "human_readable_source": " \n \n#ifndef _LINUX_DMA_DIRECT_H\n#define _LINUX_DMA_DIRECT_H 1\n\n#include <linux/dma-mapping.h>\n#include <linux/dma-map-ops.h>\n#include <linux/memblock.h>  \n#include <linux/mem_encrypt.h>\n#include <linux/swiotlb.h>\n\nextern unsigned int zone_dma_bits;\n\n \nstruct bus_dma_region {\n\tphys_addr_t\tcpu_start;\n\tdma_addr_t\tdma_start;\n\tu64\t\tsize;\n\tu64\t\toffset;\n};\n\nstatic inline dma_addr_t translate_phys_to_dma(struct device *dev,\n\t\tphys_addr_t paddr)\n{\n\tconst struct bus_dma_region *m;\n\n\tfor (m = dev->dma_range_map; m->size; m++)\n\t\tif (paddr >= m->cpu_start && paddr - m->cpu_start < m->size)\n\t\t\treturn (dma_addr_t)paddr - m->offset;\n\n\t \n\treturn DMA_MAPPING_ERROR;\n}\n\nstatic inline phys_addr_t translate_dma_to_phys(struct device *dev,\n\t\tdma_addr_t dma_addr)\n{\n\tconst struct bus_dma_region *m;\n\n\tfor (m = dev->dma_range_map; m->size; m++)\n\t\tif (dma_addr >= m->dma_start && dma_addr - m->dma_start < m->size)\n\t\t\treturn (phys_addr_t)dma_addr + m->offset;\n\n\treturn (phys_addr_t)-1;\n}\n\n#ifdef CONFIG_ARCH_HAS_PHYS_TO_DMA\n#include <asm/dma-direct.h>\n#ifndef phys_to_dma_unencrypted\n#define phys_to_dma_unencrypted\t\tphys_to_dma\n#endif\n#else\nstatic inline dma_addr_t phys_to_dma_unencrypted(struct device *dev,\n\t\tphys_addr_t paddr)\n{\n\tif (dev->dma_range_map)\n\t\treturn translate_phys_to_dma(dev, paddr);\n\treturn paddr;\n}\n\n \nstatic inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)\n{\n\treturn __sme_set(phys_to_dma_unencrypted(dev, paddr));\n}\n\nstatic inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t dma_addr)\n{\n\tphys_addr_t paddr;\n\n\tif (dev->dma_range_map)\n\t\tpaddr = translate_dma_to_phys(dev, dma_addr);\n\telse\n\t\tpaddr = dma_addr;\n\n\treturn __sme_clr(paddr);\n}\n#endif  \n\n#ifdef CONFIG_ARCH_HAS_FORCE_DMA_UNENCRYPTED\nbool force_dma_unencrypted(struct device *dev);\n#else\nstatic inline bool force_dma_unencrypted(struct device *dev)\n{\n\treturn false;\n}\n#endif  \n\nstatic inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size,\n\t\tbool is_ram)\n{\n\tdma_addr_t end = addr + size - 1;\n\n\tif (addr == DMA_MAPPING_ERROR)\n\t\treturn false;\n\tif (is_ram && !IS_ENABLED(CONFIG_ARCH_DMA_ADDR_T_64BIT) &&\n\t    min(addr, end) < phys_to_dma(dev, PFN_PHYS(min_low_pfn)))\n\t\treturn false;\n\n\treturn end <= min_not_zero(*dev->dma_mask, dev->bus_dma_limit);\n}\n\nu64 dma_direct_get_required_mask(struct device *dev);\nvoid *dma_direct_alloc(struct device *dev, size_t size, dma_addr_t *dma_handle,\n\t\tgfp_t gfp, unsigned long attrs);\nvoid dma_direct_free(struct device *dev, size_t size, void *cpu_addr,\n\t\tdma_addr_t dma_addr, unsigned long attrs);\nstruct page *dma_direct_alloc_pages(struct device *dev, size_t size,\n\t\tdma_addr_t *dma_handle, enum dma_data_direction dir, gfp_t gfp);\nvoid dma_direct_free_pages(struct device *dev, size_t size,\n\t\tstruct page *page, dma_addr_t dma_addr,\n\t\tenum dma_data_direction dir);\nint dma_direct_supported(struct device *dev, u64 mask);\ndma_addr_t dma_direct_map_resource(struct device *dev, phys_addr_t paddr,\n\t\tsize_t size, enum dma_data_direction dir, unsigned long attrs);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}