{
  "module_name": "ftrace.h",
  "hash_id": "b2b131b8643a03662243f7e0c57438180aa4f8d2eeac94e0916505255f4be331",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/ftrace.h",
  "human_readable_source": " \n \n\n#ifndef _LINUX_FTRACE_H\n#define _LINUX_FTRACE_H\n\n#include <linux/trace_recursion.h>\n#include <linux/trace_clock.h>\n#include <linux/jump_label.h>\n#include <linux/kallsyms.h>\n#include <linux/linkage.h>\n#include <linux/bitops.h>\n#include <linux/ptrace.h>\n#include <linux/ktime.h>\n#include <linux/sched.h>\n#include <linux/types.h>\n#include <linux/init.h>\n#include <linux/fs.h>\n\n#include <asm/ftrace.h>\n\n \n#ifndef ARCH_SUPPORTS_FTRACE_OPS\n#define ARCH_SUPPORTS_FTRACE_OPS 0\n#endif\n\n#ifdef CONFIG_TRACING\nextern void ftrace_boot_snapshot(void);\n#else\nstatic inline void ftrace_boot_snapshot(void) { }\n#endif\n\nstruct ftrace_ops;\nstruct ftrace_regs;\nstruct dyn_ftrace;\n\nchar *arch_ftrace_match_adjust(char *str, const char *search);\n\n#ifdef CONFIG_HAVE_FUNCTION_GRAPH_RETVAL\nstruct fgraph_ret_regs;\nunsigned long ftrace_return_to_handler(struct fgraph_ret_regs *ret_regs);\n#else\nunsigned long ftrace_return_to_handler(unsigned long frame_pointer);\n#endif\n\n#ifdef CONFIG_FUNCTION_TRACER\n \n#if !ARCH_SUPPORTS_FTRACE_OPS\n# define FTRACE_FORCE_LIST_FUNC 1\nvoid arch_ftrace_ops_list_func(unsigned long ip, unsigned long parent_ip);\n#else\n# define FTRACE_FORCE_LIST_FUNC 0\nvoid arch_ftrace_ops_list_func(unsigned long ip, unsigned long parent_ip,\n\t\t\t       struct ftrace_ops *op, struct ftrace_regs *fregs);\n#endif\nextern const struct ftrace_ops ftrace_nop_ops;\nextern const struct ftrace_ops ftrace_list_ops;\nstruct ftrace_ops *ftrace_find_unique_ops(struct dyn_ftrace *rec);\n#endif  \n\n \n#ifdef CONFIG_TRACING\nvoid trace_init(void);\nvoid early_trace_init(void);\n#else\nstatic inline void trace_init(void) { }\nstatic inline void early_trace_init(void) { }\n#endif\n\nstruct module;\nstruct ftrace_hash;\nstruct ftrace_direct_func;\n\n#if defined(CONFIG_FUNCTION_TRACER) && defined(CONFIG_MODULES) && \\\n\tdefined(CONFIG_DYNAMIC_FTRACE)\nconst char *\nftrace_mod_address_lookup(unsigned long addr, unsigned long *size,\n\t\t   unsigned long *off, char **modname, char *sym);\n#else\nstatic inline const char *\nftrace_mod_address_lookup(unsigned long addr, unsigned long *size,\n\t\t   unsigned long *off, char **modname, char *sym)\n{\n\treturn NULL;\n}\n#endif\n\n#if defined(CONFIG_FUNCTION_TRACER) && defined(CONFIG_DYNAMIC_FTRACE)\nint ftrace_mod_get_kallsym(unsigned int symnum, unsigned long *value,\n\t\t\t   char *type, char *name,\n\t\t\t   char *module_name, int *exported);\n#else\nstatic inline int ftrace_mod_get_kallsym(unsigned int symnum, unsigned long *value,\n\t\t\t\t\t char *type, char *name,\n\t\t\t\t\t char *module_name, int *exported)\n{\n\treturn -1;\n}\n#endif\n\n#ifdef CONFIG_FUNCTION_TRACER\n\nextern int ftrace_enabled;\n\n#ifndef CONFIG_HAVE_DYNAMIC_FTRACE_WITH_ARGS\n\nstruct ftrace_regs {\n\tstruct pt_regs\t\tregs;\n};\n#define arch_ftrace_get_regs(fregs) (&(fregs)->regs)\n\n \n#define ftrace_regs_set_instruction_pointer(fregs, ip) do { } while (0)\n#endif  \n\nstatic __always_inline struct pt_regs *ftrace_get_regs(struct ftrace_regs *fregs)\n{\n\tif (!fregs)\n\t\treturn NULL;\n\n\treturn arch_ftrace_get_regs(fregs);\n}\n\n \nstatic __always_inline bool ftrace_regs_has_args(struct ftrace_regs *fregs)\n{\n\tif (IS_ENABLED(CONFIG_HAVE_DYNAMIC_FTRACE_WITH_ARGS))\n\t\treturn true;\n\n\treturn ftrace_get_regs(fregs) != NULL;\n}\n\n#ifndef CONFIG_HAVE_DYNAMIC_FTRACE_WITH_ARGS\n#define ftrace_regs_get_instruction_pointer(fregs) \\\n\tinstruction_pointer(ftrace_get_regs(fregs))\n#define ftrace_regs_get_argument(fregs, n) \\\n\tregs_get_kernel_argument(ftrace_get_regs(fregs), n)\n#define ftrace_regs_get_stack_pointer(fregs) \\\n\tkernel_stack_pointer(ftrace_get_regs(fregs))\n#define ftrace_regs_return_value(fregs) \\\n\tregs_return_value(ftrace_get_regs(fregs))\n#define ftrace_regs_set_return_value(fregs, ret) \\\n\tregs_set_return_value(ftrace_get_regs(fregs), ret)\n#define ftrace_override_function_with_return(fregs) \\\n\toverride_function_with_return(ftrace_get_regs(fregs))\n#define ftrace_regs_query_register_offset(name) \\\n\tregs_query_register_offset(name)\n#endif\n\ntypedef void (*ftrace_func_t)(unsigned long ip, unsigned long parent_ip,\n\t\t\t      struct ftrace_ops *op, struct ftrace_regs *fregs);\n\nftrace_func_t ftrace_ops_get_func(struct ftrace_ops *ops);\n\n \nenum {\n\tFTRACE_OPS_FL_ENABLED\t\t\t= BIT(0),\n\tFTRACE_OPS_FL_DYNAMIC\t\t\t= BIT(1),\n\tFTRACE_OPS_FL_SAVE_REGS\t\t\t= BIT(2),\n\tFTRACE_OPS_FL_SAVE_REGS_IF_SUPPORTED\t= BIT(3),\n\tFTRACE_OPS_FL_RECURSION\t\t\t= BIT(4),\n\tFTRACE_OPS_FL_STUB\t\t\t= BIT(5),\n\tFTRACE_OPS_FL_INITIALIZED\t\t= BIT(6),\n\tFTRACE_OPS_FL_DELETED\t\t\t= BIT(7),\n\tFTRACE_OPS_FL_ADDING\t\t\t= BIT(8),\n\tFTRACE_OPS_FL_REMOVING\t\t\t= BIT(9),\n\tFTRACE_OPS_FL_MODIFYING\t\t\t= BIT(10),\n\tFTRACE_OPS_FL_ALLOC_TRAMP\t\t= BIT(11),\n\tFTRACE_OPS_FL_IPMODIFY\t\t\t= BIT(12),\n\tFTRACE_OPS_FL_PID\t\t\t= BIT(13),\n\tFTRACE_OPS_FL_RCU\t\t\t= BIT(14),\n\tFTRACE_OPS_FL_TRACE_ARRAY\t\t= BIT(15),\n\tFTRACE_OPS_FL_PERMANENT                 = BIT(16),\n\tFTRACE_OPS_FL_DIRECT\t\t\t= BIT(17),\n};\n\n#ifndef CONFIG_DYNAMIC_FTRACE_WITH_ARGS\n#define FTRACE_OPS_FL_SAVE_ARGS                        FTRACE_OPS_FL_SAVE_REGS\n#else\n#define FTRACE_OPS_FL_SAVE_ARGS                        0\n#endif\n\n \nenum ftrace_ops_cmd {\n\tFTRACE_OPS_CMD_ENABLE_SHARE_IPMODIFY_SELF,\n\tFTRACE_OPS_CMD_ENABLE_SHARE_IPMODIFY_PEER,\n\tFTRACE_OPS_CMD_DISABLE_SHARE_IPMODIFY_PEER,\n};\n\n \ntypedef int (*ftrace_ops_func_t)(struct ftrace_ops *op, enum ftrace_ops_cmd cmd);\n\n#ifdef CONFIG_DYNAMIC_FTRACE\n \nstruct ftrace_ops_hash {\n\tstruct ftrace_hash __rcu\t*notrace_hash;\n\tstruct ftrace_hash __rcu\t*filter_hash;\n\tstruct mutex\t\t\tregex_lock;\n};\n\nvoid ftrace_free_init_mem(void);\nvoid ftrace_free_mem(struct module *mod, void *start, void *end);\n#else\nstatic inline void ftrace_free_init_mem(void)\n{\n\tftrace_boot_snapshot();\n}\nstatic inline void ftrace_free_mem(struct module *mod, void *start, void *end) { }\n#endif\n\n \nstruct ftrace_ops {\n\tftrace_func_t\t\t\tfunc;\n\tstruct ftrace_ops __rcu\t\t*next;\n\tunsigned long\t\t\tflags;\n\tvoid\t\t\t\t*private;\n\tftrace_func_t\t\t\tsaved_func;\n#ifdef CONFIG_DYNAMIC_FTRACE\n\tstruct ftrace_ops_hash\t\tlocal_hash;\n\tstruct ftrace_ops_hash\t\t*func_hash;\n\tstruct ftrace_ops_hash\t\told_hash;\n\tunsigned long\t\t\ttrampoline;\n\tunsigned long\t\t\ttrampoline_size;\n\tstruct list_head\t\tlist;\n\tftrace_ops_func_t\t\tops_func;\n#ifdef CONFIG_DYNAMIC_FTRACE_WITH_DIRECT_CALLS\n\tunsigned long\t\t\tdirect_call;\n#endif\n#endif\n};\n\nextern struct ftrace_ops __rcu *ftrace_ops_list;\nextern struct ftrace_ops ftrace_list_end;\n\n \n#define do_for_each_ftrace_op(op, list)\t\t\t\\\n\top = rcu_dereference_raw_check(list);\t\t\t\\\n\tdo\n\n \n#define while_for_each_ftrace_op(op)\t\t\t\t\\\n\twhile (likely(op = rcu_dereference_raw_check((op)->next)) &&\t\\\n\t       unlikely((op) != &ftrace_list_end))\n\n \nenum ftrace_tracing_type_t {\n\tFTRACE_TYPE_ENTER = 0,  \n\tFTRACE_TYPE_RETURN,\t \n};\n\n \nextern enum ftrace_tracing_type_t ftrace_tracing_type;\n\n \nint register_ftrace_function(struct ftrace_ops *ops);\nint unregister_ftrace_function(struct ftrace_ops *ops);\n\nextern void ftrace_stub(unsigned long a0, unsigned long a1,\n\t\t\tstruct ftrace_ops *op, struct ftrace_regs *fregs);\n\n\nint ftrace_lookup_symbols(const char **sorted_syms, size_t cnt, unsigned long *addrs);\n#else  \n \n#define register_ftrace_function(ops) ({ 0; })\n#define unregister_ftrace_function(ops) ({ 0; })\nstatic inline void ftrace_kill(void) { }\nstatic inline void ftrace_free_init_mem(void) { }\nstatic inline void ftrace_free_mem(struct module *mod, void *start, void *end) { }\nstatic inline int ftrace_lookup_symbols(const char **sorted_syms, size_t cnt, unsigned long *addrs)\n{\n\treturn -EOPNOTSUPP;\n}\n#endif  \n\nstruct ftrace_func_entry {\n\tstruct hlist_node hlist;\n\tunsigned long ip;\n\tunsigned long direct;  \n};\n\n#ifdef CONFIG_DYNAMIC_FTRACE_WITH_DIRECT_CALLS\nextern int ftrace_direct_func_count;\nunsigned long ftrace_find_rec_direct(unsigned long ip);\nint register_ftrace_direct(struct ftrace_ops *ops, unsigned long addr);\nint unregister_ftrace_direct(struct ftrace_ops *ops, unsigned long addr,\n\t\t\t     bool free_filters);\nint modify_ftrace_direct(struct ftrace_ops *ops, unsigned long addr);\nint modify_ftrace_direct_nolock(struct ftrace_ops *ops, unsigned long addr);\n\nvoid ftrace_stub_direct_tramp(void);\n\n#else\nstruct ftrace_ops;\n# define ftrace_direct_func_count 0\nstatic inline unsigned long ftrace_find_rec_direct(unsigned long ip)\n{\n\treturn 0;\n}\nstatic inline int register_ftrace_direct(struct ftrace_ops *ops, unsigned long addr)\n{\n\treturn -ENODEV;\n}\nstatic inline int unregister_ftrace_direct(struct ftrace_ops *ops, unsigned long addr,\n\t\t\t\t\t   bool free_filters)\n{\n\treturn -ENODEV;\n}\nstatic inline int modify_ftrace_direct(struct ftrace_ops *ops, unsigned long addr)\n{\n\treturn -ENODEV;\n}\nstatic inline int modify_ftrace_direct_nolock(struct ftrace_ops *ops, unsigned long addr)\n{\n\treturn -ENODEV;\n}\n\n \nstatic inline void arch_ftrace_set_direct_caller(struct ftrace_regs *fregs,\n\t\t\t\t\t\t unsigned long addr) { }\n#endif  \n\n#ifdef CONFIG_STACK_TRACER\n\nextern int stack_tracer_enabled;\n\nint stack_trace_sysctl(struct ctl_table *table, int write, void *buffer,\n\t\t       size_t *lenp, loff_t *ppos);\n\n \nDECLARE_PER_CPU(int, disable_stack_tracer);\n\n \nstatic inline void stack_tracer_disable(void)\n{\n\t \n\tif (IS_ENABLED(CONFIG_DEBUG_PREEMPT))\n\t\tWARN_ON_ONCE(!preempt_count() || !irqs_disabled());\n\tthis_cpu_inc(disable_stack_tracer);\n}\n\n \nstatic inline void stack_tracer_enable(void)\n{\n\tif (IS_ENABLED(CONFIG_DEBUG_PREEMPT))\n\t\tWARN_ON_ONCE(!preempt_count() || !irqs_disabled());\n\tthis_cpu_dec(disable_stack_tracer);\n}\n#else\nstatic inline void stack_tracer_disable(void) { }\nstatic inline void stack_tracer_enable(void) { }\n#endif\n\n#ifdef CONFIG_DYNAMIC_FTRACE\n\nvoid ftrace_arch_code_modify_prepare(void);\nvoid ftrace_arch_code_modify_post_process(void);\n\nenum ftrace_bug_type {\n\tFTRACE_BUG_UNKNOWN,\n\tFTRACE_BUG_INIT,\n\tFTRACE_BUG_NOP,\n\tFTRACE_BUG_CALL,\n\tFTRACE_BUG_UPDATE,\n};\nextern enum ftrace_bug_type ftrace_bug_type;\n\n \nextern const void *ftrace_expected;\n\nvoid ftrace_bug(int err, struct dyn_ftrace *rec);\n\nstruct seq_file;\n\nextern int ftrace_text_reserved(const void *start, const void *end);\n\nstruct ftrace_ops *ftrace_ops_trampoline(unsigned long addr);\n\nbool is_ftrace_trampoline(unsigned long addr);\n\n \nenum {\n\tFTRACE_FL_ENABLED\t= (1UL << 31),\n\tFTRACE_FL_REGS\t\t= (1UL << 30),\n\tFTRACE_FL_REGS_EN\t= (1UL << 29),\n\tFTRACE_FL_TRAMP\t\t= (1UL << 28),\n\tFTRACE_FL_TRAMP_EN\t= (1UL << 27),\n\tFTRACE_FL_IPMODIFY\t= (1UL << 26),\n\tFTRACE_FL_DISABLED\t= (1UL << 25),\n\tFTRACE_FL_DIRECT\t= (1UL << 24),\n\tFTRACE_FL_DIRECT_EN\t= (1UL << 23),\n\tFTRACE_FL_CALL_OPS\t= (1UL << 22),\n\tFTRACE_FL_CALL_OPS_EN\t= (1UL << 21),\n\tFTRACE_FL_TOUCHED\t= (1UL << 20),\n\tFTRACE_FL_MODIFIED\t= (1UL << 19),\n};\n\n#define FTRACE_REF_MAX_SHIFT\t19\n#define FTRACE_REF_MAX\t\t((1UL << FTRACE_REF_MAX_SHIFT) - 1)\n\n#define ftrace_rec_count(rec)\t((rec)->flags & FTRACE_REF_MAX)\n\nstruct dyn_ftrace {\n\tunsigned long\t\tip;  \n\tunsigned long\t\tflags;\n\tstruct dyn_arch_ftrace\tarch;\n};\n\nint ftrace_set_filter_ip(struct ftrace_ops *ops, unsigned long ip,\n\t\t\t int remove, int reset);\nint ftrace_set_filter_ips(struct ftrace_ops *ops, unsigned long *ips,\n\t\t\t  unsigned int cnt, int remove, int reset);\nint ftrace_set_filter(struct ftrace_ops *ops, unsigned char *buf,\n\t\t       int len, int reset);\nint ftrace_set_notrace(struct ftrace_ops *ops, unsigned char *buf,\n\t\t\tint len, int reset);\nvoid ftrace_set_global_filter(unsigned char *buf, int len, int reset);\nvoid ftrace_set_global_notrace(unsigned char *buf, int len, int reset);\nvoid ftrace_free_filter(struct ftrace_ops *ops);\nvoid ftrace_ops_set_global_filter(struct ftrace_ops *ops);\n\nenum {\n\tFTRACE_UPDATE_CALLS\t\t= (1 << 0),\n\tFTRACE_DISABLE_CALLS\t\t= (1 << 1),\n\tFTRACE_UPDATE_TRACE_FUNC\t= (1 << 2),\n\tFTRACE_START_FUNC_RET\t\t= (1 << 3),\n\tFTRACE_STOP_FUNC_RET\t\t= (1 << 4),\n\tFTRACE_MAY_SLEEP\t\t= (1 << 5),\n};\n\n \nenum {\n\tFTRACE_UPDATE_IGNORE,\n\tFTRACE_UPDATE_MAKE_CALL,\n\tFTRACE_UPDATE_MODIFY_CALL,\n\tFTRACE_UPDATE_MAKE_NOP,\n};\n\nenum {\n\tFTRACE_ITER_FILTER\t= (1 << 0),\n\tFTRACE_ITER_NOTRACE\t= (1 << 1),\n\tFTRACE_ITER_PRINTALL\t= (1 << 2),\n\tFTRACE_ITER_DO_PROBES\t= (1 << 3),\n\tFTRACE_ITER_PROBE\t= (1 << 4),\n\tFTRACE_ITER_MOD\t\t= (1 << 5),\n\tFTRACE_ITER_ENABLED\t= (1 << 6),\n\tFTRACE_ITER_TOUCHED\t= (1 << 7),\n\tFTRACE_ITER_ADDRS\t= (1 << 8),\n};\n\nvoid arch_ftrace_update_code(int command);\nvoid arch_ftrace_update_trampoline(struct ftrace_ops *ops);\nvoid *arch_ftrace_trampoline_func(struct ftrace_ops *ops, struct dyn_ftrace *rec);\nvoid arch_ftrace_trampoline_free(struct ftrace_ops *ops);\n\nstruct ftrace_rec_iter;\n\nstruct ftrace_rec_iter *ftrace_rec_iter_start(void);\nstruct ftrace_rec_iter *ftrace_rec_iter_next(struct ftrace_rec_iter *iter);\nstruct dyn_ftrace *ftrace_rec_iter_record(struct ftrace_rec_iter *iter);\n\n#define for_ftrace_rec_iter(iter)\t\t\\\n\tfor (iter = ftrace_rec_iter_start();\t\\\n\t     iter;\t\t\t\t\\\n\t     iter = ftrace_rec_iter_next(iter))\n\n\nint ftrace_update_record(struct dyn_ftrace *rec, bool enable);\nint ftrace_test_record(struct dyn_ftrace *rec, bool enable);\nvoid ftrace_run_stop_machine(int command);\nunsigned long ftrace_location(unsigned long ip);\nunsigned long ftrace_location_range(unsigned long start, unsigned long end);\nunsigned long ftrace_get_addr_new(struct dyn_ftrace *rec);\nunsigned long ftrace_get_addr_curr(struct dyn_ftrace *rec);\n\nextern ftrace_func_t ftrace_trace_function;\n\nint ftrace_regex_open(struct ftrace_ops *ops, int flag,\n\t\t  struct inode *inode, struct file *file);\nssize_t ftrace_filter_write(struct file *file, const char __user *ubuf,\n\t\t\t    size_t cnt, loff_t *ppos);\nssize_t ftrace_notrace_write(struct file *file, const char __user *ubuf,\n\t\t\t     size_t cnt, loff_t *ppos);\nint ftrace_regex_release(struct inode *inode, struct file *file);\n\nvoid __init\nftrace_set_early_filter(struct ftrace_ops *ops, char *buf, int enable);\n\n \nextern int ftrace_dyn_arch_init(void);\nextern void ftrace_replace_code(int enable);\nextern int ftrace_update_ftrace_func(ftrace_func_t func);\nextern void ftrace_caller(void);\nextern void ftrace_regs_caller(void);\nextern void ftrace_call(void);\nextern void ftrace_regs_call(void);\nextern void mcount_call(void);\n\nvoid ftrace_modify_all_code(int command);\n\n#ifndef FTRACE_ADDR\n#define FTRACE_ADDR ((unsigned long)ftrace_caller)\n#endif\n\n#ifndef FTRACE_GRAPH_ADDR\n#define FTRACE_GRAPH_ADDR ((unsigned long)ftrace_graph_caller)\n#endif\n\n#ifndef FTRACE_REGS_ADDR\n#ifdef CONFIG_DYNAMIC_FTRACE_WITH_REGS\n# define FTRACE_REGS_ADDR ((unsigned long)ftrace_regs_caller)\n#else\n# define FTRACE_REGS_ADDR FTRACE_ADDR\n#endif\n#endif\n\n \n#ifndef FTRACE_GRAPH_TRAMP_ADDR\n#define FTRACE_GRAPH_TRAMP_ADDR ((unsigned long) 0)\n#endif\n\n#ifdef CONFIG_FUNCTION_GRAPH_TRACER\nextern void ftrace_graph_caller(void);\nextern int ftrace_enable_ftrace_graph_caller(void);\nextern int ftrace_disable_ftrace_graph_caller(void);\n#else\nstatic inline int ftrace_enable_ftrace_graph_caller(void) { return 0; }\nstatic inline int ftrace_disable_ftrace_graph_caller(void) { return 0; }\n#endif\n\n \nextern int ftrace_make_nop(struct module *mod,\n\t\t\t   struct dyn_ftrace *rec, unsigned long addr);\n\n \n\n#ifndef ftrace_need_init_nop\n#define ftrace_need_init_nop() (!__is_defined(CC_USING_NOP_MCOUNT))\n#endif\n\n \n#ifndef ftrace_init_nop\nstatic inline int ftrace_init_nop(struct module *mod, struct dyn_ftrace *rec)\n{\n\treturn ftrace_make_nop(mod, rec, MCOUNT_ADDR);\n}\n#endif\n\n \nextern int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr);\n\n#if defined(CONFIG_DYNAMIC_FTRACE_WITH_REGS) || \\\n\tdefined(CONFIG_DYNAMIC_FTRACE_WITH_CALL_OPS)\n \nextern int ftrace_modify_call(struct dyn_ftrace *rec, unsigned long old_addr,\n\t\t\t      unsigned long addr);\n#else\n \nstatic inline int ftrace_modify_call(struct dyn_ftrace *rec, unsigned long old_addr,\n\t\t\t\t     unsigned long addr)\n{\n\treturn -EINVAL;\n}\n#endif\n\nextern int skip_trace(unsigned long ip);\nextern void ftrace_module_init(struct module *mod);\nextern void ftrace_module_enable(struct module *mod);\nextern void ftrace_release_mod(struct module *mod);\n#else  \nstatic inline int skip_trace(unsigned long ip) { return 0; }\nstatic inline void ftrace_module_init(struct module *mod) { }\nstatic inline void ftrace_module_enable(struct module *mod) { }\nstatic inline void ftrace_release_mod(struct module *mod) { }\nstatic inline int ftrace_text_reserved(const void *start, const void *end)\n{\n\treturn 0;\n}\nstatic inline unsigned long ftrace_location(unsigned long ip)\n{\n\treturn 0;\n}\n\n \n#define ftrace_regex_open(ops, flag, inod, file) ({ -ENODEV; })\n#define ftrace_set_early_filter(ops, buf, enable) do { } while (0)\n#define ftrace_set_filter_ip(ops, ip, remove, reset) ({ -ENODEV; })\n#define ftrace_set_filter_ips(ops, ips, cnt, remove, reset) ({ -ENODEV; })\n#define ftrace_set_filter(ops, buf, len, reset) ({ -ENODEV; })\n#define ftrace_set_notrace(ops, buf, len, reset) ({ -ENODEV; })\n#define ftrace_free_filter(ops) do { } while (0)\n#define ftrace_ops_set_global_filter(ops) do { } while (0)\n\nstatic inline ssize_t ftrace_filter_write(struct file *file, const char __user *ubuf,\n\t\t\t    size_t cnt, loff_t *ppos) { return -ENODEV; }\nstatic inline ssize_t ftrace_notrace_write(struct file *file, const char __user *ubuf,\n\t\t\t     size_t cnt, loff_t *ppos) { return -ENODEV; }\nstatic inline int\nftrace_regex_release(struct inode *inode, struct file *file) { return -ENODEV; }\n\nstatic inline bool is_ftrace_trampoline(unsigned long addr)\n{\n\treturn false;\n}\n#endif  \n\n#ifdef CONFIG_FUNCTION_GRAPH_TRACER\n#ifndef ftrace_graph_func\n#define ftrace_graph_func ftrace_stub\n#define FTRACE_OPS_GRAPH_STUB FTRACE_OPS_FL_STUB\n#else\n#define FTRACE_OPS_GRAPH_STUB 0\n#endif\n#endif  \n\n \nvoid ftrace_kill(void);\n\nstatic inline void tracer_disable(void)\n{\n#ifdef CONFIG_FUNCTION_TRACER\n\tftrace_enabled = 0;\n#endif\n}\n\n \nstatic inline int __ftrace_enabled_save(void)\n{\n#ifdef CONFIG_FUNCTION_TRACER\n\tint saved_ftrace_enabled = ftrace_enabled;\n\tftrace_enabled = 0;\n\treturn saved_ftrace_enabled;\n#else\n\treturn 0;\n#endif\n}\n\nstatic inline void __ftrace_enabled_restore(int enabled)\n{\n#ifdef CONFIG_FUNCTION_TRACER\n\tftrace_enabled = enabled;\n#endif\n}\n\n \n#ifndef ftrace_return_address0\n# define ftrace_return_address0 __builtin_return_address(0)\n#endif\n\n \n#ifndef ftrace_return_address\n# ifdef CONFIG_FRAME_POINTER\n#  define ftrace_return_address(n) __builtin_return_address(n)\n# else\n#  define ftrace_return_address(n) 0UL\n# endif\n#endif\n\n#define CALLER_ADDR0 ((unsigned long)ftrace_return_address0)\n#define CALLER_ADDR1 ((unsigned long)ftrace_return_address(1))\n#define CALLER_ADDR2 ((unsigned long)ftrace_return_address(2))\n#define CALLER_ADDR3 ((unsigned long)ftrace_return_address(3))\n#define CALLER_ADDR4 ((unsigned long)ftrace_return_address(4))\n#define CALLER_ADDR5 ((unsigned long)ftrace_return_address(5))\n#define CALLER_ADDR6 ((unsigned long)ftrace_return_address(6))\n\nstatic __always_inline unsigned long get_lock_parent_ip(void)\n{\n\tunsigned long addr = CALLER_ADDR0;\n\n\tif (!in_lock_functions(addr))\n\t\treturn addr;\n\taddr = CALLER_ADDR1;\n\tif (!in_lock_functions(addr))\n\t\treturn addr;\n\treturn CALLER_ADDR2;\n}\n\n#ifdef CONFIG_TRACE_PREEMPT_TOGGLE\n  extern void trace_preempt_on(unsigned long a0, unsigned long a1);\n  extern void trace_preempt_off(unsigned long a0, unsigned long a1);\n#else\n \n# define trace_preempt_on(a0, a1) do { } while (0)\n# define trace_preempt_off(a0, a1) do { } while (0)\n#endif\n\n#ifdef CONFIG_FTRACE_MCOUNT_RECORD\nextern void ftrace_init(void);\n#ifdef CC_USING_PATCHABLE_FUNCTION_ENTRY\n#define FTRACE_CALLSITE_SECTION\t\"__patchable_function_entries\"\n#else\n#define FTRACE_CALLSITE_SECTION\t\"__mcount_loc\"\n#endif\n#else\nstatic inline void ftrace_init(void) { }\n#endif\n\n \nstruct ftrace_graph_ent {\n\tunsigned long func;  \n\tint depth;\n} __packed;\n\n \nstruct ftrace_graph_ret {\n\tunsigned long func;  \n#ifdef CONFIG_FUNCTION_GRAPH_RETVAL\n\tunsigned long retval;\n#endif\n\tint depth;\n\t \n\tunsigned int overrun;\n\tunsigned long long calltime;\n\tunsigned long long rettime;\n} __packed;\n\n \ntypedef void (*trace_func_graph_ret_t)(struct ftrace_graph_ret *);  \ntypedef int (*trace_func_graph_ent_t)(struct ftrace_graph_ent *);  \n\nextern int ftrace_graph_entry_stub(struct ftrace_graph_ent *trace);\n\n#ifdef CONFIG_FUNCTION_GRAPH_TRACER\n\nstruct fgraph_ops {\n\ttrace_func_graph_ent_t\t\tentryfunc;\n\ttrace_func_graph_ret_t\t\tretfunc;\n};\n\n \nstruct ftrace_ret_stack {\n\tunsigned long ret;\n\tunsigned long func;\n\tunsigned long long calltime;\n#ifdef CONFIG_FUNCTION_PROFILER\n\tunsigned long long subtime;\n#endif\n#ifdef HAVE_FUNCTION_GRAPH_FP_TEST\n\tunsigned long fp;\n#endif\n#ifdef HAVE_FUNCTION_GRAPH_RET_ADDR_PTR\n\tunsigned long *retp;\n#endif\n};\n\n \nextern void return_to_handler(void);\n\nextern int\nfunction_graph_enter(unsigned long ret, unsigned long func,\n\t\t     unsigned long frame_pointer, unsigned long *retp);\n\nstruct ftrace_ret_stack *\nftrace_graph_get_ret_stack(struct task_struct *task, int idx);\n\nunsigned long ftrace_graph_ret_addr(struct task_struct *task, int *idx,\n\t\t\t\t    unsigned long ret, unsigned long *retp);\n\n \n#define __notrace_funcgraph\t\tnotrace\n\n#define FTRACE_RETFUNC_DEPTH 50\n#define FTRACE_RETSTACK_ALLOC_SIZE 32\n\nextern int register_ftrace_graph(struct fgraph_ops *ops);\nextern void unregister_ftrace_graph(struct fgraph_ops *ops);\n\n \nDECLARE_STATIC_KEY_FALSE(kill_ftrace_graph);\n\nstatic inline bool ftrace_graph_is_dead(void)\n{\n\treturn static_branch_unlikely(&kill_ftrace_graph);\n}\n\nextern void ftrace_graph_stop(void);\n\n \nextern trace_func_graph_ret_t ftrace_graph_return;\nextern trace_func_graph_ent_t ftrace_graph_entry;\n\nextern void ftrace_graph_init_task(struct task_struct *t);\nextern void ftrace_graph_exit_task(struct task_struct *t);\nextern void ftrace_graph_init_idle_task(struct task_struct *t, int cpu);\n\nstatic inline void pause_graph_tracing(void)\n{\n\tatomic_inc(&current->tracing_graph_pause);\n}\n\nstatic inline void unpause_graph_tracing(void)\n{\n\tatomic_dec(&current->tracing_graph_pause);\n}\n#else  \n\n#define __notrace_funcgraph\n\nstatic inline void ftrace_graph_init_task(struct task_struct *t) { }\nstatic inline void ftrace_graph_exit_task(struct task_struct *t) { }\nstatic inline void ftrace_graph_init_idle_task(struct task_struct *t, int cpu) { }\n\n \n#define register_ftrace_graph(ops) ({ -1; })\n#define unregister_ftrace_graph(ops) do { } while (0)\n\nstatic inline unsigned long\nftrace_graph_ret_addr(struct task_struct *task, int *idx, unsigned long ret,\n\t\t      unsigned long *retp)\n{\n\treturn ret;\n}\n\nstatic inline void pause_graph_tracing(void) { }\nstatic inline void unpause_graph_tracing(void) { }\n#endif  \n\n#ifdef CONFIG_TRACING\nenum ftrace_dump_mode;\n\nextern enum ftrace_dump_mode ftrace_dump_on_oops;\nextern int tracepoint_printk;\n\nextern void disable_trace_on_warning(void);\nextern int __disable_trace_on_warning;\n\nint tracepoint_printk_sysctl(struct ctl_table *table, int write,\n\t\t\t     void *buffer, size_t *lenp, loff_t *ppos);\n\n#else  \nstatic inline void  disable_trace_on_warning(void) { }\n#endif  \n\n#ifdef CONFIG_FTRACE_SYSCALLS\n\nunsigned long arch_syscall_addr(int nr);\n\n#endif  \n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}