{
  "module_name": "migrate.h",
  "hash_id": "e98550f12690ff5d60491fa58d72160dc7afad23f85cde8e3595c8c7be98694a",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/migrate.h",
  "human_readable_source": " \n#ifndef _LINUX_MIGRATE_H\n#define _LINUX_MIGRATE_H\n\n#include <linux/mm.h>\n#include <linux/mempolicy.h>\n#include <linux/migrate_mode.h>\n#include <linux/hugetlb.h>\n\ntypedef struct folio *new_folio_t(struct folio *folio, unsigned long private);\ntypedef void free_folio_t(struct folio *folio, unsigned long private);\n\nstruct migration_target_control;\n\n \n#define MIGRATEPAGE_SUCCESS\t\t0\n#define MIGRATEPAGE_UNMAP\t\t1\n\n \nstruct movable_operations {\n\tbool (*isolate_page)(struct page *, isolate_mode_t);\n\tint (*migrate_page)(struct page *dst, struct page *src,\n\t\t\tenum migrate_mode);\n\tvoid (*putback_page)(struct page *);\n};\n\n \nextern const char *migrate_reason_names[MR_TYPES];\n\n#ifdef CONFIG_MIGRATION\n\nvoid putback_movable_pages(struct list_head *l);\nint migrate_folio_extra(struct address_space *mapping, struct folio *dst,\n\t\tstruct folio *src, enum migrate_mode mode, int extra_count);\nint migrate_folio(struct address_space *mapping, struct folio *dst,\n\t\tstruct folio *src, enum migrate_mode mode);\nint migrate_pages(struct list_head *l, new_folio_t new, free_folio_t free,\n\t\t  unsigned long private, enum migrate_mode mode, int reason,\n\t\t  unsigned int *ret_succeeded);\nstruct folio *alloc_migration_target(struct folio *src, unsigned long private);\nbool isolate_movable_page(struct page *page, isolate_mode_t mode);\n\nint migrate_huge_page_move_mapping(struct address_space *mapping,\n\t\tstruct folio *dst, struct folio *src);\nvoid migration_entry_wait_on_locked(swp_entry_t entry, spinlock_t *ptl)\n\t\t__releases(ptl);\nvoid folio_migrate_flags(struct folio *newfolio, struct folio *folio);\nvoid folio_migrate_copy(struct folio *newfolio, struct folio *folio);\nint folio_migrate_mapping(struct address_space *mapping,\n\t\tstruct folio *newfolio, struct folio *folio, int extra_count);\n\n#else\n\nstatic inline void putback_movable_pages(struct list_head *l) {}\nstatic inline int migrate_pages(struct list_head *l, new_folio_t new,\n\t\tfree_folio_t free, unsigned long private,\n\t\tenum migrate_mode mode, int reason, unsigned int *ret_succeeded)\n\t{ return -ENOSYS; }\nstatic inline struct folio *alloc_migration_target(struct folio *src,\n\t\tunsigned long private)\n\t{ return NULL; }\nstatic inline bool isolate_movable_page(struct page *page, isolate_mode_t mode)\n\t{ return false; }\n\nstatic inline int migrate_huge_page_move_mapping(struct address_space *mapping,\n\t\t\t\t  struct folio *dst, struct folio *src)\n{\n\treturn -ENOSYS;\n}\n\n#endif  \n\n#ifdef CONFIG_COMPACTION\nbool PageMovable(struct page *page);\nvoid __SetPageMovable(struct page *page, const struct movable_operations *ops);\nvoid __ClearPageMovable(struct page *page);\n#else\nstatic inline bool PageMovable(struct page *page) { return false; }\nstatic inline void __SetPageMovable(struct page *page,\n\t\tconst struct movable_operations *ops)\n{\n}\nstatic inline void __ClearPageMovable(struct page *page)\n{\n}\n#endif\n\nstatic inline bool folio_test_movable(struct folio *folio)\n{\n\treturn PageMovable(&folio->page);\n}\n\nstatic inline\nconst struct movable_operations *folio_movable_ops(struct folio *folio)\n{\n\tVM_BUG_ON(!__folio_test_movable(folio));\n\n\treturn (const struct movable_operations *)\n\t\t((unsigned long)folio->mapping - PAGE_MAPPING_MOVABLE);\n}\n\nstatic inline\nconst struct movable_operations *page_movable_ops(struct page *page)\n{\n\tVM_BUG_ON(!__PageMovable(page));\n\n\treturn (const struct movable_operations *)\n\t\t((unsigned long)page->mapping - PAGE_MAPPING_MOVABLE);\n}\n\n#ifdef CONFIG_NUMA_BALANCING\nint migrate_misplaced_page(struct page *page, struct vm_area_struct *vma,\n\t\t\t   int node);\n#else\nstatic inline int migrate_misplaced_page(struct page *page,\n\t\t\t\t\t struct vm_area_struct *vma, int node)\n{\n\treturn -EAGAIN;  \n}\n#endif  \n\n#ifdef CONFIG_MIGRATION\n\n \n#define MIGRATE_PFN_VALID\t(1UL << 0)\n#define MIGRATE_PFN_MIGRATE\t(1UL << 1)\n#define MIGRATE_PFN_WRITE\t(1UL << 3)\n#define MIGRATE_PFN_SHIFT\t6\n\nstatic inline struct page *migrate_pfn_to_page(unsigned long mpfn)\n{\n\tif (!(mpfn & MIGRATE_PFN_VALID))\n\t\treturn NULL;\n\treturn pfn_to_page(mpfn >> MIGRATE_PFN_SHIFT);\n}\n\nstatic inline unsigned long migrate_pfn(unsigned long pfn)\n{\n\treturn (pfn << MIGRATE_PFN_SHIFT) | MIGRATE_PFN_VALID;\n}\n\nenum migrate_vma_direction {\n\tMIGRATE_VMA_SELECT_SYSTEM = 1 << 0,\n\tMIGRATE_VMA_SELECT_DEVICE_PRIVATE = 1 << 1,\n\tMIGRATE_VMA_SELECT_DEVICE_COHERENT = 1 << 2,\n};\n\nstruct migrate_vma {\n\tstruct vm_area_struct\t*vma;\n\t \n\tunsigned long\t\t*dst;\n\tunsigned long\t\t*src;\n\tunsigned long\t\tcpages;\n\tunsigned long\t\tnpages;\n\tunsigned long\t\tstart;\n\tunsigned long\t\tend;\n\n\t \n\tvoid\t\t\t*pgmap_owner;\n\tunsigned long\t\tflags;\n\n\t \n\tstruct page\t\t*fault_page;\n};\n\nint migrate_vma_setup(struct migrate_vma *args);\nvoid migrate_vma_pages(struct migrate_vma *migrate);\nvoid migrate_vma_finalize(struct migrate_vma *migrate);\nint migrate_device_range(unsigned long *src_pfns, unsigned long start,\n\t\t\tunsigned long npages);\nvoid migrate_device_pages(unsigned long *src_pfns, unsigned long *dst_pfns,\n\t\t\tunsigned long npages);\nvoid migrate_device_finalize(unsigned long *src_pfns,\n\t\t\tunsigned long *dst_pfns, unsigned long npages);\n\n#endif  \n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}