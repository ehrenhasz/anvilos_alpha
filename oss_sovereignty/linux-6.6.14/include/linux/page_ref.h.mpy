{
  "module_name": "page_ref.h",
  "hash_id": "7911a8b879cff30cde0b61bf00700e3e7ed53166801c6799a2077ed5fcba626a",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/page_ref.h",
  "human_readable_source": " \n#ifndef _LINUX_PAGE_REF_H\n#define _LINUX_PAGE_REF_H\n\n#include <linux/atomic.h>\n#include <linux/mm_types.h>\n#include <linux/page-flags.h>\n#include <linux/tracepoint-defs.h>\n\nDECLARE_TRACEPOINT(page_ref_set);\nDECLARE_TRACEPOINT(page_ref_mod);\nDECLARE_TRACEPOINT(page_ref_mod_and_test);\nDECLARE_TRACEPOINT(page_ref_mod_and_return);\nDECLARE_TRACEPOINT(page_ref_mod_unless);\nDECLARE_TRACEPOINT(page_ref_freeze);\nDECLARE_TRACEPOINT(page_ref_unfreeze);\n\n#ifdef CONFIG_DEBUG_PAGE_REF\n\n \n#define page_ref_tracepoint_active(t) tracepoint_enabled(t)\n\nextern void __page_ref_set(struct page *page, int v);\nextern void __page_ref_mod(struct page *page, int v);\nextern void __page_ref_mod_and_test(struct page *page, int v, int ret);\nextern void __page_ref_mod_and_return(struct page *page, int v, int ret);\nextern void __page_ref_mod_unless(struct page *page, int v, int u);\nextern void __page_ref_freeze(struct page *page, int v, int ret);\nextern void __page_ref_unfreeze(struct page *page, int v);\n\n#else\n\n#define page_ref_tracepoint_active(t) false\n\nstatic inline void __page_ref_set(struct page *page, int v)\n{\n}\nstatic inline void __page_ref_mod(struct page *page, int v)\n{\n}\nstatic inline void __page_ref_mod_and_test(struct page *page, int v, int ret)\n{\n}\nstatic inline void __page_ref_mod_and_return(struct page *page, int v, int ret)\n{\n}\nstatic inline void __page_ref_mod_unless(struct page *page, int v, int u)\n{\n}\nstatic inline void __page_ref_freeze(struct page *page, int v, int ret)\n{\n}\nstatic inline void __page_ref_unfreeze(struct page *page, int v)\n{\n}\n\n#endif\n\nstatic inline int page_ref_count(const struct page *page)\n{\n\treturn atomic_read(&page->_refcount);\n}\n\n \nstatic inline int folio_ref_count(const struct folio *folio)\n{\n\treturn page_ref_count(&folio->page);\n}\n\nstatic inline int page_count(const struct page *page)\n{\n\treturn folio_ref_count(page_folio(page));\n}\n\nstatic inline void set_page_count(struct page *page, int v)\n{\n\tatomic_set(&page->_refcount, v);\n\tif (page_ref_tracepoint_active(page_ref_set))\n\t\t__page_ref_set(page, v);\n}\n\nstatic inline void folio_set_count(struct folio *folio, int v)\n{\n\tset_page_count(&folio->page, v);\n}\n\n \nstatic inline void init_page_count(struct page *page)\n{\n\tset_page_count(page, 1);\n}\n\nstatic inline void page_ref_add(struct page *page, int nr)\n{\n\tatomic_add(nr, &page->_refcount);\n\tif (page_ref_tracepoint_active(page_ref_mod))\n\t\t__page_ref_mod(page, nr);\n}\n\nstatic inline void folio_ref_add(struct folio *folio, int nr)\n{\n\tpage_ref_add(&folio->page, nr);\n}\n\nstatic inline void page_ref_sub(struct page *page, int nr)\n{\n\tatomic_sub(nr, &page->_refcount);\n\tif (page_ref_tracepoint_active(page_ref_mod))\n\t\t__page_ref_mod(page, -nr);\n}\n\nstatic inline void folio_ref_sub(struct folio *folio, int nr)\n{\n\tpage_ref_sub(&folio->page, nr);\n}\n\nstatic inline int page_ref_sub_return(struct page *page, int nr)\n{\n\tint ret = atomic_sub_return(nr, &page->_refcount);\n\n\tif (page_ref_tracepoint_active(page_ref_mod_and_return))\n\t\t__page_ref_mod_and_return(page, -nr, ret);\n\treturn ret;\n}\n\nstatic inline int folio_ref_sub_return(struct folio *folio, int nr)\n{\n\treturn page_ref_sub_return(&folio->page, nr);\n}\n\nstatic inline void page_ref_inc(struct page *page)\n{\n\tatomic_inc(&page->_refcount);\n\tif (page_ref_tracepoint_active(page_ref_mod))\n\t\t__page_ref_mod(page, 1);\n}\n\nstatic inline void folio_ref_inc(struct folio *folio)\n{\n\tpage_ref_inc(&folio->page);\n}\n\nstatic inline void page_ref_dec(struct page *page)\n{\n\tatomic_dec(&page->_refcount);\n\tif (page_ref_tracepoint_active(page_ref_mod))\n\t\t__page_ref_mod(page, -1);\n}\n\nstatic inline void folio_ref_dec(struct folio *folio)\n{\n\tpage_ref_dec(&folio->page);\n}\n\nstatic inline int page_ref_sub_and_test(struct page *page, int nr)\n{\n\tint ret = atomic_sub_and_test(nr, &page->_refcount);\n\n\tif (page_ref_tracepoint_active(page_ref_mod_and_test))\n\t\t__page_ref_mod_and_test(page, -nr, ret);\n\treturn ret;\n}\n\nstatic inline int folio_ref_sub_and_test(struct folio *folio, int nr)\n{\n\treturn page_ref_sub_and_test(&folio->page, nr);\n}\n\nstatic inline int page_ref_inc_return(struct page *page)\n{\n\tint ret = atomic_inc_return(&page->_refcount);\n\n\tif (page_ref_tracepoint_active(page_ref_mod_and_return))\n\t\t__page_ref_mod_and_return(page, 1, ret);\n\treturn ret;\n}\n\nstatic inline int folio_ref_inc_return(struct folio *folio)\n{\n\treturn page_ref_inc_return(&folio->page);\n}\n\nstatic inline int page_ref_dec_and_test(struct page *page)\n{\n\tint ret = atomic_dec_and_test(&page->_refcount);\n\n\tif (page_ref_tracepoint_active(page_ref_mod_and_test))\n\t\t__page_ref_mod_and_test(page, -1, ret);\n\treturn ret;\n}\n\nstatic inline int folio_ref_dec_and_test(struct folio *folio)\n{\n\treturn page_ref_dec_and_test(&folio->page);\n}\n\nstatic inline int page_ref_dec_return(struct page *page)\n{\n\tint ret = atomic_dec_return(&page->_refcount);\n\n\tif (page_ref_tracepoint_active(page_ref_mod_and_return))\n\t\t__page_ref_mod_and_return(page, -1, ret);\n\treturn ret;\n}\n\nstatic inline int folio_ref_dec_return(struct folio *folio)\n{\n\treturn page_ref_dec_return(&folio->page);\n}\n\nstatic inline bool page_ref_add_unless(struct page *page, int nr, int u)\n{\n\tbool ret = atomic_add_unless(&page->_refcount, nr, u);\n\n\tif (page_ref_tracepoint_active(page_ref_mod_unless))\n\t\t__page_ref_mod_unless(page, nr, ret);\n\treturn ret;\n}\n\nstatic inline bool folio_ref_add_unless(struct folio *folio, int nr, int u)\n{\n\treturn page_ref_add_unless(&folio->page, nr, u);\n}\n\n \nstatic inline bool folio_try_get(struct folio *folio)\n{\n\treturn folio_ref_add_unless(folio, 1, 0);\n}\n\nstatic inline bool folio_ref_try_add_rcu(struct folio *folio, int count)\n{\n#ifdef CONFIG_TINY_RCU\n\t \n# ifdef CONFIG_PREEMPT_COUNT\n\tVM_BUG_ON(!in_atomic() && !irqs_disabled());\n# endif\n\tVM_BUG_ON_FOLIO(folio_ref_count(folio) == 0, folio);\n\tfolio_ref_add(folio, count);\n#else\n\tif (unlikely(!folio_ref_add_unless(folio, count, 0))) {\n\t\t \n\t\treturn false;\n\t}\n#endif\n\treturn true;\n}\n\n \nstatic inline bool folio_try_get_rcu(struct folio *folio)\n{\n\treturn folio_ref_try_add_rcu(folio, 1);\n}\n\nstatic inline int page_ref_freeze(struct page *page, int count)\n{\n\tint ret = likely(atomic_cmpxchg(&page->_refcount, count, 0) == count);\n\n\tif (page_ref_tracepoint_active(page_ref_freeze))\n\t\t__page_ref_freeze(page, count, ret);\n\treturn ret;\n}\n\nstatic inline int folio_ref_freeze(struct folio *folio, int count)\n{\n\treturn page_ref_freeze(&folio->page, count);\n}\n\nstatic inline void page_ref_unfreeze(struct page *page, int count)\n{\n\tVM_BUG_ON_PAGE(page_count(page) != 0, page);\n\tVM_BUG_ON(count == 0);\n\n\tatomic_set_release(&page->_refcount, count);\n\tif (page_ref_tracepoint_active(page_ref_unfreeze))\n\t\t__page_ref_unfreeze(page, count);\n}\n\nstatic inline void folio_ref_unfreeze(struct folio *folio, int count)\n{\n\tpage_ref_unfreeze(&folio->page, count);\n}\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}