{
  "module_name": "memory_hotplug.h",
  "hash_id": "a434443d29127a81c6d1296cac3848392e7b42e76dd00eb21b3f15a3afd2a99f",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/memory_hotplug.h",
  "human_readable_source": " \n#ifndef __LINUX_MEMORY_HOTPLUG_H\n#define __LINUX_MEMORY_HOTPLUG_H\n\n#include <linux/mmzone.h>\n#include <linux/spinlock.h>\n#include <linux/notifier.h>\n#include <linux/bug.h>\n\nstruct page;\nstruct zone;\nstruct pglist_data;\nstruct mem_section;\nstruct memory_group;\nstruct resource;\nstruct vmem_altmap;\nstruct dev_pagemap;\n\n#ifdef CONFIG_HAVE_ARCH_NODEDATA_EXTENSION\n \nextern pg_data_t *arch_alloc_nodedata(int nid);\nextern void arch_refresh_nodedata(int nid, pg_data_t *pgdat);\n\n#else  \n\n#define arch_alloc_nodedata(nid)\tgeneric_alloc_nodedata(nid)\n\n#ifdef CONFIG_NUMA\n \n#define generic_alloc_nodedata(nid)\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\\\n\tmemblock_alloc(sizeof(*pgdat), SMP_CACHE_BYTES);\t\\\n})\n\nextern pg_data_t *node_data[];\nstatic inline void arch_refresh_nodedata(int nid, pg_data_t *pgdat)\n{\n\tnode_data[nid] = pgdat;\n}\n\n#else  \n\n \nstatic inline pg_data_t *generic_alloc_nodedata(int nid)\n{\n\tBUG();\n\treturn NULL;\n}\nstatic inline void arch_refresh_nodedata(int nid, pg_data_t *pgdat)\n{\n}\n#endif  \n#endif  \n\n#ifdef CONFIG_MEMORY_HOTPLUG\nstruct page *pfn_to_online_page(unsigned long pfn);\n\n \nenum {\n\t \n\tMMOP_OFFLINE = 0,\n\t \n\tMMOP_ONLINE,\n\t \n\tMMOP_ONLINE_KERNEL,\n\t \n\tMMOP_ONLINE_MOVABLE,\n};\n\n \ntypedef int __bitwise mhp_t;\n\n \n#define MHP_NONE\t\t((__force mhp_t)0)\n \n#define MHP_MERGE_RESOURCE\t((__force mhp_t)BIT(0))\n\n \n#define MHP_MEMMAP_ON_MEMORY   ((__force mhp_t)BIT(1))\n \n#define MHP_NID_IS_MGID\t\t((__force mhp_t)BIT(2))\n\n \nstruct mhp_params {\n\tstruct vmem_altmap *altmap;\n\tpgprot_t pgprot;\n\tstruct dev_pagemap *pgmap;\n};\n\nbool mhp_range_allowed(u64 start, u64 size, bool need_mapping);\nstruct range mhp_get_pluggable_range(bool need_mapping);\n\n \nstatic inline unsigned zone_span_seqbegin(struct zone *zone)\n{\n\treturn read_seqbegin(&zone->span_seqlock);\n}\nstatic inline int zone_span_seqretry(struct zone *zone, unsigned iv)\n{\n\treturn read_seqretry(&zone->span_seqlock, iv);\n}\nstatic inline void zone_span_writelock(struct zone *zone)\n{\n\twrite_seqlock(&zone->span_seqlock);\n}\nstatic inline void zone_span_writeunlock(struct zone *zone)\n{\n\twrite_sequnlock(&zone->span_seqlock);\n}\nstatic inline void zone_seqlock_init(struct zone *zone)\n{\n\tseqlock_init(&zone->span_seqlock);\n}\nextern void adjust_present_page_count(struct page *page,\n\t\t\t\t      struct memory_group *group,\n\t\t\t\t      long nr_pages);\n \nextern int mhp_init_memmap_on_memory(unsigned long pfn, unsigned long nr_pages,\n\t\t\t\t     struct zone *zone);\nextern void mhp_deinit_memmap_on_memory(unsigned long pfn, unsigned long nr_pages);\nextern int online_pages(unsigned long pfn, unsigned long nr_pages,\n\t\t\tstruct zone *zone, struct memory_group *group);\nextern void __offline_isolated_pages(unsigned long start_pfn,\n\t\t\t\t     unsigned long end_pfn);\n\ntypedef void (*online_page_callback_t)(struct page *page, unsigned int order);\n\nextern void generic_online_page(struct page *page, unsigned int order);\nextern int set_online_page_callback(online_page_callback_t callback);\nextern int restore_online_page_callback(online_page_callback_t callback);\n\nextern int try_online_node(int nid);\n\nextern int arch_add_memory(int nid, u64 start, u64 size,\n\t\t\t   struct mhp_params *params);\nextern u64 max_mem_size;\n\nextern int mhp_online_type_from_str(const char *str);\n\n \nextern int mhp_default_online_type;\n \nextern bool movable_node_enabled;\nstatic inline bool movable_node_is_enabled(void)\n{\n\treturn movable_node_enabled;\n}\n\nextern void arch_remove_memory(u64 start, u64 size, struct vmem_altmap *altmap);\nextern void __remove_pages(unsigned long start_pfn, unsigned long nr_pages,\n\t\t\t   struct vmem_altmap *altmap);\n\n \nextern int __add_pages(int nid, unsigned long start_pfn, unsigned long nr_pages,\n\t\t       struct mhp_params *params);\n\n#ifndef CONFIG_ARCH_HAS_ADD_PAGES\nstatic inline int add_pages(int nid, unsigned long start_pfn,\n\t\tunsigned long nr_pages, struct mhp_params *params)\n{\n\treturn __add_pages(nid, start_pfn, nr_pages, params);\n}\n#else  \nint add_pages(int nid, unsigned long start_pfn, unsigned long nr_pages,\n\t      struct mhp_params *params);\n#endif  \n\nvoid get_online_mems(void);\nvoid put_online_mems(void);\n\nvoid mem_hotplug_begin(void);\nvoid mem_hotplug_done(void);\n\n \nstatic inline void pgdat_kswapd_lock(pg_data_t *pgdat)\n{\n\tmutex_lock(&pgdat->kswapd_lock);\n}\n\nstatic inline void pgdat_kswapd_unlock(pg_data_t *pgdat)\n{\n\tmutex_unlock(&pgdat->kswapd_lock);\n}\n\nstatic inline void pgdat_kswapd_lock_init(pg_data_t *pgdat)\n{\n\tmutex_init(&pgdat->kswapd_lock);\n}\n\n#else  \n#define pfn_to_online_page(pfn)\t\t\t\\\n({\t\t\t\t\t\t\\\n\tstruct page *___page = NULL;\t\t\\\n\tif (pfn_valid(pfn))\t\t\t\\\n\t\t___page = pfn_to_page(pfn);\t\\\n\t___page;\t\t\t\t\\\n })\n\nstatic inline unsigned zone_span_seqbegin(struct zone *zone)\n{\n\treturn 0;\n}\nstatic inline int zone_span_seqretry(struct zone *zone, unsigned iv)\n{\n\treturn 0;\n}\nstatic inline void zone_span_writelock(struct zone *zone) {}\nstatic inline void zone_span_writeunlock(struct zone *zone) {}\nstatic inline void zone_seqlock_init(struct zone *zone) {}\n\nstatic inline int try_online_node(int nid)\n{\n\treturn 0;\n}\n\nstatic inline void get_online_mems(void) {}\nstatic inline void put_online_mems(void) {}\n\nstatic inline void mem_hotplug_begin(void) {}\nstatic inline void mem_hotplug_done(void) {}\n\nstatic inline bool movable_node_is_enabled(void)\n{\n\treturn false;\n}\n\nstatic inline void pgdat_kswapd_lock(pg_data_t *pgdat) {}\nstatic inline void pgdat_kswapd_unlock(pg_data_t *pgdat) {}\nstatic inline void pgdat_kswapd_lock_init(pg_data_t *pgdat) {}\n#endif  \n\n \nstruct range arch_get_mappable_range(void);\n\n#if defined(CONFIG_MEMORY_HOTPLUG) || defined(CONFIG_DEFERRED_STRUCT_PAGE_INIT)\n \nstatic inline\nvoid pgdat_resize_lock(struct pglist_data *pgdat, unsigned long *flags)\n{\n\tspin_lock_irqsave(&pgdat->node_size_lock, *flags);\n}\nstatic inline\nvoid pgdat_resize_unlock(struct pglist_data *pgdat, unsigned long *flags)\n{\n\tspin_unlock_irqrestore(&pgdat->node_size_lock, *flags);\n}\nstatic inline\nvoid pgdat_resize_init(struct pglist_data *pgdat)\n{\n\tspin_lock_init(&pgdat->node_size_lock);\n}\n#else  \n \nstatic inline void pgdat_resize_lock(struct pglist_data *p, unsigned long *f) {}\nstatic inline void pgdat_resize_unlock(struct pglist_data *p, unsigned long *f) {}\nstatic inline void pgdat_resize_init(struct pglist_data *pgdat) {}\n#endif  \n\n#ifdef CONFIG_MEMORY_HOTREMOVE\n\nextern void try_offline_node(int nid);\nextern int offline_pages(unsigned long start_pfn, unsigned long nr_pages,\n\t\t\t struct zone *zone, struct memory_group *group);\nextern int remove_memory(u64 start, u64 size);\nextern void __remove_memory(u64 start, u64 size);\nextern int offline_and_remove_memory(u64 start, u64 size);\n\n#else\nstatic inline void try_offline_node(int nid) {}\n\nstatic inline int offline_pages(unsigned long start_pfn, unsigned long nr_pages,\n\t\t\t\tstruct zone *zone, struct memory_group *group)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int remove_memory(u64 start, u64 size)\n{\n\treturn -EBUSY;\n}\n\nstatic inline void __remove_memory(u64 start, u64 size) {}\n#endif  \n\n#ifdef CONFIG_MEMORY_HOTPLUG\nextern void __ref free_area_init_core_hotplug(struct pglist_data *pgdat);\nextern int __add_memory(int nid, u64 start, u64 size, mhp_t mhp_flags);\nextern int add_memory(int nid, u64 start, u64 size, mhp_t mhp_flags);\nextern int add_memory_resource(int nid, struct resource *resource,\n\t\t\t       mhp_t mhp_flags);\nextern int add_memory_driver_managed(int nid, u64 start, u64 size,\n\t\t\t\t     const char *resource_name,\n\t\t\t\t     mhp_t mhp_flags);\nextern void move_pfn_range_to_zone(struct zone *zone, unsigned long start_pfn,\n\t\t\t\t   unsigned long nr_pages,\n\t\t\t\t   struct vmem_altmap *altmap, int migratetype);\nextern void remove_pfn_range_from_zone(struct zone *zone,\n\t\t\t\t       unsigned long start_pfn,\n\t\t\t\t       unsigned long nr_pages);\nextern int sparse_add_section(int nid, unsigned long pfn,\n\t\tunsigned long nr_pages, struct vmem_altmap *altmap,\n\t\tstruct dev_pagemap *pgmap);\nextern void sparse_remove_section(unsigned long pfn, unsigned long nr_pages,\n\t\t\t\t  struct vmem_altmap *altmap);\nextern struct page *sparse_decode_mem_map(unsigned long coded_mem_map,\n\t\t\t\t\t  unsigned long pnum);\nextern struct zone *zone_for_pfn_range(int online_type, int nid,\n\t\tstruct memory_group *group, unsigned long start_pfn,\n\t\tunsigned long nr_pages);\nextern int arch_create_linear_mapping(int nid, u64 start, u64 size,\n\t\t\t\t      struct mhp_params *params);\nvoid arch_remove_linear_mapping(u64 start, u64 size);\n#endif  \n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}