{
  "module_name": "blk_types.h",
  "hash_id": "457486b07268ce5d3a20c0929c6c0b12312950190331e006a27cf270ed61516d",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/blk_types.h",
  "human_readable_source": " \n \n#ifndef __LINUX_BLK_TYPES_H\n#define __LINUX_BLK_TYPES_H\n\n#include <linux/types.h>\n#include <linux/bvec.h>\n#include <linux/device.h>\n#include <linux/ktime.h>\n\nstruct bio_set;\nstruct bio;\nstruct bio_integrity_payload;\nstruct page;\nstruct io_context;\nstruct cgroup_subsys_state;\ntypedef void (bio_end_io_t) (struct bio *);\nstruct bio_crypt_ctx;\n\n \n#ifndef SECTOR_SHIFT\n#define SECTOR_SHIFT 9\n#endif\n#ifndef SECTOR_SIZE\n#define SECTOR_SIZE (1 << SECTOR_SHIFT)\n#endif\n\n#define PAGE_SECTORS_SHIFT\t(PAGE_SHIFT - SECTOR_SHIFT)\n#define PAGE_SECTORS\t\t(1 << PAGE_SECTORS_SHIFT)\n#define SECTOR_MASK\t\t(PAGE_SECTORS - 1)\n\nstruct block_device {\n\tsector_t\t\tbd_start_sect;\n\tsector_t\t\tbd_nr_sectors;\n\tstruct gendisk *\tbd_disk;\n\tstruct request_queue *\tbd_queue;\n\tstruct disk_stats __percpu *bd_stats;\n\tunsigned long\t\tbd_stamp;\n\tbool\t\t\tbd_read_only;\t \n\tu8\t\t\tbd_partno;\n\tbool\t\t\tbd_write_holder;\n\tbool\t\t\tbd_has_submit_bio;\n\tdev_t\t\t\tbd_dev;\n\tatomic_t\t\tbd_openers;\n\tspinlock_t\t\tbd_size_lock;  \n\tstruct inode *\t\tbd_inode;\t \n\tvoid *\t\t\tbd_claiming;\n\tvoid *\t\t\tbd_holder;\n\tconst struct blk_holder_ops *bd_holder_ops;\n\tstruct mutex\t\tbd_holder_lock;\n\t \n\tint\t\t\tbd_fsfreeze_count;\n\tint\t\t\tbd_holders;\n\tstruct kobject\t\t*bd_holder_dir;\n\n\t \n\tstruct mutex\t\tbd_fsfreeze_mutex;\n\tstruct super_block\t*bd_fsfreeze_sb;\n\n\tstruct partition_meta_info *bd_meta_info;\n#ifdef CONFIG_FAIL_MAKE_REQUEST\n\tbool\t\t\tbd_make_it_fail;\n#endif\n\tbool\t\t\tbd_ro_warned;\n\t \n\tstruct device\t\tbd_device;\n} __randomize_layout;\n\n#define bdev_whole(_bdev) \\\n\t((_bdev)->bd_disk->part0)\n\n#define dev_to_bdev(device) \\\n\tcontainer_of((device), struct block_device, bd_device)\n\n#define bdev_kobj(_bdev) \\\n\t(&((_bdev)->bd_device.kobj))\n\n \n#if defined(CONFIG_ALPHA) && !defined(__alpha_bwx__)\ntypedef u32 __bitwise blk_status_t;\ntypedef u32 blk_short_t;\n#else\ntypedef u8 __bitwise blk_status_t;\ntypedef u16 blk_short_t;\n#endif\n#define\tBLK_STS_OK 0\n#define BLK_STS_NOTSUPP\t\t((__force blk_status_t)1)\n#define BLK_STS_TIMEOUT\t\t((__force blk_status_t)2)\n#define BLK_STS_NOSPC\t\t((__force blk_status_t)3)\n#define BLK_STS_TRANSPORT\t((__force blk_status_t)4)\n#define BLK_STS_TARGET\t\t((__force blk_status_t)5)\n#define BLK_STS_RESV_CONFLICT\t((__force blk_status_t)6)\n#define BLK_STS_MEDIUM\t\t((__force blk_status_t)7)\n#define BLK_STS_PROTECTION\t((__force blk_status_t)8)\n#define BLK_STS_RESOURCE\t((__force blk_status_t)9)\n#define BLK_STS_IOERR\t\t((__force blk_status_t)10)\n\n \n#define BLK_STS_DM_REQUEUE    ((__force blk_status_t)11)\n\n \n#define BLK_STS_AGAIN\t\t((__force blk_status_t)12)\n\n \n#define BLK_STS_DEV_RESOURCE\t((__force blk_status_t)13)\n\n \n#define BLK_STS_ZONE_RESOURCE\t((__force blk_status_t)14)\n\n \n#define BLK_STS_ZONE_OPEN_RESOURCE\t((__force blk_status_t)15)\n\n \n#define BLK_STS_ZONE_ACTIVE_RESOURCE\t((__force blk_status_t)16)\n\n \n#define BLK_STS_OFFLINE\t\t((__force blk_status_t)17)\n\n \n#define BLK_STS_DURATION_LIMIT\t((__force blk_status_t)18)\n\n \nstatic inline bool blk_path_error(blk_status_t error)\n{\n\tswitch (error) {\n\tcase BLK_STS_NOTSUPP:\n\tcase BLK_STS_NOSPC:\n\tcase BLK_STS_TARGET:\n\tcase BLK_STS_RESV_CONFLICT:\n\tcase BLK_STS_MEDIUM:\n\tcase BLK_STS_PROTECTION:\n\t\treturn false;\n\t}\n\n\t \n\treturn true;\n}\n\n \n#define BIO_ISSUE_RES_BITS      1\n#define BIO_ISSUE_SIZE_BITS     12\n#define BIO_ISSUE_RES_SHIFT     (64 - BIO_ISSUE_RES_BITS)\n#define BIO_ISSUE_SIZE_SHIFT    (BIO_ISSUE_RES_SHIFT - BIO_ISSUE_SIZE_BITS)\n#define BIO_ISSUE_TIME_MASK     ((1ULL << BIO_ISSUE_SIZE_SHIFT) - 1)\n#define BIO_ISSUE_SIZE_MASK     \\\n\t(((1ULL << BIO_ISSUE_SIZE_BITS) - 1) << BIO_ISSUE_SIZE_SHIFT)\n#define BIO_ISSUE_RES_MASK      (~((1ULL << BIO_ISSUE_RES_SHIFT) - 1))\n\n \n#define BIO_ISSUE_THROTL_SKIP_LATENCY (1ULL << 63)\n\nstruct bio_issue {\n\tu64 value;\n};\n\nstatic inline u64 __bio_issue_time(u64 time)\n{\n\treturn time & BIO_ISSUE_TIME_MASK;\n}\n\nstatic inline u64 bio_issue_time(struct bio_issue *issue)\n{\n\treturn __bio_issue_time(issue->value);\n}\n\nstatic inline sector_t bio_issue_size(struct bio_issue *issue)\n{\n\treturn ((issue->value & BIO_ISSUE_SIZE_MASK) >> BIO_ISSUE_SIZE_SHIFT);\n}\n\nstatic inline void bio_issue_init(struct bio_issue *issue,\n\t\t\t\t       sector_t size)\n{\n\tsize &= (1ULL << BIO_ISSUE_SIZE_BITS) - 1;\n\tissue->value = ((issue->value & BIO_ISSUE_RES_MASK) |\n\t\t\t(ktime_get_ns() & BIO_ISSUE_TIME_MASK) |\n\t\t\t((u64)size << BIO_ISSUE_SIZE_SHIFT));\n}\n\ntypedef __u32 __bitwise blk_opf_t;\n\ntypedef unsigned int blk_qc_t;\n#define BLK_QC_T_NONE\t\t-1U\n\n \nstruct bio {\n\tstruct bio\t\t*bi_next;\t \n\tstruct block_device\t*bi_bdev;\n\tblk_opf_t\t\tbi_opf;\t\t \n\tunsigned short\t\tbi_flags;\t \n\tunsigned short\t\tbi_ioprio;\n\tblk_status_t\t\tbi_status;\n\tatomic_t\t\t__bi_remaining;\n\n\tstruct bvec_iter\tbi_iter;\n\n\tblk_qc_t\t\tbi_cookie;\n\tbio_end_io_t\t\t*bi_end_io;\n\tvoid\t\t\t*bi_private;\n#ifdef CONFIG_BLK_CGROUP\n\t \n\tstruct blkcg_gq\t\t*bi_blkg;\n\tstruct bio_issue\tbi_issue;\n#ifdef CONFIG_BLK_CGROUP_IOCOST\n\tu64\t\t\tbi_iocost_cost;\n#endif\n#endif\n\n#ifdef CONFIG_BLK_INLINE_ENCRYPTION\n\tstruct bio_crypt_ctx\t*bi_crypt_context;\n#endif\n\n\tunion {\n#if defined(CONFIG_BLK_DEV_INTEGRITY)\n\t\tstruct bio_integrity_payload *bi_integrity;  \n#endif\n\t};\n\n\tunsigned short\t\tbi_vcnt;\t \n\n\t \n\n\tunsigned short\t\tbi_max_vecs;\t \n\n\tatomic_t\t\t__bi_cnt;\t \n\n\tstruct bio_vec\t\t*bi_io_vec;\t \n\n\tstruct bio_set\t\t*bi_pool;\n\n\t \n\tstruct bio_vec\t\tbi_inline_vecs[];\n};\n\n#define BIO_RESET_BYTES\t\toffsetof(struct bio, bi_max_vecs)\n#define BIO_MAX_SECTORS\t\t(UINT_MAX >> SECTOR_SHIFT)\n\n \nenum {\n\tBIO_PAGE_PINNED,\t \n\tBIO_CLONED,\t\t \n\tBIO_BOUNCED,\t\t \n\tBIO_QUIET,\t\t \n\tBIO_CHAIN,\t\t \n\tBIO_REFFED,\t\t \n\tBIO_BPS_THROTTLED,\t \n\tBIO_TRACE_COMPLETION,\t \n\tBIO_CGROUP_ACCT,\t \n\tBIO_QOS_THROTTLED,\t \n\tBIO_QOS_MERGED,\t\t \n\tBIO_REMAPPED,\n\tBIO_ZONE_WRITE_LOCKED,\t \n\tBIO_FLAG_LAST\n};\n\ntypedef __u32 __bitwise blk_mq_req_flags_t;\n\n#define REQ_OP_BITS\t8\n#define REQ_OP_MASK\t(__force blk_opf_t)((1 << REQ_OP_BITS) - 1)\n#define REQ_FLAG_BITS\t24\n\n \nenum req_op {\n\t \n\tREQ_OP_READ\t\t= (__force blk_opf_t)0,\n\t \n\tREQ_OP_WRITE\t\t= (__force blk_opf_t)1,\n\t \n\tREQ_OP_FLUSH\t\t= (__force blk_opf_t)2,\n\t \n\tREQ_OP_DISCARD\t\t= (__force blk_opf_t)3,\n\t \n\tREQ_OP_SECURE_ERASE\t= (__force blk_opf_t)5,\n\t \n\tREQ_OP_WRITE_ZEROES\t= (__force blk_opf_t)9,\n\t \n\tREQ_OP_ZONE_OPEN\t= (__force blk_opf_t)10,\n\t \n\tREQ_OP_ZONE_CLOSE\t= (__force blk_opf_t)11,\n\t \n\tREQ_OP_ZONE_FINISH\t= (__force blk_opf_t)12,\n\t \n\tREQ_OP_ZONE_APPEND\t= (__force blk_opf_t)13,\n\t \n\tREQ_OP_ZONE_RESET\t= (__force blk_opf_t)15,\n\t \n\tREQ_OP_ZONE_RESET_ALL\t= (__force blk_opf_t)17,\n\n\t \n\tREQ_OP_DRV_IN\t\t= (__force blk_opf_t)34,\n\tREQ_OP_DRV_OUT\t\t= (__force blk_opf_t)35,\n\n\tREQ_OP_LAST\t\t= (__force blk_opf_t)36,\n};\n\nenum req_flag_bits {\n\t__REQ_FAILFAST_DEV =\t \n\t\tREQ_OP_BITS,\n\t__REQ_FAILFAST_TRANSPORT,  \n\t__REQ_FAILFAST_DRIVER,\t \n\t__REQ_SYNC,\t\t \n\t__REQ_META,\t\t \n\t__REQ_PRIO,\t\t \n\t__REQ_NOMERGE,\t\t \n\t__REQ_IDLE,\t\t \n\t__REQ_INTEGRITY,\t \n\t__REQ_FUA,\t\t \n\t__REQ_PREFLUSH,\t\t \n\t__REQ_RAHEAD,\t\t \n\t__REQ_BACKGROUND,\t \n\t__REQ_NOWAIT,            \n\t__REQ_POLLED,\t\t \n\t__REQ_ALLOC_CACHE,\t \n\t__REQ_SWAP,\t\t \n\t__REQ_DRV,\t\t \n\t__REQ_FS_PRIVATE,\t \n\n\t \n\t \n\t__REQ_NOUNMAP,\t\t \n\n\t__REQ_NR_BITS,\t\t \n};\n\n#define REQ_FAILFAST_DEV\t\\\n\t\t\t(__force blk_opf_t)(1ULL << __REQ_FAILFAST_DEV)\n#define REQ_FAILFAST_TRANSPORT\t\\\n\t\t\t(__force blk_opf_t)(1ULL << __REQ_FAILFAST_TRANSPORT)\n#define REQ_FAILFAST_DRIVER\t\\\n\t\t\t(__force blk_opf_t)(1ULL << __REQ_FAILFAST_DRIVER)\n#define REQ_SYNC\t(__force blk_opf_t)(1ULL << __REQ_SYNC)\n#define REQ_META\t(__force blk_opf_t)(1ULL << __REQ_META)\n#define REQ_PRIO\t(__force blk_opf_t)(1ULL << __REQ_PRIO)\n#define REQ_NOMERGE\t(__force blk_opf_t)(1ULL << __REQ_NOMERGE)\n#define REQ_IDLE\t(__force blk_opf_t)(1ULL << __REQ_IDLE)\n#define REQ_INTEGRITY\t(__force blk_opf_t)(1ULL << __REQ_INTEGRITY)\n#define REQ_FUA\t\t(__force blk_opf_t)(1ULL << __REQ_FUA)\n#define REQ_PREFLUSH\t(__force blk_opf_t)(1ULL << __REQ_PREFLUSH)\n#define REQ_RAHEAD\t(__force blk_opf_t)(1ULL << __REQ_RAHEAD)\n#define REQ_BACKGROUND\t(__force blk_opf_t)(1ULL << __REQ_BACKGROUND)\n#define REQ_NOWAIT\t(__force blk_opf_t)(1ULL << __REQ_NOWAIT)\n#define REQ_POLLED\t(__force blk_opf_t)(1ULL << __REQ_POLLED)\n#define REQ_ALLOC_CACHE\t(__force blk_opf_t)(1ULL << __REQ_ALLOC_CACHE)\n#define REQ_SWAP\t(__force blk_opf_t)(1ULL << __REQ_SWAP)\n#define REQ_DRV\t\t(__force blk_opf_t)(1ULL << __REQ_DRV)\n#define REQ_FS_PRIVATE\t(__force blk_opf_t)(1ULL << __REQ_FS_PRIVATE)\n\n#define REQ_NOUNMAP\t(__force blk_opf_t)(1ULL << __REQ_NOUNMAP)\n\n#define REQ_FAILFAST_MASK \\\n\t(REQ_FAILFAST_DEV | REQ_FAILFAST_TRANSPORT | REQ_FAILFAST_DRIVER)\n\n#define REQ_NOMERGE_FLAGS \\\n\t(REQ_NOMERGE | REQ_PREFLUSH | REQ_FUA)\n\nenum stat_group {\n\tSTAT_READ,\n\tSTAT_WRITE,\n\tSTAT_DISCARD,\n\tSTAT_FLUSH,\n\n\tNR_STAT_GROUPS\n};\n\nstatic inline enum req_op bio_op(const struct bio *bio)\n{\n\treturn bio->bi_opf & REQ_OP_MASK;\n}\n\nstatic inline bool op_is_write(blk_opf_t op)\n{\n\treturn !!(op & (__force blk_opf_t)1);\n}\n\n \nstatic inline bool op_is_flush(blk_opf_t op)\n{\n\treturn op & (REQ_FUA | REQ_PREFLUSH);\n}\n\n \nstatic inline bool op_is_sync(blk_opf_t op)\n{\n\treturn (op & REQ_OP_MASK) == REQ_OP_READ ||\n\t\t(op & (REQ_SYNC | REQ_FUA | REQ_PREFLUSH));\n}\n\nstatic inline bool op_is_discard(blk_opf_t op)\n{\n\treturn (op & REQ_OP_MASK) == REQ_OP_DISCARD;\n}\n\n \nstatic inline bool op_is_zone_mgmt(enum req_op op)\n{\n\tswitch (op & REQ_OP_MASK) {\n\tcase REQ_OP_ZONE_RESET:\n\tcase REQ_OP_ZONE_OPEN:\n\tcase REQ_OP_ZONE_CLOSE:\n\tcase REQ_OP_ZONE_FINISH:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic inline int op_stat_group(enum req_op op)\n{\n\tif (op_is_discard(op))\n\t\treturn STAT_DISCARD;\n\treturn op_is_write(op);\n}\n\nstruct blk_rq_stat {\n\tu64 mean;\n\tu64 min;\n\tu64 max;\n\tu32 nr_samples;\n\tu64 batch;\n};\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}