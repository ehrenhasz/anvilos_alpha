{
  "module_name": "dax.h",
  "hash_id": "cb4afed53c7119811ac0a0ccafe605b1f87e2a1f0c6175d2acf2ccf28b2aa740",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/dax.h",
  "human_readable_source": " \n#ifndef _LINUX_DAX_H\n#define _LINUX_DAX_H\n\n#include <linux/fs.h>\n#include <linux/mm.h>\n#include <linux/radix-tree.h>\n\ntypedef unsigned long dax_entry_t;\n\nstruct dax_device;\nstruct gendisk;\nstruct iomap_ops;\nstruct iomap_iter;\nstruct iomap;\n\nenum dax_access_mode {\n\tDAX_ACCESS,\n\tDAX_RECOVERY_WRITE,\n};\n\nstruct dax_operations {\n\t \n\tlong (*direct_access)(struct dax_device *, pgoff_t, long,\n\t\t\tenum dax_access_mode, void **, pfn_t *);\n\t \n\tbool (*dax_supported)(struct dax_device *, struct block_device *, int,\n\t\t\tsector_t, sector_t);\n\t \n\tint (*zero_page_range)(struct dax_device *, pgoff_t, size_t);\n\t \n\tsize_t (*recovery_write)(struct dax_device *dax_dev, pgoff_t pgoff,\n\t\t\tvoid *addr, size_t bytes, struct iov_iter *iter);\n};\n\nstruct dax_holder_operations {\n\t \n\tint (*notify_failure)(struct dax_device *dax_dev, u64 offset,\n\t\t\tu64 len, int mf_flags);\n};\n\n#if IS_ENABLED(CONFIG_DAX)\nstruct dax_device *alloc_dax(void *private, const struct dax_operations *ops);\nvoid *dax_holder(struct dax_device *dax_dev);\nvoid put_dax(struct dax_device *dax_dev);\nvoid kill_dax(struct dax_device *dax_dev);\nvoid dax_write_cache(struct dax_device *dax_dev, bool wc);\nbool dax_write_cache_enabled(struct dax_device *dax_dev);\nbool dax_synchronous(struct dax_device *dax_dev);\nvoid set_dax_synchronous(struct dax_device *dax_dev);\nsize_t dax_recovery_write(struct dax_device *dax_dev, pgoff_t pgoff,\n\t\tvoid *addr, size_t bytes, struct iov_iter *i);\n \nstatic inline bool daxdev_mapping_supported(struct vm_area_struct *vma,\n\t\t\t\t\t     struct dax_device *dax_dev)\n{\n\tif (!(vma->vm_flags & VM_SYNC))\n\t\treturn true;\n\tif (!IS_DAX(file_inode(vma->vm_file)))\n\t\treturn false;\n\treturn dax_synchronous(dax_dev);\n}\n#else\nstatic inline void *dax_holder(struct dax_device *dax_dev)\n{\n\treturn NULL;\n}\nstatic inline struct dax_device *alloc_dax(void *private,\n\t\tconst struct dax_operations *ops)\n{\n\t \n\treturn NULL;\n}\nstatic inline void put_dax(struct dax_device *dax_dev)\n{\n}\nstatic inline void kill_dax(struct dax_device *dax_dev)\n{\n}\nstatic inline void dax_write_cache(struct dax_device *dax_dev, bool wc)\n{\n}\nstatic inline bool dax_write_cache_enabled(struct dax_device *dax_dev)\n{\n\treturn false;\n}\nstatic inline bool dax_synchronous(struct dax_device *dax_dev)\n{\n\treturn true;\n}\nstatic inline void set_dax_synchronous(struct dax_device *dax_dev)\n{\n}\nstatic inline bool daxdev_mapping_supported(struct vm_area_struct *vma,\n\t\t\t\tstruct dax_device *dax_dev)\n{\n\treturn !(vma->vm_flags & VM_SYNC);\n}\nstatic inline size_t dax_recovery_write(struct dax_device *dax_dev,\n\t\tpgoff_t pgoff, void *addr, size_t bytes, struct iov_iter *i)\n{\n\treturn 0;\n}\n#endif\n\nvoid set_dax_nocache(struct dax_device *dax_dev);\nvoid set_dax_nomc(struct dax_device *dax_dev);\n\nstruct writeback_control;\n#if defined(CONFIG_BLOCK) && defined(CONFIG_FS_DAX)\nint dax_add_host(struct dax_device *dax_dev, struct gendisk *disk);\nvoid dax_remove_host(struct gendisk *disk);\nstruct dax_device *fs_dax_get_by_bdev(struct block_device *bdev, u64 *start_off,\n\t\tvoid *holder, const struct dax_holder_operations *ops);\nvoid fs_put_dax(struct dax_device *dax_dev, void *holder);\n#else\nstatic inline int dax_add_host(struct dax_device *dax_dev, struct gendisk *disk)\n{\n\treturn 0;\n}\nstatic inline void dax_remove_host(struct gendisk *disk)\n{\n}\nstatic inline struct dax_device *fs_dax_get_by_bdev(struct block_device *bdev,\n\t\tu64 *start_off, void *holder,\n\t\tconst struct dax_holder_operations *ops)\n{\n\treturn NULL;\n}\nstatic inline void fs_put_dax(struct dax_device *dax_dev, void *holder)\n{\n}\n#endif  \n\n#if IS_ENABLED(CONFIG_FS_DAX)\nint dax_writeback_mapping_range(struct address_space *mapping,\n\t\tstruct dax_device *dax_dev, struct writeback_control *wbc);\n\nstruct page *dax_layout_busy_page(struct address_space *mapping);\nstruct page *dax_layout_busy_page_range(struct address_space *mapping, loff_t start, loff_t end);\ndax_entry_t dax_lock_folio(struct folio *folio);\nvoid dax_unlock_folio(struct folio *folio, dax_entry_t cookie);\ndax_entry_t dax_lock_mapping_entry(struct address_space *mapping,\n\t\tunsigned long index, struct page **page);\nvoid dax_unlock_mapping_entry(struct address_space *mapping,\n\t\tunsigned long index, dax_entry_t cookie);\n#else\nstatic inline struct page *dax_layout_busy_page(struct address_space *mapping)\n{\n\treturn NULL;\n}\n\nstatic inline struct page *dax_layout_busy_page_range(struct address_space *mapping, pgoff_t start, pgoff_t nr_pages)\n{\n\treturn NULL;\n}\n\nstatic inline int dax_writeback_mapping_range(struct address_space *mapping,\n\t\tstruct dax_device *dax_dev, struct writeback_control *wbc)\n{\n\treturn -EOPNOTSUPP;\n}\n\nstatic inline dax_entry_t dax_lock_folio(struct folio *folio)\n{\n\tif (IS_DAX(folio->mapping->host))\n\t\treturn ~0UL;\n\treturn 0;\n}\n\nstatic inline void dax_unlock_folio(struct folio *folio, dax_entry_t cookie)\n{\n}\n\nstatic inline dax_entry_t dax_lock_mapping_entry(struct address_space *mapping,\n\t\tunsigned long index, struct page **page)\n{\n\treturn 0;\n}\n\nstatic inline void dax_unlock_mapping_entry(struct address_space *mapping,\n\t\tunsigned long index, dax_entry_t cookie)\n{\n}\n#endif\n\nint dax_file_unshare(struct inode *inode, loff_t pos, loff_t len,\n\t\tconst struct iomap_ops *ops);\nint dax_zero_range(struct inode *inode, loff_t pos, loff_t len, bool *did_zero,\n\t\tconst struct iomap_ops *ops);\nint dax_truncate_page(struct inode *inode, loff_t pos, bool *did_zero,\n\t\tconst struct iomap_ops *ops);\n\n#if IS_ENABLED(CONFIG_DAX)\nint dax_read_lock(void);\nvoid dax_read_unlock(int id);\n#else\nstatic inline int dax_read_lock(void)\n{\n\treturn 0;\n}\n\nstatic inline void dax_read_unlock(int id)\n{\n}\n#endif  \nbool dax_alive(struct dax_device *dax_dev);\nvoid *dax_get_private(struct dax_device *dax_dev);\nlong dax_direct_access(struct dax_device *dax_dev, pgoff_t pgoff, long nr_pages,\n\t\tenum dax_access_mode mode, void **kaddr, pfn_t *pfn);\nsize_t dax_copy_from_iter(struct dax_device *dax_dev, pgoff_t pgoff, void *addr,\n\t\tsize_t bytes, struct iov_iter *i);\nsize_t dax_copy_to_iter(struct dax_device *dax_dev, pgoff_t pgoff, void *addr,\n\t\tsize_t bytes, struct iov_iter *i);\nint dax_zero_page_range(struct dax_device *dax_dev, pgoff_t pgoff,\n\t\t\tsize_t nr_pages);\nint dax_holder_notify_failure(struct dax_device *dax_dev, u64 off, u64 len,\n\t\tint mf_flags);\nvoid dax_flush(struct dax_device *dax_dev, void *addr, size_t size);\n\nssize_t dax_iomap_rw(struct kiocb *iocb, struct iov_iter *iter,\n\t\tconst struct iomap_ops *ops);\nvm_fault_t dax_iomap_fault(struct vm_fault *vmf, unsigned int order,\n\t\t    pfn_t *pfnp, int *errp, const struct iomap_ops *ops);\nvm_fault_t dax_finish_sync_fault(struct vm_fault *vmf,\n\t\tunsigned int order, pfn_t pfn);\nint dax_delete_mapping_entry(struct address_space *mapping, pgoff_t index);\nint dax_invalidate_mapping_entry_sync(struct address_space *mapping,\n\t\t\t\t      pgoff_t index);\nint dax_dedupe_file_range_compare(struct inode *src, loff_t srcoff,\n\t\t\t\t  struct inode *dest, loff_t destoff,\n\t\t\t\t  loff_t len, bool *is_same,\n\t\t\t\t  const struct iomap_ops *ops);\nint dax_remap_file_range_prep(struct file *file_in, loff_t pos_in,\n\t\t\t      struct file *file_out, loff_t pos_out,\n\t\t\t      loff_t *len, unsigned int remap_flags,\n\t\t\t      const struct iomap_ops *ops);\nstatic inline bool dax_mapping(struct address_space *mapping)\n{\n\treturn mapping->host && IS_DAX(mapping->host);\n}\n\n \nstatic inline int dax_mem2blk_err(int err)\n{\n\treturn (err == -EHWPOISON) ? -EIO : err;\n}\n\n#ifdef CONFIG_DEV_DAX_HMEM_DEVICES\nvoid hmem_register_resource(int target_nid, struct resource *r);\n#else\nstatic inline void hmem_register_resource(int target_nid, struct resource *r)\n{\n}\n#endif\n\ntypedef int (*walk_hmem_fn)(struct device *dev, int target_nid,\n\t\t\t    const struct resource *res);\nint walk_hmem_resources(struct device *dev, walk_hmem_fn fn);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}