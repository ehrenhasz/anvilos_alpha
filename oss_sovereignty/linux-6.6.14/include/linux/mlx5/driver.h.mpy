{
  "module_name": "driver.h",
  "hash_id": "48edf3510fd4acb8282f2a42827842c273d6f51f9150f4bce128c0619b633983",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/mlx5/driver.h",
  "human_readable_source": " \n\n#ifndef MLX5_DRIVER_H\n#define MLX5_DRIVER_H\n\n#include <linux/kernel.h>\n#include <linux/completion.h>\n#include <linux/pci.h>\n#include <linux/irq.h>\n#include <linux/spinlock_types.h>\n#include <linux/semaphore.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/xarray.h>\n#include <linux/workqueue.h>\n#include <linux/mempool.h>\n#include <linux/interrupt.h>\n#include <linux/idr.h>\n#include <linux/notifier.h>\n#include <linux/refcount.h>\n#include <linux/auxiliary_bus.h>\n#include <linux/mutex.h>\n\n#include <linux/mlx5/device.h>\n#include <linux/mlx5/doorbell.h>\n#include <linux/mlx5/eq.h>\n#include <linux/timecounter.h>\n#include <linux/ptp_clock_kernel.h>\n#include <net/devlink.h>\n\n#define MLX5_ADEV_NAME \"mlx5_core\"\n\n#define MLX5_IRQ_EQ_CTRL (U8_MAX)\n\nenum {\n\tMLX5_BOARD_ID_LEN = 64,\n};\n\nenum {\n\tMLX5_CMD_WQ_MAX_NAME\t= 32,\n};\n\nenum {\n\tCMD_OWNER_SW\t\t= 0x0,\n\tCMD_OWNER_HW\t\t= 0x1,\n\tCMD_STATUS_SUCCESS\t= 0,\n};\n\nenum mlx5_sqp_t {\n\tMLX5_SQP_SMI\t\t= 0,\n\tMLX5_SQP_GSI\t\t= 1,\n\tMLX5_SQP_IEEE_1588\t= 2,\n\tMLX5_SQP_SNIFFER\t= 3,\n\tMLX5_SQP_SYNC_UMR\t= 4,\n};\n\nenum {\n\tMLX5_MAX_PORTS\t= 4,\n};\n\nenum {\n\tMLX5_ATOMIC_MODE_OFFSET = 16,\n\tMLX5_ATOMIC_MODE_IB_COMP = 1,\n\tMLX5_ATOMIC_MODE_CX = 2,\n\tMLX5_ATOMIC_MODE_8B = 3,\n\tMLX5_ATOMIC_MODE_16B = 4,\n\tMLX5_ATOMIC_MODE_32B = 5,\n\tMLX5_ATOMIC_MODE_64B = 6,\n\tMLX5_ATOMIC_MODE_128B = 7,\n\tMLX5_ATOMIC_MODE_256B = 8,\n};\n\nenum {\n\tMLX5_REG_SBPR            = 0xb001,\n\tMLX5_REG_SBCM            = 0xb002,\n\tMLX5_REG_QPTS            = 0x4002,\n\tMLX5_REG_QETCR\t\t = 0x4005,\n\tMLX5_REG_QTCT\t\t = 0x400a,\n\tMLX5_REG_QPDPM           = 0x4013,\n\tMLX5_REG_QCAM            = 0x4019,\n\tMLX5_REG_DCBX_PARAM      = 0x4020,\n\tMLX5_REG_DCBX_APP        = 0x4021,\n\tMLX5_REG_FPGA_CAP\t = 0x4022,\n\tMLX5_REG_FPGA_CTRL\t = 0x4023,\n\tMLX5_REG_FPGA_ACCESS_REG = 0x4024,\n\tMLX5_REG_CORE_DUMP\t = 0x402e,\n\tMLX5_REG_PCAP\t\t = 0x5001,\n\tMLX5_REG_PMTU\t\t = 0x5003,\n\tMLX5_REG_PTYS\t\t = 0x5004,\n\tMLX5_REG_PAOS\t\t = 0x5006,\n\tMLX5_REG_PFCC            = 0x5007,\n\tMLX5_REG_PPCNT\t\t = 0x5008,\n\tMLX5_REG_PPTB            = 0x500b,\n\tMLX5_REG_PBMC            = 0x500c,\n\tMLX5_REG_PMAOS\t\t = 0x5012,\n\tMLX5_REG_PUDE\t\t = 0x5009,\n\tMLX5_REG_PMPE\t\t = 0x5010,\n\tMLX5_REG_PELC\t\t = 0x500e,\n\tMLX5_REG_PVLC\t\t = 0x500f,\n\tMLX5_REG_PCMR\t\t = 0x5041,\n\tMLX5_REG_PDDR\t\t = 0x5031,\n\tMLX5_REG_PMLP\t\t = 0x5002,\n\tMLX5_REG_PPLM\t\t = 0x5023,\n\tMLX5_REG_PCAM\t\t = 0x507f,\n\tMLX5_REG_NODE_DESC\t = 0x6001,\n\tMLX5_REG_HOST_ENDIANNESS = 0x7004,\n\tMLX5_REG_MTCAP\t\t = 0x9009,\n\tMLX5_REG_MTMP\t\t = 0x900A,\n\tMLX5_REG_MCIA\t\t = 0x9014,\n\tMLX5_REG_MFRL\t\t = 0x9028,\n\tMLX5_REG_MLCR\t\t = 0x902b,\n\tMLX5_REG_MRTC\t\t = 0x902d,\n\tMLX5_REG_MTRC_CAP\t = 0x9040,\n\tMLX5_REG_MTRC_CONF\t = 0x9041,\n\tMLX5_REG_MTRC_STDB\t = 0x9042,\n\tMLX5_REG_MTRC_CTRL\t = 0x9043,\n\tMLX5_REG_MPEIN\t\t = 0x9050,\n\tMLX5_REG_MPCNT\t\t = 0x9051,\n\tMLX5_REG_MTPPS\t\t = 0x9053,\n\tMLX5_REG_MTPPSE\t\t = 0x9054,\n\tMLX5_REG_MTUTC\t\t = 0x9055,\n\tMLX5_REG_MPEGC\t\t = 0x9056,\n\tMLX5_REG_MCQS\t\t = 0x9060,\n\tMLX5_REG_MCQI\t\t = 0x9061,\n\tMLX5_REG_MCC\t\t = 0x9062,\n\tMLX5_REG_MCDA\t\t = 0x9063,\n\tMLX5_REG_MCAM\t\t = 0x907f,\n\tMLX5_REG_MIRC\t\t = 0x9162,\n\tMLX5_REG_SBCAM\t\t = 0xB01F,\n\tMLX5_REG_RESOURCE_DUMP   = 0xC000,\n\tMLX5_REG_DTOR            = 0xC00E,\n};\n\nenum mlx5_qpts_trust_state {\n\tMLX5_QPTS_TRUST_PCP  = 1,\n\tMLX5_QPTS_TRUST_DSCP = 2,\n};\n\nenum mlx5_dcbx_oper_mode {\n\tMLX5E_DCBX_PARAM_VER_OPER_HOST  = 0x0,\n\tMLX5E_DCBX_PARAM_VER_OPER_AUTO  = 0x3,\n};\n\nenum {\n\tMLX5_ATOMIC_OPS_CMP_SWAP\t= 1 << 0,\n\tMLX5_ATOMIC_OPS_FETCH_ADD\t= 1 << 1,\n\tMLX5_ATOMIC_OPS_EXTENDED_CMP_SWAP = 1 << 2,\n\tMLX5_ATOMIC_OPS_EXTENDED_FETCH_ADD = 1 << 3,\n};\n\nenum mlx5_page_fault_resume_flags {\n\tMLX5_PAGE_FAULT_RESUME_REQUESTOR = 1 << 0,\n\tMLX5_PAGE_FAULT_RESUME_WRITE\t = 1 << 1,\n\tMLX5_PAGE_FAULT_RESUME_RDMA\t = 1 << 2,\n\tMLX5_PAGE_FAULT_RESUME_ERROR\t = 1 << 7,\n};\n\nenum dbg_rsc_type {\n\tMLX5_DBG_RSC_QP,\n\tMLX5_DBG_RSC_EQ,\n\tMLX5_DBG_RSC_CQ,\n};\n\nenum port_state_policy {\n\tMLX5_POLICY_DOWN\t= 0,\n\tMLX5_POLICY_UP\t\t= 1,\n\tMLX5_POLICY_FOLLOW\t= 2,\n\tMLX5_POLICY_INVALID\t= 0xffffffff\n};\n\nenum mlx5_coredev_type {\n\tMLX5_COREDEV_PF,\n\tMLX5_COREDEV_VF,\n\tMLX5_COREDEV_SF,\n};\n\nstruct mlx5_field_desc {\n\tint\t\t\ti;\n};\n\nstruct mlx5_rsc_debug {\n\tstruct mlx5_core_dev   *dev;\n\tvoid\t\t       *object;\n\tenum dbg_rsc_type\ttype;\n\tstruct dentry\t       *root;\n\tstruct mlx5_field_desc\tfields[];\n};\n\nenum mlx5_dev_event {\n\tMLX5_DEV_EVENT_SYS_ERROR = 128,  \n\tMLX5_DEV_EVENT_PORT_AFFINITY = 129,\n\tMLX5_DEV_EVENT_MULTIPORT_ESW = 130,\n};\n\nenum mlx5_port_status {\n\tMLX5_PORT_UP        = 1,\n\tMLX5_PORT_DOWN      = 2,\n};\n\nenum mlx5_cmdif_state {\n\tMLX5_CMDIF_STATE_UNINITIALIZED,\n\tMLX5_CMDIF_STATE_UP,\n\tMLX5_CMDIF_STATE_DOWN,\n};\n\nstruct mlx5_cmd_first {\n\t__be32\t\tdata[4];\n};\n\nstruct mlx5_cmd_msg {\n\tstruct list_head\t\tlist;\n\tstruct cmd_msg_cache\t       *parent;\n\tu32\t\t\t\tlen;\n\tstruct mlx5_cmd_first\t\tfirst;\n\tstruct mlx5_cmd_mailbox\t       *next;\n};\n\nstruct mlx5_cmd_debug {\n\tstruct dentry\t       *dbg_root;\n\tvoid\t\t       *in_msg;\n\tvoid\t\t       *out_msg;\n\tu8\t\t\tstatus;\n\tu16\t\t\tinlen;\n\tu16\t\t\toutlen;\n};\n\nstruct cmd_msg_cache {\n\t \n\tspinlock_t\t\tlock;\n\tstruct list_head\thead;\n\tunsigned int\t\tmax_inbox_size;\n\tunsigned int\t\tnum_ent;\n};\n\nenum {\n\tMLX5_NUM_COMMAND_CACHES = 5,\n};\n\nstruct mlx5_cmd_stats {\n\tu64\t\tsum;\n\tu64\t\tn;\n\t \n\tu64\t\tfailed;\n\t \n\tu64\t\tfailed_mbox_status;\n\t \n\tu32\t\tlast_failed_errno;\n\t \n\tu8\t\tlast_failed_mbox_status;\n\t \n\tu32\t\tlast_failed_syndrome;\n\tstruct dentry  *root;\n\t \n\tspinlock_t\tlock;\n};\n\nstruct mlx5_cmd {\n\tstruct mlx5_nb    nb;\n\n\t \n\tstruct {\n\t\tu16\t\tcmdif_rev;\n\t\tu8\t\tlog_sz;\n\t\tu8\t\tlog_stride;\n\t\tint\t\tmax_reg_cmds;\n\t\tunsigned long\tbitmask;\n\t\tstruct semaphore sem;\n\t\tstruct semaphore pages_sem;\n\t\tstruct semaphore throttle_sem;\n\t} vars;\n\tenum mlx5_cmdif_state\tstate;\n\tvoid\t       *cmd_alloc_buf;\n\tdma_addr_t\talloc_dma;\n\tint\t\talloc_size;\n\tvoid\t       *cmd_buf;\n\tdma_addr_t\tdma;\n\n\t \n\tspinlock_t\talloc_lock;\n\n\t \n\tspinlock_t\ttoken_lock;\n\tu8\t\ttoken;\n\tchar\t\twq_name[MLX5_CMD_WQ_MAX_NAME];\n\tstruct workqueue_struct *wq;\n\tint\tmode;\n\tu16     allowed_opcode;\n\tstruct mlx5_cmd_work_ent *ent_arr[MLX5_MAX_COMMANDS];\n\tstruct dma_pool *pool;\n\tstruct mlx5_cmd_debug dbg;\n\tstruct cmd_msg_cache cache[MLX5_NUM_COMMAND_CACHES];\n\tint checksum_disabled;\n\tstruct xarray stats;\n};\n\nstruct mlx5_cmd_mailbox {\n\tvoid\t       *buf;\n\tdma_addr_t\tdma;\n\tstruct mlx5_cmd_mailbox *next;\n};\n\nstruct mlx5_buf_list {\n\tvoid\t\t       *buf;\n\tdma_addr_t\t\tmap;\n};\n\nstruct mlx5_frag_buf {\n\tstruct mlx5_buf_list\t*frags;\n\tint\t\t\tnpages;\n\tint\t\t\tsize;\n\tu8\t\t\tpage_shift;\n};\n\nstruct mlx5_frag_buf_ctrl {\n\tstruct mlx5_buf_list   *frags;\n\tu32\t\t\tsz_m1;\n\tu16\t\t\tfrag_sz_m1;\n\tu16\t\t\tstrides_offset;\n\tu8\t\t\tlog_sz;\n\tu8\t\t\tlog_stride;\n\tu8\t\t\tlog_frag_strides;\n};\n\nstruct mlx5_core_psv {\n\tu32\tpsv_idx;\n\tstruct psv_layout {\n\t\tu32\tpd;\n\t\tu16\tsyndrome;\n\t\tu16\treserved;\n\t\tu16\tbg;\n\t\tu16\tapp_tag;\n\t\tu32\tref_tag;\n\t} psv;\n};\n\nstruct mlx5_core_sig_ctx {\n\tstruct mlx5_core_psv\tpsv_memory;\n\tstruct mlx5_core_psv\tpsv_wire;\n\tstruct ib_sig_err       err_item;\n\tbool\t\t\tsig_status_checked;\n\tbool\t\t\tsig_err_exists;\n\tu32\t\t\tsigerr_count;\n};\n\n#define MLX5_24BIT_MASK\t\t((1 << 24) - 1)\n\nenum mlx5_res_type {\n\tMLX5_RES_QP\t= MLX5_EVENT_QUEUE_TYPE_QP,\n\tMLX5_RES_RQ\t= MLX5_EVENT_QUEUE_TYPE_RQ,\n\tMLX5_RES_SQ\t= MLX5_EVENT_QUEUE_TYPE_SQ,\n\tMLX5_RES_SRQ\t= 3,\n\tMLX5_RES_XSRQ\t= 4,\n\tMLX5_RES_XRQ\t= 5,\n};\n\nstruct mlx5_core_rsc_common {\n\tenum mlx5_res_type\tres;\n\trefcount_t\t\trefcount;\n\tstruct completion\tfree;\n};\n\nstruct mlx5_uars_page {\n\tvoid __iomem\t       *map;\n\tbool\t\t\twc;\n\tu32\t\t\tindex;\n\tstruct list_head\tlist;\n\tunsigned int\t\tbfregs;\n\tunsigned long\t       *reg_bitmap;  \n\tunsigned long\t       *fp_bitmap;\n\tunsigned int\t\treg_avail;\n\tunsigned int\t\tfp_avail;\n\tstruct kref\t\tref_count;\n\tstruct mlx5_core_dev   *mdev;\n};\n\nstruct mlx5_bfreg_head {\n\t \n\tstruct mutex\t\tlock;\n\tstruct list_head\tlist;\n};\n\nstruct mlx5_bfreg_data {\n\tstruct mlx5_bfreg_head\treg_head;\n\tstruct mlx5_bfreg_head\twc_head;\n};\n\nstruct mlx5_sq_bfreg {\n\tvoid __iomem\t       *map;\n\tstruct mlx5_uars_page  *up;\n\tbool\t\t\twc;\n\tu32\t\t\tindex;\n\tunsigned int\t\toffset;\n};\n\nstruct mlx5_core_health {\n\tstruct health_buffer __iomem   *health;\n\t__be32 __iomem\t\t       *health_counter;\n\tstruct timer_list\t\ttimer;\n\tu32\t\t\t\tprev;\n\tint\t\t\t\tmiss_counter;\n\tu8\t\t\t\tsynd;\n\tu32\t\t\t\tfatal_error;\n\tu32\t\t\t\tcrdump_size;\n\tstruct workqueue_struct\t       *wq;\n\tunsigned long\t\t\tflags;\n\tstruct work_struct\t\tfatal_report_work;\n\tstruct work_struct\t\treport_work;\n\tstruct devlink_health_reporter *fw_reporter;\n\tstruct devlink_health_reporter *fw_fatal_reporter;\n\tstruct devlink_health_reporter *vnic_reporter;\n\tstruct delayed_work\t\tupdate_fw_log_ts_work;\n};\n\nenum {\n\tMLX5_PF_NOTIFY_DISABLE_VF,\n\tMLX5_PF_NOTIFY_ENABLE_VF,\n};\n\nstruct mlx5_vf_context {\n\tint\tenabled;\n\tu64\tport_guid;\n\tu64\tnode_guid;\n\t \n\tu8\tport_guid_valid:1;\n\tu8\tnode_guid_valid:1;\n\tenum port_state_policy\tpolicy;\n\tstruct blocking_notifier_head notifier;\n};\n\nstruct mlx5_core_sriov {\n\tstruct mlx5_vf_context\t*vfs_ctx;\n\tint\t\t\tnum_vfs;\n\tu16\t\t\tmax_vfs;\n\tu16\t\t\tmax_ec_vfs;\n};\n\nstruct mlx5_fc_pool {\n\tstruct mlx5_core_dev *dev;\n\tstruct mutex pool_lock;  \n\tstruct list_head fully_used;\n\tstruct list_head partially_used;\n\tstruct list_head unused;\n\tint available_fcs;\n\tint used_fcs;\n\tint threshold;\n};\n\nstruct mlx5_fc_stats {\n\tspinlock_t counters_idr_lock;  \n\tstruct idr counters_idr;\n\tstruct list_head counters;\n\tstruct llist_head addlist;\n\tstruct llist_head dellist;\n\n\tstruct workqueue_struct *wq;\n\tstruct delayed_work work;\n\tunsigned long next_query;\n\tunsigned long sampling_interval;  \n\tu32 *bulk_query_out;\n\tint bulk_query_len;\n\tsize_t num_counters;\n\tbool bulk_query_alloc_failed;\n\tunsigned long next_bulk_query_alloc;\n\tstruct mlx5_fc_pool fc_pool;\n};\n\nstruct mlx5_events;\nstruct mlx5_mpfs;\nstruct mlx5_eswitch;\nstruct mlx5_lag;\nstruct mlx5_devcom_dev;\nstruct mlx5_fw_reset;\nstruct mlx5_eq_table;\nstruct mlx5_irq_table;\nstruct mlx5_vhca_state_notifier;\nstruct mlx5_sf_dev_table;\nstruct mlx5_sf_hw_table;\nstruct mlx5_sf_table;\nstruct mlx5_crypto_dek_priv;\n\nstruct mlx5_rate_limit {\n\tu32\t\t\trate;\n\tu32\t\t\tmax_burst_sz;\n\tu16\t\t\ttypical_pkt_sz;\n};\n\nstruct mlx5_rl_entry {\n\tu8 rl_raw[MLX5_ST_SZ_BYTES(set_pp_rate_limit_context)];\n\tu64 refcount;\n\tu16 index;\n\tu16 uid;\n\tu8 dedicated : 1;\n};\n\nstruct mlx5_rl_table {\n\t \n\tstruct mutex            rl_lock;\n\tu16                     max_size;\n\tu32                     max_rate;\n\tu32                     min_rate;\n\tstruct mlx5_rl_entry   *rl_entry;\n\tu64 refcount;\n};\n\nstruct mlx5_core_roce {\n\tstruct mlx5_flow_table *ft;\n\tstruct mlx5_flow_group *fg;\n\tstruct mlx5_flow_handle *allow_rule;\n};\n\nenum {\n\tMLX5_PRIV_FLAGS_DISABLE_IB_ADEV = 1 << 0,\n\tMLX5_PRIV_FLAGS_DISABLE_ALL_ADEV = 1 << 1,\n\t \n\tMLX5_PRIV_FLAGS_DETACH = 1 << 2,\n};\n\nstruct mlx5_adev {\n\tstruct auxiliary_device adev;\n\tstruct mlx5_core_dev *mdev;\n\tint idx;\n};\n\nstruct mlx5_debugfs_entries {\n\tstruct dentry *dbg_root;\n\tstruct dentry *qp_debugfs;\n\tstruct dentry *eq_debugfs;\n\tstruct dentry *cq_debugfs;\n\tstruct dentry *cmdif_debugfs;\n\tstruct dentry *pages_debugfs;\n\tstruct dentry *lag_debugfs;\n};\n\nenum mlx5_func_type {\n\tMLX5_PF,\n\tMLX5_VF,\n\tMLX5_SF,\n\tMLX5_HOST_PF,\n\tMLX5_EC_VF,\n\tMLX5_FUNC_TYPE_NUM,\n};\n\nstruct mlx5_ft_pool;\nstruct mlx5_priv {\n\t \n\tstruct mlx5_irq_table   *irq_table;\n\tstruct mlx5_eq_table\t*eq_table;\n\n\t \n\tstruct mlx5_nb          pg_nb;\n\tstruct workqueue_struct *pg_wq;\n\tstruct xarray           page_root_xa;\n\tatomic_t\t\treg_pages;\n\tstruct list_head\tfree_list;\n\tu32\t\t\tfw_pages;\n\tu32\t\t\tpage_counters[MLX5_FUNC_TYPE_NUM];\n\tu32\t\t\tfw_pages_alloc_failed;\n\tu32\t\t\tgive_pages_dropped;\n\tu32\t\t\treclaim_pages_discard;\n\n\tstruct mlx5_core_health health;\n\tstruct list_head\ttraps;\n\n\tstruct mlx5_debugfs_entries dbg;\n\n\t \n\t \n\tstruct mutex            alloc_mutex;\n\tint                     numa_node;\n\n\tstruct mutex            pgdir_mutex;\n\tstruct list_head        pgdir_list;\n\t \n\n\tstruct mlx5_adev       **adev;\n\tint\t\t\tadev_idx;\n\tint\t\t\tsw_vhca_id;\n\tstruct mlx5_events      *events;\n\n\tstruct mlx5_flow_steering *steering;\n\tstruct mlx5_mpfs        *mpfs;\n\tstruct mlx5_eswitch     *eswitch;\n\tstruct mlx5_core_sriov\tsriov;\n\tstruct mlx5_lag\t\t*lag;\n\tu32\t\t\tflags;\n\tstruct mlx5_devcom_dev\t*devc;\n\tstruct mlx5_fw_reset\t*fw_reset;\n\tstruct mlx5_core_roce\troce;\n\tstruct mlx5_fc_stats\t\tfc_stats;\n\tstruct mlx5_rl_table            rl_table;\n\tstruct mlx5_ft_pool\t\t*ft_pool;\n\n\tstruct mlx5_bfreg_data\t\tbfregs;\n\tstruct mlx5_uars_page\t       *uar;\n#ifdef CONFIG_MLX5_SF\n\tstruct mlx5_vhca_state_notifier *vhca_state_notifier;\n\tstruct mlx5_sf_dev_table *sf_dev_table;\n\tstruct mlx5_core_dev *parent_mdev;\n#endif\n#ifdef CONFIG_MLX5_SF_MANAGER\n\tstruct mlx5_sf_hw_table *sf_hw_table;\n\tstruct mlx5_sf_table *sf_table;\n#endif\n};\n\nenum mlx5_device_state {\n\tMLX5_DEVICE_STATE_UP = 1,\n\tMLX5_DEVICE_STATE_INTERNAL_ERROR,\n};\n\nenum mlx5_interface_state {\n\tMLX5_INTERFACE_STATE_UP = BIT(0),\n\tMLX5_BREAK_FW_WAIT = BIT(1),\n};\n\nenum mlx5_pci_status {\n\tMLX5_PCI_STATUS_DISABLED,\n\tMLX5_PCI_STATUS_ENABLED,\n};\n\nenum mlx5_pagefault_type_flags {\n\tMLX5_PFAULT_REQUESTOR = 1 << 0,\n\tMLX5_PFAULT_WRITE     = 1 << 1,\n\tMLX5_PFAULT_RDMA      = 1 << 2,\n};\n\nstruct mlx5_td {\n\t \n\tstruct mutex     list_lock;\n\tstruct list_head tirs_list;\n\tu32              tdn;\n};\n\nstruct mlx5e_resources {\n\tstruct mlx5e_hw_objs {\n\t\tu32                        pdn;\n\t\tstruct mlx5_td             td;\n\t\tu32\t\t\t   mkey;\n\t\tstruct mlx5_sq_bfreg       bfreg;\n\t} hw_objs;\n\tstruct net_device *uplink_netdev;\n\tstruct mutex uplink_netdev_lock;\n\tstruct mlx5_crypto_dek_priv *dek_priv;\n};\n\nenum mlx5_sw_icm_type {\n\tMLX5_SW_ICM_TYPE_STEERING,\n\tMLX5_SW_ICM_TYPE_HEADER_MODIFY,\n\tMLX5_SW_ICM_TYPE_HEADER_MODIFY_PATTERN,\n};\n\n#define MLX5_MAX_RESERVED_GIDS 8\n\nstruct mlx5_rsvd_gids {\n\tunsigned int start;\n\tunsigned int count;\n\tstruct ida ida;\n};\n\n#define MAX_PIN_NUM\t8\nstruct mlx5_pps {\n\tu8                         pin_caps[MAX_PIN_NUM];\n\tstruct work_struct         out_work;\n\tu64                        start[MAX_PIN_NUM];\n\tu8                         enabled;\n\tu64                        min_npps_period;\n\tu64                        min_out_pulse_duration_ns;\n};\n\nstruct mlx5_timer {\n\tstruct cyclecounter        cycles;\n\tstruct timecounter         tc;\n\tu32                        nominal_c_mult;\n\tunsigned long              overflow_period;\n\tstruct delayed_work        overflow_work;\n};\n\nstruct mlx5_clock {\n\tstruct mlx5_nb             pps_nb;\n\tseqlock_t                  lock;\n\tstruct hwtstamp_config     hwtstamp_config;\n\tstruct ptp_clock          *ptp;\n\tstruct ptp_clock_info      ptp_info;\n\tstruct mlx5_pps            pps_info;\n\tstruct mlx5_timer          timer;\n};\n\nstruct mlx5_dm;\nstruct mlx5_fw_tracer;\nstruct mlx5_vxlan;\nstruct mlx5_geneve;\nstruct mlx5_hv_vhca;\n\n#define MLX5_LOG_SW_ICM_BLOCK_SIZE(dev) (MLX5_CAP_DEV_MEM(dev, log_sw_icm_alloc_granularity))\n#define MLX5_SW_ICM_BLOCK_SIZE(dev) (1 << MLX5_LOG_SW_ICM_BLOCK_SIZE(dev))\n\nenum {\n\tMLX5_PROF_MASK_QP_SIZE\t\t= (u64)1 << 0,\n\tMLX5_PROF_MASK_MR_CACHE\t\t= (u64)1 << 1,\n};\n\nenum {\n\tMKEY_CACHE_LAST_STD_ENTRY = 20,\n\tMLX5_IMR_KSM_CACHE_ENTRY,\n\tMAX_MKEY_CACHE_ENTRIES\n};\n\nstruct mlx5_profile {\n\tu64\tmask;\n\tu8\tlog_max_qp;\n\tu8\tnum_cmd_caches;\n\tstruct {\n\t\tint\tsize;\n\t\tint\tlimit;\n\t} mr_cache[MAX_MKEY_CACHE_ENTRIES];\n};\n\nstruct mlx5_hca_cap {\n\tu32 cur[MLX5_UN_SZ_DW(hca_cap_union)];\n\tu32 max[MLX5_UN_SZ_DW(hca_cap_union)];\n};\n\nstruct mlx5_core_dev {\n\tstruct device *device;\n\tenum mlx5_coredev_type coredev_type;\n\tstruct pci_dev\t       *pdev;\n\t \n\tstruct mutex\t\tpci_status_mutex;\n\tenum mlx5_pci_status\tpci_status;\n\tu8\t\t\trev_id;\n\tchar\t\t\tboard_id[MLX5_BOARD_ID_LEN];\n\tstruct mlx5_cmd\t\tcmd;\n\tstruct {\n\t\tstruct mlx5_hca_cap *hca[MLX5_CAP_NUM];\n\t\tu32 pcam[MLX5_ST_SZ_DW(pcam_reg)];\n\t\tu32 mcam[MLX5_MCAM_REGS_NUM][MLX5_ST_SZ_DW(mcam_reg)];\n\t\tu32 fpga[MLX5_ST_SZ_DW(fpga_cap)];\n\t\tu32 qcam[MLX5_ST_SZ_DW(qcam_reg)];\n\t\tu8  embedded_cpu;\n\t} caps;\n\tstruct mlx5_timeouts\t*timeouts;\n\tu64\t\t\tsys_image_guid;\n\tphys_addr_t\t\tiseg_base;\n\tstruct mlx5_init_seg __iomem *iseg;\n\tphys_addr_t             bar_addr;\n\tenum mlx5_device_state\tstate;\n\t \n\tstruct mutex\t\tintf_state_mutex;\n\tstruct lock_class_key\tlock_key;\n\tunsigned long\t\tintf_state;\n\tstruct mlx5_priv\tpriv;\n\tstruct mlx5_profile\tprofile;\n\tu32\t\t\tissi;\n\tstruct mlx5e_resources  mlx5e_res;\n\tstruct mlx5_dm          *dm;\n\tstruct mlx5_vxlan       *vxlan;\n\tstruct mlx5_geneve      *geneve;\n\tstruct {\n\t\tstruct mlx5_rsvd_gids\treserved_gids;\n\t\tu32\t\t\troce_en;\n\t} roce;\n#ifdef CONFIG_MLX5_FPGA\n\tstruct mlx5_fpga_device *fpga;\n#endif\n\tstruct mlx5_clock        clock;\n\tstruct mlx5_ib_clock_info  *clock_info;\n\tstruct mlx5_fw_tracer   *tracer;\n\tstruct mlx5_rsc_dump    *rsc_dump;\n\tu32                      vsc_addr;\n\tstruct mlx5_hv_vhca\t*hv_vhca;\n\tstruct mlx5_hwmon\t*hwmon;\n\tu64\t\t\tnum_block_tc;\n\tu64\t\t\tnum_block_ipsec;\n#ifdef CONFIG_MLX5_MACSEC\n\tstruct mlx5_macsec_fs *macsec_fs;\n\t \n\tstruct blocking_notifier_head macsec_nh;\n#endif\n\tu64 num_ipsec_offloads;\n};\n\nstruct mlx5_db {\n\t__be32\t\t\t*db;\n\tunion {\n\t\tstruct mlx5_db_pgdir\t\t*pgdir;\n\t\tstruct mlx5_ib_user_db_page\t*user_page;\n\t}\t\t\tu;\n\tdma_addr_t\t\tdma;\n\tint\t\t\tindex;\n};\n\nenum {\n\tMLX5_COMP_EQ_SIZE = 1024,\n};\n\nenum {\n\tMLX5_PTYS_IB = 1 << 0,\n\tMLX5_PTYS_EN = 1 << 2,\n};\n\ntypedef void (*mlx5_cmd_cbk_t)(int status, void *context);\n\nenum {\n\tMLX5_CMD_ENT_STATE_PENDING_COMP,\n};\n\nstruct mlx5_cmd_work_ent {\n\tunsigned long\t\tstate;\n\tstruct mlx5_cmd_msg    *in;\n\tstruct mlx5_cmd_msg    *out;\n\tvoid\t\t       *uout;\n\tint\t\t\tuout_size;\n\tmlx5_cmd_cbk_t\t\tcallback;\n\tstruct delayed_work\tcb_timeout_work;\n\tvoid\t\t       *context;\n\tint\t\t\tidx;\n\tstruct completion\thandling;\n\tstruct completion\tdone;\n\tstruct mlx5_cmd        *cmd;\n\tstruct work_struct\twork;\n\tstruct mlx5_cmd_layout *lay;\n\tint\t\t\tret;\n\tint\t\t\tpage_queue;\n\tu8\t\t\tstatus;\n\tu8\t\t\ttoken;\n\tu64\t\t\tts1;\n\tu64\t\t\tts2;\n\tu16\t\t\top;\n\tbool\t\t\tpolling;\n\t \n\trefcount_t              refcnt;\n};\n\nenum phy_port_state {\n\tMLX5_AAA_111\n};\n\nstruct mlx5_hca_vport_context {\n\tu32\t\t\tfield_select;\n\tbool\t\t\tsm_virt_aware;\n\tbool\t\t\thas_smi;\n\tbool\t\t\thas_raw;\n\tenum port_state_policy\tpolicy;\n\tenum phy_port_state\tphys_state;\n\tenum ib_port_state\tvport_state;\n\tu8\t\t\tport_physical_state;\n\tu64\t\t\tsys_image_guid;\n\tu64\t\t\tport_guid;\n\tu64\t\t\tnode_guid;\n\tu32\t\t\tcap_mask1;\n\tu32\t\t\tcap_mask1_perm;\n\tu16\t\t\tcap_mask2;\n\tu16\t\t\tcap_mask2_perm;\n\tu16\t\t\tlid;\n\tu8\t\t\tinit_type_reply;  \n\tu8\t\t\tlmc;\n\tu8\t\t\tsubnet_timeout;\n\tu16\t\t\tsm_lid;\n\tu8\t\t\tsm_sl;\n\tu16\t\t\tqkey_violation_counter;\n\tu16\t\t\tpkey_violation_counter;\n\tbool\t\t\tgrh_required;\n};\n\n#define STRUCT_FIELD(header, field) \\\n\t.struct_offset_bytes = offsetof(struct ib_unpacked_ ## header, field),      \\\n\t.struct_size_bytes   = sizeof((struct ib_unpacked_ ## header *)0)->field\n\nextern struct dentry *mlx5_debugfs_root;\n\nstatic inline u16 fw_rev_maj(struct mlx5_core_dev *dev)\n{\n\treturn ioread32be(&dev->iseg->fw_rev) & 0xffff;\n}\n\nstatic inline u16 fw_rev_min(struct mlx5_core_dev *dev)\n{\n\treturn ioread32be(&dev->iseg->fw_rev) >> 16;\n}\n\nstatic inline u16 fw_rev_sub(struct mlx5_core_dev *dev)\n{\n\treturn ioread32be(&dev->iseg->cmdif_rev_fw_sub) & 0xffff;\n}\n\nstatic inline u32 mlx5_base_mkey(const u32 key)\n{\n\treturn key & 0xffffff00u;\n}\n\nstatic inline u32 wq_get_byte_sz(u8 log_sz, u8 log_stride)\n{\n\treturn ((u32)1 << log_sz) << log_stride;\n}\n\nstatic inline void mlx5_init_fbc_offset(struct mlx5_buf_list *frags,\n\t\t\t\t\tu8 log_stride, u8 log_sz,\n\t\t\t\t\tu16 strides_offset,\n\t\t\t\t\tstruct mlx5_frag_buf_ctrl *fbc)\n{\n\tfbc->frags      = frags;\n\tfbc->log_stride = log_stride;\n\tfbc->log_sz     = log_sz;\n\tfbc->sz_m1\t= (1 << fbc->log_sz) - 1;\n\tfbc->log_frag_strides = PAGE_SHIFT - fbc->log_stride;\n\tfbc->frag_sz_m1\t= (1 << fbc->log_frag_strides) - 1;\n\tfbc->strides_offset = strides_offset;\n}\n\nstatic inline void mlx5_init_fbc(struct mlx5_buf_list *frags,\n\t\t\t\t u8 log_stride, u8 log_sz,\n\t\t\t\t struct mlx5_frag_buf_ctrl *fbc)\n{\n\tmlx5_init_fbc_offset(frags, log_stride, log_sz, 0, fbc);\n}\n\nstatic inline void *mlx5_frag_buf_get_wqe(struct mlx5_frag_buf_ctrl *fbc,\n\t\t\t\t\t  u32 ix)\n{\n\tunsigned int frag;\n\n\tix  += fbc->strides_offset;\n\tfrag = ix >> fbc->log_frag_strides;\n\n\treturn fbc->frags[frag].buf + ((fbc->frag_sz_m1 & ix) << fbc->log_stride);\n}\n\nstatic inline u32\nmlx5_frag_buf_get_idx_last_contig_stride(struct mlx5_frag_buf_ctrl *fbc, u32 ix)\n{\n\tu32 last_frag_stride_idx = (ix + fbc->strides_offset) | fbc->frag_sz_m1;\n\n\treturn min_t(u32, last_frag_stride_idx - fbc->strides_offset, fbc->sz_m1);\n}\n\nenum {\n\tCMD_ALLOWED_OPCODE_ALL,\n};\n\nvoid mlx5_cmd_use_events(struct mlx5_core_dev *dev);\nvoid mlx5_cmd_use_polling(struct mlx5_core_dev *dev);\nvoid mlx5_cmd_allowed_opcode(struct mlx5_core_dev *dev, u16 opcode);\n\nstruct mlx5_async_ctx {\n\tstruct mlx5_core_dev *dev;\n\tatomic_t num_inflight;\n\tstruct completion inflight_done;\n};\n\nstruct mlx5_async_work;\n\ntypedef void (*mlx5_async_cbk_t)(int status, struct mlx5_async_work *context);\n\nstruct mlx5_async_work {\n\tstruct mlx5_async_ctx *ctx;\n\tmlx5_async_cbk_t user_callback;\n\tu16 opcode;  \n\tu16 op_mod;  \n\tvoid *out;  \n};\n\nvoid mlx5_cmd_init_async_ctx(struct mlx5_core_dev *dev,\n\t\t\t     struct mlx5_async_ctx *ctx);\nvoid mlx5_cmd_cleanup_async_ctx(struct mlx5_async_ctx *ctx);\nint mlx5_cmd_exec_cb(struct mlx5_async_ctx *ctx, void *in, int in_size,\n\t\t     void *out, int out_size, mlx5_async_cbk_t callback,\n\t\t     struct mlx5_async_work *work);\nvoid mlx5_cmd_out_err(struct mlx5_core_dev *dev, u16 opcode, u16 op_mod, void *out);\nint mlx5_cmd_do(struct mlx5_core_dev *dev, void *in, int in_size, void *out, int out_size);\nint mlx5_cmd_check(struct mlx5_core_dev *dev, int err, void *in, void *out);\nint mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,\n\t\t  int out_size);\n\n#define mlx5_cmd_exec_inout(dev, ifc_cmd, in, out)                             \\\n\t({                                                                     \\\n\t\tmlx5_cmd_exec(dev, in, MLX5_ST_SZ_BYTES(ifc_cmd##_in), out,    \\\n\t\t\t      MLX5_ST_SZ_BYTES(ifc_cmd##_out));                \\\n\t})\n\n#define mlx5_cmd_exec_in(dev, ifc_cmd, in)                                     \\\n\t({                                                                     \\\n\t\tu32 _out[MLX5_ST_SZ_DW(ifc_cmd##_out)] = {};                   \\\n\t\tmlx5_cmd_exec_inout(dev, ifc_cmd, in, _out);                   \\\n\t})\n\nint mlx5_cmd_exec_polling(struct mlx5_core_dev *dev, void *in, int in_size,\n\t\t\t  void *out, int out_size);\nbool mlx5_cmd_is_down(struct mlx5_core_dev *dev);\n\nvoid mlx5_core_uplink_netdev_set(struct mlx5_core_dev *mdev, struct net_device *netdev);\nvoid mlx5_core_uplink_netdev_event_replay(struct mlx5_core_dev *mdev);\n\nvoid mlx5_core_mp_event_replay(struct mlx5_core_dev *dev, u32 event, void *data);\n\nvoid mlx5_health_cleanup(struct mlx5_core_dev *dev);\nint mlx5_health_init(struct mlx5_core_dev *dev);\nvoid mlx5_start_health_poll(struct mlx5_core_dev *dev);\nvoid mlx5_stop_health_poll(struct mlx5_core_dev *dev, bool disable_health);\nvoid mlx5_start_health_fw_log_up(struct mlx5_core_dev *dev);\nvoid mlx5_drain_health_wq(struct mlx5_core_dev *dev);\nvoid mlx5_trigger_health_work(struct mlx5_core_dev *dev);\nint mlx5_frag_buf_alloc_node(struct mlx5_core_dev *dev, int size,\n\t\t\t     struct mlx5_frag_buf *buf, int node);\nvoid mlx5_frag_buf_free(struct mlx5_core_dev *dev, struct mlx5_frag_buf *buf);\nstruct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,\n\t\t\t\t\t\t      gfp_t flags, int npages);\nvoid mlx5_free_cmd_mailbox_chain(struct mlx5_core_dev *dev,\n\t\t\t\t struct mlx5_cmd_mailbox *head);\nint mlx5_core_create_mkey(struct mlx5_core_dev *dev, u32 *mkey, u32 *in,\n\t\t\t  int inlen);\nint mlx5_core_destroy_mkey(struct mlx5_core_dev *dev, u32 mkey);\nint mlx5_core_query_mkey(struct mlx5_core_dev *dev, u32 mkey, u32 *out,\n\t\t\t int outlen);\nint mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);\nint mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);\nint mlx5_pagealloc_init(struct mlx5_core_dev *dev);\nvoid mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);\nvoid mlx5_pagealloc_start(struct mlx5_core_dev *dev);\nvoid mlx5_pagealloc_stop(struct mlx5_core_dev *dev);\nvoid mlx5_pages_debugfs_init(struct mlx5_core_dev *dev);\nvoid mlx5_pages_debugfs_cleanup(struct mlx5_core_dev *dev);\nvoid mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,\n\t\t\t\t s32 npages, bool ec_function);\nint mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev, int boot);\nint mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev);\nvoid mlx5_register_debugfs(void);\nvoid mlx5_unregister_debugfs(void);\n\nvoid mlx5_fill_page_frag_array_perm(struct mlx5_frag_buf *buf, __be64 *pas, u8 perm);\nvoid mlx5_fill_page_frag_array(struct mlx5_frag_buf *frag_buf, __be64 *pas);\nint mlx5_comp_eqn_get(struct mlx5_core_dev *dev, u16 vecidx, int *eqn);\nint mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);\nint mlx5_core_detach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);\n\nstruct dentry *mlx5_debugfs_get_dev_root(struct mlx5_core_dev *dev);\nvoid mlx5_qp_debugfs_init(struct mlx5_core_dev *dev);\nvoid mlx5_qp_debugfs_cleanup(struct mlx5_core_dev *dev);\nint mlx5_access_reg(struct mlx5_core_dev *dev, void *data_in, int size_in,\n\t\t    void *data_out, int size_out, u16 reg_id, int arg,\n\t\t    int write, bool verbose);\nint mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,\n\t\t\t int size_in, void *data_out, int size_out,\n\t\t\t u16 reg_num, int arg, int write);\n\nint mlx5_db_alloc_node(struct mlx5_core_dev *dev, struct mlx5_db *db,\n\t\t       int node);\n\nstatic inline int mlx5_db_alloc(struct mlx5_core_dev *dev, struct mlx5_db *db)\n{\n\treturn mlx5_db_alloc_node(dev, db, dev->priv.numa_node);\n}\n\nvoid mlx5_db_free(struct mlx5_core_dev *dev, struct mlx5_db *db);\n\nconst char *mlx5_command_str(int command);\nvoid mlx5_cmdif_debugfs_init(struct mlx5_core_dev *dev);\nvoid mlx5_cmdif_debugfs_cleanup(struct mlx5_core_dev *dev);\nint mlx5_core_create_psv(struct mlx5_core_dev *dev, u32 pdn,\n\t\t\t int npsvs, u32 *sig_index);\nint mlx5_core_destroy_psv(struct mlx5_core_dev *dev, int psv_num);\n__be32 mlx5_core_get_terminate_scatter_list_mkey(struct mlx5_core_dev *dev);\nvoid mlx5_core_put_rsc(struct mlx5_core_rsc_common *common);\nint mlx5_query_odp_caps(struct mlx5_core_dev *dev,\n\t\t\tstruct mlx5_odp_caps *odp_caps);\n\nint mlx5_init_rl_table(struct mlx5_core_dev *dev);\nvoid mlx5_cleanup_rl_table(struct mlx5_core_dev *dev);\nint mlx5_rl_add_rate(struct mlx5_core_dev *dev, u16 *index,\n\t\t     struct mlx5_rate_limit *rl);\nvoid mlx5_rl_remove_rate(struct mlx5_core_dev *dev, struct mlx5_rate_limit *rl);\nbool mlx5_rl_is_in_range(struct mlx5_core_dev *dev, u32 rate);\nint mlx5_rl_add_rate_raw(struct mlx5_core_dev *dev, void *rl_in, u16 uid,\n\t\t\t bool dedicated_entry, u16 *index);\nvoid mlx5_rl_remove_rate_raw(struct mlx5_core_dev *dev, u16 index);\nbool mlx5_rl_are_equal(struct mlx5_rate_limit *rl_0,\n\t\t       struct mlx5_rate_limit *rl_1);\nint mlx5_alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,\n\t\t     bool map_wc, bool fast_path);\nvoid mlx5_free_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg);\n\nunsigned int mlx5_comp_vectors_max(struct mlx5_core_dev *dev);\nint mlx5_comp_vector_get_cpu(struct mlx5_core_dev *dev, int vector);\nunsigned int mlx5_core_reserved_gids_count(struct mlx5_core_dev *dev);\nint mlx5_core_roce_gid_set(struct mlx5_core_dev *dev, unsigned int index,\n\t\t\t   u8 roce_version, u8 roce_l3_type, const u8 *gid,\n\t\t\t   const u8 *mac, bool vlan, u16 vlan_id, u8 port_num);\n\nstatic inline u32 mlx5_mkey_to_idx(u32 mkey)\n{\n\treturn mkey >> 8;\n}\n\nstatic inline u32 mlx5_idx_to_mkey(u32 mkey_idx)\n{\n\treturn mkey_idx << 8;\n}\n\nstatic inline u8 mlx5_mkey_variant(u32 mkey)\n{\n\treturn mkey & 0xff;\n}\n\n \nint mlx5_notifier_register(struct mlx5_core_dev *dev, struct notifier_block *nb);\nint mlx5_notifier_unregister(struct mlx5_core_dev *dev, struct notifier_block *nb);\n\n \nint mlx5_eq_notifier_register(struct mlx5_core_dev *dev, struct mlx5_nb *nb);\nint mlx5_eq_notifier_unregister(struct mlx5_core_dev *dev, struct mlx5_nb *nb);\n\n \nint mlx5_blocking_notifier_register(struct mlx5_core_dev *dev, struct notifier_block *nb);\nint mlx5_blocking_notifier_unregister(struct mlx5_core_dev *dev, struct notifier_block *nb);\nint mlx5_blocking_notifier_call_chain(struct mlx5_core_dev *dev, unsigned int event,\n\t\t\t\t      void *data);\n\nint mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);\n\nint mlx5_cmd_create_vport_lag(struct mlx5_core_dev *dev);\nint mlx5_cmd_destroy_vport_lag(struct mlx5_core_dev *dev);\nbool mlx5_lag_is_roce(struct mlx5_core_dev *dev);\nbool mlx5_lag_is_sriov(struct mlx5_core_dev *dev);\nbool mlx5_lag_is_active(struct mlx5_core_dev *dev);\nbool mlx5_lag_mode_is_hash(struct mlx5_core_dev *dev);\nbool mlx5_lag_is_master(struct mlx5_core_dev *dev);\nbool mlx5_lag_is_shared_fdb(struct mlx5_core_dev *dev);\nbool mlx5_lag_is_mpesw(struct mlx5_core_dev *dev);\nstruct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);\nu8 mlx5_lag_get_slave_port(struct mlx5_core_dev *dev,\n\t\t\t   struct net_device *slave);\nint mlx5_lag_query_cong_counters(struct mlx5_core_dev *dev,\n\t\t\t\t u64 *values,\n\t\t\t\t int num_counters,\n\t\t\t\t size_t *offsets);\nstruct mlx5_core_dev *mlx5_lag_get_next_peer_mdev(struct mlx5_core_dev *dev, int *i);\n\n#define mlx5_lag_for_each_peer_mdev(dev, peer, i)\t\t\t\t\\\n\tfor (i = 0, peer = mlx5_lag_get_next_peer_mdev(dev, &i);\t\t\\\n\t     peer;\t\t\t\t\t\t\t\t\\\n\t     peer = mlx5_lag_get_next_peer_mdev(dev, &i))\n\nu8 mlx5_lag_get_num_ports(struct mlx5_core_dev *dev);\nstruct mlx5_uars_page *mlx5_get_uars_page(struct mlx5_core_dev *mdev);\nvoid mlx5_put_uars_page(struct mlx5_core_dev *mdev, struct mlx5_uars_page *up);\nint mlx5_dm_sw_icm_alloc(struct mlx5_core_dev *dev, enum mlx5_sw_icm_type type,\n\t\t\t u64 length, u32 log_alignment, u16 uid,\n\t\t\t phys_addr_t *addr, u32 *obj_id);\nint mlx5_dm_sw_icm_dealloc(struct mlx5_core_dev *dev, enum mlx5_sw_icm_type type,\n\t\t\t   u64 length, u16 uid, phys_addr_t addr, u32 obj_id);\n\nstruct mlx5_core_dev *mlx5_vf_get_core_dev(struct pci_dev *pdev);\nvoid mlx5_vf_put_core_dev(struct mlx5_core_dev *mdev);\n\nint mlx5_sriov_blocking_notifier_register(struct mlx5_core_dev *mdev,\n\t\t\t\t\t  int vf_id,\n\t\t\t\t\t  struct notifier_block *nb);\nvoid mlx5_sriov_blocking_notifier_unregister(struct mlx5_core_dev *mdev,\n\t\t\t\t\t     int vf_id,\n\t\t\t\t\t     struct notifier_block *nb);\n#ifdef CONFIG_MLX5_CORE_IPOIB\nstruct net_device *mlx5_rdma_netdev_alloc(struct mlx5_core_dev *mdev,\n\t\t\t\t\t  struct ib_device *ibdev,\n\t\t\t\t\t  const char *name,\n\t\t\t\t\t  void (*setup)(struct net_device *));\n#endif  \nint mlx5_rdma_rn_get_params(struct mlx5_core_dev *mdev,\n\t\t\t    struct ib_device *device,\n\t\t\t    struct rdma_netdev_alloc_params *params);\n\nenum {\n\tMLX5_PCI_DEV_IS_VF\t\t= 1 << 0,\n};\n\nstatic inline bool mlx5_core_is_pf(const struct mlx5_core_dev *dev)\n{\n\treturn dev->coredev_type == MLX5_COREDEV_PF;\n}\n\nstatic inline bool mlx5_core_is_vf(const struct mlx5_core_dev *dev)\n{\n\treturn dev->coredev_type == MLX5_COREDEV_VF;\n}\n\nstatic inline bool mlx5_core_is_ecpf(const struct mlx5_core_dev *dev)\n{\n\treturn dev->caps.embedded_cpu;\n}\n\nstatic inline bool\nmlx5_core_is_ecpf_esw_manager(const struct mlx5_core_dev *dev)\n{\n\treturn dev->caps.embedded_cpu && MLX5_CAP_GEN(dev, eswitch_manager);\n}\n\nstatic inline bool mlx5_ecpf_vport_exists(const struct mlx5_core_dev *dev)\n{\n\treturn mlx5_core_is_pf(dev) && MLX5_CAP_ESW(dev, ecpf_vport_exists);\n}\n\nstatic inline u16 mlx5_core_max_vfs(const struct mlx5_core_dev *dev)\n{\n\treturn dev->priv.sriov.max_vfs;\n}\n\nstatic inline int mlx5_lag_is_lacp_owner(struct mlx5_core_dev *dev)\n{\n\t \n\treturn  MLX5_CAP_GEN(dev, vport_group_manager) &&\n\t\t   (MLX5_CAP_GEN(dev, num_lag_ports) > 1) &&\n\t\t    MLX5_CAP_GEN(dev, lag_master);\n}\n\nstatic inline u16 mlx5_core_max_ec_vfs(const struct mlx5_core_dev *dev)\n{\n\treturn dev->priv.sriov.max_ec_vfs;\n}\n\nstatic inline int mlx5_get_gid_table_len(u16 param)\n{\n\tif (param > 4) {\n\t\tpr_warn(\"gid table length is zero\\n\");\n\t\treturn 0;\n\t}\n\n\treturn 8 * (1 << param);\n}\n\nstatic inline bool mlx5_rl_is_supported(struct mlx5_core_dev *dev)\n{\n\treturn !!(dev->priv.rl_table.max_size);\n}\n\nstatic inline int mlx5_core_is_mp_slave(struct mlx5_core_dev *dev)\n{\n\treturn MLX5_CAP_GEN(dev, affiliate_nic_vport_criteria) &&\n\t       MLX5_CAP_GEN(dev, num_vhca_ports) <= 1;\n}\n\nstatic inline int mlx5_core_is_mp_master(struct mlx5_core_dev *dev)\n{\n\treturn MLX5_CAP_GEN(dev, num_vhca_ports) > 1;\n}\n\nstatic inline int mlx5_core_mp_enabled(struct mlx5_core_dev *dev)\n{\n\treturn mlx5_core_is_mp_slave(dev) ||\n\t       mlx5_core_is_mp_master(dev);\n}\n\nstatic inline int mlx5_core_native_port_num(struct mlx5_core_dev *dev)\n{\n\tif (!mlx5_core_mp_enabled(dev))\n\t\treturn 1;\n\n\treturn MLX5_CAP_GEN(dev, native_port_num);\n}\n\nstatic inline int mlx5_get_dev_index(struct mlx5_core_dev *dev)\n{\n\tint idx = MLX5_CAP_GEN(dev, native_port_num);\n\n\tif (idx >= 1 && idx <= MLX5_MAX_PORTS)\n\t\treturn idx - 1;\n\telse\n\t\treturn PCI_FUNC(dev->pdev->devfn);\n}\n\nenum {\n\tMLX5_TRIGGERED_CMD_COMP = (u64)1 << 32,\n};\n\nbool mlx5_is_roce_on(struct mlx5_core_dev *dev);\n\nstatic inline bool mlx5_get_roce_state(struct mlx5_core_dev *dev)\n{\n\tif (MLX5_CAP_GEN(dev, roce_rw_supported))\n\t\treturn MLX5_CAP_GEN(dev, roce);\n\n\t \n\treturn mlx5_is_roce_on(dev);\n}\n\n#ifdef CONFIG_MLX5_MACSEC\nstatic inline bool mlx5e_is_macsec_device(const struct mlx5_core_dev *mdev)\n{\n\tif (!(MLX5_CAP_GEN_64(mdev, general_obj_types) &\n\t    MLX5_GENERAL_OBJ_TYPES_CAP_MACSEC_OFFLOAD))\n\t\treturn false;\n\n\tif (!MLX5_CAP_GEN(mdev, log_max_dek))\n\t\treturn false;\n\n\tif (!MLX5_CAP_MACSEC(mdev, log_max_macsec_offload))\n\t\treturn false;\n\n\tif (!MLX5_CAP_FLOWTABLE_NIC_RX(mdev, macsec_decrypt) ||\n\t    !MLX5_CAP_FLOWTABLE_NIC_RX(mdev, reformat_remove_macsec))\n\t\treturn false;\n\n\tif (!MLX5_CAP_FLOWTABLE_NIC_TX(mdev, macsec_encrypt) ||\n\t    !MLX5_CAP_FLOWTABLE_NIC_TX(mdev, reformat_add_macsec))\n\t\treturn false;\n\n\tif (!MLX5_CAP_MACSEC(mdev, macsec_crypto_esp_aes_gcm_128_encrypt) &&\n\t    !MLX5_CAP_MACSEC(mdev, macsec_crypto_esp_aes_gcm_256_encrypt))\n\t\treturn false;\n\n\tif (!MLX5_CAP_MACSEC(mdev, macsec_crypto_esp_aes_gcm_128_decrypt) &&\n\t    !MLX5_CAP_MACSEC(mdev, macsec_crypto_esp_aes_gcm_256_decrypt))\n\t\treturn false;\n\n\treturn true;\n}\n\n#define NIC_RDMA_BOTH_DIRS_CAPS (MLX5_FT_NIC_RX_2_NIC_RX_RDMA | MLX5_FT_NIC_TX_RDMA_2_NIC_TX)\n\nstatic inline bool mlx5_is_macsec_roce_supported(struct mlx5_core_dev *mdev)\n{\n\tif (((MLX5_CAP_GEN_2(mdev, flow_table_type_2_type) &\n\t     NIC_RDMA_BOTH_DIRS_CAPS) != NIC_RDMA_BOTH_DIRS_CAPS) ||\n\t     !MLX5_CAP_FLOWTABLE_RDMA_TX(mdev, max_modify_header_actions) ||\n\t     !mlx5e_is_macsec_device(mdev) || !mdev->macsec_fs)\n\t\treturn false;\n\n\treturn true;\n}\n#endif\n\nenum {\n\tMLX5_OCTWORD = 16,\n};\n\nstruct msi_map mlx5_msix_alloc(struct mlx5_core_dev *dev,\n\t\t\t       irqreturn_t (*handler)(int, void *),\n\t\t\t       const struct irq_affinity_desc *affdesc,\n\t\t\t       const char *name);\nvoid mlx5_msix_free(struct mlx5_core_dev *dev, struct msi_map map);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}