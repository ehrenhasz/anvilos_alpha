{
  "module_name": "host1x.h",
  "hash_id": "fe93416b76f63a859a3381c690bb6c5b5c40aac2ab2ffe63904240b87560ed6a",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/host1x.h",
  "human_readable_source": " \n \n\n#ifndef __LINUX_HOST1X_H\n#define __LINUX_HOST1X_H\n\n#include <linux/device.h>\n#include <linux/dma-direction.h>\n#include <linux/dma-fence.h>\n#include <linux/spinlock.h>\n#include <linux/types.h>\n\nenum host1x_class {\n\tHOST1X_CLASS_HOST1X = 0x1,\n\tHOST1X_CLASS_GR2D = 0x51,\n\tHOST1X_CLASS_GR2D_SB = 0x52,\n\tHOST1X_CLASS_VIC = 0x5D,\n\tHOST1X_CLASS_GR3D = 0x60,\n\tHOST1X_CLASS_NVDEC = 0xF0,\n\tHOST1X_CLASS_NVDEC1 = 0xF5,\n};\n\nstruct host1x;\nstruct host1x_client;\nstruct iommu_group;\n\nu64 host1x_get_dma_mask(struct host1x *host1x);\n\n \nstruct host1x_bo_cache {\n\tstruct list_head mappings;\n\tstruct mutex lock;\n};\n\nstatic inline void host1x_bo_cache_init(struct host1x_bo_cache *cache)\n{\n\tINIT_LIST_HEAD(&cache->mappings);\n\tmutex_init(&cache->lock);\n}\n\nstatic inline void host1x_bo_cache_destroy(struct host1x_bo_cache *cache)\n{\n\t \n\tmutex_destroy(&cache->lock);\n}\n\n \nstruct host1x_client_ops {\n\tint (*early_init)(struct host1x_client *client);\n\tint (*init)(struct host1x_client *client);\n\tint (*exit)(struct host1x_client *client);\n\tint (*late_exit)(struct host1x_client *client);\n\tint (*suspend)(struct host1x_client *client);\n\tint (*resume)(struct host1x_client *client);\n};\n\n \nstruct host1x_client {\n\tstruct list_head list;\n\tstruct device *host;\n\tstruct device *dev;\n\tstruct iommu_group *group;\n\n\tconst struct host1x_client_ops *ops;\n\n\tenum host1x_class class;\n\tstruct host1x_channel *channel;\n\n\tstruct host1x_syncpt **syncpts;\n\tunsigned int num_syncpts;\n\n\tstruct host1x_client *parent;\n\tunsigned int usecount;\n\tstruct mutex lock;\n\n\tstruct host1x_bo_cache cache;\n};\n\n \n\nstruct host1x_bo;\nstruct sg_table;\n\nstruct host1x_bo_mapping {\n\tstruct kref ref;\n\tstruct dma_buf_attachment *attach;\n\tenum dma_data_direction direction;\n\tstruct list_head list;\n\tstruct host1x_bo *bo;\n\tstruct sg_table *sgt;\n\tunsigned int chunks;\n\tstruct device *dev;\n\tdma_addr_t phys;\n\tsize_t size;\n\n\tstruct host1x_bo_cache *cache;\n\tstruct list_head entry;\n};\n\nstatic inline struct host1x_bo_mapping *to_host1x_bo_mapping(struct kref *ref)\n{\n\treturn container_of(ref, struct host1x_bo_mapping, ref);\n}\n\nstruct host1x_bo_ops {\n\tstruct host1x_bo *(*get)(struct host1x_bo *bo);\n\tvoid (*put)(struct host1x_bo *bo);\n\tstruct host1x_bo_mapping *(*pin)(struct device *dev, struct host1x_bo *bo,\n\t\t\t\t\t enum dma_data_direction dir);\n\tvoid (*unpin)(struct host1x_bo_mapping *map);\n\tvoid *(*mmap)(struct host1x_bo *bo);\n\tvoid (*munmap)(struct host1x_bo *bo, void *addr);\n};\n\nstruct host1x_bo {\n\tconst struct host1x_bo_ops *ops;\n\tstruct list_head mappings;\n\tspinlock_t lock;\n};\n\nstatic inline void host1x_bo_init(struct host1x_bo *bo,\n\t\t\t\t  const struct host1x_bo_ops *ops)\n{\n\tINIT_LIST_HEAD(&bo->mappings);\n\tspin_lock_init(&bo->lock);\n\tbo->ops = ops;\n}\n\nstatic inline struct host1x_bo *host1x_bo_get(struct host1x_bo *bo)\n{\n\treturn bo->ops->get(bo);\n}\n\nstatic inline void host1x_bo_put(struct host1x_bo *bo)\n{\n\tbo->ops->put(bo);\n}\n\nstruct host1x_bo_mapping *host1x_bo_pin(struct device *dev, struct host1x_bo *bo,\n\t\t\t\t\tenum dma_data_direction dir,\n\t\t\t\t\tstruct host1x_bo_cache *cache);\nvoid host1x_bo_unpin(struct host1x_bo_mapping *map);\n\nstatic inline void *host1x_bo_mmap(struct host1x_bo *bo)\n{\n\treturn bo->ops->mmap(bo);\n}\n\nstatic inline void host1x_bo_munmap(struct host1x_bo *bo, void *addr)\n{\n\tbo->ops->munmap(bo, addr);\n}\n\n \n\n#define HOST1X_SYNCPT_CLIENT_MANAGED\t(1 << 0)\n#define HOST1X_SYNCPT_HAS_BASE\t\t(1 << 1)\n\nstruct host1x_syncpt_base;\nstruct host1x_syncpt;\nstruct host1x;\n\nstruct host1x_syncpt *host1x_syncpt_get_by_id(struct host1x *host, u32 id);\nstruct host1x_syncpt *host1x_syncpt_get_by_id_noref(struct host1x *host, u32 id);\nstruct host1x_syncpt *host1x_syncpt_get(struct host1x_syncpt *sp);\nu32 host1x_syncpt_id(struct host1x_syncpt *sp);\nu32 host1x_syncpt_read_min(struct host1x_syncpt *sp);\nu32 host1x_syncpt_read_max(struct host1x_syncpt *sp);\nu32 host1x_syncpt_read(struct host1x_syncpt *sp);\nint host1x_syncpt_incr(struct host1x_syncpt *sp);\nu32 host1x_syncpt_incr_max(struct host1x_syncpt *sp, u32 incrs);\nint host1x_syncpt_wait(struct host1x_syncpt *sp, u32 thresh, long timeout,\n\t\t       u32 *value);\nstruct host1x_syncpt *host1x_syncpt_request(struct host1x_client *client,\n\t\t\t\t\t    unsigned long flags);\nvoid host1x_syncpt_put(struct host1x_syncpt *sp);\nstruct host1x_syncpt *host1x_syncpt_alloc(struct host1x *host,\n\t\t\t\t\t  unsigned long flags,\n\t\t\t\t\t  const char *name);\n\nstruct host1x_syncpt_base *host1x_syncpt_get_base(struct host1x_syncpt *sp);\nu32 host1x_syncpt_base_id(struct host1x_syncpt_base *base);\n\nvoid host1x_syncpt_release_vblank_reservation(struct host1x_client *client,\n\t\t\t\t\t      u32 syncpt_id);\n\nstruct dma_fence *host1x_fence_create(struct host1x_syncpt *sp, u32 threshold,\n\t\t\t\t      bool timeout);\nvoid host1x_fence_cancel(struct dma_fence *fence);\n\n \n\nstruct host1x_channel;\nstruct host1x_job;\n\nstruct host1x_channel *host1x_channel_request(struct host1x_client *client);\nstruct host1x_channel *host1x_channel_get(struct host1x_channel *channel);\nvoid host1x_channel_stop(struct host1x_channel *channel);\nvoid host1x_channel_put(struct host1x_channel *channel);\nint host1x_job_submit(struct host1x_job *job);\n\n \n\n#define HOST1X_RELOC_READ\t(1 << 0)\n#define HOST1X_RELOC_WRITE\t(1 << 1)\n\nstruct host1x_reloc {\n\tstruct {\n\t\tstruct host1x_bo *bo;\n\t\tunsigned long offset;\n\t} cmdbuf;\n\tstruct {\n\t\tstruct host1x_bo *bo;\n\t\tunsigned long offset;\n\t} target;\n\tunsigned long shift;\n\tunsigned long flags;\n};\n\nstruct host1x_job {\n\t \n\tstruct kref ref;\n\n\t \n\tstruct list_head list;\n\n\t \n\tstruct host1x_channel *channel;\n\n\t \n\tstruct host1x_client *client;\n\n\t \n\tstruct host1x_job_cmd *cmds;\n\tunsigned int num_cmds;\n\n\t \n\tstruct host1x_reloc *relocs;\n\tunsigned int num_relocs;\n\tstruct host1x_job_unpin_data *unpins;\n\tunsigned int num_unpins;\n\n\tdma_addr_t *addr_phys;\n\tdma_addr_t *gather_addr_phys;\n\tdma_addr_t *reloc_addr_phys;\n\n\t \n\tstruct host1x_syncpt *syncpt;\n\tu32 syncpt_incrs;\n\tu32 syncpt_end;\n\n\t \n\tstruct dma_fence *fence;\n\tstruct dma_fence_cb fence_cb;\n\n\t \n\tunsigned int timeout;\n\n\t \n\tbool cancelled;\n\n\t \n\tunsigned int first_get;\n\tunsigned int num_slots;\n\n\t \n\tsize_t gather_copy_size;\n\tdma_addr_t gather_copy;\n\tu8 *gather_copy_mapped;\n\n\t \n\tint (*is_addr_reg)(struct device *dev, u32 class, u32 reg);\n\n\t \n\tint (*is_valid_class)(u32 class);\n\n\t \n\tu32 class;\n\n\t \n\tbool serialize;\n\n\t \n\tbool syncpt_recovery;\n\n\t \n\tvoid (*release)(struct host1x_job *job);\n\tvoid *user_data;\n\n\t \n\tbool enable_firewall;\n\n\t \n\t \n\tstruct host1x_memory_context *memory_context;\n\t \n\tu32 engine_fallback_streamid;\n\t \n\tu32 engine_streamid_offset;\n};\n\nstruct host1x_job *host1x_job_alloc(struct host1x_channel *ch,\n\t\t\t\t    u32 num_cmdbufs, u32 num_relocs,\n\t\t\t\t    bool skip_firewall);\nvoid host1x_job_add_gather(struct host1x_job *job, struct host1x_bo *bo,\n\t\t\t   unsigned int words, unsigned int offset);\nvoid host1x_job_add_wait(struct host1x_job *job, u32 id, u32 thresh,\n\t\t\t bool relative, u32 next_class);\nstruct host1x_job *host1x_job_get(struct host1x_job *job);\nvoid host1x_job_put(struct host1x_job *job);\nint host1x_job_pin(struct host1x_job *job, struct device *dev);\nvoid host1x_job_unpin(struct host1x_job *job);\n\n \n\nstruct host1x_device;\n\n \nstruct host1x_driver {\n\tstruct device_driver driver;\n\n\tconst struct of_device_id *subdevs;\n\tstruct list_head list;\n\n\tint (*probe)(struct host1x_device *device);\n\tint (*remove)(struct host1x_device *device);\n\tvoid (*shutdown)(struct host1x_device *device);\n};\n\nstatic inline struct host1x_driver *\nto_host1x_driver(struct device_driver *driver)\n{\n\treturn container_of(driver, struct host1x_driver, driver);\n}\n\nint host1x_driver_register_full(struct host1x_driver *driver,\n\t\t\t\tstruct module *owner);\nvoid host1x_driver_unregister(struct host1x_driver *driver);\n\n#define host1x_driver_register(driver) \\\n\thost1x_driver_register_full(driver, THIS_MODULE)\n\nstruct host1x_device {\n\tstruct host1x_driver *driver;\n\tstruct list_head list;\n\tstruct device dev;\n\n\tstruct mutex subdevs_lock;\n\tstruct list_head subdevs;\n\tstruct list_head active;\n\n\tstruct mutex clients_lock;\n\tstruct list_head clients;\n\n\tbool registered;\n\n\tstruct device_dma_parameters dma_parms;\n};\n\nstatic inline struct host1x_device *to_host1x_device(struct device *dev)\n{\n\treturn container_of(dev, struct host1x_device, dev);\n}\n\nint host1x_device_init(struct host1x_device *device);\nint host1x_device_exit(struct host1x_device *device);\n\nvoid __host1x_client_init(struct host1x_client *client, struct lock_class_key *key);\nvoid host1x_client_exit(struct host1x_client *client);\n\n#define host1x_client_init(client)\t\t\t\\\n\t({\t\t\t\t\t\t\\\n\t\tstatic struct lock_class_key __key;\t\\\n\t\t__host1x_client_init(client, &__key);\t\\\n\t})\n\nint __host1x_client_register(struct host1x_client *client);\n\n \n#define host1x_client_register(client)\t\t\t\\\n\t({\t\t\t\t\t\t\\\n\t\tstatic struct lock_class_key __key;\t\\\n\t\t__host1x_client_init(client, &__key);\t\\\n\t\t__host1x_client_register(client);\t\\\n\t})\n\nvoid host1x_client_unregister(struct host1x_client *client);\n\nint host1x_client_suspend(struct host1x_client *client);\nint host1x_client_resume(struct host1x_client *client);\n\nstruct tegra_mipi_device;\n\nstruct tegra_mipi_device *tegra_mipi_request(struct device *device,\n\t\t\t\t\t     struct device_node *np);\nvoid tegra_mipi_free(struct tegra_mipi_device *device);\nint tegra_mipi_enable(struct tegra_mipi_device *device);\nint tegra_mipi_disable(struct tegra_mipi_device *device);\nint tegra_mipi_start_calibration(struct tegra_mipi_device *device);\nint tegra_mipi_finish_calibration(struct tegra_mipi_device *device);\n\n \n\nstruct host1x_memory_context {\n\tstruct host1x *host;\n\n\trefcount_t ref;\n\tstruct pid *owner;\n\n\tstruct device dev;\n\tu64 dma_mask;\n\tu32 stream_id;\n};\n\n#ifdef CONFIG_IOMMU_API\nstruct host1x_memory_context *host1x_memory_context_alloc(struct host1x *host1x,\n\t\t\t\t\t\t\t  struct device *dev,\n\t\t\t\t\t\t\t  struct pid *pid);\nvoid host1x_memory_context_get(struct host1x_memory_context *cd);\nvoid host1x_memory_context_put(struct host1x_memory_context *cd);\n#else\nstatic inline struct host1x_memory_context *host1x_memory_context_alloc(struct host1x *host1x,\n\t\t\t\t\t\t\t\t\tstruct device *dev,\n\t\t\t\t\t\t\t\t\tstruct pid *pid)\n{\n\treturn NULL;\n}\n\nstatic inline void host1x_memory_context_get(struct host1x_memory_context *cd)\n{\n}\n\nstatic inline void host1x_memory_context_put(struct host1x_memory_context *cd)\n{\n}\n#endif\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}