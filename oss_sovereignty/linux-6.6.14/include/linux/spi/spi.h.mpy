{
  "module_name": "spi.h",
  "hash_id": "a20545fcec9aa75033be2f4da3609227a1f39214ef6829532752d956bdabd0f9",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/spi/spi.h",
  "human_readable_source": " \n\n#ifndef __LINUX_SPI_H\n#define __LINUX_SPI_H\n\n#include <linux/acpi.h>\n#include <linux/bits.h>\n#include <linux/completion.h>\n#include <linux/device.h>\n#include <linux/gpio/consumer.h>\n#include <linux/kthread.h>\n#include <linux/mod_devicetable.h>\n#include <linux/overflow.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/u64_stats_sync.h>\n\n#include <uapi/linux/spi/spi.h>\n\nstruct dma_chan;\nstruct software_node;\nstruct ptp_system_timestamp;\nstruct spi_controller;\nstruct spi_transfer;\nstruct spi_controller_mem_ops;\nstruct spi_controller_mem_caps;\nstruct spi_message;\n\n \nextern struct bus_type spi_bus_type;\n\n \nstruct spi_statistics {\n\tstruct u64_stats_sync\tsyncp;\n\n\tu64_stats_t\t\tmessages;\n\tu64_stats_t\t\ttransfers;\n\tu64_stats_t\t\terrors;\n\tu64_stats_t\t\ttimedout;\n\n\tu64_stats_t\t\tspi_sync;\n\tu64_stats_t\t\tspi_sync_immediate;\n\tu64_stats_t\t\tspi_async;\n\n\tu64_stats_t\t\tbytes;\n\tu64_stats_t\t\tbytes_rx;\n\tu64_stats_t\t\tbytes_tx;\n\n#define SPI_STATISTICS_HISTO_SIZE 17\n\tu64_stats_t\ttransfer_bytes_histo[SPI_STATISTICS_HISTO_SIZE];\n\n\tu64_stats_t\ttransfers_split_maxsize;\n};\n\n#define SPI_STATISTICS_ADD_TO_FIELD(pcpu_stats, field, count)\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tstruct spi_statistics *__lstats;\t\t\t\\\n\t\tget_cpu();\t\t\t\t\t\t\\\n\t\t__lstats = this_cpu_ptr(pcpu_stats);\t\t\t\\\n\t\tu64_stats_update_begin(&__lstats->syncp);\t\t\\\n\t\tu64_stats_add(&__lstats->field, count);\t\t\t\\\n\t\tu64_stats_update_end(&__lstats->syncp);\t\t\t\\\n\t\tput_cpu();\t\t\t\t\t\t\\\n\t} while (0)\n\n#define SPI_STATISTICS_INCREMENT_FIELD(pcpu_stats, field)\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tstruct spi_statistics *__lstats;\t\t\t\\\n\t\tget_cpu();\t\t\t\t\t\t\\\n\t\t__lstats = this_cpu_ptr(pcpu_stats);\t\t\t\\\n\t\tu64_stats_update_begin(&__lstats->syncp);\t\t\\\n\t\tu64_stats_inc(&__lstats->field);\t\t\t\\\n\t\tu64_stats_update_end(&__lstats->syncp);\t\t\t\\\n\t\tput_cpu();\t\t\t\t\t\t\\\n\t} while (0)\n\n \nstruct spi_delay {\n#define SPI_DELAY_UNIT_USECS\t0\n#define SPI_DELAY_UNIT_NSECS\t1\n#define SPI_DELAY_UNIT_SCK\t2\n\tu16\tvalue;\n\tu8\tunit;\n};\n\nextern int spi_delay_to_ns(struct spi_delay *_delay, struct spi_transfer *xfer);\nextern int spi_delay_exec(struct spi_delay *_delay, struct spi_transfer *xfer);\nextern void spi_transfer_cs_change_delay_exec(struct spi_message *msg,\n\t\t\t\t\t\t  struct spi_transfer *xfer);\n\n \nstruct spi_device {\n\tstruct device\t\tdev;\n\tstruct spi_controller\t*controller;\n\tstruct spi_controller\t*master;\t \n\tu32\t\t\tmax_speed_hz;\n\tu8\t\t\tchip_select;\n\tu8\t\t\tbits_per_word;\n\tbool\t\t\trt;\n#define SPI_NO_TX\t\tBIT(31)\t\t \n#define SPI_NO_RX\t\tBIT(30)\t\t \n\t \n#define SPI_TPM_HW_FLOW\t\tBIT(29)\t\t \n\t \n#define SPI_MODE_KERNEL_MASK\t(~(BIT(29) - 1))\n\tu32\t\t\tmode;\n\tint\t\t\tirq;\n\tvoid\t\t\t*controller_state;\n\tvoid\t\t\t*controller_data;\n\tchar\t\t\tmodalias[SPI_NAME_SIZE];\n\tconst char\t\t*driver_override;\n\tstruct gpio_desc\t*cs_gpiod;\t \n\tstruct spi_delay\tword_delay;  \n\t \n\tstruct spi_delay\tcs_setup;\n\tstruct spi_delay\tcs_hold;\n\tstruct spi_delay\tcs_inactive;\n\n\t \n\tstruct spi_statistics __percpu\t*pcpu_statistics;\n\n\t \n};\n\n \nstatic_assert((SPI_MODE_KERNEL_MASK & SPI_MODE_USER_MASK) == 0,\n\t      \"SPI_MODE_USER_MASK & SPI_MODE_KERNEL_MASK must not overlap\");\n\nstatic inline struct spi_device *to_spi_device(const struct device *dev)\n{\n\treturn dev ? container_of(dev, struct spi_device, dev) : NULL;\n}\n\n \nstatic inline struct spi_device *spi_dev_get(struct spi_device *spi)\n{\n\treturn (spi && get_device(&spi->dev)) ? spi : NULL;\n}\n\nstatic inline void spi_dev_put(struct spi_device *spi)\n{\n\tif (spi)\n\t\tput_device(&spi->dev);\n}\n\n \nstatic inline void *spi_get_ctldata(const struct spi_device *spi)\n{\n\treturn spi->controller_state;\n}\n\nstatic inline void spi_set_ctldata(struct spi_device *spi, void *state)\n{\n\tspi->controller_state = state;\n}\n\n \n\nstatic inline void spi_set_drvdata(struct spi_device *spi, void *data)\n{\n\tdev_set_drvdata(&spi->dev, data);\n}\n\nstatic inline void *spi_get_drvdata(const struct spi_device *spi)\n{\n\treturn dev_get_drvdata(&spi->dev);\n}\n\nstatic inline u8 spi_get_chipselect(const struct spi_device *spi, u8 idx)\n{\n\treturn spi->chip_select;\n}\n\nstatic inline void spi_set_chipselect(struct spi_device *spi, u8 idx, u8 chipselect)\n{\n\tspi->chip_select = chipselect;\n}\n\nstatic inline struct gpio_desc *spi_get_csgpiod(const struct spi_device *spi, u8 idx)\n{\n\treturn spi->cs_gpiod;\n}\n\nstatic inline void spi_set_csgpiod(struct spi_device *spi, u8 idx, struct gpio_desc *csgpiod)\n{\n\tspi->cs_gpiod = csgpiod;\n}\n\n \nstruct spi_driver {\n\tconst struct spi_device_id *id_table;\n\tint\t\t\t(*probe)(struct spi_device *spi);\n\tvoid\t\t\t(*remove)(struct spi_device *spi);\n\tvoid\t\t\t(*shutdown)(struct spi_device *spi);\n\tstruct device_driver\tdriver;\n};\n\nstatic inline struct spi_driver *to_spi_driver(struct device_driver *drv)\n{\n\treturn drv ? container_of(drv, struct spi_driver, driver) : NULL;\n}\n\nextern int __spi_register_driver(struct module *owner, struct spi_driver *sdrv);\n\n \nstatic inline void spi_unregister_driver(struct spi_driver *sdrv)\n{\n\tif (sdrv)\n\t\tdriver_unregister(&sdrv->driver);\n}\n\nextern struct spi_device *spi_new_ancillary_device(struct spi_device *spi, u8 chip_select);\n\n \n#define spi_register_driver(driver) \\\n\t__spi_register_driver(THIS_MODULE, driver)\n\n \n#define module_spi_driver(__spi_driver) \\\n\tmodule_driver(__spi_driver, spi_register_driver, \\\n\t\t\tspi_unregister_driver)\n\n \nstruct spi_controller {\n\tstruct device\tdev;\n\n\tstruct list_head list;\n\n\t \n\ts16\t\t\tbus_num;\n\n\t \n\tu16\t\t\tnum_chipselect;\n\n\t \n\tu16\t\t\tdma_alignment;\n\n\t \n\tu32\t\t\tmode_bits;\n\n\t \n\tu32\t\t\tbuswidth_override_bits;\n\n\t \n\tu32\t\t\tbits_per_word_mask;\n#define SPI_BPW_MASK(bits) BIT((bits) - 1)\n#define SPI_BPW_RANGE_MASK(min, max) GENMASK((max) - 1, (min) - 1)\n\n\t \n\tu32\t\t\tmin_speed_hz;\n\tu32\t\t\tmax_speed_hz;\n\n\t \n\tu16\t\t\tflags;\n#define SPI_CONTROLLER_HALF_DUPLEX\tBIT(0)\t \n#define SPI_CONTROLLER_NO_RX\t\tBIT(1)\t \n#define SPI_CONTROLLER_NO_TX\t\tBIT(2)\t \n#define SPI_CONTROLLER_MUST_RX\t\tBIT(3)\t \n#define SPI_CONTROLLER_MUST_TX\t\tBIT(4)\t \n#define SPI_CONTROLLER_GPIO_SS\t\tBIT(5)\t \n#define SPI_CONTROLLER_SUSPENDED\tBIT(6)\t \n\n\t \n\tbool\t\t\tdevm_allocated;\n\n\tunion {\n\t\t \n\t\tbool\t\t\tslave;\n\t\t \n\t\tbool\t\t\ttarget;\n\t};\n\n\t \n\tsize_t (*max_transfer_size)(struct spi_device *spi);\n\tsize_t (*max_message_size)(struct spi_device *spi);\n\n\t \n\tstruct mutex\t\tio_mutex;\n\n\t \n\tstruct mutex\t\tadd_lock;\n\n\t \n\tspinlock_t\t\tbus_lock_spinlock;\n\tstruct mutex\t\tbus_lock_mutex;\n\n\t \n\tbool\t\t\tbus_lock_flag;\n\n\t \n\tint\t\t\t(*setup)(struct spi_device *spi);\n\n\t \n\tint (*set_cs_timing)(struct spi_device *spi);\n\n\t \n\tint\t\t\t(*transfer)(struct spi_device *spi,\n\t\t\t\t\t\tstruct spi_message *mesg);\n\n\t \n\tvoid\t\t\t(*cleanup)(struct spi_device *spi);\n\n\t \n\tbool\t\t\t(*can_dma)(struct spi_controller *ctlr,\n\t\t\t\t\t   struct spi_device *spi,\n\t\t\t\t\t   struct spi_transfer *xfer);\n\tstruct device *dma_map_dev;\n\tstruct device *cur_rx_dma_dev;\n\tstruct device *cur_tx_dma_dev;\n\n\t \n\tbool\t\t\t\tqueued;\n\tstruct kthread_worker\t\t*kworker;\n\tstruct kthread_work\t\tpump_messages;\n\tspinlock_t\t\t\tqueue_lock;\n\tstruct list_head\t\tqueue;\n\tstruct spi_message\t\t*cur_msg;\n\tstruct completion               cur_msg_completion;\n\tbool\t\t\t\tcur_msg_incomplete;\n\tbool\t\t\t\tcur_msg_need_completion;\n\tbool\t\t\t\tbusy;\n\tbool\t\t\t\trunning;\n\tbool\t\t\t\trt;\n\tbool\t\t\t\tauto_runtime_pm;\n\tbool\t\t\t\tcur_msg_mapped;\n\tchar\t\t\t\tlast_cs;\n\tbool\t\t\t\tlast_cs_mode_high;\n\tbool                            fallback;\n\tstruct completion               xfer_completion;\n\tsize_t\t\t\t\tmax_dma_len;\n\n\tint (*prepare_transfer_hardware)(struct spi_controller *ctlr);\n\tint (*transfer_one_message)(struct spi_controller *ctlr,\n\t\t\t\t    struct spi_message *mesg);\n\tint (*unprepare_transfer_hardware)(struct spi_controller *ctlr);\n\tint (*prepare_message)(struct spi_controller *ctlr,\n\t\t\t       struct spi_message *message);\n\tint (*unprepare_message)(struct spi_controller *ctlr,\n\t\t\t\t struct spi_message *message);\n\tunion {\n\t\tint (*slave_abort)(struct spi_controller *ctlr);\n\t\tint (*target_abort)(struct spi_controller *ctlr);\n\t};\n\n\t \n\tvoid (*set_cs)(struct spi_device *spi, bool enable);\n\tint (*transfer_one)(struct spi_controller *ctlr, struct spi_device *spi,\n\t\t\t    struct spi_transfer *transfer);\n\tvoid (*handle_err)(struct spi_controller *ctlr,\n\t\t\t   struct spi_message *message);\n\n\t \n\tconst struct spi_controller_mem_ops *mem_ops;\n\tconst struct spi_controller_mem_caps *mem_caps;\n\n\t \n\tstruct gpio_desc\t**cs_gpiods;\n\tbool\t\t\tuse_gpio_descriptors;\n\ts8\t\t\tunused_native_cs;\n\ts8\t\t\tmax_native_cs;\n\n\t \n\tstruct spi_statistics __percpu\t*pcpu_statistics;\n\n\t \n\tstruct dma_chan\t\t*dma_tx;\n\tstruct dma_chan\t\t*dma_rx;\n\n\t \n\tvoid\t\t\t*dummy_rx;\n\tvoid\t\t\t*dummy_tx;\n\n\tint (*fw_translate_cs)(struct spi_controller *ctlr, unsigned cs);\n\n\t \n\tbool\t\t\tptp_sts_supported;\n\n\t \n\tunsigned long\t\tirq_flags;\n\n\t \n\tbool\t\t\tqueue_empty;\n\tbool\t\t\tmust_async;\n};\n\nstatic inline void *spi_controller_get_devdata(struct spi_controller *ctlr)\n{\n\treturn dev_get_drvdata(&ctlr->dev);\n}\n\nstatic inline void spi_controller_set_devdata(struct spi_controller *ctlr,\n\t\t\t\t\t      void *data)\n{\n\tdev_set_drvdata(&ctlr->dev, data);\n}\n\nstatic inline struct spi_controller *spi_controller_get(struct spi_controller *ctlr)\n{\n\tif (!ctlr || !get_device(&ctlr->dev))\n\t\treturn NULL;\n\treturn ctlr;\n}\n\nstatic inline void spi_controller_put(struct spi_controller *ctlr)\n{\n\tif (ctlr)\n\t\tput_device(&ctlr->dev);\n}\n\nstatic inline bool spi_controller_is_slave(struct spi_controller *ctlr)\n{\n\treturn IS_ENABLED(CONFIG_SPI_SLAVE) && ctlr->slave;\n}\n\nstatic inline bool spi_controller_is_target(struct spi_controller *ctlr)\n{\n\treturn IS_ENABLED(CONFIG_SPI_SLAVE) && ctlr->target;\n}\n\n \nextern int spi_controller_suspend(struct spi_controller *ctlr);\nextern int spi_controller_resume(struct spi_controller *ctlr);\n\n \nextern struct spi_message *spi_get_next_queued_message(struct spi_controller *ctlr);\nextern void spi_finalize_current_message(struct spi_controller *ctlr);\nextern void spi_finalize_current_transfer(struct spi_controller *ctlr);\n\n \nvoid spi_take_timestamp_pre(struct spi_controller *ctlr,\n\t\t\t    struct spi_transfer *xfer,\n\t\t\t    size_t progress, bool irqs_off);\nvoid spi_take_timestamp_post(struct spi_controller *ctlr,\n\t\t\t     struct spi_transfer *xfer,\n\t\t\t     size_t progress, bool irqs_off);\n\n \nextern struct spi_controller *__spi_alloc_controller(struct device *host,\n\t\t\t\t\t\tunsigned int size, bool slave);\n\nstatic inline struct spi_controller *spi_alloc_master(struct device *host,\n\t\t\t\t\t\t      unsigned int size)\n{\n\treturn __spi_alloc_controller(host, size, false);\n}\n\nstatic inline struct spi_controller *spi_alloc_slave(struct device *host,\n\t\t\t\t\t\t     unsigned int size)\n{\n\tif (!IS_ENABLED(CONFIG_SPI_SLAVE))\n\t\treturn NULL;\n\n\treturn __spi_alloc_controller(host, size, true);\n}\n\nstatic inline struct spi_controller *spi_alloc_host(struct device *dev,\n\t\t\t\t\t\t    unsigned int size)\n{\n\treturn __spi_alloc_controller(dev, size, false);\n}\n\nstatic inline struct spi_controller *spi_alloc_target(struct device *dev,\n\t\t\t\t\t\t      unsigned int size)\n{\n\tif (!IS_ENABLED(CONFIG_SPI_SLAVE))\n\t\treturn NULL;\n\n\treturn __spi_alloc_controller(dev, size, true);\n}\n\nstruct spi_controller *__devm_spi_alloc_controller(struct device *dev,\n\t\t\t\t\t\t   unsigned int size,\n\t\t\t\t\t\t   bool slave);\n\nstatic inline struct spi_controller *devm_spi_alloc_master(struct device *dev,\n\t\t\t\t\t\t\t   unsigned int size)\n{\n\treturn __devm_spi_alloc_controller(dev, size, false);\n}\n\nstatic inline struct spi_controller *devm_spi_alloc_slave(struct device *dev,\n\t\t\t\t\t\t\t  unsigned int size)\n{\n\tif (!IS_ENABLED(CONFIG_SPI_SLAVE))\n\t\treturn NULL;\n\n\treturn __devm_spi_alloc_controller(dev, size, true);\n}\n\nstatic inline struct spi_controller *devm_spi_alloc_host(struct device *dev,\n\t\t\t\t\t\t\t unsigned int size)\n{\n\treturn __devm_spi_alloc_controller(dev, size, false);\n}\n\nstatic inline struct spi_controller *devm_spi_alloc_target(struct device *dev,\n\t\t\t\t\t\t\t   unsigned int size)\n{\n\tif (!IS_ENABLED(CONFIG_SPI_SLAVE))\n\t\treturn NULL;\n\n\treturn __devm_spi_alloc_controller(dev, size, true);\n}\n\nextern int spi_register_controller(struct spi_controller *ctlr);\nextern int devm_spi_register_controller(struct device *dev,\n\t\t\t\t\tstruct spi_controller *ctlr);\nextern void spi_unregister_controller(struct spi_controller *ctlr);\n\n#if IS_ENABLED(CONFIG_ACPI)\nextern struct spi_device *acpi_spi_device_alloc(struct spi_controller *ctlr,\n\t\t\t\t\t\tstruct acpi_device *adev,\n\t\t\t\t\t\tint index);\nint acpi_spi_count_resources(struct acpi_device *adev);\n#endif\n\n \n\ntypedef void (*spi_res_release_t)(struct spi_controller *ctlr,\n\t\t\t\t  struct spi_message *msg,\n\t\t\t\t  void *res);\n\n \nstruct spi_res {\n\tstruct list_head        entry;\n\tspi_res_release_t       release;\n\tunsigned long long      data[];  \n};\n\n \n\n \n\n \nstruct spi_transfer {\n\t \n\tconst void\t*tx_buf;\n\tvoid\t\t*rx_buf;\n\tunsigned\tlen;\n\n#define SPI_TRANS_FAIL_NO_START\tBIT(0)\n\tu16\t\terror;\n\n\tdma_addr_t\ttx_dma;\n\tdma_addr_t\trx_dma;\n\tstruct sg_table tx_sg;\n\tstruct sg_table rx_sg;\n\n\tunsigned\tdummy_data:1;\n\tunsigned\tcs_off:1;\n\tunsigned\tcs_change:1;\n\tunsigned\ttx_nbits:3;\n\tunsigned\trx_nbits:3;\n\tunsigned\ttimestamped:1;\n#define\tSPI_NBITS_SINGLE\t0x01  \n#define\tSPI_NBITS_DUAL\t\t0x02  \n#define\tSPI_NBITS_QUAD\t\t0x04  \n\tu8\t\tbits_per_word;\n\tstruct spi_delay\tdelay;\n\tstruct spi_delay\tcs_change_delay;\n\tstruct spi_delay\tword_delay;\n\tu32\t\tspeed_hz;\n\n\tu32\t\teffective_speed_hz;\n\n\tunsigned int\tptp_sts_word_pre;\n\tunsigned int\tptp_sts_word_post;\n\n\tstruct ptp_system_timestamp *ptp_sts;\n\n\tstruct list_head transfer_list;\n};\n\n \nstruct spi_message {\n\tstruct list_head\ttransfers;\n\n\tstruct spi_device\t*spi;\n\n\tunsigned\t\tis_dma_mapped:1;\n\n\t \n\tbool\t\t\tprepared;\n\n\t \n\n\t \n\tint\t\t\tstatus;\n\tvoid\t\t\t(*complete)(void *context);\n\tvoid\t\t\t*context;\n\tunsigned\t\tframe_length;\n\tunsigned\t\tactual_length;\n\n\t \n\tstruct list_head\tqueue;\n\tvoid\t\t\t*state;\n\n\t \n\tstruct list_head        resources;\n\n\t \n\tstruct spi_transfer\tt[];\n};\n\nstatic inline void spi_message_init_no_memset(struct spi_message *m)\n{\n\tINIT_LIST_HEAD(&m->transfers);\n\tINIT_LIST_HEAD(&m->resources);\n}\n\nstatic inline void spi_message_init(struct spi_message *m)\n{\n\tmemset(m, 0, sizeof *m);\n\tspi_message_init_no_memset(m);\n}\n\nstatic inline void\nspi_message_add_tail(struct spi_transfer *t, struct spi_message *m)\n{\n\tlist_add_tail(&t->transfer_list, &m->transfers);\n}\n\nstatic inline void\nspi_transfer_del(struct spi_transfer *t)\n{\n\tlist_del(&t->transfer_list);\n}\n\nstatic inline int\nspi_transfer_delay_exec(struct spi_transfer *t)\n{\n\treturn spi_delay_exec(&t->delay, t);\n}\n\n \nstatic inline void\nspi_message_init_with_transfers(struct spi_message *m,\nstruct spi_transfer *xfers, unsigned int num_xfers)\n{\n\tunsigned int i;\n\n\tspi_message_init(m);\n\tfor (i = 0; i < num_xfers; ++i)\n\t\tspi_message_add_tail(&xfers[i], m);\n}\n\n \nstatic inline struct spi_message *spi_message_alloc(unsigned ntrans, gfp_t flags)\n{\n\tstruct spi_message *m;\n\n\tm = kzalloc(struct_size(m, t, ntrans), flags);\n\tif (m) {\n\t\tunsigned i;\n\n\t\tspi_message_init_no_memset(m);\n\t\tfor (i = 0; i < ntrans; i++)\n\t\t\tspi_message_add_tail(&m->t[i], m);\n\t}\n\treturn m;\n}\n\nstatic inline void spi_message_free(struct spi_message *m)\n{\n\tkfree(m);\n}\n\nextern int spi_setup(struct spi_device *spi);\nextern int spi_async(struct spi_device *spi, struct spi_message *message);\nextern int spi_slave_abort(struct spi_device *spi);\nextern int spi_target_abort(struct spi_device *spi);\n\nstatic inline size_t\nspi_max_message_size(struct spi_device *spi)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\n\tif (!ctlr->max_message_size)\n\t\treturn SIZE_MAX;\n\treturn ctlr->max_message_size(spi);\n}\n\nstatic inline size_t\nspi_max_transfer_size(struct spi_device *spi)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\tsize_t tr_max = SIZE_MAX;\n\tsize_t msg_max = spi_max_message_size(spi);\n\n\tif (ctlr->max_transfer_size)\n\t\ttr_max = ctlr->max_transfer_size(spi);\n\n\t \n\treturn min(tr_max, msg_max);\n}\n\n \nstatic inline bool spi_is_bpw_supported(struct spi_device *spi, u32 bpw)\n{\n\tu32 bpw_mask = spi->master->bits_per_word_mask;\n\n\tif (bpw == 8 || (bpw <= 32 && bpw_mask & SPI_BPW_MASK(bpw)))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic inline unsigned int spi_controller_xfer_timeout(struct spi_controller *ctlr,\n\t\t\t\t\t\t       struct spi_transfer *xfer)\n{\n\treturn max(xfer->len * 8 * 2 / (xfer->speed_hz / 1000), 500U);\n}\n\n \n\n \n\nstruct spi_replaced_transfers;\ntypedef void (*spi_replaced_release_t)(struct spi_controller *ctlr,\n\t\t\t\t       struct spi_message *msg,\n\t\t\t\t       struct spi_replaced_transfers *res);\n \nstruct spi_replaced_transfers {\n\tspi_replaced_release_t release;\n\tvoid *extradata;\n\tstruct list_head replaced_transfers;\n\tstruct list_head *replaced_after;\n\tsize_t inserted;\n\tstruct spi_transfer inserted_transfers[];\n};\n\n \n\n \n\nextern int spi_split_transfers_maxsize(struct spi_controller *ctlr,\n\t\t\t\t       struct spi_message *msg,\n\t\t\t\t       size_t maxsize,\n\t\t\t\t       gfp_t gfp);\nextern int spi_split_transfers_maxwords(struct spi_controller *ctlr,\n\t\t\t\t\tstruct spi_message *msg,\n\t\t\t\t\tsize_t maxwords,\n\t\t\t\t\tgfp_t gfp);\n\n \n\n \n\nextern int spi_sync(struct spi_device *spi, struct spi_message *message);\nextern int spi_sync_locked(struct spi_device *spi, struct spi_message *message);\nextern int spi_bus_lock(struct spi_controller *ctlr);\nextern int spi_bus_unlock(struct spi_controller *ctlr);\n\n \nstatic inline int\nspi_sync_transfer(struct spi_device *spi, struct spi_transfer *xfers,\n\tunsigned int num_xfers)\n{\n\tstruct spi_message msg;\n\n\tspi_message_init_with_transfers(&msg, xfers, num_xfers);\n\n\treturn spi_sync(spi, &msg);\n}\n\n \nstatic inline int\nspi_write(struct spi_device *spi, const void *buf, size_t len)\n{\n\tstruct spi_transfer\tt = {\n\t\t\t.tx_buf\t\t= buf,\n\t\t\t.len\t\t= len,\n\t\t};\n\n\treturn spi_sync_transfer(spi, &t, 1);\n}\n\n \nstatic inline int\nspi_read(struct spi_device *spi, void *buf, size_t len)\n{\n\tstruct spi_transfer\tt = {\n\t\t\t.rx_buf\t\t= buf,\n\t\t\t.len\t\t= len,\n\t\t};\n\n\treturn spi_sync_transfer(spi, &t, 1);\n}\n\n \nextern int spi_write_then_read(struct spi_device *spi,\n\t\tconst void *txbuf, unsigned n_tx,\n\t\tvoid *rxbuf, unsigned n_rx);\n\n \nstatic inline ssize_t spi_w8r8(struct spi_device *spi, u8 cmd)\n{\n\tssize_t\t\t\tstatus;\n\tu8\t\t\tresult;\n\n\tstatus = spi_write_then_read(spi, &cmd, 1, &result, 1);\n\n\t \n\treturn (status < 0) ? status : result;\n}\n\n \nstatic inline ssize_t spi_w8r16(struct spi_device *spi, u8 cmd)\n{\n\tssize_t\t\t\tstatus;\n\tu16\t\t\tresult;\n\n\tstatus = spi_write_then_read(spi, &cmd, 1, &result, 2);\n\n\t \n\treturn (status < 0) ? status : result;\n}\n\n \nstatic inline ssize_t spi_w8r16be(struct spi_device *spi, u8 cmd)\n\n{\n\tssize_t status;\n\t__be16 result;\n\n\tstatus = spi_write_then_read(spi, &cmd, 1, &result, 2);\n\tif (status < 0)\n\t\treturn status;\n\n\treturn be16_to_cpu(result);\n}\n\n \n\n \n\n \nstruct spi_board_info {\n\t \n\tchar\t\tmodalias[SPI_NAME_SIZE];\n\tconst void\t*platform_data;\n\tconst struct software_node *swnode;\n\tvoid\t\t*controller_data;\n\tint\t\tirq;\n\n\t \n\tu32\t\tmax_speed_hz;\n\n\n\t \n\tu16\t\tbus_num;\n\tu16\t\tchip_select;\n\n\t \n\tu32\t\tmode;\n\n\t \n};\n\n#ifdef\tCONFIG_SPI\nextern int\nspi_register_board_info(struct spi_board_info const *info, unsigned n);\n#else\n \nstatic inline int\nspi_register_board_info(struct spi_board_info const *info, unsigned n)\n\t{ return 0; }\n#endif\n\n \nextern struct spi_device *\nspi_alloc_device(struct spi_controller *ctlr);\n\nextern int\nspi_add_device(struct spi_device *spi);\n\nextern struct spi_device *\nspi_new_device(struct spi_controller *, struct spi_board_info *);\n\nextern void spi_unregister_device(struct spi_device *spi);\n\nextern const struct spi_device_id *\nspi_get_device_id(const struct spi_device *sdev);\n\nextern const void *\nspi_get_device_match_data(const struct spi_device *sdev);\n\nstatic inline bool\nspi_transfer_is_last(struct spi_controller *ctlr, struct spi_transfer *xfer)\n{\n\treturn list_is_last(&xfer->transfer_list, &ctlr->cur_msg->transfers);\n}\n\n \n#define spi_master\t\t\tspi_controller\n\n#define SPI_MASTER_HALF_DUPLEX\t\tSPI_CONTROLLER_HALF_DUPLEX\n\n#define spi_master_get_devdata(_ctlr)\tspi_controller_get_devdata(_ctlr)\n#define spi_master_set_devdata(_ctlr, _data)\t\\\n\tspi_controller_set_devdata(_ctlr, _data)\n#define spi_master_get(_ctlr)\t\tspi_controller_get(_ctlr)\n#define spi_master_put(_ctlr)\t\tspi_controller_put(_ctlr)\n#define spi_master_suspend(_ctlr)\tspi_controller_suspend(_ctlr)\n#define spi_master_resume(_ctlr)\tspi_controller_resume(_ctlr)\n\n#define spi_register_master(_ctlr)\tspi_register_controller(_ctlr)\n#define devm_spi_register_master(_dev, _ctlr) \\\n\tdevm_spi_register_controller(_dev, _ctlr)\n#define spi_unregister_master(_ctlr)\tspi_unregister_controller(_ctlr)\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}