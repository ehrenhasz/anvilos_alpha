{
  "module_name": "backing-dev.h",
  "hash_id": "e6fb61b209db1b4230e07c0b90af519a218990c6039293c510f1808ae50a99f6",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/backing-dev.h",
  "human_readable_source": " \n \n\n#ifndef _LINUX_BACKING_DEV_H\n#define _LINUX_BACKING_DEV_H\n\n#include <linux/kernel.h>\n#include <linux/fs.h>\n#include <linux/sched.h>\n#include <linux/device.h>\n#include <linux/writeback.h>\n#include <linux/backing-dev-defs.h>\n#include <linux/slab.h>\n\nstatic inline struct backing_dev_info *bdi_get(struct backing_dev_info *bdi)\n{\n\tkref_get(&bdi->refcnt);\n\treturn bdi;\n}\n\nstruct backing_dev_info *bdi_get_by_id(u64 id);\nvoid bdi_put(struct backing_dev_info *bdi);\n\n__printf(2, 3)\nint bdi_register(struct backing_dev_info *bdi, const char *fmt, ...);\n__printf(2, 0)\nint bdi_register_va(struct backing_dev_info *bdi, const char *fmt,\n\t\t    va_list args);\nvoid bdi_set_owner(struct backing_dev_info *bdi, struct device *owner);\nvoid bdi_unregister(struct backing_dev_info *bdi);\n\nstruct backing_dev_info *bdi_alloc(int node_id);\n\nvoid wb_start_background_writeback(struct bdi_writeback *wb);\nvoid wb_workfn(struct work_struct *work);\nvoid wb_wakeup_delayed(struct bdi_writeback *wb);\n\nvoid wb_wait_for_completion(struct wb_completion *done);\n\nextern spinlock_t bdi_lock;\nextern struct list_head bdi_list;\n\nextern struct workqueue_struct *bdi_wq;\n\nstatic inline bool wb_has_dirty_io(struct bdi_writeback *wb)\n{\n\treturn test_bit(WB_has_dirty_io, &wb->state);\n}\n\nstatic inline bool bdi_has_dirty_io(struct backing_dev_info *bdi)\n{\n\t \n\treturn atomic_long_read(&bdi->tot_write_bandwidth);\n}\n\nstatic inline void wb_stat_mod(struct bdi_writeback *wb,\n\t\t\t\t enum wb_stat_item item, s64 amount)\n{\n\tpercpu_counter_add_batch(&wb->stat[item], amount, WB_STAT_BATCH);\n}\n\nstatic inline void inc_wb_stat(struct bdi_writeback *wb, enum wb_stat_item item)\n{\n\twb_stat_mod(wb, item, 1);\n}\n\nstatic inline void dec_wb_stat(struct bdi_writeback *wb, enum wb_stat_item item)\n{\n\twb_stat_mod(wb, item, -1);\n}\n\nstatic inline s64 wb_stat(struct bdi_writeback *wb, enum wb_stat_item item)\n{\n\treturn percpu_counter_read_positive(&wb->stat[item]);\n}\n\nstatic inline s64 wb_stat_sum(struct bdi_writeback *wb, enum wb_stat_item item)\n{\n\treturn percpu_counter_sum_positive(&wb->stat[item]);\n}\n\nextern void wb_writeout_inc(struct bdi_writeback *wb);\n\n \nstatic inline unsigned long wb_stat_error(void)\n{\n#ifdef CONFIG_SMP\n\treturn nr_cpu_ids * WB_STAT_BATCH;\n#else\n\treturn 1;\n#endif\n}\n\n \n#define BDI_RATIO_SCALE 10000\n\nu64 bdi_get_min_bytes(struct backing_dev_info *bdi);\nu64 bdi_get_max_bytes(struct backing_dev_info *bdi);\nint bdi_set_min_ratio(struct backing_dev_info *bdi, unsigned int min_ratio);\nint bdi_set_max_ratio(struct backing_dev_info *bdi, unsigned int max_ratio);\nint bdi_set_min_ratio_no_scale(struct backing_dev_info *bdi, unsigned int min_ratio);\nint bdi_set_max_ratio_no_scale(struct backing_dev_info *bdi, unsigned int max_ratio);\nint bdi_set_min_bytes(struct backing_dev_info *bdi, u64 min_bytes);\nint bdi_set_max_bytes(struct backing_dev_info *bdi, u64 max_bytes);\nint bdi_set_strict_limit(struct backing_dev_info *bdi, unsigned int strict_limit);\n\n \n#define BDI_CAP_WRITEBACK\t\t(1 << 0)\n#define BDI_CAP_WRITEBACK_ACCT\t\t(1 << 1)\n#define BDI_CAP_STRICTLIMIT\t\t(1 << 2)\n\nextern struct backing_dev_info noop_backing_dev_info;\n\nint bdi_init(struct backing_dev_info *bdi);\n\n \nstatic inline bool writeback_in_progress(struct bdi_writeback *wb)\n{\n\treturn test_bit(WB_writeback_running, &wb->state);\n}\n\nstruct backing_dev_info *inode_to_bdi(struct inode *inode);\n\nstatic inline bool mapping_can_writeback(struct address_space *mapping)\n{\n\treturn inode_to_bdi(mapping->host)->capabilities & BDI_CAP_WRITEBACK;\n}\n\n#ifdef CONFIG_CGROUP_WRITEBACK\n\nstruct bdi_writeback *wb_get_lookup(struct backing_dev_info *bdi,\n\t\t\t\t    struct cgroup_subsys_state *memcg_css);\nstruct bdi_writeback *wb_get_create(struct backing_dev_info *bdi,\n\t\t\t\t    struct cgroup_subsys_state *memcg_css,\n\t\t\t\t    gfp_t gfp);\nvoid wb_memcg_offline(struct mem_cgroup *memcg);\nvoid wb_blkcg_offline(struct cgroup_subsys_state *css);\n\n \nstatic inline bool inode_cgwb_enabled(struct inode *inode)\n{\n\tstruct backing_dev_info *bdi = inode_to_bdi(inode);\n\n\treturn cgroup_subsys_on_dfl(memory_cgrp_subsys) &&\n\t\tcgroup_subsys_on_dfl(io_cgrp_subsys) &&\n\t\t(bdi->capabilities & BDI_CAP_WRITEBACK) &&\n\t\t(inode->i_sb->s_iflags & SB_I_CGROUPWB);\n}\n\n \nstatic inline struct bdi_writeback *wb_find_current(struct backing_dev_info *bdi)\n{\n\tstruct cgroup_subsys_state *memcg_css;\n\tstruct bdi_writeback *wb;\n\n\tmemcg_css = task_css(current, memory_cgrp_id);\n\tif (!memcg_css->parent)\n\t\treturn &bdi->wb;\n\n\twb = radix_tree_lookup(&bdi->cgwb_tree, memcg_css->id);\n\n\t \n\tif (likely(wb && wb->blkcg_css == task_css(current, io_cgrp_id)))\n\t\treturn wb;\n\treturn NULL;\n}\n\n \nstatic inline struct bdi_writeback *\nwb_get_create_current(struct backing_dev_info *bdi, gfp_t gfp)\n{\n\tstruct bdi_writeback *wb;\n\n\trcu_read_lock();\n\twb = wb_find_current(bdi);\n\tif (wb && unlikely(!wb_tryget(wb)))\n\t\twb = NULL;\n\trcu_read_unlock();\n\n\tif (unlikely(!wb)) {\n\t\tstruct cgroup_subsys_state *memcg_css;\n\n\t\tmemcg_css = task_get_css(current, memory_cgrp_id);\n\t\twb = wb_get_create(bdi, memcg_css, gfp);\n\t\tcss_put(memcg_css);\n\t}\n\treturn wb;\n}\n\n \nstatic inline struct bdi_writeback *inode_to_wb(const struct inode *inode)\n{\n#ifdef CONFIG_LOCKDEP\n\tWARN_ON_ONCE(debug_locks &&\n\t\t     (!lockdep_is_held(&inode->i_lock) &&\n\t\t      !lockdep_is_held(&inode->i_mapping->i_pages.xa_lock) &&\n\t\t      !lockdep_is_held(&inode->i_wb->list_lock)));\n#endif\n\treturn inode->i_wb;\n}\n\nstatic inline struct bdi_writeback *inode_to_wb_wbc(\n\t\t\t\tstruct inode *inode,\n\t\t\t\tstruct writeback_control *wbc)\n{\n\t \n\treturn wbc->wb ? wbc->wb : &inode_to_bdi(inode)->wb;\n}\n\n \nstatic inline struct bdi_writeback *\nunlocked_inode_to_wb_begin(struct inode *inode, struct wb_lock_cookie *cookie)\n{\n\trcu_read_lock();\n\n\t \n\tcookie->locked = smp_load_acquire(&inode->i_state) & I_WB_SWITCH;\n\n\tif (unlikely(cookie->locked))\n\t\txa_lock_irqsave(&inode->i_mapping->i_pages, cookie->flags);\n\n\t \n\treturn inode->i_wb;\n}\n\n \nstatic inline void unlocked_inode_to_wb_end(struct inode *inode,\n\t\t\t\t\t    struct wb_lock_cookie *cookie)\n{\n\tif (unlikely(cookie->locked))\n\t\txa_unlock_irqrestore(&inode->i_mapping->i_pages, cookie->flags);\n\n\trcu_read_unlock();\n}\n\n#else\t \n\nstatic inline bool inode_cgwb_enabled(struct inode *inode)\n{\n\treturn false;\n}\n\nstatic inline struct bdi_writeback *wb_find_current(struct backing_dev_info *bdi)\n{\n\treturn &bdi->wb;\n}\n\nstatic inline struct bdi_writeback *\nwb_get_create_current(struct backing_dev_info *bdi, gfp_t gfp)\n{\n\treturn &bdi->wb;\n}\n\nstatic inline struct bdi_writeback *inode_to_wb(struct inode *inode)\n{\n\treturn &inode_to_bdi(inode)->wb;\n}\n\nstatic inline struct bdi_writeback *inode_to_wb_wbc(\n\t\t\t\tstruct inode *inode,\n\t\t\t\tstruct writeback_control *wbc)\n{\n\treturn inode_to_wb(inode);\n}\n\n\nstatic inline struct bdi_writeback *\nunlocked_inode_to_wb_begin(struct inode *inode, struct wb_lock_cookie *cookie)\n{\n\treturn inode_to_wb(inode);\n}\n\nstatic inline void unlocked_inode_to_wb_end(struct inode *inode,\n\t\t\t\t\t    struct wb_lock_cookie *cookie)\n{\n}\n\nstatic inline void wb_memcg_offline(struct mem_cgroup *memcg)\n{\n}\n\nstatic inline void wb_blkcg_offline(struct cgroup_subsys_state *css)\n{\n}\n\n#endif\t \n\nconst char *bdi_dev_name(struct backing_dev_info *bdi);\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}