{
  "module_name": "kasan.h",
  "hash_id": "20ed2c2af893b165557b208d978472c2c0c428b12549be6314ce5c5f42b81364",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/kasan.h",
  "human_readable_source": " \n#ifndef _LINUX_KASAN_H\n#define _LINUX_KASAN_H\n\n#include <linux/bug.h>\n#include <linux/kasan-enabled.h>\n#include <linux/kernel.h>\n#include <linux/static_key.h>\n#include <linux/types.h>\n\nstruct kmem_cache;\nstruct page;\nstruct slab;\nstruct vm_struct;\nstruct task_struct;\n\n#ifdef CONFIG_KASAN\n\n#include <linux/linkage.h>\n#include <asm/kasan.h>\n\n#endif\n\ntypedef unsigned int __bitwise kasan_vmalloc_flags_t;\n\n#define KASAN_VMALLOC_NONE\t\t((__force kasan_vmalloc_flags_t)0x00u)\n#define KASAN_VMALLOC_INIT\t\t((__force kasan_vmalloc_flags_t)0x01u)\n#define KASAN_VMALLOC_VM_ALLOC\t\t((__force kasan_vmalloc_flags_t)0x02u)\n#define KASAN_VMALLOC_PROT_NORMAL\t((__force kasan_vmalloc_flags_t)0x04u)\n\n#if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)\n\n#include <linux/pgtable.h>\n\n \n\n#ifdef CONFIG_KASAN_SW_TAGS\n \n#define KASAN_SHADOW_INIT 0xFE\n#else\n#define KASAN_SHADOW_INIT 0\n#endif\n\n#ifndef PTE_HWTABLE_PTRS\n#define PTE_HWTABLE_PTRS 0\n#endif\n\nextern unsigned char kasan_early_shadow_page[PAGE_SIZE];\nextern pte_t kasan_early_shadow_pte[MAX_PTRS_PER_PTE + PTE_HWTABLE_PTRS];\nextern pmd_t kasan_early_shadow_pmd[MAX_PTRS_PER_PMD];\nextern pud_t kasan_early_shadow_pud[MAX_PTRS_PER_PUD];\nextern p4d_t kasan_early_shadow_p4d[MAX_PTRS_PER_P4D];\n\nint kasan_populate_early_shadow(const void *shadow_start,\n\t\t\t\tconst void *shadow_end);\n\n#ifndef kasan_mem_to_shadow\nstatic inline void *kasan_mem_to_shadow(const void *addr)\n{\n\treturn (void *)((unsigned long)addr >> KASAN_SHADOW_SCALE_SHIFT)\n\t\t+ KASAN_SHADOW_OFFSET;\n}\n#endif\n\nint kasan_add_zero_shadow(void *start, unsigned long size);\nvoid kasan_remove_zero_shadow(void *start, unsigned long size);\n\n \nextern void kasan_enable_current(void);\n\n \nextern void kasan_disable_current(void);\n\n#else  \n\nstatic inline int kasan_add_zero_shadow(void *start, unsigned long size)\n{\n\treturn 0;\n}\nstatic inline void kasan_remove_zero_shadow(void *start,\n\t\t\t\t\tunsigned long size)\n{}\n\nstatic inline void kasan_enable_current(void) {}\nstatic inline void kasan_disable_current(void) {}\n\n#endif  \n\n#ifdef CONFIG_KASAN_HW_TAGS\n\n#else  \n\n#endif  \n\nstatic inline bool kasan_has_integrated_init(void)\n{\n\treturn kasan_hw_tags_enabled();\n}\n\n#ifdef CONFIG_KASAN\nvoid __kasan_unpoison_range(const void *addr, size_t size);\nstatic __always_inline void kasan_unpoison_range(const void *addr, size_t size)\n{\n\tif (kasan_enabled())\n\t\t__kasan_unpoison_range(addr, size);\n}\n\nvoid __kasan_poison_pages(struct page *page, unsigned int order, bool init);\nstatic __always_inline void kasan_poison_pages(struct page *page,\n\t\t\t\t\t\tunsigned int order, bool init)\n{\n\tif (kasan_enabled())\n\t\t__kasan_poison_pages(page, order, init);\n}\n\nbool __kasan_unpoison_pages(struct page *page, unsigned int order, bool init);\nstatic __always_inline bool kasan_unpoison_pages(struct page *page,\n\t\t\t\t\t\t unsigned int order, bool init)\n{\n\tif (kasan_enabled())\n\t\treturn __kasan_unpoison_pages(page, order, init);\n\treturn false;\n}\n\nvoid __kasan_poison_slab(struct slab *slab);\nstatic __always_inline void kasan_poison_slab(struct slab *slab)\n{\n\tif (kasan_enabled())\n\t\t__kasan_poison_slab(slab);\n}\n\nvoid __kasan_unpoison_object_data(struct kmem_cache *cache, void *object);\nstatic __always_inline void kasan_unpoison_object_data(struct kmem_cache *cache,\n\t\t\t\t\t\t\tvoid *object)\n{\n\tif (kasan_enabled())\n\t\t__kasan_unpoison_object_data(cache, object);\n}\n\nvoid __kasan_poison_object_data(struct kmem_cache *cache, void *object);\nstatic __always_inline void kasan_poison_object_data(struct kmem_cache *cache,\n\t\t\t\t\t\t\tvoid *object)\n{\n\tif (kasan_enabled())\n\t\t__kasan_poison_object_data(cache, object);\n}\n\nvoid * __must_check __kasan_init_slab_obj(struct kmem_cache *cache,\n\t\t\t\t\t  const void *object);\nstatic __always_inline void * __must_check kasan_init_slab_obj(\n\t\t\t\tstruct kmem_cache *cache, const void *object)\n{\n\tif (kasan_enabled())\n\t\treturn __kasan_init_slab_obj(cache, object);\n\treturn (void *)object;\n}\n\nbool __kasan_slab_free(struct kmem_cache *s, void *object,\n\t\t\tunsigned long ip, bool init);\nstatic __always_inline bool kasan_slab_free(struct kmem_cache *s,\n\t\t\t\t\t\tvoid *object, bool init)\n{\n\tif (kasan_enabled())\n\t\treturn __kasan_slab_free(s, object, _RET_IP_, init);\n\treturn false;\n}\n\nvoid __kasan_kfree_large(void *ptr, unsigned long ip);\nstatic __always_inline void kasan_kfree_large(void *ptr)\n{\n\tif (kasan_enabled())\n\t\t__kasan_kfree_large(ptr, _RET_IP_);\n}\n\nvoid __kasan_slab_free_mempool(void *ptr, unsigned long ip);\nstatic __always_inline void kasan_slab_free_mempool(void *ptr)\n{\n\tif (kasan_enabled())\n\t\t__kasan_slab_free_mempool(ptr, _RET_IP_);\n}\n\nvoid * __must_check __kasan_slab_alloc(struct kmem_cache *s,\n\t\t\t\t       void *object, gfp_t flags, bool init);\nstatic __always_inline void * __must_check kasan_slab_alloc(\n\t\tstruct kmem_cache *s, void *object, gfp_t flags, bool init)\n{\n\tif (kasan_enabled())\n\t\treturn __kasan_slab_alloc(s, object, flags, init);\n\treturn object;\n}\n\nvoid * __must_check __kasan_kmalloc(struct kmem_cache *s, const void *object,\n\t\t\t\t    size_t size, gfp_t flags);\nstatic __always_inline void * __must_check kasan_kmalloc(struct kmem_cache *s,\n\t\t\t\tconst void *object, size_t size, gfp_t flags)\n{\n\tif (kasan_enabled())\n\t\treturn __kasan_kmalloc(s, object, size, flags);\n\treturn (void *)object;\n}\n\nvoid * __must_check __kasan_kmalloc_large(const void *ptr,\n\t\t\t\t\t  size_t size, gfp_t flags);\nstatic __always_inline void * __must_check kasan_kmalloc_large(const void *ptr,\n\t\t\t\t\t\t      size_t size, gfp_t flags)\n{\n\tif (kasan_enabled())\n\t\treturn __kasan_kmalloc_large(ptr, size, flags);\n\treturn (void *)ptr;\n}\n\nvoid * __must_check __kasan_krealloc(const void *object,\n\t\t\t\t     size_t new_size, gfp_t flags);\nstatic __always_inline void * __must_check kasan_krealloc(const void *object,\n\t\t\t\t\t\t size_t new_size, gfp_t flags)\n{\n\tif (kasan_enabled())\n\t\treturn __kasan_krealloc(object, new_size, flags);\n\treturn (void *)object;\n}\n\n \nbool __kasan_check_byte(const void *addr, unsigned long ip);\nstatic __always_inline bool kasan_check_byte(const void *addr)\n{\n\tif (kasan_enabled())\n\t\treturn __kasan_check_byte(addr, _RET_IP_);\n\treturn true;\n}\n\n#else  \n\nstatic inline void kasan_unpoison_range(const void *address, size_t size) {}\nstatic inline void kasan_poison_pages(struct page *page, unsigned int order,\n\t\t\t\t      bool init) {}\nstatic inline bool kasan_unpoison_pages(struct page *page, unsigned int order,\n\t\t\t\t\tbool init)\n{\n\treturn false;\n}\nstatic inline void kasan_poison_slab(struct slab *slab) {}\nstatic inline void kasan_unpoison_object_data(struct kmem_cache *cache,\n\t\t\t\t\tvoid *object) {}\nstatic inline void kasan_poison_object_data(struct kmem_cache *cache,\n\t\t\t\t\tvoid *object) {}\nstatic inline void *kasan_init_slab_obj(struct kmem_cache *cache,\n\t\t\t\tconst void *object)\n{\n\treturn (void *)object;\n}\nstatic inline bool kasan_slab_free(struct kmem_cache *s, void *object, bool init)\n{\n\treturn false;\n}\nstatic inline void kasan_kfree_large(void *ptr) {}\nstatic inline void kasan_slab_free_mempool(void *ptr) {}\nstatic inline void *kasan_slab_alloc(struct kmem_cache *s, void *object,\n\t\t\t\t   gfp_t flags, bool init)\n{\n\treturn object;\n}\nstatic inline void *kasan_kmalloc(struct kmem_cache *s, const void *object,\n\t\t\t\tsize_t size, gfp_t flags)\n{\n\treturn (void *)object;\n}\nstatic inline void *kasan_kmalloc_large(const void *ptr, size_t size, gfp_t flags)\n{\n\treturn (void *)ptr;\n}\nstatic inline void *kasan_krealloc(const void *object, size_t new_size,\n\t\t\t\t gfp_t flags)\n{\n\treturn (void *)object;\n}\nstatic inline bool kasan_check_byte(const void *address)\n{\n\treturn true;\n}\n\n#endif  \n\n#if defined(CONFIG_KASAN) && defined(CONFIG_KASAN_STACK)\nvoid kasan_unpoison_task_stack(struct task_struct *task);\n#else\nstatic inline void kasan_unpoison_task_stack(struct task_struct *task) {}\n#endif\n\n#ifdef CONFIG_KASAN_GENERIC\n\nstruct kasan_cache {\n\tint alloc_meta_offset;\n\tint free_meta_offset;\n};\n\nsize_t kasan_metadata_size(struct kmem_cache *cache, bool in_object);\nslab_flags_t kasan_never_merge(void);\nvoid kasan_cache_create(struct kmem_cache *cache, unsigned int *size,\n\t\t\tslab_flags_t *flags);\n\nvoid kasan_cache_shrink(struct kmem_cache *cache);\nvoid kasan_cache_shutdown(struct kmem_cache *cache);\nvoid kasan_record_aux_stack(void *ptr);\nvoid kasan_record_aux_stack_noalloc(void *ptr);\n\n#else  \n\n \nstatic inline size_t kasan_metadata_size(struct kmem_cache *cache,\n\t\t\t\t\t\tbool in_object)\n{\n\treturn 0;\n}\n \nstatic inline slab_flags_t kasan_never_merge(void)\n{\n\treturn 0;\n}\n \nstatic inline void kasan_cache_create(struct kmem_cache *cache,\n\t\t\t\t      unsigned int *size,\n\t\t\t\t      slab_flags_t *flags) {}\n\nstatic inline void kasan_cache_shrink(struct kmem_cache *cache) {}\nstatic inline void kasan_cache_shutdown(struct kmem_cache *cache) {}\nstatic inline void kasan_record_aux_stack(void *ptr) {}\nstatic inline void kasan_record_aux_stack_noalloc(void *ptr) {}\n\n#endif  \n\n#if defined(CONFIG_KASAN_SW_TAGS) || defined(CONFIG_KASAN_HW_TAGS)\n\nstatic inline void *kasan_reset_tag(const void *addr)\n{\n\treturn (void *)arch_kasan_reset_tag(addr);\n}\n\n \nbool kasan_report(const void *addr, size_t size,\n\t\tbool is_write, unsigned long ip);\n\n#else  \n\nstatic inline void *kasan_reset_tag(const void *addr)\n{\n\treturn (void *)addr;\n}\n\n#endif  \n\n#ifdef CONFIG_KASAN_HW_TAGS\n\nvoid kasan_report_async(void);\n\n#endif  \n\n#ifdef CONFIG_KASAN_SW_TAGS\nvoid __init kasan_init_sw_tags(void);\n#else\nstatic inline void kasan_init_sw_tags(void) { }\n#endif\n\n#ifdef CONFIG_KASAN_HW_TAGS\nvoid kasan_init_hw_tags_cpu(void);\nvoid __init kasan_init_hw_tags(void);\n#else\nstatic inline void kasan_init_hw_tags_cpu(void) { }\nstatic inline void kasan_init_hw_tags(void) { }\n#endif\n\n#ifdef CONFIG_KASAN_VMALLOC\n\n#if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)\n\nvoid kasan_populate_early_vm_area_shadow(void *start, unsigned long size);\nint kasan_populate_vmalloc(unsigned long addr, unsigned long size);\nvoid kasan_release_vmalloc(unsigned long start, unsigned long end,\n\t\t\t   unsigned long free_region_start,\n\t\t\t   unsigned long free_region_end);\n\n#else  \n\nstatic inline void kasan_populate_early_vm_area_shadow(void *start,\n\t\t\t\t\t\t       unsigned long size)\n{ }\nstatic inline int kasan_populate_vmalloc(unsigned long start,\n\t\t\t\t\tunsigned long size)\n{\n\treturn 0;\n}\nstatic inline void kasan_release_vmalloc(unsigned long start,\n\t\t\t\t\t unsigned long end,\n\t\t\t\t\t unsigned long free_region_start,\n\t\t\t\t\t unsigned long free_region_end) { }\n\n#endif  \n\nvoid *__kasan_unpoison_vmalloc(const void *start, unsigned long size,\n\t\t\t       kasan_vmalloc_flags_t flags);\nstatic __always_inline void *kasan_unpoison_vmalloc(const void *start,\n\t\t\t\t\t\tunsigned long size,\n\t\t\t\t\t\tkasan_vmalloc_flags_t flags)\n{\n\tif (kasan_enabled())\n\t\treturn __kasan_unpoison_vmalloc(start, size, flags);\n\treturn (void *)start;\n}\n\nvoid __kasan_poison_vmalloc(const void *start, unsigned long size);\nstatic __always_inline void kasan_poison_vmalloc(const void *start,\n\t\t\t\t\t\t unsigned long size)\n{\n\tif (kasan_enabled())\n\t\t__kasan_poison_vmalloc(start, size);\n}\n\n#else  \n\nstatic inline void kasan_populate_early_vm_area_shadow(void *start,\n\t\t\t\t\t\t       unsigned long size) { }\nstatic inline int kasan_populate_vmalloc(unsigned long start,\n\t\t\t\t\tunsigned long size)\n{\n\treturn 0;\n}\nstatic inline void kasan_release_vmalloc(unsigned long start,\n\t\t\t\t\t unsigned long end,\n\t\t\t\t\t unsigned long free_region_start,\n\t\t\t\t\t unsigned long free_region_end) { }\n\nstatic inline void *kasan_unpoison_vmalloc(const void *start,\n\t\t\t\t\t   unsigned long size,\n\t\t\t\t\t   kasan_vmalloc_flags_t flags)\n{\n\treturn (void *)start;\n}\nstatic inline void kasan_poison_vmalloc(const void *start, unsigned long size)\n{ }\n\n#endif  \n\n#if (defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)) && \\\n\t\t!defined(CONFIG_KASAN_VMALLOC)\n\n \nint kasan_alloc_module_shadow(void *addr, size_t size, gfp_t gfp_mask);\nvoid kasan_free_module_shadow(const struct vm_struct *vm);\n\n#else  \n\nstatic inline int kasan_alloc_module_shadow(void *addr, size_t size, gfp_t gfp_mask) { return 0; }\nstatic inline void kasan_free_module_shadow(const struct vm_struct *vm) {}\n\n#endif  \n\n#if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)\nvoid kasan_non_canonical_hook(unsigned long addr);\n#else  \nstatic inline void kasan_non_canonical_hook(unsigned long addr) { }\n#endif  \n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}