{
  "module_name": "dma-resv.h",
  "hash_id": "1c5a13d82b23e8c9c6c154e2118131507f53d84dbb4c836e8e2055372aa1ebb2",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/dma-resv.h",
  "human_readable_source": " \n#ifndef _LINUX_RESERVATION_H\n#define _LINUX_RESERVATION_H\n\n#include <linux/ww_mutex.h>\n#include <linux/dma-fence.h>\n#include <linux/slab.h>\n#include <linux/seqlock.h>\n#include <linux/rcupdate.h>\n\nextern struct ww_class reservation_ww_class;\n\nstruct dma_resv_list;\n\n \nenum dma_resv_usage {\n\t \n\tDMA_RESV_USAGE_KERNEL,\n\n\t \n\tDMA_RESV_USAGE_WRITE,\n\n\t \n\tDMA_RESV_USAGE_READ,\n\n\t \n\tDMA_RESV_USAGE_BOOKKEEP\n};\n\n \nstatic inline enum dma_resv_usage dma_resv_usage_rw(bool write)\n{\n\t \n\treturn write ? DMA_RESV_USAGE_READ : DMA_RESV_USAGE_WRITE;\n}\n\n \nstruct dma_resv {\n\t \n\tstruct ww_mutex lock;\n\n\t \n\tstruct dma_resv_list __rcu *fences;\n};\n\n \nstruct dma_resv_iter {\n\t \n\tstruct dma_resv *obj;\n\n\t \n\tenum dma_resv_usage usage;\n\n\t \n\tstruct dma_fence *fence;\n\n\t \n\tenum dma_resv_usage fence_usage;\n\n\t \n\tunsigned int index;\n\n\t \n\tstruct dma_resv_list *fences;\n\n\t \n\tunsigned int num_fences;\n\n\t \n\tbool is_restarted;\n};\n\nstruct dma_fence *dma_resv_iter_first_unlocked(struct dma_resv_iter *cursor);\nstruct dma_fence *dma_resv_iter_next_unlocked(struct dma_resv_iter *cursor);\nstruct dma_fence *dma_resv_iter_first(struct dma_resv_iter *cursor);\nstruct dma_fence *dma_resv_iter_next(struct dma_resv_iter *cursor);\n\n \nstatic inline void dma_resv_iter_begin(struct dma_resv_iter *cursor,\n\t\t\t\t       struct dma_resv *obj,\n\t\t\t\t       enum dma_resv_usage usage)\n{\n\tcursor->obj = obj;\n\tcursor->usage = usage;\n\tcursor->fence = NULL;\n}\n\n \nstatic inline void dma_resv_iter_end(struct dma_resv_iter *cursor)\n{\n\tdma_fence_put(cursor->fence);\n}\n\n \nstatic inline enum dma_resv_usage\ndma_resv_iter_usage(struct dma_resv_iter *cursor)\n{\n\treturn cursor->fence_usage;\n}\n\n \nstatic inline bool dma_resv_iter_is_restarted(struct dma_resv_iter *cursor)\n{\n\treturn cursor->is_restarted;\n}\n\n \n#define dma_resv_for_each_fence_unlocked(cursor, fence)\t\t\t\\\n\tfor (fence = dma_resv_iter_first_unlocked(cursor);\t\t\\\n\t     fence; fence = dma_resv_iter_next_unlocked(cursor))\n\n \n#define dma_resv_for_each_fence(cursor, obj, usage, fence)\t\\\n\tfor (dma_resv_iter_begin(cursor, obj, usage),\t\\\n\t     fence = dma_resv_iter_first(cursor); fence;\t\\\n\t     fence = dma_resv_iter_next(cursor))\n\n#define dma_resv_held(obj) lockdep_is_held(&(obj)->lock.base)\n#define dma_resv_assert_held(obj) lockdep_assert_held(&(obj)->lock.base)\n\n#ifdef CONFIG_DEBUG_MUTEXES\nvoid dma_resv_reset_max_fences(struct dma_resv *obj);\n#else\nstatic inline void dma_resv_reset_max_fences(struct dma_resv *obj) {}\n#endif\n\n \nstatic inline int dma_resv_lock(struct dma_resv *obj,\n\t\t\t\tstruct ww_acquire_ctx *ctx)\n{\n\treturn ww_mutex_lock(&obj->lock, ctx);\n}\n\n \nstatic inline int dma_resv_lock_interruptible(struct dma_resv *obj,\n\t\t\t\t\t      struct ww_acquire_ctx *ctx)\n{\n\treturn ww_mutex_lock_interruptible(&obj->lock, ctx);\n}\n\n \nstatic inline void dma_resv_lock_slow(struct dma_resv *obj,\n\t\t\t\t      struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_slow(&obj->lock, ctx);\n}\n\n \nstatic inline int dma_resv_lock_slow_interruptible(struct dma_resv *obj,\n\t\t\t\t\t\t   struct ww_acquire_ctx *ctx)\n{\n\treturn ww_mutex_lock_slow_interruptible(&obj->lock, ctx);\n}\n\n \nstatic inline bool __must_check dma_resv_trylock(struct dma_resv *obj)\n{\n\treturn ww_mutex_trylock(&obj->lock, NULL);\n}\n\n \nstatic inline bool dma_resv_is_locked(struct dma_resv *obj)\n{\n\treturn ww_mutex_is_locked(&obj->lock);\n}\n\n \nstatic inline struct ww_acquire_ctx *dma_resv_locking_ctx(struct dma_resv *obj)\n{\n\treturn READ_ONCE(obj->lock.ctx);\n}\n\n \nstatic inline void dma_resv_unlock(struct dma_resv *obj)\n{\n\tdma_resv_reset_max_fences(obj);\n\tww_mutex_unlock(&obj->lock);\n}\n\nvoid dma_resv_init(struct dma_resv *obj);\nvoid dma_resv_fini(struct dma_resv *obj);\nint dma_resv_reserve_fences(struct dma_resv *obj, unsigned int num_fences);\nvoid dma_resv_add_fence(struct dma_resv *obj, struct dma_fence *fence,\n\t\t\tenum dma_resv_usage usage);\nvoid dma_resv_replace_fences(struct dma_resv *obj, uint64_t context,\n\t\t\t     struct dma_fence *fence,\n\t\t\t     enum dma_resv_usage usage);\nint dma_resv_get_fences(struct dma_resv *obj, enum dma_resv_usage usage,\n\t\t\tunsigned int *num_fences, struct dma_fence ***fences);\nint dma_resv_get_singleton(struct dma_resv *obj, enum dma_resv_usage usage,\n\t\t\t   struct dma_fence **fence);\nint dma_resv_copy_fences(struct dma_resv *dst, struct dma_resv *src);\nlong dma_resv_wait_timeout(struct dma_resv *obj, enum dma_resv_usage usage,\n\t\t\t   bool intr, unsigned long timeout);\nvoid dma_resv_set_deadline(struct dma_resv *obj, enum dma_resv_usage usage,\n\t\t\t   ktime_t deadline);\nbool dma_resv_test_signaled(struct dma_resv *obj, enum dma_resv_usage usage);\nvoid dma_resv_describe(struct dma_resv *obj, struct seq_file *seq);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}