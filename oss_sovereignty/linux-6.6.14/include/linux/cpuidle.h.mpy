{
  "module_name": "cpuidle.h",
  "hash_id": "40688510be513adad1904c6879f26644b40375824c923fcd38bea02b2627f7b9",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/cpuidle.h",
  "human_readable_source": " \n\n#ifndef _LINUX_CPUIDLE_H\n#define _LINUX_CPUIDLE_H\n\n#include <linux/percpu.h>\n#include <linux/list.h>\n#include <linux/hrtimer.h>\n#include <linux/context_tracking.h>\n\n#define CPUIDLE_STATE_MAX\t10\n#define CPUIDLE_NAME_LEN\t16\n#define CPUIDLE_DESC_LEN\t32\n\nstruct module;\n\nstruct cpuidle_device;\nstruct cpuidle_driver;\n\n\n \n\n#define CPUIDLE_STATE_DISABLED_BY_USER\t\tBIT(0)\n#define CPUIDLE_STATE_DISABLED_BY_DRIVER\tBIT(1)\n\nstruct cpuidle_state_usage {\n\tunsigned long long\tdisable;\n\tunsigned long long\tusage;\n\tu64\t\t\ttime_ns;\n\tunsigned long long\tabove;  \n\tunsigned long long\tbelow;  \n\tunsigned long long\trejected;  \n#ifdef CONFIG_SUSPEND\n\tunsigned long long\ts2idle_usage;\n\tunsigned long long\ts2idle_time;  \n#endif\n};\n\nstruct cpuidle_state {\n\tchar\t\tname[CPUIDLE_NAME_LEN];\n\tchar\t\tdesc[CPUIDLE_DESC_LEN];\n\n\ts64\t\texit_latency_ns;\n\ts64\t\ttarget_residency_ns;\n\tunsigned int\tflags;\n\tunsigned int\texit_latency;  \n\tint\t\tpower_usage;  \n\tunsigned int\ttarget_residency;  \n\n\tint (*enter)\t(struct cpuidle_device *dev,\n\t\t\tstruct cpuidle_driver *drv,\n\t\t\tint index);\n\n\tint (*enter_dead) (struct cpuidle_device *dev, int index);\n\n\t \n\tint (*enter_s2idle)(struct cpuidle_device *dev,\n\t\t\t    struct cpuidle_driver *drv,\n\t\t\t    int index);\n};\n\n \n#define CPUIDLE_FLAG_NONE       \t(0x00)\n#define CPUIDLE_FLAG_POLLING\t\tBIT(0)  \n#define CPUIDLE_FLAG_COUPLED\t\tBIT(1)  \n#define CPUIDLE_FLAG_TIMER_STOP \tBIT(2)  \n#define CPUIDLE_FLAG_UNUSABLE\t\tBIT(3)  \n#define CPUIDLE_FLAG_OFF\t\tBIT(4)  \n#define CPUIDLE_FLAG_TLB_FLUSHED\tBIT(5)  \n#define CPUIDLE_FLAG_RCU_IDLE\t\tBIT(6)  \n\nstruct cpuidle_device_kobj;\nstruct cpuidle_state_kobj;\nstruct cpuidle_driver_kobj;\n\nstruct cpuidle_device {\n\tunsigned int\t\tregistered:1;\n\tunsigned int\t\tenabled:1;\n\tunsigned int\t\tpoll_time_limit:1;\n\tunsigned int\t\tcpu;\n\tktime_t\t\t\tnext_hrtimer;\n\n\tint\t\t\tlast_state_idx;\n\tu64\t\t\tlast_residency_ns;\n\tu64\t\t\tpoll_limit_ns;\n\tu64\t\t\tforced_idle_latency_limit_ns;\n\tstruct cpuidle_state_usage\tstates_usage[CPUIDLE_STATE_MAX];\n\tstruct cpuidle_state_kobj *kobjs[CPUIDLE_STATE_MAX];\n\tstruct cpuidle_driver_kobj *kobj_driver;\n\tstruct cpuidle_device_kobj *kobj_dev;\n\tstruct list_head \tdevice_list;\n\n#ifdef CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED\n\tcpumask_t\t\tcoupled_cpus;\n\tstruct cpuidle_coupled\t*coupled;\n#endif\n};\n\nDECLARE_PER_CPU(struct cpuidle_device *, cpuidle_devices);\nDECLARE_PER_CPU(struct cpuidle_device, cpuidle_dev);\n\nstatic __always_inline void ct_cpuidle_enter(void)\n{\n\tlockdep_assert_irqs_disabled();\n\t \n\ttrace_hardirqs_on_prepare();\n\tlockdep_hardirqs_on_prepare();\n\tinstrumentation_end();\n\tct_idle_enter();\n\tlockdep_hardirqs_on(_RET_IP_);\n}\n\nstatic __always_inline void ct_cpuidle_exit(void)\n{\n\t \n\tlockdep_hardirqs_off(_RET_IP_);\n\tct_idle_exit();\n\tinstrumentation_begin();\n}\n\n \n\nstruct cpuidle_driver {\n\tconst char\t\t*name;\n\tstruct module \t\t*owner;\n\n         \n\tunsigned int            bctimer:1;\n\t \n\tstruct cpuidle_state\tstates[CPUIDLE_STATE_MAX];\n\tint\t\t\tstate_count;\n\tint\t\t\tsafe_state_index;\n\n\t \n\tstruct cpumask\t\t*cpumask;\n\n\t \n\tconst char\t\t*governor;\n};\n\n#ifdef CONFIG_CPU_IDLE\nextern void disable_cpuidle(void);\nextern bool cpuidle_not_available(struct cpuidle_driver *drv,\n\t\t\t\t  struct cpuidle_device *dev);\n\nextern int cpuidle_select(struct cpuidle_driver *drv,\n\t\t\t  struct cpuidle_device *dev,\n\t\t\t  bool *stop_tick);\nextern int cpuidle_enter(struct cpuidle_driver *drv,\n\t\t\t struct cpuidle_device *dev, int index);\nextern void cpuidle_reflect(struct cpuidle_device *dev, int index);\nextern u64 cpuidle_poll_time(struct cpuidle_driver *drv,\n\t\t\t     struct cpuidle_device *dev);\n\nextern int cpuidle_register_driver(struct cpuidle_driver *drv);\nextern struct cpuidle_driver *cpuidle_get_driver(void);\nextern void cpuidle_driver_state_disabled(struct cpuidle_driver *drv, int idx,\n\t\t\t\t\tbool disable);\nextern void cpuidle_unregister_driver(struct cpuidle_driver *drv);\nextern int cpuidle_register_device(struct cpuidle_device *dev);\nextern void cpuidle_unregister_device(struct cpuidle_device *dev);\nextern int cpuidle_register(struct cpuidle_driver *drv,\n\t\t\t    const struct cpumask *const coupled_cpus);\nextern void cpuidle_unregister(struct cpuidle_driver *drv);\nextern void cpuidle_pause_and_lock(void);\nextern void cpuidle_resume_and_unlock(void);\nextern void cpuidle_pause(void);\nextern void cpuidle_resume(void);\nextern int cpuidle_enable_device(struct cpuidle_device *dev);\nextern void cpuidle_disable_device(struct cpuidle_device *dev);\nextern int cpuidle_play_dead(void);\n\nextern struct cpuidle_driver *cpuidle_get_cpu_driver(struct cpuidle_device *dev);\nstatic inline struct cpuidle_device *cpuidle_get_device(void)\n{return __this_cpu_read(cpuidle_devices); }\n#else\nstatic inline void disable_cpuidle(void) { }\nstatic inline bool cpuidle_not_available(struct cpuidle_driver *drv,\n\t\t\t\t\t struct cpuidle_device *dev)\n{return true; }\nstatic inline int cpuidle_select(struct cpuidle_driver *drv,\n\t\t\t\t struct cpuidle_device *dev, bool *stop_tick)\n{return -ENODEV; }\nstatic inline int cpuidle_enter(struct cpuidle_driver *drv,\n\t\t\t\tstruct cpuidle_device *dev, int index)\n{return -ENODEV; }\nstatic inline void cpuidle_reflect(struct cpuidle_device *dev, int index) { }\nstatic inline u64 cpuidle_poll_time(struct cpuidle_driver *drv,\n\t\t\t     struct cpuidle_device *dev)\n{return 0; }\nstatic inline int cpuidle_register_driver(struct cpuidle_driver *drv)\n{return -ENODEV; }\nstatic inline struct cpuidle_driver *cpuidle_get_driver(void) {return NULL; }\nstatic inline void cpuidle_driver_state_disabled(struct cpuidle_driver *drv,\n\t\t\t\t\t       int idx, bool disable) { }\nstatic inline void cpuidle_unregister_driver(struct cpuidle_driver *drv) { }\nstatic inline int cpuidle_register_device(struct cpuidle_device *dev)\n{return -ENODEV; }\nstatic inline void cpuidle_unregister_device(struct cpuidle_device *dev) { }\nstatic inline int cpuidle_register(struct cpuidle_driver *drv,\n\t\t\t\t   const struct cpumask *const coupled_cpus)\n{return -ENODEV; }\nstatic inline void cpuidle_unregister(struct cpuidle_driver *drv) { }\nstatic inline void cpuidle_pause_and_lock(void) { }\nstatic inline void cpuidle_resume_and_unlock(void) { }\nstatic inline void cpuidle_pause(void) { }\nstatic inline void cpuidle_resume(void) { }\nstatic inline int cpuidle_enable_device(struct cpuidle_device *dev)\n{return -ENODEV; }\nstatic inline void cpuidle_disable_device(struct cpuidle_device *dev) { }\nstatic inline int cpuidle_play_dead(void) {return -ENODEV; }\nstatic inline struct cpuidle_driver *cpuidle_get_cpu_driver(\n\tstruct cpuidle_device *dev) {return NULL; }\nstatic inline struct cpuidle_device *cpuidle_get_device(void) {return NULL; }\n#endif\n\n#ifdef CONFIG_CPU_IDLE\nextern int cpuidle_find_deepest_state(struct cpuidle_driver *drv,\n\t\t\t\t      struct cpuidle_device *dev,\n\t\t\t\t      u64 latency_limit_ns);\nextern int cpuidle_enter_s2idle(struct cpuidle_driver *drv,\n\t\t\t\tstruct cpuidle_device *dev);\nextern void cpuidle_use_deepest_state(u64 latency_limit_ns);\n#else\nstatic inline int cpuidle_find_deepest_state(struct cpuidle_driver *drv,\n\t\t\t\t\t     struct cpuidle_device *dev,\n\t\t\t\t\t     u64 latency_limit_ns)\n{return -ENODEV; }\nstatic inline int cpuidle_enter_s2idle(struct cpuidle_driver *drv,\n\t\t\t\t       struct cpuidle_device *dev)\n{return -ENODEV; }\nstatic inline void cpuidle_use_deepest_state(u64 latency_limit_ns)\n{\n}\n#endif\n\n \nextern void sched_idle_set_state(struct cpuidle_state *idle_state);\nextern void default_idle_call(void);\n\n#ifdef CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED\nvoid cpuidle_coupled_parallel_barrier(struct cpuidle_device *dev, atomic_t *a);\n#else\nstatic inline void cpuidle_coupled_parallel_barrier(struct cpuidle_device *dev, atomic_t *a)\n{\n}\n#endif\n\n#if defined(CONFIG_CPU_IDLE) && defined(CONFIG_ARCH_HAS_CPU_RELAX)\nvoid cpuidle_poll_state_init(struct cpuidle_driver *drv);\n#else\nstatic inline void cpuidle_poll_state_init(struct cpuidle_driver *drv) {}\n#endif\n\n \n\nstruct cpuidle_governor {\n\tchar\t\t\tname[CPUIDLE_NAME_LEN];\n\tstruct list_head \tgovernor_list;\n\tunsigned int\t\trating;\n\n\tint  (*enable)\t\t(struct cpuidle_driver *drv,\n\t\t\t\t\tstruct cpuidle_device *dev);\n\tvoid (*disable)\t\t(struct cpuidle_driver *drv,\n\t\t\t\t\tstruct cpuidle_device *dev);\n\n\tint  (*select)\t\t(struct cpuidle_driver *drv,\n\t\t\t\t\tstruct cpuidle_device *dev,\n\t\t\t\t\tbool *stop_tick);\n\tvoid (*reflect)\t\t(struct cpuidle_device *dev, int index);\n};\n\nextern int cpuidle_register_governor(struct cpuidle_governor *gov);\nextern s64 cpuidle_governor_latency_req(unsigned int cpu);\n\n#define __CPU_PM_CPU_IDLE_ENTER(low_level_idle_enter,\t\t\t\\\n\t\t\t\tidx,\t\t\t\t\t\\\n\t\t\t\tstate,\t\t\t\t\t\\\n\t\t\t\tis_retention, is_rcu)\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tint __ret = 0;\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (!idx) {\t\t\t\t\t\t\t\\\n\t\tcpu_do_idle();\t\t\t\t\t\t\\\n\t\treturn idx;\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (!is_retention)\t\t\t\t\t\t\\\n\t\t__ret =  cpu_pm_enter();\t\t\t\t\\\n\tif (!__ret) {\t\t\t\t\t\t\t\\\n\t\tif (!is_rcu)\t\t\t\t\t\t\\\n\t\t\tct_cpuidle_enter();\t\t\t\t\\\n\t\t__ret = low_level_idle_enter(state);\t\t\t\\\n\t\tif (!is_rcu)\t\t\t\t\t\t\\\n\t\t\tct_cpuidle_exit();\t\t\t\t\\\n\t\tif (!is_retention)\t\t\t\t\t\\\n\t\t\tcpu_pm_exit();\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t__ret ? -1 : idx;\t\t\t\t\t\t\\\n})\n\n#define CPU_PM_CPU_IDLE_ENTER(low_level_idle_enter, idx)\t\\\n\t__CPU_PM_CPU_IDLE_ENTER(low_level_idle_enter, idx, idx, 0, 0)\n\n#define CPU_PM_CPU_IDLE_ENTER_RETENTION(low_level_idle_enter, idx)\t\\\n\t__CPU_PM_CPU_IDLE_ENTER(low_level_idle_enter, idx, idx, 1, 0)\n\n#define CPU_PM_CPU_IDLE_ENTER_PARAM(low_level_idle_enter, idx, state)\t\\\n\t__CPU_PM_CPU_IDLE_ENTER(low_level_idle_enter, idx, state, 0, 0)\n\n#define CPU_PM_CPU_IDLE_ENTER_PARAM_RCU(low_level_idle_enter, idx, state)\t\\\n\t__CPU_PM_CPU_IDLE_ENTER(low_level_idle_enter, idx, state, 0, 1)\n\n#define CPU_PM_CPU_IDLE_ENTER_RETENTION_PARAM(low_level_idle_enter, idx, state)\t\\\n\t__CPU_PM_CPU_IDLE_ENTER(low_level_idle_enter, idx, state, 1, 0)\n\n#define CPU_PM_CPU_IDLE_ENTER_RETENTION_PARAM_RCU(low_level_idle_enter, idx, state)\t\\\n\t__CPU_PM_CPU_IDLE_ENTER(low_level_idle_enter, idx, state, 1, 1)\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}