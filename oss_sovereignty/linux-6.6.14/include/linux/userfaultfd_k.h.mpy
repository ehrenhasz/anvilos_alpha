{
  "module_name": "userfaultfd_k.h",
  "hash_id": "e60aae84531af64083f8bb982f161d13d55bda8335affbfc7ab37f284e9b6d85",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/userfaultfd_k.h",
  "human_readable_source": " \n \n\n#ifndef _LINUX_USERFAULTFD_K_H\n#define _LINUX_USERFAULTFD_K_H\n\n#ifdef CONFIG_USERFAULTFD\n\n#include <linux/userfaultfd.h>  \n\n#include <linux/fcntl.h>\n#include <linux/mm.h>\n#include <linux/swap.h>\n#include <linux/swapops.h>\n#include <asm-generic/pgtable_uffd.h>\n#include <linux/hugetlb_inline.h>\n\n \n#define __VM_UFFD_FLAGS (VM_UFFD_MISSING | VM_UFFD_WP | VM_UFFD_MINOR)\n\n \n#define UFFD_CLOEXEC O_CLOEXEC\n#define UFFD_NONBLOCK O_NONBLOCK\n\n#define UFFD_SHARED_FCNTL_FLAGS (O_CLOEXEC | O_NONBLOCK)\n#define UFFD_FLAGS_SET (EFD_SHARED_FCNTL_FLAGS)\n\nextern vm_fault_t handle_userfault(struct vm_fault *vmf, unsigned long reason);\n\n \ntypedef unsigned int __bitwise uffd_flags_t;\n\n \nenum mfill_atomic_mode {\n\tMFILL_ATOMIC_COPY,\n\tMFILL_ATOMIC_ZEROPAGE,\n\tMFILL_ATOMIC_CONTINUE,\n\tMFILL_ATOMIC_POISON,\n\tNR_MFILL_ATOMIC_MODES,\n};\n\n#define MFILL_ATOMIC_MODE_BITS (const_ilog2(NR_MFILL_ATOMIC_MODES - 1) + 1)\n#define MFILL_ATOMIC_BIT(nr) BIT(MFILL_ATOMIC_MODE_BITS + (nr))\n#define MFILL_ATOMIC_FLAG(nr) ((__force uffd_flags_t) MFILL_ATOMIC_BIT(nr))\n#define MFILL_ATOMIC_MODE_MASK ((__force uffd_flags_t) (MFILL_ATOMIC_BIT(0) - 1))\n\nstatic inline bool uffd_flags_mode_is(uffd_flags_t flags, enum mfill_atomic_mode expected)\n{\n\treturn (flags & MFILL_ATOMIC_MODE_MASK) == ((__force uffd_flags_t) expected);\n}\n\nstatic inline uffd_flags_t uffd_flags_set_mode(uffd_flags_t flags, enum mfill_atomic_mode mode)\n{\n\tflags &= ~MFILL_ATOMIC_MODE_MASK;\n\treturn flags | ((__force uffd_flags_t) mode);\n}\n\n \n#define MFILL_ATOMIC_WP MFILL_ATOMIC_FLAG(0)\n\nextern int mfill_atomic_install_pte(pmd_t *dst_pmd,\n\t\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t\t    unsigned long dst_addr, struct page *page,\n\t\t\t\t    bool newly_allocated, uffd_flags_t flags);\n\nextern ssize_t mfill_atomic_copy(struct mm_struct *dst_mm, unsigned long dst_start,\n\t\t\t\t unsigned long src_start, unsigned long len,\n\t\t\t\t atomic_t *mmap_changing, uffd_flags_t flags);\nextern ssize_t mfill_atomic_zeropage(struct mm_struct *dst_mm,\n\t\t\t\t     unsigned long dst_start,\n\t\t\t\t     unsigned long len,\n\t\t\t\t     atomic_t *mmap_changing);\nextern ssize_t mfill_atomic_continue(struct mm_struct *dst_mm, unsigned long dst_start,\n\t\t\t\t     unsigned long len, atomic_t *mmap_changing,\n\t\t\t\t     uffd_flags_t flags);\nextern ssize_t mfill_atomic_poison(struct mm_struct *dst_mm, unsigned long start,\n\t\t\t\t   unsigned long len, atomic_t *mmap_changing,\n\t\t\t\t   uffd_flags_t flags);\nextern int mwriteprotect_range(struct mm_struct *dst_mm,\n\t\t\t       unsigned long start, unsigned long len,\n\t\t\t       bool enable_wp, atomic_t *mmap_changing);\nextern long uffd_wp_range(struct vm_area_struct *vma,\n\t\t\t  unsigned long start, unsigned long len, bool enable_wp);\n\n \nstatic inline bool is_mergeable_vm_userfaultfd_ctx(struct vm_area_struct *vma,\n\t\t\t\t\tstruct vm_userfaultfd_ctx vm_ctx)\n{\n\treturn vma->vm_userfaultfd_ctx.ctx == vm_ctx.ctx;\n}\n\n \nstatic inline bool uffd_disable_huge_pmd_share(struct vm_area_struct *vma)\n{\n\treturn vma->vm_flags & (VM_UFFD_WP | VM_UFFD_MINOR);\n}\n\n \nstatic inline bool uffd_disable_fault_around(struct vm_area_struct *vma)\n{\n\treturn vma->vm_flags & (VM_UFFD_WP | VM_UFFD_MINOR);\n}\n\nstatic inline bool userfaultfd_missing(struct vm_area_struct *vma)\n{\n\treturn vma->vm_flags & VM_UFFD_MISSING;\n}\n\nstatic inline bool userfaultfd_wp(struct vm_area_struct *vma)\n{\n\treturn vma->vm_flags & VM_UFFD_WP;\n}\n\nstatic inline bool userfaultfd_minor(struct vm_area_struct *vma)\n{\n\treturn vma->vm_flags & VM_UFFD_MINOR;\n}\n\nstatic inline bool userfaultfd_pte_wp(struct vm_area_struct *vma,\n\t\t\t\t      pte_t pte)\n{\n\treturn userfaultfd_wp(vma) && pte_uffd_wp(pte);\n}\n\nstatic inline bool userfaultfd_huge_pmd_wp(struct vm_area_struct *vma,\n\t\t\t\t\t   pmd_t pmd)\n{\n\treturn userfaultfd_wp(vma) && pmd_uffd_wp(pmd);\n}\n\nstatic inline bool userfaultfd_armed(struct vm_area_struct *vma)\n{\n\treturn vma->vm_flags & __VM_UFFD_FLAGS;\n}\n\nstatic inline bool vma_can_userfault(struct vm_area_struct *vma,\n\t\t\t\t     unsigned long vm_flags)\n{\n\tif ((vm_flags & VM_UFFD_MINOR) &&\n\t    (!is_vm_hugetlb_page(vma) && !vma_is_shmem(vma)))\n\t\treturn false;\n#ifndef CONFIG_PTE_MARKER_UFFD_WP\n\t \n\tif ((vm_flags & VM_UFFD_WP) && !vma_is_anonymous(vma))\n\t\treturn false;\n#endif\n\treturn vma_is_anonymous(vma) || is_vm_hugetlb_page(vma) ||\n\t    vma_is_shmem(vma);\n}\n\nextern int dup_userfaultfd(struct vm_area_struct *, struct list_head *);\nextern void dup_userfaultfd_complete(struct list_head *);\n\nextern void mremap_userfaultfd_prep(struct vm_area_struct *,\n\t\t\t\t    struct vm_userfaultfd_ctx *);\nextern void mremap_userfaultfd_complete(struct vm_userfaultfd_ctx *,\n\t\t\t\t\tunsigned long from, unsigned long to,\n\t\t\t\t\tunsigned long len);\n\nextern bool userfaultfd_remove(struct vm_area_struct *vma,\n\t\t\t       unsigned long start,\n\t\t\t       unsigned long end);\n\nextern int userfaultfd_unmap_prep(struct vm_area_struct *vma,\n\t\tunsigned long start, unsigned long end, struct list_head *uf);\nextern void userfaultfd_unmap_complete(struct mm_struct *mm,\n\t\t\t\t       struct list_head *uf);\nextern bool userfaultfd_wp_unpopulated(struct vm_area_struct *vma);\n\n#else  \n\n \nstatic inline vm_fault_t handle_userfault(struct vm_fault *vmf,\n\t\t\t\tunsigned long reason)\n{\n\treturn VM_FAULT_SIGBUS;\n}\n\nstatic inline bool is_mergeable_vm_userfaultfd_ctx(struct vm_area_struct *vma,\n\t\t\t\t\tstruct vm_userfaultfd_ctx vm_ctx)\n{\n\treturn true;\n}\n\nstatic inline bool userfaultfd_missing(struct vm_area_struct *vma)\n{\n\treturn false;\n}\n\nstatic inline bool userfaultfd_wp(struct vm_area_struct *vma)\n{\n\treturn false;\n}\n\nstatic inline bool userfaultfd_minor(struct vm_area_struct *vma)\n{\n\treturn false;\n}\n\nstatic inline bool userfaultfd_pte_wp(struct vm_area_struct *vma,\n\t\t\t\t      pte_t pte)\n{\n\treturn false;\n}\n\nstatic inline bool userfaultfd_huge_pmd_wp(struct vm_area_struct *vma,\n\t\t\t\t\t   pmd_t pmd)\n{\n\treturn false;\n}\n\n\nstatic inline bool userfaultfd_armed(struct vm_area_struct *vma)\n{\n\treturn false;\n}\n\nstatic inline int dup_userfaultfd(struct vm_area_struct *vma,\n\t\t\t\t  struct list_head *l)\n{\n\treturn 0;\n}\n\nstatic inline void dup_userfaultfd_complete(struct list_head *l)\n{\n}\n\nstatic inline void mremap_userfaultfd_prep(struct vm_area_struct *vma,\n\t\t\t\t\t   struct vm_userfaultfd_ctx *ctx)\n{\n}\n\nstatic inline void mremap_userfaultfd_complete(struct vm_userfaultfd_ctx *ctx,\n\t\t\t\t\t       unsigned long from,\n\t\t\t\t\t       unsigned long to,\n\t\t\t\t\t       unsigned long len)\n{\n}\n\nstatic inline bool userfaultfd_remove(struct vm_area_struct *vma,\n\t\t\t\t      unsigned long start,\n\t\t\t\t      unsigned long end)\n{\n\treturn true;\n}\n\nstatic inline int userfaultfd_unmap_prep(struct vm_area_struct *vma,\n\t\t\t\t\t unsigned long start, unsigned long end,\n\t\t\t\t\t struct list_head *uf)\n{\n\treturn 0;\n}\n\nstatic inline void userfaultfd_unmap_complete(struct mm_struct *mm,\n\t\t\t\t\t      struct list_head *uf)\n{\n}\n\nstatic inline bool uffd_disable_fault_around(struct vm_area_struct *vma)\n{\n\treturn false;\n}\n\nstatic inline bool userfaultfd_wp_unpopulated(struct vm_area_struct *vma)\n{\n\treturn false;\n}\n\n#endif  \n\nstatic inline bool userfaultfd_wp_use_markers(struct vm_area_struct *vma)\n{\n\t \n\tif (!userfaultfd_wp(vma))\n\t\treturn false;\n\n\t \n\tif (!vma_is_anonymous(vma))\n\t\treturn true;\n\n\t \n\treturn userfaultfd_wp_unpopulated(vma);\n}\n\nstatic inline bool pte_marker_entry_uffd_wp(swp_entry_t entry)\n{\n#ifdef CONFIG_PTE_MARKER_UFFD_WP\n\treturn is_pte_marker_entry(entry) &&\n\t    (pte_marker_get(entry) & PTE_MARKER_UFFD_WP);\n#else\n\treturn false;\n#endif\n}\n\nstatic inline bool pte_marker_uffd_wp(pte_t pte)\n{\n#ifdef CONFIG_PTE_MARKER_UFFD_WP\n\tswp_entry_t entry;\n\n\tif (!is_swap_pte(pte))\n\t\treturn false;\n\n\tentry = pte_to_swp_entry(pte);\n\n\treturn pte_marker_entry_uffd_wp(entry);\n#else\n\treturn false;\n#endif\n}\n\n \nstatic inline bool pte_swp_uffd_wp_any(pte_t pte)\n{\n#ifdef CONFIG_PTE_MARKER_UFFD_WP\n\tif (!is_swap_pte(pte))\n\t\treturn false;\n\n\tif (pte_swp_uffd_wp(pte))\n\t\treturn true;\n\n\tif (pte_marker_uffd_wp(pte))\n\t\treturn true;\n#endif\n\treturn false;\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}