{
  "module_name": "thunderbolt.h",
  "hash_id": "66b0c439c0bab1003ee15815dc1044c1fc078d761260a3ade9e777ebfa14f027",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/thunderbolt.h",
  "human_readable_source": " \n \n\n#ifndef THUNDERBOLT_H_\n#define THUNDERBOLT_H_\n\n#include <linux/device.h>\n#include <linux/idr.h>\n#include <linux/list.h>\n#include <linux/mutex.h>\n#include <linux/mod_devicetable.h>\n#include <linux/pci.h>\n#include <linux/uuid.h>\n#include <linux/workqueue.h>\n\nenum tb_cfg_pkg_type {\n\tTB_CFG_PKG_READ = 1,\n\tTB_CFG_PKG_WRITE = 2,\n\tTB_CFG_PKG_ERROR = 3,\n\tTB_CFG_PKG_NOTIFY_ACK = 4,\n\tTB_CFG_PKG_EVENT = 5,\n\tTB_CFG_PKG_XDOMAIN_REQ = 6,\n\tTB_CFG_PKG_XDOMAIN_RESP = 7,\n\tTB_CFG_PKG_OVERRIDE = 8,\n\tTB_CFG_PKG_RESET = 9,\n\tTB_CFG_PKG_ICM_EVENT = 10,\n\tTB_CFG_PKG_ICM_CMD = 11,\n\tTB_CFG_PKG_ICM_RESP = 12,\n\tTB_CFG_PKG_PREPARE_TO_SLEEP = 13,\n};\n\n \nenum tb_security_level {\n\tTB_SECURITY_NONE,\n\tTB_SECURITY_USER,\n\tTB_SECURITY_SECURE,\n\tTB_SECURITY_DPONLY,\n\tTB_SECURITY_USBONLY,\n\tTB_SECURITY_NOPCIE,\n};\n\n \nstruct tb {\n\tstruct device dev;\n\tstruct mutex lock;\n\tstruct tb_nhi *nhi;\n\tstruct tb_ctl *ctl;\n\tstruct workqueue_struct *wq;\n\tstruct tb_switch *root_switch;\n\tconst struct tb_cm_ops *cm_ops;\n\tint index;\n\tenum tb_security_level security_level;\n\tsize_t nboot_acl;\n\tunsigned long privdata[];\n};\n\nextern struct bus_type tb_bus_type;\nextern struct device_type tb_service_type;\nextern struct device_type tb_xdomain_type;\n\n#define TB_LINKS_PER_PHY_PORT\t2\n\nstatic inline unsigned int tb_phy_port_from_link(unsigned int link)\n{\n\treturn (link - 1) / TB_LINKS_PER_PHY_PORT;\n}\n\n \nstruct tb_property_dir {\n\tconst uuid_t *uuid;\n\tstruct list_head properties;\n};\n\nenum tb_property_type {\n\tTB_PROPERTY_TYPE_UNKNOWN = 0x00,\n\tTB_PROPERTY_TYPE_DIRECTORY = 0x44,\n\tTB_PROPERTY_TYPE_DATA = 0x64,\n\tTB_PROPERTY_TYPE_TEXT = 0x74,\n\tTB_PROPERTY_TYPE_VALUE = 0x76,\n};\n\n#define TB_PROPERTY_KEY_SIZE\t8\n\n \nstruct tb_property {\n\tstruct list_head list;\n\tchar key[TB_PROPERTY_KEY_SIZE + 1];\n\tenum tb_property_type type;\n\tsize_t length;\n\tunion {\n\t\tstruct tb_property_dir *dir;\n\t\tu8 *data;\n\t\tchar *text;\n\t\tu32 immediate;\n\t} value;\n};\n\nstruct tb_property_dir *tb_property_parse_dir(const u32 *block,\n\t\t\t\t\t      size_t block_len);\nssize_t tb_property_format_dir(const struct tb_property_dir *dir, u32 *block,\n\t\t\t       size_t block_len);\nstruct tb_property_dir *tb_property_copy_dir(const struct tb_property_dir *dir);\nstruct tb_property_dir *tb_property_create_dir(const uuid_t *uuid);\nvoid tb_property_free_dir(struct tb_property_dir *dir);\nint tb_property_add_immediate(struct tb_property_dir *parent, const char *key,\n\t\t\t      u32 value);\nint tb_property_add_data(struct tb_property_dir *parent, const char *key,\n\t\t\t const void *buf, size_t buflen);\nint tb_property_add_text(struct tb_property_dir *parent, const char *key,\n\t\t\t const char *text);\nint tb_property_add_dir(struct tb_property_dir *parent, const char *key,\n\t\t\tstruct tb_property_dir *dir);\nvoid tb_property_remove(struct tb_property *tb_property);\nstruct tb_property *tb_property_find(struct tb_property_dir *dir,\n\t\t\tconst char *key, enum tb_property_type type);\nstruct tb_property *tb_property_get_next(struct tb_property_dir *dir,\n\t\t\t\t\t struct tb_property *prev);\n\n#define tb_property_for_each(dir, property)\t\t\t\\\n\tfor (property = tb_property_get_next(dir, NULL);\t\\\n\t     property;\t\t\t\t\t\t\\\n\t     property = tb_property_get_next(dir, property))\n\nint tb_register_property_dir(const char *key, struct tb_property_dir *dir);\nvoid tb_unregister_property_dir(const char *key, struct tb_property_dir *dir);\n\n \nenum tb_link_width {\n\tTB_LINK_WIDTH_SINGLE = BIT(0),\n\tTB_LINK_WIDTH_DUAL = BIT(1),\n\tTB_LINK_WIDTH_ASYM_TX = BIT(2),\n\tTB_LINK_WIDTH_ASYM_RX = BIT(3),\n};\n\n \nstruct tb_xdomain {\n\tstruct device dev;\n\tstruct tb *tb;\n\tuuid_t *remote_uuid;\n\tconst uuid_t *local_uuid;\n\tu64 route;\n\tu16 vendor;\n\tu16 device;\n\tunsigned int local_max_hopid;\n\tunsigned int remote_max_hopid;\n\tstruct mutex lock;\n\tconst char *vendor_name;\n\tconst char *device_name;\n\tunsigned int link_speed;\n\tenum tb_link_width link_width;\n\tbool link_usb4;\n\tbool is_unplugged;\n\tbool needs_uuid;\n\tstruct ida service_ids;\n\tstruct ida in_hopids;\n\tstruct ida out_hopids;\n\tu32 *local_property_block;\n\tu32 local_property_block_gen;\n\tu32 local_property_block_len;\n\tstruct tb_property_dir *remote_properties;\n\tu32 remote_property_block_gen;\n\tint state;\n\tstruct delayed_work state_work;\n\tint state_retries;\n\tstruct delayed_work properties_changed_work;\n\tint properties_changed_retries;\n\tbool bonding_possible;\n\tu8 target_link_width;\n\tu8 link;\n\tu8 depth;\n};\n\nint tb_xdomain_lane_bonding_enable(struct tb_xdomain *xd);\nvoid tb_xdomain_lane_bonding_disable(struct tb_xdomain *xd);\nint tb_xdomain_alloc_in_hopid(struct tb_xdomain *xd, int hopid);\nvoid tb_xdomain_release_in_hopid(struct tb_xdomain *xd, int hopid);\nint tb_xdomain_alloc_out_hopid(struct tb_xdomain *xd, int hopid);\nvoid tb_xdomain_release_out_hopid(struct tb_xdomain *xd, int hopid);\nint tb_xdomain_enable_paths(struct tb_xdomain *xd, int transmit_path,\n\t\t\t    int transmit_ring, int receive_path,\n\t\t\t    int receive_ring);\nint tb_xdomain_disable_paths(struct tb_xdomain *xd, int transmit_path,\n\t\t\t     int transmit_ring, int receive_path,\n\t\t\t     int receive_ring);\n\nstatic inline int tb_xdomain_disable_all_paths(struct tb_xdomain *xd)\n{\n\treturn tb_xdomain_disable_paths(xd, -1, -1, -1, -1);\n}\n\nstruct tb_xdomain *tb_xdomain_find_by_uuid(struct tb *tb, const uuid_t *uuid);\nstruct tb_xdomain *tb_xdomain_find_by_route(struct tb *tb, u64 route);\n\nstatic inline struct tb_xdomain *\ntb_xdomain_find_by_uuid_locked(struct tb *tb, const uuid_t *uuid)\n{\n\tstruct tb_xdomain *xd;\n\n\tmutex_lock(&tb->lock);\n\txd = tb_xdomain_find_by_uuid(tb, uuid);\n\tmutex_unlock(&tb->lock);\n\n\treturn xd;\n}\n\nstatic inline struct tb_xdomain *\ntb_xdomain_find_by_route_locked(struct tb *tb, u64 route)\n{\n\tstruct tb_xdomain *xd;\n\n\tmutex_lock(&tb->lock);\n\txd = tb_xdomain_find_by_route(tb, route);\n\tmutex_unlock(&tb->lock);\n\n\treturn xd;\n}\n\nstatic inline struct tb_xdomain *tb_xdomain_get(struct tb_xdomain *xd)\n{\n\tif (xd)\n\t\tget_device(&xd->dev);\n\treturn xd;\n}\n\nstatic inline void tb_xdomain_put(struct tb_xdomain *xd)\n{\n\tif (xd)\n\t\tput_device(&xd->dev);\n}\n\nstatic inline bool tb_is_xdomain(const struct device *dev)\n{\n\treturn dev->type == &tb_xdomain_type;\n}\n\nstatic inline struct tb_xdomain *tb_to_xdomain(struct device *dev)\n{\n\tif (tb_is_xdomain(dev))\n\t\treturn container_of(dev, struct tb_xdomain, dev);\n\treturn NULL;\n}\n\nint tb_xdomain_response(struct tb_xdomain *xd, const void *response,\n\t\t\tsize_t size, enum tb_cfg_pkg_type type);\nint tb_xdomain_request(struct tb_xdomain *xd, const void *request,\n\t\t       size_t request_size, enum tb_cfg_pkg_type request_type,\n\t\t       void *response, size_t response_size,\n\t\t       enum tb_cfg_pkg_type response_type,\n\t\t       unsigned int timeout_msec);\n\n \nstruct tb_protocol_handler {\n\tconst uuid_t *uuid;\n\tint (*callback)(const void *buf, size_t size, void *data);\n\tvoid *data;\n\tstruct list_head list;\n};\n\nint tb_register_protocol_handler(struct tb_protocol_handler *handler);\nvoid tb_unregister_protocol_handler(struct tb_protocol_handler *handler);\n\n \nstruct tb_service {\n\tstruct device dev;\n\tint id;\n\tconst char *key;\n\tu32 prtcid;\n\tu32 prtcvers;\n\tu32 prtcrevs;\n\tu32 prtcstns;\n\tstruct dentry *debugfs_dir;\n};\n\nstatic inline struct tb_service *tb_service_get(struct tb_service *svc)\n{\n\tif (svc)\n\t\tget_device(&svc->dev);\n\treturn svc;\n}\n\nstatic inline void tb_service_put(struct tb_service *svc)\n{\n\tif (svc)\n\t\tput_device(&svc->dev);\n}\n\nstatic inline bool tb_is_service(const struct device *dev)\n{\n\treturn dev->type == &tb_service_type;\n}\n\nstatic inline struct tb_service *tb_to_service(struct device *dev)\n{\n\tif (tb_is_service(dev))\n\t\treturn container_of(dev, struct tb_service, dev);\n\treturn NULL;\n}\n\n \nstruct tb_service_driver {\n\tstruct device_driver driver;\n\tint (*probe)(struct tb_service *svc, const struct tb_service_id *id);\n\tvoid (*remove)(struct tb_service *svc);\n\tvoid (*shutdown)(struct tb_service *svc);\n\tconst struct tb_service_id *id_table;\n};\n\n#define TB_SERVICE(key, id)\t\t\t\t\\\n\t.match_flags = TBSVC_MATCH_PROTOCOL_KEY |\t\\\n\t\t       TBSVC_MATCH_PROTOCOL_ID,\t\t\\\n\t.protocol_key = (key),\t\t\t\t\\\n\t.protocol_id = (id)\n\nint tb_register_service_driver(struct tb_service_driver *drv);\nvoid tb_unregister_service_driver(struct tb_service_driver *drv);\n\nstatic inline void *tb_service_get_drvdata(const struct tb_service *svc)\n{\n\treturn dev_get_drvdata(&svc->dev);\n}\n\nstatic inline void tb_service_set_drvdata(struct tb_service *svc, void *data)\n{\n\tdev_set_drvdata(&svc->dev, data);\n}\n\nstatic inline struct tb_xdomain *tb_service_parent(struct tb_service *svc)\n{\n\treturn tb_to_xdomain(svc->dev.parent);\n}\n\n \nstruct tb_nhi {\n\tspinlock_t lock;\n\tstruct pci_dev *pdev;\n\tconst struct tb_nhi_ops *ops;\n\tvoid __iomem *iobase;\n\tstruct tb_ring **tx_rings;\n\tstruct tb_ring **rx_rings;\n\tstruct ida msix_ida;\n\tbool going_away;\n\tbool iommu_dma_protection;\n\tstruct work_struct interrupt_work;\n\tu32 hop_count;\n\tunsigned long quirks;\n};\n\n \nstruct tb_ring {\n\tspinlock_t lock;\n\tstruct tb_nhi *nhi;\n\tint size;\n\tint hop;\n\tint head;\n\tint tail;\n\tstruct ring_desc *descriptors;\n\tdma_addr_t descriptors_dma;\n\tstruct list_head queue;\n\tstruct list_head in_flight;\n\tstruct work_struct work;\n\tbool is_tx:1;\n\tbool running:1;\n\tint irq;\n\tu8 vector;\n\tunsigned int flags;\n\tint e2e_tx_hop;\n\tu16 sof_mask;\n\tu16 eof_mask;\n\tvoid (*start_poll)(void *data);\n\tvoid *poll_data;\n};\n\n \n#define RING_FLAG_NO_SUSPEND\tBIT(0)\n \n#define RING_FLAG_FRAME\t\tBIT(1)\n \n#define RING_FLAG_E2E\t\tBIT(2)\n\nstruct ring_frame;\ntypedef void (*ring_cb)(struct tb_ring *, struct ring_frame *, bool canceled);\n\n \nenum ring_desc_flags {\n\tRING_DESC_ISOCH = 0x1,\n\tRING_DESC_CRC_ERROR = 0x1,\n\tRING_DESC_COMPLETED = 0x2,\n\tRING_DESC_POSTED = 0x4,\n\tRING_DESC_BUFFER_OVERRUN = 0x04,\n\tRING_DESC_INTERRUPT = 0x8,\n};\n\n \nstruct ring_frame {\n\tdma_addr_t buffer_phy;\n\tring_cb callback;\n\tstruct list_head list;\n\tu32 size:12;\n\tu32 flags:12;\n\tu32 eof:4;\n\tu32 sof:4;\n};\n\n \n#define TB_FRAME_SIZE\t\t0x100\n\nstruct tb_ring *tb_ring_alloc_tx(struct tb_nhi *nhi, int hop, int size,\n\t\t\t\t unsigned int flags);\nstruct tb_ring *tb_ring_alloc_rx(struct tb_nhi *nhi, int hop, int size,\n\t\t\t\t unsigned int flags, int e2e_tx_hop,\n\t\t\t\t u16 sof_mask, u16 eof_mask,\n\t\t\t\t void (*start_poll)(void *), void *poll_data);\nvoid tb_ring_start(struct tb_ring *ring);\nvoid tb_ring_stop(struct tb_ring *ring);\nvoid tb_ring_free(struct tb_ring *ring);\n\nint __tb_ring_enqueue(struct tb_ring *ring, struct ring_frame *frame);\n\n \nstatic inline int tb_ring_rx(struct tb_ring *ring, struct ring_frame *frame)\n{\n\tWARN_ON(ring->is_tx);\n\treturn __tb_ring_enqueue(ring, frame);\n}\n\n \nstatic inline int tb_ring_tx(struct tb_ring *ring, struct ring_frame *frame)\n{\n\tWARN_ON(!ring->is_tx);\n\treturn __tb_ring_enqueue(ring, frame);\n}\n\n \nstruct ring_frame *tb_ring_poll(struct tb_ring *ring);\nvoid tb_ring_poll_complete(struct tb_ring *ring);\n\n \nstatic inline struct device *tb_ring_dma_device(struct tb_ring *ring)\n{\n\treturn &ring->nhi->pdev->dev;\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}