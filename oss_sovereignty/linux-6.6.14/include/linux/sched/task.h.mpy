{
  "module_name": "task.h",
  "hash_id": "c41528d8877f9e06fd1767b20ab9de7965a85423266c76b029be04c90ed0c6d4",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/sched/task.h",
  "human_readable_source": " \n#ifndef _LINUX_SCHED_TASK_H\n#define _LINUX_SCHED_TASK_H\n\n \n\n#include <linux/sched.h>\n#include <linux/uaccess.h>\n\nstruct task_struct;\nstruct rusage;\nunion thread_union;\nstruct css_set;\n\n \n#define CLONE_LEGACY_FLAGS 0xffffffffULL\n\nstruct kernel_clone_args {\n\tu64 flags;\n\tint __user *pidfd;\n\tint __user *child_tid;\n\tint __user *parent_tid;\n\tconst char *name;\n\tint exit_signal;\n\tu32 kthread:1;\n\tu32 io_thread:1;\n\tu32 user_worker:1;\n\tu32 no_files:1;\n\tunsigned long stack;\n\tunsigned long stack_size;\n\tunsigned long tls;\n\tpid_t *set_tid;\n\t \n\tsize_t set_tid_size;\n\tint cgroup;\n\tint idle;\n\tint (*fn)(void *);\n\tvoid *fn_arg;\n\tstruct cgroup *cgrp;\n\tstruct css_set *cset;\n};\n\n \nextern rwlock_t tasklist_lock;\nextern spinlock_t mmlist_lock;\n\nextern union thread_union init_thread_union;\nextern struct task_struct init_task;\n\nextern int lockdep_tasklist_lock_is_held(void);\n\nextern asmlinkage void schedule_tail(struct task_struct *prev);\nextern void init_idle(struct task_struct *idle, int cpu);\n\nextern int sched_fork(unsigned long clone_flags, struct task_struct *p);\nextern void sched_cgroup_fork(struct task_struct *p, struct kernel_clone_args *kargs);\nextern void sched_post_fork(struct task_struct *p);\nextern void sched_dead(struct task_struct *p);\n\nvoid __noreturn do_task_dead(void);\nvoid __noreturn make_task_dead(int signr);\n\nextern void mm_cache_init(void);\nextern void proc_caches_init(void);\n\nextern void fork_init(void);\n\nextern void release_task(struct task_struct * p);\n\nextern int copy_thread(struct task_struct *, const struct kernel_clone_args *);\n\nextern void flush_thread(void);\n\n#ifdef CONFIG_HAVE_EXIT_THREAD\nextern void exit_thread(struct task_struct *tsk);\n#else\nstatic inline void exit_thread(struct task_struct *tsk)\n{\n}\n#endif\nextern __noreturn void do_group_exit(int);\n\nextern void exit_files(struct task_struct *);\nextern void exit_itimers(struct task_struct *);\n\nextern pid_t kernel_clone(struct kernel_clone_args *kargs);\nstruct task_struct *copy_process(struct pid *pid, int trace, int node,\n\t\t\t\t struct kernel_clone_args *args);\nstruct task_struct *create_io_thread(int (*fn)(void *), void *arg, int node);\nstruct task_struct *fork_idle(int);\nextern pid_t kernel_thread(int (*fn)(void *), void *arg, const char *name,\n\t\t\t    unsigned long flags);\nextern pid_t user_mode_thread(int (*fn)(void *), void *arg, unsigned long flags);\nextern long kernel_wait4(pid_t, int __user *, int, struct rusage *);\nint kernel_wait(pid_t pid, int *stat);\n\nextern void free_task(struct task_struct *tsk);\n\n \n#ifdef CONFIG_SMP\nextern void sched_exec(void);\n#else\n#define sched_exec()   {}\n#endif\n\nstatic inline struct task_struct *get_task_struct(struct task_struct *t)\n{\n\trefcount_inc(&t->usage);\n\treturn t;\n}\n\nextern void __put_task_struct(struct task_struct *t);\nextern void __put_task_struct_rcu_cb(struct rcu_head *rhp);\n\nstatic inline void put_task_struct(struct task_struct *t)\n{\n\tif (!refcount_dec_and_test(&t->usage))\n\t\treturn;\n\n\t \n\tif (!IS_ENABLED(CONFIG_PREEMPT_RT) || preemptible()) {\n\t\tstatic DEFINE_WAIT_OVERRIDE_MAP(put_task_map, LD_WAIT_SLEEP);\n\n\t\tlock_map_acquire_try(&put_task_map);\n\t\t__put_task_struct(t);\n\t\tlock_map_release(&put_task_map);\n\t\treturn;\n\t}\n\n\t \n\tcall_rcu(&t->rcu, __put_task_struct_rcu_cb);\n}\n\nDEFINE_FREE(put_task, struct task_struct *, if (_T) put_task_struct(_T))\n\nstatic inline void put_task_struct_many(struct task_struct *t, int nr)\n{\n\tif (refcount_sub_and_test(nr, &t->usage))\n\t\t__put_task_struct(t);\n}\n\nvoid put_task_struct_rcu_user(struct task_struct *task);\n\n \nvoid release_thread(struct task_struct *dead_task);\n\n#ifdef CONFIG_ARCH_WANTS_DYNAMIC_TASK_STRUCT\nextern int arch_task_struct_size __read_mostly;\n#else\n# define arch_task_struct_size (sizeof(struct task_struct))\n#endif\n\n#ifndef CONFIG_HAVE_ARCH_THREAD_STRUCT_WHITELIST\n \nstatic inline void arch_thread_struct_whitelist(unsigned long *offset,\n\t\t\t\t\t\tunsigned long *size)\n{\n\t*offset = 0;\n\t \n\t*size = arch_task_struct_size - offsetof(struct task_struct, thread);\n}\n#endif\n\n#ifdef CONFIG_VMAP_STACK\nstatic inline struct vm_struct *task_stack_vm_area(const struct task_struct *t)\n{\n\treturn t->stack_vm_area;\n}\n#else\nstatic inline struct vm_struct *task_stack_vm_area(const struct task_struct *t)\n{\n\treturn NULL;\n}\n#endif\n\n \nstatic inline void task_lock(struct task_struct *p)\n{\n\tspin_lock(&p->alloc_lock);\n}\n\nstatic inline void task_unlock(struct task_struct *p)\n{\n\tspin_unlock(&p->alloc_lock);\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}