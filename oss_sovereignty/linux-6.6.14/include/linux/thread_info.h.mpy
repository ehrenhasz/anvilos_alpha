{
  "module_name": "thread_info.h",
  "hash_id": "c2ace3f8f7a311064bcd01254b157629fe3d524ad1c7bbbec3f6f0191fb693c0",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/thread_info.h",
  "human_readable_source": " \n \n\n#ifndef _LINUX_THREAD_INFO_H\n#define _LINUX_THREAD_INFO_H\n\n#include <linux/types.h>\n#include <linux/limits.h>\n#include <linux/bug.h>\n#include <linux/restart_block.h>\n#include <linux/errno.h>\n\n#ifdef CONFIG_THREAD_INFO_IN_TASK\n \n#include <asm/current.h>\n#define current_thread_info() ((struct thread_info *)current)\n#endif\n\n#include <linux/bitops.h>\n\n \nenum {\n\tBAD_STACK = -1,\n\tNOT_STACK = 0,\n\tGOOD_FRAME,\n\tGOOD_STACK,\n};\n\n#ifdef CONFIG_GENERIC_ENTRY\nenum syscall_work_bit {\n\tSYSCALL_WORK_BIT_SECCOMP,\n\tSYSCALL_WORK_BIT_SYSCALL_TRACEPOINT,\n\tSYSCALL_WORK_BIT_SYSCALL_TRACE,\n\tSYSCALL_WORK_BIT_SYSCALL_EMU,\n\tSYSCALL_WORK_BIT_SYSCALL_AUDIT,\n\tSYSCALL_WORK_BIT_SYSCALL_USER_DISPATCH,\n\tSYSCALL_WORK_BIT_SYSCALL_EXIT_TRAP,\n};\n\n#define SYSCALL_WORK_SECCOMP\t\tBIT(SYSCALL_WORK_BIT_SECCOMP)\n#define SYSCALL_WORK_SYSCALL_TRACEPOINT\tBIT(SYSCALL_WORK_BIT_SYSCALL_TRACEPOINT)\n#define SYSCALL_WORK_SYSCALL_TRACE\tBIT(SYSCALL_WORK_BIT_SYSCALL_TRACE)\n#define SYSCALL_WORK_SYSCALL_EMU\tBIT(SYSCALL_WORK_BIT_SYSCALL_EMU)\n#define SYSCALL_WORK_SYSCALL_AUDIT\tBIT(SYSCALL_WORK_BIT_SYSCALL_AUDIT)\n#define SYSCALL_WORK_SYSCALL_USER_DISPATCH BIT(SYSCALL_WORK_BIT_SYSCALL_USER_DISPATCH)\n#define SYSCALL_WORK_SYSCALL_EXIT_TRAP\tBIT(SYSCALL_WORK_BIT_SYSCALL_EXIT_TRAP)\n#endif\n\n#include <asm/thread_info.h>\n\n#ifdef __KERNEL__\n\n#ifndef arch_set_restart_data\n#define arch_set_restart_data(restart) do { } while (0)\n#endif\n\nstatic inline long set_restart_fn(struct restart_block *restart,\n\t\t\t\t\tlong (*fn)(struct restart_block *))\n{\n\trestart->fn = fn;\n\tarch_set_restart_data(restart);\n\treturn -ERESTART_RESTARTBLOCK;\n}\n\n#ifndef THREAD_ALIGN\n#define THREAD_ALIGN\tTHREAD_SIZE\n#endif\n\n#define THREADINFO_GFP\t\t(GFP_KERNEL_ACCOUNT | __GFP_ZERO)\n\n \n\nstatic inline void set_ti_thread_flag(struct thread_info *ti, int flag)\n{\n\tset_bit(flag, (unsigned long *)&ti->flags);\n}\n\nstatic inline void clear_ti_thread_flag(struct thread_info *ti, int flag)\n{\n\tclear_bit(flag, (unsigned long *)&ti->flags);\n}\n\nstatic inline void update_ti_thread_flag(struct thread_info *ti, int flag,\n\t\t\t\t\t bool value)\n{\n\tif (value)\n\t\tset_ti_thread_flag(ti, flag);\n\telse\n\t\tclear_ti_thread_flag(ti, flag);\n}\n\nstatic inline int test_and_set_ti_thread_flag(struct thread_info *ti, int flag)\n{\n\treturn test_and_set_bit(flag, (unsigned long *)&ti->flags);\n}\n\nstatic inline int test_and_clear_ti_thread_flag(struct thread_info *ti, int flag)\n{\n\treturn test_and_clear_bit(flag, (unsigned long *)&ti->flags);\n}\n\nstatic inline int test_ti_thread_flag(struct thread_info *ti, int flag)\n{\n\treturn test_bit(flag, (unsigned long *)&ti->flags);\n}\n\n \nstatic __always_inline unsigned long read_ti_thread_flags(struct thread_info *ti)\n{\n\treturn READ_ONCE(ti->flags);\n}\n\n#define set_thread_flag(flag) \\\n\tset_ti_thread_flag(current_thread_info(), flag)\n#define clear_thread_flag(flag) \\\n\tclear_ti_thread_flag(current_thread_info(), flag)\n#define update_thread_flag(flag, value) \\\n\tupdate_ti_thread_flag(current_thread_info(), flag, value)\n#define test_and_set_thread_flag(flag) \\\n\ttest_and_set_ti_thread_flag(current_thread_info(), flag)\n#define test_and_clear_thread_flag(flag) \\\n\ttest_and_clear_ti_thread_flag(current_thread_info(), flag)\n#define test_thread_flag(flag) \\\n\ttest_ti_thread_flag(current_thread_info(), flag)\n#define read_thread_flags() \\\n\tread_ti_thread_flags(current_thread_info())\n\n#define read_task_thread_flags(t) \\\n\tread_ti_thread_flags(task_thread_info(t))\n\n#ifdef CONFIG_GENERIC_ENTRY\n#define set_syscall_work(fl) \\\n\tset_bit(SYSCALL_WORK_BIT_##fl, &current_thread_info()->syscall_work)\n#define test_syscall_work(fl) \\\n\ttest_bit(SYSCALL_WORK_BIT_##fl, &current_thread_info()->syscall_work)\n#define clear_syscall_work(fl) \\\n\tclear_bit(SYSCALL_WORK_BIT_##fl, &current_thread_info()->syscall_work)\n\n#define set_task_syscall_work(t, fl) \\\n\tset_bit(SYSCALL_WORK_BIT_##fl, &task_thread_info(t)->syscall_work)\n#define test_task_syscall_work(t, fl) \\\n\ttest_bit(SYSCALL_WORK_BIT_##fl, &task_thread_info(t)->syscall_work)\n#define clear_task_syscall_work(t, fl) \\\n\tclear_bit(SYSCALL_WORK_BIT_##fl, &task_thread_info(t)->syscall_work)\n\n#else  \n\n#define set_syscall_work(fl)\t\t\t\t\t\t\\\n\tset_ti_thread_flag(current_thread_info(), TIF_##fl)\n#define test_syscall_work(fl) \\\n\ttest_ti_thread_flag(current_thread_info(), TIF_##fl)\n#define clear_syscall_work(fl) \\\n\tclear_ti_thread_flag(current_thread_info(), TIF_##fl)\n\n#define set_task_syscall_work(t, fl) \\\n\tset_ti_thread_flag(task_thread_info(t), TIF_##fl)\n#define test_task_syscall_work(t, fl) \\\n\ttest_ti_thread_flag(task_thread_info(t), TIF_##fl)\n#define clear_task_syscall_work(t, fl) \\\n\tclear_ti_thread_flag(task_thread_info(t), TIF_##fl)\n#endif  \n\n#ifdef _ASM_GENERIC_BITOPS_INSTRUMENTED_NON_ATOMIC_H\n\nstatic __always_inline bool tif_need_resched(void)\n{\n\treturn arch_test_bit(TIF_NEED_RESCHED,\n\t\t\t     (unsigned long *)(&current_thread_info()->flags));\n}\n\n#else\n\nstatic __always_inline bool tif_need_resched(void)\n{\n\treturn test_bit(TIF_NEED_RESCHED,\n\t\t\t(unsigned long *)(&current_thread_info()->flags));\n}\n\n#endif  \n\n#ifndef CONFIG_HAVE_ARCH_WITHIN_STACK_FRAMES\nstatic inline int arch_within_stack_frames(const void * const stack,\n\t\t\t\t\t   const void * const stackend,\n\t\t\t\t\t   const void *obj, unsigned long len)\n{\n\treturn 0;\n}\n#endif\n\n#ifdef CONFIG_HARDENED_USERCOPY\nextern void __check_object_size(const void *ptr, unsigned long n,\n\t\t\t\t\tbool to_user);\n\nstatic __always_inline void check_object_size(const void *ptr, unsigned long n,\n\t\t\t\t\t      bool to_user)\n{\n\tif (!__builtin_constant_p(n))\n\t\t__check_object_size(ptr, n, to_user);\n}\n#else\nstatic inline void check_object_size(const void *ptr, unsigned long n,\n\t\t\t\t     bool to_user)\n{ }\n#endif  \n\nextern void __compiletime_error(\"copy source size is too small\")\n__bad_copy_from(void);\nextern void __compiletime_error(\"copy destination size is too small\")\n__bad_copy_to(void);\n\nvoid __copy_overflow(int size, unsigned long count);\n\nstatic inline void copy_overflow(int size, unsigned long count)\n{\n\tif (IS_ENABLED(CONFIG_BUG))\n\t\t__copy_overflow(size, count);\n}\n\nstatic __always_inline __must_check bool\ncheck_copy_size(const void *addr, size_t bytes, bool is_source)\n{\n\tint sz = __builtin_object_size(addr, 0);\n\tif (unlikely(sz >= 0 && sz < bytes)) {\n\t\tif (!__builtin_constant_p(bytes))\n\t\t\tcopy_overflow(sz, bytes);\n\t\telse if (is_source)\n\t\t\t__bad_copy_from();\n\t\telse\n\t\t\t__bad_copy_to();\n\t\treturn false;\n\t}\n\tif (WARN_ON_ONCE(bytes > INT_MAX))\n\t\treturn false;\n\tcheck_object_size(addr, bytes, is_source);\n\treturn true;\n}\n\n#ifndef arch_setup_new_exec\nstatic inline void arch_setup_new_exec(void) { }\n#endif\n\nvoid arch_task_cache_init(void);  \nvoid arch_release_task_struct(struct task_struct *tsk);\nint arch_dup_task_struct(struct task_struct *dst,\n\t\t\t\tstruct task_struct *src);\n\n#endif\t \n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}