{
  "module_name": "math64.h",
  "hash_id": "3c7ceae0d0e1311dd8af0738feb2def668e9bd0bafd6b11381a3fb1645d73f52",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/math64.h",
  "human_readable_source": " \n#ifndef _LINUX_MATH64_H\n#define _LINUX_MATH64_H\n\n#include <linux/types.h>\n#include <linux/math.h>\n#include <vdso/math64.h>\n#include <asm/div64.h>\n\n#if BITS_PER_LONG == 64\n\n#define div64_long(x, y) div64_s64((x), (y))\n#define div64_ul(x, y)   div64_u64((x), (y))\n\n \nstatic inline u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)\n{\n\t*remainder = dividend % divisor;\n\treturn dividend / divisor;\n}\n\n \nstatic inline s64 div_s64_rem(s64 dividend, s32 divisor, s32 *remainder)\n{\n\t*remainder = dividend % divisor;\n\treturn dividend / divisor;\n}\n\n \nstatic inline u64 div64_u64_rem(u64 dividend, u64 divisor, u64 *remainder)\n{\n\t*remainder = dividend % divisor;\n\treturn dividend / divisor;\n}\n\n \nstatic inline u64 div64_u64(u64 dividend, u64 divisor)\n{\n\treturn dividend / divisor;\n}\n\n \nstatic inline s64 div64_s64(s64 dividend, s64 divisor)\n{\n\treturn dividend / divisor;\n}\n\n#elif BITS_PER_LONG == 32\n\n#define div64_long(x, y) div_s64((x), (y))\n#define div64_ul(x, y)   div_u64((x), (y))\n\n#ifndef div_u64_rem\nstatic inline u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)\n{\n\t*remainder = do_div(dividend, divisor);\n\treturn dividend;\n}\n#endif\n\n#ifndef div_s64_rem\nextern s64 div_s64_rem(s64 dividend, s32 divisor, s32 *remainder);\n#endif\n\n#ifndef div64_u64_rem\nextern u64 div64_u64_rem(u64 dividend, u64 divisor, u64 *remainder);\n#endif\n\n#ifndef div64_u64\nextern u64 div64_u64(u64 dividend, u64 divisor);\n#endif\n\n#ifndef div64_s64\nextern s64 div64_s64(s64 dividend, s64 divisor);\n#endif\n\n#endif  \n\n \n#ifndef div_u64\nstatic inline u64 div_u64(u64 dividend, u32 divisor)\n{\n\tu32 remainder;\n\treturn div_u64_rem(dividend, divisor, &remainder);\n}\n#endif\n\n \n#ifndef div_s64\nstatic inline s64 div_s64(s64 dividend, s32 divisor)\n{\n\ts32 remainder;\n\treturn div_s64_rem(dividend, divisor, &remainder);\n}\n#endif\n\nu32 iter_div_u64_rem(u64 dividend, u32 divisor, u64 *remainder);\n\n#ifndef mul_u32_u32\n \nstatic inline u64 mul_u32_u32(u32 a, u32 b)\n{\n\treturn (u64)a * b;\n}\n#endif\n\n#if defined(CONFIG_ARCH_SUPPORTS_INT128) && defined(__SIZEOF_INT128__)\n\n#ifndef mul_u64_u32_shr\nstatic __always_inline u64 mul_u64_u32_shr(u64 a, u32 mul, unsigned int shift)\n{\n\treturn (u64)(((unsigned __int128)a * mul) >> shift);\n}\n#endif  \n\n#ifndef mul_u64_u64_shr\nstatic __always_inline u64 mul_u64_u64_shr(u64 a, u64 mul, unsigned int shift)\n{\n\treturn (u64)(((unsigned __int128)a * mul) >> shift);\n}\n#endif  \n\n#else\n\n#ifndef mul_u64_u32_shr\nstatic __always_inline u64 mul_u64_u32_shr(u64 a, u32 mul, unsigned int shift)\n{\n\tu32 ah, al;\n\tu64 ret;\n\n\tal = a;\n\tah = a >> 32;\n\n\tret = mul_u32_u32(al, mul) >> shift;\n\tif (ah)\n\t\tret += mul_u32_u32(ah, mul) << (32 - shift);\n\n\treturn ret;\n}\n#endif  \n\n#ifndef mul_u64_u64_shr\nstatic inline u64 mul_u64_u64_shr(u64 a, u64 b, unsigned int shift)\n{\n\tunion {\n\t\tu64 ll;\n\t\tstruct {\n#ifdef __BIG_ENDIAN\n\t\t\tu32 high, low;\n#else\n\t\t\tu32 low, high;\n#endif\n\t\t} l;\n\t} rl, rm, rn, rh, a0, b0;\n\tu64 c;\n\n\ta0.ll = a;\n\tb0.ll = b;\n\n\trl.ll = mul_u32_u32(a0.l.low, b0.l.low);\n\trm.ll = mul_u32_u32(a0.l.low, b0.l.high);\n\trn.ll = mul_u32_u32(a0.l.high, b0.l.low);\n\trh.ll = mul_u32_u32(a0.l.high, b0.l.high);\n\n\t \n\trl.l.high = c = (u64)rl.l.high + rm.l.low + rn.l.low;\n\trh.l.low = c = (c >> 32) + rm.l.high + rn.l.high + rh.l.low;\n\trh.l.high = (c >> 32) + rh.l.high;\n\n\t \n\tif (shift == 0)\n\t\treturn rl.ll;\n\tif (shift < 64)\n\t\treturn (rl.ll >> shift) | (rh.ll << (64 - shift));\n\treturn rh.ll >> (shift & 63);\n}\n#endif  \n\n#endif\n\n#ifndef mul_s64_u64_shr\nstatic inline u64 mul_s64_u64_shr(s64 a, u64 b, unsigned int shift)\n{\n\tu64 ret;\n\n\t \n\tret = mul_u64_u64_shr(abs(a), b, shift);\n\n\tif (a < 0)\n\t\tret = -((s64) ret);\n\n\treturn ret;\n}\n#endif  \n\n#ifndef mul_u64_u32_div\nstatic inline u64 mul_u64_u32_div(u64 a, u32 mul, u32 divisor)\n{\n\tunion {\n\t\tu64 ll;\n\t\tstruct {\n#ifdef __BIG_ENDIAN\n\t\t\tu32 high, low;\n#else\n\t\t\tu32 low, high;\n#endif\n\t\t} l;\n\t} u, rl, rh;\n\n\tu.ll = a;\n\trl.ll = mul_u32_u32(u.l.low, mul);\n\trh.ll = mul_u32_u32(u.l.high, mul) + rl.l.high;\n\n\t \n\trl.l.high = do_div(rh.ll, divisor);\n\n\t \n\tdo_div(rl.ll, divisor);\n\n\trl.l.high = rh.l.low;\n\treturn rl.ll;\n}\n#endif  \n\nu64 mul_u64_u64_div_u64(u64 a, u64 mul, u64 div);\n\n \n#define DIV64_U64_ROUND_UP(ll, d)\t\\\n\t({ u64 _tmp = (d); div64_u64((ll) + _tmp - 1, _tmp); })\n\n \n#define DIV64_U64_ROUND_CLOSEST(dividend, divisor)\t\\\n\t({ u64 _tmp = (divisor); div64_u64((dividend) + _tmp / 2, _tmp); })\n\n \n#define DIV_U64_ROUND_CLOSEST(dividend, divisor)\t\\\n\t({ u32 _tmp = (divisor); div_u64((u64)(dividend) + _tmp / 2, _tmp); })\n\n \n#define DIV_S64_ROUND_CLOSEST(dividend, divisor)(\t\\\n{\t\t\t\t\t\t\t\\\n\ts64 __x = (dividend);\t\t\t\t\\\n\ts32 __d = (divisor);\t\t\t\t\\\n\t((__x > 0) == (__d > 0)) ?\t\t\t\\\n\t\tdiv_s64((__x + (__d / 2)), __d) :\t\\\n\t\tdiv_s64((__x - (__d / 2)), __d);\t\\\n}\t\t\t\t\t\t\t\\\n)\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}