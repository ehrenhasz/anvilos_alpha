{
  "module_name": "slab_def.h",
  "hash_id": "9e1a18cc4a320b91311415312608cdb621aa18e2aeb9696abdeda1b48d2fd2d0",
  "original_prompt": "Ingested from linux-6.6.14/include/linux/slab_def.h",
  "human_readable_source": " \n#ifndef _LINUX_SLAB_DEF_H\n#define\t_LINUX_SLAB_DEF_H\n\n#include <linux/kfence.h>\n#include <linux/reciprocal_div.h>\n\n \n\nstruct kmem_cache {\n\tstruct array_cache __percpu *cpu_cache;\n\n \n\tunsigned int batchcount;\n\tunsigned int limit;\n\tunsigned int shared;\n\n\tunsigned int size;\n\tstruct reciprocal_value reciprocal_buffer_size;\n \n\n\tslab_flags_t flags;\t\t \n\tunsigned int num;\t\t \n\n \n\t \n\tunsigned int gfporder;\n\n\t \n\tgfp_t allocflags;\n\n\tsize_t colour;\t\t\t \n\tunsigned int colour_off;\t \n\tunsigned int freelist_size;\n\n\t \n\tvoid (*ctor)(void *obj);\n\n \n\tconst char *name;\n\tstruct list_head list;\n\tint refcount;\n\tint object_size;\n\tint align;\n\n \n#ifdef CONFIG_DEBUG_SLAB\n\tunsigned long num_active;\n\tunsigned long num_allocations;\n\tunsigned long high_mark;\n\tunsigned long grown;\n\tunsigned long reaped;\n\tunsigned long errors;\n\tunsigned long max_freeable;\n\tunsigned long node_allocs;\n\tunsigned long node_frees;\n\tunsigned long node_overflow;\n\tatomic_t allochit;\n\tatomic_t allocmiss;\n\tatomic_t freehit;\n\tatomic_t freemiss;\n\n\t \n\tint obj_offset;\n#endif  \n\n#ifdef CONFIG_KASAN_GENERIC\n\tstruct kasan_cache kasan_info;\n#endif\n\n#ifdef CONFIG_SLAB_FREELIST_RANDOM\n\tunsigned int *random_seq;\n#endif\n\n#ifdef CONFIG_HARDENED_USERCOPY\n\tunsigned int useroffset;\t \n\tunsigned int usersize;\t\t \n#endif\n\n\tstruct kmem_cache_node *node[MAX_NUMNODES];\n};\n\nstatic inline void *nearest_obj(struct kmem_cache *cache, const struct slab *slab,\n\t\t\t\tvoid *x)\n{\n\tvoid *object = x - (x - slab->s_mem) % cache->size;\n\tvoid *last_object = slab->s_mem + (cache->num - 1) * cache->size;\n\n\tif (unlikely(object > last_object))\n\t\treturn last_object;\n\telse\n\t\treturn object;\n}\n\n \nstatic inline unsigned int obj_to_index(const struct kmem_cache *cache,\n\t\t\t\t\tconst struct slab *slab, void *obj)\n{\n\tu32 offset = (obj - slab->s_mem);\n\treturn reciprocal_divide(offset, cache->reciprocal_buffer_size);\n}\n\nstatic inline int objs_per_slab(const struct kmem_cache *cache,\n\t\t\t\t     const struct slab *slab)\n{\n\tif (is_kfence_address(slab_address(slab)))\n\t\treturn 1;\n\treturn cache->num;\n}\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}