{
  "module_name": "qman.h",
  "hash_id": "5985972f3f30ba9e733962d5b6869eeb97cf555f594c32029292af73c2066eb1",
  "original_prompt": "Ingested from linux-6.6.14/include/soc/fsl/qman.h",
  "human_readable_source": " \n\n#ifndef __FSL_QMAN_H\n#define __FSL_QMAN_H\n\n#include <linux/bitops.h>\n#include <linux/device.h>\n\n \n#define QM_CHANNEL_SWPORTAL0 0\n#define QMAN_CHANNEL_POOL1 0x21\n#define QMAN_CHANNEL_CAAM 0x80\n#define QMAN_CHANNEL_POOL1_REV3 0x401\n#define QMAN_CHANNEL_CAAM_REV3 0x840\nextern u16 qm_channel_pool1;\nextern u16 qm_channel_caam;\n\n \n#define QM_PIRQ_CSCI\t0x00100000\t \n#define QM_PIRQ_EQCI\t0x00080000\t \n#define QM_PIRQ_EQRI\t0x00040000\t \n#define QM_PIRQ_DQRI\t0x00020000\t \n#define QM_PIRQ_MRI\t0x00010000\t \n \n#define QM_PIRQ_SLOW\t(QM_PIRQ_CSCI | QM_PIRQ_EQCI | QM_PIRQ_EQRI | \\\n\t\t\t QM_PIRQ_MRI)\n\n \n#define QM_SDQCR_CHANNELS_POOL_MASK\t0x00007fff\n \n#define QM_SDQCR_CHANNELS_POOL(n)\t(0x00008000 >> (n))\n \nstatic inline u32 QM_SDQCR_CHANNELS_POOL_CONV(u16 channel)\n{\n\treturn QM_SDQCR_CHANNELS_POOL(channel + 1 - qm_channel_pool1);\n}\n\n \n\n \nstruct qm_fd {\n\tunion {\n\t\tstruct {\n\t\t\tu8 cfg8b_w1;\n\t\t\tu8 bpid;\t \n\t\t\tu8 cfg8b_w3;\n\t\t\tu8 addr_hi;\t \n\t\t\t__be32 addr_lo;\t \n\t\t} __packed;\n\t\t__be64 data;\n\t};\n\t__be32 cfg;\t \n\tunion {\n\t\t__be32 cmd;\n\t\t__be32 status;\n\t};\n} __aligned(8);\n\n#define QM_FD_FORMAT_SG\t\tBIT(31)\n#define QM_FD_FORMAT_LONG\tBIT(30)\n#define QM_FD_FORMAT_COMPOUND\tBIT(29)\n#define QM_FD_FORMAT_MASK\tGENMASK(31, 29)\n#define QM_FD_OFF_SHIFT\t\t20\n#define QM_FD_OFF_MASK\t\tGENMASK(28, 20)\n#define QM_FD_LEN_MASK\t\tGENMASK(19, 0)\n#define QM_FD_LEN_BIG_MASK\tGENMASK(28, 0)\n\nenum qm_fd_format {\n\t \n\tqm_fd_contig = 0,\n\tqm_fd_contig_big = QM_FD_FORMAT_LONG,\n\tqm_fd_sg = QM_FD_FORMAT_SG,\n\tqm_fd_sg_big = QM_FD_FORMAT_SG | QM_FD_FORMAT_LONG,\n\tqm_fd_compound = QM_FD_FORMAT_COMPOUND\n};\n\nstatic inline dma_addr_t qm_fd_addr(const struct qm_fd *fd)\n{\n\treturn be64_to_cpu(fd->data) & 0xffffffffffLLU;\n}\n\nstatic inline u64 qm_fd_addr_get64(const struct qm_fd *fd)\n{\n\treturn be64_to_cpu(fd->data) & 0xffffffffffLLU;\n}\n\nstatic inline void qm_fd_addr_set64(struct qm_fd *fd, u64 addr)\n{\n\tfd->addr_hi = upper_32_bits(addr);\n\tfd->addr_lo = cpu_to_be32(lower_32_bits(addr));\n}\n\n \nstatic inline enum qm_fd_format qm_fd_get_format(const struct qm_fd *fd)\n{\n\treturn be32_to_cpu(fd->cfg) & QM_FD_FORMAT_MASK;\n}\n\nstatic inline int qm_fd_get_offset(const struct qm_fd *fd)\n{\n\treturn (be32_to_cpu(fd->cfg) & QM_FD_OFF_MASK) >> QM_FD_OFF_SHIFT;\n}\n\nstatic inline int qm_fd_get_length(const struct qm_fd *fd)\n{\n\treturn be32_to_cpu(fd->cfg) & QM_FD_LEN_MASK;\n}\n\nstatic inline int qm_fd_get_len_big(const struct qm_fd *fd)\n{\n\treturn be32_to_cpu(fd->cfg) & QM_FD_LEN_BIG_MASK;\n}\n\nstatic inline void qm_fd_set_param(struct qm_fd *fd, enum qm_fd_format fmt,\n\t\t\t\t   int off, int len)\n{\n\tfd->cfg = cpu_to_be32(fmt | (len & QM_FD_LEN_BIG_MASK) |\n\t\t\t      ((off << QM_FD_OFF_SHIFT) & QM_FD_OFF_MASK));\n}\n\n#define qm_fd_set_contig(fd, off, len) \\\n\tqm_fd_set_param(fd, qm_fd_contig, off, len)\n#define qm_fd_set_sg(fd, off, len) qm_fd_set_param(fd, qm_fd_sg, off, len)\n#define qm_fd_set_contig_big(fd, len) \\\n\tqm_fd_set_param(fd, qm_fd_contig_big, 0, len)\n#define qm_fd_set_sg_big(fd, len) qm_fd_set_param(fd, qm_fd_sg_big, 0, len)\n#define qm_fd_set_compound(fd, len) qm_fd_set_param(fd, qm_fd_compound, 0, len)\n\nstatic inline void qm_fd_clear_fd(struct qm_fd *fd)\n{\n\tfd->data = 0;\n\tfd->cfg = 0;\n\tfd->cmd = 0;\n}\n\n \nstruct qm_sg_entry {\n\tunion {\n\t\tstruct {\n\t\t\tu8 __reserved1[3];\n\t\t\tu8 addr_hi;\t \n\t\t\t__be32 addr_lo;\t \n\t\t};\n\t\t__be64 data;\n\t};\n\t__be32 cfg;\t \n\tu8 __reserved2;\n\tu8 bpid;\n\t__be16 offset;  \n} __packed;\n\n#define QM_SG_LEN_MASK\tGENMASK(29, 0)\n#define QM_SG_OFF_MASK\tGENMASK(12, 0)\n#define QM_SG_FIN\tBIT(30)\n#define QM_SG_EXT\tBIT(31)\n\nstatic inline dma_addr_t qm_sg_addr(const struct qm_sg_entry *sg)\n{\n\treturn be64_to_cpu(sg->data) & 0xffffffffffLLU;\n}\n\nstatic inline u64 qm_sg_entry_get64(const struct qm_sg_entry *sg)\n{\n\treturn be64_to_cpu(sg->data) & 0xffffffffffLLU;\n}\n\nstatic inline void qm_sg_entry_set64(struct qm_sg_entry *sg, u64 addr)\n{\n\tsg->addr_hi = upper_32_bits(addr);\n\tsg->addr_lo = cpu_to_be32(lower_32_bits(addr));\n}\n\nstatic inline bool qm_sg_entry_is_final(const struct qm_sg_entry *sg)\n{\n\treturn be32_to_cpu(sg->cfg) & QM_SG_FIN;\n}\n\nstatic inline bool qm_sg_entry_is_ext(const struct qm_sg_entry *sg)\n{\n\treturn be32_to_cpu(sg->cfg) & QM_SG_EXT;\n}\n\nstatic inline int qm_sg_entry_get_len(const struct qm_sg_entry *sg)\n{\n\treturn be32_to_cpu(sg->cfg) & QM_SG_LEN_MASK;\n}\n\nstatic inline void qm_sg_entry_set_len(struct qm_sg_entry *sg, int len)\n{\n\tsg->cfg = cpu_to_be32(len & QM_SG_LEN_MASK);\n}\n\nstatic inline void qm_sg_entry_set_f(struct qm_sg_entry *sg, int len)\n{\n\tsg->cfg = cpu_to_be32(QM_SG_FIN | (len & QM_SG_LEN_MASK));\n}\n\nstatic inline int qm_sg_entry_get_off(const struct qm_sg_entry *sg)\n{\n\treturn be32_to_cpu(sg->offset) & QM_SG_OFF_MASK;\n}\n\n \nstruct qm_dqrr_entry {\n\tu8 verb;\n\tu8 stat;\n\t__be16 seqnum;\t \n\tu8 tok;\n\tu8 __reserved2[3];\n\t__be32 fqid;\t \n\t__be32 context_b;\n\tstruct qm_fd fd;\n\tu8 __reserved4[32];\n} __packed __aligned(64);\n#define QM_DQRR_VERB_VBIT\t\t0x80\n#define QM_DQRR_VERB_MASK\t\t0x7f\t \n#define QM_DQRR_VERB_FRAME_DEQUEUE\t0x60\t \n#define QM_DQRR_STAT_FQ_EMPTY\t\t0x80\t \n#define QM_DQRR_STAT_FQ_HELDACTIVE\t0x40\t \n#define QM_DQRR_STAT_FQ_FORCEELIGIBLE\t0x20\t \n#define QM_DQRR_STAT_FD_VALID\t\t0x10\t \n#define QM_DQRR_STAT_UNSCHEDULED\t0x02\t \n#define QM_DQRR_STAT_DQCR_EXPIRED\t0x01\t \n\n \n#define QM_FQID_MASK\tGENMASK(23, 0)\n#define qm_fqid_set(p, v) ((p)->fqid = cpu_to_be32((v) & QM_FQID_MASK))\n#define qm_fqid_get(p)    (be32_to_cpu((p)->fqid) & QM_FQID_MASK)\n\n \n \nunion qm_mr_entry {\n\tstruct {\n\t\tu8 verb;\n\t\tu8 __reserved[63];\n\t};\n\tstruct {\n\t\tu8 verb;\n\t\tu8 dca;\n\t\t__be16 seqnum;\n\t\tu8 rc;\t\t \n\t\tu8 __reserved[3];\n\t\t__be32 fqid;\t \n\t\t__be32 tag;\n\t\tstruct qm_fd fd;\n\t\tu8 __reserved1[32];\n\t} __packed __aligned(64) ern;\n\tstruct {\n\t\tu8 verb;\n\t\tu8 fqs;\t\t \n\t\tu8 __reserved1[6];\n\t\t__be32 fqid;\t \n\t\t__be32 context_b;\n\t\tu8 __reserved2[48];\n\t} __packed fq;\t\t \n};\n#define QM_MR_VERB_VBIT\t\t\t0x80\n \n#define QM_MR_VERB_TYPE_MASK\t\t0x27\n#define QM_MR_VERB_DC_ERN\t\t0x20\n#define QM_MR_VERB_FQRN\t\t\t0x21\n#define QM_MR_VERB_FQRNI\t\t0x22\n#define QM_MR_VERB_FQRL\t\t\t0x23\n#define QM_MR_VERB_FQPN\t\t\t0x24\n#define QM_MR_RC_MASK\t\t\t0xf0\t \n#define QM_MR_RC_CGR_TAILDROP\t\t0x00\n#define QM_MR_RC_WRED\t\t\t0x10\n#define QM_MR_RC_ERROR\t\t\t0x20\n#define QM_MR_RC_ORPWINDOW_EARLY\t0x30\n#define QM_MR_RC_ORPWINDOW_LATE\t\t0x40\n#define QM_MR_RC_FQ_TAILDROP\t\t0x50\n#define QM_MR_RC_ORPWINDOW_RETIRED\t0x60\n#define QM_MR_RC_ORP_ZERO\t\t0x70\n#define QM_MR_FQS_ORLPRESENT\t\t0x02\t \n#define QM_MR_FQS_NOTEMPTY\t\t0x01\t \n\n \nstruct qm_fqd_stashing {\n\t \n\tu8 exclusive;\n\t \n\tu8 cl;  \n};\n\nstruct qm_fqd_oac {\n\t \n\tu8 oac;  \n\t \n\ts8 oal;  \n};\n\nstruct qm_fqd {\n\t \n\tu8 orpc;\n\tu8 cgid;\n\t__be16 fq_ctrl;\t \n\t__be16 dest_wq;\t \n\t__be16 ics_cred;  \n\t \n\tunion {\n\t\t__be16 td;  \n\t\tstruct qm_fqd_oac oac_init;\n\t};\n\t__be32 context_b;\n\tunion {\n\t\t \n\t\t__be64 opaque;\n\t\tstruct {\n\t\t\t__be32 hi;\n\t\t\t__be32 lo;\n\t\t};\n\t\t \n\t\t \n\t\tstruct {\n\t\t\tstruct qm_fqd_stashing stashing;\n\t\t\t \n\t\t\t__be16 context_hi;\n\t\t\t__be32 context_lo;\n\t\t} __packed;\n\t} context_a;\n\tstruct qm_fqd_oac oac_query;\n} __packed;\n\n#define QM_FQD_CHAN_OFF\t\t3\n#define QM_FQD_WQ_MASK\t\tGENMASK(2, 0)\n#define QM_FQD_TD_EXP_MASK\tGENMASK(4, 0)\n#define QM_FQD_TD_MANT_OFF\t5\n#define QM_FQD_TD_MANT_MASK\tGENMASK(12, 5)\n#define QM_FQD_TD_MAX\t\t0xe0000000\n#define QM_FQD_TD_MANT_MAX\t0xff\n#define QM_FQD_OAC_OFF\t\t6\n#define QM_FQD_AS_OFF\t\t4\n#define QM_FQD_DS_OFF\t\t2\n#define QM_FQD_XS_MASK\t\t0x3\n\n \nstatic inline u64 qm_fqd_stashing_get64(const struct qm_fqd *fqd)\n{\n\treturn be64_to_cpu(fqd->context_a.opaque) & 0xffffffffffffULL;\n}\n\nstatic inline dma_addr_t qm_fqd_stashing_addr(const struct qm_fqd *fqd)\n{\n\treturn be64_to_cpu(fqd->context_a.opaque) & 0xffffffffffffULL;\n}\n\nstatic inline u64 qm_fqd_context_a_get64(const struct qm_fqd *fqd)\n{\n\treturn qm_fqd_stashing_get64(fqd);\n}\n\nstatic inline void qm_fqd_stashing_set64(struct qm_fqd *fqd, u64 addr)\n{\n\tfqd->context_a.context_hi = cpu_to_be16(upper_32_bits(addr));\n\tfqd->context_a.context_lo = cpu_to_be32(lower_32_bits(addr));\n}\n\nstatic inline void qm_fqd_context_a_set64(struct qm_fqd *fqd, u64 addr)\n{\n\tfqd->context_a.hi = cpu_to_be32(upper_32_bits(addr));\n\tfqd->context_a.lo = cpu_to_be32(lower_32_bits(addr));\n}\n\n \nstatic inline int qm_fqd_set_taildrop(struct qm_fqd *fqd, u32 val,\n\t\t\t\t      int roundup)\n{\n\tu32 e = 0;\n\tint td, oddbit = 0;\n\n\tif (val > QM_FQD_TD_MAX)\n\t\treturn -ERANGE;\n\n\twhile (val > QM_FQD_TD_MANT_MAX) {\n\t\toddbit = val & 1;\n\t\tval >>= 1;\n\t\te++;\n\t\tif (roundup && oddbit)\n\t\t\tval++;\n\t}\n\n\ttd = (val << QM_FQD_TD_MANT_OFF) & QM_FQD_TD_MANT_MASK;\n\ttd |= (e & QM_FQD_TD_EXP_MASK);\n\tfqd->td = cpu_to_be16(td);\n\treturn 0;\n}\n \nstatic inline int qm_fqd_get_taildrop(const struct qm_fqd *fqd)\n{\n\tint td = be16_to_cpu(fqd->td);\n\n\treturn ((td & QM_FQD_TD_MANT_MASK) >> QM_FQD_TD_MANT_OFF)\n\t\t<< (td & QM_FQD_TD_EXP_MASK);\n}\n\nstatic inline void qm_fqd_set_stashing(struct qm_fqd *fqd, u8 as, u8 ds, u8 cs)\n{\n\tstruct qm_fqd_stashing *st = &fqd->context_a.stashing;\n\n\tst->cl = ((as & QM_FQD_XS_MASK) << QM_FQD_AS_OFF) |\n\t\t ((ds & QM_FQD_XS_MASK) << QM_FQD_DS_OFF) |\n\t\t (cs & QM_FQD_XS_MASK);\n}\n\nstatic inline u8 qm_fqd_get_stashing(const struct qm_fqd *fqd)\n{\n\treturn fqd->context_a.stashing.cl;\n}\n\nstatic inline void qm_fqd_set_oac(struct qm_fqd *fqd, u8 val)\n{\n\tfqd->oac_init.oac = val << QM_FQD_OAC_OFF;\n}\n\nstatic inline void qm_fqd_set_oal(struct qm_fqd *fqd, s8 val)\n{\n\tfqd->oac_init.oal = val;\n}\n\nstatic inline void qm_fqd_set_destwq(struct qm_fqd *fqd, int ch, int wq)\n{\n\tfqd->dest_wq = cpu_to_be16((ch << QM_FQD_CHAN_OFF) |\n\t\t\t\t   (wq & QM_FQD_WQ_MASK));\n}\n\nstatic inline int qm_fqd_get_chan(const struct qm_fqd *fqd)\n{\n\treturn be16_to_cpu(fqd->dest_wq) >> QM_FQD_CHAN_OFF;\n}\n\nstatic inline int qm_fqd_get_wq(const struct qm_fqd *fqd)\n{\n\treturn be16_to_cpu(fqd->dest_wq) & QM_FQD_WQ_MASK;\n}\n\n \n \n#define QM_FQCTRL_MASK\t\t0x07ff\t \n#define QM_FQCTRL_CGE\t\t0x0400\t \n#define QM_FQCTRL_TDE\t\t0x0200\t \n#define QM_FQCTRL_CTXASTASHING\t0x0080\t \n#define QM_FQCTRL_CPCSTASH\t0x0040\t \n#define QM_FQCTRL_FORCESFDR\t0x0008\t \n#define QM_FQCTRL_AVOIDBLOCK\t0x0004\t \n#define QM_FQCTRL_HOLDACTIVE\t0x0002\t \n#define QM_FQCTRL_PREFERINCACHE\t0x0001\t \n#define QM_FQCTRL_LOCKINCACHE\tQM_FQCTRL_PREFERINCACHE  \n\n \n \n#define QM_STASHING_EXCL_ANNOTATION\t0x04\n#define QM_STASHING_EXCL_DATA\t\t0x02\n#define QM_STASHING_EXCL_CTX\t\t0x01\n\n \n \n#define QM_OAC_ICS\t\t0x2  \n#define QM_OAC_CG\t\t0x1  \n\n \nstruct qm_cgr_wr_parm {\n\t \n\t__be32 word;\n};\n \nstruct qm_cgr_cs_thres {\n\t \n\t__be16 word;\n};\n \nstruct __qm_mc_cgr {\n\tstruct qm_cgr_wr_parm wr_parm_g;\n\tstruct qm_cgr_wr_parm wr_parm_y;\n\tstruct qm_cgr_wr_parm wr_parm_r;\n\tu8 wr_en_g;\t \n\tu8 wr_en_y;\t \n\tu8 wr_en_r;\t \n\tu8 cscn_en;\t \n\tunion {\n\t\tstruct {\n\t\t\t__be16 cscn_targ_upd_ctrl;  \n\t\t\t__be16 cscn_targ_dcp_low;\n\t\t};\n\t\t__be32 cscn_targ;\t \n\t};\n\tu8 cstd_en;\t \n\tu8 cs;\t\t \n\tstruct qm_cgr_cs_thres cs_thres;  \n\tu8 mode;\t \n} __packed;\n#define QM_CGR_EN\t\t0x01  \n#define QM_CGR_TARG_UDP_CTRL_WRITE_BIT\t0x8000  \n#define QM_CGR_TARG_UDP_CTRL_DCP\t0x4000  \n#define QM_CGR_TARG_PORTAL(n)\t(0x80000000 >> (n))  \n#define QM_CGR_TARG_FMAN0\t0x00200000  \n#define QM_CGR_TARG_FMAN1\t0x00100000  \n \nstatic inline u64 qm_cgr_cs_thres_get64(const struct qm_cgr_cs_thres *th)\n{\n\tint thres = be16_to_cpu(th->word);\n\n\treturn ((thres >> 5) & 0xff) << (thres & 0x1f);\n}\n\nstatic inline int qm_cgr_cs_thres_set64(struct qm_cgr_cs_thres *th, u64 val,\n\t\t\t\t\tint roundup)\n{\n\tu32 e = 0;\n\tint oddbit = 0;\n\n\twhile (val > 0xff) {\n\t\toddbit = val & 1;\n\t\tval >>= 1;\n\t\te++;\n\t\tif (roundup && oddbit)\n\t\t\tval++;\n\t}\n\tth->word = cpu_to_be16(((val & 0xff) << 5) | (e & 0x1f));\n\treturn 0;\n}\n\n \nstruct qm_mcc_initfq {\n\tu8 __reserved1[2];\n\t__be16 we_mask;\t \n\t__be32 fqid;\t \n\t__be16 count;\t \n\tstruct qm_fqd fqd;  \n\tu8 __reserved2[30];\n} __packed;\n \nstruct qm_mcc_initcgr {\n\tu8 __reserve1[2];\n\t__be16 we_mask;\t \n\tstruct __qm_mc_cgr cgr;\t \n\tu8 __reserved2[2];\n\tu8 cgid;\n\tu8 __reserved3[32];\n} __packed;\n\n \n#define QM_INITFQ_WE_MASK\t\t0x01ff\t \n#define QM_INITFQ_WE_OAC\t\t0x0100\n#define QM_INITFQ_WE_ORPC\t\t0x0080\n#define QM_INITFQ_WE_CGID\t\t0x0040\n#define QM_INITFQ_WE_FQCTRL\t\t0x0020\n#define QM_INITFQ_WE_DESTWQ\t\t0x0010\n#define QM_INITFQ_WE_ICSCRED\t\t0x0008\n#define QM_INITFQ_WE_TDTHRESH\t\t0x0004\n#define QM_INITFQ_WE_CONTEXTB\t\t0x0002\n#define QM_INITFQ_WE_CONTEXTA\t\t0x0001\n \n#define QM_CGR_WE_MASK\t\t\t0x07ff\t \n#define QM_CGR_WE_WR_PARM_G\t\t0x0400\n#define QM_CGR_WE_WR_PARM_Y\t\t0x0200\n#define QM_CGR_WE_WR_PARM_R\t\t0x0100\n#define QM_CGR_WE_WR_EN_G\t\t0x0080\n#define QM_CGR_WE_WR_EN_Y\t\t0x0040\n#define QM_CGR_WE_WR_EN_R\t\t0x0020\n#define QM_CGR_WE_CSCN_EN\t\t0x0010\n#define QM_CGR_WE_CSCN_TARG\t\t0x0008\n#define QM_CGR_WE_CSTD_EN\t\t0x0004\n#define QM_CGR_WE_CS_THRES\t\t0x0002\n#define QM_CGR_WE_MODE\t\t\t0x0001\n\n#define QMAN_CGR_FLAG_USE_INIT\t     0x00000001\n#define QMAN_CGR_MODE_FRAME          0x00000001\n\n\t \n \nstruct qman_portal;\n\n \nstruct qman_fq;\n\n \nstruct qman_cgr;\n\n \nenum qman_cb_dqrr_result {\n\t \n\tqman_cb_dqrr_consume,\n\t \n\tqman_cb_dqrr_park,\n\t \n\tqman_cb_dqrr_defer,\n\t \n\tqman_cb_dqrr_stop,\n\t \n\tqman_cb_dqrr_consume_stop\n};\ntypedef enum qman_cb_dqrr_result (*qman_cb_dqrr)(struct qman_portal *qm,\n\t\t\t\t\tstruct qman_fq *fq,\n\t\t\t\t\tconst struct qm_dqrr_entry *dqrr,\n\t\t\t\t\tbool sched_napi);\n\n \ntypedef void (*qman_cb_mr)(struct qman_portal *qm, struct qman_fq *fq,\n\t\t\t   const union qm_mr_entry *msg);\n\n \nenum qman_fq_state {\n\tqman_fq_state_oos,\n\tqman_fq_state_parked,\n\tqman_fq_state_sched,\n\tqman_fq_state_retired\n};\n\n#define QMAN_FQ_STATE_CHANGING\t     0x80000000  \n#define QMAN_FQ_STATE_NE\t     0x40000000  \n#define QMAN_FQ_STATE_ORL\t     0x20000000  \n#define QMAN_FQ_STATE_BLOCKOOS\t     0xe0000000  \n#define QMAN_FQ_STATE_CGR_EN\t     0x10000000  \n#define QMAN_FQ_STATE_VDQCR\t     0x08000000  \n\n \n\nstruct qman_fq_cb {\n\tqman_cb_dqrr dqrr;\t \n\tqman_cb_mr ern;\t\t \n\tqman_cb_mr fqs;\t\t \n};\n\nstruct qman_fq {\n\t \n\tstruct qman_fq_cb cb;\n\t \n\tu32 fqid, idx;\n\tunsigned long flags;\n\tenum qman_fq_state state;\n\tint cgr_groupid;\n};\n\n \ntypedef void (*qman_cb_cgr)(struct qman_portal *qm,\n\t\t\t    struct qman_cgr *cgr, int congested);\n\nstruct qman_cgr {\n\t \n\tu32 cgrid;  \n\tqman_cb_cgr cb;\n\t \n\tu16 chan;  \n\tstruct list_head node;\n};\n\n \n#define QMAN_FQ_FLAG_NO_ENQUEUE\t     0x00000001  \n#define QMAN_FQ_FLAG_NO_MODIFY\t     0x00000002  \n#define QMAN_FQ_FLAG_TO_DCPORTAL     0x00000004  \n#define QMAN_FQ_FLAG_DYNAMIC_FQID    0x00000020  \n\n \n#define QMAN_INITFQ_FLAG_SCHED\t     0x00000001  \n#define QMAN_INITFQ_FLAG_LOCAL\t     0x00000004  \n\n \n#define QM_VDQCR_PRECEDENCE_VDQCR\t0x0\n#define QM_VDQCR_PRECEDENCE_SDQCR\t0x80000000\n#define QM_VDQCR_EXACT\t\t\t0x40000000\n#define QM_VDQCR_NUMFRAMES_MASK\t\t0x3f000000\n#define QM_VDQCR_NUMFRAMES_SET(n)\t(((n) & 0x3f) << 24)\n#define QM_VDQCR_NUMFRAMES_GET(n)\t(((n) >> 24) & 0x3f)\n#define QM_VDQCR_NUMFRAMES_TILLEMPTY\tQM_VDQCR_NUMFRAMES_SET(0)\n\n#define QMAN_VOLATILE_FLAG_WAIT\t     0x00000001  \n#define QMAN_VOLATILE_FLAG_WAIT_INT  0x00000002  \n#define QMAN_VOLATILE_FLAG_FINISH    0x00000004  \n\n \nstruct qm_mcr_queryfq_np {\n\tu8 verb;\n\tu8 result;\n\tu8 __reserved1;\n\tu8 state;\t\t \n\tu32 fqd_link;\t\t \n\tu16 odp_seq;\t\t \n\tu16 orp_nesn;\t\t \n\tu16 orp_ea_hseq;\t \n\tu16 orp_ea_tseq;\t \n\tu32 orp_ea_hptr;\t \n\tu32 orp_ea_tptr;\t \n\tu32 pfdr_hptr;\t\t \n\tu32 pfdr_tptr;\t\t \n\tu8 __reserved2[5];\n\tu8 is;\t\t\t \n\tu16 ics_surp;\n\tu32 byte_cnt;\n\tu32 frm_cnt;\t\t \n\tu32 __reserved3;\n\tu16 ra1_sfdr;\t\t \n\tu16 ra2_sfdr;\t\t \n\tu16 __reserved4;\n\tu16 od1_sfdr;\t\t \n\tu16 od2_sfdr;\t\t \n\tu16 od3_sfdr;\t\t \n} __packed;\n\n#define QM_MCR_NP_STATE_FE\t\t0x10\n#define QM_MCR_NP_STATE_R\t\t0x08\n#define QM_MCR_NP_STATE_MASK\t\t0x07\t \n#define QM_MCR_NP_STATE_OOS\t\t0x00\n#define QM_MCR_NP_STATE_RETIRED\t\t0x01\n#define QM_MCR_NP_STATE_TEN_SCHED\t0x02\n#define QM_MCR_NP_STATE_TRU_SCHED\t0x03\n#define QM_MCR_NP_STATE_PARKED\t\t0x04\n#define QM_MCR_NP_STATE_ACTIVE\t\t0x05\n#define QM_MCR_NP_PTR_MASK\t\t0x07ff\t \n#define QM_MCR_NP_RA1_NRA(v)\t\t(((v) >> 14) & 0x3)\t \n#define QM_MCR_NP_RA2_IT(v)\t\t(((v) >> 14) & 0x1)\t \n#define QM_MCR_NP_OD1_NOD(v)\t\t(((v) >> 14) & 0x3)\t \n#define QM_MCR_NP_OD3_NPC(v)\t\t(((v) >> 14) & 0x3)\t \n\nenum qm_mcr_queryfq_np_masks {\n\tqm_mcr_fqd_link_mask = BIT(24) - 1,\n\tqm_mcr_odp_seq_mask = BIT(14) - 1,\n\tqm_mcr_orp_nesn_mask = BIT(14) - 1,\n\tqm_mcr_orp_ea_hseq_mask = BIT(15) - 1,\n\tqm_mcr_orp_ea_tseq_mask = BIT(15) - 1,\n\tqm_mcr_orp_ea_hptr_mask = BIT(24) - 1,\n\tqm_mcr_orp_ea_tptr_mask = BIT(24) - 1,\n\tqm_mcr_pfdr_hptr_mask = BIT(24) - 1,\n\tqm_mcr_pfdr_tptr_mask = BIT(24) - 1,\n\tqm_mcr_is_mask = BIT(1) - 1,\n\tqm_mcr_frm_cnt_mask = BIT(24) - 1,\n};\n\n#define qm_mcr_np_get(np, field) \\\n\t((np)->field & (qm_mcr_##field##_mask))\n\n\t \n \nvoid qman_p_irqsource_add(struct qman_portal *p, u32 bits);\n\n \nvoid qman_p_irqsource_remove(struct qman_portal *p, u32 bits);\n\n \nconst cpumask_t *qman_affine_cpus(void);\n\n \nu16 qman_affine_channel(int cpu);\n\n \nstruct qman_portal *qman_get_affine_portal(int cpu);\n\n \nint qman_start_using_portal(struct qman_portal *p, struct device *dev);\n\n \nint qman_p_poll_dqrr(struct qman_portal *p, unsigned int limit);\n\n \nvoid qman_p_static_dequeue_add(struct qman_portal *p, u32 pools);\n\n\t \n \nint qman_create_fq(u32 fqid, u32 flags, struct qman_fq *fq);\n\n \nvoid qman_destroy_fq(struct qman_fq *fq);\n\n \nu32 qman_fq_fqid(struct qman_fq *fq);\n\n \nint qman_init_fq(struct qman_fq *fq, u32 flags, struct qm_mcc_initfq *opts);\n\n \nint qman_schedule_fq(struct qman_fq *fq);\n\n \nint qman_retire_fq(struct qman_fq *fq, u32 *flags);\n\n \nint qman_oos_fq(struct qman_fq *fq);\n\n \nint qman_volatile_dequeue(struct qman_fq *fq, u32 flags, u32 vdqcr);\n\n \nint qman_enqueue(struct qman_fq *fq, const struct qm_fd *fd);\n\n \nint qman_alloc_fqid_range(u32 *result, u32 count);\n#define qman_alloc_fqid(result) qman_alloc_fqid_range(result, 1)\n\n \nint qman_release_fqid(u32 fqid);\n\n \nint qman_query_fq_np(struct qman_fq *fq, struct qm_mcr_queryfq_np *np);\n\n\t \n \nint qman_alloc_pool_range(u32 *result, u32 count);\n#define qman_alloc_pool(result) qman_alloc_pool_range(result, 1)\n\n \nint qman_release_pool(u32 id);\n\n\t \n \nint qman_create_cgr(struct qman_cgr *cgr, u32 flags,\n\t\t    struct qm_mcc_initcgr *opts);\n\n \nint qman_delete_cgr(struct qman_cgr *cgr);\n\n \nvoid qman_delete_cgr_safe(struct qman_cgr *cgr);\n\n \nint qman_update_cgr_safe(struct qman_cgr *cgr, struct qm_mcc_initcgr *opts);\n\n \nint qman_query_cgr_congested(struct qman_cgr *cgr, bool *result);\n\n \nint qman_alloc_cgrid_range(u32 *result, u32 count);\n#define qman_alloc_cgrid(result) qman_alloc_cgrid_range(result, 1)\n\n \nint qman_release_cgrid(u32 id);\n\n \nint qman_is_probed(void);\n\n \nint qman_portals_probed(void);\n\n \nvoid qman_dqrr_get_ithresh(struct qman_portal *portal, u8 *ithresh);\n\n \nint qman_dqrr_set_ithresh(struct qman_portal *portal, u8 ithresh);\n\n \nvoid qman_portal_get_iperiod(struct qman_portal *portal, u32 *iperiod);\n\n \nint qman_portal_set_iperiod(struct qman_portal *portal, u32 iperiod);\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}