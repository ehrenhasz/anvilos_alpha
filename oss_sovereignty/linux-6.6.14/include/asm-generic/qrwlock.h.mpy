{
  "module_name": "qrwlock.h",
  "hash_id": "2f6ae4cac72c79717b2dc7320089fe492c0fe5f6d575e790da3a52cf99a1766f",
  "original_prompt": "Ingested from linux-6.6.14/include/asm-generic/qrwlock.h",
  "human_readable_source": " \n \n#ifndef __ASM_GENERIC_QRWLOCK_H\n#define __ASM_GENERIC_QRWLOCK_H\n\n#include <linux/atomic.h>\n#include <asm/barrier.h>\n#include <asm/processor.h>\n\n#include <asm-generic/qrwlock_types.h>\n\n \n\n \n#define\t_QW_WAITING\t0x100\t\t \n#define\t_QW_LOCKED\t0x0ff\t\t \n#define\t_QW_WMASK\t0x1ff\t\t \n#define\t_QR_SHIFT\t9\t\t \n#define _QR_BIAS\t(1U << _QR_SHIFT)\n\n \nextern void queued_read_lock_slowpath(struct qrwlock *lock);\nextern void queued_write_lock_slowpath(struct qrwlock *lock);\n\n \nstatic inline int queued_read_trylock(struct qrwlock *lock)\n{\n\tint cnts;\n\n\tcnts = atomic_read(&lock->cnts);\n\tif (likely(!(cnts & _QW_WMASK))) {\n\t\tcnts = (u32)atomic_add_return_acquire(_QR_BIAS, &lock->cnts);\n\t\tif (likely(!(cnts & _QW_WMASK)))\n\t\t\treturn 1;\n\t\tatomic_sub(_QR_BIAS, &lock->cnts);\n\t}\n\treturn 0;\n}\n\n \nstatic inline int queued_write_trylock(struct qrwlock *lock)\n{\n\tint cnts;\n\n\tcnts = atomic_read(&lock->cnts);\n\tif (unlikely(cnts))\n\t\treturn 0;\n\n\treturn likely(atomic_try_cmpxchg_acquire(&lock->cnts, &cnts,\n\t\t\t\t_QW_LOCKED));\n}\n \nstatic inline void queued_read_lock(struct qrwlock *lock)\n{\n\tint cnts;\n\n\tcnts = atomic_add_return_acquire(_QR_BIAS, &lock->cnts);\n\tif (likely(!(cnts & _QW_WMASK)))\n\t\treturn;\n\n\t \n\tqueued_read_lock_slowpath(lock);\n}\n\n \nstatic inline void queued_write_lock(struct qrwlock *lock)\n{\n\tint cnts = 0;\n\t \n\tif (likely(atomic_try_cmpxchg_acquire(&lock->cnts, &cnts, _QW_LOCKED)))\n\t\treturn;\n\n\tqueued_write_lock_slowpath(lock);\n}\n\n \nstatic inline void queued_read_unlock(struct qrwlock *lock)\n{\n\t \n\t(void)atomic_sub_return_release(_QR_BIAS, &lock->cnts);\n}\n\n \nstatic inline void queued_write_unlock(struct qrwlock *lock)\n{\n\tsmp_store_release(&lock->wlocked, 0);\n}\n\n \nstatic inline int queued_rwlock_is_contended(struct qrwlock *lock)\n{\n\treturn arch_spin_is_locked(&lock->wait_lock);\n}\n\n \n#define arch_read_lock(l)\t\tqueued_read_lock(l)\n#define arch_write_lock(l)\t\tqueued_write_lock(l)\n#define arch_read_trylock(l)\t\tqueued_read_trylock(l)\n#define arch_write_trylock(l)\t\tqueued_write_trylock(l)\n#define arch_read_unlock(l)\t\tqueued_read_unlock(l)\n#define arch_write_unlock(l)\t\tqueued_write_unlock(l)\n#define arch_rwlock_is_contended(l)\tqueued_rwlock_is_contended(l)\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}