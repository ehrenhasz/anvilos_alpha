{
  "module_name": "kmem.h",
  "hash_id": "e0b48a7a31646b558efa140cd22b39cc4039485fda96871174cc7769d87efbc1",
  "original_prompt": "Ingested from linux-6.6.14/include/trace/events/kmem.h",
  "human_readable_source": " \n#undef TRACE_SYSTEM\n#define TRACE_SYSTEM kmem\n\n#if !defined(_TRACE_KMEM_H) || defined(TRACE_HEADER_MULTI_READ)\n#define _TRACE_KMEM_H\n\n#include <linux/types.h>\n#include <linux/tracepoint.h>\n#include <trace/events/mmflags.h>\n\nTRACE_EVENT(kmem_cache_alloc,\n\n\tTP_PROTO(unsigned long call_site,\n\t\t const void *ptr,\n\t\t struct kmem_cache *s,\n\t\t gfp_t gfp_flags,\n\t\t int node),\n\n\tTP_ARGS(call_site, ptr, s, gfp_flags, node),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tcall_site\t)\n\t\t__field(\tconst void *,\tptr\t\t)\n\t\t__field(\tsize_t,\t\tbytes_req\t)\n\t\t__field(\tsize_t,\t\tbytes_alloc\t)\n\t\t__field(\tunsigned long,\tgfp_flags\t)\n\t\t__field(\tint,\t\tnode\t\t)\n\t\t__field(\tbool,\t\taccounted\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->call_site\t= call_site;\n\t\t__entry->ptr\t\t= ptr;\n\t\t__entry->bytes_req\t= s->object_size;\n\t\t__entry->bytes_alloc\t= s->size;\n\t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n\t\t__entry->node\t\t= node;\n\t\t__entry->accounted\t= IS_ENABLED(CONFIG_MEMCG_KMEM) ?\n\t\t\t\t\t  ((gfp_flags & __GFP_ACCOUNT) ||\n\t\t\t\t\t  (s->flags & SLAB_ACCOUNT)) : false;\n\t),\n\n\tTP_printk(\"call_site=%pS ptr=%p bytes_req=%zu bytes_alloc=%zu gfp_flags=%s node=%d accounted=%s\",\n\t\t(void *)__entry->call_site,\n\t\t__entry->ptr,\n\t\t__entry->bytes_req,\n\t\t__entry->bytes_alloc,\n\t\tshow_gfp_flags(__entry->gfp_flags),\n\t\t__entry->node,\n\t\t__entry->accounted ? \"true\" : \"false\")\n);\n\nTRACE_EVENT(kmalloc,\n\n\tTP_PROTO(unsigned long call_site,\n\t\t const void *ptr,\n\t\t size_t bytes_req,\n\t\t size_t bytes_alloc,\n\t\t gfp_t gfp_flags,\n\t\t int node),\n\n\tTP_ARGS(call_site, ptr, bytes_req, bytes_alloc, gfp_flags, node),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tcall_site\t)\n\t\t__field(\tconst void *,\tptr\t\t)\n\t\t__field(\tsize_t,\t\tbytes_req\t)\n\t\t__field(\tsize_t,\t\tbytes_alloc\t)\n\t\t__field(\tunsigned long,\tgfp_flags\t)\n\t\t__field(\tint,\t\tnode\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->call_site\t= call_site;\n\t\t__entry->ptr\t\t= ptr;\n\t\t__entry->bytes_req\t= bytes_req;\n\t\t__entry->bytes_alloc\t= bytes_alloc;\n\t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n\t\t__entry->node\t\t= node;\n\t),\n\n\tTP_printk(\"call_site=%pS ptr=%p bytes_req=%zu bytes_alloc=%zu gfp_flags=%s node=%d accounted=%s\",\n\t\t(void *)__entry->call_site,\n\t\t__entry->ptr,\n\t\t__entry->bytes_req,\n\t\t__entry->bytes_alloc,\n\t\tshow_gfp_flags(__entry->gfp_flags),\n\t\t__entry->node,\n\t\t(IS_ENABLED(CONFIG_MEMCG_KMEM) &&\n\t\t (__entry->gfp_flags & (__force unsigned long)__GFP_ACCOUNT)) ? \"true\" : \"false\")\n);\n\nTRACE_EVENT(kfree,\n\n\tTP_PROTO(unsigned long call_site, const void *ptr),\n\n\tTP_ARGS(call_site, ptr),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tcall_site\t)\n\t\t__field(\tconst void *,\tptr\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->call_site\t= call_site;\n\t\t__entry->ptr\t\t= ptr;\n\t),\n\n\tTP_printk(\"call_site=%pS ptr=%p\",\n\t\t  (void *)__entry->call_site, __entry->ptr)\n);\n\nTRACE_EVENT(kmem_cache_free,\n\n\tTP_PROTO(unsigned long call_site, const void *ptr, const struct kmem_cache *s),\n\n\tTP_ARGS(call_site, ptr, s),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tcall_site\t)\n\t\t__field(\tconst void *,\tptr\t\t)\n\t\t__string(\tname,\t\ts->name\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->call_site\t= call_site;\n\t\t__entry->ptr\t\t= ptr;\n\t\t__assign_str(name, s->name);\n\t),\n\n\tTP_printk(\"call_site=%pS ptr=%p name=%s\",\n\t\t  (void *)__entry->call_site, __entry->ptr, __get_str(name))\n);\n\nTRACE_EVENT(mm_page_free,\n\n\tTP_PROTO(struct page *page, unsigned int order),\n\n\tTP_ARGS(page, order),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tpfn\t\t)\n\t\t__field(\tunsigned int,\torder\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->pfn\t\t= page_to_pfn(page);\n\t\t__entry->order\t\t= order;\n\t),\n\n\tTP_printk(\"page=%p pfn=0x%lx order=%d\",\n\t\t\tpfn_to_page(__entry->pfn),\n\t\t\t__entry->pfn,\n\t\t\t__entry->order)\n);\n\nTRACE_EVENT(mm_page_free_batched,\n\n\tTP_PROTO(struct page *page),\n\n\tTP_ARGS(page),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tpfn\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->pfn\t\t= page_to_pfn(page);\n\t),\n\n\tTP_printk(\"page=%p pfn=0x%lx order=0\",\n\t\t\tpfn_to_page(__entry->pfn),\n\t\t\t__entry->pfn)\n);\n\nTRACE_EVENT(mm_page_alloc,\n\n\tTP_PROTO(struct page *page, unsigned int order,\n\t\t\tgfp_t gfp_flags, int migratetype),\n\n\tTP_ARGS(page, order, gfp_flags, migratetype),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tpfn\t\t)\n\t\t__field(\tunsigned int,\torder\t\t)\n\t\t__field(\tunsigned long,\tgfp_flags\t)\n\t\t__field(\tint,\t\tmigratetype\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->pfn\t\t= page ? page_to_pfn(page) : -1UL;\n\t\t__entry->order\t\t= order;\n\t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n\t\t__entry->migratetype\t= migratetype;\n\t),\n\n\tTP_printk(\"page=%p pfn=0x%lx order=%d migratetype=%d gfp_flags=%s\",\n\t\t__entry->pfn != -1UL ? pfn_to_page(__entry->pfn) : NULL,\n\t\t__entry->pfn != -1UL ? __entry->pfn : 0,\n\t\t__entry->order,\n\t\t__entry->migratetype,\n\t\tshow_gfp_flags(__entry->gfp_flags))\n);\n\nDECLARE_EVENT_CLASS(mm_page,\n\n\tTP_PROTO(struct page *page, unsigned int order, int migratetype,\n\t\t int percpu_refill),\n\n\tTP_ARGS(page, order, migratetype, percpu_refill),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tpfn\t\t)\n\t\t__field(\tunsigned int,\torder\t\t)\n\t\t__field(\tint,\t\tmigratetype\t)\n\t\t__field(\tint,\t\tpercpu_refill\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->pfn\t\t= page ? page_to_pfn(page) : -1UL;\n\t\t__entry->order\t\t= order;\n\t\t__entry->migratetype\t= migratetype;\n\t\t__entry->percpu_refill\t= percpu_refill;\n\t),\n\n\tTP_printk(\"page=%p pfn=0x%lx order=%u migratetype=%d percpu_refill=%d\",\n\t\t__entry->pfn != -1UL ? pfn_to_page(__entry->pfn) : NULL,\n\t\t__entry->pfn != -1UL ? __entry->pfn : 0,\n\t\t__entry->order,\n\t\t__entry->migratetype,\n\t\t__entry->percpu_refill)\n);\n\nDEFINE_EVENT(mm_page, mm_page_alloc_zone_locked,\n\n\tTP_PROTO(struct page *page, unsigned int order, int migratetype,\n\t\t int percpu_refill),\n\n\tTP_ARGS(page, order, migratetype, percpu_refill)\n);\n\nTRACE_EVENT(mm_page_pcpu_drain,\n\n\tTP_PROTO(struct page *page, unsigned int order, int migratetype),\n\n\tTP_ARGS(page, order, migratetype),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tpfn\t\t)\n\t\t__field(\tunsigned int,\torder\t\t)\n\t\t__field(\tint,\t\tmigratetype\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->pfn\t\t= page ? page_to_pfn(page) : -1UL;\n\t\t__entry->order\t\t= order;\n\t\t__entry->migratetype\t= migratetype;\n\t),\n\n\tTP_printk(\"page=%p pfn=0x%lx order=%d migratetype=%d\",\n\t\tpfn_to_page(__entry->pfn), __entry->pfn,\n\t\t__entry->order, __entry->migratetype)\n);\n\nTRACE_EVENT(mm_page_alloc_extfrag,\n\n\tTP_PROTO(struct page *page,\n\t\tint alloc_order, int fallback_order,\n\t\tint alloc_migratetype, int fallback_migratetype),\n\n\tTP_ARGS(page,\n\t\talloc_order, fallback_order,\n\t\talloc_migratetype, fallback_migratetype),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\tpfn\t\t\t)\n\t\t__field(\tint,\t\talloc_order\t\t)\n\t\t__field(\tint,\t\tfallback_order\t\t)\n\t\t__field(\tint,\t\talloc_migratetype\t)\n\t\t__field(\tint,\t\tfallback_migratetype\t)\n\t\t__field(\tint,\t\tchange_ownership\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->pfn\t\t\t= page_to_pfn(page);\n\t\t__entry->alloc_order\t\t= alloc_order;\n\t\t__entry->fallback_order\t\t= fallback_order;\n\t\t__entry->alloc_migratetype\t= alloc_migratetype;\n\t\t__entry->fallback_migratetype\t= fallback_migratetype;\n\t\t__entry->change_ownership\t= (alloc_migratetype ==\n\t\t\t\t\tget_pageblock_migratetype(page));\n\t),\n\n\tTP_printk(\"page=%p pfn=0x%lx alloc_order=%d fallback_order=%d pageblock_order=%d alloc_migratetype=%d fallback_migratetype=%d fragmenting=%d change_ownership=%d\",\n\t\tpfn_to_page(__entry->pfn),\n\t\t__entry->pfn,\n\t\t__entry->alloc_order,\n\t\t__entry->fallback_order,\n\t\tpageblock_order,\n\t\t__entry->alloc_migratetype,\n\t\t__entry->fallback_migratetype,\n\t\t__entry->fallback_order < pageblock_order,\n\t\t__entry->change_ownership)\n);\n\n \n#ifndef __PTR_TO_HASHVAL\nstatic unsigned int __maybe_unused mm_ptr_to_hash(const void *ptr)\n{\n\tint ret;\n\tunsigned long hashval;\n\n\tret = ptr_to_hashval(ptr, &hashval);\n\tif (ret)\n\t\treturn 0;\n\n\t \n\treturn (unsigned int)hashval;\n}\n#define __PTR_TO_HASHVAL\n#endif\n\n#define TRACE_MM_PAGES\t\t\\\n\tEM(MM_FILEPAGES)\t\\\n\tEM(MM_ANONPAGES)\t\\\n\tEM(MM_SWAPENTS)\t\t\\\n\tEMe(MM_SHMEMPAGES)\n\n#undef EM\n#undef EMe\n\n#define EM(a)\tTRACE_DEFINE_ENUM(a);\n#define EMe(a)\tTRACE_DEFINE_ENUM(a);\n\nTRACE_MM_PAGES\n\n#undef EM\n#undef EMe\n\n#define EM(a)\t{ a, #a },\n#define EMe(a)\t{ a, #a }\n\nTRACE_EVENT(rss_stat,\n\n\tTP_PROTO(struct mm_struct *mm,\n\t\tint member),\n\n\tTP_ARGS(mm, member),\n\n\tTP_STRUCT__entry(\n\t\t__field(unsigned int, mm_id)\n\t\t__field(unsigned int, curr)\n\t\t__field(int, member)\n\t\t__field(long, size)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->mm_id = mm_ptr_to_hash(mm);\n\t\t__entry->curr = !!(current->mm == mm);\n\t\t__entry->member = member;\n\t\t__entry->size = (percpu_counter_sum_positive(&mm->rss_stat[member])\n\t\t\t\t\t\t\t    << PAGE_SHIFT);\n\t),\n\n\tTP_printk(\"mm_id=%u curr=%d type=%s size=%ldB\",\n\t\t__entry->mm_id,\n\t\t__entry->curr,\n\t\t__print_symbolic(__entry->member, TRACE_MM_PAGES),\n\t\t__entry->size)\n\t);\n#endif  \n\n \n#include <trace/define_trace.h>\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}