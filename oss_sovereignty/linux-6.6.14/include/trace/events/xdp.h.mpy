{
  "module_name": "xdp.h",
  "hash_id": "020fd4fbb14c2fc547fb8bf27cd68d7ba5f886133335fc825e87fff052432635",
  "original_prompt": "Ingested from linux-6.6.14/include/trace/events/xdp.h",
  "human_readable_source": " \n#undef TRACE_SYSTEM\n#define TRACE_SYSTEM xdp\n\n#if !defined(_TRACE_XDP_H) || defined(TRACE_HEADER_MULTI_READ)\n#define _TRACE_XDP_H\n\n#include <linux/netdevice.h>\n#include <linux/filter.h>\n#include <linux/tracepoint.h>\n#include <linux/bpf.h>\n#include <net/xdp.h>\n\n#define __XDP_ACT_MAP(FN)\t\\\n\tFN(ABORTED)\t\t\\\n\tFN(DROP)\t\t\\\n\tFN(PASS)\t\t\\\n\tFN(TX)\t\t\t\\\n\tFN(REDIRECT)\n\n#define __XDP_ACT_TP_FN(x)\t\\\n\tTRACE_DEFINE_ENUM(XDP_##x);\n#define __XDP_ACT_SYM_FN(x)\t\\\n\t{ XDP_##x, #x },\n#define __XDP_ACT_SYM_TAB\t\\\n\t__XDP_ACT_MAP(__XDP_ACT_SYM_FN) { -1, NULL }\n__XDP_ACT_MAP(__XDP_ACT_TP_FN)\n\nTRACE_EVENT(xdp_exception,\n\n\tTP_PROTO(const struct net_device *dev,\n\t\t const struct bpf_prog *xdp, u32 act),\n\n\tTP_ARGS(dev, xdp, act),\n\n\tTP_STRUCT__entry(\n\t\t__field(int, prog_id)\n\t\t__field(u32, act)\n\t\t__field(int, ifindex)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->prog_id\t= xdp->aux->id;\n\t\t__entry->act\t\t= act;\n\t\t__entry->ifindex\t= dev->ifindex;\n\t),\n\n\tTP_printk(\"prog_id=%d action=%s ifindex=%d\",\n\t\t  __entry->prog_id,\n\t\t  __print_symbolic(__entry->act, __XDP_ACT_SYM_TAB),\n\t\t  __entry->ifindex)\n);\n\nTRACE_EVENT(xdp_bulk_tx,\n\n\tTP_PROTO(const struct net_device *dev,\n\t\t int sent, int drops, int err),\n\n\tTP_ARGS(dev, sent, drops, err),\n\n\tTP_STRUCT__entry(\n\t\t__field(int, ifindex)\n\t\t__field(u32, act)\n\t\t__field(int, drops)\n\t\t__field(int, sent)\n\t\t__field(int, err)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->ifindex\t= dev->ifindex;\n\t\t__entry->act\t\t= XDP_TX;\n\t\t__entry->drops\t\t= drops;\n\t\t__entry->sent\t\t= sent;\n\t\t__entry->err\t\t= err;\n\t),\n\n\tTP_printk(\"ifindex=%d action=%s sent=%d drops=%d err=%d\",\n\t\t  __entry->ifindex,\n\t\t  __print_symbolic(__entry->act, __XDP_ACT_SYM_TAB),\n\t\t  __entry->sent, __entry->drops, __entry->err)\n);\n\n#ifndef __DEVMAP_OBJ_TYPE\n#define __DEVMAP_OBJ_TYPE\nstruct _bpf_dtab_netdev {\n\tstruct net_device *dev;\n};\n#endif  \n\nDECLARE_EVENT_CLASS(xdp_redirect_template,\n\n\tTP_PROTO(const struct net_device *dev,\n\t\t const struct bpf_prog *xdp,\n\t\t const void *tgt, int err,\n\t\t enum bpf_map_type map_type,\n\t\t u32 map_id, u32 index),\n\n\tTP_ARGS(dev, xdp, tgt, err, map_type, map_id, index),\n\n\tTP_STRUCT__entry(\n\t\t__field(int, prog_id)\n\t\t__field(u32, act)\n\t\t__field(int, ifindex)\n\t\t__field(int, err)\n\t\t__field(int, to_ifindex)\n\t\t__field(u32, map_id)\n\t\t__field(int, map_index)\n\t),\n\n\tTP_fast_assign(\n\t\tu32 ifindex = 0, map_index = index;\n\n\t\tif (map_type == BPF_MAP_TYPE_DEVMAP || map_type == BPF_MAP_TYPE_DEVMAP_HASH) {\n\t\t\t \n\t\t\tif (tgt)\n\t\t\t\tifindex = ((struct _bpf_dtab_netdev *)tgt)->dev->ifindex;\n\t\t} else if (map_type == BPF_MAP_TYPE_UNSPEC && map_id == INT_MAX) {\n\t\t\tifindex = index;\n\t\t\tmap_index = 0;\n\t\t}\n\n\t\t__entry->prog_id\t= xdp->aux->id;\n\t\t__entry->act\t\t= XDP_REDIRECT;\n\t\t__entry->ifindex\t= dev->ifindex;\n\t\t__entry->err\t\t= err;\n\t\t__entry->to_ifindex\t= ifindex;\n\t\t__entry->map_id\t\t= map_id;\n\t\t__entry->map_index\t= map_index;\n\t),\n\n\tTP_printk(\"prog_id=%d action=%s ifindex=%d to_ifindex=%d err=%d\"\n\t\t  \" map_id=%d map_index=%d\",\n\t\t  __entry->prog_id,\n\t\t  __print_symbolic(__entry->act, __XDP_ACT_SYM_TAB),\n\t\t  __entry->ifindex, __entry->to_ifindex,\n\t\t  __entry->err, __entry->map_id, __entry->map_index)\n);\n\nDEFINE_EVENT(xdp_redirect_template, xdp_redirect,\n\tTP_PROTO(const struct net_device *dev,\n\t\t const struct bpf_prog *xdp,\n\t\t const void *tgt, int err,\n\t\t enum bpf_map_type map_type,\n\t\t u32 map_id, u32 index),\n\tTP_ARGS(dev, xdp, tgt, err, map_type, map_id, index)\n);\n\nDEFINE_EVENT(xdp_redirect_template, xdp_redirect_err,\n\tTP_PROTO(const struct net_device *dev,\n\t\t const struct bpf_prog *xdp,\n\t\t const void *tgt, int err,\n\t\t enum bpf_map_type map_type,\n\t\t u32 map_id, u32 index),\n\tTP_ARGS(dev, xdp, tgt, err, map_type, map_id, index)\n);\n\n#define _trace_xdp_redirect(dev, xdp, to)\t\t\t\t\t\t\\\n\t trace_xdp_redirect(dev, xdp, NULL, 0, BPF_MAP_TYPE_UNSPEC, INT_MAX, to)\n\n#define _trace_xdp_redirect_err(dev, xdp, to, err)\t\t\t\t\t\\\n\t trace_xdp_redirect_err(dev, xdp, NULL, err, BPF_MAP_TYPE_UNSPEC, INT_MAX, to)\n\n#define _trace_xdp_redirect_map(dev, xdp, to, map_type, map_id, index) \\\n\t trace_xdp_redirect(dev, xdp, to, 0, map_type, map_id, index)\n\n#define _trace_xdp_redirect_map_err(dev, xdp, to, map_type, map_id, index, err) \\\n\t trace_xdp_redirect_err(dev, xdp, to, err, map_type, map_id, index)\n\n \nDEFINE_EVENT(xdp_redirect_template, xdp_redirect_map,\n\tTP_PROTO(const struct net_device *dev,\n\t\t const struct bpf_prog *xdp,\n\t\t const void *tgt, int err,\n\t\t enum bpf_map_type map_type,\n\t\t u32 map_id, u32 index),\n\tTP_ARGS(dev, xdp, tgt, err, map_type, map_id, index)\n);\n\nDEFINE_EVENT(xdp_redirect_template, xdp_redirect_map_err,\n\tTP_PROTO(const struct net_device *dev,\n\t\t const struct bpf_prog *xdp,\n\t\t const void *tgt, int err,\n\t\t enum bpf_map_type map_type,\n\t\t u32 map_id, u32 index),\n\tTP_ARGS(dev, xdp, tgt, err, map_type, map_id, index)\n);\n\nTRACE_EVENT(xdp_cpumap_kthread,\n\n\tTP_PROTO(int map_id, unsigned int processed,  unsigned int drops,\n\t\t int sched, struct xdp_cpumap_stats *xdp_stats),\n\n\tTP_ARGS(map_id, processed, drops, sched, xdp_stats),\n\n\tTP_STRUCT__entry(\n\t\t__field(int, map_id)\n\t\t__field(u32, act)\n\t\t__field(int, cpu)\n\t\t__field(unsigned int, drops)\n\t\t__field(unsigned int, processed)\n\t\t__field(int, sched)\n\t\t__field(unsigned int, xdp_pass)\n\t\t__field(unsigned int, xdp_drop)\n\t\t__field(unsigned int, xdp_redirect)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->map_id\t\t= map_id;\n\t\t__entry->act\t\t= XDP_REDIRECT;\n\t\t__entry->cpu\t\t= smp_processor_id();\n\t\t__entry->drops\t\t= drops;\n\t\t__entry->processed\t= processed;\n\t\t__entry->sched\t= sched;\n\t\t__entry->xdp_pass\t= xdp_stats->pass;\n\t\t__entry->xdp_drop\t= xdp_stats->drop;\n\t\t__entry->xdp_redirect\t= xdp_stats->redirect;\n\t),\n\n\tTP_printk(\"kthread\"\n\t\t  \" cpu=%d map_id=%d action=%s\"\n\t\t  \" processed=%u drops=%u\"\n\t\t  \" sched=%d\"\n\t\t  \" xdp_pass=%u xdp_drop=%u xdp_redirect=%u\",\n\t\t  __entry->cpu, __entry->map_id,\n\t\t  __print_symbolic(__entry->act, __XDP_ACT_SYM_TAB),\n\t\t  __entry->processed, __entry->drops,\n\t\t  __entry->sched,\n\t\t  __entry->xdp_pass, __entry->xdp_drop, __entry->xdp_redirect)\n);\n\nTRACE_EVENT(xdp_cpumap_enqueue,\n\n\tTP_PROTO(int map_id, unsigned int processed,  unsigned int drops,\n\t\t int to_cpu),\n\n\tTP_ARGS(map_id, processed, drops, to_cpu),\n\n\tTP_STRUCT__entry(\n\t\t__field(int, map_id)\n\t\t__field(u32, act)\n\t\t__field(int, cpu)\n\t\t__field(unsigned int, drops)\n\t\t__field(unsigned int, processed)\n\t\t__field(int, to_cpu)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->map_id\t\t= map_id;\n\t\t__entry->act\t\t= XDP_REDIRECT;\n\t\t__entry->cpu\t\t= smp_processor_id();\n\t\t__entry->drops\t\t= drops;\n\t\t__entry->processed\t= processed;\n\t\t__entry->to_cpu\t\t= to_cpu;\n\t),\n\n\tTP_printk(\"enqueue\"\n\t\t  \" cpu=%d map_id=%d action=%s\"\n\t\t  \" processed=%u drops=%u\"\n\t\t  \" to_cpu=%d\",\n\t\t  __entry->cpu, __entry->map_id,\n\t\t  __print_symbolic(__entry->act, __XDP_ACT_SYM_TAB),\n\t\t  __entry->processed, __entry->drops,\n\t\t  __entry->to_cpu)\n);\n\nTRACE_EVENT(xdp_devmap_xmit,\n\n\tTP_PROTO(const struct net_device *from_dev,\n\t\t const struct net_device *to_dev,\n\t\t int sent, int drops, int err),\n\n\tTP_ARGS(from_dev, to_dev, sent, drops, err),\n\n\tTP_STRUCT__entry(\n\t\t__field(int, from_ifindex)\n\t\t__field(u32, act)\n\t\t__field(int, to_ifindex)\n\t\t__field(int, drops)\n\t\t__field(int, sent)\n\t\t__field(int, err)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->from_ifindex\t= from_dev->ifindex;\n\t\t__entry->act\t\t= XDP_REDIRECT;\n\t\t__entry->to_ifindex\t= to_dev->ifindex;\n\t\t__entry->drops\t\t= drops;\n\t\t__entry->sent\t\t= sent;\n\t\t__entry->err\t\t= err;\n\t),\n\n\tTP_printk(\"ndo_xdp_xmit\"\n\t\t  \" from_ifindex=%d to_ifindex=%d action=%s\"\n\t\t  \" sent=%d drops=%d\"\n\t\t  \" err=%d\",\n\t\t  __entry->from_ifindex, __entry->to_ifindex,\n\t\t  __print_symbolic(__entry->act, __XDP_ACT_SYM_TAB),\n\t\t  __entry->sent, __entry->drops,\n\t\t  __entry->err)\n);\n\n \n#include <net/xdp_priv.h>\n\n#define __MEM_TYPE_MAP(FN)\t\\\n\tFN(PAGE_SHARED)\t\t\\\n\tFN(PAGE_ORDER0)\t\t\\\n\tFN(PAGE_POOL)\t\t\\\n\tFN(XSK_BUFF_POOL)\n\n#define __MEM_TYPE_TP_FN(x)\t\\\n\tTRACE_DEFINE_ENUM(MEM_TYPE_##x);\n#define __MEM_TYPE_SYM_FN(x)\t\\\n\t{ MEM_TYPE_##x, #x },\n#define __MEM_TYPE_SYM_TAB\t\\\n\t__MEM_TYPE_MAP(__MEM_TYPE_SYM_FN) { -1, 0 }\n__MEM_TYPE_MAP(__MEM_TYPE_TP_FN)\n\nTRACE_EVENT(mem_disconnect,\n\n\tTP_PROTO(const struct xdp_mem_allocator *xa),\n\n\tTP_ARGS(xa),\n\n\tTP_STRUCT__entry(\n\t\t__field(const struct xdp_mem_allocator *,\txa)\n\t\t__field(u32,\t\tmem_id)\n\t\t__field(u32,\t\tmem_type)\n\t\t__field(const void *,\tallocator)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->xa\t\t= xa;\n\t\t__entry->mem_id\t\t= xa->mem.id;\n\t\t__entry->mem_type\t= xa->mem.type;\n\t\t__entry->allocator\t= xa->allocator;\n\t),\n\n\tTP_printk(\"mem_id=%d mem_type=%s allocator=%p\",\n\t\t  __entry->mem_id,\n\t\t  __print_symbolic(__entry->mem_type, __MEM_TYPE_SYM_TAB),\n\t\t  __entry->allocator\n\t)\n);\n\nTRACE_EVENT(mem_connect,\n\n\tTP_PROTO(const struct xdp_mem_allocator *xa,\n\t\t const struct xdp_rxq_info *rxq),\n\n\tTP_ARGS(xa, rxq),\n\n\tTP_STRUCT__entry(\n\t\t__field(const struct xdp_mem_allocator *,\txa)\n\t\t__field(u32,\t\tmem_id)\n\t\t__field(u32,\t\tmem_type)\n\t\t__field(const void *,\tallocator)\n\t\t__field(const struct xdp_rxq_info *,\t\trxq)\n\t\t__field(int,\t\tifindex)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->xa\t\t= xa;\n\t\t__entry->mem_id\t\t= xa->mem.id;\n\t\t__entry->mem_type\t= xa->mem.type;\n\t\t__entry->allocator\t= xa->allocator;\n\t\t__entry->rxq\t\t= rxq;\n\t\t__entry->ifindex\t= rxq->dev->ifindex;\n\t),\n\n\tTP_printk(\"mem_id=%d mem_type=%s allocator=%p\"\n\t\t  \" ifindex=%d\",\n\t\t  __entry->mem_id,\n\t\t  __print_symbolic(__entry->mem_type, __MEM_TYPE_SYM_TAB),\n\t\t  __entry->allocator,\n\t\t  __entry->ifindex\n\t)\n);\n\nTRACE_EVENT(mem_return_failed,\n\n\tTP_PROTO(const struct xdp_mem_info *mem,\n\t\t const struct page *page),\n\n\tTP_ARGS(mem, page),\n\n\tTP_STRUCT__entry(\n\t\t__field(const struct page *,\tpage)\n\t\t__field(u32,\t\tmem_id)\n\t\t__field(u32,\t\tmem_type)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->page\t\t= page;\n\t\t__entry->mem_id\t\t= mem->id;\n\t\t__entry->mem_type\t= mem->type;\n\t),\n\n\tTP_printk(\"mem_id=%d mem_type=%s page=%p\",\n\t\t  __entry->mem_id,\n\t\t  __print_symbolic(__entry->mem_type, __MEM_TYPE_SYM_TAB),\n\t\t  __entry->page\n\t)\n);\n\nTRACE_EVENT(bpf_xdp_link_attach_failed,\n\n\tTP_PROTO(const char *msg),\n\n\tTP_ARGS(msg),\n\n\tTP_STRUCT__entry(\n\t\t__string(msg, msg)\n\t),\n\n\tTP_fast_assign(\n\t\t__assign_str(msg, msg);\n\t),\n\n\tTP_printk(\"errmsg=%s\", __get_str(msg))\n);\n\n#endif  \n\n#include <trace/define_trace.h>\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}