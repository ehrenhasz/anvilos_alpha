{
  "module_name": "sched.h",
  "hash_id": "cd94d837ddb7c87af587e6dbe1ea029a7ddf289741d2cf9bdfc037caae11680c",
  "original_prompt": "Ingested from linux-6.6.14/include/trace/events/sched.h",
  "human_readable_source": " \n#undef TRACE_SYSTEM\n#define TRACE_SYSTEM sched\n\n#if !defined(_TRACE_SCHED_H) || defined(TRACE_HEADER_MULTI_READ)\n#define _TRACE_SCHED_H\n\n#include <linux/kthread.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/tracepoint.h>\n#include <linux/binfmts.h>\n\n \nTRACE_EVENT(sched_kthread_stop,\n\n\tTP_PROTO(struct task_struct *t),\n\n\tTP_ARGS(t),\n\n\tTP_STRUCT__entry(\n\t\t__array(\tchar,\tcomm,\tTASK_COMM_LEN\t)\n\t\t__field(\tpid_t,\tpid\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->comm, t->comm, TASK_COMM_LEN);\n\t\t__entry->pid\t= t->pid;\n\t),\n\n\tTP_printk(\"comm=%s pid=%d\", __entry->comm, __entry->pid)\n);\n\n \nTRACE_EVENT(sched_kthread_stop_ret,\n\n\tTP_PROTO(int ret),\n\n\tTP_ARGS(ret),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tint,\tret\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->ret\t= ret;\n\t),\n\n\tTP_printk(\"ret=%d\", __entry->ret)\n);\n\n \nTRACE_EVENT(sched_kthread_work_queue_work,\n\n\tTP_PROTO(struct kthread_worker *worker,\n\t\t struct kthread_work *work),\n\n\tTP_ARGS(worker, work),\n\n\tTP_STRUCT__entry(\n\t\t__field( void *,\twork\t)\n\t\t__field( void *,\tfunction)\n\t\t__field( void *,\tworker)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->work\t\t= work;\n\t\t__entry->function\t= work->func;\n\t\t__entry->worker\t\t= worker;\n\t),\n\n\tTP_printk(\"work struct=%p function=%ps worker=%p\",\n\t\t  __entry->work, __entry->function, __entry->worker)\n);\n\n \nTRACE_EVENT(sched_kthread_work_execute_start,\n\n\tTP_PROTO(struct kthread_work *work),\n\n\tTP_ARGS(work),\n\n\tTP_STRUCT__entry(\n\t\t__field( void *,\twork\t)\n\t\t__field( void *,\tfunction)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->work\t\t= work;\n\t\t__entry->function\t= work->func;\n\t),\n\n\tTP_printk(\"work struct %p: function %ps\", __entry->work, __entry->function)\n);\n\n \nTRACE_EVENT(sched_kthread_work_execute_end,\n\n\tTP_PROTO(struct kthread_work *work, kthread_work_func_t function),\n\n\tTP_ARGS(work, function),\n\n\tTP_STRUCT__entry(\n\t\t__field( void *,\twork\t)\n\t\t__field( void *,\tfunction)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->work\t\t= work;\n\t\t__entry->function\t= function;\n\t),\n\n\tTP_printk(\"work struct %p: function %ps\", __entry->work, __entry->function)\n);\n\n \nDECLARE_EVENT_CLASS(sched_wakeup_template,\n\n\tTP_PROTO(struct task_struct *p),\n\n\tTP_ARGS(__perf_task(p)),\n\n\tTP_STRUCT__entry(\n\t\t__array(\tchar,\tcomm,\tTASK_COMM_LEN\t)\n\t\t__field(\tpid_t,\tpid\t\t\t)\n\t\t__field(\tint,\tprio\t\t\t)\n\t\t__field(\tint,\ttarget_cpu\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->comm, p->comm, TASK_COMM_LEN);\n\t\t__entry->pid\t\t= p->pid;\n\t\t__entry->prio\t\t= p->prio;  \n\t\t__entry->target_cpu\t= task_cpu(p);\n\t),\n\n\tTP_printk(\"comm=%s pid=%d prio=%d target_cpu=%03d\",\n\t\t  __entry->comm, __entry->pid, __entry->prio,\n\t\t  __entry->target_cpu)\n);\n\n \nDEFINE_EVENT(sched_wakeup_template, sched_waking,\n\t     TP_PROTO(struct task_struct *p),\n\t     TP_ARGS(p));\n\n \nDEFINE_EVENT(sched_wakeup_template, sched_wakeup,\n\t     TP_PROTO(struct task_struct *p),\n\t     TP_ARGS(p));\n\n \nDEFINE_EVENT(sched_wakeup_template, sched_wakeup_new,\n\t     TP_PROTO(struct task_struct *p),\n\t     TP_ARGS(p));\n\n#ifdef CREATE_TRACE_POINTS\nstatic inline long __trace_sched_switch_state(bool preempt,\n\t\t\t\t\t      unsigned int prev_state,\n\t\t\t\t\t      struct task_struct *p)\n{\n\tunsigned int state;\n\n#ifdef CONFIG_SCHED_DEBUG\n\tBUG_ON(p != current);\n#endif  \n\n\t \n\tif (preempt)\n\t\treturn TASK_REPORT_MAX;\n\n\t \n\tstate = __task_state_index(prev_state, p->exit_state);\n\n\treturn state ? (1 << (state - 1)) : state;\n}\n#endif  \n\n \nTRACE_EVENT(sched_switch,\n\n\tTP_PROTO(bool preempt,\n\t\t struct task_struct *prev,\n\t\t struct task_struct *next,\n\t\t unsigned int prev_state),\n\n\tTP_ARGS(preempt, prev, next, prev_state),\n\n\tTP_STRUCT__entry(\n\t\t__array(\tchar,\tprev_comm,\tTASK_COMM_LEN\t)\n\t\t__field(\tpid_t,\tprev_pid\t\t\t)\n\t\t__field(\tint,\tprev_prio\t\t\t)\n\t\t__field(\tlong,\tprev_state\t\t\t)\n\t\t__array(\tchar,\tnext_comm,\tTASK_COMM_LEN\t)\n\t\t__field(\tpid_t,\tnext_pid\t\t\t)\n\t\t__field(\tint,\tnext_prio\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->next_comm, next->comm, TASK_COMM_LEN);\n\t\t__entry->prev_pid\t= prev->pid;\n\t\t__entry->prev_prio\t= prev->prio;\n\t\t__entry->prev_state\t= __trace_sched_switch_state(preempt, prev_state, prev);\n\t\tmemcpy(__entry->prev_comm, prev->comm, TASK_COMM_LEN);\n\t\t__entry->next_pid\t= next->pid;\n\t\t__entry->next_prio\t= next->prio;\n\t\t \n\t),\n\n\tTP_printk(\"prev_comm=%s prev_pid=%d prev_prio=%d prev_state=%s%s ==> next_comm=%s next_pid=%d next_prio=%d\",\n\t\t__entry->prev_comm, __entry->prev_pid, __entry->prev_prio,\n\n\t\t(__entry->prev_state & (TASK_REPORT_MAX - 1)) ?\n\t\t  __print_flags(__entry->prev_state & (TASK_REPORT_MAX - 1), \"|\",\n\t\t\t\t{ TASK_INTERRUPTIBLE, \"S\" },\n\t\t\t\t{ TASK_UNINTERRUPTIBLE, \"D\" },\n\t\t\t\t{ __TASK_STOPPED, \"T\" },\n\t\t\t\t{ __TASK_TRACED, \"t\" },\n\t\t\t\t{ EXIT_DEAD, \"X\" },\n\t\t\t\t{ EXIT_ZOMBIE, \"Z\" },\n\t\t\t\t{ TASK_PARKED, \"P\" },\n\t\t\t\t{ TASK_DEAD, \"I\" }) :\n\t\t  \"R\",\n\n\t\t__entry->prev_state & TASK_REPORT_MAX ? \"+\" : \"\",\n\t\t__entry->next_comm, __entry->next_pid, __entry->next_prio)\n);\n\n \nTRACE_EVENT(sched_migrate_task,\n\n\tTP_PROTO(struct task_struct *p, int dest_cpu),\n\n\tTP_ARGS(p, dest_cpu),\n\n\tTP_STRUCT__entry(\n\t\t__array(\tchar,\tcomm,\tTASK_COMM_LEN\t)\n\t\t__field(\tpid_t,\tpid\t\t\t)\n\t\t__field(\tint,\tprio\t\t\t)\n\t\t__field(\tint,\torig_cpu\t\t)\n\t\t__field(\tint,\tdest_cpu\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->comm, p->comm, TASK_COMM_LEN);\n\t\t__entry->pid\t\t= p->pid;\n\t\t__entry->prio\t\t= p->prio;  \n\t\t__entry->orig_cpu\t= task_cpu(p);\n\t\t__entry->dest_cpu\t= dest_cpu;\n\t),\n\n\tTP_printk(\"comm=%s pid=%d prio=%d orig_cpu=%d dest_cpu=%d\",\n\t\t  __entry->comm, __entry->pid, __entry->prio,\n\t\t  __entry->orig_cpu, __entry->dest_cpu)\n);\n\nDECLARE_EVENT_CLASS(sched_process_template,\n\n\tTP_PROTO(struct task_struct *p),\n\n\tTP_ARGS(p),\n\n\tTP_STRUCT__entry(\n\t\t__array(\tchar,\tcomm,\tTASK_COMM_LEN\t)\n\t\t__field(\tpid_t,\tpid\t\t\t)\n\t\t__field(\tint,\tprio\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->comm, p->comm, TASK_COMM_LEN);\n\t\t__entry->pid\t\t= p->pid;\n\t\t__entry->prio\t\t= p->prio;  \n\t),\n\n\tTP_printk(\"comm=%s pid=%d prio=%d\",\n\t\t  __entry->comm, __entry->pid, __entry->prio)\n);\n\n \nDEFINE_EVENT(sched_process_template, sched_process_free,\n\t     TP_PROTO(struct task_struct *p),\n\t     TP_ARGS(p));\n\n \nDEFINE_EVENT(sched_process_template, sched_process_exit,\n\t     TP_PROTO(struct task_struct *p),\n\t     TP_ARGS(p));\n\n \nDEFINE_EVENT(sched_process_template, sched_wait_task,\n\tTP_PROTO(struct task_struct *p),\n\tTP_ARGS(p));\n\n \nTRACE_EVENT(sched_process_wait,\n\n\tTP_PROTO(struct pid *pid),\n\n\tTP_ARGS(pid),\n\n\tTP_STRUCT__entry(\n\t\t__array(\tchar,\tcomm,\tTASK_COMM_LEN\t)\n\t\t__field(\tpid_t,\tpid\t\t\t)\n\t\t__field(\tint,\tprio\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->comm, current->comm, TASK_COMM_LEN);\n\t\t__entry->pid\t\t= pid_nr(pid);\n\t\t__entry->prio\t\t= current->prio;  \n\t),\n\n\tTP_printk(\"comm=%s pid=%d prio=%d\",\n\t\t  __entry->comm, __entry->pid, __entry->prio)\n);\n\n \nTRACE_EVENT(sched_process_fork,\n\n\tTP_PROTO(struct task_struct *parent, struct task_struct *child),\n\n\tTP_ARGS(parent, child),\n\n\tTP_STRUCT__entry(\n\t\t__array(\tchar,\tparent_comm,\tTASK_COMM_LEN\t)\n\t\t__field(\tpid_t,\tparent_pid\t\t\t)\n\t\t__array(\tchar,\tchild_comm,\tTASK_COMM_LEN\t)\n\t\t__field(\tpid_t,\tchild_pid\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->parent_comm, parent->comm, TASK_COMM_LEN);\n\t\t__entry->parent_pid\t= parent->pid;\n\t\tmemcpy(__entry->child_comm, child->comm, TASK_COMM_LEN);\n\t\t__entry->child_pid\t= child->pid;\n\t),\n\n\tTP_printk(\"comm=%s pid=%d child_comm=%s child_pid=%d\",\n\t\t__entry->parent_comm, __entry->parent_pid,\n\t\t__entry->child_comm, __entry->child_pid)\n);\n\n \nTRACE_EVENT(sched_process_exec,\n\n\tTP_PROTO(struct task_struct *p, pid_t old_pid,\n\t\t struct linux_binprm *bprm),\n\n\tTP_ARGS(p, old_pid, bprm),\n\n\tTP_STRUCT__entry(\n\t\t__string(\tfilename,\tbprm->filename\t)\n\t\t__field(\tpid_t,\t\tpid\t\t)\n\t\t__field(\tpid_t,\t\told_pid\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__assign_str(filename, bprm->filename);\n\t\t__entry->pid\t\t= p->pid;\n\t\t__entry->old_pid\t= old_pid;\n\t),\n\n\tTP_printk(\"filename=%s pid=%d old_pid=%d\", __get_str(filename),\n\t\t  __entry->pid, __entry->old_pid)\n);\n\n\n#ifdef CONFIG_SCHEDSTATS\n#define DEFINE_EVENT_SCHEDSTAT DEFINE_EVENT\n#define DECLARE_EVENT_CLASS_SCHEDSTAT DECLARE_EVENT_CLASS\n#else\n#define DEFINE_EVENT_SCHEDSTAT DEFINE_EVENT_NOP\n#define DECLARE_EVENT_CLASS_SCHEDSTAT DECLARE_EVENT_CLASS_NOP\n#endif\n\n \nDECLARE_EVENT_CLASS_SCHEDSTAT(sched_stat_template,\n\n\tTP_PROTO(struct task_struct *tsk, u64 delay),\n\n\tTP_ARGS(__perf_task(tsk), __perf_count(delay)),\n\n\tTP_STRUCT__entry(\n\t\t__array( char,\tcomm,\tTASK_COMM_LEN\t)\n\t\t__field( pid_t,\tpid\t\t\t)\n\t\t__field( u64,\tdelay\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->comm, tsk->comm, TASK_COMM_LEN);\n\t\t__entry->pid\t= tsk->pid;\n\t\t__entry->delay\t= delay;\n\t),\n\n\tTP_printk(\"comm=%s pid=%d delay=%Lu [ns]\",\n\t\t\t__entry->comm, __entry->pid,\n\t\t\t(unsigned long long)__entry->delay)\n);\n\n \nDEFINE_EVENT_SCHEDSTAT(sched_stat_template, sched_stat_wait,\n\t     TP_PROTO(struct task_struct *tsk, u64 delay),\n\t     TP_ARGS(tsk, delay));\n\n \nDEFINE_EVENT_SCHEDSTAT(sched_stat_template, sched_stat_sleep,\n\t     TP_PROTO(struct task_struct *tsk, u64 delay),\n\t     TP_ARGS(tsk, delay));\n\n \nDEFINE_EVENT_SCHEDSTAT(sched_stat_template, sched_stat_iowait,\n\t     TP_PROTO(struct task_struct *tsk, u64 delay),\n\t     TP_ARGS(tsk, delay));\n\n \nDEFINE_EVENT_SCHEDSTAT(sched_stat_template, sched_stat_blocked,\n\t     TP_PROTO(struct task_struct *tsk, u64 delay),\n\t     TP_ARGS(tsk, delay));\n\n \nDECLARE_EVENT_CLASS(sched_stat_runtime,\n\n\tTP_PROTO(struct task_struct *tsk, u64 runtime, u64 vruntime),\n\n\tTP_ARGS(tsk, __perf_count(runtime), vruntime),\n\n\tTP_STRUCT__entry(\n\t\t__array( char,\tcomm,\tTASK_COMM_LEN\t)\n\t\t__field( pid_t,\tpid\t\t\t)\n\t\t__field( u64,\truntime\t\t\t)\n\t\t__field( u64,\tvruntime\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->comm, tsk->comm, TASK_COMM_LEN);\n\t\t__entry->pid\t\t= tsk->pid;\n\t\t__entry->runtime\t= runtime;\n\t\t__entry->vruntime\t= vruntime;\n\t),\n\n\tTP_printk(\"comm=%s pid=%d runtime=%Lu [ns] vruntime=%Lu [ns]\",\n\t\t\t__entry->comm, __entry->pid,\n\t\t\t(unsigned long long)__entry->runtime,\n\t\t\t(unsigned long long)__entry->vruntime)\n);\n\nDEFINE_EVENT(sched_stat_runtime, sched_stat_runtime,\n\t     TP_PROTO(struct task_struct *tsk, u64 runtime, u64 vruntime),\n\t     TP_ARGS(tsk, runtime, vruntime));\n\n \nTRACE_EVENT(sched_pi_setprio,\n\n\tTP_PROTO(struct task_struct *tsk, struct task_struct *pi_task),\n\n\tTP_ARGS(tsk, pi_task),\n\n\tTP_STRUCT__entry(\n\t\t__array( char,\tcomm,\tTASK_COMM_LEN\t)\n\t\t__field( pid_t,\tpid\t\t\t)\n\t\t__field( int,\toldprio\t\t\t)\n\t\t__field( int,\tnewprio\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->comm, tsk->comm, TASK_COMM_LEN);\n\t\t__entry->pid\t\t= tsk->pid;\n\t\t__entry->oldprio\t= tsk->prio;\n\t\t__entry->newprio\t= pi_task ?\n\t\t\t\tmin(tsk->normal_prio, pi_task->prio) :\n\t\t\t\ttsk->normal_prio;\n\t\t \n\t),\n\n\tTP_printk(\"comm=%s pid=%d oldprio=%d newprio=%d\",\n\t\t\t__entry->comm, __entry->pid,\n\t\t\t__entry->oldprio, __entry->newprio)\n);\n\n#ifdef CONFIG_DETECT_HUNG_TASK\nTRACE_EVENT(sched_process_hang,\n\tTP_PROTO(struct task_struct *tsk),\n\tTP_ARGS(tsk),\n\n\tTP_STRUCT__entry(\n\t\t__array( char,\tcomm,\tTASK_COMM_LEN\t)\n\t\t__field( pid_t,\tpid\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\tmemcpy(__entry->comm, tsk->comm, TASK_COMM_LEN);\n\t\t__entry->pid = tsk->pid;\n\t),\n\n\tTP_printk(\"comm=%s pid=%d\", __entry->comm, __entry->pid)\n);\n#endif  \n\n \nTRACE_EVENT(sched_move_numa,\n\n\tTP_PROTO(struct task_struct *tsk, int src_cpu, int dst_cpu),\n\n\tTP_ARGS(tsk, src_cpu, dst_cpu),\n\n\tTP_STRUCT__entry(\n\t\t__field( pid_t,\tpid\t\t\t)\n\t\t__field( pid_t,\ttgid\t\t\t)\n\t\t__field( pid_t,\tngid\t\t\t)\n\t\t__field( int,\tsrc_cpu\t\t\t)\n\t\t__field( int,\tsrc_nid\t\t\t)\n\t\t__field( int,\tdst_cpu\t\t\t)\n\t\t__field( int,\tdst_nid\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->pid\t\t= task_pid_nr(tsk);\n\t\t__entry->tgid\t\t= task_tgid_nr(tsk);\n\t\t__entry->ngid\t\t= task_numa_group_id(tsk);\n\t\t__entry->src_cpu\t= src_cpu;\n\t\t__entry->src_nid\t= cpu_to_node(src_cpu);\n\t\t__entry->dst_cpu\t= dst_cpu;\n\t\t__entry->dst_nid\t= cpu_to_node(dst_cpu);\n\t),\n\n\tTP_printk(\"pid=%d tgid=%d ngid=%d src_cpu=%d src_nid=%d dst_cpu=%d dst_nid=%d\",\n\t\t\t__entry->pid, __entry->tgid, __entry->ngid,\n\t\t\t__entry->src_cpu, __entry->src_nid,\n\t\t\t__entry->dst_cpu, __entry->dst_nid)\n);\n\nDECLARE_EVENT_CLASS(sched_numa_pair_template,\n\n\tTP_PROTO(struct task_struct *src_tsk, int src_cpu,\n\t\t struct task_struct *dst_tsk, int dst_cpu),\n\n\tTP_ARGS(src_tsk, src_cpu, dst_tsk, dst_cpu),\n\n\tTP_STRUCT__entry(\n\t\t__field( pid_t,\tsrc_pid\t\t\t)\n\t\t__field( pid_t,\tsrc_tgid\t\t)\n\t\t__field( pid_t,\tsrc_ngid\t\t)\n\t\t__field( int,\tsrc_cpu\t\t\t)\n\t\t__field( int,\tsrc_nid\t\t\t)\n\t\t__field( pid_t,\tdst_pid\t\t\t)\n\t\t__field( pid_t,\tdst_tgid\t\t)\n\t\t__field( pid_t,\tdst_ngid\t\t)\n\t\t__field( int,\tdst_cpu\t\t\t)\n\t\t__field( int,\tdst_nid\t\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->src_pid\t= task_pid_nr(src_tsk);\n\t\t__entry->src_tgid\t= task_tgid_nr(src_tsk);\n\t\t__entry->src_ngid\t= task_numa_group_id(src_tsk);\n\t\t__entry->src_cpu\t= src_cpu;\n\t\t__entry->src_nid\t= cpu_to_node(src_cpu);\n\t\t__entry->dst_pid\t= dst_tsk ? task_pid_nr(dst_tsk) : 0;\n\t\t__entry->dst_tgid\t= dst_tsk ? task_tgid_nr(dst_tsk) : 0;\n\t\t__entry->dst_ngid\t= dst_tsk ? task_numa_group_id(dst_tsk) : 0;\n\t\t__entry->dst_cpu\t= dst_cpu;\n\t\t__entry->dst_nid\t= dst_cpu >= 0 ? cpu_to_node(dst_cpu) : -1;\n\t),\n\n\tTP_printk(\"src_pid=%d src_tgid=%d src_ngid=%d src_cpu=%d src_nid=%d dst_pid=%d dst_tgid=%d dst_ngid=%d dst_cpu=%d dst_nid=%d\",\n\t\t\t__entry->src_pid, __entry->src_tgid, __entry->src_ngid,\n\t\t\t__entry->src_cpu, __entry->src_nid,\n\t\t\t__entry->dst_pid, __entry->dst_tgid, __entry->dst_ngid,\n\t\t\t__entry->dst_cpu, __entry->dst_nid)\n);\n\nDEFINE_EVENT(sched_numa_pair_template, sched_stick_numa,\n\n\tTP_PROTO(struct task_struct *src_tsk, int src_cpu,\n\t\t struct task_struct *dst_tsk, int dst_cpu),\n\n\tTP_ARGS(src_tsk, src_cpu, dst_tsk, dst_cpu)\n);\n\nDEFINE_EVENT(sched_numa_pair_template, sched_swap_numa,\n\n\tTP_PROTO(struct task_struct *src_tsk, int src_cpu,\n\t\t struct task_struct *dst_tsk, int dst_cpu),\n\n\tTP_ARGS(src_tsk, src_cpu, dst_tsk, dst_cpu)\n);\n\n\n \nTRACE_EVENT(sched_wake_idle_without_ipi,\n\n\tTP_PROTO(int cpu),\n\n\tTP_ARGS(cpu),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tint,\tcpu\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->cpu\t= cpu;\n\t),\n\n\tTP_printk(\"cpu=%d\", __entry->cpu)\n);\n\n \nDECLARE_TRACE(pelt_cfs_tp,\n\tTP_PROTO(struct cfs_rq *cfs_rq),\n\tTP_ARGS(cfs_rq));\n\nDECLARE_TRACE(pelt_rt_tp,\n\tTP_PROTO(struct rq *rq),\n\tTP_ARGS(rq));\n\nDECLARE_TRACE(pelt_dl_tp,\n\tTP_PROTO(struct rq *rq),\n\tTP_ARGS(rq));\n\nDECLARE_TRACE(pelt_thermal_tp,\n\tTP_PROTO(struct rq *rq),\n\tTP_ARGS(rq));\n\nDECLARE_TRACE(pelt_irq_tp,\n\tTP_PROTO(struct rq *rq),\n\tTP_ARGS(rq));\n\nDECLARE_TRACE(pelt_se_tp,\n\tTP_PROTO(struct sched_entity *se),\n\tTP_ARGS(se));\n\nDECLARE_TRACE(sched_cpu_capacity_tp,\n\tTP_PROTO(struct rq *rq),\n\tTP_ARGS(rq));\n\nDECLARE_TRACE(sched_overutilized_tp,\n\tTP_PROTO(struct root_domain *rd, bool overutilized),\n\tTP_ARGS(rd, overutilized));\n\nDECLARE_TRACE(sched_util_est_cfs_tp,\n\tTP_PROTO(struct cfs_rq *cfs_rq),\n\tTP_ARGS(cfs_rq));\n\nDECLARE_TRACE(sched_util_est_se_tp,\n\tTP_PROTO(struct sched_entity *se),\n\tTP_ARGS(se));\n\nDECLARE_TRACE(sched_update_nr_running_tp,\n\tTP_PROTO(struct rq *rq, int change),\n\tTP_ARGS(rq, change));\n\n#endif  \n\n \n#include <trace/define_trace.h>\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}