{
  "module_name": "percpu.h",
  "hash_id": "2f19cb4a85bd53851b74be9c071657e2cbffe0a276f08c770eacf5cda92a77cb",
  "original_prompt": "Ingested from linux-6.6.14/include/trace/events/percpu.h",
  "human_readable_source": " \n#undef TRACE_SYSTEM\n#define TRACE_SYSTEM percpu\n\n#if !defined(_TRACE_PERCPU_H) || defined(TRACE_HEADER_MULTI_READ)\n#define _TRACE_PERCPU_H\n\n#include <linux/tracepoint.h>\n#include <trace/events/mmflags.h>\n\nTRACE_EVENT(percpu_alloc_percpu,\n\n\tTP_PROTO(unsigned long call_site,\n\t\t bool reserved, bool is_atomic, size_t size,\n\t\t size_t align, void *base_addr, int off,\n\t\t void __percpu *ptr, size_t bytes_alloc, gfp_t gfp_flags),\n\n\tTP_ARGS(call_site, reserved, is_atomic, size, align, base_addr, off,\n\t\tptr, bytes_alloc, gfp_flags),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tunsigned long,\t\tcall_site\t)\n\t\t__field(\tbool,\t\t\treserved\t)\n\t\t__field(\tbool,\t\t\tis_atomic\t)\n\t\t__field(\tsize_t,\t\t\tsize\t\t)\n\t\t__field(\tsize_t,\t\t\talign\t\t)\n\t\t__field(\tvoid *,\t\t\tbase_addr\t)\n\t\t__field(\tint,\t\t\toff\t\t)\n\t\t__field(\tvoid __percpu *,\tptr\t\t)\n\t\t__field(\tsize_t,\t\t\tbytes_alloc\t)\n\t\t__field(\tunsigned long,\t\tgfp_flags\t)\n\t),\n\tTP_fast_assign(\n\t\t__entry->call_site\t= call_site;\n\t\t__entry->reserved\t= reserved;\n\t\t__entry->is_atomic\t= is_atomic;\n\t\t__entry->size\t\t= size;\n\t\t__entry->align\t\t= align;\n\t\t__entry->base_addr\t= base_addr;\n\t\t__entry->off\t\t= off;\n\t\t__entry->ptr\t\t= ptr;\n\t\t__entry->bytes_alloc\t= bytes_alloc;\n\t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n\t),\n\n\tTP_printk(\"call_site=%pS reserved=%d is_atomic=%d size=%zu align=%zu base_addr=%p off=%d ptr=%p bytes_alloc=%zu gfp_flags=%s\",\n\t\t  (void *)__entry->call_site,\n\t\t  __entry->reserved, __entry->is_atomic,\n\t\t  __entry->size, __entry->align,\n\t\t  __entry->base_addr, __entry->off, __entry->ptr,\n\t\t  __entry->bytes_alloc, show_gfp_flags(__entry->gfp_flags))\n);\n\nTRACE_EVENT(percpu_free_percpu,\n\n\tTP_PROTO(void *base_addr, int off, void __percpu *ptr),\n\n\tTP_ARGS(base_addr, off, ptr),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tvoid *,\t\t\tbase_addr\t)\n\t\t__field(\tint,\t\t\toff\t\t)\n\t\t__field(\tvoid __percpu *,\tptr\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->base_addr\t= base_addr;\n\t\t__entry->off\t\t= off;\n\t\t__entry->ptr\t\t= ptr;\n\t),\n\n\tTP_printk(\"base_addr=%p off=%d ptr=%p\",\n\t\t__entry->base_addr, __entry->off, __entry->ptr)\n);\n\nTRACE_EVENT(percpu_alloc_percpu_fail,\n\n\tTP_PROTO(bool reserved, bool is_atomic, size_t size, size_t align),\n\n\tTP_ARGS(reserved, is_atomic, size, align),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tbool,\treserved\t)\n\t\t__field(\tbool,\tis_atomic\t)\n\t\t__field(\tsize_t,\tsize\t\t)\n\t\t__field(\tsize_t, align\t\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->reserved\t= reserved;\n\t\t__entry->is_atomic\t= is_atomic;\n\t\t__entry->size\t\t= size;\n\t\t__entry->align\t\t= align;\n\t),\n\n\tTP_printk(\"reserved=%d is_atomic=%d size=%zu align=%zu\",\n\t\t  __entry->reserved, __entry->is_atomic,\n\t\t  __entry->size, __entry->align)\n);\n\nTRACE_EVENT(percpu_create_chunk,\n\n\tTP_PROTO(void *base_addr),\n\n\tTP_ARGS(base_addr),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tvoid *, base_addr\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->base_addr\t= base_addr;\n\t),\n\n\tTP_printk(\"base_addr=%p\", __entry->base_addr)\n);\n\nTRACE_EVENT(percpu_destroy_chunk,\n\n\tTP_PROTO(void *base_addr),\n\n\tTP_ARGS(base_addr),\n\n\tTP_STRUCT__entry(\n\t\t__field(\tvoid *,\tbase_addr\t)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->base_addr\t= base_addr;\n\t),\n\n\tTP_printk(\"base_addr=%p\", __entry->base_addr)\n);\n\n#endif  \n\n#include <trace/define_trace.h>\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}