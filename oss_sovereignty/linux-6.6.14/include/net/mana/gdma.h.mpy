{
  "module_name": "gdma.h",
  "hash_id": "f7b1d67d2dbddf1f45fb9147bedf3894b130787e05d8b305fec112cd3ca9a73f",
  "original_prompt": "Ingested from linux-6.6.14/include/net/mana/gdma.h",
  "human_readable_source": " \n \n\n#ifndef _GDMA_H\n#define _GDMA_H\n\n#include <linux/dma-mapping.h>\n#include <linux/netdevice.h>\n\n#include \"shm_channel.h\"\n\n#define GDMA_STATUS_MORE_ENTRIES\t0x00000105\n\n \n\nenum gdma_request_type {\n\tGDMA_VERIFY_VF_DRIVER_VERSION\t= 1,\n\tGDMA_QUERY_MAX_RESOURCES\t= 2,\n\tGDMA_LIST_DEVICES\t\t= 3,\n\tGDMA_REGISTER_DEVICE\t\t= 4,\n\tGDMA_DEREGISTER_DEVICE\t\t= 5,\n\tGDMA_GENERATE_TEST_EQE\t\t= 10,\n\tGDMA_CREATE_QUEUE\t\t= 12,\n\tGDMA_DISABLE_QUEUE\t\t= 13,\n\tGDMA_ALLOCATE_RESOURCE_RANGE\t= 22,\n\tGDMA_DESTROY_RESOURCE_RANGE\t= 24,\n\tGDMA_CREATE_DMA_REGION\t\t= 25,\n\tGDMA_DMA_REGION_ADD_PAGES\t= 26,\n\tGDMA_DESTROY_DMA_REGION\t\t= 27,\n\tGDMA_CREATE_PD\t\t\t= 29,\n\tGDMA_DESTROY_PD\t\t\t= 30,\n\tGDMA_CREATE_MR\t\t\t= 31,\n\tGDMA_DESTROY_MR\t\t\t= 32,\n\tGDMA_QUERY_HWC_TIMEOUT\t\t= 84,  \n};\n\n#define GDMA_RESOURCE_DOORBELL_PAGE\t27\n\nenum gdma_queue_type {\n\tGDMA_INVALID_QUEUE,\n\tGDMA_SQ,\n\tGDMA_RQ,\n\tGDMA_CQ,\n\tGDMA_EQ,\n};\n\nenum gdma_work_request_flags {\n\tGDMA_WR_NONE\t\t\t= 0,\n\tGDMA_WR_OOB_IN_SGL\t\t= BIT(0),\n\tGDMA_WR_PAD_BY_SGE0\t\t= BIT(1),\n};\n\nenum gdma_eqe_type {\n\tGDMA_EQE_COMPLETION\t\t= 3,\n\tGDMA_EQE_TEST_EVENT\t\t= 64,\n\tGDMA_EQE_HWC_INIT_EQ_ID_DB\t= 129,\n\tGDMA_EQE_HWC_INIT_DATA\t\t= 130,\n\tGDMA_EQE_HWC_INIT_DONE\t\t= 131,\n\tGDMA_EQE_HWC_SOC_RECONFIG\t= 132,\n\tGDMA_EQE_HWC_SOC_RECONFIG_DATA\t= 133,\n};\n\nenum {\n\tGDMA_DEVICE_NONE\t= 0,\n\tGDMA_DEVICE_HWC\t\t= 1,\n\tGDMA_DEVICE_MANA\t= 2,\n};\n\nstruct gdma_resource {\n\t \n\tspinlock_t lock;\n\n\t \n\tu32 size;\n\n\t \n\tunsigned long *map;\n};\n\nunion gdma_doorbell_entry {\n\tu64\tas_uint64;\n\n\tstruct {\n\t\tu64 id\t\t: 24;\n\t\tu64 reserved\t: 8;\n\t\tu64 tail_ptr\t: 31;\n\t\tu64 arm\t\t: 1;\n\t} cq;\n\n\tstruct {\n\t\tu64 id\t\t: 24;\n\t\tu64 wqe_cnt\t: 8;\n\t\tu64 tail_ptr\t: 32;\n\t} rq;\n\n\tstruct {\n\t\tu64 id\t\t: 24;\n\t\tu64 reserved\t: 8;\n\t\tu64 tail_ptr\t: 32;\n\t} sq;\n\n\tstruct {\n\t\tu64 id\t\t: 16;\n\t\tu64 reserved\t: 16;\n\t\tu64 tail_ptr\t: 31;\n\t\tu64 arm\t\t: 1;\n\t} eq;\n};  \n\nstruct gdma_msg_hdr {\n\tu32 hdr_type;\n\tu32 msg_type;\n\tu16 msg_version;\n\tu16 hwc_msg_id;\n\tu32 msg_size;\n};  \n\nstruct gdma_dev_id {\n\tunion {\n\t\tstruct {\n\t\t\tu16 type;\n\t\t\tu16 instance;\n\t\t};\n\n\t\tu32 as_uint32;\n\t};\n};  \n\nstruct gdma_req_hdr {\n\tstruct gdma_msg_hdr req;\n\tstruct gdma_msg_hdr resp;  \n\tstruct gdma_dev_id dev_id;\n\tu32 activity_id;\n};  \n\nstruct gdma_resp_hdr {\n\tstruct gdma_msg_hdr response;\n\tstruct gdma_dev_id dev_id;\n\tu32 activity_id;\n\tu32 status;\n\tu32 reserved;\n};  \n\nstruct gdma_general_req {\n\tstruct gdma_req_hdr hdr;\n};  \n\n#define GDMA_MESSAGE_V1 1\n#define GDMA_MESSAGE_V2 2\n\nstruct gdma_general_resp {\n\tstruct gdma_resp_hdr hdr;\n};  \n\n#define GDMA_STANDARD_HEADER_TYPE 0\n\nstatic inline void mana_gd_init_req_hdr(struct gdma_req_hdr *hdr, u32 code,\n\t\t\t\t\tu32 req_size, u32 resp_size)\n{\n\thdr->req.hdr_type = GDMA_STANDARD_HEADER_TYPE;\n\thdr->req.msg_type = code;\n\thdr->req.msg_version = GDMA_MESSAGE_V1;\n\thdr->req.msg_size = req_size;\n\n\thdr->resp.hdr_type = GDMA_STANDARD_HEADER_TYPE;\n\thdr->resp.msg_type = code;\n\thdr->resp.msg_version = GDMA_MESSAGE_V1;\n\thdr->resp.msg_size = resp_size;\n}\n\n \nstruct gdma_sge {\n\tu64 address;\n\tu32 mem_key;\n\tu32 size;\n};  \n\nstruct gdma_wqe_request {\n\tstruct gdma_sge *sgl;\n\tu32 num_sge;\n\n\tu32 inline_oob_size;\n\tconst void *inline_oob_data;\n\n\tu32 flags;\n\tu32 client_data_unit;\n};\n\nenum gdma_page_type {\n\tGDMA_PAGE_TYPE_4K,\n};\n\n#define GDMA_INVALID_DMA_REGION 0\n\nstruct gdma_mem_info {\n\tstruct device *dev;\n\n\tdma_addr_t dma_handle;\n\tvoid *virt_addr;\n\tu64 length;\n\n\t \n\tu64 dma_region_handle;\n};\n\n#define REGISTER_ATB_MST_MKEY_LOWER_SIZE 8\n\nstruct gdma_dev {\n\tstruct gdma_context *gdma_context;\n\n\tstruct gdma_dev_id dev_id;\n\n\tu32 pdid;\n\tu32 doorbell;\n\tu32 gpa_mkey;\n\n\t \n\tvoid *driver_data;\n\n\tstruct auxiliary_device *adev;\n};\n\n#define MINIMUM_SUPPORTED_PAGE_SIZE PAGE_SIZE\n\n#define GDMA_CQE_SIZE 64\n#define GDMA_EQE_SIZE 16\n#define GDMA_MAX_SQE_SIZE 512\n#define GDMA_MAX_RQE_SIZE 256\n\n#define GDMA_COMP_DATA_SIZE 0x3C\n\n#define GDMA_EVENT_DATA_SIZE 0xC\n\n \n#define GDMA_WQE_BU_SIZE 32\n\n#define INVALID_PDID\t\tUINT_MAX\n#define INVALID_DOORBELL\tUINT_MAX\n#define INVALID_MEM_KEY\t\tUINT_MAX\n#define INVALID_QUEUE_ID\tUINT_MAX\n#define INVALID_PCI_MSIX_INDEX  UINT_MAX\n\nstruct gdma_comp {\n\tu32 cqe_data[GDMA_COMP_DATA_SIZE / 4];\n\tu32 wq_num;\n\tbool is_sq;\n};\n\nstruct gdma_event {\n\tu32 details[GDMA_EVENT_DATA_SIZE / 4];\n\tu8  type;\n};\n\nstruct gdma_queue;\n\nstruct mana_eq {\n\tstruct gdma_queue *eq;\n};\n\ntypedef void gdma_eq_callback(void *context, struct gdma_queue *q,\n\t\t\t      struct gdma_event *e);\n\ntypedef void gdma_cq_callback(void *context, struct gdma_queue *q);\n\n \nstruct gdma_queue {\n\tstruct gdma_dev *gdma_dev;\n\n\tenum gdma_queue_type type;\n\tu32 id;\n\n\tstruct gdma_mem_info mem_info;\n\n\tvoid *queue_mem_ptr;\n\tu32 queue_size;\n\n\tbool monitor_avl_buf;\n\n\tu32 head;\n\tu32 tail;\n\n\t \n\tunion {\n\t\tstruct {\n\t\t\tbool disable_needed;\n\n\t\t\tgdma_eq_callback *callback;\n\t\t\tvoid *context;\n\n\t\t\tunsigned int msix_index;\n\n\t\t\tu32 log2_throttle_limit;\n\t\t} eq;\n\n\t\tstruct {\n\t\t\tgdma_cq_callback *callback;\n\t\t\tvoid *context;\n\n\t\t\tstruct gdma_queue *parent;  \n\t\t} cq;\n\t};\n};\n\nstruct gdma_queue_spec {\n\tenum gdma_queue_type type;\n\tbool monitor_avl_buf;\n\tunsigned int queue_size;\n\n\t \n\tunion {\n\t\tstruct {\n\t\t\tgdma_eq_callback *callback;\n\t\t\tvoid *context;\n\n\t\t\tunsigned long log2_throttle_limit;\n\t\t} eq;\n\n\t\tstruct {\n\t\t\tgdma_cq_callback *callback;\n\t\t\tvoid *context;\n\n\t\t\tstruct gdma_queue *parent_eq;\n\n\t\t} cq;\n\t};\n};\n\n#define MANA_IRQ_NAME_SZ 32\n\nstruct gdma_irq_context {\n\tvoid (*handler)(void *arg);\n\tvoid *arg;\n\tchar name[MANA_IRQ_NAME_SZ];\n};\n\nstruct gdma_context {\n\tstruct device\t\t*dev;\n\n\t \n\tunsigned int\t\tmax_num_queues;\n\tunsigned int\t\tmax_num_msix;\n\tunsigned int\t\tnum_msix_usable;\n\tstruct gdma_resource\tmsix_resource;\n\tstruct gdma_irq_context\t*irq_contexts;\n\n\t \n\tu16 adapter_mtu;\n\n\t \n\tunsigned int\t\tmax_num_cqs;\n\tstruct gdma_queue\t**cq_table;\n\n\t \n\tstruct mutex\t\teq_test_event_mutex;\n\tstruct completion\teq_test_event;\n\tu32\t\t\ttest_event_eq_id;\n\n\tbool\t\t\tis_pf;\n\tphys_addr_t\t\tbar0_pa;\n\tvoid __iomem\t\t*bar0_va;\n\tvoid __iomem\t\t*shm_base;\n\tvoid __iomem\t\t*db_page_base;\n\tphys_addr_t\t\tphys_db_page_base;\n\tu32 db_page_size;\n\tint                     numa_node;\n\n\t \n\tstruct shm_channel\tshm_channel;\n\n\t \n\tstruct gdma_dev\t\thwc;\n\n\t \n\tstruct gdma_dev\t\tmana;\n};\n\n#define MAX_NUM_GDMA_DEVICES\t4\n\nstatic inline bool mana_gd_is_mana(struct gdma_dev *gd)\n{\n\treturn gd->dev_id.type == GDMA_DEVICE_MANA;\n}\n\nstatic inline bool mana_gd_is_hwc(struct gdma_dev *gd)\n{\n\treturn gd->dev_id.type == GDMA_DEVICE_HWC;\n}\n\nu8 *mana_gd_get_wqe_ptr(const struct gdma_queue *wq, u32 wqe_offset);\nu32 mana_gd_wq_avail_space(struct gdma_queue *wq);\n\nint mana_gd_test_eq(struct gdma_context *gc, struct gdma_queue *eq);\n\nint mana_gd_create_hwc_queue(struct gdma_dev *gd,\n\t\t\t     const struct gdma_queue_spec *spec,\n\t\t\t     struct gdma_queue **queue_ptr);\n\nint mana_gd_create_mana_eq(struct gdma_dev *gd,\n\t\t\t   const struct gdma_queue_spec *spec,\n\t\t\t   struct gdma_queue **queue_ptr);\n\nint mana_gd_create_mana_wq_cq(struct gdma_dev *gd,\n\t\t\t      const struct gdma_queue_spec *spec,\n\t\t\t      struct gdma_queue **queue_ptr);\n\nvoid mana_gd_destroy_queue(struct gdma_context *gc, struct gdma_queue *queue);\n\nint mana_gd_poll_cq(struct gdma_queue *cq, struct gdma_comp *comp, int num_cqe);\n\nvoid mana_gd_ring_cq(struct gdma_queue *cq, u8 arm_bit);\n\nstruct gdma_wqe {\n\tu32 reserved\t:24;\n\tu32 last_vbytes\t:8;\n\n\tunion {\n\t\tu32 flags;\n\n\t\tstruct {\n\t\t\tu32 num_sge\t\t:8;\n\t\t\tu32 inline_oob_size_div4:3;\n\t\t\tu32 client_oob_in_sgl\t:1;\n\t\t\tu32 reserved1\t\t:4;\n\t\t\tu32 client_data_unit\t:14;\n\t\t\tu32 reserved2\t\t:2;\n\t\t};\n\t};\n};  \n\n#define INLINE_OOB_SMALL_SIZE 8\n#define INLINE_OOB_LARGE_SIZE 24\n\n#define MAX_TX_WQE_SIZE 512\n#define MAX_RX_WQE_SIZE 256\n\n#define MAX_TX_WQE_SGL_ENTRIES\t((GDMA_MAX_SQE_SIZE -\t\t\t   \\\n\t\t\tsizeof(struct gdma_sge) - INLINE_OOB_SMALL_SIZE) / \\\n\t\t\tsizeof(struct gdma_sge))\n\n#define MAX_RX_WQE_SGL_ENTRIES\t((GDMA_MAX_RQE_SIZE -\t\t\t   \\\n\t\t\tsizeof(struct gdma_sge)) / sizeof(struct gdma_sge))\n\nstruct gdma_cqe {\n\tu32 cqe_data[GDMA_COMP_DATA_SIZE / 4];\n\n\tunion {\n\t\tu32 as_uint32;\n\n\t\tstruct {\n\t\t\tu32 wq_num\t: 24;\n\t\t\tu32 is_sq\t: 1;\n\t\t\tu32 reserved\t: 4;\n\t\t\tu32 owner_bits\t: 3;\n\t\t};\n\t} cqe_info;\n};  \n\n#define GDMA_CQE_OWNER_BITS 3\n\n#define GDMA_CQE_OWNER_MASK ((1 << GDMA_CQE_OWNER_BITS) - 1)\n\n#define SET_ARM_BIT 1\n\n#define GDMA_EQE_OWNER_BITS 3\n\nunion gdma_eqe_info {\n\tu32 as_uint32;\n\n\tstruct {\n\t\tu32 type\t: 8;\n\t\tu32 reserved1\t: 8;\n\t\tu32 client_id\t: 2;\n\t\tu32 reserved2\t: 11;\n\t\tu32 owner_bits\t: 3;\n\t};\n};  \n\n#define GDMA_EQE_OWNER_MASK ((1 << GDMA_EQE_OWNER_BITS) - 1)\n#define INITIALIZED_OWNER_BIT(log2_num_entries) (1UL << (log2_num_entries))\n\nstruct gdma_eqe {\n\tu32 details[GDMA_EVENT_DATA_SIZE / 4];\n\tu32 eqe_info;\n};  \n\n#define GDMA_REG_DB_PAGE_OFFSET\t8\n#define GDMA_REG_DB_PAGE_SIZE\t0x10\n#define GDMA_REG_SHM_OFFSET\t0x18\n\n#define GDMA_PF_REG_DB_PAGE_SIZE\t0xD0\n#define GDMA_PF_REG_DB_PAGE_OFF\t\t0xC8\n#define GDMA_PF_REG_SHM_OFF\t\t0x70\n\n#define GDMA_SRIOV_REG_CFG_BASE_OFF\t0x108\n\n#define MANA_PF_DEVICE_ID 0x00B9\n#define MANA_VF_DEVICE_ID 0x00BA\n\nstruct gdma_posted_wqe_info {\n\tu32 wqe_size_in_bu;\n};\n\n \nstruct gdma_generate_test_event_req {\n\tstruct gdma_req_hdr hdr;\n\tu32 queue_index;\n};  \n\n \nenum {\n\tGDMA_PROTOCOL_V1\t= 1,\n\tGDMA_PROTOCOL_FIRST\t= GDMA_PROTOCOL_V1,\n\tGDMA_PROTOCOL_LAST\t= GDMA_PROTOCOL_V1,\n};\n\n#define GDMA_DRV_CAP_FLAG_1_EQ_SHARING_MULTI_VPORT BIT(0)\n\n \n#define GDMA_DRV_CAP_FLAG_1_NAPI_WKDONE_FIX BIT(2)\n#define GDMA_DRV_CAP_FLAG_1_HWC_TIMEOUT_RECONFIG BIT(3)\n\n#define GDMA_DRV_CAP_FLAGS1 \\\n\t(GDMA_DRV_CAP_FLAG_1_EQ_SHARING_MULTI_VPORT | \\\n\t GDMA_DRV_CAP_FLAG_1_NAPI_WKDONE_FIX | \\\n\t GDMA_DRV_CAP_FLAG_1_HWC_TIMEOUT_RECONFIG)\n\n#define GDMA_DRV_CAP_FLAGS2 0\n\n#define GDMA_DRV_CAP_FLAGS3 0\n\n#define GDMA_DRV_CAP_FLAGS4 0\n\nstruct gdma_verify_ver_req {\n\tstruct gdma_req_hdr hdr;\n\n\t \n\tu64 protocol_ver_min;\n\tu64 protocol_ver_max;\n\n\t \n\tu64 gd_drv_cap_flags1;\n\tu64 gd_drv_cap_flags2;\n\tu64 gd_drv_cap_flags3;\n\tu64 gd_drv_cap_flags4;\n\n\t \n\tu64 drv_ver;\n\tu32 os_type;  \n\tu32 reserved;\n\tu32 os_ver_major;\n\tu32 os_ver_minor;\n\tu32 os_ver_build;\n\tu32 os_ver_platform;\n\tu64 reserved_2;\n\tu8 os_ver_str1[128];\n\tu8 os_ver_str2[128];\n\tu8 os_ver_str3[128];\n\tu8 os_ver_str4[128];\n};  \n\nstruct gdma_verify_ver_resp {\n\tstruct gdma_resp_hdr hdr;\n\tu64 gdma_protocol_ver;\n\tu64 pf_cap_flags1;\n\tu64 pf_cap_flags2;\n\tu64 pf_cap_flags3;\n\tu64 pf_cap_flags4;\n};  \n\n \nstruct gdma_query_max_resources_resp {\n\tstruct gdma_resp_hdr hdr;\n\tu32 status;\n\tu32 max_sq;\n\tu32 max_rq;\n\tu32 max_cq;\n\tu32 max_eq;\n\tu32 max_db;\n\tu32 max_mst;\n\tu32 max_cq_mod_ctx;\n\tu32 max_mod_cq;\n\tu32 max_msix;\n};  \n\n \nstruct gdma_list_devices_resp {\n\tstruct gdma_resp_hdr hdr;\n\tu32 num_of_devs;\n\tu32 reserved;\n\tstruct gdma_dev_id devs[64];\n};  \n\n \nstruct gdma_register_device_resp {\n\tstruct gdma_resp_hdr hdr;\n\tu32 pdid;\n\tu32 gpa_mkey;\n\tu32 db_id;\n};  \n\nstruct gdma_allocate_resource_range_req {\n\tstruct gdma_req_hdr hdr;\n\tu32 resource_type;\n\tu32 num_resources;\n\tu32 alignment;\n\tu32 allocated_resources;\n};\n\nstruct gdma_allocate_resource_range_resp {\n\tstruct gdma_resp_hdr hdr;\n\tu32 allocated_resources;\n};\n\nstruct gdma_destroy_resource_range_req {\n\tstruct gdma_req_hdr hdr;\n\tu32 resource_type;\n\tu32 num_resources;\n\tu32 allocated_resources;\n};\n\n \nstruct gdma_create_queue_req {\n\tstruct gdma_req_hdr hdr;\n\tu32 type;\n\tu32 reserved1;\n\tu32 pdid;\n\tu32 doolbell_id;\n\tu64 gdma_region;\n\tu32 reserved2;\n\tu32 queue_size;\n\tu32 log2_throttle_limit;\n\tu32 eq_pci_msix_index;\n\tu32 cq_mod_ctx_id;\n\tu32 cq_parent_eq_id;\n\tu8  rq_drop_on_overrun;\n\tu8  rq_err_on_wqe_overflow;\n\tu8  rq_chain_rec_wqes;\n\tu8  sq_hw_db;\n\tu32 reserved3;\n};  \n\nstruct gdma_create_queue_resp {\n\tstruct gdma_resp_hdr hdr;\n\tu32 queue_index;\n};  \n\n \nstruct gdma_disable_queue_req {\n\tstruct gdma_req_hdr hdr;\n\tu32 type;\n\tu32 queue_index;\n\tu32 alloc_res_id_on_creation;\n};  \n\n \nstruct gdma_query_hwc_timeout_req {\n\tstruct gdma_req_hdr hdr;\n\tu32 timeout_ms;\n\tu32 reserved;\n};\n\nstruct gdma_query_hwc_timeout_resp {\n\tstruct gdma_resp_hdr hdr;\n\tu32 timeout_ms;\n\tu32 reserved;\n};\n\nenum atb_page_size {\n\tATB_PAGE_SIZE_4K,\n\tATB_PAGE_SIZE_8K,\n\tATB_PAGE_SIZE_16K,\n\tATB_PAGE_SIZE_32K,\n\tATB_PAGE_SIZE_64K,\n\tATB_PAGE_SIZE_128K,\n\tATB_PAGE_SIZE_256K,\n\tATB_PAGE_SIZE_512K,\n\tATB_PAGE_SIZE_1M,\n\tATB_PAGE_SIZE_2M,\n\tATB_PAGE_SIZE_MAX,\n};\n\nenum gdma_mr_access_flags {\n\tGDMA_ACCESS_FLAG_LOCAL_READ = BIT_ULL(0),\n\tGDMA_ACCESS_FLAG_LOCAL_WRITE = BIT_ULL(1),\n\tGDMA_ACCESS_FLAG_REMOTE_READ = BIT_ULL(2),\n\tGDMA_ACCESS_FLAG_REMOTE_WRITE = BIT_ULL(3),\n\tGDMA_ACCESS_FLAG_REMOTE_ATOMIC = BIT_ULL(4),\n};\n\n \nstruct gdma_create_dma_region_req {\n\tstruct gdma_req_hdr hdr;\n\n\t \n\tu64 length;\n\n\t \n\tu32 offset_in_page;\n\n\t \n\tu32 gdma_page_type;\n\n\t \n\tu32 page_count;\n\n\t \n\tu32 page_addr_list_len;\n\tu64 page_addr_list[];\n};  \n\nstruct gdma_create_dma_region_resp {\n\tstruct gdma_resp_hdr hdr;\n\tu64 dma_region_handle;\n};  \n\n \nstruct gdma_dma_region_add_pages_req {\n\tstruct gdma_req_hdr hdr;\n\n\tu64 dma_region_handle;\n\n\tu32 page_addr_list_len;\n\tu32 reserved3;\n\n\tu64 page_addr_list[];\n};  \n\n \nstruct gdma_destroy_dma_region_req {\n\tstruct gdma_req_hdr hdr;\n\n\tu64 dma_region_handle;\n};  \n\nenum gdma_pd_flags {\n\tGDMA_PD_FLAG_INVALID = 0,\n};\n\nstruct gdma_create_pd_req {\n\tstruct gdma_req_hdr hdr;\n\tenum gdma_pd_flags flags;\n\tu32 reserved;\n}; \n\nstruct gdma_create_pd_resp {\n\tstruct gdma_resp_hdr hdr;\n\tu64 pd_handle;\n\tu32 pd_id;\n\tu32 reserved;\n}; \n\nstruct gdma_destroy_pd_req {\n\tstruct gdma_req_hdr hdr;\n\tu64 pd_handle;\n}; \n\nstruct gdma_destory_pd_resp {\n\tstruct gdma_resp_hdr hdr;\n}; \n\nenum gdma_mr_type {\n\t \n\tGDMA_MR_TYPE_GVA = 2,\n};\n\nstruct gdma_create_mr_params {\n\tu64 pd_handle;\n\tenum gdma_mr_type mr_type;\n\tunion {\n\t\tstruct {\n\t\t\tu64 dma_region_handle;\n\t\t\tu64 virtual_address;\n\t\t\tenum gdma_mr_access_flags access_flags;\n\t\t} gva;\n\t};\n};\n\nstruct gdma_create_mr_request {\n\tstruct gdma_req_hdr hdr;\n\tu64 pd_handle;\n\tenum gdma_mr_type mr_type;\n\tu32 reserved_1;\n\n\tunion {\n\t\tstruct {\n\t\t\tu64 dma_region_handle;\n\t\t\tu64 virtual_address;\n\t\t\tenum gdma_mr_access_flags access_flags;\n\t\t} gva;\n\n\t};\n\tu32 reserved_2;\n}; \n\nstruct gdma_create_mr_response {\n\tstruct gdma_resp_hdr hdr;\n\tu64 mr_handle;\n\tu32 lkey;\n\tu32 rkey;\n}; \n\nstruct gdma_destroy_mr_request {\n\tstruct gdma_req_hdr hdr;\n\tu64 mr_handle;\n}; \n\nstruct gdma_destroy_mr_response {\n\tstruct gdma_resp_hdr hdr;\n}; \n\nint mana_gd_verify_vf_version(struct pci_dev *pdev);\n\nint mana_gd_register_device(struct gdma_dev *gd);\nint mana_gd_deregister_device(struct gdma_dev *gd);\n\nint mana_gd_post_work_request(struct gdma_queue *wq,\n\t\t\t      const struct gdma_wqe_request *wqe_req,\n\t\t\t      struct gdma_posted_wqe_info *wqe_info);\n\nint mana_gd_post_and_ring(struct gdma_queue *queue,\n\t\t\t  const struct gdma_wqe_request *wqe,\n\t\t\t  struct gdma_posted_wqe_info *wqe_info);\n\nint mana_gd_alloc_res_map(u32 res_avail, struct gdma_resource *r);\nvoid mana_gd_free_res_map(struct gdma_resource *r);\n\nvoid mana_gd_wq_ring_doorbell(struct gdma_context *gc,\n\t\t\t      struct gdma_queue *queue);\n\nint mana_gd_alloc_memory(struct gdma_context *gc, unsigned int length,\n\t\t\t struct gdma_mem_info *gmi);\n\nvoid mana_gd_free_memory(struct gdma_mem_info *gmi);\n\nint mana_gd_send_request(struct gdma_context *gc, u32 req_len, const void *req,\n\t\t\t u32 resp_len, void *resp);\n\nint mana_gd_destroy_dma_region(struct gdma_context *gc, u64 dma_region_handle);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}