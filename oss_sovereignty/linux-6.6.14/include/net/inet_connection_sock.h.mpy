{
  "module_name": "inet_connection_sock.h",
  "hash_id": "a0b99fa206b426ef578a46f3f9b5ba3967fed5c10441f673ad500c9851fa3485",
  "original_prompt": "Ingested from linux-6.6.14/include/net/inet_connection_sock.h",
  "human_readable_source": " \n \n#ifndef _INET_CONNECTION_SOCK_H\n#define _INET_CONNECTION_SOCK_H\n\n#include <linux/compiler.h>\n#include <linux/string.h>\n#include <linux/timer.h>\n#include <linux/poll.h>\n#include <linux/kernel.h>\n#include <linux/sockptr.h>\n\n#include <net/inet_sock.h>\n#include <net/request_sock.h>\n\n \n#undef INET_CSK_CLEAR_TIMERS\n\nstruct inet_bind_bucket;\nstruct inet_bind2_bucket;\nstruct tcp_congestion_ops;\n\n \nstruct inet_connection_sock_af_ops {\n\tint\t    (*queue_xmit)(struct sock *sk, struct sk_buff *skb, struct flowi *fl);\n\tvoid\t    (*send_check)(struct sock *sk, struct sk_buff *skb);\n\tint\t    (*rebuild_header)(struct sock *sk);\n\tvoid\t    (*sk_rx_dst_set)(struct sock *sk, const struct sk_buff *skb);\n\tint\t    (*conn_request)(struct sock *sk, struct sk_buff *skb);\n\tstruct sock *(*syn_recv_sock)(const struct sock *sk, struct sk_buff *skb,\n\t\t\t\t      struct request_sock *req,\n\t\t\t\t      struct dst_entry *dst,\n\t\t\t\t      struct request_sock *req_unhash,\n\t\t\t\t      bool *own_req);\n\tu16\t    net_header_len;\n\tu16\t    net_frag_header_len;\n\tu16\t    sockaddr_len;\n\tint\t    (*setsockopt)(struct sock *sk, int level, int optname,\n\t\t\t\t  sockptr_t optval, unsigned int optlen);\n\tint\t    (*getsockopt)(struct sock *sk, int level, int optname,\n\t\t\t\t  char __user *optval, int __user *optlen);\n\tvoid\t    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);\n\tvoid\t    (*mtu_reduced)(struct sock *sk);\n};\n\n \nstruct inet_connection_sock {\n\t \n\tstruct inet_sock\t  icsk_inet;\n\tstruct request_sock_queue icsk_accept_queue;\n\tstruct inet_bind_bucket\t  *icsk_bind_hash;\n\tstruct inet_bind2_bucket  *icsk_bind2_hash;\n\tunsigned long\t\t  icsk_timeout;\n \tstruct timer_list\t  icsk_retransmit_timer;\n \tstruct timer_list\t  icsk_delack_timer;\n\t__u32\t\t\t  icsk_rto;\n\t__u32                     icsk_rto_min;\n\t__u32                     icsk_delack_max;\n\t__u32\t\t\t  icsk_pmtu_cookie;\n\tconst struct tcp_congestion_ops *icsk_ca_ops;\n\tconst struct inet_connection_sock_af_ops *icsk_af_ops;\n\tconst struct tcp_ulp_ops  *icsk_ulp_ops;\n\tvoid __rcu\t\t  *icsk_ulp_data;\n\tvoid (*icsk_clean_acked)(struct sock *sk, u32 acked_seq);\n\tunsigned int\t\t  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);\n\t__u8\t\t\t  icsk_ca_state:5,\n\t\t\t\t  icsk_ca_initialized:1,\n\t\t\t\t  icsk_ca_setsockopt:1,\n\t\t\t\t  icsk_ca_dst_locked:1;\n\t__u8\t\t\t  icsk_retransmits;\n\t__u8\t\t\t  icsk_pending;\n\t__u8\t\t\t  icsk_backoff;\n\t__u8\t\t\t  icsk_syn_retries;\n\t__u8\t\t\t  icsk_probes_out;\n\t__u16\t\t\t  icsk_ext_hdr_len;\n\tstruct {\n\t\t__u8\t\t  pending;\t  \n\t\t__u8\t\t  quick;\t  \n\t\t__u8\t\t  pingpong;\t  \n\t\t__u8\t\t  retry;\t  \n\t\t__u32\t\t  ato;\t\t  \n\t\tunsigned long\t  timeout;\t  \n\t\t__u32\t\t  lrcvtime;\t  \n\t\t__u16\t\t  last_seg_size;  \n\t\t__u16\t\t  rcv_mss;\t  \n\t} icsk_ack;\n\tstruct {\n\t\t \n\t\tint\t\t  search_high;\n\t\tint\t\t  search_low;\n\n\t\t \n\t\tu32\t\t  probe_size:31,\n\t\t \n\t\t\t\t  enabled:1;\n\n\t\tu32\t\t  probe_timestamp;\n\t} icsk_mtup;\n\tu32\t\t\t  icsk_probes_tstamp;\n\tu32\t\t\t  icsk_user_timeout;\n\n\tu64\t\t\t  icsk_ca_priv[104 / sizeof(u64)];\n#define ICSK_CA_PRIV_SIZE\t  sizeof_field(struct inet_connection_sock, icsk_ca_priv)\n};\n\n#define ICSK_TIME_RETRANS\t1\t \n#define ICSK_TIME_DACK\t\t2\t \n#define ICSK_TIME_PROBE0\t3\t \n#define ICSK_TIME_LOSS_PROBE\t5\t \n#define ICSK_TIME_REO_TIMEOUT\t6\t \n\nstatic inline struct inet_connection_sock *inet_csk(const struct sock *sk)\n{\n\treturn (struct inet_connection_sock *)sk;\n}\n\nstatic inline void *inet_csk_ca(const struct sock *sk)\n{\n\treturn (void *)inet_csk(sk)->icsk_ca_priv;\n}\n\nstruct sock *inet_csk_clone_lock(const struct sock *sk,\n\t\t\t\t const struct request_sock *req,\n\t\t\t\t const gfp_t priority);\n\nenum inet_csk_ack_state_t {\n\tICSK_ACK_SCHED\t= 1,\n\tICSK_ACK_TIMER  = 2,\n\tICSK_ACK_PUSHED = 4,\n\tICSK_ACK_PUSHED2 = 8,\n\tICSK_ACK_NOW = 16,\t \n\tICSK_ACK_NOMEM = 32,\n};\n\nvoid inet_csk_init_xmit_timers(struct sock *sk,\n\t\t\t       void (*retransmit_handler)(struct timer_list *),\n\t\t\t       void (*delack_handler)(struct timer_list *),\n\t\t\t       void (*keepalive_handler)(struct timer_list *));\nvoid inet_csk_clear_xmit_timers(struct sock *sk);\n\nstatic inline void inet_csk_schedule_ack(struct sock *sk)\n{\n\tinet_csk(sk)->icsk_ack.pending |= ICSK_ACK_SCHED;\n}\n\nstatic inline int inet_csk_ack_scheduled(const struct sock *sk)\n{\n\treturn inet_csk(sk)->icsk_ack.pending & ICSK_ACK_SCHED;\n}\n\nstatic inline void inet_csk_delack_init(struct sock *sk)\n{\n\tmemset(&inet_csk(sk)->icsk_ack, 0, sizeof(inet_csk(sk)->icsk_ack));\n}\n\nvoid inet_csk_delete_keepalive_timer(struct sock *sk);\nvoid inet_csk_reset_keepalive_timer(struct sock *sk, unsigned long timeout);\n\nstatic inline void inet_csk_clear_xmit_timer(struct sock *sk, const int what)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\n\tif (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0) {\n\t\ticsk->icsk_pending = 0;\n#ifdef INET_CSK_CLEAR_TIMERS\n\t\tsk_stop_timer(sk, &icsk->icsk_retransmit_timer);\n#endif\n\t} else if (what == ICSK_TIME_DACK) {\n\t\ticsk->icsk_ack.pending = 0;\n\t\ticsk->icsk_ack.retry = 0;\n#ifdef INET_CSK_CLEAR_TIMERS\n\t\tsk_stop_timer(sk, &icsk->icsk_delack_timer);\n#endif\n\t} else {\n\t\tpr_debug(\"inet_csk BUG: unknown timer value\\n\");\n\t}\n}\n\n \nstatic inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,\n\t\t\t\t\t     unsigned long when,\n\t\t\t\t\t     const unsigned long max_when)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\n\tif (when > max_when) {\n\t\tpr_debug(\"reset_xmit_timer: sk=%p %d when=0x%lx, caller=%p\\n\",\n\t\t\t sk, what, when, (void *)_THIS_IP_);\n\t\twhen = max_when;\n\t}\n\n\tif (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0 ||\n\t    what == ICSK_TIME_LOSS_PROBE || what == ICSK_TIME_REO_TIMEOUT) {\n\t\ticsk->icsk_pending = what;\n\t\ticsk->icsk_timeout = jiffies + when;\n\t\tsk_reset_timer(sk, &icsk->icsk_retransmit_timer, icsk->icsk_timeout);\n\t} else if (what == ICSK_TIME_DACK) {\n\t\ticsk->icsk_ack.pending |= ICSK_ACK_TIMER;\n\t\ticsk->icsk_ack.timeout = jiffies + when;\n\t\tsk_reset_timer(sk, &icsk->icsk_delack_timer, icsk->icsk_ack.timeout);\n\t} else {\n\t\tpr_debug(\"inet_csk BUG: unknown timer value\\n\");\n\t}\n}\n\nstatic inline unsigned long\ninet_csk_rto_backoff(const struct inet_connection_sock *icsk,\n\t\t     unsigned long max_when)\n{\n        u64 when = (u64)icsk->icsk_rto << icsk->icsk_backoff;\n\n        return (unsigned long)min_t(u64, when, max_when);\n}\n\nstruct sock *inet_csk_accept(struct sock *sk, int flags, int *err, bool kern);\n\nint inet_csk_get_port(struct sock *sk, unsigned short snum);\n\nstruct dst_entry *inet_csk_route_req(const struct sock *sk, struct flowi4 *fl4,\n\t\t\t\t     const struct request_sock *req);\nstruct dst_entry *inet_csk_route_child_sock(const struct sock *sk,\n\t\t\t\t\t    struct sock *newsk,\n\t\t\t\t\t    const struct request_sock *req);\n\nstruct sock *inet_csk_reqsk_queue_add(struct sock *sk,\n\t\t\t\t      struct request_sock *req,\n\t\t\t\t      struct sock *child);\nvoid inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,\n\t\t\t\t   unsigned long timeout);\nstruct sock *inet_csk_complete_hashdance(struct sock *sk, struct sock *child,\n\t\t\t\t\t struct request_sock *req,\n\t\t\t\t\t bool own_req);\n\nstatic inline void inet_csk_reqsk_queue_added(struct sock *sk)\n{\n\treqsk_queue_added(&inet_csk(sk)->icsk_accept_queue);\n}\n\nstatic inline int inet_csk_reqsk_queue_len(const struct sock *sk)\n{\n\treturn reqsk_queue_len(&inet_csk(sk)->icsk_accept_queue);\n}\n\nstatic inline int inet_csk_reqsk_queue_is_full(const struct sock *sk)\n{\n\treturn inet_csk_reqsk_queue_len(sk) >= sk->sk_max_ack_backlog;\n}\n\nbool inet_csk_reqsk_queue_drop(struct sock *sk, struct request_sock *req);\nvoid inet_csk_reqsk_queue_drop_and_put(struct sock *sk, struct request_sock *req);\n\nstatic inline unsigned long\nreqsk_timeout(struct request_sock *req, unsigned long max_timeout)\n{\n\tu64 timeout = (u64)req->timeout << req->num_timeout;\n\n\treturn (unsigned long)min_t(u64, timeout, max_timeout);\n}\n\nstatic inline void inet_csk_prepare_for_destroy_sock(struct sock *sk)\n{\n\t \n\tsock_set_flag(sk, SOCK_DEAD);\n\tthis_cpu_inc(*sk->sk_prot->orphan_count);\n}\n\nvoid inet_csk_destroy_sock(struct sock *sk);\nvoid inet_csk_prepare_forced_close(struct sock *sk);\n\n \nstatic inline __poll_t inet_csk_listen_poll(const struct sock *sk)\n{\n\treturn !reqsk_queue_empty(&inet_csk(sk)->icsk_accept_queue) ?\n\t\t\t(EPOLLIN | EPOLLRDNORM) : 0;\n}\n\nint inet_csk_listen_start(struct sock *sk);\nvoid inet_csk_listen_stop(struct sock *sk);\n\nvoid inet_csk_addr2sockaddr(struct sock *sk, struct sockaddr *uaddr);\n\n \nvoid inet_csk_update_fastreuse(struct inet_bind_bucket *tb,\n\t\t\t       struct sock *sk);\n\nstruct dst_entry *inet_csk_update_pmtu(struct sock *sk, u32 mtu);\n\n#define TCP_PINGPONG_THRESH\t1\n\nstatic inline void inet_csk_enter_pingpong_mode(struct sock *sk)\n{\n\tinet_csk(sk)->icsk_ack.pingpong = TCP_PINGPONG_THRESH;\n}\n\nstatic inline void inet_csk_exit_pingpong_mode(struct sock *sk)\n{\n\tinet_csk(sk)->icsk_ack.pingpong = 0;\n}\n\nstatic inline bool inet_csk_in_pingpong_mode(struct sock *sk)\n{\n\treturn inet_csk(sk)->icsk_ack.pingpong >= TCP_PINGPONG_THRESH;\n}\n\nstatic inline bool inet_csk_has_ulp(const struct sock *sk)\n{\n\treturn inet_test_bit(IS_ICSK, sk) && !!inet_csk(sk)->icsk_ulp_ops;\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}