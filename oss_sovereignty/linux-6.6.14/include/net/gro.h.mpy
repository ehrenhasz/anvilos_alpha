{
  "module_name": "gro.h",
  "hash_id": "465e28347294706fa2a6a08a83aa187656aa99bd0bf49830708eecd21b2a4ba1",
  "original_prompt": "Ingested from linux-6.6.14/include/net/gro.h",
  "human_readable_source": " \n\n#ifndef _NET_IPV6_GRO_H\n#define _NET_IPV6_GRO_H\n\n#include <linux/indirect_call_wrapper.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <net/ip6_checksum.h>\n#include <linux/skbuff.h>\n#include <net/udp.h>\n\nstruct napi_gro_cb {\n\tunion {\n\t\tstruct {\n\t\t\t \n\t\t\tvoid\t*frag0;\n\n\t\t\t \n\t\t\tunsigned int frag0_len;\n\t\t};\n\n\t\tstruct {\n\t\t\t \n\t\t\tstruct sk_buff *last;\n\n\t\t\t \n\t\t\tunsigned long age;\n\t\t};\n\t};\n\n\t \n\tint\tdata_offset;\n\n\t \n\tu16\tflush;\n\n\t \n\tu16\tflush_id;\n\n\t \n\tu16\tcount;\n\n\t \n\tu16\tproto;\n\n \n#define NAPI_GRO_FREE             1\n#define NAPI_GRO_FREE_STOLEN_HEAD 2\n\t \n\tstruct_group(zeroed,\n\n\t\t \n\t\tu16\tgro_remcsum_start;\n\n\t\t \n\t\tu8\tsame_flow:1;\n\n\t\t \n\t\tu8\tencap_mark:1;\n\n\t\t \n\t\tu8\tcsum_valid:1;\n\n\t\t \n\t\tu8\tcsum_cnt:3;\n\n\t\t \n\t\tu8\tfree:2;\n\n\t\t \n\t\tu8\tis_ipv6:1;\n\n\t\t \n\t\tu8\tis_fou:1;\n\n\t\t \n\t\tu8\tis_atomic:1;\n\n\t\t \n\t\tu8 recursion_counter:4;\n\n\t\t \n\t\tu8\tis_flist:1;\n\t);\n\n\t \n\t__wsum\tcsum;\n};\n\n#define NAPI_GRO_CB(skb) ((struct napi_gro_cb *)(skb)->cb)\n\n#define GRO_RECURSION_LIMIT 15\nstatic inline int gro_recursion_inc_test(struct sk_buff *skb)\n{\n\treturn ++NAPI_GRO_CB(skb)->recursion_counter == GRO_RECURSION_LIMIT;\n}\n\ntypedef struct sk_buff *(*gro_receive_t)(struct list_head *, struct sk_buff *);\nstatic inline struct sk_buff *call_gro_receive(gro_receive_t cb,\n\t\t\t\t\t       struct list_head *head,\n\t\t\t\t\t       struct sk_buff *skb)\n{\n\tif (unlikely(gro_recursion_inc_test(skb))) {\n\t\tNAPI_GRO_CB(skb)->flush |= 1;\n\t\treturn NULL;\n\t}\n\n\treturn cb(head, skb);\n}\n\ntypedef struct sk_buff *(*gro_receive_sk_t)(struct sock *, struct list_head *,\n\t\t\t\t\t    struct sk_buff *);\nstatic inline struct sk_buff *call_gro_receive_sk(gro_receive_sk_t cb,\n\t\t\t\t\t\t  struct sock *sk,\n\t\t\t\t\t\t  struct list_head *head,\n\t\t\t\t\t\t  struct sk_buff *skb)\n{\n\tif (unlikely(gro_recursion_inc_test(skb))) {\n\t\tNAPI_GRO_CB(skb)->flush |= 1;\n\t\treturn NULL;\n\t}\n\n\treturn cb(sk, head, skb);\n}\n\nstatic inline unsigned int skb_gro_offset(const struct sk_buff *skb)\n{\n\treturn NAPI_GRO_CB(skb)->data_offset;\n}\n\nstatic inline unsigned int skb_gro_len(const struct sk_buff *skb)\n{\n\treturn skb->len - NAPI_GRO_CB(skb)->data_offset;\n}\n\nstatic inline void skb_gro_pull(struct sk_buff *skb, unsigned int len)\n{\n\tNAPI_GRO_CB(skb)->data_offset += len;\n}\n\nstatic inline void *skb_gro_header_fast(struct sk_buff *skb,\n\t\t\t\t\tunsigned int offset)\n{\n\treturn NAPI_GRO_CB(skb)->frag0 + offset;\n}\n\nstatic inline int skb_gro_header_hard(struct sk_buff *skb, unsigned int hlen)\n{\n\treturn NAPI_GRO_CB(skb)->frag0_len < hlen;\n}\n\nstatic inline void skb_gro_frag0_invalidate(struct sk_buff *skb)\n{\n\tNAPI_GRO_CB(skb)->frag0 = NULL;\n\tNAPI_GRO_CB(skb)->frag0_len = 0;\n}\n\nstatic inline void *skb_gro_header_slow(struct sk_buff *skb, unsigned int hlen,\n\t\t\t\t\tunsigned int offset)\n{\n\tif (!pskb_may_pull(skb, hlen))\n\t\treturn NULL;\n\n\tskb_gro_frag0_invalidate(skb);\n\treturn skb->data + offset;\n}\n\nstatic inline void *skb_gro_header(struct sk_buff *skb,\n\t\t\t\t\tunsigned int hlen, unsigned int offset)\n{\n\tvoid *ptr;\n\n\tptr = skb_gro_header_fast(skb, offset);\n\tif (skb_gro_header_hard(skb, hlen))\n\t\tptr = skb_gro_header_slow(skb, hlen, offset);\n\treturn ptr;\n}\n\nstatic inline void *skb_gro_network_header(struct sk_buff *skb)\n{\n\treturn (NAPI_GRO_CB(skb)->frag0 ?: skb->data) +\n\t       skb_network_offset(skb);\n}\n\nstatic inline __wsum inet_gro_compute_pseudo(struct sk_buff *skb, int proto)\n{\n\tconst struct iphdr *iph = skb_gro_network_header(skb);\n\n\treturn csum_tcpudp_nofold(iph->saddr, iph->daddr,\n\t\t\t\t  skb_gro_len(skb), proto, 0);\n}\n\nstatic inline void skb_gro_postpull_rcsum(struct sk_buff *skb,\n\t\t\t\t\tconst void *start, unsigned int len)\n{\n\tif (NAPI_GRO_CB(skb)->csum_valid)\n\t\tNAPI_GRO_CB(skb)->csum = wsum_negate(csum_partial(start, len,\n\t\t\t\t\t\twsum_negate(NAPI_GRO_CB(skb)->csum)));\n}\n\n \n\n__sum16 __skb_gro_checksum_complete(struct sk_buff *skb);\n\nstatic inline bool skb_at_gro_remcsum_start(struct sk_buff *skb)\n{\n\treturn (NAPI_GRO_CB(skb)->gro_remcsum_start == skb_gro_offset(skb));\n}\n\nstatic inline bool __skb_gro_checksum_validate_needed(struct sk_buff *skb,\n\t\t\t\t\t\t      bool zero_okay,\n\t\t\t\t\t\t      __sum16 check)\n{\n\treturn ((skb->ip_summed != CHECKSUM_PARTIAL ||\n\t\tskb_checksum_start_offset(skb) <\n\t\t skb_gro_offset(skb)) &&\n\t\t!skb_at_gro_remcsum_start(skb) &&\n\t\tNAPI_GRO_CB(skb)->csum_cnt == 0 &&\n\t\t(!zero_okay || check));\n}\n\nstatic inline __sum16 __skb_gro_checksum_validate_complete(struct sk_buff *skb,\n\t\t\t\t\t\t\t   __wsum psum)\n{\n\tif (NAPI_GRO_CB(skb)->csum_valid &&\n\t    !csum_fold(csum_add(psum, NAPI_GRO_CB(skb)->csum)))\n\t\treturn 0;\n\n\tNAPI_GRO_CB(skb)->csum = psum;\n\n\treturn __skb_gro_checksum_complete(skb);\n}\n\nstatic inline void skb_gro_incr_csum_unnecessary(struct sk_buff *skb)\n{\n\tif (NAPI_GRO_CB(skb)->csum_cnt > 0) {\n\t\t \n\t\tNAPI_GRO_CB(skb)->csum_cnt--;\n\t} else {\n\t\t \n\t\t__skb_incr_checksum_unnecessary(skb);\n\t}\n}\n\n#define __skb_gro_checksum_validate(skb, proto, zero_okay, check,\t\\\n\t\t\t\t    compute_pseudo)\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\t__sum16 __ret = 0;\t\t\t\t\t\t\\\n\tif (__skb_gro_checksum_validate_needed(skb, zero_okay, check))\t\\\n\t\t__ret = __skb_gro_checksum_validate_complete(skb,\t\\\n\t\t\t\tcompute_pseudo(skb, proto));\t\t\\\n\tif (!__ret)\t\t\t\t\t\t\t\\\n\t\tskb_gro_incr_csum_unnecessary(skb);\t\t\t\\\n\t__ret;\t\t\t\t\t\t\t\t\\\n})\n\n#define skb_gro_checksum_validate(skb, proto, compute_pseudo)\t\t\\\n\t__skb_gro_checksum_validate(skb, proto, false, 0, compute_pseudo)\n\n#define skb_gro_checksum_validate_zero_check(skb, proto, check,\t\t\\\n\t\t\t\t\t     compute_pseudo)\t\t\\\n\t__skb_gro_checksum_validate(skb, proto, true, check, compute_pseudo)\n\n#define skb_gro_checksum_simple_validate(skb)\t\t\t\t\\\n\t__skb_gro_checksum_validate(skb, 0, false, 0, null_compute_pseudo)\n\nstatic inline bool __skb_gro_checksum_convert_check(struct sk_buff *skb)\n{\n\treturn (NAPI_GRO_CB(skb)->csum_cnt == 0 &&\n\t\t!NAPI_GRO_CB(skb)->csum_valid);\n}\n\nstatic inline void __skb_gro_checksum_convert(struct sk_buff *skb,\n\t\t\t\t\t      __wsum pseudo)\n{\n\tNAPI_GRO_CB(skb)->csum = ~pseudo;\n\tNAPI_GRO_CB(skb)->csum_valid = 1;\n}\n\n#define skb_gro_checksum_try_convert(skb, proto, compute_pseudo)\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (__skb_gro_checksum_convert_check(skb))\t\t\t\\\n\t\t__skb_gro_checksum_convert(skb, \t\t\t\\\n\t\t\t\t\t   compute_pseudo(skb, proto));\t\\\n} while (0)\n\nstruct gro_remcsum {\n\tint offset;\n\t__wsum delta;\n};\n\nstatic inline void skb_gro_remcsum_init(struct gro_remcsum *grc)\n{\n\tgrc->offset = 0;\n\tgrc->delta = 0;\n}\n\nstatic inline void *skb_gro_remcsum_process(struct sk_buff *skb, void *ptr,\n\t\t\t\t\t    unsigned int off, size_t hdrlen,\n\t\t\t\t\t    int start, int offset,\n\t\t\t\t\t    struct gro_remcsum *grc,\n\t\t\t\t\t    bool nopartial)\n{\n\t__wsum delta;\n\tsize_t plen = hdrlen + max_t(size_t, offset + sizeof(u16), start);\n\n\tBUG_ON(!NAPI_GRO_CB(skb)->csum_valid);\n\n\tif (!nopartial) {\n\t\tNAPI_GRO_CB(skb)->gro_remcsum_start = off + hdrlen + start;\n\t\treturn ptr;\n\t}\n\n\tptr = skb_gro_header(skb, off + plen, off);\n\tif (!ptr)\n\t\treturn NULL;\n\n\tdelta = remcsum_adjust(ptr + hdrlen, NAPI_GRO_CB(skb)->csum,\n\t\t\t       start, offset);\n\n\t \n\tNAPI_GRO_CB(skb)->csum = csum_add(NAPI_GRO_CB(skb)->csum, delta);\n\n\tgrc->offset = off + hdrlen + offset;\n\tgrc->delta = delta;\n\n\treturn ptr;\n}\n\nstatic inline void skb_gro_remcsum_cleanup(struct sk_buff *skb,\n\t\t\t\t\t   struct gro_remcsum *grc)\n{\n\tvoid *ptr;\n\tsize_t plen = grc->offset + sizeof(u16);\n\n\tif (!grc->delta)\n\t\treturn;\n\n\tptr = skb_gro_header(skb, plen, grc->offset);\n\tif (!ptr)\n\t\treturn;\n\n\tremcsum_unadjust((__sum16 *)ptr, grc->delta);\n}\n\n#ifdef CONFIG_XFRM_OFFLOAD\nstatic inline void skb_gro_flush_final(struct sk_buff *skb, struct sk_buff *pp, int flush)\n{\n\tif (PTR_ERR(pp) != -EINPROGRESS)\n\t\tNAPI_GRO_CB(skb)->flush |= flush;\n}\nstatic inline void skb_gro_flush_final_remcsum(struct sk_buff *skb,\n\t\t\t\t\t       struct sk_buff *pp,\n\t\t\t\t\t       int flush,\n\t\t\t\t\t       struct gro_remcsum *grc)\n{\n\tif (PTR_ERR(pp) != -EINPROGRESS) {\n\t\tNAPI_GRO_CB(skb)->flush |= flush;\n\t\tskb_gro_remcsum_cleanup(skb, grc);\n\t\tskb->remcsum_offload = 0;\n\t}\n}\n#else\nstatic inline void skb_gro_flush_final(struct sk_buff *skb, struct sk_buff *pp, int flush)\n{\n\tNAPI_GRO_CB(skb)->flush |= flush;\n}\nstatic inline void skb_gro_flush_final_remcsum(struct sk_buff *skb,\n\t\t\t\t\t       struct sk_buff *pp,\n\t\t\t\t\t       int flush,\n\t\t\t\t\t       struct gro_remcsum *grc)\n{\n\tNAPI_GRO_CB(skb)->flush |= flush;\n\tskb_gro_remcsum_cleanup(skb, grc);\n\tskb->remcsum_offload = 0;\n}\n#endif\n\nINDIRECT_CALLABLE_DECLARE(struct sk_buff *ipv6_gro_receive(struct list_head *,\n\t\t\t\t\t\t\t   struct sk_buff *));\nINDIRECT_CALLABLE_DECLARE(int ipv6_gro_complete(struct sk_buff *, int));\nINDIRECT_CALLABLE_DECLARE(struct sk_buff *inet_gro_receive(struct list_head *,\n\t\t\t\t\t\t\t   struct sk_buff *));\nINDIRECT_CALLABLE_DECLARE(int inet_gro_complete(struct sk_buff *, int));\n\nINDIRECT_CALLABLE_DECLARE(struct sk_buff *udp4_gro_receive(struct list_head *,\n\t\t\t\t\t\t\t   struct sk_buff *));\nINDIRECT_CALLABLE_DECLARE(int udp4_gro_complete(struct sk_buff *, int));\n\nINDIRECT_CALLABLE_DECLARE(struct sk_buff *udp6_gro_receive(struct list_head *,\n\t\t\t\t\t\t\t   struct sk_buff *));\nINDIRECT_CALLABLE_DECLARE(int udp6_gro_complete(struct sk_buff *, int));\n\n#define indirect_call_gro_receive_inet(cb, f2, f1, head, skb)\t\\\n({\t\t\t\t\t\t\t\t\\\n\tunlikely(gro_recursion_inc_test(skb)) ?\t\t\t\\\n\t\tNAPI_GRO_CB(skb)->flush |= 1, NULL :\t\t\\\n\t\tINDIRECT_CALL_INET(cb, f2, f1, head, skb);\t\\\n})\n\nstruct sk_buff *udp_gro_receive(struct list_head *head, struct sk_buff *skb,\n\t\t\t\tstruct udphdr *uh, struct sock *sk);\nint udp_gro_complete(struct sk_buff *skb, int nhoff, udp_lookup_t lookup);\n\nstatic inline struct udphdr *udp_gro_udphdr(struct sk_buff *skb)\n{\n\tstruct udphdr *uh;\n\tunsigned int hlen, off;\n\n\toff  = skb_gro_offset(skb);\n\thlen = off + sizeof(*uh);\n\tuh   = skb_gro_header(skb, hlen, off);\n\n\treturn uh;\n}\n\nstatic inline __wsum ip6_gro_compute_pseudo(struct sk_buff *skb, int proto)\n{\n\tconst struct ipv6hdr *iph = skb_gro_network_header(skb);\n\n\treturn ~csum_unfold(csum_ipv6_magic(&iph->saddr, &iph->daddr,\n\t\t\t\t\t    skb_gro_len(skb), proto, 0));\n}\n\nint skb_gro_receive(struct sk_buff *p, struct sk_buff *skb);\n\n \nstatic inline void gro_normal_list(struct napi_struct *napi)\n{\n\tif (!napi->rx_count)\n\t\treturn;\n\tnetif_receive_skb_list_internal(&napi->rx_list);\n\tINIT_LIST_HEAD(&napi->rx_list);\n\tnapi->rx_count = 0;\n}\n\n \nstatic inline void gro_normal_one(struct napi_struct *napi, struct sk_buff *skb, int segs)\n{\n\tlist_add_tail(&skb->list, &napi->rx_list);\n\tnapi->rx_count += segs;\n\tif (napi->rx_count >= READ_ONCE(gro_normal_batch))\n\t\tgro_normal_list(napi);\n}\n\n \nstatic inline void inet_get_iif_sdif(const struct sk_buff *skb, int *iif, int *sdif)\n{\n\t*iif = inet_iif(skb) ?: skb->dev->ifindex;\n\t*sdif = 0;\n\n#if IS_ENABLED(CONFIG_NET_L3_MASTER_DEV)\n\tif (netif_is_l3_slave(skb->dev)) {\n\t\tstruct net_device *master = netdev_master_upper_dev_get_rcu(skb->dev);\n\n\t\t*sdif = *iif;\n\t\t*iif = master ? master->ifindex : 0;\n\t}\n#endif\n}\n\n \nstatic inline void inet6_get_iif_sdif(const struct sk_buff *skb, int *iif, int *sdif)\n{\n\t \n\t*iif = skb->dev->ifindex;\n\t*sdif = 0;\n\n#if IS_ENABLED(CONFIG_NET_L3_MASTER_DEV)\n\tif (netif_is_l3_slave(skb->dev)) {\n\t\tstruct net_device *master = netdev_master_upper_dev_get_rcu(skb->dev);\n\n\t\t*sdif = *iif;\n\t\t*iif = master ? master->ifindex : 0;\n\t}\n#endif\n}\n\nextern struct list_head offload_base;\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}