{
  "module_name": "pkt_cls.h",
  "hash_id": "31adb40be0529bab03606cf7f8e4121f1f6ff9df00963ccac2bd3a5fb88d3d38",
  "original_prompt": "Ingested from linux-6.6.14/include/net/pkt_cls.h",
  "human_readable_source": " \n#ifndef __NET_PKT_CLS_H\n#define __NET_PKT_CLS_H\n\n#include <linux/pkt_cls.h>\n#include <linux/workqueue.h>\n#include <net/sch_generic.h>\n#include <net/act_api.h>\n#include <net/net_namespace.h>\n\n \n#define TC_ACT_CONSUMED\t\t(TC_ACT_VALUE_MAX + 1)\n\n \n\nstruct tcf_walker {\n\tint\tstop;\n\tint\tskip;\n\tint\tcount;\n\tbool\tnonempty;\n\tunsigned long cookie;\n\tint\t(*fn)(struct tcf_proto *, void *node, struct tcf_walker *);\n};\n\nint register_tcf_proto_ops(struct tcf_proto_ops *ops);\nvoid unregister_tcf_proto_ops(struct tcf_proto_ops *ops);\n\nstruct tcf_block_ext_info {\n\tenum flow_block_binder_type binder_type;\n\ttcf_chain_head_change_t *chain_head_change;\n\tvoid *chain_head_change_priv;\n\tu32 block_index;\n};\n\nstruct tcf_qevent {\n\tstruct tcf_block\t*block;\n\tstruct tcf_block_ext_info info;\n\tstruct tcf_proto __rcu *filter_chain;\n};\n\nstruct tcf_block_cb;\nbool tcf_queue_work(struct rcu_work *rwork, work_func_t func);\n\n#ifdef CONFIG_NET_CLS\nstruct tcf_chain *tcf_chain_get_by_act(struct tcf_block *block,\n\t\t\t\t       u32 chain_index);\nvoid tcf_chain_put_by_act(struct tcf_chain *chain);\nstruct tcf_chain *tcf_get_next_chain(struct tcf_block *block,\n\t\t\t\t     struct tcf_chain *chain);\nstruct tcf_proto *tcf_get_next_proto(struct tcf_chain *chain,\n\t\t\t\t     struct tcf_proto *tp);\nvoid tcf_block_netif_keep_dst(struct tcf_block *block);\nint tcf_block_get(struct tcf_block **p_block,\n\t\t  struct tcf_proto __rcu **p_filter_chain, struct Qdisc *q,\n\t\t  struct netlink_ext_ack *extack);\nint tcf_block_get_ext(struct tcf_block **p_block, struct Qdisc *q,\n\t\t      struct tcf_block_ext_info *ei,\n\t\t      struct netlink_ext_ack *extack);\nvoid tcf_block_put(struct tcf_block *block);\nvoid tcf_block_put_ext(struct tcf_block *block, struct Qdisc *q,\n\t\t       struct tcf_block_ext_info *ei);\nint tcf_exts_init_ex(struct tcf_exts *exts, struct net *net, int action,\n\t\t     int police, struct tcf_proto *tp, u32 handle, bool used_action_miss);\n\nstatic inline bool tcf_block_shared(struct tcf_block *block)\n{\n\treturn block->index;\n}\n\nstatic inline bool tcf_block_non_null_shared(struct tcf_block *block)\n{\n\treturn block && block->index;\n}\n\nstatic inline struct Qdisc *tcf_block_q(struct tcf_block *block)\n{\n\tWARN_ON(tcf_block_shared(block));\n\treturn block->q;\n}\n\nint tcf_classify(struct sk_buff *skb,\n\t\t const struct tcf_block *block,\n\t\t const struct tcf_proto *tp, struct tcf_result *res,\n\t\t bool compat_mode);\n\nstatic inline bool tc_cls_stats_dump(struct tcf_proto *tp,\n\t\t\t\t     struct tcf_walker *arg,\n\t\t\t\t     void *filter)\n{\n\tif (arg->count >= arg->skip && arg->fn(tp, filter, arg) < 0) {\n\t\targ->stop = 1;\n\t\treturn false;\n\t}\n\n\targ->count++;\n\treturn true;\n}\n\n#else\nstatic inline bool tcf_block_shared(struct tcf_block *block)\n{\n\treturn false;\n}\n\nstatic inline bool tcf_block_non_null_shared(struct tcf_block *block)\n{\n\treturn false;\n}\n\nstatic inline\nint tcf_block_get(struct tcf_block **p_block,\n\t\t  struct tcf_proto __rcu **p_filter_chain, struct Qdisc *q,\n\t\t  struct netlink_ext_ack *extack)\n{\n\treturn 0;\n}\n\nstatic inline\nint tcf_block_get_ext(struct tcf_block **p_block, struct Qdisc *q,\n\t\t      struct tcf_block_ext_info *ei,\n\t\t      struct netlink_ext_ack *extack)\n{\n\treturn 0;\n}\n\nstatic inline void tcf_block_put(struct tcf_block *block)\n{\n}\n\nstatic inline\nvoid tcf_block_put_ext(struct tcf_block *block, struct Qdisc *q,\n\t\t       struct tcf_block_ext_info *ei)\n{\n}\n\nstatic inline struct Qdisc *tcf_block_q(struct tcf_block *block)\n{\n\treturn NULL;\n}\n\nstatic inline int tcf_classify(struct sk_buff *skb,\n\t\t\t       const struct tcf_block *block,\n\t\t\t       const struct tcf_proto *tp,\n\t\t\t       struct tcf_result *res, bool compat_mode)\n{\n\treturn TC_ACT_UNSPEC;\n}\n\n#endif\n\nstatic inline unsigned long\n__cls_set_class(unsigned long *clp, unsigned long cl)\n{\n\treturn xchg(clp, cl);\n}\n\nstatic inline void\n__tcf_bind_filter(struct Qdisc *q, struct tcf_result *r, unsigned long base)\n{\n\tunsigned long cl;\n\n\tcl = q->ops->cl_ops->bind_tcf(q, base, r->classid);\n\tcl = __cls_set_class(&r->class, cl);\n\tif (cl)\n\t\tq->ops->cl_ops->unbind_tcf(q, cl);\n}\n\nstatic inline void\ntcf_bind_filter(struct tcf_proto *tp, struct tcf_result *r, unsigned long base)\n{\n\tstruct Qdisc *q = tp->chain->block->q;\n\n\t \n\tif (!q)\n\t\treturn;\n\tsch_tree_lock(q);\n\t__tcf_bind_filter(q, r, base);\n\tsch_tree_unlock(q);\n}\n\nstatic inline void\n__tcf_unbind_filter(struct Qdisc *q, struct tcf_result *r)\n{\n\tunsigned long cl;\n\n\tif ((cl = __cls_set_class(&r->class, 0)) != 0)\n\t\tq->ops->cl_ops->unbind_tcf(q, cl);\n}\n\nstatic inline void\ntcf_unbind_filter(struct tcf_proto *tp, struct tcf_result *r)\n{\n\tstruct Qdisc *q = tp->chain->block->q;\n\n\tif (!q)\n\t\treturn;\n\t__tcf_unbind_filter(q, r);\n}\n\nstatic inline void tc_cls_bind_class(u32 classid, unsigned long cl,\n\t\t\t\t     void *q, struct tcf_result *res,\n\t\t\t\t     unsigned long base)\n{\n\tif (res->classid == classid) {\n\t\tif (cl)\n\t\t\t__tcf_bind_filter(q, res, base);\n\t\telse\n\t\t\t__tcf_unbind_filter(q, res);\n\t}\n}\n\nstruct tcf_exts {\n#ifdef CONFIG_NET_CLS_ACT\n\t__u32\ttype;  \n\tint nr_actions;\n\tstruct tc_action **actions;\n\tstruct net\t*net;\n\tnetns_tracker\tns_tracker;\n\tstruct tcf_exts_miss_cookie_node *miss_cookie_node;\n#endif\n\t \n\tint action;\n\tint police;\n};\n\nstatic inline int tcf_exts_init(struct tcf_exts *exts, struct net *net,\n\t\t\t\tint action, int police)\n{\n#ifdef CONFIG_NET_CLS\n\treturn tcf_exts_init_ex(exts, net, action, police, NULL, 0, false);\n#else\n\treturn -EOPNOTSUPP;\n#endif\n}\n\n \nstatic inline bool tcf_exts_get_net(struct tcf_exts *exts)\n{\n#ifdef CONFIG_NET_CLS_ACT\n\texts->net = maybe_get_net(exts->net);\n\tif (exts->net)\n\t\tnetns_tracker_alloc(exts->net, &exts->ns_tracker, GFP_KERNEL);\n\treturn exts->net != NULL;\n#else\n\treturn true;\n#endif\n}\n\nstatic inline void tcf_exts_put_net(struct tcf_exts *exts)\n{\n#ifdef CONFIG_NET_CLS_ACT\n\tif (exts->net)\n\t\tput_net_track(exts->net, &exts->ns_tracker);\n#endif\n}\n\n#ifdef CONFIG_NET_CLS_ACT\n#define tcf_exts_for_each_action(i, a, exts) \\\n\tfor (i = 0; i < TCA_ACT_MAX_PRIO && ((a) = (exts)->actions[i]); i++)\n#else\n#define tcf_exts_for_each_action(i, a, exts) \\\n\tfor (; 0; (void)(i), (void)(a), (void)(exts))\n#endif\n\n#define tcf_act_for_each_action(i, a, actions) \\\n\tfor (i = 0; i < TCA_ACT_MAX_PRIO && ((a) = actions[i]); i++)\n\nstatic inline bool tc_act_in_hw(struct tc_action *act)\n{\n\treturn !!act->in_hw_count;\n}\n\nstatic inline void\ntcf_exts_hw_stats_update(const struct tcf_exts *exts,\n\t\t\t struct flow_stats *stats,\n\t\t\t bool use_act_stats)\n{\n#ifdef CONFIG_NET_CLS_ACT\n\tint i;\n\n\tfor (i = 0; i < exts->nr_actions; i++) {\n\t\tstruct tc_action *a = exts->actions[i];\n\n\t\tif (use_act_stats || tc_act_in_hw(a)) {\n\t\t\tif (!tcf_action_update_hw_stats(a))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tpreempt_disable();\n\t\ttcf_action_stats_update(a, stats->bytes, stats->pkts, stats->drops,\n\t\t\t\t\tstats->lastused, true);\n\t\tpreempt_enable();\n\n\t\ta->used_hw_stats = stats->used_hw_stats;\n\t\ta->used_hw_stats_valid = stats->used_hw_stats_valid;\n\t}\n#endif\n}\n\n \nstatic inline bool tcf_exts_has_actions(struct tcf_exts *exts)\n{\n#ifdef CONFIG_NET_CLS_ACT\n\treturn exts->nr_actions;\n#else\n\treturn false;\n#endif\n}\n\n \nstatic inline int\ntcf_exts_exec(struct sk_buff *skb, struct tcf_exts *exts,\n\t      struct tcf_result *res)\n{\n#ifdef CONFIG_NET_CLS_ACT\n\treturn tcf_action_exec(skb, exts->actions, exts->nr_actions, res);\n#endif\n\treturn TC_ACT_OK;\n}\n\nstatic inline int\ntcf_exts_exec_ex(struct sk_buff *skb, struct tcf_exts *exts, int act_index,\n\t\t struct tcf_result *res)\n{\n#ifdef CONFIG_NET_CLS_ACT\n\treturn tcf_action_exec(skb, exts->actions + act_index,\n\t\t\t       exts->nr_actions - act_index, res);\n#else\n\treturn TC_ACT_OK;\n#endif\n}\n\nint tcf_exts_validate(struct net *net, struct tcf_proto *tp,\n\t\t      struct nlattr **tb, struct nlattr *rate_tlv,\n\t\t      struct tcf_exts *exts, u32 flags,\n\t\t      struct netlink_ext_ack *extack);\nint tcf_exts_validate_ex(struct net *net, struct tcf_proto *tp, struct nlattr **tb,\n\t\t\t struct nlattr *rate_tlv, struct tcf_exts *exts,\n\t\t\t u32 flags, u32 fl_flags, struct netlink_ext_ack *extack);\nvoid tcf_exts_destroy(struct tcf_exts *exts);\nvoid tcf_exts_change(struct tcf_exts *dst, struct tcf_exts *src);\nint tcf_exts_dump(struct sk_buff *skb, struct tcf_exts *exts);\nint tcf_exts_terse_dump(struct sk_buff *skb, struct tcf_exts *exts);\nint tcf_exts_dump_stats(struct sk_buff *skb, struct tcf_exts *exts);\n\n \nstruct tcf_pkt_info {\n\tunsigned char *\t\tptr;\n\tint\t\t\tnexthdr;\n};\n\n#ifdef CONFIG_NET_EMATCH\n\nstruct tcf_ematch_ops;\n\n \nstruct tcf_ematch {\n\tstruct tcf_ematch_ops * ops;\n\tunsigned long\t\tdata;\n\tunsigned int\t\tdatalen;\n\tu16\t\t\tmatchid;\n\tu16\t\t\tflags;\n\tstruct net\t\t*net;\n};\n\nstatic inline int tcf_em_is_container(struct tcf_ematch *em)\n{\n\treturn !em->ops;\n}\n\nstatic inline int tcf_em_is_simple(struct tcf_ematch *em)\n{\n\treturn em->flags & TCF_EM_SIMPLE;\n}\n\nstatic inline int tcf_em_is_inverted(struct tcf_ematch *em)\n{\n\treturn em->flags & TCF_EM_INVERT;\n}\n\nstatic inline int tcf_em_last_match(struct tcf_ematch *em)\n{\n\treturn (em->flags & TCF_EM_REL_MASK) == TCF_EM_REL_END;\n}\n\nstatic inline int tcf_em_early_end(struct tcf_ematch *em, int result)\n{\n\tif (tcf_em_last_match(em))\n\t\treturn 1;\n\n\tif (result == 0 && em->flags & TCF_EM_REL_AND)\n\t\treturn 1;\n\n\tif (result != 0 && em->flags & TCF_EM_REL_OR)\n\t\treturn 1;\n\n\treturn 0;\n}\n\t\n \nstruct tcf_ematch_tree {\n\tstruct tcf_ematch_tree_hdr hdr;\n\tstruct tcf_ematch *\tmatches;\n\t\n};\n\n \nstruct tcf_ematch_ops {\n\tint\t\t\tkind;\n\tint\t\t\tdatalen;\n\tint\t\t\t(*change)(struct net *net, void *,\n\t\t\t\t\t  int, struct tcf_ematch *);\n\tint\t\t\t(*match)(struct sk_buff *, struct tcf_ematch *,\n\t\t\t\t\t struct tcf_pkt_info *);\n\tvoid\t\t\t(*destroy)(struct tcf_ematch *);\n\tint\t\t\t(*dump)(struct sk_buff *, struct tcf_ematch *);\n\tstruct module\t\t*owner;\n\tstruct list_head\tlink;\n};\n\nint tcf_em_register(struct tcf_ematch_ops *);\nvoid tcf_em_unregister(struct tcf_ematch_ops *);\nint tcf_em_tree_validate(struct tcf_proto *, struct nlattr *,\n\t\t\t struct tcf_ematch_tree *);\nvoid tcf_em_tree_destroy(struct tcf_ematch_tree *);\nint tcf_em_tree_dump(struct sk_buff *, struct tcf_ematch_tree *, int);\nint __tcf_em_tree_match(struct sk_buff *, struct tcf_ematch_tree *,\n\t\t\tstruct tcf_pkt_info *);\n\n \nstatic inline int tcf_em_tree_match(struct sk_buff *skb,\n\t\t\t\t    struct tcf_ematch_tree *tree,\n\t\t\t\t    struct tcf_pkt_info *info)\n{\n\tif (tree->hdr.nmatches)\n\t\treturn __tcf_em_tree_match(skb, tree, info);\n\telse\n\t\treturn 1;\n}\n\n#define MODULE_ALIAS_TCF_EMATCH(kind)\tMODULE_ALIAS(\"ematch-kind-\" __stringify(kind))\n\n#else  \n\nstruct tcf_ematch_tree {\n};\n\n#define tcf_em_tree_validate(tp, tb, t) ((void)(t), 0)\n#define tcf_em_tree_destroy(t) do { (void)(t); } while(0)\n#define tcf_em_tree_dump(skb, t, tlv) (0)\n#define tcf_em_tree_match(skb, t, info) ((void)(info), 1)\n\n#endif  \n\nstatic inline unsigned char * tcf_get_base_ptr(struct sk_buff *skb, int layer)\n{\n\tswitch (layer) {\n\t\tcase TCF_LAYER_LINK:\n\t\t\treturn skb_mac_header(skb);\n\t\tcase TCF_LAYER_NETWORK:\n\t\t\treturn skb_network_header(skb);\n\t\tcase TCF_LAYER_TRANSPORT:\n\t\t\treturn skb_transport_header(skb);\n\t}\n\n\treturn NULL;\n}\n\nstatic inline int tcf_valid_offset(const struct sk_buff *skb,\n\t\t\t\t   const unsigned char *ptr, const int len)\n{\n\treturn likely((ptr + len) <= skb_tail_pointer(skb) &&\n\t\t      ptr >= skb->head &&\n\t\t      (ptr <= (ptr + len)));\n}\n\nstatic inline int\ntcf_change_indev(struct net *net, struct nlattr *indev_tlv,\n\t\t struct netlink_ext_ack *extack)\n{\n\tchar indev[IFNAMSIZ];\n\tstruct net_device *dev;\n\n\tif (nla_strscpy(indev, indev_tlv, IFNAMSIZ) < 0) {\n\t\tNL_SET_ERR_MSG_ATTR(extack, indev_tlv,\n\t\t\t\t    \"Interface name too long\");\n\t\treturn -EINVAL;\n\t}\n\tdev = __dev_get_by_name(net, indev);\n\tif (!dev) {\n\t\tNL_SET_ERR_MSG_ATTR(extack, indev_tlv,\n\t\t\t\t    \"Network device not found\");\n\t\treturn -ENODEV;\n\t}\n\treturn dev->ifindex;\n}\n\nstatic inline bool\ntcf_match_indev(struct sk_buff *skb, int ifindex)\n{\n\tif (!ifindex)\n\t\treturn true;\n\tif  (!skb->skb_iif)\n\t\treturn false;\n\treturn ifindex == skb->skb_iif;\n}\n\nint tc_setup_offload_action(struct flow_action *flow_action,\n\t\t\t    const struct tcf_exts *exts,\n\t\t\t    struct netlink_ext_ack *extack);\nvoid tc_cleanup_offload_action(struct flow_action *flow_action);\nint tc_setup_action(struct flow_action *flow_action,\n\t\t    struct tc_action *actions[],\n\t\t    u32 miss_cookie_base,\n\t\t    struct netlink_ext_ack *extack);\n\nint tc_setup_cb_call(struct tcf_block *block, enum tc_setup_type type,\n\t\t     void *type_data, bool err_stop, bool rtnl_held);\nint tc_setup_cb_add(struct tcf_block *block, struct tcf_proto *tp,\n\t\t    enum tc_setup_type type, void *type_data, bool err_stop,\n\t\t    u32 *flags, unsigned int *in_hw_count, bool rtnl_held);\nint tc_setup_cb_replace(struct tcf_block *block, struct tcf_proto *tp,\n\t\t\tenum tc_setup_type type, void *type_data, bool err_stop,\n\t\t\tu32 *old_flags, unsigned int *old_in_hw_count,\n\t\t\tu32 *new_flags, unsigned int *new_in_hw_count,\n\t\t\tbool rtnl_held);\nint tc_setup_cb_destroy(struct tcf_block *block, struct tcf_proto *tp,\n\t\t\tenum tc_setup_type type, void *type_data, bool err_stop,\n\t\t\tu32 *flags, unsigned int *in_hw_count, bool rtnl_held);\nint tc_setup_cb_reoffload(struct tcf_block *block, struct tcf_proto *tp,\n\t\t\t  bool add, flow_setup_cb_t *cb,\n\t\t\t  enum tc_setup_type type, void *type_data,\n\t\t\t  void *cb_priv, u32 *flags, unsigned int *in_hw_count);\nunsigned int tcf_exts_num_actions(struct tcf_exts *exts);\n\n#ifdef CONFIG_NET_CLS_ACT\nint tcf_qevent_init(struct tcf_qevent *qe, struct Qdisc *sch,\n\t\t    enum flow_block_binder_type binder_type,\n\t\t    struct nlattr *block_index_attr,\n\t\t    struct netlink_ext_ack *extack);\nvoid tcf_qevent_destroy(struct tcf_qevent *qe, struct Qdisc *sch);\nint tcf_qevent_validate_change(struct tcf_qevent *qe, struct nlattr *block_index_attr,\n\t\t\t       struct netlink_ext_ack *extack);\nstruct sk_buff *tcf_qevent_handle(struct tcf_qevent *qe, struct Qdisc *sch, struct sk_buff *skb,\n\t\t\t\t  struct sk_buff **to_free, int *ret);\nint tcf_qevent_dump(struct sk_buff *skb, int attr_name, struct tcf_qevent *qe);\n#else\nstatic inline int tcf_qevent_init(struct tcf_qevent *qe, struct Qdisc *sch,\n\t\t\t\t  enum flow_block_binder_type binder_type,\n\t\t\t\t  struct nlattr *block_index_attr,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\treturn 0;\n}\n\nstatic inline void tcf_qevent_destroy(struct tcf_qevent *qe, struct Qdisc *sch)\n{\n}\n\nstatic inline int tcf_qevent_validate_change(struct tcf_qevent *qe, struct nlattr *block_index_attr,\n\t\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\treturn 0;\n}\n\nstatic inline struct sk_buff *\ntcf_qevent_handle(struct tcf_qevent *qe, struct Qdisc *sch, struct sk_buff *skb,\n\t\t  struct sk_buff **to_free, int *ret)\n{\n\treturn skb;\n}\n\nstatic inline int tcf_qevent_dump(struct sk_buff *skb, int attr_name, struct tcf_qevent *qe)\n{\n\treturn 0;\n}\n#endif\n\nstruct tc_cls_u32_knode {\n\tstruct tcf_exts *exts;\n\tstruct tcf_result *res;\n\tstruct tc_u32_sel *sel;\n\tu32 handle;\n\tu32 val;\n\tu32 mask;\n\tu32 link_handle;\n\tu8 fshift;\n};\n\nstruct tc_cls_u32_hnode {\n\tu32 handle;\n\tu32 prio;\n\tunsigned int divisor;\n};\n\nenum tc_clsu32_command {\n\tTC_CLSU32_NEW_KNODE,\n\tTC_CLSU32_REPLACE_KNODE,\n\tTC_CLSU32_DELETE_KNODE,\n\tTC_CLSU32_NEW_HNODE,\n\tTC_CLSU32_REPLACE_HNODE,\n\tTC_CLSU32_DELETE_HNODE,\n};\n\nstruct tc_cls_u32_offload {\n\tstruct flow_cls_common_offload common;\n\t \n\tenum tc_clsu32_command command;\n\tunion {\n\t\tstruct tc_cls_u32_knode knode;\n\t\tstruct tc_cls_u32_hnode hnode;\n\t};\n};\n\nstatic inline bool tc_can_offload(const struct net_device *dev)\n{\n\treturn dev->features & NETIF_F_HW_TC;\n}\n\nstatic inline bool tc_can_offload_extack(const struct net_device *dev,\n\t\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tbool can = tc_can_offload(dev);\n\n\tif (!can)\n\t\tNL_SET_ERR_MSG(extack, \"TC offload is disabled on net device\");\n\n\treturn can;\n}\n\nstatic inline bool\ntc_cls_can_offload_and_chain0(const struct net_device *dev,\n\t\t\t      struct flow_cls_common_offload *common)\n{\n\tif (!tc_can_offload_extack(dev, common->extack))\n\t\treturn false;\n\tif (common->chain_index) {\n\t\tNL_SET_ERR_MSG(common->extack,\n\t\t\t       \"Driver supports only offload of chain 0\");\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic inline bool tc_skip_hw(u32 flags)\n{\n\treturn (flags & TCA_CLS_FLAGS_SKIP_HW) ? true : false;\n}\n\nstatic inline bool tc_skip_sw(u32 flags)\n{\n\treturn (flags & TCA_CLS_FLAGS_SKIP_SW) ? true : false;\n}\n\n \nstatic inline bool tc_flags_valid(u32 flags)\n{\n\tif (flags & ~(TCA_CLS_FLAGS_SKIP_HW | TCA_CLS_FLAGS_SKIP_SW |\n\t\t      TCA_CLS_FLAGS_VERBOSE))\n\t\treturn false;\n\n\tflags &= TCA_CLS_FLAGS_SKIP_HW | TCA_CLS_FLAGS_SKIP_SW;\n\tif (!(flags ^ (TCA_CLS_FLAGS_SKIP_HW | TCA_CLS_FLAGS_SKIP_SW)))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic inline bool tc_in_hw(u32 flags)\n{\n\treturn (flags & TCA_CLS_FLAGS_IN_HW) ? true : false;\n}\n\nstatic inline void\ntc_cls_common_offload_init(struct flow_cls_common_offload *cls_common,\n\t\t\t   const struct tcf_proto *tp, u32 flags,\n\t\t\t   struct netlink_ext_ack *extack)\n{\n\tcls_common->chain_index = tp->chain->index;\n\tcls_common->protocol = tp->protocol;\n\tcls_common->prio = tp->prio >> 16;\n\tif (tc_skip_sw(flags) || flags & TCA_CLS_FLAGS_VERBOSE)\n\t\tcls_common->extack = extack;\n}\n\n#if IS_ENABLED(CONFIG_NET_TC_SKB_EXT)\nstatic inline struct tc_skb_ext *tc_skb_ext_alloc(struct sk_buff *skb)\n{\n\tstruct tc_skb_ext *tc_skb_ext = skb_ext_add(skb, TC_SKB_EXT);\n\n\tif (tc_skb_ext)\n\t\tmemset(tc_skb_ext, 0, sizeof(*tc_skb_ext));\n\treturn tc_skb_ext;\n}\n#endif\n\nenum tc_matchall_command {\n\tTC_CLSMATCHALL_REPLACE,\n\tTC_CLSMATCHALL_DESTROY,\n\tTC_CLSMATCHALL_STATS,\n};\n\nstruct tc_cls_matchall_offload {\n\tstruct flow_cls_common_offload common;\n\tenum tc_matchall_command command;\n\tstruct flow_rule *rule;\n\tstruct flow_stats stats;\n\tbool use_act_stats;\n\tunsigned long cookie;\n};\n\nenum tc_clsbpf_command {\n\tTC_CLSBPF_OFFLOAD,\n\tTC_CLSBPF_STATS,\n};\n\nstruct tc_cls_bpf_offload {\n\tstruct flow_cls_common_offload common;\n\tenum tc_clsbpf_command command;\n\tstruct tcf_exts *exts;\n\tstruct bpf_prog *prog;\n\tstruct bpf_prog *oldprog;\n\tconst char *name;\n\tbool exts_integrated;\n};\n\n \nstruct tc_cookie {\n\tu8  *data;\n\tu32 len;\n\tstruct rcu_head rcu;\n};\n\nstruct tc_qopt_offload_stats {\n\tstruct gnet_stats_basic_sync *bstats;\n\tstruct gnet_stats_queue *qstats;\n};\n\nenum tc_mq_command {\n\tTC_MQ_CREATE,\n\tTC_MQ_DESTROY,\n\tTC_MQ_STATS,\n\tTC_MQ_GRAFT,\n};\n\nstruct tc_mq_opt_offload_graft_params {\n\tunsigned long queue;\n\tu32 child_handle;\n};\n\nstruct tc_mq_qopt_offload {\n\tenum tc_mq_command command;\n\tu32 handle;\n\tunion {\n\t\tstruct tc_qopt_offload_stats stats;\n\t\tstruct tc_mq_opt_offload_graft_params graft_params;\n\t};\n};\n\nenum tc_htb_command {\n\t \n\tTC_HTB_CREATE,  \n\tTC_HTB_DESTROY,  \n\n\t \n\t \n\tTC_HTB_LEAF_ALLOC_QUEUE,\n\t \n\tTC_HTB_LEAF_TO_INNER,\n\t \n\tTC_HTB_LEAF_DEL,\n\t \n\tTC_HTB_LEAF_DEL_LAST,\n\t \n\tTC_HTB_LEAF_DEL_LAST_FORCE,\n\t \n\tTC_HTB_NODE_MODIFY,\n\n\t \n\tTC_HTB_LEAF_QUERY_QUEUE,  \n};\n\nstruct tc_htb_qopt_offload {\n\tstruct netlink_ext_ack *extack;\n\tenum tc_htb_command command;\n\tu32 parent_classid;\n\tu16 classid;\n\tu16 qid;\n\tu32 quantum;\n\tu64 rate;\n\tu64 ceil;\n\tu8 prio;\n};\n\n#define TC_HTB_CLASSID_ROOT U32_MAX\n\nenum tc_red_command {\n\tTC_RED_REPLACE,\n\tTC_RED_DESTROY,\n\tTC_RED_STATS,\n\tTC_RED_XSTATS,\n\tTC_RED_GRAFT,\n};\n\nstruct tc_red_qopt_offload_params {\n\tu32 min;\n\tu32 max;\n\tu32 probability;\n\tu32 limit;\n\tbool is_ecn;\n\tbool is_harddrop;\n\tbool is_nodrop;\n\tstruct gnet_stats_queue *qstats;\n};\n\nstruct tc_red_qopt_offload {\n\tenum tc_red_command command;\n\tu32 handle;\n\tu32 parent;\n\tunion {\n\t\tstruct tc_red_qopt_offload_params set;\n\t\tstruct tc_qopt_offload_stats stats;\n\t\tstruct red_stats *xstats;\n\t\tu32 child_handle;\n\t};\n};\n\nenum tc_gred_command {\n\tTC_GRED_REPLACE,\n\tTC_GRED_DESTROY,\n\tTC_GRED_STATS,\n};\n\nstruct tc_gred_vq_qopt_offload_params {\n\tbool present;\n\tu32 limit;\n\tu32 prio;\n\tu32 min;\n\tu32 max;\n\tbool is_ecn;\n\tbool is_harddrop;\n\tu32 probability;\n\t \n\tu32 *backlog;\n};\n\nstruct tc_gred_qopt_offload_params {\n\tbool grio_on;\n\tbool wred_on;\n\tunsigned int dp_cnt;\n\tunsigned int dp_def;\n\tstruct gnet_stats_queue *qstats;\n\tstruct tc_gred_vq_qopt_offload_params tab[MAX_DPs];\n};\n\nstruct tc_gred_qopt_offload_stats {\n\tstruct gnet_stats_basic_sync bstats[MAX_DPs];\n\tstruct gnet_stats_queue qstats[MAX_DPs];\n\tstruct red_stats *xstats[MAX_DPs];\n};\n\nstruct tc_gred_qopt_offload {\n\tenum tc_gred_command command;\n\tu32 handle;\n\tu32 parent;\n\tunion {\n\t\tstruct tc_gred_qopt_offload_params set;\n\t\tstruct tc_gred_qopt_offload_stats stats;\n\t};\n};\n\nenum tc_prio_command {\n\tTC_PRIO_REPLACE,\n\tTC_PRIO_DESTROY,\n\tTC_PRIO_STATS,\n\tTC_PRIO_GRAFT,\n};\n\nstruct tc_prio_qopt_offload_params {\n\tint bands;\n\tu8 priomap[TC_PRIO_MAX + 1];\n\t \n\tstruct gnet_stats_queue *qstats;\n};\n\nstruct tc_prio_qopt_offload_graft_params {\n\tu8 band;\n\tu32 child_handle;\n};\n\nstruct tc_prio_qopt_offload {\n\tenum tc_prio_command command;\n\tu32 handle;\n\tu32 parent;\n\tunion {\n\t\tstruct tc_prio_qopt_offload_params replace_params;\n\t\tstruct tc_qopt_offload_stats stats;\n\t\tstruct tc_prio_qopt_offload_graft_params graft_params;\n\t};\n};\n\nenum tc_root_command {\n\tTC_ROOT_GRAFT,\n};\n\nstruct tc_root_qopt_offload {\n\tenum tc_root_command command;\n\tu32 handle;\n\tbool ingress;\n};\n\nenum tc_ets_command {\n\tTC_ETS_REPLACE,\n\tTC_ETS_DESTROY,\n\tTC_ETS_STATS,\n\tTC_ETS_GRAFT,\n};\n\nstruct tc_ets_qopt_offload_replace_params {\n\tunsigned int bands;\n\tu8 priomap[TC_PRIO_MAX + 1];\n\tunsigned int quanta[TCQ_ETS_MAX_BANDS];\t \n\tunsigned int weights[TCQ_ETS_MAX_BANDS];\n\tstruct gnet_stats_queue *qstats;\n};\n\nstruct tc_ets_qopt_offload_graft_params {\n\tu8 band;\n\tu32 child_handle;\n};\n\nstruct tc_ets_qopt_offload {\n\tenum tc_ets_command command;\n\tu32 handle;\n\tu32 parent;\n\tunion {\n\t\tstruct tc_ets_qopt_offload_replace_params replace_params;\n\t\tstruct tc_qopt_offload_stats stats;\n\t\tstruct tc_ets_qopt_offload_graft_params graft_params;\n\t};\n};\n\nenum tc_tbf_command {\n\tTC_TBF_REPLACE,\n\tTC_TBF_DESTROY,\n\tTC_TBF_STATS,\n\tTC_TBF_GRAFT,\n};\n\nstruct tc_tbf_qopt_offload_replace_params {\n\tstruct psched_ratecfg rate;\n\tu32 max_size;\n\tstruct gnet_stats_queue *qstats;\n};\n\nstruct tc_tbf_qopt_offload {\n\tenum tc_tbf_command command;\n\tu32 handle;\n\tu32 parent;\n\tunion {\n\t\tstruct tc_tbf_qopt_offload_replace_params replace_params;\n\t\tstruct tc_qopt_offload_stats stats;\n\t\tu32 child_handle;\n\t};\n};\n\nenum tc_fifo_command {\n\tTC_FIFO_REPLACE,\n\tTC_FIFO_DESTROY,\n\tTC_FIFO_STATS,\n};\n\nstruct tc_fifo_qopt_offload {\n\tenum tc_fifo_command command;\n\tu32 handle;\n\tu32 parent;\n\tunion {\n\t\tstruct tc_qopt_offload_stats stats;\n\t};\n};\n\n#ifdef CONFIG_NET_CLS_ACT\nDECLARE_STATIC_KEY_FALSE(tc_skb_ext_tc);\nvoid tc_skb_ext_tc_enable(void);\nvoid tc_skb_ext_tc_disable(void);\n#define tc_skb_ext_tc_enabled() static_branch_unlikely(&tc_skb_ext_tc)\n#else  \nstatic inline void tc_skb_ext_tc_enable(void) { }\nstatic inline void tc_skb_ext_tc_disable(void) { }\n#define tc_skb_ext_tc_enabled() false\n#endif\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}