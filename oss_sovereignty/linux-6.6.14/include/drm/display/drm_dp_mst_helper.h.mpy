{
  "module_name": "drm_dp_mst_helper.h",
  "hash_id": "8a18167bdb33b867b0ee87f50aaa0118e48b7db97071d9b74073e3a53c775f3b",
  "original_prompt": "Ingested from linux-6.6.14/include/drm/display/drm_dp_mst_helper.h",
  "human_readable_source": " \n#ifndef _DRM_DP_MST_HELPER_H_\n#define _DRM_DP_MST_HELPER_H_\n\n#include <linux/types.h>\n#include <drm/display/drm_dp_helper.h>\n#include <drm/drm_atomic.h>\n\n#if IS_ENABLED(CONFIG_DRM_DEBUG_DP_MST_TOPOLOGY_REFS)\n#include <linux/stackdepot.h>\n#include <linux/timekeeping.h>\n\nenum drm_dp_mst_topology_ref_type {\n\tDRM_DP_MST_TOPOLOGY_REF_GET,\n\tDRM_DP_MST_TOPOLOGY_REF_PUT,\n};\n\nstruct drm_dp_mst_topology_ref_history {\n\tstruct drm_dp_mst_topology_ref_entry {\n\t\tenum drm_dp_mst_topology_ref_type type;\n\t\tint count;\n\t\tktime_t ts_nsec;\n\t\tdepot_stack_handle_t backtrace;\n\t} *entries;\n\tint len;\n};\n#endif  \n\nstruct drm_dp_mst_branch;\n\n \nstruct drm_dp_mst_port {\n\t \n\tstruct kref topology_kref;\n\n\t \n\tstruct kref malloc_kref;\n\n#if IS_ENABLED(CONFIG_DRM_DEBUG_DP_MST_TOPOLOGY_REFS)\n\t \n\tstruct drm_dp_mst_topology_ref_history topology_ref_history;\n#endif\n\n\tu8 port_num;\n\tbool input;\n\tbool mcs;\n\tbool ddps;\n\tu8 pdt;\n\tbool ldps;\n\tu8 dpcd_rev;\n\tu8 num_sdp_streams;\n\tu8 num_sdp_stream_sinks;\n\tuint16_t full_pbn;\n\tstruct list_head next;\n\t \n\tstruct drm_dp_mst_branch *mstb;\n\tstruct drm_dp_aux aux;  \n\tstruct drm_dp_aux *passthrough_aux;\n\tstruct drm_dp_mst_branch *parent;\n\n\tstruct drm_connector *connector;\n\tstruct drm_dp_mst_topology_mgr *mgr;\n\n\t \n\tconst struct drm_edid *cached_edid;\n\n\t \n\tbool fec_capable;\n};\n\n \nstruct drm_dp_sideband_msg_hdr {\n\tu8 lct;\n\tu8 lcr;\n\tu8 rad[8];\n\tbool broadcast;\n\tbool path_msg;\n\tu8 msg_len;\n\tbool somt;\n\tbool eomt;\n\tbool seqno;\n};\n\nstruct drm_dp_sideband_msg_rx {\n\tu8 chunk[48];\n\tu8 msg[256];\n\tu8 curchunk_len;\n\tu8 curchunk_idx;  \n\tu8 curchunk_hdrlen;\n\tu8 curlen;  \n\tbool have_somt;\n\tbool have_eomt;\n\tstruct drm_dp_sideband_msg_hdr initial_hdr;\n};\n\n \nstruct drm_dp_mst_branch {\n\t \n\tstruct kref topology_kref;\n\n\t \n\tstruct kref malloc_kref;\n\n#if IS_ENABLED(CONFIG_DRM_DEBUG_DP_MST_TOPOLOGY_REFS)\n\t \n\tstruct drm_dp_mst_topology_ref_history topology_ref_history;\n#endif\n\n\t \n\tstruct list_head destroy_next;\n\n\tu8 rad[8];\n\tu8 lct;\n\tint num_ports;\n\n\t \n\tstruct list_head ports;\n\n\tstruct drm_dp_mst_port *port_parent;\n\tstruct drm_dp_mst_topology_mgr *mgr;\n\n\tbool link_address_sent;\n\n\t \n\tu8 guid[16];\n};\n\n\nstruct drm_dp_nak_reply {\n\tu8 guid[16];\n\tu8 reason;\n\tu8 nak_data;\n};\n\nstruct drm_dp_link_address_ack_reply {\n\tu8 guid[16];\n\tu8 nports;\n\tstruct drm_dp_link_addr_reply_port {\n\t\tbool input_port;\n\t\tu8 peer_device_type;\n\t\tu8 port_number;\n\t\tbool mcs;\n\t\tbool ddps;\n\t\tbool legacy_device_plug_status;\n\t\tu8 dpcd_revision;\n\t\tu8 peer_guid[16];\n\t\tu8 num_sdp_streams;\n\t\tu8 num_sdp_stream_sinks;\n\t} ports[16];\n};\n\nstruct drm_dp_remote_dpcd_read_ack_reply {\n\tu8 port_number;\n\tu8 num_bytes;\n\tu8 bytes[255];\n};\n\nstruct drm_dp_remote_dpcd_write_ack_reply {\n\tu8 port_number;\n};\n\nstruct drm_dp_remote_dpcd_write_nak_reply {\n\tu8 port_number;\n\tu8 reason;\n\tu8 bytes_written_before_failure;\n};\n\nstruct drm_dp_remote_i2c_read_ack_reply {\n\tu8 port_number;\n\tu8 num_bytes;\n\tu8 bytes[255];\n};\n\nstruct drm_dp_remote_i2c_read_nak_reply {\n\tu8 port_number;\n\tu8 nak_reason;\n\tu8 i2c_nak_transaction;\n};\n\nstruct drm_dp_remote_i2c_write_ack_reply {\n\tu8 port_number;\n};\n\nstruct drm_dp_query_stream_enc_status_ack_reply {\n\t \n\tu8 stream_id;\n\n\t \n\tbool reply_signed;\n\n\t \n\tbool unauthorizable_device_present;\n\tbool legacy_device_present;\n\tbool query_capable_device_present;\n\n\t \n\tbool hdcp_1x_device_present;\n\tbool hdcp_2x_device_present;\n\n\t \n\tbool auth_completed;\n\n\t \n\tbool encryption_enabled;\n\n\t \n\tbool repeater_present;\n\n\t \n\tu8 state;\n};\n\n#define DRM_DP_MAX_SDP_STREAMS 16\nstruct drm_dp_allocate_payload {\n\tu8 port_number;\n\tu8 number_sdp_streams;\n\tu8 vcpi;\n\tu16 pbn;\n\tu8 sdp_stream_sink[DRM_DP_MAX_SDP_STREAMS];\n};\n\nstruct drm_dp_allocate_payload_ack_reply {\n\tu8 port_number;\n\tu8 vcpi;\n\tu16 allocated_pbn;\n};\n\nstruct drm_dp_connection_status_notify {\n\tu8 guid[16];\n\tu8 port_number;\n\tbool legacy_device_plug_status;\n\tbool displayport_device_plug_status;\n\tbool message_capability_status;\n\tbool input_port;\n\tu8 peer_device_type;\n};\n\nstruct drm_dp_remote_dpcd_read {\n\tu8 port_number;\n\tu32 dpcd_address;\n\tu8 num_bytes;\n};\n\nstruct drm_dp_remote_dpcd_write {\n\tu8 port_number;\n\tu32 dpcd_address;\n\tu8 num_bytes;\n\tu8 *bytes;\n};\n\n#define DP_REMOTE_I2C_READ_MAX_TRANSACTIONS 4\nstruct drm_dp_remote_i2c_read {\n\tu8 num_transactions;\n\tu8 port_number;\n\tstruct drm_dp_remote_i2c_read_tx {\n\t\tu8 i2c_dev_id;\n\t\tu8 num_bytes;\n\t\tu8 *bytes;\n\t\tu8 no_stop_bit;\n\t\tu8 i2c_transaction_delay;\n\t} transactions[DP_REMOTE_I2C_READ_MAX_TRANSACTIONS];\n\tu8 read_i2c_device_id;\n\tu8 num_bytes_read;\n};\n\nstruct drm_dp_remote_i2c_write {\n\tu8 port_number;\n\tu8 write_i2c_device_id;\n\tu8 num_bytes;\n\tu8 *bytes;\n};\n\nstruct drm_dp_query_stream_enc_status {\n\tu8 stream_id;\n\tu8 client_id[7];\t \n\tu8 stream_event;\n\tbool valid_stream_event;\n\tu8 stream_behavior;\n\tu8 valid_stream_behavior;\n};\n\n \nstruct drm_dp_port_number_req {\n\tu8 port_number;\n};\n\nstruct drm_dp_enum_path_resources_ack_reply {\n\tu8 port_number;\n\tbool fec_capable;\n\tu16 full_payload_bw_number;\n\tu16 avail_payload_bw_number;\n};\n\n \nstruct drm_dp_port_number_rep {\n\tu8 port_number;\n};\n\nstruct drm_dp_query_payload {\n\tu8 port_number;\n\tu8 vcpi;\n};\n\nstruct drm_dp_resource_status_notify {\n\tu8 port_number;\n\tu8 guid[16];\n\tu16 available_pbn;\n};\n\nstruct drm_dp_query_payload_ack_reply {\n\tu8 port_number;\n\tu16 allocated_pbn;\n};\n\nstruct drm_dp_sideband_msg_req_body {\n\tu8 req_type;\n\tunion ack_req {\n\t\tstruct drm_dp_connection_status_notify conn_stat;\n\t\tstruct drm_dp_port_number_req port_num;\n\t\tstruct drm_dp_resource_status_notify resource_stat;\n\n\t\tstruct drm_dp_query_payload query_payload;\n\t\tstruct drm_dp_allocate_payload allocate_payload;\n\n\t\tstruct drm_dp_remote_dpcd_read dpcd_read;\n\t\tstruct drm_dp_remote_dpcd_write dpcd_write;\n\n\t\tstruct drm_dp_remote_i2c_read i2c_read;\n\t\tstruct drm_dp_remote_i2c_write i2c_write;\n\n\t\tstruct drm_dp_query_stream_enc_status enc_status;\n\t} u;\n};\n\nstruct drm_dp_sideband_msg_reply_body {\n\tu8 reply_type;\n\tu8 req_type;\n\tunion ack_replies {\n\t\tstruct drm_dp_nak_reply nak;\n\t\tstruct drm_dp_link_address_ack_reply link_addr;\n\t\tstruct drm_dp_port_number_rep port_number;\n\n\t\tstruct drm_dp_enum_path_resources_ack_reply path_resources;\n\t\tstruct drm_dp_allocate_payload_ack_reply allocate_payload;\n\t\tstruct drm_dp_query_payload_ack_reply query_payload;\n\n\t\tstruct drm_dp_remote_dpcd_read_ack_reply remote_dpcd_read_ack;\n\t\tstruct drm_dp_remote_dpcd_write_ack_reply remote_dpcd_write_ack;\n\t\tstruct drm_dp_remote_dpcd_write_nak_reply remote_dpcd_write_nack;\n\n\t\tstruct drm_dp_remote_i2c_read_ack_reply remote_i2c_read_ack;\n\t\tstruct drm_dp_remote_i2c_read_nak_reply remote_i2c_read_nack;\n\t\tstruct drm_dp_remote_i2c_write_ack_reply remote_i2c_write_ack;\n\n\t\tstruct drm_dp_query_stream_enc_status_ack_reply enc_status;\n\t} u;\n};\n\n \n#define DRM_DP_SIDEBAND_TX_QUEUED 0\n \n#define DRM_DP_SIDEBAND_TX_START_SEND 1\n \n#define DRM_DP_SIDEBAND_TX_SENT 2\n \n#define DRM_DP_SIDEBAND_TX_RX 3\n#define DRM_DP_SIDEBAND_TX_TIMEOUT 4\n\nstruct drm_dp_sideband_msg_tx {\n\tu8 msg[256];\n\tu8 chunk[48];\n\tu8 cur_offset;\n\tu8 cur_len;\n\tstruct drm_dp_mst_branch *dst;\n\tstruct list_head next;\n\tint seqno;\n\tint state;\n\tbool path_msg;\n\tstruct drm_dp_sideband_msg_reply_body reply;\n};\n\n \nstruct drm_dp_mst_topology_mgr;\nstruct drm_dp_mst_topology_cbs {\n\t \n\tstruct drm_connector *(*add_connector)(struct drm_dp_mst_topology_mgr *mgr, struct drm_dp_mst_port *port, const char *path);\n\t \n\tvoid (*poll_hpd_irq)(struct drm_dp_mst_topology_mgr *mgr);\n};\n\n#define to_dp_mst_topology_state(x) container_of(x, struct drm_dp_mst_topology_state, base)\n\n \nstruct drm_dp_mst_atomic_payload {\n\t \n\tstruct drm_dp_mst_port *port;\n\n\t \n\ts8 vc_start_slot;\n\n\t \n\tu8 vcpi;\n\t \n\tint time_slots;\n\t \n\tint pbn;\n\n\t \n\tbool delete : 1;\n\t \n\tbool dsc_enabled : 1;\n\n\t \n\tstruct list_head next;\n};\n\n \nstruct drm_dp_mst_topology_state {\n\t \n\tstruct drm_private_state base;\n\n\t \n\tstruct drm_dp_mst_topology_mgr *mgr;\n\n\t \n\tu32 pending_crtc_mask;\n\t \n\tstruct drm_crtc_commit **commit_deps;\n\t \n\tsize_t num_commit_deps;\n\n\t \n\tu32 payload_mask;\n\t \n\tstruct list_head payloads;\n\n\t \n\tu8 total_avail_slots;\n\t \n\tu8 start_slot;\n\n\t \n\tint pbn_div;\n};\n\n#define to_dp_mst_topology_mgr(x) container_of(x, struct drm_dp_mst_topology_mgr, base)\n\n \nstruct drm_dp_mst_topology_mgr {\n\t \n\tstruct drm_private_obj base;\n\n\t \n\tstruct drm_device *dev;\n\t \n\tconst struct drm_dp_mst_topology_cbs *cbs;\n\t \n\tint max_dpcd_transaction_bytes;\n\t \n\tstruct drm_dp_aux *aux;\n\t \n\tint max_payloads;\n\t \n\tint conn_base_id;\n\n\t \n\tstruct drm_dp_sideband_msg_rx up_req_recv;\n\n\t \n\tstruct drm_dp_sideband_msg_rx down_rep_recv;\n\n\t \n\tstruct mutex lock;\n\n\t \n\tstruct mutex probe_lock;\n\n\t \n\tbool mst_state : 1;\n\n\t \n\tbool payload_id_table_cleared : 1;\n\n\t \n\tu8 payload_count;\n\n\t \n\tu8 next_start_slot;\n\n\t \n\tstruct drm_dp_mst_branch *mst_primary;\n\n\t \n\tu8 dpcd[DP_RECEIVER_CAP_SIZE];\n\t \n\tu8 sink_count;\n\n\t \n\tconst struct drm_private_state_funcs *funcs;\n\n\t \n\tstruct mutex qlock;\n\n\t \n\tstruct list_head tx_msg_downq;\n\n\t \n\twait_queue_head_t tx_waitq;\n\t \n\tstruct work_struct work;\n\t \n\tstruct work_struct tx_work;\n\n\t \n\tstruct list_head destroy_port_list;\n\t \n\tstruct list_head destroy_branch_device_list;\n\t \n\tstruct mutex delayed_destroy_lock;\n\n\t \n\tstruct workqueue_struct *delayed_destroy_wq;\n\n\t \n\tstruct work_struct delayed_destroy_work;\n\n\t \n\tstruct list_head up_req_list;\n\t \n\tstruct mutex up_req_lock;\n\t \n\tstruct work_struct up_req_work;\n\n#if IS_ENABLED(CONFIG_DRM_DEBUG_DP_MST_TOPOLOGY_REFS)\n\t \n\tstruct mutex topology_ref_history_lock;\n#endif\n};\n\nint drm_dp_mst_topology_mgr_init(struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t\t struct drm_device *dev, struct drm_dp_aux *aux,\n\t\t\t\t int max_dpcd_transaction_bytes,\n\t\t\t\t int max_payloads, int conn_base_id);\n\nvoid drm_dp_mst_topology_mgr_destroy(struct drm_dp_mst_topology_mgr *mgr);\n\nbool drm_dp_read_mst_cap(struct drm_dp_aux *aux, const u8 dpcd[DP_RECEIVER_CAP_SIZE]);\nint drm_dp_mst_topology_mgr_set_mst(struct drm_dp_mst_topology_mgr *mgr, bool mst_state);\n\nint drm_dp_mst_hpd_irq_handle_event(struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t\t    const u8 *esi,\n\t\t\t\t    u8 *ack,\n\t\t\t\t    bool *handled);\nvoid drm_dp_mst_hpd_irq_send_new_request(struct drm_dp_mst_topology_mgr *mgr);\n\nint\ndrm_dp_mst_detect_port(struct drm_connector *connector,\n\t\t       struct drm_modeset_acquire_ctx *ctx,\n\t\t       struct drm_dp_mst_topology_mgr *mgr,\n\t\t       struct drm_dp_mst_port *port);\n\nconst struct drm_edid *drm_dp_mst_edid_read(struct drm_connector *connector,\n\t\t\t\t\t    struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t\t\t    struct drm_dp_mst_port *port);\nstruct edid *drm_dp_mst_get_edid(struct drm_connector *connector,\n\t\t\t\t struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t\t struct drm_dp_mst_port *port);\n\nint drm_dp_get_vc_payload_bw(const struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t     int link_rate, int link_lane_count);\n\nint drm_dp_calc_pbn_mode(int clock, int bpp);\n\nvoid drm_dp_mst_update_slots(struct drm_dp_mst_topology_state *mst_state, uint8_t link_encoding_cap);\n\nint drm_dp_add_payload_part1(struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t     struct drm_dp_mst_topology_state *mst_state,\n\t\t\t     struct drm_dp_mst_atomic_payload *payload);\nint drm_dp_add_payload_part2(struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t     struct drm_atomic_state *state,\n\t\t\t     struct drm_dp_mst_atomic_payload *payload);\nvoid drm_dp_remove_payload(struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t   struct drm_dp_mst_topology_state *mst_state,\n\t\t\t   const struct drm_dp_mst_atomic_payload *old_payload,\n\t\t\t   struct drm_dp_mst_atomic_payload *new_payload);\n\nint drm_dp_check_act_status(struct drm_dp_mst_topology_mgr *mgr);\n\nvoid drm_dp_mst_dump_topology(struct seq_file *m,\n\t\t\t      struct drm_dp_mst_topology_mgr *mgr);\n\nvoid drm_dp_mst_topology_mgr_suspend(struct drm_dp_mst_topology_mgr *mgr);\nint __must_check\ndrm_dp_mst_topology_mgr_resume(struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t       bool sync);\n\nssize_t drm_dp_mst_dpcd_read(struct drm_dp_aux *aux,\n\t\t\t     unsigned int offset, void *buffer, size_t size);\nssize_t drm_dp_mst_dpcd_write(struct drm_dp_aux *aux,\n\t\t\t      unsigned int offset, void *buffer, size_t size);\n\nint drm_dp_mst_connector_late_register(struct drm_connector *connector,\n\t\t\t\t       struct drm_dp_mst_port *port);\nvoid drm_dp_mst_connector_early_unregister(struct drm_connector *connector,\n\t\t\t\t\t   struct drm_dp_mst_port *port);\n\nstruct drm_dp_mst_topology_state *\ndrm_atomic_get_mst_topology_state(struct drm_atomic_state *state,\n\t\t\t\t  struct drm_dp_mst_topology_mgr *mgr);\nstruct drm_dp_mst_topology_state *\ndrm_atomic_get_old_mst_topology_state(struct drm_atomic_state *state,\n\t\t\t\t      struct drm_dp_mst_topology_mgr *mgr);\nstruct drm_dp_mst_topology_state *\ndrm_atomic_get_new_mst_topology_state(struct drm_atomic_state *state,\n\t\t\t\t      struct drm_dp_mst_topology_mgr *mgr);\nstruct drm_dp_mst_atomic_payload *\ndrm_atomic_get_mst_payload_state(struct drm_dp_mst_topology_state *state,\n\t\t\t\t struct drm_dp_mst_port *port);\nint __must_check\ndrm_dp_atomic_find_time_slots(struct drm_atomic_state *state,\n\t\t\t      struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t      struct drm_dp_mst_port *port, int pbn);\nint drm_dp_mst_atomic_enable_dsc(struct drm_atomic_state *state,\n\t\t\t\t struct drm_dp_mst_port *port,\n\t\t\t\t int pbn, bool enable);\nint __must_check\ndrm_dp_mst_add_affected_dsc_crtcs(struct drm_atomic_state *state,\n\t\t\t\t  struct drm_dp_mst_topology_mgr *mgr);\nint __must_check\ndrm_dp_atomic_release_time_slots(struct drm_atomic_state *state,\n\t\t\t\t struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t\t struct drm_dp_mst_port *port);\nvoid drm_dp_mst_atomic_wait_for_dependencies(struct drm_atomic_state *state);\nint __must_check drm_dp_mst_atomic_setup_commit(struct drm_atomic_state *state);\nint drm_dp_send_power_updown_phy(struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t\t struct drm_dp_mst_port *port, bool power_up);\nint drm_dp_send_query_stream_enc_status(struct drm_dp_mst_topology_mgr *mgr,\n\t\tstruct drm_dp_mst_port *port,\n\t\tstruct drm_dp_query_stream_enc_status_ack_reply *status);\nint __must_check drm_dp_mst_atomic_check(struct drm_atomic_state *state);\nint __must_check drm_dp_mst_root_conn_atomic_check(struct drm_connector_state *new_conn_state,\n\t\t\t\t\t\t   struct drm_dp_mst_topology_mgr *mgr);\n\nvoid drm_dp_mst_get_port_malloc(struct drm_dp_mst_port *port);\nvoid drm_dp_mst_put_port_malloc(struct drm_dp_mst_port *port);\n\nstruct drm_dp_aux *drm_dp_mst_dsc_aux_for_port(struct drm_dp_mst_port *port);\n\nstatic inline struct drm_dp_mst_topology_state *\nto_drm_dp_mst_topology_state(struct drm_private_state *state)\n{\n\treturn container_of(state, struct drm_dp_mst_topology_state, base);\n}\n\nextern const struct drm_private_state_funcs drm_dp_mst_topology_state_funcs;\n\n \nstatic inline bool\n__drm_dp_mst_state_iter_get(struct drm_atomic_state *state,\n\t\t\t    struct drm_dp_mst_topology_mgr **mgr,\n\t\t\t    struct drm_dp_mst_topology_state **old_state,\n\t\t\t    struct drm_dp_mst_topology_state **new_state,\n\t\t\t    int i)\n{\n\tstruct __drm_private_objs_state *objs_state = &state->private_objs[i];\n\n\tif (objs_state->ptr->funcs != &drm_dp_mst_topology_state_funcs)\n\t\treturn false;\n\n\t*mgr = to_dp_mst_topology_mgr(objs_state->ptr);\n\tif (old_state)\n\t\t*old_state = to_dp_mst_topology_state(objs_state->old_state);\n\tif (new_state)\n\t\t*new_state = to_dp_mst_topology_state(objs_state->new_state);\n\n\treturn true;\n}\n\n \n#define for_each_oldnew_mst_mgr_in_state(__state, mgr, old_state, new_state, __i) \\\n\tfor ((__i) = 0; (__i) < (__state)->num_private_objs; (__i)++) \\\n\t\tfor_each_if(__drm_dp_mst_state_iter_get((__state), &(mgr), &(old_state), &(new_state), (__i)))\n\n \n#define for_each_old_mst_mgr_in_state(__state, mgr, old_state, __i) \\\n\tfor ((__i) = 0; (__i) < (__state)->num_private_objs; (__i)++) \\\n\t\tfor_each_if(__drm_dp_mst_state_iter_get((__state), &(mgr), &(old_state), NULL, (__i)))\n\n \n#define for_each_new_mst_mgr_in_state(__state, mgr, new_state, __i) \\\n\tfor ((__i) = 0; (__i) < (__state)->num_private_objs; (__i)++) \\\n\t\tfor_each_if(__drm_dp_mst_state_iter_get((__state), &(mgr), NULL, &(new_state), (__i)))\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}