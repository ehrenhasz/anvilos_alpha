{
  "module_name": "radix-tree.c",
  "hash_id": "4ed81f445287267b698a829c37d9fd55d654b625645dfb2d7b16b5429e7179e0",
  "original_prompt": "Ingested from linux-6.6.14/lib/radix-tree.c",
  "human_readable_source": "\n \n\n#include <linux/bitmap.h>\n#include <linux/bitops.h>\n#include <linux/bug.h>\n#include <linux/cpu.h>\n#include <linux/errno.h>\n#include <linux/export.h>\n#include <linux/idr.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/kmemleak.h>\n#include <linux/percpu.h>\n#include <linux/preempt.h>\t\t \n#include <linux/radix-tree.h>\n#include <linux/rcupdate.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/xarray.h>\n\n#include \"radix-tree.h\"\n\n \nstruct kmem_cache *radix_tree_node_cachep;\n\n \n#define RADIX_TREE_PRELOAD_SIZE (RADIX_TREE_MAX_PATH * 2 - 1)\n\n \n#define IDR_INDEX_BITS\t\t(8   * sizeof(int) - 1)\n#define IDR_MAX_PATH\t\t(DIV_ROUND_UP(IDR_INDEX_BITS, \\\n\t\t\t\t\t\tRADIX_TREE_MAP_SHIFT))\n#define IDR_PRELOAD_SIZE\t(IDR_MAX_PATH * 2 - 1)\n\n \nDEFINE_PER_CPU(struct radix_tree_preload, radix_tree_preloads) = {\n\t.lock = INIT_LOCAL_LOCK(lock),\n};\nEXPORT_PER_CPU_SYMBOL_GPL(radix_tree_preloads);\n\nstatic inline struct radix_tree_node *entry_to_node(void *ptr)\n{\n\treturn (void *)((unsigned long)ptr & ~RADIX_TREE_INTERNAL_NODE);\n}\n\nstatic inline void *node_to_entry(void *ptr)\n{\n\treturn (void *)((unsigned long)ptr | RADIX_TREE_INTERNAL_NODE);\n}\n\n#define RADIX_TREE_RETRY\tXA_RETRY_ENTRY\n\nstatic inline unsigned long\nget_slot_offset(const struct radix_tree_node *parent, void __rcu **slot)\n{\n\treturn parent ? slot - parent->slots : 0;\n}\n\nstatic unsigned int radix_tree_descend(const struct radix_tree_node *parent,\n\t\t\tstruct radix_tree_node **nodep, unsigned long index)\n{\n\tunsigned int offset = (index >> parent->shift) & RADIX_TREE_MAP_MASK;\n\tvoid __rcu **entry = rcu_dereference_raw(parent->slots[offset]);\n\n\t*nodep = (void *)entry;\n\treturn offset;\n}\n\nstatic inline gfp_t root_gfp_mask(const struct radix_tree_root *root)\n{\n\treturn root->xa_flags & (__GFP_BITS_MASK & ~GFP_ZONEMASK);\n}\n\nstatic inline void tag_set(struct radix_tree_node *node, unsigned int tag,\n\t\tint offset)\n{\n\t__set_bit(offset, node->tags[tag]);\n}\n\nstatic inline void tag_clear(struct radix_tree_node *node, unsigned int tag,\n\t\tint offset)\n{\n\t__clear_bit(offset, node->tags[tag]);\n}\n\nstatic inline int tag_get(const struct radix_tree_node *node, unsigned int tag,\n\t\tint offset)\n{\n\treturn test_bit(offset, node->tags[tag]);\n}\n\nstatic inline void root_tag_set(struct radix_tree_root *root, unsigned tag)\n{\n\troot->xa_flags |= (__force gfp_t)(1 << (tag + ROOT_TAG_SHIFT));\n}\n\nstatic inline void root_tag_clear(struct radix_tree_root *root, unsigned tag)\n{\n\troot->xa_flags &= (__force gfp_t)~(1 << (tag + ROOT_TAG_SHIFT));\n}\n\nstatic inline void root_tag_clear_all(struct radix_tree_root *root)\n{\n\troot->xa_flags &= (__force gfp_t)((1 << ROOT_TAG_SHIFT) - 1);\n}\n\nstatic inline int root_tag_get(const struct radix_tree_root *root, unsigned tag)\n{\n\treturn (__force int)root->xa_flags & (1 << (tag + ROOT_TAG_SHIFT));\n}\n\nstatic inline unsigned root_tags_get(const struct radix_tree_root *root)\n{\n\treturn (__force unsigned)root->xa_flags >> ROOT_TAG_SHIFT;\n}\n\nstatic inline bool is_idr(const struct radix_tree_root *root)\n{\n\treturn !!(root->xa_flags & ROOT_IS_IDR);\n}\n\n \nstatic inline int any_tag_set(const struct radix_tree_node *node,\n\t\t\t\t\t\t\tunsigned int tag)\n{\n\tunsigned idx;\n\tfor (idx = 0; idx < RADIX_TREE_TAG_LONGS; idx++) {\n\t\tif (node->tags[tag][idx])\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic inline void all_tag_set(struct radix_tree_node *node, unsigned int tag)\n{\n\tbitmap_fill(node->tags[tag], RADIX_TREE_MAP_SIZE);\n}\n\n \nstatic __always_inline unsigned long\nradix_tree_find_next_bit(struct radix_tree_node *node, unsigned int tag,\n\t\t\t unsigned long offset)\n{\n\tconst unsigned long *addr = node->tags[tag];\n\n\tif (offset < RADIX_TREE_MAP_SIZE) {\n\t\tunsigned long tmp;\n\n\t\taddr += offset / BITS_PER_LONG;\n\t\ttmp = *addr >> (offset % BITS_PER_LONG);\n\t\tif (tmp)\n\t\t\treturn __ffs(tmp) + offset;\n\t\toffset = (offset + BITS_PER_LONG) & ~(BITS_PER_LONG - 1);\n\t\twhile (offset < RADIX_TREE_MAP_SIZE) {\n\t\t\ttmp = *++addr;\n\t\t\tif (tmp)\n\t\t\t\treturn __ffs(tmp) + offset;\n\t\t\toffset += BITS_PER_LONG;\n\t\t}\n\t}\n\treturn RADIX_TREE_MAP_SIZE;\n}\n\nstatic unsigned int iter_offset(const struct radix_tree_iter *iter)\n{\n\treturn iter->index & RADIX_TREE_MAP_MASK;\n}\n\n \nstatic inline unsigned long shift_maxindex(unsigned int shift)\n{\n\treturn (RADIX_TREE_MAP_SIZE << shift) - 1;\n}\n\nstatic inline unsigned long node_maxindex(const struct radix_tree_node *node)\n{\n\treturn shift_maxindex(node->shift);\n}\n\nstatic unsigned long next_index(unsigned long index,\n\t\t\t\tconst struct radix_tree_node *node,\n\t\t\t\tunsigned long offset)\n{\n\treturn (index & ~node_maxindex(node)) + (offset << node->shift);\n}\n\n \nstatic struct radix_tree_node *\nradix_tree_node_alloc(gfp_t gfp_mask, struct radix_tree_node *parent,\n\t\t\tstruct radix_tree_root *root,\n\t\t\tunsigned int shift, unsigned int offset,\n\t\t\tunsigned int count, unsigned int nr_values)\n{\n\tstruct radix_tree_node *ret = NULL;\n\n\t \n\tif (!gfpflags_allow_blocking(gfp_mask) && !in_interrupt()) {\n\t\tstruct radix_tree_preload *rtp;\n\n\t\t \n\t\tret = kmem_cache_alloc(radix_tree_node_cachep,\n\t\t\t\t       gfp_mask | __GFP_NOWARN);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\t \n\t\trtp = this_cpu_ptr(&radix_tree_preloads);\n\t\tif (rtp->nr) {\n\t\t\tret = rtp->nodes;\n\t\t\trtp->nodes = ret->parent;\n\t\t\trtp->nr--;\n\t\t}\n\t\t \n\t\tkmemleak_update_trace(ret);\n\t\tgoto out;\n\t}\n\tret = kmem_cache_alloc(radix_tree_node_cachep, gfp_mask);\nout:\n\tBUG_ON(radix_tree_is_internal_node(ret));\n\tif (ret) {\n\t\tret->shift = shift;\n\t\tret->offset = offset;\n\t\tret->count = count;\n\t\tret->nr_values = nr_values;\n\t\tret->parent = parent;\n\t\tret->array = root;\n\t}\n\treturn ret;\n}\n\nvoid radix_tree_node_rcu_free(struct rcu_head *head)\n{\n\tstruct radix_tree_node *node =\n\t\t\tcontainer_of(head, struct radix_tree_node, rcu_head);\n\n\t \n\tmemset(node->slots, 0, sizeof(node->slots));\n\tmemset(node->tags, 0, sizeof(node->tags));\n\tINIT_LIST_HEAD(&node->private_list);\n\n\tkmem_cache_free(radix_tree_node_cachep, node);\n}\n\nstatic inline void\nradix_tree_node_free(struct radix_tree_node *node)\n{\n\tcall_rcu(&node->rcu_head, radix_tree_node_rcu_free);\n}\n\n \nstatic __must_check int __radix_tree_preload(gfp_t gfp_mask, unsigned nr)\n{\n\tstruct radix_tree_preload *rtp;\n\tstruct radix_tree_node *node;\n\tint ret = -ENOMEM;\n\n\t \n\tgfp_mask &= ~__GFP_ACCOUNT;\n\n\tlocal_lock(&radix_tree_preloads.lock);\n\trtp = this_cpu_ptr(&radix_tree_preloads);\n\twhile (rtp->nr < nr) {\n\t\tlocal_unlock(&radix_tree_preloads.lock);\n\t\tnode = kmem_cache_alloc(radix_tree_node_cachep, gfp_mask);\n\t\tif (node == NULL)\n\t\t\tgoto out;\n\t\tlocal_lock(&radix_tree_preloads.lock);\n\t\trtp = this_cpu_ptr(&radix_tree_preloads);\n\t\tif (rtp->nr < nr) {\n\t\t\tnode->parent = rtp->nodes;\n\t\t\trtp->nodes = node;\n\t\t\trtp->nr++;\n\t\t} else {\n\t\t\tkmem_cache_free(radix_tree_node_cachep, node);\n\t\t}\n\t}\n\tret = 0;\nout:\n\treturn ret;\n}\n\n \nint radix_tree_preload(gfp_t gfp_mask)\n{\n\t \n\tWARN_ON_ONCE(!gfpflags_allow_blocking(gfp_mask));\n\treturn __radix_tree_preload(gfp_mask, RADIX_TREE_PRELOAD_SIZE);\n}\nEXPORT_SYMBOL(radix_tree_preload);\n\n \nint radix_tree_maybe_preload(gfp_t gfp_mask)\n{\n\tif (gfpflags_allow_blocking(gfp_mask))\n\t\treturn __radix_tree_preload(gfp_mask, RADIX_TREE_PRELOAD_SIZE);\n\t \n\tlocal_lock(&radix_tree_preloads.lock);\n\treturn 0;\n}\nEXPORT_SYMBOL(radix_tree_maybe_preload);\n\nstatic unsigned radix_tree_load_root(const struct radix_tree_root *root,\n\t\tstruct radix_tree_node **nodep, unsigned long *maxindex)\n{\n\tstruct radix_tree_node *node = rcu_dereference_raw(root->xa_head);\n\n\t*nodep = node;\n\n\tif (likely(radix_tree_is_internal_node(node))) {\n\t\tnode = entry_to_node(node);\n\t\t*maxindex = node_maxindex(node);\n\t\treturn node->shift + RADIX_TREE_MAP_SHIFT;\n\t}\n\n\t*maxindex = 0;\n\treturn 0;\n}\n\n \nstatic int radix_tree_extend(struct radix_tree_root *root, gfp_t gfp,\n\t\t\t\tunsigned long index, unsigned int shift)\n{\n\tvoid *entry;\n\tunsigned int maxshift;\n\tint tag;\n\n\t \n\tmaxshift = shift;\n\twhile (index > shift_maxindex(maxshift))\n\t\tmaxshift += RADIX_TREE_MAP_SHIFT;\n\n\tentry = rcu_dereference_raw(root->xa_head);\n\tif (!entry && (!is_idr(root) || root_tag_get(root, IDR_FREE)))\n\t\tgoto out;\n\n\tdo {\n\t\tstruct radix_tree_node *node = radix_tree_node_alloc(gfp, NULL,\n\t\t\t\t\t\t\troot, shift, 0, 1, 0);\n\t\tif (!node)\n\t\t\treturn -ENOMEM;\n\n\t\tif (is_idr(root)) {\n\t\t\tall_tag_set(node, IDR_FREE);\n\t\t\tif (!root_tag_get(root, IDR_FREE)) {\n\t\t\t\ttag_clear(node, IDR_FREE, 0);\n\t\t\t\troot_tag_set(root, IDR_FREE);\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tfor (tag = 0; tag < RADIX_TREE_MAX_TAGS; tag++) {\n\t\t\t\tif (root_tag_get(root, tag))\n\t\t\t\t\ttag_set(node, tag, 0);\n\t\t\t}\n\t\t}\n\n\t\tBUG_ON(shift > BITS_PER_LONG);\n\t\tif (radix_tree_is_internal_node(entry)) {\n\t\t\tentry_to_node(entry)->parent = node;\n\t\t} else if (xa_is_value(entry)) {\n\t\t\t \n\t\t\tnode->nr_values = 1;\n\t\t}\n\t\t \n\t\tnode->slots[0] = (void __rcu *)entry;\n\t\tentry = node_to_entry(node);\n\t\trcu_assign_pointer(root->xa_head, entry);\n\t\tshift += RADIX_TREE_MAP_SHIFT;\n\t} while (shift <= maxshift);\nout:\n\treturn maxshift + RADIX_TREE_MAP_SHIFT;\n}\n\n \nstatic inline bool radix_tree_shrink(struct radix_tree_root *root)\n{\n\tbool shrunk = false;\n\n\tfor (;;) {\n\t\tstruct radix_tree_node *node = rcu_dereference_raw(root->xa_head);\n\t\tstruct radix_tree_node *child;\n\n\t\tif (!radix_tree_is_internal_node(node))\n\t\t\tbreak;\n\t\tnode = entry_to_node(node);\n\n\t\t \n\t\tif (node->count != 1)\n\t\t\tbreak;\n\t\tchild = rcu_dereference_raw(node->slots[0]);\n\t\tif (!child)\n\t\t\tbreak;\n\n\t\t \n\t\tif (!node->shift && is_idr(root))\n\t\t\tbreak;\n\n\t\tif (radix_tree_is_internal_node(child))\n\t\t\tentry_to_node(child)->parent = NULL;\n\n\t\t \n\t\troot->xa_head = (void __rcu *)child;\n\t\tif (is_idr(root) && !tag_get(node, IDR_FREE, 0))\n\t\t\troot_tag_clear(root, IDR_FREE);\n\n\t\t \n\t\tnode->count = 0;\n\t\tif (!radix_tree_is_internal_node(child)) {\n\t\t\tnode->slots[0] = (void __rcu *)RADIX_TREE_RETRY;\n\t\t}\n\n\t\tWARN_ON_ONCE(!list_empty(&node->private_list));\n\t\tradix_tree_node_free(node);\n\t\tshrunk = true;\n\t}\n\n\treturn shrunk;\n}\n\nstatic bool delete_node(struct radix_tree_root *root,\n\t\t\tstruct radix_tree_node *node)\n{\n\tbool deleted = false;\n\n\tdo {\n\t\tstruct radix_tree_node *parent;\n\n\t\tif (node->count) {\n\t\t\tif (node_to_entry(node) ==\n\t\t\t\t\trcu_dereference_raw(root->xa_head))\n\t\t\t\tdeleted |= radix_tree_shrink(root);\n\t\t\treturn deleted;\n\t\t}\n\n\t\tparent = node->parent;\n\t\tif (parent) {\n\t\t\tparent->slots[node->offset] = NULL;\n\t\t\tparent->count--;\n\t\t} else {\n\t\t\t \n\t\t\tif (!is_idr(root))\n\t\t\t\troot_tag_clear_all(root);\n\t\t\troot->xa_head = NULL;\n\t\t}\n\n\t\tWARN_ON_ONCE(!list_empty(&node->private_list));\n\t\tradix_tree_node_free(node);\n\t\tdeleted = true;\n\n\t\tnode = parent;\n\t} while (node);\n\n\treturn deleted;\n}\n\n \nstatic int __radix_tree_create(struct radix_tree_root *root,\n\t\tunsigned long index, struct radix_tree_node **nodep,\n\t\tvoid __rcu ***slotp)\n{\n\tstruct radix_tree_node *node = NULL, *child;\n\tvoid __rcu **slot = (void __rcu **)&root->xa_head;\n\tunsigned long maxindex;\n\tunsigned int shift, offset = 0;\n\tunsigned long max = index;\n\tgfp_t gfp = root_gfp_mask(root);\n\n\tshift = radix_tree_load_root(root, &child, &maxindex);\n\n\t \n\tif (max > maxindex) {\n\t\tint error = radix_tree_extend(root, gfp, max, shift);\n\t\tif (error < 0)\n\t\t\treturn error;\n\t\tshift = error;\n\t\tchild = rcu_dereference_raw(root->xa_head);\n\t}\n\n\twhile (shift > 0) {\n\t\tshift -= RADIX_TREE_MAP_SHIFT;\n\t\tif (child == NULL) {\n\t\t\t \n\t\t\tchild = radix_tree_node_alloc(gfp, node, root, shift,\n\t\t\t\t\t\t\toffset, 0, 0);\n\t\t\tif (!child)\n\t\t\t\treturn -ENOMEM;\n\t\t\trcu_assign_pointer(*slot, node_to_entry(child));\n\t\t\tif (node)\n\t\t\t\tnode->count++;\n\t\t} else if (!radix_tree_is_internal_node(child))\n\t\t\tbreak;\n\n\t\t \n\t\tnode = entry_to_node(child);\n\t\toffset = radix_tree_descend(node, &child, index);\n\t\tslot = &node->slots[offset];\n\t}\n\n\tif (nodep)\n\t\t*nodep = node;\n\tif (slotp)\n\t\t*slotp = slot;\n\treturn 0;\n}\n\n \nstatic void radix_tree_free_nodes(struct radix_tree_node *node)\n{\n\tunsigned offset = 0;\n\tstruct radix_tree_node *child = entry_to_node(node);\n\n\tfor (;;) {\n\t\tvoid *entry = rcu_dereference_raw(child->slots[offset]);\n\t\tif (xa_is_node(entry) && child->shift) {\n\t\t\tchild = entry_to_node(entry);\n\t\t\toffset = 0;\n\t\t\tcontinue;\n\t\t}\n\t\toffset++;\n\t\twhile (offset == RADIX_TREE_MAP_SIZE) {\n\t\t\tstruct radix_tree_node *old = child;\n\t\t\toffset = child->offset + 1;\n\t\t\tchild = child->parent;\n\t\t\tWARN_ON_ONCE(!list_empty(&old->private_list));\n\t\t\tradix_tree_node_free(old);\n\t\t\tif (old == entry_to_node(node))\n\t\t\t\treturn;\n\t\t}\n\t}\n}\n\nstatic inline int insert_entries(struct radix_tree_node *node,\n\t\tvoid __rcu **slot, void *item)\n{\n\tif (*slot)\n\t\treturn -EEXIST;\n\trcu_assign_pointer(*slot, item);\n\tif (node) {\n\t\tnode->count++;\n\t\tif (xa_is_value(item))\n\t\t\tnode->nr_values++;\n\t}\n\treturn 1;\n}\n\n \nint radix_tree_insert(struct radix_tree_root *root, unsigned long index,\n\t\t\tvoid *item)\n{\n\tstruct radix_tree_node *node;\n\tvoid __rcu **slot;\n\tint error;\n\n\tBUG_ON(radix_tree_is_internal_node(item));\n\n\terror = __radix_tree_create(root, index, &node, &slot);\n\tif (error)\n\t\treturn error;\n\n\terror = insert_entries(node, slot, item);\n\tif (error < 0)\n\t\treturn error;\n\n\tif (node) {\n\t\tunsigned offset = get_slot_offset(node, slot);\n\t\tBUG_ON(tag_get(node, 0, offset));\n\t\tBUG_ON(tag_get(node, 1, offset));\n\t\tBUG_ON(tag_get(node, 2, offset));\n\t} else {\n\t\tBUG_ON(root_tags_get(root));\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(radix_tree_insert);\n\n \nvoid *__radix_tree_lookup(const struct radix_tree_root *root,\n\t\t\t  unsigned long index, struct radix_tree_node **nodep,\n\t\t\t  void __rcu ***slotp)\n{\n\tstruct radix_tree_node *node, *parent;\n\tunsigned long maxindex;\n\tvoid __rcu **slot;\n\n restart:\n\tparent = NULL;\n\tslot = (void __rcu **)&root->xa_head;\n\tradix_tree_load_root(root, &node, &maxindex);\n\tif (index > maxindex)\n\t\treturn NULL;\n\n\twhile (radix_tree_is_internal_node(node)) {\n\t\tunsigned offset;\n\n\t\tparent = entry_to_node(node);\n\t\toffset = radix_tree_descend(parent, &node, index);\n\t\tslot = parent->slots + offset;\n\t\tif (node == RADIX_TREE_RETRY)\n\t\t\tgoto restart;\n\t\tif (parent->shift == 0)\n\t\t\tbreak;\n\t}\n\n\tif (nodep)\n\t\t*nodep = parent;\n\tif (slotp)\n\t\t*slotp = slot;\n\treturn node;\n}\n\n \nvoid __rcu **radix_tree_lookup_slot(const struct radix_tree_root *root,\n\t\t\t\tunsigned long index)\n{\n\tvoid __rcu **slot;\n\n\tif (!__radix_tree_lookup(root, index, NULL, &slot))\n\t\treturn NULL;\n\treturn slot;\n}\nEXPORT_SYMBOL(radix_tree_lookup_slot);\n\n \nvoid *radix_tree_lookup(const struct radix_tree_root *root, unsigned long index)\n{\n\treturn __radix_tree_lookup(root, index, NULL, NULL);\n}\nEXPORT_SYMBOL(radix_tree_lookup);\n\nstatic void replace_slot(void __rcu **slot, void *item,\n\t\tstruct radix_tree_node *node, int count, int values)\n{\n\tif (node && (count || values)) {\n\t\tnode->count += count;\n\t\tnode->nr_values += values;\n\t}\n\n\trcu_assign_pointer(*slot, item);\n}\n\nstatic bool node_tag_get(const struct radix_tree_root *root,\n\t\t\t\tconst struct radix_tree_node *node,\n\t\t\t\tunsigned int tag, unsigned int offset)\n{\n\tif (node)\n\t\treturn tag_get(node, tag, offset);\n\treturn root_tag_get(root, tag);\n}\n\n \nstatic int calculate_count(struct radix_tree_root *root,\n\t\t\t\tstruct radix_tree_node *node, void __rcu **slot,\n\t\t\t\tvoid *item, void *old)\n{\n\tif (is_idr(root)) {\n\t\tunsigned offset = get_slot_offset(node, slot);\n\t\tbool free = node_tag_get(root, node, IDR_FREE, offset);\n\t\tif (!free)\n\t\t\treturn 0;\n\t\tif (!old)\n\t\t\treturn 1;\n\t}\n\treturn !!item - !!old;\n}\n\n \nvoid __radix_tree_replace(struct radix_tree_root *root,\n\t\t\t  struct radix_tree_node *node,\n\t\t\t  void __rcu **slot, void *item)\n{\n\tvoid *old = rcu_dereference_raw(*slot);\n\tint values = !!xa_is_value(item) - !!xa_is_value(old);\n\tint count = calculate_count(root, node, slot, item, old);\n\n\t \n\tWARN_ON_ONCE(!node && (slot != (void __rcu **)&root->xa_head) &&\n\t\t\t(count || values));\n\treplace_slot(slot, item, node, count, values);\n\n\tif (!node)\n\t\treturn;\n\n\tdelete_node(root, node);\n}\n\n \nvoid radix_tree_replace_slot(struct radix_tree_root *root,\n\t\t\t     void __rcu **slot, void *item)\n{\n\t__radix_tree_replace(root, NULL, slot, item);\n}\nEXPORT_SYMBOL(radix_tree_replace_slot);\n\n \nvoid radix_tree_iter_replace(struct radix_tree_root *root,\n\t\t\t\tconst struct radix_tree_iter *iter,\n\t\t\t\tvoid __rcu **slot, void *item)\n{\n\t__radix_tree_replace(root, iter->node, slot, item);\n}\n\nstatic void node_tag_set(struct radix_tree_root *root,\n\t\t\t\tstruct radix_tree_node *node,\n\t\t\t\tunsigned int tag, unsigned int offset)\n{\n\twhile (node) {\n\t\tif (tag_get(node, tag, offset))\n\t\t\treturn;\n\t\ttag_set(node, tag, offset);\n\t\toffset = node->offset;\n\t\tnode = node->parent;\n\t}\n\n\tif (!root_tag_get(root, tag))\n\t\troot_tag_set(root, tag);\n}\n\n \nvoid *radix_tree_tag_set(struct radix_tree_root *root,\n\t\t\tunsigned long index, unsigned int tag)\n{\n\tstruct radix_tree_node *node, *parent;\n\tunsigned long maxindex;\n\n\tradix_tree_load_root(root, &node, &maxindex);\n\tBUG_ON(index > maxindex);\n\n\twhile (radix_tree_is_internal_node(node)) {\n\t\tunsigned offset;\n\n\t\tparent = entry_to_node(node);\n\t\toffset = radix_tree_descend(parent, &node, index);\n\t\tBUG_ON(!node);\n\n\t\tif (!tag_get(parent, tag, offset))\n\t\t\ttag_set(parent, tag, offset);\n\t}\n\n\t \n\tif (!root_tag_get(root, tag))\n\t\troot_tag_set(root, tag);\n\n\treturn node;\n}\nEXPORT_SYMBOL(radix_tree_tag_set);\n\nstatic void node_tag_clear(struct radix_tree_root *root,\n\t\t\t\tstruct radix_tree_node *node,\n\t\t\t\tunsigned int tag, unsigned int offset)\n{\n\twhile (node) {\n\t\tif (!tag_get(node, tag, offset))\n\t\t\treturn;\n\t\ttag_clear(node, tag, offset);\n\t\tif (any_tag_set(node, tag))\n\t\t\treturn;\n\n\t\toffset = node->offset;\n\t\tnode = node->parent;\n\t}\n\n\t \n\tif (root_tag_get(root, tag))\n\t\troot_tag_clear(root, tag);\n}\n\n \nvoid *radix_tree_tag_clear(struct radix_tree_root *root,\n\t\t\tunsigned long index, unsigned int tag)\n{\n\tstruct radix_tree_node *node, *parent;\n\tunsigned long maxindex;\n\tint offset = 0;\n\n\tradix_tree_load_root(root, &node, &maxindex);\n\tif (index > maxindex)\n\t\treturn NULL;\n\n\tparent = NULL;\n\n\twhile (radix_tree_is_internal_node(node)) {\n\t\tparent = entry_to_node(node);\n\t\toffset = radix_tree_descend(parent, &node, index);\n\t}\n\n\tif (node)\n\t\tnode_tag_clear(root, parent, tag, offset);\n\n\treturn node;\n}\nEXPORT_SYMBOL(radix_tree_tag_clear);\n\n \nvoid radix_tree_iter_tag_clear(struct radix_tree_root *root,\n\t\t\tconst struct radix_tree_iter *iter, unsigned int tag)\n{\n\tnode_tag_clear(root, iter->node, tag, iter_offset(iter));\n}\n\n \nint radix_tree_tag_get(const struct radix_tree_root *root,\n\t\t\tunsigned long index, unsigned int tag)\n{\n\tstruct radix_tree_node *node, *parent;\n\tunsigned long maxindex;\n\n\tif (!root_tag_get(root, tag))\n\t\treturn 0;\n\n\tradix_tree_load_root(root, &node, &maxindex);\n\tif (index > maxindex)\n\t\treturn 0;\n\n\twhile (radix_tree_is_internal_node(node)) {\n\t\tunsigned offset;\n\n\t\tparent = entry_to_node(node);\n\t\toffset = radix_tree_descend(parent, &node, index);\n\n\t\tif (!tag_get(parent, tag, offset))\n\t\t\treturn 0;\n\t\tif (node == RADIX_TREE_RETRY)\n\t\t\tbreak;\n\t}\n\n\treturn 1;\n}\nEXPORT_SYMBOL(radix_tree_tag_get);\n\n \nstatic void set_iter_tags(struct radix_tree_iter *iter,\n\t\t\t\tstruct radix_tree_node *node, unsigned offset,\n\t\t\t\tunsigned tag)\n{\n\tunsigned tag_long = offset / BITS_PER_LONG;\n\tunsigned tag_bit  = offset % BITS_PER_LONG;\n\n\tif (!node) {\n\t\titer->tags = 1;\n\t\treturn;\n\t}\n\n\titer->tags = node->tags[tag][tag_long] >> tag_bit;\n\n\t \n\tif (tag_long < RADIX_TREE_TAG_LONGS - 1) {\n\t\t \n\t\tif (tag_bit)\n\t\t\titer->tags |= node->tags[tag][tag_long + 1] <<\n\t\t\t\t\t\t(BITS_PER_LONG - tag_bit);\n\t\t \n\t\titer->next_index = __radix_tree_iter_add(iter, BITS_PER_LONG);\n\t}\n}\n\nvoid __rcu **radix_tree_iter_resume(void __rcu **slot,\n\t\t\t\t\tstruct radix_tree_iter *iter)\n{\n\titer->index = __radix_tree_iter_add(iter, 1);\n\titer->next_index = iter->index;\n\titer->tags = 0;\n\treturn NULL;\n}\nEXPORT_SYMBOL(radix_tree_iter_resume);\n\n \nvoid __rcu **radix_tree_next_chunk(const struct radix_tree_root *root,\n\t\t\t     struct radix_tree_iter *iter, unsigned flags)\n{\n\tunsigned tag = flags & RADIX_TREE_ITER_TAG_MASK;\n\tstruct radix_tree_node *node, *child;\n\tunsigned long index, offset, maxindex;\n\n\tif ((flags & RADIX_TREE_ITER_TAGGED) && !root_tag_get(root, tag))\n\t\treturn NULL;\n\n\t \n\tindex = iter->next_index;\n\tif (!index && iter->index)\n\t\treturn NULL;\n\n restart:\n\tradix_tree_load_root(root, &child, &maxindex);\n\tif (index > maxindex)\n\t\treturn NULL;\n\tif (!child)\n\t\treturn NULL;\n\n\tif (!radix_tree_is_internal_node(child)) {\n\t\t \n\t\titer->index = index;\n\t\titer->next_index = maxindex + 1;\n\t\titer->tags = 1;\n\t\titer->node = NULL;\n\t\treturn (void __rcu **)&root->xa_head;\n\t}\n\n\tdo {\n\t\tnode = entry_to_node(child);\n\t\toffset = radix_tree_descend(node, &child, index);\n\n\t\tif ((flags & RADIX_TREE_ITER_TAGGED) ?\n\t\t\t\t!tag_get(node, tag, offset) : !child) {\n\t\t\t \n\t\t\tif (flags & RADIX_TREE_ITER_CONTIG)\n\t\t\t\treturn NULL;\n\n\t\t\tif (flags & RADIX_TREE_ITER_TAGGED)\n\t\t\t\toffset = radix_tree_find_next_bit(node, tag,\n\t\t\t\t\t\toffset + 1);\n\t\t\telse\n\t\t\t\twhile (++offset\t< RADIX_TREE_MAP_SIZE) {\n\t\t\t\t\tvoid *slot = rcu_dereference_raw(\n\t\t\t\t\t\t\tnode->slots[offset]);\n\t\t\t\t\tif (slot)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tindex &= ~node_maxindex(node);\n\t\t\tindex += offset << node->shift;\n\t\t\t \n\t\t\tif (!index)\n\t\t\t\treturn NULL;\n\t\t\tif (offset == RADIX_TREE_MAP_SIZE)\n\t\t\t\tgoto restart;\n\t\t\tchild = rcu_dereference_raw(node->slots[offset]);\n\t\t}\n\n\t\tif (!child)\n\t\t\tgoto restart;\n\t\tif (child == RADIX_TREE_RETRY)\n\t\t\tbreak;\n\t} while (node->shift && radix_tree_is_internal_node(child));\n\n\t \n\titer->index = (index &~ node_maxindex(node)) | offset;\n\titer->next_index = (index | node_maxindex(node)) + 1;\n\titer->node = node;\n\n\tif (flags & RADIX_TREE_ITER_TAGGED)\n\t\tset_iter_tags(iter, node, offset, tag);\n\n\treturn node->slots + offset;\n}\nEXPORT_SYMBOL(radix_tree_next_chunk);\n\n \nunsigned int\nradix_tree_gang_lookup(const struct radix_tree_root *root, void **results,\n\t\t\tunsigned long first_index, unsigned int max_items)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tunsigned int ret = 0;\n\n\tif (unlikely(!max_items))\n\t\treturn 0;\n\n\tradix_tree_for_each_slot(slot, root, &iter, first_index) {\n\t\tresults[ret] = rcu_dereference_raw(*slot);\n\t\tif (!results[ret])\n\t\t\tcontinue;\n\t\tif (radix_tree_is_internal_node(results[ret])) {\n\t\t\tslot = radix_tree_iter_retry(&iter);\n\t\t\tcontinue;\n\t\t}\n\t\tif (++ret == max_items)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL(radix_tree_gang_lookup);\n\n \nunsigned int\nradix_tree_gang_lookup_tag(const struct radix_tree_root *root, void **results,\n\t\tunsigned long first_index, unsigned int max_items,\n\t\tunsigned int tag)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tunsigned int ret = 0;\n\n\tif (unlikely(!max_items))\n\t\treturn 0;\n\n\tradix_tree_for_each_tagged(slot, root, &iter, first_index, tag) {\n\t\tresults[ret] = rcu_dereference_raw(*slot);\n\t\tif (!results[ret])\n\t\t\tcontinue;\n\t\tif (radix_tree_is_internal_node(results[ret])) {\n\t\t\tslot = radix_tree_iter_retry(&iter);\n\t\t\tcontinue;\n\t\t}\n\t\tif (++ret == max_items)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL(radix_tree_gang_lookup_tag);\n\n \nunsigned int\nradix_tree_gang_lookup_tag_slot(const struct radix_tree_root *root,\n\t\tvoid __rcu ***results, unsigned long first_index,\n\t\tunsigned int max_items, unsigned int tag)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tunsigned int ret = 0;\n\n\tif (unlikely(!max_items))\n\t\treturn 0;\n\n\tradix_tree_for_each_tagged(slot, root, &iter, first_index, tag) {\n\t\tresults[ret] = slot;\n\t\tif (++ret == max_items)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL(radix_tree_gang_lookup_tag_slot);\n\nstatic bool __radix_tree_delete(struct radix_tree_root *root,\n\t\t\t\tstruct radix_tree_node *node, void __rcu **slot)\n{\n\tvoid *old = rcu_dereference_raw(*slot);\n\tint values = xa_is_value(old) ? -1 : 0;\n\tunsigned offset = get_slot_offset(node, slot);\n\tint tag;\n\n\tif (is_idr(root))\n\t\tnode_tag_set(root, node, IDR_FREE, offset);\n\telse\n\t\tfor (tag = 0; tag < RADIX_TREE_MAX_TAGS; tag++)\n\t\t\tnode_tag_clear(root, node, tag, offset);\n\n\treplace_slot(slot, NULL, node, -1, values);\n\treturn node && delete_node(root, node);\n}\n\n \nvoid radix_tree_iter_delete(struct radix_tree_root *root,\n\t\t\t\tstruct radix_tree_iter *iter, void __rcu **slot)\n{\n\tif (__radix_tree_delete(root, iter->node, slot))\n\t\titer->index = iter->next_index;\n}\nEXPORT_SYMBOL(radix_tree_iter_delete);\n\n \nvoid *radix_tree_delete_item(struct radix_tree_root *root,\n\t\t\t     unsigned long index, void *item)\n{\n\tstruct radix_tree_node *node = NULL;\n\tvoid __rcu **slot = NULL;\n\tvoid *entry;\n\n\tentry = __radix_tree_lookup(root, index, &node, &slot);\n\tif (!slot)\n\t\treturn NULL;\n\tif (!entry && (!is_idr(root) || node_tag_get(root, node, IDR_FREE,\n\t\t\t\t\t\tget_slot_offset(node, slot))))\n\t\treturn NULL;\n\n\tif (item && entry != item)\n\t\treturn NULL;\n\n\t__radix_tree_delete(root, node, slot);\n\n\treturn entry;\n}\nEXPORT_SYMBOL(radix_tree_delete_item);\n\n \nvoid *radix_tree_delete(struct radix_tree_root *root, unsigned long index)\n{\n\treturn radix_tree_delete_item(root, index, NULL);\n}\nEXPORT_SYMBOL(radix_tree_delete);\n\n \nint radix_tree_tagged(const struct radix_tree_root *root, unsigned int tag)\n{\n\treturn root_tag_get(root, tag);\n}\nEXPORT_SYMBOL(radix_tree_tagged);\n\n \nvoid idr_preload(gfp_t gfp_mask)\n{\n\tif (__radix_tree_preload(gfp_mask, IDR_PRELOAD_SIZE))\n\t\tlocal_lock(&radix_tree_preloads.lock);\n}\nEXPORT_SYMBOL(idr_preload);\n\nvoid __rcu **idr_get_free(struct radix_tree_root *root,\n\t\t\t      struct radix_tree_iter *iter, gfp_t gfp,\n\t\t\t      unsigned long max)\n{\n\tstruct radix_tree_node *node = NULL, *child;\n\tvoid __rcu **slot = (void __rcu **)&root->xa_head;\n\tunsigned long maxindex, start = iter->next_index;\n\tunsigned int shift, offset = 0;\n\n grow:\n\tshift = radix_tree_load_root(root, &child, &maxindex);\n\tif (!radix_tree_tagged(root, IDR_FREE))\n\t\tstart = max(start, maxindex + 1);\n\tif (start > max)\n\t\treturn ERR_PTR(-ENOSPC);\n\n\tif (start > maxindex) {\n\t\tint error = radix_tree_extend(root, gfp, start, shift);\n\t\tif (error < 0)\n\t\t\treturn ERR_PTR(error);\n\t\tshift = error;\n\t\tchild = rcu_dereference_raw(root->xa_head);\n\t}\n\tif (start == 0 && shift == 0)\n\t\tshift = RADIX_TREE_MAP_SHIFT;\n\n\twhile (shift) {\n\t\tshift -= RADIX_TREE_MAP_SHIFT;\n\t\tif (child == NULL) {\n\t\t\t \n\t\t\tchild = radix_tree_node_alloc(gfp, node, root, shift,\n\t\t\t\t\t\t\toffset, 0, 0);\n\t\t\tif (!child)\n\t\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t\tall_tag_set(child, IDR_FREE);\n\t\t\trcu_assign_pointer(*slot, node_to_entry(child));\n\t\t\tif (node)\n\t\t\t\tnode->count++;\n\t\t} else if (!radix_tree_is_internal_node(child))\n\t\t\tbreak;\n\n\t\tnode = entry_to_node(child);\n\t\toffset = radix_tree_descend(node, &child, start);\n\t\tif (!tag_get(node, IDR_FREE, offset)) {\n\t\t\toffset = radix_tree_find_next_bit(node, IDR_FREE,\n\t\t\t\t\t\t\toffset + 1);\n\t\t\tstart = next_index(start, node, offset);\n\t\t\tif (start > max || start == 0)\n\t\t\t\treturn ERR_PTR(-ENOSPC);\n\t\t\twhile (offset == RADIX_TREE_MAP_SIZE) {\n\t\t\t\toffset = node->offset + 1;\n\t\t\t\tnode = node->parent;\n\t\t\t\tif (!node)\n\t\t\t\t\tgoto grow;\n\t\t\t\tshift = node->shift;\n\t\t\t}\n\t\t\tchild = rcu_dereference_raw(node->slots[offset]);\n\t\t}\n\t\tslot = &node->slots[offset];\n\t}\n\n\titer->index = start;\n\tif (node)\n\t\titer->next_index = 1 + min(max, (start | node_maxindex(node)));\n\telse\n\t\titer->next_index = 1;\n\titer->node = node;\n\tset_iter_tags(iter, node, offset, IDR_FREE);\n\n\treturn slot;\n}\n\n \nvoid idr_destroy(struct idr *idr)\n{\n\tstruct radix_tree_node *node = rcu_dereference_raw(idr->idr_rt.xa_head);\n\tif (radix_tree_is_internal_node(node))\n\t\tradix_tree_free_nodes(node);\n\tidr->idr_rt.xa_head = NULL;\n\troot_tag_set(&idr->idr_rt, IDR_FREE);\n}\nEXPORT_SYMBOL(idr_destroy);\n\nstatic void\nradix_tree_node_ctor(void *arg)\n{\n\tstruct radix_tree_node *node = arg;\n\n\tmemset(node, 0, sizeof(*node));\n\tINIT_LIST_HEAD(&node->private_list);\n}\n\nstatic int radix_tree_cpu_dead(unsigned int cpu)\n{\n\tstruct radix_tree_preload *rtp;\n\tstruct radix_tree_node *node;\n\n\t \n\trtp = &per_cpu(radix_tree_preloads, cpu);\n\twhile (rtp->nr) {\n\t\tnode = rtp->nodes;\n\t\trtp->nodes = node->parent;\n\t\tkmem_cache_free(radix_tree_node_cachep, node);\n\t\trtp->nr--;\n\t}\n\treturn 0;\n}\n\nvoid __init radix_tree_init(void)\n{\n\tint ret;\n\n\tBUILD_BUG_ON(RADIX_TREE_MAX_TAGS + __GFP_BITS_SHIFT > 32);\n\tBUILD_BUG_ON(ROOT_IS_IDR & ~GFP_ZONEMASK);\n\tBUILD_BUG_ON(XA_CHUNK_SIZE > 255);\n\tradix_tree_node_cachep = kmem_cache_create(\"radix_tree_node\",\n\t\t\tsizeof(struct radix_tree_node), 0,\n\t\t\tSLAB_PANIC | SLAB_RECLAIM_ACCOUNT,\n\t\t\tradix_tree_node_ctor);\n\tret = cpuhp_setup_state_nocalls(CPUHP_RADIX_DEAD, \"lib/radix:dead\",\n\t\t\t\t\tNULL, radix_tree_cpu_dead);\n\tWARN_ON(ret < 0);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}