{
  "module_name": "cpu_rmap.c",
  "hash_id": "8a29a2341743e7dd26bbb7e56c7fabf4fc8142e3404b2d6bd71b12c0c34a8370",
  "original_prompt": "Ingested from linux-6.6.14/lib/cpu_rmap.c",
  "human_readable_source": "\n \n\n#include <linux/cpu_rmap.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n\n \n\n \nstruct cpu_rmap *alloc_cpu_rmap(unsigned int size, gfp_t flags)\n{\n\tstruct cpu_rmap *rmap;\n\tunsigned int cpu;\n\tsize_t obj_offset;\n\n\t \n\tif (size > 0xffff)\n\t\treturn NULL;\n\n\t \n\tobj_offset = ALIGN(offsetof(struct cpu_rmap, near[nr_cpu_ids]),\n\t\t\t   sizeof(void *));\n\n\trmap = kzalloc(obj_offset + size * sizeof(rmap->obj[0]), flags);\n\tif (!rmap)\n\t\treturn NULL;\n\n\tkref_init(&rmap->refcount);\n\trmap->obj = (void **)((char *)rmap + obj_offset);\n\n\t \n\tfor_each_possible_cpu(cpu) {\n\t\trmap->near[cpu].index = cpu % size;\n\t\trmap->near[cpu].dist = CPU_RMAP_DIST_INF;\n\t}\n\n\trmap->size = size;\n\treturn rmap;\n}\nEXPORT_SYMBOL(alloc_cpu_rmap);\n\n \nstatic void cpu_rmap_release(struct kref *ref)\n{\n\tstruct cpu_rmap *rmap = container_of(ref, struct cpu_rmap, refcount);\n\tkfree(rmap);\n}\n\n \nstatic inline void cpu_rmap_get(struct cpu_rmap *rmap)\n{\n\tkref_get(&rmap->refcount);\n}\n\n \nint cpu_rmap_put(struct cpu_rmap *rmap)\n{\n\treturn kref_put(&rmap->refcount, cpu_rmap_release);\n}\nEXPORT_SYMBOL(cpu_rmap_put);\n\n \nstatic bool cpu_rmap_copy_neigh(struct cpu_rmap *rmap, unsigned int cpu,\n\t\t\t\tconst struct cpumask *mask, u16 dist)\n{\n\tint neigh;\n\n\tfor_each_cpu(neigh, mask) {\n\t\tif (rmap->near[cpu].dist > dist &&\n\t\t    rmap->near[neigh].dist <= dist) {\n\t\t\trmap->near[cpu].index = rmap->near[neigh].index;\n\t\t\trmap->near[cpu].dist = dist;\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\n#ifdef DEBUG\nstatic void debug_print_rmap(const struct cpu_rmap *rmap, const char *prefix)\n{\n\tunsigned index;\n\tunsigned int cpu;\n\n\tpr_info(\"cpu_rmap %p, %s:\\n\", rmap, prefix);\n\n\tfor_each_possible_cpu(cpu) {\n\t\tindex = rmap->near[cpu].index;\n\t\tpr_info(\"cpu %d -> obj %u (distance %u)\\n\",\n\t\t\tcpu, index, rmap->near[cpu].dist);\n\t}\n}\n#else\nstatic inline void\ndebug_print_rmap(const struct cpu_rmap *rmap, const char *prefix)\n{\n}\n#endif\n\nstatic int get_free_index(struct cpu_rmap *rmap)\n{\n\tint i;\n\n\tfor (i = 0; i < rmap->size; i++)\n\t\tif (!rmap->obj[i])\n\t\t\treturn i;\n\n\treturn -ENOSPC;\n}\n\n \nint cpu_rmap_add(struct cpu_rmap *rmap, void *obj)\n{\n\tint index = get_free_index(rmap);\n\n\tif (index < 0)\n\t\treturn index;\n\n\trmap->obj[index] = obj;\n\treturn index;\n}\nEXPORT_SYMBOL(cpu_rmap_add);\n\n \nint cpu_rmap_update(struct cpu_rmap *rmap, u16 index,\n\t\t    const struct cpumask *affinity)\n{\n\tcpumask_var_t update_mask;\n\tunsigned int cpu;\n\n\tif (unlikely(!zalloc_cpumask_var(&update_mask, GFP_KERNEL)))\n\t\treturn -ENOMEM;\n\n\t \n\tfor_each_online_cpu(cpu) {\n\t\tif (rmap->near[cpu].index == index) {\n\t\t\trmap->near[cpu].dist = CPU_RMAP_DIST_INF;\n\t\t\tcpumask_set_cpu(cpu, update_mask);\n\t\t}\n\t}\n\n\tdebug_print_rmap(rmap, \"after invalidating old distances\");\n\n\t \n\tfor_each_cpu(cpu, affinity) {\n\t\trmap->near[cpu].index = index;\n\t\trmap->near[cpu].dist = 0;\n\t\tcpumask_or(update_mask, update_mask,\n\t\t\t   cpumask_of_node(cpu_to_node(cpu)));\n\t}\n\n\tdebug_print_rmap(rmap, \"after updating neighbours\");\n\n\t \n\tfor_each_cpu(cpu, update_mask) {\n\t\tif (cpu_rmap_copy_neigh(rmap, cpu,\n\t\t\t\t\ttopology_sibling_cpumask(cpu), 1))\n\t\t\tcontinue;\n\t\tif (cpu_rmap_copy_neigh(rmap, cpu,\n\t\t\t\t\ttopology_core_cpumask(cpu), 2))\n\t\t\tcontinue;\n\t\tif (cpu_rmap_copy_neigh(rmap, cpu,\n\t\t\t\t\tcpumask_of_node(cpu_to_node(cpu)), 3))\n\t\t\tcontinue;\n\t\t \n\t}\n\n\tdebug_print_rmap(rmap, \"after copying neighbours\");\n\n\tfree_cpumask_var(update_mask);\n\treturn 0;\n}\nEXPORT_SYMBOL(cpu_rmap_update);\n\n \n\nstruct irq_glue {\n\tstruct irq_affinity_notify notify;\n\tstruct cpu_rmap *rmap;\n\tu16 index;\n};\n\n \nvoid free_irq_cpu_rmap(struct cpu_rmap *rmap)\n{\n\tstruct irq_glue *glue;\n\tu16 index;\n\n\tif (!rmap)\n\t\treturn;\n\n\tfor (index = 0; index < rmap->size; index++) {\n\t\tglue = rmap->obj[index];\n\t\tif (glue)\n\t\t\tirq_set_affinity_notifier(glue->notify.irq, NULL);\n\t}\n\n\tcpu_rmap_put(rmap);\n}\nEXPORT_SYMBOL(free_irq_cpu_rmap);\n\n \nstatic void\nirq_cpu_rmap_notify(struct irq_affinity_notify *notify, const cpumask_t *mask)\n{\n\tstruct irq_glue *glue =\n\t\tcontainer_of(notify, struct irq_glue, notify);\n\tint rc;\n\n\trc = cpu_rmap_update(glue->rmap, glue->index, mask);\n\tif (rc)\n\t\tpr_warn(\"irq_cpu_rmap_notify: update failed: %d\\n\", rc);\n}\n\n \nstatic void irq_cpu_rmap_release(struct kref *ref)\n{\n\tstruct irq_glue *glue =\n\t\tcontainer_of(ref, struct irq_glue, notify.kref);\n\n\tglue->rmap->obj[glue->index] = NULL;\n\tcpu_rmap_put(glue->rmap);\n\tkfree(glue);\n}\n\n \nint irq_cpu_rmap_remove(struct cpu_rmap *rmap, int irq)\n{\n\treturn irq_set_affinity_notifier(irq, NULL);\n}\nEXPORT_SYMBOL(irq_cpu_rmap_remove);\n\n \nint irq_cpu_rmap_add(struct cpu_rmap *rmap, int irq)\n{\n\tstruct irq_glue *glue = kzalloc(sizeof(*glue), GFP_KERNEL);\n\tint rc;\n\n\tif (!glue)\n\t\treturn -ENOMEM;\n\tglue->notify.notify = irq_cpu_rmap_notify;\n\tglue->notify.release = irq_cpu_rmap_release;\n\tglue->rmap = rmap;\n\tcpu_rmap_get(rmap);\n\trc = cpu_rmap_add(rmap, glue);\n\tif (rc < 0)\n\t\tgoto err_add;\n\n\tglue->index = rc;\n\trc = irq_set_affinity_notifier(irq, &glue->notify);\n\tif (rc)\n\t\tgoto err_set;\n\n\treturn rc;\n\nerr_set:\n\trmap->obj[glue->index] = NULL;\nerr_add:\n\tcpu_rmap_put(glue->rmap);\n\tkfree(glue);\n\treturn rc;\n}\nEXPORT_SYMBOL(irq_cpu_rmap_add);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}