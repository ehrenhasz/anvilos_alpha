{
  "module_name": "flex_proportions.c",
  "hash_id": "2f68d10017434ab4dbabb612b88ad4767e15725afe44b038908ea24a230f35ba",
  "original_prompt": "Ingested from linux-6.6.14/lib/flex_proportions.c",
  "human_readable_source": "\n \n#include <linux/flex_proportions.h>\n\nint fprop_global_init(struct fprop_global *p, gfp_t gfp)\n{\n\tint err;\n\n\tp->period = 0;\n\t \n\terr = percpu_counter_init(&p->events, 1, gfp);\n\tif (err)\n\t\treturn err;\n\tseqcount_init(&p->sequence);\n\treturn 0;\n}\n\nvoid fprop_global_destroy(struct fprop_global *p)\n{\n\tpercpu_counter_destroy(&p->events);\n}\n\n \nbool fprop_new_period(struct fprop_global *p, int periods)\n{\n\ts64 events = percpu_counter_sum(&p->events);\n\n\t \n\tif (events <= 1)\n\t\treturn false;\n\tpreempt_disable_nested();\n\twrite_seqcount_begin(&p->sequence);\n\tif (periods < 64)\n\t\tevents -= events >> periods;\n\t \n\tpercpu_counter_add(&p->events, -events);\n\tp->period += periods;\n\twrite_seqcount_end(&p->sequence);\n\tpreempt_enable_nested();\n\n\treturn true;\n}\n\n \n\nint fprop_local_init_single(struct fprop_local_single *pl)\n{\n\tpl->events = 0;\n\tpl->period = 0;\n\traw_spin_lock_init(&pl->lock);\n\treturn 0;\n}\n\nvoid fprop_local_destroy_single(struct fprop_local_single *pl)\n{\n}\n\nstatic void fprop_reflect_period_single(struct fprop_global *p,\n\t\t\t\t\tstruct fprop_local_single *pl)\n{\n\tunsigned int period = p->period;\n\tunsigned long flags;\n\n\t \n\tif (pl->period == period)\n\t\treturn;\n\traw_spin_lock_irqsave(&pl->lock, flags);\n\t \n\tif (pl->period >= period) {\n\t\traw_spin_unlock_irqrestore(&pl->lock, flags);\n\t\treturn;\n\t}\n\t \n\tif (period - pl->period < BITS_PER_LONG)\n\t\tpl->events >>= period - pl->period;\n\telse\n\t\tpl->events = 0;\n\tpl->period = period;\n\traw_spin_unlock_irqrestore(&pl->lock, flags);\n}\n\n \nvoid __fprop_inc_single(struct fprop_global *p, struct fprop_local_single *pl)\n{\n\tfprop_reflect_period_single(p, pl);\n\tpl->events++;\n\tpercpu_counter_add(&p->events, 1);\n}\n\n \nvoid fprop_fraction_single(struct fprop_global *p,\n\t\t\t   struct fprop_local_single *pl,\n\t\t\t   unsigned long *numerator, unsigned long *denominator)\n{\n\tunsigned int seq;\n\ts64 num, den;\n\n\tdo {\n\t\tseq = read_seqcount_begin(&p->sequence);\n\t\tfprop_reflect_period_single(p, pl);\n\t\tnum = pl->events;\n\t\tden = percpu_counter_read_positive(&p->events);\n\t} while (read_seqcount_retry(&p->sequence, seq));\n\n\t \n\tif (den <= num) {\n\t\tif (num)\n\t\t\tden = num;\n\t\telse\n\t\t\tden = 1;\n\t}\n\t*denominator = den;\n\t*numerator = num;\n}\n\n \n#define PROP_BATCH (8*(1+ilog2(nr_cpu_ids)))\n\nint fprop_local_init_percpu(struct fprop_local_percpu *pl, gfp_t gfp)\n{\n\tint err;\n\n\terr = percpu_counter_init(&pl->events, 0, gfp);\n\tif (err)\n\t\treturn err;\n\tpl->period = 0;\n\traw_spin_lock_init(&pl->lock);\n\treturn 0;\n}\n\nvoid fprop_local_destroy_percpu(struct fprop_local_percpu *pl)\n{\n\tpercpu_counter_destroy(&pl->events);\n}\n\nstatic void fprop_reflect_period_percpu(struct fprop_global *p,\n\t\t\t\t\tstruct fprop_local_percpu *pl)\n{\n\tunsigned int period = p->period;\n\tunsigned long flags;\n\n\t \n\tif (pl->period == period)\n\t\treturn;\n\traw_spin_lock_irqsave(&pl->lock, flags);\n\t \n\tif (pl->period >= period) {\n\t\traw_spin_unlock_irqrestore(&pl->lock, flags);\n\t\treturn;\n\t}\n\t \n\tif (period - pl->period < BITS_PER_LONG) {\n\t\ts64 val = percpu_counter_read(&pl->events);\n\n\t\tif (val < (nr_cpu_ids * PROP_BATCH))\n\t\t\tval = percpu_counter_sum(&pl->events);\n\n\t\tpercpu_counter_add_batch(&pl->events,\n\t\t\t-val + (val >> (period-pl->period)), PROP_BATCH);\n\t} else\n\t\tpercpu_counter_set(&pl->events, 0);\n\tpl->period = period;\n\traw_spin_unlock_irqrestore(&pl->lock, flags);\n}\n\n \nvoid __fprop_add_percpu(struct fprop_global *p, struct fprop_local_percpu *pl,\n\t\tlong nr)\n{\n\tfprop_reflect_period_percpu(p, pl);\n\tpercpu_counter_add_batch(&pl->events, nr, PROP_BATCH);\n\tpercpu_counter_add(&p->events, nr);\n}\n\nvoid fprop_fraction_percpu(struct fprop_global *p,\n\t\t\t   struct fprop_local_percpu *pl,\n\t\t\t   unsigned long *numerator, unsigned long *denominator)\n{\n\tunsigned int seq;\n\ts64 num, den;\n\n\tdo {\n\t\tseq = read_seqcount_begin(&p->sequence);\n\t\tfprop_reflect_period_percpu(p, pl);\n\t\tnum = percpu_counter_read_positive(&pl->events);\n\t\tden = percpu_counter_read_positive(&p->events);\n\t} while (read_seqcount_retry(&p->sequence, seq));\n\n\t \n\tif (den <= num) {\n\t\tif (num)\n\t\t\tden = num;\n\t\telse\n\t\t\tden = 1;\n\t}\n\t*denominator = den;\n\t*numerator = num;\n}\n\n \nvoid __fprop_add_percpu_max(struct fprop_global *p,\n\t\tstruct fprop_local_percpu *pl, int max_frac, long nr)\n{\n\tif (unlikely(max_frac < FPROP_FRAC_BASE)) {\n\t\tunsigned long numerator, denominator;\n\t\ts64 tmp;\n\n\t\tfprop_fraction_percpu(p, pl, &numerator, &denominator);\n\t\t \n\t\ttmp = (u64)denominator * max_frac -\n\t\t\t\t\t((u64)numerator << FPROP_FRAC_SHIFT);\n\t\tif (tmp < 0) {\n\t\t\t \n\t\t\treturn;\n\t\t} else if (tmp < nr * (FPROP_FRAC_BASE - max_frac)) {\n\t\t\t \n\t\t\tnr = div_u64(tmp + FPROP_FRAC_BASE - max_frac - 1,\n\t\t\t\t\tFPROP_FRAC_BASE - max_frac);\n\t\t}\n\t}\n\n\t__fprop_add_percpu(p, pl, nr);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}