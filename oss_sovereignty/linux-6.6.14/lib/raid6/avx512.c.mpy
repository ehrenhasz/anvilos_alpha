{
  "module_name": "avx512.c",
  "hash_id": "89a935be5abb983207ed50d556a45f3a8f358302c54e5d3447d3959bdf750c35",
  "original_prompt": "Ingested from linux-6.6.14/lib/raid6/avx512.c",
  "human_readable_source": "\n \n\n \n\n#ifdef CONFIG_AS_AVX512\n\n#include <linux/raid/pq.h>\n#include \"x86.h\"\n\nstatic const struct raid6_avx512_constants {\n\tu64 x1d[8];\n} raid6_avx512_constants __aligned(512/8) = {\n\t{ 0x1d1d1d1d1d1d1d1dULL, 0x1d1d1d1d1d1d1d1dULL,\n\t  0x1d1d1d1d1d1d1d1dULL, 0x1d1d1d1d1d1d1d1dULL,\n\t  0x1d1d1d1d1d1d1d1dULL, 0x1d1d1d1d1d1d1d1dULL,\n\t  0x1d1d1d1d1d1d1d1dULL, 0x1d1d1d1d1d1d1d1dULL,},\n};\n\nstatic int raid6_have_avx512(void)\n{\n\treturn boot_cpu_has(X86_FEATURE_AVX2) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX512F) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX512BW) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX512VL) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX512DQ);\n}\n\nstatic void raid6_avx5121_gen_syndrome(int disks, size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = disks - 3;          \n\tp = dptr[z0+1];          \n\tq = dptr[z0+2];          \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"vmovdqa64 %0,%%zmm0\\n\\t\"\n\t\t     \"vpxorq %%zmm1,%%zmm1,%%zmm1\"  \n\t\t     :\n\t\t     : \"m\" (raid6_avx512_constants.x1d[0]));\n\n\tfor (d = 0; d < bytes; d += 64) {\n\t\tasm volatile(\"prefetchnta %0\\n\\t\"\n\t\t\t     \"vmovdqa64 %0,%%zmm2\\n\\t\"      \n\t\t\t     \"prefetchnta %1\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm2,%%zmm4\\n\\t\"  \n\t\t\t     \"vmovdqa64 %1,%%zmm6\"\n\t\t\t     :\n\t\t\t     : \"m\" (dptr[z0][d]), \"m\" (dptr[z0-1][d]));\n\t\tfor (z = z0-2; z >= 0; z--) {\n\t\t\tasm volatile(\"prefetchnta %0\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm4,%%zmm1,%%k1\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm6,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm6,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %0,%%zmm6\"\n\t\t\t\t     :\n\t\t\t\t     : \"m\" (dptr[z][d]));\n\t\t}\n\t\tasm volatile(\"vpcmpgtb %%zmm4,%%zmm1,%%k1\\n\\t\"\n\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t     \"vpxorq %%zmm6,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t     \"vpxorq %%zmm6,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm2,%0\\n\\t\"\n\t\t\t     \"vpxorq %%zmm2,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm4,%1\\n\\t\"\n\t\t\t     \"vpxorq %%zmm4,%%zmm4,%%zmm4\"\n\t\t\t     :\n\t\t\t     : \"m\" (p[d]), \"m\" (q[d]));\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\nstatic void raid6_avx5121_xor_syndrome(int disks, int start, int stop,\n\t\t\t\t       size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = stop;\t\t \n\tp = dptr[disks-2];\t \n\tq = dptr[disks-1];\t \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"vmovdqa64 %0,%%zmm0\"\n\t\t     : : \"m\" (raid6_avx512_constants.x1d[0]));\n\n\tfor (d = 0 ; d < bytes ; d += 64) {\n\t\tasm volatile(\"vmovdqa64 %0,%%zmm4\\n\\t\"\n\t\t\t     \"vmovdqa64 %1,%%zmm2\\n\\t\"\n\t\t\t     \"vpxorq %%zmm4,%%zmm2,%%zmm2\"\n\t\t\t     :\n\t\t\t     : \"m\" (dptr[z0][d]),  \"m\" (p[d]));\n\t\t \n\t\tfor (z = z0-1 ; z >= start ; z--) {\n\t\t\tasm volatile(\"vpxorq %%zmm5,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm4,%%zmm5,%%k1\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %0,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\"\n\t\t\t\t     :\n\t\t\t\t     : \"m\" (dptr[z][d]));\n\t\t}\n\t\t \n\t\tfor (z = start-1 ; z >= 0 ; z--) {\n\t\t\tasm volatile(\"vpxorq %%zmm5,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm4,%%zmm5,%%k1\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\"\n\t\t\t\t     :\n\t\t\t\t     : );\n\t\t}\n\t\tasm volatile(\"vpxorq %0,%%zmm4,%%zmm4\\n\\t\"\n\t\t \n\t\t\t     \"vmovdqa64 %%zmm4,%0\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm2,%1\"\n\t\t\t     :\n\t\t\t     : \"m\" (q[d]), \"m\" (p[d]));\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\nconst struct raid6_calls raid6_avx512x1 = {\n\traid6_avx5121_gen_syndrome,\n\traid6_avx5121_xor_syndrome,\n\traid6_have_avx512,\n\t\"avx512x1\",\n\t.priority = 2\t\t \n};\n\n \nstatic void raid6_avx5122_gen_syndrome(int disks, size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = disks - 3;          \n\tp = dptr[z0+1];          \n\tq = dptr[z0+2];          \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"vmovdqa64 %0,%%zmm0\\n\\t\"\n\t\t     \"vpxorq %%zmm1,%%zmm1,%%zmm1\"  \n\t\t     :\n\t\t     : \"m\" (raid6_avx512_constants.x1d[0]));\n\n\t \n\tfor (d = 0; d < bytes; d += 128) {\n\t\tasm volatile(\"prefetchnta %0\\n\\t\"\n\t\t\t     \"prefetchnta %1\\n\\t\"\n\t\t\t     \"vmovdqa64 %0,%%zmm2\\n\\t\"       \n\t\t\t     \"vmovdqa64 %1,%%zmm3\\n\\t\"       \n\t\t\t     \"vmovdqa64 %%zmm2,%%zmm4\\n\\t\"   \n\t\t\t     \"vmovdqa64 %%zmm3,%%zmm6\"       \n\t\t\t     :\n\t\t\t     : \"m\" (dptr[z0][d]), \"m\" (dptr[z0][d+64]));\n\t\tfor (z = z0-1; z >= 0; z--) {\n\t\t\tasm volatile(\"prefetchnta %0\\n\\t\"\n\t\t\t\t     \"prefetchnta %1\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm4,%%zmm1,%%k1\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm6,%%zmm1,%%k2\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k2,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm6,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %0,%%zmm5\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %1,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm3,%%zmm3\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\"\n\t\t\t\t     :\n\t\t\t\t     : \"m\" (dptr[z][d]), \"m\" (dptr[z][d+64]));\n\t\t}\n\t\tasm volatile(\"vmovntdq %%zmm2,%0\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm3,%1\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm4,%2\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm6,%3\"\n\t\t\t     :\n\t\t\t     : \"m\" (p[d]), \"m\" (p[d+64]), \"m\" (q[d]),\n\t\t\t       \"m\" (q[d+64]));\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\nstatic void raid6_avx5122_xor_syndrome(int disks, int start, int stop,\n\t\t\t\t       size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = stop;\t\t \n\tp = dptr[disks-2];\t \n\tq = dptr[disks-1];\t \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"vmovdqa64 %0,%%zmm0\"\n\t\t     : : \"m\" (raid6_avx512_constants.x1d[0]));\n\n\tfor (d = 0 ; d < bytes ; d += 128) {\n\t\tasm volatile(\"vmovdqa64 %0,%%zmm4\\n\\t\"\n\t\t\t     \"vmovdqa64 %1,%%zmm6\\n\\t\"\n\t\t\t     \"vmovdqa64 %2,%%zmm2\\n\\t\"\n\t\t\t     \"vmovdqa64 %3,%%zmm3\\n\\t\"\n\t\t\t     \"vpxorq %%zmm4,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t     \"vpxorq %%zmm6,%%zmm3,%%zmm3\"\n\t\t\t     :\n\t\t\t     : \"m\" (dptr[z0][d]), \"m\" (dptr[z0][d+64]),\n\t\t\t       \"m\" (p[d]), \"m\" (p[d+64]));\n\t\t \n\t\tfor (z = z0-1 ; z >= start ; z--) {\n\t\t\tasm volatile(\"vpxorq %%zmm5,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm4,%%zmm5,%%k1\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm6,%%zmm7,%%k2\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k2,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm6,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %0,%%zmm5\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %1,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm3,%%zmm3\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\"\n\t\t\t\t     :\n\t\t\t\t     : \"m\" (dptr[z][d]),  \"m\" (dptr[z][d+64]));\n\t\t}\n\t\t \n\t\tfor (z = start-1 ; z >= 0 ; z--) {\n\t\t\tasm volatile(\"vpxorq %%zmm5,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm4,%%zmm5,%%k1\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm6,%%zmm7,%%k2\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k2,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm6,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\"\n\t\t\t\t     :\n\t\t\t\t     : );\n\t\t}\n\t\tasm volatile(\"vpxorq %0,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t     \"vpxorq %1,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t      \n\t\t\t     \"vmovdqa64 %%zmm4,%0\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm6,%1\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm2,%2\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm3,%3\"\n\t\t\t     :\n\t\t\t     : \"m\" (q[d]), \"m\" (q[d+64]), \"m\" (p[d]),\n\t\t\t       \"m\" (p[d+64]));\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\nconst struct raid6_calls raid6_avx512x2 = {\n\traid6_avx5122_gen_syndrome,\n\traid6_avx5122_xor_syndrome,\n\traid6_have_avx512,\n\t\"avx512x2\",\n\t.priority = 2\t\t \n};\n\n#ifdef CONFIG_X86_64\n\n \nstatic void raid6_avx5124_gen_syndrome(int disks, size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = disks - 3;          \n\tp = dptr[z0+1];          \n\tq = dptr[z0+2];          \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"vmovdqa64 %0,%%zmm0\\n\\t\"\n\t\t     \"vpxorq %%zmm1,%%zmm1,%%zmm1\\n\\t\"        \n\t\t     \"vpxorq %%zmm2,%%zmm2,%%zmm2\\n\\t\"        \n\t\t     \"vpxorq %%zmm3,%%zmm3,%%zmm3\\n\\t\"        \n\t\t     \"vpxorq %%zmm4,%%zmm4,%%zmm4\\n\\t\"        \n\t\t     \"vpxorq %%zmm6,%%zmm6,%%zmm6\\n\\t\"        \n\t\t     \"vpxorq %%zmm10,%%zmm10,%%zmm10\\n\\t\"     \n\t\t     \"vpxorq %%zmm11,%%zmm11,%%zmm11\\n\\t\"     \n\t\t     \"vpxorq %%zmm12,%%zmm12,%%zmm12\\n\\t\"     \n\t\t     \"vpxorq %%zmm14,%%zmm14,%%zmm14\"         \n\t\t     :\n\t\t     : \"m\" (raid6_avx512_constants.x1d[0]));\n\n\tfor (d = 0; d < bytes; d += 256) {\n\t\tfor (z = z0; z >= 0; z--) {\n\t\tasm volatile(\"prefetchnta %0\\n\\t\"\n\t\t\t     \"prefetchnta %1\\n\\t\"\n\t\t\t     \"prefetchnta %2\\n\\t\"\n\t\t\t     \"prefetchnta %3\\n\\t\"\n\t\t\t     \"vpcmpgtb %%zmm4,%%zmm1,%%k1\\n\\t\"\n\t\t\t     \"vpcmpgtb %%zmm6,%%zmm1,%%k2\\n\\t\"\n\t\t\t     \"vpcmpgtb %%zmm12,%%zmm1,%%k3\\n\\t\"\n\t\t\t     \"vpcmpgtb %%zmm14,%%zmm1,%%k4\\n\\t\"\n\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t     \"vpmovm2b %%k2,%%zmm7\\n\\t\"\n\t\t\t     \"vpmovm2b %%k3,%%zmm13\\n\\t\"\n\t\t\t     \"vpmovm2b %%k4,%%zmm15\\n\\t\"\n\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t     \"vpaddb %%zmm6,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t     \"vpaddb %%zmm12,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t     \"vpaddb %%zmm14,%%zmm14,%%zmm14\\n\\t\"\n\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t     \"vpandq %%zmm0,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t     \"vpandq %%zmm0,%%zmm13,%%zmm13\\n\\t\"\n\t\t\t     \"vpandq %%zmm0,%%zmm15,%%zmm15\\n\\t\"\n\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t     \"vpxorq %%zmm13,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t     \"vpxorq %%zmm15,%%zmm14,%%zmm14\\n\\t\"\n\t\t\t     \"vmovdqa64 %0,%%zmm5\\n\\t\"\n\t\t\t     \"vmovdqa64 %1,%%zmm7\\n\\t\"\n\t\t\t     \"vmovdqa64 %2,%%zmm13\\n\\t\"\n\t\t\t     \"vmovdqa64 %3,%%zmm15\\n\\t\"\n\t\t\t     \"vpxorq %%zmm5,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t     \"vpxorq %%zmm7,%%zmm3,%%zmm3\\n\\t\"\n\t\t\t     \"vpxorq %%zmm13,%%zmm10,%%zmm10\\n\\t\"\n\t\t\t     \"vpxorq %%zmm15,%%zmm11,%%zmm11\\n\"\n\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t     \"vpxorq %%zmm13,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t     \"vpxorq %%zmm15,%%zmm14,%%zmm14\"\n\t\t\t     :\n\t\t\t     : \"m\" (dptr[z][d]), \"m\" (dptr[z][d+64]),\n\t\t\t       \"m\" (dptr[z][d+128]), \"m\" (dptr[z][d+192]));\n\t\t}\n\t\tasm volatile(\"vmovntdq %%zmm2,%0\\n\\t\"\n\t\t\t     \"vpxorq %%zmm2,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm3,%1\\n\\t\"\n\t\t\t     \"vpxorq %%zmm3,%%zmm3,%%zmm3\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm10,%2\\n\\t\"\n\t\t\t     \"vpxorq %%zmm10,%%zmm10,%%zmm10\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm11,%3\\n\\t\"\n\t\t\t     \"vpxorq %%zmm11,%%zmm11,%%zmm11\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm4,%4\\n\\t\"\n\t\t\t     \"vpxorq %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm6,%5\\n\\t\"\n\t\t\t     \"vpxorq %%zmm6,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm12,%6\\n\\t\"\n\t\t\t     \"vpxorq %%zmm12,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm14,%7\\n\\t\"\n\t\t\t     \"vpxorq %%zmm14,%%zmm14,%%zmm14\"\n\t\t\t     :\n\t\t\t     : \"m\" (p[d]), \"m\" (p[d+64]), \"m\" (p[d+128]),\n\t\t\t       \"m\" (p[d+192]), \"m\" (q[d]), \"m\" (q[d+64]),\n\t\t\t       \"m\" (q[d+128]), \"m\" (q[d+192]));\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\nstatic void raid6_avx5124_xor_syndrome(int disks, int start, int stop,\n\t\t\t\t       size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = stop;\t\t \n\tp = dptr[disks-2];\t \n\tq = dptr[disks-1];\t \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"vmovdqa64 %0,%%zmm0\"\n\t\t     :: \"m\" (raid6_avx512_constants.x1d[0]));\n\n\tfor (d = 0 ; d < bytes ; d += 256) {\n\t\tasm volatile(\"vmovdqa64 %0,%%zmm4\\n\\t\"\n\t\t\t     \"vmovdqa64 %1,%%zmm6\\n\\t\"\n\t\t\t     \"vmovdqa64 %2,%%zmm12\\n\\t\"\n\t\t\t     \"vmovdqa64 %3,%%zmm14\\n\\t\"\n\t\t\t     \"vmovdqa64 %4,%%zmm2\\n\\t\"\n\t\t\t     \"vmovdqa64 %5,%%zmm3\\n\\t\"\n\t\t\t     \"vmovdqa64 %6,%%zmm10\\n\\t\"\n\t\t\t     \"vmovdqa64 %7,%%zmm11\\n\\t\"\n\t\t\t     \"vpxorq %%zmm4,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t     \"vpxorq %%zmm6,%%zmm3,%%zmm3\\n\\t\"\n\t\t\t     \"vpxorq %%zmm12,%%zmm10,%%zmm10\\n\\t\"\n\t\t\t     \"vpxorq %%zmm14,%%zmm11,%%zmm11\"\n\t\t\t     :\n\t\t\t     : \"m\" (dptr[z0][d]), \"m\" (dptr[z0][d+64]),\n\t\t\t       \"m\" (dptr[z0][d+128]), \"m\" (dptr[z0][d+192]),\n\t\t\t       \"m\" (p[d]), \"m\" (p[d+64]), \"m\" (p[d+128]),\n\t\t\t       \"m\" (p[d+192]));\n\t\t \n\t\tfor (z = z0-1 ; z >= start ; z--) {\n\t\t\tasm volatile(\"vpxorq %%zmm5,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm13,%%zmm13,%%zmm13\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm15,%%zmm15,%%zmm15\\n\\t\"\n\t\t\t\t     \"prefetchnta %0\\n\\t\"\n\t\t\t\t     \"prefetchnta %2\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm4,%%zmm5,%%k1\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm6,%%zmm7,%%k2\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm12,%%zmm13,%%k3\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm14,%%zmm15,%%k4\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k2,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k3,%%zmm13\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k4,%%zmm15\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm6,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm12,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t\t     \"vpaddb %%Zmm14,%%zmm14,%%zmm14\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm13,%%zmm13\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm15,%%zmm15\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm13,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm15,%%zmm14,%%zmm14\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %0,%%zmm5\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %1,%%zmm7\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %2,%%zmm13\\n\\t\"\n\t\t\t\t     \"vmovdqa64 %3,%%zmm15\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm2,%%zmm2\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm3,%%zmm3\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm13,%%zmm10,%%zmm10\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm15,%%zmm11,%%zmm11\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm13,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm15,%%zmm14,%%zmm14\"\n\t\t\t\t     :\n\t\t\t\t     : \"m\" (dptr[z][d]), \"m\" (dptr[z][d+64]),\n\t\t\t\t       \"m\" (dptr[z][d+128]),\n\t\t\t\t       \"m\" (dptr[z][d+192]));\n\t\t}\n\t\tasm volatile(\"prefetchnta %0\\n\\t\"\n\t\t\t     \"prefetchnta %1\\n\\t\"\n\t\t\t     :\n\t\t\t     : \"m\" (q[d]), \"m\" (q[d+128]));\n\t\t \n\t\tfor (z = start-1 ; z >= 0 ; z--) {\n\t\t\tasm volatile(\"vpxorq %%zmm5,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm13,%%zmm13,%%zmm13\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm15,%%zmm15,%%zmm15\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm4,%%zmm5,%%k1\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm6,%%zmm7,%%k2\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm12,%%zmm13,%%k3\\n\\t\"\n\t\t\t\t     \"vpcmpgtb %%zmm14,%%zmm15,%%k4\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k1,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k2,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k3,%%zmm13\\n\\t\"\n\t\t\t\t     \"vpmovm2b %%k4,%%zmm15\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm6,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm12,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t\t     \"vpaddb %%zmm14,%%zmm14,%%zmm14\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm5,%%zmm5\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm7,%%zmm7\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm13,%%zmm13\\n\\t\"\n\t\t\t\t     \"vpandq %%zmm0,%%zmm15,%%zmm15\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm5,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm7,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm13,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t\t     \"vpxorq %%zmm15,%%zmm14,%%zmm14\"\n\t\t\t\t     :\n\t\t\t\t     : );\n\t\t}\n\t\tasm volatile(\"vmovntdq %%zmm2,%0\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm3,%1\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm10,%2\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm11,%3\\n\\t\"\n\t\t\t     \"vpxorq %4,%%zmm4,%%zmm4\\n\\t\"\n\t\t\t     \"vpxorq %5,%%zmm6,%%zmm6\\n\\t\"\n\t\t\t     \"vpxorq %6,%%zmm12,%%zmm12\\n\\t\"\n\t\t\t     \"vpxorq %7,%%zmm14,%%zmm14\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm4,%4\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm6,%5\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm12,%6\\n\\t\"\n\t\t\t     \"vmovntdq %%zmm14,%7\"\n\t\t\t     :\n\t\t\t     : \"m\" (p[d]),  \"m\" (p[d+64]), \"m\" (p[d+128]),\n\t\t\t       \"m\" (p[d+192]), \"m\" (q[d]),  \"m\" (q[d+64]),\n\t\t\t       \"m\" (q[d+128]), \"m\" (q[d+192]));\n\t}\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\nconst struct raid6_calls raid6_avx512x4 = {\n\traid6_avx5124_gen_syndrome,\n\traid6_avx5124_xor_syndrome,\n\traid6_have_avx512,\n\t\"avx512x4\",\n\t.priority = 2\t\t \n};\n#endif\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}