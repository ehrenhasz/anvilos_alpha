{
  "module_name": "sse2.c",
  "hash_id": "299da19e917eb6dd7361c2ac47f2366e4105cf4c80ec21ae269ac7dd92e3a9ae",
  "original_prompt": "Ingested from linux-6.6.14/lib/raid6/sse2.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/raid/pq.h>\n#include \"x86.h\"\n\nstatic const struct raid6_sse_constants {\n\tu64 x1d[2];\n} raid6_sse_constants  __attribute__((aligned(16))) = {\n\t{ 0x1d1d1d1d1d1d1d1dULL, 0x1d1d1d1d1d1d1d1dULL },\n};\n\nstatic int raid6_have_sse2(void)\n{\n\t \n\treturn boot_cpu_has(X86_FEATURE_MMX) &&\n\t\tboot_cpu_has(X86_FEATURE_FXSR) &&\n\t\tboot_cpu_has(X86_FEATURE_XMM) &&\n\t\tboot_cpu_has(X86_FEATURE_XMM2);\n}\n\n \nstatic void raid6_sse21_gen_syndrome(int disks, size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = disks - 3;\t\t \n\tp = dptr[z0+1];\t\t \n\tq = dptr[z0+2];\t\t \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"movdqa %0,%%xmm0\" : : \"m\" (raid6_sse_constants.x1d[0]));\n\tasm volatile(\"pxor %xmm5,%xmm5\");\t \n\n\tfor ( d = 0 ; d < bytes ; d += 16 ) {\n\t\tasm volatile(\"prefetchnta %0\" : : \"m\" (dptr[z0][d]));\n\t\tasm volatile(\"movdqa %0,%%xmm2\" : : \"m\" (dptr[z0][d]));  \n\t\tasm volatile(\"prefetchnta %0\" : : \"m\" (dptr[z0-1][d]));\n\t\tasm volatile(\"movdqa %xmm2,%xmm4\");  \n\t\tasm volatile(\"movdqa %0,%%xmm6\" : : \"m\" (dptr[z0-1][d]));\n\t\tfor ( z = z0-2 ; z >= 0 ; z-- ) {\n\t\t\tasm volatile(\"prefetchnta %0\" : : \"m\" (dptr[z][d]));\n\t\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm6,%xmm2\");\n\t\t\tasm volatile(\"pxor %xmm6,%xmm4\");\n\t\t\tasm volatile(\"movdqa %0,%%xmm6\" : : \"m\" (dptr[z][d]));\n\t\t}\n\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\tasm volatile(\"pxor %xmm6,%xmm2\");\n\t\tasm volatile(\"pxor %xmm6,%xmm4\");\n\n\t\tasm volatile(\"movntdq %%xmm2,%0\" : \"=m\" (p[d]));\n\t\tasm volatile(\"pxor %xmm2,%xmm2\");\n\t\tasm volatile(\"movntdq %%xmm4,%0\" : \"=m\" (q[d]));\n\t\tasm volatile(\"pxor %xmm4,%xmm4\");\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\n\nstatic void raid6_sse21_xor_syndrome(int disks, int start, int stop,\n\t\t\t\t     size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = stop;\t\t \n\tp = dptr[disks-2];\t \n\tq = dptr[disks-1];\t \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"movdqa %0,%%xmm0\" : : \"m\" (raid6_sse_constants.x1d[0]));\n\n\tfor ( d = 0 ; d < bytes ; d += 16 ) {\n\t\tasm volatile(\"movdqa %0,%%xmm4\" :: \"m\" (dptr[z0][d]));\n\t\tasm volatile(\"movdqa %0,%%xmm2\" : : \"m\" (p[d]));\n\t\tasm volatile(\"pxor %xmm4,%xmm2\");\n\t\t \n\t\tfor ( z = z0-1 ; z >= start ; z-- ) {\n\t\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"movdqa %0,%%xmm5\" :: \"m\" (dptr[z][d]));\n\t\t\tasm volatile(\"pxor %xmm5,%xmm2\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t}\n\t\t \n\t\tfor ( z = start-1 ; z >= 0 ; z-- ) {\n\t\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t}\n\t\tasm volatile(\"pxor %0,%%xmm4\" : : \"m\" (q[d]));\n\t\t \n\t\tasm volatile(\"movdqa %%xmm4,%0\" : \"=m\" (q[d]));\n\t\tasm volatile(\"movdqa %%xmm2,%0\" : \"=m\" (p[d]));\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\nconst struct raid6_calls raid6_sse2x1 = {\n\traid6_sse21_gen_syndrome,\n\traid6_sse21_xor_syndrome,\n\traid6_have_sse2,\n\t\"sse2x1\",\n\t1\t\t\t \n};\n\n \nstatic void raid6_sse22_gen_syndrome(int disks, size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = disks - 3;\t\t \n\tp = dptr[z0+1];\t\t \n\tq = dptr[z0+2];\t\t \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"movdqa %0,%%xmm0\" : : \"m\" (raid6_sse_constants.x1d[0]));\n\tasm volatile(\"pxor %xmm5,%xmm5\");  \n\tasm volatile(\"pxor %xmm7,%xmm7\");  \n\n\t \n\tfor ( d = 0 ; d < bytes ; d += 32 ) {\n\t\tasm volatile(\"prefetchnta %0\" : : \"m\" (dptr[z0][d]));\n\t\tasm volatile(\"movdqa %0,%%xmm2\" : : \"m\" (dptr[z0][d]));     \n\t\tasm volatile(\"movdqa %0,%%xmm3\" : : \"m\" (dptr[z0][d+16]));  \n\t\tasm volatile(\"movdqa %xmm2,%xmm4\");  \n\t\tasm volatile(\"movdqa %xmm3,%xmm6\");  \n\t\tfor ( z = z0-1 ; z >= 0 ; z-- ) {\n\t\t\tasm volatile(\"prefetchnta %0\" : : \"m\" (dptr[z][d]));\n\t\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\t\tasm volatile(\"pcmpgtb %xmm6,%xmm7\");\n\t\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\t\tasm volatile(\"paddb %xmm6,%xmm6\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm7\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t\tasm volatile(\"movdqa %0,%%xmm5\" : : \"m\" (dptr[z][d]));\n\t\t\tasm volatile(\"movdqa %0,%%xmm7\" : : \"m\" (dptr[z][d+16]));\n\t\t\tasm volatile(\"pxor %xmm5,%xmm2\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm3\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm7\");\n\t\t}\n\t\tasm volatile(\"movntdq %%xmm2,%0\" : \"=m\" (p[d]));\n\t\tasm volatile(\"movntdq %%xmm3,%0\" : \"=m\" (p[d+16]));\n\t\tasm volatile(\"movntdq %%xmm4,%0\" : \"=m\" (q[d]));\n\t\tasm volatile(\"movntdq %%xmm6,%0\" : \"=m\" (q[d+16]));\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\nstatic void raid6_sse22_xor_syndrome(int disks, int start, int stop,\n\t\t\t\t     size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = stop;\t\t \n\tp = dptr[disks-2];\t \n\tq = dptr[disks-1];\t \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"movdqa %0,%%xmm0\" : : \"m\" (raid6_sse_constants.x1d[0]));\n\n\tfor ( d = 0 ; d < bytes ; d += 32 ) {\n\t\tasm volatile(\"movdqa %0,%%xmm4\" :: \"m\" (dptr[z0][d]));\n\t\tasm volatile(\"movdqa %0,%%xmm6\" :: \"m\" (dptr[z0][d+16]));\n\t\tasm volatile(\"movdqa %0,%%xmm2\" : : \"m\" (p[d]));\n\t\tasm volatile(\"movdqa %0,%%xmm3\" : : \"m\" (p[d+16]));\n\t\tasm volatile(\"pxor %xmm4,%xmm2\");\n\t\tasm volatile(\"pxor %xmm6,%xmm3\");\n\t\t \n\t\tfor ( z = z0-1 ; z >= start ; z-- ) {\n\t\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm7\");\n\t\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\t\tasm volatile(\"pcmpgtb %xmm6,%xmm7\");\n\t\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\t\tasm volatile(\"paddb %xmm6,%xmm6\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm7\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t\tasm volatile(\"movdqa %0,%%xmm5\" :: \"m\" (dptr[z][d]));\n\t\t\tasm volatile(\"movdqa %0,%%xmm7\" :: \"m\" (dptr[z][d+16]));\n\t\t\tasm volatile(\"pxor %xmm5,%xmm2\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm3\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t}\n\t\t \n\t\tfor ( z = start-1 ; z >= 0 ; z-- ) {\n\t\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm7\");\n\t\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\t\tasm volatile(\"pcmpgtb %xmm6,%xmm7\");\n\t\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\t\tasm volatile(\"paddb %xmm6,%xmm6\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm7\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t}\n\t\tasm volatile(\"pxor %0,%%xmm4\" : : \"m\" (q[d]));\n\t\tasm volatile(\"pxor %0,%%xmm6\" : : \"m\" (q[d+16]));\n\t\t \n\t\tasm volatile(\"movdqa %%xmm4,%0\" : \"=m\" (q[d]));\n\t\tasm volatile(\"movdqa %%xmm6,%0\" : \"=m\" (q[d+16]));\n\t\tasm volatile(\"movdqa %%xmm2,%0\" : \"=m\" (p[d]));\n\t\tasm volatile(\"movdqa %%xmm3,%0\" : \"=m\" (p[d+16]));\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\nconst struct raid6_calls raid6_sse2x2 = {\n\traid6_sse22_gen_syndrome,\n\traid6_sse22_xor_syndrome,\n\traid6_have_sse2,\n\t\"sse2x2\",\n\t1\t\t\t \n};\n\n#ifdef CONFIG_X86_64\n\n \nstatic void raid6_sse24_gen_syndrome(int disks, size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = disks - 3;\t\t \n\tp = dptr[z0+1];\t\t \n\tq = dptr[z0+2];\t\t \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"movdqa %0,%%xmm0\" :: \"m\" (raid6_sse_constants.x1d[0]));\n\tasm volatile(\"pxor %xmm2,%xmm2\");\t \n\tasm volatile(\"pxor %xmm3,%xmm3\");\t \n\tasm volatile(\"pxor %xmm4,%xmm4\"); \t \n\tasm volatile(\"pxor %xmm5,%xmm5\");\t \n\tasm volatile(\"pxor %xmm6,%xmm6\"); \t \n\tasm volatile(\"pxor %xmm7,%xmm7\"); \t \n\tasm volatile(\"pxor %xmm10,%xmm10\");\t \n\tasm volatile(\"pxor %xmm11,%xmm11\");\t \n\tasm volatile(\"pxor %xmm12,%xmm12\"); \t \n\tasm volatile(\"pxor %xmm13,%xmm13\");\t \n\tasm volatile(\"pxor %xmm14,%xmm14\"); \t \n\tasm volatile(\"pxor %xmm15,%xmm15\"); \t \n\n\tfor ( d = 0 ; d < bytes ; d += 64 ) {\n\t\tfor ( z = z0 ; z >= 0 ; z-- ) {\n\t\t\t \n\t\t\tasm volatile(\"prefetchnta %0\" :: \"m\" (dptr[z][d]));\n\t\t\tasm volatile(\"prefetchnta %0\" :: \"m\" (dptr[z][d+32]));\n\t\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\t\tasm volatile(\"pcmpgtb %xmm6,%xmm7\");\n\t\t\tasm volatile(\"pcmpgtb %xmm12,%xmm13\");\n\t\t\tasm volatile(\"pcmpgtb %xmm14,%xmm15\");\n\t\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\t\tasm volatile(\"paddb %xmm6,%xmm6\");\n\t\t\tasm volatile(\"paddb %xmm12,%xmm12\");\n\t\t\tasm volatile(\"paddb %xmm14,%xmm14\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm7\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm13\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm15\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm12\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm14\");\n\t\t\tasm volatile(\"movdqa %0,%%xmm5\" :: \"m\" (dptr[z][d]));\n\t\t\tasm volatile(\"movdqa %0,%%xmm7\" :: \"m\" (dptr[z][d+16]));\n\t\t\tasm volatile(\"movdqa %0,%%xmm13\" :: \"m\" (dptr[z][d+32]));\n\t\t\tasm volatile(\"movdqa %0,%%xmm15\" :: \"m\" (dptr[z][d+48]));\n\t\t\tasm volatile(\"pxor %xmm5,%xmm2\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm3\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm10\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm11\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm12\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm14\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm7\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm13\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm15\");\n\t\t}\n\t\tasm volatile(\"movntdq %%xmm2,%0\" : \"=m\" (p[d]));\n\t\tasm volatile(\"pxor %xmm2,%xmm2\");\n\t\tasm volatile(\"movntdq %%xmm3,%0\" : \"=m\" (p[d+16]));\n\t\tasm volatile(\"pxor %xmm3,%xmm3\");\n\t\tasm volatile(\"movntdq %%xmm10,%0\" : \"=m\" (p[d+32]));\n\t\tasm volatile(\"pxor %xmm10,%xmm10\");\n\t\tasm volatile(\"movntdq %%xmm11,%0\" : \"=m\" (p[d+48]));\n\t\tasm volatile(\"pxor %xmm11,%xmm11\");\n\t\tasm volatile(\"movntdq %%xmm4,%0\" : \"=m\" (q[d]));\n\t\tasm volatile(\"pxor %xmm4,%xmm4\");\n\t\tasm volatile(\"movntdq %%xmm6,%0\" : \"=m\" (q[d+16]));\n\t\tasm volatile(\"pxor %xmm6,%xmm6\");\n\t\tasm volatile(\"movntdq %%xmm12,%0\" : \"=m\" (q[d+32]));\n\t\tasm volatile(\"pxor %xmm12,%xmm12\");\n\t\tasm volatile(\"movntdq %%xmm14,%0\" : \"=m\" (q[d+48]));\n\t\tasm volatile(\"pxor %xmm14,%xmm14\");\n\t}\n\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\nstatic void raid6_sse24_xor_syndrome(int disks, int start, int stop,\n\t\t\t\t     size_t bytes, void **ptrs)\n{\n\tu8 **dptr = (u8 **)ptrs;\n\tu8 *p, *q;\n\tint d, z, z0;\n\n\tz0 = stop;\t\t \n\tp = dptr[disks-2];\t \n\tq = dptr[disks-1];\t \n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"movdqa %0,%%xmm0\" :: \"m\" (raid6_sse_constants.x1d[0]));\n\n\tfor ( d = 0 ; d < bytes ; d += 64 ) {\n\t\tasm volatile(\"movdqa %0,%%xmm4\" :: \"m\" (dptr[z0][d]));\n\t\tasm volatile(\"movdqa %0,%%xmm6\" :: \"m\" (dptr[z0][d+16]));\n\t\tasm volatile(\"movdqa %0,%%xmm12\" :: \"m\" (dptr[z0][d+32]));\n\t\tasm volatile(\"movdqa %0,%%xmm14\" :: \"m\" (dptr[z0][d+48]));\n\t\tasm volatile(\"movdqa %0,%%xmm2\" : : \"m\" (p[d]));\n\t\tasm volatile(\"movdqa %0,%%xmm3\" : : \"m\" (p[d+16]));\n\t\tasm volatile(\"movdqa %0,%%xmm10\" : : \"m\" (p[d+32]));\n\t\tasm volatile(\"movdqa %0,%%xmm11\" : : \"m\" (p[d+48]));\n\t\tasm volatile(\"pxor %xmm4,%xmm2\");\n\t\tasm volatile(\"pxor %xmm6,%xmm3\");\n\t\tasm volatile(\"pxor %xmm12,%xmm10\");\n\t\tasm volatile(\"pxor %xmm14,%xmm11\");\n\t\t \n\t\tfor ( z = z0-1 ; z >= start ; z-- ) {\n\t\t\tasm volatile(\"prefetchnta %0\" :: \"m\" (dptr[z][d]));\n\t\t\tasm volatile(\"prefetchnta %0\" :: \"m\" (dptr[z][d+32]));\n\t\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm7\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm13\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm15\");\n\t\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\t\tasm volatile(\"pcmpgtb %xmm6,%xmm7\");\n\t\t\tasm volatile(\"pcmpgtb %xmm12,%xmm13\");\n\t\t\tasm volatile(\"pcmpgtb %xmm14,%xmm15\");\n\t\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\t\tasm volatile(\"paddb %xmm6,%xmm6\");\n\t\t\tasm volatile(\"paddb %xmm12,%xmm12\");\n\t\t\tasm volatile(\"paddb %xmm14,%xmm14\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm7\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm13\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm15\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm12\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm14\");\n\t\t\tasm volatile(\"movdqa %0,%%xmm5\" :: \"m\" (dptr[z][d]));\n\t\t\tasm volatile(\"movdqa %0,%%xmm7\" :: \"m\" (dptr[z][d+16]));\n\t\t\tasm volatile(\"movdqa %0,%%xmm13\" :: \"m\" (dptr[z][d+32]));\n\t\t\tasm volatile(\"movdqa %0,%%xmm15\" :: \"m\" (dptr[z][d+48]));\n\t\t\tasm volatile(\"pxor %xmm5,%xmm2\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm3\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm10\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm11\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm12\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm14\");\n\t\t}\n\t\tasm volatile(\"prefetchnta %0\" :: \"m\" (q[d]));\n\t\tasm volatile(\"prefetchnta %0\" :: \"m\" (q[d+32]));\n\t\t \n\t\tfor ( z = start-1 ; z >= 0 ; z-- ) {\n\t\t\tasm volatile(\"pxor %xmm5,%xmm5\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm7\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm13\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm15\");\n\t\t\tasm volatile(\"pcmpgtb %xmm4,%xmm5\");\n\t\t\tasm volatile(\"pcmpgtb %xmm6,%xmm7\");\n\t\t\tasm volatile(\"pcmpgtb %xmm12,%xmm13\");\n\t\t\tasm volatile(\"pcmpgtb %xmm14,%xmm15\");\n\t\t\tasm volatile(\"paddb %xmm4,%xmm4\");\n\t\t\tasm volatile(\"paddb %xmm6,%xmm6\");\n\t\t\tasm volatile(\"paddb %xmm12,%xmm12\");\n\t\t\tasm volatile(\"paddb %xmm14,%xmm14\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm5\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm7\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm13\");\n\t\t\tasm volatile(\"pand %xmm0,%xmm15\");\n\t\t\tasm volatile(\"pxor %xmm5,%xmm4\");\n\t\t\tasm volatile(\"pxor %xmm7,%xmm6\");\n\t\t\tasm volatile(\"pxor %xmm13,%xmm12\");\n\t\t\tasm volatile(\"pxor %xmm15,%xmm14\");\n\t\t}\n\t\tasm volatile(\"movntdq %%xmm2,%0\" : \"=m\" (p[d]));\n\t\tasm volatile(\"movntdq %%xmm3,%0\" : \"=m\" (p[d+16]));\n\t\tasm volatile(\"movntdq %%xmm10,%0\" : \"=m\" (p[d+32]));\n\t\tasm volatile(\"movntdq %%xmm11,%0\" : \"=m\" (p[d+48]));\n\t\tasm volatile(\"pxor %0,%%xmm4\" : : \"m\" (q[d]));\n\t\tasm volatile(\"pxor %0,%%xmm6\" : : \"m\" (q[d+16]));\n\t\tasm volatile(\"pxor %0,%%xmm12\" : : \"m\" (q[d+32]));\n\t\tasm volatile(\"pxor %0,%%xmm14\" : : \"m\" (q[d+48]));\n\t\tasm volatile(\"movntdq %%xmm4,%0\" : \"=m\" (q[d]));\n\t\tasm volatile(\"movntdq %%xmm6,%0\" : \"=m\" (q[d+16]));\n\t\tasm volatile(\"movntdq %%xmm12,%0\" : \"=m\" (q[d+32]));\n\t\tasm volatile(\"movntdq %%xmm14,%0\" : \"=m\" (q[d+48]));\n\t}\n\tasm volatile(\"sfence\" : : : \"memory\");\n\tkernel_fpu_end();\n}\n\n\nconst struct raid6_calls raid6_sse2x4 = {\n\traid6_sse24_gen_syndrome,\n\traid6_sse24_xor_syndrome,\n\traid6_have_sse2,\n\t\"sse2x4\",\n\t1\t\t\t \n};\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}