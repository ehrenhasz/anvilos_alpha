{
  "module_name": "recov_avx512.c",
  "hash_id": "cb8c1ab70fe82b1b9bf08b7336d57fe702ff3e2d9019985c16b60f41bb642561",
  "original_prompt": "Ingested from linux-6.6.14/lib/raid6/recov_avx512.c",
  "human_readable_source": "\n \n\n#ifdef CONFIG_AS_AVX512\n\n#include <linux/raid/pq.h>\n#include \"x86.h\"\n\nstatic int raid6_has_avx512(void)\n{\n\treturn boot_cpu_has(X86_FEATURE_AVX2) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX512F) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX512BW) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX512VL) &&\n\t\tboot_cpu_has(X86_FEATURE_AVX512DQ);\n}\n\nstatic void raid6_2data_recov_avx512(int disks, size_t bytes, int faila,\n\t\t\t\t     int failb, void **ptrs)\n{\n\tu8 *p, *q, *dp, *dq;\n\tconst u8 *pbmul;\t \n\tconst u8 *qmul;\t\t \n\tconst u8 x0f = 0x0f;\n\n\tp = (u8 *)ptrs[disks-2];\n\tq = (u8 *)ptrs[disks-1];\n\n\t \n\n\tdp = (u8 *)ptrs[faila];\n\tptrs[faila] = (void *)raid6_empty_zero_page;\n\tptrs[disks-2] = dp;\n\tdq = (u8 *)ptrs[failb];\n\tptrs[failb] = (void *)raid6_empty_zero_page;\n\tptrs[disks-1] = dq;\n\n\traid6_call.gen_syndrome(disks, bytes, ptrs);\n\n\t \n\tptrs[faila]   = dp;\n\tptrs[failb]   = dq;\n\tptrs[disks-2] = p;\n\tptrs[disks-1] = q;\n\n\t \n\tpbmul = raid6_vgfmul[raid6_gfexi[failb-faila]];\n\tqmul  = raid6_vgfmul[raid6_gfinv[raid6_gfexp[faila] ^\n\t\traid6_gfexp[failb]]];\n\n\tkernel_fpu_begin();\n\n\t \n\tasm volatile(\"vpbroadcastb %0, %%zmm7\" : : \"m\" (x0f));\n\n\twhile (bytes) {\n#ifdef CONFIG_X86_64\n\t\tasm volatile(\"vmovdqa64 %0, %%zmm1\\n\\t\"\n\t\t\t     \"vmovdqa64 %1, %%zmm9\\n\\t\"\n\t\t\t     \"vmovdqa64 %2, %%zmm0\\n\\t\"\n\t\t\t     \"vmovdqa64 %3, %%zmm8\\n\\t\"\n\t\t\t     \"vpxorq %4, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpxorq %5, %%zmm9, %%zmm9\\n\\t\"\n\t\t\t     \"vpxorq %6, %%zmm0, %%zmm0\\n\\t\"\n\t\t\t     \"vpxorq %7, %%zmm8, %%zmm8\"\n\t\t\t     :\n\t\t\t     : \"m\" (q[0]), \"m\" (q[64]), \"m\" (p[0]),\n\t\t\t       \"m\" (p[64]), \"m\" (dq[0]), \"m\" (dq[64]),\n\t\t\t       \"m\" (dp[0]), \"m\" (dp[64]));\n\n\t\t \n\n\t\tasm volatile(\"vbroadcasti64x2 %0, %%zmm4\\n\\t\"\n\t\t\t     \"vbroadcasti64x2 %1, %%zmm5\"\n\t\t\t     :\n\t\t\t     : \"m\" (qmul[0]), \"m\" (qmul[16]));\n\n\t\tasm volatile(\"vpsraw $4, %%zmm1, %%zmm3\\n\\t\"\n\t\t\t     \"vpsraw $4, %%zmm9, %%zmm12\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm9, %%zmm9\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm3, %%zmm3\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm12, %%zmm12\\n\\t\"\n\t\t\t     \"vpshufb %%zmm9, %%zmm4, %%zmm14\\n\\t\"\n\t\t\t     \"vpshufb %%zmm1, %%zmm4, %%zmm4\\n\\t\"\n\t\t\t     \"vpshufb %%zmm12, %%zmm5, %%zmm15\\n\\t\"\n\t\t\t     \"vpshufb %%zmm3, %%zmm5, %%zmm5\\n\\t\"\n\t\t\t     \"vpxorq %%zmm14, %%zmm15, %%zmm15\\n\\t\"\n\t\t\t     \"vpxorq %%zmm4, %%zmm5, %%zmm5\"\n\t\t\t     :\n\t\t\t     : );\n\n\t\t \n\n\t\tasm volatile(\"vbroadcasti64x2 %0, %%zmm4\\n\\t\"\n\t\t\t     \"vbroadcasti64x2 %1, %%zmm1\\n\\t\"\n\t\t\t     \"vpsraw $4, %%zmm0, %%zmm2\\n\\t\"\n\t\t\t     \"vpsraw $4, %%zmm8, %%zmm6\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm0, %%zmm3\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm8, %%zmm14\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm2, %%zmm2\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm6, %%zmm6\\n\\t\"\n\t\t\t     \"vpshufb %%zmm14, %%zmm4, %%zmm12\\n\\t\"\n\t\t\t     \"vpshufb %%zmm3, %%zmm4, %%zmm4\\n\\t\"\n\t\t\t     \"vpshufb %%zmm6, %%zmm1, %%zmm13\\n\\t\"\n\t\t\t     \"vpshufb %%zmm2, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpxorq %%zmm4, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpxorq %%zmm12, %%zmm13, %%zmm13\"\n\t\t\t     :\n\t\t\t     : \"m\" (pbmul[0]), \"m\" (pbmul[16]));\n\n\t\t \n\t\tasm volatile(\"vpxorq %%zmm5, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpxorq %%zmm15, %%zmm13, %%zmm13\"\n\t\t\t     :\n\t\t\t     : );\n\n\t\t \n\t\tasm volatile(\"vmovdqa64 %%zmm1, %0\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm13,%1\\n\\t\"\n\t\t\t     \"vpxorq %%zmm1, %%zmm0, %%zmm0\\n\\t\"\n\t\t\t     \"vpxorq %%zmm13, %%zmm8, %%zmm8\"\n\t\t\t     :\n\t\t\t     : \"m\" (dq[0]), \"m\" (dq[64]));\n\n\t\tasm volatile(\"vmovdqa64 %%zmm0, %0\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm8, %1\"\n\t\t\t     :\n\t\t\t     : \"m\" (dp[0]), \"m\" (dp[64]));\n\n\t\tbytes -= 128;\n\t\tp += 128;\n\t\tq += 128;\n\t\tdp += 128;\n\t\tdq += 128;\n#else\n\t\tasm volatile(\"vmovdqa64 %0, %%zmm1\\n\\t\"\n\t\t\t     \"vmovdqa64 %1, %%zmm0\\n\\t\"\n\t\t\t     \"vpxorq %2, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpxorq %3, %%zmm0, %%zmm0\"\n\t\t\t     :\n\t\t\t     : \"m\" (*q), \"m\" (*p), \"m\"(*dq), \"m\" (*dp));\n\n\t\t \n\n\t\tasm volatile(\"vbroadcasti64x2 %0, %%zmm4\\n\\t\"\n\t\t\t     \"vbroadcasti64x2 %1, %%zmm5\"\n\t\t\t     :\n\t\t\t     : \"m\" (qmul[0]), \"m\" (qmul[16]));\n\n\t\t \n\t\tasm volatile(\"vpsraw $4, %%zmm1, %%zmm3\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm3, %%zmm3\\n\\t\"\n\t\t\t     \"vpshufb %%zmm1, %%zmm4, %%zmm4\\n\\t\"\n\t\t\t     \"vpshufb %%zmm3, %%zmm5, %%zmm5\\n\\t\"\n\t\t\t     \"vpxorq %%zmm4, %%zmm5, %%zmm5\"\n\t\t\t     :\n\t\t\t     : );\n\n\t\t \n\n\t\tasm volatile(\"vbroadcasti64x2 %0, %%zmm4\\n\\t\"\n\t\t\t     \"vbroadcasti64x2 %1, %%zmm1\"\n\t\t\t     :\n\t\t\t     : \"m\" (pbmul[0]), \"m\" (pbmul[16]));\n\n\t\tasm volatile(\"vpsraw $4, %%zmm0, %%zmm2\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm0, %%zmm3\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm2, %%zmm2\\n\\t\"\n\t\t\t     \"vpshufb %%zmm3, %%zmm4, %%zmm4\\n\\t\"\n\t\t\t     \"vpshufb %%zmm2, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpxorq %%zmm4, %%zmm1, %%zmm1\"\n\t\t\t     :\n\t\t\t     : );\n\n\t\t \n\t\tasm volatile(\"vpxorq %%zmm5, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t      \n\t\t\t     \"vmovdqa64 %%zmm1, %0\\n\\t\"\n\t\t\t     :\n\t\t\t     : \"m\" (dq[0]));\n\n\t\tasm volatile(\"vpxorq %%zmm1, %%zmm0, %%zmm0\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm0, %0\"\n\t\t\t     :\n\t\t\t     : \"m\" (dp[0]));\n\n\t\tbytes -= 64;\n\t\tp += 64;\n\t\tq += 64;\n\t\tdp += 64;\n\t\tdq += 64;\n#endif\n\t}\n\n\tkernel_fpu_end();\n}\n\nstatic void raid6_datap_recov_avx512(int disks, size_t bytes, int faila,\n\t\t\t\t     void **ptrs)\n{\n\tu8 *p, *q, *dq;\n\tconst u8 *qmul;\t\t \n\tconst u8 x0f = 0x0f;\n\n\tp = (u8 *)ptrs[disks-2];\n\tq = (u8 *)ptrs[disks-1];\n\n\t \n\n\tdq = (u8 *)ptrs[faila];\n\tptrs[faila] = (void *)raid6_empty_zero_page;\n\tptrs[disks-1] = dq;\n\n\traid6_call.gen_syndrome(disks, bytes, ptrs);\n\n\t \n\tptrs[faila]   = dq;\n\tptrs[disks-1] = q;\n\n\t \n\tqmul  = raid6_vgfmul[raid6_gfinv[raid6_gfexp[faila]]];\n\n\tkernel_fpu_begin();\n\n\tasm volatile(\"vpbroadcastb %0, %%zmm7\" : : \"m\" (x0f));\n\n\twhile (bytes) {\n#ifdef CONFIG_X86_64\n\t\tasm volatile(\"vmovdqa64 %0, %%zmm3\\n\\t\"\n\t\t\t     \"vmovdqa64 %1, %%zmm8\\n\\t\"\n\t\t\t     \"vpxorq %2, %%zmm3, %%zmm3\\n\\t\"\n\t\t\t     \"vpxorq %3, %%zmm8, %%zmm8\"\n\t\t\t     :\n\t\t\t     : \"m\" (dq[0]), \"m\" (dq[64]), \"m\" (q[0]),\n\t\t\t       \"m\" (q[64]));\n\n\t\t \n\t\tasm volatile(\"vbroadcasti64x2 %0, %%zmm0\\n\\t\"\n\t\t\t     \"vmovapd %%zmm0, %%zmm13\\n\\t\"\n\t\t\t     \"vbroadcasti64x2 %1, %%zmm1\\n\\t\"\n\t\t\t     \"vmovapd %%zmm1, %%zmm14\"\n\t\t\t     :\n\t\t\t     : \"m\" (qmul[0]), \"m\" (qmul[16]));\n\n\t\tasm volatile(\"vpsraw $4, %%zmm3, %%zmm6\\n\\t\"\n\t\t\t     \"vpsraw $4, %%zmm8, %%zmm12\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm3, %%zmm3\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm8, %%zmm8\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm6, %%zmm6\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm12, %%zmm12\\n\\t\"\n\t\t\t     \"vpshufb %%zmm3, %%zmm0, %%zmm0\\n\\t\"\n\t\t\t     \"vpshufb %%zmm8, %%zmm13, %%zmm13\\n\\t\"\n\t\t\t     \"vpshufb %%zmm6, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpshufb %%zmm12, %%zmm14, %%zmm14\\n\\t\"\n\t\t\t     \"vpxorq %%zmm0, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpxorq %%zmm13, %%zmm14, %%zmm14\"\n\t\t\t     :\n\t\t\t     : );\n\n\t\t \n\t\tasm volatile(\"vmovdqa64 %0, %%zmm2\\n\\t\"\n\t\t\t     \"vmovdqa64 %1, %%zmm12\\n\\t\"\n\t\t\t     \"vpxorq %%zmm1, %%zmm2, %%zmm2\\n\\t\"\n\t\t\t     \"vpxorq %%zmm14, %%zmm12, %%zmm12\"\n\t\t\t     :\n\t\t\t     : \"m\" (p[0]), \"m\" (p[64]));\n\n\t\t \n\n\t\tasm volatile(\"vmovdqa64 %%zmm1, %0\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm14, %1\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm2, %2\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm12,%3\"\n\t\t\t     :\n\t\t\t     : \"m\" (dq[0]), \"m\" (dq[64]), \"m\" (p[0]),\n\t\t\t       \"m\" (p[64]));\n\n\t\tbytes -= 128;\n\t\tp += 128;\n\t\tq += 128;\n\t\tdq += 128;\n#else\n\t\tasm volatile(\"vmovdqa64 %0, %%zmm3\\n\\t\"\n\t\t\t     \"vpxorq %1, %%zmm3, %%zmm3\"\n\t\t\t     :\n\t\t\t     : \"m\" (dq[0]), \"m\" (q[0]));\n\n\t\t \n\n\t\tasm volatile(\"vbroadcasti64x2 %0, %%zmm0\\n\\t\"\n\t\t\t     \"vbroadcasti64x2 %1, %%zmm1\"\n\t\t\t     :\n\t\t\t     : \"m\" (qmul[0]), \"m\" (qmul[16]));\n\n\t\tasm volatile(\"vpsraw $4, %%zmm3, %%zmm6\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm3, %%zmm3\\n\\t\"\n\t\t\t     \"vpandq %%zmm7, %%zmm6, %%zmm6\\n\\t\"\n\t\t\t     \"vpshufb %%zmm3, %%zmm0, %%zmm0\\n\\t\"\n\t\t\t     \"vpshufb %%zmm6, %%zmm1, %%zmm1\\n\\t\"\n\t\t\t     \"vpxorq %%zmm0, %%zmm1, %%zmm1\"\n\t\t\t     :\n\t\t\t     : );\n\n\t\t \n\n\t\tasm volatile(\"vmovdqa64 %0, %%zmm2\\n\\t\"\n\t\t\t     \"vpxorq %%zmm1, %%zmm2, %%zmm2\"\n\t\t\t     :\n\t\t\t     : \"m\" (p[0]));\n\n\t\t \n\n\t\tasm volatile(\"vmovdqa64 %%zmm1, %0\\n\\t\"\n\t\t\t     \"vmovdqa64 %%zmm2, %1\"\n\t\t\t     :\n\t\t\t     : \"m\" (dq[0]), \"m\" (p[0]));\n\n\t\tbytes -= 64;\n\t\tp += 64;\n\t\tq += 64;\n\t\tdq += 64;\n#endif\n\t}\n\n\tkernel_fpu_end();\n}\n\nconst struct raid6_recov_calls raid6_recov_avx512 = {\n\t.data2 = raid6_2data_recov_avx512,\n\t.datap = raid6_datap_recov_avx512,\n\t.valid = raid6_has_avx512,\n#ifdef CONFIG_X86_64\n\t.name = \"avx512x2\",\n#else\n\t.name = \"avx512x1\",\n#endif\n\t.priority = 3,\n};\n\n#else\n#warning \"your version of binutils lacks AVX512 support\"\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}