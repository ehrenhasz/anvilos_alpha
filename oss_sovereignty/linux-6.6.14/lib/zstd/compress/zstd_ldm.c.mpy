{
  "module_name": "zstd_ldm.c",
  "hash_id": "cb546b0bb48e360a5c1b73ef83887b2edfecbae930c8a494391dc8e5287efe02",
  "original_prompt": "Ingested from linux-6.6.14/lib/zstd/compress/zstd_ldm.c",
  "human_readable_source": " \n\n#include \"zstd_ldm.h\"\n\n#include \"../common/debug.h\"\n#include <linux/xxhash.h>\n#include \"zstd_fast.h\"           \n#include \"zstd_double_fast.h\"    \n#include \"zstd_ldm_geartab.h\"\n\n#define LDM_BUCKET_SIZE_LOG 3\n#define LDM_MIN_MATCH_LENGTH 64\n#define LDM_HASH_RLOG 7\n\ntypedef struct {\n    U64 rolling;\n    U64 stopMask;\n} ldmRollingHashState_t;\n\n \nstatic void ZSTD_ldm_gear_init(ldmRollingHashState_t* state, ldmParams_t const* params)\n{\n    unsigned maxBitsInMask = MIN(params->minMatchLength, 64);\n    unsigned hashRateLog = params->hashRateLog;\n\n    state->rolling = ~(U32)0;\n\n     \n    if (hashRateLog > 0 && hashRateLog <= maxBitsInMask) {\n        state->stopMask = (((U64)1 << hashRateLog) - 1) << (maxBitsInMask - hashRateLog);\n    } else {\n         \n        state->stopMask = ((U64)1 << hashRateLog) - 1;\n    }\n}\n\n \nstatic void ZSTD_ldm_gear_reset(ldmRollingHashState_t* state,\n                                BYTE const* data, size_t minMatchLength)\n{\n    U64 hash = state->rolling;\n    size_t n = 0;\n\n#define GEAR_ITER_ONCE() do {                                  \\\n        hash = (hash << 1) + ZSTD_ldm_gearTab[data[n] & 0xff]; \\\n        n += 1;                                                \\\n    } while (0)\n    while (n + 3 < minMatchLength) {\n        GEAR_ITER_ONCE();\n        GEAR_ITER_ONCE();\n        GEAR_ITER_ONCE();\n        GEAR_ITER_ONCE();\n    }\n    while (n < minMatchLength) {\n        GEAR_ITER_ONCE();\n    }\n#undef GEAR_ITER_ONCE\n}\n\n \nstatic size_t ZSTD_ldm_gear_feed(ldmRollingHashState_t* state,\n                                 BYTE const* data, size_t size,\n                                 size_t* splits, unsigned* numSplits)\n{\n    size_t n;\n    U64 hash, mask;\n\n    hash = state->rolling;\n    mask = state->stopMask;\n    n = 0;\n\n#define GEAR_ITER_ONCE() do { \\\n        hash = (hash << 1) + ZSTD_ldm_gearTab[data[n] & 0xff]; \\\n        n += 1; \\\n        if (UNLIKELY((hash & mask) == 0)) { \\\n            splits[*numSplits] = n; \\\n            *numSplits += 1; \\\n            if (*numSplits == LDM_BATCH_SIZE) \\\n                goto done; \\\n        } \\\n    } while (0)\n\n    while (n + 3 < size) {\n        GEAR_ITER_ONCE();\n        GEAR_ITER_ONCE();\n        GEAR_ITER_ONCE();\n        GEAR_ITER_ONCE();\n    }\n    while (n < size) {\n        GEAR_ITER_ONCE();\n    }\n\n#undef GEAR_ITER_ONCE\n\ndone:\n    state->rolling = hash;\n    return n;\n}\n\nvoid ZSTD_ldm_adjustParameters(ldmParams_t* params,\n                               ZSTD_compressionParameters const* cParams)\n{\n    params->windowLog = cParams->windowLog;\n    ZSTD_STATIC_ASSERT(LDM_BUCKET_SIZE_LOG <= ZSTD_LDM_BUCKETSIZELOG_MAX);\n    DEBUGLOG(4, \"ZSTD_ldm_adjustParameters\");\n    if (!params->bucketSizeLog) params->bucketSizeLog = LDM_BUCKET_SIZE_LOG;\n    if (!params->minMatchLength) params->minMatchLength = LDM_MIN_MATCH_LENGTH;\n    if (params->hashLog == 0) {\n        params->hashLog = MAX(ZSTD_HASHLOG_MIN, params->windowLog - LDM_HASH_RLOG);\n        assert(params->hashLog <= ZSTD_HASHLOG_MAX);\n    }\n    if (params->hashRateLog == 0) {\n        params->hashRateLog = params->windowLog < params->hashLog\n                                   ? 0\n                                   : params->windowLog - params->hashLog;\n    }\n    params->bucketSizeLog = MIN(params->bucketSizeLog, params->hashLog);\n}\n\nsize_t ZSTD_ldm_getTableSize(ldmParams_t params)\n{\n    size_t const ldmHSize = ((size_t)1) << params.hashLog;\n    size_t const ldmBucketSizeLog = MIN(params.bucketSizeLog, params.hashLog);\n    size_t const ldmBucketSize = ((size_t)1) << (params.hashLog - ldmBucketSizeLog);\n    size_t const totalSize = ZSTD_cwksp_alloc_size(ldmBucketSize)\n                           + ZSTD_cwksp_alloc_size(ldmHSize * sizeof(ldmEntry_t));\n    return params.enableLdm == ZSTD_ps_enable ? totalSize : 0;\n}\n\nsize_t ZSTD_ldm_getMaxNbSeq(ldmParams_t params, size_t maxChunkSize)\n{\n    return params.enableLdm == ZSTD_ps_enable ? (maxChunkSize / params.minMatchLength) : 0;\n}\n\n \nstatic ldmEntry_t* ZSTD_ldm_getBucket(\n        ldmState_t* ldmState, size_t hash, ldmParams_t const ldmParams)\n{\n    return ldmState->hashTable + (hash << ldmParams.bucketSizeLog);\n}\n\n \nstatic void ZSTD_ldm_insertEntry(ldmState_t* ldmState,\n                                 size_t const hash, const ldmEntry_t entry,\n                                 ldmParams_t const ldmParams)\n{\n    BYTE* const pOffset = ldmState->bucketOffsets + hash;\n    unsigned const offset = *pOffset;\n\n    *(ZSTD_ldm_getBucket(ldmState, hash, ldmParams) + offset) = entry;\n    *pOffset = (BYTE)((offset + 1) & ((1u << ldmParams.bucketSizeLog) - 1));\n\n}\n\n \nstatic size_t ZSTD_ldm_countBackwardsMatch(\n            const BYTE* pIn, const BYTE* pAnchor,\n            const BYTE* pMatch, const BYTE* pMatchBase)\n{\n    size_t matchLength = 0;\n    while (pIn > pAnchor && pMatch > pMatchBase && pIn[-1] == pMatch[-1]) {\n        pIn--;\n        pMatch--;\n        matchLength++;\n    }\n    return matchLength;\n}\n\n \nstatic size_t ZSTD_ldm_countBackwardsMatch_2segments(\n                    const BYTE* pIn, const BYTE* pAnchor,\n                    const BYTE* pMatch, const BYTE* pMatchBase,\n                    const BYTE* pExtDictStart, const BYTE* pExtDictEnd)\n{\n    size_t matchLength = ZSTD_ldm_countBackwardsMatch(pIn, pAnchor, pMatch, pMatchBase);\n    if (pMatch - matchLength != pMatchBase || pMatchBase == pExtDictStart) {\n         \n        return matchLength;\n    }\n    DEBUGLOG(7, \"ZSTD_ldm_countBackwardsMatch_2segments: found 2-parts backwards match (length in prefix==%zu)\", matchLength);\n    matchLength += ZSTD_ldm_countBackwardsMatch(pIn - matchLength, pAnchor, pExtDictEnd, pExtDictStart);\n    DEBUGLOG(7, \"final backwards match length = %zu\", matchLength);\n    return matchLength;\n}\n\n \nstatic size_t ZSTD_ldm_fillFastTables(ZSTD_matchState_t* ms,\n                                      void const* end)\n{\n    const BYTE* const iend = (const BYTE*)end;\n\n    switch(ms->cParams.strategy)\n    {\n    case ZSTD_fast:\n        ZSTD_fillHashTable(ms, iend, ZSTD_dtlm_fast);\n        break;\n\n    case ZSTD_dfast:\n        ZSTD_fillDoubleHashTable(ms, iend, ZSTD_dtlm_fast);\n        break;\n\n    case ZSTD_greedy:\n    case ZSTD_lazy:\n    case ZSTD_lazy2:\n    case ZSTD_btlazy2:\n    case ZSTD_btopt:\n    case ZSTD_btultra:\n    case ZSTD_btultra2:\n        break;\n    default:\n        assert(0);   \n    }\n\n    return 0;\n}\n\nvoid ZSTD_ldm_fillHashTable(\n            ldmState_t* ldmState, const BYTE* ip,\n            const BYTE* iend, ldmParams_t const* params)\n{\n    U32 const minMatchLength = params->minMatchLength;\n    U32 const hBits = params->hashLog - params->bucketSizeLog;\n    BYTE const* const base = ldmState->window.base;\n    BYTE const* const istart = ip;\n    ldmRollingHashState_t hashState;\n    size_t* const splits = ldmState->splitIndices;\n    unsigned numSplits;\n\n    DEBUGLOG(5, \"ZSTD_ldm_fillHashTable\");\n\n    ZSTD_ldm_gear_init(&hashState, params);\n    while (ip < iend) {\n        size_t hashed;\n        unsigned n;\n\n        numSplits = 0;\n        hashed = ZSTD_ldm_gear_feed(&hashState, ip, iend - ip, splits, &numSplits);\n\n        for (n = 0; n < numSplits; n++) {\n            if (ip + splits[n] >= istart + minMatchLength) {\n                BYTE const* const split = ip + splits[n] - minMatchLength;\n                U64 const xxhash = xxh64(split, minMatchLength, 0);\n                U32 const hash = (U32)(xxhash & (((U32)1 << hBits) - 1));\n                ldmEntry_t entry;\n\n                entry.offset = (U32)(split - base);\n                entry.checksum = (U32)(xxhash >> 32);\n                ZSTD_ldm_insertEntry(ldmState, hash, entry, *params);\n            }\n        }\n\n        ip += hashed;\n    }\n}\n\n\n \nstatic void ZSTD_ldm_limitTableUpdate(ZSTD_matchState_t* ms, const BYTE* anchor)\n{\n    U32 const curr = (U32)(anchor - ms->window.base);\n    if (curr > ms->nextToUpdate + 1024) {\n        ms->nextToUpdate =\n            curr - MIN(512, curr - ms->nextToUpdate - 1024);\n    }\n}\n\nstatic size_t ZSTD_ldm_generateSequences_internal(\n        ldmState_t* ldmState, rawSeqStore_t* rawSeqStore,\n        ldmParams_t const* params, void const* src, size_t srcSize)\n{\n     \n    int const extDict = ZSTD_window_hasExtDict(ldmState->window);\n    U32 const minMatchLength = params->minMatchLength;\n    U32 const entsPerBucket = 1U << params->bucketSizeLog;\n    U32 const hBits = params->hashLog - params->bucketSizeLog;\n     \n    U32 const dictLimit = ldmState->window.dictLimit;\n    U32 const lowestIndex = extDict ? ldmState->window.lowLimit : dictLimit;\n    BYTE const* const base = ldmState->window.base;\n    BYTE const* const dictBase = extDict ? ldmState->window.dictBase : NULL;\n    BYTE const* const dictStart = extDict ? dictBase + lowestIndex : NULL;\n    BYTE const* const dictEnd = extDict ? dictBase + dictLimit : NULL;\n    BYTE const* const lowPrefixPtr = base + dictLimit;\n     \n    BYTE const* const istart = (BYTE const*)src;\n    BYTE const* const iend = istart + srcSize;\n    BYTE const* const ilimit = iend - HASH_READ_SIZE;\n     \n    BYTE const* anchor = istart;\n    BYTE const* ip = istart;\n     \n    ldmRollingHashState_t hashState;\n     \n    size_t* const splits = ldmState->splitIndices;\n    ldmMatchCandidate_t* const candidates = ldmState->matchCandidates;\n    unsigned numSplits;\n\n    if (srcSize < minMatchLength)\n        return iend - anchor;\n\n     \n    ZSTD_ldm_gear_init(&hashState, params);\n    ZSTD_ldm_gear_reset(&hashState, ip, minMatchLength);\n    ip += minMatchLength;\n\n    while (ip < ilimit) {\n        size_t hashed;\n        unsigned n;\n\n        numSplits = 0;\n        hashed = ZSTD_ldm_gear_feed(&hashState, ip, ilimit - ip,\n                                    splits, &numSplits);\n\n        for (n = 0; n < numSplits; n++) {\n            BYTE const* const split = ip + splits[n] - minMatchLength;\n            U64 const xxhash = xxh64(split, minMatchLength, 0);\n            U32 const hash = (U32)(xxhash & (((U32)1 << hBits) - 1));\n\n            candidates[n].split = split;\n            candidates[n].hash = hash;\n            candidates[n].checksum = (U32)(xxhash >> 32);\n            candidates[n].bucket = ZSTD_ldm_getBucket(ldmState, hash, *params);\n            PREFETCH_L1(candidates[n].bucket);\n        }\n\n        for (n = 0; n < numSplits; n++) {\n            size_t forwardMatchLength = 0, backwardMatchLength = 0,\n                   bestMatchLength = 0, mLength;\n            U32 offset;\n            BYTE const* const split = candidates[n].split;\n            U32 const checksum = candidates[n].checksum;\n            U32 const hash = candidates[n].hash;\n            ldmEntry_t* const bucket = candidates[n].bucket;\n            ldmEntry_t const* cur;\n            ldmEntry_t const* bestEntry = NULL;\n            ldmEntry_t newEntry;\n\n            newEntry.offset = (U32)(split - base);\n            newEntry.checksum = checksum;\n\n             \n            if (split < anchor) {\n                ZSTD_ldm_insertEntry(ldmState, hash, newEntry, *params);\n                continue;\n            }\n\n            for (cur = bucket; cur < bucket + entsPerBucket; cur++) {\n                size_t curForwardMatchLength, curBackwardMatchLength,\n                       curTotalMatchLength;\n                if (cur->checksum != checksum || cur->offset <= lowestIndex) {\n                    continue;\n                }\n                if (extDict) {\n                    BYTE const* const curMatchBase =\n                        cur->offset < dictLimit ? dictBase : base;\n                    BYTE const* const pMatch = curMatchBase + cur->offset;\n                    BYTE const* const matchEnd =\n                        cur->offset < dictLimit ? dictEnd : iend;\n                    BYTE const* const lowMatchPtr =\n                        cur->offset < dictLimit ? dictStart : lowPrefixPtr;\n                    curForwardMatchLength =\n                        ZSTD_count_2segments(split, pMatch, iend, matchEnd, lowPrefixPtr);\n                    if (curForwardMatchLength < minMatchLength) {\n                        continue;\n                    }\n                    curBackwardMatchLength = ZSTD_ldm_countBackwardsMatch_2segments(\n                            split, anchor, pMatch, lowMatchPtr, dictStart, dictEnd);\n                } else {  \n                    BYTE const* const pMatch = base + cur->offset;\n                    curForwardMatchLength = ZSTD_count(split, pMatch, iend);\n                    if (curForwardMatchLength < minMatchLength) {\n                        continue;\n                    }\n                    curBackwardMatchLength =\n                        ZSTD_ldm_countBackwardsMatch(split, anchor, pMatch, lowPrefixPtr);\n                }\n                curTotalMatchLength = curForwardMatchLength + curBackwardMatchLength;\n\n                if (curTotalMatchLength > bestMatchLength) {\n                    bestMatchLength = curTotalMatchLength;\n                    forwardMatchLength = curForwardMatchLength;\n                    backwardMatchLength = curBackwardMatchLength;\n                    bestEntry = cur;\n                }\n            }\n\n             \n            if (bestEntry == NULL) {\n                ZSTD_ldm_insertEntry(ldmState, hash, newEntry, *params);\n                continue;\n            }\n\n             \n            offset = (U32)(split - base) - bestEntry->offset;\n            mLength = forwardMatchLength + backwardMatchLength;\n            {\n                rawSeq* const seq = rawSeqStore->seq + rawSeqStore->size;\n\n                 \n                if (rawSeqStore->size == rawSeqStore->capacity)\n                    return ERROR(dstSize_tooSmall);\n                seq->litLength = (U32)(split - backwardMatchLength - anchor);\n                seq->matchLength = (U32)mLength;\n                seq->offset = offset;\n                rawSeqStore->size++;\n            }\n\n             \n            ZSTD_ldm_insertEntry(ldmState, hash, newEntry, *params);\n\n            anchor = split + forwardMatchLength;\n\n             \n            if (anchor > ip + hashed) {\n                ZSTD_ldm_gear_reset(&hashState, anchor - minMatchLength, minMatchLength);\n                 \n                ip = anchor - hashed;\n                break;\n            }\n        }\n\n        ip += hashed;\n    }\n\n    return iend - anchor;\n}\n\n \nstatic void ZSTD_ldm_reduceTable(ldmEntry_t* const table, U32 const size,\n                                 U32 const reducerValue)\n{\n    U32 u;\n    for (u = 0; u < size; u++) {\n        if (table[u].offset < reducerValue) table[u].offset = 0;\n        else table[u].offset -= reducerValue;\n    }\n}\n\nsize_t ZSTD_ldm_generateSequences(\n        ldmState_t* ldmState, rawSeqStore_t* sequences,\n        ldmParams_t const* params, void const* src, size_t srcSize)\n{\n    U32 const maxDist = 1U << params->windowLog;\n    BYTE const* const istart = (BYTE const*)src;\n    BYTE const* const iend = istart + srcSize;\n    size_t const kMaxChunkSize = 1 << 20;\n    size_t const nbChunks = (srcSize / kMaxChunkSize) + ((srcSize % kMaxChunkSize) != 0);\n    size_t chunk;\n    size_t leftoverSize = 0;\n\n    assert(ZSTD_CHUNKSIZE_MAX >= kMaxChunkSize);\n     \n    assert(ldmState->window.nextSrc >= (BYTE const*)src + srcSize);\n     \n    assert(sequences->pos <= sequences->size);\n    assert(sequences->size <= sequences->capacity);\n    for (chunk = 0; chunk < nbChunks && sequences->size < sequences->capacity; ++chunk) {\n        BYTE const* const chunkStart = istart + chunk * kMaxChunkSize;\n        size_t const remaining = (size_t)(iend - chunkStart);\n        BYTE const *const chunkEnd =\n            (remaining < kMaxChunkSize) ? iend : chunkStart + kMaxChunkSize;\n        size_t const chunkSize = chunkEnd - chunkStart;\n        size_t newLeftoverSize;\n        size_t const prevSize = sequences->size;\n\n        assert(chunkStart < iend);\n         \n        if (ZSTD_window_needOverflowCorrection(ldmState->window, 0, maxDist, ldmState->loadedDictEnd, chunkStart, chunkEnd)) {\n            U32 const ldmHSize = 1U << params->hashLog;\n            U32 const correction = ZSTD_window_correctOverflow(\n                &ldmState->window,   0, maxDist, chunkStart);\n            ZSTD_ldm_reduceTable(ldmState->hashTable, ldmHSize, correction);\n             \n            ldmState->loadedDictEnd = 0;\n        }\n         \n        ZSTD_window_enforceMaxDist(&ldmState->window, chunkEnd, maxDist, &ldmState->loadedDictEnd, NULL);\n         \n        newLeftoverSize = ZSTD_ldm_generateSequences_internal(\n            ldmState, sequences, params, chunkStart, chunkSize);\n        if (ZSTD_isError(newLeftoverSize))\n            return newLeftoverSize;\n         \n         \n        if (prevSize < sequences->size) {\n            sequences->seq[prevSize].litLength += (U32)leftoverSize;\n            leftoverSize = newLeftoverSize;\n        } else {\n            assert(newLeftoverSize == chunkSize);\n            leftoverSize += chunkSize;\n        }\n    }\n    return 0;\n}\n\nvoid\nZSTD_ldm_skipSequences(rawSeqStore_t* rawSeqStore, size_t srcSize, U32 const minMatch)\n{\n    while (srcSize > 0 && rawSeqStore->pos < rawSeqStore->size) {\n        rawSeq* seq = rawSeqStore->seq + rawSeqStore->pos;\n        if (srcSize <= seq->litLength) {\n             \n            seq->litLength -= (U32)srcSize;\n            return;\n        }\n        srcSize -= seq->litLength;\n        seq->litLength = 0;\n        if (srcSize < seq->matchLength) {\n             \n            seq->matchLength -= (U32)srcSize;\n            if (seq->matchLength < minMatch) {\n                 \n                if (rawSeqStore->pos + 1 < rawSeqStore->size) {\n                    seq[1].litLength += seq[0].matchLength;\n                }\n                rawSeqStore->pos++;\n            }\n            return;\n        }\n        srcSize -= seq->matchLength;\n        seq->matchLength = 0;\n        rawSeqStore->pos++;\n    }\n}\n\n \nstatic rawSeq maybeSplitSequence(rawSeqStore_t* rawSeqStore,\n                                 U32 const remaining, U32 const minMatch)\n{\n    rawSeq sequence = rawSeqStore->seq[rawSeqStore->pos];\n    assert(sequence.offset > 0);\n     \n    if (remaining >= sequence.litLength + sequence.matchLength) {\n        rawSeqStore->pos++;\n        return sequence;\n    }\n     \n    if (remaining <= sequence.litLength) {\n        sequence.offset = 0;\n    } else if (remaining < sequence.litLength + sequence.matchLength) {\n        sequence.matchLength = remaining - sequence.litLength;\n        if (sequence.matchLength < minMatch) {\n            sequence.offset = 0;\n        }\n    }\n     \n    ZSTD_ldm_skipSequences(rawSeqStore, remaining, minMatch);\n    return sequence;\n}\n\nvoid ZSTD_ldm_skipRawSeqStoreBytes(rawSeqStore_t* rawSeqStore, size_t nbBytes) {\n    U32 currPos = (U32)(rawSeqStore->posInSequence + nbBytes);\n    while (currPos && rawSeqStore->pos < rawSeqStore->size) {\n        rawSeq currSeq = rawSeqStore->seq[rawSeqStore->pos];\n        if (currPos >= currSeq.litLength + currSeq.matchLength) {\n            currPos -= currSeq.litLength + currSeq.matchLength;\n            rawSeqStore->pos++;\n        } else {\n            rawSeqStore->posInSequence = currPos;\n            break;\n        }\n    }\n    if (currPos == 0 || rawSeqStore->pos == rawSeqStore->size) {\n        rawSeqStore->posInSequence = 0;\n    }\n}\n\nsize_t ZSTD_ldm_blockCompress(rawSeqStore_t* rawSeqStore,\n    ZSTD_matchState_t* ms, seqStore_t* seqStore, U32 rep[ZSTD_REP_NUM],\n    ZSTD_paramSwitch_e useRowMatchFinder,\n    void const* src, size_t srcSize)\n{\n    const ZSTD_compressionParameters* const cParams = &ms->cParams;\n    unsigned const minMatch = cParams->minMatch;\n    ZSTD_blockCompressor const blockCompressor =\n        ZSTD_selectBlockCompressor(cParams->strategy, useRowMatchFinder, ZSTD_matchState_dictMode(ms));\n     \n    BYTE const* const istart = (BYTE const*)src;\n    BYTE const* const iend = istart + srcSize;\n     \n    BYTE const* ip = istart;\n\n    DEBUGLOG(5, \"ZSTD_ldm_blockCompress: srcSize=%zu\", srcSize);\n     \n    if (cParams->strategy >= ZSTD_btopt) {\n        size_t lastLLSize;\n        ms->ldmSeqStore = rawSeqStore;\n        lastLLSize = blockCompressor(ms, seqStore, rep, src, srcSize);\n        ZSTD_ldm_skipRawSeqStoreBytes(rawSeqStore, srcSize);\n        return lastLLSize;\n    }\n\n    assert(rawSeqStore->pos <= rawSeqStore->size);\n    assert(rawSeqStore->size <= rawSeqStore->capacity);\n     \n    while (rawSeqStore->pos < rawSeqStore->size && ip < iend) {\n         \n        rawSeq const sequence = maybeSplitSequence(rawSeqStore,\n                                                   (U32)(iend - ip), minMatch);\n        int i;\n         \n        if (sequence.offset == 0)\n            break;\n\n        assert(ip + sequence.litLength + sequence.matchLength <= iend);\n\n         \n        ZSTD_ldm_limitTableUpdate(ms, ip);\n        ZSTD_ldm_fillFastTables(ms, ip);\n         \n        DEBUGLOG(5, \"pos %u : calling block compressor on segment of size %u\", (unsigned)(ip-istart), sequence.litLength);\n        {\n            size_t const newLitLength =\n                blockCompressor(ms, seqStore, rep, ip, sequence.litLength);\n            ip += sequence.litLength;\n             \n            for (i = ZSTD_REP_NUM - 1; i > 0; i--)\n                rep[i] = rep[i-1];\n            rep[0] = sequence.offset;\n             \n            ZSTD_storeSeq(seqStore, newLitLength, ip - newLitLength, iend,\n                          STORE_OFFSET(sequence.offset),\n                          sequence.matchLength);\n            ip += sequence.matchLength;\n        }\n    }\n     \n    ZSTD_ldm_limitTableUpdate(ms, ip);\n    ZSTD_ldm_fillFastTables(ms, ip);\n     \n    return blockCompressor(ms, seqStore, rep, ip, iend - ip);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}