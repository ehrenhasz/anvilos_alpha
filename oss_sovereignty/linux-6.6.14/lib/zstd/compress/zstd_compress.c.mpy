{
  "module_name": "zstd_compress.c",
  "hash_id": "4b51f318d02cd8380bfe65aeb584be9bd6ca817bdf420745bb9dbf2fc98abaf8",
  "original_prompt": "Ingested from linux-6.6.14/lib/zstd/compress/zstd_compress.c",
  "human_readable_source": " \n\n \n#include \"../common/zstd_deps.h\"   \n#include \"../common/mem.h\"\n#include \"hist.h\"            \n#define FSE_STATIC_LINKING_ONLY    \n#include \"../common/fse.h\"\n#define HUF_STATIC_LINKING_ONLY\n#include \"../common/huf.h\"\n#include \"zstd_compress_internal.h\"\n#include \"zstd_compress_sequences.h\"\n#include \"zstd_compress_literals.h\"\n#include \"zstd_fast.h\"\n#include \"zstd_double_fast.h\"\n#include \"zstd_lazy.h\"\n#include \"zstd_opt.h\"\n#include \"zstd_ldm.h\"\n#include \"zstd_compress_superblock.h\"\n\n \n \n\n \n#ifndef ZSTD_HASHLOG3_MAX\n#  define ZSTD_HASHLOG3_MAX 17\n#endif\n\n \n \nsize_t ZSTD_compressBound(size_t srcSize) {\n    return ZSTD_COMPRESSBOUND(srcSize);\n}\n\n\n \nstruct ZSTD_CDict_s {\n    const void* dictContent;\n    size_t dictContentSize;\n    ZSTD_dictContentType_e dictContentType;  \n    U32* entropyWorkspace;  \n    ZSTD_cwksp workspace;\n    ZSTD_matchState_t matchState;\n    ZSTD_compressedBlockState_t cBlockState;\n    ZSTD_customMem customMem;\n    U32 dictID;\n    int compressionLevel;  \n    ZSTD_paramSwitch_e useRowMatchFinder;  \n};   \n\nZSTD_CCtx* ZSTD_createCCtx(void)\n{\n    return ZSTD_createCCtx_advanced(ZSTD_defaultCMem);\n}\n\nstatic void ZSTD_initCCtx(ZSTD_CCtx* cctx, ZSTD_customMem memManager)\n{\n    assert(cctx != NULL);\n    ZSTD_memset(cctx, 0, sizeof(*cctx));\n    cctx->customMem = memManager;\n    cctx->bmi2 = ZSTD_cpuSupportsBmi2();\n    {   size_t const err = ZSTD_CCtx_reset(cctx, ZSTD_reset_parameters);\n        assert(!ZSTD_isError(err));\n        (void)err;\n    }\n}\n\nZSTD_CCtx* ZSTD_createCCtx_advanced(ZSTD_customMem customMem)\n{\n    ZSTD_STATIC_ASSERT(zcss_init==0);\n    ZSTD_STATIC_ASSERT(ZSTD_CONTENTSIZE_UNKNOWN==(0ULL - 1));\n    if ((!customMem.customAlloc) ^ (!customMem.customFree)) return NULL;\n    {   ZSTD_CCtx* const cctx = (ZSTD_CCtx*)ZSTD_customMalloc(sizeof(ZSTD_CCtx), customMem);\n        if (!cctx) return NULL;\n        ZSTD_initCCtx(cctx, customMem);\n        return cctx;\n    }\n}\n\nZSTD_CCtx* ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize)\n{\n    ZSTD_cwksp ws;\n    ZSTD_CCtx* cctx;\n    if (workspaceSize <= sizeof(ZSTD_CCtx)) return NULL;   \n    if ((size_t)workspace & 7) return NULL;   \n    ZSTD_cwksp_init(&ws, workspace, workspaceSize, ZSTD_cwksp_static_alloc);\n\n    cctx = (ZSTD_CCtx*)ZSTD_cwksp_reserve_object(&ws, sizeof(ZSTD_CCtx));\n    if (cctx == NULL) return NULL;\n\n    ZSTD_memset(cctx, 0, sizeof(ZSTD_CCtx));\n    ZSTD_cwksp_move(&cctx->workspace, &ws);\n    cctx->staticSize = workspaceSize;\n\n     \n    if (!ZSTD_cwksp_check_available(&cctx->workspace, ENTROPY_WORKSPACE_SIZE + 2 * sizeof(ZSTD_compressedBlockState_t))) return NULL;\n    cctx->blockState.prevCBlock = (ZSTD_compressedBlockState_t*)ZSTD_cwksp_reserve_object(&cctx->workspace, sizeof(ZSTD_compressedBlockState_t));\n    cctx->blockState.nextCBlock = (ZSTD_compressedBlockState_t*)ZSTD_cwksp_reserve_object(&cctx->workspace, sizeof(ZSTD_compressedBlockState_t));\n    cctx->entropyWorkspace = (U32*)ZSTD_cwksp_reserve_object(&cctx->workspace, ENTROPY_WORKSPACE_SIZE);\n    cctx->bmi2 = ZSTD_cpuid_bmi2(ZSTD_cpuid());\n    return cctx;\n}\n\n \nstatic void ZSTD_clearAllDicts(ZSTD_CCtx* cctx)\n{\n    ZSTD_customFree(cctx->localDict.dictBuffer, cctx->customMem);\n    ZSTD_freeCDict(cctx->localDict.cdict);\n    ZSTD_memset(&cctx->localDict, 0, sizeof(cctx->localDict));\n    ZSTD_memset(&cctx->prefixDict, 0, sizeof(cctx->prefixDict));\n    cctx->cdict = NULL;\n}\n\nstatic size_t ZSTD_sizeof_localDict(ZSTD_localDict dict)\n{\n    size_t const bufferSize = dict.dictBuffer != NULL ? dict.dictSize : 0;\n    size_t const cdictSize = ZSTD_sizeof_CDict(dict.cdict);\n    return bufferSize + cdictSize;\n}\n\nstatic void ZSTD_freeCCtxContent(ZSTD_CCtx* cctx)\n{\n    assert(cctx != NULL);\n    assert(cctx->staticSize == 0);\n    ZSTD_clearAllDicts(cctx);\n    ZSTD_cwksp_free(&cctx->workspace, cctx->customMem);\n}\n\nsize_t ZSTD_freeCCtx(ZSTD_CCtx* cctx)\n{\n    if (cctx==NULL) return 0;    \n    RETURN_ERROR_IF(cctx->staticSize, memory_allocation,\n                    \"not compatible with static CCtx\");\n    {\n        int cctxInWorkspace = ZSTD_cwksp_owns_buffer(&cctx->workspace, cctx);\n        ZSTD_freeCCtxContent(cctx);\n        if (!cctxInWorkspace) {\n            ZSTD_customFree(cctx, cctx->customMem);\n        }\n    }\n    return 0;\n}\n\n\nstatic size_t ZSTD_sizeof_mtctx(const ZSTD_CCtx* cctx)\n{\n    (void)cctx;\n    return 0;\n}\n\n\nsize_t ZSTD_sizeof_CCtx(const ZSTD_CCtx* cctx)\n{\n    if (cctx==NULL) return 0;    \n     \n    return (cctx->workspace.workspace == cctx ? 0 : sizeof(*cctx))\n           + ZSTD_cwksp_sizeof(&cctx->workspace)\n           + ZSTD_sizeof_localDict(cctx->localDict)\n           + ZSTD_sizeof_mtctx(cctx);\n}\n\nsize_t ZSTD_sizeof_CStream(const ZSTD_CStream* zcs)\n{\n    return ZSTD_sizeof_CCtx(zcs);   \n}\n\n \nconst seqStore_t* ZSTD_getSeqStore(const ZSTD_CCtx* ctx) { return &(ctx->seqStore); }\n\n \nstatic int ZSTD_rowMatchFinderSupported(const ZSTD_strategy strategy) {\n    return (strategy >= ZSTD_greedy && strategy <= ZSTD_lazy2);\n}\n\n \nstatic int ZSTD_rowMatchFinderUsed(const ZSTD_strategy strategy, const ZSTD_paramSwitch_e mode) {\n    assert(mode != ZSTD_ps_auto);\n    return ZSTD_rowMatchFinderSupported(strategy) && (mode == ZSTD_ps_enable);\n}\n\n \nstatic ZSTD_paramSwitch_e ZSTD_resolveRowMatchFinderMode(ZSTD_paramSwitch_e mode,\n                                                         const ZSTD_compressionParameters* const cParams) {\n#if defined(ZSTD_ARCH_X86_SSE2) || defined(ZSTD_ARCH_ARM_NEON)\n    int const kHasSIMD128 = 1;\n#else\n    int const kHasSIMD128 = 0;\n#endif\n    if (mode != ZSTD_ps_auto) return mode;  \n    mode = ZSTD_ps_disable;\n    if (!ZSTD_rowMatchFinderSupported(cParams->strategy)) return mode;\n    if (kHasSIMD128) {\n        if (cParams->windowLog > 14) mode = ZSTD_ps_enable;\n    } else {\n        if (cParams->windowLog > 17) mode = ZSTD_ps_enable;\n    }\n    return mode;\n}\n\n \nstatic ZSTD_paramSwitch_e ZSTD_resolveBlockSplitterMode(ZSTD_paramSwitch_e mode,\n                                                        const ZSTD_compressionParameters* const cParams) {\n    if (mode != ZSTD_ps_auto) return mode;\n    return (cParams->strategy >= ZSTD_btopt && cParams->windowLog >= 17) ? ZSTD_ps_enable : ZSTD_ps_disable;\n}\n\n \nstatic int ZSTD_allocateChainTable(const ZSTD_strategy strategy,\n                                   const ZSTD_paramSwitch_e useRowMatchFinder,\n                                   const U32 forDDSDict) {\n    assert(useRowMatchFinder != ZSTD_ps_auto);\n     \n    return forDDSDict || ((strategy != ZSTD_fast) && !ZSTD_rowMatchFinderUsed(strategy, useRowMatchFinder));\n}\n\n \nstatic ZSTD_paramSwitch_e ZSTD_resolveEnableLdm(ZSTD_paramSwitch_e mode,\n                                 const ZSTD_compressionParameters* const cParams) {\n    if (mode != ZSTD_ps_auto) return mode;\n    return (cParams->strategy >= ZSTD_btopt && cParams->windowLog >= 27) ? ZSTD_ps_enable : ZSTD_ps_disable;\n}\n\nstatic ZSTD_CCtx_params ZSTD_makeCCtxParamsFromCParams(\n        ZSTD_compressionParameters cParams)\n{\n    ZSTD_CCtx_params cctxParams;\n     \n    ZSTD_CCtxParams_init(&cctxParams, ZSTD_CLEVEL_DEFAULT);\n    cctxParams.cParams = cParams;\n\n     \n    cctxParams.ldmParams.enableLdm = ZSTD_resolveEnableLdm(cctxParams.ldmParams.enableLdm, &cParams);\n    if (cctxParams.ldmParams.enableLdm == ZSTD_ps_enable) {\n        ZSTD_ldm_adjustParameters(&cctxParams.ldmParams, &cParams);\n        assert(cctxParams.ldmParams.hashLog >= cctxParams.ldmParams.bucketSizeLog);\n        assert(cctxParams.ldmParams.hashRateLog < 32);\n    }\n    cctxParams.useBlockSplitter = ZSTD_resolveBlockSplitterMode(cctxParams.useBlockSplitter, &cParams);\n    cctxParams.useRowMatchFinder = ZSTD_resolveRowMatchFinderMode(cctxParams.useRowMatchFinder, &cParams);\n    assert(!ZSTD_checkCParams(cParams));\n    return cctxParams;\n}\n\nstatic ZSTD_CCtx_params* ZSTD_createCCtxParams_advanced(\n        ZSTD_customMem customMem)\n{\n    ZSTD_CCtx_params* params;\n    if ((!customMem.customAlloc) ^ (!customMem.customFree)) return NULL;\n    params = (ZSTD_CCtx_params*)ZSTD_customCalloc(\n            sizeof(ZSTD_CCtx_params), customMem);\n    if (!params) { return NULL; }\n    ZSTD_CCtxParams_init(params, ZSTD_CLEVEL_DEFAULT);\n    params->customMem = customMem;\n    return params;\n}\n\nZSTD_CCtx_params* ZSTD_createCCtxParams(void)\n{\n    return ZSTD_createCCtxParams_advanced(ZSTD_defaultCMem);\n}\n\nsize_t ZSTD_freeCCtxParams(ZSTD_CCtx_params* params)\n{\n    if (params == NULL) { return 0; }\n    ZSTD_customFree(params, params->customMem);\n    return 0;\n}\n\nsize_t ZSTD_CCtxParams_reset(ZSTD_CCtx_params* params)\n{\n    return ZSTD_CCtxParams_init(params, ZSTD_CLEVEL_DEFAULT);\n}\n\nsize_t ZSTD_CCtxParams_init(ZSTD_CCtx_params* cctxParams, int compressionLevel) {\n    RETURN_ERROR_IF(!cctxParams, GENERIC, \"NULL pointer!\");\n    ZSTD_memset(cctxParams, 0, sizeof(*cctxParams));\n    cctxParams->compressionLevel = compressionLevel;\n    cctxParams->fParams.contentSizeFlag = 1;\n    return 0;\n}\n\n#define ZSTD_NO_CLEVEL 0\n\n \nstatic void ZSTD_CCtxParams_init_internal(ZSTD_CCtx_params* cctxParams, ZSTD_parameters const* params, int compressionLevel)\n{\n    assert(!ZSTD_checkCParams(params->cParams));\n    ZSTD_memset(cctxParams, 0, sizeof(*cctxParams));\n    cctxParams->cParams = params->cParams;\n    cctxParams->fParams = params->fParams;\n     \n    cctxParams->compressionLevel = compressionLevel;\n    cctxParams->useRowMatchFinder = ZSTD_resolveRowMatchFinderMode(cctxParams->useRowMatchFinder, &params->cParams);\n    cctxParams->useBlockSplitter = ZSTD_resolveBlockSplitterMode(cctxParams->useBlockSplitter, &params->cParams);\n    cctxParams->ldmParams.enableLdm = ZSTD_resolveEnableLdm(cctxParams->ldmParams.enableLdm, &params->cParams);\n    DEBUGLOG(4, \"ZSTD_CCtxParams_init_internal: useRowMatchFinder=%d, useBlockSplitter=%d ldm=%d\",\n                cctxParams->useRowMatchFinder, cctxParams->useBlockSplitter, cctxParams->ldmParams.enableLdm);\n}\n\nsize_t ZSTD_CCtxParams_init_advanced(ZSTD_CCtx_params* cctxParams, ZSTD_parameters params)\n{\n    RETURN_ERROR_IF(!cctxParams, GENERIC, \"NULL pointer!\");\n    FORWARD_IF_ERROR( ZSTD_checkCParams(params.cParams) , \"\");\n    ZSTD_CCtxParams_init_internal(cctxParams, &params, ZSTD_NO_CLEVEL);\n    return 0;\n}\n\n \nstatic void ZSTD_CCtxParams_setZstdParams(\n        ZSTD_CCtx_params* cctxParams, const ZSTD_parameters* params)\n{\n    assert(!ZSTD_checkCParams(params->cParams));\n    cctxParams->cParams = params->cParams;\n    cctxParams->fParams = params->fParams;\n     \n    cctxParams->compressionLevel = ZSTD_NO_CLEVEL;\n}\n\nZSTD_bounds ZSTD_cParam_getBounds(ZSTD_cParameter param)\n{\n    ZSTD_bounds bounds = { 0, 0, 0 };\n\n    switch(param)\n    {\n    case ZSTD_c_compressionLevel:\n        bounds.lowerBound = ZSTD_minCLevel();\n        bounds.upperBound = ZSTD_maxCLevel();\n        return bounds;\n\n    case ZSTD_c_windowLog:\n        bounds.lowerBound = ZSTD_WINDOWLOG_MIN;\n        bounds.upperBound = ZSTD_WINDOWLOG_MAX;\n        return bounds;\n\n    case ZSTD_c_hashLog:\n        bounds.lowerBound = ZSTD_HASHLOG_MIN;\n        bounds.upperBound = ZSTD_HASHLOG_MAX;\n        return bounds;\n\n    case ZSTD_c_chainLog:\n        bounds.lowerBound = ZSTD_CHAINLOG_MIN;\n        bounds.upperBound = ZSTD_CHAINLOG_MAX;\n        return bounds;\n\n    case ZSTD_c_searchLog:\n        bounds.lowerBound = ZSTD_SEARCHLOG_MIN;\n        bounds.upperBound = ZSTD_SEARCHLOG_MAX;\n        return bounds;\n\n    case ZSTD_c_minMatch:\n        bounds.lowerBound = ZSTD_MINMATCH_MIN;\n        bounds.upperBound = ZSTD_MINMATCH_MAX;\n        return bounds;\n\n    case ZSTD_c_targetLength:\n        bounds.lowerBound = ZSTD_TARGETLENGTH_MIN;\n        bounds.upperBound = ZSTD_TARGETLENGTH_MAX;\n        return bounds;\n\n    case ZSTD_c_strategy:\n        bounds.lowerBound = ZSTD_STRATEGY_MIN;\n        bounds.upperBound = ZSTD_STRATEGY_MAX;\n        return bounds;\n\n    case ZSTD_c_contentSizeFlag:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 1;\n        return bounds;\n\n    case ZSTD_c_checksumFlag:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 1;\n        return bounds;\n\n    case ZSTD_c_dictIDFlag:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 1;\n        return bounds;\n\n    case ZSTD_c_nbWorkers:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 0;\n        return bounds;\n\n    case ZSTD_c_jobSize:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 0;\n        return bounds;\n\n    case ZSTD_c_overlapLog:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 0;\n        return bounds;\n\n    case ZSTD_c_enableDedicatedDictSearch:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 1;\n        return bounds;\n\n    case ZSTD_c_enableLongDistanceMatching:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 1;\n        return bounds;\n\n    case ZSTD_c_ldmHashLog:\n        bounds.lowerBound = ZSTD_LDM_HASHLOG_MIN;\n        bounds.upperBound = ZSTD_LDM_HASHLOG_MAX;\n        return bounds;\n\n    case ZSTD_c_ldmMinMatch:\n        bounds.lowerBound = ZSTD_LDM_MINMATCH_MIN;\n        bounds.upperBound = ZSTD_LDM_MINMATCH_MAX;\n        return bounds;\n\n    case ZSTD_c_ldmBucketSizeLog:\n        bounds.lowerBound = ZSTD_LDM_BUCKETSIZELOG_MIN;\n        bounds.upperBound = ZSTD_LDM_BUCKETSIZELOG_MAX;\n        return bounds;\n\n    case ZSTD_c_ldmHashRateLog:\n        bounds.lowerBound = ZSTD_LDM_HASHRATELOG_MIN;\n        bounds.upperBound = ZSTD_LDM_HASHRATELOG_MAX;\n        return bounds;\n\n     \n    case ZSTD_c_rsyncable:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 1;\n        return bounds;\n\n    case ZSTD_c_forceMaxWindow :\n        bounds.lowerBound = 0;\n        bounds.upperBound = 1;\n        return bounds;\n\n    case ZSTD_c_format:\n        ZSTD_STATIC_ASSERT(ZSTD_f_zstd1 < ZSTD_f_zstd1_magicless);\n        bounds.lowerBound = ZSTD_f_zstd1;\n        bounds.upperBound = ZSTD_f_zstd1_magicless;    \n        return bounds;\n\n    case ZSTD_c_forceAttachDict:\n        ZSTD_STATIC_ASSERT(ZSTD_dictDefaultAttach < ZSTD_dictForceLoad);\n        bounds.lowerBound = ZSTD_dictDefaultAttach;\n        bounds.upperBound = ZSTD_dictForceLoad;        \n        return bounds;\n\n    case ZSTD_c_literalCompressionMode:\n        ZSTD_STATIC_ASSERT(ZSTD_ps_auto < ZSTD_ps_enable && ZSTD_ps_enable < ZSTD_ps_disable);\n        bounds.lowerBound = (int)ZSTD_ps_auto;\n        bounds.upperBound = (int)ZSTD_ps_disable;\n        return bounds;\n\n    case ZSTD_c_targetCBlockSize:\n        bounds.lowerBound = ZSTD_TARGETCBLOCKSIZE_MIN;\n        bounds.upperBound = ZSTD_TARGETCBLOCKSIZE_MAX;\n        return bounds;\n\n    case ZSTD_c_srcSizeHint:\n        bounds.lowerBound = ZSTD_SRCSIZEHINT_MIN;\n        bounds.upperBound = ZSTD_SRCSIZEHINT_MAX;\n        return bounds;\n\n    case ZSTD_c_stableInBuffer:\n    case ZSTD_c_stableOutBuffer:\n        bounds.lowerBound = (int)ZSTD_bm_buffered;\n        bounds.upperBound = (int)ZSTD_bm_stable;\n        return bounds;\n\n    case ZSTD_c_blockDelimiters:\n        bounds.lowerBound = (int)ZSTD_sf_noBlockDelimiters;\n        bounds.upperBound = (int)ZSTD_sf_explicitBlockDelimiters;\n        return bounds;\n\n    case ZSTD_c_validateSequences:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 1;\n        return bounds;\n\n    case ZSTD_c_useBlockSplitter:\n        bounds.lowerBound = (int)ZSTD_ps_auto;\n        bounds.upperBound = (int)ZSTD_ps_disable;\n        return bounds;\n\n    case ZSTD_c_useRowMatchFinder:\n        bounds.lowerBound = (int)ZSTD_ps_auto;\n        bounds.upperBound = (int)ZSTD_ps_disable;\n        return bounds;\n\n    case ZSTD_c_deterministicRefPrefix:\n        bounds.lowerBound = 0;\n        bounds.upperBound = 1;\n        return bounds;\n\n    default:\n        bounds.error = ERROR(parameter_unsupported);\n        return bounds;\n    }\n}\n\n \nstatic size_t ZSTD_cParam_clampBounds(ZSTD_cParameter cParam, int* value)\n{\n    ZSTD_bounds const bounds = ZSTD_cParam_getBounds(cParam);\n    if (ZSTD_isError(bounds.error)) return bounds.error;\n    if (*value < bounds.lowerBound) *value = bounds.lowerBound;\n    if (*value > bounds.upperBound) *value = bounds.upperBound;\n    return 0;\n}\n\n#define BOUNDCHECK(cParam, val) { \\\n    RETURN_ERROR_IF(!ZSTD_cParam_withinBounds(cParam,val), \\\n                    parameter_outOfBound, \"Param out of bounds\"); \\\n}\n\n\nstatic int ZSTD_isUpdateAuthorized(ZSTD_cParameter param)\n{\n    switch(param)\n    {\n    case ZSTD_c_compressionLevel:\n    case ZSTD_c_hashLog:\n    case ZSTD_c_chainLog:\n    case ZSTD_c_searchLog:\n    case ZSTD_c_minMatch:\n    case ZSTD_c_targetLength:\n    case ZSTD_c_strategy:\n        return 1;\n\n    case ZSTD_c_format:\n    case ZSTD_c_windowLog:\n    case ZSTD_c_contentSizeFlag:\n    case ZSTD_c_checksumFlag:\n    case ZSTD_c_dictIDFlag:\n    case ZSTD_c_forceMaxWindow :\n    case ZSTD_c_nbWorkers:\n    case ZSTD_c_jobSize:\n    case ZSTD_c_overlapLog:\n    case ZSTD_c_rsyncable:\n    case ZSTD_c_enableDedicatedDictSearch:\n    case ZSTD_c_enableLongDistanceMatching:\n    case ZSTD_c_ldmHashLog:\n    case ZSTD_c_ldmMinMatch:\n    case ZSTD_c_ldmBucketSizeLog:\n    case ZSTD_c_ldmHashRateLog:\n    case ZSTD_c_forceAttachDict:\n    case ZSTD_c_literalCompressionMode:\n    case ZSTD_c_targetCBlockSize:\n    case ZSTD_c_srcSizeHint:\n    case ZSTD_c_stableInBuffer:\n    case ZSTD_c_stableOutBuffer:\n    case ZSTD_c_blockDelimiters:\n    case ZSTD_c_validateSequences:\n    case ZSTD_c_useBlockSplitter:\n    case ZSTD_c_useRowMatchFinder:\n    case ZSTD_c_deterministicRefPrefix:\n    default:\n        return 0;\n    }\n}\n\nsize_t ZSTD_CCtx_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, int value)\n{\n    DEBUGLOG(4, \"ZSTD_CCtx_setParameter (%i, %i)\", (int)param, value);\n    if (cctx->streamStage != zcss_init) {\n        if (ZSTD_isUpdateAuthorized(param)) {\n            cctx->cParamsChanged = 1;\n        } else {\n            RETURN_ERROR(stage_wrong, \"can only set params in ctx init stage\");\n    }   }\n\n    switch(param)\n    {\n    case ZSTD_c_nbWorkers:\n        RETURN_ERROR_IF((value!=0) && cctx->staticSize, parameter_unsupported,\n                        \"MT not compatible with static alloc\");\n        break;\n\n    case ZSTD_c_compressionLevel:\n    case ZSTD_c_windowLog:\n    case ZSTD_c_hashLog:\n    case ZSTD_c_chainLog:\n    case ZSTD_c_searchLog:\n    case ZSTD_c_minMatch:\n    case ZSTD_c_targetLength:\n    case ZSTD_c_strategy:\n    case ZSTD_c_ldmHashRateLog:\n    case ZSTD_c_format:\n    case ZSTD_c_contentSizeFlag:\n    case ZSTD_c_checksumFlag:\n    case ZSTD_c_dictIDFlag:\n    case ZSTD_c_forceMaxWindow:\n    case ZSTD_c_forceAttachDict:\n    case ZSTD_c_literalCompressionMode:\n    case ZSTD_c_jobSize:\n    case ZSTD_c_overlapLog:\n    case ZSTD_c_rsyncable:\n    case ZSTD_c_enableDedicatedDictSearch:\n    case ZSTD_c_enableLongDistanceMatching:\n    case ZSTD_c_ldmHashLog:\n    case ZSTD_c_ldmMinMatch:\n    case ZSTD_c_ldmBucketSizeLog:\n    case ZSTD_c_targetCBlockSize:\n    case ZSTD_c_srcSizeHint:\n    case ZSTD_c_stableInBuffer:\n    case ZSTD_c_stableOutBuffer:\n    case ZSTD_c_blockDelimiters:\n    case ZSTD_c_validateSequences:\n    case ZSTD_c_useBlockSplitter:\n    case ZSTD_c_useRowMatchFinder:\n    case ZSTD_c_deterministicRefPrefix:\n        break;\n\n    default: RETURN_ERROR(parameter_unsupported, \"unknown parameter\");\n    }\n    return ZSTD_CCtxParams_setParameter(&cctx->requestedParams, param, value);\n}\n\nsize_t ZSTD_CCtxParams_setParameter(ZSTD_CCtx_params* CCtxParams,\n                                    ZSTD_cParameter param, int value)\n{\n    DEBUGLOG(4, \"ZSTD_CCtxParams_setParameter (%i, %i)\", (int)param, value);\n    switch(param)\n    {\n    case ZSTD_c_format :\n        BOUNDCHECK(ZSTD_c_format, value);\n        CCtxParams->format = (ZSTD_format_e)value;\n        return (size_t)CCtxParams->format;\n\n    case ZSTD_c_compressionLevel : {\n        FORWARD_IF_ERROR(ZSTD_cParam_clampBounds(param, &value), \"\");\n        if (value == 0)\n            CCtxParams->compressionLevel = ZSTD_CLEVEL_DEFAULT;  \n        else\n            CCtxParams->compressionLevel = value;\n        if (CCtxParams->compressionLevel >= 0) return (size_t)CCtxParams->compressionLevel;\n        return 0;   \n    }\n\n    case ZSTD_c_windowLog :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_windowLog, value);\n        CCtxParams->cParams.windowLog = (U32)value;\n        return CCtxParams->cParams.windowLog;\n\n    case ZSTD_c_hashLog :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_hashLog, value);\n        CCtxParams->cParams.hashLog = (U32)value;\n        return CCtxParams->cParams.hashLog;\n\n    case ZSTD_c_chainLog :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_chainLog, value);\n        CCtxParams->cParams.chainLog = (U32)value;\n        return CCtxParams->cParams.chainLog;\n\n    case ZSTD_c_searchLog :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_searchLog, value);\n        CCtxParams->cParams.searchLog = (U32)value;\n        return (size_t)value;\n\n    case ZSTD_c_minMatch :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_minMatch, value);\n        CCtxParams->cParams.minMatch = value;\n        return CCtxParams->cParams.minMatch;\n\n    case ZSTD_c_targetLength :\n        BOUNDCHECK(ZSTD_c_targetLength, value);\n        CCtxParams->cParams.targetLength = value;\n        return CCtxParams->cParams.targetLength;\n\n    case ZSTD_c_strategy :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_strategy, value);\n        CCtxParams->cParams.strategy = (ZSTD_strategy)value;\n        return (size_t)CCtxParams->cParams.strategy;\n\n    case ZSTD_c_contentSizeFlag :\n         \n        DEBUGLOG(4, \"set content size flag = %u\", (value!=0));\n        CCtxParams->fParams.contentSizeFlag = value != 0;\n        return CCtxParams->fParams.contentSizeFlag;\n\n    case ZSTD_c_checksumFlag :\n         \n        CCtxParams->fParams.checksumFlag = value != 0;\n        return CCtxParams->fParams.checksumFlag;\n\n    case ZSTD_c_dictIDFlag :  \n        DEBUGLOG(4, \"set dictIDFlag = %u\", (value!=0));\n        CCtxParams->fParams.noDictIDFlag = !value;\n        return !CCtxParams->fParams.noDictIDFlag;\n\n    case ZSTD_c_forceMaxWindow :\n        CCtxParams->forceWindow = (value != 0);\n        return CCtxParams->forceWindow;\n\n    case ZSTD_c_forceAttachDict : {\n        const ZSTD_dictAttachPref_e pref = (ZSTD_dictAttachPref_e)value;\n        BOUNDCHECK(ZSTD_c_forceAttachDict, pref);\n        CCtxParams->attachDictPref = pref;\n        return CCtxParams->attachDictPref;\n    }\n\n    case ZSTD_c_literalCompressionMode : {\n        const ZSTD_paramSwitch_e lcm = (ZSTD_paramSwitch_e)value;\n        BOUNDCHECK(ZSTD_c_literalCompressionMode, lcm);\n        CCtxParams->literalCompressionMode = lcm;\n        return CCtxParams->literalCompressionMode;\n    }\n\n    case ZSTD_c_nbWorkers :\n        RETURN_ERROR_IF(value!=0, parameter_unsupported, \"not compiled with multithreading\");\n        return 0;\n\n    case ZSTD_c_jobSize :\n        RETURN_ERROR_IF(value!=0, parameter_unsupported, \"not compiled with multithreading\");\n        return 0;\n\n    case ZSTD_c_overlapLog :\n        RETURN_ERROR_IF(value!=0, parameter_unsupported, \"not compiled with multithreading\");\n        return 0;\n\n    case ZSTD_c_rsyncable :\n        RETURN_ERROR_IF(value!=0, parameter_unsupported, \"not compiled with multithreading\");\n        return 0;\n\n    case ZSTD_c_enableDedicatedDictSearch :\n        CCtxParams->enableDedicatedDictSearch = (value!=0);\n        return CCtxParams->enableDedicatedDictSearch;\n\n    case ZSTD_c_enableLongDistanceMatching :\n        CCtxParams->ldmParams.enableLdm = (ZSTD_paramSwitch_e)value;\n        return CCtxParams->ldmParams.enableLdm;\n\n    case ZSTD_c_ldmHashLog :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_ldmHashLog, value);\n        CCtxParams->ldmParams.hashLog = value;\n        return CCtxParams->ldmParams.hashLog;\n\n    case ZSTD_c_ldmMinMatch :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_ldmMinMatch, value);\n        CCtxParams->ldmParams.minMatchLength = value;\n        return CCtxParams->ldmParams.minMatchLength;\n\n    case ZSTD_c_ldmBucketSizeLog :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_ldmBucketSizeLog, value);\n        CCtxParams->ldmParams.bucketSizeLog = value;\n        return CCtxParams->ldmParams.bucketSizeLog;\n\n    case ZSTD_c_ldmHashRateLog :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_ldmHashRateLog, value);\n        CCtxParams->ldmParams.hashRateLog = value;\n        return CCtxParams->ldmParams.hashRateLog;\n\n    case ZSTD_c_targetCBlockSize :\n        if (value!=0)    \n            BOUNDCHECK(ZSTD_c_targetCBlockSize, value);\n        CCtxParams->targetCBlockSize = value;\n        return CCtxParams->targetCBlockSize;\n\n    case ZSTD_c_srcSizeHint :\n        if (value!=0)     \n            BOUNDCHECK(ZSTD_c_srcSizeHint, value);\n        CCtxParams->srcSizeHint = value;\n        return CCtxParams->srcSizeHint;\n\n    case ZSTD_c_stableInBuffer:\n        BOUNDCHECK(ZSTD_c_stableInBuffer, value);\n        CCtxParams->inBufferMode = (ZSTD_bufferMode_e)value;\n        return CCtxParams->inBufferMode;\n\n    case ZSTD_c_stableOutBuffer:\n        BOUNDCHECK(ZSTD_c_stableOutBuffer, value);\n        CCtxParams->outBufferMode = (ZSTD_bufferMode_e)value;\n        return CCtxParams->outBufferMode;\n\n    case ZSTD_c_blockDelimiters:\n        BOUNDCHECK(ZSTD_c_blockDelimiters, value);\n        CCtxParams->blockDelimiters = (ZSTD_sequenceFormat_e)value;\n        return CCtxParams->blockDelimiters;\n\n    case ZSTD_c_validateSequences:\n        BOUNDCHECK(ZSTD_c_validateSequences, value);\n        CCtxParams->validateSequences = value;\n        return CCtxParams->validateSequences;\n\n    case ZSTD_c_useBlockSplitter:\n        BOUNDCHECK(ZSTD_c_useBlockSplitter, value);\n        CCtxParams->useBlockSplitter = (ZSTD_paramSwitch_e)value;\n        return CCtxParams->useBlockSplitter;\n\n    case ZSTD_c_useRowMatchFinder:\n        BOUNDCHECK(ZSTD_c_useRowMatchFinder, value);\n        CCtxParams->useRowMatchFinder = (ZSTD_paramSwitch_e)value;\n        return CCtxParams->useRowMatchFinder;\n\n    case ZSTD_c_deterministicRefPrefix:\n        BOUNDCHECK(ZSTD_c_deterministicRefPrefix, value);\n        CCtxParams->deterministicRefPrefix = !!value;\n        return CCtxParams->deterministicRefPrefix;\n\n    default: RETURN_ERROR(parameter_unsupported, \"unknown parameter\");\n    }\n}\n\nsize_t ZSTD_CCtx_getParameter(ZSTD_CCtx const* cctx, ZSTD_cParameter param, int* value)\n{\n    return ZSTD_CCtxParams_getParameter(&cctx->requestedParams, param, value);\n}\n\nsize_t ZSTD_CCtxParams_getParameter(\n        ZSTD_CCtx_params const* CCtxParams, ZSTD_cParameter param, int* value)\n{\n    switch(param)\n    {\n    case ZSTD_c_format :\n        *value = CCtxParams->format;\n        break;\n    case ZSTD_c_compressionLevel :\n        *value = CCtxParams->compressionLevel;\n        break;\n    case ZSTD_c_windowLog :\n        *value = (int)CCtxParams->cParams.windowLog;\n        break;\n    case ZSTD_c_hashLog :\n        *value = (int)CCtxParams->cParams.hashLog;\n        break;\n    case ZSTD_c_chainLog :\n        *value = (int)CCtxParams->cParams.chainLog;\n        break;\n    case ZSTD_c_searchLog :\n        *value = CCtxParams->cParams.searchLog;\n        break;\n    case ZSTD_c_minMatch :\n        *value = CCtxParams->cParams.minMatch;\n        break;\n    case ZSTD_c_targetLength :\n        *value = CCtxParams->cParams.targetLength;\n        break;\n    case ZSTD_c_strategy :\n        *value = (unsigned)CCtxParams->cParams.strategy;\n        break;\n    case ZSTD_c_contentSizeFlag :\n        *value = CCtxParams->fParams.contentSizeFlag;\n        break;\n    case ZSTD_c_checksumFlag :\n        *value = CCtxParams->fParams.checksumFlag;\n        break;\n    case ZSTD_c_dictIDFlag :\n        *value = !CCtxParams->fParams.noDictIDFlag;\n        break;\n    case ZSTD_c_forceMaxWindow :\n        *value = CCtxParams->forceWindow;\n        break;\n    case ZSTD_c_forceAttachDict :\n        *value = CCtxParams->attachDictPref;\n        break;\n    case ZSTD_c_literalCompressionMode :\n        *value = CCtxParams->literalCompressionMode;\n        break;\n    case ZSTD_c_nbWorkers :\n        assert(CCtxParams->nbWorkers == 0);\n        *value = CCtxParams->nbWorkers;\n        break;\n    case ZSTD_c_jobSize :\n        RETURN_ERROR(parameter_unsupported, \"not compiled with multithreading\");\n    case ZSTD_c_overlapLog :\n        RETURN_ERROR(parameter_unsupported, \"not compiled with multithreading\");\n    case ZSTD_c_rsyncable :\n        RETURN_ERROR(parameter_unsupported, \"not compiled with multithreading\");\n    case ZSTD_c_enableDedicatedDictSearch :\n        *value = CCtxParams->enableDedicatedDictSearch;\n        break;\n    case ZSTD_c_enableLongDistanceMatching :\n        *value = CCtxParams->ldmParams.enableLdm;\n        break;\n    case ZSTD_c_ldmHashLog :\n        *value = CCtxParams->ldmParams.hashLog;\n        break;\n    case ZSTD_c_ldmMinMatch :\n        *value = CCtxParams->ldmParams.minMatchLength;\n        break;\n    case ZSTD_c_ldmBucketSizeLog :\n        *value = CCtxParams->ldmParams.bucketSizeLog;\n        break;\n    case ZSTD_c_ldmHashRateLog :\n        *value = CCtxParams->ldmParams.hashRateLog;\n        break;\n    case ZSTD_c_targetCBlockSize :\n        *value = (int)CCtxParams->targetCBlockSize;\n        break;\n    case ZSTD_c_srcSizeHint :\n        *value = (int)CCtxParams->srcSizeHint;\n        break;\n    case ZSTD_c_stableInBuffer :\n        *value = (int)CCtxParams->inBufferMode;\n        break;\n    case ZSTD_c_stableOutBuffer :\n        *value = (int)CCtxParams->outBufferMode;\n        break;\n    case ZSTD_c_blockDelimiters :\n        *value = (int)CCtxParams->blockDelimiters;\n        break;\n    case ZSTD_c_validateSequences :\n        *value = (int)CCtxParams->validateSequences;\n        break;\n    case ZSTD_c_useBlockSplitter :\n        *value = (int)CCtxParams->useBlockSplitter;\n        break;\n    case ZSTD_c_useRowMatchFinder :\n        *value = (int)CCtxParams->useRowMatchFinder;\n        break;\n    case ZSTD_c_deterministicRefPrefix:\n        *value = (int)CCtxParams->deterministicRefPrefix;\n        break;\n    default: RETURN_ERROR(parameter_unsupported, \"unknown parameter\");\n    }\n    return 0;\n}\n\n \nsize_t ZSTD_CCtx_setParametersUsingCCtxParams(\n        ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params)\n{\n    DEBUGLOG(4, \"ZSTD_CCtx_setParametersUsingCCtxParams\");\n    RETURN_ERROR_IF(cctx->streamStage != zcss_init, stage_wrong,\n                    \"The context is in the wrong stage!\");\n    RETURN_ERROR_IF(cctx->cdict, stage_wrong,\n                    \"Can't override parameters with cdict attached (some must \"\n                    \"be inherited from the cdict).\");\n\n    cctx->requestedParams = *params;\n    return 0;\n}\n\nsize_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize)\n{\n    DEBUGLOG(4, \"ZSTD_CCtx_setPledgedSrcSize to %u bytes\", (U32)pledgedSrcSize);\n    RETURN_ERROR_IF(cctx->streamStage != zcss_init, stage_wrong,\n                    \"Can't set pledgedSrcSize when not in init stage.\");\n    cctx->pledgedSrcSizePlusOne = pledgedSrcSize+1;\n    return 0;\n}\n\nstatic ZSTD_compressionParameters ZSTD_dedicatedDictSearch_getCParams(\n        int const compressionLevel,\n        size_t const dictSize);\nstatic int ZSTD_dedicatedDictSearch_isSupported(\n        const ZSTD_compressionParameters* cParams);\nstatic void ZSTD_dedicatedDictSearch_revertCParams(\n        ZSTD_compressionParameters* cParams);\n\n \nstatic size_t ZSTD_initLocalDict(ZSTD_CCtx* cctx)\n{\n    ZSTD_localDict* const dl = &cctx->localDict;\n    if (dl->dict == NULL) {\n         \n        assert(dl->dictBuffer == NULL);\n        assert(dl->cdict == NULL);\n        assert(dl->dictSize == 0);\n        return 0;\n    }\n    if (dl->cdict != NULL) {\n        assert(cctx->cdict == dl->cdict);\n         \n        return 0;\n    }\n    assert(dl->dictSize > 0);\n    assert(cctx->cdict == NULL);\n    assert(cctx->prefixDict.dict == NULL);\n\n    dl->cdict = ZSTD_createCDict_advanced2(\n            dl->dict,\n            dl->dictSize,\n            ZSTD_dlm_byRef,\n            dl->dictContentType,\n            &cctx->requestedParams,\n            cctx->customMem);\n    RETURN_ERROR_IF(!dl->cdict, memory_allocation, \"ZSTD_createCDict_advanced failed\");\n    cctx->cdict = dl->cdict;\n    return 0;\n}\n\nsize_t ZSTD_CCtx_loadDictionary_advanced(\n        ZSTD_CCtx* cctx, const void* dict, size_t dictSize,\n        ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType)\n{\n    RETURN_ERROR_IF(cctx->streamStage != zcss_init, stage_wrong,\n                    \"Can't load a dictionary when ctx is not in init stage.\");\n    DEBUGLOG(4, \"ZSTD_CCtx_loadDictionary_advanced (size: %u)\", (U32)dictSize);\n    ZSTD_clearAllDicts(cctx);   \n    if (dict == NULL || dictSize == 0)   \n        return 0;\n    if (dictLoadMethod == ZSTD_dlm_byRef) {\n        cctx->localDict.dict = dict;\n    } else {\n        void* dictBuffer;\n        RETURN_ERROR_IF(cctx->staticSize, memory_allocation,\n                        \"no malloc for static CCtx\");\n        dictBuffer = ZSTD_customMalloc(dictSize, cctx->customMem);\n        RETURN_ERROR_IF(!dictBuffer, memory_allocation, \"NULL pointer!\");\n        ZSTD_memcpy(dictBuffer, dict, dictSize);\n        cctx->localDict.dictBuffer = dictBuffer;\n        cctx->localDict.dict = dictBuffer;\n    }\n    cctx->localDict.dictSize = dictSize;\n    cctx->localDict.dictContentType = dictContentType;\n    return 0;\n}\n\nsize_t ZSTD_CCtx_loadDictionary_byReference(\n      ZSTD_CCtx* cctx, const void* dict, size_t dictSize)\n{\n    return ZSTD_CCtx_loadDictionary_advanced(\n            cctx, dict, dictSize, ZSTD_dlm_byRef, ZSTD_dct_auto);\n}\n\nsize_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize)\n{\n    return ZSTD_CCtx_loadDictionary_advanced(\n            cctx, dict, dictSize, ZSTD_dlm_byCopy, ZSTD_dct_auto);\n}\n\n\nsize_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict)\n{\n    RETURN_ERROR_IF(cctx->streamStage != zcss_init, stage_wrong,\n                    \"Can't ref a dict when ctx not in init stage.\");\n     \n    ZSTD_clearAllDicts(cctx);\n    cctx->cdict = cdict;\n    return 0;\n}\n\nsize_t ZSTD_CCtx_refThreadPool(ZSTD_CCtx* cctx, ZSTD_threadPool* pool)\n{\n    RETURN_ERROR_IF(cctx->streamStage != zcss_init, stage_wrong,\n                    \"Can't ref a pool when ctx not in init stage.\");\n    cctx->pool = pool;\n    return 0;\n}\n\nsize_t ZSTD_CCtx_refPrefix(ZSTD_CCtx* cctx, const void* prefix, size_t prefixSize)\n{\n    return ZSTD_CCtx_refPrefix_advanced(cctx, prefix, prefixSize, ZSTD_dct_rawContent);\n}\n\nsize_t ZSTD_CCtx_refPrefix_advanced(\n        ZSTD_CCtx* cctx, const void* prefix, size_t prefixSize, ZSTD_dictContentType_e dictContentType)\n{\n    RETURN_ERROR_IF(cctx->streamStage != zcss_init, stage_wrong,\n                    \"Can't ref a prefix when ctx not in init stage.\");\n    ZSTD_clearAllDicts(cctx);\n    if (prefix != NULL && prefixSize > 0) {\n        cctx->prefixDict.dict = prefix;\n        cctx->prefixDict.dictSize = prefixSize;\n        cctx->prefixDict.dictContentType = dictContentType;\n    }\n    return 0;\n}\n\n \nsize_t ZSTD_CCtx_reset(ZSTD_CCtx* cctx, ZSTD_ResetDirective reset)\n{\n    if ( (reset == ZSTD_reset_session_only)\n      || (reset == ZSTD_reset_session_and_parameters) ) {\n        cctx->streamStage = zcss_init;\n        cctx->pledgedSrcSizePlusOne = 0;\n    }\n    if ( (reset == ZSTD_reset_parameters)\n      || (reset == ZSTD_reset_session_and_parameters) ) {\n        RETURN_ERROR_IF(cctx->streamStage != zcss_init, stage_wrong,\n                        \"Can't reset parameters only when not in init stage.\");\n        ZSTD_clearAllDicts(cctx);\n        return ZSTD_CCtxParams_reset(&cctx->requestedParams);\n    }\n    return 0;\n}\n\n\n \nsize_t ZSTD_checkCParams(ZSTD_compressionParameters cParams)\n{\n    BOUNDCHECK(ZSTD_c_windowLog, (int)cParams.windowLog);\n    BOUNDCHECK(ZSTD_c_chainLog,  (int)cParams.chainLog);\n    BOUNDCHECK(ZSTD_c_hashLog,   (int)cParams.hashLog);\n    BOUNDCHECK(ZSTD_c_searchLog, (int)cParams.searchLog);\n    BOUNDCHECK(ZSTD_c_minMatch,  (int)cParams.minMatch);\n    BOUNDCHECK(ZSTD_c_targetLength,(int)cParams.targetLength);\n    BOUNDCHECK(ZSTD_c_strategy,  cParams.strategy);\n    return 0;\n}\n\n \nstatic ZSTD_compressionParameters\nZSTD_clampCParams(ZSTD_compressionParameters cParams)\n{\n#   define CLAMP_TYPE(cParam, val, type) {                                \\\n        ZSTD_bounds const bounds = ZSTD_cParam_getBounds(cParam);         \\\n        if ((int)val<bounds.lowerBound) val=(type)bounds.lowerBound;      \\\n        else if ((int)val>bounds.upperBound) val=(type)bounds.upperBound; \\\n    }\n#   define CLAMP(cParam, val) CLAMP_TYPE(cParam, val, unsigned)\n    CLAMP(ZSTD_c_windowLog, cParams.windowLog);\n    CLAMP(ZSTD_c_chainLog,  cParams.chainLog);\n    CLAMP(ZSTD_c_hashLog,   cParams.hashLog);\n    CLAMP(ZSTD_c_searchLog, cParams.searchLog);\n    CLAMP(ZSTD_c_minMatch,  cParams.minMatch);\n    CLAMP(ZSTD_c_targetLength,cParams.targetLength);\n    CLAMP_TYPE(ZSTD_c_strategy,cParams.strategy, ZSTD_strategy);\n    return cParams;\n}\n\n \nU32 ZSTD_cycleLog(U32 hashLog, ZSTD_strategy strat)\n{\n    U32 const btScale = ((U32)strat >= (U32)ZSTD_btlazy2);\n    return hashLog - btScale;\n}\n\n \nstatic U32 ZSTD_dictAndWindowLog(U32 windowLog, U64 srcSize, U64 dictSize)\n{\n    const U64 maxWindowSize = 1ULL << ZSTD_WINDOWLOG_MAX;\n     \n    if (dictSize == 0) {\n        return windowLog;\n    }\n    assert(windowLog <= ZSTD_WINDOWLOG_MAX);\n    assert(srcSize != ZSTD_CONTENTSIZE_UNKNOWN);  \n    {\n        U64 const windowSize = 1ULL << windowLog;\n        U64 const dictAndWindowSize = dictSize + windowSize;\n         \n        if (windowSize >= dictSize + srcSize) {\n            return windowLog;  \n        } else if (dictAndWindowSize >= maxWindowSize) {\n            return ZSTD_WINDOWLOG_MAX;  \n        } else  {\n            return ZSTD_highbit32((U32)dictAndWindowSize - 1) + 1;\n        }\n    }\n}\n\n \nstatic ZSTD_compressionParameters\nZSTD_adjustCParams_internal(ZSTD_compressionParameters cPar,\n                            unsigned long long srcSize,\n                            size_t dictSize,\n                            ZSTD_cParamMode_e mode)\n{\n    const U64 minSrcSize = 513;  \n    const U64 maxWindowResize = 1ULL << (ZSTD_WINDOWLOG_MAX-1);\n    assert(ZSTD_checkCParams(cPar)==0);\n\n    switch (mode) {\n    case ZSTD_cpm_unknown:\n    case ZSTD_cpm_noAttachDict:\n         \n        break;\n    case ZSTD_cpm_createCDict:\n         \n        if (dictSize && srcSize == ZSTD_CONTENTSIZE_UNKNOWN)\n            srcSize = minSrcSize;\n        break;\n    case ZSTD_cpm_attachDict:\n         \n        dictSize = 0;\n        break;\n    default:\n        assert(0);\n        break;\n    }\n\n     \n    if ( (srcSize < maxWindowResize)\n      && (dictSize < maxWindowResize) )  {\n        U32 const tSize = (U32)(srcSize + dictSize);\n        static U32 const hashSizeMin = 1 << ZSTD_HASHLOG_MIN;\n        U32 const srcLog = (tSize < hashSizeMin) ? ZSTD_HASHLOG_MIN :\n                            ZSTD_highbit32(tSize-1) + 1;\n        if (cPar.windowLog > srcLog) cPar.windowLog = srcLog;\n    }\n    if (srcSize != ZSTD_CONTENTSIZE_UNKNOWN) {\n        U32 const dictAndWindowLog = ZSTD_dictAndWindowLog(cPar.windowLog, (U64)srcSize, (U64)dictSize);\n        U32 const cycleLog = ZSTD_cycleLog(cPar.chainLog, cPar.strategy);\n        if (cPar.hashLog > dictAndWindowLog+1) cPar.hashLog = dictAndWindowLog+1;\n        if (cycleLog > dictAndWindowLog)\n            cPar.chainLog -= (cycleLog - dictAndWindowLog);\n    }\n\n    if (cPar.windowLog < ZSTD_WINDOWLOG_ABSOLUTEMIN)\n        cPar.windowLog = ZSTD_WINDOWLOG_ABSOLUTEMIN;   \n\n    return cPar;\n}\n\nZSTD_compressionParameters\nZSTD_adjustCParams(ZSTD_compressionParameters cPar,\n                   unsigned long long srcSize,\n                   size_t dictSize)\n{\n    cPar = ZSTD_clampCParams(cPar);    \n    if (srcSize == 0) srcSize = ZSTD_CONTENTSIZE_UNKNOWN;\n    return ZSTD_adjustCParams_internal(cPar, srcSize, dictSize, ZSTD_cpm_unknown);\n}\n\nstatic ZSTD_compressionParameters ZSTD_getCParams_internal(int compressionLevel, unsigned long long srcSizeHint, size_t dictSize, ZSTD_cParamMode_e mode);\nstatic ZSTD_parameters ZSTD_getParams_internal(int compressionLevel, unsigned long long srcSizeHint, size_t dictSize, ZSTD_cParamMode_e mode);\n\nstatic void ZSTD_overrideCParams(\n              ZSTD_compressionParameters* cParams,\n        const ZSTD_compressionParameters* overrides)\n{\n    if (overrides->windowLog)    cParams->windowLog    = overrides->windowLog;\n    if (overrides->hashLog)      cParams->hashLog      = overrides->hashLog;\n    if (overrides->chainLog)     cParams->chainLog     = overrides->chainLog;\n    if (overrides->searchLog)    cParams->searchLog    = overrides->searchLog;\n    if (overrides->minMatch)     cParams->minMatch     = overrides->minMatch;\n    if (overrides->targetLength) cParams->targetLength = overrides->targetLength;\n    if (overrides->strategy)     cParams->strategy     = overrides->strategy;\n}\n\nZSTD_compressionParameters ZSTD_getCParamsFromCCtxParams(\n        const ZSTD_CCtx_params* CCtxParams, U64 srcSizeHint, size_t dictSize, ZSTD_cParamMode_e mode)\n{\n    ZSTD_compressionParameters cParams;\n    if (srcSizeHint == ZSTD_CONTENTSIZE_UNKNOWN && CCtxParams->srcSizeHint > 0) {\n      srcSizeHint = CCtxParams->srcSizeHint;\n    }\n    cParams = ZSTD_getCParams_internal(CCtxParams->compressionLevel, srcSizeHint, dictSize, mode);\n    if (CCtxParams->ldmParams.enableLdm == ZSTD_ps_enable) cParams.windowLog = ZSTD_LDM_DEFAULT_WINDOW_LOG;\n    ZSTD_overrideCParams(&cParams, &CCtxParams->cParams);\n    assert(!ZSTD_checkCParams(cParams));\n     \n    return ZSTD_adjustCParams_internal(cParams, srcSizeHint, dictSize, mode);\n}\n\nstatic size_t\nZSTD_sizeof_matchState(const ZSTD_compressionParameters* const cParams,\n                       const ZSTD_paramSwitch_e useRowMatchFinder,\n                       const U32 enableDedicatedDictSearch,\n                       const U32 forCCtx)\n{\n     \n    size_t const chainSize = ZSTD_allocateChainTable(cParams->strategy, useRowMatchFinder, enableDedicatedDictSearch && !forCCtx)\n                                ? ((size_t)1 << cParams->chainLog)\n                                : 0;\n    size_t const hSize = ((size_t)1) << cParams->hashLog;\n    U32    const hashLog3 = (forCCtx && cParams->minMatch==3) ? MIN(ZSTD_HASHLOG3_MAX, cParams->windowLog) : 0;\n    size_t const h3Size = hashLog3 ? ((size_t)1) << hashLog3 : 0;\n     \n    size_t const tableSpace = chainSize * sizeof(U32)\n                            + hSize * sizeof(U32)\n                            + h3Size * sizeof(U32);\n    size_t const optPotentialSpace =\n        ZSTD_cwksp_aligned_alloc_size((MaxML+1) * sizeof(U32))\n      + ZSTD_cwksp_aligned_alloc_size((MaxLL+1) * sizeof(U32))\n      + ZSTD_cwksp_aligned_alloc_size((MaxOff+1) * sizeof(U32))\n      + ZSTD_cwksp_aligned_alloc_size((1<<Litbits) * sizeof(U32))\n      + ZSTD_cwksp_aligned_alloc_size((ZSTD_OPT_NUM+1) * sizeof(ZSTD_match_t))\n      + ZSTD_cwksp_aligned_alloc_size((ZSTD_OPT_NUM+1) * sizeof(ZSTD_optimal_t));\n    size_t const lazyAdditionalSpace = ZSTD_rowMatchFinderUsed(cParams->strategy, useRowMatchFinder)\n                                            ? ZSTD_cwksp_aligned_alloc_size(hSize*sizeof(U16))\n                                            : 0;\n    size_t const optSpace = (forCCtx && (cParams->strategy >= ZSTD_btopt))\n                                ? optPotentialSpace\n                                : 0;\n    size_t const slackSpace = ZSTD_cwksp_slack_space_required();\n\n     \n    ZSTD_STATIC_ASSERT(ZSTD_HASHLOG_MIN >= 4 && ZSTD_WINDOWLOG_MIN >= 4 && ZSTD_CHAINLOG_MIN >= 4);\n    assert(useRowMatchFinder != ZSTD_ps_auto);\n\n    DEBUGLOG(4, \"chainSize: %u - hSize: %u - h3Size: %u\",\n                (U32)chainSize, (U32)hSize, (U32)h3Size);\n    return tableSpace + optSpace + slackSpace + lazyAdditionalSpace;\n}\n\nstatic size_t ZSTD_estimateCCtxSize_usingCCtxParams_internal(\n        const ZSTD_compressionParameters* cParams,\n        const ldmParams_t* ldmParams,\n        const int isStatic,\n        const ZSTD_paramSwitch_e useRowMatchFinder,\n        const size_t buffInSize,\n        const size_t buffOutSize,\n        const U64 pledgedSrcSize)\n{\n    size_t const windowSize = (size_t) BOUNDED(1ULL, 1ULL << cParams->windowLog, pledgedSrcSize);\n    size_t const blockSize = MIN(ZSTD_BLOCKSIZE_MAX, windowSize);\n    U32    const divider = (cParams->minMatch==3) ? 3 : 4;\n    size_t const maxNbSeq = blockSize / divider;\n    size_t const tokenSpace = ZSTD_cwksp_alloc_size(WILDCOPY_OVERLENGTH + blockSize)\n                            + ZSTD_cwksp_aligned_alloc_size(maxNbSeq * sizeof(seqDef))\n                            + 3 * ZSTD_cwksp_alloc_size(maxNbSeq * sizeof(BYTE));\n    size_t const entropySpace = ZSTD_cwksp_alloc_size(ENTROPY_WORKSPACE_SIZE);\n    size_t const blockStateSpace = 2 * ZSTD_cwksp_alloc_size(sizeof(ZSTD_compressedBlockState_t));\n    size_t const matchStateSize = ZSTD_sizeof_matchState(cParams, useRowMatchFinder,   0,   1);\n\n    size_t const ldmSpace = ZSTD_ldm_getTableSize(*ldmParams);\n    size_t const maxNbLdmSeq = ZSTD_ldm_getMaxNbSeq(*ldmParams, blockSize);\n    size_t const ldmSeqSpace = ldmParams->enableLdm == ZSTD_ps_enable ?\n        ZSTD_cwksp_aligned_alloc_size(maxNbLdmSeq * sizeof(rawSeq)) : 0;\n\n\n    size_t const bufferSpace = ZSTD_cwksp_alloc_size(buffInSize)\n                             + ZSTD_cwksp_alloc_size(buffOutSize);\n\n    size_t const cctxSpace = isStatic ? ZSTD_cwksp_alloc_size(sizeof(ZSTD_CCtx)) : 0;\n\n    size_t const neededSpace =\n        cctxSpace +\n        entropySpace +\n        blockStateSpace +\n        ldmSpace +\n        ldmSeqSpace +\n        matchStateSize +\n        tokenSpace +\n        bufferSpace;\n\n    DEBUGLOG(5, \"estimate workspace : %u\", (U32)neededSpace);\n    return neededSpace;\n}\n\nsize_t ZSTD_estimateCCtxSize_usingCCtxParams(const ZSTD_CCtx_params* params)\n{\n    ZSTD_compressionParameters const cParams =\n                ZSTD_getCParamsFromCCtxParams(params, ZSTD_CONTENTSIZE_UNKNOWN, 0, ZSTD_cpm_noAttachDict);\n    ZSTD_paramSwitch_e const useRowMatchFinder = ZSTD_resolveRowMatchFinderMode(params->useRowMatchFinder,\n                                                                               &cParams);\n\n    RETURN_ERROR_IF(params->nbWorkers > 0, GENERIC, \"Estimate CCtx size is supported for single-threaded compression only.\");\n     \n    return ZSTD_estimateCCtxSize_usingCCtxParams_internal(\n        &cParams, &params->ldmParams, 1, useRowMatchFinder, 0, 0, ZSTD_CONTENTSIZE_UNKNOWN);\n}\n\nsize_t ZSTD_estimateCCtxSize_usingCParams(ZSTD_compressionParameters cParams)\n{\n    ZSTD_CCtx_params initialParams = ZSTD_makeCCtxParamsFromCParams(cParams);\n    if (ZSTD_rowMatchFinderSupported(cParams.strategy)) {\n         \n        size_t noRowCCtxSize;\n        size_t rowCCtxSize;\n        initialParams.useRowMatchFinder = ZSTD_ps_disable;\n        noRowCCtxSize = ZSTD_estimateCCtxSize_usingCCtxParams(&initialParams);\n        initialParams.useRowMatchFinder = ZSTD_ps_enable;\n        rowCCtxSize = ZSTD_estimateCCtxSize_usingCCtxParams(&initialParams);\n        return MAX(noRowCCtxSize, rowCCtxSize);\n    } else {\n        return ZSTD_estimateCCtxSize_usingCCtxParams(&initialParams);\n    }\n}\n\nstatic size_t ZSTD_estimateCCtxSize_internal(int compressionLevel)\n{\n    int tier = 0;\n    size_t largestSize = 0;\n    static const unsigned long long srcSizeTiers[4] = {16 KB, 128 KB, 256 KB, ZSTD_CONTENTSIZE_UNKNOWN};\n    for (; tier < 4; ++tier) {\n         \n        ZSTD_compressionParameters const cParams = ZSTD_getCParams_internal(compressionLevel, srcSizeTiers[tier], 0, ZSTD_cpm_noAttachDict);\n        largestSize = MAX(ZSTD_estimateCCtxSize_usingCParams(cParams), largestSize);\n    }\n    return largestSize;\n}\n\nsize_t ZSTD_estimateCCtxSize(int compressionLevel)\n{\n    int level;\n    size_t memBudget = 0;\n    for (level=MIN(compressionLevel, 1); level<=compressionLevel; level++) {\n         \n        size_t const newMB = ZSTD_estimateCCtxSize_internal(level);\n        if (newMB > memBudget) memBudget = newMB;\n    }\n    return memBudget;\n}\n\nsize_t ZSTD_estimateCStreamSize_usingCCtxParams(const ZSTD_CCtx_params* params)\n{\n    RETURN_ERROR_IF(params->nbWorkers > 0, GENERIC, \"Estimate CCtx size is supported for single-threaded compression only.\");\n    {   ZSTD_compressionParameters const cParams =\n                ZSTD_getCParamsFromCCtxParams(params, ZSTD_CONTENTSIZE_UNKNOWN, 0, ZSTD_cpm_noAttachDict);\n        size_t const blockSize = MIN(ZSTD_BLOCKSIZE_MAX, (size_t)1 << cParams.windowLog);\n        size_t const inBuffSize = (params->inBufferMode == ZSTD_bm_buffered)\n                ? ((size_t)1 << cParams.windowLog) + blockSize\n                : 0;\n        size_t const outBuffSize = (params->outBufferMode == ZSTD_bm_buffered)\n                ? ZSTD_compressBound(blockSize) + 1\n                : 0;\n        ZSTD_paramSwitch_e const useRowMatchFinder = ZSTD_resolveRowMatchFinderMode(params->useRowMatchFinder, &params->cParams);\n\n        return ZSTD_estimateCCtxSize_usingCCtxParams_internal(\n            &cParams, &params->ldmParams, 1, useRowMatchFinder, inBuffSize, outBuffSize,\n            ZSTD_CONTENTSIZE_UNKNOWN);\n    }\n}\n\nsize_t ZSTD_estimateCStreamSize_usingCParams(ZSTD_compressionParameters cParams)\n{\n    ZSTD_CCtx_params initialParams = ZSTD_makeCCtxParamsFromCParams(cParams);\n    if (ZSTD_rowMatchFinderSupported(cParams.strategy)) {\n         \n        size_t noRowCCtxSize;\n        size_t rowCCtxSize;\n        initialParams.useRowMatchFinder = ZSTD_ps_disable;\n        noRowCCtxSize = ZSTD_estimateCStreamSize_usingCCtxParams(&initialParams);\n        initialParams.useRowMatchFinder = ZSTD_ps_enable;\n        rowCCtxSize = ZSTD_estimateCStreamSize_usingCCtxParams(&initialParams);\n        return MAX(noRowCCtxSize, rowCCtxSize);\n    } else {\n        return ZSTD_estimateCStreamSize_usingCCtxParams(&initialParams);\n    }\n}\n\nstatic size_t ZSTD_estimateCStreamSize_internal(int compressionLevel)\n{\n    ZSTD_compressionParameters const cParams = ZSTD_getCParams_internal(compressionLevel, ZSTD_CONTENTSIZE_UNKNOWN, 0, ZSTD_cpm_noAttachDict);\n    return ZSTD_estimateCStreamSize_usingCParams(cParams);\n}\n\nsize_t ZSTD_estimateCStreamSize(int compressionLevel)\n{\n    int level;\n    size_t memBudget = 0;\n    for (level=MIN(compressionLevel, 1); level<=compressionLevel; level++) {\n        size_t const newMB = ZSTD_estimateCStreamSize_internal(level);\n        if (newMB > memBudget) memBudget = newMB;\n    }\n    return memBudget;\n}\n\n \nZSTD_frameProgression ZSTD_getFrameProgression(const ZSTD_CCtx* cctx)\n{\n    {   ZSTD_frameProgression fp;\n        size_t const buffered = (cctx->inBuff == NULL) ? 0 :\n                                cctx->inBuffPos - cctx->inToCompress;\n        if (buffered) assert(cctx->inBuffPos >= cctx->inToCompress);\n        assert(buffered <= ZSTD_BLOCKSIZE_MAX);\n        fp.ingested = cctx->consumedSrcSize + buffered;\n        fp.consumed = cctx->consumedSrcSize;\n        fp.produced = cctx->producedCSize;\n        fp.flushed  = cctx->producedCSize;    \n        fp.currentJobID = 0;\n        fp.nbActiveWorkers = 0;\n        return fp;\n}   }\n\n \nsize_t ZSTD_toFlushNow(ZSTD_CCtx* cctx)\n{\n    (void)cctx;\n    return 0;    \n}\n\nstatic void ZSTD_assertEqualCParams(ZSTD_compressionParameters cParams1,\n                                    ZSTD_compressionParameters cParams2)\n{\n    (void)cParams1;\n    (void)cParams2;\n    assert(cParams1.windowLog    == cParams2.windowLog);\n    assert(cParams1.chainLog     == cParams2.chainLog);\n    assert(cParams1.hashLog      == cParams2.hashLog);\n    assert(cParams1.searchLog    == cParams2.searchLog);\n    assert(cParams1.minMatch     == cParams2.minMatch);\n    assert(cParams1.targetLength == cParams2.targetLength);\n    assert(cParams1.strategy     == cParams2.strategy);\n}\n\nvoid ZSTD_reset_compressedBlockState(ZSTD_compressedBlockState_t* bs)\n{\n    int i;\n    for (i = 0; i < ZSTD_REP_NUM; ++i)\n        bs->rep[i] = repStartValue[i];\n    bs->entropy.huf.repeatMode = HUF_repeat_none;\n    bs->entropy.fse.offcode_repeatMode = FSE_repeat_none;\n    bs->entropy.fse.matchlength_repeatMode = FSE_repeat_none;\n    bs->entropy.fse.litlength_repeatMode = FSE_repeat_none;\n}\n\n \nstatic void ZSTD_invalidateMatchState(ZSTD_matchState_t* ms)\n{\n    ZSTD_window_clear(&ms->window);\n\n    ms->nextToUpdate = ms->window.dictLimit;\n    ms->loadedDictEnd = 0;\n    ms->opt.litLengthSum = 0;   \n    ms->dictMatchState = NULL;\n}\n\n \ntypedef enum {\n    ZSTDcrp_makeClean,\n    ZSTDcrp_leaveDirty\n} ZSTD_compResetPolicy_e;\n\n \ntypedef enum {\n    ZSTDirp_continue,\n    ZSTDirp_reset\n} ZSTD_indexResetPolicy_e;\n\ntypedef enum {\n    ZSTD_resetTarget_CDict,\n    ZSTD_resetTarget_CCtx\n} ZSTD_resetTarget_e;\n\n\nstatic size_t\nZSTD_reset_matchState(ZSTD_matchState_t* ms,\n                      ZSTD_cwksp* ws,\n                const ZSTD_compressionParameters* cParams,\n                const ZSTD_paramSwitch_e useRowMatchFinder,\n                const ZSTD_compResetPolicy_e crp,\n                const ZSTD_indexResetPolicy_e forceResetIndex,\n                const ZSTD_resetTarget_e forWho)\n{\n     \n    size_t const chainSize = ZSTD_allocateChainTable(cParams->strategy, useRowMatchFinder,\n                                                     ms->dedicatedDictSearch && (forWho == ZSTD_resetTarget_CDict))\n                                ? ((size_t)1 << cParams->chainLog)\n                                : 0;\n    size_t const hSize = ((size_t)1) << cParams->hashLog;\n    U32    const hashLog3 = ((forWho == ZSTD_resetTarget_CCtx) && cParams->minMatch==3) ? MIN(ZSTD_HASHLOG3_MAX, cParams->windowLog) : 0;\n    size_t const h3Size = hashLog3 ? ((size_t)1) << hashLog3 : 0;\n\n    DEBUGLOG(4, \"reset indices : %u\", forceResetIndex == ZSTDirp_reset);\n    assert(useRowMatchFinder != ZSTD_ps_auto);\n    if (forceResetIndex == ZSTDirp_reset) {\n        ZSTD_window_init(&ms->window);\n        ZSTD_cwksp_mark_tables_dirty(ws);\n    }\n\n    ms->hashLog3 = hashLog3;\n\n    ZSTD_invalidateMatchState(ms);\n\n    assert(!ZSTD_cwksp_reserve_failed(ws));  \n\n    ZSTD_cwksp_clear_tables(ws);\n\n    DEBUGLOG(5, \"reserving table space\");\n     \n    ms->hashTable = (U32*)ZSTD_cwksp_reserve_table(ws, hSize * sizeof(U32));\n    ms->chainTable = (U32*)ZSTD_cwksp_reserve_table(ws, chainSize * sizeof(U32));\n    ms->hashTable3 = (U32*)ZSTD_cwksp_reserve_table(ws, h3Size * sizeof(U32));\n    RETURN_ERROR_IF(ZSTD_cwksp_reserve_failed(ws), memory_allocation,\n                    \"failed a workspace allocation in ZSTD_reset_matchState\");\n\n    DEBUGLOG(4, \"reset table : %u\", crp!=ZSTDcrp_leaveDirty);\n    if (crp!=ZSTDcrp_leaveDirty) {\n         \n        ZSTD_cwksp_clean_tables(ws);\n    }\n\n     \n    if ((forWho == ZSTD_resetTarget_CCtx) && (cParams->strategy >= ZSTD_btopt)) {\n        DEBUGLOG(4, \"reserving optimal parser space\");\n        ms->opt.litFreq = (unsigned*)ZSTD_cwksp_reserve_aligned(ws, (1<<Litbits) * sizeof(unsigned));\n        ms->opt.litLengthFreq = (unsigned*)ZSTD_cwksp_reserve_aligned(ws, (MaxLL+1) * sizeof(unsigned));\n        ms->opt.matchLengthFreq = (unsigned*)ZSTD_cwksp_reserve_aligned(ws, (MaxML+1) * sizeof(unsigned));\n        ms->opt.offCodeFreq = (unsigned*)ZSTD_cwksp_reserve_aligned(ws, (MaxOff+1) * sizeof(unsigned));\n        ms->opt.matchTable = (ZSTD_match_t*)ZSTD_cwksp_reserve_aligned(ws, (ZSTD_OPT_NUM+1) * sizeof(ZSTD_match_t));\n        ms->opt.priceTable = (ZSTD_optimal_t*)ZSTD_cwksp_reserve_aligned(ws, (ZSTD_OPT_NUM+1) * sizeof(ZSTD_optimal_t));\n    }\n\n    if (ZSTD_rowMatchFinderUsed(cParams->strategy, useRowMatchFinder)) {\n        {    \n            size_t const tagTableSize = hSize*sizeof(U16);\n            ms->tagTable = (U16*)ZSTD_cwksp_reserve_aligned(ws, tagTableSize);\n            if (ms->tagTable) ZSTD_memset(ms->tagTable, 0, tagTableSize);\n        }\n        {    \n            U32 const rowLog = BOUNDED(4, cParams->searchLog, 6);\n            assert(cParams->hashLog >= rowLog);\n            ms->rowHashLog = cParams->hashLog - rowLog;\n        }\n    }\n\n    ms->cParams = *cParams;\n\n    RETURN_ERROR_IF(ZSTD_cwksp_reserve_failed(ws), memory_allocation,\n                    \"failed a workspace allocation in ZSTD_reset_matchState\");\n    return 0;\n}\n\n \n#define ZSTD_INDEXOVERFLOW_MARGIN (16 MB)\nstatic int ZSTD_indexTooCloseToMax(ZSTD_window_t w)\n{\n    return (size_t)(w.nextSrc - w.base) > (ZSTD_CURRENT_MAX - ZSTD_INDEXOVERFLOW_MARGIN);\n}\n\n \nstatic int ZSTD_dictTooBig(size_t const loadedDictSize)\n{\n    return loadedDictSize > ZSTD_CHUNKSIZE_MAX;\n}\n\n \nstatic size_t ZSTD_resetCCtx_internal(ZSTD_CCtx* zc,\n                                      ZSTD_CCtx_params const* params,\n                                      U64 const pledgedSrcSize,\n                                      size_t const loadedDictSize,\n                                      ZSTD_compResetPolicy_e const crp,\n                                      ZSTD_buffered_policy_e const zbuff)\n{\n    ZSTD_cwksp* const ws = &zc->workspace;\n    DEBUGLOG(4, \"ZSTD_resetCCtx_internal: pledgedSrcSize=%u, wlog=%u, useRowMatchFinder=%d useBlockSplitter=%d\",\n                (U32)pledgedSrcSize, params->cParams.windowLog, (int)params->useRowMatchFinder, (int)params->useBlockSplitter);\n    assert(!ZSTD_isError(ZSTD_checkCParams(params->cParams)));\n\n    zc->isFirstBlock = 1;\n\n     \n    zc->appliedParams = *params;\n    params = &zc->appliedParams;\n\n    assert(params->useRowMatchFinder != ZSTD_ps_auto);\n    assert(params->useBlockSplitter != ZSTD_ps_auto);\n    assert(params->ldmParams.enableLdm != ZSTD_ps_auto);\n    if (params->ldmParams.enableLdm == ZSTD_ps_enable) {\n         \n        ZSTD_ldm_adjustParameters(&zc->appliedParams.ldmParams, &params->cParams);\n        assert(params->ldmParams.hashLog >= params->ldmParams.bucketSizeLog);\n        assert(params->ldmParams.hashRateLog < 32);\n    }\n\n    {   size_t const windowSize = MAX(1, (size_t)MIN(((U64)1 << params->cParams.windowLog), pledgedSrcSize));\n        size_t const blockSize = MIN(ZSTD_BLOCKSIZE_MAX, windowSize);\n        U32    const divider = (params->cParams.minMatch==3) ? 3 : 4;\n        size_t const maxNbSeq = blockSize / divider;\n        size_t const buffOutSize = (zbuff == ZSTDb_buffered && params->outBufferMode == ZSTD_bm_buffered)\n                ? ZSTD_compressBound(blockSize) + 1\n                : 0;\n        size_t const buffInSize = (zbuff == ZSTDb_buffered && params->inBufferMode == ZSTD_bm_buffered)\n                ? windowSize + blockSize\n                : 0;\n        size_t const maxNbLdmSeq = ZSTD_ldm_getMaxNbSeq(params->ldmParams, blockSize);\n\n        int const indexTooClose = ZSTD_indexTooCloseToMax(zc->blockState.matchState.window);\n        int const dictTooBig = ZSTD_dictTooBig(loadedDictSize);\n        ZSTD_indexResetPolicy_e needsIndexReset =\n            (indexTooClose || dictTooBig || !zc->initialized) ? ZSTDirp_reset : ZSTDirp_continue;\n\n        size_t const neededSpace =\n            ZSTD_estimateCCtxSize_usingCCtxParams_internal(\n                &params->cParams, &params->ldmParams, zc->staticSize != 0, params->useRowMatchFinder,\n                buffInSize, buffOutSize, pledgedSrcSize);\n        int resizeWorkspace;\n\n        FORWARD_IF_ERROR(neededSpace, \"cctx size estimate failed!\");\n\n        if (!zc->staticSize) ZSTD_cwksp_bump_oversized_duration(ws, 0);\n\n        {    \n            int const workspaceTooSmall = ZSTD_cwksp_sizeof(ws) < neededSpace;\n            int const workspaceWasteful = ZSTD_cwksp_check_wasteful(ws, neededSpace);\n            resizeWorkspace = workspaceTooSmall || workspaceWasteful;\n            DEBUGLOG(4, \"Need %zu B workspace\", neededSpace);\n            DEBUGLOG(4, \"windowSize: %zu - blockSize: %zu\", windowSize, blockSize);\n\n            if (resizeWorkspace) {\n                DEBUGLOG(4, \"Resize workspaceSize from %zuKB to %zuKB\",\n                            ZSTD_cwksp_sizeof(ws) >> 10,\n                            neededSpace >> 10);\n\n                RETURN_ERROR_IF(zc->staticSize, memory_allocation, \"static cctx : no resize\");\n\n                needsIndexReset = ZSTDirp_reset;\n\n                ZSTD_cwksp_free(ws, zc->customMem);\n                FORWARD_IF_ERROR(ZSTD_cwksp_create(ws, neededSpace, zc->customMem), \"\");\n\n                DEBUGLOG(5, \"reserving object space\");\n                 \n                assert(ZSTD_cwksp_check_available(ws, 2 * sizeof(ZSTD_compressedBlockState_t)));\n                zc->blockState.prevCBlock = (ZSTD_compressedBlockState_t*) ZSTD_cwksp_reserve_object(ws, sizeof(ZSTD_compressedBlockState_t));\n                RETURN_ERROR_IF(zc->blockState.prevCBlock == NULL, memory_allocation, \"couldn't allocate prevCBlock\");\n                zc->blockState.nextCBlock = (ZSTD_compressedBlockState_t*) ZSTD_cwksp_reserve_object(ws, sizeof(ZSTD_compressedBlockState_t));\n                RETURN_ERROR_IF(zc->blockState.nextCBlock == NULL, memory_allocation, \"couldn't allocate nextCBlock\");\n                zc->entropyWorkspace = (U32*) ZSTD_cwksp_reserve_object(ws, ENTROPY_WORKSPACE_SIZE);\n                RETURN_ERROR_IF(zc->entropyWorkspace == NULL, memory_allocation, \"couldn't allocate entropyWorkspace\");\n        }   }\n\n        ZSTD_cwksp_clear(ws);\n\n         \n        zc->blockState.matchState.cParams = params->cParams;\n        zc->pledgedSrcSizePlusOne = pledgedSrcSize+1;\n        zc->consumedSrcSize = 0;\n        zc->producedCSize = 0;\n        if (pledgedSrcSize == ZSTD_CONTENTSIZE_UNKNOWN)\n            zc->appliedParams.fParams.contentSizeFlag = 0;\n        DEBUGLOG(4, \"pledged content size : %u ; flag : %u\",\n            (unsigned)pledgedSrcSize, zc->appliedParams.fParams.contentSizeFlag);\n        zc->blockSize = blockSize;\n\n        xxh64_reset(&zc->xxhState, 0);\n        zc->stage = ZSTDcs_init;\n        zc->dictID = 0;\n        zc->dictContentSize = 0;\n\n        ZSTD_reset_compressedBlockState(zc->blockState.prevCBlock);\n\n         \n        zc->seqStore.litStart = ZSTD_cwksp_reserve_buffer(ws, blockSize + WILDCOPY_OVERLENGTH);\n        zc->seqStore.maxNbLit = blockSize;\n\n         \n        zc->bufferedPolicy = zbuff;\n        zc->inBuffSize = buffInSize;\n        zc->inBuff = (char*)ZSTD_cwksp_reserve_buffer(ws, buffInSize);\n        zc->outBuffSize = buffOutSize;\n        zc->outBuff = (char*)ZSTD_cwksp_reserve_buffer(ws, buffOutSize);\n\n         \n        if (params->ldmParams.enableLdm == ZSTD_ps_enable) {\n             \n            size_t const numBuckets =\n                  ((size_t)1) << (params->ldmParams.hashLog -\n                                  params->ldmParams.bucketSizeLog);\n            zc->ldmState.bucketOffsets = ZSTD_cwksp_reserve_buffer(ws, numBuckets);\n            ZSTD_memset(zc->ldmState.bucketOffsets, 0, numBuckets);\n        }\n\n         \n        ZSTD_referenceExternalSequences(zc, NULL, 0);\n        zc->seqStore.maxNbSeq = maxNbSeq;\n        zc->seqStore.llCode = ZSTD_cwksp_reserve_buffer(ws, maxNbSeq * sizeof(BYTE));\n        zc->seqStore.mlCode = ZSTD_cwksp_reserve_buffer(ws, maxNbSeq * sizeof(BYTE));\n        zc->seqStore.ofCode = ZSTD_cwksp_reserve_buffer(ws, maxNbSeq * sizeof(BYTE));\n        zc->seqStore.sequencesStart = (seqDef*)ZSTD_cwksp_reserve_aligned(ws, maxNbSeq * sizeof(seqDef));\n\n        FORWARD_IF_ERROR(ZSTD_reset_matchState(\n            &zc->blockState.matchState,\n            ws,\n            &params->cParams,\n            params->useRowMatchFinder,\n            crp,\n            needsIndexReset,\n            ZSTD_resetTarget_CCtx), \"\");\n\n         \n        if (params->ldmParams.enableLdm == ZSTD_ps_enable) {\n             \n            size_t const ldmHSize = ((size_t)1) << params->ldmParams.hashLog;\n            zc->ldmState.hashTable = (ldmEntry_t*)ZSTD_cwksp_reserve_aligned(ws, ldmHSize * sizeof(ldmEntry_t));\n            ZSTD_memset(zc->ldmState.hashTable, 0, ldmHSize * sizeof(ldmEntry_t));\n            zc->ldmSequences = (rawSeq*)ZSTD_cwksp_reserve_aligned(ws, maxNbLdmSeq * sizeof(rawSeq));\n            zc->maxNbLdmSequences = maxNbLdmSeq;\n\n            ZSTD_window_init(&zc->ldmState.window);\n            zc->ldmState.loadedDictEnd = 0;\n        }\n\n        DEBUGLOG(3, \"wksp: finished allocating, %zd bytes remain available\", ZSTD_cwksp_available_space(ws));\n        assert(ZSTD_cwksp_estimated_space_within_bounds(ws, neededSpace, resizeWorkspace));\n\n        zc->initialized = 1;\n\n        return 0;\n    }\n}\n\n \nvoid ZSTD_invalidateRepCodes(ZSTD_CCtx* cctx) {\n    int i;\n    for (i=0; i<ZSTD_REP_NUM; i++) cctx->blockState.prevCBlock->rep[i] = 0;\n    assert(!ZSTD_window_hasExtDict(cctx->blockState.matchState.window));\n}\n\n \nstatic const size_t attachDictSizeCutoffs[ZSTD_STRATEGY_MAX+1] = {\n    8 KB,   \n    8 KB,   \n    16 KB,  \n    32 KB,  \n    32 KB,  \n    32 KB,  \n    32 KB,  \n    32 KB,  \n    8 KB,   \n    8 KB    \n};\n\nstatic int ZSTD_shouldAttachDict(const ZSTD_CDict* cdict,\n                                 const ZSTD_CCtx_params* params,\n                                 U64 pledgedSrcSize)\n{\n    size_t cutoff = attachDictSizeCutoffs[cdict->matchState.cParams.strategy];\n    int const dedicatedDictSearch = cdict->matchState.dedicatedDictSearch;\n    return dedicatedDictSearch\n        || ( ( pledgedSrcSize <= cutoff\n            || pledgedSrcSize == ZSTD_CONTENTSIZE_UNKNOWN\n            || params->attachDictPref == ZSTD_dictForceAttach )\n          && params->attachDictPref != ZSTD_dictForceCopy\n          && !params->forceWindow );  \n}\n\nstatic size_t\nZSTD_resetCCtx_byAttachingCDict(ZSTD_CCtx* cctx,\n                        const ZSTD_CDict* cdict,\n                        ZSTD_CCtx_params params,\n                        U64 pledgedSrcSize,\n                        ZSTD_buffered_policy_e zbuff)\n{\n    DEBUGLOG(4, \"ZSTD_resetCCtx_byAttachingCDict() pledgedSrcSize=%llu\",\n                (unsigned long long)pledgedSrcSize);\n    {\n        ZSTD_compressionParameters adjusted_cdict_cParams = cdict->matchState.cParams;\n        unsigned const windowLog = params.cParams.windowLog;\n        assert(windowLog != 0);\n         \n         \n\n        if (cdict->matchState.dedicatedDictSearch) {\n            ZSTD_dedicatedDictSearch_revertCParams(&adjusted_cdict_cParams);\n        }\n\n        params.cParams = ZSTD_adjustCParams_internal(adjusted_cdict_cParams, pledgedSrcSize,\n                                                     cdict->dictContentSize, ZSTD_cpm_attachDict);\n        params.cParams.windowLog = windowLog;\n        params.useRowMatchFinder = cdict->useRowMatchFinder;     \n        FORWARD_IF_ERROR(ZSTD_resetCCtx_internal(cctx, &params, pledgedSrcSize,\n                                                   0,\n                                                 ZSTDcrp_makeClean, zbuff), \"\");\n        assert(cctx->appliedParams.cParams.strategy == adjusted_cdict_cParams.strategy);\n    }\n\n    {   const U32 cdictEnd = (U32)( cdict->matchState.window.nextSrc\n                                  - cdict->matchState.window.base);\n        const U32 cdictLen = cdictEnd - cdict->matchState.window.dictLimit;\n        if (cdictLen == 0) {\n             \n            DEBUGLOG(4, \"skipping attaching empty dictionary\");\n        } else {\n            DEBUGLOG(4, \"attaching dictionary into context\");\n            cctx->blockState.matchState.dictMatchState = &cdict->matchState;\n\n             \n            if (cctx->blockState.matchState.window.dictLimit < cdictEnd) {\n                cctx->blockState.matchState.window.nextSrc =\n                    cctx->blockState.matchState.window.base + cdictEnd;\n                ZSTD_window_clear(&cctx->blockState.matchState.window);\n            }\n             \n            cctx->blockState.matchState.loadedDictEnd = cctx->blockState.matchState.window.dictLimit;\n    }   }\n\n    cctx->dictID = cdict->dictID;\n    cctx->dictContentSize = cdict->dictContentSize;\n\n     \n    ZSTD_memcpy(cctx->blockState.prevCBlock, &cdict->cBlockState, sizeof(cdict->cBlockState));\n\n    return 0;\n}\n\nstatic size_t ZSTD_resetCCtx_byCopyingCDict(ZSTD_CCtx* cctx,\n                            const ZSTD_CDict* cdict,\n                            ZSTD_CCtx_params params,\n                            U64 pledgedSrcSize,\n                            ZSTD_buffered_policy_e zbuff)\n{\n    const ZSTD_compressionParameters *cdict_cParams = &cdict->matchState.cParams;\n\n    assert(!cdict->matchState.dedicatedDictSearch);\n    DEBUGLOG(4, \"ZSTD_resetCCtx_byCopyingCDict() pledgedSrcSize=%llu\",\n                (unsigned long long)pledgedSrcSize);\n\n    {   unsigned const windowLog = params.cParams.windowLog;\n        assert(windowLog != 0);\n         \n        params.cParams = *cdict_cParams;\n        params.cParams.windowLog = windowLog;\n        params.useRowMatchFinder = cdict->useRowMatchFinder;\n        FORWARD_IF_ERROR(ZSTD_resetCCtx_internal(cctx, &params, pledgedSrcSize,\n                                                   0,\n                                                 ZSTDcrp_leaveDirty, zbuff), \"\");\n        assert(cctx->appliedParams.cParams.strategy == cdict_cParams->strategy);\n        assert(cctx->appliedParams.cParams.hashLog == cdict_cParams->hashLog);\n        assert(cctx->appliedParams.cParams.chainLog == cdict_cParams->chainLog);\n    }\n\n    ZSTD_cwksp_mark_tables_dirty(&cctx->workspace);\n    assert(params.useRowMatchFinder != ZSTD_ps_auto);\n\n     \n    {   size_t const chainSize = ZSTD_allocateChainTable(cdict_cParams->strategy, cdict->useRowMatchFinder, 0  )\n                                                            ? ((size_t)1 << cdict_cParams->chainLog)\n                                                            : 0;\n        size_t const hSize =  (size_t)1 << cdict_cParams->hashLog;\n\n        ZSTD_memcpy(cctx->blockState.matchState.hashTable,\n               cdict->matchState.hashTable,\n               hSize * sizeof(U32));\n         \n        if (ZSTD_allocateChainTable(cctx->appliedParams.cParams.strategy, cctx->appliedParams.useRowMatchFinder, 0  )) {\n            ZSTD_memcpy(cctx->blockState.matchState.chainTable,\n               cdict->matchState.chainTable,\n               chainSize * sizeof(U32));\n        }\n         \n        if (ZSTD_rowMatchFinderUsed(cdict_cParams->strategy, cdict->useRowMatchFinder)) {\n            size_t const tagTableSize = hSize*sizeof(U16);\n            ZSTD_memcpy(cctx->blockState.matchState.tagTable,\n                cdict->matchState.tagTable,\n                tagTableSize);\n        }\n    }\n\n     \n    {   int const h3log = cctx->blockState.matchState.hashLog3;\n        size_t const h3Size = h3log ? ((size_t)1 << h3log) : 0;\n        assert(cdict->matchState.hashLog3 == 0);\n        ZSTD_memset(cctx->blockState.matchState.hashTable3, 0, h3Size * sizeof(U32));\n    }\n\n    ZSTD_cwksp_mark_tables_clean(&cctx->workspace);\n\n     \n    {   ZSTD_matchState_t const* srcMatchState = &cdict->matchState;\n        ZSTD_matchState_t* dstMatchState = &cctx->blockState.matchState;\n        dstMatchState->window       = srcMatchState->window;\n        dstMatchState->nextToUpdate = srcMatchState->nextToUpdate;\n        dstMatchState->loadedDictEnd= srcMatchState->loadedDictEnd;\n    }\n\n    cctx->dictID = cdict->dictID;\n    cctx->dictContentSize = cdict->dictContentSize;\n\n     \n    ZSTD_memcpy(cctx->blockState.prevCBlock, &cdict->cBlockState, sizeof(cdict->cBlockState));\n\n    return 0;\n}\n\n \nstatic size_t ZSTD_resetCCtx_usingCDict(ZSTD_CCtx* cctx,\n                            const ZSTD_CDict* cdict,\n                            const ZSTD_CCtx_params* params,\n                            U64 pledgedSrcSize,\n                            ZSTD_buffered_policy_e zbuff)\n{\n\n    DEBUGLOG(4, \"ZSTD_resetCCtx_usingCDict (pledgedSrcSize=%u)\",\n                (unsigned)pledgedSrcSize);\n\n    if (ZSTD_shouldAttachDict(cdict, params, pledgedSrcSize)) {\n        return ZSTD_resetCCtx_byAttachingCDict(\n            cctx, cdict, *params, pledgedSrcSize, zbuff);\n    } else {\n        return ZSTD_resetCCtx_byCopyingCDict(\n            cctx, cdict, *params, pledgedSrcSize, zbuff);\n    }\n}\n\n \nstatic size_t ZSTD_copyCCtx_internal(ZSTD_CCtx* dstCCtx,\n                            const ZSTD_CCtx* srcCCtx,\n                            ZSTD_frameParameters fParams,\n                            U64 pledgedSrcSize,\n                            ZSTD_buffered_policy_e zbuff)\n{\n    RETURN_ERROR_IF(srcCCtx->stage!=ZSTDcs_init, stage_wrong,\n                    \"Can't copy a ctx that's not in init stage.\");\n    DEBUGLOG(5, \"ZSTD_copyCCtx_internal\");\n    ZSTD_memcpy(&dstCCtx->customMem, &srcCCtx->customMem, sizeof(ZSTD_customMem));\n    {   ZSTD_CCtx_params params = dstCCtx->requestedParams;\n         \n        params.cParams = srcCCtx->appliedParams.cParams;\n        assert(srcCCtx->appliedParams.useRowMatchFinder != ZSTD_ps_auto);\n        assert(srcCCtx->appliedParams.useBlockSplitter != ZSTD_ps_auto);\n        assert(srcCCtx->appliedParams.ldmParams.enableLdm != ZSTD_ps_auto);\n        params.useRowMatchFinder = srcCCtx->appliedParams.useRowMatchFinder;\n        params.useBlockSplitter = srcCCtx->appliedParams.useBlockSplitter;\n        params.ldmParams = srcCCtx->appliedParams.ldmParams;\n        params.fParams = fParams;\n        ZSTD_resetCCtx_internal(dstCCtx, &params, pledgedSrcSize,\n                                  0,\n                                ZSTDcrp_leaveDirty, zbuff);\n        assert(dstCCtx->appliedParams.cParams.windowLog == srcCCtx->appliedParams.cParams.windowLog);\n        assert(dstCCtx->appliedParams.cParams.strategy == srcCCtx->appliedParams.cParams.strategy);\n        assert(dstCCtx->appliedParams.cParams.hashLog == srcCCtx->appliedParams.cParams.hashLog);\n        assert(dstCCtx->appliedParams.cParams.chainLog == srcCCtx->appliedParams.cParams.chainLog);\n        assert(dstCCtx->blockState.matchState.hashLog3 == srcCCtx->blockState.matchState.hashLog3);\n    }\n\n    ZSTD_cwksp_mark_tables_dirty(&dstCCtx->workspace);\n\n     \n    {   size_t const chainSize = ZSTD_allocateChainTable(srcCCtx->appliedParams.cParams.strategy,\n                                                         srcCCtx->appliedParams.useRowMatchFinder,\n                                                         0  )\n                                    ? ((size_t)1 << srcCCtx->appliedParams.cParams.chainLog)\n                                    : 0;\n        size_t const hSize =  (size_t)1 << srcCCtx->appliedParams.cParams.hashLog;\n        int const h3log = srcCCtx->blockState.matchState.hashLog3;\n        size_t const h3Size = h3log ? ((size_t)1 << h3log) : 0;\n\n        ZSTD_memcpy(dstCCtx->blockState.matchState.hashTable,\n               srcCCtx->blockState.matchState.hashTable,\n               hSize * sizeof(U32));\n        ZSTD_memcpy(dstCCtx->blockState.matchState.chainTable,\n               srcCCtx->blockState.matchState.chainTable,\n               chainSize * sizeof(U32));\n        ZSTD_memcpy(dstCCtx->blockState.matchState.hashTable3,\n               srcCCtx->blockState.matchState.hashTable3,\n               h3Size * sizeof(U32));\n    }\n\n    ZSTD_cwksp_mark_tables_clean(&dstCCtx->workspace);\n\n     \n    {\n        const ZSTD_matchState_t* srcMatchState = &srcCCtx->blockState.matchState;\n        ZSTD_matchState_t* dstMatchState = &dstCCtx->blockState.matchState;\n        dstMatchState->window       = srcMatchState->window;\n        dstMatchState->nextToUpdate = srcMatchState->nextToUpdate;\n        dstMatchState->loadedDictEnd= srcMatchState->loadedDictEnd;\n    }\n    dstCCtx->dictID = srcCCtx->dictID;\n    dstCCtx->dictContentSize = srcCCtx->dictContentSize;\n\n     \n    ZSTD_memcpy(dstCCtx->blockState.prevCBlock, srcCCtx->blockState.prevCBlock, sizeof(*srcCCtx->blockState.prevCBlock));\n\n    return 0;\n}\n\n \nsize_t ZSTD_copyCCtx(ZSTD_CCtx* dstCCtx, const ZSTD_CCtx* srcCCtx, unsigned long long pledgedSrcSize)\n{\n    ZSTD_frameParameters fParams = { 1  , 0  , 0   };\n    ZSTD_buffered_policy_e const zbuff = srcCCtx->bufferedPolicy;\n    ZSTD_STATIC_ASSERT((U32)ZSTDb_buffered==1);\n    if (pledgedSrcSize==0) pledgedSrcSize = ZSTD_CONTENTSIZE_UNKNOWN;\n    fParams.contentSizeFlag = (pledgedSrcSize != ZSTD_CONTENTSIZE_UNKNOWN);\n\n    return ZSTD_copyCCtx_internal(dstCCtx, srcCCtx,\n                                fParams, pledgedSrcSize,\n                                zbuff);\n}\n\n\n#define ZSTD_ROWSIZE 16\n \nFORCE_INLINE_TEMPLATE void\nZSTD_reduceTable_internal (U32* const table, U32 const size, U32 const reducerValue, int const preserveMark)\n{\n    int const nbRows = (int)size / ZSTD_ROWSIZE;\n    int cellNb = 0;\n    int rowNb;\n     \n    U32 const reducerThreshold = reducerValue + ZSTD_WINDOW_START_INDEX;\n    assert((size & (ZSTD_ROWSIZE-1)) == 0);   \n    assert(size < (1U<<31));    \n\n\n    for (rowNb=0 ; rowNb < nbRows ; rowNb++) {\n        int column;\n        for (column=0; column<ZSTD_ROWSIZE; column++) {\n            U32 newVal;\n            if (preserveMark && table[cellNb] == ZSTD_DUBT_UNSORTED_MARK) {\n                 \n                newVal = ZSTD_DUBT_UNSORTED_MARK;\n            } else if (table[cellNb] < reducerThreshold) {\n                newVal = 0;\n            } else {\n                newVal = table[cellNb] - reducerValue;\n            }\n            table[cellNb] = newVal;\n            cellNb++;\n    }   }\n}\n\nstatic void ZSTD_reduceTable(U32* const table, U32 const size, U32 const reducerValue)\n{\n    ZSTD_reduceTable_internal(table, size, reducerValue, 0);\n}\n\nstatic void ZSTD_reduceTable_btlazy2(U32* const table, U32 const size, U32 const reducerValue)\n{\n    ZSTD_reduceTable_internal(table, size, reducerValue, 1);\n}\n\n \nstatic void ZSTD_reduceIndex (ZSTD_matchState_t* ms, ZSTD_CCtx_params const* params, const U32 reducerValue)\n{\n    {   U32 const hSize = (U32)1 << params->cParams.hashLog;\n        ZSTD_reduceTable(ms->hashTable, hSize, reducerValue);\n    }\n\n    if (ZSTD_allocateChainTable(params->cParams.strategy, params->useRowMatchFinder, (U32)ms->dedicatedDictSearch)) {\n        U32 const chainSize = (U32)1 << params->cParams.chainLog;\n        if (params->cParams.strategy == ZSTD_btlazy2)\n            ZSTD_reduceTable_btlazy2(ms->chainTable, chainSize, reducerValue);\n        else\n            ZSTD_reduceTable(ms->chainTable, chainSize, reducerValue);\n    }\n\n    if (ms->hashLog3) {\n        U32 const h3Size = (U32)1 << ms->hashLog3;\n        ZSTD_reduceTable(ms->hashTable3, h3Size, reducerValue);\n    }\n}\n\n\n \n\n \n\nvoid ZSTD_seqToCodes(const seqStore_t* seqStorePtr)\n{\n    const seqDef* const sequences = seqStorePtr->sequencesStart;\n    BYTE* const llCodeTable = seqStorePtr->llCode;\n    BYTE* const ofCodeTable = seqStorePtr->ofCode;\n    BYTE* const mlCodeTable = seqStorePtr->mlCode;\n    U32 const nbSeq = (U32)(seqStorePtr->sequences - seqStorePtr->sequencesStart);\n    U32 u;\n    assert(nbSeq <= seqStorePtr->maxNbSeq);\n    for (u=0; u<nbSeq; u++) {\n        U32 const llv = sequences[u].litLength;\n        U32 const mlv = sequences[u].mlBase;\n        llCodeTable[u] = (BYTE)ZSTD_LLcode(llv);\n        ofCodeTable[u] = (BYTE)ZSTD_highbit32(sequences[u].offBase);\n        mlCodeTable[u] = (BYTE)ZSTD_MLcode(mlv);\n    }\n    if (seqStorePtr->longLengthType==ZSTD_llt_literalLength)\n        llCodeTable[seqStorePtr->longLengthPos] = MaxLL;\n    if (seqStorePtr->longLengthType==ZSTD_llt_matchLength)\n        mlCodeTable[seqStorePtr->longLengthPos] = MaxML;\n}\n\n \nstatic int ZSTD_useTargetCBlockSize(const ZSTD_CCtx_params* cctxParams)\n{\n    DEBUGLOG(5, \"ZSTD_useTargetCBlockSize (targetCBlockSize=%zu)\", cctxParams->targetCBlockSize);\n    return (cctxParams->targetCBlockSize != 0);\n}\n\n \nstatic int ZSTD_blockSplitterEnabled(ZSTD_CCtx_params* cctxParams)\n{\n    DEBUGLOG(5, \"ZSTD_blockSplitterEnabled (useBlockSplitter=%d)\", cctxParams->useBlockSplitter);\n    assert(cctxParams->useBlockSplitter != ZSTD_ps_auto);\n    return (cctxParams->useBlockSplitter == ZSTD_ps_enable);\n}\n\n \ntypedef struct {\n    U32 LLtype;\n    U32 Offtype;\n    U32 MLtype;\n    size_t size;\n    size_t lastCountSize;  \n} ZSTD_symbolEncodingTypeStats_t;\n\n \nstatic ZSTD_symbolEncodingTypeStats_t\nZSTD_buildSequencesStatistics(seqStore_t* seqStorePtr, size_t nbSeq,\n                        const ZSTD_fseCTables_t* prevEntropy, ZSTD_fseCTables_t* nextEntropy,\n                              BYTE* dst, const BYTE* const dstEnd,\n                              ZSTD_strategy strategy, unsigned* countWorkspace,\n                              void* entropyWorkspace, size_t entropyWkspSize) {\n    BYTE* const ostart = dst;\n    const BYTE* const oend = dstEnd;\n    BYTE* op = ostart;\n    FSE_CTable* CTable_LitLength = nextEntropy->litlengthCTable;\n    FSE_CTable* CTable_OffsetBits = nextEntropy->offcodeCTable;\n    FSE_CTable* CTable_MatchLength = nextEntropy->matchlengthCTable;\n    const BYTE* const ofCodeTable = seqStorePtr->ofCode;\n    const BYTE* const llCodeTable = seqStorePtr->llCode;\n    const BYTE* const mlCodeTable = seqStorePtr->mlCode;\n    ZSTD_symbolEncodingTypeStats_t stats;\n\n    stats.lastCountSize = 0;\n     \n    ZSTD_seqToCodes(seqStorePtr);\n    assert(op <= oend);\n    assert(nbSeq != 0);  \n     \n    {   unsigned max = MaxLL;\n        size_t const mostFrequent = HIST_countFast_wksp(countWorkspace, &max, llCodeTable, nbSeq, entropyWorkspace, entropyWkspSize);    \n        DEBUGLOG(5, \"Building LL table\");\n        nextEntropy->litlength_repeatMode = prevEntropy->litlength_repeatMode;\n        stats.LLtype = ZSTD_selectEncodingType(&nextEntropy->litlength_repeatMode,\n                                        countWorkspace, max, mostFrequent, nbSeq,\n                                        LLFSELog, prevEntropy->litlengthCTable,\n                                        LL_defaultNorm, LL_defaultNormLog,\n                                        ZSTD_defaultAllowed, strategy);\n        assert(set_basic < set_compressed && set_rle < set_compressed);\n        assert(!(stats.LLtype < set_compressed && nextEntropy->litlength_repeatMode != FSE_repeat_none));  \n        {   size_t const countSize = ZSTD_buildCTable(\n                op, (size_t)(oend - op),\n                CTable_LitLength, LLFSELog, (symbolEncodingType_e)stats.LLtype,\n                countWorkspace, max, llCodeTable, nbSeq,\n                LL_defaultNorm, LL_defaultNormLog, MaxLL,\n                prevEntropy->litlengthCTable,\n                sizeof(prevEntropy->litlengthCTable),\n                entropyWorkspace, entropyWkspSize);\n            if (ZSTD_isError(countSize)) {\n                DEBUGLOG(3, \"ZSTD_buildCTable for LitLens failed\");\n                stats.size = countSize;\n                return stats;\n            }\n            if (stats.LLtype == set_compressed)\n                stats.lastCountSize = countSize;\n            op += countSize;\n            assert(op <= oend);\n    }   }\n     \n    {   unsigned max = MaxOff;\n        size_t const mostFrequent = HIST_countFast_wksp(\n            countWorkspace, &max, ofCodeTable, nbSeq, entropyWorkspace, entropyWkspSize);   \n         \n        ZSTD_defaultPolicy_e const defaultPolicy = (max <= DefaultMaxOff) ? ZSTD_defaultAllowed : ZSTD_defaultDisallowed;\n        DEBUGLOG(5, \"Building OF table\");\n        nextEntropy->offcode_repeatMode = prevEntropy->offcode_repeatMode;\n        stats.Offtype = ZSTD_selectEncodingType(&nextEntropy->offcode_repeatMode,\n                                        countWorkspace, max, mostFrequent, nbSeq,\n                                        OffFSELog, prevEntropy->offcodeCTable,\n                                        OF_defaultNorm, OF_defaultNormLog,\n                                        defaultPolicy, strategy);\n        assert(!(stats.Offtype < set_compressed && nextEntropy->offcode_repeatMode != FSE_repeat_none));  \n        {   size_t const countSize = ZSTD_buildCTable(\n                op, (size_t)(oend - op),\n                CTable_OffsetBits, OffFSELog, (symbolEncodingType_e)stats.Offtype,\n                countWorkspace, max, ofCodeTable, nbSeq,\n                OF_defaultNorm, OF_defaultNormLog, DefaultMaxOff,\n                prevEntropy->offcodeCTable,\n                sizeof(prevEntropy->offcodeCTable),\n                entropyWorkspace, entropyWkspSize);\n            if (ZSTD_isError(countSize)) {\n                DEBUGLOG(3, \"ZSTD_buildCTable for Offsets failed\");\n                stats.size = countSize;\n                return stats;\n            }\n            if (stats.Offtype == set_compressed)\n                stats.lastCountSize = countSize;\n            op += countSize;\n            assert(op <= oend);\n    }   }\n     \n    {   unsigned max = MaxML;\n        size_t const mostFrequent = HIST_countFast_wksp(\n            countWorkspace, &max, mlCodeTable, nbSeq, entropyWorkspace, entropyWkspSize);    \n        DEBUGLOG(5, \"Building ML table (remaining space : %i)\", (int)(oend-op));\n        nextEntropy->matchlength_repeatMode = prevEntropy->matchlength_repeatMode;\n        stats.MLtype = ZSTD_selectEncodingType(&nextEntropy->matchlength_repeatMode,\n                                        countWorkspace, max, mostFrequent, nbSeq,\n                                        MLFSELog, prevEntropy->matchlengthCTable,\n                                        ML_defaultNorm, ML_defaultNormLog,\n                                        ZSTD_defaultAllowed, strategy);\n        assert(!(stats.MLtype < set_compressed && nextEntropy->matchlength_repeatMode != FSE_repeat_none));  \n        {   size_t const countSize = ZSTD_buildCTable(\n                op, (size_t)(oend - op),\n                CTable_MatchLength, MLFSELog, (symbolEncodingType_e)stats.MLtype,\n                countWorkspace, max, mlCodeTable, nbSeq,\n                ML_defaultNorm, ML_defaultNormLog, MaxML,\n                prevEntropy->matchlengthCTable,\n                sizeof(prevEntropy->matchlengthCTable),\n                entropyWorkspace, entropyWkspSize);\n            if (ZSTD_isError(countSize)) {\n                DEBUGLOG(3, \"ZSTD_buildCTable for MatchLengths failed\");\n                stats.size = countSize;\n                return stats;\n            }\n            if (stats.MLtype == set_compressed)\n                stats.lastCountSize = countSize;\n            op += countSize;\n            assert(op <= oend);\n    }   }\n    stats.size = (size_t)(op-ostart);\n    return stats;\n}\n\n \n#define SUSPECT_UNCOMPRESSIBLE_LITERAL_RATIO 20\nMEM_STATIC size_t\nZSTD_entropyCompressSeqStore_internal(seqStore_t* seqStorePtr,\n                          const ZSTD_entropyCTables_t* prevEntropy,\n                                ZSTD_entropyCTables_t* nextEntropy,\n                          const ZSTD_CCtx_params* cctxParams,\n                                void* dst, size_t dstCapacity,\n                                void* entropyWorkspace, size_t entropyWkspSize,\n                          const int bmi2)\n{\n    const int longOffsets = cctxParams->cParams.windowLog > STREAM_ACCUMULATOR_MIN;\n    ZSTD_strategy const strategy = cctxParams->cParams.strategy;\n    unsigned* count = (unsigned*)entropyWorkspace;\n    FSE_CTable* CTable_LitLength = nextEntropy->fse.litlengthCTable;\n    FSE_CTable* CTable_OffsetBits = nextEntropy->fse.offcodeCTable;\n    FSE_CTable* CTable_MatchLength = nextEntropy->fse.matchlengthCTable;\n    const seqDef* const sequences = seqStorePtr->sequencesStart;\n    const size_t nbSeq = seqStorePtr->sequences - seqStorePtr->sequencesStart;\n    const BYTE* const ofCodeTable = seqStorePtr->ofCode;\n    const BYTE* const llCodeTable = seqStorePtr->llCode;\n    const BYTE* const mlCodeTable = seqStorePtr->mlCode;\n    BYTE* const ostart = (BYTE*)dst;\n    BYTE* const oend = ostart + dstCapacity;\n    BYTE* op = ostart;\n    size_t lastCountSize;\n\n    entropyWorkspace = count + (MaxSeq + 1);\n    entropyWkspSize -= (MaxSeq + 1) * sizeof(*count);\n\n    DEBUGLOG(4, \"ZSTD_entropyCompressSeqStore_internal (nbSeq=%zu)\", nbSeq);\n    ZSTD_STATIC_ASSERT(HUF_WORKSPACE_SIZE >= (1<<MAX(MLFSELog,LLFSELog)));\n    assert(entropyWkspSize >= HUF_WORKSPACE_SIZE);\n\n     \n    {   const BYTE* const literals = seqStorePtr->litStart;\n        size_t const numSequences = seqStorePtr->sequences - seqStorePtr->sequencesStart;\n        size_t const numLiterals = seqStorePtr->lit - seqStorePtr->litStart;\n         \n        unsigned const suspectUncompressible = (numSequences == 0) || (numLiterals / numSequences >= SUSPECT_UNCOMPRESSIBLE_LITERAL_RATIO);\n        size_t const litSize = (size_t)(seqStorePtr->lit - literals);\n        size_t const cSize = ZSTD_compressLiterals(\n                                    &prevEntropy->huf, &nextEntropy->huf,\n                                    cctxParams->cParams.strategy,\n                                    ZSTD_literalsCompressionIsDisabled(cctxParams),\n                                    op, dstCapacity,\n                                    literals, litSize,\n                                    entropyWorkspace, entropyWkspSize,\n                                    bmi2, suspectUncompressible);\n        FORWARD_IF_ERROR(cSize, \"ZSTD_compressLiterals failed\");\n        assert(cSize <= dstCapacity);\n        op += cSize;\n    }\n\n     \n    RETURN_ERROR_IF((oend-op) < 3   + 1  ,\n                    dstSize_tooSmall, \"Can't fit seq hdr in output buf!\");\n    if (nbSeq < 128) {\n        *op++ = (BYTE)nbSeq;\n    } else if (nbSeq < LONGNBSEQ) {\n        op[0] = (BYTE)((nbSeq>>8) + 0x80);\n        op[1] = (BYTE)nbSeq;\n        op+=2;\n    } else {\n        op[0]=0xFF;\n        MEM_writeLE16(op+1, (U16)(nbSeq - LONGNBSEQ));\n        op+=3;\n    }\n    assert(op <= oend);\n    if (nbSeq==0) {\n         \n        ZSTD_memcpy(&nextEntropy->fse, &prevEntropy->fse, sizeof(prevEntropy->fse));\n        return (size_t)(op - ostart);\n    }\n    {\n        ZSTD_symbolEncodingTypeStats_t stats;\n        BYTE* seqHead = op++;\n         \n        stats = ZSTD_buildSequencesStatistics(seqStorePtr, nbSeq,\n                                             &prevEntropy->fse, &nextEntropy->fse,\n                                              op, oend,\n                                              strategy, count,\n                                              entropyWorkspace, entropyWkspSize);\n        FORWARD_IF_ERROR(stats.size, \"ZSTD_buildSequencesStatistics failed!\");\n        *seqHead = (BYTE)((stats.LLtype<<6) + (stats.Offtype<<4) + (stats.MLtype<<2));\n        lastCountSize = stats.lastCountSize;\n        op += stats.size;\n    }\n\n    {   size_t const bitstreamSize = ZSTD_encodeSequences(\n                                        op, (size_t)(oend - op),\n                                        CTable_MatchLength, mlCodeTable,\n                                        CTable_OffsetBits, ofCodeTable,\n                                        CTable_LitLength, llCodeTable,\n                                        sequences, nbSeq,\n                                        longOffsets, bmi2);\n        FORWARD_IF_ERROR(bitstreamSize, \"ZSTD_encodeSequences failed\");\n        op += bitstreamSize;\n        assert(op <= oend);\n         \n        if (lastCountSize && (lastCountSize + bitstreamSize) < 4) {\n             \n            assert(lastCountSize + bitstreamSize == 3);\n            DEBUGLOG(5, \"Avoiding bug in zstd decoder in versions <= 1.3.4 by \"\n                        \"emitting an uncompressed block.\");\n            return 0;\n        }\n    }\n\n    DEBUGLOG(5, \"compressed block size : %u\", (unsigned)(op - ostart));\n    return (size_t)(op - ostart);\n}\n\nMEM_STATIC size_t\nZSTD_entropyCompressSeqStore(seqStore_t* seqStorePtr,\n                       const ZSTD_entropyCTables_t* prevEntropy,\n                             ZSTD_entropyCTables_t* nextEntropy,\n                       const ZSTD_CCtx_params* cctxParams,\n                             void* dst, size_t dstCapacity,\n                             size_t srcSize,\n                             void* entropyWorkspace, size_t entropyWkspSize,\n                             int bmi2)\n{\n    size_t const cSize = ZSTD_entropyCompressSeqStore_internal(\n                            seqStorePtr, prevEntropy, nextEntropy, cctxParams,\n                            dst, dstCapacity,\n                            entropyWorkspace, entropyWkspSize, bmi2);\n    if (cSize == 0) return 0;\n     \n    if ((cSize == ERROR(dstSize_tooSmall)) & (srcSize <= dstCapacity))\n        return 0;   \n    FORWARD_IF_ERROR(cSize, \"ZSTD_entropyCompressSeqStore_internal failed\");\n\n     \n    {   size_t const maxCSize = srcSize - ZSTD_minGain(srcSize, cctxParams->cParams.strategy);\n        if (cSize >= maxCSize) return 0;   \n    }\n    DEBUGLOG(4, \"ZSTD_entropyCompressSeqStore() cSize: %zu\", cSize);\n    return cSize;\n}\n\n \nZSTD_blockCompressor ZSTD_selectBlockCompressor(ZSTD_strategy strat, ZSTD_paramSwitch_e useRowMatchFinder, ZSTD_dictMode_e dictMode)\n{\n    static const ZSTD_blockCompressor blockCompressor[4][ZSTD_STRATEGY_MAX+1] = {\n        { ZSTD_compressBlock_fast   ,\n          ZSTD_compressBlock_fast,\n          ZSTD_compressBlock_doubleFast,\n          ZSTD_compressBlock_greedy,\n          ZSTD_compressBlock_lazy,\n          ZSTD_compressBlock_lazy2,\n          ZSTD_compressBlock_btlazy2,\n          ZSTD_compressBlock_btopt,\n          ZSTD_compressBlock_btultra,\n          ZSTD_compressBlock_btultra2 },\n        { ZSTD_compressBlock_fast_extDict   ,\n          ZSTD_compressBlock_fast_extDict,\n          ZSTD_compressBlock_doubleFast_extDict,\n          ZSTD_compressBlock_greedy_extDict,\n          ZSTD_compressBlock_lazy_extDict,\n          ZSTD_compressBlock_lazy2_extDict,\n          ZSTD_compressBlock_btlazy2_extDict,\n          ZSTD_compressBlock_btopt_extDict,\n          ZSTD_compressBlock_btultra_extDict,\n          ZSTD_compressBlock_btultra_extDict },\n        { ZSTD_compressBlock_fast_dictMatchState   ,\n          ZSTD_compressBlock_fast_dictMatchState,\n          ZSTD_compressBlock_doubleFast_dictMatchState,\n          ZSTD_compressBlock_greedy_dictMatchState,\n          ZSTD_compressBlock_lazy_dictMatchState,\n          ZSTD_compressBlock_lazy2_dictMatchState,\n          ZSTD_compressBlock_btlazy2_dictMatchState,\n          ZSTD_compressBlock_btopt_dictMatchState,\n          ZSTD_compressBlock_btultra_dictMatchState,\n          ZSTD_compressBlock_btultra_dictMatchState },\n        { NULL   ,\n          NULL,\n          NULL,\n          ZSTD_compressBlock_greedy_dedicatedDictSearch,\n          ZSTD_compressBlock_lazy_dedicatedDictSearch,\n          ZSTD_compressBlock_lazy2_dedicatedDictSearch,\n          NULL,\n          NULL,\n          NULL,\n          NULL }\n    };\n    ZSTD_blockCompressor selectedCompressor;\n    ZSTD_STATIC_ASSERT((unsigned)ZSTD_fast == 1);\n\n    assert(ZSTD_cParam_withinBounds(ZSTD_c_strategy, strat));\n    DEBUGLOG(4, \"Selected block compressor: dictMode=%d strat=%d rowMatchfinder=%d\", (int)dictMode, (int)strat, (int)useRowMatchFinder);\n    if (ZSTD_rowMatchFinderUsed(strat, useRowMatchFinder)) {\n        static const ZSTD_blockCompressor rowBasedBlockCompressors[4][3] = {\n            { ZSTD_compressBlock_greedy_row,\n            ZSTD_compressBlock_lazy_row,\n            ZSTD_compressBlock_lazy2_row },\n            { ZSTD_compressBlock_greedy_extDict_row,\n            ZSTD_compressBlock_lazy_extDict_row,\n            ZSTD_compressBlock_lazy2_extDict_row },\n            { ZSTD_compressBlock_greedy_dictMatchState_row,\n            ZSTD_compressBlock_lazy_dictMatchState_row,\n            ZSTD_compressBlock_lazy2_dictMatchState_row },\n            { ZSTD_compressBlock_greedy_dedicatedDictSearch_row,\n            ZSTD_compressBlock_lazy_dedicatedDictSearch_row,\n            ZSTD_compressBlock_lazy2_dedicatedDictSearch_row }\n        };\n        DEBUGLOG(4, \"Selecting a row-based matchfinder\");\n        assert(useRowMatchFinder != ZSTD_ps_auto);\n        selectedCompressor = rowBasedBlockCompressors[(int)dictMode][(int)strat - (int)ZSTD_greedy];\n    } else {\n        selectedCompressor = blockCompressor[(int)dictMode][(int)strat];\n    }\n    assert(selectedCompressor != NULL);\n    return selectedCompressor;\n}\n\nstatic void ZSTD_storeLastLiterals(seqStore_t* seqStorePtr,\n                                   const BYTE* anchor, size_t lastLLSize)\n{\n    ZSTD_memcpy(seqStorePtr->lit, anchor, lastLLSize);\n    seqStorePtr->lit += lastLLSize;\n}\n\nvoid ZSTD_resetSeqStore(seqStore_t* ssPtr)\n{\n    ssPtr->lit = ssPtr->litStart;\n    ssPtr->sequences = ssPtr->sequencesStart;\n    ssPtr->longLengthType = ZSTD_llt_none;\n}\n\ntypedef enum { ZSTDbss_compress, ZSTDbss_noCompress } ZSTD_buildSeqStore_e;\n\nstatic size_t ZSTD_buildSeqStore(ZSTD_CCtx* zc, const void* src, size_t srcSize)\n{\n    ZSTD_matchState_t* const ms = &zc->blockState.matchState;\n    DEBUGLOG(5, \"ZSTD_buildSeqStore (srcSize=%zu)\", srcSize);\n    assert(srcSize <= ZSTD_BLOCKSIZE_MAX);\n     \n    ZSTD_assertEqualCParams(zc->appliedParams.cParams, ms->cParams);\n    if (srcSize < MIN_CBLOCK_SIZE+ZSTD_blockHeaderSize+1) {\n        if (zc->appliedParams.cParams.strategy >= ZSTD_btopt) {\n            ZSTD_ldm_skipRawSeqStoreBytes(&zc->externSeqStore, srcSize);\n        } else {\n            ZSTD_ldm_skipSequences(&zc->externSeqStore, srcSize, zc->appliedParams.cParams.minMatch);\n        }\n        return ZSTDbss_noCompress;  \n    }\n    ZSTD_resetSeqStore(&(zc->seqStore));\n     \n    ms->opt.symbolCosts = &zc->blockState.prevCBlock->entropy;\n     \n    ms->opt.literalCompressionMode = zc->appliedParams.literalCompressionMode;\n     \n    assert(ms->dictMatchState == NULL || ms->loadedDictEnd == ms->window.dictLimit);\n\n     \n    {   const BYTE* const base = ms->window.base;\n        const BYTE* const istart = (const BYTE*)src;\n        const U32 curr = (U32)(istart-base);\n        if (sizeof(ptrdiff_t)==8) assert(istart - base < (ptrdiff_t)(U32)(-1));    \n        if (curr > ms->nextToUpdate + 384)\n            ms->nextToUpdate = curr - MIN(192, (U32)(curr - ms->nextToUpdate - 384));\n    }\n\n     \n    {   ZSTD_dictMode_e const dictMode = ZSTD_matchState_dictMode(ms);\n        size_t lastLLSize;\n        {   int i;\n            for (i = 0; i < ZSTD_REP_NUM; ++i)\n                zc->blockState.nextCBlock->rep[i] = zc->blockState.prevCBlock->rep[i];\n        }\n        if (zc->externSeqStore.pos < zc->externSeqStore.size) {\n            assert(zc->appliedParams.ldmParams.enableLdm == ZSTD_ps_disable);\n             \n            lastLLSize =\n                ZSTD_ldm_blockCompress(&zc->externSeqStore,\n                                       ms, &zc->seqStore,\n                                       zc->blockState.nextCBlock->rep,\n                                       zc->appliedParams.useRowMatchFinder,\n                                       src, srcSize);\n            assert(zc->externSeqStore.pos <= zc->externSeqStore.size);\n        } else if (zc->appliedParams.ldmParams.enableLdm == ZSTD_ps_enable) {\n            rawSeqStore_t ldmSeqStore = kNullRawSeqStore;\n\n            ldmSeqStore.seq = zc->ldmSequences;\n            ldmSeqStore.capacity = zc->maxNbLdmSequences;\n             \n            FORWARD_IF_ERROR(ZSTD_ldm_generateSequences(&zc->ldmState, &ldmSeqStore,\n                                               &zc->appliedParams.ldmParams,\n                                               src, srcSize), \"\");\n             \n            lastLLSize =\n                ZSTD_ldm_blockCompress(&ldmSeqStore,\n                                       ms, &zc->seqStore,\n                                       zc->blockState.nextCBlock->rep,\n                                       zc->appliedParams.useRowMatchFinder,\n                                       src, srcSize);\n            assert(ldmSeqStore.pos == ldmSeqStore.size);\n        } else {    \n            ZSTD_blockCompressor const blockCompressor = ZSTD_selectBlockCompressor(zc->appliedParams.cParams.strategy,\n                                                                                    zc->appliedParams.useRowMatchFinder,\n                                                                                    dictMode);\n            ms->ldmSeqStore = NULL;\n            lastLLSize = blockCompressor(ms, &zc->seqStore, zc->blockState.nextCBlock->rep, src, srcSize);\n        }\n        {   const BYTE* const lastLiterals = (const BYTE*)src + srcSize - lastLLSize;\n            ZSTD_storeLastLiterals(&zc->seqStore, lastLiterals, lastLLSize);\n    }   }\n    return ZSTDbss_compress;\n}\n\nstatic void ZSTD_copyBlockSequences(ZSTD_CCtx* zc)\n{\n    const seqStore_t* seqStore = ZSTD_getSeqStore(zc);\n    const seqDef* seqStoreSeqs = seqStore->sequencesStart;\n    size_t seqStoreSeqSize = seqStore->sequences - seqStoreSeqs;\n    size_t seqStoreLiteralsSize = (size_t)(seqStore->lit - seqStore->litStart);\n    size_t literalsRead = 0;\n    size_t lastLLSize;\n\n    ZSTD_Sequence* outSeqs = &zc->seqCollector.seqStart[zc->seqCollector.seqIndex];\n    size_t i;\n    repcodes_t updatedRepcodes;\n\n    assert(zc->seqCollector.seqIndex + 1 < zc->seqCollector.maxSequences);\n     \n    assert(zc->seqCollector.maxSequences >= seqStoreSeqSize + 1);\n    ZSTD_memcpy(updatedRepcodes.rep, zc->blockState.prevCBlock->rep, sizeof(repcodes_t));\n    for (i = 0; i < seqStoreSeqSize; ++i) {\n        U32 rawOffset = seqStoreSeqs[i].offBase - ZSTD_REP_NUM;\n        outSeqs[i].litLength = seqStoreSeqs[i].litLength;\n        outSeqs[i].matchLength = seqStoreSeqs[i].mlBase + MINMATCH;\n        outSeqs[i].rep = 0;\n\n        if (i == seqStore->longLengthPos) {\n            if (seqStore->longLengthType == ZSTD_llt_literalLength) {\n                outSeqs[i].litLength += 0x10000;\n            } else if (seqStore->longLengthType == ZSTD_llt_matchLength) {\n                outSeqs[i].matchLength += 0x10000;\n            }\n        }\n\n        if (seqStoreSeqs[i].offBase <= ZSTD_REP_NUM) {\n             \n            outSeqs[i].rep = seqStoreSeqs[i].offBase;\n            if (outSeqs[i].litLength != 0) {\n                rawOffset = updatedRepcodes.rep[outSeqs[i].rep - 1];\n            } else {\n                if (outSeqs[i].rep == 3) {\n                    rawOffset = updatedRepcodes.rep[0] - 1;\n                } else {\n                    rawOffset = updatedRepcodes.rep[outSeqs[i].rep];\n                }\n            }\n        }\n        outSeqs[i].offset = rawOffset;\n         \n        ZSTD_updateRep(updatedRepcodes.rep,\n                       seqStoreSeqs[i].offBase - 1,\n                       seqStoreSeqs[i].litLength == 0);\n        literalsRead += outSeqs[i].litLength;\n    }\n     \n    assert(seqStoreLiteralsSize >= literalsRead);\n    lastLLSize = seqStoreLiteralsSize - literalsRead;\n    outSeqs[i].litLength = (U32)lastLLSize;\n    outSeqs[i].matchLength = outSeqs[i].offset = outSeqs[i].rep = 0;\n    seqStoreSeqSize++;\n    zc->seqCollector.seqIndex += seqStoreSeqSize;\n}\n\nsize_t ZSTD_generateSequences(ZSTD_CCtx* zc, ZSTD_Sequence* outSeqs,\n                              size_t outSeqsSize, const void* src, size_t srcSize)\n{\n    const size_t dstCapacity = ZSTD_compressBound(srcSize);\n    void* dst = ZSTD_customMalloc(dstCapacity, ZSTD_defaultCMem);\n    SeqCollector seqCollector;\n\n    RETURN_ERROR_IF(dst == NULL, memory_allocation, \"NULL pointer!\");\n\n    seqCollector.collectSequences = 1;\n    seqCollector.seqStart = outSeqs;\n    seqCollector.seqIndex = 0;\n    seqCollector.maxSequences = outSeqsSize;\n    zc->seqCollector = seqCollector;\n\n    ZSTD_compress2(zc, dst, dstCapacity, src, srcSize);\n    ZSTD_customFree(dst, ZSTD_defaultCMem);\n    return zc->seqCollector.seqIndex;\n}\n\nsize_t ZSTD_mergeBlockDelimiters(ZSTD_Sequence* sequences, size_t seqsSize) {\n    size_t in = 0;\n    size_t out = 0;\n    for (; in < seqsSize; ++in) {\n        if (sequences[in].offset == 0 && sequences[in].matchLength == 0) {\n            if (in != seqsSize - 1) {\n                sequences[in+1].litLength += sequences[in].litLength;\n            }\n        } else {\n            sequences[out] = sequences[in];\n            ++out;\n        }\n    }\n    return out;\n}\n\n \nstatic int ZSTD_isRLE(const BYTE* src, size_t length) {\n    const BYTE* ip = src;\n    const BYTE value = ip[0];\n    const size_t valueST = (size_t)((U64)value * 0x0101010101010101ULL);\n    const size_t unrollSize = sizeof(size_t) * 4;\n    const size_t unrollMask = unrollSize - 1;\n    const size_t prefixLength = length & unrollMask;\n    size_t i;\n    size_t u;\n    if (length == 1) return 1;\n     \n    if (prefixLength && ZSTD_count(ip+1, ip, ip+prefixLength) != prefixLength-1) {\n        return 0;\n    }\n    for (i = prefixLength; i != length; i += unrollSize) {\n        for (u = 0; u < unrollSize; u += sizeof(size_t)) {\n            if (MEM_readST(ip + i + u) != valueST) {\n                return 0;\n            }\n        }\n    }\n    return 1;\n}\n\n \nstatic int ZSTD_maybeRLE(seqStore_t const* seqStore)\n{\n    size_t const nbSeqs = (size_t)(seqStore->sequences - seqStore->sequencesStart);\n    size_t const nbLits = (size_t)(seqStore->lit - seqStore->litStart);\n\n    return nbSeqs < 4 && nbLits < 10;\n}\n\nstatic void ZSTD_blockState_confirmRepcodesAndEntropyTables(ZSTD_blockState_t* const bs)\n{\n    ZSTD_compressedBlockState_t* const tmp = bs->prevCBlock;\n    bs->prevCBlock = bs->nextCBlock;\n    bs->nextCBlock = tmp;\n}\n\n \nstatic void writeBlockHeader(void* op, size_t cSize, size_t blockSize, U32 lastBlock) {\n    U32 const cBlockHeader = cSize == 1 ?\n                        lastBlock + (((U32)bt_rle)<<1) + (U32)(blockSize << 3) :\n                        lastBlock + (((U32)bt_compressed)<<1) + (U32)(cSize << 3);\n    MEM_writeLE24(op, cBlockHeader);\n    DEBUGLOG(3, \"writeBlockHeader: cSize: %zu blockSize: %zu lastBlock: %u\", cSize, blockSize, lastBlock);\n}\n\n \nstatic size_t ZSTD_buildBlockEntropyStats_literals(void* const src, size_t srcSize,\n                                            const ZSTD_hufCTables_t* prevHuf,\n                                                  ZSTD_hufCTables_t* nextHuf,\n                                                  ZSTD_hufCTablesMetadata_t* hufMetadata,\n                                                  const int literalsCompressionIsDisabled,\n                                                  void* workspace, size_t wkspSize)\n{\n    BYTE* const wkspStart = (BYTE*)workspace;\n    BYTE* const wkspEnd = wkspStart + wkspSize;\n    BYTE* const countWkspStart = wkspStart;\n    unsigned* const countWksp = (unsigned*)workspace;\n    const size_t countWkspSize = (HUF_SYMBOLVALUE_MAX + 1) * sizeof(unsigned);\n    BYTE* const nodeWksp = countWkspStart + countWkspSize;\n    const size_t nodeWkspSize = wkspEnd-nodeWksp;\n    unsigned maxSymbolValue = HUF_SYMBOLVALUE_MAX;\n    unsigned huffLog = HUF_TABLELOG_DEFAULT;\n    HUF_repeat repeat = prevHuf->repeatMode;\n    DEBUGLOG(5, \"ZSTD_buildBlockEntropyStats_literals (srcSize=%zu)\", srcSize);\n\n     \n    ZSTD_memcpy(nextHuf, prevHuf, sizeof(*prevHuf));\n\n    if (literalsCompressionIsDisabled) {\n        DEBUGLOG(5, \"set_basic - disabled\");\n        hufMetadata->hType = set_basic;\n        return 0;\n    }\n\n     \n#ifndef COMPRESS_LITERALS_SIZE_MIN\n#define COMPRESS_LITERALS_SIZE_MIN 63\n#endif\n    {   size_t const minLitSize = (prevHuf->repeatMode == HUF_repeat_valid) ? 6 : COMPRESS_LITERALS_SIZE_MIN;\n        if (srcSize <= minLitSize) {\n            DEBUGLOG(5, \"set_basic - too small\");\n            hufMetadata->hType = set_basic;\n            return 0;\n        }\n    }\n\n     \n    {   size_t const largest = HIST_count_wksp (countWksp, &maxSymbolValue, (const BYTE*)src, srcSize, workspace, wkspSize);\n        FORWARD_IF_ERROR(largest, \"HIST_count_wksp failed\");\n        if (largest == srcSize) {\n            DEBUGLOG(5, \"set_rle\");\n            hufMetadata->hType = set_rle;\n            return 0;\n        }\n        if (largest <= (srcSize >> 7)+4) {\n            DEBUGLOG(5, \"set_basic - no gain\");\n            hufMetadata->hType = set_basic;\n            return 0;\n        }\n    }\n\n     \n    if (repeat == HUF_repeat_check && !HUF_validateCTable((HUF_CElt const*)prevHuf->CTable, countWksp, maxSymbolValue)) {\n        repeat = HUF_repeat_none;\n    }\n\n     \n    ZSTD_memset(nextHuf->CTable, 0, sizeof(nextHuf->CTable));\n    huffLog = HUF_optimalTableLog(huffLog, srcSize, maxSymbolValue);\n    {   size_t const maxBits = HUF_buildCTable_wksp((HUF_CElt*)nextHuf->CTable, countWksp,\n                                                    maxSymbolValue, huffLog,\n                                                    nodeWksp, nodeWkspSize);\n        FORWARD_IF_ERROR(maxBits, \"HUF_buildCTable_wksp\");\n        huffLog = (U32)maxBits;\n        {    \n            size_t const newCSize = HUF_estimateCompressedSize(\n                    (HUF_CElt*)nextHuf->CTable, countWksp, maxSymbolValue);\n            size_t const hSize = HUF_writeCTable_wksp(\n                    hufMetadata->hufDesBuffer, sizeof(hufMetadata->hufDesBuffer),\n                    (HUF_CElt*)nextHuf->CTable, maxSymbolValue, huffLog,\n                    nodeWksp, nodeWkspSize);\n             \n            if (repeat != HUF_repeat_none) {\n                size_t const oldCSize = HUF_estimateCompressedSize(\n                        (HUF_CElt const*)prevHuf->CTable, countWksp, maxSymbolValue);\n                if (oldCSize < srcSize && (oldCSize <= hSize + newCSize || hSize + 12 >= srcSize)) {\n                    DEBUGLOG(5, \"set_repeat - smaller\");\n                    ZSTD_memcpy(nextHuf, prevHuf, sizeof(*prevHuf));\n                    hufMetadata->hType = set_repeat;\n                    return 0;\n                }\n            }\n            if (newCSize + hSize >= srcSize) {\n                DEBUGLOG(5, \"set_basic - no gains\");\n                ZSTD_memcpy(nextHuf, prevHuf, sizeof(*prevHuf));\n                hufMetadata->hType = set_basic;\n                return 0;\n            }\n            DEBUGLOG(5, \"set_compressed (hSize=%u)\", (U32)hSize);\n            hufMetadata->hType = set_compressed;\n            nextHuf->repeatMode = HUF_repeat_check;\n            return hSize;\n        }\n    }\n}\n\n\n \nstatic ZSTD_symbolEncodingTypeStats_t\nZSTD_buildDummySequencesStatistics(ZSTD_fseCTables_t* nextEntropy) {\n    ZSTD_symbolEncodingTypeStats_t stats = {set_basic, set_basic, set_basic, 0, 0};\n    nextEntropy->litlength_repeatMode = FSE_repeat_none;\n    nextEntropy->offcode_repeatMode = FSE_repeat_none;\n    nextEntropy->matchlength_repeatMode = FSE_repeat_none;\n    return stats;\n}\n\n \nstatic size_t ZSTD_buildBlockEntropyStats_sequences(seqStore_t* seqStorePtr,\n                                              const ZSTD_fseCTables_t* prevEntropy,\n                                                    ZSTD_fseCTables_t* nextEntropy,\n                                              const ZSTD_CCtx_params* cctxParams,\n                                                    ZSTD_fseCTablesMetadata_t* fseMetadata,\n                                                    void* workspace, size_t wkspSize)\n{\n    ZSTD_strategy const strategy = cctxParams->cParams.strategy;\n    size_t const nbSeq = seqStorePtr->sequences - seqStorePtr->sequencesStart;\n    BYTE* const ostart = fseMetadata->fseTablesBuffer;\n    BYTE* const oend = ostart + sizeof(fseMetadata->fseTablesBuffer);\n    BYTE* op = ostart;\n    unsigned* countWorkspace = (unsigned*)workspace;\n    unsigned* entropyWorkspace = countWorkspace + (MaxSeq + 1);\n    size_t entropyWorkspaceSize = wkspSize - (MaxSeq + 1) * sizeof(*countWorkspace);\n    ZSTD_symbolEncodingTypeStats_t stats;\n\n    DEBUGLOG(5, \"ZSTD_buildBlockEntropyStats_sequences (nbSeq=%zu)\", nbSeq);\n    stats = nbSeq != 0 ? ZSTD_buildSequencesStatistics(seqStorePtr, nbSeq,\n                                          prevEntropy, nextEntropy, op, oend,\n                                          strategy, countWorkspace,\n                                          entropyWorkspace, entropyWorkspaceSize)\n                       : ZSTD_buildDummySequencesStatistics(nextEntropy);\n    FORWARD_IF_ERROR(stats.size, \"ZSTD_buildSequencesStatistics failed!\");\n    fseMetadata->llType = (symbolEncodingType_e) stats.LLtype;\n    fseMetadata->ofType = (symbolEncodingType_e) stats.Offtype;\n    fseMetadata->mlType = (symbolEncodingType_e) stats.MLtype;\n    fseMetadata->lastCountSize = stats.lastCountSize;\n    return stats.size;\n}\n\n\n \nsize_t ZSTD_buildBlockEntropyStats(seqStore_t* seqStorePtr,\n                             const ZSTD_entropyCTables_t* prevEntropy,\n                                   ZSTD_entropyCTables_t* nextEntropy,\n                             const ZSTD_CCtx_params* cctxParams,\n                                   ZSTD_entropyCTablesMetadata_t* entropyMetadata,\n                                   void* workspace, size_t wkspSize)\n{\n    size_t const litSize = seqStorePtr->lit - seqStorePtr->litStart;\n    entropyMetadata->hufMetadata.hufDesSize =\n        ZSTD_buildBlockEntropyStats_literals(seqStorePtr->litStart, litSize,\n                                            &prevEntropy->huf, &nextEntropy->huf,\n                                            &entropyMetadata->hufMetadata,\n                                            ZSTD_literalsCompressionIsDisabled(cctxParams),\n                                            workspace, wkspSize);\n    FORWARD_IF_ERROR(entropyMetadata->hufMetadata.hufDesSize, \"ZSTD_buildBlockEntropyStats_literals failed\");\n    entropyMetadata->fseMetadata.fseTablesSize =\n        ZSTD_buildBlockEntropyStats_sequences(seqStorePtr,\n                                              &prevEntropy->fse, &nextEntropy->fse,\n                                              cctxParams,\n                                              &entropyMetadata->fseMetadata,\n                                              workspace, wkspSize);\n    FORWARD_IF_ERROR(entropyMetadata->fseMetadata.fseTablesSize, \"ZSTD_buildBlockEntropyStats_sequences failed\");\n    return 0;\n}\n\n \nstatic size_t ZSTD_estimateBlockSize_literal(const BYTE* literals, size_t litSize,\n                                                const ZSTD_hufCTables_t* huf,\n                                                const ZSTD_hufCTablesMetadata_t* hufMetadata,\n                                                void* workspace, size_t wkspSize,\n                                                int writeEntropy)\n{\n    unsigned* const countWksp = (unsigned*)workspace;\n    unsigned maxSymbolValue = HUF_SYMBOLVALUE_MAX;\n    size_t literalSectionHeaderSize = 3 + (litSize >= 1 KB) + (litSize >= 16 KB);\n    U32 singleStream = litSize < 256;\n\n    if (hufMetadata->hType == set_basic) return litSize;\n    else if (hufMetadata->hType == set_rle) return 1;\n    else if (hufMetadata->hType == set_compressed || hufMetadata->hType == set_repeat) {\n        size_t const largest = HIST_count_wksp (countWksp, &maxSymbolValue, (const BYTE*)literals, litSize, workspace, wkspSize);\n        if (ZSTD_isError(largest)) return litSize;\n        {   size_t cLitSizeEstimate = HUF_estimateCompressedSize((const HUF_CElt*)huf->CTable, countWksp, maxSymbolValue);\n            if (writeEntropy) cLitSizeEstimate += hufMetadata->hufDesSize;\n            if (!singleStream) cLitSizeEstimate += 6;  \n            return cLitSizeEstimate + literalSectionHeaderSize;\n    }   }\n    assert(0);  \n    return 0;\n}\n\n \nstatic size_t ZSTD_estimateBlockSize_symbolType(symbolEncodingType_e type,\n                        const BYTE* codeTable, size_t nbSeq, unsigned maxCode,\n                        const FSE_CTable* fseCTable,\n                        const U8* additionalBits,\n                        short const* defaultNorm, U32 defaultNormLog, U32 defaultMax,\n                        void* workspace, size_t wkspSize)\n{\n    unsigned* const countWksp = (unsigned*)workspace;\n    const BYTE* ctp = codeTable;\n    const BYTE* const ctStart = ctp;\n    const BYTE* const ctEnd = ctStart + nbSeq;\n    size_t cSymbolTypeSizeEstimateInBits = 0;\n    unsigned max = maxCode;\n\n    HIST_countFast_wksp(countWksp, &max, codeTable, nbSeq, workspace, wkspSize);   \n    if (type == set_basic) {\n         \n        assert(max <= defaultMax);\n        (void)defaultMax;\n        cSymbolTypeSizeEstimateInBits = ZSTD_crossEntropyCost(defaultNorm, defaultNormLog, countWksp, max);\n    } else if (type == set_rle) {\n        cSymbolTypeSizeEstimateInBits = 0;\n    } else if (type == set_compressed || type == set_repeat) {\n        cSymbolTypeSizeEstimateInBits = ZSTD_fseBitCost(fseCTable, countWksp, max);\n    }\n    if (ZSTD_isError(cSymbolTypeSizeEstimateInBits)) {\n        return nbSeq * 10;\n    }\n    while (ctp < ctEnd) {\n        if (additionalBits) cSymbolTypeSizeEstimateInBits += additionalBits[*ctp];\n        else cSymbolTypeSizeEstimateInBits += *ctp;  \n        ctp++;\n    }\n    return cSymbolTypeSizeEstimateInBits >> 3;\n}\n\n \nstatic size_t ZSTD_estimateBlockSize_sequences(const BYTE* ofCodeTable,\n                                                  const BYTE* llCodeTable,\n                                                  const BYTE* mlCodeTable,\n                                                  size_t nbSeq,\n                                                  const ZSTD_fseCTables_t* fseTables,\n                                                  const ZSTD_fseCTablesMetadata_t* fseMetadata,\n                                                  void* workspace, size_t wkspSize,\n                                                  int writeEntropy)\n{\n    size_t sequencesSectionHeaderSize = 1   + 1   + (nbSeq >= 128) + (nbSeq >= LONGNBSEQ);\n    size_t cSeqSizeEstimate = 0;\n    cSeqSizeEstimate += ZSTD_estimateBlockSize_symbolType(fseMetadata->ofType, ofCodeTable, nbSeq, MaxOff,\n                                         fseTables->offcodeCTable, NULL,\n                                         OF_defaultNorm, OF_defaultNormLog, DefaultMaxOff,\n                                         workspace, wkspSize);\n    cSeqSizeEstimate += ZSTD_estimateBlockSize_symbolType(fseMetadata->llType, llCodeTable, nbSeq, MaxLL,\n                                         fseTables->litlengthCTable, LL_bits,\n                                         LL_defaultNorm, LL_defaultNormLog, MaxLL,\n                                         workspace, wkspSize);\n    cSeqSizeEstimate += ZSTD_estimateBlockSize_symbolType(fseMetadata->mlType, mlCodeTable, nbSeq, MaxML,\n                                         fseTables->matchlengthCTable, ML_bits,\n                                         ML_defaultNorm, ML_defaultNormLog, MaxML,\n                                         workspace, wkspSize);\n    if (writeEntropy) cSeqSizeEstimate += fseMetadata->fseTablesSize;\n    return cSeqSizeEstimate + sequencesSectionHeaderSize;\n}\n\n \nstatic size_t ZSTD_estimateBlockSize(const BYTE* literals, size_t litSize,\n                                     const BYTE* ofCodeTable,\n                                     const BYTE* llCodeTable,\n                                     const BYTE* mlCodeTable,\n                                     size_t nbSeq,\n                                     const ZSTD_entropyCTables_t* entropy,\n                                     const ZSTD_entropyCTablesMetadata_t* entropyMetadata,\n                                     void* workspace, size_t wkspSize,\n                                     int writeLitEntropy, int writeSeqEntropy) {\n    size_t const literalsSize = ZSTD_estimateBlockSize_literal(literals, litSize,\n                                                         &entropy->huf, &entropyMetadata->hufMetadata,\n                                                         workspace, wkspSize, writeLitEntropy);\n    size_t const seqSize = ZSTD_estimateBlockSize_sequences(ofCodeTable, llCodeTable, mlCodeTable,\n                                                         nbSeq, &entropy->fse, &entropyMetadata->fseMetadata,\n                                                         workspace, wkspSize, writeSeqEntropy);\n    return seqSize + literalsSize + ZSTD_blockHeaderSize;\n}\n\n \nstatic size_t ZSTD_buildEntropyStatisticsAndEstimateSubBlockSize(seqStore_t* seqStore, ZSTD_CCtx* zc) {\n    ZSTD_entropyCTablesMetadata_t* entropyMetadata = &zc->blockSplitCtx.entropyMetadata;\n    DEBUGLOG(6, \"ZSTD_buildEntropyStatisticsAndEstimateSubBlockSize()\");\n    FORWARD_IF_ERROR(ZSTD_buildBlockEntropyStats(seqStore,\n                    &zc->blockState.prevCBlock->entropy,\n                    &zc->blockState.nextCBlock->entropy,\n                    &zc->appliedParams,\n                    entropyMetadata,\n                    zc->entropyWorkspace, ENTROPY_WORKSPACE_SIZE  ), \"\");\n    return ZSTD_estimateBlockSize(seqStore->litStart, (size_t)(seqStore->lit - seqStore->litStart),\n                    seqStore->ofCode, seqStore->llCode, seqStore->mlCode,\n                    (size_t)(seqStore->sequences - seqStore->sequencesStart),\n                    &zc->blockState.nextCBlock->entropy, entropyMetadata, zc->entropyWorkspace, ENTROPY_WORKSPACE_SIZE,\n                    (int)(entropyMetadata->hufMetadata.hType == set_compressed), 1);\n}\n\n \nstatic size_t ZSTD_countSeqStoreLiteralsBytes(const seqStore_t* const seqStore) {\n    size_t literalsBytes = 0;\n    size_t const nbSeqs = seqStore->sequences - seqStore->sequencesStart;\n    size_t i;\n    for (i = 0; i < nbSeqs; ++i) {\n        seqDef seq = seqStore->sequencesStart[i];\n        literalsBytes += seq.litLength;\n        if (i == seqStore->longLengthPos && seqStore->longLengthType == ZSTD_llt_literalLength) {\n            literalsBytes += 0x10000;\n        }\n    }\n    return literalsBytes;\n}\n\n \nstatic size_t ZSTD_countSeqStoreMatchBytes(const seqStore_t* const seqStore) {\n    size_t matchBytes = 0;\n    size_t const nbSeqs = seqStore->sequences - seqStore->sequencesStart;\n    size_t i;\n    for (i = 0; i < nbSeqs; ++i) {\n        seqDef seq = seqStore->sequencesStart[i];\n        matchBytes += seq.mlBase + MINMATCH;\n        if (i == seqStore->longLengthPos && seqStore->longLengthType == ZSTD_llt_matchLength) {\n            matchBytes += 0x10000;\n        }\n    }\n    return matchBytes;\n}\n\n \nstatic void ZSTD_deriveSeqStoreChunk(seqStore_t* resultSeqStore,\n                               const seqStore_t* originalSeqStore,\n                                     size_t startIdx, size_t endIdx) {\n    BYTE* const litEnd = originalSeqStore->lit;\n    size_t literalsBytes;\n    size_t literalsBytesPreceding = 0;\n\n    *resultSeqStore = *originalSeqStore;\n    if (startIdx > 0) {\n        resultSeqStore->sequences = originalSeqStore->sequencesStart + startIdx;\n        literalsBytesPreceding = ZSTD_countSeqStoreLiteralsBytes(resultSeqStore);\n    }\n\n     \n    if (originalSeqStore->longLengthType != ZSTD_llt_none) {\n        if (originalSeqStore->longLengthPos < startIdx || originalSeqStore->longLengthPos > endIdx) {\n            resultSeqStore->longLengthType = ZSTD_llt_none;\n        } else {\n            resultSeqStore->longLengthPos -= (U32)startIdx;\n        }\n    }\n    resultSeqStore->sequencesStart = originalSeqStore->sequencesStart + startIdx;\n    resultSeqStore->sequences = originalSeqStore->sequencesStart + endIdx;\n    literalsBytes = ZSTD_countSeqStoreLiteralsBytes(resultSeqStore);\n    resultSeqStore->litStart += literalsBytesPreceding;\n    if (endIdx == (size_t)(originalSeqStore->sequences - originalSeqStore->sequencesStart)) {\n         \n        resultSeqStore->lit = litEnd;\n    } else {\n        resultSeqStore->lit = resultSeqStore->litStart+literalsBytes;\n    }\n    resultSeqStore->llCode += startIdx;\n    resultSeqStore->mlCode += startIdx;\n    resultSeqStore->ofCode += startIdx;\n}\n\n \nstatic U32\nZSTD_resolveRepcodeToRawOffset(const U32 rep[ZSTD_REP_NUM], const U32 offCode, const U32 ll0)\n{\n    U32 const adjustedOffCode = STORED_REPCODE(offCode) - 1 + ll0;   \n    assert(STORED_IS_REPCODE(offCode));\n    if (adjustedOffCode == ZSTD_REP_NUM) {\n         \n        assert(rep[0] > 0);\n        return rep[0] - 1;\n    }\n    return rep[adjustedOffCode];\n}\n\n \nstatic void ZSTD_seqStore_resolveOffCodes(repcodes_t* const dRepcodes, repcodes_t* const cRepcodes,\n                                          seqStore_t* const seqStore, U32 const nbSeq) {\n    U32 idx = 0;\n    for (; idx < nbSeq; ++idx) {\n        seqDef* const seq = seqStore->sequencesStart + idx;\n        U32 const ll0 = (seq->litLength == 0);\n        U32 const offCode = OFFBASE_TO_STORED(seq->offBase);\n        assert(seq->offBase > 0);\n        if (STORED_IS_REPCODE(offCode)) {\n            U32 const dRawOffset = ZSTD_resolveRepcodeToRawOffset(dRepcodes->rep, offCode, ll0);\n            U32 const cRawOffset = ZSTD_resolveRepcodeToRawOffset(cRepcodes->rep, offCode, ll0);\n             \n            if (dRawOffset != cRawOffset) {\n                seq->offBase = cRawOffset + ZSTD_REP_NUM;\n            }\n        }\n         \n        ZSTD_updateRep(dRepcodes->rep, OFFBASE_TO_STORED(seq->offBase), ll0);\n        ZSTD_updateRep(cRepcodes->rep, offCode, ll0);\n    }\n}\n\n \nstatic size_t\nZSTD_compressSeqStore_singleBlock(ZSTD_CCtx* zc, seqStore_t* const seqStore,\n                                  repcodes_t* const dRep, repcodes_t* const cRep,\n                                  void* dst, size_t dstCapacity,\n                                  const void* src, size_t srcSize,\n                                  U32 lastBlock, U32 isPartition)\n{\n    const U32 rleMaxLength = 25;\n    BYTE* op = (BYTE*)dst;\n    const BYTE* ip = (const BYTE*)src;\n    size_t cSize;\n    size_t cSeqsSize;\n\n     \n    repcodes_t const dRepOriginal = *dRep;\n    DEBUGLOG(5, \"ZSTD_compressSeqStore_singleBlock\");\n    if (isPartition)\n        ZSTD_seqStore_resolveOffCodes(dRep, cRep, seqStore, (U32)(seqStore->sequences - seqStore->sequencesStart));\n\n    RETURN_ERROR_IF(dstCapacity < ZSTD_blockHeaderSize, dstSize_tooSmall, \"Block header doesn't fit\");\n    cSeqsSize = ZSTD_entropyCompressSeqStore(seqStore,\n                &zc->blockState.prevCBlock->entropy, &zc->blockState.nextCBlock->entropy,\n                &zc->appliedParams,\n                op + ZSTD_blockHeaderSize, dstCapacity - ZSTD_blockHeaderSize,\n                srcSize,\n                zc->entropyWorkspace, ENTROPY_WORKSPACE_SIZE  ,\n                zc->bmi2);\n    FORWARD_IF_ERROR(cSeqsSize, \"ZSTD_entropyCompressSeqStore failed!\");\n\n    if (!zc->isFirstBlock &&\n        cSeqsSize < rleMaxLength &&\n        ZSTD_isRLE((BYTE const*)src, srcSize)) {\n         \n        cSeqsSize = 1;\n    }\n\n    if (zc->seqCollector.collectSequences) {\n        ZSTD_copyBlockSequences(zc);\n        ZSTD_blockState_confirmRepcodesAndEntropyTables(&zc->blockState);\n        return 0;\n    }\n\n    if (cSeqsSize == 0) {\n        cSize = ZSTD_noCompressBlock(op, dstCapacity, ip, srcSize, lastBlock);\n        FORWARD_IF_ERROR(cSize, \"Nocompress block failed\");\n        DEBUGLOG(4, \"Writing out nocompress block, size: %zu\", cSize);\n        *dRep = dRepOriginal;  \n    } else if (cSeqsSize == 1) {\n        cSize = ZSTD_rleCompressBlock(op, dstCapacity, *ip, srcSize, lastBlock);\n        FORWARD_IF_ERROR(cSize, \"RLE compress block failed\");\n        DEBUGLOG(4, \"Writing out RLE block, size: %zu\", cSize);\n        *dRep = dRepOriginal;  \n    } else {\n        ZSTD_blockState_confirmRepcodesAndEntropyTables(&zc->blockState);\n        writeBlockHeader(op, cSeqsSize, srcSize, lastBlock);\n        cSize = ZSTD_blockHeaderSize + cSeqsSize;\n        DEBUGLOG(4, \"Writing out compressed block, size: %zu\", cSize);\n    }\n\n    if (zc->blockState.prevCBlock->entropy.fse.offcode_repeatMode == FSE_repeat_valid)\n        zc->blockState.prevCBlock->entropy.fse.offcode_repeatMode = FSE_repeat_check;\n\n    return cSize;\n}\n\n \ntypedef struct {\n    U32* splitLocations;     \n    size_t idx;              \n} seqStoreSplits;\n\n#define MIN_SEQUENCES_BLOCK_SPLITTING 300\n\n \nstatic void\nZSTD_deriveBlockSplitsHelper(seqStoreSplits* splits, size_t startIdx, size_t endIdx,\n                             ZSTD_CCtx* zc, const seqStore_t* origSeqStore)\n{\n    seqStore_t* fullSeqStoreChunk = &zc->blockSplitCtx.fullSeqStoreChunk;\n    seqStore_t* firstHalfSeqStore = &zc->blockSplitCtx.firstHalfSeqStore;\n    seqStore_t* secondHalfSeqStore = &zc->blockSplitCtx.secondHalfSeqStore;\n    size_t estimatedOriginalSize;\n    size_t estimatedFirstHalfSize;\n    size_t estimatedSecondHalfSize;\n    size_t midIdx = (startIdx + endIdx)/2;\n\n    if (endIdx - startIdx < MIN_SEQUENCES_BLOCK_SPLITTING || splits->idx >= ZSTD_MAX_NB_BLOCK_SPLITS) {\n        DEBUGLOG(6, \"ZSTD_deriveBlockSplitsHelper: Too few sequences\");\n        return;\n    }\n    DEBUGLOG(4, \"ZSTD_deriveBlockSplitsHelper: startIdx=%zu endIdx=%zu\", startIdx, endIdx);\n    ZSTD_deriveSeqStoreChunk(fullSeqStoreChunk, origSeqStore, startIdx, endIdx);\n    ZSTD_deriveSeqStoreChunk(firstHalfSeqStore, origSeqStore, startIdx, midIdx);\n    ZSTD_deriveSeqStoreChunk(secondHalfSeqStore, origSeqStore, midIdx, endIdx);\n    estimatedOriginalSize = ZSTD_buildEntropyStatisticsAndEstimateSubBlockSize(fullSeqStoreChunk, zc);\n    estimatedFirstHalfSize = ZSTD_buildEntropyStatisticsAndEstimateSubBlockSize(firstHalfSeqStore, zc);\n    estimatedSecondHalfSize = ZSTD_buildEntropyStatisticsAndEstimateSubBlockSize(secondHalfSeqStore, zc);\n    DEBUGLOG(4, \"Estimated original block size: %zu -- First half split: %zu -- Second half split: %zu\",\n             estimatedOriginalSize, estimatedFirstHalfSize, estimatedSecondHalfSize);\n    if (ZSTD_isError(estimatedOriginalSize) || ZSTD_isError(estimatedFirstHalfSize) || ZSTD_isError(estimatedSecondHalfSize)) {\n        return;\n    }\n    if (estimatedFirstHalfSize + estimatedSecondHalfSize < estimatedOriginalSize) {\n        ZSTD_deriveBlockSplitsHelper(splits, startIdx, midIdx, zc, origSeqStore);\n        splits->splitLocations[splits->idx] = (U32)midIdx;\n        splits->idx++;\n        ZSTD_deriveBlockSplitsHelper(splits, midIdx, endIdx, zc, origSeqStore);\n    }\n}\n\n \nstatic size_t ZSTD_deriveBlockSplits(ZSTD_CCtx* zc, U32 partitions[], U32 nbSeq) {\n    seqStoreSplits splits = {partitions, 0};\n    if (nbSeq <= 4) {\n        DEBUGLOG(4, \"ZSTD_deriveBlockSplits: Too few sequences to split\");\n         \n        return 0;\n    }\n    ZSTD_deriveBlockSplitsHelper(&splits, 0, nbSeq, zc, &zc->seqStore);\n    splits.splitLocations[splits.idx] = nbSeq;\n    DEBUGLOG(5, \"ZSTD_deriveBlockSplits: final nb partitions: %zu\", splits.idx+1);\n    return splits.idx;\n}\n\n \nstatic size_t\nZSTD_compressBlock_splitBlock_internal(ZSTD_CCtx* zc, void* dst, size_t dstCapacity,\n                                       const void* src, size_t blockSize, U32 lastBlock, U32 nbSeq)\n{\n    size_t cSize = 0;\n    const BYTE* ip = (const BYTE*)src;\n    BYTE* op = (BYTE*)dst;\n    size_t i = 0;\n    size_t srcBytesTotal = 0;\n    U32* partitions = zc->blockSplitCtx.partitions;  \n    seqStore_t* nextSeqStore = &zc->blockSplitCtx.nextSeqStore;\n    seqStore_t* currSeqStore = &zc->blockSplitCtx.currSeqStore;\n    size_t numSplits = ZSTD_deriveBlockSplits(zc, partitions, nbSeq);\n\n     \n    repcodes_t dRep;\n    repcodes_t cRep;\n    ZSTD_memcpy(dRep.rep, zc->blockState.prevCBlock->rep, sizeof(repcodes_t));\n    ZSTD_memcpy(cRep.rep, zc->blockState.prevCBlock->rep, sizeof(repcodes_t));\n    ZSTD_memset(nextSeqStore, 0, sizeof(seqStore_t));\n\n    DEBUGLOG(4, \"ZSTD_compressBlock_splitBlock_internal (dstCapacity=%u, dictLimit=%u, nextToUpdate=%u)\",\n                (unsigned)dstCapacity, (unsigned)zc->blockState.matchState.window.dictLimit,\n                (unsigned)zc->blockState.matchState.nextToUpdate);\n\n    if (numSplits == 0) {\n        size_t cSizeSingleBlock = ZSTD_compressSeqStore_singleBlock(zc, &zc->seqStore,\n                                                                   &dRep, &cRep,\n                                                                    op, dstCapacity,\n                                                                    ip, blockSize,\n                                                                    lastBlock, 0  );\n        FORWARD_IF_ERROR(cSizeSingleBlock, \"Compressing single block from splitBlock_internal() failed!\");\n        DEBUGLOG(5, \"ZSTD_compressBlock_splitBlock_internal: No splits\");\n        assert(cSizeSingleBlock <= ZSTD_BLOCKSIZE_MAX + ZSTD_blockHeaderSize);\n        return cSizeSingleBlock;\n    }\n\n    ZSTD_deriveSeqStoreChunk(currSeqStore, &zc->seqStore, 0, partitions[0]);\n    for (i = 0; i <= numSplits; ++i) {\n        size_t srcBytes;\n        size_t cSizeChunk;\n        U32 const lastPartition = (i == numSplits);\n        U32 lastBlockEntireSrc = 0;\n\n        srcBytes = ZSTD_countSeqStoreLiteralsBytes(currSeqStore) + ZSTD_countSeqStoreMatchBytes(currSeqStore);\n        srcBytesTotal += srcBytes;\n        if (lastPartition) {\n             \n            srcBytes += blockSize - srcBytesTotal;\n            lastBlockEntireSrc = lastBlock;\n        } else {\n            ZSTD_deriveSeqStoreChunk(nextSeqStore, &zc->seqStore, partitions[i], partitions[i+1]);\n        }\n\n        cSizeChunk = ZSTD_compressSeqStore_singleBlock(zc, currSeqStore,\n                                                      &dRep, &cRep,\n                                                       op, dstCapacity,\n                                                       ip, srcBytes,\n                                                       lastBlockEntireSrc, 1  );\n        DEBUGLOG(5, \"Estimated size: %zu actual size: %zu\", ZSTD_buildEntropyStatisticsAndEstimateSubBlockSize(currSeqStore, zc), cSizeChunk);\n        FORWARD_IF_ERROR(cSizeChunk, \"Compressing chunk failed!\");\n\n        ip += srcBytes;\n        op += cSizeChunk;\n        dstCapacity -= cSizeChunk;\n        cSize += cSizeChunk;\n        *currSeqStore = *nextSeqStore;\n        assert(cSizeChunk <= ZSTD_BLOCKSIZE_MAX + ZSTD_blockHeaderSize);\n    }\n     \n    ZSTD_memcpy(zc->blockState.prevCBlock->rep, dRep.rep, sizeof(repcodes_t));\n    return cSize;\n}\n\nstatic size_t\nZSTD_compressBlock_splitBlock(ZSTD_CCtx* zc,\n                              void* dst, size_t dstCapacity,\n                              const void* src, size_t srcSize, U32 lastBlock)\n{\n    const BYTE* ip = (const BYTE*)src;\n    BYTE* op = (BYTE*)dst;\n    U32 nbSeq;\n    size_t cSize;\n    DEBUGLOG(4, \"ZSTD_compressBlock_splitBlock\");\n    assert(zc->appliedParams.useBlockSplitter == ZSTD_ps_enable);\n\n    {   const size_t bss = ZSTD_buildSeqStore(zc, src, srcSize);\n        FORWARD_IF_ERROR(bss, \"ZSTD_buildSeqStore failed\");\n        if (bss == ZSTDbss_noCompress) {\n            if (zc->blockState.prevCBlock->entropy.fse.offcode_repeatMode == FSE_repeat_valid)\n                zc->blockState.prevCBlock->entropy.fse.offcode_repeatMode = FSE_repeat_check;\n            cSize = ZSTD_noCompressBlock(op, dstCapacity, ip, srcSize, lastBlock);\n            FORWARD_IF_ERROR(cSize, \"ZSTD_noCompressBlock failed\");\n            DEBUGLOG(4, \"ZSTD_compressBlock_splitBlock: Nocompress block\");\n            return cSize;\n        }\n        nbSeq = (U32)(zc->seqStore.sequences - zc->seqStore.sequencesStart);\n    }\n\n    cSize = ZSTD_compressBlock_splitBlock_internal(zc, dst, dstCapacity, src, srcSize, lastBlock, nbSeq);\n    FORWARD_IF_ERROR(cSize, \"Splitting blocks failed!\");\n    return cSize;\n}\n\nstatic size_t\nZSTD_compressBlock_internal(ZSTD_CCtx* zc,\n                            void* dst, size_t dstCapacity,\n                            const void* src, size_t srcSize, U32 frame)\n{\n     \n    const U32 rleMaxLength = 25;\n    size_t cSize;\n    const BYTE* ip = (const BYTE*)src;\n    BYTE* op = (BYTE*)dst;\n    DEBUGLOG(5, \"ZSTD_compressBlock_internal (dstCapacity=%u, dictLimit=%u, nextToUpdate=%u)\",\n                (unsigned)dstCapacity, (unsigned)zc->blockState.matchState.window.dictLimit,\n                (unsigned)zc->blockState.matchState.nextToUpdate);\n\n    {   const size_t bss = ZSTD_buildSeqStore(zc, src, srcSize);\n        FORWARD_IF_ERROR(bss, \"ZSTD_buildSeqStore failed\");\n        if (bss == ZSTDbss_noCompress) { cSize = 0; goto out; }\n    }\n\n    if (zc->seqCollector.collectSequences) {\n        ZSTD_copyBlockSequences(zc);\n        ZSTD_blockState_confirmRepcodesAndEntropyTables(&zc->blockState);\n        return 0;\n    }\n\n     \n    cSize = ZSTD_entropyCompressSeqStore(&zc->seqStore,\n            &zc->blockState.prevCBlock->entropy, &zc->blockState.nextCBlock->entropy,\n            &zc->appliedParams,\n            dst, dstCapacity,\n            srcSize,\n            zc->entropyWorkspace, ENTROPY_WORKSPACE_SIZE  ,\n            zc->bmi2);\n\n    if (frame &&\n         \n        !zc->isFirstBlock &&\n        cSize < rleMaxLength &&\n        ZSTD_isRLE(ip, srcSize))\n    {\n        cSize = 1;\n        op[0] = ip[0];\n    }\n\nout:\n    if (!ZSTD_isError(cSize) && cSize > 1) {\n        ZSTD_blockState_confirmRepcodesAndEntropyTables(&zc->blockState);\n    }\n     \n    if (zc->blockState.prevCBlock->entropy.fse.offcode_repeatMode == FSE_repeat_valid)\n        zc->blockState.prevCBlock->entropy.fse.offcode_repeatMode = FSE_repeat_check;\n\n    return cSize;\n}\n\nstatic size_t ZSTD_compressBlock_targetCBlockSize_body(ZSTD_CCtx* zc,\n                               void* dst, size_t dstCapacity,\n                               const void* src, size_t srcSize,\n                               const size_t bss, U32 lastBlock)\n{\n    DEBUGLOG(6, \"Attempting ZSTD_compressSuperBlock()\");\n    if (bss == ZSTDbss_compress) {\n        if ( \n            !zc->isFirstBlock &&\n            ZSTD_maybeRLE(&zc->seqStore) &&\n            ZSTD_isRLE((BYTE const*)src, srcSize))\n        {\n            return ZSTD_rleCompressBlock(dst, dstCapacity, *(BYTE const*)src, srcSize, lastBlock);\n        }\n         \n        {\n            size_t const cSize = ZSTD_compressSuperBlock(zc, dst, dstCapacity, src, srcSize, lastBlock);\n            if (cSize != ERROR(dstSize_tooSmall)) {\n                size_t const maxCSize = srcSize - ZSTD_minGain(srcSize, zc->appliedParams.cParams.strategy);\n                FORWARD_IF_ERROR(cSize, \"ZSTD_compressSuperBlock failed\");\n                if (cSize != 0 && cSize < maxCSize + ZSTD_blockHeaderSize) {\n                    ZSTD_blockState_confirmRepcodesAndEntropyTables(&zc->blockState);\n                    return cSize;\n                }\n            }\n        }\n    }\n\n    DEBUGLOG(6, \"Resorting to ZSTD_noCompressBlock()\");\n     \n    return ZSTD_noCompressBlock(dst, dstCapacity, src, srcSize, lastBlock);\n}\n\nstatic size_t ZSTD_compressBlock_targetCBlockSize(ZSTD_CCtx* zc,\n                               void* dst, size_t dstCapacity,\n                               const void* src, size_t srcSize,\n                               U32 lastBlock)\n{\n    size_t cSize = 0;\n    const size_t bss = ZSTD_buildSeqStore(zc, src, srcSize);\n    DEBUGLOG(5, \"ZSTD_compressBlock_targetCBlockSize (dstCapacity=%u, dictLimit=%u, nextToUpdate=%u, srcSize=%zu)\",\n                (unsigned)dstCapacity, (unsigned)zc->blockState.matchState.window.dictLimit, (unsigned)zc->blockState.matchState.nextToUpdate, srcSize);\n    FORWARD_IF_ERROR(bss, \"ZSTD_buildSeqStore failed\");\n\n    cSize = ZSTD_compressBlock_targetCBlockSize_body(zc, dst, dstCapacity, src, srcSize, bss, lastBlock);\n    FORWARD_IF_ERROR(cSize, \"ZSTD_compressBlock_targetCBlockSize_body failed\");\n\n    if (zc->blockState.prevCBlock->entropy.fse.offcode_repeatMode == FSE_repeat_valid)\n        zc->blockState.prevCBlock->entropy.fse.offcode_repeatMode = FSE_repeat_check;\n\n    return cSize;\n}\n\nstatic void ZSTD_overflowCorrectIfNeeded(ZSTD_matchState_t* ms,\n                                         ZSTD_cwksp* ws,\n                                         ZSTD_CCtx_params const* params,\n                                         void const* ip,\n                                         void const* iend)\n{\n    U32 const cycleLog = ZSTD_cycleLog(params->cParams.chainLog, params->cParams.strategy);\n    U32 const maxDist = (U32)1 << params->cParams.windowLog;\n    if (ZSTD_window_needOverflowCorrection(ms->window, cycleLog, maxDist, ms->loadedDictEnd, ip, iend)) {\n        U32 const correction = ZSTD_window_correctOverflow(&ms->window, cycleLog, maxDist, ip);\n        ZSTD_STATIC_ASSERT(ZSTD_CHAINLOG_MAX <= 30);\n        ZSTD_STATIC_ASSERT(ZSTD_WINDOWLOG_MAX_32 <= 30);\n        ZSTD_STATIC_ASSERT(ZSTD_WINDOWLOG_MAX <= 31);\n        ZSTD_cwksp_mark_tables_dirty(ws);\n        ZSTD_reduceIndex(ms, params, correction);\n        ZSTD_cwksp_mark_tables_clean(ws);\n        if (ms->nextToUpdate < correction) ms->nextToUpdate = 0;\n        else ms->nextToUpdate -= correction;\n         \n        ms->loadedDictEnd = 0;\n        ms->dictMatchState = NULL;\n    }\n}\n\n \nstatic size_t ZSTD_compress_frameChunk(ZSTD_CCtx* cctx,\n                                     void* dst, size_t dstCapacity,\n                               const void* src, size_t srcSize,\n                                     U32 lastFrameChunk)\n{\n    size_t blockSize = cctx->blockSize;\n    size_t remaining = srcSize;\n    const BYTE* ip = (const BYTE*)src;\n    BYTE* const ostart = (BYTE*)dst;\n    BYTE* op = ostart;\n    U32 const maxDist = (U32)1 << cctx->appliedParams.cParams.windowLog;\n\n    assert(cctx->appliedParams.cParams.windowLog <= ZSTD_WINDOWLOG_MAX);\n\n    DEBUGLOG(4, \"ZSTD_compress_frameChunk (blockSize=%u)\", (unsigned)blockSize);\n    if (cctx->appliedParams.fParams.checksumFlag && srcSize)\n        xxh64_update(&cctx->xxhState, src, srcSize);\n\n    while (remaining) {\n        ZSTD_matchState_t* const ms = &cctx->blockState.matchState;\n        U32 const lastBlock = lastFrameChunk & (blockSize >= remaining);\n\n        RETURN_ERROR_IF(dstCapacity < ZSTD_blockHeaderSize + MIN_CBLOCK_SIZE,\n                        dstSize_tooSmall,\n                        \"not enough space to store compressed block\");\n        if (remaining < blockSize) blockSize = remaining;\n\n        ZSTD_overflowCorrectIfNeeded(\n            ms, &cctx->workspace, &cctx->appliedParams, ip, ip + blockSize);\n        ZSTD_checkDictValidity(&ms->window, ip + blockSize, maxDist, &ms->loadedDictEnd, &ms->dictMatchState);\n        ZSTD_window_enforceMaxDist(&ms->window, ip, maxDist, &ms->loadedDictEnd, &ms->dictMatchState);\n\n         \n        if (ms->nextToUpdate < ms->window.lowLimit) ms->nextToUpdate = ms->window.lowLimit;\n\n        {   size_t cSize;\n            if (ZSTD_useTargetCBlockSize(&cctx->appliedParams)) {\n                cSize = ZSTD_compressBlock_targetCBlockSize(cctx, op, dstCapacity, ip, blockSize, lastBlock);\n                FORWARD_IF_ERROR(cSize, \"ZSTD_compressBlock_targetCBlockSize failed\");\n                assert(cSize > 0);\n                assert(cSize <= blockSize + ZSTD_blockHeaderSize);\n            } else if (ZSTD_blockSplitterEnabled(&cctx->appliedParams)) {\n                cSize = ZSTD_compressBlock_splitBlock(cctx, op, dstCapacity, ip, blockSize, lastBlock);\n                FORWARD_IF_ERROR(cSize, \"ZSTD_compressBlock_splitBlock failed\");\n                assert(cSize > 0 || cctx->seqCollector.collectSequences == 1);\n            } else {\n                cSize = ZSTD_compressBlock_internal(cctx,\n                                        op+ZSTD_blockHeaderSize, dstCapacity-ZSTD_blockHeaderSize,\n                                        ip, blockSize, 1  );\n                FORWARD_IF_ERROR(cSize, \"ZSTD_compressBlock_internal failed\");\n\n                if (cSize == 0) {   \n                    cSize = ZSTD_noCompressBlock(op, dstCapacity, ip, blockSize, lastBlock);\n                    FORWARD_IF_ERROR(cSize, \"ZSTD_noCompressBlock failed\");\n                } else {\n                    U32 const cBlockHeader = cSize == 1 ?\n                        lastBlock + (((U32)bt_rle)<<1) + (U32)(blockSize << 3) :\n                        lastBlock + (((U32)bt_compressed)<<1) + (U32)(cSize << 3);\n                    MEM_writeLE24(op, cBlockHeader);\n                    cSize += ZSTD_blockHeaderSize;\n                }\n            }\n\n\n            ip += blockSize;\n            assert(remaining >= blockSize);\n            remaining -= blockSize;\n            op += cSize;\n            assert(dstCapacity >= cSize);\n            dstCapacity -= cSize;\n            cctx->isFirstBlock = 0;\n            DEBUGLOG(5, \"ZSTD_compress_frameChunk: adding a block of size %u\",\n                        (unsigned)cSize);\n    }   }\n\n    if (lastFrameChunk && (op>ostart)) cctx->stage = ZSTDcs_ending;\n    return (size_t)(op-ostart);\n}\n\n\nstatic size_t ZSTD_writeFrameHeader(void* dst, size_t dstCapacity,\n                                    const ZSTD_CCtx_params* params, U64 pledgedSrcSize, U32 dictID)\n{   BYTE* const op = (BYTE*)dst;\n    U32   const dictIDSizeCodeLength = (dictID>0) + (dictID>=256) + (dictID>=65536);    \n    U32   const dictIDSizeCode = params->fParams.noDictIDFlag ? 0 : dictIDSizeCodeLength;    \n    U32   const checksumFlag = params->fParams.checksumFlag>0;\n    U32   const windowSize = (U32)1 << params->cParams.windowLog;\n    U32   const singleSegment = params->fParams.contentSizeFlag && (windowSize >= pledgedSrcSize);\n    BYTE  const windowLogByte = (BYTE)((params->cParams.windowLog - ZSTD_WINDOWLOG_ABSOLUTEMIN) << 3);\n    U32   const fcsCode = params->fParams.contentSizeFlag ?\n                     (pledgedSrcSize>=256) + (pledgedSrcSize>=65536+256) + (pledgedSrcSize>=0xFFFFFFFFU) : 0;   \n    BYTE  const frameHeaderDescriptionByte = (BYTE)(dictIDSizeCode + (checksumFlag<<2) + (singleSegment<<5) + (fcsCode<<6) );\n    size_t pos=0;\n\n    assert(!(params->fParams.contentSizeFlag && pledgedSrcSize == ZSTD_CONTENTSIZE_UNKNOWN));\n    RETURN_ERROR_IF(dstCapacity < ZSTD_FRAMEHEADERSIZE_MAX, dstSize_tooSmall,\n                    \"dst buf is too small to fit worst-case frame header size.\");\n    DEBUGLOG(4, \"ZSTD_writeFrameHeader : dictIDFlag : %u ; dictID : %u ; dictIDSizeCode : %u\",\n                !params->fParams.noDictIDFlag, (unsigned)dictID, (unsigned)dictIDSizeCode);\n    if (params->format == ZSTD_f_zstd1) {\n        MEM_writeLE32(dst, ZSTD_MAGICNUMBER);\n        pos = 4;\n    }\n    op[pos++] = frameHeaderDescriptionByte;\n    if (!singleSegment) op[pos++] = windowLogByte;\n    switch(dictIDSizeCode)\n    {\n        default:\n            assert(0);  \n            ZSTD_FALLTHROUGH;\n        case 0 : break;\n        case 1 : op[pos] = (BYTE)(dictID); pos++; break;\n        case 2 : MEM_writeLE16(op+pos, (U16)dictID); pos+=2; break;\n        case 3 : MEM_writeLE32(op+pos, dictID); pos+=4; break;\n    }\n    switch(fcsCode)\n    {\n        default:\n            assert(0);  \n            ZSTD_FALLTHROUGH;\n        case 0 : if (singleSegment) op[pos++] = (BYTE)(pledgedSrcSize); break;\n        case 1 : MEM_writeLE16(op+pos, (U16)(pledgedSrcSize-256)); pos+=2; break;\n        case 2 : MEM_writeLE32(op+pos, (U32)(pledgedSrcSize)); pos+=4; break;\n        case 3 : MEM_writeLE64(op+pos, (U64)(pledgedSrcSize)); pos+=8; break;\n    }\n    return pos;\n}\n\n \nsize_t ZSTD_writeSkippableFrame(void* dst, size_t dstCapacity,\n                                const void* src, size_t srcSize, unsigned magicVariant) {\n    BYTE* op = (BYTE*)dst;\n    RETURN_ERROR_IF(dstCapacity < srcSize + ZSTD_SKIPPABLEHEADERSIZE  ,\n                    dstSize_tooSmall, \"Not enough room for skippable frame\");\n    RETURN_ERROR_IF(srcSize > (unsigned)0xFFFFFFFF, srcSize_wrong, \"Src size too large for skippable frame\");\n    RETURN_ERROR_IF(magicVariant > 15, parameter_outOfBound, \"Skippable frame magic number variant not supported\");\n\n    MEM_writeLE32(op, (U32)(ZSTD_MAGIC_SKIPPABLE_START + magicVariant));\n    MEM_writeLE32(op+4, (U32)srcSize);\n    ZSTD_memcpy(op+8, src, srcSize);\n    return srcSize + ZSTD_SKIPPABLEHEADERSIZE;\n}\n\n \nsize_t ZSTD_writeLastEmptyBlock(void* dst, size_t dstCapacity)\n{\n    RETURN_ERROR_IF(dstCapacity < ZSTD_blockHeaderSize, dstSize_tooSmall,\n                    \"dst buf is too small to write frame trailer empty block.\");\n    {   U32 const cBlockHeader24 = 1   + (((U32)bt_raw)<<1);   \n        MEM_writeLE24(dst, cBlockHeader24);\n        return ZSTD_blockHeaderSize;\n    }\n}\n\nsize_t ZSTD_referenceExternalSequences(ZSTD_CCtx* cctx, rawSeq* seq, size_t nbSeq)\n{\n    RETURN_ERROR_IF(cctx->stage != ZSTDcs_init, stage_wrong,\n                    \"wrong cctx stage\");\n    RETURN_ERROR_IF(cctx->appliedParams.ldmParams.enableLdm == ZSTD_ps_enable,\n                    parameter_unsupported,\n                    \"incompatible with ldm\");\n    cctx->externSeqStore.seq = seq;\n    cctx->externSeqStore.size = nbSeq;\n    cctx->externSeqStore.capacity = nbSeq;\n    cctx->externSeqStore.pos = 0;\n    cctx->externSeqStore.posInSequence = 0;\n    return 0;\n}\n\n\nstatic size_t ZSTD_compressContinue_internal (ZSTD_CCtx* cctx,\n                              void* dst, size_t dstCapacity,\n                        const void* src, size_t srcSize,\n                               U32 frame, U32 lastFrameChunk)\n{\n    ZSTD_matchState_t* const ms = &cctx->blockState.matchState;\n    size_t fhSize = 0;\n\n    DEBUGLOG(5, \"ZSTD_compressContinue_internal, stage: %u, srcSize: %u\",\n                cctx->stage, (unsigned)srcSize);\n    RETURN_ERROR_IF(cctx->stage==ZSTDcs_created, stage_wrong,\n                    \"missing init (ZSTD_compressBegin)\");\n\n    if (frame && (cctx->stage==ZSTDcs_init)) {\n        fhSize = ZSTD_writeFrameHeader(dst, dstCapacity, &cctx->appliedParams,\n                                       cctx->pledgedSrcSizePlusOne-1, cctx->dictID);\n        FORWARD_IF_ERROR(fhSize, \"ZSTD_writeFrameHeader failed\");\n        assert(fhSize <= dstCapacity);\n        dstCapacity -= fhSize;\n        dst = (char*)dst + fhSize;\n        cctx->stage = ZSTDcs_ongoing;\n    }\n\n    if (!srcSize) return fhSize;   \n\n    if (!ZSTD_window_update(&ms->window, src, srcSize, ms->forceNonContiguous)) {\n        ms->forceNonContiguous = 0;\n        ms->nextToUpdate = ms->window.dictLimit;\n    }\n    if (cctx->appliedParams.ldmParams.enableLdm == ZSTD_ps_enable) {\n        ZSTD_window_update(&cctx->ldmState.window, src, srcSize,   0);\n    }\n\n    if (!frame) {\n         \n        ZSTD_overflowCorrectIfNeeded(\n            ms, &cctx->workspace, &cctx->appliedParams,\n            src, (BYTE const*)src + srcSize);\n    }\n\n    DEBUGLOG(5, \"ZSTD_compressContinue_internal (blockSize=%u)\", (unsigned)cctx->blockSize);\n    {   size_t const cSize = frame ?\n                             ZSTD_compress_frameChunk (cctx, dst, dstCapacity, src, srcSize, lastFrameChunk) :\n                             ZSTD_compressBlock_internal (cctx, dst, dstCapacity, src, srcSize, 0  );\n        FORWARD_IF_ERROR(cSize, \"%s\", frame ? \"ZSTD_compress_frameChunk failed\" : \"ZSTD_compressBlock_internal failed\");\n        cctx->consumedSrcSize += srcSize;\n        cctx->producedCSize += (cSize + fhSize);\n        assert(!(cctx->appliedParams.fParams.contentSizeFlag && cctx->pledgedSrcSizePlusOne == 0));\n        if (cctx->pledgedSrcSizePlusOne != 0) {   \n            ZSTD_STATIC_ASSERT(ZSTD_CONTENTSIZE_UNKNOWN == (unsigned long long)-1);\n            RETURN_ERROR_IF(\n                cctx->consumedSrcSize+1 > cctx->pledgedSrcSizePlusOne,\n                srcSize_wrong,\n                \"error : pledgedSrcSize = %u, while realSrcSize >= %u\",\n                (unsigned)cctx->pledgedSrcSizePlusOne-1,\n                (unsigned)cctx->consumedSrcSize);\n        }\n        return cSize + fhSize;\n    }\n}\n\nsize_t ZSTD_compressContinue (ZSTD_CCtx* cctx,\n                              void* dst, size_t dstCapacity,\n                        const void* src, size_t srcSize)\n{\n    DEBUGLOG(5, \"ZSTD_compressContinue (srcSize=%u)\", (unsigned)srcSize);\n    return ZSTD_compressContinue_internal(cctx, dst, dstCapacity, src, srcSize, 1  , 0  );\n}\n\n\nsize_t ZSTD_getBlockSize(const ZSTD_CCtx* cctx)\n{\n    ZSTD_compressionParameters const cParams = cctx->appliedParams.cParams;\n    assert(!ZSTD_checkCParams(cParams));\n    return MIN (ZSTD_BLOCKSIZE_MAX, (U32)1 << cParams.windowLog);\n}\n\nsize_t ZSTD_compressBlock(ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize)\n{\n    DEBUGLOG(5, \"ZSTD_compressBlock: srcSize = %u\", (unsigned)srcSize);\n    { size_t const blockSizeMax = ZSTD_getBlockSize(cctx);\n      RETURN_ERROR_IF(srcSize > blockSizeMax, srcSize_wrong, \"input is larger than a block\"); }\n\n    return ZSTD_compressContinue_internal(cctx, dst, dstCapacity, src, srcSize, 0  , 0  );\n}\n\n \nstatic size_t ZSTD_loadDictionaryContent(ZSTD_matchState_t* ms,\n                                         ldmState_t* ls,\n                                         ZSTD_cwksp* ws,\n                                         ZSTD_CCtx_params const* params,\n                                         const void* src, size_t srcSize,\n                                         ZSTD_dictTableLoadMethod_e dtlm)\n{\n    const BYTE* ip = (const BYTE*) src;\n    const BYTE* const iend = ip + srcSize;\n    int const loadLdmDict = params->ldmParams.enableLdm == ZSTD_ps_enable && ls != NULL;\n\n     \n    ZSTD_assertEqualCParams(params->cParams, ms->cParams);\n\n    if (srcSize > ZSTD_CHUNKSIZE_MAX) {\n         \n        U32 const maxDictSize = ZSTD_CURRENT_MAX - 1;\n         \n        assert(ZSTD_window_isEmpty(ms->window));\n        if (loadLdmDict)\n            assert(ZSTD_window_isEmpty(ls->window));\n         \n        if (srcSize > maxDictSize) {\n            ip = iend - maxDictSize;\n            src = ip;\n            srcSize = maxDictSize;\n        }\n    }\n\n    DEBUGLOG(4, \"ZSTD_loadDictionaryContent(): useRowMatchFinder=%d\", (int)params->useRowMatchFinder);\n    ZSTD_window_update(&ms->window, src, srcSize,   0);\n    ms->loadedDictEnd = params->forceWindow ? 0 : (U32)(iend - ms->window.base);\n    ms->forceNonContiguous = params->deterministicRefPrefix;\n\n    if (loadLdmDict) {\n        ZSTD_window_update(&ls->window, src, srcSize,   0);\n        ls->loadedDictEnd = params->forceWindow ? 0 : (U32)(iend - ls->window.base);\n    }\n\n    if (srcSize <= HASH_READ_SIZE) return 0;\n\n    ZSTD_overflowCorrectIfNeeded(ms, ws, params, ip, iend);\n\n    if (loadLdmDict)\n        ZSTD_ldm_fillHashTable(ls, ip, iend, &params->ldmParams);\n\n    switch(params->cParams.strategy)\n    {\n    case ZSTD_fast:\n        ZSTD_fillHashTable(ms, iend, dtlm);\n        break;\n    case ZSTD_dfast:\n        ZSTD_fillDoubleHashTable(ms, iend, dtlm);\n        break;\n\n    case ZSTD_greedy:\n    case ZSTD_lazy:\n    case ZSTD_lazy2:\n        assert(srcSize >= HASH_READ_SIZE);\n        if (ms->dedicatedDictSearch) {\n            assert(ms->chainTable != NULL);\n            ZSTD_dedicatedDictSearch_lazy_loadDictionary(ms, iend-HASH_READ_SIZE);\n        } else {\n            assert(params->useRowMatchFinder != ZSTD_ps_auto);\n            if (params->useRowMatchFinder == ZSTD_ps_enable) {\n                size_t const tagTableSize = ((size_t)1 << params->cParams.hashLog) * sizeof(U16);\n                ZSTD_memset(ms->tagTable, 0, tagTableSize);\n                ZSTD_row_update(ms, iend-HASH_READ_SIZE);\n                DEBUGLOG(4, \"Using row-based hash table for lazy dict\");\n            } else {\n                ZSTD_insertAndFindFirstIndex(ms, iend-HASH_READ_SIZE);\n                DEBUGLOG(4, \"Using chain-based hash table for lazy dict\");\n            }\n        }\n        break;\n\n    case ZSTD_btlazy2:    \n    case ZSTD_btopt:\n    case ZSTD_btultra:\n    case ZSTD_btultra2:\n        assert(srcSize >= HASH_READ_SIZE);\n        ZSTD_updateTree(ms, iend-HASH_READ_SIZE, iend);\n        break;\n\n    default:\n        assert(0);   \n    }\n\n    ms->nextToUpdate = (U32)(iend - ms->window.base);\n    return 0;\n}\n\n\n \nstatic FSE_repeat ZSTD_dictNCountRepeat(short* normalizedCounter, unsigned dictMaxSymbolValue, unsigned maxSymbolValue)\n{\n    U32 s;\n    if (dictMaxSymbolValue < maxSymbolValue) {\n        return FSE_repeat_check;\n    }\n    for (s = 0; s <= maxSymbolValue; ++s) {\n        if (normalizedCounter[s] == 0) {\n            return FSE_repeat_check;\n        }\n    }\n    return FSE_repeat_valid;\n}\n\nsize_t ZSTD_loadCEntropy(ZSTD_compressedBlockState_t* bs, void* workspace,\n                         const void* const dict, size_t dictSize)\n{\n    short offcodeNCount[MaxOff+1];\n    unsigned offcodeMaxValue = MaxOff;\n    const BYTE* dictPtr = (const BYTE*)dict;     \n    const BYTE* const dictEnd = dictPtr + dictSize;\n    dictPtr += 8;\n    bs->entropy.huf.repeatMode = HUF_repeat_check;\n\n    {   unsigned maxSymbolValue = 255;\n        unsigned hasZeroWeights = 1;\n        size_t const hufHeaderSize = HUF_readCTable((HUF_CElt*)bs->entropy.huf.CTable, &maxSymbolValue, dictPtr,\n            dictEnd-dictPtr, &hasZeroWeights);\n\n         \n        if (!hasZeroWeights)\n            bs->entropy.huf.repeatMode = HUF_repeat_valid;\n\n        RETURN_ERROR_IF(HUF_isError(hufHeaderSize), dictionary_corrupted, \"\");\n        RETURN_ERROR_IF(maxSymbolValue < 255, dictionary_corrupted, \"\");\n        dictPtr += hufHeaderSize;\n    }\n\n    {   unsigned offcodeLog;\n        size_t const offcodeHeaderSize = FSE_readNCount(offcodeNCount, &offcodeMaxValue, &offcodeLog, dictPtr, dictEnd-dictPtr);\n        RETURN_ERROR_IF(FSE_isError(offcodeHeaderSize), dictionary_corrupted, \"\");\n        RETURN_ERROR_IF(offcodeLog > OffFSELog, dictionary_corrupted, \"\");\n         \n        RETURN_ERROR_IF(FSE_isError(FSE_buildCTable_wksp(\n                bs->entropy.fse.offcodeCTable,\n                offcodeNCount, MaxOff, offcodeLog,\n                workspace, HUF_WORKSPACE_SIZE)),\n            dictionary_corrupted, \"\");\n         \n        dictPtr += offcodeHeaderSize;\n    }\n\n    {   short matchlengthNCount[MaxML+1];\n        unsigned matchlengthMaxValue = MaxML, matchlengthLog;\n        size_t const matchlengthHeaderSize = FSE_readNCount(matchlengthNCount, &matchlengthMaxValue, &matchlengthLog, dictPtr, dictEnd-dictPtr);\n        RETURN_ERROR_IF(FSE_isError(matchlengthHeaderSize), dictionary_corrupted, \"\");\n        RETURN_ERROR_IF(matchlengthLog > MLFSELog, dictionary_corrupted, \"\");\n        RETURN_ERROR_IF(FSE_isError(FSE_buildCTable_wksp(\n                bs->entropy.fse.matchlengthCTable,\n                matchlengthNCount, matchlengthMaxValue, matchlengthLog,\n                workspace, HUF_WORKSPACE_SIZE)),\n            dictionary_corrupted, \"\");\n        bs->entropy.fse.matchlength_repeatMode = ZSTD_dictNCountRepeat(matchlengthNCount, matchlengthMaxValue, MaxML);\n        dictPtr += matchlengthHeaderSize;\n    }\n\n    {   short litlengthNCount[MaxLL+1];\n        unsigned litlengthMaxValue = MaxLL, litlengthLog;\n        size_t const litlengthHeaderSize = FSE_readNCount(litlengthNCount, &litlengthMaxValue, &litlengthLog, dictPtr, dictEnd-dictPtr);\n        RETURN_ERROR_IF(FSE_isError(litlengthHeaderSize), dictionary_corrupted, \"\");\n        RETURN_ERROR_IF(litlengthLog > LLFSELog, dictionary_corrupted, \"\");\n        RETURN_ERROR_IF(FSE_isError(FSE_buildCTable_wksp(\n                bs->entropy.fse.litlengthCTable,\n                litlengthNCount, litlengthMaxValue, litlengthLog,\n                workspace, HUF_WORKSPACE_SIZE)),\n            dictionary_corrupted, \"\");\n        bs->entropy.fse.litlength_repeatMode = ZSTD_dictNCountRepeat(litlengthNCount, litlengthMaxValue, MaxLL);\n        dictPtr += litlengthHeaderSize;\n    }\n\n    RETURN_ERROR_IF(dictPtr+12 > dictEnd, dictionary_corrupted, \"\");\n    bs->rep[0] = MEM_readLE32(dictPtr+0);\n    bs->rep[1] = MEM_readLE32(dictPtr+4);\n    bs->rep[2] = MEM_readLE32(dictPtr+8);\n    dictPtr += 12;\n\n    {   size_t const dictContentSize = (size_t)(dictEnd - dictPtr);\n        U32 offcodeMax = MaxOff;\n        if (dictContentSize <= ((U32)-1) - 128 KB) {\n            U32 const maxOffset = (U32)dictContentSize + 128 KB;  \n            offcodeMax = ZSTD_highbit32(maxOffset);  \n        }\n         \n        bs->entropy.fse.offcode_repeatMode = ZSTD_dictNCountRepeat(offcodeNCount, offcodeMaxValue, MIN(offcodeMax, MaxOff));\n\n         \n        {   U32 u;\n            for (u=0; u<3; u++) {\n                RETURN_ERROR_IF(bs->rep[u] == 0, dictionary_corrupted, \"\");\n                RETURN_ERROR_IF(bs->rep[u] > dictContentSize, dictionary_corrupted, \"\");\n    }   }   }\n\n    return dictPtr - (const BYTE*)dict;\n}\n\n \n \nstatic size_t ZSTD_loadZstdDictionary(ZSTD_compressedBlockState_t* bs,\n                                      ZSTD_matchState_t* ms,\n                                      ZSTD_cwksp* ws,\n                                      ZSTD_CCtx_params const* params,\n                                      const void* dict, size_t dictSize,\n                                      ZSTD_dictTableLoadMethod_e dtlm,\n                                      void* workspace)\n{\n    const BYTE* dictPtr = (const BYTE*)dict;\n    const BYTE* const dictEnd = dictPtr + dictSize;\n    size_t dictID;\n    size_t eSize;\n    ZSTD_STATIC_ASSERT(HUF_WORKSPACE_SIZE >= (1<<MAX(MLFSELog,LLFSELog)));\n    assert(dictSize >= 8);\n    assert(MEM_readLE32(dictPtr) == ZSTD_MAGIC_DICTIONARY);\n\n    dictID = params->fParams.noDictIDFlag ? 0 :  MEM_readLE32(dictPtr + 4   );\n    eSize = ZSTD_loadCEntropy(bs, workspace, dict, dictSize);\n    FORWARD_IF_ERROR(eSize, \"ZSTD_loadCEntropy failed\");\n    dictPtr += eSize;\n\n    {\n        size_t const dictContentSize = (size_t)(dictEnd - dictPtr);\n        FORWARD_IF_ERROR(ZSTD_loadDictionaryContent(\n            ms, NULL, ws, params, dictPtr, dictContentSize, dtlm), \"\");\n    }\n    return dictID;\n}\n\n \nstatic size_t\nZSTD_compress_insertDictionary(ZSTD_compressedBlockState_t* bs,\n                               ZSTD_matchState_t* ms,\n                               ldmState_t* ls,\n                               ZSTD_cwksp* ws,\n                         const ZSTD_CCtx_params* params,\n                         const void* dict, size_t dictSize,\n                               ZSTD_dictContentType_e dictContentType,\n                               ZSTD_dictTableLoadMethod_e dtlm,\n                               void* workspace)\n{\n    DEBUGLOG(4, \"ZSTD_compress_insertDictionary (dictSize=%u)\", (U32)dictSize);\n    if ((dict==NULL) || (dictSize<8)) {\n        RETURN_ERROR_IF(dictContentType == ZSTD_dct_fullDict, dictionary_wrong, \"\");\n        return 0;\n    }\n\n    ZSTD_reset_compressedBlockState(bs);\n\n     \n    if (dictContentType == ZSTD_dct_rawContent)\n        return ZSTD_loadDictionaryContent(ms, ls, ws, params, dict, dictSize, dtlm);\n\n    if (MEM_readLE32(dict) != ZSTD_MAGIC_DICTIONARY) {\n        if (dictContentType == ZSTD_dct_auto) {\n            DEBUGLOG(4, \"raw content dictionary detected\");\n            return ZSTD_loadDictionaryContent(\n                ms, ls, ws, params, dict, dictSize, dtlm);\n        }\n        RETURN_ERROR_IF(dictContentType == ZSTD_dct_fullDict, dictionary_wrong, \"\");\n        assert(0);    \n    }\n\n     \n    return ZSTD_loadZstdDictionary(\n        bs, ms, ws, params, dict, dictSize, dtlm, workspace);\n}\n\n#define ZSTD_USE_CDICT_PARAMS_SRCSIZE_CUTOFF (128 KB)\n#define ZSTD_USE_CDICT_PARAMS_DICTSIZE_MULTIPLIER (6ULL)\n\n \nstatic size_t ZSTD_compressBegin_internal(ZSTD_CCtx* cctx,\n                                    const void* dict, size_t dictSize,\n                                    ZSTD_dictContentType_e dictContentType,\n                                    ZSTD_dictTableLoadMethod_e dtlm,\n                                    const ZSTD_CDict* cdict,\n                                    const ZSTD_CCtx_params* params, U64 pledgedSrcSize,\n                                    ZSTD_buffered_policy_e zbuff)\n{\n    size_t const dictContentSize = cdict ? cdict->dictContentSize : dictSize;\n    DEBUGLOG(4, \"ZSTD_compressBegin_internal: wlog=%u\", params->cParams.windowLog);\n     \n    assert(!ZSTD_isError(ZSTD_checkCParams(params->cParams)));\n    assert(!((dict) && (cdict)));   \n    if ( (cdict)\n      && (cdict->dictContentSize > 0)\n      && ( pledgedSrcSize < ZSTD_USE_CDICT_PARAMS_SRCSIZE_CUTOFF\n        || pledgedSrcSize < cdict->dictContentSize * ZSTD_USE_CDICT_PARAMS_DICTSIZE_MULTIPLIER\n        || pledgedSrcSize == ZSTD_CONTENTSIZE_UNKNOWN\n        || cdict->compressionLevel == 0)\n      && (params->attachDictPref != ZSTD_dictForceLoad) ) {\n        return ZSTD_resetCCtx_usingCDict(cctx, cdict, params, pledgedSrcSize, zbuff);\n    }\n\n    FORWARD_IF_ERROR( ZSTD_resetCCtx_internal(cctx, params, pledgedSrcSize,\n                                     dictContentSize,\n                                     ZSTDcrp_makeClean, zbuff) , \"\");\n    {   size_t const dictID = cdict ?\n                ZSTD_compress_insertDictionary(\n                        cctx->blockState.prevCBlock, &cctx->blockState.matchState,\n                        &cctx->ldmState, &cctx->workspace, &cctx->appliedParams, cdict->dictContent,\n                        cdict->dictContentSize, cdict->dictContentType, dtlm,\n                        cctx->entropyWorkspace)\n              : ZSTD_compress_insertDictionary(\n                        cctx->blockState.prevCBlock, &cctx->blockState.matchState,\n                        &cctx->ldmState, &cctx->workspace, &cctx->appliedParams, dict, dictSize,\n                        dictContentType, dtlm, cctx->entropyWorkspace);\n        FORWARD_IF_ERROR(dictID, \"ZSTD_compress_insertDictionary failed\");\n        assert(dictID <= UINT_MAX);\n        cctx->dictID = (U32)dictID;\n        cctx->dictContentSize = dictContentSize;\n    }\n    return 0;\n}\n\nsize_t ZSTD_compressBegin_advanced_internal(ZSTD_CCtx* cctx,\n                                    const void* dict, size_t dictSize,\n                                    ZSTD_dictContentType_e dictContentType,\n                                    ZSTD_dictTableLoadMethod_e dtlm,\n                                    const ZSTD_CDict* cdict,\n                                    const ZSTD_CCtx_params* params,\n                                    unsigned long long pledgedSrcSize)\n{\n    DEBUGLOG(4, \"ZSTD_compressBegin_advanced_internal: wlog=%u\", params->cParams.windowLog);\n     \n    FORWARD_IF_ERROR( ZSTD_checkCParams(params->cParams) , \"\");\n    return ZSTD_compressBegin_internal(cctx,\n                                       dict, dictSize, dictContentType, dtlm,\n                                       cdict,\n                                       params, pledgedSrcSize,\n                                       ZSTDb_not_buffered);\n}\n\n \nsize_t ZSTD_compressBegin_advanced(ZSTD_CCtx* cctx,\n                             const void* dict, size_t dictSize,\n                                   ZSTD_parameters params, unsigned long long pledgedSrcSize)\n{\n    ZSTD_CCtx_params cctxParams;\n    ZSTD_CCtxParams_init_internal(&cctxParams, &params, ZSTD_NO_CLEVEL);\n    return ZSTD_compressBegin_advanced_internal(cctx,\n                                            dict, dictSize, ZSTD_dct_auto, ZSTD_dtlm_fast,\n                                            NULL  ,\n                                            &cctxParams, pledgedSrcSize);\n}\n\nsize_t ZSTD_compressBegin_usingDict(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, int compressionLevel)\n{\n    ZSTD_CCtx_params cctxParams;\n    {\n        ZSTD_parameters const params = ZSTD_getParams_internal(compressionLevel, ZSTD_CONTENTSIZE_UNKNOWN, dictSize, ZSTD_cpm_noAttachDict);\n        ZSTD_CCtxParams_init_internal(&cctxParams, &params, (compressionLevel == 0) ? ZSTD_CLEVEL_DEFAULT : compressionLevel);\n    }\n    DEBUGLOG(4, \"ZSTD_compressBegin_usingDict (dictSize=%u)\", (unsigned)dictSize);\n    return ZSTD_compressBegin_internal(cctx, dict, dictSize, ZSTD_dct_auto, ZSTD_dtlm_fast, NULL,\n                                       &cctxParams, ZSTD_CONTENTSIZE_UNKNOWN, ZSTDb_not_buffered);\n}\n\nsize_t ZSTD_compressBegin(ZSTD_CCtx* cctx, int compressionLevel)\n{\n    return ZSTD_compressBegin_usingDict(cctx, NULL, 0, compressionLevel);\n}\n\n\n \nstatic size_t ZSTD_writeEpilogue(ZSTD_CCtx* cctx, void* dst, size_t dstCapacity)\n{\n    BYTE* const ostart = (BYTE*)dst;\n    BYTE* op = ostart;\n    size_t fhSize = 0;\n\n    DEBUGLOG(4, \"ZSTD_writeEpilogue\");\n    RETURN_ERROR_IF(cctx->stage == ZSTDcs_created, stage_wrong, \"init missing\");\n\n     \n    if (cctx->stage == ZSTDcs_init) {\n        fhSize = ZSTD_writeFrameHeader(dst, dstCapacity, &cctx->appliedParams, 0, 0);\n        FORWARD_IF_ERROR(fhSize, \"ZSTD_writeFrameHeader failed\");\n        dstCapacity -= fhSize;\n        op += fhSize;\n        cctx->stage = ZSTDcs_ongoing;\n    }\n\n    if (cctx->stage != ZSTDcs_ending) {\n         \n        U32 const cBlockHeader24 = 1   + (((U32)bt_raw)<<1) + 0;\n        RETURN_ERROR_IF(dstCapacity<4, dstSize_tooSmall, \"no room for epilogue\");\n        MEM_writeLE32(op, cBlockHeader24);\n        op += ZSTD_blockHeaderSize;\n        dstCapacity -= ZSTD_blockHeaderSize;\n    }\n\n    if (cctx->appliedParams.fParams.checksumFlag) {\n        U32 const checksum = (U32) xxh64_digest(&cctx->xxhState);\n        RETURN_ERROR_IF(dstCapacity<4, dstSize_tooSmall, \"no room for checksum\");\n        DEBUGLOG(4, \"ZSTD_writeEpilogue: write checksum : %08X\", (unsigned)checksum);\n        MEM_writeLE32(op, checksum);\n        op += 4;\n    }\n\n    cctx->stage = ZSTDcs_created;   \n    return op-ostart;\n}\n\nvoid ZSTD_CCtx_trace(ZSTD_CCtx* cctx, size_t extraCSize)\n{\n    (void)cctx;\n    (void)extraCSize;\n}\n\nsize_t ZSTD_compressEnd (ZSTD_CCtx* cctx,\n                         void* dst, size_t dstCapacity,\n                   const void* src, size_t srcSize)\n{\n    size_t endResult;\n    size_t const cSize = ZSTD_compressContinue_internal(cctx,\n                                dst, dstCapacity, src, srcSize,\n                                1  , 1  );\n    FORWARD_IF_ERROR(cSize, \"ZSTD_compressContinue_internal failed\");\n    endResult = ZSTD_writeEpilogue(cctx, (char*)dst + cSize, dstCapacity-cSize);\n    FORWARD_IF_ERROR(endResult, \"ZSTD_writeEpilogue failed\");\n    assert(!(cctx->appliedParams.fParams.contentSizeFlag && cctx->pledgedSrcSizePlusOne == 0));\n    if (cctx->pledgedSrcSizePlusOne != 0) {   \n        ZSTD_STATIC_ASSERT(ZSTD_CONTENTSIZE_UNKNOWN == (unsigned long long)-1);\n        DEBUGLOG(4, \"end of frame : controlling src size\");\n        RETURN_ERROR_IF(\n            cctx->pledgedSrcSizePlusOne != cctx->consumedSrcSize+1,\n            srcSize_wrong,\n             \"error : pledgedSrcSize = %u, while realSrcSize = %u\",\n            (unsigned)cctx->pledgedSrcSizePlusOne-1,\n            (unsigned)cctx->consumedSrcSize);\n    }\n    ZSTD_CCtx_trace(cctx, endResult);\n    return cSize + endResult;\n}\n\nsize_t ZSTD_compress_advanced (ZSTD_CCtx* cctx,\n                               void* dst, size_t dstCapacity,\n                         const void* src, size_t srcSize,\n                         const void* dict,size_t dictSize,\n                               ZSTD_parameters params)\n{\n    DEBUGLOG(4, \"ZSTD_compress_advanced\");\n    FORWARD_IF_ERROR(ZSTD_checkCParams(params.cParams), \"\");\n    ZSTD_CCtxParams_init_internal(&cctx->simpleApiParams, &params, ZSTD_NO_CLEVEL);\n    return ZSTD_compress_advanced_internal(cctx,\n                                           dst, dstCapacity,\n                                           src, srcSize,\n                                           dict, dictSize,\n                                           &cctx->simpleApiParams);\n}\n\n \nsize_t ZSTD_compress_advanced_internal(\n        ZSTD_CCtx* cctx,\n        void* dst, size_t dstCapacity,\n        const void* src, size_t srcSize,\n        const void* dict,size_t dictSize,\n        const ZSTD_CCtx_params* params)\n{\n    DEBUGLOG(4, \"ZSTD_compress_advanced_internal (srcSize:%u)\", (unsigned)srcSize);\n    FORWARD_IF_ERROR( ZSTD_compressBegin_internal(cctx,\n                         dict, dictSize, ZSTD_dct_auto, ZSTD_dtlm_fast, NULL,\n                         params, srcSize, ZSTDb_not_buffered) , \"\");\n    return ZSTD_compressEnd(cctx, dst, dstCapacity, src, srcSize);\n}\n\nsize_t ZSTD_compress_usingDict(ZSTD_CCtx* cctx,\n                               void* dst, size_t dstCapacity,\n                         const void* src, size_t srcSize,\n                         const void* dict, size_t dictSize,\n                               int compressionLevel)\n{\n    {\n        ZSTD_parameters const params = ZSTD_getParams_internal(compressionLevel, srcSize, dict ? dictSize : 0, ZSTD_cpm_noAttachDict);\n        assert(params.fParams.contentSizeFlag == 1);\n        ZSTD_CCtxParams_init_internal(&cctx->simpleApiParams, &params, (compressionLevel == 0) ? ZSTD_CLEVEL_DEFAULT: compressionLevel);\n    }\n    DEBUGLOG(4, \"ZSTD_compress_usingDict (srcSize=%u)\", (unsigned)srcSize);\n    return ZSTD_compress_advanced_internal(cctx, dst, dstCapacity, src, srcSize, dict, dictSize, &cctx->simpleApiParams);\n}\n\nsize_t ZSTD_compressCCtx(ZSTD_CCtx* cctx,\n                         void* dst, size_t dstCapacity,\n                   const void* src, size_t srcSize,\n                         int compressionLevel)\n{\n    DEBUGLOG(4, \"ZSTD_compressCCtx (srcSize=%u)\", (unsigned)srcSize);\n    assert(cctx != NULL);\n    return ZSTD_compress_usingDict(cctx, dst, dstCapacity, src, srcSize, NULL, 0, compressionLevel);\n}\n\nsize_t ZSTD_compress(void* dst, size_t dstCapacity,\n               const void* src, size_t srcSize,\n                     int compressionLevel)\n{\n    size_t result;\n    ZSTD_CCtx* cctx = ZSTD_createCCtx();\n    RETURN_ERROR_IF(!cctx, memory_allocation, \"ZSTD_createCCtx failed\");\n    result = ZSTD_compressCCtx(cctx, dst, dstCapacity, src, srcSize, compressionLevel);\n    ZSTD_freeCCtx(cctx);\n    return result;\n}\n\n\n \n\n \nsize_t ZSTD_estimateCDictSize_advanced(\n        size_t dictSize, ZSTD_compressionParameters cParams,\n        ZSTD_dictLoadMethod_e dictLoadMethod)\n{\n    DEBUGLOG(5, \"sizeof(ZSTD_CDict) : %u\", (unsigned)sizeof(ZSTD_CDict));\n    return ZSTD_cwksp_alloc_size(sizeof(ZSTD_CDict))\n         + ZSTD_cwksp_alloc_size(HUF_WORKSPACE_SIZE)\n          \n         + ZSTD_sizeof_matchState(&cParams, ZSTD_resolveRowMatchFinderMode(ZSTD_ps_auto, &cParams),\n                                    1,   0)\n         + (dictLoadMethod == ZSTD_dlm_byRef ? 0\n            : ZSTD_cwksp_alloc_size(ZSTD_cwksp_align(dictSize, sizeof(void *))));\n}\n\nsize_t ZSTD_estimateCDictSize(size_t dictSize, int compressionLevel)\n{\n    ZSTD_compressionParameters const cParams = ZSTD_getCParams_internal(compressionLevel, ZSTD_CONTENTSIZE_UNKNOWN, dictSize, ZSTD_cpm_createCDict);\n    return ZSTD_estimateCDictSize_advanced(dictSize, cParams, ZSTD_dlm_byCopy);\n}\n\nsize_t ZSTD_sizeof_CDict(const ZSTD_CDict* cdict)\n{\n    if (cdict==NULL) return 0;    \n    DEBUGLOG(5, \"sizeof(*cdict) : %u\", (unsigned)sizeof(*cdict));\n     \n    return (cdict->workspace.workspace == cdict ? 0 : sizeof(*cdict))\n        + ZSTD_cwksp_sizeof(&cdict->workspace);\n}\n\nstatic size_t ZSTD_initCDict_internal(\n                    ZSTD_CDict* cdict,\n              const void* dictBuffer, size_t dictSize,\n                    ZSTD_dictLoadMethod_e dictLoadMethod,\n                    ZSTD_dictContentType_e dictContentType,\n                    ZSTD_CCtx_params params)\n{\n    DEBUGLOG(3, \"ZSTD_initCDict_internal (dictContentType:%u)\", (unsigned)dictContentType);\n    assert(!ZSTD_checkCParams(params.cParams));\n    cdict->matchState.cParams = params.cParams;\n    cdict->matchState.dedicatedDictSearch = params.enableDedicatedDictSearch;\n    if ((dictLoadMethod == ZSTD_dlm_byRef) || (!dictBuffer) || (!dictSize)) {\n        cdict->dictContent = dictBuffer;\n    } else {\n         void *internalBuffer = ZSTD_cwksp_reserve_object(&cdict->workspace, ZSTD_cwksp_align(dictSize, sizeof(void*)));\n        RETURN_ERROR_IF(!internalBuffer, memory_allocation, \"NULL pointer!\");\n        cdict->dictContent = internalBuffer;\n        ZSTD_memcpy(internalBuffer, dictBuffer, dictSize);\n    }\n    cdict->dictContentSize = dictSize;\n    cdict->dictContentType = dictContentType;\n\n    cdict->entropyWorkspace = (U32*)ZSTD_cwksp_reserve_object(&cdict->workspace, HUF_WORKSPACE_SIZE);\n\n\n     \n    ZSTD_reset_compressedBlockState(&cdict->cBlockState);\n    FORWARD_IF_ERROR(ZSTD_reset_matchState(\n        &cdict->matchState,\n        &cdict->workspace,\n        &params.cParams,\n        params.useRowMatchFinder,\n        ZSTDcrp_makeClean,\n        ZSTDirp_reset,\n        ZSTD_resetTarget_CDict), \"\");\n     \n    {   params.compressionLevel = ZSTD_CLEVEL_DEFAULT;\n        params.fParams.contentSizeFlag = 1;\n        {   size_t const dictID = ZSTD_compress_insertDictionary(\n                    &cdict->cBlockState, &cdict->matchState, NULL, &cdict->workspace,\n                    &params, cdict->dictContent, cdict->dictContentSize,\n                    dictContentType, ZSTD_dtlm_full, cdict->entropyWorkspace);\n            FORWARD_IF_ERROR(dictID, \"ZSTD_compress_insertDictionary failed\");\n            assert(dictID <= (size_t)(U32)-1);\n            cdict->dictID = (U32)dictID;\n        }\n    }\n\n    return 0;\n}\n\nstatic ZSTD_CDict* ZSTD_createCDict_advanced_internal(size_t dictSize,\n                                      ZSTD_dictLoadMethod_e dictLoadMethod,\n                                      ZSTD_compressionParameters cParams,\n                                      ZSTD_paramSwitch_e useRowMatchFinder,\n                                      U32 enableDedicatedDictSearch,\n                                      ZSTD_customMem customMem)\n{\n    if ((!customMem.customAlloc) ^ (!customMem.customFree)) return NULL;\n\n    {   size_t const workspaceSize =\n            ZSTD_cwksp_alloc_size(sizeof(ZSTD_CDict)) +\n            ZSTD_cwksp_alloc_size(HUF_WORKSPACE_SIZE) +\n            ZSTD_sizeof_matchState(&cParams, useRowMatchFinder, enableDedicatedDictSearch,   0) +\n            (dictLoadMethod == ZSTD_dlm_byRef ? 0\n             : ZSTD_cwksp_alloc_size(ZSTD_cwksp_align(dictSize, sizeof(void*))));\n        void* const workspace = ZSTD_customMalloc(workspaceSize, customMem);\n        ZSTD_cwksp ws;\n        ZSTD_CDict* cdict;\n\n        if (!workspace) {\n            ZSTD_customFree(workspace, customMem);\n            return NULL;\n        }\n\n        ZSTD_cwksp_init(&ws, workspace, workspaceSize, ZSTD_cwksp_dynamic_alloc);\n\n        cdict = (ZSTD_CDict*)ZSTD_cwksp_reserve_object(&ws, sizeof(ZSTD_CDict));\n        assert(cdict != NULL);\n        ZSTD_cwksp_move(&cdict->workspace, &ws);\n        cdict->customMem = customMem;\n        cdict->compressionLevel = ZSTD_NO_CLEVEL;  \n        cdict->useRowMatchFinder = useRowMatchFinder;\n        return cdict;\n    }\n}\n\nZSTD_CDict* ZSTD_createCDict_advanced(const void* dictBuffer, size_t dictSize,\n                                      ZSTD_dictLoadMethod_e dictLoadMethod,\n                                      ZSTD_dictContentType_e dictContentType,\n                                      ZSTD_compressionParameters cParams,\n                                      ZSTD_customMem customMem)\n{\n    ZSTD_CCtx_params cctxParams;\n    ZSTD_memset(&cctxParams, 0, sizeof(cctxParams));\n    ZSTD_CCtxParams_init(&cctxParams, 0);\n    cctxParams.cParams = cParams;\n    cctxParams.customMem = customMem;\n    return ZSTD_createCDict_advanced2(\n        dictBuffer, dictSize,\n        dictLoadMethod, dictContentType,\n        &cctxParams, customMem);\n}\n\nZSTD_CDict* ZSTD_createCDict_advanced2(\n        const void* dict, size_t dictSize,\n        ZSTD_dictLoadMethod_e dictLoadMethod,\n        ZSTD_dictContentType_e dictContentType,\n        const ZSTD_CCtx_params* originalCctxParams,\n        ZSTD_customMem customMem)\n{\n    ZSTD_CCtx_params cctxParams = *originalCctxParams;\n    ZSTD_compressionParameters cParams;\n    ZSTD_CDict* cdict;\n\n    DEBUGLOG(3, \"ZSTD_createCDict_advanced2, mode %u\", (unsigned)dictContentType);\n    if (!customMem.customAlloc ^ !customMem.customFree) return NULL;\n\n    if (cctxParams.enableDedicatedDictSearch) {\n        cParams = ZSTD_dedicatedDictSearch_getCParams(\n            cctxParams.compressionLevel, dictSize);\n        ZSTD_overrideCParams(&cParams, &cctxParams.cParams);\n    } else {\n        cParams = ZSTD_getCParamsFromCCtxParams(\n            &cctxParams, ZSTD_CONTENTSIZE_UNKNOWN, dictSize, ZSTD_cpm_createCDict);\n    }\n\n    if (!ZSTD_dedicatedDictSearch_isSupported(&cParams)) {\n         \n        cctxParams.enableDedicatedDictSearch = 0;\n        cParams = ZSTD_getCParamsFromCCtxParams(\n            &cctxParams, ZSTD_CONTENTSIZE_UNKNOWN, dictSize, ZSTD_cpm_createCDict);\n    }\n\n    DEBUGLOG(3, \"ZSTD_createCDict_advanced2: DDS: %u\", cctxParams.enableDedicatedDictSearch);\n    cctxParams.cParams = cParams;\n    cctxParams.useRowMatchFinder = ZSTD_resolveRowMatchFinderMode(cctxParams.useRowMatchFinder, &cParams);\n\n    cdict = ZSTD_createCDict_advanced_internal(dictSize,\n                        dictLoadMethod, cctxParams.cParams,\n                        cctxParams.useRowMatchFinder, cctxParams.enableDedicatedDictSearch,\n                        customMem);\n\n    if (ZSTD_isError( ZSTD_initCDict_internal(cdict,\n                                    dict, dictSize,\n                                    dictLoadMethod, dictContentType,\n                                    cctxParams) )) {\n        ZSTD_freeCDict(cdict);\n        return NULL;\n    }\n\n    return cdict;\n}\n\nZSTD_CDict* ZSTD_createCDict(const void* dict, size_t dictSize, int compressionLevel)\n{\n    ZSTD_compressionParameters cParams = ZSTD_getCParams_internal(compressionLevel, ZSTD_CONTENTSIZE_UNKNOWN, dictSize, ZSTD_cpm_createCDict);\n    ZSTD_CDict* const cdict = ZSTD_createCDict_advanced(dict, dictSize,\n                                                  ZSTD_dlm_byCopy, ZSTD_dct_auto,\n                                                  cParams, ZSTD_defaultCMem);\n    if (cdict)\n        cdict->compressionLevel = (compressionLevel == 0) ? ZSTD_CLEVEL_DEFAULT : compressionLevel;\n    return cdict;\n}\n\nZSTD_CDict* ZSTD_createCDict_byReference(const void* dict, size_t dictSize, int compressionLevel)\n{\n    ZSTD_compressionParameters cParams = ZSTD_getCParams_internal(compressionLevel, ZSTD_CONTENTSIZE_UNKNOWN, dictSize, ZSTD_cpm_createCDict);\n    ZSTD_CDict* const cdict = ZSTD_createCDict_advanced(dict, dictSize,\n                                     ZSTD_dlm_byRef, ZSTD_dct_auto,\n                                     cParams, ZSTD_defaultCMem);\n    if (cdict)\n        cdict->compressionLevel = (compressionLevel == 0) ? ZSTD_CLEVEL_DEFAULT : compressionLevel;\n    return cdict;\n}\n\nsize_t ZSTD_freeCDict(ZSTD_CDict* cdict)\n{\n    if (cdict==NULL) return 0;    \n    {   ZSTD_customMem const cMem = cdict->customMem;\n        int cdictInWorkspace = ZSTD_cwksp_owns_buffer(&cdict->workspace, cdict);\n        ZSTD_cwksp_free(&cdict->workspace, cMem);\n        if (!cdictInWorkspace) {\n            ZSTD_customFree(cdict, cMem);\n        }\n        return 0;\n    }\n}\n\n \nconst ZSTD_CDict* ZSTD_initStaticCDict(\n                                 void* workspace, size_t workspaceSize,\n                           const void* dict, size_t dictSize,\n                                 ZSTD_dictLoadMethod_e dictLoadMethod,\n                                 ZSTD_dictContentType_e dictContentType,\n                                 ZSTD_compressionParameters cParams)\n{\n    ZSTD_paramSwitch_e const useRowMatchFinder = ZSTD_resolveRowMatchFinderMode(ZSTD_ps_auto, &cParams);\n     \n    size_t const matchStateSize = ZSTD_sizeof_matchState(&cParams, useRowMatchFinder,   1,   0);\n    size_t const neededSize = ZSTD_cwksp_alloc_size(sizeof(ZSTD_CDict))\n                            + (dictLoadMethod == ZSTD_dlm_byRef ? 0\n                               : ZSTD_cwksp_alloc_size(ZSTD_cwksp_align(dictSize, sizeof(void*))))\n                            + ZSTD_cwksp_alloc_size(HUF_WORKSPACE_SIZE)\n                            + matchStateSize;\n    ZSTD_CDict* cdict;\n    ZSTD_CCtx_params params;\n\n    if ((size_t)workspace & 7) return NULL;   \n\n    {\n        ZSTD_cwksp ws;\n        ZSTD_cwksp_init(&ws, workspace, workspaceSize, ZSTD_cwksp_static_alloc);\n        cdict = (ZSTD_CDict*)ZSTD_cwksp_reserve_object(&ws, sizeof(ZSTD_CDict));\n        if (cdict == NULL) return NULL;\n        ZSTD_cwksp_move(&cdict->workspace, &ws);\n    }\n\n    DEBUGLOG(4, \"(workspaceSize < neededSize) : (%u < %u) => %u\",\n        (unsigned)workspaceSize, (unsigned)neededSize, (unsigned)(workspaceSize < neededSize));\n    if (workspaceSize < neededSize) return NULL;\n\n    ZSTD_CCtxParams_init(&params, 0);\n    params.cParams = cParams;\n    params.useRowMatchFinder = useRowMatchFinder;\n    cdict->useRowMatchFinder = useRowMatchFinder;\n\n    if (ZSTD_isError( ZSTD_initCDict_internal(cdict,\n                                              dict, dictSize,\n                                              dictLoadMethod, dictContentType,\n                                              params) ))\n        return NULL;\n\n    return cdict;\n}\n\nZSTD_compressionParameters ZSTD_getCParamsFromCDict(const ZSTD_CDict* cdict)\n{\n    assert(cdict != NULL);\n    return cdict->matchState.cParams;\n}\n\n \nunsigned ZSTD_getDictID_fromCDict(const ZSTD_CDict* cdict)\n{\n    if (cdict==NULL) return 0;\n    return cdict->dictID;\n}\n\n \nstatic size_t ZSTD_compressBegin_usingCDict_internal(\n    ZSTD_CCtx* const cctx, const ZSTD_CDict* const cdict,\n    ZSTD_frameParameters const fParams, unsigned long long const pledgedSrcSize)\n{\n    ZSTD_CCtx_params cctxParams;\n    DEBUGLOG(4, \"ZSTD_compressBegin_usingCDict_internal\");\n    RETURN_ERROR_IF(cdict==NULL, dictionary_wrong, \"NULL pointer!\");\n     \n    {\n        ZSTD_parameters params;\n        params.fParams = fParams;\n        params.cParams = ( pledgedSrcSize < ZSTD_USE_CDICT_PARAMS_SRCSIZE_CUTOFF\n                        || pledgedSrcSize < cdict->dictContentSize * ZSTD_USE_CDICT_PARAMS_DICTSIZE_MULTIPLIER\n                        || pledgedSrcSize == ZSTD_CONTENTSIZE_UNKNOWN\n                        || cdict->compressionLevel == 0 ) ?\n                ZSTD_getCParamsFromCDict(cdict)\n              : ZSTD_getCParams(cdict->compressionLevel,\n                                pledgedSrcSize,\n                                cdict->dictContentSize);\n        ZSTD_CCtxParams_init_internal(&cctxParams, &params, cdict->compressionLevel);\n    }\n     \n    if (pledgedSrcSize != ZSTD_CONTENTSIZE_UNKNOWN) {\n        U32 const limitedSrcSize = (U32)MIN(pledgedSrcSize, 1U << 19);\n        U32 const limitedSrcLog = limitedSrcSize > 1 ? ZSTD_highbit32(limitedSrcSize - 1) + 1 : 1;\n        cctxParams.cParams.windowLog = MAX(cctxParams.cParams.windowLog, limitedSrcLog);\n    }\n    return ZSTD_compressBegin_internal(cctx,\n                                        NULL, 0, ZSTD_dct_auto, ZSTD_dtlm_fast,\n                                        cdict,\n                                        &cctxParams, pledgedSrcSize,\n                                        ZSTDb_not_buffered);\n}\n\n\n \nsize_t ZSTD_compressBegin_usingCDict_advanced(\n    ZSTD_CCtx* const cctx, const ZSTD_CDict* const cdict,\n    ZSTD_frameParameters const fParams, unsigned long long const pledgedSrcSize)\n{\n    return ZSTD_compressBegin_usingCDict_internal(cctx, cdict, fParams, pledgedSrcSize);\n}\n\n \nsize_t ZSTD_compressBegin_usingCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict)\n{\n    ZSTD_frameParameters const fParams = { 0  , 0  , 0   };\n    return ZSTD_compressBegin_usingCDict_internal(cctx, cdict, fParams, ZSTD_CONTENTSIZE_UNKNOWN);\n}\n\n \nstatic size_t ZSTD_compress_usingCDict_internal(ZSTD_CCtx* cctx,\n                                void* dst, size_t dstCapacity,\n                                const void* src, size_t srcSize,\n                                const ZSTD_CDict* cdict, ZSTD_frameParameters fParams)\n{\n    FORWARD_IF_ERROR(ZSTD_compressBegin_usingCDict_internal(cctx, cdict, fParams, srcSize), \"\");  \n    return ZSTD_compressEnd(cctx, dst, dstCapacity, src, srcSize);\n}\n\n \nsize_t ZSTD_compress_usingCDict_advanced(ZSTD_CCtx* cctx,\n                                void* dst, size_t dstCapacity,\n                                const void* src, size_t srcSize,\n                                const ZSTD_CDict* cdict, ZSTD_frameParameters fParams)\n{\n    return ZSTD_compress_usingCDict_internal(cctx, dst, dstCapacity, src, srcSize, cdict, fParams);\n}\n\n \nsize_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,\n                                void* dst, size_t dstCapacity,\n                                const void* src, size_t srcSize,\n                                const ZSTD_CDict* cdict)\n{\n    ZSTD_frameParameters const fParams = { 1  , 0  , 0   };\n    return ZSTD_compress_usingCDict_internal(cctx, dst, dstCapacity, src, srcSize, cdict, fParams);\n}\n\n\n\n \n\nZSTD_CStream* ZSTD_createCStream(void)\n{\n    DEBUGLOG(3, \"ZSTD_createCStream\");\n    return ZSTD_createCStream_advanced(ZSTD_defaultCMem);\n}\n\nZSTD_CStream* ZSTD_initStaticCStream(void *workspace, size_t workspaceSize)\n{\n    return ZSTD_initStaticCCtx(workspace, workspaceSize);\n}\n\nZSTD_CStream* ZSTD_createCStream_advanced(ZSTD_customMem customMem)\n{    \n    return ZSTD_createCCtx_advanced(customMem);\n}\n\nsize_t ZSTD_freeCStream(ZSTD_CStream* zcs)\n{\n    return ZSTD_freeCCtx(zcs);    \n}\n\n\n\n \n\nsize_t ZSTD_CStreamInSize(void)  { return ZSTD_BLOCKSIZE_MAX; }\n\nsize_t ZSTD_CStreamOutSize(void)\n{\n    return ZSTD_compressBound(ZSTD_BLOCKSIZE_MAX) + ZSTD_blockHeaderSize + 4   ;\n}\n\nstatic ZSTD_cParamMode_e ZSTD_getCParamMode(ZSTD_CDict const* cdict, ZSTD_CCtx_params const* params, U64 pledgedSrcSize)\n{\n    if (cdict != NULL && ZSTD_shouldAttachDict(cdict, params, pledgedSrcSize))\n        return ZSTD_cpm_attachDict;\n    else\n        return ZSTD_cpm_noAttachDict;\n}\n\n \nsize_t ZSTD_resetCStream(ZSTD_CStream* zcs, unsigned long long pss)\n{\n     \n    U64 const pledgedSrcSize = (pss==0) ? ZSTD_CONTENTSIZE_UNKNOWN : pss;\n    DEBUGLOG(4, \"ZSTD_resetCStream: pledgedSrcSize = %u\", (unsigned)pledgedSrcSize);\n    FORWARD_IF_ERROR( ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize) , \"\");\n    return 0;\n}\n\n \nsize_t ZSTD_initCStream_internal(ZSTD_CStream* zcs,\n                    const void* dict, size_t dictSize, const ZSTD_CDict* cdict,\n                    const ZSTD_CCtx_params* params,\n                    unsigned long long pledgedSrcSize)\n{\n    DEBUGLOG(4, \"ZSTD_initCStream_internal\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize) , \"\");\n    assert(!ZSTD_isError(ZSTD_checkCParams(params->cParams)));\n    zcs->requestedParams = *params;\n    assert(!((dict) && (cdict)));   \n    if (dict) {\n        FORWARD_IF_ERROR( ZSTD_CCtx_loadDictionary(zcs, dict, dictSize) , \"\");\n    } else {\n         \n        FORWARD_IF_ERROR( ZSTD_CCtx_refCDict(zcs, cdict) , \"\");\n    }\n    return 0;\n}\n\n \nsize_t ZSTD_initCStream_usingCDict_advanced(ZSTD_CStream* zcs,\n                                            const ZSTD_CDict* cdict,\n                                            ZSTD_frameParameters fParams,\n                                            unsigned long long pledgedSrcSize)\n{\n    DEBUGLOG(4, \"ZSTD_initCStream_usingCDict_advanced\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize) , \"\");\n    zcs->requestedParams.fParams = fParams;\n    FORWARD_IF_ERROR( ZSTD_CCtx_refCDict(zcs, cdict) , \"\");\n    return 0;\n}\n\n \nsize_t ZSTD_initCStream_usingCDict(ZSTD_CStream* zcs, const ZSTD_CDict* cdict)\n{\n    DEBUGLOG(4, \"ZSTD_initCStream_usingCDict\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_refCDict(zcs, cdict) , \"\");\n    return 0;\n}\n\n\n \nsize_t ZSTD_initCStream_advanced(ZSTD_CStream* zcs,\n                                 const void* dict, size_t dictSize,\n                                 ZSTD_parameters params, unsigned long long pss)\n{\n     \n    U64 const pledgedSrcSize = (pss==0 && params.fParams.contentSizeFlag==0) ? ZSTD_CONTENTSIZE_UNKNOWN : pss;\n    DEBUGLOG(4, \"ZSTD_initCStream_advanced\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize) , \"\");\n    FORWARD_IF_ERROR( ZSTD_checkCParams(params.cParams) , \"\");\n    ZSTD_CCtxParams_setZstdParams(&zcs->requestedParams, &params);\n    FORWARD_IF_ERROR( ZSTD_CCtx_loadDictionary(zcs, dict, dictSize) , \"\");\n    return 0;\n}\n\nsize_t ZSTD_initCStream_usingDict(ZSTD_CStream* zcs, const void* dict, size_t dictSize, int compressionLevel)\n{\n    DEBUGLOG(4, \"ZSTD_initCStream_usingDict\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_loadDictionary(zcs, dict, dictSize) , \"\");\n    return 0;\n}\n\nsize_t ZSTD_initCStream_srcSize(ZSTD_CStream* zcs, int compressionLevel, unsigned long long pss)\n{\n     \n    U64 const pledgedSrcSize = (pss==0) ? ZSTD_CONTENTSIZE_UNKNOWN : pss;\n    DEBUGLOG(4, \"ZSTD_initCStream_srcSize\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_refCDict(zcs, NULL) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize) , \"\");\n    return 0;\n}\n\nsize_t ZSTD_initCStream(ZSTD_CStream* zcs, int compressionLevel)\n{\n    DEBUGLOG(4, \"ZSTD_initCStream\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_refCDict(zcs, NULL) , \"\");\n    FORWARD_IF_ERROR( ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel) , \"\");\n    return 0;\n}\n\n \n\nstatic size_t ZSTD_nextInputSizeHint(const ZSTD_CCtx* cctx)\n{\n    size_t hintInSize = cctx->inBuffTarget - cctx->inBuffPos;\n    if (hintInSize==0) hintInSize = cctx->blockSize;\n    return hintInSize;\n}\n\n \nstatic size_t ZSTD_compressStream_generic(ZSTD_CStream* zcs,\n                                          ZSTD_outBuffer* output,\n                                          ZSTD_inBuffer* input,\n                                          ZSTD_EndDirective const flushMode)\n{\n    const char* const istart = (const char*)input->src;\n    const char* const iend = input->size != 0 ? istart + input->size : istart;\n    const char* ip = input->pos != 0 ? istart + input->pos : istart;\n    char* const ostart = (char*)output->dst;\n    char* const oend = output->size != 0 ? ostart + output->size : ostart;\n    char* op = output->pos != 0 ? ostart + output->pos : ostart;\n    U32 someMoreWork = 1;\n\n     \n    DEBUGLOG(5, \"ZSTD_compressStream_generic, flush=%u\", (unsigned)flushMode);\n    if (zcs->appliedParams.inBufferMode == ZSTD_bm_buffered) {\n        assert(zcs->inBuff != NULL);\n        assert(zcs->inBuffSize > 0);\n    }\n    if (zcs->appliedParams.outBufferMode == ZSTD_bm_buffered) {\n        assert(zcs->outBuff !=  NULL);\n        assert(zcs->outBuffSize > 0);\n    }\n    assert(output->pos <= output->size);\n    assert(input->pos <= input->size);\n    assert((U32)flushMode <= (U32)ZSTD_e_end);\n\n    while (someMoreWork) {\n        switch(zcs->streamStage)\n        {\n        case zcss_init:\n            RETURN_ERROR(init_missing, \"call ZSTD_initCStream() first!\");\n\n        case zcss_load:\n            if ( (flushMode == ZSTD_e_end)\n              && ( (size_t)(oend-op) >= ZSTD_compressBound(iend-ip)      \n                || zcs->appliedParams.outBufferMode == ZSTD_bm_stable)   \n              && (zcs->inBuffPos == 0) ) {\n                 \n                size_t const cSize = ZSTD_compressEnd(zcs,\n                                                op, oend-op, ip, iend-ip);\n                DEBUGLOG(4, \"ZSTD_compressEnd : cSize=%u\", (unsigned)cSize);\n                FORWARD_IF_ERROR(cSize, \"ZSTD_compressEnd failed\");\n                ip = iend;\n                op += cSize;\n                zcs->frameEnded = 1;\n                ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);\n                someMoreWork = 0; break;\n            }\n             \n            if (zcs->appliedParams.inBufferMode == ZSTD_bm_buffered) {\n                size_t const toLoad = zcs->inBuffTarget - zcs->inBuffPos;\n                size_t const loaded = ZSTD_limitCopy(\n                                        zcs->inBuff + zcs->inBuffPos, toLoad,\n                                        ip, iend-ip);\n                zcs->inBuffPos += loaded;\n                if (loaded != 0)\n                    ip += loaded;\n                if ( (flushMode == ZSTD_e_continue)\n                  && (zcs->inBuffPos < zcs->inBuffTarget) ) {\n                     \n                    someMoreWork = 0; break;\n                }\n                if ( (flushMode == ZSTD_e_flush)\n                  && (zcs->inBuffPos == zcs->inToCompress) ) {\n                     \n                    someMoreWork = 0; break;\n                }\n            }\n             \n            DEBUGLOG(5, \"stream compression stage (flushMode==%u)\", flushMode);\n            {   int const inputBuffered = (zcs->appliedParams.inBufferMode == ZSTD_bm_buffered);\n                void* cDst;\n                size_t cSize;\n                size_t oSize = oend-op;\n                size_t const iSize = inputBuffered\n                    ? zcs->inBuffPos - zcs->inToCompress\n                    : MIN((size_t)(iend - ip), zcs->blockSize);\n                if (oSize >= ZSTD_compressBound(iSize) || zcs->appliedParams.outBufferMode == ZSTD_bm_stable)\n                    cDst = op;    \n                else\n                    cDst = zcs->outBuff, oSize = zcs->outBuffSize;\n                if (inputBuffered) {\n                    unsigned const lastBlock = (flushMode == ZSTD_e_end) && (ip==iend);\n                    cSize = lastBlock ?\n                            ZSTD_compressEnd(zcs, cDst, oSize,\n                                        zcs->inBuff + zcs->inToCompress, iSize) :\n                            ZSTD_compressContinue(zcs, cDst, oSize,\n                                        zcs->inBuff + zcs->inToCompress, iSize);\n                    FORWARD_IF_ERROR(cSize, \"%s\", lastBlock ? \"ZSTD_compressEnd failed\" : \"ZSTD_compressContinue failed\");\n                    zcs->frameEnded = lastBlock;\n                     \n                    zcs->inBuffTarget = zcs->inBuffPos + zcs->blockSize;\n                    if (zcs->inBuffTarget > zcs->inBuffSize)\n                        zcs->inBuffPos = 0, zcs->inBuffTarget = zcs->blockSize;\n                    DEBUGLOG(5, \"inBuffTarget:%u / inBuffSize:%u\",\n                            (unsigned)zcs->inBuffTarget, (unsigned)zcs->inBuffSize);\n                    if (!lastBlock)\n                        assert(zcs->inBuffTarget <= zcs->inBuffSize);\n                    zcs->inToCompress = zcs->inBuffPos;\n                } else {\n                    unsigned const lastBlock = (ip + iSize == iend);\n                    assert(flushMode == ZSTD_e_end  );\n                    cSize = lastBlock ?\n                            ZSTD_compressEnd(zcs, cDst, oSize, ip, iSize) :\n                            ZSTD_compressContinue(zcs, cDst, oSize, ip, iSize);\n                     \n                    if (iSize > 0)\n                        ip += iSize;\n                    FORWARD_IF_ERROR(cSize, \"%s\", lastBlock ? \"ZSTD_compressEnd failed\" : \"ZSTD_compressContinue failed\");\n                    zcs->frameEnded = lastBlock;\n                    if (lastBlock)\n                        assert(ip == iend);\n                }\n                if (cDst == op) {   \n                    op += cSize;\n                    if (zcs->frameEnded) {\n                        DEBUGLOG(5, \"Frame completed directly in outBuffer\");\n                        someMoreWork = 0;\n                        ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);\n                    }\n                    break;\n                }\n                zcs->outBuffContentSize = cSize;\n                zcs->outBuffFlushedSize = 0;\n                zcs->streamStage = zcss_flush;  \n            }\n\t    ZSTD_FALLTHROUGH;\n        case zcss_flush:\n            DEBUGLOG(5, \"flush stage\");\n            assert(zcs->appliedParams.outBufferMode == ZSTD_bm_buffered);\n            {   size_t const toFlush = zcs->outBuffContentSize - zcs->outBuffFlushedSize;\n                size_t const flushed = ZSTD_limitCopy(op, (size_t)(oend-op),\n                            zcs->outBuff + zcs->outBuffFlushedSize, toFlush);\n                DEBUGLOG(5, \"toFlush: %u into %u ==> flushed: %u\",\n                            (unsigned)toFlush, (unsigned)(oend-op), (unsigned)flushed);\n                if (flushed)\n                    op += flushed;\n                zcs->outBuffFlushedSize += flushed;\n                if (toFlush!=flushed) {\n                     \n                    assert(op==oend);\n                    someMoreWork = 0;\n                    break;\n                }\n                zcs->outBuffContentSize = zcs->outBuffFlushedSize = 0;\n                if (zcs->frameEnded) {\n                    DEBUGLOG(5, \"Frame completed on flush\");\n                    someMoreWork = 0;\n                    ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);\n                    break;\n                }\n                zcs->streamStage = zcss_load;\n                break;\n            }\n\n        default:  \n            assert(0);\n        }\n    }\n\n    input->pos = ip - istart;\n    output->pos = op - ostart;\n    if (zcs->frameEnded) return 0;\n    return ZSTD_nextInputSizeHint(zcs);\n}\n\nstatic size_t ZSTD_nextInputSizeHint_MTorST(const ZSTD_CCtx* cctx)\n{\n    return ZSTD_nextInputSizeHint(cctx);\n\n}\n\nsize_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input)\n{\n    FORWARD_IF_ERROR( ZSTD_compressStream2(zcs, output, input, ZSTD_e_continue) , \"\");\n    return ZSTD_nextInputSizeHint_MTorST(zcs);\n}\n\n \nstatic void ZSTD_setBufferExpectations(ZSTD_CCtx* cctx, ZSTD_outBuffer const* output, ZSTD_inBuffer const* input)\n{\n    if (cctx->appliedParams.inBufferMode == ZSTD_bm_stable) {\n        cctx->expectedInBuffer = *input;\n    }\n    if (cctx->appliedParams.outBufferMode == ZSTD_bm_stable) {\n        cctx->expectedOutBufferSize = output->size - output->pos;\n    }\n}\n\n \nstatic size_t ZSTD_checkBufferStability(ZSTD_CCtx const* cctx,\n                                        ZSTD_outBuffer const* output,\n                                        ZSTD_inBuffer const* input,\n                                        ZSTD_EndDirective endOp)\n{\n    if (cctx->appliedParams.inBufferMode == ZSTD_bm_stable) {\n        ZSTD_inBuffer const expect = cctx->expectedInBuffer;\n        if (expect.src != input->src || expect.pos != input->pos || expect.size != input->size)\n            RETURN_ERROR(srcBuffer_wrong, \"ZSTD_c_stableInBuffer enabled but input differs!\");\n        if (endOp != ZSTD_e_end)\n            RETURN_ERROR(srcBuffer_wrong, \"ZSTD_c_stableInBuffer can only be used with ZSTD_e_end!\");\n    }\n    if (cctx->appliedParams.outBufferMode == ZSTD_bm_stable) {\n        size_t const outBufferSize = output->size - output->pos;\n        if (cctx->expectedOutBufferSize != outBufferSize)\n            RETURN_ERROR(dstBuffer_wrong, \"ZSTD_c_stableOutBuffer enabled but output size differs!\");\n    }\n    return 0;\n}\n\nstatic size_t ZSTD_CCtx_init_compressStream2(ZSTD_CCtx* cctx,\n                                             ZSTD_EndDirective endOp,\n                                             size_t inSize) {\n    ZSTD_CCtx_params params = cctx->requestedParams;\n    ZSTD_prefixDict const prefixDict = cctx->prefixDict;\n    FORWARD_IF_ERROR( ZSTD_initLocalDict(cctx) , \"\");  \n    ZSTD_memset(&cctx->prefixDict, 0, sizeof(cctx->prefixDict));    \n    assert(prefixDict.dict==NULL || cctx->cdict==NULL);     \n    if (cctx->cdict && !cctx->localDict.cdict) {\n         \n        params.compressionLevel = cctx->cdict->compressionLevel;\n    }\n    DEBUGLOG(4, \"ZSTD_compressStream2 : transparent init stage\");\n    if (endOp == ZSTD_e_end) cctx->pledgedSrcSizePlusOne = inSize + 1;   \n    {\n        size_t const dictSize = prefixDict.dict\n                ? prefixDict.dictSize\n                : (cctx->cdict ? cctx->cdict->dictContentSize : 0);\n        ZSTD_cParamMode_e const mode = ZSTD_getCParamMode(cctx->cdict, &params, cctx->pledgedSrcSizePlusOne - 1);\n        params.cParams = ZSTD_getCParamsFromCCtxParams(\n                &params, cctx->pledgedSrcSizePlusOne-1,\n                dictSize, mode);\n    }\n\n    params.useBlockSplitter = ZSTD_resolveBlockSplitterMode(params.useBlockSplitter, &params.cParams);\n    params.ldmParams.enableLdm = ZSTD_resolveEnableLdm(params.ldmParams.enableLdm, &params.cParams);\n    params.useRowMatchFinder = ZSTD_resolveRowMatchFinderMode(params.useRowMatchFinder, &params.cParams);\n\n    {   U64 const pledgedSrcSize = cctx->pledgedSrcSizePlusOne - 1;\n        assert(!ZSTD_isError(ZSTD_checkCParams(params.cParams)));\n        FORWARD_IF_ERROR( ZSTD_compressBegin_internal(cctx,\n                prefixDict.dict, prefixDict.dictSize, prefixDict.dictContentType, ZSTD_dtlm_fast,\n                cctx->cdict,\n                &params, pledgedSrcSize,\n                ZSTDb_buffered) , \"\");\n        assert(cctx->appliedParams.nbWorkers == 0);\n        cctx->inToCompress = 0;\n        cctx->inBuffPos = 0;\n        if (cctx->appliedParams.inBufferMode == ZSTD_bm_buffered) {\n             \n            cctx->inBuffTarget = cctx->blockSize + (cctx->blockSize == pledgedSrcSize);\n        } else {\n            cctx->inBuffTarget = 0;\n        }\n        cctx->outBuffContentSize = cctx->outBuffFlushedSize = 0;\n        cctx->streamStage = zcss_load;\n        cctx->frameEnded = 0;\n    }\n    return 0;\n}\n\nsize_t ZSTD_compressStream2( ZSTD_CCtx* cctx,\n                             ZSTD_outBuffer* output,\n                             ZSTD_inBuffer* input,\n                             ZSTD_EndDirective endOp)\n{\n    DEBUGLOG(5, \"ZSTD_compressStream2, endOp=%u \", (unsigned)endOp);\n     \n    RETURN_ERROR_IF(output->pos > output->size, dstSize_tooSmall, \"invalid output buffer\");\n    RETURN_ERROR_IF(input->pos  > input->size, srcSize_wrong, \"invalid input buffer\");\n    RETURN_ERROR_IF((U32)endOp > (U32)ZSTD_e_end, parameter_outOfBound, \"invalid endDirective\");\n    assert(cctx != NULL);\n\n     \n    if (cctx->streamStage == zcss_init) {\n        FORWARD_IF_ERROR(ZSTD_CCtx_init_compressStream2(cctx, endOp, input->size), \"CompressStream2 initialization failed\");\n        ZSTD_setBufferExpectations(cctx, output, input);     \n    }\n     \n\n    FORWARD_IF_ERROR(ZSTD_checkBufferStability(cctx, output, input, endOp), \"invalid buffers\");\n     \n    FORWARD_IF_ERROR( ZSTD_compressStream_generic(cctx, output, input, endOp) , \"\");\n    DEBUGLOG(5, \"completed ZSTD_compressStream2\");\n    ZSTD_setBufferExpectations(cctx, output, input);\n    return cctx->outBuffContentSize - cctx->outBuffFlushedSize;  \n}\n\nsize_t ZSTD_compressStream2_simpleArgs (\n                            ZSTD_CCtx* cctx,\n                            void* dst, size_t dstCapacity, size_t* dstPos,\n                      const void* src, size_t srcSize, size_t* srcPos,\n                            ZSTD_EndDirective endOp)\n{\n    ZSTD_outBuffer output = { dst, dstCapacity, *dstPos };\n    ZSTD_inBuffer  input  = { src, srcSize, *srcPos };\n     \n    size_t const cErr = ZSTD_compressStream2(cctx, &output, &input, endOp);\n    *dstPos = output.pos;\n    *srcPos = input.pos;\n    return cErr;\n}\n\nsize_t ZSTD_compress2(ZSTD_CCtx* cctx,\n                      void* dst, size_t dstCapacity,\n                      const void* src, size_t srcSize)\n{\n    ZSTD_bufferMode_e const originalInBufferMode = cctx->requestedParams.inBufferMode;\n    ZSTD_bufferMode_e const originalOutBufferMode = cctx->requestedParams.outBufferMode;\n    DEBUGLOG(4, \"ZSTD_compress2 (srcSize=%u)\", (unsigned)srcSize);\n    ZSTD_CCtx_reset(cctx, ZSTD_reset_session_only);\n     \n    cctx->requestedParams.inBufferMode = ZSTD_bm_stable;\n    cctx->requestedParams.outBufferMode = ZSTD_bm_stable;\n    {   size_t oPos = 0;\n        size_t iPos = 0;\n        size_t const result = ZSTD_compressStream2_simpleArgs(cctx,\n                                        dst, dstCapacity, &oPos,\n                                        src, srcSize, &iPos,\n                                        ZSTD_e_end);\n         \n        cctx->requestedParams.inBufferMode = originalInBufferMode;\n        cctx->requestedParams.outBufferMode = originalOutBufferMode;\n        FORWARD_IF_ERROR(result, \"ZSTD_compressStream2_simpleArgs failed\");\n        if (result != 0) {   \n            assert(oPos == dstCapacity);\n            RETURN_ERROR(dstSize_tooSmall, \"\");\n        }\n        assert(iPos == srcSize);    \n        return oPos;\n    }\n}\n\ntypedef struct {\n    U32 idx;              \n    U32 posInSequence;    \n    size_t posInSrc;         \n} ZSTD_sequencePosition;\n\n \nstatic size_t\nZSTD_validateSequence(U32 offCode, U32 matchLength,\n                      size_t posInSrc, U32 windowLog, size_t dictSize)\n{\n    U32 const windowSize = 1 << windowLog;\n     \n    size_t const offsetBound = posInSrc > windowSize ? (size_t)windowSize : posInSrc + (size_t)dictSize;\n    RETURN_ERROR_IF(offCode > STORE_OFFSET(offsetBound), corruption_detected, \"Offset too large!\");\n    RETURN_ERROR_IF(matchLength < MINMATCH, corruption_detected, \"Matchlength too small\");\n    return 0;\n}\n\n \nstatic U32 ZSTD_finalizeOffCode(U32 rawOffset, const U32 rep[ZSTD_REP_NUM], U32 ll0)\n{\n    U32 offCode = STORE_OFFSET(rawOffset);\n\n    if (!ll0 && rawOffset == rep[0]) {\n        offCode = STORE_REPCODE_1;\n    } else if (rawOffset == rep[1]) {\n        offCode = STORE_REPCODE(2 - ll0);\n    } else if (rawOffset == rep[2]) {\n        offCode = STORE_REPCODE(3 - ll0);\n    } else if (ll0 && rawOffset == rep[0] - 1) {\n        offCode = STORE_REPCODE_3;\n    }\n    return offCode;\n}\n\n \nstatic size_t\nZSTD_copySequencesToSeqStoreExplicitBlockDelim(ZSTD_CCtx* cctx,\n                                              ZSTD_sequencePosition* seqPos,\n                                        const ZSTD_Sequence* const inSeqs, size_t inSeqsSize,\n                                        const void* src, size_t blockSize)\n{\n    U32 idx = seqPos->idx;\n    BYTE const* ip = (BYTE const*)(src);\n    const BYTE* const iend = ip + blockSize;\n    repcodes_t updatedRepcodes;\n    U32 dictSize;\n\n    if (cctx->cdict) {\n        dictSize = (U32)cctx->cdict->dictContentSize;\n    } else if (cctx->prefixDict.dict) {\n        dictSize = (U32)cctx->prefixDict.dictSize;\n    } else {\n        dictSize = 0;\n    }\n    ZSTD_memcpy(updatedRepcodes.rep, cctx->blockState.prevCBlock->rep, sizeof(repcodes_t));\n    for (; (inSeqs[idx].matchLength != 0 || inSeqs[idx].offset != 0) && idx < inSeqsSize; ++idx) {\n        U32 const litLength = inSeqs[idx].litLength;\n        U32 const ll0 = (litLength == 0);\n        U32 const matchLength = inSeqs[idx].matchLength;\n        U32 const offCode = ZSTD_finalizeOffCode(inSeqs[idx].offset, updatedRepcodes.rep, ll0);\n        ZSTD_updateRep(updatedRepcodes.rep, offCode, ll0);\n\n        DEBUGLOG(6, \"Storing sequence: (of: %u, ml: %u, ll: %u)\", offCode, matchLength, litLength);\n        if (cctx->appliedParams.validateSequences) {\n            seqPos->posInSrc += litLength + matchLength;\n            FORWARD_IF_ERROR(ZSTD_validateSequence(offCode, matchLength, seqPos->posInSrc,\n                                                cctx->appliedParams.cParams.windowLog, dictSize),\n                                                \"Sequence validation failed\");\n        }\n        RETURN_ERROR_IF(idx - seqPos->idx > cctx->seqStore.maxNbSeq, memory_allocation,\n                        \"Not enough memory allocated. Try adjusting ZSTD_c_minMatch.\");\n        ZSTD_storeSeq(&cctx->seqStore, litLength, ip, iend, offCode, matchLength);\n        ip += matchLength + litLength;\n    }\n    ZSTD_memcpy(cctx->blockState.nextCBlock->rep, updatedRepcodes.rep, sizeof(repcodes_t));\n\n    if (inSeqs[idx].litLength) {\n        DEBUGLOG(6, \"Storing last literals of size: %u\", inSeqs[idx].litLength);\n        ZSTD_storeLastLiterals(&cctx->seqStore, ip, inSeqs[idx].litLength);\n        ip += inSeqs[idx].litLength;\n        seqPos->posInSrc += inSeqs[idx].litLength;\n    }\n    RETURN_ERROR_IF(ip != iend, corruption_detected, \"Blocksize doesn't agree with block delimiter!\");\n    seqPos->idx = idx+1;\n    return 0;\n}\n\n \nstatic size_t\nZSTD_copySequencesToSeqStoreNoBlockDelim(ZSTD_CCtx* cctx, ZSTD_sequencePosition* seqPos,\n                                   const ZSTD_Sequence* const inSeqs, size_t inSeqsSize,\n                                   const void* src, size_t blockSize)\n{\n    U32 idx = seqPos->idx;\n    U32 startPosInSequence = seqPos->posInSequence;\n    U32 endPosInSequence = seqPos->posInSequence + (U32)blockSize;\n    size_t dictSize;\n    BYTE const* ip = (BYTE const*)(src);\n    BYTE const* iend = ip + blockSize;   \n    repcodes_t updatedRepcodes;\n    U32 bytesAdjustment = 0;\n    U32 finalMatchSplit = 0;\n\n    if (cctx->cdict) {\n        dictSize = cctx->cdict->dictContentSize;\n    } else if (cctx->prefixDict.dict) {\n        dictSize = cctx->prefixDict.dictSize;\n    } else {\n        dictSize = 0;\n    }\n    DEBUGLOG(5, \"ZSTD_copySequencesToSeqStore: idx: %u PIS: %u blockSize: %zu\", idx, startPosInSequence, blockSize);\n    DEBUGLOG(5, \"Start seq: idx: %u (of: %u ml: %u ll: %u)\", idx, inSeqs[idx].offset, inSeqs[idx].matchLength, inSeqs[idx].litLength);\n    ZSTD_memcpy(updatedRepcodes.rep, cctx->blockState.prevCBlock->rep, sizeof(repcodes_t));\n    while (endPosInSequence && idx < inSeqsSize && !finalMatchSplit) {\n        const ZSTD_Sequence currSeq = inSeqs[idx];\n        U32 litLength = currSeq.litLength;\n        U32 matchLength = currSeq.matchLength;\n        U32 const rawOffset = currSeq.offset;\n        U32 offCode;\n\n         \n        if (endPosInSequence >= currSeq.litLength + currSeq.matchLength) {\n            if (startPosInSequence >= litLength) {\n                startPosInSequence -= litLength;\n                litLength = 0;\n                matchLength -= startPosInSequence;\n            } else {\n                litLength -= startPosInSequence;\n            }\n             \n            endPosInSequence -= currSeq.litLength + currSeq.matchLength;\n            startPosInSequence = 0;\n            idx++;\n        } else {\n             \n            DEBUGLOG(6, \"Require a split: diff: %u, idx: %u PIS: %u\",\n                     currSeq.litLength + currSeq.matchLength - endPosInSequence, idx, endPosInSequence);\n            if (endPosInSequence > litLength) {\n                U32 firstHalfMatchLength;\n                litLength = startPosInSequence >= litLength ? 0 : litLength - startPosInSequence;\n                firstHalfMatchLength = endPosInSequence - startPosInSequence - litLength;\n                if (matchLength > blockSize && firstHalfMatchLength >= cctx->appliedParams.cParams.minMatch) {\n                     \n                    U32 secondHalfMatchLength = currSeq.matchLength + currSeq.litLength - endPosInSequence;\n                    if (secondHalfMatchLength < cctx->appliedParams.cParams.minMatch) {\n                         \n                        endPosInSequence -= cctx->appliedParams.cParams.minMatch - secondHalfMatchLength;\n                        bytesAdjustment = cctx->appliedParams.cParams.minMatch - secondHalfMatchLength;\n                        firstHalfMatchLength -= bytesAdjustment;\n                    }\n                    matchLength = firstHalfMatchLength;\n                     \n                    finalMatchSplit = 1;\n                } else {\n                     \n                    bytesAdjustment = endPosInSequence - currSeq.litLength;\n                    endPosInSequence = currSeq.litLength;\n                    break;\n                }\n            } else {\n                 \n                break;\n            }\n        }\n         \n        {   U32 const ll0 = (litLength == 0);\n            offCode = ZSTD_finalizeOffCode(rawOffset, updatedRepcodes.rep, ll0);\n            ZSTD_updateRep(updatedRepcodes.rep, offCode, ll0);\n        }\n\n        if (cctx->appliedParams.validateSequences) {\n            seqPos->posInSrc += litLength + matchLength;\n            FORWARD_IF_ERROR(ZSTD_validateSequence(offCode, matchLength, seqPos->posInSrc,\n                                                   cctx->appliedParams.cParams.windowLog, dictSize),\n                                                   \"Sequence validation failed\");\n        }\n        DEBUGLOG(6, \"Storing sequence: (of: %u, ml: %u, ll: %u)\", offCode, matchLength, litLength);\n        RETURN_ERROR_IF(idx - seqPos->idx > cctx->seqStore.maxNbSeq, memory_allocation,\n                        \"Not enough memory allocated. Try adjusting ZSTD_c_minMatch.\");\n        ZSTD_storeSeq(&cctx->seqStore, litLength, ip, iend, offCode, matchLength);\n        ip += matchLength + litLength;\n    }\n    DEBUGLOG(5, \"Ending seq: idx: %u (of: %u ml: %u ll: %u)\", idx, inSeqs[idx].offset, inSeqs[idx].matchLength, inSeqs[idx].litLength);\n    assert(idx == inSeqsSize || endPosInSequence <= inSeqs[idx].litLength + inSeqs[idx].matchLength);\n    seqPos->idx = idx;\n    seqPos->posInSequence = endPosInSequence;\n    ZSTD_memcpy(cctx->blockState.nextCBlock->rep, updatedRepcodes.rep, sizeof(repcodes_t));\n\n    iend -= bytesAdjustment;\n    if (ip != iend) {\n         \n        U32 lastLLSize = (U32)(iend - ip);\n        assert(ip <= iend);\n        DEBUGLOG(6, \"Storing last literals of size: %u\", lastLLSize);\n        ZSTD_storeLastLiterals(&cctx->seqStore, ip, lastLLSize);\n        seqPos->posInSrc += lastLLSize;\n    }\n\n    return bytesAdjustment;\n}\n\ntypedef size_t (*ZSTD_sequenceCopier) (ZSTD_CCtx* cctx, ZSTD_sequencePosition* seqPos,\n                                       const ZSTD_Sequence* const inSeqs, size_t inSeqsSize,\n                                       const void* src, size_t blockSize);\nstatic ZSTD_sequenceCopier ZSTD_selectSequenceCopier(ZSTD_sequenceFormat_e mode)\n{\n    ZSTD_sequenceCopier sequenceCopier = NULL;\n    assert(ZSTD_cParam_withinBounds(ZSTD_c_blockDelimiters, mode));\n    if (mode == ZSTD_sf_explicitBlockDelimiters) {\n        return ZSTD_copySequencesToSeqStoreExplicitBlockDelim;\n    } else if (mode == ZSTD_sf_noBlockDelimiters) {\n        return ZSTD_copySequencesToSeqStoreNoBlockDelim;\n    }\n    assert(sequenceCopier != NULL);\n    return sequenceCopier;\n}\n\n \nstatic size_t\nZSTD_compressSequences_internal(ZSTD_CCtx* cctx,\n                                void* dst, size_t dstCapacity,\n                          const ZSTD_Sequence* inSeqs, size_t inSeqsSize,\n                          const void* src, size_t srcSize)\n{\n    size_t cSize = 0;\n    U32 lastBlock;\n    size_t blockSize;\n    size_t compressedSeqsSize;\n    size_t remaining = srcSize;\n    ZSTD_sequencePosition seqPos = {0, 0, 0};\n\n    BYTE const* ip = (BYTE const*)src;\n    BYTE* op = (BYTE*)dst;\n    ZSTD_sequenceCopier const sequenceCopier = ZSTD_selectSequenceCopier(cctx->appliedParams.blockDelimiters);\n\n    DEBUGLOG(4, \"ZSTD_compressSequences_internal srcSize: %zu, inSeqsSize: %zu\", srcSize, inSeqsSize);\n     \n    if (remaining == 0) {\n        U32 const cBlockHeader24 = 1   + (((U32)bt_raw)<<1);\n        RETURN_ERROR_IF(dstCapacity<4, dstSize_tooSmall, \"No room for empty frame block header\");\n        MEM_writeLE32(op, cBlockHeader24);\n        op += ZSTD_blockHeaderSize;\n        dstCapacity -= ZSTD_blockHeaderSize;\n        cSize += ZSTD_blockHeaderSize;\n    }\n\n    while (remaining) {\n        size_t cBlockSize;\n        size_t additionalByteAdjustment;\n        lastBlock = remaining <= cctx->blockSize;\n        blockSize = lastBlock ? (U32)remaining : (U32)cctx->blockSize;\n        ZSTD_resetSeqStore(&cctx->seqStore);\n        DEBUGLOG(4, \"Working on new block. Blocksize: %zu\", blockSize);\n\n        additionalByteAdjustment = sequenceCopier(cctx, &seqPos, inSeqs, inSeqsSize, ip, blockSize);\n        FORWARD_IF_ERROR(additionalByteAdjustment, \"Bad sequence copy\");\n        blockSize -= additionalByteAdjustment;\n\n         \n        if (blockSize < MIN_CBLOCK_SIZE+ZSTD_blockHeaderSize+1) {\n            cBlockSize = ZSTD_noCompressBlock(op, dstCapacity, ip, blockSize, lastBlock);\n            FORWARD_IF_ERROR(cBlockSize, \"Nocompress block failed\");\n            DEBUGLOG(4, \"Block too small, writing out nocompress block: cSize: %zu\", cBlockSize);\n            cSize += cBlockSize;\n            ip += blockSize;\n            op += cBlockSize;\n            remaining -= blockSize;\n            dstCapacity -= cBlockSize;\n            continue;\n        }\n\n        compressedSeqsSize = ZSTD_entropyCompressSeqStore(&cctx->seqStore,\n                                &cctx->blockState.prevCBlock->entropy, &cctx->blockState.nextCBlock->entropy,\n                                &cctx->appliedParams,\n                                op + ZSTD_blockHeaderSize  , dstCapacity - ZSTD_blockHeaderSize,\n                                blockSize,\n                                cctx->entropyWorkspace, ENTROPY_WORKSPACE_SIZE  ,\n                                cctx->bmi2);\n        FORWARD_IF_ERROR(compressedSeqsSize, \"Compressing sequences of block failed\");\n        DEBUGLOG(4, \"Compressed sequences size: %zu\", compressedSeqsSize);\n\n        if (!cctx->isFirstBlock &&\n            ZSTD_maybeRLE(&cctx->seqStore) &&\n            ZSTD_isRLE((BYTE const*)src, srcSize)) {\n             \n            compressedSeqsSize = 1;\n        }\n\n        if (compressedSeqsSize == 0) {\n             \n            cBlockSize = ZSTD_noCompressBlock(op, dstCapacity, ip, blockSize, lastBlock);\n            FORWARD_IF_ERROR(cBlockSize, \"Nocompress block failed\");\n            DEBUGLOG(4, \"Writing out nocompress block, size: %zu\", cBlockSize);\n        } else if (compressedSeqsSize == 1) {\n            cBlockSize = ZSTD_rleCompressBlock(op, dstCapacity, *ip, blockSize, lastBlock);\n            FORWARD_IF_ERROR(cBlockSize, \"RLE compress block failed\");\n            DEBUGLOG(4, \"Writing out RLE block, size: %zu\", cBlockSize);\n        } else {\n            U32 cBlockHeader;\n             \n            ZSTD_blockState_confirmRepcodesAndEntropyTables(&cctx->blockState);\n            if (cctx->blockState.prevCBlock->entropy.fse.offcode_repeatMode == FSE_repeat_valid)\n                cctx->blockState.prevCBlock->entropy.fse.offcode_repeatMode = FSE_repeat_check;\n\n             \n            cBlockHeader = lastBlock + (((U32)bt_compressed)<<1) + (U32)(compressedSeqsSize << 3);\n            MEM_writeLE24(op, cBlockHeader);\n            cBlockSize = ZSTD_blockHeaderSize + compressedSeqsSize;\n            DEBUGLOG(4, \"Writing out compressed block, size: %zu\", cBlockSize);\n        }\n\n        cSize += cBlockSize;\n        DEBUGLOG(4, \"cSize running total: %zu\", cSize);\n\n        if (lastBlock) {\n            break;\n        } else {\n            ip += blockSize;\n            op += cBlockSize;\n            remaining -= blockSize;\n            dstCapacity -= cBlockSize;\n            cctx->isFirstBlock = 0;\n        }\n    }\n\n    return cSize;\n}\n\nsize_t ZSTD_compressSequences(ZSTD_CCtx* const cctx, void* dst, size_t dstCapacity,\n                              const ZSTD_Sequence* inSeqs, size_t inSeqsSize,\n                              const void* src, size_t srcSize)\n{\n    BYTE* op = (BYTE*)dst;\n    size_t cSize = 0;\n    size_t compressedBlocksSize = 0;\n    size_t frameHeaderSize = 0;\n\n     \n    DEBUGLOG(3, \"ZSTD_compressSequences()\");\n    assert(cctx != NULL);\n    FORWARD_IF_ERROR(ZSTD_CCtx_init_compressStream2(cctx, ZSTD_e_end, srcSize), \"CCtx initialization failed\");\n     \n    frameHeaderSize = ZSTD_writeFrameHeader(op, dstCapacity, &cctx->appliedParams, srcSize, cctx->dictID);\n    op += frameHeaderSize;\n    dstCapacity -= frameHeaderSize;\n    cSize += frameHeaderSize;\n    if (cctx->appliedParams.fParams.checksumFlag && srcSize) {\n        xxh64_update(&cctx->xxhState, src, srcSize);\n    }\n     \n    compressedBlocksSize = ZSTD_compressSequences_internal(cctx,\n                                                           op, dstCapacity,\n                                                           inSeqs, inSeqsSize,\n                                                           src, srcSize);\n    FORWARD_IF_ERROR(compressedBlocksSize, \"Compressing blocks failed!\");\n    cSize += compressedBlocksSize;\n    dstCapacity -= compressedBlocksSize;\n\n    if (cctx->appliedParams.fParams.checksumFlag) {\n        U32 const checksum = (U32) xxh64_digest(&cctx->xxhState);\n        RETURN_ERROR_IF(dstCapacity<4, dstSize_tooSmall, \"no room for checksum\");\n        DEBUGLOG(4, \"Write checksum : %08X\", (unsigned)checksum);\n        MEM_writeLE32((char*)dst + cSize, checksum);\n        cSize += 4;\n    }\n\n    DEBUGLOG(3, \"Final compressed size: %zu\", cSize);\n    return cSize;\n}\n\n \n\n \nsize_t ZSTD_flushStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output)\n{\n    ZSTD_inBuffer input = { NULL, 0, 0 };\n    return ZSTD_compressStream2(zcs, output, &input, ZSTD_e_flush);\n}\n\n\nsize_t ZSTD_endStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output)\n{\n    ZSTD_inBuffer input = { NULL, 0, 0 };\n    size_t const remainingToFlush = ZSTD_compressStream2(zcs, output, &input, ZSTD_e_end);\n    FORWARD_IF_ERROR( remainingToFlush , \"ZSTD_compressStream2 failed\");\n    if (zcs->appliedParams.nbWorkers > 0) return remainingToFlush;    \n     \n    {   size_t const lastBlockSize = zcs->frameEnded ? 0 : ZSTD_BLOCKHEADERSIZE;\n        size_t const checksumSize = (size_t)(zcs->frameEnded ? 0 : zcs->appliedParams.fParams.checksumFlag * 4);\n        size_t const toFlush = remainingToFlush + lastBlockSize + checksumSize;\n        DEBUGLOG(4, \"ZSTD_endStream : remaining to flush : %u\", (unsigned)toFlush);\n        return toFlush;\n    }\n}\n\n\n \n#include \"clevels.h\"\n\nint ZSTD_maxCLevel(void) { return ZSTD_MAX_CLEVEL; }\nint ZSTD_minCLevel(void) { return (int)-ZSTD_TARGETLENGTH_MAX; }\nint ZSTD_defaultCLevel(void) { return ZSTD_CLEVEL_DEFAULT; }\n\nstatic ZSTD_compressionParameters ZSTD_dedicatedDictSearch_getCParams(int const compressionLevel, size_t const dictSize)\n{\n    ZSTD_compressionParameters cParams = ZSTD_getCParams_internal(compressionLevel, 0, dictSize, ZSTD_cpm_createCDict);\n    switch (cParams.strategy) {\n        case ZSTD_fast:\n        case ZSTD_dfast:\n            break;\n        case ZSTD_greedy:\n        case ZSTD_lazy:\n        case ZSTD_lazy2:\n            cParams.hashLog += ZSTD_LAZY_DDSS_BUCKET_LOG;\n            break;\n        case ZSTD_btlazy2:\n        case ZSTD_btopt:\n        case ZSTD_btultra:\n        case ZSTD_btultra2:\n            break;\n    }\n    return cParams;\n}\n\nstatic int ZSTD_dedicatedDictSearch_isSupported(\n        ZSTD_compressionParameters const* cParams)\n{\n    return (cParams->strategy >= ZSTD_greedy)\n        && (cParams->strategy <= ZSTD_lazy2)\n        && (cParams->hashLog > cParams->chainLog)\n        && (cParams->chainLog <= 24);\n}\n\n \nstatic void ZSTD_dedicatedDictSearch_revertCParams(\n        ZSTD_compressionParameters* cParams) {\n    switch (cParams->strategy) {\n        case ZSTD_fast:\n        case ZSTD_dfast:\n            break;\n        case ZSTD_greedy:\n        case ZSTD_lazy:\n        case ZSTD_lazy2:\n            cParams->hashLog -= ZSTD_LAZY_DDSS_BUCKET_LOG;\n            if (cParams->hashLog < ZSTD_HASHLOG_MIN) {\n                cParams->hashLog = ZSTD_HASHLOG_MIN;\n            }\n            break;\n        case ZSTD_btlazy2:\n        case ZSTD_btopt:\n        case ZSTD_btultra:\n        case ZSTD_btultra2:\n            break;\n    }\n}\n\nstatic U64 ZSTD_getCParamRowSize(U64 srcSizeHint, size_t dictSize, ZSTD_cParamMode_e mode)\n{\n    switch (mode) {\n    case ZSTD_cpm_unknown:\n    case ZSTD_cpm_noAttachDict:\n    case ZSTD_cpm_createCDict:\n        break;\n    case ZSTD_cpm_attachDict:\n        dictSize = 0;\n        break;\n    default:\n        assert(0);\n        break;\n    }\n    {   int const unknown = srcSizeHint == ZSTD_CONTENTSIZE_UNKNOWN;\n        size_t const addedSize = unknown && dictSize > 0 ? 500 : 0;\n        return unknown && dictSize == 0 ? ZSTD_CONTENTSIZE_UNKNOWN : srcSizeHint+dictSize+addedSize;\n    }\n}\n\n \nstatic ZSTD_compressionParameters ZSTD_getCParams_internal(int compressionLevel, unsigned long long srcSizeHint, size_t dictSize, ZSTD_cParamMode_e mode)\n{\n    U64 const rSize = ZSTD_getCParamRowSize(srcSizeHint, dictSize, mode);\n    U32 const tableID = (rSize <= 256 KB) + (rSize <= 128 KB) + (rSize <= 16 KB);\n    int row;\n    DEBUGLOG(5, \"ZSTD_getCParams_internal (cLevel=%i)\", compressionLevel);\n\n     \n    if (compressionLevel == 0) row = ZSTD_CLEVEL_DEFAULT;    \n    else if (compressionLevel < 0) row = 0;    \n    else if (compressionLevel > ZSTD_MAX_CLEVEL) row = ZSTD_MAX_CLEVEL;\n    else row = compressionLevel;\n\n    {   ZSTD_compressionParameters cp = ZSTD_defaultCParameters[tableID][row];\n        DEBUGLOG(5, \"ZSTD_getCParams_internal selected tableID: %u row: %u strat: %u\", tableID, row, (U32)cp.strategy);\n         \n        if (compressionLevel < 0) {\n            int const clampedCompressionLevel = MAX(ZSTD_minCLevel(), compressionLevel);\n            cp.targetLength = (unsigned)(-clampedCompressionLevel);\n        }\n         \n        return ZSTD_adjustCParams_internal(cp, srcSizeHint, dictSize, mode);\n    }\n}\n\n \nZSTD_compressionParameters ZSTD_getCParams(int compressionLevel, unsigned long long srcSizeHint, size_t dictSize)\n{\n    if (srcSizeHint == 0) srcSizeHint = ZSTD_CONTENTSIZE_UNKNOWN;\n    return ZSTD_getCParams_internal(compressionLevel, srcSizeHint, dictSize, ZSTD_cpm_unknown);\n}\n\n \nstatic ZSTD_parameters ZSTD_getParams_internal(int compressionLevel, unsigned long long srcSizeHint, size_t dictSize, ZSTD_cParamMode_e mode) {\n    ZSTD_parameters params;\n    ZSTD_compressionParameters const cParams = ZSTD_getCParams_internal(compressionLevel, srcSizeHint, dictSize, mode);\n    DEBUGLOG(5, \"ZSTD_getParams (cLevel=%i)\", compressionLevel);\n    ZSTD_memset(&params, 0, sizeof(params));\n    params.cParams = cParams;\n    params.fParams.contentSizeFlag = 1;\n    return params;\n}\n\n \nZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long srcSizeHint, size_t dictSize) {\n    if (srcSizeHint == 0) srcSizeHint = ZSTD_CONTENTSIZE_UNKNOWN;\n    return ZSTD_getParams_internal(compressionLevel, srcSizeHint, dictSize, ZSTD_cpm_unknown);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}