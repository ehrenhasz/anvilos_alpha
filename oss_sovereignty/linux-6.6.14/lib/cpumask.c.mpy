{
  "module_name": "cpumask.c",
  "hash_id": "1314774c62217d152c8352d9eb1090c0c4dc45b91de5e61e3d55a87e32facf4d",
  "original_prompt": "Ingested from linux-6.6.14/lib/cpumask.c",
  "human_readable_source": "\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/bitops.h>\n#include <linux/cpumask.h>\n#include <linux/export.h>\n#include <linux/memblock.h>\n#include <linux/numa.h>\n\n \nunsigned int cpumask_next_wrap(int n, const struct cpumask *mask, int start, bool wrap)\n{\n\tunsigned int next;\n\nagain:\n\tnext = cpumask_next(n, mask);\n\n\tif (wrap && n < start && next >= start) {\n\t\treturn nr_cpumask_bits;\n\n\t} else if (next >= nr_cpumask_bits) {\n\t\twrap = true;\n\t\tn = -1;\n\t\tgoto again;\n\t}\n\n\treturn next;\n}\nEXPORT_SYMBOL(cpumask_next_wrap);\n\n \n#ifdef CONFIG_CPUMASK_OFFSTACK\n \nbool alloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags, int node)\n{\n\t*mask = kmalloc_node(cpumask_size(), flags, node);\n\n#ifdef CONFIG_DEBUG_PER_CPU_MAPS\n\tif (!*mask) {\n\t\tprintk(KERN_ERR \"=> alloc_cpumask_var: failed!\\n\");\n\t\tdump_stack();\n\t}\n#endif\n\n\treturn *mask != NULL;\n}\nEXPORT_SYMBOL(alloc_cpumask_var_node);\n\n \nvoid __init alloc_bootmem_cpumask_var(cpumask_var_t *mask)\n{\n\t*mask = memblock_alloc(cpumask_size(), SMP_CACHE_BYTES);\n\tif (!*mask)\n\t\tpanic(\"%s: Failed to allocate %u bytes\\n\", __func__,\n\t\t      cpumask_size());\n}\n\n \nvoid free_cpumask_var(cpumask_var_t mask)\n{\n\tkfree(mask);\n}\nEXPORT_SYMBOL(free_cpumask_var);\n\n \nvoid __init free_bootmem_cpumask_var(cpumask_var_t mask)\n{\n\tmemblock_free(mask, cpumask_size());\n}\n#endif\n\n \nunsigned int cpumask_local_spread(unsigned int i, int node)\n{\n\tunsigned int cpu;\n\n\t \n\ti %= num_online_cpus();\n\n\tcpu = (node == NUMA_NO_NODE) ?\n\t\tcpumask_nth(i, cpu_online_mask) :\n\t\tsched_numa_find_nth_cpu(cpu_online_mask, i, node);\n\n\tWARN_ON(cpu >= nr_cpu_ids);\n\treturn cpu;\n}\nEXPORT_SYMBOL(cpumask_local_spread);\n\nstatic DEFINE_PER_CPU(int, distribute_cpu_mask_prev);\n\n \nunsigned int cpumask_any_and_distribute(const struct cpumask *src1p,\n\t\t\t       const struct cpumask *src2p)\n{\n\tunsigned int next, prev;\n\n\t \n\tprev = __this_cpu_read(distribute_cpu_mask_prev);\n\n\tnext = find_next_and_bit_wrap(cpumask_bits(src1p), cpumask_bits(src2p),\n\t\t\t\t\tnr_cpumask_bits, prev + 1);\n\tif (next < nr_cpu_ids)\n\t\t__this_cpu_write(distribute_cpu_mask_prev, next);\n\n\treturn next;\n}\nEXPORT_SYMBOL(cpumask_any_and_distribute);\n\nunsigned int cpumask_any_distribute(const struct cpumask *srcp)\n{\n\tunsigned int next, prev;\n\n\t \n\tprev = __this_cpu_read(distribute_cpu_mask_prev);\n\tnext = find_next_bit_wrap(cpumask_bits(srcp), nr_cpumask_bits, prev + 1);\n\tif (next < nr_cpu_ids)\n\t\t__this_cpu_write(distribute_cpu_mask_prev, next);\n\n\treturn next;\n}\nEXPORT_SYMBOL(cpumask_any_distribute);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}