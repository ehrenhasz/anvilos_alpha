{
  "module_name": "debugobjects.c",
  "hash_id": "09b46cbd5a371eed61c09e46b9793d3f5fcb4868c11e290a04634c648dd8e5df",
  "original_prompt": "Ingested from linux-6.6.14/lib/debugobjects.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"ODEBUG: \" fmt\n\n#include <linux/debugobjects.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/sched/task_stack.h>\n#include <linux/seq_file.h>\n#include <linux/debugfs.h>\n#include <linux/slab.h>\n#include <linux/hash.h>\n#include <linux/kmemleak.h>\n#include <linux/cpu.h>\n\n#define ODEBUG_HASH_BITS\t14\n#define ODEBUG_HASH_SIZE\t(1 << ODEBUG_HASH_BITS)\n\n#define ODEBUG_POOL_SIZE\t1024\n#define ODEBUG_POOL_MIN_LEVEL\t256\n#define ODEBUG_POOL_PERCPU_SIZE\t64\n#define ODEBUG_BATCH_SIZE\t16\n\n#define ODEBUG_CHUNK_SHIFT\tPAGE_SHIFT\n#define ODEBUG_CHUNK_SIZE\t(1 << ODEBUG_CHUNK_SHIFT)\n#define ODEBUG_CHUNK_MASK\t(~(ODEBUG_CHUNK_SIZE - 1))\n\n \n#define ODEBUG_FREE_WORK_MAX\t1024\n#define ODEBUG_FREE_WORK_DELAY\tDIV_ROUND_UP(HZ, 10)\n\nstruct debug_bucket {\n\tstruct hlist_head\tlist;\n\traw_spinlock_t\t\tlock;\n};\n\n \nstruct debug_percpu_free {\n\tstruct hlist_head\tfree_objs;\n\tint\t\t\tobj_free;\n};\n\nstatic DEFINE_PER_CPU(struct debug_percpu_free, percpu_obj_pool);\n\nstatic struct debug_bucket\tobj_hash[ODEBUG_HASH_SIZE];\n\nstatic struct debug_obj\t\tobj_static_pool[ODEBUG_POOL_SIZE] __initdata;\n\nstatic DEFINE_RAW_SPINLOCK(pool_lock);\n\nstatic HLIST_HEAD(obj_pool);\nstatic HLIST_HEAD(obj_to_free);\n\n \nstatic int\t\t\tobj_pool_min_free = ODEBUG_POOL_SIZE;\nstatic int\t\t\tobj_pool_free = ODEBUG_POOL_SIZE;\nstatic int\t\t\tobj_pool_used;\nstatic int\t\t\tobj_pool_max_used;\nstatic bool\t\t\tobj_freeing;\n \nstatic int\t\t\tobj_nr_tofree;\n\nstatic int\t\t\tdebug_objects_maxchain __read_mostly;\nstatic int __maybe_unused\tdebug_objects_maxchecked __read_mostly;\nstatic int\t\t\tdebug_objects_fixups __read_mostly;\nstatic int\t\t\tdebug_objects_warnings __read_mostly;\nstatic int\t\t\tdebug_objects_enabled __read_mostly\n\t\t\t\t= CONFIG_DEBUG_OBJECTS_ENABLE_DEFAULT;\nstatic int\t\t\tdebug_objects_pool_size __read_mostly\n\t\t\t\t= ODEBUG_POOL_SIZE;\nstatic int\t\t\tdebug_objects_pool_min_level __read_mostly\n\t\t\t\t= ODEBUG_POOL_MIN_LEVEL;\nstatic const struct debug_obj_descr *descr_test  __read_mostly;\nstatic struct kmem_cache\t*obj_cache __read_mostly;\n\n \nstatic int\t\t\tdebug_objects_allocated;\nstatic int\t\t\tdebug_objects_freed;\n\nstatic void free_obj_work(struct work_struct *work);\nstatic DECLARE_DELAYED_WORK(debug_obj_work, free_obj_work);\n\nstatic int __init enable_object_debug(char *str)\n{\n\tdebug_objects_enabled = 1;\n\treturn 0;\n}\n\nstatic int __init disable_object_debug(char *str)\n{\n\tdebug_objects_enabled = 0;\n\treturn 0;\n}\n\nearly_param(\"debug_objects\", enable_object_debug);\nearly_param(\"no_debug_objects\", disable_object_debug);\n\nstatic const char *obj_states[ODEBUG_STATE_MAX] = {\n\t[ODEBUG_STATE_NONE]\t\t= \"none\",\n\t[ODEBUG_STATE_INIT]\t\t= \"initialized\",\n\t[ODEBUG_STATE_INACTIVE]\t\t= \"inactive\",\n\t[ODEBUG_STATE_ACTIVE]\t\t= \"active\",\n\t[ODEBUG_STATE_DESTROYED]\t= \"destroyed\",\n\t[ODEBUG_STATE_NOTAVAILABLE]\t= \"not available\",\n};\n\nstatic void fill_pool(void)\n{\n\tgfp_t gfp = __GFP_HIGH | __GFP_NOWARN;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\n\tif (likely(READ_ONCE(obj_pool_free) >= debug_objects_pool_min_level))\n\t\treturn;\n\n\t \n\twhile (READ_ONCE(obj_nr_tofree) && (READ_ONCE(obj_pool_free) < obj_pool_min_free)) {\n\t\traw_spin_lock_irqsave(&pool_lock, flags);\n\t\t \n\t\twhile (obj_nr_tofree && (obj_pool_free < obj_pool_min_free)) {\n\t\t\tobj = hlist_entry(obj_to_free.first, typeof(*obj), node);\n\t\t\thlist_del(&obj->node);\n\t\t\tWRITE_ONCE(obj_nr_tofree, obj_nr_tofree - 1);\n\t\t\thlist_add_head(&obj->node, &obj_pool);\n\t\t\tWRITE_ONCE(obj_pool_free, obj_pool_free + 1);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&pool_lock, flags);\n\t}\n\n\tif (unlikely(!obj_cache))\n\t\treturn;\n\n\twhile (READ_ONCE(obj_pool_free) < debug_objects_pool_min_level) {\n\t\tstruct debug_obj *new[ODEBUG_BATCH_SIZE];\n\t\tint cnt;\n\n\t\tfor (cnt = 0; cnt < ODEBUG_BATCH_SIZE; cnt++) {\n\t\t\tnew[cnt] = kmem_cache_zalloc(obj_cache, gfp);\n\t\t\tif (!new[cnt])\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!cnt)\n\t\t\treturn;\n\n\t\traw_spin_lock_irqsave(&pool_lock, flags);\n\t\twhile (cnt) {\n\t\t\thlist_add_head(&new[--cnt]->node, &obj_pool);\n\t\t\tdebug_objects_allocated++;\n\t\t\tWRITE_ONCE(obj_pool_free, obj_pool_free + 1);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&pool_lock, flags);\n\t}\n}\n\n \nstatic struct debug_obj *lookup_object(void *addr, struct debug_bucket *b)\n{\n\tstruct debug_obj *obj;\n\tint cnt = 0;\n\n\thlist_for_each_entry(obj, &b->list, node) {\n\t\tcnt++;\n\t\tif (obj->object == addr)\n\t\t\treturn obj;\n\t}\n\tif (cnt > debug_objects_maxchain)\n\t\tdebug_objects_maxchain = cnt;\n\n\treturn NULL;\n}\n\n \nstatic struct debug_obj *__alloc_object(struct hlist_head *list)\n{\n\tstruct debug_obj *obj = NULL;\n\n\tif (list->first) {\n\t\tobj = hlist_entry(list->first, typeof(*obj), node);\n\t\thlist_del(&obj->node);\n\t}\n\n\treturn obj;\n}\n\nstatic struct debug_obj *\nalloc_object(void *addr, struct debug_bucket *b, const struct debug_obj_descr *descr)\n{\n\tstruct debug_percpu_free *percpu_pool = this_cpu_ptr(&percpu_obj_pool);\n\tstruct debug_obj *obj;\n\n\tif (likely(obj_cache)) {\n\t\tobj = __alloc_object(&percpu_pool->free_objs);\n\t\tif (obj) {\n\t\t\tpercpu_pool->obj_free--;\n\t\t\tgoto init_obj;\n\t\t}\n\t}\n\n\traw_spin_lock(&pool_lock);\n\tobj = __alloc_object(&obj_pool);\n\tif (obj) {\n\t\tobj_pool_used++;\n\t\tWRITE_ONCE(obj_pool_free, obj_pool_free - 1);\n\n\t\t \n\t\tif (likely(obj_cache)) {\n\t\t\tint i;\n\n\t\t\tfor (i = 0; i < ODEBUG_BATCH_SIZE; i++) {\n\t\t\t\tstruct debug_obj *obj2;\n\n\t\t\t\tobj2 = __alloc_object(&obj_pool);\n\t\t\t\tif (!obj2)\n\t\t\t\t\tbreak;\n\t\t\t\thlist_add_head(&obj2->node,\n\t\t\t\t\t       &percpu_pool->free_objs);\n\t\t\t\tpercpu_pool->obj_free++;\n\t\t\t\tobj_pool_used++;\n\t\t\t\tWRITE_ONCE(obj_pool_free, obj_pool_free - 1);\n\t\t\t}\n\t\t}\n\n\t\tif (obj_pool_used > obj_pool_max_used)\n\t\t\tobj_pool_max_used = obj_pool_used;\n\n\t\tif (obj_pool_free < obj_pool_min_free)\n\t\t\tobj_pool_min_free = obj_pool_free;\n\t}\n\traw_spin_unlock(&pool_lock);\n\ninit_obj:\n\tif (obj) {\n\t\tobj->object = addr;\n\t\tobj->descr  = descr;\n\t\tobj->state  = ODEBUG_STATE_NONE;\n\t\tobj->astate = 0;\n\t\thlist_add_head(&obj->node, &b->list);\n\t}\n\treturn obj;\n}\n\n \nstatic void free_obj_work(struct work_struct *work)\n{\n\tstruct hlist_node *tmp;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\tHLIST_HEAD(tofree);\n\n\tWRITE_ONCE(obj_freeing, false);\n\tif (!raw_spin_trylock_irqsave(&pool_lock, flags))\n\t\treturn;\n\n\tif (obj_pool_free >= debug_objects_pool_size)\n\t\tgoto free_objs;\n\n\t \n\twhile (obj_nr_tofree && obj_pool_free < debug_objects_pool_size) {\n\t\tobj = hlist_entry(obj_to_free.first, typeof(*obj), node);\n\t\thlist_del(&obj->node);\n\t\thlist_add_head(&obj->node, &obj_pool);\n\t\tWRITE_ONCE(obj_pool_free, obj_pool_free + 1);\n\t\tWRITE_ONCE(obj_nr_tofree, obj_nr_tofree - 1);\n\t}\n\traw_spin_unlock_irqrestore(&pool_lock, flags);\n\treturn;\n\nfree_objs:\n\t \n\tif (obj_nr_tofree) {\n\t\thlist_move_list(&obj_to_free, &tofree);\n\t\tdebug_objects_freed += obj_nr_tofree;\n\t\tWRITE_ONCE(obj_nr_tofree, 0);\n\t}\n\traw_spin_unlock_irqrestore(&pool_lock, flags);\n\n\thlist_for_each_entry_safe(obj, tmp, &tofree, node) {\n\t\thlist_del(&obj->node);\n\t\tkmem_cache_free(obj_cache, obj);\n\t}\n}\n\nstatic void __free_object(struct debug_obj *obj)\n{\n\tstruct debug_obj *objs[ODEBUG_BATCH_SIZE];\n\tstruct debug_percpu_free *percpu_pool;\n\tint lookahead_count = 0;\n\tunsigned long flags;\n\tbool work;\n\n\tlocal_irq_save(flags);\n\tif (!obj_cache)\n\t\tgoto free_to_obj_pool;\n\n\t \n\tpercpu_pool = this_cpu_ptr(&percpu_obj_pool);\n\tif (percpu_pool->obj_free < ODEBUG_POOL_PERCPU_SIZE) {\n\t\thlist_add_head(&obj->node, &percpu_pool->free_objs);\n\t\tpercpu_pool->obj_free++;\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\n\t \n\tfor (; lookahead_count < ODEBUG_BATCH_SIZE; lookahead_count++) {\n\t\tobjs[lookahead_count] = __alloc_object(&percpu_pool->free_objs);\n\t\tif (!objs[lookahead_count])\n\t\t\tbreak;\n\t\tpercpu_pool->obj_free--;\n\t}\n\nfree_to_obj_pool:\n\traw_spin_lock(&pool_lock);\n\twork = (obj_pool_free > debug_objects_pool_size) && obj_cache &&\n\t       (obj_nr_tofree < ODEBUG_FREE_WORK_MAX);\n\tobj_pool_used--;\n\n\tif (work) {\n\t\tWRITE_ONCE(obj_nr_tofree, obj_nr_tofree + 1);\n\t\thlist_add_head(&obj->node, &obj_to_free);\n\t\tif (lookahead_count) {\n\t\t\tWRITE_ONCE(obj_nr_tofree, obj_nr_tofree + lookahead_count);\n\t\t\tobj_pool_used -= lookahead_count;\n\t\t\twhile (lookahead_count) {\n\t\t\t\thlist_add_head(&objs[--lookahead_count]->node,\n\t\t\t\t\t       &obj_to_free);\n\t\t\t}\n\t\t}\n\n\t\tif ((obj_pool_free > debug_objects_pool_size) &&\n\t\t    (obj_nr_tofree < ODEBUG_FREE_WORK_MAX)) {\n\t\t\tint i;\n\n\t\t\t \n\t\t\tfor (i = 0; i < ODEBUG_BATCH_SIZE; i++) {\n\t\t\t\tobj = __alloc_object(&obj_pool);\n\t\t\t\thlist_add_head(&obj->node, &obj_to_free);\n\t\t\t\tWRITE_ONCE(obj_pool_free, obj_pool_free - 1);\n\t\t\t\tWRITE_ONCE(obj_nr_tofree, obj_nr_tofree + 1);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tWRITE_ONCE(obj_pool_free, obj_pool_free + 1);\n\t\thlist_add_head(&obj->node, &obj_pool);\n\t\tif (lookahead_count) {\n\t\t\tWRITE_ONCE(obj_pool_free, obj_pool_free + lookahead_count);\n\t\t\tobj_pool_used -= lookahead_count;\n\t\t\twhile (lookahead_count) {\n\t\t\t\thlist_add_head(&objs[--lookahead_count]->node,\n\t\t\t\t\t       &obj_pool);\n\t\t\t}\n\t\t}\n\t}\n\traw_spin_unlock(&pool_lock);\n\tlocal_irq_restore(flags);\n}\n\n \nstatic void free_object(struct debug_obj *obj)\n{\n\t__free_object(obj);\n\tif (!READ_ONCE(obj_freeing) && READ_ONCE(obj_nr_tofree)) {\n\t\tWRITE_ONCE(obj_freeing, true);\n\t\tschedule_delayed_work(&debug_obj_work, ODEBUG_FREE_WORK_DELAY);\n\t}\n}\n\n#ifdef CONFIG_HOTPLUG_CPU\nstatic int object_cpu_offline(unsigned int cpu)\n{\n\tstruct debug_percpu_free *percpu_pool;\n\tstruct hlist_node *tmp;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\n\t \n\tpercpu_pool = per_cpu_ptr(&percpu_obj_pool, cpu);\n\thlist_for_each_entry_safe(obj, tmp, &percpu_pool->free_objs, node) {\n\t\thlist_del(&obj->node);\n\t\tkmem_cache_free(obj_cache, obj);\n\t}\n\n\traw_spin_lock_irqsave(&pool_lock, flags);\n\tobj_pool_used -= percpu_pool->obj_free;\n\tdebug_objects_freed += percpu_pool->obj_free;\n\traw_spin_unlock_irqrestore(&pool_lock, flags);\n\n\tpercpu_pool->obj_free = 0;\n\n\treturn 0;\n}\n#endif\n\n \nstatic void debug_objects_oom(void)\n{\n\tstruct debug_bucket *db = obj_hash;\n\tstruct hlist_node *tmp;\n\tHLIST_HEAD(freelist);\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\tint i;\n\n\tpr_warn(\"Out of memory. ODEBUG disabled\\n\");\n\n\tfor (i = 0; i < ODEBUG_HASH_SIZE; i++, db++) {\n\t\traw_spin_lock_irqsave(&db->lock, flags);\n\t\thlist_move_list(&db->list, &freelist);\n\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\n\t\t \n\t\thlist_for_each_entry_safe(obj, tmp, &freelist, node) {\n\t\t\thlist_del(&obj->node);\n\t\t\tfree_object(obj);\n\t\t}\n\t}\n}\n\n \nstatic struct debug_bucket *get_bucket(unsigned long addr)\n{\n\tunsigned long hash;\n\n\thash = hash_long((addr >> ODEBUG_CHUNK_SHIFT), ODEBUG_HASH_BITS);\n\treturn &obj_hash[hash];\n}\n\nstatic void debug_print_object(struct debug_obj *obj, char *msg)\n{\n\tconst struct debug_obj_descr *descr = obj->descr;\n\tstatic int limit;\n\n\t \n\tif (!debug_objects_enabled)\n\t\treturn;\n\n\tif (limit < 5 && descr != descr_test) {\n\t\tvoid *hint = descr->debug_hint ?\n\t\t\tdescr->debug_hint(obj->object) : NULL;\n\t\tlimit++;\n\t\tWARN(1, KERN_ERR \"ODEBUG: %s %s (active state %u) \"\n\t\t\t\t \"object: %p object type: %s hint: %pS\\n\",\n\t\t\tmsg, obj_states[obj->state], obj->astate,\n\t\t\tobj->object, descr->name, hint);\n\t}\n\tdebug_objects_warnings++;\n}\n\n \nstatic bool\ndebug_object_fixup(bool (*fixup)(void *addr, enum debug_obj_state state),\n\t\t   void * addr, enum debug_obj_state state)\n{\n\tif (fixup && fixup(addr, state)) {\n\t\tdebug_objects_fixups++;\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic void debug_object_is_on_stack(void *addr, int onstack)\n{\n\tint is_on_stack;\n\tstatic int limit;\n\n\tif (limit > 4)\n\t\treturn;\n\n\tis_on_stack = object_is_on_stack(addr);\n\tif (is_on_stack == onstack)\n\t\treturn;\n\n\tlimit++;\n\tif (is_on_stack)\n\t\tpr_warn(\"object %p is on stack %p, but NOT annotated.\\n\", addr,\n\t\t\t task_stack_page(current));\n\telse\n\t\tpr_warn(\"object %p is NOT on stack %p, but annotated.\\n\", addr,\n\t\t\t task_stack_page(current));\n\n\tWARN_ON(1);\n}\n\nstatic struct debug_obj *lookup_object_or_alloc(void *addr, struct debug_bucket *b,\n\t\t\t\t\t\tconst struct debug_obj_descr *descr,\n\t\t\t\t\t\tbool onstack, bool alloc_ifstatic)\n{\n\tstruct debug_obj *obj = lookup_object(addr, b);\n\tenum debug_obj_state state = ODEBUG_STATE_NONE;\n\n\tif (likely(obj))\n\t\treturn obj;\n\n\t \n\tif (unlikely(alloc_ifstatic)) {\n\t\tif (!descr->is_static_object || !descr->is_static_object(addr))\n\t\t\treturn ERR_PTR(-ENOENT);\n\t\t \n\t\tstate = ODEBUG_STATE_INIT;\n\t}\n\n\tobj = alloc_object(addr, b, descr);\n\tif (likely(obj)) {\n\t\tobj->state = state;\n\t\tdebug_object_is_on_stack(addr, onstack);\n\t\treturn obj;\n\t}\n\n\t \n\tdebug_objects_enabled = 0;\n\treturn NULL;\n}\n\nstatic void debug_objects_fill_pool(void)\n{\n\t \n\tif (!IS_ENABLED(CONFIG_PREEMPT_RT) || preemptible()) {\n\t\t \n\t\tstatic DEFINE_WAIT_OVERRIDE_MAP(fill_pool_map, LD_WAIT_SLEEP);\n\t\tlock_map_acquire_try(&fill_pool_map);\n\t\tfill_pool();\n\t\tlock_map_release(&fill_pool_map);\n\t}\n}\n\nstatic void\n__debug_object_init(void *addr, const struct debug_obj_descr *descr, int onstack)\n{\n\tenum debug_obj_state state;\n\tstruct debug_bucket *db;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\n\tdebug_objects_fill_pool();\n\n\tdb = get_bucket((unsigned long) addr);\n\n\traw_spin_lock_irqsave(&db->lock, flags);\n\n\tobj = lookup_object_or_alloc(addr, db, descr, onstack, false);\n\tif (unlikely(!obj)) {\n\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\t\tdebug_objects_oom();\n\t\treturn;\n\t}\n\n\tswitch (obj->state) {\n\tcase ODEBUG_STATE_NONE:\n\tcase ODEBUG_STATE_INIT:\n\tcase ODEBUG_STATE_INACTIVE:\n\t\tobj->state = ODEBUG_STATE_INIT;\n\t\tbreak;\n\n\tcase ODEBUG_STATE_ACTIVE:\n\t\tstate = obj->state;\n\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\t\tdebug_print_object(obj, \"init\");\n\t\tdebug_object_fixup(descr->fixup_init, addr, state);\n\t\treturn;\n\n\tcase ODEBUG_STATE_DESTROYED:\n\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\t\tdebug_print_object(obj, \"init\");\n\t\treturn;\n\tdefault:\n\t\tbreak;\n\t}\n\n\traw_spin_unlock_irqrestore(&db->lock, flags);\n}\n\n \nvoid debug_object_init(void *addr, const struct debug_obj_descr *descr)\n{\n\tif (!debug_objects_enabled)\n\t\treturn;\n\n\t__debug_object_init(addr, descr, 0);\n}\nEXPORT_SYMBOL_GPL(debug_object_init);\n\n \nvoid debug_object_init_on_stack(void *addr, const struct debug_obj_descr *descr)\n{\n\tif (!debug_objects_enabled)\n\t\treturn;\n\n\t__debug_object_init(addr, descr, 1);\n}\nEXPORT_SYMBOL_GPL(debug_object_init_on_stack);\n\n \nint debug_object_activate(void *addr, const struct debug_obj_descr *descr)\n{\n\tstruct debug_obj o = { .object = addr, .state = ODEBUG_STATE_NOTAVAILABLE, .descr = descr };\n\tenum debug_obj_state state;\n\tstruct debug_bucket *db;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\tint ret;\n\n\tif (!debug_objects_enabled)\n\t\treturn 0;\n\n\tdebug_objects_fill_pool();\n\n\tdb = get_bucket((unsigned long) addr);\n\n\traw_spin_lock_irqsave(&db->lock, flags);\n\n\tobj = lookup_object_or_alloc(addr, db, descr, false, true);\n\tif (likely(!IS_ERR_OR_NULL(obj))) {\n\t\tbool print_object = false;\n\n\t\tswitch (obj->state) {\n\t\tcase ODEBUG_STATE_INIT:\n\t\tcase ODEBUG_STATE_INACTIVE:\n\t\t\tobj->state = ODEBUG_STATE_ACTIVE;\n\t\t\tret = 0;\n\t\t\tbreak;\n\n\t\tcase ODEBUG_STATE_ACTIVE:\n\t\t\tstate = obj->state;\n\t\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\t\t\tdebug_print_object(obj, \"activate\");\n\t\t\tret = debug_object_fixup(descr->fixup_activate, addr, state);\n\t\t\treturn ret ? 0 : -EINVAL;\n\n\t\tcase ODEBUG_STATE_DESTROYED:\n\t\t\tprint_object = true;\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\t\tif (print_object)\n\t\t\tdebug_print_object(obj, \"activate\");\n\t\treturn ret;\n\t}\n\n\traw_spin_unlock_irqrestore(&db->lock, flags);\n\n\t \n\tif (!obj) {\n\t\tdebug_objects_oom();\n\t\treturn 0;\n\t}\n\n\t \n\tdebug_print_object(&o, \"activate\");\n\tret = debug_object_fixup(descr->fixup_activate, addr, ODEBUG_STATE_NOTAVAILABLE);\n\treturn ret ? 0 : -EINVAL;\n}\nEXPORT_SYMBOL_GPL(debug_object_activate);\n\n \nvoid debug_object_deactivate(void *addr, const struct debug_obj_descr *descr)\n{\n\tstruct debug_bucket *db;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\tbool print_object = false;\n\n\tif (!debug_objects_enabled)\n\t\treturn;\n\n\tdb = get_bucket((unsigned long) addr);\n\n\traw_spin_lock_irqsave(&db->lock, flags);\n\n\tobj = lookup_object(addr, db);\n\tif (obj) {\n\t\tswitch (obj->state) {\n\t\tcase ODEBUG_STATE_INIT:\n\t\tcase ODEBUG_STATE_INACTIVE:\n\t\tcase ODEBUG_STATE_ACTIVE:\n\t\t\tif (!obj->astate)\n\t\t\t\tobj->state = ODEBUG_STATE_INACTIVE;\n\t\t\telse\n\t\t\t\tprint_object = true;\n\t\t\tbreak;\n\n\t\tcase ODEBUG_STATE_DESTROYED:\n\t\t\tprint_object = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\traw_spin_unlock_irqrestore(&db->lock, flags);\n\tif (!obj) {\n\t\tstruct debug_obj o = { .object = addr,\n\t\t\t\t       .state = ODEBUG_STATE_NOTAVAILABLE,\n\t\t\t\t       .descr = descr };\n\n\t\tdebug_print_object(&o, \"deactivate\");\n\t} else if (print_object) {\n\t\tdebug_print_object(obj, \"deactivate\");\n\t}\n}\nEXPORT_SYMBOL_GPL(debug_object_deactivate);\n\n \nvoid debug_object_destroy(void *addr, const struct debug_obj_descr *descr)\n{\n\tenum debug_obj_state state;\n\tstruct debug_bucket *db;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\tbool print_object = false;\n\n\tif (!debug_objects_enabled)\n\t\treturn;\n\n\tdb = get_bucket((unsigned long) addr);\n\n\traw_spin_lock_irqsave(&db->lock, flags);\n\n\tobj = lookup_object(addr, db);\n\tif (!obj)\n\t\tgoto out_unlock;\n\n\tswitch (obj->state) {\n\tcase ODEBUG_STATE_NONE:\n\tcase ODEBUG_STATE_INIT:\n\tcase ODEBUG_STATE_INACTIVE:\n\t\tobj->state = ODEBUG_STATE_DESTROYED;\n\t\tbreak;\n\tcase ODEBUG_STATE_ACTIVE:\n\t\tstate = obj->state;\n\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\t\tdebug_print_object(obj, \"destroy\");\n\t\tdebug_object_fixup(descr->fixup_destroy, addr, state);\n\t\treturn;\n\n\tcase ODEBUG_STATE_DESTROYED:\n\t\tprint_object = true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\nout_unlock:\n\traw_spin_unlock_irqrestore(&db->lock, flags);\n\tif (print_object)\n\t\tdebug_print_object(obj, \"destroy\");\n}\nEXPORT_SYMBOL_GPL(debug_object_destroy);\n\n \nvoid debug_object_free(void *addr, const struct debug_obj_descr *descr)\n{\n\tenum debug_obj_state state;\n\tstruct debug_bucket *db;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\n\tif (!debug_objects_enabled)\n\t\treturn;\n\n\tdb = get_bucket((unsigned long) addr);\n\n\traw_spin_lock_irqsave(&db->lock, flags);\n\n\tobj = lookup_object(addr, db);\n\tif (!obj)\n\t\tgoto out_unlock;\n\n\tswitch (obj->state) {\n\tcase ODEBUG_STATE_ACTIVE:\n\t\tstate = obj->state;\n\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\t\tdebug_print_object(obj, \"free\");\n\t\tdebug_object_fixup(descr->fixup_free, addr, state);\n\t\treturn;\n\tdefault:\n\t\thlist_del(&obj->node);\n\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\t\tfree_object(obj);\n\t\treturn;\n\t}\nout_unlock:\n\traw_spin_unlock_irqrestore(&db->lock, flags);\n}\nEXPORT_SYMBOL_GPL(debug_object_free);\n\n \nvoid debug_object_assert_init(void *addr, const struct debug_obj_descr *descr)\n{\n\tstruct debug_obj o = { .object = addr, .state = ODEBUG_STATE_NOTAVAILABLE, .descr = descr };\n\tstruct debug_bucket *db;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\n\tif (!debug_objects_enabled)\n\t\treturn;\n\n\tdebug_objects_fill_pool();\n\n\tdb = get_bucket((unsigned long) addr);\n\n\traw_spin_lock_irqsave(&db->lock, flags);\n\tobj = lookup_object_or_alloc(addr, db, descr, false, true);\n\traw_spin_unlock_irqrestore(&db->lock, flags);\n\tif (likely(!IS_ERR_OR_NULL(obj)))\n\t\treturn;\n\n\t \n\tif (!obj) {\n\t\tdebug_objects_oom();\n\t\treturn;\n\t}\n\n\t \n\tdebug_print_object(&o, \"assert_init\");\n\tdebug_object_fixup(descr->fixup_assert_init, addr, ODEBUG_STATE_NOTAVAILABLE);\n}\nEXPORT_SYMBOL_GPL(debug_object_assert_init);\n\n \nvoid\ndebug_object_active_state(void *addr, const struct debug_obj_descr *descr,\n\t\t\t  unsigned int expect, unsigned int next)\n{\n\tstruct debug_bucket *db;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\tbool print_object = false;\n\n\tif (!debug_objects_enabled)\n\t\treturn;\n\n\tdb = get_bucket((unsigned long) addr);\n\n\traw_spin_lock_irqsave(&db->lock, flags);\n\n\tobj = lookup_object(addr, db);\n\tif (obj) {\n\t\tswitch (obj->state) {\n\t\tcase ODEBUG_STATE_ACTIVE:\n\t\t\tif (obj->astate == expect)\n\t\t\t\tobj->astate = next;\n\t\t\telse\n\t\t\t\tprint_object = true;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tprint_object = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\traw_spin_unlock_irqrestore(&db->lock, flags);\n\tif (!obj) {\n\t\tstruct debug_obj o = { .object = addr,\n\t\t\t\t       .state = ODEBUG_STATE_NOTAVAILABLE,\n\t\t\t\t       .descr = descr };\n\n\t\tdebug_print_object(&o, \"active_state\");\n\t} else if (print_object) {\n\t\tdebug_print_object(obj, \"active_state\");\n\t}\n}\nEXPORT_SYMBOL_GPL(debug_object_active_state);\n\n#ifdef CONFIG_DEBUG_OBJECTS_FREE\nstatic void __debug_check_no_obj_freed(const void *address, unsigned long size)\n{\n\tunsigned long flags, oaddr, saddr, eaddr, paddr, chunks;\n\tconst struct debug_obj_descr *descr;\n\tenum debug_obj_state state;\n\tstruct debug_bucket *db;\n\tstruct hlist_node *tmp;\n\tstruct debug_obj *obj;\n\tint cnt, objs_checked = 0;\n\n\tsaddr = (unsigned long) address;\n\teaddr = saddr + size;\n\tpaddr = saddr & ODEBUG_CHUNK_MASK;\n\tchunks = ((eaddr - paddr) + (ODEBUG_CHUNK_SIZE - 1));\n\tchunks >>= ODEBUG_CHUNK_SHIFT;\n\n\tfor (;chunks > 0; chunks--, paddr += ODEBUG_CHUNK_SIZE) {\n\t\tdb = get_bucket(paddr);\n\nrepeat:\n\t\tcnt = 0;\n\t\traw_spin_lock_irqsave(&db->lock, flags);\n\t\thlist_for_each_entry_safe(obj, tmp, &db->list, node) {\n\t\t\tcnt++;\n\t\t\toaddr = (unsigned long) obj->object;\n\t\t\tif (oaddr < saddr || oaddr >= eaddr)\n\t\t\t\tcontinue;\n\n\t\t\tswitch (obj->state) {\n\t\t\tcase ODEBUG_STATE_ACTIVE:\n\t\t\t\tdescr = obj->descr;\n\t\t\t\tstate = obj->state;\n\t\t\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\t\t\t\tdebug_print_object(obj, \"free\");\n\t\t\t\tdebug_object_fixup(descr->fixup_free,\n\t\t\t\t\t\t   (void *) oaddr, state);\n\t\t\t\tgoto repeat;\n\t\t\tdefault:\n\t\t\t\thlist_del(&obj->node);\n\t\t\t\t__free_object(obj);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\traw_spin_unlock_irqrestore(&db->lock, flags);\n\n\t\tif (cnt > debug_objects_maxchain)\n\t\t\tdebug_objects_maxchain = cnt;\n\n\t\tobjs_checked += cnt;\n\t}\n\n\tif (objs_checked > debug_objects_maxchecked)\n\t\tdebug_objects_maxchecked = objs_checked;\n\n\t \n\tif (!READ_ONCE(obj_freeing) && READ_ONCE(obj_nr_tofree)) {\n\t\tWRITE_ONCE(obj_freeing, true);\n\t\tschedule_delayed_work(&debug_obj_work, ODEBUG_FREE_WORK_DELAY);\n\t}\n}\n\nvoid debug_check_no_obj_freed(const void *address, unsigned long size)\n{\n\tif (debug_objects_enabled)\n\t\t__debug_check_no_obj_freed(address, size);\n}\n#endif\n\n#ifdef CONFIG_DEBUG_FS\n\nstatic int debug_stats_show(struct seq_file *m, void *v)\n{\n\tint cpu, obj_percpu_free = 0;\n\n\tfor_each_possible_cpu(cpu)\n\t\tobj_percpu_free += per_cpu(percpu_obj_pool.obj_free, cpu);\n\n\tseq_printf(m, \"max_chain     :%d\\n\", debug_objects_maxchain);\n\tseq_printf(m, \"max_checked   :%d\\n\", debug_objects_maxchecked);\n\tseq_printf(m, \"warnings      :%d\\n\", debug_objects_warnings);\n\tseq_printf(m, \"fixups        :%d\\n\", debug_objects_fixups);\n\tseq_printf(m, \"pool_free     :%d\\n\", READ_ONCE(obj_pool_free) + obj_percpu_free);\n\tseq_printf(m, \"pool_pcp_free :%d\\n\", obj_percpu_free);\n\tseq_printf(m, \"pool_min_free :%d\\n\", obj_pool_min_free);\n\tseq_printf(m, \"pool_used     :%d\\n\", obj_pool_used - obj_percpu_free);\n\tseq_printf(m, \"pool_max_used :%d\\n\", obj_pool_max_used);\n\tseq_printf(m, \"on_free_list  :%d\\n\", READ_ONCE(obj_nr_tofree));\n\tseq_printf(m, \"objs_allocated:%d\\n\", debug_objects_allocated);\n\tseq_printf(m, \"objs_freed    :%d\\n\", debug_objects_freed);\n\treturn 0;\n}\nDEFINE_SHOW_ATTRIBUTE(debug_stats);\n\nstatic int __init debug_objects_init_debugfs(void)\n{\n\tstruct dentry *dbgdir;\n\n\tif (!debug_objects_enabled)\n\t\treturn 0;\n\n\tdbgdir = debugfs_create_dir(\"debug_objects\", NULL);\n\n\tdebugfs_create_file(\"stats\", 0444, dbgdir, NULL, &debug_stats_fops);\n\n\treturn 0;\n}\n__initcall(debug_objects_init_debugfs);\n\n#else\nstatic inline void debug_objects_init_debugfs(void) { }\n#endif\n\n#ifdef CONFIG_DEBUG_OBJECTS_SELFTEST\n\n \nstruct self_test {\n\tunsigned long\tdummy1[6];\n\tint\t\tstatic_init;\n\tunsigned long\tdummy2[3];\n};\n\nstatic __initconst const struct debug_obj_descr descr_type_test;\n\nstatic bool __init is_static_object(void *addr)\n{\n\tstruct self_test *obj = addr;\n\n\treturn obj->static_init;\n}\n\n \nstatic bool __init fixup_init(void *addr, enum debug_obj_state state)\n{\n\tstruct self_test *obj = addr;\n\n\tswitch (state) {\n\tcase ODEBUG_STATE_ACTIVE:\n\t\tdebug_object_deactivate(obj, &descr_type_test);\n\t\tdebug_object_init(obj, &descr_type_test);\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nstatic bool __init fixup_activate(void *addr, enum debug_obj_state state)\n{\n\tstruct self_test *obj = addr;\n\n\tswitch (state) {\n\tcase ODEBUG_STATE_NOTAVAILABLE:\n\t\treturn true;\n\tcase ODEBUG_STATE_ACTIVE:\n\t\tdebug_object_deactivate(obj, &descr_type_test);\n\t\tdebug_object_activate(obj, &descr_type_test);\n\t\treturn true;\n\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nstatic bool __init fixup_destroy(void *addr, enum debug_obj_state state)\n{\n\tstruct self_test *obj = addr;\n\n\tswitch (state) {\n\tcase ODEBUG_STATE_ACTIVE:\n\t\tdebug_object_deactivate(obj, &descr_type_test);\n\t\tdebug_object_destroy(obj, &descr_type_test);\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nstatic bool __init fixup_free(void *addr, enum debug_obj_state state)\n{\n\tstruct self_test *obj = addr;\n\n\tswitch (state) {\n\tcase ODEBUG_STATE_ACTIVE:\n\t\tdebug_object_deactivate(obj, &descr_type_test);\n\t\tdebug_object_free(obj, &descr_type_test);\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic int __init\ncheck_results(void *addr, enum debug_obj_state state, int fixups, int warnings)\n{\n\tstruct debug_bucket *db;\n\tstruct debug_obj *obj;\n\tunsigned long flags;\n\tint res = -EINVAL;\n\n\tdb = get_bucket((unsigned long) addr);\n\n\traw_spin_lock_irqsave(&db->lock, flags);\n\n\tobj = lookup_object(addr, db);\n\tif (!obj && state != ODEBUG_STATE_NONE) {\n\t\tWARN(1, KERN_ERR \"ODEBUG: selftest object not found\\n\");\n\t\tgoto out;\n\t}\n\tif (obj && obj->state != state) {\n\t\tWARN(1, KERN_ERR \"ODEBUG: selftest wrong state: %d != %d\\n\",\n\t\t       obj->state, state);\n\t\tgoto out;\n\t}\n\tif (fixups != debug_objects_fixups) {\n\t\tWARN(1, KERN_ERR \"ODEBUG: selftest fixups failed %d != %d\\n\",\n\t\t       fixups, debug_objects_fixups);\n\t\tgoto out;\n\t}\n\tif (warnings != debug_objects_warnings) {\n\t\tWARN(1, KERN_ERR \"ODEBUG: selftest warnings failed %d != %d\\n\",\n\t\t       warnings, debug_objects_warnings);\n\t\tgoto out;\n\t}\n\tres = 0;\nout:\n\traw_spin_unlock_irqrestore(&db->lock, flags);\n\tif (res)\n\t\tdebug_objects_enabled = 0;\n\treturn res;\n}\n\nstatic __initconst const struct debug_obj_descr descr_type_test = {\n\t.name\t\t\t= \"selftest\",\n\t.is_static_object\t= is_static_object,\n\t.fixup_init\t\t= fixup_init,\n\t.fixup_activate\t\t= fixup_activate,\n\t.fixup_destroy\t\t= fixup_destroy,\n\t.fixup_free\t\t= fixup_free,\n};\n\nstatic __initdata struct self_test obj = { .static_init = 0 };\n\nstatic void __init debug_objects_selftest(void)\n{\n\tint fixups, oldfixups, warnings, oldwarnings;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\n\tfixups = oldfixups = debug_objects_fixups;\n\twarnings = oldwarnings = debug_objects_warnings;\n\tdescr_test = &descr_type_test;\n\n\tdebug_object_init(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_INIT, fixups, warnings))\n\t\tgoto out;\n\tdebug_object_activate(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_ACTIVE, fixups, warnings))\n\t\tgoto out;\n\tdebug_object_activate(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_ACTIVE, ++fixups, ++warnings))\n\t\tgoto out;\n\tdebug_object_deactivate(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_INACTIVE, fixups, warnings))\n\t\tgoto out;\n\tdebug_object_destroy(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_DESTROYED, fixups, warnings))\n\t\tgoto out;\n\tdebug_object_init(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_DESTROYED, fixups, ++warnings))\n\t\tgoto out;\n\tdebug_object_activate(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_DESTROYED, fixups, ++warnings))\n\t\tgoto out;\n\tdebug_object_deactivate(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_DESTROYED, fixups, ++warnings))\n\t\tgoto out;\n\tdebug_object_free(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_NONE, fixups, warnings))\n\t\tgoto out;\n\n\tobj.static_init = 1;\n\tdebug_object_activate(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_ACTIVE, fixups, warnings))\n\t\tgoto out;\n\tdebug_object_init(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_INIT, ++fixups, ++warnings))\n\t\tgoto out;\n\tdebug_object_free(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_NONE, fixups, warnings))\n\t\tgoto out;\n\n#ifdef CONFIG_DEBUG_OBJECTS_FREE\n\tdebug_object_init(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_INIT, fixups, warnings))\n\t\tgoto out;\n\tdebug_object_activate(&obj, &descr_type_test);\n\tif (check_results(&obj, ODEBUG_STATE_ACTIVE, fixups, warnings))\n\t\tgoto out;\n\t__debug_check_no_obj_freed(&obj, sizeof(obj));\n\tif (check_results(&obj, ODEBUG_STATE_NONE, ++fixups, ++warnings))\n\t\tgoto out;\n#endif\n\tpr_info(\"selftest passed\\n\");\n\nout:\n\tdebug_objects_fixups = oldfixups;\n\tdebug_objects_warnings = oldwarnings;\n\tdescr_test = NULL;\n\n\tlocal_irq_restore(flags);\n}\n#else\nstatic inline void debug_objects_selftest(void) { }\n#endif\n\n \nvoid __init debug_objects_early_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ODEBUG_HASH_SIZE; i++)\n\t\traw_spin_lock_init(&obj_hash[i].lock);\n\n\tfor (i = 0; i < ODEBUG_POOL_SIZE; i++)\n\t\thlist_add_head(&obj_static_pool[i].node, &obj_pool);\n}\n\n \nstatic int __init debug_objects_replace_static_objects(void)\n{\n\tstruct debug_bucket *db = obj_hash;\n\tstruct hlist_node *tmp;\n\tstruct debug_obj *obj, *new;\n\tHLIST_HEAD(objects);\n\tint i, cnt = 0;\n\n\tfor (i = 0; i < ODEBUG_POOL_SIZE; i++) {\n\t\tobj = kmem_cache_zalloc(obj_cache, GFP_KERNEL);\n\t\tif (!obj)\n\t\t\tgoto free;\n\t\thlist_add_head(&obj->node, &objects);\n\t}\n\n\tdebug_objects_allocated += i;\n\n\t \n\n\t \n\thlist_for_each_entry_safe(obj, tmp, &obj_pool, node)\n\t\thlist_del(&obj->node);\n\t \n\thlist_move_list(&objects, &obj_pool);\n\n\t \n\tfor (i = 0; i < ODEBUG_HASH_SIZE; i++, db++) {\n\t\thlist_move_list(&db->list, &objects);\n\n\t\thlist_for_each_entry(obj, &objects, node) {\n\t\t\tnew = hlist_entry(obj_pool.first, typeof(*obj), node);\n\t\t\thlist_del(&new->node);\n\t\t\t \n\t\t\t*new = *obj;\n\t\t\thlist_add_head(&new->node, &db->list);\n\t\t\tcnt++;\n\t\t}\n\t}\n\n\tpr_debug(\"%d of %d active objects replaced\\n\",\n\t\t cnt, obj_pool_used);\n\treturn 0;\nfree:\n\thlist_for_each_entry_safe(obj, tmp, &objects, node) {\n\t\thlist_del(&obj->node);\n\t\tkmem_cache_free(obj_cache, obj);\n\t}\n\treturn -ENOMEM;\n}\n\n \nvoid __init debug_objects_mem_init(void)\n{\n\tint cpu, extras;\n\n\tif (!debug_objects_enabled)\n\t\treturn;\n\n\t \n\tfor_each_possible_cpu(cpu)\n\t\tINIT_HLIST_HEAD(&per_cpu(percpu_obj_pool.free_objs, cpu));\n\n\tobj_cache = kmem_cache_create(\"debug_objects_cache\",\n\t\t\t\t      sizeof (struct debug_obj), 0,\n\t\t\t\t      SLAB_DEBUG_OBJECTS | SLAB_NOLEAKTRACE,\n\t\t\t\t      NULL);\n\n\tif (!obj_cache || debug_objects_replace_static_objects()) {\n\t\tdebug_objects_enabled = 0;\n\t\tkmem_cache_destroy(obj_cache);\n\t\tpr_warn(\"out of memory.\\n\");\n\t\treturn;\n\t} else\n\t\tdebug_objects_selftest();\n\n#ifdef CONFIG_HOTPLUG_CPU\n\tcpuhp_setup_state_nocalls(CPUHP_DEBUG_OBJ_DEAD, \"object:offline\", NULL,\n\t\t\t\t\tobject_cpu_offline);\n#endif\n\n\t \n\textras = num_possible_cpus() * ODEBUG_BATCH_SIZE;\n\tdebug_objects_pool_size += extras;\n\tdebug_objects_pool_min_level += extras;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}