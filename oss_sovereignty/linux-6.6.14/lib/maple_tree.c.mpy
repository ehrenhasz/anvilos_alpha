{
  "module_name": "maple_tree.c",
  "hash_id": "749e49e33732419478aa670338182f15eb0c1e13a585c2d07e6f12a389db8b2a",
  "original_prompt": "Ingested from linux-6.6.14/lib/maple_tree.c",
  "human_readable_source": "\n \n\n \n\n\n#include <linux/maple_tree.h>\n#include <linux/xarray.h>\n#include <linux/types.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/limits.h>\n#include <asm/barrier.h>\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/maple_tree.h>\n\n#define MA_ROOT_PARENT 1\n\n \n#define MA_STATE_BULK\t\t1\n#define MA_STATE_REBALANCE\t2\n#define MA_STATE_PREALLOC\t4\n\n#define ma_parent_ptr(x) ((struct maple_pnode *)(x))\n#define mas_tree_parent(x) ((unsigned long)(x->tree) | MA_ROOT_PARENT)\n#define ma_mnode_ptr(x) ((struct maple_node *)(x))\n#define ma_enode_ptr(x) ((struct maple_enode *)(x))\nstatic struct kmem_cache *maple_node_cache;\n\n#ifdef CONFIG_DEBUG_MAPLE_TREE\nstatic const unsigned long mt_max[] = {\n\t[maple_dense]\t\t= MAPLE_NODE_SLOTS,\n\t[maple_leaf_64]\t\t= ULONG_MAX,\n\t[maple_range_64]\t= ULONG_MAX,\n\t[maple_arange_64]\t= ULONG_MAX,\n};\n#define mt_node_max(x) mt_max[mte_node_type(x)]\n#endif\n\nstatic const unsigned char mt_slots[] = {\n\t[maple_dense]\t\t= MAPLE_NODE_SLOTS,\n\t[maple_leaf_64]\t\t= MAPLE_RANGE64_SLOTS,\n\t[maple_range_64]\t= MAPLE_RANGE64_SLOTS,\n\t[maple_arange_64]\t= MAPLE_ARANGE64_SLOTS,\n};\n#define mt_slot_count(x) mt_slots[mte_node_type(x)]\n\nstatic const unsigned char mt_pivots[] = {\n\t[maple_dense]\t\t= 0,\n\t[maple_leaf_64]\t\t= MAPLE_RANGE64_SLOTS - 1,\n\t[maple_range_64]\t= MAPLE_RANGE64_SLOTS - 1,\n\t[maple_arange_64]\t= MAPLE_ARANGE64_SLOTS - 1,\n};\n#define mt_pivot_count(x) mt_pivots[mte_node_type(x)]\n\nstatic const unsigned char mt_min_slots[] = {\n\t[maple_dense]\t\t= MAPLE_NODE_SLOTS / 2,\n\t[maple_leaf_64]\t\t= (MAPLE_RANGE64_SLOTS / 2) - 2,\n\t[maple_range_64]\t= (MAPLE_RANGE64_SLOTS / 2) - 2,\n\t[maple_arange_64]\t= (MAPLE_ARANGE64_SLOTS / 2) - 1,\n};\n#define mt_min_slot_count(x) mt_min_slots[mte_node_type(x)]\n\n#define MAPLE_BIG_NODE_SLOTS\t(MAPLE_RANGE64_SLOTS * 2 + 2)\n#define MAPLE_BIG_NODE_GAPS\t(MAPLE_ARANGE64_SLOTS * 2 + 1)\n\nstruct maple_big_node {\n\tstruct maple_pnode *parent;\n\tunsigned long pivot[MAPLE_BIG_NODE_SLOTS - 1];\n\tunion {\n\t\tstruct maple_enode *slot[MAPLE_BIG_NODE_SLOTS];\n\t\tstruct {\n\t\t\tunsigned long padding[MAPLE_BIG_NODE_GAPS];\n\t\t\tunsigned long gap[MAPLE_BIG_NODE_GAPS];\n\t\t};\n\t};\n\tunsigned char b_end;\n\tenum maple_type type;\n};\n\n \nstruct maple_subtree_state {\n\tstruct ma_state *orig_l;\t \n\tstruct ma_state *orig_r;\t \n\tstruct ma_state *l;\t\t \n\tstruct ma_state *m;\t\t \n\tstruct ma_state *r;\t\t \n\tstruct ma_topiary *free;\t \n\tstruct ma_topiary *destroy;\t \n\tstruct maple_big_node *bn;\n};\n\n#ifdef CONFIG_KASAN_STACK\n \n#define noinline_for_kasan noinline_for_stack\n#else\n#define noinline_for_kasan inline\n#endif\n\n \nstatic inline struct maple_node *mt_alloc_one(gfp_t gfp)\n{\n\treturn kmem_cache_alloc(maple_node_cache, gfp);\n}\n\nstatic inline int mt_alloc_bulk(gfp_t gfp, size_t size, void **nodes)\n{\n\treturn kmem_cache_alloc_bulk(maple_node_cache, gfp, size, nodes);\n}\n\nstatic inline void mt_free_bulk(size_t size, void __rcu **nodes)\n{\n\tkmem_cache_free_bulk(maple_node_cache, size, (void **)nodes);\n}\n\nstatic void mt_free_rcu(struct rcu_head *head)\n{\n\tstruct maple_node *node = container_of(head, struct maple_node, rcu);\n\n\tkmem_cache_free(maple_node_cache, node);\n}\n\n \nstatic void ma_free_rcu(struct maple_node *node)\n{\n\tWARN_ON(node->parent != ma_parent_ptr(node));\n\tcall_rcu(&node->rcu, mt_free_rcu);\n}\n\nstatic void mas_set_height(struct ma_state *mas)\n{\n\tunsigned int new_flags = mas->tree->ma_flags;\n\n\tnew_flags &= ~MT_FLAGS_HEIGHT_MASK;\n\tMAS_BUG_ON(mas, mas->depth > MAPLE_HEIGHT_MAX);\n\tnew_flags |= mas->depth << MT_FLAGS_HEIGHT_OFFSET;\n\tmas->tree->ma_flags = new_flags;\n}\n\nstatic unsigned int mas_mt_height(struct ma_state *mas)\n{\n\treturn mt_height(mas->tree);\n}\n\nstatic inline enum maple_type mte_node_type(const struct maple_enode *entry)\n{\n\treturn ((unsigned long)entry >> MAPLE_NODE_TYPE_SHIFT) &\n\t\tMAPLE_NODE_TYPE_MASK;\n}\n\nstatic inline bool ma_is_dense(const enum maple_type type)\n{\n\treturn type < maple_leaf_64;\n}\n\nstatic inline bool ma_is_leaf(const enum maple_type type)\n{\n\treturn type < maple_range_64;\n}\n\nstatic inline bool mte_is_leaf(const struct maple_enode *entry)\n{\n\treturn ma_is_leaf(mte_node_type(entry));\n}\n\n \nstatic inline bool mt_is_reserved(const void *entry)\n{\n\treturn ((unsigned long)entry < MAPLE_RESERVED_RANGE) &&\n\t\txa_is_internal(entry);\n}\n\nstatic inline void mas_set_err(struct ma_state *mas, long err)\n{\n\tmas->node = MA_ERROR(err);\n}\n\nstatic inline bool mas_is_ptr(const struct ma_state *mas)\n{\n\treturn mas->node == MAS_ROOT;\n}\n\nstatic inline bool mas_is_start(const struct ma_state *mas)\n{\n\treturn mas->node == MAS_START;\n}\n\nbool mas_is_err(struct ma_state *mas)\n{\n\treturn xa_is_err(mas->node);\n}\n\nstatic __always_inline bool mas_is_overflow(struct ma_state *mas)\n{\n\tif (unlikely(mas->node == MAS_OVERFLOW))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic __always_inline bool mas_is_underflow(struct ma_state *mas)\n{\n\tif (unlikely(mas->node == MAS_UNDERFLOW))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic inline bool mas_searchable(struct ma_state *mas)\n{\n\tif (mas_is_none(mas))\n\t\treturn false;\n\n\tif (mas_is_ptr(mas))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic inline struct maple_node *mte_to_node(const struct maple_enode *entry)\n{\n\treturn (struct maple_node *)((unsigned long)entry & ~MAPLE_NODE_MASK);\n}\n\n \nstatic inline struct maple_topiary *mte_to_mat(const struct maple_enode *entry)\n{\n\treturn (struct maple_topiary *)\n\t\t((unsigned long)entry & ~MAPLE_NODE_MASK);\n}\n\n \nstatic inline struct maple_node *mas_mn(const struct ma_state *mas)\n{\n\treturn mte_to_node(mas->node);\n}\n\n \nstatic inline void mte_set_node_dead(struct maple_enode *mn)\n{\n\tmte_to_node(mn)->parent = ma_parent_ptr(mte_to_node(mn));\n\tsmp_wmb();  \n}\n\n \n#define MAPLE_ROOT_NODE\t\t\t0x02\n \n#define MAPLE_ENODE_TYPE_SHIFT\t\t0x03\n \n#define MAPLE_ENODE_NULL\t\t0x04\n\nstatic inline struct maple_enode *mt_mk_node(const struct maple_node *node,\n\t\t\t\t\t     enum maple_type type)\n{\n\treturn (void *)((unsigned long)node |\n\t\t\t(type << MAPLE_ENODE_TYPE_SHIFT) | MAPLE_ENODE_NULL);\n}\n\nstatic inline void *mte_mk_root(const struct maple_enode *node)\n{\n\treturn (void *)((unsigned long)node | MAPLE_ROOT_NODE);\n}\n\nstatic inline void *mte_safe_root(const struct maple_enode *node)\n{\n\treturn (void *)((unsigned long)node & ~MAPLE_ROOT_NODE);\n}\n\nstatic inline void *mte_set_full(const struct maple_enode *node)\n{\n\treturn (void *)((unsigned long)node & ~MAPLE_ENODE_NULL);\n}\n\nstatic inline void *mte_clear_full(const struct maple_enode *node)\n{\n\treturn (void *)((unsigned long)node | MAPLE_ENODE_NULL);\n}\n\nstatic inline bool mte_has_null(const struct maple_enode *node)\n{\n\treturn (unsigned long)node & MAPLE_ENODE_NULL;\n}\n\nstatic inline bool ma_is_root(struct maple_node *node)\n{\n\treturn ((unsigned long)node->parent & MA_ROOT_PARENT);\n}\n\nstatic inline bool mte_is_root(const struct maple_enode *node)\n{\n\treturn ma_is_root(mte_to_node(node));\n}\n\nstatic inline bool mas_is_root_limits(const struct ma_state *mas)\n{\n\treturn !mas->min && mas->max == ULONG_MAX;\n}\n\nstatic inline bool mt_is_alloc(struct maple_tree *mt)\n{\n\treturn (mt->ma_flags & MT_FLAGS_ALLOC_RANGE);\n}\n\n \n\n#define MAPLE_PARENT_ROOT\t\t0x01\n\n#define MAPLE_PARENT_SLOT_SHIFT\t\t0x03\n#define MAPLE_PARENT_SLOT_MASK\t\t0xF8\n\n#define MAPLE_PARENT_16B_SLOT_SHIFT\t0x02\n#define MAPLE_PARENT_16B_SLOT_MASK\t0xFC\n\n#define MAPLE_PARENT_RANGE64\t\t0x06\n#define MAPLE_PARENT_RANGE32\t\t0x04\n#define MAPLE_PARENT_NOT_RANGE16\t0x02\n\n \nstatic inline unsigned long mte_parent_shift(unsigned long parent)\n{\n\t \n\tif (likely(parent & MAPLE_PARENT_NOT_RANGE16))\n\t\treturn MAPLE_PARENT_SLOT_SHIFT;\n\n\treturn MAPLE_PARENT_16B_SLOT_SHIFT;\n}\n\n \nstatic inline unsigned long mte_parent_slot_mask(unsigned long parent)\n{\n\t \n\tif (likely(parent & MAPLE_PARENT_NOT_RANGE16))\n\t\treturn MAPLE_PARENT_SLOT_MASK;\n\n\treturn MAPLE_PARENT_16B_SLOT_MASK;\n}\n\n \nstatic inline\nenum maple_type mas_parent_type(struct ma_state *mas, struct maple_enode *enode)\n{\n\tunsigned long p_type;\n\n\tp_type = (unsigned long)mte_to_node(enode)->parent;\n\tif (WARN_ON(p_type & MAPLE_PARENT_ROOT))\n\t\treturn 0;\n\n\tp_type &= MAPLE_NODE_MASK;\n\tp_type &= ~mte_parent_slot_mask(p_type);\n\tswitch (p_type) {\n\tcase MAPLE_PARENT_RANGE64:  \n\t\tif (mt_is_alloc(mas->tree))\n\t\t\treturn maple_arange_64;\n\t\treturn maple_range_64;\n\t}\n\n\treturn 0;\n}\n\n \nstatic inline\nvoid mas_set_parent(struct ma_state *mas, struct maple_enode *enode,\n\t\t    const struct maple_enode *parent, unsigned char slot)\n{\n\tunsigned long val = (unsigned long)parent;\n\tunsigned long shift;\n\tunsigned long type;\n\tenum maple_type p_type = mte_node_type(parent);\n\n\tMAS_BUG_ON(mas, p_type == maple_dense);\n\tMAS_BUG_ON(mas, p_type == maple_leaf_64);\n\n\tswitch (p_type) {\n\tcase maple_range_64:\n\tcase maple_arange_64:\n\t\tshift = MAPLE_PARENT_SLOT_SHIFT;\n\t\ttype = MAPLE_PARENT_RANGE64;\n\t\tbreak;\n\tdefault:\n\tcase maple_dense:\n\tcase maple_leaf_64:\n\t\tshift = type = 0;\n\t\tbreak;\n\t}\n\n\tval &= ~MAPLE_NODE_MASK;  \n\tval |= (slot << shift) | type;\n\tmte_to_node(enode)->parent = ma_parent_ptr(val);\n}\n\n \nstatic inline unsigned int mte_parent_slot(const struct maple_enode *enode)\n{\n\tunsigned long val = (unsigned long)mte_to_node(enode)->parent;\n\n\tif (val & MA_ROOT_PARENT)\n\t\treturn 0;\n\n\t \n\treturn (val & MAPLE_PARENT_16B_SLOT_MASK) >> mte_parent_shift(val);\n}\n\n \nstatic inline struct maple_node *mte_parent(const struct maple_enode *enode)\n{\n\treturn (void *)((unsigned long)\n\t\t\t(mte_to_node(enode)->parent) & ~MAPLE_NODE_MASK);\n}\n\n \nstatic inline bool ma_dead_node(const struct maple_node *node)\n{\n\tstruct maple_node *parent;\n\n\t \n\tsmp_rmb();\n\tparent = (void *)((unsigned long) node->parent & ~MAPLE_NODE_MASK);\n\treturn (parent == node);\n}\n\n \nstatic inline bool mte_dead_node(const struct maple_enode *enode)\n{\n\tstruct maple_node *parent, *node;\n\n\tnode = mte_to_node(enode);\n\t \n\tsmp_rmb();\n\tparent = mte_parent(enode);\n\treturn (parent == node);\n}\n\n \nstatic inline unsigned long mas_allocated(const struct ma_state *mas)\n{\n\tif (!mas->alloc || ((unsigned long)mas->alloc & 0x1))\n\t\treturn 0;\n\n\treturn mas->alloc->total;\n}\n\n \nstatic inline void mas_set_alloc_req(struct ma_state *mas, unsigned long count)\n{\n\tif (!mas->alloc || ((unsigned long)mas->alloc & 0x1)) {\n\t\tif (!count)\n\t\t\tmas->alloc = NULL;\n\t\telse\n\t\t\tmas->alloc = (struct maple_alloc *)(((count) << 1U) | 1U);\n\t\treturn;\n\t}\n\n\tmas->alloc->request_count = count;\n}\n\n \nstatic inline unsigned int mas_alloc_req(const struct ma_state *mas)\n{\n\tif ((unsigned long)mas->alloc & 0x1)\n\t\treturn (unsigned long)(mas->alloc) >> 1;\n\telse if (mas->alloc)\n\t\treturn mas->alloc->request_count;\n\treturn 0;\n}\n\n \nstatic inline unsigned long *ma_pivots(struct maple_node *node,\n\t\t\t\t\t   enum maple_type type)\n{\n\tswitch (type) {\n\tcase maple_arange_64:\n\t\treturn node->ma64.pivot;\n\tcase maple_range_64:\n\tcase maple_leaf_64:\n\t\treturn node->mr64.pivot;\n\tcase maple_dense:\n\t\treturn NULL;\n\t}\n\treturn NULL;\n}\n\n \nstatic inline unsigned long *ma_gaps(struct maple_node *node,\n\t\t\t\t     enum maple_type type)\n{\n\tswitch (type) {\n\tcase maple_arange_64:\n\t\treturn node->ma64.gap;\n\tcase maple_range_64:\n\tcase maple_leaf_64:\n\tcase maple_dense:\n\t\treturn NULL;\n\t}\n\treturn NULL;\n}\n\n \nstatic inline unsigned long mas_pivot(struct ma_state *mas, unsigned char piv)\n{\n\tstruct maple_node *node = mas_mn(mas);\n\tenum maple_type type = mte_node_type(mas->node);\n\n\tif (MAS_WARN_ON(mas, piv >= mt_pivots[type])) {\n\t\tmas_set_err(mas, -EIO);\n\t\treturn 0;\n\t}\n\n\tswitch (type) {\n\tcase maple_arange_64:\n\t\treturn node->ma64.pivot[piv];\n\tcase maple_range_64:\n\tcase maple_leaf_64:\n\t\treturn node->mr64.pivot[piv];\n\tcase maple_dense:\n\t\treturn 0;\n\t}\n\treturn 0;\n}\n\n \nstatic inline unsigned long\nmas_safe_pivot(const struct ma_state *mas, unsigned long *pivots,\n\t       unsigned char piv, enum maple_type type)\n{\n\tif (piv >= mt_pivots[type])\n\t\treturn mas->max;\n\n\treturn pivots[piv];\n}\n\n \nstatic inline unsigned long\nmas_safe_min(struct ma_state *mas, unsigned long *pivots, unsigned char offset)\n{\n\tif (likely(offset))\n\t\treturn pivots[offset - 1] + 1;\n\n\treturn mas->min;\n}\n\n \nstatic inline void mte_set_pivot(struct maple_enode *mn, unsigned char piv,\n\t\t\t\tunsigned long val)\n{\n\tstruct maple_node *node = mte_to_node(mn);\n\tenum maple_type type = mte_node_type(mn);\n\n\tBUG_ON(piv >= mt_pivots[type]);\n\tswitch (type) {\n\tdefault:\n\tcase maple_range_64:\n\tcase maple_leaf_64:\n\t\tnode->mr64.pivot[piv] = val;\n\t\tbreak;\n\tcase maple_arange_64:\n\t\tnode->ma64.pivot[piv] = val;\n\t\tbreak;\n\tcase maple_dense:\n\t\tbreak;\n\t}\n\n}\n\n \nstatic inline void __rcu **ma_slots(struct maple_node *mn, enum maple_type mt)\n{\n\tswitch (mt) {\n\tdefault:\n\tcase maple_arange_64:\n\t\treturn mn->ma64.slot;\n\tcase maple_range_64:\n\tcase maple_leaf_64:\n\t\treturn mn->mr64.slot;\n\tcase maple_dense:\n\t\treturn mn->slot;\n\t}\n}\n\nstatic inline bool mt_write_locked(const struct maple_tree *mt)\n{\n\treturn mt_external_lock(mt) ? mt_write_lock_is_held(mt) :\n\t\tlockdep_is_held(&mt->ma_lock);\n}\n\nstatic inline bool mt_locked(const struct maple_tree *mt)\n{\n\treturn mt_external_lock(mt) ? mt_lock_is_held(mt) :\n\t\tlockdep_is_held(&mt->ma_lock);\n}\n\nstatic inline void *mt_slot(const struct maple_tree *mt,\n\t\tvoid __rcu **slots, unsigned char offset)\n{\n\treturn rcu_dereference_check(slots[offset], mt_locked(mt));\n}\n\nstatic inline void *mt_slot_locked(struct maple_tree *mt, void __rcu **slots,\n\t\t\t\t   unsigned char offset)\n{\n\treturn rcu_dereference_protected(slots[offset], mt_write_locked(mt));\n}\n \nstatic inline void *mas_slot_locked(struct ma_state *mas, void __rcu **slots,\n\t\t\t\t       unsigned char offset)\n{\n\treturn mt_slot_locked(mas->tree, slots, offset);\n}\n\n \nstatic inline void *mas_slot(struct ma_state *mas, void __rcu **slots,\n\t\t\t     unsigned char offset)\n{\n\treturn mt_slot(mas->tree, slots, offset);\n}\n\n \nstatic inline void *mas_root(struct ma_state *mas)\n{\n\treturn rcu_dereference_check(mas->tree->ma_root, mt_locked(mas->tree));\n}\n\nstatic inline void *mt_root_locked(struct maple_tree *mt)\n{\n\treturn rcu_dereference_protected(mt->ma_root, mt_write_locked(mt));\n}\n\n \nstatic inline void *mas_root_locked(struct ma_state *mas)\n{\n\treturn mt_root_locked(mas->tree);\n}\n\nstatic inline struct maple_metadata *ma_meta(struct maple_node *mn,\n\t\t\t\t\t     enum maple_type mt)\n{\n\tswitch (mt) {\n\tcase maple_arange_64:\n\t\treturn &mn->ma64.meta;\n\tdefault:\n\t\treturn &mn->mr64.meta;\n\t}\n}\n\n \nstatic inline void ma_set_meta(struct maple_node *mn, enum maple_type mt,\n\t\t\t       unsigned char offset, unsigned char end)\n{\n\tstruct maple_metadata *meta = ma_meta(mn, mt);\n\n\tmeta->gap = offset;\n\tmeta->end = end;\n}\n\n \nstatic inline void mt_clear_meta(struct maple_tree *mt, struct maple_node *mn,\n\t\t\t\t  enum maple_type type)\n{\n\tstruct maple_metadata *meta;\n\tunsigned long *pivots;\n\tvoid __rcu **slots;\n\tvoid *next;\n\n\tswitch (type) {\n\tcase maple_range_64:\n\t\tpivots = mn->mr64.pivot;\n\t\tif (unlikely(pivots[MAPLE_RANGE64_SLOTS - 2])) {\n\t\t\tslots = mn->mr64.slot;\n\t\t\tnext = mt_slot_locked(mt, slots,\n\t\t\t\t\t      MAPLE_RANGE64_SLOTS - 1);\n\t\t\tif (unlikely((mte_to_node(next) &&\n\t\t\t\t      mte_node_type(next))))\n\t\t\t\treturn;  \n\t\t}\n\t\tfallthrough;\n\tcase maple_arange_64:\n\t\tmeta = ma_meta(mn, type);\n\t\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\n\tmeta->gap = 0;\n\tmeta->end = 0;\n}\n\n \nstatic inline unsigned char ma_meta_end(struct maple_node *mn,\n\t\t\t\t\tenum maple_type mt)\n{\n\tstruct maple_metadata *meta = ma_meta(mn, mt);\n\n\treturn meta->end;\n}\n\n \nstatic inline unsigned char ma_meta_gap(struct maple_node *mn,\n\t\t\t\t\tenum maple_type mt)\n{\n\treturn mn->ma64.meta.gap;\n}\n\n \nstatic inline void ma_set_meta_gap(struct maple_node *mn, enum maple_type mt,\n\t\t\t\t   unsigned char offset)\n{\n\n\tstruct maple_metadata *meta = ma_meta(mn, mt);\n\n\tmeta->gap = offset;\n}\n\n \nstatic inline void mat_add(struct ma_topiary *mat,\n\t\t\t   struct maple_enode *dead_enode)\n{\n\tmte_set_node_dead(dead_enode);\n\tmte_to_mat(dead_enode)->next = NULL;\n\tif (!mat->tail) {\n\t\tmat->tail = mat->head = dead_enode;\n\t\treturn;\n\t}\n\n\tmte_to_mat(mat->tail)->next = dead_enode;\n\tmat->tail = dead_enode;\n}\n\nstatic void mt_free_walk(struct rcu_head *head);\nstatic void mt_destroy_walk(struct maple_enode *enode, struct maple_tree *mt,\n\t\t\t    bool free);\n \nstatic void mas_mat_destroy(struct ma_state *mas, struct ma_topiary *mat)\n{\n\tstruct maple_enode *next;\n\tstruct maple_node *node;\n\tbool in_rcu = mt_in_rcu(mas->tree);\n\n\twhile (mat->head) {\n\t\tnext = mte_to_mat(mat->head)->next;\n\t\tnode = mte_to_node(mat->head);\n\t\tmt_destroy_walk(mat->head, mas->tree, !in_rcu);\n\t\tif (in_rcu)\n\t\t\tcall_rcu(&node->rcu, mt_free_walk);\n\t\tmat->head = next;\n\t}\n}\n \nstatic inline void mas_descend(struct ma_state *mas)\n{\n\tenum maple_type type;\n\tunsigned long *pivots;\n\tstruct maple_node *node;\n\tvoid __rcu **slots;\n\n\tnode = mas_mn(mas);\n\ttype = mte_node_type(mas->node);\n\tpivots = ma_pivots(node, type);\n\tslots = ma_slots(node, type);\n\n\tif (mas->offset)\n\t\tmas->min = pivots[mas->offset - 1] + 1;\n\tmas->max = mas_safe_pivot(mas, pivots, mas->offset, type);\n\tmas->node = mas_slot(mas, slots, mas->offset);\n}\n\n \nstatic inline void mte_set_gap(const struct maple_enode *mn,\n\t\t\t\t unsigned char gap, unsigned long val)\n{\n\tswitch (mte_node_type(mn)) {\n\tdefault:\n\t\tbreak;\n\tcase maple_arange_64:\n\t\tmte_to_node(mn)->ma64.gap[gap] = val;\n\t\tbreak;\n\t}\n}\n\n \nstatic int mas_ascend(struct ma_state *mas)\n{\n\tstruct maple_enode *p_enode;  \n\tstruct maple_enode *a_enode;  \n\tstruct maple_node *a_node;  \n\tstruct maple_node *p_node;  \n\tunsigned char a_slot;\n\tenum maple_type a_type;\n\tunsigned long min, max;\n\tunsigned long *pivots;\n\tbool set_max = false, set_min = false;\n\n\ta_node = mas_mn(mas);\n\tif (ma_is_root(a_node)) {\n\t\tmas->offset = 0;\n\t\treturn 0;\n\t}\n\n\tp_node = mte_parent(mas->node);\n\tif (unlikely(a_node == p_node))\n\t\treturn 1;\n\n\ta_type = mas_parent_type(mas, mas->node);\n\tmas->offset = mte_parent_slot(mas->node);\n\ta_enode = mt_mk_node(p_node, a_type);\n\n\t \n\tif (p_node != mte_parent(mas->node))\n\t\treturn 1;\n\n\tmas->node = a_enode;\n\n\tif (mte_is_root(a_enode)) {\n\t\tmas->max = ULONG_MAX;\n\t\tmas->min = 0;\n\t\treturn 0;\n\t}\n\n\tif (!mas->min)\n\t\tset_min = true;\n\n\tif (mas->max == ULONG_MAX)\n\t\tset_max = true;\n\n\tmin = 0;\n\tmax = ULONG_MAX;\n\tdo {\n\t\tp_enode = a_enode;\n\t\ta_type = mas_parent_type(mas, p_enode);\n\t\ta_node = mte_parent(p_enode);\n\t\ta_slot = mte_parent_slot(p_enode);\n\t\ta_enode = mt_mk_node(a_node, a_type);\n\t\tpivots = ma_pivots(a_node, a_type);\n\n\t\tif (unlikely(ma_dead_node(a_node)))\n\t\t\treturn 1;\n\n\t\tif (!set_min && a_slot) {\n\t\t\tset_min = true;\n\t\t\tmin = pivots[a_slot - 1] + 1;\n\t\t}\n\n\t\tif (!set_max && a_slot < mt_pivots[a_type]) {\n\t\t\tset_max = true;\n\t\t\tmax = pivots[a_slot];\n\t\t}\n\n\t\tif (unlikely(ma_dead_node(a_node)))\n\t\t\treturn 1;\n\n\t\tif (unlikely(ma_is_root(a_node)))\n\t\t\tbreak;\n\n\t} while (!set_min || !set_max);\n\n\tmas->max = max;\n\tmas->min = min;\n\treturn 0;\n}\n\n \nstatic inline struct maple_node *mas_pop_node(struct ma_state *mas)\n{\n\tstruct maple_alloc *ret, *node = mas->alloc;\n\tunsigned long total = mas_allocated(mas);\n\tunsigned int req = mas_alloc_req(mas);\n\n\t \n\tif (WARN_ON(!total))\n\t\treturn NULL;\n\n\tif (total == 1) {\n\t\t \n\t\tmas->alloc = NULL;\n\t\tret = node;\n\t\tgoto single_node;\n\t}\n\n\tif (node->node_count == 1) {\n\t\t \n\t\tmas->alloc = node->slot[0];\n\t\tmas->alloc->total = node->total - 1;\n\t\tret = node;\n\t\tgoto new_head;\n\t}\n\tnode->total--;\n\tret = node->slot[--node->node_count];\n\tnode->slot[node->node_count] = NULL;\n\nsingle_node:\nnew_head:\n\tif (req) {\n\t\treq++;\n\t\tmas_set_alloc_req(mas, req);\n\t}\n\n\tmemset(ret, 0, sizeof(*ret));\n\treturn (struct maple_node *)ret;\n}\n\n \nstatic inline void mas_push_node(struct ma_state *mas, struct maple_node *used)\n{\n\tstruct maple_alloc *reuse = (struct maple_alloc *)used;\n\tstruct maple_alloc *head = mas->alloc;\n\tunsigned long count;\n\tunsigned int requested = mas_alloc_req(mas);\n\n\tcount = mas_allocated(mas);\n\n\treuse->request_count = 0;\n\treuse->node_count = 0;\n\tif (count && (head->node_count < MAPLE_ALLOC_SLOTS)) {\n\t\thead->slot[head->node_count++] = reuse;\n\t\thead->total++;\n\t\tgoto done;\n\t}\n\n\treuse->total = 1;\n\tif ((head) && !((unsigned long)head & 0x1)) {\n\t\treuse->slot[0] = head;\n\t\treuse->node_count = 1;\n\t\treuse->total += head->total;\n\t}\n\n\tmas->alloc = reuse;\ndone:\n\tif (requested > 1)\n\t\tmas_set_alloc_req(mas, requested - 1);\n}\n\n \nstatic inline void mas_alloc_nodes(struct ma_state *mas, gfp_t gfp)\n{\n\tstruct maple_alloc *node;\n\tunsigned long allocated = mas_allocated(mas);\n\tunsigned int requested = mas_alloc_req(mas);\n\tunsigned int count;\n\tvoid **slots = NULL;\n\tunsigned int max_req = 0;\n\n\tif (!requested)\n\t\treturn;\n\n\tmas_set_alloc_req(mas, 0);\n\tif (mas->mas_flags & MA_STATE_PREALLOC) {\n\t\tif (allocated)\n\t\t\treturn;\n\t\tWARN_ON(!allocated);\n\t}\n\n\tif (!allocated || mas->alloc->node_count == MAPLE_ALLOC_SLOTS) {\n\t\tnode = (struct maple_alloc *)mt_alloc_one(gfp);\n\t\tif (!node)\n\t\t\tgoto nomem_one;\n\n\t\tif (allocated) {\n\t\t\tnode->slot[0] = mas->alloc;\n\t\t\tnode->node_count = 1;\n\t\t} else {\n\t\t\tnode->node_count = 0;\n\t\t}\n\n\t\tmas->alloc = node;\n\t\tnode->total = ++allocated;\n\t\trequested--;\n\t}\n\n\tnode = mas->alloc;\n\tnode->request_count = 0;\n\twhile (requested) {\n\t\tmax_req = MAPLE_ALLOC_SLOTS - node->node_count;\n\t\tslots = (void **)&node->slot[node->node_count];\n\t\tmax_req = min(requested, max_req);\n\t\tcount = mt_alloc_bulk(gfp, max_req, slots);\n\t\tif (!count)\n\t\t\tgoto nomem_bulk;\n\n\t\tif (node->node_count == 0) {\n\t\t\tnode->slot[0]->node_count = 0;\n\t\t\tnode->slot[0]->request_count = 0;\n\t\t}\n\n\t\tnode->node_count += count;\n\t\tallocated += count;\n\t\tnode = node->slot[0];\n\t\trequested -= count;\n\t}\n\tmas->alloc->total = allocated;\n\treturn;\n\nnomem_bulk:\n\t \n\tmemset(slots, 0, max_req * sizeof(unsigned long));\nnomem_one:\n\tmas_set_alloc_req(mas, requested);\n\tif (mas->alloc && !(((unsigned long)mas->alloc & 0x1)))\n\t\tmas->alloc->total = allocated;\n\tmas_set_err(mas, -ENOMEM);\n}\n\n \nstatic inline void mas_free(struct ma_state *mas, struct maple_enode *used)\n{\n\tstruct maple_node *tmp = mte_to_node(used);\n\n\tif (mt_in_rcu(mas->tree))\n\t\tma_free_rcu(tmp);\n\telse\n\t\tmas_push_node(mas, tmp);\n}\n\n \nstatic void mas_node_count_gfp(struct ma_state *mas, int count, gfp_t gfp)\n{\n\tunsigned long allocated = mas_allocated(mas);\n\n\tif (allocated < count) {\n\t\tmas_set_alloc_req(mas, count - allocated);\n\t\tmas_alloc_nodes(mas, gfp);\n\t}\n}\n\n \nstatic void mas_node_count(struct ma_state *mas, int count)\n{\n\treturn mas_node_count_gfp(mas, count, GFP_NOWAIT | __GFP_NOWARN);\n}\n\n \nstatic inline struct maple_enode *mas_start(struct ma_state *mas)\n{\n\tif (likely(mas_is_start(mas))) {\n\t\tstruct maple_enode *root;\n\n\t\tmas->min = 0;\n\t\tmas->max = ULONG_MAX;\n\nretry:\n\t\tmas->depth = 0;\n\t\troot = mas_root(mas);\n\t\t \n\t\tif (likely(xa_is_node(root))) {\n\t\t\tmas->depth = 1;\n\t\t\tmas->node = mte_safe_root(root);\n\t\t\tmas->offset = 0;\n\t\t\tif (mte_dead_node(mas->node))\n\t\t\t\tgoto retry;\n\n\t\t\treturn NULL;\n\t\t}\n\n\t\t \n\t\tif (unlikely(!root)) {\n\t\t\tmas->node = MAS_NONE;\n\t\t\tmas->offset = MAPLE_NODE_SLOTS;\n\t\t\treturn NULL;\n\t\t}\n\n\t\t \n\t\tmas->node = MAS_ROOT;\n\t\tmas->offset = MAPLE_NODE_SLOTS;\n\n\t\t \n\t\tif (mas->index > 0)\n\t\t\treturn NULL;\n\n\t\treturn root;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic inline unsigned char ma_data_end(struct maple_node *node,\n\t\t\t\t\tenum maple_type type,\n\t\t\t\t\tunsigned long *pivots,\n\t\t\t\t\tunsigned long max)\n{\n\tunsigned char offset;\n\n\tif (!pivots)\n\t\treturn 0;\n\n\tif (type == maple_arange_64)\n\t\treturn ma_meta_end(node, type);\n\n\toffset = mt_pivots[type] - 1;\n\tif (likely(!pivots[offset]))\n\t\treturn ma_meta_end(node, type);\n\n\tif (likely(pivots[offset] == max))\n\t\treturn offset;\n\n\treturn mt_pivots[type];\n}\n\n \nstatic inline unsigned char mas_data_end(struct ma_state *mas)\n{\n\tenum maple_type type;\n\tstruct maple_node *node;\n\tunsigned char offset;\n\tunsigned long *pivots;\n\n\ttype = mte_node_type(mas->node);\n\tnode = mas_mn(mas);\n\tif (type == maple_arange_64)\n\t\treturn ma_meta_end(node, type);\n\n\tpivots = ma_pivots(node, type);\n\tif (unlikely(ma_dead_node(node)))\n\t\treturn 0;\n\n\toffset = mt_pivots[type] - 1;\n\tif (likely(!pivots[offset]))\n\t\treturn ma_meta_end(node, type);\n\n\tif (likely(pivots[offset] == mas->max))\n\t\treturn offset;\n\n\treturn mt_pivots[type];\n}\n\n \nstatic unsigned long mas_leaf_max_gap(struct ma_state *mas)\n{\n\tenum maple_type mt;\n\tunsigned long pstart, gap, max_gap;\n\tstruct maple_node *mn;\n\tunsigned long *pivots;\n\tvoid __rcu **slots;\n\tunsigned char i;\n\tunsigned char max_piv;\n\n\tmt = mte_node_type(mas->node);\n\tmn = mas_mn(mas);\n\tslots = ma_slots(mn, mt);\n\tmax_gap = 0;\n\tif (unlikely(ma_is_dense(mt))) {\n\t\tgap = 0;\n\t\tfor (i = 0; i < mt_slots[mt]; i++) {\n\t\t\tif (slots[i]) {\n\t\t\t\tif (gap > max_gap)\n\t\t\t\t\tmax_gap = gap;\n\t\t\t\tgap = 0;\n\t\t\t} else {\n\t\t\t\tgap++;\n\t\t\t}\n\t\t}\n\t\tif (gap > max_gap)\n\t\t\tmax_gap = gap;\n\t\treturn max_gap;\n\t}\n\n\t \n\tpivots = ma_pivots(mn, mt);\n\tif (likely(!slots[0])) {\n\t\tmax_gap = pivots[0] - mas->min + 1;\n\t\ti = 2;\n\t} else {\n\t\ti = 1;\n\t}\n\n\t \n\tmax_piv = ma_data_end(mn, mt, pivots, mas->max) - 1;\n\t \n\tif (unlikely(mas->max == ULONG_MAX) && !slots[max_piv + 1]) {\n\t\tgap = ULONG_MAX - pivots[max_piv];\n\t\tif (gap > max_gap)\n\t\t\tmax_gap = gap;\n\t}\n\n\tfor (; i <= max_piv; i++) {\n\t\t \n\t\tif (likely(slots[i]))\n\t\t\tcontinue;\n\n\t\tpstart = pivots[i - 1];\n\t\tgap = pivots[i] - pstart;\n\t\tif (gap > max_gap)\n\t\t\tmax_gap = gap;\n\n\t\t \n\t\ti++;\n\t}\n\treturn max_gap;\n}\n\n \nstatic inline unsigned long\nma_max_gap(struct maple_node *node, unsigned long *gaps, enum maple_type mt,\n\t    unsigned char *off)\n{\n\tunsigned char offset, i;\n\tunsigned long max_gap = 0;\n\n\ti = offset = ma_meta_end(node, mt);\n\tdo {\n\t\tif (gaps[i] > max_gap) {\n\t\t\tmax_gap = gaps[i];\n\t\t\toffset = i;\n\t\t}\n\t} while (i--);\n\n\t*off = offset;\n\treturn max_gap;\n}\n\n \nstatic inline unsigned long mas_max_gap(struct ma_state *mas)\n{\n\tunsigned long *gaps;\n\tunsigned char offset;\n\tenum maple_type mt;\n\tstruct maple_node *node;\n\n\tmt = mte_node_type(mas->node);\n\tif (ma_is_leaf(mt))\n\t\treturn mas_leaf_max_gap(mas);\n\n\tnode = mas_mn(mas);\n\tMAS_BUG_ON(mas, mt != maple_arange_64);\n\toffset = ma_meta_gap(node, mt);\n\tgaps = ma_gaps(node, mt);\n\treturn gaps[offset];\n}\n\n \nstatic inline void mas_parent_gap(struct ma_state *mas, unsigned char offset,\n\t\tunsigned long new)\n{\n\tunsigned long meta_gap = 0;\n\tstruct maple_node *pnode;\n\tstruct maple_enode *penode;\n\tunsigned long *pgaps;\n\tunsigned char meta_offset;\n\tenum maple_type pmt;\n\n\tpnode = mte_parent(mas->node);\n\tpmt = mas_parent_type(mas, mas->node);\n\tpenode = mt_mk_node(pnode, pmt);\n\tpgaps = ma_gaps(pnode, pmt);\n\nascend:\n\tMAS_BUG_ON(mas, pmt != maple_arange_64);\n\tmeta_offset = ma_meta_gap(pnode, pmt);\n\tmeta_gap = pgaps[meta_offset];\n\n\tpgaps[offset] = new;\n\n\tif (meta_gap == new)\n\t\treturn;\n\n\tif (offset != meta_offset) {\n\t\tif (meta_gap > new)\n\t\t\treturn;\n\n\t\tma_set_meta_gap(pnode, pmt, offset);\n\t} else if (new < meta_gap) {\n\t\tnew = ma_max_gap(pnode, pgaps, pmt, &meta_offset);\n\t\tma_set_meta_gap(pnode, pmt, meta_offset);\n\t}\n\n\tif (ma_is_root(pnode))\n\t\treturn;\n\n\t \n\tpnode = mte_parent(penode);\n\tpmt = mas_parent_type(mas, penode);\n\tpgaps = ma_gaps(pnode, pmt);\n\toffset = mte_parent_slot(penode);\n\tpenode = mt_mk_node(pnode, pmt);\n\tgoto ascend;\n}\n\n \nstatic inline void mas_update_gap(struct ma_state *mas)\n{\n\tunsigned char pslot;\n\tunsigned long p_gap;\n\tunsigned long max_gap;\n\n\tif (!mt_is_alloc(mas->tree))\n\t\treturn;\n\n\tif (mte_is_root(mas->node))\n\t\treturn;\n\n\tmax_gap = mas_max_gap(mas);\n\n\tpslot = mte_parent_slot(mas->node);\n\tp_gap = ma_gaps(mte_parent(mas->node),\n\t\t\tmas_parent_type(mas, mas->node))[pslot];\n\n\tif (p_gap != max_gap)\n\t\tmas_parent_gap(mas, pslot, max_gap);\n}\n\n \nstatic inline void mas_adopt_children(struct ma_state *mas,\n\t\tstruct maple_enode *parent)\n{\n\tenum maple_type type = mte_node_type(parent);\n\tstruct maple_node *node = mte_to_node(parent);\n\tvoid __rcu **slots = ma_slots(node, type);\n\tunsigned long *pivots = ma_pivots(node, type);\n\tstruct maple_enode *child;\n\tunsigned char offset;\n\n\toffset = ma_data_end(node, type, pivots, mas->max);\n\tdo {\n\t\tchild = mas_slot_locked(mas, slots, offset);\n\t\tmas_set_parent(mas, child, parent, offset);\n\t} while (offset--);\n}\n\n \nstatic inline void mas_put_in_tree(struct ma_state *mas,\n\t\tstruct maple_enode *old_enode)\n\t__must_hold(mas->tree->ma_lock)\n{\n\tunsigned char offset;\n\tvoid __rcu **slots;\n\n\tif (mte_is_root(mas->node)) {\n\t\tmas_mn(mas)->parent = ma_parent_ptr(mas_tree_parent(mas));\n\t\trcu_assign_pointer(mas->tree->ma_root, mte_mk_root(mas->node));\n\t\tmas_set_height(mas);\n\t} else {\n\n\t\toffset = mte_parent_slot(mas->node);\n\t\tslots = ma_slots(mte_parent(mas->node),\n\t\t\t\t mas_parent_type(mas, mas->node));\n\t\trcu_assign_pointer(slots[offset], mas->node);\n\t}\n\n\tmte_set_node_dead(old_enode);\n}\n\n \nstatic inline void mas_replace_node(struct ma_state *mas,\n\t\tstruct maple_enode *old_enode)\n\t__must_hold(mas->tree->ma_lock)\n{\n\tmas_put_in_tree(mas, old_enode);\n\tmas_free(mas, old_enode);\n}\n\n \nstatic inline bool mas_find_child(struct ma_state *mas, struct ma_state *child)\n\t__must_hold(mas->tree->ma_lock)\n{\n\tenum maple_type mt;\n\tunsigned char offset;\n\tunsigned char end;\n\tunsigned long *pivots;\n\tstruct maple_enode *entry;\n\tstruct maple_node *node;\n\tvoid __rcu **slots;\n\n\tmt = mte_node_type(mas->node);\n\tnode = mas_mn(mas);\n\tslots = ma_slots(node, mt);\n\tpivots = ma_pivots(node, mt);\n\tend = ma_data_end(node, mt, pivots, mas->max);\n\tfor (offset = mas->offset; offset <= end; offset++) {\n\t\tentry = mas_slot_locked(mas, slots, offset);\n\t\tif (mte_parent(entry) == node) {\n\t\t\t*child = *mas;\n\t\t\tmas->offset = offset + 1;\n\t\t\tchild->offset = offset;\n\t\t\tmas_descend(child);\n\t\t\tchild->offset = 0;\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\n \nstatic inline void mab_shift_right(struct maple_big_node *b_node,\n\t\t\t\t unsigned char shift)\n{\n\tunsigned long size = b_node->b_end * sizeof(unsigned long);\n\n\tmemmove(b_node->pivot + shift, b_node->pivot, size);\n\tmemmove(b_node->slot + shift, b_node->slot, size);\n\tif (b_node->type == maple_arange_64)\n\t\tmemmove(b_node->gap + shift, b_node->gap, size);\n}\n\n \nstatic inline bool mab_middle_node(struct maple_big_node *b_node, int split,\n\t\t\t\t   unsigned char slot_count)\n{\n\tunsigned char size = b_node->b_end;\n\n\tif (size >= 2 * slot_count)\n\t\treturn true;\n\n\tif (!b_node->slot[split] && (size >= 2 * slot_count - 1))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic inline int mab_no_null_split(struct maple_big_node *b_node,\n\t\t\t\t    unsigned char split, unsigned char slot_count)\n{\n\tif (!b_node->slot[split]) {\n\t\t \n\t\tif ((split < slot_count - 1) &&\n\t\t    (b_node->b_end - split) > (mt_min_slots[b_node->type]))\n\t\t\tsplit++;\n\t\telse\n\t\t\tsplit--;\n\t}\n\treturn split;\n}\n\n \nstatic inline int mab_calc_split(struct ma_state *mas,\n\t struct maple_big_node *bn, unsigned char *mid_split, unsigned long min)\n{\n\tunsigned char b_end = bn->b_end;\n\tint split = b_end / 2;  \n\tunsigned char slot_min, slot_count = mt_slots[bn->type];\n\n\t \n\tif (unlikely((mas->mas_flags & MA_STATE_BULK))) {\n\t\t*mid_split = 0;\n\t\tsplit = b_end - mt_min_slots[bn->type];\n\n\t\tif (!ma_is_leaf(bn->type))\n\t\t\treturn split;\n\n\t\tmas->mas_flags |= MA_STATE_REBALANCE;\n\t\tif (!bn->slot[split])\n\t\t\tsplit--;\n\t\treturn split;\n\t}\n\n\t \n\tif (unlikely(mab_middle_node(bn, split, slot_count))) {\n\t\tsplit = b_end / 3;\n\t\t*mid_split = split * 2;\n\t} else {\n\t\tslot_min = mt_min_slots[bn->type];\n\n\t\t*mid_split = 0;\n\t\t \n\t\twhile ((split < slot_count - 1) &&\n\t\t       ((bn->pivot[split] - min) < slot_count - 1) &&\n\t\t       (b_end - split > slot_min))\n\t\t\tsplit++;\n\t}\n\n\t \n\tsplit = mab_no_null_split(bn, split, slot_count);\n\n\tif (unlikely(*mid_split))\n\t\t*mid_split = mab_no_null_split(bn, *mid_split, slot_count);\n\n\treturn split;\n}\n\n \nstatic inline void mas_mab_cp(struct ma_state *mas, unsigned char mas_start,\n\t\t\tunsigned char mas_end, struct maple_big_node *b_node,\n\t\t\tunsigned char mab_start)\n{\n\tenum maple_type mt;\n\tstruct maple_node *node;\n\tvoid __rcu **slots;\n\tunsigned long *pivots, *gaps;\n\tint i = mas_start, j = mab_start;\n\tunsigned char piv_end;\n\n\tnode = mas_mn(mas);\n\tmt = mte_node_type(mas->node);\n\tpivots = ma_pivots(node, mt);\n\tif (!i) {\n\t\tb_node->pivot[j] = pivots[i++];\n\t\tif (unlikely(i > mas_end))\n\t\t\tgoto complete;\n\t\tj++;\n\t}\n\n\tpiv_end = min(mas_end, mt_pivots[mt]);\n\tfor (; i < piv_end; i++, j++) {\n\t\tb_node->pivot[j] = pivots[i];\n\t\tif (unlikely(!b_node->pivot[j]))\n\t\t\tbreak;\n\n\t\tif (unlikely(mas->max == b_node->pivot[j]))\n\t\t\tgoto complete;\n\t}\n\n\tif (likely(i <= mas_end))\n\t\tb_node->pivot[j] = mas_safe_pivot(mas, pivots, i, mt);\n\ncomplete:\n\tb_node->b_end = ++j;\n\tj -= mab_start;\n\tslots = ma_slots(node, mt);\n\tmemcpy(b_node->slot + mab_start, slots + mas_start, sizeof(void *) * j);\n\tif (!ma_is_leaf(mt) && mt_is_alloc(mas->tree)) {\n\t\tgaps = ma_gaps(node, mt);\n\t\tmemcpy(b_node->gap + mab_start, gaps + mas_start,\n\t\t       sizeof(unsigned long) * j);\n\t}\n}\n\n \nstatic inline void mas_leaf_set_meta(struct ma_state *mas,\n\t\tstruct maple_node *node, unsigned long *pivots,\n\t\tenum maple_type mt, unsigned char end)\n{\n\t \n\tif (mt_pivots[mt] <= end)\n\t\treturn;\n\n\tif (pivots[end] && pivots[end] < mas->max)\n\t\tend++;\n\n\tif (end < mt_slots[mt] - 1)\n\t\tma_set_meta(node, mt, 0, end);\n}\n\n \nstatic inline void mab_mas_cp(struct maple_big_node *b_node,\n\t\t\t      unsigned char mab_start, unsigned char mab_end,\n\t\t\t      struct ma_state *mas, bool new_max)\n{\n\tint i, j = 0;\n\tenum maple_type mt = mte_node_type(mas->node);\n\tstruct maple_node *node = mte_to_node(mas->node);\n\tvoid __rcu **slots = ma_slots(node, mt);\n\tunsigned long *pivots = ma_pivots(node, mt);\n\tunsigned long *gaps = NULL;\n\tunsigned char end;\n\n\tif (mab_end - mab_start > mt_pivots[mt])\n\t\tmab_end--;\n\n\tif (!pivots[mt_pivots[mt] - 1])\n\t\tslots[mt_pivots[mt]] = NULL;\n\n\ti = mab_start;\n\tdo {\n\t\tpivots[j++] = b_node->pivot[i++];\n\t} while (i <= mab_end && likely(b_node->pivot[i]));\n\n\tmemcpy(slots, b_node->slot + mab_start,\n\t       sizeof(void *) * (i - mab_start));\n\n\tif (new_max)\n\t\tmas->max = b_node->pivot[i - 1];\n\n\tend = j - 1;\n\tif (likely(!ma_is_leaf(mt) && mt_is_alloc(mas->tree))) {\n\t\tunsigned long max_gap = 0;\n\t\tunsigned char offset = 0;\n\n\t\tgaps = ma_gaps(node, mt);\n\t\tdo {\n\t\t\tgaps[--j] = b_node->gap[--i];\n\t\t\tif (gaps[j] > max_gap) {\n\t\t\t\toffset = j;\n\t\t\t\tmax_gap = gaps[j];\n\t\t\t}\n\t\t} while (j);\n\n\t\tma_set_meta(node, mt, offset, end);\n\t} else {\n\t\tmas_leaf_set_meta(mas, node, pivots, mt, end);\n\t}\n}\n\n \nstatic inline void mas_bulk_rebalance(struct ma_state *mas, unsigned char end,\n\t\t\t\t      enum maple_type mt)\n{\n\tif (!(mas->mas_flags & MA_STATE_BULK))\n\t\treturn;\n\n\tif (mte_is_root(mas->node))\n\t\treturn;\n\n\tif (end > mt_min_slots[mt]) {\n\t\tmas->mas_flags &= ~MA_STATE_REBALANCE;\n\t\treturn;\n\t}\n}\n\n \nstatic noinline_for_kasan void mas_store_b_node(struct ma_wr_state *wr_mas,\n\t\tstruct maple_big_node *b_node, unsigned char offset_end)\n{\n\tunsigned char slot;\n\tunsigned char b_end;\n\t \n\tunsigned long piv;\n\tstruct ma_state *mas = wr_mas->mas;\n\n\tb_node->type = wr_mas->type;\n\tb_end = 0;\n\tslot = mas->offset;\n\tif (slot) {\n\t\t \n\t\tmas_mab_cp(mas, 0, slot - 1, b_node, 0);\n\t\tb_end = b_node->b_end;\n\t\tpiv = b_node->pivot[b_end - 1];\n\t} else\n\t\tpiv = mas->min - 1;\n\n\tif (piv + 1 < mas->index) {\n\t\t \n\t\tb_node->slot[b_end] = wr_mas->content;\n\t\tif (!wr_mas->content)\n\t\t\tb_node->gap[b_end] = mas->index - 1 - piv;\n\t\tb_node->pivot[b_end++] = mas->index - 1;\n\t}\n\n\t \n\tmas->offset = b_end;\n\tb_node->slot[b_end] = wr_mas->entry;\n\tb_node->pivot[b_end] = mas->last;\n\n\t \n\tif (mas->last >= mas->max)\n\t\tgoto b_end;\n\n\t \n\tpiv = mas_safe_pivot(mas, wr_mas->pivots, offset_end, wr_mas->type);\n\tif (piv > mas->last) {\n\t\tif (piv == ULONG_MAX)\n\t\t\tmas_bulk_rebalance(mas, b_node->b_end, wr_mas->type);\n\n\t\tif (offset_end != slot)\n\t\t\twr_mas->content = mas_slot_locked(mas, wr_mas->slots,\n\t\t\t\t\t\t\t  offset_end);\n\n\t\tb_node->slot[++b_end] = wr_mas->content;\n\t\tif (!wr_mas->content)\n\t\t\tb_node->gap[b_end] = piv - mas->last + 1;\n\t\tb_node->pivot[b_end] = piv;\n\t}\n\n\tslot = offset_end + 1;\n\tif (slot > wr_mas->node_end)\n\t\tgoto b_end;\n\n\t \n\tmas_mab_cp(mas, slot, wr_mas->node_end + 1, b_node, ++b_end);\n\tb_node->b_end--;\n\treturn;\n\nb_end:\n\tb_node->b_end = b_end;\n}\n\n \nstatic inline bool mas_prev_sibling(struct ma_state *mas)\n{\n\tunsigned int p_slot = mte_parent_slot(mas->node);\n\n\tif (mte_is_root(mas->node))\n\t\treturn false;\n\n\tif (!p_slot)\n\t\treturn false;\n\n\tmas_ascend(mas);\n\tmas->offset = p_slot - 1;\n\tmas_descend(mas);\n\treturn true;\n}\n\n \nstatic inline bool mas_next_sibling(struct ma_state *mas)\n{\n\tMA_STATE(parent, mas->tree, mas->index, mas->last);\n\n\tif (mte_is_root(mas->node))\n\t\treturn false;\n\n\tparent = *mas;\n\tmas_ascend(&parent);\n\tparent.offset = mte_parent_slot(mas->node) + 1;\n\tif (parent.offset > mas_data_end(&parent))\n\t\treturn false;\n\n\t*mas = parent;\n\tmas_descend(mas);\n\treturn true;\n}\n\n \nstatic inline struct maple_enode *mte_node_or_none(struct maple_enode *enode)\n{\n\tif (enode)\n\t\treturn enode;\n\n\treturn ma_enode_ptr(MAS_NONE);\n}\n\n \nstatic inline void mas_wr_node_walk(struct ma_wr_state *wr_mas)\n{\n\tstruct ma_state *mas = wr_mas->mas;\n\tunsigned char count, offset;\n\n\tif (unlikely(ma_is_dense(wr_mas->type))) {\n\t\twr_mas->r_max = wr_mas->r_min = mas->index;\n\t\tmas->offset = mas->index = mas->min;\n\t\treturn;\n\t}\n\n\twr_mas->node = mas_mn(wr_mas->mas);\n\twr_mas->pivots = ma_pivots(wr_mas->node, wr_mas->type);\n\tcount = wr_mas->node_end = ma_data_end(wr_mas->node, wr_mas->type,\n\t\t\t\t\t       wr_mas->pivots, mas->max);\n\toffset = mas->offset;\n\n\twhile (offset < count && mas->index > wr_mas->pivots[offset])\n\t\toffset++;\n\n\twr_mas->r_max = offset < count ? wr_mas->pivots[offset] : mas->max;\n\twr_mas->r_min = mas_safe_min(mas, wr_mas->pivots, offset);\n\twr_mas->offset_end = mas->offset = offset;\n}\n\n \nstatic inline void mast_rebalance_next(struct maple_subtree_state *mast)\n{\n\tunsigned char b_end = mast->bn->b_end;\n\n\tmas_mab_cp(mast->orig_r, 0, mt_slot_count(mast->orig_r->node),\n\t\t   mast->bn, b_end);\n\tmast->orig_r->last = mast->orig_r->max;\n}\n\n \nstatic inline void mast_rebalance_prev(struct maple_subtree_state *mast)\n{\n\tunsigned char end = mas_data_end(mast->orig_l) + 1;\n\tunsigned char b_end = mast->bn->b_end;\n\n\tmab_shift_right(mast->bn, end);\n\tmas_mab_cp(mast->orig_l, 0, end - 1, mast->bn, 0);\n\tmast->l->min = mast->orig_l->min;\n\tmast->orig_l->index = mast->orig_l->min;\n\tmast->bn->b_end = end + b_end;\n\tmast->l->offset += end;\n}\n\n \nstatic inline\nbool mast_spanning_rebalance(struct maple_subtree_state *mast)\n{\n\tstruct ma_state r_tmp = *mast->orig_r;\n\tstruct ma_state l_tmp = *mast->orig_l;\n\tunsigned char depth = 0;\n\n\tr_tmp = *mast->orig_r;\n\tl_tmp = *mast->orig_l;\n\tdo {\n\t\tmas_ascend(mast->orig_r);\n\t\tmas_ascend(mast->orig_l);\n\t\tdepth++;\n\t\tif (mast->orig_r->offset < mas_data_end(mast->orig_r)) {\n\t\t\tmast->orig_r->offset++;\n\t\t\tdo {\n\t\t\t\tmas_descend(mast->orig_r);\n\t\t\t\tmast->orig_r->offset = 0;\n\t\t\t} while (--depth);\n\n\t\t\tmast_rebalance_next(mast);\n\t\t\t*mast->orig_l = l_tmp;\n\t\t\treturn true;\n\t\t} else if (mast->orig_l->offset != 0) {\n\t\t\tmast->orig_l->offset--;\n\t\t\tdo {\n\t\t\t\tmas_descend(mast->orig_l);\n\t\t\t\tmast->orig_l->offset =\n\t\t\t\t\tmas_data_end(mast->orig_l);\n\t\t\t} while (--depth);\n\n\t\t\tmast_rebalance_prev(mast);\n\t\t\t*mast->orig_r = r_tmp;\n\t\t\treturn true;\n\t\t}\n\t} while (!mte_is_root(mast->orig_r->node));\n\n\t*mast->orig_r = r_tmp;\n\t*mast->orig_l = l_tmp;\n\treturn false;\n}\n\n \nstatic inline void mast_ascend(struct maple_subtree_state *mast)\n{\n\tMA_WR_STATE(wr_mas, mast->orig_r,  NULL);\n\tmas_ascend(mast->orig_l);\n\tmas_ascend(mast->orig_r);\n\n\tmast->orig_r->offset = 0;\n\tmast->orig_r->index = mast->r->max;\n\t \n\tif (mast->orig_r->last < mast->orig_r->index)\n\t\tmast->orig_r->last = mast->orig_r->index;\n\n\twr_mas.type = mte_node_type(mast->orig_r->node);\n\tmas_wr_node_walk(&wr_mas);\n\t \n\tmast->orig_l->offset = 0;\n\tmast->orig_l->index = mast->l->min;\n\twr_mas.mas = mast->orig_l;\n\twr_mas.type = mte_node_type(mast->orig_l->node);\n\tmas_wr_node_walk(&wr_mas);\n\n\tmast->bn->type = wr_mas.type;\n}\n\n \nstatic inline struct maple_enode\n*mas_new_ma_node(struct ma_state *mas, struct maple_big_node *b_node)\n{\n\treturn mt_mk_node(ma_mnode_ptr(mas_pop_node(mas)), b_node->type);\n}\n\n \nstatic inline unsigned char mas_mab_to_node(struct ma_state *mas,\n\tstruct maple_big_node *b_node, struct maple_enode **left,\n\tstruct maple_enode **right, struct maple_enode **middle,\n\tunsigned char *mid_split, unsigned long min)\n{\n\tunsigned char split = 0;\n\tunsigned char slot_count = mt_slots[b_node->type];\n\n\t*left = mas_new_ma_node(mas, b_node);\n\t*right = NULL;\n\t*middle = NULL;\n\t*mid_split = 0;\n\n\tif (b_node->b_end < slot_count) {\n\t\tsplit = b_node->b_end;\n\t} else {\n\t\tsplit = mab_calc_split(mas, b_node, mid_split, min);\n\t\t*right = mas_new_ma_node(mas, b_node);\n\t}\n\n\tif (*mid_split)\n\t\t*middle = mas_new_ma_node(mas, b_node);\n\n\treturn split;\n\n}\n\n \nstatic inline void mab_set_b_end(struct maple_big_node *b_node,\n\t\t\t\t struct ma_state *mas,\n\t\t\t\t void *entry)\n{\n\tif (!entry)\n\t\treturn;\n\n\tb_node->slot[b_node->b_end] = entry;\n\tif (mt_is_alloc(mas->tree))\n\t\tb_node->gap[b_node->b_end] = mas_max_gap(mas);\n\tb_node->pivot[b_node->b_end++] = mas->max;\n}\n\n \nstatic inline void mas_set_split_parent(struct ma_state *mas,\n\t\t\t\t\tstruct maple_enode *left,\n\t\t\t\t\tstruct maple_enode *right,\n\t\t\t\t\tunsigned char *slot, unsigned char split)\n{\n\tif (mas_is_none(mas))\n\t\treturn;\n\n\tif ((*slot) <= split)\n\t\tmas_set_parent(mas, mas->node, left, *slot);\n\telse if (right)\n\t\tmas_set_parent(mas, mas->node, right, (*slot) - split - 1);\n\n\t(*slot)++;\n}\n\n \nstatic inline void mte_mid_split_check(struct maple_enode **l,\n\t\t\t\t       struct maple_enode **r,\n\t\t\t\t       struct maple_enode *right,\n\t\t\t\t       unsigned char slot,\n\t\t\t\t       unsigned char *split,\n\t\t\t\t       unsigned char mid_split)\n{\n\tif (*r == right)\n\t\treturn;\n\n\tif (slot < mid_split)\n\t\treturn;\n\n\t*l = *r;\n\t*r = right;\n\t*split = mid_split;\n}\n\n \nstatic inline void mast_set_split_parents(struct maple_subtree_state *mast,\n\t\t\t\t\t  struct maple_enode *left,\n\t\t\t\t\t  struct maple_enode *middle,\n\t\t\t\t\t  struct maple_enode *right,\n\t\t\t\t\t  unsigned char split,\n\t\t\t\t\t  unsigned char mid_split)\n{\n\tunsigned char slot;\n\tstruct maple_enode *l = left;\n\tstruct maple_enode *r = right;\n\n\tif (mas_is_none(mast->l))\n\t\treturn;\n\n\tif (middle)\n\t\tr = middle;\n\n\tslot = mast->l->offset;\n\n\tmte_mid_split_check(&l, &r, right, slot, &split, mid_split);\n\tmas_set_split_parent(mast->l, l, r, &slot, split);\n\n\tmte_mid_split_check(&l, &r, right, slot, &split, mid_split);\n\tmas_set_split_parent(mast->m, l, r, &slot, split);\n\n\tmte_mid_split_check(&l, &r, right, slot, &split, mid_split);\n\tmas_set_split_parent(mast->r, l, r, &slot, split);\n}\n\n \nstatic inline void mas_topiary_node(struct ma_state *mas,\n\t\tstruct maple_enode *enode, bool in_rcu)\n{\n\tstruct maple_node *tmp;\n\n\tif (enode == MAS_NONE)\n\t\treturn;\n\n\ttmp = mte_to_node(enode);\n\tmte_set_node_dead(enode);\n\tif (in_rcu)\n\t\tma_free_rcu(tmp);\n\telse\n\t\tmas_push_node(mas, tmp);\n}\n\n \nstatic inline void mas_topiary_replace(struct ma_state *mas,\n\t\tstruct maple_enode *old_enode)\n{\n\tstruct ma_state tmp[3], tmp_next[3];\n\tMA_TOPIARY(subtrees, mas->tree);\n\tbool in_rcu;\n\tint i, n;\n\n\t \n\tmas_put_in_tree(mas, old_enode);\n\n\t \n\ttmp[0] = *mas;\n\ttmp[0].offset = 0;\n\ttmp[1].node = MAS_NONE;\n\ttmp[2].node = MAS_NONE;\n\twhile (!mte_is_leaf(tmp[0].node)) {\n\t\tn = 0;\n\t\tfor (i = 0; i < 3; i++) {\n\t\t\tif (mas_is_none(&tmp[i]))\n\t\t\t\tcontinue;\n\n\t\t\twhile (n < 3) {\n\t\t\t\tif (!mas_find_child(&tmp[i], &tmp_next[n]))\n\t\t\t\t\tbreak;\n\t\t\t\tn++;\n\t\t\t}\n\n\t\t\tmas_adopt_children(&tmp[i], tmp[i].node);\n\t\t}\n\n\t\tif (MAS_WARN_ON(mas, n == 0))\n\t\t\tbreak;\n\n\t\twhile (n < 3)\n\t\t\ttmp_next[n++].node = MAS_NONE;\n\n\t\tfor (i = 0; i < 3; i++)\n\t\t\ttmp[i] = tmp_next[i];\n\t}\n\n\t \n\tif (mte_is_leaf(old_enode))\n\t\treturn mas_free(mas, old_enode);\n\n\ttmp[0] = *mas;\n\ttmp[0].offset = 0;\n\ttmp[0].node = old_enode;\n\ttmp[1].node = MAS_NONE;\n\ttmp[2].node = MAS_NONE;\n\tin_rcu = mt_in_rcu(mas->tree);\n\tdo {\n\t\tn = 0;\n\t\tfor (i = 0; i < 3; i++) {\n\t\t\tif (mas_is_none(&tmp[i]))\n\t\t\t\tcontinue;\n\n\t\t\twhile (n < 3) {\n\t\t\t\tif (!mas_find_child(&tmp[i], &tmp_next[n]))\n\t\t\t\t\tbreak;\n\n\t\t\t\tif ((tmp_next[n].min >= tmp_next->index) &&\n\t\t\t\t    (tmp_next[n].max <= tmp_next->last)) {\n\t\t\t\t\tmat_add(&subtrees, tmp_next[n].node);\n\t\t\t\t\ttmp_next[n].node = MAS_NONE;\n\t\t\t\t} else {\n\t\t\t\t\tn++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (MAS_WARN_ON(mas, n == 0))\n\t\t\tbreak;\n\n\t\twhile (n < 3)\n\t\t\ttmp_next[n++].node = MAS_NONE;\n\n\t\tfor (i = 0; i < 3; i++) {\n\t\t\tmas_topiary_node(mas, tmp[i].node, in_rcu);\n\t\t\ttmp[i] = tmp_next[i];\n\t\t}\n\t} while (!mte_is_leaf(tmp[0].node));\n\n\tfor (i = 0; i < 3; i++)\n\t\tmas_topiary_node(mas, tmp[i].node, in_rcu);\n\n\tmas_mat_destroy(mas, &subtrees);\n}\n\n \nstatic inline void mas_wmb_replace(struct ma_state *mas,\n\t\tstruct maple_enode *old_enode)\n{\n\t \n\tmas_topiary_replace(mas, old_enode);\n\n\tif (mte_is_leaf(mas->node))\n\t\treturn;\n\n\tmas_update_gap(mas);\n}\n\n \nstatic inline void mast_cp_to_nodes(struct maple_subtree_state *mast,\n\tstruct maple_enode *left, struct maple_enode *middle,\n\tstruct maple_enode *right, unsigned char split, unsigned char mid_split)\n{\n\tbool new_lmax = true;\n\n\tmast->l->node = mte_node_or_none(left);\n\tmast->m->node = mte_node_or_none(middle);\n\tmast->r->node = mte_node_or_none(right);\n\n\tmast->l->min = mast->orig_l->min;\n\tif (split == mast->bn->b_end) {\n\t\tmast->l->max = mast->orig_r->max;\n\t\tnew_lmax = false;\n\t}\n\n\tmab_mas_cp(mast->bn, 0, split, mast->l, new_lmax);\n\n\tif (middle) {\n\t\tmab_mas_cp(mast->bn, 1 + split, mid_split, mast->m, true);\n\t\tmast->m->min = mast->bn->pivot[split] + 1;\n\t\tsplit = mid_split;\n\t}\n\n\tmast->r->max = mast->orig_r->max;\n\tif (right) {\n\t\tmab_mas_cp(mast->bn, 1 + split, mast->bn->b_end, mast->r, false);\n\t\tmast->r->min = mast->bn->pivot[split] + 1;\n\t}\n}\n\n \nstatic inline void mast_combine_cp_left(struct maple_subtree_state *mast)\n{\n\tunsigned char l_slot = mast->orig_l->offset;\n\n\tif (!l_slot)\n\t\treturn;\n\n\tmas_mab_cp(mast->orig_l, 0, l_slot - 1, mast->bn, 0);\n}\n\n \nstatic inline void mast_combine_cp_right(struct maple_subtree_state *mast)\n{\n\tif (mast->bn->pivot[mast->bn->b_end - 1] >= mast->orig_r->max)\n\t\treturn;\n\n\tmas_mab_cp(mast->orig_r, mast->orig_r->offset + 1,\n\t\t   mt_slot_count(mast->orig_r->node), mast->bn,\n\t\t   mast->bn->b_end);\n\tmast->orig_r->last = mast->orig_r->max;\n}\n\n \nstatic inline bool mast_sufficient(struct maple_subtree_state *mast)\n{\n\tif (mast->bn->b_end > mt_min_slot_count(mast->orig_l->node))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic inline bool mast_overflow(struct maple_subtree_state *mast)\n{\n\tif (mast->bn->b_end >= mt_slot_count(mast->orig_l->node))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic inline void *mtree_range_walk(struct ma_state *mas)\n{\n\tunsigned long *pivots;\n\tunsigned char offset;\n\tstruct maple_node *node;\n\tstruct maple_enode *next, *last;\n\tenum maple_type type;\n\tvoid __rcu **slots;\n\tunsigned char end;\n\tunsigned long max, min;\n\tunsigned long prev_max, prev_min;\n\n\tnext = mas->node;\n\tmin = mas->min;\n\tmax = mas->max;\n\tdo {\n\t\toffset = 0;\n\t\tlast = next;\n\t\tnode = mte_to_node(next);\n\t\ttype = mte_node_type(next);\n\t\tpivots = ma_pivots(node, type);\n\t\tend = ma_data_end(node, type, pivots, max);\n\t\tif (unlikely(ma_dead_node(node)))\n\t\t\tgoto dead_node;\n\n\t\tif (pivots[offset] >= mas->index) {\n\t\t\tprev_max = max;\n\t\t\tprev_min = min;\n\t\t\tmax = pivots[offset];\n\t\t\tgoto next;\n\t\t}\n\n\t\tdo {\n\t\t\toffset++;\n\t\t} while ((offset < end) && (pivots[offset] < mas->index));\n\n\t\tprev_min = min;\n\t\tmin = pivots[offset - 1] + 1;\n\t\tprev_max = max;\n\t\tif (likely(offset < end && pivots[offset]))\n\t\t\tmax = pivots[offset];\n\nnext:\n\t\tslots = ma_slots(node, type);\n\t\tnext = mt_slot(mas->tree, slots, offset);\n\t\tif (unlikely(ma_dead_node(node)))\n\t\t\tgoto dead_node;\n\t} while (!ma_is_leaf(type));\n\n\tmas->offset = offset;\n\tmas->index = min;\n\tmas->last = max;\n\tmas->min = prev_min;\n\tmas->max = prev_max;\n\tmas->node = last;\n\treturn (void *)next;\n\ndead_node:\n\tmas_reset(mas);\n\treturn NULL;\n}\n\n \nstatic int mas_spanning_rebalance(struct ma_state *mas,\n\t\tstruct maple_subtree_state *mast, unsigned char count)\n{\n\tunsigned char split, mid_split;\n\tunsigned char slot = 0;\n\tstruct maple_enode *left = NULL, *middle = NULL, *right = NULL;\n\tstruct maple_enode *old_enode;\n\n\tMA_STATE(l_mas, mas->tree, mas->index, mas->index);\n\tMA_STATE(r_mas, mas->tree, mas->index, mas->last);\n\tMA_STATE(m_mas, mas->tree, mas->index, mas->index);\n\n\t \n\tmast->l = &l_mas;\n\tmast->m = &m_mas;\n\tmast->r = &r_mas;\n\tl_mas.node = r_mas.node = m_mas.node = MAS_NONE;\n\n\t \n\tif (((mast->orig_l->min != 0) || (mast->orig_r->max != ULONG_MAX)) &&\n\t    unlikely(mast->bn->b_end <= mt_min_slots[mast->bn->type]))\n\t\tmast_spanning_rebalance(mast);\n\n\tl_mas.depth = 0;\n\n\t \n\twhile (count--) {\n\t\tmast->bn->b_end--;\n\t\tmast->bn->type = mte_node_type(mast->orig_l->node);\n\t\tsplit = mas_mab_to_node(mas, mast->bn, &left, &right, &middle,\n\t\t\t\t\t&mid_split, mast->orig_l->min);\n\t\tmast_set_split_parents(mast, left, middle, right, split,\n\t\t\t\t       mid_split);\n\t\tmast_cp_to_nodes(mast, left, middle, right, split, mid_split);\n\n\t\t \n\t\tmemset(mast->bn, 0, sizeof(struct maple_big_node));\n\t\tmast->bn->type = mte_node_type(left);\n\t\tl_mas.depth++;\n\n\t\t \n\t\tif (mas_is_root_limits(mast->l))\n\t\t\tgoto new_root;\n\n\t\tmast_ascend(mast);\n\t\tmast_combine_cp_left(mast);\n\t\tl_mas.offset = mast->bn->b_end;\n\t\tmab_set_b_end(mast->bn, &l_mas, left);\n\t\tmab_set_b_end(mast->bn, &m_mas, middle);\n\t\tmab_set_b_end(mast->bn, &r_mas, right);\n\n\t\t \n\t\tmast_combine_cp_right(mast);\n\t\tmast->orig_l->last = mast->orig_l->max;\n\n\t\tif (mast_sufficient(mast))\n\t\t\tcontinue;\n\n\t\tif (mast_overflow(mast))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (mas_is_root_limits(mast->orig_l))\n\t\t\tbreak;\n\n\t\tmast_spanning_rebalance(mast);\n\n\t\t \n\t\tif (!count)\n\t\t\tcount++;\n\t}\n\n\tl_mas.node = mt_mk_node(ma_mnode_ptr(mas_pop_node(mas)),\n\t\t\t\tmte_node_type(mast->orig_l->node));\n\tl_mas.depth++;\n\tmab_mas_cp(mast->bn, 0, mt_slots[mast->bn->type] - 1, &l_mas, true);\n\tmas_set_parent(mas, left, l_mas.node, slot);\n\tif (middle)\n\t\tmas_set_parent(mas, middle, l_mas.node, ++slot);\n\n\tif (right)\n\t\tmas_set_parent(mas, right, l_mas.node, ++slot);\n\n\tif (mas_is_root_limits(mast->l)) {\nnew_root:\n\t\tmas_mn(mast->l)->parent = ma_parent_ptr(mas_tree_parent(mas));\n\t\twhile (!mte_is_root(mast->orig_l->node))\n\t\t\tmast_ascend(mast);\n\t} else {\n\t\tmas_mn(&l_mas)->parent = mas_mn(mast->orig_l)->parent;\n\t}\n\n\told_enode = mast->orig_l->node;\n\tmas->depth = l_mas.depth;\n\tmas->node = l_mas.node;\n\tmas->min = l_mas.min;\n\tmas->max = l_mas.max;\n\tmas->offset = l_mas.offset;\n\tmas_wmb_replace(mas, old_enode);\n\tmtree_range_walk(mas);\n\treturn mast->bn->b_end;\n}\n\n \nstatic inline int mas_rebalance(struct ma_state *mas,\n\t\t\t\tstruct maple_big_node *b_node)\n{\n\tchar empty_count = mas_mt_height(mas);\n\tstruct maple_subtree_state mast;\n\tunsigned char shift, b_end = ++b_node->b_end;\n\n\tMA_STATE(l_mas, mas->tree, mas->index, mas->last);\n\tMA_STATE(r_mas, mas->tree, mas->index, mas->last);\n\n\ttrace_ma_op(__func__, mas);\n\n\t \n\tmas_node_count(mas, empty_count * 2 - 1);\n\tif (mas_is_err(mas))\n\t\treturn 0;\n\n\tmast.orig_l = &l_mas;\n\tmast.orig_r = &r_mas;\n\tmast.bn = b_node;\n\tmast.bn->type = mte_node_type(mas->node);\n\n\tl_mas = r_mas = *mas;\n\n\tif (mas_next_sibling(&r_mas)) {\n\t\tmas_mab_cp(&r_mas, 0, mt_slot_count(r_mas.node), b_node, b_end);\n\t\tr_mas.last = r_mas.index = r_mas.max;\n\t} else {\n\t\tmas_prev_sibling(&l_mas);\n\t\tshift = mas_data_end(&l_mas) + 1;\n\t\tmab_shift_right(b_node, shift);\n\t\tmas->offset += shift;\n\t\tmas_mab_cp(&l_mas, 0, shift - 1, b_node, 0);\n\t\tb_node->b_end = shift + b_end;\n\t\tl_mas.index = l_mas.last = l_mas.min;\n\t}\n\n\treturn mas_spanning_rebalance(mas, &mast, empty_count);\n}\n\n \nstatic inline void mas_destroy_rebalance(struct ma_state *mas, unsigned char end)\n{\n\tenum maple_type mt = mte_node_type(mas->node);\n\tstruct maple_node reuse, *newnode, *parent, *new_left, *left, *node;\n\tstruct maple_enode *eparent, *old_eparent;\n\tunsigned char offset, tmp, split = mt_slots[mt] / 2;\n\tvoid __rcu **l_slots, **slots;\n\tunsigned long *l_pivs, *pivs, gap;\n\tbool in_rcu = mt_in_rcu(mas->tree);\n\n\tMA_STATE(l_mas, mas->tree, mas->index, mas->last);\n\n\tl_mas = *mas;\n\tmas_prev_sibling(&l_mas);\n\n\t \n\tif (in_rcu) {\n\t\t \n\t\tmas_node_count(mas, 3);\n\t\tif (mas_is_err(mas))\n\t\t\treturn;\n\n\t\tnewnode = mas_pop_node(mas);\n\t} else {\n\t\tnewnode = &reuse;\n\t}\n\n\tnode = mas_mn(mas);\n\tnewnode->parent = node->parent;\n\tslots = ma_slots(newnode, mt);\n\tpivs = ma_pivots(newnode, mt);\n\tleft = mas_mn(&l_mas);\n\tl_slots = ma_slots(left, mt);\n\tl_pivs = ma_pivots(left, mt);\n\tif (!l_slots[split])\n\t\tsplit++;\n\ttmp = mas_data_end(&l_mas) - split;\n\n\tmemcpy(slots, l_slots + split + 1, sizeof(void *) * tmp);\n\tmemcpy(pivs, l_pivs + split + 1, sizeof(unsigned long) * tmp);\n\tpivs[tmp] = l_mas.max;\n\tmemcpy(slots + tmp, ma_slots(node, mt), sizeof(void *) * end);\n\tmemcpy(pivs + tmp, ma_pivots(node, mt), sizeof(unsigned long) * end);\n\n\tl_mas.max = l_pivs[split];\n\tmas->min = l_mas.max + 1;\n\told_eparent = mt_mk_node(mte_parent(l_mas.node),\n\t\t\t     mas_parent_type(&l_mas, l_mas.node));\n\ttmp += end;\n\tif (!in_rcu) {\n\t\tunsigned char max_p = mt_pivots[mt];\n\t\tunsigned char max_s = mt_slots[mt];\n\n\t\tif (tmp < max_p)\n\t\t\tmemset(pivs + tmp, 0,\n\t\t\t       sizeof(unsigned long) * (max_p - tmp));\n\n\t\tif (tmp < mt_slots[mt])\n\t\t\tmemset(slots + tmp, 0, sizeof(void *) * (max_s - tmp));\n\n\t\tmemcpy(node, newnode, sizeof(struct maple_node));\n\t\tma_set_meta(node, mt, 0, tmp - 1);\n\t\tmte_set_pivot(old_eparent, mte_parent_slot(l_mas.node),\n\t\t\t      l_pivs[split]);\n\n\t\t \n\t\ttmp = split + 1;\n\t\tmemset(l_pivs + tmp, 0, sizeof(unsigned long) * (max_p - tmp));\n\t\tmemset(l_slots + tmp, 0, sizeof(void *) * (max_s - tmp));\n\t\tma_set_meta(left, mt, 0, split);\n\t\teparent = old_eparent;\n\n\t\tgoto done;\n\t}\n\n\t \n\tmas->node = mt_mk_node(newnode, mt);\n\tma_set_meta(newnode, mt, 0, tmp);\n\n\tnew_left = mas_pop_node(mas);\n\tnew_left->parent = left->parent;\n\tmt = mte_node_type(l_mas.node);\n\tslots = ma_slots(new_left, mt);\n\tpivs = ma_pivots(new_left, mt);\n\tmemcpy(slots, l_slots, sizeof(void *) * split);\n\tmemcpy(pivs, l_pivs, sizeof(unsigned long) * split);\n\tma_set_meta(new_left, mt, 0, split);\n\tl_mas.node = mt_mk_node(new_left, mt);\n\n\t \n\toffset = mte_parent_slot(mas->node);\n\tmt = mas_parent_type(&l_mas, l_mas.node);\n\tparent = mas_pop_node(mas);\n\tslots = ma_slots(parent, mt);\n\tpivs = ma_pivots(parent, mt);\n\tmemcpy(parent, mte_to_node(old_eparent), sizeof(struct maple_node));\n\trcu_assign_pointer(slots[offset], mas->node);\n\trcu_assign_pointer(slots[offset - 1], l_mas.node);\n\tpivs[offset - 1] = l_mas.max;\n\teparent = mt_mk_node(parent, mt);\ndone:\n\tgap = mas_leaf_max_gap(mas);\n\tmte_set_gap(eparent, mte_parent_slot(mas->node), gap);\n\tgap = mas_leaf_max_gap(&l_mas);\n\tmte_set_gap(eparent, mte_parent_slot(l_mas.node), gap);\n\tmas_ascend(mas);\n\n\tif (in_rcu) {\n\t\tmas_replace_node(mas, old_eparent);\n\t\tmas_adopt_children(mas, mas->node);\n\t}\n\n\tmas_update_gap(mas);\n}\n\n \nstatic inline bool mas_split_final_node(struct maple_subtree_state *mast,\n\t\t\t\t\tstruct ma_state *mas, int height)\n{\n\tstruct maple_enode *ancestor;\n\n\tif (mte_is_root(mas->node)) {\n\t\tif (mt_is_alloc(mas->tree))\n\t\t\tmast->bn->type = maple_arange_64;\n\t\telse\n\t\t\tmast->bn->type = maple_range_64;\n\t\tmas->depth = height;\n\t}\n\t \n\tancestor = mas_new_ma_node(mas, mast->bn);\n\tmas_set_parent(mas, mast->l->node, ancestor, mast->l->offset);\n\tmas_set_parent(mas, mast->r->node, ancestor, mast->r->offset);\n\tmte_to_node(ancestor)->parent = mas_mn(mas)->parent;\n\n\tmast->l->node = ancestor;\n\tmab_mas_cp(mast->bn, 0, mt_slots[mast->bn->type] - 1, mast->l, true);\n\tmas->offset = mast->bn->b_end - 1;\n\treturn true;\n}\n\n \nstatic inline void mast_fill_bnode(struct maple_subtree_state *mast,\n\t\t\t\t\t struct ma_state *mas,\n\t\t\t\t\t unsigned char skip)\n{\n\tbool cp = true;\n\tunsigned char split;\n\n\tmemset(mast->bn->gap, 0, sizeof(unsigned long) * ARRAY_SIZE(mast->bn->gap));\n\tmemset(mast->bn->slot, 0, sizeof(unsigned long) * ARRAY_SIZE(mast->bn->slot));\n\tmemset(mast->bn->pivot, 0, sizeof(unsigned long) * ARRAY_SIZE(mast->bn->pivot));\n\tmast->bn->b_end = 0;\n\n\tif (mte_is_root(mas->node)) {\n\t\tcp = false;\n\t} else {\n\t\tmas_ascend(mas);\n\t\tmas->offset = mte_parent_slot(mas->node);\n\t}\n\n\tif (cp && mast->l->offset)\n\t\tmas_mab_cp(mas, 0, mast->l->offset - 1, mast->bn, 0);\n\n\tsplit = mast->bn->b_end;\n\tmab_set_b_end(mast->bn, mast->l, mast->l->node);\n\tmast->r->offset = mast->bn->b_end;\n\tmab_set_b_end(mast->bn, mast->r, mast->r->node);\n\tif (mast->bn->pivot[mast->bn->b_end - 1] == mas->max)\n\t\tcp = false;\n\n\tif (cp)\n\t\tmas_mab_cp(mas, split + skip, mt_slot_count(mas->node) - 1,\n\t\t\t   mast->bn, mast->bn->b_end);\n\n\tmast->bn->b_end--;\n\tmast->bn->type = mte_node_type(mas->node);\n}\n\n \nstatic inline void mast_split_data(struct maple_subtree_state *mast,\n\t   struct ma_state *mas, unsigned char split)\n{\n\tunsigned char p_slot;\n\n\tmab_mas_cp(mast->bn, 0, split, mast->l, true);\n\tmte_set_pivot(mast->r->node, 0, mast->r->max);\n\tmab_mas_cp(mast->bn, split + 1, mast->bn->b_end, mast->r, false);\n\tmast->l->offset = mte_parent_slot(mas->node);\n\tmast->l->max = mast->bn->pivot[split];\n\tmast->r->min = mast->l->max + 1;\n\tif (mte_is_leaf(mas->node))\n\t\treturn;\n\n\tp_slot = mast->orig_l->offset;\n\tmas_set_split_parent(mast->orig_l, mast->l->node, mast->r->node,\n\t\t\t     &p_slot, split);\n\tmas_set_split_parent(mast->orig_r, mast->l->node, mast->r->node,\n\t\t\t     &p_slot, split);\n}\n\n \nstatic inline bool mas_push_data(struct ma_state *mas, int height,\n\t\t\t\t struct maple_subtree_state *mast, bool left)\n{\n\tunsigned char slot_total = mast->bn->b_end;\n\tunsigned char end, space, split;\n\n\tMA_STATE(tmp_mas, mas->tree, mas->index, mas->last);\n\ttmp_mas = *mas;\n\ttmp_mas.depth = mast->l->depth;\n\n\tif (left && !mas_prev_sibling(&tmp_mas))\n\t\treturn false;\n\telse if (!left && !mas_next_sibling(&tmp_mas))\n\t\treturn false;\n\n\tend = mas_data_end(&tmp_mas);\n\tslot_total += end;\n\tspace = 2 * mt_slot_count(mas->node) - 2;\n\t \n\tif (ma_is_leaf(mast->bn->type))\n\t\tspace--;\n\n\tif (mas->max == ULONG_MAX)\n\t\tspace--;\n\n\tif (slot_total >= space)\n\t\treturn false;\n\n\t \n\tmast->bn->b_end++;\n\tif (left) {\n\t\tmab_shift_right(mast->bn, end + 1);\n\t\tmas_mab_cp(&tmp_mas, 0, end, mast->bn, 0);\n\t\tmast->bn->b_end = slot_total + 1;\n\t} else {\n\t\tmas_mab_cp(&tmp_mas, 0, end, mast->bn, mast->bn->b_end);\n\t}\n\n\t \n\tsplit = mt_slots[mast->bn->type] - 2;\n\tif (left) {\n\t\t \n\t\t*mas = tmp_mas;\n\t\t \n\t\ttmp_mas.node = mast->l->node;\n\t\t*mast->l = tmp_mas;\n\t} else {\n\t\ttmp_mas.node = mast->r->node;\n\t\t*mast->r = tmp_mas;\n\t\tsplit = slot_total - split;\n\t}\n\tsplit = mab_no_null_split(mast->bn, split, mt_slots[mast->bn->type]);\n\t \n\tif (left)\n\t\tmast->orig_l->offset += end + 1;\n\n\tmast_split_data(mast, mas, split);\n\tmast_fill_bnode(mast, mas, 2);\n\tmas_split_final_node(mast, mas, height + 1);\n\treturn true;\n}\n\n \nstatic int mas_split(struct ma_state *mas, struct maple_big_node *b_node)\n{\n\tstruct maple_subtree_state mast;\n\tint height = 0;\n\tunsigned char mid_split, split = 0;\n\tstruct maple_enode *old;\n\n\t \n\tMA_STATE(l_mas, mas->tree, mas->index, mas->last);\n\tMA_STATE(r_mas, mas->tree, mas->index, mas->last);\n\tMA_STATE(prev_l_mas, mas->tree, mas->index, mas->last);\n\tMA_STATE(prev_r_mas, mas->tree, mas->index, mas->last);\n\n\ttrace_ma_op(__func__, mas);\n\tmas->depth = mas_mt_height(mas);\n\t \n\tmas_node_count(mas, 1 + mas->depth * 2);\n\tif (mas_is_err(mas))\n\t\treturn 0;\n\n\tmast.l = &l_mas;\n\tmast.r = &r_mas;\n\tmast.orig_l = &prev_l_mas;\n\tmast.orig_r = &prev_r_mas;\n\tmast.bn = b_node;\n\n\twhile (height++ <= mas->depth) {\n\t\tif (mt_slots[b_node->type] > b_node->b_end) {\n\t\t\tmas_split_final_node(&mast, mas, height);\n\t\t\tbreak;\n\t\t}\n\n\t\tl_mas = r_mas = *mas;\n\t\tl_mas.node = mas_new_ma_node(mas, b_node);\n\t\tr_mas.node = mas_new_ma_node(mas, b_node);\n\t\t \n\t\t \n\t\tif (mas_push_data(mas, height, &mast, true))\n\t\t\tbreak;\n\n\t\t \n\t\tif (mas_push_data(mas, height, &mast, false))\n\t\t\tbreak;\n\n\t\tsplit = mab_calc_split(mas, b_node, &mid_split, prev_l_mas.min);\n\t\tmast_split_data(&mast, mas, split);\n\t\t \n\t\tmast.r->max = mas->max;\n\t\tmast_fill_bnode(&mast, mas, 1);\n\t\tprev_l_mas = *mast.l;\n\t\tprev_r_mas = *mast.r;\n\t}\n\n\t \n\told = mas->node;\n\tmas->node = l_mas.node;\n\tmas_wmb_replace(mas, old);\n\tmtree_range_walk(mas);\n\treturn 1;\n}\n\n \nstatic inline bool mas_reuse_node(struct ma_wr_state *wr_mas,\n\t\t\t  struct maple_big_node *bn, unsigned char end)\n{\n\t \n\tif (mt_in_rcu(wr_mas->mas->tree))\n\t\treturn false;\n\n\tif (end > bn->b_end) {\n\t\tint clear = mt_slots[wr_mas->type] - bn->b_end;\n\n\t\tmemset(wr_mas->slots + bn->b_end, 0, sizeof(void *) * clear--);\n\t\tmemset(wr_mas->pivots + bn->b_end, 0, sizeof(void *) * clear);\n\t}\n\tmab_mas_cp(bn, 0, bn->b_end, wr_mas->mas, false);\n\treturn true;\n}\n\n \nstatic noinline_for_kasan int mas_commit_b_node(struct ma_wr_state *wr_mas,\n\t\t\t    struct maple_big_node *b_node, unsigned char end)\n{\n\tstruct maple_node *node;\n\tstruct maple_enode *old_enode;\n\tunsigned char b_end = b_node->b_end;\n\tenum maple_type b_type = b_node->type;\n\n\told_enode = wr_mas->mas->node;\n\tif ((b_end < mt_min_slots[b_type]) &&\n\t    (!mte_is_root(old_enode)) &&\n\t    (mas_mt_height(wr_mas->mas) > 1))\n\t\treturn mas_rebalance(wr_mas->mas, b_node);\n\n\tif (b_end >= mt_slots[b_type])\n\t\treturn mas_split(wr_mas->mas, b_node);\n\n\tif (mas_reuse_node(wr_mas, b_node, end))\n\t\tgoto reuse_node;\n\n\tmas_node_count(wr_mas->mas, 1);\n\tif (mas_is_err(wr_mas->mas))\n\t\treturn 0;\n\n\tnode = mas_pop_node(wr_mas->mas);\n\tnode->parent = mas_mn(wr_mas->mas)->parent;\n\twr_mas->mas->node = mt_mk_node(node, b_type);\n\tmab_mas_cp(b_node, 0, b_end, wr_mas->mas, false);\n\tmas_replace_node(wr_mas->mas, old_enode);\nreuse_node:\n\tmas_update_gap(wr_mas->mas);\n\treturn 1;\n}\n\n \nstatic inline int mas_root_expand(struct ma_state *mas, void *entry)\n{\n\tvoid *contents = mas_root_locked(mas);\n\tenum maple_type type = maple_leaf_64;\n\tstruct maple_node *node;\n\tvoid __rcu **slots;\n\tunsigned long *pivots;\n\tint slot = 0;\n\n\tmas_node_count(mas, 1);\n\tif (unlikely(mas_is_err(mas)))\n\t\treturn 0;\n\n\tnode = mas_pop_node(mas);\n\tpivots = ma_pivots(node, type);\n\tslots = ma_slots(node, type);\n\tnode->parent = ma_parent_ptr(mas_tree_parent(mas));\n\tmas->node = mt_mk_node(node, type);\n\n\tif (mas->index) {\n\t\tif (contents) {\n\t\t\trcu_assign_pointer(slots[slot], contents);\n\t\t\tif (likely(mas->index > 1))\n\t\t\t\tslot++;\n\t\t}\n\t\tpivots[slot++] = mas->index - 1;\n\t}\n\n\trcu_assign_pointer(slots[slot], entry);\n\tmas->offset = slot;\n\tpivots[slot] = mas->last;\n\tif (mas->last != ULONG_MAX)\n\t\tpivots[++slot] = ULONG_MAX;\n\n\tmas->depth = 1;\n\tmas_set_height(mas);\n\tma_set_meta(node, maple_leaf_64, 0, slot);\n\t \n\trcu_assign_pointer(mas->tree->ma_root, mte_mk_root(mas->node));\n\treturn slot;\n}\n\nstatic inline void mas_store_root(struct ma_state *mas, void *entry)\n{\n\tif (likely((mas->last != 0) || (mas->index != 0)))\n\t\tmas_root_expand(mas, entry);\n\telse if (((unsigned long) (entry) & 3) == 2)\n\t\tmas_root_expand(mas, entry);\n\telse {\n\t\trcu_assign_pointer(mas->tree->ma_root, entry);\n\t\tmas->node = MAS_START;\n\t}\n}\n\n \nstatic bool mas_is_span_wr(struct ma_wr_state *wr_mas)\n{\n\tunsigned long max = wr_mas->r_max;\n\tunsigned long last = wr_mas->mas->last;\n\tenum maple_type type = wr_mas->type;\n\tvoid *entry = wr_mas->entry;\n\n\t \n\tif (last < max)\n\t\treturn false;\n\n\tif (ma_is_leaf(type)) {\n\t\tmax = wr_mas->mas->max;\n\t\tif (last < max)\n\t\t\treturn false;\n\t}\n\n\tif (last == max) {\n\t\t \n\t\tif (entry || last == ULONG_MAX)\n\t\t\treturn false;\n\t}\n\n\ttrace_ma_write(__func__, wr_mas->mas, wr_mas->r_max, entry);\n\treturn true;\n}\n\nstatic inline void mas_wr_walk_descend(struct ma_wr_state *wr_mas)\n{\n\twr_mas->type = mte_node_type(wr_mas->mas->node);\n\tmas_wr_node_walk(wr_mas);\n\twr_mas->slots = ma_slots(wr_mas->node, wr_mas->type);\n}\n\nstatic inline void mas_wr_walk_traverse(struct ma_wr_state *wr_mas)\n{\n\twr_mas->mas->max = wr_mas->r_max;\n\twr_mas->mas->min = wr_mas->r_min;\n\twr_mas->mas->node = wr_mas->content;\n\twr_mas->mas->offset = 0;\n\twr_mas->mas->depth++;\n}\n \nstatic bool mas_wr_walk(struct ma_wr_state *wr_mas)\n{\n\tstruct ma_state *mas = wr_mas->mas;\n\n\twhile (true) {\n\t\tmas_wr_walk_descend(wr_mas);\n\t\tif (unlikely(mas_is_span_wr(wr_mas)))\n\t\t\treturn false;\n\n\t\twr_mas->content = mas_slot_locked(mas, wr_mas->slots,\n\t\t\t\t\t\t  mas->offset);\n\t\tif (ma_is_leaf(wr_mas->type))\n\t\t\treturn true;\n\n\t\tmas_wr_walk_traverse(wr_mas);\n\t}\n\n\treturn true;\n}\n\nstatic bool mas_wr_walk_index(struct ma_wr_state *wr_mas)\n{\n\tstruct ma_state *mas = wr_mas->mas;\n\n\twhile (true) {\n\t\tmas_wr_walk_descend(wr_mas);\n\t\twr_mas->content = mas_slot_locked(mas, wr_mas->slots,\n\t\t\t\t\t\t  mas->offset);\n\t\tif (ma_is_leaf(wr_mas->type))\n\t\t\treturn true;\n\t\tmas_wr_walk_traverse(wr_mas);\n\n\t}\n\treturn true;\n}\n \nstatic inline void mas_extend_spanning_null(struct ma_wr_state *l_wr_mas,\n\t\t\t\t\t    struct ma_wr_state *r_wr_mas)\n{\n\tstruct ma_state *r_mas = r_wr_mas->mas;\n\tstruct ma_state *l_mas = l_wr_mas->mas;\n\tunsigned char l_slot;\n\n\tl_slot = l_mas->offset;\n\tif (!l_wr_mas->content)\n\t\tl_mas->index = l_wr_mas->r_min;\n\n\tif ((l_mas->index == l_wr_mas->r_min) &&\n\t\t (l_slot &&\n\t\t  !mas_slot_locked(l_mas, l_wr_mas->slots, l_slot - 1))) {\n\t\tif (l_slot > 1)\n\t\t\tl_mas->index = l_wr_mas->pivots[l_slot - 2] + 1;\n\t\telse\n\t\t\tl_mas->index = l_mas->min;\n\n\t\tl_mas->offset = l_slot - 1;\n\t}\n\n\tif (!r_wr_mas->content) {\n\t\tif (r_mas->last < r_wr_mas->r_max)\n\t\t\tr_mas->last = r_wr_mas->r_max;\n\t\tr_mas->offset++;\n\t} else if ((r_mas->last == r_wr_mas->r_max) &&\n\t    (r_mas->last < r_mas->max) &&\n\t    !mas_slot_locked(r_mas, r_wr_mas->slots, r_mas->offset + 1)) {\n\t\tr_mas->last = mas_safe_pivot(r_mas, r_wr_mas->pivots,\n\t\t\t\t\t     r_wr_mas->type, r_mas->offset + 1);\n\t\tr_mas->offset++;\n\t}\n}\n\nstatic inline void *mas_state_walk(struct ma_state *mas)\n{\n\tvoid *entry;\n\n\tentry = mas_start(mas);\n\tif (mas_is_none(mas))\n\t\treturn NULL;\n\n\tif (mas_is_ptr(mas))\n\t\treturn entry;\n\n\treturn mtree_range_walk(mas);\n}\n\n \nstatic inline void *mtree_lookup_walk(struct ma_state *mas)\n{\n\tunsigned long *pivots;\n\tunsigned char offset;\n\tstruct maple_node *node;\n\tstruct maple_enode *next;\n\tenum maple_type type;\n\tvoid __rcu **slots;\n\tunsigned char end;\n\tunsigned long max;\n\n\tnext = mas->node;\n\tmax = ULONG_MAX;\n\tdo {\n\t\toffset = 0;\n\t\tnode = mte_to_node(next);\n\t\ttype = mte_node_type(next);\n\t\tpivots = ma_pivots(node, type);\n\t\tend = ma_data_end(node, type, pivots, max);\n\t\tif (unlikely(ma_dead_node(node)))\n\t\t\tgoto dead_node;\n\t\tdo {\n\t\t\tif (pivots[offset] >= mas->index) {\n\t\t\t\tmax = pivots[offset];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} while (++offset < end);\n\n\t\tslots = ma_slots(node, type);\n\t\tnext = mt_slot(mas->tree, slots, offset);\n\t\tif (unlikely(ma_dead_node(node)))\n\t\t\tgoto dead_node;\n\t} while (!ma_is_leaf(type));\n\n\treturn (void *)next;\n\ndead_node:\n\tmas_reset(mas);\n\treturn NULL;\n}\n\nstatic void mte_destroy_walk(struct maple_enode *, struct maple_tree *);\n \nstatic inline int mas_new_root(struct ma_state *mas, void *entry)\n{\n\tstruct maple_enode *root = mas_root_locked(mas);\n\tenum maple_type type = maple_leaf_64;\n\tstruct maple_node *node;\n\tvoid __rcu **slots;\n\tunsigned long *pivots;\n\n\tif (!entry && !mas->index && mas->last == ULONG_MAX) {\n\t\tmas->depth = 0;\n\t\tmas_set_height(mas);\n\t\trcu_assign_pointer(mas->tree->ma_root, entry);\n\t\tmas->node = MAS_START;\n\t\tgoto done;\n\t}\n\n\tmas_node_count(mas, 1);\n\tif (mas_is_err(mas))\n\t\treturn 0;\n\n\tnode = mas_pop_node(mas);\n\tpivots = ma_pivots(node, type);\n\tslots = ma_slots(node, type);\n\tnode->parent = ma_parent_ptr(mas_tree_parent(mas));\n\tmas->node = mt_mk_node(node, type);\n\trcu_assign_pointer(slots[0], entry);\n\tpivots[0] = mas->last;\n\tmas->depth = 1;\n\tmas_set_height(mas);\n\trcu_assign_pointer(mas->tree->ma_root, mte_mk_root(mas->node));\n\ndone:\n\tif (xa_is_node(root))\n\t\tmte_destroy_walk(root, mas->tree);\n\n\treturn 1;\n}\n \nstatic inline int mas_wr_spanning_store(struct ma_wr_state *wr_mas)\n{\n\tstruct maple_subtree_state mast;\n\tstruct maple_big_node b_node;\n\tstruct ma_state *mas;\n\tunsigned char height;\n\n\t \n\tMA_STATE(l_mas, NULL, 0, 0);\n\tMA_STATE(r_mas, NULL, 0, 0);\n\tMA_WR_STATE(r_wr_mas, &r_mas, wr_mas->entry);\n\tMA_WR_STATE(l_wr_mas, &l_mas, wr_mas->entry);\n\n\t \n\tmas = wr_mas->mas;\n\ttrace_ma_op(__func__, mas);\n\n\tif (unlikely(!mas->index && mas->last == ULONG_MAX))\n\t\treturn mas_new_root(mas, wr_mas->entry);\n\t \n\theight = mas_mt_height(mas);\n\tmas_node_count(mas, 1 + height * 3);\n\tif (mas_is_err(mas))\n\t\treturn 0;\n\n\t \n\tr_mas = *mas;\n\t \n\tif (r_mas.last + 1)\n\t\tr_mas.last++;\n\n\tr_mas.index = r_mas.last;\n\tmas_wr_walk_index(&r_wr_mas);\n\tr_mas.last = r_mas.index = mas->last;\n\n\t \n\tl_mas = *mas;\n\tmas_wr_walk_index(&l_wr_mas);\n\n\tif (!wr_mas->entry) {\n\t\tmas_extend_spanning_null(&l_wr_mas, &r_wr_mas);\n\t\tmas->offset = l_mas.offset;\n\t\tmas->index = l_mas.index;\n\t\tmas->last = l_mas.last = r_mas.last;\n\t}\n\n\t \n\tif (!l_mas.index && r_mas.last == ULONG_MAX) {\n\t\tmas_set_range(mas, 0, ULONG_MAX);\n\t\treturn mas_new_root(mas, wr_mas->entry);\n\t}\n\n\tmemset(&b_node, 0, sizeof(struct maple_big_node));\n\t \n\tmas_store_b_node(&l_wr_mas, &b_node, l_wr_mas.node_end);\n\t \n\tif (r_mas.offset <= r_wr_mas.node_end)\n\t\tmas_mab_cp(&r_mas, r_mas.offset, r_wr_mas.node_end,\n\t\t\t   &b_node, b_node.b_end + 1);\n\telse\n\t\tb_node.b_end++;\n\n\t \n\tl_mas.index = l_mas.last = mas->index;\n\n\tmast.bn = &b_node;\n\tmast.orig_l = &l_mas;\n\tmast.orig_r = &r_mas;\n\t \n\treturn mas_spanning_rebalance(mas, &mast, height + 1);\n}\n\n \nstatic inline bool mas_wr_node_store(struct ma_wr_state *wr_mas,\n\t\t\t\t     unsigned char new_end)\n{\n\tstruct ma_state *mas = wr_mas->mas;\n\tvoid __rcu **dst_slots;\n\tunsigned long *dst_pivots;\n\tunsigned char dst_offset, offset_end = wr_mas->offset_end;\n\tstruct maple_node reuse, *newnode;\n\tunsigned char copy_size, node_pivots = mt_pivots[wr_mas->type];\n\tbool in_rcu = mt_in_rcu(mas->tree);\n\n\t \n\tif (!mte_is_root(mas->node) && (new_end <= mt_min_slots[wr_mas->type]) &&\n\t    !(mas->mas_flags & MA_STATE_BULK))\n\t\treturn false;\n\n\tif (mas->last == wr_mas->end_piv)\n\t\toffset_end++;  \n\telse if (unlikely(wr_mas->r_max == ULONG_MAX))\n\t\tmas_bulk_rebalance(mas, wr_mas->node_end, wr_mas->type);\n\n\t \n\tif (in_rcu) {\n\t\tmas_node_count(mas, 1);\n\t\tif (mas_is_err(mas))\n\t\t\treturn false;\n\n\t\tnewnode = mas_pop_node(mas);\n\t} else {\n\t\tmemset(&reuse, 0, sizeof(struct maple_node));\n\t\tnewnode = &reuse;\n\t}\n\n\tnewnode->parent = mas_mn(mas)->parent;\n\tdst_pivots = ma_pivots(newnode, wr_mas->type);\n\tdst_slots = ma_slots(newnode, wr_mas->type);\n\t \n\tmemcpy(dst_pivots, wr_mas->pivots, sizeof(unsigned long) * mas->offset);\n\tmemcpy(dst_slots, wr_mas->slots, sizeof(void *) * mas->offset);\n\n\t \n\tif (wr_mas->r_min < mas->index) {\n\t\trcu_assign_pointer(dst_slots[mas->offset], wr_mas->content);\n\t\tdst_pivots[mas->offset++] = mas->index - 1;\n\t}\n\n\t \n\tif (mas->offset < node_pivots)\n\t\tdst_pivots[mas->offset] = mas->last;\n\trcu_assign_pointer(dst_slots[mas->offset], wr_mas->entry);\n\n\t \n\tif (offset_end > wr_mas->node_end)\n\t\tgoto done;\n\n\tdst_offset = mas->offset + 1;\n\t \n\tcopy_size = wr_mas->node_end - offset_end + 1;\n\tmemcpy(dst_slots + dst_offset, wr_mas->slots + offset_end,\n\t       sizeof(void *) * copy_size);\n\tmemcpy(dst_pivots + dst_offset, wr_mas->pivots + offset_end,\n\t       sizeof(unsigned long) * (copy_size - 1));\n\n\tif (new_end < node_pivots)\n\t\tdst_pivots[new_end] = mas->max;\n\ndone:\n\tmas_leaf_set_meta(mas, newnode, dst_pivots, maple_leaf_64, new_end);\n\tif (in_rcu) {\n\t\tstruct maple_enode *old_enode = mas->node;\n\n\t\tmas->node = mt_mk_node(newnode, wr_mas->type);\n\t\tmas_replace_node(mas, old_enode);\n\t} else {\n\t\tmemcpy(wr_mas->node, newnode, sizeof(struct maple_node));\n\t}\n\ttrace_ma_write(__func__, mas, 0, wr_mas->entry);\n\tmas_update_gap(mas);\n\treturn true;\n}\n\n \nstatic inline bool mas_wr_slot_store(struct ma_wr_state *wr_mas)\n{\n\tstruct ma_state *mas = wr_mas->mas;\n\tunsigned char offset = mas->offset;\n\tvoid __rcu **slots = wr_mas->slots;\n\tbool gap = false;\n\n\tgap |= !mt_slot_locked(mas->tree, slots, offset);\n\tgap |= !mt_slot_locked(mas->tree, slots, offset + 1);\n\n\tif (wr_mas->offset_end - offset == 1) {\n\t\tif (mas->index == wr_mas->r_min) {\n\t\t\t \n\t\t\trcu_assign_pointer(slots[offset], wr_mas->entry);\n\t\t\twr_mas->pivots[offset] = mas->last;\n\t\t} else {\n\t\t\t \n\t\t\trcu_assign_pointer(slots[offset + 1], wr_mas->entry);\n\t\t\twr_mas->pivots[offset] = mas->index - 1;\n\t\t\tmas->offset++;  \n\t\t}\n\t} else if (!mt_in_rcu(mas->tree)) {\n\t\t \n\t\tgap |= !mt_slot_locked(mas->tree, slots, offset + 2);\n\t\trcu_assign_pointer(slots[offset + 1], wr_mas->entry);\n\t\twr_mas->pivots[offset] = mas->index - 1;\n\t\twr_mas->pivots[offset + 1] = mas->last;\n\t\tmas->offset++;  \n\t} else {\n\t\treturn false;\n\t}\n\n\ttrace_ma_write(__func__, mas, 0, wr_mas->entry);\n\t \n\tif (!wr_mas->entry || gap)\n\t\tmas_update_gap(mas);\n\n\treturn true;\n}\n\nstatic inline void mas_wr_extend_null(struct ma_wr_state *wr_mas)\n{\n\tstruct ma_state *mas = wr_mas->mas;\n\n\tif (!wr_mas->slots[wr_mas->offset_end]) {\n\t\t \n\t\tmas->last = wr_mas->end_piv;\n\t} else {\n\t\t \n\t\tif ((mas->last == wr_mas->end_piv) &&\n\t\t    (wr_mas->node_end != wr_mas->offset_end) &&\n\t\t    !wr_mas->slots[wr_mas->offset_end + 1]) {\n\t\t\twr_mas->offset_end++;\n\t\t\tif (wr_mas->offset_end == wr_mas->node_end)\n\t\t\t\tmas->last = mas->max;\n\t\t\telse\n\t\t\t\tmas->last = wr_mas->pivots[wr_mas->offset_end];\n\t\t\twr_mas->end_piv = mas->last;\n\t\t}\n\t}\n\n\tif (!wr_mas->content) {\n\t\t \n\t\tmas->index = wr_mas->r_min;\n\t} else {\n\t\t \n\t\tif (mas->index == wr_mas->r_min && mas->offset &&\n\t\t    !wr_mas->slots[mas->offset - 1]) {\n\t\t\tmas->offset--;\n\t\t\twr_mas->r_min = mas->index =\n\t\t\t\tmas_safe_min(mas, wr_mas->pivots, mas->offset);\n\t\t\twr_mas->r_max = wr_mas->pivots[mas->offset];\n\t\t}\n\t}\n}\n\nstatic inline void mas_wr_end_piv(struct ma_wr_state *wr_mas)\n{\n\twhile ((wr_mas->offset_end < wr_mas->node_end) &&\n\t       (wr_mas->mas->last > wr_mas->pivots[wr_mas->offset_end]))\n\t\twr_mas->offset_end++;\n\n\tif (wr_mas->offset_end < wr_mas->node_end)\n\t\twr_mas->end_piv = wr_mas->pivots[wr_mas->offset_end];\n\telse\n\t\twr_mas->end_piv = wr_mas->mas->max;\n\n\tif (!wr_mas->entry)\n\t\tmas_wr_extend_null(wr_mas);\n}\n\nstatic inline unsigned char mas_wr_new_end(struct ma_wr_state *wr_mas)\n{\n\tstruct ma_state *mas = wr_mas->mas;\n\tunsigned char new_end = wr_mas->node_end + 2;\n\n\tnew_end -= wr_mas->offset_end - mas->offset;\n\tif (wr_mas->r_min == mas->index)\n\t\tnew_end--;\n\n\tif (wr_mas->end_piv == mas->last)\n\t\tnew_end--;\n\n\treturn new_end;\n}\n\n \nstatic inline bool mas_wr_append(struct ma_wr_state *wr_mas,\n\t\tunsigned char new_end)\n{\n\tstruct ma_state *mas;\n\tvoid __rcu **slots;\n\tunsigned char end;\n\n\tmas = wr_mas->mas;\n\tif (mt_in_rcu(mas->tree))\n\t\treturn false;\n\n\tif (mas->offset != wr_mas->node_end)\n\t\treturn false;\n\n\tend = wr_mas->node_end;\n\tif (mas->offset != end)\n\t\treturn false;\n\n\tif (new_end < mt_pivots[wr_mas->type]) {\n\t\twr_mas->pivots[new_end] = wr_mas->pivots[end];\n\t\tma_set_meta(wr_mas->node, wr_mas->type, 0, new_end);\n\t}\n\n\tslots = wr_mas->slots;\n\tif (new_end == end + 1) {\n\t\tif (mas->last == wr_mas->r_max) {\n\t\t\t \n\t\t\trcu_assign_pointer(slots[new_end], wr_mas->entry);\n\t\t\twr_mas->pivots[end] = mas->index - 1;\n\t\t\tmas->offset = new_end;\n\t\t} else {\n\t\t\t \n\t\t\trcu_assign_pointer(slots[new_end], wr_mas->content);\n\t\t\twr_mas->pivots[end] = mas->last;\n\t\t\trcu_assign_pointer(slots[end], wr_mas->entry);\n\t\t}\n\t} else {\n\t\t \n\t\trcu_assign_pointer(slots[new_end], wr_mas->content);\n\t\twr_mas->pivots[end + 1] = mas->last;\n\t\trcu_assign_pointer(slots[end + 1], wr_mas->entry);\n\t\twr_mas->pivots[end] = mas->index - 1;\n\t\tmas->offset = end + 1;\n\t}\n\n\tif (!wr_mas->content || !wr_mas->entry)\n\t\tmas_update_gap(mas);\n\n\ttrace_ma_write(__func__, mas, new_end, wr_mas->entry);\n\treturn  true;\n}\n\n \nstatic void mas_wr_bnode(struct ma_wr_state *wr_mas)\n{\n\tstruct maple_big_node b_node;\n\n\ttrace_ma_write(__func__, wr_mas->mas, 0, wr_mas->entry);\n\tmemset(&b_node, 0, sizeof(struct maple_big_node));\n\tmas_store_b_node(wr_mas, &b_node, wr_mas->offset_end);\n\tmas_commit_b_node(wr_mas, &b_node, wr_mas->node_end);\n}\n\nstatic inline void mas_wr_modify(struct ma_wr_state *wr_mas)\n{\n\tstruct ma_state *mas = wr_mas->mas;\n\tunsigned char new_end;\n\n\t \n\tif (wr_mas->r_min == mas->index && wr_mas->r_max == mas->last) {\n\t\trcu_assign_pointer(wr_mas->slots[mas->offset], wr_mas->entry);\n\t\tif (!!wr_mas->entry ^ !!wr_mas->content)\n\t\t\tmas_update_gap(mas);\n\t\treturn;\n\t}\n\n\t \n\tnew_end = mas_wr_new_end(wr_mas);\n\tif (new_end >= mt_slots[wr_mas->type])\n\t\tgoto slow_path;\n\n\t \n\tif (mas_wr_append(wr_mas, new_end))\n\t\treturn;\n\n\tif (new_end == wr_mas->node_end && mas_wr_slot_store(wr_mas))\n\t\treturn;\n\n\tif (mas_wr_node_store(wr_mas, new_end))\n\t\treturn;\n\n\tif (mas_is_err(mas))\n\t\treturn;\n\nslow_path:\n\tmas_wr_bnode(wr_mas);\n}\n\n \nstatic inline void *mas_wr_store_entry(struct ma_wr_state *wr_mas)\n{\n\tstruct ma_state *mas = wr_mas->mas;\n\n\twr_mas->content = mas_start(mas);\n\tif (mas_is_none(mas) || mas_is_ptr(mas)) {\n\t\tmas_store_root(mas, wr_mas->entry);\n\t\treturn wr_mas->content;\n\t}\n\n\tif (unlikely(!mas_wr_walk(wr_mas))) {\n\t\tmas_wr_spanning_store(wr_mas);\n\t\treturn wr_mas->content;\n\t}\n\n\t \n\tmas_wr_end_piv(wr_mas);\n\t \n\tif (unlikely(!mas->index && mas->last == ULONG_MAX)) {\n\t\tmas_new_root(mas, wr_mas->entry);\n\t\treturn wr_mas->content;\n\t}\n\n\tmas_wr_modify(wr_mas);\n\treturn wr_mas->content;\n}\n\n \nstatic inline void *mas_insert(struct ma_state *mas, void *entry)\n{\n\tMA_WR_STATE(wr_mas, mas, entry);\n\n\t \n\twr_mas.content = mas_start(mas);\n\tif (wr_mas.content)\n\t\tgoto exists;\n\n\tif (mas_is_none(mas) || mas_is_ptr(mas)) {\n\t\tmas_store_root(mas, entry);\n\t\treturn NULL;\n\t}\n\n\t \n\tif (!mas_wr_walk(&wr_mas))\n\t\tgoto exists;\n\n\t \n\twr_mas.offset_end = mas->offset;\n\twr_mas.end_piv = wr_mas.r_max;\n\n\tif (wr_mas.content || (mas->last > wr_mas.r_max))\n\t\tgoto exists;\n\n\tif (!entry)\n\t\treturn NULL;\n\n\tmas_wr_modify(&wr_mas);\n\treturn wr_mas.content;\n\nexists:\n\tmas_set_err(mas, -EEXIST);\n\treturn wr_mas.content;\n\n}\n\nstatic inline void mas_rewalk(struct ma_state *mas, unsigned long index)\n{\nretry:\n\tmas_set(mas, index);\n\tmas_state_walk(mas);\n\tif (mas_is_start(mas))\n\t\tgoto retry;\n}\n\nstatic inline bool mas_rewalk_if_dead(struct ma_state *mas,\n\t\tstruct maple_node *node, const unsigned long index)\n{\n\tif (unlikely(ma_dead_node(node))) {\n\t\tmas_rewalk(mas, index);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nstatic inline int mas_prev_node(struct ma_state *mas, unsigned long min)\n{\n\tenum maple_type mt;\n\tint offset, level;\n\tvoid __rcu **slots;\n\tstruct maple_node *node;\n\tunsigned long *pivots;\n\tunsigned long max;\n\n\tnode = mas_mn(mas);\n\tif (!mas->min)\n\t\tgoto no_entry;\n\n\tmax = mas->min - 1;\n\tif (max < min)\n\t\tgoto no_entry;\n\n\tlevel = 0;\n\tdo {\n\t\tif (ma_is_root(node))\n\t\t\tgoto no_entry;\n\n\t\t \n\t\tif (unlikely(mas_ascend(mas)))\n\t\t\treturn 1;\n\t\toffset = mas->offset;\n\t\tlevel++;\n\t\tnode = mas_mn(mas);\n\t} while (!offset);\n\n\toffset--;\n\tmt = mte_node_type(mas->node);\n\twhile (level > 1) {\n\t\tlevel--;\n\t\tslots = ma_slots(node, mt);\n\t\tmas->node = mas_slot(mas, slots, offset);\n\t\tif (unlikely(ma_dead_node(node)))\n\t\t\treturn 1;\n\n\t\tmt = mte_node_type(mas->node);\n\t\tnode = mas_mn(mas);\n\t\tpivots = ma_pivots(node, mt);\n\t\toffset = ma_data_end(node, mt, pivots, max);\n\t\tif (unlikely(ma_dead_node(node)))\n\t\t\treturn 1;\n\t}\n\n\tslots = ma_slots(node, mt);\n\tmas->node = mas_slot(mas, slots, offset);\n\tpivots = ma_pivots(node, mt);\n\tif (unlikely(ma_dead_node(node)))\n\t\treturn 1;\n\n\tif (likely(offset))\n\t\tmas->min = pivots[offset - 1] + 1;\n\tmas->max = max;\n\tmas->offset = mas_data_end(mas);\n\tif (unlikely(mte_dead_node(mas->node)))\n\t\treturn 1;\n\n\treturn 0;\n\nno_entry:\n\tif (unlikely(ma_dead_node(node)))\n\t\treturn 1;\n\n\tmas->node = MAS_NONE;\n\treturn 0;\n}\n\n \nstatic void *mas_prev_slot(struct ma_state *mas, unsigned long min, bool empty,\n\t\t\t   bool set_underflow)\n{\n\tvoid *entry;\n\tvoid __rcu **slots;\n\tunsigned long pivot;\n\tenum maple_type type;\n\tunsigned long *pivots;\n\tstruct maple_node *node;\n\tunsigned long save_point = mas->index;\n\nretry:\n\tnode = mas_mn(mas);\n\ttype = mte_node_type(mas->node);\n\tpivots = ma_pivots(node, type);\n\tif (unlikely(mas_rewalk_if_dead(mas, node, save_point)))\n\t\tgoto retry;\n\n\tif (mas->min <= min) {\n\t\tpivot = mas_safe_min(mas, pivots, mas->offset);\n\n\t\tif (unlikely(mas_rewalk_if_dead(mas, node, save_point)))\n\t\t\tgoto retry;\n\n\t\tif (pivot <= min)\n\t\t\tgoto underflow;\n\t}\n\nagain:\n\tif (likely(mas->offset)) {\n\t\tmas->offset--;\n\t\tmas->last = mas->index - 1;\n\t\tmas->index = mas_safe_min(mas, pivots, mas->offset);\n\t} else  {\n\t\tif (mas_prev_node(mas, min)) {\n\t\t\tmas_rewalk(mas, save_point);\n\t\t\tgoto retry;\n\t\t}\n\n\t\tif (mas_is_none(mas))\n\t\t\tgoto underflow;\n\n\t\tmas->last = mas->max;\n\t\tnode = mas_mn(mas);\n\t\ttype = mte_node_type(mas->node);\n\t\tpivots = ma_pivots(node, type);\n\t\tmas->index = pivots[mas->offset - 1] + 1;\n\t}\n\n\tslots = ma_slots(node, type);\n\tentry = mas_slot(mas, slots, mas->offset);\n\tif (unlikely(mas_rewalk_if_dead(mas, node, save_point)))\n\t\tgoto retry;\n\n\tif (likely(entry))\n\t\treturn entry;\n\n\tif (!empty) {\n\t\tif (mas->index <= min)\n\t\t\tgoto underflow;\n\n\t\tgoto again;\n\t}\n\n\treturn entry;\n\nunderflow:\n\tif (set_underflow)\n\t\tmas->node = MAS_UNDERFLOW;\n\treturn NULL;\n}\n\n \nstatic inline int mas_next_node(struct ma_state *mas, struct maple_node *node,\n\t\t\t\tunsigned long max)\n{\n\tunsigned long min;\n\tunsigned long *pivots;\n\tstruct maple_enode *enode;\n\tint level = 0;\n\tunsigned char node_end;\n\tenum maple_type mt;\n\tvoid __rcu **slots;\n\n\tif (mas->max >= max)\n\t\tgoto no_entry;\n\n\tmin = mas->max + 1;\n\tlevel = 0;\n\tdo {\n\t\tif (ma_is_root(node))\n\t\t\tgoto no_entry;\n\n\t\t \n\t\tif (unlikely(mas_ascend(mas)))\n\t\t\treturn 1;\n\n\t\tlevel++;\n\t\tnode = mas_mn(mas);\n\t\tmt = mte_node_type(mas->node);\n\t\tpivots = ma_pivots(node, mt);\n\t\tnode_end = ma_data_end(node, mt, pivots, mas->max);\n\t\tif (unlikely(ma_dead_node(node)))\n\t\t\treturn 1;\n\n\t} while (unlikely(mas->offset == node_end));\n\n\tslots = ma_slots(node, mt);\n\tmas->offset++;\n\tenode = mas_slot(mas, slots, mas->offset);\n\tif (unlikely(ma_dead_node(node)))\n\t\treturn 1;\n\n\tif (level > 1)\n\t\tmas->offset = 0;\n\n\twhile (unlikely(level > 1)) {\n\t\tlevel--;\n\t\tmas->node = enode;\n\t\tnode = mas_mn(mas);\n\t\tmt = mte_node_type(mas->node);\n\t\tslots = ma_slots(node, mt);\n\t\tenode = mas_slot(mas, slots, 0);\n\t\tif (unlikely(ma_dead_node(node)))\n\t\t\treturn 1;\n\t}\n\n\tif (!mas->offset)\n\t\tpivots = ma_pivots(node, mt);\n\n\tmas->max = mas_safe_pivot(mas, pivots, mas->offset, mt);\n\tif (unlikely(ma_dead_node(node)))\n\t\treturn 1;\n\n\tmas->node = enode;\n\tmas->min = min;\n\treturn 0;\n\nno_entry:\n\tif (unlikely(ma_dead_node(node)))\n\t\treturn 1;\n\n\tmas->node = MAS_NONE;\n\treturn 0;\n}\n\n \nstatic void *mas_next_slot(struct ma_state *mas, unsigned long max, bool empty,\n\t\t\t   bool set_overflow)\n{\n\tvoid __rcu **slots;\n\tunsigned long *pivots;\n\tunsigned long pivot;\n\tenum maple_type type;\n\tstruct maple_node *node;\n\tunsigned char data_end;\n\tunsigned long save_point = mas->last;\n\tvoid *entry;\n\nretry:\n\tnode = mas_mn(mas);\n\ttype = mte_node_type(mas->node);\n\tpivots = ma_pivots(node, type);\n\tdata_end = ma_data_end(node, type, pivots, mas->max);\n\tif (unlikely(mas_rewalk_if_dead(mas, node, save_point)))\n\t\tgoto retry;\n\n\tif (mas->max >= max) {\n\t\tif (likely(mas->offset < data_end))\n\t\t\tpivot = pivots[mas->offset];\n\t\telse\n\t\t\tgoto overflow;\n\n\t\tif (unlikely(mas_rewalk_if_dead(mas, node, save_point)))\n\t\t\tgoto retry;\n\n\t\tif (pivot >= max)\n\t\t\tgoto overflow;\n\t}\n\n\tif (likely(mas->offset < data_end)) {\n\t\tmas->index = pivots[mas->offset] + 1;\nagain:\n\t\tmas->offset++;\n\t\tif (likely(mas->offset < data_end))\n\t\t\tmas->last = pivots[mas->offset];\n\t\telse\n\t\t\tmas->last = mas->max;\n\t} else  {\n\t\tif (mas_next_node(mas, node, max)) {\n\t\t\tmas_rewalk(mas, save_point);\n\t\t\tgoto retry;\n\t\t}\n\n\t\tif (WARN_ON_ONCE(mas_is_none(mas))) {\n\t\t\tmas->node = MAS_OVERFLOW;\n\t\t\treturn NULL;\n\t\t\tgoto overflow;\n\t\t}\n\n\t\tmas->offset = 0;\n\t\tmas->index = mas->min;\n\t\tnode = mas_mn(mas);\n\t\ttype = mte_node_type(mas->node);\n\t\tpivots = ma_pivots(node, type);\n\t\tmas->last = pivots[0];\n\t}\n\n\tslots = ma_slots(node, type);\n\tentry = mt_slot(mas->tree, slots, mas->offset);\n\tif (unlikely(mas_rewalk_if_dead(mas, node, save_point)))\n\t\tgoto retry;\n\n\tif (entry)\n\t\treturn entry;\n\n\tif (!empty) {\n\t\tif (mas->last >= max)\n\t\t\tgoto overflow;\n\n\t\tmas->index = mas->last + 1;\n\t\t \n\t\tgoto again;\n\t}\n\n\treturn entry;\n\noverflow:\n\tif (set_overflow)\n\t\tmas->node = MAS_OVERFLOW;\n\treturn NULL;\n}\n\n \nstatic inline void *mas_next_entry(struct ma_state *mas, unsigned long limit)\n{\n\tif (mas->last >= limit) {\n\t\tmas->node = MAS_OVERFLOW;\n\t\treturn NULL;\n\t}\n\n\treturn mas_next_slot(mas, limit, false, true);\n}\n\n \nstatic bool mas_rev_awalk(struct ma_state *mas, unsigned long size,\n\t\tunsigned long *gap_min, unsigned long *gap_max)\n{\n\tenum maple_type type = mte_node_type(mas->node);\n\tstruct maple_node *node = mas_mn(mas);\n\tunsigned long *pivots, *gaps;\n\tvoid __rcu **slots;\n\tunsigned long gap = 0;\n\tunsigned long max, min;\n\tunsigned char offset;\n\n\tif (unlikely(mas_is_err(mas)))\n\t\treturn true;\n\n\tif (ma_is_dense(type)) {\n\t\t \n\t\tmas->offset = (unsigned char)(mas->index - mas->min);\n\t\treturn true;\n\t}\n\n\tpivots = ma_pivots(node, type);\n\tslots = ma_slots(node, type);\n\tgaps = ma_gaps(node, type);\n\toffset = mas->offset;\n\tmin = mas_safe_min(mas, pivots, offset);\n\t \n\twhile (mas->last < min)\n\t\tmin = mas_safe_min(mas, pivots, --offset);\n\n\tmax = mas_safe_pivot(mas, pivots, offset, type);\n\twhile (mas->index <= max) {\n\t\tgap = 0;\n\t\tif (gaps)\n\t\t\tgap = gaps[offset];\n\t\telse if (!mas_slot(mas, slots, offset))\n\t\t\tgap = max - min + 1;\n\n\t\tif (gap) {\n\t\t\tif ((size <= gap) && (size <= mas->last - min + 1))\n\t\t\t\tbreak;\n\n\t\t\tif (!gaps) {\n\t\t\t\t \n\t\t\t\tif (offset < 2)\n\t\t\t\t\tgoto ascend;\n\n\t\t\t\toffset -= 2;\n\t\t\t\tmax = pivots[offset];\n\t\t\t\tmin = mas_safe_min(mas, pivots, offset);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tif (!offset)\n\t\t\tgoto ascend;\n\n\t\toffset--;\n\t\tmax = min - 1;\n\t\tmin = mas_safe_min(mas, pivots, offset);\n\t}\n\n\tif (unlikely((mas->index > max) || (size - 1 > max - mas->index)))\n\t\tgoto no_space;\n\n\tif (unlikely(ma_is_leaf(type))) {\n\t\tmas->offset = offset;\n\t\t*gap_min = min;\n\t\t*gap_max = min + gap - 1;\n\t\treturn true;\n\t}\n\n\t \n\tmas->node = mas_slot(mas, slots, offset);\n\tmas->min = min;\n\tmas->max = max;\n\tmas->offset = mas_data_end(mas);\n\treturn false;\n\nascend:\n\tif (!mte_is_root(mas->node))\n\t\treturn false;\n\nno_space:\n\tmas_set_err(mas, -EBUSY);\n\treturn false;\n}\n\nstatic inline bool mas_anode_descend(struct ma_state *mas, unsigned long size)\n{\n\tenum maple_type type = mte_node_type(mas->node);\n\tunsigned long pivot, min, gap = 0;\n\tunsigned char offset, data_end;\n\tunsigned long *gaps, *pivots;\n\tvoid __rcu **slots;\n\tstruct maple_node *node;\n\tbool found = false;\n\n\tif (ma_is_dense(type)) {\n\t\tmas->offset = (unsigned char)(mas->index - mas->min);\n\t\treturn true;\n\t}\n\n\tnode = mas_mn(mas);\n\tpivots = ma_pivots(node, type);\n\tslots = ma_slots(node, type);\n\tgaps = ma_gaps(node, type);\n\toffset = mas->offset;\n\tmin = mas_safe_min(mas, pivots, offset);\n\tdata_end = ma_data_end(node, type, pivots, mas->max);\n\tfor (; offset <= data_end; offset++) {\n\t\tpivot = mas_safe_pivot(mas, pivots, offset, type);\n\n\t\t \n\t\tif (mas->index > pivot)\n\t\t\tgoto next_slot;\n\n\t\tif (gaps)\n\t\t\tgap = gaps[offset];\n\t\telse if (!mas_slot(mas, slots, offset))\n\t\t\tgap = min(pivot, mas->last) - max(mas->index, min) + 1;\n\t\telse\n\t\t\tgoto next_slot;\n\n\t\tif (gap >= size) {\n\t\t\tif (ma_is_leaf(type)) {\n\t\t\t\tfound = true;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tif (mas->index <= pivot) {\n\t\t\t\tmas->node = mas_slot(mas, slots, offset);\n\t\t\t\tmas->min = min;\n\t\t\t\tmas->max = pivot;\n\t\t\t\toffset = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\nnext_slot:\n\t\tmin = pivot + 1;\n\t\tif (mas->last <= pivot) {\n\t\t\tmas_set_err(mas, -EBUSY);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tif (mte_is_root(mas->node))\n\t\tfound = true;\ndone:\n\tmas->offset = offset;\n\treturn found;\n}\n\n \nvoid *mas_walk(struct ma_state *mas)\n{\n\tvoid *entry;\n\n\tif (!mas_is_active(mas) || !mas_is_start(mas))\n\t\tmas->node = MAS_START;\nretry:\n\tentry = mas_state_walk(mas);\n\tif (mas_is_start(mas)) {\n\t\tgoto retry;\n\t} else if (mas_is_none(mas)) {\n\t\tmas->index = 0;\n\t\tmas->last = ULONG_MAX;\n\t} else if (mas_is_ptr(mas)) {\n\t\tif (!mas->index) {\n\t\t\tmas->last = 0;\n\t\t\treturn entry;\n\t\t}\n\n\t\tmas->index = 1;\n\t\tmas->last = ULONG_MAX;\n\t\tmas->node = MAS_NONE;\n\t\treturn NULL;\n\t}\n\n\treturn entry;\n}\nEXPORT_SYMBOL_GPL(mas_walk);\n\nstatic inline bool mas_rewind_node(struct ma_state *mas)\n{\n\tunsigned char slot;\n\n\tdo {\n\t\tif (mte_is_root(mas->node)) {\n\t\t\tslot = mas->offset;\n\t\t\tif (!slot)\n\t\t\t\treturn false;\n\t\t} else {\n\t\t\tmas_ascend(mas);\n\t\t\tslot = mas->offset;\n\t\t}\n\t} while (!slot);\n\n\tmas->offset = --slot;\n\treturn true;\n}\n\n \nstatic inline bool mas_skip_node(struct ma_state *mas)\n{\n\tif (mas_is_err(mas))\n\t\treturn false;\n\n\tdo {\n\t\tif (mte_is_root(mas->node)) {\n\t\t\tif (mas->offset >= mas_data_end(mas)) {\n\t\t\t\tmas_set_err(mas, -EBUSY);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t} else {\n\t\t\tmas_ascend(mas);\n\t\t}\n\t} while (mas->offset >= mas_data_end(mas));\n\n\tmas->offset++;\n\treturn true;\n}\n\n \nstatic inline void mas_awalk(struct ma_state *mas, unsigned long size)\n{\n\tstruct maple_enode *last = NULL;\n\n\t \n\twhile (!mas_is_err(mas) && !mas_anode_descend(mas, size)) {\n\t\tif (last == mas->node)\n\t\t\tmas_skip_node(mas);\n\t\telse\n\t\t\tlast = mas->node;\n\t}\n}\n\n \nstatic inline int mas_sparse_area(struct ma_state *mas, unsigned long min,\n\t\t\t\tunsigned long max, unsigned long size, bool fwd)\n{\n\tif (!unlikely(mas_is_none(mas)) && min == 0) {\n\t\tmin++;\n\t\t \n\t\tif (min > max || max - min + 1 < size)\n\t\t\treturn -EBUSY;\n\t}\n\t \n\n\tif (fwd) {\n\t\tmas->index = min;\n\t\tmas->last = min + size - 1;\n\t} else {\n\t\tmas->last = max;\n\t\tmas->index = max - size + 1;\n\t}\n\treturn 0;\n}\n\n \nint mas_empty_area(struct ma_state *mas, unsigned long min,\n\t\tunsigned long max, unsigned long size)\n{\n\tunsigned char offset;\n\tunsigned long *pivots;\n\tenum maple_type mt;\n\n\tif (min > max)\n\t\treturn -EINVAL;\n\n\tif (size == 0 || max - min < size - 1)\n\t\treturn -EINVAL;\n\n\tif (mas_is_start(mas))\n\t\tmas_start(mas);\n\telse if (mas->offset >= 2)\n\t\tmas->offset -= 2;\n\telse if (!mas_skip_node(mas))\n\t\treturn -EBUSY;\n\n\t \n\tif (mas_is_none(mas) || mas_is_ptr(mas))\n\t\treturn mas_sparse_area(mas, min, max, size, true);\n\n\t \n\tmas->index = min;\n\tmas->last = max;\n\tmas_awalk(mas, size);\n\n\tif (unlikely(mas_is_err(mas)))\n\t\treturn xa_err(mas->node);\n\n\toffset = mas->offset;\n\tif (unlikely(offset == MAPLE_NODE_SLOTS))\n\t\treturn -EBUSY;\n\n\tmt = mte_node_type(mas->node);\n\tpivots = ma_pivots(mas_mn(mas), mt);\n\tmin = mas_safe_min(mas, pivots, offset);\n\tif (mas->index < min)\n\t\tmas->index = min;\n\tmas->last = mas->index + size - 1;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mas_empty_area);\n\n \nint mas_empty_area_rev(struct ma_state *mas, unsigned long min,\n\t\tunsigned long max, unsigned long size)\n{\n\tstruct maple_enode *last = mas->node;\n\n\tif (min > max)\n\t\treturn -EINVAL;\n\n\tif (size == 0 || max - min < size - 1)\n\t\treturn -EINVAL;\n\n\tif (mas_is_start(mas)) {\n\t\tmas_start(mas);\n\t\tmas->offset = mas_data_end(mas);\n\t} else if (mas->offset >= 2) {\n\t\tmas->offset -= 2;\n\t} else if (!mas_rewind_node(mas)) {\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tif (mas_is_none(mas) || mas_is_ptr(mas))\n\t\treturn mas_sparse_area(mas, min, max, size, false);\n\n\t \n\tmas->index = min;\n\tmas->last = max;\n\n\twhile (!mas_rev_awalk(mas, size, &min, &max)) {\n\t\tif (last == mas->node) {\n\t\t\tif (!mas_rewind_node(mas))\n\t\t\t\treturn -EBUSY;\n\t\t} else {\n\t\t\tlast = mas->node;\n\t\t}\n\t}\n\n\tif (mas_is_err(mas))\n\t\treturn xa_err(mas->node);\n\n\tif (unlikely(mas->offset == MAPLE_NODE_SLOTS))\n\t\treturn -EBUSY;\n\n\t \n\tif (max < mas->last)\n\t\tmas->last = max;\n\n\tmas->index = mas->last - size + 1;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mas_empty_area_rev);\n\n \nstatic inline\nunsigned char mte_dead_leaves(struct maple_enode *enode, struct maple_tree *mt,\n\t\t\t      void __rcu **slots)\n{\n\tstruct maple_node *node;\n\tenum maple_type type;\n\tvoid *entry;\n\tint offset;\n\n\tfor (offset = 0; offset < mt_slot_count(enode); offset++) {\n\t\tentry = mt_slot(mt, slots, offset);\n\t\ttype = mte_node_type(entry);\n\t\tnode = mte_to_node(entry);\n\t\t \n\t\tif (!node || !type)\n\t\t\tbreak;\n\n\t\tmte_set_node_dead(entry);\n\t\tnode->type = type;\n\t\trcu_assign_pointer(slots[offset], node);\n\t}\n\n\treturn offset;\n}\n\n \nstatic void __rcu **mte_dead_walk(struct maple_enode **enode, unsigned char offset)\n{\n\tstruct maple_node *node, *next;\n\tvoid __rcu **slots = NULL;\n\n\tnext = mte_to_node(*enode);\n\tdo {\n\t\t*enode = ma_enode_ptr(next);\n\t\tnode = mte_to_node(*enode);\n\t\tslots = ma_slots(node, node->type);\n\t\tnext = rcu_dereference_protected(slots[offset],\n\t\t\t\t\tlock_is_held(&rcu_callback_map));\n\t\toffset = 0;\n\t} while (!ma_is_leaf(next->type));\n\n\treturn slots;\n}\n\n \nstatic void mt_free_walk(struct rcu_head *head)\n{\n\tvoid __rcu **slots;\n\tstruct maple_node *node, *start;\n\tstruct maple_enode *enode;\n\tunsigned char offset;\n\tenum maple_type type;\n\n\tnode = container_of(head, struct maple_node, rcu);\n\n\tif (ma_is_leaf(node->type))\n\t\tgoto free_leaf;\n\n\tstart = node;\n\tenode = mt_mk_node(node, node->type);\n\tslots = mte_dead_walk(&enode, 0);\n\tnode = mte_to_node(enode);\n\tdo {\n\t\tmt_free_bulk(node->slot_len, slots);\n\t\toffset = node->parent_slot + 1;\n\t\tenode = node->piv_parent;\n\t\tif (mte_to_node(enode) == node)\n\t\t\tgoto free_leaf;\n\n\t\ttype = mte_node_type(enode);\n\t\tslots = ma_slots(mte_to_node(enode), type);\n\t\tif ((offset < mt_slots[type]) &&\n\t\t    rcu_dereference_protected(slots[offset],\n\t\t\t\t\t      lock_is_held(&rcu_callback_map)))\n\t\t\tslots = mte_dead_walk(&enode, offset);\n\t\tnode = mte_to_node(enode);\n\t} while ((node != start) || (node->slot_len < offset));\n\n\tslots = ma_slots(node, node->type);\n\tmt_free_bulk(node->slot_len, slots);\n\nfree_leaf:\n\tmt_free_rcu(&node->rcu);\n}\n\nstatic inline void __rcu **mte_destroy_descend(struct maple_enode **enode,\n\tstruct maple_tree *mt, struct maple_enode *prev, unsigned char offset)\n{\n\tstruct maple_node *node;\n\tstruct maple_enode *next = *enode;\n\tvoid __rcu **slots = NULL;\n\tenum maple_type type;\n\tunsigned char next_offset = 0;\n\n\tdo {\n\t\t*enode = next;\n\t\tnode = mte_to_node(*enode);\n\t\ttype = mte_node_type(*enode);\n\t\tslots = ma_slots(node, type);\n\t\tnext = mt_slot_locked(mt, slots, next_offset);\n\t\tif ((mte_dead_node(next)))\n\t\t\tnext = mt_slot_locked(mt, slots, ++next_offset);\n\n\t\tmte_set_node_dead(*enode);\n\t\tnode->type = type;\n\t\tnode->piv_parent = prev;\n\t\tnode->parent_slot = offset;\n\t\toffset = next_offset;\n\t\tnext_offset = 0;\n\t\tprev = *enode;\n\t} while (!mte_is_leaf(next));\n\n\treturn slots;\n}\n\nstatic void mt_destroy_walk(struct maple_enode *enode, struct maple_tree *mt,\n\t\t\t    bool free)\n{\n\tvoid __rcu **slots;\n\tstruct maple_node *node = mte_to_node(enode);\n\tstruct maple_enode *start;\n\n\tif (mte_is_leaf(enode)) {\n\t\tnode->type = mte_node_type(enode);\n\t\tgoto free_leaf;\n\t}\n\n\tstart = enode;\n\tslots = mte_destroy_descend(&enode, mt, start, 0);\n\tnode = mte_to_node(enode);  \n\tdo {\n\t\tenum maple_type type;\n\t\tunsigned char offset;\n\t\tstruct maple_enode *parent, *tmp;\n\n\t\tnode->slot_len = mte_dead_leaves(enode, mt, slots);\n\t\tif (free)\n\t\t\tmt_free_bulk(node->slot_len, slots);\n\t\toffset = node->parent_slot + 1;\n\t\tenode = node->piv_parent;\n\t\tif (mte_to_node(enode) == node)\n\t\t\tgoto free_leaf;\n\n\t\ttype = mte_node_type(enode);\n\t\tslots = ma_slots(mte_to_node(enode), type);\n\t\tif (offset >= mt_slots[type])\n\t\t\tgoto next;\n\n\t\ttmp = mt_slot_locked(mt, slots, offset);\n\t\tif (mte_node_type(tmp) && mte_to_node(tmp)) {\n\t\t\tparent = enode;\n\t\t\tenode = tmp;\n\t\t\tslots = mte_destroy_descend(&enode, mt, parent, offset);\n\t\t}\nnext:\n\t\tnode = mte_to_node(enode);\n\t} while (start != enode);\n\n\tnode = mte_to_node(enode);\n\tnode->slot_len = mte_dead_leaves(enode, mt, slots);\n\tif (free)\n\t\tmt_free_bulk(node->slot_len, slots);\n\nfree_leaf:\n\tif (free)\n\t\tmt_free_rcu(&node->rcu);\n\telse\n\t\tmt_clear_meta(mt, node, node->type);\n}\n\n \nstatic inline void mte_destroy_walk(struct maple_enode *enode,\n\t\t\t\t    struct maple_tree *mt)\n{\n\tstruct maple_node *node = mte_to_node(enode);\n\n\tif (mt_in_rcu(mt)) {\n\t\tmt_destroy_walk(enode, mt, false);\n\t\tcall_rcu(&node->rcu, mt_free_walk);\n\t} else {\n\t\tmt_destroy_walk(enode, mt, true);\n\t}\n}\n\nstatic void mas_wr_store_setup(struct ma_wr_state *wr_mas)\n{\n\tif (!mas_is_active(wr_mas->mas)) {\n\t\tif (mas_is_start(wr_mas->mas))\n\t\t\treturn;\n\n\t\tif (unlikely(mas_is_paused(wr_mas->mas)))\n\t\t\tgoto reset;\n\n\t\tif (unlikely(mas_is_none(wr_mas->mas)))\n\t\t\tgoto reset;\n\n\t\tif (unlikely(mas_is_overflow(wr_mas->mas)))\n\t\t\tgoto reset;\n\n\t\tif (unlikely(mas_is_underflow(wr_mas->mas)))\n\t\t\tgoto reset;\n\t}\n\n\t \n\tif (wr_mas->mas->last > wr_mas->mas->max)\n\t\tgoto reset;\n\n\tif (wr_mas->entry)\n\t\treturn;\n\n\tif (mte_is_leaf(wr_mas->mas->node) &&\n\t    wr_mas->mas->last == wr_mas->mas->max)\n\t\tgoto reset;\n\n\treturn;\n\nreset:\n\tmas_reset(wr_mas->mas);\n}\n\n \n\n \nvoid *mas_store(struct ma_state *mas, void *entry)\n{\n\tMA_WR_STATE(wr_mas, mas, entry);\n\n\ttrace_ma_write(__func__, mas, 0, entry);\n#ifdef CONFIG_DEBUG_MAPLE_TREE\n\tif (MAS_WARN_ON(mas, mas->index > mas->last))\n\t\tpr_err(\"Error %lX > %lX %p\\n\", mas->index, mas->last, entry);\n\n\tif (mas->index > mas->last) {\n\t\tmas_set_err(mas, -EINVAL);\n\t\treturn NULL;\n\t}\n\n#endif\n\n\t \n\tmas_wr_store_setup(&wr_mas);\n\tmas_wr_store_entry(&wr_mas);\n\treturn wr_mas.content;\n}\nEXPORT_SYMBOL_GPL(mas_store);\n\n \nint mas_store_gfp(struct ma_state *mas, void *entry, gfp_t gfp)\n{\n\tMA_WR_STATE(wr_mas, mas, entry);\n\n\tmas_wr_store_setup(&wr_mas);\n\ttrace_ma_write(__func__, mas, 0, entry);\nretry:\n\tmas_wr_store_entry(&wr_mas);\n\tif (unlikely(mas_nomem(mas, gfp)))\n\t\tgoto retry;\n\n\tif (unlikely(mas_is_err(mas)))\n\t\treturn xa_err(mas->node);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mas_store_gfp);\n\n \nvoid mas_store_prealloc(struct ma_state *mas, void *entry)\n{\n\tMA_WR_STATE(wr_mas, mas, entry);\n\n\tmas_wr_store_setup(&wr_mas);\n\ttrace_ma_write(__func__, mas, 0, entry);\n\tmas_wr_store_entry(&wr_mas);\n\tMAS_WR_BUG_ON(&wr_mas, mas_is_err(mas));\n\tmas_destroy(mas);\n}\nEXPORT_SYMBOL_GPL(mas_store_prealloc);\n\n \nint mas_preallocate(struct ma_state *mas, void *entry, gfp_t gfp)\n{\n\tMA_WR_STATE(wr_mas, mas, entry);\n\tunsigned char node_size;\n\tint request = 1;\n\tint ret;\n\n\n\tif (unlikely(!mas->index && mas->last == ULONG_MAX))\n\t\tgoto ask_now;\n\n\tmas_wr_store_setup(&wr_mas);\n\twr_mas.content = mas_start(mas);\n\t \n\tif (unlikely(mas_is_none(mas) || mas_is_ptr(mas)))\n\t\tgoto ask_now;\n\n\tif (unlikely(!mas_wr_walk(&wr_mas))) {\n\t\t \n\t\trequest = 1 + mas_mt_height(mas) * 3;\n\t\tgoto ask_now;\n\t}\n\n\t \n\t \n\tif (wr_mas.r_min == mas->index && wr_mas.r_max == mas->last)\n\t\treturn 0;\n\n\tmas_wr_end_piv(&wr_mas);\n\tnode_size = mas_wr_new_end(&wr_mas);\n\n\t \n\tif (node_size == wr_mas.node_end) {\n\t\t \n\t\tif (!mt_in_rcu(mas->tree))\n\t\t\treturn 0;\n\t\t \n\t\tif (wr_mas.offset_end - mas->offset == 1)\n\t\t\treturn 0;\n\t}\n\n\tif (node_size >= mt_slots[wr_mas.type]) {\n\t\t \n\t\trequest = 1 + mas_mt_height(mas) * 2;\n\t\tgoto ask_now;\n\t}\n\n\t \n\tif (unlikely(mte_is_root(mas->node)))\n\t\tgoto ask_now;\n\n\t \n\tif (node_size  - 1 <= mt_min_slots[wr_mas.type])\n\t\trequest = mas_mt_height(mas) * 2 - 1;\n\n\t \nask_now:\n\tmas_node_count_gfp(mas, request, gfp);\n\tmas->mas_flags |= MA_STATE_PREALLOC;\n\tif (likely(!mas_is_err(mas)))\n\t\treturn 0;\n\n\tmas_set_alloc_req(mas, 0);\n\tret = xa_err(mas->node);\n\tmas_reset(mas);\n\tmas_destroy(mas);\n\tmas_reset(mas);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(mas_preallocate);\n\n \nvoid mas_destroy(struct ma_state *mas)\n{\n\tstruct maple_alloc *node;\n\tunsigned long total;\n\n\t \n\tif (mas->mas_flags & MA_STATE_REBALANCE) {\n\t\tunsigned char end;\n\n\t\tmas_start(mas);\n\t\tmtree_range_walk(mas);\n\t\tend = mas_data_end(mas) + 1;\n\t\tif (end < mt_min_slot_count(mas->node) - 1)\n\t\t\tmas_destroy_rebalance(mas, end);\n\n\t\tmas->mas_flags &= ~MA_STATE_REBALANCE;\n\t}\n\tmas->mas_flags &= ~(MA_STATE_BULK|MA_STATE_PREALLOC);\n\n\ttotal = mas_allocated(mas);\n\twhile (total) {\n\t\tnode = mas->alloc;\n\t\tmas->alloc = node->slot[0];\n\t\tif (node->node_count > 1) {\n\t\t\tsize_t count = node->node_count - 1;\n\n\t\t\tmt_free_bulk(count, (void __rcu **)&node->slot[1]);\n\t\t\ttotal -= count;\n\t\t}\n\t\tkmem_cache_free(maple_node_cache, node);\n\t\ttotal--;\n\t}\n\n\tmas->alloc = NULL;\n}\nEXPORT_SYMBOL_GPL(mas_destroy);\n\n \nint mas_expected_entries(struct ma_state *mas, unsigned long nr_entries)\n{\n\tint nonleaf_cap = MAPLE_ARANGE64_SLOTS - 2;\n\tstruct maple_enode *enode = mas->node;\n\tint nr_nodes;\n\tint ret;\n\n\t \n\n\t \n\tmas->mas_flags |= MA_STATE_BULK;\n\n\t \n\tnr_nodes = max(nr_entries, nr_entries * 2 + 1);\n\tif (!mt_is_alloc(mas->tree))\n\t\tnonleaf_cap = MAPLE_RANGE64_SLOTS - 2;\n\n\t \n\tnr_nodes = DIV_ROUND_UP(nr_nodes, MAPLE_RANGE64_SLOTS - 2);\n\t \n\tnr_nodes += DIV_ROUND_UP(nr_nodes, nonleaf_cap);\n\t \n\tmas_node_count_gfp(mas, nr_nodes + 3, GFP_KERNEL);\n\n\t \n\tmas->mas_flags |= MA_STATE_PREALLOC;\n\n\tif (!mas_is_err(mas))\n\t\treturn 0;\n\n\tret = xa_err(mas->node);\n\tmas->node = enode;\n\tmas_destroy(mas);\n\treturn ret;\n\n}\nEXPORT_SYMBOL_GPL(mas_expected_entries);\n\nstatic inline bool mas_next_setup(struct ma_state *mas, unsigned long max,\n\t\tvoid **entry)\n{\n\tbool was_none = mas_is_none(mas);\n\n\tif (unlikely(mas->last >= max)) {\n\t\tmas->node = MAS_OVERFLOW;\n\t\treturn true;\n\t}\n\n\tif (mas_is_active(mas))\n\t\treturn false;\n\n\tif (mas_is_none(mas) || mas_is_paused(mas)) {\n\t\tmas->node = MAS_START;\n\t} else if (mas_is_overflow(mas)) {\n\t\t \n\t\tmas->node = MAS_START;\n\t} else if (mas_is_underflow(mas)) {\n\t\tmas->node = MAS_START;\n\t\t*entry = mas_walk(mas);\n\t\tif (*entry)\n\t\t\treturn true;\n\t}\n\n\tif (mas_is_start(mas))\n\t\t*entry = mas_walk(mas);  \n\n\tif (mas_is_ptr(mas)) {\n\t\t*entry = NULL;\n\t\tif (was_none && mas->index == 0) {\n\t\t\tmas->index = mas->last = 0;\n\t\t\treturn true;\n\t\t}\n\t\tmas->index = 1;\n\t\tmas->last = ULONG_MAX;\n\t\tmas->node = MAS_NONE;\n\t\treturn true;\n\t}\n\n\tif (mas_is_none(mas))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nvoid *mas_next(struct ma_state *mas, unsigned long max)\n{\n\tvoid *entry = NULL;\n\n\tif (mas_next_setup(mas, max, &entry))\n\t\treturn entry;\n\n\t \n\treturn mas_next_slot(mas, max, false, true);\n}\nEXPORT_SYMBOL_GPL(mas_next);\n\n \nvoid *mas_next_range(struct ma_state *mas, unsigned long max)\n{\n\tvoid *entry = NULL;\n\n\tif (mas_next_setup(mas, max, &entry))\n\t\treturn entry;\n\n\t \n\treturn mas_next_slot(mas, max, true, true);\n}\nEXPORT_SYMBOL_GPL(mas_next_range);\n\n \nvoid *mt_next(struct maple_tree *mt, unsigned long index, unsigned long max)\n{\n\tvoid *entry = NULL;\n\tMA_STATE(mas, mt, index, index);\n\n\trcu_read_lock();\n\tentry = mas_next(&mas, max);\n\trcu_read_unlock();\n\treturn entry;\n}\nEXPORT_SYMBOL_GPL(mt_next);\n\nstatic inline bool mas_prev_setup(struct ma_state *mas, unsigned long min,\n\t\tvoid **entry)\n{\n\tif (unlikely(mas->index <= min)) {\n\t\tmas->node = MAS_UNDERFLOW;\n\t\treturn true;\n\t}\n\n\tif (mas_is_active(mas))\n\t\treturn false;\n\n\tif (mas_is_overflow(mas)) {\n\t\tmas->node = MAS_START;\n\t\t*entry = mas_walk(mas);\n\t\tif (*entry)\n\t\t\treturn true;\n\t}\n\n\tif (mas_is_none(mas) || mas_is_paused(mas)) {\n\t\tmas->node = MAS_START;\n\t} else if (mas_is_underflow(mas)) {\n\t\t \n\t\tmas->node = MAS_START;\n\t}\n\n\tif (mas_is_start(mas))\n\t\tmas_walk(mas);\n\n\tif (unlikely(mas_is_ptr(mas))) {\n\t\tif (!mas->index)\n\t\t\tgoto none;\n\t\tmas->index = mas->last = 0;\n\t\t*entry = mas_root(mas);\n\t\treturn true;\n\t}\n\n\tif (mas_is_none(mas)) {\n\t\tif (mas->index) {\n\t\t\t \n\t\t\tmas->index = mas->last = 0;\n\t\t\tmas->node = MAS_ROOT;\n\t\t\t*entry = mas_root(mas);\n\t\t\treturn true;\n\t\t}\n\t\treturn true;\n\t}\n\n\treturn false;\n\nnone:\n\tmas->node = MAS_NONE;\n\treturn true;\n}\n\n \nvoid *mas_prev(struct ma_state *mas, unsigned long min)\n{\n\tvoid *entry = NULL;\n\n\tif (mas_prev_setup(mas, min, &entry))\n\t\treturn entry;\n\n\treturn mas_prev_slot(mas, min, false, true);\n}\nEXPORT_SYMBOL_GPL(mas_prev);\n\n \nvoid *mas_prev_range(struct ma_state *mas, unsigned long min)\n{\n\tvoid *entry = NULL;\n\n\tif (mas_prev_setup(mas, min, &entry))\n\t\treturn entry;\n\n\treturn mas_prev_slot(mas, min, true, true);\n}\nEXPORT_SYMBOL_GPL(mas_prev_range);\n\n \nvoid *mt_prev(struct maple_tree *mt, unsigned long index, unsigned long min)\n{\n\tvoid *entry = NULL;\n\tMA_STATE(mas, mt, index, index);\n\n\trcu_read_lock();\n\tentry = mas_prev(&mas, min);\n\trcu_read_unlock();\n\treturn entry;\n}\nEXPORT_SYMBOL_GPL(mt_prev);\n\n \nvoid mas_pause(struct ma_state *mas)\n{\n\tmas->node = MAS_PAUSE;\n}\nEXPORT_SYMBOL_GPL(mas_pause);\n\n \nstatic inline bool mas_find_setup(struct ma_state *mas, unsigned long max,\n\t\tvoid **entry)\n{\n\tif (mas_is_active(mas)) {\n\t\tif (mas->last < max)\n\t\t\treturn false;\n\n\t\treturn true;\n\t}\n\n\tif (mas_is_paused(mas)) {\n\t\tif (unlikely(mas->last >= max))\n\t\t\treturn true;\n\n\t\tmas->index = ++mas->last;\n\t\tmas->node = MAS_START;\n\t} else if (mas_is_none(mas)) {\n\t\tif (unlikely(mas->last >= max))\n\t\t\treturn true;\n\n\t\tmas->index = mas->last;\n\t\tmas->node = MAS_START;\n\t} else if (mas_is_overflow(mas) || mas_is_underflow(mas)) {\n\t\tif (mas->index > max) {\n\t\t\tmas->node = MAS_OVERFLOW;\n\t\t\treturn true;\n\t\t}\n\n\t\tmas->node = MAS_START;\n\t}\n\n\tif (mas_is_start(mas)) {\n\t\t \n\t\tif (mas->index > max)\n\t\t\treturn true;\n\n\t\t*entry = mas_walk(mas);\n\t\tif (*entry)\n\t\t\treturn true;\n\n\t}\n\n\tif (unlikely(!mas_searchable(mas))) {\n\t\tif (unlikely(mas_is_ptr(mas)))\n\t\t\tgoto ptr_out_of_range;\n\n\t\treturn true;\n\t}\n\n\tif (mas->index == max)\n\t\treturn true;\n\n\treturn false;\n\nptr_out_of_range:\n\tmas->node = MAS_NONE;\n\tmas->index = 1;\n\tmas->last = ULONG_MAX;\n\treturn true;\n}\n\n \nvoid *mas_find(struct ma_state *mas, unsigned long max)\n{\n\tvoid *entry = NULL;\n\n\tif (mas_find_setup(mas, max, &entry))\n\t\treturn entry;\n\n\t \n\treturn mas_next_slot(mas, max, false, false);\n}\nEXPORT_SYMBOL_GPL(mas_find);\n\n \nvoid *mas_find_range(struct ma_state *mas, unsigned long max)\n{\n\tvoid *entry = NULL;\n\n\tif (mas_find_setup(mas, max, &entry))\n\t\treturn entry;\n\n\t \n\treturn mas_next_slot(mas, max, true, false);\n}\nEXPORT_SYMBOL_GPL(mas_find_range);\n\n \nstatic inline bool mas_find_rev_setup(struct ma_state *mas, unsigned long min,\n\t\tvoid **entry)\n{\n\tif (mas_is_active(mas)) {\n\t\tif (mas->index > min)\n\t\t\treturn false;\n\n\t\treturn true;\n\t}\n\n\tif (mas_is_paused(mas)) {\n\t\tif (unlikely(mas->index <= min)) {\n\t\t\tmas->node = MAS_NONE;\n\t\t\treturn true;\n\t\t}\n\t\tmas->node = MAS_START;\n\t\tmas->last = --mas->index;\n\t} else if (mas_is_none(mas)) {\n\t\tif (mas->index <= min)\n\t\t\tgoto none;\n\n\t\tmas->last = mas->index;\n\t\tmas->node = MAS_START;\n\t} else if (mas_is_underflow(mas) || mas_is_overflow(mas)) {\n\t\tif (mas->last <= min) {\n\t\t\tmas->node = MAS_UNDERFLOW;\n\t\t\treturn true;\n\t\t}\n\n\t\tmas->node = MAS_START;\n\t}\n\n\tif (mas_is_start(mas)) {\n\t\t \n\t\tif (mas->index < min)\n\t\t\treturn true;\n\n\t\t*entry = mas_walk(mas);\n\t\tif (*entry)\n\t\t\treturn true;\n\t}\n\n\tif (unlikely(!mas_searchable(mas))) {\n\t\tif (mas_is_ptr(mas))\n\t\t\tgoto none;\n\n\t\tif (mas_is_none(mas)) {\n\t\t\t \n\t\t\tmas->last = mas->index = 0;\n\t\t\tmas->node = MAS_ROOT;\n\t\t\t*entry = mas_root(mas);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tif (mas->index < min)\n\t\treturn true;\n\n\treturn false;\n\nnone:\n\tmas->node = MAS_NONE;\n\treturn true;\n}\n\n \nvoid *mas_find_rev(struct ma_state *mas, unsigned long min)\n{\n\tvoid *entry = NULL;\n\n\tif (mas_find_rev_setup(mas, min, &entry))\n\t\treturn entry;\n\n\t \n\treturn mas_prev_slot(mas, min, false, false);\n\n}\nEXPORT_SYMBOL_GPL(mas_find_rev);\n\n \nvoid *mas_find_range_rev(struct ma_state *mas, unsigned long min)\n{\n\tvoid *entry = NULL;\n\n\tif (mas_find_rev_setup(mas, min, &entry))\n\t\treturn entry;\n\n\t \n\treturn mas_prev_slot(mas, min, true, false);\n}\nEXPORT_SYMBOL_GPL(mas_find_range_rev);\n\n \nvoid *mas_erase(struct ma_state *mas)\n{\n\tvoid *entry;\n\tMA_WR_STATE(wr_mas, mas, NULL);\n\n\tif (mas_is_none(mas) || mas_is_paused(mas))\n\t\tmas->node = MAS_START;\n\n\t \n\tentry = mas_state_walk(mas);\n\tif (!entry)\n\t\treturn NULL;\n\nwrite_retry:\n\t \n\tmas_reset(mas);\n\tmas_wr_store_setup(&wr_mas);\n\tmas_wr_store_entry(&wr_mas);\n\tif (mas_nomem(mas, GFP_KERNEL))\n\t\tgoto write_retry;\n\n\treturn entry;\n}\nEXPORT_SYMBOL_GPL(mas_erase);\n\n \nbool mas_nomem(struct ma_state *mas, gfp_t gfp)\n\t__must_hold(mas->tree->ma_lock)\n{\n\tif (likely(mas->node != MA_ERROR(-ENOMEM))) {\n\t\tmas_destroy(mas);\n\t\treturn false;\n\t}\n\n\tif (gfpflags_allow_blocking(gfp) && !mt_external_lock(mas->tree)) {\n\t\tmtree_unlock(mas->tree);\n\t\tmas_alloc_nodes(mas, gfp);\n\t\tmtree_lock(mas->tree);\n\t} else {\n\t\tmas_alloc_nodes(mas, gfp);\n\t}\n\n\tif (!mas_allocated(mas))\n\t\treturn false;\n\n\tmas->node = MAS_START;\n\treturn true;\n}\n\nvoid __init maple_tree_init(void)\n{\n\tmaple_node_cache = kmem_cache_create(\"maple_node\",\n\t\t\tsizeof(struct maple_node), sizeof(struct maple_node),\n\t\t\tSLAB_PANIC, NULL);\n}\n\n \nvoid *mtree_load(struct maple_tree *mt, unsigned long index)\n{\n\tMA_STATE(mas, mt, index, index);\n\tvoid *entry;\n\n\ttrace_ma_read(__func__, &mas);\n\trcu_read_lock();\nretry:\n\tentry = mas_start(&mas);\n\tif (unlikely(mas_is_none(&mas)))\n\t\tgoto unlock;\n\n\tif (unlikely(mas_is_ptr(&mas))) {\n\t\tif (index)\n\t\t\tentry = NULL;\n\n\t\tgoto unlock;\n\t}\n\n\tentry = mtree_lookup_walk(&mas);\n\tif (!entry && unlikely(mas_is_start(&mas)))\n\t\tgoto retry;\nunlock:\n\trcu_read_unlock();\n\tif (xa_is_zero(entry))\n\t\treturn NULL;\n\n\treturn entry;\n}\nEXPORT_SYMBOL(mtree_load);\n\n \nint mtree_store_range(struct maple_tree *mt, unsigned long index,\n\t\tunsigned long last, void *entry, gfp_t gfp)\n{\n\tMA_STATE(mas, mt, index, last);\n\tMA_WR_STATE(wr_mas, &mas, entry);\n\n\ttrace_ma_write(__func__, &mas, 0, entry);\n\tif (WARN_ON_ONCE(xa_is_advanced(entry)))\n\t\treturn -EINVAL;\n\n\tif (index > last)\n\t\treturn -EINVAL;\n\n\tmtree_lock(mt);\nretry:\n\tmas_wr_store_entry(&wr_mas);\n\tif (mas_nomem(&mas, gfp))\n\t\tgoto retry;\n\n\tmtree_unlock(mt);\n\tif (mas_is_err(&mas))\n\t\treturn xa_err(mas.node);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(mtree_store_range);\n\n \nint mtree_store(struct maple_tree *mt, unsigned long index, void *entry,\n\t\t gfp_t gfp)\n{\n\treturn mtree_store_range(mt, index, index, entry, gfp);\n}\nEXPORT_SYMBOL(mtree_store);\n\n \nint mtree_insert_range(struct maple_tree *mt, unsigned long first,\n\t\tunsigned long last, void *entry, gfp_t gfp)\n{\n\tMA_STATE(ms, mt, first, last);\n\n\tif (WARN_ON_ONCE(xa_is_advanced(entry)))\n\t\treturn -EINVAL;\n\n\tif (first > last)\n\t\treturn -EINVAL;\n\n\tmtree_lock(mt);\nretry:\n\tmas_insert(&ms, entry);\n\tif (mas_nomem(&ms, gfp))\n\t\tgoto retry;\n\n\tmtree_unlock(mt);\n\tif (mas_is_err(&ms))\n\t\treturn xa_err(ms.node);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(mtree_insert_range);\n\n \nint mtree_insert(struct maple_tree *mt, unsigned long index, void *entry,\n\t\t gfp_t gfp)\n{\n\treturn mtree_insert_range(mt, index, index, entry, gfp);\n}\nEXPORT_SYMBOL(mtree_insert);\n\nint mtree_alloc_range(struct maple_tree *mt, unsigned long *startp,\n\t\tvoid *entry, unsigned long size, unsigned long min,\n\t\tunsigned long max, gfp_t gfp)\n{\n\tint ret = 0;\n\n\tMA_STATE(mas, mt, 0, 0);\n\tif (!mt_is_alloc(mt))\n\t\treturn -EINVAL;\n\n\tif (WARN_ON_ONCE(mt_is_reserved(entry)))\n\t\treturn -EINVAL;\n\n\tmtree_lock(mt);\nretry:\n\tret = mas_empty_area(&mas, min, max, size);\n\tif (ret)\n\t\tgoto unlock;\n\n\tmas_insert(&mas, entry);\n\t \n\tif (mas_nomem(&mas, gfp))\n\t\tgoto retry;\n\n\tif (mas_is_err(&mas))\n\t\tret = xa_err(mas.node);\n\telse\n\t\t*startp = mas.index;\n\nunlock:\n\tmtree_unlock(mt);\n\treturn ret;\n}\nEXPORT_SYMBOL(mtree_alloc_range);\n\nint mtree_alloc_rrange(struct maple_tree *mt, unsigned long *startp,\n\t\tvoid *entry, unsigned long size, unsigned long min,\n\t\tunsigned long max, gfp_t gfp)\n{\n\tint ret = 0;\n\n\tMA_STATE(mas, mt, 0, 0);\n\tif (!mt_is_alloc(mt))\n\t\treturn -EINVAL;\n\n\tif (WARN_ON_ONCE(mt_is_reserved(entry)))\n\t\treturn -EINVAL;\n\n\tmtree_lock(mt);\nretry:\n\tret = mas_empty_area_rev(&mas, min, max, size);\n\tif (ret)\n\t\tgoto unlock;\n\n\tmas_insert(&mas, entry);\n\t \n\tif (mas_nomem(&mas, gfp))\n\t\tgoto retry;\n\n\tif (mas_is_err(&mas))\n\t\tret = xa_err(mas.node);\n\telse\n\t\t*startp = mas.index;\n\nunlock:\n\tmtree_unlock(mt);\n\treturn ret;\n}\nEXPORT_SYMBOL(mtree_alloc_rrange);\n\n \nvoid *mtree_erase(struct maple_tree *mt, unsigned long index)\n{\n\tvoid *entry = NULL;\n\n\tMA_STATE(mas, mt, index, index);\n\ttrace_ma_op(__func__, &mas);\n\n\tmtree_lock(mt);\n\tentry = mas_erase(&mas);\n\tmtree_unlock(mt);\n\n\treturn entry;\n}\nEXPORT_SYMBOL(mtree_erase);\n\n \nvoid __mt_destroy(struct maple_tree *mt)\n{\n\tvoid *root = mt_root_locked(mt);\n\n\trcu_assign_pointer(mt->ma_root, NULL);\n\tif (xa_is_node(root))\n\t\tmte_destroy_walk(root, mt);\n\n\tmt->ma_flags = 0;\n}\nEXPORT_SYMBOL_GPL(__mt_destroy);\n\n \nvoid mtree_destroy(struct maple_tree *mt)\n{\n\tmtree_lock(mt);\n\t__mt_destroy(mt);\n\tmtree_unlock(mt);\n}\nEXPORT_SYMBOL(mtree_destroy);\n\n \nvoid *mt_find(struct maple_tree *mt, unsigned long *index, unsigned long max)\n{\n\tMA_STATE(mas, mt, *index, *index);\n\tvoid *entry;\n#ifdef CONFIG_DEBUG_MAPLE_TREE\n\tunsigned long copy = *index;\n#endif\n\n\ttrace_ma_read(__func__, &mas);\n\n\tif ((*index) > max)\n\t\treturn NULL;\n\n\trcu_read_lock();\nretry:\n\tentry = mas_state_walk(&mas);\n\tif (mas_is_start(&mas))\n\t\tgoto retry;\n\n\tif (unlikely(xa_is_zero(entry)))\n\t\tentry = NULL;\n\n\tif (entry)\n\t\tgoto unlock;\n\n\twhile (mas_searchable(&mas) && (mas.last < max)) {\n\t\tentry = mas_next_entry(&mas, max);\n\t\tif (likely(entry && !xa_is_zero(entry)))\n\t\t\tbreak;\n\t}\n\n\tif (unlikely(xa_is_zero(entry)))\n\t\tentry = NULL;\nunlock:\n\trcu_read_unlock();\n\tif (likely(entry)) {\n\t\t*index = mas.last + 1;\n#ifdef CONFIG_DEBUG_MAPLE_TREE\n\t\tif (MT_WARN_ON(mt, (*index) && ((*index) <= copy)))\n\t\t\tpr_err(\"index not increased! %lx <= %lx\\n\",\n\t\t\t       *index, copy);\n#endif\n\t}\n\n\treturn entry;\n}\nEXPORT_SYMBOL(mt_find);\n\n \nvoid *mt_find_after(struct maple_tree *mt, unsigned long *index,\n\t\t    unsigned long max)\n{\n\tif (!(*index))\n\t\treturn NULL;\n\n\treturn mt_find(mt, index, max);\n}\nEXPORT_SYMBOL(mt_find_after);\n\n#ifdef CONFIG_DEBUG_MAPLE_TREE\natomic_t maple_tree_tests_run;\nEXPORT_SYMBOL_GPL(maple_tree_tests_run);\natomic_t maple_tree_tests_passed;\nEXPORT_SYMBOL_GPL(maple_tree_tests_passed);\n\n#ifndef __KERNEL__\nextern void kmem_cache_set_non_kernel(struct kmem_cache *, unsigned int);\nvoid mt_set_non_kernel(unsigned int val)\n{\n\tkmem_cache_set_non_kernel(maple_node_cache, val);\n}\n\nextern unsigned long kmem_cache_get_alloc(struct kmem_cache *);\nunsigned long mt_get_alloc_size(void)\n{\n\treturn kmem_cache_get_alloc(maple_node_cache);\n}\n\nextern void kmem_cache_zero_nr_tallocated(struct kmem_cache *);\nvoid mt_zero_nr_tallocated(void)\n{\n\tkmem_cache_zero_nr_tallocated(maple_node_cache);\n}\n\nextern unsigned int kmem_cache_nr_tallocated(struct kmem_cache *);\nunsigned int mt_nr_tallocated(void)\n{\n\treturn kmem_cache_nr_tallocated(maple_node_cache);\n}\n\nextern unsigned int kmem_cache_nr_allocated(struct kmem_cache *);\nunsigned int mt_nr_allocated(void)\n{\n\treturn kmem_cache_nr_allocated(maple_node_cache);\n}\n\n \nstatic inline int mas_dead_node(struct ma_state *mas, unsigned long index)\n{\n\tif (unlikely(!mas_searchable(mas) || mas_is_start(mas)))\n\t\treturn 0;\n\n\tif (likely(!mte_dead_node(mas->node)))\n\t\treturn 0;\n\n\tmas_rewalk(mas, index);\n\treturn 1;\n}\n\nvoid mt_cache_shrink(void)\n{\n}\n#else\n \nvoid mt_cache_shrink(void)\n{\n\tkmem_cache_shrink(maple_node_cache);\n\n}\nEXPORT_SYMBOL_GPL(mt_cache_shrink);\n\n#endif  \n \nstatic inline struct maple_enode *mas_get_slot(struct ma_state *mas,\n\t\tunsigned char offset)\n{\n\treturn mas_slot(mas, ma_slots(mas_mn(mas), mte_node_type(mas->node)),\n\t\t\toffset);\n}\n\n \nstatic void mas_dfs_postorder(struct ma_state *mas, unsigned long max)\n{\n\n\tstruct maple_enode *p = MAS_NONE, *mn = mas->node;\n\tunsigned long p_min, p_max;\n\n\tmas_next_node(mas, mas_mn(mas), max);\n\tif (!mas_is_none(mas))\n\t\treturn;\n\n\tif (mte_is_root(mn))\n\t\treturn;\n\n\tmas->node = mn;\n\tmas_ascend(mas);\n\tdo {\n\t\tp = mas->node;\n\t\tp_min = mas->min;\n\t\tp_max = mas->max;\n\t\tmas_prev_node(mas, 0);\n\t} while (!mas_is_none(mas));\n\n\tmas->node = p;\n\tmas->max = p_max;\n\tmas->min = p_min;\n}\n\n \nstatic void mt_dump_node(const struct maple_tree *mt, void *entry,\n\t\tunsigned long min, unsigned long max, unsigned int depth,\n\t\tenum mt_dump_format format);\nstatic void mt_dump_range(unsigned long min, unsigned long max,\n\t\t\t  unsigned int depth, enum mt_dump_format format)\n{\n\tstatic const char spaces[] = \"                                \";\n\n\tswitch(format) {\n\tcase mt_dump_hex:\n\t\tif (min == max)\n\t\t\tpr_info(\"%.*s%lx: \", depth * 2, spaces, min);\n\t\telse\n\t\t\tpr_info(\"%.*s%lx-%lx: \", depth * 2, spaces, min, max);\n\t\tbreak;\n\tdefault:\n\tcase mt_dump_dec:\n\t\tif (min == max)\n\t\t\tpr_info(\"%.*s%lu: \", depth * 2, spaces, min);\n\t\telse\n\t\t\tpr_info(\"%.*s%lu-%lu: \", depth * 2, spaces, min, max);\n\t}\n}\n\nstatic void mt_dump_entry(void *entry, unsigned long min, unsigned long max,\n\t\t\t  unsigned int depth, enum mt_dump_format format)\n{\n\tmt_dump_range(min, max, depth, format);\n\n\tif (xa_is_value(entry))\n\t\tpr_cont(\"value %ld (0x%lx) [%p]\\n\", xa_to_value(entry),\n\t\t\t\txa_to_value(entry), entry);\n\telse if (xa_is_zero(entry))\n\t\tpr_cont(\"zero (%ld)\\n\", xa_to_internal(entry));\n\telse if (mt_is_reserved(entry))\n\t\tpr_cont(\"UNKNOWN ENTRY (%p)\\n\", entry);\n\telse\n\t\tpr_cont(\"%p\\n\", entry);\n}\n\nstatic void mt_dump_range64(const struct maple_tree *mt, void *entry,\n\t\tunsigned long min, unsigned long max, unsigned int depth,\n\t\tenum mt_dump_format format)\n{\n\tstruct maple_range_64 *node = &mte_to_node(entry)->mr64;\n\tbool leaf = mte_is_leaf(entry);\n\tunsigned long first = min;\n\tint i;\n\n\tpr_cont(\" contents: \");\n\tfor (i = 0; i < MAPLE_RANGE64_SLOTS - 1; i++) {\n\t\tswitch(format) {\n\t\tcase mt_dump_hex:\n\t\t\tpr_cont(\"%p %lX \", node->slot[i], node->pivot[i]);\n\t\t\tbreak;\n\t\tdefault:\n\t\tcase mt_dump_dec:\n\t\t\tpr_cont(\"%p %lu \", node->slot[i], node->pivot[i]);\n\t\t}\n\t}\n\tpr_cont(\"%p\\n\", node->slot[i]);\n\tfor (i = 0; i < MAPLE_RANGE64_SLOTS; i++) {\n\t\tunsigned long last = max;\n\n\t\tif (i < (MAPLE_RANGE64_SLOTS - 1))\n\t\t\tlast = node->pivot[i];\n\t\telse if (!node->slot[i] && max != mt_node_max(entry))\n\t\t\tbreak;\n\t\tif (last == 0 && i > 0)\n\t\t\tbreak;\n\t\tif (leaf)\n\t\t\tmt_dump_entry(mt_slot(mt, node->slot, i),\n\t\t\t\t\tfirst, last, depth + 1, format);\n\t\telse if (node->slot[i])\n\t\t\tmt_dump_node(mt, mt_slot(mt, node->slot, i),\n\t\t\t\t\tfirst, last, depth + 1, format);\n\n\t\tif (last == max)\n\t\t\tbreak;\n\t\tif (last > max) {\n\t\t\tswitch(format) {\n\t\t\tcase mt_dump_hex:\n\t\t\t\tpr_err(\"node %p last (%lx) > max (%lx) at pivot %d!\\n\",\n\t\t\t\t\tnode, last, max, i);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\tcase mt_dump_dec:\n\t\t\t\tpr_err(\"node %p last (%lu) > max (%lu) at pivot %d!\\n\",\n\t\t\t\t\tnode, last, max, i);\n\t\t\t}\n\t\t}\n\t\tfirst = last + 1;\n\t}\n}\n\nstatic void mt_dump_arange64(const struct maple_tree *mt, void *entry,\n\tunsigned long min, unsigned long max, unsigned int depth,\n\tenum mt_dump_format format)\n{\n\tstruct maple_arange_64 *node = &mte_to_node(entry)->ma64;\n\tbool leaf = mte_is_leaf(entry);\n\tunsigned long first = min;\n\tint i;\n\n\tpr_cont(\" contents: \");\n\tfor (i = 0; i < MAPLE_ARANGE64_SLOTS; i++) {\n\t\tswitch (format) {\n\t\tcase mt_dump_hex:\n\t\t\tpr_cont(\"%lx \", node->gap[i]);\n\t\t\tbreak;\n\t\tdefault:\n\t\tcase mt_dump_dec:\n\t\t\tpr_cont(\"%lu \", node->gap[i]);\n\t\t}\n\t}\n\tpr_cont(\"| %02X %02X| \", node->meta.end, node->meta.gap);\n\tfor (i = 0; i < MAPLE_ARANGE64_SLOTS - 1; i++) {\n\t\tswitch (format) {\n\t\tcase mt_dump_hex:\n\t\t\tpr_cont(\"%p %lX \", node->slot[i], node->pivot[i]);\n\t\t\tbreak;\n\t\tdefault:\n\t\tcase mt_dump_dec:\n\t\t\tpr_cont(\"%p %lu \", node->slot[i], node->pivot[i]);\n\t\t}\n\t}\n\tpr_cont(\"%p\\n\", node->slot[i]);\n\tfor (i = 0; i < MAPLE_ARANGE64_SLOTS; i++) {\n\t\tunsigned long last = max;\n\n\t\tif (i < (MAPLE_ARANGE64_SLOTS - 1))\n\t\t\tlast = node->pivot[i];\n\t\telse if (!node->slot[i])\n\t\t\tbreak;\n\t\tif (last == 0 && i > 0)\n\t\t\tbreak;\n\t\tif (leaf)\n\t\t\tmt_dump_entry(mt_slot(mt, node->slot, i),\n\t\t\t\t\tfirst, last, depth + 1, format);\n\t\telse if (node->slot[i])\n\t\t\tmt_dump_node(mt, mt_slot(mt, node->slot, i),\n\t\t\t\t\tfirst, last, depth + 1, format);\n\n\t\tif (last == max)\n\t\t\tbreak;\n\t\tif (last > max) {\n\t\t\tpr_err(\"node %p last (%lu) > max (%lu) at pivot %d!\\n\",\n\t\t\t\t\tnode, last, max, i);\n\t\t\tbreak;\n\t\t}\n\t\tfirst = last + 1;\n\t}\n}\n\nstatic void mt_dump_node(const struct maple_tree *mt, void *entry,\n\t\tunsigned long min, unsigned long max, unsigned int depth,\n\t\tenum mt_dump_format format)\n{\n\tstruct maple_node *node = mte_to_node(entry);\n\tunsigned int type = mte_node_type(entry);\n\tunsigned int i;\n\n\tmt_dump_range(min, max, depth, format);\n\n\tpr_cont(\"node %p depth %d type %d parent %p\", node, depth, type,\n\t\t\tnode ? node->parent : NULL);\n\tswitch (type) {\n\tcase maple_dense:\n\t\tpr_cont(\"\\n\");\n\t\tfor (i = 0; i < MAPLE_NODE_SLOTS; i++) {\n\t\t\tif (min + i > max)\n\t\t\t\tpr_cont(\"OUT OF RANGE: \");\n\t\t\tmt_dump_entry(mt_slot(mt, node->slot, i),\n\t\t\t\t\tmin + i, min + i, depth, format);\n\t\t}\n\t\tbreak;\n\tcase maple_leaf_64:\n\tcase maple_range_64:\n\t\tmt_dump_range64(mt, entry, min, max, depth, format);\n\t\tbreak;\n\tcase maple_arange_64:\n\t\tmt_dump_arange64(mt, entry, min, max, depth, format);\n\t\tbreak;\n\n\tdefault:\n\t\tpr_cont(\" UNKNOWN TYPE\\n\");\n\t}\n}\n\nvoid mt_dump(const struct maple_tree *mt, enum mt_dump_format format)\n{\n\tvoid *entry = rcu_dereference_check(mt->ma_root, mt_locked(mt));\n\n\tpr_info(\"maple_tree(%p) flags %X, height %u root %p\\n\",\n\t\t mt, mt->ma_flags, mt_height(mt), entry);\n\tif (!xa_is_node(entry))\n\t\tmt_dump_entry(entry, 0, 0, 0, format);\n\telse if (entry)\n\t\tmt_dump_node(mt, entry, 0, mt_node_max(entry), 0, format);\n}\nEXPORT_SYMBOL_GPL(mt_dump);\n\n \nstatic void mas_validate_gaps(struct ma_state *mas)\n{\n\tstruct maple_enode *mte = mas->node;\n\tstruct maple_node *p_mn, *node = mte_to_node(mte);\n\tenum maple_type mt = mte_node_type(mas->node);\n\tunsigned long gap = 0, max_gap = 0;\n\tunsigned long p_end, p_start = mas->min;\n\tunsigned char p_slot, offset;\n\tunsigned long *gaps = NULL;\n\tunsigned long *pivots = ma_pivots(node, mt);\n\tunsigned int i;\n\n\tif (ma_is_dense(mt)) {\n\t\tfor (i = 0; i < mt_slot_count(mte); i++) {\n\t\t\tif (mas_get_slot(mas, i)) {\n\t\t\t\tif (gap > max_gap)\n\t\t\t\t\tmax_gap = gap;\n\t\t\t\tgap = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tgap++;\n\t\t}\n\t\tgoto counted;\n\t}\n\n\tgaps = ma_gaps(node, mt);\n\tfor (i = 0; i < mt_slot_count(mte); i++) {\n\t\tp_end = mas_safe_pivot(mas, pivots, i, mt);\n\n\t\tif (!gaps) {\n\t\t\tif (!mas_get_slot(mas, i))\n\t\t\t\tgap = p_end - p_start + 1;\n\t\t} else {\n\t\t\tvoid *entry = mas_get_slot(mas, i);\n\n\t\t\tgap = gaps[i];\n\t\t\tMT_BUG_ON(mas->tree, !entry);\n\n\t\t\tif (gap > p_end - p_start + 1) {\n\t\t\t\tpr_err(\"%p[%u] %lu >= %lu - %lu + 1 (%lu)\\n\",\n\t\t\t\t       mas_mn(mas), i, gap, p_end, p_start,\n\t\t\t\t       p_end - p_start + 1);\n\t\t\t\tMT_BUG_ON(mas->tree, gap > p_end - p_start + 1);\n\t\t\t}\n\t\t}\n\n\t\tif (gap > max_gap)\n\t\t\tmax_gap = gap;\n\n\t\tp_start = p_end + 1;\n\t\tif (p_end >= mas->max)\n\t\t\tbreak;\n\t}\n\ncounted:\n\tif (mt == maple_arange_64) {\n\t\toffset = ma_meta_gap(node, mt);\n\t\tif (offset > i) {\n\t\t\tpr_err(\"gap offset %p[%u] is invalid\\n\", node, offset);\n\t\t\tMT_BUG_ON(mas->tree, 1);\n\t\t}\n\n\t\tif (gaps[offset] != max_gap) {\n\t\t\tpr_err(\"gap %p[%u] is not the largest gap %lu\\n\",\n\t\t\t       node, offset, max_gap);\n\t\t\tMT_BUG_ON(mas->tree, 1);\n\t\t}\n\n\t\tMT_BUG_ON(mas->tree, !gaps);\n\t\tfor (i++ ; i < mt_slot_count(mte); i++) {\n\t\t\tif (gaps[i] != 0) {\n\t\t\t\tpr_err(\"gap %p[%u] beyond node limit != 0\\n\",\n\t\t\t\t       node, i);\n\t\t\t\tMT_BUG_ON(mas->tree, 1);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (mte_is_root(mte))\n\t\treturn;\n\n\tp_slot = mte_parent_slot(mas->node);\n\tp_mn = mte_parent(mte);\n\tMT_BUG_ON(mas->tree, max_gap > mas->max);\n\tif (ma_gaps(p_mn, mas_parent_type(mas, mte))[p_slot] != max_gap) {\n\t\tpr_err(\"gap %p[%u] != %lu\\n\", p_mn, p_slot, max_gap);\n\t\tmt_dump(mas->tree, mt_dump_hex);\n\t\tMT_BUG_ON(mas->tree, 1);\n\t}\n}\n\nstatic void mas_validate_parent_slot(struct ma_state *mas)\n{\n\tstruct maple_node *parent;\n\tstruct maple_enode *node;\n\tenum maple_type p_type;\n\tunsigned char p_slot;\n\tvoid __rcu **slots;\n\tint i;\n\n\tif (mte_is_root(mas->node))\n\t\treturn;\n\n\tp_slot = mte_parent_slot(mas->node);\n\tp_type = mas_parent_type(mas, mas->node);\n\tparent = mte_parent(mas->node);\n\tslots = ma_slots(parent, p_type);\n\tMT_BUG_ON(mas->tree, mas_mn(mas) == parent);\n\n\t \n\n\tfor (i = 0; i < mt_slots[p_type]; i++) {\n\t\tnode = mas_slot(mas, slots, i);\n\t\tif (i == p_slot) {\n\t\t\tif (node != mas->node)\n\t\t\t\tpr_err(\"parent %p[%u] does not have %p\\n\",\n\t\t\t\t\tparent, i, mas_mn(mas));\n\t\t\tMT_BUG_ON(mas->tree, node != mas->node);\n\t\t} else if (node == mas->node) {\n\t\t\tpr_err(\"Invalid child %p at parent %p[%u] p_slot %u\\n\",\n\t\t\t       mas_mn(mas), parent, i, p_slot);\n\t\t\tMT_BUG_ON(mas->tree, node == mas->node);\n\t\t}\n\t}\n}\n\nstatic void mas_validate_child_slot(struct ma_state *mas)\n{\n\tenum maple_type type = mte_node_type(mas->node);\n\tvoid __rcu **slots = ma_slots(mte_to_node(mas->node), type);\n\tunsigned long *pivots = ma_pivots(mte_to_node(mas->node), type);\n\tstruct maple_enode *child;\n\tunsigned char i;\n\n\tif (mte_is_leaf(mas->node))\n\t\treturn;\n\n\tfor (i = 0; i < mt_slots[type]; i++) {\n\t\tchild = mas_slot(mas, slots, i);\n\n\t\tif (!child) {\n\t\t\tpr_err(\"Non-leaf node lacks child at %p[%u]\\n\",\n\t\t\t       mas_mn(mas), i);\n\t\t\tMT_BUG_ON(mas->tree, 1);\n\t\t}\n\n\t\tif (mte_parent_slot(child) != i) {\n\t\t\tpr_err(\"Slot error at %p[%u]: child %p has pslot %u\\n\",\n\t\t\t       mas_mn(mas), i, mte_to_node(child),\n\t\t\t       mte_parent_slot(child));\n\t\t\tMT_BUG_ON(mas->tree, 1);\n\t\t}\n\n\t\tif (mte_parent(child) != mte_to_node(mas->node)) {\n\t\t\tpr_err(\"child %p has parent %p not %p\\n\",\n\t\t\t       mte_to_node(child), mte_parent(child),\n\t\t\t       mte_to_node(mas->node));\n\t\t\tMT_BUG_ON(mas->tree, 1);\n\t\t}\n\n\t\tif (i < mt_pivots[type] && pivots[i] == mas->max)\n\t\t\tbreak;\n\t}\n}\n\n \nstatic void mas_validate_limits(struct ma_state *mas)\n{\n\tint i;\n\tunsigned long prev_piv = 0;\n\tenum maple_type type = mte_node_type(mas->node);\n\tvoid __rcu **slots = ma_slots(mte_to_node(mas->node), type);\n\tunsigned long *pivots = ma_pivots(mas_mn(mas), type);\n\n\tfor (i = 0; i < mt_slots[type]; i++) {\n\t\tunsigned long piv;\n\n\t\tpiv = mas_safe_pivot(mas, pivots, i, type);\n\n\t\tif (!piv && (i != 0)) {\n\t\t\tpr_err(\"Missing node limit pivot at %p[%u]\",\n\t\t\t       mas_mn(mas), i);\n\t\t\tMAS_WARN_ON(mas, 1);\n\t\t}\n\n\t\tif (prev_piv > piv) {\n\t\t\tpr_err(\"%p[%u] piv %lu < prev_piv %lu\\n\",\n\t\t\t\tmas_mn(mas), i, piv, prev_piv);\n\t\t\tMAS_WARN_ON(mas, piv < prev_piv);\n\t\t}\n\n\t\tif (piv < mas->min) {\n\t\t\tpr_err(\"%p[%u] %lu < %lu\\n\", mas_mn(mas), i,\n\t\t\t\tpiv, mas->min);\n\t\t\tMAS_WARN_ON(mas, piv < mas->min);\n\t\t}\n\t\tif (piv > mas->max) {\n\t\t\tpr_err(\"%p[%u] %lu > %lu\\n\", mas_mn(mas), i,\n\t\t\t\tpiv, mas->max);\n\t\t\tMAS_WARN_ON(mas, piv > mas->max);\n\t\t}\n\t\tprev_piv = piv;\n\t\tif (piv == mas->max)\n\t\t\tbreak;\n\t}\n\n\tif (mas_data_end(mas) != i) {\n\t\tpr_err(\"node%p: data_end %u != the last slot offset %u\\n\",\n\t\t       mas_mn(mas), mas_data_end(mas), i);\n\t\tMT_BUG_ON(mas->tree, 1);\n\t}\n\n\tfor (i += 1; i < mt_slots[type]; i++) {\n\t\tvoid *entry = mas_slot(mas, slots, i);\n\n\t\tif (entry && (i != mt_slots[type] - 1)) {\n\t\t\tpr_err(\"%p[%u] should not have entry %p\\n\", mas_mn(mas),\n\t\t\t       i, entry);\n\t\t\tMT_BUG_ON(mas->tree, entry != NULL);\n\t\t}\n\n\t\tif (i < mt_pivots[type]) {\n\t\t\tunsigned long piv = pivots[i];\n\n\t\t\tif (!piv)\n\t\t\t\tcontinue;\n\n\t\t\tpr_err(\"%p[%u] should not have piv %lu\\n\",\n\t\t\t       mas_mn(mas), i, piv);\n\t\t\tMAS_WARN_ON(mas, i < mt_pivots[type] - 1);\n\t\t}\n\t}\n}\n\nstatic void mt_validate_nulls(struct maple_tree *mt)\n{\n\tvoid *entry, *last = (void *)1;\n\tunsigned char offset = 0;\n\tvoid __rcu **slots;\n\tMA_STATE(mas, mt, 0, 0);\n\n\tmas_start(&mas);\n\tif (mas_is_none(&mas) || (mas.node == MAS_ROOT))\n\t\treturn;\n\n\twhile (!mte_is_leaf(mas.node))\n\t\tmas_descend(&mas);\n\n\tslots = ma_slots(mte_to_node(mas.node), mte_node_type(mas.node));\n\tdo {\n\t\tentry = mas_slot(&mas, slots, offset);\n\t\tif (!last && !entry) {\n\t\t\tpr_err(\"Sequential nulls end at %p[%u]\\n\",\n\t\t\t\tmas_mn(&mas), offset);\n\t\t}\n\t\tMT_BUG_ON(mt, !last && !entry);\n\t\tlast = entry;\n\t\tif (offset == mas_data_end(&mas)) {\n\t\t\tmas_next_node(&mas, mas_mn(&mas), ULONG_MAX);\n\t\t\tif (mas_is_none(&mas))\n\t\t\t\treturn;\n\t\t\toffset = 0;\n\t\t\tslots = ma_slots(mte_to_node(mas.node),\n\t\t\t\t\t mte_node_type(mas.node));\n\t\t} else {\n\t\t\toffset++;\n\t\t}\n\n\t} while (!mas_is_none(&mas));\n}\n\n \nvoid mt_validate(struct maple_tree *mt)\n{\n\tunsigned char end;\n\n\tMA_STATE(mas, mt, 0, 0);\n\trcu_read_lock();\n\tmas_start(&mas);\n\tif (!mas_searchable(&mas))\n\t\tgoto done;\n\n\twhile (!mte_is_leaf(mas.node))\n\t\tmas_descend(&mas);\n\n\twhile (!mas_is_none(&mas)) {\n\t\tMAS_WARN_ON(&mas, mte_dead_node(mas.node));\n\t\tend = mas_data_end(&mas);\n\t\tif (MAS_WARN_ON(&mas, (end < mt_min_slot_count(mas.node)) &&\n\t\t\t\t(mas.max != ULONG_MAX))) {\n\t\t\tpr_err(\"Invalid size %u of %p\\n\", end, mas_mn(&mas));\n\t\t}\n\n\t\tmas_validate_parent_slot(&mas);\n\t\tmas_validate_limits(&mas);\n\t\tmas_validate_child_slot(&mas);\n\t\tif (mt_is_alloc(mt))\n\t\t\tmas_validate_gaps(&mas);\n\t\tmas_dfs_postorder(&mas, ULONG_MAX);\n\t}\n\tmt_validate_nulls(mt);\ndone:\n\trcu_read_unlock();\n\n}\nEXPORT_SYMBOL_GPL(mt_validate);\n\nvoid mas_dump(const struct ma_state *mas)\n{\n\tpr_err(\"MAS: tree=%p enode=%p \", mas->tree, mas->node);\n\tif (mas_is_none(mas))\n\t\tpr_err(\"(MAS_NONE) \");\n\telse if (mas_is_ptr(mas))\n\t\tpr_err(\"(MAS_ROOT) \");\n\telse if (mas_is_start(mas))\n\t\t pr_err(\"(MAS_START) \");\n\telse if (mas_is_paused(mas))\n\t\tpr_err(\"(MAS_PAUSED) \");\n\n\tpr_err(\"[%u] index=%lx last=%lx\\n\", mas->offset, mas->index, mas->last);\n\tpr_err(\"     min=%lx max=%lx alloc=%p, depth=%u, flags=%x\\n\",\n\t       mas->min, mas->max, mas->alloc, mas->depth, mas->mas_flags);\n\tif (mas->index > mas->last)\n\t\tpr_err(\"Check index & last\\n\");\n}\nEXPORT_SYMBOL_GPL(mas_dump);\n\nvoid mas_wr_dump(const struct ma_wr_state *wr_mas)\n{\n\tpr_err(\"WR_MAS: node=%p r_min=%lx r_max=%lx\\n\",\n\t       wr_mas->node, wr_mas->r_min, wr_mas->r_max);\n\tpr_err(\"        type=%u off_end=%u, node_end=%u, end_piv=%lx\\n\",\n\t       wr_mas->type, wr_mas->offset_end, wr_mas->node_end,\n\t       wr_mas->end_piv);\n}\nEXPORT_SYMBOL_GPL(mas_wr_dump);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}