{
  "module_name": "gettimeofday.c",
  "hash_id": "c6036b8692c52369b84f3b13f93a4d3afe2982a5806fca3ae7d8c8f7645d551e",
  "original_prompt": "Ingested from linux-6.6.14/lib/vdso/gettimeofday.c",
  "human_readable_source": "\n \n#include <vdso/datapage.h>\n#include <vdso/helpers.h>\n\n#ifndef vdso_calc_delta\n \nstatic __always_inline\nu64 vdso_calc_delta(u64 cycles, u64 last, u64 mask, u32 mult)\n{\n\treturn ((cycles - last) & mask) * mult;\n}\n#endif\n\n#ifndef vdso_shift_ns\nstatic __always_inline u64 vdso_shift_ns(u64 ns, u32 shift)\n{\n\treturn ns >> shift;\n}\n#endif\n\n#ifndef __arch_vdso_hres_capable\nstatic inline bool __arch_vdso_hres_capable(void)\n{\n\treturn true;\n}\n#endif\n\n#ifndef vdso_clocksource_ok\nstatic inline bool vdso_clocksource_ok(const struct vdso_data *vd)\n{\n\treturn vd->clock_mode != VDSO_CLOCKMODE_NONE;\n}\n#endif\n\n#ifndef vdso_cycles_ok\nstatic inline bool vdso_cycles_ok(u64 cycles)\n{\n\treturn true;\n}\n#endif\n\n#ifdef CONFIG_TIME_NS\nstatic __always_inline int do_hres_timens(const struct vdso_data *vdns, clockid_t clk,\n\t\t\t\t\t  struct __kernel_timespec *ts)\n{\n\tconst struct vdso_data *vd;\n\tconst struct timens_offset *offs = &vdns->offset[clk];\n\tconst struct vdso_timestamp *vdso_ts;\n\tu64 cycles, last, ns;\n\tu32 seq;\n\ts64 sec;\n\n\tvd = vdns - (clk == CLOCK_MONOTONIC_RAW ? CS_RAW : CS_HRES_COARSE);\n\tvd = __arch_get_timens_vdso_data(vd);\n\tif (clk != CLOCK_MONOTONIC_RAW)\n\t\tvd = &vd[CS_HRES_COARSE];\n\telse\n\t\tvd = &vd[CS_RAW];\n\tvdso_ts = &vd->basetime[clk];\n\n\tdo {\n\t\tseq = vdso_read_begin(vd);\n\n\t\tif (unlikely(!vdso_clocksource_ok(vd)))\n\t\t\treturn -1;\n\n\t\tcycles = __arch_get_hw_counter(vd->clock_mode, vd);\n\t\tif (unlikely(!vdso_cycles_ok(cycles)))\n\t\t\treturn -1;\n\t\tns = vdso_ts->nsec;\n\t\tlast = vd->cycle_last;\n\t\tns += vdso_calc_delta(cycles, last, vd->mask, vd->mult);\n\t\tns = vdso_shift_ns(ns, vd->shift);\n\t\tsec = vdso_ts->sec;\n\t} while (unlikely(vdso_read_retry(vd, seq)));\n\n\t \n\tsec += offs->sec;\n\tns += offs->nsec;\n\n\t \n\tts->tv_sec = sec + __iter_div_u64_rem(ns, NSEC_PER_SEC, &ns);\n\tts->tv_nsec = ns;\n\n\treturn 0;\n}\n#else\nstatic __always_inline\nconst struct vdso_data *__arch_get_timens_vdso_data(const struct vdso_data *vd)\n{\n\treturn NULL;\n}\n\nstatic __always_inline int do_hres_timens(const struct vdso_data *vdns, clockid_t clk,\n\t\t\t\t\t  struct __kernel_timespec *ts)\n{\n\treturn -EINVAL;\n}\n#endif\n\nstatic __always_inline int do_hres(const struct vdso_data *vd, clockid_t clk,\n\t\t\t\t   struct __kernel_timespec *ts)\n{\n\tconst struct vdso_timestamp *vdso_ts = &vd->basetime[clk];\n\tu64 cycles, last, sec, ns;\n\tu32 seq;\n\n\t \n\tif (!__arch_vdso_hres_capable())\n\t\treturn -1;\n\n\tdo {\n\t\t \n\t\twhile (unlikely((seq = READ_ONCE(vd->seq)) & 1)) {\n\t\t\tif (IS_ENABLED(CONFIG_TIME_NS) &&\n\t\t\t    vd->clock_mode == VDSO_CLOCKMODE_TIMENS)\n\t\t\t\treturn do_hres_timens(vd, clk, ts);\n\t\t\tcpu_relax();\n\t\t}\n\t\tsmp_rmb();\n\n\t\tif (unlikely(!vdso_clocksource_ok(vd)))\n\t\t\treturn -1;\n\n\t\tcycles = __arch_get_hw_counter(vd->clock_mode, vd);\n\t\tif (unlikely(!vdso_cycles_ok(cycles)))\n\t\t\treturn -1;\n\t\tns = vdso_ts->nsec;\n\t\tlast = vd->cycle_last;\n\t\tns += vdso_calc_delta(cycles, last, vd->mask, vd->mult);\n\t\tns = vdso_shift_ns(ns, vd->shift);\n\t\tsec = vdso_ts->sec;\n\t} while (unlikely(vdso_read_retry(vd, seq)));\n\n\t \n\tts->tv_sec = sec + __iter_div_u64_rem(ns, NSEC_PER_SEC, &ns);\n\tts->tv_nsec = ns;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_TIME_NS\nstatic __always_inline int do_coarse_timens(const struct vdso_data *vdns, clockid_t clk,\n\t\t\t\t\t    struct __kernel_timespec *ts)\n{\n\tconst struct vdso_data *vd = __arch_get_timens_vdso_data(vdns);\n\tconst struct vdso_timestamp *vdso_ts = &vd->basetime[clk];\n\tconst struct timens_offset *offs = &vdns->offset[clk];\n\tu64 nsec;\n\ts64 sec;\n\ts32 seq;\n\n\tdo {\n\t\tseq = vdso_read_begin(vd);\n\t\tsec = vdso_ts->sec;\n\t\tnsec = vdso_ts->nsec;\n\t} while (unlikely(vdso_read_retry(vd, seq)));\n\n\t \n\tsec += offs->sec;\n\tnsec += offs->nsec;\n\n\t \n\tts->tv_sec = sec + __iter_div_u64_rem(nsec, NSEC_PER_SEC, &nsec);\n\tts->tv_nsec = nsec;\n\treturn 0;\n}\n#else\nstatic __always_inline int do_coarse_timens(const struct vdso_data *vdns, clockid_t clk,\n\t\t\t\t\t    struct __kernel_timespec *ts)\n{\n\treturn -1;\n}\n#endif\n\nstatic __always_inline int do_coarse(const struct vdso_data *vd, clockid_t clk,\n\t\t\t\t     struct __kernel_timespec *ts)\n{\n\tconst struct vdso_timestamp *vdso_ts = &vd->basetime[clk];\n\tu32 seq;\n\n\tdo {\n\t\t \n\t\twhile ((seq = READ_ONCE(vd->seq)) & 1) {\n\t\t\tif (IS_ENABLED(CONFIG_TIME_NS) &&\n\t\t\t    vd->clock_mode == VDSO_CLOCKMODE_TIMENS)\n\t\t\t\treturn do_coarse_timens(vd, clk, ts);\n\t\t\tcpu_relax();\n\t\t}\n\t\tsmp_rmb();\n\n\t\tts->tv_sec = vdso_ts->sec;\n\t\tts->tv_nsec = vdso_ts->nsec;\n\t} while (unlikely(vdso_read_retry(vd, seq)));\n\n\treturn 0;\n}\n\nstatic __always_inline int\n__cvdso_clock_gettime_common(const struct vdso_data *vd, clockid_t clock,\n\t\t\t     struct __kernel_timespec *ts)\n{\n\tu32 msk;\n\n\t \n\tif (unlikely((u32) clock >= MAX_CLOCKS))\n\t\treturn -1;\n\n\t \n\tmsk = 1U << clock;\n\tif (likely(msk & VDSO_HRES))\n\t\tvd = &vd[CS_HRES_COARSE];\n\telse if (msk & VDSO_COARSE)\n\t\treturn do_coarse(&vd[CS_HRES_COARSE], clock, ts);\n\telse if (msk & VDSO_RAW)\n\t\tvd = &vd[CS_RAW];\n\telse\n\t\treturn -1;\n\n\treturn do_hres(vd, clock, ts);\n}\n\nstatic __maybe_unused int\n__cvdso_clock_gettime_data(const struct vdso_data *vd, clockid_t clock,\n\t\t\t   struct __kernel_timespec *ts)\n{\n\tint ret = __cvdso_clock_gettime_common(vd, clock, ts);\n\n\tif (unlikely(ret))\n\t\treturn clock_gettime_fallback(clock, ts);\n\treturn 0;\n}\n\nstatic __maybe_unused int\n__cvdso_clock_gettime(clockid_t clock, struct __kernel_timespec *ts)\n{\n\treturn __cvdso_clock_gettime_data(__arch_get_vdso_data(), clock, ts);\n}\n\n#ifdef BUILD_VDSO32\nstatic __maybe_unused int\n__cvdso_clock_gettime32_data(const struct vdso_data *vd, clockid_t clock,\n\t\t\t     struct old_timespec32 *res)\n{\n\tstruct __kernel_timespec ts;\n\tint ret;\n\n\tret = __cvdso_clock_gettime_common(vd, clock, &ts);\n\n\tif (unlikely(ret))\n\t\treturn clock_gettime32_fallback(clock, res);\n\n\t \n\tres->tv_sec = ts.tv_sec;\n\tres->tv_nsec = ts.tv_nsec;\n\n\treturn ret;\n}\n\nstatic __maybe_unused int\n__cvdso_clock_gettime32(clockid_t clock, struct old_timespec32 *res)\n{\n\treturn __cvdso_clock_gettime32_data(__arch_get_vdso_data(), clock, res);\n}\n#endif  \n\nstatic __maybe_unused int\n__cvdso_gettimeofday_data(const struct vdso_data *vd,\n\t\t\t  struct __kernel_old_timeval *tv, struct timezone *tz)\n{\n\n\tif (likely(tv != NULL)) {\n\t\tstruct __kernel_timespec ts;\n\n\t\tif (do_hres(&vd[CS_HRES_COARSE], CLOCK_REALTIME, &ts))\n\t\t\treturn gettimeofday_fallback(tv, tz);\n\n\t\ttv->tv_sec = ts.tv_sec;\n\t\ttv->tv_usec = (u32)ts.tv_nsec / NSEC_PER_USEC;\n\t}\n\n\tif (unlikely(tz != NULL)) {\n\t\tif (IS_ENABLED(CONFIG_TIME_NS) &&\n\t\t    vd->clock_mode == VDSO_CLOCKMODE_TIMENS)\n\t\t\tvd = __arch_get_timens_vdso_data(vd);\n\n\t\ttz->tz_minuteswest = vd[CS_HRES_COARSE].tz_minuteswest;\n\t\ttz->tz_dsttime = vd[CS_HRES_COARSE].tz_dsttime;\n\t}\n\n\treturn 0;\n}\n\nstatic __maybe_unused int\n__cvdso_gettimeofday(struct __kernel_old_timeval *tv, struct timezone *tz)\n{\n\treturn __cvdso_gettimeofday_data(__arch_get_vdso_data(), tv, tz);\n}\n\n#ifdef VDSO_HAS_TIME\nstatic __maybe_unused __kernel_old_time_t\n__cvdso_time_data(const struct vdso_data *vd, __kernel_old_time_t *time)\n{\n\t__kernel_old_time_t t;\n\n\tif (IS_ENABLED(CONFIG_TIME_NS) &&\n\t    vd->clock_mode == VDSO_CLOCKMODE_TIMENS)\n\t\tvd = __arch_get_timens_vdso_data(vd);\n\n\tt = READ_ONCE(vd[CS_HRES_COARSE].basetime[CLOCK_REALTIME].sec);\n\n\tif (time)\n\t\t*time = t;\n\n\treturn t;\n}\n\nstatic __maybe_unused __kernel_old_time_t __cvdso_time(__kernel_old_time_t *time)\n{\n\treturn __cvdso_time_data(__arch_get_vdso_data(), time);\n}\n#endif  \n\n#ifdef VDSO_HAS_CLOCK_GETRES\nstatic __maybe_unused\nint __cvdso_clock_getres_common(const struct vdso_data *vd, clockid_t clock,\n\t\t\t\tstruct __kernel_timespec *res)\n{\n\tu32 msk;\n\tu64 ns;\n\n\t \n\tif (unlikely((u32) clock >= MAX_CLOCKS))\n\t\treturn -1;\n\n\tif (IS_ENABLED(CONFIG_TIME_NS) &&\n\t    vd->clock_mode == VDSO_CLOCKMODE_TIMENS)\n\t\tvd = __arch_get_timens_vdso_data(vd);\n\n\t \n\tmsk = 1U << clock;\n\tif (msk & (VDSO_HRES | VDSO_RAW)) {\n\t\t \n\t\tns = READ_ONCE(vd[CS_HRES_COARSE].hrtimer_res);\n\t} else if (msk & VDSO_COARSE) {\n\t\t \n\t\tns = LOW_RES_NSEC;\n\t} else {\n\t\treturn -1;\n\t}\n\n\tif (likely(res)) {\n\t\tres->tv_sec = 0;\n\t\tres->tv_nsec = ns;\n\t}\n\treturn 0;\n}\n\nstatic __maybe_unused\nint __cvdso_clock_getres_data(const struct vdso_data *vd, clockid_t clock,\n\t\t\t      struct __kernel_timespec *res)\n{\n\tint ret = __cvdso_clock_getres_common(vd, clock, res);\n\n\tif (unlikely(ret))\n\t\treturn clock_getres_fallback(clock, res);\n\treturn 0;\n}\n\nstatic __maybe_unused\nint __cvdso_clock_getres(clockid_t clock, struct __kernel_timespec *res)\n{\n\treturn __cvdso_clock_getres_data(__arch_get_vdso_data(), clock, res);\n}\n\n#ifdef BUILD_VDSO32\nstatic __maybe_unused int\n__cvdso_clock_getres_time32_data(const struct vdso_data *vd, clockid_t clock,\n\t\t\t\t struct old_timespec32 *res)\n{\n\tstruct __kernel_timespec ts;\n\tint ret;\n\n\tret = __cvdso_clock_getres_common(vd, clock, &ts);\n\n\tif (unlikely(ret))\n\t\treturn clock_getres32_fallback(clock, res);\n\n\tif (likely(res)) {\n\t\tres->tv_sec = ts.tv_sec;\n\t\tres->tv_nsec = ts.tv_nsec;\n\t}\n\treturn ret;\n}\n\nstatic __maybe_unused int\n__cvdso_clock_getres_time32(clockid_t clock, struct old_timespec32 *res)\n{\n\treturn __cvdso_clock_getres_time32_data(__arch_get_vdso_data(),\n\t\t\t\t\t\tclock, res);\n}\n#endif  \n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}