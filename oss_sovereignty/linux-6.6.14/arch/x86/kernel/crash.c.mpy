{
  "module_name": "crash.c",
  "hash_id": "9250454163f9d1130a23b8e8ccd4bf8fbacb52520635cc105dd1573d0bc7c99a",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/crash.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\t\"kexec: \" fmt\n\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/smp.h>\n#include <linux/reboot.h>\n#include <linux/kexec.h>\n#include <linux/delay.h>\n#include <linux/elf.h>\n#include <linux/elfcore.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/memblock.h>\n\n#include <asm/processor.h>\n#include <asm/hardirq.h>\n#include <asm/nmi.h>\n#include <asm/hw_irq.h>\n#include <asm/apic.h>\n#include <asm/e820/types.h>\n#include <asm/io_apic.h>\n#include <asm/hpet.h>\n#include <linux/kdebug.h>\n#include <asm/cpu.h>\n#include <asm/reboot.h>\n#include <asm/intel_pt.h>\n#include <asm/crash.h>\n#include <asm/cmdline.h>\n\n \nstruct crash_memmap_data {\n\tstruct boot_params *params;\n\t \n\tunsigned int type;\n};\n\n#if defined(CONFIG_SMP) && defined(CONFIG_X86_LOCAL_APIC)\n\nstatic void kdump_nmi_callback(int cpu, struct pt_regs *regs)\n{\n\tcrash_save_cpu(regs, cpu);\n\n\t \n\tcpu_emergency_stop_pt();\n\n\tdisable_local_APIC();\n}\n\nvoid kdump_nmi_shootdown_cpus(void)\n{\n\tnmi_shootdown_cpus(kdump_nmi_callback);\n\n\tdisable_local_APIC();\n}\n\n \nvoid crash_smp_send_stop(void)\n{\n\tstatic int cpus_stopped;\n\n\tif (cpus_stopped)\n\t\treturn;\n\n\tif (smp_ops.crash_stop_other_cpus)\n\t\tsmp_ops.crash_stop_other_cpus();\n\telse\n\t\tsmp_send_stop();\n\n\tcpus_stopped = 1;\n}\n\n#else\nvoid crash_smp_send_stop(void)\n{\n\t \n}\n#endif\n\nvoid native_machine_crash_shutdown(struct pt_regs *regs)\n{\n\t \n\t \n\tlocal_irq_disable();\n\n\tcrash_smp_send_stop();\n\n\tcpu_emergency_disable_virtualization();\n\n\t \n\tcpu_emergency_stop_pt();\n\n#ifdef CONFIG_X86_IO_APIC\n\t \n\tioapic_zap_locks();\n\tclear_IO_APIC();\n#endif\n\tlapic_shutdown();\n\trestore_boot_irq_mode();\n#ifdef CONFIG_HPET_TIMER\n\thpet_disable();\n#endif\n\tcrash_save_cpu(regs, safe_smp_processor_id());\n}\n\n#if defined(CONFIG_KEXEC_FILE) || defined(CONFIG_CRASH_HOTPLUG)\nstatic int get_nr_ram_ranges_callback(struct resource *res, void *arg)\n{\n\tunsigned int *nr_ranges = arg;\n\n\t(*nr_ranges)++;\n\treturn 0;\n}\n\n \nstatic struct crash_mem *fill_up_crash_elf_data(void)\n{\n\tunsigned int nr_ranges = 0;\n\tstruct crash_mem *cmem;\n\n\twalk_system_ram_res(0, -1, &nr_ranges, get_nr_ram_ranges_callback);\n\tif (!nr_ranges)\n\t\treturn NULL;\n\n\t \n\tnr_ranges += 2;\n\tcmem = vzalloc(struct_size(cmem, ranges, nr_ranges));\n\tif (!cmem)\n\t\treturn NULL;\n\n\tcmem->max_nr_ranges = nr_ranges;\n\tcmem->nr_ranges = 0;\n\n\treturn cmem;\n}\n\n \nstatic int elf_header_exclude_ranges(struct crash_mem *cmem)\n{\n\tint ret = 0;\n\n\t \n\tret = crash_exclude_mem_range(cmem, 0, (1<<20)-1);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = crash_exclude_mem_range(cmem, crashk_res.start, crashk_res.end);\n\tif (ret)\n\t\treturn ret;\n\n\tif (crashk_low_res.end)\n\t\tret = crash_exclude_mem_range(cmem, crashk_low_res.start,\n\t\t\t\t\t      crashk_low_res.end);\n\n\treturn ret;\n}\n\nstatic int prepare_elf64_ram_headers_callback(struct resource *res, void *arg)\n{\n\tstruct crash_mem *cmem = arg;\n\n\tcmem->ranges[cmem->nr_ranges].start = res->start;\n\tcmem->ranges[cmem->nr_ranges].end = res->end;\n\tcmem->nr_ranges++;\n\n\treturn 0;\n}\n\n \nstatic int prepare_elf_headers(struct kimage *image, void **addr,\n\t\t\t\t\tunsigned long *sz, unsigned long *nr_mem_ranges)\n{\n\tstruct crash_mem *cmem;\n\tint ret;\n\n\tcmem = fill_up_crash_elf_data();\n\tif (!cmem)\n\t\treturn -ENOMEM;\n\n\tret = walk_system_ram_res(0, -1, cmem, prepare_elf64_ram_headers_callback);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tret = elf_header_exclude_ranges(cmem);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\t*nr_mem_ranges = cmem->nr_ranges;\n\n\t \n\tret =  crash_prepare_elf64_headers(cmem, IS_ENABLED(CONFIG_X86_64), addr, sz);\n\nout:\n\tvfree(cmem);\n\treturn ret;\n}\n#endif\n\n#ifdef CONFIG_KEXEC_FILE\nstatic int add_e820_entry(struct boot_params *params, struct e820_entry *entry)\n{\n\tunsigned int nr_e820_entries;\n\n\tnr_e820_entries = params->e820_entries;\n\tif (nr_e820_entries >= E820_MAX_ENTRIES_ZEROPAGE)\n\t\treturn 1;\n\n\tmemcpy(&params->e820_table[nr_e820_entries], entry, sizeof(struct e820_entry));\n\tparams->e820_entries++;\n\treturn 0;\n}\n\nstatic int memmap_entry_callback(struct resource *res, void *arg)\n{\n\tstruct crash_memmap_data *cmd = arg;\n\tstruct boot_params *params = cmd->params;\n\tstruct e820_entry ei;\n\n\tei.addr = res->start;\n\tei.size = resource_size(res);\n\tei.type = cmd->type;\n\tadd_e820_entry(params, &ei);\n\n\treturn 0;\n}\n\nstatic int memmap_exclude_ranges(struct kimage *image, struct crash_mem *cmem,\n\t\t\t\t unsigned long long mstart,\n\t\t\t\t unsigned long long mend)\n{\n\tunsigned long start, end;\n\n\tcmem->ranges[0].start = mstart;\n\tcmem->ranges[0].end = mend;\n\tcmem->nr_ranges = 1;\n\n\t \n\tstart = image->elf_load_addr;\n\tend = start + image->elf_headers_sz - 1;\n\treturn crash_exclude_mem_range(cmem, start, end);\n}\n\n \nint crash_setup_memmap_entries(struct kimage *image, struct boot_params *params)\n{\n\tint i, ret = 0;\n\tunsigned long flags;\n\tstruct e820_entry ei;\n\tstruct crash_memmap_data cmd;\n\tstruct crash_mem *cmem;\n\n\tcmem = vzalloc(struct_size(cmem, ranges, 1));\n\tif (!cmem)\n\t\treturn -ENOMEM;\n\n\tmemset(&cmd, 0, sizeof(struct crash_memmap_data));\n\tcmd.params = params;\n\n\t \n\tcmd.type = E820_TYPE_RAM;\n\tflags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;\n\twalk_iomem_res_desc(IORES_DESC_NONE, flags, 0, (1<<20)-1, &cmd,\n\t\t\t    memmap_entry_callback);\n\n\t \n\tcmd.type = E820_TYPE_ACPI;\n\tflags = IORESOURCE_MEM | IORESOURCE_BUSY;\n\twalk_iomem_res_desc(IORES_DESC_ACPI_TABLES, flags, 0, -1, &cmd,\n\t\t\t    memmap_entry_callback);\n\n\t \n\tcmd.type = E820_TYPE_NVS;\n\twalk_iomem_res_desc(IORES_DESC_ACPI_NV_STORAGE, flags, 0, -1, &cmd,\n\t\t\t    memmap_entry_callback);\n\n\t \n\tcmd.type = E820_TYPE_RESERVED;\n\tflags = IORESOURCE_MEM;\n\twalk_iomem_res_desc(IORES_DESC_RESERVED, flags, 0, -1, &cmd,\n\t\t\t    memmap_entry_callback);\n\n\t \n\tif (crashk_low_res.end) {\n\t\tei.addr = crashk_low_res.start;\n\t\tei.size = resource_size(&crashk_low_res);\n\t\tei.type = E820_TYPE_RAM;\n\t\tadd_e820_entry(params, &ei);\n\t}\n\n\t \n\tret = memmap_exclude_ranges(image, cmem, crashk_res.start, crashk_res.end);\n\tif (ret)\n\t\tgoto out;\n\n\tfor (i = 0; i < cmem->nr_ranges; i++) {\n\t\tei.size = cmem->ranges[i].end - cmem->ranges[i].start + 1;\n\n\t\t \n\t\tif (ei.size < PAGE_SIZE)\n\t\t\tcontinue;\n\t\tei.addr = cmem->ranges[i].start;\n\t\tei.type = E820_TYPE_RAM;\n\t\tadd_e820_entry(params, &ei);\n\t}\n\nout:\n\tvfree(cmem);\n\treturn ret;\n}\n\nint crash_load_segments(struct kimage *image)\n{\n\tint ret;\n\tunsigned long pnum = 0;\n\tstruct kexec_buf kbuf = { .image = image, .buf_min = 0,\n\t\t\t\t  .buf_max = ULONG_MAX, .top_down = false };\n\n\t \n\tret = prepare_elf_headers(image, &kbuf.buffer, &kbuf.bufsz, &pnum);\n\tif (ret)\n\t\treturn ret;\n\n\timage->elf_headers\t= kbuf.buffer;\n\timage->elf_headers_sz\t= kbuf.bufsz;\n\tkbuf.memsz\t\t= kbuf.bufsz;\n\n#ifdef CONFIG_CRASH_HOTPLUG\n\t \n\tif (IS_ENABLED(CONFIG_MEMORY_HOTPLUG))\n\t\tpnum = 2 + CONFIG_NR_CPUS_DEFAULT + CONFIG_CRASH_MAX_MEMORY_RANGES;\n\telse\n\t\tpnum += 2 + CONFIG_NR_CPUS_DEFAULT;\n\n\tif (pnum < (unsigned long)PN_XNUM) {\n\t\tkbuf.memsz = pnum * sizeof(Elf64_Phdr);\n\t\tkbuf.memsz += sizeof(Elf64_Ehdr);\n\n\t\timage->elfcorehdr_index = image->nr_segments;\n\n\t\t \n\t\timage->elf_headers_sz = kbuf.memsz;\n\t} else {\n\t\tpr_err(\"number of Phdrs %lu exceeds max\\n\", pnum);\n\t}\n#endif\n\n\tkbuf.buf_align = ELF_CORE_HEADER_ALIGN;\n\tkbuf.mem = KEXEC_BUF_MEM_UNKNOWN;\n\tret = kexec_add_buffer(&kbuf);\n\tif (ret)\n\t\treturn ret;\n\timage->elf_load_addr = kbuf.mem;\n\tpr_debug(\"Loaded ELF headers at 0x%lx bufsz=0x%lx memsz=0x%lx\\n\",\n\t\t image->elf_load_addr, kbuf.bufsz, kbuf.memsz);\n\n\treturn ret;\n}\n#endif  \n\n#ifdef CONFIG_CRASH_HOTPLUG\n\n#undef pr_fmt\n#define pr_fmt(fmt) \"crash hp: \" fmt\n\n \n#ifdef CONFIG_HOTPLUG_CPU\nint arch_crash_hotplug_cpu_support(void)\n{\n\treturn crash_check_update_elfcorehdr();\n}\n#endif\n\n#ifdef CONFIG_MEMORY_HOTPLUG\nint arch_crash_hotplug_memory_support(void)\n{\n\treturn crash_check_update_elfcorehdr();\n}\n#endif\n\nunsigned int arch_crash_get_elfcorehdr_size(void)\n{\n\tunsigned int sz;\n\n\t \n\tsz = 2 + CONFIG_NR_CPUS_DEFAULT;\n\tif (IS_ENABLED(CONFIG_MEMORY_HOTPLUG))\n\t\tsz += CONFIG_CRASH_MAX_MEMORY_RANGES;\n\tsz *= sizeof(Elf64_Phdr);\n\treturn sz;\n}\n\n \nvoid arch_crash_handle_hotplug_event(struct kimage *image)\n{\n\tvoid *elfbuf = NULL, *old_elfcorehdr;\n\tunsigned long nr_mem_ranges;\n\tunsigned long mem, memsz;\n\tunsigned long elfsz = 0;\n\n\t \n\tif ((image->file_mode || image->elfcorehdr_updated) &&\n\t\t((image->hp_action == KEXEC_CRASH_HP_ADD_CPU) ||\n\t\t(image->hp_action == KEXEC_CRASH_HP_REMOVE_CPU)))\n\t\treturn;\n\n\t \n\tif (prepare_elf_headers(image, &elfbuf, &elfsz, &nr_mem_ranges)) {\n\t\tpr_err(\"unable to create new elfcorehdr\");\n\t\tgoto out;\n\t}\n\n\t \n\tmem = image->segment[image->elfcorehdr_index].mem;\n\tmemsz = image->segment[image->elfcorehdr_index].memsz;\n\tif (elfsz > memsz) {\n\t\tpr_err(\"update elfcorehdr elfsz %lu > memsz %lu\",\n\t\t\telfsz, memsz);\n\t\tgoto out;\n\t}\n\n\t \n\told_elfcorehdr = kmap_local_page(pfn_to_page(mem >> PAGE_SHIFT));\n\tif (!old_elfcorehdr) {\n\t\tpr_err(\"mapping elfcorehdr segment failed\\n\");\n\t\tgoto out;\n\t}\n\n\t \n\txchg(&kexec_crash_image, NULL);\n\tmemcpy_flushcache(old_elfcorehdr, elfbuf, elfsz);\n\txchg(&kexec_crash_image, image);\n\tkunmap_local(old_elfcorehdr);\n\tpr_debug(\"updated elfcorehdr\\n\");\n\nout:\n\tvfree(elfbuf);\n}\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}