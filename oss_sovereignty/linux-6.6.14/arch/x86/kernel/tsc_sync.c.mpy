{
  "module_name": "tsc_sync.c",
  "hash_id": "108f0bf8f23308b98afb5450f4688f96980d5c84c4d5abf5f2e1847656db82ca",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/tsc_sync.c",
  "human_readable_source": "\n \n#include <linux/workqueue.h>\n#include <linux/topology.h>\n#include <linux/spinlock.h>\n#include <linux/kernel.h>\n#include <linux/smp.h>\n#include <linux/nmi.h>\n#include <asm/tsc.h>\n\nstruct tsc_adjust {\n\ts64\t\tbootval;\n\ts64\t\tadjusted;\n\tunsigned long\tnextcheck;\n\tbool\t\twarned;\n};\n\nstatic DEFINE_PER_CPU(struct tsc_adjust, tsc_adjust);\nstatic struct timer_list tsc_sync_check_timer;\n\n \nbool __read_mostly tsc_async_resets;\n\nvoid mark_tsc_async_resets(char *reason)\n{\n\tif (tsc_async_resets)\n\t\treturn;\n\ttsc_async_resets = true;\n\tpr_info(\"tsc: Marking TSC async resets true due to %s\\n\", reason);\n}\n\nvoid tsc_verify_tsc_adjust(bool resume)\n{\n\tstruct tsc_adjust *adj = this_cpu_ptr(&tsc_adjust);\n\ts64 curval;\n\n\tif (!boot_cpu_has(X86_FEATURE_TSC_ADJUST))\n\t\treturn;\n\n\t \n\tif (check_tsc_unstable())\n\t\treturn;\n\n\t \n\tif (!resume && time_before(jiffies, adj->nextcheck))\n\t\treturn;\n\n\tadj->nextcheck = jiffies + HZ;\n\n\trdmsrl(MSR_IA32_TSC_ADJUST, curval);\n\tif (adj->adjusted == curval)\n\t\treturn;\n\n\t \n\twrmsrl(MSR_IA32_TSC_ADJUST, adj->adjusted);\n\n\tif (!adj->warned || resume) {\n\t\tpr_warn(FW_BUG \"TSC ADJUST differs: CPU%u %lld --> %lld. Restoring\\n\",\n\t\t\tsmp_processor_id(), adj->adjusted, curval);\n\t\tadj->warned = true;\n\t}\n}\n\n \n\n#define SYNC_CHECK_INTERVAL\t\t(HZ * 600)\n\nstatic void tsc_sync_check_timer_fn(struct timer_list *unused)\n{\n\tint next_cpu;\n\n\ttsc_verify_tsc_adjust(false);\n\n\t \n\tnext_cpu = cpumask_next(raw_smp_processor_id(), cpu_online_mask);\n\tif (next_cpu >= nr_cpu_ids)\n\t\tnext_cpu = cpumask_first(cpu_online_mask);\n\n\ttsc_sync_check_timer.expires += SYNC_CHECK_INTERVAL;\n\tadd_timer_on(&tsc_sync_check_timer, next_cpu);\n}\n\nstatic int __init start_sync_check_timer(void)\n{\n\tif (!cpu_feature_enabled(X86_FEATURE_TSC_ADJUST) || tsc_clocksource_reliable)\n\t\treturn 0;\n\n\ttimer_setup(&tsc_sync_check_timer, tsc_sync_check_timer_fn, 0);\n\ttsc_sync_check_timer.expires = jiffies + SYNC_CHECK_INTERVAL;\n\tadd_timer(&tsc_sync_check_timer);\n\n\treturn 0;\n}\nlate_initcall(start_sync_check_timer);\n\nstatic void tsc_sanitize_first_cpu(struct tsc_adjust *cur, s64 bootval,\n\t\t\t\t   unsigned int cpu, bool bootcpu)\n{\n\t \n\tif (bootcpu && bootval != 0) {\n\t\tif (likely(!tsc_async_resets)) {\n\t\t\tpr_warn(FW_BUG \"TSC ADJUST: CPU%u: %lld force to 0\\n\",\n\t\t\t\tcpu, bootval);\n\t\t\twrmsrl(MSR_IA32_TSC_ADJUST, 0);\n\t\t\tbootval = 0;\n\t\t} else {\n\t\t\tpr_info(\"TSC ADJUST: CPU%u: %lld NOT forced to 0\\n\",\n\t\t\t\tcpu, bootval);\n\t\t}\n\t}\n\tcur->adjusted = bootval;\n}\n\n#ifndef CONFIG_SMP\nbool __init tsc_store_and_check_tsc_adjust(bool bootcpu)\n{\n\tstruct tsc_adjust *cur = this_cpu_ptr(&tsc_adjust);\n\ts64 bootval;\n\n\tif (!boot_cpu_has(X86_FEATURE_TSC_ADJUST))\n\t\treturn false;\n\n\t \n\tif (check_tsc_unstable())\n\t\treturn false;\n\n\trdmsrl(MSR_IA32_TSC_ADJUST, bootval);\n\tcur->bootval = bootval;\n\tcur->nextcheck = jiffies + HZ;\n\ttsc_sanitize_first_cpu(cur, bootval, smp_processor_id(), bootcpu);\n\treturn false;\n}\n\n#else  \n\n \nbool tsc_store_and_check_tsc_adjust(bool bootcpu)\n{\n\tstruct tsc_adjust *ref, *cur = this_cpu_ptr(&tsc_adjust);\n\tunsigned int refcpu, cpu = smp_processor_id();\n\tstruct cpumask *mask;\n\ts64 bootval;\n\n\tif (!boot_cpu_has(X86_FEATURE_TSC_ADJUST))\n\t\treturn false;\n\n\trdmsrl(MSR_IA32_TSC_ADJUST, bootval);\n\tcur->bootval = bootval;\n\tcur->nextcheck = jiffies + HZ;\n\tcur->warned = false;\n\n\t \n\tif (tsc_async_resets)\n\t\tcur->adjusted = bootval;\n\n\t \n\tmask = topology_core_cpumask(cpu);\n\trefcpu = mask ? cpumask_any_but(mask, cpu) : nr_cpu_ids;\n\n\tif (refcpu >= nr_cpu_ids) {\n\t\ttsc_sanitize_first_cpu(cur, bootval, smp_processor_id(),\n\t\t\t\t       bootcpu);\n\t\treturn false;\n\t}\n\n\tref = per_cpu_ptr(&tsc_adjust, refcpu);\n\t \n\tif (bootval != ref->bootval)\n\t\tprintk_once(FW_BUG \"TSC ADJUST differs within socket(s), fixing all errors\\n\");\n\n\t \n\tif (bootval != ref->adjusted) {\n\t\tcur->adjusted = ref->adjusted;\n\t\twrmsrl(MSR_IA32_TSC_ADJUST, ref->adjusted);\n\t}\n\t \n\treturn true;\n}\n\n \nstatic atomic_t start_count;\nstatic atomic_t stop_count;\nstatic atomic_t test_runs;\n\n \nstatic arch_spinlock_t sync_lock = __ARCH_SPIN_LOCK_UNLOCKED;\n\nstatic cycles_t last_tsc;\nstatic cycles_t max_warp;\nstatic int nr_warps;\nstatic int random_warps;\n\n \nstatic cycles_t check_tsc_warp(unsigned int timeout)\n{\n\tcycles_t start, now, prev, end, cur_max_warp = 0;\n\tint i, cur_warps = 0;\n\n\tstart = rdtsc_ordered();\n\t \n\tend = start + (cycles_t) tsc_khz * timeout;\n\n\tfor (i = 0; ; i++) {\n\t\t \n\t\tarch_spin_lock(&sync_lock);\n\t\tprev = last_tsc;\n\t\tnow = rdtsc_ordered();\n\t\tlast_tsc = now;\n\t\tarch_spin_unlock(&sync_lock);\n\n\t\t \n\t\tif (unlikely(!(i & 7))) {\n\t\t\tif (now > end || i > 10000000)\n\t\t\t\tbreak;\n\t\t\tcpu_relax();\n\t\t\ttouch_nmi_watchdog();\n\t\t}\n\t\t \n\t\tif (unlikely(prev > now)) {\n\t\t\tarch_spin_lock(&sync_lock);\n\t\t\tmax_warp = max(max_warp, prev - now);\n\t\t\tcur_max_warp = max_warp;\n\t\t\t \n\t\t\tif (cur_warps != nr_warps)\n\t\t\t\trandom_warps++;\n\t\t\tnr_warps++;\n\t\t\tcur_warps = nr_warps;\n\t\t\tarch_spin_unlock(&sync_lock);\n\t\t}\n\t}\n\tWARN(!(now-start),\n\t\t\"Warning: zero tsc calibration delta: %Ld [max: %Ld]\\n\",\n\t\t\tnow-start, end-start);\n\treturn cur_max_warp;\n}\n\n \nstatic inline unsigned int loop_timeout(int cpu)\n{\n\treturn (cpumask_weight(topology_core_cpumask(cpu)) > 1) ? 2 : 20;\n}\n\nstatic void tsc_sync_mark_tsc_unstable(struct work_struct *work)\n{\n\tmark_tsc_unstable(\"check_tsc_sync_source failed\");\n}\n\nstatic DECLARE_WORK(tsc_sync_work, tsc_sync_mark_tsc_unstable);\n\n \nstatic void check_tsc_sync_source(void *__cpu)\n{\n\tunsigned int cpu = (unsigned long)__cpu;\n\tint cpus = 2;\n\n\t \n\tif (!boot_cpu_has(X86_FEATURE_TSC_ADJUST))\n\t\tatomic_set(&test_runs, 1);\n\telse\n\t\tatomic_set(&test_runs, 3);\nretry:\n\t \n\twhile (atomic_read(&start_count) != cpus - 1)\n\t\tcpu_relax();\n\n\t \n\tatomic_inc(&start_count);\n\n\tcheck_tsc_warp(loop_timeout(cpu));\n\n\twhile (atomic_read(&stop_count) != cpus-1)\n\t\tcpu_relax();\n\n\t \n\tif (!nr_warps) {\n\t\tatomic_set(&test_runs, 0);\n\n\t\tpr_debug(\"TSC synchronization [CPU#%d -> CPU#%u]: passed\\n\",\n\t\t\tsmp_processor_id(), cpu);\n\n\t} else if (atomic_dec_and_test(&test_runs) || random_warps) {\n\t\t \n\t\tatomic_set(&test_runs, 0);\n\n\t\tpr_warn(\"TSC synchronization [CPU#%d -> CPU#%u]:\\n\",\n\t\t\tsmp_processor_id(), cpu);\n\t\tpr_warn(\"Measured %Ld cycles TSC warp between CPUs, \"\n\t\t\t\"turning off TSC clock.\\n\", max_warp);\n\t\tif (random_warps)\n\t\t\tpr_warn(\"TSC warped randomly between CPUs\\n\");\n\t\tschedule_work(&tsc_sync_work);\n\t}\n\n\t \n\tatomic_set(&start_count, 0);\n\trandom_warps = 0;\n\tnr_warps = 0;\n\tmax_warp = 0;\n\tlast_tsc = 0;\n\n\t \n\tatomic_inc(&stop_count);\n\n\t \n\tif (atomic_read(&test_runs) > 0)\n\t\tgoto retry;\n}\n\n \nvoid check_tsc_sync_target(void)\n{\n\tstruct tsc_adjust *cur = this_cpu_ptr(&tsc_adjust);\n\tunsigned int cpu = smp_processor_id();\n\tcycles_t cur_max_warp, gbl_max_warp;\n\tint cpus = 2;\n\n\t \n\tif (unsynchronized_tsc())\n\t\treturn;\n\n\t \n\tif (tsc_store_and_check_tsc_adjust(false) || tsc_clocksource_reliable)\n\t\treturn;\n\n\t \n\tsmp_call_function_single(cpumask_first(cpu_online_mask), check_tsc_sync_source,\n\t\t\t\t (unsigned long *)(unsigned long)cpu, 0);\nretry:\n\t \n\tatomic_inc(&start_count);\n\twhile (atomic_read(&start_count) != cpus)\n\t\tcpu_relax();\n\n\tcur_max_warp = check_tsc_warp(loop_timeout(cpu));\n\n\t \n\tgbl_max_warp = max_warp;\n\n\t \n\tatomic_inc(&stop_count);\n\n\t \n\twhile (atomic_read(&stop_count) != cpus)\n\t\tcpu_relax();\n\n\t \n\tatomic_set(&stop_count, 0);\n\n\t \n\tif (!atomic_read(&test_runs))\n\t\treturn;\n\n\t \n\tif (!cur_max_warp)\n\t\tcur_max_warp = -gbl_max_warp;\n\n\t \n\tcur->adjusted += cur_max_warp;\n\n\tpr_warn(\"TSC ADJUST compensate: CPU%u observed %lld warp. Adjust: %lld\\n\",\n\t\tcpu, cur_max_warp, cur->adjusted);\n\n\twrmsrl(MSR_IA32_TSC_ADJUST, cur->adjusted);\n\tgoto retry;\n\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}