{
  "module_name": "core.c",
  "hash_id": "056107ba582617b3a99b9d9b01d6870dbe7e5ef4cf3a1c1453e3d92ca08d7d49",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/kprobes/core.c",
  "human_readable_source": "\n \n#include <linux/kprobes.h>\n#include <linux/ptrace.h>\n#include <linux/string.h>\n#include <linux/slab.h>\n#include <linux/hardirq.h>\n#include <linux/preempt.h>\n#include <linux/sched/debug.h>\n#include <linux/perf_event.h>\n#include <linux/extable.h>\n#include <linux/kdebug.h>\n#include <linux/kallsyms.h>\n#include <linux/kgdb.h>\n#include <linux/ftrace.h>\n#include <linux/kasan.h>\n#include <linux/moduleloader.h>\n#include <linux/objtool.h>\n#include <linux/vmalloc.h>\n#include <linux/pgtable.h>\n#include <linux/set_memory.h>\n#include <linux/cfi.h>\n\n#include <asm/text-patching.h>\n#include <asm/cacheflush.h>\n#include <asm/desc.h>\n#include <linux/uaccess.h>\n#include <asm/alternative.h>\n#include <asm/insn.h>\n#include <asm/debugreg.h>\n#include <asm/ibt.h>\n\n#include \"common.h\"\n\nDEFINE_PER_CPU(struct kprobe *, current_kprobe) = NULL;\nDEFINE_PER_CPU(struct kprobe_ctlblk, kprobe_ctlblk);\n\n#define W(row, b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, ba, bb, bc, bd, be, bf)\\\n\t(((b0##UL << 0x0)|(b1##UL << 0x1)|(b2##UL << 0x2)|(b3##UL << 0x3) |   \\\n\t  (b4##UL << 0x4)|(b5##UL << 0x5)|(b6##UL << 0x6)|(b7##UL << 0x7) |   \\\n\t  (b8##UL << 0x8)|(b9##UL << 0x9)|(ba##UL << 0xa)|(bb##UL << 0xb) |   \\\n\t  (bc##UL << 0xc)|(bd##UL << 0xd)|(be##UL << 0xe)|(bf##UL << 0xf))    \\\n\t << (row % 32))\n\t \nstatic volatile u32 twobyte_is_boostable[256 / 32] = {\n\t \n\t \n\tW(0x00, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0) |  \n\tW(0x10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1) ,  \n\tW(0x20, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) |  \n\tW(0x30, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) ,  \n\tW(0x40, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1) |  \n\tW(0x50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) ,  \n\tW(0x60, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1) |  \n\tW(0x70, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1) ,  \n\tW(0x80, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) |  \n\tW(0x90, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1) ,  \n\tW(0xa0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1) |  \n\tW(0xb0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1) ,  \n\tW(0xc0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1) |  \n\tW(0xd0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1) ,  \n\tW(0xe0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1) |  \n\tW(0xf0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0)    \n\t \n\t \n};\n#undef W\n\nstruct kretprobe_blackpoint kretprobe_blacklist[] = {\n\t{\"__switch_to\", },  \n\t{NULL, NULL}\t \n};\n\nconst int kretprobe_blacklist_size = ARRAY_SIZE(kretprobe_blacklist);\n\nstatic nokprobe_inline void\n__synthesize_relative_insn(void *dest, void *from, void *to, u8 op)\n{\n\tstruct __arch_relative_insn {\n\t\tu8 op;\n\t\ts32 raddr;\n\t} __packed *insn;\n\n\tinsn = (struct __arch_relative_insn *)dest;\n\tinsn->raddr = (s32)((long)(to) - ((long)(from) + 5));\n\tinsn->op = op;\n}\n\n \nvoid synthesize_reljump(void *dest, void *from, void *to)\n{\n\t__synthesize_relative_insn(dest, from, to, JMP32_INSN_OPCODE);\n}\nNOKPROBE_SYMBOL(synthesize_reljump);\n\n \nvoid synthesize_relcall(void *dest, void *from, void *to)\n{\n\t__synthesize_relative_insn(dest, from, to, CALL_INSN_OPCODE);\n}\nNOKPROBE_SYMBOL(synthesize_relcall);\n\n \nint can_boost(struct insn *insn, void *addr)\n{\n\tkprobe_opcode_t opcode;\n\tinsn_byte_t prefix;\n\tint i;\n\n\tif (search_exception_tables((unsigned long)addr))\n\t\treturn 0;\t \n\n\t \n\tif (insn->opcode.nbytes == 2)\n\t\treturn test_bit(insn->opcode.bytes[1],\n\t\t\t\t(unsigned long *)twobyte_is_boostable);\n\n\tif (insn->opcode.nbytes != 1)\n\t\treturn 0;\n\n\tfor_each_insn_prefix(insn, i, prefix) {\n\t\tinsn_attr_t attr;\n\n\t\tattr = inat_get_opcode_attribute(prefix);\n\t\t \n\t\tif (prefix == 0x2e || inat_is_address_size_prefix(attr))\n\t\t\treturn 0;\n\t}\n\n\topcode = insn->opcode.bytes[0];\n\n\tswitch (opcode) {\n\tcase 0x62:\t\t \n\tcase 0x70 ... 0x7f:\t \n\tcase 0x9a:\t\t \n\tcase 0xc0 ... 0xc1:\t \n\tcase 0xcc ... 0xce:\t \n\tcase 0xd0 ... 0xd3:\t \n\tcase 0xd6:\t\t \n\tcase 0xd8 ... 0xdf:\t \n\tcase 0xe0 ... 0xe3:\t \n\tcase 0xe8 ... 0xe9:\t \n\tcase 0xeb:\t\t \n\tcase 0xf0 ... 0xf4:\t \n\tcase 0xf6 ... 0xf7:\t \n\tcase 0xfe:\t\t \n\t\t \n\t\treturn 0;\n\tcase 0xff:\t\t \n\t\t \n\t\treturn X86_MODRM_REG(insn->modrm.bytes[0]) == 4;\n\tdefault:\n\t\treturn 1;\n\t}\n}\n\nstatic unsigned long\n__recover_probed_insn(kprobe_opcode_t *buf, unsigned long addr)\n{\n\tstruct kprobe *kp;\n\tbool faddr;\n\n\tkp = get_kprobe((void *)addr);\n\tfaddr = ftrace_location(addr) == addr;\n\t \n\tif (!kp && !faddr)\n\t\treturn addr;\n\n\t \n\tif (copy_from_kernel_nofault(buf, (void *)addr,\n\t\tMAX_INSN_SIZE * sizeof(kprobe_opcode_t)))\n\t\treturn 0UL;\n\n\tif (faddr)\n\t\tmemcpy(buf, x86_nops[5], 5);\n\telse\n\t\tbuf[0] = kp->opcode;\n\treturn (unsigned long)buf;\n}\n\n \nunsigned long recover_probed_instruction(kprobe_opcode_t *buf, unsigned long addr)\n{\n\tunsigned long __addr;\n\n\t__addr = __recover_optprobed_insn(buf, addr);\n\tif (__addr != addr)\n\t\treturn __addr;\n\n\treturn __recover_probed_insn(buf, addr);\n}\n\n \nstatic int can_probe(unsigned long paddr)\n{\n\tunsigned long addr, __addr, offset = 0;\n\tstruct insn insn;\n\tkprobe_opcode_t buf[MAX_INSN_SIZE];\n\n\tif (!kallsyms_lookup_size_offset(paddr, NULL, &offset))\n\t\treturn 0;\n\n\t \n\taddr = paddr - offset;\n\twhile (addr < paddr) {\n\t\tint ret;\n\n\t\t \n\t\t__addr = recover_probed_instruction(buf, addr);\n\t\tif (!__addr)\n\t\t\treturn 0;\n\n\t\tret = insn_decode_kernel(&insn, (void *)__addr);\n\t\tif (ret < 0)\n\t\t\treturn 0;\n\n#ifdef CONFIG_KGDB\n\t\t \n\t\tif (insn.opcode.bytes[0] == INT3_INSN_OPCODE &&\n\t\t    kgdb_has_hit_break(addr))\n\t\t\treturn 0;\n#endif\n\t\taddr += insn.length;\n\t}\n\tif (IS_ENABLED(CONFIG_CFI_CLANG)) {\n\t\t \n\t\t__addr = recover_probed_instruction(buf, addr);\n\t\tif (!__addr)\n\t\t\treturn 0;\n\n\t\tif (insn_decode_kernel(&insn, (void *)__addr) < 0)\n\t\t\treturn 0;\n\n\t\tif (insn.opcode.value == 0xBA)\n\t\t\toffset = 12;\n\t\telse if (insn.opcode.value == 0x3)\n\t\t\toffset = 6;\n\t\telse\n\t\t\tgoto out;\n\n\t\t \n\t\tif (is_cfi_trap(addr + offset))\n\t\t\treturn 0;\n\t}\n\nout:\n\treturn (addr == paddr);\n}\n\n \nkprobe_opcode_t *arch_adjust_kprobe_addr(unsigned long addr, unsigned long offset,\n\t\t\t\t\t bool *on_func_entry)\n{\n\tif (is_endbr(*(u32 *)addr)) {\n\t\t*on_func_entry = !offset || offset == 4;\n\t\tif (*on_func_entry)\n\t\t\toffset = 4;\n\n\t} else {\n\t\t*on_func_entry = !offset;\n\t}\n\n\treturn (kprobe_opcode_t *)(addr + offset);\n}\n\n \nint __copy_instruction(u8 *dest, u8 *src, u8 *real, struct insn *insn)\n{\n\tkprobe_opcode_t buf[MAX_INSN_SIZE];\n\tunsigned long recovered_insn = recover_probed_instruction(buf, (unsigned long)src);\n\tint ret;\n\n\tif (!recovered_insn || !insn)\n\t\treturn 0;\n\n\t \n\tif (copy_from_kernel_nofault(dest, (void *)recovered_insn,\n\t\t\tMAX_INSN_SIZE))\n\t\treturn 0;\n\n\tret = insn_decode_kernel(insn, dest);\n\tif (ret < 0)\n\t\treturn 0;\n\n\t \n\tif (insn_has_emulate_prefix(insn))\n\t\treturn 0;\n\n\t \n\tif (insn->opcode.bytes[0] == INT3_INSN_OPCODE)\n\t\treturn 0;\n\n\t \n\tif (insn_masking_exception(insn))\n\t\treturn 0;\n\n#ifdef CONFIG_X86_64\n\t \n\tif (insn_rip_relative(insn)) {\n\t\ts64 newdisp;\n\t\tu8 *disp;\n\t\t \n\t\tnewdisp = (u8 *) src + (s64) insn->displacement.value\n\t\t\t  - (u8 *) real;\n\t\tif ((s64) (s32) newdisp != newdisp) {\n\t\t\tpr_err(\"Kprobes error: new displacement does not fit into s32 (%llx)\\n\", newdisp);\n\t\t\treturn 0;\n\t\t}\n\t\tdisp = (u8 *) dest + insn_offset_displacement(insn);\n\t\t*(s32 *) disp = (s32) newdisp;\n\t}\n#endif\n\treturn insn->length;\n}\n\n \nstatic int prepare_singlestep(kprobe_opcode_t *buf, struct kprobe *p,\n\t\t\t      struct insn *insn)\n{\n\tint len = insn->length;\n\n\tif (!IS_ENABLED(CONFIG_PREEMPTION) &&\n\t    !p->post_handler && can_boost(insn, p->addr) &&\n\t    MAX_INSN_SIZE - len >= JMP32_INSN_SIZE) {\n\t\t \n\t\tsynthesize_reljump(buf + len, p->ainsn.insn + len,\n\t\t\t\t   p->addr + insn->length);\n\t\tlen += JMP32_INSN_SIZE;\n\t\tp->ainsn.boostable = 1;\n\t} else {\n\t\t \n\t\tif (MAX_INSN_SIZE - len < INT3_INSN_SIZE)\n\t\t\treturn -ENOSPC;\n\n\t\tbuf[len] = INT3_INSN_OPCODE;\n\t\tlen += INT3_INSN_SIZE;\n\t}\n\n\treturn len;\n}\n\n \nvoid *alloc_insn_page(void)\n{\n\tvoid *page;\n\n\tpage = module_alloc(PAGE_SIZE);\n\tif (!page)\n\t\treturn NULL;\n\n\t \n\tset_memory_rox((unsigned long)page, 1);\n\n\treturn page;\n}\n\n \n\nstatic void kprobe_emulate_ifmodifiers(struct kprobe *p, struct pt_regs *regs)\n{\n\tswitch (p->ainsn.opcode) {\n\tcase 0xfa:\t \n\t\tregs->flags &= ~(X86_EFLAGS_IF);\n\t\tbreak;\n\tcase 0xfb:\t \n\t\tregs->flags |= X86_EFLAGS_IF;\n\t\tbreak;\n\tcase 0x9c:\t \n\t\tint3_emulate_push(regs, regs->flags);\n\t\tbreak;\n\tcase 0x9d:\t \n\t\tregs->flags = int3_emulate_pop(regs);\n\t\tbreak;\n\t}\n\tregs->ip = regs->ip - INT3_INSN_SIZE + p->ainsn.size;\n}\nNOKPROBE_SYMBOL(kprobe_emulate_ifmodifiers);\n\nstatic void kprobe_emulate_ret(struct kprobe *p, struct pt_regs *regs)\n{\n\tint3_emulate_ret(regs);\n}\nNOKPROBE_SYMBOL(kprobe_emulate_ret);\n\nstatic void kprobe_emulate_call(struct kprobe *p, struct pt_regs *regs)\n{\n\tunsigned long func = regs->ip - INT3_INSN_SIZE + p->ainsn.size;\n\n\tfunc += p->ainsn.rel32;\n\tint3_emulate_call(regs, func);\n}\nNOKPROBE_SYMBOL(kprobe_emulate_call);\n\nstatic void kprobe_emulate_jmp(struct kprobe *p, struct pt_regs *regs)\n{\n\tunsigned long ip = regs->ip - INT3_INSN_SIZE + p->ainsn.size;\n\n\tip += p->ainsn.rel32;\n\tint3_emulate_jmp(regs, ip);\n}\nNOKPROBE_SYMBOL(kprobe_emulate_jmp);\n\nstatic void kprobe_emulate_jcc(struct kprobe *p, struct pt_regs *regs)\n{\n\tunsigned long ip = regs->ip - INT3_INSN_SIZE + p->ainsn.size;\n\n\tint3_emulate_jcc(regs, p->ainsn.jcc.type, ip, p->ainsn.rel32);\n}\nNOKPROBE_SYMBOL(kprobe_emulate_jcc);\n\nstatic void kprobe_emulate_loop(struct kprobe *p, struct pt_regs *regs)\n{\n\tunsigned long ip = regs->ip - INT3_INSN_SIZE + p->ainsn.size;\n\tbool match;\n\n\tif (p->ainsn.loop.type != 3) {\t \n\t\tif (p->ainsn.loop.asize == 32)\n\t\t\tmatch = ((*(u32 *)&regs->cx)--) != 0;\n#ifdef CONFIG_X86_64\n\t\telse if (p->ainsn.loop.asize == 64)\n\t\t\tmatch = ((*(u64 *)&regs->cx)--) != 0;\n#endif\n\t\telse\n\t\t\tmatch = ((*(u16 *)&regs->cx)--) != 0;\n\t} else {\t\t\t \n\t\tif (p->ainsn.loop.asize == 32)\n\t\t\tmatch = *(u32 *)(&regs->cx) == 0;\n#ifdef CONFIG_X86_64\n\t\telse if (p->ainsn.loop.asize == 64)\n\t\t\tmatch = *(u64 *)(&regs->cx) == 0;\n#endif\n\t\telse\n\t\t\tmatch = *(u16 *)(&regs->cx) == 0;\n\t}\n\n\tif (p->ainsn.loop.type == 0)\t \n\t\tmatch = match && !(regs->flags & X86_EFLAGS_ZF);\n\telse if (p->ainsn.loop.type == 1)\t \n\t\tmatch = match && (regs->flags & X86_EFLAGS_ZF);\n\n\tif (match)\n\t\tip += p->ainsn.rel32;\n\tint3_emulate_jmp(regs, ip);\n}\nNOKPROBE_SYMBOL(kprobe_emulate_loop);\n\nstatic const int addrmode_regoffs[] = {\n\toffsetof(struct pt_regs, ax),\n\toffsetof(struct pt_regs, cx),\n\toffsetof(struct pt_regs, dx),\n\toffsetof(struct pt_regs, bx),\n\toffsetof(struct pt_regs, sp),\n\toffsetof(struct pt_regs, bp),\n\toffsetof(struct pt_regs, si),\n\toffsetof(struct pt_regs, di),\n#ifdef CONFIG_X86_64\n\toffsetof(struct pt_regs, r8),\n\toffsetof(struct pt_regs, r9),\n\toffsetof(struct pt_regs, r10),\n\toffsetof(struct pt_regs, r11),\n\toffsetof(struct pt_regs, r12),\n\toffsetof(struct pt_regs, r13),\n\toffsetof(struct pt_regs, r14),\n\toffsetof(struct pt_regs, r15),\n#endif\n};\n\nstatic void kprobe_emulate_call_indirect(struct kprobe *p, struct pt_regs *regs)\n{\n\tunsigned long offs = addrmode_regoffs[p->ainsn.indirect.reg];\n\n\tint3_emulate_push(regs, regs->ip - INT3_INSN_SIZE + p->ainsn.size);\n\tint3_emulate_jmp(regs, regs_get_register(regs, offs));\n}\nNOKPROBE_SYMBOL(kprobe_emulate_call_indirect);\n\nstatic void kprobe_emulate_jmp_indirect(struct kprobe *p, struct pt_regs *regs)\n{\n\tunsigned long offs = addrmode_regoffs[p->ainsn.indirect.reg];\n\n\tint3_emulate_jmp(regs, regs_get_register(regs, offs));\n}\nNOKPROBE_SYMBOL(kprobe_emulate_jmp_indirect);\n\nstatic int prepare_emulation(struct kprobe *p, struct insn *insn)\n{\n\tinsn_byte_t opcode = insn->opcode.bytes[0];\n\n\tswitch (opcode) {\n\tcase 0xfa:\t\t \n\tcase 0xfb:\t\t \n\tcase 0x9c:\t\t \n\tcase 0x9d:\t\t \n\t\t \n\t\tp->ainsn.emulate_op = kprobe_emulate_ifmodifiers;\n\t\tp->ainsn.opcode = opcode;\n\t\tbreak;\n\tcase 0xc2:\t \n\tcase 0xc3:\n\tcase 0xca:\n\tcase 0xcb:\n\t\tp->ainsn.emulate_op = kprobe_emulate_ret;\n\t\tbreak;\n\tcase 0x9a:\t \n\tcase 0xea:\t \n\tcase 0xcc:\t \n\tcase 0xcf:\t \n\t\treturn -EOPNOTSUPP;\n\t\tbreak;\n\tcase 0xe8:\t \n\t\tp->ainsn.emulate_op = kprobe_emulate_call;\n\t\tif (insn->immediate.nbytes == 2)\n\t\t\tp->ainsn.rel32 = *(s16 *)&insn->immediate.value;\n\t\telse\n\t\t\tp->ainsn.rel32 = *(s32 *)&insn->immediate.value;\n\t\tbreak;\n\tcase 0xeb:\t \n\tcase 0xe9:\t \n\t\tp->ainsn.emulate_op = kprobe_emulate_jmp;\n\t\tif (insn->immediate.nbytes == 1)\n\t\t\tp->ainsn.rel32 = *(s8 *)&insn->immediate.value;\n\t\telse if (insn->immediate.nbytes == 2)\n\t\t\tp->ainsn.rel32 = *(s16 *)&insn->immediate.value;\n\t\telse\n\t\t\tp->ainsn.rel32 = *(s32 *)&insn->immediate.value;\n\t\tbreak;\n\tcase 0x70 ... 0x7f:\n\t\t \n\t\tp->ainsn.emulate_op = kprobe_emulate_jcc;\n\t\tp->ainsn.jcc.type = opcode & 0xf;\n\t\tp->ainsn.rel32 = insn->immediate.value;\n\t\tbreak;\n\tcase 0x0f:\n\t\topcode = insn->opcode.bytes[1];\n\t\tif ((opcode & 0xf0) == 0x80) {\n\t\t\t \n\t\t\tp->ainsn.emulate_op = kprobe_emulate_jcc;\n\t\t\tp->ainsn.jcc.type = opcode & 0xf;\n\t\t\tif (insn->immediate.nbytes == 2)\n\t\t\t\tp->ainsn.rel32 = *(s16 *)&insn->immediate.value;\n\t\t\telse\n\t\t\t\tp->ainsn.rel32 = *(s32 *)&insn->immediate.value;\n\t\t} else if (opcode == 0x01 &&\n\t\t\t   X86_MODRM_REG(insn->modrm.bytes[0]) == 0 &&\n\t\t\t   X86_MODRM_MOD(insn->modrm.bytes[0]) == 3) {\n\t\t\t \n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tbreak;\n\tcase 0xe0:\t \n\tcase 0xe1:\t \n\tcase 0xe2:\t \n\tcase 0xe3:\t \n\t\tp->ainsn.emulate_op = kprobe_emulate_loop;\n\t\tp->ainsn.loop.type = opcode & 0x3;\n\t\tp->ainsn.loop.asize = insn->addr_bytes * 8;\n\t\tp->ainsn.rel32 = *(s8 *)&insn->immediate.value;\n\t\tbreak;\n\tcase 0xff:\n\t\t \n\t\topcode = insn->modrm.bytes[0];\n\t\tswitch (X86_MODRM_REG(opcode)) {\n\t\tcase 0b010:\t \n\t\t\tp->ainsn.emulate_op = kprobe_emulate_call_indirect;\n\t\t\tbreak;\n\t\tcase 0b100:\t \n\t\t\tp->ainsn.emulate_op = kprobe_emulate_jmp_indirect;\n\t\t\tbreak;\n\t\tcase 0b011:\t \n\t\tcase 0b101:\t \n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (!p->ainsn.emulate_op)\n\t\t\tbreak;\n\n\t\tif (insn->addr_bytes != sizeof(unsigned long))\n\t\t\treturn -EOPNOTSUPP;\t \n\t\tif (X86_MODRM_MOD(opcode) != 3)\n\t\t\treturn -EOPNOTSUPP;\t \n\n\t\tp->ainsn.indirect.reg = X86_MODRM_RM(opcode);\n#ifdef CONFIG_X86_64\n\t\tif (X86_REX_B(insn->rex_prefix.value))\n\t\t\tp->ainsn.indirect.reg += 8;\n#endif\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\tp->ainsn.size = insn->length;\n\n\treturn 0;\n}\n\nstatic int arch_copy_kprobe(struct kprobe *p)\n{\n\tstruct insn insn;\n\tkprobe_opcode_t buf[MAX_INSN_SIZE];\n\tint ret, len;\n\n\t \n\tlen = __copy_instruction(buf, p->addr, p->ainsn.insn, &insn);\n\tif (!len)\n\t\treturn -EINVAL;\n\n\t \n\tret = prepare_emulation(p, &insn);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tlen = prepare_singlestep(buf, p, &insn);\n\tif (len < 0)\n\t\treturn len;\n\n\t \n\tp->opcode = buf[0];\n\n\tp->ainsn.tp_len = len;\n\tperf_event_text_poke(p->ainsn.insn, NULL, 0, buf, len);\n\n\t \n\ttext_poke(p->ainsn.insn, buf, len);\n\n\treturn 0;\n}\n\nint arch_prepare_kprobe(struct kprobe *p)\n{\n\tint ret;\n\n\tif (alternatives_text_reserved(p->addr, p->addr))\n\t\treturn -EINVAL;\n\n\tif (!can_probe((unsigned long)p->addr))\n\t\treturn -EILSEQ;\n\n\tmemset(&p->ainsn, 0, sizeof(p->ainsn));\n\n\t \n\tp->ainsn.insn = get_insn_slot();\n\tif (!p->ainsn.insn)\n\t\treturn -ENOMEM;\n\n\tret = arch_copy_kprobe(p);\n\tif (ret) {\n\t\tfree_insn_slot(p->ainsn.insn, 0);\n\t\tp->ainsn.insn = NULL;\n\t}\n\n\treturn ret;\n}\n\nvoid arch_arm_kprobe(struct kprobe *p)\n{\n\tu8 int3 = INT3_INSN_OPCODE;\n\n\ttext_poke(p->addr, &int3, 1);\n\ttext_poke_sync();\n\tperf_event_text_poke(p->addr, &p->opcode, 1, &int3, 1);\n}\n\nvoid arch_disarm_kprobe(struct kprobe *p)\n{\n\tu8 int3 = INT3_INSN_OPCODE;\n\n\tperf_event_text_poke(p->addr, &int3, 1, &p->opcode, 1);\n\ttext_poke(p->addr, &p->opcode, 1);\n\ttext_poke_sync();\n}\n\nvoid arch_remove_kprobe(struct kprobe *p)\n{\n\tif (p->ainsn.insn) {\n\t\t \n\t\tperf_event_text_poke(p->ainsn.insn, p->ainsn.insn,\n\t\t\t\t     p->ainsn.tp_len, NULL, 0);\n\t\tfree_insn_slot(p->ainsn.insn, p->ainsn.boostable);\n\t\tp->ainsn.insn = NULL;\n\t}\n}\n\nstatic nokprobe_inline void\nsave_previous_kprobe(struct kprobe_ctlblk *kcb)\n{\n\tkcb->prev_kprobe.kp = kprobe_running();\n\tkcb->prev_kprobe.status = kcb->kprobe_status;\n\tkcb->prev_kprobe.old_flags = kcb->kprobe_old_flags;\n\tkcb->prev_kprobe.saved_flags = kcb->kprobe_saved_flags;\n}\n\nstatic nokprobe_inline void\nrestore_previous_kprobe(struct kprobe_ctlblk *kcb)\n{\n\t__this_cpu_write(current_kprobe, kcb->prev_kprobe.kp);\n\tkcb->kprobe_status = kcb->prev_kprobe.status;\n\tkcb->kprobe_old_flags = kcb->prev_kprobe.old_flags;\n\tkcb->kprobe_saved_flags = kcb->prev_kprobe.saved_flags;\n}\n\nstatic nokprobe_inline void\nset_current_kprobe(struct kprobe *p, struct pt_regs *regs,\n\t\t   struct kprobe_ctlblk *kcb)\n{\n\t__this_cpu_write(current_kprobe, p);\n\tkcb->kprobe_saved_flags = kcb->kprobe_old_flags\n\t\t= (regs->flags & X86_EFLAGS_IF);\n}\n\nstatic void kprobe_post_process(struct kprobe *cur, struct pt_regs *regs,\n\t\t\t       struct kprobe_ctlblk *kcb)\n{\n\t \n\tif (kcb->kprobe_status == KPROBE_REENTER) {\n\t\t \n\t\trestore_previous_kprobe(kcb);\n\t} else {\n\t\t \n\t\tkcb->kprobe_status = KPROBE_HIT_SSDONE;\n\t\tif (cur->post_handler)\n\t\t\tcur->post_handler(cur, regs, 0);\n\t\treset_current_kprobe();\n\t}\n}\nNOKPROBE_SYMBOL(kprobe_post_process);\n\nstatic void setup_singlestep(struct kprobe *p, struct pt_regs *regs,\n\t\t\t     struct kprobe_ctlblk *kcb, int reenter)\n{\n\tif (setup_detour_execution(p, regs, reenter))\n\t\treturn;\n\n#if !defined(CONFIG_PREEMPTION)\n\tif (p->ainsn.boostable) {\n\t\t \n\t\tif (!reenter)\n\t\t\treset_current_kprobe();\n\t\t \n\t\tregs->ip = (unsigned long)p->ainsn.insn;\n\t\treturn;\n\t}\n#endif\n\tif (reenter) {\n\t\tsave_previous_kprobe(kcb);\n\t\tset_current_kprobe(p, regs, kcb);\n\t\tkcb->kprobe_status = KPROBE_REENTER;\n\t} else\n\t\tkcb->kprobe_status = KPROBE_HIT_SS;\n\n\tif (p->ainsn.emulate_op) {\n\t\tp->ainsn.emulate_op(p, regs);\n\t\tkprobe_post_process(p, regs, kcb);\n\t\treturn;\n\t}\n\n\t \n\tregs->flags &= ~X86_EFLAGS_IF;\n\tregs->ip = (unsigned long)p->ainsn.insn;\n}\nNOKPROBE_SYMBOL(setup_singlestep);\n\n \nstatic void resume_singlestep(struct kprobe *p, struct pt_regs *regs,\n\t\t\t      struct kprobe_ctlblk *kcb)\n{\n\tunsigned long copy_ip = (unsigned long)p->ainsn.insn;\n\tunsigned long orig_ip = (unsigned long)p->addr;\n\n\t \n\tregs->flags |= kcb->kprobe_saved_flags;\n\t \n\tregs->ip += (orig_ip - copy_ip) - INT3_INSN_SIZE;\n}\nNOKPROBE_SYMBOL(resume_singlestep);\n\n \nstatic int reenter_kprobe(struct kprobe *p, struct pt_regs *regs,\n\t\t\t  struct kprobe_ctlblk *kcb)\n{\n\tswitch (kcb->kprobe_status) {\n\tcase KPROBE_HIT_SSDONE:\n\tcase KPROBE_HIT_ACTIVE:\n\tcase KPROBE_HIT_SS:\n\t\tkprobes_inc_nmissed_count(p);\n\t\tsetup_singlestep(p, regs, kcb, 1);\n\t\tbreak;\n\tcase KPROBE_REENTER:\n\t\t \n\t\tpr_err(\"Unrecoverable kprobe detected.\\n\");\n\t\tdump_kprobe(p);\n\t\tBUG();\n\tdefault:\n\t\t \n\t\tWARN_ON(1);\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\nNOKPROBE_SYMBOL(reenter_kprobe);\n\nstatic nokprobe_inline int kprobe_is_ss(struct kprobe_ctlblk *kcb)\n{\n\treturn (kcb->kprobe_status == KPROBE_HIT_SS ||\n\t\tkcb->kprobe_status == KPROBE_REENTER);\n}\n\n \nint kprobe_int3_handler(struct pt_regs *regs)\n{\n\tkprobe_opcode_t *addr;\n\tstruct kprobe *p;\n\tstruct kprobe_ctlblk *kcb;\n\n\tif (user_mode(regs))\n\t\treturn 0;\n\n\taddr = (kprobe_opcode_t *)(regs->ip - sizeof(kprobe_opcode_t));\n\t \n\n\tkcb = get_kprobe_ctlblk();\n\tp = get_kprobe(addr);\n\n\tif (p) {\n\t\tif (kprobe_running()) {\n\t\t\tif (reenter_kprobe(p, regs, kcb))\n\t\t\t\treturn 1;\n\t\t} else {\n\t\t\tset_current_kprobe(p, regs, kcb);\n\t\t\tkcb->kprobe_status = KPROBE_HIT_ACTIVE;\n\n\t\t\t \n\t\t\tif (!p->pre_handler || !p->pre_handler(p, regs))\n\t\t\t\tsetup_singlestep(p, regs, kcb, 0);\n\t\t\telse\n\t\t\t\treset_current_kprobe();\n\t\t\treturn 1;\n\t\t}\n\t} else if (kprobe_is_ss(kcb)) {\n\t\tp = kprobe_running();\n\t\tif ((unsigned long)p->ainsn.insn < regs->ip &&\n\t\t    (unsigned long)p->ainsn.insn + MAX_INSN_SIZE > regs->ip) {\n\t\t\t \n\t\t\tresume_singlestep(p, regs, kcb);\n\t\t\tkprobe_post_process(p, regs, kcb);\n\t\t\treturn 1;\n\t\t}\n\t}  \n\n\treturn 0;\n}\nNOKPROBE_SYMBOL(kprobe_int3_handler);\n\nint kprobe_fault_handler(struct pt_regs *regs, int trapnr)\n{\n\tstruct kprobe *cur = kprobe_running();\n\tstruct kprobe_ctlblk *kcb = get_kprobe_ctlblk();\n\n\tif (unlikely(regs->ip == (unsigned long)cur->ainsn.insn)) {\n\t\t \n\t\tWARN_ON(kcb->kprobe_status != KPROBE_HIT_SS &&\n\t\t\tkcb->kprobe_status != KPROBE_REENTER);\n\t\t \n\t\tregs->ip = (unsigned long)cur->addr;\n\n\t\t \n\t\tregs->flags |= kcb->kprobe_old_flags;\n\n\t\tif (kcb->kprobe_status == KPROBE_REENTER)\n\t\t\trestore_previous_kprobe(kcb);\n\t\telse\n\t\t\treset_current_kprobe();\n\t}\n\n\treturn 0;\n}\nNOKPROBE_SYMBOL(kprobe_fault_handler);\n\nint __init arch_populate_kprobe_blacklist(void)\n{\n\treturn kprobe_add_area_blacklist((unsigned long)__entry_text_start,\n\t\t\t\t\t (unsigned long)__entry_text_end);\n}\n\nint __init arch_init_kprobes(void)\n{\n\treturn 0;\n}\n\nint arch_trampoline_kprobe(struct kprobe *p)\n{\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}