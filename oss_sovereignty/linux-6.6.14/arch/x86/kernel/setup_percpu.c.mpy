{
  "module_name": "setup_percpu.c",
  "hash_id": "158bc6fa39dc5bf9b7936e7f9c75f408126c4197d721f481d4fa48b71fca1270",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/setup_percpu.c",
  "human_readable_source": "\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kernel.h>\n#include <linux/export.h>\n#include <linux/init.h>\n#include <linux/memblock.h>\n#include <linux/percpu.h>\n#include <linux/kexec.h>\n#include <linux/crash_dump.h>\n#include <linux/smp.h>\n#include <linux/topology.h>\n#include <linux/pfn.h>\n#include <linux/stackprotector.h>\n#include <asm/sections.h>\n#include <asm/processor.h>\n#include <asm/desc.h>\n#include <asm/setup.h>\n#include <asm/mpspec.h>\n#include <asm/apicdef.h>\n#include <asm/highmem.h>\n#include <asm/proto.h>\n#include <asm/cpumask.h>\n#include <asm/cpu.h>\n\n#ifdef CONFIG_X86_64\n#define BOOT_PERCPU_OFFSET ((unsigned long)__per_cpu_load)\n#else\n#define BOOT_PERCPU_OFFSET 0\n#endif\n\nDEFINE_PER_CPU_READ_MOSTLY(unsigned long, this_cpu_off) = BOOT_PERCPU_OFFSET;\nEXPORT_PER_CPU_SYMBOL(this_cpu_off);\n\nunsigned long __per_cpu_offset[NR_CPUS] __ro_after_init = {\n\t[0 ... NR_CPUS-1] = BOOT_PERCPU_OFFSET,\n};\nEXPORT_SYMBOL(__per_cpu_offset);\n\n \n#ifdef CONFIG_X86_64\n#define PERCPU_FIRST_CHUNK_RESERVE\tPERCPU_MODULE_RESERVE\n#else\n#define PERCPU_FIRST_CHUNK_RESERVE\t0\n#endif\n\n#ifdef CONFIG_X86_32\n \nstatic bool __init pcpu_need_numa(void)\n{\n#ifdef CONFIG_NUMA\n\tpg_data_t *last = NULL;\n\tunsigned int cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tint node = early_cpu_to_node(cpu);\n\n\t\tif (node_online(node) && NODE_DATA(node) &&\n\t\t    last && last != NODE_DATA(node))\n\t\t\treturn true;\n\n\t\tlast = NODE_DATA(node);\n\t}\n#endif\n\treturn false;\n}\n#endif\n\nstatic int __init pcpu_cpu_distance(unsigned int from, unsigned int to)\n{\n#ifdef CONFIG_NUMA\n\tif (early_cpu_to_node(from) == early_cpu_to_node(to))\n\t\treturn LOCAL_DISTANCE;\n\telse\n\t\treturn REMOTE_DISTANCE;\n#else\n\treturn LOCAL_DISTANCE;\n#endif\n}\n\nstatic int __init pcpu_cpu_to_node(int cpu)\n{\n\treturn early_cpu_to_node(cpu);\n}\n\nvoid __init pcpu_populate_pte(unsigned long addr)\n{\n\tpopulate_extra_pte(addr);\n}\n\nstatic inline void setup_percpu_segment(int cpu)\n{\n#ifdef CONFIG_X86_32\n\tstruct desc_struct d = GDT_ENTRY_INIT(0x8092, per_cpu_offset(cpu),\n\t\t\t\t\t      0xFFFFF);\n\n\twrite_gdt_entry(get_cpu_gdt_rw(cpu), GDT_ENTRY_PERCPU, &d, DESCTYPE_S);\n#endif\n}\n\nvoid __init setup_per_cpu_areas(void)\n{\n\tunsigned int cpu;\n\tunsigned long delta;\n\tint rc;\n\n\tpr_info(\"NR_CPUS:%d nr_cpumask_bits:%d nr_cpu_ids:%u nr_node_ids:%u\\n\",\n\t\tNR_CPUS, nr_cpumask_bits, nr_cpu_ids, nr_node_ids);\n\n\t \n#ifdef CONFIG_X86_32\n\tif (pcpu_chosen_fc == PCPU_FC_AUTO && pcpu_need_numa())\n\t\tpcpu_chosen_fc = PCPU_FC_PAGE;\n#endif\n\trc = -EINVAL;\n\tif (pcpu_chosen_fc != PCPU_FC_PAGE) {\n\t\tconst size_t dyn_size = PERCPU_MODULE_RESERVE +\n\t\t\tPERCPU_DYNAMIC_RESERVE - PERCPU_FIRST_CHUNK_RESERVE;\n\t\tsize_t atom_size;\n\n\t\t \n#ifdef CONFIG_X86_64\n\t\tatom_size = PMD_SIZE;\n#else\n\t\tatom_size = PAGE_SIZE;\n#endif\n\t\trc = pcpu_embed_first_chunk(PERCPU_FIRST_CHUNK_RESERVE,\n\t\t\t\t\t    dyn_size, atom_size,\n\t\t\t\t\t    pcpu_cpu_distance,\n\t\t\t\t\t    pcpu_cpu_to_node);\n\t\tif (rc < 0)\n\t\t\tpr_warn(\"%s allocator failed (%d), falling back to page size\\n\",\n\t\t\t\tpcpu_fc_names[pcpu_chosen_fc], rc);\n\t}\n\tif (rc < 0)\n\t\trc = pcpu_page_first_chunk(PERCPU_FIRST_CHUNK_RESERVE,\n\t\t\t\t\t   pcpu_cpu_to_node);\n\tif (rc < 0)\n\t\tpanic(\"cannot initialize percpu area (err=%d)\", rc);\n\n\t \n\tdelta = (unsigned long)pcpu_base_addr - (unsigned long)__per_cpu_start;\n\tfor_each_possible_cpu(cpu) {\n\t\tper_cpu_offset(cpu) = delta + pcpu_unit_offsets[cpu];\n\t\tper_cpu(this_cpu_off, cpu) = per_cpu_offset(cpu);\n\t\tper_cpu(pcpu_hot.cpu_number, cpu) = cpu;\n\t\tsetup_percpu_segment(cpu);\n\t\t \n#ifdef CONFIG_X86_LOCAL_APIC\n\t\tper_cpu(x86_cpu_to_apicid, cpu) =\n\t\t\tearly_per_cpu_map(x86_cpu_to_apicid, cpu);\n\t\tper_cpu(x86_cpu_to_acpiid, cpu) =\n\t\t\tearly_per_cpu_map(x86_cpu_to_acpiid, cpu);\n#endif\n#ifdef CONFIG_NUMA\n\t\tper_cpu(x86_cpu_to_node_map, cpu) =\n\t\t\tearly_per_cpu_map(x86_cpu_to_node_map, cpu);\n\t\t \n\t\tset_cpu_numa_node(cpu, early_cpu_to_node(cpu));\n#endif\n\t\t \n\t\tif (!cpu)\n\t\t\tswitch_gdt_and_percpu_base(cpu);\n\t}\n\n\t \n#ifdef CONFIG_X86_LOCAL_APIC\n\tearly_per_cpu_ptr(x86_cpu_to_apicid) = NULL;\n\tearly_per_cpu_ptr(x86_cpu_to_acpiid) = NULL;\n#endif\n#ifdef CONFIG_NUMA\n\tearly_per_cpu_ptr(x86_cpu_to_node_map) = NULL;\n#endif\n\n\t \n\tsetup_node_to_cpumask_map();\n\n\t \n\tsetup_cpu_local_masks();\n\n\t \n\tsync_initial_page_table();\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}