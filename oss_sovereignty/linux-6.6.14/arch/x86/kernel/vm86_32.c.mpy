{
  "module_name": "vm86_32.c",
  "hash_id": "898c03c3b9afb74d6a85a36b9cec3a3ec35c56e27fce77f7e3e60bbca7b7820c",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/vm86_32.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/capability.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/syscalls.h>\n#include <linux/sched.h>\n#include <linux/sched/task_stack.h>\n#include <linux/kernel.h>\n#include <linux/signal.h>\n#include <linux/string.h>\n#include <linux/mm.h>\n#include <linux/smp.h>\n#include <linux/highmem.h>\n#include <linux/ptrace.h>\n#include <linux/audit.h>\n#include <linux/stddef.h>\n#include <linux/slab.h>\n#include <linux/security.h>\n\n#include <linux/uaccess.h>\n#include <asm/io.h>\n#include <asm/tlbflush.h>\n#include <asm/irq.h>\n#include <asm/traps.h>\n#include <asm/vm86.h>\n#include <asm/switch_to.h>\n\n \n\n\n \n#define AL(regs)\t(((unsigned char *)&((regs)->pt.ax))[0])\n#define AH(regs)\t(((unsigned char *)&((regs)->pt.ax))[1])\n#define IP(regs)\t(*(unsigned short *)&((regs)->pt.ip))\n#define SP(regs)\t(*(unsigned short *)&((regs)->pt.sp))\n\n \n#define VFLAGS\t(*(unsigned short *)&(current->thread.vm86->veflags))\n#define VEFLAGS\t(current->thread.vm86->veflags)\n\n#define set_flags(X, new, mask) \\\n((X) = ((X) & ~(mask)) | ((new) & (mask)))\n\n#define SAFE_MASK\t(0xDD5)\n#define RETURN_MASK\t(0xDFF)\n\nvoid save_v86_state(struct kernel_vm86_regs *regs, int retval)\n{\n\tstruct task_struct *tsk = current;\n\tstruct vm86plus_struct __user *user;\n\tstruct vm86 *vm86 = current->thread.vm86;\n\n\t \n\tlocal_irq_enable();\n\n\tBUG_ON(!vm86);\n\n\tset_flags(regs->pt.flags, VEFLAGS, X86_EFLAGS_VIF | vm86->veflags_mask);\n\tuser = vm86->user_vm86;\n\n\tif (!user_access_begin(user, vm86->vm86plus.is_vm86pus ?\n\t\t       sizeof(struct vm86plus_struct) :\n\t\t       sizeof(struct vm86_struct)))\n\t\tgoto Efault;\n\n\tunsafe_put_user(regs->pt.bx, &user->regs.ebx, Efault_end);\n\tunsafe_put_user(regs->pt.cx, &user->regs.ecx, Efault_end);\n\tunsafe_put_user(regs->pt.dx, &user->regs.edx, Efault_end);\n\tunsafe_put_user(regs->pt.si, &user->regs.esi, Efault_end);\n\tunsafe_put_user(regs->pt.di, &user->regs.edi, Efault_end);\n\tunsafe_put_user(regs->pt.bp, &user->regs.ebp, Efault_end);\n\tunsafe_put_user(regs->pt.ax, &user->regs.eax, Efault_end);\n\tunsafe_put_user(regs->pt.ip, &user->regs.eip, Efault_end);\n\tunsafe_put_user(regs->pt.cs, &user->regs.cs, Efault_end);\n\tunsafe_put_user(regs->pt.flags, &user->regs.eflags, Efault_end);\n\tunsafe_put_user(regs->pt.sp, &user->regs.esp, Efault_end);\n\tunsafe_put_user(regs->pt.ss, &user->regs.ss, Efault_end);\n\tunsafe_put_user(regs->es, &user->regs.es, Efault_end);\n\tunsafe_put_user(regs->ds, &user->regs.ds, Efault_end);\n\tunsafe_put_user(regs->fs, &user->regs.fs, Efault_end);\n\tunsafe_put_user(regs->gs, &user->regs.gs, Efault_end);\n\n\t \n\n\tuser_access_end();\n\nexit_vm86:\n\tpreempt_disable();\n\ttsk->thread.sp0 = vm86->saved_sp0;\n\ttsk->thread.sysenter_cs = __KERNEL_CS;\n\tupdate_task_stack(tsk);\n\trefresh_sysenter_cs(&tsk->thread);\n\tvm86->saved_sp0 = 0;\n\tpreempt_enable();\n\n\tmemcpy(&regs->pt, &vm86->regs32, sizeof(struct pt_regs));\n\n\tloadsegment(gs, vm86->regs32.gs);\n\n\tregs->pt.ax = retval;\n\treturn;\n\nEfault_end:\n\tuser_access_end();\nEfault:\n\tpr_alert(\"could not access userspace vm86 info\\n\");\n\tforce_exit_sig(SIGSEGV);\n\tgoto exit_vm86;\n}\n\nstatic int do_vm86_irq_handling(int subfunction, int irqnumber);\nstatic long do_sys_vm86(struct vm86plus_struct __user *user_vm86, bool plus);\n\nSYSCALL_DEFINE1(vm86old, struct vm86_struct __user *, user_vm86)\n{\n\treturn do_sys_vm86((struct vm86plus_struct __user *) user_vm86, false);\n}\n\n\nSYSCALL_DEFINE2(vm86, unsigned long, cmd, unsigned long, arg)\n{\n\tswitch (cmd) {\n\tcase VM86_REQUEST_IRQ:\n\tcase VM86_FREE_IRQ:\n\tcase VM86_GET_IRQ_BITS:\n\tcase VM86_GET_AND_RESET_IRQ:\n\t\treturn do_vm86_irq_handling(cmd, (int)arg);\n\tcase VM86_PLUS_INSTALL_CHECK:\n\t\t \n\t\treturn 0;\n\t}\n\n\t \n\treturn do_sys_vm86((struct vm86plus_struct __user *) arg, true);\n}\n\n\nstatic long do_sys_vm86(struct vm86plus_struct __user *user_vm86, bool plus)\n{\n\tstruct task_struct *tsk = current;\n\tstruct vm86 *vm86 = tsk->thread.vm86;\n\tstruct kernel_vm86_regs vm86regs;\n\tstruct pt_regs *regs = current_pt_regs();\n\tunsigned long err = 0;\n\tstruct vm86_struct v;\n\n\terr = security_mmap_addr(0);\n\tif (err) {\n\t\t \n\t\tpr_info_once(\"Denied a call to vm86(old) from %s[%d] (uid: %d).  Set the vm.mmap_min_addr sysctl to 0 and/or adjust LSM mmap_min_addr policy to enable vm86 if you are using a vm86-based DOS emulator.\\n\",\n\t\t\t     current->comm, task_pid_nr(current),\n\t\t\t     from_kuid_munged(&init_user_ns, current_uid()));\n\t\treturn -EPERM;\n\t}\n\n\tif (!vm86) {\n\t\tif (!(vm86 = kzalloc(sizeof(*vm86), GFP_KERNEL)))\n\t\t\treturn -ENOMEM;\n\t\ttsk->thread.vm86 = vm86;\n\t}\n\tif (vm86->saved_sp0)\n\t\treturn -EPERM;\n\n\tif (copy_from_user(&v, user_vm86,\n\t\t\toffsetof(struct vm86_struct, int_revectored)))\n\t\treturn -EFAULT;\n\n\n\t \n\tif (v.flags & VM86_SCREEN_BITMAP) {\n\t\tchar comm[TASK_COMM_LEN];\n\n\t\tpr_info_once(\"vm86: '%s' uses VM86_SCREEN_BITMAP, which is no longer supported\\n\", get_task_comm(comm, current));\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&vm86regs, 0, sizeof(vm86regs));\n\n\tvm86regs.pt.bx = v.regs.ebx;\n\tvm86regs.pt.cx = v.regs.ecx;\n\tvm86regs.pt.dx = v.regs.edx;\n\tvm86regs.pt.si = v.regs.esi;\n\tvm86regs.pt.di = v.regs.edi;\n\tvm86regs.pt.bp = v.regs.ebp;\n\tvm86regs.pt.ax = v.regs.eax;\n\tvm86regs.pt.ip = v.regs.eip;\n\tvm86regs.pt.cs = v.regs.cs;\n\tvm86regs.pt.flags = v.regs.eflags;\n\tvm86regs.pt.sp = v.regs.esp;\n\tvm86regs.pt.ss = v.regs.ss;\n\tvm86regs.es = v.regs.es;\n\tvm86regs.ds = v.regs.ds;\n\tvm86regs.fs = v.regs.fs;\n\tvm86regs.gs = v.regs.gs;\n\n\tvm86->flags = v.flags;\n\tvm86->cpu_type = v.cpu_type;\n\n\tif (copy_from_user(&vm86->int_revectored,\n\t\t\t   &user_vm86->int_revectored,\n\t\t\t   sizeof(struct revectored_struct)))\n\t\treturn -EFAULT;\n\tif (copy_from_user(&vm86->int21_revectored,\n\t\t\t   &user_vm86->int21_revectored,\n\t\t\t   sizeof(struct revectored_struct)))\n\t\treturn -EFAULT;\n\tif (plus) {\n\t\tif (copy_from_user(&vm86->vm86plus, &user_vm86->vm86plus,\n\t\t\t\t   sizeof(struct vm86plus_info_struct)))\n\t\t\treturn -EFAULT;\n\t\tvm86->vm86plus.is_vm86pus = 1;\n\t} else\n\t\tmemset(&vm86->vm86plus, 0,\n\t\t       sizeof(struct vm86plus_info_struct));\n\n\tmemcpy(&vm86->regs32, regs, sizeof(struct pt_regs));\n\tvm86->user_vm86 = user_vm86;\n\n \n\tVEFLAGS = vm86regs.pt.flags;\n\tvm86regs.pt.flags &= SAFE_MASK;\n\tvm86regs.pt.flags |= regs->flags & ~SAFE_MASK;\n\tvm86regs.pt.flags |= X86_VM_MASK;\n\n\tvm86regs.pt.orig_ax = regs->orig_ax;\n\n\tswitch (vm86->cpu_type) {\n\tcase CPU_286:\n\t\tvm86->veflags_mask = 0;\n\t\tbreak;\n\tcase CPU_386:\n\t\tvm86->veflags_mask = X86_EFLAGS_NT | X86_EFLAGS_IOPL;\n\t\tbreak;\n\tcase CPU_486:\n\t\tvm86->veflags_mask = X86_EFLAGS_AC | X86_EFLAGS_NT | X86_EFLAGS_IOPL;\n\t\tbreak;\n\tdefault:\n\t\tvm86->veflags_mask = X86_EFLAGS_ID | X86_EFLAGS_AC | X86_EFLAGS_NT | X86_EFLAGS_IOPL;\n\t\tbreak;\n\t}\n\n \n\tvm86->saved_sp0 = tsk->thread.sp0;\n\tsavesegment(gs, vm86->regs32.gs);\n\n\t \n\tpreempt_disable();\n\ttsk->thread.sp0 += 16;\n\n\tif (boot_cpu_has(X86_FEATURE_SEP)) {\n\t\ttsk->thread.sysenter_cs = 0;\n\t\trefresh_sysenter_cs(&tsk->thread);\n\t}\n\n\tupdate_task_stack(tsk);\n\tpreempt_enable();\n\n\tmemcpy((struct kernel_vm86_regs *)regs, &vm86regs, sizeof(vm86regs));\n\treturn regs->ax;\n}\n\nstatic inline void set_IF(struct kernel_vm86_regs *regs)\n{\n\tVEFLAGS |= X86_EFLAGS_VIF;\n}\n\nstatic inline void clear_IF(struct kernel_vm86_regs *regs)\n{\n\tVEFLAGS &= ~X86_EFLAGS_VIF;\n}\n\nstatic inline void clear_TF(struct kernel_vm86_regs *regs)\n{\n\tregs->pt.flags &= ~X86_EFLAGS_TF;\n}\n\nstatic inline void clear_AC(struct kernel_vm86_regs *regs)\n{\n\tregs->pt.flags &= ~X86_EFLAGS_AC;\n}\n\n \n\nstatic inline void set_vflags_long(unsigned long flags, struct kernel_vm86_regs *regs)\n{\n\tset_flags(VEFLAGS, flags, current->thread.vm86->veflags_mask);\n\tset_flags(regs->pt.flags, flags, SAFE_MASK);\n\tif (flags & X86_EFLAGS_IF)\n\t\tset_IF(regs);\n\telse\n\t\tclear_IF(regs);\n}\n\nstatic inline void set_vflags_short(unsigned short flags, struct kernel_vm86_regs *regs)\n{\n\tset_flags(VFLAGS, flags, current->thread.vm86->veflags_mask);\n\tset_flags(regs->pt.flags, flags, SAFE_MASK);\n\tif (flags & X86_EFLAGS_IF)\n\t\tset_IF(regs);\n\telse\n\t\tclear_IF(regs);\n}\n\nstatic inline unsigned long get_vflags(struct kernel_vm86_regs *regs)\n{\n\tunsigned long flags = regs->pt.flags & RETURN_MASK;\n\n\tif (VEFLAGS & X86_EFLAGS_VIF)\n\t\tflags |= X86_EFLAGS_IF;\n\tflags |= X86_EFLAGS_IOPL;\n\treturn flags | (VEFLAGS & current->thread.vm86->veflags_mask);\n}\n\nstatic inline int is_revectored(int nr, struct revectored_struct *bitmap)\n{\n\treturn test_bit(nr, bitmap->__map);\n}\n\n#define val_byte(val, n) (((__u8 *)&val)[n])\n\n#define pushb(base, ptr, val, err_label) \\\n\tdo { \\\n\t\t__u8 __val = val; \\\n\t\tptr--; \\\n\t\tif (put_user(__val, base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t} while (0)\n\n#define pushw(base, ptr, val, err_label) \\\n\tdo { \\\n\t\t__u16 __val = val; \\\n\t\tptr--; \\\n\t\tif (put_user(val_byte(__val, 1), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr--; \\\n\t\tif (put_user(val_byte(__val, 0), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t} while (0)\n\n#define pushl(base, ptr, val, err_label) \\\n\tdo { \\\n\t\t__u32 __val = val; \\\n\t\tptr--; \\\n\t\tif (put_user(val_byte(__val, 3), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr--; \\\n\t\tif (put_user(val_byte(__val, 2), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr--; \\\n\t\tif (put_user(val_byte(__val, 1), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr--; \\\n\t\tif (put_user(val_byte(__val, 0), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t} while (0)\n\n#define popb(base, ptr, err_label) \\\n\t({ \\\n\t\t__u8 __res; \\\n\t\tif (get_user(__res, base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr++; \\\n\t\t__res; \\\n\t})\n\n#define popw(base, ptr, err_label) \\\n\t({ \\\n\t\t__u16 __res; \\\n\t\tif (get_user(val_byte(__res, 0), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr++; \\\n\t\tif (get_user(val_byte(__res, 1), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr++; \\\n\t\t__res; \\\n\t})\n\n#define popl(base, ptr, err_label) \\\n\t({ \\\n\t\t__u32 __res; \\\n\t\tif (get_user(val_byte(__res, 0), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr++; \\\n\t\tif (get_user(val_byte(__res, 1), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr++; \\\n\t\tif (get_user(val_byte(__res, 2), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr++; \\\n\t\tif (get_user(val_byte(__res, 3), base + ptr) < 0) \\\n\t\t\tgoto err_label; \\\n\t\tptr++; \\\n\t\t__res; \\\n\t})\n\n \nstatic void do_int(struct kernel_vm86_regs *regs, int i,\n    unsigned char __user *ssp, unsigned short sp)\n{\n\tunsigned long __user *intr_ptr;\n\tunsigned long segoffs;\n\tstruct vm86 *vm86 = current->thread.vm86;\n\n\tif (regs->pt.cs == BIOSSEG)\n\t\tgoto cannot_handle;\n\tif (is_revectored(i, &vm86->int_revectored))\n\t\tgoto cannot_handle;\n\tif (i == 0x21 && is_revectored(AH(regs), &vm86->int21_revectored))\n\t\tgoto cannot_handle;\n\tintr_ptr = (unsigned long __user *) (i << 2);\n\tif (get_user(segoffs, intr_ptr))\n\t\tgoto cannot_handle;\n\tif ((segoffs >> 16) == BIOSSEG)\n\t\tgoto cannot_handle;\n\tpushw(ssp, sp, get_vflags(regs), cannot_handle);\n\tpushw(ssp, sp, regs->pt.cs, cannot_handle);\n\tpushw(ssp, sp, IP(regs), cannot_handle);\n\tregs->pt.cs = segoffs >> 16;\n\tSP(regs) -= 6;\n\tIP(regs) = segoffs & 0xffff;\n\tclear_TF(regs);\n\tclear_IF(regs);\n\tclear_AC(regs);\n\treturn;\n\ncannot_handle:\n\tsave_v86_state(regs, VM86_INTx + (i << 8));\n}\n\nint handle_vm86_trap(struct kernel_vm86_regs *regs, long error_code, int trapno)\n{\n\tstruct vm86 *vm86 = current->thread.vm86;\n\n\tif (vm86->vm86plus.is_vm86pus) {\n\t\tif ((trapno == 3) || (trapno == 1)) {\n\t\t\tsave_v86_state(regs, VM86_TRAP + (trapno << 8));\n\t\t\treturn 0;\n\t\t}\n\t\tdo_int(regs, trapno, (unsigned char __user *) (regs->pt.ss << 4), SP(regs));\n\t\treturn 0;\n\t}\n\tif (trapno != 1)\n\t\treturn 1;  \n\tcurrent->thread.trap_nr = trapno;\n\tcurrent->thread.error_code = error_code;\n\tforce_sig(SIGTRAP);\n\treturn 0;\n}\n\nvoid handle_vm86_fault(struct kernel_vm86_regs *regs, long error_code)\n{\n\tunsigned char opcode;\n\tunsigned char __user *csp;\n\tunsigned char __user *ssp;\n\tunsigned short ip, sp, orig_flags;\n\tint data32, pref_done;\n\tstruct vm86plus_info_struct *vmpi = &current->thread.vm86->vm86plus;\n\n#define CHECK_IF_IN_TRAP \\\n\tif (vmpi->vm86dbg_active && vmpi->vm86dbg_TFpendig) \\\n\t\tnewflags |= X86_EFLAGS_TF\n\n\torig_flags = *(unsigned short *)&regs->pt.flags;\n\n\tcsp = (unsigned char __user *) (regs->pt.cs << 4);\n\tssp = (unsigned char __user *) (regs->pt.ss << 4);\n\tsp = SP(regs);\n\tip = IP(regs);\n\n\tdata32 = 0;\n\tpref_done = 0;\n\tdo {\n\t\tswitch (opcode = popb(csp, ip, simulate_sigsegv)) {\n\t\tcase 0x66:            data32 = 1; break;\n\t\tcase 0x67:         break;\n\t\tcase 0x2e:                     break;\n\t\tcase 0x3e:                     break;\n\t\tcase 0x26:                     break;\n\t\tcase 0x36:                     break;\n\t\tcase 0x65:                     break;\n\t\tcase 0x64:                     break;\n\t\tcase 0xf2:              break;\n\t\tcase 0xf3:                    break;\n\t\tdefault: pref_done = 1;\n\t\t}\n\t} while (!pref_done);\n\n\tswitch (opcode) {\n\n\t \n\tcase 0x9c:\n\t\tif (data32) {\n\t\t\tpushl(ssp, sp, get_vflags(regs), simulate_sigsegv);\n\t\t\tSP(regs) -= 4;\n\t\t} else {\n\t\t\tpushw(ssp, sp, get_vflags(regs), simulate_sigsegv);\n\t\t\tSP(regs) -= 2;\n\t\t}\n\t\tIP(regs) = ip;\n\t\tgoto vm86_fault_return;\n\n\t \n\tcase 0x9d:\n\t\t{\n\t\tunsigned long newflags;\n\t\tif (data32) {\n\t\t\tnewflags = popl(ssp, sp, simulate_sigsegv);\n\t\t\tSP(regs) += 4;\n\t\t} else {\n\t\t\tnewflags = popw(ssp, sp, simulate_sigsegv);\n\t\t\tSP(regs) += 2;\n\t\t}\n\t\tIP(regs) = ip;\n\t\tCHECK_IF_IN_TRAP;\n\t\tif (data32)\n\t\t\tset_vflags_long(newflags, regs);\n\t\telse\n\t\t\tset_vflags_short(newflags, regs);\n\n\t\tgoto check_vip;\n\t\t}\n\n\t \n\tcase 0xcd: {\n\t\tint intno = popb(csp, ip, simulate_sigsegv);\n\t\tIP(regs) = ip;\n\t\tif (vmpi->vm86dbg_active) {\n\t\t\tif ((1 << (intno & 7)) & vmpi->vm86dbg_intxxtab[intno >> 3]) {\n\t\t\t\tsave_v86_state(regs, VM86_INTx + (intno << 8));\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tdo_int(regs, intno, ssp, sp);\n\t\treturn;\n\t}\n\n\t \n\tcase 0xcf:\n\t\t{\n\t\tunsigned long newip;\n\t\tunsigned long newcs;\n\t\tunsigned long newflags;\n\t\tif (data32) {\n\t\t\tnewip = popl(ssp, sp, simulate_sigsegv);\n\t\t\tnewcs = popl(ssp, sp, simulate_sigsegv);\n\t\t\tnewflags = popl(ssp, sp, simulate_sigsegv);\n\t\t\tSP(regs) += 12;\n\t\t} else {\n\t\t\tnewip = popw(ssp, sp, simulate_sigsegv);\n\t\t\tnewcs = popw(ssp, sp, simulate_sigsegv);\n\t\t\tnewflags = popw(ssp, sp, simulate_sigsegv);\n\t\t\tSP(regs) += 6;\n\t\t}\n\t\tIP(regs) = newip;\n\t\tregs->pt.cs = newcs;\n\t\tCHECK_IF_IN_TRAP;\n\t\tif (data32) {\n\t\t\tset_vflags_long(newflags, regs);\n\t\t} else {\n\t\t\tset_vflags_short(newflags, regs);\n\t\t}\n\t\tgoto check_vip;\n\t\t}\n\n\t \n\tcase 0xfa:\n\t\tIP(regs) = ip;\n\t\tclear_IF(regs);\n\t\tgoto vm86_fault_return;\n\n\t \n\t \n\tcase 0xfb:\n\t\tIP(regs) = ip;\n\t\tset_IF(regs);\n\t\tgoto check_vip;\n\n\tdefault:\n\t\tsave_v86_state(regs, VM86_UNKNOWN);\n\t}\n\n\treturn;\n\ncheck_vip:\n\tif ((VEFLAGS & (X86_EFLAGS_VIP | X86_EFLAGS_VIF)) ==\n\t    (X86_EFLAGS_VIP | X86_EFLAGS_VIF)) {\n\t\tsave_v86_state(regs, VM86_STI);\n\t\treturn;\n\t}\n\nvm86_fault_return:\n\tif (vmpi->force_return_for_pic  && (VEFLAGS & (X86_EFLAGS_IF | X86_EFLAGS_VIF))) {\n\t\tsave_v86_state(regs, VM86_PICRETURN);\n\t\treturn;\n\t}\n\tif (orig_flags & X86_EFLAGS_TF)\n\t\thandle_vm86_trap(regs, 0, X86_TRAP_DB);\n\treturn;\n\nsimulate_sigsegv:\n\t \n\tsave_v86_state(regs, VM86_UNKNOWN);\n}\n\n \n\n#define VM86_IRQNAME\t\t\"vm86irq\"\n\nstatic struct vm86_irqs {\n\tstruct task_struct *tsk;\n\tint sig;\n} vm86_irqs[16];\n\nstatic DEFINE_SPINLOCK(irqbits_lock);\nstatic int irqbits;\n\n#define ALLOWED_SIGS (1   \\\n\t| (1 << SIGUSR1) | (1 << SIGUSR2) | (1 << SIGIO)  | (1 << SIGURG) \\\n\t| (1 << SIGUNUSED))\n\nstatic irqreturn_t irq_handler(int intno, void *dev_id)\n{\n\tint irq_bit;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&irqbits_lock, flags);\n\tirq_bit = 1 << intno;\n\tif ((irqbits & irq_bit) || !vm86_irqs[intno].tsk)\n\t\tgoto out;\n\tirqbits |= irq_bit;\n\tif (vm86_irqs[intno].sig)\n\t\tsend_sig(vm86_irqs[intno].sig, vm86_irqs[intno].tsk, 1);\n\t \n\tdisable_irq_nosync(intno);\n\tspin_unlock_irqrestore(&irqbits_lock, flags);\n\treturn IRQ_HANDLED;\n\nout:\n\tspin_unlock_irqrestore(&irqbits_lock, flags);\n\treturn IRQ_NONE;\n}\n\nstatic inline void free_vm86_irq(int irqnumber)\n{\n\tunsigned long flags;\n\n\tfree_irq(irqnumber, NULL);\n\tvm86_irqs[irqnumber].tsk = NULL;\n\n\tspin_lock_irqsave(&irqbits_lock, flags);\n\tirqbits &= ~(1 << irqnumber);\n\tspin_unlock_irqrestore(&irqbits_lock, flags);\n}\n\nvoid release_vm86_irqs(struct task_struct *task)\n{\n\tint i;\n\tfor (i = FIRST_VM86_IRQ ; i <= LAST_VM86_IRQ; i++)\n\t    if (vm86_irqs[i].tsk == task)\n\t\tfree_vm86_irq(i);\n}\n\nstatic inline int get_and_reset_irq(int irqnumber)\n{\n\tint bit;\n\tunsigned long flags;\n\tint ret = 0;\n\n\tif (invalid_vm86_irq(irqnumber)) return 0;\n\tif (vm86_irqs[irqnumber].tsk != current) return 0;\n\tspin_lock_irqsave(&irqbits_lock, flags);\n\tbit = irqbits & (1 << irqnumber);\n\tirqbits &= ~bit;\n\tif (bit) {\n\t\tenable_irq(irqnumber);\n\t\tret = 1;\n\t}\n\n\tspin_unlock_irqrestore(&irqbits_lock, flags);\n\treturn ret;\n}\n\n\nstatic int do_vm86_irq_handling(int subfunction, int irqnumber)\n{\n\tint ret;\n\tswitch (subfunction) {\n\t\tcase VM86_GET_AND_RESET_IRQ: {\n\t\t\treturn get_and_reset_irq(irqnumber);\n\t\t}\n\t\tcase VM86_GET_IRQ_BITS: {\n\t\t\treturn irqbits;\n\t\t}\n\t\tcase VM86_REQUEST_IRQ: {\n\t\t\tint sig = irqnumber >> 8;\n\t\t\tint irq = irqnumber & 255;\n\t\t\tif (!capable(CAP_SYS_ADMIN)) return -EPERM;\n\t\t\tif (!((1 << sig) & ALLOWED_SIGS)) return -EPERM;\n\t\t\tif (invalid_vm86_irq(irq)) return -EPERM;\n\t\t\tif (vm86_irqs[irq].tsk) return -EPERM;\n\t\t\tret = request_irq(irq, &irq_handler, 0, VM86_IRQNAME, NULL);\n\t\t\tif (ret) return ret;\n\t\t\tvm86_irqs[irq].sig = sig;\n\t\t\tvm86_irqs[irq].tsk = current;\n\t\t\treturn irq;\n\t\t}\n\t\tcase  VM86_FREE_IRQ: {\n\t\t\tif (invalid_vm86_irq(irqnumber)) return -EPERM;\n\t\t\tif (!vm86_irqs[irqnumber].tsk) return 0;\n\t\t\tif (vm86_irqs[irqnumber].tsk != current) return -EPERM;\n\t\t\tfree_vm86_irq(irqnumber);\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn -EINVAL;\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}