{
  "module_name": "ipi.c",
  "hash_id": "dcf97ba358beeb8ce2c7c3f391fcb70af2aea2a0d516ade08cb4fe2692635abf",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/apic/ipi.c",
  "human_readable_source": "\n\n#include <linux/cpumask.h>\n#include <linux/delay.h>\n#include <linux/smp.h>\n\n#include <asm/io_apic.h>\n\n#include \"local.h\"\n\nDEFINE_STATIC_KEY_FALSE(apic_use_ipi_shorthand);\n\n#ifdef CONFIG_SMP\nstatic int apic_ipi_shorthand_off __ro_after_init;\n\nstatic __init int apic_ipi_shorthand(char *str)\n{\n\tget_option(&str, &apic_ipi_shorthand_off);\n\treturn 1;\n}\n__setup(\"no_ipi_broadcast=\", apic_ipi_shorthand);\n\nstatic int __init print_ipi_mode(void)\n{\n\tpr_info(\"IPI shorthand broadcast: %s\\n\",\n\t\tapic_ipi_shorthand_off ? \"disabled\" : \"enabled\");\n\treturn 0;\n}\nlate_initcall(print_ipi_mode);\n\nvoid apic_smt_update(void)\n{\n\t \n\tif (apic_ipi_shorthand_off || num_online_cpus() == 1 ||\n\t    !cpumask_equal(cpu_present_mask, &cpus_booted_once_mask)) {\n\t\tstatic_branch_disable(&apic_use_ipi_shorthand);\n\t} else {\n\t\tstatic_branch_enable(&apic_use_ipi_shorthand);\n\t}\n}\n\nvoid apic_send_IPI_allbutself(unsigned int vector)\n{\n\tif (num_online_cpus() < 2)\n\t\treturn;\n\n\tif (static_branch_likely(&apic_use_ipi_shorthand))\n\t\t__apic_send_IPI_allbutself(vector);\n\telse\n\t\t__apic_send_IPI_mask_allbutself(cpu_online_mask, vector);\n}\n\n \nvoid native_smp_send_reschedule(int cpu)\n{\n\tif (unlikely(cpu_is_offline(cpu))) {\n\t\tWARN(1, \"sched: Unexpected reschedule of offline CPU#%d!\\n\", cpu);\n\t\treturn;\n\t}\n\t__apic_send_IPI(cpu, RESCHEDULE_VECTOR);\n}\n\nvoid native_send_call_func_single_ipi(int cpu)\n{\n\t__apic_send_IPI(cpu, CALL_FUNCTION_SINGLE_VECTOR);\n}\n\nvoid native_send_call_func_ipi(const struct cpumask *mask)\n{\n\tif (static_branch_likely(&apic_use_ipi_shorthand)) {\n\t\tunsigned int cpu = smp_processor_id();\n\n\t\tif (!cpumask_or_equal(mask, cpumask_of(cpu), cpu_online_mask))\n\t\t\tgoto sendmask;\n\n\t\tif (cpumask_test_cpu(cpu, mask))\n\t\t\t__apic_send_IPI_all(CALL_FUNCTION_VECTOR);\n\t\telse if (num_online_cpus() > 1)\n\t\t\t__apic_send_IPI_allbutself(CALL_FUNCTION_VECTOR);\n\t\treturn;\n\t}\n\nsendmask:\n\t__apic_send_IPI_mask(mask, CALL_FUNCTION_VECTOR);\n}\n\n#endif  \n\nstatic inline int __prepare_ICR2(unsigned int mask)\n{\n\treturn SET_XAPIC_DEST_FIELD(mask);\n}\n\nu32 apic_mem_wait_icr_idle_timeout(void)\n{\n\tint cnt;\n\n\tfor (cnt = 0; cnt < 1000; cnt++) {\n\t\tif (!(apic_read(APIC_ICR) & APIC_ICR_BUSY))\n\t\t\treturn 0;\n\t\tinc_irq_stat(icr_read_retry_count);\n\t\tudelay(100);\n\t}\n\treturn APIC_ICR_BUSY;\n}\n\nvoid apic_mem_wait_icr_idle(void)\n{\n\twhile (native_apic_mem_read(APIC_ICR) & APIC_ICR_BUSY)\n\t\tcpu_relax();\n}\n\n \nstatic void __default_send_IPI_shortcut(unsigned int shortcut, int vector)\n{\n\t \n\tif (unlikely(vector == NMI_VECTOR))\n\t\tapic_mem_wait_icr_idle_timeout();\n\telse\n\t\tapic_mem_wait_icr_idle();\n\n\t \n\tnative_apic_mem_write(APIC_ICR, __prepare_ICR(shortcut, vector, 0));\n}\n\n \nvoid __default_send_IPI_dest_field(unsigned int dest_mask, int vector,\n\t\t\t\t   unsigned int dest_mode)\n{\n\t \n\tif (unlikely(vector == NMI_VECTOR))\n\t\tapic_mem_wait_icr_idle_timeout();\n\telse\n\t\tapic_mem_wait_icr_idle();\n\n\t \n\tnative_apic_mem_write(APIC_ICR2, __prepare_ICR2(dest_mask));\n\t \n\tnative_apic_mem_write(APIC_ICR, __prepare_ICR(0, vector, dest_mode));\n}\n\nvoid default_send_IPI_single_phys(int cpu, int vector)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__default_send_IPI_dest_field(per_cpu(x86_cpu_to_apicid, cpu),\n\t\t\t\t      vector, APIC_DEST_PHYSICAL);\n\tlocal_irq_restore(flags);\n}\n\nvoid default_send_IPI_mask_sequence_phys(const struct cpumask *mask, int vector)\n{\n\tunsigned long flags;\n\tunsigned long cpu;\n\n\tlocal_irq_save(flags);\n\tfor_each_cpu(cpu, mask) {\n\t\t__default_send_IPI_dest_field(per_cpu(x86_cpu_to_apicid,\n\t\t\t\tcpu), vector, APIC_DEST_PHYSICAL);\n\t}\n\tlocal_irq_restore(flags);\n}\n\nvoid default_send_IPI_mask_allbutself_phys(const struct cpumask *mask,\n\t\t\t\t\t\t int vector)\n{\n\tunsigned int cpu, this_cpu = smp_processor_id();\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tfor_each_cpu(cpu, mask) {\n\t\tif (cpu == this_cpu)\n\t\t\tcontinue;\n\t\t__default_send_IPI_dest_field(per_cpu(x86_cpu_to_apicid,\n\t\t\t\t cpu), vector, APIC_DEST_PHYSICAL);\n\t}\n\tlocal_irq_restore(flags);\n}\n\n \nvoid default_send_IPI_single(int cpu, int vector)\n{\n\t__apic_send_IPI_mask(cpumask_of(cpu), vector);\n}\n\nvoid default_send_IPI_allbutself(int vector)\n{\n\t__default_send_IPI_shortcut(APIC_DEST_ALLBUT, vector);\n}\n\nvoid default_send_IPI_all(int vector)\n{\n\t__default_send_IPI_shortcut(APIC_DEST_ALLINC, vector);\n}\n\nvoid default_send_IPI_self(int vector)\n{\n\t__default_send_IPI_shortcut(APIC_DEST_SELF, vector);\n}\n\n#ifdef CONFIG_X86_32\nvoid default_send_IPI_mask_sequence_logical(const struct cpumask *mask, int vector)\n{\n\tunsigned long flags;\n\tunsigned int cpu;\n\n\tlocal_irq_save(flags);\n\tfor_each_cpu(cpu, mask)\n\t\t__default_send_IPI_dest_field(1U << cpu, vector, APIC_DEST_LOGICAL);\n\tlocal_irq_restore(flags);\n}\n\nvoid default_send_IPI_mask_allbutself_logical(const struct cpumask *mask,\n\t\t\t\t\t\t int vector)\n{\n\tunsigned int cpu, this_cpu = smp_processor_id();\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tfor_each_cpu(cpu, mask) {\n\t\tif (cpu == this_cpu)\n\t\t\tcontinue;\n\t\t__default_send_IPI_dest_field(1U << cpu, vector, APIC_DEST_LOGICAL);\n\t}\n\tlocal_irq_restore(flags);\n}\n\nvoid default_send_IPI_mask_logical(const struct cpumask *cpumask, int vector)\n{\n\tunsigned long mask = cpumask_bits(cpumask)[0];\n\tunsigned long flags;\n\n\tif (!mask)\n\t\treturn;\n\n\tlocal_irq_save(flags);\n\tWARN_ON(mask & ~cpumask_bits(cpu_online_mask)[0]);\n\t__default_send_IPI_dest_field(mask, vector, APIC_DEST_LOGICAL);\n\tlocal_irq_restore(flags);\n}\n\n#ifdef CONFIG_SMP\nstatic int convert_apicid_to_cpu(int apic_id)\n{\n\tint i;\n\n\tfor_each_possible_cpu(i) {\n\t\tif (per_cpu(x86_cpu_to_apicid, i) == apic_id)\n\t\t\treturn i;\n\t}\n\treturn -1;\n}\n\nint safe_smp_processor_id(void)\n{\n\tint apicid, cpuid;\n\n\tif (!boot_cpu_has(X86_FEATURE_APIC))\n\t\treturn 0;\n\n\tapicid = read_apic_id();\n\tif (apicid == BAD_APICID)\n\t\treturn 0;\n\n\tcpuid = convert_apicid_to_cpu(apicid);\n\n\treturn cpuid >= 0 ? cpuid : 0;\n}\n#endif\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}