{
  "module_name": "vector.c",
  "hash_id": "6edd6c22536abe2c1ed5c5d674c235ef969b5325b139bcd3edc5e754d343f9a0",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/apic/vector.c",
  "human_readable_source": "\n \n#include <linux/interrupt.h>\n#include <linux/irq.h>\n#include <linux/seq_file.h>\n#include <linux/init.h>\n#include <linux/compiler.h>\n#include <linux/slab.h>\n#include <asm/irqdomain.h>\n#include <asm/hw_irq.h>\n#include <asm/traps.h>\n#include <asm/apic.h>\n#include <asm/i8259.h>\n#include <asm/desc.h>\n#include <asm/irq_remapping.h>\n\n#include <asm/trace/irq_vectors.h>\n\nstruct apic_chip_data {\n\tstruct irq_cfg\t\thw_irq_cfg;\n\tunsigned int\t\tvector;\n\tunsigned int\t\tprev_vector;\n\tunsigned int\t\tcpu;\n\tunsigned int\t\tprev_cpu;\n\tunsigned int\t\tirq;\n\tstruct hlist_node\tclist;\n\tunsigned int\t\tmove_in_progress\t: 1,\n\t\t\t\tis_managed\t\t: 1,\n\t\t\t\tcan_reserve\t\t: 1,\n\t\t\t\thas_reserved\t\t: 1;\n};\n\nstruct irq_domain *x86_vector_domain;\nEXPORT_SYMBOL_GPL(x86_vector_domain);\nstatic DEFINE_RAW_SPINLOCK(vector_lock);\nstatic cpumask_var_t vector_searchmask;\nstatic struct irq_chip lapic_controller;\nstatic struct irq_matrix *vector_matrix;\n#ifdef CONFIG_SMP\n\nstatic void vector_cleanup_callback(struct timer_list *tmr);\n\nstruct vector_cleanup {\n\tstruct hlist_head\thead;\n\tstruct timer_list\ttimer;\n};\n\nstatic DEFINE_PER_CPU(struct vector_cleanup, vector_cleanup) = {\n\t.head\t= HLIST_HEAD_INIT,\n\t.timer\t= __TIMER_INITIALIZER(vector_cleanup_callback, TIMER_PINNED),\n};\n#endif\n\nvoid lock_vector_lock(void)\n{\n\t \n\traw_spin_lock(&vector_lock);\n}\n\nvoid unlock_vector_lock(void)\n{\n\traw_spin_unlock(&vector_lock);\n}\n\nvoid init_irq_alloc_info(struct irq_alloc_info *info,\n\t\t\t const struct cpumask *mask)\n{\n\tmemset(info, 0, sizeof(*info));\n\tinfo->mask = mask;\n}\n\nvoid copy_irq_alloc_info(struct irq_alloc_info *dst, struct irq_alloc_info *src)\n{\n\tif (src)\n\t\t*dst = *src;\n\telse\n\t\tmemset(dst, 0, sizeof(*dst));\n}\n\nstatic struct apic_chip_data *apic_chip_data(struct irq_data *irqd)\n{\n\tif (!irqd)\n\t\treturn NULL;\n\n\twhile (irqd->parent_data)\n\t\tirqd = irqd->parent_data;\n\n\treturn irqd->chip_data;\n}\n\nstruct irq_cfg *irqd_cfg(struct irq_data *irqd)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\n\treturn apicd ? &apicd->hw_irq_cfg : NULL;\n}\nEXPORT_SYMBOL_GPL(irqd_cfg);\n\nstruct irq_cfg *irq_cfg(unsigned int irq)\n{\n\treturn irqd_cfg(irq_get_irq_data(irq));\n}\n\nstatic struct apic_chip_data *alloc_apic_chip_data(int node)\n{\n\tstruct apic_chip_data *apicd;\n\n\tapicd = kzalloc_node(sizeof(*apicd), GFP_KERNEL, node);\n\tif (apicd)\n\t\tINIT_HLIST_NODE(&apicd->clist);\n\treturn apicd;\n}\n\nstatic void free_apic_chip_data(struct apic_chip_data *apicd)\n{\n\tkfree(apicd);\n}\n\nstatic void apic_update_irq_cfg(struct irq_data *irqd, unsigned int vector,\n\t\t\t\tunsigned int cpu)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\n\tlockdep_assert_held(&vector_lock);\n\n\tapicd->hw_irq_cfg.vector = vector;\n\tapicd->hw_irq_cfg.dest_apicid = apic->calc_dest_apicid(cpu);\n\tirq_data_update_effective_affinity(irqd, cpumask_of(cpu));\n\ttrace_vector_config(irqd->irq, vector, cpu,\n\t\t\t    apicd->hw_irq_cfg.dest_apicid);\n}\n\nstatic void apic_update_vector(struct irq_data *irqd, unsigned int newvec,\n\t\t\t       unsigned int newcpu)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\tstruct irq_desc *desc = irq_data_to_desc(irqd);\n\tbool managed = irqd_affinity_is_managed(irqd);\n\n\tlockdep_assert_held(&vector_lock);\n\n\ttrace_vector_update(irqd->irq, newvec, newcpu, apicd->vector,\n\t\t\t    apicd->cpu);\n\n\t \n\tapicd->prev_vector = 0;\n\tif (!apicd->vector || apicd->vector == MANAGED_IRQ_SHUTDOWN_VECTOR)\n\t\tgoto setnew;\n\t \n\tif (cpu_online(apicd->cpu)) {\n\t\tapicd->move_in_progress = true;\n\t\tapicd->prev_vector = apicd->vector;\n\t\tapicd->prev_cpu = apicd->cpu;\n\t\tWARN_ON_ONCE(apicd->cpu == newcpu);\n\t} else {\n\t\tirq_matrix_free(vector_matrix, apicd->cpu, apicd->vector,\n\t\t\t\tmanaged);\n\t}\n\nsetnew:\n\tapicd->vector = newvec;\n\tapicd->cpu = newcpu;\n\tBUG_ON(!IS_ERR_OR_NULL(per_cpu(vector_irq, newcpu)[newvec]));\n\tper_cpu(vector_irq, newcpu)[newvec] = desc;\n}\n\nstatic void vector_assign_managed_shutdown(struct irq_data *irqd)\n{\n\tunsigned int cpu = cpumask_first(cpu_online_mask);\n\n\tapic_update_irq_cfg(irqd, MANAGED_IRQ_SHUTDOWN_VECTOR, cpu);\n}\n\nstatic int reserve_managed_vector(struct irq_data *irqd)\n{\n\tconst struct cpumask *affmsk = irq_data_get_affinity_mask(irqd);\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\tunsigned long flags;\n\tint ret;\n\n\traw_spin_lock_irqsave(&vector_lock, flags);\n\tapicd->is_managed = true;\n\tret = irq_matrix_reserve_managed(vector_matrix, affmsk);\n\traw_spin_unlock_irqrestore(&vector_lock, flags);\n\ttrace_vector_reserve_managed(irqd->irq, ret);\n\treturn ret;\n}\n\nstatic void reserve_irq_vector_locked(struct irq_data *irqd)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\n\tirq_matrix_reserve(vector_matrix);\n\tapicd->can_reserve = true;\n\tapicd->has_reserved = true;\n\tirqd_set_can_reserve(irqd);\n\ttrace_vector_reserve(irqd->irq, 0);\n\tvector_assign_managed_shutdown(irqd);\n}\n\nstatic int reserve_irq_vector(struct irq_data *irqd)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&vector_lock, flags);\n\treserve_irq_vector_locked(irqd);\n\traw_spin_unlock_irqrestore(&vector_lock, flags);\n\treturn 0;\n}\n\nstatic int\nassign_vector_locked(struct irq_data *irqd, const struct cpumask *dest)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\tbool resvd = apicd->has_reserved;\n\tunsigned int cpu = apicd->cpu;\n\tint vector = apicd->vector;\n\n\tlockdep_assert_held(&vector_lock);\n\n\t \n\tif (vector && cpu_online(cpu) && cpumask_test_cpu(cpu, dest))\n\t\treturn 0;\n\n\t \n\tif (apicd->move_in_progress || !hlist_unhashed(&apicd->clist))\n\t\treturn -EBUSY;\n\n\tvector = irq_matrix_alloc(vector_matrix, dest, resvd, &cpu);\n\ttrace_vector_alloc(irqd->irq, vector, resvd, vector);\n\tif (vector < 0)\n\t\treturn vector;\n\tapic_update_vector(irqd, vector, cpu);\n\tapic_update_irq_cfg(irqd, vector, cpu);\n\n\treturn 0;\n}\n\nstatic int assign_irq_vector(struct irq_data *irqd, const struct cpumask *dest)\n{\n\tunsigned long flags;\n\tint ret;\n\n\traw_spin_lock_irqsave(&vector_lock, flags);\n\tcpumask_and(vector_searchmask, dest, cpu_online_mask);\n\tret = assign_vector_locked(irqd, vector_searchmask);\n\traw_spin_unlock_irqrestore(&vector_lock, flags);\n\treturn ret;\n}\n\nstatic int assign_irq_vector_any_locked(struct irq_data *irqd)\n{\n\t \n\tconst struct cpumask *affmsk = irq_data_get_affinity_mask(irqd);\n\tint node = irq_data_get_node(irqd);\n\n\tif (node != NUMA_NO_NODE) {\n\t\t \n\t\tcpumask_and(vector_searchmask, cpumask_of_node(node), affmsk);\n\t\tif (!assign_vector_locked(irqd, vector_searchmask))\n\t\t\treturn 0;\n\t}\n\n\t \n\tcpumask_and(vector_searchmask, affmsk, cpu_online_mask);\n\tif (!assign_vector_locked(irqd, vector_searchmask))\n\t\treturn 0;\n\n\tif (node != NUMA_NO_NODE) {\n\t\t \n\t\tif (!assign_vector_locked(irqd, cpumask_of_node(node)))\n\t\t\treturn 0;\n\t}\n\n\t \n\treturn assign_vector_locked(irqd, cpu_online_mask);\n}\n\nstatic int\nassign_irq_vector_policy(struct irq_data *irqd, struct irq_alloc_info *info)\n{\n\tif (irqd_affinity_is_managed(irqd))\n\t\treturn reserve_managed_vector(irqd);\n\tif (info->mask)\n\t\treturn assign_irq_vector(irqd, info->mask);\n\t \n\treturn reserve_irq_vector(irqd);\n}\n\nstatic int\nassign_managed_vector(struct irq_data *irqd, const struct cpumask *dest)\n{\n\tconst struct cpumask *affmsk = irq_data_get_affinity_mask(irqd);\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\tint vector, cpu;\n\n\tcpumask_and(vector_searchmask, dest, affmsk);\n\n\t \n\tif (apicd->vector && cpumask_test_cpu(apicd->cpu, vector_searchmask))\n\t\treturn 0;\n\tvector = irq_matrix_alloc_managed(vector_matrix, vector_searchmask,\n\t\t\t\t\t  &cpu);\n\ttrace_vector_alloc_managed(irqd->irq, vector, vector);\n\tif (vector < 0)\n\t\treturn vector;\n\tapic_update_vector(irqd, vector, cpu);\n\tapic_update_irq_cfg(irqd, vector, cpu);\n\treturn 0;\n}\n\nstatic void clear_irq_vector(struct irq_data *irqd)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\tbool managed = irqd_affinity_is_managed(irqd);\n\tunsigned int vector = apicd->vector;\n\n\tlockdep_assert_held(&vector_lock);\n\n\tif (!vector)\n\t\treturn;\n\n\ttrace_vector_clear(irqd->irq, vector, apicd->cpu, apicd->prev_vector,\n\t\t\t   apicd->prev_cpu);\n\n\tper_cpu(vector_irq, apicd->cpu)[vector] = VECTOR_SHUTDOWN;\n\tirq_matrix_free(vector_matrix, apicd->cpu, vector, managed);\n\tapicd->vector = 0;\n\n\t \n\tvector = apicd->prev_vector;\n\tif (!vector)\n\t\treturn;\n\n\tper_cpu(vector_irq, apicd->prev_cpu)[vector] = VECTOR_SHUTDOWN;\n\tirq_matrix_free(vector_matrix, apicd->prev_cpu, vector, managed);\n\tapicd->prev_vector = 0;\n\tapicd->move_in_progress = 0;\n\thlist_del_init(&apicd->clist);\n}\n\nstatic void x86_vector_deactivate(struct irq_domain *dom, struct irq_data *irqd)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\tunsigned long flags;\n\n\ttrace_vector_deactivate(irqd->irq, apicd->is_managed,\n\t\t\t\tapicd->can_reserve, false);\n\n\t \n\tif (!apicd->is_managed && !apicd->can_reserve)\n\t\treturn;\n\t \n\tif (apicd->has_reserved)\n\t\treturn;\n\n\traw_spin_lock_irqsave(&vector_lock, flags);\n\tclear_irq_vector(irqd);\n\tif (apicd->can_reserve)\n\t\treserve_irq_vector_locked(irqd);\n\telse\n\t\tvector_assign_managed_shutdown(irqd);\n\traw_spin_unlock_irqrestore(&vector_lock, flags);\n}\n\nstatic int activate_reserved(struct irq_data *irqd)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\tint ret;\n\n\tret = assign_irq_vector_any_locked(irqd);\n\tif (!ret) {\n\t\tapicd->has_reserved = false;\n\t\t \n\t\tif (!irqd_can_reserve(irqd))\n\t\t\tapicd->can_reserve = false;\n\t}\n\n\t \n\tif (!cpumask_subset(irq_data_get_effective_affinity_mask(irqd),\n\t\t\t    irq_data_get_affinity_mask(irqd))) {\n\t\tpr_warn(\"irq %u: Affinity broken due to vector space exhaustion.\\n\",\n\t\t\tirqd->irq);\n\t}\n\n\treturn ret;\n}\n\nstatic int activate_managed(struct irq_data *irqd)\n{\n\tconst struct cpumask *dest = irq_data_get_affinity_mask(irqd);\n\tint ret;\n\n\tcpumask_and(vector_searchmask, dest, cpu_online_mask);\n\tif (WARN_ON_ONCE(cpumask_empty(vector_searchmask))) {\n\t\t \n\t\tpr_err(\"Managed startup for irq %u, but no CPU\\n\", irqd->irq);\n\t\treturn -EINVAL;\n\t}\n\n\tret = assign_managed_vector(irqd, vector_searchmask);\n\t \n\tif (WARN_ON_ONCE(ret < 0)) {\n\t\tpr_err(\"Managed startup irq %u, no vector available\\n\",\n\t\t       irqd->irq);\n\t}\n\treturn ret;\n}\n\nstatic int x86_vector_activate(struct irq_domain *dom, struct irq_data *irqd,\n\t\t\t       bool reserve)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\tunsigned long flags;\n\tint ret = 0;\n\n\ttrace_vector_activate(irqd->irq, apicd->is_managed,\n\t\t\t      apicd->can_reserve, reserve);\n\n\traw_spin_lock_irqsave(&vector_lock, flags);\n\tif (!apicd->can_reserve && !apicd->is_managed)\n\t\tassign_irq_vector_any_locked(irqd);\n\telse if (reserve || irqd_is_managed_and_shutdown(irqd))\n\t\tvector_assign_managed_shutdown(irqd);\n\telse if (apicd->is_managed)\n\t\tret = activate_managed(irqd);\n\telse if (apicd->has_reserved)\n\t\tret = activate_reserved(irqd);\n\traw_spin_unlock_irqrestore(&vector_lock, flags);\n\treturn ret;\n}\n\nstatic void vector_free_reserved_and_managed(struct irq_data *irqd)\n{\n\tconst struct cpumask *dest = irq_data_get_affinity_mask(irqd);\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\n\ttrace_vector_teardown(irqd->irq, apicd->is_managed,\n\t\t\t      apicd->has_reserved);\n\n\tif (apicd->has_reserved)\n\t\tirq_matrix_remove_reserved(vector_matrix);\n\tif (apicd->is_managed)\n\t\tirq_matrix_remove_managed(vector_matrix, dest);\n}\n\nstatic void x86_vector_free_irqs(struct irq_domain *domain,\n\t\t\t\t unsigned int virq, unsigned int nr_irqs)\n{\n\tstruct apic_chip_data *apicd;\n\tstruct irq_data *irqd;\n\tunsigned long flags;\n\tint i;\n\n\tfor (i = 0; i < nr_irqs; i++) {\n\t\tirqd = irq_domain_get_irq_data(x86_vector_domain, virq + i);\n\t\tif (irqd && irqd->chip_data) {\n\t\t\traw_spin_lock_irqsave(&vector_lock, flags);\n\t\t\tclear_irq_vector(irqd);\n\t\t\tvector_free_reserved_and_managed(irqd);\n\t\t\tapicd = irqd->chip_data;\n\t\t\tirq_domain_reset_irq_data(irqd);\n\t\t\traw_spin_unlock_irqrestore(&vector_lock, flags);\n\t\t\tfree_apic_chip_data(apicd);\n\t\t}\n\t}\n}\n\nstatic bool vector_configure_legacy(unsigned int virq, struct irq_data *irqd,\n\t\t\t\t    struct apic_chip_data *apicd)\n{\n\tunsigned long flags;\n\tbool realloc = false;\n\n\tapicd->vector = ISA_IRQ_VECTOR(virq);\n\tapicd->cpu = 0;\n\n\traw_spin_lock_irqsave(&vector_lock, flags);\n\t \n\tif (irqd_is_activated(irqd)) {\n\t\ttrace_vector_setup(virq, true, 0);\n\t\tapic_update_irq_cfg(irqd, apicd->vector, apicd->cpu);\n\t} else {\n\t\t \n\t\tapicd->can_reserve = true;\n\t\tirqd_set_can_reserve(irqd);\n\t\tclear_irq_vector(irqd);\n\t\trealloc = true;\n\t}\n\traw_spin_unlock_irqrestore(&vector_lock, flags);\n\treturn realloc;\n}\n\nstatic int x86_vector_alloc_irqs(struct irq_domain *domain, unsigned int virq,\n\t\t\t\t unsigned int nr_irqs, void *arg)\n{\n\tstruct irq_alloc_info *info = arg;\n\tstruct apic_chip_data *apicd;\n\tstruct irq_data *irqd;\n\tint i, err, node;\n\n\tif (apic_is_disabled)\n\t\treturn -ENXIO;\n\n\t \n\tif (WARN_ON_ONCE(info->flags & X86_IRQ_ALLOC_LEGACY &&\n\t\t\t virq == PIC_CASCADE_IR))\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < nr_irqs; i++) {\n\t\tirqd = irq_domain_get_irq_data(domain, virq + i);\n\t\tBUG_ON(!irqd);\n\t\tnode = irq_data_get_node(irqd);\n\t\tWARN_ON_ONCE(irqd->chip_data);\n\t\tapicd = alloc_apic_chip_data(node);\n\t\tif (!apicd) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto error;\n\t\t}\n\n\t\tapicd->irq = virq + i;\n\t\tirqd->chip = &lapic_controller;\n\t\tirqd->chip_data = apicd;\n\t\tirqd->hwirq = virq + i;\n\t\tirqd_set_single_target(irqd);\n\t\t \n\t\tirqd_set_handle_enforce_irqctx(irqd);\n\n\t\t \n\t\tirqd_set_affinity_on_activate(irqd);\n\n\t\t \n\t\tif (info->flags & X86_IRQ_ALLOC_LEGACY) {\n\t\t\tif (!vector_configure_legacy(virq + i, irqd, apicd))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\terr = assign_irq_vector_policy(irqd, info);\n\t\ttrace_vector_setup(virq + i, false, err);\n\t\tif (err) {\n\t\t\tirqd->chip_data = NULL;\n\t\t\tfree_apic_chip_data(apicd);\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\treturn 0;\n\nerror:\n\tx86_vector_free_irqs(domain, virq, i);\n\treturn err;\n}\n\n#ifdef CONFIG_GENERIC_IRQ_DEBUGFS\nstatic void x86_vector_debug_show(struct seq_file *m, struct irq_domain *d,\n\t\t\t\t  struct irq_data *irqd, int ind)\n{\n\tstruct apic_chip_data apicd;\n\tunsigned long flags;\n\tint irq;\n\n\tif (!irqd) {\n\t\tirq_matrix_debug_show(m, vector_matrix, ind);\n\t\treturn;\n\t}\n\n\tirq = irqd->irq;\n\tif (irq < nr_legacy_irqs() && !test_bit(irq, &io_apic_irqs)) {\n\t\tseq_printf(m, \"%*sVector: %5d\\n\", ind, \"\", ISA_IRQ_VECTOR(irq));\n\t\tseq_printf(m, \"%*sTarget: Legacy PIC all CPUs\\n\", ind, \"\");\n\t\treturn;\n\t}\n\n\tif (!irqd->chip_data) {\n\t\tseq_printf(m, \"%*sVector: Not assigned\\n\", ind, \"\");\n\t\treturn;\n\t}\n\n\traw_spin_lock_irqsave(&vector_lock, flags);\n\tmemcpy(&apicd, irqd->chip_data, sizeof(apicd));\n\traw_spin_unlock_irqrestore(&vector_lock, flags);\n\n\tseq_printf(m, \"%*sVector: %5u\\n\", ind, \"\", apicd.vector);\n\tseq_printf(m, \"%*sTarget: %5u\\n\", ind, \"\", apicd.cpu);\n\tif (apicd.prev_vector) {\n\t\tseq_printf(m, \"%*sPrevious vector: %5u\\n\", ind, \"\", apicd.prev_vector);\n\t\tseq_printf(m, \"%*sPrevious target: %5u\\n\", ind, \"\", apicd.prev_cpu);\n\t}\n\tseq_printf(m, \"%*smove_in_progress: %u\\n\", ind, \"\", apicd.move_in_progress ? 1 : 0);\n\tseq_printf(m, \"%*sis_managed:       %u\\n\", ind, \"\", apicd.is_managed ? 1 : 0);\n\tseq_printf(m, \"%*scan_reserve:      %u\\n\", ind, \"\", apicd.can_reserve ? 1 : 0);\n\tseq_printf(m, \"%*shas_reserved:     %u\\n\", ind, \"\", apicd.has_reserved ? 1 : 0);\n\tseq_printf(m, \"%*scleanup_pending:  %u\\n\", ind, \"\", !hlist_unhashed(&apicd.clist));\n}\n#endif\n\nint x86_fwspec_is_ioapic(struct irq_fwspec *fwspec)\n{\n\tif (fwspec->param_count != 1)\n\t\treturn 0;\n\n\tif (is_fwnode_irqchip(fwspec->fwnode)) {\n\t\tconst char *fwname = fwnode_get_name(fwspec->fwnode);\n\t\treturn fwname && !strncmp(fwname, \"IO-APIC-\", 8) &&\n\t\t\tsimple_strtol(fwname+8, NULL, 10) == fwspec->param[0];\n\t}\n\treturn to_of_node(fwspec->fwnode) &&\n\t\tof_device_is_compatible(to_of_node(fwspec->fwnode),\n\t\t\t\t\t\"intel,ce4100-ioapic\");\n}\n\nint x86_fwspec_is_hpet(struct irq_fwspec *fwspec)\n{\n\tif (fwspec->param_count != 1)\n\t\treturn 0;\n\n\tif (is_fwnode_irqchip(fwspec->fwnode)) {\n\t\tconst char *fwname = fwnode_get_name(fwspec->fwnode);\n\t\treturn fwname && !strncmp(fwname, \"HPET-MSI-\", 9) &&\n\t\t\tsimple_strtol(fwname+9, NULL, 10) == fwspec->param[0];\n\t}\n\treturn 0;\n}\n\nstatic int x86_vector_select(struct irq_domain *d, struct irq_fwspec *fwspec,\n\t\t\t     enum irq_domain_bus_token bus_token)\n{\n\t \n\tif (apic_id_valid(32768))\n\t\treturn 0;\n\n\treturn x86_fwspec_is_ioapic(fwspec) || x86_fwspec_is_hpet(fwspec);\n}\n\nstatic const struct irq_domain_ops x86_vector_domain_ops = {\n\t.select\t\t= x86_vector_select,\n\t.alloc\t\t= x86_vector_alloc_irqs,\n\t.free\t\t= x86_vector_free_irqs,\n\t.activate\t= x86_vector_activate,\n\t.deactivate\t= x86_vector_deactivate,\n#ifdef CONFIG_GENERIC_IRQ_DEBUGFS\n\t.debug_show\t= x86_vector_debug_show,\n#endif\n};\n\nint __init arch_probe_nr_irqs(void)\n{\n\tint nr;\n\n\tif (nr_irqs > (NR_VECTORS * nr_cpu_ids))\n\t\tnr_irqs = NR_VECTORS * nr_cpu_ids;\n\n\tnr = (gsi_top + nr_legacy_irqs()) + 8 * nr_cpu_ids;\n#if defined(CONFIG_PCI_MSI)\n\t \n\tif (gsi_top <= NR_IRQS_LEGACY)\n\t\tnr +=  8 * nr_cpu_ids;\n\telse\n\t\tnr += gsi_top * 16;\n#endif\n\tif (nr < nr_irqs)\n\t\tnr_irqs = nr;\n\n\t \n\treturn legacy_pic->probe();\n}\n\nvoid lapic_assign_legacy_vector(unsigned int irq, bool replace)\n{\n\t \n\tirq_matrix_assign_system(vector_matrix, ISA_IRQ_VECTOR(irq), replace);\n}\n\nvoid __init lapic_update_legacy_vectors(void)\n{\n\tunsigned int i;\n\n\tif (IS_ENABLED(CONFIG_X86_IO_APIC) && nr_ioapics > 0)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < nr_legacy_irqs(); i++) {\n\t\tif (i != PIC_CASCADE_IR)\n\t\t\tlapic_assign_legacy_vector(i, true);\n\t}\n}\n\nvoid __init lapic_assign_system_vectors(void)\n{\n\tunsigned int i, vector;\n\n\tfor_each_set_bit(vector, system_vectors, NR_VECTORS)\n\t\tirq_matrix_assign_system(vector_matrix, vector, false);\n\n\tif (nr_legacy_irqs() > 1)\n\t\tlapic_assign_legacy_vector(PIC_CASCADE_IR, false);\n\n\t \n\tirq_matrix_online(vector_matrix);\n\n\t \n\tfor (i = 0; i < nr_legacy_irqs(); i++) {\n\t\t \n\t\tif (i != PIC_CASCADE_IR)\n\t\t\tirq_matrix_assign(vector_matrix, ISA_IRQ_VECTOR(i));\n\t}\n}\n\nint __init arch_early_irq_init(void)\n{\n\tstruct fwnode_handle *fn;\n\n\tfn = irq_domain_alloc_named_fwnode(\"VECTOR\");\n\tBUG_ON(!fn);\n\tx86_vector_domain = irq_domain_create_tree(fn, &x86_vector_domain_ops,\n\t\t\t\t\t\t   NULL);\n\tBUG_ON(x86_vector_domain == NULL);\n\tirq_set_default_host(x86_vector_domain);\n\n\tBUG_ON(!alloc_cpumask_var(&vector_searchmask, GFP_KERNEL));\n\n\t \n\tvector_matrix = irq_alloc_matrix(NR_VECTORS, FIRST_EXTERNAL_VECTOR,\n\t\t\t\t\t FIRST_SYSTEM_VECTOR);\n\tBUG_ON(!vector_matrix);\n\n\treturn arch_early_ioapic_init();\n}\n\n#ifdef CONFIG_SMP\n\nstatic struct irq_desc *__setup_vector_irq(int vector)\n{\n\tint isairq = vector - ISA_IRQ_VECTOR(0);\n\n\t \n\tif (isairq < 0 || isairq >= nr_legacy_irqs())\n\t\treturn VECTOR_UNUSED;\n\t \n\tif (test_bit(isairq, &io_apic_irqs))\n\t\treturn VECTOR_UNUSED;\n\treturn irq_to_desc(isairq);\n}\n\n \nvoid lapic_online(void)\n{\n\tunsigned int vector;\n\n\tlockdep_assert_held(&vector_lock);\n\n\t \n\tirq_matrix_online(vector_matrix);\n\n\t \n\tfor (vector = 0; vector < NR_VECTORS; vector++)\n\t\tthis_cpu_write(vector_irq[vector], __setup_vector_irq(vector));\n}\n\nstatic void __vector_cleanup(struct vector_cleanup *cl, bool check_irr);\n\nvoid lapic_offline(void)\n{\n\tstruct vector_cleanup *cl = this_cpu_ptr(&vector_cleanup);\n\n\tlock_vector_lock();\n\n\t \n\t__vector_cleanup(cl, false);\n\n\tirq_matrix_offline(vector_matrix);\n\tWARN_ON_ONCE(try_to_del_timer_sync(&cl->timer) < 0);\n\tWARN_ON_ONCE(!hlist_empty(&cl->head));\n\n\tunlock_vector_lock();\n}\n\nstatic int apic_set_affinity(struct irq_data *irqd,\n\t\t\t     const struct cpumask *dest, bool force)\n{\n\tint err;\n\n\tif (WARN_ON_ONCE(!irqd_is_activated(irqd)))\n\t\treturn -EIO;\n\n\traw_spin_lock(&vector_lock);\n\tcpumask_and(vector_searchmask, dest, cpu_online_mask);\n\tif (irqd_affinity_is_managed(irqd))\n\t\terr = assign_managed_vector(irqd, vector_searchmask);\n\telse\n\t\terr = assign_vector_locked(irqd, vector_searchmask);\n\traw_spin_unlock(&vector_lock);\n\treturn err ? err : IRQ_SET_MASK_OK;\n}\n\n#else\n# define apic_set_affinity\tNULL\n#endif\n\nstatic int apic_retrigger_irq(struct irq_data *irqd)\n{\n\tstruct apic_chip_data *apicd = apic_chip_data(irqd);\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&vector_lock, flags);\n\t__apic_send_IPI(apicd->cpu, apicd->vector);\n\traw_spin_unlock_irqrestore(&vector_lock, flags);\n\n\treturn 1;\n}\n\nvoid apic_ack_irq(struct irq_data *irqd)\n{\n\tirq_move_irq(irqd);\n\tapic_eoi();\n}\n\nvoid apic_ack_edge(struct irq_data *irqd)\n{\n\tirq_complete_move(irqd_cfg(irqd));\n\tapic_ack_irq(irqd);\n}\n\nstatic void x86_vector_msi_compose_msg(struct irq_data *data,\n\t\t\t\t       struct msi_msg *msg)\n{\n       __irq_msi_compose_msg(irqd_cfg(data), msg, false);\n}\n\nstatic struct irq_chip lapic_controller = {\n\t.name\t\t\t= \"APIC\",\n\t.irq_ack\t\t= apic_ack_edge,\n\t.irq_set_affinity\t= apic_set_affinity,\n\t.irq_compose_msi_msg\t= x86_vector_msi_compose_msg,\n\t.irq_retrigger\t\t= apic_retrigger_irq,\n};\n\n#ifdef CONFIG_SMP\n\nstatic void free_moved_vector(struct apic_chip_data *apicd)\n{\n\tunsigned int vector = apicd->prev_vector;\n\tunsigned int cpu = apicd->prev_cpu;\n\tbool managed = apicd->is_managed;\n\n\t \n\ttrace_vector_free_moved(apicd->irq, cpu, vector, managed);\n\tirq_matrix_free(vector_matrix, cpu, vector, managed);\n\tper_cpu(vector_irq, cpu)[vector] = VECTOR_UNUSED;\n\thlist_del_init(&apicd->clist);\n\tapicd->prev_vector = 0;\n\tapicd->move_in_progress = 0;\n}\n\nstatic void __vector_cleanup(struct vector_cleanup *cl, bool check_irr)\n{\n\tstruct apic_chip_data *apicd;\n\tstruct hlist_node *tmp;\n\tbool rearm = false;\n\n\tlockdep_assert_held(&vector_lock);\n\n\thlist_for_each_entry_safe(apicd, tmp, &cl->head, clist) {\n\t\tunsigned int irr, vector = apicd->prev_vector;\n\n\t\t \n\t\tirr = check_irr ? apic_read(APIC_IRR + (vector / 32 * 0x10)) : 0;\n\t\tif (irr & (1U << (vector % 32))) {\n\t\t\tpr_warn_once(\"Moved interrupt pending in old target APIC %u\\n\", apicd->irq);\n\t\t\trearm = true;\n\t\t\tcontinue;\n\t\t}\n\t\tfree_moved_vector(apicd);\n\t}\n\n\t \n\tif (rearm)\n\t\tmod_timer(&cl->timer, jiffies + 1);\n}\n\nstatic void vector_cleanup_callback(struct timer_list *tmr)\n{\n\tstruct vector_cleanup *cl = container_of(tmr, typeof(*cl), timer);\n\n\t \n\traw_spin_lock_irq(&vector_lock);\n\t__vector_cleanup(cl, true);\n\traw_spin_unlock_irq(&vector_lock);\n}\n\nstatic void __vector_schedule_cleanup(struct apic_chip_data *apicd)\n{\n\tunsigned int cpu = apicd->prev_cpu;\n\n\traw_spin_lock(&vector_lock);\n\tapicd->move_in_progress = 0;\n\tif (cpu_online(cpu)) {\n\t\tstruct vector_cleanup *cl = per_cpu_ptr(&vector_cleanup, cpu);\n\n\t\thlist_add_head(&apicd->clist, &cl->head);\n\n\t\t \n\t\tif (!timer_pending(&cl->timer)) {\n\t\t\tcl->timer.expires = jiffies + 1;\n\t\t\tadd_timer_on(&cl->timer, cpu);\n\t\t}\n\t} else {\n\t\tapicd->prev_vector = 0;\n\t}\n\traw_spin_unlock(&vector_lock);\n}\n\nvoid vector_schedule_cleanup(struct irq_cfg *cfg)\n{\n\tstruct apic_chip_data *apicd;\n\n\tapicd = container_of(cfg, struct apic_chip_data, hw_irq_cfg);\n\tif (apicd->move_in_progress)\n\t\t__vector_schedule_cleanup(apicd);\n}\n\nvoid irq_complete_move(struct irq_cfg *cfg)\n{\n\tstruct apic_chip_data *apicd;\n\n\tapicd = container_of(cfg, struct apic_chip_data, hw_irq_cfg);\n\tif (likely(!apicd->move_in_progress))\n\t\treturn;\n\n\t \n\tif (apicd->cpu == smp_processor_id())\n\t\t__vector_schedule_cleanup(apicd);\n}\n\n \nvoid irq_force_complete_move(struct irq_desc *desc)\n{\n\tstruct apic_chip_data *apicd;\n\tstruct irq_data *irqd;\n\tunsigned int vector;\n\n\t \n\tirqd = irq_domain_get_irq_data(x86_vector_domain,\n\t\t\t\t       irq_desc_get_irq(desc));\n\tif (!irqd)\n\t\treturn;\n\n\traw_spin_lock(&vector_lock);\n\tapicd = apic_chip_data(irqd);\n\tif (!apicd)\n\t\tgoto unlock;\n\n\t \n\tvector = apicd->prev_vector;\n\tif (!vector)\n\t\tgoto unlock;\n\n\t \n\tif (apicd->move_in_progress) {\n\t\t \n\t\tpr_warn(\"IRQ fixup: irq %d move in progress, old vector %d\\n\",\n\t\t\tirqd->irq, vector);\n\t}\n\tfree_moved_vector(apicd);\nunlock:\n\traw_spin_unlock(&vector_lock);\n}\n\n#ifdef CONFIG_HOTPLUG_CPU\n \nint lapic_can_unplug_cpu(void)\n{\n\tunsigned int rsvd, avl, tomove, cpu = smp_processor_id();\n\tint ret = 0;\n\n\traw_spin_lock(&vector_lock);\n\ttomove = irq_matrix_allocated(vector_matrix);\n\tavl = irq_matrix_available(vector_matrix, true);\n\tif (avl < tomove) {\n\t\tpr_warn(\"CPU %u has %u vectors, %u available. Cannot disable CPU\\n\",\n\t\t\tcpu, tomove, avl);\n\t\tret = -ENOSPC;\n\t\tgoto out;\n\t}\n\trsvd = irq_matrix_reserved(vector_matrix);\n\tif (avl < rsvd) {\n\t\tpr_warn(\"Reserved vectors %u > available %u. IRQ request may fail\\n\",\n\t\t\trsvd, avl);\n\t}\nout:\n\traw_spin_unlock(&vector_lock);\n\treturn ret;\n}\n#endif  \n#endif  \n\nstatic void __init print_APIC_field(int base)\n{\n\tint i;\n\n\tprintk(KERN_DEBUG);\n\n\tfor (i = 0; i < 8; i++)\n\t\tpr_cont(\"%08x\", apic_read(base + i*0x10));\n\n\tpr_cont(\"\\n\");\n}\n\nstatic void __init print_local_APIC(void *dummy)\n{\n\tunsigned int i, v, ver, maxlvt;\n\tu64 icr;\n\n\tpr_debug(\"printing local APIC contents on CPU#%d/%d:\\n\",\n\t\t smp_processor_id(), read_apic_id());\n\tv = apic_read(APIC_ID);\n\tpr_info(\"... APIC ID:      %08x (%01x)\\n\", v, read_apic_id());\n\tv = apic_read(APIC_LVR);\n\tpr_info(\"... APIC VERSION: %08x\\n\", v);\n\tver = GET_APIC_VERSION(v);\n\tmaxlvt = lapic_get_maxlvt();\n\n\tv = apic_read(APIC_TASKPRI);\n\tpr_debug(\"... APIC TASKPRI: %08x (%02x)\\n\", v, v & APIC_TPRI_MASK);\n\n\t \n\tif (APIC_INTEGRATED(ver)) {\n\t\tif (!APIC_XAPIC(ver)) {\n\t\t\tv = apic_read(APIC_ARBPRI);\n\t\t\tpr_debug(\"... APIC ARBPRI: %08x (%02x)\\n\",\n\t\t\t\t v, v & APIC_ARBPRI_MASK);\n\t\t}\n\t\tv = apic_read(APIC_PROCPRI);\n\t\tpr_debug(\"... APIC PROCPRI: %08x\\n\", v);\n\t}\n\n\t \n\tif (!APIC_INTEGRATED(ver) || maxlvt == 3) {\n\t\tv = apic_read(APIC_RRR);\n\t\tpr_debug(\"... APIC RRR: %08x\\n\", v);\n\t}\n\n\tv = apic_read(APIC_LDR);\n\tpr_debug(\"... APIC LDR: %08x\\n\", v);\n\tif (!x2apic_enabled()) {\n\t\tv = apic_read(APIC_DFR);\n\t\tpr_debug(\"... APIC DFR: %08x\\n\", v);\n\t}\n\tv = apic_read(APIC_SPIV);\n\tpr_debug(\"... APIC SPIV: %08x\\n\", v);\n\n\tpr_debug(\"... APIC ISR field:\\n\");\n\tprint_APIC_field(APIC_ISR);\n\tpr_debug(\"... APIC TMR field:\\n\");\n\tprint_APIC_field(APIC_TMR);\n\tpr_debug(\"... APIC IRR field:\\n\");\n\tprint_APIC_field(APIC_IRR);\n\n\t \n\tif (APIC_INTEGRATED(ver)) {\n\t\t \n\t\tif (maxlvt > 3)\n\t\t\tapic_write(APIC_ESR, 0);\n\n\t\tv = apic_read(APIC_ESR);\n\t\tpr_debug(\"... APIC ESR: %08x\\n\", v);\n\t}\n\n\ticr = apic_icr_read();\n\tpr_debug(\"... APIC ICR: %08x\\n\", (u32)icr);\n\tpr_debug(\"... APIC ICR2: %08x\\n\", (u32)(icr >> 32));\n\n\tv = apic_read(APIC_LVTT);\n\tpr_debug(\"... APIC LVTT: %08x\\n\", v);\n\n\tif (maxlvt > 3) {\n\t\t \n\t\tv = apic_read(APIC_LVTPC);\n\t\tpr_debug(\"... APIC LVTPC: %08x\\n\", v);\n\t}\n\tv = apic_read(APIC_LVT0);\n\tpr_debug(\"... APIC LVT0: %08x\\n\", v);\n\tv = apic_read(APIC_LVT1);\n\tpr_debug(\"... APIC LVT1: %08x\\n\", v);\n\n\tif (maxlvt > 2) {\n\t\t \n\t\tv = apic_read(APIC_LVTERR);\n\t\tpr_debug(\"... APIC LVTERR: %08x\\n\", v);\n\t}\n\n\tv = apic_read(APIC_TMICT);\n\tpr_debug(\"... APIC TMICT: %08x\\n\", v);\n\tv = apic_read(APIC_TMCCT);\n\tpr_debug(\"... APIC TMCCT: %08x\\n\", v);\n\tv = apic_read(APIC_TDCR);\n\tpr_debug(\"... APIC TDCR: %08x\\n\", v);\n\n\tif (boot_cpu_has(X86_FEATURE_EXTAPIC)) {\n\t\tv = apic_read(APIC_EFEAT);\n\t\tmaxlvt = (v >> 16) & 0xff;\n\t\tpr_debug(\"... APIC EFEAT: %08x\\n\", v);\n\t\tv = apic_read(APIC_ECTRL);\n\t\tpr_debug(\"... APIC ECTRL: %08x\\n\", v);\n\t\tfor (i = 0; i < maxlvt; i++) {\n\t\t\tv = apic_read(APIC_EILVTn(i));\n\t\t\tpr_debug(\"... APIC EILVT%d: %08x\\n\", i, v);\n\t\t}\n\t}\n\tpr_cont(\"\\n\");\n}\n\nstatic void __init print_local_APICs(int maxcpu)\n{\n\tint cpu;\n\n\tif (!maxcpu)\n\t\treturn;\n\n\tpreempt_disable();\n\tfor_each_online_cpu(cpu) {\n\t\tif (cpu >= maxcpu)\n\t\t\tbreak;\n\t\tsmp_call_function_single(cpu, print_local_APIC, NULL, 1);\n\t}\n\tpreempt_enable();\n}\n\nstatic void __init print_PIC(void)\n{\n\tunsigned int v;\n\tunsigned long flags;\n\n\tif (!nr_legacy_irqs())\n\t\treturn;\n\n\tpr_debug(\"\\nprinting PIC contents\\n\");\n\n\traw_spin_lock_irqsave(&i8259A_lock, flags);\n\n\tv = inb(0xa1) << 8 | inb(0x21);\n\tpr_debug(\"... PIC  IMR: %04x\\n\", v);\n\n\tv = inb(0xa0) << 8 | inb(0x20);\n\tpr_debug(\"... PIC  IRR: %04x\\n\", v);\n\n\toutb(0x0b, 0xa0);\n\toutb(0x0b, 0x20);\n\tv = inb(0xa0) << 8 | inb(0x20);\n\toutb(0x0a, 0xa0);\n\toutb(0x0a, 0x20);\n\n\traw_spin_unlock_irqrestore(&i8259A_lock, flags);\n\n\tpr_debug(\"... PIC  ISR: %04x\\n\", v);\n\n\tv = inb(PIC_ELCR2) << 8 | inb(PIC_ELCR1);\n\tpr_debug(\"... PIC ELCR: %04x\\n\", v);\n}\n\nstatic int show_lapic __initdata = 1;\nstatic __init int setup_show_lapic(char *arg)\n{\n\tint num = -1;\n\n\tif (strcmp(arg, \"all\") == 0) {\n\t\tshow_lapic = CONFIG_NR_CPUS;\n\t} else {\n\t\tget_option(&arg, &num);\n\t\tif (num >= 0)\n\t\t\tshow_lapic = num;\n\t}\n\n\treturn 1;\n}\n__setup(\"show_lapic=\", setup_show_lapic);\n\nstatic int __init print_ICs(void)\n{\n\tif (apic_verbosity == APIC_QUIET)\n\t\treturn 0;\n\n\tprint_PIC();\n\n\t \n\tif (!boot_cpu_has(X86_FEATURE_APIC) && !apic_from_smp_config())\n\t\treturn 0;\n\n\tprint_local_APICs(show_lapic);\n\tprint_IO_APICs();\n\n\treturn 0;\n}\n\nlate_initcall(print_ICs);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}