{
  "module_name": "sev-shared.c",
  "hash_id": "a0fae95d65f4ebf5ac5c65732e390c4ae9eca89d106cbd5955910cae581e06cd",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/sev-shared.c",
  "human_readable_source": "\n \n\n#ifndef __BOOT_COMPRESSED\n#define error(v)\tpr_err(v)\n#define has_cpuflag(f)\tboot_cpu_has(f)\n#else\n#undef WARN\n#define WARN(condition, format...) (!!(condition))\n#endif\n\n \nstruct cpuid_leaf {\n\tu32 fn;\n\tu32 subfn;\n\tu32 eax;\n\tu32 ebx;\n\tu32 ecx;\n\tu32 edx;\n};\n\n \nstruct snp_cpuid_fn {\n\tu32 eax_in;\n\tu32 ecx_in;\n\tu64 xcr0_in;\n\tu64 xss_in;\n\tu32 eax;\n\tu32 ebx;\n\tu32 ecx;\n\tu32 edx;\n\tu64 __reserved;\n} __packed;\n\n \n#define SNP_CPUID_COUNT_MAX 64\n\nstruct snp_cpuid_table {\n\tu32 count;\n\tu32 __reserved1;\n\tu64 __reserved2;\n\tstruct snp_cpuid_fn fn[SNP_CPUID_COUNT_MAX];\n} __packed;\n\n \nstatic u16 ghcb_version __ro_after_init;\n\n \nstatic struct snp_cpuid_table cpuid_table_copy __ro_after_init;\n\n \nstatic u32 cpuid_std_range_max __ro_after_init;\nstatic u32 cpuid_hyp_range_max __ro_after_init;\nstatic u32 cpuid_ext_range_max __ro_after_init;\n\nstatic bool __init sev_es_check_cpu_features(void)\n{\n\tif (!has_cpuflag(X86_FEATURE_RDRAND)) {\n\t\terror(\"RDRAND instruction not supported - no trusted source of randomness available\\n\");\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void __noreturn sev_es_terminate(unsigned int set, unsigned int reason)\n{\n\tu64 val = GHCB_MSR_TERM_REQ;\n\n\t \n\tval |= GHCB_SEV_TERM_REASON(set, reason);\n\n\t \n\tsev_es_wr_ghcb_msr(val);\n\tVMGEXIT();\n\n\twhile (true)\n\t\tasm volatile(\"hlt\\n\" : : : \"memory\");\n}\n\n \nstatic u64 get_hv_features(void)\n{\n\tu64 val;\n\n\tif (ghcb_version < 2)\n\t\treturn 0;\n\n\tsev_es_wr_ghcb_msr(GHCB_MSR_HV_FT_REQ);\n\tVMGEXIT();\n\n\tval = sev_es_rd_ghcb_msr();\n\tif (GHCB_RESP_CODE(val) != GHCB_MSR_HV_FT_RESP)\n\t\treturn 0;\n\n\treturn GHCB_MSR_HV_FT_RESP_VAL(val);\n}\n\nstatic void snp_register_ghcb_early(unsigned long paddr)\n{\n\tunsigned long pfn = paddr >> PAGE_SHIFT;\n\tu64 val;\n\n\tsev_es_wr_ghcb_msr(GHCB_MSR_REG_GPA_REQ_VAL(pfn));\n\tVMGEXIT();\n\n\tval = sev_es_rd_ghcb_msr();\n\n\t \n\tif ((GHCB_RESP_CODE(val) != GHCB_MSR_REG_GPA_RESP) ||\n\t    (GHCB_MSR_REG_GPA_RESP_VAL(val) != pfn))\n\t\tsev_es_terminate(SEV_TERM_SET_LINUX, GHCB_TERM_REGISTER);\n}\n\nstatic bool sev_es_negotiate_protocol(void)\n{\n\tu64 val;\n\n\t \n\tsev_es_wr_ghcb_msr(GHCB_MSR_SEV_INFO_REQ);\n\tVMGEXIT();\n\tval = sev_es_rd_ghcb_msr();\n\n\tif (GHCB_MSR_INFO(val) != GHCB_MSR_SEV_INFO_RESP)\n\t\treturn false;\n\n\tif (GHCB_MSR_PROTO_MAX(val) < GHCB_PROTOCOL_MIN ||\n\t    GHCB_MSR_PROTO_MIN(val) > GHCB_PROTOCOL_MAX)\n\t\treturn false;\n\n\tghcb_version = min_t(size_t, GHCB_MSR_PROTO_MAX(val), GHCB_PROTOCOL_MAX);\n\n\treturn true;\n}\n\nstatic __always_inline void vc_ghcb_invalidate(struct ghcb *ghcb)\n{\n\tghcb->save.sw_exit_code = 0;\n\t__builtin_memset(ghcb->save.valid_bitmap, 0, sizeof(ghcb->save.valid_bitmap));\n}\n\nstatic bool vc_decoding_needed(unsigned long exit_code)\n{\n\t \n\treturn !(exit_code >= SVM_EXIT_EXCP_BASE &&\n\t\t exit_code <= SVM_EXIT_LAST_EXCP);\n}\n\nstatic enum es_result vc_init_em_ctxt(struct es_em_ctxt *ctxt,\n\t\t\t\t      struct pt_regs *regs,\n\t\t\t\t      unsigned long exit_code)\n{\n\tenum es_result ret = ES_OK;\n\n\tmemset(ctxt, 0, sizeof(*ctxt));\n\tctxt->regs = regs;\n\n\tif (vc_decoding_needed(exit_code))\n\t\tret = vc_decode_insn(ctxt);\n\n\treturn ret;\n}\n\nstatic void vc_finish_insn(struct es_em_ctxt *ctxt)\n{\n\tctxt->regs->ip += ctxt->insn.length;\n}\n\nstatic enum es_result verify_exception_info(struct ghcb *ghcb, struct es_em_ctxt *ctxt)\n{\n\tu32 ret;\n\n\tret = ghcb->save.sw_exit_info_1 & GENMASK_ULL(31, 0);\n\tif (!ret)\n\t\treturn ES_OK;\n\n\tif (ret == 1) {\n\t\tu64 info = ghcb->save.sw_exit_info_2;\n\t\tunsigned long v = info & SVM_EVTINJ_VEC_MASK;\n\n\t\t \n\t\tif ((info & SVM_EVTINJ_VALID) &&\n\t\t    ((v == X86_TRAP_GP) || (v == X86_TRAP_UD)) &&\n\t\t    ((info & SVM_EVTINJ_TYPE_MASK) == SVM_EVTINJ_TYPE_EXEPT)) {\n\t\t\tctxt->fi.vector = v;\n\n\t\t\tif (info & SVM_EVTINJ_VALID_ERR)\n\t\t\t\tctxt->fi.error_code = info >> 32;\n\n\t\t\treturn ES_EXCEPTION;\n\t\t}\n\t}\n\n\treturn ES_VMM_ERROR;\n}\n\nstatic enum es_result sev_es_ghcb_hv_call(struct ghcb *ghcb,\n\t\t\t\t\t  struct es_em_ctxt *ctxt,\n\t\t\t\t\t  u64 exit_code, u64 exit_info_1,\n\t\t\t\t\t  u64 exit_info_2)\n{\n\t \n\tghcb->protocol_version = ghcb_version;\n\tghcb->ghcb_usage       = GHCB_DEFAULT_USAGE;\n\n\tghcb_set_sw_exit_code(ghcb, exit_code);\n\tghcb_set_sw_exit_info_1(ghcb, exit_info_1);\n\tghcb_set_sw_exit_info_2(ghcb, exit_info_2);\n\n\tsev_es_wr_ghcb_msr(__pa(ghcb));\n\tVMGEXIT();\n\n\treturn verify_exception_info(ghcb, ctxt);\n}\n\nstatic int __sev_cpuid_hv(u32 fn, int reg_idx, u32 *reg)\n{\n\tu64 val;\n\n\tsev_es_wr_ghcb_msr(GHCB_CPUID_REQ(fn, reg_idx));\n\tVMGEXIT();\n\tval = sev_es_rd_ghcb_msr();\n\tif (GHCB_RESP_CODE(val) != GHCB_MSR_CPUID_RESP)\n\t\treturn -EIO;\n\n\t*reg = (val >> 32);\n\n\treturn 0;\n}\n\nstatic int __sev_cpuid_hv_msr(struct cpuid_leaf *leaf)\n{\n\tint ret;\n\n\t \n\tif (cpuid_function_is_indexed(leaf->fn) && leaf->subfn)\n\t\treturn -EINVAL;\n\n\tret =         __sev_cpuid_hv(leaf->fn, GHCB_CPUID_REQ_EAX, &leaf->eax);\n\tret = ret ? : __sev_cpuid_hv(leaf->fn, GHCB_CPUID_REQ_EBX, &leaf->ebx);\n\tret = ret ? : __sev_cpuid_hv(leaf->fn, GHCB_CPUID_REQ_ECX, &leaf->ecx);\n\tret = ret ? : __sev_cpuid_hv(leaf->fn, GHCB_CPUID_REQ_EDX, &leaf->edx);\n\n\treturn ret;\n}\n\nstatic int __sev_cpuid_hv_ghcb(struct ghcb *ghcb, struct es_em_ctxt *ctxt, struct cpuid_leaf *leaf)\n{\n\tu32 cr4 = native_read_cr4();\n\tint ret;\n\n\tghcb_set_rax(ghcb, leaf->fn);\n\tghcb_set_rcx(ghcb, leaf->subfn);\n\n\tif (cr4 & X86_CR4_OSXSAVE)\n\t\t \n\t\tghcb_set_xcr0(ghcb, xgetbv(XCR_XFEATURE_ENABLED_MASK));\n\telse\n\t\t \n\t\tghcb_set_xcr0(ghcb, 1);\n\n\tret = sev_es_ghcb_hv_call(ghcb, ctxt, SVM_EXIT_CPUID, 0, 0);\n\tif (ret != ES_OK)\n\t\treturn ret;\n\n\tif (!(ghcb_rax_is_valid(ghcb) &&\n\t      ghcb_rbx_is_valid(ghcb) &&\n\t      ghcb_rcx_is_valid(ghcb) &&\n\t      ghcb_rdx_is_valid(ghcb)))\n\t\treturn ES_VMM_ERROR;\n\n\tleaf->eax = ghcb->save.rax;\n\tleaf->ebx = ghcb->save.rbx;\n\tleaf->ecx = ghcb->save.rcx;\n\tleaf->edx = ghcb->save.rdx;\n\n\treturn ES_OK;\n}\n\nstatic int sev_cpuid_hv(struct ghcb *ghcb, struct es_em_ctxt *ctxt, struct cpuid_leaf *leaf)\n{\n\treturn ghcb ? __sev_cpuid_hv_ghcb(ghcb, ctxt, leaf)\n\t\t    : __sev_cpuid_hv_msr(leaf);\n}\n\n \nstatic const struct snp_cpuid_table *snp_cpuid_get_table(void)\n{\n\tvoid *ptr;\n\n\tasm (\"lea cpuid_table_copy(%%rip), %0\"\n\t     : \"=r\" (ptr)\n\t     : \"p\" (&cpuid_table_copy));\n\n\treturn ptr;\n}\n\n \nstatic u32 snp_cpuid_calc_xsave_size(u64 xfeatures_en, bool compacted)\n{\n\tconst struct snp_cpuid_table *cpuid_table = snp_cpuid_get_table();\n\tu64 xfeatures_found = 0;\n\tu32 xsave_size = 0x240;\n\tint i;\n\n\tfor (i = 0; i < cpuid_table->count; i++) {\n\t\tconst struct snp_cpuid_fn *e = &cpuid_table->fn[i];\n\n\t\tif (!(e->eax_in == 0xD && e->ecx_in > 1 && e->ecx_in < 64))\n\t\t\tcontinue;\n\t\tif (!(xfeatures_en & (BIT_ULL(e->ecx_in))))\n\t\t\tcontinue;\n\t\tif (xfeatures_found & (BIT_ULL(e->ecx_in)))\n\t\t\tcontinue;\n\n\t\txfeatures_found |= (BIT_ULL(e->ecx_in));\n\n\t\tif (compacted)\n\t\t\txsave_size += e->eax;\n\t\telse\n\t\t\txsave_size = max(xsave_size, e->eax + e->ebx);\n\t}\n\n\t \n\tif (xfeatures_found != (xfeatures_en & GENMASK_ULL(63, 2)))\n\t\treturn 0;\n\n\treturn xsave_size;\n}\n\nstatic bool\nsnp_cpuid_get_validated_func(struct cpuid_leaf *leaf)\n{\n\tconst struct snp_cpuid_table *cpuid_table = snp_cpuid_get_table();\n\tint i;\n\n\tfor (i = 0; i < cpuid_table->count; i++) {\n\t\tconst struct snp_cpuid_fn *e = &cpuid_table->fn[i];\n\n\t\tif (e->eax_in != leaf->fn)\n\t\t\tcontinue;\n\n\t\tif (cpuid_function_is_indexed(leaf->fn) && e->ecx_in != leaf->subfn)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (e->eax_in == 0xD && (e->ecx_in == 0 || e->ecx_in == 1))\n\t\t\tif (!(e->xcr0_in == 1 || e->xcr0_in == 3) || e->xss_in)\n\t\t\t\tcontinue;\n\n\t\tleaf->eax = e->eax;\n\t\tleaf->ebx = e->ebx;\n\t\tleaf->ecx = e->ecx;\n\t\tleaf->edx = e->edx;\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void snp_cpuid_hv(struct ghcb *ghcb, struct es_em_ctxt *ctxt, struct cpuid_leaf *leaf)\n{\n\tif (sev_cpuid_hv(ghcb, ctxt, leaf))\n\t\tsev_es_terminate(SEV_TERM_SET_LINUX, GHCB_TERM_CPUID_HV);\n}\n\nstatic int snp_cpuid_postprocess(struct ghcb *ghcb, struct es_em_ctxt *ctxt,\n\t\t\t\t struct cpuid_leaf *leaf)\n{\n\tstruct cpuid_leaf leaf_hv = *leaf;\n\n\tswitch (leaf->fn) {\n\tcase 0x1:\n\t\tsnp_cpuid_hv(ghcb, ctxt, &leaf_hv);\n\n\t\t \n\t\tleaf->ebx = (leaf_hv.ebx & GENMASK(31, 24)) | (leaf->ebx & GENMASK(23, 0));\n\t\t \n\t\tleaf->edx = (leaf_hv.edx & BIT(9)) | (leaf->edx & ~BIT(9));\n\n\t\t \n\t\tif (native_read_cr4() & X86_CR4_OSXSAVE)\n\t\t\tleaf->ecx |= BIT(27);\n\t\tbreak;\n\tcase 0x7:\n\t\t \n\t\tleaf->ecx &= ~BIT(4);\n\t\tif (native_read_cr4() & X86_CR4_PKE)\n\t\t\tleaf->ecx |= BIT(4);\n\t\tbreak;\n\tcase 0xB:\n\t\tleaf_hv.subfn = 0;\n\t\tsnp_cpuid_hv(ghcb, ctxt, &leaf_hv);\n\n\t\t \n\t\tleaf->edx = leaf_hv.edx;\n\t\tbreak;\n\tcase 0xD: {\n\t\tbool compacted = false;\n\t\tu64 xcr0 = 1, xss = 0;\n\t\tu32 xsave_size;\n\n\t\tif (leaf->subfn != 0 && leaf->subfn != 1)\n\t\t\treturn 0;\n\n\t\tif (native_read_cr4() & X86_CR4_OSXSAVE)\n\t\t\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\t\tif (leaf->subfn == 1) {\n\t\t\t \n\t\t\tif (leaf->eax & BIT(3)) {\n\t\t\t\tunsigned long lo, hi;\n\n\t\t\t\tasm volatile(\"rdmsr\" : \"=a\" (lo), \"=d\" (hi)\n\t\t\t\t\t\t     : \"c\" (MSR_IA32_XSS));\n\t\t\t\txss = (hi << 32) | lo;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (!(leaf->eax & (BIT(1) | BIT(3))))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tcompacted = true;\n\t\t}\n\n\t\txsave_size = snp_cpuid_calc_xsave_size(xcr0 | xss, compacted);\n\t\tif (!xsave_size)\n\t\t\treturn -EINVAL;\n\n\t\tleaf->ebx = xsave_size;\n\t\t}\n\t\tbreak;\n\tcase 0x8000001E:\n\t\tsnp_cpuid_hv(ghcb, ctxt, &leaf_hv);\n\n\t\t \n\t\tleaf->eax = leaf_hv.eax;\n\t\t \n\t\tleaf->ebx = (leaf->ebx & GENMASK(31, 8)) | (leaf_hv.ebx & GENMASK(7, 0));\n\t\t \n\t\tleaf->ecx = (leaf->ecx & GENMASK(31, 8)) | (leaf_hv.ecx & GENMASK(7, 0));\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int snp_cpuid(struct ghcb *ghcb, struct es_em_ctxt *ctxt, struct cpuid_leaf *leaf)\n{\n\tconst struct snp_cpuid_table *cpuid_table = snp_cpuid_get_table();\n\n\tif (!cpuid_table->count)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!snp_cpuid_get_validated_func(leaf)) {\n\t\t \n\t\tleaf->eax = leaf->ebx = leaf->ecx = leaf->edx = 0;\n\n\t\t \n\t\tif (!(leaf->fn <= cpuid_std_range_max ||\n\t\t      (leaf->fn >= 0x40000000 && leaf->fn <= cpuid_hyp_range_max) ||\n\t\t      (leaf->fn >= 0x80000000 && leaf->fn <= cpuid_ext_range_max)))\n\t\t\treturn 0;\n\t}\n\n\treturn snp_cpuid_postprocess(ghcb, ctxt, leaf);\n}\n\n \nvoid __init do_vc_no_ghcb(struct pt_regs *regs, unsigned long exit_code)\n{\n\tunsigned int subfn = lower_bits(regs->cx, 32);\n\tunsigned int fn = lower_bits(regs->ax, 32);\n\tstruct cpuid_leaf leaf;\n\tint ret;\n\n\t \n\tif (exit_code != SVM_EXIT_CPUID)\n\t\tgoto fail;\n\n\tleaf.fn = fn;\n\tleaf.subfn = subfn;\n\n\tret = snp_cpuid(NULL, NULL, &leaf);\n\tif (!ret)\n\t\tgoto cpuid_done;\n\n\tif (ret != -EOPNOTSUPP)\n\t\tgoto fail;\n\n\tif (__sev_cpuid_hv_msr(&leaf))\n\t\tgoto fail;\n\ncpuid_done:\n\tregs->ax = leaf.eax;\n\tregs->bx = leaf.ebx;\n\tregs->cx = leaf.ecx;\n\tregs->dx = leaf.edx;\n\n\t \n\n\tif (fn == 0x80000000 && (regs->ax < 0x8000001f))\n\t\t \n\t\tgoto fail;\n\telse if ((fn == 0x8000001f && !(regs->ax & BIT(1))))\n\t\t \n\t\tgoto fail;\n\n\t \n\tregs->ip += 2;\n\n\treturn;\n\nfail:\n\t \n\tsev_es_terminate(SEV_TERM_SET_GEN, GHCB_SEV_ES_GEN_REQ);\n}\n\nstatic enum es_result vc_insn_string_check(struct es_em_ctxt *ctxt,\n\t\t\t\t\t   unsigned long address,\n\t\t\t\t\t   bool write)\n{\n\tif (user_mode(ctxt->regs) && fault_in_kernel_space(address)) {\n\t\tctxt->fi.vector     = X86_TRAP_PF;\n\t\tctxt->fi.error_code = X86_PF_USER;\n\t\tctxt->fi.cr2        = address;\n\t\tif (write)\n\t\t\tctxt->fi.error_code |= X86_PF_WRITE;\n\n\t\treturn ES_EXCEPTION;\n\t}\n\n\treturn ES_OK;\n}\n\nstatic enum es_result vc_insn_string_read(struct es_em_ctxt *ctxt,\n\t\t\t\t\t  void *src, char *buf,\n\t\t\t\t\t  unsigned int data_size,\n\t\t\t\t\t  unsigned int count,\n\t\t\t\t\t  bool backwards)\n{\n\tint i, b = backwards ? -1 : 1;\n\tunsigned long address = (unsigned long)src;\n\tenum es_result ret;\n\n\tret = vc_insn_string_check(ctxt, address, false);\n\tif (ret != ES_OK)\n\t\treturn ret;\n\n\tfor (i = 0; i < count; i++) {\n\t\tvoid *s = src + (i * data_size * b);\n\t\tchar *d = buf + (i * data_size);\n\n\t\tret = vc_read_mem(ctxt, s, d, data_size);\n\t\tif (ret != ES_OK)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic enum es_result vc_insn_string_write(struct es_em_ctxt *ctxt,\n\t\t\t\t\t   void *dst, char *buf,\n\t\t\t\t\t   unsigned int data_size,\n\t\t\t\t\t   unsigned int count,\n\t\t\t\t\t   bool backwards)\n{\n\tint i, s = backwards ? -1 : 1;\n\tunsigned long address = (unsigned long)dst;\n\tenum es_result ret;\n\n\tret = vc_insn_string_check(ctxt, address, true);\n\tif (ret != ES_OK)\n\t\treturn ret;\n\n\tfor (i = 0; i < count; i++) {\n\t\tvoid *d = dst + (i * data_size * s);\n\t\tchar *b = buf + (i * data_size);\n\n\t\tret = vc_write_mem(ctxt, d, b, data_size);\n\t\tif (ret != ES_OK)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n#define IOIO_TYPE_STR  BIT(2)\n#define IOIO_TYPE_IN   1\n#define IOIO_TYPE_INS  (IOIO_TYPE_IN | IOIO_TYPE_STR)\n#define IOIO_TYPE_OUT  0\n#define IOIO_TYPE_OUTS (IOIO_TYPE_OUT | IOIO_TYPE_STR)\n\n#define IOIO_REP       BIT(3)\n\n#define IOIO_ADDR_64   BIT(9)\n#define IOIO_ADDR_32   BIT(8)\n#define IOIO_ADDR_16   BIT(7)\n\n#define IOIO_DATA_32   BIT(6)\n#define IOIO_DATA_16   BIT(5)\n#define IOIO_DATA_8    BIT(4)\n\n#define IOIO_SEG_ES    (0 << 10)\n#define IOIO_SEG_DS    (3 << 10)\n\nstatic enum es_result vc_ioio_exitinfo(struct es_em_ctxt *ctxt, u64 *exitinfo)\n{\n\tstruct insn *insn = &ctxt->insn;\n\tsize_t size;\n\tu64 port;\n\n\t*exitinfo = 0;\n\n\tswitch (insn->opcode.bytes[0]) {\n\t \n\tcase 0x6c:\n\tcase 0x6d:\n\t\t*exitinfo |= IOIO_TYPE_INS;\n\t\t*exitinfo |= IOIO_SEG_ES;\n\t\tport\t   = ctxt->regs->dx & 0xffff;\n\t\tbreak;\n\n\t \n\tcase 0x6e:\n\tcase 0x6f:\n\t\t*exitinfo |= IOIO_TYPE_OUTS;\n\t\t*exitinfo |= IOIO_SEG_DS;\n\t\tport\t   = ctxt->regs->dx & 0xffff;\n\t\tbreak;\n\n\t \n\tcase 0xe4:\n\tcase 0xe5:\n\t\t*exitinfo |= IOIO_TYPE_IN;\n\t\tport\t   = (u8)insn->immediate.value & 0xffff;\n\t\tbreak;\n\n\t \n\tcase 0xe6:\n\tcase 0xe7:\n\t\t*exitinfo |= IOIO_TYPE_OUT;\n\t\tport\t   = (u8)insn->immediate.value & 0xffff;\n\t\tbreak;\n\n\t \n\tcase 0xec:\n\tcase 0xed:\n\t\t*exitinfo |= IOIO_TYPE_IN;\n\t\tport\t   = ctxt->regs->dx & 0xffff;\n\t\tbreak;\n\n\t \n\tcase 0xee:\n\tcase 0xef:\n\t\t*exitinfo |= IOIO_TYPE_OUT;\n\t\tport\t   = ctxt->regs->dx & 0xffff;\n\t\tbreak;\n\n\tdefault:\n\t\treturn ES_DECODE_FAILED;\n\t}\n\n\t*exitinfo |= port << 16;\n\n\tswitch (insn->opcode.bytes[0]) {\n\tcase 0x6c:\n\tcase 0x6e:\n\tcase 0xe4:\n\tcase 0xe6:\n\tcase 0xec:\n\tcase 0xee:\n\t\t \n\t\t*exitinfo |= IOIO_DATA_8;\n\t\tsize       = 1;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\t*exitinfo |= (insn->opnd_bytes == 2) ? IOIO_DATA_16\n\t\t\t\t\t\t     : IOIO_DATA_32;\n\t\tsize       = (insn->opnd_bytes == 2) ? 2 : 4;\n\t}\n\n\tswitch (insn->addr_bytes) {\n\tcase 2:\n\t\t*exitinfo |= IOIO_ADDR_16;\n\t\tbreak;\n\tcase 4:\n\t\t*exitinfo |= IOIO_ADDR_32;\n\t\tbreak;\n\tcase 8:\n\t\t*exitinfo |= IOIO_ADDR_64;\n\t\tbreak;\n\t}\n\n\tif (insn_has_rep_prefix(insn))\n\t\t*exitinfo |= IOIO_REP;\n\n\treturn vc_ioio_check(ctxt, (u16)port, size);\n}\n\nstatic enum es_result vc_handle_ioio(struct ghcb *ghcb, struct es_em_ctxt *ctxt)\n{\n\tstruct pt_regs *regs = ctxt->regs;\n\tu64 exit_info_1, exit_info_2;\n\tenum es_result ret;\n\n\tret = vc_ioio_exitinfo(ctxt, &exit_info_1);\n\tif (ret != ES_OK)\n\t\treturn ret;\n\n\tif (exit_info_1 & IOIO_TYPE_STR) {\n\n\t\t \n\n\t\tbool df = ((regs->flags & X86_EFLAGS_DF) == X86_EFLAGS_DF);\n\t\tunsigned int io_bytes, exit_bytes;\n\t\tunsigned int ghcb_count, op_count;\n\t\tunsigned long es_base;\n\t\tu64 sw_scratch;\n\n\t\t \n\t\tio_bytes   = (exit_info_1 >> 4) & 0x7;\n\t\tghcb_count = sizeof(ghcb->shared_buffer) / io_bytes;\n\n\t\top_count    = (exit_info_1 & IOIO_REP) ? regs->cx : 1;\n\t\texit_info_2 = min(op_count, ghcb_count);\n\t\texit_bytes  = exit_info_2 * io_bytes;\n\n\t\tes_base = insn_get_seg_base(ctxt->regs, INAT_SEG_REG_ES);\n\n\t\t \n\t\tif (!(exit_info_1 & IOIO_TYPE_IN)) {\n\t\t\tret = vc_insn_string_read(ctxt,\n\t\t\t\t\t       (void *)(es_base + regs->si),\n\t\t\t\t\t       ghcb->shared_buffer, io_bytes,\n\t\t\t\t\t       exit_info_2, df);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\t \n\t\tsw_scratch = __pa(ghcb) + offsetof(struct ghcb, shared_buffer);\n\t\tghcb_set_sw_scratch(ghcb, sw_scratch);\n\t\tret = sev_es_ghcb_hv_call(ghcb, ctxt, SVM_EXIT_IOIO,\n\t\t\t\t\t  exit_info_1, exit_info_2);\n\t\tif (ret != ES_OK)\n\t\t\treturn ret;\n\n\t\t \n\t\tif (exit_info_1 & IOIO_TYPE_IN) {\n\t\t\tret = vc_insn_string_write(ctxt,\n\t\t\t\t\t\t   (void *)(es_base + regs->di),\n\t\t\t\t\t\t   ghcb->shared_buffer, io_bytes,\n\t\t\t\t\t\t   exit_info_2, df);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tif (df)\n\t\t\t\tregs->di -= exit_bytes;\n\t\t\telse\n\t\t\t\tregs->di += exit_bytes;\n\t\t} else {\n\t\t\tif (df)\n\t\t\t\tregs->si -= exit_bytes;\n\t\t\telse\n\t\t\t\tregs->si += exit_bytes;\n\t\t}\n\n\t\tif (exit_info_1 & IOIO_REP)\n\t\t\tregs->cx -= exit_info_2;\n\n\t\tret = regs->cx ? ES_RETRY : ES_OK;\n\n\t} else {\n\n\t\t \n\n\t\tint bits = (exit_info_1 & 0x70) >> 1;\n\t\tu64 rax = 0;\n\n\t\tif (!(exit_info_1 & IOIO_TYPE_IN))\n\t\t\trax = lower_bits(regs->ax, bits);\n\n\t\tghcb_set_rax(ghcb, rax);\n\n\t\tret = sev_es_ghcb_hv_call(ghcb, ctxt, SVM_EXIT_IOIO, exit_info_1, 0);\n\t\tif (ret != ES_OK)\n\t\t\treturn ret;\n\n\t\tif (exit_info_1 & IOIO_TYPE_IN) {\n\t\t\tif (!ghcb_rax_is_valid(ghcb))\n\t\t\t\treturn ES_VMM_ERROR;\n\t\t\tregs->ax = lower_bits(ghcb->save.rax, bits);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int vc_handle_cpuid_snp(struct ghcb *ghcb, struct es_em_ctxt *ctxt)\n{\n\tstruct pt_regs *regs = ctxt->regs;\n\tstruct cpuid_leaf leaf;\n\tint ret;\n\n\tleaf.fn = regs->ax;\n\tleaf.subfn = regs->cx;\n\tret = snp_cpuid(ghcb, ctxt, &leaf);\n\tif (!ret) {\n\t\tregs->ax = leaf.eax;\n\t\tregs->bx = leaf.ebx;\n\t\tregs->cx = leaf.ecx;\n\t\tregs->dx = leaf.edx;\n\t}\n\n\treturn ret;\n}\n\nstatic enum es_result vc_handle_cpuid(struct ghcb *ghcb,\n\t\t\t\t      struct es_em_ctxt *ctxt)\n{\n\tstruct pt_regs *regs = ctxt->regs;\n\tu32 cr4 = native_read_cr4();\n\tenum es_result ret;\n\tint snp_cpuid_ret;\n\n\tsnp_cpuid_ret = vc_handle_cpuid_snp(ghcb, ctxt);\n\tif (!snp_cpuid_ret)\n\t\treturn ES_OK;\n\tif (snp_cpuid_ret != -EOPNOTSUPP)\n\t\treturn ES_VMM_ERROR;\n\n\tghcb_set_rax(ghcb, regs->ax);\n\tghcb_set_rcx(ghcb, regs->cx);\n\n\tif (cr4 & X86_CR4_OSXSAVE)\n\t\t \n\t\tghcb_set_xcr0(ghcb, xgetbv(XCR_XFEATURE_ENABLED_MASK));\n\telse\n\t\t \n\t\tghcb_set_xcr0(ghcb, 1);\n\n\tret = sev_es_ghcb_hv_call(ghcb, ctxt, SVM_EXIT_CPUID, 0, 0);\n\tif (ret != ES_OK)\n\t\treturn ret;\n\n\tif (!(ghcb_rax_is_valid(ghcb) &&\n\t      ghcb_rbx_is_valid(ghcb) &&\n\t      ghcb_rcx_is_valid(ghcb) &&\n\t      ghcb_rdx_is_valid(ghcb)))\n\t\treturn ES_VMM_ERROR;\n\n\tregs->ax = ghcb->save.rax;\n\tregs->bx = ghcb->save.rbx;\n\tregs->cx = ghcb->save.rcx;\n\tregs->dx = ghcb->save.rdx;\n\n\treturn ES_OK;\n}\n\nstatic enum es_result vc_handle_rdtsc(struct ghcb *ghcb,\n\t\t\t\t      struct es_em_ctxt *ctxt,\n\t\t\t\t      unsigned long exit_code)\n{\n\tbool rdtscp = (exit_code == SVM_EXIT_RDTSCP);\n\tenum es_result ret;\n\n\tret = sev_es_ghcb_hv_call(ghcb, ctxt, exit_code, 0, 0);\n\tif (ret != ES_OK)\n\t\treturn ret;\n\n\tif (!(ghcb_rax_is_valid(ghcb) && ghcb_rdx_is_valid(ghcb) &&\n\t     (!rdtscp || ghcb_rcx_is_valid(ghcb))))\n\t\treturn ES_VMM_ERROR;\n\n\tctxt->regs->ax = ghcb->save.rax;\n\tctxt->regs->dx = ghcb->save.rdx;\n\tif (rdtscp)\n\t\tctxt->regs->cx = ghcb->save.rcx;\n\n\treturn ES_OK;\n}\n\nstruct cc_setup_data {\n\tstruct setup_data header;\n\tu32 cc_blob_address;\n};\n\n \nstatic struct cc_blob_sev_info *find_cc_blob_setup_data(struct boot_params *bp)\n{\n\tstruct cc_setup_data *sd = NULL;\n\tstruct setup_data *hdr;\n\n\thdr = (struct setup_data *)bp->hdr.setup_data;\n\n\twhile (hdr) {\n\t\tif (hdr->type == SETUP_CC_BLOB) {\n\t\t\tsd = (struct cc_setup_data *)hdr;\n\t\t\treturn (struct cc_blob_sev_info *)(unsigned long)sd->cc_blob_address;\n\t\t}\n\t\thdr = (struct setup_data *)hdr->next;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic void __init setup_cpuid_table(const struct cc_blob_sev_info *cc_info)\n{\n\tconst struct snp_cpuid_table *cpuid_table_fw, *cpuid_table;\n\tint i;\n\n\tif (!cc_info || !cc_info->cpuid_phys || cc_info->cpuid_len < PAGE_SIZE)\n\t\tsev_es_terminate(SEV_TERM_SET_LINUX, GHCB_TERM_CPUID);\n\n\tcpuid_table_fw = (const struct snp_cpuid_table *)cc_info->cpuid_phys;\n\tif (!cpuid_table_fw->count || cpuid_table_fw->count > SNP_CPUID_COUNT_MAX)\n\t\tsev_es_terminate(SEV_TERM_SET_LINUX, GHCB_TERM_CPUID);\n\n\tcpuid_table = snp_cpuid_get_table();\n\tmemcpy((void *)cpuid_table, cpuid_table_fw, sizeof(*cpuid_table));\n\n\t \n\tfor (i = 0; i < cpuid_table->count; i++) {\n\t\tconst struct snp_cpuid_fn *fn = &cpuid_table->fn[i];\n\n\t\tif (fn->eax_in == 0x0)\n\t\t\tcpuid_std_range_max = fn->eax;\n\t\telse if (fn->eax_in == 0x40000000)\n\t\t\tcpuid_hyp_range_max = fn->eax;\n\t\telse if (fn->eax_in == 0x80000000)\n\t\t\tcpuid_ext_range_max = fn->eax;\n\t}\n}\n\nstatic void pvalidate_pages(struct snp_psc_desc *desc)\n{\n\tstruct psc_entry *e;\n\tunsigned long vaddr;\n\tunsigned int size;\n\tunsigned int i;\n\tbool validate;\n\tint rc;\n\n\tfor (i = 0; i <= desc->hdr.end_entry; i++) {\n\t\te = &desc->entries[i];\n\n\t\tvaddr = (unsigned long)pfn_to_kaddr(e->gfn);\n\t\tsize = e->pagesize ? RMP_PG_SIZE_2M : RMP_PG_SIZE_4K;\n\t\tvalidate = e->operation == SNP_PAGE_STATE_PRIVATE;\n\n\t\trc = pvalidate(vaddr, size, validate);\n\t\tif (rc == PVALIDATE_FAIL_SIZEMISMATCH && size == RMP_PG_SIZE_2M) {\n\t\t\tunsigned long vaddr_end = vaddr + PMD_SIZE;\n\n\t\t\tfor (; vaddr < vaddr_end; vaddr += PAGE_SIZE) {\n\t\t\t\trc = pvalidate(vaddr, RMP_PG_SIZE_4K, validate);\n\t\t\t\tif (rc)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (rc) {\n\t\t\tWARN(1, \"Failed to validate address 0x%lx ret %d\", vaddr, rc);\n\t\t\tsev_es_terminate(SEV_TERM_SET_LINUX, GHCB_TERM_PVALIDATE);\n\t\t}\n\t}\n}\n\nstatic int vmgexit_psc(struct ghcb *ghcb, struct snp_psc_desc *desc)\n{\n\tint cur_entry, end_entry, ret = 0;\n\tstruct snp_psc_desc *data;\n\tstruct es_em_ctxt ctxt;\n\n\tvc_ghcb_invalidate(ghcb);\n\n\t \n\tdata = (struct snp_psc_desc *)ghcb->shared_buffer;\n\tmemcpy(ghcb->shared_buffer, desc, min_t(int, GHCB_SHARED_BUF_SIZE, sizeof(*desc)));\n\n\t \n\tcur_entry = data->hdr.cur_entry;\n\tend_entry = data->hdr.end_entry;\n\n\twhile (data->hdr.cur_entry <= data->hdr.end_entry) {\n\t\tghcb_set_sw_scratch(ghcb, (u64)__pa(data));\n\n\t\t \n\t\tret = sev_es_ghcb_hv_call(ghcb, &ctxt, SVM_VMGEXIT_PSC, 0, 0);\n\n\t\t \n\t\tif (WARN(ret || ghcb->save.sw_exit_info_2,\n\t\t\t \"SNP: PSC failed ret=%d exit_info_2=%llx\\n\",\n\t\t\t ret, ghcb->save.sw_exit_info_2)) {\n\t\t\tret = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tif (WARN(data->hdr.reserved, \"Reserved bit is set in the PSC header\\n\")) {\n\t\t\tret = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tif (WARN(data->hdr.end_entry > end_entry || cur_entry > data->hdr.cur_entry,\n\"SNP: PSC processing going backward, end_entry %d (got %d) cur_entry %d (got %d)\\n\",\n\t\t\t end_entry, data->hdr.end_entry, cur_entry, data->hdr.cur_entry)) {\n\t\t\tret = 1;\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}