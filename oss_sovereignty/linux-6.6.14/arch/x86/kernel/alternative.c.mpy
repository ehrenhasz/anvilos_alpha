{
  "module_name": "alternative.c",
  "hash_id": "409807128323cf5412cba586652402e7fa384ecda203990dbac6d05dba5eaa32",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/alternative.c",
  "human_readable_source": "\n#define pr_fmt(fmt) \"SMP alternatives: \" fmt\n\n#include <linux/module.h>\n#include <linux/sched.h>\n#include <linux/perf_event.h>\n#include <linux/mutex.h>\n#include <linux/list.h>\n#include <linux/stringify.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/memory.h>\n#include <linux/stop_machine.h>\n#include <linux/slab.h>\n#include <linux/kdebug.h>\n#include <linux/kprobes.h>\n#include <linux/mmu_context.h>\n#include <linux/bsearch.h>\n#include <linux/sync_core.h>\n#include <asm/text-patching.h>\n#include <asm/alternative.h>\n#include <asm/sections.h>\n#include <asm/mce.h>\n#include <asm/nmi.h>\n#include <asm/cacheflush.h>\n#include <asm/tlbflush.h>\n#include <asm/insn.h>\n#include <asm/io.h>\n#include <asm/fixmap.h>\n#include <asm/paravirt.h>\n#include <asm/asm-prototypes.h>\n\nint __read_mostly alternatives_patched;\n\nEXPORT_SYMBOL_GPL(alternatives_patched);\n\n#define MAX_PATCH_LEN (255-1)\n\n#define DA_ALL\t\t(~0)\n#define DA_ALT\t\t0x01\n#define DA_RET\t\t0x02\n#define DA_RETPOLINE\t0x04\n#define DA_ENDBR\t0x08\n#define DA_SMP\t\t0x10\n\nstatic unsigned int __initdata_or_module debug_alternative;\n\nstatic int __init debug_alt(char *str)\n{\n\tif (str && *str == '=')\n\t\tstr++;\n\n\tif (!str || kstrtouint(str, 0, &debug_alternative))\n\t\tdebug_alternative = DA_ALL;\n\n\treturn 1;\n}\n__setup(\"debug-alternative\", debug_alt);\n\nstatic int noreplace_smp;\n\nstatic int __init setup_noreplace_smp(char *str)\n{\n\tnoreplace_smp = 1;\n\treturn 1;\n}\n__setup(\"noreplace-smp\", setup_noreplace_smp);\n\n#define DPRINTK(type, fmt, args...)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (debug_alternative & DA_##type)\t\t\t\t\\\n\t\tprintk(KERN_DEBUG pr_fmt(fmt) \"\\n\", ##args);\t\t\\\n} while (0)\n\n#define DUMP_BYTES(type, buf, len, fmt, args...)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (unlikely(debug_alternative & DA_##type)) {\t\t\t\\\n\t\tint j;\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\tif (!(len))\t\t\t\t\t\t\\\n\t\t\tbreak;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\tprintk(KERN_DEBUG pr_fmt(fmt), ##args);\t\t\t\\\n\t\tfor (j = 0; j < (len) - 1; j++)\t\t\t\t\\\n\t\t\tprintk(KERN_CONT \"%02hhx \", buf[j]);\t\t\\\n\t\tprintk(KERN_CONT \"%02hhx\\n\", buf[j]);\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (0)\n\nstatic const unsigned char x86nops[] =\n{\n\tBYTES_NOP1,\n\tBYTES_NOP2,\n\tBYTES_NOP3,\n\tBYTES_NOP4,\n\tBYTES_NOP5,\n\tBYTES_NOP6,\n\tBYTES_NOP7,\n\tBYTES_NOP8,\n#ifdef CONFIG_64BIT\n\tBYTES_NOP9,\n\tBYTES_NOP10,\n\tBYTES_NOP11,\n#endif\n};\n\nconst unsigned char * const x86_nops[ASM_NOP_MAX+1] =\n{\n\tNULL,\n\tx86nops,\n\tx86nops + 1,\n\tx86nops + 1 + 2,\n\tx86nops + 1 + 2 + 3,\n\tx86nops + 1 + 2 + 3 + 4,\n\tx86nops + 1 + 2 + 3 + 4 + 5,\n\tx86nops + 1 + 2 + 3 + 4 + 5 + 6,\n\tx86nops + 1 + 2 + 3 + 4 + 5 + 6 + 7,\n#ifdef CONFIG_64BIT\n\tx86nops + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8,\n\tx86nops + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9,\n\tx86nops + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10,\n#endif\n};\n\n \nstatic void __init_or_module add_nop(u8 *instr, unsigned int len)\n{\n\tu8 *target = instr + len;\n\n\tif (!len)\n\t\treturn;\n\n\tif (len <= ASM_NOP_MAX) {\n\t\tmemcpy(instr, x86_nops[len], len);\n\t\treturn;\n\t}\n\n\tif (len < 128) {\n\t\t__text_gen_insn(instr, JMP8_INSN_OPCODE, instr, target, JMP8_INSN_SIZE);\n\t\tinstr += JMP8_INSN_SIZE;\n\t} else {\n\t\t__text_gen_insn(instr, JMP32_INSN_OPCODE, instr, target, JMP32_INSN_SIZE);\n\t\tinstr += JMP32_INSN_SIZE;\n\t}\n\n\tfor (;instr < target; instr++)\n\t\t*instr = INT3_INSN_OPCODE;\n}\n\nextern s32 __retpoline_sites[], __retpoline_sites_end[];\nextern s32 __return_sites[], __return_sites_end[];\nextern s32 __cfi_sites[], __cfi_sites_end[];\nextern s32 __ibt_endbr_seal[], __ibt_endbr_seal_end[];\nextern struct alt_instr __alt_instructions[], __alt_instructions_end[];\nextern s32 __smp_locks[], __smp_locks_end[];\nvoid text_poke_early(void *addr, const void *opcode, size_t len);\n\n \nstatic bool insn_is_nop(struct insn *insn)\n{\n\t \n\tif (insn->opcode.bytes[0] == 0x90 &&\n\t    (!insn->prefixes.nbytes || insn->prefixes.bytes[0] != 0xF3))\n\t\treturn true;\n\n\t \n\tif (insn->opcode.bytes[0] == 0x0F && insn->opcode.bytes[1] == 0x1F)\n\t\treturn true;\n\n\t \n\n\treturn false;\n}\n\n \nstatic int skip_nops(u8 *instr, int offset, int len)\n{\n\tstruct insn insn;\n\n\tfor (; offset < len; offset += insn.length) {\n\t\tif (insn_decode_kernel(&insn, &instr[offset]))\n\t\t\tbreak;\n\n\t\tif (!insn_is_nop(&insn))\n\t\t\tbreak;\n\t}\n\n\treturn offset;\n}\n\n \nstatic bool __init_or_module\n__optimize_nops(u8 *instr, size_t len, struct insn *insn, int *next, int *prev, int *target)\n{\n\tint i = *next - insn->length;\n\n\tswitch (insn->opcode.bytes[0]) {\n\tcase JMP8_INSN_OPCODE:\n\tcase JMP32_INSN_OPCODE:\n\t\t*prev = i;\n\t\t*target = *next + insn->immediate.value;\n\t\treturn false;\n\t}\n\n\tif (insn_is_nop(insn)) {\n\t\tint nop = i;\n\n\t\t*next = skip_nops(instr, *next, len);\n\t\tif (*target && *next == *target)\n\t\t\tnop = *prev;\n\n\t\tadd_nop(instr + nop, *next - nop);\n\t\tDUMP_BYTES(ALT, instr, len, \"%px: [%d:%d) optimized NOPs: \", instr, nop, *next);\n\t\treturn true;\n\t}\n\n\t*target = 0;\n\treturn false;\n}\n\n \nstatic void __init_or_module noinline optimize_nops(u8 *instr, size_t len)\n{\n\tint prev, target = 0;\n\n\tfor (int next, i = 0; i < len; i = next) {\n\t\tstruct insn insn;\n\n\t\tif (insn_decode_kernel(&insn, &instr[i]))\n\t\t\treturn;\n\n\t\tnext = i + insn.length;\n\n\t\t__optimize_nops(instr, len, &insn, &next, &prev, &target);\n\t}\n}\n\nstatic void __init_or_module noinline optimize_nops_inplace(u8 *instr, size_t len)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\toptimize_nops(instr, len);\n\tsync_core();\n\tlocal_irq_restore(flags);\n}\n\n \n\n#define apply_reloc_n(n_, p_, d_)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\ts32 v = *(s##n_ *)(p_);\t\t\t\t\\\n\t\tv += (d_);\t\t\t\t\t\\\n\t\tBUG_ON((v >> 31) != (v >> (n_-1)));\t\t\\\n\t\t*(s##n_ *)(p_) = (s##n_)v;\t\t\t\\\n\t} while (0)\n\n\nstatic __always_inline\nvoid apply_reloc(int n, void *ptr, uintptr_t diff)\n{\n\tswitch (n) {\n\tcase 1: apply_reloc_n(8, ptr, diff); break;\n\tcase 2: apply_reloc_n(16, ptr, diff); break;\n\tcase 4: apply_reloc_n(32, ptr, diff); break;\n\tdefault: BUG();\n\t}\n}\n\nstatic __always_inline\nbool need_reloc(unsigned long offset, u8 *src, size_t src_len)\n{\n\tu8 *target = src + offset;\n\t \n\treturn (target < src || target > src + src_len);\n}\n\nstatic void __init_or_module noinline\napply_relocation(u8 *buf, size_t len, u8 *dest, u8 *src, size_t src_len)\n{\n\tint prev, target = 0;\n\n\tfor (int next, i = 0; i < len; i = next) {\n\t\tstruct insn insn;\n\n\t\tif (WARN_ON_ONCE(insn_decode_kernel(&insn, &buf[i])))\n\t\t\treturn;\n\n\t\tnext = i + insn.length;\n\n\t\tif (__optimize_nops(buf, len, &insn, &next, &prev, &target))\n\t\t\tcontinue;\n\n\t\tswitch (insn.opcode.bytes[0]) {\n\t\tcase 0x0f:\n\t\t\tif (insn.opcode.bytes[1] < 0x80 ||\n\t\t\t    insn.opcode.bytes[1] > 0x8f)\n\t\t\t\tbreak;\n\n\t\t\tfallthrough;\t \n\t\tcase 0x70 ... 0x7f:\t \n\t\tcase JMP8_INSN_OPCODE:\n\t\tcase JMP32_INSN_OPCODE:\n\t\tcase CALL_INSN_OPCODE:\n\t\t\tif (need_reloc(next + insn.immediate.value, src, src_len)) {\n\t\t\t\tapply_reloc(insn.immediate.nbytes,\n\t\t\t\t\t    buf + i + insn_offset_immediate(&insn),\n\t\t\t\t\t    src - dest);\n\t\t\t}\n\n\t\t\t \n\t\t\tif (insn.opcode.bytes[0] == JMP32_INSN_OPCODE) {\n\t\t\t\ts32 imm = insn.immediate.value;\n\t\t\t\timm += src - dest;\n\t\t\t\timm += JMP32_INSN_SIZE - JMP8_INSN_SIZE;\n\t\t\t\tif ((imm >> 31) == (imm >> 7)) {\n\t\t\t\t\tbuf[i+0] = JMP8_INSN_OPCODE;\n\t\t\t\t\tbuf[i+1] = (s8)imm;\n\n\t\t\t\t\tmemset(&buf[i+2], INT3_INSN_OPCODE, insn.length - 2);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif (insn_rip_relative(&insn)) {\n\t\t\tif (need_reloc(next + insn.displacement.value, src, src_len)) {\n\t\t\t\tapply_reloc(insn.displacement.nbytes,\n\t\t\t\t\t    buf + i + insn_offset_displacement(&insn),\n\t\t\t\t\t    src - dest);\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nvoid __init_or_module noinline apply_alternatives(struct alt_instr *start,\n\t\t\t\t\t\t  struct alt_instr *end)\n{\n\tstruct alt_instr *a;\n\tu8 *instr, *replacement;\n\tu8 insn_buff[MAX_PATCH_LEN];\n\n\tDPRINTK(ALT, \"alt table %px, -> %px\", start, end);\n\n\t \n\tkasan_disable_current();\n\n\t \n\tfor (a = start; a < end; a++) {\n\t\tint insn_buff_sz = 0;\n\n\t\tinstr = (u8 *)&a->instr_offset + a->instr_offset;\n\t\treplacement = (u8 *)&a->repl_offset + a->repl_offset;\n\t\tBUG_ON(a->instrlen > sizeof(insn_buff));\n\t\tBUG_ON(a->cpuid >= (NCAPINTS + NBUGINTS) * 32);\n\n\t\t \n\t\tif (!boot_cpu_has(a->cpuid) == !(a->flags & ALT_FLAG_NOT)) {\n\t\t\toptimize_nops_inplace(instr, a->instrlen);\n\t\t\tcontinue;\n\t\t}\n\n\t\tDPRINTK(ALT, \"feat: %s%d*32+%d, old: (%pS (%px) len: %d), repl: (%px, len: %d)\",\n\t\t\t(a->flags & ALT_FLAG_NOT) ? \"!\" : \"\",\n\t\t\ta->cpuid >> 5,\n\t\t\ta->cpuid & 0x1f,\n\t\t\tinstr, instr, a->instrlen,\n\t\t\treplacement, a->replacementlen);\n\n\t\tmemcpy(insn_buff, replacement, a->replacementlen);\n\t\tinsn_buff_sz = a->replacementlen;\n\n\t\tfor (; insn_buff_sz < a->instrlen; insn_buff_sz++)\n\t\t\tinsn_buff[insn_buff_sz] = 0x90;\n\n\t\tapply_relocation(insn_buff, a->instrlen, instr, replacement, a->replacementlen);\n\n\t\tDUMP_BYTES(ALT, instr, a->instrlen, \"%px:   old_insn: \", instr);\n\t\tDUMP_BYTES(ALT, replacement, a->replacementlen, \"%px:   rpl_insn: \", replacement);\n\t\tDUMP_BYTES(ALT, insn_buff, insn_buff_sz, \"%px: final_insn: \", instr);\n\n\t\ttext_poke_early(instr, insn_buff, insn_buff_sz);\n\t}\n\n\tkasan_enable_current();\n}\n\nstatic inline bool is_jcc32(struct insn *insn)\n{\n\t \n\treturn insn->opcode.bytes[0] == 0x0f && (insn->opcode.bytes[1] & 0xf0) == 0x80;\n}\n\n#if defined(CONFIG_RETPOLINE) && defined(CONFIG_OBJTOOL)\n\n \nstatic int emit_indirect(int op, int reg, u8 *bytes)\n{\n\tint i = 0;\n\tu8 modrm;\n\n\tswitch (op) {\n\tcase CALL_INSN_OPCODE:\n\t\tmodrm = 0x10;  \n\t\tbreak;\n\n\tcase JMP32_INSN_OPCODE:\n\t\tmodrm = 0x20;  \n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn -1;\n\t}\n\n\tif (reg >= 8) {\n\t\tbytes[i++] = 0x41;  \n\t\treg -= 8;\n\t}\n\n\tmodrm |= 0xc0;  \n\tmodrm += reg;\n\n\tbytes[i++] = 0xff;  \n\tbytes[i++] = modrm;\n\n\treturn i;\n}\n\nstatic int emit_call_track_retpoline(void *addr, struct insn *insn, int reg, u8 *bytes)\n{\n\tu8 op = insn->opcode.bytes[0];\n\tint i = 0;\n\n\t \n\tif (is_jcc32(insn)) {\n\t\tbytes[i++] = op;\n\t\top = insn->opcode.bytes[1];\n\t\tgoto clang_jcc;\n\t}\n\n\tif (insn->length == 6)\n\t\tbytes[i++] = 0x2e;  \n\n\tswitch (op) {\n\tcase CALL_INSN_OPCODE:\n\t\t__text_gen_insn(bytes+i, op, addr+i,\n\t\t\t\t__x86_indirect_call_thunk_array[reg],\n\t\t\t\tCALL_INSN_SIZE);\n\t\ti += CALL_INSN_SIZE;\n\t\tbreak;\n\n\tcase JMP32_INSN_OPCODE:\nclang_jcc:\n\t\t__text_gen_insn(bytes+i, op, addr+i,\n\t\t\t\t__x86_indirect_jump_thunk_array[reg],\n\t\t\t\tJMP32_INSN_SIZE);\n\t\ti += JMP32_INSN_SIZE;\n\t\tbreak;\n\n\tdefault:\n\t\tWARN(1, \"%pS %px %*ph\\n\", addr, addr, 6, addr);\n\t\treturn -1;\n\t}\n\n\tWARN_ON_ONCE(i != insn->length);\n\n\treturn i;\n}\n\n \nstatic int patch_retpoline(void *addr, struct insn *insn, u8 *bytes)\n{\n\tretpoline_thunk_t *target;\n\tint reg, ret, i = 0;\n\tu8 op, cc;\n\n\ttarget = addr + insn->length + insn->immediate.value;\n\treg = target - __x86_indirect_thunk_array;\n\n\tif (WARN_ON_ONCE(reg & ~0xf))\n\t\treturn -1;\n\n\t \n\tBUG_ON(reg == 4);\n\n\tif (cpu_feature_enabled(X86_FEATURE_RETPOLINE) &&\n\t    !cpu_feature_enabled(X86_FEATURE_RETPOLINE_LFENCE)) {\n\t\tif (cpu_feature_enabled(X86_FEATURE_CALL_DEPTH))\n\t\t\treturn emit_call_track_retpoline(addr, insn, reg, bytes);\n\n\t\treturn -1;\n\t}\n\n\top = insn->opcode.bytes[0];\n\n\t \n\tif (is_jcc32(insn)) {\n\t\tcc = insn->opcode.bytes[1] & 0xf;\n\t\tcc ^= 1;  \n\n\t\tbytes[i++] = 0x70 + cc;         \n\t\tbytes[i++] = insn->length - 2;  \n\n\t\t \n\t\top = JMP32_INSN_OPCODE;\n\t}\n\n\t \n\tif (cpu_feature_enabled(X86_FEATURE_RETPOLINE_LFENCE)) {\n\t\tbytes[i++] = 0x0f;\n\t\tbytes[i++] = 0xae;\n\t\tbytes[i++] = 0xe8;  \n\t}\n\n\tret = emit_indirect(op, reg, bytes + i);\n\tif (ret < 0)\n\t\treturn ret;\n\ti += ret;\n\n\t \n\tif (op == JMP32_INSN_OPCODE && i < insn->length)\n\t\tbytes[i++] = INT3_INSN_OPCODE;\n\n\tfor (; i < insn->length;)\n\t\tbytes[i++] = BYTES_NOP1;\n\n\treturn i;\n}\n\n \nvoid __init_or_module noinline apply_retpolines(s32 *start, s32 *end)\n{\n\ts32 *s;\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *addr = (void *)s + *s;\n\t\tstruct insn insn;\n\t\tint len, ret;\n\t\tu8 bytes[16];\n\t\tu8 op1, op2;\n\n\t\tret = insn_decode_kernel(&insn, addr);\n\t\tif (WARN_ON_ONCE(ret < 0))\n\t\t\tcontinue;\n\n\t\top1 = insn.opcode.bytes[0];\n\t\top2 = insn.opcode.bytes[1];\n\n\t\tswitch (op1) {\n\t\tcase CALL_INSN_OPCODE:\n\t\tcase JMP32_INSN_OPCODE:\n\t\t\tbreak;\n\n\t\tcase 0x0f:  \n\t\t\tif (op2 >= 0x80 && op2 <= 0x8f)\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tdefault:\n\t\t\tWARN_ON_ONCE(1);\n\t\t\tcontinue;\n\t\t}\n\n\t\tDPRINTK(RETPOLINE, \"retpoline at: %pS (%px) len: %d to: %pS\",\n\t\t\taddr, addr, insn.length,\n\t\t\taddr + insn.length + insn.immediate.value);\n\n\t\tlen = patch_retpoline(addr, &insn, bytes);\n\t\tif (len == insn.length) {\n\t\t\toptimize_nops(bytes, len);\n\t\t\tDUMP_BYTES(RETPOLINE, ((u8*)addr),  len, \"%px: orig: \", addr);\n\t\t\tDUMP_BYTES(RETPOLINE, ((u8*)bytes), len, \"%px: repl: \", addr);\n\t\t\ttext_poke_early(addr, bytes, len);\n\t\t}\n\t}\n}\n\n#ifdef CONFIG_RETHUNK\n\n \nstatic int patch_return(void *addr, struct insn *insn, u8 *bytes)\n{\n\tint i = 0;\n\n\t \n\tif (cpu_feature_enabled(X86_FEATURE_RETHUNK)) {\n\t\ti = JMP32_INSN_SIZE;\n\t\t__text_gen_insn(bytes, JMP32_INSN_OPCODE, addr, x86_return_thunk, i);\n\t} else {\n\t\t \n\t\tbytes[i++] = RET_INSN_OPCODE;\n\t}\n\n\tfor (; i < insn->length;)\n\t\tbytes[i++] = INT3_INSN_OPCODE;\n\treturn i;\n}\n\nvoid __init_or_module noinline apply_returns(s32 *start, s32 *end)\n{\n\ts32 *s;\n\n\tif (cpu_feature_enabled(X86_FEATURE_RETHUNK))\n\t\tstatic_call_force_reinit();\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *dest = NULL, *addr = (void *)s + *s;\n\t\tstruct insn insn;\n\t\tint len, ret;\n\t\tu8 bytes[16];\n\t\tu8 op;\n\n\t\tret = insn_decode_kernel(&insn, addr);\n\t\tif (WARN_ON_ONCE(ret < 0))\n\t\t\tcontinue;\n\n\t\top = insn.opcode.bytes[0];\n\t\tif (op == JMP32_INSN_OPCODE)\n\t\t\tdest = addr + insn.length + insn.immediate.value;\n\n\t\tif (__static_call_fixup(addr, op, dest) ||\n\t\t    WARN_ONCE(dest != &__x86_return_thunk,\n\t\t\t      \"missing return thunk: %pS-%pS: %*ph\",\n\t\t\t      addr, dest, 5, addr))\n\t\t\tcontinue;\n\n\t\tDPRINTK(RET, \"return thunk at: %pS (%px) len: %d to: %pS\",\n\t\t\taddr, addr, insn.length,\n\t\t\taddr + insn.length + insn.immediate.value);\n\n\t\tlen = patch_return(addr, &insn, bytes);\n\t\tif (len == insn.length) {\n\t\t\tDUMP_BYTES(RET, ((u8*)addr),  len, \"%px: orig: \", addr);\n\t\t\tDUMP_BYTES(RET, ((u8*)bytes), len, \"%px: repl: \", addr);\n\t\t\ttext_poke_early(addr, bytes, len);\n\t\t}\n\t}\n}\n#else\nvoid __init_or_module noinline apply_returns(s32 *start, s32 *end) { }\n#endif  \n\n#else  \n\nvoid __init_or_module noinline apply_retpolines(s32 *start, s32 *end) { }\nvoid __init_or_module noinline apply_returns(s32 *start, s32 *end) { }\n\n#endif  \n\n#ifdef CONFIG_X86_KERNEL_IBT\n\nstatic void poison_cfi(void *addr);\n\nstatic void __init_or_module poison_endbr(void *addr, bool warn)\n{\n\tu32 endbr, poison = gen_endbr_poison();\n\n\tif (WARN_ON_ONCE(get_kernel_nofault(endbr, addr)))\n\t\treturn;\n\n\tif (!is_endbr(endbr)) {\n\t\tWARN_ON_ONCE(warn);\n\t\treturn;\n\t}\n\n\tDPRINTK(ENDBR, \"ENDBR at: %pS (%px)\", addr, addr);\n\n\t \n\tDUMP_BYTES(ENDBR, ((u8*)addr), 4, \"%px: orig: \", addr);\n\tDUMP_BYTES(ENDBR, ((u8*)&poison), 4, \"%px: repl: \", addr);\n\ttext_poke_early(addr, &poison, 4);\n}\n\n \nvoid __init_or_module noinline apply_seal_endbr(s32 *start, s32 *end)\n{\n\ts32 *s;\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *addr = (void *)s + *s;\n\n\t\tpoison_endbr(addr, true);\n\t\tif (IS_ENABLED(CONFIG_FINEIBT))\n\t\t\tpoison_cfi(addr - 16);\n\t}\n}\n\n#else\n\nvoid __init_or_module apply_seal_endbr(s32 *start, s32 *end) { }\n\n#endif  \n\n#ifdef CONFIG_FINEIBT\n\nenum cfi_mode {\n\tCFI_DEFAULT,\n\tCFI_OFF,\n\tCFI_KCFI,\n\tCFI_FINEIBT,\n};\n\nstatic enum cfi_mode cfi_mode __ro_after_init = CFI_DEFAULT;\nstatic bool cfi_rand __ro_after_init = true;\nstatic u32  cfi_seed __ro_after_init;\n\n \nstatic u32 cfi_rehash(u32 hash)\n{\n\thash ^= cfi_seed;\n\twhile (unlikely(is_endbr(hash) || is_endbr(-hash))) {\n\t\tbool lsb = hash & 1;\n\t\thash >>= 1;\n\t\tif (lsb)\n\t\t\thash ^= 0x80200003;\n\t}\n\treturn hash;\n}\n\nstatic __init int cfi_parse_cmdline(char *str)\n{\n\tif (!str)\n\t\treturn -EINVAL;\n\n\twhile (str) {\n\t\tchar *next = strchr(str, ',');\n\t\tif (next) {\n\t\t\t*next = 0;\n\t\t\tnext++;\n\t\t}\n\n\t\tif (!strcmp(str, \"auto\")) {\n\t\t\tcfi_mode = CFI_DEFAULT;\n\t\t} else if (!strcmp(str, \"off\")) {\n\t\t\tcfi_mode = CFI_OFF;\n\t\t\tcfi_rand = false;\n\t\t} else if (!strcmp(str, \"kcfi\")) {\n\t\t\tcfi_mode = CFI_KCFI;\n\t\t} else if (!strcmp(str, \"fineibt\")) {\n\t\t\tcfi_mode = CFI_FINEIBT;\n\t\t} else if (!strcmp(str, \"norand\")) {\n\t\t\tcfi_rand = false;\n\t\t} else {\n\t\t\tpr_err(\"Ignoring unknown cfi option (%s).\", str);\n\t\t}\n\n\t\tstr = next;\n\t}\n\n\treturn 0;\n}\nearly_param(\"cfi\", cfi_parse_cmdline);\n\n \n\nasm(\t\".pushsection .rodata\t\t\t\\n\"\n\t\"fineibt_preamble_start:\t\t\\n\"\n\t\"\tendbr64\t\t\t\t\\n\"\n\t\"\tsubl\t$0x12345678, %r10d\t\\n\"\n\t\"\tje\tfineibt_preamble_end\t\\n\"\n\t\"\tud2\t\t\t\t\\n\"\n\t\"\tnop\t\t\t\t\\n\"\n\t\"fineibt_preamble_end:\t\t\t\\n\"\n\t\".popsection\\n\"\n);\n\nextern u8 fineibt_preamble_start[];\nextern u8 fineibt_preamble_end[];\n\n#define fineibt_preamble_size (fineibt_preamble_end - fineibt_preamble_start)\n#define fineibt_preamble_hash 7\n\nasm(\t\".pushsection .rodata\t\t\t\\n\"\n\t\"fineibt_caller_start:\t\t\t\\n\"\n\t\"\tmovl\t$0x12345678, %r10d\t\\n\"\n\t\"\tsub\t$16, %r11\t\t\\n\"\n\tASM_NOP4\n\t\"fineibt_caller_end:\t\t\t\\n\"\n\t\".popsection\t\t\t\t\\n\"\n);\n\nextern u8 fineibt_caller_start[];\nextern u8 fineibt_caller_end[];\n\n#define fineibt_caller_size (fineibt_caller_end - fineibt_caller_start)\n#define fineibt_caller_hash 2\n\n#define fineibt_caller_jmp (fineibt_caller_size - 2)\n\nstatic u32 decode_preamble_hash(void *addr)\n{\n\tu8 *p = addr;\n\n\t \n\tif (p[0] == 0xb8)\n\t\treturn *(u32 *)(addr + 1);\n\n\treturn 0;  \n}\n\nstatic u32 decode_caller_hash(void *addr)\n{\n\tu8 *p = addr;\n\n\t \n\tif (p[0] == 0x41 && p[1] == 0xba)\n\t\treturn -*(u32 *)(addr + 2);\n\n\t \n\tif (p[0] == JMP8_INSN_OPCODE && p[1] == fineibt_caller_jmp)\n\t\treturn -*(u32 *)(addr + 2);\n\n\treturn 0;  \n}\n\n \nstatic int cfi_disable_callers(s32 *start, s32 *end)\n{\n\t \n\tconst u8 jmp[] = { JMP8_INSN_OPCODE, fineibt_caller_jmp };\n\ts32 *s;\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *addr = (void *)s + *s;\n\t\tu32 hash;\n\n\t\taddr -= fineibt_caller_size;\n\t\thash = decode_caller_hash(addr);\n\t\tif (!hash)  \n\t\t\tcontinue;\n\n\t\ttext_poke_early(addr, jmp, 2);\n\t}\n\n\treturn 0;\n}\n\nstatic int cfi_enable_callers(s32 *start, s32 *end)\n{\n\t \n\tconst u8 mov[] = { 0x41, 0xba };\n\ts32 *s;\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *addr = (void *)s + *s;\n\t\tu32 hash;\n\n\t\taddr -= fineibt_caller_size;\n\t\thash = decode_caller_hash(addr);\n\t\tif (!hash)  \n\t\t\tcontinue;\n\n\t\ttext_poke_early(addr, mov, 2);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int cfi_rand_preamble(s32 *start, s32 *end)\n{\n\ts32 *s;\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *addr = (void *)s + *s;\n\t\tu32 hash;\n\n\t\thash = decode_preamble_hash(addr);\n\t\tif (WARN(!hash, \"no CFI hash found at: %pS %px %*ph\\n\",\n\t\t\t addr, addr, 5, addr))\n\t\t\treturn -EINVAL;\n\n\t\thash = cfi_rehash(hash);\n\t\ttext_poke_early(addr + 1, &hash, 4);\n\t}\n\n\treturn 0;\n}\n\nstatic int cfi_rewrite_preamble(s32 *start, s32 *end)\n{\n\ts32 *s;\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *addr = (void *)s + *s;\n\t\tu32 hash;\n\n\t\thash = decode_preamble_hash(addr);\n\t\tif (WARN(!hash, \"no CFI hash found at: %pS %px %*ph\\n\",\n\t\t\t addr, addr, 5, addr))\n\t\t\treturn -EINVAL;\n\n\t\ttext_poke_early(addr, fineibt_preamble_start, fineibt_preamble_size);\n\t\tWARN_ON(*(u32 *)(addr + fineibt_preamble_hash) != 0x12345678);\n\t\ttext_poke_early(addr + fineibt_preamble_hash, &hash, 4);\n\t}\n\n\treturn 0;\n}\n\nstatic void cfi_rewrite_endbr(s32 *start, s32 *end)\n{\n\ts32 *s;\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *addr = (void *)s + *s;\n\n\t\tpoison_endbr(addr+16, false);\n\t}\n}\n\n \nstatic int cfi_rand_callers(s32 *start, s32 *end)\n{\n\ts32 *s;\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *addr = (void *)s + *s;\n\t\tu32 hash;\n\n\t\taddr -= fineibt_caller_size;\n\t\thash = decode_caller_hash(addr);\n\t\tif (hash) {\n\t\t\thash = -cfi_rehash(hash);\n\t\t\ttext_poke_early(addr + 2, &hash, 4);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int cfi_rewrite_callers(s32 *start, s32 *end)\n{\n\ts32 *s;\n\n\tfor (s = start; s < end; s++) {\n\t\tvoid *addr = (void *)s + *s;\n\t\tu32 hash;\n\n\t\taddr -= fineibt_caller_size;\n\t\thash = decode_caller_hash(addr);\n\t\tif (hash) {\n\t\t\ttext_poke_early(addr, fineibt_caller_start, fineibt_caller_size);\n\t\t\tWARN_ON(*(u32 *)(addr + fineibt_caller_hash) != 0x12345678);\n\t\t\ttext_poke_early(addr + fineibt_caller_hash, &hash, 4);\n\t\t}\n\t\t \n\t}\n\n\treturn 0;\n}\n\nstatic void __apply_fineibt(s32 *start_retpoline, s32 *end_retpoline,\n\t\t\t    s32 *start_cfi, s32 *end_cfi, bool builtin)\n{\n\tint ret;\n\n\tif (WARN_ONCE(fineibt_preamble_size != 16,\n\t\t      \"FineIBT preamble wrong size: %ld\", fineibt_preamble_size))\n\t\treturn;\n\n\tif (cfi_mode == CFI_DEFAULT) {\n\t\tcfi_mode = CFI_KCFI;\n\t\tif (HAS_KERNEL_IBT && cpu_feature_enabled(X86_FEATURE_IBT))\n\t\t\tcfi_mode = CFI_FINEIBT;\n\t}\n\n\t \n\tret = cfi_disable_callers(start_retpoline, end_retpoline);\n\tif (ret)\n\t\tgoto err;\n\n\tif (cfi_rand) {\n\t\tif (builtin)\n\t\t\tcfi_seed = get_random_u32();\n\n\t\tret = cfi_rand_preamble(start_cfi, end_cfi);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tret = cfi_rand_callers(start_retpoline, end_retpoline);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\tswitch (cfi_mode) {\n\tcase CFI_OFF:\n\t\tif (builtin)\n\t\t\tpr_info(\"Disabling CFI\\n\");\n\t\treturn;\n\n\tcase CFI_KCFI:\n\t\tret = cfi_enable_callers(start_retpoline, end_retpoline);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tif (builtin)\n\t\t\tpr_info(\"Using kCFI\\n\");\n\t\treturn;\n\n\tcase CFI_FINEIBT:\n\t\t \n\t\tret = cfi_rewrite_preamble(start_cfi, end_cfi);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\t \n\t\tret = cfi_rewrite_callers(start_retpoline, end_retpoline);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\t \n\t\tcfi_rewrite_endbr(start_cfi, end_cfi);\n\n\t\tif (builtin)\n\t\t\tpr_info(\"Using FineIBT CFI\\n\");\n\t\treturn;\n\n\tdefault:\n\t\tbreak;\n\t}\n\nerr:\n\tpr_err(\"Something went horribly wrong trying to rewrite the CFI implementation.\\n\");\n}\n\nstatic inline void poison_hash(void *addr)\n{\n\t*(u32 *)addr = 0;\n}\n\nstatic void poison_cfi(void *addr)\n{\n\tswitch (cfi_mode) {\n\tcase CFI_FINEIBT:\n\t\t \n\t\tpoison_endbr(addr, false);\n\t\tpoison_hash(addr + fineibt_preamble_hash);\n\t\tbreak;\n\n\tcase CFI_KCFI:\n\t\t \n\t\tpoison_hash(addr + 1);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n#else\n\nstatic void __apply_fineibt(s32 *start_retpoline, s32 *end_retpoline,\n\t\t\t    s32 *start_cfi, s32 *end_cfi, bool builtin)\n{\n}\n\n#ifdef CONFIG_X86_KERNEL_IBT\nstatic void poison_cfi(void *addr) { }\n#endif\n\n#endif\n\nvoid apply_fineibt(s32 *start_retpoline, s32 *end_retpoline,\n\t\t   s32 *start_cfi, s32 *end_cfi)\n{\n\treturn __apply_fineibt(start_retpoline, end_retpoline,\n\t\t\t       start_cfi, end_cfi,\n\t\t\t         false);\n}\n\n#ifdef CONFIG_SMP\nstatic void alternatives_smp_lock(const s32 *start, const s32 *end,\n\t\t\t\t  u8 *text, u8 *text_end)\n{\n\tconst s32 *poff;\n\n\tfor (poff = start; poff < end; poff++) {\n\t\tu8 *ptr = (u8 *)poff + *poff;\n\n\t\tif (!*poff || ptr < text || ptr >= text_end)\n\t\t\tcontinue;\n\t\t \n\t\tif (*ptr == 0x3e)\n\t\t\ttext_poke(ptr, ((unsigned char []){0xf0}), 1);\n\t}\n}\n\nstatic void alternatives_smp_unlock(const s32 *start, const s32 *end,\n\t\t\t\t    u8 *text, u8 *text_end)\n{\n\tconst s32 *poff;\n\n\tfor (poff = start; poff < end; poff++) {\n\t\tu8 *ptr = (u8 *)poff + *poff;\n\n\t\tif (!*poff || ptr < text || ptr >= text_end)\n\t\t\tcontinue;\n\t\t \n\t\tif (*ptr == 0xf0)\n\t\t\ttext_poke(ptr, ((unsigned char []){0x3E}), 1);\n\t}\n}\n\nstruct smp_alt_module {\n\t \n\tstruct module\t*mod;\n\tchar\t\t*name;\n\n\t \n\tconst s32\t*locks;\n\tconst s32\t*locks_end;\n\n\t \n\tu8\t\t*text;\n\tu8\t\t*text_end;\n\n\tstruct list_head next;\n};\nstatic LIST_HEAD(smp_alt_modules);\nstatic bool uniproc_patched = false;\t \n\nvoid __init_or_module alternatives_smp_module_add(struct module *mod,\n\t\t\t\t\t\t  char *name,\n\t\t\t\t\t\t  void *locks, void *locks_end,\n\t\t\t\t\t\t  void *text,  void *text_end)\n{\n\tstruct smp_alt_module *smp;\n\n\tmutex_lock(&text_mutex);\n\tif (!uniproc_patched)\n\t\tgoto unlock;\n\n\tif (num_possible_cpus() == 1)\n\t\t \n\t\tgoto smp_unlock;\n\n\tsmp = kzalloc(sizeof(*smp), GFP_KERNEL);\n\tif (NULL == smp)\n\t\t \n\t\tgoto unlock;\n\n\tsmp->mod\t= mod;\n\tsmp->name\t= name;\n\tsmp->locks\t= locks;\n\tsmp->locks_end\t= locks_end;\n\tsmp->text\t= text;\n\tsmp->text_end\t= text_end;\n\tDPRINTK(SMP, \"locks %p -> %p, text %p -> %p, name %s\\n\",\n\t\tsmp->locks, smp->locks_end,\n\t\tsmp->text, smp->text_end, smp->name);\n\n\tlist_add_tail(&smp->next, &smp_alt_modules);\nsmp_unlock:\n\talternatives_smp_unlock(locks, locks_end, text, text_end);\nunlock:\n\tmutex_unlock(&text_mutex);\n}\n\nvoid __init_or_module alternatives_smp_module_del(struct module *mod)\n{\n\tstruct smp_alt_module *item;\n\n\tmutex_lock(&text_mutex);\n\tlist_for_each_entry(item, &smp_alt_modules, next) {\n\t\tif (mod != item->mod)\n\t\t\tcontinue;\n\t\tlist_del(&item->next);\n\t\tkfree(item);\n\t\tbreak;\n\t}\n\tmutex_unlock(&text_mutex);\n}\n\nvoid alternatives_enable_smp(void)\n{\n\tstruct smp_alt_module *mod;\n\n\t \n\tBUG_ON(num_possible_cpus() == 1);\n\n\tmutex_lock(&text_mutex);\n\n\tif (uniproc_patched) {\n\t\tpr_info(\"switching to SMP code\\n\");\n\t\tBUG_ON(num_online_cpus() != 1);\n\t\tclear_cpu_cap(&boot_cpu_data, X86_FEATURE_UP);\n\t\tclear_cpu_cap(&cpu_data(0), X86_FEATURE_UP);\n\t\tlist_for_each_entry(mod, &smp_alt_modules, next)\n\t\t\talternatives_smp_lock(mod->locks, mod->locks_end,\n\t\t\t\t\t      mod->text, mod->text_end);\n\t\tuniproc_patched = false;\n\t}\n\tmutex_unlock(&text_mutex);\n}\n\n \nint alternatives_text_reserved(void *start, void *end)\n{\n\tstruct smp_alt_module *mod;\n\tconst s32 *poff;\n\tu8 *text_start = start;\n\tu8 *text_end = end;\n\n\tlockdep_assert_held(&text_mutex);\n\n\tlist_for_each_entry(mod, &smp_alt_modules, next) {\n\t\tif (mod->text > text_end || mod->text_end < text_start)\n\t\t\tcontinue;\n\t\tfor (poff = mod->locks; poff < mod->locks_end; poff++) {\n\t\t\tconst u8 *ptr = (const u8 *)poff + *poff;\n\n\t\t\tif (text_start <= ptr && text_end > ptr)\n\t\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n#endif  \n\n#ifdef CONFIG_PARAVIRT\n\n \nstatic void __init_or_module add_nops(void *insns, unsigned int len)\n{\n\twhile (len > 0) {\n\t\tunsigned int noplen = len;\n\t\tif (noplen > ASM_NOP_MAX)\n\t\t\tnoplen = ASM_NOP_MAX;\n\t\tmemcpy(insns, x86_nops[noplen], noplen);\n\t\tinsns += noplen;\n\t\tlen -= noplen;\n\t}\n}\n\nvoid __init_or_module apply_paravirt(struct paravirt_patch_site *start,\n\t\t\t\t     struct paravirt_patch_site *end)\n{\n\tstruct paravirt_patch_site *p;\n\tchar insn_buff[MAX_PATCH_LEN];\n\n\tfor (p = start; p < end; p++) {\n\t\tunsigned int used;\n\n\t\tBUG_ON(p->len > MAX_PATCH_LEN);\n\t\t \n\t\tmemcpy(insn_buff, p->instr, p->len);\n\t\tused = paravirt_patch(p->type, insn_buff, (unsigned long)p->instr, p->len);\n\n\t\tBUG_ON(used > p->len);\n\n\t\t \n\t\tadd_nops(insn_buff + used, p->len - used);\n\t\ttext_poke_early(p->instr, insn_buff, p->len);\n\t}\n}\nextern struct paravirt_patch_site __start_parainstructions[],\n\t__stop_parainstructions[];\n#endif\t \n\n \n\n \n\nextern void int3_magic(unsigned int *ptr);  \n\nasm (\n\"\t.pushsection\t.init.text, \\\"ax\\\", @progbits\\n\"\n\"\t.type\t\tint3_magic, @function\\n\"\n\"int3_magic:\\n\"\n\tANNOTATE_NOENDBR\n\"\tmovl\t$1, (%\" _ASM_ARG1 \")\\n\"\n\tASM_RET\n\"\t.size\t\tint3_magic, .-int3_magic\\n\"\n\"\t.popsection\\n\"\n);\n\nextern void int3_selftest_ip(void);  \n\nstatic int __init\nint3_exception_notify(struct notifier_block *self, unsigned long val, void *data)\n{\n\tunsigned long selftest = (unsigned long)&int3_selftest_ip;\n\tstruct die_args *args = data;\n\tstruct pt_regs *regs = args->regs;\n\n\tOPTIMIZER_HIDE_VAR(selftest);\n\n\tif (!regs || user_mode(regs))\n\t\treturn NOTIFY_DONE;\n\n\tif (val != DIE_INT3)\n\t\treturn NOTIFY_DONE;\n\n\tif (regs->ip - INT3_INSN_SIZE != selftest)\n\t\treturn NOTIFY_DONE;\n\n\tint3_emulate_call(regs, (unsigned long)&int3_magic);\n\treturn NOTIFY_STOP;\n}\n\n \nstatic noinline void __init int3_selftest(void)\n{\n\tstatic __initdata struct notifier_block int3_exception_nb = {\n\t\t.notifier_call\t= int3_exception_notify,\n\t\t.priority\t= INT_MAX-1,  \n\t};\n\tunsigned int val = 0;\n\n\tBUG_ON(register_die_notifier(&int3_exception_nb));\n\n\t \n\tasm volatile (\"int3_selftest_ip:\\n\\t\"\n\t\t      ANNOTATE_NOENDBR\n\t\t      \"    int3; nop; nop; nop; nop\\n\\t\"\n\t\t      : ASM_CALL_CONSTRAINT\n\t\t      : __ASM_SEL_RAW(a, D) (&val)\n\t\t      : \"memory\");\n\n\tBUG_ON(val != 1);\n\n\tunregister_die_notifier(&int3_exception_nb);\n}\n\nstatic __initdata int __alt_reloc_selftest_addr;\n\nextern void __init __alt_reloc_selftest(void *arg);\n__visible noinline void __init __alt_reloc_selftest(void *arg)\n{\n\tWARN_ON(arg != &__alt_reloc_selftest_addr);\n}\n\nstatic noinline void __init alt_reloc_selftest(void)\n{\n\t \n\tasm_inline volatile (\n\t\tALTERNATIVE(\"\", \"lea %[mem], %%\" _ASM_ARG1 \"; call __alt_reloc_selftest;\", X86_FEATURE_ALWAYS)\n\t\t:  \n\t\t: [mem] \"m\" (__alt_reloc_selftest_addr)\n\t\t: _ASM_ARG1\n\t);\n}\n\nvoid __init alternative_instructions(void)\n{\n\tint3_selftest();\n\n\t \n\tstop_nmi();\n\n\t \n\n\t \n\tparavirt_set_cap();\n\n\t \n\tapply_paravirt(__parainstructions, __parainstructions_end);\n\n\t__apply_fineibt(__retpoline_sites, __retpoline_sites_end,\n\t\t\t__cfi_sites, __cfi_sites_end, true);\n\n\t \n\tapply_retpolines(__retpoline_sites, __retpoline_sites_end);\n\tapply_returns(__return_sites, __return_sites_end);\n\n\t \n\tapply_alternatives(__alt_instructions, __alt_instructions_end);\n\n\t \n\tcallthunks_patch_builtin_calls();\n\n\t \n\tapply_seal_endbr(__ibt_endbr_seal, __ibt_endbr_seal_end);\n\n#ifdef CONFIG_SMP\n\t \n\tif (!noreplace_smp && (num_present_cpus() == 1 || setup_max_cpus <= 1)) {\n\t\tuniproc_patched = true;\n\t\talternatives_smp_module_add(NULL, \"core kernel\",\n\t\t\t\t\t    __smp_locks, __smp_locks_end,\n\t\t\t\t\t    _text, _etext);\n\t}\n\n\tif (!uniproc_patched || num_possible_cpus() == 1) {\n\t\tfree_init_pages(\"SMP alternatives\",\n\t\t\t\t(unsigned long)__smp_locks,\n\t\t\t\t(unsigned long)__smp_locks_end);\n\t}\n#endif\n\n\trestart_nmi();\n\talternatives_patched = 1;\n\n\talt_reloc_selftest();\n}\n\n \nvoid __init_or_module text_poke_early(void *addr, const void *opcode,\n\t\t\t\t      size_t len)\n{\n\tunsigned long flags;\n\n\tif (boot_cpu_has(X86_FEATURE_NX) &&\n\t    is_module_text_address((unsigned long)addr)) {\n\t\t \n\t\tmemcpy(addr, opcode, len);\n\t} else {\n\t\tlocal_irq_save(flags);\n\t\tmemcpy(addr, opcode, len);\n\t\tsync_core();\n\t\tlocal_irq_restore(flags);\n\n\t\t \n\t}\n}\n\ntypedef struct {\n\tstruct mm_struct *mm;\n} temp_mm_state_t;\n\n \nstatic inline temp_mm_state_t use_temporary_mm(struct mm_struct *mm)\n{\n\ttemp_mm_state_t temp_state;\n\n\tlockdep_assert_irqs_disabled();\n\n\t \n\tif (this_cpu_read(cpu_tlbstate_shared.is_lazy))\n\t\tleave_mm(smp_processor_id());\n\n\ttemp_state.mm = this_cpu_read(cpu_tlbstate.loaded_mm);\n\tswitch_mm_irqs_off(NULL, mm, current);\n\n\t \n\tif (hw_breakpoint_active())\n\t\thw_breakpoint_disable();\n\n\treturn temp_state;\n}\n\nstatic inline void unuse_temporary_mm(temp_mm_state_t prev_state)\n{\n\tlockdep_assert_irqs_disabled();\n\tswitch_mm_irqs_off(NULL, prev_state.mm, current);\n\n\t \n\tif (hw_breakpoint_active())\n\t\thw_breakpoint_restore();\n}\n\n__ro_after_init struct mm_struct *poking_mm;\n__ro_after_init unsigned long poking_addr;\n\nstatic void text_poke_memcpy(void *dst, const void *src, size_t len)\n{\n\tmemcpy(dst, src, len);\n}\n\nstatic void text_poke_memset(void *dst, const void *src, size_t len)\n{\n\tint c = *(const int *)src;\n\n\tmemset(dst, c, len);\n}\n\ntypedef void text_poke_f(void *dst, const void *src, size_t len);\n\nstatic void *__text_poke(text_poke_f func, void *addr, const void *src, size_t len)\n{\n\tbool cross_page_boundary = offset_in_page(addr) + len > PAGE_SIZE;\n\tstruct page *pages[2] = {NULL};\n\ttemp_mm_state_t prev;\n\tunsigned long flags;\n\tpte_t pte, *ptep;\n\tspinlock_t *ptl;\n\tpgprot_t pgprot;\n\n\t \n\tBUG_ON(!after_bootmem);\n\n\tif (!core_kernel_text((unsigned long)addr)) {\n\t\tpages[0] = vmalloc_to_page(addr);\n\t\tif (cross_page_boundary)\n\t\t\tpages[1] = vmalloc_to_page(addr + PAGE_SIZE);\n\t} else {\n\t\tpages[0] = virt_to_page(addr);\n\t\tWARN_ON(!PageReserved(pages[0]));\n\t\tif (cross_page_boundary)\n\t\t\tpages[1] = virt_to_page(addr + PAGE_SIZE);\n\t}\n\t \n\tBUG_ON(!pages[0] || (cross_page_boundary && !pages[1]));\n\n\t \n\tpgprot = __pgprot(pgprot_val(PAGE_KERNEL) & ~_PAGE_GLOBAL);\n\n\t \n\tptep = get_locked_pte(poking_mm, poking_addr, &ptl);\n\n\t \n\tVM_BUG_ON(!ptep);\n\n\tlocal_irq_save(flags);\n\n\tpte = mk_pte(pages[0], pgprot);\n\tset_pte_at(poking_mm, poking_addr, ptep, pte);\n\n\tif (cross_page_boundary) {\n\t\tpte = mk_pte(pages[1], pgprot);\n\t\tset_pte_at(poking_mm, poking_addr + PAGE_SIZE, ptep + 1, pte);\n\t}\n\n\t \n\tprev = use_temporary_mm(poking_mm);\n\n\tkasan_disable_current();\n\tfunc((u8 *)poking_addr + offset_in_page(addr), src, len);\n\tkasan_enable_current();\n\n\t \n\tbarrier();\n\n\tpte_clear(poking_mm, poking_addr, ptep);\n\tif (cross_page_boundary)\n\t\tpte_clear(poking_mm, poking_addr + PAGE_SIZE, ptep + 1);\n\n\t \n\tunuse_temporary_mm(prev);\n\n\t \n\tflush_tlb_mm_range(poking_mm, poking_addr, poking_addr +\n\t\t\t   (cross_page_boundary ? 2 : 1) * PAGE_SIZE,\n\t\t\t   PAGE_SHIFT, false);\n\n\tif (func == text_poke_memcpy) {\n\t\t \n\t\tBUG_ON(memcmp(addr, src, len));\n\t}\n\n\tlocal_irq_restore(flags);\n\tpte_unmap_unlock(ptep, ptl);\n\treturn addr;\n}\n\n \nvoid *text_poke(void *addr, const void *opcode, size_t len)\n{\n\tlockdep_assert_held(&text_mutex);\n\n\treturn __text_poke(text_poke_memcpy, addr, opcode, len);\n}\n\n \nvoid *text_poke_kgdb(void *addr, const void *opcode, size_t len)\n{\n\treturn __text_poke(text_poke_memcpy, addr, opcode, len);\n}\n\nvoid *text_poke_copy_locked(void *addr, const void *opcode, size_t len,\n\t\t\t    bool core_ok)\n{\n\tunsigned long start = (unsigned long)addr;\n\tsize_t patched = 0;\n\n\tif (WARN_ON_ONCE(!core_ok && core_kernel_text(start)))\n\t\treturn NULL;\n\n\twhile (patched < len) {\n\t\tunsigned long ptr = start + patched;\n\t\tsize_t s;\n\n\t\ts = min_t(size_t, PAGE_SIZE * 2 - offset_in_page(ptr), len - patched);\n\n\t\t__text_poke(text_poke_memcpy, (void *)ptr, opcode + patched, s);\n\t\tpatched += s;\n\t}\n\treturn addr;\n}\n\n \nvoid *text_poke_copy(void *addr, const void *opcode, size_t len)\n{\n\tmutex_lock(&text_mutex);\n\taddr = text_poke_copy_locked(addr, opcode, len, false);\n\tmutex_unlock(&text_mutex);\n\treturn addr;\n}\n\n \nvoid *text_poke_set(void *addr, int c, size_t len)\n{\n\tunsigned long start = (unsigned long)addr;\n\tsize_t patched = 0;\n\n\tif (WARN_ON_ONCE(core_kernel_text(start)))\n\t\treturn NULL;\n\n\tmutex_lock(&text_mutex);\n\twhile (patched < len) {\n\t\tunsigned long ptr = start + patched;\n\t\tsize_t s;\n\n\t\ts = min_t(size_t, PAGE_SIZE * 2 - offset_in_page(ptr), len - patched);\n\n\t\t__text_poke(text_poke_memset, (void *)ptr, (void *)&c, s);\n\t\tpatched += s;\n\t}\n\tmutex_unlock(&text_mutex);\n\treturn addr;\n}\n\nstatic void do_sync_core(void *info)\n{\n\tsync_core();\n}\n\nvoid text_poke_sync(void)\n{\n\ton_each_cpu(do_sync_core, NULL, 1);\n}\n\n \nstruct text_poke_loc {\n\t \n\ts32 rel_addr;\n\ts32 disp;\n\tu8 len;\n\tu8 opcode;\n\tconst u8 text[POKE_MAX_OPCODE_SIZE];\n\t \n\tu8 old;\n};\n\nstruct bp_patching_desc {\n\tstruct text_poke_loc *vec;\n\tint nr_entries;\n\tatomic_t refs;\n};\n\nstatic struct bp_patching_desc bp_desc;\n\nstatic __always_inline\nstruct bp_patching_desc *try_get_desc(void)\n{\n\tstruct bp_patching_desc *desc = &bp_desc;\n\n\tif (!raw_atomic_inc_not_zero(&desc->refs))\n\t\treturn NULL;\n\n\treturn desc;\n}\n\nstatic __always_inline void put_desc(void)\n{\n\tstruct bp_patching_desc *desc = &bp_desc;\n\n\tsmp_mb__before_atomic();\n\traw_atomic_dec(&desc->refs);\n}\n\nstatic __always_inline void *text_poke_addr(struct text_poke_loc *tp)\n{\n\treturn _stext + tp->rel_addr;\n}\n\nstatic __always_inline int patch_cmp(const void *key, const void *elt)\n{\n\tstruct text_poke_loc *tp = (struct text_poke_loc *) elt;\n\n\tif (key < text_poke_addr(tp))\n\t\treturn -1;\n\tif (key > text_poke_addr(tp))\n\t\treturn 1;\n\treturn 0;\n}\n\nnoinstr int poke_int3_handler(struct pt_regs *regs)\n{\n\tstruct bp_patching_desc *desc;\n\tstruct text_poke_loc *tp;\n\tint ret = 0;\n\tvoid *ip;\n\n\tif (user_mode(regs))\n\t\treturn 0;\n\n\t \n\tsmp_rmb();\n\n\tdesc = try_get_desc();\n\tif (!desc)\n\t\treturn 0;\n\n\t \n\tip = (void *) regs->ip - INT3_INSN_SIZE;\n\n\t \n\tif (unlikely(desc->nr_entries > 1)) {\n\t\ttp = __inline_bsearch(ip, desc->vec, desc->nr_entries,\n\t\t\t\t      sizeof(struct text_poke_loc),\n\t\t\t\t      patch_cmp);\n\t\tif (!tp)\n\t\t\tgoto out_put;\n\t} else {\n\t\ttp = desc->vec;\n\t\tif (text_poke_addr(tp) != ip)\n\t\t\tgoto out_put;\n\t}\n\n\tip += tp->len;\n\n\tswitch (tp->opcode) {\n\tcase INT3_INSN_OPCODE:\n\t\t \n\t\tgoto out_put;\n\n\tcase RET_INSN_OPCODE:\n\t\tint3_emulate_ret(regs);\n\t\tbreak;\n\n\tcase CALL_INSN_OPCODE:\n\t\tint3_emulate_call(regs, (long)ip + tp->disp);\n\t\tbreak;\n\n\tcase JMP32_INSN_OPCODE:\n\tcase JMP8_INSN_OPCODE:\n\t\tint3_emulate_jmp(regs, (long)ip + tp->disp);\n\t\tbreak;\n\n\tcase 0x70 ... 0x7f:  \n\t\tint3_emulate_jcc(regs, tp->opcode & 0xf, (long)ip, tp->disp);\n\t\tbreak;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\tret = 1;\n\nout_put:\n\tput_desc();\n\treturn ret;\n}\n\n#define TP_VEC_MAX (PAGE_SIZE / sizeof(struct text_poke_loc))\nstatic struct text_poke_loc tp_vec[TP_VEC_MAX];\nstatic int tp_vec_nr;\n\n \nstatic void text_poke_bp_batch(struct text_poke_loc *tp, unsigned int nr_entries)\n{\n\tunsigned char int3 = INT3_INSN_OPCODE;\n\tunsigned int i;\n\tint do_sync;\n\n\tlockdep_assert_held(&text_mutex);\n\n\tbp_desc.vec = tp;\n\tbp_desc.nr_entries = nr_entries;\n\n\t \n\tatomic_set_release(&bp_desc.refs, 1);\n\n\t \n\tcond_resched();\n\n\t \n\tsmp_wmb();\n\n\t \n\tfor (i = 0; i < nr_entries; i++) {\n\t\ttp[i].old = *(u8 *)text_poke_addr(&tp[i]);\n\t\ttext_poke(text_poke_addr(&tp[i]), &int3, INT3_INSN_SIZE);\n\t}\n\n\ttext_poke_sync();\n\n\t \n\tfor (do_sync = 0, i = 0; i < nr_entries; i++) {\n\t\tu8 old[POKE_MAX_OPCODE_SIZE+1] = { tp[i].old, };\n\t\tu8 _new[POKE_MAX_OPCODE_SIZE+1];\n\t\tconst u8 *new = tp[i].text;\n\t\tint len = tp[i].len;\n\n\t\tif (len - INT3_INSN_SIZE > 0) {\n\t\t\tmemcpy(old + INT3_INSN_SIZE,\n\t\t\t       text_poke_addr(&tp[i]) + INT3_INSN_SIZE,\n\t\t\t       len - INT3_INSN_SIZE);\n\n\t\t\tif (len == 6) {\n\t\t\t\t_new[0] = 0x0f;\n\t\t\t\tmemcpy(_new + 1, new, 5);\n\t\t\t\tnew = _new;\n\t\t\t}\n\n\t\t\ttext_poke(text_poke_addr(&tp[i]) + INT3_INSN_SIZE,\n\t\t\t\t  new + INT3_INSN_SIZE,\n\t\t\t\t  len - INT3_INSN_SIZE);\n\n\t\t\tdo_sync++;\n\t\t}\n\n\t\t \n\t\tperf_event_text_poke(text_poke_addr(&tp[i]), old, len, new, len);\n\t}\n\n\tif (do_sync) {\n\t\t \n\t\ttext_poke_sync();\n\t}\n\n\t \n\tfor (do_sync = 0, i = 0; i < nr_entries; i++) {\n\t\tu8 byte = tp[i].text[0];\n\n\t\tif (tp[i].len == 6)\n\t\t\tbyte = 0x0f;\n\n\t\tif (byte == INT3_INSN_OPCODE)\n\t\t\tcontinue;\n\n\t\ttext_poke(text_poke_addr(&tp[i]), &byte, INT3_INSN_SIZE);\n\t\tdo_sync++;\n\t}\n\n\tif (do_sync)\n\t\ttext_poke_sync();\n\n\t \n\tif (!atomic_dec_and_test(&bp_desc.refs))\n\t\tatomic_cond_read_acquire(&bp_desc.refs, !VAL);\n}\n\nstatic void text_poke_loc_init(struct text_poke_loc *tp, void *addr,\n\t\t\t       const void *opcode, size_t len, const void *emulate)\n{\n\tstruct insn insn;\n\tint ret, i = 0;\n\n\tif (len == 6)\n\t\ti = 1;\n\tmemcpy((void *)tp->text, opcode+i, len-i);\n\tif (!emulate)\n\t\temulate = opcode;\n\n\tret = insn_decode_kernel(&insn, emulate);\n\tBUG_ON(ret < 0);\n\n\ttp->rel_addr = addr - (void *)_stext;\n\ttp->len = len;\n\ttp->opcode = insn.opcode.bytes[0];\n\n\tif (is_jcc32(&insn)) {\n\t\t \n\t\ttp->opcode = insn.opcode.bytes[1] - 0x10;\n\t}\n\n\tswitch (tp->opcode) {\n\tcase RET_INSN_OPCODE:\n\tcase JMP32_INSN_OPCODE:\n\tcase JMP8_INSN_OPCODE:\n\t\t \n\t\tfor (i = insn.length; i < len; i++)\n\t\t\tBUG_ON(tp->text[i] != INT3_INSN_OPCODE);\n\t\tbreak;\n\n\tdefault:\n\t\tBUG_ON(len != insn.length);\n\t}\n\n\tswitch (tp->opcode) {\n\tcase INT3_INSN_OPCODE:\n\tcase RET_INSN_OPCODE:\n\t\tbreak;\n\n\tcase CALL_INSN_OPCODE:\n\tcase JMP32_INSN_OPCODE:\n\tcase JMP8_INSN_OPCODE:\n\tcase 0x70 ... 0x7f:  \n\t\ttp->disp = insn.immediate.value;\n\t\tbreak;\n\n\tdefault:  \n\t\tswitch (len) {\n\t\tcase 2:  \n\t\t\tBUG_ON(memcmp(emulate, x86_nops[len], len));\n\t\t\ttp->opcode = JMP8_INSN_OPCODE;\n\t\t\ttp->disp = 0;\n\t\t\tbreak;\n\n\t\tcase 5:  \n\t\t\tBUG_ON(memcmp(emulate, x86_nops[len], len));\n\t\t\ttp->opcode = JMP32_INSN_OPCODE;\n\t\t\ttp->disp = 0;\n\t\t\tbreak;\n\n\t\tdefault:  \n\t\t\tBUG();\n\t\t}\n\t\tbreak;\n\t}\n}\n\n \nstatic bool tp_order_fail(void *addr)\n{\n\tstruct text_poke_loc *tp;\n\n\tif (!tp_vec_nr)\n\t\treturn false;\n\n\tif (!addr)  \n\t\treturn true;\n\n\ttp = &tp_vec[tp_vec_nr - 1];\n\tif ((unsigned long)text_poke_addr(tp) > (unsigned long)addr)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void text_poke_flush(void *addr)\n{\n\tif (tp_vec_nr == TP_VEC_MAX || tp_order_fail(addr)) {\n\t\ttext_poke_bp_batch(tp_vec, tp_vec_nr);\n\t\ttp_vec_nr = 0;\n\t}\n}\n\nvoid text_poke_finish(void)\n{\n\ttext_poke_flush(NULL);\n}\n\nvoid __ref text_poke_queue(void *addr, const void *opcode, size_t len, const void *emulate)\n{\n\tstruct text_poke_loc *tp;\n\n\ttext_poke_flush(addr);\n\n\ttp = &tp_vec[tp_vec_nr++];\n\ttext_poke_loc_init(tp, addr, opcode, len, emulate);\n}\n\n \nvoid __ref text_poke_bp(void *addr, const void *opcode, size_t len, const void *emulate)\n{\n\tstruct text_poke_loc tp;\n\n\ttext_poke_loc_init(&tp, addr, opcode, len, emulate);\n\ttext_poke_bp_batch(&tp, 1);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}