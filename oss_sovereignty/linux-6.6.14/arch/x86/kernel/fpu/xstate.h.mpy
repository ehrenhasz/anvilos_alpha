{
  "module_name": "xstate.h",
  "hash_id": "ebe8461acca6afcbe4fa6c9ed5f8b9524f87a48db118cea880062653ba2229b0",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/fpu/xstate.h",
  "human_readable_source": " \n#ifndef __X86_KERNEL_FPU_XSTATE_H\n#define __X86_KERNEL_FPU_XSTATE_H\n\n#include <asm/cpufeature.h>\n#include <asm/fpu/xstate.h>\n#include <asm/fpu/xcr.h>\n\n#ifdef CONFIG_X86_64\nDECLARE_PER_CPU(u64, xfd_state);\n#endif\n\nstatic inline void xstate_init_xcomp_bv(struct xregs_state *xsave, u64 mask)\n{\n\t \n\tif (cpu_feature_enabled(X86_FEATURE_XCOMPACTED))\n\t\txsave->header.xcomp_bv = mask | XCOMP_BV_COMPACTED_FORMAT;\n}\n\nstatic inline u64 xstate_get_group_perm(bool guest)\n{\n\tstruct fpu *fpu = &current->group_leader->thread.fpu;\n\tstruct fpu_state_perm *perm;\n\n\t \n\tperm = guest ? &fpu->guest_perm : &fpu->perm;\n\treturn READ_ONCE(perm->__state_perm);\n}\n\nstatic inline u64 xstate_get_host_group_perm(void)\n{\n\treturn xstate_get_group_perm(false);\n}\n\nenum xstate_copy_mode {\n\tXSTATE_COPY_FP,\n\tXSTATE_COPY_FX,\n\tXSTATE_COPY_XSAVE,\n};\n\nstruct membuf;\nextern void __copy_xstate_to_uabi_buf(struct membuf to, struct fpstate *fpstate,\n\t\t\t\t      u64 xfeatures, u32 pkru_val,\n\t\t\t\t      enum xstate_copy_mode copy_mode);\nextern void copy_xstate_to_uabi_buf(struct membuf to, struct task_struct *tsk,\n\t\t\t\t    enum xstate_copy_mode mode);\nextern int copy_uabi_from_kernel_to_xstate(struct fpstate *fpstate, const void *kbuf, u32 *pkru);\nextern int copy_sigframe_from_user_to_xstate(struct task_struct *tsk, const void __user *ubuf);\n\n\nextern void fpu__init_cpu_xstate(void);\nextern void fpu__init_system_xstate(unsigned int legacy_size);\n\nextern void *get_xsave_addr(struct xregs_state *xsave, int xfeature_nr);\n\nstatic inline u64 xfeatures_mask_supervisor(void)\n{\n\treturn fpu_kernel_cfg.max_features & XFEATURE_MASK_SUPERVISOR_SUPPORTED;\n}\n\nstatic inline u64 xfeatures_mask_independent(void)\n{\n\tif (!cpu_feature_enabled(X86_FEATURE_ARCH_LBR))\n\t\treturn XFEATURE_MASK_INDEPENDENT & ~XFEATURE_MASK_LBR;\n\n\treturn XFEATURE_MASK_INDEPENDENT;\n}\n\n \n\n#ifdef CONFIG_X86_64\n#define REX_PREFIX\t\"0x48, \"\n#else\n#define REX_PREFIX\n#endif\n\n \n#define XSAVE\t\t\".byte \" REX_PREFIX \"0x0f,0xae,0x27\"\n#define XSAVEOPT\t\".byte \" REX_PREFIX \"0x0f,0xae,0x37\"\n#define XSAVEC\t\t\".byte \" REX_PREFIX \"0x0f,0xc7,0x27\"\n#define XSAVES\t\t\".byte \" REX_PREFIX \"0x0f,0xc7,0x2f\"\n#define XRSTOR\t\t\".byte \" REX_PREFIX \"0x0f,0xae,0x2f\"\n#define XRSTORS\t\t\".byte \" REX_PREFIX \"0x0f,0xc7,0x1f\"\n\n \n#define XSTATE_OP(op, st, lmask, hmask, err)\t\t\t\t\\\n\tasm volatile(\"1:\" op \"\\n\\t\"\t\t\t\t\t\\\n\t\t     \"xor %[err], %[err]\\n\"\t\t\t\t\\\n\t\t     \"2:\\n\\t\"\t\t\t\t\t\t\\\n\t\t     _ASM_EXTABLE_TYPE(1b, 2b, EX_TYPE_FAULT_MCE_SAFE)\t\\\n\t\t     : [err] \"=a\" (err)\t\t\t\t\t\\\n\t\t     : \"D\" (st), \"m\" (*st), \"a\" (lmask), \"d\" (hmask)\t\\\n\t\t     : \"memory\")\n\n \n#define XSTATE_XSAVE(st, lmask, hmask, err)\t\t\t\t\\\n\tasm volatile(ALTERNATIVE_3(XSAVE,\t\t\t\t\\\n\t\t\t\t   XSAVEOPT, X86_FEATURE_XSAVEOPT,\t\\\n\t\t\t\t   XSAVEC,   X86_FEATURE_XSAVEC,\t\\\n\t\t\t\t   XSAVES,   X86_FEATURE_XSAVES)\t\\\n\t\t     \"\\n\"\t\t\t\t\t\t\\\n\t\t     \"xor %[err], %[err]\\n\"\t\t\t\t\\\n\t\t     \"3:\\n\"\t\t\t\t\t\t\\\n\t\t     _ASM_EXTABLE_TYPE_REG(661b, 3b, EX_TYPE_EFAULT_REG, %[err]) \\\n\t\t     : [err] \"=r\" (err)\t\t\t\t\t\\\n\t\t     : \"D\" (st), \"m\" (*st), \"a\" (lmask), \"d\" (hmask)\t\\\n\t\t     : \"memory\")\n\n \n#define XSTATE_XRESTORE(st, lmask, hmask)\t\t\t\t\\\n\tasm volatile(ALTERNATIVE(XRSTOR,\t\t\t\t\\\n\t\t\t\t XRSTORS, X86_FEATURE_XSAVES)\t\t\\\n\t\t     \"\\n\"\t\t\t\t\t\t\\\n\t\t     \"3:\\n\"\t\t\t\t\t\t\\\n\t\t     _ASM_EXTABLE_TYPE(661b, 3b, EX_TYPE_FPU_RESTORE)\t\\\n\t\t     :\t\t\t\t\t\t\t\\\n\t\t     : \"D\" (st), \"m\" (*st), \"a\" (lmask), \"d\" (hmask)\t\\\n\t\t     : \"memory\")\n\n#if defined(CONFIG_X86_64) && defined(CONFIG_X86_DEBUG_FPU)\nextern void xfd_validate_state(struct fpstate *fpstate, u64 mask, bool rstor);\n#else\nstatic inline void xfd_validate_state(struct fpstate *fpstate, u64 mask, bool rstor) { }\n#endif\n\n#ifdef CONFIG_X86_64\nstatic inline void xfd_update_state(struct fpstate *fpstate)\n{\n\tif (fpu_state_size_dynamic()) {\n\t\tu64 xfd = fpstate->xfd;\n\n\t\tif (__this_cpu_read(xfd_state) != xfd) {\n\t\t\twrmsrl(MSR_IA32_XFD, xfd);\n\t\t\t__this_cpu_write(xfd_state, xfd);\n\t\t}\n\t}\n}\n\nextern int __xfd_enable_feature(u64 which, struct fpu_guest *guest_fpu);\n#else\nstatic inline void xfd_update_state(struct fpstate *fpstate) { }\n\nstatic inline int __xfd_enable_feature(u64 which, struct fpu_guest *guest_fpu) {\n\treturn -EPERM;\n}\n#endif\n\n \nstatic inline void os_xsave(struct fpstate *fpstate)\n{\n\tu64 mask = fpstate->xfeatures;\n\tu32 lmask = mask;\n\tu32 hmask = mask >> 32;\n\tint err;\n\n\tWARN_ON_FPU(!alternatives_patched);\n\txfd_validate_state(fpstate, mask, false);\n\n\tXSTATE_XSAVE(&fpstate->regs.xsave, lmask, hmask, err);\n\n\t \n\tWARN_ON_FPU(err);\n}\n\n \nstatic inline void os_xrstor(struct fpstate *fpstate, u64 mask)\n{\n\tu32 lmask = mask;\n\tu32 hmask = mask >> 32;\n\n\txfd_validate_state(fpstate, mask, true);\n\tXSTATE_XRESTORE(&fpstate->regs.xsave, lmask, hmask);\n}\n\n \nstatic inline void os_xrstor_supervisor(struct fpstate *fpstate)\n{\n\tu64 mask = xfeatures_mask_supervisor();\n\tu32 lmask = mask;\n\tu32 hmask = mask >> 32;\n\n\tXSTATE_XRESTORE(&fpstate->regs.xsave, lmask, hmask);\n}\n\n \nstatic inline u64 xfeatures_need_sigframe_write(void)\n{\n\tu64 xfeaures_to_write;\n\n\t \n\txfeaures_to_write = xfeatures_in_use();\n\n\t \n\txfeaures_to_write |= XFEATURE_MASK_USER_SUPPORTED &\n\t\t\t     ~XFEATURE_MASK_SIGFRAME_INITOPT;\n\n\treturn xfeaures_to_write;\n}\n\n \nstatic inline int xsave_to_user_sigframe(struct xregs_state __user *buf)\n{\n\t \n\tstruct fpstate *fpstate = current->thread.fpu.fpstate;\n\tu64 mask = fpstate->user_xfeatures;\n\tu32 lmask;\n\tu32 hmask;\n\tint err;\n\n\t \n\tif (fpu_state_size_dynamic())\n\t\tmask &= xfeatures_need_sigframe_write();\n\n\tlmask = mask;\n\thmask = mask >> 32;\n\txfd_validate_state(fpstate, mask, false);\n\n\tstac();\n\tXSTATE_OP(XSAVE, buf, lmask, hmask, err);\n\tclac();\n\n\treturn err;\n}\n\n \nstatic inline int xrstor_from_user_sigframe(struct xregs_state __user *buf, u64 mask)\n{\n\tstruct xregs_state *xstate = ((__force struct xregs_state *)buf);\n\tu32 lmask = mask;\n\tu32 hmask = mask >> 32;\n\tint err;\n\n\txfd_validate_state(current->thread.fpu.fpstate, mask, true);\n\n\tstac();\n\tXSTATE_OP(XRSTOR, xstate, lmask, hmask, err);\n\tclac();\n\n\treturn err;\n}\n\n \nstatic inline int os_xrstor_safe(struct fpstate *fpstate, u64 mask)\n{\n\tstruct xregs_state *xstate = &fpstate->regs.xsave;\n\tu32 lmask = mask;\n\tu32 hmask = mask >> 32;\n\tint err;\n\n\t \n\txfd_update_state(fpstate);\n\n\tif (cpu_feature_enabled(X86_FEATURE_XSAVES))\n\t\tXSTATE_OP(XRSTORS, xstate, lmask, hmask, err);\n\telse\n\t\tXSTATE_OP(XRSTOR, xstate, lmask, hmask, err);\n\n\treturn err;\n}\n\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}