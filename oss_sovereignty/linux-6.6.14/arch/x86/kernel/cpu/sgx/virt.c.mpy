{
  "module_name": "virt.c",
  "hash_id": "56c39326b6b6d5cd16d3e8b7cedffc3156064549fa2639e4651f4bcb6ed4b941",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/cpu/sgx/virt.c",
  "human_readable_source": "\n \n\n#include <linux/miscdevice.h>\n#include <linux/mm.h>\n#include <linux/mman.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/xarray.h>\n#include <asm/sgx.h>\n#include <uapi/asm/sgx.h>\n\n#include \"encls.h\"\n#include \"sgx.h\"\n\nstruct sgx_vepc {\n\tstruct xarray page_array;\n\tstruct mutex lock;\n};\n\n \nstatic struct mutex zombie_secs_pages_lock;\nstatic struct list_head zombie_secs_pages;\n\nstatic int __sgx_vepc_fault(struct sgx_vepc *vepc,\n\t\t\t    struct vm_area_struct *vma, unsigned long addr)\n{\n\tstruct sgx_epc_page *epc_page;\n\tunsigned long index, pfn;\n\tint ret;\n\n\tWARN_ON(!mutex_is_locked(&vepc->lock));\n\n\t \n\tindex = vma->vm_pgoff + PFN_DOWN(addr - vma->vm_start);\n\n\tepc_page = xa_load(&vepc->page_array, index);\n\tif (epc_page)\n\t\treturn 0;\n\n\tepc_page = sgx_alloc_epc_page(vepc, false);\n\tif (IS_ERR(epc_page))\n\t\treturn PTR_ERR(epc_page);\n\n\tret = xa_err(xa_store(&vepc->page_array, index, epc_page, GFP_KERNEL));\n\tif (ret)\n\t\tgoto err_free;\n\n\tpfn = PFN_DOWN(sgx_get_epc_phys_addr(epc_page));\n\n\tret = vmf_insert_pfn(vma, addr, pfn);\n\tif (ret != VM_FAULT_NOPAGE) {\n\t\tret = -EFAULT;\n\t\tgoto err_delete;\n\t}\n\n\treturn 0;\n\nerr_delete:\n\txa_erase(&vepc->page_array, index);\nerr_free:\n\tsgx_free_epc_page(epc_page);\n\treturn ret;\n}\n\nstatic vm_fault_t sgx_vepc_fault(struct vm_fault *vmf)\n{\n\tstruct vm_area_struct *vma = vmf->vma;\n\tstruct sgx_vepc *vepc = vma->vm_private_data;\n\tint ret;\n\n\tmutex_lock(&vepc->lock);\n\tret = __sgx_vepc_fault(vepc, vma, vmf->address);\n\tmutex_unlock(&vepc->lock);\n\n\tif (!ret)\n\t\treturn VM_FAULT_NOPAGE;\n\n\tif (ret == -EBUSY && (vmf->flags & FAULT_FLAG_ALLOW_RETRY)) {\n\t\tmmap_read_unlock(vma->vm_mm);\n\t\treturn VM_FAULT_RETRY;\n\t}\n\n\treturn VM_FAULT_SIGBUS;\n}\n\nstatic const struct vm_operations_struct sgx_vepc_vm_ops = {\n\t.fault = sgx_vepc_fault,\n};\n\nstatic int sgx_vepc_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct sgx_vepc *vepc = file->private_data;\n\n\tif (!(vma->vm_flags & VM_SHARED))\n\t\treturn -EINVAL;\n\n\tvma->vm_ops = &sgx_vepc_vm_ops;\n\t \n\tvm_flags_set(vma, VM_PFNMAP | VM_IO | VM_DONTDUMP | VM_DONTCOPY);\n\tvma->vm_private_data = vepc;\n\n\treturn 0;\n}\n\nstatic int sgx_vepc_remove_page(struct sgx_epc_page *epc_page)\n{\n\t \n\treturn __eremove(sgx_get_epc_virt_addr(epc_page));\n}\n\nstatic int sgx_vepc_free_page(struct sgx_epc_page *epc_page)\n{\n\tint ret = sgx_vepc_remove_page(epc_page);\n\tif (ret) {\n\t\t \n\t\tWARN_ONCE(ret != SGX_CHILD_PRESENT, EREMOVE_ERROR_MESSAGE,\n\t\t\t  ret, ret);\n\t\treturn ret;\n\t}\n\n\tsgx_free_epc_page(epc_page);\n\treturn 0;\n}\n\nstatic long sgx_vepc_remove_all(struct sgx_vepc *vepc)\n{\n\tstruct sgx_epc_page *entry;\n\tunsigned long index;\n\tlong failures = 0;\n\n\txa_for_each(&vepc->page_array, index, entry) {\n\t\tint ret = sgx_vepc_remove_page(entry);\n\t\tif (ret) {\n\t\t\tif (ret == SGX_CHILD_PRESENT) {\n\t\t\t\t \n\t\t\t\tfailures++;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tWARN_ON_ONCE(encls_faulted(ret) &&\n\t\t\t\t\t     ENCLS_TRAPNR(ret) != X86_TRAP_GP);\n\t\t\t\treturn -EBUSY;\n\t\t\t}\n\t\t}\n\t\tcond_resched();\n\t}\n\n\t \n\treturn failures;\n}\n\nstatic int sgx_vepc_release(struct inode *inode, struct file *file)\n{\n\tstruct sgx_vepc *vepc = file->private_data;\n\tstruct sgx_epc_page *epc_page, *tmp, *entry;\n\tunsigned long index;\n\n\tLIST_HEAD(secs_pages);\n\n\txa_for_each(&vepc->page_array, index, entry) {\n\t\t \n\t\tif (sgx_vepc_free_page(entry))\n\t\t\tcontinue;\n\n\t\txa_erase(&vepc->page_array, index);\n\t\tcond_resched();\n\t}\n\n\t \n\txa_for_each(&vepc->page_array, index, entry) {\n\t\tepc_page = entry;\n\t\t \n\t\tif (sgx_vepc_free_page(epc_page))\n\t\t\tlist_add_tail(&epc_page->list, &secs_pages);\n\n\t\txa_erase(&vepc->page_array, index);\n\t\tcond_resched();\n\t}\n\n\t \n\tmutex_lock(&zombie_secs_pages_lock);\n\tlist_for_each_entry_safe(epc_page, tmp, &zombie_secs_pages, list) {\n\t\t \n\t\tlist_del(&epc_page->list);\n\n\t\tif (sgx_vepc_free_page(epc_page))\n\t\t\tlist_add_tail(&epc_page->list, &secs_pages);\n\t\tcond_resched();\n\t}\n\n\tif (!list_empty(&secs_pages))\n\t\tlist_splice_tail(&secs_pages, &zombie_secs_pages);\n\tmutex_unlock(&zombie_secs_pages_lock);\n\n\txa_destroy(&vepc->page_array);\n\tkfree(vepc);\n\n\treturn 0;\n}\n\nstatic int sgx_vepc_open(struct inode *inode, struct file *file)\n{\n\tstruct sgx_vepc *vepc;\n\n\tvepc = kzalloc(sizeof(struct sgx_vepc), GFP_KERNEL);\n\tif (!vepc)\n\t\treturn -ENOMEM;\n\tmutex_init(&vepc->lock);\n\txa_init(&vepc->page_array);\n\n\tfile->private_data = vepc;\n\n\treturn 0;\n}\n\nstatic long sgx_vepc_ioctl(struct file *file,\n\t\t\t   unsigned int cmd, unsigned long arg)\n{\n\tstruct sgx_vepc *vepc = file->private_data;\n\n\tswitch (cmd) {\n\tcase SGX_IOC_VEPC_REMOVE_ALL:\n\t\tif (arg)\n\t\t\treturn -EINVAL;\n\t\treturn sgx_vepc_remove_all(vepc);\n\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n}\n\nstatic const struct file_operations sgx_vepc_fops = {\n\t.owner\t\t= THIS_MODULE,\n\t.open\t\t= sgx_vepc_open,\n\t.unlocked_ioctl\t= sgx_vepc_ioctl,\n\t.compat_ioctl\t= sgx_vepc_ioctl,\n\t.release\t= sgx_vepc_release,\n\t.mmap\t\t= sgx_vepc_mmap,\n};\n\nstatic struct miscdevice sgx_vepc_dev = {\n\t.minor\t\t= MISC_DYNAMIC_MINOR,\n\t.name\t\t= \"sgx_vepc\",\n\t.nodename\t= \"sgx_vepc\",\n\t.fops\t\t= &sgx_vepc_fops,\n};\n\nint __init sgx_vepc_init(void)\n{\n\t \n\tif (!cpu_feature_enabled(X86_FEATURE_VMX))\n\t\treturn -ENODEV;\n\n\tINIT_LIST_HEAD(&zombie_secs_pages);\n\tmutex_init(&zombie_secs_pages_lock);\n\n\treturn misc_register(&sgx_vepc_dev);\n}\n\n \nint sgx_virt_ecreate(struct sgx_pageinfo *pageinfo, void __user *secs,\n\t\t     int *trapnr)\n{\n\tint ret;\n\n\t \n\tif (WARN_ON_ONCE(!access_ok(secs, PAGE_SIZE)))\n\t\treturn -EINVAL;\n\n\t__uaccess_begin();\n\tret = __ecreate(pageinfo, (void *)secs);\n\t__uaccess_end();\n\n\tif (encls_faulted(ret)) {\n\t\t*trapnr = ENCLS_TRAPNR(ret);\n\t\treturn -EFAULT;\n\t}\n\n\t \n\tWARN_ON_ONCE(ret);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(sgx_virt_ecreate);\n\nstatic int __sgx_virt_einit(void __user *sigstruct, void __user *token,\n\t\t\t    void __user *secs)\n{\n\tint ret;\n\n\t \n#define SGX_EINITTOKEN_SIZE\t304\n\tif (WARN_ON_ONCE(!access_ok(sigstruct, sizeof(struct sgx_sigstruct)) ||\n\t\t\t !access_ok(token, SGX_EINITTOKEN_SIZE) ||\n\t\t\t !access_ok(secs, PAGE_SIZE)))\n\t\treturn -EINVAL;\n\n\t__uaccess_begin();\n\tret = __einit((void *)sigstruct, (void *)token, (void *)secs);\n\t__uaccess_end();\n\n\treturn ret;\n}\n\n \nint sgx_virt_einit(void __user *sigstruct, void __user *token,\n\t\t   void __user *secs, u64 *lepubkeyhash, int *trapnr)\n{\n\tint ret;\n\n\tif (!cpu_feature_enabled(X86_FEATURE_SGX_LC)) {\n\t\tret = __sgx_virt_einit(sigstruct, token, secs);\n\t} else {\n\t\tpreempt_disable();\n\n\t\tsgx_update_lepubkeyhash(lepubkeyhash);\n\n\t\tret = __sgx_virt_einit(sigstruct, token, secs);\n\t\tpreempt_enable();\n\t}\n\n\t \n\tif (ret == -EINVAL)\n\t\treturn ret;\n\n\tif (encls_faulted(ret)) {\n\t\t*trapnr = ENCLS_TRAPNR(ret);\n\t\treturn -EFAULT;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(sgx_virt_einit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}