{
  "module_name": "vmware.c",
  "hash_id": "7c101fcfac139243a7c323fa94e42b572a7ca26f3a4e566b783f4de0c1a82ebc",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/cpu/vmware.c",
  "human_readable_source": " \n\n#include <linux/dmi.h>\n#include <linux/init.h>\n#include <linux/export.h>\n#include <linux/clocksource.h>\n#include <linux/cpu.h>\n#include <linux/reboot.h>\n#include <linux/static_call.h>\n#include <asm/div64.h>\n#include <asm/x86_init.h>\n#include <asm/hypervisor.h>\n#include <asm/timer.h>\n#include <asm/apic.h>\n#include <asm/vmware.h>\n#include <asm/svm.h>\n\n#undef pr_fmt\n#define pr_fmt(fmt)\t\"vmware: \" fmt\n\n#define CPUID_VMWARE_INFO_LEAF               0x40000000\n#define CPUID_VMWARE_FEATURES_LEAF           0x40000010\n#define CPUID_VMWARE_FEATURES_ECX_VMMCALL    BIT(0)\n#define CPUID_VMWARE_FEATURES_ECX_VMCALL     BIT(1)\n\n#define VMWARE_HYPERVISOR_MAGIC\t0x564D5868\n\n#define VMWARE_CMD_GETVERSION    10\n#define VMWARE_CMD_GETHZ         45\n#define VMWARE_CMD_GETVCPU_INFO  68\n#define VMWARE_CMD_LEGACY_X2APIC  3\n#define VMWARE_CMD_VCPU_RESERVED 31\n#define VMWARE_CMD_STEALCLOCK    91\n\n#define STEALCLOCK_NOT_AVAILABLE (-1)\n#define STEALCLOCK_DISABLED        0\n#define STEALCLOCK_ENABLED         1\n\n#define VMWARE_PORT(cmd, eax, ebx, ecx, edx)\t\t\t\t\\\n\t__asm__(\"inl (%%dx), %%eax\" :\t\t\t\t\t\\\n\t\t\"=a\"(eax), \"=c\"(ecx), \"=d\"(edx), \"=b\"(ebx) :\t\t\\\n\t\t\"a\"(VMWARE_HYPERVISOR_MAGIC),\t\t\t\t\\\n\t\t\"c\"(VMWARE_CMD_##cmd),\t\t\t\t\t\\\n\t\t\"d\"(VMWARE_HYPERVISOR_PORT), \"b\"(UINT_MAX) :\t\t\\\n\t\t\"memory\")\n\n#define VMWARE_VMCALL(cmd, eax, ebx, ecx, edx)\t\t\t\t\\\n\t__asm__(\"vmcall\" :\t\t\t\t\t\t\\\n\t\t\"=a\"(eax), \"=c\"(ecx), \"=d\"(edx), \"=b\"(ebx) :\t\t\\\n\t\t\"a\"(VMWARE_HYPERVISOR_MAGIC),\t\t\t\t\\\n\t\t\"c\"(VMWARE_CMD_##cmd),\t\t\t\t\t\\\n\t\t\"d\"(0), \"b\"(UINT_MAX) :\t\t\t\t\t\\\n\t\t\"memory\")\n\n#define VMWARE_VMMCALL(cmd, eax, ebx, ecx, edx)                         \\\n\t__asm__(\"vmmcall\" :\t\t\t\t\t\t\\\n\t\t\"=a\"(eax), \"=c\"(ecx), \"=d\"(edx), \"=b\"(ebx) :\t\t\\\n\t\t\"a\"(VMWARE_HYPERVISOR_MAGIC),\t\t\t\t\\\n\t\t\"c\"(VMWARE_CMD_##cmd),\t\t\t\t\t\\\n\t\t\"d\"(0), \"b\"(UINT_MAX) :\t\t\t\t\t\\\n\t\t\"memory\")\n\n#define VMWARE_CMD(cmd, eax, ebx, ecx, edx) do {\t\t\\\n\tswitch (vmware_hypercall_mode) {\t\t\t\\\n\tcase CPUID_VMWARE_FEATURES_ECX_VMCALL:\t\t\t\\\n\t\tVMWARE_VMCALL(cmd, eax, ebx, ecx, edx);\t\t\\\n\t\tbreak;\t\t\t\t\t\t\\\n\tcase CPUID_VMWARE_FEATURES_ECX_VMMCALL:\t\t\t\\\n\t\tVMWARE_VMMCALL(cmd, eax, ebx, ecx, edx);\t\\\n\t\tbreak;\t\t\t\t\t\t\\\n\tdefault:\t\t\t\t\t\t\\\n\t\tVMWARE_PORT(cmd, eax, ebx, ecx, edx);\t\t\\\n\t\tbreak;\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n\nstruct vmware_steal_time {\n\tunion {\n\t\tuint64_t clock;\t \n\t\tstruct {\n\t\t\t \n\t\t\tuint32_t clock_low;\n\t\t\tuint32_t clock_high;\n\t\t};\n\t};\n\tuint64_t reserved[7];\n};\n\nstatic unsigned long vmware_tsc_khz __ro_after_init;\nstatic u8 vmware_hypercall_mode     __ro_after_init;\n\nstatic inline int __vmware_platform(void)\n{\n\tuint32_t eax, ebx, ecx, edx;\n\tVMWARE_CMD(GETVERSION, eax, ebx, ecx, edx);\n\treturn eax != (uint32_t)-1 && ebx == VMWARE_HYPERVISOR_MAGIC;\n}\n\nstatic unsigned long vmware_get_tsc_khz(void)\n{\n\treturn vmware_tsc_khz;\n}\n\n#ifdef CONFIG_PARAVIRT\nstatic struct cyc2ns_data vmware_cyc2ns __ro_after_init;\nstatic bool vmw_sched_clock __initdata = true;\nstatic DEFINE_PER_CPU_DECRYPTED(struct vmware_steal_time, vmw_steal_time) __aligned(64);\nstatic bool has_steal_clock;\nstatic bool steal_acc __initdata = true;  \n\nstatic __init int setup_vmw_sched_clock(char *s)\n{\n\tvmw_sched_clock = false;\n\treturn 0;\n}\nearly_param(\"no-vmw-sched-clock\", setup_vmw_sched_clock);\n\nstatic __init int parse_no_stealacc(char *arg)\n{\n\tsteal_acc = false;\n\treturn 0;\n}\nearly_param(\"no-steal-acc\", parse_no_stealacc);\n\nstatic noinstr u64 vmware_sched_clock(void)\n{\n\tunsigned long long ns;\n\n\tns = mul_u64_u32_shr(rdtsc(), vmware_cyc2ns.cyc2ns_mul,\n\t\t\t     vmware_cyc2ns.cyc2ns_shift);\n\tns -= vmware_cyc2ns.cyc2ns_offset;\n\treturn ns;\n}\n\nstatic void __init vmware_cyc2ns_setup(void)\n{\n\tstruct cyc2ns_data *d = &vmware_cyc2ns;\n\tunsigned long long tsc_now = rdtsc();\n\n\tclocks_calc_mult_shift(&d->cyc2ns_mul, &d->cyc2ns_shift,\n\t\t\t       vmware_tsc_khz, NSEC_PER_MSEC, 0);\n\td->cyc2ns_offset = mul_u64_u32_shr(tsc_now, d->cyc2ns_mul,\n\t\t\t\t\t   d->cyc2ns_shift);\n\n\tpr_info(\"using clock offset of %llu ns\\n\", d->cyc2ns_offset);\n}\n\nstatic int vmware_cmd_stealclock(uint32_t arg1, uint32_t arg2)\n{\n\tuint32_t result, info;\n\n\tasm volatile (VMWARE_HYPERCALL :\n\t\t\"=a\"(result),\n\t\t\"=c\"(info) :\n\t\t\"a\"(VMWARE_HYPERVISOR_MAGIC),\n\t\t\"b\"(0),\n\t\t\"c\"(VMWARE_CMD_STEALCLOCK),\n\t\t\"d\"(0),\n\t\t\"S\"(arg1),\n\t\t\"D\"(arg2) :\n\t\t\"memory\");\n\treturn result;\n}\n\nstatic bool stealclock_enable(phys_addr_t pa)\n{\n\treturn vmware_cmd_stealclock(upper_32_bits(pa),\n\t\t\t\t     lower_32_bits(pa)) == STEALCLOCK_ENABLED;\n}\n\nstatic int __stealclock_disable(void)\n{\n\treturn vmware_cmd_stealclock(0, 1);\n}\n\nstatic void stealclock_disable(void)\n{\n\t__stealclock_disable();\n}\n\nstatic bool vmware_is_stealclock_available(void)\n{\n\treturn __stealclock_disable() != STEALCLOCK_NOT_AVAILABLE;\n}\n\n \nstatic uint64_t vmware_steal_clock(int cpu)\n{\n\tstruct vmware_steal_time *steal = &per_cpu(vmw_steal_time, cpu);\n\tuint64_t clock;\n\n\tif (IS_ENABLED(CONFIG_64BIT))\n\t\tclock = READ_ONCE(steal->clock);\n\telse {\n\t\tuint32_t initial_high, low, high;\n\n\t\tdo {\n\t\t\tinitial_high = READ_ONCE(steal->clock_high);\n\t\t\t \n\t\t\tvirt_rmb();\n\t\t\tlow = READ_ONCE(steal->clock_low);\n\t\t\t \n\t\t\tvirt_rmb();\n\t\t\thigh = READ_ONCE(steal->clock_high);\n\t\t} while (initial_high != high);\n\n\t\tclock = ((uint64_t)high << 32) | low;\n\t}\n\n\treturn mul_u64_u32_shr(clock, vmware_cyc2ns.cyc2ns_mul,\n\t\t\t     vmware_cyc2ns.cyc2ns_shift);\n}\n\nstatic void vmware_register_steal_time(void)\n{\n\tint cpu = smp_processor_id();\n\tstruct vmware_steal_time *st = &per_cpu(vmw_steal_time, cpu);\n\n\tif (!has_steal_clock)\n\t\treturn;\n\n\tif (!stealclock_enable(slow_virt_to_phys(st))) {\n\t\thas_steal_clock = false;\n\t\treturn;\n\t}\n\n\tpr_info(\"vmware-stealtime: cpu %d, pa %llx\\n\",\n\t\tcpu, (unsigned long long) slow_virt_to_phys(st));\n}\n\nstatic void vmware_disable_steal_time(void)\n{\n\tif (!has_steal_clock)\n\t\treturn;\n\n\tstealclock_disable();\n}\n\nstatic void vmware_guest_cpu_init(void)\n{\n\tif (has_steal_clock)\n\t\tvmware_register_steal_time();\n}\n\nstatic void vmware_pv_guest_cpu_reboot(void *unused)\n{\n\tvmware_disable_steal_time();\n}\n\nstatic int vmware_pv_reboot_notify(struct notifier_block *nb,\n\t\t\t\tunsigned long code, void *unused)\n{\n\tif (code == SYS_RESTART)\n\t\ton_each_cpu(vmware_pv_guest_cpu_reboot, NULL, 1);\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block vmware_pv_reboot_nb = {\n\t.notifier_call = vmware_pv_reboot_notify,\n};\n\n#ifdef CONFIG_SMP\nstatic void __init vmware_smp_prepare_boot_cpu(void)\n{\n\tvmware_guest_cpu_init();\n\tnative_smp_prepare_boot_cpu();\n}\n\nstatic int vmware_cpu_online(unsigned int cpu)\n{\n\tlocal_irq_disable();\n\tvmware_guest_cpu_init();\n\tlocal_irq_enable();\n\treturn 0;\n}\n\nstatic int vmware_cpu_down_prepare(unsigned int cpu)\n{\n\tlocal_irq_disable();\n\tvmware_disable_steal_time();\n\tlocal_irq_enable();\n\treturn 0;\n}\n#endif\n\nstatic __init int activate_jump_labels(void)\n{\n\tif (has_steal_clock) {\n\t\tstatic_key_slow_inc(&paravirt_steal_enabled);\n\t\tif (steal_acc)\n\t\t\tstatic_key_slow_inc(&paravirt_steal_rq_enabled);\n\t}\n\n\treturn 0;\n}\narch_initcall(activate_jump_labels);\n\nstatic void __init vmware_paravirt_ops_setup(void)\n{\n\tpv_info.name = \"VMware hypervisor\";\n\tpv_ops.cpu.io_delay = paravirt_nop;\n\n\tif (vmware_tsc_khz == 0)\n\t\treturn;\n\n\tvmware_cyc2ns_setup();\n\n\tif (vmw_sched_clock)\n\t\tparavirt_set_sched_clock(vmware_sched_clock);\n\n\tif (vmware_is_stealclock_available()) {\n\t\thas_steal_clock = true;\n\t\tstatic_call_update(pv_steal_clock, vmware_steal_clock);\n\n\t\t \n\t\tregister_reboot_notifier(&vmware_pv_reboot_nb);\n\n#ifdef CONFIG_SMP\n\t\tsmp_ops.smp_prepare_boot_cpu =\n\t\t\tvmware_smp_prepare_boot_cpu;\n\t\tif (cpuhp_setup_state_nocalls(CPUHP_AP_ONLINE_DYN,\n\t\t\t\t\t      \"x86/vmware:online\",\n\t\t\t\t\t      vmware_cpu_online,\n\t\t\t\t\t      vmware_cpu_down_prepare) < 0)\n\t\t\tpr_err(\"vmware_guest: Failed to install cpu hotplug callbacks\\n\");\n#else\n\t\tvmware_guest_cpu_init();\n#endif\n\t}\n}\n#else\n#define vmware_paravirt_ops_setup() do {} while (0)\n#endif\n\n \nstatic void __init vmware_set_capabilities(void)\n{\n\tsetup_force_cpu_cap(X86_FEATURE_CONSTANT_TSC);\n\tsetup_force_cpu_cap(X86_FEATURE_TSC_RELIABLE);\n\tif (vmware_tsc_khz)\n\t\tsetup_force_cpu_cap(X86_FEATURE_TSC_KNOWN_FREQ);\n\tif (vmware_hypercall_mode == CPUID_VMWARE_FEATURES_ECX_VMCALL)\n\t\tsetup_force_cpu_cap(X86_FEATURE_VMCALL);\n\telse if (vmware_hypercall_mode == CPUID_VMWARE_FEATURES_ECX_VMMCALL)\n\t\tsetup_force_cpu_cap(X86_FEATURE_VMW_VMMCALL);\n}\n\nstatic void __init vmware_platform_setup(void)\n{\n\tuint32_t eax, ebx, ecx, edx;\n\tuint64_t lpj, tsc_khz;\n\n\tVMWARE_CMD(GETHZ, eax, ebx, ecx, edx);\n\n\tif (ebx != UINT_MAX) {\n\t\tlpj = tsc_khz = eax | (((uint64_t)ebx) << 32);\n\t\tdo_div(tsc_khz, 1000);\n\t\tWARN_ON(tsc_khz >> 32);\n\t\tpr_info(\"TSC freq read from hypervisor : %lu.%03lu MHz\\n\",\n\t\t\t(unsigned long) tsc_khz / 1000,\n\t\t\t(unsigned long) tsc_khz % 1000);\n\n\t\tif (!preset_lpj) {\n\t\t\tdo_div(lpj, HZ);\n\t\t\tpreset_lpj = lpj;\n\t\t}\n\n\t\tvmware_tsc_khz = tsc_khz;\n\t\tx86_platform.calibrate_tsc = vmware_get_tsc_khz;\n\t\tx86_platform.calibrate_cpu = vmware_get_tsc_khz;\n\n#ifdef CONFIG_X86_LOCAL_APIC\n\t\t \n\t\tlapic_timer_period = ecx / HZ;\n\t\tpr_info(\"Host bus clock speed read from hypervisor : %u Hz\\n\",\n\t\t\tecx);\n#endif\n\t} else {\n\t\tpr_warn(\"Failed to get TSC freq from the hypervisor\\n\");\n\t}\n\n\tvmware_paravirt_ops_setup();\n\n#ifdef CONFIG_X86_IO_APIC\n\tno_timer_check = 1;\n#endif\n\n\tvmware_set_capabilities();\n}\n\nstatic u8 __init vmware_select_hypercall(void)\n{\n\tint eax, ebx, ecx, edx;\n\n\tcpuid(CPUID_VMWARE_FEATURES_LEAF, &eax, &ebx, &ecx, &edx);\n\treturn (ecx & (CPUID_VMWARE_FEATURES_ECX_VMMCALL |\n\t\t       CPUID_VMWARE_FEATURES_ECX_VMCALL));\n}\n\n \nstatic uint32_t __init vmware_platform(void)\n{\n\tif (boot_cpu_has(X86_FEATURE_HYPERVISOR)) {\n\t\tunsigned int eax;\n\t\tunsigned int hyper_vendor_id[3];\n\n\t\tcpuid(CPUID_VMWARE_INFO_LEAF, &eax, &hyper_vendor_id[0],\n\t\t      &hyper_vendor_id[1], &hyper_vendor_id[2]);\n\t\tif (!memcmp(hyper_vendor_id, \"VMwareVMware\", 12)) {\n\t\t\tif (eax >= CPUID_VMWARE_FEATURES_LEAF)\n\t\t\t\tvmware_hypercall_mode =\n\t\t\t\t\tvmware_select_hypercall();\n\n\t\t\tpr_info(\"hypercall mode: 0x%02x\\n\",\n\t\t\t\t(unsigned int) vmware_hypercall_mode);\n\n\t\t\treturn CPUID_VMWARE_INFO_LEAF;\n\t\t}\n\t} else if (dmi_available && dmi_name_in_serial(\"VMware\") &&\n\t\t   __vmware_platform())\n\t\treturn 1;\n\n\treturn 0;\n}\n\n \nstatic bool __init vmware_legacy_x2apic_available(void)\n{\n\tuint32_t eax, ebx, ecx, edx;\n\tVMWARE_CMD(GETVCPU_INFO, eax, ebx, ecx, edx);\n\treturn !(eax & BIT(VMWARE_CMD_VCPU_RESERVED)) &&\n\t\t(eax & BIT(VMWARE_CMD_LEGACY_X2APIC));\n}\n\n#ifdef CONFIG_AMD_MEM_ENCRYPT\nstatic void vmware_sev_es_hcall_prepare(struct ghcb *ghcb,\n\t\t\t\t\tstruct pt_regs *regs)\n{\n\t \n\tghcb_set_rip(ghcb, regs->ip);\n\tghcb_set_rbx(ghcb, regs->bx);\n\tghcb_set_rcx(ghcb, regs->cx);\n\tghcb_set_rdx(ghcb, regs->dx);\n\tghcb_set_rsi(ghcb, regs->si);\n\tghcb_set_rdi(ghcb, regs->di);\n\tghcb_set_rbp(ghcb, regs->bp);\n}\n\nstatic bool vmware_sev_es_hcall_finish(struct ghcb *ghcb, struct pt_regs *regs)\n{\n\tif (!(ghcb_rbx_is_valid(ghcb) &&\n\t      ghcb_rcx_is_valid(ghcb) &&\n\t      ghcb_rdx_is_valid(ghcb) &&\n\t      ghcb_rsi_is_valid(ghcb) &&\n\t      ghcb_rdi_is_valid(ghcb) &&\n\t      ghcb_rbp_is_valid(ghcb)))\n\t\treturn false;\n\n\tregs->bx = ghcb_get_rbx(ghcb);\n\tregs->cx = ghcb_get_rcx(ghcb);\n\tregs->dx = ghcb_get_rdx(ghcb);\n\tregs->si = ghcb_get_rsi(ghcb);\n\tregs->di = ghcb_get_rdi(ghcb);\n\tregs->bp = ghcb_get_rbp(ghcb);\n\n\treturn true;\n}\n#endif\n\nconst __initconst struct hypervisor_x86 x86_hyper_vmware = {\n\t.name\t\t\t\t= \"VMware\",\n\t.detect\t\t\t\t= vmware_platform,\n\t.type\t\t\t\t= X86_HYPER_VMWARE,\n\t.init.init_platform\t\t= vmware_platform_setup,\n\t.init.x2apic_available\t\t= vmware_legacy_x2apic_available,\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\t.runtime.sev_es_hcall_prepare\t= vmware_sev_es_hcall_prepare,\n\t.runtime.sev_es_hcall_finish\t= vmware_sev_es_hcall_finish,\n#endif\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}