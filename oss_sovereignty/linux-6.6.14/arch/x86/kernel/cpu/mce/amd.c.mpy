{
  "module_name": "amd.c",
  "hash_id": "e8b695f745de493502744a837c76fc396b96741a56e84b4b14a117022f31bfb7",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kernel/cpu/mce/amd.c",
  "human_readable_source": "\n \n#include <linux/interrupt.h>\n#include <linux/notifier.h>\n#include <linux/kobject.h>\n#include <linux/percpu.h>\n#include <linux/errno.h>\n#include <linux/sched.h>\n#include <linux/sysfs.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/string.h>\n\n#include <asm/amd_nb.h>\n#include <asm/traps.h>\n#include <asm/apic.h>\n#include <asm/mce.h>\n#include <asm/msr.h>\n#include <asm/trace/irq_vectors.h>\n\n#include \"internal.h\"\n\n#define NR_BLOCKS         5\n#define THRESHOLD_MAX     0xFFF\n#define INT_TYPE_APIC     0x00020000\n#define MASK_VALID_HI     0x80000000\n#define MASK_CNTP_HI      0x40000000\n#define MASK_LOCKED_HI    0x20000000\n#define MASK_LVTOFF_HI    0x00F00000\n#define MASK_COUNT_EN_HI  0x00080000\n#define MASK_INT_TYPE_HI  0x00060000\n#define MASK_OVERFLOW_HI  0x00010000\n#define MASK_ERR_COUNT_HI 0x00000FFF\n#define MASK_BLKPTR_LO    0xFF000000\n#define MCG_XBLK_ADDR     0xC0000400\n\n \n#define MSR_CU_DEF_ERR\t\t0xC0000410\n#define MASK_DEF_LVTOFF\t\t0x000000F0\n#define MASK_DEF_INT_TYPE\t0x00000006\n#define DEF_LVT_OFF\t\t0x2\n#define DEF_INT_TYPE_APIC\t0x2\n\n \n\n \n#define SMCA_THR_LVT_OFF\t0xF000\n\nstatic bool thresholding_irq_en;\n\nstatic const char * const th_names[] = {\n\t\"load_store\",\n\t\"insn_fetch\",\n\t\"combined_unit\",\n\t\"decode_unit\",\n\t\"northbridge\",\n\t\"execution_unit\",\n};\n\nstatic const char * const smca_umc_block_names[] = {\n\t\"dram_ecc\",\n\t\"misc_umc\"\n};\n\n#define HWID_MCATYPE(hwid, mcatype) (((hwid) << 16) | (mcatype))\n\nstruct smca_hwid {\n\tunsigned int bank_type;\t \n\tu32 hwid_mcatype;\t \n};\n\nstruct smca_bank {\n\tconst struct smca_hwid *hwid;\n\tu32 id;\t\t\t \n\tu8 sysfs_id;\t\t \n};\n\nstatic DEFINE_PER_CPU_READ_MOSTLY(struct smca_bank[MAX_NR_BANKS], smca_banks);\nstatic DEFINE_PER_CPU_READ_MOSTLY(u8[N_SMCA_BANK_TYPES], smca_bank_counts);\n\nstruct smca_bank_name {\n\tconst char *name;\t \n\tconst char *long_name;\t \n};\n\nstatic struct smca_bank_name smca_names[] = {\n\t[SMCA_LS ... SMCA_LS_V2]\t= { \"load_store\",\t\"Load Store Unit\" },\n\t[SMCA_IF]\t\t\t= { \"insn_fetch\",\t\"Instruction Fetch Unit\" },\n\t[SMCA_L2_CACHE]\t\t\t= { \"l2_cache\",\t\t\"L2 Cache\" },\n\t[SMCA_DE]\t\t\t= { \"decode_unit\",\t\"Decode Unit\" },\n\t[SMCA_RESERVED]\t\t\t= { \"reserved\",\t\t\"Reserved\" },\n\t[SMCA_EX]\t\t\t= { \"execution_unit\",\t\"Execution Unit\" },\n\t[SMCA_FP]\t\t\t= { \"floating_point\",\t\"Floating Point Unit\" },\n\t[SMCA_L3_CACHE]\t\t\t= { \"l3_cache\",\t\t\"L3 Cache\" },\n\t[SMCA_CS ... SMCA_CS_V2]\t= { \"coherent_slave\",\t\"Coherent Slave\" },\n\t[SMCA_PIE]\t\t\t= { \"pie\",\t\t\"Power, Interrupts, etc.\" },\n\n\t \n\t[SMCA_UMC]\t\t\t= { \"umc\",\t\t\"Unified Memory Controller\" },\n\t[SMCA_UMC_V2]\t\t\t= { \"umc_v2\",\t\t\"Unified Memory Controller v2\" },\n\t[SMCA_PB]\t\t\t= { \"param_block\",\t\"Parameter Block\" },\n\t[SMCA_PSP ... SMCA_PSP_V2]\t= { \"psp\",\t\t\"Platform Security Processor\" },\n\t[SMCA_SMU ... SMCA_SMU_V2]\t= { \"smu\",\t\t\"System Management Unit\" },\n\t[SMCA_MP5]\t\t\t= { \"mp5\",\t\t\"Microprocessor 5 Unit\" },\n\t[SMCA_MPDMA]\t\t\t= { \"mpdma\",\t\t\"MPDMA Unit\" },\n\t[SMCA_NBIO]\t\t\t= { \"nbio\",\t\t\"Northbridge IO Unit\" },\n\t[SMCA_PCIE ... SMCA_PCIE_V2]\t= { \"pcie\",\t\t\"PCI Express Unit\" },\n\t[SMCA_XGMI_PCS]\t\t\t= { \"xgmi_pcs\",\t\t\"Ext Global Memory Interconnect PCS Unit\" },\n\t[SMCA_NBIF]\t\t\t= { \"nbif\",\t\t\"NBIF Unit\" },\n\t[SMCA_SHUB]\t\t\t= { \"shub\",\t\t\"System Hub Unit\" },\n\t[SMCA_SATA]\t\t\t= { \"sata\",\t\t\"SATA Unit\" },\n\t[SMCA_USB]\t\t\t= { \"usb\",\t\t\"USB Unit\" },\n\t[SMCA_GMI_PCS]\t\t\t= { \"gmi_pcs\",\t\t\"Global Memory Interconnect PCS Unit\" },\n\t[SMCA_XGMI_PHY]\t\t\t= { \"xgmi_phy\",\t\t\"Ext Global Memory Interconnect PHY Unit\" },\n\t[SMCA_WAFL_PHY]\t\t\t= { \"wafl_phy\",\t\t\"WAFL PHY Unit\" },\n\t[SMCA_GMI_PHY]\t\t\t= { \"gmi_phy\",\t\t\"Global Memory Interconnect PHY Unit\" },\n};\n\nstatic const char *smca_get_name(enum smca_bank_types t)\n{\n\tif (t >= N_SMCA_BANK_TYPES)\n\t\treturn NULL;\n\n\treturn smca_names[t].name;\n}\n\nconst char *smca_get_long_name(enum smca_bank_types t)\n{\n\tif (t >= N_SMCA_BANK_TYPES)\n\t\treturn NULL;\n\n\treturn smca_names[t].long_name;\n}\nEXPORT_SYMBOL_GPL(smca_get_long_name);\n\nenum smca_bank_types smca_get_bank_type(unsigned int cpu, unsigned int bank)\n{\n\tstruct smca_bank *b;\n\n\tif (bank >= MAX_NR_BANKS)\n\t\treturn N_SMCA_BANK_TYPES;\n\n\tb = &per_cpu(smca_banks, cpu)[bank];\n\tif (!b->hwid)\n\t\treturn N_SMCA_BANK_TYPES;\n\n\treturn b->hwid->bank_type;\n}\nEXPORT_SYMBOL_GPL(smca_get_bank_type);\n\nstatic const struct smca_hwid smca_hwid_mcatypes[] = {\n\t \n\n\t \n\t{ SMCA_RESERVED, HWID_MCATYPE(0x00, 0x0)\t},\n\n\t \n\t{ SMCA_LS,\t HWID_MCATYPE(0xB0, 0x0)\t},\n\t{ SMCA_LS_V2,\t HWID_MCATYPE(0xB0, 0x10)\t},\n\t{ SMCA_IF,\t HWID_MCATYPE(0xB0, 0x1)\t},\n\t{ SMCA_L2_CACHE, HWID_MCATYPE(0xB0, 0x2)\t},\n\t{ SMCA_DE,\t HWID_MCATYPE(0xB0, 0x3)\t},\n\t \n\t{ SMCA_EX,\t HWID_MCATYPE(0xB0, 0x5)\t},\n\t{ SMCA_FP,\t HWID_MCATYPE(0xB0, 0x6)\t},\n\t{ SMCA_L3_CACHE, HWID_MCATYPE(0xB0, 0x7)\t},\n\n\t \n\t{ SMCA_CS,\t HWID_MCATYPE(0x2E, 0x0)\t},\n\t{ SMCA_PIE,\t HWID_MCATYPE(0x2E, 0x1)\t},\n\t{ SMCA_CS_V2,\t HWID_MCATYPE(0x2E, 0x2)\t},\n\n\t \n\t{ SMCA_UMC,\t HWID_MCATYPE(0x96, 0x0)\t},\n\t{ SMCA_UMC_V2,\t HWID_MCATYPE(0x96, 0x1)\t},\n\n\t \n\t{ SMCA_PB,\t HWID_MCATYPE(0x05, 0x0)\t},\n\n\t \n\t{ SMCA_PSP,\t HWID_MCATYPE(0xFF, 0x0)\t},\n\t{ SMCA_PSP_V2,\t HWID_MCATYPE(0xFF, 0x1)\t},\n\n\t \n\t{ SMCA_SMU,\t HWID_MCATYPE(0x01, 0x0)\t},\n\t{ SMCA_SMU_V2,\t HWID_MCATYPE(0x01, 0x1)\t},\n\n\t \n\t{ SMCA_MP5,\t HWID_MCATYPE(0x01, 0x2)\t},\n\n\t \n\t{ SMCA_MPDMA,\t HWID_MCATYPE(0x01, 0x3)\t},\n\n\t \n\t{ SMCA_NBIO,\t HWID_MCATYPE(0x18, 0x0)\t},\n\n\t \n\t{ SMCA_PCIE,\t HWID_MCATYPE(0x46, 0x0)\t},\n\t{ SMCA_PCIE_V2,\t HWID_MCATYPE(0x46, 0x1)\t},\n\n\t{ SMCA_XGMI_PCS, HWID_MCATYPE(0x50, 0x0)\t},\n\t{ SMCA_NBIF,\t HWID_MCATYPE(0x6C, 0x0)\t},\n\t{ SMCA_SHUB,\t HWID_MCATYPE(0x80, 0x0)\t},\n\t{ SMCA_SATA,\t HWID_MCATYPE(0xA8, 0x0)\t},\n\t{ SMCA_USB,\t HWID_MCATYPE(0xAA, 0x0)\t},\n\t{ SMCA_GMI_PCS,  HWID_MCATYPE(0x241, 0x0)\t},\n\t{ SMCA_XGMI_PHY, HWID_MCATYPE(0x259, 0x0)\t},\n\t{ SMCA_WAFL_PHY, HWID_MCATYPE(0x267, 0x0)\t},\n\t{ SMCA_GMI_PHY,\t HWID_MCATYPE(0x269, 0x0)\t},\n};\n\n \n#define MAX_MCATYPE_NAME_LEN\t30\nstatic char buf_mcatype[MAX_MCATYPE_NAME_LEN];\n\nstatic DEFINE_PER_CPU(struct threshold_bank **, threshold_banks);\n\n \nstatic DEFINE_PER_CPU(u64, bank_map);\n\n \nstatic DEFINE_PER_CPU(u64, smca_misc_banks_map);\n\nstatic void amd_threshold_interrupt(void);\nstatic void amd_deferred_error_interrupt(void);\n\nstatic void default_deferred_error_interrupt(void)\n{\n\tpr_err(\"Unexpected deferred interrupt at vector %x\\n\", DEFERRED_ERROR_VECTOR);\n}\nvoid (*deferred_error_int_vector)(void) = default_deferred_error_interrupt;\n\nstatic void smca_set_misc_banks_map(unsigned int bank, unsigned int cpu)\n{\n\tu32 low, high;\n\n\t \n\tif (rdmsr_safe(MSR_AMD64_SMCA_MCx_CONFIG(bank), &low, &high))\n\t\treturn;\n\n\tif (!(low & MCI_CONFIG_MCAX))\n\t\treturn;\n\n\tif (rdmsr_safe(MSR_AMD64_SMCA_MCx_MISC(bank), &low, &high))\n\t\treturn;\n\n\tif (low & MASK_BLKPTR_LO)\n\t\tper_cpu(smca_misc_banks_map, cpu) |= BIT_ULL(bank);\n\n}\n\nstatic void smca_configure(unsigned int bank, unsigned int cpu)\n{\n\tu8 *bank_counts = this_cpu_ptr(smca_bank_counts);\n\tconst struct smca_hwid *s_hwid;\n\tunsigned int i, hwid_mcatype;\n\tu32 high, low;\n\tu32 smca_config = MSR_AMD64_SMCA_MCx_CONFIG(bank);\n\n\t \n\tif (!rdmsr_safe(smca_config, &low, &high)) {\n\t\t \n\t\thigh |= BIT(0);\n\n\t\t \n\t\tif ((low & BIT(5)) && !((high >> 5) & 0x3))\n\t\t\thigh |= BIT(5);\n\n\t\tthis_cpu_ptr(mce_banks_array)[bank].lsb_in_status = !!(low & BIT(8));\n\n\t\twrmsr(smca_config, low, high);\n\t}\n\n\tsmca_set_misc_banks_map(bank, cpu);\n\n\tif (rdmsr_safe(MSR_AMD64_SMCA_MCx_IPID(bank), &low, &high)) {\n\t\tpr_warn(\"Failed to read MCA_IPID for bank %d\\n\", bank);\n\t\treturn;\n\t}\n\n\thwid_mcatype = HWID_MCATYPE(high & MCI_IPID_HWID,\n\t\t\t\t    (high & MCI_IPID_MCATYPE) >> 16);\n\n\tfor (i = 0; i < ARRAY_SIZE(smca_hwid_mcatypes); i++) {\n\t\ts_hwid = &smca_hwid_mcatypes[i];\n\n\t\tif (hwid_mcatype == s_hwid->hwid_mcatype) {\n\t\t\tthis_cpu_ptr(smca_banks)[bank].hwid = s_hwid;\n\t\t\tthis_cpu_ptr(smca_banks)[bank].id = low;\n\t\t\tthis_cpu_ptr(smca_banks)[bank].sysfs_id = bank_counts[s_hwid->bank_type]++;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstruct thresh_restart {\n\tstruct threshold_block\t*b;\n\tint\t\t\treset;\n\tint\t\t\tset_lvt_off;\n\tint\t\t\tlvt_off;\n\tu16\t\t\told_limit;\n};\n\nstatic inline bool is_shared_bank(int bank)\n{\n\t \n\tif (mce_flags.smca)\n\t\treturn false;\n\n\t \n\treturn (bank == 4);\n}\n\nstatic const char *bank4_names(const struct threshold_block *b)\n{\n\tswitch (b->address) {\n\t \n\tcase 0x00000413:\n\t\treturn \"dram\";\n\n\tcase 0xc0000408:\n\t\treturn \"ht_links\";\n\n\tcase 0xc0000409:\n\t\treturn \"l3_cache\";\n\n\tdefault:\n\t\tWARN(1, \"Funny MSR: 0x%08x\\n\", b->address);\n\t\treturn \"\";\n\t}\n};\n\n\nstatic bool lvt_interrupt_supported(unsigned int bank, u32 msr_high_bits)\n{\n\t \n\tif (bank == 4)\n\t\treturn true;\n\n\t \n\treturn msr_high_bits & BIT(28);\n}\n\nstatic int lvt_off_valid(struct threshold_block *b, int apic, u32 lo, u32 hi)\n{\n\tint msr = (hi & MASK_LVTOFF_HI) >> 20;\n\n\tif (apic < 0) {\n\t\tpr_err(FW_BUG \"cpu %d, failed to setup threshold interrupt \"\n\t\t       \"for bank %d, block %d (MSR%08X=0x%x%08x)\\n\", b->cpu,\n\t\t       b->bank, b->block, b->address, hi, lo);\n\t\treturn 0;\n\t}\n\n\tif (apic != msr) {\n\t\t \n\t\tif (mce_flags.smca)\n\t\t\treturn 0;\n\n\t\tpr_err(FW_BUG \"cpu %d, invalid threshold interrupt offset %d \"\n\t\t       \"for bank %d, block %d (MSR%08X=0x%x%08x)\\n\",\n\t\t       b->cpu, apic, b->bank, b->block, b->address, hi, lo);\n\t\treturn 0;\n\t}\n\n\treturn 1;\n};\n\n \nstatic void threshold_restart_bank(void *_tr)\n{\n\tstruct thresh_restart *tr = _tr;\n\tu32 hi, lo;\n\n\t \n\tif (!this_cpu_read(threshold_banks) && !tr->set_lvt_off)\n\t\treturn;\n\n\trdmsr(tr->b->address, lo, hi);\n\n\tif (tr->b->threshold_limit < (hi & THRESHOLD_MAX))\n\t\ttr->reset = 1;\t \n\n\tif (tr->reset) {\t\t \n\t\thi =\n\t\t    (hi & ~(MASK_ERR_COUNT_HI | MASK_OVERFLOW_HI)) |\n\t\t    (THRESHOLD_MAX - tr->b->threshold_limit);\n\t} else if (tr->old_limit) {\t \n\t\tint new_count = (hi & THRESHOLD_MAX) +\n\t\t    (tr->old_limit - tr->b->threshold_limit);\n\n\t\thi = (hi & ~MASK_ERR_COUNT_HI) |\n\t\t    (new_count & THRESHOLD_MAX);\n\t}\n\n\t \n\thi &= ~MASK_INT_TYPE_HI;\n\n\tif (!tr->b->interrupt_capable)\n\t\tgoto done;\n\n\tif (tr->set_lvt_off) {\n\t\tif (lvt_off_valid(tr->b, tr->lvt_off, lo, hi)) {\n\t\t\t \n\t\t\thi &= ~MASK_LVTOFF_HI;\n\t\t\thi |= tr->lvt_off << 20;\n\t\t}\n\t}\n\n\tif (tr->b->interrupt_enable)\n\t\thi |= INT_TYPE_APIC;\n\n done:\n\n\thi |= MASK_COUNT_EN_HI;\n\twrmsr(tr->b->address, lo, hi);\n}\n\nstatic void mce_threshold_block_init(struct threshold_block *b, int offset)\n{\n\tstruct thresh_restart tr = {\n\t\t.b\t\t\t= b,\n\t\t.set_lvt_off\t\t= 1,\n\t\t.lvt_off\t\t= offset,\n\t};\n\n\tb->threshold_limit\t\t= THRESHOLD_MAX;\n\tthreshold_restart_bank(&tr);\n};\n\nstatic int setup_APIC_mce_threshold(int reserved, int new)\n{\n\tif (reserved < 0 && !setup_APIC_eilvt(new, THRESHOLD_APIC_VECTOR,\n\t\t\t\t\t      APIC_EILVT_MSG_FIX, 0))\n\t\treturn new;\n\n\treturn reserved;\n}\n\nstatic int setup_APIC_deferred_error(int reserved, int new)\n{\n\tif (reserved < 0 && !setup_APIC_eilvt(new, DEFERRED_ERROR_VECTOR,\n\t\t\t\t\t      APIC_EILVT_MSG_FIX, 0))\n\t\treturn new;\n\n\treturn reserved;\n}\n\nstatic void deferred_error_interrupt_enable(struct cpuinfo_x86 *c)\n{\n\tu32 low = 0, high = 0;\n\tint def_offset = -1, def_new;\n\n\tif (rdmsr_safe(MSR_CU_DEF_ERR, &low, &high))\n\t\treturn;\n\n\tdef_new = (low & MASK_DEF_LVTOFF) >> 4;\n\tif (!(low & MASK_DEF_LVTOFF)) {\n\t\tpr_err(FW_BUG \"Your BIOS is not setting up LVT offset 0x2 for deferred error IRQs correctly.\\n\");\n\t\tdef_new = DEF_LVT_OFF;\n\t\tlow = (low & ~MASK_DEF_LVTOFF) | (DEF_LVT_OFF << 4);\n\t}\n\n\tdef_offset = setup_APIC_deferred_error(def_offset, def_new);\n\tif ((def_offset == def_new) &&\n\t    (deferred_error_int_vector != amd_deferred_error_interrupt))\n\t\tdeferred_error_int_vector = amd_deferred_error_interrupt;\n\n\tif (!mce_flags.smca)\n\t\tlow = (low & ~MASK_DEF_INT_TYPE) | DEF_INT_TYPE_APIC;\n\n\twrmsr(MSR_CU_DEF_ERR, low, high);\n}\n\nstatic u32 smca_get_block_address(unsigned int bank, unsigned int block,\n\t\t\t\t  unsigned int cpu)\n{\n\tif (!block)\n\t\treturn MSR_AMD64_SMCA_MCx_MISC(bank);\n\n\tif (!(per_cpu(smca_misc_banks_map, cpu) & BIT_ULL(bank)))\n\t\treturn 0;\n\n\treturn MSR_AMD64_SMCA_MCx_MISCy(bank, block - 1);\n}\n\nstatic u32 get_block_address(u32 current_addr, u32 low, u32 high,\n\t\t\t     unsigned int bank, unsigned int block,\n\t\t\t     unsigned int cpu)\n{\n\tu32 addr = 0, offset = 0;\n\n\tif ((bank >= per_cpu(mce_num_banks, cpu)) || (block >= NR_BLOCKS))\n\t\treturn addr;\n\n\tif (mce_flags.smca)\n\t\treturn smca_get_block_address(bank, block, cpu);\n\n\t \n\tswitch (block) {\n\tcase 0:\n\t\taddr = mca_msr_reg(bank, MCA_MISC);\n\t\tbreak;\n\tcase 1:\n\t\toffset = ((low & MASK_BLKPTR_LO) >> 21);\n\t\tif (offset)\n\t\t\taddr = MCG_XBLK_ADDR + offset;\n\t\tbreak;\n\tdefault:\n\t\taddr = ++current_addr;\n\t}\n\treturn addr;\n}\n\nstatic int\nprepare_threshold_block(unsigned int bank, unsigned int block, u32 addr,\n\t\t\tint offset, u32 misc_high)\n{\n\tunsigned int cpu = smp_processor_id();\n\tu32 smca_low, smca_high;\n\tstruct threshold_block b;\n\tint new;\n\n\tif (!block)\n\t\tper_cpu(bank_map, cpu) |= BIT_ULL(bank);\n\n\tmemset(&b, 0, sizeof(b));\n\tb.cpu\t\t\t= cpu;\n\tb.bank\t\t\t= bank;\n\tb.block\t\t\t= block;\n\tb.address\t\t= addr;\n\tb.interrupt_capable\t= lvt_interrupt_supported(bank, misc_high);\n\n\tif (!b.interrupt_capable)\n\t\tgoto done;\n\n\tb.interrupt_enable = 1;\n\n\tif (!mce_flags.smca) {\n\t\tnew = (misc_high & MASK_LVTOFF_HI) >> 20;\n\t\tgoto set_offset;\n\t}\n\n\t \n\tif (rdmsr_safe(MSR_CU_DEF_ERR, &smca_low, &smca_high))\n\t\tgoto out;\n\n\tnew = (smca_low & SMCA_THR_LVT_OFF) >> 12;\n\nset_offset:\n\toffset = setup_APIC_mce_threshold(offset, new);\n\tif (offset == new)\n\t\tthresholding_irq_en = true;\n\ndone:\n\tmce_threshold_block_init(&b, offset);\n\nout:\n\treturn offset;\n}\n\nbool amd_filter_mce(struct mce *m)\n{\n\tenum smca_bank_types bank_type = smca_get_bank_type(m->extcpu, m->bank);\n\tstruct cpuinfo_x86 *c = &boot_cpu_data;\n\n\t \n\tif (c->x86 == 0x17 &&\n\t    c->x86_model >= 0x10 && c->x86_model <= 0x2F &&\n\t    bank_type == SMCA_IF && XEC(m->status, 0x3f) == 10)\n\t\treturn true;\n\n\t \n\tif (c->x86 < 0x17) {\n\t\tif (m->bank == 4 && XEC(m->status, 0x1f) == 0x5)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nstatic void disable_err_thresholding(struct cpuinfo_x86 *c, unsigned int bank)\n{\n\tint i, num_msrs;\n\tu64 hwcr;\n\tbool need_toggle;\n\tu32 msrs[NR_BLOCKS];\n\n\tif (c->x86 == 0x15 && bank == 4) {\n\t\tmsrs[0] = 0x00000413;  \n\t\tmsrs[1] = 0xc0000408;  \n\t\tnum_msrs = 2;\n\t} else if (c->x86 == 0x17 &&\n\t\t   (c->x86_model >= 0x10 && c->x86_model <= 0x2F)) {\n\n\t\tif (smca_get_bank_type(smp_processor_id(), bank) != SMCA_IF)\n\t\t\treturn;\n\n\t\tmsrs[0] = MSR_AMD64_SMCA_MCx_MISC(bank);\n\t\tnum_msrs = 1;\n\t} else {\n\t\treturn;\n\t}\n\n\trdmsrl(MSR_K7_HWCR, hwcr);\n\n\t \n\tneed_toggle = !(hwcr & BIT(18));\n\tif (need_toggle)\n\t\twrmsrl(MSR_K7_HWCR, hwcr | BIT(18));\n\n\t \n\tfor (i = 0; i < num_msrs; i++)\n\t\tmsr_clear_bit(msrs[i], 62);\n\n\t \n\tif (need_toggle)\n\t\twrmsrl(MSR_K7_HWCR, hwcr);\n}\n\n \nvoid mce_amd_feature_init(struct cpuinfo_x86 *c)\n{\n\tunsigned int bank, block, cpu = smp_processor_id();\n\tu32 low = 0, high = 0, address = 0;\n\tint offset = -1;\n\n\n\tfor (bank = 0; bank < this_cpu_read(mce_num_banks); ++bank) {\n\t\tif (mce_flags.smca)\n\t\t\tsmca_configure(bank, cpu);\n\n\t\tdisable_err_thresholding(c, bank);\n\n\t\tfor (block = 0; block < NR_BLOCKS; ++block) {\n\t\t\taddress = get_block_address(address, low, high, bank, block, cpu);\n\t\t\tif (!address)\n\t\t\t\tbreak;\n\n\t\t\tif (rdmsr_safe(address, &low, &high))\n\t\t\t\tbreak;\n\n\t\t\tif (!(high & MASK_VALID_HI))\n\t\t\t\tcontinue;\n\n\t\t\tif (!(high & MASK_CNTP_HI)  ||\n\t\t\t     (high & MASK_LOCKED_HI))\n\t\t\t\tcontinue;\n\n\t\t\toffset = prepare_threshold_block(bank, block, address, offset, high);\n\t\t}\n\t}\n\n\tif (mce_flags.succor)\n\t\tdeferred_error_interrupt_enable(c);\n}\n\nbool amd_mce_is_memory_error(struct mce *m)\n{\n\tenum smca_bank_types bank_type;\n\t \n\tu8 xec = (m->status >> 16) & 0x1f;\n\n\tbank_type = smca_get_bank_type(m->extcpu, m->bank);\n\tif (mce_flags.smca)\n\t\treturn (bank_type == SMCA_UMC || bank_type == SMCA_UMC_V2) && xec == 0x0;\n\n\treturn m->bank == 4 && xec == 0x8;\n}\n\nstatic void __log_error(unsigned int bank, u64 status, u64 addr, u64 misc)\n{\n\tstruct mce m;\n\n\tmce_setup(&m);\n\n\tm.status = status;\n\tm.misc   = misc;\n\tm.bank   = bank;\n\tm.tsc\t = rdtsc();\n\n\tif (m.status & MCI_STATUS_ADDRV) {\n\t\tm.addr = addr;\n\n\t\tsmca_extract_err_addr(&m);\n\t}\n\n\tif (mce_flags.smca) {\n\t\trdmsrl(MSR_AMD64_SMCA_MCx_IPID(bank), m.ipid);\n\n\t\tif (m.status & MCI_STATUS_SYNDV)\n\t\t\trdmsrl(MSR_AMD64_SMCA_MCx_SYND(bank), m.synd);\n\t}\n\n\tmce_log(&m);\n}\n\nDEFINE_IDTENTRY_SYSVEC(sysvec_deferred_error)\n{\n\ttrace_deferred_error_apic_entry(DEFERRED_ERROR_VECTOR);\n\tinc_irq_stat(irq_deferred_error_count);\n\tdeferred_error_int_vector();\n\ttrace_deferred_error_apic_exit(DEFERRED_ERROR_VECTOR);\n\tapic_eoi();\n}\n\n \nstatic inline bool\n_log_error_bank(unsigned int bank, u32 msr_stat, u32 msr_addr, u64 misc)\n{\n\tu64 status, addr = 0;\n\n\trdmsrl(msr_stat, status);\n\tif (!(status & MCI_STATUS_VAL))\n\t\treturn false;\n\n\tif (status & MCI_STATUS_ADDRV)\n\t\trdmsrl(msr_addr, addr);\n\n\t__log_error(bank, status, addr, misc);\n\n\twrmsrl(msr_stat, 0);\n\n\treturn status & MCI_STATUS_DEFERRED;\n}\n\nstatic bool _log_error_deferred(unsigned int bank, u32 misc)\n{\n\tif (!_log_error_bank(bank, mca_msr_reg(bank, MCA_STATUS),\n\t\t\t     mca_msr_reg(bank, MCA_ADDR), misc))\n\t\treturn false;\n\n\t \n\tif (!mce_flags.smca)\n\t\treturn true;\n\n\t \n\twrmsrl(MSR_AMD64_SMCA_MCx_DESTAT(bank), 0);\n\treturn true;\n}\n\n \nstatic void log_error_deferred(unsigned int bank)\n{\n\tif (_log_error_deferred(bank, 0))\n\t\treturn;\n\n\t \n\t_log_error_bank(bank, MSR_AMD64_SMCA_MCx_DESTAT(bank),\n\t\t\t      MSR_AMD64_SMCA_MCx_DEADDR(bank), 0);\n}\n\n \nstatic void amd_deferred_error_interrupt(void)\n{\n\tunsigned int bank;\n\n\tfor (bank = 0; bank < this_cpu_read(mce_num_banks); ++bank)\n\t\tlog_error_deferred(bank);\n}\n\nstatic void log_error_thresholding(unsigned int bank, u64 misc)\n{\n\t_log_error_deferred(bank, misc);\n}\n\nstatic void log_and_reset_block(struct threshold_block *block)\n{\n\tstruct thresh_restart tr;\n\tu32 low = 0, high = 0;\n\n\tif (!block)\n\t\treturn;\n\n\tif (rdmsr_safe(block->address, &low, &high))\n\t\treturn;\n\n\tif (!(high & MASK_OVERFLOW_HI))\n\t\treturn;\n\n\t \n\tlog_error_thresholding(block->bank, ((u64)high << 32) | low);\n\n\t \n\tmemset(&tr, 0, sizeof(tr));\n\ttr.b = block;\n\tthreshold_restart_bank(&tr);\n}\n\n \nstatic void amd_threshold_interrupt(void)\n{\n\tstruct threshold_block *first_block = NULL, *block = NULL, *tmp = NULL;\n\tstruct threshold_bank **bp = this_cpu_read(threshold_banks);\n\tunsigned int bank, cpu = smp_processor_id();\n\n\t \n\tif (!bp)\n\t\treturn;\n\n\tfor (bank = 0; bank < this_cpu_read(mce_num_banks); ++bank) {\n\t\tif (!(per_cpu(bank_map, cpu) & BIT_ULL(bank)))\n\t\t\tcontinue;\n\n\t\tfirst_block = bp[bank]->blocks;\n\t\tif (!first_block)\n\t\t\tcontinue;\n\n\t\t \n\t\tlog_and_reset_block(first_block);\n\t\tlist_for_each_entry_safe(block, tmp, &first_block->miscj, miscj)\n\t\t\tlog_and_reset_block(block);\n\t}\n}\n\n \n\nstruct threshold_attr {\n\tstruct attribute attr;\n\tssize_t (*show) (struct threshold_block *, char *);\n\tssize_t (*store) (struct threshold_block *, const char *, size_t count);\n};\n\n#define SHOW_FIELDS(name)\t\t\t\t\t\t\\\nstatic ssize_t show_ ## name(struct threshold_block *b, char *buf)\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\treturn sprintf(buf, \"%lu\\n\", (unsigned long) b->name);\t\t\\\n}\nSHOW_FIELDS(interrupt_enable)\nSHOW_FIELDS(threshold_limit)\n\nstatic ssize_t\nstore_interrupt_enable(struct threshold_block *b, const char *buf, size_t size)\n{\n\tstruct thresh_restart tr;\n\tunsigned long new;\n\n\tif (!b->interrupt_capable)\n\t\treturn -EINVAL;\n\n\tif (kstrtoul(buf, 0, &new) < 0)\n\t\treturn -EINVAL;\n\n\tb->interrupt_enable = !!new;\n\n\tmemset(&tr, 0, sizeof(tr));\n\ttr.b\t\t= b;\n\n\tif (smp_call_function_single(b->cpu, threshold_restart_bank, &tr, 1))\n\t\treturn -ENODEV;\n\n\treturn size;\n}\n\nstatic ssize_t\nstore_threshold_limit(struct threshold_block *b, const char *buf, size_t size)\n{\n\tstruct thresh_restart tr;\n\tunsigned long new;\n\n\tif (kstrtoul(buf, 0, &new) < 0)\n\t\treturn -EINVAL;\n\n\tif (new > THRESHOLD_MAX)\n\t\tnew = THRESHOLD_MAX;\n\tif (new < 1)\n\t\tnew = 1;\n\n\tmemset(&tr, 0, sizeof(tr));\n\ttr.old_limit = b->threshold_limit;\n\tb->threshold_limit = new;\n\ttr.b = b;\n\n\tif (smp_call_function_single(b->cpu, threshold_restart_bank, &tr, 1))\n\t\treturn -ENODEV;\n\n\treturn size;\n}\n\nstatic ssize_t show_error_count(struct threshold_block *b, char *buf)\n{\n\tu32 lo, hi;\n\n\t \n\tif (rdmsr_on_cpu(b->cpu, b->address, &lo, &hi))\n\t\treturn -ENODEV;\n\n\treturn sprintf(buf, \"%u\\n\", ((hi & THRESHOLD_MAX) -\n\t\t\t\t     (THRESHOLD_MAX - b->threshold_limit)));\n}\n\nstatic struct threshold_attr error_count = {\n\t.attr = {.name = __stringify(error_count), .mode = 0444 },\n\t.show = show_error_count,\n};\n\n#define RW_ATTR(val)\t\t\t\t\t\t\t\\\nstatic struct threshold_attr val = {\t\t\t\t\t\\\n\t.attr\t= {.name = __stringify(val), .mode = 0644 },\t\t\\\n\t.show\t= show_## val,\t\t\t\t\t\t\\\n\t.store\t= store_## val,\t\t\t\t\t\t\\\n};\n\nRW_ATTR(interrupt_enable);\nRW_ATTR(threshold_limit);\n\nstatic struct attribute *default_attrs[] = {\n\t&threshold_limit.attr,\n\t&error_count.attr,\n\tNULL,\t \n\tNULL,\n};\nATTRIBUTE_GROUPS(default);\n\n#define to_block(k)\tcontainer_of(k, struct threshold_block, kobj)\n#define to_attr(a)\tcontainer_of(a, struct threshold_attr, attr)\n\nstatic ssize_t show(struct kobject *kobj, struct attribute *attr, char *buf)\n{\n\tstruct threshold_block *b = to_block(kobj);\n\tstruct threshold_attr *a = to_attr(attr);\n\tssize_t ret;\n\n\tret = a->show ? a->show(b, buf) : -EIO;\n\n\treturn ret;\n}\n\nstatic ssize_t store(struct kobject *kobj, struct attribute *attr,\n\t\t     const char *buf, size_t count)\n{\n\tstruct threshold_block *b = to_block(kobj);\n\tstruct threshold_attr *a = to_attr(attr);\n\tssize_t ret;\n\n\tret = a->store ? a->store(b, buf, count) : -EIO;\n\n\treturn ret;\n}\n\nstatic const struct sysfs_ops threshold_ops = {\n\t.show\t\t\t= show,\n\t.store\t\t\t= store,\n};\n\nstatic void threshold_block_release(struct kobject *kobj);\n\nstatic const struct kobj_type threshold_ktype = {\n\t.sysfs_ops\t\t= &threshold_ops,\n\t.default_groups\t\t= default_groups,\n\t.release\t\t= threshold_block_release,\n};\n\nstatic const char *get_name(unsigned int cpu, unsigned int bank, struct threshold_block *b)\n{\n\tenum smca_bank_types bank_type;\n\n\tif (!mce_flags.smca) {\n\t\tif (b && bank == 4)\n\t\t\treturn bank4_names(b);\n\n\t\treturn th_names[bank];\n\t}\n\n\tbank_type = smca_get_bank_type(cpu, bank);\n\tif (bank_type >= N_SMCA_BANK_TYPES)\n\t\treturn NULL;\n\n\tif (b && (bank_type == SMCA_UMC || bank_type == SMCA_UMC_V2)) {\n\t\tif (b->block < ARRAY_SIZE(smca_umc_block_names))\n\t\t\treturn smca_umc_block_names[b->block];\n\t\treturn NULL;\n\t}\n\n\tif (per_cpu(smca_bank_counts, cpu)[bank_type] == 1)\n\t\treturn smca_get_name(bank_type);\n\n\tsnprintf(buf_mcatype, MAX_MCATYPE_NAME_LEN,\n\t\t \"%s_%u\", smca_get_name(bank_type),\n\t\t\t  per_cpu(smca_banks, cpu)[bank].sysfs_id);\n\treturn buf_mcatype;\n}\n\nstatic int allocate_threshold_blocks(unsigned int cpu, struct threshold_bank *tb,\n\t\t\t\t     unsigned int bank, unsigned int block,\n\t\t\t\t     u32 address)\n{\n\tstruct threshold_block *b = NULL;\n\tu32 low, high;\n\tint err;\n\n\tif ((bank >= this_cpu_read(mce_num_banks)) || (block >= NR_BLOCKS))\n\t\treturn 0;\n\n\tif (rdmsr_safe(address, &low, &high))\n\t\treturn 0;\n\n\tif (!(high & MASK_VALID_HI)) {\n\t\tif (block)\n\t\t\tgoto recurse;\n\t\telse\n\t\t\treturn 0;\n\t}\n\n\tif (!(high & MASK_CNTP_HI)  ||\n\t     (high & MASK_LOCKED_HI))\n\t\tgoto recurse;\n\n\tb = kzalloc(sizeof(struct threshold_block), GFP_KERNEL);\n\tif (!b)\n\t\treturn -ENOMEM;\n\n\tb->block\t\t= block;\n\tb->bank\t\t\t= bank;\n\tb->cpu\t\t\t= cpu;\n\tb->address\t\t= address;\n\tb->interrupt_enable\t= 0;\n\tb->interrupt_capable\t= lvt_interrupt_supported(bank, high);\n\tb->threshold_limit\t= THRESHOLD_MAX;\n\n\tif (b->interrupt_capable) {\n\t\tdefault_attrs[2] = &interrupt_enable.attr;\n\t\tb->interrupt_enable = 1;\n\t} else {\n\t\tdefault_attrs[2] = NULL;\n\t}\n\n\tINIT_LIST_HEAD(&b->miscj);\n\n\t \n\tif (tb->blocks)\n\t\tlist_add(&b->miscj, &tb->blocks->miscj);\n\telse\n\t\ttb->blocks = b;\n\n\terr = kobject_init_and_add(&b->kobj, &threshold_ktype, tb->kobj, get_name(cpu, bank, b));\n\tif (err)\n\t\tgoto out_free;\nrecurse:\n\taddress = get_block_address(address, low, high, bank, ++block, cpu);\n\tif (!address)\n\t\treturn 0;\n\n\terr = allocate_threshold_blocks(cpu, tb, bank, block, address);\n\tif (err)\n\t\tgoto out_free;\n\n\tif (b)\n\t\tkobject_uevent(&b->kobj, KOBJ_ADD);\n\n\treturn 0;\n\nout_free:\n\tif (b) {\n\t\tlist_del(&b->miscj);\n\t\tkobject_put(&b->kobj);\n\t}\n\treturn err;\n}\n\nstatic int __threshold_add_blocks(struct threshold_bank *b)\n{\n\tstruct list_head *head = &b->blocks->miscj;\n\tstruct threshold_block *pos = NULL;\n\tstruct threshold_block *tmp = NULL;\n\tint err = 0;\n\n\terr = kobject_add(&b->blocks->kobj, b->kobj, b->blocks->kobj.name);\n\tif (err)\n\t\treturn err;\n\n\tlist_for_each_entry_safe(pos, tmp, head, miscj) {\n\n\t\terr = kobject_add(&pos->kobj, b->kobj, pos->kobj.name);\n\t\tif (err) {\n\t\t\tlist_for_each_entry_safe_reverse(pos, tmp, head, miscj)\n\t\t\t\tkobject_del(&pos->kobj);\n\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn err;\n}\n\nstatic int threshold_create_bank(struct threshold_bank **bp, unsigned int cpu,\n\t\t\t\t unsigned int bank)\n{\n\tstruct device *dev = this_cpu_read(mce_device);\n\tstruct amd_northbridge *nb = NULL;\n\tstruct threshold_bank *b = NULL;\n\tconst char *name = get_name(cpu, bank, NULL);\n\tint err = 0;\n\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tif (is_shared_bank(bank)) {\n\t\tnb = node_to_amd_nb(topology_die_id(cpu));\n\n\t\t \n\t\tif (nb && nb->bank4) {\n\t\t\t \n\t\t\tb = nb->bank4;\n\t\t\terr = kobject_add(b->kobj, &dev->kobj, name);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\tbp[bank] = b;\n\t\t\trefcount_inc(&b->cpus);\n\n\t\t\terr = __threshold_add_blocks(b);\n\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tb = kzalloc(sizeof(struct threshold_bank), GFP_KERNEL);\n\tif (!b) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t \n\tb->kobj = kobject_create_and_add(name, &dev->kobj);\n\tif (!b->kobj) {\n\t\terr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\tif (is_shared_bank(bank)) {\n\t\tb->shared = 1;\n\t\trefcount_set(&b->cpus, 1);\n\n\t\t \n\t\tif (nb) {\n\t\t\tWARN_ON(nb->bank4);\n\t\t\tnb->bank4 = b;\n\t\t}\n\t}\n\n\terr = allocate_threshold_blocks(cpu, b, bank, 0, mca_msr_reg(bank, MCA_MISC));\n\tif (err)\n\t\tgoto out_kobj;\n\n\tbp[bank] = b;\n\treturn 0;\n\nout_kobj:\n\tkobject_put(b->kobj);\nout_free:\n\tkfree(b);\nout:\n\treturn err;\n}\n\nstatic void threshold_block_release(struct kobject *kobj)\n{\n\tkfree(to_block(kobj));\n}\n\nstatic void deallocate_threshold_blocks(struct threshold_bank *bank)\n{\n\tstruct threshold_block *pos, *tmp;\n\n\tlist_for_each_entry_safe(pos, tmp, &bank->blocks->miscj, miscj) {\n\t\tlist_del(&pos->miscj);\n\t\tkobject_put(&pos->kobj);\n\t}\n\n\tkobject_put(&bank->blocks->kobj);\n}\n\nstatic void __threshold_remove_blocks(struct threshold_bank *b)\n{\n\tstruct threshold_block *pos = NULL;\n\tstruct threshold_block *tmp = NULL;\n\n\tkobject_put(b->kobj);\n\n\tlist_for_each_entry_safe(pos, tmp, &b->blocks->miscj, miscj)\n\t\tkobject_put(b->kobj);\n}\n\nstatic void threshold_remove_bank(struct threshold_bank *bank)\n{\n\tstruct amd_northbridge *nb;\n\n\tif (!bank->blocks)\n\t\tgoto out_free;\n\n\tif (!bank->shared)\n\t\tgoto out_dealloc;\n\n\tif (!refcount_dec_and_test(&bank->cpus)) {\n\t\t__threshold_remove_blocks(bank);\n\t\treturn;\n\t} else {\n\t\t \n\t\tnb = node_to_amd_nb(topology_die_id(smp_processor_id()));\n\t\tnb->bank4 = NULL;\n\t}\n\nout_dealloc:\n\tdeallocate_threshold_blocks(bank);\n\nout_free:\n\tkobject_put(bank->kobj);\n\tkfree(bank);\n}\n\nstatic void __threshold_remove_device(struct threshold_bank **bp)\n{\n\tunsigned int bank, numbanks = this_cpu_read(mce_num_banks);\n\n\tfor (bank = 0; bank < numbanks; bank++) {\n\t\tif (!bp[bank])\n\t\t\tcontinue;\n\n\t\tthreshold_remove_bank(bp[bank]);\n\t\tbp[bank] = NULL;\n\t}\n\tkfree(bp);\n}\n\nint mce_threshold_remove_device(unsigned int cpu)\n{\n\tstruct threshold_bank **bp = this_cpu_read(threshold_banks);\n\n\tif (!bp)\n\t\treturn 0;\n\n\t \n\tthis_cpu_write(threshold_banks, NULL);\n\n\t__threshold_remove_device(bp);\n\treturn 0;\n}\n\n \nint mce_threshold_create_device(unsigned int cpu)\n{\n\tunsigned int numbanks, bank;\n\tstruct threshold_bank **bp;\n\tint err;\n\n\tif (!mce_flags.amd_threshold)\n\t\treturn 0;\n\n\tbp = this_cpu_read(threshold_banks);\n\tif (bp)\n\t\treturn 0;\n\n\tnumbanks = this_cpu_read(mce_num_banks);\n\tbp = kcalloc(numbanks, sizeof(*bp), GFP_KERNEL);\n\tif (!bp)\n\t\treturn -ENOMEM;\n\n\tfor (bank = 0; bank < numbanks; ++bank) {\n\t\tif (!(this_cpu_read(bank_map) & BIT_ULL(bank)))\n\t\t\tcontinue;\n\t\terr = threshold_create_bank(bp, cpu, bank);\n\t\tif (err) {\n\t\t\t__threshold_remove_device(bp);\n\t\t\treturn err;\n\t\t}\n\t}\n\tthis_cpu_write(threshold_banks, bp);\n\n\tif (thresholding_irq_en)\n\t\tmce_threshold_vector = amd_threshold_interrupt;\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}