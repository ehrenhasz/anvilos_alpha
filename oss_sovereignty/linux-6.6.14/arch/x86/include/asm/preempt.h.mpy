{
  "module_name": "preempt.h",
  "hash_id": "70e571c39c78f218f8af0d2dcf40a6aa7414e62f88141b3c4a0c3ed4a40dcf68",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/include/asm/preempt.h",
  "human_readable_source": " \n#ifndef __ASM_PREEMPT_H\n#define __ASM_PREEMPT_H\n\n#include <asm/rmwcc.h>\n#include <asm/percpu.h>\n#include <asm/current.h>\n\n#include <linux/thread_info.h>\n#include <linux/static_call_types.h>\n\n \n#define PREEMPT_NEED_RESCHED\t0x80000000\n\n \n#define PREEMPT_ENABLED\t(0 + PREEMPT_NEED_RESCHED)\n\n \nstatic __always_inline int preempt_count(void)\n{\n\treturn raw_cpu_read_4(pcpu_hot.preempt_count) & ~PREEMPT_NEED_RESCHED;\n}\n\nstatic __always_inline void preempt_count_set(int pc)\n{\n\tint old, new;\n\n\tdo {\n\t\told = raw_cpu_read_4(pcpu_hot.preempt_count);\n\t\tnew = (old & PREEMPT_NEED_RESCHED) |\n\t\t\t(pc & ~PREEMPT_NEED_RESCHED);\n\t} while (raw_cpu_cmpxchg_4(pcpu_hot.preempt_count, old, new) != old);\n}\n\n \n#define init_task_preempt_count(p) do { } while (0)\n\n#define init_idle_preempt_count(p, cpu) do { \\\n\tper_cpu(pcpu_hot.preempt_count, (cpu)) = PREEMPT_DISABLED; \\\n} while (0)\n\n \n\nstatic __always_inline void set_preempt_need_resched(void)\n{\n\traw_cpu_and_4(pcpu_hot.preempt_count, ~PREEMPT_NEED_RESCHED);\n}\n\nstatic __always_inline void clear_preempt_need_resched(void)\n{\n\traw_cpu_or_4(pcpu_hot.preempt_count, PREEMPT_NEED_RESCHED);\n}\n\nstatic __always_inline bool test_preempt_need_resched(void)\n{\n\treturn !(raw_cpu_read_4(pcpu_hot.preempt_count) & PREEMPT_NEED_RESCHED);\n}\n\n \n\nstatic __always_inline void __preempt_count_add(int val)\n{\n\traw_cpu_add_4(pcpu_hot.preempt_count, val);\n}\n\nstatic __always_inline void __preempt_count_sub(int val)\n{\n\traw_cpu_add_4(pcpu_hot.preempt_count, -val);\n}\n\n \nstatic __always_inline bool __preempt_count_dec_and_test(void)\n{\n\treturn GEN_UNARY_RMWcc(\"decl\", pcpu_hot.preempt_count, e,\n\t\t\t       __percpu_arg([var]));\n}\n\n \nstatic __always_inline bool should_resched(int preempt_offset)\n{\n\treturn unlikely(raw_cpu_read_4(pcpu_hot.preempt_count) == preempt_offset);\n}\n\n#ifdef CONFIG_PREEMPTION\n\nextern asmlinkage void preempt_schedule(void);\nextern asmlinkage void preempt_schedule_thunk(void);\n\n#define preempt_schedule_dynamic_enabled\tpreempt_schedule_thunk\n#define preempt_schedule_dynamic_disabled\tNULL\n\nextern asmlinkage void preempt_schedule_notrace(void);\nextern asmlinkage void preempt_schedule_notrace_thunk(void);\n\n#define preempt_schedule_notrace_dynamic_enabled\tpreempt_schedule_notrace_thunk\n#define preempt_schedule_notrace_dynamic_disabled\tNULL\n\n#ifdef CONFIG_PREEMPT_DYNAMIC\n\nDECLARE_STATIC_CALL(preempt_schedule, preempt_schedule_dynamic_enabled);\n\n#define __preempt_schedule() \\\ndo { \\\n\t__STATIC_CALL_MOD_ADDRESSABLE(preempt_schedule); \\\n\tasm volatile (\"call \" STATIC_CALL_TRAMP_STR(preempt_schedule) : ASM_CALL_CONSTRAINT); \\\n} while (0)\n\nDECLARE_STATIC_CALL(preempt_schedule_notrace, preempt_schedule_notrace_dynamic_enabled);\n\n#define __preempt_schedule_notrace() \\\ndo { \\\n\t__STATIC_CALL_MOD_ADDRESSABLE(preempt_schedule_notrace); \\\n\tasm volatile (\"call \" STATIC_CALL_TRAMP_STR(preempt_schedule_notrace) : ASM_CALL_CONSTRAINT); \\\n} while (0)\n\n#else  \n\n#define __preempt_schedule() \\\n\tasm volatile (\"call preempt_schedule_thunk\" : ASM_CALL_CONSTRAINT);\n\n#define __preempt_schedule_notrace() \\\n\tasm volatile (\"call preempt_schedule_notrace_thunk\" : ASM_CALL_CONSTRAINT);\n\n#endif  \n\n#endif  \n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}