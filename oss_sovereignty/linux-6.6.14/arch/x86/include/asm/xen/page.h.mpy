{
  "module_name": "page.h",
  "hash_id": "3f0b69007d8e7a6c94cd241f78fceae61b4fce1ec548fbd8d1fb292ab9156bd1",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/include/asm/xen/page.h",
  "human_readable_source": " \n#ifndef _ASM_X86_XEN_PAGE_H\n#define _ASM_X86_XEN_PAGE_H\n\n#include <linux/kernel.h>\n#include <linux/types.h>\n#include <linux/spinlock.h>\n#include <linux/pfn.h>\n#include <linux/mm.h>\n#include <linux/device.h>\n\n#include <asm/extable.h>\n#include <asm/page.h>\n\n#include <xen/interface/xen.h>\n#include <xen/interface/grant_table.h>\n#include <xen/features.h>\n\n \ntypedef struct xmaddr {\n\tphys_addr_t maddr;\n} xmaddr_t;\n\n \ntypedef struct xpaddr {\n\tphys_addr_t paddr;\n} xpaddr_t;\n\n#ifdef CONFIG_X86_64\n#define XEN_PHYSICAL_MASK\t__sme_clr((1UL << 52) - 1)\n#else\n#define XEN_PHYSICAL_MASK\t__PHYSICAL_MASK\n#endif\n\n#define XEN_PTE_MFN_MASK\t((pteval_t)(((signed long)PAGE_MASK) & \\\n\t\t\t\t\t    XEN_PHYSICAL_MASK))\n\n#define XMADDR(x)\t((xmaddr_t) { .maddr = (x) })\n#define XPADDR(x)\t((xpaddr_t) { .paddr = (x) })\n\n \n#define INVALID_P2M_ENTRY\t(~0UL)\n#define FOREIGN_FRAME_BIT\t(1UL<<(BITS_PER_LONG-1))\n#define IDENTITY_FRAME_BIT\t(1UL<<(BITS_PER_LONG-2))\n#define FOREIGN_FRAME(m)\t((m) | FOREIGN_FRAME_BIT)\n#define IDENTITY_FRAME(m)\t((m) | IDENTITY_FRAME_BIT)\n\n#define P2M_PER_PAGE\t\t(PAGE_SIZE / sizeof(unsigned long))\n\nextern unsigned long *machine_to_phys_mapping;\nextern unsigned long  machine_to_phys_nr;\nextern unsigned long *xen_p2m_addr;\nextern unsigned long  xen_p2m_size;\nextern unsigned long  xen_max_p2m_pfn;\n\nextern int xen_alloc_p2m_entry(unsigned long pfn);\n\nextern unsigned long get_phys_to_machine(unsigned long pfn);\nextern bool set_phys_to_machine(unsigned long pfn, unsigned long mfn);\nextern bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn);\nextern unsigned long __init set_phys_range_identity(unsigned long pfn_s,\n\t\t\t\t\t\t    unsigned long pfn_e);\n\n#ifdef CONFIG_XEN_PV\nextern int set_foreign_p2m_mapping(struct gnttab_map_grant_ref *map_ops,\n\t\t\t\t   struct gnttab_map_grant_ref *kmap_ops,\n\t\t\t\t   struct page **pages, unsigned int count);\nextern int clear_foreign_p2m_mapping(struct gnttab_unmap_grant_ref *unmap_ops,\n\t\t\t\t     struct gnttab_unmap_grant_ref *kunmap_ops,\n\t\t\t\t     struct page **pages, unsigned int count);\n#else\nstatic inline int\nset_foreign_p2m_mapping(struct gnttab_map_grant_ref *map_ops,\n\t\t\tstruct gnttab_map_grant_ref *kmap_ops,\n\t\t\tstruct page **pages, unsigned int count)\n{\n\treturn 0;\n}\n\nstatic inline int\nclear_foreign_p2m_mapping(struct gnttab_unmap_grant_ref *unmap_ops,\n\t\t\t  struct gnttab_unmap_grant_ref *kunmap_ops,\n\t\t\t  struct page **pages, unsigned int count)\n{\n\treturn 0;\n}\n#endif\n\n \nstatic inline int xen_safe_write_ulong(unsigned long *addr, unsigned long val)\n{\n\tint ret = 0;\n\n\tasm volatile(\"1: mov %[val], %[ptr]\\n\"\n\t\t     \"2:\\n\"\n\t\t     _ASM_EXTABLE_TYPE_REG(1b, 2b, EX_TYPE_EFAULT_REG, %[ret])\n\t\t     : [ret] \"+r\" (ret), [ptr] \"=m\" (*addr)\n\t\t     : [val] \"r\" (val));\n\n\treturn ret;\n}\n\nstatic inline int xen_safe_read_ulong(const unsigned long *addr,\n\t\t\t\t      unsigned long *val)\n{\n\tunsigned long rval = ~0ul;\n\tint ret = 0;\n\n\tasm volatile(\"1: mov %[ptr], %[rval]\\n\"\n\t\t     \"2:\\n\"\n\t\t     _ASM_EXTABLE_TYPE_REG(1b, 2b, EX_TYPE_EFAULT_REG, %[ret])\n\t\t     : [ret] \"+r\" (ret), [rval] \"+r\" (rval)\n\t\t     : [ptr] \"m\" (*addr));\n\t*val = rval;\n\n\treturn ret;\n}\n\n#ifdef CONFIG_XEN_PV\n \nstatic inline unsigned long __pfn_to_mfn(unsigned long pfn)\n{\n\tunsigned long mfn;\n\n\tif (pfn < xen_p2m_size)\n\t\tmfn = xen_p2m_addr[pfn];\n\telse if (unlikely(pfn < xen_max_p2m_pfn))\n\t\treturn get_phys_to_machine(pfn);\n\telse\n\t\treturn IDENTITY_FRAME(pfn);\n\n\tif (unlikely(mfn == INVALID_P2M_ENTRY))\n\t\treturn get_phys_to_machine(pfn);\n\n\treturn mfn;\n}\n#else\nstatic inline unsigned long __pfn_to_mfn(unsigned long pfn)\n{\n\treturn pfn;\n}\n#endif\n\nstatic inline unsigned long pfn_to_mfn(unsigned long pfn)\n{\n\tunsigned long mfn;\n\n\t \n\tif (xen_feature(XENFEAT_auto_translated_physmap))\n\t\treturn pfn;\n\n\tmfn = __pfn_to_mfn(pfn);\n\n\tif (mfn != INVALID_P2M_ENTRY)\n\t\tmfn &= ~(FOREIGN_FRAME_BIT | IDENTITY_FRAME_BIT);\n\n\treturn mfn;\n}\n\nstatic inline int phys_to_machine_mapping_valid(unsigned long pfn)\n{\n\tif (xen_feature(XENFEAT_auto_translated_physmap))\n\t\treturn 1;\n\n\treturn __pfn_to_mfn(pfn) != INVALID_P2M_ENTRY;\n}\n\nstatic inline unsigned long mfn_to_pfn_no_overrides(unsigned long mfn)\n{\n\tunsigned long pfn;\n\tint ret;\n\n\tif (unlikely(mfn >= machine_to_phys_nr))\n\t\treturn ~0;\n\n\t \n\tret = xen_safe_read_ulong(&machine_to_phys_mapping[mfn], &pfn);\n\tif (ret < 0)\n\t\treturn ~0;\n\n\treturn pfn;\n}\n\nstatic inline unsigned long mfn_to_pfn(unsigned long mfn)\n{\n\tunsigned long pfn;\n\n\t \n\tif (xen_feature(XENFEAT_auto_translated_physmap))\n\t\treturn mfn;\n\n\tpfn = mfn_to_pfn_no_overrides(mfn);\n\tif (__pfn_to_mfn(pfn) != mfn)\n\t\tpfn = ~0;\n\n\t \n\tif (pfn == ~0 && __pfn_to_mfn(mfn) == IDENTITY_FRAME(mfn))\n\t\tpfn = mfn;\n\n\treturn pfn;\n}\n\nstatic inline xmaddr_t phys_to_machine(xpaddr_t phys)\n{\n\tunsigned offset = phys.paddr & ~PAGE_MASK;\n\treturn XMADDR(PFN_PHYS(pfn_to_mfn(PFN_DOWN(phys.paddr))) | offset);\n}\n\nstatic inline xpaddr_t machine_to_phys(xmaddr_t machine)\n{\n\tunsigned offset = machine.maddr & ~PAGE_MASK;\n\treturn XPADDR(PFN_PHYS(mfn_to_pfn(PFN_DOWN(machine.maddr))) | offset);\n}\n\n \nstatic inline unsigned long pfn_to_gfn(unsigned long pfn)\n{\n\tif (xen_feature(XENFEAT_auto_translated_physmap))\n\t\treturn pfn;\n\telse\n\t\treturn pfn_to_mfn(pfn);\n}\n\nstatic inline unsigned long gfn_to_pfn(unsigned long gfn)\n{\n\tif (xen_feature(XENFEAT_auto_translated_physmap))\n\t\treturn gfn;\n\telse\n\t\treturn mfn_to_pfn(gfn);\n}\n\n \n#define pfn_to_bfn(pfn)\t\tpfn_to_gfn(pfn)\n#define bfn_to_pfn(bfn)\t\tgfn_to_pfn(bfn)\n\n \nstatic inline unsigned long bfn_to_local_pfn(unsigned long mfn)\n{\n\tunsigned long pfn;\n\n\tif (xen_feature(XENFEAT_auto_translated_physmap))\n\t\treturn mfn;\n\n\tpfn = mfn_to_pfn(mfn);\n\tif (__pfn_to_mfn(pfn) != mfn)\n\t\treturn -1;  \n\treturn pfn;\n}\n\n \n#define virt_to_machine(v)\t(phys_to_machine(XPADDR(__pa(v))))\nstatic inline unsigned long virt_to_pfn(const void *v)\n{\n\treturn PFN_DOWN(__pa(v));\n}\n#define virt_to_mfn(v)\t\t(pfn_to_mfn(virt_to_pfn(v)))\n#define mfn_to_virt(m)\t\t(__va(mfn_to_pfn(m) << PAGE_SHIFT))\n\n \n#define virt_to_gfn(v)\t\t(pfn_to_gfn(virt_to_pfn(v)))\n#define gfn_to_virt(g)\t\t(__va(gfn_to_pfn(g) << PAGE_SHIFT))\n\nstatic inline unsigned long pte_mfn(pte_t pte)\n{\n\treturn (pte.pte & XEN_PTE_MFN_MASK) >> PAGE_SHIFT;\n}\n\nstatic inline pte_t mfn_pte(unsigned long page_nr, pgprot_t pgprot)\n{\n\tpte_t pte;\n\n\tpte.pte = ((phys_addr_t)page_nr << PAGE_SHIFT) |\n\t\t\tmassage_pgprot(pgprot);\n\n\treturn pte;\n}\n\nstatic inline pteval_t pte_val_ma(pte_t pte)\n{\n\treturn pte.pte;\n}\n\nstatic inline pte_t __pte_ma(pteval_t x)\n{\n\treturn (pte_t) { .pte = x };\n}\n\n#define pmd_val_ma(v) ((v).pmd)\n#ifdef __PAGETABLE_PUD_FOLDED\n#define pud_val_ma(v) ((v).p4d.pgd.pgd)\n#else\n#define pud_val_ma(v) ((v).pud)\n#endif\n#define __pmd_ma(x)\t((pmd_t) { (x) } )\n\n#ifdef __PAGETABLE_P4D_FOLDED\n#define p4d_val_ma(x)\t((x).pgd.pgd)\n#else\n#define p4d_val_ma(x)\t((x).p4d)\n#endif\n\nxmaddr_t arbitrary_virt_to_machine(void *address);\nunsigned long arbitrary_virt_to_mfn(void *vaddr);\nvoid make_lowmem_page_readonly(void *vaddr);\nvoid make_lowmem_page_readwrite(void *vaddr);\n\nstatic inline bool xen_arch_need_swiotlb(struct device *dev,\n\t\t\t\t\t phys_addr_t phys,\n\t\t\t\t\t dma_addr_t dev_addr)\n{\n\treturn false;\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}