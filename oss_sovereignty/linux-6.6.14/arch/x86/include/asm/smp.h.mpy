{
  "module_name": "smp.h",
  "hash_id": "c5b0365f5d8ba7979e9a88c75676f63eb144c1b12888a33e5b39cbd54f18372c",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/include/asm/smp.h",
  "human_readable_source": " \n#ifndef _ASM_X86_SMP_H\n#define _ASM_X86_SMP_H\n#ifndef __ASSEMBLY__\n#include <linux/cpumask.h>\n\n#include <asm/cpumask.h>\n#include <asm/current.h>\n#include <asm/thread_info.h>\n\nextern int smp_num_siblings;\nextern unsigned int num_processors;\n\nDECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_map);\nDECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_core_map);\nDECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_die_map);\n \nDECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_llc_shared_map);\nDECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_l2c_shared_map);\nDECLARE_PER_CPU_READ_MOSTLY(u16, cpu_llc_id);\nDECLARE_PER_CPU_READ_MOSTLY(u16, cpu_l2c_id);\n\nDECLARE_EARLY_PER_CPU_READ_MOSTLY(u16, x86_cpu_to_apicid);\nDECLARE_EARLY_PER_CPU_READ_MOSTLY(u32, x86_cpu_to_acpiid);\n\nstruct task_struct;\n\nstruct smp_ops {\n\tvoid (*smp_prepare_boot_cpu)(void);\n\tvoid (*smp_prepare_cpus)(unsigned max_cpus);\n\tvoid (*smp_cpus_done)(unsigned max_cpus);\n\n\tvoid (*stop_other_cpus)(int wait);\n\tvoid (*crash_stop_other_cpus)(void);\n\tvoid (*smp_send_reschedule)(int cpu);\n\n\tvoid (*cleanup_dead_cpu)(unsigned cpu);\n\tvoid (*poll_sync_state)(void);\n\tint (*kick_ap_alive)(unsigned cpu, struct task_struct *tidle);\n\tint (*cpu_disable)(void);\n\tvoid (*cpu_die)(unsigned int cpu);\n\tvoid (*play_dead)(void);\n\n\tvoid (*send_call_func_ipi)(const struct cpumask *mask);\n\tvoid (*send_call_func_single_ipi)(int cpu);\n};\n\n \nextern void set_cpu_sibling_map(int cpu);\n\n#ifdef CONFIG_SMP\nextern struct smp_ops smp_ops;\n\nstatic inline void smp_send_stop(void)\n{\n\tsmp_ops.stop_other_cpus(0);\n}\n\nstatic inline void stop_other_cpus(void)\n{\n\tsmp_ops.stop_other_cpus(1);\n}\n\nstatic inline void smp_prepare_boot_cpu(void)\n{\n\tsmp_ops.smp_prepare_boot_cpu();\n}\n\nstatic inline void smp_prepare_cpus(unsigned int max_cpus)\n{\n\tsmp_ops.smp_prepare_cpus(max_cpus);\n}\n\nstatic inline void smp_cpus_done(unsigned int max_cpus)\n{\n\tsmp_ops.smp_cpus_done(max_cpus);\n}\n\nstatic inline int __cpu_disable(void)\n{\n\treturn smp_ops.cpu_disable();\n}\n\nstatic inline void __cpu_die(unsigned int cpu)\n{\n\tif (smp_ops.cpu_die)\n\t\tsmp_ops.cpu_die(cpu);\n}\n\nstatic inline void __noreturn play_dead(void)\n{\n\tsmp_ops.play_dead();\n\tBUG();\n}\n\nstatic inline void arch_smp_send_reschedule(int cpu)\n{\n\tsmp_ops.smp_send_reschedule(cpu);\n}\n\nstatic inline void arch_send_call_function_single_ipi(int cpu)\n{\n\tsmp_ops.send_call_func_single_ipi(cpu);\n}\n\nstatic inline void arch_send_call_function_ipi_mask(const struct cpumask *mask)\n{\n\tsmp_ops.send_call_func_ipi(mask);\n}\n\nvoid cpu_disable_common(void);\nvoid native_smp_prepare_boot_cpu(void);\nvoid smp_prepare_cpus_common(void);\nvoid native_smp_prepare_cpus(unsigned int max_cpus);\nvoid calculate_max_logical_packages(void);\nvoid native_smp_cpus_done(unsigned int max_cpus);\nint common_cpu_up(unsigned int cpunum, struct task_struct *tidle);\nint native_kick_ap(unsigned int cpu, struct task_struct *tidle);\nint native_cpu_disable(void);\nvoid __noreturn hlt_play_dead(void);\nvoid native_play_dead(void);\nvoid play_dead_common(void);\nvoid wbinvd_on_cpu(int cpu);\nint wbinvd_on_all_cpus(void);\n\nvoid smp_kick_mwait_play_dead(void);\n\nvoid native_smp_send_reschedule(int cpu);\nvoid native_send_call_func_ipi(const struct cpumask *mask);\nvoid native_send_call_func_single_ipi(int cpu);\n\nvoid smp_store_cpu_info(int id);\n\nasmlinkage __visible void smp_reboot_interrupt(void);\n__visible void smp_reschedule_interrupt(struct pt_regs *regs);\n__visible void smp_call_function_interrupt(struct pt_regs *regs);\n__visible void smp_call_function_single_interrupt(struct pt_regs *r);\n\n#define cpu_physical_id(cpu)\tper_cpu(x86_cpu_to_apicid, cpu)\n#define cpu_acpi_id(cpu)\tper_cpu(x86_cpu_to_acpiid, cpu)\n\n \n#define raw_smp_processor_id()  this_cpu_read(pcpu_hot.cpu_number)\n#define __smp_processor_id() __this_cpu_read(pcpu_hot.cpu_number)\n\n#ifdef CONFIG_X86_32\nextern int safe_smp_processor_id(void);\n#else\n# define safe_smp_processor_id()\tsmp_processor_id()\n#endif\n\nstatic inline struct cpumask *cpu_llc_shared_mask(int cpu)\n{\n\treturn per_cpu(cpu_llc_shared_map, cpu);\n}\n\nstatic inline struct cpumask *cpu_l2c_shared_mask(int cpu)\n{\n\treturn per_cpu(cpu_l2c_shared_map, cpu);\n}\n\n#else  \n#define wbinvd_on_cpu(cpu)     wbinvd()\nstatic inline int wbinvd_on_all_cpus(void)\n{\n\twbinvd();\n\treturn 0;\n}\n\nstatic inline struct cpumask *cpu_llc_shared_mask(int cpu)\n{\n\treturn (struct cpumask *)cpumask_of(0);\n}\n#endif  \n\nextern unsigned disabled_cpus;\n\n#ifdef CONFIG_DEBUG_NMI_SELFTEST\nextern void nmi_selftest(void);\n#else\n#define nmi_selftest() do { } while (0)\n#endif\n\nextern unsigned int smpboot_control;\nextern unsigned long apic_mmio_base;\n\n#endif  \n\n \n#define STARTUP_READ_APICID\t0x80000000\n\n \n#define STARTUP_PARALLEL_MASK\t0xFF000000\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}