{
  "module_name": "bitops.h",
  "hash_id": "13328a7dbf8d3940c112ff1e5f4304afd3d421e338ebdcc24857771bbb269e2a",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/include/asm/bitops.h",
  "human_readable_source": " \n#ifndef _ASM_X86_BITOPS_H\n#define _ASM_X86_BITOPS_H\n\n \n\n#ifndef _LINUX_BITOPS_H\n#error only <linux/bitops.h> can be included directly\n#endif\n\n#include <linux/compiler.h>\n#include <asm/alternative.h>\n#include <asm/rmwcc.h>\n#include <asm/barrier.h>\n\n#if BITS_PER_LONG == 32\n# define _BITOPS_LONG_SHIFT 5\n#elif BITS_PER_LONG == 64\n# define _BITOPS_LONG_SHIFT 6\n#else\n# error \"Unexpected BITS_PER_LONG\"\n#endif\n\n#define BIT_64(n)\t\t\t(U64_C(1) << (n))\n\n \n\n#define RLONG_ADDR(x)\t\t\t \"m\" (*(volatile long *) (x))\n#define WBYTE_ADDR(x)\t\t\t\"+m\" (*(volatile char *) (x))\n\n#define ADDR\t\t\t\tRLONG_ADDR(addr)\n\n \n#define CONST_MASK_ADDR(nr, addr)\tWBYTE_ADDR((void *)(addr) + ((nr)>>3))\n#define CONST_MASK(nr)\t\t\t(1 << ((nr) & 7))\n\nstatic __always_inline void\narch_set_bit(long nr, volatile unsigned long *addr)\n{\n\tif (__builtin_constant_p(nr)) {\n\t\tasm volatile(LOCK_PREFIX \"orb %b1,%0\"\n\t\t\t: CONST_MASK_ADDR(nr, addr)\n\t\t\t: \"iq\" (CONST_MASK(nr))\n\t\t\t: \"memory\");\n\t} else {\n\t\tasm volatile(LOCK_PREFIX __ASM_SIZE(bts) \" %1,%0\"\n\t\t\t: : RLONG_ADDR(addr), \"Ir\" (nr) : \"memory\");\n\t}\n}\n\nstatic __always_inline void\narch___set_bit(unsigned long nr, volatile unsigned long *addr)\n{\n\tasm volatile(__ASM_SIZE(bts) \" %1,%0\" : : ADDR, \"Ir\" (nr) : \"memory\");\n}\n\nstatic __always_inline void\narch_clear_bit(long nr, volatile unsigned long *addr)\n{\n\tif (__builtin_constant_p(nr)) {\n\t\tasm volatile(LOCK_PREFIX \"andb %b1,%0\"\n\t\t\t: CONST_MASK_ADDR(nr, addr)\n\t\t\t: \"iq\" (~CONST_MASK(nr)));\n\t} else {\n\t\tasm volatile(LOCK_PREFIX __ASM_SIZE(btr) \" %1,%0\"\n\t\t\t: : RLONG_ADDR(addr), \"Ir\" (nr) : \"memory\");\n\t}\n}\n\nstatic __always_inline void\narch_clear_bit_unlock(long nr, volatile unsigned long *addr)\n{\n\tbarrier();\n\tarch_clear_bit(nr, addr);\n}\n\nstatic __always_inline void\narch___clear_bit(unsigned long nr, volatile unsigned long *addr)\n{\n\tasm volatile(__ASM_SIZE(btr) \" %1,%0\" : : ADDR, \"Ir\" (nr) : \"memory\");\n}\n\nstatic __always_inline bool\narch_clear_bit_unlock_is_negative_byte(long nr, volatile unsigned long *addr)\n{\n\tbool negative;\n\tasm volatile(LOCK_PREFIX \"andb %2,%1\"\n\t\tCC_SET(s)\n\t\t: CC_OUT(s) (negative), WBYTE_ADDR(addr)\n\t\t: \"ir\" ((char) ~(1 << nr)) : \"memory\");\n\treturn negative;\n}\n#define arch_clear_bit_unlock_is_negative_byte                                 \\\n\tarch_clear_bit_unlock_is_negative_byte\n\nstatic __always_inline void\narch___clear_bit_unlock(long nr, volatile unsigned long *addr)\n{\n\tarch___clear_bit(nr, addr);\n}\n\nstatic __always_inline void\narch___change_bit(unsigned long nr, volatile unsigned long *addr)\n{\n\tasm volatile(__ASM_SIZE(btc) \" %1,%0\" : : ADDR, \"Ir\" (nr) : \"memory\");\n}\n\nstatic __always_inline void\narch_change_bit(long nr, volatile unsigned long *addr)\n{\n\tif (__builtin_constant_p(nr)) {\n\t\tasm volatile(LOCK_PREFIX \"xorb %b1,%0\"\n\t\t\t: CONST_MASK_ADDR(nr, addr)\n\t\t\t: \"iq\" (CONST_MASK(nr)));\n\t} else {\n\t\tasm volatile(LOCK_PREFIX __ASM_SIZE(btc) \" %1,%0\"\n\t\t\t: : RLONG_ADDR(addr), \"Ir\" (nr) : \"memory\");\n\t}\n}\n\nstatic __always_inline bool\narch_test_and_set_bit(long nr, volatile unsigned long *addr)\n{\n\treturn GEN_BINARY_RMWcc(LOCK_PREFIX __ASM_SIZE(bts), *addr, c, \"Ir\", nr);\n}\n\nstatic __always_inline bool\narch_test_and_set_bit_lock(long nr, volatile unsigned long *addr)\n{\n\treturn arch_test_and_set_bit(nr, addr);\n}\n\nstatic __always_inline bool\narch___test_and_set_bit(unsigned long nr, volatile unsigned long *addr)\n{\n\tbool oldbit;\n\n\tasm(__ASM_SIZE(bts) \" %2,%1\"\n\t    CC_SET(c)\n\t    : CC_OUT(c) (oldbit)\n\t    : ADDR, \"Ir\" (nr) : \"memory\");\n\treturn oldbit;\n}\n\nstatic __always_inline bool\narch_test_and_clear_bit(long nr, volatile unsigned long *addr)\n{\n\treturn GEN_BINARY_RMWcc(LOCK_PREFIX __ASM_SIZE(btr), *addr, c, \"Ir\", nr);\n}\n\n \nstatic __always_inline bool\narch___test_and_clear_bit(unsigned long nr, volatile unsigned long *addr)\n{\n\tbool oldbit;\n\n\tasm volatile(__ASM_SIZE(btr) \" %2,%1\"\n\t\t     CC_SET(c)\n\t\t     : CC_OUT(c) (oldbit)\n\t\t     : ADDR, \"Ir\" (nr) : \"memory\");\n\treturn oldbit;\n}\n\nstatic __always_inline bool\narch___test_and_change_bit(unsigned long nr, volatile unsigned long *addr)\n{\n\tbool oldbit;\n\n\tasm volatile(__ASM_SIZE(btc) \" %2,%1\"\n\t\t     CC_SET(c)\n\t\t     : CC_OUT(c) (oldbit)\n\t\t     : ADDR, \"Ir\" (nr) : \"memory\");\n\n\treturn oldbit;\n}\n\nstatic __always_inline bool\narch_test_and_change_bit(long nr, volatile unsigned long *addr)\n{\n\treturn GEN_BINARY_RMWcc(LOCK_PREFIX __ASM_SIZE(btc), *addr, c, \"Ir\", nr);\n}\n\nstatic __always_inline bool constant_test_bit(long nr, const volatile unsigned long *addr)\n{\n\treturn ((1UL << (nr & (BITS_PER_LONG-1))) &\n\t\t(addr[nr >> _BITOPS_LONG_SHIFT])) != 0;\n}\n\nstatic __always_inline bool constant_test_bit_acquire(long nr, const volatile unsigned long *addr)\n{\n\tbool oldbit;\n\n\tasm volatile(\"testb %2,%1\"\n\t\t     CC_SET(nz)\n\t\t     : CC_OUT(nz) (oldbit)\n\t\t     : \"m\" (((unsigned char *)addr)[nr >> 3]),\n\t\t       \"i\" (1 << (nr & 7))\n\t\t     :\"memory\");\n\n\treturn oldbit;\n}\n\nstatic __always_inline bool variable_test_bit(long nr, volatile const unsigned long *addr)\n{\n\tbool oldbit;\n\n\tasm volatile(__ASM_SIZE(bt) \" %2,%1\"\n\t\t     CC_SET(c)\n\t\t     : CC_OUT(c) (oldbit)\n\t\t     : \"m\" (*(unsigned long *)addr), \"Ir\" (nr) : \"memory\");\n\n\treturn oldbit;\n}\n\nstatic __always_inline bool\narch_test_bit(unsigned long nr, const volatile unsigned long *addr)\n{\n\treturn __builtin_constant_p(nr) ? constant_test_bit(nr, addr) :\n\t\t\t\t\t  variable_test_bit(nr, addr);\n}\n\nstatic __always_inline bool\narch_test_bit_acquire(unsigned long nr, const volatile unsigned long *addr)\n{\n\treturn __builtin_constant_p(nr) ? constant_test_bit_acquire(nr, addr) :\n\t\t\t\t\t  variable_test_bit(nr, addr);\n}\n\nstatic __always_inline unsigned long variable__ffs(unsigned long word)\n{\n\tasm(\"rep; bsf %1,%0\"\n\t\t: \"=r\" (word)\n\t\t: \"rm\" (word));\n\treturn word;\n}\n\n \n#define __ffs(word)\t\t\t\t\\\n\t(__builtin_constant_p(word) ?\t\t\\\n\t (unsigned long)__builtin_ctzl(word) :\t\\\n\t variable__ffs(word))\n\nstatic __always_inline unsigned long variable_ffz(unsigned long word)\n{\n\tasm(\"rep; bsf %1,%0\"\n\t\t: \"=r\" (word)\n\t\t: \"r\" (~word));\n\treturn word;\n}\n\n \n#define ffz(word)\t\t\t\t\\\n\t(__builtin_constant_p(word) ?\t\t\\\n\t (unsigned long)__builtin_ctzl(~word) :\t\\\n\t variable_ffz(word))\n\n \nstatic __always_inline unsigned long __fls(unsigned long word)\n{\n\tasm(\"bsr %1,%0\"\n\t    : \"=r\" (word)\n\t    : \"rm\" (word));\n\treturn word;\n}\n\n#undef ADDR\n\n#ifdef __KERNEL__\nstatic __always_inline int variable_ffs(int x)\n{\n\tint r;\n\n#ifdef CONFIG_X86_64\n\t \n\tasm(\"bsfl %1,%0\"\n\t    : \"=r\" (r)\n\t    : \"rm\" (x), \"0\" (-1));\n#elif defined(CONFIG_X86_CMOV)\n\tasm(\"bsfl %1,%0\\n\\t\"\n\t    \"cmovzl %2,%0\"\n\t    : \"=&r\" (r) : \"rm\" (x), \"r\" (-1));\n#else\n\tasm(\"bsfl %1,%0\\n\\t\"\n\t    \"jnz 1f\\n\\t\"\n\t    \"movl $-1,%0\\n\"\n\t    \"1:\" : \"=r\" (r) : \"rm\" (x));\n#endif\n\treturn r + 1;\n}\n\n \n#define ffs(x) (__builtin_constant_p(x) ? __builtin_ffs(x) : variable_ffs(x))\n\n \nstatic __always_inline int fls(unsigned int x)\n{\n\tint r;\n\n#ifdef CONFIG_X86_64\n\t \n\tasm(\"bsrl %1,%0\"\n\t    : \"=r\" (r)\n\t    : \"rm\" (x), \"0\" (-1));\n#elif defined(CONFIG_X86_CMOV)\n\tasm(\"bsrl %1,%0\\n\\t\"\n\t    \"cmovzl %2,%0\"\n\t    : \"=&r\" (r) : \"rm\" (x), \"rm\" (-1));\n#else\n\tasm(\"bsrl %1,%0\\n\\t\"\n\t    \"jnz 1f\\n\\t\"\n\t    \"movl $-1,%0\\n\"\n\t    \"1:\" : \"=r\" (r) : \"rm\" (x));\n#endif\n\treturn r + 1;\n}\n\n \n#ifdef CONFIG_X86_64\nstatic __always_inline int fls64(__u64 x)\n{\n\tint bitpos = -1;\n\t \n\tasm(\"bsrq %1,%q0\"\n\t    : \"+r\" (bitpos)\n\t    : \"rm\" (x));\n\treturn bitpos + 1;\n}\n#else\n#include <asm-generic/bitops/fls64.h>\n#endif\n\n#include <asm-generic/bitops/sched.h>\n\n#include <asm/arch_hweight.h>\n\n#include <asm-generic/bitops/const_hweight.h>\n\n#include <asm-generic/bitops/instrumented-atomic.h>\n#include <asm-generic/bitops/instrumented-non-atomic.h>\n#include <asm-generic/bitops/instrumented-lock.h>\n\n#include <asm-generic/bitops/le.h>\n\n#include <asm-generic/bitops/ext2-atomic-setbit.h>\n\n#endif  \n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}