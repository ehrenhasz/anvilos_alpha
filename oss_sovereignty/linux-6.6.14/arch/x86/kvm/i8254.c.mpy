{
  "module_name": "i8254.c",
  "hash_id": "9b3bf167afe10a0943d6c4bcbd2ac6913ae9fd953d1790e1f92954a814feb9a9",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/i8254.c",
  "human_readable_source": " \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kvm_host.h>\n#include <linux/slab.h>\n\n#include \"ioapic.h\"\n#include \"irq.h\"\n#include \"i8254.h\"\n#include \"x86.h\"\n\n#ifndef CONFIG_X86_64\n#define mod_64(x, y) ((x) - (y) * div64_u64(x, y))\n#else\n#define mod_64(x, y) ((x) % (y))\n#endif\n\n#define RW_STATE_LSB 1\n#define RW_STATE_MSB 2\n#define RW_STATE_WORD0 3\n#define RW_STATE_WORD1 4\n\nstatic void pit_set_gate(struct kvm_pit *pit, int channel, u32 val)\n{\n\tstruct kvm_kpit_channel_state *c = &pit->pit_state.channels[channel];\n\n\tswitch (c->mode) {\n\tdefault:\n\tcase 0:\n\tcase 4:\n\t\t \n\t\tbreak;\n\tcase 1:\n\tcase 2:\n\tcase 3:\n\tcase 5:\n\t\t \n\t\tif (c->gate < val)\n\t\t\tc->count_load_time = ktime_get();\n\t\tbreak;\n\t}\n\n\tc->gate = val;\n}\n\nstatic int pit_get_gate(struct kvm_pit *pit, int channel)\n{\n\treturn pit->pit_state.channels[channel].gate;\n}\n\nstatic s64 __kpit_elapsed(struct kvm_pit *pit)\n{\n\ts64 elapsed;\n\tktime_t remaining;\n\tstruct kvm_kpit_state *ps = &pit->pit_state;\n\n\tif (!ps->period)\n\t\treturn 0;\n\n\t \n\tremaining = hrtimer_get_remaining(&ps->timer);\n\telapsed = ps->period - ktime_to_ns(remaining);\n\n\treturn elapsed;\n}\n\nstatic s64 kpit_elapsed(struct kvm_pit *pit, struct kvm_kpit_channel_state *c,\n\t\t\tint channel)\n{\n\tif (channel == 0)\n\t\treturn __kpit_elapsed(pit);\n\n\treturn ktime_to_ns(ktime_sub(ktime_get(), c->count_load_time));\n}\n\nstatic int pit_get_count(struct kvm_pit *pit, int channel)\n{\n\tstruct kvm_kpit_channel_state *c = &pit->pit_state.channels[channel];\n\ts64 d, t;\n\tint counter;\n\n\tt = kpit_elapsed(pit, c, channel);\n\td = mul_u64_u32_div(t, KVM_PIT_FREQ, NSEC_PER_SEC);\n\n\tswitch (c->mode) {\n\tcase 0:\n\tcase 1:\n\tcase 4:\n\tcase 5:\n\t\tcounter = (c->count - d) & 0xffff;\n\t\tbreak;\n\tcase 3:\n\t\t \n\t\tcounter = c->count - (mod_64((2 * d), c->count));\n\t\tbreak;\n\tdefault:\n\t\tcounter = c->count - mod_64(d, c->count);\n\t\tbreak;\n\t}\n\treturn counter;\n}\n\nstatic int pit_get_out(struct kvm_pit *pit, int channel)\n{\n\tstruct kvm_kpit_channel_state *c = &pit->pit_state.channels[channel];\n\ts64 d, t;\n\tint out;\n\n\tt = kpit_elapsed(pit, c, channel);\n\td = mul_u64_u32_div(t, KVM_PIT_FREQ, NSEC_PER_SEC);\n\n\tswitch (c->mode) {\n\tdefault:\n\tcase 0:\n\t\tout = (d >= c->count);\n\t\tbreak;\n\tcase 1:\n\t\tout = (d < c->count);\n\t\tbreak;\n\tcase 2:\n\t\tout = ((mod_64(d, c->count) == 0) && (d != 0));\n\t\tbreak;\n\tcase 3:\n\t\tout = (mod_64(d, c->count) < ((c->count + 1) >> 1));\n\t\tbreak;\n\tcase 4:\n\tcase 5:\n\t\tout = (d == c->count);\n\t\tbreak;\n\t}\n\n\treturn out;\n}\n\nstatic void pit_latch_count(struct kvm_pit *pit, int channel)\n{\n\tstruct kvm_kpit_channel_state *c = &pit->pit_state.channels[channel];\n\n\tif (!c->count_latched) {\n\t\tc->latched_count = pit_get_count(pit, channel);\n\t\tc->count_latched = c->rw_mode;\n\t}\n}\n\nstatic void pit_latch_status(struct kvm_pit *pit, int channel)\n{\n\tstruct kvm_kpit_channel_state *c = &pit->pit_state.channels[channel];\n\n\tif (!c->status_latched) {\n\t\t \n\t\tc->status = ((pit_get_out(pit, channel) << 7) |\n\t\t\t\t(c->rw_mode << 4) |\n\t\t\t\t(c->mode << 1) |\n\t\t\t\tc->bcd);\n\t\tc->status_latched = 1;\n\t}\n}\n\nstatic inline struct kvm_pit *pit_state_to_pit(struct kvm_kpit_state *ps)\n{\n\treturn container_of(ps, struct kvm_pit, pit_state);\n}\n\nstatic void kvm_pit_ack_irq(struct kvm_irq_ack_notifier *kian)\n{\n\tstruct kvm_kpit_state *ps = container_of(kian, struct kvm_kpit_state,\n\t\t\t\t\t\t irq_ack_notifier);\n\tstruct kvm_pit *pit = pit_state_to_pit(ps);\n\n\tatomic_set(&ps->irq_ack, 1);\n\t \n\tsmp_mb();\n\tif (atomic_dec_if_positive(&ps->pending) > 0)\n\t\tkthread_queue_work(pit->worker, &pit->expired);\n}\n\nvoid __kvm_migrate_pit_timer(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_pit *pit = vcpu->kvm->arch.vpit;\n\tstruct hrtimer *timer;\n\n\t \n\tif (vcpu->vcpu_id || !pit)\n\t\treturn;\n\n\ttimer = &pit->pit_state.timer;\n\tmutex_lock(&pit->pit_state.lock);\n\tif (hrtimer_cancel(timer))\n\t\thrtimer_start_expires(timer, HRTIMER_MODE_ABS);\n\tmutex_unlock(&pit->pit_state.lock);\n}\n\nstatic void destroy_pit_timer(struct kvm_pit *pit)\n{\n\thrtimer_cancel(&pit->pit_state.timer);\n\tkthread_flush_work(&pit->expired);\n}\n\nstatic void pit_do_work(struct kthread_work *work)\n{\n\tstruct kvm_pit *pit = container_of(work, struct kvm_pit, expired);\n\tstruct kvm *kvm = pit->kvm;\n\tstruct kvm_vcpu *vcpu;\n\tunsigned long i;\n\tstruct kvm_kpit_state *ps = &pit->pit_state;\n\n\tif (atomic_read(&ps->reinject) && !atomic_xchg(&ps->irq_ack, 0))\n\t\treturn;\n\n\tkvm_set_irq(kvm, pit->irq_source_id, 0, 1, false);\n\tkvm_set_irq(kvm, pit->irq_source_id, 0, 0, false);\n\n\t \n\tif (atomic_read(&kvm->arch.vapics_in_nmi_mode) > 0)\n\t\tkvm_for_each_vcpu(i, vcpu, kvm)\n\t\t\tkvm_apic_nmi_wd_deliver(vcpu);\n}\n\nstatic enum hrtimer_restart pit_timer_fn(struct hrtimer *data)\n{\n\tstruct kvm_kpit_state *ps = container_of(data, struct kvm_kpit_state, timer);\n\tstruct kvm_pit *pt = pit_state_to_pit(ps);\n\n\tif (atomic_read(&ps->reinject))\n\t\tatomic_inc(&ps->pending);\n\n\tkthread_queue_work(pt->worker, &pt->expired);\n\n\tif (ps->is_periodic) {\n\t\thrtimer_add_expires_ns(&ps->timer, ps->period);\n\t\treturn HRTIMER_RESTART;\n\t} else\n\t\treturn HRTIMER_NORESTART;\n}\n\nstatic inline void kvm_pit_reset_reinject(struct kvm_pit *pit)\n{\n\tatomic_set(&pit->pit_state.pending, 0);\n\tatomic_set(&pit->pit_state.irq_ack, 1);\n}\n\nvoid kvm_pit_set_reinject(struct kvm_pit *pit, bool reinject)\n{\n\tstruct kvm_kpit_state *ps = &pit->pit_state;\n\tstruct kvm *kvm = pit->kvm;\n\n\tif (atomic_read(&ps->reinject) == reinject)\n\t\treturn;\n\n\t \n\tif (reinject) {\n\t\tkvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);\n\t\t \n\t\tkvm_pit_reset_reinject(pit);\n\t\tkvm_register_irq_ack_notifier(kvm, &ps->irq_ack_notifier);\n\t\tkvm_register_irq_mask_notifier(kvm, 0, &pit->mask_notifier);\n\t} else {\n\t\tkvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);\n\t\tkvm_unregister_irq_ack_notifier(kvm, &ps->irq_ack_notifier);\n\t\tkvm_unregister_irq_mask_notifier(kvm, 0, &pit->mask_notifier);\n\t}\n\n\tatomic_set(&ps->reinject, reinject);\n}\n\nstatic void create_pit_timer(struct kvm_pit *pit, u32 val, int is_period)\n{\n\tstruct kvm_kpit_state *ps = &pit->pit_state;\n\tstruct kvm *kvm = pit->kvm;\n\ts64 interval;\n\n\tif (!ioapic_in_kernel(kvm) ||\n\t    ps->flags & KVM_PIT_FLAGS_HPET_LEGACY)\n\t\treturn;\n\n\tinterval = mul_u64_u32_div(val, NSEC_PER_SEC, KVM_PIT_FREQ);\n\n\tpr_debug(\"create pit timer, interval is %llu nsec\\n\", interval);\n\n\t \n\thrtimer_cancel(&ps->timer);\n\tkthread_flush_work(&pit->expired);\n\tps->period = interval;\n\tps->is_periodic = is_period;\n\n\tkvm_pit_reset_reinject(pit);\n\n\t \n\tif (ps->is_periodic) {\n\t\ts64 min_period = min_timer_period_us * 1000LL;\n\n\t\tif (ps->period < min_period) {\n\t\t\tpr_info_ratelimited(\n\t\t\t    \"requested %lld ns \"\n\t\t\t    \"i8254 timer period limited to %lld ns\\n\",\n\t\t\t    ps->period, min_period);\n\t\t\tps->period = min_period;\n\t\t}\n\t}\n\n\thrtimer_start(&ps->timer, ktime_add_ns(ktime_get(), interval),\n\t\t      HRTIMER_MODE_ABS);\n}\n\nstatic void pit_load_count(struct kvm_pit *pit, int channel, u32 val)\n{\n\tstruct kvm_kpit_state *ps = &pit->pit_state;\n\n\tpr_debug(\"load_count val is %u, channel is %d\\n\", val, channel);\n\n\t \n\tif (val == 0)\n\t\tval = 0x10000;\n\n\tps->channels[channel].count = val;\n\n\tif (channel != 0) {\n\t\tps->channels[channel].count_load_time = ktime_get();\n\t\treturn;\n\t}\n\n\t \n\tswitch (ps->channels[0].mode) {\n\tcase 0:\n\tcase 1:\n         \n\tcase 4:\n\t\tcreate_pit_timer(pit, val, 0);\n\t\tbreak;\n\tcase 2:\n\tcase 3:\n\t\tcreate_pit_timer(pit, val, 1);\n\t\tbreak;\n\tdefault:\n\t\tdestroy_pit_timer(pit);\n\t}\n}\n\nvoid kvm_pit_load_count(struct kvm_pit *pit, int channel, u32 val,\n\t\tint hpet_legacy_start)\n{\n\tu8 saved_mode;\n\n\tWARN_ON_ONCE(!mutex_is_locked(&pit->pit_state.lock));\n\n\tif (hpet_legacy_start) {\n\t\t \n\t\tWARN_ON(channel != 0);\n\t\tsaved_mode = pit->pit_state.channels[0].mode;\n\t\tpit->pit_state.channels[0].mode = 0xff;  \n\t\tpit_load_count(pit, channel, val);\n\t\tpit->pit_state.channels[0].mode = saved_mode;\n\t} else {\n\t\tpit_load_count(pit, channel, val);\n\t}\n}\n\nstatic inline struct kvm_pit *dev_to_pit(struct kvm_io_device *dev)\n{\n\treturn container_of(dev, struct kvm_pit, dev);\n}\n\nstatic inline struct kvm_pit *speaker_to_pit(struct kvm_io_device *dev)\n{\n\treturn container_of(dev, struct kvm_pit, speaker_dev);\n}\n\nstatic inline int pit_in_range(gpa_t addr)\n{\n\treturn ((addr >= KVM_PIT_BASE_ADDRESS) &&\n\t\t(addr < KVM_PIT_BASE_ADDRESS + KVM_PIT_MEM_LENGTH));\n}\n\nstatic int pit_ioport_write(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct kvm_io_device *this,\n\t\t\t    gpa_t addr, int len, const void *data)\n{\n\tstruct kvm_pit *pit = dev_to_pit(this);\n\tstruct kvm_kpit_state *pit_state = &pit->pit_state;\n\tint channel, access;\n\tstruct kvm_kpit_channel_state *s;\n\tu32 val = *(u32 *) data;\n\tif (!pit_in_range(addr))\n\t\treturn -EOPNOTSUPP;\n\n\tval  &= 0xff;\n\taddr &= KVM_PIT_CHANNEL_MASK;\n\n\tmutex_lock(&pit_state->lock);\n\n\tif (val != 0)\n\t\tpr_debug(\"write addr is 0x%x, len is %d, val is 0x%x\\n\",\n\t\t\t (unsigned int)addr, len, val);\n\n\tif (addr == 3) {\n\t\tchannel = val >> 6;\n\t\tif (channel == 3) {\n\t\t\t \n\t\t\tfor (channel = 0; channel < 3; channel++) {\n\t\t\t\tif (val & (2 << channel)) {\n\t\t\t\t\tif (!(val & 0x20))\n\t\t\t\t\t\tpit_latch_count(pit, channel);\n\t\t\t\t\tif (!(val & 0x10))\n\t\t\t\t\t\tpit_latch_status(pit, channel);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\ts = &pit_state->channels[channel];\n\t\t\taccess = (val >> 4) & KVM_PIT_CHANNEL_MASK;\n\t\t\tif (access == 0) {\n\t\t\t\tpit_latch_count(pit, channel);\n\t\t\t} else {\n\t\t\t\ts->rw_mode = access;\n\t\t\t\ts->read_state = access;\n\t\t\t\ts->write_state = access;\n\t\t\t\ts->mode = (val >> 1) & 7;\n\t\t\t\tif (s->mode > 5)\n\t\t\t\t\ts->mode -= 4;\n\t\t\t\ts->bcd = val & 1;\n\t\t\t}\n\t\t}\n\t} else {\n\t\t \n\t\ts = &pit_state->channels[addr];\n\t\tswitch (s->write_state) {\n\t\tdefault:\n\t\tcase RW_STATE_LSB:\n\t\t\tpit_load_count(pit, addr, val);\n\t\t\tbreak;\n\t\tcase RW_STATE_MSB:\n\t\t\tpit_load_count(pit, addr, val << 8);\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD0:\n\t\t\ts->write_latch = val;\n\t\t\ts->write_state = RW_STATE_WORD1;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD1:\n\t\t\tpit_load_count(pit, addr, s->write_latch | (val << 8));\n\t\t\ts->write_state = RW_STATE_WORD0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmutex_unlock(&pit_state->lock);\n\treturn 0;\n}\n\nstatic int pit_ioport_read(struct kvm_vcpu *vcpu,\n\t\t\t   struct kvm_io_device *this,\n\t\t\t   gpa_t addr, int len, void *data)\n{\n\tstruct kvm_pit *pit = dev_to_pit(this);\n\tstruct kvm_kpit_state *pit_state = &pit->pit_state;\n\tint ret, count;\n\tstruct kvm_kpit_channel_state *s;\n\tif (!pit_in_range(addr))\n\t\treturn -EOPNOTSUPP;\n\n\taddr &= KVM_PIT_CHANNEL_MASK;\n\tif (addr == 3)\n\t\treturn 0;\n\n\ts = &pit_state->channels[addr];\n\n\tmutex_lock(&pit_state->lock);\n\n\tif (s->status_latched) {\n\t\ts->status_latched = 0;\n\t\tret = s->status;\n\t} else if (s->count_latched) {\n\t\tswitch (s->count_latched) {\n\t\tdefault:\n\t\tcase RW_STATE_LSB:\n\t\t\tret = s->latched_count & 0xff;\n\t\t\ts->count_latched = 0;\n\t\t\tbreak;\n\t\tcase RW_STATE_MSB:\n\t\t\tret = s->latched_count >> 8;\n\t\t\ts->count_latched = 0;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD0:\n\t\t\tret = s->latched_count & 0xff;\n\t\t\ts->count_latched = RW_STATE_MSB;\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tswitch (s->read_state) {\n\t\tdefault:\n\t\tcase RW_STATE_LSB:\n\t\t\tcount = pit_get_count(pit, addr);\n\t\t\tret = count & 0xff;\n\t\t\tbreak;\n\t\tcase RW_STATE_MSB:\n\t\t\tcount = pit_get_count(pit, addr);\n\t\t\tret = (count >> 8) & 0xff;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD0:\n\t\t\tcount = pit_get_count(pit, addr);\n\t\t\tret = count & 0xff;\n\t\t\ts->read_state = RW_STATE_WORD1;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD1:\n\t\t\tcount = pit_get_count(pit, addr);\n\t\t\tret = (count >> 8) & 0xff;\n\t\t\ts->read_state = RW_STATE_WORD0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (len > sizeof(ret))\n\t\tlen = sizeof(ret);\n\tmemcpy(data, (char *)&ret, len);\n\n\tmutex_unlock(&pit_state->lock);\n\treturn 0;\n}\n\nstatic int speaker_ioport_write(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct kvm_io_device *this,\n\t\t\t\tgpa_t addr, int len, const void *data)\n{\n\tstruct kvm_pit *pit = speaker_to_pit(this);\n\tstruct kvm_kpit_state *pit_state = &pit->pit_state;\n\tu32 val = *(u32 *) data;\n\tif (addr != KVM_SPEAKER_BASE_ADDRESS)\n\t\treturn -EOPNOTSUPP;\n\n\tmutex_lock(&pit_state->lock);\n\tif (val & (1 << 1))\n\t\tpit_state->flags |= KVM_PIT_FLAGS_SPEAKER_DATA_ON;\n\telse\n\t\tpit_state->flags &= ~KVM_PIT_FLAGS_SPEAKER_DATA_ON;\n\tpit_set_gate(pit, 2, val & 1);\n\tmutex_unlock(&pit_state->lock);\n\treturn 0;\n}\n\nstatic int speaker_ioport_read(struct kvm_vcpu *vcpu,\n\t\t\t\t   struct kvm_io_device *this,\n\t\t\t\t   gpa_t addr, int len, void *data)\n{\n\tstruct kvm_pit *pit = speaker_to_pit(this);\n\tstruct kvm_kpit_state *pit_state = &pit->pit_state;\n\tunsigned int refresh_clock;\n\tint ret;\n\tif (addr != KVM_SPEAKER_BASE_ADDRESS)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\trefresh_clock = ((unsigned int)ktime_to_ns(ktime_get()) >> 14) & 1;\n\n\tmutex_lock(&pit_state->lock);\n\tret = (!!(pit_state->flags & KVM_PIT_FLAGS_SPEAKER_DATA_ON) << 1) |\n\t\tpit_get_gate(pit, 2) | (pit_get_out(pit, 2) << 5) |\n\t\t(refresh_clock << 4);\n\tif (len > sizeof(ret))\n\t\tlen = sizeof(ret);\n\tmemcpy(data, (char *)&ret, len);\n\tmutex_unlock(&pit_state->lock);\n\treturn 0;\n}\n\nstatic void kvm_pit_reset(struct kvm_pit *pit)\n{\n\tint i;\n\tstruct kvm_kpit_channel_state *c;\n\n\tpit->pit_state.flags = 0;\n\tfor (i = 0; i < 3; i++) {\n\t\tc = &pit->pit_state.channels[i];\n\t\tc->mode = 0xff;\n\t\tc->gate = (i != 2);\n\t\tpit_load_count(pit, i, 0);\n\t}\n\n\tkvm_pit_reset_reinject(pit);\n}\n\nstatic void pit_mask_notifer(struct kvm_irq_mask_notifier *kimn, bool mask)\n{\n\tstruct kvm_pit *pit = container_of(kimn, struct kvm_pit, mask_notifier);\n\n\tif (!mask)\n\t\tkvm_pit_reset_reinject(pit);\n}\n\nstatic const struct kvm_io_device_ops pit_dev_ops = {\n\t.read     = pit_ioport_read,\n\t.write    = pit_ioport_write,\n};\n\nstatic const struct kvm_io_device_ops speaker_dev_ops = {\n\t.read     = speaker_ioport_read,\n\t.write    = speaker_ioport_write,\n};\n\nstruct kvm_pit *kvm_create_pit(struct kvm *kvm, u32 flags)\n{\n\tstruct kvm_pit *pit;\n\tstruct kvm_kpit_state *pit_state;\n\tstruct pid *pid;\n\tpid_t pid_nr;\n\tint ret;\n\n\tpit = kzalloc(sizeof(struct kvm_pit), GFP_KERNEL_ACCOUNT);\n\tif (!pit)\n\t\treturn NULL;\n\n\tpit->irq_source_id = kvm_request_irq_source_id(kvm);\n\tif (pit->irq_source_id < 0)\n\t\tgoto fail_request;\n\n\tmutex_init(&pit->pit_state.lock);\n\n\tpid = get_pid(task_tgid(current));\n\tpid_nr = pid_vnr(pid);\n\tput_pid(pid);\n\n\tpit->worker = kthread_create_worker(0, \"kvm-pit/%d\", pid_nr);\n\tif (IS_ERR(pit->worker))\n\t\tgoto fail_kthread;\n\n\tkthread_init_work(&pit->expired, pit_do_work);\n\n\tpit->kvm = kvm;\n\n\tpit_state = &pit->pit_state;\n\thrtimer_init(&pit_state->timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS);\n\tpit_state->timer.function = pit_timer_fn;\n\n\tpit_state->irq_ack_notifier.gsi = 0;\n\tpit_state->irq_ack_notifier.irq_acked = kvm_pit_ack_irq;\n\tpit->mask_notifier.func = pit_mask_notifer;\n\n\tkvm_pit_reset(pit);\n\n\tkvm_pit_set_reinject(pit, true);\n\n\tmutex_lock(&kvm->slots_lock);\n\tkvm_iodevice_init(&pit->dev, &pit_dev_ops);\n\tret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, KVM_PIT_BASE_ADDRESS,\n\t\t\t\t      KVM_PIT_MEM_LENGTH, &pit->dev);\n\tif (ret < 0)\n\t\tgoto fail_register_pit;\n\n\tif (flags & KVM_PIT_SPEAKER_DUMMY) {\n\t\tkvm_iodevice_init(&pit->speaker_dev, &speaker_dev_ops);\n\t\tret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS,\n\t\t\t\t\t      KVM_SPEAKER_BASE_ADDRESS, 4,\n\t\t\t\t\t      &pit->speaker_dev);\n\t\tif (ret < 0)\n\t\t\tgoto fail_register_speaker;\n\t}\n\tmutex_unlock(&kvm->slots_lock);\n\n\treturn pit;\n\nfail_register_speaker:\n\tkvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS, &pit->dev);\nfail_register_pit:\n\tmutex_unlock(&kvm->slots_lock);\n\tkvm_pit_set_reinject(pit, false);\n\tkthread_destroy_worker(pit->worker);\nfail_kthread:\n\tkvm_free_irq_source_id(kvm, pit->irq_source_id);\nfail_request:\n\tkfree(pit);\n\treturn NULL;\n}\n\nvoid kvm_free_pit(struct kvm *kvm)\n{\n\tstruct kvm_pit *pit = kvm->arch.vpit;\n\n\tif (pit) {\n\t\tmutex_lock(&kvm->slots_lock);\n\t\tkvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS, &pit->dev);\n\t\tkvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS, &pit->speaker_dev);\n\t\tmutex_unlock(&kvm->slots_lock);\n\t\tkvm_pit_set_reinject(pit, false);\n\t\thrtimer_cancel(&pit->pit_state.timer);\n\t\tkthread_destroy_worker(pit->worker);\n\t\tkvm_free_irq_source_id(kvm, pit->irq_source_id);\n\t\tkfree(pit);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}