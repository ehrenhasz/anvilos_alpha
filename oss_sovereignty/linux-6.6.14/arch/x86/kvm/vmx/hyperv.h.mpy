{
  "module_name": "hyperv.h",
  "hash_id": "522f852bc582b77fceb6e8d348edc99db21739cd851f7d23ee2c54bc894f472d",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/vmx/hyperv.h",
  "human_readable_source": " \n#ifndef __KVM_X86_VMX_HYPERV_H\n#define __KVM_X86_VMX_HYPERV_H\n\n#include <linux/jump_label.h>\n\n#include <asm/hyperv-tlfs.h>\n#include <asm/mshyperv.h>\n#include <asm/vmx.h>\n\n#include \"../hyperv.h\"\n\n#include \"capabilities.h\"\n#include \"vmcs.h\"\n#include \"vmcs12.h\"\n\nstruct vmcs_config;\n\n#define current_evmcs ((struct hv_enlightened_vmcs *)this_cpu_read(current_vmcs))\n\n#define KVM_EVMCS_VERSION 1\n\nstruct evmcs_field {\n\tu16 offset;\n\tu16 clean_field;\n};\n\nextern const struct evmcs_field vmcs_field_to_evmcs_1[];\nextern const unsigned int nr_evmcs_1_fields;\n\nstatic __always_inline int evmcs_field_offset(unsigned long field,\n\t\t\t\t\t      u16 *clean_field)\n{\n\tunsigned int index = ROL16(field, 6);\n\tconst struct evmcs_field *evmcs_field;\n\n\tif (unlikely(index >= nr_evmcs_1_fields))\n\t\treturn -ENOENT;\n\n\tevmcs_field = &vmcs_field_to_evmcs_1[index];\n\n\t \n\tif (unlikely(!evmcs_field->offset))\n\t\treturn -ENOENT;\n\n\tif (clean_field)\n\t\t*clean_field = evmcs_field->clean_field;\n\n\treturn evmcs_field->offset;\n}\n\nstatic inline u64 evmcs_read_any(struct hv_enlightened_vmcs *evmcs,\n\t\t\t\t unsigned long field, u16 offset)\n{\n\t \n\treturn vmcs12_read_any((void *)evmcs, field, offset);\n}\n\n#if IS_ENABLED(CONFIG_HYPERV)\n\nDECLARE_STATIC_KEY_FALSE(__kvm_is_using_evmcs);\n\nstatic __always_inline bool kvm_is_using_evmcs(void)\n{\n\treturn static_branch_unlikely(&__kvm_is_using_evmcs);\n}\n\nstatic __always_inline int get_evmcs_offset(unsigned long field,\n\t\t\t\t\t    u16 *clean_field)\n{\n\tint offset = evmcs_field_offset(field, clean_field);\n\n\tWARN_ONCE(offset < 0, \"accessing unsupported EVMCS field %lx\\n\", field);\n\treturn offset;\n}\n\nstatic __always_inline void evmcs_write64(unsigned long field, u64 value)\n{\n\tu16 clean_field;\n\tint offset = get_evmcs_offset(field, &clean_field);\n\n\tif (offset < 0)\n\t\treturn;\n\n\t*(u64 *)((char *)current_evmcs + offset) = value;\n\n\tcurrent_evmcs->hv_clean_fields &= ~clean_field;\n}\n\nstatic __always_inline void evmcs_write32(unsigned long field, u32 value)\n{\n\tu16 clean_field;\n\tint offset = get_evmcs_offset(field, &clean_field);\n\n\tif (offset < 0)\n\t\treturn;\n\n\t*(u32 *)((char *)current_evmcs + offset) = value;\n\tcurrent_evmcs->hv_clean_fields &= ~clean_field;\n}\n\nstatic __always_inline void evmcs_write16(unsigned long field, u16 value)\n{\n\tu16 clean_field;\n\tint offset = get_evmcs_offset(field, &clean_field);\n\n\tif (offset < 0)\n\t\treturn;\n\n\t*(u16 *)((char *)current_evmcs + offset) = value;\n\tcurrent_evmcs->hv_clean_fields &= ~clean_field;\n}\n\nstatic __always_inline u64 evmcs_read64(unsigned long field)\n{\n\tint offset = get_evmcs_offset(field, NULL);\n\n\tif (offset < 0)\n\t\treturn 0;\n\n\treturn *(u64 *)((char *)current_evmcs + offset);\n}\n\nstatic __always_inline u32 evmcs_read32(unsigned long field)\n{\n\tint offset = get_evmcs_offset(field, NULL);\n\n\tif (offset < 0)\n\t\treturn 0;\n\n\treturn *(u32 *)((char *)current_evmcs + offset);\n}\n\nstatic __always_inline u16 evmcs_read16(unsigned long field)\n{\n\tint offset = get_evmcs_offset(field, NULL);\n\n\tif (offset < 0)\n\t\treturn 0;\n\n\treturn *(u16 *)((char *)current_evmcs + offset);\n}\n\nstatic inline void evmcs_load(u64 phys_addr)\n{\n\tstruct hv_vp_assist_page *vp_ap =\n\t\thv_get_vp_assist_page(smp_processor_id());\n\n\tif (current_evmcs->hv_enlightenments_control.nested_flush_hypercall)\n\t\tvp_ap->nested_control.features.directhypercall = 1;\n\tvp_ap->current_nested_vmcs = phys_addr;\n\tvp_ap->enlighten_vmentry = 1;\n}\n\nvoid evmcs_sanitize_exec_ctrls(struct vmcs_config *vmcs_conf);\n#else  \nstatic __always_inline bool kvm_is_using_evmcs(void) { return false; }\nstatic __always_inline void evmcs_write64(unsigned long field, u64 value) {}\nstatic __always_inline void evmcs_write32(unsigned long field, u32 value) {}\nstatic __always_inline void evmcs_write16(unsigned long field, u16 value) {}\nstatic __always_inline u64 evmcs_read64(unsigned long field) { return 0; }\nstatic __always_inline u32 evmcs_read32(unsigned long field) { return 0; }\nstatic __always_inline u16 evmcs_read16(unsigned long field) { return 0; }\nstatic inline void evmcs_load(u64 phys_addr) {}\n#endif  \n\n#define EVMPTR_INVALID (-1ULL)\n#define EVMPTR_MAP_PENDING (-2ULL)\n\nstatic inline bool evmptr_is_valid(u64 evmptr)\n{\n\treturn evmptr != EVMPTR_INVALID && evmptr != EVMPTR_MAP_PENDING;\n}\n\nenum nested_evmptrld_status {\n\tEVMPTRLD_DISABLED,\n\tEVMPTRLD_SUCCEEDED,\n\tEVMPTRLD_VMFAIL,\n\tEVMPTRLD_ERROR,\n};\n\nu64 nested_get_evmptr(struct kvm_vcpu *vcpu);\nuint16_t nested_get_evmcs_version(struct kvm_vcpu *vcpu);\nint nested_enable_evmcs(struct kvm_vcpu *vcpu,\n\t\t\tuint16_t *vmcs_version);\nvoid nested_evmcs_filter_control_msr(struct kvm_vcpu *vcpu, u32 msr_index, u64 *pdata);\nint nested_evmcs_check_controls(struct vmcs12 *vmcs12);\nbool nested_evmcs_l2_tlb_flush_enabled(struct kvm_vcpu *vcpu);\nvoid vmx_hv_inject_synthetic_vmexit_post_tlb_flush(struct kvm_vcpu *vcpu);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}