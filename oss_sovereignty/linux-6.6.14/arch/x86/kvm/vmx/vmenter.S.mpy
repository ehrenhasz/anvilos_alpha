{
  "module_name": "vmenter.S",
  "hash_id": "ea9207f6e5ea5ef90ee6e9c942756fe7bbf3e4db5e1efca5fd0a8c27d6ab0e04",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/vmx/vmenter.S",
  "human_readable_source": " \n#include <linux/linkage.h>\n#include <asm/asm.h>\n#include <asm/bitsperlong.h>\n#include <asm/kvm_vcpu_regs.h>\n#include <asm/nospec-branch.h>\n#include <asm/percpu.h>\n#include <asm/segment.h>\n#include \"kvm-asm-offsets.h\"\n#include \"run_flags.h\"\n\n#define WORD_SIZE (BITS_PER_LONG / 8)\n\n#define VCPU_RAX\t__VCPU_REGS_RAX * WORD_SIZE\n#define VCPU_RCX\t__VCPU_REGS_RCX * WORD_SIZE\n#define VCPU_RDX\t__VCPU_REGS_RDX * WORD_SIZE\n#define VCPU_RBX\t__VCPU_REGS_RBX * WORD_SIZE\n \n#define VCPU_RBP\t__VCPU_REGS_RBP * WORD_SIZE\n#define VCPU_RSI\t__VCPU_REGS_RSI * WORD_SIZE\n#define VCPU_RDI\t__VCPU_REGS_RDI * WORD_SIZE\n\n#ifdef CONFIG_X86_64\n#define VCPU_R8\t\t__VCPU_REGS_R8  * WORD_SIZE\n#define VCPU_R9\t\t__VCPU_REGS_R9  * WORD_SIZE\n#define VCPU_R10\t__VCPU_REGS_R10 * WORD_SIZE\n#define VCPU_R11\t__VCPU_REGS_R11 * WORD_SIZE\n#define VCPU_R12\t__VCPU_REGS_R12 * WORD_SIZE\n#define VCPU_R13\t__VCPU_REGS_R13 * WORD_SIZE\n#define VCPU_R14\t__VCPU_REGS_R14 * WORD_SIZE\n#define VCPU_R15\t__VCPU_REGS_R15 * WORD_SIZE\n#endif\n\n.macro VMX_DO_EVENT_IRQOFF call_insn call_target\n\t \n\tpush %_ASM_BP\n\tmov %_ASM_SP, %_ASM_BP\n\n#ifdef CONFIG_X86_64\n\t \n\tand  $-16, %rsp\n\tpush $__KERNEL_DS\n\tpush %rbp\n#endif\n\tpushf\n\tpush $__KERNEL_CS\n\t\\call_insn \\call_target\n\n\t \n\tmov %_ASM_BP, %_ASM_SP\n\tpop %_ASM_BP\n\tRET\n.endm\n\n.section .noinstr.text, \"ax\"\n\n \nSYM_FUNC_START(__vmx_vcpu_run)\n\tpush %_ASM_BP\n\tmov  %_ASM_SP, %_ASM_BP\n#ifdef CONFIG_X86_64\n\tpush %r15\n\tpush %r14\n\tpush %r13\n\tpush %r12\n#else\n\tpush %edi\n\tpush %esi\n#endif\n\tpush %_ASM_BX\n\n\t \n\tpush %_ASM_ARG1\n\n\t \n\tpush %_ASM_ARG3\n\n\t \n\tpush %_ASM_ARG2\n\n\t \n\tmov %_ASM_ARG3L, %ebx\n\n\tlea (%_ASM_SP), %_ASM_ARG2\n\tcall vmx_update_host_rsp\n\n\tALTERNATIVE \"jmp .Lspec_ctrl_done\", \"\", X86_FEATURE_MSR_SPEC_CTRL\n\n\t \n\tmov 2*WORD_SIZE(%_ASM_SP), %_ASM_DI\n\tmovl VMX_spec_ctrl(%_ASM_DI), %edi\n\tmovl PER_CPU_VAR(x86_spec_ctrl_current), %esi\n\tcmp %edi, %esi\n\tje .Lspec_ctrl_done\n\tmov $MSR_IA32_SPEC_CTRL, %ecx\n\txor %edx, %edx\n\tmov %edi, %eax\n\twrmsr\n\n.Lspec_ctrl_done:\n\n\t \n\n\t \n\tmov (%_ASM_SP), %_ASM_AX\n\n\t \n\ttest $VMX_RUN_VMRESUME, %ebx\n\n\t \n\tmov VCPU_RCX(%_ASM_AX), %_ASM_CX\n\tmov VCPU_RDX(%_ASM_AX), %_ASM_DX\n\tmov VCPU_RBX(%_ASM_AX), %_ASM_BX\n\tmov VCPU_RBP(%_ASM_AX), %_ASM_BP\n\tmov VCPU_RSI(%_ASM_AX), %_ASM_SI\n\tmov VCPU_RDI(%_ASM_AX), %_ASM_DI\n#ifdef CONFIG_X86_64\n\tmov VCPU_R8 (%_ASM_AX),  %r8\n\tmov VCPU_R9 (%_ASM_AX),  %r9\n\tmov VCPU_R10(%_ASM_AX), %r10\n\tmov VCPU_R11(%_ASM_AX), %r11\n\tmov VCPU_R12(%_ASM_AX), %r12\n\tmov VCPU_R13(%_ASM_AX), %r13\n\tmov VCPU_R14(%_ASM_AX), %r14\n\tmov VCPU_R15(%_ASM_AX), %r15\n#endif\n\t \n\tmov VCPU_RAX(%_ASM_AX), %_ASM_AX\n\n\t \n\tjz .Lvmlaunch\n\n\t \n\tUNWIND_HINT_SAVE\n\n \n.Lvmresume:\n\tvmresume\n\tjmp .Lvmfail\n\n.Lvmlaunch:\n\tvmlaunch\n\tjmp .Lvmfail\n\n\t_ASM_EXTABLE(.Lvmresume, .Lfixup)\n\t_ASM_EXTABLE(.Lvmlaunch, .Lfixup)\n\nSYM_INNER_LABEL_ALIGN(vmx_vmexit, SYM_L_GLOBAL)\n\n\t \n\tUNWIND_HINT_RESTORE\n\tENDBR\n\n\t \n\tpush %_ASM_AX\n\n\t \n\tmov WORD_SIZE(%_ASM_SP), %_ASM_AX\n\n\t \n\tpop           VCPU_RAX(%_ASM_AX)\n\tmov %_ASM_CX, VCPU_RCX(%_ASM_AX)\n\tmov %_ASM_DX, VCPU_RDX(%_ASM_AX)\n\tmov %_ASM_BX, VCPU_RBX(%_ASM_AX)\n\tmov %_ASM_BP, VCPU_RBP(%_ASM_AX)\n\tmov %_ASM_SI, VCPU_RSI(%_ASM_AX)\n\tmov %_ASM_DI, VCPU_RDI(%_ASM_AX)\n#ifdef CONFIG_X86_64\n\tmov %r8,  VCPU_R8 (%_ASM_AX)\n\tmov %r9,  VCPU_R9 (%_ASM_AX)\n\tmov %r10, VCPU_R10(%_ASM_AX)\n\tmov %r11, VCPU_R11(%_ASM_AX)\n\tmov %r12, VCPU_R12(%_ASM_AX)\n\tmov %r13, VCPU_R13(%_ASM_AX)\n\tmov %r14, VCPU_R14(%_ASM_AX)\n\tmov %r15, VCPU_R15(%_ASM_AX)\n#endif\n\n\t \n\txor %ebx, %ebx\n\n.Lclear_regs:\n\t \n\tpop %_ASM_AX\n\n\t \n\txor %eax, %eax\n\txor %ecx, %ecx\n\txor %edx, %edx\n\txor %ebp, %ebp\n\txor %esi, %esi\n\txor %edi, %edi\n#ifdef CONFIG_X86_64\n\txor %r8d,  %r8d\n\txor %r9d,  %r9d\n\txor %r10d, %r10d\n\txor %r11d, %r11d\n\txor %r12d, %r12d\n\txor %r13d, %r13d\n\txor %r14d, %r14d\n\txor %r15d, %r15d\n#endif\n\n\t \n\n\tFILL_RETURN_BUFFER %_ASM_CX, RSB_CLEAR_LOOPS, X86_FEATURE_RSB_VMEXIT,\\\n\t\t\t   X86_FEATURE_RSB_VMEXIT_LITE\n\n\tpop %_ASM_ARG2\t \n\tpop %_ASM_ARG1\t \n\n\tcall vmx_spec_ctrl_restore_host\n\n\t \n\tmov %_ASM_BX, %_ASM_AX\n\n\tpop %_ASM_BX\n#ifdef CONFIG_X86_64\n\tpop %r12\n\tpop %r13\n\tpop %r14\n\tpop %r15\n#else\n\tpop %esi\n\tpop %edi\n#endif\n\tpop %_ASM_BP\n\tRET\n\n.Lfixup:\n\tcmpb $0, kvm_rebooting\n\tjne .Lvmfail\n\tud2\n.Lvmfail:\n\t \n\tmov $1, %_ASM_BX\n\tjmp .Lclear_regs\n\nSYM_FUNC_END(__vmx_vcpu_run)\n\nSYM_FUNC_START(vmx_do_nmi_irqoff)\n\tVMX_DO_EVENT_IRQOFF call asm_exc_nmi_kvm_vmx\nSYM_FUNC_END(vmx_do_nmi_irqoff)\n\n#ifndef CONFIG_CC_HAS_ASM_GOTO_OUTPUT\n\n \nSYM_FUNC_START(vmread_error_trampoline)\n\tpush %_ASM_BP\n\tmov  %_ASM_SP, %_ASM_BP\n\n\tpush %_ASM_AX\n\tpush %_ASM_CX\n\tpush %_ASM_DX\n#ifdef CONFIG_X86_64\n\tpush %rdi\n\tpush %rsi\n\tpush %r8\n\tpush %r9\n\tpush %r10\n\tpush %r11\n#endif\n\n\t \n\tmov 3*WORD_SIZE(%_ASM_BP), %_ASM_ARG2\n\tmov 2*WORD_SIZE(%_ASM_BP), %_ASM_ARG1\n\n\tcall vmread_error_trampoline2\n\n\t \n\t_ASM_MOV $0, 3*WORD_SIZE(%_ASM_BP)\n\n#ifdef CONFIG_X86_64\n\tpop %r11\n\tpop %r10\n\tpop %r9\n\tpop %r8\n\tpop %rsi\n\tpop %rdi\n#endif\n\tpop %_ASM_DX\n\tpop %_ASM_CX\n\tpop %_ASM_AX\n\tpop %_ASM_BP\n\n\tRET\nSYM_FUNC_END(vmread_error_trampoline)\n#endif\n\n.section .text, \"ax\"\n\nSYM_FUNC_START(vmx_do_interrupt_irqoff)\n\tVMX_DO_EVENT_IRQOFF CALL_NOSPEC _ASM_ARG1\nSYM_FUNC_END(vmx_do_interrupt_irqoff)\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}