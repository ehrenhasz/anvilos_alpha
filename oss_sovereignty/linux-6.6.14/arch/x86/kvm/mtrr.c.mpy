{
  "module_name": "mtrr.c",
  "hash_id": "b9e35ebfb976f840e498071d9f52c5828813f935fa837833236003c04cbdcb19",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/mtrr.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kvm_host.h>\n#include <asm/mtrr.h>\n\n#include \"cpuid.h\"\n#include \"mmu.h\"\n\n#define IA32_MTRR_DEF_TYPE_E\t\t(1ULL << 11)\n#define IA32_MTRR_DEF_TYPE_FE\t\t(1ULL << 10)\n#define IA32_MTRR_DEF_TYPE_TYPE_MASK\t(0xff)\n\nstatic bool is_mtrr_base_msr(unsigned int msr)\n{\n\t \n\treturn !(msr & 0x1);\n}\n\nstatic struct kvm_mtrr_range *var_mtrr_msr_to_range(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t    unsigned int msr)\n{\n\tint index = (msr - MTRRphysBase_MSR(0)) / 2;\n\n\treturn &vcpu->arch.mtrr_state.var_ranges[index];\n}\n\nstatic bool msr_mtrr_valid(unsigned msr)\n{\n\tswitch (msr) {\n\tcase MTRRphysBase_MSR(0) ... MTRRphysMask_MSR(KVM_NR_VAR_MTRR - 1):\n\tcase MSR_MTRRfix64K_00000:\n\tcase MSR_MTRRfix16K_80000:\n\tcase MSR_MTRRfix16K_A0000:\n\tcase MSR_MTRRfix4K_C0000:\n\tcase MSR_MTRRfix4K_C8000:\n\tcase MSR_MTRRfix4K_D0000:\n\tcase MSR_MTRRfix4K_D8000:\n\tcase MSR_MTRRfix4K_E0000:\n\tcase MSR_MTRRfix4K_E8000:\n\tcase MSR_MTRRfix4K_F0000:\n\tcase MSR_MTRRfix4K_F8000:\n\tcase MSR_MTRRdefType:\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic bool valid_mtrr_type(unsigned t)\n{\n\treturn t < 8 && (1 << t) & 0x73;  \n}\n\nstatic bool kvm_mtrr_valid(struct kvm_vcpu *vcpu, u32 msr, u64 data)\n{\n\tint i;\n\tu64 mask;\n\n\tif (!msr_mtrr_valid(msr))\n\t\treturn false;\n\n\tif (msr == MSR_MTRRdefType) {\n\t\tif (data & ~0xcff)\n\t\t\treturn false;\n\t\treturn valid_mtrr_type(data & 0xff);\n\t} else if (msr >= MSR_MTRRfix64K_00000 && msr <= MSR_MTRRfix4K_F8000) {\n\t\tfor (i = 0; i < 8 ; i++)\n\t\t\tif (!valid_mtrr_type((data >> (i * 8)) & 0xff))\n\t\t\t\treturn false;\n\t\treturn true;\n\t}\n\n\t \n\tWARN_ON(!(msr >= MTRRphysBase_MSR(0) &&\n\t\t  msr <= MTRRphysMask_MSR(KVM_NR_VAR_MTRR - 1)));\n\n\tmask = kvm_vcpu_reserved_gpa_bits_raw(vcpu);\n\tif ((msr & 1) == 0) {\n\t\t \n\t\tif (!valid_mtrr_type(data & 0xff))\n\t\t\treturn false;\n\t\tmask |= 0xf00;\n\t} else\n\t\t \n\t\tmask |= 0x7ff;\n\n\treturn (data & mask) == 0;\n}\n\nstatic bool mtrr_is_enabled(struct kvm_mtrr *mtrr_state)\n{\n\treturn !!(mtrr_state->deftype & IA32_MTRR_DEF_TYPE_E);\n}\n\nstatic bool fixed_mtrr_is_enabled(struct kvm_mtrr *mtrr_state)\n{\n\treturn !!(mtrr_state->deftype & IA32_MTRR_DEF_TYPE_FE);\n}\n\nstatic u8 mtrr_default_type(struct kvm_mtrr *mtrr_state)\n{\n\treturn mtrr_state->deftype & IA32_MTRR_DEF_TYPE_TYPE_MASK;\n}\n\nstatic u8 mtrr_disabled_type(struct kvm_vcpu *vcpu)\n{\n\t \n\tif (guest_cpuid_has(vcpu, X86_FEATURE_MTRR))\n\t\treturn MTRR_TYPE_UNCACHABLE;\n\telse\n\t\treturn MTRR_TYPE_WRBACK;\n}\n\n \nstruct fixed_mtrr_segment {\n\tu64 start;\n\tu64 end;\n\n\tint range_shift;\n\n\t \n\tint range_start;\n};\n\nstatic struct fixed_mtrr_segment fixed_seg_table[] = {\n\t \n\t{\n\t\t.start = 0x0,\n\t\t.end = 0x80000,\n\t\t.range_shift = 16,  \n\t\t.range_start = 0,\n\t},\n\n\t \n\t{\n\t\t.start = 0x80000,\n\t\t.end = 0xc0000,\n\t\t.range_shift = 14,  \n\t\t.range_start = 8,\n\t},\n\n\t \n\t{\n\t\t.start = 0xc0000,\n\t\t.end = 0x100000,\n\t\t.range_shift = 12,  \n\t\t.range_start = 24,\n\t}\n};\n\n \nstatic u64 fixed_mtrr_seg_unit_size(int seg)\n{\n\treturn 8 << fixed_seg_table[seg].range_shift;\n}\n\nstatic bool fixed_msr_to_seg_unit(u32 msr, int *seg, int *unit)\n{\n\tswitch (msr) {\n\tcase MSR_MTRRfix64K_00000:\n\t\t*seg = 0;\n\t\t*unit = 0;\n\t\tbreak;\n\tcase MSR_MTRRfix16K_80000 ... MSR_MTRRfix16K_A0000:\n\t\t*seg = 1;\n\t\t*unit = array_index_nospec(\n\t\t\tmsr - MSR_MTRRfix16K_80000,\n\t\t\tMSR_MTRRfix16K_A0000 - MSR_MTRRfix16K_80000 + 1);\n\t\tbreak;\n\tcase MSR_MTRRfix4K_C0000 ... MSR_MTRRfix4K_F8000:\n\t\t*seg = 2;\n\t\t*unit = array_index_nospec(\n\t\t\tmsr - MSR_MTRRfix4K_C0000,\n\t\t\tMSR_MTRRfix4K_F8000 - MSR_MTRRfix4K_C0000 + 1);\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void fixed_mtrr_seg_unit_range(int seg, int unit, u64 *start, u64 *end)\n{\n\tstruct fixed_mtrr_segment *mtrr_seg = &fixed_seg_table[seg];\n\tu64 unit_size = fixed_mtrr_seg_unit_size(seg);\n\n\t*start = mtrr_seg->start + unit * unit_size;\n\t*end = *start + unit_size;\n\tWARN_ON(*end > mtrr_seg->end);\n}\n\nstatic int fixed_mtrr_seg_unit_range_index(int seg, int unit)\n{\n\tstruct fixed_mtrr_segment *mtrr_seg = &fixed_seg_table[seg];\n\n\tWARN_ON(mtrr_seg->start + unit * fixed_mtrr_seg_unit_size(seg)\n\t\t> mtrr_seg->end);\n\n\t \n\treturn mtrr_seg->range_start + 8 * unit;\n}\n\nstatic int fixed_mtrr_seg_end_range_index(int seg)\n{\n\tstruct fixed_mtrr_segment *mtrr_seg = &fixed_seg_table[seg];\n\tint n;\n\n\tn = (mtrr_seg->end - mtrr_seg->start) >> mtrr_seg->range_shift;\n\treturn mtrr_seg->range_start + n - 1;\n}\n\nstatic bool fixed_msr_to_range(u32 msr, u64 *start, u64 *end)\n{\n\tint seg, unit;\n\n\tif (!fixed_msr_to_seg_unit(msr, &seg, &unit))\n\t\treturn false;\n\n\tfixed_mtrr_seg_unit_range(seg, unit, start, end);\n\treturn true;\n}\n\nstatic int fixed_msr_to_range_index(u32 msr)\n{\n\tint seg, unit;\n\n\tif (!fixed_msr_to_seg_unit(msr, &seg, &unit))\n\t\treturn -1;\n\n\treturn fixed_mtrr_seg_unit_range_index(seg, unit);\n}\n\nstatic int fixed_mtrr_addr_to_seg(u64 addr)\n{\n\tstruct fixed_mtrr_segment *mtrr_seg;\n\tint seg, seg_num = ARRAY_SIZE(fixed_seg_table);\n\n\tfor (seg = 0; seg < seg_num; seg++) {\n\t\tmtrr_seg = &fixed_seg_table[seg];\n\t\tif (mtrr_seg->start <= addr && addr < mtrr_seg->end)\n\t\t\treturn seg;\n\t}\n\n\treturn -1;\n}\n\nstatic int fixed_mtrr_addr_seg_to_range_index(u64 addr, int seg)\n{\n\tstruct fixed_mtrr_segment *mtrr_seg;\n\tint index;\n\n\tmtrr_seg = &fixed_seg_table[seg];\n\tindex = mtrr_seg->range_start;\n\tindex += (addr - mtrr_seg->start) >> mtrr_seg->range_shift;\n\treturn index;\n}\n\nstatic u64 fixed_mtrr_range_end_addr(int seg, int index)\n{\n\tstruct fixed_mtrr_segment *mtrr_seg = &fixed_seg_table[seg];\n\tint pos = index - mtrr_seg->range_start;\n\n\treturn mtrr_seg->start + ((pos + 1) << mtrr_seg->range_shift);\n}\n\nstatic void var_mtrr_range(struct kvm_mtrr_range *range, u64 *start, u64 *end)\n{\n\tu64 mask;\n\n\t*start = range->base & PAGE_MASK;\n\n\tmask = range->mask & PAGE_MASK;\n\n\t \n\t*end = (*start | ~mask) + 1;\n}\n\nstatic void update_mtrr(struct kvm_vcpu *vcpu, u32 msr)\n{\n\tstruct kvm_mtrr *mtrr_state = &vcpu->arch.mtrr_state;\n\tgfn_t start, end;\n\n\tif (!tdp_enabled || !kvm_arch_has_noncoherent_dma(vcpu->kvm))\n\t\treturn;\n\n\tif (!mtrr_is_enabled(mtrr_state) && msr != MSR_MTRRdefType)\n\t\treturn;\n\n\t \n\tif (fixed_msr_to_range(msr, &start, &end)) {\n\t\tif (!fixed_mtrr_is_enabled(mtrr_state))\n\t\t\treturn;\n\t} else if (msr == MSR_MTRRdefType) {\n\t\tstart = 0x0;\n\t\tend = ~0ULL;\n\t} else {\n\t\t \n\t\tvar_mtrr_range(var_mtrr_msr_to_range(vcpu, msr), &start, &end);\n\t}\n\n\tkvm_zap_gfn_range(vcpu->kvm, gpa_to_gfn(start), gpa_to_gfn(end));\n}\n\nstatic bool var_mtrr_range_is_valid(struct kvm_mtrr_range *range)\n{\n\treturn (range->mask & (1 << 11)) != 0;\n}\n\nstatic void set_var_mtrr_msr(struct kvm_vcpu *vcpu, u32 msr, u64 data)\n{\n\tstruct kvm_mtrr *mtrr_state = &vcpu->arch.mtrr_state;\n\tstruct kvm_mtrr_range *tmp, *cur;\n\n\tcur = var_mtrr_msr_to_range(vcpu, msr);\n\n\t \n\tif (var_mtrr_range_is_valid(cur))\n\t\tlist_del(&cur->node);\n\n\t \n\tif (is_mtrr_base_msr(msr))\n\t\tcur->base = data;\n\telse\n\t\tcur->mask = data | kvm_vcpu_reserved_gpa_bits_raw(vcpu);\n\n\t \n\tif (var_mtrr_range_is_valid(cur)) {\n\t\tlist_for_each_entry(tmp, &mtrr_state->head, node)\n\t\t\tif (cur->base >= tmp->base)\n\t\t\t\tbreak;\n\t\tlist_add_tail(&cur->node, &tmp->node);\n\t}\n}\n\nint kvm_mtrr_set_msr(struct kvm_vcpu *vcpu, u32 msr, u64 data)\n{\n\tint index;\n\n\tif (!kvm_mtrr_valid(vcpu, msr, data))\n\t\treturn 1;\n\n\tindex = fixed_msr_to_range_index(msr);\n\tif (index >= 0)\n\t\t*(u64 *)&vcpu->arch.mtrr_state.fixed_ranges[index] = data;\n\telse if (msr == MSR_MTRRdefType)\n\t\tvcpu->arch.mtrr_state.deftype = data;\n\telse\n\t\tset_var_mtrr_msr(vcpu, msr, data);\n\n\tupdate_mtrr(vcpu, msr);\n\treturn 0;\n}\n\nint kvm_mtrr_get_msr(struct kvm_vcpu *vcpu, u32 msr, u64 *pdata)\n{\n\tint index;\n\n\t \n\tif (msr == MSR_MTRRcap) {\n\t\t \n\t\t*pdata = 0x500 | KVM_NR_VAR_MTRR;\n\t\treturn 0;\n\t}\n\n\tif (!msr_mtrr_valid(msr))\n\t\treturn 1;\n\n\tindex = fixed_msr_to_range_index(msr);\n\tif (index >= 0) {\n\t\t*pdata = *(u64 *)&vcpu->arch.mtrr_state.fixed_ranges[index];\n\t} else if (msr == MSR_MTRRdefType) {\n\t\t*pdata = vcpu->arch.mtrr_state.deftype;\n\t} else {\n\t\t \n\t\tif (is_mtrr_base_msr(msr))\n\t\t\t*pdata = var_mtrr_msr_to_range(vcpu, msr)->base;\n\t\telse\n\t\t\t*pdata = var_mtrr_msr_to_range(vcpu, msr)->mask;\n\n\t\t*pdata &= ~kvm_vcpu_reserved_gpa_bits_raw(vcpu);\n\t}\n\n\treturn 0;\n}\n\nvoid kvm_vcpu_mtrr_init(struct kvm_vcpu *vcpu)\n{\n\tINIT_LIST_HEAD(&vcpu->arch.mtrr_state.head);\n}\n\nstruct mtrr_iter {\n\t \n\tstruct kvm_mtrr *mtrr_state;\n\tu64 start;\n\tu64 end;\n\n\t \n\tint mem_type;\n\t \n\tbool mtrr_disabled;\n\t \n\tbool partial_map;\n\n\t \n\tunion {\n\t\t \n\t\tstruct {\n\t\t\tint index;\n\t\t\tint seg;\n\t\t};\n\n\t\t \n\t\tstruct {\n\t\t\tstruct kvm_mtrr_range *range;\n\t\t\t \n\t\t\tu64 start_max;\n\t\t};\n\t};\n\n\tbool fixed;\n};\n\nstatic bool mtrr_lookup_fixed_start(struct mtrr_iter *iter)\n{\n\tint seg, index;\n\n\tif (!fixed_mtrr_is_enabled(iter->mtrr_state))\n\t\treturn false;\n\n\tseg = fixed_mtrr_addr_to_seg(iter->start);\n\tif (seg < 0)\n\t\treturn false;\n\n\titer->fixed = true;\n\tindex = fixed_mtrr_addr_seg_to_range_index(iter->start, seg);\n\titer->index = index;\n\titer->seg = seg;\n\treturn true;\n}\n\nstatic bool match_var_range(struct mtrr_iter *iter,\n\t\t\t    struct kvm_mtrr_range *range)\n{\n\tu64 start, end;\n\n\tvar_mtrr_range(range, &start, &end);\n\tif (!(start >= iter->end || end <= iter->start)) {\n\t\titer->range = range;\n\n\t\t \n\t\titer->partial_map |= iter->start_max < start;\n\n\t\t \n\t\titer->start_max = max(iter->start_max, end);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void __mtrr_lookup_var_next(struct mtrr_iter *iter)\n{\n\tstruct kvm_mtrr *mtrr_state = iter->mtrr_state;\n\n\tlist_for_each_entry_continue(iter->range, &mtrr_state->head, node)\n\t\tif (match_var_range(iter, iter->range))\n\t\t\treturn;\n\n\titer->range = NULL;\n\titer->partial_map |= iter->start_max < iter->end;\n}\n\nstatic void mtrr_lookup_var_start(struct mtrr_iter *iter)\n{\n\tstruct kvm_mtrr *mtrr_state = iter->mtrr_state;\n\n\titer->fixed = false;\n\titer->start_max = iter->start;\n\titer->range = NULL;\n\titer->range = list_prepare_entry(iter->range, &mtrr_state->head, node);\n\n\t__mtrr_lookup_var_next(iter);\n}\n\nstatic void mtrr_lookup_fixed_next(struct mtrr_iter *iter)\n{\n\t \n\tif (fixed_mtrr_range_end_addr(iter->seg, iter->index) >= iter->end) {\n\t\titer->fixed = false;\n\t\titer->range = NULL;\n\t\treturn;\n\t}\n\n\titer->index++;\n\n\t \n\tif (iter->index >= ARRAY_SIZE(iter->mtrr_state->fixed_ranges))\n\t\treturn mtrr_lookup_var_start(iter);\n\n\t \n\tif (iter->index > fixed_mtrr_seg_end_range_index(iter->seg))\n\t\titer->seg++;\n}\n\nstatic void mtrr_lookup_var_next(struct mtrr_iter *iter)\n{\n\t__mtrr_lookup_var_next(iter);\n}\n\nstatic void mtrr_lookup_start(struct mtrr_iter *iter)\n{\n\tif (!mtrr_is_enabled(iter->mtrr_state)) {\n\t\titer->mtrr_disabled = true;\n\t\treturn;\n\t}\n\n\tif (!mtrr_lookup_fixed_start(iter))\n\t\tmtrr_lookup_var_start(iter);\n}\n\nstatic void mtrr_lookup_init(struct mtrr_iter *iter,\n\t\t\t     struct kvm_mtrr *mtrr_state, u64 start, u64 end)\n{\n\titer->mtrr_state = mtrr_state;\n\titer->start = start;\n\titer->end = end;\n\titer->mtrr_disabled = false;\n\titer->partial_map = false;\n\titer->fixed = false;\n\titer->range = NULL;\n\n\tmtrr_lookup_start(iter);\n}\n\nstatic bool mtrr_lookup_okay(struct mtrr_iter *iter)\n{\n\tif (iter->fixed) {\n\t\titer->mem_type = iter->mtrr_state->fixed_ranges[iter->index];\n\t\treturn true;\n\t}\n\n\tif (iter->range) {\n\t\titer->mem_type = iter->range->base & 0xff;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void mtrr_lookup_next(struct mtrr_iter *iter)\n{\n\tif (iter->fixed)\n\t\tmtrr_lookup_fixed_next(iter);\n\telse\n\t\tmtrr_lookup_var_next(iter);\n}\n\n#define mtrr_for_each_mem_type(_iter_, _mtrr_, _gpa_start_, _gpa_end_) \\\n\tfor (mtrr_lookup_init(_iter_, _mtrr_, _gpa_start_, _gpa_end_); \\\n\t     mtrr_lookup_okay(_iter_); mtrr_lookup_next(_iter_))\n\nu8 kvm_mtrr_get_guest_memory_type(struct kvm_vcpu *vcpu, gfn_t gfn)\n{\n\tstruct kvm_mtrr *mtrr_state = &vcpu->arch.mtrr_state;\n\tstruct mtrr_iter iter;\n\tu64 start, end;\n\tint type = -1;\n\tconst int wt_wb_mask = (1 << MTRR_TYPE_WRBACK)\n\t\t\t       | (1 << MTRR_TYPE_WRTHROUGH);\n\n\tstart = gfn_to_gpa(gfn);\n\tend = start + PAGE_SIZE;\n\n\tmtrr_for_each_mem_type(&iter, mtrr_state, start, end) {\n\t\tint curr_type = iter.mem_type;\n\n\t\t \n\n\t\tif (type == -1) {\n\t\t\ttype = curr_type;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (type == curr_type)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (curr_type == MTRR_TYPE_UNCACHABLE)\n\t\t\treturn MTRR_TYPE_UNCACHABLE;\n\n\t\t \n\t\tif (((1 << type) & wt_wb_mask) &&\n\t\t      ((1 << curr_type) & wt_wb_mask)) {\n\t\t\ttype = MTRR_TYPE_WRTHROUGH;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\n\t\t \n\t\treturn MTRR_TYPE_WRBACK;\n\t}\n\n\tif (iter.mtrr_disabled)\n\t\treturn mtrr_disabled_type(vcpu);\n\n\t \n\tif (type == -1)\n\t\treturn mtrr_default_type(mtrr_state);\n\n\t \n\tWARN_ON(iter.partial_map);\n\n\treturn type;\n}\nEXPORT_SYMBOL_GPL(kvm_mtrr_get_guest_memory_type);\n\nbool kvm_mtrr_check_gfn_range_consistency(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t\t\t  int page_num)\n{\n\tstruct kvm_mtrr *mtrr_state = &vcpu->arch.mtrr_state;\n\tstruct mtrr_iter iter;\n\tu64 start, end;\n\tint type = -1;\n\n\tstart = gfn_to_gpa(gfn);\n\tend = gfn_to_gpa(gfn + page_num);\n\tmtrr_for_each_mem_type(&iter, mtrr_state, start, end) {\n\t\tif (type == -1) {\n\t\t\ttype = iter.mem_type;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (type != iter.mem_type)\n\t\t\treturn false;\n\t}\n\n\tif (iter.mtrr_disabled)\n\t\treturn true;\n\n\tif (!iter.partial_map)\n\t\treturn true;\n\n\tif (type == -1)\n\t\treturn true;\n\n\treturn type == mtrr_default_type(mtrr_state);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}