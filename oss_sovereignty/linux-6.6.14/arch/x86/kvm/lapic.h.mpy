{
  "module_name": "lapic.h",
  "hash_id": "fbf0d8df45b7397b0727ab53a0785a80ba7a61f323a2fcb61a44a605b31a0a55",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/lapic.h",
  "human_readable_source": " \n#ifndef __KVM_X86_LAPIC_H\n#define __KVM_X86_LAPIC_H\n\n#include <kvm/iodev.h>\n\n#include <linux/kvm_host.h>\n\n#include \"hyperv.h\"\n#include \"smm.h\"\n\n#define KVM_APIC_INIT\t\t0\n#define KVM_APIC_SIPI\t\t1\n\n#define APIC_SHORT_MASK\t\t\t0xc0000\n#define APIC_DEST_NOSHORT\t\t0x0\n#define APIC_DEST_MASK\t\t\t0x800\n\n#define APIC_BUS_CYCLE_NS       1\n#define APIC_BUS_FREQUENCY      (1000000000ULL / APIC_BUS_CYCLE_NS)\n\n#define APIC_BROADCAST\t\t\t0xFF\n#define X2APIC_BROADCAST\t\t0xFFFFFFFFul\n\nenum lapic_mode {\n\tLAPIC_MODE_DISABLED = 0,\n\tLAPIC_MODE_INVALID = X2APIC_ENABLE,\n\tLAPIC_MODE_XAPIC = MSR_IA32_APICBASE_ENABLE,\n\tLAPIC_MODE_X2APIC = MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE,\n};\n\nenum lapic_lvt_entry {\n\tLVT_TIMER,\n\tLVT_THERMAL_MONITOR,\n\tLVT_PERFORMANCE_COUNTER,\n\tLVT_LINT0,\n\tLVT_LINT1,\n\tLVT_ERROR,\n\tLVT_CMCI,\n\n\tKVM_APIC_MAX_NR_LVT_ENTRIES,\n};\n\n#define APIC_LVTx(x) ((x) == LVT_CMCI ? APIC_LVTCMCI : APIC_LVTT + 0x10 * (x))\n\nstruct kvm_timer {\n\tstruct hrtimer timer;\n\ts64 period; \t\t\t\t \n\tktime_t target_expiration;\n\tu32 timer_mode;\n\tu32 timer_mode_mask;\n\tu64 tscdeadline;\n\tu64 expired_tscdeadline;\n\tu32 timer_advance_ns;\n\tatomic_t pending;\t\t\t \n\tbool hv_timer_in_use;\n};\n\nstruct kvm_lapic {\n\tunsigned long base_address;\n\tstruct kvm_io_device dev;\n\tstruct kvm_timer lapic_timer;\n\tu32 divide_count;\n\tstruct kvm_vcpu *vcpu;\n\tbool apicv_active;\n\tbool sw_enabled;\n\tbool irr_pending;\n\tbool lvt0_in_nmi_mode;\n\t \n\ts16 isr_count;\n\t \n\tint highest_isr_cache;\n\t \n\tvoid *regs;\n\tgpa_t vapic_addr;\n\tstruct gfn_to_hva_cache vapic_cache;\n\tunsigned long pending_events;\n\tunsigned int sipi_vector;\n\tint nr_lvt_entries;\n};\n\nstruct dest_map;\n\nint kvm_create_lapic(struct kvm_vcpu *vcpu, int timer_advance_ns);\nvoid kvm_free_lapic(struct kvm_vcpu *vcpu);\n\nint kvm_apic_has_interrupt(struct kvm_vcpu *vcpu);\nint kvm_apic_accept_pic_intr(struct kvm_vcpu *vcpu);\nint kvm_get_apic_interrupt(struct kvm_vcpu *vcpu);\nint kvm_apic_accept_events(struct kvm_vcpu *vcpu);\nvoid kvm_lapic_reset(struct kvm_vcpu *vcpu, bool init_event);\nu64 kvm_lapic_get_cr8(struct kvm_vcpu *vcpu);\nvoid kvm_lapic_set_tpr(struct kvm_vcpu *vcpu, unsigned long cr8);\nvoid kvm_lapic_set_eoi(struct kvm_vcpu *vcpu);\nvoid kvm_lapic_set_base(struct kvm_vcpu *vcpu, u64 value);\nu64 kvm_lapic_get_base(struct kvm_vcpu *vcpu);\nvoid kvm_recalculate_apic_map(struct kvm *kvm);\nvoid kvm_apic_set_version(struct kvm_vcpu *vcpu);\nvoid kvm_apic_after_set_mcg_cap(struct kvm_vcpu *vcpu);\nbool kvm_apic_match_dest(struct kvm_vcpu *vcpu, struct kvm_lapic *source,\n\t\t\t   int shorthand, unsigned int dest, int dest_mode);\nint kvm_apic_compare_prio(struct kvm_vcpu *vcpu1, struct kvm_vcpu *vcpu2);\nvoid kvm_apic_clear_irr(struct kvm_vcpu *vcpu, int vec);\nbool __kvm_apic_update_irr(u32 *pir, void *regs, int *max_irr);\nbool kvm_apic_update_irr(struct kvm_vcpu *vcpu, u32 *pir, int *max_irr);\nvoid kvm_apic_update_ppr(struct kvm_vcpu *vcpu);\nint kvm_apic_set_irq(struct kvm_vcpu *vcpu, struct kvm_lapic_irq *irq,\n\t\t     struct dest_map *dest_map);\nint kvm_apic_local_deliver(struct kvm_lapic *apic, int lvt_type);\nvoid kvm_apic_update_apicv(struct kvm_vcpu *vcpu);\nint kvm_alloc_apic_access_page(struct kvm *kvm);\nvoid kvm_inhibit_apic_access_page(struct kvm_vcpu *vcpu);\n\nbool kvm_irq_delivery_to_apic_fast(struct kvm *kvm, struct kvm_lapic *src,\n\t\tstruct kvm_lapic_irq *irq, int *r, struct dest_map *dest_map);\nvoid kvm_apic_send_ipi(struct kvm_lapic *apic, u32 icr_low, u32 icr_high);\n\nu64 kvm_get_apic_base(struct kvm_vcpu *vcpu);\nint kvm_set_apic_base(struct kvm_vcpu *vcpu, struct msr_data *msr_info);\nint kvm_apic_get_state(struct kvm_vcpu *vcpu, struct kvm_lapic_state *s);\nint kvm_apic_set_state(struct kvm_vcpu *vcpu, struct kvm_lapic_state *s);\nenum lapic_mode kvm_get_apic_mode(struct kvm_vcpu *vcpu);\nint kvm_lapic_find_highest_irr(struct kvm_vcpu *vcpu);\n\nu64 kvm_get_lapic_tscdeadline_msr(struct kvm_vcpu *vcpu);\nvoid kvm_set_lapic_tscdeadline_msr(struct kvm_vcpu *vcpu, u64 data);\n\nvoid kvm_apic_write_nodecode(struct kvm_vcpu *vcpu, u32 offset);\nvoid kvm_apic_set_eoi_accelerated(struct kvm_vcpu *vcpu, int vector);\n\nint kvm_lapic_set_vapic_addr(struct kvm_vcpu *vcpu, gpa_t vapic_addr);\nvoid kvm_lapic_sync_from_vapic(struct kvm_vcpu *vcpu);\nvoid kvm_lapic_sync_to_vapic(struct kvm_vcpu *vcpu);\n\nint kvm_x2apic_icr_write(struct kvm_lapic *apic, u64 data);\nint kvm_x2apic_msr_write(struct kvm_vcpu *vcpu, u32 msr, u64 data);\nint kvm_x2apic_msr_read(struct kvm_vcpu *vcpu, u32 msr, u64 *data);\n\nint kvm_hv_vapic_msr_write(struct kvm_vcpu *vcpu, u32 msr, u64 data);\nint kvm_hv_vapic_msr_read(struct kvm_vcpu *vcpu, u32 msr, u64 *data);\n\nint kvm_lapic_set_pv_eoi(struct kvm_vcpu *vcpu, u64 data, unsigned long len);\nvoid kvm_lapic_exit(void);\n\nu64 kvm_lapic_readable_reg_mask(struct kvm_lapic *apic);\n\n#define VEC_POS(v) ((v) & (32 - 1))\n#define REG_POS(v) (((v) >> 5) << 4)\n\nstatic inline void kvm_lapic_clear_vector(int vec, void *bitmap)\n{\n\tclear_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));\n}\n\nstatic inline void kvm_lapic_set_vector(int vec, void *bitmap)\n{\n\tset_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));\n}\n\nstatic inline void kvm_lapic_set_irr(int vec, struct kvm_lapic *apic)\n{\n\tkvm_lapic_set_vector(vec, apic->regs + APIC_IRR);\n\t \n\tapic->irr_pending = true;\n}\n\nstatic inline u32 __kvm_lapic_get_reg(char *regs, int reg_off)\n{\n\treturn *((u32 *) (regs + reg_off));\n}\n\nstatic inline u32 kvm_lapic_get_reg(struct kvm_lapic *apic, int reg_off)\n{\n\treturn __kvm_lapic_get_reg(apic->regs, reg_off);\n}\n\nDECLARE_STATIC_KEY_FALSE(kvm_has_noapic_vcpu);\n\nstatic inline bool lapic_in_kernel(struct kvm_vcpu *vcpu)\n{\n\tif (static_branch_unlikely(&kvm_has_noapic_vcpu))\n\t\treturn vcpu->arch.apic;\n\treturn true;\n}\n\nextern struct static_key_false_deferred apic_hw_disabled;\n\nstatic inline bool kvm_apic_hw_enabled(struct kvm_lapic *apic)\n{\n\tif (static_branch_unlikely(&apic_hw_disabled.key))\n\t\treturn apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;\n\treturn true;\n}\n\nextern struct static_key_false_deferred apic_sw_disabled;\n\nstatic inline bool kvm_apic_sw_enabled(struct kvm_lapic *apic)\n{\n\tif (static_branch_unlikely(&apic_sw_disabled.key))\n\t\treturn apic->sw_enabled;\n\treturn true;\n}\n\nstatic inline bool kvm_apic_present(struct kvm_vcpu *vcpu)\n{\n\treturn lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);\n}\n\nstatic inline int kvm_lapic_enabled(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);\n}\n\nstatic inline int apic_x2apic_mode(struct kvm_lapic *apic)\n{\n\treturn apic->vcpu->arch.apic_base & X2APIC_ENABLE;\n}\n\nstatic inline bool kvm_vcpu_apicv_active(struct kvm_vcpu *vcpu)\n{\n\treturn lapic_in_kernel(vcpu) && vcpu->arch.apic->apicv_active;\n}\n\nstatic inline bool kvm_apic_has_pending_init_or_sipi(struct kvm_vcpu *vcpu)\n{\n\treturn lapic_in_kernel(vcpu) && vcpu->arch.apic->pending_events;\n}\n\nstatic inline bool kvm_apic_init_sipi_allowed(struct kvm_vcpu *vcpu)\n{\n\treturn !is_smm(vcpu) &&\n\t       !static_call(kvm_x86_apic_init_signal_blocked)(vcpu);\n}\n\nstatic inline bool kvm_lowest_prio_delivery(struct kvm_lapic_irq *irq)\n{\n\treturn (irq->delivery_mode == APIC_DM_LOWEST ||\n\t\t\tirq->msi_redir_hint);\n}\n\nstatic inline int kvm_lapic_latched_init(struct kvm_vcpu *vcpu)\n{\n\treturn lapic_in_kernel(vcpu) && test_bit(KVM_APIC_INIT, &vcpu->arch.apic->pending_events);\n}\n\nbool kvm_apic_pending_eoi(struct kvm_vcpu *vcpu, int vector);\n\nvoid kvm_wait_lapic_expire(struct kvm_vcpu *vcpu);\n\nvoid kvm_bitmap_or_dest_vcpus(struct kvm *kvm, struct kvm_lapic_irq *irq,\n\t\t\t      unsigned long *vcpu_bitmap);\n\nbool kvm_intr_is_single_vcpu_fast(struct kvm *kvm, struct kvm_lapic_irq *irq,\n\t\t\tstruct kvm_vcpu **dest_vcpu);\nint kvm_vector_to_index(u32 vector, u32 dest_vcpus,\n\t\t\tconst unsigned long *bitmap, u32 bitmap_size);\nvoid kvm_lapic_switch_to_sw_timer(struct kvm_vcpu *vcpu);\nvoid kvm_lapic_switch_to_hv_timer(struct kvm_vcpu *vcpu);\nvoid kvm_lapic_expired_hv_timer(struct kvm_vcpu *vcpu);\nbool kvm_lapic_hv_timer_in_use(struct kvm_vcpu *vcpu);\nvoid kvm_lapic_restart_hv_timer(struct kvm_vcpu *vcpu);\nbool kvm_can_use_hv_timer(struct kvm_vcpu *vcpu);\n\nstatic inline enum lapic_mode kvm_apic_mode(u64 apic_base)\n{\n\treturn apic_base & (MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE);\n}\n\nstatic inline u8 kvm_xapic_id(struct kvm_lapic *apic)\n{\n\treturn kvm_lapic_get_reg(apic, APIC_ID) >> 24;\n}\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}