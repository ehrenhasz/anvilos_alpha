{
  "module_name": "xen.h",
  "hash_id": "5b6e1f9b93e8bccc01e155b445f5078606a5761cf9c5e75480ca58932215d2b7",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/xen.h",
  "human_readable_source": "\n \n\n#ifndef __ARCH_X86_KVM_XEN_H__\n#define __ARCH_X86_KVM_XEN_H__\n\n#include <asm/xen/hypervisor.h>\n\n#ifdef CONFIG_KVM_XEN\n#include <linux/jump_label_ratelimit.h>\n\nextern struct static_key_false_deferred kvm_xen_enabled;\n\nint __kvm_xen_has_interrupt(struct kvm_vcpu *vcpu);\nvoid kvm_xen_inject_pending_events(struct kvm_vcpu *vcpu);\nint kvm_xen_vcpu_set_attr(struct kvm_vcpu *vcpu, struct kvm_xen_vcpu_attr *data);\nint kvm_xen_vcpu_get_attr(struct kvm_vcpu *vcpu, struct kvm_xen_vcpu_attr *data);\nint kvm_xen_hvm_set_attr(struct kvm *kvm, struct kvm_xen_hvm_attr *data);\nint kvm_xen_hvm_get_attr(struct kvm *kvm, struct kvm_xen_hvm_attr *data);\nint kvm_xen_hvm_evtchn_send(struct kvm *kvm, struct kvm_irq_routing_xen_evtchn *evt);\nint kvm_xen_write_hypercall_page(struct kvm_vcpu *vcpu, u64 data);\nint kvm_xen_hvm_config(struct kvm *kvm, struct kvm_xen_hvm_config *xhc);\nvoid kvm_xen_init_vm(struct kvm *kvm);\nvoid kvm_xen_destroy_vm(struct kvm *kvm);\nvoid kvm_xen_init_vcpu(struct kvm_vcpu *vcpu);\nvoid kvm_xen_destroy_vcpu(struct kvm_vcpu *vcpu);\nint kvm_xen_set_evtchn_fast(struct kvm_xen_evtchn *xe,\n\t\t\t    struct kvm *kvm);\nint kvm_xen_setup_evtchn(struct kvm *kvm,\n\t\t\t struct kvm_kernel_irq_routing_entry *e,\n\t\t\t const struct kvm_irq_routing_entry *ue);\nvoid kvm_xen_update_tsc_info(struct kvm_vcpu *vcpu);\n\nstatic inline bool kvm_xen_msr_enabled(struct kvm *kvm)\n{\n\treturn static_branch_unlikely(&kvm_xen_enabled.key) &&\n\t\tkvm->arch.xen_hvm_config.msr;\n}\n\nstatic inline bool kvm_xen_hypercall_enabled(struct kvm *kvm)\n{\n\treturn static_branch_unlikely(&kvm_xen_enabled.key) &&\n\t\t(kvm->arch.xen_hvm_config.flags &\n\t\t KVM_XEN_HVM_CONFIG_INTERCEPT_HCALL);\n}\n\nstatic inline int kvm_xen_has_interrupt(struct kvm_vcpu *vcpu)\n{\n\tif (static_branch_unlikely(&kvm_xen_enabled.key) &&\n\t    vcpu->arch.xen.vcpu_info_cache.active &&\n\t    vcpu->kvm->arch.xen.upcall_vector)\n\t\treturn __kvm_xen_has_interrupt(vcpu);\n\n\treturn 0;\n}\n\nstatic inline bool kvm_xen_has_pending_events(struct kvm_vcpu *vcpu)\n{\n\treturn static_branch_unlikely(&kvm_xen_enabled.key) &&\n\t\tvcpu->arch.xen.evtchn_pending_sel;\n}\n\nstatic inline bool kvm_xen_timer_enabled(struct kvm_vcpu *vcpu)\n{\n\treturn !!vcpu->arch.xen.timer_virq;\n}\n\nstatic inline int kvm_xen_has_pending_timer(struct kvm_vcpu *vcpu)\n{\n\tif (kvm_xen_hypercall_enabled(vcpu->kvm) && kvm_xen_timer_enabled(vcpu))\n\t\treturn atomic_read(&vcpu->arch.xen.timer_pending);\n\n\treturn 0;\n}\n\nvoid kvm_xen_inject_timer_irqs(struct kvm_vcpu *vcpu);\n#else\nstatic inline int kvm_xen_write_hypercall_page(struct kvm_vcpu *vcpu, u64 data)\n{\n\treturn 1;\n}\n\nstatic inline void kvm_xen_init_vm(struct kvm *kvm)\n{\n}\n\nstatic inline void kvm_xen_destroy_vm(struct kvm *kvm)\n{\n}\n\nstatic inline void kvm_xen_init_vcpu(struct kvm_vcpu *vcpu)\n{\n}\n\nstatic inline void kvm_xen_destroy_vcpu(struct kvm_vcpu *vcpu)\n{\n}\n\nstatic inline bool kvm_xen_msr_enabled(struct kvm *kvm)\n{\n\treturn false;\n}\n\nstatic inline bool kvm_xen_hypercall_enabled(struct kvm *kvm)\n{\n\treturn false;\n}\n\nstatic inline int kvm_xen_has_interrupt(struct kvm_vcpu *vcpu)\n{\n\treturn 0;\n}\n\nstatic inline void kvm_xen_inject_pending_events(struct kvm_vcpu *vcpu)\n{\n}\n\nstatic inline bool kvm_xen_has_pending_events(struct kvm_vcpu *vcpu)\n{\n\treturn false;\n}\n\nstatic inline int kvm_xen_has_pending_timer(struct kvm_vcpu *vcpu)\n{\n\treturn 0;\n}\n\nstatic inline void kvm_xen_inject_timer_irqs(struct kvm_vcpu *vcpu)\n{\n}\n\nstatic inline bool kvm_xen_timer_enabled(struct kvm_vcpu *vcpu)\n{\n\treturn false;\n}\n\nstatic inline void kvm_xen_update_tsc_info(struct kvm_vcpu *vcpu)\n{\n}\n#endif\n\nint kvm_xen_hypercall(struct kvm_vcpu *vcpu);\n\n#include <asm/pvclock-abi.h>\n#include <asm/xen/interface.h>\n#include <xen/interface/vcpu.h>\n\nvoid kvm_xen_update_runstate(struct kvm_vcpu *vcpu, int state);\n\nstatic inline void kvm_xen_runstate_set_running(struct kvm_vcpu *vcpu)\n{\n\tkvm_xen_update_runstate(vcpu, RUNSTATE_running);\n}\n\nstatic inline void kvm_xen_runstate_set_preempted(struct kvm_vcpu *vcpu)\n{\n\t \n\tif (WARN_ON_ONCE(!vcpu->preempted))\n\t\treturn;\n\n\tkvm_xen_update_runstate(vcpu, RUNSTATE_runnable);\n}\n\n \nstruct compat_arch_vcpu_info {\n\tunsigned int cr2;\n\tunsigned int pad[5];\n};\n\nstruct compat_vcpu_info {\n\tuint8_t evtchn_upcall_pending;\n\tuint8_t evtchn_upcall_mask;\n\tuint16_t pad;\n\tuint32_t evtchn_pending_sel;\n\tstruct compat_arch_vcpu_info arch;\n\tstruct pvclock_vcpu_time_info time;\n};  \n\nstruct compat_arch_shared_info {\n\tunsigned int max_pfn;\n\tunsigned int pfn_to_mfn_frame_list_list;\n\tunsigned int nmi_reason;\n\tunsigned int p2m_cr3;\n\tunsigned int p2m_vaddr;\n\tunsigned int p2m_generation;\n\tuint32_t wc_sec_hi;\n};\n\nstruct compat_shared_info {\n\tstruct compat_vcpu_info vcpu_info[MAX_VIRT_CPUS];\n\tuint32_t evtchn_pending[32];\n\tuint32_t evtchn_mask[32];\n\tstruct pvclock_wall_clock wc;\n\tstruct compat_arch_shared_info arch;\n};\n\n#define COMPAT_EVTCHN_2L_NR_CHANNELS (8 *\t\t\t\t\\\n\t\t\t\t      sizeof_field(struct compat_shared_info, \\\n\t\t\t\t\t\t   evtchn_pending))\nstruct compat_vcpu_runstate_info {\n    int state;\n    uint64_t state_entry_time;\n    uint64_t time[4];\n} __attribute__((packed));\n\nstruct compat_sched_poll {\n\t \n\tuint32_t ports;\n\tunsigned int nr_ports;\n\tuint64_t timeout;\n};\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}