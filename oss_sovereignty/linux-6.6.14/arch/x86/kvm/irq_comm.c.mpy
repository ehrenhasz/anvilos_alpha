{
  "module_name": "irq_comm.c",
  "hash_id": "61075b0f450a7bf405b2087b8eee89ae54e9c497f9b4a6be9cf9fbb35e0dbf4b",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/irq_comm.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kvm_host.h>\n#include <linux/slab.h>\n#include <linux/export.h>\n#include <linux/rculist.h>\n\n#include <trace/events/kvm.h>\n\n#include \"irq.h\"\n\n#include \"ioapic.h\"\n\n#include \"lapic.h\"\n\n#include \"hyperv.h\"\n#include \"x86.h\"\n#include \"xen.h\"\n\nstatic int kvm_set_pic_irq(struct kvm_kernel_irq_routing_entry *e,\n\t\t\t   struct kvm *kvm, int irq_source_id, int level,\n\t\t\t   bool line_status)\n{\n\tstruct kvm_pic *pic = kvm->arch.vpic;\n\treturn kvm_pic_set_irq(pic, e->irqchip.pin, irq_source_id, level);\n}\n\nstatic int kvm_set_ioapic_irq(struct kvm_kernel_irq_routing_entry *e,\n\t\t\t      struct kvm *kvm, int irq_source_id, int level,\n\t\t\t      bool line_status)\n{\n\tstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\n\treturn kvm_ioapic_set_irq(ioapic, e->irqchip.pin, irq_source_id, level,\n\t\t\t\tline_status);\n}\n\nint kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,\n\t\tstruct kvm_lapic_irq *irq, struct dest_map *dest_map)\n{\n\tint r = -1;\n\tstruct kvm_vcpu *vcpu, *lowest = NULL;\n\tunsigned long i, dest_vcpu_bitmap[BITS_TO_LONGS(KVM_MAX_VCPUS)];\n\tunsigned int dest_vcpus = 0;\n\n\tif (kvm_irq_delivery_to_apic_fast(kvm, src, irq, &r, dest_map))\n\t\treturn r;\n\n\tif (irq->dest_mode == APIC_DEST_PHYSICAL &&\n\t    irq->dest_id == 0xff && kvm_lowest_prio_delivery(irq)) {\n\t\tpr_info(\"apic: phys broadcast and lowest prio\\n\");\n\t\tirq->delivery_mode = APIC_DM_FIXED;\n\t}\n\n\tmemset(dest_vcpu_bitmap, 0, sizeof(dest_vcpu_bitmap));\n\n\tkvm_for_each_vcpu(i, vcpu, kvm) {\n\t\tif (!kvm_apic_present(vcpu))\n\t\t\tcontinue;\n\n\t\tif (!kvm_apic_match_dest(vcpu, src, irq->shorthand,\n\t\t\t\t\tirq->dest_id, irq->dest_mode))\n\t\t\tcontinue;\n\n\t\tif (!kvm_lowest_prio_delivery(irq)) {\n\t\t\tif (r < 0)\n\t\t\t\tr = 0;\n\t\t\tr += kvm_apic_set_irq(vcpu, irq, dest_map);\n\t\t} else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {\n\t\t\tif (!kvm_vector_hashing_enabled()) {\n\t\t\t\tif (!lowest)\n\t\t\t\t\tlowest = vcpu;\n\t\t\t\telse if (kvm_apic_compare_prio(vcpu, lowest) < 0)\n\t\t\t\t\tlowest = vcpu;\n\t\t\t} else {\n\t\t\t\t__set_bit(i, dest_vcpu_bitmap);\n\t\t\t\tdest_vcpus++;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dest_vcpus != 0) {\n\t\tint idx = kvm_vector_to_index(irq->vector, dest_vcpus,\n\t\t\t\t\tdest_vcpu_bitmap, KVM_MAX_VCPUS);\n\n\t\tlowest = kvm_get_vcpu(kvm, idx);\n\t}\n\n\tif (lowest)\n\t\tr = kvm_apic_set_irq(lowest, irq, dest_map);\n\n\treturn r;\n}\n\nvoid kvm_set_msi_irq(struct kvm *kvm, struct kvm_kernel_irq_routing_entry *e,\n\t\t     struct kvm_lapic_irq *irq)\n{\n\tstruct msi_msg msg = { .address_lo = e->msi.address_lo,\n\t\t\t       .address_hi = e->msi.address_hi,\n\t\t\t       .data = e->msi.data };\n\n\ttrace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?\n\t\t\t      (u64)msg.address_hi << 32 : 0), msg.data);\n\n\tirq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);\n\tirq->vector = msg.arch_data.vector;\n\tirq->dest_mode = kvm_lapic_irq_dest_mode(msg.arch_addr_lo.dest_mode_logical);\n\tirq->trig_mode = msg.arch_data.is_level;\n\tirq->delivery_mode = msg.arch_data.delivery_mode << 8;\n\tirq->msi_redir_hint = msg.arch_addr_lo.redirect_hint;\n\tirq->level = 1;\n\tirq->shorthand = APIC_DEST_NOSHORT;\n}\nEXPORT_SYMBOL_GPL(kvm_set_msi_irq);\n\nstatic inline bool kvm_msi_route_invalid(struct kvm *kvm,\n\t\tstruct kvm_kernel_irq_routing_entry *e)\n{\n\treturn kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);\n}\n\nint kvm_set_msi(struct kvm_kernel_irq_routing_entry *e,\n\t\tstruct kvm *kvm, int irq_source_id, int level, bool line_status)\n{\n\tstruct kvm_lapic_irq irq;\n\n\tif (kvm_msi_route_invalid(kvm, e))\n\t\treturn -EINVAL;\n\n\tif (!level)\n\t\treturn -1;\n\n\tkvm_set_msi_irq(kvm, e, &irq);\n\n\treturn kvm_irq_delivery_to_apic(kvm, NULL, &irq, NULL);\n}\n\n\nstatic int kvm_hv_set_sint(struct kvm_kernel_irq_routing_entry *e,\n\t\t    struct kvm *kvm, int irq_source_id, int level,\n\t\t    bool line_status)\n{\n\tif (!level)\n\t\treturn -1;\n\n\treturn kvm_hv_synic_set_irq(kvm, e->hv_sint.vcpu, e->hv_sint.sint);\n}\n\nint kvm_arch_set_irq_inatomic(struct kvm_kernel_irq_routing_entry *e,\n\t\t\t      struct kvm *kvm, int irq_source_id, int level,\n\t\t\t      bool line_status)\n{\n\tstruct kvm_lapic_irq irq;\n\tint r;\n\n\tswitch (e->type) {\n\tcase KVM_IRQ_ROUTING_HV_SINT:\n\t\treturn kvm_hv_set_sint(e, kvm, irq_source_id, level,\n\t\t\t\t       line_status);\n\n\tcase KVM_IRQ_ROUTING_MSI:\n\t\tif (kvm_msi_route_invalid(kvm, e))\n\t\t\treturn -EINVAL;\n\n\t\tkvm_set_msi_irq(kvm, e, &irq);\n\n\t\tif (kvm_irq_delivery_to_apic_fast(kvm, NULL, &irq, &r, NULL))\n\t\t\treturn r;\n\t\tbreak;\n\n#ifdef CONFIG_KVM_XEN\n\tcase KVM_IRQ_ROUTING_XEN_EVTCHN:\n\t\tif (!level)\n\t\t\treturn -1;\n\n\t\treturn kvm_xen_set_evtchn_fast(&e->xen_evtchn, kvm);\n#endif\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn -EWOULDBLOCK;\n}\n\nint kvm_request_irq_source_id(struct kvm *kvm)\n{\n\tunsigned long *bitmap = &kvm->arch.irq_sources_bitmap;\n\tint irq_source_id;\n\n\tmutex_lock(&kvm->irq_lock);\n\tirq_source_id = find_first_zero_bit(bitmap, BITS_PER_LONG);\n\n\tif (irq_source_id >= BITS_PER_LONG) {\n\t\tpr_warn(\"exhausted allocatable IRQ sources!\\n\");\n\t\tirq_source_id = -EFAULT;\n\t\tgoto unlock;\n\t}\n\n\tASSERT(irq_source_id != KVM_USERSPACE_IRQ_SOURCE_ID);\n\tASSERT(irq_source_id != KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID);\n\tset_bit(irq_source_id, bitmap);\nunlock:\n\tmutex_unlock(&kvm->irq_lock);\n\n\treturn irq_source_id;\n}\n\nvoid kvm_free_irq_source_id(struct kvm *kvm, int irq_source_id)\n{\n\tASSERT(irq_source_id != KVM_USERSPACE_IRQ_SOURCE_ID);\n\tASSERT(irq_source_id != KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID);\n\n\tmutex_lock(&kvm->irq_lock);\n\tif (irq_source_id < 0 ||\n\t    irq_source_id >= BITS_PER_LONG) {\n\t\tpr_err(\"IRQ source ID out of range!\\n\");\n\t\tgoto unlock;\n\t}\n\tclear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);\n\tif (!irqchip_kernel(kvm))\n\t\tgoto unlock;\n\n\tkvm_ioapic_clear_all(kvm->arch.vioapic, irq_source_id);\n\tkvm_pic_clear_all(kvm->arch.vpic, irq_source_id);\nunlock:\n\tmutex_unlock(&kvm->irq_lock);\n}\n\nvoid kvm_register_irq_mask_notifier(struct kvm *kvm, int irq,\n\t\t\t\t    struct kvm_irq_mask_notifier *kimn)\n{\n\tmutex_lock(&kvm->irq_lock);\n\tkimn->irq = irq;\n\thlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);\n\tmutex_unlock(&kvm->irq_lock);\n}\n\nvoid kvm_unregister_irq_mask_notifier(struct kvm *kvm, int irq,\n\t\t\t\t      struct kvm_irq_mask_notifier *kimn)\n{\n\tmutex_lock(&kvm->irq_lock);\n\thlist_del_rcu(&kimn->link);\n\tmutex_unlock(&kvm->irq_lock);\n\tsynchronize_srcu(&kvm->irq_srcu);\n}\n\nvoid kvm_fire_mask_notifiers(struct kvm *kvm, unsigned irqchip, unsigned pin,\n\t\t\t     bool mask)\n{\n\tstruct kvm_irq_mask_notifier *kimn;\n\tint idx, gsi;\n\n\tidx = srcu_read_lock(&kvm->irq_srcu);\n\tgsi = kvm_irq_map_chip_pin(kvm, irqchip, pin);\n\tif (gsi != -1)\n\t\thlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)\n\t\t\tif (kimn->irq == gsi)\n\t\t\t\tkimn->func(kimn, mask);\n\tsrcu_read_unlock(&kvm->irq_srcu, idx);\n}\n\nbool kvm_arch_can_set_irq_routing(struct kvm *kvm)\n{\n\treturn irqchip_in_kernel(kvm);\n}\n\nint kvm_set_routing_entry(struct kvm *kvm,\n\t\t\t  struct kvm_kernel_irq_routing_entry *e,\n\t\t\t  const struct kvm_irq_routing_entry *ue)\n{\n\t \n\tswitch (ue->type) {\n\tcase KVM_IRQ_ROUTING_IRQCHIP:\n\t\tif (irqchip_split(kvm))\n\t\t\treturn -EINVAL;\n\t\te->irqchip.pin = ue->u.irqchip.pin;\n\t\tswitch (ue->u.irqchip.irqchip) {\n\t\tcase KVM_IRQCHIP_PIC_SLAVE:\n\t\t\te->irqchip.pin += PIC_NUM_PINS / 2;\n\t\t\tfallthrough;\n\t\tcase KVM_IRQCHIP_PIC_MASTER:\n\t\t\tif (ue->u.irqchip.pin >= PIC_NUM_PINS / 2)\n\t\t\t\treturn -EINVAL;\n\t\t\te->set = kvm_set_pic_irq;\n\t\t\tbreak;\n\t\tcase KVM_IRQCHIP_IOAPIC:\n\t\t\tif (ue->u.irqchip.pin >= KVM_IOAPIC_NUM_PINS)\n\t\t\t\treturn -EINVAL;\n\t\t\te->set = kvm_set_ioapic_irq;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t\te->irqchip.irqchip = ue->u.irqchip.irqchip;\n\t\tbreak;\n\tcase KVM_IRQ_ROUTING_MSI:\n\t\te->set = kvm_set_msi;\n\t\te->msi.address_lo = ue->u.msi.address_lo;\n\t\te->msi.address_hi = ue->u.msi.address_hi;\n\t\te->msi.data = ue->u.msi.data;\n\n\t\tif (kvm_msi_route_invalid(kvm, e))\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tcase KVM_IRQ_ROUTING_HV_SINT:\n\t\te->set = kvm_hv_set_sint;\n\t\te->hv_sint.vcpu = ue->u.hv_sint.vcpu;\n\t\te->hv_sint.sint = ue->u.hv_sint.sint;\n\t\tbreak;\n#ifdef CONFIG_KVM_XEN\n\tcase KVM_IRQ_ROUTING_XEN_EVTCHN:\n\t\treturn kvm_xen_setup_evtchn(kvm, e, ue);\n#endif\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nbool kvm_intr_is_single_vcpu(struct kvm *kvm, struct kvm_lapic_irq *irq,\n\t\t\t     struct kvm_vcpu **dest_vcpu)\n{\n\tint r = 0;\n\tunsigned long i;\n\tstruct kvm_vcpu *vcpu;\n\n\tif (kvm_intr_is_single_vcpu_fast(kvm, irq, dest_vcpu))\n\t\treturn true;\n\n\tkvm_for_each_vcpu(i, vcpu, kvm) {\n\t\tif (!kvm_apic_present(vcpu))\n\t\t\tcontinue;\n\n\t\tif (!kvm_apic_match_dest(vcpu, NULL, irq->shorthand,\n\t\t\t\t\tirq->dest_id, irq->dest_mode))\n\t\t\tcontinue;\n\n\t\tif (++r == 2)\n\t\t\treturn false;\n\n\t\t*dest_vcpu = vcpu;\n\t}\n\n\treturn r == 1;\n}\nEXPORT_SYMBOL_GPL(kvm_intr_is_single_vcpu);\n\n#define IOAPIC_ROUTING_ENTRY(irq) \\\n\t{ .gsi = irq, .type = KVM_IRQ_ROUTING_IRQCHIP,\t\\\n\t  .u.irqchip = { .irqchip = KVM_IRQCHIP_IOAPIC, .pin = (irq) } }\n#define ROUTING_ENTRY1(irq) IOAPIC_ROUTING_ENTRY(irq)\n\n#define PIC_ROUTING_ENTRY(irq) \\\n\t{ .gsi = irq, .type = KVM_IRQ_ROUTING_IRQCHIP,\t\\\n\t  .u.irqchip = { .irqchip = SELECT_PIC(irq), .pin = (irq) % 8 } }\n#define ROUTING_ENTRY2(irq) \\\n\tIOAPIC_ROUTING_ENTRY(irq), PIC_ROUTING_ENTRY(irq)\n\nstatic const struct kvm_irq_routing_entry default_routing[] = {\n\tROUTING_ENTRY2(0), ROUTING_ENTRY2(1),\n\tROUTING_ENTRY2(2), ROUTING_ENTRY2(3),\n\tROUTING_ENTRY2(4), ROUTING_ENTRY2(5),\n\tROUTING_ENTRY2(6), ROUTING_ENTRY2(7),\n\tROUTING_ENTRY2(8), ROUTING_ENTRY2(9),\n\tROUTING_ENTRY2(10), ROUTING_ENTRY2(11),\n\tROUTING_ENTRY2(12), ROUTING_ENTRY2(13),\n\tROUTING_ENTRY2(14), ROUTING_ENTRY2(15),\n\tROUTING_ENTRY1(16), ROUTING_ENTRY1(17),\n\tROUTING_ENTRY1(18), ROUTING_ENTRY1(19),\n\tROUTING_ENTRY1(20), ROUTING_ENTRY1(21),\n\tROUTING_ENTRY1(22), ROUTING_ENTRY1(23),\n};\n\nint kvm_setup_default_irq_routing(struct kvm *kvm)\n{\n\treturn kvm_set_irq_routing(kvm, default_routing,\n\t\t\t\t   ARRAY_SIZE(default_routing), 0);\n}\n\nstatic const struct kvm_irq_routing_entry empty_routing[] = {};\n\nint kvm_setup_empty_irq_routing(struct kvm *kvm)\n{\n\treturn kvm_set_irq_routing(kvm, empty_routing, 0, 0);\n}\n\nvoid kvm_arch_post_irq_routing_update(struct kvm *kvm)\n{\n\tif (!irqchip_split(kvm))\n\t\treturn;\n\tkvm_make_scan_ioapic_request(kvm);\n}\n\nvoid kvm_scan_ioapic_routes(struct kvm_vcpu *vcpu,\n\t\t\t    ulong *ioapic_handled_vectors)\n{\n\tstruct kvm *kvm = vcpu->kvm;\n\tstruct kvm_kernel_irq_routing_entry *entry;\n\tstruct kvm_irq_routing_table *table;\n\tu32 i, nr_ioapic_pins;\n\tint idx;\n\n\tidx = srcu_read_lock(&kvm->irq_srcu);\n\ttable = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);\n\tnr_ioapic_pins = min_t(u32, table->nr_rt_entries,\n\t\t\t       kvm->arch.nr_reserved_ioapic_pins);\n\tfor (i = 0; i < nr_ioapic_pins; ++i) {\n\t\thlist_for_each_entry(entry, &table->map[i], link) {\n\t\t\tstruct kvm_lapic_irq irq;\n\n\t\t\tif (entry->type != KVM_IRQ_ROUTING_MSI)\n\t\t\t\tcontinue;\n\n\t\t\tkvm_set_msi_irq(vcpu->kvm, entry, &irq);\n\n\t\t\tif (irq.trig_mode &&\n\t\t\t    (kvm_apic_match_dest(vcpu, NULL, APIC_DEST_NOSHORT,\n\t\t\t\t\t\t irq.dest_id, irq.dest_mode) ||\n\t\t\t     kvm_apic_pending_eoi(vcpu, irq.vector)))\n\t\t\t\t__set_bit(irq.vector, ioapic_handled_vectors);\n\t\t}\n\t}\n\tsrcu_read_unlock(&kvm->irq_srcu, idx);\n}\n\nvoid kvm_arch_irq_routing_update(struct kvm *kvm)\n{\n\tkvm_hv_irq_routing_update(kvm);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}