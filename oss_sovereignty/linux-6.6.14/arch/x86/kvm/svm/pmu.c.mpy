{
  "module_name": "pmu.c",
  "hash_id": "019780dda6adefc923db4396ba9fb44a006e47e592219af700674a1c1c02a15a",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/svm/pmu.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include <linux/perf_event.h>\n#include \"x86.h\"\n#include \"cpuid.h\"\n#include \"lapic.h\"\n#include \"pmu.h\"\n#include \"svm.h\"\n\nenum pmu_type {\n\tPMU_TYPE_COUNTER = 0,\n\tPMU_TYPE_EVNTSEL,\n};\n\nstatic struct kvm_pmc *amd_pmc_idx_to_pmc(struct kvm_pmu *pmu, int pmc_idx)\n{\n\tunsigned int num_counters = pmu->nr_arch_gp_counters;\n\n\tif (pmc_idx >= num_counters)\n\t\treturn NULL;\n\n\treturn &pmu->gp_counters[array_index_nospec(pmc_idx, num_counters)];\n}\n\nstatic inline struct kvm_pmc *get_gp_pmc_amd(struct kvm_pmu *pmu, u32 msr,\n\t\t\t\t\t     enum pmu_type type)\n{\n\tstruct kvm_vcpu *vcpu = pmu_to_vcpu(pmu);\n\tunsigned int idx;\n\n\tif (!vcpu->kvm->arch.enable_pmu)\n\t\treturn NULL;\n\n\tswitch (msr) {\n\tcase MSR_F15H_PERF_CTL0 ... MSR_F15H_PERF_CTR5:\n\t\tif (!guest_cpuid_has(vcpu, X86_FEATURE_PERFCTR_CORE))\n\t\t\treturn NULL;\n\t\t \n\t\tidx = (unsigned int)((msr - MSR_F15H_PERF_CTL0) / 2);\n\t\tif (!(msr & 0x1) != (type == PMU_TYPE_EVNTSEL))\n\t\t\treturn NULL;\n\t\tbreak;\n\tcase MSR_K7_EVNTSEL0 ... MSR_K7_EVNTSEL3:\n\t\tif (type != PMU_TYPE_EVNTSEL)\n\t\t\treturn NULL;\n\t\tidx = msr - MSR_K7_EVNTSEL0;\n\t\tbreak;\n\tcase MSR_K7_PERFCTR0 ... MSR_K7_PERFCTR3:\n\t\tif (type != PMU_TYPE_COUNTER)\n\t\t\treturn NULL;\n\t\tidx = msr - MSR_K7_PERFCTR0;\n\t\tbreak;\n\tdefault:\n\t\treturn NULL;\n\t}\n\n\treturn amd_pmc_idx_to_pmc(pmu, idx);\n}\n\nstatic bool amd_hw_event_available(struct kvm_pmc *pmc)\n{\n\treturn true;\n}\n\nstatic bool amd_is_valid_rdpmc_ecx(struct kvm_vcpu *vcpu, unsigned int idx)\n{\n\tstruct kvm_pmu *pmu = vcpu_to_pmu(vcpu);\n\n\tidx &= ~(3u << 30);\n\n\treturn idx < pmu->nr_arch_gp_counters;\n}\n\n \nstatic struct kvm_pmc *amd_rdpmc_ecx_to_pmc(struct kvm_vcpu *vcpu,\n\tunsigned int idx, u64 *mask)\n{\n\treturn amd_pmc_idx_to_pmc(vcpu_to_pmu(vcpu), idx & ~(3u << 30));\n}\n\nstatic struct kvm_pmc *amd_msr_idx_to_pmc(struct kvm_vcpu *vcpu, u32 msr)\n{\n\tstruct kvm_pmu *pmu = vcpu_to_pmu(vcpu);\n\tstruct kvm_pmc *pmc;\n\n\tpmc = get_gp_pmc_amd(pmu, msr, PMU_TYPE_COUNTER);\n\tpmc = pmc ? pmc : get_gp_pmc_amd(pmu, msr, PMU_TYPE_EVNTSEL);\n\n\treturn pmc;\n}\n\nstatic bool amd_is_valid_msr(struct kvm_vcpu *vcpu, u32 msr)\n{\n\tstruct kvm_pmu *pmu = vcpu_to_pmu(vcpu);\n\n\tswitch (msr) {\n\tcase MSR_K7_EVNTSEL0 ... MSR_K7_PERFCTR3:\n\t\treturn pmu->version > 0;\n\tcase MSR_F15H_PERF_CTL0 ... MSR_F15H_PERF_CTR5:\n\t\treturn guest_cpuid_has(vcpu, X86_FEATURE_PERFCTR_CORE);\n\tcase MSR_AMD64_PERF_CNTR_GLOBAL_STATUS:\n\tcase MSR_AMD64_PERF_CNTR_GLOBAL_CTL:\n\tcase MSR_AMD64_PERF_CNTR_GLOBAL_STATUS_CLR:\n\t\treturn pmu->version > 1;\n\tdefault:\n\t\tif (msr > MSR_F15H_PERF_CTR5 &&\n\t\t    msr < MSR_F15H_PERF_CTL0 + 2 * pmu->nr_arch_gp_counters)\n\t\t\treturn pmu->version > 1;\n\t\tbreak;\n\t}\n\n\treturn amd_msr_idx_to_pmc(vcpu, msr);\n}\n\nstatic int amd_pmu_get_msr(struct kvm_vcpu *vcpu, struct msr_data *msr_info)\n{\n\tstruct kvm_pmu *pmu = vcpu_to_pmu(vcpu);\n\tstruct kvm_pmc *pmc;\n\tu32 msr = msr_info->index;\n\n\t \n\tpmc = get_gp_pmc_amd(pmu, msr, PMU_TYPE_COUNTER);\n\tif (pmc) {\n\t\tmsr_info->data = pmc_read_counter(pmc);\n\t\treturn 0;\n\t}\n\t \n\tpmc = get_gp_pmc_amd(pmu, msr, PMU_TYPE_EVNTSEL);\n\tif (pmc) {\n\t\tmsr_info->data = pmc->eventsel;\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic int amd_pmu_set_msr(struct kvm_vcpu *vcpu, struct msr_data *msr_info)\n{\n\tstruct kvm_pmu *pmu = vcpu_to_pmu(vcpu);\n\tstruct kvm_pmc *pmc;\n\tu32 msr = msr_info->index;\n\tu64 data = msr_info->data;\n\n\t \n\tpmc = get_gp_pmc_amd(pmu, msr, PMU_TYPE_COUNTER);\n\tif (pmc) {\n\t\tpmc_write_counter(pmc, data);\n\t\tpmc_update_sample_period(pmc);\n\t\treturn 0;\n\t}\n\t \n\tpmc = get_gp_pmc_amd(pmu, msr, PMU_TYPE_EVNTSEL);\n\tif (pmc) {\n\t\tdata &= ~pmu->reserved_bits;\n\t\tif (data != pmc->eventsel) {\n\t\t\tpmc->eventsel = data;\n\t\t\tkvm_pmu_request_counter_reprogram(pmc);\n\t\t}\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic void amd_pmu_refresh(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_pmu *pmu = vcpu_to_pmu(vcpu);\n\tunion cpuid_0x80000022_ebx ebx;\n\n\tpmu->version = 1;\n\tif (guest_cpuid_has(vcpu, X86_FEATURE_PERFMON_V2)) {\n\t\tpmu->version = 2;\n\t\t \n\t\tBUILD_BUG_ON(x86_feature_cpuid(X86_FEATURE_PERFMON_V2).function != 0x80000022 ||\n\t\t\t     x86_feature_cpuid(X86_FEATURE_PERFMON_V2).index);\n\t\tebx.full = kvm_find_cpuid_entry_index(vcpu, 0x80000022, 0)->ebx;\n\t\tpmu->nr_arch_gp_counters = ebx.split.num_core_pmc;\n\t} else if (guest_cpuid_has(vcpu, X86_FEATURE_PERFCTR_CORE)) {\n\t\tpmu->nr_arch_gp_counters = AMD64_NUM_COUNTERS_CORE;\n\t} else {\n\t\tpmu->nr_arch_gp_counters = AMD64_NUM_COUNTERS;\n\t}\n\n\tpmu->nr_arch_gp_counters = min_t(unsigned int, pmu->nr_arch_gp_counters,\n\t\t\t\t\t kvm_pmu_cap.num_counters_gp);\n\n\tif (pmu->version > 1) {\n\t\tpmu->global_ctrl_mask = ~((1ull << pmu->nr_arch_gp_counters) - 1);\n\t\tpmu->global_status_mask = pmu->global_ctrl_mask;\n\t}\n\n\tpmu->counter_bitmask[KVM_PMC_GP] = ((u64)1 << 48) - 1;\n\tpmu->reserved_bits = 0xfffffff000280000ull;\n\tpmu->raw_event_mask = AMD64_RAW_EVENT_MASK;\n\t \n\tpmu->counter_bitmask[KVM_PMC_FIXED] = 0;\n\tpmu->nr_arch_fixed_counters = 0;\n\tbitmap_set(pmu->all_valid_pmc_idx, 0, pmu->nr_arch_gp_counters);\n}\n\nstatic void amd_pmu_init(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_pmu *pmu = vcpu_to_pmu(vcpu);\n\tint i;\n\n\tBUILD_BUG_ON(KVM_AMD_PMC_MAX_GENERIC > AMD64_NUM_COUNTERS_CORE);\n\tBUILD_BUG_ON(KVM_AMD_PMC_MAX_GENERIC > INTEL_PMC_MAX_GENERIC);\n\n\tfor (i = 0; i < KVM_AMD_PMC_MAX_GENERIC ; i++) {\n\t\tpmu->gp_counters[i].type = KVM_PMC_GP;\n\t\tpmu->gp_counters[i].vcpu = vcpu;\n\t\tpmu->gp_counters[i].idx = i;\n\t\tpmu->gp_counters[i].current_config = 0;\n\t}\n}\n\nstruct kvm_pmu_ops amd_pmu_ops __initdata = {\n\t.hw_event_available = amd_hw_event_available,\n\t.pmc_idx_to_pmc = amd_pmc_idx_to_pmc,\n\t.rdpmc_ecx_to_pmc = amd_rdpmc_ecx_to_pmc,\n\t.msr_idx_to_pmc = amd_msr_idx_to_pmc,\n\t.is_valid_rdpmc_ecx = amd_is_valid_rdpmc_ecx,\n\t.is_valid_msr = amd_is_valid_msr,\n\t.get_msr = amd_pmu_get_msr,\n\t.set_msr = amd_pmu_set_msr,\n\t.refresh = amd_pmu_refresh,\n\t.init = amd_pmu_init,\n\t.EVENTSEL_EVENT = AMD64_EVENTSEL_EVENT,\n\t.MAX_NR_GP_COUNTERS = KVM_AMD_PMC_MAX_GENERIC,\n\t.MIN_NR_GP_COUNTERS = AMD64_NUM_COUNTERS,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}