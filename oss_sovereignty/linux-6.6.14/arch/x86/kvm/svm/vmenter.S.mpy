{
  "module_name": "vmenter.S",
  "hash_id": "77a9848ab46d62cfca60487d4499d7ea504f55dcd85689bb886c480a52af492d",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/svm/vmenter.S",
  "human_readable_source": " \n#include <linux/linkage.h>\n#include <asm/asm.h>\n#include <asm/asm-offsets.h>\n#include <asm/bitsperlong.h>\n#include <asm/kvm_vcpu_regs.h>\n#include <asm/nospec-branch.h>\n#include \"kvm-asm-offsets.h\"\n\n#define WORD_SIZE (BITS_PER_LONG / 8)\n\n \n#define VCPU_RCX\t(SVM_vcpu_arch_regs + __VCPU_REGS_RCX * WORD_SIZE)\n#define VCPU_RDX\t(SVM_vcpu_arch_regs + __VCPU_REGS_RDX * WORD_SIZE)\n#define VCPU_RBX\t(SVM_vcpu_arch_regs + __VCPU_REGS_RBX * WORD_SIZE)\n \n#define VCPU_RBP\t(SVM_vcpu_arch_regs + __VCPU_REGS_RBP * WORD_SIZE)\n#define VCPU_RSI\t(SVM_vcpu_arch_regs + __VCPU_REGS_RSI * WORD_SIZE)\n#define VCPU_RDI\t(SVM_vcpu_arch_regs + __VCPU_REGS_RDI * WORD_SIZE)\n\n#ifdef CONFIG_X86_64\n#define VCPU_R8\t\t(SVM_vcpu_arch_regs + __VCPU_REGS_R8  * WORD_SIZE)\n#define VCPU_R9\t\t(SVM_vcpu_arch_regs + __VCPU_REGS_R9  * WORD_SIZE)\n#define VCPU_R10\t(SVM_vcpu_arch_regs + __VCPU_REGS_R10 * WORD_SIZE)\n#define VCPU_R11\t(SVM_vcpu_arch_regs + __VCPU_REGS_R11 * WORD_SIZE)\n#define VCPU_R12\t(SVM_vcpu_arch_regs + __VCPU_REGS_R12 * WORD_SIZE)\n#define VCPU_R13\t(SVM_vcpu_arch_regs + __VCPU_REGS_R13 * WORD_SIZE)\n#define VCPU_R14\t(SVM_vcpu_arch_regs + __VCPU_REGS_R14 * WORD_SIZE)\n#define VCPU_R15\t(SVM_vcpu_arch_regs + __VCPU_REGS_R15 * WORD_SIZE)\n#endif\n\n#define SVM_vmcb01_pa\t(SVM_vmcb01 + KVM_VMCB_pa)\n\n.section .noinstr.text, \"ax\"\n\n.macro RESTORE_GUEST_SPEC_CTRL\n\t \n\tALTERNATIVE_2 \"\", \\\n\t\t\"jmp 800f\", X86_FEATURE_MSR_SPEC_CTRL, \\\n\t\t\"\", X86_FEATURE_V_SPEC_CTRL\n801:\n.endm\n.macro RESTORE_GUEST_SPEC_CTRL_BODY\n800:\n\t \n\tmovl SVM_spec_ctrl(%_ASM_DI), %eax\n\tcmp PER_CPU_VAR(x86_spec_ctrl_current), %eax\n\tje 801b\n\tmov $MSR_IA32_SPEC_CTRL, %ecx\n\txor %edx, %edx\n\twrmsr\n\tjmp 801b\n.endm\n\n.macro RESTORE_HOST_SPEC_CTRL\n\t \n\tALTERNATIVE_2 \"\", \\\n\t\t\"jmp 900f\", X86_FEATURE_MSR_SPEC_CTRL, \\\n\t\t\"\", X86_FEATURE_V_SPEC_CTRL\n901:\n.endm\n.macro RESTORE_HOST_SPEC_CTRL_BODY\n900:\n\t \n\tmov $MSR_IA32_SPEC_CTRL, %ecx\n\n\t \n\tcmpb $0, (%_ASM_SP)\n\tjnz 998f\n\trdmsr\n\tmovl %eax, SVM_spec_ctrl(%_ASM_DI)\n998:\n\n\t \n\tmovl PER_CPU_VAR(x86_spec_ctrl_current), %eax\n\tcmp SVM_spec_ctrl(%_ASM_DI), %eax\n\tje 901b\n\txor %edx, %edx\n\twrmsr\n\tjmp 901b\n.endm\n\n\n \nSYM_FUNC_START(__svm_vcpu_run)\n\tpush %_ASM_BP\n#ifdef CONFIG_X86_64\n\tpush %r15\n\tpush %r14\n\tpush %r13\n\tpush %r12\n#else\n\tpush %edi\n\tpush %esi\n#endif\n\tpush %_ASM_BX\n\n\t \n\n\t \n\tpush %_ASM_ARG2\n\n\t \n\t__ASM_SIZE(push) PER_CPU_VAR(svm_data + SD_save_area_pa)\n\n\t \n\tpush %_ASM_ARG1\n\n.ifnc _ASM_ARG1, _ASM_DI\n\t \n\tmov %_ASM_ARG1, %_ASM_DI\n.endif\n\n\t \n\tRESTORE_GUEST_SPEC_CTRL\n\n\t \n\tmov SVM_vmcb01_pa(%_ASM_DI), %_ASM_AX\n1:\tvmload %_ASM_AX\n2:\n\n\t \n\tmov SVM_current_vmcb(%_ASM_DI), %_ASM_AX\n\tmov KVM_VMCB_pa(%_ASM_AX), %_ASM_AX\n\n\t \n\tmov VCPU_RCX(%_ASM_DI), %_ASM_CX\n\tmov VCPU_RDX(%_ASM_DI), %_ASM_DX\n\tmov VCPU_RBX(%_ASM_DI), %_ASM_BX\n\tmov VCPU_RBP(%_ASM_DI), %_ASM_BP\n\tmov VCPU_RSI(%_ASM_DI), %_ASM_SI\n#ifdef CONFIG_X86_64\n\tmov VCPU_R8 (%_ASM_DI),  %r8\n\tmov VCPU_R9 (%_ASM_DI),  %r9\n\tmov VCPU_R10(%_ASM_DI), %r10\n\tmov VCPU_R11(%_ASM_DI), %r11\n\tmov VCPU_R12(%_ASM_DI), %r12\n\tmov VCPU_R13(%_ASM_DI), %r13\n\tmov VCPU_R14(%_ASM_DI), %r14\n\tmov VCPU_R15(%_ASM_DI), %r15\n#endif\n\tmov VCPU_RDI(%_ASM_DI), %_ASM_DI\n\n\t \n\tsti\n\n3:\tvmrun %_ASM_AX\n4:\n\tcli\n\n\t \n\tpop %_ASM_AX\n\n\t \n\tmov %_ASM_CX,   VCPU_RCX(%_ASM_AX)\n\tmov %_ASM_DX,   VCPU_RDX(%_ASM_AX)\n\tmov %_ASM_BX,   VCPU_RBX(%_ASM_AX)\n\tmov %_ASM_BP,   VCPU_RBP(%_ASM_AX)\n\tmov %_ASM_SI,   VCPU_RSI(%_ASM_AX)\n\tmov %_ASM_DI,   VCPU_RDI(%_ASM_AX)\n#ifdef CONFIG_X86_64\n\tmov %r8,  VCPU_R8 (%_ASM_AX)\n\tmov %r9,  VCPU_R9 (%_ASM_AX)\n\tmov %r10, VCPU_R10(%_ASM_AX)\n\tmov %r11, VCPU_R11(%_ASM_AX)\n\tmov %r12, VCPU_R12(%_ASM_AX)\n\tmov %r13, VCPU_R13(%_ASM_AX)\n\tmov %r14, VCPU_R14(%_ASM_AX)\n\tmov %r15, VCPU_R15(%_ASM_AX)\n#endif\n\n\t \n\tmov %_ASM_AX, %_ASM_DI\n\n\tmov SVM_vmcb01_pa(%_ASM_DI), %_ASM_AX\n5:\tvmsave %_ASM_AX\n6:\n\n\t \n\tpop %_ASM_AX\n7:\tvmload %_ASM_AX\n8:\n\n#ifdef CONFIG_RETPOLINE\n\t \n\tFILL_RETURN_BUFFER %_ASM_AX, RSB_CLEAR_LOOPS, X86_FEATURE_RETPOLINE\n#endif\n\n\t \n\tRESTORE_HOST_SPEC_CTRL\n\n\t \n\tUNTRAIN_RET_VM\n\n\t \n\txor %ecx, %ecx\n\txor %edx, %edx\n\txor %ebx, %ebx\n\txor %ebp, %ebp\n\txor %esi, %esi\n\txor %edi, %edi\n#ifdef CONFIG_X86_64\n\txor %r8d,  %r8d\n\txor %r9d,  %r9d\n\txor %r10d, %r10d\n\txor %r11d, %r11d\n\txor %r12d, %r12d\n\txor %r13d, %r13d\n\txor %r14d, %r14d\n\txor %r15d, %r15d\n#endif\n\n\t \n\tpop %_ASM_BX\n\n\tpop %_ASM_BX\n\n#ifdef CONFIG_X86_64\n\tpop %r12\n\tpop %r13\n\tpop %r14\n\tpop %r15\n#else\n\tpop %esi\n\tpop %edi\n#endif\n\tpop %_ASM_BP\n\tRET\n\n\tRESTORE_GUEST_SPEC_CTRL_BODY\n\tRESTORE_HOST_SPEC_CTRL_BODY\n\n10:\tcmpb $0, kvm_rebooting\n\tjne 2b\n\tud2\n30:\tcmpb $0, kvm_rebooting\n\tjne 4b\n\tud2\n50:\tcmpb $0, kvm_rebooting\n\tjne 6b\n\tud2\n70:\tcmpb $0, kvm_rebooting\n\tjne 8b\n\tud2\n\n\t_ASM_EXTABLE(1b, 10b)\n\t_ASM_EXTABLE(3b, 30b)\n\t_ASM_EXTABLE(5b, 50b)\n\t_ASM_EXTABLE(7b, 70b)\n\nSYM_FUNC_END(__svm_vcpu_run)\n\n \nSYM_FUNC_START(__svm_sev_es_vcpu_run)\n\tpush %_ASM_BP\n#ifdef CONFIG_X86_64\n\tpush %r15\n\tpush %r14\n\tpush %r13\n\tpush %r12\n#else\n\tpush %edi\n\tpush %esi\n#endif\n\tpush %_ASM_BX\n\n\t \n\n\t \n\tpush %_ASM_ARG2\n\n\t \n\tpush %_ASM_ARG1\n\n.ifnc _ASM_ARG1, _ASM_DI\n\t \n\tmov %_ASM_ARG1, %_ASM_DI\n.endif\n\n\t \n\tRESTORE_GUEST_SPEC_CTRL\n\n\t \n\tmov SVM_current_vmcb(%_ASM_DI), %_ASM_AX\n\tmov KVM_VMCB_pa(%_ASM_AX), %_ASM_AX\n\n\t \n\tsti\n\n1:\tvmrun %_ASM_AX\n\n2:\tcli\n\n\t \n\tpop %_ASM_DI\n\n#ifdef CONFIG_RETPOLINE\n\t \n\tFILL_RETURN_BUFFER %_ASM_AX, RSB_CLEAR_LOOPS, X86_FEATURE_RETPOLINE\n#endif\n\n\t \n\tRESTORE_HOST_SPEC_CTRL\n\n\t \n\tUNTRAIN_RET_VM\n\n\t \n\tpop %_ASM_BX\n\n\tpop %_ASM_BX\n\n#ifdef CONFIG_X86_64\n\tpop %r12\n\tpop %r13\n\tpop %r14\n\tpop %r15\n#else\n\tpop %esi\n\tpop %edi\n#endif\n\tpop %_ASM_BP\n\tRET\n\n\tRESTORE_GUEST_SPEC_CTRL_BODY\n\tRESTORE_HOST_SPEC_CTRL_BODY\n\n3:\tcmpb $0, kvm_rebooting\n\tjne 2b\n\tud2\n\n\t_ASM_EXTABLE(1b, 3b)\n\nSYM_FUNC_END(__svm_sev_es_vcpu_run)\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}