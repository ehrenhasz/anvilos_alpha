{
  "module_name": "mmutrace.h",
  "hash_id": "f1f67fa6807b25287d929b37bdb5c830f9727c373c7e84bd41d5bfc744a85ce8",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/mmu/mmutrace.h",
  "human_readable_source": " \n#if !defined(_TRACE_KVMMMU_H) || defined(TRACE_HEADER_MULTI_READ)\n#define _TRACE_KVMMMU_H\n\n#include <linux/tracepoint.h>\n#include <linux/trace_events.h>\n\n#undef TRACE_SYSTEM\n#define TRACE_SYSTEM kvmmmu\n\n#define KVM_MMU_PAGE_FIELDS\t\t\\\n\t__field(__u8, mmu_valid_gen)\t\\\n\t__field(__u64, gfn)\t\t\\\n\t__field(__u32, role)\t\t\\\n\t__field(__u32, root_count)\t\\\n\t__field(bool, unsync)\n\n#define KVM_MMU_PAGE_ASSIGN(sp)\t\t\t\t\\\n\t__entry->mmu_valid_gen = sp->mmu_valid_gen;\t\\\n\t__entry->gfn = sp->gfn;\t\t\t\t\\\n\t__entry->role = sp->role.word;\t\t\t\\\n\t__entry->root_count = sp->root_count;\t\t\\\n\t__entry->unsync = sp->unsync;\n\n#define KVM_MMU_PAGE_PRINTK() ({\t\t\t\t        \\\n\tconst char *saved_ptr = trace_seq_buffer_ptr(p);\t\t\\\n\tstatic const char *access_str[] = {\t\t\t        \\\n\t\t\"---\", \"--x\", \"w--\", \"w-x\", \"-u-\", \"-ux\", \"wu-\", \"wux\"  \\\n\t};\t\t\t\t\t\t\t        \\\n\tunion kvm_mmu_page_role role;\t\t\t\t        \\\n\t\t\t\t\t\t\t\t        \\\n\trole.word = __entry->role;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\ttrace_seq_printf(p, \"sp gen %u gfn %llx l%u %u-byte q%u%s %s%s\"\t\\\n\t\t\t \" %snxe %sad root %u %s%c\",\t\t\t\\\n\t\t\t __entry->mmu_valid_gen,\t\t\t\\\n\t\t\t __entry->gfn, role.level,\t\t\t\\\n\t\t\t role.has_4_byte_gpte ? 4 : 8,\t\t\t\\\n\t\t\t role.quadrant,\t\t\t\t\t\\\n\t\t\t role.direct ? \" direct\" : \"\",\t\t\t\\\n\t\t\t access_str[role.access],\t\t\t\\\n\t\t\t role.invalid ? \" invalid\" : \"\",\t\t\\\n\t\t\t role.efer_nx ? \"\" : \"!\",\t\t\t\\\n\t\t\t role.ad_disabled ? \"!\" : \"\",\t\t\t\\\n\t\t\t __entry->root_count,\t\t\t\t\\\n\t\t\t __entry->unsync ? \"unsync\" : \"sync\", 0);\t\\\n\tsaved_ptr;\t\t\t\t\t\t\t\\\n\t\t})\n\n#define kvm_mmu_trace_pferr_flags       \\\n\t{ PFERR_PRESENT_MASK, \"P\" },\t\\\n\t{ PFERR_WRITE_MASK, \"W\" },\t\\\n\t{ PFERR_USER_MASK, \"U\" },\t\\\n\t{ PFERR_RSVD_MASK, \"RSVD\" },\t\\\n\t{ PFERR_FETCH_MASK, \"F\" }\n\nTRACE_DEFINE_ENUM(RET_PF_CONTINUE);\nTRACE_DEFINE_ENUM(RET_PF_RETRY);\nTRACE_DEFINE_ENUM(RET_PF_EMULATE);\nTRACE_DEFINE_ENUM(RET_PF_INVALID);\nTRACE_DEFINE_ENUM(RET_PF_FIXED);\nTRACE_DEFINE_ENUM(RET_PF_SPURIOUS);\n\n \nTRACE_EVENT(\n\tkvm_mmu_pagetable_walk,\n\tTP_PROTO(u64 addr, u32 pferr),\n\tTP_ARGS(addr, pferr),\n\n\tTP_STRUCT__entry(\n\t\t__field(__u64, addr)\n\t\t__field(__u32, pferr)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->addr = addr;\n\t\t__entry->pferr = pferr;\n\t),\n\n\tTP_printk(\"addr %llx pferr %x %s\", __entry->addr, __entry->pferr,\n\t\t  __print_flags(__entry->pferr, \"|\", kvm_mmu_trace_pferr_flags))\n);\n\n\n \nTRACE_EVENT(\n\tkvm_mmu_paging_element,\n\tTP_PROTO(u64 pte, int level),\n\tTP_ARGS(pte, level),\n\n\tTP_STRUCT__entry(\n\t\t__field(__u64, pte)\n\t\t__field(__u32, level)\n\t\t),\n\n\tTP_fast_assign(\n\t\t__entry->pte = pte;\n\t\t__entry->level = level;\n\t\t),\n\n\tTP_printk(\"pte %llx level %u\", __entry->pte, __entry->level)\n);\n\nDECLARE_EVENT_CLASS(kvm_mmu_set_bit_class,\n\n\tTP_PROTO(unsigned long table_gfn, unsigned index, unsigned size),\n\n\tTP_ARGS(table_gfn, index, size),\n\n\tTP_STRUCT__entry(\n\t\t__field(__u64, gpa)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->gpa = ((u64)table_gfn << PAGE_SHIFT)\n\t\t\t\t+ index * size;\n\t\t),\n\n\tTP_printk(\"gpa %llx\", __entry->gpa)\n);\n\n \nDEFINE_EVENT(kvm_mmu_set_bit_class, kvm_mmu_set_accessed_bit,\n\n\tTP_PROTO(unsigned long table_gfn, unsigned index, unsigned size),\n\n\tTP_ARGS(table_gfn, index, size)\n);\n\n \nDEFINE_EVENT(kvm_mmu_set_bit_class, kvm_mmu_set_dirty_bit,\n\n\tTP_PROTO(unsigned long table_gfn, unsigned index, unsigned size),\n\n\tTP_ARGS(table_gfn, index, size)\n);\n\nTRACE_EVENT(\n\tkvm_mmu_walker_error,\n\tTP_PROTO(u32 pferr),\n\tTP_ARGS(pferr),\n\n\tTP_STRUCT__entry(\n\t\t__field(__u32, pferr)\n\t\t),\n\n\tTP_fast_assign(\n\t\t__entry->pferr = pferr;\n\t\t),\n\n\tTP_printk(\"pferr %x %s\", __entry->pferr,\n\t\t  __print_flags(__entry->pferr, \"|\", kvm_mmu_trace_pferr_flags))\n);\n\nTRACE_EVENT(\n\tkvm_mmu_get_page,\n\tTP_PROTO(struct kvm_mmu_page *sp, bool created),\n\tTP_ARGS(sp, created),\n\n\tTP_STRUCT__entry(\n\t\tKVM_MMU_PAGE_FIELDS\n\t\t__field(bool, created)\n\t\t),\n\n\tTP_fast_assign(\n\t\tKVM_MMU_PAGE_ASSIGN(sp)\n\t\t__entry->created = created;\n\t\t),\n\n\tTP_printk(\"%s %s\", KVM_MMU_PAGE_PRINTK(),\n\t\t  __entry->created ? \"new\" : \"existing\")\n);\n\nDECLARE_EVENT_CLASS(kvm_mmu_page_class,\n\n\tTP_PROTO(struct kvm_mmu_page *sp),\n\tTP_ARGS(sp),\n\n\tTP_STRUCT__entry(\n\t\tKVM_MMU_PAGE_FIELDS\n\t),\n\n\tTP_fast_assign(\n\t\tKVM_MMU_PAGE_ASSIGN(sp)\n\t),\n\n\tTP_printk(\"%s\", KVM_MMU_PAGE_PRINTK())\n);\n\nDEFINE_EVENT(kvm_mmu_page_class, kvm_mmu_sync_page,\n\tTP_PROTO(struct kvm_mmu_page *sp),\n\n\tTP_ARGS(sp)\n);\n\nDEFINE_EVENT(kvm_mmu_page_class, kvm_mmu_unsync_page,\n\tTP_PROTO(struct kvm_mmu_page *sp),\n\n\tTP_ARGS(sp)\n);\n\nDEFINE_EVENT(kvm_mmu_page_class, kvm_mmu_prepare_zap_page,\n\tTP_PROTO(struct kvm_mmu_page *sp),\n\n\tTP_ARGS(sp)\n);\n\nTRACE_EVENT(\n\tmark_mmio_spte,\n\tTP_PROTO(u64 *sptep, gfn_t gfn, u64 spte),\n\tTP_ARGS(sptep, gfn, spte),\n\n\tTP_STRUCT__entry(\n\t\t__field(void *, sptep)\n\t\t__field(gfn_t, gfn)\n\t\t__field(unsigned, access)\n\t\t__field(unsigned int, gen)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->sptep = sptep;\n\t\t__entry->gfn = gfn;\n\t\t__entry->access = spte & ACC_ALL;\n\t\t__entry->gen = get_mmio_spte_generation(spte);\n\t),\n\n\tTP_printk(\"sptep:%p gfn %llx access %x gen %x\", __entry->sptep,\n\t\t  __entry->gfn, __entry->access, __entry->gen)\n);\n\nTRACE_EVENT(\n\thandle_mmio_page_fault,\n\tTP_PROTO(u64 addr, gfn_t gfn, unsigned access),\n\tTP_ARGS(addr, gfn, access),\n\n\tTP_STRUCT__entry(\n\t\t__field(u64, addr)\n\t\t__field(gfn_t, gfn)\n\t\t__field(unsigned, access)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->addr = addr;\n\t\t__entry->gfn = gfn;\n\t\t__entry->access = access;\n\t),\n\n\tTP_printk(\"addr:%llx gfn %llx access %x\", __entry->addr, __entry->gfn,\n\t\t  __entry->access)\n);\n\nTRACE_EVENT(\n\tfast_page_fault,\n\tTP_PROTO(struct kvm_vcpu *vcpu, struct kvm_page_fault *fault,\n\t\t u64 *sptep, u64 old_spte, int ret),\n\tTP_ARGS(vcpu, fault, sptep, old_spte, ret),\n\n\tTP_STRUCT__entry(\n\t\t__field(int, vcpu_id)\n\t\t__field(gpa_t, cr2_or_gpa)\n\t\t__field(u32, error_code)\n\t\t__field(u64 *, sptep)\n\t\t__field(u64, old_spte)\n\t\t__field(u64, new_spte)\n\t\t__field(int, ret)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->vcpu_id = vcpu->vcpu_id;\n\t\t__entry->cr2_or_gpa = fault->addr;\n\t\t__entry->error_code = fault->error_code;\n\t\t__entry->sptep = sptep;\n\t\t__entry->old_spte = old_spte;\n\t\t__entry->new_spte = *sptep;\n\t\t__entry->ret = ret;\n\t),\n\n\tTP_printk(\"vcpu %d gva %llx error_code %s sptep %p old %#llx\"\n\t\t  \" new %llx spurious %d fixed %d\", __entry->vcpu_id,\n\t\t  __entry->cr2_or_gpa, __print_flags(__entry->error_code, \"|\",\n\t\t  kvm_mmu_trace_pferr_flags), __entry->sptep,\n\t\t  __entry->old_spte, __entry->new_spte,\n\t\t  __entry->ret == RET_PF_SPURIOUS, __entry->ret == RET_PF_FIXED\n\t)\n);\n\nTRACE_EVENT(\n\tkvm_mmu_zap_all_fast,\n\tTP_PROTO(struct kvm *kvm),\n\tTP_ARGS(kvm),\n\n\tTP_STRUCT__entry(\n\t\t__field(__u8, mmu_valid_gen)\n\t\t__field(unsigned int, mmu_used_pages)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->mmu_valid_gen = kvm->arch.mmu_valid_gen;\n\t\t__entry->mmu_used_pages = kvm->arch.n_used_mmu_pages;\n\t),\n\n\tTP_printk(\"kvm-mmu-valid-gen %u used_pages %x\",\n\t\t  __entry->mmu_valid_gen, __entry->mmu_used_pages\n\t)\n);\n\n\nTRACE_EVENT(\n\tcheck_mmio_spte,\n\tTP_PROTO(u64 spte, unsigned int kvm_gen, unsigned int spte_gen),\n\tTP_ARGS(spte, kvm_gen, spte_gen),\n\n\tTP_STRUCT__entry(\n\t\t__field(unsigned int, kvm_gen)\n\t\t__field(unsigned int, spte_gen)\n\t\t__field(u64, spte)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->kvm_gen = kvm_gen;\n\t\t__entry->spte_gen = spte_gen;\n\t\t__entry->spte = spte;\n\t),\n\n\tTP_printk(\"spte %llx kvm_gen %x spte-gen %x valid %d\", __entry->spte,\n\t\t  __entry->kvm_gen, __entry->spte_gen,\n\t\t  __entry->kvm_gen == __entry->spte_gen\n\t)\n);\n\nTRACE_EVENT(\n\tkvm_mmu_set_spte,\n\tTP_PROTO(int level, gfn_t gfn, u64 *sptep),\n\tTP_ARGS(level, gfn, sptep),\n\n\tTP_STRUCT__entry(\n\t\t__field(u64, gfn)\n\t\t__field(u64, spte)\n\t\t__field(u64, sptep)\n\t\t__field(u8, level)\n\t\t \n\t\t__field(bool, r)\n\t\t__field(bool, x)\n\t\t__field(signed char, u)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->gfn = gfn;\n\t\t__entry->spte = *sptep;\n\t\t__entry->sptep = virt_to_phys(sptep);\n\t\t__entry->level = level;\n\t\t__entry->r = shadow_present_mask || (__entry->spte & PT_PRESENT_MASK);\n\t\t__entry->x = is_executable_pte(__entry->spte);\n\t\t__entry->u = shadow_user_mask ? !!(__entry->spte & shadow_user_mask) : -1;\n\t),\n\n\tTP_printk(\"gfn %llx spte %llx (%s%s%s%s) level %d at %llx\",\n\t\t  __entry->gfn, __entry->spte,\n\t\t  __entry->r ? \"r\" : \"-\",\n\t\t  __entry->spte & PT_WRITABLE_MASK ? \"w\" : \"-\",\n\t\t  __entry->x ? \"x\" : \"-\",\n\t\t  __entry->u == -1 ? \"\" : (__entry->u ? \"u\" : \"-\"),\n\t\t  __entry->level, __entry->sptep\n\t)\n);\n\nTRACE_EVENT(\n\tkvm_mmu_spte_requested,\n\tTP_PROTO(struct kvm_page_fault *fault),\n\tTP_ARGS(fault),\n\n\tTP_STRUCT__entry(\n\t\t__field(u64, gfn)\n\t\t__field(u64, pfn)\n\t\t__field(u8, level)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->gfn = fault->gfn;\n\t\t__entry->pfn = fault->pfn | (fault->gfn & (KVM_PAGES_PER_HPAGE(fault->goal_level) - 1));\n\t\t__entry->level = fault->goal_level;\n\t),\n\n\tTP_printk(\"gfn %llx pfn %llx level %d\",\n\t\t  __entry->gfn, __entry->pfn, __entry->level\n\t)\n);\n\nTRACE_EVENT(\n\tkvm_tdp_mmu_spte_changed,\n\tTP_PROTO(int as_id, gfn_t gfn, int level, u64 old_spte, u64 new_spte),\n\tTP_ARGS(as_id, gfn, level, old_spte, new_spte),\n\n\tTP_STRUCT__entry(\n\t\t__field(u64, gfn)\n\t\t__field(u64, old_spte)\n\t\t__field(u64, new_spte)\n\t\t \n\t\t__field(u8, level)\n\t\t \n\t\t__field(u8, as_id)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->gfn = gfn;\n\t\t__entry->old_spte = old_spte;\n\t\t__entry->new_spte = new_spte;\n\t\t__entry->level = level;\n\t\t__entry->as_id = as_id;\n\t),\n\n\tTP_printk(\"as id %d gfn %llx level %d old_spte %llx new_spte %llx\",\n\t\t  __entry->as_id, __entry->gfn, __entry->level,\n\t\t  __entry->old_spte, __entry->new_spte\n\t)\n);\n\nTRACE_EVENT(\n\tkvm_mmu_split_huge_page,\n\tTP_PROTO(u64 gfn, u64 spte, int level, int errno),\n\tTP_ARGS(gfn, spte, level, errno),\n\n\tTP_STRUCT__entry(\n\t\t__field(u64, gfn)\n\t\t__field(u64, spte)\n\t\t__field(int, level)\n\t\t__field(int, errno)\n\t),\n\n\tTP_fast_assign(\n\t\t__entry->gfn = gfn;\n\t\t__entry->spte = spte;\n\t\t__entry->level = level;\n\t\t__entry->errno = errno;\n\t),\n\n\tTP_printk(\"gfn %llx spte %llx level %d errno %d\",\n\t\t  __entry->gfn, __entry->spte, __entry->level, __entry->errno)\n);\n\n#endif  \n\n#undef TRACE_INCLUDE_PATH\n#define TRACE_INCLUDE_PATH mmu\n#undef TRACE_INCLUDE_FILE\n#define TRACE_INCLUDE_FILE mmutrace\n\n \n#include <trace/define_trace.h>\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}