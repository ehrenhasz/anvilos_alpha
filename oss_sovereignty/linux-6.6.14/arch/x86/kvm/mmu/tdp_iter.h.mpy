{
  "module_name": "tdp_iter.h",
  "hash_id": "6647a7303804fe96e0ffc67b75e2ea9632d5a61721e6f3a19d133ed53a803d4e",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/kvm/mmu/tdp_iter.h",
  "human_readable_source": "\n\n#ifndef __KVM_X86_MMU_TDP_ITER_H\n#define __KVM_X86_MMU_TDP_ITER_H\n\n#include <linux/kvm_host.h>\n\n#include \"mmu.h\"\n#include \"spte.h\"\n\n \nstatic inline u64 kvm_tdp_mmu_read_spte(tdp_ptep_t sptep)\n{\n\treturn READ_ONCE(*rcu_dereference(sptep));\n}\n\nstatic inline u64 kvm_tdp_mmu_write_spte_atomic(tdp_ptep_t sptep, u64 new_spte)\n{\n\treturn xchg(rcu_dereference(sptep), new_spte);\n}\n\nstatic inline void __kvm_tdp_mmu_write_spte(tdp_ptep_t sptep, u64 new_spte)\n{\n\tWRITE_ONCE(*rcu_dereference(sptep), new_spte);\n}\n\n \nstatic inline bool kvm_tdp_mmu_spte_need_atomic_write(u64 old_spte, int level)\n{\n\treturn is_shadow_present_pte(old_spte) &&\n\t       is_last_spte(old_spte, level) &&\n\t       spte_has_volatile_bits(old_spte);\n}\n\nstatic inline u64 kvm_tdp_mmu_write_spte(tdp_ptep_t sptep, u64 old_spte,\n\t\t\t\t\t u64 new_spte, int level)\n{\n\tif (kvm_tdp_mmu_spte_need_atomic_write(old_spte, level))\n\t\treturn kvm_tdp_mmu_write_spte_atomic(sptep, new_spte);\n\n\t__kvm_tdp_mmu_write_spte(sptep, new_spte);\n\treturn old_spte;\n}\n\nstatic inline u64 tdp_mmu_clear_spte_bits(tdp_ptep_t sptep, u64 old_spte,\n\t\t\t\t\t  u64 mask, int level)\n{\n\tatomic64_t *sptep_atomic;\n\n\tif (kvm_tdp_mmu_spte_need_atomic_write(old_spte, level)) {\n\t\tsptep_atomic = (atomic64_t *)rcu_dereference(sptep);\n\t\treturn (u64)atomic64_fetch_and(~mask, sptep_atomic);\n\t}\n\n\t__kvm_tdp_mmu_write_spte(sptep, old_spte & ~mask);\n\treturn old_spte;\n}\n\n \nstruct tdp_iter {\n\t \n\tgfn_t next_last_level_gfn;\n\t \n\tgfn_t yielded_gfn;\n\t \n\ttdp_ptep_t pt_path[PT64_ROOT_MAX_LEVEL];\n\t \n\ttdp_ptep_t sptep;\n\t \n\tgfn_t gfn;\n\t \n\tint root_level;\n\t \n\tint min_level;\n\t \n\tint level;\n\t \n\tint as_id;\n\t \n\tu64 old_spte;\n\t \n\tbool valid;\n\t \n\tbool yielded;\n};\n\n \n#define for_each_tdp_pte_min_level(iter, root, min_level, start, end) \\\n\tfor (tdp_iter_start(&iter, root, min_level, start); \\\n\t     iter.valid && iter.gfn < end;\t\t     \\\n\t     tdp_iter_next(&iter))\n\n#define for_each_tdp_pte(iter, root, start, end) \\\n\tfor_each_tdp_pte_min_level(iter, root, PG_LEVEL_4K, start, end)\n\ntdp_ptep_t spte_to_child_pt(u64 pte, int level);\n\nvoid tdp_iter_start(struct tdp_iter *iter, struct kvm_mmu_page *root,\n\t\t    int min_level, gfn_t next_last_level_gfn);\nvoid tdp_iter_next(struct tdp_iter *iter);\nvoid tdp_iter_restart(struct tdp_iter *iter);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}