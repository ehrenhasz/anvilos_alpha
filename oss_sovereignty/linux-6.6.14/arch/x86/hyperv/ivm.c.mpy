{
  "module_name": "ivm.c",
  "hash_id": "b85916415f825bbf92bf842cdc02c70584b274faa0efcb392ffbcc62a3b162e6",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/hyperv/ivm.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/hyperv.h>\n#include <linux/types.h>\n#include <linux/slab.h>\n#include <asm/svm.h>\n#include <asm/sev.h>\n#include <asm/io.h>\n#include <asm/coco.h>\n#include <asm/mem_encrypt.h>\n#include <asm/mshyperv.h>\n#include <asm/hypervisor.h>\n#include <asm/mtrr.h>\n#include <asm/io_apic.h>\n#include <asm/realmode.h>\n#include <asm/e820/api.h>\n#include <asm/desc.h>\n#include <uapi/asm/vmx.h>\n\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\n#define GHCB_USAGE_HYPERV_CALL\t1\n\nunion hv_ghcb {\n\tstruct ghcb ghcb;\n\tstruct {\n\t\tu64 hypercalldata[509];\n\t\tu64 outputgpa;\n\t\tunion {\n\t\t\tunion {\n\t\t\t\tstruct {\n\t\t\t\t\tu32 callcode        : 16;\n\t\t\t\t\tu32 isfast          : 1;\n\t\t\t\t\tu32 reserved1       : 14;\n\t\t\t\t\tu32 isnested        : 1;\n\t\t\t\t\tu32 countofelements : 12;\n\t\t\t\t\tu32 reserved2       : 4;\n\t\t\t\t\tu32 repstartindex   : 12;\n\t\t\t\t\tu32 reserved3       : 4;\n\t\t\t\t};\n\t\t\t\tu64 asuint64;\n\t\t\t} hypercallinput;\n\t\t\tunion {\n\t\t\t\tstruct {\n\t\t\t\t\tu16 callstatus;\n\t\t\t\t\tu16 reserved1;\n\t\t\t\t\tu32 elementsprocessed : 12;\n\t\t\t\t\tu32 reserved2         : 20;\n\t\t\t\t};\n\t\t\t\tu64 asunit64;\n\t\t\t} hypercalloutput;\n\t\t};\n\t\tu64 reserved2;\n\t} hypercall;\n} __packed __aligned(HV_HYP_PAGE_SIZE);\n\n \nstatic u16 hv_ghcb_version __ro_after_init;\n\n \nu64 hv_ghcb_hypercall(u64 control, void *input, void *output, u32 input_size)\n{\n\tunion hv_ghcb *hv_ghcb;\n\tvoid **ghcb_base;\n\tunsigned long flags;\n\tu64 status;\n\n\tif (!hv_ghcb_pg)\n\t\treturn -EFAULT;\n\n\tWARN_ON(in_nmi());\n\n\tlocal_irq_save(flags);\n\tghcb_base = (void **)this_cpu_ptr(hv_ghcb_pg);\n\thv_ghcb = (union hv_ghcb *)*ghcb_base;\n\tif (!hv_ghcb) {\n\t\tlocal_irq_restore(flags);\n\t\treturn -EFAULT;\n\t}\n\n\thv_ghcb->ghcb.protocol_version = GHCB_PROTOCOL_MAX;\n\thv_ghcb->ghcb.ghcb_usage = GHCB_USAGE_HYPERV_CALL;\n\n\thv_ghcb->hypercall.outputgpa = (u64)output;\n\thv_ghcb->hypercall.hypercallinput.asuint64 = 0;\n\thv_ghcb->hypercall.hypercallinput.callcode = control;\n\n\tif (input_size)\n\t\tmemcpy(hv_ghcb->hypercall.hypercalldata, input, input_size);\n\n\tVMGEXIT();\n\n\thv_ghcb->ghcb.ghcb_usage = 0xffffffff;\n\tmemset(hv_ghcb->ghcb.save.valid_bitmap, 0,\n\t       sizeof(hv_ghcb->ghcb.save.valid_bitmap));\n\n\tstatus = hv_ghcb->hypercall.hypercalloutput.callstatus;\n\n\tlocal_irq_restore(flags);\n\n\treturn status;\n}\n\nstatic inline u64 rd_ghcb_msr(void)\n{\n\treturn __rdmsr(MSR_AMD64_SEV_ES_GHCB);\n}\n\nstatic inline void wr_ghcb_msr(u64 val)\n{\n\tnative_wrmsrl(MSR_AMD64_SEV_ES_GHCB, val);\n}\n\nstatic enum es_result hv_ghcb_hv_call(struct ghcb *ghcb, u64 exit_code,\n\t\t\t\t   u64 exit_info_1, u64 exit_info_2)\n{\n\t \n\tghcb->protocol_version = hv_ghcb_version;\n\tghcb->ghcb_usage       = GHCB_DEFAULT_USAGE;\n\n\tghcb_set_sw_exit_code(ghcb, exit_code);\n\tghcb_set_sw_exit_info_1(ghcb, exit_info_1);\n\tghcb_set_sw_exit_info_2(ghcb, exit_info_2);\n\n\tVMGEXIT();\n\n\tif (ghcb->save.sw_exit_info_1 & GENMASK_ULL(31, 0))\n\t\treturn ES_VMM_ERROR;\n\telse\n\t\treturn ES_OK;\n}\n\nvoid __noreturn hv_ghcb_terminate(unsigned int set, unsigned int reason)\n{\n\tu64 val = GHCB_MSR_TERM_REQ;\n\n\t \n\tval |= GHCB_SEV_TERM_REASON(set, reason);\n\n\t \n\twr_ghcb_msr(val);\n\tVMGEXIT();\n\n\twhile (true)\n\t\tasm volatile(\"hlt\\n\" : : : \"memory\");\n}\n\nbool hv_ghcb_negotiate_protocol(void)\n{\n\tu64 ghcb_gpa;\n\tu64 val;\n\n\t \n\tghcb_gpa = rd_ghcb_msr();\n\n\t \n\twr_ghcb_msr(GHCB_MSR_SEV_INFO_REQ);\n\tVMGEXIT();\n\tval = rd_ghcb_msr();\n\n\tif (GHCB_MSR_INFO(val) != GHCB_MSR_SEV_INFO_RESP)\n\t\treturn false;\n\n\tif (GHCB_MSR_PROTO_MAX(val) < GHCB_PROTOCOL_MIN ||\n\t    GHCB_MSR_PROTO_MIN(val) > GHCB_PROTOCOL_MAX)\n\t\treturn false;\n\n\thv_ghcb_version = min_t(size_t, GHCB_MSR_PROTO_MAX(val),\n\t\t\t     GHCB_PROTOCOL_MAX);\n\n\t \n\twr_ghcb_msr(ghcb_gpa);\n\tVMGEXIT();\n\n\treturn true;\n}\n\nstatic void hv_ghcb_msr_write(u64 msr, u64 value)\n{\n\tunion hv_ghcb *hv_ghcb;\n\tvoid **ghcb_base;\n\tunsigned long flags;\n\n\tif (!hv_ghcb_pg)\n\t\treturn;\n\n\tWARN_ON(in_nmi());\n\n\tlocal_irq_save(flags);\n\tghcb_base = (void **)this_cpu_ptr(hv_ghcb_pg);\n\thv_ghcb = (union hv_ghcb *)*ghcb_base;\n\tif (!hv_ghcb) {\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\n\tghcb_set_rcx(&hv_ghcb->ghcb, msr);\n\tghcb_set_rax(&hv_ghcb->ghcb, lower_32_bits(value));\n\tghcb_set_rdx(&hv_ghcb->ghcb, upper_32_bits(value));\n\n\tif (hv_ghcb_hv_call(&hv_ghcb->ghcb, SVM_EXIT_MSR, 1, 0))\n\t\tpr_warn(\"Fail to write msr via ghcb %llx.\\n\", msr);\n\n\tlocal_irq_restore(flags);\n}\n\nstatic void hv_ghcb_msr_read(u64 msr, u64 *value)\n{\n\tunion hv_ghcb *hv_ghcb;\n\tvoid **ghcb_base;\n\tunsigned long flags;\n\n\t \n\tBUILD_BUG_ON(sizeof(union hv_ghcb) != HV_HYP_PAGE_SIZE);\n\n\tif (!hv_ghcb_pg)\n\t\treturn;\n\n\tWARN_ON(in_nmi());\n\n\tlocal_irq_save(flags);\n\tghcb_base = (void **)this_cpu_ptr(hv_ghcb_pg);\n\thv_ghcb = (union hv_ghcb *)*ghcb_base;\n\tif (!hv_ghcb) {\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\n\tghcb_set_rcx(&hv_ghcb->ghcb, msr);\n\tif (hv_ghcb_hv_call(&hv_ghcb->ghcb, SVM_EXIT_MSR, 0, 0))\n\t\tpr_warn(\"Fail to read msr via ghcb %llx.\\n\", msr);\n\telse\n\t\t*value = (u64)lower_32_bits(hv_ghcb->ghcb.save.rax)\n\t\t\t| ((u64)lower_32_bits(hv_ghcb->ghcb.save.rdx) << 32);\n\tlocal_irq_restore(flags);\n}\n\n \nstatic u8 ap_start_input_arg[PAGE_SIZE] __bss_decrypted __aligned(PAGE_SIZE);\nstatic u8 ap_start_stack[PAGE_SIZE] __aligned(PAGE_SIZE);\nstatic DEFINE_PER_CPU(struct sev_es_save_area *, hv_sev_vmsa);\n\n \n\n#define hv_populate_vmcb_seg(seg, gdtr_base)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tif (seg.selector) {\t\t\t\t\t\\\n\t\tseg.base = 0;\t\t\t\t\t\\\n\t\tseg.limit = HV_AP_SEGMENT_LIMIT;\t\t\\\n\t\tseg.attrib = *(u16 *)(gdtr_base + seg.selector + 5);\t\\\n\t\tseg.attrib = (seg.attrib & 0xFF) | ((seg.attrib >> 4) & 0xF00); \\\n\t}\t\t\t\t\t\t\t\\\n} while (0)\t\t\t\t\t\t\t\\\n\nstatic int snp_set_vmsa(void *va, bool vmsa)\n{\n\tu64 attrs;\n\n\t \n\tattrs = 1;\n\tif (vmsa)\n\t\tattrs |= RMPADJUST_VMSA_PAGE_BIT;\n\n\treturn rmpadjust((unsigned long)va, RMP_PG_SIZE_4K, attrs);\n}\n\nstatic void snp_cleanup_vmsa(struct sev_es_save_area *vmsa)\n{\n\tint err;\n\n\terr = snp_set_vmsa(vmsa, false);\n\tif (err)\n\t\tpr_err(\"clear VMSA page failed (%u), leaking page\\n\", err);\n\telse\n\t\tfree_page((unsigned long)vmsa);\n}\n\nint hv_snp_boot_ap(int cpu, unsigned long start_ip)\n{\n\tstruct sev_es_save_area *vmsa = (struct sev_es_save_area *)\n\t\t__get_free_page(GFP_KERNEL | __GFP_ZERO);\n\tstruct sev_es_save_area *cur_vmsa;\n\tstruct desc_ptr gdtr;\n\tu64 ret, retry = 5;\n\tstruct hv_enable_vp_vtl *start_vp_input;\n\tunsigned long flags;\n\n\tif (!vmsa)\n\t\treturn -ENOMEM;\n\n\tnative_store_gdt(&gdtr);\n\n\tvmsa->gdtr.base = gdtr.address;\n\tvmsa->gdtr.limit = gdtr.size;\n\n\tasm volatile(\"movl %%es, %%eax;\" : \"=a\" (vmsa->es.selector));\n\thv_populate_vmcb_seg(vmsa->es, vmsa->gdtr.base);\n\n\tasm volatile(\"movl %%cs, %%eax;\" : \"=a\" (vmsa->cs.selector));\n\thv_populate_vmcb_seg(vmsa->cs, vmsa->gdtr.base);\n\n\tasm volatile(\"movl %%ss, %%eax;\" : \"=a\" (vmsa->ss.selector));\n\thv_populate_vmcb_seg(vmsa->ss, vmsa->gdtr.base);\n\n\tasm volatile(\"movl %%ds, %%eax;\" : \"=a\" (vmsa->ds.selector));\n\thv_populate_vmcb_seg(vmsa->ds, vmsa->gdtr.base);\n\n\tvmsa->efer = native_read_msr(MSR_EFER);\n\n\tasm volatile(\"movq %%cr4, %%rax;\" : \"=a\" (vmsa->cr4));\n\tasm volatile(\"movq %%cr3, %%rax;\" : \"=a\" (vmsa->cr3));\n\tasm volatile(\"movq %%cr0, %%rax;\" : \"=a\" (vmsa->cr0));\n\n\tvmsa->xcr0 = 1;\n\tvmsa->g_pat = HV_AP_INIT_GPAT_DEFAULT;\n\tvmsa->rip = (u64)secondary_startup_64_no_verify;\n\tvmsa->rsp = (u64)&ap_start_stack[PAGE_SIZE];\n\n\t \n\tvmsa->vmpl = 0;\n\tvmsa->sev_features = sev_status >> 2;\n\n\tret = snp_set_vmsa(vmsa, true);\n\tif (!ret) {\n\t\tpr_err(\"RMPADJUST(%llx) failed: %llx\\n\", (u64)vmsa, ret);\n\t\tfree_page((u64)vmsa);\n\t\treturn ret;\n\t}\n\n\tlocal_irq_save(flags);\n\tstart_vp_input = (struct hv_enable_vp_vtl *)ap_start_input_arg;\n\tmemset(start_vp_input, 0, sizeof(*start_vp_input));\n\tstart_vp_input->partition_id = -1;\n\tstart_vp_input->vp_index = cpu;\n\tstart_vp_input->target_vtl.target_vtl = ms_hyperv.vtl;\n\t*(u64 *)&start_vp_input->vp_context = __pa(vmsa) | 1;\n\n\tdo {\n\t\tret = hv_do_hypercall(HVCALL_START_VP,\n\t\t\t\t      start_vp_input, NULL);\n\t} while (hv_result(ret) == HV_STATUS_TIME_OUT && retry--);\n\n\tlocal_irq_restore(flags);\n\n\tif (!hv_result_success(ret)) {\n\t\tpr_err(\"HvCallStartVirtualProcessor failed: %llx\\n\", ret);\n\t\tsnp_cleanup_vmsa(vmsa);\n\t\tvmsa = NULL;\n\t}\n\n\tcur_vmsa = per_cpu(hv_sev_vmsa, cpu);\n\t \n\tif (cur_vmsa)\n\t\tsnp_cleanup_vmsa(cur_vmsa);\n\n\t \n\tper_cpu(hv_sev_vmsa, cpu) = vmsa;\n\n\treturn ret;\n}\n\n#else\nstatic inline void hv_ghcb_msr_write(u64 msr, u64 value) {}\nstatic inline void hv_ghcb_msr_read(u64 msr, u64 *value) {}\n#endif  \n\n#ifdef CONFIG_INTEL_TDX_GUEST\nstatic void hv_tdx_msr_write(u64 msr, u64 val)\n{\n\tstruct tdx_hypercall_args args = {\n\t\t.r10 = TDX_HYPERCALL_STANDARD,\n\t\t.r11 = EXIT_REASON_MSR_WRITE,\n\t\t.r12 = msr,\n\t\t.r13 = val,\n\t};\n\n\tu64 ret = __tdx_hypercall(&args);\n\n\tWARN_ONCE(ret, \"Failed to emulate MSR write: %lld\\n\", ret);\n}\n\nstatic void hv_tdx_msr_read(u64 msr, u64 *val)\n{\n\tstruct tdx_hypercall_args args = {\n\t\t.r10 = TDX_HYPERCALL_STANDARD,\n\t\t.r11 = EXIT_REASON_MSR_READ,\n\t\t.r12 = msr,\n\t};\n\n\tu64 ret = __tdx_hypercall_ret(&args);\n\n\tif (WARN_ONCE(ret, \"Failed to emulate MSR read: %lld\\n\", ret))\n\t\t*val = 0;\n\telse\n\t\t*val = args.r11;\n}\n\nu64 hv_tdx_hypercall(u64 control, u64 param1, u64 param2)\n{\n\tstruct tdx_hypercall_args args = { };\n\n\targs.r10 = control;\n\targs.rdx = param1;\n\targs.r8  = param2;\n\n\t(void)__tdx_hypercall_ret(&args);\n\n\treturn args.r11;\n}\n\n#else\nstatic inline void hv_tdx_msr_write(u64 msr, u64 value) {}\nstatic inline void hv_tdx_msr_read(u64 msr, u64 *value) {}\n#endif  \n\n#if defined(CONFIG_AMD_MEM_ENCRYPT) || defined(CONFIG_INTEL_TDX_GUEST)\nvoid hv_ivm_msr_write(u64 msr, u64 value)\n{\n\tif (!ms_hyperv.paravisor_present)\n\t\treturn;\n\n\tif (hv_isolation_type_tdx())\n\t\thv_tdx_msr_write(msr, value);\n\telse if (hv_isolation_type_snp())\n\t\thv_ghcb_msr_write(msr, value);\n}\n\nvoid hv_ivm_msr_read(u64 msr, u64 *value)\n{\n\tif (!ms_hyperv.paravisor_present)\n\t\treturn;\n\n\tif (hv_isolation_type_tdx())\n\t\thv_tdx_msr_read(msr, value);\n\telse if (hv_isolation_type_snp())\n\t\thv_ghcb_msr_read(msr, value);\n}\n\n \nstatic int hv_mark_gpa_visibility(u16 count, const u64 pfn[],\n\t\t\t   enum hv_mem_host_visibility visibility)\n{\n\tstruct hv_gpa_range_for_visibility *input;\n\tu16 pages_processed;\n\tu64 hv_status;\n\tunsigned long flags;\n\n\t \n\tif (!hv_is_isolation_supported())\n\t\treturn 0;\n\n\tif (count > HV_MAX_MODIFY_GPA_REP_COUNT) {\n\t\tpr_err(\"Hyper-V: GPA count:%d exceeds supported:%lu\\n\", count,\n\t\t\tHV_MAX_MODIFY_GPA_REP_COUNT);\n\t\treturn -EINVAL;\n\t}\n\n\tlocal_irq_save(flags);\n\tinput = *this_cpu_ptr(hyperv_pcpu_input_arg);\n\n\tif (unlikely(!input)) {\n\t\tlocal_irq_restore(flags);\n\t\treturn -EINVAL;\n\t}\n\n\tinput->partition_id = HV_PARTITION_ID_SELF;\n\tinput->host_visibility = visibility;\n\tinput->reserved0 = 0;\n\tinput->reserved1 = 0;\n\tmemcpy((void *)input->gpa_page_list, pfn, count * sizeof(*pfn));\n\thv_status = hv_do_rep_hypercall(\n\t\t\tHVCALL_MODIFY_SPARSE_GPA_PAGE_HOST_VISIBILITY, count,\n\t\t\t0, input, &pages_processed);\n\tlocal_irq_restore(flags);\n\n\tif (hv_result_success(hv_status))\n\t\treturn 0;\n\telse\n\t\treturn -EFAULT;\n}\n\n \nstatic bool hv_vtom_set_host_visibility(unsigned long kbuffer, int pagecount, bool enc)\n{\n\tenum hv_mem_host_visibility visibility = enc ?\n\t\t\tVMBUS_PAGE_NOT_VISIBLE : VMBUS_PAGE_VISIBLE_READ_WRITE;\n\tu64 *pfn_array;\n\tint ret = 0;\n\tbool result = true;\n\tint i, pfn;\n\n\tpfn_array = kmalloc(HV_HYP_PAGE_SIZE, GFP_KERNEL);\n\tif (!pfn_array)\n\t\treturn false;\n\n\tfor (i = 0, pfn = 0; i < pagecount; i++) {\n\t\tpfn_array[pfn] = virt_to_hvpfn((void *)kbuffer + i * HV_HYP_PAGE_SIZE);\n\t\tpfn++;\n\n\t\tif (pfn == HV_MAX_MODIFY_GPA_REP_COUNT || i == pagecount - 1) {\n\t\t\tret = hv_mark_gpa_visibility(pfn, pfn_array,\n\t\t\t\t\t\t     visibility);\n\t\t\tif (ret) {\n\t\t\t\tresult = false;\n\t\t\t\tgoto err_free_pfn_array;\n\t\t\t}\n\t\t\tpfn = 0;\n\t\t}\n\t}\n\n err_free_pfn_array:\n\tkfree(pfn_array);\n\treturn result;\n}\n\nstatic bool hv_vtom_tlb_flush_required(bool private)\n{\n\treturn true;\n}\n\nstatic bool hv_vtom_cache_flush_required(void)\n{\n\treturn false;\n}\n\nstatic bool hv_is_private_mmio(u64 addr)\n{\n\t \n\tif (addr >= HV_IOAPIC_BASE_ADDRESS &&\n\t    addr < (HV_IOAPIC_BASE_ADDRESS + PAGE_SIZE))\n\t\treturn true;\n\n\t \n\tif (addr >= VTPM_BASE_ADDRESS &&\n\t    addr < (VTPM_BASE_ADDRESS + PAGE_SIZE))\n\t\treturn true;\n\n\treturn false;\n}\n\nvoid __init hv_vtom_init(void)\n{\n\tenum hv_isolation_type type = hv_get_isolation_type();\n\n\tswitch (type) {\n\tcase HV_ISOLATION_TYPE_VBS:\n\t\tfallthrough;\n\t \n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\tcase HV_ISOLATION_TYPE_SNP:\n\t\tsev_status = MSR_AMD64_SNP_VTOM;\n\t\tcc_vendor = CC_VENDOR_AMD;\n\t\tbreak;\n#endif\n\n\tcase HV_ISOLATION_TYPE_TDX:\n\t\tcc_vendor = CC_VENDOR_INTEL;\n\t\tbreak;\n\n\tdefault:\n\t\tpanic(\"hv_vtom_init: unsupported isolation type %d\\n\", type);\n\t}\n\n\tcc_set_mask(ms_hyperv.shared_gpa_boundary);\n\tphysical_mask &= ms_hyperv.shared_gpa_boundary - 1;\n\n\tx86_platform.hyper.is_private_mmio = hv_is_private_mmio;\n\tx86_platform.guest.enc_cache_flush_required = hv_vtom_cache_flush_required;\n\tx86_platform.guest.enc_tlb_flush_required = hv_vtom_tlb_flush_required;\n\tx86_platform.guest.enc_status_change_finish = hv_vtom_set_host_visibility;\n\n\t \n\tmtrr_overwrite_state(NULL, 0, MTRR_TYPE_WRBACK);\n}\n\n#endif  \n\nenum hv_isolation_type hv_get_isolation_type(void)\n{\n\tif (!(ms_hyperv.priv_high & HV_ISOLATION))\n\t\treturn HV_ISOLATION_TYPE_NONE;\n\treturn FIELD_GET(HV_ISOLATION_TYPE, ms_hyperv.isolation_config_b);\n}\nEXPORT_SYMBOL_GPL(hv_get_isolation_type);\n\n \nbool hv_is_isolation_supported(void)\n{\n\tif (!cpu_feature_enabled(X86_FEATURE_HYPERVISOR))\n\t\treturn false;\n\n\tif (!hypervisor_is_type(X86_HYPER_MS_HYPERV))\n\t\treturn false;\n\n\treturn hv_get_isolation_type() != HV_ISOLATION_TYPE_NONE;\n}\n\nDEFINE_STATIC_KEY_FALSE(isolation_type_snp);\n\n \nbool hv_isolation_type_snp(void)\n{\n\treturn static_branch_unlikely(&isolation_type_snp);\n}\n\nDEFINE_STATIC_KEY_FALSE(isolation_type_tdx);\n \nbool hv_isolation_type_tdx(void)\n{\n\treturn static_branch_unlikely(&isolation_type_tdx);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}