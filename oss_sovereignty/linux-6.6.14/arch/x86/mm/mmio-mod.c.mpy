{
  "module_name": "mmio-mod.c",
  "hash_id": "37fb9cce6666b77dfa20401a6b0fac93ada590bd10192dafa663b1638bec1078",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/mm/mmio-mod.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"mmiotrace: \" fmt\n\n#include <linux/moduleparam.h>\n#include <linux/debugfs.h>\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/io.h>\n#include <linux/mmiotrace.h>\n#include <linux/pgtable.h>\n#include <asm/e820/api.h>  \n#include <linux/atomic.h>\n#include <linux/percpu.h>\n#include <linux/cpu.h>\n\n#include \"pf_in.h\"\n\nstruct trap_reason {\n\tunsigned long addr;\n\tunsigned long ip;\n\tenum reason_type type;\n\tint active_traces;\n};\n\nstruct remap_trace {\n\tstruct list_head list;\n\tstruct kmmio_probe probe;\n\tresource_size_t phys;\n\tunsigned long id;\n};\n\n \nstatic DEFINE_PER_CPU(struct trap_reason, pf_reason);\nstatic DEFINE_PER_CPU(struct mmiotrace_rw, cpu_trace);\n\nstatic DEFINE_MUTEX(mmiotrace_mutex);\nstatic DEFINE_SPINLOCK(trace_lock);\nstatic atomic_t mmiotrace_enabled;\nstatic LIST_HEAD(trace_list);\t\t \n\n \n\n \nstatic unsigned long\tfilter_offset;\nstatic bool\t\tnommiotrace;\nstatic bool\t\ttrace_pc;\n\nmodule_param(filter_offset, ulong, 0);\nmodule_param(nommiotrace, bool, 0);\nmodule_param(trace_pc, bool, 0);\n\nMODULE_PARM_DESC(filter_offset, \"Start address of traced mappings.\");\nMODULE_PARM_DESC(nommiotrace, \"Disable actual MMIO tracing.\");\nMODULE_PARM_DESC(trace_pc, \"Record address of faulting instructions.\");\n\nstatic bool is_enabled(void)\n{\n\treturn atomic_read(&mmiotrace_enabled);\n}\n\nstatic void print_pte(unsigned long address)\n{\n\tunsigned int level;\n\tpte_t *pte = lookup_address(address, &level);\n\n\tif (!pte) {\n\t\tpr_err(\"Error in %s: no pte for page 0x%08lx\\n\",\n\t\t       __func__, address);\n\t\treturn;\n\t}\n\n\tif (level == PG_LEVEL_2M) {\n\t\tpr_emerg(\"4MB pages are not currently supported: 0x%08lx\\n\",\n\t\t\t address);\n\t\tBUG();\n\t}\n\tpr_info(\"pte for 0x%lx: 0x%llx 0x%llx\\n\",\n\t\taddress,\n\t\t(unsigned long long)pte_val(*pte),\n\t\t(unsigned long long)pte_val(*pte) & _PAGE_PRESENT);\n}\n\n \nstatic void die_kmmio_nesting_error(struct pt_regs *regs, unsigned long addr)\n{\n\tconst struct trap_reason *my_reason = &get_cpu_var(pf_reason);\n\tpr_emerg(\"unexpected fault for address: 0x%08lx, last fault for address: 0x%08lx\\n\",\n\t\t addr, my_reason->addr);\n\tprint_pte(addr);\n\tpr_emerg(\"faulting IP is at %pS\\n\", (void *)regs->ip);\n\tpr_emerg(\"last faulting IP was at %pS\\n\", (void *)my_reason->ip);\n#ifdef __i386__\n\tpr_emerg(\"eax: %08lx   ebx: %08lx   ecx: %08lx   edx: %08lx\\n\",\n\t\t regs->ax, regs->bx, regs->cx, regs->dx);\n\tpr_emerg(\"esi: %08lx   edi: %08lx   ebp: %08lx   esp: %08lx\\n\",\n\t\t regs->si, regs->di, regs->bp, regs->sp);\n#else\n\tpr_emerg(\"rax: %016lx   rcx: %016lx   rdx: %016lx\\n\",\n\t\t regs->ax, regs->cx, regs->dx);\n\tpr_emerg(\"rsi: %016lx   rdi: %016lx   rbp: %016lx   rsp: %016lx\\n\",\n\t\t regs->si, regs->di, regs->bp, regs->sp);\n#endif\n\tput_cpu_var(pf_reason);\n\tBUG();\n}\n\nstatic void pre(struct kmmio_probe *p, struct pt_regs *regs,\n\t\t\t\t\t\tunsigned long addr)\n{\n\tstruct trap_reason *my_reason = &get_cpu_var(pf_reason);\n\tstruct mmiotrace_rw *my_trace = &get_cpu_var(cpu_trace);\n\tconst unsigned long instptr = instruction_pointer(regs);\n\tconst enum reason_type type = get_ins_type(instptr);\n\tstruct remap_trace *trace = p->private;\n\n\t \n\tif (my_reason->active_traces)\n\t\tdie_kmmio_nesting_error(regs, addr);\n\telse\n\t\tmy_reason->active_traces++;\n\n\tmy_reason->type = type;\n\tmy_reason->addr = addr;\n\tmy_reason->ip = instptr;\n\n\tmy_trace->phys = addr - trace->probe.addr + trace->phys;\n\tmy_trace->map_id = trace->id;\n\n\t \n\tif (trace_pc)\n\t\tmy_trace->pc = instptr;\n\telse\n\t\tmy_trace->pc = 0;\n\n\t \n\n\tswitch (type) {\n\tcase REG_READ:\n\t\tmy_trace->opcode = MMIO_READ;\n\t\tmy_trace->width = get_ins_mem_width(instptr);\n\t\tbreak;\n\tcase REG_WRITE:\n\t\tmy_trace->opcode = MMIO_WRITE;\n\t\tmy_trace->width = get_ins_mem_width(instptr);\n\t\tmy_trace->value = get_ins_reg_val(instptr, regs);\n\t\tbreak;\n\tcase IMM_WRITE:\n\t\tmy_trace->opcode = MMIO_WRITE;\n\t\tmy_trace->width = get_ins_mem_width(instptr);\n\t\tmy_trace->value = get_ins_imm_val(instptr);\n\t\tbreak;\n\tdefault:\n\t\t{\n\t\t\tunsigned char *ip = (unsigned char *)instptr;\n\t\t\tmy_trace->opcode = MMIO_UNKNOWN_OP;\n\t\t\tmy_trace->width = 0;\n\t\t\tmy_trace->value = (*ip) << 16 | *(ip + 1) << 8 |\n\t\t\t\t\t\t\t\t*(ip + 2);\n\t\t}\n\t}\n\tput_cpu_var(cpu_trace);\n\tput_cpu_var(pf_reason);\n}\n\nstatic void post(struct kmmio_probe *p, unsigned long condition,\n\t\t\t\t\t\t\tstruct pt_regs *regs)\n{\n\tstruct trap_reason *my_reason = &get_cpu_var(pf_reason);\n\tstruct mmiotrace_rw *my_trace = &get_cpu_var(cpu_trace);\n\n\t \n\tmy_reason->active_traces--;\n\tif (my_reason->active_traces) {\n\t\tpr_emerg(\"unexpected post handler\");\n\t\tBUG();\n\t}\n\n\tswitch (my_reason->type) {\n\tcase REG_READ:\n\t\tmy_trace->value = get_ins_reg_val(my_reason->ip, regs);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tmmio_trace_rw(my_trace);\n\tput_cpu_var(cpu_trace);\n\tput_cpu_var(pf_reason);\n}\n\nstatic void ioremap_trace_core(resource_size_t offset, unsigned long size,\n\t\t\t\t\t\t\tvoid __iomem *addr)\n{\n\tstatic atomic_t next_id;\n\tstruct remap_trace *trace = kmalloc(sizeof(*trace), GFP_KERNEL);\n\t \n\tstruct mmiotrace_map map = {\n\t\t.phys = offset,\n\t\t.virt = (unsigned long)addr,\n\t\t.len = size,\n\t\t.opcode = MMIO_PROBE\n\t};\n\n\tif (!trace) {\n\t\tpr_err(\"kmalloc failed in ioremap\\n\");\n\t\treturn;\n\t}\n\n\t*trace = (struct remap_trace) {\n\t\t.probe = {\n\t\t\t.addr = (unsigned long)addr,\n\t\t\t.len = size,\n\t\t\t.pre_handler = pre,\n\t\t\t.post_handler = post,\n\t\t\t.private = trace\n\t\t},\n\t\t.phys = offset,\n\t\t.id = atomic_inc_return(&next_id)\n\t};\n\tmap.map_id = trace->id;\n\n\tspin_lock_irq(&trace_lock);\n\tif (!is_enabled()) {\n\t\tkfree(trace);\n\t\tgoto not_enabled;\n\t}\n\n\tmmio_trace_mapping(&map);\n\tlist_add_tail(&trace->list, &trace_list);\n\tif (!nommiotrace)\n\t\tregister_kmmio_probe(&trace->probe);\n\nnot_enabled:\n\tspin_unlock_irq(&trace_lock);\n}\n\nvoid mmiotrace_ioremap(resource_size_t offset, unsigned long size,\n\t\t\t\t\t\tvoid __iomem *addr)\n{\n\tif (!is_enabled())  \n\t\treturn;\n\n\tpr_debug(\"ioremap_*(0x%llx, 0x%lx) = %p\\n\",\n\t\t (unsigned long long)offset, size, addr);\n\tif ((filter_offset) && (offset != filter_offset))\n\t\treturn;\n\tioremap_trace_core(offset, size, addr);\n}\n\nstatic void iounmap_trace_core(volatile void __iomem *addr)\n{\n\tstruct mmiotrace_map map = {\n\t\t.phys = 0,\n\t\t.virt = (unsigned long)addr,\n\t\t.len = 0,\n\t\t.opcode = MMIO_UNPROBE\n\t};\n\tstruct remap_trace *trace;\n\tstruct remap_trace *tmp;\n\tstruct remap_trace *found_trace = NULL;\n\n\tpr_debug(\"Unmapping %p.\\n\", addr);\n\n\tspin_lock_irq(&trace_lock);\n\tif (!is_enabled())\n\t\tgoto not_enabled;\n\n\tlist_for_each_entry_safe(trace, tmp, &trace_list, list) {\n\t\tif ((unsigned long)addr == trace->probe.addr) {\n\t\t\tif (!nommiotrace)\n\t\t\t\tunregister_kmmio_probe(&trace->probe);\n\t\t\tlist_del(&trace->list);\n\t\t\tfound_trace = trace;\n\t\t\tbreak;\n\t\t}\n\t}\n\tmap.map_id = (found_trace) ? found_trace->id : -1;\n\tmmio_trace_mapping(&map);\n\nnot_enabled:\n\tspin_unlock_irq(&trace_lock);\n\tif (found_trace) {\n\t\tsynchronize_rcu();  \n\t\tkfree(found_trace);\n\t}\n}\n\nvoid mmiotrace_iounmap(volatile void __iomem *addr)\n{\n\tmight_sleep();\n\tif (is_enabled())  \n\t\tiounmap_trace_core(addr);\n}\n\nint mmiotrace_printk(const char *fmt, ...)\n{\n\tint ret = 0;\n\tva_list args;\n\tunsigned long flags;\n\tva_start(args, fmt);\n\n\tspin_lock_irqsave(&trace_lock, flags);\n\tif (is_enabled())\n\t\tret = mmio_trace_printk(fmt, args);\n\tspin_unlock_irqrestore(&trace_lock, flags);\n\n\tva_end(args);\n\treturn ret;\n}\nEXPORT_SYMBOL(mmiotrace_printk);\n\nstatic void clear_trace_list(void)\n{\n\tstruct remap_trace *trace;\n\tstruct remap_trace *tmp;\n\n\t \n\tlist_for_each_entry(trace, &trace_list, list) {\n\t\tpr_notice(\"purging non-iounmapped trace @0x%08lx, size 0x%lx.\\n\",\n\t\t\t  trace->probe.addr, trace->probe.len);\n\t\tif (!nommiotrace)\n\t\t\tunregister_kmmio_probe(&trace->probe);\n\t}\n\tsynchronize_rcu();  \n\n\tlist_for_each_entry_safe(trace, tmp, &trace_list, list) {\n\t\tlist_del(&trace->list);\n\t\tkfree(trace);\n\t}\n}\n\n#ifdef CONFIG_HOTPLUG_CPU\nstatic cpumask_var_t downed_cpus;\n\nstatic void enter_uniprocessor(void)\n{\n\tint cpu;\n\tint err;\n\n\tif (!cpumask_available(downed_cpus) &&\n\t    !alloc_cpumask_var(&downed_cpus, GFP_KERNEL)) {\n\t\tpr_notice(\"Failed to allocate mask\\n\");\n\t\tgoto out;\n\t}\n\n\tcpus_read_lock();\n\tcpumask_copy(downed_cpus, cpu_online_mask);\n\tcpumask_clear_cpu(cpumask_first(cpu_online_mask), downed_cpus);\n\tif (num_online_cpus() > 1)\n\t\tpr_notice(\"Disabling non-boot CPUs...\\n\");\n\tcpus_read_unlock();\n\n\tfor_each_cpu(cpu, downed_cpus) {\n\t\terr = remove_cpu(cpu);\n\t\tif (!err)\n\t\t\tpr_info(\"CPU%d is down.\\n\", cpu);\n\t\telse\n\t\t\tpr_err(\"Error taking CPU%d down: %d\\n\", cpu, err);\n\t}\nout:\n\tif (num_online_cpus() > 1)\n\t\tpr_warn(\"multiple CPUs still online, may miss events.\\n\");\n}\n\nstatic void leave_uniprocessor(void)\n{\n\tint cpu;\n\tint err;\n\n\tif (!cpumask_available(downed_cpus) || cpumask_empty(downed_cpus))\n\t\treturn;\n\tpr_notice(\"Re-enabling CPUs...\\n\");\n\tfor_each_cpu(cpu, downed_cpus) {\n\t\terr = add_cpu(cpu);\n\t\tif (!err)\n\t\t\tpr_info(\"enabled CPU%d.\\n\", cpu);\n\t\telse\n\t\t\tpr_err(\"cannot re-enable CPU%d: %d\\n\", cpu, err);\n\t}\n}\n\n#else  \nstatic void enter_uniprocessor(void)\n{\n\tif (num_online_cpus() > 1)\n\t\tpr_warn(\"multiple CPUs are online, may miss events. \"\n\t\t\t\"Suggest booting with maxcpus=1 kernel argument.\\n\");\n}\n\nstatic void leave_uniprocessor(void)\n{\n}\n#endif\n\nvoid enable_mmiotrace(void)\n{\n\tmutex_lock(&mmiotrace_mutex);\n\tif (is_enabled())\n\t\tgoto out;\n\n\tif (nommiotrace)\n\t\tpr_info(\"MMIO tracing disabled.\\n\");\n\tkmmio_init();\n\tenter_uniprocessor();\n\tspin_lock_irq(&trace_lock);\n\tatomic_inc(&mmiotrace_enabled);\n\tspin_unlock_irq(&trace_lock);\n\tpr_info(\"enabled.\\n\");\nout:\n\tmutex_unlock(&mmiotrace_mutex);\n}\n\nvoid disable_mmiotrace(void)\n{\n\tmutex_lock(&mmiotrace_mutex);\n\tif (!is_enabled())\n\t\tgoto out;\n\n\tspin_lock_irq(&trace_lock);\n\tatomic_dec(&mmiotrace_enabled);\n\tBUG_ON(is_enabled());\n\tspin_unlock_irq(&trace_lock);\n\n\tclear_trace_list();  \n\tleave_uniprocessor();\n\tkmmio_cleanup();\n\tpr_info(\"disabled.\\n\");\nout:\n\tmutex_unlock(&mmiotrace_mutex);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}