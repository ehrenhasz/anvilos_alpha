{
  "module_name": "init_32.c",
  "hash_id": "2f46eba5a3a17b3d2c661acc1cb142e04e33821ca5921f30876d7a8d04de38a5",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/mm/init_32.c",
  "human_readable_source": "\n \n\n#include <linux/signal.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/ptrace.h>\n#include <linux/mman.h>\n#include <linux/mm.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/smp.h>\n#include <linux/init.h>\n#include <linux/highmem.h>\n#include <linux/pagemap.h>\n#include <linux/pci.h>\n#include <linux/pfn.h>\n#include <linux/poison.h>\n#include <linux/memblock.h>\n#include <linux/proc_fs.h>\n#include <linux/memory_hotplug.h>\n#include <linux/initrd.h>\n#include <linux/cpumask.h>\n#include <linux/gfp.h>\n\n#include <asm/asm.h>\n#include <asm/bios_ebda.h>\n#include <asm/processor.h>\n#include <linux/uaccess.h>\n#include <asm/dma.h>\n#include <asm/fixmap.h>\n#include <asm/e820/api.h>\n#include <asm/apic.h>\n#include <asm/bugs.h>\n#include <asm/tlb.h>\n#include <asm/tlbflush.h>\n#include <asm/olpc_ofw.h>\n#include <asm/pgalloc.h>\n#include <asm/sections.h>\n#include <asm/setup.h>\n#include <asm/set_memory.h>\n#include <asm/page_types.h>\n#include <asm/cpu_entry_area.h>\n#include <asm/init.h>\n#include <asm/pgtable_areas.h>\n#include <asm/numa.h>\n\n#include \"mm_internal.h\"\n\nunsigned long highstart_pfn, highend_pfn;\n\nbool __read_mostly __vmalloc_start_set = false;\n\n \nstatic pmd_t * __init one_md_table_init(pgd_t *pgd)\n{\n\tp4d_t *p4d;\n\tpud_t *pud;\n\tpmd_t *pmd_table;\n\n#ifdef CONFIG_X86_PAE\n\tif (!(pgd_val(*pgd) & _PAGE_PRESENT)) {\n\t\tpmd_table = (pmd_t *)alloc_low_page();\n\t\tset_pgd(pgd, __pgd(__pa(pmd_table) | _PAGE_PRESENT));\n\t\tp4d = p4d_offset(pgd, 0);\n\t\tpud = pud_offset(p4d, 0);\n\t\tBUG_ON(pmd_table != pmd_offset(pud, 0));\n\n\t\treturn pmd_table;\n\t}\n#endif\n\tp4d = p4d_offset(pgd, 0);\n\tpud = pud_offset(p4d, 0);\n\tpmd_table = pmd_offset(pud, 0);\n\n\treturn pmd_table;\n}\n\n \nstatic pte_t * __init one_page_table_init(pmd_t *pmd)\n{\n\tif (!(pmd_val(*pmd) & _PAGE_PRESENT)) {\n\t\tpte_t *page_table = (pte_t *)alloc_low_page();\n\n\t\tset_pmd(pmd, __pmd(__pa(page_table) | _PAGE_TABLE));\n\t\tBUG_ON(page_table != pte_offset_kernel(pmd, 0));\n\t}\n\n\treturn pte_offset_kernel(pmd, 0);\n}\n\npmd_t * __init populate_extra_pmd(unsigned long vaddr)\n{\n\tint pgd_idx = pgd_index(vaddr);\n\tint pmd_idx = pmd_index(vaddr);\n\n\treturn one_md_table_init(swapper_pg_dir + pgd_idx) + pmd_idx;\n}\n\npte_t * __init populate_extra_pte(unsigned long vaddr)\n{\n\tint pte_idx = pte_index(vaddr);\n\tpmd_t *pmd;\n\n\tpmd = populate_extra_pmd(vaddr);\n\treturn one_page_table_init(pmd) + pte_idx;\n}\n\nstatic unsigned long __init\npage_table_range_init_count(unsigned long start, unsigned long end)\n{\n\tunsigned long count = 0;\n#ifdef CONFIG_HIGHMEM\n\tint pmd_idx_kmap_begin = fix_to_virt(FIX_KMAP_END) >> PMD_SHIFT;\n\tint pmd_idx_kmap_end = fix_to_virt(FIX_KMAP_BEGIN) >> PMD_SHIFT;\n\tint pgd_idx, pmd_idx;\n\tunsigned long vaddr;\n\n\tif (pmd_idx_kmap_begin == pmd_idx_kmap_end)\n\t\treturn 0;\n\n\tvaddr = start;\n\tpgd_idx = pgd_index(vaddr);\n\tpmd_idx = pmd_index(vaddr);\n\n\tfor ( ; (pgd_idx < PTRS_PER_PGD) && (vaddr != end); pgd_idx++) {\n\t\tfor (; (pmd_idx < PTRS_PER_PMD) && (vaddr != end);\n\t\t\t\t\t\t\tpmd_idx++) {\n\t\t\tif ((vaddr >> PMD_SHIFT) >= pmd_idx_kmap_begin &&\n\t\t\t    (vaddr >> PMD_SHIFT) <= pmd_idx_kmap_end)\n\t\t\t\tcount++;\n\t\t\tvaddr += PMD_SIZE;\n\t\t}\n\t\tpmd_idx = 0;\n\t}\n#endif\n\treturn count;\n}\n\nstatic pte_t *__init page_table_kmap_check(pte_t *pte, pmd_t *pmd,\n\t\t\t\t\t   unsigned long vaddr, pte_t *lastpte,\n\t\t\t\t\t   void **adr)\n{\n#ifdef CONFIG_HIGHMEM\n\t \n\tint pmd_idx_kmap_begin = fix_to_virt(FIX_KMAP_END) >> PMD_SHIFT;\n\tint pmd_idx_kmap_end = fix_to_virt(FIX_KMAP_BEGIN) >> PMD_SHIFT;\n\n\tif (pmd_idx_kmap_begin != pmd_idx_kmap_end\n\t    && (vaddr >> PMD_SHIFT) >= pmd_idx_kmap_begin\n\t    && (vaddr >> PMD_SHIFT) <= pmd_idx_kmap_end) {\n\t\tpte_t *newpte;\n\t\tint i;\n\n\t\tBUG_ON(after_bootmem);\n\t\tnewpte = *adr;\n\t\tfor (i = 0; i < PTRS_PER_PTE; i++)\n\t\t\tset_pte(newpte + i, pte[i]);\n\t\t*adr = (void *)(((unsigned long)(*adr)) + PAGE_SIZE);\n\n\t\tset_pmd(pmd, __pmd(__pa(newpte)|_PAGE_TABLE));\n\t\tBUG_ON(newpte != pte_offset_kernel(pmd, 0));\n\t\t__flush_tlb_all();\n\n\t\tpte = newpte;\n\t}\n\tBUG_ON(vaddr < fix_to_virt(FIX_KMAP_BEGIN - 1)\n\t       && vaddr > fix_to_virt(FIX_KMAP_END)\n\t       && lastpte && lastpte + PTRS_PER_PTE != pte);\n#endif\n\treturn pte;\n}\n\n \nstatic void __init\npage_table_range_init(unsigned long start, unsigned long end, pgd_t *pgd_base)\n{\n\tint pgd_idx, pmd_idx;\n\tunsigned long vaddr;\n\tpgd_t *pgd;\n\tpmd_t *pmd;\n\tpte_t *pte = NULL;\n\tunsigned long count = page_table_range_init_count(start, end);\n\tvoid *adr = NULL;\n\n\tif (count)\n\t\tadr = alloc_low_pages(count);\n\n\tvaddr = start;\n\tpgd_idx = pgd_index(vaddr);\n\tpmd_idx = pmd_index(vaddr);\n\tpgd = pgd_base + pgd_idx;\n\n\tfor ( ; (pgd_idx < PTRS_PER_PGD) && (vaddr != end); pgd++, pgd_idx++) {\n\t\tpmd = one_md_table_init(pgd);\n\t\tpmd = pmd + pmd_index(vaddr);\n\t\tfor (; (pmd_idx < PTRS_PER_PMD) && (vaddr != end);\n\t\t\t\t\t\t\tpmd++, pmd_idx++) {\n\t\t\tpte = page_table_kmap_check(one_page_table_init(pmd),\n\t\t\t\t\t\t    pmd, vaddr, pte, &adr);\n\n\t\t\tvaddr += PMD_SIZE;\n\t\t}\n\t\tpmd_idx = 0;\n\t}\n}\n\nstatic inline int is_x86_32_kernel_text(unsigned long addr)\n{\n\tif (addr >= (unsigned long)_text && addr <= (unsigned long)__init_end)\n\t\treturn 1;\n\treturn 0;\n}\n\n \nunsigned long __init\nkernel_physical_mapping_init(unsigned long start,\n\t\t\t     unsigned long end,\n\t\t\t     unsigned long page_size_mask,\n\t\t\t     pgprot_t prot)\n{\n\tint use_pse = page_size_mask == (1<<PG_LEVEL_2M);\n\tunsigned long last_map_addr = end;\n\tunsigned long start_pfn, end_pfn;\n\tpgd_t *pgd_base = swapper_pg_dir;\n\tint pgd_idx, pmd_idx, pte_ofs;\n\tunsigned long pfn;\n\tpgd_t *pgd;\n\tpmd_t *pmd;\n\tpte_t *pte;\n\tunsigned pages_2m, pages_4k;\n\tint mapping_iter;\n\n\tstart_pfn = start >> PAGE_SHIFT;\n\tend_pfn = end >> PAGE_SHIFT;\n\n\t \n\tmapping_iter = 1;\n\n\tif (!boot_cpu_has(X86_FEATURE_PSE))\n\t\tuse_pse = 0;\n\nrepeat:\n\tpages_2m = pages_4k = 0;\n\tpfn = start_pfn;\n\tpgd_idx = pgd_index((pfn<<PAGE_SHIFT) + PAGE_OFFSET);\n\tpgd = pgd_base + pgd_idx;\n\tfor (; pgd_idx < PTRS_PER_PGD; pgd++, pgd_idx++) {\n\t\tpmd = one_md_table_init(pgd);\n\n\t\tif (pfn >= end_pfn)\n\t\t\tcontinue;\n#ifdef CONFIG_X86_PAE\n\t\tpmd_idx = pmd_index((pfn<<PAGE_SHIFT) + PAGE_OFFSET);\n\t\tpmd += pmd_idx;\n#else\n\t\tpmd_idx = 0;\n#endif\n\t\tfor (; pmd_idx < PTRS_PER_PMD && pfn < end_pfn;\n\t\t     pmd++, pmd_idx++) {\n\t\t\tunsigned int addr = pfn * PAGE_SIZE + PAGE_OFFSET;\n\n\t\t\t \n\t\t\tif (use_pse) {\n\t\t\t\tunsigned int addr2;\n\t\t\t\tpgprot_t prot = PAGE_KERNEL_LARGE;\n\t\t\t\t \n\t\t\t\tpgprot_t init_prot =\n\t\t\t\t\t__pgprot(PTE_IDENT_ATTR |\n\t\t\t\t\t\t _PAGE_PSE);\n\n\t\t\t\tpfn &= PMD_MASK >> PAGE_SHIFT;\n\t\t\t\taddr2 = (pfn + PTRS_PER_PTE-1) * PAGE_SIZE +\n\t\t\t\t\tPAGE_OFFSET + PAGE_SIZE-1;\n\n\t\t\t\tif (is_x86_32_kernel_text(addr) ||\n\t\t\t\t    is_x86_32_kernel_text(addr2))\n\t\t\t\t\tprot = PAGE_KERNEL_LARGE_EXEC;\n\n\t\t\t\tpages_2m++;\n\t\t\t\tif (mapping_iter == 1)\n\t\t\t\t\tset_pmd(pmd, pfn_pmd(pfn, init_prot));\n\t\t\t\telse\n\t\t\t\t\tset_pmd(pmd, pfn_pmd(pfn, prot));\n\n\t\t\t\tpfn += PTRS_PER_PTE;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tpte = one_page_table_init(pmd);\n\n\t\t\tpte_ofs = pte_index((pfn<<PAGE_SHIFT) + PAGE_OFFSET);\n\t\t\tpte += pte_ofs;\n\t\t\tfor (; pte_ofs < PTRS_PER_PTE && pfn < end_pfn;\n\t\t\t     pte++, pfn++, pte_ofs++, addr += PAGE_SIZE) {\n\t\t\t\tpgprot_t prot = PAGE_KERNEL;\n\t\t\t\t \n\t\t\t\tpgprot_t init_prot = __pgprot(PTE_IDENT_ATTR);\n\n\t\t\t\tif (is_x86_32_kernel_text(addr))\n\t\t\t\t\tprot = PAGE_KERNEL_EXEC;\n\n\t\t\t\tpages_4k++;\n\t\t\t\tif (mapping_iter == 1) {\n\t\t\t\t\tset_pte(pte, pfn_pte(pfn, init_prot));\n\t\t\t\t\tlast_map_addr = (pfn << PAGE_SHIFT) + PAGE_SIZE;\n\t\t\t\t} else\n\t\t\t\t\tset_pte(pte, pfn_pte(pfn, prot));\n\t\t\t}\n\t\t}\n\t}\n\tif (mapping_iter == 1) {\n\t\t \n\t\tupdate_page_count(PG_LEVEL_2M, pages_2m);\n\t\tupdate_page_count(PG_LEVEL_4K, pages_4k);\n\n\t\t \n\t\t__flush_tlb_all();\n\n\t\t \n\t\tmapping_iter = 2;\n\t\tgoto repeat;\n\t}\n\treturn last_map_addr;\n}\n\n#ifdef CONFIG_HIGHMEM\nstatic void __init permanent_kmaps_init(pgd_t *pgd_base)\n{\n\tunsigned long vaddr = PKMAP_BASE;\n\n\tpage_table_range_init(vaddr, vaddr + PAGE_SIZE*LAST_PKMAP, pgd_base);\n\n\tpkmap_page_table = virt_to_kpte(vaddr);\n}\n\nvoid __init add_highpages_with_active_regions(int nid,\n\t\t\t unsigned long start_pfn, unsigned long end_pfn)\n{\n\tphys_addr_t start, end;\n\tu64 i;\n\n\tfor_each_free_mem_range(i, nid, MEMBLOCK_NONE, &start, &end, NULL) {\n\t\tunsigned long pfn = clamp_t(unsigned long, PFN_UP(start),\n\t\t\t\t\t    start_pfn, end_pfn);\n\t\tunsigned long e_pfn = clamp_t(unsigned long, PFN_DOWN(end),\n\t\t\t\t\t      start_pfn, end_pfn);\n\t\tfor ( ; pfn < e_pfn; pfn++)\n\t\t\tif (pfn_valid(pfn))\n\t\t\t\tfree_highmem_page(pfn_to_page(pfn));\n\t}\n}\n#else\nstatic inline void permanent_kmaps_init(pgd_t *pgd_base)\n{\n}\n#endif  \n\nvoid __init sync_initial_page_table(void)\n{\n\tclone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,\n\t\t\tswapper_pg_dir     + KERNEL_PGD_BOUNDARY,\n\t\t\tKERNEL_PGD_PTRS);\n\n\t \n\tclone_pgd_range(initial_page_table,\n\t\t\tswapper_pg_dir     + KERNEL_PGD_BOUNDARY,\n\t\t\tmin(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));\n}\n\nvoid __init native_pagetable_init(void)\n{\n\tunsigned long pfn, va;\n\tpgd_t *pgd, *base = swapper_pg_dir;\n\tp4d_t *p4d;\n\tpud_t *pud;\n\tpmd_t *pmd;\n\tpte_t *pte;\n\n\t \n\tfor (pfn = max_low_pfn; pfn < 1<<(32-PAGE_SHIFT); pfn++) {\n\t\tva = PAGE_OFFSET + (pfn<<PAGE_SHIFT);\n\t\tpgd = base + pgd_index(va);\n\t\tif (!pgd_present(*pgd))\n\t\t\tbreak;\n\n\t\tp4d = p4d_offset(pgd, va);\n\t\tpud = pud_offset(p4d, va);\n\t\tpmd = pmd_offset(pud, va);\n\t\tif (!pmd_present(*pmd))\n\t\t\tbreak;\n\n\t\t \n\t\tif (pmd_large(*pmd)) {\n\t\t\tpr_warn(\"try to clear pte for ram above max_low_pfn: pfn: %lx pmd: %p pmd phys: %lx, but pmd is big page and is not using pte !\\n\",\n\t\t\t\tpfn, pmd, __pa(pmd));\n\t\t\tBUG_ON(1);\n\t\t}\n\n\t\tpte = pte_offset_kernel(pmd, va);\n\t\tif (!pte_present(*pte))\n\t\t\tbreak;\n\n\t\tprintk(KERN_DEBUG \"clearing pte for ram above max_low_pfn: pfn: %lx pmd: %p pmd phys: %lx pte: %p pte phys: %lx\\n\",\n\t\t\t\tpfn, pmd, __pa(pmd), pte, __pa(pte));\n\t\tpte_clear(NULL, va, pte);\n\t}\n\tpaging_init();\n}\n\n \nvoid __init early_ioremap_page_table_range_init(void)\n{\n\tpgd_t *pgd_base = swapper_pg_dir;\n\tunsigned long vaddr, end;\n\n\t \n\tvaddr = __fix_to_virt(__end_of_fixed_addresses - 1) & PMD_MASK;\n\tend = (FIXADDR_TOP + PMD_SIZE - 1) & PMD_MASK;\n\tpage_table_range_init(vaddr, end, pgd_base);\n\tearly_ioremap_reset();\n}\n\nstatic void __init pagetable_init(void)\n{\n\tpgd_t *pgd_base = swapper_pg_dir;\n\n\tpermanent_kmaps_init(pgd_base);\n}\n\n#define DEFAULT_PTE_MASK ~(_PAGE_NX | _PAGE_GLOBAL)\n \npteval_t __supported_pte_mask __read_mostly = DEFAULT_PTE_MASK;\n \npteval_t __default_kernel_pte_mask __read_mostly = DEFAULT_PTE_MASK;\nEXPORT_SYMBOL_GPL(__supported_pte_mask);\n \nEXPORT_SYMBOL(__default_kernel_pte_mask);\n\n \nstatic unsigned int highmem_pages = -1;\n\n \nstatic int __init parse_highmem(char *arg)\n{\n\tif (!arg)\n\t\treturn -EINVAL;\n\n\thighmem_pages = memparse(arg, &arg) >> PAGE_SHIFT;\n\treturn 0;\n}\nearly_param(\"highmem\", parse_highmem);\n\n#define MSG_HIGHMEM_TOO_BIG \\\n\t\"highmem size (%luMB) is bigger than pages available (%luMB)!\\n\"\n\n#define MSG_LOWMEM_TOO_SMALL \\\n\t\"highmem size (%luMB) results in <64MB lowmem, ignoring it!\\n\"\n \nstatic void __init lowmem_pfn_init(void)\n{\n\t \n\tmax_low_pfn = max_pfn;\n\n\tif (highmem_pages == -1)\n\t\thighmem_pages = 0;\n#ifdef CONFIG_HIGHMEM\n\tif (highmem_pages >= max_pfn) {\n\t\tprintk(KERN_ERR MSG_HIGHMEM_TOO_BIG,\n\t\t\tpages_to_mb(highmem_pages), pages_to_mb(max_pfn));\n\t\thighmem_pages = 0;\n\t}\n\tif (highmem_pages) {\n\t\tif (max_low_pfn - highmem_pages < 64*1024*1024/PAGE_SIZE) {\n\t\t\tprintk(KERN_ERR MSG_LOWMEM_TOO_SMALL,\n\t\t\t\tpages_to_mb(highmem_pages));\n\t\t\thighmem_pages = 0;\n\t\t}\n\t\tmax_low_pfn -= highmem_pages;\n\t}\n#else\n\tif (highmem_pages)\n\t\tprintk(KERN_ERR \"ignoring highmem size on non-highmem kernel!\\n\");\n#endif\n}\n\n#define MSG_HIGHMEM_TOO_SMALL \\\n\t\"only %luMB highmem pages available, ignoring highmem size of %luMB!\\n\"\n\n#define MSG_HIGHMEM_TRIMMED \\\n\t\"Warning: only 4GB will be used. Use a HIGHMEM64G enabled kernel!\\n\"\n \nstatic void __init highmem_pfn_init(void)\n{\n\tmax_low_pfn = MAXMEM_PFN;\n\n\tif (highmem_pages == -1)\n\t\thighmem_pages = max_pfn - MAXMEM_PFN;\n\n\tif (highmem_pages + MAXMEM_PFN < max_pfn)\n\t\tmax_pfn = MAXMEM_PFN + highmem_pages;\n\n\tif (highmem_pages + MAXMEM_PFN > max_pfn) {\n\t\tprintk(KERN_WARNING MSG_HIGHMEM_TOO_SMALL,\n\t\t\tpages_to_mb(max_pfn - MAXMEM_PFN),\n\t\t\tpages_to_mb(highmem_pages));\n\t\thighmem_pages = 0;\n\t}\n#ifndef CONFIG_HIGHMEM\n\t \n\tprintk(KERN_WARNING \"Warning only %ldMB will be used.\\n\", MAXMEM>>20);\n\tif (max_pfn > MAX_NONPAE_PFN)\n\t\tprintk(KERN_WARNING \"Use a HIGHMEM64G enabled kernel.\\n\");\n\telse\n\t\tprintk(KERN_WARNING \"Use a HIGHMEM enabled kernel.\\n\");\n\tmax_pfn = MAXMEM_PFN;\n#else  \n#ifndef CONFIG_HIGHMEM64G\n\tif (max_pfn > MAX_NONPAE_PFN) {\n\t\tmax_pfn = MAX_NONPAE_PFN;\n\t\tprintk(KERN_WARNING MSG_HIGHMEM_TRIMMED);\n\t}\n#endif  \n#endif  \n}\n\n \nvoid __init find_low_pfn_range(void)\n{\n\t \n\n\tif (max_pfn <= MAXMEM_PFN)\n\t\tlowmem_pfn_init();\n\telse\n\t\thighmem_pfn_init();\n}\n\n#ifndef CONFIG_NUMA\nvoid __init initmem_init(void)\n{\n#ifdef CONFIG_HIGHMEM\n\thighstart_pfn = highend_pfn = max_pfn;\n\tif (max_pfn > max_low_pfn)\n\t\thighstart_pfn = max_low_pfn;\n\tprintk(KERN_NOTICE \"%ldMB HIGHMEM available.\\n\",\n\t\tpages_to_mb(highend_pfn - highstart_pfn));\n\thigh_memory = (void *) __va(highstart_pfn * PAGE_SIZE - 1) + 1;\n#else\n\thigh_memory = (void *) __va(max_low_pfn * PAGE_SIZE - 1) + 1;\n#endif\n\n\tmemblock_set_node(0, PHYS_ADDR_MAX, &memblock.memory, 0);\n\n#ifdef CONFIG_FLATMEM\n\tmax_mapnr = IS_ENABLED(CONFIG_HIGHMEM) ? highend_pfn : max_low_pfn;\n#endif\n\t__vmalloc_start_set = true;\n\n\tprintk(KERN_NOTICE \"%ldMB LOWMEM available.\\n\",\n\t\t\tpages_to_mb(max_low_pfn));\n\n\tsetup_bootmem_allocator();\n}\n#endif  \n\nvoid __init setup_bootmem_allocator(void)\n{\n\tprintk(KERN_INFO \"  mapped low ram: 0 - %08lx\\n\",\n\t\t max_pfn_mapped<<PAGE_SHIFT);\n\tprintk(KERN_INFO \"  low ram: 0 - %08lx\\n\", max_low_pfn<<PAGE_SHIFT);\n}\n\n \nvoid __init paging_init(void)\n{\n\tpagetable_init();\n\n\t__flush_tlb_all();\n\n\t \n\tolpc_dt_build_devicetree();\n\tsparse_init();\n\tzone_sizes_init();\n}\n\n \nstatic void __init test_wp_bit(void)\n{\n\tchar z = 0;\n\n\tprintk(KERN_INFO \"Checking if this processor honours the WP bit even in supervisor mode...\");\n\n\t__set_fixmap(FIX_WP_TEST, __pa_symbol(empty_zero_page), PAGE_KERNEL_RO);\n\n\tif (copy_to_kernel_nofault((char *)fix_to_virt(FIX_WP_TEST), &z, 1)) {\n\t\tclear_fixmap(FIX_WP_TEST);\n\t\tprintk(KERN_CONT \"Ok.\\n\");\n\t\treturn;\n\t}\n\n\tprintk(KERN_CONT \"No.\\n\");\n\tpanic(\"Linux doesn't support CPUs with broken WP.\");\n}\n\nvoid __init mem_init(void)\n{\n\tpci_iommu_alloc();\n\n#ifdef CONFIG_FLATMEM\n\tBUG_ON(!mem_map);\n#endif\n\t \n\tset_highmem_pages_init();\n\n\t \n\tmemblock_free_all();\n\n\tafter_bootmem = 1;\n\tx86_init.hyper.init_after_bootmem();\n\n\t \n#define __FIXADDR_TOP (-PAGE_SIZE)\n#ifdef CONFIG_HIGHMEM\n\tBUILD_BUG_ON(PKMAP_BASE + LAST_PKMAP*PAGE_SIZE\t> FIXADDR_START);\n\tBUILD_BUG_ON(VMALLOC_END\t\t\t> PKMAP_BASE);\n#endif\n#define high_memory (-128UL << 20)\n\tBUILD_BUG_ON(VMALLOC_START\t\t\t>= VMALLOC_END);\n#undef high_memory\n#undef __FIXADDR_TOP\n\n#ifdef CONFIG_HIGHMEM\n\tBUG_ON(PKMAP_BASE + LAST_PKMAP*PAGE_SIZE\t> FIXADDR_START);\n\tBUG_ON(VMALLOC_END\t\t\t\t> PKMAP_BASE);\n#endif\n\tBUG_ON(VMALLOC_START\t\t\t\t>= VMALLOC_END);\n\tBUG_ON((unsigned long)high_memory\t\t> VMALLOC_START);\n\n\ttest_wp_bit();\n}\n\nint kernel_set_to_readonly __read_mostly;\n\nstatic void mark_nxdata_nx(void)\n{\n\t \n\tunsigned long start = PFN_ALIGN(_etext);\n\t \n\tunsigned long size = (((unsigned long)__init_end + HPAGE_SIZE) & HPAGE_MASK) - start;\n\n\tif (__supported_pte_mask & _PAGE_NX)\n\t\tprintk(KERN_INFO \"NX-protecting the kernel data: %luk\\n\", size >> 10);\n\tset_memory_nx(start, size >> PAGE_SHIFT);\n}\n\nvoid mark_rodata_ro(void)\n{\n\tunsigned long start = PFN_ALIGN(_text);\n\tunsigned long size = (unsigned long)__end_rodata - start;\n\n\tset_pages_ro(virt_to_page(start), size >> PAGE_SHIFT);\n\tpr_info(\"Write protecting kernel text and read-only data: %luk\\n\",\n\t\tsize >> 10);\n\n\tkernel_set_to_readonly = 1;\n\n#ifdef CONFIG_CPA_DEBUG\n\tpr_info(\"Testing CPA: Reverting %lx-%lx\\n\", start, start + size);\n\tset_pages_rw(virt_to_page(start), size >> PAGE_SHIFT);\n\n\tpr_info(\"Testing CPA: write protecting again\\n\");\n\tset_pages_ro(virt_to_page(start), size >> PAGE_SHIFT);\n#endif\n\tmark_nxdata_nx();\n\tif (__supported_pte_mask & _PAGE_NX)\n\t\tdebug_checkwx();\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}