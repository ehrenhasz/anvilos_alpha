{
  "module_name": "core.c",
  "hash_id": "7335e130424f88fef720d568e37ce81f0eccd6671ab9646f1f5b293deefa78a2",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/events/zhaoxin/core.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/stddef.h>\n#include <linux/types.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/export.h>\n#include <linux/nmi.h>\n\n#include <asm/cpufeature.h>\n#include <asm/hardirq.h>\n#include <asm/apic.h>\n\n#include \"../perf_event.h\"\n\n \nstatic u64 zx_pmon_event_map[PERF_COUNT_HW_MAX] __read_mostly = {\n\n\t[PERF_COUNT_HW_CPU_CYCLES]        = 0x0082,\n\t[PERF_COUNT_HW_INSTRUCTIONS]      = 0x00c0,\n\t[PERF_COUNT_HW_CACHE_REFERENCES]  = 0x0515,\n\t[PERF_COUNT_HW_CACHE_MISSES]      = 0x051a,\n\t[PERF_COUNT_HW_BUS_CYCLES]        = 0x0083,\n};\n\nstatic struct event_constraint zxc_event_constraints[] __read_mostly = {\n\n\tFIXED_EVENT_CONSTRAINT(0x0082, 1),  \n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct event_constraint zxd_event_constraints[] __read_mostly = {\n\n\tFIXED_EVENT_CONSTRAINT(0x00c0, 0),  \n\tFIXED_EVENT_CONSTRAINT(0x0082, 1),  \n\tFIXED_EVENT_CONSTRAINT(0x0083, 2),  \n\tEVENT_CONSTRAINT_END\n};\n\nstatic __initconst const u64 zxd_hw_cache_event_ids\n\t\t\t\t[PERF_COUNT_HW_CACHE_MAX]\n\t\t\t\t[PERF_COUNT_HW_CACHE_OP_MAX]\n\t\t\t\t[PERF_COUNT_HW_CACHE_RESULT_MAX] = {\n[C(L1D)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0042,\n\t\t[C(RESULT_MISS)] = 0x0538,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0043,\n\t\t[C(RESULT_MISS)] = 0x0562,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n},\n[C(L1I)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0300,\n\t\t[C(RESULT_MISS)] = 0x0301,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = 0x030a,\n\t\t[C(RESULT_MISS)] = 0x030b,\n\t},\n},\n[C(LL)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n},\n[C(DTLB)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0042,\n\t\t[C(RESULT_MISS)] = 0x052c,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0043,\n\t\t[C(RESULT_MISS)] = 0x0530,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0564,\n\t\t[C(RESULT_MISS)] = 0x0565,\n\t},\n},\n[C(ITLB)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x00c0,\n\t\t[C(RESULT_MISS)] = 0x0534,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n},\n[C(BPU)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0700,\n\t\t[C(RESULT_MISS)] = 0x0709,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n},\n[C(NODE)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n},\n};\n\nstatic __initconst const u64 zxe_hw_cache_event_ids\n\t\t\t\t[PERF_COUNT_HW_CACHE_MAX]\n\t\t\t\t[PERF_COUNT_HW_CACHE_OP_MAX]\n\t\t\t\t[PERF_COUNT_HW_CACHE_RESULT_MAX] = {\n[C(L1D)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0568,\n\t\t[C(RESULT_MISS)] = 0x054b,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0669,\n\t\t[C(RESULT_MISS)] = 0x0562,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n},\n[C(L1I)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0300,\n\t\t[C(RESULT_MISS)] = 0x0301,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = 0x030a,\n\t\t[C(RESULT_MISS)] = 0x030b,\n\t},\n},\n[C(LL)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0,\n\t\t[C(RESULT_MISS)] = 0x0,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0,\n\t\t[C(RESULT_MISS)] = 0x0,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0,\n\t\t[C(RESULT_MISS)] = 0x0,\n\t},\n},\n[C(DTLB)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0568,\n\t\t[C(RESULT_MISS)] = 0x052c,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0669,\n\t\t[C(RESULT_MISS)] = 0x0530,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0564,\n\t\t[C(RESULT_MISS)] = 0x0565,\n\t},\n},\n[C(ITLB)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x00c0,\n\t\t[C(RESULT_MISS)] = 0x0534,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n},\n[C(BPU)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = 0x0028,\n\t\t[C(RESULT_MISS)] = 0x0029,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n},\n[C(NODE)] = {\n\t[C(OP_READ)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_WRITE)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n\t[C(OP_PREFETCH)] = {\n\t\t[C(RESULT_ACCESS)] = -1,\n\t\t[C(RESULT_MISS)] = -1,\n\t},\n},\n};\n\nstatic void zhaoxin_pmu_disable_all(void)\n{\n\twrmsrl(MSR_CORE_PERF_GLOBAL_CTRL, 0);\n}\n\nstatic void zhaoxin_pmu_enable_all(int added)\n{\n\twrmsrl(MSR_CORE_PERF_GLOBAL_CTRL, x86_pmu.intel_ctrl);\n}\n\nstatic inline u64 zhaoxin_pmu_get_status(void)\n{\n\tu64 status;\n\n\trdmsrl(MSR_CORE_PERF_GLOBAL_STATUS, status);\n\n\treturn status;\n}\n\nstatic inline void zhaoxin_pmu_ack_status(u64 ack)\n{\n\twrmsrl(MSR_CORE_PERF_GLOBAL_OVF_CTRL, ack);\n}\n\nstatic inline void zxc_pmu_ack_status(u64 ack)\n{\n\t \n\tzhaoxin_pmu_enable_all(0);\n\tzhaoxin_pmu_ack_status(ack);\n\tzhaoxin_pmu_disable_all();\n}\n\nstatic void zhaoxin_pmu_disable_fixed(struct hw_perf_event *hwc)\n{\n\tint idx = hwc->idx - INTEL_PMC_IDX_FIXED;\n\tu64 ctrl_val, mask;\n\n\tmask = 0xfULL << (idx * 4);\n\n\trdmsrl(hwc->config_base, ctrl_val);\n\tctrl_val &= ~mask;\n\twrmsrl(hwc->config_base, ctrl_val);\n}\n\nstatic void zhaoxin_pmu_disable_event(struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (unlikely(hwc->config_base == MSR_ARCH_PERFMON_FIXED_CTR_CTRL)) {\n\t\tzhaoxin_pmu_disable_fixed(hwc);\n\t\treturn;\n\t}\n\n\tx86_pmu_disable_event(event);\n}\n\nstatic void zhaoxin_pmu_enable_fixed(struct hw_perf_event *hwc)\n{\n\tint idx = hwc->idx - INTEL_PMC_IDX_FIXED;\n\tu64 ctrl_val, bits, mask;\n\n\t \n\tbits = 0x8ULL;\n\tif (hwc->config & ARCH_PERFMON_EVENTSEL_USR)\n\t\tbits |= 0x2;\n\tif (hwc->config & ARCH_PERFMON_EVENTSEL_OS)\n\t\tbits |= 0x1;\n\n\tbits <<= (idx * 4);\n\tmask = 0xfULL << (idx * 4);\n\n\trdmsrl(hwc->config_base, ctrl_val);\n\tctrl_val &= ~mask;\n\tctrl_val |= bits;\n\twrmsrl(hwc->config_base, ctrl_val);\n}\n\nstatic void zhaoxin_pmu_enable_event(struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (unlikely(hwc->config_base == MSR_ARCH_PERFMON_FIXED_CTR_CTRL)) {\n\t\tzhaoxin_pmu_enable_fixed(hwc);\n\t\treturn;\n\t}\n\n\t__x86_pmu_enable_event(hwc, ARCH_PERFMON_EVENTSEL_ENABLE);\n}\n\n \nstatic int zhaoxin_pmu_handle_irq(struct pt_regs *regs)\n{\n\tstruct perf_sample_data data;\n\tstruct cpu_hw_events *cpuc;\n\tint handled = 0;\n\tu64 status;\n\tint bit;\n\n\tcpuc = this_cpu_ptr(&cpu_hw_events);\n\tapic_write(APIC_LVTPC, APIC_DM_NMI);\n\tzhaoxin_pmu_disable_all();\n\tstatus = zhaoxin_pmu_get_status();\n\tif (!status)\n\t\tgoto done;\n\nagain:\n\tif (x86_pmu.enabled_ack)\n\t\tzxc_pmu_ack_status(status);\n\telse\n\t\tzhaoxin_pmu_ack_status(status);\n\n\tinc_irq_stat(apic_perf_irqs);\n\n\t \n\tif (__test_and_clear_bit(63, (unsigned long *)&status)) {\n\t\tif (!status)\n\t\t\tgoto done;\n\t}\n\n\tfor_each_set_bit(bit, (unsigned long *)&status, X86_PMC_IDX_MAX) {\n\t\tstruct perf_event *event = cpuc->events[bit];\n\n\t\thandled++;\n\n\t\tif (!test_bit(bit, cpuc->active_mask))\n\t\t\tcontinue;\n\n\t\tx86_perf_event_update(event);\n\t\tperf_sample_data_init(&data, 0, event->hw.last_period);\n\n\t\tif (!x86_perf_event_set_period(event))\n\t\t\tcontinue;\n\n\t\tif (perf_event_overflow(event, &data, regs))\n\t\t\tx86_pmu_stop(event, 0);\n\t}\n\n\t \n\tstatus = zhaoxin_pmu_get_status();\n\tif (status)\n\t\tgoto again;\n\ndone:\n\tzhaoxin_pmu_enable_all(0);\n\treturn handled;\n}\n\nstatic u64 zhaoxin_pmu_event_map(int hw_event)\n{\n\treturn zx_pmon_event_map[hw_event];\n}\n\nstatic struct event_constraint *\nzhaoxin_get_event_constraints(struct cpu_hw_events *cpuc, int idx,\n\t\t\tstruct perf_event *event)\n{\n\tstruct event_constraint *c;\n\n\tif (x86_pmu.event_constraints) {\n\t\tfor_each_event_constraint(c, x86_pmu.event_constraints) {\n\t\t\tif ((event->hw.config & c->cmask) == c->code)\n\t\t\t\treturn c;\n\t\t}\n\t}\n\n\treturn &unconstrained;\n}\n\nPMU_FORMAT_ATTR(event,\t\"config:0-7\");\nPMU_FORMAT_ATTR(umask,\t\"config:8-15\");\nPMU_FORMAT_ATTR(edge,\t\"config:18\");\nPMU_FORMAT_ATTR(inv,\t\"config:23\");\nPMU_FORMAT_ATTR(cmask,\t\"config:24-31\");\n\nstatic struct attribute *zx_arch_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_cmask.attr,\n\tNULL,\n};\n\nstatic ssize_t zhaoxin_event_sysfs_show(char *page, u64 config)\n{\n\tu64 event = (config & ARCH_PERFMON_EVENTSEL_EVENT);\n\n\treturn x86_event_sysfs_show(page, config, event);\n}\n\nstatic const struct x86_pmu zhaoxin_pmu __initconst = {\n\t.name\t\t\t= \"zhaoxin\",\n\t.handle_irq\t\t= zhaoxin_pmu_handle_irq,\n\t.disable_all\t\t= zhaoxin_pmu_disable_all,\n\t.enable_all\t\t= zhaoxin_pmu_enable_all,\n\t.enable\t\t\t= zhaoxin_pmu_enable_event,\n\t.disable\t\t= zhaoxin_pmu_disable_event,\n\t.hw_config\t\t= x86_pmu_hw_config,\n\t.schedule_events\t= x86_schedule_events,\n\t.eventsel\t\t= MSR_ARCH_PERFMON_EVENTSEL0,\n\t.perfctr\t\t= MSR_ARCH_PERFMON_PERFCTR0,\n\t.event_map\t\t= zhaoxin_pmu_event_map,\n\t.max_events\t\t= ARRAY_SIZE(zx_pmon_event_map),\n\t.apic\t\t\t= 1,\n\t \n\t.max_period\t\t= (1ULL << 47) - 1,\n\t.get_event_constraints\t= zhaoxin_get_event_constraints,\n\n\t.format_attrs\t\t= zx_arch_formats_attr,\n\t.events_sysfs_show\t= zhaoxin_event_sysfs_show,\n};\n\nstatic const struct { int id; char *name; } zx_arch_events_map[] __initconst = {\n\t{ PERF_COUNT_HW_CPU_CYCLES, \"cpu cycles\" },\n\t{ PERF_COUNT_HW_INSTRUCTIONS, \"instructions\" },\n\t{ PERF_COUNT_HW_BUS_CYCLES, \"bus cycles\" },\n\t{ PERF_COUNT_HW_CACHE_REFERENCES, \"cache references\" },\n\t{ PERF_COUNT_HW_CACHE_MISSES, \"cache misses\" },\n\t{ PERF_COUNT_HW_BRANCH_INSTRUCTIONS, \"branch instructions\" },\n\t{ PERF_COUNT_HW_BRANCH_MISSES, \"branch misses\" },\n};\n\nstatic __init void zhaoxin_arch_events_quirk(void)\n{\n\tint bit;\n\n\t \n\tfor_each_set_bit(bit, x86_pmu.events_mask, ARRAY_SIZE(zx_arch_events_map)) {\n\t\tzx_pmon_event_map[zx_arch_events_map[bit].id] = 0;\n\t\tpr_warn(\"CPUID marked event: \\'%s\\' unavailable\\n\",\n\t\t\tzx_arch_events_map[bit].name);\n\t}\n}\n\n__init int zhaoxin_pmu_init(void)\n{\n\tunion cpuid10_edx edx;\n\tunion cpuid10_eax eax;\n\tunion cpuid10_ebx ebx;\n\tstruct event_constraint *c;\n\tunsigned int unused;\n\tint version;\n\n\tpr_info(\"Welcome to zhaoxin pmu!\\n\");\n\n\t \n\tcpuid(10, &eax.full, &ebx.full, &unused, &edx.full);\n\n\tif (eax.split.mask_length < ARCH_PERFMON_EVENTS_COUNT - 1)\n\t\treturn -ENODEV;\n\n\tversion = eax.split.version_id;\n\tif (version != 2)\n\t\treturn -ENODEV;\n\n\tx86_pmu = zhaoxin_pmu;\n\tpr_info(\"Version check pass!\\n\");\n\n\tx86_pmu.version\t\t\t= version;\n\tx86_pmu.num_counters\t\t= eax.split.num_counters;\n\tx86_pmu.cntval_bits\t\t= eax.split.bit_width;\n\tx86_pmu.cntval_mask\t\t= (1ULL << eax.split.bit_width) - 1;\n\tx86_pmu.events_maskl\t\t= ebx.full;\n\tx86_pmu.events_mask_len\t\t= eax.split.mask_length;\n\n\tx86_pmu.num_counters_fixed = edx.split.num_counters_fixed;\n\tx86_add_quirk(zhaoxin_arch_events_quirk);\n\n\tswitch (boot_cpu_data.x86) {\n\tcase 0x06:\n\t\t \n\t\tif ((boot_cpu_data.x86_model == 0x0f && boot_cpu_data.x86_stepping >= 0x0e) ||\n\t\t\tboot_cpu_data.x86_model == 0x19) {\n\n\t\t\tx86_pmu.max_period = x86_pmu.cntval_mask >> 1;\n\n\t\t\t \n\t\t\tx86_pmu.enabled_ack = 1;\n\n\t\t\tx86_pmu.event_constraints = zxc_event_constraints;\n\t\t\tzx_pmon_event_map[PERF_COUNT_HW_INSTRUCTIONS] = 0;\n\t\t\tzx_pmon_event_map[PERF_COUNT_HW_CACHE_REFERENCES] = 0;\n\t\t\tzx_pmon_event_map[PERF_COUNT_HW_CACHE_MISSES] = 0;\n\t\t\tzx_pmon_event_map[PERF_COUNT_HW_BUS_CYCLES] = 0;\n\n\t\t\tpr_cont(\"ZXC events, \");\n\t\t\tbreak;\n\t\t}\n\t\treturn -ENODEV;\n\n\tcase 0x07:\n\t\tzx_pmon_event_map[PERF_COUNT_HW_STALLED_CYCLES_FRONTEND] =\n\t\t\tX86_CONFIG(.event = 0x01, .umask = 0x01, .inv = 0x01, .cmask = 0x01);\n\n\t\tzx_pmon_event_map[PERF_COUNT_HW_STALLED_CYCLES_BACKEND] =\n\t\t\tX86_CONFIG(.event = 0x0f, .umask = 0x04, .inv = 0, .cmask = 0);\n\n\t\tswitch (boot_cpu_data.x86_model) {\n\t\tcase 0x1b:\n\t\t\tmemcpy(hw_cache_event_ids, zxd_hw_cache_event_ids,\n\t\t\t       sizeof(hw_cache_event_ids));\n\n\t\t\tx86_pmu.event_constraints = zxd_event_constraints;\n\n\t\t\tzx_pmon_event_map[PERF_COUNT_HW_BRANCH_INSTRUCTIONS] = 0x0700;\n\t\t\tzx_pmon_event_map[PERF_COUNT_HW_BRANCH_MISSES] = 0x0709;\n\n\t\t\tpr_cont(\"ZXD events, \");\n\t\t\tbreak;\n\t\tcase 0x3b:\n\t\t\tmemcpy(hw_cache_event_ids, zxe_hw_cache_event_ids,\n\t\t\t       sizeof(hw_cache_event_ids));\n\n\t\t\tx86_pmu.event_constraints = zxd_event_constraints;\n\n\t\t\tzx_pmon_event_map[PERF_COUNT_HW_BRANCH_INSTRUCTIONS] = 0x0028;\n\t\t\tzx_pmon_event_map[PERF_COUNT_HW_BRANCH_MISSES] = 0x0029;\n\n\t\t\tpr_cont(\"ZXE events, \");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n\n\tx86_pmu.intel_ctrl = (1 << (x86_pmu.num_counters)) - 1;\n\tx86_pmu.intel_ctrl |= ((1LL << x86_pmu.num_counters_fixed)-1) << INTEL_PMC_IDX_FIXED;\n\n\tif (x86_pmu.event_constraints) {\n\t\tfor_each_event_constraint(c, x86_pmu.event_constraints) {\n\t\t\tc->idxmsk64 |= (1ULL << x86_pmu.num_counters) - 1;\n\t\t\tc->weight += x86_pmu.num_counters;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}