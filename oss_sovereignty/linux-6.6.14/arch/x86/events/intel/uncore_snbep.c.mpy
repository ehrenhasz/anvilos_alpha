{
  "module_name": "uncore_snbep.c",
  "hash_id": "fd8a2243dc14c794fa9a3d70b7a1039346ca0645a8b970288c6589877b259cac",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/events/intel/uncore_snbep.c",
  "human_readable_source": "\n \n#include \"uncore.h\"\n#include \"uncore_discovery.h\"\n\n \n#define SNBEP_CPUNODEID\t\t\t0x40\n#define SNBEP_GIDNIDMAP\t\t\t0x54\n\n \n#define SNBEP_PMON_BOX_CTL_RST_CTRL\t(1 << 0)\n#define SNBEP_PMON_BOX_CTL_RST_CTRS\t(1 << 1)\n#define SNBEP_PMON_BOX_CTL_FRZ\t\t(1 << 8)\n#define SNBEP_PMON_BOX_CTL_FRZ_EN\t(1 << 16)\n#define SNBEP_PMON_BOX_CTL_INT\t\t(SNBEP_PMON_BOX_CTL_RST_CTRL | \\\n\t\t\t\t\t SNBEP_PMON_BOX_CTL_RST_CTRS | \\\n\t\t\t\t\t SNBEP_PMON_BOX_CTL_FRZ_EN)\n \n#define SNBEP_PMON_CTL_EV_SEL_MASK\t0x000000ff\n#define SNBEP_PMON_CTL_UMASK_MASK\t0x0000ff00\n#define SNBEP_PMON_CTL_RST\t\t(1 << 17)\n#define SNBEP_PMON_CTL_EDGE_DET\t\t(1 << 18)\n#define SNBEP_PMON_CTL_EV_SEL_EXT\t(1 << 21)\n#define SNBEP_PMON_CTL_EN\t\t(1 << 22)\n#define SNBEP_PMON_CTL_INVERT\t\t(1 << 23)\n#define SNBEP_PMON_CTL_TRESH_MASK\t0xff000000\n#define SNBEP_PMON_RAW_EVENT_MASK\t(SNBEP_PMON_CTL_EV_SEL_MASK | \\\n\t\t\t\t\t SNBEP_PMON_CTL_UMASK_MASK | \\\n\t\t\t\t\t SNBEP_PMON_CTL_EDGE_DET | \\\n\t\t\t\t\t SNBEP_PMON_CTL_INVERT | \\\n\t\t\t\t\t SNBEP_PMON_CTL_TRESH_MASK)\n\n \n#define SNBEP_U_MSR_PMON_CTL_TRESH_MASK\t\t0x1f000000\n#define SNBEP_U_MSR_PMON_RAW_EVENT_MASK\t\t\\\n\t\t\t\t(SNBEP_PMON_CTL_EV_SEL_MASK | \\\n\t\t\t\t SNBEP_PMON_CTL_UMASK_MASK | \\\n\t\t\t\t SNBEP_PMON_CTL_EDGE_DET | \\\n\t\t\t\t SNBEP_PMON_CTL_INVERT | \\\n\t\t\t\t SNBEP_U_MSR_PMON_CTL_TRESH_MASK)\n\n#define SNBEP_CBO_PMON_CTL_TID_EN\t\t(1 << 19)\n#define SNBEP_CBO_MSR_PMON_RAW_EVENT_MASK\t(SNBEP_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t\t\t SNBEP_CBO_PMON_CTL_TID_EN)\n\n \n#define SNBEP_PCU_MSR_PMON_CTL_OCC_SEL_MASK\t0x0000c000\n#define SNBEP_PCU_MSR_PMON_CTL_TRESH_MASK\t0x1f000000\n#define SNBEP_PCU_MSR_PMON_CTL_OCC_INVERT\t(1 << 30)\n#define SNBEP_PCU_MSR_PMON_CTL_OCC_EDGE_DET\t(1 << 31)\n#define SNBEP_PCU_MSR_PMON_RAW_EVENT_MASK\t\\\n\t\t\t\t(SNBEP_PMON_CTL_EV_SEL_MASK | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_OCC_SEL_MASK | \\\n\t\t\t\t SNBEP_PMON_CTL_EDGE_DET | \\\n\t\t\t\t SNBEP_PMON_CTL_INVERT | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_TRESH_MASK | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_OCC_INVERT | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_OCC_EDGE_DET)\n\n#define SNBEP_QPI_PCI_PMON_RAW_EVENT_MASK\t\\\n\t\t\t\t(SNBEP_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t SNBEP_PMON_CTL_EV_SEL_EXT)\n\n \n#define SNBEP_PCI_PMON_BOX_CTL\t\t\t0xf4\n#define SNBEP_PCI_PMON_CTL0\t\t\t0xd8\n \n#define SNBEP_PCI_PMON_CTR0\t\t\t0xa0\n\n \n#define SNBEP_HA_PCI_PMON_BOX_ADDRMATCH0\t0x40\n#define SNBEP_HA_PCI_PMON_BOX_ADDRMATCH1\t0x44\n#define SNBEP_HA_PCI_PMON_BOX_OPCODEMATCH\t0x48\n \n#define SNBEP_MC_CHy_PCI_PMON_FIXED_CTL\t\t0xf0\n#define SNBEP_MC_CHy_PCI_PMON_FIXED_CTR\t\t0xd0\n \n#define SNBEP_Q_Py_PCI_PMON_PKT_MATCH0\t\t0x228\n#define SNBEP_Q_Py_PCI_PMON_PKT_MATCH1\t\t0x22c\n#define SNBEP_Q_Py_PCI_PMON_PKT_MASK0\t\t0x238\n#define SNBEP_Q_Py_PCI_PMON_PKT_MASK1\t\t0x23c\n\n \n#define SNBEP_U_MSR_PMON_CTR0\t\t\t0xc16\n#define SNBEP_U_MSR_PMON_CTL0\t\t\t0xc10\n\n#define SNBEP_U_MSR_PMON_UCLK_FIXED_CTL\t\t0xc08\n#define SNBEP_U_MSR_PMON_UCLK_FIXED_CTR\t\t0xc09\n\n \n#define SNBEP_C0_MSR_PMON_CTR0\t\t\t0xd16\n#define SNBEP_C0_MSR_PMON_CTL0\t\t\t0xd10\n#define SNBEP_C0_MSR_PMON_BOX_CTL\t\t0xd04\n#define SNBEP_C0_MSR_PMON_BOX_FILTER\t\t0xd14\n#define SNBEP_CBO_MSR_OFFSET\t\t\t0x20\n\n#define SNBEP_CB0_MSR_PMON_BOX_FILTER_TID\t0x1f\n#define SNBEP_CB0_MSR_PMON_BOX_FILTER_NID\t0x3fc00\n#define SNBEP_CB0_MSR_PMON_BOX_FILTER_STATE\t0x7c0000\n#define SNBEP_CB0_MSR_PMON_BOX_FILTER_OPC\t0xff800000\n\n#define SNBEP_CBO_EVENT_EXTRA_REG(e, m, i) {\t\\\n\t.event = (e),\t\t\t\t\\\n\t.msr = SNBEP_C0_MSR_PMON_BOX_FILTER,\t\\\n\t.config_mask = (m),\t\t\t\\\n\t.idx = (i)\t\t\t\t\\\n}\n\n \n#define SNBEP_PCU_MSR_PMON_CTR0\t\t\t0xc36\n#define SNBEP_PCU_MSR_PMON_CTL0\t\t\t0xc30\n#define SNBEP_PCU_MSR_PMON_BOX_CTL\t\t0xc24\n#define SNBEP_PCU_MSR_PMON_BOX_FILTER\t\t0xc34\n#define SNBEP_PCU_MSR_PMON_BOX_FILTER_MASK\t0xffffffff\n#define SNBEP_PCU_MSR_CORE_C3_CTR\t\t0x3fc\n#define SNBEP_PCU_MSR_CORE_C6_CTR\t\t0x3fd\n\n \n#define IVBEP_PMON_BOX_CTL_INT\t\t(SNBEP_PMON_BOX_CTL_RST_CTRL | \\\n\t\t\t\t\t SNBEP_PMON_BOX_CTL_RST_CTRS)\n#define IVBEP_PMON_RAW_EVENT_MASK\t\t(SNBEP_PMON_CTL_EV_SEL_MASK | \\\n\t\t\t\t\t SNBEP_PMON_CTL_UMASK_MASK | \\\n\t\t\t\t\t SNBEP_PMON_CTL_EDGE_DET | \\\n\t\t\t\t\t SNBEP_PMON_CTL_TRESH_MASK)\n \n#define IVBEP_U_MSR_PMON_GLOBAL_CTL\t\t0xc00\n#define IVBEP_U_PMON_GLOBAL_FRZ_ALL\t\t(1 << 31)\n#define IVBEP_U_PMON_GLOBAL_UNFRZ_ALL\t\t(1 << 29)\n\n#define IVBEP_U_MSR_PMON_RAW_EVENT_MASK\t\\\n\t\t\t\t(SNBEP_PMON_CTL_EV_SEL_MASK | \\\n\t\t\t\t SNBEP_PMON_CTL_UMASK_MASK | \\\n\t\t\t\t SNBEP_PMON_CTL_EDGE_DET | \\\n\t\t\t\t SNBEP_U_MSR_PMON_CTL_TRESH_MASK)\n \n#define IVBEP_CBO_MSR_PMON_RAW_EVENT_MASK\t\t(IVBEP_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t\t\t SNBEP_CBO_PMON_CTL_TID_EN)\n\n#define IVBEP_CB0_MSR_PMON_BOX_FILTER_TID\t\t(0x1fULL << 0)\n#define IVBEP_CB0_MSR_PMON_BOX_FILTER_LINK\t(0xfULL << 5)\n#define IVBEP_CB0_MSR_PMON_BOX_FILTER_STATE\t(0x3fULL << 17)\n#define IVBEP_CB0_MSR_PMON_BOX_FILTER_NID\t\t(0xffffULL << 32)\n#define IVBEP_CB0_MSR_PMON_BOX_FILTER_OPC\t\t(0x1ffULL << 52)\n#define IVBEP_CB0_MSR_PMON_BOX_FILTER_C6\t\t(0x1ULL << 61)\n#define IVBEP_CB0_MSR_PMON_BOX_FILTER_NC\t\t(0x1ULL << 62)\n#define IVBEP_CB0_MSR_PMON_BOX_FILTER_ISOC\t(0x1ULL << 63)\n\n \n#define IVBEP_HA_PCI_PMON_CTL_Q_OCC_RST\t\t(1 << 16)\n#define IVBEP_HA_PCI_PMON_RAW_EVENT_MASK\t\t\\\n\t\t\t\t(IVBEP_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t IVBEP_HA_PCI_PMON_CTL_Q_OCC_RST)\n \n#define IVBEP_PCU_MSR_PMON_RAW_EVENT_MASK\t\\\n\t\t\t\t(SNBEP_PMON_CTL_EV_SEL_MASK | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_OCC_SEL_MASK | \\\n\t\t\t\t SNBEP_PMON_CTL_EDGE_DET | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_TRESH_MASK | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_OCC_INVERT | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_OCC_EDGE_DET)\n \n#define IVBEP_QPI_PCI_PMON_RAW_EVENT_MASK\t\\\n\t\t\t\t(IVBEP_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t SNBEP_PMON_CTL_EV_SEL_EXT)\n\n#define __BITS_VALUE(x, i, n)  ((typeof(x))(((x) >> ((i) * (n))) & \\\n\t\t\t\t((1ULL << (n)) - 1)))\n\n \n#define HSWEP_U_MSR_PMON_CTR0\t\t\t0x709\n#define HSWEP_U_MSR_PMON_CTL0\t\t\t0x705\n#define HSWEP_U_MSR_PMON_FILTER\t\t\t0x707\n\n#define HSWEP_U_MSR_PMON_UCLK_FIXED_CTL\t\t0x703\n#define HSWEP_U_MSR_PMON_UCLK_FIXED_CTR\t\t0x704\n\n#define HSWEP_U_MSR_PMON_BOX_FILTER_TID\t\t(0x1 << 0)\n#define HSWEP_U_MSR_PMON_BOX_FILTER_CID\t\t(0x1fULL << 1)\n#define HSWEP_U_MSR_PMON_BOX_FILTER_MASK \\\n\t\t\t\t\t(HSWEP_U_MSR_PMON_BOX_FILTER_TID | \\\n\t\t\t\t\t HSWEP_U_MSR_PMON_BOX_FILTER_CID)\n\n \n#define HSWEP_C0_MSR_PMON_CTR0\t\t\t0xe08\n#define HSWEP_C0_MSR_PMON_CTL0\t\t\t0xe01\n#define HSWEP_C0_MSR_PMON_BOX_CTL\t\t\t0xe00\n#define HSWEP_C0_MSR_PMON_BOX_FILTER0\t\t0xe05\n#define HSWEP_CBO_MSR_OFFSET\t\t\t0x10\n\n\n#define HSWEP_CB0_MSR_PMON_BOX_FILTER_TID\t\t(0x3fULL << 0)\n#define HSWEP_CB0_MSR_PMON_BOX_FILTER_LINK\t(0xfULL << 6)\n#define HSWEP_CB0_MSR_PMON_BOX_FILTER_STATE\t(0x7fULL << 17)\n#define HSWEP_CB0_MSR_PMON_BOX_FILTER_NID\t\t(0xffffULL << 32)\n#define HSWEP_CB0_MSR_PMON_BOX_FILTER_OPC\t\t(0x1ffULL << 52)\n#define HSWEP_CB0_MSR_PMON_BOX_FILTER_C6\t\t(0x1ULL << 61)\n#define HSWEP_CB0_MSR_PMON_BOX_FILTER_NC\t\t(0x1ULL << 62)\n#define HSWEP_CB0_MSR_PMON_BOX_FILTER_ISOC\t(0x1ULL << 63)\n\n\n \n#define HSWEP_S0_MSR_PMON_CTR0\t\t\t0x726\n#define HSWEP_S0_MSR_PMON_CTL0\t\t\t0x721\n#define HSWEP_S0_MSR_PMON_BOX_CTL\t\t\t0x720\n#define HSWEP_SBOX_MSR_OFFSET\t\t\t0xa\n#define HSWEP_S_MSR_PMON_RAW_EVENT_MASK\t\t(SNBEP_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t\t\t SNBEP_CBO_PMON_CTL_TID_EN)\n\n \n#define HSWEP_PCU_MSR_PMON_CTR0\t\t\t0x717\n#define HSWEP_PCU_MSR_PMON_CTL0\t\t\t0x711\n#define HSWEP_PCU_MSR_PMON_BOX_CTL\t\t0x710\n#define HSWEP_PCU_MSR_PMON_BOX_FILTER\t\t0x715\n\n \n#define KNL_U_MSR_PMON_RAW_EVENT_MASK \\\n\t\t\t\t\t(SNBEP_U_MSR_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t\t\tSNBEP_CBO_PMON_CTL_TID_EN)\n \n#define KNL_CHA_MSR_OFFSET\t\t\t0xc\n#define KNL_CHA_MSR_PMON_CTL_QOR\t\t(1 << 16)\n#define KNL_CHA_MSR_PMON_RAW_EVENT_MASK \\\n\t\t\t\t\t(SNBEP_CBO_MSR_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t\t KNL_CHA_MSR_PMON_CTL_QOR)\n#define KNL_CHA_MSR_PMON_BOX_FILTER_TID\t\t0x1ff\n#define KNL_CHA_MSR_PMON_BOX_FILTER_STATE\t(7 << 18)\n#define KNL_CHA_MSR_PMON_BOX_FILTER_OP\t\t(0xfffffe2aULL << 32)\n#define KNL_CHA_MSR_PMON_BOX_FILTER_REMOTE_NODE\t(0x1ULL << 32)\n#define KNL_CHA_MSR_PMON_BOX_FILTER_LOCAL_NODE\t(0x1ULL << 33)\n#define KNL_CHA_MSR_PMON_BOX_FILTER_NNC\t\t(0x1ULL << 37)\n\n \n#define KNL_UCLK_MSR_PMON_CTR0_LOW\t\t0x400\n#define KNL_UCLK_MSR_PMON_CTL0\t\t\t0x420\n#define KNL_UCLK_MSR_PMON_BOX_CTL\t\t0x430\n#define KNL_UCLK_MSR_PMON_UCLK_FIXED_LOW\t0x44c\n#define KNL_UCLK_MSR_PMON_UCLK_FIXED_CTL\t0x454\n#define KNL_PMON_FIXED_CTL_EN\t\t\t0x1\n\n \n#define KNL_EDC0_ECLK_MSR_PMON_CTR0_LOW\t\t0xa00\n#define KNL_EDC0_ECLK_MSR_PMON_CTL0\t\t0xa20\n#define KNL_EDC0_ECLK_MSR_PMON_BOX_CTL\t\t0xa30\n#define KNL_EDC0_ECLK_MSR_PMON_ECLK_FIXED_LOW\t0xa3c\n#define KNL_EDC0_ECLK_MSR_PMON_ECLK_FIXED_CTL\t0xa44\n\n \n#define KNL_MC0_CH0_MSR_PMON_CTR0_LOW\t\t0xb00\n#define KNL_MC0_CH0_MSR_PMON_CTL0\t\t0xb20\n#define KNL_MC0_CH0_MSR_PMON_BOX_CTL\t\t0xb30\n#define KNL_MC0_CH0_MSR_PMON_FIXED_LOW\t\t0xb3c\n#define KNL_MC0_CH0_MSR_PMON_FIXED_CTL\t\t0xb44\n\n \n#define KNL_IRP_PCI_PMON_BOX_CTL\t\t0xf0\n#define KNL_IRP_PCI_PMON_RAW_EVENT_MASK\t\t(SNBEP_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t\t\t KNL_CHA_MSR_PMON_CTL_QOR)\n \n#define KNL_PCU_PMON_CTL_EV_SEL_MASK\t\t0x0000007f\n#define KNL_PCU_PMON_CTL_USE_OCC_CTR\t\t(1 << 7)\n#define KNL_PCU_MSR_PMON_CTL_TRESH_MASK\t\t0x3f000000\n#define KNL_PCU_MSR_PMON_RAW_EVENT_MASK\t\\\n\t\t\t\t(KNL_PCU_PMON_CTL_EV_SEL_MASK | \\\n\t\t\t\t KNL_PCU_PMON_CTL_USE_OCC_CTR | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_OCC_SEL_MASK | \\\n\t\t\t\t SNBEP_PMON_CTL_EDGE_DET | \\\n\t\t\t\t SNBEP_CBO_PMON_CTL_TID_EN | \\\n\t\t\t\t SNBEP_PMON_CTL_INVERT | \\\n\t\t\t\t KNL_PCU_MSR_PMON_CTL_TRESH_MASK | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_OCC_INVERT | \\\n\t\t\t\t SNBEP_PCU_MSR_PMON_CTL_OCC_EDGE_DET)\n\n \n#define SKX_CPUNODEID\t\t\t0xc0\n#define SKX_GIDNIDMAP\t\t\t0xd4\n\n \n#define SKX_MSR_CPU_BUS_NUMBER\t\t0x300\n#define SKX_MSR_CPU_BUS_VALID_BIT\t(1ULL << 63)\n#define BUS_NUM_STRIDE\t\t\t8\n\n \n#define SKX_CHA_MSR_PMON_BOX_FILTER_TID\t\t(0x1ffULL << 0)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_LINK\t(0xfULL << 9)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_STATE\t(0x3ffULL << 17)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_REM\t\t(0x1ULL << 32)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_LOC\t\t(0x1ULL << 33)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_ALL_OPC\t(0x1ULL << 35)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_NM\t\t(0x1ULL << 36)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_NOT_NM\t(0x1ULL << 37)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_OPC0\t(0x3ffULL << 41)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_OPC1\t(0x3ffULL << 51)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_C6\t\t(0x1ULL << 61)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_NC\t\t(0x1ULL << 62)\n#define SKX_CHA_MSR_PMON_BOX_FILTER_ISOC\t(0x1ULL << 63)\n\n \n#define SKX_IIO0_MSR_PMON_CTL0\t\t0xa48\n#define SKX_IIO0_MSR_PMON_CTR0\t\t0xa41\n#define SKX_IIO0_MSR_PMON_BOX_CTL\t0xa40\n#define SKX_IIO_MSR_OFFSET\t\t0x20\n\n#define SKX_PMON_CTL_TRESH_MASK\t\t(0xff << 24)\n#define SKX_PMON_CTL_TRESH_MASK_EXT\t(0xf)\n#define SKX_PMON_CTL_CH_MASK\t\t(0xff << 4)\n#define SKX_PMON_CTL_FC_MASK\t\t(0x7 << 12)\n#define SKX_IIO_PMON_RAW_EVENT_MASK\t(SNBEP_PMON_CTL_EV_SEL_MASK | \\\n\t\t\t\t\t SNBEP_PMON_CTL_UMASK_MASK | \\\n\t\t\t\t\t SNBEP_PMON_CTL_EDGE_DET | \\\n\t\t\t\t\t SNBEP_PMON_CTL_INVERT | \\\n\t\t\t\t\t SKX_PMON_CTL_TRESH_MASK)\n#define SKX_IIO_PMON_RAW_EVENT_MASK_EXT\t(SKX_PMON_CTL_TRESH_MASK_EXT | \\\n\t\t\t\t\t SKX_PMON_CTL_CH_MASK | \\\n\t\t\t\t\t SKX_PMON_CTL_FC_MASK)\n\n \n#define SKX_IRP0_MSR_PMON_CTL0\t\t0xa5b\n#define SKX_IRP0_MSR_PMON_CTR0\t\t0xa59\n#define SKX_IRP0_MSR_PMON_BOX_CTL\t0xa58\n#define SKX_IRP_MSR_OFFSET\t\t0x20\n\n \n#define SKX_UPI_PCI_PMON_CTL0\t\t0x350\n#define SKX_UPI_PCI_PMON_CTR0\t\t0x318\n#define SKX_UPI_PCI_PMON_BOX_CTL\t0x378\n#define SKX_UPI_CTL_UMASK_EXT\t\t0xffefff\n\n \n#define SKX_M2M_PCI_PMON_CTL0\t\t0x228\n#define SKX_M2M_PCI_PMON_CTR0\t\t0x200\n#define SKX_M2M_PCI_PMON_BOX_CTL\t0x258\n\n \n#define SNR_ICX_MESH2IIO_MMAP_DID\t\t0x9a2\n#define SNR_ICX_SAD_CONTROL_CFG\t\t0x3f4\n\n \n#define SAD_CONTROL_STACK_ID(data)\t\t(((data) >> 4) & 0x7)\n\n \n#define SNR_U_MSR_PMON_CTR0\t\t\t0x1f98\n#define SNR_U_MSR_PMON_CTL0\t\t\t0x1f91\n#define SNR_U_MSR_PMON_UCLK_FIXED_CTL\t\t0x1f93\n#define SNR_U_MSR_PMON_UCLK_FIXED_CTR\t\t0x1f94\n\n \n#define SNR_CHA_RAW_EVENT_MASK_EXT\t\t0x3ffffff\n#define SNR_CHA_MSR_PMON_CTL0\t\t\t0x1c01\n#define SNR_CHA_MSR_PMON_CTR0\t\t\t0x1c08\n#define SNR_CHA_MSR_PMON_BOX_CTL\t\t0x1c00\n#define SNR_C0_MSR_PMON_BOX_FILTER0\t\t0x1c05\n\n\n \n#define SNR_IIO_MSR_PMON_CTL0\t\t\t0x1e08\n#define SNR_IIO_MSR_PMON_CTR0\t\t\t0x1e01\n#define SNR_IIO_MSR_PMON_BOX_CTL\t\t0x1e00\n#define SNR_IIO_MSR_OFFSET\t\t\t0x10\n#define SNR_IIO_PMON_RAW_EVENT_MASK_EXT\t\t0x7ffff\n\n \n#define SNR_IRP0_MSR_PMON_CTL0\t\t\t0x1ea8\n#define SNR_IRP0_MSR_PMON_CTR0\t\t\t0x1ea1\n#define SNR_IRP0_MSR_PMON_BOX_CTL\t\t0x1ea0\n#define SNR_IRP_MSR_OFFSET\t\t\t0x10\n\n \n#define SNR_M2PCIE_MSR_PMON_CTL0\t\t0x1e58\n#define SNR_M2PCIE_MSR_PMON_CTR0\t\t0x1e51\n#define SNR_M2PCIE_MSR_PMON_BOX_CTL\t\t0x1e50\n#define SNR_M2PCIE_MSR_OFFSET\t\t\t0x10\n\n \n#define SNR_PCU_MSR_PMON_CTL0\t\t\t0x1ef1\n#define SNR_PCU_MSR_PMON_CTR0\t\t\t0x1ef8\n#define SNR_PCU_MSR_PMON_BOX_CTL\t\t0x1ef0\n#define SNR_PCU_MSR_PMON_BOX_FILTER\t\t0x1efc\n\n \n#define SNR_M2M_PCI_PMON_CTL0\t\t\t0x468\n#define SNR_M2M_PCI_PMON_CTR0\t\t\t0x440\n#define SNR_M2M_PCI_PMON_BOX_CTL\t\t0x438\n#define SNR_M2M_PCI_PMON_UMASK_EXT\t\t0xff\n\n \n#define SNR_PCIE3_PCI_PMON_CTL0\t\t\t0x508\n#define SNR_PCIE3_PCI_PMON_CTR0\t\t\t0x4e8\n#define SNR_PCIE3_PCI_PMON_BOX_CTL\t\t0x4e0\n\n \n#define SNR_IMC_MMIO_PMON_FIXED_CTL\t\t0x54\n#define SNR_IMC_MMIO_PMON_FIXED_CTR\t\t0x38\n#define SNR_IMC_MMIO_PMON_CTL0\t\t\t0x40\n#define SNR_IMC_MMIO_PMON_CTR0\t\t\t0x8\n#define SNR_IMC_MMIO_PMON_BOX_CTL\t\t0x22800\n#define SNR_IMC_MMIO_OFFSET\t\t\t0x4000\n#define SNR_IMC_MMIO_SIZE\t\t\t0x4000\n#define SNR_IMC_MMIO_BASE_OFFSET\t\t0xd0\n#define SNR_IMC_MMIO_BASE_MASK\t\t\t0x1FFFFFFF\n#define SNR_IMC_MMIO_MEM0_OFFSET\t\t0xd8\n#define SNR_IMC_MMIO_MEM0_MASK\t\t\t0x7FF\n\n \n#define ICX_C34_MSR_PMON_CTR0\t\t\t0xb68\n#define ICX_C34_MSR_PMON_CTL0\t\t\t0xb61\n#define ICX_C34_MSR_PMON_BOX_CTL\t\t0xb60\n#define ICX_C34_MSR_PMON_BOX_FILTER0\t\t0xb65\n\n \n#define ICX_IIO_MSR_PMON_CTL0\t\t\t0xa58\n#define ICX_IIO_MSR_PMON_CTR0\t\t\t0xa51\n#define ICX_IIO_MSR_PMON_BOX_CTL\t\t0xa50\n\n \n#define ICX_IRP0_MSR_PMON_CTL0\t\t\t0xa4d\n#define ICX_IRP0_MSR_PMON_CTR0\t\t\t0xa4b\n#define ICX_IRP0_MSR_PMON_BOX_CTL\t\t0xa4a\n\n \n#define ICX_M2PCIE_MSR_PMON_CTL0\t\t0xa46\n#define ICX_M2PCIE_MSR_PMON_CTR0\t\t0xa41\n#define ICX_M2PCIE_MSR_PMON_BOX_CTL\t\t0xa40\n\n \n#define ICX_UPI_PCI_PMON_CTL0\t\t\t0x350\n#define ICX_UPI_PCI_PMON_CTR0\t\t\t0x320\n#define ICX_UPI_PCI_PMON_BOX_CTL\t\t0x318\n#define ICX_UPI_CTL_UMASK_EXT\t\t\t0xffffff\n#define ICX_UBOX_DID\t\t\t\t0x3450\n\n \n#define ICX_M3UPI_PCI_PMON_CTL0\t\t\t0xd8\n#define ICX_M3UPI_PCI_PMON_CTR0\t\t\t0xa8\n#define ICX_M3UPI_PCI_PMON_BOX_CTL\t\t0xa0\n\n \n#define ICX_NUMBER_IMC_CHN\t\t\t3\n#define ICX_IMC_MEM_STRIDE\t\t\t0x4\n\n \n#define SPR_RAW_EVENT_MASK_EXT\t\t\t0xffffff\n#define SPR_UBOX_DID\t\t\t\t0x3250\n\n \n#define SPR_CHA_PMON_CTL_TID_EN\t\t\t(1 << 16)\n#define SPR_CHA_PMON_EVENT_MASK\t\t\t(SNBEP_PMON_RAW_EVENT_MASK | \\\n\t\t\t\t\t\t SPR_CHA_PMON_CTL_TID_EN)\n#define SPR_CHA_PMON_BOX_FILTER_TID\t\t0x3ff\n\n#define SPR_C0_MSR_PMON_BOX_FILTER0\t\t0x200e\n\nDEFINE_UNCORE_FORMAT_ATTR(event, event, \"config:0-7\");\nDEFINE_UNCORE_FORMAT_ATTR(event2, event, \"config:0-6\");\nDEFINE_UNCORE_FORMAT_ATTR(event_ext, event, \"config:0-7,21\");\nDEFINE_UNCORE_FORMAT_ATTR(use_occ_ctr, use_occ_ctr, \"config:7\");\nDEFINE_UNCORE_FORMAT_ATTR(umask, umask, \"config:8-15\");\nDEFINE_UNCORE_FORMAT_ATTR(umask_ext, umask, \"config:8-15,32-43,45-55\");\nDEFINE_UNCORE_FORMAT_ATTR(umask_ext2, umask, \"config:8-15,32-57\");\nDEFINE_UNCORE_FORMAT_ATTR(umask_ext3, umask, \"config:8-15,32-39\");\nDEFINE_UNCORE_FORMAT_ATTR(umask_ext4, umask, \"config:8-15,32-55\");\nDEFINE_UNCORE_FORMAT_ATTR(qor, qor, \"config:16\");\nDEFINE_UNCORE_FORMAT_ATTR(edge, edge, \"config:18\");\nDEFINE_UNCORE_FORMAT_ATTR(tid_en, tid_en, \"config:19\");\nDEFINE_UNCORE_FORMAT_ATTR(tid_en2, tid_en, \"config:16\");\nDEFINE_UNCORE_FORMAT_ATTR(inv, inv, \"config:23\");\nDEFINE_UNCORE_FORMAT_ATTR(thresh9, thresh, \"config:24-35\");\nDEFINE_UNCORE_FORMAT_ATTR(thresh8, thresh, \"config:24-31\");\nDEFINE_UNCORE_FORMAT_ATTR(thresh6, thresh, \"config:24-29\");\nDEFINE_UNCORE_FORMAT_ATTR(thresh5, thresh, \"config:24-28\");\nDEFINE_UNCORE_FORMAT_ATTR(occ_sel, occ_sel, \"config:14-15\");\nDEFINE_UNCORE_FORMAT_ATTR(occ_invert, occ_invert, \"config:30\");\nDEFINE_UNCORE_FORMAT_ATTR(occ_edge, occ_edge, \"config:14-51\");\nDEFINE_UNCORE_FORMAT_ATTR(occ_edge_det, occ_edge_det, \"config:31\");\nDEFINE_UNCORE_FORMAT_ATTR(ch_mask, ch_mask, \"config:36-43\");\nDEFINE_UNCORE_FORMAT_ATTR(ch_mask2, ch_mask, \"config:36-47\");\nDEFINE_UNCORE_FORMAT_ATTR(fc_mask, fc_mask, \"config:44-46\");\nDEFINE_UNCORE_FORMAT_ATTR(fc_mask2, fc_mask, \"config:48-50\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_tid, filter_tid, \"config1:0-4\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_tid2, filter_tid, \"config1:0\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_tid3, filter_tid, \"config1:0-5\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_tid4, filter_tid, \"config1:0-8\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_tid5, filter_tid, \"config1:0-9\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_cid, filter_cid, \"config1:5\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_link, filter_link, \"config1:5-8\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_link2, filter_link, \"config1:6-8\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_link3, filter_link, \"config1:12\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_nid, filter_nid, \"config1:10-17\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_nid2, filter_nid, \"config1:32-47\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_state, filter_state, \"config1:18-22\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_state2, filter_state, \"config1:17-22\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_state3, filter_state, \"config1:17-23\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_state4, filter_state, \"config1:18-20\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_state5, filter_state, \"config1:17-26\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_rem, filter_rem, \"config1:32\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_loc, filter_loc, \"config1:33\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_nm, filter_nm, \"config1:36\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_not_nm, filter_not_nm, \"config1:37\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_local, filter_local, \"config1:33\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_all_op, filter_all_op, \"config1:35\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_nnm, filter_nnm, \"config1:37\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_opc, filter_opc, \"config1:23-31\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_opc2, filter_opc, \"config1:52-60\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_opc3, filter_opc, \"config1:41-60\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_opc_0, filter_opc0, \"config1:41-50\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_opc_1, filter_opc1, \"config1:51-60\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_nc, filter_nc, \"config1:62\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_c6, filter_c6, \"config1:61\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_isoc, filter_isoc, \"config1:63\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_band0, filter_band0, \"config1:0-7\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_band1, filter_band1, \"config1:8-15\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_band2, filter_band2, \"config1:16-23\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_band3, filter_band3, \"config1:24-31\");\nDEFINE_UNCORE_FORMAT_ATTR(match_rds, match_rds, \"config1:48-51\");\nDEFINE_UNCORE_FORMAT_ATTR(match_rnid30, match_rnid30, \"config1:32-35\");\nDEFINE_UNCORE_FORMAT_ATTR(match_rnid4, match_rnid4, \"config1:31\");\nDEFINE_UNCORE_FORMAT_ATTR(match_dnid, match_dnid, \"config1:13-17\");\nDEFINE_UNCORE_FORMAT_ATTR(match_mc, match_mc, \"config1:9-12\");\nDEFINE_UNCORE_FORMAT_ATTR(match_opc, match_opc, \"config1:5-8\");\nDEFINE_UNCORE_FORMAT_ATTR(match_vnw, match_vnw, \"config1:3-4\");\nDEFINE_UNCORE_FORMAT_ATTR(match0, match0, \"config1:0-31\");\nDEFINE_UNCORE_FORMAT_ATTR(match1, match1, \"config1:32-63\");\nDEFINE_UNCORE_FORMAT_ATTR(mask_rds, mask_rds, \"config2:48-51\");\nDEFINE_UNCORE_FORMAT_ATTR(mask_rnid30, mask_rnid30, \"config2:32-35\");\nDEFINE_UNCORE_FORMAT_ATTR(mask_rnid4, mask_rnid4, \"config2:31\");\nDEFINE_UNCORE_FORMAT_ATTR(mask_dnid, mask_dnid, \"config2:13-17\");\nDEFINE_UNCORE_FORMAT_ATTR(mask_mc, mask_mc, \"config2:9-12\");\nDEFINE_UNCORE_FORMAT_ATTR(mask_opc, mask_opc, \"config2:5-8\");\nDEFINE_UNCORE_FORMAT_ATTR(mask_vnw, mask_vnw, \"config2:3-4\");\nDEFINE_UNCORE_FORMAT_ATTR(mask0, mask0, \"config2:0-31\");\nDEFINE_UNCORE_FORMAT_ATTR(mask1, mask1, \"config2:32-63\");\n\nstatic void snbep_uncore_pci_disable_box(struct intel_uncore_box *box)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tint box_ctl = uncore_pci_box_ctl(box);\n\tu32 config = 0;\n\n\tif (!pci_read_config_dword(pdev, box_ctl, &config)) {\n\t\tconfig |= SNBEP_PMON_BOX_CTL_FRZ;\n\t\tpci_write_config_dword(pdev, box_ctl, config);\n\t}\n}\n\nstatic void snbep_uncore_pci_enable_box(struct intel_uncore_box *box)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tint box_ctl = uncore_pci_box_ctl(box);\n\tu32 config = 0;\n\n\tif (!pci_read_config_dword(pdev, box_ctl, &config)) {\n\t\tconfig &= ~SNBEP_PMON_BOX_CTL_FRZ;\n\t\tpci_write_config_dword(pdev, box_ctl, config);\n\t}\n}\n\nstatic void snbep_uncore_pci_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tpci_write_config_dword(pdev, hwc->config_base, hwc->config | SNBEP_PMON_CTL_EN);\n}\n\nstatic void snbep_uncore_pci_disable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tpci_write_config_dword(pdev, hwc->config_base, hwc->config);\n}\n\nstatic u64 snbep_uncore_pci_read_counter(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\tu64 count = 0;\n\n\tpci_read_config_dword(pdev, hwc->event_base, (u32 *)&count);\n\tpci_read_config_dword(pdev, hwc->event_base + 4, (u32 *)&count + 1);\n\n\treturn count;\n}\n\nstatic void snbep_uncore_pci_init_box(struct intel_uncore_box *box)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tint box_ctl = uncore_pci_box_ctl(box);\n\n\tpci_write_config_dword(pdev, box_ctl, SNBEP_PMON_BOX_CTL_INT);\n}\n\nstatic void snbep_uncore_msr_disable_box(struct intel_uncore_box *box)\n{\n\tu64 config;\n\tunsigned msr;\n\n\tmsr = uncore_msr_box_ctl(box);\n\tif (msr) {\n\t\trdmsrl(msr, config);\n\t\tconfig |= SNBEP_PMON_BOX_CTL_FRZ;\n\t\twrmsrl(msr, config);\n\t}\n}\n\nstatic void snbep_uncore_msr_enable_box(struct intel_uncore_box *box)\n{\n\tu64 config;\n\tunsigned msr;\n\n\tmsr = uncore_msr_box_ctl(box);\n\tif (msr) {\n\t\trdmsrl(msr, config);\n\t\tconfig &= ~SNBEP_PMON_BOX_CTL_FRZ;\n\t\twrmsrl(msr, config);\n\t}\n}\n\nstatic void snbep_uncore_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\n\tif (reg1->idx != EXTRA_REG_NONE)\n\t\twrmsrl(reg1->reg, uncore_shared_reg_config(box, 0));\n\n\twrmsrl(hwc->config_base, hwc->config | SNBEP_PMON_CTL_EN);\n}\n\nstatic void snbep_uncore_msr_disable_event(struct intel_uncore_box *box,\n\t\t\t\t\tstruct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\twrmsrl(hwc->config_base, hwc->config);\n}\n\nstatic void snbep_uncore_msr_init_box(struct intel_uncore_box *box)\n{\n\tunsigned msr = uncore_msr_box_ctl(box);\n\n\tif (msr)\n\t\twrmsrl(msr, SNBEP_PMON_BOX_CTL_INT);\n}\n\nstatic struct attribute *snbep_uncore_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic struct attribute *snbep_uncore_ubox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh5.attr,\n\tNULL,\n};\n\nstatic struct attribute *snbep_uncore_cbox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_tid_en.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_filter_tid.attr,\n\t&format_attr_filter_nid.attr,\n\t&format_attr_filter_state.attr,\n\t&format_attr_filter_opc.attr,\n\tNULL,\n};\n\nstatic struct attribute *snbep_uncore_pcu_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_occ_sel.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh5.attr,\n\t&format_attr_occ_invert.attr,\n\t&format_attr_occ_edge.attr,\n\t&format_attr_filter_band0.attr,\n\t&format_attr_filter_band1.attr,\n\t&format_attr_filter_band2.attr,\n\t&format_attr_filter_band3.attr,\n\tNULL,\n};\n\nstatic struct attribute *snbep_uncore_qpi_formats_attr[] = {\n\t&format_attr_event_ext.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_match_rds.attr,\n\t&format_attr_match_rnid30.attr,\n\t&format_attr_match_rnid4.attr,\n\t&format_attr_match_dnid.attr,\n\t&format_attr_match_mc.attr,\n\t&format_attr_match_opc.attr,\n\t&format_attr_match_vnw.attr,\n\t&format_attr_match0.attr,\n\t&format_attr_match1.attr,\n\t&format_attr_mask_rds.attr,\n\t&format_attr_mask_rnid30.attr,\n\t&format_attr_mask_rnid4.attr,\n\t&format_attr_mask_dnid.attr,\n\t&format_attr_mask_mc.attr,\n\t&format_attr_mask_opc.attr,\n\t&format_attr_mask_vnw.attr,\n\t&format_attr_mask0.attr,\n\t&format_attr_mask1.attr,\n\tNULL,\n};\n\nstatic struct uncore_event_desc snbep_uncore_imc_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(clockticks,      \"event=0xff,umask=0x00\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read,  \"event=0x04,umask=0x03\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read.unit, \"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write, \"event=0x04,umask=0x0c\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write.unit, \"MiB\"),\n\t{   },\n};\n\nstatic struct uncore_event_desc snbep_uncore_qpi_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(clockticks,       \"event=0x14\"),\n\tINTEL_UNCORE_EVENT_DESC(txl_flits_active, \"event=0x00,umask=0x06\"),\n\tINTEL_UNCORE_EVENT_DESC(drs_data,         \"event=0x102,umask=0x08\"),\n\tINTEL_UNCORE_EVENT_DESC(ncb_data,         \"event=0x103,umask=0x04\"),\n\t{   },\n};\n\nstatic const struct attribute_group snbep_uncore_format_group = {\n\t.name = \"format\",\n\t.attrs = snbep_uncore_formats_attr,\n};\n\nstatic const struct attribute_group snbep_uncore_ubox_format_group = {\n\t.name = \"format\",\n\t.attrs = snbep_uncore_ubox_formats_attr,\n};\n\nstatic const struct attribute_group snbep_uncore_cbox_format_group = {\n\t.name = \"format\",\n\t.attrs = snbep_uncore_cbox_formats_attr,\n};\n\nstatic const struct attribute_group snbep_uncore_pcu_format_group = {\n\t.name = \"format\",\n\t.attrs = snbep_uncore_pcu_formats_attr,\n};\n\nstatic const struct attribute_group snbep_uncore_qpi_format_group = {\n\t.name = \"format\",\n\t.attrs = snbep_uncore_qpi_formats_attr,\n};\n\n#define __SNBEP_UNCORE_MSR_OPS_COMMON_INIT()\t\t\t\\\n\t.disable_box\t= snbep_uncore_msr_disable_box,\t\t\\\n\t.enable_box\t= snbep_uncore_msr_enable_box,\t\t\\\n\t.disable_event\t= snbep_uncore_msr_disable_event,\t\\\n\t.enable_event\t= snbep_uncore_msr_enable_event,\t\\\n\t.read_counter\t= uncore_msr_read_counter\n\n#define SNBEP_UNCORE_MSR_OPS_COMMON_INIT()\t\t\t\\\n\t__SNBEP_UNCORE_MSR_OPS_COMMON_INIT(),\t\t\t\\\n\t.init_box\t= snbep_uncore_msr_init_box\t\t\\\n\nstatic struct intel_uncore_ops snbep_uncore_msr_ops = {\n\tSNBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n};\n\n#define SNBEP_UNCORE_PCI_OPS_COMMON_INIT()\t\t\t\\\n\t.init_box\t= snbep_uncore_pci_init_box,\t\t\\\n\t.disable_box\t= snbep_uncore_pci_disable_box,\t\t\\\n\t.enable_box\t= snbep_uncore_pci_enable_box,\t\t\\\n\t.disable_event\t= snbep_uncore_pci_disable_event,\t\\\n\t.read_counter\t= snbep_uncore_pci_read_counter\n\nstatic struct intel_uncore_ops snbep_uncore_pci_ops = {\n\tSNBEP_UNCORE_PCI_OPS_COMMON_INIT(),\n\t.enable_event\t= snbep_uncore_pci_enable_event,\t\\\n};\n\nstatic struct event_constraint snbep_uncore_cbox_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x01, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x02, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x04, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x05, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x07, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x09, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x12, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x13, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x1b, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0x1c, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0x1d, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0x1e, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0x1f, 0xe),\n\tUNCORE_EVENT_CONSTRAINT(0x21, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x31, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x32, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x33, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x34, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x35, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x36, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x37, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x38, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x39, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x3b, 0x1),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct event_constraint snbep_uncore_r2pcie_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x10, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x12, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x24, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x25, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x26, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x32, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x33, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x34, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct event_constraint snbep_uncore_r3qpi_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x10, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x12, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x13, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x20, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x21, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x22, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x24, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x25, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x26, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x28, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x29, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2a, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2b, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2c, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2d, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2e, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2f, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x30, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x31, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x32, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x33, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x34, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x36, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x37, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x38, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x39, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type snbep_uncore_ubox = {\n\t.name\t\t= \"ubox\",\n\t.num_counters   = 2,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 44,\n\t.fixed_ctr_bits\t= 48,\n\t.perf_ctr\t= SNBEP_U_MSR_PMON_CTR0,\n\t.event_ctl\t= SNBEP_U_MSR_PMON_CTL0,\n\t.event_mask\t= SNBEP_U_MSR_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t= SNBEP_U_MSR_PMON_UCLK_FIXED_CTR,\n\t.fixed_ctl\t= SNBEP_U_MSR_PMON_UCLK_FIXED_CTL,\n\t.ops\t\t= &snbep_uncore_msr_ops,\n\t.format_group\t= &snbep_uncore_ubox_format_group,\n};\n\nstatic struct extra_reg snbep_uncore_cbox_extra_regs[] = {\n\tSNBEP_CBO_EVENT_EXTRA_REG(SNBEP_CBO_PMON_CTL_TID_EN,\n\t\t\t\t  SNBEP_CBO_PMON_CTL_TID_EN, 0x1),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0334, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4334, 0xffff, 0x6),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0534, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4534, 0xffff, 0x6),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0934, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4934, 0xffff, 0x6),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4134, 0xffff, 0x6),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0135, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0335, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4135, 0xffff, 0xa),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4335, 0xffff, 0xa),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4435, 0xffff, 0x2),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4835, 0xffff, 0x2),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4a35, 0xffff, 0x2),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x5035, 0xffff, 0x2),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0136, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0336, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4136, 0xffff, 0xa),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4336, 0xffff, 0xa),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4436, 0xffff, 0x2),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4836, 0xffff, 0x2),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4a36, 0xffff, 0x2),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4037, 0x40ff, 0x2),\n\tEVENT_EXTRA_END\n};\n\nstatic void snbep_cbox_put_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct intel_uncore_extra_reg *er = &box->shared_regs[0];\n\tint i;\n\n\tif (uncore_box_is_fake(box))\n\t\treturn;\n\n\tfor (i = 0; i < 5; i++) {\n\t\tif (reg1->alloc & (0x1 << i))\n\t\t\tatomic_sub(1 << (i * 6), &er->ref);\n\t}\n\treg1->alloc = 0;\n}\n\nstatic struct event_constraint *\n__snbep_cbox_get_constraint(struct intel_uncore_box *box, struct perf_event *event,\n\t\t\t    u64 (*cbox_filter_mask)(int fields))\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct intel_uncore_extra_reg *er = &box->shared_regs[0];\n\tint i, alloc = 0;\n\tunsigned long flags;\n\tu64 mask;\n\n\tif (reg1->idx == EXTRA_REG_NONE)\n\t\treturn NULL;\n\n\traw_spin_lock_irqsave(&er->lock, flags);\n\tfor (i = 0; i < 5; i++) {\n\t\tif (!(reg1->idx & (0x1 << i)))\n\t\t\tcontinue;\n\t\tif (!uncore_box_is_fake(box) && (reg1->alloc & (0x1 << i)))\n\t\t\tcontinue;\n\n\t\tmask = cbox_filter_mask(0x1 << i);\n\t\tif (!__BITS_VALUE(atomic_read(&er->ref), i, 6) ||\n\t\t    !((reg1->config ^ er->config) & mask)) {\n\t\t\tatomic_add(1 << (i * 6), &er->ref);\n\t\t\ter->config &= ~mask;\n\t\t\ter->config |= reg1->config & mask;\n\t\t\talloc |= (0x1 << i);\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n\traw_spin_unlock_irqrestore(&er->lock, flags);\n\tif (i < 5)\n\t\tgoto fail;\n\n\tif (!uncore_box_is_fake(box))\n\t\treg1->alloc |= alloc;\n\n\treturn NULL;\nfail:\n\tfor (; i >= 0; i--) {\n\t\tif (alloc & (0x1 << i))\n\t\t\tatomic_sub(1 << (i * 6), &er->ref);\n\t}\n\treturn &uncore_constraint_empty;\n}\n\nstatic u64 snbep_cbox_filter_mask(int fields)\n{\n\tu64 mask = 0;\n\n\tif (fields & 0x1)\n\t\tmask |= SNBEP_CB0_MSR_PMON_BOX_FILTER_TID;\n\tif (fields & 0x2)\n\t\tmask |= SNBEP_CB0_MSR_PMON_BOX_FILTER_NID;\n\tif (fields & 0x4)\n\t\tmask |= SNBEP_CB0_MSR_PMON_BOX_FILTER_STATE;\n\tif (fields & 0x8)\n\t\tmask |= SNBEP_CB0_MSR_PMON_BOX_FILTER_OPC;\n\n\treturn mask;\n}\n\nstatic struct event_constraint *\nsnbep_cbox_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\treturn __snbep_cbox_get_constraint(box, event, snbep_cbox_filter_mask);\n}\n\nstatic int snbep_cbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct extra_reg *er;\n\tint idx = 0;\n\n\tfor (er = snbep_uncore_cbox_extra_regs; er->msr; er++) {\n\t\tif (er->event != (event->hw.config & er->config_mask))\n\t\t\tcontinue;\n\t\tidx |= er->idx;\n\t}\n\n\tif (idx) {\n\t\treg1->reg = SNBEP_C0_MSR_PMON_BOX_FILTER +\n\t\t\tSNBEP_CBO_MSR_OFFSET * box->pmu->pmu_idx;\n\t\treg1->config = event->attr.config1 & snbep_cbox_filter_mask(idx);\n\t\treg1->idx = idx;\n\t}\n\treturn 0;\n}\n\nstatic struct intel_uncore_ops snbep_uncore_cbox_ops = {\n\tSNBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n\t.hw_config\t\t= snbep_cbox_hw_config,\n\t.get_constraint\t\t= snbep_cbox_get_constraint,\n\t.put_constraint\t\t= snbep_cbox_put_constraint,\n};\n\nstatic struct intel_uncore_type snbep_uncore_cbox = {\n\t.name\t\t\t= \"cbox\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 8,\n\t.perf_ctr_bits\t\t= 44,\n\t.event_ctl\t\t= SNBEP_C0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= SNBEP_C0_MSR_PMON_CTR0,\n\t.event_mask\t\t= SNBEP_CBO_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_C0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= SNBEP_CBO_MSR_OFFSET,\n\t.num_shared_regs\t= 1,\n\t.constraints\t\t= snbep_uncore_cbox_constraints,\n\t.ops\t\t\t= &snbep_uncore_cbox_ops,\n\t.format_group\t\t= &snbep_uncore_cbox_format_group,\n};\n\nstatic u64 snbep_pcu_alter_er(struct perf_event *event, int new_idx, bool modify)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tu64 config = reg1->config;\n\n\tif (new_idx > reg1->idx)\n\t\tconfig <<= 8 * (new_idx - reg1->idx);\n\telse\n\t\tconfig >>= 8 * (reg1->idx - new_idx);\n\n\tif (modify) {\n\t\thwc->config += new_idx - reg1->idx;\n\t\treg1->config = config;\n\t\treg1->idx = new_idx;\n\t}\n\treturn config;\n}\n\nstatic struct event_constraint *\nsnbep_pcu_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct intel_uncore_extra_reg *er = &box->shared_regs[0];\n\tunsigned long flags;\n\tint idx = reg1->idx;\n\tu64 mask, config1 = reg1->config;\n\tbool ok = false;\n\n\tif (reg1->idx == EXTRA_REG_NONE ||\n\t    (!uncore_box_is_fake(box) && reg1->alloc))\n\t\treturn NULL;\nagain:\n\tmask = 0xffULL << (idx * 8);\n\traw_spin_lock_irqsave(&er->lock, flags);\n\tif (!__BITS_VALUE(atomic_read(&er->ref), idx, 8) ||\n\t    !((config1 ^ er->config) & mask)) {\n\t\tatomic_add(1 << (idx * 8), &er->ref);\n\t\ter->config &= ~mask;\n\t\ter->config |= config1 & mask;\n\t\tok = true;\n\t}\n\traw_spin_unlock_irqrestore(&er->lock, flags);\n\n\tif (!ok) {\n\t\tidx = (idx + 1) % 4;\n\t\tif (idx != reg1->idx) {\n\t\t\tconfig1 = snbep_pcu_alter_er(event, idx, false);\n\t\t\tgoto again;\n\t\t}\n\t\treturn &uncore_constraint_empty;\n\t}\n\n\tif (!uncore_box_is_fake(box)) {\n\t\tif (idx != reg1->idx)\n\t\t\tsnbep_pcu_alter_er(event, idx, true);\n\t\treg1->alloc = 1;\n\t}\n\treturn NULL;\n}\n\nstatic void snbep_pcu_put_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct intel_uncore_extra_reg *er = &box->shared_regs[0];\n\n\tif (uncore_box_is_fake(box) || !reg1->alloc)\n\t\treturn;\n\n\tatomic_sub(1 << (reg1->idx * 8), &er->ref);\n\treg1->alloc = 0;\n}\n\nstatic int snbep_pcu_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tint ev_sel = hwc->config & SNBEP_PMON_CTL_EV_SEL_MASK;\n\n\tif (ev_sel >= 0xb && ev_sel <= 0xe) {\n\t\treg1->reg = SNBEP_PCU_MSR_PMON_BOX_FILTER;\n\t\treg1->idx = ev_sel - 0xb;\n\t\treg1->config = event->attr.config1 & (0xff << (reg1->idx * 8));\n\t}\n\treturn 0;\n}\n\nstatic struct intel_uncore_ops snbep_uncore_pcu_ops = {\n\tSNBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n\t.hw_config\t\t= snbep_pcu_hw_config,\n\t.get_constraint\t\t= snbep_pcu_get_constraint,\n\t.put_constraint\t\t= snbep_pcu_put_constraint,\n};\n\nstatic struct intel_uncore_type snbep_uncore_pcu = {\n\t.name\t\t\t= \"pcu\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= SNBEP_PCU_MSR_PMON_CTR0,\n\t.event_ctl\t\t= SNBEP_PCU_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_PCU_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_PCU_MSR_PMON_BOX_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &snbep_uncore_pcu_ops,\n\t.format_group\t\t= &snbep_uncore_pcu_format_group,\n};\n\nstatic struct intel_uncore_type *snbep_msr_uncores[] = {\n\t&snbep_uncore_ubox,\n\t&snbep_uncore_cbox,\n\t&snbep_uncore_pcu,\n\tNULL,\n};\n\nvoid snbep_uncore_cpu_init(void)\n{\n\tif (snbep_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)\n\t\tsnbep_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;\n\tuncore_msr_uncores = snbep_msr_uncores;\n}\n\nenum {\n\tSNBEP_PCI_QPI_PORT0_FILTER,\n\tSNBEP_PCI_QPI_PORT1_FILTER,\n\tBDX_PCI_QPI_PORT2_FILTER,\n};\n\nstatic int snbep_qpi_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\n\n\tif ((hwc->config & SNBEP_PMON_CTL_EV_SEL_MASK) == 0x38) {\n\t\treg1->idx = 0;\n\t\treg1->reg = SNBEP_Q_Py_PCI_PMON_PKT_MATCH0;\n\t\treg1->config = event->attr.config1;\n\t\treg2->reg = SNBEP_Q_Py_PCI_PMON_PKT_MASK0;\n\t\treg2->config = event->attr.config2;\n\t}\n\treturn 0;\n}\n\nstatic void snbep_qpi_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\n\n\tif (reg1->idx != EXTRA_REG_NONE) {\n\t\tint idx = box->pmu->pmu_idx + SNBEP_PCI_QPI_PORT0_FILTER;\n\t\tint die = box->dieid;\n\t\tstruct pci_dev *filter_pdev = uncore_extra_pci_dev[die].dev[idx];\n\n\t\tif (filter_pdev) {\n\t\t\tpci_write_config_dword(filter_pdev, reg1->reg,\n\t\t\t\t\t\t(u32)reg1->config);\n\t\t\tpci_write_config_dword(filter_pdev, reg1->reg + 4,\n\t\t\t\t\t\t(u32)(reg1->config >> 32));\n\t\t\tpci_write_config_dword(filter_pdev, reg2->reg,\n\t\t\t\t\t\t(u32)reg2->config);\n\t\t\tpci_write_config_dword(filter_pdev, reg2->reg + 4,\n\t\t\t\t\t\t(u32)(reg2->config >> 32));\n\t\t}\n\t}\n\n\tpci_write_config_dword(pdev, hwc->config_base, hwc->config | SNBEP_PMON_CTL_EN);\n}\n\nstatic struct intel_uncore_ops snbep_uncore_qpi_ops = {\n\tSNBEP_UNCORE_PCI_OPS_COMMON_INIT(),\n\t.enable_event\t\t= snbep_qpi_enable_event,\n\t.hw_config\t\t= snbep_qpi_hw_config,\n\t.get_constraint\t\t= uncore_get_constraint,\n\t.put_constraint\t\t= uncore_put_constraint,\n};\n\n#define SNBEP_UNCORE_PCI_COMMON_INIT()\t\t\t\t\\\n\t.perf_ctr\t= SNBEP_PCI_PMON_CTR0,\t\t\t\\\n\t.event_ctl\t= SNBEP_PCI_PMON_CTL0,\t\t\t\\\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\t\t\\\n\t.box_ctl\t= SNBEP_PCI_PMON_BOX_CTL,\t\t\\\n\t.ops\t\t= &snbep_uncore_pci_ops,\t\t\\\n\t.format_group\t= &snbep_uncore_format_group\n\nstatic struct intel_uncore_type snbep_uncore_ha = {\n\t.name\t\t= \"ha\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 48,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct intel_uncore_type snbep_uncore_imc = {\n\t.name\t\t= \"imc\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 4,\n\t.perf_ctr_bits\t= 48,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTR,\n\t.fixed_ctl\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTL,\n\t.event_descs\t= snbep_uncore_imc_events,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct intel_uncore_type snbep_uncore_qpi = {\n\t.name\t\t\t= \"qpi\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 2,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= SNBEP_PCI_PMON_CTR0,\n\t.event_ctl\t\t= SNBEP_PCI_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_QPI_PCI_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &snbep_uncore_qpi_ops,\n\t.event_descs\t\t= snbep_uncore_qpi_events,\n\t.format_group\t\t= &snbep_uncore_qpi_format_group,\n};\n\n\nstatic struct intel_uncore_type snbep_uncore_r2pcie = {\n\t.name\t\t= \"r2pcie\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 44,\n\t.constraints\t= snbep_uncore_r2pcie_constraints,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct intel_uncore_type snbep_uncore_r3qpi = {\n\t.name\t\t= \"r3qpi\",\n\t.num_counters   = 3,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 44,\n\t.constraints\t= snbep_uncore_r3qpi_constraints,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nenum {\n\tSNBEP_PCI_UNCORE_HA,\n\tSNBEP_PCI_UNCORE_IMC,\n\tSNBEP_PCI_UNCORE_QPI,\n\tSNBEP_PCI_UNCORE_R2PCIE,\n\tSNBEP_PCI_UNCORE_R3QPI,\n};\n\nstatic struct intel_uncore_type *snbep_pci_uncores[] = {\n\t[SNBEP_PCI_UNCORE_HA]\t\t= &snbep_uncore_ha,\n\t[SNBEP_PCI_UNCORE_IMC]\t\t= &snbep_uncore_imc,\n\t[SNBEP_PCI_UNCORE_QPI]\t\t= &snbep_uncore_qpi,\n\t[SNBEP_PCI_UNCORE_R2PCIE]\t= &snbep_uncore_r2pcie,\n\t[SNBEP_PCI_UNCORE_R3QPI]\t= &snbep_uncore_r3qpi,\n\tNULL,\n};\n\nstatic const struct pci_device_id snbep_uncore_pci_ids[] = {\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_HA),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_HA, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_IMC0),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_IMC, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_IMC1),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_IMC, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_IMC2),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_IMC, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_IMC3),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_IMC, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_QPI0),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_QPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_QPI1),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_QPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_R2PCIE),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_R2PCIE, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_R3QPI0),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_R3QPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_UNC_R3QPI1),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(SNBEP_PCI_UNCORE_R3QPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x3c86),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(UNCORE_EXTRA_PCI_DEV,\n\t\t\t\t\t\t   SNBEP_PCI_QPI_PORT0_FILTER),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x3c96),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(UNCORE_EXTRA_PCI_DEV,\n\t\t\t\t\t\t   SNBEP_PCI_QPI_PORT1_FILTER),\n\t},\n\t{   }\n};\n\nstatic struct pci_driver snbep_uncore_pci_driver = {\n\t.name\t\t= \"snbep_uncore\",\n\t.id_table\t= snbep_uncore_pci_ids,\n};\n\n#define NODE_ID_MASK\t0x7\n\n \n#define GIDNIDMAP(config, id)\t(((config) >> (3 * (id))) & 0x7)\n\nstatic int upi_nodeid_groupid(struct pci_dev *ubox_dev, int nodeid_loc, int idmap_loc,\n\t\t\t      int *nodeid, int *groupid)\n{\n\tint ret;\n\n\t \n\tret = pci_read_config_dword(ubox_dev, nodeid_loc, nodeid);\n\tif (ret)\n\t\tgoto err;\n\n\t*nodeid = *nodeid & NODE_ID_MASK;\n\t \n\tret = pci_read_config_dword(ubox_dev, idmap_loc, groupid);\n\tif (ret)\n\t\tgoto err;\nerr:\n\treturn ret;\n}\n\n \nstatic int snbep_pci2phy_map_init(int devid, int nodeid_loc, int idmap_loc, bool reverse)\n{\n\tstruct pci_dev *ubox_dev = NULL;\n\tint i, bus, nodeid, segment, die_id;\n\tstruct pci2phy_map *map;\n\tint err = 0;\n\tu32 config = 0;\n\n\twhile (1) {\n\t\t \n\t\tubox_dev = pci_get_device(PCI_VENDOR_ID_INTEL, devid, ubox_dev);\n\t\tif (!ubox_dev)\n\t\t\tbreak;\n\t\tbus = ubox_dev->bus->number;\n\t\t \n\t\tif (nr_node_ids <= 8) {\n\t\t\terr = upi_nodeid_groupid(ubox_dev, nodeid_loc, idmap_loc,\n\t\t\t\t\t\t &nodeid, &config);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\n\t\t\tsegment = pci_domain_nr(ubox_dev->bus);\n\t\t\traw_spin_lock(&pci2phy_map_lock);\n\t\t\tmap = __find_pci2phy_map(segment);\n\t\t\tif (!map) {\n\t\t\t\traw_spin_unlock(&pci2phy_map_lock);\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tfor (i = 0; i < 8; i++) {\n\t\t\t\tif (nodeid == GIDNIDMAP(config, i)) {\n\t\t\t\t\tif (topology_max_die_per_package() > 1)\n\t\t\t\t\t\tdie_id = i;\n\t\t\t\t\telse\n\t\t\t\t\t\tdie_id = topology_phys_to_logical_pkg(i);\n\t\t\t\t\tif (die_id < 0)\n\t\t\t\t\t\tdie_id = -ENODEV;\n\t\t\t\t\tmap->pbus_to_dieid[bus] = die_id;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\traw_spin_unlock(&pci2phy_map_lock);\n\t\t} else {\n\t\t\tsegment = pci_domain_nr(ubox_dev->bus);\n\t\t\traw_spin_lock(&pci2phy_map_lock);\n\t\t\tmap = __find_pci2phy_map(segment);\n\t\t\tif (!map) {\n\t\t\t\traw_spin_unlock(&pci2phy_map_lock);\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tmap->pbus_to_dieid[bus] = die_id = uncore_device_to_die(ubox_dev);\n\n\t\t\traw_spin_unlock(&pci2phy_map_lock);\n\n\t\t\tif (WARN_ON_ONCE(die_id == -1)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!err) {\n\t\t \n\t\traw_spin_lock(&pci2phy_map_lock);\n\t\tlist_for_each_entry(map, &pci2phy_map_head, list) {\n\t\t\ti = -1;\n\t\t\tif (reverse) {\n\t\t\t\tfor (bus = 255; bus >= 0; bus--) {\n\t\t\t\t\tif (map->pbus_to_dieid[bus] != -1)\n\t\t\t\t\t\ti = map->pbus_to_dieid[bus];\n\t\t\t\t\telse\n\t\t\t\t\t\tmap->pbus_to_dieid[bus] = i;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor (bus = 0; bus <= 255; bus++) {\n\t\t\t\t\tif (map->pbus_to_dieid[bus] != -1)\n\t\t\t\t\t\ti = map->pbus_to_dieid[bus];\n\t\t\t\t\telse\n\t\t\t\t\t\tmap->pbus_to_dieid[bus] = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\traw_spin_unlock(&pci2phy_map_lock);\n\t}\n\n\tpci_dev_put(ubox_dev);\n\n\treturn pcibios_err_to_errno(err);\n}\n\nint snbep_uncore_pci_init(void)\n{\n\tint ret = snbep_pci2phy_map_init(0x3ce0, SNBEP_CPUNODEID, SNBEP_GIDNIDMAP, true);\n\tif (ret)\n\t\treturn ret;\n\tuncore_pci_uncores = snbep_pci_uncores;\n\tuncore_pci_driver = &snbep_uncore_pci_driver;\n\treturn 0;\n}\n \n\n \nstatic void ivbep_uncore_msr_init_box(struct intel_uncore_box *box)\n{\n\tunsigned msr = uncore_msr_box_ctl(box);\n\tif (msr)\n\t\twrmsrl(msr, IVBEP_PMON_BOX_CTL_INT);\n}\n\nstatic void ivbep_uncore_pci_init_box(struct intel_uncore_box *box)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\n\tpci_write_config_dword(pdev, SNBEP_PCI_PMON_BOX_CTL, IVBEP_PMON_BOX_CTL_INT);\n}\n\n#define IVBEP_UNCORE_MSR_OPS_COMMON_INIT()\t\t\t\\\n\t.init_box\t= ivbep_uncore_msr_init_box,\t\t\\\n\t.disable_box\t= snbep_uncore_msr_disable_box,\t\t\\\n\t.enable_box\t= snbep_uncore_msr_enable_box,\t\t\\\n\t.disable_event\t= snbep_uncore_msr_disable_event,\t\\\n\t.enable_event\t= snbep_uncore_msr_enable_event,\t\\\n\t.read_counter\t= uncore_msr_read_counter\n\nstatic struct intel_uncore_ops ivbep_uncore_msr_ops = {\n\tIVBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n};\n\nstatic struct intel_uncore_ops ivbep_uncore_pci_ops = {\n\t.init_box\t= ivbep_uncore_pci_init_box,\n\t.disable_box\t= snbep_uncore_pci_disable_box,\n\t.enable_box\t= snbep_uncore_pci_enable_box,\n\t.disable_event\t= snbep_uncore_pci_disable_event,\n\t.enable_event\t= snbep_uncore_pci_enable_event,\n\t.read_counter\t= snbep_uncore_pci_read_counter,\n};\n\n#define IVBEP_UNCORE_PCI_COMMON_INIT()\t\t\t\t\\\n\t.perf_ctr\t= SNBEP_PCI_PMON_CTR0,\t\t\t\\\n\t.event_ctl\t= SNBEP_PCI_PMON_CTL0,\t\t\t\\\n\t.event_mask\t= IVBEP_PMON_RAW_EVENT_MASK,\t\t\\\n\t.box_ctl\t= SNBEP_PCI_PMON_BOX_CTL,\t\t\\\n\t.ops\t\t= &ivbep_uncore_pci_ops,\t\t\t\\\n\t.format_group\t= &ivbep_uncore_format_group\n\nstatic struct attribute *ivbep_uncore_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic struct attribute *ivbep_uncore_ubox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh5.attr,\n\tNULL,\n};\n\nstatic struct attribute *ivbep_uncore_cbox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_tid_en.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_filter_tid.attr,\n\t&format_attr_filter_link.attr,\n\t&format_attr_filter_state2.attr,\n\t&format_attr_filter_nid2.attr,\n\t&format_attr_filter_opc2.attr,\n\t&format_attr_filter_nc.attr,\n\t&format_attr_filter_c6.attr,\n\t&format_attr_filter_isoc.attr,\n\tNULL,\n};\n\nstatic struct attribute *ivbep_uncore_pcu_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_occ_sel.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_thresh5.attr,\n\t&format_attr_occ_invert.attr,\n\t&format_attr_occ_edge.attr,\n\t&format_attr_filter_band0.attr,\n\t&format_attr_filter_band1.attr,\n\t&format_attr_filter_band2.attr,\n\t&format_attr_filter_band3.attr,\n\tNULL,\n};\n\nstatic struct attribute *ivbep_uncore_qpi_formats_attr[] = {\n\t&format_attr_event_ext.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_match_rds.attr,\n\t&format_attr_match_rnid30.attr,\n\t&format_attr_match_rnid4.attr,\n\t&format_attr_match_dnid.attr,\n\t&format_attr_match_mc.attr,\n\t&format_attr_match_opc.attr,\n\t&format_attr_match_vnw.attr,\n\t&format_attr_match0.attr,\n\t&format_attr_match1.attr,\n\t&format_attr_mask_rds.attr,\n\t&format_attr_mask_rnid30.attr,\n\t&format_attr_mask_rnid4.attr,\n\t&format_attr_mask_dnid.attr,\n\t&format_attr_mask_mc.attr,\n\t&format_attr_mask_opc.attr,\n\t&format_attr_mask_vnw.attr,\n\t&format_attr_mask0.attr,\n\t&format_attr_mask1.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group ivbep_uncore_format_group = {\n\t.name = \"format\",\n\t.attrs = ivbep_uncore_formats_attr,\n};\n\nstatic const struct attribute_group ivbep_uncore_ubox_format_group = {\n\t.name = \"format\",\n\t.attrs = ivbep_uncore_ubox_formats_attr,\n};\n\nstatic const struct attribute_group ivbep_uncore_cbox_format_group = {\n\t.name = \"format\",\n\t.attrs = ivbep_uncore_cbox_formats_attr,\n};\n\nstatic const struct attribute_group ivbep_uncore_pcu_format_group = {\n\t.name = \"format\",\n\t.attrs = ivbep_uncore_pcu_formats_attr,\n};\n\nstatic const struct attribute_group ivbep_uncore_qpi_format_group = {\n\t.name = \"format\",\n\t.attrs = ivbep_uncore_qpi_formats_attr,\n};\n\nstatic struct intel_uncore_type ivbep_uncore_ubox = {\n\t.name\t\t= \"ubox\",\n\t.num_counters   = 2,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 44,\n\t.fixed_ctr_bits\t= 48,\n\t.perf_ctr\t= SNBEP_U_MSR_PMON_CTR0,\n\t.event_ctl\t= SNBEP_U_MSR_PMON_CTL0,\n\t.event_mask\t= IVBEP_U_MSR_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t= SNBEP_U_MSR_PMON_UCLK_FIXED_CTR,\n\t.fixed_ctl\t= SNBEP_U_MSR_PMON_UCLK_FIXED_CTL,\n\t.ops\t\t= &ivbep_uncore_msr_ops,\n\t.format_group\t= &ivbep_uncore_ubox_format_group,\n};\n\nstatic struct extra_reg ivbep_uncore_cbox_extra_regs[] = {\n\tSNBEP_CBO_EVENT_EXTRA_REG(SNBEP_CBO_PMON_CTL_TID_EN,\n\t\t\t\t  SNBEP_CBO_PMON_CTL_TID_EN, 0x1),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x1031, 0x10ff, 0x2),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x1134, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4134, 0xffff, 0xc),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x5134, 0xffff, 0xc),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0334, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4334, 0xffff, 0xc),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0534, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4534, 0xffff, 0xc),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0934, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4934, 0xffff, 0xc),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0135, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0335, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x2135, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x2335, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4135, 0xffff, 0x18),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4335, 0xffff, 0x18),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4435, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4835, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4a35, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x5035, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x8135, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x8335, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0136, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0336, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x2136, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x2336, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4136, 0xffff, 0x18),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4336, 0xffff, 0x18),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4436, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4836, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4a36, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x5036, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x8136, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x8336, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4037, 0x40ff, 0x8),\n\tEVENT_EXTRA_END\n};\n\nstatic u64 ivbep_cbox_filter_mask(int fields)\n{\n\tu64 mask = 0;\n\n\tif (fields & 0x1)\n\t\tmask |= IVBEP_CB0_MSR_PMON_BOX_FILTER_TID;\n\tif (fields & 0x2)\n\t\tmask |= IVBEP_CB0_MSR_PMON_BOX_FILTER_LINK;\n\tif (fields & 0x4)\n\t\tmask |= IVBEP_CB0_MSR_PMON_BOX_FILTER_STATE;\n\tif (fields & 0x8)\n\t\tmask |= IVBEP_CB0_MSR_PMON_BOX_FILTER_NID;\n\tif (fields & 0x10) {\n\t\tmask |= IVBEP_CB0_MSR_PMON_BOX_FILTER_OPC;\n\t\tmask |= IVBEP_CB0_MSR_PMON_BOX_FILTER_NC;\n\t\tmask |= IVBEP_CB0_MSR_PMON_BOX_FILTER_C6;\n\t\tmask |= IVBEP_CB0_MSR_PMON_BOX_FILTER_ISOC;\n\t}\n\n\treturn mask;\n}\n\nstatic struct event_constraint *\nivbep_cbox_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\treturn __snbep_cbox_get_constraint(box, event, ivbep_cbox_filter_mask);\n}\n\nstatic int ivbep_cbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct extra_reg *er;\n\tint idx = 0;\n\n\tfor (er = ivbep_uncore_cbox_extra_regs; er->msr; er++) {\n\t\tif (er->event != (event->hw.config & er->config_mask))\n\t\t\tcontinue;\n\t\tidx |= er->idx;\n\t}\n\n\tif (idx) {\n\t\treg1->reg = SNBEP_C0_MSR_PMON_BOX_FILTER +\n\t\t\tSNBEP_CBO_MSR_OFFSET * box->pmu->pmu_idx;\n\t\treg1->config = event->attr.config1 & ivbep_cbox_filter_mask(idx);\n\t\treg1->idx = idx;\n\t}\n\treturn 0;\n}\n\nstatic void ivbep_cbox_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\n\tif (reg1->idx != EXTRA_REG_NONE) {\n\t\tu64 filter = uncore_shared_reg_config(box, 0);\n\t\twrmsrl(reg1->reg, filter & 0xffffffff);\n\t\twrmsrl(reg1->reg + 6, filter >> 32);\n\t}\n\n\twrmsrl(hwc->config_base, hwc->config | SNBEP_PMON_CTL_EN);\n}\n\nstatic struct intel_uncore_ops ivbep_uncore_cbox_ops = {\n\t.init_box\t\t= ivbep_uncore_msr_init_box,\n\t.disable_box\t\t= snbep_uncore_msr_disable_box,\n\t.enable_box\t\t= snbep_uncore_msr_enable_box,\n\t.disable_event\t\t= snbep_uncore_msr_disable_event,\n\t.enable_event\t\t= ivbep_cbox_enable_event,\n\t.read_counter\t\t= uncore_msr_read_counter,\n\t.hw_config\t\t= ivbep_cbox_hw_config,\n\t.get_constraint\t\t= ivbep_cbox_get_constraint,\n\t.put_constraint\t\t= snbep_cbox_put_constraint,\n};\n\nstatic struct intel_uncore_type ivbep_uncore_cbox = {\n\t.name\t\t\t= \"cbox\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 15,\n\t.perf_ctr_bits\t\t= 44,\n\t.event_ctl\t\t= SNBEP_C0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= SNBEP_C0_MSR_PMON_CTR0,\n\t.event_mask\t\t= IVBEP_CBO_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_C0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= SNBEP_CBO_MSR_OFFSET,\n\t.num_shared_regs\t= 1,\n\t.constraints\t\t= snbep_uncore_cbox_constraints,\n\t.ops\t\t\t= &ivbep_uncore_cbox_ops,\n\t.format_group\t\t= &ivbep_uncore_cbox_format_group,\n};\n\nstatic struct intel_uncore_ops ivbep_uncore_pcu_ops = {\n\tIVBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n\t.hw_config\t\t= snbep_pcu_hw_config,\n\t.get_constraint\t\t= snbep_pcu_get_constraint,\n\t.put_constraint\t\t= snbep_pcu_put_constraint,\n};\n\nstatic struct intel_uncore_type ivbep_uncore_pcu = {\n\t.name\t\t\t= \"pcu\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= SNBEP_PCU_MSR_PMON_CTR0,\n\t.event_ctl\t\t= SNBEP_PCU_MSR_PMON_CTL0,\n\t.event_mask\t\t= IVBEP_PCU_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_PCU_MSR_PMON_BOX_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &ivbep_uncore_pcu_ops,\n\t.format_group\t\t= &ivbep_uncore_pcu_format_group,\n};\n\nstatic struct intel_uncore_type *ivbep_msr_uncores[] = {\n\t&ivbep_uncore_ubox,\n\t&ivbep_uncore_cbox,\n\t&ivbep_uncore_pcu,\n\tNULL,\n};\n\nvoid ivbep_uncore_cpu_init(void)\n{\n\tif (ivbep_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)\n\t\tivbep_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;\n\tuncore_msr_uncores = ivbep_msr_uncores;\n}\n\nstatic struct intel_uncore_type ivbep_uncore_ha = {\n\t.name\t\t= \"ha\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 48,\n\tIVBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct intel_uncore_type ivbep_uncore_imc = {\n\t.name\t\t= \"imc\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 8,\n\t.perf_ctr_bits\t= 48,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTR,\n\t.fixed_ctl\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTL,\n\t.event_descs\t= snbep_uncore_imc_events,\n\tIVBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\n \nstatic unsigned ivbep_uncore_irp_ctls[] = {0xd8, 0xdc, 0xe0, 0xe4};\nstatic unsigned ivbep_uncore_irp_ctrs[] = {0xa0, 0xb0, 0xb8, 0xc0};\n\nstatic void ivbep_uncore_irp_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tpci_write_config_dword(pdev, ivbep_uncore_irp_ctls[hwc->idx],\n\t\t\t       hwc->config | SNBEP_PMON_CTL_EN);\n}\n\nstatic void ivbep_uncore_irp_disable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tpci_write_config_dword(pdev, ivbep_uncore_irp_ctls[hwc->idx], hwc->config);\n}\n\nstatic u64 ivbep_uncore_irp_read_counter(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\tu64 count = 0;\n\n\tpci_read_config_dword(pdev, ivbep_uncore_irp_ctrs[hwc->idx], (u32 *)&count);\n\tpci_read_config_dword(pdev, ivbep_uncore_irp_ctrs[hwc->idx] + 4, (u32 *)&count + 1);\n\n\treturn count;\n}\n\nstatic struct intel_uncore_ops ivbep_uncore_irp_ops = {\n\t.init_box\t= ivbep_uncore_pci_init_box,\n\t.disable_box\t= snbep_uncore_pci_disable_box,\n\t.enable_box\t= snbep_uncore_pci_enable_box,\n\t.disable_event\t= ivbep_uncore_irp_disable_event,\n\t.enable_event\t= ivbep_uncore_irp_enable_event,\n\t.read_counter\t= ivbep_uncore_irp_read_counter,\n};\n\nstatic struct intel_uncore_type ivbep_uncore_irp = {\n\t.name\t\t\t= \"irp\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_mask\t\t= IVBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.ops\t\t\t= &ivbep_uncore_irp_ops,\n\t.format_group\t\t= &ivbep_uncore_format_group,\n};\n\nstatic struct intel_uncore_ops ivbep_uncore_qpi_ops = {\n\t.init_box\t= ivbep_uncore_pci_init_box,\n\t.disable_box\t= snbep_uncore_pci_disable_box,\n\t.enable_box\t= snbep_uncore_pci_enable_box,\n\t.disable_event\t= snbep_uncore_pci_disable_event,\n\t.enable_event\t= snbep_qpi_enable_event,\n\t.read_counter\t= snbep_uncore_pci_read_counter,\n\t.hw_config\t= snbep_qpi_hw_config,\n\t.get_constraint\t= uncore_get_constraint,\n\t.put_constraint\t= uncore_put_constraint,\n};\n\nstatic struct intel_uncore_type ivbep_uncore_qpi = {\n\t.name\t\t\t= \"qpi\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 3,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= SNBEP_PCI_PMON_CTR0,\n\t.event_ctl\t\t= SNBEP_PCI_PMON_CTL0,\n\t.event_mask\t\t= IVBEP_QPI_PCI_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &ivbep_uncore_qpi_ops,\n\t.format_group\t\t= &ivbep_uncore_qpi_format_group,\n};\n\nstatic struct intel_uncore_type ivbep_uncore_r2pcie = {\n\t.name\t\t= \"r2pcie\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 44,\n\t.constraints\t= snbep_uncore_r2pcie_constraints,\n\tIVBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct intel_uncore_type ivbep_uncore_r3qpi = {\n\t.name\t\t= \"r3qpi\",\n\t.num_counters   = 3,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 44,\n\t.constraints\t= snbep_uncore_r3qpi_constraints,\n\tIVBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nenum {\n\tIVBEP_PCI_UNCORE_HA,\n\tIVBEP_PCI_UNCORE_IMC,\n\tIVBEP_PCI_UNCORE_IRP,\n\tIVBEP_PCI_UNCORE_QPI,\n\tIVBEP_PCI_UNCORE_R2PCIE,\n\tIVBEP_PCI_UNCORE_R3QPI,\n};\n\nstatic struct intel_uncore_type *ivbep_pci_uncores[] = {\n\t[IVBEP_PCI_UNCORE_HA]\t= &ivbep_uncore_ha,\n\t[IVBEP_PCI_UNCORE_IMC]\t= &ivbep_uncore_imc,\n\t[IVBEP_PCI_UNCORE_IRP]\t= &ivbep_uncore_irp,\n\t[IVBEP_PCI_UNCORE_QPI]\t= &ivbep_uncore_qpi,\n\t[IVBEP_PCI_UNCORE_R2PCIE]\t= &ivbep_uncore_r2pcie,\n\t[IVBEP_PCI_UNCORE_R3QPI]\t= &ivbep_uncore_r3qpi,\n\tNULL,\n};\n\nstatic const struct pci_device_id ivbep_uncore_pci_ids[] = {\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe30),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_HA, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe38),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_HA, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xeb4),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_IMC, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xeb5),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_IMC, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xeb0),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_IMC, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xeb1),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_IMC, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xef4),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_IMC, 4),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xef5),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_IMC, 5),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xef0),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_IMC, 6),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xef1),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_IMC, 7),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe39),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_IRP, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe32),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_QPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe33),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_QPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe3a),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_QPI, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe34),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_R2PCIE, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe36),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_R3QPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe37),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_R3QPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe3e),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(IVBEP_PCI_UNCORE_R3QPI, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe86),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(UNCORE_EXTRA_PCI_DEV,\n\t\t\t\t\t\t   SNBEP_PCI_QPI_PORT0_FILTER),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0xe96),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(UNCORE_EXTRA_PCI_DEV,\n\t\t\t\t\t\t   SNBEP_PCI_QPI_PORT1_FILTER),\n\t},\n\t{   }\n};\n\nstatic struct pci_driver ivbep_uncore_pci_driver = {\n\t.name\t\t= \"ivbep_uncore\",\n\t.id_table\t= ivbep_uncore_pci_ids,\n};\n\nint ivbep_uncore_pci_init(void)\n{\n\tint ret = snbep_pci2phy_map_init(0x0e1e, SNBEP_CPUNODEID, SNBEP_GIDNIDMAP, true);\n\tif (ret)\n\t\treturn ret;\n\tuncore_pci_uncores = ivbep_pci_uncores;\n\tuncore_pci_driver = &ivbep_uncore_pci_driver;\n\treturn 0;\n}\n \n\n \nstatic struct attribute *knl_uncore_ubox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_tid_en.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh5.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group knl_uncore_ubox_format_group = {\n\t.name = \"format\",\n\t.attrs = knl_uncore_ubox_formats_attr,\n};\n\nstatic struct intel_uncore_type knl_uncore_ubox = {\n\t.name\t\t\t= \"ubox\",\n\t.num_counters\t\t= 2,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.fixed_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= HSWEP_U_MSR_PMON_CTR0,\n\t.event_ctl\t\t= HSWEP_U_MSR_PMON_CTL0,\n\t.event_mask\t\t= KNL_U_MSR_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t\t= HSWEP_U_MSR_PMON_UCLK_FIXED_CTR,\n\t.fixed_ctl\t\t= HSWEP_U_MSR_PMON_UCLK_FIXED_CTL,\n\t.ops\t\t\t= &snbep_uncore_msr_ops,\n\t.format_group\t\t= &knl_uncore_ubox_format_group,\n};\n\nstatic struct attribute *knl_uncore_cha_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_qor.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_tid_en.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_filter_tid4.attr,\n\t&format_attr_filter_link3.attr,\n\t&format_attr_filter_state4.attr,\n\t&format_attr_filter_local.attr,\n\t&format_attr_filter_all_op.attr,\n\t&format_attr_filter_nnm.attr,\n\t&format_attr_filter_opc3.attr,\n\t&format_attr_filter_nc.attr,\n\t&format_attr_filter_isoc.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group knl_uncore_cha_format_group = {\n\t.name = \"format\",\n\t.attrs = knl_uncore_cha_formats_attr,\n};\n\nstatic struct event_constraint knl_uncore_cha_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x1f, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x36, 0x1),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct extra_reg knl_uncore_cha_extra_regs[] = {\n\tSNBEP_CBO_EVENT_EXTRA_REG(SNBEP_CBO_PMON_CTL_TID_EN,\n\t\t\t\t  SNBEP_CBO_PMON_CTL_TID_EN, 0x1),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x3d, 0xff, 0x2),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x35, 0xff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x36, 0xff, 0x4),\n\tEVENT_EXTRA_END\n};\n\nstatic u64 knl_cha_filter_mask(int fields)\n{\n\tu64 mask = 0;\n\n\tif (fields & 0x1)\n\t\tmask |= KNL_CHA_MSR_PMON_BOX_FILTER_TID;\n\tif (fields & 0x2)\n\t\tmask |= KNL_CHA_MSR_PMON_BOX_FILTER_STATE;\n\tif (fields & 0x4)\n\t\tmask |= KNL_CHA_MSR_PMON_BOX_FILTER_OP;\n\treturn mask;\n}\n\nstatic struct event_constraint *\nknl_cha_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\treturn __snbep_cbox_get_constraint(box, event, knl_cha_filter_mask);\n}\n\nstatic int knl_cha_hw_config(struct intel_uncore_box *box,\n\t\t\t     struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct extra_reg *er;\n\tint idx = 0;\n\n\tfor (er = knl_uncore_cha_extra_regs; er->msr; er++) {\n\t\tif (er->event != (event->hw.config & er->config_mask))\n\t\t\tcontinue;\n\t\tidx |= er->idx;\n\t}\n\n\tif (idx) {\n\t\treg1->reg = HSWEP_C0_MSR_PMON_BOX_FILTER0 +\n\t\t\t    KNL_CHA_MSR_OFFSET * box->pmu->pmu_idx;\n\t\treg1->config = event->attr.config1 & knl_cha_filter_mask(idx);\n\n\t\treg1->config |= KNL_CHA_MSR_PMON_BOX_FILTER_REMOTE_NODE;\n\t\treg1->config |= KNL_CHA_MSR_PMON_BOX_FILTER_LOCAL_NODE;\n\t\treg1->config |= KNL_CHA_MSR_PMON_BOX_FILTER_NNC;\n\t\treg1->idx = idx;\n\t}\n\treturn 0;\n}\n\nstatic void hswep_cbox_enable_event(struct intel_uncore_box *box,\n\t\t\t\t    struct perf_event *event);\n\nstatic struct intel_uncore_ops knl_uncore_cha_ops = {\n\t.init_box\t\t= snbep_uncore_msr_init_box,\n\t.disable_box\t\t= snbep_uncore_msr_disable_box,\n\t.enable_box\t\t= snbep_uncore_msr_enable_box,\n\t.disable_event\t\t= snbep_uncore_msr_disable_event,\n\t.enable_event\t\t= hswep_cbox_enable_event,\n\t.read_counter\t\t= uncore_msr_read_counter,\n\t.hw_config\t\t= knl_cha_hw_config,\n\t.get_constraint\t\t= knl_cha_get_constraint,\n\t.put_constraint\t\t= snbep_cbox_put_constraint,\n};\n\nstatic struct intel_uncore_type knl_uncore_cha = {\n\t.name\t\t\t= \"cha\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 38,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= HSWEP_C0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= HSWEP_C0_MSR_PMON_CTR0,\n\t.event_mask\t\t= KNL_CHA_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= HSWEP_C0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= KNL_CHA_MSR_OFFSET,\n\t.num_shared_regs\t= 1,\n\t.constraints\t\t= knl_uncore_cha_constraints,\n\t.ops\t\t\t= &knl_uncore_cha_ops,\n\t.format_group\t\t= &knl_uncore_cha_format_group,\n};\n\nstatic struct attribute *knl_uncore_pcu_formats_attr[] = {\n\t&format_attr_event2.attr,\n\t&format_attr_use_occ_ctr.attr,\n\t&format_attr_occ_sel.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_tid_en.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh6.attr,\n\t&format_attr_occ_invert.attr,\n\t&format_attr_occ_edge_det.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group knl_uncore_pcu_format_group = {\n\t.name = \"format\",\n\t.attrs = knl_uncore_pcu_formats_attr,\n};\n\nstatic struct intel_uncore_type knl_uncore_pcu = {\n\t.name\t\t\t= \"pcu\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= HSWEP_PCU_MSR_PMON_CTR0,\n\t.event_ctl\t\t= HSWEP_PCU_MSR_PMON_CTL0,\n\t.event_mask\t\t= KNL_PCU_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= HSWEP_PCU_MSR_PMON_BOX_CTL,\n\t.ops\t\t\t= &snbep_uncore_msr_ops,\n\t.format_group\t\t= &knl_uncore_pcu_format_group,\n};\n\nstatic struct intel_uncore_type *knl_msr_uncores[] = {\n\t&knl_uncore_ubox,\n\t&knl_uncore_cha,\n\t&knl_uncore_pcu,\n\tNULL,\n};\n\nvoid knl_uncore_cpu_init(void)\n{\n\tuncore_msr_uncores = knl_msr_uncores;\n}\n\nstatic void knl_uncore_imc_enable_box(struct intel_uncore_box *box)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tint box_ctl = uncore_pci_box_ctl(box);\n\n\tpci_write_config_dword(pdev, box_ctl, 0);\n}\n\nstatic void knl_uncore_imc_enable_event(struct intel_uncore_box *box,\n\t\t\t\t\tstruct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif ((event->attr.config & SNBEP_PMON_CTL_EV_SEL_MASK)\n\t\t\t\t\t\t\t== UNCORE_FIXED_EVENT)\n\t\tpci_write_config_dword(pdev, hwc->config_base,\n\t\t\t\t       hwc->config | KNL_PMON_FIXED_CTL_EN);\n\telse\n\t\tpci_write_config_dword(pdev, hwc->config_base,\n\t\t\t\t       hwc->config | SNBEP_PMON_CTL_EN);\n}\n\nstatic struct intel_uncore_ops knl_uncore_imc_ops = {\n\t.init_box\t= snbep_uncore_pci_init_box,\n\t.disable_box\t= snbep_uncore_pci_disable_box,\n\t.enable_box\t= knl_uncore_imc_enable_box,\n\t.read_counter\t= snbep_uncore_pci_read_counter,\n\t.enable_event\t= knl_uncore_imc_enable_event,\n\t.disable_event\t= snbep_uncore_pci_disable_event,\n};\n\nstatic struct intel_uncore_type knl_uncore_imc_uclk = {\n\t.name\t\t\t= \"imc_uclk\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 2,\n\t.perf_ctr_bits\t\t= 48,\n\t.fixed_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= KNL_UCLK_MSR_PMON_CTR0_LOW,\n\t.event_ctl\t\t= KNL_UCLK_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t\t= KNL_UCLK_MSR_PMON_UCLK_FIXED_LOW,\n\t.fixed_ctl\t\t= KNL_UCLK_MSR_PMON_UCLK_FIXED_CTL,\n\t.box_ctl\t\t= KNL_UCLK_MSR_PMON_BOX_CTL,\n\t.ops\t\t\t= &knl_uncore_imc_ops,\n\t.format_group\t\t= &snbep_uncore_format_group,\n};\n\nstatic struct intel_uncore_type knl_uncore_imc_dclk = {\n\t.name\t\t\t= \"imc\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 6,\n\t.perf_ctr_bits\t\t= 48,\n\t.fixed_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= KNL_MC0_CH0_MSR_PMON_CTR0_LOW,\n\t.event_ctl\t\t= KNL_MC0_CH0_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t\t= KNL_MC0_CH0_MSR_PMON_FIXED_LOW,\n\t.fixed_ctl\t\t= KNL_MC0_CH0_MSR_PMON_FIXED_CTL,\n\t.box_ctl\t\t= KNL_MC0_CH0_MSR_PMON_BOX_CTL,\n\t.ops\t\t\t= &knl_uncore_imc_ops,\n\t.format_group\t\t= &snbep_uncore_format_group,\n};\n\nstatic struct intel_uncore_type knl_uncore_edc_uclk = {\n\t.name\t\t\t= \"edc_uclk\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 8,\n\t.perf_ctr_bits\t\t= 48,\n\t.fixed_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= KNL_UCLK_MSR_PMON_CTR0_LOW,\n\t.event_ctl\t\t= KNL_UCLK_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t\t= KNL_UCLK_MSR_PMON_UCLK_FIXED_LOW,\n\t.fixed_ctl\t\t= KNL_UCLK_MSR_PMON_UCLK_FIXED_CTL,\n\t.box_ctl\t\t= KNL_UCLK_MSR_PMON_BOX_CTL,\n\t.ops\t\t\t= &knl_uncore_imc_ops,\n\t.format_group\t\t= &snbep_uncore_format_group,\n};\n\nstatic struct intel_uncore_type knl_uncore_edc_eclk = {\n\t.name\t\t\t= \"edc_eclk\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 8,\n\t.perf_ctr_bits\t\t= 48,\n\t.fixed_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= KNL_EDC0_ECLK_MSR_PMON_CTR0_LOW,\n\t.event_ctl\t\t= KNL_EDC0_ECLK_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t\t= KNL_EDC0_ECLK_MSR_PMON_ECLK_FIXED_LOW,\n\t.fixed_ctl\t\t= KNL_EDC0_ECLK_MSR_PMON_ECLK_FIXED_CTL,\n\t.box_ctl\t\t= KNL_EDC0_ECLK_MSR_PMON_BOX_CTL,\n\t.ops\t\t\t= &knl_uncore_imc_ops,\n\t.format_group\t\t= &snbep_uncore_format_group,\n};\n\nstatic struct event_constraint knl_uncore_m2pcie_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type knl_uncore_m2pcie = {\n\t.name\t\t= \"m2pcie\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 48,\n\t.constraints\t= knl_uncore_m2pcie_constraints,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct attribute *knl_uncore_irp_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_qor.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group knl_uncore_irp_format_group = {\n\t.name = \"format\",\n\t.attrs = knl_uncore_irp_formats_attr,\n};\n\nstatic struct intel_uncore_type knl_uncore_irp = {\n\t.name\t\t\t= \"irp\",\n\t.num_counters\t\t= 2,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= SNBEP_PCI_PMON_CTR0,\n\t.event_ctl\t\t= SNBEP_PCI_PMON_CTL0,\n\t.event_mask\t\t= KNL_IRP_PCI_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= KNL_IRP_PCI_PMON_BOX_CTL,\n\t.ops\t\t\t= &snbep_uncore_pci_ops,\n\t.format_group\t\t= &knl_uncore_irp_format_group,\n};\n\nenum {\n\tKNL_PCI_UNCORE_MC_UCLK,\n\tKNL_PCI_UNCORE_MC_DCLK,\n\tKNL_PCI_UNCORE_EDC_UCLK,\n\tKNL_PCI_UNCORE_EDC_ECLK,\n\tKNL_PCI_UNCORE_M2PCIE,\n\tKNL_PCI_UNCORE_IRP,\n};\n\nstatic struct intel_uncore_type *knl_pci_uncores[] = {\n\t[KNL_PCI_UNCORE_MC_UCLK]\t= &knl_uncore_imc_uclk,\n\t[KNL_PCI_UNCORE_MC_DCLK]\t= &knl_uncore_imc_dclk,\n\t[KNL_PCI_UNCORE_EDC_UCLK]\t= &knl_uncore_edc_uclk,\n\t[KNL_PCI_UNCORE_EDC_ECLK]\t= &knl_uncore_edc_eclk,\n\t[KNL_PCI_UNCORE_M2PCIE]\t\t= &knl_uncore_m2pcie,\n\t[KNL_PCI_UNCORE_IRP]\t\t= &knl_uncore_irp,\n\tNULL,\n};\n\n \n\nstatic const struct pci_device_id knl_uncore_pci_ids[] = {\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7841),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(10, 0, KNL_PCI_UNCORE_MC_UCLK, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7841),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(11, 0, KNL_PCI_UNCORE_MC_UCLK, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7843),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(8, 2, KNL_PCI_UNCORE_MC_DCLK, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7843),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(8, 3, KNL_PCI_UNCORE_MC_DCLK, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7843),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(8, 4, KNL_PCI_UNCORE_MC_DCLK, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7843),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(9, 2, KNL_PCI_UNCORE_MC_DCLK, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7843),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(9, 3, KNL_PCI_UNCORE_MC_DCLK, 4),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7843),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(9, 4, KNL_PCI_UNCORE_MC_DCLK, 5),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7833),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(15, 0, KNL_PCI_UNCORE_EDC_UCLK, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7833),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(16, 0, KNL_PCI_UNCORE_EDC_UCLK, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7833),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(17, 0, KNL_PCI_UNCORE_EDC_UCLK, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7833),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(18, 0, KNL_PCI_UNCORE_EDC_UCLK, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7833),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(19, 0, KNL_PCI_UNCORE_EDC_UCLK, 4),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7833),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(20, 0, KNL_PCI_UNCORE_EDC_UCLK, 5),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7833),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(21, 0, KNL_PCI_UNCORE_EDC_UCLK, 6),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7833),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(22, 0, KNL_PCI_UNCORE_EDC_UCLK, 7),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7835),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(24, 2, KNL_PCI_UNCORE_EDC_ECLK, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7835),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(25, 2, KNL_PCI_UNCORE_EDC_ECLK, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7835),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(26, 2, KNL_PCI_UNCORE_EDC_ECLK, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7835),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(27, 2, KNL_PCI_UNCORE_EDC_ECLK, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7835),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(28, 2, KNL_PCI_UNCORE_EDC_ECLK, 4),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7835),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(29, 2, KNL_PCI_UNCORE_EDC_ECLK, 5),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7835),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(30, 2, KNL_PCI_UNCORE_EDC_ECLK, 6),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7835),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(31, 2, KNL_PCI_UNCORE_EDC_ECLK, 7),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7817),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(KNL_PCI_UNCORE_M2PCIE, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x7814),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(KNL_PCI_UNCORE_IRP, 0),\n\t},\n\t{   }\n};\n\nstatic struct pci_driver knl_uncore_pci_driver = {\n\t.name\t\t= \"knl_uncore\",\n\t.id_table\t= knl_uncore_pci_ids,\n};\n\nint knl_uncore_pci_init(void)\n{\n\tint ret;\n\n\t \n\tret = snb_pci2phy_map_init(0x7814);  \n\tif (ret)\n\t\treturn ret;\n\tret = snb_pci2phy_map_init(0x7817);  \n\tif (ret)\n\t\treturn ret;\n\tuncore_pci_uncores = knl_pci_uncores;\n\tuncore_pci_driver = &knl_uncore_pci_driver;\n\treturn 0;\n}\n\n \n\n \nstatic struct attribute *hswep_uncore_ubox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh5.attr,\n\t&format_attr_filter_tid2.attr,\n\t&format_attr_filter_cid.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group hswep_uncore_ubox_format_group = {\n\t.name = \"format\",\n\t.attrs = hswep_uncore_ubox_formats_attr,\n};\n\nstatic int hswep_ubox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\treg1->reg = HSWEP_U_MSR_PMON_FILTER;\n\treg1->config = event->attr.config1 & HSWEP_U_MSR_PMON_BOX_FILTER_MASK;\n\treg1->idx = 0;\n\treturn 0;\n}\n\nstatic struct intel_uncore_ops hswep_uncore_ubox_ops = {\n\tSNBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n\t.hw_config\t\t= hswep_ubox_hw_config,\n\t.get_constraint\t\t= uncore_get_constraint,\n\t.put_constraint\t\t= uncore_put_constraint,\n};\n\nstatic struct intel_uncore_type hswep_uncore_ubox = {\n\t.name\t\t\t= \"ubox\",\n\t.num_counters\t\t= 2,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 44,\n\t.fixed_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= HSWEP_U_MSR_PMON_CTR0,\n\t.event_ctl\t\t= HSWEP_U_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_U_MSR_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t\t= HSWEP_U_MSR_PMON_UCLK_FIXED_CTR,\n\t.fixed_ctl\t\t= HSWEP_U_MSR_PMON_UCLK_FIXED_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &hswep_uncore_ubox_ops,\n\t.format_group\t\t= &hswep_uncore_ubox_format_group,\n};\n\nstatic struct attribute *hswep_uncore_cbox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_tid_en.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_filter_tid3.attr,\n\t&format_attr_filter_link2.attr,\n\t&format_attr_filter_state3.attr,\n\t&format_attr_filter_nid2.attr,\n\t&format_attr_filter_opc2.attr,\n\t&format_attr_filter_nc.attr,\n\t&format_attr_filter_c6.attr,\n\t&format_attr_filter_isoc.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group hswep_uncore_cbox_format_group = {\n\t.name = \"format\",\n\t.attrs = hswep_uncore_cbox_formats_attr,\n};\n\nstatic struct event_constraint hswep_uncore_cbox_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x01, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x09, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x36, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x38, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x3b, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x3e, 0x1),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct extra_reg hswep_uncore_cbox_extra_regs[] = {\n\tSNBEP_CBO_EVENT_EXTRA_REG(SNBEP_CBO_PMON_CTL_TID_EN,\n\t\t\t\t  SNBEP_CBO_PMON_CTL_TID_EN, 0x1),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0334, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0534, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0934, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x1134, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x2134, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4134, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4037, 0x40ff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4028, 0x40ff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4032, 0x40ff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4029, 0x40ff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4033, 0x40ff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x402A, 0x40ff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0135, 0xffff, 0x12),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0335, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4135, 0xffff, 0x18),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4435, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4835, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x5035, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4335, 0xffff, 0x18),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4a35, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x2335, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x8335, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x2135, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x8135, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0136, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0336, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4136, 0xffff, 0x18),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4436, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4836, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4336, 0xffff, 0x18),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x4a36, 0xffff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x2336, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x8336, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x2136, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x8136, 0xffff, 0x10),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x5036, 0xffff, 0x8),\n\tEVENT_EXTRA_END\n};\n\nstatic u64 hswep_cbox_filter_mask(int fields)\n{\n\tu64 mask = 0;\n\tif (fields & 0x1)\n\t\tmask |= HSWEP_CB0_MSR_PMON_BOX_FILTER_TID;\n\tif (fields & 0x2)\n\t\tmask |= HSWEP_CB0_MSR_PMON_BOX_FILTER_LINK;\n\tif (fields & 0x4)\n\t\tmask |= HSWEP_CB0_MSR_PMON_BOX_FILTER_STATE;\n\tif (fields & 0x8)\n\t\tmask |= HSWEP_CB0_MSR_PMON_BOX_FILTER_NID;\n\tif (fields & 0x10) {\n\t\tmask |= HSWEP_CB0_MSR_PMON_BOX_FILTER_OPC;\n\t\tmask |= HSWEP_CB0_MSR_PMON_BOX_FILTER_NC;\n\t\tmask |= HSWEP_CB0_MSR_PMON_BOX_FILTER_C6;\n\t\tmask |= HSWEP_CB0_MSR_PMON_BOX_FILTER_ISOC;\n\t}\n\treturn mask;\n}\n\nstatic struct event_constraint *\nhswep_cbox_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\treturn __snbep_cbox_get_constraint(box, event, hswep_cbox_filter_mask);\n}\n\nstatic int hswep_cbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct extra_reg *er;\n\tint idx = 0;\n\n\tfor (er = hswep_uncore_cbox_extra_regs; er->msr; er++) {\n\t\tif (er->event != (event->hw.config & er->config_mask))\n\t\t\tcontinue;\n\t\tidx |= er->idx;\n\t}\n\n\tif (idx) {\n\t\treg1->reg = HSWEP_C0_MSR_PMON_BOX_FILTER0 +\n\t\t\t    HSWEP_CBO_MSR_OFFSET * box->pmu->pmu_idx;\n\t\treg1->config = event->attr.config1 & hswep_cbox_filter_mask(idx);\n\t\treg1->idx = idx;\n\t}\n\treturn 0;\n}\n\nstatic void hswep_cbox_enable_event(struct intel_uncore_box *box,\n\t\t\t\t  struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\n\tif (reg1->idx != EXTRA_REG_NONE) {\n\t\tu64 filter = uncore_shared_reg_config(box, 0);\n\t\twrmsrl(reg1->reg, filter & 0xffffffff);\n\t\twrmsrl(reg1->reg + 1, filter >> 32);\n\t}\n\n\twrmsrl(hwc->config_base, hwc->config | SNBEP_PMON_CTL_EN);\n}\n\nstatic struct intel_uncore_ops hswep_uncore_cbox_ops = {\n\t.init_box\t\t= snbep_uncore_msr_init_box,\n\t.disable_box\t\t= snbep_uncore_msr_disable_box,\n\t.enable_box\t\t= snbep_uncore_msr_enable_box,\n\t.disable_event\t\t= snbep_uncore_msr_disable_event,\n\t.enable_event\t\t= hswep_cbox_enable_event,\n\t.read_counter\t\t= uncore_msr_read_counter,\n\t.hw_config\t\t= hswep_cbox_hw_config,\n\t.get_constraint\t\t= hswep_cbox_get_constraint,\n\t.put_constraint\t\t= snbep_cbox_put_constraint,\n};\n\nstatic struct intel_uncore_type hswep_uncore_cbox = {\n\t.name\t\t\t= \"cbox\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 18,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= HSWEP_C0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= HSWEP_C0_MSR_PMON_CTR0,\n\t.event_mask\t\t= SNBEP_CBO_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= HSWEP_C0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= HSWEP_CBO_MSR_OFFSET,\n\t.num_shared_regs\t= 1,\n\t.constraints\t\t= hswep_uncore_cbox_constraints,\n\t.ops\t\t\t= &hswep_uncore_cbox_ops,\n\t.format_group\t\t= &hswep_uncore_cbox_format_group,\n};\n\n \nstatic void hswep_uncore_sbox_msr_init_box(struct intel_uncore_box *box)\n{\n\tunsigned msr = uncore_msr_box_ctl(box);\n\n\tif (msr) {\n\t\tu64 init = SNBEP_PMON_BOX_CTL_INT;\n\t\tu64 flags = 0;\n\t\tint i;\n\n\t\tfor_each_set_bit(i, (unsigned long *)&init, 64) {\n\t\t\tflags |= (1ULL << i);\n\t\t\twrmsrl(msr, flags);\n\t\t}\n\t}\n}\n\nstatic struct intel_uncore_ops hswep_uncore_sbox_msr_ops = {\n\t__SNBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n\t.init_box\t\t= hswep_uncore_sbox_msr_init_box\n};\n\nstatic struct attribute *hswep_uncore_sbox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_tid_en.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group hswep_uncore_sbox_format_group = {\n\t.name = \"format\",\n\t.attrs = hswep_uncore_sbox_formats_attr,\n};\n\nstatic struct intel_uncore_type hswep_uncore_sbox = {\n\t.name\t\t\t= \"sbox\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 4,\n\t.perf_ctr_bits\t\t= 44,\n\t.event_ctl\t\t= HSWEP_S0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= HSWEP_S0_MSR_PMON_CTR0,\n\t.event_mask\t\t= HSWEP_S_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= HSWEP_S0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= HSWEP_SBOX_MSR_OFFSET,\n\t.ops\t\t\t= &hswep_uncore_sbox_msr_ops,\n\t.format_group\t\t= &hswep_uncore_sbox_format_group,\n};\n\nstatic int hswep_pcu_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tint ev_sel = hwc->config & SNBEP_PMON_CTL_EV_SEL_MASK;\n\n\tif (ev_sel >= 0xb && ev_sel <= 0xe) {\n\t\treg1->reg = HSWEP_PCU_MSR_PMON_BOX_FILTER;\n\t\treg1->idx = ev_sel - 0xb;\n\t\treg1->config = event->attr.config1 & (0xff << reg1->idx);\n\t}\n\treturn 0;\n}\n\nstatic struct intel_uncore_ops hswep_uncore_pcu_ops = {\n\tSNBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n\t.hw_config\t\t= hswep_pcu_hw_config,\n\t.get_constraint\t\t= snbep_pcu_get_constraint,\n\t.put_constraint\t\t= snbep_pcu_put_constraint,\n};\n\nstatic struct intel_uncore_type hswep_uncore_pcu = {\n\t.name\t\t\t= \"pcu\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= HSWEP_PCU_MSR_PMON_CTR0,\n\t.event_ctl\t\t= HSWEP_PCU_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_PCU_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= HSWEP_PCU_MSR_PMON_BOX_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &hswep_uncore_pcu_ops,\n\t.format_group\t\t= &snbep_uncore_pcu_format_group,\n};\n\nstatic struct intel_uncore_type *hswep_msr_uncores[] = {\n\t&hswep_uncore_ubox,\n\t&hswep_uncore_cbox,\n\t&hswep_uncore_sbox,\n\t&hswep_uncore_pcu,\n\tNULL,\n};\n\n#define HSWEP_PCU_DID\t\t\t0x2fc0\n#define HSWEP_PCU_CAPID4_OFFET\t\t0x94\n#define hswep_get_chop(_cap)\t\t(((_cap) >> 6) & 0x3)\n\nstatic bool hswep_has_limit_sbox(unsigned int device)\n{\n\tstruct pci_dev *dev = pci_get_device(PCI_VENDOR_ID_INTEL, device, NULL);\n\tu32 capid4;\n\n\tif (!dev)\n\t\treturn false;\n\n\tpci_read_config_dword(dev, HSWEP_PCU_CAPID4_OFFET, &capid4);\n\tpci_dev_put(dev);\n\tif (!hswep_get_chop(capid4))\n\t\treturn true;\n\n\treturn false;\n}\n\nvoid hswep_uncore_cpu_init(void)\n{\n\tif (hswep_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)\n\t\thswep_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;\n\n\t \n\tif (hswep_has_limit_sbox(HSWEP_PCU_DID))\n\t\thswep_uncore_sbox.num_boxes = 2;\n\n\tuncore_msr_uncores = hswep_msr_uncores;\n}\n\nstatic struct intel_uncore_type hswep_uncore_ha = {\n\t.name\t\t= \"ha\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 48,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct uncore_event_desc hswep_uncore_imc_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(clockticks,      \"event=0x00,umask=0x00\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read,  \"event=0x04,umask=0x03\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read.unit, \"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write, \"event=0x04,umask=0x0c\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write.unit, \"MiB\"),\n\t{   },\n};\n\nstatic struct intel_uncore_type hswep_uncore_imc = {\n\t.name\t\t= \"imc\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 8,\n\t.perf_ctr_bits\t= 48,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTR,\n\t.fixed_ctl\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTL,\n\t.event_descs\t= hswep_uncore_imc_events,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic unsigned hswep_uncore_irp_ctrs[] = {0xa0, 0xa8, 0xb0, 0xb8};\n\nstatic u64 hswep_uncore_irp_read_counter(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\tu64 count = 0;\n\n\tpci_read_config_dword(pdev, hswep_uncore_irp_ctrs[hwc->idx], (u32 *)&count);\n\tpci_read_config_dword(pdev, hswep_uncore_irp_ctrs[hwc->idx] + 4, (u32 *)&count + 1);\n\n\treturn count;\n}\n\nstatic struct intel_uncore_ops hswep_uncore_irp_ops = {\n\t.init_box\t= snbep_uncore_pci_init_box,\n\t.disable_box\t= snbep_uncore_pci_disable_box,\n\t.enable_box\t= snbep_uncore_pci_enable_box,\n\t.disable_event\t= ivbep_uncore_irp_disable_event,\n\t.enable_event\t= ivbep_uncore_irp_enable_event,\n\t.read_counter\t= hswep_uncore_irp_read_counter,\n};\n\nstatic struct intel_uncore_type hswep_uncore_irp = {\n\t.name\t\t\t= \"irp\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.ops\t\t\t= &hswep_uncore_irp_ops,\n\t.format_group\t\t= &snbep_uncore_format_group,\n};\n\nstatic struct intel_uncore_type hswep_uncore_qpi = {\n\t.name\t\t\t= \"qpi\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 3,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= SNBEP_PCI_PMON_CTR0,\n\t.event_ctl\t\t= SNBEP_PCI_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_QPI_PCI_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &snbep_uncore_qpi_ops,\n\t.format_group\t\t= &snbep_uncore_qpi_format_group,\n};\n\nstatic struct event_constraint hswep_uncore_r2pcie_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x10, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x13, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x24, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x25, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x26, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x27, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x28, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x29, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2a, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x2b, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2c, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2d, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x32, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x33, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x34, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x35, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type hswep_uncore_r2pcie = {\n\t.name\t\t= \"r2pcie\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 48,\n\t.constraints\t= hswep_uncore_r2pcie_constraints,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct event_constraint hswep_uncore_r3qpi_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x01, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x07, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x08, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x09, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x0a, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x0e, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x10, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x12, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x13, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x14, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x15, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x1f, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x20, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x21, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x22, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x25, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x26, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x28, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x29, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2c, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2d, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2e, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2f, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x31, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x32, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x33, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x34, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x36, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x37, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x38, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x39, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type hswep_uncore_r3qpi = {\n\t.name\t\t= \"r3qpi\",\n\t.num_counters   = 3,\n\t.num_boxes\t= 3,\n\t.perf_ctr_bits\t= 44,\n\t.constraints\t= hswep_uncore_r3qpi_constraints,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nenum {\n\tHSWEP_PCI_UNCORE_HA,\n\tHSWEP_PCI_UNCORE_IMC,\n\tHSWEP_PCI_UNCORE_IRP,\n\tHSWEP_PCI_UNCORE_QPI,\n\tHSWEP_PCI_UNCORE_R2PCIE,\n\tHSWEP_PCI_UNCORE_R3QPI,\n};\n\nstatic struct intel_uncore_type *hswep_pci_uncores[] = {\n\t[HSWEP_PCI_UNCORE_HA]\t= &hswep_uncore_ha,\n\t[HSWEP_PCI_UNCORE_IMC]\t= &hswep_uncore_imc,\n\t[HSWEP_PCI_UNCORE_IRP]\t= &hswep_uncore_irp,\n\t[HSWEP_PCI_UNCORE_QPI]\t= &hswep_uncore_qpi,\n\t[HSWEP_PCI_UNCORE_R2PCIE]\t= &hswep_uncore_r2pcie,\n\t[HSWEP_PCI_UNCORE_R3QPI]\t= &hswep_uncore_r3qpi,\n\tNULL,\n};\n\nstatic const struct pci_device_id hswep_uncore_pci_ids[] = {\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f30),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_HA, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f38),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_HA, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2fb0),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_IMC, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2fb1),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_IMC, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2fb4),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_IMC, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2fb5),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_IMC, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2fd0),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_IMC, 4),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2fd1),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_IMC, 5),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2fd4),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_IMC, 6),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2fd5),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_IMC, 7),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f39),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_IRP, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f32),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_QPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f33),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_QPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f3a),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_QPI, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f34),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_R2PCIE, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f36),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_R3QPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f37),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_R3QPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f3e),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(HSWEP_PCI_UNCORE_R3QPI, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f86),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(UNCORE_EXTRA_PCI_DEV,\n\t\t\t\t\t\t   SNBEP_PCI_QPI_PORT0_FILTER),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2f96),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(UNCORE_EXTRA_PCI_DEV,\n\t\t\t\t\t\t   SNBEP_PCI_QPI_PORT1_FILTER),\n\t},\n\t{   }\n};\n\nstatic struct pci_driver hswep_uncore_pci_driver = {\n\t.name\t\t= \"hswep_uncore\",\n\t.id_table\t= hswep_uncore_pci_ids,\n};\n\nint hswep_uncore_pci_init(void)\n{\n\tint ret = snbep_pci2phy_map_init(0x2f1e, SNBEP_CPUNODEID, SNBEP_GIDNIDMAP, true);\n\tif (ret)\n\t\treturn ret;\n\tuncore_pci_uncores = hswep_pci_uncores;\n\tuncore_pci_driver = &hswep_uncore_pci_driver;\n\treturn 0;\n}\n \n\n \n\nstatic struct intel_uncore_type bdx_uncore_ubox = {\n\t.name\t\t\t= \"ubox\",\n\t.num_counters\t\t= 2,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.fixed_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= HSWEP_U_MSR_PMON_CTR0,\n\t.event_ctl\t\t= HSWEP_U_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_U_MSR_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t\t= HSWEP_U_MSR_PMON_UCLK_FIXED_CTR,\n\t.fixed_ctl\t\t= HSWEP_U_MSR_PMON_UCLK_FIXED_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &ivbep_uncore_msr_ops,\n\t.format_group\t\t= &ivbep_uncore_ubox_format_group,\n};\n\nstatic struct event_constraint bdx_uncore_cbox_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x09, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x36, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x3e, 0x1),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type bdx_uncore_cbox = {\n\t.name\t\t\t= \"cbox\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 24,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= HSWEP_C0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= HSWEP_C0_MSR_PMON_CTR0,\n\t.event_mask\t\t= SNBEP_CBO_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= HSWEP_C0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= HSWEP_CBO_MSR_OFFSET,\n\t.num_shared_regs\t= 1,\n\t.constraints\t\t= bdx_uncore_cbox_constraints,\n\t.ops\t\t\t= &hswep_uncore_cbox_ops,\n\t.format_group\t\t= &hswep_uncore_cbox_format_group,\n};\n\nstatic struct intel_uncore_type bdx_uncore_sbox = {\n\t.name\t\t\t= \"sbox\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 4,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= HSWEP_S0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= HSWEP_S0_MSR_PMON_CTR0,\n\t.event_mask\t\t= HSWEP_S_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= HSWEP_S0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= HSWEP_SBOX_MSR_OFFSET,\n\t.ops\t\t\t= &hswep_uncore_sbox_msr_ops,\n\t.format_group\t\t= &hswep_uncore_sbox_format_group,\n};\n\n#define BDX_MSR_UNCORE_SBOX\t3\n\nstatic struct intel_uncore_type *bdx_msr_uncores[] = {\n\t&bdx_uncore_ubox,\n\t&bdx_uncore_cbox,\n\t&hswep_uncore_pcu,\n\t&bdx_uncore_sbox,\n\tNULL,\n};\n\n \nstatic struct event_constraint bdx_uncore_pcu_constraints[] = {\n\tEVENT_CONSTRAINT(0x80, 0xe, 0x80),\n\tEVENT_CONSTRAINT_END\n};\n\n#define BDX_PCU_DID\t\t\t0x6fc0\n\nvoid bdx_uncore_cpu_init(void)\n{\n\tif (bdx_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)\n\t\tbdx_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;\n\tuncore_msr_uncores = bdx_msr_uncores;\n\n\t \n\tif ((boot_cpu_data.x86_model == 86) || hswep_has_limit_sbox(BDX_PCU_DID))\n\t\tuncore_msr_uncores[BDX_MSR_UNCORE_SBOX] = NULL;\n\n\thswep_uncore_pcu.constraints = bdx_uncore_pcu_constraints;\n}\n\nstatic struct intel_uncore_type bdx_uncore_ha = {\n\t.name\t\t= \"ha\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 48,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct intel_uncore_type bdx_uncore_imc = {\n\t.name\t\t= \"imc\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 8,\n\t.perf_ctr_bits\t= 48,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTR,\n\t.fixed_ctl\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTL,\n\t.event_descs\t= hswep_uncore_imc_events,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct intel_uncore_type bdx_uncore_irp = {\n\t.name\t\t\t= \"irp\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.ops\t\t\t= &hswep_uncore_irp_ops,\n\t.format_group\t\t= &snbep_uncore_format_group,\n};\n\nstatic struct intel_uncore_type bdx_uncore_qpi = {\n\t.name\t\t\t= \"qpi\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 3,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= SNBEP_PCI_PMON_CTR0,\n\t.event_ctl\t\t= SNBEP_PCI_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_QPI_PCI_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &snbep_uncore_qpi_ops,\n\t.format_group\t\t= &snbep_uncore_qpi_format_group,\n};\n\nstatic struct event_constraint bdx_uncore_r2pcie_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x10, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x13, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x25, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x26, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x28, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2c, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2d, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type bdx_uncore_r2pcie = {\n\t.name\t\t= \"r2pcie\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 48,\n\t.constraints\t= bdx_uncore_r2pcie_constraints,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nstatic struct event_constraint bdx_uncore_r3qpi_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x01, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x07, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x08, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x09, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x0a, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x0e, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x10, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x13, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x14, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x15, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x1f, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x20, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x21, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x22, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x25, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x26, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x28, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x29, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2c, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2d, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2e, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2f, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x33, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x34, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x36, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x37, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x38, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x39, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type bdx_uncore_r3qpi = {\n\t.name\t\t= \"r3qpi\",\n\t.num_counters   = 3,\n\t.num_boxes\t= 3,\n\t.perf_ctr_bits\t= 48,\n\t.constraints\t= bdx_uncore_r3qpi_constraints,\n\tSNBEP_UNCORE_PCI_COMMON_INIT(),\n};\n\nenum {\n\tBDX_PCI_UNCORE_HA,\n\tBDX_PCI_UNCORE_IMC,\n\tBDX_PCI_UNCORE_IRP,\n\tBDX_PCI_UNCORE_QPI,\n\tBDX_PCI_UNCORE_R2PCIE,\n\tBDX_PCI_UNCORE_R3QPI,\n};\n\nstatic struct intel_uncore_type *bdx_pci_uncores[] = {\n\t[BDX_PCI_UNCORE_HA]\t= &bdx_uncore_ha,\n\t[BDX_PCI_UNCORE_IMC]\t= &bdx_uncore_imc,\n\t[BDX_PCI_UNCORE_IRP]\t= &bdx_uncore_irp,\n\t[BDX_PCI_UNCORE_QPI]\t= &bdx_uncore_qpi,\n\t[BDX_PCI_UNCORE_R2PCIE]\t= &bdx_uncore_r2pcie,\n\t[BDX_PCI_UNCORE_R3QPI]\t= &bdx_uncore_r3qpi,\n\tNULL,\n};\n\nstatic const struct pci_device_id bdx_uncore_pci_ids[] = {\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f30),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_HA, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f38),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_HA, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6fb0),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_IMC, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6fb1),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_IMC, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6fb4),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_IMC, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6fb5),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_IMC, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6fd0),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_IMC, 4),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6fd1),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_IMC, 5),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6fd4),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_IMC, 6),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6fd5),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_IMC, 7),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f39),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_IRP, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f32),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_QPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f33),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_QPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f3a),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_QPI, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f34),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_R2PCIE, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f36),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_R3QPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f37),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_R3QPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f3e),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(BDX_PCI_UNCORE_R3QPI, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f86),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(UNCORE_EXTRA_PCI_DEV,\n\t\t\t\t\t\t   SNBEP_PCI_QPI_PORT0_FILTER),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f96),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(UNCORE_EXTRA_PCI_DEV,\n\t\t\t\t\t\t   SNBEP_PCI_QPI_PORT1_FILTER),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x6f46),\n\t\t.driver_data = UNCORE_PCI_DEV_DATA(UNCORE_EXTRA_PCI_DEV,\n\t\t\t\t\t\t   BDX_PCI_QPI_PORT2_FILTER),\n\t},\n\t{   }\n};\n\nstatic struct pci_driver bdx_uncore_pci_driver = {\n\t.name\t\t= \"bdx_uncore\",\n\t.id_table\t= bdx_uncore_pci_ids,\n};\n\nint bdx_uncore_pci_init(void)\n{\n\tint ret = snbep_pci2phy_map_init(0x6f1e, SNBEP_CPUNODEID, SNBEP_GIDNIDMAP, true);\n\n\tif (ret)\n\t\treturn ret;\n\tuncore_pci_uncores = bdx_pci_uncores;\n\tuncore_pci_driver = &bdx_uncore_pci_driver;\n\treturn 0;\n}\n\n \n\n \n\nstatic struct intel_uncore_type skx_uncore_ubox = {\n\t.name\t\t\t= \"ubox\",\n\t.num_counters\t\t= 2,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.fixed_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= HSWEP_U_MSR_PMON_CTR0,\n\t.event_ctl\t\t= HSWEP_U_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_U_MSR_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t\t= HSWEP_U_MSR_PMON_UCLK_FIXED_CTR,\n\t.fixed_ctl\t\t= HSWEP_U_MSR_PMON_UCLK_FIXED_CTL,\n\t.ops\t\t\t= &ivbep_uncore_msr_ops,\n\t.format_group\t\t= &ivbep_uncore_ubox_format_group,\n};\n\nstatic struct attribute *skx_uncore_cha_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_tid_en.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_filter_tid4.attr,\n\t&format_attr_filter_state5.attr,\n\t&format_attr_filter_rem.attr,\n\t&format_attr_filter_loc.attr,\n\t&format_attr_filter_nm.attr,\n\t&format_attr_filter_all_op.attr,\n\t&format_attr_filter_not_nm.attr,\n\t&format_attr_filter_opc_0.attr,\n\t&format_attr_filter_opc_1.attr,\n\t&format_attr_filter_nc.attr,\n\t&format_attr_filter_isoc.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group skx_uncore_chabox_format_group = {\n\t.name = \"format\",\n\t.attrs = skx_uncore_cha_formats_attr,\n};\n\nstatic struct event_constraint skx_uncore_chabox_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x11, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x36, 0x1),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct extra_reg skx_uncore_cha_extra_regs[] = {\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0334, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0534, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x0934, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x1134, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x3134, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x9134, 0xffff, 0x4),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x35, 0xff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x36, 0xff, 0x8),\n\tSNBEP_CBO_EVENT_EXTRA_REG(0x38, 0xff, 0x3),\n\tEVENT_EXTRA_END\n};\n\nstatic u64 skx_cha_filter_mask(int fields)\n{\n\tu64 mask = 0;\n\n\tif (fields & 0x1)\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_TID;\n\tif (fields & 0x2)\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_LINK;\n\tif (fields & 0x4)\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_STATE;\n\tif (fields & 0x8) {\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_REM;\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_LOC;\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_ALL_OPC;\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_NM;\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_NOT_NM;\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_OPC0;\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_OPC1;\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_NC;\n\t\tmask |= SKX_CHA_MSR_PMON_BOX_FILTER_ISOC;\n\t}\n\treturn mask;\n}\n\nstatic struct event_constraint *\nskx_cha_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\treturn __snbep_cbox_get_constraint(box, event, skx_cha_filter_mask);\n}\n\nstatic int skx_cha_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct extra_reg *er;\n\tint idx = 0;\n\t \n\tif (event->hw.config & SNBEP_CBO_PMON_CTL_TID_EN)\n\t\tidx = SKX_CHA_MSR_PMON_BOX_FILTER_TID;\n\n\tfor (er = skx_uncore_cha_extra_regs; er->msr; er++) {\n\t\tif (er->event != (event->hw.config & er->config_mask))\n\t\t\tcontinue;\n\t\tidx |= er->idx;\n\t}\n\n\tif (idx) {\n\t\treg1->reg = HSWEP_C0_MSR_PMON_BOX_FILTER0 +\n\t\t\t    HSWEP_CBO_MSR_OFFSET * box->pmu->pmu_idx;\n\t\treg1->config = event->attr.config1 & skx_cha_filter_mask(idx);\n\t\treg1->idx = idx;\n\t}\n\treturn 0;\n}\n\nstatic struct intel_uncore_ops skx_uncore_chabox_ops = {\n\t \n\t.init_box\t\t= ivbep_uncore_msr_init_box,\n\t.disable_box\t\t= snbep_uncore_msr_disable_box,\n\t.enable_box\t\t= snbep_uncore_msr_enable_box,\n\t.disable_event\t\t= snbep_uncore_msr_disable_event,\n\t.enable_event\t\t= hswep_cbox_enable_event,\n\t.read_counter\t\t= uncore_msr_read_counter,\n\t.hw_config\t\t= skx_cha_hw_config,\n\t.get_constraint\t\t= skx_cha_get_constraint,\n\t.put_constraint\t\t= snbep_cbox_put_constraint,\n};\n\nstatic struct intel_uncore_type skx_uncore_chabox = {\n\t.name\t\t\t= \"cha\",\n\t.num_counters\t\t= 4,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= HSWEP_C0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= HSWEP_C0_MSR_PMON_CTR0,\n\t.event_mask\t\t= HSWEP_S_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= HSWEP_C0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= HSWEP_CBO_MSR_OFFSET,\n\t.num_shared_regs\t= 1,\n\t.constraints\t\t= skx_uncore_chabox_constraints,\n\t.ops\t\t\t= &skx_uncore_chabox_ops,\n\t.format_group\t\t= &skx_uncore_chabox_format_group,\n};\n\nstatic struct attribute *skx_uncore_iio_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh9.attr,\n\t&format_attr_ch_mask.attr,\n\t&format_attr_fc_mask.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group skx_uncore_iio_format_group = {\n\t.name = \"format\",\n\t.attrs = skx_uncore_iio_formats_attr,\n};\n\nstatic struct event_constraint skx_uncore_iio_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x83, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x88, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0x95, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0xc0, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0xc5, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0xd4, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0xd5, 0xc),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic void skx_iio_enable_event(struct intel_uncore_box *box,\n\t\t\t\t struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\twrmsrl(hwc->config_base, hwc->config | SNBEP_PMON_CTL_EN);\n}\n\nstatic struct intel_uncore_ops skx_uncore_iio_ops = {\n\t.init_box\t\t= ivbep_uncore_msr_init_box,\n\t.disable_box\t\t= snbep_uncore_msr_disable_box,\n\t.enable_box\t\t= snbep_uncore_msr_enable_box,\n\t.disable_event\t\t= snbep_uncore_msr_disable_event,\n\t.enable_event\t\t= skx_iio_enable_event,\n\t.read_counter\t\t= uncore_msr_read_counter,\n};\n\nstatic struct intel_uncore_topology *pmu_topology(struct intel_uncore_pmu *pmu, int die)\n{\n\tint idx;\n\n\tfor (idx = 0; idx < pmu->type->num_boxes; idx++) {\n\t\tif (pmu->type->topology[die][idx].pmu_idx == pmu->pmu_idx)\n\t\t\treturn &pmu->type->topology[die][idx];\n\t}\n\n\treturn NULL;\n}\n\nstatic umode_t\npmu_iio_mapping_visible(struct kobject *kobj, struct attribute *attr,\n\t\t\t int die, int zero_bus_pmu)\n{\n\tstruct intel_uncore_pmu *pmu = dev_to_uncore_pmu(kobj_to_dev(kobj));\n\tstruct intel_uncore_topology *pmut = pmu_topology(pmu, die);\n\n\treturn (pmut && !pmut->iio->pci_bus_no && pmu->pmu_idx != zero_bus_pmu) ? 0 : attr->mode;\n}\n\nstatic umode_t\nskx_iio_mapping_visible(struct kobject *kobj, struct attribute *attr, int die)\n{\n\t \n\treturn pmu_iio_mapping_visible(kobj, attr, die, 0);\n}\n\nstatic ssize_t skx_iio_mapping_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct intel_uncore_pmu *pmu = dev_to_uncore_pmu(dev);\n\tstruct dev_ext_attribute *ea = to_dev_ext_attribute(attr);\n\tlong die = (long)ea->var;\n\tstruct intel_uncore_topology *pmut = pmu_topology(pmu, die);\n\n\treturn sprintf(buf, \"%04x:%02x\\n\", pmut ? pmut->iio->segment : 0,\n\t\t\t\t\t   pmut ? pmut->iio->pci_bus_no : 0);\n}\n\nstatic int skx_msr_cpu_bus_read(int cpu, u64 *topology)\n{\n\tu64 msr_value;\n\n\tif (rdmsrl_on_cpu(cpu, SKX_MSR_CPU_BUS_NUMBER, &msr_value) ||\n\t\t\t!(msr_value & SKX_MSR_CPU_BUS_VALID_BIT))\n\t\treturn -ENXIO;\n\n\t*topology = msr_value;\n\n\treturn 0;\n}\n\nstatic int die_to_cpu(int die)\n{\n\tint res = 0, cpu, current_die;\n\t \n\tcpus_read_lock();\n\tfor_each_online_cpu(cpu) {\n\t\tcurrent_die = topology_logical_die_id(cpu);\n\t\tif (current_die == die) {\n\t\t\tres = cpu;\n\t\t\tbreak;\n\t\t}\n\t}\n\tcpus_read_unlock();\n\treturn res;\n}\n\nenum {\n\tIIO_TOPOLOGY_TYPE,\n\tUPI_TOPOLOGY_TYPE,\n\tTOPOLOGY_MAX\n};\n\nstatic const size_t topology_size[TOPOLOGY_MAX] = {\n\tsizeof(*((struct intel_uncore_topology *)NULL)->iio),\n\tsizeof(*((struct intel_uncore_topology *)NULL)->upi)\n};\n\nstatic int pmu_alloc_topology(struct intel_uncore_type *type, int topology_type)\n{\n\tint die, idx;\n\tstruct intel_uncore_topology **topology;\n\n\tif (!type->num_boxes)\n\t\treturn -EPERM;\n\n\ttopology = kcalloc(uncore_max_dies(), sizeof(*topology), GFP_KERNEL);\n\tif (!topology)\n\t\tgoto err;\n\n\tfor (die = 0; die < uncore_max_dies(); die++) {\n\t\ttopology[die] = kcalloc(type->num_boxes, sizeof(**topology), GFP_KERNEL);\n\t\tif (!topology[die])\n\t\t\tgoto clear;\n\t\tfor (idx = 0; idx < type->num_boxes; idx++) {\n\t\t\ttopology[die][idx].untyped = kcalloc(type->num_boxes,\n\t\t\t\t\t\t\t     topology_size[topology_type],\n\t\t\t\t\t\t\t     GFP_KERNEL);\n\t\t\tif (!topology[die][idx].untyped)\n\t\t\t\tgoto clear;\n\t\t}\n\t}\n\n\ttype->topology = topology;\n\n\treturn 0;\nclear:\n\tfor (; die >= 0; die--) {\n\t\tfor (idx = 0; idx < type->num_boxes; idx++)\n\t\t\tkfree(topology[die][idx].untyped);\n\t\tkfree(topology[die]);\n\t}\n\tkfree(topology);\nerr:\n\treturn -ENOMEM;\n}\n\nstatic void pmu_free_topology(struct intel_uncore_type *type)\n{\n\tint die, idx;\n\n\tif (type->topology) {\n\t\tfor (die = 0; die < uncore_max_dies(); die++) {\n\t\t\tfor (idx = 0; idx < type->num_boxes; idx++)\n\t\t\t\tkfree(type->topology[die][idx].untyped);\n\t\t\tkfree(type->topology[die]);\n\t\t}\n\t\tkfree(type->topology);\n\t\ttype->topology = NULL;\n\t}\n}\n\nstatic int skx_pmu_get_topology(struct intel_uncore_type *type,\n\t\t\t\t int (*topology_cb)(struct intel_uncore_type*, int, int, u64))\n{\n\tint die, ret = -EPERM;\n\tu64 cpu_bus_msr;\n\n\tfor (die = 0; die < uncore_max_dies(); die++) {\n\t\tret = skx_msr_cpu_bus_read(die_to_cpu(die), &cpu_bus_msr);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tret = uncore_die_to_segment(die);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\n\t\tret = topology_cb(type, ret, die, cpu_bus_msr);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int skx_iio_topology_cb(struct intel_uncore_type *type, int segment,\n\t\t\t\tint die, u64 cpu_bus_msr)\n{\n\tint idx;\n\tstruct intel_uncore_topology *t;\n\n\tfor (idx = 0; idx < type->num_boxes; idx++) {\n\t\tt = &type->topology[die][idx];\n\t\tt->pmu_idx = idx;\n\t\tt->iio->segment = segment;\n\t\tt->iio->pci_bus_no = (cpu_bus_msr >> (idx * BUS_NUM_STRIDE)) & 0xff;\n\t}\n\n\treturn 0;\n}\n\nstatic int skx_iio_get_topology(struct intel_uncore_type *type)\n{\n\treturn skx_pmu_get_topology(type, skx_iio_topology_cb);\n}\n\nstatic struct attribute_group skx_iio_mapping_group = {\n\t.is_visible\t= skx_iio_mapping_visible,\n};\n\nstatic const struct attribute_group *skx_iio_attr_update[] = {\n\t&skx_iio_mapping_group,\n\tNULL,\n};\n\nstatic void pmu_clear_mapping_attr(const struct attribute_group **groups,\n\t\t\t\t   struct attribute_group *ag)\n{\n\tint i;\n\n\tfor (i = 0; groups[i]; i++) {\n\t\tif (groups[i] == ag) {\n\t\t\tfor (i++; groups[i]; i++)\n\t\t\t\tgroups[i - 1] = groups[i];\n\t\t\tgroups[i - 1] = NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void\npmu_set_mapping(struct intel_uncore_type *type, struct attribute_group *ag,\n\t\tssize_t (*show)(struct device*, struct device_attribute*, char*),\n\t\tint topology_type)\n{\n\tchar buf[64];\n\tint ret;\n\tlong die = -1;\n\tstruct attribute **attrs = NULL;\n\tstruct dev_ext_attribute *eas = NULL;\n\n\tret = pmu_alloc_topology(type, topology_type);\n\tif (ret < 0)\n\t\tgoto clear_attr_update;\n\n\tret = type->get_topology(type);\n\tif (ret < 0)\n\t\tgoto clear_topology;\n\n\t \n\tattrs = kcalloc((uncore_max_dies() + 1), sizeof(*attrs), GFP_KERNEL);\n\tif (!attrs)\n\t\tgoto clear_topology;\n\n\teas = kcalloc(uncore_max_dies(), sizeof(*eas), GFP_KERNEL);\n\tif (!eas)\n\t\tgoto clear_attrs;\n\n\tfor (die = 0; die < uncore_max_dies(); die++) {\n\t\tsnprintf(buf, sizeof(buf), \"die%ld\", die);\n\t\tsysfs_attr_init(&eas[die].attr.attr);\n\t\teas[die].attr.attr.name = kstrdup(buf, GFP_KERNEL);\n\t\tif (!eas[die].attr.attr.name)\n\t\t\tgoto err;\n\t\teas[die].attr.attr.mode = 0444;\n\t\teas[die].attr.show = show;\n\t\teas[die].attr.store = NULL;\n\t\teas[die].var = (void *)die;\n\t\tattrs[die] = &eas[die].attr.attr;\n\t}\n\tag->attrs = attrs;\n\n\treturn;\nerr:\n\tfor (; die >= 0; die--)\n\t\tkfree(eas[die].attr.attr.name);\n\tkfree(eas);\nclear_attrs:\n\tkfree(attrs);\nclear_topology:\n\tpmu_free_topology(type);\nclear_attr_update:\n\tpmu_clear_mapping_attr(type->attr_update, ag);\n}\n\nstatic void\npmu_cleanup_mapping(struct intel_uncore_type *type, struct attribute_group *ag)\n{\n\tstruct attribute **attr = ag->attrs;\n\n\tif (!attr)\n\t\treturn;\n\n\tfor (; *attr; attr++)\n\t\tkfree((*attr)->name);\n\tkfree(attr_to_ext_attr(*ag->attrs));\n\tkfree(ag->attrs);\n\tag->attrs = NULL;\n\tpmu_free_topology(type);\n}\n\nstatic void\npmu_iio_set_mapping(struct intel_uncore_type *type, struct attribute_group *ag)\n{\n\tpmu_set_mapping(type, ag, skx_iio_mapping_show, IIO_TOPOLOGY_TYPE);\n}\n\nstatic void skx_iio_set_mapping(struct intel_uncore_type *type)\n{\n\tpmu_iio_set_mapping(type, &skx_iio_mapping_group);\n}\n\nstatic void skx_iio_cleanup_mapping(struct intel_uncore_type *type)\n{\n\tpmu_cleanup_mapping(type, &skx_iio_mapping_group);\n}\n\nstatic struct intel_uncore_type skx_uncore_iio = {\n\t.name\t\t\t= \"iio\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 6,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= SKX_IIO0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= SKX_IIO0_MSR_PMON_CTR0,\n\t.event_mask\t\t= SKX_IIO_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t\t= SKX_IIO_PMON_RAW_EVENT_MASK_EXT,\n\t.box_ctl\t\t= SKX_IIO0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= SKX_IIO_MSR_OFFSET,\n\t.constraints\t\t= skx_uncore_iio_constraints,\n\t.ops\t\t\t= &skx_uncore_iio_ops,\n\t.format_group\t\t= &skx_uncore_iio_format_group,\n\t.attr_update\t\t= skx_iio_attr_update,\n\t.get_topology\t\t= skx_iio_get_topology,\n\t.set_mapping\t\t= skx_iio_set_mapping,\n\t.cleanup_mapping\t= skx_iio_cleanup_mapping,\n};\n\nenum perf_uncore_iio_freerunning_type_id {\n\tSKX_IIO_MSR_IOCLK\t\t\t= 0,\n\tSKX_IIO_MSR_BW\t\t\t\t= 1,\n\tSKX_IIO_MSR_UTIL\t\t\t= 2,\n\n\tSKX_IIO_FREERUNNING_TYPE_MAX,\n};\n\n\nstatic struct freerunning_counters skx_iio_freerunning[] = {\n\t[SKX_IIO_MSR_IOCLK]\t= { 0xa45, 0x1, 0x20, 1, 36 },\n\t[SKX_IIO_MSR_BW]\t= { 0xb00, 0x1, 0x10, 8, 36 },\n\t[SKX_IIO_MSR_UTIL]\t= { 0xb08, 0x1, 0x10, 8, 36 },\n};\n\nstatic struct uncore_event_desc skx_uncore_iio_freerunning_events[] = {\n\t \n\tINTEL_UNCORE_EVENT_DESC(ioclk,\t\t\t\"event=0xff,umask=0x10\"),\n\t \n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0,\t\t\"event=0xff,umask=0x20\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1,\t\t\"event=0xff,umask=0x21\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2,\t\t\"event=0xff,umask=0x22\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3,\t\t\"event=0xff,umask=0x23\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port0,\t\t\"event=0xff,umask=0x24\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port0.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port0.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port1,\t\t\"event=0xff,umask=0x25\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port1.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port1.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port2,\t\t\"event=0xff,umask=0x26\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port2.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port2.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port3,\t\t\"event=0xff,umask=0x27\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port3.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port3.unit,\t\"MiB\"),\n\t \n\tINTEL_UNCORE_EVENT_DESC(util_in_port0,\t\t\"event=0xff,umask=0x30\"),\n\tINTEL_UNCORE_EVENT_DESC(util_out_port0,\t\t\"event=0xff,umask=0x31\"),\n\tINTEL_UNCORE_EVENT_DESC(util_in_port1,\t\t\"event=0xff,umask=0x32\"),\n\tINTEL_UNCORE_EVENT_DESC(util_out_port1,\t\t\"event=0xff,umask=0x33\"),\n\tINTEL_UNCORE_EVENT_DESC(util_in_port2,\t\t\"event=0xff,umask=0x34\"),\n\tINTEL_UNCORE_EVENT_DESC(util_out_port2,\t\t\"event=0xff,umask=0x35\"),\n\tINTEL_UNCORE_EVENT_DESC(util_in_port3,\t\t\"event=0xff,umask=0x36\"),\n\tINTEL_UNCORE_EVENT_DESC(util_out_port3,\t\t\"event=0xff,umask=0x37\"),\n\t{   },\n};\n\nstatic struct intel_uncore_ops skx_uncore_iio_freerunning_ops = {\n\t.read_counter\t\t= uncore_msr_read_counter,\n\t.hw_config\t\t= uncore_freerunning_hw_config,\n};\n\nstatic struct attribute *skx_uncore_iio_freerunning_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group skx_uncore_iio_freerunning_format_group = {\n\t.name = \"format\",\n\t.attrs = skx_uncore_iio_freerunning_formats_attr,\n};\n\nstatic struct intel_uncore_type skx_uncore_iio_free_running = {\n\t.name\t\t\t= \"iio_free_running\",\n\t.num_counters\t\t= 17,\n\t.num_boxes\t\t= 6,\n\t.num_freerunning_types\t= SKX_IIO_FREERUNNING_TYPE_MAX,\n\t.freerunning\t\t= skx_iio_freerunning,\n\t.ops\t\t\t= &skx_uncore_iio_freerunning_ops,\n\t.event_descs\t\t= skx_uncore_iio_freerunning_events,\n\t.format_group\t\t= &skx_uncore_iio_freerunning_format_group,\n};\n\nstatic struct attribute *skx_uncore_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group skx_uncore_format_group = {\n\t.name = \"format\",\n\t.attrs = skx_uncore_formats_attr,\n};\n\nstatic struct intel_uncore_type skx_uncore_irp = {\n\t.name\t\t\t= \"irp\",\n\t.num_counters\t\t= 2,\n\t.num_boxes\t\t= 6,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= SKX_IRP0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= SKX_IRP0_MSR_PMON_CTR0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SKX_IRP0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= SKX_IRP_MSR_OFFSET,\n\t.ops\t\t\t= &skx_uncore_iio_ops,\n\t.format_group\t\t= &skx_uncore_format_group,\n};\n\nstatic struct attribute *skx_uncore_pcu_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_occ_invert.attr,\n\t&format_attr_occ_edge_det.attr,\n\t&format_attr_filter_band0.attr,\n\t&format_attr_filter_band1.attr,\n\t&format_attr_filter_band2.attr,\n\t&format_attr_filter_band3.attr,\n\tNULL,\n};\n\nstatic struct attribute_group skx_uncore_pcu_format_group = {\n\t.name = \"format\",\n\t.attrs = skx_uncore_pcu_formats_attr,\n};\n\nstatic struct intel_uncore_ops skx_uncore_pcu_ops = {\n\tIVBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n\t.hw_config\t\t= hswep_pcu_hw_config,\n\t.get_constraint\t\t= snbep_pcu_get_constraint,\n\t.put_constraint\t\t= snbep_pcu_put_constraint,\n};\n\nstatic struct intel_uncore_type skx_uncore_pcu = {\n\t.name\t\t\t= \"pcu\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= HSWEP_PCU_MSR_PMON_CTR0,\n\t.event_ctl\t\t= HSWEP_PCU_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_PCU_MSR_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= HSWEP_PCU_MSR_PMON_BOX_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &skx_uncore_pcu_ops,\n\t.format_group\t\t= &skx_uncore_pcu_format_group,\n};\n\nstatic struct intel_uncore_type *skx_msr_uncores[] = {\n\t&skx_uncore_ubox,\n\t&skx_uncore_chabox,\n\t&skx_uncore_iio,\n\t&skx_uncore_iio_free_running,\n\t&skx_uncore_irp,\n\t&skx_uncore_pcu,\n\tNULL,\n};\n\n \n#define SKX_CAPID6\t\t0x9c\n#define SKX_CHA_BIT_MASK\tGENMASK(27, 0)\n\nstatic int skx_count_chabox(void)\n{\n\tstruct pci_dev *dev = NULL;\n\tu32 val = 0;\n\n\tdev = pci_get_device(PCI_VENDOR_ID_INTEL, 0x2083, dev);\n\tif (!dev)\n\t\tgoto out;\n\n\tpci_read_config_dword(dev, SKX_CAPID6, &val);\n\tval &= SKX_CHA_BIT_MASK;\nout:\n\tpci_dev_put(dev);\n\treturn hweight32(val);\n}\n\nvoid skx_uncore_cpu_init(void)\n{\n\tskx_uncore_chabox.num_boxes = skx_count_chabox();\n\tuncore_msr_uncores = skx_msr_uncores;\n}\n\nstatic struct intel_uncore_type skx_uncore_imc = {\n\t.name\t\t= \"imc\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 6,\n\t.perf_ctr_bits\t= 48,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTR,\n\t.fixed_ctl\t= SNBEP_MC_CHy_PCI_PMON_FIXED_CTL,\n\t.event_descs\t= hswep_uncore_imc_events,\n\t.perf_ctr\t= SNBEP_PCI_PMON_CTR0,\n\t.event_ctl\t= SNBEP_PCI_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.ops\t\t= &ivbep_uncore_pci_ops,\n\t.format_group\t= &skx_uncore_format_group,\n};\n\nstatic struct attribute *skx_upi_uncore_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask_ext.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group skx_upi_uncore_format_group = {\n\t.name = \"format\",\n\t.attrs = skx_upi_uncore_formats_attr,\n};\n\nstatic void skx_upi_uncore_pci_init_box(struct intel_uncore_box *box)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\n\t__set_bit(UNCORE_BOX_FLAG_CTL_OFFS8, &box->flags);\n\tpci_write_config_dword(pdev, SKX_UPI_PCI_PMON_BOX_CTL, IVBEP_PMON_BOX_CTL_INT);\n}\n\nstatic struct intel_uncore_ops skx_upi_uncore_pci_ops = {\n\t.init_box\t= skx_upi_uncore_pci_init_box,\n\t.disable_box\t= snbep_uncore_pci_disable_box,\n\t.enable_box\t= snbep_uncore_pci_enable_box,\n\t.disable_event\t= snbep_uncore_pci_disable_event,\n\t.enable_event\t= snbep_uncore_pci_enable_event,\n\t.read_counter\t= snbep_uncore_pci_read_counter,\n};\n\nstatic umode_t\nskx_upi_mapping_visible(struct kobject *kobj, struct attribute *attr, int die)\n{\n\tstruct intel_uncore_pmu *pmu = dev_to_uncore_pmu(kobj_to_dev(kobj));\n\n\treturn pmu->type->topology[die][pmu->pmu_idx].upi->enabled ? attr->mode : 0;\n}\n\nstatic ssize_t skx_upi_mapping_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct intel_uncore_pmu *pmu = dev_to_uncore_pmu(dev);\n\tstruct dev_ext_attribute *ea = to_dev_ext_attribute(attr);\n\tlong die = (long)ea->var;\n\tstruct uncore_upi_topology *upi = pmu->type->topology[die][pmu->pmu_idx].upi;\n\n\treturn sysfs_emit(buf, \"upi_%d,die_%d\\n\", upi->pmu_idx_to, upi->die_to);\n}\n\n#define SKX_UPI_REG_DID\t\t\t0x2058\n#define SKX_UPI_REGS_ADDR_DEVICE_LINK0\t0x0e\n#define SKX_UPI_REGS_ADDR_FUNCTION\t0x00\n\n \n#define SKX_KTILP0_OFFSET\t0x94\n\n \n#define SKX_KTIPCSTS_OFFSET\t0x120\n\nstatic int upi_fill_topology(struct pci_dev *dev, struct intel_uncore_topology *tp,\n\t\t\t     int pmu_idx)\n{\n\tint ret;\n\tu32 upi_conf;\n\tstruct uncore_upi_topology *upi = tp->upi;\n\n\ttp->pmu_idx = pmu_idx;\n\tret = pci_read_config_dword(dev, SKX_KTIPCSTS_OFFSET, &upi_conf);\n\tif (ret) {\n\t\tret = pcibios_err_to_errno(ret);\n\t\tgoto err;\n\t}\n\tupi->enabled = (upi_conf >> 4) & 1;\n\tif (upi->enabled) {\n\t\tret = pci_read_config_dword(dev, SKX_KTILP0_OFFSET,\n\t\t\t\t\t    &upi_conf);\n\t\tif (ret) {\n\t\t\tret = pcibios_err_to_errno(ret);\n\t\t\tgoto err;\n\t\t}\n\t\tupi->die_to = (upi_conf >> 16) & 0xf;\n\t\tupi->pmu_idx_to = (upi_conf >> 8) & 0x1f;\n\t}\nerr:\n\treturn ret;\n}\n\nstatic int skx_upi_topology_cb(struct intel_uncore_type *type, int segment,\n\t\t\t\tint die, u64 cpu_bus_msr)\n{\n\tint idx, ret;\n\tstruct intel_uncore_topology *upi;\n\tunsigned int devfn;\n\tstruct pci_dev *dev = NULL;\n\tu8 bus = cpu_bus_msr >> (3 * BUS_NUM_STRIDE);\n\n\tfor (idx = 0; idx < type->num_boxes; idx++) {\n\t\tupi = &type->topology[die][idx];\n\t\tdevfn = PCI_DEVFN(SKX_UPI_REGS_ADDR_DEVICE_LINK0 + idx,\n\t\t\t\t  SKX_UPI_REGS_ADDR_FUNCTION);\n\t\tdev = pci_get_domain_bus_and_slot(segment, bus, devfn);\n\t\tif (dev) {\n\t\t\tret = upi_fill_topology(dev, upi, idx);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tpci_dev_put(dev);\n\treturn ret;\n}\n\nstatic int skx_upi_get_topology(struct intel_uncore_type *type)\n{\n\t \n\tif (boot_cpu_data.x86_stepping == 11)\n\t\treturn -EPERM;\n\n\treturn skx_pmu_get_topology(type, skx_upi_topology_cb);\n}\n\nstatic struct attribute_group skx_upi_mapping_group = {\n\t.is_visible\t= skx_upi_mapping_visible,\n};\n\nstatic const struct attribute_group *skx_upi_attr_update[] = {\n\t&skx_upi_mapping_group,\n\tNULL\n};\n\nstatic void\npmu_upi_set_mapping(struct intel_uncore_type *type, struct attribute_group *ag)\n{\n\tpmu_set_mapping(type, ag, skx_upi_mapping_show, UPI_TOPOLOGY_TYPE);\n}\n\nstatic void skx_upi_set_mapping(struct intel_uncore_type *type)\n{\n\tpmu_upi_set_mapping(type, &skx_upi_mapping_group);\n}\n\nstatic void skx_upi_cleanup_mapping(struct intel_uncore_type *type)\n{\n\tpmu_cleanup_mapping(type, &skx_upi_mapping_group);\n}\n\nstatic struct intel_uncore_type skx_uncore_upi = {\n\t.name\t\t= \"upi\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 3,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= SKX_UPI_PCI_PMON_CTR0,\n\t.event_ctl\t= SKX_UPI_PCI_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext = SKX_UPI_CTL_UMASK_EXT,\n\t.box_ctl\t= SKX_UPI_PCI_PMON_BOX_CTL,\n\t.ops\t\t= &skx_upi_uncore_pci_ops,\n\t.format_group\t= &skx_upi_uncore_format_group,\n\t.attr_update\t= skx_upi_attr_update,\n\t.get_topology\t= skx_upi_get_topology,\n\t.set_mapping\t= skx_upi_set_mapping,\n\t.cleanup_mapping = skx_upi_cleanup_mapping,\n};\n\nstatic void skx_m2m_uncore_pci_init_box(struct intel_uncore_box *box)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\n\t__set_bit(UNCORE_BOX_FLAG_CTL_OFFS8, &box->flags);\n\tpci_write_config_dword(pdev, SKX_M2M_PCI_PMON_BOX_CTL, IVBEP_PMON_BOX_CTL_INT);\n}\n\nstatic struct intel_uncore_ops skx_m2m_uncore_pci_ops = {\n\t.init_box\t= skx_m2m_uncore_pci_init_box,\n\t.disable_box\t= snbep_uncore_pci_disable_box,\n\t.enable_box\t= snbep_uncore_pci_enable_box,\n\t.disable_event\t= snbep_uncore_pci_disable_event,\n\t.enable_event\t= snbep_uncore_pci_enable_event,\n\t.read_counter\t= snbep_uncore_pci_read_counter,\n};\n\nstatic struct intel_uncore_type skx_uncore_m2m = {\n\t.name\t\t= \"m2m\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= SKX_M2M_PCI_PMON_CTR0,\n\t.event_ctl\t= SKX_M2M_PCI_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t= SKX_M2M_PCI_PMON_BOX_CTL,\n\t.ops\t\t= &skx_m2m_uncore_pci_ops,\n\t.format_group\t= &skx_uncore_format_group,\n};\n\nstatic struct event_constraint skx_uncore_m2pcie_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type skx_uncore_m2pcie = {\n\t.name\t\t= \"m2pcie\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 4,\n\t.perf_ctr_bits\t= 48,\n\t.constraints\t= skx_uncore_m2pcie_constraints,\n\t.perf_ctr\t= SNBEP_PCI_PMON_CTR0,\n\t.event_ctl\t= SNBEP_PCI_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.ops\t\t= &ivbep_uncore_pci_ops,\n\t.format_group\t= &skx_uncore_format_group,\n};\n\nstatic struct event_constraint skx_uncore_m3upi_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x1d, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x1e, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x40, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x4e, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x4f, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x50, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x51, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x52, 0x7),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type skx_uncore_m3upi = {\n\t.name\t\t= \"m3upi\",\n\t.num_counters   = 3,\n\t.num_boxes\t= 3,\n\t.perf_ctr_bits\t= 48,\n\t.constraints\t= skx_uncore_m3upi_constraints,\n\t.perf_ctr\t= SNBEP_PCI_PMON_CTR0,\n\t.event_ctl\t= SNBEP_PCI_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t= SNBEP_PCI_PMON_BOX_CTL,\n\t.ops\t\t= &ivbep_uncore_pci_ops,\n\t.format_group\t= &skx_uncore_format_group,\n};\n\nenum {\n\tSKX_PCI_UNCORE_IMC,\n\tSKX_PCI_UNCORE_M2M,\n\tSKX_PCI_UNCORE_UPI,\n\tSKX_PCI_UNCORE_M2PCIE,\n\tSKX_PCI_UNCORE_M3UPI,\n};\n\nstatic struct intel_uncore_type *skx_pci_uncores[] = {\n\t[SKX_PCI_UNCORE_IMC]\t= &skx_uncore_imc,\n\t[SKX_PCI_UNCORE_M2M]\t= &skx_uncore_m2m,\n\t[SKX_PCI_UNCORE_UPI]\t= &skx_uncore_upi,\n\t[SKX_PCI_UNCORE_M2PCIE]\t= &skx_uncore_m2pcie,\n\t[SKX_PCI_UNCORE_M3UPI]\t= &skx_uncore_m3upi,\n\tNULL,\n};\n\nstatic const struct pci_device_id skx_uncore_pci_ids[] = {\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2042),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(10, 2, SKX_PCI_UNCORE_IMC, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2046),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(10, 6, SKX_PCI_UNCORE_IMC, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x204a),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(11, 2, SKX_PCI_UNCORE_IMC, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2042),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(12, 2, SKX_PCI_UNCORE_IMC, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2046),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(12, 6, SKX_PCI_UNCORE_IMC, 4),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x204a),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(13, 2, SKX_PCI_UNCORE_IMC, 5),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2066),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(8, 0, SKX_PCI_UNCORE_M2M, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2066),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(9, 0, SKX_PCI_UNCORE_M2M, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2058),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(14, 0, SKX_PCI_UNCORE_UPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2058),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(15, 0, SKX_PCI_UNCORE_UPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2058),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(16, 0, SKX_PCI_UNCORE_UPI, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2088),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(21, 1, SKX_PCI_UNCORE_M2PCIE, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2088),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(22, 1, SKX_PCI_UNCORE_M2PCIE, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2088),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(23, 1, SKX_PCI_UNCORE_M2PCIE, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2088),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(21, 5, SKX_PCI_UNCORE_M2PCIE, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x204D),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(18, 1, SKX_PCI_UNCORE_M3UPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x204E),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(18, 2, SKX_PCI_UNCORE_M3UPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x204D),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(18, 5, SKX_PCI_UNCORE_M3UPI, 2),\n\t},\n\t{   }\n};\n\n\nstatic struct pci_driver skx_uncore_pci_driver = {\n\t.name\t\t= \"skx_uncore\",\n\t.id_table\t= skx_uncore_pci_ids,\n};\n\nint skx_uncore_pci_init(void)\n{\n\t \n\tint ret = snbep_pci2phy_map_init(0x2014, SKX_CPUNODEID, SKX_GIDNIDMAP, false);\n\n\tif (ret)\n\t\treturn ret;\n\n\tuncore_pci_uncores = skx_pci_uncores;\n\tuncore_pci_driver = &skx_uncore_pci_driver;\n\treturn 0;\n}\n\n \n\n \n\nstatic struct intel_uncore_type snr_uncore_ubox = {\n\t.name\t\t\t= \"ubox\",\n\t.num_counters\t\t= 2,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.fixed_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= SNR_U_MSR_PMON_CTR0,\n\t.event_ctl\t\t= SNR_U_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.fixed_ctr\t\t= SNR_U_MSR_PMON_UCLK_FIXED_CTR,\n\t.fixed_ctl\t\t= SNR_U_MSR_PMON_UCLK_FIXED_CTL,\n\t.ops\t\t\t= &ivbep_uncore_msr_ops,\n\t.format_group\t\t= &ivbep_uncore_format_group,\n};\n\nstatic struct attribute *snr_uncore_cha_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask_ext2.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_tid_en.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_filter_tid5.attr,\n\tNULL,\n};\nstatic const struct attribute_group snr_uncore_chabox_format_group = {\n\t.name = \"format\",\n\t.attrs = snr_uncore_cha_formats_attr,\n};\n\nstatic int snr_cha_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\n\treg1->reg = SNR_C0_MSR_PMON_BOX_FILTER0 +\n\t\t    box->pmu->type->msr_offset * box->pmu->pmu_idx;\n\treg1->config = event->attr.config1 & SKX_CHA_MSR_PMON_BOX_FILTER_TID;\n\treg1->idx = 0;\n\n\treturn 0;\n}\n\nstatic void snr_cha_enable_event(struct intel_uncore_box *box,\n\t\t\t\t   struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\n\tif (reg1->idx != EXTRA_REG_NONE)\n\t\twrmsrl(reg1->reg, reg1->config);\n\n\twrmsrl(hwc->config_base, hwc->config | SNBEP_PMON_CTL_EN);\n}\n\nstatic struct intel_uncore_ops snr_uncore_chabox_ops = {\n\t.init_box\t\t= ivbep_uncore_msr_init_box,\n\t.disable_box\t\t= snbep_uncore_msr_disable_box,\n\t.enable_box\t\t= snbep_uncore_msr_enable_box,\n\t.disable_event\t\t= snbep_uncore_msr_disable_event,\n\t.enable_event\t\t= snr_cha_enable_event,\n\t.read_counter\t\t= uncore_msr_read_counter,\n\t.hw_config\t\t= snr_cha_hw_config,\n};\n\nstatic struct intel_uncore_type snr_uncore_chabox = {\n\t.name\t\t\t= \"cha\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 6,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= SNR_CHA_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= SNR_CHA_MSR_PMON_CTR0,\n\t.box_ctl\t\t= SNR_CHA_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= HSWEP_CBO_MSR_OFFSET,\n\t.event_mask\t\t= HSWEP_S_MSR_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t\t= SNR_CHA_RAW_EVENT_MASK_EXT,\n\t.ops\t\t\t= &snr_uncore_chabox_ops,\n\t.format_group\t\t= &snr_uncore_chabox_format_group,\n};\n\nstatic struct attribute *snr_uncore_iio_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh9.attr,\n\t&format_attr_ch_mask2.attr,\n\t&format_attr_fc_mask2.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group snr_uncore_iio_format_group = {\n\t.name = \"format\",\n\t.attrs = snr_uncore_iio_formats_attr,\n};\n\nstatic umode_t\nsnr_iio_mapping_visible(struct kobject *kobj, struct attribute *attr, int die)\n{\n\t \n\treturn pmu_iio_mapping_visible(kobj, attr, die, 1);\n}\n\nstatic struct attribute_group snr_iio_mapping_group = {\n\t.is_visible\t= snr_iio_mapping_visible,\n};\n\nstatic const struct attribute_group *snr_iio_attr_update[] = {\n\t&snr_iio_mapping_group,\n\tNULL,\n};\n\nstatic int sad_cfg_iio_topology(struct intel_uncore_type *type, u8 *sad_pmon_mapping)\n{\n\tu32 sad_cfg;\n\tint die, stack_id, ret = -EPERM;\n\tstruct pci_dev *dev = NULL;\n\n\twhile ((dev = pci_get_device(PCI_VENDOR_ID_INTEL, SNR_ICX_MESH2IIO_MMAP_DID, dev))) {\n\t\tret = pci_read_config_dword(dev, SNR_ICX_SAD_CONTROL_CFG, &sad_cfg);\n\t\tif (ret) {\n\t\t\tret = pcibios_err_to_errno(ret);\n\t\t\tbreak;\n\t\t}\n\n\t\tdie = uncore_pcibus_to_dieid(dev->bus);\n\t\tstack_id = SAD_CONTROL_STACK_ID(sad_cfg);\n\t\tif (die < 0 || stack_id >= type->num_boxes) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tstack_id = sad_pmon_mapping[stack_id];\n\n\t\ttype->topology[die][stack_id].iio->segment = pci_domain_nr(dev->bus);\n\t\ttype->topology[die][stack_id].pmu_idx = stack_id;\n\t\ttype->topology[die][stack_id].iio->pci_bus_no = dev->bus->number;\n\t}\n\n\tpci_dev_put(dev);\n\n\treturn ret;\n}\n\n \nenum {\n\tSNR_QAT_PMON_ID,\n\tSNR_CBDMA_DMI_PMON_ID,\n\tSNR_NIS_PMON_ID,\n\tSNR_DLB_PMON_ID,\n\tSNR_PCIE_GEN3_PMON_ID\n};\n\nstatic u8 snr_sad_pmon_mapping[] = {\n\tSNR_CBDMA_DMI_PMON_ID,\n\tSNR_PCIE_GEN3_PMON_ID,\n\tSNR_DLB_PMON_ID,\n\tSNR_NIS_PMON_ID,\n\tSNR_QAT_PMON_ID\n};\n\nstatic int snr_iio_get_topology(struct intel_uncore_type *type)\n{\n\treturn sad_cfg_iio_topology(type, snr_sad_pmon_mapping);\n}\n\nstatic void snr_iio_set_mapping(struct intel_uncore_type *type)\n{\n\tpmu_iio_set_mapping(type, &snr_iio_mapping_group);\n}\n\nstatic void snr_iio_cleanup_mapping(struct intel_uncore_type *type)\n{\n\tpmu_cleanup_mapping(type, &snr_iio_mapping_group);\n}\n\nstatic struct event_constraint snr_uncore_iio_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x83, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0xc0, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0xd5, 0xc),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type snr_uncore_iio = {\n\t.name\t\t\t= \"iio\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 5,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= SNR_IIO_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= SNR_IIO_MSR_PMON_CTR0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t\t= SNR_IIO_PMON_RAW_EVENT_MASK_EXT,\n\t.box_ctl\t\t= SNR_IIO_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= SNR_IIO_MSR_OFFSET,\n\t.constraints\t\t= snr_uncore_iio_constraints,\n\t.ops\t\t\t= &ivbep_uncore_msr_ops,\n\t.format_group\t\t= &snr_uncore_iio_format_group,\n\t.attr_update\t\t= snr_iio_attr_update,\n\t.get_topology\t\t= snr_iio_get_topology,\n\t.set_mapping\t\t= snr_iio_set_mapping,\n\t.cleanup_mapping\t= snr_iio_cleanup_mapping,\n};\n\nstatic struct intel_uncore_type snr_uncore_irp = {\n\t.name\t\t\t= \"irp\",\n\t.num_counters\t\t= 2,\n\t.num_boxes\t\t= 5,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= SNR_IRP0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= SNR_IRP0_MSR_PMON_CTR0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNR_IRP0_MSR_PMON_BOX_CTL,\n\t.msr_offset\t\t= SNR_IRP_MSR_OFFSET,\n\t.ops\t\t\t= &ivbep_uncore_msr_ops,\n\t.format_group\t\t= &ivbep_uncore_format_group,\n};\n\nstatic struct intel_uncore_type snr_uncore_m2pcie = {\n\t.name\t\t= \"m2pcie\",\n\t.num_counters\t= 4,\n\t.num_boxes\t= 5,\n\t.perf_ctr_bits\t= 48,\n\t.event_ctl\t= SNR_M2PCIE_MSR_PMON_CTL0,\n\t.perf_ctr\t= SNR_M2PCIE_MSR_PMON_CTR0,\n\t.box_ctl\t= SNR_M2PCIE_MSR_PMON_BOX_CTL,\n\t.msr_offset\t= SNR_M2PCIE_MSR_OFFSET,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.ops\t\t= &ivbep_uncore_msr_ops,\n\t.format_group\t= &ivbep_uncore_format_group,\n};\n\nstatic int snr_pcu_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tint ev_sel = hwc->config & SNBEP_PMON_CTL_EV_SEL_MASK;\n\n\tif (ev_sel >= 0xb && ev_sel <= 0xe) {\n\t\treg1->reg = SNR_PCU_MSR_PMON_BOX_FILTER;\n\t\treg1->idx = ev_sel - 0xb;\n\t\treg1->config = event->attr.config1 & (0xff << reg1->idx);\n\t}\n\treturn 0;\n}\n\nstatic struct intel_uncore_ops snr_uncore_pcu_ops = {\n\tIVBEP_UNCORE_MSR_OPS_COMMON_INIT(),\n\t.hw_config\t\t= snr_pcu_hw_config,\n\t.get_constraint\t\t= snbep_pcu_get_constraint,\n\t.put_constraint\t\t= snbep_pcu_put_constraint,\n};\n\nstatic struct intel_uncore_type snr_uncore_pcu = {\n\t.name\t\t\t= \"pcu\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= SNR_PCU_MSR_PMON_CTR0,\n\t.event_ctl\t\t= SNR_PCU_MSR_PMON_CTL0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= SNR_PCU_MSR_PMON_BOX_CTL,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &snr_uncore_pcu_ops,\n\t.format_group\t\t= &skx_uncore_pcu_format_group,\n};\n\nenum perf_uncore_snr_iio_freerunning_type_id {\n\tSNR_IIO_MSR_IOCLK,\n\tSNR_IIO_MSR_BW_IN,\n\n\tSNR_IIO_FREERUNNING_TYPE_MAX,\n};\n\nstatic struct freerunning_counters snr_iio_freerunning[] = {\n\t[SNR_IIO_MSR_IOCLK]\t= { 0x1eac, 0x1, 0x10, 1, 48 },\n\t[SNR_IIO_MSR_BW_IN]\t= { 0x1f00, 0x1, 0x10, 8, 48 },\n};\n\nstatic struct uncore_event_desc snr_uncore_iio_freerunning_events[] = {\n\t \n\tINTEL_UNCORE_EVENT_DESC(ioclk,\t\t\t\"event=0xff,umask=0x10\"),\n\t \n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0,\t\t\"event=0xff,umask=0x20\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1,\t\t\"event=0xff,umask=0x21\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2,\t\t\"event=0xff,umask=0x22\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3,\t\t\"event=0xff,umask=0x23\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port4,\t\t\"event=0xff,umask=0x24\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port4.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port4.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port5,\t\t\"event=0xff,umask=0x25\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port5.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port5.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port6,\t\t\"event=0xff,umask=0x26\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port6.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port6.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port7,\t\t\"event=0xff,umask=0x27\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port7.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port7.unit,\t\"MiB\"),\n\t{   },\n};\n\nstatic struct intel_uncore_type snr_uncore_iio_free_running = {\n\t.name\t\t\t= \"iio_free_running\",\n\t.num_counters\t\t= 9,\n\t.num_boxes\t\t= 5,\n\t.num_freerunning_types\t= SNR_IIO_FREERUNNING_TYPE_MAX,\n\t.freerunning\t\t= snr_iio_freerunning,\n\t.ops\t\t\t= &skx_uncore_iio_freerunning_ops,\n\t.event_descs\t\t= snr_uncore_iio_freerunning_events,\n\t.format_group\t\t= &skx_uncore_iio_freerunning_format_group,\n};\n\nstatic struct intel_uncore_type *snr_msr_uncores[] = {\n\t&snr_uncore_ubox,\n\t&snr_uncore_chabox,\n\t&snr_uncore_iio,\n\t&snr_uncore_irp,\n\t&snr_uncore_m2pcie,\n\t&snr_uncore_pcu,\n\t&snr_uncore_iio_free_running,\n\tNULL,\n};\n\nvoid snr_uncore_cpu_init(void)\n{\n\tuncore_msr_uncores = snr_msr_uncores;\n}\n\nstatic void snr_m2m_uncore_pci_init_box(struct intel_uncore_box *box)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tint box_ctl = uncore_pci_box_ctl(box);\n\n\t__set_bit(UNCORE_BOX_FLAG_CTL_OFFS8, &box->flags);\n\tpci_write_config_dword(pdev, box_ctl, IVBEP_PMON_BOX_CTL_INT);\n}\n\nstatic struct intel_uncore_ops snr_m2m_uncore_pci_ops = {\n\t.init_box\t= snr_m2m_uncore_pci_init_box,\n\t.disable_box\t= snbep_uncore_pci_disable_box,\n\t.enable_box\t= snbep_uncore_pci_enable_box,\n\t.disable_event\t= snbep_uncore_pci_disable_event,\n\t.enable_event\t= snbep_uncore_pci_enable_event,\n\t.read_counter\t= snbep_uncore_pci_read_counter,\n};\n\nstatic struct attribute *snr_m2m_uncore_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask_ext3.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group snr_m2m_uncore_format_group = {\n\t.name = \"format\",\n\t.attrs = snr_m2m_uncore_formats_attr,\n};\n\nstatic struct intel_uncore_type snr_uncore_m2m = {\n\t.name\t\t= \"m2m\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= SNR_M2M_PCI_PMON_CTR0,\n\t.event_ctl\t= SNR_M2M_PCI_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t= SNR_M2M_PCI_PMON_UMASK_EXT,\n\t.box_ctl\t= SNR_M2M_PCI_PMON_BOX_CTL,\n\t.ops\t\t= &snr_m2m_uncore_pci_ops,\n\t.format_group\t= &snr_m2m_uncore_format_group,\n};\n\nstatic void snr_uncore_pci_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tpci_write_config_dword(pdev, hwc->config_base, (u32)(hwc->config | SNBEP_PMON_CTL_EN));\n\tpci_write_config_dword(pdev, hwc->config_base + 4, (u32)(hwc->config >> 32));\n}\n\nstatic struct intel_uncore_ops snr_pcie3_uncore_pci_ops = {\n\t.init_box\t= snr_m2m_uncore_pci_init_box,\n\t.disable_box\t= snbep_uncore_pci_disable_box,\n\t.enable_box\t= snbep_uncore_pci_enable_box,\n\t.disable_event\t= snbep_uncore_pci_disable_event,\n\t.enable_event\t= snr_uncore_pci_enable_event,\n\t.read_counter\t= snbep_uncore_pci_read_counter,\n};\n\nstatic struct intel_uncore_type snr_uncore_pcie3 = {\n\t.name\t\t= \"pcie3\",\n\t.num_counters\t= 4,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= SNR_PCIE3_PCI_PMON_CTR0,\n\t.event_ctl\t= SNR_PCIE3_PCI_PMON_CTL0,\n\t.event_mask\t= SKX_IIO_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t= SKX_IIO_PMON_RAW_EVENT_MASK_EXT,\n\t.box_ctl\t= SNR_PCIE3_PCI_PMON_BOX_CTL,\n\t.ops\t\t= &snr_pcie3_uncore_pci_ops,\n\t.format_group\t= &skx_uncore_iio_format_group,\n};\n\nenum {\n\tSNR_PCI_UNCORE_M2M,\n\tSNR_PCI_UNCORE_PCIE3,\n};\n\nstatic struct intel_uncore_type *snr_pci_uncores[] = {\n\t[SNR_PCI_UNCORE_M2M]\t\t= &snr_uncore_m2m,\n\t[SNR_PCI_UNCORE_PCIE3]\t\t= &snr_uncore_pcie3,\n\tNULL,\n};\n\nstatic const struct pci_device_id snr_uncore_pci_ids[] = {\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x344a),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(12, 0, SNR_PCI_UNCORE_M2M, 0),\n\t},\n\t{   }\n};\n\nstatic struct pci_driver snr_uncore_pci_driver = {\n\t.name\t\t= \"snr_uncore\",\n\t.id_table\t= snr_uncore_pci_ids,\n};\n\nstatic const struct pci_device_id snr_uncore_pci_sub_ids[] = {\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x334a),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(4, 0, SNR_PCI_UNCORE_PCIE3, 0),\n\t},\n\t{   }\n};\n\nstatic struct pci_driver snr_uncore_pci_sub_driver = {\n\t.name\t\t= \"snr_uncore_sub\",\n\t.id_table\t= snr_uncore_pci_sub_ids,\n};\n\nint snr_uncore_pci_init(void)\n{\n\t \n\tint ret = snbep_pci2phy_map_init(0x3460, SKX_CPUNODEID,\n\t\t\t\t\t SKX_GIDNIDMAP, true);\n\n\tif (ret)\n\t\treturn ret;\n\n\tuncore_pci_uncores = snr_pci_uncores;\n\tuncore_pci_driver = &snr_uncore_pci_driver;\n\tuncore_pci_sub_driver = &snr_uncore_pci_sub_driver;\n\treturn 0;\n}\n\n#define SNR_MC_DEVICE_ID\t0x3451\n\nstatic struct pci_dev *snr_uncore_get_mc_dev(unsigned int device, int id)\n{\n\tstruct pci_dev *mc_dev = NULL;\n\tint pkg;\n\n\twhile (1) {\n\t\tmc_dev = pci_get_device(PCI_VENDOR_ID_INTEL, device, mc_dev);\n\t\tif (!mc_dev)\n\t\t\tbreak;\n\t\tpkg = uncore_pcibus_to_dieid(mc_dev->bus);\n\t\tif (pkg == id)\n\t\t\tbreak;\n\t}\n\treturn mc_dev;\n}\n\nstatic int snr_uncore_mmio_map(struct intel_uncore_box *box,\n\t\t\t       unsigned int box_ctl, int mem_offset,\n\t\t\t       unsigned int device)\n{\n\tstruct pci_dev *pdev = snr_uncore_get_mc_dev(device, box->dieid);\n\tstruct intel_uncore_type *type = box->pmu->type;\n\tresource_size_t addr;\n\tu32 pci_dword;\n\n\tif (!pdev)\n\t\treturn -ENODEV;\n\n\tpci_read_config_dword(pdev, SNR_IMC_MMIO_BASE_OFFSET, &pci_dword);\n\taddr = ((resource_size_t)pci_dword & SNR_IMC_MMIO_BASE_MASK) << 23;\n\n\tpci_read_config_dword(pdev, mem_offset, &pci_dword);\n\taddr |= (pci_dword & SNR_IMC_MMIO_MEM0_MASK) << 12;\n\n\taddr += box_ctl;\n\n\tpci_dev_put(pdev);\n\n\tbox->io_addr = ioremap(addr, type->mmio_map_size);\n\tif (!box->io_addr) {\n\t\tpr_warn(\"perf uncore: Failed to ioremap for %s.\\n\", type->name);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void __snr_uncore_mmio_init_box(struct intel_uncore_box *box,\n\t\t\t\t       unsigned int box_ctl, int mem_offset,\n\t\t\t\t       unsigned int device)\n{\n\tif (!snr_uncore_mmio_map(box, box_ctl, mem_offset, device))\n\t\twritel(IVBEP_PMON_BOX_CTL_INT, box->io_addr);\n}\n\nstatic void snr_uncore_mmio_init_box(struct intel_uncore_box *box)\n{\n\t__snr_uncore_mmio_init_box(box, uncore_mmio_box_ctl(box),\n\t\t\t\t   SNR_IMC_MMIO_MEM0_OFFSET,\n\t\t\t\t   SNR_MC_DEVICE_ID);\n}\n\nstatic void snr_uncore_mmio_disable_box(struct intel_uncore_box *box)\n{\n\tu32 config;\n\n\tif (!box->io_addr)\n\t\treturn;\n\n\tconfig = readl(box->io_addr);\n\tconfig |= SNBEP_PMON_BOX_CTL_FRZ;\n\twritel(config, box->io_addr);\n}\n\nstatic void snr_uncore_mmio_enable_box(struct intel_uncore_box *box)\n{\n\tu32 config;\n\n\tif (!box->io_addr)\n\t\treturn;\n\n\tconfig = readl(box->io_addr);\n\tconfig &= ~SNBEP_PMON_BOX_CTL_FRZ;\n\twritel(config, box->io_addr);\n}\n\nstatic void snr_uncore_mmio_enable_event(struct intel_uncore_box *box,\n\t\t\t\t\t   struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (!box->io_addr)\n\t\treturn;\n\n\tif (!uncore_mmio_is_valid_offset(box, hwc->config_base))\n\t\treturn;\n\n\twritel(hwc->config | SNBEP_PMON_CTL_EN,\n\t       box->io_addr + hwc->config_base);\n}\n\nstatic void snr_uncore_mmio_disable_event(struct intel_uncore_box *box,\n\t\t\t\t\t    struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (!box->io_addr)\n\t\treturn;\n\n\tif (!uncore_mmio_is_valid_offset(box, hwc->config_base))\n\t\treturn;\n\n\twritel(hwc->config, box->io_addr + hwc->config_base);\n}\n\nstatic struct intel_uncore_ops snr_uncore_mmio_ops = {\n\t.init_box\t= snr_uncore_mmio_init_box,\n\t.exit_box\t= uncore_mmio_exit_box,\n\t.disable_box\t= snr_uncore_mmio_disable_box,\n\t.enable_box\t= snr_uncore_mmio_enable_box,\n\t.disable_event\t= snr_uncore_mmio_disable_event,\n\t.enable_event\t= snr_uncore_mmio_enable_event,\n\t.read_counter\t= uncore_mmio_read_counter,\n};\n\nstatic struct uncore_event_desc snr_uncore_imc_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(clockticks,      \"event=0x00,umask=0x00\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read,  \"event=0x04,umask=0x0f\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read.unit, \"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write, \"event=0x04,umask=0x30\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write.unit, \"MiB\"),\n\t{   },\n};\n\nstatic struct intel_uncore_type snr_uncore_imc = {\n\t.name\t\t= \"imc\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 48,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= SNR_IMC_MMIO_PMON_FIXED_CTR,\n\t.fixed_ctl\t= SNR_IMC_MMIO_PMON_FIXED_CTL,\n\t.event_descs\t= snr_uncore_imc_events,\n\t.perf_ctr\t= SNR_IMC_MMIO_PMON_CTR0,\n\t.event_ctl\t= SNR_IMC_MMIO_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t= SNR_IMC_MMIO_PMON_BOX_CTL,\n\t.mmio_offset\t= SNR_IMC_MMIO_OFFSET,\n\t.mmio_map_size\t= SNR_IMC_MMIO_SIZE,\n\t.ops\t\t= &snr_uncore_mmio_ops,\n\t.format_group\t= &skx_uncore_format_group,\n};\n\nenum perf_uncore_snr_imc_freerunning_type_id {\n\tSNR_IMC_DCLK,\n\tSNR_IMC_DDR,\n\n\tSNR_IMC_FREERUNNING_TYPE_MAX,\n};\n\nstatic struct freerunning_counters snr_imc_freerunning[] = {\n\t[SNR_IMC_DCLK]\t= { 0x22b0, 0x0, 0, 1, 48 },\n\t[SNR_IMC_DDR]\t= { 0x2290, 0x8, 0, 2, 48 },\n};\n\nstatic struct uncore_event_desc snr_uncore_imc_freerunning_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(dclk,\t\t\"event=0xff,umask=0x10\"),\n\n\tINTEL_UNCORE_EVENT_DESC(read,\t\t\"event=0xff,umask=0x20\"),\n\tINTEL_UNCORE_EVENT_DESC(read.scale,\t\"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(read.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(write,\t\t\"event=0xff,umask=0x21\"),\n\tINTEL_UNCORE_EVENT_DESC(write.scale,\t\"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(write.unit,\t\"MiB\"),\n\t{   },\n};\n\nstatic struct intel_uncore_ops snr_uncore_imc_freerunning_ops = {\n\t.init_box\t= snr_uncore_mmio_init_box,\n\t.exit_box\t= uncore_mmio_exit_box,\n\t.read_counter\t= uncore_mmio_read_counter,\n\t.hw_config\t= uncore_freerunning_hw_config,\n};\n\nstatic struct intel_uncore_type snr_uncore_imc_free_running = {\n\t.name\t\t\t= \"imc_free_running\",\n\t.num_counters\t\t= 3,\n\t.num_boxes\t\t= 1,\n\t.num_freerunning_types\t= SNR_IMC_FREERUNNING_TYPE_MAX,\n\t.mmio_map_size\t\t= SNR_IMC_MMIO_SIZE,\n\t.freerunning\t\t= snr_imc_freerunning,\n\t.ops\t\t\t= &snr_uncore_imc_freerunning_ops,\n\t.event_descs\t\t= snr_uncore_imc_freerunning_events,\n\t.format_group\t\t= &skx_uncore_iio_freerunning_format_group,\n};\n\nstatic struct intel_uncore_type *snr_mmio_uncores[] = {\n\t&snr_uncore_imc,\n\t&snr_uncore_imc_free_running,\n\tNULL,\n};\n\nvoid snr_uncore_mmio_init(void)\n{\n\tuncore_mmio_uncores = snr_mmio_uncores;\n}\n\n \n\n \n\nstatic unsigned icx_cha_msr_offsets[] = {\n\t0x2a0, 0x2ae, 0x2bc, 0x2ca, 0x2d8, 0x2e6, 0x2f4, 0x302, 0x310,\n\t0x31e, 0x32c, 0x33a, 0x348, 0x356, 0x364, 0x372, 0x380, 0x38e,\n\t0x3aa, 0x3b8, 0x3c6, 0x3d4, 0x3e2, 0x3f0, 0x3fe, 0x40c, 0x41a,\n\t0x428, 0x436, 0x444, 0x452, 0x460, 0x46e, 0x47c, 0x0,   0xe,\n\t0x1c,  0x2a,  0x38,  0x46,\n};\n\nstatic int icx_cha_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tbool tie_en = !!(event->hw.config & SNBEP_CBO_PMON_CTL_TID_EN);\n\n\tif (tie_en) {\n\t\treg1->reg = ICX_C34_MSR_PMON_BOX_FILTER0 +\n\t\t\t    icx_cha_msr_offsets[box->pmu->pmu_idx];\n\t\treg1->config = event->attr.config1 & SKX_CHA_MSR_PMON_BOX_FILTER_TID;\n\t\treg1->idx = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic struct intel_uncore_ops icx_uncore_chabox_ops = {\n\t.init_box\t\t= ivbep_uncore_msr_init_box,\n\t.disable_box\t\t= snbep_uncore_msr_disable_box,\n\t.enable_box\t\t= snbep_uncore_msr_enable_box,\n\t.disable_event\t\t= snbep_uncore_msr_disable_event,\n\t.enable_event\t\t= snr_cha_enable_event,\n\t.read_counter\t\t= uncore_msr_read_counter,\n\t.hw_config\t\t= icx_cha_hw_config,\n};\n\nstatic struct intel_uncore_type icx_uncore_chabox = {\n\t.name\t\t\t= \"cha\",\n\t.num_counters\t\t= 4,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= ICX_C34_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= ICX_C34_MSR_PMON_CTR0,\n\t.box_ctl\t\t= ICX_C34_MSR_PMON_BOX_CTL,\n\t.msr_offsets\t\t= icx_cha_msr_offsets,\n\t.event_mask\t\t= HSWEP_S_MSR_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t\t= SNR_CHA_RAW_EVENT_MASK_EXT,\n\t.constraints\t\t= skx_uncore_chabox_constraints,\n\t.ops\t\t\t= &icx_uncore_chabox_ops,\n\t.format_group\t\t= &snr_uncore_chabox_format_group,\n};\n\nstatic unsigned icx_msr_offsets[] = {\n\t0x0, 0x20, 0x40, 0x90, 0xb0, 0xd0,\n};\n\nstatic struct event_constraint icx_uncore_iio_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x02, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x03, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x83, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x88, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0xc0, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0xc5, 0xc),\n\tUNCORE_EVENT_CONSTRAINT(0xd5, 0xc),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic umode_t\nicx_iio_mapping_visible(struct kobject *kobj, struct attribute *attr, int die)\n{\n\t \n\treturn pmu_iio_mapping_visible(kobj, attr, die, 5);\n}\n\nstatic struct attribute_group icx_iio_mapping_group = {\n\t.is_visible\t= icx_iio_mapping_visible,\n};\n\nstatic const struct attribute_group *icx_iio_attr_update[] = {\n\t&icx_iio_mapping_group,\n\tNULL,\n};\n\n \nenum {\n\tICX_PCIE1_PMON_ID,\n\tICX_PCIE2_PMON_ID,\n\tICX_PCIE3_PMON_ID,\n\tICX_PCIE4_PMON_ID,\n\tICX_PCIE5_PMON_ID,\n\tICX_CBDMA_DMI_PMON_ID\n};\n\nstatic u8 icx_sad_pmon_mapping[] = {\n\tICX_CBDMA_DMI_PMON_ID,\n\tICX_PCIE1_PMON_ID,\n\tICX_PCIE2_PMON_ID,\n\tICX_PCIE3_PMON_ID,\n\tICX_PCIE4_PMON_ID,\n\tICX_PCIE5_PMON_ID,\n};\n\nstatic int icx_iio_get_topology(struct intel_uncore_type *type)\n{\n\treturn sad_cfg_iio_topology(type, icx_sad_pmon_mapping);\n}\n\nstatic void icx_iio_set_mapping(struct intel_uncore_type *type)\n{\n\t \n\tif (boot_cpu_data.x86_model == INTEL_FAM6_ICELAKE_D) {\n\t\tpmu_clear_mapping_attr(type->attr_update, &icx_iio_mapping_group);\n\t\treturn;\n\t}\n\tpmu_iio_set_mapping(type, &icx_iio_mapping_group);\n}\n\nstatic void icx_iio_cleanup_mapping(struct intel_uncore_type *type)\n{\n\tpmu_cleanup_mapping(type, &icx_iio_mapping_group);\n}\n\nstatic struct intel_uncore_type icx_uncore_iio = {\n\t.name\t\t\t= \"iio\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 6,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= ICX_IIO_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= ICX_IIO_MSR_PMON_CTR0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t\t= SNR_IIO_PMON_RAW_EVENT_MASK_EXT,\n\t.box_ctl\t\t= ICX_IIO_MSR_PMON_BOX_CTL,\n\t.msr_offsets\t\t= icx_msr_offsets,\n\t.constraints\t\t= icx_uncore_iio_constraints,\n\t.ops\t\t\t= &skx_uncore_iio_ops,\n\t.format_group\t\t= &snr_uncore_iio_format_group,\n\t.attr_update\t\t= icx_iio_attr_update,\n\t.get_topology\t\t= icx_iio_get_topology,\n\t.set_mapping\t\t= icx_iio_set_mapping,\n\t.cleanup_mapping\t= icx_iio_cleanup_mapping,\n};\n\nstatic struct intel_uncore_type icx_uncore_irp = {\n\t.name\t\t\t= \"irp\",\n\t.num_counters\t\t= 2,\n\t.num_boxes\t\t= 6,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= ICX_IRP0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= ICX_IRP0_MSR_PMON_CTR0,\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= ICX_IRP0_MSR_PMON_BOX_CTL,\n\t.msr_offsets\t\t= icx_msr_offsets,\n\t.ops\t\t\t= &ivbep_uncore_msr_ops,\n\t.format_group\t\t= &ivbep_uncore_format_group,\n};\n\nstatic struct event_constraint icx_uncore_m2pcie_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x14, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x23, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2d, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type icx_uncore_m2pcie = {\n\t.name\t\t= \"m2pcie\",\n\t.num_counters\t= 4,\n\t.num_boxes\t= 6,\n\t.perf_ctr_bits\t= 48,\n\t.event_ctl\t= ICX_M2PCIE_MSR_PMON_CTL0,\n\t.perf_ctr\t= ICX_M2PCIE_MSR_PMON_CTR0,\n\t.box_ctl\t= ICX_M2PCIE_MSR_PMON_BOX_CTL,\n\t.msr_offsets\t= icx_msr_offsets,\n\t.constraints\t= icx_uncore_m2pcie_constraints,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.ops\t\t= &ivbep_uncore_msr_ops,\n\t.format_group\t= &ivbep_uncore_format_group,\n};\n\nenum perf_uncore_icx_iio_freerunning_type_id {\n\tICX_IIO_MSR_IOCLK,\n\tICX_IIO_MSR_BW_IN,\n\n\tICX_IIO_FREERUNNING_TYPE_MAX,\n};\n\nstatic unsigned icx_iio_clk_freerunning_box_offsets[] = {\n\t0x0, 0x20, 0x40, 0x90, 0xb0, 0xd0,\n};\n\nstatic unsigned icx_iio_bw_freerunning_box_offsets[] = {\n\t0x0, 0x10, 0x20, 0x90, 0xa0, 0xb0,\n};\n\nstatic struct freerunning_counters icx_iio_freerunning[] = {\n\t[ICX_IIO_MSR_IOCLK]\t= { 0xa55, 0x1, 0x20, 1, 48, icx_iio_clk_freerunning_box_offsets },\n\t[ICX_IIO_MSR_BW_IN]\t= { 0xaa0, 0x1, 0x10, 8, 48, icx_iio_bw_freerunning_box_offsets },\n};\n\nstatic struct uncore_event_desc icx_uncore_iio_freerunning_events[] = {\n\t \n\tINTEL_UNCORE_EVENT_DESC(ioclk,\t\t\t\"event=0xff,umask=0x10\"),\n\t \n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0,\t\t\"event=0xff,umask=0x20\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1,\t\t\"event=0xff,umask=0x21\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2,\t\t\"event=0xff,umask=0x22\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3,\t\t\"event=0xff,umask=0x23\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port4,\t\t\"event=0xff,umask=0x24\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port4.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port4.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port5,\t\t\"event=0xff,umask=0x25\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port5.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port5.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port6,\t\t\"event=0xff,umask=0x26\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port6.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port6.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port7,\t\t\"event=0xff,umask=0x27\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port7.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port7.unit,\t\"MiB\"),\n\t{   },\n};\n\nstatic struct intel_uncore_type icx_uncore_iio_free_running = {\n\t.name\t\t\t= \"iio_free_running\",\n\t.num_counters\t\t= 9,\n\t.num_boxes\t\t= 6,\n\t.num_freerunning_types\t= ICX_IIO_FREERUNNING_TYPE_MAX,\n\t.freerunning\t\t= icx_iio_freerunning,\n\t.ops\t\t\t= &skx_uncore_iio_freerunning_ops,\n\t.event_descs\t\t= icx_uncore_iio_freerunning_events,\n\t.format_group\t\t= &skx_uncore_iio_freerunning_format_group,\n};\n\nstatic struct intel_uncore_type *icx_msr_uncores[] = {\n\t&skx_uncore_ubox,\n\t&icx_uncore_chabox,\n\t&icx_uncore_iio,\n\t&icx_uncore_irp,\n\t&icx_uncore_m2pcie,\n\t&skx_uncore_pcu,\n\t&icx_uncore_iio_free_running,\n\tNULL,\n};\n\n \n#define ICX_CAPID6\t\t0x9c\n#define ICX_CAPID7\t\t0xa0\n\nstatic u64 icx_count_chabox(void)\n{\n\tstruct pci_dev *dev = NULL;\n\tu64 caps = 0;\n\n\tdev = pci_get_device(PCI_VENDOR_ID_INTEL, 0x345b, dev);\n\tif (!dev)\n\t\tgoto out;\n\n\tpci_read_config_dword(dev, ICX_CAPID6, (u32 *)&caps);\n\tpci_read_config_dword(dev, ICX_CAPID7, (u32 *)&caps + 1);\nout:\n\tpci_dev_put(dev);\n\treturn hweight64(caps);\n}\n\nvoid icx_uncore_cpu_init(void)\n{\n\tu64 num_boxes = icx_count_chabox();\n\n\tif (WARN_ON(num_boxes > ARRAY_SIZE(icx_cha_msr_offsets)))\n\t\treturn;\n\ticx_uncore_chabox.num_boxes = num_boxes;\n\tuncore_msr_uncores = icx_msr_uncores;\n}\n\nstatic struct intel_uncore_type icx_uncore_m2m = {\n\t.name\t\t= \"m2m\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 4,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= SNR_M2M_PCI_PMON_CTR0,\n\t.event_ctl\t= SNR_M2M_PCI_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t= SNR_M2M_PCI_PMON_UMASK_EXT,\n\t.box_ctl\t= SNR_M2M_PCI_PMON_BOX_CTL,\n\t.ops\t\t= &snr_m2m_uncore_pci_ops,\n\t.format_group\t= &snr_m2m_uncore_format_group,\n};\n\nstatic struct attribute *icx_upi_uncore_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask_ext4.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group icx_upi_uncore_format_group = {\n\t.name = \"format\",\n\t.attrs = icx_upi_uncore_formats_attr,\n};\n\n#define ICX_UPI_REGS_ADDR_DEVICE_LINK0\t0x02\n#define ICX_UPI_REGS_ADDR_FUNCTION\t0x01\n\nstatic int discover_upi_topology(struct intel_uncore_type *type, int ubox_did, int dev_link0)\n{\n\tstruct pci_dev *ubox = NULL;\n\tstruct pci_dev *dev = NULL;\n\tu32 nid, gid;\n\tint i, idx, lgc_pkg, ret = -EPERM;\n\tstruct intel_uncore_topology *upi;\n\tunsigned int devfn;\n\n\t \n\tif (uncore_max_dies() > 8)\n\t\tgoto err;\n\n\twhile ((ubox = pci_get_device(PCI_VENDOR_ID_INTEL, ubox_did, ubox))) {\n\t\tret = upi_nodeid_groupid(ubox, SKX_CPUNODEID, SKX_GIDNIDMAP, &nid, &gid);\n\t\tif (ret) {\n\t\t\tret = pcibios_err_to_errno(ret);\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (i = 0; i < 8; i++) {\n\t\t\tif (nid != GIDNIDMAP(gid, i))\n\t\t\t\tcontinue;\n\t\t\tlgc_pkg = topology_phys_to_logical_pkg(i);\n\t\t\tif (lgc_pkg < 0) {\n\t\t\t\tret = -EPERM;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tfor (idx = 0; idx < type->num_boxes; idx++) {\n\t\t\t\tupi = &type->topology[lgc_pkg][idx];\n\t\t\t\tdevfn = PCI_DEVFN(dev_link0 + idx, ICX_UPI_REGS_ADDR_FUNCTION);\n\t\t\t\tdev = pci_get_domain_bus_and_slot(pci_domain_nr(ubox->bus),\n\t\t\t\t\t\t\t\t  ubox->bus->number,\n\t\t\t\t\t\t\t\t  devfn);\n\t\t\t\tif (dev) {\n\t\t\t\t\tret = upi_fill_topology(dev, upi, idx);\n\t\t\t\t\tif (ret)\n\t\t\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\nerr:\n\tpci_dev_put(ubox);\n\tpci_dev_put(dev);\n\treturn ret;\n}\n\nstatic int icx_upi_get_topology(struct intel_uncore_type *type)\n{\n\treturn discover_upi_topology(type, ICX_UBOX_DID, ICX_UPI_REGS_ADDR_DEVICE_LINK0);\n}\n\nstatic struct attribute_group icx_upi_mapping_group = {\n\t.is_visible\t= skx_upi_mapping_visible,\n};\n\nstatic const struct attribute_group *icx_upi_attr_update[] = {\n\t&icx_upi_mapping_group,\n\tNULL\n};\n\nstatic void icx_upi_set_mapping(struct intel_uncore_type *type)\n{\n\tpmu_upi_set_mapping(type, &icx_upi_mapping_group);\n}\n\nstatic void icx_upi_cleanup_mapping(struct intel_uncore_type *type)\n{\n\tpmu_cleanup_mapping(type, &icx_upi_mapping_group);\n}\n\nstatic struct intel_uncore_type icx_uncore_upi = {\n\t.name\t\t= \"upi\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 3,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= ICX_UPI_PCI_PMON_CTR0,\n\t.event_ctl\t= ICX_UPI_PCI_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext = ICX_UPI_CTL_UMASK_EXT,\n\t.box_ctl\t= ICX_UPI_PCI_PMON_BOX_CTL,\n\t.ops\t\t= &skx_upi_uncore_pci_ops,\n\t.format_group\t= &icx_upi_uncore_format_group,\n\t.attr_update\t= icx_upi_attr_update,\n\t.get_topology\t= icx_upi_get_topology,\n\t.set_mapping\t= icx_upi_set_mapping,\n\t.cleanup_mapping = icx_upi_cleanup_mapping,\n};\n\nstatic struct event_constraint icx_uncore_m3upi_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x1c, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x1d, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x1e, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x1f, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x40, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x4e, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x4f, 0x7),\n\tUNCORE_EVENT_CONSTRAINT(0x50, 0x7),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type icx_uncore_m3upi = {\n\t.name\t\t= \"m3upi\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 3,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= ICX_M3UPI_PCI_PMON_CTR0,\n\t.event_ctl\t= ICX_M3UPI_PCI_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t= ICX_M3UPI_PCI_PMON_BOX_CTL,\n\t.constraints\t= icx_uncore_m3upi_constraints,\n\t.ops\t\t= &ivbep_uncore_pci_ops,\n\t.format_group\t= &skx_uncore_format_group,\n};\n\nenum {\n\tICX_PCI_UNCORE_M2M,\n\tICX_PCI_UNCORE_UPI,\n\tICX_PCI_UNCORE_M3UPI,\n};\n\nstatic struct intel_uncore_type *icx_pci_uncores[] = {\n\t[ICX_PCI_UNCORE_M2M]\t\t= &icx_uncore_m2m,\n\t[ICX_PCI_UNCORE_UPI]\t\t= &icx_uncore_upi,\n\t[ICX_PCI_UNCORE_M3UPI]\t\t= &icx_uncore_m3upi,\n\tNULL,\n};\n\nstatic const struct pci_device_id icx_uncore_pci_ids[] = {\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x344a),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(12, 0, ICX_PCI_UNCORE_M2M, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x344a),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(13, 0, ICX_PCI_UNCORE_M2M, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x344a),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(14, 0, ICX_PCI_UNCORE_M2M, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x344a),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(15, 0, ICX_PCI_UNCORE_M2M, 3),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x3441),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(2, 1, ICX_PCI_UNCORE_UPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x3441),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(3, 1, ICX_PCI_UNCORE_UPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x3441),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(4, 1, ICX_PCI_UNCORE_UPI, 2),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x3446),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(5, 1, ICX_PCI_UNCORE_M3UPI, 0),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x3446),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(6, 1, ICX_PCI_UNCORE_M3UPI, 1),\n\t},\n\t{  \n\t\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x3446),\n\t\t.driver_data = UNCORE_PCI_DEV_FULL_DATA(7, 1, ICX_PCI_UNCORE_M3UPI, 2),\n\t},\n\t{   }\n};\n\nstatic struct pci_driver icx_uncore_pci_driver = {\n\t.name\t\t= \"icx_uncore\",\n\t.id_table\t= icx_uncore_pci_ids,\n};\n\nint icx_uncore_pci_init(void)\n{\n\t \n\tint ret = snbep_pci2phy_map_init(0x3450, SKX_CPUNODEID,\n\t\t\t\t\t SKX_GIDNIDMAP, true);\n\n\tif (ret)\n\t\treturn ret;\n\n\tuncore_pci_uncores = icx_pci_uncores;\n\tuncore_pci_driver = &icx_uncore_pci_driver;\n\treturn 0;\n}\n\nstatic void icx_uncore_imc_init_box(struct intel_uncore_box *box)\n{\n\tunsigned int box_ctl = box->pmu->type->box_ctl +\n\t\t\t       box->pmu->type->mmio_offset * (box->pmu->pmu_idx % ICX_NUMBER_IMC_CHN);\n\tint mem_offset = (box->pmu->pmu_idx / ICX_NUMBER_IMC_CHN) * ICX_IMC_MEM_STRIDE +\n\t\t\t SNR_IMC_MMIO_MEM0_OFFSET;\n\n\t__snr_uncore_mmio_init_box(box, box_ctl, mem_offset,\n\t\t\t\t   SNR_MC_DEVICE_ID);\n}\n\nstatic struct intel_uncore_ops icx_uncore_mmio_ops = {\n\t.init_box\t= icx_uncore_imc_init_box,\n\t.exit_box\t= uncore_mmio_exit_box,\n\t.disable_box\t= snr_uncore_mmio_disable_box,\n\t.enable_box\t= snr_uncore_mmio_enable_box,\n\t.disable_event\t= snr_uncore_mmio_disable_event,\n\t.enable_event\t= snr_uncore_mmio_enable_event,\n\t.read_counter\t= uncore_mmio_read_counter,\n};\n\nstatic struct intel_uncore_type icx_uncore_imc = {\n\t.name\t\t= \"imc\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 12,\n\t.perf_ctr_bits\t= 48,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= SNR_IMC_MMIO_PMON_FIXED_CTR,\n\t.fixed_ctl\t= SNR_IMC_MMIO_PMON_FIXED_CTL,\n\t.event_descs\t= snr_uncore_imc_events,\n\t.perf_ctr\t= SNR_IMC_MMIO_PMON_CTR0,\n\t.event_ctl\t= SNR_IMC_MMIO_PMON_CTL0,\n\t.event_mask\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t= SNR_IMC_MMIO_PMON_BOX_CTL,\n\t.mmio_offset\t= SNR_IMC_MMIO_OFFSET,\n\t.mmio_map_size\t= SNR_IMC_MMIO_SIZE,\n\t.ops\t\t= &icx_uncore_mmio_ops,\n\t.format_group\t= &skx_uncore_format_group,\n};\n\nenum perf_uncore_icx_imc_freerunning_type_id {\n\tICX_IMC_DCLK,\n\tICX_IMC_DDR,\n\tICX_IMC_DDRT,\n\n\tICX_IMC_FREERUNNING_TYPE_MAX,\n};\n\nstatic struct freerunning_counters icx_imc_freerunning[] = {\n\t[ICX_IMC_DCLK]\t= { 0x22b0, 0x0, 0, 1, 48 },\n\t[ICX_IMC_DDR]\t= { 0x2290, 0x8, 0, 2, 48 },\n\t[ICX_IMC_DDRT]\t= { 0x22a0, 0x8, 0, 2, 48 },\n};\n\nstatic struct uncore_event_desc icx_uncore_imc_freerunning_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(dclk,\t\t\t\"event=0xff,umask=0x10\"),\n\n\tINTEL_UNCORE_EVENT_DESC(read,\t\t\t\"event=0xff,umask=0x20\"),\n\tINTEL_UNCORE_EVENT_DESC(read.scale,\t\t\"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(read.unit,\t\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(write,\t\t\t\"event=0xff,umask=0x21\"),\n\tINTEL_UNCORE_EVENT_DESC(write.scale,\t\t\"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(write.unit,\t\t\"MiB\"),\n\n\tINTEL_UNCORE_EVENT_DESC(ddrt_read,\t\t\"event=0xff,umask=0x30\"),\n\tINTEL_UNCORE_EVENT_DESC(ddrt_read.scale,\t\"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(ddrt_read.unit,\t\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(ddrt_write,\t\t\"event=0xff,umask=0x31\"),\n\tINTEL_UNCORE_EVENT_DESC(ddrt_write.scale,\t\"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(ddrt_write.unit,\t\"MiB\"),\n\t{   },\n};\n\nstatic void icx_uncore_imc_freerunning_init_box(struct intel_uncore_box *box)\n{\n\tint mem_offset = box->pmu->pmu_idx * ICX_IMC_MEM_STRIDE +\n\t\t\t SNR_IMC_MMIO_MEM0_OFFSET;\n\n\tsnr_uncore_mmio_map(box, uncore_mmio_box_ctl(box),\n\t\t\t    mem_offset, SNR_MC_DEVICE_ID);\n}\n\nstatic struct intel_uncore_ops icx_uncore_imc_freerunning_ops = {\n\t.init_box\t= icx_uncore_imc_freerunning_init_box,\n\t.exit_box\t= uncore_mmio_exit_box,\n\t.read_counter\t= uncore_mmio_read_counter,\n\t.hw_config\t= uncore_freerunning_hw_config,\n};\n\nstatic struct intel_uncore_type icx_uncore_imc_free_running = {\n\t.name\t\t\t= \"imc_free_running\",\n\t.num_counters\t\t= 5,\n\t.num_boxes\t\t= 4,\n\t.num_freerunning_types\t= ICX_IMC_FREERUNNING_TYPE_MAX,\n\t.mmio_map_size\t\t= SNR_IMC_MMIO_SIZE,\n\t.freerunning\t\t= icx_imc_freerunning,\n\t.ops\t\t\t= &icx_uncore_imc_freerunning_ops,\n\t.event_descs\t\t= icx_uncore_imc_freerunning_events,\n\t.format_group\t\t= &skx_uncore_iio_freerunning_format_group,\n};\n\nstatic struct intel_uncore_type *icx_mmio_uncores[] = {\n\t&icx_uncore_imc,\n\t&icx_uncore_imc_free_running,\n\tNULL,\n};\n\nvoid icx_uncore_mmio_init(void)\n{\n\tuncore_mmio_uncores = icx_mmio_uncores;\n}\n\n \n\n \n\nstatic void spr_uncore_msr_enable_event(struct intel_uncore_box *box,\n\t\t\t\t\tstruct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\n\tif (reg1->idx != EXTRA_REG_NONE)\n\t\twrmsrl(reg1->reg, reg1->config);\n\n\twrmsrl(hwc->config_base, hwc->config);\n}\n\nstatic void spr_uncore_msr_disable_event(struct intel_uncore_box *box,\n\t\t\t\t\t struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\n\tif (reg1->idx != EXTRA_REG_NONE)\n\t\twrmsrl(reg1->reg, 0);\n\n\twrmsrl(hwc->config_base, 0);\n}\n\nstatic int spr_cha_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tbool tie_en = !!(event->hw.config & SPR_CHA_PMON_CTL_TID_EN);\n\tstruct intel_uncore_type *type = box->pmu->type;\n\n\tif (tie_en) {\n\t\treg1->reg = SPR_C0_MSR_PMON_BOX_FILTER0 +\n\t\t\t    HSWEP_CBO_MSR_OFFSET * type->box_ids[box->pmu->pmu_idx];\n\t\treg1->config = event->attr.config1 & SPR_CHA_PMON_BOX_FILTER_TID;\n\t\treg1->idx = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic struct intel_uncore_ops spr_uncore_chabox_ops = {\n\t.init_box\t\t= intel_generic_uncore_msr_init_box,\n\t.disable_box\t\t= intel_generic_uncore_msr_disable_box,\n\t.enable_box\t\t= intel_generic_uncore_msr_enable_box,\n\t.disable_event\t\t= spr_uncore_msr_disable_event,\n\t.enable_event\t\t= spr_uncore_msr_enable_event,\n\t.read_counter\t\t= uncore_msr_read_counter,\n\t.hw_config\t\t= spr_cha_hw_config,\n\t.get_constraint\t\t= uncore_get_constraint,\n\t.put_constraint\t\t= uncore_put_constraint,\n};\n\nstatic struct attribute *spr_uncore_cha_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask_ext4.attr,\n\t&format_attr_tid_en2.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_filter_tid5.attr,\n\tNULL,\n};\nstatic const struct attribute_group spr_uncore_chabox_format_group = {\n\t.name = \"format\",\n\t.attrs = spr_uncore_cha_formats_attr,\n};\n\nstatic ssize_t alias_show(struct device *dev,\n\t\t\t  struct device_attribute *attr,\n\t\t\t  char *buf)\n{\n\tstruct intel_uncore_pmu *pmu = dev_to_uncore_pmu(dev);\n\tchar pmu_name[UNCORE_PMU_NAME_LEN];\n\n\tuncore_get_alias_name(pmu_name, pmu);\n\treturn sysfs_emit(buf, \"%s\\n\", pmu_name);\n}\n\nstatic DEVICE_ATTR_RO(alias);\n\nstatic struct attribute *uncore_alias_attrs[] = {\n\t&dev_attr_alias.attr,\n\tNULL\n};\n\nATTRIBUTE_GROUPS(uncore_alias);\n\nstatic struct intel_uncore_type spr_uncore_chabox = {\n\t.name\t\t\t= \"cha\",\n\t.event_mask\t\t= SPR_CHA_PMON_EVENT_MASK,\n\t.event_mask_ext\t\t= SPR_RAW_EVENT_MASK_EXT,\n\t.num_shared_regs\t= 1,\n\t.constraints\t\t= skx_uncore_chabox_constraints,\n\t.ops\t\t\t= &spr_uncore_chabox_ops,\n\t.format_group\t\t= &spr_uncore_chabox_format_group,\n\t.attr_update\t\t= uncore_alias_groups,\n};\n\nstatic struct intel_uncore_type spr_uncore_iio = {\n\t.name\t\t\t= \"iio\",\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t\t= SNR_IIO_PMON_RAW_EVENT_MASK_EXT,\n\t.format_group\t\t= &snr_uncore_iio_format_group,\n\t.attr_update\t\t= uncore_alias_groups,\n\t.constraints\t\t= icx_uncore_iio_constraints,\n};\n\nstatic struct attribute *spr_uncore_raw_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask_ext4.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group spr_uncore_raw_format_group = {\n\t.name\t\t\t= \"format\",\n\t.attrs\t\t\t= spr_uncore_raw_formats_attr,\n};\n\n#define SPR_UNCORE_COMMON_FORMAT()\t\t\t\t\\\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\t\\\n\t.event_mask_ext\t\t= SPR_RAW_EVENT_MASK_EXT,\t\\\n\t.format_group\t\t= &spr_uncore_raw_format_group,\t\\\n\t.attr_update\t\t= uncore_alias_groups\n\nstatic struct intel_uncore_type spr_uncore_irp = {\n\tSPR_UNCORE_COMMON_FORMAT(),\n\t.name\t\t\t= \"irp\",\n\n};\n\nstatic struct event_constraint spr_uncore_m2pcie_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x14, 0x3),\n\tUNCORE_EVENT_CONSTRAINT(0x2d, 0x3),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type spr_uncore_m2pcie = {\n\tSPR_UNCORE_COMMON_FORMAT(),\n\t.name\t\t\t= \"m2pcie\",\n\t.constraints\t\t= spr_uncore_m2pcie_constraints,\n};\n\nstatic struct intel_uncore_type spr_uncore_pcu = {\n\t.name\t\t\t= \"pcu\",\n\t.attr_update\t\t= uncore_alias_groups,\n};\n\nstatic void spr_uncore_mmio_enable_event(struct intel_uncore_box *box,\n\t\t\t\t\t struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (!box->io_addr)\n\t\treturn;\n\n\tif (uncore_pmc_fixed(hwc->idx))\n\t\twritel(SNBEP_PMON_CTL_EN, box->io_addr + hwc->config_base);\n\telse\n\t\twritel(hwc->config, box->io_addr + hwc->config_base);\n}\n\nstatic struct intel_uncore_ops spr_uncore_mmio_ops = {\n\t.init_box\t\t= intel_generic_uncore_mmio_init_box,\n\t.exit_box\t\t= uncore_mmio_exit_box,\n\t.disable_box\t\t= intel_generic_uncore_mmio_disable_box,\n\t.enable_box\t\t= intel_generic_uncore_mmio_enable_box,\n\t.disable_event\t\t= intel_generic_uncore_mmio_disable_event,\n\t.enable_event\t\t= spr_uncore_mmio_enable_event,\n\t.read_counter\t\t= uncore_mmio_read_counter,\n};\n\nstatic struct uncore_event_desc spr_uncore_imc_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(clockticks,      \"event=0x01,umask=0x00\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read,  \"event=0x05,umask=0xcf\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_read.unit, \"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write, \"event=0x05,umask=0xf0\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(cas_count_write.unit, \"MiB\"),\n\t{   },\n};\n\nstatic struct intel_uncore_type spr_uncore_imc = {\n\tSPR_UNCORE_COMMON_FORMAT(),\n\t.name\t\t\t= \"imc\",\n\t.fixed_ctr_bits\t\t= 48,\n\t.fixed_ctr\t\t= SNR_IMC_MMIO_PMON_FIXED_CTR,\n\t.fixed_ctl\t\t= SNR_IMC_MMIO_PMON_FIXED_CTL,\n\t.ops\t\t\t= &spr_uncore_mmio_ops,\n\t.event_descs\t\t= spr_uncore_imc_events,\n};\n\nstatic void spr_uncore_pci_enable_event(struct intel_uncore_box *box,\n\t\t\t\t\tstruct perf_event *event)\n{\n\tstruct pci_dev *pdev = box->pci_dev;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tpci_write_config_dword(pdev, hwc->config_base + 4, (u32)(hwc->config >> 32));\n\tpci_write_config_dword(pdev, hwc->config_base, (u32)hwc->config);\n}\n\nstatic struct intel_uncore_ops spr_uncore_pci_ops = {\n\t.init_box\t\t= intel_generic_uncore_pci_init_box,\n\t.disable_box\t\t= intel_generic_uncore_pci_disable_box,\n\t.enable_box\t\t= intel_generic_uncore_pci_enable_box,\n\t.disable_event\t\t= intel_generic_uncore_pci_disable_event,\n\t.enable_event\t\t= spr_uncore_pci_enable_event,\n\t.read_counter\t\t= intel_generic_uncore_pci_read_counter,\n};\n\n#define SPR_UNCORE_PCI_COMMON_FORMAT()\t\t\t\\\n\tSPR_UNCORE_COMMON_FORMAT(),\t\t\t\\\n\t.ops\t\t\t= &spr_uncore_pci_ops\n\nstatic struct intel_uncore_type spr_uncore_m2m = {\n\tSPR_UNCORE_PCI_COMMON_FORMAT(),\n\t.name\t\t\t= \"m2m\",\n};\n\nstatic struct attribute_group spr_upi_mapping_group = {\n\t.is_visible\t= skx_upi_mapping_visible,\n};\n\nstatic const struct attribute_group *spr_upi_attr_update[] = {\n\t&uncore_alias_group,\n\t&spr_upi_mapping_group,\n\tNULL\n};\n\n#define SPR_UPI_REGS_ADDR_DEVICE_LINK0\t0x01\n\nstatic void spr_upi_set_mapping(struct intel_uncore_type *type)\n{\n\tpmu_upi_set_mapping(type, &spr_upi_mapping_group);\n}\n\nstatic void spr_upi_cleanup_mapping(struct intel_uncore_type *type)\n{\n\tpmu_cleanup_mapping(type, &spr_upi_mapping_group);\n}\n\nstatic int spr_upi_get_topology(struct intel_uncore_type *type)\n{\n\treturn discover_upi_topology(type, SPR_UBOX_DID, SPR_UPI_REGS_ADDR_DEVICE_LINK0);\n}\n\nstatic struct intel_uncore_type spr_uncore_mdf = {\n\tSPR_UNCORE_COMMON_FORMAT(),\n\t.name\t\t\t= \"mdf\",\n};\n\n#define UNCORE_SPR_NUM_UNCORE_TYPES\t\t12\n#define UNCORE_SPR_CHA\t\t\t\t0\n#define UNCORE_SPR_IIO\t\t\t\t1\n#define UNCORE_SPR_IMC\t\t\t\t6\n#define UNCORE_SPR_UPI\t\t\t\t8\n#define UNCORE_SPR_M3UPI\t\t\t9\n\n \nstatic struct intel_uncore_type *spr_uncores[UNCORE_SPR_NUM_UNCORE_TYPES] = {\n\t&spr_uncore_chabox,\n\t&spr_uncore_iio,\n\t&spr_uncore_irp,\n\t&spr_uncore_m2pcie,\n\t&spr_uncore_pcu,\n\tNULL,\n\t&spr_uncore_imc,\n\t&spr_uncore_m2m,\n\tNULL,\n\tNULL,\n\tNULL,\n\t&spr_uncore_mdf,\n};\n\n \n#define SPR_UNCORE_UPI_NUM_BOXES\t4\n\nstatic unsigned int spr_upi_pci_offsets[SPR_UNCORE_UPI_NUM_BOXES] = {\n\t0, 0x8000, 0x10000, 0x18000\n};\n\nstatic struct intel_uncore_type spr_uncore_upi = {\n\t.event_mask\t\t= SNBEP_PMON_RAW_EVENT_MASK,\n\t.event_mask_ext\t\t= SPR_RAW_EVENT_MASK_EXT,\n\t.format_group\t\t= &spr_uncore_raw_format_group,\n\t.ops\t\t\t= &spr_uncore_pci_ops,\n\t.name\t\t\t= \"upi\",\n\t.attr_update\t\t= spr_upi_attr_update,\n\t.get_topology\t\t= spr_upi_get_topology,\n\t.set_mapping\t\t= spr_upi_set_mapping,\n\t.cleanup_mapping\t= spr_upi_cleanup_mapping,\n\t.type_id\t\t= UNCORE_SPR_UPI,\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= SPR_UNCORE_UPI_NUM_BOXES,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= ICX_UPI_PCI_PMON_CTR0,\n\t.event_ctl\t\t= ICX_UPI_PCI_PMON_CTL0,\n\t.box_ctl\t\t= ICX_UPI_PCI_PMON_BOX_CTL,\n\t.pci_offsets\t\t= spr_upi_pci_offsets,\n};\n\nstatic struct intel_uncore_type spr_uncore_m3upi = {\n\tSPR_UNCORE_PCI_COMMON_FORMAT(),\n\t.name\t\t\t= \"m3upi\",\n\t.type_id\t\t= UNCORE_SPR_M3UPI,\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= SPR_UNCORE_UPI_NUM_BOXES,\n\t.perf_ctr_bits\t\t= 48,\n\t.perf_ctr\t\t= ICX_M3UPI_PCI_PMON_CTR0,\n\t.event_ctl\t\t= ICX_M3UPI_PCI_PMON_CTL0,\n\t.box_ctl\t\t= ICX_M3UPI_PCI_PMON_BOX_CTL,\n\t.pci_offsets\t\t= spr_upi_pci_offsets,\n\t.constraints\t\t= icx_uncore_m3upi_constraints,\n};\n\nenum perf_uncore_spr_iio_freerunning_type_id {\n\tSPR_IIO_MSR_IOCLK,\n\tSPR_IIO_MSR_BW_IN,\n\tSPR_IIO_MSR_BW_OUT,\n\n\tSPR_IIO_FREERUNNING_TYPE_MAX,\n};\n\nstatic struct freerunning_counters spr_iio_freerunning[] = {\n\t[SPR_IIO_MSR_IOCLK]\t= { 0x340e, 0x1, 0x10, 1, 48 },\n\t[SPR_IIO_MSR_BW_IN]\t= { 0x3800, 0x1, 0x10, 8, 48 },\n\t[SPR_IIO_MSR_BW_OUT]\t= { 0x3808, 0x1, 0x10, 8, 48 },\n};\n\nstatic struct uncore_event_desc spr_uncore_iio_freerunning_events[] = {\n\t \n\tINTEL_UNCORE_EVENT_DESC(ioclk,\t\t\t\"event=0xff,umask=0x10\"),\n\t \n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0,\t\t\"event=0xff,umask=0x20\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port0.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1,\t\t\"event=0xff,umask=0x21\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port1.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2,\t\t\"event=0xff,umask=0x22\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port2.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3,\t\t\"event=0xff,umask=0x23\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port3.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port4,\t\t\"event=0xff,umask=0x24\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port4.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port4.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port5,\t\t\"event=0xff,umask=0x25\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port5.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port5.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port6,\t\t\"event=0xff,umask=0x26\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port6.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port6.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port7,\t\t\"event=0xff,umask=0x27\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port7.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_in_port7.unit,\t\"MiB\"),\n\t \n\tINTEL_UNCORE_EVENT_DESC(bw_out_port0,\t\t\"event=0xff,umask=0x30\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port0.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port0.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port1,\t\t\"event=0xff,umask=0x31\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port1.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port1.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port2,\t\t\"event=0xff,umask=0x32\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port2.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port2.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port3,\t\t\"event=0xff,umask=0x33\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port3.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port3.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port4,\t\t\"event=0xff,umask=0x34\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port4.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port4.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port5,\t\t\"event=0xff,umask=0x35\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port5.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port5.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port6,\t\t\"event=0xff,umask=0x36\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port6.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port6.unit,\t\"MiB\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port7,\t\t\"event=0xff,umask=0x37\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port7.scale,\t\"3.814697266e-6\"),\n\tINTEL_UNCORE_EVENT_DESC(bw_out_port7.unit,\t\"MiB\"),\n\t{   },\n};\n\nstatic struct intel_uncore_type spr_uncore_iio_free_running = {\n\t.name\t\t\t= \"iio_free_running\",\n\t.num_counters\t\t= 17,\n\t.num_freerunning_types\t= SPR_IIO_FREERUNNING_TYPE_MAX,\n\t.freerunning\t\t= spr_iio_freerunning,\n\t.ops\t\t\t= &skx_uncore_iio_freerunning_ops,\n\t.event_descs\t\t= spr_uncore_iio_freerunning_events,\n\t.format_group\t\t= &skx_uncore_iio_freerunning_format_group,\n};\n\nenum perf_uncore_spr_imc_freerunning_type_id {\n\tSPR_IMC_DCLK,\n\tSPR_IMC_PQ_CYCLES,\n\n\tSPR_IMC_FREERUNNING_TYPE_MAX,\n};\n\nstatic struct freerunning_counters spr_imc_freerunning[] = {\n\t[SPR_IMC_DCLK]\t\t= { 0x22b0, 0x0, 0, 1, 48 },\n\t[SPR_IMC_PQ_CYCLES]\t= { 0x2318, 0x8, 0, 2, 48 },\n};\n\nstatic struct uncore_event_desc spr_uncore_imc_freerunning_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(dclk,\t\t\t\"event=0xff,umask=0x10\"),\n\n\tINTEL_UNCORE_EVENT_DESC(rpq_cycles,\t\t\"event=0xff,umask=0x20\"),\n\tINTEL_UNCORE_EVENT_DESC(wpq_cycles,\t\t\"event=0xff,umask=0x21\"),\n\t{   },\n};\n\n#define SPR_MC_DEVICE_ID\t0x3251\n\nstatic void spr_uncore_imc_freerunning_init_box(struct intel_uncore_box *box)\n{\n\tint mem_offset = box->pmu->pmu_idx * ICX_IMC_MEM_STRIDE + SNR_IMC_MMIO_MEM0_OFFSET;\n\n\tsnr_uncore_mmio_map(box, uncore_mmio_box_ctl(box),\n\t\t\t    mem_offset, SPR_MC_DEVICE_ID);\n}\n\nstatic struct intel_uncore_ops spr_uncore_imc_freerunning_ops = {\n\t.init_box\t= spr_uncore_imc_freerunning_init_box,\n\t.exit_box\t= uncore_mmio_exit_box,\n\t.read_counter\t= uncore_mmio_read_counter,\n\t.hw_config\t= uncore_freerunning_hw_config,\n};\n\nstatic struct intel_uncore_type spr_uncore_imc_free_running = {\n\t.name\t\t\t= \"imc_free_running\",\n\t.num_counters\t\t= 3,\n\t.mmio_map_size\t\t= SNR_IMC_MMIO_SIZE,\n\t.num_freerunning_types\t= SPR_IMC_FREERUNNING_TYPE_MAX,\n\t.freerunning\t\t= spr_imc_freerunning,\n\t.ops\t\t\t= &spr_uncore_imc_freerunning_ops,\n\t.event_descs\t\t= spr_uncore_imc_freerunning_events,\n\t.format_group\t\t= &skx_uncore_iio_freerunning_format_group,\n};\n\n#define UNCORE_SPR_MSR_EXTRA_UNCORES\t\t1\n#define UNCORE_SPR_MMIO_EXTRA_UNCORES\t\t1\n#define UNCORE_SPR_PCI_EXTRA_UNCORES\t\t2\n\nstatic struct intel_uncore_type *spr_msr_uncores[UNCORE_SPR_MSR_EXTRA_UNCORES] = {\n\t&spr_uncore_iio_free_running,\n};\n\nstatic struct intel_uncore_type *spr_mmio_uncores[UNCORE_SPR_MMIO_EXTRA_UNCORES] = {\n\t&spr_uncore_imc_free_running,\n};\n\nstatic struct intel_uncore_type *spr_pci_uncores[UNCORE_SPR_PCI_EXTRA_UNCORES] = {\n\t&spr_uncore_upi,\n\t&spr_uncore_m3upi\n};\n\nint spr_uncore_units_ignore[] = {\n\tUNCORE_SPR_UPI,\n\tUNCORE_SPR_M3UPI,\n\tUNCORE_IGNORE_END\n};\n\nstatic void uncore_type_customized_copy(struct intel_uncore_type *to_type,\n\t\t\t\t\tstruct intel_uncore_type *from_type)\n{\n\tif (!to_type || !from_type)\n\t\treturn;\n\n\tif (from_type->name)\n\t\tto_type->name = from_type->name;\n\tif (from_type->fixed_ctr_bits)\n\t\tto_type->fixed_ctr_bits = from_type->fixed_ctr_bits;\n\tif (from_type->event_mask)\n\t\tto_type->event_mask = from_type->event_mask;\n\tif (from_type->event_mask_ext)\n\t\tto_type->event_mask_ext = from_type->event_mask_ext;\n\tif (from_type->fixed_ctr)\n\t\tto_type->fixed_ctr = from_type->fixed_ctr;\n\tif (from_type->fixed_ctl)\n\t\tto_type->fixed_ctl = from_type->fixed_ctl;\n\tif (from_type->fixed_ctr_bits)\n\t\tto_type->fixed_ctr_bits = from_type->fixed_ctr_bits;\n\tif (from_type->num_shared_regs)\n\t\tto_type->num_shared_regs = from_type->num_shared_regs;\n\tif (from_type->constraints)\n\t\tto_type->constraints = from_type->constraints;\n\tif (from_type->ops)\n\t\tto_type->ops = from_type->ops;\n\tif (from_type->event_descs)\n\t\tto_type->event_descs = from_type->event_descs;\n\tif (from_type->format_group)\n\t\tto_type->format_group = from_type->format_group;\n\tif (from_type->attr_update)\n\t\tto_type->attr_update = from_type->attr_update;\n\tif (from_type->set_mapping)\n\t\tto_type->set_mapping = from_type->set_mapping;\n\tif (from_type->get_topology)\n\t\tto_type->get_topology = from_type->get_topology;\n\tif (from_type->cleanup_mapping)\n\t\tto_type->cleanup_mapping = from_type->cleanup_mapping;\n}\n\nstatic struct intel_uncore_type **\nuncore_get_uncores(enum uncore_access_type type_id, int num_extra,\n\t\t    struct intel_uncore_type **extra)\n{\n\tstruct intel_uncore_type **types, **start_types;\n\tint i;\n\n\tstart_types = types = intel_uncore_generic_init_uncores(type_id, num_extra);\n\n\t \n\tfor (; *types; types++) {\n\t\tif ((*types)->type_id >= UNCORE_SPR_NUM_UNCORE_TYPES)\n\t\t\tcontinue;\n\t\tuncore_type_customized_copy(*types, spr_uncores[(*types)->type_id]);\n\t}\n\n\tfor (i = 0; i < num_extra; i++, types++)\n\t\t*types = extra[i];\n\n\treturn start_types;\n}\n\nstatic struct intel_uncore_type *\nuncore_find_type_by_id(struct intel_uncore_type **types, int type_id)\n{\n\tfor (; *types; types++) {\n\t\tif (type_id == (*types)->type_id)\n\t\t\treturn *types;\n\t}\n\n\treturn NULL;\n}\n\nstatic int uncore_type_max_boxes(struct intel_uncore_type **types,\n\t\t\t\t int type_id)\n{\n\tstruct intel_uncore_type *type;\n\tint i, max = 0;\n\n\ttype = uncore_find_type_by_id(types, type_id);\n\tif (!type)\n\t\treturn 0;\n\n\tfor (i = 0; i < type->num_boxes; i++) {\n\t\tif (type->box_ids[i] > max)\n\t\t\tmax = type->box_ids[i];\n\t}\n\n\treturn max + 1;\n}\n\n#define SPR_MSR_UNC_CBO_CONFIG\t\t0x2FFE\n\nvoid spr_uncore_cpu_init(void)\n{\n\tstruct intel_uncore_type *type;\n\tu64 num_cbo;\n\n\tuncore_msr_uncores = uncore_get_uncores(UNCORE_ACCESS_MSR,\n\t\t\t\t\t\tUNCORE_SPR_MSR_EXTRA_UNCORES,\n\t\t\t\t\t\tspr_msr_uncores);\n\n\ttype = uncore_find_type_by_id(uncore_msr_uncores, UNCORE_SPR_CHA);\n\tif (type) {\n\t\t \n\t\trdmsrl(SPR_MSR_UNC_CBO_CONFIG, num_cbo);\n\t\t \n\t\tif (num_cbo)\n\t\t\ttype->num_boxes = num_cbo;\n\t}\n\tspr_uncore_iio_free_running.num_boxes = uncore_type_max_boxes(uncore_msr_uncores, UNCORE_SPR_IIO);\n}\n\n#define SPR_UNCORE_UPI_PCIID\t\t0x3241\n#define SPR_UNCORE_UPI0_DEVFN\t\t0x9\n#define SPR_UNCORE_M3UPI_PCIID\t\t0x3246\n#define SPR_UNCORE_M3UPI0_DEVFN\t\t0x29\n\nstatic void spr_update_device_location(int type_id)\n{\n\tstruct intel_uncore_type *type;\n\tstruct pci_dev *dev = NULL;\n\tu32 device, devfn;\n\tu64 *ctls;\n\tint die;\n\n\tif (type_id == UNCORE_SPR_UPI) {\n\t\ttype = &spr_uncore_upi;\n\t\tdevice = SPR_UNCORE_UPI_PCIID;\n\t\tdevfn = SPR_UNCORE_UPI0_DEVFN;\n\t} else if (type_id == UNCORE_SPR_M3UPI) {\n\t\ttype = &spr_uncore_m3upi;\n\t\tdevice = SPR_UNCORE_M3UPI_PCIID;\n\t\tdevfn = SPR_UNCORE_M3UPI0_DEVFN;\n\t} else\n\t\treturn;\n\n\tctls = kcalloc(__uncore_max_dies, sizeof(u64), GFP_KERNEL);\n\tif (!ctls) {\n\t\ttype->num_boxes = 0;\n\t\treturn;\n\t}\n\n\twhile ((dev = pci_get_device(PCI_VENDOR_ID_INTEL, device, dev)) != NULL) {\n\t\tif (devfn != dev->devfn)\n\t\t\tcontinue;\n\n\t\tdie = uncore_device_to_die(dev);\n\t\tif (die < 0)\n\t\t\tcontinue;\n\n\t\tctls[die] = pci_domain_nr(dev->bus) << UNCORE_DISCOVERY_PCI_DOMAIN_OFFSET |\n\t\t\t    dev->bus->number << UNCORE_DISCOVERY_PCI_BUS_OFFSET |\n\t\t\t    devfn << UNCORE_DISCOVERY_PCI_DEVFN_OFFSET |\n\t\t\t    type->box_ctl;\n\t}\n\n\ttype->box_ctls = ctls;\n}\n\nint spr_uncore_pci_init(void)\n{\n\t \n\tspr_update_device_location(UNCORE_SPR_UPI);\n\tspr_update_device_location(UNCORE_SPR_M3UPI);\n\tuncore_pci_uncores = uncore_get_uncores(UNCORE_ACCESS_PCI,\n\t\t\t\t\t\tUNCORE_SPR_PCI_EXTRA_UNCORES,\n\t\t\t\t\t\tspr_pci_uncores);\n\treturn 0;\n}\n\nvoid spr_uncore_mmio_init(void)\n{\n\tint ret = snbep_pci2phy_map_init(0x3250, SKX_CPUNODEID, SKX_GIDNIDMAP, true);\n\n\tif (ret)\n\t\tuncore_mmio_uncores = uncore_get_uncores(UNCORE_ACCESS_MMIO, 0, NULL);\n\telse {\n\t\tuncore_mmio_uncores = uncore_get_uncores(UNCORE_ACCESS_MMIO,\n\t\t\t\t\t\t\t UNCORE_SPR_MMIO_EXTRA_UNCORES,\n\t\t\t\t\t\t\t spr_mmio_uncores);\n\n\t\tspr_uncore_imc_free_running.num_boxes = uncore_type_max_boxes(uncore_mmio_uncores, UNCORE_SPR_IMC) / 2;\n\t}\n}\n\n \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}