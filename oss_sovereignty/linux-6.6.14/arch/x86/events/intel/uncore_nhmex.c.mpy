{
  "module_name": "uncore_nhmex.c",
  "hash_id": "695c6bfe10b62ccb5bd7f8f8843d85a3324e7df449b54a74934e00794a99efac",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/events/intel/uncore_nhmex.c",
  "human_readable_source": "\n \n#include \"uncore.h\"\n\n \n#define NHMEX_PMON_CTL_EV_SEL_MASK\t0x000000ff\n#define NHMEX_PMON_CTL_UMASK_MASK\t0x0000ff00\n#define NHMEX_PMON_CTL_EN_BIT0\t\t(1 << 0)\n#define NHMEX_PMON_CTL_EDGE_DET\t\t(1 << 18)\n#define NHMEX_PMON_CTL_PMI_EN\t\t(1 << 20)\n#define NHMEX_PMON_CTL_EN_BIT22\t\t(1 << 22)\n#define NHMEX_PMON_CTL_INVERT\t\t(1 << 23)\n#define NHMEX_PMON_CTL_TRESH_MASK\t0xff000000\n#define NHMEX_PMON_RAW_EVENT_MASK\t(NHMEX_PMON_CTL_EV_SEL_MASK | \\\n\t\t\t\t\t NHMEX_PMON_CTL_UMASK_MASK | \\\n\t\t\t\t\t NHMEX_PMON_CTL_EDGE_DET | \\\n\t\t\t\t\t NHMEX_PMON_CTL_INVERT | \\\n\t\t\t\t\t NHMEX_PMON_CTL_TRESH_MASK)\n\n \n#define NHMEX_U_MSR_PMON_GLOBAL_CTL\t\t0xc00\n#define NHMEX_U_MSR_PMON_CTR\t\t\t0xc11\n#define NHMEX_U_MSR_PMON_EV_SEL\t\t\t0xc10\n\n#define NHMEX_U_PMON_GLOBAL_EN\t\t\t(1 << 0)\n#define NHMEX_U_PMON_GLOBAL_PMI_CORE_SEL\t0x0000001e\n#define NHMEX_U_PMON_GLOBAL_EN_ALL\t\t(1 << 28)\n#define NHMEX_U_PMON_GLOBAL_RST_ALL\t\t(1 << 29)\n#define NHMEX_U_PMON_GLOBAL_FRZ_ALL\t\t(1 << 31)\n\n#define NHMEX_U_PMON_RAW_EVENT_MASK\t\t\\\n\t\t(NHMEX_PMON_CTL_EV_SEL_MASK |\t\\\n\t\t NHMEX_PMON_CTL_EDGE_DET)\n\n \n#define NHMEX_C0_MSR_PMON_GLOBAL_CTL\t\t0xd00\n#define NHMEX_C0_MSR_PMON_CTR0\t\t\t0xd11\n#define NHMEX_C0_MSR_PMON_EV_SEL0\t\t0xd10\n#define NHMEX_C_MSR_OFFSET\t\t\t0x20\n\n \n#define NHMEX_B0_MSR_PMON_GLOBAL_CTL\t\t0xc20\n#define NHMEX_B0_MSR_PMON_CTR0\t\t\t0xc31\n#define NHMEX_B0_MSR_PMON_CTL0\t\t\t0xc30\n#define NHMEX_B_MSR_OFFSET\t\t\t0x40\n#define NHMEX_B0_MSR_MATCH\t\t\t0xe45\n#define NHMEX_B0_MSR_MASK\t\t\t0xe46\n#define NHMEX_B1_MSR_MATCH\t\t\t0xe4d\n#define NHMEX_B1_MSR_MASK\t\t\t0xe4e\n\n#define NHMEX_B_PMON_CTL_EN\t\t\t(1 << 0)\n#define NHMEX_B_PMON_CTL_EV_SEL_SHIFT\t\t1\n#define NHMEX_B_PMON_CTL_EV_SEL_MASK\t\t\\\n\t\t(0x1f << NHMEX_B_PMON_CTL_EV_SEL_SHIFT)\n#define NHMEX_B_PMON_CTR_SHIFT\t\t6\n#define NHMEX_B_PMON_CTR_MASK\t\t\\\n\t\t(0x3 << NHMEX_B_PMON_CTR_SHIFT)\n#define NHMEX_B_PMON_RAW_EVENT_MASK\t\t\\\n\t\t(NHMEX_B_PMON_CTL_EV_SEL_MASK | \\\n\t\t NHMEX_B_PMON_CTR_MASK)\n\n \n#define NHMEX_S0_MSR_PMON_GLOBAL_CTL\t\t0xc40\n#define NHMEX_S0_MSR_PMON_CTR0\t\t\t0xc51\n#define NHMEX_S0_MSR_PMON_CTL0\t\t\t0xc50\n#define NHMEX_S_MSR_OFFSET\t\t\t0x80\n#define NHMEX_S0_MSR_MM_CFG\t\t\t0xe48\n#define NHMEX_S0_MSR_MATCH\t\t\t0xe49\n#define NHMEX_S0_MSR_MASK\t\t\t0xe4a\n#define NHMEX_S1_MSR_MM_CFG\t\t\t0xe58\n#define NHMEX_S1_MSR_MATCH\t\t\t0xe59\n#define NHMEX_S1_MSR_MASK\t\t\t0xe5a\n\n#define NHMEX_S_PMON_MM_CFG_EN\t\t\t(0x1ULL << 63)\n#define NHMEX_S_EVENT_TO_R_PROG_EV\t\t0\n\n \n#define NHMEX_M0_MSR_GLOBAL_CTL\t\t\t0xca0\n#define NHMEX_M0_MSR_PMU_DSP\t\t\t0xca5\n#define NHMEX_M0_MSR_PMU_ISS\t\t\t0xca6\n#define NHMEX_M0_MSR_PMU_MAP\t\t\t0xca7\n#define NHMEX_M0_MSR_PMU_MSC_THR\t\t0xca8\n#define NHMEX_M0_MSR_PMU_PGT\t\t\t0xca9\n#define NHMEX_M0_MSR_PMU_PLD\t\t\t0xcaa\n#define NHMEX_M0_MSR_PMU_ZDP_CTL_FVC\t\t0xcab\n#define NHMEX_M0_MSR_PMU_CTL0\t\t\t0xcb0\n#define NHMEX_M0_MSR_PMU_CNT0\t\t\t0xcb1\n#define NHMEX_M_MSR_OFFSET\t\t\t0x40\n#define NHMEX_M0_MSR_PMU_MM_CFG\t\t\t0xe54\n#define NHMEX_M1_MSR_PMU_MM_CFG\t\t\t0xe5c\n\n#define NHMEX_M_PMON_MM_CFG_EN\t\t\t(1ULL << 63)\n#define NHMEX_M_PMON_ADDR_MATCH_MASK\t\t0x3ffffffffULL\n#define NHMEX_M_PMON_ADDR_MASK_MASK\t\t0x7ffffffULL\n#define NHMEX_M_PMON_ADDR_MASK_SHIFT\t\t34\n\n#define NHMEX_M_PMON_CTL_EN\t\t\t(1 << 0)\n#define NHMEX_M_PMON_CTL_PMI_EN\t\t\t(1 << 1)\n#define NHMEX_M_PMON_CTL_COUNT_MODE_SHIFT\t2\n#define NHMEX_M_PMON_CTL_COUNT_MODE_MASK\t\\\n\t(0x3 << NHMEX_M_PMON_CTL_COUNT_MODE_SHIFT)\n#define NHMEX_M_PMON_CTL_STORAGE_MODE_SHIFT\t4\n#define NHMEX_M_PMON_CTL_STORAGE_MODE_MASK\t\\\n\t(0x3 << NHMEX_M_PMON_CTL_STORAGE_MODE_SHIFT)\n#define NHMEX_M_PMON_CTL_WRAP_MODE\t\t(1 << 6)\n#define NHMEX_M_PMON_CTL_FLAG_MODE\t\t(1 << 7)\n#define NHMEX_M_PMON_CTL_INC_SEL_SHIFT\t\t9\n#define NHMEX_M_PMON_CTL_INC_SEL_MASK\t\t\\\n\t(0x1f << NHMEX_M_PMON_CTL_INC_SEL_SHIFT)\n#define NHMEX_M_PMON_CTL_SET_FLAG_SEL_SHIFT\t19\n#define NHMEX_M_PMON_CTL_SET_FLAG_SEL_MASK\t\\\n\t(0x7 << NHMEX_M_PMON_CTL_SET_FLAG_SEL_SHIFT)\n#define NHMEX_M_PMON_RAW_EVENT_MASK\t\t\t\\\n\t\t(NHMEX_M_PMON_CTL_COUNT_MODE_MASK |\t\\\n\t\t NHMEX_M_PMON_CTL_STORAGE_MODE_MASK |\t\\\n\t\t NHMEX_M_PMON_CTL_WRAP_MODE |\t\t\\\n\t\t NHMEX_M_PMON_CTL_FLAG_MODE |\t\t\\\n\t\t NHMEX_M_PMON_CTL_INC_SEL_MASK |\t\\\n\t\t NHMEX_M_PMON_CTL_SET_FLAG_SEL_MASK)\n\n#define NHMEX_M_PMON_ZDP_CTL_FVC_MASK\t\t(((1 << 11) - 1) | (1 << 23))\n#define NHMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(n)\t(0x7ULL << (11 + 3 * (n)))\n\n#define WSMEX_M_PMON_ZDP_CTL_FVC_MASK\t\t(((1 << 12) - 1) | (1 << 24))\n#define WSMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(n)\t(0x7ULL << (12 + 3 * (n)))\n\n \n#define MBOX_INC_SEL(x) ((x) << NHMEX_M_PMON_CTL_INC_SEL_SHIFT)\n#define MBOX_SET_FLAG_SEL(x) (((x) << NHMEX_M_PMON_CTL_SET_FLAG_SEL_SHIFT) | \\\n\t\t\t\tNHMEX_M_PMON_CTL_FLAG_MODE)\n#define MBOX_INC_SEL_MASK (NHMEX_M_PMON_CTL_INC_SEL_MASK | \\\n\t\t\t   NHMEX_M_PMON_CTL_FLAG_MODE)\n#define MBOX_SET_FLAG_SEL_MASK (NHMEX_M_PMON_CTL_SET_FLAG_SEL_MASK | \\\n\t\t\t\tNHMEX_M_PMON_CTL_FLAG_MODE)\n#define MBOX_INC_SEL_EXTAR_REG(c, r) \\\n\t\tEVENT_EXTRA_REG(MBOX_INC_SEL(c), NHMEX_M0_MSR_PMU_##r, \\\n\t\t\t\tMBOX_INC_SEL_MASK, (u64)-1, NHMEX_M_##r)\n#define MBOX_SET_FLAG_SEL_EXTRA_REG(c, r) \\\n\t\tEVENT_EXTRA_REG(MBOX_SET_FLAG_SEL(c), NHMEX_M0_MSR_PMU_##r, \\\n\t\t\t\tMBOX_SET_FLAG_SEL_MASK, \\\n\t\t\t\t(u64)-1, NHMEX_M_##r)\n\n \n#define NHMEX_R_MSR_GLOBAL_CTL\t\t\t0xe00\n#define NHMEX_R_MSR_PMON_CTL0\t\t\t0xe10\n#define NHMEX_R_MSR_PMON_CNT0\t\t\t0xe11\n#define NHMEX_R_MSR_OFFSET\t\t\t0x20\n\n#define NHMEX_R_MSR_PORTN_QLX_CFG(n)\t\t\\\n\t\t((n) < 4 ? (0xe0c + (n)) : (0xe2c + (n) - 4))\n#define NHMEX_R_MSR_PORTN_IPERF_CFG0(n)\t\t(0xe04 + (n))\n#define NHMEX_R_MSR_PORTN_IPERF_CFG1(n)\t\t(0xe24 + (n))\n#define NHMEX_R_MSR_PORTN_XBR_OFFSET(n)\t\t\\\n\t\t(((n) < 4 ? 0 : 0x10) + (n) * 4)\n#define NHMEX_R_MSR_PORTN_XBR_SET1_MM_CFG(n)\t\\\n\t\t(0xe60 + NHMEX_R_MSR_PORTN_XBR_OFFSET(n))\n#define NHMEX_R_MSR_PORTN_XBR_SET1_MATCH(n)\t\\\n\t\t(NHMEX_R_MSR_PORTN_XBR_SET1_MM_CFG(n) + 1)\n#define NHMEX_R_MSR_PORTN_XBR_SET1_MASK(n)\t\\\n\t\t(NHMEX_R_MSR_PORTN_XBR_SET1_MM_CFG(n) + 2)\n#define NHMEX_R_MSR_PORTN_XBR_SET2_MM_CFG(n)\t\\\n\t\t(0xe70 + NHMEX_R_MSR_PORTN_XBR_OFFSET(n))\n#define NHMEX_R_MSR_PORTN_XBR_SET2_MATCH(n)\t\\\n\t\t(NHMEX_R_MSR_PORTN_XBR_SET2_MM_CFG(n) + 1)\n#define NHMEX_R_MSR_PORTN_XBR_SET2_MASK(n)\t\\\n\t\t(NHMEX_R_MSR_PORTN_XBR_SET2_MM_CFG(n) + 2)\n\n#define NHMEX_R_PMON_CTL_EN\t\t\t(1 << 0)\n#define NHMEX_R_PMON_CTL_EV_SEL_SHIFT\t\t1\n#define NHMEX_R_PMON_CTL_EV_SEL_MASK\t\t\\\n\t\t(0x1f << NHMEX_R_PMON_CTL_EV_SEL_SHIFT)\n#define NHMEX_R_PMON_CTL_PMI_EN\t\t\t(1 << 6)\n#define NHMEX_R_PMON_RAW_EVENT_MASK\t\tNHMEX_R_PMON_CTL_EV_SEL_MASK\n\n \n#define NHMEX_W_MSR_GLOBAL_CTL\t\t\t0xc80\n#define NHMEX_W_MSR_PMON_CNT0\t\t\t0xc90\n#define NHMEX_W_MSR_PMON_EVT_SEL0\t\t0xc91\n#define NHMEX_W_MSR_PMON_FIXED_CTR\t\t0x394\n#define NHMEX_W_MSR_PMON_FIXED_CTL\t\t0x395\n\n#define NHMEX_W_PMON_GLOBAL_FIXED_EN\t\t(1ULL << 31)\n\n#define __BITS_VALUE(x, i, n)  ((typeof(x))(((x) >> ((i) * (n))) & \\\n\t\t\t\t((1ULL << (n)) - 1)))\n\nDEFINE_UNCORE_FORMAT_ATTR(event, event, \"config:0-7\");\nDEFINE_UNCORE_FORMAT_ATTR(event5, event, \"config:1-5\");\nDEFINE_UNCORE_FORMAT_ATTR(umask, umask, \"config:8-15\");\nDEFINE_UNCORE_FORMAT_ATTR(edge, edge, \"config:18\");\nDEFINE_UNCORE_FORMAT_ATTR(inv, inv, \"config:23\");\nDEFINE_UNCORE_FORMAT_ATTR(thresh8, thresh, \"config:24-31\");\nDEFINE_UNCORE_FORMAT_ATTR(counter, counter, \"config:6-7\");\nDEFINE_UNCORE_FORMAT_ATTR(match, match, \"config1:0-63\");\nDEFINE_UNCORE_FORMAT_ATTR(mask, mask, \"config2:0-63\");\n\nstatic void nhmex_uncore_msr_init_box(struct intel_uncore_box *box)\n{\n\twrmsrl(NHMEX_U_MSR_PMON_GLOBAL_CTL, NHMEX_U_PMON_GLOBAL_EN_ALL);\n}\n\nstatic void nhmex_uncore_msr_exit_box(struct intel_uncore_box *box)\n{\n\twrmsrl(NHMEX_U_MSR_PMON_GLOBAL_CTL, 0);\n}\n\nstatic void nhmex_uncore_msr_disable_box(struct intel_uncore_box *box)\n{\n\tunsigned msr = uncore_msr_box_ctl(box);\n\tu64 config;\n\n\tif (msr) {\n\t\trdmsrl(msr, config);\n\t\tconfig &= ~((1ULL << uncore_num_counters(box)) - 1);\n\t\t \n\t\tif (uncore_msr_fixed_ctl(box))\n\t\t\tconfig &= ~NHMEX_W_PMON_GLOBAL_FIXED_EN;\n\t\twrmsrl(msr, config);\n\t}\n}\n\nstatic void nhmex_uncore_msr_enable_box(struct intel_uncore_box *box)\n{\n\tunsigned msr = uncore_msr_box_ctl(box);\n\tu64 config;\n\n\tif (msr) {\n\t\trdmsrl(msr, config);\n\t\tconfig |= (1ULL << uncore_num_counters(box)) - 1;\n\t\t \n\t\tif (uncore_msr_fixed_ctl(box))\n\t\t\tconfig |= NHMEX_W_PMON_GLOBAL_FIXED_EN;\n\t\twrmsrl(msr, config);\n\t}\n}\n\nstatic void nhmex_uncore_msr_disable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\twrmsrl(event->hw.config_base, 0);\n}\n\nstatic void nhmex_uncore_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (hwc->idx == UNCORE_PMC_IDX_FIXED)\n\t\twrmsrl(hwc->config_base, NHMEX_PMON_CTL_EN_BIT0);\n\telse if (box->pmu->type->event_mask & NHMEX_PMON_CTL_EN_BIT0)\n\t\twrmsrl(hwc->config_base, hwc->config | NHMEX_PMON_CTL_EN_BIT22);\n\telse\n\t\twrmsrl(hwc->config_base, hwc->config | NHMEX_PMON_CTL_EN_BIT0);\n}\n\n#define NHMEX_UNCORE_OPS_COMMON_INIT()\t\t\t\t\\\n\t.init_box\t= nhmex_uncore_msr_init_box,\t\t\\\n\t.exit_box\t= nhmex_uncore_msr_exit_box,\t\t\\\n\t.disable_box\t= nhmex_uncore_msr_disable_box,\t\t\\\n\t.enable_box\t= nhmex_uncore_msr_enable_box,\t\t\\\n\t.disable_event\t= nhmex_uncore_msr_disable_event,\t\\\n\t.read_counter\t= uncore_msr_read_counter\n\nstatic struct intel_uncore_ops nhmex_uncore_ops = {\n\tNHMEX_UNCORE_OPS_COMMON_INIT(),\n\t.enable_event\t= nhmex_uncore_msr_enable_event,\n};\n\nstatic struct attribute *nhmex_uncore_ubox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_edge.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group nhmex_uncore_ubox_format_group = {\n\t.name\t\t= \"format\",\n\t.attrs\t\t= nhmex_uncore_ubox_formats_attr,\n};\n\nstatic struct intel_uncore_type nhmex_uncore_ubox = {\n\t.name\t\t= \"ubox\",\n\t.num_counters\t= 1,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 48,\n\t.event_ctl\t= NHMEX_U_MSR_PMON_EV_SEL,\n\t.perf_ctr\t= NHMEX_U_MSR_PMON_CTR,\n\t.event_mask\t= NHMEX_U_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t= NHMEX_U_MSR_PMON_GLOBAL_CTL,\n\t.ops\t\t= &nhmex_uncore_ops,\n\t.format_group\t= &nhmex_uncore_ubox_format_group\n};\n\nstatic struct attribute *nhmex_uncore_cbox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group nhmex_uncore_cbox_format_group = {\n\t.name = \"format\",\n\t.attrs = nhmex_uncore_cbox_formats_attr,\n};\n\n \nstatic unsigned nhmex_cbox_msr_offsets[] = {\n\t0x0, 0x80, 0x40, 0xc0, 0x20, 0xa0, 0x60, 0xe0, 0x240, 0x2c0,\n};\n\nstatic struct intel_uncore_type nhmex_uncore_cbox = {\n\t.name\t\t\t= \"cbox\",\n\t.num_counters\t\t= 6,\n\t.num_boxes\t\t= 10,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= NHMEX_C0_MSR_PMON_EV_SEL0,\n\t.perf_ctr\t\t= NHMEX_C0_MSR_PMON_CTR0,\n\t.event_mask\t\t= NHMEX_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= NHMEX_C0_MSR_PMON_GLOBAL_CTL,\n\t.msr_offsets\t\t= nhmex_cbox_msr_offsets,\n\t.pair_ctr_ctl\t\t= 1,\n\t.ops\t\t\t= &nhmex_uncore_ops,\n\t.format_group\t\t= &nhmex_uncore_cbox_format_group\n};\n\nstatic struct uncore_event_desc nhmex_uncore_wbox_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(clockticks, \"event=0xff,umask=0\"),\n\t{   },\n};\n\nstatic struct intel_uncore_type nhmex_uncore_wbox = {\n\t.name\t\t\t= \"wbox\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 1,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= NHMEX_W_MSR_PMON_CNT0,\n\t.perf_ctr\t\t= NHMEX_W_MSR_PMON_EVT_SEL0,\n\t.fixed_ctr\t\t= NHMEX_W_MSR_PMON_FIXED_CTR,\n\t.fixed_ctl\t\t= NHMEX_W_MSR_PMON_FIXED_CTL,\n\t.event_mask\t\t= NHMEX_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= NHMEX_W_MSR_GLOBAL_CTL,\n\t.pair_ctr_ctl\t\t= 1,\n\t.event_descs\t\t= nhmex_uncore_wbox_events,\n\t.ops\t\t\t= &nhmex_uncore_ops,\n\t.format_group\t\t= &nhmex_uncore_cbox_format_group\n};\n\nstatic int nhmex_bbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\n\tint ctr, ev_sel;\n\n\tctr = (hwc->config & NHMEX_B_PMON_CTR_MASK) >>\n\t\tNHMEX_B_PMON_CTR_SHIFT;\n\tev_sel = (hwc->config & NHMEX_B_PMON_CTL_EV_SEL_MASK) >>\n\t\t  NHMEX_B_PMON_CTL_EV_SEL_SHIFT;\n\n\t \n\tif ((ctr == 0 && ev_sel > 0x3) || (ctr == 1 && ev_sel > 0x6) ||\n\t    (ctr == 2 && ev_sel != 0x4) || ctr == 3)\n\t\treturn 0;\n\n\tif (box->pmu->pmu_idx == 0)\n\t\treg1->reg = NHMEX_B0_MSR_MATCH;\n\telse\n\t\treg1->reg = NHMEX_B1_MSR_MATCH;\n\treg1->idx = 0;\n\treg1->config = event->attr.config1;\n\treg2->config = event->attr.config2;\n\treturn 0;\n}\n\nstatic void nhmex_bbox_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\n\n\tif (reg1->idx != EXTRA_REG_NONE) {\n\t\twrmsrl(reg1->reg, reg1->config);\n\t\twrmsrl(reg1->reg + 1, reg2->config);\n\t}\n\twrmsrl(hwc->config_base, NHMEX_PMON_CTL_EN_BIT0 |\n\t\t(hwc->config & NHMEX_B_PMON_CTL_EV_SEL_MASK));\n}\n\n \nstatic struct event_constraint nhmex_uncore_bbox_constraints[] = {\n\tEVENT_CONSTRAINT(0 , 1, 0xc0),\n\tEVENT_CONSTRAINT(0x40, 2, 0xc0),\n\tEVENT_CONSTRAINT(0x80, 4, 0xc0),\n\tEVENT_CONSTRAINT(0xc0, 8, 0xc0),\n\tEVENT_CONSTRAINT_END,\n};\n\nstatic struct attribute *nhmex_uncore_bbox_formats_attr[] = {\n\t&format_attr_event5.attr,\n\t&format_attr_counter.attr,\n\t&format_attr_match.attr,\n\t&format_attr_mask.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group nhmex_uncore_bbox_format_group = {\n\t.name = \"format\",\n\t.attrs = nhmex_uncore_bbox_formats_attr,\n};\n\nstatic struct intel_uncore_ops nhmex_uncore_bbox_ops = {\n\tNHMEX_UNCORE_OPS_COMMON_INIT(),\n\t.enable_event\t\t= nhmex_bbox_msr_enable_event,\n\t.hw_config\t\t= nhmex_bbox_hw_config,\n\t.get_constraint\t\t= uncore_get_constraint,\n\t.put_constraint\t\t= uncore_put_constraint,\n};\n\nstatic struct intel_uncore_type nhmex_uncore_bbox = {\n\t.name\t\t\t= \"bbox\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 2,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= NHMEX_B0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= NHMEX_B0_MSR_PMON_CTR0,\n\t.event_mask\t\t= NHMEX_B_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= NHMEX_B0_MSR_PMON_GLOBAL_CTL,\n\t.msr_offset\t\t= NHMEX_B_MSR_OFFSET,\n\t.pair_ctr_ctl\t\t= 1,\n\t.num_shared_regs\t= 1,\n\t.constraints\t\t= nhmex_uncore_bbox_constraints,\n\t.ops\t\t\t= &nhmex_uncore_bbox_ops,\n\t.format_group\t\t= &nhmex_uncore_bbox_format_group\n};\n\nstatic int nhmex_sbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\n\n\t \n\tif ((hwc->config & NHMEX_PMON_CTL_EV_SEL_MASK) !=\n\t    NHMEX_S_EVENT_TO_R_PROG_EV)\n\t\treturn 0;\n\n\tif (box->pmu->pmu_idx == 0)\n\t\treg1->reg = NHMEX_S0_MSR_MM_CFG;\n\telse\n\t\treg1->reg = NHMEX_S1_MSR_MM_CFG;\n\treg1->idx = 0;\n\treg1->config = event->attr.config1;\n\treg2->config = event->attr.config2;\n\treturn 0;\n}\n\nstatic void nhmex_sbox_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\n\n\tif (reg1->idx != EXTRA_REG_NONE) {\n\t\twrmsrl(reg1->reg, 0);\n\t\twrmsrl(reg1->reg + 1, reg1->config);\n\t\twrmsrl(reg1->reg + 2, reg2->config);\n\t\twrmsrl(reg1->reg, NHMEX_S_PMON_MM_CFG_EN);\n\t}\n\twrmsrl(hwc->config_base, hwc->config | NHMEX_PMON_CTL_EN_BIT22);\n}\n\nstatic struct attribute *nhmex_uncore_sbox_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_thresh8.attr,\n\t&format_attr_match.attr,\n\t&format_attr_mask.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group nhmex_uncore_sbox_format_group = {\n\t.name\t\t\t= \"format\",\n\t.attrs\t\t\t= nhmex_uncore_sbox_formats_attr,\n};\n\nstatic struct intel_uncore_ops nhmex_uncore_sbox_ops = {\n\tNHMEX_UNCORE_OPS_COMMON_INIT(),\n\t.enable_event\t\t= nhmex_sbox_msr_enable_event,\n\t.hw_config\t\t= nhmex_sbox_hw_config,\n\t.get_constraint\t\t= uncore_get_constraint,\n\t.put_constraint\t\t= uncore_put_constraint,\n};\n\nstatic struct intel_uncore_type nhmex_uncore_sbox = {\n\t.name\t\t\t= \"sbox\",\n\t.num_counters\t\t= 4,\n\t.num_boxes\t\t= 2,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= NHMEX_S0_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= NHMEX_S0_MSR_PMON_CTR0,\n\t.event_mask\t\t= NHMEX_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= NHMEX_S0_MSR_PMON_GLOBAL_CTL,\n\t.msr_offset\t\t= NHMEX_S_MSR_OFFSET,\n\t.pair_ctr_ctl\t\t= 1,\n\t.num_shared_regs\t= 1,\n\t.ops\t\t\t= &nhmex_uncore_sbox_ops,\n\t.format_group\t\t= &nhmex_uncore_sbox_format_group\n};\n\nenum {\n\tEXTRA_REG_NHMEX_M_FILTER,\n\tEXTRA_REG_NHMEX_M_DSP,\n\tEXTRA_REG_NHMEX_M_ISS,\n\tEXTRA_REG_NHMEX_M_MAP,\n\tEXTRA_REG_NHMEX_M_MSC_THR,\n\tEXTRA_REG_NHMEX_M_PGT,\n\tEXTRA_REG_NHMEX_M_PLD,\n\tEXTRA_REG_NHMEX_M_ZDP_CTL_FVC,\n};\n\nstatic struct extra_reg nhmex_uncore_mbox_extra_regs[] = {\n\tMBOX_INC_SEL_EXTAR_REG(0x0, DSP),\n\tMBOX_INC_SEL_EXTAR_REG(0x4, MSC_THR),\n\tMBOX_INC_SEL_EXTAR_REG(0x5, MSC_THR),\n\tMBOX_INC_SEL_EXTAR_REG(0x9, ISS),\n\t \n\tMBOX_INC_SEL_EXTAR_REG(0xa, ISS),\n\tMBOX_INC_SEL_EXTAR_REG(0xa, PLD),\n\tMBOX_INC_SEL_EXTAR_REG(0xb, PLD),\n\t \n\tMBOX_INC_SEL_EXTAR_REG(0xd, ZDP_CTL_FVC),\n\tMBOX_INC_SEL_EXTAR_REG(0xe, ZDP_CTL_FVC),\n\tMBOX_INC_SEL_EXTAR_REG(0xf, ZDP_CTL_FVC),\n\tMBOX_INC_SEL_EXTAR_REG(0x10, ZDP_CTL_FVC),\n\tMBOX_INC_SEL_EXTAR_REG(0x16, PGT),\n\tMBOX_SET_FLAG_SEL_EXTRA_REG(0x0, DSP),\n\tMBOX_SET_FLAG_SEL_EXTRA_REG(0x1, ISS),\n\tMBOX_SET_FLAG_SEL_EXTRA_REG(0x5, PGT),\n\tMBOX_SET_FLAG_SEL_EXTRA_REG(0x6, MAP),\n\tEVENT_EXTRA_END\n};\n\n \nstatic bool uncore_nhmex;\n\nstatic bool nhmex_mbox_get_shared_reg(struct intel_uncore_box *box, int idx, u64 config)\n{\n\tstruct intel_uncore_extra_reg *er;\n\tunsigned long flags;\n\tbool ret = false;\n\tu64 mask;\n\n\tif (idx < EXTRA_REG_NHMEX_M_ZDP_CTL_FVC) {\n\t\ter = &box->shared_regs[idx];\n\t\traw_spin_lock_irqsave(&er->lock, flags);\n\t\tif (!atomic_read(&er->ref) || er->config == config) {\n\t\t\tatomic_inc(&er->ref);\n\t\t\ter->config = config;\n\t\t\tret = true;\n\t\t}\n\t\traw_spin_unlock_irqrestore(&er->lock, flags);\n\n\t\treturn ret;\n\t}\n\t \n\tidx -= EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\n\tif (WARN_ON_ONCE(idx >= 4))\n\t\treturn false;\n\n\t \n\tif (uncore_nhmex)\n\t\tmask = NHMEX_M_PMON_ZDP_CTL_FVC_MASK;\n\telse\n\t\tmask = WSMEX_M_PMON_ZDP_CTL_FVC_MASK;\n\ter = &box->shared_regs[EXTRA_REG_NHMEX_M_ZDP_CTL_FVC];\n\n\traw_spin_lock_irqsave(&er->lock, flags);\n\t \n\tif (__BITS_VALUE(atomic_read(&er->ref), idx, 8)) {\n\t\tif (uncore_nhmex)\n\t\t\tmask |= NHMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\n\t\telse\n\t\t\tmask |= WSMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\n\t}\n\n\tif (!atomic_read(&er->ref) || !((er->config ^ config) & mask)) {\n\t\tatomic_add(1 << (idx * 8), &er->ref);\n\t\tif (uncore_nhmex)\n\t\t\tmask = NHMEX_M_PMON_ZDP_CTL_FVC_MASK |\n\t\t\t\tNHMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\n\t\telse\n\t\t\tmask = WSMEX_M_PMON_ZDP_CTL_FVC_MASK |\n\t\t\t\tWSMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\n\t\ter->config &= ~mask;\n\t\ter->config |= (config & mask);\n\t\tret = true;\n\t}\n\traw_spin_unlock_irqrestore(&er->lock, flags);\n\n\treturn ret;\n}\n\nstatic void nhmex_mbox_put_shared_reg(struct intel_uncore_box *box, int idx)\n{\n\tstruct intel_uncore_extra_reg *er;\n\n\tif (idx < EXTRA_REG_NHMEX_M_ZDP_CTL_FVC) {\n\t\ter = &box->shared_regs[idx];\n\t\tatomic_dec(&er->ref);\n\t\treturn;\n\t}\n\n\tidx -= EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\n\ter = &box->shared_regs[EXTRA_REG_NHMEX_M_ZDP_CTL_FVC];\n\tatomic_sub(1 << (idx * 8), &er->ref);\n}\n\nstatic u64 nhmex_mbox_alter_er(struct perf_event *event, int new_idx, bool modify)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tu64 idx, orig_idx = __BITS_VALUE(reg1->idx, 0, 8);\n\tu64 config = reg1->config;\n\n\t \n\tidx = orig_idx - EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\n\tif (uncore_nhmex)\n\t\tconfig &= NHMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\n\telse\n\t\tconfig &= WSMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\n\tif (new_idx > orig_idx) {\n\t\tidx = new_idx - orig_idx;\n\t\tconfig <<= 3 * idx;\n\t} else {\n\t\tidx = orig_idx - new_idx;\n\t\tconfig >>= 3 * idx;\n\t}\n\n\t \n\tif (uncore_nhmex)\n\t\tconfig |= NHMEX_M_PMON_ZDP_CTL_FVC_MASK & reg1->config;\n\telse\n\t\tconfig |= WSMEX_M_PMON_ZDP_CTL_FVC_MASK & reg1->config;\n\tconfig |= NHMEX_M_PMON_ZDP_CTL_FVC_MASK & reg1->config;\n\tif (modify) {\n\t\t \n\t\tif (new_idx > orig_idx)\n\t\t\thwc->config += idx << NHMEX_M_PMON_CTL_INC_SEL_SHIFT;\n\t\telse\n\t\t\thwc->config -= idx << NHMEX_M_PMON_CTL_INC_SEL_SHIFT;\n\t\treg1->config = config;\n\t\treg1->idx = ~0xff | new_idx;\n\t}\n\treturn config;\n}\n\nstatic struct event_constraint *\nnhmex_mbox_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &event->hw.branch_reg;\n\tint i, idx[2], alloc = 0;\n\tu64 config1 = reg1->config;\n\n\tidx[0] = __BITS_VALUE(reg1->idx, 0, 8);\n\tidx[1] = __BITS_VALUE(reg1->idx, 1, 8);\nagain:\n\tfor (i = 0; i < 2; i++) {\n\t\tif (!uncore_box_is_fake(box) && (reg1->alloc & (0x1 << i)))\n\t\t\tidx[i] = 0xff;\n\n\t\tif (idx[i] == 0xff)\n\t\t\tcontinue;\n\n\t\tif (!nhmex_mbox_get_shared_reg(box, idx[i],\n\t\t\t\t__BITS_VALUE(config1, i, 32)))\n\t\t\tgoto fail;\n\t\talloc |= (0x1 << i);\n\t}\n\n\t \n\tif (reg2->idx != EXTRA_REG_NONE &&\n\t    (uncore_box_is_fake(box) || !reg2->alloc) &&\n\t    !nhmex_mbox_get_shared_reg(box, reg2->idx, reg2->config))\n\t\tgoto fail;\n\n\t \n\tif (!uncore_box_is_fake(box)) {\n\t\tif (idx[0] != 0xff && idx[0] != __BITS_VALUE(reg1->idx, 0, 8))\n\t\t\tnhmex_mbox_alter_er(event, idx[0], true);\n\t\treg1->alloc |= alloc;\n\t\tif (reg2->idx != EXTRA_REG_NONE)\n\t\t\treg2->alloc = 1;\n\t}\n\treturn NULL;\nfail:\n\tif (idx[0] != 0xff && !(alloc & 0x1) &&\n\t    idx[0] >= EXTRA_REG_NHMEX_M_ZDP_CTL_FVC) {\n\t\t \n\t\tBUG_ON(__BITS_VALUE(reg1->idx, 1, 8) != 0xff);\n\t\tidx[0] -= EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\n\t\tidx[0] = (idx[0] + 1) % 4;\n\t\tidx[0] += EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\n\t\tif (idx[0] != __BITS_VALUE(reg1->idx, 0, 8)) {\n\t\t\tconfig1 = nhmex_mbox_alter_er(event, idx[0], false);\n\t\t\tgoto again;\n\t\t}\n\t}\n\n\tif (alloc & 0x1)\n\t\tnhmex_mbox_put_shared_reg(box, idx[0]);\n\tif (alloc & 0x2)\n\t\tnhmex_mbox_put_shared_reg(box, idx[1]);\n\treturn &uncore_constraint_empty;\n}\n\nstatic void nhmex_mbox_put_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &event->hw.branch_reg;\n\n\tif (uncore_box_is_fake(box))\n\t\treturn;\n\n\tif (reg1->alloc & 0x1)\n\t\tnhmex_mbox_put_shared_reg(box, __BITS_VALUE(reg1->idx, 0, 8));\n\tif (reg1->alloc & 0x2)\n\t\tnhmex_mbox_put_shared_reg(box, __BITS_VALUE(reg1->idx, 1, 8));\n\treg1->alloc = 0;\n\n\tif (reg2->alloc) {\n\t\tnhmex_mbox_put_shared_reg(box, reg2->idx);\n\t\treg2->alloc = 0;\n\t}\n}\n\nstatic int nhmex_mbox_extra_reg_idx(struct extra_reg *er)\n{\n\tif (er->idx < EXTRA_REG_NHMEX_M_ZDP_CTL_FVC)\n\t\treturn er->idx;\n\treturn er->idx + (er->event >> NHMEX_M_PMON_CTL_INC_SEL_SHIFT) - 0xd;\n}\n\nstatic int nhmex_mbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct intel_uncore_type *type = box->pmu->type;\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &event->hw.branch_reg;\n\tstruct extra_reg *er;\n\tunsigned msr;\n\tint reg_idx = 0;\n\t \n\tfor (er = nhmex_uncore_mbox_extra_regs; er->msr; er++) {\n\t\tif (er->event != (event->hw.config & er->config_mask))\n\t\t\tcontinue;\n\t\tif (event->attr.config1 & ~er->valid_mask)\n\t\t\treturn -EINVAL;\n\n\t\tmsr = er->msr + type->msr_offset * box->pmu->pmu_idx;\n\t\tif (WARN_ON_ONCE(msr >= 0xffff || er->idx >= 0xff))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (er->idx == EXTRA_REG_NHMEX_M_PLD)\n\t\t\treg_idx = 1;\n\t\telse if (WARN_ON_ONCE(reg_idx > 0))\n\t\t\treturn -EINVAL;\n\n\t\treg1->idx &= ~(0xff << (reg_idx * 8));\n\t\treg1->reg &= ~(0xffff << (reg_idx * 16));\n\t\treg1->idx |= nhmex_mbox_extra_reg_idx(er) << (reg_idx * 8);\n\t\treg1->reg |= msr << (reg_idx * 16);\n\t\treg1->config = event->attr.config1;\n\t\treg_idx++;\n\t}\n\t \n\tif (reg_idx == 2) {\n\t\treg2->idx = EXTRA_REG_NHMEX_M_FILTER;\n\t\tif (event->attr.config2 & NHMEX_M_PMON_MM_CFG_EN)\n\t\t\treg2->config = event->attr.config2;\n\t\telse\n\t\t\treg2->config = ~0ULL;\n\t\tif (box->pmu->pmu_idx == 0)\n\t\t\treg2->reg = NHMEX_M0_MSR_PMU_MM_CFG;\n\t\telse\n\t\t\treg2->reg = NHMEX_M1_MSR_PMU_MM_CFG;\n\t}\n\treturn 0;\n}\n\nstatic u64 nhmex_mbox_shared_reg_config(struct intel_uncore_box *box, int idx)\n{\n\tstruct intel_uncore_extra_reg *er;\n\tunsigned long flags;\n\tu64 config;\n\n\tif (idx < EXTRA_REG_NHMEX_M_ZDP_CTL_FVC)\n\t\treturn box->shared_regs[idx].config;\n\n\ter = &box->shared_regs[EXTRA_REG_NHMEX_M_ZDP_CTL_FVC];\n\traw_spin_lock_irqsave(&er->lock, flags);\n\tconfig = er->config;\n\traw_spin_unlock_irqrestore(&er->lock, flags);\n\treturn config;\n}\n\nstatic void nhmex_mbox_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\n\tint idx;\n\n\tidx = __BITS_VALUE(reg1->idx, 0, 8);\n\tif (idx != 0xff)\n\t\twrmsrl(__BITS_VALUE(reg1->reg, 0, 16),\n\t\t\tnhmex_mbox_shared_reg_config(box, idx));\n\tidx = __BITS_VALUE(reg1->idx, 1, 8);\n\tif (idx != 0xff)\n\t\twrmsrl(__BITS_VALUE(reg1->reg, 1, 16),\n\t\t\tnhmex_mbox_shared_reg_config(box, idx));\n\n\tif (reg2->idx != EXTRA_REG_NONE) {\n\t\twrmsrl(reg2->reg, 0);\n\t\tif (reg2->config != ~0ULL) {\n\t\t\twrmsrl(reg2->reg + 1,\n\t\t\t\treg2->config & NHMEX_M_PMON_ADDR_MATCH_MASK);\n\t\t\twrmsrl(reg2->reg + 2, NHMEX_M_PMON_ADDR_MASK_MASK &\n\t\t\t\t(reg2->config >> NHMEX_M_PMON_ADDR_MASK_SHIFT));\n\t\t\twrmsrl(reg2->reg, NHMEX_M_PMON_MM_CFG_EN);\n\t\t}\n\t}\n\n\twrmsrl(hwc->config_base, hwc->config | NHMEX_PMON_CTL_EN_BIT0);\n}\n\nDEFINE_UNCORE_FORMAT_ATTR(count_mode,\t\tcount_mode,\t\"config:2-3\");\nDEFINE_UNCORE_FORMAT_ATTR(storage_mode,\t\tstorage_mode,\t\"config:4-5\");\nDEFINE_UNCORE_FORMAT_ATTR(wrap_mode,\t\twrap_mode,\t\"config:6\");\nDEFINE_UNCORE_FORMAT_ATTR(flag_mode,\t\tflag_mode,\t\"config:7\");\nDEFINE_UNCORE_FORMAT_ATTR(inc_sel,\t\tinc_sel,\t\"config:9-13\");\nDEFINE_UNCORE_FORMAT_ATTR(set_flag_sel,\t\tset_flag_sel,\t\"config:19-21\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_cfg_en,\tfilter_cfg_en,\t\"config2:63\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_match,\t\tfilter_match,\t\"config2:0-33\");\nDEFINE_UNCORE_FORMAT_ATTR(filter_mask,\t\tfilter_mask,\t\"config2:34-61\");\nDEFINE_UNCORE_FORMAT_ATTR(dsp,\t\t\tdsp,\t\t\"config1:0-31\");\nDEFINE_UNCORE_FORMAT_ATTR(thr,\t\t\tthr,\t\t\"config1:0-31\");\nDEFINE_UNCORE_FORMAT_ATTR(fvc,\t\t\tfvc,\t\t\"config1:0-31\");\nDEFINE_UNCORE_FORMAT_ATTR(pgt,\t\t\tpgt,\t\t\"config1:0-31\");\nDEFINE_UNCORE_FORMAT_ATTR(map,\t\t\tmap,\t\t\"config1:0-31\");\nDEFINE_UNCORE_FORMAT_ATTR(iss,\t\t\tiss,\t\t\"config1:0-31\");\nDEFINE_UNCORE_FORMAT_ATTR(pld,\t\t\tpld,\t\t\"config1:32-63\");\n\nstatic struct attribute *nhmex_uncore_mbox_formats_attr[] = {\n\t&format_attr_count_mode.attr,\n\t&format_attr_storage_mode.attr,\n\t&format_attr_wrap_mode.attr,\n\t&format_attr_flag_mode.attr,\n\t&format_attr_inc_sel.attr,\n\t&format_attr_set_flag_sel.attr,\n\t&format_attr_filter_cfg_en.attr,\n\t&format_attr_filter_match.attr,\n\t&format_attr_filter_mask.attr,\n\t&format_attr_dsp.attr,\n\t&format_attr_thr.attr,\n\t&format_attr_fvc.attr,\n\t&format_attr_pgt.attr,\n\t&format_attr_map.attr,\n\t&format_attr_iss.attr,\n\t&format_attr_pld.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group nhmex_uncore_mbox_format_group = {\n\t.name\t\t= \"format\",\n\t.attrs\t\t= nhmex_uncore_mbox_formats_attr,\n};\n\nstatic struct uncore_event_desc nhmex_uncore_mbox_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(bbox_cmds_read, \"inc_sel=0xd,fvc=0x2800\"),\n\tINTEL_UNCORE_EVENT_DESC(bbox_cmds_write, \"inc_sel=0xd,fvc=0x2820\"),\n\t{   },\n};\n\nstatic struct uncore_event_desc wsmex_uncore_mbox_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(bbox_cmds_read, \"inc_sel=0xd,fvc=0x5000\"),\n\tINTEL_UNCORE_EVENT_DESC(bbox_cmds_write, \"inc_sel=0xd,fvc=0x5040\"),\n\t{   },\n};\n\nstatic struct intel_uncore_ops nhmex_uncore_mbox_ops = {\n\tNHMEX_UNCORE_OPS_COMMON_INIT(),\n\t.enable_event\t= nhmex_mbox_msr_enable_event,\n\t.hw_config\t= nhmex_mbox_hw_config,\n\t.get_constraint\t= nhmex_mbox_get_constraint,\n\t.put_constraint\t= nhmex_mbox_put_constraint,\n};\n\nstatic struct intel_uncore_type nhmex_uncore_mbox = {\n\t.name\t\t\t= \"mbox\",\n\t.num_counters\t\t= 6,\n\t.num_boxes\t\t= 2,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= NHMEX_M0_MSR_PMU_CTL0,\n\t.perf_ctr\t\t= NHMEX_M0_MSR_PMU_CNT0,\n\t.event_mask\t\t= NHMEX_M_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= NHMEX_M0_MSR_GLOBAL_CTL,\n\t.msr_offset\t\t= NHMEX_M_MSR_OFFSET,\n\t.pair_ctr_ctl\t\t= 1,\n\t.num_shared_regs\t= 8,\n\t.event_descs\t\t= nhmex_uncore_mbox_events,\n\t.ops\t\t\t= &nhmex_uncore_mbox_ops,\n\t.format_group\t\t= &nhmex_uncore_mbox_format_group,\n};\n\nstatic void nhmex_rbox_alter_er(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\n\t \n\tif (reg1->idx % 2) {\n\t\treg1->idx--;\n\t\thwc->config -= 1 << NHMEX_R_PMON_CTL_EV_SEL_SHIFT;\n\t} else {\n\t\treg1->idx++;\n\t\thwc->config += 1 << NHMEX_R_PMON_CTL_EV_SEL_SHIFT;\n\t}\n\n\t \n\tswitch (reg1->idx % 6) {\n\tcase 2:\n\t\t \n\t\treg1->config >>= 8;\n\t\tbreak;\n\tcase 3:\n\t\t \n\t\treg1->config <<= 8;\n\t\tbreak;\n\t}\n}\n\n \nstatic struct event_constraint *\nnhmex_rbox_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\n\tstruct intel_uncore_extra_reg *er;\n\tunsigned long flags;\n\tint idx, er_idx;\n\tu64 config1;\n\tbool ok = false;\n\n\tif (!uncore_box_is_fake(box) && reg1->alloc)\n\t\treturn NULL;\n\n\tidx = reg1->idx % 6;\n\tconfig1 = reg1->config;\nagain:\n\ter_idx = idx;\n\t \n\tif (er_idx > 2)\n\t\ter_idx--;\n\ter_idx += (reg1->idx / 6) * 5;\n\n\ter = &box->shared_regs[er_idx];\n\traw_spin_lock_irqsave(&er->lock, flags);\n\tif (idx < 2) {\n\t\tif (!atomic_read(&er->ref) || er->config == reg1->config) {\n\t\t\tatomic_inc(&er->ref);\n\t\t\ter->config = reg1->config;\n\t\t\tok = true;\n\t\t}\n\t} else if (idx == 2 || idx == 3) {\n\t\t \n\t\tu64 mask = 0xff << ((idx - 2) * 8);\n\t\tif (!__BITS_VALUE(atomic_read(&er->ref), idx - 2, 8) ||\n\t\t\t\t!((er->config ^ config1) & mask)) {\n\t\t\tatomic_add(1 << ((idx - 2) * 8), &er->ref);\n\t\t\ter->config &= ~mask;\n\t\t\ter->config |= config1 & mask;\n\t\t\tok = true;\n\t\t}\n\t} else {\n\t\tif (!atomic_read(&er->ref) ||\n\t\t\t\t(er->config == (hwc->config >> 32) &&\n\t\t\t\t er->config1 == reg1->config &&\n\t\t\t\t er->config2 == reg2->config)) {\n\t\t\tatomic_inc(&er->ref);\n\t\t\ter->config = (hwc->config >> 32);\n\t\t\ter->config1 = reg1->config;\n\t\t\ter->config2 = reg2->config;\n\t\t\tok = true;\n\t\t}\n\t}\n\traw_spin_unlock_irqrestore(&er->lock, flags);\n\n\tif (!ok) {\n\t\t \n\t\tidx ^= 1;\n\t\tif (idx != reg1->idx % 6) {\n\t\t\tif (idx == 2)\n\t\t\t\tconfig1 >>= 8;\n\t\t\telse if (idx == 3)\n\t\t\t\tconfig1 <<= 8;\n\t\t\tgoto again;\n\t\t}\n\t} else {\n\t\tif (!uncore_box_is_fake(box)) {\n\t\t\tif (idx != reg1->idx % 6)\n\t\t\t\tnhmex_rbox_alter_er(box, event);\n\t\t\treg1->alloc = 1;\n\t\t}\n\t\treturn NULL;\n\t}\n\treturn &uncore_constraint_empty;\n}\n\nstatic void nhmex_rbox_put_constraint(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct intel_uncore_extra_reg *er;\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tint idx, er_idx;\n\n\tif (uncore_box_is_fake(box) || !reg1->alloc)\n\t\treturn;\n\n\tidx = reg1->idx % 6;\n\ter_idx = idx;\n\tif (er_idx > 2)\n\t\ter_idx--;\n\ter_idx += (reg1->idx / 6) * 5;\n\n\ter = &box->shared_regs[er_idx];\n\tif (idx == 2 || idx == 3)\n\t\tatomic_sub(1 << ((idx - 2) * 8), &er->ref);\n\telse\n\t\tatomic_dec(&er->ref);\n\n\treg1->alloc = 0;\n}\n\nstatic int nhmex_rbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &event->hw.branch_reg;\n\tint idx;\n\n\tidx = (event->hw.config & NHMEX_R_PMON_CTL_EV_SEL_MASK) >>\n\t\tNHMEX_R_PMON_CTL_EV_SEL_SHIFT;\n\tif (idx >= 0x18)\n\t\treturn -EINVAL;\n\n\treg1->idx = idx;\n\treg1->config = event->attr.config1;\n\n\tswitch (idx % 6) {\n\tcase 4:\n\tcase 5:\n\t\thwc->config |= event->attr.config & (~0ULL << 32);\n\t\treg2->config = event->attr.config2;\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic void nhmex_rbox_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\n\tstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\n\tint idx, port;\n\n\tidx = reg1->idx;\n\tport = idx / 6 + box->pmu->pmu_idx * 4;\n\n\tswitch (idx % 6) {\n\tcase 0:\n\t\twrmsrl(NHMEX_R_MSR_PORTN_IPERF_CFG0(port), reg1->config);\n\t\tbreak;\n\tcase 1:\n\t\twrmsrl(NHMEX_R_MSR_PORTN_IPERF_CFG1(port), reg1->config);\n\t\tbreak;\n\tcase 2:\n\tcase 3:\n\t\twrmsrl(NHMEX_R_MSR_PORTN_QLX_CFG(port),\n\t\t\tuncore_shared_reg_config(box, 2 + (idx / 6) * 5));\n\t\tbreak;\n\tcase 4:\n\t\twrmsrl(NHMEX_R_MSR_PORTN_XBR_SET1_MM_CFG(port),\n\t\t\thwc->config >> 32);\n\t\twrmsrl(NHMEX_R_MSR_PORTN_XBR_SET1_MATCH(port), reg1->config);\n\t\twrmsrl(NHMEX_R_MSR_PORTN_XBR_SET1_MASK(port), reg2->config);\n\t\tbreak;\n\tcase 5:\n\t\twrmsrl(NHMEX_R_MSR_PORTN_XBR_SET2_MM_CFG(port),\n\t\t\thwc->config >> 32);\n\t\twrmsrl(NHMEX_R_MSR_PORTN_XBR_SET2_MATCH(port), reg1->config);\n\t\twrmsrl(NHMEX_R_MSR_PORTN_XBR_SET2_MASK(port), reg2->config);\n\t\tbreak;\n\t}\n\n\twrmsrl(hwc->config_base, NHMEX_PMON_CTL_EN_BIT0 |\n\t\t(hwc->config & NHMEX_R_PMON_CTL_EV_SEL_MASK));\n}\n\nDEFINE_UNCORE_FORMAT_ATTR(xbr_mm_cfg, xbr_mm_cfg, \"config:32-63\");\nDEFINE_UNCORE_FORMAT_ATTR(xbr_match, xbr_match, \"config1:0-63\");\nDEFINE_UNCORE_FORMAT_ATTR(xbr_mask, xbr_mask, \"config2:0-63\");\nDEFINE_UNCORE_FORMAT_ATTR(qlx_cfg, qlx_cfg, \"config1:0-15\");\nDEFINE_UNCORE_FORMAT_ATTR(iperf_cfg, iperf_cfg, \"config1:0-31\");\n\nstatic struct attribute *nhmex_uncore_rbox_formats_attr[] = {\n\t&format_attr_event5.attr,\n\t&format_attr_xbr_mm_cfg.attr,\n\t&format_attr_xbr_match.attr,\n\t&format_attr_xbr_mask.attr,\n\t&format_attr_qlx_cfg.attr,\n\t&format_attr_iperf_cfg.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group nhmex_uncore_rbox_format_group = {\n\t.name = \"format\",\n\t.attrs = nhmex_uncore_rbox_formats_attr,\n};\n\nstatic struct uncore_event_desc nhmex_uncore_rbox_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(qpi0_flit_send,\t\t\"event=0x0,iperf_cfg=0x80000000\"),\n\tINTEL_UNCORE_EVENT_DESC(qpi1_filt_send,\t\t\"event=0x6,iperf_cfg=0x80000000\"),\n\tINTEL_UNCORE_EVENT_DESC(qpi0_idle_filt,\t\t\"event=0x0,iperf_cfg=0x40000000\"),\n\tINTEL_UNCORE_EVENT_DESC(qpi1_idle_filt,\t\t\"event=0x6,iperf_cfg=0x40000000\"),\n\tINTEL_UNCORE_EVENT_DESC(qpi0_date_response,\t\"event=0x0,iperf_cfg=0xc4\"),\n\tINTEL_UNCORE_EVENT_DESC(qpi1_date_response,\t\"event=0x6,iperf_cfg=0xc4\"),\n\t{   },\n};\n\nstatic struct intel_uncore_ops nhmex_uncore_rbox_ops = {\n\tNHMEX_UNCORE_OPS_COMMON_INIT(),\n\t.enable_event\t\t= nhmex_rbox_msr_enable_event,\n\t.hw_config\t\t= nhmex_rbox_hw_config,\n\t.get_constraint\t\t= nhmex_rbox_get_constraint,\n\t.put_constraint\t\t= nhmex_rbox_put_constraint,\n};\n\nstatic struct intel_uncore_type nhmex_uncore_rbox = {\n\t.name\t\t\t= \"rbox\",\n\t.num_counters\t\t= 8,\n\t.num_boxes\t\t= 2,\n\t.perf_ctr_bits\t\t= 48,\n\t.event_ctl\t\t= NHMEX_R_MSR_PMON_CTL0,\n\t.perf_ctr\t\t= NHMEX_R_MSR_PMON_CNT0,\n\t.event_mask\t\t= NHMEX_R_PMON_RAW_EVENT_MASK,\n\t.box_ctl\t\t= NHMEX_R_MSR_GLOBAL_CTL,\n\t.msr_offset\t\t= NHMEX_R_MSR_OFFSET,\n\t.pair_ctr_ctl\t\t= 1,\n\t.num_shared_regs\t= 20,\n\t.event_descs\t\t= nhmex_uncore_rbox_events,\n\t.ops\t\t\t= &nhmex_uncore_rbox_ops,\n\t.format_group\t\t= &nhmex_uncore_rbox_format_group\n};\n\nstatic struct intel_uncore_type *nhmex_msr_uncores[] = {\n\t&nhmex_uncore_ubox,\n\t&nhmex_uncore_cbox,\n\t&nhmex_uncore_bbox,\n\t&nhmex_uncore_sbox,\n\t&nhmex_uncore_mbox,\n\t&nhmex_uncore_rbox,\n\t&nhmex_uncore_wbox,\n\tNULL,\n};\n\nvoid nhmex_uncore_cpu_init(void)\n{\n\tif (boot_cpu_data.x86_model == 46)\n\t\tuncore_nhmex = true;\n\telse\n\t\tnhmex_uncore_mbox.event_descs = wsmex_uncore_mbox_events;\n\tif (nhmex_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)\n\t\tnhmex_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;\n\tuncore_msr_uncores = nhmex_msr_uncores;\n}\n \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}