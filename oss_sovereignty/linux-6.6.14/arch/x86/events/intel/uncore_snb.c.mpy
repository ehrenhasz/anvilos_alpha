{
  "module_name": "uncore_snb.c",
  "hash_id": "b2247af53a593747443f97a347972ddb096a79615b1b8d6fbc4cc1836f66fc67",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/events/intel/uncore_snb.c",
  "human_readable_source": "\n \n#include \"uncore.h\"\n#include \"uncore_discovery.h\"\n\n \n#define PCI_DEVICE_ID_INTEL_SNB_IMC\t\t0x0100\n#define PCI_DEVICE_ID_INTEL_IVB_IMC\t\t0x0154\n#define PCI_DEVICE_ID_INTEL_IVB_E3_IMC\t\t0x0150\n#define PCI_DEVICE_ID_INTEL_HSW_IMC\t\t0x0c00\n#define PCI_DEVICE_ID_INTEL_HSW_U_IMC\t\t0x0a04\n#define PCI_DEVICE_ID_INTEL_BDW_IMC\t\t0x1604\n#define PCI_DEVICE_ID_INTEL_SKL_U_IMC\t\t0x1904\n#define PCI_DEVICE_ID_INTEL_SKL_Y_IMC\t\t0x190c\n#define PCI_DEVICE_ID_INTEL_SKL_HD_IMC\t\t0x1900\n#define PCI_DEVICE_ID_INTEL_SKL_HQ_IMC\t\t0x1910\n#define PCI_DEVICE_ID_INTEL_SKL_SD_IMC\t\t0x190f\n#define PCI_DEVICE_ID_INTEL_SKL_SQ_IMC\t\t0x191f\n#define PCI_DEVICE_ID_INTEL_SKL_E3_IMC\t\t0x1918\n#define PCI_DEVICE_ID_INTEL_KBL_Y_IMC\t\t0x590c\n#define PCI_DEVICE_ID_INTEL_KBL_U_IMC\t\t0x5904\n#define PCI_DEVICE_ID_INTEL_KBL_UQ_IMC\t\t0x5914\n#define PCI_DEVICE_ID_INTEL_KBL_SD_IMC\t\t0x590f\n#define PCI_DEVICE_ID_INTEL_KBL_SQ_IMC\t\t0x591f\n#define PCI_DEVICE_ID_INTEL_KBL_HQ_IMC\t\t0x5910\n#define PCI_DEVICE_ID_INTEL_KBL_WQ_IMC\t\t0x5918\n#define PCI_DEVICE_ID_INTEL_CFL_2U_IMC\t\t0x3ecc\n#define PCI_DEVICE_ID_INTEL_CFL_4U_IMC\t\t0x3ed0\n#define PCI_DEVICE_ID_INTEL_CFL_4H_IMC\t\t0x3e10\n#define PCI_DEVICE_ID_INTEL_CFL_6H_IMC\t\t0x3ec4\n#define PCI_DEVICE_ID_INTEL_CFL_2S_D_IMC\t0x3e0f\n#define PCI_DEVICE_ID_INTEL_CFL_4S_D_IMC\t0x3e1f\n#define PCI_DEVICE_ID_INTEL_CFL_6S_D_IMC\t0x3ec2\n#define PCI_DEVICE_ID_INTEL_CFL_8S_D_IMC\t0x3e30\n#define PCI_DEVICE_ID_INTEL_CFL_4S_W_IMC\t0x3e18\n#define PCI_DEVICE_ID_INTEL_CFL_6S_W_IMC\t0x3ec6\n#define PCI_DEVICE_ID_INTEL_CFL_8S_W_IMC\t0x3e31\n#define PCI_DEVICE_ID_INTEL_CFL_4S_S_IMC\t0x3e33\n#define PCI_DEVICE_ID_INTEL_CFL_6S_S_IMC\t0x3eca\n#define PCI_DEVICE_ID_INTEL_CFL_8S_S_IMC\t0x3e32\n#define PCI_DEVICE_ID_INTEL_AML_YD_IMC\t\t0x590c\n#define PCI_DEVICE_ID_INTEL_AML_YQ_IMC\t\t0x590d\n#define PCI_DEVICE_ID_INTEL_WHL_UQ_IMC\t\t0x3ed0\n#define PCI_DEVICE_ID_INTEL_WHL_4_UQ_IMC\t0x3e34\n#define PCI_DEVICE_ID_INTEL_WHL_UD_IMC\t\t0x3e35\n#define PCI_DEVICE_ID_INTEL_CML_H1_IMC\t\t0x9b44\n#define PCI_DEVICE_ID_INTEL_CML_H2_IMC\t\t0x9b54\n#define PCI_DEVICE_ID_INTEL_CML_H3_IMC\t\t0x9b64\n#define PCI_DEVICE_ID_INTEL_CML_U1_IMC\t\t0x9b51\n#define PCI_DEVICE_ID_INTEL_CML_U2_IMC\t\t0x9b61\n#define PCI_DEVICE_ID_INTEL_CML_U3_IMC\t\t0x9b71\n#define PCI_DEVICE_ID_INTEL_CML_S1_IMC\t\t0x9b33\n#define PCI_DEVICE_ID_INTEL_CML_S2_IMC\t\t0x9b43\n#define PCI_DEVICE_ID_INTEL_CML_S3_IMC\t\t0x9b53\n#define PCI_DEVICE_ID_INTEL_CML_S4_IMC\t\t0x9b63\n#define PCI_DEVICE_ID_INTEL_CML_S5_IMC\t\t0x9b73\n#define PCI_DEVICE_ID_INTEL_ICL_U_IMC\t\t0x8a02\n#define PCI_DEVICE_ID_INTEL_ICL_U2_IMC\t\t0x8a12\n#define PCI_DEVICE_ID_INTEL_TGL_U1_IMC\t\t0x9a02\n#define PCI_DEVICE_ID_INTEL_TGL_U2_IMC\t\t0x9a04\n#define PCI_DEVICE_ID_INTEL_TGL_U3_IMC\t\t0x9a12\n#define PCI_DEVICE_ID_INTEL_TGL_U4_IMC\t\t0x9a14\n#define PCI_DEVICE_ID_INTEL_TGL_H_IMC\t\t0x9a36\n#define PCI_DEVICE_ID_INTEL_RKL_1_IMC\t\t0x4c43\n#define PCI_DEVICE_ID_INTEL_RKL_2_IMC\t\t0x4c53\n#define PCI_DEVICE_ID_INTEL_ADL_1_IMC\t\t0x4660\n#define PCI_DEVICE_ID_INTEL_ADL_2_IMC\t\t0x4641\n#define PCI_DEVICE_ID_INTEL_ADL_3_IMC\t\t0x4601\n#define PCI_DEVICE_ID_INTEL_ADL_4_IMC\t\t0x4602\n#define PCI_DEVICE_ID_INTEL_ADL_5_IMC\t\t0x4609\n#define PCI_DEVICE_ID_INTEL_ADL_6_IMC\t\t0x460a\n#define PCI_DEVICE_ID_INTEL_ADL_7_IMC\t\t0x4621\n#define PCI_DEVICE_ID_INTEL_ADL_8_IMC\t\t0x4623\n#define PCI_DEVICE_ID_INTEL_ADL_9_IMC\t\t0x4629\n#define PCI_DEVICE_ID_INTEL_ADL_10_IMC\t\t0x4637\n#define PCI_DEVICE_ID_INTEL_ADL_11_IMC\t\t0x463b\n#define PCI_DEVICE_ID_INTEL_ADL_12_IMC\t\t0x4648\n#define PCI_DEVICE_ID_INTEL_ADL_13_IMC\t\t0x4649\n#define PCI_DEVICE_ID_INTEL_ADL_14_IMC\t\t0x4650\n#define PCI_DEVICE_ID_INTEL_ADL_15_IMC\t\t0x4668\n#define PCI_DEVICE_ID_INTEL_ADL_16_IMC\t\t0x4670\n#define PCI_DEVICE_ID_INTEL_ADL_17_IMC\t\t0x4614\n#define PCI_DEVICE_ID_INTEL_ADL_18_IMC\t\t0x4617\n#define PCI_DEVICE_ID_INTEL_ADL_19_IMC\t\t0x4618\n#define PCI_DEVICE_ID_INTEL_ADL_20_IMC\t\t0x461B\n#define PCI_DEVICE_ID_INTEL_ADL_21_IMC\t\t0x461C\n#define PCI_DEVICE_ID_INTEL_RPL_1_IMC\t\t0xA700\n#define PCI_DEVICE_ID_INTEL_RPL_2_IMC\t\t0xA702\n#define PCI_DEVICE_ID_INTEL_RPL_3_IMC\t\t0xA706\n#define PCI_DEVICE_ID_INTEL_RPL_4_IMC\t\t0xA709\n#define PCI_DEVICE_ID_INTEL_RPL_5_IMC\t\t0xA701\n#define PCI_DEVICE_ID_INTEL_RPL_6_IMC\t\t0xA703\n#define PCI_DEVICE_ID_INTEL_RPL_7_IMC\t\t0xA704\n#define PCI_DEVICE_ID_INTEL_RPL_8_IMC\t\t0xA705\n#define PCI_DEVICE_ID_INTEL_RPL_9_IMC\t\t0xA706\n#define PCI_DEVICE_ID_INTEL_RPL_10_IMC\t\t0xA707\n#define PCI_DEVICE_ID_INTEL_RPL_11_IMC\t\t0xA708\n#define PCI_DEVICE_ID_INTEL_RPL_12_IMC\t\t0xA709\n#define PCI_DEVICE_ID_INTEL_RPL_13_IMC\t\t0xA70a\n#define PCI_DEVICE_ID_INTEL_RPL_14_IMC\t\t0xA70b\n#define PCI_DEVICE_ID_INTEL_RPL_15_IMC\t\t0xA715\n#define PCI_DEVICE_ID_INTEL_RPL_16_IMC\t\t0xA716\n#define PCI_DEVICE_ID_INTEL_RPL_17_IMC\t\t0xA717\n#define PCI_DEVICE_ID_INTEL_RPL_18_IMC\t\t0xA718\n#define PCI_DEVICE_ID_INTEL_RPL_19_IMC\t\t0xA719\n#define PCI_DEVICE_ID_INTEL_RPL_20_IMC\t\t0xA71A\n#define PCI_DEVICE_ID_INTEL_RPL_21_IMC\t\t0xA71B\n#define PCI_DEVICE_ID_INTEL_RPL_22_IMC\t\t0xA71C\n#define PCI_DEVICE_ID_INTEL_RPL_23_IMC\t\t0xA728\n#define PCI_DEVICE_ID_INTEL_RPL_24_IMC\t\t0xA729\n#define PCI_DEVICE_ID_INTEL_RPL_25_IMC\t\t0xA72A\n#define PCI_DEVICE_ID_INTEL_MTL_1_IMC\t\t0x7d00\n#define PCI_DEVICE_ID_INTEL_MTL_2_IMC\t\t0x7d01\n#define PCI_DEVICE_ID_INTEL_MTL_3_IMC\t\t0x7d02\n#define PCI_DEVICE_ID_INTEL_MTL_4_IMC\t\t0x7d05\n#define PCI_DEVICE_ID_INTEL_MTL_5_IMC\t\t0x7d10\n#define PCI_DEVICE_ID_INTEL_MTL_6_IMC\t\t0x7d14\n#define PCI_DEVICE_ID_INTEL_MTL_7_IMC\t\t0x7d15\n#define PCI_DEVICE_ID_INTEL_MTL_8_IMC\t\t0x7d16\n#define PCI_DEVICE_ID_INTEL_MTL_9_IMC\t\t0x7d21\n#define PCI_DEVICE_ID_INTEL_MTL_10_IMC\t\t0x7d22\n#define PCI_DEVICE_ID_INTEL_MTL_11_IMC\t\t0x7d23\n#define PCI_DEVICE_ID_INTEL_MTL_12_IMC\t\t0x7d24\n#define PCI_DEVICE_ID_INTEL_MTL_13_IMC\t\t0x7d28\n\n\n#define IMC_UNCORE_DEV(a)\t\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tPCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_##a##_IMC),\t\\\n\t.driver_data = UNCORE_PCI_DEV_DATA(SNB_PCI_UNCORE_IMC, 0),\t\\\n}\n\n \n#define SNB_UNC_CTL_EV_SEL_MASK\t\t\t0x000000ff\n#define SNB_UNC_CTL_UMASK_MASK\t\t\t0x0000ff00\n#define SNB_UNC_CTL_EDGE_DET\t\t\t(1 << 18)\n#define SNB_UNC_CTL_EN\t\t\t\t(1 << 22)\n#define SNB_UNC_CTL_INVERT\t\t\t(1 << 23)\n#define SNB_UNC_CTL_CMASK_MASK\t\t\t0x1f000000\n#define NHM_UNC_CTL_CMASK_MASK\t\t\t0xff000000\n#define NHM_UNC_FIXED_CTR_CTL_EN\t\t(1 << 0)\n\n#define SNB_UNC_RAW_EVENT_MASK\t\t\t(SNB_UNC_CTL_EV_SEL_MASK | \\\n\t\t\t\t\t\t SNB_UNC_CTL_UMASK_MASK | \\\n\t\t\t\t\t\t SNB_UNC_CTL_EDGE_DET | \\\n\t\t\t\t\t\t SNB_UNC_CTL_INVERT | \\\n\t\t\t\t\t\t SNB_UNC_CTL_CMASK_MASK)\n\n#define NHM_UNC_RAW_EVENT_MASK\t\t\t(SNB_UNC_CTL_EV_SEL_MASK | \\\n\t\t\t\t\t\t SNB_UNC_CTL_UMASK_MASK | \\\n\t\t\t\t\t\t SNB_UNC_CTL_EDGE_DET | \\\n\t\t\t\t\t\t SNB_UNC_CTL_INVERT | \\\n\t\t\t\t\t\t NHM_UNC_CTL_CMASK_MASK)\n\n \n#define SNB_UNC_PERF_GLOBAL_CTL                 0x391\n#define SNB_UNC_FIXED_CTR_CTRL                  0x394\n#define SNB_UNC_FIXED_CTR                       0x395\n\n \n#define SNB_UNC_GLOBAL_CTL_CORE_ALL             ((1 << 4) - 1)\n#define SNB_UNC_GLOBAL_CTL_EN                   (1 << 29)\n\n \n#define SNB_UNC_CBO_0_PERFEVTSEL0               0x700\n#define SNB_UNC_CBO_0_PER_CTR0                  0x706\n#define SNB_UNC_CBO_MSR_OFFSET                  0x10\n\n \n#define SNB_UNC_ARB_PER_CTR0\t\t\t0x3b0\n#define SNB_UNC_ARB_PERFEVTSEL0\t\t\t0x3b2\n#define SNB_UNC_ARB_MSR_OFFSET\t\t\t0x10\n\n \n#define NHM_UNC_PERF_GLOBAL_CTL                 0x391\n#define NHM_UNC_FIXED_CTR                       0x394\n#define NHM_UNC_FIXED_CTR_CTRL                  0x395\n\n \n#define NHM_UNC_GLOBAL_CTL_EN_PC_ALL            ((1ULL << 8) - 1)\n#define NHM_UNC_GLOBAL_CTL_EN_FC                (1ULL << 32)\n\n \n#define NHM_UNC_PERFEVTSEL0                     0x3c0\n#define NHM_UNC_UNCORE_PMC0                     0x3b0\n\n \n#define SKL_UNC_PERF_GLOBAL_CTL\t\t\t0xe01\n#define SKL_UNC_GLOBAL_CTL_CORE_ALL\t\t((1 << 5) - 1)\n\n \n#define ICL_UNC_CBO_CONFIG\t\t\t0x396\n#define ICL_UNC_NUM_CBO_MASK\t\t\t0xf\n#define ICL_UNC_CBO_0_PER_CTR0\t\t\t0x702\n#define ICL_UNC_CBO_MSR_OFFSET\t\t\t0x8\n\n \n#define ICL_UNC_ARB_PER_CTR\t\t\t0x3b1\n#define ICL_UNC_ARB_PERFEVTSEL\t\t\t0x3b3\n\n \n#define ADL_UNC_PERF_GLOBAL_CTL\t\t\t0x2ff0\n#define ADL_UNC_FIXED_CTR_CTRL                  0x2fde\n#define ADL_UNC_FIXED_CTR                       0x2fdf\n\n \n#define ADL_UNC_CBO_0_PER_CTR0\t\t\t0x2002\n#define ADL_UNC_CBO_0_PERFEVTSEL0\t\t0x2000\n#define ADL_UNC_CTL_THRESHOLD\t\t\t0x3f000000\n#define ADL_UNC_RAW_EVENT_MASK\t\t\t(SNB_UNC_CTL_EV_SEL_MASK | \\\n\t\t\t\t\t\t SNB_UNC_CTL_UMASK_MASK | \\\n\t\t\t\t\t\t SNB_UNC_CTL_EDGE_DET | \\\n\t\t\t\t\t\t SNB_UNC_CTL_INVERT | \\\n\t\t\t\t\t\t ADL_UNC_CTL_THRESHOLD)\n\n \n#define ADL_UNC_ARB_PER_CTR0\t\t\t0x2FD2\n#define ADL_UNC_ARB_PERFEVTSEL0\t\t\t0x2FD0\n#define ADL_UNC_ARB_MSR_OFFSET\t\t\t0x8\n\n \n#define MTL_UNC_CBO_0_PER_CTR0\t\t\t0x2448\n#define MTL_UNC_CBO_0_PERFEVTSEL0\t\t0x2442\n\n \n#define MTL_UNC_HAC_ARB_CTR\t\t\t0x2018\n#define MTL_UNC_HAC_ARB_CTRL\t\t\t0x2012\n\n \n#define MTL_UNC_ARB_CTR\t\t\t\t0x2418\n#define MTL_UNC_ARB_CTRL\t\t\t0x2412\n\n \n#define MTL_UNC_CNCU_FIXED_CTR\t\t\t0x2408\n#define MTL_UNC_CNCU_FIXED_CTRL\t\t\t0x2402\n#define MTL_UNC_CNCU_BOX_CTL\t\t\t0x240e\n\n \n#define MTL_UNC_SNCU_FIXED_CTR\t\t\t0x2008\n#define MTL_UNC_SNCU_FIXED_CTRL\t\t\t0x2002\n#define MTL_UNC_SNCU_BOX_CTL\t\t\t0x200e\n\n \n#define MTL_UNC_HBO_CTR\t\t\t\t0x2048\n#define MTL_UNC_HBO_CTRL\t\t\t0x2042\n\nDEFINE_UNCORE_FORMAT_ATTR(event, event, \"config:0-7\");\nDEFINE_UNCORE_FORMAT_ATTR(umask, umask, \"config:8-15\");\nDEFINE_UNCORE_FORMAT_ATTR(chmask, chmask, \"config:8-11\");\nDEFINE_UNCORE_FORMAT_ATTR(edge, edge, \"config:18\");\nDEFINE_UNCORE_FORMAT_ATTR(inv, inv, \"config:23\");\nDEFINE_UNCORE_FORMAT_ATTR(cmask5, cmask, \"config:24-28\");\nDEFINE_UNCORE_FORMAT_ATTR(cmask8, cmask, \"config:24-31\");\nDEFINE_UNCORE_FORMAT_ATTR(threshold, threshold, \"config:24-29\");\n\n \nstatic void snb_uncore_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (hwc->idx < UNCORE_PMC_IDX_FIXED)\n\t\twrmsrl(hwc->config_base, hwc->config | SNB_UNC_CTL_EN);\n\telse\n\t\twrmsrl(hwc->config_base, SNB_UNC_CTL_EN);\n}\n\nstatic void snb_uncore_msr_disable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\twrmsrl(event->hw.config_base, 0);\n}\n\nstatic void snb_uncore_msr_init_box(struct intel_uncore_box *box)\n{\n\tif (box->pmu->pmu_idx == 0) {\n\t\twrmsrl(SNB_UNC_PERF_GLOBAL_CTL,\n\t\t\tSNB_UNC_GLOBAL_CTL_EN | SNB_UNC_GLOBAL_CTL_CORE_ALL);\n\t}\n}\n\nstatic void snb_uncore_msr_enable_box(struct intel_uncore_box *box)\n{\n\twrmsrl(SNB_UNC_PERF_GLOBAL_CTL,\n\t\tSNB_UNC_GLOBAL_CTL_EN | SNB_UNC_GLOBAL_CTL_CORE_ALL);\n}\n\nstatic void snb_uncore_msr_exit_box(struct intel_uncore_box *box)\n{\n\tif (box->pmu->pmu_idx == 0)\n\t\twrmsrl(SNB_UNC_PERF_GLOBAL_CTL, 0);\n}\n\nstatic struct uncore_event_desc snb_uncore_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(clockticks, \"event=0xff,umask=0x00\"),\n\t{   },\n};\n\nstatic struct attribute *snb_uncore_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_cmask5.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group snb_uncore_format_group = {\n\t.name\t\t= \"format\",\n\t.attrs\t\t= snb_uncore_formats_attr,\n};\n\nstatic struct intel_uncore_ops snb_uncore_msr_ops = {\n\t.init_box\t= snb_uncore_msr_init_box,\n\t.enable_box\t= snb_uncore_msr_enable_box,\n\t.exit_box\t= snb_uncore_msr_exit_box,\n\t.disable_event\t= snb_uncore_msr_disable_event,\n\t.enable_event\t= snb_uncore_msr_enable_event,\n\t.read_counter\t= uncore_msr_read_counter,\n};\n\nstatic struct event_constraint snb_uncore_arb_constraints[] = {\n\tUNCORE_EVENT_CONSTRAINT(0x80, 0x1),\n\tUNCORE_EVENT_CONSTRAINT(0x83, 0x1),\n\tEVENT_CONSTRAINT_END\n};\n\nstatic struct intel_uncore_type snb_uncore_cbox = {\n\t.name\t\t= \"cbox\",\n\t.num_counters   = 2,\n\t.num_boxes\t= 4,\n\t.perf_ctr_bits\t= 44,\n\t.fixed_ctr_bits\t= 48,\n\t.perf_ctr\t= SNB_UNC_CBO_0_PER_CTR0,\n\t.event_ctl\t= SNB_UNC_CBO_0_PERFEVTSEL0,\n\t.fixed_ctr\t= SNB_UNC_FIXED_CTR,\n\t.fixed_ctl\t= SNB_UNC_FIXED_CTR_CTRL,\n\t.single_fixed\t= 1,\n\t.event_mask\t= SNB_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= SNB_UNC_CBO_MSR_OFFSET,\n\t.ops\t\t= &snb_uncore_msr_ops,\n\t.format_group\t= &snb_uncore_format_group,\n\t.event_descs\t= snb_uncore_events,\n};\n\nstatic struct intel_uncore_type snb_uncore_arb = {\n\t.name\t\t= \"arb\",\n\t.num_counters   = 2,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 44,\n\t.perf_ctr\t= SNB_UNC_ARB_PER_CTR0,\n\t.event_ctl\t= SNB_UNC_ARB_PERFEVTSEL0,\n\t.event_mask\t= SNB_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= SNB_UNC_ARB_MSR_OFFSET,\n\t.constraints\t= snb_uncore_arb_constraints,\n\t.ops\t\t= &snb_uncore_msr_ops,\n\t.format_group\t= &snb_uncore_format_group,\n};\n\nstatic struct intel_uncore_type *snb_msr_uncores[] = {\n\t&snb_uncore_cbox,\n\t&snb_uncore_arb,\n\tNULL,\n};\n\nvoid snb_uncore_cpu_init(void)\n{\n\tuncore_msr_uncores = snb_msr_uncores;\n\tif (snb_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)\n\t\tsnb_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;\n}\n\nstatic void skl_uncore_msr_init_box(struct intel_uncore_box *box)\n{\n\tif (box->pmu->pmu_idx == 0) {\n\t\twrmsrl(SKL_UNC_PERF_GLOBAL_CTL,\n\t\t\tSNB_UNC_GLOBAL_CTL_EN | SKL_UNC_GLOBAL_CTL_CORE_ALL);\n\t}\n\n\t \n\tif (box->pmu->pmu_idx == 7)\n\t\t__set_bit(UNCORE_BOX_FLAG_CFL8_CBOX_MSR_OFFS, &box->flags);\n}\n\nstatic void skl_uncore_msr_enable_box(struct intel_uncore_box *box)\n{\n\twrmsrl(SKL_UNC_PERF_GLOBAL_CTL,\n\t\tSNB_UNC_GLOBAL_CTL_EN | SKL_UNC_GLOBAL_CTL_CORE_ALL);\n}\n\nstatic void skl_uncore_msr_exit_box(struct intel_uncore_box *box)\n{\n\tif (box->pmu->pmu_idx == 0)\n\t\twrmsrl(SKL_UNC_PERF_GLOBAL_CTL, 0);\n}\n\nstatic struct intel_uncore_ops skl_uncore_msr_ops = {\n\t.init_box\t= skl_uncore_msr_init_box,\n\t.enable_box\t= skl_uncore_msr_enable_box,\n\t.exit_box\t= skl_uncore_msr_exit_box,\n\t.disable_event\t= snb_uncore_msr_disable_event,\n\t.enable_event\t= snb_uncore_msr_enable_event,\n\t.read_counter\t= uncore_msr_read_counter,\n};\n\nstatic struct intel_uncore_type skl_uncore_cbox = {\n\t.name\t\t= \"cbox\",\n\t.num_counters   = 4,\n\t.num_boxes\t= 8,\n\t.perf_ctr_bits\t= 44,\n\t.fixed_ctr_bits\t= 48,\n\t.perf_ctr\t= SNB_UNC_CBO_0_PER_CTR0,\n\t.event_ctl\t= SNB_UNC_CBO_0_PERFEVTSEL0,\n\t.fixed_ctr\t= SNB_UNC_FIXED_CTR,\n\t.fixed_ctl\t= SNB_UNC_FIXED_CTR_CTRL,\n\t.single_fixed\t= 1,\n\t.event_mask\t= SNB_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= SNB_UNC_CBO_MSR_OFFSET,\n\t.ops\t\t= &skl_uncore_msr_ops,\n\t.format_group\t= &snb_uncore_format_group,\n\t.event_descs\t= snb_uncore_events,\n};\n\nstatic struct intel_uncore_type *skl_msr_uncores[] = {\n\t&skl_uncore_cbox,\n\t&snb_uncore_arb,\n\tNULL,\n};\n\nvoid skl_uncore_cpu_init(void)\n{\n\tuncore_msr_uncores = skl_msr_uncores;\n\tif (skl_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)\n\t\tskl_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;\n\tsnb_uncore_arb.ops = &skl_uncore_msr_ops;\n}\n\nstatic struct intel_uncore_ops icl_uncore_msr_ops = {\n\t.disable_event\t= snb_uncore_msr_disable_event,\n\t.enable_event\t= snb_uncore_msr_enable_event,\n\t.read_counter\t= uncore_msr_read_counter,\n};\n\nstatic struct intel_uncore_type icl_uncore_cbox = {\n\t.name\t\t= \"cbox\",\n\t.num_counters   = 2,\n\t.perf_ctr_bits\t= 44,\n\t.perf_ctr\t= ICL_UNC_CBO_0_PER_CTR0,\n\t.event_ctl\t= SNB_UNC_CBO_0_PERFEVTSEL0,\n\t.event_mask\t= SNB_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= ICL_UNC_CBO_MSR_OFFSET,\n\t.ops\t\t= &icl_uncore_msr_ops,\n\t.format_group\t= &snb_uncore_format_group,\n};\n\nstatic struct uncore_event_desc icl_uncore_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(clockticks, \"event=0xff\"),\n\t{   },\n};\n\nstatic struct attribute *icl_uncore_clock_formats_attr[] = {\n\t&format_attr_event.attr,\n\tNULL,\n};\n\nstatic struct attribute_group icl_uncore_clock_format_group = {\n\t.name = \"format\",\n\t.attrs = icl_uncore_clock_formats_attr,\n};\n\nstatic struct intel_uncore_type icl_uncore_clockbox = {\n\t.name\t\t= \"clock\",\n\t.num_counters\t= 1,\n\t.num_boxes\t= 1,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= SNB_UNC_FIXED_CTR,\n\t.fixed_ctl\t= SNB_UNC_FIXED_CTR_CTRL,\n\t.single_fixed\t= 1,\n\t.event_mask\t= SNB_UNC_CTL_EV_SEL_MASK,\n\t.format_group\t= &icl_uncore_clock_format_group,\n\t.ops\t\t= &icl_uncore_msr_ops,\n\t.event_descs\t= icl_uncore_events,\n};\n\nstatic struct intel_uncore_type icl_uncore_arb = {\n\t.name\t\t= \"arb\",\n\t.num_counters   = 1,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 44,\n\t.perf_ctr\t= ICL_UNC_ARB_PER_CTR,\n\t.event_ctl\t= ICL_UNC_ARB_PERFEVTSEL,\n\t.event_mask\t= SNB_UNC_RAW_EVENT_MASK,\n\t.ops\t\t= &icl_uncore_msr_ops,\n\t.format_group\t= &snb_uncore_format_group,\n};\n\nstatic struct intel_uncore_type *icl_msr_uncores[] = {\n\t&icl_uncore_cbox,\n\t&icl_uncore_arb,\n\t&icl_uncore_clockbox,\n\tNULL,\n};\n\nstatic int icl_get_cbox_num(void)\n{\n\tu64 num_boxes;\n\n\trdmsrl(ICL_UNC_CBO_CONFIG, num_boxes);\n\n\treturn num_boxes & ICL_UNC_NUM_CBO_MASK;\n}\n\nvoid icl_uncore_cpu_init(void)\n{\n\tuncore_msr_uncores = icl_msr_uncores;\n\ticl_uncore_cbox.num_boxes = icl_get_cbox_num();\n}\n\nstatic struct intel_uncore_type *tgl_msr_uncores[] = {\n\t&icl_uncore_cbox,\n\t&snb_uncore_arb,\n\t&icl_uncore_clockbox,\n\tNULL,\n};\n\nstatic void rkl_uncore_msr_init_box(struct intel_uncore_box *box)\n{\n\tif (box->pmu->pmu_idx == 0)\n\t\twrmsrl(SKL_UNC_PERF_GLOBAL_CTL, SNB_UNC_GLOBAL_CTL_EN);\n}\n\nvoid tgl_uncore_cpu_init(void)\n{\n\tuncore_msr_uncores = tgl_msr_uncores;\n\ticl_uncore_cbox.num_boxes = icl_get_cbox_num();\n\ticl_uncore_cbox.ops = &skl_uncore_msr_ops;\n\ticl_uncore_clockbox.ops = &skl_uncore_msr_ops;\n\tsnb_uncore_arb.ops = &skl_uncore_msr_ops;\n\tskl_uncore_msr_ops.init_box = rkl_uncore_msr_init_box;\n}\n\nstatic void adl_uncore_msr_init_box(struct intel_uncore_box *box)\n{\n\tif (box->pmu->pmu_idx == 0)\n\t\twrmsrl(ADL_UNC_PERF_GLOBAL_CTL, SNB_UNC_GLOBAL_CTL_EN);\n}\n\nstatic void adl_uncore_msr_enable_box(struct intel_uncore_box *box)\n{\n\twrmsrl(ADL_UNC_PERF_GLOBAL_CTL, SNB_UNC_GLOBAL_CTL_EN);\n}\n\nstatic void adl_uncore_msr_disable_box(struct intel_uncore_box *box)\n{\n\tif (box->pmu->pmu_idx == 0)\n\t\twrmsrl(ADL_UNC_PERF_GLOBAL_CTL, 0);\n}\n\nstatic void adl_uncore_msr_exit_box(struct intel_uncore_box *box)\n{\n\tif (box->pmu->pmu_idx == 0)\n\t\twrmsrl(ADL_UNC_PERF_GLOBAL_CTL, 0);\n}\n\nstatic struct intel_uncore_ops adl_uncore_msr_ops = {\n\t.init_box\t= adl_uncore_msr_init_box,\n\t.enable_box\t= adl_uncore_msr_enable_box,\n\t.disable_box\t= adl_uncore_msr_disable_box,\n\t.exit_box\t= adl_uncore_msr_exit_box,\n\t.disable_event\t= snb_uncore_msr_disable_event,\n\t.enable_event\t= snb_uncore_msr_enable_event,\n\t.read_counter\t= uncore_msr_read_counter,\n};\n\nstatic struct attribute *adl_uncore_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_threshold.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group adl_uncore_format_group = {\n\t.name\t\t= \"format\",\n\t.attrs\t\t= adl_uncore_formats_attr,\n};\n\nstatic struct intel_uncore_type adl_uncore_cbox = {\n\t.name\t\t= \"cbox\",\n\t.num_counters   = 2,\n\t.perf_ctr_bits\t= 44,\n\t.perf_ctr\t= ADL_UNC_CBO_0_PER_CTR0,\n\t.event_ctl\t= ADL_UNC_CBO_0_PERFEVTSEL0,\n\t.event_mask\t= ADL_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= ICL_UNC_CBO_MSR_OFFSET,\n\t.ops\t\t= &adl_uncore_msr_ops,\n\t.format_group\t= &adl_uncore_format_group,\n};\n\nstatic struct intel_uncore_type adl_uncore_arb = {\n\t.name\t\t= \"arb\",\n\t.num_counters   = 2,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 44,\n\t.perf_ctr\t= ADL_UNC_ARB_PER_CTR0,\n\t.event_ctl\t= ADL_UNC_ARB_PERFEVTSEL0,\n\t.event_mask\t= SNB_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= ADL_UNC_ARB_MSR_OFFSET,\n\t.constraints\t= snb_uncore_arb_constraints,\n\t.ops\t\t= &adl_uncore_msr_ops,\n\t.format_group\t= &snb_uncore_format_group,\n};\n\nstatic struct intel_uncore_type adl_uncore_clockbox = {\n\t.name\t\t= \"clock\",\n\t.num_counters\t= 1,\n\t.num_boxes\t= 1,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= ADL_UNC_FIXED_CTR,\n\t.fixed_ctl\t= ADL_UNC_FIXED_CTR_CTRL,\n\t.single_fixed\t= 1,\n\t.event_mask\t= SNB_UNC_CTL_EV_SEL_MASK,\n\t.format_group\t= &icl_uncore_clock_format_group,\n\t.ops\t\t= &adl_uncore_msr_ops,\n\t.event_descs\t= icl_uncore_events,\n};\n\nstatic struct intel_uncore_type *adl_msr_uncores[] = {\n\t&adl_uncore_cbox,\n\t&adl_uncore_arb,\n\t&adl_uncore_clockbox,\n\tNULL,\n};\n\nvoid adl_uncore_cpu_init(void)\n{\n\tadl_uncore_cbox.num_boxes = icl_get_cbox_num();\n\tuncore_msr_uncores = adl_msr_uncores;\n}\n\nstatic struct intel_uncore_type mtl_uncore_cbox = {\n\t.name\t\t= \"cbox\",\n\t.num_counters   = 2,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= MTL_UNC_CBO_0_PER_CTR0,\n\t.event_ctl\t= MTL_UNC_CBO_0_PERFEVTSEL0,\n\t.event_mask\t= ADL_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= SNB_UNC_CBO_MSR_OFFSET,\n\t.ops\t\t= &icl_uncore_msr_ops,\n\t.format_group\t= &adl_uncore_format_group,\n};\n\nstatic struct intel_uncore_type mtl_uncore_hac_arb = {\n\t.name\t\t= \"hac_arb\",\n\t.num_counters   = 2,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= MTL_UNC_HAC_ARB_CTR,\n\t.event_ctl\t= MTL_UNC_HAC_ARB_CTRL,\n\t.event_mask\t= ADL_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= SNB_UNC_CBO_MSR_OFFSET,\n\t.ops\t\t= &icl_uncore_msr_ops,\n\t.format_group\t= &adl_uncore_format_group,\n};\n\nstatic struct intel_uncore_type mtl_uncore_arb = {\n\t.name\t\t= \"arb\",\n\t.num_counters   = 2,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= MTL_UNC_ARB_CTR,\n\t.event_ctl\t= MTL_UNC_ARB_CTRL,\n\t.event_mask\t= ADL_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= SNB_UNC_CBO_MSR_OFFSET,\n\t.ops\t\t= &icl_uncore_msr_ops,\n\t.format_group\t= &adl_uncore_format_group,\n};\n\nstatic struct intel_uncore_type mtl_uncore_hac_cbox = {\n\t.name\t\t= \"hac_cbox\",\n\t.num_counters   = 2,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 48,\n\t.perf_ctr\t= MTL_UNC_HBO_CTR,\n\t.event_ctl\t= MTL_UNC_HBO_CTRL,\n\t.event_mask\t= ADL_UNC_RAW_EVENT_MASK,\n\t.msr_offset\t= SNB_UNC_CBO_MSR_OFFSET,\n\t.ops\t\t= &icl_uncore_msr_ops,\n\t.format_group\t= &adl_uncore_format_group,\n};\n\nstatic void mtl_uncore_msr_init_box(struct intel_uncore_box *box)\n{\n\twrmsrl(uncore_msr_box_ctl(box), SNB_UNC_GLOBAL_CTL_EN);\n}\n\nstatic struct intel_uncore_ops mtl_uncore_msr_ops = {\n\t.init_box\t= mtl_uncore_msr_init_box,\n\t.disable_event\t= snb_uncore_msr_disable_event,\n\t.enable_event\t= snb_uncore_msr_enable_event,\n\t.read_counter\t= uncore_msr_read_counter,\n};\n\nstatic struct intel_uncore_type mtl_uncore_cncu = {\n\t.name\t\t= \"cncu\",\n\t.num_counters   = 1,\n\t.num_boxes\t= 1,\n\t.box_ctl\t= MTL_UNC_CNCU_BOX_CTL,\n\t.fixed_ctr_bits = 48,\n\t.fixed_ctr\t= MTL_UNC_CNCU_FIXED_CTR,\n\t.fixed_ctl\t= MTL_UNC_CNCU_FIXED_CTRL,\n\t.single_fixed\t= 1,\n\t.event_mask\t= SNB_UNC_CTL_EV_SEL_MASK,\n\t.format_group\t= &icl_uncore_clock_format_group,\n\t.ops\t\t= &mtl_uncore_msr_ops,\n\t.event_descs\t= icl_uncore_events,\n};\n\nstatic struct intel_uncore_type mtl_uncore_sncu = {\n\t.name\t\t= \"sncu\",\n\t.num_counters   = 1,\n\t.num_boxes\t= 1,\n\t.box_ctl\t= MTL_UNC_SNCU_BOX_CTL,\n\t.fixed_ctr_bits\t= 48,\n\t.fixed_ctr\t= MTL_UNC_SNCU_FIXED_CTR,\n\t.fixed_ctl\t= MTL_UNC_SNCU_FIXED_CTRL,\n\t.single_fixed\t= 1,\n\t.event_mask\t= SNB_UNC_CTL_EV_SEL_MASK,\n\t.format_group\t= &icl_uncore_clock_format_group,\n\t.ops\t\t= &mtl_uncore_msr_ops,\n\t.event_descs\t= icl_uncore_events,\n};\n\nstatic struct intel_uncore_type *mtl_msr_uncores[] = {\n\t&mtl_uncore_cbox,\n\t&mtl_uncore_hac_arb,\n\t&mtl_uncore_arb,\n\t&mtl_uncore_hac_cbox,\n\t&mtl_uncore_cncu,\n\t&mtl_uncore_sncu,\n\tNULL\n};\n\nvoid mtl_uncore_cpu_init(void)\n{\n\tmtl_uncore_cbox.num_boxes = icl_get_cbox_num();\n\tuncore_msr_uncores = mtl_msr_uncores;\n}\n\nenum {\n\tSNB_PCI_UNCORE_IMC,\n};\n\nstatic struct uncore_event_desc snb_uncore_imc_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(data_reads,  \"event=0x01\"),\n\tINTEL_UNCORE_EVENT_DESC(data_reads.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(data_reads.unit, \"MiB\"),\n\n\tINTEL_UNCORE_EVENT_DESC(data_writes, \"event=0x02\"),\n\tINTEL_UNCORE_EVENT_DESC(data_writes.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(data_writes.unit, \"MiB\"),\n\n\tINTEL_UNCORE_EVENT_DESC(gt_requests, \"event=0x03\"),\n\tINTEL_UNCORE_EVENT_DESC(gt_requests.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(gt_requests.unit, \"MiB\"),\n\n\tINTEL_UNCORE_EVENT_DESC(ia_requests, \"event=0x04\"),\n\tINTEL_UNCORE_EVENT_DESC(ia_requests.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(ia_requests.unit, \"MiB\"),\n\n\tINTEL_UNCORE_EVENT_DESC(io_requests, \"event=0x05\"),\n\tINTEL_UNCORE_EVENT_DESC(io_requests.scale, \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(io_requests.unit, \"MiB\"),\n\n\t{   },\n};\n\n#define SNB_UNCORE_PCI_IMC_EVENT_MASK\t\t0xff\n#define SNB_UNCORE_PCI_IMC_BAR_OFFSET\t\t0x48\n\n \n#define SNB_UNCORE_PCI_IMC_MAP_SIZE\t\t0x6000\n\n#define SNB_UNCORE_PCI_IMC_DATA_READS\t\t0x1\n#define SNB_UNCORE_PCI_IMC_DATA_READS_BASE\t0x5050\n#define SNB_UNCORE_PCI_IMC_DATA_WRITES\t\t0x2\n#define SNB_UNCORE_PCI_IMC_DATA_WRITES_BASE\t0x5054\n#define SNB_UNCORE_PCI_IMC_CTR_BASE\t\tSNB_UNCORE_PCI_IMC_DATA_READS_BASE\n\n \n#define SNB_UNCORE_PCI_IMC_GT_REQUESTS\t\t0x3\n#define SNB_UNCORE_PCI_IMC_GT_REQUESTS_BASE\t0x5040\n#define SNB_UNCORE_PCI_IMC_IA_REQUESTS\t\t0x4\n#define SNB_UNCORE_PCI_IMC_IA_REQUESTS_BASE\t0x5044\n#define SNB_UNCORE_PCI_IMC_IO_REQUESTS\t\t0x5\n#define SNB_UNCORE_PCI_IMC_IO_REQUESTS_BASE\t0x5048\n\nenum perf_snb_uncore_imc_freerunning_types {\n\tSNB_PCI_UNCORE_IMC_DATA_READS\t\t= 0,\n\tSNB_PCI_UNCORE_IMC_DATA_WRITES,\n\tSNB_PCI_UNCORE_IMC_GT_REQUESTS,\n\tSNB_PCI_UNCORE_IMC_IA_REQUESTS,\n\tSNB_PCI_UNCORE_IMC_IO_REQUESTS,\n\n\tSNB_PCI_UNCORE_IMC_FREERUNNING_TYPE_MAX,\n};\n\nstatic struct freerunning_counters snb_uncore_imc_freerunning[] = {\n\t[SNB_PCI_UNCORE_IMC_DATA_READS]\t\t= { SNB_UNCORE_PCI_IMC_DATA_READS_BASE,\n\t\t\t\t\t\t\t0x0, 0x0, 1, 32 },\n\t[SNB_PCI_UNCORE_IMC_DATA_WRITES]\t= { SNB_UNCORE_PCI_IMC_DATA_WRITES_BASE,\n\t\t\t\t\t\t\t0x0, 0x0, 1, 32 },\n\t[SNB_PCI_UNCORE_IMC_GT_REQUESTS]\t= { SNB_UNCORE_PCI_IMC_GT_REQUESTS_BASE,\n\t\t\t\t\t\t\t0x0, 0x0, 1, 32 },\n\t[SNB_PCI_UNCORE_IMC_IA_REQUESTS]\t= { SNB_UNCORE_PCI_IMC_IA_REQUESTS_BASE,\n\t\t\t\t\t\t\t0x0, 0x0, 1, 32 },\n\t[SNB_PCI_UNCORE_IMC_IO_REQUESTS]\t= { SNB_UNCORE_PCI_IMC_IO_REQUESTS_BASE,\n\t\t\t\t\t\t\t0x0, 0x0, 1, 32 },\n};\n\nstatic struct attribute *snb_uncore_imc_formats_attr[] = {\n\t&format_attr_event.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group snb_uncore_imc_format_group = {\n\t.name = \"format\",\n\t.attrs = snb_uncore_imc_formats_attr,\n};\n\nstatic void snb_uncore_imc_init_box(struct intel_uncore_box *box)\n{\n\tstruct intel_uncore_type *type = box->pmu->type;\n\tstruct pci_dev *pdev = box->pci_dev;\n\tint where = SNB_UNCORE_PCI_IMC_BAR_OFFSET;\n\tresource_size_t addr;\n\tu32 pci_dword;\n\n\tpci_read_config_dword(pdev, where, &pci_dword);\n\taddr = pci_dword;\n\n#ifdef CONFIG_PHYS_ADDR_T_64BIT\n\tpci_read_config_dword(pdev, where + 4, &pci_dword);\n\taddr |= ((resource_size_t)pci_dword << 32);\n#endif\n\n\taddr &= ~(PAGE_SIZE - 1);\n\n\tbox->io_addr = ioremap(addr, type->mmio_map_size);\n\tif (!box->io_addr)\n\t\tpr_warn(\"perf uncore: Failed to ioremap for %s.\\n\", type->name);\n\n\tbox->hrtimer_duration = UNCORE_SNB_IMC_HRTIMER_INTERVAL;\n}\n\nstatic void snb_uncore_imc_enable_box(struct intel_uncore_box *box)\n{}\n\nstatic void snb_uncore_imc_disable_box(struct intel_uncore_box *box)\n{}\n\nstatic void snb_uncore_imc_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{}\n\nstatic void snb_uncore_imc_disable_event(struct intel_uncore_box *box, struct perf_event *event)\n{}\n\n \nstatic int snb_uncore_imc_event_init(struct perf_event *event)\n{\n\tstruct intel_uncore_pmu *pmu;\n\tstruct intel_uncore_box *box;\n\tstruct hw_perf_event *hwc = &event->hw;\n\tu64 cfg = event->attr.config & SNB_UNCORE_PCI_IMC_EVENT_MASK;\n\tint idx, base;\n\n\tif (event->attr.type != event->pmu->type)\n\t\treturn -ENOENT;\n\n\tpmu = uncore_event_to_pmu(event);\n\t \n\tif (pmu->func_id < 0)\n\t\treturn -ENOENT;\n\n\t \n\tif (hwc->sample_period)\n\t\treturn -EINVAL;\n\n\t \n\tif (event->attr.sample_period)  \n\t\treturn -EINVAL;\n\n\t \n\tif (event->cpu < 0)\n\t\treturn -EINVAL;\n\n\t \n\tif (event->attr.config & ~SNB_UNCORE_PCI_IMC_EVENT_MASK)\n\t\treturn -EINVAL;\n\n\tbox = uncore_pmu_to_box(pmu, event->cpu);\n\tif (!box || box->cpu < 0)\n\t\treturn -EINVAL;\n\n\tevent->cpu = box->cpu;\n\tevent->pmu_private = box;\n\n\tevent->event_caps |= PERF_EV_CAP_READ_ACTIVE_PKG;\n\n\tevent->hw.idx = -1;\n\tevent->hw.last_tag = ~0ULL;\n\tevent->hw.extra_reg.idx = EXTRA_REG_NONE;\n\tevent->hw.branch_reg.idx = EXTRA_REG_NONE;\n\t \n\tswitch (cfg) {\n\tcase SNB_UNCORE_PCI_IMC_DATA_READS:\n\t\tbase = SNB_UNCORE_PCI_IMC_DATA_READS_BASE;\n\t\tidx = UNCORE_PMC_IDX_FREERUNNING;\n\t\tbreak;\n\tcase SNB_UNCORE_PCI_IMC_DATA_WRITES:\n\t\tbase = SNB_UNCORE_PCI_IMC_DATA_WRITES_BASE;\n\t\tidx = UNCORE_PMC_IDX_FREERUNNING;\n\t\tbreak;\n\tcase SNB_UNCORE_PCI_IMC_GT_REQUESTS:\n\t\tbase = SNB_UNCORE_PCI_IMC_GT_REQUESTS_BASE;\n\t\tidx = UNCORE_PMC_IDX_FREERUNNING;\n\t\tbreak;\n\tcase SNB_UNCORE_PCI_IMC_IA_REQUESTS:\n\t\tbase = SNB_UNCORE_PCI_IMC_IA_REQUESTS_BASE;\n\t\tidx = UNCORE_PMC_IDX_FREERUNNING;\n\t\tbreak;\n\tcase SNB_UNCORE_PCI_IMC_IO_REQUESTS:\n\t\tbase = SNB_UNCORE_PCI_IMC_IO_REQUESTS_BASE;\n\t\tidx = UNCORE_PMC_IDX_FREERUNNING;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tevent->hw.event_base = base;\n\tevent->hw.idx = idx;\n\n\t \n\tevent->hw.config = ((cfg - 1) << 8) | 0x10ff;\n\n\t \n\n\treturn 0;\n}\n\nstatic int snb_uncore_imc_hw_config(struct intel_uncore_box *box, struct perf_event *event)\n{\n\treturn 0;\n}\n\nint snb_pci2phy_map_init(int devid)\n{\n\tstruct pci_dev *dev = NULL;\n\tstruct pci2phy_map *map;\n\tint bus, segment;\n\n\tdev = pci_get_device(PCI_VENDOR_ID_INTEL, devid, dev);\n\tif (!dev)\n\t\treturn -ENOTTY;\n\n\tbus = dev->bus->number;\n\tsegment = pci_domain_nr(dev->bus);\n\n\traw_spin_lock(&pci2phy_map_lock);\n\tmap = __find_pci2phy_map(segment);\n\tif (!map) {\n\t\traw_spin_unlock(&pci2phy_map_lock);\n\t\tpci_dev_put(dev);\n\t\treturn -ENOMEM;\n\t}\n\tmap->pbus_to_dieid[bus] = 0;\n\traw_spin_unlock(&pci2phy_map_lock);\n\n\tpci_dev_put(dev);\n\n\treturn 0;\n}\n\nstatic u64 snb_uncore_imc_read_counter(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\t \n\treturn (u64)readl(box->io_addr + hwc->event_base);\n}\n\nstatic struct pmu snb_uncore_imc_pmu = {\n\t.task_ctx_nr\t= perf_invalid_context,\n\t.event_init\t= snb_uncore_imc_event_init,\n\t.add\t\t= uncore_pmu_event_add,\n\t.del\t\t= uncore_pmu_event_del,\n\t.start\t\t= uncore_pmu_event_start,\n\t.stop\t\t= uncore_pmu_event_stop,\n\t.read\t\t= uncore_pmu_event_read,\n\t.capabilities\t= PERF_PMU_CAP_NO_EXCLUDE,\n};\n\nstatic struct intel_uncore_ops snb_uncore_imc_ops = {\n\t.init_box\t= snb_uncore_imc_init_box,\n\t.exit_box\t= uncore_mmio_exit_box,\n\t.enable_box\t= snb_uncore_imc_enable_box,\n\t.disable_box\t= snb_uncore_imc_disable_box,\n\t.disable_event\t= snb_uncore_imc_disable_event,\n\t.enable_event\t= snb_uncore_imc_enable_event,\n\t.hw_config\t= snb_uncore_imc_hw_config,\n\t.read_counter\t= snb_uncore_imc_read_counter,\n};\n\nstatic struct intel_uncore_type snb_uncore_imc = {\n\t.name\t\t= \"imc\",\n\t.num_counters   = 5,\n\t.num_boxes\t= 1,\n\t.num_freerunning_types\t= SNB_PCI_UNCORE_IMC_FREERUNNING_TYPE_MAX,\n\t.mmio_map_size\t= SNB_UNCORE_PCI_IMC_MAP_SIZE,\n\t.freerunning\t= snb_uncore_imc_freerunning,\n\t.event_descs\t= snb_uncore_imc_events,\n\t.format_group\t= &snb_uncore_imc_format_group,\n\t.ops\t\t= &snb_uncore_imc_ops,\n\t.pmu\t\t= &snb_uncore_imc_pmu,\n};\n\nstatic struct intel_uncore_type *snb_pci_uncores[] = {\n\t[SNB_PCI_UNCORE_IMC]\t= &snb_uncore_imc,\n\tNULL,\n};\n\nstatic const struct pci_device_id snb_uncore_pci_ids[] = {\n\tIMC_UNCORE_DEV(SNB),\n\t{   },\n};\n\nstatic const struct pci_device_id ivb_uncore_pci_ids[] = {\n\tIMC_UNCORE_DEV(IVB),\n\tIMC_UNCORE_DEV(IVB_E3),\n\t{   },\n};\n\nstatic const struct pci_device_id hsw_uncore_pci_ids[] = {\n\tIMC_UNCORE_DEV(HSW),\n\tIMC_UNCORE_DEV(HSW_U),\n\t{   },\n};\n\nstatic const struct pci_device_id bdw_uncore_pci_ids[] = {\n\tIMC_UNCORE_DEV(BDW),\n\t{   },\n};\n\nstatic const struct pci_device_id skl_uncore_pci_ids[] = {\n\tIMC_UNCORE_DEV(SKL_Y),\n\tIMC_UNCORE_DEV(SKL_U),\n\tIMC_UNCORE_DEV(SKL_HD),\n\tIMC_UNCORE_DEV(SKL_HQ),\n\tIMC_UNCORE_DEV(SKL_SD),\n\tIMC_UNCORE_DEV(SKL_SQ),\n\tIMC_UNCORE_DEV(SKL_E3),\n\tIMC_UNCORE_DEV(KBL_Y),\n\tIMC_UNCORE_DEV(KBL_U),\n\tIMC_UNCORE_DEV(KBL_UQ),\n\tIMC_UNCORE_DEV(KBL_SD),\n\tIMC_UNCORE_DEV(KBL_SQ),\n\tIMC_UNCORE_DEV(KBL_HQ),\n\tIMC_UNCORE_DEV(KBL_WQ),\n\tIMC_UNCORE_DEV(CFL_2U),\n\tIMC_UNCORE_DEV(CFL_4U),\n\tIMC_UNCORE_DEV(CFL_4H),\n\tIMC_UNCORE_DEV(CFL_6H),\n\tIMC_UNCORE_DEV(CFL_2S_D),\n\tIMC_UNCORE_DEV(CFL_4S_D),\n\tIMC_UNCORE_DEV(CFL_6S_D),\n\tIMC_UNCORE_DEV(CFL_8S_D),\n\tIMC_UNCORE_DEV(CFL_4S_W),\n\tIMC_UNCORE_DEV(CFL_6S_W),\n\tIMC_UNCORE_DEV(CFL_8S_W),\n\tIMC_UNCORE_DEV(CFL_4S_S),\n\tIMC_UNCORE_DEV(CFL_6S_S),\n\tIMC_UNCORE_DEV(CFL_8S_S),\n\tIMC_UNCORE_DEV(AML_YD),\n\tIMC_UNCORE_DEV(AML_YQ),\n\tIMC_UNCORE_DEV(WHL_UQ),\n\tIMC_UNCORE_DEV(WHL_4_UQ),\n\tIMC_UNCORE_DEV(WHL_UD),\n\tIMC_UNCORE_DEV(CML_H1),\n\tIMC_UNCORE_DEV(CML_H2),\n\tIMC_UNCORE_DEV(CML_H3),\n\tIMC_UNCORE_DEV(CML_U1),\n\tIMC_UNCORE_DEV(CML_U2),\n\tIMC_UNCORE_DEV(CML_U3),\n\tIMC_UNCORE_DEV(CML_S1),\n\tIMC_UNCORE_DEV(CML_S2),\n\tIMC_UNCORE_DEV(CML_S3),\n\tIMC_UNCORE_DEV(CML_S4),\n\tIMC_UNCORE_DEV(CML_S5),\n\t{   },\n};\n\nstatic const struct pci_device_id icl_uncore_pci_ids[] = {\n\tIMC_UNCORE_DEV(ICL_U),\n\tIMC_UNCORE_DEV(ICL_U2),\n\tIMC_UNCORE_DEV(RKL_1),\n\tIMC_UNCORE_DEV(RKL_2),\n\t{   },\n};\n\nstatic struct pci_driver snb_uncore_pci_driver = {\n\t.name\t\t= \"snb_uncore\",\n\t.id_table\t= snb_uncore_pci_ids,\n};\n\nstatic struct pci_driver ivb_uncore_pci_driver = {\n\t.name\t\t= \"ivb_uncore\",\n\t.id_table\t= ivb_uncore_pci_ids,\n};\n\nstatic struct pci_driver hsw_uncore_pci_driver = {\n\t.name\t\t= \"hsw_uncore\",\n\t.id_table\t= hsw_uncore_pci_ids,\n};\n\nstatic struct pci_driver bdw_uncore_pci_driver = {\n\t.name\t\t= \"bdw_uncore\",\n\t.id_table\t= bdw_uncore_pci_ids,\n};\n\nstatic struct pci_driver skl_uncore_pci_driver = {\n\t.name\t\t= \"skl_uncore\",\n\t.id_table\t= skl_uncore_pci_ids,\n};\n\nstatic struct pci_driver icl_uncore_pci_driver = {\n\t.name\t\t= \"icl_uncore\",\n\t.id_table\t= icl_uncore_pci_ids,\n};\n\nstruct imc_uncore_pci_dev {\n\t__u32 pci_id;\n\tstruct pci_driver *driver;\n};\n#define IMC_DEV(a, d) \\\n\t{ .pci_id = PCI_DEVICE_ID_INTEL_##a, .driver = (d) }\n\nstatic const struct imc_uncore_pci_dev desktop_imc_pci_ids[] = {\n\tIMC_DEV(SNB_IMC, &snb_uncore_pci_driver),\n\tIMC_DEV(IVB_IMC, &ivb_uncore_pci_driver),     \n\tIMC_DEV(IVB_E3_IMC, &ivb_uncore_pci_driver),  \n\tIMC_DEV(HSW_IMC, &hsw_uncore_pci_driver),     \n\tIMC_DEV(HSW_U_IMC, &hsw_uncore_pci_driver),   \n\tIMC_DEV(BDW_IMC, &bdw_uncore_pci_driver),     \n\tIMC_DEV(SKL_Y_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(SKL_U_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(SKL_HD_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(SKL_HQ_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(SKL_SD_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(SKL_SQ_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(SKL_E3_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(KBL_Y_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(KBL_U_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(KBL_UQ_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(KBL_SD_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(KBL_SQ_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(KBL_HQ_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(KBL_WQ_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_2U_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_4U_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_4H_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_6H_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_2S_D_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_4S_D_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_6S_D_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_8S_D_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_4S_W_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_6S_W_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_8S_W_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_4S_S_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_6S_S_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(CFL_8S_S_IMC, &skl_uncore_pci_driver),   \n\tIMC_DEV(AML_YD_IMC, &skl_uncore_pci_driver),\t \n\tIMC_DEV(AML_YQ_IMC, &skl_uncore_pci_driver),\t \n\tIMC_DEV(WHL_UQ_IMC, &skl_uncore_pci_driver),\t \n\tIMC_DEV(WHL_4_UQ_IMC, &skl_uncore_pci_driver),\t \n\tIMC_DEV(WHL_UD_IMC, &skl_uncore_pci_driver),\t \n\tIMC_DEV(CML_H1_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_H2_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_H3_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_U1_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_U2_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_U3_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_S1_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_S2_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_S3_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_S4_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(CML_S5_IMC, &skl_uncore_pci_driver),\n\tIMC_DEV(ICL_U_IMC, &icl_uncore_pci_driver),\t \n\tIMC_DEV(ICL_U2_IMC, &icl_uncore_pci_driver),\t \n\tIMC_DEV(RKL_1_IMC, &icl_uncore_pci_driver),\n\tIMC_DEV(RKL_2_IMC, &icl_uncore_pci_driver),\n\t{    }\n};\n\n\n#define for_each_imc_pci_id(x, t) \\\n\tfor (x = (t); (x)->pci_id; x++)\n\nstatic struct pci_driver *imc_uncore_find_dev(void)\n{\n\tconst struct imc_uncore_pci_dev *p;\n\tint ret;\n\n\tfor_each_imc_pci_id(p, desktop_imc_pci_ids) {\n\t\tret = snb_pci2phy_map_init(p->pci_id);\n\t\tif (ret == 0)\n\t\t\treturn p->driver;\n\t}\n\treturn NULL;\n}\n\nstatic int imc_uncore_pci_init(void)\n{\n\tstruct pci_driver *imc_drv = imc_uncore_find_dev();\n\n\tif (!imc_drv)\n\t\treturn -ENODEV;\n\n\tuncore_pci_uncores = snb_pci_uncores;\n\tuncore_pci_driver = imc_drv;\n\n\treturn 0;\n}\n\nint snb_uncore_pci_init(void)\n{\n\treturn imc_uncore_pci_init();\n}\n\nint ivb_uncore_pci_init(void)\n{\n\treturn imc_uncore_pci_init();\n}\nint hsw_uncore_pci_init(void)\n{\n\treturn imc_uncore_pci_init();\n}\n\nint bdw_uncore_pci_init(void)\n{\n\treturn imc_uncore_pci_init();\n}\n\nint skl_uncore_pci_init(void)\n{\n\treturn imc_uncore_pci_init();\n}\n\n \n\n \nstatic void nhm_uncore_msr_disable_box(struct intel_uncore_box *box)\n{\n\twrmsrl(NHM_UNC_PERF_GLOBAL_CTL, 0);\n}\n\nstatic void nhm_uncore_msr_enable_box(struct intel_uncore_box *box)\n{\n\twrmsrl(NHM_UNC_PERF_GLOBAL_CTL, NHM_UNC_GLOBAL_CTL_EN_PC_ALL | NHM_UNC_GLOBAL_CTL_EN_FC);\n}\n\nstatic void nhm_uncore_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (hwc->idx < UNCORE_PMC_IDX_FIXED)\n\t\twrmsrl(hwc->config_base, hwc->config | SNB_UNC_CTL_EN);\n\telse\n\t\twrmsrl(hwc->config_base, NHM_UNC_FIXED_CTR_CTL_EN);\n}\n\nstatic struct attribute *nhm_uncore_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\t&format_attr_edge.attr,\n\t&format_attr_inv.attr,\n\t&format_attr_cmask8.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group nhm_uncore_format_group = {\n\t.name = \"format\",\n\t.attrs = nhm_uncore_formats_attr,\n};\n\nstatic struct uncore_event_desc nhm_uncore_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(clockticks,                \"event=0xff,umask=0x00\"),\n\tINTEL_UNCORE_EVENT_DESC(qmc_writes_full_any,       \"event=0x2f,umask=0x0f\"),\n\tINTEL_UNCORE_EVENT_DESC(qmc_normal_reads_any,      \"event=0x2c,umask=0x0f\"),\n\tINTEL_UNCORE_EVENT_DESC(qhl_request_ioh_reads,     \"event=0x20,umask=0x01\"),\n\tINTEL_UNCORE_EVENT_DESC(qhl_request_ioh_writes,    \"event=0x20,umask=0x02\"),\n\tINTEL_UNCORE_EVENT_DESC(qhl_request_remote_reads,  \"event=0x20,umask=0x04\"),\n\tINTEL_UNCORE_EVENT_DESC(qhl_request_remote_writes, \"event=0x20,umask=0x08\"),\n\tINTEL_UNCORE_EVENT_DESC(qhl_request_local_reads,   \"event=0x20,umask=0x10\"),\n\tINTEL_UNCORE_EVENT_DESC(qhl_request_local_writes,  \"event=0x20,umask=0x20\"),\n\t{   },\n};\n\nstatic struct intel_uncore_ops nhm_uncore_msr_ops = {\n\t.disable_box\t= nhm_uncore_msr_disable_box,\n\t.enable_box\t= nhm_uncore_msr_enable_box,\n\t.disable_event\t= snb_uncore_msr_disable_event,\n\t.enable_event\t= nhm_uncore_msr_enable_event,\n\t.read_counter\t= uncore_msr_read_counter,\n};\n\nstatic struct intel_uncore_type nhm_uncore = {\n\t.name\t\t= \"\",\n\t.num_counters   = 8,\n\t.num_boxes\t= 1,\n\t.perf_ctr_bits\t= 48,\n\t.fixed_ctr_bits\t= 48,\n\t.event_ctl\t= NHM_UNC_PERFEVTSEL0,\n\t.perf_ctr\t= NHM_UNC_UNCORE_PMC0,\n\t.fixed_ctr\t= NHM_UNC_FIXED_CTR,\n\t.fixed_ctl\t= NHM_UNC_FIXED_CTR_CTRL,\n\t.event_mask\t= NHM_UNC_RAW_EVENT_MASK,\n\t.event_descs\t= nhm_uncore_events,\n\t.ops\t\t= &nhm_uncore_msr_ops,\n\t.format_group\t= &nhm_uncore_format_group,\n};\n\nstatic struct intel_uncore_type *nhm_msr_uncores[] = {\n\t&nhm_uncore,\n\tNULL,\n};\n\nvoid nhm_uncore_cpu_init(void)\n{\n\tuncore_msr_uncores = nhm_msr_uncores;\n}\n\n \n\n \n\nstatic const struct pci_device_id tgl_uncore_pci_ids[] = {\n\tIMC_UNCORE_DEV(TGL_U1),\n\tIMC_UNCORE_DEV(TGL_U2),\n\tIMC_UNCORE_DEV(TGL_U3),\n\tIMC_UNCORE_DEV(TGL_U4),\n\tIMC_UNCORE_DEV(TGL_H),\n\tIMC_UNCORE_DEV(ADL_1),\n\tIMC_UNCORE_DEV(ADL_2),\n\tIMC_UNCORE_DEV(ADL_3),\n\tIMC_UNCORE_DEV(ADL_4),\n\tIMC_UNCORE_DEV(ADL_5),\n\tIMC_UNCORE_DEV(ADL_6),\n\tIMC_UNCORE_DEV(ADL_7),\n\tIMC_UNCORE_DEV(ADL_8),\n\tIMC_UNCORE_DEV(ADL_9),\n\tIMC_UNCORE_DEV(ADL_10),\n\tIMC_UNCORE_DEV(ADL_11),\n\tIMC_UNCORE_DEV(ADL_12),\n\tIMC_UNCORE_DEV(ADL_13),\n\tIMC_UNCORE_DEV(ADL_14),\n\tIMC_UNCORE_DEV(ADL_15),\n\tIMC_UNCORE_DEV(ADL_16),\n\tIMC_UNCORE_DEV(ADL_17),\n\tIMC_UNCORE_DEV(ADL_18),\n\tIMC_UNCORE_DEV(ADL_19),\n\tIMC_UNCORE_DEV(ADL_20),\n\tIMC_UNCORE_DEV(ADL_21),\n\tIMC_UNCORE_DEV(RPL_1),\n\tIMC_UNCORE_DEV(RPL_2),\n\tIMC_UNCORE_DEV(RPL_3),\n\tIMC_UNCORE_DEV(RPL_4),\n\tIMC_UNCORE_DEV(RPL_5),\n\tIMC_UNCORE_DEV(RPL_6),\n\tIMC_UNCORE_DEV(RPL_7),\n\tIMC_UNCORE_DEV(RPL_8),\n\tIMC_UNCORE_DEV(RPL_9),\n\tIMC_UNCORE_DEV(RPL_10),\n\tIMC_UNCORE_DEV(RPL_11),\n\tIMC_UNCORE_DEV(RPL_12),\n\tIMC_UNCORE_DEV(RPL_13),\n\tIMC_UNCORE_DEV(RPL_14),\n\tIMC_UNCORE_DEV(RPL_15),\n\tIMC_UNCORE_DEV(RPL_16),\n\tIMC_UNCORE_DEV(RPL_17),\n\tIMC_UNCORE_DEV(RPL_18),\n\tIMC_UNCORE_DEV(RPL_19),\n\tIMC_UNCORE_DEV(RPL_20),\n\tIMC_UNCORE_DEV(RPL_21),\n\tIMC_UNCORE_DEV(RPL_22),\n\tIMC_UNCORE_DEV(RPL_23),\n\tIMC_UNCORE_DEV(RPL_24),\n\tIMC_UNCORE_DEV(RPL_25),\n\tIMC_UNCORE_DEV(MTL_1),\n\tIMC_UNCORE_DEV(MTL_2),\n\tIMC_UNCORE_DEV(MTL_3),\n\tIMC_UNCORE_DEV(MTL_4),\n\tIMC_UNCORE_DEV(MTL_5),\n\tIMC_UNCORE_DEV(MTL_6),\n\tIMC_UNCORE_DEV(MTL_7),\n\tIMC_UNCORE_DEV(MTL_8),\n\tIMC_UNCORE_DEV(MTL_9),\n\tIMC_UNCORE_DEV(MTL_10),\n\tIMC_UNCORE_DEV(MTL_11),\n\tIMC_UNCORE_DEV(MTL_12),\n\tIMC_UNCORE_DEV(MTL_13),\n\t{   }\n};\n\nenum perf_tgl_uncore_imc_freerunning_types {\n\tTGL_MMIO_UNCORE_IMC_DATA_TOTAL,\n\tTGL_MMIO_UNCORE_IMC_DATA_READ,\n\tTGL_MMIO_UNCORE_IMC_DATA_WRITE,\n\tTGL_MMIO_UNCORE_IMC_FREERUNNING_TYPE_MAX\n};\n\nstatic struct freerunning_counters tgl_l_uncore_imc_freerunning[] = {\n\t[TGL_MMIO_UNCORE_IMC_DATA_TOTAL]\t= { 0x5040, 0x0, 0x0, 1, 64 },\n\t[TGL_MMIO_UNCORE_IMC_DATA_READ]\t\t= { 0x5058, 0x0, 0x0, 1, 64 },\n\t[TGL_MMIO_UNCORE_IMC_DATA_WRITE]\t= { 0x50A0, 0x0, 0x0, 1, 64 },\n};\n\nstatic struct freerunning_counters tgl_uncore_imc_freerunning[] = {\n\t[TGL_MMIO_UNCORE_IMC_DATA_TOTAL]\t= { 0xd840, 0x0, 0x0, 1, 64 },\n\t[TGL_MMIO_UNCORE_IMC_DATA_READ]\t\t= { 0xd858, 0x0, 0x0, 1, 64 },\n\t[TGL_MMIO_UNCORE_IMC_DATA_WRITE]\t= { 0xd8A0, 0x0, 0x0, 1, 64 },\n};\n\nstatic struct uncore_event_desc tgl_uncore_imc_events[] = {\n\tINTEL_UNCORE_EVENT_DESC(data_total,         \"event=0xff,umask=0x10\"),\n\tINTEL_UNCORE_EVENT_DESC(data_total.scale,   \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(data_total.unit,    \"MiB\"),\n\n\tINTEL_UNCORE_EVENT_DESC(data_read,         \"event=0xff,umask=0x20\"),\n\tINTEL_UNCORE_EVENT_DESC(data_read.scale,   \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(data_read.unit,    \"MiB\"),\n\n\tINTEL_UNCORE_EVENT_DESC(data_write,        \"event=0xff,umask=0x30\"),\n\tINTEL_UNCORE_EVENT_DESC(data_write.scale,  \"6.103515625e-5\"),\n\tINTEL_UNCORE_EVENT_DESC(data_write.unit,   \"MiB\"),\n\n\t{   }\n};\n\nstatic struct pci_dev *tgl_uncore_get_mc_dev(void)\n{\n\tconst struct pci_device_id *ids = tgl_uncore_pci_ids;\n\tstruct pci_dev *mc_dev = NULL;\n\n\twhile (ids && ids->vendor) {\n\t\tmc_dev = pci_get_device(PCI_VENDOR_ID_INTEL, ids->device, NULL);\n\t\tif (mc_dev)\n\t\t\treturn mc_dev;\n\t\tids++;\n\t}\n\n\treturn mc_dev;\n}\n\n#define TGL_UNCORE_MMIO_IMC_MEM_OFFSET\t\t0x10000\n#define TGL_UNCORE_PCI_IMC_MAP_SIZE\t\t0xe000\n\nstatic void __uncore_imc_init_box(struct intel_uncore_box *box,\n\t\t\t\t  unsigned int base_offset)\n{\n\tstruct pci_dev *pdev = tgl_uncore_get_mc_dev();\n\tstruct intel_uncore_pmu *pmu = box->pmu;\n\tstruct intel_uncore_type *type = pmu->type;\n\tresource_size_t addr;\n\tu32 mch_bar;\n\n\tif (!pdev) {\n\t\tpr_warn(\"perf uncore: Cannot find matched IMC device.\\n\");\n\t\treturn;\n\t}\n\n\tpci_read_config_dword(pdev, SNB_UNCORE_PCI_IMC_BAR_OFFSET, &mch_bar);\n\t \n\tif (!(mch_bar & BIT(0))) {\n\t\tpr_warn(\"perf uncore: MCHBAR is disabled. Failed to map IMC free-running counters.\\n\");\n\t\tpci_dev_put(pdev);\n\t\treturn;\n\t}\n\tmch_bar &= ~BIT(0);\n\taddr = (resource_size_t)(mch_bar + TGL_UNCORE_MMIO_IMC_MEM_OFFSET * pmu->pmu_idx);\n\n#ifdef CONFIG_PHYS_ADDR_T_64BIT\n\tpci_read_config_dword(pdev, SNB_UNCORE_PCI_IMC_BAR_OFFSET + 4, &mch_bar);\n\taddr |= ((resource_size_t)mch_bar << 32);\n#endif\n\n\taddr += base_offset;\n\tbox->io_addr = ioremap(addr, type->mmio_map_size);\n\tif (!box->io_addr)\n\t\tpr_warn(\"perf uncore: Failed to ioremap for %s.\\n\", type->name);\n\n\tpci_dev_put(pdev);\n}\n\nstatic void tgl_uncore_imc_freerunning_init_box(struct intel_uncore_box *box)\n{\n\t__uncore_imc_init_box(box, 0);\n}\n\nstatic struct intel_uncore_ops tgl_uncore_imc_freerunning_ops = {\n\t.init_box\t= tgl_uncore_imc_freerunning_init_box,\n\t.exit_box\t= uncore_mmio_exit_box,\n\t.read_counter\t= uncore_mmio_read_counter,\n\t.hw_config\t= uncore_freerunning_hw_config,\n};\n\nstatic struct attribute *tgl_uncore_imc_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_umask.attr,\n\tNULL\n};\n\nstatic const struct attribute_group tgl_uncore_imc_format_group = {\n\t.name = \"format\",\n\t.attrs = tgl_uncore_imc_formats_attr,\n};\n\nstatic struct intel_uncore_type tgl_uncore_imc_free_running = {\n\t.name\t\t\t= \"imc_free_running\",\n\t.num_counters\t\t= 3,\n\t.num_boxes\t\t= 2,\n\t.num_freerunning_types\t= TGL_MMIO_UNCORE_IMC_FREERUNNING_TYPE_MAX,\n\t.mmio_map_size\t\t= TGL_UNCORE_PCI_IMC_MAP_SIZE,\n\t.freerunning\t\t= tgl_uncore_imc_freerunning,\n\t.ops\t\t\t= &tgl_uncore_imc_freerunning_ops,\n\t.event_descs\t\t= tgl_uncore_imc_events,\n\t.format_group\t\t= &tgl_uncore_imc_format_group,\n};\n\nstatic struct intel_uncore_type *tgl_mmio_uncores[] = {\n\t&tgl_uncore_imc_free_running,\n\tNULL\n};\n\nvoid tgl_l_uncore_mmio_init(void)\n{\n\ttgl_uncore_imc_free_running.freerunning = tgl_l_uncore_imc_freerunning;\n\tuncore_mmio_uncores = tgl_mmio_uncores;\n}\n\nvoid tgl_uncore_mmio_init(void)\n{\n\tuncore_mmio_uncores = tgl_mmio_uncores;\n}\n\n \n\n \n#define ADL_UNCORE_IMC_BASE\t\t\t0xd900\n#define ADL_UNCORE_IMC_MAP_SIZE\t\t\t0x200\n#define ADL_UNCORE_IMC_CTR\t\t\t0xe8\n#define ADL_UNCORE_IMC_CTRL\t\t\t0xd0\n#define ADL_UNCORE_IMC_GLOBAL_CTL\t\t0xc0\n#define ADL_UNCORE_IMC_BOX_CTL\t\t\t0xc4\n#define ADL_UNCORE_IMC_FREERUNNING_BASE\t\t0xd800\n#define ADL_UNCORE_IMC_FREERUNNING_MAP_SIZE\t0x100\n\n#define ADL_UNCORE_IMC_CTL_FRZ\t\t\t(1 << 0)\n#define ADL_UNCORE_IMC_CTL_RST_CTRL\t\t(1 << 1)\n#define ADL_UNCORE_IMC_CTL_RST_CTRS\t\t(1 << 2)\n#define ADL_UNCORE_IMC_CTL_INT\t\t\t(ADL_UNCORE_IMC_CTL_RST_CTRL | \\\n\t\t\t\t\t\tADL_UNCORE_IMC_CTL_RST_CTRS)\n\nstatic void adl_uncore_imc_init_box(struct intel_uncore_box *box)\n{\n\t__uncore_imc_init_box(box, ADL_UNCORE_IMC_BASE);\n\n\t \n\tif (box->io_addr && (box->pmu->pmu_idx == 1))\n\t\twritel(ADL_UNCORE_IMC_CTL_INT, box->io_addr + ADL_UNCORE_IMC_GLOBAL_CTL);\n}\n\nstatic void adl_uncore_mmio_disable_box(struct intel_uncore_box *box)\n{\n\tif (!box->io_addr)\n\t\treturn;\n\n\twritel(ADL_UNCORE_IMC_CTL_FRZ, box->io_addr + uncore_mmio_box_ctl(box));\n}\n\nstatic void adl_uncore_mmio_enable_box(struct intel_uncore_box *box)\n{\n\tif (!box->io_addr)\n\t\treturn;\n\n\twritel(0, box->io_addr + uncore_mmio_box_ctl(box));\n}\n\nstatic struct intel_uncore_ops adl_uncore_mmio_ops = {\n\t.init_box\t= adl_uncore_imc_init_box,\n\t.exit_box\t= uncore_mmio_exit_box,\n\t.disable_box\t= adl_uncore_mmio_disable_box,\n\t.enable_box\t= adl_uncore_mmio_enable_box,\n\t.disable_event\t= intel_generic_uncore_mmio_disable_event,\n\t.enable_event\t= intel_generic_uncore_mmio_enable_event,\n\t.read_counter\t= uncore_mmio_read_counter,\n};\n\n#define ADL_UNC_CTL_CHMASK_MASK\t\t\t0x00000f00\n#define ADL_UNC_IMC_EVENT_MASK\t\t\t(SNB_UNC_CTL_EV_SEL_MASK | \\\n\t\t\t\t\t\t ADL_UNC_CTL_CHMASK_MASK | \\\n\t\t\t\t\t\t SNB_UNC_CTL_EDGE_DET)\n\nstatic struct attribute *adl_uncore_imc_formats_attr[] = {\n\t&format_attr_event.attr,\n\t&format_attr_chmask.attr,\n\t&format_attr_edge.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group adl_uncore_imc_format_group = {\n\t.name\t\t= \"format\",\n\t.attrs\t\t= adl_uncore_imc_formats_attr,\n};\n\nstatic struct intel_uncore_type adl_uncore_imc = {\n\t.name\t\t= \"imc\",\n\t.num_counters   = 5,\n\t.num_boxes\t= 2,\n\t.perf_ctr_bits\t= 64,\n\t.perf_ctr\t= ADL_UNCORE_IMC_CTR,\n\t.event_ctl\t= ADL_UNCORE_IMC_CTRL,\n\t.event_mask\t= ADL_UNC_IMC_EVENT_MASK,\n\t.box_ctl\t= ADL_UNCORE_IMC_BOX_CTL,\n\t.mmio_offset\t= 0,\n\t.mmio_map_size\t= ADL_UNCORE_IMC_MAP_SIZE,\n\t.ops\t\t= &adl_uncore_mmio_ops,\n\t.format_group\t= &adl_uncore_imc_format_group,\n};\n\nenum perf_adl_uncore_imc_freerunning_types {\n\tADL_MMIO_UNCORE_IMC_DATA_TOTAL,\n\tADL_MMIO_UNCORE_IMC_DATA_READ,\n\tADL_MMIO_UNCORE_IMC_DATA_WRITE,\n\tADL_MMIO_UNCORE_IMC_FREERUNNING_TYPE_MAX\n};\n\nstatic struct freerunning_counters adl_uncore_imc_freerunning[] = {\n\t[ADL_MMIO_UNCORE_IMC_DATA_TOTAL]\t= { 0x40, 0x0, 0x0, 1, 64 },\n\t[ADL_MMIO_UNCORE_IMC_DATA_READ]\t\t= { 0x58, 0x0, 0x0, 1, 64 },\n\t[ADL_MMIO_UNCORE_IMC_DATA_WRITE]\t= { 0xA0, 0x0, 0x0, 1, 64 },\n};\n\nstatic void adl_uncore_imc_freerunning_init_box(struct intel_uncore_box *box)\n{\n\t__uncore_imc_init_box(box, ADL_UNCORE_IMC_FREERUNNING_BASE);\n}\n\nstatic struct intel_uncore_ops adl_uncore_imc_freerunning_ops = {\n\t.init_box\t= adl_uncore_imc_freerunning_init_box,\n\t.exit_box\t= uncore_mmio_exit_box,\n\t.read_counter\t= uncore_mmio_read_counter,\n\t.hw_config\t= uncore_freerunning_hw_config,\n};\n\nstatic struct intel_uncore_type adl_uncore_imc_free_running = {\n\t.name\t\t\t= \"imc_free_running\",\n\t.num_counters\t\t= 3,\n\t.num_boxes\t\t= 2,\n\t.num_freerunning_types\t= ADL_MMIO_UNCORE_IMC_FREERUNNING_TYPE_MAX,\n\t.mmio_map_size\t\t= ADL_UNCORE_IMC_FREERUNNING_MAP_SIZE,\n\t.freerunning\t\t= adl_uncore_imc_freerunning,\n\t.ops\t\t\t= &adl_uncore_imc_freerunning_ops,\n\t.event_descs\t\t= tgl_uncore_imc_events,\n\t.format_group\t\t= &tgl_uncore_imc_format_group,\n};\n\nstatic struct intel_uncore_type *adl_mmio_uncores[] = {\n\t&adl_uncore_imc,\n\t&adl_uncore_imc_free_running,\n\tNULL\n};\n\nvoid adl_uncore_mmio_init(void)\n{\n\tuncore_mmio_uncores = adl_mmio_uncores;\n}\n\n \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}