{
  "module_name": "bts.c",
  "hash_id": "9049d7f042f3990235628e024ef76b4d810fb63df7592726dfa6833209015419",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/events/intel/bts.c",
  "human_readable_source": "\n \n\n#undef DEBUG\n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/bitops.h>\n#include <linux/types.h>\n#include <linux/slab.h>\n#include <linux/debugfs.h>\n#include <linux/device.h>\n#include <linux/coredump.h>\n\n#include <linux/sizes.h>\n#include <asm/perf_event.h>\n\n#include \"../perf_event.h\"\n\nstruct bts_ctx {\n\tstruct perf_output_handle\thandle;\n\tstruct debug_store\t\tds_back;\n\tint\t\t\t\tstate;\n};\n\n \nenum {\n\t \n\tBTS_STATE_STOPPED = 0,\n\t \n\tBTS_STATE_INACTIVE,\n\t \n\tBTS_STATE_ACTIVE,\n};\n\nstatic DEFINE_PER_CPU(struct bts_ctx, bts_ctx);\n\n#define BTS_RECORD_SIZE\t\t24\n#define BTS_SAFETY_MARGIN\t4080\n\nstruct bts_phys {\n\tstruct page\t*page;\n\tunsigned long\tsize;\n\tunsigned long\toffset;\n\tunsigned long\tdisplacement;\n};\n\nstruct bts_buffer {\n\tsize_t\t\treal_size;\t \n\tunsigned int\tnr_pages;\n\tunsigned int\tnr_bufs;\n\tunsigned int\tcur_buf;\n\tbool\t\tsnapshot;\n\tlocal_t\t\tdata_size;\n\tlocal_t\t\thead;\n\tunsigned long\tend;\n\tvoid\t\t**data_pages;\n\tstruct bts_phys\tbuf[];\n};\n\nstatic struct pmu bts_pmu;\n\nstatic int buf_nr_pages(struct page *page)\n{\n\tif (!PagePrivate(page))\n\t\treturn 1;\n\n\treturn 1 << page_private(page);\n}\n\nstatic size_t buf_size(struct page *page)\n{\n\treturn buf_nr_pages(page) * PAGE_SIZE;\n}\n\nstatic void *\nbts_buffer_setup_aux(struct perf_event *event, void **pages,\n\t\t     int nr_pages, bool overwrite)\n{\n\tstruct bts_buffer *buf;\n\tstruct page *page;\n\tint cpu = event->cpu;\n\tint node = (cpu == -1) ? cpu : cpu_to_node(cpu);\n\tunsigned long offset;\n\tsize_t size = nr_pages << PAGE_SHIFT;\n\tint pg, nbuf, pad;\n\n\t \n\tfor (pg = 0, nbuf = 0; pg < nr_pages;) {\n\t\tpage = virt_to_page(pages[pg]);\n\t\tpg += buf_nr_pages(page);\n\t\tnbuf++;\n\t}\n\n\t \n\tif (overwrite && nbuf > 1)\n\t\treturn NULL;\n\n\tbuf = kzalloc_node(offsetof(struct bts_buffer, buf[nbuf]), GFP_KERNEL, node);\n\tif (!buf)\n\t\treturn NULL;\n\n\tbuf->nr_pages = nr_pages;\n\tbuf->nr_bufs = nbuf;\n\tbuf->snapshot = overwrite;\n\tbuf->data_pages = pages;\n\tbuf->real_size = size - size % BTS_RECORD_SIZE;\n\n\tfor (pg = 0, nbuf = 0, offset = 0, pad = 0; nbuf < buf->nr_bufs; nbuf++) {\n\t\tunsigned int __nr_pages;\n\n\t\tpage = virt_to_page(pages[pg]);\n\t\t__nr_pages = buf_nr_pages(page);\n\t\tbuf->buf[nbuf].page = page;\n\t\tbuf->buf[nbuf].offset = offset;\n\t\tbuf->buf[nbuf].displacement = (pad ? BTS_RECORD_SIZE - pad : 0);\n\t\tbuf->buf[nbuf].size = buf_size(page) - buf->buf[nbuf].displacement;\n\t\tpad = buf->buf[nbuf].size % BTS_RECORD_SIZE;\n\t\tbuf->buf[nbuf].size -= pad;\n\n\t\tpg += __nr_pages;\n\t\toffset += __nr_pages << PAGE_SHIFT;\n\t}\n\n\treturn buf;\n}\n\nstatic void bts_buffer_free_aux(void *data)\n{\n\tkfree(data);\n}\n\nstatic unsigned long bts_buffer_offset(struct bts_buffer *buf, unsigned int idx)\n{\n\treturn buf->buf[idx].offset + buf->buf[idx].displacement;\n}\n\nstatic void\nbts_config_buffer(struct bts_buffer *buf)\n{\n\tint cpu = raw_smp_processor_id();\n\tstruct debug_store *ds = per_cpu(cpu_hw_events, cpu).ds;\n\tstruct bts_phys *phys = &buf->buf[buf->cur_buf];\n\tunsigned long index, thresh = 0, end = phys->size;\n\tstruct page *page = phys->page;\n\n\tindex = local_read(&buf->head);\n\n\tif (!buf->snapshot) {\n\t\tif (buf->end < phys->offset + buf_size(page))\n\t\t\tend = buf->end - phys->offset - phys->displacement;\n\n\t\tindex -= phys->offset + phys->displacement;\n\n\t\tif (end - index > BTS_SAFETY_MARGIN)\n\t\t\tthresh = end - BTS_SAFETY_MARGIN;\n\t\telse if (end - index > BTS_RECORD_SIZE)\n\t\t\tthresh = end - BTS_RECORD_SIZE;\n\t\telse\n\t\t\tthresh = end;\n\t}\n\n\tds->bts_buffer_base = (u64)(long)page_address(page) + phys->displacement;\n\tds->bts_index = ds->bts_buffer_base + index;\n\tds->bts_absolute_maximum = ds->bts_buffer_base + end;\n\tds->bts_interrupt_threshold = !buf->snapshot\n\t\t? ds->bts_buffer_base + thresh\n\t\t: ds->bts_absolute_maximum + BTS_RECORD_SIZE;\n}\n\nstatic void bts_buffer_pad_out(struct bts_phys *phys, unsigned long head)\n{\n\tunsigned long index = head - phys->offset;\n\n\tmemset(page_address(phys->page) + index, 0, phys->size - index);\n}\n\nstatic void bts_update(struct bts_ctx *bts)\n{\n\tint cpu = raw_smp_processor_id();\n\tstruct debug_store *ds = per_cpu(cpu_hw_events, cpu).ds;\n\tstruct bts_buffer *buf = perf_get_aux(&bts->handle);\n\tunsigned long index = ds->bts_index - ds->bts_buffer_base, old, head;\n\n\tif (!buf)\n\t\treturn;\n\n\thead = index + bts_buffer_offset(buf, buf->cur_buf);\n\told = local_xchg(&buf->head, head);\n\n\tif (!buf->snapshot) {\n\t\tif (old == head)\n\t\t\treturn;\n\n\t\tif (ds->bts_index >= ds->bts_absolute_maximum)\n\t\t\tperf_aux_output_flag(&bts->handle,\n\t\t\t                     PERF_AUX_FLAG_TRUNCATED);\n\n\t\t \n\t\tlocal_add(head - old, &buf->data_size);\n\t} else {\n\t\tlocal_set(&buf->data_size, head);\n\t}\n\n\t \n\tbarrier();\n}\n\nstatic int\nbts_buffer_reset(struct bts_buffer *buf, struct perf_output_handle *handle);\n\n \n\nstatic void __bts_event_start(struct perf_event *event)\n{\n\tstruct bts_ctx *bts = this_cpu_ptr(&bts_ctx);\n\tstruct bts_buffer *buf = perf_get_aux(&bts->handle);\n\tu64 config = 0;\n\n\tif (!buf->snapshot)\n\t\tconfig |= ARCH_PERFMON_EVENTSEL_INT;\n\tif (!event->attr.exclude_kernel)\n\t\tconfig |= ARCH_PERFMON_EVENTSEL_OS;\n\tif (!event->attr.exclude_user)\n\t\tconfig |= ARCH_PERFMON_EVENTSEL_USR;\n\n\tbts_config_buffer(buf);\n\n\t \n\twmb();\n\n\t \n\tWRITE_ONCE(bts->state, BTS_STATE_ACTIVE);\n\n\tintel_pmu_enable_bts(config);\n\n}\n\nstatic void bts_event_start(struct perf_event *event, int flags)\n{\n\tstruct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);\n\tstruct bts_ctx *bts = this_cpu_ptr(&bts_ctx);\n\tstruct bts_buffer *buf;\n\n\tbuf = perf_aux_output_begin(&bts->handle, event);\n\tif (!buf)\n\t\tgoto fail_stop;\n\n\tif (bts_buffer_reset(buf, &bts->handle))\n\t\tgoto fail_end_stop;\n\n\tbts->ds_back.bts_buffer_base = cpuc->ds->bts_buffer_base;\n\tbts->ds_back.bts_absolute_maximum = cpuc->ds->bts_absolute_maximum;\n\tbts->ds_back.bts_interrupt_threshold = cpuc->ds->bts_interrupt_threshold;\n\n\tperf_event_itrace_started(event);\n\tevent->hw.state = 0;\n\n\t__bts_event_start(event);\n\n\treturn;\n\nfail_end_stop:\n\tperf_aux_output_end(&bts->handle, 0);\n\nfail_stop:\n\tevent->hw.state = PERF_HES_STOPPED;\n}\n\nstatic void __bts_event_stop(struct perf_event *event, int state)\n{\n\tstruct bts_ctx *bts = this_cpu_ptr(&bts_ctx);\n\n\t \n\tWRITE_ONCE(bts->state, state);\n\n\t \n\tintel_pmu_disable_bts();\n}\n\nstatic void bts_event_stop(struct perf_event *event, int flags)\n{\n\tstruct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);\n\tstruct bts_ctx *bts = this_cpu_ptr(&bts_ctx);\n\tstruct bts_buffer *buf = NULL;\n\tint state = READ_ONCE(bts->state);\n\n\tif (state == BTS_STATE_ACTIVE)\n\t\t__bts_event_stop(event, BTS_STATE_STOPPED);\n\n\tif (state != BTS_STATE_STOPPED)\n\t\tbuf = perf_get_aux(&bts->handle);\n\n\tevent->hw.state |= PERF_HES_STOPPED;\n\n\tif (flags & PERF_EF_UPDATE) {\n\t\tbts_update(bts);\n\n\t\tif (buf) {\n\t\t\tif (buf->snapshot)\n\t\t\t\tbts->handle.head =\n\t\t\t\t\tlocal_xchg(&buf->data_size,\n\t\t\t\t\t\t   buf->nr_pages << PAGE_SHIFT);\n\t\t\tperf_aux_output_end(&bts->handle,\n\t\t\t                    local_xchg(&buf->data_size, 0));\n\t\t}\n\n\t\tcpuc->ds->bts_index = bts->ds_back.bts_buffer_base;\n\t\tcpuc->ds->bts_buffer_base = bts->ds_back.bts_buffer_base;\n\t\tcpuc->ds->bts_absolute_maximum = bts->ds_back.bts_absolute_maximum;\n\t\tcpuc->ds->bts_interrupt_threshold = bts->ds_back.bts_interrupt_threshold;\n\t}\n}\n\nvoid intel_bts_enable_local(void)\n{\n\tstruct bts_ctx *bts = this_cpu_ptr(&bts_ctx);\n\tint state = READ_ONCE(bts->state);\n\n\t \n\tif (WARN_ON_ONCE(state == BTS_STATE_ACTIVE))\n\t\treturn;\n\n\tif (state == BTS_STATE_STOPPED)\n\t\treturn;\n\n\tif (bts->handle.event)\n\t\t__bts_event_start(bts->handle.event);\n}\n\nvoid intel_bts_disable_local(void)\n{\n\tstruct bts_ctx *bts = this_cpu_ptr(&bts_ctx);\n\n\t \n\tif (READ_ONCE(bts->state) != BTS_STATE_ACTIVE)\n\t\treturn;\n\n\tif (bts->handle.event)\n\t\t__bts_event_stop(bts->handle.event, BTS_STATE_INACTIVE);\n}\n\nstatic int\nbts_buffer_reset(struct bts_buffer *buf, struct perf_output_handle *handle)\n{\n\tunsigned long head, space, next_space, pad, gap, skip, wakeup;\n\tunsigned int next_buf;\n\tstruct bts_phys *phys, *next_phys;\n\tint ret;\n\n\tif (buf->snapshot)\n\t\treturn 0;\n\n\thead = handle->head & ((buf->nr_pages << PAGE_SHIFT) - 1);\n\n\tphys = &buf->buf[buf->cur_buf];\n\tspace = phys->offset + phys->displacement + phys->size - head;\n\tpad = space;\n\tif (space > handle->size) {\n\t\tspace = handle->size;\n\t\tspace -= space % BTS_RECORD_SIZE;\n\t}\n\tif (space <= BTS_SAFETY_MARGIN) {\n\t\t \n\t\tnext_buf = buf->cur_buf + 1;\n\t\tif (next_buf >= buf->nr_bufs)\n\t\t\tnext_buf = 0;\n\t\tnext_phys = &buf->buf[next_buf];\n\t\tgap = buf_size(phys->page) - phys->displacement - phys->size +\n\t\t      next_phys->displacement;\n\t\tskip = pad + gap;\n\t\tif (handle->size >= skip) {\n\t\t\tnext_space = next_phys->size;\n\t\t\tif (next_space + skip > handle->size) {\n\t\t\t\tnext_space = handle->size - skip;\n\t\t\t\tnext_space -= next_space % BTS_RECORD_SIZE;\n\t\t\t}\n\t\t\tif (next_space > space || !space) {\n\t\t\t\tif (pad)\n\t\t\t\t\tbts_buffer_pad_out(phys, head);\n\t\t\t\tret = perf_aux_output_skip(handle, skip);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t\t \n\t\t\t\tphys = next_phys;\n\t\t\t\tspace = next_space;\n\t\t\t\thead = phys->offset + phys->displacement;\n\t\t\t\t \n\t\t\t\tbuf->cur_buf = next_buf;\n\t\t\t\tlocal_set(&buf->head, head);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\twakeup = BTS_SAFETY_MARGIN + BTS_RECORD_SIZE + handle->wakeup -\n\t\t handle->head;\n\tif (space > wakeup) {\n\t\tspace = wakeup;\n\t\tspace -= space % BTS_RECORD_SIZE;\n\t}\n\n\tbuf->end = head + space;\n\n\t \n\tif (!space)\n\t\treturn -ENOSPC;\n\n\treturn 0;\n}\n\nint intel_bts_interrupt(void)\n{\n\tstruct debug_store *ds = this_cpu_ptr(&cpu_hw_events)->ds;\n\tstruct bts_ctx *bts = this_cpu_ptr(&bts_ctx);\n\tstruct perf_event *event = bts->handle.event;\n\tstruct bts_buffer *buf;\n\ts64 old_head;\n\tint err = -ENOSPC, handled = 0;\n\n\t \n\tif (ds && (ds->bts_index >= ds->bts_interrupt_threshold))\n\t\thandled = 1;\n\n\t \n\tif (READ_ONCE(bts->state) == BTS_STATE_STOPPED)\n\t\treturn handled;\n\n\tbuf = perf_get_aux(&bts->handle);\n\tif (!buf)\n\t\treturn handled;\n\n\t \n\tif (buf->snapshot)\n\t\treturn 0;\n\n\told_head = local_read(&buf->head);\n\tbts_update(bts);\n\n\t \n\tif (old_head == local_read(&buf->head))\n\t\treturn handled;\n\n\tperf_aux_output_end(&bts->handle, local_xchg(&buf->data_size, 0));\n\n\tbuf = perf_aux_output_begin(&bts->handle, event);\n\tif (buf)\n\t\terr = bts_buffer_reset(buf, &bts->handle);\n\n\tif (err) {\n\t\tWRITE_ONCE(bts->state, BTS_STATE_STOPPED);\n\n\t\tif (buf) {\n\t\t\t \n\t\t\tbarrier();\n\t\t\tperf_aux_output_end(&bts->handle, 0);\n\t\t}\n\t}\n\n\treturn 1;\n}\n\nstatic void bts_event_del(struct perf_event *event, int mode)\n{\n\tbts_event_stop(event, PERF_EF_UPDATE);\n}\n\nstatic int bts_event_add(struct perf_event *event, int mode)\n{\n\tstruct bts_ctx *bts = this_cpu_ptr(&bts_ctx);\n\tstruct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tevent->hw.state = PERF_HES_STOPPED;\n\n\tif (test_bit(INTEL_PMC_IDX_FIXED_BTS, cpuc->active_mask))\n\t\treturn -EBUSY;\n\n\tif (bts->handle.event)\n\t\treturn -EBUSY;\n\n\tif (mode & PERF_EF_START) {\n\t\tbts_event_start(event, 0);\n\t\tif (hwc->state & PERF_HES_STOPPED)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void bts_event_destroy(struct perf_event *event)\n{\n\tx86_release_hardware();\n\tx86_del_exclusive(x86_lbr_exclusive_bts);\n}\n\nstatic int bts_event_init(struct perf_event *event)\n{\n\tint ret;\n\n\tif (event->attr.type != bts_pmu.type)\n\t\treturn -ENOENT;\n\n\t \n\tif (event->attr.exclude_kernel) {\n\t\tret = perf_allow_kernel(&event->attr);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (x86_add_exclusive(x86_lbr_exclusive_bts))\n\t\treturn -EBUSY;\n\n\tret = x86_reserve_hardware();\n\tif (ret) {\n\t\tx86_del_exclusive(x86_lbr_exclusive_bts);\n\t\treturn ret;\n\t}\n\n\tevent->destroy = bts_event_destroy;\n\n\treturn 0;\n}\n\nstatic void bts_event_read(struct perf_event *event)\n{\n}\n\nstatic __init int bts_init(void)\n{\n\tif (!boot_cpu_has(X86_FEATURE_DTES64) || !x86_pmu.bts)\n\t\treturn -ENODEV;\n\n\tif (boot_cpu_has(X86_FEATURE_PTI)) {\n\t\t \n\t\treturn -ENODEV;\n\t}\n\n\tbts_pmu.capabilities\t= PERF_PMU_CAP_AUX_NO_SG | PERF_PMU_CAP_ITRACE |\n\t\t\t\t  PERF_PMU_CAP_EXCLUSIVE;\n\tbts_pmu.task_ctx_nr\t= perf_sw_context;\n\tbts_pmu.event_init\t= bts_event_init;\n\tbts_pmu.add\t\t= bts_event_add;\n\tbts_pmu.del\t\t= bts_event_del;\n\tbts_pmu.start\t\t= bts_event_start;\n\tbts_pmu.stop\t\t= bts_event_stop;\n\tbts_pmu.read\t\t= bts_event_read;\n\tbts_pmu.setup_aux\t= bts_buffer_setup_aux;\n\tbts_pmu.free_aux\t= bts_buffer_free_aux;\n\n\treturn perf_pmu_register(&bts_pmu, \"intel_bts\", -1);\n}\narch_initcall(bts_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}