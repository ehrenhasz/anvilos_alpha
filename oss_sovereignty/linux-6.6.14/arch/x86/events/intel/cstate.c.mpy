{
  "module_name": "cstate.c",
  "hash_id": "7d388f696a5d81406fd01c3620d0095ec0179b105e323a8c52709ae9e0fad57d",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/events/intel/cstate.c",
  "human_readable_source": " \n\n \n\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/perf_event.h>\n#include <linux/nospec.h>\n#include <asm/cpu_device_id.h>\n#include <asm/intel-family.h>\n#include \"../perf_event.h\"\n#include \"../probe.h\"\n\nMODULE_LICENSE(\"GPL\");\n\n#define DEFINE_CSTATE_FORMAT_ATTR(_var, _name, _format)\t\t\\\nstatic ssize_t __cstate_##_var##_show(struct device *dev,\t\\\n\t\t\t\tstruct device_attribute *attr,\t\\\n\t\t\t\tchar *page)\t\t\t\\\n{\t\t\t\t\t\t\t\t\\\n\tBUILD_BUG_ON(sizeof(_format) >= PAGE_SIZE);\t\t\\\n\treturn sprintf(page, _format \"\\n\");\t\t\t\\\n}\t\t\t\t\t\t\t\t\\\nstatic struct device_attribute format_attr_##_var =\t\t\\\n\t__ATTR(_name, 0444, __cstate_##_var##_show, NULL)\n\nstatic ssize_t cstate_get_attr_cpumask(struct device *dev,\n\t\t\t\t       struct device_attribute *attr,\n\t\t\t\t       char *buf);\n\n \nstruct cstate_model {\n\tunsigned long\t\tcore_events;\n\tunsigned long\t\tpkg_events;\n\tunsigned long\t\tquirks;\n};\n\n \n#define SLM_PKG_C6_USE_C7_MSR\t(1UL << 0)\n#define KNL_CORE_C6_MSR\t\t(1UL << 1)\n\nstruct perf_cstate_msr {\n\tu64\tmsr;\n\tstruct\tperf_pmu_events_attr *attr;\n};\n\n\n \nstatic struct pmu cstate_core_pmu;\nstatic bool has_cstate_core;\n\nenum perf_cstate_core_events {\n\tPERF_CSTATE_CORE_C1_RES = 0,\n\tPERF_CSTATE_CORE_C3_RES,\n\tPERF_CSTATE_CORE_C6_RES,\n\tPERF_CSTATE_CORE_C7_RES,\n\n\tPERF_CSTATE_CORE_EVENT_MAX,\n};\n\nPMU_EVENT_ATTR_STRING(c1-residency, attr_cstate_core_c1, \"event=0x00\");\nPMU_EVENT_ATTR_STRING(c3-residency, attr_cstate_core_c3, \"event=0x01\");\nPMU_EVENT_ATTR_STRING(c6-residency, attr_cstate_core_c6, \"event=0x02\");\nPMU_EVENT_ATTR_STRING(c7-residency, attr_cstate_core_c7, \"event=0x03\");\n\nstatic unsigned long core_msr_mask;\n\nPMU_EVENT_GROUP(events, cstate_core_c1);\nPMU_EVENT_GROUP(events, cstate_core_c3);\nPMU_EVENT_GROUP(events, cstate_core_c6);\nPMU_EVENT_GROUP(events, cstate_core_c7);\n\nstatic bool test_msr(int idx, void *data)\n{\n\treturn test_bit(idx, (unsigned long *) data);\n}\n\nstatic struct perf_msr core_msr[] = {\n\t[PERF_CSTATE_CORE_C1_RES] = { MSR_CORE_C1_RES,\t\t&group_cstate_core_c1,\ttest_msr },\n\t[PERF_CSTATE_CORE_C3_RES] = { MSR_CORE_C3_RESIDENCY,\t&group_cstate_core_c3,\ttest_msr },\n\t[PERF_CSTATE_CORE_C6_RES] = { MSR_CORE_C6_RESIDENCY,\t&group_cstate_core_c6,\ttest_msr },\n\t[PERF_CSTATE_CORE_C7_RES] = { MSR_CORE_C7_RESIDENCY,\t&group_cstate_core_c7,\ttest_msr },\n};\n\nstatic struct attribute *attrs_empty[] = {\n\tNULL,\n};\n\n \nstatic struct attribute_group core_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = attrs_empty,\n};\n\nDEFINE_CSTATE_FORMAT_ATTR(core_event, event, \"config:0-63\");\nstatic struct attribute *core_format_attrs[] = {\n\t&format_attr_core_event.attr,\n\tNULL,\n};\n\nstatic struct attribute_group core_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = core_format_attrs,\n};\n\nstatic cpumask_t cstate_core_cpu_mask;\nstatic DEVICE_ATTR(cpumask, S_IRUGO, cstate_get_attr_cpumask, NULL);\n\nstatic struct attribute *cstate_cpumask_attrs[] = {\n\t&dev_attr_cpumask.attr,\n\tNULL,\n};\n\nstatic struct attribute_group cpumask_attr_group = {\n\t.attrs = cstate_cpumask_attrs,\n};\n\nstatic const struct attribute_group *core_attr_groups[] = {\n\t&core_events_attr_group,\n\t&core_format_attr_group,\n\t&cpumask_attr_group,\n\tNULL,\n};\n\n \nstatic struct pmu cstate_pkg_pmu;\nstatic bool has_cstate_pkg;\n\nenum perf_cstate_pkg_events {\n\tPERF_CSTATE_PKG_C2_RES = 0,\n\tPERF_CSTATE_PKG_C3_RES,\n\tPERF_CSTATE_PKG_C6_RES,\n\tPERF_CSTATE_PKG_C7_RES,\n\tPERF_CSTATE_PKG_C8_RES,\n\tPERF_CSTATE_PKG_C9_RES,\n\tPERF_CSTATE_PKG_C10_RES,\n\n\tPERF_CSTATE_PKG_EVENT_MAX,\n};\n\nPMU_EVENT_ATTR_STRING(c2-residency,  attr_cstate_pkg_c2,  \"event=0x00\");\nPMU_EVENT_ATTR_STRING(c3-residency,  attr_cstate_pkg_c3,  \"event=0x01\");\nPMU_EVENT_ATTR_STRING(c6-residency,  attr_cstate_pkg_c6,  \"event=0x02\");\nPMU_EVENT_ATTR_STRING(c7-residency,  attr_cstate_pkg_c7,  \"event=0x03\");\nPMU_EVENT_ATTR_STRING(c8-residency,  attr_cstate_pkg_c8,  \"event=0x04\");\nPMU_EVENT_ATTR_STRING(c9-residency,  attr_cstate_pkg_c9,  \"event=0x05\");\nPMU_EVENT_ATTR_STRING(c10-residency, attr_cstate_pkg_c10, \"event=0x06\");\n\nstatic unsigned long pkg_msr_mask;\n\nPMU_EVENT_GROUP(events, cstate_pkg_c2);\nPMU_EVENT_GROUP(events, cstate_pkg_c3);\nPMU_EVENT_GROUP(events, cstate_pkg_c6);\nPMU_EVENT_GROUP(events, cstate_pkg_c7);\nPMU_EVENT_GROUP(events, cstate_pkg_c8);\nPMU_EVENT_GROUP(events, cstate_pkg_c9);\nPMU_EVENT_GROUP(events, cstate_pkg_c10);\n\nstatic struct perf_msr pkg_msr[] = {\n\t[PERF_CSTATE_PKG_C2_RES]  = { MSR_PKG_C2_RESIDENCY,\t&group_cstate_pkg_c2,\ttest_msr },\n\t[PERF_CSTATE_PKG_C3_RES]  = { MSR_PKG_C3_RESIDENCY,\t&group_cstate_pkg_c3,\ttest_msr },\n\t[PERF_CSTATE_PKG_C6_RES]  = { MSR_PKG_C6_RESIDENCY,\t&group_cstate_pkg_c6,\ttest_msr },\n\t[PERF_CSTATE_PKG_C7_RES]  = { MSR_PKG_C7_RESIDENCY,\t&group_cstate_pkg_c7,\ttest_msr },\n\t[PERF_CSTATE_PKG_C8_RES]  = { MSR_PKG_C8_RESIDENCY,\t&group_cstate_pkg_c8,\ttest_msr },\n\t[PERF_CSTATE_PKG_C9_RES]  = { MSR_PKG_C9_RESIDENCY,\t&group_cstate_pkg_c9,\ttest_msr },\n\t[PERF_CSTATE_PKG_C10_RES] = { MSR_PKG_C10_RESIDENCY,\t&group_cstate_pkg_c10,\ttest_msr },\n};\n\nstatic struct attribute_group pkg_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = attrs_empty,\n};\n\nDEFINE_CSTATE_FORMAT_ATTR(pkg_event, event, \"config:0-63\");\nstatic struct attribute *pkg_format_attrs[] = {\n\t&format_attr_pkg_event.attr,\n\tNULL,\n};\nstatic struct attribute_group pkg_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = pkg_format_attrs,\n};\n\nstatic cpumask_t cstate_pkg_cpu_mask;\n\nstatic const struct attribute_group *pkg_attr_groups[] = {\n\t&pkg_events_attr_group,\n\t&pkg_format_attr_group,\n\t&cpumask_attr_group,\n\tNULL,\n};\n\nstatic ssize_t cstate_get_attr_cpumask(struct device *dev,\n\t\t\t\t       struct device_attribute *attr,\n\t\t\t\t       char *buf)\n{\n\tstruct pmu *pmu = dev_get_drvdata(dev);\n\n\tif (pmu == &cstate_core_pmu)\n\t\treturn cpumap_print_to_pagebuf(true, buf, &cstate_core_cpu_mask);\n\telse if (pmu == &cstate_pkg_pmu)\n\t\treturn cpumap_print_to_pagebuf(true, buf, &cstate_pkg_cpu_mask);\n\telse\n\t\treturn 0;\n}\n\nstatic int cstate_pmu_event_init(struct perf_event *event)\n{\n\tu64 cfg = event->attr.config;\n\tint cpu;\n\n\tif (event->attr.type != event->pmu->type)\n\t\treturn -ENOENT;\n\n\t \n\tif (event->attr.sample_period)  \n\t\treturn -EINVAL;\n\n\tif (event->cpu < 0)\n\t\treturn -EINVAL;\n\n\tif (event->pmu == &cstate_core_pmu) {\n\t\tif (cfg >= PERF_CSTATE_CORE_EVENT_MAX)\n\t\t\treturn -EINVAL;\n\t\tcfg = array_index_nospec((unsigned long)cfg, PERF_CSTATE_CORE_EVENT_MAX);\n\t\tif (!(core_msr_mask & (1 << cfg)))\n\t\t\treturn -EINVAL;\n\t\tevent->hw.event_base = core_msr[cfg].msr;\n\t\tcpu = cpumask_any_and(&cstate_core_cpu_mask,\n\t\t\t\t      topology_sibling_cpumask(event->cpu));\n\t} else if (event->pmu == &cstate_pkg_pmu) {\n\t\tif (cfg >= PERF_CSTATE_PKG_EVENT_MAX)\n\t\t\treturn -EINVAL;\n\t\tcfg = array_index_nospec((unsigned long)cfg, PERF_CSTATE_PKG_EVENT_MAX);\n\t\tif (!(pkg_msr_mask & (1 << cfg)))\n\t\t\treturn -EINVAL;\n\t\tevent->hw.event_base = pkg_msr[cfg].msr;\n\t\tcpu = cpumask_any_and(&cstate_pkg_cpu_mask,\n\t\t\t\t      topology_die_cpumask(event->cpu));\n\t} else {\n\t\treturn -ENOENT;\n\t}\n\n\tif (cpu >= nr_cpu_ids)\n\t\treturn -ENODEV;\n\n\tevent->cpu = cpu;\n\tevent->hw.config = cfg;\n\tevent->hw.idx = -1;\n\treturn 0;\n}\n\nstatic inline u64 cstate_pmu_read_counter(struct perf_event *event)\n{\n\tu64 val;\n\n\trdmsrl(event->hw.event_base, val);\n\treturn val;\n}\n\nstatic void cstate_pmu_event_update(struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tu64 prev_raw_count, new_raw_count;\n\n\tprev_raw_count = local64_read(&hwc->prev_count);\n\tdo {\n\t\tnew_raw_count = cstate_pmu_read_counter(event);\n\t} while (!local64_try_cmpxchg(&hwc->prev_count,\n\t\t\t\t      &prev_raw_count, new_raw_count));\n\n\tlocal64_add(new_raw_count - prev_raw_count, &event->count);\n}\n\nstatic void cstate_pmu_event_start(struct perf_event *event, int mode)\n{\n\tlocal64_set(&event->hw.prev_count, cstate_pmu_read_counter(event));\n}\n\nstatic void cstate_pmu_event_stop(struct perf_event *event, int mode)\n{\n\tcstate_pmu_event_update(event);\n}\n\nstatic void cstate_pmu_event_del(struct perf_event *event, int mode)\n{\n\tcstate_pmu_event_stop(event, PERF_EF_UPDATE);\n}\n\nstatic int cstate_pmu_event_add(struct perf_event *event, int mode)\n{\n\tif (mode & PERF_EF_START)\n\t\tcstate_pmu_event_start(event, mode);\n\n\treturn 0;\n}\n\n \nstatic int cstate_cpu_exit(unsigned int cpu)\n{\n\tunsigned int target;\n\n\tif (has_cstate_core &&\n\t    cpumask_test_and_clear_cpu(cpu, &cstate_core_cpu_mask)) {\n\n\t\ttarget = cpumask_any_but(topology_sibling_cpumask(cpu), cpu);\n\t\t \n\t\tif (target < nr_cpu_ids) {\n\t\t\tcpumask_set_cpu(target, &cstate_core_cpu_mask);\n\t\t\tperf_pmu_migrate_context(&cstate_core_pmu, cpu, target);\n\t\t}\n\t}\n\n\tif (has_cstate_pkg &&\n\t    cpumask_test_and_clear_cpu(cpu, &cstate_pkg_cpu_mask)) {\n\n\t\ttarget = cpumask_any_but(topology_die_cpumask(cpu), cpu);\n\t\t \n\t\tif (target < nr_cpu_ids) {\n\t\t\tcpumask_set_cpu(target, &cstate_pkg_cpu_mask);\n\t\t\tperf_pmu_migrate_context(&cstate_pkg_pmu, cpu, target);\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int cstate_cpu_init(unsigned int cpu)\n{\n\tunsigned int target;\n\n\t \n\ttarget = cpumask_any_and(&cstate_core_cpu_mask,\n\t\t\t\t topology_sibling_cpumask(cpu));\n\n\tif (has_cstate_core && target >= nr_cpu_ids)\n\t\tcpumask_set_cpu(cpu, &cstate_core_cpu_mask);\n\n\t \n\ttarget = cpumask_any_and(&cstate_pkg_cpu_mask,\n\t\t\t\t topology_die_cpumask(cpu));\n\tif (has_cstate_pkg && target >= nr_cpu_ids)\n\t\tcpumask_set_cpu(cpu, &cstate_pkg_cpu_mask);\n\n\treturn 0;\n}\n\nstatic const struct attribute_group *core_attr_update[] = {\n\t&group_cstate_core_c1,\n\t&group_cstate_core_c3,\n\t&group_cstate_core_c6,\n\t&group_cstate_core_c7,\n\tNULL,\n};\n\nstatic const struct attribute_group *pkg_attr_update[] = {\n\t&group_cstate_pkg_c2,\n\t&group_cstate_pkg_c3,\n\t&group_cstate_pkg_c6,\n\t&group_cstate_pkg_c7,\n\t&group_cstate_pkg_c8,\n\t&group_cstate_pkg_c9,\n\t&group_cstate_pkg_c10,\n\tNULL,\n};\n\nstatic struct pmu cstate_core_pmu = {\n\t.attr_groups\t= core_attr_groups,\n\t.attr_update\t= core_attr_update,\n\t.name\t\t= \"cstate_core\",\n\t.task_ctx_nr\t= perf_invalid_context,\n\t.event_init\t= cstate_pmu_event_init,\n\t.add\t\t= cstate_pmu_event_add,\n\t.del\t\t= cstate_pmu_event_del,\n\t.start\t\t= cstate_pmu_event_start,\n\t.stop\t\t= cstate_pmu_event_stop,\n\t.read\t\t= cstate_pmu_event_update,\n\t.capabilities\t= PERF_PMU_CAP_NO_INTERRUPT | PERF_PMU_CAP_NO_EXCLUDE,\n\t.module\t\t= THIS_MODULE,\n};\n\nstatic struct pmu cstate_pkg_pmu = {\n\t.attr_groups\t= pkg_attr_groups,\n\t.attr_update\t= pkg_attr_update,\n\t.name\t\t= \"cstate_pkg\",\n\t.task_ctx_nr\t= perf_invalid_context,\n\t.event_init\t= cstate_pmu_event_init,\n\t.add\t\t= cstate_pmu_event_add,\n\t.del\t\t= cstate_pmu_event_del,\n\t.start\t\t= cstate_pmu_event_start,\n\t.stop\t\t= cstate_pmu_event_stop,\n\t.read\t\t= cstate_pmu_event_update,\n\t.capabilities\t= PERF_PMU_CAP_NO_INTERRUPT | PERF_PMU_CAP_NO_EXCLUDE,\n\t.module\t\t= THIS_MODULE,\n};\n\nstatic const struct cstate_model nhm_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C6_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C7_RES),\n};\n\nstatic const struct cstate_model snb_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C7_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C2_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C7_RES),\n};\n\nstatic const struct cstate_model hswult_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C7_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C2_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C7_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C8_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C9_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C10_RES),\n};\n\nstatic const struct cstate_model cnl_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C1_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C7_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C2_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C7_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C8_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C9_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C10_RES),\n};\n\nstatic const struct cstate_model icl_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C7_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C2_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C7_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C8_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C9_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C10_RES),\n};\n\nstatic const struct cstate_model icx_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C1_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C6_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C2_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C6_RES),\n};\n\nstatic const struct cstate_model adl_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C1_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C7_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C2_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C7_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C8_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C9_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C10_RES),\n};\n\nstatic const struct cstate_model slm_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C1_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C6_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C6_RES),\n\t.quirks\t\t\t= SLM_PKG_C6_USE_C7_MSR,\n};\n\n\nstatic const struct cstate_model knl_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C6_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C2_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C6_RES),\n\t.quirks\t\t\t= KNL_CORE_C6_MSR,\n};\n\n\nstatic const struct cstate_model glm_cstates __initconst = {\n\t.core_events\t\t= BIT(PERF_CSTATE_CORE_C1_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_CORE_C6_RES),\n\n\t.pkg_events\t\t= BIT(PERF_CSTATE_PKG_C2_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C3_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C6_RES) |\n\t\t\t\t  BIT(PERF_CSTATE_PKG_C10_RES),\n};\n\n\nstatic const struct x86_cpu_id intel_cstates_match[] __initconst = {\n\tX86_MATCH_INTEL_FAM6_MODEL(NEHALEM,\t\t&nhm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(NEHALEM_EP,\t\t&nhm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(NEHALEM_EX,\t\t&nhm_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(WESTMERE,\t\t&nhm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(WESTMERE_EP,\t\t&nhm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(WESTMERE_EX,\t\t&nhm_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(SANDYBRIDGE,\t\t&snb_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(SANDYBRIDGE_X,\t&snb_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(IVYBRIDGE,\t\t&snb_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(IVYBRIDGE_X,\t\t&snb_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(HASWELL,\t\t&snb_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(HASWELL_X,\t\t&snb_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(HASWELL_G,\t\t&snb_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(HASWELL_L,\t\t&hswult_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_SILVERMONT,\t&slm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_SILVERMONT_D,\t&slm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_AIRMONT,\t&slm_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(BROADWELL,\t\t&snb_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(BROADWELL_D,\t\t&snb_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(BROADWELL_G,\t\t&snb_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(BROADWELL_X,\t\t&snb_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(SKYLAKE_L,\t\t&snb_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(SKYLAKE,\t\t&snb_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(SKYLAKE_X,\t\t&snb_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(KABYLAKE_L,\t\t&hswult_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(KABYLAKE,\t\t&hswult_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(COMETLAKE_L,\t\t&hswult_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(COMETLAKE,\t\t&hswult_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(CANNONLAKE_L,\t&cnl_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(XEON_PHI_KNL,\t&knl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(XEON_PHI_KNM,\t&knl_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_GOLDMONT,\t&glm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_GOLDMONT_D,\t&glm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_GOLDMONT_PLUS,\t&glm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_TREMONT_D,\t&glm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_TREMONT,\t&glm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_TREMONT_L,\t&glm_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ATOM_GRACEMONT,\t&adl_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(ICELAKE_L,\t\t&icl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ICELAKE,\t\t&icl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ICELAKE_X,\t\t&icx_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ICELAKE_D,\t\t&icx_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(SAPPHIRERAPIDS_X,\t&icx_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(EMERALDRAPIDS_X,\t&icx_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(GRANITERAPIDS_X,\t&icx_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(GRANITERAPIDS_D,\t&icx_cstates),\n\n\tX86_MATCH_INTEL_FAM6_MODEL(TIGERLAKE_L,\t\t&icl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(TIGERLAKE,\t\t&icl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ROCKETLAKE,\t\t&icl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ALDERLAKE,\t\t&adl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(ALDERLAKE_L,\t\t&adl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(RAPTORLAKE,\t\t&adl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(RAPTORLAKE_P,\t&adl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(RAPTORLAKE_S,\t&adl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(METEORLAKE,\t\t&adl_cstates),\n\tX86_MATCH_INTEL_FAM6_MODEL(METEORLAKE_L,\t&adl_cstates),\n\t{ },\n};\nMODULE_DEVICE_TABLE(x86cpu, intel_cstates_match);\n\nstatic int __init cstate_probe(const struct cstate_model *cm)\n{\n\t \n\tif (cm->quirks & SLM_PKG_C6_USE_C7_MSR)\n\t\tpkg_msr[PERF_CSTATE_PKG_C6_RES].msr = MSR_PKG_C7_RESIDENCY;\n\n\t \n\tif (cm->quirks & KNL_CORE_C6_MSR)\n\t\tpkg_msr[PERF_CSTATE_CORE_C6_RES].msr = MSR_KNL_CORE_C6_RESIDENCY;\n\n\n\tcore_msr_mask = perf_msr_probe(core_msr, PERF_CSTATE_CORE_EVENT_MAX,\n\t\t\t\t       true, (void *) &cm->core_events);\n\n\tpkg_msr_mask = perf_msr_probe(pkg_msr, PERF_CSTATE_PKG_EVENT_MAX,\n\t\t\t\t      true, (void *) &cm->pkg_events);\n\n\thas_cstate_core = !!core_msr_mask;\n\thas_cstate_pkg  = !!pkg_msr_mask;\n\n\treturn (has_cstate_core || has_cstate_pkg) ? 0 : -ENODEV;\n}\n\nstatic inline void cstate_cleanup(void)\n{\n\tcpuhp_remove_state_nocalls(CPUHP_AP_PERF_X86_CSTATE_ONLINE);\n\tcpuhp_remove_state_nocalls(CPUHP_AP_PERF_X86_CSTATE_STARTING);\n\n\tif (has_cstate_core)\n\t\tperf_pmu_unregister(&cstate_core_pmu);\n\n\tif (has_cstate_pkg)\n\t\tperf_pmu_unregister(&cstate_pkg_pmu);\n}\n\nstatic int __init cstate_init(void)\n{\n\tint err;\n\n\tcpuhp_setup_state(CPUHP_AP_PERF_X86_CSTATE_STARTING,\n\t\t\t  \"perf/x86/cstate:starting\", cstate_cpu_init, NULL);\n\tcpuhp_setup_state(CPUHP_AP_PERF_X86_CSTATE_ONLINE,\n\t\t\t  \"perf/x86/cstate:online\", NULL, cstate_cpu_exit);\n\n\tif (has_cstate_core) {\n\t\terr = perf_pmu_register(&cstate_core_pmu, cstate_core_pmu.name, -1);\n\t\tif (err) {\n\t\t\thas_cstate_core = false;\n\t\t\tpr_info(\"Failed to register cstate core pmu\\n\");\n\t\t\tcstate_cleanup();\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (has_cstate_pkg) {\n\t\tif (topology_max_die_per_package() > 1) {\n\t\t\terr = perf_pmu_register(&cstate_pkg_pmu,\n\t\t\t\t\t\t\"cstate_die\", -1);\n\t\t} else {\n\t\t\terr = perf_pmu_register(&cstate_pkg_pmu,\n\t\t\t\t\t\tcstate_pkg_pmu.name, -1);\n\t\t}\n\t\tif (err) {\n\t\t\thas_cstate_pkg = false;\n\t\t\tpr_info(\"Failed to register cstate pkg pmu\\n\");\n\t\t\tcstate_cleanup();\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int __init cstate_pmu_init(void)\n{\n\tconst struct x86_cpu_id *id;\n\tint err;\n\n\tif (boot_cpu_has(X86_FEATURE_HYPERVISOR))\n\t\treturn -ENODEV;\n\n\tid = x86_match_cpu(intel_cstates_match);\n\tif (!id)\n\t\treturn -ENODEV;\n\n\terr = cstate_probe((const struct cstate_model *) id->driver_data);\n\tif (err)\n\t\treturn err;\n\n\treturn cstate_init();\n}\nmodule_init(cstate_pmu_init);\n\nstatic void __exit cstate_pmu_exit(void)\n{\n\tcstate_cleanup();\n}\nmodule_exit(cstate_pmu_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}