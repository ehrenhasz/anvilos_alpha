{
  "module_name": "uv_time.c",
  "hash_id": "43d92a378cdd6f1adb8ac20b102ddc944059d39eeb1e9a1291933ca5f2610042",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/platform/uv/uv_time.c",
  "human_readable_source": "\n \n#include <linux/clockchips.h>\n#include <linux/slab.h>\n\n#include <asm/uv/uv_mmrs.h>\n#include <asm/uv/uv_hub.h>\n#include <asm/uv/bios.h>\n#include <asm/uv/uv.h>\n#include <asm/apic.h>\n#include <asm/cpu.h>\n\n#define RTC_NAME\t\t\"sgi_rtc\"\n\nstatic u64 uv_read_rtc(struct clocksource *cs);\nstatic int uv_rtc_next_event(unsigned long, struct clock_event_device *);\nstatic int uv_rtc_shutdown(struct clock_event_device *evt);\n\nstatic struct clocksource clocksource_uv = {\n\t.name\t\t= RTC_NAME,\n\t.rating\t\t= 299,\n\t.read\t\t= uv_read_rtc,\n\t.mask\t\t= (u64)UVH_RTC_REAL_TIME_CLOCK_MASK,\n\t.flags\t\t= CLOCK_SOURCE_IS_CONTINUOUS,\n};\n\nstatic struct clock_event_device clock_event_device_uv = {\n\t.name\t\t\t= RTC_NAME,\n\t.features\t\t= CLOCK_EVT_FEAT_ONESHOT,\n\t.shift\t\t\t= 20,\n\t.rating\t\t\t= 400,\n\t.irq\t\t\t= -1,\n\t.set_next_event\t\t= uv_rtc_next_event,\n\t.set_state_shutdown\t= uv_rtc_shutdown,\n\t.event_handler\t\t= NULL,\n};\n\nstatic DEFINE_PER_CPU(struct clock_event_device, cpu_ced);\n\n \nstruct uv_rtc_timer_head {\n\tspinlock_t\tlock;\n\t \n\tint\t\tnext_cpu;\n\t \n\tint\t\tncpus;\n\tstruct {\n\t\tint\tlcpu;\t\t \n\t\tu64\texpires;\t \n\t} cpu[];\n};\n\n \nstatic struct uv_rtc_timer_head\t\t**blade_info __read_mostly;\n\nstatic int\t\t\t\tuv_rtc_evt_enable;\n\n \n\n \nstatic void uv_rtc_send_IPI(int cpu)\n{\n\tunsigned long apicid, val;\n\tint pnode;\n\n\tapicid = cpu_physical_id(cpu);\n\tpnode = uv_apicid_to_pnode(apicid);\n\tval = (1UL << UVH_IPI_INT_SEND_SHFT) |\n\t      (apicid << UVH_IPI_INT_APIC_ID_SHFT) |\n\t      (X86_PLATFORM_IPI_VECTOR << UVH_IPI_INT_VECTOR_SHFT);\n\n\tuv_write_global_mmr64(pnode, UVH_IPI_INT, val);\n}\n\n \nstatic int uv_intr_pending(int pnode)\n{\n\treturn uv_read_global_mmr64(pnode, UVH_EVENT_OCCURRED2) &\n\t\tUVH_EVENT_OCCURRED2_RTC_1_MASK;\n}\n\n \nstatic int uv_setup_intr(int cpu, u64 expires)\n{\n\tu64 val;\n\tunsigned long apicid = cpu_physical_id(cpu);\n\tint pnode = uv_cpu_to_pnode(cpu);\n\n\tuv_write_global_mmr64(pnode, UVH_RTC1_INT_CONFIG,\n\t\tUVH_RTC1_INT_CONFIG_M_MASK);\n\tuv_write_global_mmr64(pnode, UVH_INT_CMPB, -1L);\n\n\tuv_write_global_mmr64(pnode, UVH_EVENT_OCCURRED2_ALIAS,\n\t\t\t      UVH_EVENT_OCCURRED2_RTC_1_MASK);\n\n\tval = (X86_PLATFORM_IPI_VECTOR << UVH_RTC1_INT_CONFIG_VECTOR_SHFT) |\n\t\t((u64)apicid << UVH_RTC1_INT_CONFIG_APIC_ID_SHFT);\n\n\t \n\tuv_write_global_mmr64(pnode, UVH_RTC1_INT_CONFIG, val);\n\t \n\tuv_write_global_mmr64(pnode, UVH_INT_CMPB, expires);\n\n\tif (uv_read_rtc(NULL) <= expires)\n\t\treturn 0;\n\n\treturn !uv_intr_pending(pnode);\n}\n\n \n\nstatic __init void uv_rtc_deallocate_timers(void)\n{\n\tint bid;\n\n\tfor_each_possible_blade(bid) {\n\t\tkfree(blade_info[bid]);\n\t}\n\tkfree(blade_info);\n}\n\n \nstatic __init int uv_rtc_allocate_timers(void)\n{\n\tint cpu;\n\n\tblade_info = kcalloc(uv_possible_blades, sizeof(void *), GFP_KERNEL);\n\tif (!blade_info)\n\t\treturn -ENOMEM;\n\n\tfor_each_present_cpu(cpu) {\n\t\tint nid = cpu_to_node(cpu);\n\t\tint bid = uv_cpu_to_blade_id(cpu);\n\t\tint bcpu = uv_cpu_blade_processor_id(cpu);\n\t\tstruct uv_rtc_timer_head *head = blade_info[bid];\n\n\t\tif (!head) {\n\t\t\thead = kmalloc_node(struct_size(head, cpu,\n\t\t\t\tuv_blade_nr_possible_cpus(bid)),\n\t\t\t\tGFP_KERNEL, nid);\n\t\t\tif (!head) {\n\t\t\t\tuv_rtc_deallocate_timers();\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tspin_lock_init(&head->lock);\n\t\t\thead->ncpus = uv_blade_nr_possible_cpus(bid);\n\t\t\thead->next_cpu = -1;\n\t\t\tblade_info[bid] = head;\n\t\t}\n\n\t\thead->cpu[bcpu].lcpu = cpu;\n\t\thead->cpu[bcpu].expires = ULLONG_MAX;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void uv_rtc_find_next_timer(struct uv_rtc_timer_head *head, int pnode)\n{\n\tu64 lowest = ULLONG_MAX;\n\tint c, bcpu = -1;\n\n\thead->next_cpu = -1;\n\tfor (c = 0; c < head->ncpus; c++) {\n\t\tu64 exp = head->cpu[c].expires;\n\t\tif (exp < lowest) {\n\t\t\tbcpu = c;\n\t\t\tlowest = exp;\n\t\t}\n\t}\n\tif (bcpu >= 0) {\n\t\thead->next_cpu = bcpu;\n\t\tc = head->cpu[bcpu].lcpu;\n\t\tif (uv_setup_intr(c, lowest))\n\t\t\t \n\t\t\tuv_rtc_send_IPI(c);\n\t} else {\n\t\tuv_write_global_mmr64(pnode, UVH_RTC1_INT_CONFIG,\n\t\t\tUVH_RTC1_INT_CONFIG_M_MASK);\n\t}\n}\n\n \nstatic int uv_rtc_set_timer(int cpu, u64 expires)\n{\n\tint pnode = uv_cpu_to_pnode(cpu);\n\tint bid = uv_cpu_to_blade_id(cpu);\n\tstruct uv_rtc_timer_head *head = blade_info[bid];\n\tint bcpu = uv_cpu_blade_processor_id(cpu);\n\tu64 *t = &head->cpu[bcpu].expires;\n\tunsigned long flags;\n\tint next_cpu;\n\n\tspin_lock_irqsave(&head->lock, flags);\n\n\tnext_cpu = head->next_cpu;\n\t*t = expires;\n\n\t \n\tif (next_cpu < 0 || bcpu == next_cpu ||\n\t\t\texpires < head->cpu[next_cpu].expires) {\n\t\thead->next_cpu = bcpu;\n\t\tif (uv_setup_intr(cpu, expires)) {\n\t\t\t*t = ULLONG_MAX;\n\t\t\tuv_rtc_find_next_timer(head, pnode);\n\t\t\tspin_unlock_irqrestore(&head->lock, flags);\n\t\t\treturn -ETIME;\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&head->lock, flags);\n\treturn 0;\n}\n\n \nstatic int uv_rtc_unset_timer(int cpu, int force)\n{\n\tint pnode = uv_cpu_to_pnode(cpu);\n\tint bid = uv_cpu_to_blade_id(cpu);\n\tstruct uv_rtc_timer_head *head = blade_info[bid];\n\tint bcpu = uv_cpu_blade_processor_id(cpu);\n\tu64 *t = &head->cpu[bcpu].expires;\n\tunsigned long flags;\n\tint rc = 0;\n\n\tspin_lock_irqsave(&head->lock, flags);\n\n\tif ((head->next_cpu == bcpu && uv_read_rtc(NULL) >= *t) || force)\n\t\trc = 1;\n\n\tif (rc) {\n\t\t*t = ULLONG_MAX;\n\t\t \n\t\tif (head->next_cpu == bcpu)\n\t\t\tuv_rtc_find_next_timer(head, pnode);\n\t}\n\n\tspin_unlock_irqrestore(&head->lock, flags);\n\n\treturn rc;\n}\n\n\n \n\n \nstatic u64 uv_read_rtc(struct clocksource *cs)\n{\n\tunsigned long offset;\n\n\tif (uv_get_min_hub_revision_id() == 1)\n\t\toffset = 0;\n\telse\n\t\toffset = (uv_blade_processor_id() * L1_CACHE_BYTES) % PAGE_SIZE;\n\n\treturn (u64)uv_read_local_mmr(UVH_RTC | offset);\n}\n\n \nstatic int uv_rtc_next_event(unsigned long delta,\n\t\t\t     struct clock_event_device *ced)\n{\n\tint ced_cpu = cpumask_first(ced->cpumask);\n\n\treturn uv_rtc_set_timer(ced_cpu, delta + uv_read_rtc(NULL));\n}\n\n \nstatic int uv_rtc_shutdown(struct clock_event_device *evt)\n{\n\tint ced_cpu = cpumask_first(evt->cpumask);\n\n\tuv_rtc_unset_timer(ced_cpu, 1);\n\treturn 0;\n}\n\nstatic void uv_rtc_interrupt(void)\n{\n\tint cpu = smp_processor_id();\n\tstruct clock_event_device *ced = &per_cpu(cpu_ced, cpu);\n\n\tif (!ced || !ced->event_handler)\n\t\treturn;\n\n\tif (uv_rtc_unset_timer(cpu, 0) != 1)\n\t\treturn;\n\n\tced->event_handler(ced);\n}\n\nstatic int __init uv_enable_evt_rtc(char *str)\n{\n\tuv_rtc_evt_enable = 1;\n\n\treturn 1;\n}\n__setup(\"uvrtcevt\", uv_enable_evt_rtc);\n\nstatic __init void uv_rtc_register_clockevents(struct work_struct *dummy)\n{\n\tstruct clock_event_device *ced = this_cpu_ptr(&cpu_ced);\n\n\t*ced = clock_event_device_uv;\n\tced->cpumask = cpumask_of(smp_processor_id());\n\tclockevents_register_device(ced);\n}\n\nstatic __init int uv_rtc_setup_clock(void)\n{\n\tint rc;\n\n\tif (!is_uv_system())\n\t\treturn -ENODEV;\n\n\trc = clocksource_register_hz(&clocksource_uv, sn_rtc_cycles_per_second);\n\tif (rc)\n\t\tprintk(KERN_INFO \"UV RTC clocksource failed rc %d\\n\", rc);\n\telse\n\t\tprintk(KERN_INFO \"UV RTC clocksource registered freq %lu MHz\\n\",\n\t\t\tsn_rtc_cycles_per_second/(unsigned long)1E6);\n\n\tif (rc || !uv_rtc_evt_enable || x86_platform_ipi_callback)\n\t\treturn rc;\n\n\t \n\trc = uv_rtc_allocate_timers();\n\tif (rc)\n\t\tgoto error;\n\n\tx86_platform_ipi_callback = uv_rtc_interrupt;\n\n\tclock_event_device_uv.mult = div_sc(sn_rtc_cycles_per_second,\n\t\t\t\tNSEC_PER_SEC, clock_event_device_uv.shift);\n\n\tclock_event_device_uv.min_delta_ns = NSEC_PER_SEC /\n\t\t\t\t\t\tsn_rtc_cycles_per_second;\n\tclock_event_device_uv.min_delta_ticks = 1;\n\n\tclock_event_device_uv.max_delta_ns = clocksource_uv.mask *\n\t\t\t\t(NSEC_PER_SEC / sn_rtc_cycles_per_second);\n\tclock_event_device_uv.max_delta_ticks = clocksource_uv.mask;\n\n\trc = schedule_on_each_cpu(uv_rtc_register_clockevents);\n\tif (rc) {\n\t\tx86_platform_ipi_callback = NULL;\n\t\tuv_rtc_deallocate_timers();\n\t\tgoto error;\n\t}\n\n\tprintk(KERN_INFO \"UV RTC clockevents registered\\n\");\n\n\treturn 0;\n\nerror:\n\tclocksource_unregister(&clocksource_uv);\n\tprintk(KERN_INFO \"UV RTC clockevents failed rc %d\\n\", rc);\n\n\treturn rc;\n}\narch_initcall(uv_rtc_setup_clock);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}