{
  "module_name": "spinlock.c",
  "hash_id": "e90f1f4085ca33608c9315f6c335c8fe7392ff5479a3963ae09cee369c080f12",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/xen/spinlock.c",
  "human_readable_source": "\n \n#include <linux/kernel.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/atomic.h>\n\n#include <asm/paravirt.h>\n#include <asm/qspinlock.h>\n\n#include <xen/events.h>\n\n#include \"xen-ops.h\"\n\nstatic DEFINE_PER_CPU(int, lock_kicker_irq) = -1;\nstatic DEFINE_PER_CPU(char *, irq_name);\nstatic DEFINE_PER_CPU(atomic_t, xen_qlock_wait_nest);\nstatic bool xen_pvspin = true;\n\nstatic void xen_qlock_kick(int cpu)\n{\n\tint irq = per_cpu(lock_kicker_irq, cpu);\n\n\t \n\tif (irq == -1)\n\t\treturn;\n\n\txen_send_IPI_one(cpu, XEN_SPIN_UNLOCK_VECTOR);\n}\n\n \nstatic void xen_qlock_wait(u8 *byte, u8 val)\n{\n\tint irq = __this_cpu_read(lock_kicker_irq);\n\tatomic_t *nest_cnt = this_cpu_ptr(&xen_qlock_wait_nest);\n\n\t \n\tif (irq == -1 || in_nmi())\n\t\treturn;\n\n\t \n\tatomic_inc(nest_cnt);\n\n\t \n\tif (atomic_read(nest_cnt) == 1 && xen_test_irq_pending(irq)) {\n\t\txen_clear_irq_pending(irq);\n\t} else if (READ_ONCE(*byte) == val) {\n\t\t \n\t\txen_poll_irq(irq);\n\t}\n\n\tatomic_dec(nest_cnt);\n}\n\nstatic irqreturn_t dummy_handler(int irq, void *dev_id)\n{\n\tBUG();\n\treturn IRQ_HANDLED;\n}\n\nvoid xen_init_lock_cpu(int cpu)\n{\n\tint irq;\n\tchar *name;\n\n\tif (!xen_pvspin)\n\t\treturn;\n\n\tWARN(per_cpu(lock_kicker_irq, cpu) >= 0, \"spinlock on CPU%d exists on IRQ%d!\\n\",\n\t     cpu, per_cpu(lock_kicker_irq, cpu));\n\n\tname = kasprintf(GFP_KERNEL, \"spinlock%d\", cpu);\n\tper_cpu(irq_name, cpu) = name;\n\tirq = bind_ipi_to_irqhandler(XEN_SPIN_UNLOCK_VECTOR,\n\t\t\t\t     cpu,\n\t\t\t\t     dummy_handler,\n\t\t\t\t     IRQF_PERCPU|IRQF_NOBALANCING,\n\t\t\t\t     name,\n\t\t\t\t     NULL);\n\n\tif (irq >= 0) {\n\t\tdisable_irq(irq);  \n\t\tper_cpu(lock_kicker_irq, cpu) = irq;\n\t}\n\n\tprintk(\"cpu %d spinlock event irq %d\\n\", cpu, irq);\n}\n\nvoid xen_uninit_lock_cpu(int cpu)\n{\n\tint irq;\n\n\tif (!xen_pvspin)\n\t\treturn;\n\n\tkfree(per_cpu(irq_name, cpu));\n\tper_cpu(irq_name, cpu) = NULL;\n\t \n\tirq = per_cpu(lock_kicker_irq, cpu);\n\tif (irq == -1)\n\t\treturn;\n\n\tunbind_from_irqhandler(irq, NULL);\n\tper_cpu(lock_kicker_irq, cpu) = -1;\n}\n\nPV_CALLEE_SAVE_REGS_THUNK(xen_vcpu_stolen);\n\n \nvoid __init xen_init_spinlocks(void)\n{\n\t \n\tif (num_possible_cpus() == 1 || nopvspin)\n\t\txen_pvspin = false;\n\n\tif (!xen_pvspin) {\n\t\tprintk(KERN_DEBUG \"xen: PV spinlocks disabled\\n\");\n\t\tstatic_branch_disable(&virt_spin_lock_key);\n\t\treturn;\n\t}\n\tprintk(KERN_DEBUG \"xen: PV spinlocks enabled\\n\");\n\n\t__pv_init_lock_hash();\n\tpv_ops.lock.queued_spin_lock_slowpath = __pv_queued_spin_lock_slowpath;\n\tpv_ops.lock.queued_spin_unlock =\n\t\tPV_CALLEE_SAVE(__pv_queued_spin_unlock);\n\tpv_ops.lock.wait = xen_qlock_wait;\n\tpv_ops.lock.kick = xen_qlock_kick;\n\tpv_ops.lock.vcpu_is_preempted = PV_CALLEE_SAVE(xen_vcpu_stolen);\n}\n\nstatic __init int xen_parse_nopvspin(char *arg)\n{\n\tpr_notice(\"\\\"xen_nopvspin\\\" is deprecated, please use \\\"nopvspin\\\" instead\\n\");\n\txen_pvspin = false;\n\treturn 0;\n}\nearly_param(\"xen_nopvspin\", xen_parse_nopvspin);\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}