{
  "module_name": "enlighten_pv.c",
  "hash_id": "7ccd6b8c5eacf46ac6f086ceea1cb9af897a769f4ddf52064a9c9f9483b5a681",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/xen/enlighten_pv.c",
  "human_readable_source": "\n \n\n#include <linux/cpu.h>\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/preempt.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/delay.h>\n#include <linux/start_kernel.h>\n#include <linux/sched.h>\n#include <linux/kprobes.h>\n#include <linux/kstrtox.h>\n#include <linux/memblock.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/page-flags.h>\n#include <linux/pci.h>\n#include <linux/gfp.h>\n#include <linux/edd.h>\n#include <linux/reboot.h>\n#include <linux/virtio_anchor.h>\n#include <linux/stackprotector.h>\n\n#include <xen/xen.h>\n#include <xen/events.h>\n#include <xen/interface/xen.h>\n#include <xen/interface/version.h>\n#include <xen/interface/physdev.h>\n#include <xen/interface/vcpu.h>\n#include <xen/interface/memory.h>\n#include <xen/interface/nmi.h>\n#include <xen/interface/xen-mca.h>\n#include <xen/features.h>\n#include <xen/page.h>\n#include <xen/hvc-console.h>\n#include <xen/acpi.h>\n\n#include <asm/paravirt.h>\n#include <asm/apic.h>\n#include <asm/page.h>\n#include <asm/xen/pci.h>\n#include <asm/xen/hypercall.h>\n#include <asm/xen/hypervisor.h>\n#include <asm/xen/cpuid.h>\n#include <asm/fixmap.h>\n#include <asm/processor.h>\n#include <asm/proto.h>\n#include <asm/msr-index.h>\n#include <asm/traps.h>\n#include <asm/setup.h>\n#include <asm/desc.h>\n#include <asm/pgalloc.h>\n#include <asm/tlbflush.h>\n#include <asm/reboot.h>\n#include <asm/hypervisor.h>\n#include <asm/mach_traps.h>\n#include <asm/mtrr.h>\n#include <asm/mwait.h>\n#include <asm/pci_x86.h>\n#include <asm/cpu.h>\n#ifdef CONFIG_X86_IOPL_IOPERM\n#include <asm/io_bitmap.h>\n#endif\n\n#ifdef CONFIG_ACPI\n#include <linux/acpi.h>\n#include <asm/acpi.h>\n#include <acpi/proc_cap_intel.h>\n#include <acpi/processor.h>\n#include <xen/interface/platform.h>\n#endif\n\n#include \"xen-ops.h\"\n#include \"mmu.h\"\n#include \"smp.h\"\n#include \"multicalls.h\"\n#include \"pmu.h\"\n\n#include \"../kernel/cpu/cpu.h\"  \n\nvoid *xen_initial_gdt;\n\nstatic int xen_cpu_up_prepare_pv(unsigned int cpu);\nstatic int xen_cpu_dead_pv(unsigned int cpu);\n\nstruct tls_descs {\n\tstruct desc_struct desc[3];\n};\n\nDEFINE_PER_CPU(enum xen_lazy_mode, xen_lazy_mode) = XEN_LAZY_NONE;\nDEFINE_PER_CPU(unsigned int, xen_lazy_nesting);\n\nenum xen_lazy_mode xen_get_lazy_mode(void)\n{\n\tif (in_interrupt())\n\t\treturn XEN_LAZY_NONE;\n\n\treturn this_cpu_read(xen_lazy_mode);\n}\n\n \nstatic DEFINE_PER_CPU(struct tls_descs, shadow_tls_desc);\n\nstatic __read_mostly bool xen_msr_safe = IS_ENABLED(CONFIG_XEN_PV_MSR_SAFE);\n\nstatic int __init parse_xen_msr_safe(char *str)\n{\n\tif (str)\n\t\treturn kstrtobool(str, &xen_msr_safe);\n\treturn -EINVAL;\n}\nearly_param(\"xen_msr_safe\", parse_xen_msr_safe);\n\n \nstatic void __init xen_set_mtrr_data(void)\n{\n#ifdef CONFIG_MTRR\n\tstruct xen_platform_op op = {\n\t\t.cmd = XENPF_read_memtype,\n\t\t.interface_version = XENPF_INTERFACE_VERSION,\n\t};\n\tunsigned int reg;\n\tunsigned long mask;\n\tuint32_t eax, width;\n\tstatic struct mtrr_var_range var[MTRR_MAX_VAR_RANGES] __initdata;\n\n\t \n\twidth = 36;\n\teax = cpuid_eax(0x80000000);\n\tif ((eax >> 16) == 0x8000 && eax >= 0x80000008) {\n\t\teax = cpuid_eax(0x80000008);\n\t\twidth = eax & 0xff;\n\t}\n\n\tfor (reg = 0; reg < MTRR_MAX_VAR_RANGES; reg++) {\n\t\top.u.read_memtype.reg = reg;\n\t\tif (HYPERVISOR_platform_op(&op))\n\t\t\tbreak;\n\n\t\t \n\t\tvar[reg].base_lo = op.u.read_memtype.type;\n\t\tvar[reg].base_lo |= op.u.read_memtype.mfn << PAGE_SHIFT;\n\t\tvar[reg].base_hi = op.u.read_memtype.mfn >> (32 - PAGE_SHIFT);\n\t\tmask = ~((op.u.read_memtype.nr_mfns << PAGE_SHIFT) - 1);\n\t\tmask &= (1UL << width) - 1;\n\t\tif (mask)\n\t\t\tmask |= MTRR_PHYSMASK_V;\n\t\tvar[reg].mask_lo = mask;\n\t\tvar[reg].mask_hi = mask >> 32;\n\t}\n\n\t \n\tif (reg)\n\t\tmtrr_overwrite_state(var, reg, MTRR_TYPE_UNCACHABLE);\n#endif\n}\n\nstatic void __init xen_pv_init_platform(void)\n{\n\t \n\tif (IS_ENABLED(CONFIG_XEN_VIRTIO))\n\t\tvirtio_set_mem_acc_cb(xen_virtio_restricted_mem_acc);\n\n\tpopulate_extra_pte(fix_to_virt(FIX_PARAVIRT_BOOTMAP));\n\n\tset_fixmap(FIX_PARAVIRT_BOOTMAP, xen_start_info->shared_info);\n\tHYPERVISOR_shared_info = (void *)fix_to_virt(FIX_PARAVIRT_BOOTMAP);\n\n\t \n\txen_vcpu_info_reset(0);\n\n\t \n\txen_init_time_ops();\n\n\tif (xen_initial_domain())\n\t\txen_set_mtrr_data();\n\telse\n\t\tmtrr_overwrite_state(NULL, 0, MTRR_TYPE_WRBACK);\n}\n\nstatic void __init xen_pv_guest_late_init(void)\n{\n#ifndef CONFIG_SMP\n\t \n\txen_setup_vcpu_info_placement();\n#endif\n}\n\nstatic __read_mostly unsigned int cpuid_leaf5_ecx_val;\nstatic __read_mostly unsigned int cpuid_leaf5_edx_val;\n\nstatic void xen_cpuid(unsigned int *ax, unsigned int *bx,\n\t\t      unsigned int *cx, unsigned int *dx)\n{\n\tunsigned maskebx = ~0;\n\n\t \n\tswitch (*ax) {\n\tcase CPUID_MWAIT_LEAF:\n\t\t \n\t\t*ax = 0;\n\t\t*bx = 0;\n\t\t*cx = cpuid_leaf5_ecx_val;\n\t\t*dx = cpuid_leaf5_edx_val;\n\t\treturn;\n\n\tcase 0xb:\n\t\t \n\t\tmaskebx = 0;\n\t\tbreak;\n\t}\n\n\tasm(XEN_EMULATE_PREFIX \"cpuid\"\n\t\t: \"=a\" (*ax),\n\t\t  \"=b\" (*bx),\n\t\t  \"=c\" (*cx),\n\t\t  \"=d\" (*dx)\n\t\t: \"0\" (*ax), \"2\" (*cx));\n\n\t*bx &= maskebx;\n}\n\nstatic bool __init xen_check_mwait(void)\n{\n#ifdef CONFIG_ACPI\n\tstruct xen_platform_op op = {\n\t\t.cmd\t\t\t= XENPF_set_processor_pminfo,\n\t\t.u.set_pminfo.id\t= -1,\n\t\t.u.set_pminfo.type\t= XEN_PM_PDC,\n\t};\n\tuint32_t buf[3];\n\tunsigned int ax, bx, cx, dx;\n\tunsigned int mwait_mask;\n\n\t \n\tif (!xen_initial_domain())\n\t\treturn false;\n\n\t \n\tif (!xen_running_on_version_or_later(4, 2))\n\t\treturn false;\n\n\tax = 1;\n\tcx = 0;\n\n\tnative_cpuid(&ax, &bx, &cx, &dx);\n\n\tmwait_mask = (1 << (X86_FEATURE_EST % 32)) |\n\t\t     (1 << (X86_FEATURE_MWAIT % 32));\n\n\tif ((cx & mwait_mask) != mwait_mask)\n\t\treturn false;\n\n\t \n\n\tax = CPUID_MWAIT_LEAF;\n\tbx = 0;\n\tcx = 0;\n\tdx = 0;\n\n\tnative_cpuid(&ax, &bx, &cx, &dx);\n\n\t \n\tbuf[0] = ACPI_PDC_REVISION_ID;\n\tbuf[1] = 1;\n\tbuf[2] = (ACPI_PROC_CAP_C_CAPABILITY_SMP | ACPI_PROC_CAP_EST_CAPABILITY_SWSMP);\n\n\tset_xen_guest_handle(op.u.set_pminfo.pdc, buf);\n\n\tif ((HYPERVISOR_platform_op(&op) == 0) &&\n\t    (buf[2] & (ACPI_PROC_CAP_C_C1_FFH | ACPI_PROC_CAP_C_C2C3_FFH))) {\n\t\tcpuid_leaf5_ecx_val = cx;\n\t\tcpuid_leaf5_edx_val = dx;\n\t}\n\treturn true;\n#else\n\treturn false;\n#endif\n}\n\nstatic bool __init xen_check_xsave(void)\n{\n\tunsigned int cx, xsave_mask;\n\n\tcx = cpuid_ecx(1);\n\n\txsave_mask = (1 << (X86_FEATURE_XSAVE % 32)) |\n\t\t     (1 << (X86_FEATURE_OSXSAVE % 32));\n\n\t \n\treturn (cx & xsave_mask) == xsave_mask;\n}\n\nstatic void __init xen_init_capabilities(void)\n{\n\tsetup_force_cpu_cap(X86_FEATURE_XENPV);\n\tsetup_clear_cpu_cap(X86_FEATURE_DCA);\n\tsetup_clear_cpu_cap(X86_FEATURE_APERFMPERF);\n\tsetup_clear_cpu_cap(X86_FEATURE_MTRR);\n\tsetup_clear_cpu_cap(X86_FEATURE_ACC);\n\tsetup_clear_cpu_cap(X86_FEATURE_X2APIC);\n\tsetup_clear_cpu_cap(X86_FEATURE_SME);\n\tsetup_clear_cpu_cap(X86_FEATURE_LKGS);\n\n\t \n\tsetup_clear_cpu_cap(X86_FEATURE_PCID);\n\n\tif (!xen_initial_domain())\n\t\tsetup_clear_cpu_cap(X86_FEATURE_ACPI);\n\n\tif (xen_check_mwait())\n\t\tsetup_force_cpu_cap(X86_FEATURE_MWAIT);\n\telse\n\t\tsetup_clear_cpu_cap(X86_FEATURE_MWAIT);\n\n\tif (!xen_check_xsave()) {\n\t\tsetup_clear_cpu_cap(X86_FEATURE_XSAVE);\n\t\tsetup_clear_cpu_cap(X86_FEATURE_OSXSAVE);\n\t}\n}\n\nstatic noinstr void xen_set_debugreg(int reg, unsigned long val)\n{\n\tHYPERVISOR_set_debugreg(reg, val);\n}\n\nstatic noinstr unsigned long xen_get_debugreg(int reg)\n{\n\treturn HYPERVISOR_get_debugreg(reg);\n}\n\nstatic void xen_start_context_switch(struct task_struct *prev)\n{\n\tBUG_ON(preemptible());\n\n\tif (this_cpu_read(xen_lazy_mode) == XEN_LAZY_MMU) {\n\t\tarch_leave_lazy_mmu_mode();\n\t\tset_ti_thread_flag(task_thread_info(prev), TIF_LAZY_MMU_UPDATES);\n\t}\n\tenter_lazy(XEN_LAZY_CPU);\n}\n\nstatic void xen_end_context_switch(struct task_struct *next)\n{\n\tBUG_ON(preemptible());\n\n\txen_mc_flush();\n\tleave_lazy(XEN_LAZY_CPU);\n\tif (test_and_clear_ti_thread_flag(task_thread_info(next), TIF_LAZY_MMU_UPDATES))\n\t\tarch_enter_lazy_mmu_mode();\n}\n\nstatic unsigned long xen_store_tr(void)\n{\n\treturn 0;\n}\n\n \nstatic void set_aliased_prot(void *v, pgprot_t prot)\n{\n\tint level;\n\tpte_t *ptep;\n\tpte_t pte;\n\tunsigned long pfn;\n\tunsigned char dummy;\n\tvoid *va;\n\n\tptep = lookup_address((unsigned long)v, &level);\n\tBUG_ON(ptep == NULL);\n\n\tpfn = pte_pfn(*ptep);\n\tpte = pfn_pte(pfn, prot);\n\n\t \n\n\tpreempt_disable();\n\n\tcopy_from_kernel_nofault(&dummy, v, 1);\n\n\tif (HYPERVISOR_update_va_mapping((unsigned long)v, pte, 0))\n\t\tBUG();\n\n\tva = __va(PFN_PHYS(pfn));\n\n\tif (va != v && HYPERVISOR_update_va_mapping((unsigned long)va, pte, 0))\n\t\tBUG();\n\n\tpreempt_enable();\n}\n\nstatic void xen_alloc_ldt(struct desc_struct *ldt, unsigned entries)\n{\n\tconst unsigned entries_per_page = PAGE_SIZE / LDT_ENTRY_SIZE;\n\tint i;\n\n\t \n\n\tfor (i = 0; i < entries; i += entries_per_page)\n\t\tset_aliased_prot(ldt + i, PAGE_KERNEL_RO);\n}\n\nstatic void xen_free_ldt(struct desc_struct *ldt, unsigned entries)\n{\n\tconst unsigned entries_per_page = PAGE_SIZE / LDT_ENTRY_SIZE;\n\tint i;\n\n\tfor (i = 0; i < entries; i += entries_per_page)\n\t\tset_aliased_prot(ldt + i, PAGE_KERNEL);\n}\n\nstatic void xen_set_ldt(const void *addr, unsigned entries)\n{\n\tstruct mmuext_op *op;\n\tstruct multicall_space mcs = xen_mc_entry(sizeof(*op));\n\n\ttrace_xen_cpu_set_ldt(addr, entries);\n\n\top = mcs.args;\n\top->cmd = MMUEXT_SET_LDT;\n\top->arg1.linear_addr = (unsigned long)addr;\n\top->arg2.nr_ents = entries;\n\n\tMULTI_mmuext_op(mcs.mc, op, 1, NULL, DOMID_SELF);\n\n\txen_mc_issue(XEN_LAZY_CPU);\n}\n\nstatic void xen_load_gdt(const struct desc_ptr *dtr)\n{\n\tunsigned long va = dtr->address;\n\tunsigned int size = dtr->size + 1;\n\tunsigned long pfn, mfn;\n\tint level;\n\tpte_t *ptep;\n\tvoid *virt;\n\n\t \n\tBUG_ON(size > PAGE_SIZE);\n\tBUG_ON(va & ~PAGE_MASK);\n\n\t \n\tptep = lookup_address(va, &level);\n\tBUG_ON(ptep == NULL);\n\n\tpfn = pte_pfn(*ptep);\n\tmfn = pfn_to_mfn(pfn);\n\tvirt = __va(PFN_PHYS(pfn));\n\n\tmake_lowmem_page_readonly((void *)va);\n\tmake_lowmem_page_readonly(virt);\n\n\tif (HYPERVISOR_set_gdt(&mfn, size / sizeof(struct desc_struct)))\n\t\tBUG();\n}\n\n \nstatic void __init xen_load_gdt_boot(const struct desc_ptr *dtr)\n{\n\tunsigned long va = dtr->address;\n\tunsigned int size = dtr->size + 1;\n\tunsigned long pfn, mfn;\n\tpte_t pte;\n\n\t \n\tBUG_ON(size > PAGE_SIZE);\n\tBUG_ON(va & ~PAGE_MASK);\n\n\tpfn = virt_to_pfn((void *)va);\n\tmfn = pfn_to_mfn(pfn);\n\n\tpte = pfn_pte(pfn, PAGE_KERNEL_RO);\n\n\tif (HYPERVISOR_update_va_mapping((unsigned long)va, pte, 0))\n\t\tBUG();\n\n\tif (HYPERVISOR_set_gdt(&mfn, size / sizeof(struct desc_struct)))\n\t\tBUG();\n}\n\nstatic inline bool desc_equal(const struct desc_struct *d1,\n\t\t\t      const struct desc_struct *d2)\n{\n\treturn !memcmp(d1, d2, sizeof(*d1));\n}\n\nstatic void load_TLS_descriptor(struct thread_struct *t,\n\t\t\t\tunsigned int cpu, unsigned int i)\n{\n\tstruct desc_struct *shadow = &per_cpu(shadow_tls_desc, cpu).desc[i];\n\tstruct desc_struct *gdt;\n\txmaddr_t maddr;\n\tstruct multicall_space mc;\n\n\tif (desc_equal(shadow, &t->tls_array[i]))\n\t\treturn;\n\n\t*shadow = t->tls_array[i];\n\n\tgdt = get_cpu_gdt_rw(cpu);\n\tmaddr = arbitrary_virt_to_machine(&gdt[GDT_ENTRY_TLS_MIN+i]);\n\tmc = __xen_mc_entry(0);\n\n\tMULTI_update_descriptor(mc.mc, maddr.maddr, t->tls_array[i]);\n}\n\nstatic void xen_load_tls(struct thread_struct *t, unsigned int cpu)\n{\n\t \n\tif (xen_get_lazy_mode() == XEN_LAZY_CPU)\n\t\tloadsegment(fs, 0);\n\n\txen_mc_batch();\n\n\tload_TLS_descriptor(t, cpu, 0);\n\tload_TLS_descriptor(t, cpu, 1);\n\tload_TLS_descriptor(t, cpu, 2);\n\n\txen_mc_issue(XEN_LAZY_CPU);\n}\n\nstatic void xen_load_gs_index(unsigned int idx)\n{\n\tif (HYPERVISOR_set_segment_base(SEGBASE_GS_USER_SEL, idx))\n\t\tBUG();\n}\n\nstatic void xen_write_ldt_entry(struct desc_struct *dt, int entrynum,\n\t\t\t\tconst void *ptr)\n{\n\txmaddr_t mach_lp = arbitrary_virt_to_machine(&dt[entrynum]);\n\tu64 entry = *(u64 *)ptr;\n\n\ttrace_xen_cpu_write_ldt_entry(dt, entrynum, entry);\n\n\tpreempt_disable();\n\n\txen_mc_flush();\n\tif (HYPERVISOR_update_descriptor(mach_lp.maddr, entry))\n\t\tBUG();\n\n\tpreempt_enable();\n}\n\nvoid noist_exc_debug(struct pt_regs *regs);\n\nDEFINE_IDTENTRY_RAW(xenpv_exc_nmi)\n{\n\t \n\texc_nmi(regs);\n}\n\nDEFINE_IDTENTRY_RAW_ERRORCODE(xenpv_exc_double_fault)\n{\n\t \n\texc_double_fault(regs, error_code);\n}\n\nDEFINE_IDTENTRY_RAW(xenpv_exc_debug)\n{\n\t \n\tif (user_mode(regs))\n\t\tnoist_exc_debug(regs);\n\telse\n\t\texc_debug(regs);\n}\n\nDEFINE_IDTENTRY_RAW(exc_xen_unknown_trap)\n{\n\t \n\tinstrumentation_begin();\n\tpr_err(\"Unknown trap in Xen PV mode.\");\n\tBUG();\n\tinstrumentation_end();\n}\n\n#ifdef CONFIG_X86_MCE\nDEFINE_IDTENTRY_RAW(xenpv_exc_machine_check)\n{\n\t \n\tif (user_mode(regs))\n\t\tnoist_exc_machine_check(regs);\n\telse\n\t\texc_machine_check(regs);\n}\n#endif\n\nstruct trap_array_entry {\n\tvoid (*orig)(void);\n\tvoid (*xen)(void);\n\tbool ist_okay;\n};\n\n#define TRAP_ENTRY(func, ist_ok) {\t\t\t\\\n\t.orig\t\t= asm_##func,\t\t\t\\\n\t.xen\t\t= xen_asm_##func,\t\t\\\n\t.ist_okay\t= ist_ok }\n\n#define TRAP_ENTRY_REDIR(func, ist_ok) {\t\t\\\n\t.orig\t\t= asm_##func,\t\t\t\\\n\t.xen\t\t= xen_asm_xenpv_##func,\t\t\\\n\t.ist_okay\t= ist_ok }\n\nstatic struct trap_array_entry trap_array[] = {\n\tTRAP_ENTRY_REDIR(exc_debug,\t\t\ttrue  ),\n\tTRAP_ENTRY_REDIR(exc_double_fault,\t\ttrue  ),\n#ifdef CONFIG_X86_MCE\n\tTRAP_ENTRY_REDIR(exc_machine_check,\t\ttrue  ),\n#endif\n\tTRAP_ENTRY_REDIR(exc_nmi,\t\t\ttrue  ),\n\tTRAP_ENTRY(exc_int3,\t\t\t\tfalse ),\n\tTRAP_ENTRY(exc_overflow,\t\t\tfalse ),\n#ifdef CONFIG_IA32_EMULATION\n\tTRAP_ENTRY(int80_emulation,\t\t\tfalse ),\n#endif\n\tTRAP_ENTRY(exc_page_fault,\t\t\tfalse ),\n\tTRAP_ENTRY(exc_divide_error,\t\t\tfalse ),\n\tTRAP_ENTRY(exc_bounds,\t\t\t\tfalse ),\n\tTRAP_ENTRY(exc_invalid_op,\t\t\tfalse ),\n\tTRAP_ENTRY(exc_device_not_available,\t\tfalse ),\n\tTRAP_ENTRY(exc_coproc_segment_overrun,\t\tfalse ),\n\tTRAP_ENTRY(exc_invalid_tss,\t\t\tfalse ),\n\tTRAP_ENTRY(exc_segment_not_present,\t\tfalse ),\n\tTRAP_ENTRY(exc_stack_segment,\t\t\tfalse ),\n\tTRAP_ENTRY(exc_general_protection,\t\tfalse ),\n\tTRAP_ENTRY(exc_spurious_interrupt_bug,\t\tfalse ),\n\tTRAP_ENTRY(exc_coprocessor_error,\t\tfalse ),\n\tTRAP_ENTRY(exc_alignment_check,\t\t\tfalse ),\n\tTRAP_ENTRY(exc_simd_coprocessor_error,\t\tfalse ),\n#ifdef CONFIG_X86_CET\n\tTRAP_ENTRY(exc_control_protection,\t\tfalse ),\n#endif\n};\n\nstatic bool __ref get_trap_addr(void **addr, unsigned int ist)\n{\n\tunsigned int nr;\n\tbool ist_okay = false;\n\tbool found = false;\n\n\t \n\tfor (nr = 0; nr < ARRAY_SIZE(trap_array); nr++) {\n\t\tstruct trap_array_entry *entry = trap_array + nr;\n\n\t\tif (*addr == entry->orig) {\n\t\t\t*addr = entry->xen;\n\t\t\tist_okay = entry->ist_okay;\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (nr == ARRAY_SIZE(trap_array) &&\n\t    *addr >= (void *)early_idt_handler_array[0] &&\n\t    *addr < (void *)early_idt_handler_array[NUM_EXCEPTION_VECTORS]) {\n\t\tnr = (*addr - (void *)early_idt_handler_array[0]) /\n\t\t     EARLY_IDT_HANDLER_SIZE;\n\t\t*addr = (void *)xen_early_idt_handler_array[nr];\n\t\tfound = true;\n\t}\n\n\tif (!found)\n\t\t*addr = (void *)xen_asm_exc_xen_unknown_trap;\n\n\tif (WARN_ON(found && ist != 0 && !ist_okay))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int cvt_gate_to_trap(int vector, const gate_desc *val,\n\t\t\t    struct trap_info *info)\n{\n\tunsigned long addr;\n\n\tif (val->bits.type != GATE_TRAP && val->bits.type != GATE_INTERRUPT)\n\t\treturn 0;\n\n\tinfo->vector = vector;\n\n\taddr = gate_offset(val);\n\tif (!get_trap_addr((void **)&addr, val->bits.ist))\n\t\treturn 0;\n\tinfo->address = addr;\n\n\tinfo->cs = gate_segment(val);\n\tinfo->flags = val->bits.dpl;\n\t \n\tif (val->bits.type == GATE_INTERRUPT)\n\t\tinfo->flags |= 1 << 2;\n\n\treturn 1;\n}\n\n \nstatic DEFINE_PER_CPU(struct desc_ptr, idt_desc);\n\n \nstatic void xen_write_idt_entry(gate_desc *dt, int entrynum, const gate_desc *g)\n{\n\tunsigned long p = (unsigned long)&dt[entrynum];\n\tunsigned long start, end;\n\n\ttrace_xen_cpu_write_idt_entry(dt, entrynum, g);\n\n\tpreempt_disable();\n\n\tstart = __this_cpu_read(idt_desc.address);\n\tend = start + __this_cpu_read(idt_desc.size) + 1;\n\n\txen_mc_flush();\n\n\tnative_write_idt_entry(dt, entrynum, g);\n\n\tif (p >= start && (p + 8) <= end) {\n\t\tstruct trap_info info[2];\n\n\t\tinfo[1].address = 0;\n\n\t\tif (cvt_gate_to_trap(entrynum, g, &info[0]))\n\t\t\tif (HYPERVISOR_set_trap_table(info))\n\t\t\t\tBUG();\n\t}\n\n\tpreempt_enable();\n}\n\nstatic unsigned xen_convert_trap_info(const struct desc_ptr *desc,\n\t\t\t\t      struct trap_info *traps, bool full)\n{\n\tunsigned in, out, count;\n\n\tcount = (desc->size+1) / sizeof(gate_desc);\n\tBUG_ON(count > 256);\n\n\tfor (in = out = 0; in < count; in++) {\n\t\tgate_desc *entry = (gate_desc *)(desc->address) + in;\n\n\t\tif (cvt_gate_to_trap(in, entry, &traps[out]) || full)\n\t\t\tout++;\n\t}\n\n\treturn out;\n}\n\nvoid xen_copy_trap_info(struct trap_info *traps)\n{\n\tconst struct desc_ptr *desc = this_cpu_ptr(&idt_desc);\n\n\txen_convert_trap_info(desc, traps, true);\n}\n\n \nstatic void xen_load_idt(const struct desc_ptr *desc)\n{\n\tstatic DEFINE_SPINLOCK(lock);\n\tstatic struct trap_info traps[257];\n\tstatic const struct trap_info zero = { };\n\tunsigned out;\n\n\ttrace_xen_cpu_load_idt(desc);\n\n\tspin_lock(&lock);\n\n\tmemcpy(this_cpu_ptr(&idt_desc), desc, sizeof(idt_desc));\n\n\tout = xen_convert_trap_info(desc, traps, false);\n\ttraps[out] = zero;\n\n\txen_mc_flush();\n\tif (HYPERVISOR_set_trap_table(traps))\n\t\tBUG();\n\n\tspin_unlock(&lock);\n}\n\n \nstatic void xen_write_gdt_entry(struct desc_struct *dt, int entry,\n\t\t\t\tconst void *desc, int type)\n{\n\ttrace_xen_cpu_write_gdt_entry(dt, entry, desc, type);\n\n\tpreempt_disable();\n\n\tswitch (type) {\n\tcase DESC_LDT:\n\tcase DESC_TSS:\n\t\t \n\t\tbreak;\n\n\tdefault: {\n\t\txmaddr_t maddr = arbitrary_virt_to_machine(&dt[entry]);\n\n\t\txen_mc_flush();\n\t\tif (HYPERVISOR_update_descriptor(maddr.maddr, *(u64 *)desc))\n\t\t\tBUG();\n\t}\n\n\t}\n\n\tpreempt_enable();\n}\n\n \nstatic void __init xen_write_gdt_entry_boot(struct desc_struct *dt, int entry,\n\t\t\t\t\t    const void *desc, int type)\n{\n\ttrace_xen_cpu_write_gdt_entry(dt, entry, desc, type);\n\n\tswitch (type) {\n\tcase DESC_LDT:\n\tcase DESC_TSS:\n\t\t \n\t\tbreak;\n\n\tdefault: {\n\t\txmaddr_t maddr = virt_to_machine(&dt[entry]);\n\n\t\tif (HYPERVISOR_update_descriptor(maddr.maddr, *(u64 *)desc))\n\t\t\tdt[entry] = *(struct desc_struct *)desc;\n\t}\n\n\t}\n}\n\nstatic void xen_load_sp0(unsigned long sp0)\n{\n\tstruct multicall_space mcs;\n\n\tmcs = xen_mc_entry(0);\n\tMULTI_stack_switch(mcs.mc, __KERNEL_DS, sp0);\n\txen_mc_issue(XEN_LAZY_CPU);\n\tthis_cpu_write(cpu_tss_rw.x86_tss.sp0, sp0);\n}\n\n#ifdef CONFIG_X86_IOPL_IOPERM\nstatic void xen_invalidate_io_bitmap(void)\n{\n\tstruct physdev_set_iobitmap iobitmap = {\n\t\t.bitmap = NULL,\n\t\t.nr_ports = 0,\n\t};\n\n\tnative_tss_invalidate_io_bitmap();\n\tHYPERVISOR_physdev_op(PHYSDEVOP_set_iobitmap, &iobitmap);\n}\n\nstatic void xen_update_io_bitmap(void)\n{\n\tstruct physdev_set_iobitmap iobitmap;\n\tstruct tss_struct *tss = this_cpu_ptr(&cpu_tss_rw);\n\n\tnative_tss_update_io_bitmap();\n\n\tiobitmap.bitmap = (uint8_t *)(&tss->x86_tss) +\n\t\t\t  tss->x86_tss.io_bitmap_base;\n\tif (tss->x86_tss.io_bitmap_base == IO_BITMAP_OFFSET_INVALID)\n\t\tiobitmap.nr_ports = 0;\n\telse\n\t\tiobitmap.nr_ports = IO_BITMAP_BITS;\n\n\tHYPERVISOR_physdev_op(PHYSDEVOP_set_iobitmap, &iobitmap);\n}\n#endif\n\nstatic void xen_io_delay(void)\n{\n}\n\nstatic DEFINE_PER_CPU(unsigned long, xen_cr0_value);\n\nstatic unsigned long xen_read_cr0(void)\n{\n\tunsigned long cr0 = this_cpu_read(xen_cr0_value);\n\n\tif (unlikely(cr0 == 0)) {\n\t\tcr0 = native_read_cr0();\n\t\tthis_cpu_write(xen_cr0_value, cr0);\n\t}\n\n\treturn cr0;\n}\n\nstatic void xen_write_cr0(unsigned long cr0)\n{\n\tstruct multicall_space mcs;\n\n\tthis_cpu_write(xen_cr0_value, cr0);\n\n\t \n\tmcs = xen_mc_entry(0);\n\n\tMULTI_fpu_taskswitch(mcs.mc, (cr0 & X86_CR0_TS) != 0);\n\n\txen_mc_issue(XEN_LAZY_CPU);\n}\n\nstatic void xen_write_cr4(unsigned long cr4)\n{\n\tcr4 &= ~(X86_CR4_PGE | X86_CR4_PSE | X86_CR4_PCE);\n\n\tnative_write_cr4(cr4);\n}\n\nstatic u64 xen_do_read_msr(unsigned int msr, int *err)\n{\n\tu64 val = 0;\t \n\n\tif (pmu_msr_read(msr, &val, err))\n\t\treturn val;\n\n\tif (err)\n\t\tval = native_read_msr_safe(msr, err);\n\telse\n\t\tval = native_read_msr(msr);\n\n\tswitch (msr) {\n\tcase MSR_IA32_APICBASE:\n\t\tval &= ~X2APIC_ENABLE;\n\t\tbreak;\n\t}\n\treturn val;\n}\n\nstatic void set_seg(unsigned int which, unsigned int low, unsigned int high,\n\t\t    int *err)\n{\n\tu64 base = ((u64)high << 32) | low;\n\n\tif (HYPERVISOR_set_segment_base(which, base) == 0)\n\t\treturn;\n\n\tif (err)\n\t\t*err = -EIO;\n\telse\n\t\tWARN(1, \"Xen set_segment_base(%u, %llx) failed\\n\", which, base);\n}\n\n \nstatic void xen_do_write_msr(unsigned int msr, unsigned int low,\n\t\t\t     unsigned int high, int *err)\n{\n\tswitch (msr) {\n\tcase MSR_FS_BASE:\n\t\tset_seg(SEGBASE_FS, low, high, err);\n\t\tbreak;\n\n\tcase MSR_KERNEL_GS_BASE:\n\t\tset_seg(SEGBASE_GS_USER, low, high, err);\n\t\tbreak;\n\n\tcase MSR_GS_BASE:\n\t\tset_seg(SEGBASE_GS_KERNEL, low, high, err);\n\t\tbreak;\n\n\tcase MSR_STAR:\n\tcase MSR_CSTAR:\n\tcase MSR_LSTAR:\n\tcase MSR_SYSCALL_MASK:\n\tcase MSR_IA32_SYSENTER_CS:\n\tcase MSR_IA32_SYSENTER_ESP:\n\tcase MSR_IA32_SYSENTER_EIP:\n\t\t \n\t\tbreak;\n\n\tdefault:\n\t\tif (!pmu_msr_write(msr, low, high, err)) {\n\t\t\tif (err)\n\t\t\t\t*err = native_write_msr_safe(msr, low, high);\n\t\t\telse\n\t\t\t\tnative_write_msr(msr, low, high);\n\t\t}\n\t}\n}\n\nstatic u64 xen_read_msr_safe(unsigned int msr, int *err)\n{\n\treturn xen_do_read_msr(msr, err);\n}\n\nstatic int xen_write_msr_safe(unsigned int msr, unsigned int low,\n\t\t\t      unsigned int high)\n{\n\tint err = 0;\n\n\txen_do_write_msr(msr, low, high, &err);\n\n\treturn err;\n}\n\nstatic u64 xen_read_msr(unsigned int msr)\n{\n\tint err;\n\n\treturn xen_do_read_msr(msr, xen_msr_safe ? &err : NULL);\n}\n\nstatic void xen_write_msr(unsigned int msr, unsigned low, unsigned high)\n{\n\tint err;\n\n\txen_do_write_msr(msr, low, high, xen_msr_safe ? &err : NULL);\n}\n\n \nvoid __init xen_setup_vcpu_info_placement(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\t \n\t\tper_cpu(xen_vcpu_id, cpu) = cpu;\n\t\txen_vcpu_setup(cpu);\n\t}\n\n\tpv_ops.irq.save_fl = __PV_IS_CALLEE_SAVE(xen_save_fl_direct);\n\tpv_ops.irq.irq_disable = __PV_IS_CALLEE_SAVE(xen_irq_disable_direct);\n\tpv_ops.irq.irq_enable = __PV_IS_CALLEE_SAVE(xen_irq_enable_direct);\n\tpv_ops.mmu.read_cr2 = __PV_IS_CALLEE_SAVE(xen_read_cr2_direct);\n}\n\nstatic const struct pv_info xen_info __initconst = {\n\t.extra_user_64bit_cs = FLAT_USER_CS64,\n\t.name = \"Xen\",\n};\n\nstatic const typeof(pv_ops) xen_cpu_ops __initconst = {\n\t.cpu = {\n\t\t.cpuid = xen_cpuid,\n\n\t\t.set_debugreg = xen_set_debugreg,\n\t\t.get_debugreg = xen_get_debugreg,\n\n\t\t.read_cr0 = xen_read_cr0,\n\t\t.write_cr0 = xen_write_cr0,\n\n\t\t.write_cr4 = xen_write_cr4,\n\n\t\t.wbinvd = pv_native_wbinvd,\n\n\t\t.read_msr = xen_read_msr,\n\t\t.write_msr = xen_write_msr,\n\n\t\t.read_msr_safe = xen_read_msr_safe,\n\t\t.write_msr_safe = xen_write_msr_safe,\n\n\t\t.read_pmc = xen_read_pmc,\n\n\t\t.load_tr_desc = paravirt_nop,\n\t\t.set_ldt = xen_set_ldt,\n\t\t.load_gdt = xen_load_gdt,\n\t\t.load_idt = xen_load_idt,\n\t\t.load_tls = xen_load_tls,\n\t\t.load_gs_index = xen_load_gs_index,\n\n\t\t.alloc_ldt = xen_alloc_ldt,\n\t\t.free_ldt = xen_free_ldt,\n\n\t\t.store_tr = xen_store_tr,\n\n\t\t.write_ldt_entry = xen_write_ldt_entry,\n\t\t.write_gdt_entry = xen_write_gdt_entry,\n\t\t.write_idt_entry = xen_write_idt_entry,\n\t\t.load_sp0 = xen_load_sp0,\n\n#ifdef CONFIG_X86_IOPL_IOPERM\n\t\t.invalidate_io_bitmap = xen_invalidate_io_bitmap,\n\t\t.update_io_bitmap = xen_update_io_bitmap,\n#endif\n\t\t.io_delay = xen_io_delay,\n\n\t\t.start_context_switch = xen_start_context_switch,\n\t\t.end_context_switch = xen_end_context_switch,\n\t},\n};\n\nstatic void xen_restart(char *msg)\n{\n\txen_reboot(SHUTDOWN_reboot);\n}\n\nstatic void xen_machine_halt(void)\n{\n\txen_reboot(SHUTDOWN_poweroff);\n}\n\nstatic void xen_machine_power_off(void)\n{\n\tdo_kernel_power_off();\n\txen_reboot(SHUTDOWN_poweroff);\n}\n\nstatic void xen_crash_shutdown(struct pt_regs *regs)\n{\n\txen_reboot(SHUTDOWN_crash);\n}\n\nstatic const struct machine_ops xen_machine_ops __initconst = {\n\t.restart = xen_restart,\n\t.halt = xen_machine_halt,\n\t.power_off = xen_machine_power_off,\n\t.shutdown = xen_machine_halt,\n\t.crash_shutdown = xen_crash_shutdown,\n\t.emergency_restart = xen_emergency_restart,\n};\n\nstatic unsigned char xen_get_nmi_reason(void)\n{\n\tunsigned char reason = 0;\n\n\t \n\tif (test_bit(_XEN_NMIREASON_io_error,\n\t\t     &HYPERVISOR_shared_info->arch.nmi_reason))\n\t\treason |= NMI_REASON_IOCHK;\n\tif (test_bit(_XEN_NMIREASON_pci_serr,\n\t\t     &HYPERVISOR_shared_info->arch.nmi_reason))\n\t\treason |= NMI_REASON_SERR;\n\n\treturn reason;\n}\n\nstatic void __init xen_boot_params_init_edd(void)\n{\n#if IS_ENABLED(CONFIG_EDD)\n\tstruct xen_platform_op op;\n\tstruct edd_info *edd_info;\n\tu32 *mbr_signature;\n\tunsigned nr;\n\tint ret;\n\n\tedd_info = boot_params.eddbuf;\n\tmbr_signature = boot_params.edd_mbr_sig_buffer;\n\n\top.cmd = XENPF_firmware_info;\n\n\top.u.firmware_info.type = XEN_FW_DISK_INFO;\n\tfor (nr = 0; nr < EDDMAXNR; nr++) {\n\t\tstruct edd_info *info = edd_info + nr;\n\n\t\top.u.firmware_info.index = nr;\n\t\tinfo->params.length = sizeof(info->params);\n\t\tset_xen_guest_handle(op.u.firmware_info.u.disk_info.edd_params,\n\t\t\t\t     &info->params);\n\t\tret = HYPERVISOR_platform_op(&op);\n\t\tif (ret)\n\t\t\tbreak;\n\n#define C(x) info->x = op.u.firmware_info.u.disk_info.x\n\t\tC(device);\n\t\tC(version);\n\t\tC(interface_support);\n\t\tC(legacy_max_cylinder);\n\t\tC(legacy_max_head);\n\t\tC(legacy_sectors_per_track);\n#undef C\n\t}\n\tboot_params.eddbuf_entries = nr;\n\n\top.u.firmware_info.type = XEN_FW_DISK_MBR_SIGNATURE;\n\tfor (nr = 0; nr < EDD_MBR_SIG_MAX; nr++) {\n\t\top.u.firmware_info.index = nr;\n\t\tret = HYPERVISOR_platform_op(&op);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tmbr_signature[nr] = op.u.firmware_info.u.disk_mbr_signature.mbr_signature;\n\t}\n\tboot_params.edd_mbr_sig_buf_entries = nr;\n#endif\n}\n\n \nstatic void __init xen_setup_gdt(int cpu)\n{\n\tpv_ops.cpu.write_gdt_entry = xen_write_gdt_entry_boot;\n\tpv_ops.cpu.load_gdt = xen_load_gdt_boot;\n\n\tswitch_gdt_and_percpu_base(cpu);\n\n\tpv_ops.cpu.write_gdt_entry = xen_write_gdt_entry;\n\tpv_ops.cpu.load_gdt = xen_load_gdt;\n}\n\nstatic void __init xen_dom0_set_legacy_features(void)\n{\n\tx86_platform.legacy.rtc = 1;\n}\n\nstatic void __init xen_domu_set_legacy_features(void)\n{\n\tx86_platform.legacy.rtc = 0;\n}\n\nextern void early_xen_iret_patch(void);\n\n \nasmlinkage __visible void __init xen_start_kernel(struct start_info *si)\n{\n\tstruct physdev_set_iopl set_iopl;\n\tunsigned long initrd_start = 0;\n\tint rc;\n\n\tif (!si)\n\t\treturn;\n\n\tclear_bss();\n\n\txen_start_info = si;\n\n\t__text_gen_insn(&early_xen_iret_patch,\n\t\t\tJMP32_INSN_OPCODE, &early_xen_iret_patch, &xen_iret,\n\t\t\tJMP32_INSN_SIZE);\n\n\txen_domain_type = XEN_PV_DOMAIN;\n\txen_start_flags = xen_start_info->flags;\n\n\txen_setup_features();\n\n\t \n\tpv_info = xen_info;\n\tpv_ops.cpu = xen_cpu_ops.cpu;\n\txen_init_irq_ops();\n\n\t \n\txen_vcpu_info_reset(0);\n\n\tx86_platform.get_nmi_reason = xen_get_nmi_reason;\n\tx86_platform.realmode_reserve = x86_init_noop;\n\tx86_platform.realmode_init = x86_init_noop;\n\n\tx86_init.resources.memory_setup = xen_memory_setup;\n\tx86_init.irqs.intr_mode_select\t= x86_init_noop;\n\tx86_init.irqs.intr_mode_init\t= x86_64_probe_apic;\n\tx86_init.oem.arch_setup = xen_arch_setup;\n\tx86_init.oem.banner = xen_banner;\n\tx86_init.hyper.init_platform = xen_pv_init_platform;\n\tx86_init.hyper.guest_late_init = xen_pv_guest_late_init;\n\n\t \n\n\txen_setup_machphys_mapping();\n\txen_init_mmu_ops();\n\n\t \n\t__supported_pte_mask &= ~_PAGE_GLOBAL;\n\t__default_kernel_pte_mask &= ~_PAGE_GLOBAL;\n\n\t \n\txen_build_dynamic_phys_to_machine();\n\n\t \n\tget_cpu_cap(&boot_cpu_data);\n\tx86_configure_nx();\n\n\t \n\txen_setup_gdt(0);\n\n\t \n\tget_cpu_address_sizes(&boot_cpu_data);\n\n\t \n\tper_cpu(xen_vcpu_id, 0) = 0;\n\n\tidt_setup_early_handler();\n\n\txen_init_capabilities();\n\n\t \n\txen_init_apic();\n\n\tmachine_ops = xen_machine_ops;\n\n\t \n\txen_initial_gdt = &per_cpu(gdt_page, 0);\n\n\txen_smp_init();\n\n#ifdef CONFIG_ACPI_NUMA\n\t \n\tdisable_srat();\n#endif\n\tWARN_ON(xen_cpuhp_setup(xen_cpu_up_prepare_pv, xen_cpu_dead_pv));\n\n\tlocal_irq_disable();\n\tearly_boot_irqs_disabled = true;\n\n\txen_raw_console_write(\"mapping kernel into physical memory\\n\");\n\txen_setup_kernel_pagetable((pgd_t *)xen_start_info->pt_base,\n\t\t\t\t   xen_start_info->nr_pages);\n\txen_reserve_special_pages();\n\n\t \n\tset_iopl.iopl = 1;\n\trc = HYPERVISOR_physdev_op(PHYSDEVOP_set_iopl, &set_iopl);\n\tif (rc != 0)\n\t\txen_raw_printk(\"physdev_op failed %d\\n\", rc);\n\n\n\tif (xen_start_info->mod_start) {\n\t    if (xen_start_info->flags & SIF_MOD_START_PFN)\n\t\tinitrd_start = PFN_PHYS(xen_start_info->mod_start);\n\t    else\n\t\tinitrd_start = __pa(xen_start_info->mod_start);\n\t}\n\n\t \n\tboot_params.hdr.type_of_loader = (9 << 4) | 0;\n\tboot_params.hdr.ramdisk_image = initrd_start;\n\tboot_params.hdr.ramdisk_size = xen_start_info->mod_len;\n\tboot_params.hdr.cmd_line_ptr = __pa(xen_start_info->cmd_line);\n\tboot_params.hdr.hardware_subarch = X86_SUBARCH_XEN;\n\n\tif (!xen_initial_domain()) {\n\t\tif (pci_xen)\n\t\t\tx86_init.pci.arch_init = pci_xen_init;\n\t\tx86_platform.set_legacy_features =\n\t\t\t\txen_domu_set_legacy_features;\n\t} else {\n\t\tconst struct dom0_vga_console_info *info =\n\t\t\t(void *)((char *)xen_start_info +\n\t\t\t\t xen_start_info->console.dom0.info_off);\n\t\tstruct xen_platform_op op = {\n\t\t\t.cmd = XENPF_firmware_info,\n\t\t\t.interface_version = XENPF_INTERFACE_VERSION,\n\t\t\t.u.firmware_info.type = XEN_FW_KBD_SHIFT_FLAGS,\n\t\t};\n\n\t\tx86_platform.set_legacy_features =\n\t\t\t\txen_dom0_set_legacy_features;\n\t\txen_init_vga(info, xen_start_info->console.dom0.info_size,\n\t\t\t     &boot_params.screen_info);\n\t\txen_start_info->console.domU.mfn = 0;\n\t\txen_start_info->console.domU.evtchn = 0;\n\n\t\tif (HYPERVISOR_platform_op(&op) == 0)\n\t\t\tboot_params.kbd_status = op.u.firmware_info.u.kbd_shift_flags;\n\n\t\t \n\t\tpci_request_acs();\n\n\t\txen_acpi_sleep_register();\n\n\t\txen_boot_params_init_edd();\n\n#ifdef CONFIG_ACPI\n\t\t \n\t\tacpi_disable_cmcff = 1;\n#endif\n\t}\n\n\txen_add_preferred_consoles();\n\n#ifdef CONFIG_PCI\n\t \n\tpci_probe &= ~PCI_PROBE_BIOS;\n#endif\n\txen_raw_console_write(\"about to get started...\\n\");\n\n\t \n\txen_setup_runstate_info(0);\n\n\txen_efi_init(&boot_params);\n\n\t \n\tcr4_init_shadow();  \n\tx86_64_start_reservations((char *)__pa_symbol(&boot_params));\n}\n\nstatic int xen_cpu_up_prepare_pv(unsigned int cpu)\n{\n\tint rc;\n\n\tif (per_cpu(xen_vcpu, cpu) == NULL)\n\t\treturn -ENODEV;\n\n\txen_setup_timer(cpu);\n\n\trc = xen_smp_intr_init(cpu);\n\tif (rc) {\n\t\tWARN(1, \"xen_smp_intr_init() for CPU %d failed: %d\\n\",\n\t\t     cpu, rc);\n\t\treturn rc;\n\t}\n\n\trc = xen_smp_intr_init_pv(cpu);\n\tif (rc) {\n\t\tWARN(1, \"xen_smp_intr_init_pv() for CPU %d failed: %d\\n\",\n\t\t     cpu, rc);\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int xen_cpu_dead_pv(unsigned int cpu)\n{\n\txen_smp_intr_free(cpu);\n\txen_smp_intr_free_pv(cpu);\n\n\txen_teardown_timer(cpu);\n\n\treturn 0;\n}\n\nstatic uint32_t __init xen_platform_pv(void)\n{\n\tif (xen_pv_domain())\n\t\treturn xen_cpuid_base();\n\n\treturn 0;\n}\n\nconst __initconst struct hypervisor_x86 x86_hyper_xen_pv = {\n\t.name                   = \"Xen PV\",\n\t.detect                 = xen_platform_pv,\n\t.type\t\t\t= X86_HYPER_XEN_PV,\n\t.runtime.pin_vcpu       = xen_pin_vcpu,\n\t.ignore_nopv\t\t= true,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}