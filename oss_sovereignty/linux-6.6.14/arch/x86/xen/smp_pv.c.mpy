{
  "module_name": "smp_pv.c",
  "hash_id": "52f4cb5ec1f1b75a94d78346c9a64ab7fda3f6ee966205c0ff53710407126cf3",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/xen/smp_pv.c",
  "human_readable_source": "\n \n#include <linux/sched.h>\n#include <linux/sched/task_stack.h>\n#include <linux/err.h>\n#include <linux/slab.h>\n#include <linux/smp.h>\n#include <linux/irq_work.h>\n#include <linux/tick.h>\n#include <linux/nmi.h>\n#include <linux/cpuhotplug.h>\n#include <linux/stackprotector.h>\n#include <linux/pgtable.h>\n\n#include <asm/paravirt.h>\n#include <asm/idtentry.h>\n#include <asm/desc.h>\n#include <asm/cpu.h>\n#include <asm/io_apic.h>\n\n#include <xen/interface/xen.h>\n#include <xen/interface/vcpu.h>\n#include <xen/interface/xenpmu.h>\n\n#include <asm/spec-ctrl.h>\n#include <asm/xen/interface.h>\n#include <asm/xen/hypercall.h>\n\n#include <xen/xen.h>\n#include <xen/page.h>\n#include <xen/events.h>\n\n#include <xen/hvc-console.h>\n#include \"xen-ops.h\"\n#include \"mmu.h\"\n#include \"smp.h\"\n#include \"pmu.h\"\n\ncpumask_var_t xen_cpu_initialized_map;\n\nstatic DEFINE_PER_CPU(struct xen_common_irq, xen_irq_work) = { .irq = -1 };\nstatic DEFINE_PER_CPU(struct xen_common_irq, xen_pmu_irq) = { .irq = -1 };\n\nstatic irqreturn_t xen_irq_work_interrupt(int irq, void *dev_id);\n\nstatic void cpu_bringup(void)\n{\n\tint cpu;\n\n\tcr4_init();\n\tcpuhp_ap_sync_alive();\n\tcpu_init();\n\tfpu__init_cpu();\n\ttouch_softlockup_watchdog();\n\n\t \n\tif (!xen_feature(XENFEAT_supervisor_mode_kernel)) {\n\t\txen_enable_sysenter();\n\t\txen_enable_syscall();\n\t}\n\tcpu = smp_processor_id();\n\tsmp_store_cpu_info(cpu);\n\tcpu_data(cpu).x86_max_cores = 1;\n\tset_cpu_sibling_map(cpu);\n\n\tspeculative_store_bypass_ht_init();\n\n\txen_setup_cpu_clockevents();\n\n\tnotify_cpu_starting(cpu);\n\n\tset_cpu_online(cpu, true);\n\n\tsmp_mb();\n\n\t \n\tlocal_irq_enable();\n}\n\nasmlinkage __visible void cpu_bringup_and_idle(void)\n{\n\tcpu_bringup();\n\tcpu_startup_entry(CPUHP_AP_ONLINE_IDLE);\n}\n\nvoid xen_smp_intr_free_pv(unsigned int cpu)\n{\n\tkfree(per_cpu(xen_irq_work, cpu).name);\n\tper_cpu(xen_irq_work, cpu).name = NULL;\n\tif (per_cpu(xen_irq_work, cpu).irq >= 0) {\n\t\tunbind_from_irqhandler(per_cpu(xen_irq_work, cpu).irq, NULL);\n\t\tper_cpu(xen_irq_work, cpu).irq = -1;\n\t}\n\n\tkfree(per_cpu(xen_pmu_irq, cpu).name);\n\tper_cpu(xen_pmu_irq, cpu).name = NULL;\n\tif (per_cpu(xen_pmu_irq, cpu).irq >= 0) {\n\t\tunbind_from_irqhandler(per_cpu(xen_pmu_irq, cpu).irq, NULL);\n\t\tper_cpu(xen_pmu_irq, cpu).irq = -1;\n\t}\n}\n\nint xen_smp_intr_init_pv(unsigned int cpu)\n{\n\tint rc;\n\tchar *callfunc_name, *pmu_name;\n\n\tcallfunc_name = kasprintf(GFP_KERNEL, \"irqwork%d\", cpu);\n\tper_cpu(xen_irq_work, cpu).name = callfunc_name;\n\trc = bind_ipi_to_irqhandler(XEN_IRQ_WORK_VECTOR,\n\t\t\t\t    cpu,\n\t\t\t\t    xen_irq_work_interrupt,\n\t\t\t\t    IRQF_PERCPU|IRQF_NOBALANCING,\n\t\t\t\t    callfunc_name,\n\t\t\t\t    NULL);\n\tif (rc < 0)\n\t\tgoto fail;\n\tper_cpu(xen_irq_work, cpu).irq = rc;\n\n\tif (is_xen_pmu) {\n\t\tpmu_name = kasprintf(GFP_KERNEL, \"pmu%d\", cpu);\n\t\tper_cpu(xen_pmu_irq, cpu).name = pmu_name;\n\t\trc = bind_virq_to_irqhandler(VIRQ_XENPMU, cpu,\n\t\t\t\t\t     xen_pmu_irq_handler,\n\t\t\t\t\t     IRQF_PERCPU|IRQF_NOBALANCING,\n\t\t\t\t\t     pmu_name, NULL);\n\t\tif (rc < 0)\n\t\t\tgoto fail;\n\t\tper_cpu(xen_pmu_irq, cpu).irq = rc;\n\t}\n\n\treturn 0;\n\n fail:\n\txen_smp_intr_free_pv(cpu);\n\treturn rc;\n}\n\nstatic void __init _get_smp_config(unsigned int early)\n{\n\tint i, rc;\n\tunsigned int subtract = 0;\n\n\tif (early)\n\t\treturn;\n\n\tnum_processors = 0;\n\tdisabled_cpus = 0;\n\tfor (i = 0; i < nr_cpu_ids; i++) {\n\t\trc = HYPERVISOR_vcpu_op(VCPUOP_is_up, i, NULL);\n\t\tif (rc >= 0) {\n\t\t\tnum_processors++;\n\t\t\tset_cpu_possible(i, true);\n\t\t} else {\n\t\t\tset_cpu_possible(i, false);\n\t\t\tset_cpu_present(i, false);\n\t\t\tsubtract++;\n\t\t}\n\t}\n#ifdef CONFIG_HOTPLUG_CPU\n\t \n\tif (subtract)\n\t\tset_nr_cpu_ids(nr_cpu_ids - subtract);\n#endif\n\t \n\tsmp_found_config = 1;\n}\n\nstatic void __init xen_pv_smp_prepare_boot_cpu(void)\n{\n\tBUG_ON(smp_processor_id() != 0);\n\tnative_smp_prepare_boot_cpu();\n\n\tif (!xen_feature(XENFEAT_writable_page_tables))\n\t\t \n\t\tmake_lowmem_page_readwrite(xen_initial_gdt);\n\n\txen_setup_vcpu_info_placement();\n\n\t \n\txen_init_spinlocks();\n}\n\nstatic void __init xen_pv_smp_prepare_cpus(unsigned int max_cpus)\n{\n\tunsigned cpu;\n\n\tif (ioapic_is_disabled) {\n\t\tchar *m = (max_cpus == 0) ?\n\t\t\t\"The nosmp parameter is incompatible with Xen; \" \\\n\t\t\t\"use Xen dom0_max_vcpus=1 parameter\" :\n\t\t\t\"The noapic parameter is incompatible with Xen\";\n\n\t\txen_raw_printk(m);\n\t\tpanic(m);\n\t}\n\txen_init_lock_cpu(0);\n\n\tsmp_prepare_cpus_common();\n\n\tcpu_data(0).x86_max_cores = 1;\n\n\tspeculative_store_bypass_ht_init();\n\n\txen_pmu_init(0);\n\n\tif (xen_smp_intr_init(0) || xen_smp_intr_init_pv(0))\n\t\tBUG();\n\n\tif (!alloc_cpumask_var(&xen_cpu_initialized_map, GFP_KERNEL))\n\t\tpanic(\"could not allocate xen_cpu_initialized_map\\n\");\n\n\tcpumask_copy(xen_cpu_initialized_map, cpumask_of(0));\n\n\t \n\twhile ((num_possible_cpus() > 1) && (num_possible_cpus() > max_cpus)) {\n\t\tfor (cpu = nr_cpu_ids - 1; !cpu_possible(cpu); cpu--)\n\t\t\tcontinue;\n\t\tset_cpu_possible(cpu, false);\n\t}\n\n\tfor_each_possible_cpu(cpu)\n\t\tset_cpu_present(cpu, true);\n}\n\nstatic int\ncpu_initialize_context(unsigned int cpu, struct task_struct *idle)\n{\n\tstruct vcpu_guest_context *ctxt;\n\tstruct desc_struct *gdt;\n\tunsigned long gdt_mfn;\n\n\tif (cpumask_test_and_set_cpu(cpu, xen_cpu_initialized_map))\n\t\treturn 0;\n\n\tctxt = kzalloc(sizeof(*ctxt), GFP_KERNEL);\n\tif (ctxt == NULL) {\n\t\tcpumask_clear_cpu(cpu, xen_cpu_initialized_map);\n\t\treturn -ENOMEM;\n\t}\n\n\tgdt = get_cpu_gdt_rw(cpu);\n\n\t \n\tctxt->user_regs.eip = (unsigned long)asm_cpu_bringup_and_idle;\n\tctxt->flags = VGCF_IN_KERNEL;\n\tctxt->user_regs.eflags = 0x1000;  \n\tctxt->user_regs.ds = __USER_DS;\n\tctxt->user_regs.es = __USER_DS;\n\tctxt->user_regs.ss = __KERNEL_DS;\n\tctxt->user_regs.cs = __KERNEL_CS;\n\tctxt->user_regs.esp = (unsigned long)task_pt_regs(idle);\n\n\txen_copy_trap_info(ctxt->trap_ctxt);\n\n\tBUG_ON((unsigned long)gdt & ~PAGE_MASK);\n\n\tgdt_mfn = arbitrary_virt_to_mfn(gdt);\n\tmake_lowmem_page_readonly(gdt);\n\tmake_lowmem_page_readonly(mfn_to_virt(gdt_mfn));\n\n\tctxt->gdt_frames[0] = gdt_mfn;\n\tctxt->gdt_ents      = GDT_ENTRIES;\n\n\t \n\tctxt->kernel_ss = __KERNEL_DS;\n\tctxt->kernel_sp = task_top_of_stack(idle);\n\n\tctxt->gs_base_kernel = per_cpu_offset(cpu);\n\tctxt->event_callback_eip    =\n\t\t(unsigned long)xen_asm_exc_xen_hypervisor_callback;\n\tctxt->failsafe_callback_eip =\n\t\t(unsigned long)xen_failsafe_callback;\n\tper_cpu(xen_cr3, cpu) = __pa(swapper_pg_dir);\n\n\tctxt->ctrlreg[3] = xen_pfn_to_cr3(virt_to_gfn(swapper_pg_dir));\n\tif (HYPERVISOR_vcpu_op(VCPUOP_initialise, xen_vcpu_nr(cpu), ctxt))\n\t\tBUG();\n\n\tkfree(ctxt);\n\treturn 0;\n}\n\nstatic int xen_pv_kick_ap(unsigned int cpu, struct task_struct *idle)\n{\n\tint rc;\n\n\trc = common_cpu_up(cpu, idle);\n\tif (rc)\n\t\treturn rc;\n\n\txen_setup_runstate_info(cpu);\n\n\t \n\tper_cpu(xen_vcpu, cpu)->evtchn_upcall_mask = 1;\n\n\trc = cpu_initialize_context(cpu, idle);\n\tif (rc)\n\t\treturn rc;\n\n\txen_pmu_init(cpu);\n\n\t \n\tBUG_ON(HYPERVISOR_vcpu_op(VCPUOP_up, xen_vcpu_nr(cpu), NULL));\n\n\treturn 0;\n}\n\nstatic void xen_pv_poll_sync_state(void)\n{\n\tHYPERVISOR_sched_op(SCHEDOP_yield, NULL);\n}\n\n#ifdef CONFIG_HOTPLUG_CPU\nstatic int xen_pv_cpu_disable(void)\n{\n\tunsigned int cpu = smp_processor_id();\n\tif (cpu == 0)\n\t\treturn -EBUSY;\n\n\tcpu_disable_common();\n\n\tload_cr3(swapper_pg_dir);\n\treturn 0;\n}\n\nstatic void xen_pv_cpu_die(unsigned int cpu)\n{\n\twhile (HYPERVISOR_vcpu_op(VCPUOP_is_up, xen_vcpu_nr(cpu), NULL)) {\n\t\t__set_current_state(TASK_UNINTERRUPTIBLE);\n\t\tschedule_timeout(HZ/10);\n\t}\n}\n\nstatic void xen_pv_cleanup_dead_cpu(unsigned int cpu)\n{\n\txen_smp_intr_free(cpu);\n\txen_uninit_lock_cpu(cpu);\n\txen_teardown_timer(cpu);\n\txen_pmu_finish(cpu);\n}\n\nstatic void __noreturn xen_pv_play_dead(void)  \n{\n\tplay_dead_common();\n\tHYPERVISOR_vcpu_op(VCPUOP_down, xen_vcpu_nr(smp_processor_id()), NULL);\n\txen_cpu_bringup_again((unsigned long)task_pt_regs(current));\n\tBUG();\n}\n\n#else  \nstatic int xen_pv_cpu_disable(void)\n{\n\treturn -ENOSYS;\n}\n\nstatic void xen_pv_cpu_die(unsigned int cpu)\n{\n\tBUG();\n}\n\nstatic void xen_pv_cleanup_dead_cpu(unsigned int cpu)\n{\n\tBUG();\n}\n\nstatic void __noreturn xen_pv_play_dead(void)\n{\n\tBUG();\n}\n\n#endif\nstatic void stop_self(void *v)\n{\n\tint cpu = smp_processor_id();\n\n\t \n\tload_cr3(swapper_pg_dir);\n\t \n\n\tset_cpu_online(cpu, false);\n\n\tHYPERVISOR_vcpu_op(VCPUOP_down, xen_vcpu_nr(cpu), NULL);\n\tBUG();\n}\n\nstatic void xen_pv_stop_other_cpus(int wait)\n{\n\tsmp_call_function(stop_self, NULL, wait);\n}\n\nstatic irqreturn_t xen_irq_work_interrupt(int irq, void *dev_id)\n{\n\tirq_work_run();\n\tinc_irq_stat(apic_irq_work_irqs);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic const struct smp_ops xen_smp_ops __initconst = {\n\t.smp_prepare_boot_cpu = xen_pv_smp_prepare_boot_cpu,\n\t.smp_prepare_cpus = xen_pv_smp_prepare_cpus,\n\t.smp_cpus_done = xen_smp_cpus_done,\n\n\t.kick_ap_alive = xen_pv_kick_ap,\n\t.cpu_die = xen_pv_cpu_die,\n\t.cleanup_dead_cpu = xen_pv_cleanup_dead_cpu,\n\t.poll_sync_state = xen_pv_poll_sync_state,\n\t.cpu_disable = xen_pv_cpu_disable,\n\t.play_dead = xen_pv_play_dead,\n\n\t.stop_other_cpus = xen_pv_stop_other_cpus,\n\t.smp_send_reschedule = xen_smp_send_reschedule,\n\n\t.send_call_func_ipi = xen_smp_send_call_function_ipi,\n\t.send_call_func_single_ipi = xen_smp_send_call_function_single_ipi,\n};\n\nvoid __init xen_smp_init(void)\n{\n\tsmp_ops = xen_smp_ops;\n\n\t \n\tx86_init.mpparse.find_smp_config = x86_init_noop;\n\tx86_init.mpparse.get_smp_config = _get_smp_config;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}