{
  "module_name": "bpf_jit_comp32.c",
  "hash_id": "7a1b0ddd008a885014a43759c6927c68d83afa3f08cdb22866bf02b6546b60c2",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/net/bpf_jit_comp32.c",
  "human_readable_source": "\n \n\n#include <linux/netdevice.h>\n#include <linux/filter.h>\n#include <linux/if_vlan.h>\n#include <asm/cacheflush.h>\n#include <asm/set_memory.h>\n#include <asm/nospec-branch.h>\n#include <asm/asm-prototypes.h>\n#include <linux/bpf.h>\n\n \n\nstatic u8 *emit_code(u8 *ptr, u32 bytes, unsigned int len)\n{\n\tif (len == 1)\n\t\t*ptr = bytes;\n\telse if (len == 2)\n\t\t*(u16 *)ptr = bytes;\n\telse {\n\t\t*(u32 *)ptr = bytes;\n\t\tbarrier();\n\t}\n\treturn ptr + len;\n}\n\n#define EMIT(bytes, len) \\\n\tdo { prog = emit_code(prog, bytes, len); cnt += len; } while (0)\n\n#define EMIT1(b1)\t\tEMIT(b1, 1)\n#define EMIT2(b1, b2)\t\tEMIT((b1) + ((b2) << 8), 2)\n#define EMIT3(b1, b2, b3)\tEMIT((b1) + ((b2) << 8) + ((b3) << 16), 3)\n#define EMIT4(b1, b2, b3, b4)   \\\n\tEMIT((b1) + ((b2) << 8) + ((b3) << 16) + ((b4) << 24), 4)\n\n#define EMIT1_off32(b1, off) \\\n\tdo { EMIT1(b1); EMIT(off, 4); } while (0)\n#define EMIT2_off32(b1, b2, off) \\\n\tdo { EMIT2(b1, b2); EMIT(off, 4); } while (0)\n#define EMIT3_off32(b1, b2, b3, off) \\\n\tdo { EMIT3(b1, b2, b3); EMIT(off, 4); } while (0)\n#define EMIT4_off32(b1, b2, b3, b4, off) \\\n\tdo { EMIT4(b1, b2, b3, b4); EMIT(off, 4); } while (0)\n\n#define jmp_label(label, jmp_insn_len) (label - cnt - jmp_insn_len)\n\nstatic bool is_imm8(int value)\n{\n\treturn value <= 127 && value >= -128;\n}\n\nstatic bool is_simm32(s64 value)\n{\n\treturn value == (s64) (s32) value;\n}\n\n#define STACK_OFFSET(k)\t(k)\n#define TCALL_CNT\t(MAX_BPF_JIT_REG + 0)\t \n\n#define IA32_EAX\t(0x0)\n#define IA32_EBX\t(0x3)\n#define IA32_ECX\t(0x1)\n#define IA32_EDX\t(0x2)\n#define IA32_ESI\t(0x6)\n#define IA32_EDI\t(0x7)\n#define IA32_EBP\t(0x5)\n#define IA32_ESP\t(0x4)\n\n \n#define IA32_JB  0x72\n#define IA32_JAE 0x73\n#define IA32_JE  0x74\n#define IA32_JNE 0x75\n#define IA32_JBE 0x76\n#define IA32_JA  0x77\n#define IA32_JL  0x7C\n#define IA32_JGE 0x7D\n#define IA32_JLE 0x7E\n#define IA32_JG  0x7F\n\n#define COND_JMP_OPCODE_INVALID\t(0xFF)\n\n \nstatic const u8 bpf2ia32[][2] = {\n\t \n\t[BPF_REG_0] = {STACK_OFFSET(0), STACK_OFFSET(4)},\n\n\t \n\t \n\t[BPF_REG_1] = {STACK_OFFSET(8), STACK_OFFSET(12)},\n\t[BPF_REG_2] = {STACK_OFFSET(16), STACK_OFFSET(20)},\n\t[BPF_REG_3] = {STACK_OFFSET(24), STACK_OFFSET(28)},\n\t[BPF_REG_4] = {STACK_OFFSET(32), STACK_OFFSET(36)},\n\t[BPF_REG_5] = {STACK_OFFSET(40), STACK_OFFSET(44)},\n\n\t \n\t \n\t[BPF_REG_6] = {STACK_OFFSET(48), STACK_OFFSET(52)},\n\t[BPF_REG_7] = {STACK_OFFSET(56), STACK_OFFSET(60)},\n\t[BPF_REG_8] = {STACK_OFFSET(64), STACK_OFFSET(68)},\n\t[BPF_REG_9] = {STACK_OFFSET(72), STACK_OFFSET(76)},\n\n\t \n\t[BPF_REG_FP] = {STACK_OFFSET(80), STACK_OFFSET(84)},\n\n\t \n\t[BPF_REG_AX] = {IA32_ESI, IA32_EDI},\n\n\t \n\t[TCALL_CNT] = {STACK_OFFSET(88), STACK_OFFSET(92)},\n};\n\n#define dst_lo\tdst[0]\n#define dst_hi\tdst[1]\n#define src_lo\tsrc[0]\n#define src_hi\tsrc[1]\n\n#define STACK_ALIGNMENT\t8\n \n#define SCRATCH_SIZE 96\n\n \n#define _STACK_SIZE\t(stack_depth + SCRATCH_SIZE)\n\n#define STACK_SIZE ALIGN(_STACK_SIZE, STACK_ALIGNMENT)\n\n \n#define STACK_VAR(off) (off)\n\n \nstatic u8 add_1reg(u8 byte, u32 dst_reg)\n{\n\treturn byte + dst_reg;\n}\n\n \nstatic u8 add_2reg(u8 byte, u32 dst_reg, u32 src_reg)\n{\n\treturn byte + dst_reg + (src_reg << 3);\n}\n\nstatic void jit_fill_hole(void *area, unsigned int size)\n{\n\t \n\tmemset(area, 0xcc, size);\n}\n\nstatic inline void emit_ia32_mov_i(const u8 dst, const u32 val, bool dstk,\n\t\t\t\t   u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\n\tif (dstk) {\n\t\tif (val == 0) {\n\t\t\t \n\t\t\tEMIT2(0x33, add_2reg(0xC0, IA32_EAX, IA32_EAX));\n\t\t\t \n\t\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t      STACK_VAR(dst));\n\t\t} else {\n\t\t\tEMIT3_off32(0xC7, add_1reg(0x40, IA32_EBP),\n\t\t\t\t    STACK_VAR(dst), val);\n\t\t}\n\t} else {\n\t\tif (val == 0)\n\t\t\tEMIT2(0x33, add_2reg(0xC0, dst, dst));\n\t\telse\n\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, dst),\n\t\t\t\t    val);\n\t}\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_mov_r(const u8 dst, const u8 src, bool dstk,\n\t\t\t\t   bool sstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 sreg = sstk ? IA32_EAX : src;\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX), STACK_VAR(src));\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, sreg), STACK_VAR(dst));\n\telse\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dst, sreg));\n\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_mov_r64(const bool is64, const u8 dst[],\n\t\t\t\t     const u8 src[], bool dstk,\n\t\t\t\t     bool sstk, u8 **pprog,\n\t\t\t\t     const struct bpf_prog_aux *aux)\n{\n\temit_ia32_mov_r(dst_lo, src_lo, dstk, sstk, pprog);\n\tif (is64)\n\t\t \n\t\temit_ia32_mov_r(dst_hi, src_hi, dstk, sstk, pprog);\n\telse if (!aux->verifier_zext)\n\t\t \n\t\temit_ia32_mov_i(dst_hi, 0, dstk, pprog);\n}\n\n \nstatic inline void emit_ia32_mov_i64(const bool is64, const u8 dst[],\n\t\t\t\t     const u32 val, bool dstk, u8 **pprog)\n{\n\tu32 hi = 0;\n\n\tif (is64 && (val & (1<<31)))\n\t\thi = (u32)~0;\n\temit_ia32_mov_i(dst_lo, val, dstk, pprog);\n\temit_ia32_mov_i(dst_hi, hi, dstk, pprog);\n}\n\n \nstatic inline void emit_ia32_mul_r(const u8 dst, const u8 src, bool dstk,\n\t\t\t\t   bool sstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 sreg = sstk ? IA32_ECX : src;\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX), STACK_VAR(src));\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX), STACK_VAR(dst));\n\telse\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, dst, IA32_EAX));\n\n\n\tEMIT2(0xF7, add_1reg(0xE0, sreg));\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst));\n\telse\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dst, IA32_EAX));\n\n\t*pprog = prog;\n}\n\nstatic inline void emit_ia32_to_le_r64(const u8 dst[], s32 val,\n\t\t\t\t\t bool dstk, u8 **pprog,\n\t\t\t\t\t const struct bpf_prog_aux *aux)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\n\tif (dstk && val != 64) {\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\tswitch (val) {\n\tcase 16:\n\t\t \n\t\tEMIT2(0x0F, 0xB7);\n\t\tEMIT1(add_2reg(0xC0, dreg_lo, dreg_lo));\n\t\tif (!aux->verifier_zext)\n\t\t\t \n\t\t\tEMIT2(0x33, add_2reg(0xC0, dreg_hi, dreg_hi));\n\t\tbreak;\n\tcase 32:\n\t\tif (!aux->verifier_zext)\n\t\t\t \n\t\t\tEMIT2(0x33, add_2reg(0xC0, dreg_hi, dreg_hi));\n\t\tbreak;\n\tcase 64:\n\t\t \n\t\tbreak;\n\t}\n\n\tif (dstk && val != 64) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_lo),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_hi),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t*pprog = prog;\n}\n\nstatic inline void emit_ia32_to_be_r64(const u8 dst[], s32 val,\n\t\t\t\t       bool dstk, u8 **pprog,\n\t\t\t\t       const struct bpf_prog_aux *aux)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\n\tif (dstk) {\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\tswitch (val) {\n\tcase 16:\n\t\t \n\t\tEMIT1(0x66);\n\t\tEMIT3(0xC1, add_1reg(0xC8, dreg_lo), 8);\n\n\t\tEMIT2(0x0F, 0xB7);\n\t\tEMIT1(add_2reg(0xC0, dreg_lo, dreg_lo));\n\n\t\tif (!aux->verifier_zext)\n\t\t\t \n\t\t\tEMIT2(0x33, add_2reg(0xC0, dreg_hi, dreg_hi));\n\t\tbreak;\n\tcase 32:\n\t\t \n\t\tEMIT1(0x0F);\n\t\tEMIT1(add_1reg(0xC8, dreg_lo));\n\n\t\tif (!aux->verifier_zext)\n\t\t\t \n\t\t\tEMIT2(0x33, add_2reg(0xC0, dreg_hi, dreg_hi));\n\t\tbreak;\n\tcase 64:\n\t\t \n\t\tEMIT1(0x0F);\n\t\tEMIT1(add_1reg(0xC8, dreg_lo));\n\n\t\t \n\t\tEMIT1(0x0F);\n\t\tEMIT1(add_1reg(0xC8, dreg_hi));\n\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, IA32_ECX, dreg_hi));\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dreg_hi, dreg_lo));\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dreg_lo, IA32_ECX));\n\n\t\tbreak;\n\t}\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_lo),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_hi),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_div_mod_r(const u8 op, const u8 dst, const u8 src,\n\t\t\t\t       bool dstk, bool sstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX),\n\t\t      STACK_VAR(src));\n\telse if (src != IA32_ECX)\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, src, IA32_ECX));\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst));\n\telse\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, dst, IA32_EAX));\n\n\t \n\tEMIT2(0x31, add_2reg(0xC0, IA32_EDX, IA32_EDX));\n\t \n\tEMIT2(0xF7, add_1reg(0xF0, IA32_ECX));\n\n\tif (op == BPF_MOD) {\n\t\tif (dstk)\n\t\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t\t      STACK_VAR(dst));\n\t\telse\n\t\t\tEMIT2(0x89, add_2reg(0xC0, dst, IA32_EDX));\n\t} else {\n\t\tif (dstk)\n\t\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t      STACK_VAR(dst));\n\t\telse\n\t\t\tEMIT2(0x89, add_2reg(0xC0, dst, IA32_EAX));\n\t}\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_shift_r(const u8 op, const u8 dst, const u8 src,\n\t\t\t\t     bool dstk, bool sstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg = dstk ? IA32_EAX : dst;\n\tu8 b2;\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX), STACK_VAR(dst));\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX), STACK_VAR(src));\n\telse if (src != IA32_ECX)\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, src, IA32_ECX));\n\n\tswitch (op) {\n\tcase BPF_LSH:\n\t\tb2 = 0xE0; break;\n\tcase BPF_RSH:\n\t\tb2 = 0xE8; break;\n\tcase BPF_ARSH:\n\t\tb2 = 0xF8; break;\n\tdefault:\n\t\treturn;\n\t}\n\tEMIT2(0xD3, add_1reg(b2, dreg));\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg), STACK_VAR(dst));\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_alu_r(const bool is64, const bool hi, const u8 op,\n\t\t\t\t   const u8 dst, const u8 src, bool dstk,\n\t\t\t\t   bool sstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 sreg = sstk ? IA32_EAX : src;\n\tu8 dreg = dstk ? IA32_EDX : dst;\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX), STACK_VAR(src));\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX), STACK_VAR(dst));\n\n\tswitch (BPF_OP(op)) {\n\t \n\tcase BPF_ADD:\n\t\tif (hi && is64)\n\t\t\tEMIT2(0x11, add_2reg(0xC0, dreg, sreg));\n\t\telse\n\t\t\tEMIT2(0x01, add_2reg(0xC0, dreg, sreg));\n\t\tbreak;\n\t \n\tcase BPF_SUB:\n\t\tif (hi && is64)\n\t\t\tEMIT2(0x19, add_2reg(0xC0, dreg, sreg));\n\t\telse\n\t\t\tEMIT2(0x29, add_2reg(0xC0, dreg, sreg));\n\t\tbreak;\n\t \n\tcase BPF_OR:\n\t\tEMIT2(0x09, add_2reg(0xC0, dreg, sreg));\n\t\tbreak;\n\t \n\tcase BPF_AND:\n\t\tEMIT2(0x21, add_2reg(0xC0, dreg, sreg));\n\t\tbreak;\n\t \n\tcase BPF_XOR:\n\t\tEMIT2(0x31, add_2reg(0xC0, dreg, sreg));\n\t\tbreak;\n\t}\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg),\n\t\t      STACK_VAR(dst));\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_alu_r64(const bool is64, const u8 op,\n\t\t\t\t     const u8 dst[], const u8 src[],\n\t\t\t\t     bool dstk,  bool sstk,\n\t\t\t\t     u8 **pprog, const struct bpf_prog_aux *aux)\n{\n\tu8 *prog = *pprog;\n\n\temit_ia32_alu_r(is64, false, op, dst_lo, src_lo, dstk, sstk, &prog);\n\tif (is64)\n\t\temit_ia32_alu_r(is64, true, op, dst_hi, src_hi, dstk, sstk,\n\t\t\t\t&prog);\n\telse if (!aux->verifier_zext)\n\t\temit_ia32_mov_i(dst_hi, 0, dstk, &prog);\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_alu_i(const bool is64, const bool hi, const u8 op,\n\t\t\t\t   const u8 dst, const s32 val, bool dstk,\n\t\t\t\t   u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg = dstk ? IA32_EAX : dst;\n\tu8 sreg = IA32_EDX;\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX), STACK_VAR(dst));\n\n\tif (!is_imm8(val))\n\t\t \n\t\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_EDX), val);\n\n\tswitch (op) {\n\t \n\tcase BPF_ADD:\n\t\tif (hi && is64) {\n\t\t\tif (is_imm8(val))\n\t\t\t\tEMIT3(0x83, add_1reg(0xD0, dreg), val);\n\t\t\telse\n\t\t\t\tEMIT2(0x11, add_2reg(0xC0, dreg, sreg));\n\t\t} else {\n\t\t\tif (is_imm8(val))\n\t\t\t\tEMIT3(0x83, add_1reg(0xC0, dreg), val);\n\t\t\telse\n\t\t\t\tEMIT2(0x01, add_2reg(0xC0, dreg, sreg));\n\t\t}\n\t\tbreak;\n\t \n\tcase BPF_SUB:\n\t\tif (hi && is64) {\n\t\t\tif (is_imm8(val))\n\t\t\t\tEMIT3(0x83, add_1reg(0xD8, dreg), val);\n\t\t\telse\n\t\t\t\tEMIT2(0x19, add_2reg(0xC0, dreg, sreg));\n\t\t} else {\n\t\t\tif (is_imm8(val))\n\t\t\t\tEMIT3(0x83, add_1reg(0xE8, dreg), val);\n\t\t\telse\n\t\t\t\tEMIT2(0x29, add_2reg(0xC0, dreg, sreg));\n\t\t}\n\t\tbreak;\n\t \n\tcase BPF_OR:\n\t\tif (is_imm8(val))\n\t\t\tEMIT3(0x83, add_1reg(0xC8, dreg), val);\n\t\telse\n\t\t\tEMIT2(0x09, add_2reg(0xC0, dreg, sreg));\n\t\tbreak;\n\t \n\tcase BPF_AND:\n\t\tif (is_imm8(val))\n\t\t\tEMIT3(0x83, add_1reg(0xE0, dreg), val);\n\t\telse\n\t\t\tEMIT2(0x21, add_2reg(0xC0, dreg, sreg));\n\t\tbreak;\n\t \n\tcase BPF_XOR:\n\t\tif (is_imm8(val))\n\t\t\tEMIT3(0x83, add_1reg(0xF0, dreg), val);\n\t\telse\n\t\t\tEMIT2(0x31, add_2reg(0xC0, dreg, sreg));\n\t\tbreak;\n\tcase BPF_NEG:\n\t\tEMIT2(0xF7, add_1reg(0xD8, dreg));\n\t\tbreak;\n\t}\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg),\n\t\t      STACK_VAR(dst));\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_alu_i64(const bool is64, const u8 op,\n\t\t\t\t     const u8 dst[], const u32 val,\n\t\t\t\t     bool dstk, u8 **pprog,\n\t\t\t\t     const struct bpf_prog_aux *aux)\n{\n\tu8 *prog = *pprog;\n\tu32 hi = 0;\n\n\tif (is64 && (val & (1<<31)))\n\t\thi = (u32)~0;\n\n\temit_ia32_alu_i(is64, false, op, dst_lo, val, dstk, &prog);\n\tif (is64)\n\t\temit_ia32_alu_i(is64, true, op, dst_hi, hi, dstk, &prog);\n\telse if (!aux->verifier_zext)\n\t\temit_ia32_mov_i(dst_hi, 0, dstk, &prog);\n\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_neg64(const u8 dst[], bool dstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\n\tif (dstk) {\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\n\t \n\tEMIT2(0xF7, add_1reg(0xD8, dreg_lo));\n\t \n\tEMIT3(0x83, add_1reg(0xD0, dreg_hi), 0x00);\n\t \n\tEMIT2(0xF7, add_1reg(0xD8, dreg_hi));\n\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_lo),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_hi),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_lsh_r64(const u8 dst[], const u8 src[],\n\t\t\t\t     bool dstk, bool sstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\n\tif (dstk) {\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX),\n\t\t      STACK_VAR(src_lo));\n\telse\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, src_lo, IA32_ECX));\n\n\t \n\tEMIT3(0x0F, 0xA5, add_2reg(0xC0, dreg_hi, dreg_lo));\n\t \n\tEMIT2(0xD3, add_1reg(0xE0, dreg_lo));\n\n\t \n\n\t \n\tEMIT3(0x83, add_1reg(0xF8, IA32_ECX), 32);\n\t \n\tEMIT2(IA32_JB, 4);\n\n\t \n\tEMIT2(0x89, add_2reg(0xC0, dreg_hi, dreg_lo));\n\t \n\tEMIT2(0x33, add_2reg(0xC0, dreg_lo, dreg_lo));\n\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_lo),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_hi),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t \n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_arsh_r64(const u8 dst[], const u8 src[],\n\t\t\t\t      bool dstk, bool sstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\n\tif (dstk) {\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX),\n\t\t      STACK_VAR(src_lo));\n\telse\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, src_lo, IA32_ECX));\n\n\t \n\tEMIT3(0x0F, 0xAD, add_2reg(0xC0, dreg_lo, dreg_hi));\n\t \n\tEMIT2(0xD3, add_1reg(0xF8, dreg_hi));\n\n\t \n\n\t \n\tEMIT3(0x83, add_1reg(0xF8, IA32_ECX), 32);\n\t \n\tEMIT2(IA32_JB, 5);\n\n\t \n\tEMIT2(0x89, add_2reg(0xC0, dreg_lo, dreg_hi));\n\t \n\tEMIT3(0xC1, add_1reg(0xF8, dreg_hi), 31);\n\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_lo),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_hi),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t \n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_rsh_r64(const u8 dst[], const u8 src[], bool dstk,\n\t\t\t\t     bool sstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\n\tif (dstk) {\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX),\n\t\t      STACK_VAR(src_lo));\n\telse\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, src_lo, IA32_ECX));\n\n\t \n\tEMIT3(0x0F, 0xAD, add_2reg(0xC0, dreg_lo, dreg_hi));\n\t \n\tEMIT2(0xD3, add_1reg(0xE8, dreg_hi));\n\n\t \n\n\t \n\tEMIT3(0x83, add_1reg(0xF8, IA32_ECX), 32);\n\t \n\tEMIT2(IA32_JB, 4);\n\n\t \n\tEMIT2(0x89, add_2reg(0xC0, dreg_lo, dreg_hi));\n\t \n\tEMIT2(0x33, add_2reg(0xC0, dreg_hi, dreg_hi));\n\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_lo),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_hi),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t \n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_lsh_i64(const u8 dst[], const u32 val,\n\t\t\t\t     bool dstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\n\tif (dstk) {\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t \n\tif (val < 32) {\n\t\t \n\t\tEMIT4(0x0F, 0xA4, add_2reg(0xC0, dreg_hi, dreg_lo), val);\n\t\t \n\t\tEMIT3(0xC1, add_1reg(0xE0, dreg_lo), val);\n\t} else if (val >= 32 && val < 64) {\n\t\tu32 value = val - 32;\n\n\t\t \n\t\tEMIT3(0xC1, add_1reg(0xE0, dreg_lo), value);\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dreg_hi, dreg_lo));\n\t\t \n\t\tEMIT2(0x33, add_2reg(0xC0, dreg_lo, dreg_lo));\n\t} else {\n\t\t \n\t\tEMIT2(0x33, add_2reg(0xC0, dreg_lo, dreg_lo));\n\t\t \n\t\tEMIT2(0x33, add_2reg(0xC0, dreg_hi, dreg_hi));\n\t}\n\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_lo),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_hi),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_rsh_i64(const u8 dst[], const u32 val,\n\t\t\t\t     bool dstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\n\tif (dstk) {\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\n\t \n\tif (val < 32) {\n\t\t \n\t\tEMIT4(0x0F, 0xAC, add_2reg(0xC0, dreg_lo, dreg_hi), val);\n\t\t \n\t\tEMIT3(0xC1, add_1reg(0xE8, dreg_hi), val);\n\t} else if (val >= 32 && val < 64) {\n\t\tu32 value = val - 32;\n\n\t\t \n\t\tEMIT3(0xC1, add_1reg(0xE8, dreg_hi), value);\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dreg_lo, dreg_hi));\n\t\t \n\t\tEMIT2(0x33, add_2reg(0xC0, dreg_hi, dreg_hi));\n\t} else {\n\t\t \n\t\tEMIT2(0x33, add_2reg(0xC0, dreg_lo, dreg_lo));\n\t\t \n\t\tEMIT2(0x33, add_2reg(0xC0, dreg_hi, dreg_hi));\n\t}\n\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_lo),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_hi),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t*pprog = prog;\n}\n\n \nstatic inline void emit_ia32_arsh_i64(const u8 dst[], const u32 val,\n\t\t\t\t      bool dstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\n\tif (dstk) {\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t \n\tif (val < 32) {\n\t\t \n\t\tEMIT4(0x0F, 0xAC, add_2reg(0xC0, dreg_lo, dreg_hi), val);\n\t\t \n\t\tEMIT3(0xC1, add_1reg(0xF8, dreg_hi), val);\n\t} else if (val >= 32 && val < 64) {\n\t\tu32 value = val - 32;\n\n\t\t \n\t\tEMIT3(0xC1, add_1reg(0xF8, dreg_hi), value);\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dreg_lo, dreg_hi));\n\n\t\t \n\t\tEMIT3(0xC1, add_1reg(0xF8, dreg_hi), 31);\n\t} else {\n\t\t \n\t\tEMIT3(0xC1, add_1reg(0xF8, dreg_hi), 31);\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dreg_lo, dreg_hi));\n\t}\n\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_lo),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, dreg_hi),\n\t\t      STACK_VAR(dst_hi));\n\t}\n\t*pprog = prog;\n}\n\nstatic inline void emit_ia32_mul_r64(const u8 dst[], const u8 src[], bool dstk,\n\t\t\t\t     bool sstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_hi));\n\telse\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, dst_hi, IA32_EAX));\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0xF7, add_1reg(0x60, IA32_EBP), STACK_VAR(src_lo));\n\telse\n\t\t \n\t\tEMIT2(0xF7, add_1reg(0xE0, src_lo));\n\n\t \n\tEMIT2(0x89, add_2reg(0xC0, IA32_ECX, IA32_EAX));\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\telse\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, dst_lo, IA32_EAX));\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0xF7, add_1reg(0x60, IA32_EBP), STACK_VAR(src_hi));\n\telse\n\t\t \n\t\tEMIT2(0xF7, add_1reg(0xE0, src_hi));\n\n\t \n\tEMIT2(0x01, add_2reg(0xC0, IA32_ECX, IA32_EAX));\n\n\tif (dstk)\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\telse\n\t\t \n\t\tEMIT2(0x8B, add_2reg(0xC0, dst_lo, IA32_EAX));\n\n\tif (sstk)\n\t\t \n\t\tEMIT3(0xF7, add_1reg(0x60, IA32_EBP), STACK_VAR(src_lo));\n\telse\n\t\t \n\t\tEMIT2(0xF7, add_1reg(0xE0, src_lo));\n\n\t \n\tEMIT2(0x01, add_2reg(0xC0, IA32_ECX, IA32_EDX));\n\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_ECX),\n\t\t      STACK_VAR(dst_hi));\n\t} else {\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dst_lo, IA32_EAX));\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dst_hi, IA32_ECX));\n\t}\n\n\t*pprog = prog;\n}\n\nstatic inline void emit_ia32_mul_i64(const u8 dst[], const u32 val,\n\t\t\t\t     bool dstk, u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tu32 hi;\n\n\thi = val & (1<<31) ? (u32)~0 : 0;\n\t \n\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_EAX), val);\n\tif (dstk)\n\t\t \n\t\tEMIT3(0xF7, add_1reg(0x60, IA32_EBP), STACK_VAR(dst_hi));\n\telse\n\t\t \n\t\tEMIT2(0xF7, add_1reg(0xE0, dst_hi));\n\n\t \n\tEMIT2(0x89, add_2reg(0xC0, IA32_ECX, IA32_EAX));\n\n\t \n\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_EAX), hi);\n\tif (dstk)\n\t\t \n\t\tEMIT3(0xF7, add_1reg(0x60, IA32_EBP), STACK_VAR(dst_lo));\n\telse\n\t\t \n\t\tEMIT2(0xF7, add_1reg(0xE0, dst_lo));\n\t \n\tEMIT2(0x01, add_2reg(0xC0, IA32_ECX, IA32_EAX));\n\n\t \n\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_EAX), val);\n\tif (dstk)\n\t\t \n\t\tEMIT3(0xF7, add_1reg(0x60, IA32_EBP), STACK_VAR(dst_lo));\n\telse\n\t\t \n\t\tEMIT2(0xF7, add_1reg(0xE0, dst_lo));\n\n\t \n\tEMIT2(0x01, add_2reg(0xC0, IA32_ECX, IA32_EDX));\n\n\tif (dstk) {\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(dst_lo));\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_ECX),\n\t\t      STACK_VAR(dst_hi));\n\t} else {\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dst_lo, IA32_EAX));\n\t\t \n\t\tEMIT2(0x89, add_2reg(0xC0, dst_hi, IA32_ECX));\n\t}\n\n\t*pprog = prog;\n}\n\nstatic int bpf_size_to_x86_bytes(int bpf_size)\n{\n\tif (bpf_size == BPF_W)\n\t\treturn 4;\n\telse if (bpf_size == BPF_H)\n\t\treturn 2;\n\telse if (bpf_size == BPF_B)\n\t\treturn 1;\n\telse if (bpf_size == BPF_DW)\n\t\treturn 4;  \n\telse\n\t\treturn 0;\n}\n\nstruct jit_context {\n\tint cleanup_addr;  \n};\n\n \n#define BPF_MAX_INSN_SIZE\t128\n#define BPF_INSN_SAFETY\t\t64\n\n#define PROLOGUE_SIZE 35\n\n \nstatic void emit_prologue(u8 **pprog, u32 stack_depth)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tconst u8 *r1 = bpf2ia32[BPF_REG_1];\n\tconst u8 fplo = bpf2ia32[BPF_REG_FP][0];\n\tconst u8 fphi = bpf2ia32[BPF_REG_FP][1];\n\tconst u8 *tcc = bpf2ia32[TCALL_CNT];\n\n\t \n\tEMIT1(0x55);\n\t \n\tEMIT2(0x89, 0xE5);\n\t \n\tEMIT1(0x57);\n\t \n\tEMIT1(0x56);\n\t \n\tEMIT1(0x53);\n\n\t \n\tEMIT2_off32(0x81, 0xEC, STACK_SIZE);\n\t \n\tEMIT3(0x83, add_1reg(0xE8, IA32_EBP), SCRATCH_SIZE + 12);\n\t \n\tEMIT2(0x31, add_2reg(0xC0, IA32_EBX, IA32_EBX));\n\n\t \n\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EBP), STACK_VAR(fplo));\n\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EBX), STACK_VAR(fphi));\n\n\t \n\t \n\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EAX), STACK_VAR(r1[0]));\n\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EBX), STACK_VAR(r1[1]));\n\n\t \n\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EBX), STACK_VAR(tcc[0]));\n\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EBX), STACK_VAR(tcc[1]));\n\n\tBUILD_BUG_ON(cnt != PROLOGUE_SIZE);\n\t*pprog = prog;\n}\n\n \nstatic void emit_epilogue(u8 **pprog, u32 stack_depth)\n{\n\tu8 *prog = *pprog;\n\tconst u8 *r0 = bpf2ia32[BPF_REG_0];\n\tint cnt = 0;\n\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX), STACK_VAR(r0[0]));\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX), STACK_VAR(r0[1]));\n\n\t \n\tEMIT3(0x83, add_1reg(0xC0, IA32_EBP), SCRATCH_SIZE + 12);\n\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EBX), -12);\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ESI), -8);\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDI), -4);\n\n\tEMIT1(0xC9);  \n\tEMIT1(0xC3);  \n\t*pprog = prog;\n}\n\nstatic int emit_jmp_edx(u8 **pprog, u8 *ip)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\n#ifdef CONFIG_RETPOLINE\n\tEMIT1_off32(0xE9, (u8 *)__x86_indirect_thunk_edx - (ip + 5));\n#else\n\tEMIT2(0xFF, 0xE2);\n#endif\n\t*pprog = prog;\n\n\treturn cnt;\n}\n\n \nstatic void emit_bpf_tail_call(u8 **pprog, u8 *ip)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\tconst u8 *r1 = bpf2ia32[BPF_REG_1];\n\tconst u8 *r2 = bpf2ia32[BPF_REG_2];\n\tconst u8 *r3 = bpf2ia32[BPF_REG_3];\n\tconst u8 *tcc = bpf2ia32[TCALL_CNT];\n\tu32 lo, hi;\n\tstatic int jmp_label1 = -1;\n\n\t \n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX), STACK_VAR(r2[0]));\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX), STACK_VAR(r3[0]));\n\n\t \n\tEMIT3(0x39, add_2reg(0x40, IA32_EAX, IA32_EDX),\n\t      offsetof(struct bpf_array, map.max_entries));\n\t \n\tEMIT2(IA32_JBE, jmp_label(jmp_label1, 2));\n\n\t \n\tlo = (u32)MAX_TAIL_CALL_CNT;\n\thi = (u32)((u64)MAX_TAIL_CALL_CNT >> 32);\n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX), STACK_VAR(tcc[0]));\n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EBX), STACK_VAR(tcc[1]));\n\n\t \n\tEMIT3(0x83, add_1reg(0xF8, IA32_EBX), hi);\n\tEMIT2(IA32_JNE, 3);\n\t \n\tEMIT3(0x83, add_1reg(0xF8, IA32_ECX), lo);\n\n\t \n\tEMIT2(IA32_JAE, jmp_label(jmp_label1, 2));\n\n\t \n\tEMIT3(0x83, add_1reg(0xC0, IA32_ECX), 0x01);\n\t \n\tEMIT3(0x83, add_1reg(0xD0, IA32_EBX), 0x00);\n\n\t \n\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_ECX), STACK_VAR(tcc[0]));\n\t \n\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EBX), STACK_VAR(tcc[1]));\n\n\t \n\t \n\tEMIT3_off32(0x8B, 0x94, 0x90, offsetof(struct bpf_array, ptrs));\n\n\t \n\t \n\tEMIT2(0x85, add_2reg(0xC0, IA32_EDX, IA32_EDX));\n\t \n\tEMIT2(IA32_JE, jmp_label(jmp_label1, 2));\n\n\t \n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EDX, IA32_EDX),\n\t      offsetof(struct bpf_prog, bpf_func));\n\t \n\tEMIT3(0x83, add_1reg(0xC0, IA32_EDX), PROLOGUE_SIZE);\n\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX), STACK_VAR(r1[0]));\n\n\t \n\tcnt += emit_jmp_edx(&prog, ip + cnt);\n\n\tif (jmp_label1 == -1)\n\t\tjmp_label1 = cnt;\n\n\t \n\t*pprog = prog;\n}\n\n \nstatic inline void emit_push_r64(const u8 src[], u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX), STACK_VAR(src_hi));\n\t \n\tEMIT1(0x51);\n\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX), STACK_VAR(src_lo));\n\t \n\tEMIT1(0x51);\n\n\t*pprog = prog;\n}\n\nstatic void emit_push_r32(const u8 src[], u8 **pprog)\n{\n\tu8 *prog = *pprog;\n\tint cnt = 0;\n\n\t \n\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX), STACK_VAR(src_lo));\n\t \n\tEMIT1(0x51);\n\n\t*pprog = prog;\n}\n\nstatic u8 get_cond_jmp_opcode(const u8 op, bool is_cmp_lo)\n{\n\tu8 jmp_cond;\n\n\t \n\tswitch (op) {\n\tcase BPF_JEQ:\n\t\tjmp_cond = IA32_JE;\n\t\tbreak;\n\tcase BPF_JSET:\n\tcase BPF_JNE:\n\t\tjmp_cond = IA32_JNE;\n\t\tbreak;\n\tcase BPF_JGT:\n\t\t \n\t\tjmp_cond = IA32_JA;\n\t\tbreak;\n\tcase BPF_JLT:\n\t\t \n\t\tjmp_cond = IA32_JB;\n\t\tbreak;\n\tcase BPF_JGE:\n\t\t \n\t\tjmp_cond = IA32_JAE;\n\t\tbreak;\n\tcase BPF_JLE:\n\t\t \n\t\tjmp_cond = IA32_JBE;\n\t\tbreak;\n\tcase BPF_JSGT:\n\t\tif (!is_cmp_lo)\n\t\t\t \n\t\t\tjmp_cond = IA32_JG;\n\t\telse\n\t\t\t \n\t\t\tjmp_cond = IA32_JA;\n\t\tbreak;\n\tcase BPF_JSLT:\n\t\tif (!is_cmp_lo)\n\t\t\t \n\t\t\tjmp_cond = IA32_JL;\n\t\telse\n\t\t\t \n\t\t\tjmp_cond = IA32_JB;\n\t\tbreak;\n\tcase BPF_JSGE:\n\t\tif (!is_cmp_lo)\n\t\t\t \n\t\t\tjmp_cond = IA32_JGE;\n\t\telse\n\t\t\t \n\t\t\tjmp_cond = IA32_JAE;\n\t\tbreak;\n\tcase BPF_JSLE:\n\t\tif (!is_cmp_lo)\n\t\t\t \n\t\t\tjmp_cond = IA32_JLE;\n\t\telse\n\t\t\t \n\t\t\tjmp_cond = IA32_JBE;\n\t\tbreak;\n\tdefault:  \n\t\tjmp_cond = COND_JMP_OPCODE_INVALID;\n\t\tbreak;\n\t}\n\n\treturn jmp_cond;\n}\n\n \nstatic int emit_kfunc_call(const struct bpf_prog *bpf_prog, u8 *end_addr,\n\t\t\t   const struct bpf_insn *insn, u8 **pprog)\n{\n\tconst u8 arg_regs[] = { IA32_EAX, IA32_EDX, IA32_ECX };\n\tint i, cnt = 0, first_stack_regno, last_stack_regno;\n\tint free_arg_regs = ARRAY_SIZE(arg_regs);\n\tconst struct btf_func_model *fm;\n\tint bytes_in_stack = 0;\n\tconst u8 *cur_arg_reg;\n\tu8 *prog = *pprog;\n\ts64 jmp_offset;\n\n\tfm = bpf_jit_find_kfunc_model(bpf_prog, insn);\n\tif (!fm)\n\t\treturn -EINVAL;\n\n\tfirst_stack_regno = BPF_REG_1;\n\tfor (i = 0; i < fm->nr_args; i++) {\n\t\tint regs_needed = fm->arg_size[i] > sizeof(u32) ? 2 : 1;\n\n\t\tif (regs_needed > free_arg_regs)\n\t\t\tbreak;\n\n\t\tfree_arg_regs -= regs_needed;\n\t\tfirst_stack_regno++;\n\t}\n\n\t \n\tlast_stack_regno = BPF_REG_0 + fm->nr_args;\n\tfor (i = last_stack_regno; i >= first_stack_regno; i--) {\n\t\tif (fm->arg_size[i - 1] > sizeof(u32)) {\n\t\t\temit_push_r64(bpf2ia32[i], &prog);\n\t\t\tbytes_in_stack += 8;\n\t\t} else {\n\t\t\temit_push_r32(bpf2ia32[i], &prog);\n\t\t\tbytes_in_stack += 4;\n\t\t}\n\t}\n\n\tcur_arg_reg = &arg_regs[0];\n\tfor (i = BPF_REG_1; i < first_stack_regno; i++) {\n\t\t \n\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, *cur_arg_reg++),\n\t\t      STACK_VAR(bpf2ia32[i][0]));\n\t\tif (fm->arg_size[i - 1] > sizeof(u32))\n\t\t\t \n\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, *cur_arg_reg++),\n\t\t\t      STACK_VAR(bpf2ia32[i][1]));\n\t}\n\n\tif (bytes_in_stack)\n\t\t \n\t\tend_addr -= 3;\n\n\t \n\tif (fm->ret_size > sizeof(u32))\n\t\tend_addr -= 3;\n\n\t \n\tif (fm->ret_size)\n\t\tend_addr -= 3;\n\n\tjmp_offset = (u8 *)__bpf_call_base + insn->imm - end_addr;\n\tif (!is_simm32(jmp_offset)) {\n\t\tpr_err(\"unsupported BPF kernel function jmp_offset:%lld\\n\",\n\t\t       jmp_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tEMIT1_off32(0xE8, jmp_offset);\n\n\tif (fm->ret_size)\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t      STACK_VAR(bpf2ia32[BPF_REG_0][0]));\n\n\tif (fm->ret_size > sizeof(u32))\n\t\t \n\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t      STACK_VAR(bpf2ia32[BPF_REG_0][1]));\n\n\tif (bytes_in_stack)\n\t\t \n\t\tEMIT3(0x83, add_1reg(0xC0, IA32_ESP), bytes_in_stack);\n\n\t*pprog = prog;\n\n\treturn 0;\n}\n\nstatic int do_jit(struct bpf_prog *bpf_prog, int *addrs, u8 *image,\n\t\t  int oldproglen, struct jit_context *ctx)\n{\n\tstruct bpf_insn *insn = bpf_prog->insnsi;\n\tint insn_cnt = bpf_prog->len;\n\tbool seen_exit = false;\n\tu8 temp[BPF_MAX_INSN_SIZE + BPF_INSN_SAFETY];\n\tint i, cnt = 0;\n\tint proglen = 0;\n\tu8 *prog = temp;\n\n\temit_prologue(&prog, bpf_prog->aux->stack_depth);\n\n\tfor (i = 0; i < insn_cnt; i++, insn++) {\n\t\tconst s32 imm32 = insn->imm;\n\t\tconst bool is64 = BPF_CLASS(insn->code) == BPF_ALU64;\n\t\tconst bool dstk = insn->dst_reg != BPF_REG_AX;\n\t\tconst bool sstk = insn->src_reg != BPF_REG_AX;\n\t\tconst u8 code = insn->code;\n\t\tconst u8 *dst = bpf2ia32[insn->dst_reg];\n\t\tconst u8 *src = bpf2ia32[insn->src_reg];\n\t\tconst u8 *r0 = bpf2ia32[BPF_REG_0];\n\t\ts64 jmp_offset;\n\t\tu8 jmp_cond;\n\t\tint ilen;\n\t\tu8 *func;\n\n\t\tswitch (code) {\n\t\t \n\t\t \n\t\tcase BPF_ALU | BPF_MOV | BPF_K:\n\t\tcase BPF_ALU | BPF_MOV | BPF_X:\n\t\tcase BPF_ALU64 | BPF_MOV | BPF_K:\n\t\tcase BPF_ALU64 | BPF_MOV | BPF_X:\n\t\t\tswitch (BPF_SRC(code)) {\n\t\t\tcase BPF_X:\n\t\t\t\tif (imm32 == 1) {\n\t\t\t\t\t \n\t\t\t\t\temit_ia32_mov_i(dst_hi, 0, dstk, &prog);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\temit_ia32_mov_r64(is64, dst, src, dstk, sstk,\n\t\t\t\t\t\t  &prog, bpf_prog->aux);\n\t\t\t\tbreak;\n\t\t\tcase BPF_K:\n\t\t\t\t \n\t\t\t\temit_ia32_mov_i64(is64, dst, imm32,\n\t\t\t\t\t\t  dstk, &prog);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\t \n\t\t \n\t\t \n\t\t \n\t\t \n\t\t \n\t\t \n\t\t \n\t\tcase BPF_ALU | BPF_ADD | BPF_K:\n\t\tcase BPF_ALU | BPF_ADD | BPF_X:\n\t\tcase BPF_ALU | BPF_SUB | BPF_K:\n\t\tcase BPF_ALU | BPF_SUB | BPF_X:\n\t\tcase BPF_ALU | BPF_OR | BPF_K:\n\t\tcase BPF_ALU | BPF_OR | BPF_X:\n\t\tcase BPF_ALU | BPF_AND | BPF_K:\n\t\tcase BPF_ALU | BPF_AND | BPF_X:\n\t\tcase BPF_ALU | BPF_XOR | BPF_K:\n\t\tcase BPF_ALU | BPF_XOR | BPF_X:\n\t\tcase BPF_ALU64 | BPF_ADD | BPF_K:\n\t\tcase BPF_ALU64 | BPF_ADD | BPF_X:\n\t\tcase BPF_ALU64 | BPF_SUB | BPF_K:\n\t\tcase BPF_ALU64 | BPF_SUB | BPF_X:\n\t\tcase BPF_ALU64 | BPF_OR | BPF_K:\n\t\tcase BPF_ALU64 | BPF_OR | BPF_X:\n\t\tcase BPF_ALU64 | BPF_AND | BPF_K:\n\t\tcase BPF_ALU64 | BPF_AND | BPF_X:\n\t\tcase BPF_ALU64 | BPF_XOR | BPF_K:\n\t\tcase BPF_ALU64 | BPF_XOR | BPF_X:\n\t\t\tswitch (BPF_SRC(code)) {\n\t\t\tcase BPF_X:\n\t\t\t\temit_ia32_alu_r64(is64, BPF_OP(code), dst,\n\t\t\t\t\t\t  src, dstk, sstk, &prog,\n\t\t\t\t\t\t  bpf_prog->aux);\n\t\t\t\tbreak;\n\t\t\tcase BPF_K:\n\t\t\t\temit_ia32_alu_i64(is64, BPF_OP(code), dst,\n\t\t\t\t\t\t  imm32, dstk, &prog,\n\t\t\t\t\t\t  bpf_prog->aux);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase BPF_ALU | BPF_MUL | BPF_K:\n\t\tcase BPF_ALU | BPF_MUL | BPF_X:\n\t\t\tswitch (BPF_SRC(code)) {\n\t\t\tcase BPF_X:\n\t\t\t\temit_ia32_mul_r(dst_lo, src_lo, dstk,\n\t\t\t\t\t\tsstk, &prog);\n\t\t\t\tbreak;\n\t\t\tcase BPF_K:\n\t\t\t\t \n\t\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_ECX),\n\t\t\t\t\t    imm32);\n\t\t\t\temit_ia32_mul_r(dst_lo, IA32_ECX, dstk,\n\t\t\t\t\t\tfalse, &prog);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!bpf_prog->aux->verifier_zext)\n\t\t\t\temit_ia32_mov_i(dst_hi, 0, dstk, &prog);\n\t\t\tbreak;\n\t\tcase BPF_ALU | BPF_LSH | BPF_X:\n\t\tcase BPF_ALU | BPF_RSH | BPF_X:\n\t\tcase BPF_ALU | BPF_ARSH | BPF_K:\n\t\tcase BPF_ALU | BPF_ARSH | BPF_X:\n\t\t\tswitch (BPF_SRC(code)) {\n\t\t\tcase BPF_X:\n\t\t\t\temit_ia32_shift_r(BPF_OP(code), dst_lo, src_lo,\n\t\t\t\t\t\t  dstk, sstk, &prog);\n\t\t\t\tbreak;\n\t\t\tcase BPF_K:\n\t\t\t\t \n\t\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_ECX),\n\t\t\t\t\t    imm32);\n\t\t\t\temit_ia32_shift_r(BPF_OP(code), dst_lo,\n\t\t\t\t\t\t  IA32_ECX, dstk, false,\n\t\t\t\t\t\t  &prog);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!bpf_prog->aux->verifier_zext)\n\t\t\t\temit_ia32_mov_i(dst_hi, 0, dstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\t \n\t\tcase BPF_ALU | BPF_DIV | BPF_K:\n\t\tcase BPF_ALU | BPF_DIV | BPF_X:\n\t\tcase BPF_ALU | BPF_MOD | BPF_K:\n\t\tcase BPF_ALU | BPF_MOD | BPF_X:\n\t\t\tswitch (BPF_SRC(code)) {\n\t\t\tcase BPF_X:\n\t\t\t\temit_ia32_div_mod_r(BPF_OP(code), dst_lo,\n\t\t\t\t\t\t    src_lo, dstk, sstk, &prog);\n\t\t\t\tbreak;\n\t\t\tcase BPF_K:\n\t\t\t\t \n\t\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_ECX),\n\t\t\t\t\t    imm32);\n\t\t\t\temit_ia32_div_mod_r(BPF_OP(code), dst_lo,\n\t\t\t\t\t\t    IA32_ECX, dstk, false,\n\t\t\t\t\t\t    &prog);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!bpf_prog->aux->verifier_zext)\n\t\t\t\temit_ia32_mov_i(dst_hi, 0, dstk, &prog);\n\t\t\tbreak;\n\t\tcase BPF_ALU64 | BPF_DIV | BPF_K:\n\t\tcase BPF_ALU64 | BPF_DIV | BPF_X:\n\t\tcase BPF_ALU64 | BPF_MOD | BPF_K:\n\t\tcase BPF_ALU64 | BPF_MOD | BPF_X:\n\t\t\tgoto notyet;\n\t\t \n\t\t \n\t\tcase BPF_ALU | BPF_RSH | BPF_K:\n\t\tcase BPF_ALU | BPF_LSH | BPF_K:\n\t\t\tif (unlikely(imm32 > 31))\n\t\t\t\treturn -EINVAL;\n\t\t\t \n\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_ECX), imm32);\n\t\t\temit_ia32_shift_r(BPF_OP(code), dst_lo, IA32_ECX, dstk,\n\t\t\t\t\t  false, &prog);\n\t\t\tif (!bpf_prog->aux->verifier_zext)\n\t\t\t\temit_ia32_mov_i(dst_hi, 0, dstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU64 | BPF_LSH | BPF_K:\n\t\t\tif (unlikely(imm32 > 63))\n\t\t\t\treturn -EINVAL;\n\t\t\temit_ia32_lsh_i64(dst, imm32, dstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU64 | BPF_RSH | BPF_K:\n\t\t\tif (unlikely(imm32 > 63))\n\t\t\t\treturn -EINVAL;\n\t\t\temit_ia32_rsh_i64(dst, imm32, dstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU64 | BPF_LSH | BPF_X:\n\t\t\temit_ia32_lsh_r64(dst, src, dstk, sstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU64 | BPF_RSH | BPF_X:\n\t\t\temit_ia32_rsh_r64(dst, src, dstk, sstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU64 | BPF_ARSH | BPF_X:\n\t\t\temit_ia32_arsh_r64(dst, src, dstk, sstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU64 | BPF_ARSH | BPF_K:\n\t\t\tif (unlikely(imm32 > 63))\n\t\t\t\treturn -EINVAL;\n\t\t\temit_ia32_arsh_i64(dst, imm32, dstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU | BPF_NEG:\n\t\t\temit_ia32_alu_i(is64, false, BPF_OP(code),\n\t\t\t\t\tdst_lo, 0, dstk, &prog);\n\t\t\tif (!bpf_prog->aux->verifier_zext)\n\t\t\t\temit_ia32_mov_i(dst_hi, 0, dstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU64 | BPF_NEG:\n\t\t\temit_ia32_neg64(dst, dstk, &prog);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU64 | BPF_MUL | BPF_X:\n\t\tcase BPF_ALU64 | BPF_MUL | BPF_K:\n\t\t\tswitch (BPF_SRC(code)) {\n\t\t\tcase BPF_X:\n\t\t\t\temit_ia32_mul_r64(dst, src, dstk, sstk, &prog);\n\t\t\t\tbreak;\n\t\t\tcase BPF_K:\n\t\t\t\temit_ia32_mul_i64(dst, imm32, dstk, &prog);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU | BPF_END | BPF_FROM_LE:\n\t\t\temit_ia32_to_le_r64(dst, imm32, dstk, &prog,\n\t\t\t\t\t    bpf_prog->aux);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ALU | BPF_END | BPF_FROM_BE:\n\t\t\temit_ia32_to_be_r64(dst, imm32, dstk, &prog,\n\t\t\t\t\t    bpf_prog->aux);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_LD | BPF_IMM | BPF_DW: {\n\t\t\ts32 hi, lo = imm32;\n\n\t\t\thi = insn[1].imm;\n\t\t\temit_ia32_mov_i(dst_lo, lo, dstk, &prog);\n\t\t\temit_ia32_mov_i(dst_hi, hi, dstk, &prog);\n\t\t\tinsn++;\n\t\t\ti++;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tcase BPF_ST | BPF_NOSPEC:\n\t\t\tif (boot_cpu_has(X86_FEATURE_XMM2))\n\t\t\t\t \n\t\t\t\tEMIT3(0x0F, 0xAE, 0xE8);\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_ST | BPF_MEM | BPF_H:\n\t\tcase BPF_ST | BPF_MEM | BPF_B:\n\t\tcase BPF_ST | BPF_MEM | BPF_W:\n\t\tcase BPF_ST | BPF_MEM | BPF_DW:\n\t\t\tif (dstk)\n\t\t\t\t \n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t\t      STACK_VAR(dst_lo));\n\t\t\telse\n\t\t\t\t \n\t\t\t\tEMIT2(0x8B, add_2reg(0xC0, dst_lo, IA32_EAX));\n\n\t\t\tswitch (BPF_SIZE(code)) {\n\t\t\tcase BPF_B:\n\t\t\t\tEMIT(0xC6, 1); break;\n\t\t\tcase BPF_H:\n\t\t\t\tEMIT2(0x66, 0xC7); break;\n\t\t\tcase BPF_W:\n\t\t\tcase BPF_DW:\n\t\t\t\tEMIT(0xC7, 1); break;\n\t\t\t}\n\n\t\t\tif (is_imm8(insn->off))\n\t\t\t\tEMIT2(add_1reg(0x40, IA32_EAX), insn->off);\n\t\t\telse\n\t\t\t\tEMIT1_off32(add_1reg(0x80, IA32_EAX),\n\t\t\t\t\t    insn->off);\n\t\t\tEMIT(imm32, bpf_size_to_x86_bytes(BPF_SIZE(code)));\n\n\t\t\tif (BPF_SIZE(code) == BPF_DW) {\n\t\t\t\tu32 hi;\n\n\t\t\t\thi = imm32 & (1<<31) ? (u32)~0 : 0;\n\t\t\t\tEMIT2_off32(0xC7, add_1reg(0x80, IA32_EAX),\n\t\t\t\t\t    insn->off + 4);\n\t\t\t\tEMIT(hi, 4);\n\t\t\t}\n\t\t\tbreak;\n\n\t\t \n\t\tcase BPF_STX | BPF_MEM | BPF_B:\n\t\tcase BPF_STX | BPF_MEM | BPF_H:\n\t\tcase BPF_STX | BPF_MEM | BPF_W:\n\t\tcase BPF_STX | BPF_MEM | BPF_DW:\n\t\t\tif (dstk)\n\t\t\t\t \n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t\t      STACK_VAR(dst_lo));\n\t\t\telse\n\t\t\t\t \n\t\t\t\tEMIT2(0x8B, add_2reg(0xC0, dst_lo, IA32_EAX));\n\n\t\t\tif (sstk)\n\t\t\t\t \n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t\t\t      STACK_VAR(src_lo));\n\t\t\telse\n\t\t\t\t \n\t\t\t\tEMIT2(0x8B, add_2reg(0xC0, src_lo, IA32_EDX));\n\n\t\t\tswitch (BPF_SIZE(code)) {\n\t\t\tcase BPF_B:\n\t\t\t\tEMIT(0x88, 1); break;\n\t\t\tcase BPF_H:\n\t\t\t\tEMIT2(0x66, 0x89); break;\n\t\t\tcase BPF_W:\n\t\t\tcase BPF_DW:\n\t\t\t\tEMIT(0x89, 1); break;\n\t\t\t}\n\n\t\t\tif (is_imm8(insn->off))\n\t\t\t\tEMIT2(add_2reg(0x40, IA32_EAX, IA32_EDX),\n\t\t\t\t      insn->off);\n\t\t\telse\n\t\t\t\tEMIT1_off32(add_2reg(0x80, IA32_EAX, IA32_EDX),\n\t\t\t\t\t    insn->off);\n\n\t\t\tif (BPF_SIZE(code) == BPF_DW) {\n\t\t\t\tif (sstk)\n\t\t\t\t\t \n\t\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t\t\t     IA32_EDX),\n\t\t\t\t\t      STACK_VAR(src_hi));\n\t\t\t\telse\n\t\t\t\t\t \n\t\t\t\t\tEMIT2(0x8B, add_2reg(0xC0, src_hi,\n\t\t\t\t\t\t\t     IA32_EDX));\n\t\t\t\tEMIT1(0x89);\n\t\t\t\tif (is_imm8(insn->off + 4)) {\n\t\t\t\t\tEMIT2(add_2reg(0x40, IA32_EAX,\n\t\t\t\t\t\t       IA32_EDX),\n\t\t\t\t\t      insn->off + 4);\n\t\t\t\t} else {\n\t\t\t\t\tEMIT1(add_2reg(0x80, IA32_EAX,\n\t\t\t\t\t\t       IA32_EDX));\n\t\t\t\t\tEMIT(insn->off + 4, 4);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\t \n\t\tcase BPF_LDX | BPF_MEM | BPF_B:\n\t\tcase BPF_LDX | BPF_MEM | BPF_H:\n\t\tcase BPF_LDX | BPF_MEM | BPF_W:\n\t\tcase BPF_LDX | BPF_MEM | BPF_DW:\n\t\t\tif (sstk)\n\t\t\t\t \n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t\t      STACK_VAR(src_lo));\n\t\t\telse\n\t\t\t\t \n\t\t\t\tEMIT2(0x8B, add_2reg(0xC0, src_lo, IA32_EAX));\n\n\t\t\tswitch (BPF_SIZE(code)) {\n\t\t\tcase BPF_B:\n\t\t\t\tEMIT2(0x0F, 0xB6); break;\n\t\t\tcase BPF_H:\n\t\t\t\tEMIT2(0x0F, 0xB7); break;\n\t\t\tcase BPF_W:\n\t\t\tcase BPF_DW:\n\t\t\t\tEMIT(0x8B, 1); break;\n\t\t\t}\n\n\t\t\tif (is_imm8(insn->off))\n\t\t\t\tEMIT2(add_2reg(0x40, IA32_EAX, IA32_EDX),\n\t\t\t\t      insn->off);\n\t\t\telse\n\t\t\t\tEMIT1_off32(add_2reg(0x80, IA32_EAX, IA32_EDX),\n\t\t\t\t\t    insn->off);\n\n\t\t\tif (dstk)\n\t\t\t\t \n\t\t\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t\t\t      STACK_VAR(dst_lo));\n\t\t\telse\n\t\t\t\t \n\t\t\t\tEMIT2(0x89, add_2reg(0xC0, dst_lo, IA32_EDX));\n\t\t\tswitch (BPF_SIZE(code)) {\n\t\t\tcase BPF_B:\n\t\t\tcase BPF_H:\n\t\t\tcase BPF_W:\n\t\t\t\tif (bpf_prog->aux->verifier_zext)\n\t\t\t\t\tbreak;\n\t\t\t\tif (dstk) {\n\t\t\t\t\tEMIT3(0xC7, add_1reg(0x40, IA32_EBP),\n\t\t\t\t\t      STACK_VAR(dst_hi));\n\t\t\t\t\tEMIT(0x0, 4);\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tEMIT2(0x33,\n\t\t\t\t\t      add_2reg(0xC0, dst_hi, dst_hi));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase BPF_DW:\n\t\t\t\tEMIT2_off32(0x8B,\n\t\t\t\t\t    add_2reg(0x80, IA32_EAX, IA32_EDX),\n\t\t\t\t\t    insn->off + 4);\n\t\t\t\tif (dstk)\n\t\t\t\t\tEMIT3(0x89,\n\t\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t\t       IA32_EDX),\n\t\t\t\t\t      STACK_VAR(dst_hi));\n\t\t\t\telse\n\t\t\t\t\tEMIT2(0x89,\n\t\t\t\t\t      add_2reg(0xC0, dst_hi, IA32_EDX));\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\t \n\t\tcase BPF_JMP | BPF_CALL:\n\t\t{\n\t\t\tconst u8 *r1 = bpf2ia32[BPF_REG_1];\n\t\t\tconst u8 *r2 = bpf2ia32[BPF_REG_2];\n\t\t\tconst u8 *r3 = bpf2ia32[BPF_REG_3];\n\t\t\tconst u8 *r4 = bpf2ia32[BPF_REG_4];\n\t\t\tconst u8 *r5 = bpf2ia32[BPF_REG_5];\n\n\t\t\tif (insn->src_reg == BPF_PSEUDO_CALL)\n\t\t\t\tgoto notyet;\n\n\t\t\tif (insn->src_reg == BPF_PSEUDO_KFUNC_CALL) {\n\t\t\t\tint err;\n\n\t\t\t\terr = emit_kfunc_call(bpf_prog,\n\t\t\t\t\t\t      image + addrs[i],\n\t\t\t\t\t\t      insn, &prog);\n\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tfunc = (u8 *) __bpf_call_base + imm32;\n\t\t\tjmp_offset = func - (image + addrs[i]);\n\n\t\t\tif (!imm32 || !is_simm32(jmp_offset)) {\n\t\t\t\tpr_err(\"unsupported BPF func %d addr %p image %p\\n\",\n\t\t\t\t       imm32, func, image);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t \n\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t      STACK_VAR(r1[0]));\n\t\t\t \n\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t\t      STACK_VAR(r1[1]));\n\n\t\t\temit_push_r64(r5, &prog);\n\t\t\temit_push_r64(r4, &prog);\n\t\t\temit_push_r64(r3, &prog);\n\t\t\temit_push_r64(r2, &prog);\n\n\t\t\tEMIT1_off32(0xE8, jmp_offset + 9);\n\n\t\t\t \n\t\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t      STACK_VAR(r0[0]));\n\t\t\t \n\t\t\tEMIT3(0x89, add_2reg(0x40, IA32_EBP, IA32_EDX),\n\t\t\t      STACK_VAR(r0[1]));\n\n\t\t\t \n\t\t\tEMIT3(0x83, add_1reg(0xC0, IA32_ESP), 32);\n\t\t\tbreak;\n\t\t}\n\t\tcase BPF_JMP | BPF_TAIL_CALL:\n\t\t\temit_bpf_tail_call(&prog, image + addrs[i - 1]);\n\t\t\tbreak;\n\n\t\t \n\t\tcase BPF_JMP | BPF_JEQ | BPF_X:\n\t\tcase BPF_JMP | BPF_JNE | BPF_X:\n\t\tcase BPF_JMP | BPF_JGT | BPF_X:\n\t\tcase BPF_JMP | BPF_JLT | BPF_X:\n\t\tcase BPF_JMP | BPF_JGE | BPF_X:\n\t\tcase BPF_JMP | BPF_JLE | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JEQ | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JNE | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JGT | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JLT | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JGE | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JLE | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JSGT | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JSLE | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JSLT | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JSGE | BPF_X: {\n\t\t\tbool is_jmp64 = BPF_CLASS(insn->code) == BPF_JMP;\n\t\t\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\t\t\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\t\t\tu8 sreg_lo = sstk ? IA32_ECX : src_lo;\n\t\t\tu8 sreg_hi = sstk ? IA32_EBX : src_hi;\n\n\t\t\tif (dstk) {\n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t\t      STACK_VAR(dst_lo));\n\t\t\t\tif (is_jmp64)\n\t\t\t\t\tEMIT3(0x8B,\n\t\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t\t       IA32_EDX),\n\t\t\t\t\t      STACK_VAR(dst_hi));\n\t\t\t}\n\n\t\t\tif (sstk) {\n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX),\n\t\t\t\t      STACK_VAR(src_lo));\n\t\t\t\tif (is_jmp64)\n\t\t\t\t\tEMIT3(0x8B,\n\t\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t\t       IA32_EBX),\n\t\t\t\t\t      STACK_VAR(src_hi));\n\t\t\t}\n\n\t\t\tif (is_jmp64) {\n\t\t\t\t \n\t\t\t\tEMIT2(0x39, add_2reg(0xC0, dreg_hi, sreg_hi));\n\t\t\t\tEMIT2(IA32_JNE, 2);\n\t\t\t}\n\t\t\t \n\t\t\tEMIT2(0x39, add_2reg(0xC0, dreg_lo, sreg_lo));\n\t\t\tgoto emit_cond_jmp;\n\t\t}\n\t\tcase BPF_JMP | BPF_JSGT | BPF_X:\n\t\tcase BPF_JMP | BPF_JSLE | BPF_X:\n\t\tcase BPF_JMP | BPF_JSLT | BPF_X:\n\t\tcase BPF_JMP | BPF_JSGE | BPF_X: {\n\t\t\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\t\t\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\t\t\tu8 sreg_lo = sstk ? IA32_ECX : src_lo;\n\t\t\tu8 sreg_hi = sstk ? IA32_EBX : src_hi;\n\n\t\t\tif (dstk) {\n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t\t      STACK_VAR(dst_lo));\n\t\t\t\tEMIT3(0x8B,\n\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t       IA32_EDX),\n\t\t\t\t      STACK_VAR(dst_hi));\n\t\t\t}\n\n\t\t\tif (sstk) {\n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX),\n\t\t\t\t      STACK_VAR(src_lo));\n\t\t\t\tEMIT3(0x8B,\n\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t       IA32_EBX),\n\t\t\t\t      STACK_VAR(src_hi));\n\t\t\t}\n\n\t\t\t \n\t\t\tEMIT2(0x39, add_2reg(0xC0, dreg_hi, sreg_hi));\n\t\t\tEMIT2(IA32_JNE, 10);\n\t\t\t \n\t\t\tEMIT2(0x39, add_2reg(0xC0, dreg_lo, sreg_lo));\n\t\t\tgoto emit_cond_jmp_signed;\n\t\t}\n\t\tcase BPF_JMP | BPF_JSET | BPF_X:\n\t\tcase BPF_JMP32 | BPF_JSET | BPF_X: {\n\t\t\tbool is_jmp64 = BPF_CLASS(insn->code) == BPF_JMP;\n\t\t\tu8 dreg_lo = IA32_EAX;\n\t\t\tu8 dreg_hi = IA32_EDX;\n\t\t\tu8 sreg_lo = sstk ? IA32_ECX : src_lo;\n\t\t\tu8 sreg_hi = sstk ? IA32_EBX : src_hi;\n\n\t\t\tif (dstk) {\n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t\t      STACK_VAR(dst_lo));\n\t\t\t\tif (is_jmp64)\n\t\t\t\t\tEMIT3(0x8B,\n\t\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t\t       IA32_EDX),\n\t\t\t\t\t      STACK_VAR(dst_hi));\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tEMIT2(0x89, add_2reg(0xC0, dreg_lo, dst_lo));\n\t\t\t\tif (is_jmp64)\n\t\t\t\t\t \n\t\t\t\t\tEMIT2(0x89,\n\t\t\t\t\t      add_2reg(0xC0, dreg_hi, dst_hi));\n\t\t\t}\n\n\t\t\tif (sstk) {\n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX),\n\t\t\t\t      STACK_VAR(src_lo));\n\t\t\t\tif (is_jmp64)\n\t\t\t\t\tEMIT3(0x8B,\n\t\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t\t       IA32_EBX),\n\t\t\t\t\t      STACK_VAR(src_hi));\n\t\t\t}\n\t\t\t \n\t\t\tEMIT2(0x23, add_2reg(0xC0, sreg_lo, dreg_lo));\n\t\t\tif (is_jmp64) {\n\t\t\t\t \n\t\t\t\tEMIT2(0x23, add_2reg(0xC0, sreg_hi, dreg_hi));\n\t\t\t\t \n\t\t\t\tEMIT2(0x09, add_2reg(0xC0, dreg_lo, dreg_hi));\n\t\t\t}\n\t\t\tgoto emit_cond_jmp;\n\t\t}\n\t\tcase BPF_JMP | BPF_JSET | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JSET | BPF_K: {\n\t\t\tbool is_jmp64 = BPF_CLASS(insn->code) == BPF_JMP;\n\t\t\tu8 dreg_lo = IA32_EAX;\n\t\t\tu8 dreg_hi = IA32_EDX;\n\t\t\tu8 sreg_lo = IA32_ECX;\n\t\t\tu8 sreg_hi = IA32_EBX;\n\t\t\tu32 hi;\n\n\t\t\tif (dstk) {\n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t\t      STACK_VAR(dst_lo));\n\t\t\t\tif (is_jmp64)\n\t\t\t\t\tEMIT3(0x8B,\n\t\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t\t       IA32_EDX),\n\t\t\t\t\t      STACK_VAR(dst_hi));\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tEMIT2(0x89, add_2reg(0xC0, dreg_lo, dst_lo));\n\t\t\t\tif (is_jmp64)\n\t\t\t\t\t \n\t\t\t\t\tEMIT2(0x89,\n\t\t\t\t\t      add_2reg(0xC0, dreg_hi, dst_hi));\n\t\t\t}\n\n\t\t\t \n\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, sreg_lo), imm32);\n\n\t\t\t \n\t\t\tEMIT2(0x23, add_2reg(0xC0, sreg_lo, dreg_lo));\n\t\t\tif (is_jmp64) {\n\t\t\t\thi = imm32 & (1 << 31) ? (u32)~0 : 0;\n\t\t\t\t \n\t\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, sreg_hi), hi);\n\t\t\t\t \n\t\t\t\tEMIT2(0x23, add_2reg(0xC0, sreg_hi, dreg_hi));\n\t\t\t\t \n\t\t\t\tEMIT2(0x09, add_2reg(0xC0, dreg_lo, dreg_hi));\n\t\t\t}\n\t\t\tgoto emit_cond_jmp;\n\t\t}\n\t\tcase BPF_JMP | BPF_JEQ | BPF_K:\n\t\tcase BPF_JMP | BPF_JNE | BPF_K:\n\t\tcase BPF_JMP | BPF_JGT | BPF_K:\n\t\tcase BPF_JMP | BPF_JLT | BPF_K:\n\t\tcase BPF_JMP | BPF_JGE | BPF_K:\n\t\tcase BPF_JMP | BPF_JLE | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JEQ | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JNE | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JGT | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JLT | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JGE | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JLE | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JSGT | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JSLE | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JSLT | BPF_K:\n\t\tcase BPF_JMP32 | BPF_JSGE | BPF_K: {\n\t\t\tbool is_jmp64 = BPF_CLASS(insn->code) == BPF_JMP;\n\t\t\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\t\t\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\t\t\tu8 sreg_lo = IA32_ECX;\n\t\t\tu8 sreg_hi = IA32_EBX;\n\t\t\tu32 hi;\n\n\t\t\tif (dstk) {\n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t\t      STACK_VAR(dst_lo));\n\t\t\t\tif (is_jmp64)\n\t\t\t\t\tEMIT3(0x8B,\n\t\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t\t       IA32_EDX),\n\t\t\t\t\t      STACK_VAR(dst_hi));\n\t\t\t}\n\n\t\t\t \n\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_ECX), imm32);\n\t\t\tif (is_jmp64) {\n\t\t\t\thi = imm32 & (1 << 31) ? (u32)~0 : 0;\n\t\t\t\t \n\t\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_EBX), hi);\n\t\t\t\t \n\t\t\t\tEMIT2(0x39, add_2reg(0xC0, dreg_hi, sreg_hi));\n\t\t\t\tEMIT2(IA32_JNE, 2);\n\t\t\t}\n\t\t\t \n\t\t\tEMIT2(0x39, add_2reg(0xC0, dreg_lo, sreg_lo));\n\nemit_cond_jmp:\t\tjmp_cond = get_cond_jmp_opcode(BPF_OP(code), false);\n\t\t\tif (jmp_cond == COND_JMP_OPCODE_INVALID)\n\t\t\t\treturn -EFAULT;\n\t\t\tjmp_offset = addrs[i + insn->off] - addrs[i];\n\t\t\tif (is_imm8(jmp_offset)) {\n\t\t\t\tEMIT2(jmp_cond, jmp_offset);\n\t\t\t} else if (is_simm32(jmp_offset)) {\n\t\t\t\tEMIT2_off32(0x0F, jmp_cond + 0x10, jmp_offset);\n\t\t\t} else {\n\t\t\t\tpr_err(\"cond_jmp gen bug %llx\\n\", jmp_offset);\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase BPF_JMP | BPF_JSGT | BPF_K:\n\t\tcase BPF_JMP | BPF_JSLE | BPF_K:\n\t\tcase BPF_JMP | BPF_JSLT | BPF_K:\n\t\tcase BPF_JMP | BPF_JSGE | BPF_K: {\n\t\t\tu8 dreg_lo = dstk ? IA32_EAX : dst_lo;\n\t\t\tu8 dreg_hi = dstk ? IA32_EDX : dst_hi;\n\t\t\tu8 sreg_lo = IA32_ECX;\n\t\t\tu8 sreg_hi = IA32_EBX;\n\t\t\tu32 hi;\n\n\t\t\tif (dstk) {\n\t\t\t\tEMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),\n\t\t\t\t      STACK_VAR(dst_lo));\n\t\t\t\tEMIT3(0x8B,\n\t\t\t\t      add_2reg(0x40, IA32_EBP,\n\t\t\t\t\t       IA32_EDX),\n\t\t\t\t      STACK_VAR(dst_hi));\n\t\t\t}\n\n\t\t\t \n\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_ECX), imm32);\n\t\t\thi = imm32 & (1 << 31) ? (u32)~0 : 0;\n\t\t\t \n\t\t\tEMIT2_off32(0xC7, add_1reg(0xC0, IA32_EBX), hi);\n\t\t\t \n\t\t\tEMIT2(0x39, add_2reg(0xC0, dreg_hi, sreg_hi));\n\t\t\tEMIT2(IA32_JNE, 10);\n\t\t\t \n\t\t\tEMIT2(0x39, add_2reg(0xC0, dreg_lo, sreg_lo));\n\n\t\t\t \nemit_cond_jmp_signed:\t \n\t\t\tjmp_cond = get_cond_jmp_opcode(BPF_OP(code), true);\n\t\t\tif (jmp_cond == COND_JMP_OPCODE_INVALID)\n\t\t\t\treturn -EFAULT;\n\t\t\tjmp_offset = addrs[i + insn->off] - addrs[i] + 8;\n\t\t\tif (is_simm32(jmp_offset)) {\n\t\t\t\tEMIT2_off32(0x0F, jmp_cond + 0x10, jmp_offset);\n\t\t\t} else {\n\t\t\t\tpr_err(\"cond_jmp gen bug %llx\\n\", jmp_offset);\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\tEMIT2(0xEB, 6);\n\n\t\t\t \n\t\t\tjmp_cond = get_cond_jmp_opcode(BPF_OP(code), false);\n\t\t\tif (jmp_cond == COND_JMP_OPCODE_INVALID)\n\t\t\t\treturn -EFAULT;\n\t\t\tjmp_offset = addrs[i + insn->off] - addrs[i];\n\t\t\tif (is_simm32(jmp_offset)) {\n\t\t\t\tEMIT2_off32(0x0F, jmp_cond + 0x10, jmp_offset);\n\t\t\t} else {\n\t\t\t\tpr_err(\"cond_jmp gen bug %llx\\n\", jmp_offset);\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase BPF_JMP | BPF_JA:\n\t\t\tif (insn->off == -1)\n\t\t\t\t \n\t\t\t\tjmp_offset = -2;\n\t\t\telse\n\t\t\t\tjmp_offset = addrs[i + insn->off] - addrs[i];\n\n\t\t\tif (!jmp_offset)\n\t\t\t\t \n\t\t\t\tbreak;\nemit_jmp:\n\t\t\tif (is_imm8(jmp_offset)) {\n\t\t\t\tEMIT2(0xEB, jmp_offset);\n\t\t\t} else if (is_simm32(jmp_offset)) {\n\t\t\t\tEMIT1_off32(0xE9, jmp_offset);\n\t\t\t} else {\n\t\t\t\tpr_err(\"jmp gen bug %llx\\n\", jmp_offset);\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase BPF_STX | BPF_ATOMIC | BPF_W:\n\t\tcase BPF_STX | BPF_ATOMIC | BPF_DW:\n\t\t\tgoto notyet;\n\t\tcase BPF_JMP | BPF_EXIT:\n\t\t\tif (seen_exit) {\n\t\t\t\tjmp_offset = ctx->cleanup_addr - addrs[i];\n\t\t\t\tgoto emit_jmp;\n\t\t\t}\n\t\t\tseen_exit = true;\n\t\t\t \n\t\t\tctx->cleanup_addr = proglen;\n\t\t\temit_epilogue(&prog, bpf_prog->aux->stack_depth);\n\t\t\tbreak;\nnotyet:\n\t\t\tpr_info_once(\"*** NOT YET: opcode %02x ***\\n\", code);\n\t\t\treturn -EFAULT;\n\t\tdefault:\n\t\t\t \n\t\t\tpr_err(\"bpf_jit: unknown opcode %02x\\n\", code);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tilen = prog - temp;\n\t\tif (ilen > BPF_MAX_INSN_SIZE) {\n\t\t\tpr_err(\"bpf_jit: fatal insn size error\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tif (image) {\n\t\t\t \n\t\t\tif (unlikely(proglen + ilen > oldproglen ||\n\t\t\t\t     proglen + ilen != addrs[i])) {\n\t\t\t\tpr_err(\"bpf_jit: fatal error\\n\");\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\tmemcpy(image + proglen, temp, ilen);\n\t\t}\n\t\tproglen += ilen;\n\t\taddrs[i] = proglen;\n\t\tprog = temp;\n\t}\n\treturn proglen;\n}\n\nbool bpf_jit_needs_zext(void)\n{\n\treturn true;\n}\n\nstruct bpf_prog *bpf_int_jit_compile(struct bpf_prog *prog)\n{\n\tstruct bpf_binary_header *header = NULL;\n\tstruct bpf_prog *tmp, *orig_prog = prog;\n\tint proglen, oldproglen = 0;\n\tstruct jit_context ctx = {};\n\tbool tmp_blinded = false;\n\tu8 *image = NULL;\n\tint *addrs;\n\tint pass;\n\tint i;\n\n\tif (!prog->jit_requested)\n\t\treturn orig_prog;\n\n\ttmp = bpf_jit_blind_constants(prog);\n\t \n\tif (IS_ERR(tmp))\n\t\treturn orig_prog;\n\tif (tmp != prog) {\n\t\ttmp_blinded = true;\n\t\tprog = tmp;\n\t}\n\n\taddrs = kmalloc_array(prog->len, sizeof(*addrs), GFP_KERNEL);\n\tif (!addrs) {\n\t\tprog = orig_prog;\n\t\tgoto out;\n\t}\n\n\t \n\tfor (proglen = 0, i = 0; i < prog->len; i++) {\n\t\tproglen += 64;\n\t\taddrs[i] = proglen;\n\t}\n\tctx.cleanup_addr = proglen;\n\n\t \n\tfor (pass = 0; pass < 20 || image; pass++) {\n\t\tproglen = do_jit(prog, addrs, image, oldproglen, &ctx);\n\t\tif (proglen <= 0) {\nout_image:\n\t\t\timage = NULL;\n\t\t\tif (header)\n\t\t\t\tbpf_jit_binary_free(header);\n\t\t\tprog = orig_prog;\n\t\t\tgoto out_addrs;\n\t\t}\n\t\tif (image) {\n\t\t\tif (proglen != oldproglen) {\n\t\t\t\tpr_err(\"bpf_jit: proglen=%d != oldproglen=%d\\n\",\n\t\t\t\t       proglen, oldproglen);\n\t\t\t\tgoto out_image;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (proglen == oldproglen) {\n\t\t\theader = bpf_jit_binary_alloc(proglen, &image,\n\t\t\t\t\t\t      1, jit_fill_hole);\n\t\t\tif (!header) {\n\t\t\t\tprog = orig_prog;\n\t\t\t\tgoto out_addrs;\n\t\t\t}\n\t\t}\n\t\toldproglen = proglen;\n\t\tcond_resched();\n\t}\n\n\tif (bpf_jit_enable > 1)\n\t\tbpf_jit_dump(prog->len, proglen, pass + 1, image);\n\n\tif (image) {\n\t\tbpf_jit_binary_lock_ro(header);\n\t\tprog->bpf_func = (void *)image;\n\t\tprog->jited = 1;\n\t\tprog->jited_len = proglen;\n\t} else {\n\t\tprog = orig_prog;\n\t}\n\nout_addrs:\n\tkfree(addrs);\nout:\n\tif (tmp_blinded)\n\t\tbpf_jit_prog_release_other(prog, prog == orig_prog ?\n\t\t\t\t\t   tmp : orig_prog);\n\treturn prog;\n}\n\nbool bpf_jit_supports_kfunc_call(void)\n{\n\treturn true;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}