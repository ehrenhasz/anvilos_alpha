{
  "module_name": "entry_64.S",
  "hash_id": "814bc3caf03042382c401f33d556467189e5a7f6cb2a2e895a47ea1efe89c96b",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/entry/entry_64.S",
  "human_readable_source": " \n \n#include <linux/linkage.h>\n#include <asm/segment.h>\n#include <asm/cache.h>\n#include <asm/errno.h>\n#include <asm/asm-offsets.h>\n#include <asm/msr.h>\n#include <asm/unistd.h>\n#include <asm/thread_info.h>\n#include <asm/hw_irq.h>\n#include <asm/page_types.h>\n#include <asm/irqflags.h>\n#include <asm/paravirt.h>\n#include <asm/percpu.h>\n#include <asm/asm.h>\n#include <asm/smap.h>\n#include <asm/pgtable_types.h>\n#include <asm/export.h>\n#include <asm/frame.h>\n#include <asm/trapnr.h>\n#include <asm/nospec-branch.h>\n#include <asm/fsgsbase.h>\n#include <linux/err.h>\n\n#include \"calling.h\"\n\n.code64\n.section .entry.text, \"ax\"\n\n \n\nSYM_CODE_START(entry_SYSCALL_64)\n\tUNWIND_HINT_ENTRY\n\tENDBR\n\n\tswapgs\n\t \n\tmovq\t%rsp, PER_CPU_VAR(cpu_tss_rw + TSS_sp2)\n\tSWITCH_TO_KERNEL_CR3 scratch_reg=%rsp\n\tmovq\tPER_CPU_VAR(pcpu_hot + X86_top_of_stack), %rsp\n\nSYM_INNER_LABEL(entry_SYSCALL_64_safe_stack, SYM_L_GLOBAL)\n\tANNOTATE_NOENDBR\n\n\t \n\tpushq\t$__USER_DS\t\t\t\t \n\tpushq\tPER_CPU_VAR(cpu_tss_rw + TSS_sp2)\t \n\tpushq\t%r11\t\t\t\t\t \n\tpushq\t$__USER_CS\t\t\t\t \n\tpushq\t%rcx\t\t\t\t\t \nSYM_INNER_LABEL(entry_SYSCALL_64_after_hwframe, SYM_L_GLOBAL)\n\tpushq\t%rax\t\t\t\t\t \n\n\tPUSH_AND_CLEAR_REGS rax=$-ENOSYS\n\n\t \n\tmovq\t%rsp, %rdi\n\t \n\tmovslq\t%eax, %rsi\n\n\t \n\tIBRS_ENTER\n\tUNTRAIN_RET\n\n\tcall\tdo_syscall_64\t\t \n\n\t \n\n\tALTERNATIVE \"\", \"jmp\tswapgs_restore_regs_and_return_to_usermode\", \\\n\t\tX86_FEATURE_XENPV\n\n\tmovq\tRCX(%rsp), %rcx\n\tmovq\tRIP(%rsp), %r11\n\n\tcmpq\t%rcx, %r11\t \n\tjne\tswapgs_restore_regs_and_return_to_usermode\n\n\t \n#ifdef CONFIG_X86_5LEVEL\n\tALTERNATIVE \"shl $(64 - 48), %rcx; sar $(64 - 48), %rcx\", \\\n\t\t\"shl $(64 - 57), %rcx; sar $(64 - 57), %rcx\", X86_FEATURE_LA57\n#else\n\tshl\t$(64 - (__VIRTUAL_MASK_SHIFT+1)), %rcx\n\tsar\t$(64 - (__VIRTUAL_MASK_SHIFT+1)), %rcx\n#endif\n\n\t \n\tcmpq\t%rcx, %r11\n\tjne\tswapgs_restore_regs_and_return_to_usermode\n\n\tcmpq\t$__USER_CS, CS(%rsp)\t\t \n\tjne\tswapgs_restore_regs_and_return_to_usermode\n\n\tmovq\tR11(%rsp), %r11\n\tcmpq\t%r11, EFLAGS(%rsp)\t\t \n\tjne\tswapgs_restore_regs_and_return_to_usermode\n\n\t \n\ttestq\t$(X86_EFLAGS_RF|X86_EFLAGS_TF), %r11\n\tjnz\tswapgs_restore_regs_and_return_to_usermode\n\n\t \n\n\tcmpq\t$__USER_DS, SS(%rsp)\t\t \n\tjne\tswapgs_restore_regs_and_return_to_usermode\n\n\t \nsyscall_return_via_sysret:\n\tIBRS_EXIT\n\tPOP_REGS pop_rdi=0\n\n\t \n\tmovq\t%rsp, %rdi\n\tmovq\tPER_CPU_VAR(cpu_tss_rw + TSS_sp0), %rsp\n\tUNWIND_HINT_END_OF_STACK\n\n\tpushq\tRSP-RDI(%rdi)\t \n\tpushq\t(%rdi)\t\t \n\n\t \n\tSTACKLEAK_ERASE_NOCLOBBER\n\n\tSWITCH_TO_USER_CR3_STACK scratch_reg=%rdi\n\n\tpopq\t%rdi\n\tpopq\t%rsp\nSYM_INNER_LABEL(entry_SYSRETQ_unsafe_stack, SYM_L_GLOBAL)\n\tANNOTATE_NOENDBR\n\tswapgs\n\tsysretq\nSYM_INNER_LABEL(entry_SYSRETQ_end, SYM_L_GLOBAL)\n\tANNOTATE_NOENDBR\n\tint3\nSYM_CODE_END(entry_SYSCALL_64)\n\n \n.pushsection .text, \"ax\"\nSYM_FUNC_START(__switch_to_asm)\n\t \n\tpushq\t%rbp\n\tpushq\t%rbx\n\tpushq\t%r12\n\tpushq\t%r13\n\tpushq\t%r14\n\tpushq\t%r15\n\n\t \n\tmovq\t%rsp, TASK_threadsp(%rdi)\n\tmovq\tTASK_threadsp(%rsi), %rsp\n\n#ifdef CONFIG_STACKPROTECTOR\n\tmovq\tTASK_stack_canary(%rsi), %rbx\n\tmovq\t%rbx, PER_CPU_VAR(fixed_percpu_data) + FIXED_stack_canary\n#endif\n\n\t \n\tFILL_RETURN_BUFFER %r12, RSB_CLEAR_LOOPS, X86_FEATURE_RSB_CTXSW\n\n\t \n\tpopq\t%r15\n\tpopq\t%r14\n\tpopq\t%r13\n\tpopq\t%r12\n\tpopq\t%rbx\n\tpopq\t%rbp\n\n\tjmp\t__switch_to\nSYM_FUNC_END(__switch_to_asm)\n.popsection\n\n \n.pushsection .text, \"ax\"\nSYM_CODE_START(ret_from_fork_asm)\n\t \n\tUNWIND_HINT_END_OF_STACK\n\tANNOTATE_NOENDBR  \n\tCALL_DEPTH_ACCOUNT\n\n\tmovq\t%rax, %rdi\t\t \n\tmovq\t%rsp, %rsi\t\t \n\tmovq\t%rbx, %rdx\t\t \n\tmovq\t%r12, %rcx\t\t \n\tcall\tret_from_fork\n\n\t \n\tUNWIND_HINT_REGS\n\tjmp\tswapgs_restore_regs_and_return_to_usermode\nSYM_CODE_END(ret_from_fork_asm)\n.popsection\n\n.macro DEBUG_ENTRY_ASSERT_IRQS_OFF\n#ifdef CONFIG_DEBUG_ENTRY\n\tpushq %rax\n\tSAVE_FLAGS\n\ttestl $X86_EFLAGS_IF, %eax\n\tjz .Lokay_\\@\n\tud2\n.Lokay_\\@:\n\tpopq %rax\n#endif\n.endm\n\nSYM_CODE_START(xen_error_entry)\n\tANNOTATE_NOENDBR\n\tUNWIND_HINT_FUNC\n\tPUSH_AND_CLEAR_REGS save_ret=1\n\tENCODE_FRAME_POINTER 8\n\tUNTRAIN_RET_FROM_CALL\n\tRET\nSYM_CODE_END(xen_error_entry)\n\n \n.macro idtentry_body cfunc has_error_code:req\n\n\t \n\tALTERNATIVE \"call error_entry; movq %rax, %rsp\", \\\n\t\t    \"call xen_error_entry\", X86_FEATURE_XENPV\n\n\tENCODE_FRAME_POINTER\n\tUNWIND_HINT_REGS\n\n\tmovq\t%rsp, %rdi\t\t\t \n\n\t.if \\has_error_code == 1\n\t\tmovq\tORIG_RAX(%rsp), %rsi\t \n\t\tmovq\t$-1, ORIG_RAX(%rsp)\t \n\t.endif\n\n\tcall\t\\cfunc\n\n\t \n\tREACHABLE\n\n\tjmp\terror_return\n.endm\n\n \n.macro idtentry vector asmsym cfunc has_error_code:req\nSYM_CODE_START(\\asmsym)\n\n\t.if \\vector == X86_TRAP_BP\n\t\t \n\t\tUNWIND_HINT_IRET_ENTRY offset=\\has_error_code*8 signal=0\n\t.else\n\t\tUNWIND_HINT_IRET_ENTRY offset=\\has_error_code*8\n\t.endif\n\n\tENDBR\n\tASM_CLAC\n\tcld\n\n\t.if \\has_error_code == 0\n\t\tpushq\t$-1\t\t\t \n\t.endif\n\n\t.if \\vector == X86_TRAP_BP\n\t\t \n\t\ttestb\t$3, CS-ORIG_RAX(%rsp)\n\t\tjnz\t.Lfrom_usermode_no_gap_\\@\n\t\t.rept\t6\n\t\tpushq\t5*8(%rsp)\n\t\t.endr\n\t\tUNWIND_HINT_IRET_REGS offset=8\n.Lfrom_usermode_no_gap_\\@:\n\t.endif\n\n\tidtentry_body \\cfunc \\has_error_code\n\n_ASM_NOKPROBE(\\asmsym)\nSYM_CODE_END(\\asmsym)\n.endm\n\n \n.macro idtentry_irq vector cfunc\n\t.p2align CONFIG_X86_L1_CACHE_SHIFT\n\tidtentry \\vector asm_\\cfunc \\cfunc has_error_code=1\n.endm\n\n \n.macro idtentry_sysvec vector cfunc\n\tidtentry \\vector asm_\\cfunc \\cfunc has_error_code=0\n.endm\n\n \n.macro idtentry_mce_db vector asmsym cfunc\nSYM_CODE_START(\\asmsym)\n\tUNWIND_HINT_IRET_ENTRY\n\tENDBR\n\tASM_CLAC\n\tcld\n\n\tpushq\t$-1\t\t\t \n\n\t \n\ttestb\t$3, CS-ORIG_RAX(%rsp)\n\tjnz\t.Lfrom_usermode_switch_stack_\\@\n\n\t \n\tcall\tparanoid_entry\n\n\tUNWIND_HINT_REGS\n\n\tmovq\t%rsp, %rdi\t\t \n\n\tcall\t\\cfunc\n\n\tjmp\tparanoid_exit\n\n\t \n.Lfrom_usermode_switch_stack_\\@:\n\tidtentry_body noist_\\cfunc, has_error_code=0\n\n_ASM_NOKPROBE(\\asmsym)\nSYM_CODE_END(\\asmsym)\n.endm\n\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n \n.macro idtentry_vc vector asmsym cfunc\nSYM_CODE_START(\\asmsym)\n\tUNWIND_HINT_IRET_ENTRY\n\tENDBR\n\tASM_CLAC\n\tcld\n\n\t \n\ttestb\t$3, CS-ORIG_RAX(%rsp)\n\tjnz\t.Lfrom_usermode_switch_stack_\\@\n\n\t \n\tcall\tparanoid_entry\n\n\tUNWIND_HINT_REGS\n\n\t \n\tmovq\t%rsp, %rdi\t\t \n\tcall\tvc_switch_off_ist\n\tmovq\t%rax, %rsp\t\t \n\n\tENCODE_FRAME_POINTER\n\tUNWIND_HINT_REGS\n\n\t \n\tmovq\tORIG_RAX(%rsp), %rsi\t \n\tmovq\t$-1, ORIG_RAX(%rsp)\t \n\n\tmovq\t%rsp, %rdi\t\t \n\n\tcall\tkernel_\\cfunc\n\n\t \n\tjmp\tparanoid_exit\n\n\t \n.Lfrom_usermode_switch_stack_\\@:\n\tidtentry_body user_\\cfunc, has_error_code=1\n\n_ASM_NOKPROBE(\\asmsym)\nSYM_CODE_END(\\asmsym)\n.endm\n#endif\n\n \n.macro idtentry_df vector asmsym cfunc\nSYM_CODE_START(\\asmsym)\n\tUNWIND_HINT_IRET_ENTRY offset=8\n\tENDBR\n\tASM_CLAC\n\tcld\n\n\t \n\tcall\tparanoid_entry\n\tUNWIND_HINT_REGS\n\n\tmovq\t%rsp, %rdi\t\t \n\tmovq\tORIG_RAX(%rsp), %rsi\t \n\tmovq\t$-1, ORIG_RAX(%rsp)\t \n\tcall\t\\cfunc\n\n\t \n\tREACHABLE\n\n\tjmp\tparanoid_exit\n\n_ASM_NOKPROBE(\\asmsym)\nSYM_CODE_END(\\asmsym)\n.endm\n\n \n\t__ALIGN\n\t.globl __irqentry_text_start\n__irqentry_text_start:\n\n#include <asm/idtentry.h>\n\n\t__ALIGN\n\t.globl __irqentry_text_end\n__irqentry_text_end:\n\tANNOTATE_NOENDBR\n\nSYM_CODE_START_LOCAL(common_interrupt_return)\nSYM_INNER_LABEL(swapgs_restore_regs_and_return_to_usermode, SYM_L_GLOBAL)\n\tIBRS_EXIT\n#ifdef CONFIG_DEBUG_ENTRY\n\t \n\ttestb\t$3, CS(%rsp)\n\tjnz\t1f\n\tud2\n1:\n#endif\n#ifdef CONFIG_XEN_PV\n\tALTERNATIVE \"\", \"jmp xenpv_restore_regs_and_return_to_usermode\", X86_FEATURE_XENPV\n#endif\n\n\tPOP_REGS pop_rdi=0\n\n\t \n\tmovq\t%rsp, %rdi\n\tmovq\tPER_CPU_VAR(cpu_tss_rw + TSS_sp0), %rsp\n\tUNWIND_HINT_END_OF_STACK\n\n\t \n\tpushq\t6*8(%rdi)\t \n\tpushq\t5*8(%rdi)\t \n\tpushq\t4*8(%rdi)\t \n\tpushq\t3*8(%rdi)\t \n\tpushq\t2*8(%rdi)\t \n\n\t \n\tpushq\t(%rdi)\n\n\t \n\tSTACKLEAK_ERASE_NOCLOBBER\n\n\tSWITCH_TO_USER_CR3_STACK scratch_reg=%rdi\n\n\t \n\tpopq\t%rdi\n\tswapgs\n\tjmp\t.Lnative_iret\n\n\nSYM_INNER_LABEL(restore_regs_and_return_to_kernel, SYM_L_GLOBAL)\n#ifdef CONFIG_DEBUG_ENTRY\n\t \n\ttestb\t$3, CS(%rsp)\n\tjz\t1f\n\tud2\n1:\n#endif\n\tPOP_REGS\n\taddq\t$8, %rsp\t \n\t \n#ifdef CONFIG_XEN_PV\nSYM_INNER_LABEL(early_xen_iret_patch, SYM_L_GLOBAL)\n\tANNOTATE_NOENDBR\n\t.byte 0xe9\n\t.long .Lnative_iret - (. + 4)\n#endif\n\n.Lnative_iret:\n\tUNWIND_HINT_IRET_REGS\n\t \n#ifdef CONFIG_X86_ESPFIX64\n\ttestb\t$4, (SS-RIP)(%rsp)\n\tjnz\tnative_irq_return_ldt\n#endif\n\nSYM_INNER_LABEL(native_irq_return_iret, SYM_L_GLOBAL)\n\tANNOTATE_NOENDBR  \n\t \n\tiretq\n\n#ifdef CONFIG_X86_ESPFIX64\nnative_irq_return_ldt:\n\t \n\n\tpushq\t%rdi\t\t\t\t \n\tswapgs\t\t\t\t\t \n\tSWITCH_TO_KERNEL_CR3 scratch_reg=%rdi\t \n\n\tmovq\tPER_CPU_VAR(espfix_waddr), %rdi\n\tmovq\t%rax, (0*8)(%rdi)\t\t \n\tmovq\t(1*8)(%rsp), %rax\t\t \n\tmovq\t%rax, (1*8)(%rdi)\n\tmovq\t(2*8)(%rsp), %rax\t\t \n\tmovq\t%rax, (2*8)(%rdi)\n\tmovq\t(3*8)(%rsp), %rax\t\t \n\tmovq\t%rax, (3*8)(%rdi)\n\tmovq\t(5*8)(%rsp), %rax\t\t \n\tmovq\t%rax, (5*8)(%rdi)\n\tmovq\t(4*8)(%rsp), %rax\t\t \n\tmovq\t%rax, (4*8)(%rdi)\n\t \n\n\tandl\t$0xffff0000, %eax\t\t \n\n\t \n\torq\tPER_CPU_VAR(espfix_stack), %rax\n\n\tSWITCH_TO_USER_CR3_STACK scratch_reg=%rdi\n\tswapgs\t\t\t\t\t \n\tpopq\t%rdi\t\t\t\t \n\n\tmovq\t%rax, %rsp\n\tUNWIND_HINT_IRET_REGS offset=8\n\n\t \n\tpopq\t%rax\t\t\t\t \n\n\t \n\tjmp\tnative_irq_return_iret\n#endif\nSYM_CODE_END(common_interrupt_return)\n_ASM_NOKPROBE(common_interrupt_return)\n\n \nSYM_FUNC_START(asm_load_gs_index)\n\tFRAME_BEGIN\n\tswapgs\n.Lgs_change:\n\tANNOTATE_NOENDBR  \n\tmovl\t%edi, %gs\n2:\tALTERNATIVE \"\", \"mfence\", X86_BUG_SWAPGS_FENCE\n\tswapgs\n\tFRAME_END\n\tRET\n\n\t \n.Lbad_gs:\n\tswapgs\t\t\t\t\t \n.macro ZAP_GS\n\t \n\tmovl $__USER_DS, %eax\n\tmovl %eax, %gs\n.endm\n\tALTERNATIVE \"\", \"ZAP_GS\", X86_BUG_NULL_SEG\n\txorl\t%eax, %eax\n\tmovl\t%eax, %gs\n\tjmp\t2b\n\n\t_ASM_EXTABLE(.Lgs_change, .Lbad_gs)\n\nSYM_FUNC_END(asm_load_gs_index)\nEXPORT_SYMBOL(asm_load_gs_index)\n\n#ifdef CONFIG_XEN_PV\n \n\t__FUNC_ALIGN\nSYM_CODE_START_LOCAL_NOALIGN(exc_xen_hypervisor_callback)\n\n \n\tUNWIND_HINT_FUNC\n\tmovq\t%rdi, %rsp\t\t\t \n\tUNWIND_HINT_REGS\n\n\tcall\txen_pv_evtchn_do_upcall\n\n\tjmp\terror_return\nSYM_CODE_END(exc_xen_hypervisor_callback)\n\n \n\t__FUNC_ALIGN\nSYM_CODE_START_NOALIGN(xen_failsafe_callback)\n\tUNWIND_HINT_UNDEFINED\n\tENDBR\n\tmovl\t%ds, %ecx\n\tcmpw\t%cx, 0x10(%rsp)\n\tjne\t1f\n\tmovl\t%es, %ecx\n\tcmpw\t%cx, 0x18(%rsp)\n\tjne\t1f\n\tmovl\t%fs, %ecx\n\tcmpw\t%cx, 0x20(%rsp)\n\tjne\t1f\n\tmovl\t%gs, %ecx\n\tcmpw\t%cx, 0x28(%rsp)\n\tjne\t1f\n\t \n\tmovq\t(%rsp), %rcx\n\tmovq\t8(%rsp), %r11\n\taddq\t$0x30, %rsp\n\tpushq\t$0\t\t\t\t \n\tUNWIND_HINT_IRET_REGS offset=8\n\tjmp\tasm_exc_general_protection\n1:\t \n\tmovq\t(%rsp), %rcx\n\tmovq\t8(%rsp), %r11\n\taddq\t$0x30, %rsp\n\tUNWIND_HINT_IRET_REGS\n\tpushq\t$-1  \n\tPUSH_AND_CLEAR_REGS\n\tENCODE_FRAME_POINTER\n\tjmp\terror_return\nSYM_CODE_END(xen_failsafe_callback)\n#endif  \n\n \nSYM_CODE_START(paranoid_entry)\n\tANNOTATE_NOENDBR\n\tUNWIND_HINT_FUNC\n\tPUSH_AND_CLEAR_REGS save_ret=1\n\tENCODE_FRAME_POINTER 8\n\n\t \n\tSAVE_AND_SWITCH_TO_KERNEL_CR3 scratch_reg=%rax save_reg=%r14\n\n\t \n\tALTERNATIVE \"jmp .Lparanoid_entry_checkgs\", \"\", X86_FEATURE_FSGSBASE\n\n\t \n\tSAVE_AND_SET_GSBASE scratch_reg=%rax save_reg=%rbx\n\tjmp .Lparanoid_gsbase_done\n\n.Lparanoid_entry_checkgs:\n\t \n\tmovl\t$1, %ebx\n\n\t \n\tmovl\t$MSR_GS_BASE, %ecx\n\trdmsr\n\ttestl\t%edx, %edx\n\tjs\t.Lparanoid_kernel_gsbase\n\n\t \n\txorl\t%ebx, %ebx\n\tswapgs\n.Lparanoid_kernel_gsbase:\n\tFENCE_SWAPGS_KERNEL_ENTRY\n.Lparanoid_gsbase_done:\n\n\t \n\tIBRS_ENTER save_reg=%r15\n\tUNTRAIN_RET_FROM_CALL\n\n\tRET\nSYM_CODE_END(paranoid_entry)\n\n \nSYM_CODE_START_LOCAL(paranoid_exit)\n\tUNWIND_HINT_REGS\n\n\t \n\tIBRS_EXIT save_reg=%r15\n\n\t \n\tRESTORE_CR3\tscratch_reg=%rax save_reg=%r14\n\n\t \n\tALTERNATIVE \"jmp .Lparanoid_exit_checkgs\", \"\", X86_FEATURE_FSGSBASE\n\n\t \n\twrgsbase\t%rbx\n\tjmp\t\trestore_regs_and_return_to_kernel\n\n.Lparanoid_exit_checkgs:\n\t \n\ttestl\t\t%ebx, %ebx\n\tjnz\t\trestore_regs_and_return_to_kernel\n\n\t \n\tswapgs\n\tjmp\t\trestore_regs_and_return_to_kernel\nSYM_CODE_END(paranoid_exit)\n\n \nSYM_CODE_START(error_entry)\n\tANNOTATE_NOENDBR\n\tUNWIND_HINT_FUNC\n\n\tPUSH_AND_CLEAR_REGS save_ret=1\n\tENCODE_FRAME_POINTER 8\n\n\ttestb\t$3, CS+8(%rsp)\n\tjz\t.Lerror_kernelspace\n\n\t \n\tswapgs\n\tFENCE_SWAPGS_USER_ENTRY\n\t \n\tSWITCH_TO_KERNEL_CR3 scratch_reg=%rax\n\tIBRS_ENTER\n\tUNTRAIN_RET_FROM_CALL\n\n\tleaq\t8(%rsp), %rdi\t\t\t \n\t \n\tjmp\tsync_regs\n\n\t \n.Lerror_kernelspace:\n\tleaq\tnative_irq_return_iret(%rip), %rcx\n\tcmpq\t%rcx, RIP+8(%rsp)\n\tje\t.Lerror_bad_iret\n\tmovl\t%ecx, %eax\t\t\t \n\tcmpq\t%rax, RIP+8(%rsp)\n\tje\t.Lbstep_iret\n\tcmpq\t$.Lgs_change, RIP+8(%rsp)\n\tjne\t.Lerror_entry_done_lfence\n\n\t \n\tswapgs\n\n\t \n.Lerror_entry_done_lfence:\n\tFENCE_SWAPGS_KERNEL_ENTRY\n\tCALL_DEPTH_ACCOUNT\n\tleaq\t8(%rsp), %rax\t\t\t \n\tVALIDATE_UNRET_END\n\tRET\n\n.Lbstep_iret:\n\t \n\tmovq\t%rcx, RIP+8(%rsp)\n\t \n\n.Lerror_bad_iret:\n\t \n\tswapgs\n\tFENCE_SWAPGS_USER_ENTRY\n\tSWITCH_TO_KERNEL_CR3 scratch_reg=%rax\n\tIBRS_ENTER\n\tUNTRAIN_RET_FROM_CALL\n\n\t \n\tleaq\t8(%rsp), %rdi\t\t\t \n\tcall\tfixup_bad_iret\n\tmov\t%rax, %rdi\n\tjmp\tsync_regs\nSYM_CODE_END(error_entry)\n\nSYM_CODE_START_LOCAL(error_return)\n\tUNWIND_HINT_REGS\n\tDEBUG_ENTRY_ASSERT_IRQS_OFF\n\ttestb\t$3, CS(%rsp)\n\tjz\trestore_regs_and_return_to_kernel\n\tjmp\tswapgs_restore_regs_and_return_to_usermode\nSYM_CODE_END(error_return)\n\n \nSYM_CODE_START(asm_exc_nmi)\n\tUNWIND_HINT_IRET_ENTRY\n\tENDBR\n\n\t \n\n\tASM_CLAC\n\tcld\n\n\t \n\tpushq\t%rdx\n\n\ttestb\t$3, CS-RIP+8(%rsp)\n\tjz\t.Lnmi_from_kernel\n\n\t \n\n\tswapgs\n\tFENCE_SWAPGS_USER_ENTRY\n\tSWITCH_TO_KERNEL_CR3 scratch_reg=%rdx\n\tmovq\t%rsp, %rdx\n\tmovq\tPER_CPU_VAR(pcpu_hot + X86_top_of_stack), %rsp\n\tUNWIND_HINT_IRET_REGS base=%rdx offset=8\n\tpushq\t5*8(%rdx)\t \n\tpushq\t4*8(%rdx)\t \n\tpushq\t3*8(%rdx)\t \n\tpushq\t2*8(%rdx)\t \n\tpushq\t1*8(%rdx)\t \n\tUNWIND_HINT_IRET_REGS\n\tpushq   $-1\t\t \n\tPUSH_AND_CLEAR_REGS rdx=(%rdx)\n\tENCODE_FRAME_POINTER\n\n\tIBRS_ENTER\n\tUNTRAIN_RET\n\n\t \n\n\tmovq\t%rsp, %rdi\n\tmovq\t$-1, %rsi\n\tcall\texc_nmi\n\n\t \n\tjmp\tswapgs_restore_regs_and_return_to_usermode\n\n.Lnmi_from_kernel:\n\t \n\n\t \n\n\tmovq\t$repeat_nmi, %rdx\n\tcmpq\t8(%rsp), %rdx\n\tja\t1f\n\tmovq\t$end_repeat_nmi, %rdx\n\tcmpq\t8(%rsp), %rdx\n\tja\tnested_nmi_out\n1:\n\n\t \n\tcmpl\t$1, -8(%rsp)\n\tje\tnested_nmi\n\n\t \n\tlea\t6*8(%rsp), %rdx\n\t \n\tcmpq\t%rdx, 4*8(%rsp)\n\t \n\tja\tfirst_nmi\n\n\tsubq\t$EXCEPTION_STKSZ, %rdx\n\tcmpq\t%rdx, 4*8(%rsp)\n\t \n\tjb\tfirst_nmi\n\n\t \n\n\ttestb\t$(X86_EFLAGS_DF >> 8), (3*8 + 1)(%rsp)\n\tjz\tfirst_nmi\t \n\n\t \n\nnested_nmi:\n\t \n\tsubq\t$8, %rsp\n\tleaq\t-10*8(%rsp), %rdx\n\tpushq\t$__KERNEL_DS\n\tpushq\t%rdx\n\tpushfq\n\tpushq\t$__KERNEL_CS\n\tpushq\t$repeat_nmi\n\n\t \n\taddq\t$(6*8), %rsp\n\nnested_nmi_out:\n\tpopq\t%rdx\n\n\t \n\tiretq\n\nfirst_nmi:\n\t \n\tmovq\t(%rsp), %rdx\n\n\t \n\tpushq\t$0\n\n\t \n\tsubq\t$(5*8), %rsp\n\n\t \n\t.rept 5\n\tpushq\t11*8(%rsp)\n\t.endr\n\tUNWIND_HINT_IRET_REGS\n\n\t \n\n#ifdef CONFIG_DEBUG_ENTRY\n\t \n\tpushq\t$0\t\t \n\tpushq\t%rsp\t\t \n\taddq\t$8, (%rsp)\t \n\tpushfq\t\t\t \n\tpushq\t$__KERNEL_CS\t \n\tpushq\t$1f\t\t \n\tiretq\t\t\t \n\tUNWIND_HINT_IRET_REGS\n1:\n#endif\n\nrepeat_nmi:\n\tANNOTATE_NOENDBR  \n\t \n\tmovq\t$1, 10*8(%rsp)\t\t \n\n\t \n\taddq\t$(10*8), %rsp\n\t.rept 5\n\tpushq\t-6*8(%rsp)\n\t.endr\n\tsubq\t$(5*8), %rsp\nend_repeat_nmi:\n\tANNOTATE_NOENDBR  \n\n\t \n\tpushq\t$-1\t\t\t\t \n\n\t \n\tcall\tparanoid_entry\n\tUNWIND_HINT_REGS\n\n\tmovq\t%rsp, %rdi\n\tmovq\t$-1, %rsi\n\tcall\texc_nmi\n\n\t \n\tIBRS_EXIT save_reg=%r15\n\n\t \n\tRESTORE_CR3 scratch_reg=%r15 save_reg=%r14\n\n\t \n\tALTERNATIVE \"jmp nmi_no_fsgsbase\", \"\", X86_FEATURE_FSGSBASE\n\n\twrgsbase\t%rbx\n\tjmp\tnmi_restore\n\nnmi_no_fsgsbase:\n\t \n\ttestl\t%ebx, %ebx\n\tjnz\tnmi_restore\n\nnmi_swapgs:\n\tswapgs\n\nnmi_restore:\n\tPOP_REGS\n\n\t \n\taddq\t$6*8, %rsp\n\n\t \n\tstd\n\tmovq\t$0, 5*8(%rsp)\t\t \n\n\t \n\tiretq\nSYM_CODE_END(asm_exc_nmi)\n\n#ifndef CONFIG_IA32_EMULATION\n \nSYM_CODE_START(ignore_sysret)\n\tUNWIND_HINT_END_OF_STACK\n\tENDBR\n\tmov\t$-ENOSYS, %eax\n\tsysretl\nSYM_CODE_END(ignore_sysret)\n#endif\n\n.pushsection .text, \"ax\"\n\t__FUNC_ALIGN\nSYM_CODE_START_NOALIGN(rewind_stack_and_make_dead)\n\tUNWIND_HINT_FUNC\n\t \n\txorl\t%ebp, %ebp\n\n\tmovq\tPER_CPU_VAR(pcpu_hot + X86_top_of_stack), %rax\n\tleaq\t-PTREGS_SIZE(%rax), %rsp\n\tUNWIND_HINT_REGS\n\n\tcall\tmake_task_dead\nSYM_CODE_END(rewind_stack_and_make_dead)\n.popsection\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}