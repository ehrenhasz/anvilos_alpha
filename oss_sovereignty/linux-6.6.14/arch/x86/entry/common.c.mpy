{
  "module_name": "common.c",
  "hash_id": "877dff250d5339a68b362ddab8600faf9f8f11d9a7863e7381f434adc9d389f1",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/entry/common.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/sched.h>\n#include <linux/sched/task_stack.h>\n#include <linux/entry-common.h>\n#include <linux/mm.h>\n#include <linux/smp.h>\n#include <linux/errno.h>\n#include <linux/ptrace.h>\n#include <linux/export.h>\n#include <linux/nospec.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n\n#ifdef CONFIG_XEN_PV\n#include <xen/xen-ops.h>\n#include <xen/events.h>\n#endif\n\n#include <asm/apic.h>\n#include <asm/desc.h>\n#include <asm/traps.h>\n#include <asm/vdso.h>\n#include <asm/cpufeature.h>\n#include <asm/fpu/api.h>\n#include <asm/nospec-branch.h>\n#include <asm/io_bitmap.h>\n#include <asm/syscall.h>\n#include <asm/irq_stack.h>\n\n#ifdef CONFIG_X86_64\n\nstatic __always_inline bool do_syscall_x64(struct pt_regs *regs, int nr)\n{\n\t \n\tunsigned int unr = nr;\n\n\tif (likely(unr < NR_syscalls)) {\n\t\tunr = array_index_nospec(unr, NR_syscalls);\n\t\tregs->ax = sys_call_table[unr](regs);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic __always_inline bool do_syscall_x32(struct pt_regs *regs, int nr)\n{\n\t \n\tunsigned int xnr = nr - __X32_SYSCALL_BIT;\n\n\tif (IS_ENABLED(CONFIG_X86_X32_ABI) && likely(xnr < X32_NR_syscalls)) {\n\t\txnr = array_index_nospec(xnr, X32_NR_syscalls);\n\t\tregs->ax = x32_sys_call_table[xnr](regs);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n__visible noinstr void do_syscall_64(struct pt_regs *regs, int nr)\n{\n\tadd_random_kstack_offset();\n\tnr = syscall_enter_from_user_mode(regs, nr);\n\n\tinstrumentation_begin();\n\n\tif (!do_syscall_x64(regs, nr) && !do_syscall_x32(regs, nr) && nr != -1) {\n\t\t \n\t\tregs->ax = __x64_sys_ni_syscall(regs);\n\t}\n\n\tinstrumentation_end();\n\tsyscall_exit_to_user_mode(regs);\n}\n#endif\n\n#if defined(CONFIG_X86_32) || defined(CONFIG_IA32_EMULATION)\nstatic __always_inline int syscall_32_enter(struct pt_regs *regs)\n{\n\tif (IS_ENABLED(CONFIG_IA32_EMULATION))\n\t\tcurrent_thread_info()->status |= TS_COMPAT;\n\n\treturn (int)regs->orig_ax;\n}\n\n#ifdef CONFIG_IA32_EMULATION\nbool __ia32_enabled __ro_after_init = true;\n#endif\n\n \nstatic __always_inline void do_syscall_32_irqs_on(struct pt_regs *regs, int nr)\n{\n\t \n\tunsigned int unr = nr;\n\n\tif (likely(unr < IA32_NR_syscalls)) {\n\t\tunr = array_index_nospec(unr, IA32_NR_syscalls);\n\t\tregs->ax = ia32_sys_call_table[unr](regs);\n\t} else if (nr != -1) {\n\t\tregs->ax = __ia32_sys_ni_syscall(regs);\n\t}\n}\n\n#ifdef CONFIG_IA32_EMULATION\nstatic __always_inline bool int80_is_external(void)\n{\n\tconst unsigned int offs = (0x80 / 32) * 0x10;\n\tconst u32 bit = BIT(0x80 % 32);\n\n\t \n\tif (cpu_feature_enabled(X86_FEATURE_XENPV))\n\t\treturn false;\n\n\t \n\treturn apic_read(APIC_ISR + offs) & bit;\n}\n\n \nDEFINE_IDTENTRY_RAW(int80_emulation)\n{\n\tint nr;\n\n\t \n\tif (unlikely(!user_mode(regs))) {\n\t\tirqentry_enter(regs);\n\t\tinstrumentation_begin();\n\t\tpanic(\"Unexpected external interrupt 0x80\\n\");\n\t}\n\n\t \n\tenter_from_user_mode(regs);\n\n\tinstrumentation_begin();\n\tadd_random_kstack_offset();\n\n\t \n\tif (unlikely(int80_is_external()))\n\t\tpanic(\"Unexpected external interrupt 0x80\\n\");\n\n\t \n\tregs->orig_ax = regs->ax & GENMASK(31, 0);\n\tregs->ax = -ENOSYS;\n\n\tnr = syscall_32_enter(regs);\n\n\tlocal_irq_enable();\n\tnr = syscall_enter_from_user_mode_work(regs, nr);\n\tdo_syscall_32_irqs_on(regs, nr);\n\n\tinstrumentation_end();\n\tsyscall_exit_to_user_mode(regs);\n}\n#else  \n\n \n__visible noinstr void do_int80_syscall_32(struct pt_regs *regs)\n{\n\tint nr = syscall_32_enter(regs);\n\n\tadd_random_kstack_offset();\n\t \n\tnr = syscall_enter_from_user_mode(regs, nr);\n\tinstrumentation_begin();\n\n\tdo_syscall_32_irqs_on(regs, nr);\n\n\tinstrumentation_end();\n\tsyscall_exit_to_user_mode(regs);\n}\n#endif  \n\nstatic noinstr bool __do_fast_syscall_32(struct pt_regs *regs)\n{\n\tint nr = syscall_32_enter(regs);\n\tint res;\n\n\tadd_random_kstack_offset();\n\t \n\tsyscall_enter_from_user_mode_prepare(regs);\n\n\tinstrumentation_begin();\n\t \n\tif (IS_ENABLED(CONFIG_X86_64)) {\n\t\t \n\t\tres = __get_user(*(u32 *)&regs->bp,\n\t\t\t (u32 __user __force *)(unsigned long)(u32)regs->sp);\n\t} else {\n\t\tres = get_user(*(u32 *)&regs->bp,\n\t\t       (u32 __user __force *)(unsigned long)(u32)regs->sp);\n\t}\n\n\tif (res) {\n\t\t \n\t\tregs->ax = -EFAULT;\n\n\t\tlocal_irq_disable();\n\t\tinstrumentation_end();\n\t\tirqentry_exit_to_user_mode(regs);\n\t\treturn false;\n\t}\n\n\tnr = syscall_enter_from_user_mode_work(regs, nr);\n\n\t \n\tdo_syscall_32_irqs_on(regs, nr);\n\n\tinstrumentation_end();\n\tsyscall_exit_to_user_mode(regs);\n\treturn true;\n}\n\n \n__visible noinstr long do_fast_syscall_32(struct pt_regs *regs)\n{\n\t \n\tunsigned long landing_pad = (unsigned long)current->mm->context.vdso +\n\t\t\t\t\tvdso_image_32.sym_int80_landing_pad;\n\n\t \n\tregs->ip = landing_pad;\n\n\t \n\tif (!__do_fast_syscall_32(regs))\n\t\treturn 0;\n\n#ifdef CONFIG_X86_64\n\t \n\treturn regs->cs == __USER32_CS && regs->ss == __USER_DS &&\n\t\tregs->ip == landing_pad &&\n\t\t(regs->flags & (X86_EFLAGS_RF | X86_EFLAGS_TF)) == 0;\n#else\n\t \n\treturn static_cpu_has(X86_FEATURE_SEP) &&\n\t\tregs->cs == __USER_CS && regs->ss == __USER_DS &&\n\t\tregs->ip == landing_pad &&\n\t\t(regs->flags & (X86_EFLAGS_RF | X86_EFLAGS_TF | X86_EFLAGS_VM)) == 0;\n#endif\n}\n\n \n__visible noinstr long do_SYSENTER_32(struct pt_regs *regs)\n{\n\t \n\tregs->sp = regs->bp;\n\n\t \n\tregs->flags |= X86_EFLAGS_IF;\n\n\treturn do_fast_syscall_32(regs);\n}\n#endif\n\nSYSCALL_DEFINE0(ni_syscall)\n{\n\treturn -ENOSYS;\n}\n\n#ifdef CONFIG_XEN_PV\n#ifndef CONFIG_PREEMPTION\n \nDEFINE_PER_CPU(bool, xen_in_preemptible_hcall);\nEXPORT_SYMBOL_GPL(xen_in_preemptible_hcall);\n\n \nstatic __always_inline bool get_and_clear_inhcall(void)\n{\n\tbool inhcall = __this_cpu_read(xen_in_preemptible_hcall);\n\n\t__this_cpu_write(xen_in_preemptible_hcall, false);\n\treturn inhcall;\n}\n\nstatic __always_inline void restore_inhcall(bool inhcall)\n{\n\t__this_cpu_write(xen_in_preemptible_hcall, inhcall);\n}\n#else\nstatic __always_inline bool get_and_clear_inhcall(void) { return false; }\nstatic __always_inline void restore_inhcall(bool inhcall) { }\n#endif\n\nstatic void __xen_pv_evtchn_do_upcall(struct pt_regs *regs)\n{\n\tstruct pt_regs *old_regs = set_irq_regs(regs);\n\n\tinc_irq_stat(irq_hv_callback_count);\n\n\txen_evtchn_do_upcall();\n\n\tset_irq_regs(old_regs);\n}\n\n__visible noinstr void xen_pv_evtchn_do_upcall(struct pt_regs *regs)\n{\n\tirqentry_state_t state = irqentry_enter(regs);\n\tbool inhcall;\n\n\tinstrumentation_begin();\n\trun_sysvec_on_irqstack_cond(__xen_pv_evtchn_do_upcall, regs);\n\n\tinhcall = get_and_clear_inhcall();\n\tif (inhcall && !WARN_ON_ONCE(state.exit_rcu)) {\n\t\tirqentry_exit_cond_resched();\n\t\tinstrumentation_end();\n\t\trestore_inhcall(inhcall);\n\t} else {\n\t\tinstrumentation_end();\n\t\tirqentry_exit(regs, state);\n\t}\n}\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}