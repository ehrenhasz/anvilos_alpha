{
  "module_name": "sha1_avx2_x86_64_asm.S",
  "hash_id": "3c1558f248bf97e2630645ca545762d1783613c4b168f1d3ecdb39fb362b201d",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/crypto/sha1_avx2_x86_64_asm.S",
  "human_readable_source": " \n\n \n\n#include <linux/linkage.h>\n\n#define\tCTX\t%rdi\t \n#define BUF\t%rsi\t \n#define CNT\t%rdx\t \n\n#define\tREG_A\t%ecx\n#define\tREG_B\t%esi\n#define\tREG_C\t%edi\n#define\tREG_D\t%eax\n#define\tREG_E\t%edx\n#define\tREG_TB\t%ebx\n#define\tREG_TA\t%r12d\n#define\tREG_RA\t%rcx\n#define\tREG_RB\t%rsi\n#define\tREG_RC\t%rdi\n#define\tREG_RD\t%rax\n#define\tREG_RE\t%rdx\n#define\tREG_RTA\t%r12\n#define\tREG_RTB\t%rbx\n#define\tREG_T1\t%r11d\n#define\txmm_mov\tvmovups\n#define\tavx2_zeroupper\tvzeroupper\n#define\tRND_F1\t1\n#define\tRND_F2\t2\n#define\tRND_F3\t3\n\n.macro REGALLOC\n\t.set A, REG_A\n\t.set B, REG_B\n\t.set C, REG_C\n\t.set D, REG_D\n\t.set E, REG_E\n\t.set TB, REG_TB\n\t.set TA, REG_TA\n\n\t.set RA, REG_RA\n\t.set RB, REG_RB\n\t.set RC, REG_RC\n\t.set RD, REG_RD\n\t.set RE, REG_RE\n\n\t.set RTA, REG_RTA\n\t.set RTB, REG_RTB\n\n\t.set T1, REG_T1\n.endm\n\n#define HASH_PTR\t%r9\n#define BLOCKS_CTR\t%r8\n#define BUFFER_PTR\t%r10\n#define BUFFER_PTR2\t%r13\n\n#define PRECALC_BUF\t%r14\n#define WK_BUF\t\t%r15\n\n#define W_TMP\t\t%xmm0\n#define WY_TMP\t\t%ymm0\n#define WY_TMP2\t\t%ymm9\n\n# AVX2 variables\n#define WY0\t\t%ymm3\n#define WY4\t\t%ymm5\n#define WY08\t\t%ymm7\n#define WY12\t\t%ymm8\n#define WY16\t\t%ymm12\n#define WY20\t\t%ymm13\n#define WY24\t\t%ymm14\n#define WY28\t\t%ymm15\n\n#define YMM_SHUFB_BSWAP\t%ymm10\n\n \n#define W_SIZE\t\t(80*2*2 +16)\n\n#define WK(t)\t((((t) % 80) / 4)*32 + ( (t) % 4)*4 + ((t)/80)*16 )(WK_BUF)\n#define PRECALC_WK(t)\t((t)*2*2)(PRECALC_BUF)\n\n\n.macro UPDATE_HASH  hash, val\n\tadd\t\\hash, \\val\n\tmov\t\\val, \\hash\n.endm\n\n.macro PRECALC_RESET_WY\n\t.set WY_00, WY0\n\t.set WY_04, WY4\n\t.set WY_08, WY08\n\t.set WY_12, WY12\n\t.set WY_16, WY16\n\t.set WY_20, WY20\n\t.set WY_24, WY24\n\t.set WY_28, WY28\n\t.set WY_32, WY_00\n.endm\n\n.macro PRECALC_ROTATE_WY\n\t \n\t.set WY_32, WY_28\n\t.set WY_28, WY_24\n\t.set WY_24, WY_20\n\t.set WY_20, WY_16\n\t.set WY_16, WY_12\n\t.set WY_12, WY_08\n\t.set WY_08, WY_04\n\t.set WY_04, WY_00\n\t.set WY_00, WY_32\n\n\t \n\t.set WY, WY_00\n\t.set WY_minus_04, WY_04\n\t.set WY_minus_08, WY_08\n\t.set WY_minus_12, WY_12\n\t.set WY_minus_16, WY_16\n\t.set WY_minus_20, WY_20\n\t.set WY_minus_24, WY_24\n\t.set WY_minus_28, WY_28\n\t.set WY_minus_32, WY\n.endm\n\n.macro PRECALC_00_15\n\t.if (i == 0) # Initialize and rotate registers\n\t\tPRECALC_RESET_WY\n\t\tPRECALC_ROTATE_WY\n\t.endif\n\n\t \n\t.if   ((i & 7) == 0)\n\t\t \n\t\tvmovdqu (i * 2)(BUFFER_PTR), W_TMP\n\t.elseif ((i & 7) == 1)\n\t\tvinsertf128 $1, ((i-1) * 2)(BUFFER_PTR2),\\\n\t\t\t WY_TMP, WY_TMP\n\t.elseif ((i & 7) == 2)\n\t\tvpshufb YMM_SHUFB_BSWAP, WY_TMP, WY\n\t.elseif ((i & 7) == 4)\n\t\tvpaddd  K_XMM + K_XMM_AR(%rip), WY, WY_TMP\n\t.elseif ((i & 7) == 7)\n\t\tvmovdqu  WY_TMP, PRECALC_WK(i&~7)\n\n\t\tPRECALC_ROTATE_WY\n\t.endif\n.endm\n\n.macro PRECALC_16_31\n\t \n\t.if   ((i & 7) == 0)\n\t\t \n\t\t \n\t\tvpalignr\t$8, WY_minus_16, WY_minus_12, WY\n\t\tvpsrldq\t$4, WY_minus_04, WY_TMP                \n\t.elseif ((i & 7) == 1)\n\t\tvpxor\tWY_minus_08, WY, WY\n\t\tvpxor\tWY_minus_16, WY_TMP, WY_TMP\n\t.elseif ((i & 7) == 2)\n\t\tvpxor\tWY_TMP, WY, WY\n\t\tvpslldq\t$12, WY, WY_TMP2\n\t.elseif ((i & 7) == 3)\n\t\tvpslld\t$1, WY, WY_TMP\n\t\tvpsrld\t$31, WY, WY\n\t.elseif ((i & 7) == 4)\n\t\tvpor\tWY, WY_TMP, WY_TMP\n\t\tvpslld\t$2, WY_TMP2, WY\n\t.elseif ((i & 7) == 5)\n\t\tvpsrld\t$30, WY_TMP2, WY_TMP2\n\t\tvpxor\tWY, WY_TMP, WY_TMP\n\t.elseif ((i & 7) == 7)\n\t\tvpxor\tWY_TMP2, WY_TMP, WY\n\t\tvpaddd  K_XMM + K_XMM_AR(%rip), WY, WY_TMP\n\t\tvmovdqu\tWY_TMP, PRECALC_WK(i&~7)\n\n\t\tPRECALC_ROTATE_WY\n\t.endif\n.endm\n\n.macro PRECALC_32_79\n\t \n\n\t.if   ((i & 7) == 0)\n\t \n\t\tvpalignr\t$8, WY_minus_08, WY_minus_04, WY_TMP\n\t.elseif ((i & 7) == 1)\n\t\t \n\t\tvpxor\tWY_minus_28, WY, WY\n\t.elseif ((i & 7) == 2)\n\t\tvpxor\tWY_minus_16, WY_TMP, WY_TMP\n\t.elseif ((i & 7) == 3)\n\t\tvpxor\tWY_TMP, WY, WY\n\t.elseif ((i & 7) == 4)\n\t\tvpslld\t$2, WY, WY_TMP\n\t.elseif ((i & 7) == 5)\n\t\tvpsrld\t$30, WY, WY\n\t\tvpor\tWY, WY_TMP, WY\n\t.elseif ((i & 7) == 7)\n\t\tvpaddd  K_XMM + K_XMM_AR(%rip), WY, WY_TMP\n\t\tvmovdqu\tWY_TMP, PRECALC_WK(i&~7)\n\n\t\tPRECALC_ROTATE_WY\n\t.endif\n.endm\n\n.macro PRECALC r, s\n\t.set i, \\r\n\n\t.if (i < 40)\n\t\t.set K_XMM, 32*0\n\t.elseif (i < 80)\n\t\t.set K_XMM, 32*1\n\t.elseif (i < 120)\n\t\t.set K_XMM, 32*2\n\t.else\n\t\t.set K_XMM, 32*3\n\t.endif\n\n\t.if (i<32)\n\t\tPRECALC_00_15\t\\s\n\t.elseif (i<64)\n\t\tPRECALC_16_31\t\\s\n\t.elseif (i < 160)\n\t\tPRECALC_32_79\t\\s\n\t.endif\n.endm\n\n.macro ROTATE_STATE\n\t.set T_REG, E\n\t.set E, D\n\t.set D, C\n\t.set C, B\n\t.set B, TB\n\t.set TB, A\n\t.set A, T_REG\n\n\t.set T_REG, RE\n\t.set RE, RD\n\t.set RD, RC\n\t.set RC, RB\n\t.set RB, RTB\n\t.set RTB, RA\n\t.set RA, T_REG\n.endm\n\n \n\n.macro RND_FUN f, r\n\t.if (\\f == RND_F1)\n\t\tROUND_F1\t\\r\n\t.elseif (\\f == RND_F2)\n\t\tROUND_F2\t\\r\n\t.elseif (\\f == RND_F3)\n\t\tROUND_F3\t\\r\n\t.endif\n.endm\n\n.macro RR r\n\t.set round_id, (\\r % 80)\n\n\t.if (round_id == 0)         \n\t\t.set ROUND_FUNC, RND_F1\n\t\tmov\tB, TB\n\n\t\trorx\t$(32-30), B, B     \n\t\tandn\tD, TB, T1\n\t\tand\tC, TB\n\t\txor\tT1, TB\n\t.endif\n\n\tRND_FUN ROUND_FUNC, \\r\n\tROTATE_STATE\n\n\t.if   (round_id == 18)\n\t\t.set ROUND_FUNC, RND_F2\n\t.elseif (round_id == 38)\n\t\t.set ROUND_FUNC, RND_F3\n\t.elseif (round_id == 58)\n\t\t.set ROUND_FUNC, RND_F2\n\t.endif\n\n\t.set round_id, ( (\\r+1) % 80)\n\n\tRND_FUN ROUND_FUNC, (\\r+1)\n\tROTATE_STATE\n.endm\n\n.macro ROUND_F1 r\n\tadd\tWK(\\r), E\n\n\tandn\tC, A, T1\t\t\t \n\tlea\t(RE,RTB), E\t\t \n\n\trorx\t$(32-5), A, TA\t\t \n\trorx\t$(32-30),A, TB\t\t \n\n\tPRECALC\t(\\r)\t\t\t \n\n\t \n\tand\tB, A\t\t\t \n\txor\tT1, A\t\t\t \n\n\tlea\t(RE,RTA), E\t\t \n.endm\n\n.macro ROUND_F2 r\n\tadd\tWK(\\r), E\n\tlea\t(RE,RTB), E\t\t \n\n\t \n\trorx\t$(32-5), A, TA\t\t \n\t.if ((round_id) < 79)\n\t\trorx\t$(32-30), A, TB\t \n\t.endif\n\tPRECALC\t(\\r)\t\t\t \n\n\t.if ((round_id) < 79)\n\t\txor\tB, A\n\t.endif\n\n\tadd\tTA, E\t\t\t \n\n\t.if ((round_id) < 79)\n\t\txor\tC, A\n\t.endif\n.endm\n\n.macro ROUND_F3 r\n\tadd\tWK(\\r), E\n\tPRECALC\t(\\r)\t\t\t \n\n\tlea\t(RE,RTB), E\t\t \n\n\tmov\tB, T1\n\tor\tA, T1\n\n\trorx\t$(32-5), A, TA\t\t \n\trorx\t$(32-30), A, TB\t\t \n\n\t \n\tand\tC, T1\n\tand\tB, A\n\tor\tT1, A\n\n\tadd\tTA, E\t\t\t \n\n.endm\n\n \n.macro ADD_IF_GE a, b, c, d\n\tmov     \\a, RTA\n\tadd     $\\d, RTA\n\tcmp     $\\c, \\b\n\tcmovge  RTA, \\a\n.endm\n\n \n.macro SHA1_PIPELINED_MAIN_BODY\n\n\tREGALLOC\n\n\tmov\t(HASH_PTR), A\n\tmov\t4(HASH_PTR), B\n\tmov\t8(HASH_PTR), C\n\tmov\t12(HASH_PTR), D\n\tmov\t16(HASH_PTR), E\n\n\tmov\t%rsp, PRECALC_BUF\n\tlea\t(2*4*80+32)(%rsp), WK_BUF\n\n\t# Precalc WK for first 2 blocks\n\tADD_IF_GE BUFFER_PTR2, BLOCKS_CTR, 2, 64\n\t.set i, 0\n\t.rept    160\n\t\tPRECALC i\n\t\t.set i, i + 1\n\t.endr\n\n\t \n\tADD_IF_GE BUFFER_PTR, BLOCKS_CTR, 3, 128\n\tADD_IF_GE BUFFER_PTR2, BLOCKS_CTR, 4, 128\n\txchg\tWK_BUF, PRECALC_BUF\n\n\t.align 32\n.L_loop:\n\t \n\ttest BLOCKS_CTR, BLOCKS_CTR\n\tjnz .L_begin\n\t.align 32\n\tjmp\t.L_end\n\t.align 32\n.L_begin:\n\n\t \n\t.set j, 0\n\t.rept 5\n\t\tRR\tj\n\t\t.set j, j+2\n\t.endr\n\n\t \n\t.rept 25\n\t\tRR\tj\n\t\t.set j, j+2\n\t.endr\n\n\t \n\tsub $1, BLOCKS_CTR\n\t \n\tADD_IF_GE BUFFER_PTR, BLOCKS_CTR, 4, 128\n\t \n\t.rept 10\n\t\tRR\tj\n\t\t.set j, j+2\n\t.endr\n\n\tUPDATE_HASH\t(HASH_PTR), A\n\tUPDATE_HASH\t4(HASH_PTR), TB\n\tUPDATE_HASH\t8(HASH_PTR), C\n\tUPDATE_HASH\t12(HASH_PTR), D\n\tUPDATE_HASH\t16(HASH_PTR), E\n\n\ttest\tBLOCKS_CTR, BLOCKS_CTR\n\tjz\t.L_loop\n\n\tmov\tTB, B\n\n\t \n\t \n\n\t.set j, 0\n\t.rept 10\n\t\tRR\tj+80\n\t\t.set j, j+2\n\t.endr\n\n\t \n\t.rept 10\n\t\tRR\tj+80\n\t\t.set j, j+2\n\t.endr\n\n\t \n\t.rept 10\n\t\tRR\tj+80\n\t\t.set j, j+2\n\t.endr\n\n\t \n\tsub     $1, BLOCKS_CTR\n\t \n\tADD_IF_GE BUFFER_PTR2, BLOCKS_CTR, 4, 128\n\n\t \n\t.rept 10\n\t\tRR\tj+80\n\t\t.set j, j+2\n\t.endr\n\n\tUPDATE_HASH\t(HASH_PTR), A\n\tUPDATE_HASH\t4(HASH_PTR), TB\n\tUPDATE_HASH\t8(HASH_PTR), C\n\tUPDATE_HASH\t12(HASH_PTR), D\n\tUPDATE_HASH\t16(HASH_PTR), E\n\n\t \n\tmov\tA, TA\n\tmov\tTB, A\n\tmov\tC, TB\n\tmov\tE, C\n\tmov\tD, B\n\tmov\tTA, D\n\n\tREGALLOC\n\n\txchg\tWK_BUF, PRECALC_BUF\n\n\tjmp\t.L_loop\n\n\t.align 32\n.L_end:\n\n.endm\n \n.macro SHA1_VECTOR_ASM  name\n\tSYM_FUNC_START(\\name)\n\n\tpush\t%rbx\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n\n\tRESERVE_STACK  = (W_SIZE*4 + 8+24)\n\n\t \n\tpush\t%rbp\n\tmov\t%rsp, %rbp\n\tand\t$~(0x20-1), %rsp\n\tsub\t$RESERVE_STACK, %rsp\n\n\tavx2_zeroupper\n\n\t \n\tmov\tCTX, HASH_PTR\n\tmov\tBUF, BUFFER_PTR\n\n\tmov\tBUF, BUFFER_PTR2\n\tmov\tCNT, BLOCKS_CTR\n\n\txmm_mov\tBSWAP_SHUFB_CTL(%rip), YMM_SHUFB_BSWAP\n\n\tSHA1_PIPELINED_MAIN_BODY\n\n\tavx2_zeroupper\n\n\tmov\t%rbp, %rsp\n\tpop\t%rbp\n\n\tpop\t%r15\n\tpop\t%r14\n\tpop\t%r13\n\tpop\t%r12\n\tpop\t%rbx\n\n\tRET\n\n\tSYM_FUNC_END(\\name)\n.endm\n\n.section .rodata\n\n#define K1 0x5a827999\n#define K2 0x6ed9eba1\n#define K3 0x8f1bbcdc\n#define K4 0xca62c1d6\n\n.align 128\nK_XMM_AR:\n\t.long K1, K1, K1, K1\n\t.long K1, K1, K1, K1\n\t.long K2, K2, K2, K2\n\t.long K2, K2, K2, K2\n\t.long K3, K3, K3, K3\n\t.long K3, K3, K3, K3\n\t.long K4, K4, K4, K4\n\t.long K4, K4, K4, K4\n\nBSWAP_SHUFB_CTL:\n\t.long 0x00010203\n\t.long 0x04050607\n\t.long 0x08090a0b\n\t.long 0x0c0d0e0f\n\t.long 0x00010203\n\t.long 0x04050607\n\t.long 0x08090a0b\n\t.long 0x0c0d0e0f\n.text\n\nSHA1_VECTOR_ASM     sha1_transform_avx2\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}