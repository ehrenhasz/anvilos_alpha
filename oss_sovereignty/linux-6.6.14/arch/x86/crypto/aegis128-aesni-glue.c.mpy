{
  "module_name": "aegis128-aesni-glue.c",
  "hash_id": "adf19074d2300849c024d2a8301cc35d8b73415b8b520dd48195629af9d34b05",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/crypto/aegis128-aesni-glue.c",
  "human_readable_source": "\n \n\n#include <crypto/internal/aead.h>\n#include <crypto/internal/simd.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/scatterwalk.h>\n#include <linux/module.h>\n#include <asm/fpu/api.h>\n#include <asm/cpu_device_id.h>\n\n#define AEGIS128_BLOCK_ALIGN 16\n#define AEGIS128_BLOCK_SIZE 16\n#define AEGIS128_NONCE_SIZE 16\n#define AEGIS128_STATE_BLOCKS 5\n#define AEGIS128_KEY_SIZE 16\n#define AEGIS128_MIN_AUTH_SIZE 8\n#define AEGIS128_MAX_AUTH_SIZE 16\n\nasmlinkage void crypto_aegis128_aesni_init(void *state, void *key, void *iv);\n\nasmlinkage void crypto_aegis128_aesni_ad(\n\t\tvoid *state, unsigned int length, const void *data);\n\nasmlinkage void crypto_aegis128_aesni_enc(\n\t\tvoid *state, unsigned int length, const void *src, void *dst);\n\nasmlinkage void crypto_aegis128_aesni_dec(\n\t\tvoid *state, unsigned int length, const void *src, void *dst);\n\nasmlinkage void crypto_aegis128_aesni_enc_tail(\n\t\tvoid *state, unsigned int length, const void *src, void *dst);\n\nasmlinkage void crypto_aegis128_aesni_dec_tail(\n\t\tvoid *state, unsigned int length, const void *src, void *dst);\n\nasmlinkage void crypto_aegis128_aesni_final(\n\t\tvoid *state, void *tag_xor, unsigned int cryptlen,\n\t\tunsigned int assoclen);\n\nstruct aegis_block {\n\tu8 bytes[AEGIS128_BLOCK_SIZE] __aligned(AEGIS128_BLOCK_ALIGN);\n};\n\nstruct aegis_state {\n\tstruct aegis_block blocks[AEGIS128_STATE_BLOCKS];\n};\n\nstruct aegis_ctx {\n\tstruct aegis_block key;\n};\n\nstruct aegis_crypt_ops {\n\tint (*skcipher_walk_init)(struct skcipher_walk *walk,\n\t\t\t\t  struct aead_request *req, bool atomic);\n\n\tvoid (*crypt_blocks)(void *state, unsigned int length, const void *src,\n\t\t\t     void *dst);\n\tvoid (*crypt_tail)(void *state, unsigned int length, const void *src,\n\t\t\t   void *dst);\n};\n\nstatic void crypto_aegis128_aesni_process_ad(\n\t\tstruct aegis_state *state, struct scatterlist *sg_src,\n\t\tunsigned int assoclen)\n{\n\tstruct scatter_walk walk;\n\tstruct aegis_block buf;\n\tunsigned int pos = 0;\n\n\tscatterwalk_start(&walk, sg_src);\n\twhile (assoclen != 0) {\n\t\tunsigned int size = scatterwalk_clamp(&walk, assoclen);\n\t\tunsigned int left = size;\n\t\tvoid *mapped = scatterwalk_map(&walk);\n\t\tconst u8 *src = (const u8 *)mapped;\n\n\t\tif (pos + size >= AEGIS128_BLOCK_SIZE) {\n\t\t\tif (pos > 0) {\n\t\t\t\tunsigned int fill = AEGIS128_BLOCK_SIZE - pos;\n\t\t\t\tmemcpy(buf.bytes + pos, src, fill);\n\t\t\t\tcrypto_aegis128_aesni_ad(state,\n\t\t\t\t\t\t\t AEGIS128_BLOCK_SIZE,\n\t\t\t\t\t\t\t buf.bytes);\n\t\t\t\tpos = 0;\n\t\t\t\tleft -= fill;\n\t\t\t\tsrc += fill;\n\t\t\t}\n\n\t\t\tcrypto_aegis128_aesni_ad(state, left, src);\n\n\t\t\tsrc += left & ~(AEGIS128_BLOCK_SIZE - 1);\n\t\t\tleft &= AEGIS128_BLOCK_SIZE - 1;\n\t\t}\n\n\t\tmemcpy(buf.bytes + pos, src, left);\n\t\tpos += left;\n\t\tassoclen -= size;\n\n\t\tscatterwalk_unmap(mapped);\n\t\tscatterwalk_advance(&walk, size);\n\t\tscatterwalk_done(&walk, 0, assoclen);\n\t}\n\n\tif (pos > 0) {\n\t\tmemset(buf.bytes + pos, 0, AEGIS128_BLOCK_SIZE - pos);\n\t\tcrypto_aegis128_aesni_ad(state, AEGIS128_BLOCK_SIZE, buf.bytes);\n\t}\n}\n\nstatic void crypto_aegis128_aesni_process_crypt(\n\t\tstruct aegis_state *state, struct skcipher_walk *walk,\n\t\tconst struct aegis_crypt_ops *ops)\n{\n\twhile (walk->nbytes >= AEGIS128_BLOCK_SIZE) {\n\t\tops->crypt_blocks(state,\n\t\t\t\t  round_down(walk->nbytes, AEGIS128_BLOCK_SIZE),\n\t\t\t\t  walk->src.virt.addr, walk->dst.virt.addr);\n\t\tskcipher_walk_done(walk, walk->nbytes % AEGIS128_BLOCK_SIZE);\n\t}\n\n\tif (walk->nbytes) {\n\t\tops->crypt_tail(state, walk->nbytes, walk->src.virt.addr,\n\t\t\t\twalk->dst.virt.addr);\n\t\tskcipher_walk_done(walk, 0);\n\t}\n}\n\nstatic struct aegis_ctx *crypto_aegis128_aesni_ctx(struct crypto_aead *aead)\n{\n\tu8 *ctx = crypto_aead_ctx(aead);\n\tctx = PTR_ALIGN(ctx, __alignof__(struct aegis_ctx));\n\treturn (void *)ctx;\n}\n\nstatic int crypto_aegis128_aesni_setkey(struct crypto_aead *aead, const u8 *key,\n\t\t\t\t\tunsigned int keylen)\n{\n\tstruct aegis_ctx *ctx = crypto_aegis128_aesni_ctx(aead);\n\n\tif (keylen != AEGIS128_KEY_SIZE)\n\t\treturn -EINVAL;\n\n\tmemcpy(ctx->key.bytes, key, AEGIS128_KEY_SIZE);\n\n\treturn 0;\n}\n\nstatic int crypto_aegis128_aesni_setauthsize(struct crypto_aead *tfm,\n\t\t\t\t\t\tunsigned int authsize)\n{\n\tif (authsize > AEGIS128_MAX_AUTH_SIZE)\n\t\treturn -EINVAL;\n\tif (authsize < AEGIS128_MIN_AUTH_SIZE)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic void crypto_aegis128_aesni_crypt(struct aead_request *req,\n\t\t\t\t\tstruct aegis_block *tag_xor,\n\t\t\t\t\tunsigned int cryptlen,\n\t\t\t\t\tconst struct aegis_crypt_ops *ops)\n{\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aegis_ctx *ctx = crypto_aegis128_aesni_ctx(tfm);\n\tstruct skcipher_walk walk;\n\tstruct aegis_state state;\n\n\tops->skcipher_walk_init(&walk, req, true);\n\n\tkernel_fpu_begin();\n\n\tcrypto_aegis128_aesni_init(&state, ctx->key.bytes, req->iv);\n\tcrypto_aegis128_aesni_process_ad(&state, req->src, req->assoclen);\n\tcrypto_aegis128_aesni_process_crypt(&state, &walk, ops);\n\tcrypto_aegis128_aesni_final(&state, tag_xor, req->assoclen, cryptlen);\n\n\tkernel_fpu_end();\n}\n\nstatic int crypto_aegis128_aesni_encrypt(struct aead_request *req)\n{\n\tstatic const struct aegis_crypt_ops OPS = {\n\t\t.skcipher_walk_init = skcipher_walk_aead_encrypt,\n\t\t.crypt_blocks = crypto_aegis128_aesni_enc,\n\t\t.crypt_tail = crypto_aegis128_aesni_enc_tail,\n\t};\n\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aegis_block tag = {};\n\tunsigned int authsize = crypto_aead_authsize(tfm);\n\tunsigned int cryptlen = req->cryptlen;\n\n\tcrypto_aegis128_aesni_crypt(req, &tag, cryptlen, &OPS);\n\n\tscatterwalk_map_and_copy(tag.bytes, req->dst,\n\t\t\t\t req->assoclen + cryptlen, authsize, 1);\n\treturn 0;\n}\n\nstatic int crypto_aegis128_aesni_decrypt(struct aead_request *req)\n{\n\tstatic const struct aegis_block zeros = {};\n\n\tstatic const struct aegis_crypt_ops OPS = {\n\t\t.skcipher_walk_init = skcipher_walk_aead_decrypt,\n\t\t.crypt_blocks = crypto_aegis128_aesni_dec,\n\t\t.crypt_tail = crypto_aegis128_aesni_dec_tail,\n\t};\n\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aegis_block tag;\n\tunsigned int authsize = crypto_aead_authsize(tfm);\n\tunsigned int cryptlen = req->cryptlen - authsize;\n\n\tscatterwalk_map_and_copy(tag.bytes, req->src,\n\t\t\t\t req->assoclen + cryptlen, authsize, 0);\n\n\tcrypto_aegis128_aesni_crypt(req, &tag, cryptlen, &OPS);\n\n\treturn crypto_memneq(tag.bytes, zeros.bytes, authsize) ? -EBADMSG : 0;\n}\n\nstatic int crypto_aegis128_aesni_init_tfm(struct crypto_aead *aead)\n{\n\treturn 0;\n}\n\nstatic void crypto_aegis128_aesni_exit_tfm(struct crypto_aead *aead)\n{\n}\n\nstatic struct aead_alg crypto_aegis128_aesni_alg = {\n\t.setkey = crypto_aegis128_aesni_setkey,\n\t.setauthsize = crypto_aegis128_aesni_setauthsize,\n\t.encrypt = crypto_aegis128_aesni_encrypt,\n\t.decrypt = crypto_aegis128_aesni_decrypt,\n\t.init = crypto_aegis128_aesni_init_tfm,\n\t.exit = crypto_aegis128_aesni_exit_tfm,\n\n\t.ivsize = AEGIS128_NONCE_SIZE,\n\t.maxauthsize = AEGIS128_MAX_AUTH_SIZE,\n\t.chunksize = AEGIS128_BLOCK_SIZE,\n\n\t.base = {\n\t\t.cra_flags = CRYPTO_ALG_INTERNAL,\n\t\t.cra_blocksize = 1,\n\t\t.cra_ctxsize = sizeof(struct aegis_ctx) +\n\t\t\t       __alignof__(struct aegis_ctx),\n\t\t.cra_alignmask = 0,\n\t\t.cra_priority = 400,\n\n\t\t.cra_name = \"__aegis128\",\n\t\t.cra_driver_name = \"__aegis128-aesni\",\n\n\t\t.cra_module = THIS_MODULE,\n\t}\n};\n\nstatic struct simd_aead_alg *simd_alg;\n\nstatic int __init crypto_aegis128_aesni_module_init(void)\n{\n\tif (!boot_cpu_has(X86_FEATURE_XMM2) ||\n\t    !boot_cpu_has(X86_FEATURE_AES) ||\n\t    !cpu_has_xfeatures(XFEATURE_MASK_SSE, NULL))\n\t\treturn -ENODEV;\n\n\treturn simd_register_aeads_compat(&crypto_aegis128_aesni_alg, 1,\n\t\t\t\t\t  &simd_alg);\n}\n\nstatic void __exit crypto_aegis128_aesni_module_exit(void)\n{\n\tsimd_unregister_aeads(&crypto_aegis128_aesni_alg, 1, &simd_alg);\n}\n\nmodule_init(crypto_aegis128_aesni_module_init);\nmodule_exit(crypto_aegis128_aesni_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Ondrej Mosnacek <omosnacek@gmail.com>\");\nMODULE_DESCRIPTION(\"AEGIS-128 AEAD algorithm -- AESNI+SSE2 implementation\");\nMODULE_ALIAS_CRYPTO(\"aegis128\");\nMODULE_ALIAS_CRYPTO(\"aegis128-aesni\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}