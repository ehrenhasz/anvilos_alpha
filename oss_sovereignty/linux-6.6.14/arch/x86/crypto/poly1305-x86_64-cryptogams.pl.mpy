{
  "module_name": "poly1305-x86_64-cryptogams.pl",
  "hash_id": "853471dfcfee9fd3e0896e681481fb1568ab6583682a7e7fdcd9e2705dcc5d8d",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/crypto/poly1305-x86_64-cryptogams.pl",
  "human_readable_source": "#!/usr/bin/env perl\n# SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause\n#\n# Copyright (C) 2017-2018 Samuel Neves <sneves@dei.uc.pt>. All Rights Reserved.\n# Copyright (C) 2017-2019 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.\n# Copyright (C) 2006-2017 CRYPTOGAMS by <appro@openssl.org>. All Rights Reserved.\n#\n# This code is taken from the OpenSSL project but the author, Andy Polyakov,\n# has relicensed it under the licenses specified in the SPDX header above.\n# The original headers, including the original license headers, are\n# included below for completeness.\n#\n# ====================================================================\n# Written by Andy Polyakov <appro@openssl.org> for the OpenSSL\n# project. The module is, however, dual licensed under OpenSSL and\n# CRYPTOGAMS licenses depending on where you obtain it. For further\n# details see http://www.openssl.org/~appro/cryptogams/.\n# ====================================================================\n#\n# This module implements Poly1305 hash for x86_64.\n#\n# March 2015\n#\n# Initial release.\n#\n# December 2016\n#\n# Add AVX512F+VL+BW code path.\n#\n# November 2017\n#\n# Convert AVX512F+VL+BW code path to pure AVX512F, so that it can be\n# executed even on Knights Landing. Trigger for modification was\n# observation that AVX512 code paths can negatively affect overall\n# Skylake-X system performance. Since we are likely to suppress\n# AVX512F capability flag [at least on Skylake-X], conversion serves\n# as kind of \"investment protection\". Note that next *lake processor,\n# Cannonlake, has AVX512IFMA code path to execute...\n#\n# Numbers are cycles per processed byte with poly1305_blocks alone,\n# measured with rdtsc at fixed clock frequency.\n#\n#\t\tIALU/gcc-4.8(*)\tAVX(**)\t\tAVX2\tAVX-512\n# P4\t\t4.46/+120%\t-\n# Core 2\t2.41/+90%\t-\n# Westmere\t1.88/+120%\t-\n# Sandy Bridge\t1.39/+140%\t1.10\n# Haswell\t1.14/+175%\t1.11\t\t0.65\n# Skylake[-X]\t1.13/+120%\t0.96\t\t0.51\t[0.35]\n# Silvermont\t2.83/+95%\t-\n# Knights L\t3.60/?\t\t1.65\t\t1.10\t0.41(***)\n# Goldmont\t1.70/+180%\t-\n# VIA Nano\t1.82/+150%\t-\n# Sledgehammer\t1.38/+160%\t-\n# Bulldozer\t2.30/+130%\t0.97\n# Ryzen\t\t1.15/+200%\t1.08\t\t1.18\n#\n# (*)\timprovement coefficients relative to clang are more modest and\n#\tare ~50% on most processors, in both cases we are comparing to\n#\t__int128 code;\n# (**)\tSSE2 implementation was attempted, but among non-AVX processors\n#\tit was faster than integer-only code only on older Intel P4 and\n#\tCore processors, 50-30%, less newer processor is, but slower on\n#\tcontemporary ones, for example almost 2x slower on Atom, and as\n#\tformer are naturally disappearing, SSE2 is deemed unnecessary;\n# (***)\tstrangely enough performance seems to vary from core to core,\n#\tlisted result is best case;\n\n$flavour = shift;\n$output  = shift;\nif ($flavour =~ /\\./) { $output = $flavour; undef $flavour; }\n\n$win64=0; $win64=1 if ($flavour =~ /[nm]asm|mingw64/ || $output =~ /\\.asm$/);\n$kernel=0; $kernel=1 if (!$flavour && !$output);\n\nif (!$kernel) {\n\t$0 =~ m/(.*[\\/\\\\])[^\\/\\\\]+$/; $dir=$1;\n\t( $xlate=\"${dir}x86_64-xlate.pl\" and -f $xlate ) or\n\t( $xlate=\"${dir}../../perlasm/x86_64-xlate.pl\" and -f $xlate) or\n\tdie \"can't locate x86_64-xlate.pl\";\n\n\topen OUT,\"| \\\"$^X\\\" \\\"$xlate\\\" $flavour \\\"$output\\\"\";\n\t*STDOUT=*OUT;\n\n\tif (`$ENV{CC} -Wa,-v -c -o /dev/null -x assembler /dev/null 2>&1`\n\t    =~ /GNU assembler version ([2-9]\\.[0-9]+)/) {\n\t\t$avx = ($1>=2.19) + ($1>=2.22) + ($1>=2.25);\n\t}\n\n\tif (!$avx && $win64 && ($flavour =~ /nasm/ || $ENV{ASM} =~ /nasm/) &&\n\t    `nasm -v 2>&1` =~ /NASM version ([2-9]\\.[0-9]+)(?:\\.([0-9]+))?/) {\n\t\t$avx = ($1>=2.09) + ($1>=2.10) + ($1>=2.12);\n\t\t$avx += 1 if ($1==2.11 && $2>=8);\n\t}\n\n\tif (!$avx && $win64 && ($flavour =~ /masm/ || $ENV{ASM} =~ /ml64/) &&\n\t    `ml64 2>&1` =~ /Version ([0-9]+)\\./) {\n\t\t$avx = ($1>=10) + ($1>=11);\n\t}\n\n\tif (!$avx && `$ENV{CC} -v 2>&1` =~ /((?:^clang|LLVM) version|.*based on LLVM) ([3-9]\\.[0-9]+)/) {\n\t\t$avx = ($2>=3.0) + ($2>3.0);\n\t}\n} else {\n\t$avx = 4; # The kernel uses ifdefs for this.\n}\n\nsub declare_function() {\n\tmy ($name, $align, $nargs) = @_;\n\tif($kernel) {\n\t\t$code .= \"SYM_FUNC_START($name)\\n\";\n\t\t$code .= \".L$name:\\n\";\n\t} else {\n\t\t$code .= \".globl\t$name\\n\";\n\t\t$code .= \".type\t$name,\\@function,$nargs\\n\";\n\t\t$code .= \".align\t$align\\n\";\n\t\t$code .= \"$name:\\n\";\n\t}\n}\n\nsub end_function() {\n\tmy ($name) = @_;\n\tif($kernel) {\n\t\t$code .= \"SYM_FUNC_END($name)\\n\";\n\t} else {\n\t\t$code .= \".size   $name,.-$name\\n\";\n\t}\n}\n\n$code.=<<___ if $kernel;\n#include <linux/linkage.h>\n___\n\nif ($avx) {\n$code.=<<___ if $kernel;\n.section .rodata\n___\n$code.=<<___;\n.align\t64\n.Lconst:\n.Lmask24:\n.long\t0x0ffffff,0,0x0ffffff,0,0x0ffffff,0,0x0ffffff,0\n.L129:\n.long\t`1<<24`,0,`1<<24`,0,`1<<24`,0,`1<<24`,0\n.Lmask26:\n.long\t0x3ffffff,0,0x3ffffff,0,0x3ffffff,0,0x3ffffff,0\n.Lpermd_avx2:\n.long\t2,2,2,3,2,0,2,1\n.Lpermd_avx512:\n.long\t0,0,0,1, 0,2,0,3, 0,4,0,5, 0,6,0,7\n\n.L2_44_inp_permd:\n.long\t0,1,1,2,2,3,7,7\n.L2_44_inp_shift:\n.quad\t0,12,24,64\n.L2_44_mask:\n.quad\t0xfffffffffff,0xfffffffffff,0x3ffffffffff,0xffffffffffffffff\n.L2_44_shift_rgt:\n.quad\t44,44,42,64\n.L2_44_shift_lft:\n.quad\t8,8,10,64\n\n.align\t64\n.Lx_mask44:\n.quad\t0xfffffffffff,0xfffffffffff,0xfffffffffff,0xfffffffffff\n.quad\t0xfffffffffff,0xfffffffffff,0xfffffffffff,0xfffffffffff\n.Lx_mask42:\n.quad\t0x3ffffffffff,0x3ffffffffff,0x3ffffffffff,0x3ffffffffff\n.quad\t0x3ffffffffff,0x3ffffffffff,0x3ffffffffff,0x3ffffffffff\n___\n}\n$code.=<<___ if (!$kernel);\n.asciz\t\"Poly1305 for x86_64, CRYPTOGAMS by <appro\\@openssl.org>\"\n.align\t16\n___\n\nmy ($ctx,$inp,$len,$padbit)=(\"%rdi\",\"%rsi\",\"%rdx\",\"%rcx\");\nmy ($mac,$nonce)=($inp,$len);\t# *_emit arguments\nmy ($d1,$d2,$d3, $r0,$r1,$s1)=(\"%r8\",\"%r9\",\"%rdi\",\"%r11\",\"%r12\",\"%r13\");\nmy ($h0,$h1,$h2)=(\"%r14\",\"%rbx\",\"%r10\");\n\nsub poly1305_iteration {\n# input:\tcopy of $r1 in %rax, $h0-$h2, $r0-$r1\n# output:\t$h0-$h2 *= $r0-$r1\n$code.=<<___;\n\tmulq\t$h0\t\t\t# h0*r1\n\tmov\t%rax,$d2\n\t mov\t$r0,%rax\n\tmov\t%rdx,$d3\n\n\tmulq\t$h0\t\t\t# h0*r0\n\tmov\t%rax,$h0\t\t# future $h0\n\t mov\t$r0,%rax\n\tmov\t%rdx,$d1\n\n\tmulq\t$h1\t\t\t# h1*r0\n\tadd\t%rax,$d2\n\t mov\t$s1,%rax\n\tadc\t%rdx,$d3\n\n\tmulq\t$h1\t\t\t# h1*s1\n\t mov\t$h2,$h1\t\t\t# borrow $h1\n\tadd\t%rax,$h0\n\tadc\t%rdx,$d1\n\n\timulq\t$s1,$h1\t\t\t# h2*s1\n\tadd\t$h1,$d2\n\t mov\t$d1,$h1\n\tadc\t\\$0,$d3\n\n\timulq\t$r0,$h2\t\t\t# h2*r0\n\tadd\t$d2,$h1\n\tmov\t\\$-4,%rax\t\t# mask value\n\tadc\t$h2,$d3\n\n\tand\t$d3,%rax\t\t# last reduction step\n\tmov\t$d3,$h2\n\tshr\t\\$2,$d3\n\tand\t\\$3,$h2\n\tadd\t$d3,%rax\n\tadd\t%rax,$h0\n\tadc\t\\$0,$h1\n\tadc\t\\$0,$h2\n___\n}\n\n########################################################################\n# Layout of opaque area is following.\n#\n#\tunsigned __int64 h[3];\t\t# current hash value base 2^64\n#\tunsigned __int64 r[2];\t\t# key value base 2^64\n\n$code.=<<___;\n.text\n___\n$code.=<<___ if (!$kernel);\n.extern\tOPENSSL_ia32cap_P\n\n.globl\tpoly1305_init_x86_64\n.hidden\tpoly1305_init_x86_64\n.globl\tpoly1305_blocks_x86_64\n.hidden\tpoly1305_blocks_x86_64\n.globl\tpoly1305_emit_x86_64\n.hidden\tpoly1305_emit_x86_64\n___\n&declare_function(\"poly1305_init_x86_64\", 32, 3);\n$code.=<<___;\n\txor\t%eax,%eax\n\tmov\t%rax,0($ctx)\t\t# initialize hash value\n\tmov\t%rax,8($ctx)\n\tmov\t%rax,16($ctx)\n\n\ttest\t$inp,$inp\n\tje\t.Lno_key\n___\n$code.=<<___ if (!$kernel);\n\tlea\tpoly1305_blocks_x86_64(%rip),%r10\n\tlea\tpoly1305_emit_x86_64(%rip),%r11\n___\n$code.=<<___\tif (!$kernel && $avx);\n\tmov\tOPENSSL_ia32cap_P+4(%rip),%r9\n\tlea\tpoly1305_blocks_avx(%rip),%rax\n\tlea\tpoly1305_emit_avx(%rip),%rcx\n\tbt\t\\$`60-32`,%r9\t\t# AVX?\n\tcmovc\t%rax,%r10\n\tcmovc\t%rcx,%r11\n___\n$code.=<<___\tif (!$kernel && $avx>1);\n\tlea\tpoly1305_blocks_avx2(%rip),%rax\n\tbt\t\\$`5+32`,%r9\t\t# AVX2?\n\tcmovc\t%rax,%r10\n___\n$code.=<<___\tif (!$kernel && $avx>3);\n\tmov\t\\$`(1<<31|1<<21|1<<16)`,%rax\n\tshr\t\\$32,%r9\n\tand\t%rax,%r9\n\tcmp\t%rax,%r9\n\tje\t.Linit_base2_44\n___\n$code.=<<___;\n\tmov\t\\$0x0ffffffc0fffffff,%rax\n\tmov\t\\$0x0ffffffc0ffffffc,%rcx\n\tand\t0($inp),%rax\n\tand\t8($inp),%rcx\n\tmov\t%rax,24($ctx)\n\tmov\t%rcx,32($ctx)\n___\n$code.=<<___\tif (!$kernel && $flavour !~ /elf32/);\n\tmov\t%r10,0(%rdx)\n\tmov\t%r11,8(%rdx)\n___\n$code.=<<___\tif (!$kernel && $flavour =~ /elf32/);\n\tmov\t%r10d,0(%rdx)\n\tmov\t%r11d,4(%rdx)\n___\n$code.=<<___;\n\tmov\t\\$1,%eax\n.Lno_key:\n\tRET\n___\n&end_function(\"poly1305_init_x86_64\");\n\n&declare_function(\"poly1305_blocks_x86_64\", 32, 4);\n$code.=<<___;\n.cfi_startproc\n.Lblocks:\n\tshr\t\\$4,$len\n\tjz\t.Lno_data\t\t# too short\n\n\tpush\t%rbx\n.cfi_push\t%rbx\n\tpush\t%r12\n.cfi_push\t%r12\n\tpush\t%r13\n.cfi_push\t%r13\n\tpush\t%r14\n.cfi_push\t%r14\n\tpush\t%r15\n.cfi_push\t%r15\n\tpush\t$ctx\n.cfi_push\t$ctx\n.Lblocks_body:\n\n\tmov\t$len,%r15\t\t# reassign $len\n\n\tmov\t24($ctx),$r0\t\t# load r\n\tmov\t32($ctx),$s1\n\n\tmov\t0($ctx),$h0\t\t# load hash value\n\tmov\t8($ctx),$h1\n\tmov\t16($ctx),$h2\n\n\tmov\t$s1,$r1\n\tshr\t\\$2,$s1\n\tmov\t$r1,%rax\n\tadd\t$r1,$s1\t\t\t# s1 = r1 + (r1 >> 2)\n\tjmp\t.Loop\n\n.align\t32\n.Loop:\n\tadd\t0($inp),$h0\t\t# accumulate input\n\tadc\t8($inp),$h1\n\tlea\t16($inp),$inp\n\tadc\t$padbit,$h2\n___\n\n\t&poly1305_iteration();\n\n$code.=<<___;\n\tmov\t$r1,%rax\n\tdec\t%r15\t\t\t# len-=16\n\tjnz\t.Loop\n\n\tmov\t0(%rsp),$ctx\n.cfi_restore\t$ctx\n\n\tmov\t$h0,0($ctx)\t\t# store hash value\n\tmov\t$h1,8($ctx)\n\tmov\t$h2,16($ctx)\n\n\tmov\t8(%rsp),%r15\n.cfi_restore\t%r15\n\tmov\t16(%rsp),%r14\n.cfi_restore\t%r14\n\tmov\t24(%rsp),%r13\n.cfi_restore\t%r13\n\tmov\t32(%rsp),%r12\n.cfi_restore\t%r12\n\tmov\t40(%rsp),%rbx\n.cfi_restore\t%rbx\n\tlea\t48(%rsp),%rsp\n.cfi_adjust_cfa_offset\t-48\n.Lno_data:\n.Lblocks_epilogue:\n\tRET\n.cfi_endproc\n___\n&end_function(\"poly1305_blocks_x86_64\");\n\n&declare_function(\"poly1305_emit_x86_64\", 32, 3);\n$code.=<<___;\n.Lemit:\n\tmov\t0($ctx),%r8\t# load hash value\n\tmov\t8($ctx),%r9\n\tmov\t16($ctx),%r10\n\n\tmov\t%r8,%rax\n\tadd\t\\$5,%r8\t\t# compare to modulus\n\tmov\t%r9,%rcx\n\tadc\t\\$0,%r9\n\tadc\t\\$0,%r10\n\tshr\t\\$2,%r10\t# did 130-bit value overflow?\n\tcmovnz\t%r8,%rax\n\tcmovnz\t%r9,%rcx\n\n\tadd\t0($nonce),%rax\t# accumulate nonce\n\tadc\t8($nonce),%rcx\n\tmov\t%rax,0($mac)\t# write result\n\tmov\t%rcx,8($mac)\n\n\tRET\n___\n&end_function(\"poly1305_emit_x86_64\");\nif ($avx) {\n\n########################################################################\n# Layout of opaque area is following.\n#\n#\tunsigned __int32 h[5];\t\t# current hash value base 2^26\n#\tunsigned __int32 is_base2_26;\n#\tunsigned __int64 r[2];\t\t# key value base 2^64\n#\tunsigned __int64 pad;\n#\tstruct { unsigned __int32 r^2, r^1, r^4, r^3; } r[9];\n#\n# where r^n are base 2^26 digits of degrees of multiplier key. There are\n# 5 digits, but last four are interleaved with multiples of 5, totalling\n# in 9 elements: r0, r1, 5*r1, r2, 5*r2, r3, 5*r3, r4, 5*r4.\n\nmy ($H0,$H1,$H2,$H3,$H4, $T0,$T1,$T2,$T3,$T4, $D0,$D1,$D2,$D3,$D4, $MASK) =\n    map(\"%xmm$_\",(0..15));\n\n$code.=<<___;\n.type\t__poly1305_block,\\@abi-omnipotent\n.align\t32\n__poly1305_block:\n\tpush $ctx\n___\n\t&poly1305_iteration();\n$code.=<<___;\n\tpop $ctx\n\tRET\n.size\t__poly1305_block,.-__poly1305_block\n\n.type\t__poly1305_init_avx,\\@abi-omnipotent\n.align\t32\n__poly1305_init_avx:\n\tpush %rbp\n\tmov %rsp,%rbp\n\tmov\t$r0,$h0\n\tmov\t$r1,$h1\n\txor\t$h2,$h2\n\n\tlea\t48+64($ctx),$ctx\t# size optimization\n\n\tmov\t$r1,%rax\n\tcall\t__poly1305_block\t# r^2\n\n\tmov\t\\$0x3ffffff,%eax\t# save interleaved r^2 and r base 2^26\n\tmov\t\\$0x3ffffff,%edx\n\tmov\t$h0,$d1\n\tand\t$h0#d,%eax\n\tmov\t$r0,$d2\n\tand\t$r0#d,%edx\n\tmov\t%eax,`16*0+0-64`($ctx)\n\tshr\t\\$26,$d1\n\tmov\t%edx,`16*0+4-64`($ctx)\n\tshr\t\\$26,$d2\n\n\tmov\t\\$0x3ffffff,%eax\n\tmov\t\\$0x3ffffff,%edx\n\tand\t$d1#d,%eax\n\tand\t$d2#d,%edx\n\tmov\t%eax,`16*1+0-64`($ctx)\n\tlea\t(%rax,%rax,4),%eax\t# *5\n\tmov\t%edx,`16*1+4-64`($ctx)\n\tlea\t(%rdx,%rdx,4),%edx\t# *5\n\tmov\t%eax,`16*2+0-64`($ctx)\n\tshr\t\\$26,$d1\n\tmov\t%edx,`16*2+4-64`($ctx)\n\tshr\t\\$26,$d2\n\n\tmov\t$h1,%rax\n\tmov\t$r1,%rdx\n\tshl\t\\$12,%rax\n\tshl\t\\$12,%rdx\n\tor\t$d1,%rax\n\tor\t$d2,%rdx\n\tand\t\\$0x3ffffff,%eax\n\tand\t\\$0x3ffffff,%edx\n\tmov\t%eax,`16*3+0-64`($ctx)\n\tlea\t(%rax,%rax,4),%eax\t# *5\n\tmov\t%edx,`16*3+4-64`($ctx)\n\tlea\t(%rdx,%rdx,4),%edx\t# *5\n\tmov\t%eax,`16*4+0-64`($ctx)\n\tmov\t$h1,$d1\n\tmov\t%edx,`16*4+4-64`($ctx)\n\tmov\t$r1,$d2\n\n\tmov\t\\$0x3ffffff,%eax\n\tmov\t\\$0x3ffffff,%edx\n\tshr\t\\$14,$d1\n\tshr\t\\$14,$d2\n\tand\t$d1#d,%eax\n\tand\t$d2#d,%edx\n\tmov\t%eax,`16*5+0-64`($ctx)\n\tlea\t(%rax,%rax,4),%eax\t# *5\n\tmov\t%edx,`16*5+4-64`($ctx)\n\tlea\t(%rdx,%rdx,4),%edx\t# *5\n\tmov\t%eax,`16*6+0-64`($ctx)\n\tshr\t\\$26,$d1\n\tmov\t%edx,`16*6+4-64`($ctx)\n\tshr\t\\$26,$d2\n\n\tmov\t$h2,%rax\n\tshl\t\\$24,%rax\n\tor\t%rax,$d1\n\tmov\t$d1#d,`16*7+0-64`($ctx)\n\tlea\t($d1,$d1,4),$d1\t\t# *5\n\tmov\t$d2#d,`16*7+4-64`($ctx)\n\tlea\t($d2,$d2,4),$d2\t\t# *5\n\tmov\t$d1#d,`16*8+0-64`($ctx)\n\tmov\t$d2#d,`16*8+4-64`($ctx)\n\n\tmov\t$r1,%rax\n\tcall\t__poly1305_block\t# r^3\n\n\tmov\t\\$0x3ffffff,%eax\t# save r^3 base 2^26\n\tmov\t$h0,$d1\n\tand\t$h0#d,%eax\n\tshr\t\\$26,$d1\n\tmov\t%eax,`16*0+12-64`($ctx)\n\n\tmov\t\\$0x3ffffff,%edx\n\tand\t$d1#d,%edx\n\tmov\t%edx,`16*1+12-64`($ctx)\n\tlea\t(%rdx,%rdx,4),%edx\t# *5\n\tshr\t\\$26,$d1\n\tmov\t%edx,`16*2+12-64`($ctx)\n\n\tmov\t$h1,%rax\n\tshl\t\\$12,%rax\n\tor\t$d1,%rax\n\tand\t\\$0x3ffffff,%eax\n\tmov\t%eax,`16*3+12-64`($ctx)\n\tlea\t(%rax,%rax,4),%eax\t# *5\n\tmov\t$h1,$d1\n\tmov\t%eax,`16*4+12-64`($ctx)\n\n\tmov\t\\$0x3ffffff,%edx\n\tshr\t\\$14,$d1\n\tand\t$d1#d,%edx\n\tmov\t%edx,`16*5+12-64`($ctx)\n\tlea\t(%rdx,%rdx,4),%edx\t# *5\n\tshr\t\\$26,$d1\n\tmov\t%edx,`16*6+12-64`($ctx)\n\n\tmov\t$h2,%rax\n\tshl\t\\$24,%rax\n\tor\t%rax,$d1\n\tmov\t$d1#d,`16*7+12-64`($ctx)\n\tlea\t($d1,$d1,4),$d1\t\t# *5\n\tmov\t$d1#d,`16*8+12-64`($ctx)\n\n\tmov\t$r1,%rax\n\tcall\t__poly1305_block\t# r^4\n\n\tmov\t\\$0x3ffffff,%eax\t# save r^4 base 2^26\n\tmov\t$h0,$d1\n\tand\t$h0#d,%eax\n\tshr\t\\$26,$d1\n\tmov\t%eax,`16*0+8-64`($ctx)\n\n\tmov\t\\$0x3ffffff,%edx\n\tand\t$d1#d,%edx\n\tmov\t%edx,`16*1+8-64`($ctx)\n\tlea\t(%rdx,%rdx,4),%edx\t# *5\n\tshr\t\\$26,$d1\n\tmov\t%edx,`16*2+8-64`($ctx)\n\n\tmov\t$h1,%rax\n\tshl\t\\$12,%rax\n\tor\t$d1,%rax\n\tand\t\\$0x3ffffff,%eax\n\tmov\t%eax,`16*3+8-64`($ctx)\n\tlea\t(%rax,%rax,4),%eax\t# *5\n\tmov\t$h1,$d1\n\tmov\t%eax,`16*4+8-64`($ctx)\n\n\tmov\t\\$0x3ffffff,%edx\n\tshr\t\\$14,$d1\n\tand\t$d1#d,%edx\n\tmov\t%edx,`16*5+8-64`($ctx)\n\tlea\t(%rdx,%rdx,4),%edx\t# *5\n\tshr\t\\$26,$d1\n\tmov\t%edx,`16*6+8-64`($ctx)\n\n\tmov\t$h2,%rax\n\tshl\t\\$24,%rax\n\tor\t%rax,$d1\n\tmov\t$d1#d,`16*7+8-64`($ctx)\n\tlea\t($d1,$d1,4),$d1\t\t# *5\n\tmov\t$d1#d,`16*8+8-64`($ctx)\n\n\tlea\t-48-64($ctx),$ctx\t# size [de-]optimization\n\tpop %rbp\n\tRET\n.size\t__poly1305_init_avx,.-__poly1305_init_avx\n___\n\n&declare_function(\"poly1305_blocks_avx\", 32, 4);\n$code.=<<___;\n.cfi_startproc\n\tmov\t20($ctx),%r8d\t\t# is_base2_26\n\tcmp\t\\$128,$len\n\tjae\t.Lblocks_avx\n\ttest\t%r8d,%r8d\n\tjz\t.Lblocks\n\n.Lblocks_avx:\n\tand\t\\$-16,$len\n\tjz\t.Lno_data_avx\n\n\tvzeroupper\n\n\ttest\t%r8d,%r8d\n\tjz\t.Lbase2_64_avx\n\n\ttest\t\\$31,$len\n\tjz\t.Leven_avx\n\n\tpush\t%rbp\n.cfi_push\t%rbp\n\tmov \t%rsp,%rbp\n\tpush\t%rbx\n.cfi_push\t%rbx\n\tpush\t%r12\n.cfi_push\t%r12\n\tpush\t%r13\n.cfi_push\t%r13\n\tpush\t%r14\n.cfi_push\t%r14\n\tpush\t%r15\n.cfi_push\t%r15\n.Lblocks_avx_body:\n\n\tmov\t$len,%r15\t\t# reassign $len\n\n\tmov\t0($ctx),$d1\t\t# load hash value\n\tmov\t8($ctx),$d2\n\tmov\t16($ctx),$h2#d\n\n\tmov\t24($ctx),$r0\t\t# load r\n\tmov\t32($ctx),$s1\n\n\t################################# base 2^26 -> base 2^64\n\tmov\t$d1#d,$h0#d\n\tand\t\\$`-1*(1<<31)`,$d1\n\tmov\t$d2,$r1\t\t\t# borrow $r1\n\tmov\t$d2#d,$h1#d\n\tand\t\\$`-1*(1<<31)`,$d2\n\n\tshr\t\\$6,$d1\n\tshl\t\\$52,$r1\n\tadd\t$d1,$h0\n\tshr\t\\$12,$h1\n\tshr\t\\$18,$d2\n\tadd\t$r1,$h0\n\tadc\t$d2,$h1\n\n\tmov\t$h2,$d1\n\tshl\t\\$40,$d1\n\tshr\t\\$24,$h2\n\tadd\t$d1,$h1\n\tadc\t\\$0,$h2\t\t\t# can be partially reduced...\n\n\tmov\t\\$-4,$d2\t\t# ... so reduce\n\tmov\t$h2,$d1\n\tand\t$h2,$d2\n\tshr\t\\$2,$d1\n\tand\t\\$3,$h2\n\tadd\t$d2,$d1\t\t\t# =*5\n\tadd\t$d1,$h0\n\tadc\t\\$0,$h1\n\tadc\t\\$0,$h2\n\n\tmov\t$s1,$r1\n\tmov\t$s1,%rax\n\tshr\t\\$2,$s1\n\tadd\t$r1,$s1\t\t\t# s1 = r1 + (r1 >> 2)\n\n\tadd\t0($inp),$h0\t\t# accumulate input\n\tadc\t8($inp),$h1\n\tlea\t16($inp),$inp\n\tadc\t$padbit,$h2\n\n\tcall\t__poly1305_block\n\n\ttest\t$padbit,$padbit\t\t# if $padbit is zero,\n\tjz\t.Lstore_base2_64_avx\t# store hash in base 2^64 format\n\n\t################################# base 2^64 -> base 2^26\n\tmov\t$h0,%rax\n\tmov\t$h0,%rdx\n\tshr\t\\$52,$h0\n\tmov\t$h1,$r0\n\tmov\t$h1,$r1\n\tshr\t\\$26,%rdx\n\tand\t\\$0x3ffffff,%rax\t# h[0]\n\tshl\t\\$12,$r0\n\tand\t\\$0x3ffffff,%rdx\t# h[1]\n\tshr\t\\$14,$h1\n\tor\t$r0,$h0\n\tshl\t\\$24,$h2\n\tand\t\\$0x3ffffff,$h0\t\t# h[2]\n\tshr\t\\$40,$r1\n\tand\t\\$0x3ffffff,$h1\t\t# h[3]\n\tor\t$r1,$h2\t\t\t# h[4]\n\n\tsub\t\\$16,%r15\n\tjz\t.Lstore_base2_26_avx\n\n\tvmovd\t%rax#d,$H0\n\tvmovd\t%rdx#d,$H1\n\tvmovd\t$h0#d,$H2\n\tvmovd\t$h1#d,$H3\n\tvmovd\t$h2#d,$H4\n\tjmp\t.Lproceed_avx\n\n.align\t32\n.Lstore_base2_64_avx:\n\tmov\t$h0,0($ctx)\n\tmov\t$h1,8($ctx)\n\tmov\t$h2,16($ctx)\t\t# note that is_base2_26 is zeroed\n\tjmp\t.Ldone_avx\n\n.align\t16\n.Lstore_base2_26_avx:\n\tmov\t%rax#d,0($ctx)\t\t# store hash value base 2^26\n\tmov\t%rdx#d,4($ctx)\n\tmov\t$h0#d,8($ctx)\n\tmov\t$h1#d,12($ctx)\n\tmov\t$h2#d,16($ctx)\n.align\t16\n.Ldone_avx:\n\tpop \t\t%r15\n.cfi_restore\t%r15\n\tpop \t\t%r14\n.cfi_restore\t%r14\n\tpop \t\t%r13\n.cfi_restore\t%r13\n\tpop \t\t%r12\n.cfi_restore\t%r12\n\tpop \t\t%rbx\n.cfi_restore\t%rbx\n\tpop \t\t%rbp\n.cfi_restore\t%rbp\n.Lno_data_avx:\n.Lblocks_avx_epilogue:\n\tRET\n.cfi_endproc\n\n.align\t32\n.Lbase2_64_avx:\n.cfi_startproc\n\tpush\t%rbp\n.cfi_push\t%rbp\n\tmov \t%rsp,%rbp\n\tpush\t%rbx\n.cfi_push\t%rbx\n\tpush\t%r12\n.cfi_push\t%r12\n\tpush\t%r13\n.cfi_push\t%r13\n\tpush\t%r14\n.cfi_push\t%r14\n\tpush\t%r15\n.cfi_push\t%r15\n.Lbase2_64_avx_body:\n\n\tmov\t$len,%r15\t\t# reassign $len\n\n\tmov\t24($ctx),$r0\t\t# load r\n\tmov\t32($ctx),$s1\n\n\tmov\t0($ctx),$h0\t\t# load hash value\n\tmov\t8($ctx),$h1\n\tmov\t16($ctx),$h2#d\n\n\tmov\t$s1,$r1\n\tmov\t$s1,%rax\n\tshr\t\\$2,$s1\n\tadd\t$r1,$s1\t\t\t# s1 = r1 + (r1 >> 2)\n\n\ttest\t\\$31,$len\n\tjz\t.Linit_avx\n\n\tadd\t0($inp),$h0\t\t# accumulate input\n\tadc\t8($inp),$h1\n\tlea\t16($inp),$inp\n\tadc\t$padbit,$h2\n\tsub\t\\$16,%r15\n\n\tcall\t__poly1305_block\n\n.Linit_avx:\n\t################################# base 2^64 -> base 2^26\n\tmov\t$h0,%rax\n\tmov\t$h0,%rdx\n\tshr\t\\$52,$h0\n\tmov\t$h1,$d1\n\tmov\t$h1,$d2\n\tshr\t\\$26,%rdx\n\tand\t\\$0x3ffffff,%rax\t# h[0]\n\tshl\t\\$12,$d1\n\tand\t\\$0x3ffffff,%rdx\t# h[1]\n\tshr\t\\$14,$h1\n\tor\t$d1,$h0\n\tshl\t\\$24,$h2\n\tand\t\\$0x3ffffff,$h0\t\t# h[2]\n\tshr\t\\$40,$d2\n\tand\t\\$0x3ffffff,$h1\t\t# h[3]\n\tor\t$d2,$h2\t\t\t# h[4]\n\n\tvmovd\t%rax#d,$H0\n\tvmovd\t%rdx#d,$H1\n\tvmovd\t$h0#d,$H2\n\tvmovd\t$h1#d,$H3\n\tvmovd\t$h2#d,$H4\n\tmovl\t\\$1,20($ctx)\t\t# set is_base2_26\n\n\tcall\t__poly1305_init_avx\n\n.Lproceed_avx:\n\tmov\t%r15,$len\n\tpop \t\t%r15\n.cfi_restore\t%r15\n\tpop \t\t%r14\n.cfi_restore\t%r14\n\tpop \t\t%r13\n.cfi_restore\t%r13\n\tpop \t\t%r12\n.cfi_restore\t%r12\n\tpop \t\t%rbx\n.cfi_restore\t%rbx\n\tpop \t\t%rbp\n.cfi_restore\t%rbp\n.Lbase2_64_avx_epilogue:\n\tjmp\t.Ldo_avx\n.cfi_endproc\n\n.align\t32\n.Leven_avx:\n.cfi_startproc\n\tvmovd\t\t4*0($ctx),$H0\t\t# load hash value\n\tvmovd\t\t4*1($ctx),$H1\n\tvmovd\t\t4*2($ctx),$H2\n\tvmovd\t\t4*3($ctx),$H3\n\tvmovd\t\t4*4($ctx),$H4\n\n.Ldo_avx:\n___\n$code.=<<___\tif (!$win64);\n\tlea\t\t8(%rsp),%r10\n.cfi_def_cfa_register\t%r10\n\tand\t\t\\$-32,%rsp\n\tsub\t\t\\$-8,%rsp\n\tlea\t\t-0x58(%rsp),%r11\n\tsub\t\t\\$0x178,%rsp\n___\n$code.=<<___\tif ($win64);\n\tlea\t\t-0xf8(%rsp),%r11\n\tsub\t\t\\$0x218,%rsp\n\tvmovdqa\t\t%xmm6,0x50(%r11)\n\tvmovdqa\t\t%xmm7,0x60(%r11)\n\tvmovdqa\t\t%xmm8,0x70(%r11)\n\tvmovdqa\t\t%xmm9,0x80(%r11)\n\tvmovdqa\t\t%xmm10,0x90(%r11)\n\tvmovdqa\t\t%xmm11,0xa0(%r11)\n\tvmovdqa\t\t%xmm12,0xb0(%r11)\n\tvmovdqa\t\t%xmm13,0xc0(%r11)\n\tvmovdqa\t\t%xmm14,0xd0(%r11)\n\tvmovdqa\t\t%xmm15,0xe0(%r11)\n.Ldo_avx_body:\n___\n$code.=<<___;\n\tsub\t\t\\$64,$len\n\tlea\t\t-32($inp),%rax\n\tcmovc\t\t%rax,$inp\n\n\tvmovdqu\t\t`16*3`($ctx),$D4\t# preload r0^2\n\tlea\t\t`16*3+64`($ctx),$ctx\t# size optimization\n\tlea\t\t.Lconst(%rip),%rcx\n\n\t################################################################\n\t# load input\n\tvmovdqu\t\t16*2($inp),$T0\n\tvmovdqu\t\t16*3($inp),$T1\n\tvmovdqa\t\t64(%rcx),$MASK\t\t# .Lmask26\n\n\tvpsrldq\t\t\\$6,$T0,$T2\t\t# splat input\n\tvpsrldq\t\t\\$6,$T1,$T3\n\tvpunpckhqdq\t$T1,$T0,$T4\t\t# 4\n\tvpunpcklqdq\t$T1,$T0,$T0\t\t# 0:1\n\tvpunpcklqdq\t$T3,$T2,$T3\t\t# 2:3\n\n\tvpsrlq\t\t\\$40,$T4,$T4\t\t# 4\n\tvpsrlq\t\t\\$26,$T0,$T1\n\tvpand\t\t$MASK,$T0,$T0\t\t# 0\n\tvpsrlq\t\t\\$4,$T3,$T2\n\tvpand\t\t$MASK,$T1,$T1\t\t# 1\n\tvpsrlq\t\t\\$30,$T3,$T3\n\tvpand\t\t$MASK,$T2,$T2\t\t# 2\n\tvpand\t\t$MASK,$T3,$T3\t\t# 3\n\tvpor\t\t32(%rcx),$T4,$T4\t# padbit, yes, always\n\n\tjbe\t\t.Lskip_loop_avx\n\n\t# expand and copy pre-calculated table to stack\n\tvmovdqu\t\t`16*1-64`($ctx),$D1\n\tvmovdqu\t\t`16*2-64`($ctx),$D2\n\tvpshufd\t\t\\$0xEE,$D4,$D3\t\t# 34xx -> 3434\n\tvpshufd\t\t\\$0x44,$D4,$D0\t\t# xx12 -> 1212\n\tvmovdqa\t\t$D3,-0x90(%r11)\n\tvmovdqa\t\t$D0,0x00(%rsp)\n\tvpshufd\t\t\\$0xEE,$D1,$D4\n\tvmovdqu\t\t`16*3-64`($ctx),$D0\n\tvpshufd\t\t\\$0x44,$D1,$D1\n\tvmovdqa\t\t$D4,-0x80(%r11)\n\tvmovdqa\t\t$D1,0x10(%rsp)\n\tvpshufd\t\t\\$0xEE,$D2,$D3\n\tvmovdqu\t\t`16*4-64`($ctx),$D1\n\tvpshufd\t\t\\$0x44,$D2,$D2\n\tvmovdqa\t\t$D3,-0x70(%r11)\n\tvmovdqa\t\t$D2,0x20(%rsp)\n\tvpshufd\t\t\\$0xEE,$D0,$D4\n\tvmovdqu\t\t`16*5-64`($ctx),$D2\n\tvpshufd\t\t\\$0x44,$D0,$D0\n\tvmovdqa\t\t$D4,-0x60(%r11)\n\tvmovdqa\t\t$D0,0x30(%rsp)\n\tvpshufd\t\t\\$0xEE,$D1,$D3\n\tvmovdqu\t\t`16*6-64`($ctx),$D0\n\tvpshufd\t\t\\$0x44,$D1,$D1\n\tvmovdqa\t\t$D3,-0x50(%r11)\n\tvmovdqa\t\t$D1,0x40(%rsp)\n\tvpshufd\t\t\\$0xEE,$D2,$D4\n\tvmovdqu\t\t`16*7-64`($ctx),$D1\n\tvpshufd\t\t\\$0x44,$D2,$D2\n\tvmovdqa\t\t$D4,-0x40(%r11)\n\tvmovdqa\t\t$D2,0x50(%rsp)\n\tvpshufd\t\t\\$0xEE,$D0,$D3\n\tvmovdqu\t\t`16*8-64`($ctx),$D2\n\tvpshufd\t\t\\$0x44,$D0,$D0\n\tvmovdqa\t\t$D3,-0x30(%r11)\n\tvmovdqa\t\t$D0,0x60(%rsp)\n\tvpshufd\t\t\\$0xEE,$D1,$D4\n\tvpshufd\t\t\\$0x44,$D1,$D1\n\tvmovdqa\t\t$D4,-0x20(%r11)\n\tvmovdqa\t\t$D1,0x70(%rsp)\n\tvpshufd\t\t\\$0xEE,$D2,$D3\n\t vmovdqa\t0x00(%rsp),$D4\t\t# preload r0^2\n\tvpshufd\t\t\\$0x44,$D2,$D2\n\tvmovdqa\t\t$D3,-0x10(%r11)\n\tvmovdqa\t\t$D2,0x80(%rsp)\n\n\tjmp\t\t.Loop_avx\n\n.align\t32\n.Loop_avx:\n\t################################################################\n\t# ((inp[0]*r^4+inp[2]*r^2+inp[4])*r^4+inp[6]*r^2\n\t# ((inp[1]*r^4+inp[3]*r^2+inp[5])*r^3+inp[7]*r\n\t#   \\___________________/\n\t# ((inp[0]*r^4+inp[2]*r^2+inp[4])*r^4+inp[6]*r^2+inp[8])*r^2\n\t# ((inp[1]*r^4+inp[3]*r^2+inp[5])*r^4+inp[7]*r^2+inp[9])*r\n\t#   \\___________________/ \\____________________/\n\t#\n\t# Note that we start with inp[2:3]*r^2. This is because it\n\t# doesn't depend on reduction in previous iteration.\n\t################################################################\n\t# d4 = h4*r0 + h3*r1   + h2*r2   + h1*r3   + h0*r4\n\t# d3 = h3*r0 + h2*r1   + h1*r2   + h0*r3   + h4*5*r4\n\t# d2 = h2*r0 + h1*r1   + h0*r2   + h4*5*r3 + h3*5*r4\n\t# d1 = h1*r0 + h0*r1   + h4*5*r2 + h3*5*r3 + h2*5*r4\n\t# d0 = h0*r0 + h4*5*r1 + h3*5*r2 + h2*5*r3 + h1*5*r4\n\t#\n\t# though note that $Tx and $Hx are \"reversed\" in this section,\n\t# and $D4 is preloaded with r0^2...\n\n\tvpmuludq\t$T0,$D4,$D0\t\t# d0 = h0*r0\n\tvpmuludq\t$T1,$D4,$D1\t\t# d1 = h1*r0\n\t  vmovdqa\t$H2,0x20(%r11)\t\t\t\t# offload hash\n\tvpmuludq\t$T2,$D4,$D2\t\t# d3 = h2*r0\n\t vmovdqa\t0x10(%rsp),$H2\t\t# r1^2\n\tvpmuludq\t$T3,$D4,$D3\t\t# d3 = h3*r0\n\tvpmuludq\t$T4,$D4,$D4\t\t# d4 = h4*r0\n\n\t  vmovdqa\t$H0,0x00(%r11)\t\t\t\t#\n\tvpmuludq\t0x20(%rsp),$T4,$H0\t# h4*s1\n\t  vmovdqa\t$H1,0x10(%r11)\t\t\t\t#\n\tvpmuludq\t$T3,$H2,$H1\t\t# h3*r1\n\tvpaddq\t\t$H0,$D0,$D0\t\t# d0 += h4*s1\n\tvpaddq\t\t$H1,$D4,$D4\t\t# d4 += h3*r1\n\t  vmovdqa\t$H3,0x30(%r11)\t\t\t\t#\n\tvpmuludq\t$T2,$H2,$H0\t\t# h2*r1\n\tvpmuludq\t$T1,$H2,$H1\t\t# h1*r1\n\tvpaddq\t\t$H0,$D3,$D3\t\t# d3 += h2*r1\n\t vmovdqa\t0x30(%rsp),$H3\t\t# r2^2\n\tvpaddq\t\t$H1,$D2,$D2\t\t# d2 += h1*r1\n\t  vmovdqa\t$H4,0x40(%r11)\t\t\t\t#\n\tvpmuludq\t$T0,$H2,$H2\t\t# h0*r1\n\t vpmuludq\t$T2,$H3,$H0\t\t# h2*r2\n\tvpaddq\t\t$H2,$D1,$D1\t\t# d1 += h0*r1\n\n\t vmovdqa\t0x40(%rsp),$H4\t\t# s2^2\n\tvpaddq\t\t$H0,$D4,$D4\t\t# d4 += h2*r2\n\tvpmuludq\t$T1,$H3,$H1\t\t# h1*r2\n\tvpmuludq\t$T0,$H3,$H3\t\t# h0*r2\n\tvpaddq\t\t$H1,$D3,$D3\t\t# d3 += h1*r2\n\t vmovdqa\t0x50(%rsp),$H2\t\t# r3^2\n\tvpaddq\t\t$H3,$D2,$D2\t\t# d2 += h0*r2\n\tvpmuludq\t$T4,$H4,$H0\t\t# h4*s2\n\tvpmuludq\t$T3,$H4,$H4\t\t# h3*s2\n\tvpaddq\t\t$H0,$D1,$D1\t\t# d1 += h4*s2\n\t vmovdqa\t0x60(%rsp),$H3\t\t# s3^2\n\tvpaddq\t\t$H4,$D0,$D0\t\t# d0 += h3*s2\n\n\t vmovdqa\t0x80(%rsp),$H4\t\t# s4^2\n\tvpmuludq\t$T1,$H2,$H1\t\t# h1*r3\n\tvpmuludq\t$T0,$H2,$H2\t\t# h0*r3\n\tvpaddq\t\t$H1,$D4,$D4\t\t# d4 += h1*r3\n\tvpaddq\t\t$H2,$D3,$D3\t\t# d3 += h0*r3\n\tvpmuludq\t$T4,$H3,$H0\t\t# h4*s3\n\tvpmuludq\t$T3,$H3,$H1\t\t# h3*s3\n\tvpaddq\t\t$H0,$D2,$D2\t\t# d2 += h4*s3\n\t vmovdqu\t16*0($inp),$H0\t\t\t\t# load input\n\tvpaddq\t\t$H1,$D1,$D1\t\t# d1 += h3*s3\n\tvpmuludq\t$T2,$H3,$H3\t\t# h2*s3\n\t vpmuludq\t$T2,$H4,$T2\t\t# h2*s4\n\tvpaddq\t\t$H3,$D0,$D0\t\t# d0 += h2*s3\n\n\t vmovdqu\t16*1($inp),$H1\t\t\t\t#\n\tvpaddq\t\t$T2,$D1,$D1\t\t# d1 += h2*s4\n\tvpmuludq\t$T3,$H4,$T3\t\t# h3*s4\n\tvpmuludq\t$T4,$H4,$T4\t\t# h4*s4\n\t vpsrldq\t\\$6,$H0,$H2\t\t\t\t# splat input\n\tvpaddq\t\t$T3,$D2,$D2\t\t# d2 += h3*s4\n\tvpaddq\t\t$T4,$D3,$D3\t\t# d3 += h4*s4\n\t vpsrldq\t\\$6,$H1,$H3\t\t\t\t#\n\tvpmuludq\t0x70(%rsp),$T0,$T4\t# h0*r4\n\tvpmuludq\t$T1,$H4,$T0\t\t# h1*s4\n\t vpunpckhqdq\t$H1,$H0,$H4\t\t# 4\n\tvpaddq\t\t$T4,$D4,$D4\t\t# d4 += h0*r4\n\t vmovdqa\t-0x90(%r11),$T4\t\t# r0^4\n\tvpaddq\t\t$T0,$D0,$D0\t\t# d0 += h1*s4\n\n\tvpunpcklqdq\t$H1,$H0,$H0\t\t# 0:1\n\tvpunpcklqdq\t$H3,$H2,$H3\t\t# 2:3\n\n\t#vpsrlq\t\t\\$40,$H4,$H4\t\t# 4\n\tvpsrldq\t\t\\$`40/8`,$H4,$H4\t# 4\n\tvpsrlq\t\t\\$26,$H0,$H1\n\tvpand\t\t$MASK,$H0,$H0\t\t# 0\n\tvpsrlq\t\t\\$4,$H3,$H2\n\tvpand\t\t$MASK,$H1,$H1\t\t# 1\n\tvpand\t\t0(%rcx),$H4,$H4\t\t# .Lmask24\n\tvpsrlq\t\t\\$30,$H3,$H3\n\tvpand\t\t$MASK,$H2,$H2\t\t# 2\n\tvpand\t\t$MASK,$H3,$H3\t\t# 3\n\tvpor\t\t32(%rcx),$H4,$H4\t# padbit, yes, always\n\n\tvpaddq\t\t0x00(%r11),$H0,$H0\t# add hash value\n\tvpaddq\t\t0x10(%r11),$H1,$H1\n\tvpaddq\t\t0x20(%r11),$H2,$H2\n\tvpaddq\t\t0x30(%r11),$H3,$H3\n\tvpaddq\t\t0x40(%r11),$H4,$H4\n\n\tlea\t\t16*2($inp),%rax\n\tlea\t\t16*4($inp),$inp\n\tsub\t\t\\$64,$len\n\tcmovc\t\t%rax,$inp\n\n\t################################################################\n\t# Now we accumulate (inp[0:1]+hash)*r^4\n\t################################################################\n\t# d4 = h4*r0 + h3*r1   + h2*r2   + h1*r3   + h0*r4\n\t# d3 = h3*r0 + h2*r1   + h1*r2   + h0*r3   + h4*5*r4\n\t# d2 = h2*r0 + h1*r1   + h0*r2   + h4*5*r3 + h3*5*r4\n\t# d1 = h1*r0 + h0*r1   + h4*5*r2 + h3*5*r3 + h2*5*r4\n\t# d0 = h0*r0 + h4*5*r1 + h3*5*r2 + h2*5*r3 + h1*5*r4\n\n\tvpmuludq\t$H0,$T4,$T0\t\t# h0*r0\n\tvpmuludq\t$H1,$T4,$T1\t\t# h1*r0\n\tvpaddq\t\t$T0,$D0,$D0\n\tvpaddq\t\t$T1,$D1,$D1\n\t vmovdqa\t-0x80(%r11),$T2\t\t# r1^4\n\tvpmuludq\t$H2,$T4,$T0\t\t# h2*r0\n\tvpmuludq\t$H3,$T4,$T1\t\t# h3*r0\n\tvpaddq\t\t$T0,$D2,$D2\n\tvpaddq\t\t$T1,$D3,$D3\n\tvpmuludq\t$H4,$T4,$T4\t\t# h4*r0\n\t vpmuludq\t-0x70(%r11),$H4,$T0\t# h4*s1\n\tvpaddq\t\t$T4,$D4,$D4\n\n\tvpaddq\t\t$T0,$D0,$D0\t\t# d0 += h4*s1\n\tvpmuludq\t$H2,$T2,$T1\t\t# h2*r1\n\tvpmuludq\t$H3,$T2,$T0\t\t# h3*r1\n\tvpaddq\t\t$T1,$D3,$D3\t\t# d3 += h2*r1\n\t vmovdqa\t-0x60(%r11),$T3\t\t# r2^4\n\tvpaddq\t\t$T0,$D4,$D4\t\t# d4 += h3*r1\n\tvpmuludq\t$H1,$T2,$T1\t\t# h1*r1\n\tvpmuludq\t$H0,$T2,$T2\t\t# h0*r1\n\tvpaddq\t\t$T1,$D2,$D2\t\t# d2 += h1*r1\n\tvpaddq\t\t$T2,$D1,$D1\t\t# d1 += h0*r1\n\n\t vmovdqa\t-0x50(%r11),$T4\t\t# s2^4\n\tvpmuludq\t$H2,$T3,$T0\t\t# h2*r2\n\tvpmuludq\t$H1,$T3,$T1\t\t# h1*r2\n\tvpaddq\t\t$T0,$D4,$D4\t\t# d4 += h2*r2\n\tvpaddq\t\t$T1,$D3,$D3\t\t# d3 += h1*r2\n\t vmovdqa\t-0x40(%r11),$T2\t\t# r3^4\n\tvpmuludq\t$H0,$T3,$T3\t\t# h0*r2\n\tvpmuludq\t$H4,$T4,$T0\t\t# h4*s2\n\tvpaddq\t\t$T3,$D2,$D2\t\t# d2 += h0*r2\n\tvpaddq\t\t$T0,$D1,$D1\t\t# d1 += h4*s2\n\t vmovdqa\t-0x30(%r11),$T3\t\t# s3^4\n\tvpmuludq\t$H3,$T4,$T4\t\t# h3*s2\n\t vpmuludq\t$H1,$T2,$T1\t\t# h1*r3\n\tvpaddq\t\t$T4,$D0,$D0\t\t# d0 += h3*s2\n\n\t vmovdqa\t-0x10(%r11),$T4\t\t# s4^4\n\tvpaddq\t\t$T1,$D4,$D4\t\t# d4 += h1*r3\n\tvpmuludq\t$H0,$T2,$T2\t\t# h0*r3\n\tvpmuludq\t$H4,$T3,$T0\t\t# h4*s3\n\tvpaddq\t\t$T2,$D3,$D3\t\t# d3 += h0*r3\n\tvpaddq\t\t$T0,$D2,$D2\t\t# d2 += h4*s3\n\t vmovdqu\t16*2($inp),$T0\t\t\t\t# load input\n\tvpmuludq\t$H3,$T3,$T2\t\t# h3*s3\n\tvpmuludq\t$H2,$T3,$T3\t\t# h2*s3\n\tvpaddq\t\t$T2,$D1,$D1\t\t# d1 += h3*s3\n\t vmovdqu\t16*3($inp),$T1\t\t\t\t#\n\tvpaddq\t\t$T3,$D0,$D0\t\t# d0 += h2*s3\n\n\tvpmuludq\t$H2,$T4,$H2\t\t# h2*s4\n\tvpmuludq\t$H3,$T4,$H3\t\t# h3*s4\n\t vpsrldq\t\\$6,$T0,$T2\t\t\t\t# splat input\n\tvpaddq\t\t$H2,$D1,$D1\t\t# d1 += h2*s4\n\tvpmuludq\t$H4,$T4,$H4\t\t# h4*s4\n\t vpsrldq\t\\$6,$T1,$T3\t\t\t\t#\n\tvpaddq\t\t$H3,$D2,$H2\t\t# h2 = d2 + h3*s4\n\tvpaddq\t\t$H4,$D3,$H3\t\t# h3 = d3 + h4*s4\n\tvpmuludq\t-0x20(%r11),$H0,$H4\t# h0*r4\n\tvpmuludq\t$H1,$T4,$H0\n\t vpunpckhqdq\t$T1,$T0,$T4\t\t# 4\n\tvpaddq\t\t$H4,$D4,$H4\t\t# h4 = d4 + h0*r4\n\tvpaddq\t\t$H0,$D0,$H0\t\t# h0 = d0 + h1*s4\n\n\tvpunpcklqdq\t$T1,$T0,$T0\t\t# 0:1\n\tvpunpcklqdq\t$T3,$T2,$T3\t\t# 2:3\n\n\t#vpsrlq\t\t\\$40,$T4,$T4\t\t# 4\n\tvpsrldq\t\t\\$`40/8`,$T4,$T4\t# 4\n\tvpsrlq\t\t\\$26,$T0,$T1\n\t vmovdqa\t0x00(%rsp),$D4\t\t# preload r0^2\n\tvpand\t\t$MASK,$T0,$T0\t\t# 0\n\tvpsrlq\t\t\\$4,$T3,$T2\n\tvpand\t\t$MASK,$T1,$T1\t\t# 1\n\tvpand\t\t0(%rcx),$T4,$T4\t\t# .Lmask24\n\tvpsrlq\t\t\\$30,$T3,$T3\n\tvpand\t\t$MASK,$T2,$T2\t\t# 2\n\tvpand\t\t$MASK,$T3,$T3\t\t# 3\n\tvpor\t\t32(%rcx),$T4,$T4\t# padbit, yes, always\n\n\t################################################################\n\t# lazy reduction as discussed in \"NEON crypto\" by D.J. Bernstein\n\t# and P. Schwabe\n\n\tvpsrlq\t\t\\$26,$H3,$D3\n\tvpand\t\t$MASK,$H3,$H3\n\tvpaddq\t\t$D3,$H4,$H4\t\t# h3 -> h4\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpand\t\t$MASK,$H0,$H0\n\tvpaddq\t\t$D0,$D1,$H1\t\t# h0 -> h1\n\n\tvpsrlq\t\t\\$26,$H4,$D0\n\tvpand\t\t$MASK,$H4,$H4\n\n\tvpsrlq\t\t\\$26,$H1,$D1\n\tvpand\t\t$MASK,$H1,$H1\n\tvpaddq\t\t$D1,$H2,$H2\t\t# h1 -> h2\n\n\tvpaddq\t\t$D0,$H0,$H0\n\tvpsllq\t\t\\$2,$D0,$D0\n\tvpaddq\t\t$D0,$H0,$H0\t\t# h4 -> h0\n\n\tvpsrlq\t\t\\$26,$H2,$D2\n\tvpand\t\t$MASK,$H2,$H2\n\tvpaddq\t\t$D2,$H3,$H3\t\t# h2 -> h3\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpand\t\t$MASK,$H0,$H0\n\tvpaddq\t\t$D0,$H1,$H1\t\t# h0 -> h1\n\n\tvpsrlq\t\t\\$26,$H3,$D3\n\tvpand\t\t$MASK,$H3,$H3\n\tvpaddq\t\t$D3,$H4,$H4\t\t# h3 -> h4\n\n\tja\t\t.Loop_avx\n\n.Lskip_loop_avx:\n\t################################################################\n\t# multiply (inp[0:1]+hash) or inp[2:3] by r^2:r^1\n\n\tvpshufd\t\t\\$0x10,$D4,$D4\t\t# r0^n, xx12 -> x1x2\n\tadd\t\t\\$32,$len\n\tjnz\t\t.Long_tail_avx\n\n\tvpaddq\t\t$H2,$T2,$T2\n\tvpaddq\t\t$H0,$T0,$T0\n\tvpaddq\t\t$H1,$T1,$T1\n\tvpaddq\t\t$H3,$T3,$T3\n\tvpaddq\t\t$H4,$T4,$T4\n\n.Long_tail_avx:\n\tvmovdqa\t\t$H2,0x20(%r11)\n\tvmovdqa\t\t$H0,0x00(%r11)\n\tvmovdqa\t\t$H1,0x10(%r11)\n\tvmovdqa\t\t$H3,0x30(%r11)\n\tvmovdqa\t\t$H4,0x40(%r11)\n\n\t# d4 = h4*r0 + h3*r1   + h2*r2   + h1*r3   + h0*r4\n\t# d3 = h3*r0 + h2*r1   + h1*r2   + h0*r3   + h4*5*r4\n\t# d2 = h2*r0 + h1*r1   + h0*r2   + h4*5*r3 + h3*5*r4\n\t# d1 = h1*r0 + h0*r1   + h4*5*r2 + h3*5*r3 + h2*5*r4\n\t# d0 = h0*r0 + h4*5*r1 + h3*5*r2 + h2*5*r3 + h1*5*r4\n\n\tvpmuludq\t$T2,$D4,$D2\t\t# d2 = h2*r0\n\tvpmuludq\t$T0,$D4,$D0\t\t# d0 = h0*r0\n\t vpshufd\t\\$0x10,`16*1-64`($ctx),$H2\t\t# r1^n\n\tvpmuludq\t$T1,$D4,$D1\t\t# d1 = h1*r0\n\tvpmuludq\t$T3,$D4,$D3\t\t# d3 = h3*r0\n\tvpmuludq\t$T4,$D4,$D4\t\t# d4 = h4*r0\n\n\tvpmuludq\t$T3,$H2,$H0\t\t# h3*r1\n\tvpaddq\t\t$H0,$D4,$D4\t\t# d4 += h3*r1\n\t vpshufd\t\\$0x10,`16*2-64`($ctx),$H3\t\t# s1^n\n\tvpmuludq\t$T2,$H2,$H1\t\t# h2*r1\n\tvpaddq\t\t$H1,$D3,$D3\t\t# d3 += h2*r1\n\t vpshufd\t\\$0x10,`16*3-64`($ctx),$H4\t\t# r2^n\n\tvpmuludq\t$T1,$H2,$H0\t\t# h1*r1\n\tvpaddq\t\t$H0,$D2,$D2\t\t# d2 += h1*r1\n\tvpmuludq\t$T0,$H2,$H2\t\t# h0*r1\n\tvpaddq\t\t$H2,$D1,$D1\t\t# d1 += h0*r1\n\tvpmuludq\t$T4,$H3,$H3\t\t# h4*s1\n\tvpaddq\t\t$H3,$D0,$D0\t\t# d0 += h4*s1\n\n\t vpshufd\t\\$0x10,`16*4-64`($ctx),$H2\t\t# s2^n\n\tvpmuludq\t$T2,$H4,$H1\t\t# h2*r2\n\tvpaddq\t\t$H1,$D4,$D4\t\t# d4 += h2*r2\n\tvpmuludq\t$T1,$H4,$H0\t\t# h1*r2\n\tvpaddq\t\t$H0,$D3,$D3\t\t# d3 += h1*r2\n\t vpshufd\t\\$0x10,`16*5-64`($ctx),$H3\t\t# r3^n\n\tvpmuludq\t$T0,$H4,$H4\t\t# h0*r2\n\tvpaddq\t\t$H4,$D2,$D2\t\t# d2 += h0*r2\n\tvpmuludq\t$T4,$H2,$H1\t\t# h4*s2\n\tvpaddq\t\t$H1,$D1,$D1\t\t# d1 += h4*s2\n\t vpshufd\t\\$0x10,`16*6-64`($ctx),$H4\t\t# s3^n\n\tvpmuludq\t$T3,$H2,$H2\t\t# h3*s2\n\tvpaddq\t\t$H2,$D0,$D0\t\t# d0 += h3*s2\n\n\tvpmuludq\t$T1,$H3,$H0\t\t# h1*r3\n\tvpaddq\t\t$H0,$D4,$D4\t\t# d4 += h1*r3\n\tvpmuludq\t$T0,$H3,$H3\t\t# h0*r3\n\tvpaddq\t\t$H3,$D3,$D3\t\t# d3 += h0*r3\n\t vpshufd\t\\$0x10,`16*7-64`($ctx),$H2\t\t# r4^n\n\tvpmuludq\t$T4,$H4,$H1\t\t# h4*s3\n\tvpaddq\t\t$H1,$D2,$D2\t\t# d2 += h4*s3\n\t vpshufd\t\\$0x10,`16*8-64`($ctx),$H3\t\t# s4^n\n\tvpmuludq\t$T3,$H4,$H0\t\t# h3*s3\n\tvpaddq\t\t$H0,$D1,$D1\t\t# d1 += h3*s3\n\tvpmuludq\t$T2,$H4,$H4\t\t# h2*s3\n\tvpaddq\t\t$H4,$D0,$D0\t\t# d0 += h2*s3\n\n\tvpmuludq\t$T0,$H2,$H2\t\t# h0*r4\n\tvpaddq\t\t$H2,$D4,$D4\t\t# h4 = d4 + h0*r4\n\tvpmuludq\t$T4,$H3,$H1\t\t# h4*s4\n\tvpaddq\t\t$H1,$D3,$D3\t\t# h3 = d3 + h4*s4\n\tvpmuludq\t$T3,$H3,$H0\t\t# h3*s4\n\tvpaddq\t\t$H0,$D2,$D2\t\t# h2 = d2 + h3*s4\n\tvpmuludq\t$T2,$H3,$H1\t\t# h2*s4\n\tvpaddq\t\t$H1,$D1,$D1\t\t# h1 = d1 + h2*s4\n\tvpmuludq\t$T1,$H3,$H3\t\t# h1*s4\n\tvpaddq\t\t$H3,$D0,$D0\t\t# h0 = d0 + h1*s4\n\n\tjz\t\t.Lshort_tail_avx\n\n\tvmovdqu\t\t16*0($inp),$H0\t\t# load input\n\tvmovdqu\t\t16*1($inp),$H1\n\n\tvpsrldq\t\t\\$6,$H0,$H2\t\t# splat input\n\tvpsrldq\t\t\\$6,$H1,$H3\n\tvpunpckhqdq\t$H1,$H0,$H4\t\t# 4\n\tvpunpcklqdq\t$H1,$H0,$H0\t\t# 0:1\n\tvpunpcklqdq\t$H3,$H2,$H3\t\t# 2:3\n\n\tvpsrlq\t\t\\$40,$H4,$H4\t\t# 4\n\tvpsrlq\t\t\\$26,$H0,$H1\n\tvpand\t\t$MASK,$H0,$H0\t\t# 0\n\tvpsrlq\t\t\\$4,$H3,$H2\n\tvpand\t\t$MASK,$H1,$H1\t\t# 1\n\tvpsrlq\t\t\\$30,$H3,$H3\n\tvpand\t\t$MASK,$H2,$H2\t\t# 2\n\tvpand\t\t$MASK,$H3,$H3\t\t# 3\n\tvpor\t\t32(%rcx),$H4,$H4\t# padbit, yes, always\n\n\tvpshufd\t\t\\$0x32,`16*0-64`($ctx),$T4\t# r0^n, 34xx -> x3x4\n\tvpaddq\t\t0x00(%r11),$H0,$H0\n\tvpaddq\t\t0x10(%r11),$H1,$H1\n\tvpaddq\t\t0x20(%r11),$H2,$H2\n\tvpaddq\t\t0x30(%r11),$H3,$H3\n\tvpaddq\t\t0x40(%r11),$H4,$H4\n\n\t################################################################\n\t# multiply (inp[0:1]+hash) by r^4:r^3 and accumulate\n\n\tvpmuludq\t$H0,$T4,$T0\t\t# h0*r0\n\tvpaddq\t\t$T0,$D0,$D0\t\t# d0 += h0*r0\n\tvpmuludq\t$H1,$T4,$T1\t\t# h1*r0\n\tvpaddq\t\t$T1,$D1,$D1\t\t# d1 += h1*r0\n\tvpmuludq\t$H2,$T4,$T0\t\t# h2*r0\n\tvpaddq\t\t$T0,$D2,$D2\t\t# d2 += h2*r0\n\t vpshufd\t\\$0x32,`16*1-64`($ctx),$T2\t\t# r1^n\n\tvpmuludq\t$H3,$T4,$T1\t\t# h3*r0\n\tvpaddq\t\t$T1,$D3,$D3\t\t# d3 += h3*r0\n\tvpmuludq\t$H4,$T4,$T4\t\t# h4*r0\n\tvpaddq\t\t$T4,$D4,$D4\t\t# d4 += h4*r0\n\n\tvpmuludq\t$H3,$T2,$T0\t\t# h3*r1\n\tvpaddq\t\t$T0,$D4,$D4\t\t# d4 += h3*r1\n\t vpshufd\t\\$0x32,`16*2-64`($ctx),$T3\t\t# s1\n\tvpmuludq\t$H2,$T2,$T1\t\t# h2*r1\n\tvpaddq\t\t$T1,$D3,$D3\t\t# d3 += h2*r1\n\t vpshufd\t\\$0x32,`16*3-64`($ctx),$T4\t\t# r2\n\tvpmuludq\t$H1,$T2,$T0\t\t# h1*r1\n\tvpaddq\t\t$T0,$D2,$D2\t\t# d2 += h1*r1\n\tvpmuludq\t$H0,$T2,$T2\t\t# h0*r1\n\tvpaddq\t\t$T2,$D1,$D1\t\t# d1 += h0*r1\n\tvpmuludq\t$H4,$T3,$T3\t\t# h4*s1\n\tvpaddq\t\t$T3,$D0,$D0\t\t# d0 += h4*s1\n\n\t vpshufd\t\\$0x32,`16*4-64`($ctx),$T2\t\t# s2\n\tvpmuludq\t$H2,$T4,$T1\t\t# h2*r2\n\tvpaddq\t\t$T1,$D4,$D4\t\t# d4 += h2*r2\n\tvpmuludq\t$H1,$T4,$T0\t\t# h1*r2\n\tvpaddq\t\t$T0,$D3,$D3\t\t# d3 += h1*r2\n\t vpshufd\t\\$0x32,`16*5-64`($ctx),$T3\t\t# r3\n\tvpmuludq\t$H0,$T4,$T4\t\t# h0*r2\n\tvpaddq\t\t$T4,$D2,$D2\t\t# d2 += h0*r2\n\tvpmuludq\t$H4,$T2,$T1\t\t# h4*s2\n\tvpaddq\t\t$T1,$D1,$D1\t\t# d1 += h4*s2\n\t vpshufd\t\\$0x32,`16*6-64`($ctx),$T4\t\t# s3\n\tvpmuludq\t$H3,$T2,$T2\t\t# h3*s2\n\tvpaddq\t\t$T2,$D0,$D0\t\t# d0 += h3*s2\n\n\tvpmuludq\t$H1,$T3,$T0\t\t# h1*r3\n\tvpaddq\t\t$T0,$D4,$D4\t\t# d4 += h1*r3\n\tvpmuludq\t$H0,$T3,$T3\t\t# h0*r3\n\tvpaddq\t\t$T3,$D3,$D3\t\t# d3 += h0*r3\n\t vpshufd\t\\$0x32,`16*7-64`($ctx),$T2\t\t# r4\n\tvpmuludq\t$H4,$T4,$T1\t\t# h4*s3\n\tvpaddq\t\t$T1,$D2,$D2\t\t# d2 += h4*s3\n\t vpshufd\t\\$0x32,`16*8-64`($ctx),$T3\t\t# s4\n\tvpmuludq\t$H3,$T4,$T0\t\t# h3*s3\n\tvpaddq\t\t$T0,$D1,$D1\t\t# d1 += h3*s3\n\tvpmuludq\t$H2,$T4,$T4\t\t# h2*s3\n\tvpaddq\t\t$T4,$D0,$D0\t\t# d0 += h2*s3\n\n\tvpmuludq\t$H0,$T2,$T2\t\t# h0*r4\n\tvpaddq\t\t$T2,$D4,$D4\t\t# d4 += h0*r4\n\tvpmuludq\t$H4,$T3,$T1\t\t# h4*s4\n\tvpaddq\t\t$T1,$D3,$D3\t\t# d3 += h4*s4\n\tvpmuludq\t$H3,$T3,$T0\t\t# h3*s4\n\tvpaddq\t\t$T0,$D2,$D2\t\t# d2 += h3*s4\n\tvpmuludq\t$H2,$T3,$T1\t\t# h2*s4\n\tvpaddq\t\t$T1,$D1,$D1\t\t# d1 += h2*s4\n\tvpmuludq\t$H1,$T3,$T3\t\t# h1*s4\n\tvpaddq\t\t$T3,$D0,$D0\t\t# d0 += h1*s4\n\n.Lshort_tail_avx:\n\t################################################################\n\t# horizontal addition\n\n\tvpsrldq\t\t\\$8,$D4,$T4\n\tvpsrldq\t\t\\$8,$D3,$T3\n\tvpsrldq\t\t\\$8,$D1,$T1\n\tvpsrldq\t\t\\$8,$D0,$T0\n\tvpsrldq\t\t\\$8,$D2,$T2\n\tvpaddq\t\t$T3,$D3,$D3\n\tvpaddq\t\t$T4,$D4,$D4\n\tvpaddq\t\t$T0,$D0,$D0\n\tvpaddq\t\t$T1,$D1,$D1\n\tvpaddq\t\t$T2,$D2,$D2\n\n\t################################################################\n\t# lazy reduction\n\n\tvpsrlq\t\t\\$26,$D3,$H3\n\tvpand\t\t$MASK,$D3,$D3\n\tvpaddq\t\t$H3,$D4,$D4\t\t# h3 -> h4\n\n\tvpsrlq\t\t\\$26,$D0,$H0\n\tvpand\t\t$MASK,$D0,$D0\n\tvpaddq\t\t$H0,$D1,$D1\t\t# h0 -> h1\n\n\tvpsrlq\t\t\\$26,$D4,$H4\n\tvpand\t\t$MASK,$D4,$D4\n\n\tvpsrlq\t\t\\$26,$D1,$H1\n\tvpand\t\t$MASK,$D1,$D1\n\tvpaddq\t\t$H1,$D2,$D2\t\t# h1 -> h2\n\n\tvpaddq\t\t$H4,$D0,$D0\n\tvpsllq\t\t\\$2,$H4,$H4\n\tvpaddq\t\t$H4,$D0,$D0\t\t# h4 -> h0\n\n\tvpsrlq\t\t\\$26,$D2,$H2\n\tvpand\t\t$MASK,$D2,$D2\n\tvpaddq\t\t$H2,$D3,$D3\t\t# h2 -> h3\n\n\tvpsrlq\t\t\\$26,$D0,$H0\n\tvpand\t\t$MASK,$D0,$D0\n\tvpaddq\t\t$H0,$D1,$D1\t\t# h0 -> h1\n\n\tvpsrlq\t\t\\$26,$D3,$H3\n\tvpand\t\t$MASK,$D3,$D3\n\tvpaddq\t\t$H3,$D4,$D4\t\t# h3 -> h4\n\n\tvmovd\t\t$D0,`4*0-48-64`($ctx)\t# save partially reduced\n\tvmovd\t\t$D1,`4*1-48-64`($ctx)\n\tvmovd\t\t$D2,`4*2-48-64`($ctx)\n\tvmovd\t\t$D3,`4*3-48-64`($ctx)\n\tvmovd\t\t$D4,`4*4-48-64`($ctx)\n___\n$code.=<<___\tif ($win64);\n\tvmovdqa\t\t0x50(%r11),%xmm6\n\tvmovdqa\t\t0x60(%r11),%xmm7\n\tvmovdqa\t\t0x70(%r11),%xmm8\n\tvmovdqa\t\t0x80(%r11),%xmm9\n\tvmovdqa\t\t0x90(%r11),%xmm10\n\tvmovdqa\t\t0xa0(%r11),%xmm11\n\tvmovdqa\t\t0xb0(%r11),%xmm12\n\tvmovdqa\t\t0xc0(%r11),%xmm13\n\tvmovdqa\t\t0xd0(%r11),%xmm14\n\tvmovdqa\t\t0xe0(%r11),%xmm15\n\tlea\t\t0xf8(%r11),%rsp\n.Ldo_avx_epilogue:\n___\n$code.=<<___\tif (!$win64);\n\tlea\t\t-8(%r10),%rsp\n.cfi_def_cfa_register\t%rsp\n___\n$code.=<<___;\n\tvzeroupper\n\tRET\n.cfi_endproc\n___\n&end_function(\"poly1305_blocks_avx\");\n\n&declare_function(\"poly1305_emit_avx\", 32, 3);\n$code.=<<___;\n\tcmpl\t\\$0,20($ctx)\t# is_base2_26?\n\tje\t.Lemit\n\n\tmov\t0($ctx),%eax\t# load hash value base 2^26\n\tmov\t4($ctx),%ecx\n\tmov\t8($ctx),%r8d\n\tmov\t12($ctx),%r11d\n\tmov\t16($ctx),%r10d\n\n\tshl\t\\$26,%rcx\t# base 2^26 -> base 2^64\n\tmov\t%r8,%r9\n\tshl\t\\$52,%r8\n\tadd\t%rcx,%rax\n\tshr\t\\$12,%r9\n\tadd\t%rax,%r8\t# h0\n\tadc\t\\$0,%r9\n\n\tshl\t\\$14,%r11\n\tmov\t%r10,%rax\n\tshr\t\\$24,%r10\n\tadd\t%r11,%r9\n\tshl\t\\$40,%rax\n\tadd\t%rax,%r9\t# h1\n\tadc\t\\$0,%r10\t# h2\n\n\tmov\t%r10,%rax\t# could be partially reduced, so reduce\n\tmov\t%r10,%rcx\n\tand\t\\$3,%r10\n\tshr\t\\$2,%rax\n\tand\t\\$-4,%rcx\n\tadd\t%rcx,%rax\n\tadd\t%rax,%r8\n\tadc\t\\$0,%r9\n\tadc\t\\$0,%r10\n\n\tmov\t%r8,%rax\n\tadd\t\\$5,%r8\t\t# compare to modulus\n\tmov\t%r9,%rcx\n\tadc\t\\$0,%r9\n\tadc\t\\$0,%r10\n\tshr\t\\$2,%r10\t# did 130-bit value overflow?\n\tcmovnz\t%r8,%rax\n\tcmovnz\t%r9,%rcx\n\n\tadd\t0($nonce),%rax\t# accumulate nonce\n\tadc\t8($nonce),%rcx\n\tmov\t%rax,0($mac)\t# write result\n\tmov\t%rcx,8($mac)\n\n\tRET\n___\n&end_function(\"poly1305_emit_avx\");\n\nif ($avx>1) {\n\nmy ($H0,$H1,$H2,$H3,$H4, $MASK, $T4,$T0,$T1,$T2,$T3, $D0,$D1,$D2,$D3,$D4) =\n    map(\"%ymm$_\",(0..15));\nmy $S4=$MASK;\n\nsub poly1305_blocks_avxN {\n\tmy ($avx512) = @_;\n\tmy $suffix = $avx512 ? \"_avx512\" : \"\";\n$code.=<<___;\n.cfi_startproc\n\tmov\t20($ctx),%r8d\t\t# is_base2_26\n\tcmp\t\\$128,$len\n\tjae\t.Lblocks_avx2$suffix\n\ttest\t%r8d,%r8d\n\tjz\t.Lblocks\n\n.Lblocks_avx2$suffix:\n\tand\t\\$-16,$len\n\tjz\t.Lno_data_avx2$suffix\n\n\tvzeroupper\n\n\ttest\t%r8d,%r8d\n\tjz\t.Lbase2_64_avx2$suffix\n\n\ttest\t\\$63,$len\n\tjz\t.Leven_avx2$suffix\n\n\tpush\t%rbp\n.cfi_push\t%rbp\n\tmov \t%rsp,%rbp\n\tpush\t%rbx\n.cfi_push\t%rbx\n\tpush\t%r12\n.cfi_push\t%r12\n\tpush\t%r13\n.cfi_push\t%r13\n\tpush\t%r14\n.cfi_push\t%r14\n\tpush\t%r15\n.cfi_push\t%r15\n.Lblocks_avx2_body$suffix:\n\n\tmov\t$len,%r15\t\t# reassign $len\n\n\tmov\t0($ctx),$d1\t\t# load hash value\n\tmov\t8($ctx),$d2\n\tmov\t16($ctx),$h2#d\n\n\tmov\t24($ctx),$r0\t\t# load r\n\tmov\t32($ctx),$s1\n\n\t################################# base 2^26 -> base 2^64\n\tmov\t$d1#d,$h0#d\n\tand\t\\$`-1*(1<<31)`,$d1\n\tmov\t$d2,$r1\t\t\t# borrow $r1\n\tmov\t$d2#d,$h1#d\n\tand\t\\$`-1*(1<<31)`,$d2\n\n\tshr\t\\$6,$d1\n\tshl\t\\$52,$r1\n\tadd\t$d1,$h0\n\tshr\t\\$12,$h1\n\tshr\t\\$18,$d2\n\tadd\t$r1,$h0\n\tadc\t$d2,$h1\n\n\tmov\t$h2,$d1\n\tshl\t\\$40,$d1\n\tshr\t\\$24,$h2\n\tadd\t$d1,$h1\n\tadc\t\\$0,$h2\t\t\t# can be partially reduced...\n\n\tmov\t\\$-4,$d2\t\t# ... so reduce\n\tmov\t$h2,$d1\n\tand\t$h2,$d2\n\tshr\t\\$2,$d1\n\tand\t\\$3,$h2\n\tadd\t$d2,$d1\t\t\t# =*5\n\tadd\t$d1,$h0\n\tadc\t\\$0,$h1\n\tadc\t\\$0,$h2\n\n\tmov\t$s1,$r1\n\tmov\t$s1,%rax\n\tshr\t\\$2,$s1\n\tadd\t$r1,$s1\t\t\t# s1 = r1 + (r1 >> 2)\n\n.Lbase2_26_pre_avx2$suffix:\n\tadd\t0($inp),$h0\t\t# accumulate input\n\tadc\t8($inp),$h1\n\tlea\t16($inp),$inp\n\tadc\t$padbit,$h2\n\tsub\t\\$16,%r15\n\n\tcall\t__poly1305_block\n\tmov\t$r1,%rax\n\n\ttest\t\\$63,%r15\n\tjnz\t.Lbase2_26_pre_avx2$suffix\n\n\ttest\t$padbit,$padbit\t\t# if $padbit is zero,\n\tjz\t.Lstore_base2_64_avx2$suffix\t# store hash in base 2^64 format\n\n\t################################# base 2^64 -> base 2^26\n\tmov\t$h0,%rax\n\tmov\t$h0,%rdx\n\tshr\t\\$52,$h0\n\tmov\t$h1,$r0\n\tmov\t$h1,$r1\n\tshr\t\\$26,%rdx\n\tand\t\\$0x3ffffff,%rax\t# h[0]\n\tshl\t\\$12,$r0\n\tand\t\\$0x3ffffff,%rdx\t# h[1]\n\tshr\t\\$14,$h1\n\tor\t$r0,$h0\n\tshl\t\\$24,$h2\n\tand\t\\$0x3ffffff,$h0\t\t# h[2]\n\tshr\t\\$40,$r1\n\tand\t\\$0x3ffffff,$h1\t\t# h[3]\n\tor\t$r1,$h2\t\t\t# h[4]\n\n\ttest\t%r15,%r15\n\tjz\t.Lstore_base2_26_avx2$suffix\n\n\tvmovd\t%rax#d,%x#$H0\n\tvmovd\t%rdx#d,%x#$H1\n\tvmovd\t$h0#d,%x#$H2\n\tvmovd\t$h1#d,%x#$H3\n\tvmovd\t$h2#d,%x#$H4\n\tjmp\t.Lproceed_avx2$suffix\n\n.align\t32\n.Lstore_base2_64_avx2$suffix:\n\tmov\t$h0,0($ctx)\n\tmov\t$h1,8($ctx)\n\tmov\t$h2,16($ctx)\t\t# note that is_base2_26 is zeroed\n\tjmp\t.Ldone_avx2$suffix\n\n.align\t16\n.Lstore_base2_26_avx2$suffix:\n\tmov\t%rax#d,0($ctx)\t\t# store hash value base 2^26\n\tmov\t%rdx#d,4($ctx)\n\tmov\t$h0#d,8($ctx)\n\tmov\t$h1#d,12($ctx)\n\tmov\t$h2#d,16($ctx)\n.align\t16\n.Ldone_avx2$suffix:\n\tpop \t\t%r15\n.cfi_restore\t%r15\n\tpop \t\t%r14\n.cfi_restore\t%r14\n\tpop \t\t%r13\n.cfi_restore\t%r13\n\tpop \t\t%r12\n.cfi_restore\t%r12\n\tpop \t\t%rbx\n.cfi_restore\t%rbx\n\tpop \t\t%rbp\n.cfi_restore \t%rbp\n.Lno_data_avx2$suffix:\n.Lblocks_avx2_epilogue$suffix:\n\tRET\n.cfi_endproc\n\n.align\t32\n.Lbase2_64_avx2$suffix:\n.cfi_startproc\n\tpush\t%rbp\n.cfi_push\t%rbp\n\tmov \t%rsp,%rbp\n\tpush\t%rbx\n.cfi_push\t%rbx\n\tpush\t%r12\n.cfi_push\t%r12\n\tpush\t%r13\n.cfi_push\t%r13\n\tpush\t%r14\n.cfi_push\t%r14\n\tpush\t%r15\n.cfi_push\t%r15\n.Lbase2_64_avx2_body$suffix:\n\n\tmov\t$len,%r15\t\t# reassign $len\n\n\tmov\t24($ctx),$r0\t\t# load r\n\tmov\t32($ctx),$s1\n\n\tmov\t0($ctx),$h0\t\t# load hash value\n\tmov\t8($ctx),$h1\n\tmov\t16($ctx),$h2#d\n\n\tmov\t$s1,$r1\n\tmov\t$s1,%rax\n\tshr\t\\$2,$s1\n\tadd\t$r1,$s1\t\t\t# s1 = r1 + (r1 >> 2)\n\n\ttest\t\\$63,$len\n\tjz\t.Linit_avx2$suffix\n\n.Lbase2_64_pre_avx2$suffix:\n\tadd\t0($inp),$h0\t\t# accumulate input\n\tadc\t8($inp),$h1\n\tlea\t16($inp),$inp\n\tadc\t$padbit,$h2\n\tsub\t\\$16,%r15\n\n\tcall\t__poly1305_block\n\tmov\t$r1,%rax\n\n\ttest\t\\$63,%r15\n\tjnz\t.Lbase2_64_pre_avx2$suffix\n\n.Linit_avx2$suffix:\n\t################################# base 2^64 -> base 2^26\n\tmov\t$h0,%rax\n\tmov\t$h0,%rdx\n\tshr\t\\$52,$h0\n\tmov\t$h1,$d1\n\tmov\t$h1,$d2\n\tshr\t\\$26,%rdx\n\tand\t\\$0x3ffffff,%rax\t# h[0]\n\tshl\t\\$12,$d1\n\tand\t\\$0x3ffffff,%rdx\t# h[1]\n\tshr\t\\$14,$h1\n\tor\t$d1,$h0\n\tshl\t\\$24,$h2\n\tand\t\\$0x3ffffff,$h0\t\t# h[2]\n\tshr\t\\$40,$d2\n\tand\t\\$0x3ffffff,$h1\t\t# h[3]\n\tor\t$d2,$h2\t\t\t# h[4]\n\n\tvmovd\t%rax#d,%x#$H0\n\tvmovd\t%rdx#d,%x#$H1\n\tvmovd\t$h0#d,%x#$H2\n\tvmovd\t$h1#d,%x#$H3\n\tvmovd\t$h2#d,%x#$H4\n\tmovl\t\\$1,20($ctx)\t\t# set is_base2_26\n\n\tcall\t__poly1305_init_avx\n\n.Lproceed_avx2$suffix:\n\tmov\t%r15,$len\t\t\t# restore $len\n___\n$code.=<<___ if (!$kernel);\n\tmov\tOPENSSL_ia32cap_P+8(%rip),%r9d\n\tmov\t\\$`(1<<31|1<<30|1<<16)`,%r11d\n___\n$code.=<<___;\n\tpop \t\t%r15\n.cfi_restore\t%r15\n\tpop \t\t%r14\n.cfi_restore\t%r14\n\tpop \t\t%r13\n.cfi_restore\t%r13\n\tpop \t\t%r12\n.cfi_restore\t%r12\n\tpop \t\t%rbx\n.cfi_restore\t%rbx\n\tpop \t\t%rbp\n.cfi_restore \t%rbp\n.Lbase2_64_avx2_epilogue$suffix:\n\tjmp\t.Ldo_avx2$suffix\n.cfi_endproc\n\n.align\t32\n.Leven_avx2$suffix:\n.cfi_startproc\n___\n$code.=<<___ if (!$kernel);\n\tmov\t\tOPENSSL_ia32cap_P+8(%rip),%r9d\n___\n$code.=<<___;\n\tvmovd\t\t4*0($ctx),%x#$H0\t# load hash value base 2^26\n\tvmovd\t\t4*1($ctx),%x#$H1\n\tvmovd\t\t4*2($ctx),%x#$H2\n\tvmovd\t\t4*3($ctx),%x#$H3\n\tvmovd\t\t4*4($ctx),%x#$H4\n\n.Ldo_avx2$suffix:\n___\n$code.=<<___\t\tif (!$kernel && $avx>2);\n\tcmp\t\t\\$512,$len\n\tjb\t\t.Lskip_avx512\n\tand\t\t%r11d,%r9d\n\ttest\t\t\\$`1<<16`,%r9d\t\t# check for AVX512F\n\tjnz\t\t.Lblocks_avx512\n.Lskip_avx512$suffix:\n___\n$code.=<<___ if ($avx > 2 && $avx512 && $kernel);\n\tcmp\t\t\\$512,$len\n\tjae\t\t.Lblocks_avx512\n___\n$code.=<<___\tif (!$win64);\n\tlea\t\t8(%rsp),%r10\n.cfi_def_cfa_register\t%r10\n\tsub\t\t\\$0x128,%rsp\n___\n$code.=<<___\tif ($win64);\n\tlea\t\t8(%rsp),%r10\n\tsub\t\t\\$0x1c8,%rsp\n\tvmovdqa\t\t%xmm6,-0xb0(%r10)\n\tvmovdqa\t\t%xmm7,-0xa0(%r10)\n\tvmovdqa\t\t%xmm8,-0x90(%r10)\n\tvmovdqa\t\t%xmm9,-0x80(%r10)\n\tvmovdqa\t\t%xmm10,-0x70(%r10)\n\tvmovdqa\t\t%xmm11,-0x60(%r10)\n\tvmovdqa\t\t%xmm12,-0x50(%r10)\n\tvmovdqa\t\t%xmm13,-0x40(%r10)\n\tvmovdqa\t\t%xmm14,-0x30(%r10)\n\tvmovdqa\t\t%xmm15,-0x20(%r10)\n.Ldo_avx2_body$suffix:\n___\n$code.=<<___;\n\tlea\t\t.Lconst(%rip),%rcx\n\tlea\t\t48+64($ctx),$ctx\t# size optimization\n\tvmovdqa\t\t96(%rcx),$T0\t\t# .Lpermd_avx2\n\n\t# expand and copy pre-calculated table to stack\n\tvmovdqu\t\t`16*0-64`($ctx),%x#$T2\n\tand\t\t\\$-512,%rsp\n\tvmovdqu\t\t`16*1-64`($ctx),%x#$T3\n\tvmovdqu\t\t`16*2-64`($ctx),%x#$T4\n\tvmovdqu\t\t`16*3-64`($ctx),%x#$D0\n\tvmovdqu\t\t`16*4-64`($ctx),%x#$D1\n\tvmovdqu\t\t`16*5-64`($ctx),%x#$D2\n\tlea\t\t0x90(%rsp),%rax\t\t# size optimization\n\tvmovdqu\t\t`16*6-64`($ctx),%x#$D3\n\tvpermd\t\t$T2,$T0,$T2\t\t# 00003412 -> 14243444\n\tvmovdqu\t\t`16*7-64`($ctx),%x#$D4\n\tvpermd\t\t$T3,$T0,$T3\n\tvmovdqu\t\t`16*8-64`($ctx),%x#$MASK\n\tvpermd\t\t$T4,$T0,$T4\n\tvmovdqa\t\t$T2,0x00(%rsp)\n\tvpermd\t\t$D0,$T0,$D0\n\tvmovdqa\t\t$T3,0x20-0x90(%rax)\n\tvpermd\t\t$D1,$T0,$D1\n\tvmovdqa\t\t$T4,0x40-0x90(%rax)\n\tvpermd\t\t$D2,$T0,$D2\n\tvmovdqa\t\t$D0,0x60-0x90(%rax)\n\tvpermd\t\t$D3,$T0,$D3\n\tvmovdqa\t\t$D1,0x80-0x90(%rax)\n\tvpermd\t\t$D4,$T0,$D4\n\tvmovdqa\t\t$D2,0xa0-0x90(%rax)\n\tvpermd\t\t$MASK,$T0,$MASK\n\tvmovdqa\t\t$D3,0xc0-0x90(%rax)\n\tvmovdqa\t\t$D4,0xe0-0x90(%rax)\n\tvmovdqa\t\t$MASK,0x100-0x90(%rax)\n\tvmovdqa\t\t64(%rcx),$MASK\t\t# .Lmask26\n\n\t################################################################\n\t# load input\n\tvmovdqu\t\t16*0($inp),%x#$T0\n\tvmovdqu\t\t16*1($inp),%x#$T1\n\tvinserti128\t\\$1,16*2($inp),$T0,$T0\n\tvinserti128\t\\$1,16*3($inp),$T1,$T1\n\tlea\t\t16*4($inp),$inp\n\n\tvpsrldq\t\t\\$6,$T0,$T2\t\t# splat input\n\tvpsrldq\t\t\\$6,$T1,$T3\n\tvpunpckhqdq\t$T1,$T0,$T4\t\t# 4\n\tvpunpcklqdq\t$T3,$T2,$T2\t\t# 2:3\n\tvpunpcklqdq\t$T1,$T0,$T0\t\t# 0:1\n\n\tvpsrlq\t\t\\$30,$T2,$T3\n\tvpsrlq\t\t\\$4,$T2,$T2\n\tvpsrlq\t\t\\$26,$T0,$T1\n\tvpsrlq\t\t\\$40,$T4,$T4\t\t# 4\n\tvpand\t\t$MASK,$T2,$T2\t\t# 2\n\tvpand\t\t$MASK,$T0,$T0\t\t# 0\n\tvpand\t\t$MASK,$T1,$T1\t\t# 1\n\tvpand\t\t$MASK,$T3,$T3\t\t# 3\n\tvpor\t\t32(%rcx),$T4,$T4\t# padbit, yes, always\n\n\tvpaddq\t\t$H2,$T2,$H2\t\t# accumulate input\n\tsub\t\t\\$64,$len\n\tjz\t\t.Ltail_avx2$suffix\n\tjmp\t\t.Loop_avx2$suffix\n\n.align\t32\n.Loop_avx2$suffix:\n\t################################################################\n\t# ((inp[0]*r^4+inp[4])*r^4+inp[ 8])*r^4\n\t# ((inp[1]*r^4+inp[5])*r^4+inp[ 9])*r^3\n\t# ((inp[2]*r^4+inp[6])*r^4+inp[10])*r^2\n\t# ((inp[3]*r^4+inp[7])*r^4+inp[11])*r^1\n\t#   \\________/\\__________/\n\t################################################################\n\t#vpaddq\t\t$H2,$T2,$H2\t\t# accumulate input\n\tvpaddq\t\t$H0,$T0,$H0\n\tvmovdqa\t\t`32*0`(%rsp),$T0\t# r0^4\n\tvpaddq\t\t$H1,$T1,$H1\n\tvmovdqa\t\t`32*1`(%rsp),$T1\t# r1^4\n\tvpaddq\t\t$H3,$T3,$H3\n\tvmovdqa\t\t`32*3`(%rsp),$T2\t# r2^4\n\tvpaddq\t\t$H4,$T4,$H4\n\tvmovdqa\t\t`32*6-0x90`(%rax),$T3\t# s3^4\n\tvmovdqa\t\t`32*8-0x90`(%rax),$S4\t# s4^4\n\n\t# d4 = h4*r0 + h3*r1   + h2*r2   + h1*r3   + h0*r4\n\t# d3 = h3*r0 + h2*r1   + h1*r2   + h0*r3   + h4*5*r4\n\t# d2 = h2*r0 + h1*r1   + h0*r2   + h4*5*r3 + h3*5*r4\n\t# d1 = h1*r0 + h0*r1   + h4*5*r2 + h3*5*r3 + h2*5*r4\n\t# d0 = h0*r0 + h4*5*r1 + h3*5*r2 + h2*5*r3 + h1*5*r4\n\t#\n\t# however, as h2 is \"chronologically\" first one available pull\n\t# corresponding operations up, so it's\n\t#\n\t# d4 = h2*r2   + h4*r0 + h3*r1             + h1*r3   + h0*r4\n\t# d3 = h2*r1   + h3*r0           + h1*r2   + h0*r3   + h4*5*r4\n\t# d2 = h2*r0           + h1*r1   + h0*r2   + h4*5*r3 + h3*5*r4\n\t# d1 = h2*5*r4 + h1*r0 + h0*r1   + h4*5*r2 + h3*5*r3\n\t# d0 = h2*5*r3 + h0*r0 + h4*5*r1 + h3*5*r2           + h1*5*r4\n\n\tvpmuludq\t$H2,$T0,$D2\t\t# d2 = h2*r0\n\tvpmuludq\t$H2,$T1,$D3\t\t# d3 = h2*r1\n\tvpmuludq\t$H2,$T2,$D4\t\t# d4 = h2*r2\n\tvpmuludq\t$H2,$T3,$D0\t\t# d0 = h2*s3\n\tvpmuludq\t$H2,$S4,$D1\t\t# d1 = h2*s4\n\n\tvpmuludq\t$H0,$T1,$T4\t\t# h0*r1\n\tvpmuludq\t$H1,$T1,$H2\t\t# h1*r1, borrow $H2 as temp\n\tvpaddq\t\t$T4,$D1,$D1\t\t# d1 += h0*r1\n\tvpaddq\t\t$H2,$D2,$D2\t\t# d2 += h1*r1\n\tvpmuludq\t$H3,$T1,$T4\t\t# h3*r1\n\tvpmuludq\t`32*2`(%rsp),$H4,$H2\t# h4*s1\n\tvpaddq\t\t$T4,$D4,$D4\t\t# d4 += h3*r1\n\tvpaddq\t\t$H2,$D0,$D0\t\t# d0 += h4*s1\n\t vmovdqa\t`32*4-0x90`(%rax),$T1\t# s2\n\n\tvpmuludq\t$H0,$T0,$T4\t\t# h0*r0\n\tvpmuludq\t$H1,$T0,$H2\t\t# h1*r0\n\tvpaddq\t\t$T4,$D0,$D0\t\t# d0 += h0*r0\n\tvpaddq\t\t$H2,$D1,$D1\t\t# d1 += h1*r0\n\tvpmuludq\t$H3,$T0,$T4\t\t# h3*r0\n\tvpmuludq\t$H4,$T0,$H2\t\t# h4*r0\n\t vmovdqu\t16*0($inp),%x#$T0\t# load input\n\tvpaddq\t\t$T4,$D3,$D3\t\t# d3 += h3*r0\n\tvpaddq\t\t$H2,$D4,$D4\t\t# d4 += h4*r0\n\t vinserti128\t\\$1,16*2($inp),$T0,$T0\n\n\tvpmuludq\t$H3,$T1,$T4\t\t# h3*s2\n\tvpmuludq\t$H4,$T1,$H2\t\t# h4*s2\n\t vmovdqu\t16*1($inp),%x#$T1\n\tvpaddq\t\t$T4,$D0,$D0\t\t# d0 += h3*s2\n\tvpaddq\t\t$H2,$D1,$D1\t\t# d1 += h4*s2\n\t vmovdqa\t`32*5-0x90`(%rax),$H2\t# r3\n\tvpmuludq\t$H1,$T2,$T4\t\t# h1*r2\n\tvpmuludq\t$H0,$T2,$T2\t\t# h0*r2\n\tvpaddq\t\t$T4,$D3,$D3\t\t# d3 += h1*r2\n\tvpaddq\t\t$T2,$D2,$D2\t\t# d2 += h0*r2\n\t vinserti128\t\\$1,16*3($inp),$T1,$T1\n\t lea\t\t16*4($inp),$inp\n\n\tvpmuludq\t$H1,$H2,$T4\t\t# h1*r3\n\tvpmuludq\t$H0,$H2,$H2\t\t# h0*r3\n\t vpsrldq\t\\$6,$T0,$T2\t\t# splat input\n\tvpaddq\t\t$T4,$D4,$D4\t\t# d4 += h1*r3\n\tvpaddq\t\t$H2,$D3,$D3\t\t# d3 += h0*r3\n\tvpmuludq\t$H3,$T3,$T4\t\t# h3*s3\n\tvpmuludq\t$H4,$T3,$H2\t\t# h4*s3\n\t vpsrldq\t\\$6,$T1,$T3\n\tvpaddq\t\t$T4,$D1,$D1\t\t# d1 += h3*s3\n\tvpaddq\t\t$H2,$D2,$D2\t\t# d2 += h4*s3\n\t vpunpckhqdq\t$T1,$T0,$T4\t\t# 4\n\n\tvpmuludq\t$H3,$S4,$H3\t\t# h3*s4\n\tvpmuludq\t$H4,$S4,$H4\t\t# h4*s4\n\t vpunpcklqdq\t$T1,$T0,$T0\t\t# 0:1\n\tvpaddq\t\t$H3,$D2,$H2\t\t# h2 = d2 + h3*r4\n\tvpaddq\t\t$H4,$D3,$H3\t\t# h3 = d3 + h4*r4\n\t vpunpcklqdq\t$T3,$T2,$T3\t\t# 2:3\n\tvpmuludq\t`32*7-0x90`(%rax),$H0,$H4\t# h0*r4\n\tvpmuludq\t$H1,$S4,$H0\t\t# h1*s4\n\tvmovdqa\t\t64(%rcx),$MASK\t\t# .Lmask26\n\tvpaddq\t\t$H4,$D4,$H4\t\t# h4 = d4 + h0*r4\n\tvpaddq\t\t$H0,$D0,$H0\t\t# h0 = d0 + h1*s4\n\n\t################################################################\n\t# lazy reduction (interleaved with tail of input splat)\n\n\tvpsrlq\t\t\\$26,$H3,$D3\n\tvpand\t\t$MASK,$H3,$H3\n\tvpaddq\t\t$D3,$H4,$H4\t\t# h3 -> h4\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpand\t\t$MASK,$H0,$H0\n\tvpaddq\t\t$D0,$D1,$H1\t\t# h0 -> h1\n\n\tvpsrlq\t\t\\$26,$H4,$D4\n\tvpand\t\t$MASK,$H4,$H4\n\n\t vpsrlq\t\t\\$4,$T3,$T2\n\n\tvpsrlq\t\t\\$26,$H1,$D1\n\tvpand\t\t$MASK,$H1,$H1\n\tvpaddq\t\t$D1,$H2,$H2\t\t# h1 -> h2\n\n\tvpaddq\t\t$D4,$H0,$H0\n\tvpsllq\t\t\\$2,$D4,$D4\n\tvpaddq\t\t$D4,$H0,$H0\t\t# h4 -> h0\n\n\t vpand\t\t$MASK,$T2,$T2\t\t# 2\n\t vpsrlq\t\t\\$26,$T0,$T1\n\n\tvpsrlq\t\t\\$26,$H2,$D2\n\tvpand\t\t$MASK,$H2,$H2\n\tvpaddq\t\t$D2,$H3,$H3\t\t# h2 -> h3\n\n\t vpaddq\t\t$T2,$H2,$H2\t\t# modulo-scheduled\n\t vpsrlq\t\t\\$30,$T3,$T3\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpand\t\t$MASK,$H0,$H0\n\tvpaddq\t\t$D0,$H1,$H1\t\t# h0 -> h1\n\n\t vpsrlq\t\t\\$40,$T4,$T4\t\t# 4\n\n\tvpsrlq\t\t\\$26,$H3,$D3\n\tvpand\t\t$MASK,$H3,$H3\n\tvpaddq\t\t$D3,$H4,$H4\t\t# h3 -> h4\n\n\t vpand\t\t$MASK,$T0,$T0\t\t# 0\n\t vpand\t\t$MASK,$T1,$T1\t\t# 1\n\t vpand\t\t$MASK,$T3,$T3\t\t# 3\n\t vpor\t\t32(%rcx),$T4,$T4\t# padbit, yes, always\n\n\tsub\t\t\\$64,$len\n\tjnz\t\t.Loop_avx2$suffix\n\n\t.byte\t\t0x66,0x90\n.Ltail_avx2$suffix:\n\t################################################################\n\t# while above multiplications were by r^4 in all lanes, in last\n\t# iteration we multiply least significant lane by r^4 and most\n\t# significant one by r, so copy of above except that references\n\t# to the precomputed table are displaced by 4...\n\n\t#vpaddq\t\t$H2,$T2,$H2\t\t# accumulate input\n\tvpaddq\t\t$H0,$T0,$H0\n\tvmovdqu\t\t`32*0+4`(%rsp),$T0\t# r0^4\n\tvpaddq\t\t$H1,$T1,$H1\n\tvmovdqu\t\t`32*1+4`(%rsp),$T1\t# r1^4\n\tvpaddq\t\t$H3,$T3,$H3\n\tvmovdqu\t\t`32*3+4`(%rsp),$T2\t# r2^4\n\tvpaddq\t\t$H4,$T4,$H4\n\tvmovdqu\t\t`32*6+4-0x90`(%rax),$T3\t# s3^4\n\tvmovdqu\t\t`32*8+4-0x90`(%rax),$S4\t# s4^4\n\n\tvpmuludq\t$H2,$T0,$D2\t\t# d2 = h2*r0\n\tvpmuludq\t$H2,$T1,$D3\t\t# d3 = h2*r1\n\tvpmuludq\t$H2,$T2,$D4\t\t# d4 = h2*r2\n\tvpmuludq\t$H2,$T3,$D0\t\t# d0 = h2*s3\n\tvpmuludq\t$H2,$S4,$D1\t\t# d1 = h2*s4\n\n\tvpmuludq\t$H0,$T1,$T4\t\t# h0*r1\n\tvpmuludq\t$H1,$T1,$H2\t\t# h1*r1\n\tvpaddq\t\t$T4,$D1,$D1\t\t# d1 += h0*r1\n\tvpaddq\t\t$H2,$D2,$D2\t\t# d2 += h1*r1\n\tvpmuludq\t$H3,$T1,$T4\t\t# h3*r1\n\tvpmuludq\t`32*2+4`(%rsp),$H4,$H2\t# h4*s1\n\tvpaddq\t\t$T4,$D4,$D4\t\t# d4 += h3*r1\n\tvpaddq\t\t$H2,$D0,$D0\t\t# d0 += h4*s1\n\n\tvpmuludq\t$H0,$T0,$T4\t\t# h0*r0\n\tvpmuludq\t$H1,$T0,$H2\t\t# h1*r0\n\tvpaddq\t\t$T4,$D0,$D0\t\t# d0 += h0*r0\n\t vmovdqu\t`32*4+4-0x90`(%rax),$T1\t# s2\n\tvpaddq\t\t$H2,$D1,$D1\t\t# d1 += h1*r0\n\tvpmuludq\t$H3,$T0,$T4\t\t# h3*r0\n\tvpmuludq\t$H4,$T0,$H2\t\t# h4*r0\n\tvpaddq\t\t$T4,$D3,$D3\t\t# d3 += h3*r0\n\tvpaddq\t\t$H2,$D4,$D4\t\t# d4 += h4*r0\n\n\tvpmuludq\t$H3,$T1,$T4\t\t# h3*s2\n\tvpmuludq\t$H4,$T1,$H2\t\t# h4*s2\n\tvpaddq\t\t$T4,$D0,$D0\t\t# d0 += h3*s2\n\tvpaddq\t\t$H2,$D1,$D1\t\t# d1 += h4*s2\n\t vmovdqu\t`32*5+4-0x90`(%rax),$H2\t# r3\n\tvpmuludq\t$H1,$T2,$T4\t\t# h1*r2\n\tvpmuludq\t$H0,$T2,$T2\t\t# h0*r2\n\tvpaddq\t\t$T4,$D3,$D3\t\t# d3 += h1*r2\n\tvpaddq\t\t$T2,$D2,$D2\t\t# d2 += h0*r2\n\n\tvpmuludq\t$H1,$H2,$T4\t\t# h1*r3\n\tvpmuludq\t$H0,$H2,$H2\t\t# h0*r3\n\tvpaddq\t\t$T4,$D4,$D4\t\t# d4 += h1*r3\n\tvpaddq\t\t$H2,$D3,$D3\t\t# d3 += h0*r3\n\tvpmuludq\t$H3,$T3,$T4\t\t# h3*s3\n\tvpmuludq\t$H4,$T3,$H2\t\t# h4*s3\n\tvpaddq\t\t$T4,$D1,$D1\t\t# d1 += h3*s3\n\tvpaddq\t\t$H2,$D2,$D2\t\t# d2 += h4*s3\n\n\tvpmuludq\t$H3,$S4,$H3\t\t# h3*s4\n\tvpmuludq\t$H4,$S4,$H4\t\t# h4*s4\n\tvpaddq\t\t$H3,$D2,$H2\t\t# h2 = d2 + h3*r4\n\tvpaddq\t\t$H4,$D3,$H3\t\t# h3 = d3 + h4*r4\n\tvpmuludq\t`32*7+4-0x90`(%rax),$H0,$H4\t\t# h0*r4\n\tvpmuludq\t$H1,$S4,$H0\t\t# h1*s4\n\tvmovdqa\t\t64(%rcx),$MASK\t\t# .Lmask26\n\tvpaddq\t\t$H4,$D4,$H4\t\t# h4 = d4 + h0*r4\n\tvpaddq\t\t$H0,$D0,$H0\t\t# h0 = d0 + h1*s4\n\n\t################################################################\n\t# horizontal addition\n\n\tvpsrldq\t\t\\$8,$D1,$T1\n\tvpsrldq\t\t\\$8,$H2,$T2\n\tvpsrldq\t\t\\$8,$H3,$T3\n\tvpsrldq\t\t\\$8,$H4,$T4\n\tvpsrldq\t\t\\$8,$H0,$T0\n\tvpaddq\t\t$T1,$D1,$D1\n\tvpaddq\t\t$T2,$H2,$H2\n\tvpaddq\t\t$T3,$H3,$H3\n\tvpaddq\t\t$T4,$H4,$H4\n\tvpaddq\t\t$T0,$H0,$H0\n\n\tvpermq\t\t\\$0x2,$H3,$T3\n\tvpermq\t\t\\$0x2,$H4,$T4\n\tvpermq\t\t\\$0x2,$H0,$T0\n\tvpermq\t\t\\$0x2,$D1,$T1\n\tvpermq\t\t\\$0x2,$H2,$T2\n\tvpaddq\t\t$T3,$H3,$H3\n\tvpaddq\t\t$T4,$H4,$H4\n\tvpaddq\t\t$T0,$H0,$H0\n\tvpaddq\t\t$T1,$D1,$D1\n\tvpaddq\t\t$T2,$H2,$H2\n\n\t################################################################\n\t# lazy reduction\n\n\tvpsrlq\t\t\\$26,$H3,$D3\n\tvpand\t\t$MASK,$H3,$H3\n\tvpaddq\t\t$D3,$H4,$H4\t\t# h3 -> h4\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpand\t\t$MASK,$H0,$H0\n\tvpaddq\t\t$D0,$D1,$H1\t\t# h0 -> h1\n\n\tvpsrlq\t\t\\$26,$H4,$D4\n\tvpand\t\t$MASK,$H4,$H4\n\n\tvpsrlq\t\t\\$26,$H1,$D1\n\tvpand\t\t$MASK,$H1,$H1\n\tvpaddq\t\t$D1,$H2,$H2\t\t# h1 -> h2\n\n\tvpaddq\t\t$D4,$H0,$H0\n\tvpsllq\t\t\\$2,$D4,$D4\n\tvpaddq\t\t$D4,$H0,$H0\t\t# h4 -> h0\n\n\tvpsrlq\t\t\\$26,$H2,$D2\n\tvpand\t\t$MASK,$H2,$H2\n\tvpaddq\t\t$D2,$H3,$H3\t\t# h2 -> h3\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpand\t\t$MASK,$H0,$H0\n\tvpaddq\t\t$D0,$H1,$H1\t\t# h0 -> h1\n\n\tvpsrlq\t\t\\$26,$H3,$D3\n\tvpand\t\t$MASK,$H3,$H3\n\tvpaddq\t\t$D3,$H4,$H4\t\t# h3 -> h4\n\n\tvmovd\t\t%x#$H0,`4*0-48-64`($ctx)# save partially reduced\n\tvmovd\t\t%x#$H1,`4*1-48-64`($ctx)\n\tvmovd\t\t%x#$H2,`4*2-48-64`($ctx)\n\tvmovd\t\t%x#$H3,`4*3-48-64`($ctx)\n\tvmovd\t\t%x#$H4,`4*4-48-64`($ctx)\n___\n$code.=<<___\tif ($win64);\n\tvmovdqa\t\t-0xb0(%r10),%xmm6\n\tvmovdqa\t\t-0xa0(%r10),%xmm7\n\tvmovdqa\t\t-0x90(%r10),%xmm8\n\tvmovdqa\t\t-0x80(%r10),%xmm9\n\tvmovdqa\t\t-0x70(%r10),%xmm10\n\tvmovdqa\t\t-0x60(%r10),%xmm11\n\tvmovdqa\t\t-0x50(%r10),%xmm12\n\tvmovdqa\t\t-0x40(%r10),%xmm13\n\tvmovdqa\t\t-0x30(%r10),%xmm14\n\tvmovdqa\t\t-0x20(%r10),%xmm15\n\tlea\t\t-8(%r10),%rsp\n.Ldo_avx2_epilogue$suffix:\n___\n$code.=<<___\tif (!$win64);\n\tlea\t\t-8(%r10),%rsp\n.cfi_def_cfa_register\t%rsp\n___\n$code.=<<___;\n\tvzeroupper\n\tRET\n.cfi_endproc\n___\nif($avx > 2 && $avx512) {\nmy ($R0,$R1,$R2,$R3,$R4, $S1,$S2,$S3,$S4) = map(\"%zmm$_\",(16..24));\nmy ($M0,$M1,$M2,$M3,$M4) = map(\"%zmm$_\",(25..29));\nmy $PADBIT=\"%zmm30\";\n\nmap(s/%y/%z/,($T4,$T0,$T1,$T2,$T3));\t\t# switch to %zmm domain\nmap(s/%y/%z/,($D0,$D1,$D2,$D3,$D4));\nmap(s/%y/%z/,($H0,$H1,$H2,$H3,$H4));\nmap(s/%y/%z/,($MASK));\n\n$code.=<<___;\n.cfi_startproc\n.Lblocks_avx512:\n\tmov\t\t\\$15,%eax\n\tkmovw\t\t%eax,%k2\n___\n$code.=<<___\tif (!$win64);\n\tlea\t\t8(%rsp),%r10\n.cfi_def_cfa_register\t%r10\n\tsub\t\t\\$0x128,%rsp\n___\n$code.=<<___\tif ($win64);\n\tlea\t\t8(%rsp),%r10\n\tsub\t\t\\$0x1c8,%rsp\n\tvmovdqa\t\t%xmm6,-0xb0(%r10)\n\tvmovdqa\t\t%xmm7,-0xa0(%r10)\n\tvmovdqa\t\t%xmm8,-0x90(%r10)\n\tvmovdqa\t\t%xmm9,-0x80(%r10)\n\tvmovdqa\t\t%xmm10,-0x70(%r10)\n\tvmovdqa\t\t%xmm11,-0x60(%r10)\n\tvmovdqa\t\t%xmm12,-0x50(%r10)\n\tvmovdqa\t\t%xmm13,-0x40(%r10)\n\tvmovdqa\t\t%xmm14,-0x30(%r10)\n\tvmovdqa\t\t%xmm15,-0x20(%r10)\n.Ldo_avx512_body:\n___\n$code.=<<___;\n\tlea\t\t.Lconst(%rip),%rcx\n\tlea\t\t48+64($ctx),$ctx\t# size optimization\n\tvmovdqa\t\t96(%rcx),%y#$T2\t\t# .Lpermd_avx2\n\n\t# expand pre-calculated table\n\tvmovdqu\t\t`16*0-64`($ctx),%x#$D0\t# will become expanded ${R0}\n\tand\t\t\\$-512,%rsp\n\tvmovdqu\t\t`16*1-64`($ctx),%x#$D1\t# will become ... ${R1}\n\tmov\t\t\\$0x20,%rax\n\tvmovdqu\t\t`16*2-64`($ctx),%x#$T0\t# ... ${S1}\n\tvmovdqu\t\t`16*3-64`($ctx),%x#$D2\t# ... ${R2}\n\tvmovdqu\t\t`16*4-64`($ctx),%x#$T1\t# ... ${S2}\n\tvmovdqu\t\t`16*5-64`($ctx),%x#$D3\t# ... ${R3}\n\tvmovdqu\t\t`16*6-64`($ctx),%x#$T3\t# ... ${S3}\n\tvmovdqu\t\t`16*7-64`($ctx),%x#$D4\t# ... ${R4}\n\tvmovdqu\t\t`16*8-64`($ctx),%x#$T4\t# ... ${S4}\n\tvpermd\t\t$D0,$T2,$R0\t\t# 00003412 -> 14243444\n\tvpbroadcastq\t64(%rcx),$MASK\t\t# .Lmask26\n\tvpermd\t\t$D1,$T2,$R1\n\tvpermd\t\t$T0,$T2,$S1\n\tvpermd\t\t$D2,$T2,$R2\n\tvmovdqa64\t$R0,0x00(%rsp){%k2}\t# save in case $len%128 != 0\n\t vpsrlq\t\t\\$32,$R0,$T0\t\t# 14243444 -> 01020304\n\tvpermd\t\t$T1,$T2,$S2\n\tvmovdqu64\t$R1,0x00(%rsp,%rax){%k2}\n\t vpsrlq\t\t\\$32,$R1,$T1\n\tvpermd\t\t$D3,$T2,$R3\n\tvmovdqa64\t$S1,0x40(%rsp){%k2}\n\tvpermd\t\t$T3,$T2,$S3\n\tvpermd\t\t$D4,$T2,$R4\n\tvmovdqu64\t$R2,0x40(%rsp,%rax){%k2}\n\tvpermd\t\t$T4,$T2,$S4\n\tvmovdqa64\t$S2,0x80(%rsp){%k2}\n\tvmovdqu64\t$R3,0x80(%rsp,%rax){%k2}\n\tvmovdqa64\t$S3,0xc0(%rsp){%k2}\n\tvmovdqu64\t$R4,0xc0(%rsp,%rax){%k2}\n\tvmovdqa64\t$S4,0x100(%rsp){%k2}\n\n\t################################################################\n\t# calculate 5th through 8th powers of the key\n\t#\n\t# d0 = r0'*r0 + r1'*5*r4 + r2'*5*r3 + r3'*5*r2 + r4'*5*r1\n\t# d1 = r0'*r1 + r1'*r0   + r2'*5*r4 + r3'*5*r3 + r4'*5*r2\n\t# d2 = r0'*r2 + r1'*r1   + r2'*r0   + r3'*5*r4 + r4'*5*r3\n\t# d3 = r0'*r3 + r1'*r2   + r2'*r1   + r3'*r0   + r4'*5*r4\n\t# d4 = r0'*r4 + r1'*r3   + r2'*r2   + r3'*r1   + r4'*r0\n\n\tvpmuludq\t$T0,$R0,$D0\t\t# d0 = r0'*r0\n\tvpmuludq\t$T0,$R1,$D1\t\t# d1 = r0'*r1\n\tvpmuludq\t$T0,$R2,$D2\t\t# d2 = r0'*r2\n\tvpmuludq\t$T0,$R3,$D3\t\t# d3 = r0'*r3\n\tvpmuludq\t$T0,$R4,$D4\t\t# d4 = r0'*r4\n\t vpsrlq\t\t\\$32,$R2,$T2\n\n\tvpmuludq\t$T1,$S4,$M0\n\tvpmuludq\t$T1,$R0,$M1\n\tvpmuludq\t$T1,$R1,$M2\n\tvpmuludq\t$T1,$R2,$M3\n\tvpmuludq\t$T1,$R3,$M4\n\t vpsrlq\t\t\\$32,$R3,$T3\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += r1'*5*r4\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += r1'*r0\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += r1'*r1\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += r1'*r2\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += r1'*r3\n\n\tvpmuludq\t$T2,$S3,$M0\n\tvpmuludq\t$T2,$S4,$M1\n\tvpmuludq\t$T2,$R1,$M3\n\tvpmuludq\t$T2,$R2,$M4\n\tvpmuludq\t$T2,$R0,$M2\n\t vpsrlq\t\t\\$32,$R4,$T4\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += r2'*5*r3\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += r2'*5*r4\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += r2'*r1\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += r2'*r2\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += r2'*r0\n\n\tvpmuludq\t$T3,$S2,$M0\n\tvpmuludq\t$T3,$R0,$M3\n\tvpmuludq\t$T3,$R1,$M4\n\tvpmuludq\t$T3,$S3,$M1\n\tvpmuludq\t$T3,$S4,$M2\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += r3'*5*r2\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += r3'*r0\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += r3'*r1\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += r3'*5*r3\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += r3'*5*r4\n\n\tvpmuludq\t$T4,$S4,$M3\n\tvpmuludq\t$T4,$R0,$M4\n\tvpmuludq\t$T4,$S1,$M0\n\tvpmuludq\t$T4,$S2,$M1\n\tvpmuludq\t$T4,$S3,$M2\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += r2'*5*r4\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += r2'*r0\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += r2'*5*r1\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += r2'*5*r2\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += r2'*5*r3\n\n\t################################################################\n\t# load input\n\tvmovdqu64\t16*0($inp),%z#$T3\n\tvmovdqu64\t16*4($inp),%z#$T4\n\tlea\t\t16*8($inp),$inp\n\n\t################################################################\n\t# lazy reduction\n\n\tvpsrlq\t\t\\$26,$D3,$M3\n\tvpandq\t\t$MASK,$D3,$D3\n\tvpaddq\t\t$M3,$D4,$D4\t\t# d3 -> d4\n\n\tvpsrlq\t\t\\$26,$D0,$M0\n\tvpandq\t\t$MASK,$D0,$D0\n\tvpaddq\t\t$M0,$D1,$D1\t\t# d0 -> d1\n\n\tvpsrlq\t\t\\$26,$D4,$M4\n\tvpandq\t\t$MASK,$D4,$D4\n\n\tvpsrlq\t\t\\$26,$D1,$M1\n\tvpandq\t\t$MASK,$D1,$D1\n\tvpaddq\t\t$M1,$D2,$D2\t\t# d1 -> d2\n\n\tvpaddq\t\t$M4,$D0,$D0\n\tvpsllq\t\t\\$2,$M4,$M4\n\tvpaddq\t\t$M4,$D0,$D0\t\t# d4 -> d0\n\n\tvpsrlq\t\t\\$26,$D2,$M2\n\tvpandq\t\t$MASK,$D2,$D2\n\tvpaddq\t\t$M2,$D3,$D3\t\t# d2 -> d3\n\n\tvpsrlq\t\t\\$26,$D0,$M0\n\tvpandq\t\t$MASK,$D0,$D0\n\tvpaddq\t\t$M0,$D1,$D1\t\t# d0 -> d1\n\n\tvpsrlq\t\t\\$26,$D3,$M3\n\tvpandq\t\t$MASK,$D3,$D3\n\tvpaddq\t\t$M3,$D4,$D4\t\t# d3 -> d4\n\n\t################################################################\n\t# at this point we have 14243444 in $R0-$S4 and 05060708 in\n\t# $D0-$D4, ...\n\n\tvpunpcklqdq\t$T4,$T3,$T0\t# transpose input\n\tvpunpckhqdq\t$T4,$T3,$T4\n\n\t# ... since input 64-bit lanes are ordered as 73625140, we could\n\t# \"vperm\" it to 76543210 (here and in each loop iteration), *or*\n\t# we could just flow along, hence the goal for $R0-$S4 is\n\t# 1858286838784888 ...\n\n\tvmovdqa32\t128(%rcx),$M0\t\t# .Lpermd_avx512:\n\tmov\t\t\\$0x7777,%eax\n\tkmovw\t\t%eax,%k1\n\n\tvpermd\t\t$R0,$M0,$R0\t\t# 14243444 -> 1---2---3---4---\n\tvpermd\t\t$R1,$M0,$R1\n\tvpermd\t\t$R2,$M0,$R2\n\tvpermd\t\t$R3,$M0,$R3\n\tvpermd\t\t$R4,$M0,$R4\n\n\tvpermd\t\t$D0,$M0,${R0}{%k1}\t# 05060708 -> 1858286838784888\n\tvpermd\t\t$D1,$M0,${R1}{%k1}\n\tvpermd\t\t$D2,$M0,${R2}{%k1}\n\tvpermd\t\t$D3,$M0,${R3}{%k1}\n\tvpermd\t\t$D4,$M0,${R4}{%k1}\n\n\tvpslld\t\t\\$2,$R1,$S1\t\t# *5\n\tvpslld\t\t\\$2,$R2,$S2\n\tvpslld\t\t\\$2,$R3,$S3\n\tvpslld\t\t\\$2,$R4,$S4\n\tvpaddd\t\t$R1,$S1,$S1\n\tvpaddd\t\t$R2,$S2,$S2\n\tvpaddd\t\t$R3,$S3,$S3\n\tvpaddd\t\t$R4,$S4,$S4\n\n\tvpbroadcastq\t32(%rcx),$PADBIT\t# .L129\n\n\tvpsrlq\t\t\\$52,$T0,$T2\t\t# splat input\n\tvpsllq\t\t\\$12,$T4,$T3\n\tvporq\t\t$T3,$T2,$T2\n\tvpsrlq\t\t\\$26,$T0,$T1\n\tvpsrlq\t\t\\$14,$T4,$T3\n\tvpsrlq\t\t\\$40,$T4,$T4\t\t# 4\n\tvpandq\t\t$MASK,$T2,$T2\t\t# 2\n\tvpandq\t\t$MASK,$T0,$T0\t\t# 0\n\t#vpandq\t\t$MASK,$T1,$T1\t\t# 1\n\t#vpandq\t\t$MASK,$T3,$T3\t\t# 3\n\t#vporq\t\t$PADBIT,$T4,$T4\t\t# padbit, yes, always\n\n\tvpaddq\t\t$H2,$T2,$H2\t\t# accumulate input\n\tsub\t\t\\$192,$len\n\tjbe\t\t.Ltail_avx512\n\tjmp\t\t.Loop_avx512\n\n.align\t32\n.Loop_avx512:\n\t################################################################\n\t# ((inp[0]*r^8+inp[ 8])*r^8+inp[16])*r^8\n\t# ((inp[1]*r^8+inp[ 9])*r^8+inp[17])*r^7\n\t# ((inp[2]*r^8+inp[10])*r^8+inp[18])*r^6\n\t# ((inp[3]*r^8+inp[11])*r^8+inp[19])*r^5\n\t# ((inp[4]*r^8+inp[12])*r^8+inp[20])*r^4\n\t# ((inp[5]*r^8+inp[13])*r^8+inp[21])*r^3\n\t# ((inp[6]*r^8+inp[14])*r^8+inp[22])*r^2\n\t# ((inp[7]*r^8+inp[15])*r^8+inp[23])*r^1\n\t#   \\________/\\___________/\n\t################################################################\n\t#vpaddq\t\t$H2,$T2,$H2\t\t# accumulate input\n\n\t# d4 = h4*r0 + h3*r1   + h2*r2   + h1*r3   + h0*r4\n\t# d3 = h3*r0 + h2*r1   + h1*r2   + h0*r3   + h4*5*r4\n\t# d2 = h2*r0 + h1*r1   + h0*r2   + h4*5*r3 + h3*5*r4\n\t# d1 = h1*r0 + h0*r1   + h4*5*r2 + h3*5*r3 + h2*5*r4\n\t# d0 = h0*r0 + h4*5*r1 + h3*5*r2 + h2*5*r3 + h1*5*r4\n\t#\n\t# however, as h2 is \"chronologically\" first one available pull\n\t# corresponding operations up, so it's\n\t#\n\t# d3 = h2*r1   + h0*r3 + h1*r2   + h3*r0 + h4*5*r4\n\t# d4 = h2*r2   + h0*r4 + h1*r3   + h3*r1 + h4*r0\n\t# d0 = h2*5*r3 + h0*r0 + h1*5*r4         + h3*5*r2 + h4*5*r1\n\t# d1 = h2*5*r4 + h0*r1           + h1*r0 + h3*5*r3 + h4*5*r2\n\t# d2 = h2*r0           + h0*r2   + h1*r1 + h3*5*r4 + h4*5*r3\n\n\tvpmuludq\t$H2,$R1,$D3\t\t# d3 = h2*r1\n\t vpaddq\t\t$H0,$T0,$H0\n\tvpmuludq\t$H2,$R2,$D4\t\t# d4 = h2*r2\n\t vpandq\t\t$MASK,$T1,$T1\t\t# 1\n\tvpmuludq\t$H2,$S3,$D0\t\t# d0 = h2*s3\n\t vpandq\t\t$MASK,$T3,$T3\t\t# 3\n\tvpmuludq\t$H2,$S4,$D1\t\t# d1 = h2*s4\n\t vporq\t\t$PADBIT,$T4,$T4\t\t# padbit, yes, always\n\tvpmuludq\t$H2,$R0,$D2\t\t# d2 = h2*r0\n\t vpaddq\t\t$H1,$T1,$H1\t\t# accumulate input\n\t vpaddq\t\t$H3,$T3,$H3\n\t vpaddq\t\t$H4,$T4,$H4\n\n\t  vmovdqu64\t16*0($inp),$T3\t\t# load input\n\t  vmovdqu64\t16*4($inp),$T4\n\t  lea\t\t16*8($inp),$inp\n\tvpmuludq\t$H0,$R3,$M3\n\tvpmuludq\t$H0,$R4,$M4\n\tvpmuludq\t$H0,$R0,$M0\n\tvpmuludq\t$H0,$R1,$M1\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += h0*r3\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += h0*r4\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += h0*r0\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += h0*r1\n\n\tvpmuludq\t$H1,$R2,$M3\n\tvpmuludq\t$H1,$R3,$M4\n\tvpmuludq\t$H1,$S4,$M0\n\tvpmuludq\t$H0,$R2,$M2\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += h1*r2\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += h1*r3\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += h1*s4\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += h0*r2\n\n\t  vpunpcklqdq\t$T4,$T3,$T0\t\t# transpose input\n\t  vpunpckhqdq\t$T4,$T3,$T4\n\n\tvpmuludq\t$H3,$R0,$M3\n\tvpmuludq\t$H3,$R1,$M4\n\tvpmuludq\t$H1,$R0,$M1\n\tvpmuludq\t$H1,$R1,$M2\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += h3*r0\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += h3*r1\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += h1*r0\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += h1*r1\n\n\tvpmuludq\t$H4,$S4,$M3\n\tvpmuludq\t$H4,$R0,$M4\n\tvpmuludq\t$H3,$S2,$M0\n\tvpmuludq\t$H3,$S3,$M1\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += h4*s4\n\tvpmuludq\t$H3,$S4,$M2\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += h4*r0\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += h3*s2\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += h3*s3\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += h3*s4\n\n\tvpmuludq\t$H4,$S1,$M0\n\tvpmuludq\t$H4,$S2,$M1\n\tvpmuludq\t$H4,$S3,$M2\n\tvpaddq\t\t$M0,$D0,$H0\t\t# h0 = d0 + h4*s1\n\tvpaddq\t\t$M1,$D1,$H1\t\t# h1 = d2 + h4*s2\n\tvpaddq\t\t$M2,$D2,$H2\t\t# h2 = d3 + h4*s3\n\n\t################################################################\n\t# lazy reduction (interleaved with input splat)\n\n\t vpsrlq\t\t\\$52,$T0,$T2\t\t# splat input\n\t vpsllq\t\t\\$12,$T4,$T3\n\n\tvpsrlq\t\t\\$26,$D3,$H3\n\tvpandq\t\t$MASK,$D3,$D3\n\tvpaddq\t\t$H3,$D4,$H4\t\t# h3 -> h4\n\n\t vporq\t\t$T3,$T2,$T2\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpandq\t\t$MASK,$H0,$H0\n\tvpaddq\t\t$D0,$H1,$H1\t\t# h0 -> h1\n\n\t vpandq\t\t$MASK,$T2,$T2\t\t# 2\n\n\tvpsrlq\t\t\\$26,$H4,$D4\n\tvpandq\t\t$MASK,$H4,$H4\n\n\tvpsrlq\t\t\\$26,$H1,$D1\n\tvpandq\t\t$MASK,$H1,$H1\n\tvpaddq\t\t$D1,$H2,$H2\t\t# h1 -> h2\n\n\tvpaddq\t\t$D4,$H0,$H0\n\tvpsllq\t\t\\$2,$D4,$D4\n\tvpaddq\t\t$D4,$H0,$H0\t\t# h4 -> h0\n\n\t vpaddq\t\t$T2,$H2,$H2\t\t# modulo-scheduled\n\t vpsrlq\t\t\\$26,$T0,$T1\n\n\tvpsrlq\t\t\\$26,$H2,$D2\n\tvpandq\t\t$MASK,$H2,$H2\n\tvpaddq\t\t$D2,$D3,$H3\t\t# h2 -> h3\n\n\t vpsrlq\t\t\\$14,$T4,$T3\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpandq\t\t$MASK,$H0,$H0\n\tvpaddq\t\t$D0,$H1,$H1\t\t# h0 -> h1\n\n\t vpsrlq\t\t\\$40,$T4,$T4\t\t# 4\n\n\tvpsrlq\t\t\\$26,$H3,$D3\n\tvpandq\t\t$MASK,$H3,$H3\n\tvpaddq\t\t$D3,$H4,$H4\t\t# h3 -> h4\n\n\t vpandq\t\t$MASK,$T0,$T0\t\t# 0\n\t #vpandq\t$MASK,$T1,$T1\t\t# 1\n\t #vpandq\t$MASK,$T3,$T3\t\t# 3\n\t #vporq\t\t$PADBIT,$T4,$T4\t\t# padbit, yes, always\n\n\tsub\t\t\\$128,$len\n\tja\t\t.Loop_avx512\n\n.Ltail_avx512:\n\t################################################################\n\t# while above multiplications were by r^8 in all lanes, in last\n\t# iteration we multiply least significant lane by r^8 and most\n\t# significant one by r, that's why table gets shifted...\n\n\tvpsrlq\t\t\\$32,$R0,$R0\t\t# 0105020603070408\n\tvpsrlq\t\t\\$32,$R1,$R1\n\tvpsrlq\t\t\\$32,$R2,$R2\n\tvpsrlq\t\t\\$32,$S3,$S3\n\tvpsrlq\t\t\\$32,$S4,$S4\n\tvpsrlq\t\t\\$32,$R3,$R3\n\tvpsrlq\t\t\\$32,$R4,$R4\n\tvpsrlq\t\t\\$32,$S1,$S1\n\tvpsrlq\t\t\\$32,$S2,$S2\n\n\t################################################################\n\t# load either next or last 64 byte of input\n\tlea\t\t($inp,$len),$inp\n\n\t#vpaddq\t\t$H2,$T2,$H2\t\t# accumulate input\n\tvpaddq\t\t$H0,$T0,$H0\n\n\tvpmuludq\t$H2,$R1,$D3\t\t# d3 = h2*r1\n\tvpmuludq\t$H2,$R2,$D4\t\t# d4 = h2*r2\n\tvpmuludq\t$H2,$S3,$D0\t\t# d0 = h2*s3\n\t vpandq\t\t$MASK,$T1,$T1\t\t# 1\n\tvpmuludq\t$H2,$S4,$D1\t\t# d1 = h2*s4\n\t vpandq\t\t$MASK,$T3,$T3\t\t# 3\n\tvpmuludq\t$H2,$R0,$D2\t\t# d2 = h2*r0\n\t vporq\t\t$PADBIT,$T4,$T4\t\t# padbit, yes, always\n\t vpaddq\t\t$H1,$T1,$H1\t\t# accumulate input\n\t vpaddq\t\t$H3,$T3,$H3\n\t vpaddq\t\t$H4,$T4,$H4\n\n\t  vmovdqu\t16*0($inp),%x#$T0\n\tvpmuludq\t$H0,$R3,$M3\n\tvpmuludq\t$H0,$R4,$M4\n\tvpmuludq\t$H0,$R0,$M0\n\tvpmuludq\t$H0,$R1,$M1\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += h0*r3\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += h0*r4\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += h0*r0\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += h0*r1\n\n\t  vmovdqu\t16*1($inp),%x#$T1\n\tvpmuludq\t$H1,$R2,$M3\n\tvpmuludq\t$H1,$R3,$M4\n\tvpmuludq\t$H1,$S4,$M0\n\tvpmuludq\t$H0,$R2,$M2\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += h1*r2\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += h1*r3\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += h1*s4\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += h0*r2\n\n\t  vinserti128\t\\$1,16*2($inp),%y#$T0,%y#$T0\n\tvpmuludq\t$H3,$R0,$M3\n\tvpmuludq\t$H3,$R1,$M4\n\tvpmuludq\t$H1,$R0,$M1\n\tvpmuludq\t$H1,$R1,$M2\n\tvpaddq\t\t$M3,$D3,$D3\t\t# d3 += h3*r0\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += h3*r1\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += h1*r0\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += h1*r1\n\n\t  vinserti128\t\\$1,16*3($inp),%y#$T1,%y#$T1\n\tvpmuludq\t$H4,$S4,$M3\n\tvpmuludq\t$H4,$R0,$M4\n\tvpmuludq\t$H3,$S2,$M0\n\tvpmuludq\t$H3,$S3,$M1\n\tvpmuludq\t$H3,$S4,$M2\n\tvpaddq\t\t$M3,$D3,$H3\t\t# h3 = d3 + h4*s4\n\tvpaddq\t\t$M4,$D4,$D4\t\t# d4 += h4*r0\n\tvpaddq\t\t$M0,$D0,$D0\t\t# d0 += h3*s2\n\tvpaddq\t\t$M1,$D1,$D1\t\t# d1 += h3*s3\n\tvpaddq\t\t$M2,$D2,$D2\t\t# d2 += h3*s4\n\n\tvpmuludq\t$H4,$S1,$M0\n\tvpmuludq\t$H4,$S2,$M1\n\tvpmuludq\t$H4,$S3,$M2\n\tvpaddq\t\t$M0,$D0,$H0\t\t# h0 = d0 + h4*s1\n\tvpaddq\t\t$M1,$D1,$H1\t\t# h1 = d2 + h4*s2\n\tvpaddq\t\t$M2,$D2,$H2\t\t# h2 = d3 + h4*s3\n\n\t################################################################\n\t# horizontal addition\n\n\tmov\t\t\\$1,%eax\n\tvpermq\t\t\\$0xb1,$H3,$D3\n\tvpermq\t\t\\$0xb1,$D4,$H4\n\tvpermq\t\t\\$0xb1,$H0,$D0\n\tvpermq\t\t\\$0xb1,$H1,$D1\n\tvpermq\t\t\\$0xb1,$H2,$D2\n\tvpaddq\t\t$D3,$H3,$H3\n\tvpaddq\t\t$D4,$H4,$H4\n\tvpaddq\t\t$D0,$H0,$H0\n\tvpaddq\t\t$D1,$H1,$H1\n\tvpaddq\t\t$D2,$H2,$H2\n\n\tkmovw\t\t%eax,%k3\n\tvpermq\t\t\\$0x2,$H3,$D3\n\tvpermq\t\t\\$0x2,$H4,$D4\n\tvpermq\t\t\\$0x2,$H0,$D0\n\tvpermq\t\t\\$0x2,$H1,$D1\n\tvpermq\t\t\\$0x2,$H2,$D2\n\tvpaddq\t\t$D3,$H3,$H3\n\tvpaddq\t\t$D4,$H4,$H4\n\tvpaddq\t\t$D0,$H0,$H0\n\tvpaddq\t\t$D1,$H1,$H1\n\tvpaddq\t\t$D2,$H2,$H2\n\n\tvextracti64x4\t\\$0x1,$H3,%y#$D3\n\tvextracti64x4\t\\$0x1,$H4,%y#$D4\n\tvextracti64x4\t\\$0x1,$H0,%y#$D0\n\tvextracti64x4\t\\$0x1,$H1,%y#$D1\n\tvextracti64x4\t\\$0x1,$H2,%y#$D2\n\tvpaddq\t\t$D3,$H3,${H3}{%k3}{z}\t# keep single qword in case\n\tvpaddq\t\t$D4,$H4,${H4}{%k3}{z}\t# it's passed to .Ltail_avx2\n\tvpaddq\t\t$D0,$H0,${H0}{%k3}{z}\n\tvpaddq\t\t$D1,$H1,${H1}{%k3}{z}\n\tvpaddq\t\t$D2,$H2,${H2}{%k3}{z}\n___\nmap(s/%z/%y/,($T0,$T1,$T2,$T3,$T4, $PADBIT));\nmap(s/%z/%y/,($H0,$H1,$H2,$H3,$H4, $D0,$D1,$D2,$D3,$D4, $MASK));\n$code.=<<___;\n\t################################################################\n\t# lazy reduction (interleaved with input splat)\n\n\tvpsrlq\t\t\\$26,$H3,$D3\n\tvpand\t\t$MASK,$H3,$H3\n\t vpsrldq\t\\$6,$T0,$T2\t\t# splat input\n\t vpsrldq\t\\$6,$T1,$T3\n\t vpunpckhqdq\t$T1,$T0,$T4\t\t# 4\n\tvpaddq\t\t$D3,$H4,$H4\t\t# h3 -> h4\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpand\t\t$MASK,$H0,$H0\n\t vpunpcklqdq\t$T3,$T2,$T2\t\t# 2:3\n\t vpunpcklqdq\t$T1,$T0,$T0\t\t# 0:1\n\tvpaddq\t\t$D0,$H1,$H1\t\t# h0 -> h1\n\n\tvpsrlq\t\t\\$26,$H4,$D4\n\tvpand\t\t$MASK,$H4,$H4\n\n\tvpsrlq\t\t\\$26,$H1,$D1\n\tvpand\t\t$MASK,$H1,$H1\n\t vpsrlq\t\t\\$30,$T2,$T3\n\t vpsrlq\t\t\\$4,$T2,$T2\n\tvpaddq\t\t$D1,$H2,$H2\t\t# h1 -> h2\n\n\tvpaddq\t\t$D4,$H0,$H0\n\tvpsllq\t\t\\$2,$D4,$D4\n\t vpsrlq\t\t\\$26,$T0,$T1\n\t vpsrlq\t\t\\$40,$T4,$T4\t\t# 4\n\tvpaddq\t\t$D4,$H0,$H0\t\t# h4 -> h0\n\n\tvpsrlq\t\t\\$26,$H2,$D2\n\tvpand\t\t$MASK,$H2,$H2\n\t vpand\t\t$MASK,$T2,$T2\t\t# 2\n\t vpand\t\t$MASK,$T0,$T0\t\t# 0\n\tvpaddq\t\t$D2,$H3,$H3\t\t# h2 -> h3\n\n\tvpsrlq\t\t\\$26,$H0,$D0\n\tvpand\t\t$MASK,$H0,$H0\n\t vpaddq\t\t$H2,$T2,$H2\t\t# accumulate input for .Ltail_avx2\n\t vpand\t\t$MASK,$T1,$T1\t\t# 1\n\tvpaddq\t\t$D0,$H1,$H1\t\t# h0 -> h1\n\n\tvpsrlq\t\t\\$26,$H3,$D3\n\tvpand\t\t$MASK,$H3,$H3\n\t vpand\t\t$MASK,$T3,$T3\t\t# 3\n\t vpor\t\t32(%rcx),$T4,$T4\t# padbit, yes, always\n\tvpaddq\t\t$D3,$H4,$H4\t\t# h3 -> h4\n\n\tlea\t\t0x90(%rsp),%rax\t\t# size optimization for .Ltail_avx2\n\tadd\t\t\\$64,$len\n\tjnz\t\t.Ltail_avx2$suffix\n\n\tvpsubq\t\t$T2,$H2,$H2\t\t# undo input accumulation\n\tvmovd\t\t%x#$H0,`4*0-48-64`($ctx)# save partially reduced\n\tvmovd\t\t%x#$H1,`4*1-48-64`($ctx)\n\tvmovd\t\t%x#$H2,`4*2-48-64`($ctx)\n\tvmovd\t\t%x#$H3,`4*3-48-64`($ctx)\n\tvmovd\t\t%x#$H4,`4*4-48-64`($ctx)\n\tvzeroall\n___\n$code.=<<___\tif ($win64);\n\tmovdqa\t\t-0xb0(%r10),%xmm6\n\tmovdqa\t\t-0xa0(%r10),%xmm7\n\tmovdqa\t\t-0x90(%r10),%xmm8\n\tmovdqa\t\t-0x80(%r10),%xmm9\n\tmovdqa\t\t-0x70(%r10),%xmm10\n\tmovdqa\t\t-0x60(%r10),%xmm11\n\tmovdqa\t\t-0x50(%r10),%xmm12\n\tmovdqa\t\t-0x40(%r10),%xmm13\n\tmovdqa\t\t-0x30(%r10),%xmm14\n\tmovdqa\t\t-0x20(%r10),%xmm15\n\tlea\t\t-8(%r10),%rsp\n.Ldo_avx512_epilogue:\n___\n$code.=<<___\tif (!$win64);\n\tlea\t\t-8(%r10),%rsp\n.cfi_def_cfa_register\t%rsp\n___\n$code.=<<___;\n\tRET\n.cfi_endproc\n___\n\n}\n\n}\n\n&declare_function(\"poly1305_blocks_avx2\", 32, 4);\npoly1305_blocks_avxN(0);\n&end_function(\"poly1305_blocks_avx2\");\n\n#######################################################################\nif ($avx>2) {\n# On entry we have input length divisible by 64. But since inner loop\n# processes 128 bytes per iteration, cases when length is not divisible\n# by 128 are handled by passing tail 64 bytes to .Ltail_avx2. For this\n# reason stack layout is kept identical to poly1305_blocks_avx2. If not\n# for this tail, we wouldn't have to even allocate stack frame...\n\nif($kernel) {\n\t$code .= \"#ifdef CONFIG_AS_AVX512\\n\";\n}\n\n&declare_function(\"poly1305_blocks_avx512\", 32, 4);\npoly1305_blocks_avxN(1);\n&end_function(\"poly1305_blocks_avx512\");\n\nif ($kernel) {\n\t$code .= \"#endif\\n\";\n}\n\nif (!$kernel && $avx>3) {\n########################################################################\n# VPMADD52 version using 2^44 radix.\n#\n# One can argue that base 2^52 would be more natural. Well, even though\n# some operations would be more natural, one has to recognize couple of\n# things. Base 2^52 doesn't provide advantage over base 2^44 if you look\n# at amount of multiply-n-accumulate operations. Secondly, it makes it\n# impossible to pre-compute multiples of 5 [referred to as s[]/sN in\n# reference implementations], which means that more such operations\n# would have to be performed in inner loop, which in turn makes critical\n# path longer. In other words, even though base 2^44 reduction might\n# look less elegant, overall critical path is actually shorter...\n\n########################################################################\n# Layout of opaque area is following.\n#\n#\tunsigned __int64 h[3];\t\t# current hash value base 2^44\n#\tunsigned __int64 s[2];\t\t# key value*20 base 2^44\n#\tunsigned __int64 r[3];\t\t# key value base 2^44\n#\tstruct { unsigned __int64 r^1, r^3, r^2, r^4; } R[4];\n#\t\t\t\t\t# r^n positions reflect\n#\t\t\t\t\t# placement in register, not\n#\t\t\t\t\t# memory, R[3] is R[1]*20\n\n$code.=<<___;\n.type\tpoly1305_init_base2_44,\\@function,3\n.align\t32\npoly1305_init_base2_44:\n\txor\t%eax,%eax\n\tmov\t%rax,0($ctx)\t\t# initialize hash value\n\tmov\t%rax,8($ctx)\n\tmov\t%rax,16($ctx)\n\n.Linit_base2_44:\n\tlea\tpoly1305_blocks_vpmadd52(%rip),%r10\n\tlea\tpoly1305_emit_base2_44(%rip),%r11\n\n\tmov\t\\$0x0ffffffc0fffffff,%rax\n\tmov\t\\$0x0ffffffc0ffffffc,%rcx\n\tand\t0($inp),%rax\n\tmov\t\\$0x00000fffffffffff,%r8\n\tand\t8($inp),%rcx\n\tmov\t\\$0x00000fffffffffff,%r9\n\tand\t%rax,%r8\n\tshrd\t\\$44,%rcx,%rax\n\tmov\t%r8,40($ctx)\t\t# r0\n\tand\t%r9,%rax\n\tshr\t\\$24,%rcx\n\tmov\t%rax,48($ctx)\t\t# r1\n\tlea\t(%rax,%rax,4),%rax\t# *5\n\tmov\t%rcx,56($ctx)\t\t# r2\n\tshl\t\\$2,%rax\t\t# magic <<2\n\tlea\t(%rcx,%rcx,4),%rcx\t# *5\n\tshl\t\\$2,%rcx\t\t# magic <<2\n\tmov\t%rax,24($ctx)\t\t# s1\n\tmov\t%rcx,32($ctx)\t\t# s2\n\tmovq\t\\$-1,64($ctx)\t\t# write impossible value\n___\n$code.=<<___\tif ($flavour !~ /elf32/);\n\tmov\t%r10,0(%rdx)\n\tmov\t%r11,8(%rdx)\n___\n$code.=<<___\tif ($flavour =~ /elf32/);\n\tmov\t%r10d,0(%rdx)\n\tmov\t%r11d,4(%rdx)\n___\n$code.=<<___;\n\tmov\t\\$1,%eax\n\tRET\n.size\tpoly1305_init_base2_44,.-poly1305_init_base2_44\n___\n{\nmy ($H0,$H1,$H2,$r2r1r0,$r1r0s2,$r0s2s1,$Dlo,$Dhi) = map(\"%ymm$_\",(0..5,16,17));\nmy ($T0,$inp_permd,$inp_shift,$PAD) = map(\"%ymm$_\",(18..21));\nmy ($reduc_mask,$reduc_rght,$reduc_left) = map(\"%ymm$_\",(22..25));\n\n$code.=<<___;\n.type\tpoly1305_blocks_vpmadd52,\\@function,4\n.align\t32\npoly1305_blocks_vpmadd52:\n\tshr\t\\$4,$len\n\tjz\t.Lno_data_vpmadd52\t\t# too short\n\n\tshl\t\\$40,$padbit\n\tmov\t64($ctx),%r8\t\t\t# peek on power of the key\n\n\t# if powers of the key are not calculated yet, process up to 3\n\t# blocks with this single-block subroutine, otherwise ensure that\n\t# length is divisible by 2 blocks and pass the rest down to next\n\t# subroutine...\n\n\tmov\t\\$3,%rax\n\tmov\t\\$1,%r10\n\tcmp\t\\$4,$len\t\t\t# is input long\n\tcmovae\t%r10,%rax\n\ttest\t%r8,%r8\t\t\t\t# is power value impossible?\n\tcmovns\t%r10,%rax\n\n\tand\t$len,%rax\t\t\t# is input of favourable length?\n\tjz\t.Lblocks_vpmadd52_4x\n\n\tsub\t\t%rax,$len\n\tmov\t\t\\$7,%r10d\n\tmov\t\t\\$1,%r11d\n\tkmovw\t\t%r10d,%k7\n\tlea\t\t.L2_44_inp_permd(%rip),%r10\n\tkmovw\t\t%r11d,%k1\n\n\tvmovq\t\t$padbit,%x#$PAD\n\tvmovdqa64\t0(%r10),$inp_permd\t# .L2_44_inp_permd\n\tvmovdqa64\t32(%r10),$inp_shift\t# .L2_44_inp_shift\n\tvpermq\t\t\\$0xcf,$PAD,$PAD\n\tvmovdqa64\t64(%r10),$reduc_mask\t# .L2_44_mask\n\n\tvmovdqu64\t0($ctx),${Dlo}{%k7}{z}\t\t# load hash value\n\tvmovdqu64\t40($ctx),${r2r1r0}{%k7}{z}\t# load keys\n\tvmovdqu64\t32($ctx),${r1r0s2}{%k7}{z}\n\tvmovdqu64\t24($ctx),${r0s2s1}{%k7}{z}\n\n\tvmovdqa64\t96(%r10),$reduc_rght\t# .L2_44_shift_rgt\n\tvmovdqa64\t128(%r10),$reduc_left\t# .L2_44_shift_lft\n\n\tjmp\t\t.Loop_vpmadd52\n\n.align\t32\n.Loop_vpmadd52:\n\tvmovdqu32\t0($inp),%x#$T0\t\t# load input as ----3210\n\tlea\t\t16($inp),$inp\n\n\tvpermd\t\t$T0,$inp_permd,$T0\t# ----3210 -> --322110\n\tvpsrlvq\t\t$inp_shift,$T0,$T0\n\tvpandq\t\t$reduc_mask,$T0,$T0\n\tvporq\t\t$PAD,$T0,$T0\n\n\tvpaddq\t\t$T0,$Dlo,$Dlo\t\t# accumulate input\n\n\tvpermq\t\t\\$0,$Dlo,${H0}{%k7}{z}\t# smash hash value\n\tvpermq\t\t\\$0b01010101,$Dlo,${H1}{%k7}{z}\n\tvpermq\t\t\\$0b10101010,$Dlo,${H2}{%k7}{z}\n\n\tvpxord\t\t$Dlo,$Dlo,$Dlo\n\tvpxord\t\t$Dhi,$Dhi,$Dhi\n\n\tvpmadd52luq\t$r2r1r0,$H0,$Dlo\n\tvpmadd52huq\t$r2r1r0,$H0,$Dhi\n\n\tvpmadd52luq\t$r1r0s2,$H1,$Dlo\n\tvpmadd52huq\t$r1r0s2,$H1,$Dhi\n\n\tvpmadd52luq\t$r0s2s1,$H2,$Dlo\n\tvpmadd52huq\t$r0s2s1,$H2,$Dhi\n\n\tvpsrlvq\t\t$reduc_rght,$Dlo,$T0\t# 0 in topmost qword\n\tvpsllvq\t\t$reduc_left,$Dhi,$Dhi\t# 0 in topmost qword\n\tvpandq\t\t$reduc_mask,$Dlo,$Dlo\n\n\tvpaddq\t\t$T0,$Dhi,$Dhi\n\n\tvpermq\t\t\\$0b10010011,$Dhi,$Dhi\t# 0 in lowest qword\n\n\tvpaddq\t\t$Dhi,$Dlo,$Dlo\t\t# note topmost qword :-)\n\n\tvpsrlvq\t\t$reduc_rght,$Dlo,$T0\t# 0 in topmost word\n\tvpandq\t\t$reduc_mask,$Dlo,$Dlo\n\n\tvpermq\t\t\\$0b10010011,$T0,$T0\n\n\tvpaddq\t\t$T0,$Dlo,$Dlo\n\n\tvpermq\t\t\\$0b10010011,$Dlo,${T0}{%k1}{z}\n\n\tvpaddq\t\t$T0,$Dlo,$Dlo\n\tvpsllq\t\t\\$2,$T0,$T0\n\n\tvpaddq\t\t$T0,$Dlo,$Dlo\n\n\tdec\t\t%rax\t\t\t# len-=16\n\tjnz\t\t.Loop_vpmadd52\n\n\tvmovdqu64\t$Dlo,0($ctx){%k7}\t# store hash value\n\n\ttest\t\t$len,$len\n\tjnz\t\t.Lblocks_vpmadd52_4x\n\n.Lno_data_vpmadd52:\n\tRET\n.size\tpoly1305_blocks_vpmadd52,.-poly1305_blocks_vpmadd52\n___\n}\n{\n########################################################################\n# As implied by its name 4x subroutine processes 4 blocks in parallel\n# (but handles even 4*n+2 blocks lengths). It takes up to 4th key power\n# and is handled in 256-bit %ymm registers.\n\nmy ($H0,$H1,$H2,$R0,$R1,$R2,$S1,$S2) = map(\"%ymm$_\",(0..5,16,17));\nmy ($D0lo,$D0hi,$D1lo,$D1hi,$D2lo,$D2hi) = map(\"%ymm$_\",(18..23));\nmy ($T0,$T1,$T2,$T3,$mask44,$mask42,$tmp,$PAD) = map(\"%ymm$_\",(24..31));\n\n$code.=<<___;\n.type\tpoly1305_blocks_vpmadd52_4x,\\@function,4\n.align\t32\npoly1305_blocks_vpmadd52_4x:\n\tshr\t\\$4,$len\n\tjz\t.Lno_data_vpmadd52_4x\t\t# too short\n\n\tshl\t\\$40,$padbit\n\tmov\t64($ctx),%r8\t\t\t# peek on power of the key\n\n.Lblocks_vpmadd52_4x:\n\tvpbroadcastq\t$padbit,$PAD\n\n\tvmovdqa64\t.Lx_mask44(%rip),$mask44\n\tmov\t\t\\$5,%eax\n\tvmovdqa64\t.Lx_mask42(%rip),$mask42\n\tkmovw\t\t%eax,%k1\t\t# used in 2x path\n\n\ttest\t\t%r8,%r8\t\t\t# is power value impossible?\n\tjs\t\t.Linit_vpmadd52\t\t# if it is, then init R[4]\n\n\tvmovq\t\t0($ctx),%x#$H0\t\t# load current hash value\n\tvmovq\t\t8($ctx),%x#$H1\n\tvmovq\t\t16($ctx),%x#$H2\n\n\ttest\t\t\\$3,$len\t\t# is length 4*n+2?\n\tjnz\t\t.Lblocks_vpmadd52_2x_do\n\n.Lblocks_vpmadd52_4x_do:\n\tvpbroadcastq\t64($ctx),$R0\t\t# load 4th power of the key\n\tvpbroadcastq\t96($ctx),$R1\n\tvpbroadcastq\t128($ctx),$R2\n\tvpbroadcastq\t160($ctx),$S1\n\n.Lblocks_vpmadd52_4x_key_loaded:\n\tvpsllq\t\t\\$2,$R2,$S2\t\t# S2 = R2*5*4\n\tvpaddq\t\t$R2,$S2,$S2\n\tvpsllq\t\t\\$2,$S2,$S2\n\n\ttest\t\t\\$7,$len\t\t# is len 8*n?\n\tjz\t\t.Lblocks_vpmadd52_8x\n\n\tvmovdqu64\t16*0($inp),$T2\t\t# load data\n\tvmovdqu64\t16*2($inp),$T3\n\tlea\t\t16*4($inp),$inp\n\n\tvpunpcklqdq\t$T3,$T2,$T1\t\t# transpose data\n\tvpunpckhqdq\t$T3,$T2,$T3\n\n\t# at this point 64-bit lanes are ordered as 3-1-2-0\n\n\tvpsrlq\t\t\\$24,$T3,$T2\t\t# splat the data\n\tvporq\t\t$PAD,$T2,$T2\n\t vpaddq\t\t$T2,$H2,$H2\t\t# accumulate input\n\tvpandq\t\t$mask44,$T1,$T0\n\tvpsrlq\t\t\\$44,$T1,$T1\n\tvpsllq\t\t\\$20,$T3,$T3\n\tvporq\t\t$T3,$T1,$T1\n\tvpandq\t\t$mask44,$T1,$T1\n\n\tsub\t\t\\$4,$len\n\tjz\t\t.Ltail_vpmadd52_4x\n\tjmp\t\t.Loop_vpmadd52_4x\n\tud2\n\n.align\t32\n.Linit_vpmadd52:\n\tvmovq\t\t24($ctx),%x#$S1\t\t# load key\n\tvmovq\t\t56($ctx),%x#$H2\n\tvmovq\t\t32($ctx),%x#$S2\n\tvmovq\t\t40($ctx),%x#$R0\n\tvmovq\t\t48($ctx),%x#$R1\n\n\tvmovdqa\t\t$R0,$H0\n\tvmovdqa\t\t$R1,$H1\n\tvmovdqa\t\t$H2,$R2\n\n\tmov\t\t\\$2,%eax\n\n.Lmul_init_vpmadd52:\n\tvpxorq\t\t$D0lo,$D0lo,$D0lo\n\tvpmadd52luq\t$H2,$S1,$D0lo\n\tvpxorq\t\t$D0hi,$D0hi,$D0hi\n\tvpmadd52huq\t$H2,$S1,$D0hi\n\tvpxorq\t\t$D1lo,$D1lo,$D1lo\n\tvpmadd52luq\t$H2,$S2,$D1lo\n\tvpxorq\t\t$D1hi,$D1hi,$D1hi\n\tvpmadd52huq\t$H2,$S2,$D1hi\n\tvpxorq\t\t$D2lo,$D2lo,$D2lo\n\tvpmadd52luq\t$H2,$R0,$D2lo\n\tvpxorq\t\t$D2hi,$D2hi,$D2hi\n\tvpmadd52huq\t$H2,$R0,$D2hi\n\n\tvpmadd52luq\t$H0,$R0,$D0lo\n\tvpmadd52huq\t$H0,$R0,$D0hi\n\tvpmadd52luq\t$H0,$R1,$D1lo\n\tvpmadd52huq\t$H0,$R1,$D1hi\n\tvpmadd52luq\t$H0,$R2,$D2lo\n\tvpmadd52huq\t$H0,$R2,$D2hi\n\n\tvpmadd52luq\t$H1,$S2,$D0lo\n\tvpmadd52huq\t$H1,$S2,$D0hi\n\tvpmadd52luq\t$H1,$R0,$D1lo\n\tvpmadd52huq\t$H1,$R0,$D1hi\n\tvpmadd52luq\t$H1,$R1,$D2lo\n\tvpmadd52huq\t$H1,$R1,$D2hi\n\n\t################################################################\n\t# partial reduction\n\tvpsrlq\t\t\\$44,$D0lo,$tmp\n\tvpsllq\t\t\\$8,$D0hi,$D0hi\n\tvpandq\t\t$mask44,$D0lo,$H0\n\tvpaddq\t\t$tmp,$D0hi,$D0hi\n\n\tvpaddq\t\t$D0hi,$D1lo,$D1lo\n\n\tvpsrlq\t\t\\$44,$D1lo,$tmp\n\tvpsllq\t\t\\$8,$D1hi,$D1hi\n\tvpandq\t\t$mask44,$D1lo,$H1\n\tvpaddq\t\t$tmp,$D1hi,$D1hi\n\n\tvpaddq\t\t$D1hi,$D2lo,$D2lo\n\n\tvpsrlq\t\t\\$42,$D2lo,$tmp\n\tvpsllq\t\t\\$10,$D2hi,$D2hi\n\tvpandq\t\t$mask42,$D2lo,$H2\n\tvpaddq\t\t$tmp,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$H0,$H0\n\tvpsllq\t\t\\$2,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$H0,$H0\n\n\tvpsrlq\t\t\\$44,$H0,$tmp\t\t# additional step\n\tvpandq\t\t$mask44,$H0,$H0\n\n\tvpaddq\t\t$tmp,$H1,$H1\n\n\tdec\t\t%eax\n\tjz\t\t.Ldone_init_vpmadd52\n\n\tvpunpcklqdq\t$R1,$H1,$R1\t\t# 1,2\n\tvpbroadcastq\t%x#$H1,%x#$H1\t\t# 2,2\n\tvpunpcklqdq\t$R2,$H2,$R2\n\tvpbroadcastq\t%x#$H2,%x#$H2\n\tvpunpcklqdq\t$R0,$H0,$R0\n\tvpbroadcastq\t%x#$H0,%x#$H0\n\n\tvpsllq\t\t\\$2,$R1,$S1\t\t# S1 = R1*5*4\n\tvpsllq\t\t\\$2,$R2,$S2\t\t# S2 = R2*5*4\n\tvpaddq\t\t$R1,$S1,$S1\n\tvpaddq\t\t$R2,$S2,$S2\n\tvpsllq\t\t\\$2,$S1,$S1\n\tvpsllq\t\t\\$2,$S2,$S2\n\n\tjmp\t\t.Lmul_init_vpmadd52\n\tud2\n\n.align\t32\n.Ldone_init_vpmadd52:\n\tvinserti128\t\\$1,%x#$R1,$H1,$R1\t# 1,2,3,4\n\tvinserti128\t\\$1,%x#$R2,$H2,$R2\n\tvinserti128\t\\$1,%x#$R0,$H0,$R0\n\n\tvpermq\t\t\\$0b11011000,$R1,$R1\t# 1,3,2,4\n\tvpermq\t\t\\$0b11011000,$R2,$R2\n\tvpermq\t\t\\$0b11011000,$R0,$R0\n\n\tvpsllq\t\t\\$2,$R1,$S1\t\t# S1 = R1*5*4\n\tvpaddq\t\t$R1,$S1,$S1\n\tvpsllq\t\t\\$2,$S1,$S1\n\n\tvmovq\t\t0($ctx),%x#$H0\t\t# load current hash value\n\tvmovq\t\t8($ctx),%x#$H1\n\tvmovq\t\t16($ctx),%x#$H2\n\n\ttest\t\t\\$3,$len\t\t# is length 4*n+2?\n\tjnz\t\t.Ldone_init_vpmadd52_2x\n\n\tvmovdqu64\t$R0,64($ctx)\t\t# save key powers\n\tvpbroadcastq\t%x#$R0,$R0\t\t# broadcast 4th power\n\tvmovdqu64\t$R1,96($ctx)\n\tvpbroadcastq\t%x#$R1,$R1\n\tvmovdqu64\t$R2,128($ctx)\n\tvpbroadcastq\t%x#$R2,$R2\n\tvmovdqu64\t$S1,160($ctx)\n\tvpbroadcastq\t%x#$S1,$S1\n\n\tjmp\t\t.Lblocks_vpmadd52_4x_key_loaded\n\tud2\n\n.align\t32\n.Ldone_init_vpmadd52_2x:\n\tvmovdqu64\t$R0,64($ctx)\t\t# save key powers\n\tvpsrldq\t\t\\$8,$R0,$R0\t\t# 0-1-0-2\n\tvmovdqu64\t$R1,96($ctx)\n\tvpsrldq\t\t\\$8,$R1,$R1\n\tvmovdqu64\t$R2,128($ctx)\n\tvpsrldq\t\t\\$8,$R2,$R2\n\tvmovdqu64\t$S1,160($ctx)\n\tvpsrldq\t\t\\$8,$S1,$S1\n\tjmp\t\t.Lblocks_vpmadd52_2x_key_loaded\n\tud2\n\n.align\t32\n.Lblocks_vpmadd52_2x_do:\n\tvmovdqu64\t128+8($ctx),${R2}{%k1}{z}# load 2nd and 1st key powers\n\tvmovdqu64\t160+8($ctx),${S1}{%k1}{z}\n\tvmovdqu64\t64+8($ctx),${R0}{%k1}{z}\n\tvmovdqu64\t96+8($ctx),${R1}{%k1}{z}\n\n.Lblocks_vpmadd52_2x_key_loaded:\n\tvmovdqu64\t16*0($inp),$T2\t\t# load data\n\tvpxorq\t\t$T3,$T3,$T3\n\tlea\t\t16*2($inp),$inp\n\n\tvpunpcklqdq\t$T3,$T2,$T1\t\t# transpose data\n\tvpunpckhqdq\t$T3,$T2,$T3\n\n\t# at this point 64-bit lanes are ordered as x-1-x-0\n\n\tvpsrlq\t\t\\$24,$T3,$T2\t\t# splat the data\n\tvporq\t\t$PAD,$T2,$T2\n\t vpaddq\t\t$T2,$H2,$H2\t\t# accumulate input\n\tvpandq\t\t$mask44,$T1,$T0\n\tvpsrlq\t\t\\$44,$T1,$T1\n\tvpsllq\t\t\\$20,$T3,$T3\n\tvporq\t\t$T3,$T1,$T1\n\tvpandq\t\t$mask44,$T1,$T1\n\n\tjmp\t\t.Ltail_vpmadd52_2x\n\tud2\n\n.align\t32\n.Loop_vpmadd52_4x:\n\t#vpaddq\t\t$T2,$H2,$H2\t\t# accumulate input\n\tvpaddq\t\t$T0,$H0,$H0\n\tvpaddq\t\t$T1,$H1,$H1\n\n\tvpxorq\t\t$D0lo,$D0lo,$D0lo\n\tvpmadd52luq\t$H2,$S1,$D0lo\n\tvpxorq\t\t$D0hi,$D0hi,$D0hi\n\tvpmadd52huq\t$H2,$S1,$D0hi\n\tvpxorq\t\t$D1lo,$D1lo,$D1lo\n\tvpmadd52luq\t$H2,$S2,$D1lo\n\tvpxorq\t\t$D1hi,$D1hi,$D1hi\n\tvpmadd52huq\t$H2,$S2,$D1hi\n\tvpxorq\t\t$D2lo,$D2lo,$D2lo\n\tvpmadd52luq\t$H2,$R0,$D2lo\n\tvpxorq\t\t$D2hi,$D2hi,$D2hi\n\tvpmadd52huq\t$H2,$R0,$D2hi\n\n\t vmovdqu64\t16*0($inp),$T2\t\t# load data\n\t vmovdqu64\t16*2($inp),$T3\n\t lea\t\t16*4($inp),$inp\n\tvpmadd52luq\t$H0,$R0,$D0lo\n\tvpmadd52huq\t$H0,$R0,$D0hi\n\tvpmadd52luq\t$H0,$R1,$D1lo\n\tvpmadd52huq\t$H0,$R1,$D1hi\n\tvpmadd52luq\t$H0,$R2,$D2lo\n\tvpmadd52huq\t$H0,$R2,$D2hi\n\n\t vpunpcklqdq\t$T3,$T2,$T1\t\t# transpose data\n\t vpunpckhqdq\t$T3,$T2,$T3\n\tvpmadd52luq\t$H1,$S2,$D0lo\n\tvpmadd52huq\t$H1,$S2,$D0hi\n\tvpmadd52luq\t$H1,$R0,$D1lo\n\tvpmadd52huq\t$H1,$R0,$D1hi\n\tvpmadd52luq\t$H1,$R1,$D2lo\n\tvpmadd52huq\t$H1,$R1,$D2hi\n\n\t################################################################\n\t# partial reduction (interleaved with data splat)\n\tvpsrlq\t\t\\$44,$D0lo,$tmp\n\tvpsllq\t\t\\$8,$D0hi,$D0hi\n\tvpandq\t\t$mask44,$D0lo,$H0\n\tvpaddq\t\t$tmp,$D0hi,$D0hi\n\n\t vpsrlq\t\t\\$24,$T3,$T2\n\t vporq\t\t$PAD,$T2,$T2\n\tvpaddq\t\t$D0hi,$D1lo,$D1lo\n\n\tvpsrlq\t\t\\$44,$D1lo,$tmp\n\tvpsllq\t\t\\$8,$D1hi,$D1hi\n\tvpandq\t\t$mask44,$D1lo,$H1\n\tvpaddq\t\t$tmp,$D1hi,$D1hi\n\n\t vpandq\t\t$mask44,$T1,$T0\n\t vpsrlq\t\t\\$44,$T1,$T1\n\t vpsllq\t\t\\$20,$T3,$T3\n\tvpaddq\t\t$D1hi,$D2lo,$D2lo\n\n\tvpsrlq\t\t\\$42,$D2lo,$tmp\n\tvpsllq\t\t\\$10,$D2hi,$D2hi\n\tvpandq\t\t$mask42,$D2lo,$H2\n\tvpaddq\t\t$tmp,$D2hi,$D2hi\n\n\t  vpaddq\t$T2,$H2,$H2\t\t# accumulate input\n\tvpaddq\t\t$D2hi,$H0,$H0\n\tvpsllq\t\t\\$2,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$H0,$H0\n\t vporq\t\t$T3,$T1,$T1\n\t vpandq\t\t$mask44,$T1,$T1\n\n\tvpsrlq\t\t\\$44,$H0,$tmp\t\t# additional step\n\tvpandq\t\t$mask44,$H0,$H0\n\n\tvpaddq\t\t$tmp,$H1,$H1\n\n\tsub\t\t\\$4,$len\t\t# len-=64\n\tjnz\t\t.Loop_vpmadd52_4x\n\n.Ltail_vpmadd52_4x:\n\tvmovdqu64\t128($ctx),$R2\t\t# load all key powers\n\tvmovdqu64\t160($ctx),$S1\n\tvmovdqu64\t64($ctx),$R0\n\tvmovdqu64\t96($ctx),$R1\n\n.Ltail_vpmadd52_2x:\n\tvpsllq\t\t\\$2,$R2,$S2\t\t# S2 = R2*5*4\n\tvpaddq\t\t$R2,$S2,$S2\n\tvpsllq\t\t\\$2,$S2,$S2\n\n\t#vpaddq\t\t$T2,$H2,$H2\t\t# accumulate input\n\tvpaddq\t\t$T0,$H0,$H0\n\tvpaddq\t\t$T1,$H1,$H1\n\n\tvpxorq\t\t$D0lo,$D0lo,$D0lo\n\tvpmadd52luq\t$H2,$S1,$D0lo\n\tvpxorq\t\t$D0hi,$D0hi,$D0hi\n\tvpmadd52huq\t$H2,$S1,$D0hi\n\tvpxorq\t\t$D1lo,$D1lo,$D1lo\n\tvpmadd52luq\t$H2,$S2,$D1lo\n\tvpxorq\t\t$D1hi,$D1hi,$D1hi\n\tvpmadd52huq\t$H2,$S2,$D1hi\n\tvpxorq\t\t$D2lo,$D2lo,$D2lo\n\tvpmadd52luq\t$H2,$R0,$D2lo\n\tvpxorq\t\t$D2hi,$D2hi,$D2hi\n\tvpmadd52huq\t$H2,$R0,$D2hi\n\n\tvpmadd52luq\t$H0,$R0,$D0lo\n\tvpmadd52huq\t$H0,$R0,$D0hi\n\tvpmadd52luq\t$H0,$R1,$D1lo\n\tvpmadd52huq\t$H0,$R1,$D1hi\n\tvpmadd52luq\t$H0,$R2,$D2lo\n\tvpmadd52huq\t$H0,$R2,$D2hi\n\n\tvpmadd52luq\t$H1,$S2,$D0lo\n\tvpmadd52huq\t$H1,$S2,$D0hi\n\tvpmadd52luq\t$H1,$R0,$D1lo\n\tvpmadd52huq\t$H1,$R0,$D1hi\n\tvpmadd52luq\t$H1,$R1,$D2lo\n\tvpmadd52huq\t$H1,$R1,$D2hi\n\n\t################################################################\n\t# horizontal addition\n\n\tmov\t\t\\$1,%eax\n\tkmovw\t\t%eax,%k1\n\tvpsrldq\t\t\\$8,$D0lo,$T0\n\tvpsrldq\t\t\\$8,$D0hi,$H0\n\tvpsrldq\t\t\\$8,$D1lo,$T1\n\tvpsrldq\t\t\\$8,$D1hi,$H1\n\tvpaddq\t\t$T0,$D0lo,$D0lo\n\tvpaddq\t\t$H0,$D0hi,$D0hi\n\tvpsrldq\t\t\\$8,$D2lo,$T2\n\tvpsrldq\t\t\\$8,$D2hi,$H2\n\tvpaddq\t\t$T1,$D1lo,$D1lo\n\tvpaddq\t\t$H1,$D1hi,$D1hi\n\t vpermq\t\t\\$0x2,$D0lo,$T0\n\t vpermq\t\t\\$0x2,$D0hi,$H0\n\tvpaddq\t\t$T2,$D2lo,$D2lo\n\tvpaddq\t\t$H2,$D2hi,$D2hi\n\n\tvpermq\t\t\\$0x2,$D1lo,$T1\n\tvpermq\t\t\\$0x2,$D1hi,$H1\n\tvpaddq\t\t$T0,$D0lo,${D0lo}{%k1}{z}\n\tvpaddq\t\t$H0,$D0hi,${D0hi}{%k1}{z}\n\tvpermq\t\t\\$0x2,$D2lo,$T2\n\tvpermq\t\t\\$0x2,$D2hi,$H2\n\tvpaddq\t\t$T1,$D1lo,${D1lo}{%k1}{z}\n\tvpaddq\t\t$H1,$D1hi,${D1hi}{%k1}{z}\n\tvpaddq\t\t$T2,$D2lo,${D2lo}{%k1}{z}\n\tvpaddq\t\t$H2,$D2hi,${D2hi}{%k1}{z}\n\n\t################################################################\n\t# partial reduction\n\tvpsrlq\t\t\\$44,$D0lo,$tmp\n\tvpsllq\t\t\\$8,$D0hi,$D0hi\n\tvpandq\t\t$mask44,$D0lo,$H0\n\tvpaddq\t\t$tmp,$D0hi,$D0hi\n\n\tvpaddq\t\t$D0hi,$D1lo,$D1lo\n\n\tvpsrlq\t\t\\$44,$D1lo,$tmp\n\tvpsllq\t\t\\$8,$D1hi,$D1hi\n\tvpandq\t\t$mask44,$D1lo,$H1\n\tvpaddq\t\t$tmp,$D1hi,$D1hi\n\n\tvpaddq\t\t$D1hi,$D2lo,$D2lo\n\n\tvpsrlq\t\t\\$42,$D2lo,$tmp\n\tvpsllq\t\t\\$10,$D2hi,$D2hi\n\tvpandq\t\t$mask42,$D2lo,$H2\n\tvpaddq\t\t$tmp,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$H0,$H0\n\tvpsllq\t\t\\$2,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$H0,$H0\n\n\tvpsrlq\t\t\\$44,$H0,$tmp\t\t# additional step\n\tvpandq\t\t$mask44,$H0,$H0\n\n\tvpaddq\t\t$tmp,$H1,$H1\n\t\t\t\t\t\t# at this point $len is\n\t\t\t\t\t\t# either 4*n+2 or 0...\n\tsub\t\t\\$2,$len\t\t# len-=32\n\tja\t\t.Lblocks_vpmadd52_4x_do\n\n\tvmovq\t\t%x#$H0,0($ctx)\n\tvmovq\t\t%x#$H1,8($ctx)\n\tvmovq\t\t%x#$H2,16($ctx)\n\tvzeroall\n\n.Lno_data_vpmadd52_4x:\n\tRET\n.size\tpoly1305_blocks_vpmadd52_4x,.-poly1305_blocks_vpmadd52_4x\n___\n}\n{\n########################################################################\n# As implied by its name 8x subroutine processes 8 blocks in parallel...\n# This is intermediate version, as it's used only in cases when input\n# length is either 8*n, 8*n+1 or 8*n+2...\n\nmy ($H0,$H1,$H2,$R0,$R1,$R2,$S1,$S2) = map(\"%ymm$_\",(0..5,16,17));\nmy ($D0lo,$D0hi,$D1lo,$D1hi,$D2lo,$D2hi) = map(\"%ymm$_\",(18..23));\nmy ($T0,$T1,$T2,$T3,$mask44,$mask42,$tmp,$PAD) = map(\"%ymm$_\",(24..31));\nmy ($RR0,$RR1,$RR2,$SS1,$SS2) = map(\"%ymm$_\",(6..10));\n\n$code.=<<___;\n.type\tpoly1305_blocks_vpmadd52_8x,\\@function,4\n.align\t32\npoly1305_blocks_vpmadd52_8x:\n\tshr\t\\$4,$len\n\tjz\t.Lno_data_vpmadd52_8x\t\t# too short\n\n\tshl\t\\$40,$padbit\n\tmov\t64($ctx),%r8\t\t\t# peek on power of the key\n\n\tvmovdqa64\t.Lx_mask44(%rip),$mask44\n\tvmovdqa64\t.Lx_mask42(%rip),$mask42\n\n\ttest\t%r8,%r8\t\t\t\t# is power value impossible?\n\tjs\t.Linit_vpmadd52\t\t\t# if it is, then init R[4]\n\n\tvmovq\t0($ctx),%x#$H0\t\t\t# load current hash value\n\tvmovq\t8($ctx),%x#$H1\n\tvmovq\t16($ctx),%x#$H2\n\n.Lblocks_vpmadd52_8x:\n\t################################################################\n\t# fist we calculate more key powers\n\n\tvmovdqu64\t128($ctx),$R2\t\t# load 1-3-2-4 powers\n\tvmovdqu64\t160($ctx),$S1\n\tvmovdqu64\t64($ctx),$R0\n\tvmovdqu64\t96($ctx),$R1\n\n\tvpsllq\t\t\\$2,$R2,$S2\t\t# S2 = R2*5*4\n\tvpaddq\t\t$R2,$S2,$S2\n\tvpsllq\t\t\\$2,$S2,$S2\n\n\tvpbroadcastq\t%x#$R2,$RR2\t\t# broadcast 4th power\n\tvpbroadcastq\t%x#$R0,$RR0\n\tvpbroadcastq\t%x#$R1,$RR1\n\n\tvpxorq\t\t$D0lo,$D0lo,$D0lo\n\tvpmadd52luq\t$RR2,$S1,$D0lo\n\tvpxorq\t\t$D0hi,$D0hi,$D0hi\n\tvpmadd52huq\t$RR2,$S1,$D0hi\n\tvpxorq\t\t$D1lo,$D1lo,$D1lo\n\tvpmadd52luq\t$RR2,$S2,$D1lo\n\tvpxorq\t\t$D1hi,$D1hi,$D1hi\n\tvpmadd52huq\t$RR2,$S2,$D1hi\n\tvpxorq\t\t$D2lo,$D2lo,$D2lo\n\tvpmadd52luq\t$RR2,$R0,$D2lo\n\tvpxorq\t\t$D2hi,$D2hi,$D2hi\n\tvpmadd52huq\t$RR2,$R0,$D2hi\n\n\tvpmadd52luq\t$RR0,$R0,$D0lo\n\tvpmadd52huq\t$RR0,$R0,$D0hi\n\tvpmadd52luq\t$RR0,$R1,$D1lo\n\tvpmadd52huq\t$RR0,$R1,$D1hi\n\tvpmadd52luq\t$RR0,$R2,$D2lo\n\tvpmadd52huq\t$RR0,$R2,$D2hi\n\n\tvpmadd52luq\t$RR1,$S2,$D0lo\n\tvpmadd52huq\t$RR1,$S2,$D0hi\n\tvpmadd52luq\t$RR1,$R0,$D1lo\n\tvpmadd52huq\t$RR1,$R0,$D1hi\n\tvpmadd52luq\t$RR1,$R1,$D2lo\n\tvpmadd52huq\t$RR1,$R1,$D2hi\n\n\t################################################################\n\t# partial reduction\n\tvpsrlq\t\t\\$44,$D0lo,$tmp\n\tvpsllq\t\t\\$8,$D0hi,$D0hi\n\tvpandq\t\t$mask44,$D0lo,$RR0\n\tvpaddq\t\t$tmp,$D0hi,$D0hi\n\n\tvpaddq\t\t$D0hi,$D1lo,$D1lo\n\n\tvpsrlq\t\t\\$44,$D1lo,$tmp\n\tvpsllq\t\t\\$8,$D1hi,$D1hi\n\tvpandq\t\t$mask44,$D1lo,$RR1\n\tvpaddq\t\t$tmp,$D1hi,$D1hi\n\n\tvpaddq\t\t$D1hi,$D2lo,$D2lo\n\n\tvpsrlq\t\t\\$42,$D2lo,$tmp\n\tvpsllq\t\t\\$10,$D2hi,$D2hi\n\tvpandq\t\t$mask42,$D2lo,$RR2\n\tvpaddq\t\t$tmp,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$RR0,$RR0\n\tvpsllq\t\t\\$2,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$RR0,$RR0\n\n\tvpsrlq\t\t\\$44,$RR0,$tmp\t\t# additional step\n\tvpandq\t\t$mask44,$RR0,$RR0\n\n\tvpaddq\t\t$tmp,$RR1,$RR1\n\n\t################################################################\n\t# At this point Rx holds 1324 powers, RRx - 5768, and the goal\n\t# is 15263748, which reflects how data is loaded...\n\n\tvpunpcklqdq\t$R2,$RR2,$T2\t\t# 3748\n\tvpunpckhqdq\t$R2,$RR2,$R2\t\t# 1526\n\tvpunpcklqdq\t$R0,$RR0,$T0\n\tvpunpckhqdq\t$R0,$RR0,$R0\n\tvpunpcklqdq\t$R1,$RR1,$T1\n\tvpunpckhqdq\t$R1,$RR1,$R1\n___\n######## switch to %zmm\nmap(s/%y/%z/, $H0,$H1,$H2,$R0,$R1,$R2,$S1,$S2);\nmap(s/%y/%z/, $D0lo,$D0hi,$D1lo,$D1hi,$D2lo,$D2hi);\nmap(s/%y/%z/, $T0,$T1,$T2,$T3,$mask44,$mask42,$tmp,$PAD);\nmap(s/%y/%z/, $RR0,$RR1,$RR2,$SS1,$SS2);\n\n$code.=<<___;\n\tvshufi64x2\t\\$0x44,$R2,$T2,$RR2\t# 15263748\n\tvshufi64x2\t\\$0x44,$R0,$T0,$RR0\n\tvshufi64x2\t\\$0x44,$R1,$T1,$RR1\n\n\tvmovdqu64\t16*0($inp),$T2\t\t# load data\n\tvmovdqu64\t16*4($inp),$T3\n\tlea\t\t16*8($inp),$inp\n\n\tvpsllq\t\t\\$2,$RR2,$SS2\t\t# S2 = R2*5*4\n\tvpsllq\t\t\\$2,$RR1,$SS1\t\t# S1 = R1*5*4\n\tvpaddq\t\t$RR2,$SS2,$SS2\n\tvpaddq\t\t$RR1,$SS1,$SS1\n\tvpsllq\t\t\\$2,$SS2,$SS2\n\tvpsllq\t\t\\$2,$SS1,$SS1\n\n\tvpbroadcastq\t$padbit,$PAD\n\tvpbroadcastq\t%x#$mask44,$mask44\n\tvpbroadcastq\t%x#$mask42,$mask42\n\n\tvpbroadcastq\t%x#$SS1,$S1\t\t# broadcast 8th power\n\tvpbroadcastq\t%x#$SS2,$S2\n\tvpbroadcastq\t%x#$RR0,$R0\n\tvpbroadcastq\t%x#$RR1,$R1\n\tvpbroadcastq\t%x#$RR2,$R2\n\n\tvpunpcklqdq\t$T3,$T2,$T1\t\t# transpose data\n\tvpunpckhqdq\t$T3,$T2,$T3\n\n\t# at this point 64-bit lanes are ordered as 73625140\n\n\tvpsrlq\t\t\\$24,$T3,$T2\t\t# splat the data\n\tvporq\t\t$PAD,$T2,$T2\n\t vpaddq\t\t$T2,$H2,$H2\t\t# accumulate input\n\tvpandq\t\t$mask44,$T1,$T0\n\tvpsrlq\t\t\\$44,$T1,$T1\n\tvpsllq\t\t\\$20,$T3,$T3\n\tvporq\t\t$T3,$T1,$T1\n\tvpandq\t\t$mask44,$T1,$T1\n\n\tsub\t\t\\$8,$len\n\tjz\t\t.Ltail_vpmadd52_8x\n\tjmp\t\t.Loop_vpmadd52_8x\n\n.align\t32\n.Loop_vpmadd52_8x:\n\t#vpaddq\t\t$T2,$H2,$H2\t\t# accumulate input\n\tvpaddq\t\t$T0,$H0,$H0\n\tvpaddq\t\t$T1,$H1,$H1\n\n\tvpxorq\t\t$D0lo,$D0lo,$D0lo\n\tvpmadd52luq\t$H2,$S1,$D0lo\n\tvpxorq\t\t$D0hi,$D0hi,$D0hi\n\tvpmadd52huq\t$H2,$S1,$D0hi\n\tvpxorq\t\t$D1lo,$D1lo,$D1lo\n\tvpmadd52luq\t$H2,$S2,$D1lo\n\tvpxorq\t\t$D1hi,$D1hi,$D1hi\n\tvpmadd52huq\t$H2,$S2,$D1hi\n\tvpxorq\t\t$D2lo,$D2lo,$D2lo\n\tvpmadd52luq\t$H2,$R0,$D2lo\n\tvpxorq\t\t$D2hi,$D2hi,$D2hi\n\tvpmadd52huq\t$H2,$R0,$D2hi\n\n\t vmovdqu64\t16*0($inp),$T2\t\t# load data\n\t vmovdqu64\t16*4($inp),$T3\n\t lea\t\t16*8($inp),$inp\n\tvpmadd52luq\t$H0,$R0,$D0lo\n\tvpmadd52huq\t$H0,$R0,$D0hi\n\tvpmadd52luq\t$H0,$R1,$D1lo\n\tvpmadd52huq\t$H0,$R1,$D1hi\n\tvpmadd52luq\t$H0,$R2,$D2lo\n\tvpmadd52huq\t$H0,$R2,$D2hi\n\n\t vpunpcklqdq\t$T3,$T2,$T1\t\t# transpose data\n\t vpunpckhqdq\t$T3,$T2,$T3\n\tvpmadd52luq\t$H1,$S2,$D0lo\n\tvpmadd52huq\t$H1,$S2,$D0hi\n\tvpmadd52luq\t$H1,$R0,$D1lo\n\tvpmadd52huq\t$H1,$R0,$D1hi\n\tvpmadd52luq\t$H1,$R1,$D2lo\n\tvpmadd52huq\t$H1,$R1,$D2hi\n\n\t################################################################\n\t# partial reduction (interleaved with data splat)\n\tvpsrlq\t\t\\$44,$D0lo,$tmp\n\tvpsllq\t\t\\$8,$D0hi,$D0hi\n\tvpandq\t\t$mask44,$D0lo,$H0\n\tvpaddq\t\t$tmp,$D0hi,$D0hi\n\n\t vpsrlq\t\t\\$24,$T3,$T2\n\t vporq\t\t$PAD,$T2,$T2\n\tvpaddq\t\t$D0hi,$D1lo,$D1lo\n\n\tvpsrlq\t\t\\$44,$D1lo,$tmp\n\tvpsllq\t\t\\$8,$D1hi,$D1hi\n\tvpandq\t\t$mask44,$D1lo,$H1\n\tvpaddq\t\t$tmp,$D1hi,$D1hi\n\n\t vpandq\t\t$mask44,$T1,$T0\n\t vpsrlq\t\t\\$44,$T1,$T1\n\t vpsllq\t\t\\$20,$T3,$T3\n\tvpaddq\t\t$D1hi,$D2lo,$D2lo\n\n\tvpsrlq\t\t\\$42,$D2lo,$tmp\n\tvpsllq\t\t\\$10,$D2hi,$D2hi\n\tvpandq\t\t$mask42,$D2lo,$H2\n\tvpaddq\t\t$tmp,$D2hi,$D2hi\n\n\t  vpaddq\t$T2,$H2,$H2\t\t# accumulate input\n\tvpaddq\t\t$D2hi,$H0,$H0\n\tvpsllq\t\t\\$2,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$H0,$H0\n\t vporq\t\t$T3,$T1,$T1\n\t vpandq\t\t$mask44,$T1,$T1\n\n\tvpsrlq\t\t\\$44,$H0,$tmp\t\t# additional step\n\tvpandq\t\t$mask44,$H0,$H0\n\n\tvpaddq\t\t$tmp,$H1,$H1\n\n\tsub\t\t\\$8,$len\t\t# len-=128\n\tjnz\t\t.Loop_vpmadd52_8x\n\n.Ltail_vpmadd52_8x:\n\t#vpaddq\t\t$T2,$H2,$H2\t\t# accumulate input\n\tvpaddq\t\t$T0,$H0,$H0\n\tvpaddq\t\t$T1,$H1,$H1\n\n\tvpxorq\t\t$D0lo,$D0lo,$D0lo\n\tvpmadd52luq\t$H2,$SS1,$D0lo\n\tvpxorq\t\t$D0hi,$D0hi,$D0hi\n\tvpmadd52huq\t$H2,$SS1,$D0hi\n\tvpxorq\t\t$D1lo,$D1lo,$D1lo\n\tvpmadd52luq\t$H2,$SS2,$D1lo\n\tvpxorq\t\t$D1hi,$D1hi,$D1hi\n\tvpmadd52huq\t$H2,$SS2,$D1hi\n\tvpxorq\t\t$D2lo,$D2lo,$D2lo\n\tvpmadd52luq\t$H2,$RR0,$D2lo\n\tvpxorq\t\t$D2hi,$D2hi,$D2hi\n\tvpmadd52huq\t$H2,$RR0,$D2hi\n\n\tvpmadd52luq\t$H0,$RR0,$D0lo\n\tvpmadd52huq\t$H0,$RR0,$D0hi\n\tvpmadd52luq\t$H0,$RR1,$D1lo\n\tvpmadd52huq\t$H0,$RR1,$D1hi\n\tvpmadd52luq\t$H0,$RR2,$D2lo\n\tvpmadd52huq\t$H0,$RR2,$D2hi\n\n\tvpmadd52luq\t$H1,$SS2,$D0lo\n\tvpmadd52huq\t$H1,$SS2,$D0hi\n\tvpmadd52luq\t$H1,$RR0,$D1lo\n\tvpmadd52huq\t$H1,$RR0,$D1hi\n\tvpmadd52luq\t$H1,$RR1,$D2lo\n\tvpmadd52huq\t$H1,$RR1,$D2hi\n\n\t################################################################\n\t# horizontal addition\n\n\tmov\t\t\\$1,%eax\n\tkmovw\t\t%eax,%k1\n\tvpsrldq\t\t\\$8,$D0lo,$T0\n\tvpsrldq\t\t\\$8,$D0hi,$H0\n\tvpsrldq\t\t\\$8,$D1lo,$T1\n\tvpsrldq\t\t\\$8,$D1hi,$H1\n\tvpaddq\t\t$T0,$D0lo,$D0lo\n\tvpaddq\t\t$H0,$D0hi,$D0hi\n\tvpsrldq\t\t\\$8,$D2lo,$T2\n\tvpsrldq\t\t\\$8,$D2hi,$H2\n\tvpaddq\t\t$T1,$D1lo,$D1lo\n\tvpaddq\t\t$H1,$D1hi,$D1hi\n\t vpermq\t\t\\$0x2,$D0lo,$T0\n\t vpermq\t\t\\$0x2,$D0hi,$H0\n\tvpaddq\t\t$T2,$D2lo,$D2lo\n\tvpaddq\t\t$H2,$D2hi,$D2hi\n\n\tvpermq\t\t\\$0x2,$D1lo,$T1\n\tvpermq\t\t\\$0x2,$D1hi,$H1\n\tvpaddq\t\t$T0,$D0lo,$D0lo\n\tvpaddq\t\t$H0,$D0hi,$D0hi\n\tvpermq\t\t\\$0x2,$D2lo,$T2\n\tvpermq\t\t\\$0x2,$D2hi,$H2\n\tvpaddq\t\t$T1,$D1lo,$D1lo\n\tvpaddq\t\t$H1,$D1hi,$D1hi\n\t vextracti64x4\t\\$1,$D0lo,%y#$T0\n\t vextracti64x4\t\\$1,$D0hi,%y#$H0\n\tvpaddq\t\t$T2,$D2lo,$D2lo\n\tvpaddq\t\t$H2,$D2hi,$D2hi\n\n\tvextracti64x4\t\\$1,$D1lo,%y#$T1\n\tvextracti64x4\t\\$1,$D1hi,%y#$H1\n\tvextracti64x4\t\\$1,$D2lo,%y#$T2\n\tvextracti64x4\t\\$1,$D2hi,%y#$H2\n___\n######## switch back to %ymm\nmap(s/%z/%y/, $H0,$H1,$H2,$R0,$R1,$R2,$S1,$S2);\nmap(s/%z/%y/, $D0lo,$D0hi,$D1lo,$D1hi,$D2lo,$D2hi);\nmap(s/%z/%y/, $T0,$T1,$T2,$T3,$mask44,$mask42,$tmp,$PAD);\n\n$code.=<<___;\n\tvpaddq\t\t$T0,$D0lo,${D0lo}{%k1}{z}\n\tvpaddq\t\t$H0,$D0hi,${D0hi}{%k1}{z}\n\tvpaddq\t\t$T1,$D1lo,${D1lo}{%k1}{z}\n\tvpaddq\t\t$H1,$D1hi,${D1hi}{%k1}{z}\n\tvpaddq\t\t$T2,$D2lo,${D2lo}{%k1}{z}\n\tvpaddq\t\t$H2,$D2hi,${D2hi}{%k1}{z}\n\n\t################################################################\n\t# partial reduction\n\tvpsrlq\t\t\\$44,$D0lo,$tmp\n\tvpsllq\t\t\\$8,$D0hi,$D0hi\n\tvpandq\t\t$mask44,$D0lo,$H0\n\tvpaddq\t\t$tmp,$D0hi,$D0hi\n\n\tvpaddq\t\t$D0hi,$D1lo,$D1lo\n\n\tvpsrlq\t\t\\$44,$D1lo,$tmp\n\tvpsllq\t\t\\$8,$D1hi,$D1hi\n\tvpandq\t\t$mask44,$D1lo,$H1\n\tvpaddq\t\t$tmp,$D1hi,$D1hi\n\n\tvpaddq\t\t$D1hi,$D2lo,$D2lo\n\n\tvpsrlq\t\t\\$42,$D2lo,$tmp\n\tvpsllq\t\t\\$10,$D2hi,$D2hi\n\tvpandq\t\t$mask42,$D2lo,$H2\n\tvpaddq\t\t$tmp,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$H0,$H0\n\tvpsllq\t\t\\$2,$D2hi,$D2hi\n\n\tvpaddq\t\t$D2hi,$H0,$H0\n\n\tvpsrlq\t\t\\$44,$H0,$tmp\t\t# additional step\n\tvpandq\t\t$mask44,$H0,$H0\n\n\tvpaddq\t\t$tmp,$H1,$H1\n\n\t################################################################\n\n\tvmovq\t\t%x#$H0,0($ctx)\n\tvmovq\t\t%x#$H1,8($ctx)\n\tvmovq\t\t%x#$H2,16($ctx)\n\tvzeroall\n\n.Lno_data_vpmadd52_8x:\n\tRET\n.size\tpoly1305_blocks_vpmadd52_8x,.-poly1305_blocks_vpmadd52_8x\n___\n}\n$code.=<<___;\n.type\tpoly1305_emit_base2_44,\\@function,3\n.align\t32\npoly1305_emit_base2_44:\n\tmov\t0($ctx),%r8\t# load hash value\n\tmov\t8($ctx),%r9\n\tmov\t16($ctx),%r10\n\n\tmov\t%r9,%rax\n\tshr\t\\$20,%r9\n\tshl\t\\$44,%rax\n\tmov\t%r10,%rcx\n\tshr\t\\$40,%r10\n\tshl\t\\$24,%rcx\n\n\tadd\t%rax,%r8\n\tadc\t%rcx,%r9\n\tadc\t\\$0,%r10\n\n\tmov\t%r8,%rax\n\tadd\t\\$5,%r8\t\t# compare to modulus\n\tmov\t%r9,%rcx\n\tadc\t\\$0,%r9\n\tadc\t\\$0,%r10\n\tshr\t\\$2,%r10\t# did 130-bit value overflow?\n\tcmovnz\t%r8,%rax\n\tcmovnz\t%r9,%rcx\n\n\tadd\t0($nonce),%rax\t# accumulate nonce\n\tadc\t8($nonce),%rcx\n\tmov\t%rax,0($mac)\t# write result\n\tmov\t%rcx,8($mac)\n\n\tRET\n.size\tpoly1305_emit_base2_44,.-poly1305_emit_base2_44\n___\n}\t}\t}\n}\n\nif (!$kernel)\n{\t# chacha20-poly1305 helpers\nmy ($out,$inp,$otp,$len)=$win64 ? (\"%rcx\",\"%rdx\",\"%r8\", \"%r9\") :  # Win64 order\n                                  (\"%rdi\",\"%rsi\",\"%rdx\",\"%rcx\");  # Unix order\n$code.=<<___;\n.globl\txor128_encrypt_n_pad\n.type\txor128_encrypt_n_pad,\\@abi-omnipotent\n.align\t16\nxor128_encrypt_n_pad:\n\tsub\t$otp,$inp\n\tsub\t$otp,$out\n\tmov\t$len,%r10\t\t# put len aside\n\tshr\t\\$4,$len\t\t# len / 16\n\tjz\t.Ltail_enc\n\tnop\n.Loop_enc_xmm:\n\tmovdqu\t($inp,$otp),%xmm0\n\tpxor\t($otp),%xmm0\n\tmovdqu\t%xmm0,($out,$otp)\n\tmovdqa\t%xmm0,($otp)\n\tlea\t16($otp),$otp\n\tdec\t$len\n\tjnz\t.Loop_enc_xmm\n\n\tand\t\\$15,%r10\t\t# len % 16\n\tjz\t.Ldone_enc\n\n.Ltail_enc:\n\tmov\t\\$16,$len\n\tsub\t%r10,$len\n\txor\t%eax,%eax\n.Loop_enc_byte:\n\tmov\t($inp,$otp),%al\n\txor\t($otp),%al\n\tmov\t%al,($out,$otp)\n\tmov\t%al,($otp)\n\tlea\t1($otp),$otp\n\tdec\t%r10\n\tjnz\t.Loop_enc_byte\n\n\txor\t%eax,%eax\n.Loop_enc_pad:\n\tmov\t%al,($otp)\n\tlea\t1($otp),$otp\n\tdec\t$len\n\tjnz\t.Loop_enc_pad\n\n.Ldone_enc:\n\tmov\t$otp,%rax\n\tRET\n.size\txor128_encrypt_n_pad,.-xor128_encrypt_n_pad\n\n.globl\txor128_decrypt_n_pad\n.type\txor128_decrypt_n_pad,\\@abi-omnipotent\n.align\t16\nxor128_decrypt_n_pad:\n\tsub\t$otp,$inp\n\tsub\t$otp,$out\n\tmov\t$len,%r10\t\t# put len aside\n\tshr\t\\$4,$len\t\t# len / 16\n\tjz\t.Ltail_dec\n\tnop\n.Loop_dec_xmm:\n\tmovdqu\t($inp,$otp),%xmm0\n\tmovdqa\t($otp),%xmm1\n\tpxor\t%xmm0,%xmm1\n\tmovdqu\t%xmm1,($out,$otp)\n\tmovdqa\t%xmm0,($otp)\n\tlea\t16($otp),$otp\n\tdec\t$len\n\tjnz\t.Loop_dec_xmm\n\n\tpxor\t%xmm1,%xmm1\n\tand\t\\$15,%r10\t\t# len % 16\n\tjz\t.Ldone_dec\n\n.Ltail_dec:\n\tmov\t\\$16,$len\n\tsub\t%r10,$len\n\txor\t%eax,%eax\n\txor\t%r11d,%r11d\n.Loop_dec_byte:\n\tmov\t($inp,$otp),%r11b\n\tmov\t($otp),%al\n\txor\t%r11b,%al\n\tmov\t%al,($out,$otp)\n\tmov\t%r11b,($otp)\n\tlea\t1($otp),$otp\n\tdec\t%r10\n\tjnz\t.Loop_dec_byte\n\n\txor\t%eax,%eax\n.Loop_dec_pad:\n\tmov\t%al,($otp)\n\tlea\t1($otp),$otp\n\tdec\t$len\n\tjnz\t.Loop_dec_pad\n\n.Ldone_dec:\n\tmov\t$otp,%rax\n\tRET\n.size\txor128_decrypt_n_pad,.-xor128_decrypt_n_pad\n___\n}\n\n# EXCEPTION_DISPOSITION handler (EXCEPTION_RECORD *rec,ULONG64 frame,\n#\t\tCONTEXT *context,DISPATCHER_CONTEXT *disp)\nif ($win64) {\n$rec=\"%rcx\";\n$frame=\"%rdx\";\n$context=\"%r8\";\n$disp=\"%r9\";\n\n$code.=<<___;\n.extern\t__imp_RtlVirtualUnwind\n.type\tse_handler,\\@abi-omnipotent\n.align\t16\nse_handler:\n\tpush\t%rsi\n\tpush\t%rdi\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n\tpushfq\n\tsub\t\\$64,%rsp\n\n\tmov\t120($context),%rax\t# pull context->Rax\n\tmov\t248($context),%rbx\t# pull context->Rip\n\n\tmov\t8($disp),%rsi\t\t# disp->ImageBase\n\tmov\t56($disp),%r11\t\t# disp->HandlerData\n\n\tmov\t0(%r11),%r10d\t\t# HandlerData[0]\n\tlea\t(%rsi,%r10),%r10\t# prologue label\n\tcmp\t%r10,%rbx\t\t# context->Rip<.Lprologue\n\tjb\t.Lcommon_seh_tail\n\n\tmov\t152($context),%rax\t# pull context->Rsp\n\n\tmov\t4(%r11),%r10d\t\t# HandlerData[1]\n\tlea\t(%rsi,%r10),%r10\t# epilogue label\n\tcmp\t%r10,%rbx\t\t# context->Rip>=.Lepilogue\n\tjae\t.Lcommon_seh_tail\n\n\tlea\t48(%rax),%rax\n\n\tmov\t-8(%rax),%rbx\n\tmov\t-16(%rax),%rbp\n\tmov\t-24(%rax),%r12\n\tmov\t-32(%rax),%r13\n\tmov\t-40(%rax),%r14\n\tmov\t-48(%rax),%r15\n\tmov\t%rbx,144($context)\t# restore context->Rbx\n\tmov\t%rbp,160($context)\t# restore context->Rbp\n\tmov\t%r12,216($context)\t# restore context->R12\n\tmov\t%r13,224($context)\t# restore context->R13\n\tmov\t%r14,232($context)\t# restore context->R14\n\tmov\t%r15,240($context)\t# restore context->R14\n\n\tjmp\t.Lcommon_seh_tail\n.size\tse_handler,.-se_handler\n\n.type\tavx_handler,\\@abi-omnipotent\n.align\t16\navx_handler:\n\tpush\t%rsi\n\tpush\t%rdi\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n\tpushfq\n\tsub\t\\$64,%rsp\n\n\tmov\t120($context),%rax\t# pull context->Rax\n\tmov\t248($context),%rbx\t# pull context->Rip\n\n\tmov\t8($disp),%rsi\t\t# disp->ImageBase\n\tmov\t56($disp),%r11\t\t# disp->HandlerData\n\n\tmov\t0(%r11),%r10d\t\t# HandlerData[0]\n\tlea\t(%rsi,%r10),%r10\t# prologue label\n\tcmp\t%r10,%rbx\t\t# context->Rip<prologue label\n\tjb\t.Lcommon_seh_tail\n\n\tmov\t152($context),%rax\t# pull context->Rsp\n\n\tmov\t4(%r11),%r10d\t\t# HandlerData[1]\n\tlea\t(%rsi,%r10),%r10\t# epilogue label\n\tcmp\t%r10,%rbx\t\t# context->Rip>=epilogue label\n\tjae\t.Lcommon_seh_tail\n\n\tmov\t208($context),%rax\t# pull context->R11\n\n\tlea\t0x50(%rax),%rsi\n\tlea\t0xf8(%rax),%rax\n\tlea\t512($context),%rdi\t# &context.Xmm6\n\tmov\t\\$20,%ecx\n\t.long\t0xa548f3fc\t\t# cld; rep movsq\n\n.Lcommon_seh_tail:\n\tmov\t8(%rax),%rdi\n\tmov\t16(%rax),%rsi\n\tmov\t%rax,152($context)\t# restore context->Rsp\n\tmov\t%rsi,168($context)\t# restore context->Rsi\n\tmov\t%rdi,176($context)\t# restore context->Rdi\n\n\tmov\t40($disp),%rdi\t\t# disp->ContextRecord\n\tmov\t$context,%rsi\t\t# context\n\tmov\t\\$154,%ecx\t\t# sizeof(CONTEXT)\n\t.long\t0xa548f3fc\t\t# cld; rep movsq\n\n\tmov\t$disp,%rsi\n\txor\t%ecx,%ecx\t\t# arg1, UNW_FLAG_NHANDLER\n\tmov\t8(%rsi),%rdx\t\t# arg2, disp->ImageBase\n\tmov\t0(%rsi),%r8\t\t# arg3, disp->ControlPc\n\tmov\t16(%rsi),%r9\t\t# arg4, disp->FunctionEntry\n\tmov\t40(%rsi),%r10\t\t# disp->ContextRecord\n\tlea\t56(%rsi),%r11\t\t# &disp->HandlerData\n\tlea\t24(%rsi),%r12\t\t# &disp->EstablisherFrame\n\tmov\t%r10,32(%rsp)\t\t# arg5\n\tmov\t%r11,40(%rsp)\t\t# arg6\n\tmov\t%r12,48(%rsp)\t\t# arg7\n\tmov\t%rcx,56(%rsp)\t\t# arg8, (NULL)\n\tcall\t*__imp_RtlVirtualUnwind(%rip)\n\n\tmov\t\\$1,%eax\t\t# ExceptionContinueSearch\n\tadd\t\\$64,%rsp\n\tpopfq\n\tpop\t%r15\n\tpop\t%r14\n\tpop\t%r13\n\tpop\t%r12\n\tpop\t%rbp\n\tpop\t%rbx\n\tpop\t%rdi\n\tpop\t%rsi\n\tRET\n.size\tavx_handler,.-avx_handler\n\n.section\t.pdata\n.align\t4\n\t.rva\t.LSEH_begin_poly1305_init_x86_64\n\t.rva\t.LSEH_end_poly1305_init_x86_64\n\t.rva\t.LSEH_info_poly1305_init_x86_64\n\n\t.rva\t.LSEH_begin_poly1305_blocks_x86_64\n\t.rva\t.LSEH_end_poly1305_blocks_x86_64\n\t.rva\t.LSEH_info_poly1305_blocks_x86_64\n\n\t.rva\t.LSEH_begin_poly1305_emit_x86_64\n\t.rva\t.LSEH_end_poly1305_emit_x86_64\n\t.rva\t.LSEH_info_poly1305_emit_x86_64\n___\n$code.=<<___ if ($avx);\n\t.rva\t.LSEH_begin_poly1305_blocks_avx\n\t.rva\t.Lbase2_64_avx\n\t.rva\t.LSEH_info_poly1305_blocks_avx_1\n\n\t.rva\t.Lbase2_64_avx\n\t.rva\t.Leven_avx\n\t.rva\t.LSEH_info_poly1305_blocks_avx_2\n\n\t.rva\t.Leven_avx\n\t.rva\t.LSEH_end_poly1305_blocks_avx\n\t.rva\t.LSEH_info_poly1305_blocks_avx_3\n\n\t.rva\t.LSEH_begin_poly1305_emit_avx\n\t.rva\t.LSEH_end_poly1305_emit_avx\n\t.rva\t.LSEH_info_poly1305_emit_avx\n___\n$code.=<<___ if ($avx>1);\n\t.rva\t.LSEH_begin_poly1305_blocks_avx2\n\t.rva\t.Lbase2_64_avx2\n\t.rva\t.LSEH_info_poly1305_blocks_avx2_1\n\n\t.rva\t.Lbase2_64_avx2\n\t.rva\t.Leven_avx2\n\t.rva\t.LSEH_info_poly1305_blocks_avx2_2\n\n\t.rva\t.Leven_avx2\n\t.rva\t.LSEH_end_poly1305_blocks_avx2\n\t.rva\t.LSEH_info_poly1305_blocks_avx2_3\n___\n$code.=<<___ if ($avx>2);\n\t.rva\t.LSEH_begin_poly1305_blocks_avx512\n\t.rva\t.LSEH_end_poly1305_blocks_avx512\n\t.rva\t.LSEH_info_poly1305_blocks_avx512\n___\n$code.=<<___;\n.section\t.xdata\n.align\t8\n.LSEH_info_poly1305_init_x86_64:\n\t.byte\t9,0,0,0\n\t.rva\tse_handler\n\t.rva\t.LSEH_begin_poly1305_init_x86_64,.LSEH_begin_poly1305_init_x86_64\n\n.LSEH_info_poly1305_blocks_x86_64:\n\t.byte\t9,0,0,0\n\t.rva\tse_handler\n\t.rva\t.Lblocks_body,.Lblocks_epilogue\n\n.LSEH_info_poly1305_emit_x86_64:\n\t.byte\t9,0,0,0\n\t.rva\tse_handler\n\t.rva\t.LSEH_begin_poly1305_emit_x86_64,.LSEH_begin_poly1305_emit_x86_64\n___\n$code.=<<___ if ($avx);\n.LSEH_info_poly1305_blocks_avx_1:\n\t.byte\t9,0,0,0\n\t.rva\tse_handler\n\t.rva\t.Lblocks_avx_body,.Lblocks_avx_epilogue\t\t# HandlerData[]\n\n.LSEH_info_poly1305_blocks_avx_2:\n\t.byte\t9,0,0,0\n\t.rva\tse_handler\n\t.rva\t.Lbase2_64_avx_body,.Lbase2_64_avx_epilogue\t# HandlerData[]\n\n.LSEH_info_poly1305_blocks_avx_3:\n\t.byte\t9,0,0,0\n\t.rva\tavx_handler\n\t.rva\t.Ldo_avx_body,.Ldo_avx_epilogue\t\t\t# HandlerData[]\n\n.LSEH_info_poly1305_emit_avx:\n\t.byte\t9,0,0,0\n\t.rva\tse_handler\n\t.rva\t.LSEH_begin_poly1305_emit_avx,.LSEH_begin_poly1305_emit_avx\n___\n$code.=<<___ if ($avx>1);\n.LSEH_info_poly1305_blocks_avx2_1:\n\t.byte\t9,0,0,0\n\t.rva\tse_handler\n\t.rva\t.Lblocks_avx2_body,.Lblocks_avx2_epilogue\t# HandlerData[]\n\n.LSEH_info_poly1305_blocks_avx2_2:\n\t.byte\t9,0,0,0\n\t.rva\tse_handler\n\t.rva\t.Lbase2_64_avx2_body,.Lbase2_64_avx2_epilogue\t# HandlerData[]\n\n.LSEH_info_poly1305_blocks_avx2_3:\n\t.byte\t9,0,0,0\n\t.rva\tavx_handler\n\t.rva\t.Ldo_avx2_body,.Ldo_avx2_epilogue\t\t# HandlerData[]\n___\n$code.=<<___ if ($avx>2);\n.LSEH_info_poly1305_blocks_avx512:\n\t.byte\t9,0,0,0\n\t.rva\tavx_handler\n\t.rva\t.Ldo_avx512_body,.Ldo_avx512_epilogue\t\t# HandlerData[]\n___\n}\n\nopen SELF,$0;\nwhile(<SELF>) {\n\tnext if (/^#!/);\n\tlast if (!s/^#/\\/\\// and !/^$/);\n\tprint;\n}\nclose SELF;\n\nforeach (split('\\n',$code)) {\n\ts/\\`([^\\`]*)\\`/eval($1)/ge;\n\ts/%r([a-z]+)#d/%e$1/g;\n\ts/%r([0-9]+)#d/%r$1d/g;\n\ts/%x#%[yz]/%x/g or s/%y#%z/%y/g or s/%z#%[yz]/%z/g;\n\n\tif ($kernel) {\n\t\ts/(^\\.type.*),[0-9]+$/\\1/;\n\t\ts/(^\\.type.*),\\@abi-omnipotent+$/\\1,\\@function/;\n\t\tnext if /^\\.cfi.*/;\n\t}\n\n\tprint $_,\"\\n\";\n}\nclose STDOUT;\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}