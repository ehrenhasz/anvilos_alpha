{
  "module_name": "crc32-pclmul_asm.S",
  "hash_id": "5aa770b53d110e467c3360199f15e9f094f337889e501378f64c16e5a3ae0673",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/crypto/crc32-pclmul_asm.S",
  "human_readable_source": " \n \n\n#include <linux/linkage.h>\n\n\n.section .rodata\n.align 16\n \n.Lconstant_R2R1:\n\t.octa 0x00000001c6e415960000000154442bd4\n \n.Lconstant_R4R3:\n\t.octa 0x00000000ccaa009e00000001751997d0\n \n.Lconstant_R5:\n\t.octa 0x00000000000000000000000163cd6124\n.Lconstant_mask32:\n\t.octa 0x000000000000000000000000FFFFFFFF\n \n.Lconstant_RUpoly:\n\t.octa 0x00000001F701164100000001DB710641\n\n#define CONSTANT %xmm0\n\n#ifdef __x86_64__\n#define BUF     %rdi\n#define LEN     %rsi\n#define CRC     %edx\n#else\n#define BUF     %eax\n#define LEN     %edx\n#define CRC     %ecx\n#endif\n\n\n\n.text\n \n\nSYM_FUNC_START(crc32_pclmul_le_16)  \n\tmovdqa  (BUF), %xmm1\n\tmovdqa  0x10(BUF), %xmm2\n\tmovdqa  0x20(BUF), %xmm3\n\tmovdqa  0x30(BUF), %xmm4\n\tmovd    CRC, CONSTANT\n\tpxor    CONSTANT, %xmm1\n\tsub     $0x40, LEN\n\tadd     $0x40, BUF\n\tcmp     $0x40, LEN\n\tjb      .Lless_64\n\n#ifdef __x86_64__\n\tmovdqa .Lconstant_R2R1(%rip), CONSTANT\n#else\n\tmovdqa .Lconstant_R2R1, CONSTANT\n#endif\n\n.Lloop_64: \n\tprefetchnta    0x40(BUF)\n\tmovdqa  %xmm1, %xmm5\n\tmovdqa  %xmm2, %xmm6\n\tmovdqa  %xmm3, %xmm7\n#ifdef __x86_64__\n\tmovdqa  %xmm4, %xmm8\n#endif\n\tpclmulqdq $0x00, CONSTANT, %xmm1\n\tpclmulqdq $0x00, CONSTANT, %xmm2\n\tpclmulqdq $0x00, CONSTANT, %xmm3\n#ifdef __x86_64__\n\tpclmulqdq $0x00, CONSTANT, %xmm4\n#endif\n\tpclmulqdq $0x11, CONSTANT, %xmm5\n\tpclmulqdq $0x11, CONSTANT, %xmm6\n\tpclmulqdq $0x11, CONSTANT, %xmm7\n#ifdef __x86_64__\n\tpclmulqdq $0x11, CONSTANT, %xmm8\n#endif\n\tpxor    %xmm5, %xmm1\n\tpxor    %xmm6, %xmm2\n\tpxor    %xmm7, %xmm3\n#ifdef __x86_64__\n\tpxor    %xmm8, %xmm4\n#else\n\t \n\tmovdqa  %xmm4, %xmm5\n\tpclmulqdq $0x00, CONSTANT, %xmm4\n\tpclmulqdq $0x11, CONSTANT, %xmm5\n\tpxor    %xmm5, %xmm4\n#endif\n\n\tpxor    (BUF), %xmm1\n\tpxor    0x10(BUF), %xmm2\n\tpxor    0x20(BUF), %xmm3\n\tpxor    0x30(BUF), %xmm4\n\n\tsub     $0x40, LEN\n\tadd     $0x40, BUF\n\tcmp     $0x40, LEN\n\tjge     .Lloop_64\n.Lless_64: \n#ifdef __x86_64__\n\tmovdqa  .Lconstant_R4R3(%rip), CONSTANT\n#else\n\tmovdqa  .Lconstant_R4R3, CONSTANT\n#endif\n\tprefetchnta     (BUF)\n\n\tmovdqa  %xmm1, %xmm5\n\tpclmulqdq $0x00, CONSTANT, %xmm1\n\tpclmulqdq $0x11, CONSTANT, %xmm5\n\tpxor    %xmm5, %xmm1\n\tpxor    %xmm2, %xmm1\n\n\tmovdqa  %xmm1, %xmm5\n\tpclmulqdq $0x00, CONSTANT, %xmm1\n\tpclmulqdq $0x11, CONSTANT, %xmm5\n\tpxor    %xmm5, %xmm1\n\tpxor    %xmm3, %xmm1\n\n\tmovdqa  %xmm1, %xmm5\n\tpclmulqdq $0x00, CONSTANT, %xmm1\n\tpclmulqdq $0x11, CONSTANT, %xmm5\n\tpxor    %xmm5, %xmm1\n\tpxor    %xmm4, %xmm1\n\n\tcmp     $0x10, LEN\n\tjb      .Lfold_64\n.Lloop_16: \n\tmovdqa  %xmm1, %xmm5\n\tpclmulqdq $0x00, CONSTANT, %xmm1\n\tpclmulqdq $0x11, CONSTANT, %xmm5\n\tpxor    %xmm5, %xmm1\n\tpxor    (BUF), %xmm1\n\tsub     $0x10, LEN\n\tadd     $0x10, BUF\n\tcmp     $0x10, LEN\n\tjge     .Lloop_16\n\n.Lfold_64:\n\t \n\tpclmulqdq $0x01, %xmm1, CONSTANT  \n\tpsrldq  $0x08, %xmm1\n\tpxor    CONSTANT, %xmm1\n\n\t \n\tmovdqa  %xmm1, %xmm2\n#ifdef __x86_64__\n\tmovdqa  .Lconstant_R5(%rip), CONSTANT\n\tmovdqa  .Lconstant_mask32(%rip), %xmm3\n#else\n\tmovdqa  .Lconstant_R5, CONSTANT\n\tmovdqa  .Lconstant_mask32, %xmm3\n#endif\n\tpsrldq  $0x04, %xmm2\n\tpand    %xmm3, %xmm1\n\tpclmulqdq $0x00, CONSTANT, %xmm1\n\tpxor    %xmm2, %xmm1\n\n\t \n#ifdef __x86_64__\n\tmovdqa  .Lconstant_RUpoly(%rip), CONSTANT\n#else\n\tmovdqa  .Lconstant_RUpoly, CONSTANT\n#endif\n\tmovdqa  %xmm1, %xmm2\n\tpand    %xmm3, %xmm1\n\tpclmulqdq $0x10, CONSTANT, %xmm1\n\tpand    %xmm3, %xmm1\n\tpclmulqdq $0x00, CONSTANT, %xmm1\n\tpxor    %xmm2, %xmm1\n\tpextrd  $0x01, %xmm1, %eax\n\n\tRET\nSYM_FUNC_END(crc32_pclmul_le_16)\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}