{
  "module_name": "ghash-clmulni-intel_glue.c",
  "hash_id": "273902f54bd67a7ffddae7a787e38118e94ac92dbec312bdcb929533605c5f91",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/crypto/ghash-clmulni-intel_glue.c",
  "human_readable_source": "\n \n\n#include <linux/err.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/crypto.h>\n#include <crypto/algapi.h>\n#include <crypto/cryptd.h>\n#include <crypto/gf128mul.h>\n#include <crypto/internal/hash.h>\n#include <crypto/internal/simd.h>\n#include <asm/cpu_device_id.h>\n#include <asm/simd.h>\n#include <asm/unaligned.h>\n\n#define GHASH_BLOCK_SIZE\t16\n#define GHASH_DIGEST_SIZE\t16\n\nvoid clmul_ghash_mul(char *dst, const le128 *shash);\n\nvoid clmul_ghash_update(char *dst, const char *src, unsigned int srclen,\n\t\t\tconst le128 *shash);\n\nstruct ghash_async_ctx {\n\tstruct cryptd_ahash *cryptd_tfm;\n};\n\nstruct ghash_ctx {\n\tle128 shash;\n};\n\nstruct ghash_desc_ctx {\n\tu8 buffer[GHASH_BLOCK_SIZE];\n\tu32 bytes;\n};\n\nstatic int ghash_init(struct shash_desc *desc)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\n\tmemset(dctx, 0, sizeof(*dctx));\n\n\treturn 0;\n}\n\nstatic int ghash_setkey(struct crypto_shash *tfm,\n\t\t\tconst u8 *key, unsigned int keylen)\n{\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(tfm);\n\tu64 a, b;\n\n\tif (keylen != GHASH_BLOCK_SIZE)\n\t\treturn -EINVAL;\n\n\t \n\ta = get_unaligned_be64(key);\n\tb = get_unaligned_be64(key + 8);\n\tctx->shash.a = cpu_to_le64((a << 1) | (b >> 63));\n\tctx->shash.b = cpu_to_le64((b << 1) | (a >> 63));\n\tif (a >> 63)\n\t\tctx->shash.a ^= cpu_to_le64((u64)0xc2 << 56);\n\treturn 0;\n}\n\nstatic int ghash_update(struct shash_desc *desc,\n\t\t\t const u8 *src, unsigned int srclen)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *dst = dctx->buffer;\n\n\tkernel_fpu_begin();\n\tif (dctx->bytes) {\n\t\tint n = min(srclen, dctx->bytes);\n\t\tu8 *pos = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\tdctx->bytes -= n;\n\t\tsrclen -= n;\n\n\t\twhile (n--)\n\t\t\t*pos++ ^= *src++;\n\n\t\tif (!dctx->bytes)\n\t\t\tclmul_ghash_mul(dst, &ctx->shash);\n\t}\n\n\tclmul_ghash_update(dst, src, srclen, &ctx->shash);\n\tkernel_fpu_end();\n\n\tif (srclen & 0xf) {\n\t\tsrc += srclen - (srclen & 0xf);\n\t\tsrclen &= 0xf;\n\t\tdctx->bytes = GHASH_BLOCK_SIZE - srclen;\n\t\twhile (srclen--)\n\t\t\t*dst++ ^= *src++;\n\t}\n\n\treturn 0;\n}\n\nstatic void ghash_flush(struct ghash_ctx *ctx, struct ghash_desc_ctx *dctx)\n{\n\tu8 *dst = dctx->buffer;\n\n\tif (dctx->bytes) {\n\t\tu8 *tmp = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\twhile (dctx->bytes--)\n\t\t\t*tmp++ ^= 0;\n\n\t\tkernel_fpu_begin();\n\t\tclmul_ghash_mul(dst, &ctx->shash);\n\t\tkernel_fpu_end();\n\t}\n\n\tdctx->bytes = 0;\n}\n\nstatic int ghash_final(struct shash_desc *desc, u8 *dst)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *buf = dctx->buffer;\n\n\tghash_flush(ctx, dctx);\n\tmemcpy(dst, buf, GHASH_BLOCK_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg ghash_alg = {\n\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t.init\t\t= ghash_init,\n\t.update\t\t= ghash_update,\n\t.final\t\t= ghash_final,\n\t.setkey\t\t= ghash_setkey,\n\t.descsize\t= sizeof(struct ghash_desc_ctx),\n\t.base\t\t= {\n\t\t.cra_name\t\t= \"__ghash\",\n\t\t.cra_driver_name\t= \"__ghash-pclmulqdqni\",\n\t\t.cra_priority\t\t= 0,\n\t\t.cra_flags\t\t= CRYPTO_ALG_INTERNAL,\n\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct ghash_ctx),\n\t\t.cra_module\t\t= THIS_MODULE,\n\t},\n};\n\nstatic int ghash_async_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\tstruct crypto_shash *child = cryptd_ahash_child(cryptd_tfm);\n\n\tdesc->tfm = child;\n\treturn crypto_shash_init(desc);\n}\n\nstatic int ghash_async_update(struct ahash_request *req)\n{\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\tif (!crypto_simd_usable() ||\n\t    (in_atomic() && cryptd_ahash_queued(cryptd_tfm))) {\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_update(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\treturn shash_ahash_update(req, desc);\n\t}\n}\n\nstatic int ghash_async_final(struct ahash_request *req)\n{\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\tif (!crypto_simd_usable() ||\n\t    (in_atomic() && cryptd_ahash_queued(cryptd_tfm))) {\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_final(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\treturn crypto_shash_final(desc, req->result);\n\t}\n}\n\nstatic int ghash_async_import(struct ahash_request *req, const void *in)\n{\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\n\tghash_async_init(req);\n\tmemcpy(dctx, in, sizeof(*dctx));\n\treturn 0;\n\n}\n\nstatic int ghash_async_export(struct ahash_request *req, void *out)\n{\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, dctx, sizeof(*dctx));\n\treturn 0;\n\n}\n\nstatic int ghash_async_digest(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\tif (!crypto_simd_usable() ||\n\t    (in_atomic() && cryptd_ahash_queued(cryptd_tfm))) {\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_digest(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\tstruct crypto_shash *child = cryptd_ahash_child(cryptd_tfm);\n\n\t\tdesc->tfm = child;\n\t\treturn shash_ahash_digest(req, desc);\n\t}\n}\n\nstatic int ghash_async_setkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct crypto_ahash *child = &ctx->cryptd_tfm->base;\n\n\tcrypto_ahash_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ahash_set_flags(child, crypto_ahash_get_flags(tfm)\n\t\t\t       & CRYPTO_TFM_REQ_MASK);\n\treturn crypto_ahash_setkey(child, key, keylen);\n}\n\nstatic int ghash_async_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct cryptd_ahash *cryptd_tfm;\n\tstruct ghash_async_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcryptd_tfm = cryptd_alloc_ahash(\"__ghash-pclmulqdqni\",\n\t\t\t\t\tCRYPTO_ALG_INTERNAL,\n\t\t\t\t\tCRYPTO_ALG_INTERNAL);\n\tif (IS_ERR(cryptd_tfm))\n\t\treturn PTR_ERR(cryptd_tfm);\n\tctx->cryptd_tfm = cryptd_tfm;\n\tcrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\n\t\t\t\t sizeof(struct ahash_request) +\n\t\t\t\t crypto_ahash_reqsize(&cryptd_tfm->base));\n\n\treturn 0;\n}\n\nstatic void ghash_async_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct ghash_async_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcryptd_free_ahash(ctx->cryptd_tfm);\n}\n\nstatic struct ahash_alg ghash_async_alg = {\n\t.init\t\t= ghash_async_init,\n\t.update\t\t= ghash_async_update,\n\t.final\t\t= ghash_async_final,\n\t.setkey\t\t= ghash_async_setkey,\n\t.digest\t\t= ghash_async_digest,\n\t.export\t\t= ghash_async_export,\n\t.import\t\t= ghash_async_import,\n\t.halg = {\n\t\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t\t.statesize = sizeof(struct ghash_desc_ctx),\n\t\t.base = {\n\t\t\t.cra_name\t\t= \"ghash\",\n\t\t\t.cra_driver_name\t= \"ghash-clmulni\",\n\t\t\t.cra_priority\t\t= 400,\n\t\t\t.cra_ctxsize\t\t= sizeof(struct ghash_async_ctx),\n\t\t\t.cra_flags\t\t= CRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t.cra_init\t\t= ghash_async_init_tfm,\n\t\t\t.cra_exit\t\t= ghash_async_exit_tfm,\n\t\t},\n\t},\n};\n\nstatic const struct x86_cpu_id pcmul_cpu_id[] = {\n\tX86_MATCH_FEATURE(X86_FEATURE_PCLMULQDQ, NULL),  \n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, pcmul_cpu_id);\n\nstatic int __init ghash_pclmulqdqni_mod_init(void)\n{\n\tint err;\n\n\tif (!x86_match_cpu(pcmul_cpu_id))\n\t\treturn -ENODEV;\n\n\terr = crypto_register_shash(&ghash_alg);\n\tif (err)\n\t\tgoto err_out;\n\terr = crypto_register_ahash(&ghash_async_alg);\n\tif (err)\n\t\tgoto err_shash;\n\n\treturn 0;\n\nerr_shash:\n\tcrypto_unregister_shash(&ghash_alg);\nerr_out:\n\treturn err;\n}\n\nstatic void __exit ghash_pclmulqdqni_mod_exit(void)\n{\n\tcrypto_unregister_ahash(&ghash_async_alg);\n\tcrypto_unregister_shash(&ghash_alg);\n}\n\nmodule_init(ghash_pclmulqdqni_mod_init);\nmodule_exit(ghash_pclmulqdqni_mod_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"GHASH hash function, accelerated by PCLMULQDQ-NI\");\nMODULE_ALIAS_CRYPTO(\"ghash\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}