{
  "module_name": "sha256_ssse3_glue.c",
  "hash_id": "5bf9227f3bb1a7bdb1642eee2bb02cfac68e250fe900b69e4e4e49e75d563d54",
  "original_prompt": "Ingested from linux-6.6.14/arch/x86/crypto/sha256_ssse3_glue.c",
  "human_readable_source": " \n\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <crypto/internal/simd.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <crypto/sha2.h>\n#include <crypto/sha256_base.h>\n#include <linux/string.h>\n#include <asm/cpu_device_id.h>\n#include <asm/simd.h>\n\nasmlinkage void sha256_transform_ssse3(struct sha256_state *state,\n\t\t\t\t       const u8 *data, int blocks);\n\nstatic const struct x86_cpu_id module_cpu_ids[] = {\n\tX86_MATCH_FEATURE(X86_FEATURE_AVX2, NULL),\n\tX86_MATCH_FEATURE(X86_FEATURE_AVX, NULL),\n\tX86_MATCH_FEATURE(X86_FEATURE_SSSE3, NULL),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, module_cpu_ids);\n\nstatic int _sha256_update(struct shash_desc *desc, const u8 *data,\n\t\t\t  unsigned int len, sha256_block_fn *sha256_xform)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tif (!crypto_simd_usable() ||\n\t    (sctx->count % SHA256_BLOCK_SIZE) + len < SHA256_BLOCK_SIZE)\n\t\treturn crypto_sha256_update(desc, data, len);\n\n\t \n\tBUILD_BUG_ON(offsetof(struct sha256_state, state) != 0);\n\n\tkernel_fpu_begin();\n\tsha256_base_do_update(desc, data, len, sha256_xform);\n\tkernel_fpu_end();\n\n\treturn 0;\n}\n\nstatic int sha256_finup(struct shash_desc *desc, const u8 *data,\n\t      unsigned int len, u8 *out, sha256_block_fn *sha256_xform)\n{\n\tif (!crypto_simd_usable())\n\t\treturn crypto_sha256_finup(desc, data, len, out);\n\n\tkernel_fpu_begin();\n\tif (len)\n\t\tsha256_base_do_update(desc, data, len, sha256_xform);\n\tsha256_base_do_finalize(desc, sha256_xform);\n\tkernel_fpu_end();\n\n\treturn sha256_base_finish(desc, out);\n}\n\nstatic int sha256_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\treturn _sha256_update(desc, data, len, sha256_transform_ssse3);\n}\n\nstatic int sha256_ssse3_finup(struct shash_desc *desc, const u8 *data,\n\t      unsigned int len, u8 *out)\n{\n\treturn sha256_finup(desc, data, len, out, sha256_transform_ssse3);\n}\n\n \nstatic int sha256_ssse3_final(struct shash_desc *desc, u8 *out)\n{\n\treturn sha256_ssse3_finup(desc, NULL, 0, out);\n}\n\nstatic struct shash_alg sha256_ssse3_algs[] = { {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_base_init,\n\t.update\t\t=\tsha256_ssse3_update,\n\t.final\t\t=\tsha256_ssse3_final,\n\t.finup\t\t=\tsha256_ssse3_finup,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name =\t\"sha256-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_base_init,\n\t.update\t\t=\tsha256_ssse3_update,\n\t.final\t\t=\tsha256_ssse3_final,\n\t.finup\t\t=\tsha256_ssse3_finup,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name =\t\"sha224-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int register_sha256_ssse3(void)\n{\n\tif (boot_cpu_has(X86_FEATURE_SSSE3))\n\t\treturn crypto_register_shashes(sha256_ssse3_algs,\n\t\t\t\tARRAY_SIZE(sha256_ssse3_algs));\n\treturn 0;\n}\n\nstatic void unregister_sha256_ssse3(void)\n{\n\tif (boot_cpu_has(X86_FEATURE_SSSE3))\n\t\tcrypto_unregister_shashes(sha256_ssse3_algs,\n\t\t\t\tARRAY_SIZE(sha256_ssse3_algs));\n}\n\nasmlinkage void sha256_transform_avx(struct sha256_state *state,\n\t\t\t\t     const u8 *data, int blocks);\n\nstatic int sha256_avx_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\treturn _sha256_update(desc, data, len, sha256_transform_avx);\n}\n\nstatic int sha256_avx_finup(struct shash_desc *desc, const u8 *data,\n\t\t      unsigned int len, u8 *out)\n{\n\treturn sha256_finup(desc, data, len, out, sha256_transform_avx);\n}\n\nstatic int sha256_avx_final(struct shash_desc *desc, u8 *out)\n{\n\treturn sha256_avx_finup(desc, NULL, 0, out);\n}\n\nstatic struct shash_alg sha256_avx_algs[] = { {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_base_init,\n\t.update\t\t=\tsha256_avx_update,\n\t.final\t\t=\tsha256_avx_final,\n\t.finup\t\t=\tsha256_avx_finup,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name =\t\"sha256-avx\",\n\t\t.cra_priority\t=\t160,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_base_init,\n\t.update\t\t=\tsha256_avx_update,\n\t.final\t\t=\tsha256_avx_final,\n\t.finup\t\t=\tsha256_avx_finup,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name =\t\"sha224-avx\",\n\t\t.cra_priority\t=\t160,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic bool avx_usable(void)\n{\n\tif (!cpu_has_xfeatures(XFEATURE_MASK_SSE | XFEATURE_MASK_YMM, NULL)) {\n\t\tif (boot_cpu_has(X86_FEATURE_AVX))\n\t\t\tpr_info(\"AVX detected but unusable.\\n\");\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic int register_sha256_avx(void)\n{\n\tif (avx_usable())\n\t\treturn crypto_register_shashes(sha256_avx_algs,\n\t\t\t\tARRAY_SIZE(sha256_avx_algs));\n\treturn 0;\n}\n\nstatic void unregister_sha256_avx(void)\n{\n\tif (avx_usable())\n\t\tcrypto_unregister_shashes(sha256_avx_algs,\n\t\t\t\tARRAY_SIZE(sha256_avx_algs));\n}\n\nasmlinkage void sha256_transform_rorx(struct sha256_state *state,\n\t\t\t\t      const u8 *data, int blocks);\n\nstatic int sha256_avx2_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\treturn _sha256_update(desc, data, len, sha256_transform_rorx);\n}\n\nstatic int sha256_avx2_finup(struct shash_desc *desc, const u8 *data,\n\t\t      unsigned int len, u8 *out)\n{\n\treturn sha256_finup(desc, data, len, out, sha256_transform_rorx);\n}\n\nstatic int sha256_avx2_final(struct shash_desc *desc, u8 *out)\n{\n\treturn sha256_avx2_finup(desc, NULL, 0, out);\n}\n\nstatic struct shash_alg sha256_avx2_algs[] = { {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_base_init,\n\t.update\t\t=\tsha256_avx2_update,\n\t.final\t\t=\tsha256_avx2_final,\n\t.finup\t\t=\tsha256_avx2_finup,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name =\t\"sha256-avx2\",\n\t\t.cra_priority\t=\t170,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_base_init,\n\t.update\t\t=\tsha256_avx2_update,\n\t.final\t\t=\tsha256_avx2_final,\n\t.finup\t\t=\tsha256_avx2_finup,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name =\t\"sha224-avx2\",\n\t\t.cra_priority\t=\t170,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic bool avx2_usable(void)\n{\n\tif (avx_usable() && boot_cpu_has(X86_FEATURE_AVX2) &&\n\t\t    boot_cpu_has(X86_FEATURE_BMI2))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int register_sha256_avx2(void)\n{\n\tif (avx2_usable())\n\t\treturn crypto_register_shashes(sha256_avx2_algs,\n\t\t\t\tARRAY_SIZE(sha256_avx2_algs));\n\treturn 0;\n}\n\nstatic void unregister_sha256_avx2(void)\n{\n\tif (avx2_usable())\n\t\tcrypto_unregister_shashes(sha256_avx2_algs,\n\t\t\t\tARRAY_SIZE(sha256_avx2_algs));\n}\n\n#ifdef CONFIG_AS_SHA256_NI\nasmlinkage void sha256_ni_transform(struct sha256_state *digest,\n\t\t\t\t    const u8 *data, int rounds);\n\nstatic int sha256_ni_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\treturn _sha256_update(desc, data, len, sha256_ni_transform);\n}\n\nstatic int sha256_ni_finup(struct shash_desc *desc, const u8 *data,\n\t\t      unsigned int len, u8 *out)\n{\n\treturn sha256_finup(desc, data, len, out, sha256_ni_transform);\n}\n\nstatic int sha256_ni_final(struct shash_desc *desc, u8 *out)\n{\n\treturn sha256_ni_finup(desc, NULL, 0, out);\n}\n\nstatic struct shash_alg sha256_ni_algs[] = { {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_base_init,\n\t.update\t\t=\tsha256_ni_update,\n\t.final\t\t=\tsha256_ni_final,\n\t.finup\t\t=\tsha256_ni_finup,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name =\t\"sha256-ni\",\n\t\t.cra_priority\t=\t250,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_base_init,\n\t.update\t\t=\tsha256_ni_update,\n\t.final\t\t=\tsha256_ni_final,\n\t.finup\t\t=\tsha256_ni_finup,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name =\t\"sha224-ni\",\n\t\t.cra_priority\t=\t250,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int register_sha256_ni(void)\n{\n\tif (boot_cpu_has(X86_FEATURE_SHA_NI))\n\t\treturn crypto_register_shashes(sha256_ni_algs,\n\t\t\t\tARRAY_SIZE(sha256_ni_algs));\n\treturn 0;\n}\n\nstatic void unregister_sha256_ni(void)\n{\n\tif (boot_cpu_has(X86_FEATURE_SHA_NI))\n\t\tcrypto_unregister_shashes(sha256_ni_algs,\n\t\t\t\tARRAY_SIZE(sha256_ni_algs));\n}\n\n#else\nstatic inline int register_sha256_ni(void) { return 0; }\nstatic inline void unregister_sha256_ni(void) { }\n#endif\n\nstatic int __init sha256_ssse3_mod_init(void)\n{\n\tif (!x86_match_cpu(module_cpu_ids))\n\t\treturn -ENODEV;\n\n\tif (register_sha256_ssse3())\n\t\tgoto fail;\n\n\tif (register_sha256_avx()) {\n\t\tunregister_sha256_ssse3();\n\t\tgoto fail;\n\t}\n\n\tif (register_sha256_avx2()) {\n\t\tunregister_sha256_avx();\n\t\tunregister_sha256_ssse3();\n\t\tgoto fail;\n\t}\n\n\tif (register_sha256_ni()) {\n\t\tunregister_sha256_avx2();\n\t\tunregister_sha256_avx();\n\t\tunregister_sha256_ssse3();\n\t\tgoto fail;\n\t}\n\n\treturn 0;\nfail:\n\treturn -ENODEV;\n}\n\nstatic void __exit sha256_ssse3_mod_fini(void)\n{\n\tunregister_sha256_ni();\n\tunregister_sha256_avx2();\n\tunregister_sha256_avx();\n\tunregister_sha256_ssse3();\n}\n\nmodule_init(sha256_ssse3_mod_init);\nmodule_exit(sha256_ssse3_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA256 Secure Hash Algorithm, Supplemental SSE3 accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"sha256\");\nMODULE_ALIAS_CRYPTO(\"sha256-ssse3\");\nMODULE_ALIAS_CRYPTO(\"sha256-avx\");\nMODULE_ALIAS_CRYPTO(\"sha256-avx2\");\nMODULE_ALIAS_CRYPTO(\"sha224\");\nMODULE_ALIAS_CRYPTO(\"sha224-ssse3\");\nMODULE_ALIAS_CRYPTO(\"sha224-avx\");\nMODULE_ALIAS_CRYPTO(\"sha224-avx2\");\n#ifdef CONFIG_AS_SHA256_NI\nMODULE_ALIAS_CRYPTO(\"sha256-ni\");\nMODULE_ALIAS_CRYPTO(\"sha224-ni\");\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}