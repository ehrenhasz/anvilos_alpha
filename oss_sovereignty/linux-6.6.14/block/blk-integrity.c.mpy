{
  "module_name": "blk-integrity.c",
  "hash_id": "4347b539ea00749f94d1edcaec30b1314b20e408914d6591cf5f5fce4f991d27",
  "original_prompt": "Ingested from linux-6.6.14/block/blk-integrity.c",
  "human_readable_source": "\n \n\n#include <linux/blk-integrity.h>\n#include <linux/backing-dev.h>\n#include <linux/mempool.h>\n#include <linux/bio.h>\n#include <linux/scatterlist.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n\n#include \"blk.h\"\n\n \nint blk_rq_count_integrity_sg(struct request_queue *q, struct bio *bio)\n{\n\tstruct bio_vec iv, ivprv = { NULL };\n\tunsigned int segments = 0;\n\tunsigned int seg_size = 0;\n\tstruct bvec_iter iter;\n\tint prev = 0;\n\n\tbio_for_each_integrity_vec(iv, bio, iter) {\n\n\t\tif (prev) {\n\t\t\tif (!biovec_phys_mergeable(q, &ivprv, &iv))\n\t\t\t\tgoto new_segment;\n\t\t\tif (seg_size + iv.bv_len > queue_max_segment_size(q))\n\t\t\t\tgoto new_segment;\n\n\t\t\tseg_size += iv.bv_len;\n\t\t} else {\nnew_segment:\n\t\t\tsegments++;\n\t\t\tseg_size = iv.bv_len;\n\t\t}\n\n\t\tprev = 1;\n\t\tivprv = iv;\n\t}\n\n\treturn segments;\n}\nEXPORT_SYMBOL(blk_rq_count_integrity_sg);\n\n \nint blk_rq_map_integrity_sg(struct request_queue *q, struct bio *bio,\n\t\t\t    struct scatterlist *sglist)\n{\n\tstruct bio_vec iv, ivprv = { NULL };\n\tstruct scatterlist *sg = NULL;\n\tunsigned int segments = 0;\n\tstruct bvec_iter iter;\n\tint prev = 0;\n\n\tbio_for_each_integrity_vec(iv, bio, iter) {\n\n\t\tif (prev) {\n\t\t\tif (!biovec_phys_mergeable(q, &ivprv, &iv))\n\t\t\t\tgoto new_segment;\n\t\t\tif (sg->length + iv.bv_len > queue_max_segment_size(q))\n\t\t\t\tgoto new_segment;\n\n\t\t\tsg->length += iv.bv_len;\n\t\t} else {\nnew_segment:\n\t\t\tif (!sg)\n\t\t\t\tsg = sglist;\n\t\t\telse {\n\t\t\t\tsg_unmark_end(sg);\n\t\t\t\tsg = sg_next(sg);\n\t\t\t}\n\n\t\t\tsg_set_page(sg, iv.bv_page, iv.bv_len, iv.bv_offset);\n\t\t\tsegments++;\n\t\t}\n\n\t\tprev = 1;\n\t\tivprv = iv;\n\t}\n\n\tif (sg)\n\t\tsg_mark_end(sg);\n\n\treturn segments;\n}\nEXPORT_SYMBOL(blk_rq_map_integrity_sg);\n\n \nint blk_integrity_compare(struct gendisk *gd1, struct gendisk *gd2)\n{\n\tstruct blk_integrity *b1 = &gd1->queue->integrity;\n\tstruct blk_integrity *b2 = &gd2->queue->integrity;\n\n\tif (!b1->profile && !b2->profile)\n\t\treturn 0;\n\n\tif (!b1->profile || !b2->profile)\n\t\treturn -1;\n\n\tif (b1->interval_exp != b2->interval_exp) {\n\t\tpr_err(\"%s: %s/%s protection interval %u != %u\\n\",\n\t\t       __func__, gd1->disk_name, gd2->disk_name,\n\t\t       1 << b1->interval_exp, 1 << b2->interval_exp);\n\t\treturn -1;\n\t}\n\n\tif (b1->tuple_size != b2->tuple_size) {\n\t\tpr_err(\"%s: %s/%s tuple sz %u != %u\\n\", __func__,\n\t\t       gd1->disk_name, gd2->disk_name,\n\t\t       b1->tuple_size, b2->tuple_size);\n\t\treturn -1;\n\t}\n\n\tif (b1->tag_size && b2->tag_size && (b1->tag_size != b2->tag_size)) {\n\t\tpr_err(\"%s: %s/%s tag sz %u != %u\\n\", __func__,\n\t\t       gd1->disk_name, gd2->disk_name,\n\t\t       b1->tag_size, b2->tag_size);\n\t\treturn -1;\n\t}\n\n\tif (b1->profile != b2->profile) {\n\t\tpr_err(\"%s: %s/%s type %s != %s\\n\", __func__,\n\t\t       gd1->disk_name, gd2->disk_name,\n\t\t       b1->profile->name, b2->profile->name);\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(blk_integrity_compare);\n\nbool blk_integrity_merge_rq(struct request_queue *q, struct request *req,\n\t\t\t    struct request *next)\n{\n\tif (blk_integrity_rq(req) == 0 && blk_integrity_rq(next) == 0)\n\t\treturn true;\n\n\tif (blk_integrity_rq(req) == 0 || blk_integrity_rq(next) == 0)\n\t\treturn false;\n\n\tif (bio_integrity(req->bio)->bip_flags !=\n\t    bio_integrity(next->bio)->bip_flags)\n\t\treturn false;\n\n\tif (req->nr_integrity_segments + next->nr_integrity_segments >\n\t    q->limits.max_integrity_segments)\n\t\treturn false;\n\n\tif (integrity_req_gap_back_merge(req, next->bio))\n\t\treturn false;\n\n\treturn true;\n}\n\nbool blk_integrity_merge_bio(struct request_queue *q, struct request *req,\n\t\t\t     struct bio *bio)\n{\n\tint nr_integrity_segs;\n\tstruct bio *next = bio->bi_next;\n\n\tif (blk_integrity_rq(req) == 0 && bio_integrity(bio) == NULL)\n\t\treturn true;\n\n\tif (blk_integrity_rq(req) == 0 || bio_integrity(bio) == NULL)\n\t\treturn false;\n\n\tif (bio_integrity(req->bio)->bip_flags != bio_integrity(bio)->bip_flags)\n\t\treturn false;\n\n\tbio->bi_next = NULL;\n\tnr_integrity_segs = blk_rq_count_integrity_sg(q, bio);\n\tbio->bi_next = next;\n\n\tif (req->nr_integrity_segments + nr_integrity_segs >\n\t    q->limits.max_integrity_segments)\n\t\treturn false;\n\n\treq->nr_integrity_segments += nr_integrity_segs;\n\n\treturn true;\n}\n\nstatic inline struct blk_integrity *dev_to_bi(struct device *dev)\n{\n\treturn &dev_to_disk(dev)->queue->integrity;\n}\n\nstatic ssize_t format_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *page)\n{\n\tstruct blk_integrity *bi = dev_to_bi(dev);\n\n\tif (bi->profile && bi->profile->name)\n\t\treturn sysfs_emit(page, \"%s\\n\", bi->profile->name);\n\treturn sysfs_emit(page, \"none\\n\");\n}\n\nstatic ssize_t tag_size_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *page)\n{\n\tstruct blk_integrity *bi = dev_to_bi(dev);\n\n\treturn sysfs_emit(page, \"%u\\n\", bi->tag_size);\n}\n\nstatic ssize_t protection_interval_bytes_show(struct device *dev,\n\t\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t\t      char *page)\n{\n\tstruct blk_integrity *bi = dev_to_bi(dev);\n\n\treturn sysfs_emit(page, \"%u\\n\",\n\t\t\t  bi->interval_exp ? 1 << bi->interval_exp : 0);\n}\n\nstatic ssize_t read_verify_store(struct device *dev,\n\t\t\t\t struct device_attribute *attr,\n\t\t\t\t const char *page, size_t count)\n{\n\tstruct blk_integrity *bi = dev_to_bi(dev);\n\tchar *p = (char *) page;\n\tunsigned long val = simple_strtoul(p, &p, 10);\n\n\tif (val)\n\t\tbi->flags |= BLK_INTEGRITY_VERIFY;\n\telse\n\t\tbi->flags &= ~BLK_INTEGRITY_VERIFY;\n\n\treturn count;\n}\n\nstatic ssize_t read_verify_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr, char *page)\n{\n\tstruct blk_integrity *bi = dev_to_bi(dev);\n\n\treturn sysfs_emit(page, \"%d\\n\", !!(bi->flags & BLK_INTEGRITY_VERIFY));\n}\n\nstatic ssize_t write_generate_store(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    const char *page, size_t count)\n{\n\tstruct blk_integrity *bi = dev_to_bi(dev);\n\n\tchar *p = (char *) page;\n\tunsigned long val = simple_strtoul(p, &p, 10);\n\n\tif (val)\n\t\tbi->flags |= BLK_INTEGRITY_GENERATE;\n\telse\n\t\tbi->flags &= ~BLK_INTEGRITY_GENERATE;\n\n\treturn count;\n}\n\nstatic ssize_t write_generate_show(struct device *dev,\n\t\t\t\t   struct device_attribute *attr, char *page)\n{\n\tstruct blk_integrity *bi = dev_to_bi(dev);\n\n\treturn sysfs_emit(page, \"%d\\n\", !!(bi->flags & BLK_INTEGRITY_GENERATE));\n}\n\nstatic ssize_t device_is_integrity_capable_show(struct device *dev,\n\t\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\t\tchar *page)\n{\n\tstruct blk_integrity *bi = dev_to_bi(dev);\n\n\treturn sysfs_emit(page, \"%u\\n\",\n\t\t\t  !!(bi->flags & BLK_INTEGRITY_DEVICE_CAPABLE));\n}\n\nstatic DEVICE_ATTR_RO(format);\nstatic DEVICE_ATTR_RO(tag_size);\nstatic DEVICE_ATTR_RO(protection_interval_bytes);\nstatic DEVICE_ATTR_RW(read_verify);\nstatic DEVICE_ATTR_RW(write_generate);\nstatic DEVICE_ATTR_RO(device_is_integrity_capable);\n\nstatic struct attribute *integrity_attrs[] = {\n\t&dev_attr_format.attr,\n\t&dev_attr_tag_size.attr,\n\t&dev_attr_protection_interval_bytes.attr,\n\t&dev_attr_read_verify.attr,\n\t&dev_attr_write_generate.attr,\n\t&dev_attr_device_is_integrity_capable.attr,\n\tNULL\n};\n\nconst struct attribute_group blk_integrity_attr_group = {\n\t.name = \"integrity\",\n\t.attrs = integrity_attrs,\n};\n\nstatic blk_status_t blk_integrity_nop_fn(struct blk_integrity_iter *iter)\n{\n\treturn BLK_STS_OK;\n}\n\nstatic void blk_integrity_nop_prepare(struct request *rq)\n{\n}\n\nstatic void blk_integrity_nop_complete(struct request *rq,\n\t\tunsigned int nr_bytes)\n{\n}\n\nstatic const struct blk_integrity_profile nop_profile = {\n\t.name = \"nop\",\n\t.generate_fn = blk_integrity_nop_fn,\n\t.verify_fn = blk_integrity_nop_fn,\n\t.prepare_fn = blk_integrity_nop_prepare,\n\t.complete_fn = blk_integrity_nop_complete,\n};\n\n \nvoid blk_integrity_register(struct gendisk *disk, struct blk_integrity *template)\n{\n\tstruct blk_integrity *bi = &disk->queue->integrity;\n\n\tbi->flags = BLK_INTEGRITY_VERIFY | BLK_INTEGRITY_GENERATE |\n\t\ttemplate->flags;\n\tbi->interval_exp = template->interval_exp ? :\n\t\tilog2(queue_logical_block_size(disk->queue));\n\tbi->profile = template->profile ? template->profile : &nop_profile;\n\tbi->tuple_size = template->tuple_size;\n\tbi->tag_size = template->tag_size;\n\n\tblk_queue_flag_set(QUEUE_FLAG_STABLE_WRITES, disk->queue);\n\n#ifdef CONFIG_BLK_INLINE_ENCRYPTION\n\tif (disk->queue->crypto_profile) {\n\t\tpr_warn(\"blk-integrity: Integrity and hardware inline encryption are not supported together. Disabling hardware inline encryption.\\n\");\n\t\tdisk->queue->crypto_profile = NULL;\n\t}\n#endif\n}\nEXPORT_SYMBOL(blk_integrity_register);\n\n \nvoid blk_integrity_unregister(struct gendisk *disk)\n{\n\tstruct blk_integrity *bi = &disk->queue->integrity;\n\n\tif (!bi->profile)\n\t\treturn;\n\n\t \n\tblk_flush_integrity();\n\tblk_queue_flag_clear(QUEUE_FLAG_STABLE_WRITES, disk->queue);\n\tmemset(bi, 0, sizeof(*bi));\n}\nEXPORT_SYMBOL(blk_integrity_unregister);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}