{
  "module_name": "blk-iolatency.c",
  "hash_id": "ced173920e987fa958e3ce21beb5952bba4e7b7620bd063da830b740310d29b4",
  "original_prompt": "Ingested from linux-6.6.14/block/blk-iolatency.c",
  "human_readable_source": "\n \n#include <linux/kernel.h>\n#include <linux/blk_types.h>\n#include <linux/backing-dev.h>\n#include <linux/module.h>\n#include <linux/timer.h>\n#include <linux/memcontrol.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/signal.h>\n#include <trace/events/block.h>\n#include <linux/blk-mq.h>\n#include \"blk-rq-qos.h\"\n#include \"blk-stat.h\"\n#include \"blk-cgroup.h\"\n#include \"blk.h\"\n\n#define DEFAULT_SCALE_COOKIE 1000000U\n\nstatic struct blkcg_policy blkcg_policy_iolatency;\nstruct iolatency_grp;\n\nstruct blk_iolatency {\n\tstruct rq_qos rqos;\n\tstruct timer_list timer;\n\n\t \n\tbool enabled;\n\tatomic_t enable_cnt;\n\tstruct work_struct enable_work;\n};\n\nstatic inline struct blk_iolatency *BLKIOLATENCY(struct rq_qos *rqos)\n{\n\treturn container_of(rqos, struct blk_iolatency, rqos);\n}\n\nstruct child_latency_info {\n\tspinlock_t lock;\n\n\t \n\tu64 last_scale_event;\n\n\t \n\tu64 scale_lat;\n\n\t \n\tu64 nr_samples;\n\n\t \n\tstruct iolatency_grp *scale_grp;\n\n\t \n\tatomic_t scale_cookie;\n};\n\nstruct percentile_stats {\n\tu64 total;\n\tu64 missed;\n};\n\nstruct latency_stat {\n\tunion {\n\t\tstruct percentile_stats ps;\n\t\tstruct blk_rq_stat rqs;\n\t};\n};\n\nstruct iolatency_grp {\n\tstruct blkg_policy_data pd;\n\tstruct latency_stat __percpu *stats;\n\tstruct latency_stat cur_stat;\n\tstruct blk_iolatency *blkiolat;\n\tunsigned int max_depth;\n\tstruct rq_wait rq_wait;\n\tatomic64_t window_start;\n\tatomic_t scale_cookie;\n\tu64 min_lat_nsec;\n\tu64 cur_win_nsec;\n\n\t \n\tu64 lat_avg;\n\n\t \n\tu64 nr_samples;\n\n\tbool ssd;\n\tstruct child_latency_info child_lat;\n};\n\n#define BLKIOLATENCY_MIN_WIN_SIZE (100 * NSEC_PER_MSEC)\n#define BLKIOLATENCY_MAX_WIN_SIZE NSEC_PER_SEC\n \n#define BLKIOLATENCY_NR_EXP_FACTORS 5\n#define BLKIOLATENCY_EXP_BUCKET_SIZE (BLKIOLATENCY_MAX_WIN_SIZE / \\\n\t\t\t\t      (BLKIOLATENCY_NR_EXP_FACTORS - 1))\nstatic const u64 iolatency_exp_factors[BLKIOLATENCY_NR_EXP_FACTORS] = {\n\t2045, \n\t2039, \n\t2031, \n\t2023, \n\t2014, \n};\n\nstatic inline struct iolatency_grp *pd_to_lat(struct blkg_policy_data *pd)\n{\n\treturn pd ? container_of(pd, struct iolatency_grp, pd) : NULL;\n}\n\nstatic inline struct iolatency_grp *blkg_to_lat(struct blkcg_gq *blkg)\n{\n\treturn pd_to_lat(blkg_to_pd(blkg, &blkcg_policy_iolatency));\n}\n\nstatic inline struct blkcg_gq *lat_to_blkg(struct iolatency_grp *iolat)\n{\n\treturn pd_to_blkg(&iolat->pd);\n}\n\nstatic inline void latency_stat_init(struct iolatency_grp *iolat,\n\t\t\t\t     struct latency_stat *stat)\n{\n\tif (iolat->ssd) {\n\t\tstat->ps.total = 0;\n\t\tstat->ps.missed = 0;\n\t} else\n\t\tblk_rq_stat_init(&stat->rqs);\n}\n\nstatic inline void latency_stat_sum(struct iolatency_grp *iolat,\n\t\t\t\t    struct latency_stat *sum,\n\t\t\t\t    struct latency_stat *stat)\n{\n\tif (iolat->ssd) {\n\t\tsum->ps.total += stat->ps.total;\n\t\tsum->ps.missed += stat->ps.missed;\n\t} else\n\t\tblk_rq_stat_sum(&sum->rqs, &stat->rqs);\n}\n\nstatic inline void latency_stat_record_time(struct iolatency_grp *iolat,\n\t\t\t\t\t    u64 req_time)\n{\n\tstruct latency_stat *stat = get_cpu_ptr(iolat->stats);\n\tif (iolat->ssd) {\n\t\tif (req_time >= iolat->min_lat_nsec)\n\t\t\tstat->ps.missed++;\n\t\tstat->ps.total++;\n\t} else\n\t\tblk_rq_stat_add(&stat->rqs, req_time);\n\tput_cpu_ptr(stat);\n}\n\nstatic inline bool latency_sum_ok(struct iolatency_grp *iolat,\n\t\t\t\t  struct latency_stat *stat)\n{\n\tif (iolat->ssd) {\n\t\tu64 thresh = div64_u64(stat->ps.total, 10);\n\t\tthresh = max(thresh, 1ULL);\n\t\treturn stat->ps.missed < thresh;\n\t}\n\treturn stat->rqs.mean <= iolat->min_lat_nsec;\n}\n\nstatic inline u64 latency_stat_samples(struct iolatency_grp *iolat,\n\t\t\t\t       struct latency_stat *stat)\n{\n\tif (iolat->ssd)\n\t\treturn stat->ps.total;\n\treturn stat->rqs.nr_samples;\n}\n\nstatic inline void iolat_update_total_lat_avg(struct iolatency_grp *iolat,\n\t\t\t\t\t      struct latency_stat *stat)\n{\n\tint exp_idx;\n\n\tif (iolat->ssd)\n\t\treturn;\n\n\t \n\texp_idx = min_t(int, BLKIOLATENCY_NR_EXP_FACTORS - 1,\n\t\t\tdiv64_u64(iolat->cur_win_nsec,\n\t\t\t\t  BLKIOLATENCY_EXP_BUCKET_SIZE));\n\tiolat->lat_avg = calc_load(iolat->lat_avg,\n\t\t\t\t   iolatency_exp_factors[exp_idx],\n\t\t\t\t   stat->rqs.mean);\n}\n\nstatic void iolat_cleanup_cb(struct rq_wait *rqw, void *private_data)\n{\n\tatomic_dec(&rqw->inflight);\n\twake_up(&rqw->wait);\n}\n\nstatic bool iolat_acquire_inflight(struct rq_wait *rqw, void *private_data)\n{\n\tstruct iolatency_grp *iolat = private_data;\n\treturn rq_wait_inc_below(rqw, iolat->max_depth);\n}\n\nstatic void __blkcg_iolatency_throttle(struct rq_qos *rqos,\n\t\t\t\t       struct iolatency_grp *iolat,\n\t\t\t\t       bool issue_as_root,\n\t\t\t\t       bool use_memdelay)\n{\n\tstruct rq_wait *rqw = &iolat->rq_wait;\n\tunsigned use_delay = atomic_read(&lat_to_blkg(iolat)->use_delay);\n\n\tif (use_delay)\n\t\tblkcg_schedule_throttle(rqos->disk, use_memdelay);\n\n\t \n\tif (issue_as_root || fatal_signal_pending(current)) {\n\t\tatomic_inc(&rqw->inflight);\n\t\treturn;\n\t}\n\n\trq_qos_wait(rqw, iolat, iolat_acquire_inflight, iolat_cleanup_cb);\n}\n\n#define SCALE_DOWN_FACTOR 2\n#define SCALE_UP_FACTOR 4\n\nstatic inline unsigned long scale_amount(unsigned long qd, bool up)\n{\n\treturn max(up ? qd >> SCALE_UP_FACTOR : qd >> SCALE_DOWN_FACTOR, 1UL);\n}\n\n \nstatic void scale_cookie_change(struct blk_iolatency *blkiolat,\n\t\t\t\tstruct child_latency_info *lat_info,\n\t\t\t\tbool up)\n{\n\tunsigned long qd = blkiolat->rqos.disk->queue->nr_requests;\n\tunsigned long scale = scale_amount(qd, up);\n\tunsigned long old = atomic_read(&lat_info->scale_cookie);\n\tunsigned long max_scale = qd << 1;\n\tunsigned long diff = 0;\n\n\tif (old < DEFAULT_SCALE_COOKIE)\n\t\tdiff = DEFAULT_SCALE_COOKIE - old;\n\n\tif (up) {\n\t\tif (scale + old > DEFAULT_SCALE_COOKIE)\n\t\t\tatomic_set(&lat_info->scale_cookie,\n\t\t\t\t   DEFAULT_SCALE_COOKIE);\n\t\telse if (diff > qd)\n\t\t\tatomic_inc(&lat_info->scale_cookie);\n\t\telse\n\t\t\tatomic_add(scale, &lat_info->scale_cookie);\n\t} else {\n\t\t \n\t\tif (diff > qd) {\n\t\t\tif (diff < max_scale)\n\t\t\t\tatomic_dec(&lat_info->scale_cookie);\n\t\t} else {\n\t\t\tatomic_sub(scale, &lat_info->scale_cookie);\n\t\t}\n\t}\n}\n\n \nstatic void scale_change(struct iolatency_grp *iolat, bool up)\n{\n\tunsigned long qd = iolat->blkiolat->rqos.disk->queue->nr_requests;\n\tunsigned long scale = scale_amount(qd, up);\n\tunsigned long old = iolat->max_depth;\n\n\tif (old > qd)\n\t\told = qd;\n\n\tif (up) {\n\t\tif (old == 1 && blkcg_unuse_delay(lat_to_blkg(iolat)))\n\t\t\treturn;\n\n\t\tif (old < qd) {\n\t\t\told += scale;\n\t\t\told = min(old, qd);\n\t\t\tiolat->max_depth = old;\n\t\t\twake_up_all(&iolat->rq_wait.wait);\n\t\t}\n\t} else {\n\t\told >>= 1;\n\t\tiolat->max_depth = max(old, 1UL);\n\t}\n}\n\n \nstatic void check_scale_change(struct iolatency_grp *iolat)\n{\n\tstruct iolatency_grp *parent;\n\tstruct child_latency_info *lat_info;\n\tunsigned int cur_cookie;\n\tunsigned int our_cookie = atomic_read(&iolat->scale_cookie);\n\tu64 scale_lat;\n\tint direction = 0;\n\n\tparent = blkg_to_lat(lat_to_blkg(iolat)->parent);\n\tif (!parent)\n\t\treturn;\n\n\tlat_info = &parent->child_lat;\n\tcur_cookie = atomic_read(&lat_info->scale_cookie);\n\tscale_lat = READ_ONCE(lat_info->scale_lat);\n\n\tif (cur_cookie < our_cookie)\n\t\tdirection = -1;\n\telse if (cur_cookie > our_cookie)\n\t\tdirection = 1;\n\telse\n\t\treturn;\n\n\tif (!atomic_try_cmpxchg(&iolat->scale_cookie, &our_cookie, cur_cookie)) {\n\t\t \n\t\treturn;\n\t}\n\n\tif (direction < 0 && iolat->min_lat_nsec) {\n\t\tu64 samples_thresh;\n\n\t\tif (!scale_lat || iolat->min_lat_nsec <= scale_lat)\n\t\t\treturn;\n\n\t\t \n\t\tsamples_thresh = lat_info->nr_samples * 5;\n\t\tsamples_thresh = max(1ULL, div64_u64(samples_thresh, 100));\n\t\tif (iolat->nr_samples <= samples_thresh)\n\t\t\treturn;\n\t}\n\n\t \n\tif (iolat->max_depth == 1 && direction < 0) {\n\t\tblkcg_use_delay(lat_to_blkg(iolat));\n\t\treturn;\n\t}\n\n\t \n\tif (cur_cookie == DEFAULT_SCALE_COOKIE) {\n\t\tblkcg_clear_delay(lat_to_blkg(iolat));\n\t\tiolat->max_depth = UINT_MAX;\n\t\twake_up_all(&iolat->rq_wait.wait);\n\t\treturn;\n\t}\n\n\tscale_change(iolat, direction > 0);\n}\n\nstatic void blkcg_iolatency_throttle(struct rq_qos *rqos, struct bio *bio)\n{\n\tstruct blk_iolatency *blkiolat = BLKIOLATENCY(rqos);\n\tstruct blkcg_gq *blkg = bio->bi_blkg;\n\tbool issue_as_root = bio_issue_as_root_blkg(bio);\n\n\tif (!blkiolat->enabled)\n\t\treturn;\n\n\twhile (blkg && blkg->parent) {\n\t\tstruct iolatency_grp *iolat = blkg_to_lat(blkg);\n\t\tif (!iolat) {\n\t\t\tblkg = blkg->parent;\n\t\t\tcontinue;\n\t\t}\n\n\t\tcheck_scale_change(iolat);\n\t\t__blkcg_iolatency_throttle(rqos, iolat, issue_as_root,\n\t\t\t\t     (bio->bi_opf & REQ_SWAP) == REQ_SWAP);\n\t\tblkg = blkg->parent;\n\t}\n\tif (!timer_pending(&blkiolat->timer))\n\t\tmod_timer(&blkiolat->timer, jiffies + HZ);\n}\n\nstatic void iolatency_record_time(struct iolatency_grp *iolat,\n\t\t\t\t  struct bio_issue *issue, u64 now,\n\t\t\t\t  bool issue_as_root)\n{\n\tu64 start = bio_issue_time(issue);\n\tu64 req_time;\n\n\t \n\tnow = __bio_issue_time(now);\n\n\tif (now <= start)\n\t\treturn;\n\n\treq_time = now - start;\n\n\t \n\tif (unlikely(issue_as_root && iolat->max_depth != UINT_MAX)) {\n\t\tu64 sub = iolat->min_lat_nsec;\n\t\tif (req_time < sub)\n\t\t\tblkcg_add_delay(lat_to_blkg(iolat), now, sub - req_time);\n\t\treturn;\n\t}\n\n\tlatency_stat_record_time(iolat, req_time);\n}\n\n#define BLKIOLATENCY_MIN_ADJUST_TIME (500 * NSEC_PER_MSEC)\n#define BLKIOLATENCY_MIN_GOOD_SAMPLES 5\n\nstatic void iolatency_check_latencies(struct iolatency_grp *iolat, u64 now)\n{\n\tstruct blkcg_gq *blkg = lat_to_blkg(iolat);\n\tstruct iolatency_grp *parent;\n\tstruct child_latency_info *lat_info;\n\tstruct latency_stat stat;\n\tunsigned long flags;\n\tint cpu;\n\n\tlatency_stat_init(iolat, &stat);\n\tpreempt_disable();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct latency_stat *s;\n\t\ts = per_cpu_ptr(iolat->stats, cpu);\n\t\tlatency_stat_sum(iolat, &stat, s);\n\t\tlatency_stat_init(iolat, s);\n\t}\n\tpreempt_enable();\n\n\tparent = blkg_to_lat(blkg->parent);\n\tif (!parent)\n\t\treturn;\n\n\tlat_info = &parent->child_lat;\n\n\tiolat_update_total_lat_avg(iolat, &stat);\n\n\t \n\tif (latency_sum_ok(iolat, &stat) &&\n\t    atomic_read(&lat_info->scale_cookie) == DEFAULT_SCALE_COOKIE)\n\t\treturn;\n\n\t \n\tspin_lock_irqsave(&lat_info->lock, flags);\n\n\tlatency_stat_sum(iolat, &iolat->cur_stat, &stat);\n\tlat_info->nr_samples -= iolat->nr_samples;\n\tlat_info->nr_samples += latency_stat_samples(iolat, &iolat->cur_stat);\n\tiolat->nr_samples = latency_stat_samples(iolat, &iolat->cur_stat);\n\n\tif ((lat_info->last_scale_event >= now ||\n\t    now - lat_info->last_scale_event < BLKIOLATENCY_MIN_ADJUST_TIME))\n\t\tgoto out;\n\n\tif (latency_sum_ok(iolat, &iolat->cur_stat) &&\n\t    latency_sum_ok(iolat, &stat)) {\n\t\tif (latency_stat_samples(iolat, &iolat->cur_stat) <\n\t\t    BLKIOLATENCY_MIN_GOOD_SAMPLES)\n\t\t\tgoto out;\n\t\tif (lat_info->scale_grp == iolat) {\n\t\t\tlat_info->last_scale_event = now;\n\t\t\tscale_cookie_change(iolat->blkiolat, lat_info, true);\n\t\t}\n\t} else if (lat_info->scale_lat == 0 ||\n\t\t   lat_info->scale_lat >= iolat->min_lat_nsec) {\n\t\tlat_info->last_scale_event = now;\n\t\tif (!lat_info->scale_grp ||\n\t\t    lat_info->scale_lat > iolat->min_lat_nsec) {\n\t\t\tWRITE_ONCE(lat_info->scale_lat, iolat->min_lat_nsec);\n\t\t\tlat_info->scale_grp = iolat;\n\t\t}\n\t\tscale_cookie_change(iolat->blkiolat, lat_info, false);\n\t}\n\tlatency_stat_init(iolat, &iolat->cur_stat);\nout:\n\tspin_unlock_irqrestore(&lat_info->lock, flags);\n}\n\nstatic void blkcg_iolatency_done_bio(struct rq_qos *rqos, struct bio *bio)\n{\n\tstruct blkcg_gq *blkg;\n\tstruct rq_wait *rqw;\n\tstruct iolatency_grp *iolat;\n\tu64 window_start;\n\tu64 now;\n\tbool issue_as_root = bio_issue_as_root_blkg(bio);\n\tint inflight = 0;\n\n\tblkg = bio->bi_blkg;\n\tif (!blkg || !bio_flagged(bio, BIO_QOS_THROTTLED))\n\t\treturn;\n\n\tiolat = blkg_to_lat(bio->bi_blkg);\n\tif (!iolat)\n\t\treturn;\n\n\tif (!iolat->blkiolat->enabled)\n\t\treturn;\n\n\tnow = ktime_to_ns(ktime_get());\n\twhile (blkg && blkg->parent) {\n\t\tiolat = blkg_to_lat(blkg);\n\t\tif (!iolat) {\n\t\t\tblkg = blkg->parent;\n\t\t\tcontinue;\n\t\t}\n\t\trqw = &iolat->rq_wait;\n\n\t\tinflight = atomic_dec_return(&rqw->inflight);\n\t\tWARN_ON_ONCE(inflight < 0);\n\t\t \n\t\tif (iolat->min_lat_nsec && bio->bi_status != BLK_STS_AGAIN) {\n\t\t\tiolatency_record_time(iolat, &bio->bi_issue, now,\n\t\t\t\t\t      issue_as_root);\n\t\t\twindow_start = atomic64_read(&iolat->window_start);\n\t\t\tif (now > window_start &&\n\t\t\t    (now - window_start) >= iolat->cur_win_nsec) {\n\t\t\t\tif (atomic64_try_cmpxchg(&iolat->window_start,\n\t\t\t\t\t\t\t &window_start, now))\n\t\t\t\t\tiolatency_check_latencies(iolat, now);\n\t\t\t}\n\t\t}\n\t\twake_up(&rqw->wait);\n\t\tblkg = blkg->parent;\n\t}\n}\n\nstatic void blkcg_iolatency_exit(struct rq_qos *rqos)\n{\n\tstruct blk_iolatency *blkiolat = BLKIOLATENCY(rqos);\n\n\ttimer_shutdown_sync(&blkiolat->timer);\n\tflush_work(&blkiolat->enable_work);\n\tblkcg_deactivate_policy(rqos->disk, &blkcg_policy_iolatency);\n\tkfree(blkiolat);\n}\n\nstatic const struct rq_qos_ops blkcg_iolatency_ops = {\n\t.throttle = blkcg_iolatency_throttle,\n\t.done_bio = blkcg_iolatency_done_bio,\n\t.exit = blkcg_iolatency_exit,\n};\n\nstatic void blkiolatency_timer_fn(struct timer_list *t)\n{\n\tstruct blk_iolatency *blkiolat = from_timer(blkiolat, t, timer);\n\tstruct blkcg_gq *blkg;\n\tstruct cgroup_subsys_state *pos_css;\n\tu64 now = ktime_to_ns(ktime_get());\n\n\trcu_read_lock();\n\tblkg_for_each_descendant_pre(blkg, pos_css,\n\t\t\t\t     blkiolat->rqos.disk->queue->root_blkg) {\n\t\tstruct iolatency_grp *iolat;\n\t\tstruct child_latency_info *lat_info;\n\t\tunsigned long flags;\n\t\tu64 cookie;\n\n\t\t \n\t\tif (!blkg_tryget(blkg))\n\t\t\tcontinue;\n\n\t\tiolat = blkg_to_lat(blkg);\n\t\tif (!iolat)\n\t\t\tgoto next;\n\n\t\tlat_info = &iolat->child_lat;\n\t\tcookie = atomic_read(&lat_info->scale_cookie);\n\n\t\tif (cookie >= DEFAULT_SCALE_COOKIE)\n\t\t\tgoto next;\n\n\t\tspin_lock_irqsave(&lat_info->lock, flags);\n\t\tif (lat_info->last_scale_event >= now)\n\t\t\tgoto next_lock;\n\n\t\t \n\t\tif (lat_info->scale_grp == NULL) {\n\t\t\tscale_cookie_change(iolat->blkiolat, lat_info, true);\n\t\t\tgoto next_lock;\n\t\t}\n\n\t\t \n\t\tif (now - lat_info->last_scale_event >=\n\t\t    ((u64)NSEC_PER_SEC * 5))\n\t\t\tlat_info->scale_grp = NULL;\nnext_lock:\n\t\tspin_unlock_irqrestore(&lat_info->lock, flags);\nnext:\n\t\tblkg_put(blkg);\n\t}\n\trcu_read_unlock();\n}\n\n \nstatic void blkiolatency_enable_work_fn(struct work_struct *work)\n{\n\tstruct blk_iolatency *blkiolat = container_of(work, struct blk_iolatency,\n\t\t\t\t\t\t      enable_work);\n\tbool enabled;\n\n\t \n\tenabled = atomic_read(&blkiolat->enable_cnt);\n\tif (enabled != blkiolat->enabled) {\n\t\tblk_mq_freeze_queue(blkiolat->rqos.disk->queue);\n\t\tblkiolat->enabled = enabled;\n\t\tblk_mq_unfreeze_queue(blkiolat->rqos.disk->queue);\n\t}\n}\n\nstatic int blk_iolatency_init(struct gendisk *disk)\n{\n\tstruct blk_iolatency *blkiolat;\n\tint ret;\n\n\tblkiolat = kzalloc(sizeof(*blkiolat), GFP_KERNEL);\n\tif (!blkiolat)\n\t\treturn -ENOMEM;\n\n\tret = rq_qos_add(&blkiolat->rqos, disk, RQ_QOS_LATENCY,\n\t\t\t &blkcg_iolatency_ops);\n\tif (ret)\n\t\tgoto err_free;\n\tret = blkcg_activate_policy(disk, &blkcg_policy_iolatency);\n\tif (ret)\n\t\tgoto err_qos_del;\n\n\ttimer_setup(&blkiolat->timer, blkiolatency_timer_fn, 0);\n\tINIT_WORK(&blkiolat->enable_work, blkiolatency_enable_work_fn);\n\n\treturn 0;\n\nerr_qos_del:\n\trq_qos_del(&blkiolat->rqos);\nerr_free:\n\tkfree(blkiolat);\n\treturn ret;\n}\n\nstatic void iolatency_set_min_lat_nsec(struct blkcg_gq *blkg, u64 val)\n{\n\tstruct iolatency_grp *iolat = blkg_to_lat(blkg);\n\tstruct blk_iolatency *blkiolat = iolat->blkiolat;\n\tu64 oldval = iolat->min_lat_nsec;\n\n\tiolat->min_lat_nsec = val;\n\tiolat->cur_win_nsec = max_t(u64, val << 4, BLKIOLATENCY_MIN_WIN_SIZE);\n\tiolat->cur_win_nsec = min_t(u64, iolat->cur_win_nsec,\n\t\t\t\t    BLKIOLATENCY_MAX_WIN_SIZE);\n\n\tif (!oldval && val) {\n\t\tif (atomic_inc_return(&blkiolat->enable_cnt) == 1)\n\t\t\tschedule_work(&blkiolat->enable_work);\n\t}\n\tif (oldval && !val) {\n\t\tblkcg_clear_delay(blkg);\n\t\tif (atomic_dec_return(&blkiolat->enable_cnt) == 0)\n\t\t\tschedule_work(&blkiolat->enable_work);\n\t}\n}\n\nstatic void iolatency_clear_scaling(struct blkcg_gq *blkg)\n{\n\tif (blkg->parent) {\n\t\tstruct iolatency_grp *iolat = blkg_to_lat(blkg->parent);\n\t\tstruct child_latency_info *lat_info;\n\t\tif (!iolat)\n\t\t\treturn;\n\n\t\tlat_info = &iolat->child_lat;\n\t\tspin_lock(&lat_info->lock);\n\t\tatomic_set(&lat_info->scale_cookie, DEFAULT_SCALE_COOKIE);\n\t\tlat_info->last_scale_event = 0;\n\t\tlat_info->scale_grp = NULL;\n\t\tlat_info->scale_lat = 0;\n\t\tspin_unlock(&lat_info->lock);\n\t}\n}\n\nstatic ssize_t iolatency_set_limit(struct kernfs_open_file *of, char *buf,\n\t\t\t     size_t nbytes, loff_t off)\n{\n\tstruct blkcg *blkcg = css_to_blkcg(of_css(of));\n\tstruct blkcg_gq *blkg;\n\tstruct blkg_conf_ctx ctx;\n\tstruct iolatency_grp *iolat;\n\tchar *p, *tok;\n\tu64 lat_val = 0;\n\tu64 oldval;\n\tint ret;\n\n\tblkg_conf_init(&ctx, buf);\n\n\tret = blkg_conf_open_bdev(&ctx);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tlockdep_assert_held(&ctx.bdev->bd_queue->rq_qos_mutex);\n\tif (!iolat_rq_qos(ctx.bdev->bd_queue))\n\t\tret = blk_iolatency_init(ctx.bdev->bd_disk);\n\tif (ret)\n\t\tgoto out;\n\n\tret = blkg_conf_prep(blkcg, &blkcg_policy_iolatency, &ctx);\n\tif (ret)\n\t\tgoto out;\n\n\tiolat = blkg_to_lat(ctx.blkg);\n\tp = ctx.body;\n\n\tret = -EINVAL;\n\twhile ((tok = strsep(&p, \" \"))) {\n\t\tchar key[16];\n\t\tchar val[21];\t \n\n\t\tif (sscanf(tok, \"%15[^=]=%20s\", key, val) != 2)\n\t\t\tgoto out;\n\n\t\tif (!strcmp(key, \"target\")) {\n\t\t\tu64 v;\n\n\t\t\tif (!strcmp(val, \"max\"))\n\t\t\t\tlat_val = 0;\n\t\t\telse if (sscanf(val, \"%llu\", &v) == 1)\n\t\t\t\tlat_val = v * NSEC_PER_USEC;\n\t\t\telse\n\t\t\t\tgoto out;\n\t\t} else {\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tblkg = ctx.blkg;\n\toldval = iolat->min_lat_nsec;\n\n\tiolatency_set_min_lat_nsec(blkg, lat_val);\n\tif (oldval != iolat->min_lat_nsec)\n\t\tiolatency_clear_scaling(blkg);\n\tret = 0;\nout:\n\tblkg_conf_exit(&ctx);\n\treturn ret ?: nbytes;\n}\n\nstatic u64 iolatency_prfill_limit(struct seq_file *sf,\n\t\t\t\t  struct blkg_policy_data *pd, int off)\n{\n\tstruct iolatency_grp *iolat = pd_to_lat(pd);\n\tconst char *dname = blkg_dev_name(pd->blkg);\n\n\tif (!dname || !iolat->min_lat_nsec)\n\t\treturn 0;\n\tseq_printf(sf, \"%s target=%llu\\n\",\n\t\t   dname, div_u64(iolat->min_lat_nsec, NSEC_PER_USEC));\n\treturn 0;\n}\n\nstatic int iolatency_print_limit(struct seq_file *sf, void *v)\n{\n\tblkcg_print_blkgs(sf, css_to_blkcg(seq_css(sf)),\n\t\t\t  iolatency_prfill_limit,\n\t\t\t  &blkcg_policy_iolatency, seq_cft(sf)->private, false);\n\treturn 0;\n}\n\nstatic void iolatency_ssd_stat(struct iolatency_grp *iolat, struct seq_file *s)\n{\n\tstruct latency_stat stat;\n\tint cpu;\n\n\tlatency_stat_init(iolat, &stat);\n\tpreempt_disable();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct latency_stat *s;\n\t\ts = per_cpu_ptr(iolat->stats, cpu);\n\t\tlatency_stat_sum(iolat, &stat, s);\n\t}\n\tpreempt_enable();\n\n\tif (iolat->max_depth == UINT_MAX)\n\t\tseq_printf(s, \" missed=%llu total=%llu depth=max\",\n\t\t\t(unsigned long long)stat.ps.missed,\n\t\t\t(unsigned long long)stat.ps.total);\n\telse\n\t\tseq_printf(s, \" missed=%llu total=%llu depth=%u\",\n\t\t\t(unsigned long long)stat.ps.missed,\n\t\t\t(unsigned long long)stat.ps.total,\n\t\t\tiolat->max_depth);\n}\n\nstatic void iolatency_pd_stat(struct blkg_policy_data *pd, struct seq_file *s)\n{\n\tstruct iolatency_grp *iolat = pd_to_lat(pd);\n\tunsigned long long avg_lat;\n\tunsigned long long cur_win;\n\n\tif (!blkcg_debug_stats)\n\t\treturn;\n\n\tif (iolat->ssd)\n\t\treturn iolatency_ssd_stat(iolat, s);\n\n\tavg_lat = div64_u64(iolat->lat_avg, NSEC_PER_USEC);\n\tcur_win = div64_u64(iolat->cur_win_nsec, NSEC_PER_MSEC);\n\tif (iolat->max_depth == UINT_MAX)\n\t\tseq_printf(s, \" depth=max avg_lat=%llu win=%llu\",\n\t\t\tavg_lat, cur_win);\n\telse\n\t\tseq_printf(s, \" depth=%u avg_lat=%llu win=%llu\",\n\t\t\tiolat->max_depth, avg_lat, cur_win);\n}\n\nstatic struct blkg_policy_data *iolatency_pd_alloc(struct gendisk *disk,\n\t\tstruct blkcg *blkcg, gfp_t gfp)\n{\n\tstruct iolatency_grp *iolat;\n\n\tiolat = kzalloc_node(sizeof(*iolat), gfp, disk->node_id);\n\tif (!iolat)\n\t\treturn NULL;\n\tiolat->stats = __alloc_percpu_gfp(sizeof(struct latency_stat),\n\t\t\t\t       __alignof__(struct latency_stat), gfp);\n\tif (!iolat->stats) {\n\t\tkfree(iolat);\n\t\treturn NULL;\n\t}\n\treturn &iolat->pd;\n}\n\nstatic void iolatency_pd_init(struct blkg_policy_data *pd)\n{\n\tstruct iolatency_grp *iolat = pd_to_lat(pd);\n\tstruct blkcg_gq *blkg = lat_to_blkg(iolat);\n\tstruct rq_qos *rqos = iolat_rq_qos(blkg->q);\n\tstruct blk_iolatency *blkiolat = BLKIOLATENCY(rqos);\n\tu64 now = ktime_to_ns(ktime_get());\n\tint cpu;\n\n\tif (blk_queue_nonrot(blkg->q))\n\t\tiolat->ssd = true;\n\telse\n\t\tiolat->ssd = false;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct latency_stat *stat;\n\t\tstat = per_cpu_ptr(iolat->stats, cpu);\n\t\tlatency_stat_init(iolat, stat);\n\t}\n\n\tlatency_stat_init(iolat, &iolat->cur_stat);\n\trq_wait_init(&iolat->rq_wait);\n\tspin_lock_init(&iolat->child_lat.lock);\n\tiolat->max_depth = UINT_MAX;\n\tiolat->blkiolat = blkiolat;\n\tiolat->cur_win_nsec = 100 * NSEC_PER_MSEC;\n\tatomic64_set(&iolat->window_start, now);\n\n\t \n\tif (blkg->parent && blkg_to_pd(blkg->parent, &blkcg_policy_iolatency)) {\n\t\tstruct iolatency_grp *parent = blkg_to_lat(blkg->parent);\n\t\tatomic_set(&iolat->scale_cookie,\n\t\t\t   atomic_read(&parent->child_lat.scale_cookie));\n\t} else {\n\t\tatomic_set(&iolat->scale_cookie, DEFAULT_SCALE_COOKIE);\n\t}\n\n\tatomic_set(&iolat->child_lat.scale_cookie, DEFAULT_SCALE_COOKIE);\n}\n\nstatic void iolatency_pd_offline(struct blkg_policy_data *pd)\n{\n\tstruct iolatency_grp *iolat = pd_to_lat(pd);\n\tstruct blkcg_gq *blkg = lat_to_blkg(iolat);\n\n\tiolatency_set_min_lat_nsec(blkg, 0);\n\tiolatency_clear_scaling(blkg);\n}\n\nstatic void iolatency_pd_free(struct blkg_policy_data *pd)\n{\n\tstruct iolatency_grp *iolat = pd_to_lat(pd);\n\tfree_percpu(iolat->stats);\n\tkfree(iolat);\n}\n\nstatic struct cftype iolatency_files[] = {\n\t{\n\t\t.name = \"latency\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.seq_show = iolatency_print_limit,\n\t\t.write = iolatency_set_limit,\n\t},\n\t{}\n};\n\nstatic struct blkcg_policy blkcg_policy_iolatency = {\n\t.dfl_cftypes\t= iolatency_files,\n\t.pd_alloc_fn\t= iolatency_pd_alloc,\n\t.pd_init_fn\t= iolatency_pd_init,\n\t.pd_offline_fn\t= iolatency_pd_offline,\n\t.pd_free_fn\t= iolatency_pd_free,\n\t.pd_stat_fn\t= iolatency_pd_stat,\n};\n\nstatic int __init iolatency_init(void)\n{\n\treturn blkcg_policy_register(&blkcg_policy_iolatency);\n}\n\nstatic void __exit iolatency_exit(void)\n{\n\tblkcg_policy_unregister(&blkcg_policy_iolatency);\n}\n\nmodule_init(iolatency_init);\nmodule_exit(iolatency_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}