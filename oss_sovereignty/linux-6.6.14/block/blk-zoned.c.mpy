{
  "module_name": "blk-zoned.c",
  "hash_id": "6b3954c795cd4781c4490418e97a3f813df17b3efdc69503578f6fe28ffa1652",
  "original_prompt": "Ingested from linux-6.6.14/block/blk-zoned.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/rbtree.h>\n#include <linux/blkdev.h>\n#include <linux/blk-mq.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/mm.h>\n\n#include \"blk.h\"\n\n#define ZONE_COND_NAME(name) [BLK_ZONE_COND_##name] = #name\nstatic const char *const zone_cond_name[] = {\n\tZONE_COND_NAME(NOT_WP),\n\tZONE_COND_NAME(EMPTY),\n\tZONE_COND_NAME(IMP_OPEN),\n\tZONE_COND_NAME(EXP_OPEN),\n\tZONE_COND_NAME(CLOSED),\n\tZONE_COND_NAME(READONLY),\n\tZONE_COND_NAME(FULL),\n\tZONE_COND_NAME(OFFLINE),\n};\n#undef ZONE_COND_NAME\n\n \nconst char *blk_zone_cond_str(enum blk_zone_cond zone_cond)\n{\n\tstatic const char *zone_cond_str = \"UNKNOWN\";\n\n\tif (zone_cond < ARRAY_SIZE(zone_cond_name) && zone_cond_name[zone_cond])\n\t\tzone_cond_str = zone_cond_name[zone_cond];\n\n\treturn zone_cond_str;\n}\nEXPORT_SYMBOL_GPL(blk_zone_cond_str);\n\n \nbool blk_req_needs_zone_write_lock(struct request *rq)\n{\n\tif (!rq->q->disk->seq_zones_wlock)\n\t\treturn false;\n\n\treturn blk_rq_is_seq_zoned_write(rq);\n}\nEXPORT_SYMBOL_GPL(blk_req_needs_zone_write_lock);\n\nbool blk_req_zone_write_trylock(struct request *rq)\n{\n\tunsigned int zno = blk_rq_zone_no(rq);\n\n\tif (test_and_set_bit(zno, rq->q->disk->seq_zones_wlock))\n\t\treturn false;\n\n\tWARN_ON_ONCE(rq->rq_flags & RQF_ZONE_WRITE_LOCKED);\n\trq->rq_flags |= RQF_ZONE_WRITE_LOCKED;\n\n\treturn true;\n}\nEXPORT_SYMBOL_GPL(blk_req_zone_write_trylock);\n\nvoid __blk_req_zone_write_lock(struct request *rq)\n{\n\tif (WARN_ON_ONCE(test_and_set_bit(blk_rq_zone_no(rq),\n\t\t\t\t\t  rq->q->disk->seq_zones_wlock)))\n\t\treturn;\n\n\tWARN_ON_ONCE(rq->rq_flags & RQF_ZONE_WRITE_LOCKED);\n\trq->rq_flags |= RQF_ZONE_WRITE_LOCKED;\n}\nEXPORT_SYMBOL_GPL(__blk_req_zone_write_lock);\n\nvoid __blk_req_zone_write_unlock(struct request *rq)\n{\n\trq->rq_flags &= ~RQF_ZONE_WRITE_LOCKED;\n\tif (rq->q->disk->seq_zones_wlock)\n\t\tWARN_ON_ONCE(!test_and_clear_bit(blk_rq_zone_no(rq),\n\t\t\t\t\t\t rq->q->disk->seq_zones_wlock));\n}\nEXPORT_SYMBOL_GPL(__blk_req_zone_write_unlock);\n\n \nunsigned int bdev_nr_zones(struct block_device *bdev)\n{\n\tsector_t zone_sectors = bdev_zone_sectors(bdev);\n\n\tif (!bdev_is_zoned(bdev))\n\t\treturn 0;\n\treturn (bdev_nr_sectors(bdev) + zone_sectors - 1) >>\n\t\tilog2(zone_sectors);\n}\nEXPORT_SYMBOL_GPL(bdev_nr_zones);\n\n \nint blkdev_report_zones(struct block_device *bdev, sector_t sector,\n\t\t\tunsigned int nr_zones, report_zones_cb cb, void *data)\n{\n\tstruct gendisk *disk = bdev->bd_disk;\n\tsector_t capacity = get_capacity(disk);\n\n\tif (!bdev_is_zoned(bdev) || WARN_ON_ONCE(!disk->fops->report_zones))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!nr_zones || sector >= capacity)\n\t\treturn 0;\n\n\treturn disk->fops->report_zones(disk, sector, nr_zones, cb, data);\n}\nEXPORT_SYMBOL_GPL(blkdev_report_zones);\n\nstatic inline unsigned long *blk_alloc_zone_bitmap(int node,\n\t\t\t\t\t\t   unsigned int nr_zones)\n{\n\treturn kcalloc_node(BITS_TO_LONGS(nr_zones), sizeof(unsigned long),\n\t\t\t    GFP_NOIO, node);\n}\n\nstatic int blk_zone_need_reset_cb(struct blk_zone *zone, unsigned int idx,\n\t\t\t\t  void *data)\n{\n\t \n\tswitch (zone->cond) {\n\tcase BLK_ZONE_COND_NOT_WP:\n\tcase BLK_ZONE_COND_EMPTY:\n\tcase BLK_ZONE_COND_READONLY:\n\tcase BLK_ZONE_COND_OFFLINE:\n\t\treturn 0;\n\tdefault:\n\t\tset_bit(idx, (unsigned long *)data);\n\t\treturn 0;\n\t}\n}\n\nstatic int blkdev_zone_reset_all_emulated(struct block_device *bdev,\n\t\t\t\t\t  gfp_t gfp_mask)\n{\n\tstruct gendisk *disk = bdev->bd_disk;\n\tsector_t capacity = bdev_nr_sectors(bdev);\n\tsector_t zone_sectors = bdev_zone_sectors(bdev);\n\tunsigned long *need_reset;\n\tstruct bio *bio = NULL;\n\tsector_t sector = 0;\n\tint ret;\n\n\tneed_reset = blk_alloc_zone_bitmap(disk->queue->node, disk->nr_zones);\n\tif (!need_reset)\n\t\treturn -ENOMEM;\n\n\tret = disk->fops->report_zones(disk, 0, disk->nr_zones,\n\t\t\t\t       blk_zone_need_reset_cb, need_reset);\n\tif (ret < 0)\n\t\tgoto out_free_need_reset;\n\n\tret = 0;\n\twhile (sector < capacity) {\n\t\tif (!test_bit(disk_zone_no(disk, sector), need_reset)) {\n\t\t\tsector += zone_sectors;\n\t\t\tcontinue;\n\t\t}\n\n\t\tbio = blk_next_bio(bio, bdev, 0, REQ_OP_ZONE_RESET | REQ_SYNC,\n\t\t\t\t   gfp_mask);\n\t\tbio->bi_iter.bi_sector = sector;\n\t\tsector += zone_sectors;\n\n\t\t \n\t\tcond_resched();\n\t}\n\n\tif (bio) {\n\t\tret = submit_bio_wait(bio);\n\t\tbio_put(bio);\n\t}\n\nout_free_need_reset:\n\tkfree(need_reset);\n\treturn ret;\n}\n\nstatic int blkdev_zone_reset_all(struct block_device *bdev, gfp_t gfp_mask)\n{\n\tstruct bio bio;\n\n\tbio_init(&bio, bdev, NULL, 0, REQ_OP_ZONE_RESET_ALL | REQ_SYNC);\n\treturn submit_bio_wait(&bio);\n}\n\n \nint blkdev_zone_mgmt(struct block_device *bdev, enum req_op op,\n\t\t     sector_t sector, sector_t nr_sectors, gfp_t gfp_mask)\n{\n\tstruct request_queue *q = bdev_get_queue(bdev);\n\tsector_t zone_sectors = bdev_zone_sectors(bdev);\n\tsector_t capacity = bdev_nr_sectors(bdev);\n\tsector_t end_sector = sector + nr_sectors;\n\tstruct bio *bio = NULL;\n\tint ret = 0;\n\n\tif (!bdev_is_zoned(bdev))\n\t\treturn -EOPNOTSUPP;\n\n\tif (bdev_read_only(bdev))\n\t\treturn -EPERM;\n\n\tif (!op_is_zone_mgmt(op))\n\t\treturn -EOPNOTSUPP;\n\n\tif (end_sector <= sector || end_sector > capacity)\n\t\t \n\t\treturn -EINVAL;\n\n\t \n\tif (!bdev_is_zone_start(bdev, sector))\n\t\treturn -EINVAL;\n\n\tif (!bdev_is_zone_start(bdev, nr_sectors) && end_sector != capacity)\n\t\treturn -EINVAL;\n\n\t \n\tif (op == REQ_OP_ZONE_RESET && sector == 0 && nr_sectors == capacity) {\n\t\tif (!blk_queue_zone_resetall(q))\n\t\t\treturn blkdev_zone_reset_all_emulated(bdev, gfp_mask);\n\t\treturn blkdev_zone_reset_all(bdev, gfp_mask);\n\t}\n\n\twhile (sector < end_sector) {\n\t\tbio = blk_next_bio(bio, bdev, 0, op | REQ_SYNC, gfp_mask);\n\t\tbio->bi_iter.bi_sector = sector;\n\t\tsector += zone_sectors;\n\n\t\t \n\t\tcond_resched();\n\t}\n\n\tret = submit_bio_wait(bio);\n\tbio_put(bio);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(blkdev_zone_mgmt);\n\nstruct zone_report_args {\n\tstruct blk_zone __user *zones;\n};\n\nstatic int blkdev_copy_zone_to_user(struct blk_zone *zone, unsigned int idx,\n\t\t\t\t    void *data)\n{\n\tstruct zone_report_args *args = data;\n\n\tif (copy_to_user(&args->zones[idx], zone, sizeof(struct blk_zone)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\n \nint blkdev_report_zones_ioctl(struct block_device *bdev, unsigned int cmd,\n\t\tunsigned long arg)\n{\n\tvoid __user *argp = (void __user *)arg;\n\tstruct zone_report_args args;\n\tstruct blk_zone_report rep;\n\tint ret;\n\n\tif (!argp)\n\t\treturn -EINVAL;\n\n\tif (!bdev_is_zoned(bdev))\n\t\treturn -ENOTTY;\n\n\tif (copy_from_user(&rep, argp, sizeof(struct blk_zone_report)))\n\t\treturn -EFAULT;\n\n\tif (!rep.nr_zones)\n\t\treturn -EINVAL;\n\n\targs.zones = argp + sizeof(struct blk_zone_report);\n\tret = blkdev_report_zones(bdev, rep.sector, rep.nr_zones,\n\t\t\t\t  blkdev_copy_zone_to_user, &args);\n\tif (ret < 0)\n\t\treturn ret;\n\n\trep.nr_zones = ret;\n\trep.flags = BLK_ZONE_REP_CAPACITY;\n\tif (copy_to_user(argp, &rep, sizeof(struct blk_zone_report)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int blkdev_truncate_zone_range(struct block_device *bdev,\n\t\tblk_mode_t mode, const struct blk_zone_range *zrange)\n{\n\tloff_t start, end;\n\n\tif (zrange->sector + zrange->nr_sectors <= zrange->sector ||\n\t    zrange->sector + zrange->nr_sectors > get_capacity(bdev->bd_disk))\n\t\t \n\t\treturn -EINVAL;\n\n\tstart = zrange->sector << SECTOR_SHIFT;\n\tend = ((zrange->sector + zrange->nr_sectors) << SECTOR_SHIFT) - 1;\n\n\treturn truncate_bdev_range(bdev, mode, start, end);\n}\n\n \nint blkdev_zone_mgmt_ioctl(struct block_device *bdev, blk_mode_t mode,\n\t\t\t   unsigned int cmd, unsigned long arg)\n{\n\tvoid __user *argp = (void __user *)arg;\n\tstruct blk_zone_range zrange;\n\tenum req_op op;\n\tint ret;\n\n\tif (!argp)\n\t\treturn -EINVAL;\n\n\tif (!bdev_is_zoned(bdev))\n\t\treturn -ENOTTY;\n\n\tif (!(mode & BLK_OPEN_WRITE))\n\t\treturn -EBADF;\n\n\tif (copy_from_user(&zrange, argp, sizeof(struct blk_zone_range)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase BLKRESETZONE:\n\t\top = REQ_OP_ZONE_RESET;\n\n\t\t \n\t\tfilemap_invalidate_lock(bdev->bd_inode->i_mapping);\n\t\tret = blkdev_truncate_zone_range(bdev, mode, &zrange);\n\t\tif (ret)\n\t\t\tgoto fail;\n\t\tbreak;\n\tcase BLKOPENZONE:\n\t\top = REQ_OP_ZONE_OPEN;\n\t\tbreak;\n\tcase BLKCLOSEZONE:\n\t\top = REQ_OP_ZONE_CLOSE;\n\t\tbreak;\n\tcase BLKFINISHZONE:\n\t\top = REQ_OP_ZONE_FINISH;\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n\n\tret = blkdev_zone_mgmt(bdev, op, zrange.sector, zrange.nr_sectors,\n\t\t\t       GFP_KERNEL);\n\nfail:\n\tif (cmd == BLKRESETZONE)\n\t\tfilemap_invalidate_unlock(bdev->bd_inode->i_mapping);\n\n\treturn ret;\n}\n\nvoid disk_free_zone_bitmaps(struct gendisk *disk)\n{\n\tkfree(disk->conv_zones_bitmap);\n\tdisk->conv_zones_bitmap = NULL;\n\tkfree(disk->seq_zones_wlock);\n\tdisk->seq_zones_wlock = NULL;\n}\n\nstruct blk_revalidate_zone_args {\n\tstruct gendisk\t*disk;\n\tunsigned long\t*conv_zones_bitmap;\n\tunsigned long\t*seq_zones_wlock;\n\tunsigned int\tnr_zones;\n\tsector_t\tsector;\n};\n\n \nstatic int blk_revalidate_zone_cb(struct blk_zone *zone, unsigned int idx,\n\t\t\t\t  void *data)\n{\n\tstruct blk_revalidate_zone_args *args = data;\n\tstruct gendisk *disk = args->disk;\n\tstruct request_queue *q = disk->queue;\n\tsector_t capacity = get_capacity(disk);\n\tsector_t zone_sectors = q->limits.chunk_sectors;\n\n\t \n\tif (zone->start != args->sector) {\n\t\tpr_warn(\"%s: Zone gap at sectors %llu..%llu\\n\",\n\t\t\tdisk->disk_name, args->sector, zone->start);\n\t\treturn -ENODEV;\n\t}\n\n\tif (zone->start >= capacity || !zone->len) {\n\t\tpr_warn(\"%s: Invalid zone start %llu, length %llu\\n\",\n\t\t\tdisk->disk_name, zone->start, zone->len);\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tif (zone->start + zone->len < capacity) {\n\t\tif (zone->len != zone_sectors) {\n\t\t\tpr_warn(\"%s: Invalid zoned device with non constant zone size\\n\",\n\t\t\t\tdisk->disk_name);\n\t\t\treturn -ENODEV;\n\t\t}\n\t} else if (zone->len > zone_sectors) {\n\t\tpr_warn(\"%s: Invalid zoned device with larger last zone size\\n\",\n\t\t\tdisk->disk_name);\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tswitch (zone->type) {\n\tcase BLK_ZONE_TYPE_CONVENTIONAL:\n\t\tif (!args->conv_zones_bitmap) {\n\t\t\targs->conv_zones_bitmap =\n\t\t\t\tblk_alloc_zone_bitmap(q->node, args->nr_zones);\n\t\t\tif (!args->conv_zones_bitmap)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\t\tset_bit(idx, args->conv_zones_bitmap);\n\t\tbreak;\n\tcase BLK_ZONE_TYPE_SEQWRITE_REQ:\n\tcase BLK_ZONE_TYPE_SEQWRITE_PREF:\n\t\tif (!args->seq_zones_wlock) {\n\t\t\targs->seq_zones_wlock =\n\t\t\t\tblk_alloc_zone_bitmap(q->node, args->nr_zones);\n\t\t\tif (!args->seq_zones_wlock)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"%s: Invalid zone type 0x%x at sectors %llu\\n\",\n\t\t\tdisk->disk_name, (int)zone->type, zone->start);\n\t\treturn -ENODEV;\n\t}\n\n\targs->sector += zone->len;\n\treturn 0;\n}\n\n \nint blk_revalidate_disk_zones(struct gendisk *disk,\n\t\t\t      void (*update_driver_data)(struct gendisk *disk))\n{\n\tstruct request_queue *q = disk->queue;\n\tsector_t zone_sectors = q->limits.chunk_sectors;\n\tsector_t capacity = get_capacity(disk);\n\tstruct blk_revalidate_zone_args args = { };\n\tunsigned int noio_flag;\n\tint ret;\n\n\tif (WARN_ON_ONCE(!blk_queue_is_zoned(q)))\n\t\treturn -EIO;\n\tif (WARN_ON_ONCE(!queue_is_mq(q)))\n\t\treturn -EIO;\n\n\tif (!capacity)\n\t\treturn -ENODEV;\n\n\t \n\tif (!zone_sectors || !is_power_of_2(zone_sectors)) {\n\t\tpr_warn(\"%s: Invalid non power of two zone size (%llu)\\n\",\n\t\t\tdisk->disk_name, zone_sectors);\n\t\treturn -ENODEV;\n\t}\n\n\tif (!q->limits.max_zone_append_sectors) {\n\t\tpr_warn(\"%s: Invalid 0 maximum zone append limit\\n\",\n\t\t\tdisk->disk_name);\n\t\treturn -ENODEV;\n\t}\n\n\t \n\targs.disk = disk;\n\targs.nr_zones = (capacity + zone_sectors - 1) >> ilog2(zone_sectors);\n\tnoio_flag = memalloc_noio_save();\n\tret = disk->fops->report_zones(disk, 0, UINT_MAX,\n\t\t\t\t       blk_revalidate_zone_cb, &args);\n\tif (!ret) {\n\t\tpr_warn(\"%s: No zones reported\\n\", disk->disk_name);\n\t\tret = -ENODEV;\n\t}\n\tmemalloc_noio_restore(noio_flag);\n\n\t \n\tif (ret > 0 && args.sector != capacity) {\n\t\tpr_warn(\"%s: Missing zones from sector %llu\\n\",\n\t\t\tdisk->disk_name, args.sector);\n\t\tret = -ENODEV;\n\t}\n\n\t \n\tblk_mq_freeze_queue(q);\n\tif (ret > 0) {\n\t\tdisk->nr_zones = args.nr_zones;\n\t\tswap(disk->seq_zones_wlock, args.seq_zones_wlock);\n\t\tswap(disk->conv_zones_bitmap, args.conv_zones_bitmap);\n\t\tif (update_driver_data)\n\t\t\tupdate_driver_data(disk);\n\t\tret = 0;\n\t} else {\n\t\tpr_warn(\"%s: failed to revalidate zones\\n\", disk->disk_name);\n\t\tdisk_free_zone_bitmaps(disk);\n\t}\n\tblk_mq_unfreeze_queue(q);\n\n\tkfree(args.seq_zones_wlock);\n\tkfree(args.conv_zones_bitmap);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(blk_revalidate_disk_zones);\n\nvoid disk_clear_zone_settings(struct gendisk *disk)\n{\n\tstruct request_queue *q = disk->queue;\n\n\tblk_mq_freeze_queue(q);\n\n\tdisk_free_zone_bitmaps(disk);\n\tblk_queue_flag_clear(QUEUE_FLAG_ZONE_RESETALL, q);\n\tq->required_elevator_features &= ~ELEVATOR_F_ZBD_SEQ_WRITE;\n\tdisk->nr_zones = 0;\n\tdisk->max_open_zones = 0;\n\tdisk->max_active_zones = 0;\n\tq->limits.chunk_sectors = 0;\n\tq->limits.zone_write_granularity = 0;\n\tq->limits.max_zone_append_sectors = 0;\n\n\tblk_mq_unfreeze_queue(q);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}