{
  "module_name": "blk-mq-debugfs.c",
  "hash_id": "625112ef46133e53443b3d9f563947400dc1914fecf8df55df33445ff93de425",
  "original_prompt": "Ingested from linux-6.6.14/block/blk-mq-debugfs.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/blkdev.h>\n#include <linux/debugfs.h>\n\n#include \"blk.h\"\n#include \"blk-mq.h\"\n#include \"blk-mq-debugfs.h\"\n#include \"blk-mq-sched.h\"\n#include \"blk-rq-qos.h\"\n\nstatic int queue_poll_stat_show(void *data, struct seq_file *m)\n{\n\treturn 0;\n}\n\nstatic void *queue_requeue_list_start(struct seq_file *m, loff_t *pos)\n\t__acquires(&q->requeue_lock)\n{\n\tstruct request_queue *q = m->private;\n\n\tspin_lock_irq(&q->requeue_lock);\n\treturn seq_list_start(&q->requeue_list, *pos);\n}\n\nstatic void *queue_requeue_list_next(struct seq_file *m, void *v, loff_t *pos)\n{\n\tstruct request_queue *q = m->private;\n\n\treturn seq_list_next(v, &q->requeue_list, pos);\n}\n\nstatic void queue_requeue_list_stop(struct seq_file *m, void *v)\n\t__releases(&q->requeue_lock)\n{\n\tstruct request_queue *q = m->private;\n\n\tspin_unlock_irq(&q->requeue_lock);\n}\n\nstatic const struct seq_operations queue_requeue_list_seq_ops = {\n\t.start\t= queue_requeue_list_start,\n\t.next\t= queue_requeue_list_next,\n\t.stop\t= queue_requeue_list_stop,\n\t.show\t= blk_mq_debugfs_rq_show,\n};\n\nstatic int blk_flags_show(struct seq_file *m, const unsigned long flags,\n\t\t\t  const char *const *flag_name, int flag_name_count)\n{\n\tbool sep = false;\n\tint i;\n\n\tfor (i = 0; i < sizeof(flags) * BITS_PER_BYTE; i++) {\n\t\tif (!(flags & BIT(i)))\n\t\t\tcontinue;\n\t\tif (sep)\n\t\t\tseq_puts(m, \"|\");\n\t\tsep = true;\n\t\tif (i < flag_name_count && flag_name[i])\n\t\t\tseq_puts(m, flag_name[i]);\n\t\telse\n\t\t\tseq_printf(m, \"%d\", i);\n\t}\n\treturn 0;\n}\n\nstatic int queue_pm_only_show(void *data, struct seq_file *m)\n{\n\tstruct request_queue *q = data;\n\n\tseq_printf(m, \"%d\\n\", atomic_read(&q->pm_only));\n\treturn 0;\n}\n\n#define QUEUE_FLAG_NAME(name) [QUEUE_FLAG_##name] = #name\nstatic const char *const blk_queue_flag_name[] = {\n\tQUEUE_FLAG_NAME(STOPPED),\n\tQUEUE_FLAG_NAME(DYING),\n\tQUEUE_FLAG_NAME(NOMERGES),\n\tQUEUE_FLAG_NAME(SAME_COMP),\n\tQUEUE_FLAG_NAME(FAIL_IO),\n\tQUEUE_FLAG_NAME(NONROT),\n\tQUEUE_FLAG_NAME(IO_STAT),\n\tQUEUE_FLAG_NAME(NOXMERGES),\n\tQUEUE_FLAG_NAME(ADD_RANDOM),\n\tQUEUE_FLAG_NAME(SYNCHRONOUS),\n\tQUEUE_FLAG_NAME(SAME_FORCE),\n\tQUEUE_FLAG_NAME(INIT_DONE),\n\tQUEUE_FLAG_NAME(STABLE_WRITES),\n\tQUEUE_FLAG_NAME(POLL),\n\tQUEUE_FLAG_NAME(WC),\n\tQUEUE_FLAG_NAME(FUA),\n\tQUEUE_FLAG_NAME(DAX),\n\tQUEUE_FLAG_NAME(STATS),\n\tQUEUE_FLAG_NAME(REGISTERED),\n\tQUEUE_FLAG_NAME(QUIESCED),\n\tQUEUE_FLAG_NAME(PCI_P2PDMA),\n\tQUEUE_FLAG_NAME(ZONE_RESETALL),\n\tQUEUE_FLAG_NAME(RQ_ALLOC_TIME),\n\tQUEUE_FLAG_NAME(HCTX_ACTIVE),\n\tQUEUE_FLAG_NAME(NOWAIT),\n\tQUEUE_FLAG_NAME(SQ_SCHED),\n\tQUEUE_FLAG_NAME(SKIP_TAGSET_QUIESCE),\n};\n#undef QUEUE_FLAG_NAME\n\nstatic int queue_state_show(void *data, struct seq_file *m)\n{\n\tstruct request_queue *q = data;\n\n\tblk_flags_show(m, q->queue_flags, blk_queue_flag_name,\n\t\t       ARRAY_SIZE(blk_queue_flag_name));\n\tseq_puts(m, \"\\n\");\n\treturn 0;\n}\n\nstatic ssize_t queue_state_write(void *data, const char __user *buf,\n\t\t\t\t size_t count, loff_t *ppos)\n{\n\tstruct request_queue *q = data;\n\tchar opbuf[16] = { }, *op;\n\n\t \n\tif (blk_queue_dying(q))\n\t\treturn -ENOENT;\n\n\tif (count >= sizeof(opbuf)) {\n\t\tpr_err(\"%s: operation too long\\n\", __func__);\n\t\tgoto inval;\n\t}\n\n\tif (copy_from_user(opbuf, buf, count))\n\t\treturn -EFAULT;\n\top = strstrip(opbuf);\n\tif (strcmp(op, \"run\") == 0) {\n\t\tblk_mq_run_hw_queues(q, true);\n\t} else if (strcmp(op, \"start\") == 0) {\n\t\tblk_mq_start_stopped_hw_queues(q, true);\n\t} else if (strcmp(op, \"kick\") == 0) {\n\t\tblk_mq_kick_requeue_list(q);\n\t} else {\n\t\tpr_err(\"%s: unsupported operation '%s'\\n\", __func__, op);\ninval:\n\t\tpr_err(\"%s: use 'run', 'start' or 'kick'\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\treturn count;\n}\n\nstatic const struct blk_mq_debugfs_attr blk_mq_debugfs_queue_attrs[] = {\n\t{ \"poll_stat\", 0400, queue_poll_stat_show },\n\t{ \"requeue_list\", 0400, .seq_ops = &queue_requeue_list_seq_ops },\n\t{ \"pm_only\", 0600, queue_pm_only_show, NULL },\n\t{ \"state\", 0600, queue_state_show, queue_state_write },\n\t{ \"zone_wlock\", 0400, queue_zone_wlock_show, NULL },\n\t{ },\n};\n\n#define HCTX_STATE_NAME(name) [BLK_MQ_S_##name] = #name\nstatic const char *const hctx_state_name[] = {\n\tHCTX_STATE_NAME(STOPPED),\n\tHCTX_STATE_NAME(TAG_ACTIVE),\n\tHCTX_STATE_NAME(SCHED_RESTART),\n\tHCTX_STATE_NAME(INACTIVE),\n};\n#undef HCTX_STATE_NAME\n\nstatic int hctx_state_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\n\tblk_flags_show(m, hctx->state, hctx_state_name,\n\t\t       ARRAY_SIZE(hctx_state_name));\n\tseq_puts(m, \"\\n\");\n\treturn 0;\n}\n\n#define BLK_TAG_ALLOC_NAME(name) [BLK_TAG_ALLOC_##name] = #name\nstatic const char *const alloc_policy_name[] = {\n\tBLK_TAG_ALLOC_NAME(FIFO),\n\tBLK_TAG_ALLOC_NAME(RR),\n};\n#undef BLK_TAG_ALLOC_NAME\n\n#define HCTX_FLAG_NAME(name) [ilog2(BLK_MQ_F_##name)] = #name\nstatic const char *const hctx_flag_name[] = {\n\tHCTX_FLAG_NAME(SHOULD_MERGE),\n\tHCTX_FLAG_NAME(TAG_QUEUE_SHARED),\n\tHCTX_FLAG_NAME(BLOCKING),\n\tHCTX_FLAG_NAME(NO_SCHED),\n\tHCTX_FLAG_NAME(STACKING),\n\tHCTX_FLAG_NAME(TAG_HCTX_SHARED),\n};\n#undef HCTX_FLAG_NAME\n\nstatic int hctx_flags_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\tconst int alloc_policy = BLK_MQ_FLAG_TO_ALLOC_POLICY(hctx->flags);\n\n\tseq_puts(m, \"alloc_policy=\");\n\tif (alloc_policy < ARRAY_SIZE(alloc_policy_name) &&\n\t    alloc_policy_name[alloc_policy])\n\t\tseq_puts(m, alloc_policy_name[alloc_policy]);\n\telse\n\t\tseq_printf(m, \"%d\", alloc_policy);\n\tseq_puts(m, \" \");\n\tblk_flags_show(m,\n\t\t       hctx->flags ^ BLK_ALLOC_POLICY_TO_MQ_FLAG(alloc_policy),\n\t\t       hctx_flag_name, ARRAY_SIZE(hctx_flag_name));\n\tseq_puts(m, \"\\n\");\n\treturn 0;\n}\n\n#define CMD_FLAG_NAME(name) [__REQ_##name] = #name\nstatic const char *const cmd_flag_name[] = {\n\tCMD_FLAG_NAME(FAILFAST_DEV),\n\tCMD_FLAG_NAME(FAILFAST_TRANSPORT),\n\tCMD_FLAG_NAME(FAILFAST_DRIVER),\n\tCMD_FLAG_NAME(SYNC),\n\tCMD_FLAG_NAME(META),\n\tCMD_FLAG_NAME(PRIO),\n\tCMD_FLAG_NAME(NOMERGE),\n\tCMD_FLAG_NAME(IDLE),\n\tCMD_FLAG_NAME(INTEGRITY),\n\tCMD_FLAG_NAME(FUA),\n\tCMD_FLAG_NAME(PREFLUSH),\n\tCMD_FLAG_NAME(RAHEAD),\n\tCMD_FLAG_NAME(BACKGROUND),\n\tCMD_FLAG_NAME(NOWAIT),\n\tCMD_FLAG_NAME(NOUNMAP),\n\tCMD_FLAG_NAME(POLLED),\n};\n#undef CMD_FLAG_NAME\n\n#define RQF_NAME(name) [ilog2((__force u32)RQF_##name)] = #name\nstatic const char *const rqf_name[] = {\n\tRQF_NAME(STARTED),\n\tRQF_NAME(FLUSH_SEQ),\n\tRQF_NAME(MIXED_MERGE),\n\tRQF_NAME(MQ_INFLIGHT),\n\tRQF_NAME(DONTPREP),\n\tRQF_NAME(SCHED_TAGS),\n\tRQF_NAME(USE_SCHED),\n\tRQF_NAME(FAILED),\n\tRQF_NAME(QUIET),\n\tRQF_NAME(IO_STAT),\n\tRQF_NAME(PM),\n\tRQF_NAME(HASHED),\n\tRQF_NAME(STATS),\n\tRQF_NAME(SPECIAL_PAYLOAD),\n\tRQF_NAME(ZONE_WRITE_LOCKED),\n\tRQF_NAME(TIMED_OUT),\n\tRQF_NAME(RESV),\n};\n#undef RQF_NAME\n\nstatic const char *const blk_mq_rq_state_name_array[] = {\n\t[MQ_RQ_IDLE]\t\t= \"idle\",\n\t[MQ_RQ_IN_FLIGHT]\t= \"in_flight\",\n\t[MQ_RQ_COMPLETE]\t= \"complete\",\n};\n\nstatic const char *blk_mq_rq_state_name(enum mq_rq_state rq_state)\n{\n\tif (WARN_ON_ONCE((unsigned int)rq_state >=\n\t\t\t ARRAY_SIZE(blk_mq_rq_state_name_array)))\n\t\treturn \"(?)\";\n\treturn blk_mq_rq_state_name_array[rq_state];\n}\n\nint __blk_mq_debugfs_rq_show(struct seq_file *m, struct request *rq)\n{\n\tconst struct blk_mq_ops *const mq_ops = rq->q->mq_ops;\n\tconst enum req_op op = req_op(rq);\n\tconst char *op_str = blk_op_str(op);\n\n\tseq_printf(m, \"%p {.op=\", rq);\n\tif (strcmp(op_str, \"UNKNOWN\") == 0)\n\t\tseq_printf(m, \"%u\", op);\n\telse\n\t\tseq_printf(m, \"%s\", op_str);\n\tseq_puts(m, \", .cmd_flags=\");\n\tblk_flags_show(m, (__force unsigned int)(rq->cmd_flags & ~REQ_OP_MASK),\n\t\t       cmd_flag_name, ARRAY_SIZE(cmd_flag_name));\n\tseq_puts(m, \", .rq_flags=\");\n\tblk_flags_show(m, (__force unsigned int)rq->rq_flags, rqf_name,\n\t\t       ARRAY_SIZE(rqf_name));\n\tseq_printf(m, \", .state=%s\", blk_mq_rq_state_name(blk_mq_rq_state(rq)));\n\tseq_printf(m, \", .tag=%d, .internal_tag=%d\", rq->tag,\n\t\t   rq->internal_tag);\n\tif (mq_ops->show_rq)\n\t\tmq_ops->show_rq(m, rq);\n\tseq_puts(m, \"}\\n\");\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__blk_mq_debugfs_rq_show);\n\nint blk_mq_debugfs_rq_show(struct seq_file *m, void *v)\n{\n\treturn __blk_mq_debugfs_rq_show(m, list_entry_rq(v));\n}\nEXPORT_SYMBOL_GPL(blk_mq_debugfs_rq_show);\n\nstatic void *hctx_dispatch_start(struct seq_file *m, loff_t *pos)\n\t__acquires(&hctx->lock)\n{\n\tstruct blk_mq_hw_ctx *hctx = m->private;\n\n\tspin_lock(&hctx->lock);\n\treturn seq_list_start(&hctx->dispatch, *pos);\n}\n\nstatic void *hctx_dispatch_next(struct seq_file *m, void *v, loff_t *pos)\n{\n\tstruct blk_mq_hw_ctx *hctx = m->private;\n\n\treturn seq_list_next(v, &hctx->dispatch, pos);\n}\n\nstatic void hctx_dispatch_stop(struct seq_file *m, void *v)\n\t__releases(&hctx->lock)\n{\n\tstruct blk_mq_hw_ctx *hctx = m->private;\n\n\tspin_unlock(&hctx->lock);\n}\n\nstatic const struct seq_operations hctx_dispatch_seq_ops = {\n\t.start\t= hctx_dispatch_start,\n\t.next\t= hctx_dispatch_next,\n\t.stop\t= hctx_dispatch_stop,\n\t.show\t= blk_mq_debugfs_rq_show,\n};\n\nstruct show_busy_params {\n\tstruct seq_file\t\t*m;\n\tstruct blk_mq_hw_ctx\t*hctx;\n};\n\n \nstatic bool hctx_show_busy_rq(struct request *rq, void *data)\n{\n\tconst struct show_busy_params *params = data;\n\n\tif (rq->mq_hctx == params->hctx)\n\t\t__blk_mq_debugfs_rq_show(params->m, rq);\n\n\treturn true;\n}\n\nstatic int hctx_busy_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\tstruct show_busy_params params = { .m = m, .hctx = hctx };\n\n\tblk_mq_tagset_busy_iter(hctx->queue->tag_set, hctx_show_busy_rq,\n\t\t\t\t&params);\n\n\treturn 0;\n}\n\nstatic const char *const hctx_types[] = {\n\t[HCTX_TYPE_DEFAULT]\t= \"default\",\n\t[HCTX_TYPE_READ]\t= \"read\",\n\t[HCTX_TYPE_POLL]\t= \"poll\",\n};\n\nstatic int hctx_type_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(hctx_types) != HCTX_MAX_TYPES);\n\tseq_printf(m, \"%s\\n\", hctx_types[hctx->type]);\n\treturn 0;\n}\n\nstatic int hctx_ctx_map_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\n\tsbitmap_bitmap_show(&hctx->ctx_map, m);\n\treturn 0;\n}\n\nstatic void blk_mq_debugfs_tags_show(struct seq_file *m,\n\t\t\t\t     struct blk_mq_tags *tags)\n{\n\tseq_printf(m, \"nr_tags=%u\\n\", tags->nr_tags);\n\tseq_printf(m, \"nr_reserved_tags=%u\\n\", tags->nr_reserved_tags);\n\tseq_printf(m, \"active_queues=%d\\n\",\n\t\t   READ_ONCE(tags->active_queues));\n\n\tseq_puts(m, \"\\nbitmap_tags:\\n\");\n\tsbitmap_queue_show(&tags->bitmap_tags, m);\n\n\tif (tags->nr_reserved_tags) {\n\t\tseq_puts(m, \"\\nbreserved_tags:\\n\");\n\t\tsbitmap_queue_show(&tags->breserved_tags, m);\n\t}\n}\n\nstatic int hctx_tags_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\tstruct request_queue *q = hctx->queue;\n\tint res;\n\n\tres = mutex_lock_interruptible(&q->sysfs_lock);\n\tif (res)\n\t\tgoto out;\n\tif (hctx->tags)\n\t\tblk_mq_debugfs_tags_show(m, hctx->tags);\n\tmutex_unlock(&q->sysfs_lock);\n\nout:\n\treturn res;\n}\n\nstatic int hctx_tags_bitmap_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\tstruct request_queue *q = hctx->queue;\n\tint res;\n\n\tres = mutex_lock_interruptible(&q->sysfs_lock);\n\tif (res)\n\t\tgoto out;\n\tif (hctx->tags)\n\t\tsbitmap_bitmap_show(&hctx->tags->bitmap_tags.sb, m);\n\tmutex_unlock(&q->sysfs_lock);\n\nout:\n\treturn res;\n}\n\nstatic int hctx_sched_tags_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\tstruct request_queue *q = hctx->queue;\n\tint res;\n\n\tres = mutex_lock_interruptible(&q->sysfs_lock);\n\tif (res)\n\t\tgoto out;\n\tif (hctx->sched_tags)\n\t\tblk_mq_debugfs_tags_show(m, hctx->sched_tags);\n\tmutex_unlock(&q->sysfs_lock);\n\nout:\n\treturn res;\n}\n\nstatic int hctx_sched_tags_bitmap_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\tstruct request_queue *q = hctx->queue;\n\tint res;\n\n\tres = mutex_lock_interruptible(&q->sysfs_lock);\n\tif (res)\n\t\tgoto out;\n\tif (hctx->sched_tags)\n\t\tsbitmap_bitmap_show(&hctx->sched_tags->bitmap_tags.sb, m);\n\tmutex_unlock(&q->sysfs_lock);\n\nout:\n\treturn res;\n}\n\nstatic int hctx_run_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\n\tseq_printf(m, \"%lu\\n\", hctx->run);\n\treturn 0;\n}\n\nstatic ssize_t hctx_run_write(void *data, const char __user *buf, size_t count,\n\t\t\t      loff_t *ppos)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\n\thctx->run = 0;\n\treturn count;\n}\n\nstatic int hctx_active_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\n\tseq_printf(m, \"%d\\n\", __blk_mq_active_requests(hctx));\n\treturn 0;\n}\n\nstatic int hctx_dispatch_busy_show(void *data, struct seq_file *m)\n{\n\tstruct blk_mq_hw_ctx *hctx = data;\n\n\tseq_printf(m, \"%u\\n\", hctx->dispatch_busy);\n\treturn 0;\n}\n\n#define CTX_RQ_SEQ_OPS(name, type)\t\t\t\t\t\\\nstatic void *ctx_##name##_rq_list_start(struct seq_file *m, loff_t *pos) \\\n\t__acquires(&ctx->lock)\t\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tstruct blk_mq_ctx *ctx = m->private;\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tspin_lock(&ctx->lock);\t\t\t\t\t\t\\\n\treturn seq_list_start(&ctx->rq_lists[type], *pos);\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\nstatic void *ctx_##name##_rq_list_next(struct seq_file *m, void *v,\t\\\n\t\t\t\t     loff_t *pos)\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tstruct blk_mq_ctx *ctx = m->private;\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\treturn seq_list_next(v, &ctx->rq_lists[type], pos);\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\nstatic void ctx_##name##_rq_list_stop(struct seq_file *m, void *v)\t\\\n\t__releases(&ctx->lock)\t\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tstruct blk_mq_ctx *ctx = m->private;\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tspin_unlock(&ctx->lock);\t\t\t\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\nstatic const struct seq_operations ctx_##name##_rq_list_seq_ops = {\t\\\n\t.start\t= ctx_##name##_rq_list_start,\t\t\t\t\\\n\t.next\t= ctx_##name##_rq_list_next,\t\t\t\t\\\n\t.stop\t= ctx_##name##_rq_list_stop,\t\t\t\t\\\n\t.show\t= blk_mq_debugfs_rq_show,\t\t\t\t\\\n}\n\nCTX_RQ_SEQ_OPS(default, HCTX_TYPE_DEFAULT);\nCTX_RQ_SEQ_OPS(read, HCTX_TYPE_READ);\nCTX_RQ_SEQ_OPS(poll, HCTX_TYPE_POLL);\n\nstatic int blk_mq_debugfs_show(struct seq_file *m, void *v)\n{\n\tconst struct blk_mq_debugfs_attr *attr = m->private;\n\tvoid *data = d_inode(m->file->f_path.dentry->d_parent)->i_private;\n\n\treturn attr->show(data, m);\n}\n\nstatic ssize_t blk_mq_debugfs_write(struct file *file, const char __user *buf,\n\t\t\t\t    size_t count, loff_t *ppos)\n{\n\tstruct seq_file *m = file->private_data;\n\tconst struct blk_mq_debugfs_attr *attr = m->private;\n\tvoid *data = d_inode(file->f_path.dentry->d_parent)->i_private;\n\n\t \n\tif (attr == data || !attr->write)\n\t\treturn -EPERM;\n\n\treturn attr->write(data, buf, count, ppos);\n}\n\nstatic int blk_mq_debugfs_open(struct inode *inode, struct file *file)\n{\n\tconst struct blk_mq_debugfs_attr *attr = inode->i_private;\n\tvoid *data = d_inode(file->f_path.dentry->d_parent)->i_private;\n\tstruct seq_file *m;\n\tint ret;\n\n\tif (attr->seq_ops) {\n\t\tret = seq_open(file, attr->seq_ops);\n\t\tif (!ret) {\n\t\t\tm = file->private_data;\n\t\t\tm->private = data;\n\t\t}\n\t\treturn ret;\n\t}\n\n\tif (WARN_ON_ONCE(!attr->show))\n\t\treturn -EPERM;\n\n\treturn single_open(file, blk_mq_debugfs_show, inode->i_private);\n}\n\nstatic int blk_mq_debugfs_release(struct inode *inode, struct file *file)\n{\n\tconst struct blk_mq_debugfs_attr *attr = inode->i_private;\n\n\tif (attr->show)\n\t\treturn single_release(inode, file);\n\n\treturn seq_release(inode, file);\n}\n\nstatic const struct file_operations blk_mq_debugfs_fops = {\n\t.open\t\t= blk_mq_debugfs_open,\n\t.read\t\t= seq_read,\n\t.write\t\t= blk_mq_debugfs_write,\n\t.llseek\t\t= seq_lseek,\n\t.release\t= blk_mq_debugfs_release,\n};\n\nstatic const struct blk_mq_debugfs_attr blk_mq_debugfs_hctx_attrs[] = {\n\t{\"state\", 0400, hctx_state_show},\n\t{\"flags\", 0400, hctx_flags_show},\n\t{\"dispatch\", 0400, .seq_ops = &hctx_dispatch_seq_ops},\n\t{\"busy\", 0400, hctx_busy_show},\n\t{\"ctx_map\", 0400, hctx_ctx_map_show},\n\t{\"tags\", 0400, hctx_tags_show},\n\t{\"tags_bitmap\", 0400, hctx_tags_bitmap_show},\n\t{\"sched_tags\", 0400, hctx_sched_tags_show},\n\t{\"sched_tags_bitmap\", 0400, hctx_sched_tags_bitmap_show},\n\t{\"run\", 0600, hctx_run_show, hctx_run_write},\n\t{\"active\", 0400, hctx_active_show},\n\t{\"dispatch_busy\", 0400, hctx_dispatch_busy_show},\n\t{\"type\", 0400, hctx_type_show},\n\t{},\n};\n\nstatic const struct blk_mq_debugfs_attr blk_mq_debugfs_ctx_attrs[] = {\n\t{\"default_rq_list\", 0400, .seq_ops = &ctx_default_rq_list_seq_ops},\n\t{\"read_rq_list\", 0400, .seq_ops = &ctx_read_rq_list_seq_ops},\n\t{\"poll_rq_list\", 0400, .seq_ops = &ctx_poll_rq_list_seq_ops},\n\t{},\n};\n\nstatic void debugfs_create_files(struct dentry *parent, void *data,\n\t\t\t\t const struct blk_mq_debugfs_attr *attr)\n{\n\tif (IS_ERR_OR_NULL(parent))\n\t\treturn;\n\n\td_inode(parent)->i_private = data;\n\n\tfor (; attr->name; attr++)\n\t\tdebugfs_create_file(attr->name, attr->mode, parent,\n\t\t\t\t    (void *)attr, &blk_mq_debugfs_fops);\n}\n\nvoid blk_mq_debugfs_register(struct request_queue *q)\n{\n\tstruct blk_mq_hw_ctx *hctx;\n\tunsigned long i;\n\n\tdebugfs_create_files(q->debugfs_dir, q, blk_mq_debugfs_queue_attrs);\n\n\t \n\tif (q->elevator && !q->sched_debugfs_dir)\n\t\tblk_mq_debugfs_register_sched(q);\n\n\t \n\tqueue_for_each_hw_ctx(q, hctx, i) {\n\t\tif (!hctx->debugfs_dir)\n\t\t\tblk_mq_debugfs_register_hctx(q, hctx);\n\t\tif (q->elevator && !hctx->sched_debugfs_dir)\n\t\t\tblk_mq_debugfs_register_sched_hctx(q, hctx);\n\t}\n\n\tif (q->rq_qos) {\n\t\tstruct rq_qos *rqos = q->rq_qos;\n\n\t\twhile (rqos) {\n\t\t\tblk_mq_debugfs_register_rqos(rqos);\n\t\t\trqos = rqos->next;\n\t\t}\n\t}\n}\n\nstatic void blk_mq_debugfs_register_ctx(struct blk_mq_hw_ctx *hctx,\n\t\t\t\t\tstruct blk_mq_ctx *ctx)\n{\n\tstruct dentry *ctx_dir;\n\tchar name[20];\n\n\tsnprintf(name, sizeof(name), \"cpu%u\", ctx->cpu);\n\tctx_dir = debugfs_create_dir(name, hctx->debugfs_dir);\n\n\tdebugfs_create_files(ctx_dir, ctx, blk_mq_debugfs_ctx_attrs);\n}\n\nvoid blk_mq_debugfs_register_hctx(struct request_queue *q,\n\t\t\t\t  struct blk_mq_hw_ctx *hctx)\n{\n\tstruct blk_mq_ctx *ctx;\n\tchar name[20];\n\tint i;\n\n\tif (!q->debugfs_dir)\n\t\treturn;\n\n\tsnprintf(name, sizeof(name), \"hctx%u\", hctx->queue_num);\n\thctx->debugfs_dir = debugfs_create_dir(name, q->debugfs_dir);\n\n\tdebugfs_create_files(hctx->debugfs_dir, hctx, blk_mq_debugfs_hctx_attrs);\n\n\thctx_for_each_ctx(hctx, ctx, i)\n\t\tblk_mq_debugfs_register_ctx(hctx, ctx);\n}\n\nvoid blk_mq_debugfs_unregister_hctx(struct blk_mq_hw_ctx *hctx)\n{\n\tif (!hctx->queue->debugfs_dir)\n\t\treturn;\n\tdebugfs_remove_recursive(hctx->debugfs_dir);\n\thctx->sched_debugfs_dir = NULL;\n\thctx->debugfs_dir = NULL;\n}\n\nvoid blk_mq_debugfs_register_hctxs(struct request_queue *q)\n{\n\tstruct blk_mq_hw_ctx *hctx;\n\tunsigned long i;\n\n\tqueue_for_each_hw_ctx(q, hctx, i)\n\t\tblk_mq_debugfs_register_hctx(q, hctx);\n}\n\nvoid blk_mq_debugfs_unregister_hctxs(struct request_queue *q)\n{\n\tstruct blk_mq_hw_ctx *hctx;\n\tunsigned long i;\n\n\tqueue_for_each_hw_ctx(q, hctx, i)\n\t\tblk_mq_debugfs_unregister_hctx(hctx);\n}\n\nvoid blk_mq_debugfs_register_sched(struct request_queue *q)\n{\n\tstruct elevator_type *e = q->elevator->type;\n\n\tlockdep_assert_held(&q->debugfs_mutex);\n\n\t \n\tif (!q->debugfs_dir)\n\t\treturn;\n\n\tif (!e->queue_debugfs_attrs)\n\t\treturn;\n\n\tq->sched_debugfs_dir = debugfs_create_dir(\"sched\", q->debugfs_dir);\n\n\tdebugfs_create_files(q->sched_debugfs_dir, q, e->queue_debugfs_attrs);\n}\n\nvoid blk_mq_debugfs_unregister_sched(struct request_queue *q)\n{\n\tlockdep_assert_held(&q->debugfs_mutex);\n\n\tdebugfs_remove_recursive(q->sched_debugfs_dir);\n\tq->sched_debugfs_dir = NULL;\n}\n\nstatic const char *rq_qos_id_to_name(enum rq_qos_id id)\n{\n\tswitch (id) {\n\tcase RQ_QOS_WBT:\n\t\treturn \"wbt\";\n\tcase RQ_QOS_LATENCY:\n\t\treturn \"latency\";\n\tcase RQ_QOS_COST:\n\t\treturn \"cost\";\n\t}\n\treturn \"unknown\";\n}\n\nvoid blk_mq_debugfs_unregister_rqos(struct rq_qos *rqos)\n{\n\tlockdep_assert_held(&rqos->disk->queue->debugfs_mutex);\n\n\tif (!rqos->disk->queue->debugfs_dir)\n\t\treturn;\n\tdebugfs_remove_recursive(rqos->debugfs_dir);\n\trqos->debugfs_dir = NULL;\n}\n\nvoid blk_mq_debugfs_register_rqos(struct rq_qos *rqos)\n{\n\tstruct request_queue *q = rqos->disk->queue;\n\tconst char *dir_name = rq_qos_id_to_name(rqos->id);\n\n\tlockdep_assert_held(&q->debugfs_mutex);\n\n\tif (rqos->debugfs_dir || !rqos->ops->debugfs_attrs)\n\t\treturn;\n\n\tif (!q->rqos_debugfs_dir)\n\t\tq->rqos_debugfs_dir = debugfs_create_dir(\"rqos\",\n\t\t\t\t\t\t\t q->debugfs_dir);\n\n\trqos->debugfs_dir = debugfs_create_dir(dir_name, q->rqos_debugfs_dir);\n\tdebugfs_create_files(rqos->debugfs_dir, rqos, rqos->ops->debugfs_attrs);\n}\n\nvoid blk_mq_debugfs_register_sched_hctx(struct request_queue *q,\n\t\t\t\t\tstruct blk_mq_hw_ctx *hctx)\n{\n\tstruct elevator_type *e = q->elevator->type;\n\n\tlockdep_assert_held(&q->debugfs_mutex);\n\n\t \n\tif (!hctx->debugfs_dir)\n\t\treturn;\n\n\tif (!e->hctx_debugfs_attrs)\n\t\treturn;\n\n\thctx->sched_debugfs_dir = debugfs_create_dir(\"sched\",\n\t\t\t\t\t\t     hctx->debugfs_dir);\n\tdebugfs_create_files(hctx->sched_debugfs_dir, hctx,\n\t\t\t     e->hctx_debugfs_attrs);\n}\n\nvoid blk_mq_debugfs_unregister_sched_hctx(struct blk_mq_hw_ctx *hctx)\n{\n\tlockdep_assert_held(&hctx->queue->debugfs_mutex);\n\n\tif (!hctx->queue->debugfs_dir)\n\t\treturn;\n\tdebugfs_remove_recursive(hctx->sched_debugfs_dir);\n\thctx->sched_debugfs_dir = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}