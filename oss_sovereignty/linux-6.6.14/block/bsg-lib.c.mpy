{
  "module_name": "bsg-lib.c",
  "hash_id": "94a66bbb17b07e29c9c136d2ff9719cd7b7ce03dd90204ed9dc31a7c2ca7f79d",
  "original_prompt": "Ingested from linux-6.6.14/block/bsg-lib.c",
  "human_readable_source": "\n \n#include <linux/bsg.h>\n#include <linux/slab.h>\n#include <linux/blk-mq.h>\n#include <linux/delay.h>\n#include <linux/scatterlist.h>\n#include <linux/bsg-lib.h>\n#include <linux/export.h>\n#include <scsi/scsi_cmnd.h>\n#include <scsi/sg.h>\n\n#define uptr64(val) ((void __user *)(uintptr_t)(val))\n\nstruct bsg_set {\n\tstruct blk_mq_tag_set\ttag_set;\n\tstruct bsg_device\t*bd;\n\tbsg_job_fn\t\t*job_fn;\n\tbsg_timeout_fn\t\t*timeout_fn;\n};\n\nstatic int bsg_transport_sg_io_fn(struct request_queue *q, struct sg_io_v4 *hdr,\n\t\tbool open_for_write, unsigned int timeout)\n{\n\tstruct bsg_job *job;\n\tstruct request *rq;\n\tstruct bio *bio;\n\tvoid *reply;\n\tint ret;\n\n\tif (hdr->protocol != BSG_PROTOCOL_SCSI  ||\n\t    hdr->subprotocol != BSG_SUB_PROTOCOL_SCSI_TRANSPORT)\n\t\treturn -EINVAL;\n\tif (!capable(CAP_SYS_RAWIO))\n\t\treturn -EPERM;\n\n\trq = blk_mq_alloc_request(q, hdr->dout_xfer_len ?\n\t\t\t     REQ_OP_DRV_OUT : REQ_OP_DRV_IN, 0);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\trq->timeout = timeout;\n\n\tjob = blk_mq_rq_to_pdu(rq);\n\treply = job->reply;\n\tmemset(job, 0, sizeof(*job));\n\tjob->reply = reply;\n\tjob->reply_len = SCSI_SENSE_BUFFERSIZE;\n\tjob->dd_data = job + 1;\n\n\tjob->request_len = hdr->request_len;\n\tjob->request = memdup_user(uptr64(hdr->request), hdr->request_len);\n\tif (IS_ERR(job->request)) {\n\t\tret = PTR_ERR(job->request);\n\t\tgoto out_free_rq;\n\t}\n\n\tif (hdr->dout_xfer_len && hdr->din_xfer_len) {\n\t\tjob->bidi_rq = blk_mq_alloc_request(rq->q, REQ_OP_DRV_IN, 0);\n\t\tif (IS_ERR(job->bidi_rq)) {\n\t\t\tret = PTR_ERR(job->bidi_rq);\n\t\t\tgoto out_free_job_request;\n\t\t}\n\n\t\tret = blk_rq_map_user(rq->q, job->bidi_rq, NULL,\n\t\t\t\tuptr64(hdr->din_xferp), hdr->din_xfer_len,\n\t\t\t\tGFP_KERNEL);\n\t\tif (ret)\n\t\t\tgoto out_free_bidi_rq;\n\n\t\tjob->bidi_bio = job->bidi_rq->bio;\n\t} else {\n\t\tjob->bidi_rq = NULL;\n\t\tjob->bidi_bio = NULL;\n\t}\n\n\tret = 0;\n\tif (hdr->dout_xfer_len) {\n\t\tret = blk_rq_map_user(rq->q, rq, NULL, uptr64(hdr->dout_xferp),\n\t\t\t\thdr->dout_xfer_len, GFP_KERNEL);\n\t} else if (hdr->din_xfer_len) {\n\t\tret = blk_rq_map_user(rq->q, rq, NULL, uptr64(hdr->din_xferp),\n\t\t\t\thdr->din_xfer_len, GFP_KERNEL);\n\t}\n\n\tif (ret)\n\t\tgoto out_unmap_bidi_rq;\n\n\tbio = rq->bio;\n\tblk_execute_rq(rq, !(hdr->flags & BSG_FLAG_Q_AT_TAIL));\n\n\t \n\thdr->device_status = job->result & 0xff;\n\thdr->transport_status = host_byte(job->result);\n\thdr->driver_status = 0;\n\thdr->info = 0;\n\tif (hdr->device_status || hdr->transport_status || hdr->driver_status)\n\t\thdr->info |= SG_INFO_CHECK;\n\thdr->response_len = 0;\n\n\tif (job->result < 0) {\n\t\t \n\t\tjob->reply_len = sizeof(u32);\n\t\tret = job->result;\n\t}\n\n\tif (job->reply_len && hdr->response) {\n\t\tint len = min(hdr->max_response_len, job->reply_len);\n\n\t\tif (copy_to_user(uptr64(hdr->response), job->reply, len))\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\thdr->response_len = len;\n\t}\n\n\t \n\thdr->dout_resid = 0;\n\n\tif (job->bidi_rq) {\n\t\tunsigned int rsp_len = job->reply_payload.payload_len;\n\n\t\tif (WARN_ON(job->reply_payload_rcv_len > rsp_len))\n\t\t\thdr->din_resid = 0;\n\t\telse\n\t\t\thdr->din_resid = rsp_len - job->reply_payload_rcv_len;\n\t} else {\n\t\thdr->din_resid = 0;\n\t}\n\n\tblk_rq_unmap_user(bio);\nout_unmap_bidi_rq:\n\tif (job->bidi_rq)\n\t\tblk_rq_unmap_user(job->bidi_bio);\nout_free_bidi_rq:\n\tif (job->bidi_rq)\n\t\tblk_mq_free_request(job->bidi_rq);\nout_free_job_request:\n\tkfree(job->request);\nout_free_rq:\n\tblk_mq_free_request(rq);\n\treturn ret;\n}\n\n \nstatic void bsg_teardown_job(struct kref *kref)\n{\n\tstruct bsg_job *job = container_of(kref, struct bsg_job, kref);\n\tstruct request *rq = blk_mq_rq_from_pdu(job);\n\n\tput_device(job->dev);\t \n\n\tkfree(job->request_payload.sg_list);\n\tkfree(job->reply_payload.sg_list);\n\n\tblk_mq_end_request(rq, BLK_STS_OK);\n}\n\nvoid bsg_job_put(struct bsg_job *job)\n{\n\tkref_put(&job->kref, bsg_teardown_job);\n}\nEXPORT_SYMBOL_GPL(bsg_job_put);\n\nint bsg_job_get(struct bsg_job *job)\n{\n\treturn kref_get_unless_zero(&job->kref);\n}\nEXPORT_SYMBOL_GPL(bsg_job_get);\n\n \nvoid bsg_job_done(struct bsg_job *job, int result,\n\t\t  unsigned int reply_payload_rcv_len)\n{\n\tstruct request *rq = blk_mq_rq_from_pdu(job);\n\n\tjob->result = result;\n\tjob->reply_payload_rcv_len = reply_payload_rcv_len;\n\tif (likely(!blk_should_fake_timeout(rq->q)))\n\t\tblk_mq_complete_request(rq);\n}\nEXPORT_SYMBOL_GPL(bsg_job_done);\n\n \nstatic void bsg_complete(struct request *rq)\n{\n\tstruct bsg_job *job = blk_mq_rq_to_pdu(rq);\n\n\tbsg_job_put(job);\n}\n\nstatic int bsg_map_buffer(struct bsg_buffer *buf, struct request *req)\n{\n\tsize_t sz = (sizeof(struct scatterlist) * req->nr_phys_segments);\n\n\tBUG_ON(!req->nr_phys_segments);\n\n\tbuf->sg_list = kmalloc(sz, GFP_KERNEL);\n\tif (!buf->sg_list)\n\t\treturn -ENOMEM;\n\tsg_init_table(buf->sg_list, req->nr_phys_segments);\n\tbuf->sg_cnt = blk_rq_map_sg(req->q, req, buf->sg_list);\n\tbuf->payload_len = blk_rq_bytes(req);\n\treturn 0;\n}\n\n \nstatic bool bsg_prepare_job(struct device *dev, struct request *req)\n{\n\tstruct bsg_job *job = blk_mq_rq_to_pdu(req);\n\tint ret;\n\n\tjob->timeout = req->timeout;\n\n\tif (req->bio) {\n\t\tret = bsg_map_buffer(&job->request_payload, req);\n\t\tif (ret)\n\t\t\tgoto failjob_rls_job;\n\t}\n\tif (job->bidi_rq) {\n\t\tret = bsg_map_buffer(&job->reply_payload, job->bidi_rq);\n\t\tif (ret)\n\t\t\tgoto failjob_rls_rqst_payload;\n\t}\n\tjob->dev = dev;\n\t \n\tget_device(job->dev);\n\tkref_init(&job->kref);\n\treturn true;\n\nfailjob_rls_rqst_payload:\n\tkfree(job->request_payload.sg_list);\nfailjob_rls_job:\n\tjob->result = -ENOMEM;\n\treturn false;\n}\n\n \nstatic blk_status_t bsg_queue_rq(struct blk_mq_hw_ctx *hctx,\n\t\t\t\t const struct blk_mq_queue_data *bd)\n{\n\tstruct request_queue *q = hctx->queue;\n\tstruct device *dev = q->queuedata;\n\tstruct request *req = bd->rq;\n\tstruct bsg_set *bset =\n\t\tcontainer_of(q->tag_set, struct bsg_set, tag_set);\n\tblk_status_t sts = BLK_STS_IOERR;\n\tint ret;\n\n\tblk_mq_start_request(req);\n\n\tif (!get_device(dev))\n\t\treturn BLK_STS_IOERR;\n\n\tif (!bsg_prepare_job(dev, req))\n\t\tgoto out;\n\n\tret = bset->job_fn(blk_mq_rq_to_pdu(req));\n\tif (!ret)\n\t\tsts = BLK_STS_OK;\n\nout:\n\tput_device(dev);\n\treturn sts;\n}\n\n \nstatic int bsg_init_rq(struct blk_mq_tag_set *set, struct request *req,\n\t\t       unsigned int hctx_idx, unsigned int numa_node)\n{\n\tstruct bsg_job *job = blk_mq_rq_to_pdu(req);\n\n\tjob->reply = kzalloc(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL);\n\tif (!job->reply)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void bsg_exit_rq(struct blk_mq_tag_set *set, struct request *req,\n\t\t       unsigned int hctx_idx)\n{\n\tstruct bsg_job *job = blk_mq_rq_to_pdu(req);\n\n\tkfree(job->reply);\n}\n\nvoid bsg_remove_queue(struct request_queue *q)\n{\n\tif (q) {\n\t\tstruct bsg_set *bset =\n\t\t\tcontainer_of(q->tag_set, struct bsg_set, tag_set);\n\n\t\tbsg_unregister_queue(bset->bd);\n\t\tblk_mq_destroy_queue(q);\n\t\tblk_put_queue(q);\n\t\tblk_mq_free_tag_set(&bset->tag_set);\n\t\tkfree(bset);\n\t}\n}\nEXPORT_SYMBOL_GPL(bsg_remove_queue);\n\nstatic enum blk_eh_timer_return bsg_timeout(struct request *rq)\n{\n\tstruct bsg_set *bset =\n\t\tcontainer_of(rq->q->tag_set, struct bsg_set, tag_set);\n\n\tif (!bset->timeout_fn)\n\t\treturn BLK_EH_DONE;\n\treturn bset->timeout_fn(rq);\n}\n\nstatic const struct blk_mq_ops bsg_mq_ops = {\n\t.queue_rq\t\t= bsg_queue_rq,\n\t.init_request\t\t= bsg_init_rq,\n\t.exit_request\t\t= bsg_exit_rq,\n\t.complete\t\t= bsg_complete,\n\t.timeout\t\t= bsg_timeout,\n};\n\n \nstruct request_queue *bsg_setup_queue(struct device *dev, const char *name,\n\t\tbsg_job_fn *job_fn, bsg_timeout_fn *timeout, int dd_job_size)\n{\n\tstruct bsg_set *bset;\n\tstruct blk_mq_tag_set *set;\n\tstruct request_queue *q;\n\tint ret = -ENOMEM;\n\n\tbset = kzalloc(sizeof(*bset), GFP_KERNEL);\n\tif (!bset)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbset->job_fn = job_fn;\n\tbset->timeout_fn = timeout;\n\n\tset = &bset->tag_set;\n\tset->ops = &bsg_mq_ops;\n\tset->nr_hw_queues = 1;\n\tset->queue_depth = 128;\n\tset->numa_node = NUMA_NO_NODE;\n\tset->cmd_size = sizeof(struct bsg_job) + dd_job_size;\n\tset->flags = BLK_MQ_F_NO_SCHED | BLK_MQ_F_BLOCKING;\n\tif (blk_mq_alloc_tag_set(set))\n\t\tgoto out_tag_set;\n\n\tq = blk_mq_init_queue(set);\n\tif (IS_ERR(q)) {\n\t\tret = PTR_ERR(q);\n\t\tgoto out_queue;\n\t}\n\n\tq->queuedata = dev;\n\tblk_queue_rq_timeout(q, BLK_DEFAULT_SG_TIMEOUT);\n\n\tbset->bd = bsg_register_queue(q, dev, name, bsg_transport_sg_io_fn);\n\tif (IS_ERR(bset->bd)) {\n\t\tret = PTR_ERR(bset->bd);\n\t\tgoto out_cleanup_queue;\n\t}\n\n\treturn q;\nout_cleanup_queue:\n\tblk_mq_destroy_queue(q);\n\tblk_put_queue(q);\nout_queue:\n\tblk_mq_free_tag_set(set);\nout_tag_set:\n\tkfree(bset);\n\treturn ERR_PTR(ret);\n}\nEXPORT_SYMBOL_GPL(bsg_setup_queue);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}