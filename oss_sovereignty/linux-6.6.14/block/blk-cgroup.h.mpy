{
  "module_name": "blk-cgroup.h",
  "hash_id": "9fb7e1622d3cba772235997cc83024983f97927ec3cd494a87dbce5fb2e57c0b",
  "original_prompt": "Ingested from linux-6.6.14/block/blk-cgroup.h",
  "human_readable_source": " \n#ifndef _BLK_CGROUP_PRIVATE_H\n#define _BLK_CGROUP_PRIVATE_H\n \n\n#include <linux/blk-cgroup.h>\n#include <linux/cgroup.h>\n#include <linux/kthread.h>\n#include <linux/blk-mq.h>\n#include <linux/llist.h>\n\nstruct blkcg_gq;\nstruct blkg_policy_data;\n\n\n \n#define BLKG_STAT_CPU_BATCH\t(INT_MAX / 2)\n\n#ifdef CONFIG_BLK_CGROUP\n\nenum blkg_iostat_type {\n\tBLKG_IOSTAT_READ,\n\tBLKG_IOSTAT_WRITE,\n\tBLKG_IOSTAT_DISCARD,\n\n\tBLKG_IOSTAT_NR,\n};\n\nstruct blkg_iostat {\n\tu64\t\t\t\tbytes[BLKG_IOSTAT_NR];\n\tu64\t\t\t\tios[BLKG_IOSTAT_NR];\n};\n\nstruct blkg_iostat_set {\n\tstruct u64_stats_sync\t\tsync;\n\tstruct blkcg_gq\t\t       *blkg;\n\tstruct llist_node\t\tlnode;\n\tint\t\t\t\tlqueued;\t \n\tstruct blkg_iostat\t\tcur;\n\tstruct blkg_iostat\t\tlast;\n};\n\n \nstruct blkcg_gq {\n\t \n\tstruct request_queue\t\t*q;\n\tstruct list_head\t\tq_node;\n\tstruct hlist_node\t\tblkcg_node;\n\tstruct blkcg\t\t\t*blkcg;\n\n\t \n\tstruct blkcg_gq\t\t\t*parent;\n\n\t \n\tstruct percpu_ref\t\trefcnt;\n\n\t \n\tbool\t\t\t\tonline;\n\n\tstruct blkg_iostat_set __percpu\t*iostat_cpu;\n\tstruct blkg_iostat_set\t\tiostat;\n\n\tstruct blkg_policy_data\t\t*pd[BLKCG_MAX_POLS];\n#ifdef CONFIG_BLK_CGROUP_PUNT_BIO\n\tspinlock_t\t\t\tasync_bio_lock;\n\tstruct bio_list\t\t\tasync_bios;\n#endif\n\tunion {\n\t\tstruct work_struct\tasync_bio_work;\n\t\tstruct work_struct\tfree_work;\n\t};\n\n\tatomic_t\t\t\tuse_delay;\n\tatomic64_t\t\t\tdelay_nsec;\n\tatomic64_t\t\t\tdelay_start;\n\tu64\t\t\t\tlast_delay;\n\tint\t\t\t\tlast_use;\n\n\tstruct rcu_head\t\t\trcu_head;\n};\n\nstruct blkcg {\n\tstruct cgroup_subsys_state\tcss;\n\tspinlock_t\t\t\tlock;\n\trefcount_t\t\t\tonline_pin;\n\n\tstruct radix_tree_root\t\tblkg_tree;\n\tstruct blkcg_gq\t__rcu\t\t*blkg_hint;\n\tstruct hlist_head\t\tblkg_list;\n\n\tstruct blkcg_policy_data\t*cpd[BLKCG_MAX_POLS];\n\n\tstruct list_head\t\tall_blkcgs_node;\n\n\t \n\tstruct llist_head __percpu\t*lhead;\n\n#ifdef CONFIG_BLK_CGROUP_FC_APPID\n\tchar                            fc_app_id[FC_APPID_LEN];\n#endif\n#ifdef CONFIG_CGROUP_WRITEBACK\n\tstruct list_head\t\tcgwb_list;\n#endif\n};\n\nstatic inline struct blkcg *css_to_blkcg(struct cgroup_subsys_state *css)\n{\n\treturn css ? container_of(css, struct blkcg, css) : NULL;\n}\n\n \nstruct blkg_policy_data {\n\t \n\tstruct blkcg_gq\t\t\t*blkg;\n\tint\t\t\t\tplid;\n\tbool\t\t\t\tonline;\n};\n\n \nstruct blkcg_policy_data {\n\t \n\tstruct blkcg\t\t\t*blkcg;\n\tint\t\t\t\tplid;\n};\n\ntypedef struct blkcg_policy_data *(blkcg_pol_alloc_cpd_fn)(gfp_t gfp);\ntypedef void (blkcg_pol_init_cpd_fn)(struct blkcg_policy_data *cpd);\ntypedef void (blkcg_pol_free_cpd_fn)(struct blkcg_policy_data *cpd);\ntypedef void (blkcg_pol_bind_cpd_fn)(struct blkcg_policy_data *cpd);\ntypedef struct blkg_policy_data *(blkcg_pol_alloc_pd_fn)(struct gendisk *disk,\n\t\tstruct blkcg *blkcg, gfp_t gfp);\ntypedef void (blkcg_pol_init_pd_fn)(struct blkg_policy_data *pd);\ntypedef void (blkcg_pol_online_pd_fn)(struct blkg_policy_data *pd);\ntypedef void (blkcg_pol_offline_pd_fn)(struct blkg_policy_data *pd);\ntypedef void (blkcg_pol_free_pd_fn)(struct blkg_policy_data *pd);\ntypedef void (blkcg_pol_reset_pd_stats_fn)(struct blkg_policy_data *pd);\ntypedef void (blkcg_pol_stat_pd_fn)(struct blkg_policy_data *pd,\n\t\t\t\tstruct seq_file *s);\n\nstruct blkcg_policy {\n\tint\t\t\t\tplid;\n\t \n\tstruct cftype\t\t\t*dfl_cftypes;\n\tstruct cftype\t\t\t*legacy_cftypes;\n\n\t \n\tblkcg_pol_alloc_cpd_fn\t\t*cpd_alloc_fn;\n\tblkcg_pol_free_cpd_fn\t\t*cpd_free_fn;\n\n\tblkcg_pol_alloc_pd_fn\t\t*pd_alloc_fn;\n\tblkcg_pol_init_pd_fn\t\t*pd_init_fn;\n\tblkcg_pol_online_pd_fn\t\t*pd_online_fn;\n\tblkcg_pol_offline_pd_fn\t\t*pd_offline_fn;\n\tblkcg_pol_free_pd_fn\t\t*pd_free_fn;\n\tblkcg_pol_reset_pd_stats_fn\t*pd_reset_stats_fn;\n\tblkcg_pol_stat_pd_fn\t\t*pd_stat_fn;\n};\n\nextern struct blkcg blkcg_root;\nextern bool blkcg_debug_stats;\n\nint blkcg_init_disk(struct gendisk *disk);\nvoid blkcg_exit_disk(struct gendisk *disk);\n\n \nint blkcg_policy_register(struct blkcg_policy *pol);\nvoid blkcg_policy_unregister(struct blkcg_policy *pol);\nint blkcg_activate_policy(struct gendisk *disk, const struct blkcg_policy *pol);\nvoid blkcg_deactivate_policy(struct gendisk *disk,\n\t\t\t     const struct blkcg_policy *pol);\n\nconst char *blkg_dev_name(struct blkcg_gq *blkg);\nvoid blkcg_print_blkgs(struct seq_file *sf, struct blkcg *blkcg,\n\t\t       u64 (*prfill)(struct seq_file *,\n\t\t\t\t     struct blkg_policy_data *, int),\n\t\t       const struct blkcg_policy *pol, int data,\n\t\t       bool show_total);\nu64 __blkg_prfill_u64(struct seq_file *sf, struct blkg_policy_data *pd, u64 v);\n\nstruct blkg_conf_ctx {\n\tchar\t\t\t\t*input;\n\tchar\t\t\t\t*body;\n\tstruct block_device\t\t*bdev;\n\tstruct blkcg_gq\t\t\t*blkg;\n};\n\nvoid blkg_conf_init(struct blkg_conf_ctx *ctx, char *input);\nint blkg_conf_open_bdev(struct blkg_conf_ctx *ctx);\nint blkg_conf_prep(struct blkcg *blkcg, const struct blkcg_policy *pol,\n\t\t   struct blkg_conf_ctx *ctx);\nvoid blkg_conf_exit(struct blkg_conf_ctx *ctx);\n\n \nstatic inline bool bio_issue_as_root_blkg(struct bio *bio)\n{\n\treturn (bio->bi_opf & (REQ_META | REQ_SWAP)) != 0;\n}\n\n \nstatic inline struct blkcg_gq *blkg_lookup(struct blkcg *blkcg,\n\t\t\t\t\t   struct request_queue *q)\n{\n\tstruct blkcg_gq *blkg;\n\n\tif (blkcg == &blkcg_root)\n\t\treturn q->root_blkg;\n\n\tblkg = rcu_dereference_check(blkcg->blkg_hint,\n\t\t\tlockdep_is_held(&q->queue_lock));\n\tif (blkg && blkg->q == q)\n\t\treturn blkg;\n\n\tblkg = radix_tree_lookup(&blkcg->blkg_tree, q->id);\n\tif (blkg && blkg->q != q)\n\t\tblkg = NULL;\n\treturn blkg;\n}\n\n \nstatic inline struct blkg_policy_data *blkg_to_pd(struct blkcg_gq *blkg,\n\t\t\t\t\t\t  struct blkcg_policy *pol)\n{\n\treturn blkg ? blkg->pd[pol->plid] : NULL;\n}\n\nstatic inline struct blkcg_policy_data *blkcg_to_cpd(struct blkcg *blkcg,\n\t\t\t\t\t\t     struct blkcg_policy *pol)\n{\n\treturn blkcg ? blkcg->cpd[pol->plid] : NULL;\n}\n\n \nstatic inline struct blkcg_gq *pd_to_blkg(struct blkg_policy_data *pd)\n{\n\treturn pd ? pd->blkg : NULL;\n}\n\nstatic inline struct blkcg *cpd_to_blkcg(struct blkcg_policy_data *cpd)\n{\n\treturn cpd ? cpd->blkcg : NULL;\n}\n\n \nstatic inline int blkg_path(struct blkcg_gq *blkg, char *buf, int buflen)\n{\n\treturn cgroup_path(blkg->blkcg->css.cgroup, buf, buflen);\n}\n\n \nstatic inline void blkg_get(struct blkcg_gq *blkg)\n{\n\tpercpu_ref_get(&blkg->refcnt);\n}\n\n \nstatic inline bool blkg_tryget(struct blkcg_gq *blkg)\n{\n\treturn blkg && percpu_ref_tryget(&blkg->refcnt);\n}\n\n \nstatic inline void blkg_put(struct blkcg_gq *blkg)\n{\n\tpercpu_ref_put(&blkg->refcnt);\n}\n\n \n#define blkg_for_each_descendant_pre(d_blkg, pos_css, p_blkg)\t\t\\\n\tcss_for_each_descendant_pre((pos_css), &(p_blkg)->blkcg->css)\t\\\n\t\tif (((d_blkg) = blkg_lookup(css_to_blkcg(pos_css),\t\\\n\t\t\t\t\t    (p_blkg)->q)))\n\n \n#define blkg_for_each_descendant_post(d_blkg, pos_css, p_blkg)\t\t\\\n\tcss_for_each_descendant_post((pos_css), &(p_blkg)->blkcg->css)\t\\\n\t\tif (((d_blkg) = blkg_lookup(css_to_blkcg(pos_css),\t\\\n\t\t\t\t\t    (p_blkg)->q)))\n\nstatic inline void blkcg_bio_issue_init(struct bio *bio)\n{\n\tbio_issue_init(&bio->bi_issue, bio_sectors(bio));\n}\n\nstatic inline void blkcg_use_delay(struct blkcg_gq *blkg)\n{\n\tif (WARN_ON_ONCE(atomic_read(&blkg->use_delay) < 0))\n\t\treturn;\n\tif (atomic_add_return(1, &blkg->use_delay) == 1)\n\t\tatomic_inc(&blkg->blkcg->css.cgroup->congestion_count);\n}\n\nstatic inline int blkcg_unuse_delay(struct blkcg_gq *blkg)\n{\n\tint old = atomic_read(&blkg->use_delay);\n\n\tif (WARN_ON_ONCE(old < 0))\n\t\treturn 0;\n\tif (old == 0)\n\t\treturn 0;\n\n\t \n\twhile (old && !atomic_try_cmpxchg(&blkg->use_delay, &old, old - 1))\n\t\t;\n\n\tif (old == 0)\n\t\treturn 0;\n\tif (old == 1)\n\t\tatomic_dec(&blkg->blkcg->css.cgroup->congestion_count);\n\treturn 1;\n}\n\n \nstatic inline void blkcg_set_delay(struct blkcg_gq *blkg, u64 delay)\n{\n\tint old = atomic_read(&blkg->use_delay);\n\n\t \n\tif (!old && atomic_try_cmpxchg(&blkg->use_delay, &old, -1))\n\t\tatomic_inc(&blkg->blkcg->css.cgroup->congestion_count);\n\n\tatomic64_set(&blkg->delay_nsec, delay);\n}\n\n \nstatic inline void blkcg_clear_delay(struct blkcg_gq *blkg)\n{\n\tint old = atomic_read(&blkg->use_delay);\n\n\t \n\tif (old && atomic_try_cmpxchg(&blkg->use_delay, &old, 0))\n\t\tatomic_dec(&blkg->blkcg->css.cgroup->congestion_count);\n}\n\n \nstatic inline bool blk_cgroup_mergeable(struct request *rq, struct bio *bio)\n{\n\treturn rq->bio->bi_blkg == bio->bi_blkg &&\n\t\tbio_issue_as_root_blkg(rq->bio) == bio_issue_as_root_blkg(bio);\n}\n\nvoid blk_cgroup_bio_start(struct bio *bio);\nvoid blkcg_add_delay(struct blkcg_gq *blkg, u64 now, u64 delta);\n#else\t \n\nstruct blkg_policy_data {\n};\n\nstruct blkcg_policy_data {\n};\n\nstruct blkcg_policy {\n};\n\nstruct blkcg {\n};\n\nstatic inline struct blkcg_gq *blkg_lookup(struct blkcg *blkcg, void *key) { return NULL; }\nstatic inline int blkcg_init_disk(struct gendisk *disk) { return 0; }\nstatic inline void blkcg_exit_disk(struct gendisk *disk) { }\nstatic inline int blkcg_policy_register(struct blkcg_policy *pol) { return 0; }\nstatic inline void blkcg_policy_unregister(struct blkcg_policy *pol) { }\nstatic inline int blkcg_activate_policy(struct gendisk *disk,\n\t\t\t\t\tconst struct blkcg_policy *pol) { return 0; }\nstatic inline void blkcg_deactivate_policy(struct gendisk *disk,\n\t\t\t\t\t   const struct blkcg_policy *pol) { }\n\nstatic inline struct blkg_policy_data *blkg_to_pd(struct blkcg_gq *blkg,\n\t\t\t\t\t\t  struct blkcg_policy *pol) { return NULL; }\nstatic inline struct blkcg_gq *pd_to_blkg(struct blkg_policy_data *pd) { return NULL; }\nstatic inline char *blkg_path(struct blkcg_gq *blkg) { return NULL; }\nstatic inline void blkg_get(struct blkcg_gq *blkg) { }\nstatic inline void blkg_put(struct blkcg_gq *blkg) { }\nstatic inline void blkcg_bio_issue_init(struct bio *bio) { }\nstatic inline void blk_cgroup_bio_start(struct bio *bio) { }\nstatic inline bool blk_cgroup_mergeable(struct request *rq, struct bio *bio) { return true; }\n\n#define blk_queue_for_each_rl(rl, q)\t\\\n\tfor ((rl) = &(q)->root_rl; (rl); (rl) = NULL)\n\n#endif\t \n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}