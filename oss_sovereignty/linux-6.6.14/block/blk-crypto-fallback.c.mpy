{
  "module_name": "blk-crypto-fallback.c",
  "hash_id": "cb5d7cc25294c589880024110c0e3b807fa43db95ffc91d519b15ec9894d8c19",
  "original_prompt": "Ingested from linux-6.6.14/block/blk-crypto-fallback.c",
  "human_readable_source": "\n \n\n \n\n#define pr_fmt(fmt) \"blk-crypto-fallback: \" fmt\n\n#include <crypto/skcipher.h>\n#include <linux/blk-crypto.h>\n#include <linux/blk-crypto-profile.h>\n#include <linux/blkdev.h>\n#include <linux/crypto.h>\n#include <linux/mempool.h>\n#include <linux/module.h>\n#include <linux/random.h>\n#include <linux/scatterlist.h>\n\n#include \"blk-cgroup.h\"\n#include \"blk-crypto-internal.h\"\n\nstatic unsigned int num_prealloc_bounce_pg = 32;\nmodule_param(num_prealloc_bounce_pg, uint, 0);\nMODULE_PARM_DESC(num_prealloc_bounce_pg,\n\t\t \"Number of preallocated bounce pages for the blk-crypto crypto API fallback\");\n\nstatic unsigned int blk_crypto_num_keyslots = 100;\nmodule_param_named(num_keyslots, blk_crypto_num_keyslots, uint, 0);\nMODULE_PARM_DESC(num_keyslots,\n\t\t \"Number of keyslots for the blk-crypto crypto API fallback\");\n\nstatic unsigned int num_prealloc_fallback_crypt_ctxs = 128;\nmodule_param(num_prealloc_fallback_crypt_ctxs, uint, 0);\nMODULE_PARM_DESC(num_prealloc_crypt_fallback_ctxs,\n\t\t \"Number of preallocated bio fallback crypto contexts for blk-crypto to use during crypto API fallback\");\n\nstruct bio_fallback_crypt_ctx {\n\tstruct bio_crypt_ctx crypt_ctx;\n\t \n\tstruct bvec_iter crypt_iter;\n\tunion {\n\t\tstruct {\n\t\t\tstruct work_struct work;\n\t\t\tstruct bio *bio;\n\t\t};\n\t\tstruct {\n\t\t\tvoid *bi_private_orig;\n\t\t\tbio_end_io_t *bi_end_io_orig;\n\t\t};\n\t};\n};\n\nstatic struct kmem_cache *bio_fallback_crypt_ctx_cache;\nstatic mempool_t *bio_fallback_crypt_ctx_pool;\n\n \nstatic DEFINE_MUTEX(tfms_init_lock);\nstatic bool tfms_inited[BLK_ENCRYPTION_MODE_MAX];\n\nstatic struct blk_crypto_fallback_keyslot {\n\tenum blk_crypto_mode_num crypto_mode;\n\tstruct crypto_skcipher *tfms[BLK_ENCRYPTION_MODE_MAX];\n} *blk_crypto_keyslots;\n\nstatic struct blk_crypto_profile *blk_crypto_fallback_profile;\nstatic struct workqueue_struct *blk_crypto_wq;\nstatic mempool_t *blk_crypto_bounce_page_pool;\nstatic struct bio_set crypto_bio_split;\n\n \nstatic u8 blank_key[BLK_CRYPTO_MAX_KEY_SIZE];\n\nstatic void blk_crypto_fallback_evict_keyslot(unsigned int slot)\n{\n\tstruct blk_crypto_fallback_keyslot *slotp = &blk_crypto_keyslots[slot];\n\tenum blk_crypto_mode_num crypto_mode = slotp->crypto_mode;\n\tint err;\n\n\tWARN_ON(slotp->crypto_mode == BLK_ENCRYPTION_MODE_INVALID);\n\n\t \n\terr = crypto_skcipher_setkey(slotp->tfms[crypto_mode], blank_key,\n\t\t\t\t     blk_crypto_modes[crypto_mode].keysize);\n\tWARN_ON(err);\n\tslotp->crypto_mode = BLK_ENCRYPTION_MODE_INVALID;\n}\n\nstatic int\nblk_crypto_fallback_keyslot_program(struct blk_crypto_profile *profile,\n\t\t\t\t    const struct blk_crypto_key *key,\n\t\t\t\t    unsigned int slot)\n{\n\tstruct blk_crypto_fallback_keyslot *slotp = &blk_crypto_keyslots[slot];\n\tconst enum blk_crypto_mode_num crypto_mode =\n\t\t\t\t\t\tkey->crypto_cfg.crypto_mode;\n\tint err;\n\n\tif (crypto_mode != slotp->crypto_mode &&\n\t    slotp->crypto_mode != BLK_ENCRYPTION_MODE_INVALID)\n\t\tblk_crypto_fallback_evict_keyslot(slot);\n\n\tslotp->crypto_mode = crypto_mode;\n\terr = crypto_skcipher_setkey(slotp->tfms[crypto_mode], key->raw,\n\t\t\t\t     key->size);\n\tif (err) {\n\t\tblk_crypto_fallback_evict_keyslot(slot);\n\t\treturn err;\n\t}\n\treturn 0;\n}\n\nstatic int blk_crypto_fallback_keyslot_evict(struct blk_crypto_profile *profile,\n\t\t\t\t\t     const struct blk_crypto_key *key,\n\t\t\t\t\t     unsigned int slot)\n{\n\tblk_crypto_fallback_evict_keyslot(slot);\n\treturn 0;\n}\n\nstatic const struct blk_crypto_ll_ops blk_crypto_fallback_ll_ops = {\n\t.keyslot_program        = blk_crypto_fallback_keyslot_program,\n\t.keyslot_evict          = blk_crypto_fallback_keyslot_evict,\n};\n\nstatic void blk_crypto_fallback_encrypt_endio(struct bio *enc_bio)\n{\n\tstruct bio *src_bio = enc_bio->bi_private;\n\tint i;\n\n\tfor (i = 0; i < enc_bio->bi_vcnt; i++)\n\t\tmempool_free(enc_bio->bi_io_vec[i].bv_page,\n\t\t\t     blk_crypto_bounce_page_pool);\n\n\tsrc_bio->bi_status = enc_bio->bi_status;\n\n\tbio_uninit(enc_bio);\n\tkfree(enc_bio);\n\tbio_endio(src_bio);\n}\n\nstatic struct bio *blk_crypto_fallback_clone_bio(struct bio *bio_src)\n{\n\tunsigned int nr_segs = bio_segments(bio_src);\n\tstruct bvec_iter iter;\n\tstruct bio_vec bv;\n\tstruct bio *bio;\n\n\tbio = bio_kmalloc(nr_segs, GFP_NOIO);\n\tif (!bio)\n\t\treturn NULL;\n\tbio_init(bio, bio_src->bi_bdev, bio->bi_inline_vecs, nr_segs,\n\t\t bio_src->bi_opf);\n\tif (bio_flagged(bio_src, BIO_REMAPPED))\n\t\tbio_set_flag(bio, BIO_REMAPPED);\n\tbio->bi_ioprio\t\t= bio_src->bi_ioprio;\n\tbio->bi_iter.bi_sector\t= bio_src->bi_iter.bi_sector;\n\tbio->bi_iter.bi_size\t= bio_src->bi_iter.bi_size;\n\n\tbio_for_each_segment(bv, bio_src, iter)\n\t\tbio->bi_io_vec[bio->bi_vcnt++] = bv;\n\n\tbio_clone_blkg_association(bio, bio_src);\n\n\treturn bio;\n}\n\nstatic bool\nblk_crypto_fallback_alloc_cipher_req(struct blk_crypto_keyslot *slot,\n\t\t\t\t     struct skcipher_request **ciph_req_ret,\n\t\t\t\t     struct crypto_wait *wait)\n{\n\tstruct skcipher_request *ciph_req;\n\tconst struct blk_crypto_fallback_keyslot *slotp;\n\tint keyslot_idx = blk_crypto_keyslot_index(slot);\n\n\tslotp = &blk_crypto_keyslots[keyslot_idx];\n\tciph_req = skcipher_request_alloc(slotp->tfms[slotp->crypto_mode],\n\t\t\t\t\t  GFP_NOIO);\n\tif (!ciph_req)\n\t\treturn false;\n\n\tskcipher_request_set_callback(ciph_req,\n\t\t\t\t      CRYPTO_TFM_REQ_MAY_BACKLOG |\n\t\t\t\t      CRYPTO_TFM_REQ_MAY_SLEEP,\n\t\t\t\t      crypto_req_done, wait);\n\t*ciph_req_ret = ciph_req;\n\n\treturn true;\n}\n\nstatic bool blk_crypto_fallback_split_bio_if_needed(struct bio **bio_ptr)\n{\n\tstruct bio *bio = *bio_ptr;\n\tunsigned int i = 0;\n\tunsigned int num_sectors = 0;\n\tstruct bio_vec bv;\n\tstruct bvec_iter iter;\n\n\tbio_for_each_segment(bv, bio, iter) {\n\t\tnum_sectors += bv.bv_len >> SECTOR_SHIFT;\n\t\tif (++i == BIO_MAX_VECS)\n\t\t\tbreak;\n\t}\n\tif (num_sectors < bio_sectors(bio)) {\n\t\tstruct bio *split_bio;\n\n\t\tsplit_bio = bio_split(bio, num_sectors, GFP_NOIO,\n\t\t\t\t      &crypto_bio_split);\n\t\tif (!split_bio) {\n\t\t\tbio->bi_status = BLK_STS_RESOURCE;\n\t\t\treturn false;\n\t\t}\n\t\tbio_chain(split_bio, bio);\n\t\tsubmit_bio_noacct(bio);\n\t\t*bio_ptr = split_bio;\n\t}\n\n\treturn true;\n}\n\nunion blk_crypto_iv {\n\t__le64 dun[BLK_CRYPTO_DUN_ARRAY_SIZE];\n\tu8 bytes[BLK_CRYPTO_MAX_IV_SIZE];\n};\n\nstatic void blk_crypto_dun_to_iv(const u64 dun[BLK_CRYPTO_DUN_ARRAY_SIZE],\n\t\t\t\t union blk_crypto_iv *iv)\n{\n\tint i;\n\n\tfor (i = 0; i < BLK_CRYPTO_DUN_ARRAY_SIZE; i++)\n\t\tiv->dun[i] = cpu_to_le64(dun[i]);\n}\n\n \nstatic bool blk_crypto_fallback_encrypt_bio(struct bio **bio_ptr)\n{\n\tstruct bio *src_bio, *enc_bio;\n\tstruct bio_crypt_ctx *bc;\n\tstruct blk_crypto_keyslot *slot;\n\tint data_unit_size;\n\tstruct skcipher_request *ciph_req = NULL;\n\tDECLARE_CRYPTO_WAIT(wait);\n\tu64 curr_dun[BLK_CRYPTO_DUN_ARRAY_SIZE];\n\tstruct scatterlist src, dst;\n\tunion blk_crypto_iv iv;\n\tunsigned int i, j;\n\tbool ret = false;\n\tblk_status_t blk_st;\n\n\t \n\tif (!blk_crypto_fallback_split_bio_if_needed(bio_ptr))\n\t\treturn false;\n\n\tsrc_bio = *bio_ptr;\n\tbc = src_bio->bi_crypt_context;\n\tdata_unit_size = bc->bc_key->crypto_cfg.data_unit_size;\n\n\t \n\tenc_bio = blk_crypto_fallback_clone_bio(src_bio);\n\tif (!enc_bio) {\n\t\tsrc_bio->bi_status = BLK_STS_RESOURCE;\n\t\treturn false;\n\t}\n\n\t \n\tblk_st = blk_crypto_get_keyslot(blk_crypto_fallback_profile,\n\t\t\t\t\tbc->bc_key, &slot);\n\tif (blk_st != BLK_STS_OK) {\n\t\tsrc_bio->bi_status = blk_st;\n\t\tgoto out_put_enc_bio;\n\t}\n\n\t \n\tif (!blk_crypto_fallback_alloc_cipher_req(slot, &ciph_req, &wait)) {\n\t\tsrc_bio->bi_status = BLK_STS_RESOURCE;\n\t\tgoto out_release_keyslot;\n\t}\n\n\tmemcpy(curr_dun, bc->bc_dun, sizeof(curr_dun));\n\tsg_init_table(&src, 1);\n\tsg_init_table(&dst, 1);\n\n\tskcipher_request_set_crypt(ciph_req, &src, &dst, data_unit_size,\n\t\t\t\t   iv.bytes);\n\n\t \n\tfor (i = 0; i < enc_bio->bi_vcnt; i++) {\n\t\tstruct bio_vec *enc_bvec = &enc_bio->bi_io_vec[i];\n\t\tstruct page *plaintext_page = enc_bvec->bv_page;\n\t\tstruct page *ciphertext_page =\n\t\t\tmempool_alloc(blk_crypto_bounce_page_pool, GFP_NOIO);\n\n\t\tenc_bvec->bv_page = ciphertext_page;\n\n\t\tif (!ciphertext_page) {\n\t\t\tsrc_bio->bi_status = BLK_STS_RESOURCE;\n\t\t\tgoto out_free_bounce_pages;\n\t\t}\n\n\t\tsg_set_page(&src, plaintext_page, data_unit_size,\n\t\t\t    enc_bvec->bv_offset);\n\t\tsg_set_page(&dst, ciphertext_page, data_unit_size,\n\t\t\t    enc_bvec->bv_offset);\n\n\t\t \n\t\tfor (j = 0; j < enc_bvec->bv_len; j += data_unit_size) {\n\t\t\tblk_crypto_dun_to_iv(curr_dun, &iv);\n\t\t\tif (crypto_wait_req(crypto_skcipher_encrypt(ciph_req),\n\t\t\t\t\t    &wait)) {\n\t\t\t\ti++;\n\t\t\t\tsrc_bio->bi_status = BLK_STS_IOERR;\n\t\t\t\tgoto out_free_bounce_pages;\n\t\t\t}\n\t\t\tbio_crypt_dun_increment(curr_dun, 1);\n\t\t\tsrc.offset += data_unit_size;\n\t\t\tdst.offset += data_unit_size;\n\t\t}\n\t}\n\n\tenc_bio->bi_private = src_bio;\n\tenc_bio->bi_end_io = blk_crypto_fallback_encrypt_endio;\n\t*bio_ptr = enc_bio;\n\tret = true;\n\n\tenc_bio = NULL;\n\tgoto out_free_ciph_req;\n\nout_free_bounce_pages:\n\twhile (i > 0)\n\t\tmempool_free(enc_bio->bi_io_vec[--i].bv_page,\n\t\t\t     blk_crypto_bounce_page_pool);\nout_free_ciph_req:\n\tskcipher_request_free(ciph_req);\nout_release_keyslot:\n\tblk_crypto_put_keyslot(slot);\nout_put_enc_bio:\n\tif (enc_bio)\n\t\tbio_uninit(enc_bio);\n\tkfree(enc_bio);\n\treturn ret;\n}\n\n \nstatic void blk_crypto_fallback_decrypt_bio(struct work_struct *work)\n{\n\tstruct bio_fallback_crypt_ctx *f_ctx =\n\t\tcontainer_of(work, struct bio_fallback_crypt_ctx, work);\n\tstruct bio *bio = f_ctx->bio;\n\tstruct bio_crypt_ctx *bc = &f_ctx->crypt_ctx;\n\tstruct blk_crypto_keyslot *slot;\n\tstruct skcipher_request *ciph_req = NULL;\n\tDECLARE_CRYPTO_WAIT(wait);\n\tu64 curr_dun[BLK_CRYPTO_DUN_ARRAY_SIZE];\n\tunion blk_crypto_iv iv;\n\tstruct scatterlist sg;\n\tstruct bio_vec bv;\n\tstruct bvec_iter iter;\n\tconst int data_unit_size = bc->bc_key->crypto_cfg.data_unit_size;\n\tunsigned int i;\n\tblk_status_t blk_st;\n\n\t \n\tblk_st = blk_crypto_get_keyslot(blk_crypto_fallback_profile,\n\t\t\t\t\tbc->bc_key, &slot);\n\tif (blk_st != BLK_STS_OK) {\n\t\tbio->bi_status = blk_st;\n\t\tgoto out_no_keyslot;\n\t}\n\n\t \n\tif (!blk_crypto_fallback_alloc_cipher_req(slot, &ciph_req, &wait)) {\n\t\tbio->bi_status = BLK_STS_RESOURCE;\n\t\tgoto out;\n\t}\n\n\tmemcpy(curr_dun, bc->bc_dun, sizeof(curr_dun));\n\tsg_init_table(&sg, 1);\n\tskcipher_request_set_crypt(ciph_req, &sg, &sg, data_unit_size,\n\t\t\t\t   iv.bytes);\n\n\t \n\t__bio_for_each_segment(bv, bio, iter, f_ctx->crypt_iter) {\n\t\tstruct page *page = bv.bv_page;\n\n\t\tsg_set_page(&sg, page, data_unit_size, bv.bv_offset);\n\n\t\t \n\t\tfor (i = 0; i < bv.bv_len; i += data_unit_size) {\n\t\t\tblk_crypto_dun_to_iv(curr_dun, &iv);\n\t\t\tif (crypto_wait_req(crypto_skcipher_decrypt(ciph_req),\n\t\t\t\t\t    &wait)) {\n\t\t\t\tbio->bi_status = BLK_STS_IOERR;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tbio_crypt_dun_increment(curr_dun, 1);\n\t\t\tsg.offset += data_unit_size;\n\t\t}\n\t}\n\nout:\n\tskcipher_request_free(ciph_req);\n\tblk_crypto_put_keyslot(slot);\nout_no_keyslot:\n\tmempool_free(f_ctx, bio_fallback_crypt_ctx_pool);\n\tbio_endio(bio);\n}\n\n \nstatic void blk_crypto_fallback_decrypt_endio(struct bio *bio)\n{\n\tstruct bio_fallback_crypt_ctx *f_ctx = bio->bi_private;\n\n\tbio->bi_private = f_ctx->bi_private_orig;\n\tbio->bi_end_io = f_ctx->bi_end_io_orig;\n\n\t \n\tif (bio->bi_status) {\n\t\tmempool_free(f_ctx, bio_fallback_crypt_ctx_pool);\n\t\tbio_endio(bio);\n\t\treturn;\n\t}\n\n\tINIT_WORK(&f_ctx->work, blk_crypto_fallback_decrypt_bio);\n\tf_ctx->bio = bio;\n\tqueue_work(blk_crypto_wq, &f_ctx->work);\n}\n\n \nbool blk_crypto_fallback_bio_prep(struct bio **bio_ptr)\n{\n\tstruct bio *bio = *bio_ptr;\n\tstruct bio_crypt_ctx *bc = bio->bi_crypt_context;\n\tstruct bio_fallback_crypt_ctx *f_ctx;\n\n\tif (WARN_ON_ONCE(!tfms_inited[bc->bc_key->crypto_cfg.crypto_mode])) {\n\t\t \n\t\tbio->bi_status = BLK_STS_IOERR;\n\t\treturn false;\n\t}\n\n\tif (!__blk_crypto_cfg_supported(blk_crypto_fallback_profile,\n\t\t\t\t\t&bc->bc_key->crypto_cfg)) {\n\t\tbio->bi_status = BLK_STS_NOTSUPP;\n\t\treturn false;\n\t}\n\n\tif (bio_data_dir(bio) == WRITE)\n\t\treturn blk_crypto_fallback_encrypt_bio(bio_ptr);\n\n\t \n\tf_ctx = mempool_alloc(bio_fallback_crypt_ctx_pool, GFP_NOIO);\n\tf_ctx->crypt_ctx = *bc;\n\tf_ctx->crypt_iter = bio->bi_iter;\n\tf_ctx->bi_private_orig = bio->bi_private;\n\tf_ctx->bi_end_io_orig = bio->bi_end_io;\n\tbio->bi_private = (void *)f_ctx;\n\tbio->bi_end_io = blk_crypto_fallback_decrypt_endio;\n\tbio_crypt_free_ctx(bio);\n\n\treturn true;\n}\n\nint blk_crypto_fallback_evict_key(const struct blk_crypto_key *key)\n{\n\treturn __blk_crypto_evict_key(blk_crypto_fallback_profile, key);\n}\n\nstatic bool blk_crypto_fallback_inited;\nstatic int blk_crypto_fallback_init(void)\n{\n\tint i;\n\tint err;\n\n\tif (blk_crypto_fallback_inited)\n\t\treturn 0;\n\n\tget_random_bytes(blank_key, BLK_CRYPTO_MAX_KEY_SIZE);\n\n\terr = bioset_init(&crypto_bio_split, 64, 0, 0);\n\tif (err)\n\t\tgoto out;\n\n\t \n\tblk_crypto_fallback_profile =\n\t\tkzalloc(sizeof(*blk_crypto_fallback_profile), GFP_KERNEL);\n\tif (!blk_crypto_fallback_profile) {\n\t\terr = -ENOMEM;\n\t\tgoto fail_free_bioset;\n\t}\n\n\terr = blk_crypto_profile_init(blk_crypto_fallback_profile,\n\t\t\t\t      blk_crypto_num_keyslots);\n\tif (err)\n\t\tgoto fail_free_profile;\n\terr = -ENOMEM;\n\n\tblk_crypto_fallback_profile->ll_ops = blk_crypto_fallback_ll_ops;\n\tblk_crypto_fallback_profile->max_dun_bytes_supported = BLK_CRYPTO_MAX_IV_SIZE;\n\n\t \n\tfor (i = 0; i < BLK_ENCRYPTION_MODE_MAX; i++)\n\t\tblk_crypto_fallback_profile->modes_supported[i] = 0xFFFFFFFF;\n\tblk_crypto_fallback_profile->modes_supported[BLK_ENCRYPTION_MODE_INVALID] = 0;\n\n\tblk_crypto_wq = alloc_workqueue(\"blk_crypto_wq\",\n\t\t\t\t\tWQ_UNBOUND | WQ_HIGHPRI |\n\t\t\t\t\tWQ_MEM_RECLAIM, num_online_cpus());\n\tif (!blk_crypto_wq)\n\t\tgoto fail_destroy_profile;\n\n\tblk_crypto_keyslots = kcalloc(blk_crypto_num_keyslots,\n\t\t\t\t      sizeof(blk_crypto_keyslots[0]),\n\t\t\t\t      GFP_KERNEL);\n\tif (!blk_crypto_keyslots)\n\t\tgoto fail_free_wq;\n\n\tblk_crypto_bounce_page_pool =\n\t\tmempool_create_page_pool(num_prealloc_bounce_pg, 0);\n\tif (!blk_crypto_bounce_page_pool)\n\t\tgoto fail_free_keyslots;\n\n\tbio_fallback_crypt_ctx_cache = KMEM_CACHE(bio_fallback_crypt_ctx, 0);\n\tif (!bio_fallback_crypt_ctx_cache)\n\t\tgoto fail_free_bounce_page_pool;\n\n\tbio_fallback_crypt_ctx_pool =\n\t\tmempool_create_slab_pool(num_prealloc_fallback_crypt_ctxs,\n\t\t\t\t\t bio_fallback_crypt_ctx_cache);\n\tif (!bio_fallback_crypt_ctx_pool)\n\t\tgoto fail_free_crypt_ctx_cache;\n\n\tblk_crypto_fallback_inited = true;\n\n\treturn 0;\nfail_free_crypt_ctx_cache:\n\tkmem_cache_destroy(bio_fallback_crypt_ctx_cache);\nfail_free_bounce_page_pool:\n\tmempool_destroy(blk_crypto_bounce_page_pool);\nfail_free_keyslots:\n\tkfree(blk_crypto_keyslots);\nfail_free_wq:\n\tdestroy_workqueue(blk_crypto_wq);\nfail_destroy_profile:\n\tblk_crypto_profile_destroy(blk_crypto_fallback_profile);\nfail_free_profile:\n\tkfree(blk_crypto_fallback_profile);\nfail_free_bioset:\n\tbioset_exit(&crypto_bio_split);\nout:\n\treturn err;\n}\n\n \nint blk_crypto_fallback_start_using_mode(enum blk_crypto_mode_num mode_num)\n{\n\tconst char *cipher_str = blk_crypto_modes[mode_num].cipher_str;\n\tstruct blk_crypto_fallback_keyslot *slotp;\n\tunsigned int i;\n\tint err = 0;\n\n\t \n\tif (likely(smp_load_acquire(&tfms_inited[mode_num])))\n\t\treturn 0;\n\n\tmutex_lock(&tfms_init_lock);\n\tif (tfms_inited[mode_num])\n\t\tgoto out;\n\n\terr = blk_crypto_fallback_init();\n\tif (err)\n\t\tgoto out;\n\n\tfor (i = 0; i < blk_crypto_num_keyslots; i++) {\n\t\tslotp = &blk_crypto_keyslots[i];\n\t\tslotp->tfms[mode_num] = crypto_alloc_skcipher(cipher_str, 0, 0);\n\t\tif (IS_ERR(slotp->tfms[mode_num])) {\n\t\t\terr = PTR_ERR(slotp->tfms[mode_num]);\n\t\t\tif (err == -ENOENT) {\n\t\t\t\tpr_warn_once(\"Missing crypto API support for \\\"%s\\\"\\n\",\n\t\t\t\t\t     cipher_str);\n\t\t\t\terr = -ENOPKG;\n\t\t\t}\n\t\t\tslotp->tfms[mode_num] = NULL;\n\t\t\tgoto out_free_tfms;\n\t\t}\n\n\t\tcrypto_skcipher_set_flags(slotp->tfms[mode_num],\n\t\t\t\t\t  CRYPTO_TFM_REQ_FORBID_WEAK_KEYS);\n\t}\n\n\t \n\tsmp_store_release(&tfms_inited[mode_num], true);\n\tgoto out;\n\nout_free_tfms:\n\tfor (i = 0; i < blk_crypto_num_keyslots; i++) {\n\t\tslotp = &blk_crypto_keyslots[i];\n\t\tcrypto_free_skcipher(slotp->tfms[mode_num]);\n\t\tslotp->tfms[mode_num] = NULL;\n\t}\nout:\n\tmutex_unlock(&tfms_init_lock);\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}