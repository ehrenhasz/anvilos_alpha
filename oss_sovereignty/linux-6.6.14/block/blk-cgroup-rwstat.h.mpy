{
  "module_name": "blk-cgroup-rwstat.h",
  "hash_id": "1f9b11e75ef060b6676cc19d913fdbfe82a35b1a697553a610a7be1eb42ebaee",
  "original_prompt": "Ingested from linux-6.6.14/block/blk-cgroup-rwstat.h",
  "human_readable_source": " \n#ifndef _BLK_CGROUP_RWSTAT_H\n#define _BLK_CGROUP_RWSTAT_H\n\n#include \"blk-cgroup.h\"\n\nenum blkg_rwstat_type {\n\tBLKG_RWSTAT_READ,\n\tBLKG_RWSTAT_WRITE,\n\tBLKG_RWSTAT_SYNC,\n\tBLKG_RWSTAT_ASYNC,\n\tBLKG_RWSTAT_DISCARD,\n\n\tBLKG_RWSTAT_NR,\n\tBLKG_RWSTAT_TOTAL = BLKG_RWSTAT_NR,\n};\n\n \nstruct blkg_rwstat {\n\tstruct percpu_counter\t\tcpu_cnt[BLKG_RWSTAT_NR];\n\tatomic64_t\t\t\taux_cnt[BLKG_RWSTAT_NR];\n};\n\nstruct blkg_rwstat_sample {\n\tu64\t\t\t\tcnt[BLKG_RWSTAT_NR];\n};\n\nstatic inline u64 blkg_rwstat_read_counter(struct blkg_rwstat *rwstat,\n\t\tunsigned int idx)\n{\n\treturn atomic64_read(&rwstat->aux_cnt[idx]) +\n\t\tpercpu_counter_sum_positive(&rwstat->cpu_cnt[idx]);\n}\n\nint blkg_rwstat_init(struct blkg_rwstat *rwstat, gfp_t gfp);\nvoid blkg_rwstat_exit(struct blkg_rwstat *rwstat);\nu64 __blkg_prfill_rwstat(struct seq_file *sf, struct blkg_policy_data *pd,\n\t\t\t const struct blkg_rwstat_sample *rwstat);\nu64 blkg_prfill_rwstat(struct seq_file *sf, struct blkg_policy_data *pd,\n\t\t       int off);\nvoid blkg_rwstat_recursive_sum(struct blkcg_gq *blkg, struct blkcg_policy *pol,\n\t\tint off, struct blkg_rwstat_sample *sum);\n\n\n \nstatic inline void blkg_rwstat_add(struct blkg_rwstat *rwstat,\n\t\t\t\t   blk_opf_t opf, uint64_t val)\n{\n\tstruct percpu_counter *cnt;\n\n\tif (op_is_discard(opf))\n\t\tcnt = &rwstat->cpu_cnt[BLKG_RWSTAT_DISCARD];\n\telse if (op_is_write(opf))\n\t\tcnt = &rwstat->cpu_cnt[BLKG_RWSTAT_WRITE];\n\telse\n\t\tcnt = &rwstat->cpu_cnt[BLKG_RWSTAT_READ];\n\n\tpercpu_counter_add_batch(cnt, val, BLKG_STAT_CPU_BATCH);\n\n\tif (op_is_sync(opf))\n\t\tcnt = &rwstat->cpu_cnt[BLKG_RWSTAT_SYNC];\n\telse\n\t\tcnt = &rwstat->cpu_cnt[BLKG_RWSTAT_ASYNC];\n\n\tpercpu_counter_add_batch(cnt, val, BLKG_STAT_CPU_BATCH);\n}\n\n \nstatic inline void blkg_rwstat_read(struct blkg_rwstat *rwstat,\n\t\tstruct blkg_rwstat_sample *result)\n{\n\tint i;\n\n\tfor (i = 0; i < BLKG_RWSTAT_NR; i++)\n\t\tresult->cnt[i] =\n\t\t\tpercpu_counter_sum_positive(&rwstat->cpu_cnt[i]);\n}\n\n \nstatic inline uint64_t blkg_rwstat_total(struct blkg_rwstat *rwstat)\n{\n\tstruct blkg_rwstat_sample tmp = { };\n\n\tblkg_rwstat_read(rwstat, &tmp);\n\treturn tmp.cnt[BLKG_RWSTAT_READ] + tmp.cnt[BLKG_RWSTAT_WRITE];\n}\n\n \nstatic inline void blkg_rwstat_reset(struct blkg_rwstat *rwstat)\n{\n\tint i;\n\n\tfor (i = 0; i < BLKG_RWSTAT_NR; i++) {\n\t\tpercpu_counter_set(&rwstat->cpu_cnt[i], 0);\n\t\tatomic64_set(&rwstat->aux_cnt[i], 0);\n\t}\n}\n\n \nstatic inline void blkg_rwstat_add_aux(struct blkg_rwstat *to,\n\t\t\t\t       struct blkg_rwstat *from)\n{\n\tu64 sum[BLKG_RWSTAT_NR];\n\tint i;\n\n\tfor (i = 0; i < BLKG_RWSTAT_NR; i++)\n\t\tsum[i] = percpu_counter_sum_positive(&from->cpu_cnt[i]);\n\n\tfor (i = 0; i < BLKG_RWSTAT_NR; i++)\n\t\tatomic64_add(sum[i] + atomic64_read(&from->aux_cnt[i]),\n\t\t\t     &to->aux_cnt[i]);\n}\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}