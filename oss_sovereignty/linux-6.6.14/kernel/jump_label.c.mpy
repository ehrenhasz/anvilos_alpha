{
  "module_name": "jump_label.c",
  "hash_id": "ee772dc8b37a2488a4da116b93723d64024e985d6f8ee6b4356826b3b27b604e",
  "original_prompt": "Ingested from linux-6.6.14/kernel/jump_label.c",
  "human_readable_source": "\n \n#include <linux/memory.h>\n#include <linux/uaccess.h>\n#include <linux/module.h>\n#include <linux/list.h>\n#include <linux/slab.h>\n#include <linux/sort.h>\n#include <linux/err.h>\n#include <linux/static_key.h>\n#include <linux/jump_label_ratelimit.h>\n#include <linux/bug.h>\n#include <linux/cpu.h>\n#include <asm/sections.h>\n\n \nstatic DEFINE_MUTEX(jump_label_mutex);\n\nvoid jump_label_lock(void)\n{\n\tmutex_lock(&jump_label_mutex);\n}\n\nvoid jump_label_unlock(void)\n{\n\tmutex_unlock(&jump_label_mutex);\n}\n\nstatic int jump_label_cmp(const void *a, const void *b)\n{\n\tconst struct jump_entry *jea = a;\n\tconst struct jump_entry *jeb = b;\n\n\t \n\tif (jump_entry_key(jea) < jump_entry_key(jeb))\n\t\treturn -1;\n\n\tif (jump_entry_key(jea) > jump_entry_key(jeb))\n\t\treturn 1;\n\n\t \n\tif (jump_entry_code(jea) < jump_entry_code(jeb))\n\t\treturn -1;\n\n\tif (jump_entry_code(jea) > jump_entry_code(jeb))\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic void jump_label_swap(void *a, void *b, int size)\n{\n\tlong delta = (unsigned long)a - (unsigned long)b;\n\tstruct jump_entry *jea = a;\n\tstruct jump_entry *jeb = b;\n\tstruct jump_entry tmp = *jea;\n\n\tjea->code\t= jeb->code - delta;\n\tjea->target\t= jeb->target - delta;\n\tjea->key\t= jeb->key - delta;\n\n\tjeb->code\t= tmp.code + delta;\n\tjeb->target\t= tmp.target + delta;\n\tjeb->key\t= tmp.key + delta;\n}\n\nstatic void\njump_label_sort_entries(struct jump_entry *start, struct jump_entry *stop)\n{\n\tunsigned long size;\n\tvoid *swapfn = NULL;\n\n\tif (IS_ENABLED(CONFIG_HAVE_ARCH_JUMP_LABEL_RELATIVE))\n\t\tswapfn = jump_label_swap;\n\n\tsize = (((unsigned long)stop - (unsigned long)start)\n\t\t\t\t\t/ sizeof(struct jump_entry));\n\tsort(start, size, sizeof(struct jump_entry), jump_label_cmp, swapfn);\n}\n\nstatic void jump_label_update(struct static_key *key);\n\n \nint static_key_count(struct static_key *key)\n{\n\t \n\tint n = atomic_read(&key->enabled);\n\n\treturn n >= 0 ? n : 1;\n}\nEXPORT_SYMBOL_GPL(static_key_count);\n\n \nbool static_key_fast_inc_not_disabled(struct static_key *key)\n{\n\tint v;\n\n\tSTATIC_KEY_CHECK_USE(key);\n\t \n\tv = atomic_read(&key->enabled);\n\tdo {\n\t\tif (v <= 0 || (v + 1) < 0)\n\t\t\treturn false;\n\t} while (!likely(atomic_try_cmpxchg(&key->enabled, &v, v + 1)));\n\n\treturn true;\n}\nEXPORT_SYMBOL_GPL(static_key_fast_inc_not_disabled);\n\nbool static_key_slow_inc_cpuslocked(struct static_key *key)\n{\n\tlockdep_assert_cpus_held();\n\n\t \n\tif (static_key_fast_inc_not_disabled(key))\n\t\treturn true;\n\n\tjump_label_lock();\n\tif (atomic_read(&key->enabled) == 0) {\n\t\tatomic_set(&key->enabled, -1);\n\t\tjump_label_update(key);\n\t\t \n\t\tatomic_set_release(&key->enabled, 1);\n\t} else {\n\t\tif (WARN_ON_ONCE(!static_key_fast_inc_not_disabled(key))) {\n\t\t\tjump_label_unlock();\n\t\t\treturn false;\n\t\t}\n\t}\n\tjump_label_unlock();\n\treturn true;\n}\n\nbool static_key_slow_inc(struct static_key *key)\n{\n\tbool ret;\n\n\tcpus_read_lock();\n\tret = static_key_slow_inc_cpuslocked(key);\n\tcpus_read_unlock();\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(static_key_slow_inc);\n\nvoid static_key_enable_cpuslocked(struct static_key *key)\n{\n\tSTATIC_KEY_CHECK_USE(key);\n\tlockdep_assert_cpus_held();\n\n\tif (atomic_read(&key->enabled) > 0) {\n\t\tWARN_ON_ONCE(atomic_read(&key->enabled) != 1);\n\t\treturn;\n\t}\n\n\tjump_label_lock();\n\tif (atomic_read(&key->enabled) == 0) {\n\t\tatomic_set(&key->enabled, -1);\n\t\tjump_label_update(key);\n\t\t \n\t\tatomic_set_release(&key->enabled, 1);\n\t}\n\tjump_label_unlock();\n}\nEXPORT_SYMBOL_GPL(static_key_enable_cpuslocked);\n\nvoid static_key_enable(struct static_key *key)\n{\n\tcpus_read_lock();\n\tstatic_key_enable_cpuslocked(key);\n\tcpus_read_unlock();\n}\nEXPORT_SYMBOL_GPL(static_key_enable);\n\nvoid static_key_disable_cpuslocked(struct static_key *key)\n{\n\tSTATIC_KEY_CHECK_USE(key);\n\tlockdep_assert_cpus_held();\n\n\tif (atomic_read(&key->enabled) != 1) {\n\t\tWARN_ON_ONCE(atomic_read(&key->enabled) != 0);\n\t\treturn;\n\t}\n\n\tjump_label_lock();\n\tif (atomic_cmpxchg(&key->enabled, 1, 0))\n\t\tjump_label_update(key);\n\tjump_label_unlock();\n}\nEXPORT_SYMBOL_GPL(static_key_disable_cpuslocked);\n\nvoid static_key_disable(struct static_key *key)\n{\n\tcpus_read_lock();\n\tstatic_key_disable_cpuslocked(key);\n\tcpus_read_unlock();\n}\nEXPORT_SYMBOL_GPL(static_key_disable);\n\nstatic bool static_key_slow_try_dec(struct static_key *key)\n{\n\tint val;\n\n\tval = atomic_fetch_add_unless(&key->enabled, -1, 1);\n\tif (val == 1)\n\t\treturn false;\n\n\t \n\tWARN(val < 0, \"jump label: negative count!\\n\");\n\treturn true;\n}\n\nstatic void __static_key_slow_dec_cpuslocked(struct static_key *key)\n{\n\tlockdep_assert_cpus_held();\n\n\tif (static_key_slow_try_dec(key))\n\t\treturn;\n\n\tjump_label_lock();\n\tif (atomic_dec_and_test(&key->enabled))\n\t\tjump_label_update(key);\n\tjump_label_unlock();\n}\n\nstatic void __static_key_slow_dec(struct static_key *key)\n{\n\tcpus_read_lock();\n\t__static_key_slow_dec_cpuslocked(key);\n\tcpus_read_unlock();\n}\n\nvoid jump_label_update_timeout(struct work_struct *work)\n{\n\tstruct static_key_deferred *key =\n\t\tcontainer_of(work, struct static_key_deferred, work.work);\n\t__static_key_slow_dec(&key->key);\n}\nEXPORT_SYMBOL_GPL(jump_label_update_timeout);\n\nvoid static_key_slow_dec(struct static_key *key)\n{\n\tSTATIC_KEY_CHECK_USE(key);\n\t__static_key_slow_dec(key);\n}\nEXPORT_SYMBOL_GPL(static_key_slow_dec);\n\nvoid static_key_slow_dec_cpuslocked(struct static_key *key)\n{\n\tSTATIC_KEY_CHECK_USE(key);\n\t__static_key_slow_dec_cpuslocked(key);\n}\n\nvoid __static_key_slow_dec_deferred(struct static_key *key,\n\t\t\t\t    struct delayed_work *work,\n\t\t\t\t    unsigned long timeout)\n{\n\tSTATIC_KEY_CHECK_USE(key);\n\n\tif (static_key_slow_try_dec(key))\n\t\treturn;\n\n\tschedule_delayed_work(work, timeout);\n}\nEXPORT_SYMBOL_GPL(__static_key_slow_dec_deferred);\n\nvoid __static_key_deferred_flush(void *key, struct delayed_work *work)\n{\n\tSTATIC_KEY_CHECK_USE(key);\n\tflush_delayed_work(work);\n}\nEXPORT_SYMBOL_GPL(__static_key_deferred_flush);\n\nvoid jump_label_rate_limit(struct static_key_deferred *key,\n\t\tunsigned long rl)\n{\n\tSTATIC_KEY_CHECK_USE(key);\n\tkey->timeout = rl;\n\tINIT_DELAYED_WORK(&key->work, jump_label_update_timeout);\n}\nEXPORT_SYMBOL_GPL(jump_label_rate_limit);\n\nstatic int addr_conflict(struct jump_entry *entry, void *start, void *end)\n{\n\tif (jump_entry_code(entry) <= (unsigned long)end &&\n\t    jump_entry_code(entry) + jump_entry_size(entry) > (unsigned long)start)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic int __jump_label_text_reserved(struct jump_entry *iter_start,\n\t\tstruct jump_entry *iter_stop, void *start, void *end, bool init)\n{\n\tstruct jump_entry *iter;\n\n\titer = iter_start;\n\twhile (iter < iter_stop) {\n\t\tif (init || !jump_entry_is_init(iter)) {\n\t\t\tif (addr_conflict(iter, start, end))\n\t\t\t\treturn 1;\n\t\t}\n\t\titer++;\n\t}\n\n\treturn 0;\n}\n\n#ifndef arch_jump_label_transform_static\nstatic void arch_jump_label_transform_static(struct jump_entry *entry,\n\t\t\t\t\t     enum jump_label_type type)\n{\n\t \n}\n#endif\n\nstatic inline struct jump_entry *static_key_entries(struct static_key *key)\n{\n\tWARN_ON_ONCE(key->type & JUMP_TYPE_LINKED);\n\treturn (struct jump_entry *)(key->type & ~JUMP_TYPE_MASK);\n}\n\nstatic inline bool static_key_type(struct static_key *key)\n{\n\treturn key->type & JUMP_TYPE_TRUE;\n}\n\nstatic inline bool static_key_linked(struct static_key *key)\n{\n\treturn key->type & JUMP_TYPE_LINKED;\n}\n\nstatic inline void static_key_clear_linked(struct static_key *key)\n{\n\tkey->type &= ~JUMP_TYPE_LINKED;\n}\n\nstatic inline void static_key_set_linked(struct static_key *key)\n{\n\tkey->type |= JUMP_TYPE_LINKED;\n}\n\n \nstatic void static_key_set_entries(struct static_key *key,\n\t\t\t\t   struct jump_entry *entries)\n{\n\tunsigned long type;\n\n\tWARN_ON_ONCE((unsigned long)entries & JUMP_TYPE_MASK);\n\ttype = key->type & JUMP_TYPE_MASK;\n\tkey->entries = entries;\n\tkey->type |= type;\n}\n\nstatic enum jump_label_type jump_label_type(struct jump_entry *entry)\n{\n\tstruct static_key *key = jump_entry_key(entry);\n\tbool enabled = static_key_enabled(key);\n\tbool branch = jump_entry_is_branch(entry);\n\n\t \n\treturn enabled ^ branch;\n}\n\nstatic bool jump_label_can_update(struct jump_entry *entry, bool init)\n{\n\t \n\tif (!init && jump_entry_is_init(entry))\n\t\treturn false;\n\n\tif (!kernel_text_address(jump_entry_code(entry))) {\n\t\t \n\t\tWARN_ONCE(!jump_entry_is_init(entry),\n\t\t\t  \"can't patch jump_label at %pS\",\n\t\t\t  (void *)jump_entry_code(entry));\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n#ifndef HAVE_JUMP_LABEL_BATCH\nstatic void __jump_label_update(struct static_key *key,\n\t\t\t\tstruct jump_entry *entry,\n\t\t\t\tstruct jump_entry *stop,\n\t\t\t\tbool init)\n{\n\tfor (; (entry < stop) && (jump_entry_key(entry) == key); entry++) {\n\t\tif (jump_label_can_update(entry, init))\n\t\t\tarch_jump_label_transform(entry, jump_label_type(entry));\n\t}\n}\n#else\nstatic void __jump_label_update(struct static_key *key,\n\t\t\t\tstruct jump_entry *entry,\n\t\t\t\tstruct jump_entry *stop,\n\t\t\t\tbool init)\n{\n\tfor (; (entry < stop) && (jump_entry_key(entry) == key); entry++) {\n\n\t\tif (!jump_label_can_update(entry, init))\n\t\t\tcontinue;\n\n\t\tif (!arch_jump_label_transform_queue(entry, jump_label_type(entry))) {\n\t\t\t \n\t\t\tarch_jump_label_transform_apply();\n\t\t\tBUG_ON(!arch_jump_label_transform_queue(entry, jump_label_type(entry)));\n\t\t}\n\t}\n\tarch_jump_label_transform_apply();\n}\n#endif\n\nvoid __init jump_label_init(void)\n{\n\tstruct jump_entry *iter_start = __start___jump_table;\n\tstruct jump_entry *iter_stop = __stop___jump_table;\n\tstruct static_key *key = NULL;\n\tstruct jump_entry *iter;\n\n\t \n\tBUILD_BUG_ON((int)ATOMIC_INIT(0) != 0);\n\tBUILD_BUG_ON((int)ATOMIC_INIT(1) != 1);\n\n\tif (static_key_initialized)\n\t\treturn;\n\n\tcpus_read_lock();\n\tjump_label_lock();\n\tjump_label_sort_entries(iter_start, iter_stop);\n\n\tfor (iter = iter_start; iter < iter_stop; iter++) {\n\t\tstruct static_key *iterk;\n\t\tbool in_init;\n\n\t\t \n\t\tif (jump_label_type(iter) == JUMP_LABEL_NOP)\n\t\t\tarch_jump_label_transform_static(iter, JUMP_LABEL_NOP);\n\n\t\tin_init = init_section_contains((void *)jump_entry_code(iter), 1);\n\t\tjump_entry_set_init(iter, in_init);\n\n\t\titerk = jump_entry_key(iter);\n\t\tif (iterk == key)\n\t\t\tcontinue;\n\n\t\tkey = iterk;\n\t\tstatic_key_set_entries(key, iter);\n\t}\n\tstatic_key_initialized = true;\n\tjump_label_unlock();\n\tcpus_read_unlock();\n}\n\n#ifdef CONFIG_MODULES\n\nenum jump_label_type jump_label_init_type(struct jump_entry *entry)\n{\n\tstruct static_key *key = jump_entry_key(entry);\n\tbool type = static_key_type(key);\n\tbool branch = jump_entry_is_branch(entry);\n\n\t \n\treturn type ^ branch;\n}\n\nstruct static_key_mod {\n\tstruct static_key_mod *next;\n\tstruct jump_entry *entries;\n\tstruct module *mod;\n};\n\nstatic inline struct static_key_mod *static_key_mod(struct static_key *key)\n{\n\tWARN_ON_ONCE(!static_key_linked(key));\n\treturn (struct static_key_mod *)(key->type & ~JUMP_TYPE_MASK);\n}\n\n \nstatic void static_key_set_mod(struct static_key *key,\n\t\t\t       struct static_key_mod *mod)\n{\n\tunsigned long type;\n\n\tWARN_ON_ONCE((unsigned long)mod & JUMP_TYPE_MASK);\n\ttype = key->type & JUMP_TYPE_MASK;\n\tkey->next = mod;\n\tkey->type |= type;\n}\n\nstatic int __jump_label_mod_text_reserved(void *start, void *end)\n{\n\tstruct module *mod;\n\tint ret;\n\n\tpreempt_disable();\n\tmod = __module_text_address((unsigned long)start);\n\tWARN_ON_ONCE(__module_text_address((unsigned long)end) != mod);\n\tif (!try_module_get(mod))\n\t\tmod = NULL;\n\tpreempt_enable();\n\n\tif (!mod)\n\t\treturn 0;\n\n\tret = __jump_label_text_reserved(mod->jump_entries,\n\t\t\t\tmod->jump_entries + mod->num_jump_entries,\n\t\t\t\tstart, end, mod->state == MODULE_STATE_COMING);\n\n\tmodule_put(mod);\n\n\treturn ret;\n}\n\nstatic void __jump_label_mod_update(struct static_key *key)\n{\n\tstruct static_key_mod *mod;\n\n\tfor (mod = static_key_mod(key); mod; mod = mod->next) {\n\t\tstruct jump_entry *stop;\n\t\tstruct module *m;\n\n\t\t \n\t\tif (!mod->entries)\n\t\t\tcontinue;\n\n\t\tm = mod->mod;\n\t\tif (!m)\n\t\t\tstop = __stop___jump_table;\n\t\telse\n\t\t\tstop = m->jump_entries + m->num_jump_entries;\n\t\t__jump_label_update(key, mod->entries, stop,\n\t\t\t\t    m && m->state == MODULE_STATE_COMING);\n\t}\n}\n\nstatic int jump_label_add_module(struct module *mod)\n{\n\tstruct jump_entry *iter_start = mod->jump_entries;\n\tstruct jump_entry *iter_stop = iter_start + mod->num_jump_entries;\n\tstruct jump_entry *iter;\n\tstruct static_key *key = NULL;\n\tstruct static_key_mod *jlm, *jlm2;\n\n\t \n\tif (iter_start == iter_stop)\n\t\treturn 0;\n\n\tjump_label_sort_entries(iter_start, iter_stop);\n\n\tfor (iter = iter_start; iter < iter_stop; iter++) {\n\t\tstruct static_key *iterk;\n\t\tbool in_init;\n\n\t\tin_init = within_module_init(jump_entry_code(iter), mod);\n\t\tjump_entry_set_init(iter, in_init);\n\n\t\titerk = jump_entry_key(iter);\n\t\tif (iterk == key)\n\t\t\tcontinue;\n\n\t\tkey = iterk;\n\t\tif (within_module((unsigned long)key, mod)) {\n\t\t\tstatic_key_set_entries(key, iter);\n\t\t\tcontinue;\n\t\t}\n\t\tjlm = kzalloc(sizeof(struct static_key_mod), GFP_KERNEL);\n\t\tif (!jlm)\n\t\t\treturn -ENOMEM;\n\t\tif (!static_key_linked(key)) {\n\t\t\tjlm2 = kzalloc(sizeof(struct static_key_mod),\n\t\t\t\t       GFP_KERNEL);\n\t\t\tif (!jlm2) {\n\t\t\t\tkfree(jlm);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tpreempt_disable();\n\t\t\tjlm2->mod = __module_address((unsigned long)key);\n\t\t\tpreempt_enable();\n\t\t\tjlm2->entries = static_key_entries(key);\n\t\t\tjlm2->next = NULL;\n\t\t\tstatic_key_set_mod(key, jlm2);\n\t\t\tstatic_key_set_linked(key);\n\t\t}\n\t\tjlm->mod = mod;\n\t\tjlm->entries = iter;\n\t\tjlm->next = static_key_mod(key);\n\t\tstatic_key_set_mod(key, jlm);\n\t\tstatic_key_set_linked(key);\n\n\t\t \n\t\tif (jump_label_type(iter) != jump_label_init_type(iter))\n\t\t\t__jump_label_update(key, iter, iter_stop, true);\n\t}\n\n\treturn 0;\n}\n\nstatic void jump_label_del_module(struct module *mod)\n{\n\tstruct jump_entry *iter_start = mod->jump_entries;\n\tstruct jump_entry *iter_stop = iter_start + mod->num_jump_entries;\n\tstruct jump_entry *iter;\n\tstruct static_key *key = NULL;\n\tstruct static_key_mod *jlm, **prev;\n\n\tfor (iter = iter_start; iter < iter_stop; iter++) {\n\t\tif (jump_entry_key(iter) == key)\n\t\t\tcontinue;\n\n\t\tkey = jump_entry_key(iter);\n\n\t\tif (within_module((unsigned long)key, mod))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (WARN_ON(!static_key_linked(key)))\n\t\t\tcontinue;\n\n\t\tprev = &key->next;\n\t\tjlm = static_key_mod(key);\n\n\t\twhile (jlm && jlm->mod != mod) {\n\t\t\tprev = &jlm->next;\n\t\t\tjlm = jlm->next;\n\t\t}\n\n\t\t \n\t\tif (WARN_ON(!jlm))\n\t\t\tcontinue;\n\n\t\tif (prev == &key->next)\n\t\t\tstatic_key_set_mod(key, jlm->next);\n\t\telse\n\t\t\t*prev = jlm->next;\n\n\t\tkfree(jlm);\n\n\t\tjlm = static_key_mod(key);\n\t\t \n\t\tif (jlm->next == NULL) {\n\t\t\tstatic_key_set_entries(key, jlm->entries);\n\t\t\tstatic_key_clear_linked(key);\n\t\t\tkfree(jlm);\n\t\t}\n\t}\n}\n\nstatic int\njump_label_module_notify(struct notifier_block *self, unsigned long val,\n\t\t\t void *data)\n{\n\tstruct module *mod = data;\n\tint ret = 0;\n\n\tcpus_read_lock();\n\tjump_label_lock();\n\n\tswitch (val) {\n\tcase MODULE_STATE_COMING:\n\t\tret = jump_label_add_module(mod);\n\t\tif (ret) {\n\t\t\tWARN(1, \"Failed to allocate memory: jump_label may not work properly.\\n\");\n\t\t\tjump_label_del_module(mod);\n\t\t}\n\t\tbreak;\n\tcase MODULE_STATE_GOING:\n\t\tjump_label_del_module(mod);\n\t\tbreak;\n\t}\n\n\tjump_label_unlock();\n\tcpus_read_unlock();\n\n\treturn notifier_from_errno(ret);\n}\n\nstatic struct notifier_block jump_label_module_nb = {\n\t.notifier_call = jump_label_module_notify,\n\t.priority = 1,  \n};\n\nstatic __init int jump_label_init_module(void)\n{\n\treturn register_module_notifier(&jump_label_module_nb);\n}\nearly_initcall(jump_label_init_module);\n\n#endif  \n\n \nint jump_label_text_reserved(void *start, void *end)\n{\n\tbool init = system_state < SYSTEM_RUNNING;\n\tint ret = __jump_label_text_reserved(__start___jump_table,\n\t\t\t__stop___jump_table, start, end, init);\n\n\tif (ret)\n\t\treturn ret;\n\n#ifdef CONFIG_MODULES\n\tret = __jump_label_mod_text_reserved(start, end);\n#endif\n\treturn ret;\n}\n\nstatic void jump_label_update(struct static_key *key)\n{\n\tstruct jump_entry *stop = __stop___jump_table;\n\tbool init = system_state < SYSTEM_RUNNING;\n\tstruct jump_entry *entry;\n#ifdef CONFIG_MODULES\n\tstruct module *mod;\n\n\tif (static_key_linked(key)) {\n\t\t__jump_label_mod_update(key);\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tmod = __module_address((unsigned long)key);\n\tif (mod) {\n\t\tstop = mod->jump_entries + mod->num_jump_entries;\n\t\tinit = mod->state == MODULE_STATE_COMING;\n\t}\n\tpreempt_enable();\n#endif\n\tentry = static_key_entries(key);\n\t \n\tif (entry)\n\t\t__jump_label_update(key, entry, stop, init);\n}\n\n#ifdef CONFIG_STATIC_KEYS_SELFTEST\nstatic DEFINE_STATIC_KEY_TRUE(sk_true);\nstatic DEFINE_STATIC_KEY_FALSE(sk_false);\n\nstatic __init int jump_label_test(void)\n{\n\tint i;\n\n\tfor (i = 0; i < 2; i++) {\n\t\tWARN_ON(static_key_enabled(&sk_true.key) != true);\n\t\tWARN_ON(static_key_enabled(&sk_false.key) != false);\n\n\t\tWARN_ON(!static_branch_likely(&sk_true));\n\t\tWARN_ON(!static_branch_unlikely(&sk_true));\n\t\tWARN_ON(static_branch_likely(&sk_false));\n\t\tWARN_ON(static_branch_unlikely(&sk_false));\n\n\t\tstatic_branch_disable(&sk_true);\n\t\tstatic_branch_enable(&sk_false);\n\n\t\tWARN_ON(static_key_enabled(&sk_true.key) == true);\n\t\tWARN_ON(static_key_enabled(&sk_false.key) == false);\n\n\t\tWARN_ON(static_branch_likely(&sk_true));\n\t\tWARN_ON(static_branch_unlikely(&sk_true));\n\t\tWARN_ON(!static_branch_likely(&sk_false));\n\t\tWARN_ON(!static_branch_unlikely(&sk_false));\n\n\t\tstatic_branch_enable(&sk_true);\n\t\tstatic_branch_disable(&sk_false);\n\t}\n\n\treturn 0;\n}\nearly_initcall(jump_label_test);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}