{
  "module_name": "context_tracking.c",
  "hash_id": "76d796308ed6624d1dc80f4d50f4be63350c6e49c9c7a4b0bd4a51ba7453f434",
  "original_prompt": "Ingested from linux-6.6.14/kernel/context_tracking.c",
  "human_readable_source": "\n \n\n#include <linux/context_tracking.h>\n#include <linux/rcupdate.h>\n#include <linux/sched.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/kprobes.h>\n#include <trace/events/rcu.h>\n\n\nDEFINE_PER_CPU(struct context_tracking, context_tracking) = {\n#ifdef CONFIG_CONTEXT_TRACKING_IDLE\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n#endif\n\t.state = ATOMIC_INIT(RCU_DYNTICKS_IDX),\n};\nEXPORT_SYMBOL_GPL(context_tracking);\n\n#ifdef CONFIG_CONTEXT_TRACKING_IDLE\n#define TPS(x)  tracepoint_string(x)\n\n \nstatic __always_inline void rcu_dynticks_task_enter(void)\n{\n#if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL)\n\tWRITE_ONCE(current->rcu_tasks_idle_cpu, smp_processor_id());\n#endif  \n}\n\n \nstatic __always_inline void rcu_dynticks_task_exit(void)\n{\n#if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL)\n\tWRITE_ONCE(current->rcu_tasks_idle_cpu, -1);\n#endif  \n}\n\n \nstatic __always_inline void rcu_dynticks_task_trace_enter(void)\n{\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))\n\t\tcurrent->trc_reader_special.b.need_mb = true;\n#endif  \n}\n\n \nstatic __always_inline void rcu_dynticks_task_trace_exit(void)\n{\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))\n\t\tcurrent->trc_reader_special.b.need_mb = false;\n#endif  \n}\n\n \nstatic noinstr void ct_kernel_exit_state(int offset)\n{\n\tint seq;\n\n\t \n\trcu_dynticks_task_trace_enter();  \n\tseq = ct_state_inc(offset);\n\t\n\tWARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) && (seq & RCU_DYNTICKS_IDX));\n}\n\n \nstatic noinstr void ct_kernel_enter_state(int offset)\n{\n\tint seq;\n\n\t \n\tseq = ct_state_inc(offset);\n\t\n\trcu_dynticks_task_trace_exit();  \n\tWARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) && !(seq & RCU_DYNTICKS_IDX));\n}\n\n \nstatic void noinstr ct_kernel_exit(bool user, int offset)\n{\n\tstruct context_tracking *ct = this_cpu_ptr(&context_tracking);\n\n\tWARN_ON_ONCE(ct_dynticks_nmi_nesting() != DYNTICK_IRQ_NONIDLE);\n\tWRITE_ONCE(ct->dynticks_nmi_nesting, 0);\n\tWARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &&\n\t\t     ct_dynticks_nesting() == 0);\n\tif (ct_dynticks_nesting() != 1) {\n\t\t\n\t\tct->dynticks_nesting--;\n\t\treturn;\n\t}\n\n\tinstrumentation_begin();\n\tlockdep_assert_irqs_disabled();\n\ttrace_rcu_dyntick(TPS(\"Start\"), ct_dynticks_nesting(), 0, ct_dynticks());\n\tWARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) && !user && !is_idle_task(current));\n\trcu_preempt_deferred_qs(current);\n\n\t\n\tinstrument_atomic_write(&ct->state, sizeof(ct->state));\n\n\tinstrumentation_end();\n\tWRITE_ONCE(ct->dynticks_nesting, 0);  \n\t\n\tct_kernel_exit_state(offset);\n\t\n\trcu_dynticks_task_enter();\n}\n\n \nstatic void noinstr ct_kernel_enter(bool user, int offset)\n{\n\tstruct context_tracking *ct = this_cpu_ptr(&context_tracking);\n\tlong oldval;\n\n\tWARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) && !raw_irqs_disabled());\n\toldval = ct_dynticks_nesting();\n\tWARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) && oldval < 0);\n\tif (oldval) {\n\t\t\n\t\tct->dynticks_nesting++;\n\t\treturn;\n\t}\n\trcu_dynticks_task_exit();\n\t\n\tct_kernel_enter_state(offset);\n\t\n\tinstrumentation_begin();\n\n\t\n\tinstrument_atomic_write(&ct->state, sizeof(ct->state));\n\n\ttrace_rcu_dyntick(TPS(\"End\"), ct_dynticks_nesting(), 1, ct_dynticks());\n\tWARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) && !user && !is_idle_task(current));\n\tWRITE_ONCE(ct->dynticks_nesting, 1);\n\tWARN_ON_ONCE(ct_dynticks_nmi_nesting());\n\tWRITE_ONCE(ct->dynticks_nmi_nesting, DYNTICK_IRQ_NONIDLE);\n\tinstrumentation_end();\n}\n\n \nvoid noinstr ct_nmi_exit(void)\n{\n\tstruct context_tracking *ct = this_cpu_ptr(&context_tracking);\n\n\tinstrumentation_begin();\n\t \n\tWARN_ON_ONCE(ct_dynticks_nmi_nesting() <= 0);\n\tWARN_ON_ONCE(rcu_dynticks_curr_cpu_in_eqs());\n\n\t \n\tif (ct_dynticks_nmi_nesting() != 1) {\n\t\ttrace_rcu_dyntick(TPS(\"--=\"), ct_dynticks_nmi_nesting(), ct_dynticks_nmi_nesting() - 2,\n\t\t\t\t  ct_dynticks());\n\t\tWRITE_ONCE(ct->dynticks_nmi_nesting,  \n\t\t\t   ct_dynticks_nmi_nesting() - 2);\n\t\tinstrumentation_end();\n\t\treturn;\n\t}\n\n\t \n\ttrace_rcu_dyntick(TPS(\"Startirq\"), ct_dynticks_nmi_nesting(), 0, ct_dynticks());\n\tWRITE_ONCE(ct->dynticks_nmi_nesting, 0);  \n\n\t \n\tinstrument_atomic_write(&ct->state, sizeof(ct->state));\n\tinstrumentation_end();\n\n\t \n\tct_kernel_exit_state(RCU_DYNTICKS_IDX);\n\t \n\n\tif (!in_nmi())\n\t\trcu_dynticks_task_enter();\n}\n\n \nvoid noinstr ct_nmi_enter(void)\n{\n\tlong incby = 2;\n\tstruct context_tracking *ct = this_cpu_ptr(&context_tracking);\n\n\t \n\tWARN_ON_ONCE(ct_dynticks_nmi_nesting() < 0);\n\n\t \n\tif (rcu_dynticks_curr_cpu_in_eqs()) {\n\n\t\tif (!in_nmi())\n\t\t\trcu_dynticks_task_exit();\n\n\t\t\n\t\tct_kernel_enter_state(RCU_DYNTICKS_IDX);\n\t\t\n\n\t\tinstrumentation_begin();\n\t\t\n\t\tinstrument_atomic_read(&ct->state, sizeof(ct->state));\n\t\t\n\t\tinstrument_atomic_write(&ct->state, sizeof(ct->state));\n\n\t\tincby = 1;\n\t} else if (!in_nmi()) {\n\t\tinstrumentation_begin();\n\t\trcu_irq_enter_check_tick();\n\t} else  {\n\t\tinstrumentation_begin();\n\t}\n\n\ttrace_rcu_dyntick(incby == 1 ? TPS(\"Endirq\") : TPS(\"++=\"),\n\t\t\t  ct_dynticks_nmi_nesting(),\n\t\t\t  ct_dynticks_nmi_nesting() + incby, ct_dynticks());\n\tinstrumentation_end();\n\tWRITE_ONCE(ct->dynticks_nmi_nesting,  \n\t\t   ct_dynticks_nmi_nesting() + incby);\n\tbarrier();\n}\n\n \nvoid noinstr ct_idle_enter(void)\n{\n\tWARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) && !raw_irqs_disabled());\n\tct_kernel_exit(false, RCU_DYNTICKS_IDX + CONTEXT_IDLE);\n}\nEXPORT_SYMBOL_GPL(ct_idle_enter);\n\n \nvoid noinstr ct_idle_exit(void)\n{\n\tunsigned long flags;\n\n\traw_local_irq_save(flags);\n\tct_kernel_enter(false, RCU_DYNTICKS_IDX - CONTEXT_IDLE);\n\traw_local_irq_restore(flags);\n}\nEXPORT_SYMBOL_GPL(ct_idle_exit);\n\n \nnoinstr void ct_irq_enter(void)\n{\n\tlockdep_assert_irqs_disabled();\n\tct_nmi_enter();\n}\n\n \nnoinstr void ct_irq_exit(void)\n{\n\tlockdep_assert_irqs_disabled();\n\tct_nmi_exit();\n}\n\n \nvoid ct_irq_enter_irqson(void)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tct_irq_enter();\n\tlocal_irq_restore(flags);\n}\n\n \nvoid ct_irq_exit_irqson(void)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tct_irq_exit();\n\tlocal_irq_restore(flags);\n}\n#else\nstatic __always_inline void ct_kernel_exit(bool user, int offset) { }\nstatic __always_inline void ct_kernel_enter(bool user, int offset) { }\n#endif  \n\n#ifdef CONFIG_CONTEXT_TRACKING_USER\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/context_tracking.h>\n\nDEFINE_STATIC_KEY_FALSE(context_tracking_key);\nEXPORT_SYMBOL_GPL(context_tracking_key);\n\nstatic noinstr bool context_tracking_recursion_enter(void)\n{\n\tint recursion;\n\n\trecursion = __this_cpu_inc_return(context_tracking.recursion);\n\tif (recursion == 1)\n\t\treturn true;\n\n\tWARN_ONCE((recursion < 1), \"Invalid context tracking recursion value %d\\n\", recursion);\n\t__this_cpu_dec(context_tracking.recursion);\n\n\treturn false;\n}\n\nstatic __always_inline void context_tracking_recursion_exit(void)\n{\n\t__this_cpu_dec(context_tracking.recursion);\n}\n\n \nvoid noinstr __ct_user_enter(enum ctx_state state)\n{\n\tstruct context_tracking *ct = this_cpu_ptr(&context_tracking);\n\tlockdep_assert_irqs_disabled();\n\n\t \n\tWARN_ON_ONCE(!current->mm);\n\n\tif (!context_tracking_recursion_enter())\n\t\treturn;\n\n\tif (__ct_state() != state) {\n\t\tif (ct->active) {\n\t\t\t \n\t\t\tif (state == CONTEXT_USER) {\n\t\t\t\tinstrumentation_begin();\n\t\t\t\ttrace_user_enter(0);\n\t\t\t\tvtime_user_enter(current);\n\t\t\t\tinstrumentation_end();\n\t\t\t}\n\t\t\t \n\t\t\trcu_irq_work_resched();\n\n\t\t\t \n\t\t\tct_kernel_exit(true, RCU_DYNTICKS_IDX + state);\n\n\t\t\t \n\t\t\tif (!IS_ENABLED(CONFIG_CONTEXT_TRACKING_IDLE))\n\t\t\t\traw_atomic_set(&ct->state, state);\n\t\t} else {\n\t\t\t \n\t\t\tif (!IS_ENABLED(CONFIG_CONTEXT_TRACKING_IDLE)) {\n\t\t\t\t \n\t\t\t\traw_atomic_set(&ct->state, state);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\traw_atomic_add(state, &ct->state);\n\t\t\t}\n\t\t}\n\t}\n\tcontext_tracking_recursion_exit();\n}\nEXPORT_SYMBOL_GPL(__ct_user_enter);\n\n \nvoid ct_user_enter(enum ctx_state state)\n{\n\tunsigned long flags;\n\n\t \n\tif (in_interrupt())\n\t\treturn;\n\n\tlocal_irq_save(flags);\n\t__ct_user_enter(state);\n\tlocal_irq_restore(flags);\n}\nNOKPROBE_SYMBOL(ct_user_enter);\nEXPORT_SYMBOL_GPL(ct_user_enter);\n\n \nvoid user_enter_callable(void)\n{\n\tuser_enter();\n}\nNOKPROBE_SYMBOL(user_enter_callable);\n\n \nvoid noinstr __ct_user_exit(enum ctx_state state)\n{\n\tstruct context_tracking *ct = this_cpu_ptr(&context_tracking);\n\n\tif (!context_tracking_recursion_enter())\n\t\treturn;\n\n\tif (__ct_state() == state) {\n\t\tif (ct->active) {\n\t\t\t \n\t\t\tct_kernel_enter(true, RCU_DYNTICKS_IDX - state);\n\t\t\tif (state == CONTEXT_USER) {\n\t\t\t\tinstrumentation_begin();\n\t\t\t\tvtime_user_exit(current);\n\t\t\t\ttrace_user_exit(0);\n\t\t\t\tinstrumentation_end();\n\t\t\t}\n\n\t\t\t \n\t\t\tif (!IS_ENABLED(CONFIG_CONTEXT_TRACKING_IDLE))\n\t\t\t\traw_atomic_set(&ct->state, CONTEXT_KERNEL);\n\n\t\t} else {\n\t\t\tif (!IS_ENABLED(CONFIG_CONTEXT_TRACKING_IDLE)) {\n\t\t\t\t \n\t\t\t\traw_atomic_set(&ct->state, CONTEXT_KERNEL);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\traw_atomic_sub(state, &ct->state);\n\t\t\t}\n\t\t}\n\t}\n\tcontext_tracking_recursion_exit();\n}\nEXPORT_SYMBOL_GPL(__ct_user_exit);\n\n \nvoid ct_user_exit(enum ctx_state state)\n{\n\tunsigned long flags;\n\n\tif (in_interrupt())\n\t\treturn;\n\n\tlocal_irq_save(flags);\n\t__ct_user_exit(state);\n\tlocal_irq_restore(flags);\n}\nNOKPROBE_SYMBOL(ct_user_exit);\nEXPORT_SYMBOL_GPL(ct_user_exit);\n\n \nvoid user_exit_callable(void)\n{\n\tuser_exit();\n}\nNOKPROBE_SYMBOL(user_exit_callable);\n\nvoid __init ct_cpu_track_user(int cpu)\n{\n\tstatic __initdata bool initialized = false;\n\n\tif (!per_cpu(context_tracking.active, cpu)) {\n\t\tper_cpu(context_tracking.active, cpu) = true;\n\t\tstatic_branch_inc(&context_tracking_key);\n\t}\n\n\tif (initialized)\n\t\treturn;\n\n#ifdef CONFIG_HAVE_TIF_NOHZ\n\t \n\tset_tsk_thread_flag(&init_task, TIF_NOHZ);\n#endif\n\tWARN_ON_ONCE(!tasklist_empty());\n\n\tinitialized = true;\n}\n\n#ifdef CONFIG_CONTEXT_TRACKING_USER_FORCE\nvoid __init context_tracking_init(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tct_cpu_track_user(cpu);\n}\n#endif\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}