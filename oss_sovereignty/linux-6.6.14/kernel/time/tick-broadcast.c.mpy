{
  "module_name": "tick-broadcast.c",
  "hash_id": "3245ff32911b3405a0d146e809e75b2c12238b47549a7c3cc091674dba525936",
  "original_prompt": "Ingested from linux-6.6.14/kernel/time/tick-broadcast.c",
  "human_readable_source": "\n \n#include <linux/cpu.h>\n#include <linux/err.h>\n#include <linux/hrtimer.h>\n#include <linux/interrupt.h>\n#include <linux/percpu.h>\n#include <linux/profile.h>\n#include <linux/sched.h>\n#include <linux/smp.h>\n#include <linux/module.h>\n\n#include \"tick-internal.h\"\n\n \n\nstatic struct tick_device tick_broadcast_device;\nstatic cpumask_var_t tick_broadcast_mask __cpumask_var_read_mostly;\nstatic cpumask_var_t tick_broadcast_on __cpumask_var_read_mostly;\nstatic cpumask_var_t tmpmask __cpumask_var_read_mostly;\nstatic int tick_broadcast_forced;\n\nstatic __cacheline_aligned_in_smp DEFINE_RAW_SPINLOCK(tick_broadcast_lock);\n\n#ifdef CONFIG_TICK_ONESHOT\nstatic DEFINE_PER_CPU(struct clock_event_device *, tick_oneshot_wakeup_device);\n\nstatic void tick_broadcast_setup_oneshot(struct clock_event_device *bc, bool from_periodic);\nstatic void tick_broadcast_clear_oneshot(int cpu);\nstatic void tick_resume_broadcast_oneshot(struct clock_event_device *bc);\n# ifdef CONFIG_HOTPLUG_CPU\nstatic void tick_broadcast_oneshot_offline(unsigned int cpu);\n# endif\n#else\nstatic inline void\ntick_broadcast_setup_oneshot(struct clock_event_device *bc, bool from_periodic) { BUG(); }\nstatic inline void tick_broadcast_clear_oneshot(int cpu) { }\nstatic inline void tick_resume_broadcast_oneshot(struct clock_event_device *bc) { }\n# ifdef CONFIG_HOTPLUG_CPU\nstatic inline void tick_broadcast_oneshot_offline(unsigned int cpu) { }\n# endif\n#endif\n\n \nstruct tick_device *tick_get_broadcast_device(void)\n{\n\treturn &tick_broadcast_device;\n}\n\nstruct cpumask *tick_get_broadcast_mask(void)\n{\n\treturn tick_broadcast_mask;\n}\n\nstatic struct clock_event_device *tick_get_oneshot_wakeup_device(int cpu);\n\nconst struct clock_event_device *tick_get_wakeup_device(int cpu)\n{\n\treturn tick_get_oneshot_wakeup_device(cpu);\n}\n\n \nstatic void tick_broadcast_start_periodic(struct clock_event_device *bc)\n{\n\tif (bc)\n\t\ttick_setup_periodic(bc, 1);\n}\n\n \nstatic bool tick_check_broadcast_device(struct clock_event_device *curdev,\n\t\t\t\t\tstruct clock_event_device *newdev)\n{\n\tif ((newdev->features & CLOCK_EVT_FEAT_DUMMY) ||\n\t    (newdev->features & CLOCK_EVT_FEAT_PERCPU) ||\n\t    (newdev->features & CLOCK_EVT_FEAT_C3STOP))\n\t\treturn false;\n\n\tif (tick_broadcast_device.mode == TICKDEV_MODE_ONESHOT &&\n\t    !(newdev->features & CLOCK_EVT_FEAT_ONESHOT))\n\t\treturn false;\n\n\treturn !curdev || newdev->rating > curdev->rating;\n}\n\n#ifdef CONFIG_TICK_ONESHOT\nstatic struct clock_event_device *tick_get_oneshot_wakeup_device(int cpu)\n{\n\treturn per_cpu(tick_oneshot_wakeup_device, cpu);\n}\n\nstatic void tick_oneshot_wakeup_handler(struct clock_event_device *wd)\n{\n\t \n\ttick_receive_broadcast();\n}\n\nstatic bool tick_set_oneshot_wakeup_device(struct clock_event_device *newdev,\n\t\t\t\t\t   int cpu)\n{\n\tstruct clock_event_device *curdev = tick_get_oneshot_wakeup_device(cpu);\n\n\tif (!newdev)\n\t\tgoto set_device;\n\n\tif ((newdev->features & CLOCK_EVT_FEAT_DUMMY) ||\n\t    (newdev->features & CLOCK_EVT_FEAT_C3STOP))\n\t\t return false;\n\n\tif (!(newdev->features & CLOCK_EVT_FEAT_PERCPU) ||\n\t    !(newdev->features & CLOCK_EVT_FEAT_ONESHOT))\n\t\treturn false;\n\n\tif (!cpumask_equal(newdev->cpumask, cpumask_of(cpu)))\n\t\treturn false;\n\n\tif (curdev && newdev->rating <= curdev->rating)\n\t\treturn false;\n\n\tif (!try_module_get(newdev->owner))\n\t\treturn false;\n\n\tnewdev->event_handler = tick_oneshot_wakeup_handler;\nset_device:\n\tclockevents_exchange_device(curdev, newdev);\n\tper_cpu(tick_oneshot_wakeup_device, cpu) = newdev;\n\treturn true;\n}\n#else\nstatic struct clock_event_device *tick_get_oneshot_wakeup_device(int cpu)\n{\n\treturn NULL;\n}\n\nstatic bool tick_set_oneshot_wakeup_device(struct clock_event_device *newdev,\n\t\t\t\t\t   int cpu)\n{\n\treturn false;\n}\n#endif\n\n \nvoid tick_install_broadcast_device(struct clock_event_device *dev, int cpu)\n{\n\tstruct clock_event_device *cur = tick_broadcast_device.evtdev;\n\n\tif (tick_set_oneshot_wakeup_device(dev, cpu))\n\t\treturn;\n\n\tif (!tick_check_broadcast_device(cur, dev))\n\t\treturn;\n\n\tif (!try_module_get(dev->owner))\n\t\treturn;\n\n\tclockevents_exchange_device(cur, dev);\n\tif (cur)\n\t\tcur->event_handler = clockevents_handle_noop;\n\ttick_broadcast_device.evtdev = dev;\n\tif (!cpumask_empty(tick_broadcast_mask))\n\t\ttick_broadcast_start_periodic(dev);\n\n\tif (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))\n\t\treturn;\n\n\t \n\tif (tick_broadcast_oneshot_active()) {\n\t\ttick_broadcast_switch_to_oneshot();\n\t\treturn;\n\t}\n\n\t \n\ttick_clock_notify();\n}\n\n \nint tick_is_broadcast_device(struct clock_event_device *dev)\n{\n\treturn (dev && tick_broadcast_device.evtdev == dev);\n}\n\nint tick_broadcast_update_freq(struct clock_event_device *dev, u32 freq)\n{\n\tint ret = -ENODEV;\n\n\tif (tick_is_broadcast_device(dev)) {\n\t\traw_spin_lock(&tick_broadcast_lock);\n\t\tret = __clockevents_update_freq(dev, freq);\n\t\traw_spin_unlock(&tick_broadcast_lock);\n\t}\n\treturn ret;\n}\n\n\nstatic void err_broadcast(const struct cpumask *mask)\n{\n\tpr_crit_once(\"Failed to broadcast timer tick. Some CPUs may be unresponsive.\\n\");\n}\n\nstatic void tick_device_setup_broadcast_func(struct clock_event_device *dev)\n{\n\tif (!dev->broadcast)\n\t\tdev->broadcast = tick_broadcast;\n\tif (!dev->broadcast) {\n\t\tpr_warn_once(\"%s depends on broadcast, but no broadcast function available\\n\",\n\t\t\t     dev->name);\n\t\tdev->broadcast = err_broadcast;\n\t}\n}\n\n \nint tick_device_uses_broadcast(struct clock_event_device *dev, int cpu)\n{\n\tstruct clock_event_device *bc = tick_broadcast_device.evtdev;\n\tunsigned long flags;\n\tint ret = 0;\n\n\traw_spin_lock_irqsave(&tick_broadcast_lock, flags);\n\n\t \n\tif (!tick_device_is_functional(dev)) {\n\t\tdev->event_handler = tick_handle_periodic;\n\t\ttick_device_setup_broadcast_func(dev);\n\t\tcpumask_set_cpu(cpu, tick_broadcast_mask);\n\t\tif (tick_broadcast_device.mode == TICKDEV_MODE_PERIODIC)\n\t\t\ttick_broadcast_start_periodic(bc);\n\t\telse\n\t\t\ttick_broadcast_setup_oneshot(bc, false);\n\t\tret = 1;\n\t} else {\n\t\t \n\t\tif (!(dev->features & CLOCK_EVT_FEAT_C3STOP))\n\t\t\tcpumask_clear_cpu(cpu, tick_broadcast_mask);\n\t\telse\n\t\t\ttick_device_setup_broadcast_func(dev);\n\n\t\t \n\t\tif (!cpumask_test_cpu(cpu, tick_broadcast_on))\n\t\t\tcpumask_clear_cpu(cpu, tick_broadcast_mask);\n\n\t\tswitch (tick_broadcast_device.mode) {\n\t\tcase TICKDEV_MODE_ONESHOT:\n\t\t\t \n\t\t\ttick_broadcast_clear_oneshot(cpu);\n\t\t\tret = 0;\n\t\t\tbreak;\n\n\t\tcase TICKDEV_MODE_PERIODIC:\n\t\t\t \n\t\t\tif (cpumask_empty(tick_broadcast_mask) && bc)\n\t\t\t\tclockevents_shutdown(bc);\n\t\t\t \n\t\t\tif (bc && !(bc->features & CLOCK_EVT_FEAT_HRTIMER))\n\t\t\t\tret = cpumask_test_cpu(cpu, tick_broadcast_mask);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\traw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\n\treturn ret;\n}\n\nint tick_receive_broadcast(void)\n{\n\tstruct tick_device *td = this_cpu_ptr(&tick_cpu_device);\n\tstruct clock_event_device *evt = td->evtdev;\n\n\tif (!evt)\n\t\treturn -ENODEV;\n\n\tif (!evt->event_handler)\n\t\treturn -EINVAL;\n\n\tevt->event_handler(evt);\n\treturn 0;\n}\n\n \nstatic bool tick_do_broadcast(struct cpumask *mask)\n{\n\tint cpu = smp_processor_id();\n\tstruct tick_device *td;\n\tbool local = false;\n\n\t \n\tif (cpumask_test_cpu(cpu, mask)) {\n\t\tstruct clock_event_device *bc = tick_broadcast_device.evtdev;\n\n\t\tcpumask_clear_cpu(cpu, mask);\n\t\t \n\t\tlocal = !(bc->features & CLOCK_EVT_FEAT_HRTIMER);\n\t}\n\n\tif (!cpumask_empty(mask)) {\n\t\t \n\t\ttd = &per_cpu(tick_cpu_device, cpumask_first(mask));\n\t\ttd->evtdev->broadcast(mask);\n\t}\n\treturn local;\n}\n\n \nstatic bool tick_do_periodic_broadcast(void)\n{\n\tcpumask_and(tmpmask, cpu_online_mask, tick_broadcast_mask);\n\treturn tick_do_broadcast(tmpmask);\n}\n\n \nstatic void tick_handle_periodic_broadcast(struct clock_event_device *dev)\n{\n\tstruct tick_device *td = this_cpu_ptr(&tick_cpu_device);\n\tbool bc_local;\n\n\traw_spin_lock(&tick_broadcast_lock);\n\n\t \n\tif (clockevent_state_shutdown(tick_broadcast_device.evtdev)) {\n\t\traw_spin_unlock(&tick_broadcast_lock);\n\t\treturn;\n\t}\n\n\tbc_local = tick_do_periodic_broadcast();\n\n\tif (clockevent_state_oneshot(dev)) {\n\t\tktime_t next = ktime_add_ns(dev->next_event, TICK_NSEC);\n\n\t\tclockevents_program_event(dev, next, true);\n\t}\n\traw_spin_unlock(&tick_broadcast_lock);\n\n\t \n\tif (bc_local)\n\t\ttd->evtdev->event_handler(td->evtdev);\n}\n\n \nvoid tick_broadcast_control(enum tick_broadcast_mode mode)\n{\n\tstruct clock_event_device *bc, *dev;\n\tstruct tick_device *td;\n\tint cpu, bc_stopped;\n\tunsigned long flags;\n\n\t \n\traw_spin_lock_irqsave(&tick_broadcast_lock, flags);\n\ttd = this_cpu_ptr(&tick_cpu_device);\n\tdev = td->evtdev;\n\n\t \n\tif (!dev || !(dev->features & CLOCK_EVT_FEAT_C3STOP))\n\t\tgoto out;\n\n\tif (!tick_device_is_functional(dev))\n\t\tgoto out;\n\n\tcpu = smp_processor_id();\n\tbc = tick_broadcast_device.evtdev;\n\tbc_stopped = cpumask_empty(tick_broadcast_mask);\n\n\tswitch (mode) {\n\tcase TICK_BROADCAST_FORCE:\n\t\ttick_broadcast_forced = 1;\n\t\tfallthrough;\n\tcase TICK_BROADCAST_ON:\n\t\tcpumask_set_cpu(cpu, tick_broadcast_on);\n\t\tif (!cpumask_test_and_set_cpu(cpu, tick_broadcast_mask)) {\n\t\t\t \n\t\t\tif (bc && !(bc->features & CLOCK_EVT_FEAT_HRTIMER) &&\n\t\t\t    tick_broadcast_device.mode == TICKDEV_MODE_PERIODIC)\n\t\t\t\tclockevents_shutdown(dev);\n\t\t}\n\t\tbreak;\n\n\tcase TICK_BROADCAST_OFF:\n\t\tif (tick_broadcast_forced)\n\t\t\tbreak;\n\t\tcpumask_clear_cpu(cpu, tick_broadcast_on);\n\t\tif (cpumask_test_and_clear_cpu(cpu, tick_broadcast_mask)) {\n\t\t\tif (tick_broadcast_device.mode ==\n\t\t\t    TICKDEV_MODE_PERIODIC)\n\t\t\t\ttick_setup_periodic(dev, 0);\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (bc) {\n\t\tif (cpumask_empty(tick_broadcast_mask)) {\n\t\t\tif (!bc_stopped)\n\t\t\t\tclockevents_shutdown(bc);\n\t\t} else if (bc_stopped) {\n\t\t\tif (tick_broadcast_device.mode == TICKDEV_MODE_PERIODIC)\n\t\t\t\ttick_broadcast_start_periodic(bc);\n\t\t\telse\n\t\t\t\ttick_broadcast_setup_oneshot(bc, false);\n\t\t}\n\t}\nout:\n\traw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\n}\nEXPORT_SYMBOL_GPL(tick_broadcast_control);\n\n \nvoid tick_set_periodic_handler(struct clock_event_device *dev, int broadcast)\n{\n\tif (!broadcast)\n\t\tdev->event_handler = tick_handle_periodic;\n\telse\n\t\tdev->event_handler = tick_handle_periodic_broadcast;\n}\n\n#ifdef CONFIG_HOTPLUG_CPU\nstatic void tick_shutdown_broadcast(void)\n{\n\tstruct clock_event_device *bc = tick_broadcast_device.evtdev;\n\n\tif (tick_broadcast_device.mode == TICKDEV_MODE_PERIODIC) {\n\t\tif (bc && cpumask_empty(tick_broadcast_mask))\n\t\t\tclockevents_shutdown(bc);\n\t}\n}\n\n \nvoid tick_broadcast_offline(unsigned int cpu)\n{\n\traw_spin_lock(&tick_broadcast_lock);\n\tcpumask_clear_cpu(cpu, tick_broadcast_mask);\n\tcpumask_clear_cpu(cpu, tick_broadcast_on);\n\ttick_broadcast_oneshot_offline(cpu);\n\ttick_shutdown_broadcast();\n\traw_spin_unlock(&tick_broadcast_lock);\n}\n\n#endif\n\nvoid tick_suspend_broadcast(void)\n{\n\tstruct clock_event_device *bc;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&tick_broadcast_lock, flags);\n\n\tbc = tick_broadcast_device.evtdev;\n\tif (bc)\n\t\tclockevents_shutdown(bc);\n\n\traw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\n}\n\n \nbool tick_resume_check_broadcast(void)\n{\n\tif (tick_broadcast_device.mode == TICKDEV_MODE_ONESHOT)\n\t\treturn false;\n\telse\n\t\treturn cpumask_test_cpu(smp_processor_id(), tick_broadcast_mask);\n}\n\nvoid tick_resume_broadcast(void)\n{\n\tstruct clock_event_device *bc;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&tick_broadcast_lock, flags);\n\n\tbc = tick_broadcast_device.evtdev;\n\n\tif (bc) {\n\t\tclockevents_tick_resume(bc);\n\n\t\tswitch (tick_broadcast_device.mode) {\n\t\tcase TICKDEV_MODE_PERIODIC:\n\t\t\tif (!cpumask_empty(tick_broadcast_mask))\n\t\t\t\ttick_broadcast_start_periodic(bc);\n\t\t\tbreak;\n\t\tcase TICKDEV_MODE_ONESHOT:\n\t\t\tif (!cpumask_empty(tick_broadcast_mask))\n\t\t\t\ttick_resume_broadcast_oneshot(bc);\n\t\t\tbreak;\n\t\t}\n\t}\n\traw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\n}\n\n#ifdef CONFIG_TICK_ONESHOT\n\nstatic cpumask_var_t tick_broadcast_oneshot_mask __cpumask_var_read_mostly;\nstatic cpumask_var_t tick_broadcast_pending_mask __cpumask_var_read_mostly;\nstatic cpumask_var_t tick_broadcast_force_mask __cpumask_var_read_mostly;\n\n \nstruct cpumask *tick_get_broadcast_oneshot_mask(void)\n{\n\treturn tick_broadcast_oneshot_mask;\n}\n\n \nnoinstr int tick_check_broadcast_expired(void)\n{\n#ifdef _ASM_GENERIC_BITOPS_INSTRUMENTED_NON_ATOMIC_H\n\treturn arch_test_bit(smp_processor_id(), cpumask_bits(tick_broadcast_force_mask));\n#else\n\treturn cpumask_test_cpu(smp_processor_id(), tick_broadcast_force_mask);\n#endif\n}\n\n \nstatic void tick_broadcast_set_affinity(struct clock_event_device *bc,\n\t\t\t\t\tconst struct cpumask *cpumask)\n{\n\tif (!(bc->features & CLOCK_EVT_FEAT_DYNIRQ))\n\t\treturn;\n\n\tif (cpumask_equal(bc->cpumask, cpumask))\n\t\treturn;\n\n\tbc->cpumask = cpumask;\n\tirq_set_affinity(bc->irq, bc->cpumask);\n}\n\nstatic void tick_broadcast_set_event(struct clock_event_device *bc, int cpu,\n\t\t\t\t     ktime_t expires)\n{\n\tif (!clockevent_state_oneshot(bc))\n\t\tclockevents_switch_state(bc, CLOCK_EVT_STATE_ONESHOT);\n\n\tclockevents_program_event(bc, expires, 1);\n\ttick_broadcast_set_affinity(bc, cpumask_of(cpu));\n}\n\nstatic void tick_resume_broadcast_oneshot(struct clock_event_device *bc)\n{\n\tclockevents_switch_state(bc, CLOCK_EVT_STATE_ONESHOT);\n}\n\n \nvoid tick_check_oneshot_broadcast_this_cpu(void)\n{\n\tif (cpumask_test_cpu(smp_processor_id(), tick_broadcast_oneshot_mask)) {\n\t\tstruct tick_device *td = this_cpu_ptr(&tick_cpu_device);\n\n\t\t \n\t\tif (td->mode == TICKDEV_MODE_ONESHOT) {\n\t\t\tclockevents_switch_state(td->evtdev,\n\t\t\t\t\t      CLOCK_EVT_STATE_ONESHOT);\n\t\t}\n\t}\n}\n\n \nstatic void tick_handle_oneshot_broadcast(struct clock_event_device *dev)\n{\n\tstruct tick_device *td;\n\tktime_t now, next_event;\n\tint cpu, next_cpu = 0;\n\tbool bc_local;\n\n\traw_spin_lock(&tick_broadcast_lock);\n\tdev->next_event = KTIME_MAX;\n\tnext_event = KTIME_MAX;\n\tcpumask_clear(tmpmask);\n\tnow = ktime_get();\n\t \n\tfor_each_cpu(cpu, tick_broadcast_oneshot_mask) {\n\t\t \n\t\tif (!IS_ENABLED(CONFIG_SMP) &&\n\t\t    cpumask_empty(tick_broadcast_oneshot_mask))\n\t\t\tbreak;\n\n\t\ttd = &per_cpu(tick_cpu_device, cpu);\n\t\tif (td->evtdev->next_event <= now) {\n\t\t\tcpumask_set_cpu(cpu, tmpmask);\n\t\t\t \n\t\t\tcpumask_set_cpu(cpu, tick_broadcast_pending_mask);\n\t\t} else if (td->evtdev->next_event < next_event) {\n\t\t\tnext_event = td->evtdev->next_event;\n\t\t\tnext_cpu = cpu;\n\t\t}\n\t}\n\n\t \n\tcpumask_clear_cpu(smp_processor_id(), tick_broadcast_pending_mask);\n\n\t \n\tcpumask_or(tmpmask, tmpmask, tick_broadcast_force_mask);\n\tcpumask_clear(tick_broadcast_force_mask);\n\n\t \n\tif (WARN_ON_ONCE(!cpumask_subset(tmpmask, cpu_online_mask)))\n\t\tcpumask_and(tmpmask, tmpmask, cpu_online_mask);\n\n\t \n\tbc_local = tick_do_broadcast(tmpmask);\n\n\t \n\tif (next_event != KTIME_MAX)\n\t\ttick_broadcast_set_event(dev, next_cpu, next_event);\n\n\traw_spin_unlock(&tick_broadcast_lock);\n\n\tif (bc_local) {\n\t\ttd = this_cpu_ptr(&tick_cpu_device);\n\t\ttd->evtdev->event_handler(td->evtdev);\n\t}\n}\n\nstatic int broadcast_needs_cpu(struct clock_event_device *bc, int cpu)\n{\n\tif (!(bc->features & CLOCK_EVT_FEAT_HRTIMER))\n\t\treturn 0;\n\tif (bc->next_event == KTIME_MAX)\n\t\treturn 0;\n\treturn bc->bound_on == cpu ? -EBUSY : 0;\n}\n\nstatic void broadcast_shutdown_local(struct clock_event_device *bc,\n\t\t\t\t     struct clock_event_device *dev)\n{\n\t \n\tif (bc->features & CLOCK_EVT_FEAT_HRTIMER) {\n\t\tif (broadcast_needs_cpu(bc, smp_processor_id()))\n\t\t\treturn;\n\t\tif (dev->next_event < bc->next_event)\n\t\t\treturn;\n\t}\n\tclockevents_switch_state(dev, CLOCK_EVT_STATE_SHUTDOWN);\n}\n\nstatic int ___tick_broadcast_oneshot_control(enum tick_broadcast_state state,\n\t\t\t\t\t     struct tick_device *td,\n\t\t\t\t\t     int cpu)\n{\n\tstruct clock_event_device *bc, *dev = td->evtdev;\n\tint ret = 0;\n\tktime_t now;\n\n\traw_spin_lock(&tick_broadcast_lock);\n\tbc = tick_broadcast_device.evtdev;\n\n\tif (state == TICK_BROADCAST_ENTER) {\n\t\t \n\t\tret = broadcast_needs_cpu(bc, cpu);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\t \n\t\tif (tick_broadcast_device.mode == TICKDEV_MODE_PERIODIC) {\n\t\t\t \n\t\t\tif (bc->features & CLOCK_EVT_FEAT_HRTIMER)\n\t\t\t\tret = -EBUSY;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!cpumask_test_and_set_cpu(cpu, tick_broadcast_oneshot_mask)) {\n\t\t\tWARN_ON_ONCE(cpumask_test_cpu(cpu, tick_broadcast_pending_mask));\n\n\t\t\t \n\t\t\tbroadcast_shutdown_local(bc, dev);\n\n\t\t\t \n\t\t\tif (cpumask_test_cpu(cpu, tick_broadcast_force_mask)) {\n\t\t\t\tret = -EBUSY;\n\t\t\t} else if (dev->next_event < bc->next_event) {\n\t\t\t\ttick_broadcast_set_event(bc, cpu, dev->next_event);\n\t\t\t\t \n\t\t\t\tret = broadcast_needs_cpu(bc, cpu);\n\t\t\t\tif (ret) {\n\t\t\t\t\tcpumask_clear_cpu(cpu,\n\t\t\t\t\t\ttick_broadcast_oneshot_mask);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (cpumask_test_and_clear_cpu(cpu, tick_broadcast_oneshot_mask)) {\n\t\t\tclockevents_switch_state(dev, CLOCK_EVT_STATE_ONESHOT);\n\t\t\t \n\t\t\tif (cpumask_test_and_clear_cpu(cpu,\n\t\t\t\t       tick_broadcast_pending_mask))\n\t\t\t\tgoto out;\n\n\t\t\t \n\t\t\tif (dev->next_event == KTIME_MAX)\n\t\t\t\tgoto out;\n\t\t\t \n\t\t\tnow = ktime_get();\n\t\t\tif (dev->next_event <= now) {\n\t\t\t\tcpumask_set_cpu(cpu, tick_broadcast_force_mask);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\t \n\t\t\ttick_program_event(dev->next_event, 1);\n\t\t}\n\t}\nout:\n\traw_spin_unlock(&tick_broadcast_lock);\n\treturn ret;\n}\n\nstatic int tick_oneshot_wakeup_control(enum tick_broadcast_state state,\n\t\t\t\t       struct tick_device *td,\n\t\t\t\t       int cpu)\n{\n\tstruct clock_event_device *dev, *wd;\n\n\tdev = td->evtdev;\n\tif (td->mode != TICKDEV_MODE_ONESHOT)\n\t\treturn -EINVAL;\n\n\twd = tick_get_oneshot_wakeup_device(cpu);\n\tif (!wd)\n\t\treturn -ENODEV;\n\n\tswitch (state) {\n\tcase TICK_BROADCAST_ENTER:\n\t\tclockevents_switch_state(dev, CLOCK_EVT_STATE_ONESHOT_STOPPED);\n\t\tclockevents_switch_state(wd, CLOCK_EVT_STATE_ONESHOT);\n\t\tclockevents_program_event(wd, dev->next_event, 1);\n\t\tbreak;\n\tcase TICK_BROADCAST_EXIT:\n\t\t \n\t\tif (clockevent_get_state(wd) != CLOCK_EVT_STATE_ONESHOT)\n\t\t\treturn -ENODEV;\n\t}\n\n\treturn 0;\n}\n\nint __tick_broadcast_oneshot_control(enum tick_broadcast_state state)\n{\n\tstruct tick_device *td = this_cpu_ptr(&tick_cpu_device);\n\tint cpu = smp_processor_id();\n\n\tif (!tick_oneshot_wakeup_control(state, td, cpu))\n\t\treturn 0;\n\n\tif (tick_broadcast_device.evtdev)\n\t\treturn ___tick_broadcast_oneshot_control(state, td, cpu);\n\n\t \n\treturn -EBUSY;\n}\n\n \nstatic void tick_broadcast_clear_oneshot(int cpu)\n{\n\tcpumask_clear_cpu(cpu, tick_broadcast_oneshot_mask);\n\tcpumask_clear_cpu(cpu, tick_broadcast_pending_mask);\n}\n\nstatic void tick_broadcast_init_next_event(struct cpumask *mask,\n\t\t\t\t\t   ktime_t expires)\n{\n\tstruct tick_device *td;\n\tint cpu;\n\n\tfor_each_cpu(cpu, mask) {\n\t\ttd = &per_cpu(tick_cpu_device, cpu);\n\t\tif (td->evtdev)\n\t\t\ttd->evtdev->next_event = expires;\n\t}\n}\n\nstatic inline ktime_t tick_get_next_period(void)\n{\n\tktime_t next;\n\n\t \n\traw_spin_lock(&jiffies_lock);\n\tnext = tick_next_period;\n\traw_spin_unlock(&jiffies_lock);\n\treturn next;\n}\n\n \nstatic void tick_broadcast_setup_oneshot(struct clock_event_device *bc,\n\t\t\t\t\t bool from_periodic)\n{\n\tint cpu = smp_processor_id();\n\tktime_t nexttick = 0;\n\n\tif (!bc)\n\t\treturn;\n\n\t \n\tif (bc->event_handler == tick_handle_oneshot_broadcast) {\n\t\t \n\t\ttick_broadcast_clear_oneshot(cpu);\n\t\treturn;\n\t}\n\n\n\tbc->event_handler = tick_handle_oneshot_broadcast;\n\tbc->next_event = KTIME_MAX;\n\n\t \n\tif (from_periodic) {\n\t\tcpumask_copy(tmpmask, tick_broadcast_mask);\n\t\t \n\t\tcpumask_clear_cpu(cpu, tmpmask);\n\t\tcpumask_or(tick_broadcast_oneshot_mask, tick_broadcast_oneshot_mask, tmpmask);\n\n\t\t \n\t\tnexttick = tick_get_next_period();\n\t\ttick_broadcast_init_next_event(tmpmask, nexttick);\n\n\t\t \n\t\tif (clockevent_state_oneshot(bc))\n\t\t\treturn;\n\t}\n\n\t \n\tif (!cpumask_empty(tick_broadcast_oneshot_mask))\n\t\ttick_broadcast_set_event(bc, cpu, nexttick);\n}\n\n \nvoid tick_broadcast_switch_to_oneshot(void)\n{\n\tstruct clock_event_device *bc;\n\tenum tick_device_mode oldmode;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&tick_broadcast_lock, flags);\n\n\toldmode = tick_broadcast_device.mode;\n\ttick_broadcast_device.mode = TICKDEV_MODE_ONESHOT;\n\tbc = tick_broadcast_device.evtdev;\n\tif (bc)\n\t\ttick_broadcast_setup_oneshot(bc, oldmode == TICKDEV_MODE_PERIODIC);\n\n\traw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\n}\n\n#ifdef CONFIG_HOTPLUG_CPU\nvoid hotplug_cpu__broadcast_tick_pull(int deadcpu)\n{\n\tstruct clock_event_device *bc;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&tick_broadcast_lock, flags);\n\tbc = tick_broadcast_device.evtdev;\n\n\tif (bc && broadcast_needs_cpu(bc, deadcpu)) {\n\t\t \n\t\tclockevents_program_event(bc, bc->next_event, 1);\n\t}\n\traw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\n}\n\n \nstatic void tick_broadcast_oneshot_offline(unsigned int cpu)\n{\n\tif (tick_get_oneshot_wakeup_device(cpu))\n\t\ttick_set_oneshot_wakeup_device(NULL, cpu);\n\n\t \n\tcpumask_clear_cpu(cpu, tick_broadcast_oneshot_mask);\n\tcpumask_clear_cpu(cpu, tick_broadcast_pending_mask);\n\tcpumask_clear_cpu(cpu, tick_broadcast_force_mask);\n}\n#endif\n\n \nint tick_broadcast_oneshot_active(void)\n{\n\treturn tick_broadcast_device.mode == TICKDEV_MODE_ONESHOT;\n}\n\n \nbool tick_broadcast_oneshot_available(void)\n{\n\tstruct clock_event_device *bc = tick_broadcast_device.evtdev;\n\n\treturn bc ? bc->features & CLOCK_EVT_FEAT_ONESHOT : false;\n}\n\n#else\nint __tick_broadcast_oneshot_control(enum tick_broadcast_state state)\n{\n\tstruct clock_event_device *bc = tick_broadcast_device.evtdev;\n\n\tif (!bc || (bc->features & CLOCK_EVT_FEAT_HRTIMER))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n#endif\n\nvoid __init tick_broadcast_init(void)\n{\n\tzalloc_cpumask_var(&tick_broadcast_mask, GFP_NOWAIT);\n\tzalloc_cpumask_var(&tick_broadcast_on, GFP_NOWAIT);\n\tzalloc_cpumask_var(&tmpmask, GFP_NOWAIT);\n#ifdef CONFIG_TICK_ONESHOT\n\tzalloc_cpumask_var(&tick_broadcast_oneshot_mask, GFP_NOWAIT);\n\tzalloc_cpumask_var(&tick_broadcast_pending_mask, GFP_NOWAIT);\n\tzalloc_cpumask_var(&tick_broadcast_force_mask, GFP_NOWAIT);\n#endif\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}