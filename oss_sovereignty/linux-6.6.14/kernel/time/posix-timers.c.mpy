{
  "module_name": "posix-timers.c",
  "hash_id": "29a853113a4ee4da763296c28f59cca6f6c3503317c39bbcb0ffd65ed64570dc",
  "original_prompt": "Ingested from linux-6.6.14/kernel/time/posix-timers.c",
  "human_readable_source": "\n \n#include <linux/mm.h>\n#include <linux/interrupt.h>\n#include <linux/slab.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/sched/task.h>\n\n#include <linux/uaccess.h>\n#include <linux/list.h>\n#include <linux/init.h>\n#include <linux/compiler.h>\n#include <linux/hash.h>\n#include <linux/posix-clock.h>\n#include <linux/posix-timers.h>\n#include <linux/syscalls.h>\n#include <linux/wait.h>\n#include <linux/workqueue.h>\n#include <linux/export.h>\n#include <linux/hashtable.h>\n#include <linux/compat.h>\n#include <linux/nospec.h>\n#include <linux/time_namespace.h>\n\n#include \"timekeeping.h\"\n#include \"posix-timers.h\"\n\nstatic struct kmem_cache *posix_timers_cache;\n\n \nstatic DEFINE_HASHTABLE(posix_timers_hashtable, 9);\nstatic DEFINE_SPINLOCK(hash_lock);\n\nstatic const struct k_clock * const posix_clocks[];\nstatic const struct k_clock *clockid_to_kclock(const clockid_t id);\nstatic const struct k_clock clock_realtime, clock_monotonic;\n\n \n#if SIGEV_THREAD_ID != (SIGEV_THREAD_ID & \\\n\t\t\t~(SIGEV_SIGNAL | SIGEV_NONE | SIGEV_THREAD))\n#error \"SIGEV_THREAD_ID must not share bit with other SIGEV values!\"\n#endif\n\nstatic struct k_itimer *__lock_timer(timer_t timer_id, unsigned long *flags);\n\n#define lock_timer(tid, flags)\t\t\t\t\t\t   \\\n({\tstruct k_itimer *__timr;\t\t\t\t\t   \\\n\t__cond_lock(&__timr->it_lock, __timr = __lock_timer(tid, flags));  \\\n\t__timr;\t\t\t\t\t\t\t\t   \\\n})\n\nstatic int hash(struct signal_struct *sig, unsigned int nr)\n{\n\treturn hash_32(hash32_ptr(sig) ^ nr, HASH_BITS(posix_timers_hashtable));\n}\n\nstatic struct k_itimer *__posix_timers_find(struct hlist_head *head,\n\t\t\t\t\t    struct signal_struct *sig,\n\t\t\t\t\t    timer_t id)\n{\n\tstruct k_itimer *timer;\n\n\thlist_for_each_entry_rcu(timer, head, t_hash, lockdep_is_held(&hash_lock)) {\n\t\t \n\t\tif ((READ_ONCE(timer->it_signal) == sig) && (timer->it_id == id))\n\t\t\treturn timer;\n\t}\n\treturn NULL;\n}\n\nstatic struct k_itimer *posix_timer_by_id(timer_t id)\n{\n\tstruct signal_struct *sig = current->signal;\n\tstruct hlist_head *head = &posix_timers_hashtable[hash(sig, id)];\n\n\treturn __posix_timers_find(head, sig, id);\n}\n\nstatic int posix_timer_add(struct k_itimer *timer)\n{\n\tstruct signal_struct *sig = current->signal;\n\tstruct hlist_head *head;\n\tunsigned int cnt, id;\n\n\t \n\tfor (cnt = 0; cnt <= INT_MAX; cnt++) {\n\t\tspin_lock(&hash_lock);\n\t\tid = sig->next_posix_timer_id;\n\n\t\t \n\t\tsig->next_posix_timer_id = (id + 1) & INT_MAX;\n\n\t\thead = &posix_timers_hashtable[hash(sig, id)];\n\t\tif (!__posix_timers_find(head, sig, id)) {\n\t\t\thlist_add_head_rcu(&timer->t_hash, head);\n\t\t\tspin_unlock(&hash_lock);\n\t\t\treturn id;\n\t\t}\n\t\tspin_unlock(&hash_lock);\n\t}\n\t \n\treturn -EAGAIN;\n}\n\nstatic inline void unlock_timer(struct k_itimer *timr, unsigned long flags)\n{\n\tspin_unlock_irqrestore(&timr->it_lock, flags);\n}\n\nstatic int posix_get_realtime_timespec(clockid_t which_clock, struct timespec64 *tp)\n{\n\tktime_get_real_ts64(tp);\n\treturn 0;\n}\n\nstatic ktime_t posix_get_realtime_ktime(clockid_t which_clock)\n{\n\treturn ktime_get_real();\n}\n\nstatic int posix_clock_realtime_set(const clockid_t which_clock,\n\t\t\t\t    const struct timespec64 *tp)\n{\n\treturn do_sys_settimeofday64(tp, NULL);\n}\n\nstatic int posix_clock_realtime_adj(const clockid_t which_clock,\n\t\t\t\t    struct __kernel_timex *t)\n{\n\treturn do_adjtimex(t);\n}\n\nstatic int posix_get_monotonic_timespec(clockid_t which_clock, struct timespec64 *tp)\n{\n\tktime_get_ts64(tp);\n\ttimens_add_monotonic(tp);\n\treturn 0;\n}\n\nstatic ktime_t posix_get_monotonic_ktime(clockid_t which_clock)\n{\n\treturn ktime_get();\n}\n\nstatic int posix_get_monotonic_raw(clockid_t which_clock, struct timespec64 *tp)\n{\n\tktime_get_raw_ts64(tp);\n\ttimens_add_monotonic(tp);\n\treturn 0;\n}\n\nstatic int posix_get_realtime_coarse(clockid_t which_clock, struct timespec64 *tp)\n{\n\tktime_get_coarse_real_ts64(tp);\n\treturn 0;\n}\n\nstatic int posix_get_monotonic_coarse(clockid_t which_clock,\n\t\t\t\t\t\tstruct timespec64 *tp)\n{\n\tktime_get_coarse_ts64(tp);\n\ttimens_add_monotonic(tp);\n\treturn 0;\n}\n\nstatic int posix_get_coarse_res(const clockid_t which_clock, struct timespec64 *tp)\n{\n\t*tp = ktime_to_timespec64(KTIME_LOW_RES);\n\treturn 0;\n}\n\nstatic int posix_get_boottime_timespec(const clockid_t which_clock, struct timespec64 *tp)\n{\n\tktime_get_boottime_ts64(tp);\n\ttimens_add_boottime(tp);\n\treturn 0;\n}\n\nstatic ktime_t posix_get_boottime_ktime(const clockid_t which_clock)\n{\n\treturn ktime_get_boottime();\n}\n\nstatic int posix_get_tai_timespec(clockid_t which_clock, struct timespec64 *tp)\n{\n\tktime_get_clocktai_ts64(tp);\n\treturn 0;\n}\n\nstatic ktime_t posix_get_tai_ktime(clockid_t which_clock)\n{\n\treturn ktime_get_clocktai();\n}\n\nstatic int posix_get_hrtimer_res(clockid_t which_clock, struct timespec64 *tp)\n{\n\ttp->tv_sec = 0;\n\ttp->tv_nsec = hrtimer_resolution;\n\treturn 0;\n}\n\nstatic __init int init_posix_timers(void)\n{\n\tposix_timers_cache = kmem_cache_create(\"posix_timers_cache\",\n\t\t\t\t\tsizeof(struct k_itimer), 0,\n\t\t\t\t\tSLAB_PANIC | SLAB_ACCOUNT, NULL);\n\treturn 0;\n}\n__initcall(init_posix_timers);\n\n \nstatic inline int timer_overrun_to_int(struct k_itimer *timr, int baseval)\n{\n\ts64 sum = timr->it_overrun_last + (s64)baseval;\n\n\treturn sum > (s64)INT_MAX ? INT_MAX : (int)sum;\n}\n\nstatic void common_hrtimer_rearm(struct k_itimer *timr)\n{\n\tstruct hrtimer *timer = &timr->it.real.timer;\n\n\ttimr->it_overrun += hrtimer_forward(timer, timer->base->get_time(),\n\t\t\t\t\t    timr->it_interval);\n\thrtimer_restart(timer);\n}\n\n \nvoid posixtimer_rearm(struct kernel_siginfo *info)\n{\n\tstruct k_itimer *timr;\n\tunsigned long flags;\n\n\ttimr = lock_timer(info->si_tid, &flags);\n\tif (!timr)\n\t\treturn;\n\n\tif (timr->it_interval && timr->it_requeue_pending == info->si_sys_private) {\n\t\ttimr->kclock->timer_rearm(timr);\n\n\t\ttimr->it_active = 1;\n\t\ttimr->it_overrun_last = timr->it_overrun;\n\t\ttimr->it_overrun = -1LL;\n\t\t++timr->it_requeue_pending;\n\n\t\tinfo->si_overrun = timer_overrun_to_int(timr, info->si_overrun);\n\t}\n\n\tunlock_timer(timr, flags);\n}\n\nint posix_timer_event(struct k_itimer *timr, int si_private)\n{\n\tenum pid_type type;\n\tint ret;\n\t \n\ttimr->sigq->info.si_sys_private = si_private;\n\n\ttype = !(timr->it_sigev_notify & SIGEV_THREAD_ID) ? PIDTYPE_TGID : PIDTYPE_PID;\n\tret = send_sigqueue(timr->sigq, timr->it_pid, type);\n\t \n\treturn ret > 0;\n}\n\n \nstatic enum hrtimer_restart posix_timer_fn(struct hrtimer *timer)\n{\n\tenum hrtimer_restart ret = HRTIMER_NORESTART;\n\tstruct k_itimer *timr;\n\tunsigned long flags;\n\tint si_private = 0;\n\n\ttimr = container_of(timer, struct k_itimer, it.real.timer);\n\tspin_lock_irqsave(&timr->it_lock, flags);\n\n\ttimr->it_active = 0;\n\tif (timr->it_interval != 0)\n\t\tsi_private = ++timr->it_requeue_pending;\n\n\tif (posix_timer_event(timr, si_private)) {\n\t\t \n\t\tif (timr->it_interval != 0) {\n\t\t\tktime_t now = hrtimer_cb_get_time(timer);\n\n\t\t\t \n\t\t\tif (IS_ENABLED(CONFIG_HIGH_RES_TIMERS)) {\n\t\t\t\tktime_t kj = TICK_NSEC;\n\n\t\t\t\tif (timr->it_interval < kj)\n\t\t\t\t\tnow = ktime_add(now, kj);\n\t\t\t}\n\n\t\t\ttimr->it_overrun += hrtimer_forward(timer, now, timr->it_interval);\n\t\t\tret = HRTIMER_RESTART;\n\t\t\t++timr->it_requeue_pending;\n\t\t\ttimr->it_active = 1;\n\t\t}\n\t}\n\n\tunlock_timer(timr, flags);\n\treturn ret;\n}\n\nstatic struct pid *good_sigevent(sigevent_t * event)\n{\n\tstruct pid *pid = task_tgid(current);\n\tstruct task_struct *rtn;\n\n\tswitch (event->sigev_notify) {\n\tcase SIGEV_SIGNAL | SIGEV_THREAD_ID:\n\t\tpid = find_vpid(event->sigev_notify_thread_id);\n\t\trtn = pid_task(pid, PIDTYPE_PID);\n\t\tif (!rtn || !same_thread_group(rtn, current))\n\t\t\treturn NULL;\n\t\tfallthrough;\n\tcase SIGEV_SIGNAL:\n\tcase SIGEV_THREAD:\n\t\tif (event->sigev_signo <= 0 || event->sigev_signo > SIGRTMAX)\n\t\t\treturn NULL;\n\t\tfallthrough;\n\tcase SIGEV_NONE:\n\t\treturn pid;\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic struct k_itimer * alloc_posix_timer(void)\n{\n\tstruct k_itimer *tmr = kmem_cache_zalloc(posix_timers_cache, GFP_KERNEL);\n\n\tif (!tmr)\n\t\treturn tmr;\n\tif (unlikely(!(tmr->sigq = sigqueue_alloc()))) {\n\t\tkmem_cache_free(posix_timers_cache, tmr);\n\t\treturn NULL;\n\t}\n\tclear_siginfo(&tmr->sigq->info);\n\treturn tmr;\n}\n\nstatic void k_itimer_rcu_free(struct rcu_head *head)\n{\n\tstruct k_itimer *tmr = container_of(head, struct k_itimer, rcu);\n\n\tkmem_cache_free(posix_timers_cache, tmr);\n}\n\nstatic void posix_timer_free(struct k_itimer *tmr)\n{\n\tput_pid(tmr->it_pid);\n\tsigqueue_free(tmr->sigq);\n\tcall_rcu(&tmr->rcu, k_itimer_rcu_free);\n}\n\nstatic void posix_timer_unhash_and_free(struct k_itimer *tmr)\n{\n\tspin_lock(&hash_lock);\n\thlist_del_rcu(&tmr->t_hash);\n\tspin_unlock(&hash_lock);\n\tposix_timer_free(tmr);\n}\n\nstatic int common_timer_create(struct k_itimer *new_timer)\n{\n\thrtimer_init(&new_timer->it.real.timer, new_timer->it_clock, 0);\n\treturn 0;\n}\n\n \nstatic int do_timer_create(clockid_t which_clock, struct sigevent *event,\n\t\t\t   timer_t __user *created_timer_id)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\tstruct k_itimer *new_timer;\n\tint error, new_timer_id;\n\n\tif (!kc)\n\t\treturn -EINVAL;\n\tif (!kc->timer_create)\n\t\treturn -EOPNOTSUPP;\n\n\tnew_timer = alloc_posix_timer();\n\tif (unlikely(!new_timer))\n\t\treturn -EAGAIN;\n\n\tspin_lock_init(&new_timer->it_lock);\n\n\t \n\tnew_timer_id = posix_timer_add(new_timer);\n\tif (new_timer_id < 0) {\n\t\tposix_timer_free(new_timer);\n\t\treturn new_timer_id;\n\t}\n\n\tnew_timer->it_id = (timer_t) new_timer_id;\n\tnew_timer->it_clock = which_clock;\n\tnew_timer->kclock = kc;\n\tnew_timer->it_overrun = -1LL;\n\n\tif (event) {\n\t\trcu_read_lock();\n\t\tnew_timer->it_pid = get_pid(good_sigevent(event));\n\t\trcu_read_unlock();\n\t\tif (!new_timer->it_pid) {\n\t\t\terror = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tnew_timer->it_sigev_notify     = event->sigev_notify;\n\t\tnew_timer->sigq->info.si_signo = event->sigev_signo;\n\t\tnew_timer->sigq->info.si_value = event->sigev_value;\n\t} else {\n\t\tnew_timer->it_sigev_notify     = SIGEV_SIGNAL;\n\t\tnew_timer->sigq->info.si_signo = SIGALRM;\n\t\tmemset(&new_timer->sigq->info.si_value, 0, sizeof(sigval_t));\n\t\tnew_timer->sigq->info.si_value.sival_int = new_timer->it_id;\n\t\tnew_timer->it_pid = get_pid(task_tgid(current));\n\t}\n\n\tnew_timer->sigq->info.si_tid   = new_timer->it_id;\n\tnew_timer->sigq->info.si_code  = SI_TIMER;\n\n\tif (copy_to_user(created_timer_id, &new_timer_id, sizeof (new_timer_id))) {\n\t\terror = -EFAULT;\n\t\tgoto out;\n\t}\n\t \n\terror = kc->timer_create(new_timer);\n\tif (error)\n\t\tgoto out;\n\n\tspin_lock_irq(&current->sighand->siglock);\n\t \n\tWRITE_ONCE(new_timer->it_signal, current->signal);\n\tlist_add(&new_timer->list, &current->signal->posix_timers);\n\tspin_unlock_irq(&current->sighand->siglock);\n\t \n\treturn 0;\nout:\n\tposix_timer_unhash_and_free(new_timer);\n\treturn error;\n}\n\nSYSCALL_DEFINE3(timer_create, const clockid_t, which_clock,\n\t\tstruct sigevent __user *, timer_event_spec,\n\t\ttimer_t __user *, created_timer_id)\n{\n\tif (timer_event_spec) {\n\t\tsigevent_t event;\n\n\t\tif (copy_from_user(&event, timer_event_spec, sizeof (event)))\n\t\t\treturn -EFAULT;\n\t\treturn do_timer_create(which_clock, &event, created_timer_id);\n\t}\n\treturn do_timer_create(which_clock, NULL, created_timer_id);\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE3(timer_create, clockid_t, which_clock,\n\t\t       struct compat_sigevent __user *, timer_event_spec,\n\t\t       timer_t __user *, created_timer_id)\n{\n\tif (timer_event_spec) {\n\t\tsigevent_t event;\n\n\t\tif (get_compat_sigevent(&event, timer_event_spec))\n\t\t\treturn -EFAULT;\n\t\treturn do_timer_create(which_clock, &event, created_timer_id);\n\t}\n\treturn do_timer_create(which_clock, NULL, created_timer_id);\n}\n#endif\n\nstatic struct k_itimer *__lock_timer(timer_t timer_id, unsigned long *flags)\n{\n\tstruct k_itimer *timr;\n\n\t \n\tif ((unsigned long long)timer_id > INT_MAX)\n\t\treturn NULL;\n\n\t \n\trcu_read_lock();\n\ttimr = posix_timer_by_id(timer_id);\n\tif (timr) {\n\t\tspin_lock_irqsave(&timr->it_lock, *flags);\n\t\t \n\t\tif (timr->it_signal == current->signal) {\n\t\t\trcu_read_unlock();\n\t\t\treturn timr;\n\t\t}\n\t\tspin_unlock_irqrestore(&timr->it_lock, *flags);\n\t}\n\trcu_read_unlock();\n\n\treturn NULL;\n}\n\nstatic ktime_t common_hrtimer_remaining(struct k_itimer *timr, ktime_t now)\n{\n\tstruct hrtimer *timer = &timr->it.real.timer;\n\n\treturn __hrtimer_expires_remaining_adjusted(timer, now);\n}\n\nstatic s64 common_hrtimer_forward(struct k_itimer *timr, ktime_t now)\n{\n\tstruct hrtimer *timer = &timr->it.real.timer;\n\n\treturn hrtimer_forward(timer, now, timr->it_interval);\n}\n\n \nvoid common_timer_get(struct k_itimer *timr, struct itimerspec64 *cur_setting)\n{\n\tconst struct k_clock *kc = timr->kclock;\n\tktime_t now, remaining, iv;\n\tbool sig_none;\n\n\tsig_none = timr->it_sigev_notify == SIGEV_NONE;\n\tiv = timr->it_interval;\n\n\t \n\tif (iv) {\n\t\tcur_setting->it_interval = ktime_to_timespec64(iv);\n\t} else if (!timr->it_active) {\n\t\t \n\t\tif (!sig_none)\n\t\t\treturn;\n\t}\n\n\tnow = kc->clock_get_ktime(timr->it_clock);\n\n\t \n\tif (iv && (timr->it_requeue_pending & REQUEUE_PENDING || sig_none))\n\t\ttimr->it_overrun += kc->timer_forward(timr, now);\n\n\tremaining = kc->timer_remaining(timr, now);\n\t \n\tif (remaining <= 0) {\n\t\t \n\t\tif (!sig_none)\n\t\t\tcur_setting->it_value.tv_nsec = 1;\n\t} else {\n\t\tcur_setting->it_value = ktime_to_timespec64(remaining);\n\t}\n}\n\nstatic int do_timer_gettime(timer_t timer_id,  struct itimerspec64 *setting)\n{\n\tconst struct k_clock *kc;\n\tstruct k_itimer *timr;\n\tunsigned long flags;\n\tint ret = 0;\n\n\ttimr = lock_timer(timer_id, &flags);\n\tif (!timr)\n\t\treturn -EINVAL;\n\n\tmemset(setting, 0, sizeof(*setting));\n\tkc = timr->kclock;\n\tif (WARN_ON_ONCE(!kc || !kc->timer_get))\n\t\tret = -EINVAL;\n\telse\n\t\tkc->timer_get(timr, setting);\n\n\tunlock_timer(timr, flags);\n\treturn ret;\n}\n\n \nSYSCALL_DEFINE2(timer_gettime, timer_t, timer_id,\n\t\tstruct __kernel_itimerspec __user *, setting)\n{\n\tstruct itimerspec64 cur_setting;\n\n\tint ret = do_timer_gettime(timer_id, &cur_setting);\n\tif (!ret) {\n\t\tif (put_itimerspec64(&cur_setting, setting))\n\t\t\tret = -EFAULT;\n\t}\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT_32BIT_TIME\n\nSYSCALL_DEFINE2(timer_gettime32, timer_t, timer_id,\n\t\tstruct old_itimerspec32 __user *, setting)\n{\n\tstruct itimerspec64 cur_setting;\n\n\tint ret = do_timer_gettime(timer_id, &cur_setting);\n\tif (!ret) {\n\t\tif (put_old_itimerspec32(&cur_setting, setting))\n\t\t\tret = -EFAULT;\n\t}\n\treturn ret;\n}\n\n#endif\n\n \nSYSCALL_DEFINE1(timer_getoverrun, timer_t, timer_id)\n{\n\tstruct k_itimer *timr;\n\tunsigned long flags;\n\tint overrun;\n\n\ttimr = lock_timer(timer_id, &flags);\n\tif (!timr)\n\t\treturn -EINVAL;\n\n\toverrun = timer_overrun_to_int(timr, 0);\n\tunlock_timer(timr, flags);\n\n\treturn overrun;\n}\n\nstatic void common_hrtimer_arm(struct k_itimer *timr, ktime_t expires,\n\t\t\t       bool absolute, bool sigev_none)\n{\n\tstruct hrtimer *timer = &timr->it.real.timer;\n\tenum hrtimer_mode mode;\n\n\tmode = absolute ? HRTIMER_MODE_ABS : HRTIMER_MODE_REL;\n\t \n\tif (timr->it_clock == CLOCK_REALTIME)\n\t\ttimr->kclock = absolute ? &clock_realtime : &clock_monotonic;\n\n\thrtimer_init(&timr->it.real.timer, timr->it_clock, mode);\n\ttimr->it.real.timer.function = posix_timer_fn;\n\n\tif (!absolute)\n\t\texpires = ktime_add_safe(expires, timer->base->get_time());\n\thrtimer_set_expires(timer, expires);\n\n\tif (!sigev_none)\n\t\thrtimer_start_expires(timer, HRTIMER_MODE_ABS);\n}\n\nstatic int common_hrtimer_try_to_cancel(struct k_itimer *timr)\n{\n\treturn hrtimer_try_to_cancel(&timr->it.real.timer);\n}\n\nstatic void common_timer_wait_running(struct k_itimer *timer)\n{\n\thrtimer_cancel_wait_running(&timer->it.real.timer);\n}\n\n \nstatic struct k_itimer *timer_wait_running(struct k_itimer *timer,\n\t\t\t\t\t   unsigned long *flags)\n{\n\tconst struct k_clock *kc = READ_ONCE(timer->kclock);\n\ttimer_t timer_id = READ_ONCE(timer->it_id);\n\n\t \n\trcu_read_lock();\n\tunlock_timer(timer, *flags);\n\n\t \n\tif (!WARN_ON_ONCE(!kc->timer_wait_running))\n\t\tkc->timer_wait_running(timer);\n\n\trcu_read_unlock();\n\t \n\treturn lock_timer(timer_id, flags);\n}\n\n \nint common_timer_set(struct k_itimer *timr, int flags,\n\t\t     struct itimerspec64 *new_setting,\n\t\t     struct itimerspec64 *old_setting)\n{\n\tconst struct k_clock *kc = timr->kclock;\n\tbool sigev_none;\n\tktime_t expires;\n\n\tif (old_setting)\n\t\tcommon_timer_get(timr, old_setting);\n\n\t \n\ttimr->it_interval = 0;\n\t \n\tif (kc->timer_try_to_cancel(timr) < 0)\n\t\treturn TIMER_RETRY;\n\n\ttimr->it_active = 0;\n\ttimr->it_requeue_pending = (timr->it_requeue_pending + 2) &\n\t\t~REQUEUE_PENDING;\n\ttimr->it_overrun_last = 0;\n\n\t \n\tif (!new_setting->it_value.tv_sec && !new_setting->it_value.tv_nsec)\n\t\treturn 0;\n\n\ttimr->it_interval = timespec64_to_ktime(new_setting->it_interval);\n\texpires = timespec64_to_ktime(new_setting->it_value);\n\tif (flags & TIMER_ABSTIME)\n\t\texpires = timens_ktime_to_host(timr->it_clock, expires);\n\tsigev_none = timr->it_sigev_notify == SIGEV_NONE;\n\n\tkc->timer_arm(timr, expires, flags & TIMER_ABSTIME, sigev_none);\n\ttimr->it_active = !sigev_none;\n\treturn 0;\n}\n\nstatic int do_timer_settime(timer_t timer_id, int tmr_flags,\n\t\t\t    struct itimerspec64 *new_spec64,\n\t\t\t    struct itimerspec64 *old_spec64)\n{\n\tconst struct k_clock *kc;\n\tstruct k_itimer *timr;\n\tunsigned long flags;\n\tint error = 0;\n\n\tif (!timespec64_valid(&new_spec64->it_interval) ||\n\t    !timespec64_valid(&new_spec64->it_value))\n\t\treturn -EINVAL;\n\n\tif (old_spec64)\n\t\tmemset(old_spec64, 0, sizeof(*old_spec64));\n\n\ttimr = lock_timer(timer_id, &flags);\nretry:\n\tif (!timr)\n\t\treturn -EINVAL;\n\n\tkc = timr->kclock;\n\tif (WARN_ON_ONCE(!kc || !kc->timer_set))\n\t\terror = -EINVAL;\n\telse\n\t\terror = kc->timer_set(timr, tmr_flags, new_spec64, old_spec64);\n\n\tif (error == TIMER_RETRY) {\n\t\t \n\t\told_spec64 = NULL;\n\t\t \n\t\ttimr = timer_wait_running(timr, &flags);\n\t\tgoto retry;\n\t}\n\tunlock_timer(timr, flags);\n\n\treturn error;\n}\n\n \nSYSCALL_DEFINE4(timer_settime, timer_t, timer_id, int, flags,\n\t\tconst struct __kernel_itimerspec __user *, new_setting,\n\t\tstruct __kernel_itimerspec __user *, old_setting)\n{\n\tstruct itimerspec64 new_spec, old_spec, *rtn;\n\tint error = 0;\n\n\tif (!new_setting)\n\t\treturn -EINVAL;\n\n\tif (get_itimerspec64(&new_spec, new_setting))\n\t\treturn -EFAULT;\n\n\trtn = old_setting ? &old_spec : NULL;\n\terror = do_timer_settime(timer_id, flags, &new_spec, rtn);\n\tif (!error && old_setting) {\n\t\tif (put_itimerspec64(&old_spec, old_setting))\n\t\t\terror = -EFAULT;\n\t}\n\treturn error;\n}\n\n#ifdef CONFIG_COMPAT_32BIT_TIME\nSYSCALL_DEFINE4(timer_settime32, timer_t, timer_id, int, flags,\n\t\tstruct old_itimerspec32 __user *, new,\n\t\tstruct old_itimerspec32 __user *, old)\n{\n\tstruct itimerspec64 new_spec, old_spec;\n\tstruct itimerspec64 *rtn = old ? &old_spec : NULL;\n\tint error = 0;\n\n\tif (!new)\n\t\treturn -EINVAL;\n\tif (get_old_itimerspec32(&new_spec, new))\n\t\treturn -EFAULT;\n\n\terror = do_timer_settime(timer_id, flags, &new_spec, rtn);\n\tif (!error && old) {\n\t\tif (put_old_itimerspec32(&old_spec, old))\n\t\t\terror = -EFAULT;\n\t}\n\treturn error;\n}\n#endif\n\nint common_timer_del(struct k_itimer *timer)\n{\n\tconst struct k_clock *kc = timer->kclock;\n\n\ttimer->it_interval = 0;\n\tif (kc->timer_try_to_cancel(timer) < 0)\n\t\treturn TIMER_RETRY;\n\ttimer->it_active = 0;\n\treturn 0;\n}\n\nstatic inline int timer_delete_hook(struct k_itimer *timer)\n{\n\tconst struct k_clock *kc = timer->kclock;\n\n\tif (WARN_ON_ONCE(!kc || !kc->timer_del))\n\t\treturn -EINVAL;\n\treturn kc->timer_del(timer);\n}\n\n \nSYSCALL_DEFINE1(timer_delete, timer_t, timer_id)\n{\n\tstruct k_itimer *timer;\n\tunsigned long flags;\n\n\ttimer = lock_timer(timer_id, &flags);\n\nretry_delete:\n\tif (!timer)\n\t\treturn -EINVAL;\n\n\tif (unlikely(timer_delete_hook(timer) == TIMER_RETRY)) {\n\t\t \n\t\ttimer = timer_wait_running(timer, &flags);\n\t\tgoto retry_delete;\n\t}\n\n\tspin_lock(&current->sighand->siglock);\n\tlist_del(&timer->list);\n\tspin_unlock(&current->sighand->siglock);\n\t \n\tWRITE_ONCE(timer->it_signal, NULL);\n\n\tunlock_timer(timer, flags);\n\tposix_timer_unhash_and_free(timer);\n\treturn 0;\n}\n\n \nstatic void itimer_delete(struct k_itimer *timer)\n{\n\tunsigned long flags;\n\n\t \n\tspin_lock_irqsave(&timer->it_lock, flags);\n\nretry_delete:\n\t \n\tif (timer_delete_hook(timer) == TIMER_RETRY) {\n\t\t \n\t\tif (WARN_ON_ONCE(timer_wait_running(timer, &flags) != timer))\n\t\t\treturn;\n\n\t\tgoto retry_delete;\n\t}\n\tlist_del(&timer->list);\n\n\t \n\tWRITE_ONCE(timer->it_signal, NULL);\n\n\tspin_unlock_irqrestore(&timer->it_lock, flags);\n\tposix_timer_unhash_and_free(timer);\n}\n\n \nvoid exit_itimers(struct task_struct *tsk)\n{\n\tstruct list_head timers;\n\tstruct k_itimer *tmr;\n\n\tif (list_empty(&tsk->signal->posix_timers))\n\t\treturn;\n\n\t \n\tspin_lock_irq(&tsk->sighand->siglock);\n\tlist_replace_init(&tsk->signal->posix_timers, &timers);\n\tspin_unlock_irq(&tsk->sighand->siglock);\n\n\t \n\twhile (!list_empty(&timers)) {\n\t\ttmr = list_first_entry(&timers, struct k_itimer, list);\n\t\titimer_delete(tmr);\n\t}\n}\n\nSYSCALL_DEFINE2(clock_settime, const clockid_t, which_clock,\n\t\tconst struct __kernel_timespec __user *, tp)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\tstruct timespec64 new_tp;\n\n\tif (!kc || !kc->clock_set)\n\t\treturn -EINVAL;\n\n\tif (get_timespec64(&new_tp, tp))\n\t\treturn -EFAULT;\n\n\t \n\treturn kc->clock_set(which_clock, &new_tp);\n}\n\nSYSCALL_DEFINE2(clock_gettime, const clockid_t, which_clock,\n\t\tstruct __kernel_timespec __user *, tp)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\tstruct timespec64 kernel_tp;\n\tint error;\n\n\tif (!kc)\n\t\treturn -EINVAL;\n\n\terror = kc->clock_get_timespec(which_clock, &kernel_tp);\n\n\tif (!error && put_timespec64(&kernel_tp, tp))\n\t\terror = -EFAULT;\n\n\treturn error;\n}\n\nint do_clock_adjtime(const clockid_t which_clock, struct __kernel_timex * ktx)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\n\tif (!kc)\n\t\treturn -EINVAL;\n\tif (!kc->clock_adj)\n\t\treturn -EOPNOTSUPP;\n\n\treturn kc->clock_adj(which_clock, ktx);\n}\n\nSYSCALL_DEFINE2(clock_adjtime, const clockid_t, which_clock,\n\t\tstruct __kernel_timex __user *, utx)\n{\n\tstruct __kernel_timex ktx;\n\tint err;\n\n\tif (copy_from_user(&ktx, utx, sizeof(ktx)))\n\t\treturn -EFAULT;\n\n\terr = do_clock_adjtime(which_clock, &ktx);\n\n\tif (err >= 0 && copy_to_user(utx, &ktx, sizeof(ktx)))\n\t\treturn -EFAULT;\n\n\treturn err;\n}\n\n \nSYSCALL_DEFINE2(clock_getres, const clockid_t, which_clock,\n\t\tstruct __kernel_timespec __user *, tp)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\tstruct timespec64 rtn_tp;\n\tint error;\n\n\tif (!kc)\n\t\treturn -EINVAL;\n\n\terror = kc->clock_getres(which_clock, &rtn_tp);\n\n\tif (!error && tp && put_timespec64(&rtn_tp, tp))\n\t\terror = -EFAULT;\n\n\treturn error;\n}\n\n#ifdef CONFIG_COMPAT_32BIT_TIME\n\nSYSCALL_DEFINE2(clock_settime32, clockid_t, which_clock,\n\t\tstruct old_timespec32 __user *, tp)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\tstruct timespec64 ts;\n\n\tif (!kc || !kc->clock_set)\n\t\treturn -EINVAL;\n\n\tif (get_old_timespec32(&ts, tp))\n\t\treturn -EFAULT;\n\n\treturn kc->clock_set(which_clock, &ts);\n}\n\nSYSCALL_DEFINE2(clock_gettime32, clockid_t, which_clock,\n\t\tstruct old_timespec32 __user *, tp)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\tstruct timespec64 ts;\n\tint err;\n\n\tif (!kc)\n\t\treturn -EINVAL;\n\n\terr = kc->clock_get_timespec(which_clock, &ts);\n\n\tif (!err && put_old_timespec32(&ts, tp))\n\t\terr = -EFAULT;\n\n\treturn err;\n}\n\nSYSCALL_DEFINE2(clock_adjtime32, clockid_t, which_clock,\n\t\tstruct old_timex32 __user *, utp)\n{\n\tstruct __kernel_timex ktx;\n\tint err;\n\n\terr = get_old_timex32(&ktx, utp);\n\tif (err)\n\t\treturn err;\n\n\terr = do_clock_adjtime(which_clock, &ktx);\n\n\tif (err >= 0 && put_old_timex32(utp, &ktx))\n\t\treturn -EFAULT;\n\n\treturn err;\n}\n\nSYSCALL_DEFINE2(clock_getres_time32, clockid_t, which_clock,\n\t\tstruct old_timespec32 __user *, tp)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\tstruct timespec64 ts;\n\tint err;\n\n\tif (!kc)\n\t\treturn -EINVAL;\n\n\terr = kc->clock_getres(which_clock, &ts);\n\tif (!err && tp && put_old_timespec32(&ts, tp))\n\t\treturn -EFAULT;\n\n\treturn err;\n}\n\n#endif\n\n \nstatic int common_nsleep(const clockid_t which_clock, int flags,\n\t\t\t const struct timespec64 *rqtp)\n{\n\tktime_t texp = timespec64_to_ktime(*rqtp);\n\n\treturn hrtimer_nanosleep(texp, flags & TIMER_ABSTIME ?\n\t\t\t\t HRTIMER_MODE_ABS : HRTIMER_MODE_REL,\n\t\t\t\t which_clock);\n}\n\n \nstatic int common_nsleep_timens(const clockid_t which_clock, int flags,\n\t\t\t\tconst struct timespec64 *rqtp)\n{\n\tktime_t texp = timespec64_to_ktime(*rqtp);\n\n\tif (flags & TIMER_ABSTIME)\n\t\ttexp = timens_ktime_to_host(which_clock, texp);\n\n\treturn hrtimer_nanosleep(texp, flags & TIMER_ABSTIME ?\n\t\t\t\t HRTIMER_MODE_ABS : HRTIMER_MODE_REL,\n\t\t\t\t which_clock);\n}\n\nSYSCALL_DEFINE4(clock_nanosleep, const clockid_t, which_clock, int, flags,\n\t\tconst struct __kernel_timespec __user *, rqtp,\n\t\tstruct __kernel_timespec __user *, rmtp)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\tstruct timespec64 t;\n\n\tif (!kc)\n\t\treturn -EINVAL;\n\tif (!kc->nsleep)\n\t\treturn -EOPNOTSUPP;\n\n\tif (get_timespec64(&t, rqtp))\n\t\treturn -EFAULT;\n\n\tif (!timespec64_valid(&t))\n\t\treturn -EINVAL;\n\tif (flags & TIMER_ABSTIME)\n\t\trmtp = NULL;\n\tcurrent->restart_block.fn = do_no_restart_syscall;\n\tcurrent->restart_block.nanosleep.type = rmtp ? TT_NATIVE : TT_NONE;\n\tcurrent->restart_block.nanosleep.rmtp = rmtp;\n\n\treturn kc->nsleep(which_clock, flags, &t);\n}\n\n#ifdef CONFIG_COMPAT_32BIT_TIME\n\nSYSCALL_DEFINE4(clock_nanosleep_time32, clockid_t, which_clock, int, flags,\n\t\tstruct old_timespec32 __user *, rqtp,\n\t\tstruct old_timespec32 __user *, rmtp)\n{\n\tconst struct k_clock *kc = clockid_to_kclock(which_clock);\n\tstruct timespec64 t;\n\n\tif (!kc)\n\t\treturn -EINVAL;\n\tif (!kc->nsleep)\n\t\treturn -EOPNOTSUPP;\n\n\tif (get_old_timespec32(&t, rqtp))\n\t\treturn -EFAULT;\n\n\tif (!timespec64_valid(&t))\n\t\treturn -EINVAL;\n\tif (flags & TIMER_ABSTIME)\n\t\trmtp = NULL;\n\tcurrent->restart_block.fn = do_no_restart_syscall;\n\tcurrent->restart_block.nanosleep.type = rmtp ? TT_COMPAT : TT_NONE;\n\tcurrent->restart_block.nanosleep.compat_rmtp = rmtp;\n\n\treturn kc->nsleep(which_clock, flags, &t);\n}\n\n#endif\n\nstatic const struct k_clock clock_realtime = {\n\t.clock_getres\t\t= posix_get_hrtimer_res,\n\t.clock_get_timespec\t= posix_get_realtime_timespec,\n\t.clock_get_ktime\t= posix_get_realtime_ktime,\n\t.clock_set\t\t= posix_clock_realtime_set,\n\t.clock_adj\t\t= posix_clock_realtime_adj,\n\t.nsleep\t\t\t= common_nsleep,\n\t.timer_create\t\t= common_timer_create,\n\t.timer_set\t\t= common_timer_set,\n\t.timer_get\t\t= common_timer_get,\n\t.timer_del\t\t= common_timer_del,\n\t.timer_rearm\t\t= common_hrtimer_rearm,\n\t.timer_forward\t\t= common_hrtimer_forward,\n\t.timer_remaining\t= common_hrtimer_remaining,\n\t.timer_try_to_cancel\t= common_hrtimer_try_to_cancel,\n\t.timer_wait_running\t= common_timer_wait_running,\n\t.timer_arm\t\t= common_hrtimer_arm,\n};\n\nstatic const struct k_clock clock_monotonic = {\n\t.clock_getres\t\t= posix_get_hrtimer_res,\n\t.clock_get_timespec\t= posix_get_monotonic_timespec,\n\t.clock_get_ktime\t= posix_get_monotonic_ktime,\n\t.nsleep\t\t\t= common_nsleep_timens,\n\t.timer_create\t\t= common_timer_create,\n\t.timer_set\t\t= common_timer_set,\n\t.timer_get\t\t= common_timer_get,\n\t.timer_del\t\t= common_timer_del,\n\t.timer_rearm\t\t= common_hrtimer_rearm,\n\t.timer_forward\t\t= common_hrtimer_forward,\n\t.timer_remaining\t= common_hrtimer_remaining,\n\t.timer_try_to_cancel\t= common_hrtimer_try_to_cancel,\n\t.timer_wait_running\t= common_timer_wait_running,\n\t.timer_arm\t\t= common_hrtimer_arm,\n};\n\nstatic const struct k_clock clock_monotonic_raw = {\n\t.clock_getres\t\t= posix_get_hrtimer_res,\n\t.clock_get_timespec\t= posix_get_monotonic_raw,\n};\n\nstatic const struct k_clock clock_realtime_coarse = {\n\t.clock_getres\t\t= posix_get_coarse_res,\n\t.clock_get_timespec\t= posix_get_realtime_coarse,\n};\n\nstatic const struct k_clock clock_monotonic_coarse = {\n\t.clock_getres\t\t= posix_get_coarse_res,\n\t.clock_get_timespec\t= posix_get_monotonic_coarse,\n};\n\nstatic const struct k_clock clock_tai = {\n\t.clock_getres\t\t= posix_get_hrtimer_res,\n\t.clock_get_ktime\t= posix_get_tai_ktime,\n\t.clock_get_timespec\t= posix_get_tai_timespec,\n\t.nsleep\t\t\t= common_nsleep,\n\t.timer_create\t\t= common_timer_create,\n\t.timer_set\t\t= common_timer_set,\n\t.timer_get\t\t= common_timer_get,\n\t.timer_del\t\t= common_timer_del,\n\t.timer_rearm\t\t= common_hrtimer_rearm,\n\t.timer_forward\t\t= common_hrtimer_forward,\n\t.timer_remaining\t= common_hrtimer_remaining,\n\t.timer_try_to_cancel\t= common_hrtimer_try_to_cancel,\n\t.timer_wait_running\t= common_timer_wait_running,\n\t.timer_arm\t\t= common_hrtimer_arm,\n};\n\nstatic const struct k_clock clock_boottime = {\n\t.clock_getres\t\t= posix_get_hrtimer_res,\n\t.clock_get_ktime\t= posix_get_boottime_ktime,\n\t.clock_get_timespec\t= posix_get_boottime_timespec,\n\t.nsleep\t\t\t= common_nsleep_timens,\n\t.timer_create\t\t= common_timer_create,\n\t.timer_set\t\t= common_timer_set,\n\t.timer_get\t\t= common_timer_get,\n\t.timer_del\t\t= common_timer_del,\n\t.timer_rearm\t\t= common_hrtimer_rearm,\n\t.timer_forward\t\t= common_hrtimer_forward,\n\t.timer_remaining\t= common_hrtimer_remaining,\n\t.timer_try_to_cancel\t= common_hrtimer_try_to_cancel,\n\t.timer_wait_running\t= common_timer_wait_running,\n\t.timer_arm\t\t= common_hrtimer_arm,\n};\n\nstatic const struct k_clock * const posix_clocks[] = {\n\t[CLOCK_REALTIME]\t\t= &clock_realtime,\n\t[CLOCK_MONOTONIC]\t\t= &clock_monotonic,\n\t[CLOCK_PROCESS_CPUTIME_ID]\t= &clock_process,\n\t[CLOCK_THREAD_CPUTIME_ID]\t= &clock_thread,\n\t[CLOCK_MONOTONIC_RAW]\t\t= &clock_monotonic_raw,\n\t[CLOCK_REALTIME_COARSE]\t\t= &clock_realtime_coarse,\n\t[CLOCK_MONOTONIC_COARSE]\t= &clock_monotonic_coarse,\n\t[CLOCK_BOOTTIME]\t\t= &clock_boottime,\n\t[CLOCK_REALTIME_ALARM]\t\t= &alarm_clock,\n\t[CLOCK_BOOTTIME_ALARM]\t\t= &alarm_clock,\n\t[CLOCK_TAI]\t\t\t= &clock_tai,\n};\n\nstatic const struct k_clock *clockid_to_kclock(const clockid_t id)\n{\n\tclockid_t idx = id;\n\n\tif (id < 0) {\n\t\treturn (id & CLOCKFD_MASK) == CLOCKFD ?\n\t\t\t&clock_posix_dynamic : &clock_posix_cpu;\n\t}\n\n\tif (id >= ARRAY_SIZE(posix_clocks))\n\t\treturn NULL;\n\n\treturn posix_clocks[array_index_nospec(idx, ARRAY_SIZE(posix_clocks))];\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}