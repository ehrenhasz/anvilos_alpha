{
  "module_name": "clockevents.c",
  "hash_id": "0cc6f862d601fdf2946b1ed6f2c855dd1459b3e83b6bdfb9bef020553841958f",
  "original_prompt": "Ingested from linux-6.6.14/kernel/time/clockevents.c",
  "human_readable_source": "\n \n\n#include <linux/clockchips.h>\n#include <linux/hrtimer.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/smp.h>\n#include <linux/device.h>\n\n#include \"tick-internal.h\"\n\n \nstatic LIST_HEAD(clockevent_devices);\nstatic LIST_HEAD(clockevents_released);\n \nstatic DEFINE_RAW_SPINLOCK(clockevents_lock);\n \nstatic DEFINE_MUTEX(clockevents_mutex);\n\nstruct ce_unbind {\n\tstruct clock_event_device *ce;\n\tint res;\n};\n\nstatic u64 cev_delta2ns(unsigned long latch, struct clock_event_device *evt,\n\t\t\tbool ismax)\n{\n\tu64 clc = (u64) latch << evt->shift;\n\tu64 rnd;\n\n\tif (WARN_ON(!evt->mult))\n\t\tevt->mult = 1;\n\trnd = (u64) evt->mult - 1;\n\n\t \n\tif ((clc >> evt->shift) != (u64)latch)\n\t\tclc = ~0ULL;\n\n\t \n\tif ((~0ULL - clc > rnd) &&\n\t    (!ismax || evt->mult <= (1ULL << evt->shift)))\n\t\tclc += rnd;\n\n\tdo_div(clc, evt->mult);\n\n\t \n\treturn clc > 1000 ? clc : 1000;\n}\n\n \nu64 clockevent_delta2ns(unsigned long latch, struct clock_event_device *evt)\n{\n\treturn cev_delta2ns(latch, evt, false);\n}\nEXPORT_SYMBOL_GPL(clockevent_delta2ns);\n\nstatic int __clockevents_switch_state(struct clock_event_device *dev,\n\t\t\t\t      enum clock_event_state state)\n{\n\tif (dev->features & CLOCK_EVT_FEAT_DUMMY)\n\t\treturn 0;\n\n\t \n\tswitch (state) {\n\tcase CLOCK_EVT_STATE_DETACHED:\n\t\t \n\n\tcase CLOCK_EVT_STATE_SHUTDOWN:\n\t\tif (dev->set_state_shutdown)\n\t\t\treturn dev->set_state_shutdown(dev);\n\t\treturn 0;\n\n\tcase CLOCK_EVT_STATE_PERIODIC:\n\t\t \n\t\tif (!(dev->features & CLOCK_EVT_FEAT_PERIODIC))\n\t\t\treturn -ENOSYS;\n\t\tif (dev->set_state_periodic)\n\t\t\treturn dev->set_state_periodic(dev);\n\t\treturn 0;\n\n\tcase CLOCK_EVT_STATE_ONESHOT:\n\t\t \n\t\tif (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))\n\t\t\treturn -ENOSYS;\n\t\tif (dev->set_state_oneshot)\n\t\t\treturn dev->set_state_oneshot(dev);\n\t\treturn 0;\n\n\tcase CLOCK_EVT_STATE_ONESHOT_STOPPED:\n\t\t \n\t\tif (WARN_ONCE(!clockevent_state_oneshot(dev),\n\t\t\t      \"Current state: %d\\n\",\n\t\t\t      clockevent_get_state(dev)))\n\t\t\treturn -EINVAL;\n\n\t\tif (dev->set_state_oneshot_stopped)\n\t\t\treturn dev->set_state_oneshot_stopped(dev);\n\t\telse\n\t\t\treturn -ENOSYS;\n\n\tdefault:\n\t\treturn -ENOSYS;\n\t}\n}\n\n \nvoid clockevents_switch_state(struct clock_event_device *dev,\n\t\t\t      enum clock_event_state state)\n{\n\tif (clockevent_get_state(dev) != state) {\n\t\tif (__clockevents_switch_state(dev, state))\n\t\t\treturn;\n\n\t\tclockevent_set_state(dev, state);\n\n\t\t \n\t\tif (clockevent_state_oneshot(dev)) {\n\t\t\tif (WARN_ON(!dev->mult))\n\t\t\t\tdev->mult = 1;\n\t\t}\n\t}\n}\n\n \nvoid clockevents_shutdown(struct clock_event_device *dev)\n{\n\tclockevents_switch_state(dev, CLOCK_EVT_STATE_SHUTDOWN);\n\tdev->next_event = KTIME_MAX;\n}\n\n \nint clockevents_tick_resume(struct clock_event_device *dev)\n{\n\tint ret = 0;\n\n\tif (dev->tick_resume)\n\t\tret = dev->tick_resume(dev);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_GENERIC_CLOCKEVENTS_MIN_ADJUST\n\n \n#define MIN_DELTA_LIMIT\t\t(NSEC_PER_SEC / HZ)\n\n \nstatic int clockevents_increase_min_delta(struct clock_event_device *dev)\n{\n\t \n\tif (dev->min_delta_ns >= MIN_DELTA_LIMIT) {\n\t\tprintk_deferred(KERN_WARNING\n\t\t\t\t\"CE: Reprogramming failure. Giving up\\n\");\n\t\tdev->next_event = KTIME_MAX;\n\t\treturn -ETIME;\n\t}\n\n\tif (dev->min_delta_ns < 5000)\n\t\tdev->min_delta_ns = 5000;\n\telse\n\t\tdev->min_delta_ns += dev->min_delta_ns >> 1;\n\n\tif (dev->min_delta_ns > MIN_DELTA_LIMIT)\n\t\tdev->min_delta_ns = MIN_DELTA_LIMIT;\n\n\tprintk_deferred(KERN_WARNING\n\t\t\t\"CE: %s increased min_delta_ns to %llu nsec\\n\",\n\t\t\tdev->name ? dev->name : \"?\",\n\t\t\t(unsigned long long) dev->min_delta_ns);\n\treturn 0;\n}\n\n \nstatic int clockevents_program_min_delta(struct clock_event_device *dev)\n{\n\tunsigned long long clc;\n\tint64_t delta;\n\tint i;\n\n\tfor (i = 0;;) {\n\t\tdelta = dev->min_delta_ns;\n\t\tdev->next_event = ktime_add_ns(ktime_get(), delta);\n\n\t\tif (clockevent_state_shutdown(dev))\n\t\t\treturn 0;\n\n\t\tdev->retries++;\n\t\tclc = ((unsigned long long) delta * dev->mult) >> dev->shift;\n\t\tif (dev->set_next_event((unsigned long) clc, dev) == 0)\n\t\t\treturn 0;\n\n\t\tif (++i > 2) {\n\t\t\t \n\t\t\tif (clockevents_increase_min_delta(dev))\n\t\t\t\treturn -ETIME;\n\t\t\ti = 0;\n\t\t}\n\t}\n}\n\n#else   \n\n \nstatic int clockevents_program_min_delta(struct clock_event_device *dev)\n{\n\tunsigned long long clc;\n\tint64_t delta = 0;\n\tint i;\n\n\tfor (i = 0; i < 10; i++) {\n\t\tdelta += dev->min_delta_ns;\n\t\tdev->next_event = ktime_add_ns(ktime_get(), delta);\n\n\t\tif (clockevent_state_shutdown(dev))\n\t\t\treturn 0;\n\n\t\tdev->retries++;\n\t\tclc = ((unsigned long long) delta * dev->mult) >> dev->shift;\n\t\tif (dev->set_next_event((unsigned long) clc, dev) == 0)\n\t\t\treturn 0;\n\t}\n\treturn -ETIME;\n}\n\n#endif  \n\n \nint clockevents_program_event(struct clock_event_device *dev, ktime_t expires,\n\t\t\t      bool force)\n{\n\tunsigned long long clc;\n\tint64_t delta;\n\tint rc;\n\n\tif (WARN_ON_ONCE(expires < 0))\n\t\treturn -ETIME;\n\n\tdev->next_event = expires;\n\n\tif (clockevent_state_shutdown(dev))\n\t\treturn 0;\n\n\t \n\tWARN_ONCE(!clockevent_state_oneshot(dev), \"Current state: %d\\n\",\n\t\t  clockevent_get_state(dev));\n\n\t \n\tif (dev->features & CLOCK_EVT_FEAT_KTIME)\n\t\treturn dev->set_next_ktime(expires, dev);\n\n\tdelta = ktime_to_ns(ktime_sub(expires, ktime_get()));\n\tif (delta <= 0)\n\t\treturn force ? clockevents_program_min_delta(dev) : -ETIME;\n\n\tdelta = min(delta, (int64_t) dev->max_delta_ns);\n\tdelta = max(delta, (int64_t) dev->min_delta_ns);\n\n\tclc = ((unsigned long long) delta * dev->mult) >> dev->shift;\n\trc = dev->set_next_event((unsigned long) clc, dev);\n\n\treturn (rc && force) ? clockevents_program_min_delta(dev) : rc;\n}\n\n \nstatic void clockevents_notify_released(void)\n{\n\tstruct clock_event_device *dev;\n\n\twhile (!list_empty(&clockevents_released)) {\n\t\tdev = list_entry(clockevents_released.next,\n\t\t\t\t struct clock_event_device, list);\n\t\tlist_move(&dev->list, &clockevent_devices);\n\t\ttick_check_new_device(dev);\n\t}\n}\n\n \nstatic int clockevents_replace(struct clock_event_device *ced)\n{\n\tstruct clock_event_device *dev, *newdev = NULL;\n\n\tlist_for_each_entry(dev, &clockevent_devices, list) {\n\t\tif (dev == ced || !clockevent_state_detached(dev))\n\t\t\tcontinue;\n\n\t\tif (!tick_check_replacement(newdev, dev))\n\t\t\tcontinue;\n\n\t\tif (!try_module_get(dev->owner))\n\t\t\tcontinue;\n\n\t\tif (newdev)\n\t\t\tmodule_put(newdev->owner);\n\t\tnewdev = dev;\n\t}\n\tif (newdev) {\n\t\ttick_install_replacement(newdev);\n\t\tlist_del_init(&ced->list);\n\t}\n\treturn newdev ? 0 : -EBUSY;\n}\n\n \nstatic int __clockevents_try_unbind(struct clock_event_device *ced, int cpu)\n{\n\t \n\tif (clockevent_state_detached(ced)) {\n\t\tlist_del_init(&ced->list);\n\t\treturn 0;\n\t}\n\n\treturn ced == per_cpu(tick_cpu_device, cpu).evtdev ? -EAGAIN : -EBUSY;\n}\n\n \nstatic void __clockevents_unbind(void *arg)\n{\n\tstruct ce_unbind *cu = arg;\n\tint res;\n\n\traw_spin_lock(&clockevents_lock);\n\tres = __clockevents_try_unbind(cu->ce, smp_processor_id());\n\tif (res == -EAGAIN)\n\t\tres = clockevents_replace(cu->ce);\n\tcu->res = res;\n\traw_spin_unlock(&clockevents_lock);\n}\n\n \nstatic int clockevents_unbind(struct clock_event_device *ced, int cpu)\n{\n\tstruct ce_unbind cu = { .ce = ced, .res = -ENODEV };\n\n\tsmp_call_function_single(cpu, __clockevents_unbind, &cu, 1);\n\treturn cu.res;\n}\n\n \nint clockevents_unbind_device(struct clock_event_device *ced, int cpu)\n{\n\tint ret;\n\n\tmutex_lock(&clockevents_mutex);\n\tret = clockevents_unbind(ced, cpu);\n\tmutex_unlock(&clockevents_mutex);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(clockevents_unbind_device);\n\n \nvoid clockevents_register_device(struct clock_event_device *dev)\n{\n\tunsigned long flags;\n\n\t \n\tclockevent_set_state(dev, CLOCK_EVT_STATE_DETACHED);\n\n\tif (!dev->cpumask) {\n\t\tWARN_ON(num_possible_cpus() > 1);\n\t\tdev->cpumask = cpumask_of(smp_processor_id());\n\t}\n\n\tif (dev->cpumask == cpu_all_mask) {\n\t\tWARN(1, \"%s cpumask == cpu_all_mask, using cpu_possible_mask instead\\n\",\n\t\t     dev->name);\n\t\tdev->cpumask = cpu_possible_mask;\n\t}\n\n\traw_spin_lock_irqsave(&clockevents_lock, flags);\n\n\tlist_add(&dev->list, &clockevent_devices);\n\ttick_check_new_device(dev);\n\tclockevents_notify_released();\n\n\traw_spin_unlock_irqrestore(&clockevents_lock, flags);\n}\nEXPORT_SYMBOL_GPL(clockevents_register_device);\n\nstatic void clockevents_config(struct clock_event_device *dev, u32 freq)\n{\n\tu64 sec;\n\n\tif (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))\n\t\treturn;\n\n\t \n\tsec = dev->max_delta_ticks;\n\tdo_div(sec, freq);\n\tif (!sec)\n\t\tsec = 1;\n\telse if (sec > 600 && dev->max_delta_ticks > UINT_MAX)\n\t\tsec = 600;\n\n\tclockevents_calc_mult_shift(dev, freq, sec);\n\tdev->min_delta_ns = cev_delta2ns(dev->min_delta_ticks, dev, false);\n\tdev->max_delta_ns = cev_delta2ns(dev->max_delta_ticks, dev, true);\n}\n\n \nvoid clockevents_config_and_register(struct clock_event_device *dev,\n\t\t\t\t     u32 freq, unsigned long min_delta,\n\t\t\t\t     unsigned long max_delta)\n{\n\tdev->min_delta_ticks = min_delta;\n\tdev->max_delta_ticks = max_delta;\n\tclockevents_config(dev, freq);\n\tclockevents_register_device(dev);\n}\nEXPORT_SYMBOL_GPL(clockevents_config_and_register);\n\nint __clockevents_update_freq(struct clock_event_device *dev, u32 freq)\n{\n\tclockevents_config(dev, freq);\n\n\tif (clockevent_state_oneshot(dev))\n\t\treturn clockevents_program_event(dev, dev->next_event, false);\n\n\tif (clockevent_state_periodic(dev))\n\t\treturn __clockevents_switch_state(dev, CLOCK_EVT_STATE_PERIODIC);\n\n\treturn 0;\n}\n\n \nint clockevents_update_freq(struct clock_event_device *dev, u32 freq)\n{\n\tunsigned long flags;\n\tint ret;\n\n\tlocal_irq_save(flags);\n\tret = tick_broadcast_update_freq(dev, freq);\n\tif (ret == -ENODEV)\n\t\tret = __clockevents_update_freq(dev, freq);\n\tlocal_irq_restore(flags);\n\treturn ret;\n}\n\n \nvoid clockevents_handle_noop(struct clock_event_device *dev)\n{\n}\n\n \nvoid clockevents_exchange_device(struct clock_event_device *old,\n\t\t\t\t struct clock_event_device *new)\n{\n\t \n\tif (old) {\n\t\tmodule_put(old->owner);\n\t\tclockevents_switch_state(old, CLOCK_EVT_STATE_DETACHED);\n\t\tlist_move(&old->list, &clockevents_released);\n\t}\n\n\tif (new) {\n\t\tBUG_ON(!clockevent_state_detached(new));\n\t\tclockevents_shutdown(new);\n\t}\n}\n\n \nvoid clockevents_suspend(void)\n{\n\tstruct clock_event_device *dev;\n\n\tlist_for_each_entry_reverse(dev, &clockevent_devices, list)\n\t\tif (dev->suspend && !clockevent_state_detached(dev))\n\t\t\tdev->suspend(dev);\n}\n\n \nvoid clockevents_resume(void)\n{\n\tstruct clock_event_device *dev;\n\n\tlist_for_each_entry(dev, &clockevent_devices, list)\n\t\tif (dev->resume && !clockevent_state_detached(dev))\n\t\t\tdev->resume(dev);\n}\n\n#ifdef CONFIG_HOTPLUG_CPU\n\n# ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST\n \nvoid tick_offline_cpu(unsigned int cpu)\n{\n\traw_spin_lock(&clockevents_lock);\n\ttick_broadcast_offline(cpu);\n\traw_spin_unlock(&clockevents_lock);\n}\n# endif\n\n \nvoid tick_cleanup_dead_cpu(int cpu)\n{\n\tstruct clock_event_device *dev, *tmp;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&clockevents_lock, flags);\n\n\ttick_shutdown(cpu);\n\t \n\tlist_for_each_entry_safe(dev, tmp, &clockevents_released, list)\n\t\tlist_del(&dev->list);\n\t \n\tlist_for_each_entry_safe(dev, tmp, &clockevent_devices, list) {\n\t\tif (cpumask_test_cpu(cpu, dev->cpumask) &&\n\t\t    cpumask_weight(dev->cpumask) == 1 &&\n\t\t    !tick_is_broadcast_device(dev)) {\n\t\t\tBUG_ON(!clockevent_state_detached(dev));\n\t\t\tlist_del(&dev->list);\n\t\t}\n\t}\n\traw_spin_unlock_irqrestore(&clockevents_lock, flags);\n}\n#endif\n\n#ifdef CONFIG_SYSFS\nstatic struct bus_type clockevents_subsys = {\n\t.name\t\t= \"clockevents\",\n\t.dev_name       = \"clockevent\",\n};\n\nstatic DEFINE_PER_CPU(struct device, tick_percpu_dev);\nstatic struct tick_device *tick_get_tick_dev(struct device *dev);\n\nstatic ssize_t current_device_show(struct device *dev,\n\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t   char *buf)\n{\n\tstruct tick_device *td;\n\tssize_t count = 0;\n\n\traw_spin_lock_irq(&clockevents_lock);\n\ttd = tick_get_tick_dev(dev);\n\tif (td && td->evtdev)\n\t\tcount = snprintf(buf, PAGE_SIZE, \"%s\\n\", td->evtdev->name);\n\traw_spin_unlock_irq(&clockevents_lock);\n\treturn count;\n}\nstatic DEVICE_ATTR_RO(current_device);\n\n \nstatic ssize_t unbind_device_store(struct device *dev,\n\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t   const char *buf, size_t count)\n{\n\tchar name[CS_NAME_LEN];\n\tssize_t ret = sysfs_get_uname(buf, name, count);\n\tstruct clock_event_device *ce = NULL, *iter;\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = -ENODEV;\n\tmutex_lock(&clockevents_mutex);\n\traw_spin_lock_irq(&clockevents_lock);\n\tlist_for_each_entry(iter, &clockevent_devices, list) {\n\t\tif (!strcmp(iter->name, name)) {\n\t\t\tret = __clockevents_try_unbind(iter, dev->id);\n\t\t\tce = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\traw_spin_unlock_irq(&clockevents_lock);\n\t \n\tif (ret == -EAGAIN)\n\t\tret = clockevents_unbind(ce, dev->id);\n\tmutex_unlock(&clockevents_mutex);\n\treturn ret ? ret : count;\n}\nstatic DEVICE_ATTR_WO(unbind_device);\n\n#ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST\nstatic struct device tick_bc_dev = {\n\t.init_name\t= \"broadcast\",\n\t.id\t\t= 0,\n\t.bus\t\t= &clockevents_subsys,\n};\n\nstatic struct tick_device *tick_get_tick_dev(struct device *dev)\n{\n\treturn dev == &tick_bc_dev ? tick_get_broadcast_device() :\n\t\t&per_cpu(tick_cpu_device, dev->id);\n}\n\nstatic __init int tick_broadcast_init_sysfs(void)\n{\n\tint err = device_register(&tick_bc_dev);\n\n\tif (!err)\n\t\terr = device_create_file(&tick_bc_dev, &dev_attr_current_device);\n\treturn err;\n}\n#else\nstatic struct tick_device *tick_get_tick_dev(struct device *dev)\n{\n\treturn &per_cpu(tick_cpu_device, dev->id);\n}\nstatic inline int tick_broadcast_init_sysfs(void) { return 0; }\n#endif\n\nstatic int __init tick_init_sysfs(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct device *dev = &per_cpu(tick_percpu_dev, cpu);\n\t\tint err;\n\n\t\tdev->id = cpu;\n\t\tdev->bus = &clockevents_subsys;\n\t\terr = device_register(dev);\n\t\tif (!err)\n\t\t\terr = device_create_file(dev, &dev_attr_current_device);\n\t\tif (!err)\n\t\t\terr = device_create_file(dev, &dev_attr_unbind_device);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\treturn tick_broadcast_init_sysfs();\n}\n\nstatic int __init clockevents_init_sysfs(void)\n{\n\tint err = subsys_system_register(&clockevents_subsys, NULL);\n\n\tif (!err)\n\t\terr = tick_init_sysfs();\n\treturn err;\n}\ndevice_initcall(clockevents_init_sysfs);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}