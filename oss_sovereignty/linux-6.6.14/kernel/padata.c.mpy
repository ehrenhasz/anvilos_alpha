{
  "module_name": "padata.c",
  "hash_id": "3374a7dceab84491be3107eaf96759d4aae2508505716dc50ae9c2ebf53ff23f",
  "original_prompt": "Ingested from linux-6.6.14/kernel/padata.c",
  "human_readable_source": "\n \n\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/cpumask.h>\n#include <linux/err.h>\n#include <linux/cpu.h>\n#include <linux/padata.h>\n#include <linux/mutex.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/sysfs.h>\n#include <linux/rcupdate.h>\n\n#define\tPADATA_WORK_ONSTACK\t1\t \n\nstruct padata_work {\n\tstruct work_struct\tpw_work;\n\tstruct list_head\tpw_list;   \n\tvoid\t\t\t*pw_data;\n};\n\nstatic DEFINE_SPINLOCK(padata_works_lock);\nstatic struct padata_work *padata_works;\nstatic LIST_HEAD(padata_free_works);\n\nstruct padata_mt_job_state {\n\tspinlock_t\t\tlock;\n\tstruct completion\tcompletion;\n\tstruct padata_mt_job\t*job;\n\tint\t\t\tnworks;\n\tint\t\t\tnworks_fini;\n\tunsigned long\t\tchunk_size;\n};\n\nstatic void padata_free_pd(struct parallel_data *pd);\nstatic void __init padata_mt_helper(struct work_struct *work);\n\nstatic int padata_index_to_cpu(struct parallel_data *pd, int cpu_index)\n{\n\tint cpu, target_cpu;\n\n\ttarget_cpu = cpumask_first(pd->cpumask.pcpu);\n\tfor (cpu = 0; cpu < cpu_index; cpu++)\n\t\ttarget_cpu = cpumask_next(target_cpu, pd->cpumask.pcpu);\n\n\treturn target_cpu;\n}\n\nstatic int padata_cpu_hash(struct parallel_data *pd, unsigned int seq_nr)\n{\n\t \n\tint cpu_index = seq_nr % cpumask_weight(pd->cpumask.pcpu);\n\n\treturn padata_index_to_cpu(pd, cpu_index);\n}\n\nstatic struct padata_work *padata_work_alloc(void)\n{\n\tstruct padata_work *pw;\n\n\tlockdep_assert_held(&padata_works_lock);\n\n\tif (list_empty(&padata_free_works))\n\t\treturn NULL;\t \n\n\tpw = list_first_entry(&padata_free_works, struct padata_work, pw_list);\n\tlist_del(&pw->pw_list);\n\treturn pw;\n}\n\n \nstatic void __ref padata_work_init(struct padata_work *pw, work_func_t work_fn,\n\t\t\t\t   void *data, int flags)\n{\n\tif (flags & PADATA_WORK_ONSTACK)\n\t\tINIT_WORK_ONSTACK(&pw->pw_work, work_fn);\n\telse\n\t\tINIT_WORK(&pw->pw_work, work_fn);\n\tpw->pw_data = data;\n}\n\nstatic int __init padata_work_alloc_mt(int nworks, void *data,\n\t\t\t\t       struct list_head *head)\n{\n\tint i;\n\n\tspin_lock(&padata_works_lock);\n\t \n\tfor (i = 1; i < nworks; ++i) {\n\t\tstruct padata_work *pw = padata_work_alloc();\n\n\t\tif (!pw)\n\t\t\tbreak;\n\t\tpadata_work_init(pw, padata_mt_helper, data, 0);\n\t\tlist_add(&pw->pw_list, head);\n\t}\n\tspin_unlock(&padata_works_lock);\n\n\treturn i;\n}\n\nstatic void padata_work_free(struct padata_work *pw)\n{\n\tlockdep_assert_held(&padata_works_lock);\n\tlist_add(&pw->pw_list, &padata_free_works);\n}\n\nstatic void __init padata_works_free(struct list_head *works)\n{\n\tstruct padata_work *cur, *next;\n\n\tif (list_empty(works))\n\t\treturn;\n\n\tspin_lock(&padata_works_lock);\n\tlist_for_each_entry_safe(cur, next, works, pw_list) {\n\t\tlist_del(&cur->pw_list);\n\t\tpadata_work_free(cur);\n\t}\n\tspin_unlock(&padata_works_lock);\n}\n\nstatic void padata_parallel_worker(struct work_struct *parallel_work)\n{\n\tstruct padata_work *pw = container_of(parallel_work, struct padata_work,\n\t\t\t\t\t      pw_work);\n\tstruct padata_priv *padata = pw->pw_data;\n\n\tlocal_bh_disable();\n\tpadata->parallel(padata);\n\tspin_lock(&padata_works_lock);\n\tpadata_work_free(pw);\n\tspin_unlock(&padata_works_lock);\n\tlocal_bh_enable();\n}\n\n \nint padata_do_parallel(struct padata_shell *ps,\n\t\t       struct padata_priv *padata, int *cb_cpu)\n{\n\tstruct padata_instance *pinst = ps->pinst;\n\tint i, cpu, cpu_index, err;\n\tstruct parallel_data *pd;\n\tstruct padata_work *pw;\n\n\trcu_read_lock_bh();\n\n\tpd = rcu_dereference_bh(ps->pd);\n\n\terr = -EINVAL;\n\tif (!(pinst->flags & PADATA_INIT) || pinst->flags & PADATA_INVALID)\n\t\tgoto out;\n\n\tif (!cpumask_test_cpu(*cb_cpu, pd->cpumask.cbcpu)) {\n\t\tif (cpumask_empty(pd->cpumask.cbcpu))\n\t\t\tgoto out;\n\n\t\t \n\t\tcpu_index = *cb_cpu % cpumask_weight(pd->cpumask.cbcpu);\n\n\t\tcpu = cpumask_first(pd->cpumask.cbcpu);\n\t\tfor (i = 0; i < cpu_index; i++)\n\t\t\tcpu = cpumask_next(cpu, pd->cpumask.cbcpu);\n\n\t\t*cb_cpu = cpu;\n\t}\n\n\terr = -EBUSY;\n\tif ((pinst->flags & PADATA_RESET))\n\t\tgoto out;\n\n\trefcount_inc(&pd->refcnt);\n\tpadata->pd = pd;\n\tpadata->cb_cpu = *cb_cpu;\n\n\tspin_lock(&padata_works_lock);\n\tpadata->seq_nr = ++pd->seq_nr;\n\tpw = padata_work_alloc();\n\tspin_unlock(&padata_works_lock);\n\n\tif (!pw) {\n\t\t \n\t\tpadata->parallel(padata);\n\t}\n\n\trcu_read_unlock_bh();\n\n\tif (pw) {\n\t\tpadata_work_init(pw, padata_parallel_worker, padata, 0);\n\t\tqueue_work(pinst->parallel_wq, &pw->pw_work);\n\t}\n\n\treturn 0;\nout:\n\trcu_read_unlock_bh();\n\n\treturn err;\n}\nEXPORT_SYMBOL(padata_do_parallel);\n\n \nstatic struct padata_priv *padata_find_next(struct parallel_data *pd,\n\t\t\t\t\t    bool remove_object)\n{\n\tstruct padata_priv *padata;\n\tstruct padata_list *reorder;\n\tint cpu = pd->cpu;\n\n\treorder = per_cpu_ptr(pd->reorder_list, cpu);\n\n\tspin_lock(&reorder->lock);\n\tif (list_empty(&reorder->list)) {\n\t\tspin_unlock(&reorder->lock);\n\t\treturn NULL;\n\t}\n\n\tpadata = list_entry(reorder->list.next, struct padata_priv, list);\n\n\t \n\tif (padata->seq_nr != pd->processed) {\n\t\tspin_unlock(&reorder->lock);\n\t\treturn NULL;\n\t}\n\n\tif (remove_object) {\n\t\tlist_del_init(&padata->list);\n\t\t++pd->processed;\n\t\tpd->cpu = cpumask_next_wrap(cpu, pd->cpumask.pcpu, -1, false);\n\t}\n\n\tspin_unlock(&reorder->lock);\n\treturn padata;\n}\n\nstatic void padata_reorder(struct parallel_data *pd)\n{\n\tstruct padata_instance *pinst = pd->ps->pinst;\n\tint cb_cpu;\n\tstruct padata_priv *padata;\n\tstruct padata_serial_queue *squeue;\n\tstruct padata_list *reorder;\n\n\t \n\tif (!spin_trylock_bh(&pd->lock))\n\t\treturn;\n\n\twhile (1) {\n\t\tpadata = padata_find_next(pd, true);\n\n\t\t \n\t\tif (!padata)\n\t\t\tbreak;\n\n\t\tcb_cpu = padata->cb_cpu;\n\t\tsqueue = per_cpu_ptr(pd->squeue, cb_cpu);\n\n\t\tspin_lock(&squeue->serial.lock);\n\t\tlist_add_tail(&padata->list, &squeue->serial.list);\n\t\tspin_unlock(&squeue->serial.lock);\n\n\t\tqueue_work_on(cb_cpu, pinst->serial_wq, &squeue->work);\n\t}\n\n\tspin_unlock_bh(&pd->lock);\n\n\t \n\tsmp_mb();\n\n\treorder = per_cpu_ptr(pd->reorder_list, pd->cpu);\n\tif (!list_empty(&reorder->list) && padata_find_next(pd, false))\n\t\tqueue_work(pinst->serial_wq, &pd->reorder_work);\n}\n\nstatic void invoke_padata_reorder(struct work_struct *work)\n{\n\tstruct parallel_data *pd;\n\n\tlocal_bh_disable();\n\tpd = container_of(work, struct parallel_data, reorder_work);\n\tpadata_reorder(pd);\n\tlocal_bh_enable();\n}\n\nstatic void padata_serial_worker(struct work_struct *serial_work)\n{\n\tstruct padata_serial_queue *squeue;\n\tstruct parallel_data *pd;\n\tLIST_HEAD(local_list);\n\tint cnt;\n\n\tlocal_bh_disable();\n\tsqueue = container_of(serial_work, struct padata_serial_queue, work);\n\tpd = squeue->pd;\n\n\tspin_lock(&squeue->serial.lock);\n\tlist_replace_init(&squeue->serial.list, &local_list);\n\tspin_unlock(&squeue->serial.lock);\n\n\tcnt = 0;\n\n\twhile (!list_empty(&local_list)) {\n\t\tstruct padata_priv *padata;\n\n\t\tpadata = list_entry(local_list.next,\n\t\t\t\t    struct padata_priv, list);\n\n\t\tlist_del_init(&padata->list);\n\n\t\tpadata->serial(padata);\n\t\tcnt++;\n\t}\n\tlocal_bh_enable();\n\n\tif (refcount_sub_and_test(cnt, &pd->refcnt))\n\t\tpadata_free_pd(pd);\n}\n\n \nvoid padata_do_serial(struct padata_priv *padata)\n{\n\tstruct parallel_data *pd = padata->pd;\n\tint hashed_cpu = padata_cpu_hash(pd, padata->seq_nr);\n\tstruct padata_list *reorder = per_cpu_ptr(pd->reorder_list, hashed_cpu);\n\tstruct padata_priv *cur;\n\tstruct list_head *pos;\n\n\tspin_lock(&reorder->lock);\n\t \n\tlist_for_each_prev(pos, &reorder->list) {\n\t\tcur = list_entry(pos, struct padata_priv, list);\n\t\tif (cur->seq_nr < padata->seq_nr)\n\t\t\tbreak;\n\t}\n\tlist_add(&padata->list, pos);\n\tspin_unlock(&reorder->lock);\n\n\t \n\tsmp_mb();\n\n\tpadata_reorder(pd);\n}\nEXPORT_SYMBOL(padata_do_serial);\n\nstatic int padata_setup_cpumasks(struct padata_instance *pinst)\n{\n\tstruct workqueue_attrs *attrs;\n\tint err;\n\n\tattrs = alloc_workqueue_attrs();\n\tif (!attrs)\n\t\treturn -ENOMEM;\n\n\t \n\tcpumask_copy(attrs->cpumask, pinst->cpumask.pcpu);\n\terr = apply_workqueue_attrs(pinst->parallel_wq, attrs);\n\tfree_workqueue_attrs(attrs);\n\n\treturn err;\n}\n\nstatic void __init padata_mt_helper(struct work_struct *w)\n{\n\tstruct padata_work *pw = container_of(w, struct padata_work, pw_work);\n\tstruct padata_mt_job_state *ps = pw->pw_data;\n\tstruct padata_mt_job *job = ps->job;\n\tbool done;\n\n\tspin_lock(&ps->lock);\n\n\twhile (job->size > 0) {\n\t\tunsigned long start, size, end;\n\n\t\tstart = job->start;\n\t\t \n\t\tsize = roundup(start + 1, ps->chunk_size) - start;\n\t\tsize = min(size, job->size);\n\t\tend = start + size;\n\n\t\tjob->start = end;\n\t\tjob->size -= size;\n\n\t\tspin_unlock(&ps->lock);\n\t\tjob->thread_fn(start, end, job->fn_arg);\n\t\tspin_lock(&ps->lock);\n\t}\n\n\t++ps->nworks_fini;\n\tdone = (ps->nworks_fini == ps->nworks);\n\tspin_unlock(&ps->lock);\n\n\tif (done)\n\t\tcomplete(&ps->completion);\n}\n\n \nvoid __init padata_do_multithreaded(struct padata_mt_job *job)\n{\n\t \n\tstatic const unsigned long load_balance_factor = 4;\n\tstruct padata_work my_work, *pw;\n\tstruct padata_mt_job_state ps;\n\tLIST_HEAD(works);\n\tint nworks;\n\n\tif (job->size == 0)\n\t\treturn;\n\n\t \n\tnworks = max(job->size / max(job->min_chunk, job->align), 1ul);\n\tnworks = min(nworks, job->max_threads);\n\n\tif (nworks == 1) {\n\t\t \n\t\tjob->thread_fn(job->start, job->start + job->size, job->fn_arg);\n\t\treturn;\n\t}\n\n\tspin_lock_init(&ps.lock);\n\tinit_completion(&ps.completion);\n\tps.job\t       = job;\n\tps.nworks      = padata_work_alloc_mt(nworks, &ps, &works);\n\tps.nworks_fini = 0;\n\n\t \n\tps.chunk_size = job->size / (ps.nworks * load_balance_factor);\n\tps.chunk_size = max(ps.chunk_size, job->min_chunk);\n\tps.chunk_size = roundup(ps.chunk_size, job->align);\n\n\tlist_for_each_entry(pw, &works, pw_list)\n\t\tqueue_work(system_unbound_wq, &pw->pw_work);\n\n\t \n\tpadata_work_init(&my_work, padata_mt_helper, &ps, PADATA_WORK_ONSTACK);\n\tpadata_mt_helper(&my_work.pw_work);\n\n\t \n\twait_for_completion(&ps.completion);\n\n\tdestroy_work_on_stack(&my_work.pw_work);\n\tpadata_works_free(&works);\n}\n\nstatic void __padata_list_init(struct padata_list *pd_list)\n{\n\tINIT_LIST_HEAD(&pd_list->list);\n\tspin_lock_init(&pd_list->lock);\n}\n\n \nstatic void padata_init_squeues(struct parallel_data *pd)\n{\n\tint cpu;\n\tstruct padata_serial_queue *squeue;\n\n\tfor_each_cpu(cpu, pd->cpumask.cbcpu) {\n\t\tsqueue = per_cpu_ptr(pd->squeue, cpu);\n\t\tsqueue->pd = pd;\n\t\t__padata_list_init(&squeue->serial);\n\t\tINIT_WORK(&squeue->work, padata_serial_worker);\n\t}\n}\n\n \nstatic void padata_init_reorder_list(struct parallel_data *pd)\n{\n\tint cpu;\n\tstruct padata_list *list;\n\n\tfor_each_cpu(cpu, pd->cpumask.pcpu) {\n\t\tlist = per_cpu_ptr(pd->reorder_list, cpu);\n\t\t__padata_list_init(list);\n\t}\n}\n\n \nstatic struct parallel_data *padata_alloc_pd(struct padata_shell *ps)\n{\n\tstruct padata_instance *pinst = ps->pinst;\n\tstruct parallel_data *pd;\n\n\tpd = kzalloc(sizeof(struct parallel_data), GFP_KERNEL);\n\tif (!pd)\n\t\tgoto err;\n\n\tpd->reorder_list = alloc_percpu(struct padata_list);\n\tif (!pd->reorder_list)\n\t\tgoto err_free_pd;\n\n\tpd->squeue = alloc_percpu(struct padata_serial_queue);\n\tif (!pd->squeue)\n\t\tgoto err_free_reorder_list;\n\n\tpd->ps = ps;\n\n\tif (!alloc_cpumask_var(&pd->cpumask.pcpu, GFP_KERNEL))\n\t\tgoto err_free_squeue;\n\tif (!alloc_cpumask_var(&pd->cpumask.cbcpu, GFP_KERNEL))\n\t\tgoto err_free_pcpu;\n\n\tcpumask_and(pd->cpumask.pcpu, pinst->cpumask.pcpu, cpu_online_mask);\n\tcpumask_and(pd->cpumask.cbcpu, pinst->cpumask.cbcpu, cpu_online_mask);\n\n\tpadata_init_reorder_list(pd);\n\tpadata_init_squeues(pd);\n\tpd->seq_nr = -1;\n\trefcount_set(&pd->refcnt, 1);\n\tspin_lock_init(&pd->lock);\n\tpd->cpu = cpumask_first(pd->cpumask.pcpu);\n\tINIT_WORK(&pd->reorder_work, invoke_padata_reorder);\n\n\treturn pd;\n\nerr_free_pcpu:\n\tfree_cpumask_var(pd->cpumask.pcpu);\nerr_free_squeue:\n\tfree_percpu(pd->squeue);\nerr_free_reorder_list:\n\tfree_percpu(pd->reorder_list);\nerr_free_pd:\n\tkfree(pd);\nerr:\n\treturn NULL;\n}\n\nstatic void padata_free_pd(struct parallel_data *pd)\n{\n\tfree_cpumask_var(pd->cpumask.pcpu);\n\tfree_cpumask_var(pd->cpumask.cbcpu);\n\tfree_percpu(pd->reorder_list);\n\tfree_percpu(pd->squeue);\n\tkfree(pd);\n}\n\nstatic void __padata_start(struct padata_instance *pinst)\n{\n\tpinst->flags |= PADATA_INIT;\n}\n\nstatic void __padata_stop(struct padata_instance *pinst)\n{\n\tif (!(pinst->flags & PADATA_INIT))\n\t\treturn;\n\n\tpinst->flags &= ~PADATA_INIT;\n\n\tsynchronize_rcu();\n}\n\n \nstatic int padata_replace_one(struct padata_shell *ps)\n{\n\tstruct parallel_data *pd_new;\n\n\tpd_new = padata_alloc_pd(ps);\n\tif (!pd_new)\n\t\treturn -ENOMEM;\n\n\tps->opd = rcu_dereference_protected(ps->pd, 1);\n\trcu_assign_pointer(ps->pd, pd_new);\n\n\treturn 0;\n}\n\nstatic int padata_replace(struct padata_instance *pinst)\n{\n\tstruct padata_shell *ps;\n\tint err = 0;\n\n\tpinst->flags |= PADATA_RESET;\n\n\tlist_for_each_entry(ps, &pinst->pslist, list) {\n\t\terr = padata_replace_one(ps);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tsynchronize_rcu();\n\n\tlist_for_each_entry_continue_reverse(ps, &pinst->pslist, list)\n\t\tif (refcount_dec_and_test(&ps->opd->refcnt))\n\t\t\tpadata_free_pd(ps->opd);\n\n\tpinst->flags &= ~PADATA_RESET;\n\n\treturn err;\n}\n\n \nstatic bool padata_validate_cpumask(struct padata_instance *pinst,\n\t\t\t\t    const struct cpumask *cpumask)\n{\n\tif (!cpumask_intersects(cpumask, cpu_online_mask)) {\n\t\tpinst->flags |= PADATA_INVALID;\n\t\treturn false;\n\t}\n\n\tpinst->flags &= ~PADATA_INVALID;\n\treturn true;\n}\n\nstatic int __padata_set_cpumasks(struct padata_instance *pinst,\n\t\t\t\t cpumask_var_t pcpumask,\n\t\t\t\t cpumask_var_t cbcpumask)\n{\n\tint valid;\n\tint err;\n\n\tvalid = padata_validate_cpumask(pinst, pcpumask);\n\tif (!valid) {\n\t\t__padata_stop(pinst);\n\t\tgoto out_replace;\n\t}\n\n\tvalid = padata_validate_cpumask(pinst, cbcpumask);\n\tif (!valid)\n\t\t__padata_stop(pinst);\n\nout_replace:\n\tcpumask_copy(pinst->cpumask.pcpu, pcpumask);\n\tcpumask_copy(pinst->cpumask.cbcpu, cbcpumask);\n\n\terr = padata_setup_cpumasks(pinst) ?: padata_replace(pinst);\n\n\tif (valid)\n\t\t__padata_start(pinst);\n\n\treturn err;\n}\n\n \nint padata_set_cpumask(struct padata_instance *pinst, int cpumask_type,\n\t\t       cpumask_var_t cpumask)\n{\n\tstruct cpumask *serial_mask, *parallel_mask;\n\tint err = -EINVAL;\n\n\tcpus_read_lock();\n\tmutex_lock(&pinst->lock);\n\n\tswitch (cpumask_type) {\n\tcase PADATA_CPU_PARALLEL:\n\t\tserial_mask = pinst->cpumask.cbcpu;\n\t\tparallel_mask = cpumask;\n\t\tbreak;\n\tcase PADATA_CPU_SERIAL:\n\t\tparallel_mask = pinst->cpumask.pcpu;\n\t\tserial_mask = cpumask;\n\t\tbreak;\n\tdefault:\n\t\t goto out;\n\t}\n\n\terr =  __padata_set_cpumasks(pinst, parallel_mask, serial_mask);\n\nout:\n\tmutex_unlock(&pinst->lock);\n\tcpus_read_unlock();\n\n\treturn err;\n}\nEXPORT_SYMBOL(padata_set_cpumask);\n\n#ifdef CONFIG_HOTPLUG_CPU\n\nstatic int __padata_add_cpu(struct padata_instance *pinst, int cpu)\n{\n\tint err = 0;\n\n\tif (cpumask_test_cpu(cpu, cpu_online_mask)) {\n\t\terr = padata_replace(pinst);\n\n\t\tif (padata_validate_cpumask(pinst, pinst->cpumask.pcpu) &&\n\t\t    padata_validate_cpumask(pinst, pinst->cpumask.cbcpu))\n\t\t\t__padata_start(pinst);\n\t}\n\n\treturn err;\n}\n\nstatic int __padata_remove_cpu(struct padata_instance *pinst, int cpu)\n{\n\tint err = 0;\n\n\tif (!cpumask_test_cpu(cpu, cpu_online_mask)) {\n\t\tif (!padata_validate_cpumask(pinst, pinst->cpumask.pcpu) ||\n\t\t    !padata_validate_cpumask(pinst, pinst->cpumask.cbcpu))\n\t\t\t__padata_stop(pinst);\n\n\t\terr = padata_replace(pinst);\n\t}\n\n\treturn err;\n}\n\nstatic inline int pinst_has_cpu(struct padata_instance *pinst, int cpu)\n{\n\treturn cpumask_test_cpu(cpu, pinst->cpumask.pcpu) ||\n\t\tcpumask_test_cpu(cpu, pinst->cpumask.cbcpu);\n}\n\nstatic int padata_cpu_online(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct padata_instance *pinst;\n\tint ret;\n\n\tpinst = hlist_entry_safe(node, struct padata_instance, cpu_online_node);\n\tif (!pinst_has_cpu(pinst, cpu))\n\t\treturn 0;\n\n\tmutex_lock(&pinst->lock);\n\tret = __padata_add_cpu(pinst, cpu);\n\tmutex_unlock(&pinst->lock);\n\treturn ret;\n}\n\nstatic int padata_cpu_dead(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct padata_instance *pinst;\n\tint ret;\n\n\tpinst = hlist_entry_safe(node, struct padata_instance, cpu_dead_node);\n\tif (!pinst_has_cpu(pinst, cpu))\n\t\treturn 0;\n\n\tmutex_lock(&pinst->lock);\n\tret = __padata_remove_cpu(pinst, cpu);\n\tmutex_unlock(&pinst->lock);\n\treturn ret;\n}\n\nstatic enum cpuhp_state hp_online;\n#endif\n\nstatic void __padata_free(struct padata_instance *pinst)\n{\n#ifdef CONFIG_HOTPLUG_CPU\n\tcpuhp_state_remove_instance_nocalls(CPUHP_PADATA_DEAD,\n\t\t\t\t\t    &pinst->cpu_dead_node);\n\tcpuhp_state_remove_instance_nocalls(hp_online, &pinst->cpu_online_node);\n#endif\n\n\tWARN_ON(!list_empty(&pinst->pslist));\n\n\tfree_cpumask_var(pinst->cpumask.pcpu);\n\tfree_cpumask_var(pinst->cpumask.cbcpu);\n\tdestroy_workqueue(pinst->serial_wq);\n\tdestroy_workqueue(pinst->parallel_wq);\n\tkfree(pinst);\n}\n\n#define kobj2pinst(_kobj)\t\t\t\t\t\\\n\tcontainer_of(_kobj, struct padata_instance, kobj)\n#define attr2pentry(_attr)\t\t\t\t\t\\\n\tcontainer_of(_attr, struct padata_sysfs_entry, attr)\n\nstatic void padata_sysfs_release(struct kobject *kobj)\n{\n\tstruct padata_instance *pinst = kobj2pinst(kobj);\n\t__padata_free(pinst);\n}\n\nstruct padata_sysfs_entry {\n\tstruct attribute attr;\n\tssize_t (*show)(struct padata_instance *, struct attribute *, char *);\n\tssize_t (*store)(struct padata_instance *, struct attribute *,\n\t\t\t const char *, size_t);\n};\n\nstatic ssize_t show_cpumask(struct padata_instance *pinst,\n\t\t\t    struct attribute *attr,  char *buf)\n{\n\tstruct cpumask *cpumask;\n\tssize_t len;\n\n\tmutex_lock(&pinst->lock);\n\tif (!strcmp(attr->name, \"serial_cpumask\"))\n\t\tcpumask = pinst->cpumask.cbcpu;\n\telse\n\t\tcpumask = pinst->cpumask.pcpu;\n\n\tlen = snprintf(buf, PAGE_SIZE, \"%*pb\\n\",\n\t\t       nr_cpu_ids, cpumask_bits(cpumask));\n\tmutex_unlock(&pinst->lock);\n\treturn len < PAGE_SIZE ? len : -EINVAL;\n}\n\nstatic ssize_t store_cpumask(struct padata_instance *pinst,\n\t\t\t     struct attribute *attr,\n\t\t\t     const char *buf, size_t count)\n{\n\tcpumask_var_t new_cpumask;\n\tssize_t ret;\n\tint mask_type;\n\n\tif (!alloc_cpumask_var(&new_cpumask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\tret = bitmap_parse(buf, count, cpumask_bits(new_cpumask),\n\t\t\t   nr_cpumask_bits);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tmask_type = !strcmp(attr->name, \"serial_cpumask\") ?\n\t\tPADATA_CPU_SERIAL : PADATA_CPU_PARALLEL;\n\tret = padata_set_cpumask(pinst, mask_type, new_cpumask);\n\tif (!ret)\n\t\tret = count;\n\nout:\n\tfree_cpumask_var(new_cpumask);\n\treturn ret;\n}\n\n#define PADATA_ATTR_RW(_name, _show_name, _store_name)\t\t\\\n\tstatic struct padata_sysfs_entry _name##_attr =\t\t\\\n\t\t__ATTR(_name, 0644, _show_name, _store_name)\n#define PADATA_ATTR_RO(_name, _show_name)\t\t\\\n\tstatic struct padata_sysfs_entry _name##_attr = \\\n\t\t__ATTR(_name, 0400, _show_name, NULL)\n\nPADATA_ATTR_RW(serial_cpumask, show_cpumask, store_cpumask);\nPADATA_ATTR_RW(parallel_cpumask, show_cpumask, store_cpumask);\n\n \nstatic struct attribute *padata_default_attrs[] = {\n\t&serial_cpumask_attr.attr,\n\t&parallel_cpumask_attr.attr,\n\tNULL,\n};\nATTRIBUTE_GROUPS(padata_default);\n\nstatic ssize_t padata_sysfs_show(struct kobject *kobj,\n\t\t\t\t struct attribute *attr, char *buf)\n{\n\tstruct padata_instance *pinst;\n\tstruct padata_sysfs_entry *pentry;\n\tssize_t ret = -EIO;\n\n\tpinst = kobj2pinst(kobj);\n\tpentry = attr2pentry(attr);\n\tif (pentry->show)\n\t\tret = pentry->show(pinst, attr, buf);\n\n\treturn ret;\n}\n\nstatic ssize_t padata_sysfs_store(struct kobject *kobj, struct attribute *attr,\n\t\t\t\t  const char *buf, size_t count)\n{\n\tstruct padata_instance *pinst;\n\tstruct padata_sysfs_entry *pentry;\n\tssize_t ret = -EIO;\n\n\tpinst = kobj2pinst(kobj);\n\tpentry = attr2pentry(attr);\n\tif (pentry->show)\n\t\tret = pentry->store(pinst, attr, buf, count);\n\n\treturn ret;\n}\n\nstatic const struct sysfs_ops padata_sysfs_ops = {\n\t.show = padata_sysfs_show,\n\t.store = padata_sysfs_store,\n};\n\nstatic const struct kobj_type padata_attr_type = {\n\t.sysfs_ops = &padata_sysfs_ops,\n\t.default_groups = padata_default_groups,\n\t.release = padata_sysfs_release,\n};\n\n \nstruct padata_instance *padata_alloc(const char *name)\n{\n\tstruct padata_instance *pinst;\n\n\tpinst = kzalloc(sizeof(struct padata_instance), GFP_KERNEL);\n\tif (!pinst)\n\t\tgoto err;\n\n\tpinst->parallel_wq = alloc_workqueue(\"%s_parallel\", WQ_UNBOUND, 0,\n\t\t\t\t\t     name);\n\tif (!pinst->parallel_wq)\n\t\tgoto err_free_inst;\n\n\tcpus_read_lock();\n\n\tpinst->serial_wq = alloc_workqueue(\"%s_serial\", WQ_MEM_RECLAIM |\n\t\t\t\t\t   WQ_CPU_INTENSIVE, 1, name);\n\tif (!pinst->serial_wq)\n\t\tgoto err_put_cpus;\n\n\tif (!alloc_cpumask_var(&pinst->cpumask.pcpu, GFP_KERNEL))\n\t\tgoto err_free_serial_wq;\n\tif (!alloc_cpumask_var(&pinst->cpumask.cbcpu, GFP_KERNEL)) {\n\t\tfree_cpumask_var(pinst->cpumask.pcpu);\n\t\tgoto err_free_serial_wq;\n\t}\n\n\tINIT_LIST_HEAD(&pinst->pslist);\n\n\tcpumask_copy(pinst->cpumask.pcpu, cpu_possible_mask);\n\tcpumask_copy(pinst->cpumask.cbcpu, cpu_possible_mask);\n\n\tif (padata_setup_cpumasks(pinst))\n\t\tgoto err_free_masks;\n\n\t__padata_start(pinst);\n\n\tkobject_init(&pinst->kobj, &padata_attr_type);\n\tmutex_init(&pinst->lock);\n\n#ifdef CONFIG_HOTPLUG_CPU\n\tcpuhp_state_add_instance_nocalls_cpuslocked(hp_online,\n\t\t\t\t\t\t    &pinst->cpu_online_node);\n\tcpuhp_state_add_instance_nocalls_cpuslocked(CPUHP_PADATA_DEAD,\n\t\t\t\t\t\t    &pinst->cpu_dead_node);\n#endif\n\n\tcpus_read_unlock();\n\n\treturn pinst;\n\nerr_free_masks:\n\tfree_cpumask_var(pinst->cpumask.pcpu);\n\tfree_cpumask_var(pinst->cpumask.cbcpu);\nerr_free_serial_wq:\n\tdestroy_workqueue(pinst->serial_wq);\nerr_put_cpus:\n\tcpus_read_unlock();\n\tdestroy_workqueue(pinst->parallel_wq);\nerr_free_inst:\n\tkfree(pinst);\nerr:\n\treturn NULL;\n}\nEXPORT_SYMBOL(padata_alloc);\n\n \nvoid padata_free(struct padata_instance *pinst)\n{\n\tkobject_put(&pinst->kobj);\n}\nEXPORT_SYMBOL(padata_free);\n\n \nstruct padata_shell *padata_alloc_shell(struct padata_instance *pinst)\n{\n\tstruct parallel_data *pd;\n\tstruct padata_shell *ps;\n\n\tps = kzalloc(sizeof(*ps), GFP_KERNEL);\n\tif (!ps)\n\t\tgoto out;\n\n\tps->pinst = pinst;\n\n\tcpus_read_lock();\n\tpd = padata_alloc_pd(ps);\n\tcpus_read_unlock();\n\n\tif (!pd)\n\t\tgoto out_free_ps;\n\n\tmutex_lock(&pinst->lock);\n\tRCU_INIT_POINTER(ps->pd, pd);\n\tlist_add(&ps->list, &pinst->pslist);\n\tmutex_unlock(&pinst->lock);\n\n\treturn ps;\n\nout_free_ps:\n\tkfree(ps);\nout:\n\treturn NULL;\n}\nEXPORT_SYMBOL(padata_alloc_shell);\n\n \nvoid padata_free_shell(struct padata_shell *ps)\n{\n\tstruct parallel_data *pd;\n\n\tif (!ps)\n\t\treturn;\n\n\tmutex_lock(&ps->pinst->lock);\n\tlist_del(&ps->list);\n\tpd = rcu_dereference_protected(ps->pd, 1);\n\tif (refcount_dec_and_test(&pd->refcnt))\n\t\tpadata_free_pd(pd);\n\tmutex_unlock(&ps->pinst->lock);\n\n\tkfree(ps);\n}\nEXPORT_SYMBOL(padata_free_shell);\n\nvoid __init padata_init(void)\n{\n\tunsigned int i, possible_cpus;\n#ifdef CONFIG_HOTPLUG_CPU\n\tint ret;\n\n\tret = cpuhp_setup_state_multi(CPUHP_AP_ONLINE_DYN, \"padata:online\",\n\t\t\t\t      padata_cpu_online, NULL);\n\tif (ret < 0)\n\t\tgoto err;\n\thp_online = ret;\n\n\tret = cpuhp_setup_state_multi(CPUHP_PADATA_DEAD, \"padata:dead\",\n\t\t\t\t      NULL, padata_cpu_dead);\n\tif (ret < 0)\n\t\tgoto remove_online_state;\n#endif\n\n\tpossible_cpus = num_possible_cpus();\n\tpadata_works = kmalloc_array(possible_cpus, sizeof(struct padata_work),\n\t\t\t\t     GFP_KERNEL);\n\tif (!padata_works)\n\t\tgoto remove_dead_state;\n\n\tfor (i = 0; i < possible_cpus; ++i)\n\t\tlist_add(&padata_works[i].pw_list, &padata_free_works);\n\n\treturn;\n\nremove_dead_state:\n#ifdef CONFIG_HOTPLUG_CPU\n\tcpuhp_remove_multi_state(CPUHP_PADATA_DEAD);\nremove_online_state:\n\tcpuhp_remove_multi_state(hp_online);\nerr:\n#endif\n\tpr_warn(\"padata: initialization failed\\n\");\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}