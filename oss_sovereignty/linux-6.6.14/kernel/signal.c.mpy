{
  "module_name": "signal.c",
  "hash_id": "404a1075b26729397a3ab977885bd4ea2687db8c8d681ebc2b6201ee8b6e0e72",
  "original_prompt": "Ingested from linux-6.6.14/kernel/signal.c",
  "human_readable_source": "\n \n\n#include <linux/slab.h>\n#include <linux/export.h>\n#include <linux/init.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/user.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/cputime.h>\n#include <linux/file.h>\n#include <linux/fs.h>\n#include <linux/mm.h>\n#include <linux/proc_fs.h>\n#include <linux/tty.h>\n#include <linux/binfmts.h>\n#include <linux/coredump.h>\n#include <linux/security.h>\n#include <linux/syscalls.h>\n#include <linux/ptrace.h>\n#include <linux/signal.h>\n#include <linux/signalfd.h>\n#include <linux/ratelimit.h>\n#include <linux/task_work.h>\n#include <linux/capability.h>\n#include <linux/freezer.h>\n#include <linux/pid_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/user_namespace.h>\n#include <linux/uprobes.h>\n#include <linux/compat.h>\n#include <linux/cn_proc.h>\n#include <linux/compiler.h>\n#include <linux/posix-timers.h>\n#include <linux/cgroup.h>\n#include <linux/audit.h>\n#include <linux/sysctl.h>\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/signal.h>\n\n#include <asm/param.h>\n#include <linux/uaccess.h>\n#include <asm/unistd.h>\n#include <asm/siginfo.h>\n#include <asm/cacheflush.h>\n#include <asm/syscall.h>\t \n\n \n\nstatic struct kmem_cache *sigqueue_cachep;\n\nint print_fatal_signals __read_mostly;\n\nstatic void __user *sig_handler(struct task_struct *t, int sig)\n{\n\treturn t->sighand->action[sig - 1].sa.sa_handler;\n}\n\nstatic inline bool sig_handler_ignored(void __user *handler, int sig)\n{\n\t \n\treturn handler == SIG_IGN ||\n\t       (handler == SIG_DFL && sig_kernel_ignore(sig));\n}\n\nstatic bool sig_task_ignored(struct task_struct *t, int sig, bool force)\n{\n\tvoid __user *handler;\n\n\thandler = sig_handler(t, sig);\n\n\t \n\tif (unlikely(is_global_init(t) && sig_kernel_only(sig)))\n\t\treturn true;\n\n\tif (unlikely(t->signal->flags & SIGNAL_UNKILLABLE) &&\n\t    handler == SIG_DFL && !(force && sig_kernel_only(sig)))\n\t\treturn true;\n\n\t \n\tif (unlikely((t->flags & PF_KTHREAD) &&\n\t\t     (handler == SIG_KTHREAD_KERNEL) && !force))\n\t\treturn true;\n\n\treturn sig_handler_ignored(handler, sig);\n}\n\nstatic bool sig_ignored(struct task_struct *t, int sig, bool force)\n{\n\t \n\tif (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))\n\t\treturn false;\n\n\t \n\tif (t->ptrace && sig != SIGKILL)\n\t\treturn false;\n\n\treturn sig_task_ignored(t, sig, force);\n}\n\n \nstatic inline bool has_pending_signals(sigset_t *signal, sigset_t *blocked)\n{\n\tunsigned long ready;\n\tlong i;\n\n\tswitch (_NSIG_WORDS) {\n\tdefault:\n\t\tfor (i = _NSIG_WORDS, ready = 0; --i >= 0 ;)\n\t\t\tready |= signal->sig[i] &~ blocked->sig[i];\n\t\tbreak;\n\n\tcase 4: ready  = signal->sig[3] &~ blocked->sig[3];\n\t\tready |= signal->sig[2] &~ blocked->sig[2];\n\t\tready |= signal->sig[1] &~ blocked->sig[1];\n\t\tready |= signal->sig[0] &~ blocked->sig[0];\n\t\tbreak;\n\n\tcase 2: ready  = signal->sig[1] &~ blocked->sig[1];\n\t\tready |= signal->sig[0] &~ blocked->sig[0];\n\t\tbreak;\n\n\tcase 1: ready  = signal->sig[0] &~ blocked->sig[0];\n\t}\n\treturn ready !=\t0;\n}\n\n#define PENDING(p,b) has_pending_signals(&(p)->signal, (b))\n\nstatic bool recalc_sigpending_tsk(struct task_struct *t)\n{\n\tif ((t->jobctl & (JOBCTL_PENDING_MASK | JOBCTL_TRAP_FREEZE)) ||\n\t    PENDING(&t->pending, &t->blocked) ||\n\t    PENDING(&t->signal->shared_pending, &t->blocked) ||\n\t    cgroup_task_frozen(t)) {\n\t\tset_tsk_thread_flag(t, TIF_SIGPENDING);\n\t\treturn true;\n\t}\n\n\t \n\treturn false;\n}\n\n \nvoid recalc_sigpending_and_wake(struct task_struct *t)\n{\n\tif (recalc_sigpending_tsk(t))\n\t\tsignal_wake_up(t, 0);\n}\n\nvoid recalc_sigpending(void)\n{\n\tif (!recalc_sigpending_tsk(current) && !freezing(current))\n\t\tclear_thread_flag(TIF_SIGPENDING);\n\n}\nEXPORT_SYMBOL(recalc_sigpending);\n\nvoid calculate_sigpending(void)\n{\n\t \n\tspin_lock_irq(&current->sighand->siglock);\n\tset_tsk_thread_flag(current, TIF_SIGPENDING);\n\trecalc_sigpending();\n\tspin_unlock_irq(&current->sighand->siglock);\n}\n\n \n\n#define SYNCHRONOUS_MASK \\\n\t(sigmask(SIGSEGV) | sigmask(SIGBUS) | sigmask(SIGILL) | \\\n\t sigmask(SIGTRAP) | sigmask(SIGFPE) | sigmask(SIGSYS))\n\nint next_signal(struct sigpending *pending, sigset_t *mask)\n{\n\tunsigned long i, *s, *m, x;\n\tint sig = 0;\n\n\ts = pending->signal.sig;\n\tm = mask->sig;\n\n\t \n\tx = *s &~ *m;\n\tif (x) {\n\t\tif (x & SYNCHRONOUS_MASK)\n\t\t\tx &= SYNCHRONOUS_MASK;\n\t\tsig = ffz(~x) + 1;\n\t\treturn sig;\n\t}\n\n\tswitch (_NSIG_WORDS) {\n\tdefault:\n\t\tfor (i = 1; i < _NSIG_WORDS; ++i) {\n\t\t\tx = *++s &~ *++m;\n\t\t\tif (!x)\n\t\t\t\tcontinue;\n\t\t\tsig = ffz(~x) + i*_NSIG_BPW + 1;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tcase 2:\n\t\tx = s[1] &~ m[1];\n\t\tif (!x)\n\t\t\tbreak;\n\t\tsig = ffz(~x) + _NSIG_BPW + 1;\n\t\tbreak;\n\n\tcase 1:\n\t\t \n\t\tbreak;\n\t}\n\n\treturn sig;\n}\n\nstatic inline void print_dropped_signal(int sig)\n{\n\tstatic DEFINE_RATELIMIT_STATE(ratelimit_state, 5 * HZ, 10);\n\n\tif (!print_fatal_signals)\n\t\treturn;\n\n\tif (!__ratelimit(&ratelimit_state))\n\t\treturn;\n\n\tpr_info(\"%s/%d: reached RLIMIT_SIGPENDING, dropped signal %d\\n\",\n\t\t\t\tcurrent->comm, current->pid, sig);\n}\n\n \nbool task_set_jobctl_pending(struct task_struct *task, unsigned long mask)\n{\n\tBUG_ON(mask & ~(JOBCTL_PENDING_MASK | JOBCTL_STOP_CONSUME |\n\t\t\tJOBCTL_STOP_SIGMASK | JOBCTL_TRAPPING));\n\tBUG_ON((mask & JOBCTL_TRAPPING) && !(mask & JOBCTL_PENDING_MASK));\n\n\tif (unlikely(fatal_signal_pending(task) || (task->flags & PF_EXITING)))\n\t\treturn false;\n\n\tif (mask & JOBCTL_STOP_SIGMASK)\n\t\ttask->jobctl &= ~JOBCTL_STOP_SIGMASK;\n\n\ttask->jobctl |= mask;\n\treturn true;\n}\n\n \nvoid task_clear_jobctl_trapping(struct task_struct *task)\n{\n\tif (unlikely(task->jobctl & JOBCTL_TRAPPING)) {\n\t\ttask->jobctl &= ~JOBCTL_TRAPPING;\n\t\tsmp_mb();\t \n\t\twake_up_bit(&task->jobctl, JOBCTL_TRAPPING_BIT);\n\t}\n}\n\n \nvoid task_clear_jobctl_pending(struct task_struct *task, unsigned long mask)\n{\n\tBUG_ON(mask & ~JOBCTL_PENDING_MASK);\n\n\tif (mask & JOBCTL_STOP_PENDING)\n\t\tmask |= JOBCTL_STOP_CONSUME | JOBCTL_STOP_DEQUEUED;\n\n\ttask->jobctl &= ~mask;\n\n\tif (!(task->jobctl & JOBCTL_PENDING_MASK))\n\t\ttask_clear_jobctl_trapping(task);\n}\n\n \nstatic bool task_participate_group_stop(struct task_struct *task)\n{\n\tstruct signal_struct *sig = task->signal;\n\tbool consume = task->jobctl & JOBCTL_STOP_CONSUME;\n\n\tWARN_ON_ONCE(!(task->jobctl & JOBCTL_STOP_PENDING));\n\n\ttask_clear_jobctl_pending(task, JOBCTL_STOP_PENDING);\n\n\tif (!consume)\n\t\treturn false;\n\n\tif (!WARN_ON_ONCE(sig->group_stop_count == 0))\n\t\tsig->group_stop_count--;\n\n\t \n\tif (!sig->group_stop_count && !(sig->flags & SIGNAL_STOP_STOPPED)) {\n\t\tsignal_set_stop_flags(sig, SIGNAL_STOP_STOPPED);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nvoid task_join_group_stop(struct task_struct *task)\n{\n\tunsigned long mask = current->jobctl & JOBCTL_STOP_SIGMASK;\n\tstruct signal_struct *sig = current->signal;\n\n\tif (sig->group_stop_count) {\n\t\tsig->group_stop_count++;\n\t\tmask |= JOBCTL_STOP_CONSUME;\n\t} else if (!(sig->flags & SIGNAL_STOP_STOPPED))\n\t\treturn;\n\n\t \n\ttask_set_jobctl_pending(task, mask | JOBCTL_STOP_PENDING);\n}\n\n \nstatic struct sigqueue *\n__sigqueue_alloc(int sig, struct task_struct *t, gfp_t gfp_flags,\n\t\t int override_rlimit, const unsigned int sigqueue_flags)\n{\n\tstruct sigqueue *q = NULL;\n\tstruct ucounts *ucounts = NULL;\n\tlong sigpending;\n\n\t \n\trcu_read_lock();\n\tucounts = task_ucounts(t);\n\tsigpending = inc_rlimit_get_ucounts(ucounts, UCOUNT_RLIMIT_SIGPENDING);\n\trcu_read_unlock();\n\tif (!sigpending)\n\t\treturn NULL;\n\n\tif (override_rlimit || likely(sigpending <= task_rlimit(t, RLIMIT_SIGPENDING))) {\n\t\tq = kmem_cache_alloc(sigqueue_cachep, gfp_flags);\n\t} else {\n\t\tprint_dropped_signal(sig);\n\t}\n\n\tif (unlikely(q == NULL)) {\n\t\tdec_rlimit_put_ucounts(ucounts, UCOUNT_RLIMIT_SIGPENDING);\n\t} else {\n\t\tINIT_LIST_HEAD(&q->list);\n\t\tq->flags = sigqueue_flags;\n\t\tq->ucounts = ucounts;\n\t}\n\treturn q;\n}\n\nstatic void __sigqueue_free(struct sigqueue *q)\n{\n\tif (q->flags & SIGQUEUE_PREALLOC)\n\t\treturn;\n\tif (q->ucounts) {\n\t\tdec_rlimit_put_ucounts(q->ucounts, UCOUNT_RLIMIT_SIGPENDING);\n\t\tq->ucounts = NULL;\n\t}\n\tkmem_cache_free(sigqueue_cachep, q);\n}\n\nvoid flush_sigqueue(struct sigpending *queue)\n{\n\tstruct sigqueue *q;\n\n\tsigemptyset(&queue->signal);\n\twhile (!list_empty(&queue->list)) {\n\t\tq = list_entry(queue->list.next, struct sigqueue , list);\n\t\tlist_del_init(&q->list);\n\t\t__sigqueue_free(q);\n\t}\n}\n\n \nvoid flush_signals(struct task_struct *t)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&t->sighand->siglock, flags);\n\tclear_tsk_thread_flag(t, TIF_SIGPENDING);\n\tflush_sigqueue(&t->pending);\n\tflush_sigqueue(&t->signal->shared_pending);\n\tspin_unlock_irqrestore(&t->sighand->siglock, flags);\n}\nEXPORT_SYMBOL(flush_signals);\n\n#ifdef CONFIG_POSIX_TIMERS\nstatic void __flush_itimer_signals(struct sigpending *pending)\n{\n\tsigset_t signal, retain;\n\tstruct sigqueue *q, *n;\n\n\tsignal = pending->signal;\n\tsigemptyset(&retain);\n\n\tlist_for_each_entry_safe(q, n, &pending->list, list) {\n\t\tint sig = q->info.si_signo;\n\n\t\tif (likely(q->info.si_code != SI_TIMER)) {\n\t\t\tsigaddset(&retain, sig);\n\t\t} else {\n\t\t\tsigdelset(&signal, sig);\n\t\t\tlist_del_init(&q->list);\n\t\t\t__sigqueue_free(q);\n\t\t}\n\t}\n\n\tsigorsets(&pending->signal, &signal, &retain);\n}\n\nvoid flush_itimer_signals(void)\n{\n\tstruct task_struct *tsk = current;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&tsk->sighand->siglock, flags);\n\t__flush_itimer_signals(&tsk->pending);\n\t__flush_itimer_signals(&tsk->signal->shared_pending);\n\tspin_unlock_irqrestore(&tsk->sighand->siglock, flags);\n}\n#endif\n\nvoid ignore_signals(struct task_struct *t)\n{\n\tint i;\n\n\tfor (i = 0; i < _NSIG; ++i)\n\t\tt->sighand->action[i].sa.sa_handler = SIG_IGN;\n\n\tflush_signals(t);\n}\n\n \n\nvoid\nflush_signal_handlers(struct task_struct *t, int force_default)\n{\n\tint i;\n\tstruct k_sigaction *ka = &t->sighand->action[0];\n\tfor (i = _NSIG ; i != 0 ; i--) {\n\t\tif (force_default || ka->sa.sa_handler != SIG_IGN)\n\t\t\tka->sa.sa_handler = SIG_DFL;\n\t\tka->sa.sa_flags = 0;\n#ifdef __ARCH_HAS_SA_RESTORER\n\t\tka->sa.sa_restorer = NULL;\n#endif\n\t\tsigemptyset(&ka->sa.sa_mask);\n\t\tka++;\n\t}\n}\n\nbool unhandled_signal(struct task_struct *tsk, int sig)\n{\n\tvoid __user *handler = tsk->sighand->action[sig-1].sa.sa_handler;\n\tif (is_global_init(tsk))\n\t\treturn true;\n\n\tif (handler != SIG_IGN && handler != SIG_DFL)\n\t\treturn false;\n\n\t \n\tif (fatal_signal_pending(tsk))\n\t\treturn false;\n\n\t \n\treturn !tsk->ptrace;\n}\n\nstatic void collect_signal(int sig, struct sigpending *list, kernel_siginfo_t *info,\n\t\t\t   bool *resched_timer)\n{\n\tstruct sigqueue *q, *first = NULL;\n\n\t \n\tlist_for_each_entry(q, &list->list, list) {\n\t\tif (q->info.si_signo == sig) {\n\t\t\tif (first)\n\t\t\t\tgoto still_pending;\n\t\t\tfirst = q;\n\t\t}\n\t}\n\n\tsigdelset(&list->signal, sig);\n\n\tif (first) {\nstill_pending:\n\t\tlist_del_init(&first->list);\n\t\tcopy_siginfo(info, &first->info);\n\n\t\t*resched_timer =\n\t\t\t(first->flags & SIGQUEUE_PREALLOC) &&\n\t\t\t(info->si_code == SI_TIMER) &&\n\t\t\t(info->si_sys_private);\n\n\t\t__sigqueue_free(first);\n\t} else {\n\t\t \n\t\tclear_siginfo(info);\n\t\tinfo->si_signo = sig;\n\t\tinfo->si_errno = 0;\n\t\tinfo->si_code = SI_USER;\n\t\tinfo->si_pid = 0;\n\t\tinfo->si_uid = 0;\n\t}\n}\n\nstatic int __dequeue_signal(struct sigpending *pending, sigset_t *mask,\n\t\t\tkernel_siginfo_t *info, bool *resched_timer)\n{\n\tint sig = next_signal(pending, mask);\n\n\tif (sig)\n\t\tcollect_signal(sig, pending, info, resched_timer);\n\treturn sig;\n}\n\n \nint dequeue_signal(struct task_struct *tsk, sigset_t *mask,\n\t\t   kernel_siginfo_t *info, enum pid_type *type)\n{\n\tbool resched_timer = false;\n\tint signr;\n\n\t \n\t*type = PIDTYPE_PID;\n\tsignr = __dequeue_signal(&tsk->pending, mask, info, &resched_timer);\n\tif (!signr) {\n\t\t*type = PIDTYPE_TGID;\n\t\tsignr = __dequeue_signal(&tsk->signal->shared_pending,\n\t\t\t\t\t mask, info, &resched_timer);\n#ifdef CONFIG_POSIX_TIMERS\n\t\t \n\t\tif (unlikely(signr == SIGALRM)) {\n\t\t\tstruct hrtimer *tmr = &tsk->signal->real_timer;\n\n\t\t\tif (!hrtimer_is_queued(tmr) &&\n\t\t\t    tsk->signal->it_real_incr != 0) {\n\t\t\t\thrtimer_forward(tmr, tmr->base->get_time(),\n\t\t\t\t\t\ttsk->signal->it_real_incr);\n\t\t\t\thrtimer_restart(tmr);\n\t\t\t}\n\t\t}\n#endif\n\t}\n\n\trecalc_sigpending();\n\tif (!signr)\n\t\treturn 0;\n\n\tif (unlikely(sig_kernel_stop(signr))) {\n\t\t \n\t\tcurrent->jobctl |= JOBCTL_STOP_DEQUEUED;\n\t}\n#ifdef CONFIG_POSIX_TIMERS\n\tif (resched_timer) {\n\t\t \n\t\tspin_unlock(&tsk->sighand->siglock);\n\t\tposixtimer_rearm(info);\n\t\tspin_lock(&tsk->sighand->siglock);\n\n\t\t \n\t\tinfo->si_sys_private = 0;\n\t}\n#endif\n\treturn signr;\n}\nEXPORT_SYMBOL_GPL(dequeue_signal);\n\nstatic int dequeue_synchronous_signal(kernel_siginfo_t *info)\n{\n\tstruct task_struct *tsk = current;\n\tstruct sigpending *pending = &tsk->pending;\n\tstruct sigqueue *q, *sync = NULL;\n\n\t \n\tif (!((pending->signal.sig[0] & ~tsk->blocked.sig[0]) & SYNCHRONOUS_MASK))\n\t\treturn 0;\n\n\t \n\tlist_for_each_entry(q, &pending->list, list) {\n\t\t \n\t\tif ((q->info.si_code > SI_USER) &&\n\t\t    (sigmask(q->info.si_signo) & SYNCHRONOUS_MASK)) {\n\t\t\tsync = q;\n\t\t\tgoto next;\n\t\t}\n\t}\n\treturn 0;\nnext:\n\t \n\tlist_for_each_entry_continue(q, &pending->list, list) {\n\t\tif (q->info.si_signo == sync->info.si_signo)\n\t\t\tgoto still_pending;\n\t}\n\n\tsigdelset(&pending->signal, sync->info.si_signo);\n\trecalc_sigpending();\nstill_pending:\n\tlist_del_init(&sync->list);\n\tcopy_siginfo(info, &sync->info);\n\t__sigqueue_free(sync);\n\treturn info->si_signo;\n}\n\n \nvoid signal_wake_up_state(struct task_struct *t, unsigned int state)\n{\n\tlockdep_assert_held(&t->sighand->siglock);\n\n\tset_tsk_thread_flag(t, TIF_SIGPENDING);\n\n\t \n\tif (!wake_up_state(t, state | TASK_INTERRUPTIBLE))\n\t\tkick_process(t);\n}\n\n \nstatic void flush_sigqueue_mask(sigset_t *mask, struct sigpending *s)\n{\n\tstruct sigqueue *q, *n;\n\tsigset_t m;\n\n\tsigandsets(&m, mask, &s->signal);\n\tif (sigisemptyset(&m))\n\t\treturn;\n\n\tsigandnsets(&s->signal, &s->signal, mask);\n\tlist_for_each_entry_safe(q, n, &s->list, list) {\n\t\tif (sigismember(mask, q->info.si_signo)) {\n\t\t\tlist_del_init(&q->list);\n\t\t\t__sigqueue_free(q);\n\t\t}\n\t}\n}\n\nstatic inline int is_si_special(const struct kernel_siginfo *info)\n{\n\treturn info <= SEND_SIG_PRIV;\n}\n\nstatic inline bool si_fromuser(const struct kernel_siginfo *info)\n{\n\treturn info == SEND_SIG_NOINFO ||\n\t\t(!is_si_special(info) && SI_FROMUSER(info));\n}\n\n \nstatic bool kill_ok_by_cred(struct task_struct *t)\n{\n\tconst struct cred *cred = current_cred();\n\tconst struct cred *tcred = __task_cred(t);\n\n\treturn uid_eq(cred->euid, tcred->suid) ||\n\t       uid_eq(cred->euid, tcred->uid) ||\n\t       uid_eq(cred->uid, tcred->suid) ||\n\t       uid_eq(cred->uid, tcred->uid) ||\n\t       ns_capable(tcred->user_ns, CAP_KILL);\n}\n\n \nstatic int check_kill_permission(int sig, struct kernel_siginfo *info,\n\t\t\t\t struct task_struct *t)\n{\n\tstruct pid *sid;\n\tint error;\n\n\tif (!valid_signal(sig))\n\t\treturn -EINVAL;\n\n\tif (!si_fromuser(info))\n\t\treturn 0;\n\n\terror = audit_signal_info(sig, t);  \n\tif (error)\n\t\treturn error;\n\n\tif (!same_thread_group(current, t) &&\n\t    !kill_ok_by_cred(t)) {\n\t\tswitch (sig) {\n\t\tcase SIGCONT:\n\t\t\tsid = task_session(t);\n\t\t\t \n\t\t\tif (!sid || sid == task_session(current))\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tdefault:\n\t\t\treturn -EPERM;\n\t\t}\n\t}\n\n\treturn security_task_kill(t, info, sig, NULL);\n}\n\n \nstatic void ptrace_trap_notify(struct task_struct *t)\n{\n\tWARN_ON_ONCE(!(t->ptrace & PT_SEIZED));\n\tlockdep_assert_held(&t->sighand->siglock);\n\n\ttask_set_jobctl_pending(t, JOBCTL_TRAP_NOTIFY);\n\tptrace_signal_wake_up(t, t->jobctl & JOBCTL_LISTENING);\n}\n\n \nstatic bool prepare_signal(int sig, struct task_struct *p, bool force)\n{\n\tstruct signal_struct *signal = p->signal;\n\tstruct task_struct *t;\n\tsigset_t flush;\n\n\tif (signal->flags & SIGNAL_GROUP_EXIT) {\n\t\tif (signal->core_state)\n\t\t\treturn sig == SIGKILL;\n\t\t \n\t\treturn false;\n\t} else if (sig_kernel_stop(sig)) {\n\t\t \n\t\tsiginitset(&flush, sigmask(SIGCONT));\n\t\tflush_sigqueue_mask(&flush, &signal->shared_pending);\n\t\tfor_each_thread(p, t)\n\t\t\tflush_sigqueue_mask(&flush, &t->pending);\n\t} else if (sig == SIGCONT) {\n\t\tunsigned int why;\n\t\t \n\t\tsiginitset(&flush, SIG_KERNEL_STOP_MASK);\n\t\tflush_sigqueue_mask(&flush, &signal->shared_pending);\n\t\tfor_each_thread(p, t) {\n\t\t\tflush_sigqueue_mask(&flush, &t->pending);\n\t\t\ttask_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);\n\t\t\tif (likely(!(t->ptrace & PT_SEIZED))) {\n\t\t\t\tt->jobctl &= ~JOBCTL_STOPPED;\n\t\t\t\twake_up_state(t, __TASK_STOPPED);\n\t\t\t} else\n\t\t\t\tptrace_trap_notify(t);\n\t\t}\n\n\t\t \n\t\twhy = 0;\n\t\tif (signal->flags & SIGNAL_STOP_STOPPED)\n\t\t\twhy |= SIGNAL_CLD_CONTINUED;\n\t\telse if (signal->group_stop_count)\n\t\t\twhy |= SIGNAL_CLD_STOPPED;\n\n\t\tif (why) {\n\t\t\t \n\t\t\tsignal_set_stop_flags(signal, why | SIGNAL_STOP_CONTINUED);\n\t\t\tsignal->group_stop_count = 0;\n\t\t\tsignal->group_exit_code = 0;\n\t\t}\n\t}\n\n\treturn !sig_ignored(p, sig, force);\n}\n\n \nstatic inline bool wants_signal(int sig, struct task_struct *p)\n{\n\tif (sigismember(&p->blocked, sig))\n\t\treturn false;\n\n\tif (p->flags & PF_EXITING)\n\t\treturn false;\n\n\tif (sig == SIGKILL)\n\t\treturn true;\n\n\tif (task_is_stopped_or_traced(p))\n\t\treturn false;\n\n\treturn task_curr(p) || !task_sigpending(p);\n}\n\nstatic void complete_signal(int sig, struct task_struct *p, enum pid_type type)\n{\n\tstruct signal_struct *signal = p->signal;\n\tstruct task_struct *t;\n\n\t \n\tif (wants_signal(sig, p))\n\t\tt = p;\n\telse if ((type == PIDTYPE_PID) || thread_group_empty(p))\n\t\t \n\t\treturn;\n\telse {\n\t\t \n\t\tt = signal->curr_target;\n\t\twhile (!wants_signal(sig, t)) {\n\t\t\tt = next_thread(t);\n\t\t\tif (t == signal->curr_target)\n\t\t\t\t \n\t\t\t\treturn;\n\t\t}\n\t\tsignal->curr_target = t;\n\t}\n\n\t \n\tif (sig_fatal(p, sig) &&\n\t    (signal->core_state || !(signal->flags & SIGNAL_GROUP_EXIT)) &&\n\t    !sigismember(&t->real_blocked, sig) &&\n\t    (sig == SIGKILL || !p->ptrace)) {\n\t\t \n\t\tif (!sig_kernel_coredump(sig)) {\n\t\t\t \n\t\t\tsignal->flags = SIGNAL_GROUP_EXIT;\n\t\t\tsignal->group_exit_code = sig;\n\t\t\tsignal->group_stop_count = 0;\n\t\t\tt = p;\n\t\t\tdo {\n\t\t\t\ttask_clear_jobctl_pending(t, JOBCTL_PENDING_MASK);\n\t\t\t\tsigaddset(&t->pending.signal, SIGKILL);\n\t\t\t\tsignal_wake_up(t, 1);\n\t\t\t} while_each_thread(p, t);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t \n\tsignal_wake_up(t, sig == SIGKILL);\n\treturn;\n}\n\nstatic inline bool legacy_queue(struct sigpending *signals, int sig)\n{\n\treturn (sig < SIGRTMIN) && sigismember(&signals->signal, sig);\n}\n\nstatic int __send_signal_locked(int sig, struct kernel_siginfo *info,\n\t\t\t\tstruct task_struct *t, enum pid_type type, bool force)\n{\n\tstruct sigpending *pending;\n\tstruct sigqueue *q;\n\tint override_rlimit;\n\tint ret = 0, result;\n\n\tlockdep_assert_held(&t->sighand->siglock);\n\n\tresult = TRACE_SIGNAL_IGNORED;\n\tif (!prepare_signal(sig, t, force))\n\t\tgoto ret;\n\n\tpending = (type != PIDTYPE_PID) ? &t->signal->shared_pending : &t->pending;\n\t \n\tresult = TRACE_SIGNAL_ALREADY_PENDING;\n\tif (legacy_queue(pending, sig))\n\t\tgoto ret;\n\n\tresult = TRACE_SIGNAL_DELIVERED;\n\t \n\tif ((sig == SIGKILL) || (t->flags & PF_KTHREAD))\n\t\tgoto out_set;\n\n\t \n\tif (sig < SIGRTMIN)\n\t\toverride_rlimit = (is_si_special(info) || info->si_code >= 0);\n\telse\n\t\toverride_rlimit = 0;\n\n\tq = __sigqueue_alloc(sig, t, GFP_ATOMIC, override_rlimit, 0);\n\n\tif (q) {\n\t\tlist_add_tail(&q->list, &pending->list);\n\t\tswitch ((unsigned long) info) {\n\t\tcase (unsigned long) SEND_SIG_NOINFO:\n\t\t\tclear_siginfo(&q->info);\n\t\t\tq->info.si_signo = sig;\n\t\t\tq->info.si_errno = 0;\n\t\t\tq->info.si_code = SI_USER;\n\t\t\tq->info.si_pid = task_tgid_nr_ns(current,\n\t\t\t\t\t\t\ttask_active_pid_ns(t));\n\t\t\trcu_read_lock();\n\t\t\tq->info.si_uid =\n\t\t\t\tfrom_kuid_munged(task_cred_xxx(t, user_ns),\n\t\t\t\t\t\t current_uid());\n\t\t\trcu_read_unlock();\n\t\t\tbreak;\n\t\tcase (unsigned long) SEND_SIG_PRIV:\n\t\t\tclear_siginfo(&q->info);\n\t\t\tq->info.si_signo = sig;\n\t\t\tq->info.si_errno = 0;\n\t\t\tq->info.si_code = SI_KERNEL;\n\t\t\tq->info.si_pid = 0;\n\t\t\tq->info.si_uid = 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tcopy_siginfo(&q->info, info);\n\t\t\tbreak;\n\t\t}\n\t} else if (!is_si_special(info) &&\n\t\t   sig >= SIGRTMIN && info->si_code != SI_USER) {\n\t\t \n\t\tresult = TRACE_SIGNAL_OVERFLOW_FAIL;\n\t\tret = -EAGAIN;\n\t\tgoto ret;\n\t} else {\n\t\t \n\t\tresult = TRACE_SIGNAL_LOSE_INFO;\n\t}\n\nout_set:\n\tsignalfd_notify(t, sig);\n\tsigaddset(&pending->signal, sig);\n\n\t \n\tif (type > PIDTYPE_TGID) {\n\t\tstruct multiprocess_signals *delayed;\n\t\thlist_for_each_entry(delayed, &t->signal->multiprocess, node) {\n\t\t\tsigset_t *signal = &delayed->signal;\n\t\t\t \n\t\t\tif (sig == SIGCONT)\n\t\t\t\tsigdelsetmask(signal, SIG_KERNEL_STOP_MASK);\n\t\t\telse if (sig_kernel_stop(sig))\n\t\t\t\tsigdelset(signal, SIGCONT);\n\t\t\tsigaddset(signal, sig);\n\t\t}\n\t}\n\n\tcomplete_signal(sig, t, type);\nret:\n\ttrace_signal_generate(sig, info, t, type != PIDTYPE_PID, result);\n\treturn ret;\n}\n\nstatic inline bool has_si_pid_and_uid(struct kernel_siginfo *info)\n{\n\tbool ret = false;\n\tswitch (siginfo_layout(info->si_signo, info->si_code)) {\n\tcase SIL_KILL:\n\tcase SIL_CHLD:\n\tcase SIL_RT:\n\t\tret = true;\n\t\tbreak;\n\tcase SIL_TIMER:\n\tcase SIL_POLL:\n\tcase SIL_FAULT:\n\tcase SIL_FAULT_TRAPNO:\n\tcase SIL_FAULT_MCEERR:\n\tcase SIL_FAULT_BNDERR:\n\tcase SIL_FAULT_PKUERR:\n\tcase SIL_FAULT_PERF_EVENT:\n\tcase SIL_SYS:\n\t\tret = false;\n\t\tbreak;\n\t}\n\treturn ret;\n}\n\nint send_signal_locked(int sig, struct kernel_siginfo *info,\n\t\t       struct task_struct *t, enum pid_type type)\n{\n\t \n\tbool force = false;\n\n\tif (info == SEND_SIG_NOINFO) {\n\t\t \n\t\tforce = !task_pid_nr_ns(current, task_active_pid_ns(t));\n\t} else if (info == SEND_SIG_PRIV) {\n\t\t \n\t\tforce = true;\n\t} else if (has_si_pid_and_uid(info)) {\n\t\t \n\t\tstruct user_namespace *t_user_ns;\n\n\t\trcu_read_lock();\n\t\tt_user_ns = task_cred_xxx(t, user_ns);\n\t\tif (current_user_ns() != t_user_ns) {\n\t\t\tkuid_t uid = make_kuid(current_user_ns(), info->si_uid);\n\t\t\tinfo->si_uid = from_kuid_munged(t_user_ns, uid);\n\t\t}\n\t\trcu_read_unlock();\n\n\t\t \n\t\tforce = (info->si_code == SI_KERNEL);\n\n\t\t \n\t\tif (!task_pid_nr_ns(current, task_active_pid_ns(t))) {\n\t\t\tinfo->si_pid = 0;\n\t\t\tforce = true;\n\t\t}\n\t}\n\treturn __send_signal_locked(sig, info, t, type, force);\n}\n\nstatic void print_fatal_signal(int signr)\n{\n\tstruct pt_regs *regs = task_pt_regs(current);\n\tstruct file *exe_file;\n\n\texe_file = get_task_exe_file(current);\n\tif (exe_file) {\n\t\tpr_info(\"%pD: %s: potentially unexpected fatal signal %d.\\n\",\n\t\t\texe_file, current->comm, signr);\n\t\tfput(exe_file);\n\t} else {\n\t\tpr_info(\"%s: potentially unexpected fatal signal %d.\\n\",\n\t\t\tcurrent->comm, signr);\n\t}\n\n#if defined(__i386__) && !defined(__arch_um__)\n\tpr_info(\"code at %08lx: \", regs->ip);\n\t{\n\t\tint i;\n\t\tfor (i = 0; i < 16; i++) {\n\t\t\tunsigned char insn;\n\n\t\t\tif (get_user(insn, (unsigned char *)(regs->ip + i)))\n\t\t\t\tbreak;\n\t\t\tpr_cont(\"%02x \", insn);\n\t\t}\n\t}\n\tpr_cont(\"\\n\");\n#endif\n\tpreempt_disable();\n\tshow_regs(regs);\n\tpreempt_enable();\n}\n\nstatic int __init setup_print_fatal_signals(char *str)\n{\n\tget_option (&str, &print_fatal_signals);\n\n\treturn 1;\n}\n\n__setup(\"print-fatal-signals=\", setup_print_fatal_signals);\n\nint do_send_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *p,\n\t\t\tenum pid_type type)\n{\n\tunsigned long flags;\n\tint ret = -ESRCH;\n\n\tif (lock_task_sighand(p, &flags)) {\n\t\tret = send_signal_locked(sig, info, p, type);\n\t\tunlock_task_sighand(p, &flags);\n\t}\n\n\treturn ret;\n}\n\nenum sig_handler {\n\tHANDLER_CURRENT,  \n\tHANDLER_SIG_DFL,  \n\tHANDLER_EXIT,\t  \n};\n\n \nstatic int\nforce_sig_info_to_task(struct kernel_siginfo *info, struct task_struct *t,\n\tenum sig_handler handler)\n{\n\tunsigned long int flags;\n\tint ret, blocked, ignored;\n\tstruct k_sigaction *action;\n\tint sig = info->si_signo;\n\n\tspin_lock_irqsave(&t->sighand->siglock, flags);\n\taction = &t->sighand->action[sig-1];\n\tignored = action->sa.sa_handler == SIG_IGN;\n\tblocked = sigismember(&t->blocked, sig);\n\tif (blocked || ignored || (handler != HANDLER_CURRENT)) {\n\t\taction->sa.sa_handler = SIG_DFL;\n\t\tif (handler == HANDLER_EXIT)\n\t\t\taction->sa.sa_flags |= SA_IMMUTABLE;\n\t\tif (blocked) {\n\t\t\tsigdelset(&t->blocked, sig);\n\t\t\trecalc_sigpending_and_wake(t);\n\t\t}\n\t}\n\t \n\tif (action->sa.sa_handler == SIG_DFL &&\n\t    (!t->ptrace || (handler == HANDLER_EXIT)))\n\t\tt->signal->flags &= ~SIGNAL_UNKILLABLE;\n\tret = send_signal_locked(sig, info, t, PIDTYPE_PID);\n\tspin_unlock_irqrestore(&t->sighand->siglock, flags);\n\n\treturn ret;\n}\n\nint force_sig_info(struct kernel_siginfo *info)\n{\n\treturn force_sig_info_to_task(info, current, HANDLER_CURRENT);\n}\n\n \nint zap_other_threads(struct task_struct *p)\n{\n\tstruct task_struct *t = p;\n\tint count = 0;\n\n\tp->signal->group_stop_count = 0;\n\n\twhile_each_thread(p, t) {\n\t\ttask_clear_jobctl_pending(t, JOBCTL_PENDING_MASK);\n\t\t \n\t\tif ((t->flags & (PF_IO_WORKER | PF_USER_WORKER)) != PF_USER_WORKER)\n\t\t\tcount++;\n\n\t\t \n\t\tif (t->exit_state)\n\t\t\tcontinue;\n\t\tsigaddset(&t->pending.signal, SIGKILL);\n\t\tsignal_wake_up(t, 1);\n\t}\n\n\treturn count;\n}\n\nstruct sighand_struct *__lock_task_sighand(struct task_struct *tsk,\n\t\t\t\t\t   unsigned long *flags)\n{\n\tstruct sighand_struct *sighand;\n\n\trcu_read_lock();\n\tfor (;;) {\n\t\tsighand = rcu_dereference(tsk->sighand);\n\t\tif (unlikely(sighand == NULL))\n\t\t\tbreak;\n\n\t\t \n\t\tspin_lock_irqsave(&sighand->siglock, *flags);\n\t\tif (likely(sighand == rcu_access_pointer(tsk->sighand)))\n\t\t\tbreak;\n\t\tspin_unlock_irqrestore(&sighand->siglock, *flags);\n\t}\n\trcu_read_unlock();\n\n\treturn sighand;\n}\n\n#ifdef CONFIG_LOCKDEP\nvoid lockdep_assert_task_sighand_held(struct task_struct *task)\n{\n\tstruct sighand_struct *sighand;\n\n\trcu_read_lock();\n\tsighand = rcu_dereference(task->sighand);\n\tif (sighand)\n\t\tlockdep_assert_held(&sighand->siglock);\n\telse\n\t\tWARN_ON_ONCE(1);\n\trcu_read_unlock();\n}\n#endif\n\n \nint group_send_sig_info(int sig, struct kernel_siginfo *info,\n\t\t\tstruct task_struct *p, enum pid_type type)\n{\n\tint ret;\n\n\trcu_read_lock();\n\tret = check_kill_permission(sig, info, p);\n\trcu_read_unlock();\n\n\tif (!ret && sig)\n\t\tret = do_send_sig_info(sig, info, p, type);\n\n\treturn ret;\n}\n\n \nint __kill_pgrp_info(int sig, struct kernel_siginfo *info, struct pid *pgrp)\n{\n\tstruct task_struct *p = NULL;\n\tint retval, success;\n\n\tsuccess = 0;\n\tretval = -ESRCH;\n\tdo_each_pid_task(pgrp, PIDTYPE_PGID, p) {\n\t\tint err = group_send_sig_info(sig, info, p, PIDTYPE_PGID);\n\t\tsuccess |= !err;\n\t\tretval = err;\n\t} while_each_pid_task(pgrp, PIDTYPE_PGID, p);\n\treturn success ? 0 : retval;\n}\n\nint kill_pid_info(int sig, struct kernel_siginfo *info, struct pid *pid)\n{\n\tint error = -ESRCH;\n\tstruct task_struct *p;\n\n\tfor (;;) {\n\t\trcu_read_lock();\n\t\tp = pid_task(pid, PIDTYPE_PID);\n\t\tif (p)\n\t\t\terror = group_send_sig_info(sig, info, p, PIDTYPE_TGID);\n\t\trcu_read_unlock();\n\t\tif (likely(!p || error != -ESRCH))\n\t\t\treturn error;\n\n\t\t \n\t}\n}\n\nstatic int kill_proc_info(int sig, struct kernel_siginfo *info, pid_t pid)\n{\n\tint error;\n\trcu_read_lock();\n\terror = kill_pid_info(sig, info, find_vpid(pid));\n\trcu_read_unlock();\n\treturn error;\n}\n\nstatic inline bool kill_as_cred_perm(const struct cred *cred,\n\t\t\t\t     struct task_struct *target)\n{\n\tconst struct cred *pcred = __task_cred(target);\n\n\treturn uid_eq(cred->euid, pcred->suid) ||\n\t       uid_eq(cred->euid, pcred->uid) ||\n\t       uid_eq(cred->uid, pcred->suid) ||\n\t       uid_eq(cred->uid, pcred->uid);\n}\n\n \nint kill_pid_usb_asyncio(int sig, int errno, sigval_t addr,\n\t\t\t struct pid *pid, const struct cred *cred)\n{\n\tstruct kernel_siginfo info;\n\tstruct task_struct *p;\n\tunsigned long flags;\n\tint ret = -EINVAL;\n\n\tif (!valid_signal(sig))\n\t\treturn ret;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = errno;\n\tinfo.si_code = SI_ASYNCIO;\n\t*((sigval_t *)&info.si_pid) = addr;\n\n\trcu_read_lock();\n\tp = pid_task(pid, PIDTYPE_PID);\n\tif (!p) {\n\t\tret = -ESRCH;\n\t\tgoto out_unlock;\n\t}\n\tif (!kill_as_cred_perm(cred, p)) {\n\t\tret = -EPERM;\n\t\tgoto out_unlock;\n\t}\n\tret = security_task_kill(p, &info, sig, cred);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tif (sig) {\n\t\tif (lock_task_sighand(p, &flags)) {\n\t\t\tret = __send_signal_locked(sig, &info, p, PIDTYPE_TGID, false);\n\t\t\tunlock_task_sighand(p, &flags);\n\t\t} else\n\t\t\tret = -ESRCH;\n\t}\nout_unlock:\n\trcu_read_unlock();\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(kill_pid_usb_asyncio);\n\n \n\nstatic int kill_something_info(int sig, struct kernel_siginfo *info, pid_t pid)\n{\n\tint ret;\n\n\tif (pid > 0)\n\t\treturn kill_proc_info(sig, info, pid);\n\n\t \n\tif (pid == INT_MIN)\n\t\treturn -ESRCH;\n\n\tread_lock(&tasklist_lock);\n\tif (pid != -1) {\n\t\tret = __kill_pgrp_info(sig, info,\n\t\t\t\tpid ? find_vpid(-pid) : task_pgrp(current));\n\t} else {\n\t\tint retval = 0, count = 0;\n\t\tstruct task_struct * p;\n\n\t\tfor_each_process(p) {\n\t\t\tif (task_pid_vnr(p) > 1 &&\n\t\t\t\t\t!same_thread_group(p, current)) {\n\t\t\t\tint err = group_send_sig_info(sig, info, p,\n\t\t\t\t\t\t\t      PIDTYPE_MAX);\n\t\t\t\t++count;\n\t\t\t\tif (err != -EPERM)\n\t\t\t\t\tretval = err;\n\t\t\t}\n\t\t}\n\t\tret = count ? retval : -ESRCH;\n\t}\n\tread_unlock(&tasklist_lock);\n\n\treturn ret;\n}\n\n \n\nint send_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *p)\n{\n\t \n\tif (!valid_signal(sig))\n\t\treturn -EINVAL;\n\n\treturn do_send_sig_info(sig, info, p, PIDTYPE_PID);\n}\nEXPORT_SYMBOL(send_sig_info);\n\n#define __si_special(priv) \\\n\t((priv) ? SEND_SIG_PRIV : SEND_SIG_NOINFO)\n\nint\nsend_sig(int sig, struct task_struct *p, int priv)\n{\n\treturn send_sig_info(sig, __si_special(priv), p);\n}\nEXPORT_SYMBOL(send_sig);\n\nvoid force_sig(int sig)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code = SI_KERNEL;\n\tinfo.si_pid = 0;\n\tinfo.si_uid = 0;\n\tforce_sig_info(&info);\n}\nEXPORT_SYMBOL(force_sig);\n\nvoid force_fatal_sig(int sig)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code = SI_KERNEL;\n\tinfo.si_pid = 0;\n\tinfo.si_uid = 0;\n\tforce_sig_info_to_task(&info, current, HANDLER_SIG_DFL);\n}\n\nvoid force_exit_sig(int sig)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code = SI_KERNEL;\n\tinfo.si_pid = 0;\n\tinfo.si_uid = 0;\n\tforce_sig_info_to_task(&info, current, HANDLER_EXIT);\n}\n\n \nvoid force_sigsegv(int sig)\n{\n\tif (sig == SIGSEGV)\n\t\tforce_fatal_sig(SIGSEGV);\n\telse\n\t\tforce_sig(SIGSEGV);\n}\n\nint force_sig_fault_to_task(int sig, int code, void __user *addr\n\t___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)\n\t, struct task_struct *t)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code  = code;\n\tinfo.si_addr  = addr;\n#ifdef __ia64__\n\tinfo.si_imm = imm;\n\tinfo.si_flags = flags;\n\tinfo.si_isr = isr;\n#endif\n\treturn force_sig_info_to_task(&info, t, HANDLER_CURRENT);\n}\n\nint force_sig_fault(int sig, int code, void __user *addr\n\t___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr))\n{\n\treturn force_sig_fault_to_task(sig, code, addr\n\t\t\t\t       ___ARCH_SI_IA64(imm, flags, isr), current);\n}\n\nint send_sig_fault(int sig, int code, void __user *addr\n\t___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)\n\t, struct task_struct *t)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code  = code;\n\tinfo.si_addr  = addr;\n#ifdef __ia64__\n\tinfo.si_imm = imm;\n\tinfo.si_flags = flags;\n\tinfo.si_isr = isr;\n#endif\n\treturn send_sig_info(info.si_signo, &info, t);\n}\n\nint force_sig_mceerr(int code, void __user *addr, short lsb)\n{\n\tstruct kernel_siginfo info;\n\n\tWARN_ON((code != BUS_MCEERR_AO) && (code != BUS_MCEERR_AR));\n\tclear_siginfo(&info);\n\tinfo.si_signo = SIGBUS;\n\tinfo.si_errno = 0;\n\tinfo.si_code = code;\n\tinfo.si_addr = addr;\n\tinfo.si_addr_lsb = lsb;\n\treturn force_sig_info(&info);\n}\n\nint send_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *t)\n{\n\tstruct kernel_siginfo info;\n\n\tWARN_ON((code != BUS_MCEERR_AO) && (code != BUS_MCEERR_AR));\n\tclear_siginfo(&info);\n\tinfo.si_signo = SIGBUS;\n\tinfo.si_errno = 0;\n\tinfo.si_code = code;\n\tinfo.si_addr = addr;\n\tinfo.si_addr_lsb = lsb;\n\treturn send_sig_info(info.si_signo, &info, t);\n}\nEXPORT_SYMBOL(send_sig_mceerr);\n\nint force_sig_bnderr(void __user *addr, void __user *lower, void __user *upper)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = SIGSEGV;\n\tinfo.si_errno = 0;\n\tinfo.si_code  = SEGV_BNDERR;\n\tinfo.si_addr  = addr;\n\tinfo.si_lower = lower;\n\tinfo.si_upper = upper;\n\treturn force_sig_info(&info);\n}\n\n#ifdef SEGV_PKUERR\nint force_sig_pkuerr(void __user *addr, u32 pkey)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = SIGSEGV;\n\tinfo.si_errno = 0;\n\tinfo.si_code  = SEGV_PKUERR;\n\tinfo.si_addr  = addr;\n\tinfo.si_pkey  = pkey;\n\treturn force_sig_info(&info);\n}\n#endif\n\nint send_sig_perf(void __user *addr, u32 type, u64 sig_data)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo     = SIGTRAP;\n\tinfo.si_errno     = 0;\n\tinfo.si_code      = TRAP_PERF;\n\tinfo.si_addr      = addr;\n\tinfo.si_perf_data = sig_data;\n\tinfo.si_perf_type = type;\n\n\t \n\tinfo.si_perf_flags = sigismember(&current->blocked, info.si_signo) ?\n\t\t\t\t     TRAP_PERF_FLAG_ASYNC :\n\t\t\t\t     0;\n\n\treturn send_sig_info(info.si_signo, &info, current);\n}\n\n \nint force_sig_seccomp(int syscall, int reason, bool force_coredump)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = SIGSYS;\n\tinfo.si_code = SYS_SECCOMP;\n\tinfo.si_call_addr = (void __user *)KSTK_EIP(current);\n\tinfo.si_errno = reason;\n\tinfo.si_arch = syscall_get_arch(current);\n\tinfo.si_syscall = syscall;\n\treturn force_sig_info_to_task(&info, current,\n\t\tforce_coredump ? HANDLER_EXIT : HANDLER_CURRENT);\n}\n\n \nint force_sig_ptrace_errno_trap(int errno, void __user *addr)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = SIGTRAP;\n\tinfo.si_errno = errno;\n\tinfo.si_code  = TRAP_HWBKPT;\n\tinfo.si_addr  = addr;\n\treturn force_sig_info(&info);\n}\n\n \nint force_sig_fault_trapno(int sig, int code, void __user *addr, int trapno)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code  = code;\n\tinfo.si_addr  = addr;\n\tinfo.si_trapno = trapno;\n\treturn force_sig_info(&info);\n}\n\n \nint send_sig_fault_trapno(int sig, int code, void __user *addr, int trapno,\n\t\t\t  struct task_struct *t)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code  = code;\n\tinfo.si_addr  = addr;\n\tinfo.si_trapno = trapno;\n\treturn send_sig_info(info.si_signo, &info, t);\n}\n\nint kill_pgrp(struct pid *pid, int sig, int priv)\n{\n\tint ret;\n\n\tread_lock(&tasklist_lock);\n\tret = __kill_pgrp_info(sig, __si_special(priv), pid);\n\tread_unlock(&tasklist_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(kill_pgrp);\n\nint kill_pid(struct pid *pid, int sig, int priv)\n{\n\treturn kill_pid_info(sig, __si_special(priv), pid);\n}\nEXPORT_SYMBOL(kill_pid);\n\n \nstruct sigqueue *sigqueue_alloc(void)\n{\n\treturn __sigqueue_alloc(-1, current, GFP_KERNEL, 0, SIGQUEUE_PREALLOC);\n}\n\nvoid sigqueue_free(struct sigqueue *q)\n{\n\tunsigned long flags;\n\tspinlock_t *lock = &current->sighand->siglock;\n\n\tBUG_ON(!(q->flags & SIGQUEUE_PREALLOC));\n\t \n\tspin_lock_irqsave(lock, flags);\n\tq->flags &= ~SIGQUEUE_PREALLOC;\n\t \n\tif (!list_empty(&q->list))\n\t\tq = NULL;\n\tspin_unlock_irqrestore(lock, flags);\n\n\tif (q)\n\t\t__sigqueue_free(q);\n}\n\nint send_sigqueue(struct sigqueue *q, struct pid *pid, enum pid_type type)\n{\n\tint sig = q->info.si_signo;\n\tstruct sigpending *pending;\n\tstruct task_struct *t;\n\tunsigned long flags;\n\tint ret, result;\n\n\tBUG_ON(!(q->flags & SIGQUEUE_PREALLOC));\n\n\tret = -1;\n\trcu_read_lock();\n\n\t \n\tt = pid_task(pid, type);\n\tif (!t)\n\t\tgoto ret;\n\tif (type != PIDTYPE_PID && same_thread_group(t, current))\n\t\tt = current;\n\tif (!likely(lock_task_sighand(t, &flags)))\n\t\tgoto ret;\n\n\tret = 1;  \n\tresult = TRACE_SIGNAL_IGNORED;\n\tif (!prepare_signal(sig, t, false))\n\t\tgoto out;\n\n\tret = 0;\n\tif (unlikely(!list_empty(&q->list))) {\n\t\t \n\t\tBUG_ON(q->info.si_code != SI_TIMER);\n\t\tq->info.si_overrun++;\n\t\tresult = TRACE_SIGNAL_ALREADY_PENDING;\n\t\tgoto out;\n\t}\n\tq->info.si_overrun = 0;\n\n\tsignalfd_notify(t, sig);\n\tpending = (type != PIDTYPE_PID) ? &t->signal->shared_pending : &t->pending;\n\tlist_add_tail(&q->list, &pending->list);\n\tsigaddset(&pending->signal, sig);\n\tcomplete_signal(sig, t, type);\n\tresult = TRACE_SIGNAL_DELIVERED;\nout:\n\ttrace_signal_generate(sig, &q->info, t, type != PIDTYPE_PID, result);\n\tunlock_task_sighand(t, &flags);\nret:\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic void do_notify_pidfd(struct task_struct *task)\n{\n\tstruct pid *pid;\n\n\tWARN_ON(task->exit_state == 0);\n\tpid = task_pid(task);\n\twake_up_all(&pid->wait_pidfd);\n}\n\n \nbool do_notify_parent(struct task_struct *tsk, int sig)\n{\n\tstruct kernel_siginfo info;\n\tunsigned long flags;\n\tstruct sighand_struct *psig;\n\tbool autoreap = false;\n\tu64 utime, stime;\n\n\tWARN_ON_ONCE(sig == -1);\n\n\t \n\tWARN_ON_ONCE(task_is_stopped_or_traced(tsk));\n\n\tWARN_ON_ONCE(!tsk->ptrace &&\n\t       (tsk->group_leader != tsk || !thread_group_empty(tsk)));\n\n\t \n\tdo_notify_pidfd(tsk);\n\n\tif (sig != SIGCHLD) {\n\t\t \n\t\tif (tsk->parent_exec_id != READ_ONCE(tsk->parent->self_exec_id))\n\t\t\tsig = SIGCHLD;\n\t}\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\t \n\trcu_read_lock();\n\tinfo.si_pid = task_pid_nr_ns(tsk, task_active_pid_ns(tsk->parent));\n\tinfo.si_uid = from_kuid_munged(task_cred_xxx(tsk->parent, user_ns),\n\t\t\t\t       task_uid(tsk));\n\trcu_read_unlock();\n\n\ttask_cputime(tsk, &utime, &stime);\n\tinfo.si_utime = nsec_to_clock_t(utime + tsk->signal->utime);\n\tinfo.si_stime = nsec_to_clock_t(stime + tsk->signal->stime);\n\n\tinfo.si_status = tsk->exit_code & 0x7f;\n\tif (tsk->exit_code & 0x80)\n\t\tinfo.si_code = CLD_DUMPED;\n\telse if (tsk->exit_code & 0x7f)\n\t\tinfo.si_code = CLD_KILLED;\n\telse {\n\t\tinfo.si_code = CLD_EXITED;\n\t\tinfo.si_status = tsk->exit_code >> 8;\n\t}\n\n\tpsig = tsk->parent->sighand;\n\tspin_lock_irqsave(&psig->siglock, flags);\n\tif (!tsk->ptrace && sig == SIGCHLD &&\n\t    (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN ||\n\t     (psig->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDWAIT))) {\n\t\t \n\t\tautoreap = true;\n\t\tif (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN)\n\t\t\tsig = 0;\n\t}\n\t \n\tif (valid_signal(sig) && sig)\n\t\t__send_signal_locked(sig, &info, tsk->parent, PIDTYPE_TGID, false);\n\t__wake_up_parent(tsk, tsk->parent);\n\tspin_unlock_irqrestore(&psig->siglock, flags);\n\n\treturn autoreap;\n}\n\n \nstatic void do_notify_parent_cldstop(struct task_struct *tsk,\n\t\t\t\t     bool for_ptracer, int why)\n{\n\tstruct kernel_siginfo info;\n\tunsigned long flags;\n\tstruct task_struct *parent;\n\tstruct sighand_struct *sighand;\n\tu64 utime, stime;\n\n\tif (for_ptracer) {\n\t\tparent = tsk->parent;\n\t} else {\n\t\ttsk = tsk->group_leader;\n\t\tparent = tsk->real_parent;\n\t}\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = SIGCHLD;\n\tinfo.si_errno = 0;\n\t \n\trcu_read_lock();\n\tinfo.si_pid = task_pid_nr_ns(tsk, task_active_pid_ns(parent));\n\tinfo.si_uid = from_kuid_munged(task_cred_xxx(parent, user_ns), task_uid(tsk));\n\trcu_read_unlock();\n\n\ttask_cputime(tsk, &utime, &stime);\n\tinfo.si_utime = nsec_to_clock_t(utime);\n\tinfo.si_stime = nsec_to_clock_t(stime);\n\n \tinfo.si_code = why;\n \tswitch (why) {\n \tcase CLD_CONTINUED:\n \t\tinfo.si_status = SIGCONT;\n \t\tbreak;\n \tcase CLD_STOPPED:\n \t\tinfo.si_status = tsk->signal->group_exit_code & 0x7f;\n \t\tbreak;\n \tcase CLD_TRAPPED:\n \t\tinfo.si_status = tsk->exit_code & 0x7f;\n \t\tbreak;\n \tdefault:\n \t\tBUG();\n \t}\n\n\tsighand = parent->sighand;\n\tspin_lock_irqsave(&sighand->siglock, flags);\n\tif (sighand->action[SIGCHLD-1].sa.sa_handler != SIG_IGN &&\n\t    !(sighand->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDSTOP))\n\t\tsend_signal_locked(SIGCHLD, &info, parent, PIDTYPE_TGID);\n\t \n\t__wake_up_parent(tsk, parent);\n\tspin_unlock_irqrestore(&sighand->siglock, flags);\n}\n\n \nstatic int ptrace_stop(int exit_code, int why, unsigned long message,\n\t\t       kernel_siginfo_t *info)\n\t__releases(&current->sighand->siglock)\n\t__acquires(&current->sighand->siglock)\n{\n\tbool gstop_done = false;\n\n\tif (arch_ptrace_stop_needed()) {\n\t\t \n\t\tspin_unlock_irq(&current->sighand->siglock);\n\t\tarch_ptrace_stop();\n\t\tspin_lock_irq(&current->sighand->siglock);\n\t}\n\n\t \n\tif (!current->ptrace || __fatal_signal_pending(current))\n\t\treturn exit_code;\n\n\tset_special_state(TASK_TRACED);\n\tcurrent->jobctl |= JOBCTL_TRACED;\n\n\t \n\tsmp_wmb();\n\n\tcurrent->ptrace_message = message;\n\tcurrent->last_siginfo = info;\n\tcurrent->exit_code = exit_code;\n\n\t \n\tif (why == CLD_STOPPED && (current->jobctl & JOBCTL_STOP_PENDING))\n\t\tgstop_done = task_participate_group_stop(current);\n\n\t \n\ttask_clear_jobctl_pending(current, JOBCTL_TRAP_STOP);\n\tif (info && info->si_code >> 8 == PTRACE_EVENT_STOP)\n\t\ttask_clear_jobctl_pending(current, JOBCTL_TRAP_NOTIFY);\n\n\t \n\ttask_clear_jobctl_trapping(current);\n\n\tspin_unlock_irq(&current->sighand->siglock);\n\tread_lock(&tasklist_lock);\n\t \n\tif (current->ptrace)\n\t\tdo_notify_parent_cldstop(current, true, why);\n\tif (gstop_done && (!current->ptrace || ptrace_reparented(current)))\n\t\tdo_notify_parent_cldstop(current, false, why);\n\n\t \n\tpreempt_disable();\n\tread_unlock(&tasklist_lock);\n\tcgroup_enter_frozen();\n\tpreempt_enable_no_resched();\n\tschedule();\n\tcgroup_leave_frozen(true);\n\n\t \n\tspin_lock_irq(&current->sighand->siglock);\n\texit_code = current->exit_code;\n\tcurrent->last_siginfo = NULL;\n\tcurrent->ptrace_message = 0;\n\tcurrent->exit_code = 0;\n\n\t \n\tcurrent->jobctl &= ~(JOBCTL_LISTENING | JOBCTL_PTRACE_FROZEN);\n\n\t \n\trecalc_sigpending_tsk(current);\n\treturn exit_code;\n}\n\nstatic int ptrace_do_notify(int signr, int exit_code, int why, unsigned long message)\n{\n\tkernel_siginfo_t info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = signr;\n\tinfo.si_code = exit_code;\n\tinfo.si_pid = task_pid_vnr(current);\n\tinfo.si_uid = from_kuid_munged(current_user_ns(), current_uid());\n\n\t \n\treturn ptrace_stop(exit_code, why, message, &info);\n}\n\nint ptrace_notify(int exit_code, unsigned long message)\n{\n\tint signr;\n\n\tBUG_ON((exit_code & (0x7f | ~0xffff)) != SIGTRAP);\n\tif (unlikely(task_work_pending(current)))\n\t\ttask_work_run();\n\n\tspin_lock_irq(&current->sighand->siglock);\n\tsignr = ptrace_do_notify(SIGTRAP, exit_code, CLD_TRAPPED, message);\n\tspin_unlock_irq(&current->sighand->siglock);\n\treturn signr;\n}\n\n \nstatic bool do_signal_stop(int signr)\n\t__releases(&current->sighand->siglock)\n{\n\tstruct signal_struct *sig = current->signal;\n\n\tif (!(current->jobctl & JOBCTL_STOP_PENDING)) {\n\t\tunsigned long gstop = JOBCTL_STOP_PENDING | JOBCTL_STOP_CONSUME;\n\t\tstruct task_struct *t;\n\n\t\t \n\t\tWARN_ON_ONCE(signr & ~JOBCTL_STOP_SIGMASK);\n\n\t\tif (!likely(current->jobctl & JOBCTL_STOP_DEQUEUED) ||\n\t\t    unlikely(sig->flags & SIGNAL_GROUP_EXIT) ||\n\t\t    unlikely(sig->group_exec_task))\n\t\t\treturn false;\n\t\t \n\t\tif (!(sig->flags & SIGNAL_STOP_STOPPED))\n\t\t\tsig->group_exit_code = signr;\n\n\t\tsig->group_stop_count = 0;\n\n\t\tif (task_set_jobctl_pending(current, signr | gstop))\n\t\t\tsig->group_stop_count++;\n\n\t\tt = current;\n\t\twhile_each_thread(current, t) {\n\t\t\t \n\t\t\tif (!task_is_stopped(t) &&\n\t\t\t    task_set_jobctl_pending(t, signr | gstop)) {\n\t\t\t\tsig->group_stop_count++;\n\t\t\t\tif (likely(!(t->ptrace & PT_SEIZED)))\n\t\t\t\t\tsignal_wake_up(t, 0);\n\t\t\t\telse\n\t\t\t\t\tptrace_trap_notify(t);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (likely(!current->ptrace)) {\n\t\tint notify = 0;\n\n\t\t \n\t\tif (task_participate_group_stop(current))\n\t\t\tnotify = CLD_STOPPED;\n\n\t\tcurrent->jobctl |= JOBCTL_STOPPED;\n\t\tset_special_state(TASK_STOPPED);\n\t\tspin_unlock_irq(&current->sighand->siglock);\n\n\t\t \n\t\tif (notify) {\n\t\t\tread_lock(&tasklist_lock);\n\t\t\tdo_notify_parent_cldstop(current, false, notify);\n\t\t\tread_unlock(&tasklist_lock);\n\t\t}\n\n\t\t \n\t\tcgroup_enter_frozen();\n\t\tschedule();\n\t\treturn true;\n\t} else {\n\t\t \n\t\ttask_set_jobctl_pending(current, JOBCTL_TRAP_STOP);\n\t\treturn false;\n\t}\n}\n\n \nstatic void do_jobctl_trap(void)\n{\n\tstruct signal_struct *signal = current->signal;\n\tint signr = current->jobctl & JOBCTL_STOP_SIGMASK;\n\n\tif (current->ptrace & PT_SEIZED) {\n\t\tif (!signal->group_stop_count &&\n\t\t    !(signal->flags & SIGNAL_STOP_STOPPED))\n\t\t\tsignr = SIGTRAP;\n\t\tWARN_ON_ONCE(!signr);\n\t\tptrace_do_notify(signr, signr | (PTRACE_EVENT_STOP << 8),\n\t\t\t\t CLD_STOPPED, 0);\n\t} else {\n\t\tWARN_ON_ONCE(!signr);\n\t\tptrace_stop(signr, CLD_STOPPED, 0, NULL);\n\t}\n}\n\n \nstatic void do_freezer_trap(void)\n\t__releases(&current->sighand->siglock)\n{\n\t \n\tif ((current->jobctl & (JOBCTL_PENDING_MASK | JOBCTL_TRAP_FREEZE)) !=\n\t     JOBCTL_TRAP_FREEZE) {\n\t\tspin_unlock_irq(&current->sighand->siglock);\n\t\treturn;\n\t}\n\n\t \n\t__set_current_state(TASK_INTERRUPTIBLE|TASK_FREEZABLE);\n\tclear_thread_flag(TIF_SIGPENDING);\n\tspin_unlock_irq(&current->sighand->siglock);\n\tcgroup_enter_frozen();\n\tschedule();\n}\n\nstatic int ptrace_signal(int signr, kernel_siginfo_t *info, enum pid_type type)\n{\n\t \n\tcurrent->jobctl |= JOBCTL_STOP_DEQUEUED;\n\tsignr = ptrace_stop(signr, CLD_TRAPPED, 0, info);\n\n\t \n\tif (signr == 0)\n\t\treturn signr;\n\n\t \n\tif (signr != info->si_signo) {\n\t\tclear_siginfo(info);\n\t\tinfo->si_signo = signr;\n\t\tinfo->si_errno = 0;\n\t\tinfo->si_code = SI_USER;\n\t\trcu_read_lock();\n\t\tinfo->si_pid = task_pid_vnr(current->parent);\n\t\tinfo->si_uid = from_kuid_munged(current_user_ns(),\n\t\t\t\t\t\ttask_uid(current->parent));\n\t\trcu_read_unlock();\n\t}\n\n\t \n\tif (sigismember(&current->blocked, signr) ||\n\t    fatal_signal_pending(current)) {\n\t\tsend_signal_locked(signr, info, current, type);\n\t\tsignr = 0;\n\t}\n\n\treturn signr;\n}\n\nstatic void hide_si_addr_tag_bits(struct ksignal *ksig)\n{\n\tswitch (siginfo_layout(ksig->sig, ksig->info.si_code)) {\n\tcase SIL_FAULT:\n\tcase SIL_FAULT_TRAPNO:\n\tcase SIL_FAULT_MCEERR:\n\tcase SIL_FAULT_BNDERR:\n\tcase SIL_FAULT_PKUERR:\n\tcase SIL_FAULT_PERF_EVENT:\n\t\tksig->info.si_addr = arch_untagged_si_addr(\n\t\t\tksig->info.si_addr, ksig->sig, ksig->info.si_code);\n\t\tbreak;\n\tcase SIL_KILL:\n\tcase SIL_TIMER:\n\tcase SIL_POLL:\n\tcase SIL_CHLD:\n\tcase SIL_RT:\n\tcase SIL_SYS:\n\t\tbreak;\n\t}\n}\n\nbool get_signal(struct ksignal *ksig)\n{\n\tstruct sighand_struct *sighand = current->sighand;\n\tstruct signal_struct *signal = current->signal;\n\tint signr;\n\n\tclear_notify_signal();\n\tif (unlikely(task_work_pending(current)))\n\t\ttask_work_run();\n\n\tif (!task_sigpending(current))\n\t\treturn false;\n\n\tif (unlikely(uprobe_deny_signal()))\n\t\treturn false;\n\n\t \n\ttry_to_freeze();\n\nrelock:\n\tspin_lock_irq(&sighand->siglock);\n\n\t \n\tif (unlikely(signal->flags & SIGNAL_CLD_MASK)) {\n\t\tint why;\n\n\t\tif (signal->flags & SIGNAL_CLD_CONTINUED)\n\t\t\twhy = CLD_CONTINUED;\n\t\telse\n\t\t\twhy = CLD_STOPPED;\n\n\t\tsignal->flags &= ~SIGNAL_CLD_MASK;\n\n\t\tspin_unlock_irq(&sighand->siglock);\n\n\t\t \n\t\tread_lock(&tasklist_lock);\n\t\tdo_notify_parent_cldstop(current, false, why);\n\n\t\tif (ptrace_reparented(current->group_leader))\n\t\t\tdo_notify_parent_cldstop(current->group_leader,\n\t\t\t\t\t\ttrue, why);\n\t\tread_unlock(&tasklist_lock);\n\n\t\tgoto relock;\n\t}\n\n\tfor (;;) {\n\t\tstruct k_sigaction *ka;\n\t\tenum pid_type type;\n\n\t\t \n\t\tif ((signal->flags & SIGNAL_GROUP_EXIT) ||\n\t\t     signal->group_exec_task) {\n\t\t\tclear_siginfo(&ksig->info);\n\t\t\tksig->info.si_signo = signr = SIGKILL;\n\t\t\tsigdelset(&current->pending.signal, SIGKILL);\n\t\t\ttrace_signal_deliver(SIGKILL, SEND_SIG_NOINFO,\n\t\t\t\t&sighand->action[SIGKILL - 1]);\n\t\t\trecalc_sigpending();\n\t\t\tgoto fatal;\n\t\t}\n\n\t\tif (unlikely(current->jobctl & JOBCTL_STOP_PENDING) &&\n\t\t    do_signal_stop(0))\n\t\t\tgoto relock;\n\n\t\tif (unlikely(current->jobctl &\n\t\t\t     (JOBCTL_TRAP_MASK | JOBCTL_TRAP_FREEZE))) {\n\t\t\tif (current->jobctl & JOBCTL_TRAP_MASK) {\n\t\t\t\tdo_jobctl_trap();\n\t\t\t\tspin_unlock_irq(&sighand->siglock);\n\t\t\t} else if (current->jobctl & JOBCTL_TRAP_FREEZE)\n\t\t\t\tdo_freezer_trap();\n\n\t\t\tgoto relock;\n\t\t}\n\n\t\t \n\t\tif (unlikely(cgroup_task_frozen(current))) {\n\t\t\tspin_unlock_irq(&sighand->siglock);\n\t\t\tcgroup_leave_frozen(false);\n\t\t\tgoto relock;\n\t\t}\n\n\t\t \n\t\ttype = PIDTYPE_PID;\n\t\tsignr = dequeue_synchronous_signal(&ksig->info);\n\t\tif (!signr)\n\t\t\tsignr = dequeue_signal(current, &current->blocked,\n\t\t\t\t\t       &ksig->info, &type);\n\n\t\tif (!signr)\n\t\t\tbreak;  \n\n\t\tif (unlikely(current->ptrace) && (signr != SIGKILL) &&\n\t\t    !(sighand->action[signr -1].sa.sa_flags & SA_IMMUTABLE)) {\n\t\t\tsignr = ptrace_signal(signr, &ksig->info, type);\n\t\t\tif (!signr)\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tka = &sighand->action[signr-1];\n\n\t\t \n\t\ttrace_signal_deliver(signr, &ksig->info, ka);\n\n\t\tif (ka->sa.sa_handler == SIG_IGN)  \n\t\t\tcontinue;\n\t\tif (ka->sa.sa_handler != SIG_DFL) {\n\t\t\t \n\t\t\tksig->ka = *ka;\n\n\t\t\tif (ka->sa.sa_flags & SA_ONESHOT)\n\t\t\t\tka->sa.sa_handler = SIG_DFL;\n\n\t\t\tbreak;  \n\t\t}\n\n\t\t \n\t\tif (sig_kernel_ignore(signr))  \n\t\t\tcontinue;\n\n\t\t \n\t\tif (unlikely(signal->flags & SIGNAL_UNKILLABLE) &&\n\t\t\t\t!sig_kernel_only(signr))\n\t\t\tcontinue;\n\n\t\tif (sig_kernel_stop(signr)) {\n\t\t\t \n\t\t\tif (signr != SIGSTOP) {\n\t\t\t\tspin_unlock_irq(&sighand->siglock);\n\n\t\t\t\t \n\n\t\t\t\tif (is_current_pgrp_orphaned())\n\t\t\t\t\tgoto relock;\n\n\t\t\t\tspin_lock_irq(&sighand->siglock);\n\t\t\t}\n\n\t\t\tif (likely(do_signal_stop(ksig->info.si_signo))) {\n\t\t\t\t \n\t\t\t\tgoto relock;\n\t\t\t}\n\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\n\tfatal:\n\t\tspin_unlock_irq(&sighand->siglock);\n\t\tif (unlikely(cgroup_task_frozen(current)))\n\t\t\tcgroup_leave_frozen(true);\n\n\t\t \n\t\tcurrent->flags |= PF_SIGNALED;\n\n\t\tif (sig_kernel_coredump(signr)) {\n\t\t\tif (print_fatal_signals)\n\t\t\t\tprint_fatal_signal(ksig->info.si_signo);\n\t\t\tproc_coredump_connector(current);\n\t\t\t \n\t\t\tdo_coredump(&ksig->info);\n\t\t}\n\n\t\t \n\t\tif (current->flags & PF_USER_WORKER)\n\t\t\tgoto out;\n\n\t\t \n\t\tdo_group_exit(ksig->info.si_signo);\n\t\t \n\t}\n\tspin_unlock_irq(&sighand->siglock);\nout:\n\tksig->sig = signr;\n\n\tif (!(ksig->ka.sa.sa_flags & SA_EXPOSE_TAGBITS))\n\t\thide_si_addr_tag_bits(ksig);\n\n\treturn ksig->sig > 0;\n}\n\n \nstatic void signal_delivered(struct ksignal *ksig, int stepping)\n{\n\tsigset_t blocked;\n\n\t \n\tclear_restore_sigmask();\n\n\tsigorsets(&blocked, &current->blocked, &ksig->ka.sa.sa_mask);\n\tif (!(ksig->ka.sa.sa_flags & SA_NODEFER))\n\t\tsigaddset(&blocked, ksig->sig);\n\tset_current_blocked(&blocked);\n\tif (current->sas_ss_flags & SS_AUTODISARM)\n\t\tsas_ss_reset(current);\n\tif (stepping)\n\t\tptrace_notify(SIGTRAP, 0);\n}\n\nvoid signal_setup_done(int failed, struct ksignal *ksig, int stepping)\n{\n\tif (failed)\n\t\tforce_sigsegv(ksig->sig);\n\telse\n\t\tsignal_delivered(ksig, stepping);\n}\n\n \nstatic void retarget_shared_pending(struct task_struct *tsk, sigset_t *which)\n{\n\tsigset_t retarget;\n\tstruct task_struct *t;\n\n\tsigandsets(&retarget, &tsk->signal->shared_pending.signal, which);\n\tif (sigisemptyset(&retarget))\n\t\treturn;\n\n\tt = tsk;\n\twhile_each_thread(tsk, t) {\n\t\tif (t->flags & PF_EXITING)\n\t\t\tcontinue;\n\n\t\tif (!has_pending_signals(&retarget, &t->blocked))\n\t\t\tcontinue;\n\t\t \n\t\tsigandsets(&retarget, &retarget, &t->blocked);\n\n\t\tif (!task_sigpending(t))\n\t\t\tsignal_wake_up(t, 0);\n\n\t\tif (sigisemptyset(&retarget))\n\t\t\tbreak;\n\t}\n}\n\nvoid exit_signals(struct task_struct *tsk)\n{\n\tint group_stop = 0;\n\tsigset_t unblocked;\n\n\t \n\tcgroup_threadgroup_change_begin(tsk);\n\n\tif (thread_group_empty(tsk) || (tsk->signal->flags & SIGNAL_GROUP_EXIT)) {\n\t\tsched_mm_cid_exit_signals(tsk);\n\t\ttsk->flags |= PF_EXITING;\n\t\tcgroup_threadgroup_change_end(tsk);\n\t\treturn;\n\t}\n\n\tspin_lock_irq(&tsk->sighand->siglock);\n\t \n\tsched_mm_cid_exit_signals(tsk);\n\ttsk->flags |= PF_EXITING;\n\n\tcgroup_threadgroup_change_end(tsk);\n\n\tif (!task_sigpending(tsk))\n\t\tgoto out;\n\n\tunblocked = tsk->blocked;\n\tsignotset(&unblocked);\n\tretarget_shared_pending(tsk, &unblocked);\n\n\tif (unlikely(tsk->jobctl & JOBCTL_STOP_PENDING) &&\n\t    task_participate_group_stop(tsk))\n\t\tgroup_stop = CLD_STOPPED;\nout:\n\tspin_unlock_irq(&tsk->sighand->siglock);\n\n\t \n\tif (unlikely(group_stop)) {\n\t\tread_lock(&tasklist_lock);\n\t\tdo_notify_parent_cldstop(tsk, false, group_stop);\n\t\tread_unlock(&tasklist_lock);\n\t}\n}\n\n \n\n \nSYSCALL_DEFINE0(restart_syscall)\n{\n\tstruct restart_block *restart = &current->restart_block;\n\treturn restart->fn(restart);\n}\n\nlong do_no_restart_syscall(struct restart_block *param)\n{\n\treturn -EINTR;\n}\n\nstatic void __set_task_blocked(struct task_struct *tsk, const sigset_t *newset)\n{\n\tif (task_sigpending(tsk) && !thread_group_empty(tsk)) {\n\t\tsigset_t newblocked;\n\t\t \n\t\tsigandnsets(&newblocked, newset, &current->blocked);\n\t\tretarget_shared_pending(tsk, &newblocked);\n\t}\n\ttsk->blocked = *newset;\n\trecalc_sigpending();\n}\n\n \nvoid set_current_blocked(sigset_t *newset)\n{\n\tsigdelsetmask(newset, sigmask(SIGKILL) | sigmask(SIGSTOP));\n\t__set_current_blocked(newset);\n}\n\nvoid __set_current_blocked(const sigset_t *newset)\n{\n\tstruct task_struct *tsk = current;\n\n\t \n\tif (sigequalsets(&tsk->blocked, newset))\n\t\treturn;\n\n\tspin_lock_irq(&tsk->sighand->siglock);\n\t__set_task_blocked(tsk, newset);\n\tspin_unlock_irq(&tsk->sighand->siglock);\n}\n\n \nint sigprocmask(int how, sigset_t *set, sigset_t *oldset)\n{\n\tstruct task_struct *tsk = current;\n\tsigset_t newset;\n\n\t \n\tif (oldset)\n\t\t*oldset = tsk->blocked;\n\n\tswitch (how) {\n\tcase SIG_BLOCK:\n\t\tsigorsets(&newset, &tsk->blocked, set);\n\t\tbreak;\n\tcase SIG_UNBLOCK:\n\t\tsigandnsets(&newset, &tsk->blocked, set);\n\t\tbreak;\n\tcase SIG_SETMASK:\n\t\tnewset = *set;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\t__set_current_blocked(&newset);\n\treturn 0;\n}\nEXPORT_SYMBOL(sigprocmask);\n\n \nint set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)\n{\n\tsigset_t kmask;\n\n\tif (!umask)\n\t\treturn 0;\n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\tif (copy_from_user(&kmask, umask, sizeof(sigset_t)))\n\t\treturn -EFAULT;\n\n\tset_restore_sigmask();\n\tcurrent->saved_sigmask = current->blocked;\n\tset_current_blocked(&kmask);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_COMPAT\nint set_compat_user_sigmask(const compat_sigset_t __user *umask,\n\t\t\t    size_t sigsetsize)\n{\n\tsigset_t kmask;\n\n\tif (!umask)\n\t\treturn 0;\n\tif (sigsetsize != sizeof(compat_sigset_t))\n\t\treturn -EINVAL;\n\tif (get_compat_sigset(&kmask, umask))\n\t\treturn -EFAULT;\n\n\tset_restore_sigmask();\n\tcurrent->saved_sigmask = current->blocked;\n\tset_current_blocked(&kmask);\n\n\treturn 0;\n}\n#endif\n\n \nSYSCALL_DEFINE4(rt_sigprocmask, int, how, sigset_t __user *, nset,\n\t\tsigset_t __user *, oset, size_t, sigsetsize)\n{\n\tsigset_t old_set, new_set;\n\tint error;\n\n\t \n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\n\told_set = current->blocked;\n\n\tif (nset) {\n\t\tif (copy_from_user(&new_set, nset, sizeof(sigset_t)))\n\t\t\treturn -EFAULT;\n\t\tsigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));\n\n\t\terror = sigprocmask(how, &new_set, NULL);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\tif (oset) {\n\t\tif (copy_to_user(oset, &old_set, sizeof(sigset_t)))\n\t\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,\n\t\tcompat_sigset_t __user *, oset, compat_size_t, sigsetsize)\n{\n\tsigset_t old_set = current->blocked;\n\n\t \n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\n\tif (nset) {\n\t\tsigset_t new_set;\n\t\tint error;\n\t\tif (get_compat_sigset(&new_set, nset))\n\t\t\treturn -EFAULT;\n\t\tsigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));\n\n\t\terror = sigprocmask(how, &new_set, NULL);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\treturn oset ? put_compat_sigset(oset, &old_set, sizeof(*oset)) : 0;\n}\n#endif\n\nstatic void do_sigpending(sigset_t *set)\n{\n\tspin_lock_irq(&current->sighand->siglock);\n\tsigorsets(set, &current->pending.signal,\n\t\t  &current->signal->shared_pending.signal);\n\tspin_unlock_irq(&current->sighand->siglock);\n\n\t \n\tsigandsets(set, &current->blocked, set);\n}\n\n \nSYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, uset, size_t, sigsetsize)\n{\n\tsigset_t set;\n\n\tif (sigsetsize > sizeof(*uset))\n\t\treturn -EINVAL;\n\n\tdo_sigpending(&set);\n\n\tif (copy_to_user(uset, &set, sigsetsize))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,\n\t\tcompat_size_t, sigsetsize)\n{\n\tsigset_t set;\n\n\tif (sigsetsize > sizeof(*uset))\n\t\treturn -EINVAL;\n\n\tdo_sigpending(&set);\n\n\treturn put_compat_sigset(uset, &set, sigsetsize);\n}\n#endif\n\nstatic const struct {\n\tunsigned char limit, layout;\n} sig_sicodes[] = {\n\t[SIGILL]  = { NSIGILL,  SIL_FAULT },\n\t[SIGFPE]  = { NSIGFPE,  SIL_FAULT },\n\t[SIGSEGV] = { NSIGSEGV, SIL_FAULT },\n\t[SIGBUS]  = { NSIGBUS,  SIL_FAULT },\n\t[SIGTRAP] = { NSIGTRAP, SIL_FAULT },\n#if defined(SIGEMT)\n\t[SIGEMT]  = { NSIGEMT,  SIL_FAULT },\n#endif\n\t[SIGCHLD] = { NSIGCHLD, SIL_CHLD },\n\t[SIGPOLL] = { NSIGPOLL, SIL_POLL },\n\t[SIGSYS]  = { NSIGSYS,  SIL_SYS },\n};\n\nstatic bool known_siginfo_layout(unsigned sig, int si_code)\n{\n\tif (si_code == SI_KERNEL)\n\t\treturn true;\n\telse if ((si_code > SI_USER)) {\n\t\tif (sig_specific_sicodes(sig)) {\n\t\t\tif (si_code <= sig_sicodes[sig].limit)\n\t\t\t\treturn true;\n\t\t}\n\t\telse if (si_code <= NSIGPOLL)\n\t\t\treturn true;\n\t}\n\telse if (si_code >= SI_DETHREAD)\n\t\treturn true;\n\telse if (si_code == SI_ASYNCNL)\n\t\treturn true;\n\treturn false;\n}\n\nenum siginfo_layout siginfo_layout(unsigned sig, int si_code)\n{\n\tenum siginfo_layout layout = SIL_KILL;\n\tif ((si_code > SI_USER) && (si_code < SI_KERNEL)) {\n\t\tif ((sig < ARRAY_SIZE(sig_sicodes)) &&\n\t\t    (si_code <= sig_sicodes[sig].limit)) {\n\t\t\tlayout = sig_sicodes[sig].layout;\n\t\t\t \n\t\t\tif ((sig == SIGBUS) &&\n\t\t\t    (si_code >= BUS_MCEERR_AR) && (si_code <= BUS_MCEERR_AO))\n\t\t\t\tlayout = SIL_FAULT_MCEERR;\n\t\t\telse if ((sig == SIGSEGV) && (si_code == SEGV_BNDERR))\n\t\t\t\tlayout = SIL_FAULT_BNDERR;\n#ifdef SEGV_PKUERR\n\t\t\telse if ((sig == SIGSEGV) && (si_code == SEGV_PKUERR))\n\t\t\t\tlayout = SIL_FAULT_PKUERR;\n#endif\n\t\t\telse if ((sig == SIGTRAP) && (si_code == TRAP_PERF))\n\t\t\t\tlayout = SIL_FAULT_PERF_EVENT;\n\t\t\telse if (IS_ENABLED(CONFIG_SPARC) &&\n\t\t\t\t (sig == SIGILL) && (si_code == ILL_ILLTRP))\n\t\t\t\tlayout = SIL_FAULT_TRAPNO;\n\t\t\telse if (IS_ENABLED(CONFIG_ALPHA) &&\n\t\t\t\t ((sig == SIGFPE) ||\n\t\t\t\t  ((sig == SIGTRAP) && (si_code == TRAP_UNK))))\n\t\t\t\tlayout = SIL_FAULT_TRAPNO;\n\t\t}\n\t\telse if (si_code <= NSIGPOLL)\n\t\t\tlayout = SIL_POLL;\n\t} else {\n\t\tif (si_code == SI_TIMER)\n\t\t\tlayout = SIL_TIMER;\n\t\telse if (si_code == SI_SIGIO)\n\t\t\tlayout = SIL_POLL;\n\t\telse if (si_code < 0)\n\t\t\tlayout = SIL_RT;\n\t}\n\treturn layout;\n}\n\nstatic inline char __user *si_expansion(const siginfo_t __user *info)\n{\n\treturn ((char __user *)info) + sizeof(struct kernel_siginfo);\n}\n\nint copy_siginfo_to_user(siginfo_t __user *to, const kernel_siginfo_t *from)\n{\n\tchar __user *expansion = si_expansion(to);\n\tif (copy_to_user(to, from , sizeof(struct kernel_siginfo)))\n\t\treturn -EFAULT;\n\tif (clear_user(expansion, SI_EXPANSION_SIZE))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int post_copy_siginfo_from_user(kernel_siginfo_t *info,\n\t\t\t\t       const siginfo_t __user *from)\n{\n\tif (unlikely(!known_siginfo_layout(info->si_signo, info->si_code))) {\n\t\tchar __user *expansion = si_expansion(from);\n\t\tchar buf[SI_EXPANSION_SIZE];\n\t\tint i;\n\t\t \n\t\tif (copy_from_user(&buf, expansion, SI_EXPANSION_SIZE))\n\t\t\treturn -EFAULT;\n\t\tfor (i = 0; i < SI_EXPANSION_SIZE; i++) {\n\t\t\tif (buf[i] != 0)\n\t\t\t\treturn -E2BIG;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int __copy_siginfo_from_user(int signo, kernel_siginfo_t *to,\n\t\t\t\t    const siginfo_t __user *from)\n{\n\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n\t\treturn -EFAULT;\n\tto->si_signo = signo;\n\treturn post_copy_siginfo_from_user(to, from);\n}\n\nint copy_siginfo_from_user(kernel_siginfo_t *to, const siginfo_t __user *from)\n{\n\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n\t\treturn -EFAULT;\n\treturn post_copy_siginfo_from_user(to, from);\n}\n\n#ifdef CONFIG_COMPAT\n \nvoid copy_siginfo_to_external32(struct compat_siginfo *to,\n\t\tconst struct kernel_siginfo *from)\n{\n\tmemset(to, 0, sizeof(*to));\n\n\tto->si_signo = from->si_signo;\n\tto->si_errno = from->si_errno;\n\tto->si_code  = from->si_code;\n\tswitch(siginfo_layout(from->si_signo, from->si_code)) {\n\tcase SIL_KILL:\n\t\tto->si_pid = from->si_pid;\n\t\tto->si_uid = from->si_uid;\n\t\tbreak;\n\tcase SIL_TIMER:\n\t\tto->si_tid     = from->si_tid;\n\t\tto->si_overrun = from->si_overrun;\n\t\tto->si_int     = from->si_int;\n\t\tbreak;\n\tcase SIL_POLL:\n\t\tto->si_band = from->si_band;\n\t\tto->si_fd   = from->si_fd;\n\t\tbreak;\n\tcase SIL_FAULT:\n\t\tto->si_addr = ptr_to_compat(from->si_addr);\n\t\tbreak;\n\tcase SIL_FAULT_TRAPNO:\n\t\tto->si_addr = ptr_to_compat(from->si_addr);\n\t\tto->si_trapno = from->si_trapno;\n\t\tbreak;\n\tcase SIL_FAULT_MCEERR:\n\t\tto->si_addr = ptr_to_compat(from->si_addr);\n\t\tto->si_addr_lsb = from->si_addr_lsb;\n\t\tbreak;\n\tcase SIL_FAULT_BNDERR:\n\t\tto->si_addr = ptr_to_compat(from->si_addr);\n\t\tto->si_lower = ptr_to_compat(from->si_lower);\n\t\tto->si_upper = ptr_to_compat(from->si_upper);\n\t\tbreak;\n\tcase SIL_FAULT_PKUERR:\n\t\tto->si_addr = ptr_to_compat(from->si_addr);\n\t\tto->si_pkey = from->si_pkey;\n\t\tbreak;\n\tcase SIL_FAULT_PERF_EVENT:\n\t\tto->si_addr = ptr_to_compat(from->si_addr);\n\t\tto->si_perf_data = from->si_perf_data;\n\t\tto->si_perf_type = from->si_perf_type;\n\t\tto->si_perf_flags = from->si_perf_flags;\n\t\tbreak;\n\tcase SIL_CHLD:\n\t\tto->si_pid = from->si_pid;\n\t\tto->si_uid = from->si_uid;\n\t\tto->si_status = from->si_status;\n\t\tto->si_utime = from->si_utime;\n\t\tto->si_stime = from->si_stime;\n\t\tbreak;\n\tcase SIL_RT:\n\t\tto->si_pid = from->si_pid;\n\t\tto->si_uid = from->si_uid;\n\t\tto->si_int = from->si_int;\n\t\tbreak;\n\tcase SIL_SYS:\n\t\tto->si_call_addr = ptr_to_compat(from->si_call_addr);\n\t\tto->si_syscall   = from->si_syscall;\n\t\tto->si_arch      = from->si_arch;\n\t\tbreak;\n\t}\n}\n\nint __copy_siginfo_to_user32(struct compat_siginfo __user *to,\n\t\t\t   const struct kernel_siginfo *from)\n{\n\tstruct compat_siginfo new;\n\n\tcopy_siginfo_to_external32(&new, from);\n\tif (copy_to_user(to, &new, sizeof(struct compat_siginfo)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int post_copy_siginfo_from_user32(kernel_siginfo_t *to,\n\t\t\t\t\t const struct compat_siginfo *from)\n{\n\tclear_siginfo(to);\n\tto->si_signo = from->si_signo;\n\tto->si_errno = from->si_errno;\n\tto->si_code  = from->si_code;\n\tswitch(siginfo_layout(from->si_signo, from->si_code)) {\n\tcase SIL_KILL:\n\t\tto->si_pid = from->si_pid;\n\t\tto->si_uid = from->si_uid;\n\t\tbreak;\n\tcase SIL_TIMER:\n\t\tto->si_tid     = from->si_tid;\n\t\tto->si_overrun = from->si_overrun;\n\t\tto->si_int     = from->si_int;\n\t\tbreak;\n\tcase SIL_POLL:\n\t\tto->si_band = from->si_band;\n\t\tto->si_fd   = from->si_fd;\n\t\tbreak;\n\tcase SIL_FAULT:\n\t\tto->si_addr = compat_ptr(from->si_addr);\n\t\tbreak;\n\tcase SIL_FAULT_TRAPNO:\n\t\tto->si_addr = compat_ptr(from->si_addr);\n\t\tto->si_trapno = from->si_trapno;\n\t\tbreak;\n\tcase SIL_FAULT_MCEERR:\n\t\tto->si_addr = compat_ptr(from->si_addr);\n\t\tto->si_addr_lsb = from->si_addr_lsb;\n\t\tbreak;\n\tcase SIL_FAULT_BNDERR:\n\t\tto->si_addr = compat_ptr(from->si_addr);\n\t\tto->si_lower = compat_ptr(from->si_lower);\n\t\tto->si_upper = compat_ptr(from->si_upper);\n\t\tbreak;\n\tcase SIL_FAULT_PKUERR:\n\t\tto->si_addr = compat_ptr(from->si_addr);\n\t\tto->si_pkey = from->si_pkey;\n\t\tbreak;\n\tcase SIL_FAULT_PERF_EVENT:\n\t\tto->si_addr = compat_ptr(from->si_addr);\n\t\tto->si_perf_data = from->si_perf_data;\n\t\tto->si_perf_type = from->si_perf_type;\n\t\tto->si_perf_flags = from->si_perf_flags;\n\t\tbreak;\n\tcase SIL_CHLD:\n\t\tto->si_pid    = from->si_pid;\n\t\tto->si_uid    = from->si_uid;\n\t\tto->si_status = from->si_status;\n#ifdef CONFIG_X86_X32_ABI\n\t\tif (in_x32_syscall()) {\n\t\t\tto->si_utime = from->_sifields._sigchld_x32._utime;\n\t\t\tto->si_stime = from->_sifields._sigchld_x32._stime;\n\t\t} else\n#endif\n\t\t{\n\t\t\tto->si_utime = from->si_utime;\n\t\t\tto->si_stime = from->si_stime;\n\t\t}\n\t\tbreak;\n\tcase SIL_RT:\n\t\tto->si_pid = from->si_pid;\n\t\tto->si_uid = from->si_uid;\n\t\tto->si_int = from->si_int;\n\t\tbreak;\n\tcase SIL_SYS:\n\t\tto->si_call_addr = compat_ptr(from->si_call_addr);\n\t\tto->si_syscall   = from->si_syscall;\n\t\tto->si_arch      = from->si_arch;\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int __copy_siginfo_from_user32(int signo, struct kernel_siginfo *to,\n\t\t\t\t      const struct compat_siginfo __user *ufrom)\n{\n\tstruct compat_siginfo from;\n\n\tif (copy_from_user(&from, ufrom, sizeof(struct compat_siginfo)))\n\t\treturn -EFAULT;\n\n\tfrom.si_signo = signo;\n\treturn post_copy_siginfo_from_user32(to, &from);\n}\n\nint copy_siginfo_from_user32(struct kernel_siginfo *to,\n\t\t\t     const struct compat_siginfo __user *ufrom)\n{\n\tstruct compat_siginfo from;\n\n\tif (copy_from_user(&from, ufrom, sizeof(struct compat_siginfo)))\n\t\treturn -EFAULT;\n\n\treturn post_copy_siginfo_from_user32(to, &from);\n}\n#endif  \n\n \nstatic int do_sigtimedwait(const sigset_t *which, kernel_siginfo_t *info,\n\t\t    const struct timespec64 *ts)\n{\n\tktime_t *to = NULL, timeout = KTIME_MAX;\n\tstruct task_struct *tsk = current;\n\tsigset_t mask = *which;\n\tenum pid_type type;\n\tint sig, ret = 0;\n\n\tif (ts) {\n\t\tif (!timespec64_valid(ts))\n\t\t\treturn -EINVAL;\n\t\ttimeout = timespec64_to_ktime(*ts);\n\t\tto = &timeout;\n\t}\n\n\t \n\tsigdelsetmask(&mask, sigmask(SIGKILL) | sigmask(SIGSTOP));\n\tsignotset(&mask);\n\n\tspin_lock_irq(&tsk->sighand->siglock);\n\tsig = dequeue_signal(tsk, &mask, info, &type);\n\tif (!sig && timeout) {\n\t\t \n\t\ttsk->real_blocked = tsk->blocked;\n\t\tsigandsets(&tsk->blocked, &tsk->blocked, &mask);\n\t\trecalc_sigpending();\n\t\tspin_unlock_irq(&tsk->sighand->siglock);\n\n\t\t__set_current_state(TASK_INTERRUPTIBLE|TASK_FREEZABLE);\n\t\tret = schedule_hrtimeout_range(to, tsk->timer_slack_ns,\n\t\t\t\t\t       HRTIMER_MODE_REL);\n\t\tspin_lock_irq(&tsk->sighand->siglock);\n\t\t__set_task_blocked(tsk, &tsk->real_blocked);\n\t\tsigemptyset(&tsk->real_blocked);\n\t\tsig = dequeue_signal(tsk, &mask, info, &type);\n\t}\n\tspin_unlock_irq(&tsk->sighand->siglock);\n\n\tif (sig)\n\t\treturn sig;\n\treturn ret ? -EINTR : -EAGAIN;\n}\n\n \nSYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,\n\t\tsiginfo_t __user *, uinfo,\n\t\tconst struct __kernel_timespec __user *, uts,\n\t\tsize_t, sigsetsize)\n{\n\tsigset_t these;\n\tstruct timespec64 ts;\n\tkernel_siginfo_t info;\n\tint ret;\n\n\t \n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&these, uthese, sizeof(these)))\n\t\treturn -EFAULT;\n\n\tif (uts) {\n\t\tif (get_timespec64(&ts, uts))\n\t\t\treturn -EFAULT;\n\t}\n\n\tret = do_sigtimedwait(&these, &info, uts ? &ts : NULL);\n\n\tif (ret > 0 && uinfo) {\n\t\tif (copy_siginfo_to_user(uinfo, &info))\n\t\t\tret = -EFAULT;\n\t}\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT_32BIT_TIME\nSYSCALL_DEFINE4(rt_sigtimedwait_time32, const sigset_t __user *, uthese,\n\t\tsiginfo_t __user *, uinfo,\n\t\tconst struct old_timespec32 __user *, uts,\n\t\tsize_t, sigsetsize)\n{\n\tsigset_t these;\n\tstruct timespec64 ts;\n\tkernel_siginfo_t info;\n\tint ret;\n\n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&these, uthese, sizeof(these)))\n\t\treturn -EFAULT;\n\n\tif (uts) {\n\t\tif (get_old_timespec32(&ts, uts))\n\t\t\treturn -EFAULT;\n\t}\n\n\tret = do_sigtimedwait(&these, &info, uts ? &ts : NULL);\n\n\tif (ret > 0 && uinfo) {\n\t\tif (copy_siginfo_to_user(uinfo, &info))\n\t\t\tret = -EFAULT;\n\t}\n\n\treturn ret;\n}\n#endif\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE4(rt_sigtimedwait_time64, compat_sigset_t __user *, uthese,\n\t\tstruct compat_siginfo __user *, uinfo,\n\t\tstruct __kernel_timespec __user *, uts, compat_size_t, sigsetsize)\n{\n\tsigset_t s;\n\tstruct timespec64 t;\n\tkernel_siginfo_t info;\n\tlong ret;\n\n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\n\tif (get_compat_sigset(&s, uthese))\n\t\treturn -EFAULT;\n\n\tif (uts) {\n\t\tif (get_timespec64(&t, uts))\n\t\t\treturn -EFAULT;\n\t}\n\n\tret = do_sigtimedwait(&s, &info, uts ? &t : NULL);\n\n\tif (ret > 0 && uinfo) {\n\t\tif (copy_siginfo_to_user32(uinfo, &info))\n\t\t\tret = -EFAULT;\n\t}\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT_32BIT_TIME\nCOMPAT_SYSCALL_DEFINE4(rt_sigtimedwait_time32, compat_sigset_t __user *, uthese,\n\t\tstruct compat_siginfo __user *, uinfo,\n\t\tstruct old_timespec32 __user *, uts, compat_size_t, sigsetsize)\n{\n\tsigset_t s;\n\tstruct timespec64 t;\n\tkernel_siginfo_t info;\n\tlong ret;\n\n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\n\tif (get_compat_sigset(&s, uthese))\n\t\treturn -EFAULT;\n\n\tif (uts) {\n\t\tif (get_old_timespec32(&t, uts))\n\t\t\treturn -EFAULT;\n\t}\n\n\tret = do_sigtimedwait(&s, &info, uts ? &t : NULL);\n\n\tif (ret > 0 && uinfo) {\n\t\tif (copy_siginfo_to_user32(uinfo, &info))\n\t\t\tret = -EFAULT;\n\t}\n\n\treturn ret;\n}\n#endif\n#endif\n\nstatic inline void prepare_kill_siginfo(int sig, struct kernel_siginfo *info)\n{\n\tclear_siginfo(info);\n\tinfo->si_signo = sig;\n\tinfo->si_errno = 0;\n\tinfo->si_code = SI_USER;\n\tinfo->si_pid = task_tgid_vnr(current);\n\tinfo->si_uid = from_kuid_munged(current_user_ns(), current_uid());\n}\n\n \nSYSCALL_DEFINE2(kill, pid_t, pid, int, sig)\n{\n\tstruct kernel_siginfo info;\n\n\tprepare_kill_siginfo(sig, &info);\n\n\treturn kill_something_info(sig, &info, pid);\n}\n\n \nstatic bool access_pidfd_pidns(struct pid *pid)\n{\n\tstruct pid_namespace *active = task_active_pid_ns(current);\n\tstruct pid_namespace *p = ns_of_pid(pid);\n\n\tfor (;;) {\n\t\tif (!p)\n\t\t\treturn false;\n\t\tif (p == active)\n\t\t\tbreak;\n\t\tp = p->parent;\n\t}\n\n\treturn true;\n}\n\nstatic int copy_siginfo_from_user_any(kernel_siginfo_t *kinfo,\n\t\tsiginfo_t __user *info)\n{\n#ifdef CONFIG_COMPAT\n\t \n\tif (in_compat_syscall())\n\t\treturn copy_siginfo_from_user32(\n\t\t\tkinfo, (struct compat_siginfo __user *)info);\n#endif\n\treturn copy_siginfo_from_user(kinfo, info);\n}\n\nstatic struct pid *pidfd_to_pid(const struct file *file)\n{\n\tstruct pid *pid;\n\n\tpid = pidfd_pid(file);\n\tif (!IS_ERR(pid))\n\t\treturn pid;\n\n\treturn tgid_pidfd_to_pid(file);\n}\n\n \nSYSCALL_DEFINE4(pidfd_send_signal, int, pidfd, int, sig,\n\t\tsiginfo_t __user *, info, unsigned int, flags)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct pid *pid;\n\tkernel_siginfo_t kinfo;\n\n\t \n\tif (flags)\n\t\treturn -EINVAL;\n\n\tf = fdget(pidfd);\n\tif (!f.file)\n\t\treturn -EBADF;\n\n\t \n\tpid = pidfd_to_pid(f.file);\n\tif (IS_ERR(pid)) {\n\t\tret = PTR_ERR(pid);\n\t\tgoto err;\n\t}\n\n\tret = -EINVAL;\n\tif (!access_pidfd_pidns(pid))\n\t\tgoto err;\n\n\tif (info) {\n\t\tret = copy_siginfo_from_user_any(&kinfo, info);\n\t\tif (unlikely(ret))\n\t\t\tgoto err;\n\n\t\tret = -EINVAL;\n\t\tif (unlikely(sig != kinfo.si_signo))\n\t\t\tgoto err;\n\n\t\t \n\t\tret = -EPERM;\n\t\tif ((task_pid(current) != pid) &&\n\t\t    (kinfo.si_code >= 0 || kinfo.si_code == SI_TKILL))\n\t\t\tgoto err;\n\t} else {\n\t\tprepare_kill_siginfo(sig, &kinfo);\n\t}\n\n\tret = kill_pid_info(sig, &kinfo, pid);\n\nerr:\n\tfdput(f);\n\treturn ret;\n}\n\nstatic int\ndo_send_specific(pid_t tgid, pid_t pid, int sig, struct kernel_siginfo *info)\n{\n\tstruct task_struct *p;\n\tint error = -ESRCH;\n\n\trcu_read_lock();\n\tp = find_task_by_vpid(pid);\n\tif (p && (tgid <= 0 || task_tgid_vnr(p) == tgid)) {\n\t\terror = check_kill_permission(sig, info, p);\n\t\t \n\t\tif (!error && sig) {\n\t\t\terror = do_send_sig_info(sig, info, p, PIDTYPE_PID);\n\t\t\t \n\t\t\tif (unlikely(error == -ESRCH))\n\t\t\t\terror = 0;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn error;\n}\n\nstatic int do_tkill(pid_t tgid, pid_t pid, int sig)\n{\n\tstruct kernel_siginfo info;\n\n\tclear_siginfo(&info);\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code = SI_TKILL;\n\tinfo.si_pid = task_tgid_vnr(current);\n\tinfo.si_uid = from_kuid_munged(current_user_ns(), current_uid());\n\n\treturn do_send_specific(tgid, pid, sig, &info);\n}\n\n \nSYSCALL_DEFINE3(tgkill, pid_t, tgid, pid_t, pid, int, sig)\n{\n\t \n\tif (pid <= 0 || tgid <= 0)\n\t\treturn -EINVAL;\n\n\treturn do_tkill(tgid, pid, sig);\n}\n\n \nSYSCALL_DEFINE2(tkill, pid_t, pid, int, sig)\n{\n\t \n\tif (pid <= 0)\n\t\treturn -EINVAL;\n\n\treturn do_tkill(0, pid, sig);\n}\n\nstatic int do_rt_sigqueueinfo(pid_t pid, int sig, kernel_siginfo_t *info)\n{\n\t \n\tif ((info->si_code >= 0 || info->si_code == SI_TKILL) &&\n\t    (task_pid_vnr(current) != pid))\n\t\treturn -EPERM;\n\n\t \n\treturn kill_proc_info(sig, info, pid);\n}\n\n \nSYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,\n\t\tsiginfo_t __user *, uinfo)\n{\n\tkernel_siginfo_t info;\n\tint ret = __copy_siginfo_from_user(sig, &info, uinfo);\n\tif (unlikely(ret))\n\t\treturn ret;\n\treturn do_rt_sigqueueinfo(pid, sig, &info);\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,\n\t\t\tcompat_pid_t, pid,\n\t\t\tint, sig,\n\t\t\tstruct compat_siginfo __user *, uinfo)\n{\n\tkernel_siginfo_t info;\n\tint ret = __copy_siginfo_from_user32(sig, &info, uinfo);\n\tif (unlikely(ret))\n\t\treturn ret;\n\treturn do_rt_sigqueueinfo(pid, sig, &info);\n}\n#endif\n\nstatic int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, kernel_siginfo_t *info)\n{\n\t \n\tif (pid <= 0 || tgid <= 0)\n\t\treturn -EINVAL;\n\n\t \n\tif ((info->si_code >= 0 || info->si_code == SI_TKILL) &&\n\t    (task_pid_vnr(current) != pid))\n\t\treturn -EPERM;\n\n\treturn do_send_specific(tgid, pid, sig, info);\n}\n\nSYSCALL_DEFINE4(rt_tgsigqueueinfo, pid_t, tgid, pid_t, pid, int, sig,\n\t\tsiginfo_t __user *, uinfo)\n{\n\tkernel_siginfo_t info;\n\tint ret = __copy_siginfo_from_user(sig, &info, uinfo);\n\tif (unlikely(ret))\n\t\treturn ret;\n\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,\n\t\t\tcompat_pid_t, tgid,\n\t\t\tcompat_pid_t, pid,\n\t\t\tint, sig,\n\t\t\tstruct compat_siginfo __user *, uinfo)\n{\n\tkernel_siginfo_t info;\n\tint ret = __copy_siginfo_from_user32(sig, &info, uinfo);\n\tif (unlikely(ret))\n\t\treturn ret;\n\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n}\n#endif\n\n \nvoid kernel_sigaction(int sig, __sighandler_t action)\n{\n\tspin_lock_irq(&current->sighand->siglock);\n\tcurrent->sighand->action[sig - 1].sa.sa_handler = action;\n\tif (action == SIG_IGN) {\n\t\tsigset_t mask;\n\n\t\tsigemptyset(&mask);\n\t\tsigaddset(&mask, sig);\n\n\t\tflush_sigqueue_mask(&mask, &current->signal->shared_pending);\n\t\tflush_sigqueue_mask(&mask, &current->pending);\n\t\trecalc_sigpending();\n\t}\n\tspin_unlock_irq(&current->sighand->siglock);\n}\nEXPORT_SYMBOL(kernel_sigaction);\n\nvoid __weak sigaction_compat_abi(struct k_sigaction *act,\n\t\tstruct k_sigaction *oact)\n{\n}\n\nint do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)\n{\n\tstruct task_struct *p = current, *t;\n\tstruct k_sigaction *k;\n\tsigset_t mask;\n\n\tif (!valid_signal(sig) || sig < 1 || (act && sig_kernel_only(sig)))\n\t\treturn -EINVAL;\n\n\tk = &p->sighand->action[sig-1];\n\n\tspin_lock_irq(&p->sighand->siglock);\n\tif (k->sa.sa_flags & SA_IMMUTABLE) {\n\t\tspin_unlock_irq(&p->sighand->siglock);\n\t\treturn -EINVAL;\n\t}\n\tif (oact)\n\t\t*oact = *k;\n\n\t \n\tBUILD_BUG_ON(UAPI_SA_FLAGS & SA_UNSUPPORTED);\n\n\t \n\tif (act)\n\t\tact->sa.sa_flags &= UAPI_SA_FLAGS;\n\tif (oact)\n\t\toact->sa.sa_flags &= UAPI_SA_FLAGS;\n\n\tsigaction_compat_abi(act, oact);\n\n\tif (act) {\n\t\tsigdelsetmask(&act->sa.sa_mask,\n\t\t\t      sigmask(SIGKILL) | sigmask(SIGSTOP));\n\t\t*k = *act;\n\t\t \n\t\tif (sig_handler_ignored(sig_handler(p, sig), sig)) {\n\t\t\tsigemptyset(&mask);\n\t\t\tsigaddset(&mask, sig);\n\t\t\tflush_sigqueue_mask(&mask, &p->signal->shared_pending);\n\t\t\tfor_each_thread(p, t)\n\t\t\t\tflush_sigqueue_mask(&mask, &t->pending);\n\t\t}\n\t}\n\n\tspin_unlock_irq(&p->sighand->siglock);\n\treturn 0;\n}\n\n#ifdef CONFIG_DYNAMIC_SIGFRAME\nstatic inline void sigaltstack_lock(void)\n\t__acquires(&current->sighand->siglock)\n{\n\tspin_lock_irq(&current->sighand->siglock);\n}\n\nstatic inline void sigaltstack_unlock(void)\n\t__releases(&current->sighand->siglock)\n{\n\tspin_unlock_irq(&current->sighand->siglock);\n}\n#else\nstatic inline void sigaltstack_lock(void) { }\nstatic inline void sigaltstack_unlock(void) { }\n#endif\n\nstatic int\ndo_sigaltstack (const stack_t *ss, stack_t *oss, unsigned long sp,\n\t\tsize_t min_ss_size)\n{\n\tstruct task_struct *t = current;\n\tint ret = 0;\n\n\tif (oss) {\n\t\tmemset(oss, 0, sizeof(stack_t));\n\t\toss->ss_sp = (void __user *) t->sas_ss_sp;\n\t\toss->ss_size = t->sas_ss_size;\n\t\toss->ss_flags = sas_ss_flags(sp) |\n\t\t\t(current->sas_ss_flags & SS_FLAG_BITS);\n\t}\n\n\tif (ss) {\n\t\tvoid __user *ss_sp = ss->ss_sp;\n\t\tsize_t ss_size = ss->ss_size;\n\t\tunsigned ss_flags = ss->ss_flags;\n\t\tint ss_mode;\n\n\t\tif (unlikely(on_sig_stack(sp)))\n\t\t\treturn -EPERM;\n\n\t\tss_mode = ss_flags & ~SS_FLAG_BITS;\n\t\tif (unlikely(ss_mode != SS_DISABLE && ss_mode != SS_ONSTACK &&\n\t\t\t\tss_mode != 0))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (t->sas_ss_sp == (unsigned long)ss_sp &&\n\t\t    t->sas_ss_size == ss_size &&\n\t\t    t->sas_ss_flags == ss_flags)\n\t\t\treturn 0;\n\n\t\tsigaltstack_lock();\n\t\tif (ss_mode == SS_DISABLE) {\n\t\t\tss_size = 0;\n\t\t\tss_sp = NULL;\n\t\t} else {\n\t\t\tif (unlikely(ss_size < min_ss_size))\n\t\t\t\tret = -ENOMEM;\n\t\t\tif (!sigaltstack_size_valid(ss_size))\n\t\t\t\tret = -ENOMEM;\n\t\t}\n\t\tif (!ret) {\n\t\t\tt->sas_ss_sp = (unsigned long) ss_sp;\n\t\t\tt->sas_ss_size = ss_size;\n\t\t\tt->sas_ss_flags = ss_flags;\n\t\t}\n\t\tsigaltstack_unlock();\n\t}\n\treturn ret;\n}\n\nSYSCALL_DEFINE2(sigaltstack,const stack_t __user *,uss, stack_t __user *,uoss)\n{\n\tstack_t new, old;\n\tint err;\n\tif (uss && copy_from_user(&new, uss, sizeof(stack_t)))\n\t\treturn -EFAULT;\n\terr = do_sigaltstack(uss ? &new : NULL, uoss ? &old : NULL,\n\t\t\t      current_user_stack_pointer(),\n\t\t\t      MINSIGSTKSZ);\n\tif (!err && uoss && copy_to_user(uoss, &old, sizeof(stack_t)))\n\t\terr = -EFAULT;\n\treturn err;\n}\n\nint restore_altstack(const stack_t __user *uss)\n{\n\tstack_t new;\n\tif (copy_from_user(&new, uss, sizeof(stack_t)))\n\t\treturn -EFAULT;\n\t(void)do_sigaltstack(&new, NULL, current_user_stack_pointer(),\n\t\t\t     MINSIGSTKSZ);\n\t \n\treturn 0;\n}\n\nint __save_altstack(stack_t __user *uss, unsigned long sp)\n{\n\tstruct task_struct *t = current;\n\tint err = __put_user((void __user *)t->sas_ss_sp, &uss->ss_sp) |\n\t\t__put_user(t->sas_ss_flags, &uss->ss_flags) |\n\t\t__put_user(t->sas_ss_size, &uss->ss_size);\n\treturn err;\n}\n\n#ifdef CONFIG_COMPAT\nstatic int do_compat_sigaltstack(const compat_stack_t __user *uss_ptr,\n\t\t\t\t compat_stack_t __user *uoss_ptr)\n{\n\tstack_t uss, uoss;\n\tint ret;\n\n\tif (uss_ptr) {\n\t\tcompat_stack_t uss32;\n\t\tif (copy_from_user(&uss32, uss_ptr, sizeof(compat_stack_t)))\n\t\t\treturn -EFAULT;\n\t\tuss.ss_sp = compat_ptr(uss32.ss_sp);\n\t\tuss.ss_flags = uss32.ss_flags;\n\t\tuss.ss_size = uss32.ss_size;\n\t}\n\tret = do_sigaltstack(uss_ptr ? &uss : NULL, &uoss,\n\t\t\t     compat_user_stack_pointer(),\n\t\t\t     COMPAT_MINSIGSTKSZ);\n\tif (ret >= 0 && uoss_ptr)  {\n\t\tcompat_stack_t old;\n\t\tmemset(&old, 0, sizeof(old));\n\t\told.ss_sp = ptr_to_compat(uoss.ss_sp);\n\t\told.ss_flags = uoss.ss_flags;\n\t\told.ss_size = uoss.ss_size;\n\t\tif (copy_to_user(uoss_ptr, &old, sizeof(compat_stack_t)))\n\t\t\tret = -EFAULT;\n\t}\n\treturn ret;\n}\n\nCOMPAT_SYSCALL_DEFINE2(sigaltstack,\n\t\t\tconst compat_stack_t __user *, uss_ptr,\n\t\t\tcompat_stack_t __user *, uoss_ptr)\n{\n\treturn do_compat_sigaltstack(uss_ptr, uoss_ptr);\n}\n\nint compat_restore_altstack(const compat_stack_t __user *uss)\n{\n\tint err = do_compat_sigaltstack(uss, NULL);\n\t \n\treturn err == -EFAULT ? err : 0;\n}\n\nint __compat_save_altstack(compat_stack_t __user *uss, unsigned long sp)\n{\n\tint err;\n\tstruct task_struct *t = current;\n\terr = __put_user(ptr_to_compat((void __user *)t->sas_ss_sp),\n\t\t\t &uss->ss_sp) |\n\t\t__put_user(t->sas_ss_flags, &uss->ss_flags) |\n\t\t__put_user(t->sas_ss_size, &uss->ss_size);\n\treturn err;\n}\n#endif\n\n#ifdef __ARCH_WANT_SYS_SIGPENDING\n\n \nSYSCALL_DEFINE1(sigpending, old_sigset_t __user *, uset)\n{\n\tsigset_t set;\n\n\tif (sizeof(old_sigset_t) > sizeof(*uset))\n\t\treturn -EINVAL;\n\n\tdo_sigpending(&set);\n\n\tif (copy_to_user(uset, &set, sizeof(old_sigset_t)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE1(sigpending, compat_old_sigset_t __user *, set32)\n{\n\tsigset_t set;\n\n\tdo_sigpending(&set);\n\n\treturn put_user(set.sig[0], set32);\n}\n#endif\n\n#endif\n\n#ifdef __ARCH_WANT_SYS_SIGPROCMASK\n \n\nSYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, nset,\n\t\told_sigset_t __user *, oset)\n{\n\told_sigset_t old_set, new_set;\n\tsigset_t new_blocked;\n\n\told_set = current->blocked.sig[0];\n\n\tif (nset) {\n\t\tif (copy_from_user(&new_set, nset, sizeof(*nset)))\n\t\t\treturn -EFAULT;\n\n\t\tnew_blocked = current->blocked;\n\n\t\tswitch (how) {\n\t\tcase SIG_BLOCK:\n\t\t\tsigaddsetmask(&new_blocked, new_set);\n\t\t\tbreak;\n\t\tcase SIG_UNBLOCK:\n\t\t\tsigdelsetmask(&new_blocked, new_set);\n\t\t\tbreak;\n\t\tcase SIG_SETMASK:\n\t\t\tnew_blocked.sig[0] = new_set;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tset_current_blocked(&new_blocked);\n\t}\n\n\tif (oset) {\n\t\tif (copy_to_user(oset, &old_set, sizeof(*oset)))\n\t\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n#endif  \n\n#ifndef CONFIG_ODD_RT_SIGACTION\n \nSYSCALL_DEFINE4(rt_sigaction, int, sig,\n\t\tconst struct sigaction __user *, act,\n\t\tstruct sigaction __user *, oact,\n\t\tsize_t, sigsetsize)\n{\n\tstruct k_sigaction new_sa, old_sa;\n\tint ret;\n\n\t \n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\n\tif (act && copy_from_user(&new_sa.sa, act, sizeof(new_sa.sa)))\n\t\treturn -EFAULT;\n\n\tret = do_sigaction(sig, act ? &new_sa : NULL, oact ? &old_sa : NULL);\n\tif (ret)\n\t\treturn ret;\n\n\tif (oact && copy_to_user(oact, &old_sa.sa, sizeof(old_sa.sa)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,\n\t\tconst struct compat_sigaction __user *, act,\n\t\tstruct compat_sigaction __user *, oact,\n\t\tcompat_size_t, sigsetsize)\n{\n\tstruct k_sigaction new_ka, old_ka;\n#ifdef __ARCH_HAS_SA_RESTORER\n\tcompat_uptr_t restorer;\n#endif\n\tint ret;\n\n\t \n\tif (sigsetsize != sizeof(compat_sigset_t))\n\t\treturn -EINVAL;\n\n\tif (act) {\n\t\tcompat_uptr_t handler;\n\t\tret = get_user(handler, &act->sa_handler);\n\t\tnew_ka.sa.sa_handler = compat_ptr(handler);\n#ifdef __ARCH_HAS_SA_RESTORER\n\t\tret |= get_user(restorer, &act->sa_restorer);\n\t\tnew_ka.sa.sa_restorer = compat_ptr(restorer);\n#endif\n\t\tret |= get_compat_sigset(&new_ka.sa.sa_mask, &act->sa_mask);\n\t\tret |= get_user(new_ka.sa.sa_flags, &act->sa_flags);\n\t\tif (ret)\n\t\t\treturn -EFAULT;\n\t}\n\n\tret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);\n\tif (!ret && oact) {\n\t\tret = put_user(ptr_to_compat(old_ka.sa.sa_handler), \n\t\t\t       &oact->sa_handler);\n\t\tret |= put_compat_sigset(&oact->sa_mask, &old_ka.sa.sa_mask,\n\t\t\t\t\t sizeof(oact->sa_mask));\n\t\tret |= put_user(old_ka.sa.sa_flags, &oact->sa_flags);\n#ifdef __ARCH_HAS_SA_RESTORER\n\t\tret |= put_user(ptr_to_compat(old_ka.sa.sa_restorer),\n\t\t\t\t&oact->sa_restorer);\n#endif\n\t}\n\treturn ret;\n}\n#endif\n#endif  \n\n#ifdef CONFIG_OLD_SIGACTION\nSYSCALL_DEFINE3(sigaction, int, sig,\n\t\tconst struct old_sigaction __user *, act,\n\t        struct old_sigaction __user *, oact)\n{\n\tstruct k_sigaction new_ka, old_ka;\n\tint ret;\n\n\tif (act) {\n\t\told_sigset_t mask;\n\t\tif (!access_ok(act, sizeof(*act)) ||\n\t\t    __get_user(new_ka.sa.sa_handler, &act->sa_handler) ||\n\t\t    __get_user(new_ka.sa.sa_restorer, &act->sa_restorer) ||\n\t\t    __get_user(new_ka.sa.sa_flags, &act->sa_flags) ||\n\t\t    __get_user(mask, &act->sa_mask))\n\t\t\treturn -EFAULT;\n#ifdef __ARCH_HAS_KA_RESTORER\n\t\tnew_ka.ka_restorer = NULL;\n#endif\n\t\tsiginitset(&new_ka.sa.sa_mask, mask);\n\t}\n\n\tret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);\n\n\tif (!ret && oact) {\n\t\tif (!access_ok(oact, sizeof(*oact)) ||\n\t\t    __put_user(old_ka.sa.sa_handler, &oact->sa_handler) ||\n\t\t    __put_user(old_ka.sa.sa_restorer, &oact->sa_restorer) ||\n\t\t    __put_user(old_ka.sa.sa_flags, &oact->sa_flags) ||\n\t\t    __put_user(old_ka.sa.sa_mask.sig[0], &oact->sa_mask))\n\t\t\treturn -EFAULT;\n\t}\n\n\treturn ret;\n}\n#endif\n#ifdef CONFIG_COMPAT_OLD_SIGACTION\nCOMPAT_SYSCALL_DEFINE3(sigaction, int, sig,\n\t\tconst struct compat_old_sigaction __user *, act,\n\t        struct compat_old_sigaction __user *, oact)\n{\n\tstruct k_sigaction new_ka, old_ka;\n\tint ret;\n\tcompat_old_sigset_t mask;\n\tcompat_uptr_t handler, restorer;\n\n\tif (act) {\n\t\tif (!access_ok(act, sizeof(*act)) ||\n\t\t    __get_user(handler, &act->sa_handler) ||\n\t\t    __get_user(restorer, &act->sa_restorer) ||\n\t\t    __get_user(new_ka.sa.sa_flags, &act->sa_flags) ||\n\t\t    __get_user(mask, &act->sa_mask))\n\t\t\treturn -EFAULT;\n\n#ifdef __ARCH_HAS_KA_RESTORER\n\t\tnew_ka.ka_restorer = NULL;\n#endif\n\t\tnew_ka.sa.sa_handler = compat_ptr(handler);\n\t\tnew_ka.sa.sa_restorer = compat_ptr(restorer);\n\t\tsiginitset(&new_ka.sa.sa_mask, mask);\n\t}\n\n\tret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);\n\n\tif (!ret && oact) {\n\t\tif (!access_ok(oact, sizeof(*oact)) ||\n\t\t    __put_user(ptr_to_compat(old_ka.sa.sa_handler),\n\t\t\t       &oact->sa_handler) ||\n\t\t    __put_user(ptr_to_compat(old_ka.sa.sa_restorer),\n\t\t\t       &oact->sa_restorer) ||\n\t\t    __put_user(old_ka.sa.sa_flags, &oact->sa_flags) ||\n\t\t    __put_user(old_ka.sa.sa_mask.sig[0], &oact->sa_mask))\n\t\t\treturn -EFAULT;\n\t}\n\treturn ret;\n}\n#endif\n\n#ifdef CONFIG_SGETMASK_SYSCALL\n\n \nSYSCALL_DEFINE0(sgetmask)\n{\n\t \n\treturn current->blocked.sig[0];\n}\n\nSYSCALL_DEFINE1(ssetmask, int, newmask)\n{\n\tint old = current->blocked.sig[0];\n\tsigset_t newset;\n\n\tsiginitset(&newset, newmask);\n\tset_current_blocked(&newset);\n\n\treturn old;\n}\n#endif  \n\n#ifdef __ARCH_WANT_SYS_SIGNAL\n \nSYSCALL_DEFINE2(signal, int, sig, __sighandler_t, handler)\n{\n\tstruct k_sigaction new_sa, old_sa;\n\tint ret;\n\n\tnew_sa.sa.sa_handler = handler;\n\tnew_sa.sa.sa_flags = SA_ONESHOT | SA_NOMASK;\n\tsigemptyset(&new_sa.sa.sa_mask);\n\n\tret = do_sigaction(sig, &new_sa, &old_sa);\n\n\treturn ret ? ret : (unsigned long)old_sa.sa.sa_handler;\n}\n#endif  \n\n#ifdef __ARCH_WANT_SYS_PAUSE\n\nSYSCALL_DEFINE0(pause)\n{\n\twhile (!signal_pending(current)) {\n\t\t__set_current_state(TASK_INTERRUPTIBLE);\n\t\tschedule();\n\t}\n\treturn -ERESTARTNOHAND;\n}\n\n#endif\n\nstatic int sigsuspend(sigset_t *set)\n{\n\tcurrent->saved_sigmask = current->blocked;\n\tset_current_blocked(set);\n\n\twhile (!signal_pending(current)) {\n\t\t__set_current_state(TASK_INTERRUPTIBLE);\n\t\tschedule();\n\t}\n\tset_restore_sigmask();\n\treturn -ERESTARTNOHAND;\n}\n\n \nSYSCALL_DEFINE2(rt_sigsuspend, sigset_t __user *, unewset, size_t, sigsetsize)\n{\n\tsigset_t newset;\n\n\t \n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&newset, unewset, sizeof(newset)))\n\t\treturn -EFAULT;\n\treturn sigsuspend(&newset);\n}\n \n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE2(rt_sigsuspend, compat_sigset_t __user *, unewset, compat_size_t, sigsetsize)\n{\n\tsigset_t newset;\n\n\t \n\tif (sigsetsize != sizeof(sigset_t))\n\t\treturn -EINVAL;\n\n\tif (get_compat_sigset(&newset, unewset))\n\t\treturn -EFAULT;\n\treturn sigsuspend(&newset);\n}\n#endif\n\n#ifdef CONFIG_OLD_SIGSUSPEND\nSYSCALL_DEFINE1(sigsuspend, old_sigset_t, mask)\n{\n\tsigset_t blocked;\n\tsiginitset(&blocked, mask);\n\treturn sigsuspend(&blocked);\n}\n#endif\n#ifdef CONFIG_OLD_SIGSUSPEND3\nSYSCALL_DEFINE3(sigsuspend, int, unused1, int, unused2, old_sigset_t, mask)\n{\n\tsigset_t blocked;\n\tsiginitset(&blocked, mask);\n\treturn sigsuspend(&blocked);\n}\n#endif\n\n__weak const char *arch_vma_name(struct vm_area_struct *vma)\n{\n\treturn NULL;\n}\n\nstatic inline void siginfo_buildtime_checks(void)\n{\n\tBUILD_BUG_ON(sizeof(struct siginfo) != SI_MAX_SIZE);\n\n\t \n#define CHECK_OFFSET(field) \\\n\tBUILD_BUG_ON(offsetof(siginfo_t, field) != offsetof(kernel_siginfo_t, field))\n\n\t \n\tCHECK_OFFSET(si_pid);\n\tCHECK_OFFSET(si_uid);\n\n\t \n\tCHECK_OFFSET(si_tid);\n\tCHECK_OFFSET(si_overrun);\n\tCHECK_OFFSET(si_value);\n\n\t \n\tCHECK_OFFSET(si_pid);\n\tCHECK_OFFSET(si_uid);\n\tCHECK_OFFSET(si_value);\n\n\t \n\tCHECK_OFFSET(si_pid);\n\tCHECK_OFFSET(si_uid);\n\tCHECK_OFFSET(si_status);\n\tCHECK_OFFSET(si_utime);\n\tCHECK_OFFSET(si_stime);\n\n\t \n\tCHECK_OFFSET(si_addr);\n\tCHECK_OFFSET(si_trapno);\n\tCHECK_OFFSET(si_addr_lsb);\n\tCHECK_OFFSET(si_lower);\n\tCHECK_OFFSET(si_upper);\n\tCHECK_OFFSET(si_pkey);\n\tCHECK_OFFSET(si_perf_data);\n\tCHECK_OFFSET(si_perf_type);\n\tCHECK_OFFSET(si_perf_flags);\n\n\t \n\tCHECK_OFFSET(si_band);\n\tCHECK_OFFSET(si_fd);\n\n\t \n\tCHECK_OFFSET(si_call_addr);\n\tCHECK_OFFSET(si_syscall);\n\tCHECK_OFFSET(si_arch);\n#undef CHECK_OFFSET\n\n\t \n\tBUILD_BUG_ON(offsetof(struct siginfo, si_pid) !=\n\t\t     offsetof(struct siginfo, si_addr));\n\tif (sizeof(int) == sizeof(void __user *)) {\n\t\tBUILD_BUG_ON(sizeof_field(struct siginfo, si_pid) !=\n\t\t\t     sizeof(void __user *));\n\t} else {\n\t\tBUILD_BUG_ON((sizeof_field(struct siginfo, si_pid) +\n\t\t\t      sizeof_field(struct siginfo, si_uid)) !=\n\t\t\t     sizeof(void __user *));\n\t\tBUILD_BUG_ON(offsetofend(struct siginfo, si_pid) !=\n\t\t\t     offsetof(struct siginfo, si_uid));\n\t}\n#ifdef CONFIG_COMPAT\n\tBUILD_BUG_ON(offsetof(struct compat_siginfo, si_pid) !=\n\t\t     offsetof(struct compat_siginfo, si_addr));\n\tBUILD_BUG_ON(sizeof_field(struct compat_siginfo, si_pid) !=\n\t\t     sizeof(compat_uptr_t));\n\tBUILD_BUG_ON(sizeof_field(struct compat_siginfo, si_pid) !=\n\t\t     sizeof_field(struct siginfo, si_pid));\n#endif\n}\n\n#if defined(CONFIG_SYSCTL)\nstatic struct ctl_table signal_debug_table[] = {\n#ifdef CONFIG_SYSCTL_EXCEPTION_TRACE\n\t{\n\t\t.procname\t= \"exception-trace\",\n\t\t.data\t\t= &show_unhandled_signals,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec\n\t},\n#endif\n\t{ }\n};\n\nstatic int __init init_signal_sysctls(void)\n{\n\tregister_sysctl_init(\"debug\", signal_debug_table);\n\treturn 0;\n}\nearly_initcall(init_signal_sysctls);\n#endif  \n\nvoid __init signals_init(void)\n{\n\tsiginfo_buildtime_checks();\n\n\tsigqueue_cachep = KMEM_CACHE(sigqueue, SLAB_PANIC | SLAB_ACCOUNT);\n}\n\n#ifdef CONFIG_KGDB_KDB\n#include <linux/kdb.h>\n \nvoid kdb_send_sig(struct task_struct *t, int sig)\n{\n\tstatic struct task_struct *kdb_prev_t;\n\tint new_t, ret;\n\tif (!spin_trylock(&t->sighand->siglock)) {\n\t\tkdb_printf(\"Can't do kill command now.\\n\"\n\t\t\t   \"The sigmask lock is held somewhere else in \"\n\t\t\t   \"kernel, try again later\\n\");\n\t\treturn;\n\t}\n\tnew_t = kdb_prev_t != t;\n\tkdb_prev_t = t;\n\tif (!task_is_running(t) && new_t) {\n\t\tspin_unlock(&t->sighand->siglock);\n\t\tkdb_printf(\"Process is not RUNNING, sending a signal from \"\n\t\t\t   \"kdb risks deadlock\\n\"\n\t\t\t   \"on the run queue locks. \"\n\t\t\t   \"The signal has _not_ been sent.\\n\"\n\t\t\t   \"Reissue the kill command if you want to risk \"\n\t\t\t   \"the deadlock.\\n\");\n\t\treturn;\n\t}\n\tret = send_signal_locked(sig, SEND_SIG_PRIV, t, PIDTYPE_PID);\n\tspin_unlock(&t->sighand->siglock);\n\tif (ret)\n\t\tkdb_printf(\"Fail to deliver Signal %d to process %d.\\n\",\n\t\t\t   sig, t->pid);\n\telse\n\t\tkdb_printf(\"Signal %d is sent to process %d.\\n\", sig, t->pid);\n}\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}