{
  "module_name": "coherent.c",
  "hash_id": "d6ef581bdc2e1f3b56b6a3a4c7f384e112d0fa42eaa4bd1f2d9c9f937fc97ab6",
  "original_prompt": "Ingested from linux-6.6.14/kernel/dma/coherent.c",
  "human_readable_source": "\n \n#include <linux/io.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/dma-direct.h>\n#include <linux/dma-map-ops.h>\n\nstruct dma_coherent_mem {\n\tvoid\t\t*virt_base;\n\tdma_addr_t\tdevice_base;\n\tunsigned long\tpfn_base;\n\tint\t\tsize;\n\tunsigned long\t*bitmap;\n\tspinlock_t\tspinlock;\n\tbool\t\tuse_dev_dma_pfn_offset;\n};\n\nstatic inline struct dma_coherent_mem *dev_get_coherent_memory(struct device *dev)\n{\n\tif (dev && dev->dma_mem)\n\t\treturn dev->dma_mem;\n\treturn NULL;\n}\n\nstatic inline dma_addr_t dma_get_device_base(struct device *dev,\n\t\t\t\t\t     struct dma_coherent_mem * mem)\n{\n\tif (mem->use_dev_dma_pfn_offset)\n\t\treturn phys_to_dma(dev, PFN_PHYS(mem->pfn_base));\n\treturn mem->device_base;\n}\n\nstatic struct dma_coherent_mem *dma_init_coherent_memory(phys_addr_t phys_addr,\n\t\tdma_addr_t device_addr, size_t size, bool use_dma_pfn_offset)\n{\n\tstruct dma_coherent_mem *dma_mem;\n\tint pages = size >> PAGE_SHIFT;\n\tvoid *mem_base;\n\n\tif (!size)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tmem_base = memremap(phys_addr, size, MEMREMAP_WC);\n\tif (!mem_base)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tdma_mem = kzalloc(sizeof(struct dma_coherent_mem), GFP_KERNEL);\n\tif (!dma_mem)\n\t\tgoto out_unmap_membase;\n\tdma_mem->bitmap = bitmap_zalloc(pages, GFP_KERNEL);\n\tif (!dma_mem->bitmap)\n\t\tgoto out_free_dma_mem;\n\n\tdma_mem->virt_base = mem_base;\n\tdma_mem->device_base = device_addr;\n\tdma_mem->pfn_base = PFN_DOWN(phys_addr);\n\tdma_mem->size = pages;\n\tdma_mem->use_dev_dma_pfn_offset = use_dma_pfn_offset;\n\tspin_lock_init(&dma_mem->spinlock);\n\n\treturn dma_mem;\n\nout_free_dma_mem:\n\tkfree(dma_mem);\nout_unmap_membase:\n\tmemunmap(mem_base);\n\tpr_err(\"Reserved memory: failed to init DMA memory pool at %pa, size %zd MiB\\n\",\n\t\t&phys_addr, size / SZ_1M);\n\treturn ERR_PTR(-ENOMEM);\n}\n\nstatic void _dma_release_coherent_memory(struct dma_coherent_mem *mem)\n{\n\tif (!mem)\n\t\treturn;\n\n\tmemunmap(mem->virt_base);\n\tbitmap_free(mem->bitmap);\n\tkfree(mem);\n}\n\nstatic int dma_assign_coherent_memory(struct device *dev,\n\t\t\t\t      struct dma_coherent_mem *mem)\n{\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tif (dev->dma_mem)\n\t\treturn -EBUSY;\n\n\tdev->dma_mem = mem;\n\treturn 0;\n}\n\n \nint dma_declare_coherent_memory(struct device *dev, phys_addr_t phys_addr,\n\t\t\t\tdma_addr_t device_addr, size_t size)\n{\n\tstruct dma_coherent_mem *mem;\n\tint ret;\n\n\tmem = dma_init_coherent_memory(phys_addr, device_addr, size, false);\n\tif (IS_ERR(mem))\n\t\treturn PTR_ERR(mem);\n\n\tret = dma_assign_coherent_memory(dev, mem);\n\tif (ret)\n\t\t_dma_release_coherent_memory(mem);\n\treturn ret;\n}\n\nvoid dma_release_coherent_memory(struct device *dev)\n{\n\tif (dev) {\n\t\t_dma_release_coherent_memory(dev->dma_mem);\n\t\tdev->dma_mem = NULL;\n\t}\n}\n\nstatic void *__dma_alloc_from_coherent(struct device *dev,\n\t\t\t\t       struct dma_coherent_mem *mem,\n\t\t\t\t       ssize_t size, dma_addr_t *dma_handle)\n{\n\tint order = get_order(size);\n\tunsigned long flags;\n\tint pageno;\n\tvoid *ret;\n\n\tspin_lock_irqsave(&mem->spinlock, flags);\n\n\tif (unlikely(size > ((dma_addr_t)mem->size << PAGE_SHIFT)))\n\t\tgoto err;\n\n\tpageno = bitmap_find_free_region(mem->bitmap, mem->size, order);\n\tif (unlikely(pageno < 0))\n\t\tgoto err;\n\n\t \n\t*dma_handle = dma_get_device_base(dev, mem) +\n\t\t\t((dma_addr_t)pageno << PAGE_SHIFT);\n\tret = mem->virt_base + ((dma_addr_t)pageno << PAGE_SHIFT);\n\tspin_unlock_irqrestore(&mem->spinlock, flags);\n\tmemset(ret, 0, size);\n\treturn ret;\nerr:\n\tspin_unlock_irqrestore(&mem->spinlock, flags);\n\treturn NULL;\n}\n\n \nint dma_alloc_from_dev_coherent(struct device *dev, ssize_t size,\n\t\tdma_addr_t *dma_handle, void **ret)\n{\n\tstruct dma_coherent_mem *mem = dev_get_coherent_memory(dev);\n\n\tif (!mem)\n\t\treturn 0;\n\n\t*ret = __dma_alloc_from_coherent(dev, mem, size, dma_handle);\n\treturn 1;\n}\n\nstatic int __dma_release_from_coherent(struct dma_coherent_mem *mem,\n\t\t\t\t       int order, void *vaddr)\n{\n\tif (mem && vaddr >= mem->virt_base && vaddr <\n\t\t   (mem->virt_base + ((dma_addr_t)mem->size << PAGE_SHIFT))) {\n\t\tint page = (vaddr - mem->virt_base) >> PAGE_SHIFT;\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&mem->spinlock, flags);\n\t\tbitmap_release_region(mem->bitmap, page, order);\n\t\tspin_unlock_irqrestore(&mem->spinlock, flags);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nint dma_release_from_dev_coherent(struct device *dev, int order, void *vaddr)\n{\n\tstruct dma_coherent_mem *mem = dev_get_coherent_memory(dev);\n\n\treturn __dma_release_from_coherent(mem, order, vaddr);\n}\n\nstatic int __dma_mmap_from_coherent(struct dma_coherent_mem *mem,\n\t\tstruct vm_area_struct *vma, void *vaddr, size_t size, int *ret)\n{\n\tif (mem && vaddr >= mem->virt_base && vaddr + size <=\n\t\t   (mem->virt_base + ((dma_addr_t)mem->size << PAGE_SHIFT))) {\n\t\tunsigned long off = vma->vm_pgoff;\n\t\tint start = (vaddr - mem->virt_base) >> PAGE_SHIFT;\n\t\tunsigned long user_count = vma_pages(vma);\n\t\tint count = PAGE_ALIGN(size) >> PAGE_SHIFT;\n\n\t\t*ret = -ENXIO;\n\t\tif (off < count && user_count <= count - off) {\n\t\t\tunsigned long pfn = mem->pfn_base + start + off;\n\t\t\t*ret = remap_pfn_range(vma, vma->vm_start, pfn,\n\t\t\t\t\t       user_count << PAGE_SHIFT,\n\t\t\t\t\t       vma->vm_page_prot);\n\t\t}\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nint dma_mmap_from_dev_coherent(struct device *dev, struct vm_area_struct *vma,\n\t\t\t   void *vaddr, size_t size, int *ret)\n{\n\tstruct dma_coherent_mem *mem = dev_get_coherent_memory(dev);\n\n\treturn __dma_mmap_from_coherent(mem, vma, vaddr, size, ret);\n}\n\n#ifdef CONFIG_DMA_GLOBAL_POOL\nstatic struct dma_coherent_mem *dma_coherent_default_memory __ro_after_init;\n\nvoid *dma_alloc_from_global_coherent(struct device *dev, ssize_t size,\n\t\t\t\t     dma_addr_t *dma_handle)\n{\n\tif (!dma_coherent_default_memory)\n\t\treturn NULL;\n\n\treturn __dma_alloc_from_coherent(dev, dma_coherent_default_memory, size,\n\t\t\t\t\t dma_handle);\n}\n\nint dma_release_from_global_coherent(int order, void *vaddr)\n{\n\tif (!dma_coherent_default_memory)\n\t\treturn 0;\n\n\treturn __dma_release_from_coherent(dma_coherent_default_memory, order,\n\t\t\tvaddr);\n}\n\nint dma_mmap_from_global_coherent(struct vm_area_struct *vma, void *vaddr,\n\t\t\t\t   size_t size, int *ret)\n{\n\tif (!dma_coherent_default_memory)\n\t\treturn 0;\n\n\treturn __dma_mmap_from_coherent(dma_coherent_default_memory, vma,\n\t\t\t\t\tvaddr, size, ret);\n}\n\nint dma_init_global_coherent(phys_addr_t phys_addr, size_t size)\n{\n\tstruct dma_coherent_mem *mem;\n\n\tmem = dma_init_coherent_memory(phys_addr, phys_addr, size, true);\n\tif (IS_ERR(mem))\n\t\treturn PTR_ERR(mem);\n\tdma_coherent_default_memory = mem;\n\tpr_info(\"DMA: default coherent area is set\\n\");\n\treturn 0;\n}\n#endif  \n\n \n#ifdef CONFIG_OF_RESERVED_MEM\n#include <linux/of.h>\n#include <linux/of_fdt.h>\n#include <linux/of_reserved_mem.h>\n\n#ifdef CONFIG_DMA_GLOBAL_POOL\nstatic struct reserved_mem *dma_reserved_default_memory __initdata;\n#endif\n\nstatic int rmem_dma_device_init(struct reserved_mem *rmem, struct device *dev)\n{\n\tif (!rmem->priv) {\n\t\tstruct dma_coherent_mem *mem;\n\n\t\tmem = dma_init_coherent_memory(rmem->base, rmem->base,\n\t\t\t\t\t       rmem->size, true);\n\t\tif (IS_ERR(mem))\n\t\t\treturn PTR_ERR(mem);\n\t\trmem->priv = mem;\n\t}\n\tdma_assign_coherent_memory(dev, rmem->priv);\n\treturn 0;\n}\n\nstatic void rmem_dma_device_release(struct reserved_mem *rmem,\n\t\t\t\t    struct device *dev)\n{\n\tif (dev)\n\t\tdev->dma_mem = NULL;\n}\n\nstatic const struct reserved_mem_ops rmem_dma_ops = {\n\t.device_init\t= rmem_dma_device_init,\n\t.device_release\t= rmem_dma_device_release,\n};\n\nstatic int __init rmem_dma_setup(struct reserved_mem *rmem)\n{\n\tunsigned long node = rmem->fdt_node;\n\n\tif (of_get_flat_dt_prop(node, \"reusable\", NULL))\n\t\treturn -EINVAL;\n\n#ifdef CONFIG_ARM\n\tif (!of_get_flat_dt_prop(node, \"no-map\", NULL)) {\n\t\tpr_err(\"Reserved memory: regions without no-map are not yet supported\\n\");\n\t\treturn -EINVAL;\n\t}\n#endif\n\n#ifdef CONFIG_DMA_GLOBAL_POOL\n\tif (of_get_flat_dt_prop(node, \"linux,dma-default\", NULL)) {\n\t\tWARN(dma_reserved_default_memory,\n\t\t     \"Reserved memory: region for default DMA coherent area is redefined\\n\");\n\t\tdma_reserved_default_memory = rmem;\n\t}\n#endif\n\n\trmem->ops = &rmem_dma_ops;\n\tpr_info(\"Reserved memory: created DMA memory pool at %pa, size %ld MiB\\n\",\n\t\t&rmem->base, (unsigned long)rmem->size / SZ_1M);\n\treturn 0;\n}\n\n#ifdef CONFIG_DMA_GLOBAL_POOL\nstatic int __init dma_init_reserved_memory(void)\n{\n\tif (!dma_reserved_default_memory)\n\t\treturn -ENOMEM;\n\treturn dma_init_global_coherent(dma_reserved_default_memory->base,\n\t\t\t\t\tdma_reserved_default_memory->size);\n}\ncore_initcall(dma_init_reserved_memory);\n#endif  \n\nRESERVEDMEM_OF_DECLARE(dma, \"shared-dma-pool\", rmem_dma_setup);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}