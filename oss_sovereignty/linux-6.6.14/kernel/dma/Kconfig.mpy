{
  "module_name": "Kconfig",
  "hash_id": "8db3872b90d99ca8c599eba3d5361cb62085e1e19b08b2e310df98bed94cf9f7",
  "original_prompt": "Ingested from linux-6.6.14/kernel/dma/Kconfig",
  "human_readable_source": "# SPDX-License-Identifier: GPL-2.0-only\n\nconfig NO_DMA\n\tbool\n\nconfig HAS_DMA\n\tbool\n\tdepends on !NO_DMA\n\tdefault y\n\nconfig DMA_OPS\n\tdepends on HAS_DMA\n\tbool\n\n#\n# IOMMU drivers that can bypass the IOMMU code and optionally use the direct\n# mapping fast path should select this option and set the dma_ops_bypass\n# flag in struct device where applicable\n#\nconfig DMA_OPS_BYPASS\n\tbool\n\n# Lets platform IOMMU driver choose between bypass and IOMMU\nconfig ARCH_HAS_DMA_MAP_DIRECT\n\tbool\n\nconfig NEED_SG_DMA_FLAGS\n\tbool\n\nconfig NEED_SG_DMA_LENGTH\n\tbool\n\nconfig NEED_DMA_MAP_STATE\n\tbool\n\nconfig ARCH_DMA_ADDR_T_64BIT\n\tdef_bool 64BIT || PHYS_ADDR_T_64BIT\n\nconfig ARCH_HAS_DMA_SET_MASK\n\tbool\n\n#\n# Select this option if the architecture needs special handling for\n# DMA_ATTR_WRITE_COMBINE.  Normally the \"uncached\" mapping should be what\n# people think of when saying write combine, so very few platforms should\n# need to enable this.\n#\nconfig ARCH_HAS_DMA_WRITE_COMBINE\n\tbool\n\n#\n# Select if the architectures provides the arch_dma_mark_clean hook\n#\nconfig ARCH_HAS_DMA_MARK_CLEAN\n\tbool\n\nconfig DMA_DECLARE_COHERENT\n\tbool\n\nconfig ARCH_HAS_SETUP_DMA_OPS\n\tbool\n\nconfig ARCH_HAS_TEARDOWN_DMA_OPS\n\tbool\n\nconfig ARCH_HAS_SYNC_DMA_FOR_DEVICE\n\tbool\n\nconfig ARCH_HAS_SYNC_DMA_FOR_CPU\n\tbool\n\tselect NEED_DMA_MAP_STATE\n\nconfig ARCH_HAS_SYNC_DMA_FOR_CPU_ALL\n\tbool\n\nconfig ARCH_HAS_DMA_PREP_COHERENT\n\tbool\n\nconfig ARCH_HAS_FORCE_DMA_UNENCRYPTED\n\tbool\n\n#\n# Select this option if the architecture assumes DMA devices are coherent\n# by default.\n#\nconfig ARCH_DMA_DEFAULT_COHERENT\n\tbool\n\nconfig SWIOTLB\n\tbool\n\tselect NEED_DMA_MAP_STATE\n\nconfig SWIOTLB_DYNAMIC\n\tbool \"Dynamic allocation of DMA bounce buffers\"\n\tdefault n\n\tdepends on SWIOTLB\n\thelp\n\t  This enables dynamic resizing of the software IO TLB. The kernel\n\t  starts with one memory pool at boot and it will allocate additional\n\t  pools as needed. To reduce run-time kernel memory requirements, you\n\t  may have to specify a smaller size of the initial pool using\n\t  \"swiotlb=\" on the kernel command line.\n\n\t  If unsure, say N.\n\nconfig DMA_BOUNCE_UNALIGNED_KMALLOC\n\tbool\n\tdepends on SWIOTLB\n\nconfig DMA_RESTRICTED_POOL\n\tbool \"DMA Restricted Pool\"\n\tdepends on OF && OF_RESERVED_MEM && SWIOTLB\n\thelp\n\t  This enables support for restricted DMA pools which provide a level of\n\t  DMA memory protection on systems with limited hardware protection\n\t  capabilities, such as those lacking an IOMMU.\n\n\t  For more information see\n\t  <Documentation/devicetree/bindings/reserved-memory/reserved-memory.txt>\n\t  and <kernel/dma/swiotlb.c>.\n\t  If unsure, say \"n\".\n\n#\n# Should be selected if we can mmap non-coherent mappings to userspace.\n# The only thing that is really required is a way to set an uncached bit\n# in the pagetables\n#\nconfig DMA_NONCOHERENT_MMAP\n\tdefault y if !MMU\n\tbool\n\nconfig DMA_COHERENT_POOL\n\tselect GENERIC_ALLOCATOR\n\tbool\n\nconfig DMA_GLOBAL_POOL\n\tselect DMA_DECLARE_COHERENT\n\tbool\n\nconfig DMA_DIRECT_REMAP\n\tbool\n\tselect DMA_COHERENT_POOL\n\tselect DMA_NONCOHERENT_MMAP\n\nconfig DMA_CMA\n\tbool \"DMA Contiguous Memory Allocator\"\n\tdepends on HAVE_DMA_CONTIGUOUS && CMA\n\thelp\n\t  This enables the Contiguous Memory Allocator which allows drivers\n\t  to allocate big physically-contiguous blocks of memory for use with\n\t  hardware components that do not support I/O map nor scatter-gather.\n\n\t  You can disable CMA by specifying \"cma=0\" on the kernel's command\n\t  line.\n\n\t  For more information see <kernel/dma/contiguous.c>.\n\t  If unsure, say \"n\".\n\nif  DMA_CMA\n\nconfig DMA_NUMA_CMA\n\tbool \"Enable separate DMA Contiguous Memory Area for NUMA Node\"\n\tdepends on NUMA\n\thelp\n\t  Enable this option to get numa CMA areas so that NUMA devices\n\t  can get local memory by DMA coherent APIs.\n\n\t  You can set the size of pernuma CMA by specifying \"cma_pernuma=size\"\n\t  or set the node id and its size of CMA by specifying \"numa_cma=\n\t  <node>:size[,<node>:size]\" on the kernel's command line.\n\ncomment \"Default contiguous memory area size:\"\n\nconfig CMA_SIZE_MBYTES\n\tint \"Size in Mega Bytes\"\n\tdepends on !CMA_SIZE_SEL_PERCENTAGE\n\tdefault 0 if X86\n\tdefault 16\n\thelp\n\t  Defines the size (in MiB) of the default memory area for Contiguous\n\t  Memory Allocator.  If the size of 0 is selected, CMA is disabled by\n\t  default, but it can be enabled by passing cma=size[MG] to the kernel.\n\n\nconfig CMA_SIZE_PERCENTAGE\n\tint \"Percentage of total memory\"\n\tdepends on !CMA_SIZE_SEL_MBYTES\n\tdefault 0 if X86\n\tdefault 10\n\thelp\n\t  Defines the size of the default memory area for Contiguous Memory\n\t  Allocator as a percentage of the total memory in the system.\n\t  If 0 percent is selected, CMA is disabled by default, but it can be\n\t  enabled by passing cma=size[MG] to the kernel.\n\nchoice\n\tprompt \"Selected region size\"\n\tdefault CMA_SIZE_SEL_MBYTES\n\nconfig CMA_SIZE_SEL_MBYTES\n\tbool \"Use mega bytes value only\"\n\nconfig CMA_SIZE_SEL_PERCENTAGE\n\tbool \"Use percentage value only\"\n\nconfig CMA_SIZE_SEL_MIN\n\tbool \"Use lower value (minimum)\"\n\nconfig CMA_SIZE_SEL_MAX\n\tbool \"Use higher value (maximum)\"\n\nendchoice\n\nconfig CMA_ALIGNMENT\n\tint \"Maximum PAGE_SIZE order of alignment for contiguous buffers\"\n\trange 2 12\n\tdefault 8\n\thelp\n\t  DMA mapping framework by default aligns all buffers to the smallest\n\t  PAGE_SIZE order which is greater than or equal to the requested buffer\n\t  size. This works well for buffers up to a few hundreds kilobytes, but\n\t  for larger buffers it just a memory waste. With this parameter you can\n\t  specify the maximum PAGE_SIZE order for contiguous buffers. Larger\n\t  buffers will be aligned only to this specified order. The order is\n\t  expressed as a power of two multiplied by the PAGE_SIZE.\n\n\t  For example, if your system defaults to 4KiB pages, the order value\n\t  of 8 means that the buffers will be aligned up to 1MiB only.\n\n\t  If unsure, leave the default value \"8\".\n\nendif\n\nconfig DMA_API_DEBUG\n\tbool \"Enable debugging of DMA-API usage\"\n\tselect NEED_DMA_MAP_STATE\n\thelp\n\t  Enable this option to debug the use of the DMA API by device drivers.\n\t  With this option you will be able to detect common bugs in device\n\t  drivers like double-freeing of DMA mappings or freeing mappings that\n\t  were never allocated.\n\n\t  This option causes a performance degradation.  Use only if you want to\n\t  debug device drivers and dma interactions.\n\n\t  If unsure, say N.\n\nconfig DMA_API_DEBUG_SG\n\tbool \"Debug DMA scatter-gather usage\"\n\tdefault y\n\tdepends on DMA_API_DEBUG\n\thelp\n\t  Perform extra checking that callers of dma_map_sg() have respected the\n\t  appropriate segment length/boundary limits for the given device when\n\t  preparing DMA scatterlists.\n\n\t  This is particularly likely to have been overlooked in cases where the\n\t  dma_map_sg() API is used for general bulk mapping of pages rather than\n\t  preparing literal scatter-gather descriptors, where there is a risk of\n\t  unexpected behaviour from DMA API implementations if the scatterlist\n\t  is technically out-of-spec.\n\n\t  If unsure, say N.\n\nconfig DMA_MAP_BENCHMARK\n\tbool \"Enable benchmarking of streaming DMA mapping\"\n\tdepends on DEBUG_FS\n\thelp\n\t  Provides /sys/kernel/debug/dma_map_benchmark that helps with testing\n\t  performance of dma_(un)map_page.\n\n\t  See tools/testing/selftests/dma/dma_map_benchmark.c\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}