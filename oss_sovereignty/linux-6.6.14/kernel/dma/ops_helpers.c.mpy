{
  "module_name": "ops_helpers.c",
  "hash_id": "548bcf10335382b0a590dd60fc74c75e8ad252a5ac8470158edf037319abbf9c",
  "original_prompt": "Ingested from linux-6.6.14/kernel/dma/ops_helpers.c",
  "human_readable_source": "\n \n#include <linux/dma-map-ops.h>\n\nstatic struct page *dma_common_vaddr_to_page(void *cpu_addr)\n{\n\tif (is_vmalloc_addr(cpu_addr))\n\t\treturn vmalloc_to_page(cpu_addr);\n\treturn virt_to_page(cpu_addr);\n}\n\n \nint dma_common_get_sgtable(struct device *dev, struct sg_table *sgt,\n\t\t void *cpu_addr, dma_addr_t dma_addr, size_t size,\n\t\t unsigned long attrs)\n{\n\tstruct page *page = dma_common_vaddr_to_page(cpu_addr);\n\tint ret;\n\n\tret = sg_alloc_table(sgt, 1, GFP_KERNEL);\n\tif (!ret)\n\t\tsg_set_page(sgt->sgl, page, PAGE_ALIGN(size), 0);\n\treturn ret;\n}\n\n \nint dma_common_mmap(struct device *dev, struct vm_area_struct *vma,\n\t\tvoid *cpu_addr, dma_addr_t dma_addr, size_t size,\n\t\tunsigned long attrs)\n{\n#ifdef CONFIG_MMU\n\tunsigned long user_count = vma_pages(vma);\n\tunsigned long count = PAGE_ALIGN(size) >> PAGE_SHIFT;\n\tunsigned long off = vma->vm_pgoff;\n\tstruct page *page = dma_common_vaddr_to_page(cpu_addr);\n\tint ret = -ENXIO;\n\n\tvma->vm_page_prot = dma_pgprot(dev, vma->vm_page_prot, attrs);\n\n\tif (dma_mmap_from_dev_coherent(dev, vma, cpu_addr, size, &ret))\n\t\treturn ret;\n\n\tif (off >= count || user_count > count - off)\n\t\treturn -ENXIO;\n\n\treturn remap_pfn_range(vma, vma->vm_start,\n\t\t\tpage_to_pfn(page) + vma->vm_pgoff,\n\t\t\tuser_count << PAGE_SHIFT, vma->vm_page_prot);\n#else\n\treturn -ENXIO;\n#endif  \n}\n\nstruct page *dma_common_alloc_pages(struct device *dev, size_t size,\n\t\tdma_addr_t *dma_handle, enum dma_data_direction dir, gfp_t gfp)\n{\n\tconst struct dma_map_ops *ops = get_dma_ops(dev);\n\tstruct page *page;\n\n\tpage = dma_alloc_contiguous(dev, size, gfp);\n\tif (!page)\n\t\tpage = alloc_pages_node(dev_to_node(dev), gfp, get_order(size));\n\tif (!page)\n\t\treturn NULL;\n\n\t*dma_handle = ops->map_page(dev, page, 0, size, dir,\n\t\t\t\t    DMA_ATTR_SKIP_CPU_SYNC);\n\tif (*dma_handle == DMA_MAPPING_ERROR) {\n\t\tdma_free_contiguous(dev, page, size);\n\t\treturn NULL;\n\t}\n\n\tmemset(page_address(page), 0, size);\n\treturn page;\n}\n\nvoid dma_common_free_pages(struct device *dev, size_t size, struct page *page,\n\t\tdma_addr_t dma_handle, enum dma_data_direction dir)\n{\n\tconst struct dma_map_ops *ops = get_dma_ops(dev);\n\n\tif (ops->unmap_page)\n\t\tops->unmap_page(dev, dma_handle, size, dir,\n\t\t\t\tDMA_ATTR_SKIP_CPU_SYNC);\n\tdma_free_contiguous(dev, page, size);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}