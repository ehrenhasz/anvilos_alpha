{
  "module_name": "audit_tree.c",
  "hash_id": "6da0f5fb59ea7a6679295ffd6cd1e5e3b2e2e64103987d06a18a37e8a7bde55d",
  "original_prompt": "Ingested from linux-6.6.14/kernel/audit_tree.c",
  "human_readable_source": "\n#include \"audit.h\"\n#include <linux/fsnotify_backend.h>\n#include <linux/namei.h>\n#include <linux/mount.h>\n#include <linux/kthread.h>\n#include <linux/refcount.h>\n#include <linux/slab.h>\n\nstruct audit_tree;\nstruct audit_chunk;\n\nstruct audit_tree {\n\trefcount_t count;\n\tint goner;\n\tstruct audit_chunk *root;\n\tstruct list_head chunks;\n\tstruct list_head rules;\n\tstruct list_head list;\n\tstruct list_head same_root;\n\tstruct rcu_head head;\n\tchar pathname[];\n};\n\nstruct audit_chunk {\n\tstruct list_head hash;\n\tunsigned long key;\n\tstruct fsnotify_mark *mark;\n\tstruct list_head trees;\t\t \n\tint count;\n\tatomic_long_t refs;\n\tstruct rcu_head head;\n\tstruct audit_node {\n\t\tstruct list_head list;\n\t\tstruct audit_tree *owner;\n\t\tunsigned index;\t\t \n\t} owners[];\n};\n\nstruct audit_tree_mark {\n\tstruct fsnotify_mark mark;\n\tstruct audit_chunk *chunk;\n};\n\nstatic LIST_HEAD(tree_list);\nstatic LIST_HEAD(prune_list);\nstatic struct task_struct *prune_thread;\n\n \n\nstatic struct fsnotify_group *audit_tree_group;\nstatic struct kmem_cache *audit_tree_mark_cachep __read_mostly;\n\nstatic struct audit_tree *alloc_tree(const char *s)\n{\n\tstruct audit_tree *tree;\n\n\ttree = kmalloc(struct_size(tree, pathname, strlen(s) + 1), GFP_KERNEL);\n\tif (tree) {\n\t\trefcount_set(&tree->count, 1);\n\t\ttree->goner = 0;\n\t\tINIT_LIST_HEAD(&tree->chunks);\n\t\tINIT_LIST_HEAD(&tree->rules);\n\t\tINIT_LIST_HEAD(&tree->list);\n\t\tINIT_LIST_HEAD(&tree->same_root);\n\t\ttree->root = NULL;\n\t\tstrcpy(tree->pathname, s);\n\t}\n\treturn tree;\n}\n\nstatic inline void get_tree(struct audit_tree *tree)\n{\n\trefcount_inc(&tree->count);\n}\n\nstatic inline void put_tree(struct audit_tree *tree)\n{\n\tif (refcount_dec_and_test(&tree->count))\n\t\tkfree_rcu(tree, head);\n}\n\n \nconst char *audit_tree_path(struct audit_tree *tree)\n{\n\treturn tree->pathname;\n}\n\nstatic void free_chunk(struct audit_chunk *chunk)\n{\n\tint i;\n\n\tfor (i = 0; i < chunk->count; i++) {\n\t\tif (chunk->owners[i].owner)\n\t\t\tput_tree(chunk->owners[i].owner);\n\t}\n\tkfree(chunk);\n}\n\nvoid audit_put_chunk(struct audit_chunk *chunk)\n{\n\tif (atomic_long_dec_and_test(&chunk->refs))\n\t\tfree_chunk(chunk);\n}\n\nstatic void __put_chunk(struct rcu_head *rcu)\n{\n\tstruct audit_chunk *chunk = container_of(rcu, struct audit_chunk, head);\n\taudit_put_chunk(chunk);\n}\n\n \nstatic void audit_mark_put_chunk(struct audit_chunk *chunk)\n{\n\tcall_rcu(&chunk->head, __put_chunk);\n}\n\nstatic inline struct audit_tree_mark *audit_mark(struct fsnotify_mark *mark)\n{\n\treturn container_of(mark, struct audit_tree_mark, mark);\n}\n\nstatic struct audit_chunk *mark_chunk(struct fsnotify_mark *mark)\n{\n\treturn audit_mark(mark)->chunk;\n}\n\nstatic void audit_tree_destroy_watch(struct fsnotify_mark *mark)\n{\n\tkmem_cache_free(audit_tree_mark_cachep, audit_mark(mark));\n}\n\nstatic struct fsnotify_mark *alloc_mark(void)\n{\n\tstruct audit_tree_mark *amark;\n\n\tamark = kmem_cache_zalloc(audit_tree_mark_cachep, GFP_KERNEL);\n\tif (!amark)\n\t\treturn NULL;\n\tfsnotify_init_mark(&amark->mark, audit_tree_group);\n\tamark->mark.mask = FS_IN_IGNORED;\n\treturn &amark->mark;\n}\n\nstatic struct audit_chunk *alloc_chunk(int count)\n{\n\tstruct audit_chunk *chunk;\n\tint i;\n\n\tchunk = kzalloc(struct_size(chunk, owners, count), GFP_KERNEL);\n\tif (!chunk)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&chunk->hash);\n\tINIT_LIST_HEAD(&chunk->trees);\n\tchunk->count = count;\n\tatomic_long_set(&chunk->refs, 1);\n\tfor (i = 0; i < count; i++) {\n\t\tINIT_LIST_HEAD(&chunk->owners[i].list);\n\t\tchunk->owners[i].index = i;\n\t}\n\treturn chunk;\n}\n\nenum {HASH_SIZE = 128};\nstatic struct list_head chunk_hash_heads[HASH_SIZE];\nstatic __cacheline_aligned_in_smp DEFINE_SPINLOCK(hash_lock);\n\n \nstatic unsigned long inode_to_key(const struct inode *inode)\n{\n\t \n\treturn (unsigned long)&inode->i_fsnotify_marks;\n}\n\nstatic inline struct list_head *chunk_hash(unsigned long key)\n{\n\tunsigned long n = key / L1_CACHE_BYTES;\n\treturn chunk_hash_heads + n % HASH_SIZE;\n}\n\n \nstatic void insert_hash(struct audit_chunk *chunk)\n{\n\tstruct list_head *list;\n\n\t \n\tsmp_wmb();\n\tWARN_ON_ONCE(!chunk->key);\n\tlist = chunk_hash(chunk->key);\n\tlist_add_rcu(&chunk->hash, list);\n}\n\n \nstruct audit_chunk *audit_tree_lookup(const struct inode *inode)\n{\n\tunsigned long key = inode_to_key(inode);\n\tstruct list_head *list = chunk_hash(key);\n\tstruct audit_chunk *p;\n\n\tlist_for_each_entry_rcu(p, list, hash) {\n\t\t \n\t\tif (READ_ONCE(p->key) == key) {\n\t\t\tatomic_long_inc(&p->refs);\n\t\t\treturn p;\n\t\t}\n\t}\n\treturn NULL;\n}\n\nbool audit_tree_match(struct audit_chunk *chunk, struct audit_tree *tree)\n{\n\tint n;\n\tfor (n = 0; n < chunk->count; n++)\n\t\tif (chunk->owners[n].owner == tree)\n\t\t\treturn true;\n\treturn false;\n}\n\n \n\nstatic struct audit_chunk *find_chunk(struct audit_node *p)\n{\n\tint index = p->index & ~(1U<<31);\n\tp -= index;\n\treturn container_of(p, struct audit_chunk, owners[0]);\n}\n\nstatic void replace_mark_chunk(struct fsnotify_mark *mark,\n\t\t\t       struct audit_chunk *chunk)\n{\n\tstruct audit_chunk *old;\n\n\tassert_spin_locked(&hash_lock);\n\told = mark_chunk(mark);\n\taudit_mark(mark)->chunk = chunk;\n\tif (chunk)\n\t\tchunk->mark = mark;\n\tif (old)\n\t\told->mark = NULL;\n}\n\nstatic void replace_chunk(struct audit_chunk *new, struct audit_chunk *old)\n{\n\tstruct audit_tree *owner;\n\tint i, j;\n\n\tnew->key = old->key;\n\tlist_splice_init(&old->trees, &new->trees);\n\tlist_for_each_entry(owner, &new->trees, same_root)\n\t\towner->root = new;\n\tfor (i = j = 0; j < old->count; i++, j++) {\n\t\tif (!old->owners[j].owner) {\n\t\t\ti--;\n\t\t\tcontinue;\n\t\t}\n\t\towner = old->owners[j].owner;\n\t\tnew->owners[i].owner = owner;\n\t\tnew->owners[i].index = old->owners[j].index - j + i;\n\t\tif (!owner)  \n\t\t\tcontinue;\n\t\tget_tree(owner);\n\t\tlist_replace_init(&old->owners[j].list, &new->owners[i].list);\n\t}\n\treplace_mark_chunk(old->mark, new);\n\t \n\tsmp_wmb();\n\tlist_replace_rcu(&old->hash, &new->hash);\n}\n\nstatic void remove_chunk_node(struct audit_chunk *chunk, struct audit_node *p)\n{\n\tstruct audit_tree *owner = p->owner;\n\n\tif (owner->root == chunk) {\n\t\tlist_del_init(&owner->same_root);\n\t\towner->root = NULL;\n\t}\n\tlist_del_init(&p->list);\n\tp->owner = NULL;\n\tput_tree(owner);\n}\n\nstatic int chunk_count_trees(struct audit_chunk *chunk)\n{\n\tint i;\n\tint ret = 0;\n\n\tfor (i = 0; i < chunk->count; i++)\n\t\tif (chunk->owners[i].owner)\n\t\t\tret++;\n\treturn ret;\n}\n\nstatic void untag_chunk(struct audit_chunk *chunk, struct fsnotify_mark *mark)\n{\n\tstruct audit_chunk *new;\n\tint size;\n\n\tfsnotify_group_lock(audit_tree_group);\n\t \n\tif (!(mark->flags & FSNOTIFY_MARK_FLAG_ATTACHED) ||\n\t    mark_chunk(mark) != chunk)\n\t\tgoto out_mutex;\n\n\tsize = chunk_count_trees(chunk);\n\tif (!size) {\n\t\tspin_lock(&hash_lock);\n\t\tlist_del_init(&chunk->trees);\n\t\tlist_del_rcu(&chunk->hash);\n\t\treplace_mark_chunk(mark, NULL);\n\t\tspin_unlock(&hash_lock);\n\t\tfsnotify_detach_mark(mark);\n\t\tfsnotify_group_unlock(audit_tree_group);\n\t\taudit_mark_put_chunk(chunk);\n\t\tfsnotify_free_mark(mark);\n\t\treturn;\n\t}\n\n\tnew = alloc_chunk(size);\n\tif (!new)\n\t\tgoto out_mutex;\n\n\tspin_lock(&hash_lock);\n\t \n\treplace_chunk(new, chunk);\n\tspin_unlock(&hash_lock);\n\tfsnotify_group_unlock(audit_tree_group);\n\taudit_mark_put_chunk(chunk);\n\treturn;\n\nout_mutex:\n\tfsnotify_group_unlock(audit_tree_group);\n}\n\n \nstatic int create_chunk(struct inode *inode, struct audit_tree *tree)\n{\n\tstruct fsnotify_mark *mark;\n\tstruct audit_chunk *chunk = alloc_chunk(1);\n\n\tif (!chunk) {\n\t\tfsnotify_group_unlock(audit_tree_group);\n\t\treturn -ENOMEM;\n\t}\n\n\tmark = alloc_mark();\n\tif (!mark) {\n\t\tfsnotify_group_unlock(audit_tree_group);\n\t\tkfree(chunk);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (fsnotify_add_inode_mark_locked(mark, inode, 0)) {\n\t\tfsnotify_group_unlock(audit_tree_group);\n\t\tfsnotify_put_mark(mark);\n\t\tkfree(chunk);\n\t\treturn -ENOSPC;\n\t}\n\n\tspin_lock(&hash_lock);\n\tif (tree->goner) {\n\t\tspin_unlock(&hash_lock);\n\t\tfsnotify_detach_mark(mark);\n\t\tfsnotify_group_unlock(audit_tree_group);\n\t\tfsnotify_free_mark(mark);\n\t\tfsnotify_put_mark(mark);\n\t\tkfree(chunk);\n\t\treturn 0;\n\t}\n\treplace_mark_chunk(mark, chunk);\n\tchunk->owners[0].index = (1U << 31);\n\tchunk->owners[0].owner = tree;\n\tget_tree(tree);\n\tlist_add(&chunk->owners[0].list, &tree->chunks);\n\tif (!tree->root) {\n\t\ttree->root = chunk;\n\t\tlist_add(&tree->same_root, &chunk->trees);\n\t}\n\tchunk->key = inode_to_key(inode);\n\t \n\tinsert_hash(chunk);\n\tspin_unlock(&hash_lock);\n\tfsnotify_group_unlock(audit_tree_group);\n\t \n\tfsnotify_put_mark(mark);\n\treturn 0;\n}\n\n \nstatic int tag_chunk(struct inode *inode, struct audit_tree *tree)\n{\n\tstruct fsnotify_mark *mark;\n\tstruct audit_chunk *chunk, *old;\n\tstruct audit_node *p;\n\tint n;\n\n\tfsnotify_group_lock(audit_tree_group);\n\tmark = fsnotify_find_mark(&inode->i_fsnotify_marks, audit_tree_group);\n\tif (!mark)\n\t\treturn create_chunk(inode, tree);\n\n\t \n\t \n\tspin_lock(&hash_lock);\n\told = mark_chunk(mark);\n\tfor (n = 0; n < old->count; n++) {\n\t\tif (old->owners[n].owner == tree) {\n\t\t\tspin_unlock(&hash_lock);\n\t\t\tfsnotify_group_unlock(audit_tree_group);\n\t\t\tfsnotify_put_mark(mark);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tspin_unlock(&hash_lock);\n\n\tchunk = alloc_chunk(old->count + 1);\n\tif (!chunk) {\n\t\tfsnotify_group_unlock(audit_tree_group);\n\t\tfsnotify_put_mark(mark);\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock(&hash_lock);\n\tif (tree->goner) {\n\t\tspin_unlock(&hash_lock);\n\t\tfsnotify_group_unlock(audit_tree_group);\n\t\tfsnotify_put_mark(mark);\n\t\tkfree(chunk);\n\t\treturn 0;\n\t}\n\tp = &chunk->owners[chunk->count - 1];\n\tp->index = (chunk->count - 1) | (1U<<31);\n\tp->owner = tree;\n\tget_tree(tree);\n\tlist_add(&p->list, &tree->chunks);\n\tif (!tree->root) {\n\t\ttree->root = chunk;\n\t\tlist_add(&tree->same_root, &chunk->trees);\n\t}\n\t \n\treplace_chunk(chunk, old);\n\tspin_unlock(&hash_lock);\n\tfsnotify_group_unlock(audit_tree_group);\n\tfsnotify_put_mark(mark);  \n\taudit_mark_put_chunk(old);\n\n\treturn 0;\n}\n\nstatic void audit_tree_log_remove_rule(struct audit_context *context,\n\t\t\t\t       struct audit_krule *rule)\n{\n\tstruct audit_buffer *ab;\n\n\tif (!audit_enabled)\n\t\treturn;\n\tab = audit_log_start(context, GFP_KERNEL, AUDIT_CONFIG_CHANGE);\n\tif (unlikely(!ab))\n\t\treturn;\n\taudit_log_format(ab, \"op=remove_rule dir=\");\n\taudit_log_untrustedstring(ab, rule->tree->pathname);\n\taudit_log_key(ab, rule->filterkey);\n\taudit_log_format(ab, \" list=%d res=1\", rule->listnr);\n\taudit_log_end(ab);\n}\n\nstatic void kill_rules(struct audit_context *context, struct audit_tree *tree)\n{\n\tstruct audit_krule *rule, *next;\n\tstruct audit_entry *entry;\n\n\tlist_for_each_entry_safe(rule, next, &tree->rules, rlist) {\n\t\tentry = container_of(rule, struct audit_entry, rule);\n\n\t\tlist_del_init(&rule->rlist);\n\t\tif (rule->tree) {\n\t\t\t \n\t\t\taudit_tree_log_remove_rule(context, rule);\n\t\t\tif (entry->rule.exe)\n\t\t\t\taudit_remove_mark(entry->rule.exe);\n\t\t\trule->tree = NULL;\n\t\t\tlist_del_rcu(&entry->list);\n\t\t\tlist_del(&entry->rule.list);\n\t\t\tcall_rcu(&entry->rcu, audit_free_rule_rcu);\n\t\t}\n\t}\n}\n\n \nstatic void prune_tree_chunks(struct audit_tree *victim, bool tagged)\n{\n\tspin_lock(&hash_lock);\n\twhile (!list_empty(&victim->chunks)) {\n\t\tstruct audit_node *p;\n\t\tstruct audit_chunk *chunk;\n\t\tstruct fsnotify_mark *mark;\n\n\t\tp = list_first_entry(&victim->chunks, struct audit_node, list);\n\t\t \n\t\tif (tagged && !(p->index & (1U<<31)))\n\t\t\tbreak;\n\t\tchunk = find_chunk(p);\n\t\tmark = chunk->mark;\n\t\tremove_chunk_node(chunk, p);\n\t\t \n\t\tif (!mark)\n\t\t\tcontinue;\n\t\tfsnotify_get_mark(mark);\n\t\tspin_unlock(&hash_lock);\n\n\t\tuntag_chunk(chunk, mark);\n\t\tfsnotify_put_mark(mark);\n\n\t\tspin_lock(&hash_lock);\n\t}\n\tspin_unlock(&hash_lock);\n}\n\n \nstatic void prune_one(struct audit_tree *victim)\n{\n\tprune_tree_chunks(victim, false);\n\tput_tree(victim);\n}\n\n \n\nstatic void trim_marked(struct audit_tree *tree)\n{\n\tstruct list_head *p, *q;\n\tspin_lock(&hash_lock);\n\tif (tree->goner) {\n\t\tspin_unlock(&hash_lock);\n\t\treturn;\n\t}\n\t \n\tfor (p = tree->chunks.next; p != &tree->chunks; p = q) {\n\t\tstruct audit_node *node = list_entry(p, struct audit_node, list);\n\t\tq = p->next;\n\t\tif (node->index & (1U<<31)) {\n\t\t\tlist_del_init(p);\n\t\t\tlist_add(p, &tree->chunks);\n\t\t}\n\t}\n\tspin_unlock(&hash_lock);\n\n\tprune_tree_chunks(tree, true);\n\n\tspin_lock(&hash_lock);\n\tif (!tree->root && !tree->goner) {\n\t\ttree->goner = 1;\n\t\tspin_unlock(&hash_lock);\n\t\tmutex_lock(&audit_filter_mutex);\n\t\tkill_rules(audit_context(), tree);\n\t\tlist_del_init(&tree->list);\n\t\tmutex_unlock(&audit_filter_mutex);\n\t\tprune_one(tree);\n\t} else {\n\t\tspin_unlock(&hash_lock);\n\t}\n}\n\nstatic void audit_schedule_prune(void);\n\n \nint audit_remove_tree_rule(struct audit_krule *rule)\n{\n\tstruct audit_tree *tree;\n\ttree = rule->tree;\n\tif (tree) {\n\t\tspin_lock(&hash_lock);\n\t\tlist_del_init(&rule->rlist);\n\t\tif (list_empty(&tree->rules) && !tree->goner) {\n\t\t\ttree->root = NULL;\n\t\t\tlist_del_init(&tree->same_root);\n\t\t\ttree->goner = 1;\n\t\t\tlist_move(&tree->list, &prune_list);\n\t\t\trule->tree = NULL;\n\t\t\tspin_unlock(&hash_lock);\n\t\t\taudit_schedule_prune();\n\t\t\treturn 1;\n\t\t}\n\t\trule->tree = NULL;\n\t\tspin_unlock(&hash_lock);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic int compare_root(struct vfsmount *mnt, void *arg)\n{\n\treturn inode_to_key(d_backing_inode(mnt->mnt_root)) ==\n\t       (unsigned long)arg;\n}\n\nvoid audit_trim_trees(void)\n{\n\tstruct list_head cursor;\n\n\tmutex_lock(&audit_filter_mutex);\n\tlist_add(&cursor, &tree_list);\n\twhile (cursor.next != &tree_list) {\n\t\tstruct audit_tree *tree;\n\t\tstruct path path;\n\t\tstruct vfsmount *root_mnt;\n\t\tstruct audit_node *node;\n\t\tint err;\n\n\t\ttree = container_of(cursor.next, struct audit_tree, list);\n\t\tget_tree(tree);\n\t\tlist_move(&cursor, &tree->list);\n\t\tmutex_unlock(&audit_filter_mutex);\n\n\t\terr = kern_path(tree->pathname, 0, &path);\n\t\tif (err)\n\t\t\tgoto skip_it;\n\n\t\troot_mnt = collect_mounts(&path);\n\t\tpath_put(&path);\n\t\tif (IS_ERR(root_mnt))\n\t\t\tgoto skip_it;\n\n\t\tspin_lock(&hash_lock);\n\t\tlist_for_each_entry(node, &tree->chunks, list) {\n\t\t\tstruct audit_chunk *chunk = find_chunk(node);\n\t\t\t \n\t\t\tnode->index |= 1U<<31;\n\t\t\tif (iterate_mounts(compare_root,\n\t\t\t\t\t   (void *)(chunk->key),\n\t\t\t\t\t   root_mnt))\n\t\t\t\tnode->index &= ~(1U<<31);\n\t\t}\n\t\tspin_unlock(&hash_lock);\n\t\ttrim_marked(tree);\n\t\tdrop_collected_mounts(root_mnt);\nskip_it:\n\t\tput_tree(tree);\n\t\tmutex_lock(&audit_filter_mutex);\n\t}\n\tlist_del(&cursor);\n\tmutex_unlock(&audit_filter_mutex);\n}\n\nint audit_make_tree(struct audit_krule *rule, char *pathname, u32 op)\n{\n\n\tif (pathname[0] != '/' ||\n\t    (rule->listnr != AUDIT_FILTER_EXIT &&\n\t     rule->listnr != AUDIT_FILTER_URING_EXIT) ||\n\t    op != Audit_equal ||\n\t    rule->inode_f || rule->watch || rule->tree)\n\t\treturn -EINVAL;\n\trule->tree = alloc_tree(pathname);\n\tif (!rule->tree)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid audit_put_tree(struct audit_tree *tree)\n{\n\tput_tree(tree);\n}\n\nstatic int tag_mount(struct vfsmount *mnt, void *arg)\n{\n\treturn tag_chunk(d_backing_inode(mnt->mnt_root), arg);\n}\n\n \nstatic int prune_tree_thread(void *unused)\n{\n\tfor (;;) {\n\t\tif (list_empty(&prune_list)) {\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\tschedule();\n\t\t}\n\n\t\taudit_ctl_lock();\n\t\tmutex_lock(&audit_filter_mutex);\n\n\t\twhile (!list_empty(&prune_list)) {\n\t\t\tstruct audit_tree *victim;\n\n\t\t\tvictim = list_entry(prune_list.next,\n\t\t\t\t\tstruct audit_tree, list);\n\t\t\tlist_del_init(&victim->list);\n\n\t\t\tmutex_unlock(&audit_filter_mutex);\n\n\t\t\tprune_one(victim);\n\n\t\t\tmutex_lock(&audit_filter_mutex);\n\t\t}\n\n\t\tmutex_unlock(&audit_filter_mutex);\n\t\taudit_ctl_unlock();\n\t}\n\treturn 0;\n}\n\nstatic int audit_launch_prune(void)\n{\n\tif (prune_thread)\n\t\treturn 0;\n\tprune_thread = kthread_run(prune_tree_thread, NULL,\n\t\t\t\t\"audit_prune_tree\");\n\tif (IS_ERR(prune_thread)) {\n\t\tpr_err(\"cannot start thread audit_prune_tree\");\n\t\tprune_thread = NULL;\n\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\n \nint audit_add_tree_rule(struct audit_krule *rule)\n{\n\tstruct audit_tree *seed = rule->tree, *tree;\n\tstruct path path;\n\tstruct vfsmount *mnt;\n\tint err;\n\n\trule->tree = NULL;\n\tlist_for_each_entry(tree, &tree_list, list) {\n\t\tif (!strcmp(seed->pathname, tree->pathname)) {\n\t\t\tput_tree(seed);\n\t\t\trule->tree = tree;\n\t\t\tlist_add(&rule->rlist, &tree->rules);\n\t\t\treturn 0;\n\t\t}\n\t}\n\ttree = seed;\n\tlist_add(&tree->list, &tree_list);\n\tlist_add(&rule->rlist, &tree->rules);\n\t \n\tmutex_unlock(&audit_filter_mutex);\n\n\tif (unlikely(!prune_thread)) {\n\t\terr = audit_launch_prune();\n\t\tif (err)\n\t\t\tgoto Err;\n\t}\n\n\terr = kern_path(tree->pathname, 0, &path);\n\tif (err)\n\t\tgoto Err;\n\tmnt = collect_mounts(&path);\n\tpath_put(&path);\n\tif (IS_ERR(mnt)) {\n\t\terr = PTR_ERR(mnt);\n\t\tgoto Err;\n\t}\n\n\tget_tree(tree);\n\terr = iterate_mounts(tag_mount, tree, mnt);\n\tdrop_collected_mounts(mnt);\n\n\tif (!err) {\n\t\tstruct audit_node *node;\n\t\tspin_lock(&hash_lock);\n\t\tlist_for_each_entry(node, &tree->chunks, list)\n\t\t\tnode->index &= ~(1U<<31);\n\t\tspin_unlock(&hash_lock);\n\t} else {\n\t\ttrim_marked(tree);\n\t\tgoto Err;\n\t}\n\n\tmutex_lock(&audit_filter_mutex);\n\tif (list_empty(&rule->rlist)) {\n\t\tput_tree(tree);\n\t\treturn -ENOENT;\n\t}\n\trule->tree = tree;\n\tput_tree(tree);\n\n\treturn 0;\nErr:\n\tmutex_lock(&audit_filter_mutex);\n\tlist_del_init(&tree->list);\n\tlist_del_init(&tree->rules);\n\tput_tree(tree);\n\treturn err;\n}\n\nint audit_tag_tree(char *old, char *new)\n{\n\tstruct list_head cursor, barrier;\n\tint failed = 0;\n\tstruct path path1, path2;\n\tstruct vfsmount *tagged;\n\tint err;\n\n\terr = kern_path(new, 0, &path2);\n\tif (err)\n\t\treturn err;\n\ttagged = collect_mounts(&path2);\n\tpath_put(&path2);\n\tif (IS_ERR(tagged))\n\t\treturn PTR_ERR(tagged);\n\n\terr = kern_path(old, 0, &path1);\n\tif (err) {\n\t\tdrop_collected_mounts(tagged);\n\t\treturn err;\n\t}\n\n\tmutex_lock(&audit_filter_mutex);\n\tlist_add(&barrier, &tree_list);\n\tlist_add(&cursor, &barrier);\n\n\twhile (cursor.next != &tree_list) {\n\t\tstruct audit_tree *tree;\n\t\tint good_one = 0;\n\n\t\ttree = container_of(cursor.next, struct audit_tree, list);\n\t\tget_tree(tree);\n\t\tlist_move(&cursor, &tree->list);\n\t\tmutex_unlock(&audit_filter_mutex);\n\n\t\terr = kern_path(tree->pathname, 0, &path2);\n\t\tif (!err) {\n\t\t\tgood_one = path_is_under(&path1, &path2);\n\t\t\tpath_put(&path2);\n\t\t}\n\n\t\tif (!good_one) {\n\t\t\tput_tree(tree);\n\t\t\tmutex_lock(&audit_filter_mutex);\n\t\t\tcontinue;\n\t\t}\n\n\t\tfailed = iterate_mounts(tag_mount, tree, tagged);\n\t\tif (failed) {\n\t\t\tput_tree(tree);\n\t\t\tmutex_lock(&audit_filter_mutex);\n\t\t\tbreak;\n\t\t}\n\n\t\tmutex_lock(&audit_filter_mutex);\n\t\tspin_lock(&hash_lock);\n\t\tif (!tree->goner) {\n\t\t\tlist_move(&tree->list, &tree_list);\n\t\t}\n\t\tspin_unlock(&hash_lock);\n\t\tput_tree(tree);\n\t}\n\n\twhile (barrier.prev != &tree_list) {\n\t\tstruct audit_tree *tree;\n\n\t\ttree = container_of(barrier.prev, struct audit_tree, list);\n\t\tget_tree(tree);\n\t\tlist_move(&tree->list, &barrier);\n\t\tmutex_unlock(&audit_filter_mutex);\n\n\t\tif (!failed) {\n\t\t\tstruct audit_node *node;\n\t\t\tspin_lock(&hash_lock);\n\t\t\tlist_for_each_entry(node, &tree->chunks, list)\n\t\t\t\tnode->index &= ~(1U<<31);\n\t\t\tspin_unlock(&hash_lock);\n\t\t} else {\n\t\t\ttrim_marked(tree);\n\t\t}\n\n\t\tput_tree(tree);\n\t\tmutex_lock(&audit_filter_mutex);\n\t}\n\tlist_del(&barrier);\n\tlist_del(&cursor);\n\tmutex_unlock(&audit_filter_mutex);\n\tpath_put(&path1);\n\tdrop_collected_mounts(tagged);\n\treturn failed;\n}\n\n\nstatic void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}\n\n \nvoid audit_kill_trees(struct audit_context *context)\n{\n\tstruct list_head *list = &context->killed_trees;\n\n\taudit_ctl_lock();\n\tmutex_lock(&audit_filter_mutex);\n\n\twhile (!list_empty(list)) {\n\t\tstruct audit_tree *victim;\n\n\t\tvictim = list_entry(list->next, struct audit_tree, list);\n\t\tkill_rules(context, victim);\n\t\tlist_del_init(&victim->list);\n\n\t\tmutex_unlock(&audit_filter_mutex);\n\n\t\tprune_one(victim);\n\n\t\tmutex_lock(&audit_filter_mutex);\n\t}\n\n\tmutex_unlock(&audit_filter_mutex);\n\taudit_ctl_unlock();\n}\n\n \n\nstatic void evict_chunk(struct audit_chunk *chunk)\n{\n\tstruct audit_tree *owner;\n\tstruct list_head *postponed = audit_killed_trees();\n\tint need_prune = 0;\n\tint n;\n\n\tmutex_lock(&audit_filter_mutex);\n\tspin_lock(&hash_lock);\n\twhile (!list_empty(&chunk->trees)) {\n\t\towner = list_entry(chunk->trees.next,\n\t\t\t\t   struct audit_tree, same_root);\n\t\towner->goner = 1;\n\t\towner->root = NULL;\n\t\tlist_del_init(&owner->same_root);\n\t\tspin_unlock(&hash_lock);\n\t\tif (!postponed) {\n\t\t\tkill_rules(audit_context(), owner);\n\t\t\tlist_move(&owner->list, &prune_list);\n\t\t\tneed_prune = 1;\n\t\t} else {\n\t\t\tlist_move(&owner->list, postponed);\n\t\t}\n\t\tspin_lock(&hash_lock);\n\t}\n\tlist_del_rcu(&chunk->hash);\n\tfor (n = 0; n < chunk->count; n++)\n\t\tlist_del_init(&chunk->owners[n].list);\n\tspin_unlock(&hash_lock);\n\tmutex_unlock(&audit_filter_mutex);\n\tif (need_prune)\n\t\taudit_schedule_prune();\n}\n\nstatic int audit_tree_handle_event(struct fsnotify_mark *mark, u32 mask,\n\t\t\t\t   struct inode *inode, struct inode *dir,\n\t\t\t\t   const struct qstr *file_name, u32 cookie)\n{\n\treturn 0;\n}\n\nstatic void audit_tree_freeing_mark(struct fsnotify_mark *mark,\n\t\t\t\t    struct fsnotify_group *group)\n{\n\tstruct audit_chunk *chunk;\n\n\tfsnotify_group_lock(mark->group);\n\tspin_lock(&hash_lock);\n\tchunk = mark_chunk(mark);\n\treplace_mark_chunk(mark, NULL);\n\tspin_unlock(&hash_lock);\n\tfsnotify_group_unlock(mark->group);\n\tif (chunk) {\n\t\tevict_chunk(chunk);\n\t\taudit_mark_put_chunk(chunk);\n\t}\n\n\t \n\tBUG_ON(refcount_read(&mark->refcnt) < 1);\n}\n\nstatic const struct fsnotify_ops audit_tree_ops = {\n\t.handle_inode_event = audit_tree_handle_event,\n\t.freeing_mark = audit_tree_freeing_mark,\n\t.free_mark = audit_tree_destroy_watch,\n};\n\nstatic int __init audit_tree_init(void)\n{\n\tint i;\n\n\taudit_tree_mark_cachep = KMEM_CACHE(audit_tree_mark, SLAB_PANIC);\n\n\taudit_tree_group = fsnotify_alloc_group(&audit_tree_ops, 0);\n\tif (IS_ERR(audit_tree_group))\n\t\taudit_panic(\"cannot initialize fsnotify group for rectree watches\");\n\n\tfor (i = 0; i < HASH_SIZE; i++)\n\t\tINIT_LIST_HEAD(&chunk_hash_heads[i]);\n\n\treturn 0;\n}\n__initcall(audit_tree_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}