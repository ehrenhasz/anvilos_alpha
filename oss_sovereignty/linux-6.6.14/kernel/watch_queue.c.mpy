{
  "module_name": "watch_queue.c",
  "hash_id": "b4eb7cdde6eeb3b9ed11944709bf71b56e65ec7e8b113bb66267d2e58b9abddf",
  "original_prompt": "Ingested from linux-6.6.14/kernel/watch_queue.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"watchq: \" fmt\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/printk.h>\n#include <linux/miscdevice.h>\n#include <linux/fs.h>\n#include <linux/mm.h>\n#include <linux/pagemap.h>\n#include <linux/poll.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/file.h>\n#include <linux/security.h>\n#include <linux/cred.h>\n#include <linux/sched/signal.h>\n#include <linux/watch_queue.h>\n#include <linux/pipe_fs_i.h>\n\nMODULE_DESCRIPTION(\"Watch queue\");\nMODULE_AUTHOR(\"Red Hat, Inc.\");\n\n#define WATCH_QUEUE_NOTE_SIZE 128\n#define WATCH_QUEUE_NOTES_PER_PAGE (PAGE_SIZE / WATCH_QUEUE_NOTE_SIZE)\n\n \nstatic inline bool lock_wqueue(struct watch_queue *wqueue)\n{\n\tspin_lock_bh(&wqueue->lock);\n\tif (unlikely(!wqueue->pipe)) {\n\t\tspin_unlock_bh(&wqueue->lock);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic inline void unlock_wqueue(struct watch_queue *wqueue)\n{\n\tspin_unlock_bh(&wqueue->lock);\n}\n\nstatic void watch_queue_pipe_buf_release(struct pipe_inode_info *pipe,\n\t\t\t\t\t struct pipe_buffer *buf)\n{\n\tstruct watch_queue *wqueue = (struct watch_queue *)buf->private;\n\tstruct page *page;\n\tunsigned int bit;\n\n\t \n\tbit = buf->offset + buf->len;\n\tif ((bit & (WATCH_QUEUE_NOTE_SIZE - 1)) == 0)\n\t\tbit -= WATCH_QUEUE_NOTE_SIZE;\n\tbit /= WATCH_QUEUE_NOTE_SIZE;\n\n\tpage = buf->page;\n\tbit += page->index;\n\n\tset_bit(bit, wqueue->notes_bitmap);\n\tgeneric_pipe_buf_release(pipe, buf);\n}\n\n \n#define watch_queue_pipe_buf_try_steal NULL\n\n \nstatic const struct pipe_buf_operations watch_queue_pipe_buf_ops = {\n\t.release\t= watch_queue_pipe_buf_release,\n\t.try_steal\t= watch_queue_pipe_buf_try_steal,\n\t.get\t\t= generic_pipe_buf_get,\n};\n\n \nstatic bool post_one_notification(struct watch_queue *wqueue,\n\t\t\t\t  struct watch_notification *n)\n{\n\tvoid *p;\n\tstruct pipe_inode_info *pipe = wqueue->pipe;\n\tstruct pipe_buffer *buf;\n\tstruct page *page;\n\tunsigned int head, tail, mask, note, offset, len;\n\tbool done = false;\n\n\tspin_lock_irq(&pipe->rd_wait.lock);\n\n\tmask = pipe->ring_size - 1;\n\thead = pipe->head;\n\ttail = pipe->tail;\n\tif (pipe_full(head, tail, pipe->ring_size))\n\t\tgoto lost;\n\n\tnote = find_first_bit(wqueue->notes_bitmap, wqueue->nr_notes);\n\tif (note >= wqueue->nr_notes)\n\t\tgoto lost;\n\n\tpage = wqueue->notes[note / WATCH_QUEUE_NOTES_PER_PAGE];\n\toffset = note % WATCH_QUEUE_NOTES_PER_PAGE * WATCH_QUEUE_NOTE_SIZE;\n\tget_page(page);\n\tlen = n->info & WATCH_INFO_LENGTH;\n\tp = kmap_atomic(page);\n\tmemcpy(p + offset, n, len);\n\tkunmap_atomic(p);\n\n\tbuf = &pipe->bufs[head & mask];\n\tbuf->page = page;\n\tbuf->private = (unsigned long)wqueue;\n\tbuf->ops = &watch_queue_pipe_buf_ops;\n\tbuf->offset = offset;\n\tbuf->len = len;\n\tbuf->flags = PIPE_BUF_FLAG_WHOLE;\n\tsmp_store_release(&pipe->head, head + 1);  \n\n\tif (!test_and_clear_bit(note, wqueue->notes_bitmap)) {\n\t\tspin_unlock_irq(&pipe->rd_wait.lock);\n\t\tBUG();\n\t}\n\twake_up_interruptible_sync_poll_locked(&pipe->rd_wait, EPOLLIN | EPOLLRDNORM);\n\tdone = true;\n\nout:\n\tspin_unlock_irq(&pipe->rd_wait.lock);\n\tif (done)\n\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);\n\treturn done;\n\nlost:\n\tbuf = &pipe->bufs[(head - 1) & mask];\n\tbuf->flags |= PIPE_BUF_FLAG_LOSS;\n\tgoto out;\n}\n\n \nstatic bool filter_watch_notification(const struct watch_filter *wf,\n\t\t\t\t      const struct watch_notification *n)\n{\n\tconst struct watch_type_filter *wt;\n\tunsigned int st_bits = sizeof(wt->subtype_filter[0]) * 8;\n\tunsigned int st_index = n->subtype / st_bits;\n\tunsigned int st_bit = 1U << (n->subtype % st_bits);\n\tint i;\n\n\tif (!test_bit(n->type, wf->type_filter))\n\t\treturn false;\n\n\tfor (i = 0; i < wf->nr_filters; i++) {\n\t\twt = &wf->filters[i];\n\t\tif (n->type == wt->type &&\n\t\t    (wt->subtype_filter[st_index] & st_bit) &&\n\t\t    (n->info & wt->info_mask) == wt->info_filter)\n\t\t\treturn true;\n\t}\n\n\treturn false;  \n}\n\n \nvoid __post_watch_notification(struct watch_list *wlist,\n\t\t\t       struct watch_notification *n,\n\t\t\t       const struct cred *cred,\n\t\t\t       u64 id)\n{\n\tconst struct watch_filter *wf;\n\tstruct watch_queue *wqueue;\n\tstruct watch *watch;\n\n\tif (((n->info & WATCH_INFO_LENGTH) >> WATCH_INFO_LENGTH__SHIFT) == 0) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\n\thlist_for_each_entry_rcu(watch, &wlist->watchers, list_node) {\n\t\tif (watch->id != id)\n\t\t\tcontinue;\n\t\tn->info &= ~WATCH_INFO_ID;\n\t\tn->info |= watch->info_id;\n\n\t\twqueue = rcu_dereference(watch->queue);\n\t\twf = rcu_dereference(wqueue->filter);\n\t\tif (wf && !filter_watch_notification(wf, n))\n\t\t\tcontinue;\n\n\t\tif (security_post_notification(watch->cred, cred, n) < 0)\n\t\t\tcontinue;\n\n\t\tif (lock_wqueue(wqueue)) {\n\t\t\tpost_one_notification(wqueue, n);\n\t\t\tunlock_wqueue(wqueue);\n\t\t}\n\t}\n\n\trcu_read_unlock();\n}\nEXPORT_SYMBOL(__post_watch_notification);\n\n \nlong watch_queue_set_size(struct pipe_inode_info *pipe, unsigned int nr_notes)\n{\n\tstruct watch_queue *wqueue = pipe->watch_queue;\n\tstruct page **pages;\n\tunsigned long *bitmap;\n\tunsigned long user_bufs;\n\tint ret, i, nr_pages;\n\n\tif (!wqueue)\n\t\treturn -ENODEV;\n\tif (wqueue->notes)\n\t\treturn -EBUSY;\n\n\tif (nr_notes < 1 ||\n\t    nr_notes > 512)  \n\t\treturn -EINVAL;\n\n\tnr_pages = (nr_notes + WATCH_QUEUE_NOTES_PER_PAGE - 1);\n\tnr_pages /= WATCH_QUEUE_NOTES_PER_PAGE;\n\tuser_bufs = account_pipe_buffers(pipe->user, pipe->nr_accounted, nr_pages);\n\n\tif (nr_pages > pipe->max_usage &&\n\t    (too_many_pipe_buffers_hard(user_bufs) ||\n\t     too_many_pipe_buffers_soft(user_bufs)) &&\n\t    pipe_is_unprivileged_user()) {\n\t\tret = -EPERM;\n\t\tgoto error;\n\t}\n\n\tnr_notes = nr_pages * WATCH_QUEUE_NOTES_PER_PAGE;\n\tret = pipe_resize_ring(pipe, roundup_pow_of_two(nr_notes));\n\tif (ret < 0)\n\t\tgoto error;\n\n\tret = -ENOMEM;\n\tpages = kcalloc(sizeof(struct page *), nr_pages, GFP_KERNEL);\n\tif (!pages)\n\t\tgoto error;\n\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tpages[i] = alloc_page(GFP_KERNEL);\n\t\tif (!pages[i])\n\t\t\tgoto error_p;\n\t\tpages[i]->index = i * WATCH_QUEUE_NOTES_PER_PAGE;\n\t}\n\n\tbitmap = bitmap_alloc(nr_notes, GFP_KERNEL);\n\tif (!bitmap)\n\t\tgoto error_p;\n\n\tbitmap_fill(bitmap, nr_notes);\n\twqueue->notes = pages;\n\twqueue->notes_bitmap = bitmap;\n\twqueue->nr_pages = nr_pages;\n\twqueue->nr_notes = nr_notes;\n\treturn 0;\n\nerror_p:\n\twhile (--i >= 0)\n\t\t__free_page(pages[i]);\n\tkfree(pages);\nerror:\n\t(void) account_pipe_buffers(pipe->user, nr_pages, pipe->nr_accounted);\n\treturn ret;\n}\n\n \nlong watch_queue_set_filter(struct pipe_inode_info *pipe,\n\t\t\t    struct watch_notification_filter __user *_filter)\n{\n\tstruct watch_notification_type_filter *tf;\n\tstruct watch_notification_filter filter;\n\tstruct watch_type_filter *q;\n\tstruct watch_filter *wfilter;\n\tstruct watch_queue *wqueue = pipe->watch_queue;\n\tint ret, nr_filter = 0, i;\n\n\tif (!wqueue)\n\t\treturn -ENODEV;\n\n\tif (!_filter) {\n\t\t \n\t\twfilter = NULL;\n\t\tgoto set;\n\t}\n\n\t \n\tif (copy_from_user(&filter, _filter, sizeof(filter)) != 0)\n\t\treturn -EFAULT;\n\tif (filter.nr_filters == 0 ||\n\t    filter.nr_filters > 16 ||\n\t    filter.__reserved != 0)\n\t\treturn -EINVAL;\n\n\ttf = memdup_array_user(_filter->filters, filter.nr_filters, sizeof(*tf));\n\tif (IS_ERR(tf))\n\t\treturn PTR_ERR(tf);\n\n\tret = -EINVAL;\n\tfor (i = 0; i < filter.nr_filters; i++) {\n\t\tif ((tf[i].info_filter & ~tf[i].info_mask) ||\n\t\t    tf[i].info_mask & WATCH_INFO_LENGTH)\n\t\t\tgoto err_filter;\n\t\t \n\t\tif (tf[i].type >= WATCH_TYPE__NR)\n\t\t\tcontinue;\n\t\tnr_filter++;\n\t}\n\n\t \n\tret = -ENOMEM;\n\twfilter = kzalloc(struct_size(wfilter, filters, nr_filter), GFP_KERNEL);\n\tif (!wfilter)\n\t\tgoto err_filter;\n\twfilter->nr_filters = nr_filter;\n\n\tq = wfilter->filters;\n\tfor (i = 0; i < filter.nr_filters; i++) {\n\t\tif (tf[i].type >= WATCH_TYPE__NR)\n\t\t\tcontinue;\n\n\t\tq->type\t\t\t= tf[i].type;\n\t\tq->info_filter\t\t= tf[i].info_filter;\n\t\tq->info_mask\t\t= tf[i].info_mask;\n\t\tq->subtype_filter[0]\t= tf[i].subtype_filter[0];\n\t\t__set_bit(q->type, wfilter->type_filter);\n\t\tq++;\n\t}\n\n\tkfree(tf);\nset:\n\tpipe_lock(pipe);\n\twfilter = rcu_replace_pointer(wqueue->filter, wfilter,\n\t\t\t\t      lockdep_is_held(&pipe->mutex));\n\tpipe_unlock(pipe);\n\tif (wfilter)\n\t\tkfree_rcu(wfilter, rcu);\n\treturn 0;\n\nerr_filter:\n\tkfree(tf);\n\treturn ret;\n}\n\nstatic void __put_watch_queue(struct kref *kref)\n{\n\tstruct watch_queue *wqueue =\n\t\tcontainer_of(kref, struct watch_queue, usage);\n\tstruct watch_filter *wfilter;\n\tint i;\n\n\tfor (i = 0; i < wqueue->nr_pages; i++)\n\t\t__free_page(wqueue->notes[i]);\n\tkfree(wqueue->notes);\n\tbitmap_free(wqueue->notes_bitmap);\n\n\twfilter = rcu_access_pointer(wqueue->filter);\n\tif (wfilter)\n\t\tkfree_rcu(wfilter, rcu);\n\tkfree_rcu(wqueue, rcu);\n}\n\n \nvoid put_watch_queue(struct watch_queue *wqueue)\n{\n\tkref_put(&wqueue->usage, __put_watch_queue);\n}\nEXPORT_SYMBOL(put_watch_queue);\n\nstatic void free_watch(struct rcu_head *rcu)\n{\n\tstruct watch *watch = container_of(rcu, struct watch, rcu);\n\n\tput_watch_queue(rcu_access_pointer(watch->queue));\n\tatomic_dec(&watch->cred->user->nr_watches);\n\tput_cred(watch->cred);\n\tkfree(watch);\n}\n\nstatic void __put_watch(struct kref *kref)\n{\n\tstruct watch *watch = container_of(kref, struct watch, usage);\n\n\tcall_rcu(&watch->rcu, free_watch);\n}\n\n \nstatic void put_watch(struct watch *watch)\n{\n\tkref_put(&watch->usage, __put_watch);\n}\n\n \nvoid init_watch(struct watch *watch, struct watch_queue *wqueue)\n{\n\tkref_init(&watch->usage);\n\tINIT_HLIST_NODE(&watch->list_node);\n\tINIT_HLIST_NODE(&watch->queue_node);\n\trcu_assign_pointer(watch->queue, wqueue);\n}\n\nstatic int add_one_watch(struct watch *watch, struct watch_list *wlist, struct watch_queue *wqueue)\n{\n\tconst struct cred *cred;\n\tstruct watch *w;\n\n\thlist_for_each_entry(w, &wlist->watchers, list_node) {\n\t\tstruct watch_queue *wq = rcu_access_pointer(w->queue);\n\t\tif (wqueue == wq && watch->id == w->id)\n\t\t\treturn -EBUSY;\n\t}\n\n\tcred = current_cred();\n\tif (atomic_inc_return(&cred->user->nr_watches) > task_rlimit(current, RLIMIT_NOFILE)) {\n\t\tatomic_dec(&cred->user->nr_watches);\n\t\treturn -EAGAIN;\n\t}\n\n\twatch->cred = get_cred(cred);\n\trcu_assign_pointer(watch->watch_list, wlist);\n\n\tkref_get(&wqueue->usage);\n\tkref_get(&watch->usage);\n\thlist_add_head(&watch->queue_node, &wqueue->watches);\n\thlist_add_head_rcu(&watch->list_node, &wlist->watchers);\n\treturn 0;\n}\n\n \nint add_watch_to_object(struct watch *watch, struct watch_list *wlist)\n{\n\tstruct watch_queue *wqueue;\n\tint ret = -ENOENT;\n\n\trcu_read_lock();\n\n\twqueue = rcu_access_pointer(watch->queue);\n\tif (lock_wqueue(wqueue)) {\n\t\tspin_lock(&wlist->lock);\n\t\tret = add_one_watch(watch, wlist, wqueue);\n\t\tspin_unlock(&wlist->lock);\n\t\tunlock_wqueue(wqueue);\n\t}\n\n\trcu_read_unlock();\n\treturn ret;\n}\nEXPORT_SYMBOL(add_watch_to_object);\n\n \nint remove_watch_from_object(struct watch_list *wlist, struct watch_queue *wq,\n\t\t\t     u64 id, bool all)\n{\n\tstruct watch_notification_removal n;\n\tstruct watch_queue *wqueue;\n\tstruct watch *watch;\n\tint ret = -EBADSLT;\n\n\trcu_read_lock();\n\nagain:\n\tspin_lock(&wlist->lock);\n\thlist_for_each_entry(watch, &wlist->watchers, list_node) {\n\t\tif (all ||\n\t\t    (watch->id == id && rcu_access_pointer(watch->queue) == wq))\n\t\t\tgoto found;\n\t}\n\tspin_unlock(&wlist->lock);\n\tgoto out;\n\nfound:\n\tret = 0;\n\thlist_del_init_rcu(&watch->list_node);\n\trcu_assign_pointer(watch->watch_list, NULL);\n\tspin_unlock(&wlist->lock);\n\n\t \n\n\tn.watch.type = WATCH_TYPE_META;\n\tn.watch.subtype = WATCH_META_REMOVAL_NOTIFICATION;\n\tn.watch.info = watch->info_id | watch_sizeof(n.watch);\n\tn.id = id;\n\tif (id != 0)\n\t\tn.watch.info = watch->info_id | watch_sizeof(n);\n\n\twqueue = rcu_dereference(watch->queue);\n\n\tif (lock_wqueue(wqueue)) {\n\t\tpost_one_notification(wqueue, &n.watch);\n\n\t\tif (!hlist_unhashed(&watch->queue_node)) {\n\t\t\thlist_del_init_rcu(&watch->queue_node);\n\t\t\tput_watch(watch);\n\t\t}\n\n\t\tunlock_wqueue(wqueue);\n\t}\n\n\tif (wlist->release_watch) {\n\t\tvoid (*release_watch)(struct watch *);\n\n\t\trelease_watch = wlist->release_watch;\n\t\trcu_read_unlock();\n\t\t(*release_watch)(watch);\n\t\trcu_read_lock();\n\t}\n\tput_watch(watch);\n\n\tif (all && !hlist_empty(&wlist->watchers))\n\t\tgoto again;\nout:\n\trcu_read_unlock();\n\treturn ret;\n}\nEXPORT_SYMBOL(remove_watch_from_object);\n\n \nvoid watch_queue_clear(struct watch_queue *wqueue)\n{\n\tstruct watch_list *wlist;\n\tstruct watch *watch;\n\tbool release;\n\n\trcu_read_lock();\n\tspin_lock_bh(&wqueue->lock);\n\n\t \n\twqueue->pipe = NULL;\n\n\twhile (!hlist_empty(&wqueue->watches)) {\n\t\twatch = hlist_entry(wqueue->watches.first, struct watch, queue_node);\n\t\thlist_del_init_rcu(&watch->queue_node);\n\t\t \n\t\tspin_unlock_bh(&wqueue->lock);\n\n\t\t \n\t\twlist = rcu_dereference(watch->watch_list);\n\t\tif (wlist) {\n\t\t\tvoid (*release_watch)(struct watch *);\n\n\t\t\tspin_lock(&wlist->lock);\n\n\t\t\trelease = !hlist_unhashed(&watch->list_node);\n\t\t\tif (release) {\n\t\t\t\thlist_del_init_rcu(&watch->list_node);\n\t\t\t\trcu_assign_pointer(watch->watch_list, NULL);\n\n\t\t\t\t \n\t\t\t}\n\n\t\t\trelease_watch = wlist->release_watch;\n\t\t\tspin_unlock(&wlist->lock);\n\n\t\t\tif (release) {\n\t\t\t\tif (release_watch) {\n\t\t\t\t\trcu_read_unlock();\n\t\t\t\t\t \n\t\t\t\t\t(*release_watch)(watch);\n\t\t\t\t\trcu_read_lock();\n\t\t\t\t}\n\t\t\t\tput_watch(watch);\n\t\t\t}\n\t\t}\n\n\t\tput_watch(watch);\n\t\tspin_lock_bh(&wqueue->lock);\n\t}\n\n\tspin_unlock_bh(&wqueue->lock);\n\trcu_read_unlock();\n}\n\n \nstruct watch_queue *get_watch_queue(int fd)\n{\n\tstruct pipe_inode_info *pipe;\n\tstruct watch_queue *wqueue = ERR_PTR(-EINVAL);\n\tstruct fd f;\n\n\tf = fdget(fd);\n\tif (f.file) {\n\t\tpipe = get_pipe_info(f.file, false);\n\t\tif (pipe && pipe->watch_queue) {\n\t\t\twqueue = pipe->watch_queue;\n\t\t\tkref_get(&wqueue->usage);\n\t\t}\n\t\tfdput(f);\n\t}\n\n\treturn wqueue;\n}\nEXPORT_SYMBOL(get_watch_queue);\n\n \nint watch_queue_init(struct pipe_inode_info *pipe)\n{\n\tstruct watch_queue *wqueue;\n\n\twqueue = kzalloc(sizeof(*wqueue), GFP_KERNEL);\n\tif (!wqueue)\n\t\treturn -ENOMEM;\n\n\twqueue->pipe = pipe;\n\tkref_init(&wqueue->usage);\n\tspin_lock_init(&wqueue->lock);\n\tINIT_HLIST_HEAD(&wqueue->watches);\n\n\tpipe->watch_queue = wqueue;\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}