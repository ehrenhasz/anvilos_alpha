{
  "module_name": "tree_stall.h",
  "hash_id": "482df003991c81138b0751ed542ae066b9c61b5280268489a3a98d3d463ba194",
  "original_prompt": "Ingested from linux-6.6.14/kernel/rcu/tree_stall.h",
  "human_readable_source": "\n \n\n#include <linux/kvm_para.h>\n\n\n\n\n\n \nint sysctl_panic_on_rcu_stall __read_mostly;\nint sysctl_max_rcu_stall_to_panic __read_mostly;\n\n#ifdef CONFIG_PROVE_RCU\n#define RCU_STALL_DELAY_DELTA\t\t(5 * HZ)\n#else\n#define RCU_STALL_DELAY_DELTA\t\t0\n#endif\n#define RCU_STALL_MIGHT_DIV\t\t8\n#define RCU_STALL_MIGHT_MIN\t\t(2 * HZ)\n\nint rcu_exp_jiffies_till_stall_check(void)\n{\n\tint cpu_stall_timeout = READ_ONCE(rcu_exp_cpu_stall_timeout);\n\tint exp_stall_delay_delta = 0;\n\tint till_stall_check;\n\n\t\n\tif (!cpu_stall_timeout)\n\t\tcpu_stall_timeout = jiffies_to_msecs(rcu_jiffies_till_stall_check());\n\n\t\n\t\n\t\n\t\n\ttill_stall_check = clamp(msecs_to_jiffies(cpu_stall_timeout), 2UL, 300UL * HZ);\n\n\tif (cpu_stall_timeout && jiffies_to_msecs(till_stall_check) != cpu_stall_timeout)\n\t\tWRITE_ONCE(rcu_exp_cpu_stall_timeout, jiffies_to_msecs(till_stall_check));\n\n#ifdef CONFIG_PROVE_RCU\n\t \n\texp_stall_delay_delta = ((till_stall_check * 25) / 100) + 1;\n#endif\n\n\treturn till_stall_check + exp_stall_delay_delta;\n}\nEXPORT_SYMBOL_GPL(rcu_exp_jiffies_till_stall_check);\n\n \nint rcu_jiffies_till_stall_check(void)\n{\n\tint till_stall_check = READ_ONCE(rcu_cpu_stall_timeout);\n\n\t \n\tif (till_stall_check < 3) {\n\t\tWRITE_ONCE(rcu_cpu_stall_timeout, 3);\n\t\ttill_stall_check = 3;\n\t} else if (till_stall_check > 300) {\n\t\tWRITE_ONCE(rcu_cpu_stall_timeout, 300);\n\t\ttill_stall_check = 300;\n\t}\n\treturn till_stall_check * HZ + RCU_STALL_DELAY_DELTA;\n}\nEXPORT_SYMBOL_GPL(rcu_jiffies_till_stall_check);\n\n \nbool rcu_gp_might_be_stalled(void)\n{\n\tunsigned long d = rcu_jiffies_till_stall_check() / RCU_STALL_MIGHT_DIV;\n\tunsigned long j = jiffies;\n\n\tif (d < RCU_STALL_MIGHT_MIN)\n\t\td = RCU_STALL_MIGHT_MIN;\n\tsmp_mb(); \n\tif (!rcu_gp_in_progress())\n\t\treturn false;\n\t\n\t\n\tsmp_mb(); \n\t\n\treturn !time_before(j, READ_ONCE(rcu_state.gp_start) + d);\n}\n\n \nvoid rcu_sysrq_start(void)\n{\n\tif (!rcu_cpu_stall_suppress)\n\t\trcu_cpu_stall_suppress = 2;\n}\n\nvoid rcu_sysrq_end(void)\n{\n\tif (rcu_cpu_stall_suppress == 2)\n\t\trcu_cpu_stall_suppress = 0;\n}\n\n \nstatic int rcu_panic(struct notifier_block *this, unsigned long ev, void *ptr)\n{\n\trcu_cpu_stall_suppress = 1;\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block rcu_panic_block = {\n\t.notifier_call = rcu_panic,\n};\n\nstatic int __init check_cpu_stall_init(void)\n{\n\tatomic_notifier_chain_register(&panic_notifier_list, &rcu_panic_block);\n\treturn 0;\n}\nearly_initcall(check_cpu_stall_init);\n\n \nstatic void panic_on_rcu_stall(void)\n{\n\tstatic int cpu_stall;\n\n\tif (++cpu_stall < sysctl_max_rcu_stall_to_panic)\n\t\treturn;\n\n\tif (sysctl_panic_on_rcu_stall)\n\t\tpanic(\"RCU Stall\\n\");\n}\n\n \nvoid rcu_cpu_stall_reset(void)\n{\n\tWRITE_ONCE(rcu_state.nr_fqs_jiffies_stall, 3);\n\tWRITE_ONCE(rcu_state.jiffies_stall, ULONG_MAX);\n}\n\n\n\n\n\n \nstatic void record_gp_stall_check_time(void)\n{\n\tunsigned long j = jiffies;\n\tunsigned long j1;\n\n\tWRITE_ONCE(rcu_state.gp_start, j);\n\tj1 = rcu_jiffies_till_stall_check();\n\tsmp_mb(); \n\tWRITE_ONCE(rcu_state.nr_fqs_jiffies_stall, 0);\n\tWRITE_ONCE(rcu_state.jiffies_stall, j + j1);\n\trcu_state.jiffies_resched = j + j1 / 2;\n\trcu_state.n_force_qs_gpstart = READ_ONCE(rcu_state.n_force_qs);\n}\n\n \nstatic void zero_cpu_stall_ticks(struct rcu_data *rdp)\n{\n\trdp->ticks_this_gp = 0;\n\trdp->softirq_snap = kstat_softirqs_cpu(RCU_SOFTIRQ, smp_processor_id());\n\tWRITE_ONCE(rdp->last_fqs_resched, jiffies);\n}\n\n \nstatic void rcu_stall_kick_kthreads(void)\n{\n\tunsigned long j;\n\n\tif (!READ_ONCE(rcu_kick_kthreads))\n\t\treturn;\n\tj = READ_ONCE(rcu_state.jiffies_kick_kthreads);\n\tif (time_after(jiffies, j) && rcu_state.gp_kthread &&\n\t    (rcu_gp_in_progress() || READ_ONCE(rcu_state.gp_flags))) {\n\t\tWARN_ONCE(1, \"Kicking %s grace-period kthread\\n\",\n\t\t\t  rcu_state.name);\n\t\trcu_ftrace_dump(DUMP_ALL);\n\t\twake_up_process(rcu_state.gp_kthread);\n\t\tWRITE_ONCE(rcu_state.jiffies_kick_kthreads, j + HZ);\n\t}\n}\n\n \nstatic void rcu_iw_handler(struct irq_work *iwp)\n{\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp;\n\n\trdp = container_of(iwp, struct rcu_data, rcu_iw);\n\trnp = rdp->mynode;\n\traw_spin_lock_rcu_node(rnp);\n\tif (!WARN_ON_ONCE(!rdp->rcu_iw_pending)) {\n\t\trdp->rcu_iw_gp_seq = rnp->gp_seq;\n\t\trdp->rcu_iw_pending = false;\n\t}\n\traw_spin_unlock_rcu_node(rnp);\n}\n\n\n\n\n\n#ifdef CONFIG_PREEMPT_RCU\n\n \nstatic void rcu_print_detail_task_stall_rnp(struct rcu_node *rnp)\n{\n\tunsigned long flags;\n\tstruct task_struct *t;\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\tif (!rcu_preempt_blocked_readers_cgp(rnp)) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;\n\t}\n\tt = list_entry(rnp->gp_tasks->prev,\n\t\t       struct task_struct, rcu_node_entry);\n\tlist_for_each_entry_continue(t, &rnp->blkd_tasks, rcu_node_entry) {\n\t\t \n\t\ttouch_nmi_watchdog();\n\t\tsched_show_task(t);\n\t}\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n}\n\n\nstruct rcu_stall_chk_rdr {\n\tint nesting;\n\tunion rcu_special rs;\n\tbool on_blkd_list;\n};\n\n \nstatic int check_slow_task(struct task_struct *t, void *arg)\n{\n\tstruct rcu_stall_chk_rdr *rscrp = arg;\n\n\tif (task_curr(t))\n\t\treturn -EBUSY; \n\trscrp->nesting = t->rcu_read_lock_nesting;\n\trscrp->rs = t->rcu_read_unlock_special;\n\trscrp->on_blkd_list = !list_empty(&t->rcu_node_entry);\n\treturn 0;\n}\n\n \nstatic int rcu_print_task_stall(struct rcu_node *rnp, unsigned long flags)\n\t__releases(rnp->lock)\n{\n\tint i = 0;\n\tint ndetected = 0;\n\tstruct rcu_stall_chk_rdr rscr;\n\tstruct task_struct *t;\n\tstruct task_struct *ts[8];\n\n\tlockdep_assert_irqs_disabled();\n\tif (!rcu_preempt_blocked_readers_cgp(rnp)) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn 0;\n\t}\n\tpr_err(\"\\tTasks blocked on level-%d rcu_node (CPUs %d-%d):\",\n\t       rnp->level, rnp->grplo, rnp->grphi);\n\tt = list_entry(rnp->gp_tasks->prev,\n\t\t       struct task_struct, rcu_node_entry);\n\tlist_for_each_entry_continue(t, &rnp->blkd_tasks, rcu_node_entry) {\n\t\tget_task_struct(t);\n\t\tts[i++] = t;\n\t\tif (i >= ARRAY_SIZE(ts))\n\t\t\tbreak;\n\t}\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\twhile (i) {\n\t\tt = ts[--i];\n\t\tif (task_call_func(t, check_slow_task, &rscr))\n\t\t\tpr_cont(\" P%d\", t->pid);\n\t\telse\n\t\t\tpr_cont(\" P%d/%d:%c%c%c%c\",\n\t\t\t\tt->pid, rscr.nesting,\n\t\t\t\t\".b\"[rscr.rs.b.blocked],\n\t\t\t\t\".q\"[rscr.rs.b.need_qs],\n\t\t\t\t\".e\"[rscr.rs.b.exp_hint],\n\t\t\t\t\".l\"[rscr.on_blkd_list]);\n\t\tlockdep_assert_irqs_disabled();\n\t\tput_task_struct(t);\n\t\tndetected++;\n\t}\n\tpr_cont(\"\\n\");\n\treturn ndetected;\n}\n\n#else  \n\n \nstatic void rcu_print_detail_task_stall_rnp(struct rcu_node *rnp)\n{\n}\n\n \nstatic int rcu_print_task_stall(struct rcu_node *rnp, unsigned long flags)\n\t__releases(rnp->lock)\n{\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\treturn 0;\n}\n#endif  \n\n \nstatic void rcu_dump_cpu_stacks(void)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_node *rnp;\n\n\trcu_for_each_leaf_node(rnp) {\n\t\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\t\tfor_each_leaf_node_possible_cpu(rnp, cpu)\n\t\t\tif (rnp->qsmask & leaf_node_cpu_bit(rnp, cpu)) {\n\t\t\t\tif (cpu_is_offline(cpu))\n\t\t\t\t\tpr_err(\"Offline CPU %d blocking current GP.\\n\", cpu);\n\t\t\t\telse\n\t\t\t\t\tdump_cpu_task(cpu);\n\t\t\t}\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t}\n}\n\nstatic const char * const gp_state_names[] = {\n\t[RCU_GP_IDLE] = \"RCU_GP_IDLE\",\n\t[RCU_GP_WAIT_GPS] = \"RCU_GP_WAIT_GPS\",\n\t[RCU_GP_DONE_GPS] = \"RCU_GP_DONE_GPS\",\n\t[RCU_GP_ONOFF] = \"RCU_GP_ONOFF\",\n\t[RCU_GP_INIT] = \"RCU_GP_INIT\",\n\t[RCU_GP_WAIT_FQS] = \"RCU_GP_WAIT_FQS\",\n\t[RCU_GP_DOING_FQS] = \"RCU_GP_DOING_FQS\",\n\t[RCU_GP_CLEANUP] = \"RCU_GP_CLEANUP\",\n\t[RCU_GP_CLEANED] = \"RCU_GP_CLEANED\",\n};\n\n \nstatic const char *gp_state_getname(short gs)\n{\n\tif (gs < 0 || gs >= ARRAY_SIZE(gp_state_names))\n\t\treturn \"???\";\n\treturn gp_state_names[gs];\n}\n\n \nstatic bool rcu_is_gp_kthread_starving(unsigned long *jp)\n{\n\tunsigned long j = jiffies - READ_ONCE(rcu_state.gp_activity);\n\n\tif (jp)\n\t\t*jp = j;\n\treturn j > 2 * HZ;\n}\n\nstatic bool rcu_is_rcuc_kthread_starving(struct rcu_data *rdp, unsigned long *jp)\n{\n\tint cpu;\n\tstruct task_struct *rcuc;\n\tunsigned long j;\n\n\trcuc = rdp->rcu_cpu_kthread_task;\n\tif (!rcuc)\n\t\treturn false;\n\n\tcpu = task_cpu(rcuc);\n\tif (cpu_is_offline(cpu) || idle_cpu(cpu))\n\t\treturn false;\n\n\tj = jiffies - READ_ONCE(rdp->rcuc_activity);\n\n\tif (jp)\n\t\t*jp = j;\n\treturn j > 2 * HZ;\n}\n\nstatic void print_cpu_stat_info(int cpu)\n{\n\tstruct rcu_snap_record rsr, *rsrp;\n\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);\n\tstruct kernel_cpustat *kcsp = &kcpustat_cpu(cpu);\n\n\tif (!rcu_cpu_stall_cputime)\n\t\treturn;\n\n\trsrp = &rdp->snap_record;\n\tif (rsrp->gp_seq != rdp->gp_seq)\n\t\treturn;\n\n\trsr.cputime_irq     = kcpustat_field(kcsp, CPUTIME_IRQ, cpu);\n\trsr.cputime_softirq = kcpustat_field(kcsp, CPUTIME_SOFTIRQ, cpu);\n\trsr.cputime_system  = kcpustat_field(kcsp, CPUTIME_SYSTEM, cpu);\n\n\tpr_err(\"\\t         hardirqs   softirqs   csw/system\\n\");\n\tpr_err(\"\\t number: %8ld %10d %12lld\\n\",\n\t\tkstat_cpu_irqs_sum(cpu) - rsrp->nr_hardirqs,\n\t\tkstat_cpu_softirqs_sum(cpu) - rsrp->nr_softirqs,\n\t\tnr_context_switches_cpu(cpu) - rsrp->nr_csw);\n\tpr_err(\"\\tcputime: %8lld %10lld %12lld   ==> %d(ms)\\n\",\n\t\tdiv_u64(rsr.cputime_irq - rsrp->cputime_irq, NSEC_PER_MSEC),\n\t\tdiv_u64(rsr.cputime_softirq - rsrp->cputime_softirq, NSEC_PER_MSEC),\n\t\tdiv_u64(rsr.cputime_system - rsrp->cputime_system, NSEC_PER_MSEC),\n\t\tjiffies_to_msecs(jiffies - rsrp->jiffies));\n}\n\n \nstatic void print_cpu_stall_info(int cpu)\n{\n\tunsigned long delta;\n\tbool falsepositive;\n\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);\n\tchar *ticks_title;\n\tunsigned long ticks_value;\n\tbool rcuc_starved;\n\tunsigned long j;\n\tchar buf[32];\n\n\t \n\ttouch_nmi_watchdog();\n\n\tticks_value = rcu_seq_ctr(rcu_state.gp_seq - rdp->gp_seq);\n\tif (ticks_value) {\n\t\tticks_title = \"GPs behind\";\n\t} else {\n\t\tticks_title = \"ticks this GP\";\n\t\tticks_value = rdp->ticks_this_gp;\n\t}\n\tdelta = rcu_seq_ctr(rdp->mynode->gp_seq - rdp->rcu_iw_gp_seq);\n\tfalsepositive = rcu_is_gp_kthread_starving(NULL) &&\n\t\t\trcu_dynticks_in_eqs(rcu_dynticks_snap(cpu));\n\trcuc_starved = rcu_is_rcuc_kthread_starving(rdp, &j);\n\tif (rcuc_starved)\n\t\tsprintf(buf, \" rcuc=%ld jiffies(starved)\", j);\n\tpr_err(\"\\t%d-%c%c%c%c: (%lu %s) idle=%04x/%ld/%#lx softirq=%u/%u fqs=%ld%s%s\\n\",\n\t       cpu,\n\t       \"O.\"[!!cpu_online(cpu)],\n\t       \"o.\"[!!(rdp->grpmask & rdp->mynode->qsmaskinit)],\n\t       \"N.\"[!!(rdp->grpmask & rdp->mynode->qsmaskinitnext)],\n\t       !IS_ENABLED(CONFIG_IRQ_WORK) ? '?' :\n\t\t\trdp->rcu_iw_pending ? (int)min(delta, 9UL) + '0' :\n\t\t\t\t\"!.\"[!delta],\n\t       ticks_value, ticks_title,\n\t       rcu_dynticks_snap(cpu) & 0xffff,\n\t       ct_dynticks_nesting_cpu(cpu), ct_dynticks_nmi_nesting_cpu(cpu),\n\t       rdp->softirq_snap, kstat_softirqs_cpu(RCU_SOFTIRQ, cpu),\n\t       data_race(rcu_state.n_force_qs) - rcu_state.n_force_qs_gpstart,\n\t       rcuc_starved ? buf : \"\",\n\t       falsepositive ? \" (false positive?)\" : \"\");\n\n\tprint_cpu_stat_info(cpu);\n}\n\n \nstatic void rcu_check_gp_kthread_starvation(void)\n{\n\tint cpu;\n\tstruct task_struct *gpk = rcu_state.gp_kthread;\n\tunsigned long j;\n\n\tif (rcu_is_gp_kthread_starving(&j)) {\n\t\tcpu = gpk ? task_cpu(gpk) : -1;\n\t\tpr_err(\"%s kthread starved for %ld jiffies! g%ld f%#x %s(%d) ->state=%#x ->cpu=%d\\n\",\n\t\t       rcu_state.name, j,\n\t\t       (long)rcu_seq_current(&rcu_state.gp_seq),\n\t\t       data_race(READ_ONCE(rcu_state.gp_flags)),\n\t\t       gp_state_getname(rcu_state.gp_state),\n\t\t       data_race(READ_ONCE(rcu_state.gp_state)),\n\t\t       gpk ? data_race(READ_ONCE(gpk->__state)) : ~0, cpu);\n\t\tif (gpk) {\n\t\t\tpr_err(\"\\tUnless %s kthread gets sufficient CPU time, OOM is now expected behavior.\\n\", rcu_state.name);\n\t\t\tpr_err(\"RCU grace-period kthread stack dump:\\n\");\n\t\t\tsched_show_task(gpk);\n\t\t\tif (cpu >= 0) {\n\t\t\t\tif (cpu_is_offline(cpu)) {\n\t\t\t\t\tpr_err(\"RCU GP kthread last ran on offline CPU %d.\\n\", cpu);\n\t\t\t\t} else  {\n\t\t\t\t\tpr_err(\"Stack dump where RCU GP kthread last ran:\\n\");\n\t\t\t\t\tdump_cpu_task(cpu);\n\t\t\t\t}\n\t\t\t}\n\t\t\twake_up_process(gpk);\n\t\t}\n\t}\n}\n\n \nstatic void rcu_check_gp_kthread_expired_fqs_timer(void)\n{\n\tstruct task_struct *gpk = rcu_state.gp_kthread;\n\tshort gp_state;\n\tunsigned long jiffies_fqs;\n\tint cpu;\n\n\t \n\tgp_state = smp_load_acquire(&rcu_state.gp_state);\n\tjiffies_fqs = READ_ONCE(rcu_state.jiffies_force_qs);\n\n\tif (gp_state == RCU_GP_WAIT_FQS &&\n\t    time_after(jiffies, jiffies_fqs + RCU_STALL_MIGHT_MIN) &&\n\t    gpk && !READ_ONCE(gpk->on_rq)) {\n\t\tcpu = task_cpu(gpk);\n\t\tpr_err(\"%s kthread timer wakeup didn't happen for %ld jiffies! g%ld f%#x %s(%d) ->state=%#x\\n\",\n\t\t       rcu_state.name, (jiffies - jiffies_fqs),\n\t\t       (long)rcu_seq_current(&rcu_state.gp_seq),\n\t\t       data_race(rcu_state.gp_flags),\n\t\t       gp_state_getname(RCU_GP_WAIT_FQS), RCU_GP_WAIT_FQS,\n\t\t       data_race(READ_ONCE(gpk->__state)));\n\t\tpr_err(\"\\tPossible timer handling issue on cpu=%d timer-softirq=%u\\n\",\n\t\t       cpu, kstat_softirqs_cpu(TIMER_SOFTIRQ, cpu));\n\t}\n}\n\nstatic void print_other_cpu_stall(unsigned long gp_seq, unsigned long gps)\n{\n\tint cpu;\n\tunsigned long flags;\n\tunsigned long gpa;\n\tunsigned long j;\n\tint ndetected = 0;\n\tstruct rcu_node *rnp;\n\tlong totqlen = 0;\n\n\tlockdep_assert_irqs_disabled();\n\n\t \n\trcu_stall_kick_kthreads();\n\tif (rcu_stall_is_suppressed())\n\t\treturn;\n\n\t \n\ttrace_rcu_stall_warning(rcu_state.name, TPS(\"StallDetected\"));\n\tpr_err(\"INFO: %s detected stalls on CPUs/tasks:\\n\", rcu_state.name);\n\trcu_for_each_leaf_node(rnp) {\n\t\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\t\tif (rnp->qsmask != 0) {\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu)\n\t\t\t\tif (rnp->qsmask & leaf_node_cpu_bit(rnp, cpu)) {\n\t\t\t\t\tprint_cpu_stall_info(cpu);\n\t\t\t\t\tndetected++;\n\t\t\t\t}\n\t\t}\n\t\tndetected += rcu_print_task_stall(rnp, flags);  \n\t\tlockdep_assert_irqs_disabled();\n\t}\n\n\tfor_each_possible_cpu(cpu)\n\t\ttotqlen += rcu_get_n_cbs_cpu(cpu);\n\tpr_err(\"\\t(detected by %d, t=%ld jiffies, g=%ld, q=%lu ncpus=%d)\\n\",\n\t       smp_processor_id(), (long)(jiffies - gps),\n\t       (long)rcu_seq_current(&rcu_state.gp_seq), totqlen, rcu_state.n_online_cpus);\n\tif (ndetected) {\n\t\trcu_dump_cpu_stacks();\n\n\t\t \n\t\trcu_for_each_leaf_node(rnp)\n\t\t\trcu_print_detail_task_stall_rnp(rnp);\n\t} else {\n\t\tif (rcu_seq_current(&rcu_state.gp_seq) != gp_seq) {\n\t\t\tpr_err(\"INFO: Stall ended before state dump start\\n\");\n\t\t} else {\n\t\t\tj = jiffies;\n\t\t\tgpa = data_race(READ_ONCE(rcu_state.gp_activity));\n\t\t\tpr_err(\"All QSes seen, last %s kthread activity %ld (%ld-%ld), jiffies_till_next_fqs=%ld, root ->qsmask %#lx\\n\",\n\t\t\t       rcu_state.name, j - gpa, j, gpa,\n\t\t\t       data_race(READ_ONCE(jiffies_till_next_fqs)),\n\t\t\t       data_race(READ_ONCE(rcu_get_root()->qsmask)));\n\t\t}\n\t}\n\t \n\tif (ULONG_CMP_GE(jiffies, READ_ONCE(rcu_state.jiffies_stall)))\n\t\tWRITE_ONCE(rcu_state.jiffies_stall,\n\t\t\t   jiffies + 3 * rcu_jiffies_till_stall_check() + 3);\n\n\trcu_check_gp_kthread_expired_fqs_timer();\n\trcu_check_gp_kthread_starvation();\n\n\tpanic_on_rcu_stall();\n\n\trcu_force_quiescent_state();   \n}\n\nstatic void print_cpu_stall(unsigned long gps)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\tstruct rcu_node *rnp = rcu_get_root();\n\tlong totqlen = 0;\n\n\tlockdep_assert_irqs_disabled();\n\n\t \n\trcu_stall_kick_kthreads();\n\tif (rcu_stall_is_suppressed())\n\t\treturn;\n\n\t \n\ttrace_rcu_stall_warning(rcu_state.name, TPS(\"SelfDetected\"));\n\tpr_err(\"INFO: %s self-detected stall on CPU\\n\", rcu_state.name);\n\traw_spin_lock_irqsave_rcu_node(rdp->mynode, flags);\n\tprint_cpu_stall_info(smp_processor_id());\n\traw_spin_unlock_irqrestore_rcu_node(rdp->mynode, flags);\n\tfor_each_possible_cpu(cpu)\n\t\ttotqlen += rcu_get_n_cbs_cpu(cpu);\n\tpr_err(\"\\t(t=%lu jiffies g=%ld q=%lu ncpus=%d)\\n\",\n\t\tjiffies - gps,\n\t\t(long)rcu_seq_current(&rcu_state.gp_seq), totqlen, rcu_state.n_online_cpus);\n\n\trcu_check_gp_kthread_expired_fqs_timer();\n\trcu_check_gp_kthread_starvation();\n\n\trcu_dump_cpu_stacks();\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\t \n\tif (ULONG_CMP_GE(jiffies, READ_ONCE(rcu_state.jiffies_stall)))\n\t\tWRITE_ONCE(rcu_state.jiffies_stall,\n\t\t\t   jiffies + 3 * rcu_jiffies_till_stall_check() + 3);\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\n\tpanic_on_rcu_stall();\n\n\t \n\tset_tsk_need_resched(current);\n\tset_preempt_need_resched();\n}\n\nstatic void check_cpu_stall(struct rcu_data *rdp)\n{\n\tbool didstall = false;\n\tunsigned long gs1;\n\tunsigned long gs2;\n\tunsigned long gps;\n\tunsigned long j;\n\tunsigned long jn;\n\tunsigned long js;\n\tstruct rcu_node *rnp;\n\n\tlockdep_assert_irqs_disabled();\n\tif ((rcu_stall_is_suppressed() && !READ_ONCE(rcu_kick_kthreads)) ||\n\t    !rcu_gp_in_progress())\n\t\treturn;\n\trcu_stall_kick_kthreads();\n\n\t \n\tif (READ_ONCE(rcu_state.nr_fqs_jiffies_stall) > 0)\n\t\treturn;\n\n\tj = jiffies;\n\n\t \n\tgs1 = READ_ONCE(rcu_state.gp_seq);\n\tsmp_rmb();  \n\tjs = READ_ONCE(rcu_state.jiffies_stall);\n\tsmp_rmb();  \n\tgps = READ_ONCE(rcu_state.gp_start);\n\tsmp_rmb();  \n\tgs2 = READ_ONCE(rcu_state.gp_seq);\n\tif (gs1 != gs2 ||\n\t    ULONG_CMP_LT(j, js) ||\n\t    ULONG_CMP_GE(gps, js))\n\t\treturn;  \n\trnp = rdp->mynode;\n\tjn = jiffies + ULONG_MAX / 2;\n\tif (rcu_gp_in_progress() &&\n\t    (READ_ONCE(rnp->qsmask) & rdp->grpmask) &&\n\t    cmpxchg(&rcu_state.jiffies_stall, js, jn) == js) {\n\n\t\t \n\t\tif (kvm_check_and_clear_guest_paused())\n\t\t\treturn;\n\n\t\t \n\t\tprint_cpu_stall(gps);\n\t\tif (READ_ONCE(rcu_cpu_stall_ftrace_dump))\n\t\t\trcu_ftrace_dump(DUMP_ALL);\n\t\tdidstall = true;\n\n\t} else if (rcu_gp_in_progress() &&\n\t\t   ULONG_CMP_GE(j, js + RCU_STALL_RAT_DELAY) &&\n\t\t   cmpxchg(&rcu_state.jiffies_stall, js, jn) == js) {\n\n\t\t \n\t\tif (kvm_check_and_clear_guest_paused())\n\t\t\treturn;\n\n\t\t \n\t\tprint_other_cpu_stall(gs2, gps);\n\t\tif (READ_ONCE(rcu_cpu_stall_ftrace_dump))\n\t\t\trcu_ftrace_dump(DUMP_ALL);\n\t\tdidstall = true;\n\t}\n\tif (didstall && READ_ONCE(rcu_state.jiffies_stall) == jn) {\n\t\tjn = jiffies + 3 * rcu_jiffies_till_stall_check() + 3;\n\t\tWRITE_ONCE(rcu_state.jiffies_stall, jn);\n\t}\n}\n\n \n \n \n\n\n \nbool rcu_check_boost_fail(unsigned long gp_state, int *cpup)\n{\n\tbool atb = false;\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_node *rnp;\n\n\trcu_for_each_leaf_node(rnp) {\n\t\tif (!cpup) {\n\t\t\tif (data_race(READ_ONCE(rnp->qsmask))) {\n\t\t\t\treturn false;\n\t\t\t} else {\n\t\t\t\tif (READ_ONCE(rnp->gp_tasks))\n\t\t\t\t\tatb = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\t*cpup = -1;\n\t\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\t\tif (rnp->gp_tasks)\n\t\t\tatb = true;\n\t\tif (!rnp->qsmask) {\n\t\t\t \n\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\tif (rnp->qsmask & (1UL << (cpu - rnp->grplo))) {\n\t\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\t\t\t*cpup = cpu;\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t}\n\t \n\treturn atb;\n}\nEXPORT_SYMBOL_GPL(rcu_check_boost_fail);\n\n \nvoid show_rcu_gp_kthreads(void)\n{\n\tunsigned long cbs = 0;\n\tint cpu;\n\tunsigned long j;\n\tunsigned long ja;\n\tunsigned long jr;\n\tunsigned long js;\n\tunsigned long jw;\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp;\n\tstruct task_struct *t = READ_ONCE(rcu_state.gp_kthread);\n\n\tj = jiffies;\n\tja = j - data_race(READ_ONCE(rcu_state.gp_activity));\n\tjr = j - data_race(READ_ONCE(rcu_state.gp_req_activity));\n\tjs = j - data_race(READ_ONCE(rcu_state.gp_start));\n\tjw = j - data_race(READ_ONCE(rcu_state.gp_wake_time));\n\tpr_info(\"%s: wait state: %s(%d) ->state: %#x ->rt_priority %u delta ->gp_start %lu ->gp_activity %lu ->gp_req_activity %lu ->gp_wake_time %lu ->gp_wake_seq %ld ->gp_seq %ld ->gp_seq_needed %ld ->gp_max %lu ->gp_flags %#x\\n\",\n\t\trcu_state.name, gp_state_getname(rcu_state.gp_state),\n\t\tdata_race(READ_ONCE(rcu_state.gp_state)),\n\t\tt ? data_race(READ_ONCE(t->__state)) : 0x1ffff, t ? t->rt_priority : 0xffU,\n\t\tjs, ja, jr, jw, (long)data_race(READ_ONCE(rcu_state.gp_wake_seq)),\n\t\t(long)data_race(READ_ONCE(rcu_state.gp_seq)),\n\t\t(long)data_race(READ_ONCE(rcu_get_root()->gp_seq_needed)),\n\t\tdata_race(READ_ONCE(rcu_state.gp_max)),\n\t\tdata_race(READ_ONCE(rcu_state.gp_flags)));\n\trcu_for_each_node_breadth_first(rnp) {\n\t\tif (ULONG_CMP_GE(READ_ONCE(rcu_state.gp_seq), READ_ONCE(rnp->gp_seq_needed)) &&\n\t\t    !data_race(READ_ONCE(rnp->qsmask)) && !data_race(READ_ONCE(rnp->boost_tasks)) &&\n\t\t    !data_race(READ_ONCE(rnp->exp_tasks)) && !data_race(READ_ONCE(rnp->gp_tasks)))\n\t\t\tcontinue;\n\t\tpr_info(\"\\trcu_node %d:%d ->gp_seq %ld ->gp_seq_needed %ld ->qsmask %#lx %c%c%c%c ->n_boosts %ld\\n\",\n\t\t\trnp->grplo, rnp->grphi,\n\t\t\t(long)data_race(READ_ONCE(rnp->gp_seq)),\n\t\t\t(long)data_race(READ_ONCE(rnp->gp_seq_needed)),\n\t\t\tdata_race(READ_ONCE(rnp->qsmask)),\n\t\t\t\".b\"[!!data_race(READ_ONCE(rnp->boost_kthread_task))],\n\t\t\t\".B\"[!!data_race(READ_ONCE(rnp->boost_tasks))],\n\t\t\t\".E\"[!!data_race(READ_ONCE(rnp->exp_tasks))],\n\t\t\t\".G\"[!!data_race(READ_ONCE(rnp->gp_tasks))],\n\t\t\tdata_race(READ_ONCE(rnp->n_boosts)));\n\t\tif (!rcu_is_leaf_node(rnp))\n\t\t\tcontinue;\n\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\t\tif (READ_ONCE(rdp->gpwrap) ||\n\t\t\t    ULONG_CMP_GE(READ_ONCE(rcu_state.gp_seq),\n\t\t\t\t\t READ_ONCE(rdp->gp_seq_needed)))\n\t\t\t\tcontinue;\n\t\t\tpr_info(\"\\tcpu %d ->gp_seq_needed %ld\\n\",\n\t\t\t\tcpu, (long)data_race(READ_ONCE(rdp->gp_seq_needed)));\n\t\t}\n\t}\n\tfor_each_possible_cpu(cpu) {\n\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\tcbs += data_race(READ_ONCE(rdp->n_cbs_invoked));\n\t\tif (rcu_segcblist_is_offloaded(&rdp->cblist))\n\t\t\tshow_rcu_nocb_state(rdp);\n\t}\n\tpr_info(\"RCU callbacks invoked since boot: %lu\\n\", cbs);\n\tshow_rcu_tasks_gp_kthreads();\n}\nEXPORT_SYMBOL_GPL(show_rcu_gp_kthreads);\n\n \nstatic void rcu_check_gp_start_stall(struct rcu_node *rnp, struct rcu_data *rdp,\n\t\t\t\t     const unsigned long gpssdelay)\n{\n\tunsigned long flags;\n\tunsigned long j;\n\tstruct rcu_node *rnp_root = rcu_get_root();\n\tstatic atomic_t warned = ATOMIC_INIT(0);\n\n\tif (!IS_ENABLED(CONFIG_PROVE_RCU) || rcu_gp_in_progress() ||\n\t    ULONG_CMP_GE(READ_ONCE(rnp_root->gp_seq),\n\t\t\t READ_ONCE(rnp_root->gp_seq_needed)) ||\n\t    !smp_load_acquire(&rcu_state.gp_kthread))  \n\t\treturn;\n\tj = jiffies;  \n\tif (time_before(j, READ_ONCE(rcu_state.gp_req_activity) + gpssdelay) ||\n\t    time_before(j, READ_ONCE(rcu_state.gp_activity) + gpssdelay) ||\n\t    atomic_read(&warned))\n\t\treturn;\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\tj = jiffies;\n\tif (rcu_gp_in_progress() ||\n\t    ULONG_CMP_GE(READ_ONCE(rnp_root->gp_seq),\n\t\t\t READ_ONCE(rnp_root->gp_seq_needed)) ||\n\t    time_before(j, READ_ONCE(rcu_state.gp_req_activity) + gpssdelay) ||\n\t    time_before(j, READ_ONCE(rcu_state.gp_activity) + gpssdelay) ||\n\t    atomic_read(&warned)) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;\n\t}\n\t \n\n\tif (rnp_root != rnp)\n\t\traw_spin_lock_rcu_node(rnp_root);  \n\tj = jiffies;\n\tif (rcu_gp_in_progress() ||\n\t    ULONG_CMP_GE(READ_ONCE(rnp_root->gp_seq),\n\t\t\t READ_ONCE(rnp_root->gp_seq_needed)) ||\n\t    time_before(j, READ_ONCE(rcu_state.gp_req_activity) + gpssdelay) ||\n\t    time_before(j, READ_ONCE(rcu_state.gp_activity) + gpssdelay) ||\n\t    atomic_xchg(&warned, 1)) {\n\t\tif (rnp_root != rnp)\n\t\t\t \n\t\t\traw_spin_unlock_rcu_node(rnp_root);\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;\n\t}\n\tWARN_ON(1);\n\tif (rnp_root != rnp)\n\t\traw_spin_unlock_rcu_node(rnp_root);\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\tshow_rcu_gp_kthreads();\n}\n\n \nvoid rcu_fwd_progress_check(unsigned long j)\n{\n\tunsigned long cbs;\n\tint cpu;\n\tunsigned long max_cbs = 0;\n\tint max_cpu = -1;\n\tstruct rcu_data *rdp;\n\n\tif (rcu_gp_in_progress()) {\n\t\tpr_info(\"%s: GP age %lu jiffies\\n\",\n\t\t\t__func__, jiffies - data_race(READ_ONCE(rcu_state.gp_start)));\n\t\tshow_rcu_gp_kthreads();\n\t} else {\n\t\tpr_info(\"%s: Last GP end %lu jiffies ago\\n\",\n\t\t\t__func__, jiffies - data_race(READ_ONCE(rcu_state.gp_end)));\n\t\tpreempt_disable();\n\t\trdp = this_cpu_ptr(&rcu_data);\n\t\trcu_check_gp_start_stall(rdp->mynode, rdp, j);\n\t\tpreempt_enable();\n\t}\n\tfor_each_possible_cpu(cpu) {\n\t\tcbs = rcu_get_n_cbs_cpu(cpu);\n\t\tif (!cbs)\n\t\t\tcontinue;\n\t\tif (max_cpu < 0)\n\t\t\tpr_info(\"%s: callbacks\", __func__);\n\t\tpr_cont(\" %d: %lu\", cpu, cbs);\n\t\tif (cbs <= max_cbs)\n\t\t\tcontinue;\n\t\tmax_cbs = cbs;\n\t\tmax_cpu = cpu;\n\t}\n\tif (max_cpu >= 0)\n\t\tpr_cont(\"\\n\");\n}\nEXPORT_SYMBOL_GPL(rcu_fwd_progress_check);\n\n \nstatic bool sysrq_rcu;\nmodule_param(sysrq_rcu, bool, 0444);\n\n \nstatic void sysrq_show_rcu(u8 key)\n{\n\tshow_rcu_gp_kthreads();\n}\n\nstatic const struct sysrq_key_op sysrq_rcudump_op = {\n\t.handler = sysrq_show_rcu,\n\t.help_msg = \"show-rcu(y)\",\n\t.action_msg = \"Show RCU tree\",\n\t.enable_mask = SYSRQ_ENABLE_DUMP,\n};\n\nstatic int __init rcu_sysrq_init(void)\n{\n\tif (sysrq_rcu)\n\t\treturn register_sysrq_key('y', &sysrq_rcudump_op);\n\treturn 0;\n}\nearly_initcall(rcu_sysrq_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}