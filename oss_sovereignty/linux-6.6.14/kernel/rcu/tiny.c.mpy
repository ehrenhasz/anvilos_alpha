{
  "module_name": "tiny.c",
  "hash_id": "51fb1523be4169730edad529c7ba297d30a4892d8eec60049c06a7a830d7e96a",
  "original_prompt": "Ingested from linux-6.6.14/kernel/rcu/tiny.c",
  "human_readable_source": "\n \n#include <linux/completion.h>\n#include <linux/interrupt.h>\n#include <linux/notifier.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/sched.h>\n#include <linux/types.h>\n#include <linux/init.h>\n#include <linux/time.h>\n#include <linux/cpu.h>\n#include <linux/prefetch.h>\n#include <linux/slab.h>\n#include <linux/mm.h>\n\n#include \"rcu.h\"\n\n \nstruct rcu_ctrlblk {\n\tstruct rcu_head *rcucblist;\t \n\tstruct rcu_head **donetail;\t \n\tstruct rcu_head **curtail;\t \n\tunsigned long gp_seq;\t\t \n};\n\n \nstatic struct rcu_ctrlblk rcu_ctrlblk = {\n\t.donetail\t= &rcu_ctrlblk.rcucblist,\n\t.curtail\t= &rcu_ctrlblk.rcucblist,\n\t.gp_seq\t\t= 0 - 300UL,\n};\n\nvoid rcu_barrier(void)\n{\n\twait_rcu_gp(call_rcu_hurry);\n}\nEXPORT_SYMBOL(rcu_barrier);\n\n \nvoid rcu_qs(void)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tif (rcu_ctrlblk.donetail != rcu_ctrlblk.curtail) {\n\t\trcu_ctrlblk.donetail = rcu_ctrlblk.curtail;\n\t\traise_softirq_irqoff(RCU_SOFTIRQ);\n\t}\n\tWRITE_ONCE(rcu_ctrlblk.gp_seq, rcu_ctrlblk.gp_seq + 2);\n\tlocal_irq_restore(flags);\n}\n\n \nvoid rcu_sched_clock_irq(int user)\n{\n\tif (user) {\n\t\trcu_qs();\n\t} else if (rcu_ctrlblk.donetail != rcu_ctrlblk.curtail) {\n\t\tset_tsk_need_resched(current);\n\t\tset_preempt_need_resched();\n\t}\n}\n\n \nstatic inline bool rcu_reclaim_tiny(struct rcu_head *head)\n{\n\trcu_callback_t f;\n\tunsigned long offset = (unsigned long)head->func;\n\n\trcu_lock_acquire(&rcu_callback_map);\n\tif (__is_kvfree_rcu_offset(offset)) {\n\t\ttrace_rcu_invoke_kvfree_callback(\"\", head, offset);\n\t\tkvfree((void *)head - offset);\n\t\trcu_lock_release(&rcu_callback_map);\n\t\treturn true;\n\t}\n\n\ttrace_rcu_invoke_callback(\"\", head);\n\tf = head->func;\n\tWRITE_ONCE(head->func, (rcu_callback_t)0L);\n\tf(head);\n\trcu_lock_release(&rcu_callback_map);\n\treturn false;\n}\n\n \nstatic __latent_entropy void rcu_process_callbacks(struct softirq_action *unused)\n{\n\tstruct rcu_head *next, *list;\n\tunsigned long flags;\n\n\t \n\tlocal_irq_save(flags);\n\tif (rcu_ctrlblk.donetail == &rcu_ctrlblk.rcucblist) {\n\t\t \n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\tlist = rcu_ctrlblk.rcucblist;\n\trcu_ctrlblk.rcucblist = *rcu_ctrlblk.donetail;\n\t*rcu_ctrlblk.donetail = NULL;\n\tif (rcu_ctrlblk.curtail == rcu_ctrlblk.donetail)\n\t\trcu_ctrlblk.curtail = &rcu_ctrlblk.rcucblist;\n\trcu_ctrlblk.donetail = &rcu_ctrlblk.rcucblist;\n\tlocal_irq_restore(flags);\n\n\t \n\twhile (list) {\n\t\tnext = list->next;\n\t\tprefetch(next);\n\t\tdebug_rcu_head_unqueue(list);\n\t\tlocal_bh_disable();\n\t\trcu_reclaim_tiny(list);\n\t\tlocal_bh_enable();\n\t\tlist = next;\n\t}\n}\n\n \nvoid synchronize_rcu(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||\n\t\t\t lock_is_held(&rcu_lock_map) ||\n\t\t\t lock_is_held(&rcu_sched_lock_map),\n\t\t\t \"Illegal synchronize_rcu() in RCU read-side critical section\");\n\tWRITE_ONCE(rcu_ctrlblk.gp_seq, rcu_ctrlblk.gp_seq + 2);\n}\nEXPORT_SYMBOL_GPL(synchronize_rcu);\n\nstatic void tiny_rcu_leak_callback(struct rcu_head *rhp)\n{\n}\n\n \nvoid call_rcu(struct rcu_head *head, rcu_callback_t func)\n{\n\tstatic atomic_t doublefrees;\n\tunsigned long flags;\n\n\tif (debug_rcu_head_queue(head)) {\n\t\tif (atomic_inc_return(&doublefrees) < 4) {\n\t\t\tpr_err(\"%s(): Double-freed CB %p->%pS()!!!  \", __func__, head, head->func);\n\t\t\tmem_dump_obj(head);\n\t\t}\n\n\t\tif (!__is_kvfree_rcu_offset((unsigned long)head->func))\n\t\t\tWRITE_ONCE(head->func, tiny_rcu_leak_callback);\n\t\treturn;\n\t}\n\n\thead->func = func;\n\thead->next = NULL;\n\n\tlocal_irq_save(flags);\n\t*rcu_ctrlblk.curtail = head;\n\trcu_ctrlblk.curtail = &head->next;\n\tlocal_irq_restore(flags);\n\n\tif (unlikely(is_idle_task(current))) {\n\t\t \n\t\tresched_cpu(0);\n\t}\n}\nEXPORT_SYMBOL_GPL(call_rcu);\n\n \nvoid get_completed_synchronize_rcu_full(struct rcu_gp_oldstate *rgosp)\n{\n\trgosp->rgos_norm = RCU_GET_STATE_COMPLETED;\n}\nEXPORT_SYMBOL_GPL(get_completed_synchronize_rcu_full);\n\n \nunsigned long get_state_synchronize_rcu(void)\n{\n\treturn READ_ONCE(rcu_ctrlblk.gp_seq);\n}\nEXPORT_SYMBOL_GPL(get_state_synchronize_rcu);\n\n \nunsigned long start_poll_synchronize_rcu(void)\n{\n\tunsigned long gp_seq = get_state_synchronize_rcu();\n\n\tif (unlikely(is_idle_task(current))) {\n\t\t \n\t\tresched_cpu(0);\n\t}\n\treturn gp_seq;\n}\nEXPORT_SYMBOL_GPL(start_poll_synchronize_rcu);\n\n \nbool poll_state_synchronize_rcu(unsigned long oldstate)\n{\n\treturn oldstate == RCU_GET_STATE_COMPLETED || READ_ONCE(rcu_ctrlblk.gp_seq) != oldstate;\n}\nEXPORT_SYMBOL_GPL(poll_state_synchronize_rcu);\n\n#ifdef CONFIG_KASAN_GENERIC\nvoid kvfree_call_rcu(struct rcu_head *head, void *ptr)\n{\n\tif (head)\n\t\tkasan_record_aux_stack_noalloc(ptr);\n\n\t__kvfree_call_rcu(head, ptr);\n}\nEXPORT_SYMBOL_GPL(kvfree_call_rcu);\n#endif\n\nvoid __init rcu_init(void)\n{\n\topen_softirq(RCU_SOFTIRQ, rcu_process_callbacks);\n\trcu_early_boot_tests();\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}