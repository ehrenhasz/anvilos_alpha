{
  "module_name": "rcutorture.c",
  "hash_id": "110d0f492552d388ccea6bcb489daa32d978444aafbe6cce97f4508bf7545630",
  "original_prompt": "Ingested from linux-6.6.14/kernel/rcu/rcutorture.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) fmt\n\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\n#include <linux/err.h>\n#include <linux/spinlock.h>\n#include <linux/smp.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/interrupt.h>\n#include <linux/sched/signal.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/atomic.h>\n#include <linux/bitops.h>\n#include <linux/completion.h>\n#include <linux/moduleparam.h>\n#include <linux/percpu.h>\n#include <linux/notifier.h>\n#include <linux/reboot.h>\n#include <linux/freezer.h>\n#include <linux/cpu.h>\n#include <linux/delay.h>\n#include <linux/stat.h>\n#include <linux/srcu.h>\n#include <linux/slab.h>\n#include <linux/trace_clock.h>\n#include <asm/byteorder.h>\n#include <linux/torture.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/sysctl.h>\n#include <linux/oom.h>\n#include <linux/tick.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/nmi.h>\n\n#include \"rcu.h\"\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Paul E. McKenney <paulmck@linux.ibm.com> and Josh Triplett <josh@joshtriplett.org>\");\n\n \n#define RCUTORTURE_RDR_SHIFT_1\t 8\t \n#define RCUTORTURE_RDR_MASK_1\t (1 << RCUTORTURE_RDR_SHIFT_1)\n#define RCUTORTURE_RDR_SHIFT_2\t 9\t \n#define RCUTORTURE_RDR_MASK_2\t (1 << RCUTORTURE_RDR_SHIFT_2)\n#define RCUTORTURE_RDR_BH\t 0x01\t \n#define RCUTORTURE_RDR_IRQ\t 0x02\t \n#define RCUTORTURE_RDR_PREEMPT\t 0x04\t \n#define RCUTORTURE_RDR_RBH\t 0x08\t \n#define RCUTORTURE_RDR_SCHED\t 0x10\t \n#define RCUTORTURE_RDR_RCU_1\t 0x20\t \n#define RCUTORTURE_RDR_RCU_2\t 0x40\t \n#define RCUTORTURE_RDR_NBITS\t 7\t \n#define RCUTORTURE_MAX_EXTEND\t \\\n\t(RCUTORTURE_RDR_BH | RCUTORTURE_RDR_IRQ | RCUTORTURE_RDR_PREEMPT | \\\n\t RCUTORTURE_RDR_RBH | RCUTORTURE_RDR_SCHED)\n#define RCUTORTURE_RDR_MAX_LOOPS 0x7\t \n\t\t\t\t\t \n#define RCUTORTURE_RDR_MAX_SEGS (RCUTORTURE_RDR_MAX_LOOPS + 3)\n\ntorture_param(int, extendables, RCUTORTURE_MAX_EXTEND,\n\t      \"Extend readers by disabling bh (1), irqs (2), or preempt (4)\");\ntorture_param(int, fqs_duration, 0, \"Duration of fqs bursts (us), 0 to disable\");\ntorture_param(int, fqs_holdoff, 0, \"Holdoff time within fqs bursts (us)\");\ntorture_param(int, fqs_stutter, 3, \"Wait time between fqs bursts (s)\");\ntorture_param(int, fwd_progress, 1, \"Number of grace-period forward progress tasks (0 to disable)\");\ntorture_param(int, fwd_progress_div, 4, \"Fraction of CPU stall to wait\");\ntorture_param(int, fwd_progress_holdoff, 60, \"Time between forward-progress tests (s)\");\ntorture_param(bool, fwd_progress_need_resched, 1, \"Hide cond_resched() behind need_resched()\");\ntorture_param(bool, gp_cond, false, \"Use conditional/async GP wait primitives\");\ntorture_param(bool, gp_cond_exp, false, \"Use conditional/async expedited GP wait primitives\");\ntorture_param(bool, gp_cond_full, false, \"Use conditional/async full-state GP wait primitives\");\ntorture_param(bool, gp_cond_exp_full, false,\n\t\t    \"Use conditional/async full-stateexpedited GP wait primitives\");\ntorture_param(bool, gp_exp, false, \"Use expedited GP wait primitives\");\ntorture_param(bool, gp_normal, false, \"Use normal (non-expedited) GP wait primitives\");\ntorture_param(bool, gp_poll, false, \"Use polling GP wait primitives\");\ntorture_param(bool, gp_poll_exp, false, \"Use polling expedited GP wait primitives\");\ntorture_param(bool, gp_poll_full, false, \"Use polling full-state GP wait primitives\");\ntorture_param(bool, gp_poll_exp_full, false, \"Use polling full-state expedited GP wait primitives\");\ntorture_param(bool, gp_sync, false, \"Use synchronous GP wait primitives\");\ntorture_param(int, irqreader, 1, \"Allow RCU readers from irq handlers\");\ntorture_param(int, leakpointer, 0, \"Leak pointer dereferences from readers\");\ntorture_param(int, n_barrier_cbs, 0, \"# of callbacks/kthreads for barrier testing\");\ntorture_param(int, nfakewriters, 4, \"Number of RCU fake writer threads\");\ntorture_param(int, nreaders, -1, \"Number of RCU reader threads\");\ntorture_param(int, object_debug, 0, \"Enable debug-object double call_rcu() testing\");\ntorture_param(int, onoff_holdoff, 0, \"Time after boot before CPU hotplugs (s)\");\ntorture_param(int, onoff_interval, 0, \"Time between CPU hotplugs (jiffies), 0=disable\");\ntorture_param(int, nocbs_nthreads, 0, \"Number of NOCB toggle threads, 0 to disable\");\ntorture_param(int, nocbs_toggle, 1000, \"Time between toggling nocb state (ms)\");\ntorture_param(int, read_exit_delay, 13, \"Delay between read-then-exit episodes (s)\");\ntorture_param(int, read_exit_burst, 16, \"# of read-then-exit bursts per episode, zero to disable\");\ntorture_param(int, shuffle_interval, 3, \"Number of seconds between shuffles\");\ntorture_param(int, shutdown_secs, 0, \"Shutdown time (s), <= zero to disable.\");\ntorture_param(int, stall_cpu, 0, \"Stall duration (s), zero to disable.\");\ntorture_param(int, stall_cpu_holdoff, 10, \"Time to wait before starting stall (s).\");\ntorture_param(bool, stall_no_softlockup, false, \"Avoid softlockup warning during cpu stall.\");\ntorture_param(int, stall_cpu_irqsoff, 0, \"Disable interrupts while stalling.\");\ntorture_param(int, stall_cpu_block, 0, \"Sleep while stalling.\");\ntorture_param(int, stall_gp_kthread, 0, \"Grace-period kthread stall duration (s).\");\ntorture_param(int, stat_interval, 60, \"Number of seconds between stats printk()s\");\ntorture_param(int, stutter, 5, \"Number of seconds to run/halt test\");\ntorture_param(int, test_boost, 1, \"Test RCU prio boost: 0=no, 1=maybe, 2=yes.\");\ntorture_param(int, test_boost_duration, 4, \"Duration of each boost test, seconds.\");\ntorture_param(int, test_boost_interval, 7, \"Interval between boost tests, seconds.\");\ntorture_param(int, test_nmis, 0, \"End-test NMI tests, 0 to disable.\");\ntorture_param(bool, test_no_idle_hz, true, \"Test support for tickless idle CPUs\");\ntorture_param(int, test_srcu_lockdep, 0, \"Test specified SRCU deadlock scenario.\");\ntorture_param(int, verbose, 1, \"Enable verbose debugging printk()s\");\n\nstatic char *torture_type = \"rcu\";\nmodule_param(torture_type, charp, 0444);\nMODULE_PARM_DESC(torture_type, \"Type of RCU to torture (rcu, srcu, ...)\");\n\nstatic int nrealnocbers;\nstatic int nrealreaders;\nstatic struct task_struct *writer_task;\nstatic struct task_struct **fakewriter_tasks;\nstatic struct task_struct **reader_tasks;\nstatic struct task_struct **nocb_tasks;\nstatic struct task_struct *stats_task;\nstatic struct task_struct *fqs_task;\nstatic struct task_struct *boost_tasks[NR_CPUS];\nstatic struct task_struct *stall_task;\nstatic struct task_struct **fwd_prog_tasks;\nstatic struct task_struct **barrier_cbs_tasks;\nstatic struct task_struct *barrier_task;\nstatic struct task_struct *read_exit_task;\n\n#define RCU_TORTURE_PIPE_LEN 10\n\n\nstruct rcu_torture_reader_check {\n\tunsigned long rtc_myloops;\n\tint rtc_chkrdr;\n\tunsigned long rtc_chkloops;\n\tint rtc_ready;\n\tstruct rcu_torture_reader_check *rtc_assigner;\n} ____cacheline_internodealigned_in_smp;\n\n\nstruct rcu_torture {\n\tstruct rcu_head rtort_rcu;\n\tint rtort_pipe_count;\n\tstruct list_head rtort_free;\n\tint rtort_mbtest;\n\tstruct rcu_torture_reader_check *rtort_chkp;\n};\n\nstatic LIST_HEAD(rcu_torture_freelist);\nstatic struct rcu_torture __rcu *rcu_torture_current;\nstatic unsigned long rcu_torture_current_version;\nstatic struct rcu_torture rcu_tortures[10 * RCU_TORTURE_PIPE_LEN];\nstatic DEFINE_SPINLOCK(rcu_torture_lock);\nstatic DEFINE_PER_CPU(long [RCU_TORTURE_PIPE_LEN + 1], rcu_torture_count);\nstatic DEFINE_PER_CPU(long [RCU_TORTURE_PIPE_LEN + 1], rcu_torture_batch);\nstatic atomic_t rcu_torture_wcount[RCU_TORTURE_PIPE_LEN + 1];\nstatic struct rcu_torture_reader_check *rcu_torture_reader_mbchk;\nstatic atomic_t n_rcu_torture_alloc;\nstatic atomic_t n_rcu_torture_alloc_fail;\nstatic atomic_t n_rcu_torture_free;\nstatic atomic_t n_rcu_torture_mberror;\nstatic atomic_t n_rcu_torture_mbchk_fail;\nstatic atomic_t n_rcu_torture_mbchk_tries;\nstatic atomic_t n_rcu_torture_error;\nstatic long n_rcu_torture_barrier_error;\nstatic long n_rcu_torture_boost_ktrerror;\nstatic long n_rcu_torture_boost_failure;\nstatic long n_rcu_torture_boosts;\nstatic atomic_long_t n_rcu_torture_timers;\nstatic long n_barrier_attempts;\nstatic long n_barrier_successes;  \nstatic unsigned long n_read_exits;\nstatic struct list_head rcu_torture_removed;\nstatic unsigned long shutdown_jiffies;\nstatic unsigned long start_gp_seq;\nstatic atomic_long_t n_nocb_offload;\nstatic atomic_long_t n_nocb_deoffload;\n\nstatic int rcu_torture_writer_state;\n#define RTWS_FIXED_DELAY\t0\n#define RTWS_DELAY\t\t1\n#define RTWS_REPLACE\t\t2\n#define RTWS_DEF_FREE\t\t3\n#define RTWS_EXP_SYNC\t\t4\n#define RTWS_COND_GET\t\t5\n#define RTWS_COND_GET_FULL\t6\n#define RTWS_COND_GET_EXP\t7\n#define RTWS_COND_GET_EXP_FULL\t8\n#define RTWS_COND_SYNC\t\t9\n#define RTWS_COND_SYNC_FULL\t10\n#define RTWS_COND_SYNC_EXP\t11\n#define RTWS_COND_SYNC_EXP_FULL\t12\n#define RTWS_POLL_GET\t\t13\n#define RTWS_POLL_GET_FULL\t14\n#define RTWS_POLL_GET_EXP\t15\n#define RTWS_POLL_GET_EXP_FULL\t16\n#define RTWS_POLL_WAIT\t\t17\n#define RTWS_POLL_WAIT_FULL\t18\n#define RTWS_POLL_WAIT_EXP\t19\n#define RTWS_POLL_WAIT_EXP_FULL\t20\n#define RTWS_SYNC\t\t21\n#define RTWS_STUTTER\t\t22\n#define RTWS_STOPPING\t\t23\nstatic const char * const rcu_torture_writer_state_names[] = {\n\t\"RTWS_FIXED_DELAY\",\n\t\"RTWS_DELAY\",\n\t\"RTWS_REPLACE\",\n\t\"RTWS_DEF_FREE\",\n\t\"RTWS_EXP_SYNC\",\n\t\"RTWS_COND_GET\",\n\t\"RTWS_COND_GET_FULL\",\n\t\"RTWS_COND_GET_EXP\",\n\t\"RTWS_COND_GET_EXP_FULL\",\n\t\"RTWS_COND_SYNC\",\n\t\"RTWS_COND_SYNC_FULL\",\n\t\"RTWS_COND_SYNC_EXP\",\n\t\"RTWS_COND_SYNC_EXP_FULL\",\n\t\"RTWS_POLL_GET\",\n\t\"RTWS_POLL_GET_FULL\",\n\t\"RTWS_POLL_GET_EXP\",\n\t\"RTWS_POLL_GET_EXP_FULL\",\n\t\"RTWS_POLL_WAIT\",\n\t\"RTWS_POLL_WAIT_FULL\",\n\t\"RTWS_POLL_WAIT_EXP\",\n\t\"RTWS_POLL_WAIT_EXP_FULL\",\n\t\"RTWS_SYNC\",\n\t\"RTWS_STUTTER\",\n\t\"RTWS_STOPPING\",\n};\n\n \nstruct rt_read_seg {\n\tint rt_readstate;\n\tunsigned long rt_delay_jiffies;\n\tunsigned long rt_delay_ms;\n\tunsigned long rt_delay_us;\n\tbool rt_preempted;\n};\nstatic int err_segs_recorded;\nstatic struct rt_read_seg err_segs[RCUTORTURE_RDR_MAX_SEGS];\nstatic int rt_read_nsegs;\n\nstatic const char *rcu_torture_writer_state_getname(void)\n{\n\tunsigned int i = READ_ONCE(rcu_torture_writer_state);\n\n\tif (i >= ARRAY_SIZE(rcu_torture_writer_state_names))\n\t\treturn \"???\";\n\treturn rcu_torture_writer_state_names[i];\n}\n\n#ifdef CONFIG_RCU_TRACE\nstatic u64 notrace rcu_trace_clock_local(void)\n{\n\tu64 ts = trace_clock_local();\n\n\t(void)do_div(ts, NSEC_PER_USEC);\n\treturn ts;\n}\n#else  \nstatic u64 notrace rcu_trace_clock_local(void)\n{\n\treturn 0ULL;\n}\n#endif  \n\n \nstatic bool shutdown_time_arrived(void)\n{\n\treturn shutdown_secs && time_after(jiffies, shutdown_jiffies - 30 * HZ);\n}\n\nstatic unsigned long boost_starttime;\t \nstatic DEFINE_MUTEX(boost_mutex);\t \n\t\t\t\t\t \nstatic atomic_t barrier_cbs_count;\t \nstatic bool barrier_phase;\t\t \nstatic atomic_t barrier_cbs_invoked;\t \nstatic wait_queue_head_t *barrier_cbs_wq;  \nstatic DECLARE_WAIT_QUEUE_HEAD(barrier_wq);\n\nstatic atomic_t rcu_fwd_cb_nodelay;\t \n\n \nstatic struct rcu_torture *\nrcu_torture_alloc(void)\n{\n\tstruct list_head *p;\n\n\tspin_lock_bh(&rcu_torture_lock);\n\tif (list_empty(&rcu_torture_freelist)) {\n\t\tatomic_inc(&n_rcu_torture_alloc_fail);\n\t\tspin_unlock_bh(&rcu_torture_lock);\n\t\treturn NULL;\n\t}\n\tatomic_inc(&n_rcu_torture_alloc);\n\tp = rcu_torture_freelist.next;\n\tlist_del_init(p);\n\tspin_unlock_bh(&rcu_torture_lock);\n\treturn container_of(p, struct rcu_torture, rtort_free);\n}\n\n \nstatic void\nrcu_torture_free(struct rcu_torture *p)\n{\n\tatomic_inc(&n_rcu_torture_free);\n\tspin_lock_bh(&rcu_torture_lock);\n\tlist_add_tail(&p->rtort_free, &rcu_torture_freelist);\n\tspin_unlock_bh(&rcu_torture_lock);\n}\n\n \n\nstruct rcu_torture_ops {\n\tint ttype;\n\tvoid (*init)(void);\n\tvoid (*cleanup)(void);\n\tint (*readlock)(void);\n\tvoid (*read_delay)(struct torture_random_state *rrsp,\n\t\t\t   struct rt_read_seg *rtrsp);\n\tvoid (*readunlock)(int idx);\n\tint (*readlock_held)(void);\n\tunsigned long (*get_gp_seq)(void);\n\tunsigned long (*gp_diff)(unsigned long new, unsigned long old);\n\tvoid (*deferred_free)(struct rcu_torture *p);\n\tvoid (*sync)(void);\n\tvoid (*exp_sync)(void);\n\tunsigned long (*get_gp_state_exp)(void);\n\tunsigned long (*start_gp_poll_exp)(void);\n\tvoid (*start_gp_poll_exp_full)(struct rcu_gp_oldstate *rgosp);\n\tbool (*poll_gp_state_exp)(unsigned long oldstate);\n\tvoid (*cond_sync_exp)(unsigned long oldstate);\n\tvoid (*cond_sync_exp_full)(struct rcu_gp_oldstate *rgosp);\n\tunsigned long (*get_comp_state)(void);\n\tvoid (*get_comp_state_full)(struct rcu_gp_oldstate *rgosp);\n\tbool (*same_gp_state)(unsigned long oldstate1, unsigned long oldstate2);\n\tbool (*same_gp_state_full)(struct rcu_gp_oldstate *rgosp1, struct rcu_gp_oldstate *rgosp2);\n\tunsigned long (*get_gp_state)(void);\n\tvoid (*get_gp_state_full)(struct rcu_gp_oldstate *rgosp);\n\tunsigned long (*get_gp_completed)(void);\n\tvoid (*get_gp_completed_full)(struct rcu_gp_oldstate *rgosp);\n\tunsigned long (*start_gp_poll)(void);\n\tvoid (*start_gp_poll_full)(struct rcu_gp_oldstate *rgosp);\n\tbool (*poll_gp_state)(unsigned long oldstate);\n\tbool (*poll_gp_state_full)(struct rcu_gp_oldstate *rgosp);\n\tbool (*poll_need_2gp)(bool poll, bool poll_full);\n\tvoid (*cond_sync)(unsigned long oldstate);\n\tvoid (*cond_sync_full)(struct rcu_gp_oldstate *rgosp);\n\tcall_rcu_func_t call;\n\tvoid (*cb_barrier)(void);\n\tvoid (*fqs)(void);\n\tvoid (*stats)(void);\n\tvoid (*gp_kthread_dbg)(void);\n\tbool (*check_boost_failed)(unsigned long gp_state, int *cpup);\n\tint (*stall_dur)(void);\n\tlong cbflood_max;\n\tint irq_capable;\n\tint can_boost;\n\tint extendables;\n\tint slow_gps;\n\tint no_pi_lock;\n\tconst char *name;\n};\n\nstatic struct rcu_torture_ops *cur_ops;\n\n \n\nstatic int torture_readlock_not_held(void)\n{\n\treturn rcu_read_lock_bh_held() || rcu_read_lock_sched_held();\n}\n\nstatic int rcu_torture_read_lock(void)\n{\n\trcu_read_lock();\n\treturn 0;\n}\n\nstatic void\nrcu_read_delay(struct torture_random_state *rrsp, struct rt_read_seg *rtrsp)\n{\n\tunsigned long started;\n\tunsigned long completed;\n\tconst unsigned long shortdelay_us = 200;\n\tunsigned long longdelay_ms = 300;\n\tunsigned long long ts;\n\n\t \n\n\tif (!atomic_read(&rcu_fwd_cb_nodelay) &&\n\t    !(torture_random(rrsp) % (nrealreaders * 2000 * longdelay_ms))) {\n\t\tstarted = cur_ops->get_gp_seq();\n\t\tts = rcu_trace_clock_local();\n\t\tif (preempt_count() & (SOFTIRQ_MASK | HARDIRQ_MASK))\n\t\t\tlongdelay_ms = 5;  \n\t\tmdelay(longdelay_ms);\n\t\trtrsp->rt_delay_ms = longdelay_ms;\n\t\tcompleted = cur_ops->get_gp_seq();\n\t\tdo_trace_rcu_torture_read(cur_ops->name, NULL, ts,\n\t\t\t\t\t  started, completed);\n\t}\n\tif (!(torture_random(rrsp) % (nrealreaders * 2 * shortdelay_us))) {\n\t\tudelay(shortdelay_us);\n\t\trtrsp->rt_delay_us = shortdelay_us;\n\t}\n\tif (!preempt_count() &&\n\t    !(torture_random(rrsp) % (nrealreaders * 500))) {\n\t\ttorture_preempt_schedule();   \n\t\trtrsp->rt_preempted = true;\n\t}\n}\n\nstatic void rcu_torture_read_unlock(int idx)\n{\n\trcu_read_unlock();\n}\n\n \nstatic bool\nrcu_torture_pipe_update_one(struct rcu_torture *rp)\n{\n\tint i;\n\tstruct rcu_torture_reader_check *rtrcp = READ_ONCE(rp->rtort_chkp);\n\n\tif (rtrcp) {\n\t\tWRITE_ONCE(rp->rtort_chkp, NULL);\n\t\tsmp_store_release(&rtrcp->rtc_ready, 1); \n\t}\n\ti = READ_ONCE(rp->rtort_pipe_count);\n\tif (i > RCU_TORTURE_PIPE_LEN)\n\t\ti = RCU_TORTURE_PIPE_LEN;\n\tatomic_inc(&rcu_torture_wcount[i]);\n\tWRITE_ONCE(rp->rtort_pipe_count, i + 1);\n\tif (rp->rtort_pipe_count >= RCU_TORTURE_PIPE_LEN) {\n\t\trp->rtort_mbtest = 0;\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nstatic void\nrcu_torture_pipe_update(struct rcu_torture *old_rp)\n{\n\tstruct rcu_torture *rp;\n\tstruct rcu_torture *rp1;\n\n\tif (old_rp)\n\t\tlist_add(&old_rp->rtort_free, &rcu_torture_removed);\n\tlist_for_each_entry_safe(rp, rp1, &rcu_torture_removed, rtort_free) {\n\t\tif (rcu_torture_pipe_update_one(rp)) {\n\t\t\tlist_del(&rp->rtort_free);\n\t\t\trcu_torture_free(rp);\n\t\t}\n\t}\n}\n\nstatic void\nrcu_torture_cb(struct rcu_head *p)\n{\n\tstruct rcu_torture *rp = container_of(p, struct rcu_torture, rtort_rcu);\n\n\tif (torture_must_stop_irq()) {\n\t\t \n\t\t \n\t\treturn;\n\t}\n\tif (rcu_torture_pipe_update_one(rp))\n\t\trcu_torture_free(rp);\n\telse\n\t\tcur_ops->deferred_free(rp);\n}\n\nstatic unsigned long rcu_no_completed(void)\n{\n\treturn 0;\n}\n\nstatic void rcu_torture_deferred_free(struct rcu_torture *p)\n{\n\tcall_rcu_hurry(&p->rtort_rcu, rcu_torture_cb);\n}\n\nstatic void rcu_sync_torture_init(void)\n{\n\tINIT_LIST_HEAD(&rcu_torture_removed);\n}\n\nstatic bool rcu_poll_need_2gp(bool poll, bool poll_full)\n{\n\treturn poll;\n}\n\nstatic struct rcu_torture_ops rcu_ops = {\n\t.ttype\t\t\t= RCU_FLAVOR,\n\t.init\t\t\t= rcu_sync_torture_init,\n\t.readlock\t\t= rcu_torture_read_lock,\n\t.read_delay\t\t= rcu_read_delay,\n\t.readunlock\t\t= rcu_torture_read_unlock,\n\t.readlock_held\t\t= torture_readlock_not_held,\n\t.get_gp_seq\t\t= rcu_get_gp_seq,\n\t.gp_diff\t\t= rcu_seq_diff,\n\t.deferred_free\t\t= rcu_torture_deferred_free,\n\t.sync\t\t\t= synchronize_rcu,\n\t.exp_sync\t\t= synchronize_rcu_expedited,\n\t.same_gp_state\t\t= same_state_synchronize_rcu,\n\t.same_gp_state_full\t= same_state_synchronize_rcu_full,\n\t.get_comp_state\t\t= get_completed_synchronize_rcu,\n\t.get_comp_state_full\t= get_completed_synchronize_rcu_full,\n\t.get_gp_state\t\t= get_state_synchronize_rcu,\n\t.get_gp_state_full\t= get_state_synchronize_rcu_full,\n\t.get_gp_completed\t= get_completed_synchronize_rcu,\n\t.get_gp_completed_full\t= get_completed_synchronize_rcu_full,\n\t.start_gp_poll\t\t= start_poll_synchronize_rcu,\n\t.start_gp_poll_full\t= start_poll_synchronize_rcu_full,\n\t.poll_gp_state\t\t= poll_state_synchronize_rcu,\n\t.poll_gp_state_full\t= poll_state_synchronize_rcu_full,\n\t.poll_need_2gp\t\t= rcu_poll_need_2gp,\n\t.cond_sync\t\t= cond_synchronize_rcu,\n\t.cond_sync_full\t\t= cond_synchronize_rcu_full,\n\t.get_gp_state_exp\t= get_state_synchronize_rcu,\n\t.start_gp_poll_exp\t= start_poll_synchronize_rcu_expedited,\n\t.start_gp_poll_exp_full\t= start_poll_synchronize_rcu_expedited_full,\n\t.poll_gp_state_exp\t= poll_state_synchronize_rcu,\n\t.cond_sync_exp\t\t= cond_synchronize_rcu_expedited,\n\t.call\t\t\t= call_rcu_hurry,\n\t.cb_barrier\t\t= rcu_barrier,\n\t.fqs\t\t\t= rcu_force_quiescent_state,\n\t.stats\t\t\t= NULL,\n\t.gp_kthread_dbg\t\t= show_rcu_gp_kthreads,\n\t.check_boost_failed\t= rcu_check_boost_fail,\n\t.stall_dur\t\t= rcu_jiffies_till_stall_check,\n\t.irq_capable\t\t= 1,\n\t.can_boost\t\t= IS_ENABLED(CONFIG_RCU_BOOST),\n\t.extendables\t\t= RCUTORTURE_MAX_EXTEND,\n\t.name\t\t\t= \"rcu\"\n};\n\n \nstatic void rcu_busted_torture_deferred_free(struct rcu_torture *p)\n{\n\t \n\trcu_torture_cb(&p->rtort_rcu);\n}\n\nstatic void synchronize_rcu_busted(void)\n{\n\t \n}\n\nstatic void\ncall_rcu_busted(struct rcu_head *head, rcu_callback_t func)\n{\n\t \n\tfunc(head);\n}\n\nstatic struct rcu_torture_ops rcu_busted_ops = {\n\t.ttype\t\t= INVALID_RCU_FLAVOR,\n\t.init\t\t= rcu_sync_torture_init,\n\t.readlock\t= rcu_torture_read_lock,\n\t.read_delay\t= rcu_read_delay,   \n\t.readunlock\t= rcu_torture_read_unlock,\n\t.readlock_held\t= torture_readlock_not_held,\n\t.get_gp_seq\t= rcu_no_completed,\n\t.deferred_free\t= rcu_busted_torture_deferred_free,\n\t.sync\t\t= synchronize_rcu_busted,\n\t.exp_sync\t= synchronize_rcu_busted,\n\t.call\t\t= call_rcu_busted,\n\t.cb_barrier\t= NULL,\n\t.fqs\t\t= NULL,\n\t.stats\t\t= NULL,\n\t.irq_capable\t= 1,\n\t.name\t\t= \"busted\"\n};\n\n \n\nDEFINE_STATIC_SRCU(srcu_ctl);\nstatic struct srcu_struct srcu_ctld;\nstatic struct srcu_struct *srcu_ctlp = &srcu_ctl;\nstatic struct rcu_torture_ops srcud_ops;\n\nstatic int srcu_torture_read_lock(void)\n{\n\tif (cur_ops == &srcud_ops)\n\t\treturn srcu_read_lock_nmisafe(srcu_ctlp);\n\telse\n\t\treturn srcu_read_lock(srcu_ctlp);\n}\n\nstatic void\nsrcu_read_delay(struct torture_random_state *rrsp, struct rt_read_seg *rtrsp)\n{\n\tlong delay;\n\tconst long uspertick = 1000000 / HZ;\n\tconst long longdelay = 10;\n\n\t \n\n\tdelay = torture_random(rrsp) %\n\t\t(nrealreaders * 2 * longdelay * uspertick);\n\tif (!delay && in_task()) {\n\t\tschedule_timeout_interruptible(longdelay);\n\t\trtrsp->rt_delay_jiffies = longdelay;\n\t} else {\n\t\trcu_read_delay(rrsp, rtrsp);\n\t}\n}\n\nstatic void srcu_torture_read_unlock(int idx)\n{\n\tif (cur_ops == &srcud_ops)\n\t\tsrcu_read_unlock_nmisafe(srcu_ctlp, idx);\n\telse\n\t\tsrcu_read_unlock(srcu_ctlp, idx);\n}\n\nstatic int torture_srcu_read_lock_held(void)\n{\n\treturn srcu_read_lock_held(srcu_ctlp);\n}\n\nstatic unsigned long srcu_torture_completed(void)\n{\n\treturn srcu_batches_completed(srcu_ctlp);\n}\n\nstatic void srcu_torture_deferred_free(struct rcu_torture *rp)\n{\n\tcall_srcu(srcu_ctlp, &rp->rtort_rcu, rcu_torture_cb);\n}\n\nstatic void srcu_torture_synchronize(void)\n{\n\tsynchronize_srcu(srcu_ctlp);\n}\n\nstatic unsigned long srcu_torture_get_gp_state(void)\n{\n\treturn get_state_synchronize_srcu(srcu_ctlp);\n}\n\nstatic unsigned long srcu_torture_start_gp_poll(void)\n{\n\treturn start_poll_synchronize_srcu(srcu_ctlp);\n}\n\nstatic bool srcu_torture_poll_gp_state(unsigned long oldstate)\n{\n\treturn poll_state_synchronize_srcu(srcu_ctlp, oldstate);\n}\n\nstatic void srcu_torture_call(struct rcu_head *head,\n\t\t\t      rcu_callback_t func)\n{\n\tcall_srcu(srcu_ctlp, head, func);\n}\n\nstatic void srcu_torture_barrier(void)\n{\n\tsrcu_barrier(srcu_ctlp);\n}\n\nstatic void srcu_torture_stats(void)\n{\n\tsrcu_torture_stats_print(srcu_ctlp, torture_type, TORTURE_FLAG);\n}\n\nstatic void srcu_torture_synchronize_expedited(void)\n{\n\tsynchronize_srcu_expedited(srcu_ctlp);\n}\n\nstatic struct rcu_torture_ops srcu_ops = {\n\t.ttype\t\t= SRCU_FLAVOR,\n\t.init\t\t= rcu_sync_torture_init,\n\t.readlock\t= srcu_torture_read_lock,\n\t.read_delay\t= srcu_read_delay,\n\t.readunlock\t= srcu_torture_read_unlock,\n\t.readlock_held\t= torture_srcu_read_lock_held,\n\t.get_gp_seq\t= srcu_torture_completed,\n\t.deferred_free\t= srcu_torture_deferred_free,\n\t.sync\t\t= srcu_torture_synchronize,\n\t.exp_sync\t= srcu_torture_synchronize_expedited,\n\t.get_gp_state\t= srcu_torture_get_gp_state,\n\t.start_gp_poll\t= srcu_torture_start_gp_poll,\n\t.poll_gp_state\t= srcu_torture_poll_gp_state,\n\t.call\t\t= srcu_torture_call,\n\t.cb_barrier\t= srcu_torture_barrier,\n\t.stats\t\t= srcu_torture_stats,\n\t.cbflood_max\t= 50000,\n\t.irq_capable\t= 1,\n\t.no_pi_lock\t= IS_ENABLED(CONFIG_TINY_SRCU),\n\t.name\t\t= \"srcu\"\n};\n\nstatic void srcu_torture_init(void)\n{\n\trcu_sync_torture_init();\n\tWARN_ON(init_srcu_struct(&srcu_ctld));\n\tsrcu_ctlp = &srcu_ctld;\n}\n\nstatic void srcu_torture_cleanup(void)\n{\n\tcleanup_srcu_struct(&srcu_ctld);\n\tsrcu_ctlp = &srcu_ctl;  \n}\n\n \nstatic struct rcu_torture_ops srcud_ops = {\n\t.ttype\t\t= SRCU_FLAVOR,\n\t.init\t\t= srcu_torture_init,\n\t.cleanup\t= srcu_torture_cleanup,\n\t.readlock\t= srcu_torture_read_lock,\n\t.read_delay\t= srcu_read_delay,\n\t.readunlock\t= srcu_torture_read_unlock,\n\t.readlock_held\t= torture_srcu_read_lock_held,\n\t.get_gp_seq\t= srcu_torture_completed,\n\t.deferred_free\t= srcu_torture_deferred_free,\n\t.sync\t\t= srcu_torture_synchronize,\n\t.exp_sync\t= srcu_torture_synchronize_expedited,\n\t.get_gp_state\t= srcu_torture_get_gp_state,\n\t.start_gp_poll\t= srcu_torture_start_gp_poll,\n\t.poll_gp_state\t= srcu_torture_poll_gp_state,\n\t.call\t\t= srcu_torture_call,\n\t.cb_barrier\t= srcu_torture_barrier,\n\t.stats\t\t= srcu_torture_stats,\n\t.cbflood_max\t= 50000,\n\t.irq_capable\t= 1,\n\t.no_pi_lock\t= IS_ENABLED(CONFIG_TINY_SRCU),\n\t.name\t\t= \"srcud\"\n};\n\n \nstatic struct rcu_torture_ops busted_srcud_ops = {\n\t.ttype\t\t= SRCU_FLAVOR,\n\t.init\t\t= srcu_torture_init,\n\t.cleanup\t= srcu_torture_cleanup,\n\t.readlock\t= srcu_torture_read_lock,\n\t.read_delay\t= rcu_read_delay,\n\t.readunlock\t= srcu_torture_read_unlock,\n\t.readlock_held\t= torture_srcu_read_lock_held,\n\t.get_gp_seq\t= srcu_torture_completed,\n\t.deferred_free\t= srcu_torture_deferred_free,\n\t.sync\t\t= srcu_torture_synchronize,\n\t.exp_sync\t= srcu_torture_synchronize_expedited,\n\t.call\t\t= srcu_torture_call,\n\t.cb_barrier\t= srcu_torture_barrier,\n\t.stats\t\t= srcu_torture_stats,\n\t.irq_capable\t= 1,\n\t.no_pi_lock\t= IS_ENABLED(CONFIG_TINY_SRCU),\n\t.extendables\t= RCUTORTURE_MAX_EXTEND,\n\t.name\t\t= \"busted_srcud\"\n};\n\n \n\nstatic void synchronize_rcu_trivial(void)\n{\n\tint cpu;\n\n\tfor_each_online_cpu(cpu) {\n\t\trcutorture_sched_setaffinity(current->pid, cpumask_of(cpu));\n\t\tWARN_ON_ONCE(raw_smp_processor_id() != cpu);\n\t}\n}\n\nstatic int rcu_torture_read_lock_trivial(void)\n{\n\tpreempt_disable();\n\treturn 0;\n}\n\nstatic void rcu_torture_read_unlock_trivial(int idx)\n{\n\tpreempt_enable();\n}\n\nstatic struct rcu_torture_ops trivial_ops = {\n\t.ttype\t\t= RCU_TRIVIAL_FLAVOR,\n\t.init\t\t= rcu_sync_torture_init,\n\t.readlock\t= rcu_torture_read_lock_trivial,\n\t.read_delay\t= rcu_read_delay,   \n\t.readunlock\t= rcu_torture_read_unlock_trivial,\n\t.readlock_held\t= torture_readlock_not_held,\n\t.get_gp_seq\t= rcu_no_completed,\n\t.sync\t\t= synchronize_rcu_trivial,\n\t.exp_sync\t= synchronize_rcu_trivial,\n\t.fqs\t\t= NULL,\n\t.stats\t\t= NULL,\n\t.irq_capable\t= 1,\n\t.name\t\t= \"trivial\"\n};\n\n#ifdef CONFIG_TASKS_RCU\n\n \n\nstatic int tasks_torture_read_lock(void)\n{\n\treturn 0;\n}\n\nstatic void tasks_torture_read_unlock(int idx)\n{\n}\n\nstatic void rcu_tasks_torture_deferred_free(struct rcu_torture *p)\n{\n\tcall_rcu_tasks(&p->rtort_rcu, rcu_torture_cb);\n}\n\nstatic void synchronize_rcu_mult_test(void)\n{\n\tsynchronize_rcu_mult(call_rcu_tasks, call_rcu_hurry);\n}\n\nstatic struct rcu_torture_ops tasks_ops = {\n\t.ttype\t\t= RCU_TASKS_FLAVOR,\n\t.init\t\t= rcu_sync_torture_init,\n\t.readlock\t= tasks_torture_read_lock,\n\t.read_delay\t= rcu_read_delay,   \n\t.readunlock\t= tasks_torture_read_unlock,\n\t.get_gp_seq\t= rcu_no_completed,\n\t.deferred_free\t= rcu_tasks_torture_deferred_free,\n\t.sync\t\t= synchronize_rcu_tasks,\n\t.exp_sync\t= synchronize_rcu_mult_test,\n\t.call\t\t= call_rcu_tasks,\n\t.cb_barrier\t= rcu_barrier_tasks,\n\t.gp_kthread_dbg\t= show_rcu_tasks_classic_gp_kthread,\n\t.fqs\t\t= NULL,\n\t.stats\t\t= NULL,\n\t.irq_capable\t= 1,\n\t.slow_gps\t= 1,\n\t.name\t\t= \"tasks\"\n};\n\n#define TASKS_OPS &tasks_ops,\n\n#else \n\n#define TASKS_OPS\n\n#endif \n\n\n#ifdef CONFIG_TASKS_RUDE_RCU\n\n \n\nstatic void rcu_tasks_rude_torture_deferred_free(struct rcu_torture *p)\n{\n\tcall_rcu_tasks_rude(&p->rtort_rcu, rcu_torture_cb);\n}\n\nstatic struct rcu_torture_ops tasks_rude_ops = {\n\t.ttype\t\t= RCU_TASKS_RUDE_FLAVOR,\n\t.init\t\t= rcu_sync_torture_init,\n\t.readlock\t= rcu_torture_read_lock_trivial,\n\t.read_delay\t= rcu_read_delay,   \n\t.readunlock\t= rcu_torture_read_unlock_trivial,\n\t.get_gp_seq\t= rcu_no_completed,\n\t.deferred_free\t= rcu_tasks_rude_torture_deferred_free,\n\t.sync\t\t= synchronize_rcu_tasks_rude,\n\t.exp_sync\t= synchronize_rcu_tasks_rude,\n\t.call\t\t= call_rcu_tasks_rude,\n\t.cb_barrier\t= rcu_barrier_tasks_rude,\n\t.gp_kthread_dbg\t= show_rcu_tasks_rude_gp_kthread,\n\t.cbflood_max\t= 50000,\n\t.fqs\t\t= NULL,\n\t.stats\t\t= NULL,\n\t.irq_capable\t= 1,\n\t.name\t\t= \"tasks-rude\"\n};\n\n#define TASKS_RUDE_OPS &tasks_rude_ops,\n\n#else  \n\n#define TASKS_RUDE_OPS\n\n#endif  \n\n\n#ifdef CONFIG_TASKS_TRACE_RCU\n\n \n\nstatic int tasks_tracing_torture_read_lock(void)\n{\n\trcu_read_lock_trace();\n\treturn 0;\n}\n\nstatic void tasks_tracing_torture_read_unlock(int idx)\n{\n\trcu_read_unlock_trace();\n}\n\nstatic void rcu_tasks_tracing_torture_deferred_free(struct rcu_torture *p)\n{\n\tcall_rcu_tasks_trace(&p->rtort_rcu, rcu_torture_cb);\n}\n\nstatic struct rcu_torture_ops tasks_tracing_ops = {\n\t.ttype\t\t= RCU_TASKS_TRACING_FLAVOR,\n\t.init\t\t= rcu_sync_torture_init,\n\t.readlock\t= tasks_tracing_torture_read_lock,\n\t.read_delay\t= srcu_read_delay,   \n\t.readunlock\t= tasks_tracing_torture_read_unlock,\n\t.readlock_held\t= rcu_read_lock_trace_held,\n\t.get_gp_seq\t= rcu_no_completed,\n\t.deferred_free\t= rcu_tasks_tracing_torture_deferred_free,\n\t.sync\t\t= synchronize_rcu_tasks_trace,\n\t.exp_sync\t= synchronize_rcu_tasks_trace,\n\t.call\t\t= call_rcu_tasks_trace,\n\t.cb_barrier\t= rcu_barrier_tasks_trace,\n\t.gp_kthread_dbg\t= show_rcu_tasks_trace_gp_kthread,\n\t.cbflood_max\t= 50000,\n\t.fqs\t\t= NULL,\n\t.stats\t\t= NULL,\n\t.irq_capable\t= 1,\n\t.slow_gps\t= 1,\n\t.name\t\t= \"tasks-tracing\"\n};\n\n#define TASKS_TRACING_OPS &tasks_tracing_ops,\n\n#else \n\n#define TASKS_TRACING_OPS\n\n#endif \n\n\nstatic unsigned long rcutorture_seq_diff(unsigned long new, unsigned long old)\n{\n\tif (!cur_ops->gp_diff)\n\t\treturn new - old;\n\treturn cur_ops->gp_diff(new, old);\n}\n\n \n\nstatic int old_rt_runtime = -1;\n\nstatic void rcu_torture_disable_rt_throttle(void)\n{\n\t \n\tif (!IS_BUILTIN(CONFIG_RCU_TORTURE_TEST) || old_rt_runtime != -1)\n\t\treturn;\n\n\told_rt_runtime = sysctl_sched_rt_runtime;\n\tsysctl_sched_rt_runtime = -1;\n}\n\nstatic void rcu_torture_enable_rt_throttle(void)\n{\n\tif (!IS_BUILTIN(CONFIG_RCU_TORTURE_TEST) || old_rt_runtime == -1)\n\t\treturn;\n\n\tsysctl_sched_rt_runtime = old_rt_runtime;\n\told_rt_runtime = -1;\n}\n\nstatic bool rcu_torture_boost_failed(unsigned long gp_state, unsigned long *start)\n{\n\tint cpu;\n\tstatic int dbg_done;\n\tunsigned long end = jiffies;\n\tbool gp_done;\n\tunsigned long j;\n\tstatic unsigned long last_persist;\n\tunsigned long lp;\n\tunsigned long mininterval = test_boost_duration * HZ - HZ / 2;\n\n\tif (end - *start > mininterval) {\n\t\t\n\t\tsmp_mb(); \n\t\tif (cur_ops->poll_gp_state(gp_state))\n\t\t\treturn false; \n\t\tif (cur_ops->check_boost_failed && !cur_ops->check_boost_failed(gp_state, &cpu)) {\n\t\t\t\n\t\t\tj = jiffies;\n\t\t\tlp = READ_ONCE(last_persist);\n\t\t\tif (time_after(j, lp + mininterval) && cmpxchg(&last_persist, lp, j) == lp)\n\t\t\t\tpr_info(\"Boost inversion persisted: No QS from CPU %d\\n\", cpu);\n\t\t\treturn false; \n\t\t}\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_boost boosting failed\");\n\t\tn_rcu_torture_boost_failure++;\n\t\tif (!xchg(&dbg_done, 1) && cur_ops->gp_kthread_dbg) {\n\t\t\tpr_info(\"Boost inversion thread ->rt_priority %u gp_state %lu jiffies %lu\\n\",\n\t\t\t\tcurrent->rt_priority, gp_state, end - *start);\n\t\t\tcur_ops->gp_kthread_dbg();\n\t\t\t\n\t\t\tgp_done = cur_ops->poll_gp_state(gp_state);\n\t\t\tpr_info(\"Boost inversion: GP %lu %s.\\n\", gp_state,\n\t\t\t\tgp_done ? \"ended already\" : \"still pending\");\n\n\t\t}\n\n\t\treturn true; \n\t} else if (cur_ops->check_boost_failed && !cur_ops->check_boost_failed(gp_state, NULL)) {\n\t\t*start = jiffies;\n\t}\n\n\treturn false; \n}\n\nstatic int rcu_torture_boost(void *arg)\n{\n\tunsigned long endtime;\n\tunsigned long gp_state;\n\tunsigned long gp_state_time;\n\tunsigned long oldstarttime;\n\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_boost started\");\n\n\t \n\tsched_set_fifo_low(current);\n\n\t \n\tdo {\n\t\tbool failed = false; \n\t\tbool gp_initiated = false;\n\n\t\tif (kthread_should_stop())\n\t\t\tgoto checkwait;\n\n\t\t \n\t\toldstarttime = READ_ONCE(boost_starttime);\n\t\twhile (time_before(jiffies, oldstarttime)) {\n\t\t\tschedule_timeout_interruptible(oldstarttime - jiffies);\n\t\t\tif (stutter_wait(\"rcu_torture_boost\"))\n\t\t\t\tsched_set_fifo_low(current);\n\t\t\tif (torture_must_stop())\n\t\t\t\tgoto checkwait;\n\t\t}\n\n\t\t\n\t\tendtime = oldstarttime + test_boost_duration * HZ;\n\t\twhile (time_before(jiffies, endtime)) {\n\t\t\t\n\t\t\tif (gp_initiated && !failed && !cur_ops->poll_gp_state(gp_state))\n\t\t\t\tfailed = rcu_torture_boost_failed(gp_state, &gp_state_time);\n\t\t\t\n\t\t\tif (!gp_initiated || cur_ops->poll_gp_state(gp_state)) {\n\t\t\t\tgp_state = cur_ops->start_gp_poll();\n\t\t\t\tgp_initiated = true;\n\t\t\t\tgp_state_time = jiffies;\n\t\t\t}\n\t\t\tif (stutter_wait(\"rcu_torture_boost\")) {\n\t\t\t\tsched_set_fifo_low(current);\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tif (cur_ops->poll_gp_state(gp_state))\n\t\t\t\t\tgp_initiated = false;\n\t\t\t}\n\t\t\tif (torture_must_stop())\n\t\t\t\tgoto checkwait;\n\t\t}\n\n\t\t\n\t\tif (gp_initiated && !failed && !cur_ops->poll_gp_state(gp_state))\n\t\t\trcu_torture_boost_failed(gp_state, &gp_state_time);\n\n\t\t \n\t\twhile (oldstarttime == READ_ONCE(boost_starttime) && !kthread_should_stop()) {\n\t\t\tif (mutex_trylock(&boost_mutex)) {\n\t\t\t\tif (oldstarttime == boost_starttime) {\n\t\t\t\t\tWRITE_ONCE(boost_starttime,\n\t\t\t\t\t\t   jiffies + test_boost_interval * HZ);\n\t\t\t\t\tn_rcu_torture_boosts++;\n\t\t\t\t}\n\t\t\t\tmutex_unlock(&boost_mutex);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tschedule_timeout_uninterruptible(1);\n\t\t}\n\n\t\t \ncheckwait:\tif (stutter_wait(\"rcu_torture_boost\"))\n\t\t\tsched_set_fifo_low(current);\n\t} while (!torture_must_stop());\n\n\t \n\twhile (!kthread_should_stop()) {\n\t\ttorture_shutdown_absorb(\"rcu_torture_boost\");\n\t\tschedule_timeout_uninterruptible(1);\n\t}\n\ttorture_kthread_stopping(\"rcu_torture_boost\");\n\treturn 0;\n}\n\n \nstatic int\nrcu_torture_fqs(void *arg)\n{\n\tunsigned long fqs_resume_time;\n\tint fqs_burst_remaining;\n\tint oldnice = task_nice(current);\n\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_fqs task started\");\n\tdo {\n\t\tfqs_resume_time = jiffies + fqs_stutter * HZ;\n\t\twhile (time_before(jiffies, fqs_resume_time) &&\n\t\t       !kthread_should_stop()) {\n\t\t\tschedule_timeout_interruptible(1);\n\t\t}\n\t\tfqs_burst_remaining = fqs_duration;\n\t\twhile (fqs_burst_remaining > 0 &&\n\t\t       !kthread_should_stop()) {\n\t\t\tcur_ops->fqs();\n\t\t\tudelay(fqs_holdoff);\n\t\t\tfqs_burst_remaining -= fqs_holdoff;\n\t\t}\n\t\tif (stutter_wait(\"rcu_torture_fqs\"))\n\t\t\tsched_set_normal(current, oldnice);\n\t} while (!torture_must_stop());\n\ttorture_kthread_stopping(\"rcu_torture_fqs\");\n\treturn 0;\n}\n\n\nstatic int synctype[ARRAY_SIZE(rcu_torture_writer_state_names)] = { };\nstatic int nsynctypes;\n\n \nstatic void rcu_torture_write_types(void)\n{\n\tbool gp_cond1 = gp_cond, gp_cond_exp1 = gp_cond_exp, gp_cond_full1 = gp_cond_full;\n\tbool gp_cond_exp_full1 = gp_cond_exp_full, gp_exp1 = gp_exp, gp_poll_exp1 = gp_poll_exp;\n\tbool gp_poll_exp_full1 = gp_poll_exp_full, gp_normal1 = gp_normal, gp_poll1 = gp_poll;\n\tbool gp_poll_full1 = gp_poll_full, gp_sync1 = gp_sync;\n\n\t \n\tif (!gp_cond1 &&\n\t    !gp_cond_exp1 &&\n\t    !gp_cond_full1 &&\n\t    !gp_cond_exp_full1 &&\n\t    !gp_exp1 &&\n\t    !gp_poll_exp1 &&\n\t    !gp_poll_exp_full1 &&\n\t    !gp_normal1 &&\n\t    !gp_poll1 &&\n\t    !gp_poll_full1 &&\n\t    !gp_sync1) {\n\t\tgp_cond1 = true;\n\t\tgp_cond_exp1 = true;\n\t\tgp_cond_full1 = true;\n\t\tgp_cond_exp_full1 = true;\n\t\tgp_exp1 = true;\n\t\tgp_poll_exp1 = true;\n\t\tgp_poll_exp_full1 = true;\n\t\tgp_normal1 = true;\n\t\tgp_poll1 = true;\n\t\tgp_poll_full1 = true;\n\t\tgp_sync1 = true;\n\t}\n\tif (gp_cond1 && cur_ops->get_gp_state && cur_ops->cond_sync) {\n\t\tsynctype[nsynctypes++] = RTWS_COND_GET;\n\t\tpr_info(\"%s: Testing conditional GPs.\\n\", __func__);\n\t} else if (gp_cond && (!cur_ops->get_gp_state || !cur_ops->cond_sync)) {\n\t\tpr_alert(\"%s: gp_cond without primitives.\\n\", __func__);\n\t}\n\tif (gp_cond_exp1 && cur_ops->get_gp_state_exp && cur_ops->cond_sync_exp) {\n\t\tsynctype[nsynctypes++] = RTWS_COND_GET_EXP;\n\t\tpr_info(\"%s: Testing conditional expedited GPs.\\n\", __func__);\n\t} else if (gp_cond_exp && (!cur_ops->get_gp_state_exp || !cur_ops->cond_sync_exp)) {\n\t\tpr_alert(\"%s: gp_cond_exp without primitives.\\n\", __func__);\n\t}\n\tif (gp_cond_full1 && cur_ops->get_gp_state && cur_ops->cond_sync_full) {\n\t\tsynctype[nsynctypes++] = RTWS_COND_GET_FULL;\n\t\tpr_info(\"%s: Testing conditional full-state GPs.\\n\", __func__);\n\t} else if (gp_cond_full && (!cur_ops->get_gp_state || !cur_ops->cond_sync_full)) {\n\t\tpr_alert(\"%s: gp_cond_full without primitives.\\n\", __func__);\n\t}\n\tif (gp_cond_exp_full1 && cur_ops->get_gp_state_exp && cur_ops->cond_sync_exp_full) {\n\t\tsynctype[nsynctypes++] = RTWS_COND_GET_EXP_FULL;\n\t\tpr_info(\"%s: Testing conditional full-state expedited GPs.\\n\", __func__);\n\t} else if (gp_cond_exp_full &&\n\t\t   (!cur_ops->get_gp_state_exp || !cur_ops->cond_sync_exp_full)) {\n\t\tpr_alert(\"%s: gp_cond_exp_full without primitives.\\n\", __func__);\n\t}\n\tif (gp_exp1 && cur_ops->exp_sync) {\n\t\tsynctype[nsynctypes++] = RTWS_EXP_SYNC;\n\t\tpr_info(\"%s: Testing expedited GPs.\\n\", __func__);\n\t} else if (gp_exp && !cur_ops->exp_sync) {\n\t\tpr_alert(\"%s: gp_exp without primitives.\\n\", __func__);\n\t}\n\tif (gp_normal1 && cur_ops->deferred_free) {\n\t\tsynctype[nsynctypes++] = RTWS_DEF_FREE;\n\t\tpr_info(\"%s: Testing asynchronous GPs.\\n\", __func__);\n\t} else if (gp_normal && !cur_ops->deferred_free) {\n\t\tpr_alert(\"%s: gp_normal without primitives.\\n\", __func__);\n\t}\n\tif (gp_poll1 && cur_ops->get_comp_state && cur_ops->same_gp_state &&\n\t    cur_ops->start_gp_poll && cur_ops->poll_gp_state) {\n\t\tsynctype[nsynctypes++] = RTWS_POLL_GET;\n\t\tpr_info(\"%s: Testing polling GPs.\\n\", __func__);\n\t} else if (gp_poll && (!cur_ops->start_gp_poll || !cur_ops->poll_gp_state)) {\n\t\tpr_alert(\"%s: gp_poll without primitives.\\n\", __func__);\n\t}\n\tif (gp_poll_full1 && cur_ops->get_comp_state_full && cur_ops->same_gp_state_full\n\t    && cur_ops->start_gp_poll_full && cur_ops->poll_gp_state_full) {\n\t\tsynctype[nsynctypes++] = RTWS_POLL_GET_FULL;\n\t\tpr_info(\"%s: Testing polling full-state GPs.\\n\", __func__);\n\t} else if (gp_poll_full && (!cur_ops->start_gp_poll_full || !cur_ops->poll_gp_state_full)) {\n\t\tpr_alert(\"%s: gp_poll_full without primitives.\\n\", __func__);\n\t}\n\tif (gp_poll_exp1 && cur_ops->start_gp_poll_exp && cur_ops->poll_gp_state_exp) {\n\t\tsynctype[nsynctypes++] = RTWS_POLL_GET_EXP;\n\t\tpr_info(\"%s: Testing polling expedited GPs.\\n\", __func__);\n\t} else if (gp_poll_exp && (!cur_ops->start_gp_poll_exp || !cur_ops->poll_gp_state_exp)) {\n\t\tpr_alert(\"%s: gp_poll_exp without primitives.\\n\", __func__);\n\t}\n\tif (gp_poll_exp_full1 && cur_ops->start_gp_poll_exp_full && cur_ops->poll_gp_state_full) {\n\t\tsynctype[nsynctypes++] = RTWS_POLL_GET_EXP_FULL;\n\t\tpr_info(\"%s: Testing polling full-state expedited GPs.\\n\", __func__);\n\t} else if (gp_poll_exp_full &&\n\t\t   (!cur_ops->start_gp_poll_exp_full || !cur_ops->poll_gp_state_full)) {\n\t\tpr_alert(\"%s: gp_poll_exp_full without primitives.\\n\", __func__);\n\t}\n\tif (gp_sync1 && cur_ops->sync) {\n\t\tsynctype[nsynctypes++] = RTWS_SYNC;\n\t\tpr_info(\"%s: Testing normal GPs.\\n\", __func__);\n\t} else if (gp_sync && !cur_ops->sync) {\n\t\tpr_alert(\"%s: gp_sync without primitives.\\n\", __func__);\n\t}\n}\n\n \nstatic void do_rtws_sync(struct torture_random_state *trsp, void (*sync)(void))\n{\n\tunsigned long cookie;\n\tstruct rcu_gp_oldstate cookie_full;\n\tbool dopoll;\n\tbool dopoll_full;\n\tunsigned long r = torture_random(trsp);\n\n\tdopoll = cur_ops->get_gp_state && cur_ops->poll_gp_state && !(r & 0x300);\n\tdopoll_full = cur_ops->get_gp_state_full && cur_ops->poll_gp_state_full && !(r & 0xc00);\n\tif (dopoll || dopoll_full)\n\t\tcpus_read_lock();\n\tif (dopoll)\n\t\tcookie = cur_ops->get_gp_state();\n\tif (dopoll_full)\n\t\tcur_ops->get_gp_state_full(&cookie_full);\n\tif (cur_ops->poll_need_2gp && cur_ops->poll_need_2gp(dopoll, dopoll_full))\n\t\tsync();\n\tsync();\n\tWARN_ONCE(dopoll && !cur_ops->poll_gp_state(cookie),\n\t\t  \"%s: Cookie check 3 failed %pS() online %*pbl.\",\n\t\t  __func__, sync, cpumask_pr_args(cpu_online_mask));\n\tWARN_ONCE(dopoll_full && !cur_ops->poll_gp_state_full(&cookie_full),\n\t\t  \"%s: Cookie check 4 failed %pS() online %*pbl\",\n\t\t  __func__, sync, cpumask_pr_args(cpu_online_mask));\n\tif (dopoll || dopoll_full)\n\t\tcpus_read_unlock();\n}\n\n \nstatic int\nrcu_torture_writer(void *arg)\n{\n\tbool boot_ended;\n\tbool can_expedite = !rcu_gp_is_expedited() && !rcu_gp_is_normal();\n\tunsigned long cookie;\n\tstruct rcu_gp_oldstate cookie_full;\n\tint expediting = 0;\n\tunsigned long gp_snap;\n\tunsigned long gp_snap1;\n\tstruct rcu_gp_oldstate gp_snap_full;\n\tstruct rcu_gp_oldstate gp_snap1_full;\n\tint i;\n\tint idx;\n\tint oldnice = task_nice(current);\n\tstruct rcu_gp_oldstate rgo[NUM_ACTIVE_RCU_POLL_FULL_OLDSTATE];\n\tstruct rcu_torture *rp;\n\tstruct rcu_torture *old_rp;\n\tstatic DEFINE_TORTURE_RANDOM(rand);\n\tbool stutter_waited;\n\tunsigned long ulo[NUM_ACTIVE_RCU_POLL_OLDSTATE];\n\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_writer task started\");\n\tif (!can_expedite)\n\t\tpr_alert(\"%s\" TORTURE_FLAG\n\t\t\t \" GP expediting controlled from boot/sysfs for %s.\\n\",\n\t\t\t torture_type, cur_ops->name);\n\tif (WARN_ONCE(nsynctypes == 0,\n\t\t      \"%s: No update-side primitives.\\n\", __func__)) {\n\t\t \n\t\trcu_torture_writer_state = RTWS_STOPPING;\n\t\ttorture_kthread_stopping(\"rcu_torture_writer\");\n\t\treturn 0;\n\t}\n\n\tdo {\n\t\trcu_torture_writer_state = RTWS_FIXED_DELAY;\n\t\ttorture_hrtimeout_us(500, 1000, &rand);\n\t\trp = rcu_torture_alloc();\n\t\tif (rp == NULL)\n\t\t\tcontinue;\n\t\trp->rtort_pipe_count = 0;\n\t\trcu_torture_writer_state = RTWS_DELAY;\n\t\tudelay(torture_random(&rand) & 0x3ff);\n\t\trcu_torture_writer_state = RTWS_REPLACE;\n\t\told_rp = rcu_dereference_check(rcu_torture_current,\n\t\t\t\t\t       current == writer_task);\n\t\trp->rtort_mbtest = 1;\n\t\trcu_assign_pointer(rcu_torture_current, rp);\n\t\tsmp_wmb();  \n\t\tif (old_rp) {\n\t\t\ti = old_rp->rtort_pipe_count;\n\t\t\tif (i > RCU_TORTURE_PIPE_LEN)\n\t\t\t\ti = RCU_TORTURE_PIPE_LEN;\n\t\t\tatomic_inc(&rcu_torture_wcount[i]);\n\t\t\tWRITE_ONCE(old_rp->rtort_pipe_count,\n\t\t\t\t   old_rp->rtort_pipe_count + 1);\n\n\t\t\t\n\t\t\tif (cur_ops->get_gp_state && cur_ops->poll_gp_state) {\n\t\t\t\tidx = cur_ops->readlock();\n\t\t\t\tcookie = cur_ops->get_gp_state();\n\t\t\t\tWARN_ONCE(cur_ops->poll_gp_state(cookie),\n\t\t\t\t\t  \"%s: Cookie check 1 failed %s(%d) %lu->%lu\\n\",\n\t\t\t\t\t  __func__,\n\t\t\t\t\t  rcu_torture_writer_state_getname(),\n\t\t\t\t\t  rcu_torture_writer_state,\n\t\t\t\t\t  cookie, cur_ops->get_gp_state());\n\t\t\t\tif (cur_ops->get_gp_completed) {\n\t\t\t\t\tcookie = cur_ops->get_gp_completed();\n\t\t\t\t\tWARN_ON_ONCE(!cur_ops->poll_gp_state(cookie));\n\t\t\t\t}\n\t\t\t\tcur_ops->readunlock(idx);\n\t\t\t}\n\t\t\tif (cur_ops->get_gp_state_full && cur_ops->poll_gp_state_full) {\n\t\t\t\tidx = cur_ops->readlock();\n\t\t\t\tcur_ops->get_gp_state_full(&cookie_full);\n\t\t\t\tWARN_ONCE(cur_ops->poll_gp_state_full(&cookie_full),\n\t\t\t\t\t  \"%s: Cookie check 5 failed %s(%d) online %*pbl\\n\",\n\t\t\t\t\t  __func__,\n\t\t\t\t\t  rcu_torture_writer_state_getname(),\n\t\t\t\t\t  rcu_torture_writer_state,\n\t\t\t\t\t  cpumask_pr_args(cpu_online_mask));\n\t\t\t\tif (cur_ops->get_gp_completed_full) {\n\t\t\t\t\tcur_ops->get_gp_completed_full(&cookie_full);\n\t\t\t\t\tWARN_ON_ONCE(!cur_ops->poll_gp_state_full(&cookie_full));\n\t\t\t\t}\n\t\t\t\tcur_ops->readunlock(idx);\n\t\t\t}\n\t\t\tswitch (synctype[torture_random(&rand) % nsynctypes]) {\n\t\t\tcase RTWS_DEF_FREE:\n\t\t\t\trcu_torture_writer_state = RTWS_DEF_FREE;\n\t\t\t\tcur_ops->deferred_free(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_EXP_SYNC:\n\t\t\t\trcu_torture_writer_state = RTWS_EXP_SYNC;\n\t\t\t\tdo_rtws_sync(&rand, cur_ops->exp_sync);\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_COND_GET:\n\t\t\t\trcu_torture_writer_state = RTWS_COND_GET;\n\t\t\t\tgp_snap = cur_ops->get_gp_state();\n\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16, &rand);\n\t\t\t\trcu_torture_writer_state = RTWS_COND_SYNC;\n\t\t\t\tcur_ops->cond_sync(gp_snap);\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_COND_GET_EXP:\n\t\t\t\trcu_torture_writer_state = RTWS_COND_GET_EXP;\n\t\t\t\tgp_snap = cur_ops->get_gp_state_exp();\n\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16, &rand);\n\t\t\t\trcu_torture_writer_state = RTWS_COND_SYNC_EXP;\n\t\t\t\tcur_ops->cond_sync_exp(gp_snap);\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_COND_GET_FULL:\n\t\t\t\trcu_torture_writer_state = RTWS_COND_GET_FULL;\n\t\t\t\tcur_ops->get_gp_state_full(&gp_snap_full);\n\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16, &rand);\n\t\t\t\trcu_torture_writer_state = RTWS_COND_SYNC_FULL;\n\t\t\t\tcur_ops->cond_sync_full(&gp_snap_full);\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_COND_GET_EXP_FULL:\n\t\t\t\trcu_torture_writer_state = RTWS_COND_GET_EXP_FULL;\n\t\t\t\tcur_ops->get_gp_state_full(&gp_snap_full);\n\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16, &rand);\n\t\t\t\trcu_torture_writer_state = RTWS_COND_SYNC_EXP_FULL;\n\t\t\t\tcur_ops->cond_sync_exp_full(&gp_snap_full);\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_POLL_GET:\n\t\t\t\trcu_torture_writer_state = RTWS_POLL_GET;\n\t\t\t\tfor (i = 0; i < ARRAY_SIZE(ulo); i++)\n\t\t\t\t\tulo[i] = cur_ops->get_comp_state();\n\t\t\t\tgp_snap = cur_ops->start_gp_poll();\n\t\t\t\trcu_torture_writer_state = RTWS_POLL_WAIT;\n\t\t\t\twhile (!cur_ops->poll_gp_state(gp_snap)) {\n\t\t\t\t\tgp_snap1 = cur_ops->get_gp_state();\n\t\t\t\t\tfor (i = 0; i < ARRAY_SIZE(ulo); i++)\n\t\t\t\t\t\tif (cur_ops->poll_gp_state(ulo[i]) ||\n\t\t\t\t\t\t    cur_ops->same_gp_state(ulo[i], gp_snap1)) {\n\t\t\t\t\t\t\tulo[i] = gp_snap1;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tWARN_ON_ONCE(i >= ARRAY_SIZE(ulo));\n\t\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16,\n\t\t\t\t\t\t\t\t  &rand);\n\t\t\t\t}\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_POLL_GET_FULL:\n\t\t\t\trcu_torture_writer_state = RTWS_POLL_GET_FULL;\n\t\t\t\tfor (i = 0; i < ARRAY_SIZE(rgo); i++)\n\t\t\t\t\tcur_ops->get_comp_state_full(&rgo[i]);\n\t\t\t\tcur_ops->start_gp_poll_full(&gp_snap_full);\n\t\t\t\trcu_torture_writer_state = RTWS_POLL_WAIT_FULL;\n\t\t\t\twhile (!cur_ops->poll_gp_state_full(&gp_snap_full)) {\n\t\t\t\t\tcur_ops->get_gp_state_full(&gp_snap1_full);\n\t\t\t\t\tfor (i = 0; i < ARRAY_SIZE(rgo); i++)\n\t\t\t\t\t\tif (cur_ops->poll_gp_state_full(&rgo[i]) ||\n\t\t\t\t\t\t    cur_ops->same_gp_state_full(&rgo[i],\n\t\t\t\t\t\t\t\t\t\t&gp_snap1_full)) {\n\t\t\t\t\t\t\trgo[i] = gp_snap1_full;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tWARN_ON_ONCE(i >= ARRAY_SIZE(rgo));\n\t\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16,\n\t\t\t\t\t\t\t\t  &rand);\n\t\t\t\t}\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_POLL_GET_EXP:\n\t\t\t\trcu_torture_writer_state = RTWS_POLL_GET_EXP;\n\t\t\t\tgp_snap = cur_ops->start_gp_poll_exp();\n\t\t\t\trcu_torture_writer_state = RTWS_POLL_WAIT_EXP;\n\t\t\t\twhile (!cur_ops->poll_gp_state_exp(gp_snap))\n\t\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16,\n\t\t\t\t\t\t\t\t  &rand);\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_POLL_GET_EXP_FULL:\n\t\t\t\trcu_torture_writer_state = RTWS_POLL_GET_EXP_FULL;\n\t\t\t\tcur_ops->start_gp_poll_exp_full(&gp_snap_full);\n\t\t\t\trcu_torture_writer_state = RTWS_POLL_WAIT_EXP_FULL;\n\t\t\t\twhile (!cur_ops->poll_gp_state_full(&gp_snap_full))\n\t\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16,\n\t\t\t\t\t\t\t\t  &rand);\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_SYNC:\n\t\t\t\trcu_torture_writer_state = RTWS_SYNC;\n\t\t\t\tdo_rtws_sync(&rand, cur_ops->sync);\n\t\t\t\trcu_torture_pipe_update(old_rp);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWARN_ON_ONCE(1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tWRITE_ONCE(rcu_torture_current_version,\n\t\t\t   rcu_torture_current_version + 1);\n\t\t \n\t\tif (can_expedite &&\n\t\t    !(torture_random(&rand) & 0xff & (!!expediting - 1))) {\n\t\t\tWARN_ON_ONCE(expediting == 0 && rcu_gp_is_expedited());\n\t\t\tif (expediting >= 0)\n\t\t\t\trcu_expedite_gp();\n\t\t\telse\n\t\t\t\trcu_unexpedite_gp();\n\t\t\tif (++expediting > 3)\n\t\t\t\texpediting = -expediting;\n\t\t} else if (!can_expedite) {  \n\t\t\tcan_expedite = !rcu_gp_is_expedited() &&\n\t\t\t\t       !rcu_gp_is_normal();\n\t\t}\n\t\trcu_torture_writer_state = RTWS_STUTTER;\n\t\tboot_ended = rcu_inkernel_boot_has_ended();\n\t\tstutter_waited = stutter_wait(\"rcu_torture_writer\");\n\t\tif (stutter_waited &&\n\t\t    !atomic_read(&rcu_fwd_cb_nodelay) &&\n\t\t    !cur_ops->slow_gps &&\n\t\t    !torture_must_stop() &&\n\t\t    boot_ended)\n\t\t\tfor (i = 0; i < ARRAY_SIZE(rcu_tortures); i++)\n\t\t\t\tif (list_empty(&rcu_tortures[i].rtort_free) &&\n\t\t\t\t    rcu_access_pointer(rcu_torture_current) !=\n\t\t\t\t    &rcu_tortures[i]) {\n\t\t\t\t\ttracing_off();\n\t\t\t\t\tshow_rcu_gp_kthreads();\n\t\t\t\t\tWARN(1, \"%s: rtort_pipe_count: %d\\n\", __func__, rcu_tortures[i].rtort_pipe_count);\n\t\t\t\t\trcu_ftrace_dump(DUMP_ALL);\n\t\t\t\t}\n\t\tif (stutter_waited)\n\t\t\tsched_set_normal(current, oldnice);\n\t} while (!torture_must_stop());\n\trcu_torture_current = NULL;  \n\t \n\tif (expediting > 0)\n\t\texpediting = -expediting;\n\twhile (can_expedite && expediting++ < 0)\n\t\trcu_unexpedite_gp();\n\tWARN_ON_ONCE(can_expedite && rcu_gp_is_expedited());\n\tif (!can_expedite)\n\t\tpr_alert(\"%s\" TORTURE_FLAG\n\t\t\t \" Dynamic grace-period expediting was disabled.\\n\",\n\t\t\t torture_type);\n\trcu_torture_writer_state = RTWS_STOPPING;\n\ttorture_kthread_stopping(\"rcu_torture_writer\");\n\treturn 0;\n}\n\n \nstatic int\nrcu_torture_fakewriter(void *arg)\n{\n\tunsigned long gp_snap;\n\tstruct rcu_gp_oldstate gp_snap_full;\n\tDEFINE_TORTURE_RANDOM(rand);\n\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_fakewriter task started\");\n\tset_user_nice(current, MAX_NICE);\n\n\tif (WARN_ONCE(nsynctypes == 0,\n\t\t      \"%s: No update-side primitives.\\n\", __func__)) {\n\t\t \n\t\ttorture_kthread_stopping(\"rcu_torture_fakewriter\");\n\t\treturn 0;\n\t}\n\n\tdo {\n\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 10, &rand);\n\t\tif (cur_ops->cb_barrier != NULL &&\n\t\t    torture_random(&rand) % (nfakewriters * 8) == 0) {\n\t\t\tcur_ops->cb_barrier();\n\t\t} else {\n\t\t\tswitch (synctype[torture_random(&rand) % nsynctypes]) {\n\t\t\tcase RTWS_DEF_FREE:\n\t\t\t\tbreak;\n\t\t\tcase RTWS_EXP_SYNC:\n\t\t\t\tcur_ops->exp_sync();\n\t\t\t\tbreak;\n\t\t\tcase RTWS_COND_GET:\n\t\t\t\tgp_snap = cur_ops->get_gp_state();\n\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16, &rand);\n\t\t\t\tcur_ops->cond_sync(gp_snap);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_COND_GET_EXP:\n\t\t\t\tgp_snap = cur_ops->get_gp_state_exp();\n\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16, &rand);\n\t\t\t\tcur_ops->cond_sync_exp(gp_snap);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_COND_GET_FULL:\n\t\t\t\tcur_ops->get_gp_state_full(&gp_snap_full);\n\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16, &rand);\n\t\t\t\tcur_ops->cond_sync_full(&gp_snap_full);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_COND_GET_EXP_FULL:\n\t\t\t\tcur_ops->get_gp_state_full(&gp_snap_full);\n\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16, &rand);\n\t\t\t\tcur_ops->cond_sync_exp_full(&gp_snap_full);\n\t\t\t\tbreak;\n\t\t\tcase RTWS_POLL_GET:\n\t\t\t\tgp_snap = cur_ops->start_gp_poll();\n\t\t\t\twhile (!cur_ops->poll_gp_state(gp_snap)) {\n\t\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16,\n\t\t\t\t\t\t\t\t  &rand);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase RTWS_POLL_GET_FULL:\n\t\t\t\tcur_ops->start_gp_poll_full(&gp_snap_full);\n\t\t\t\twhile (!cur_ops->poll_gp_state_full(&gp_snap_full)) {\n\t\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16,\n\t\t\t\t\t\t\t\t  &rand);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase RTWS_POLL_GET_EXP:\n\t\t\t\tgp_snap = cur_ops->start_gp_poll_exp();\n\t\t\t\twhile (!cur_ops->poll_gp_state_exp(gp_snap)) {\n\t\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16,\n\t\t\t\t\t\t\t\t  &rand);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase RTWS_POLL_GET_EXP_FULL:\n\t\t\t\tcur_ops->start_gp_poll_exp_full(&gp_snap_full);\n\t\t\t\twhile (!cur_ops->poll_gp_state_full(&gp_snap_full)) {\n\t\t\t\t\ttorture_hrtimeout_jiffies(torture_random(&rand) % 16,\n\t\t\t\t\t\t\t\t  &rand);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase RTWS_SYNC:\n\t\t\t\tcur_ops->sync();\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWARN_ON_ONCE(1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tstutter_wait(\"rcu_torture_fakewriter\");\n\t} while (!torture_must_stop());\n\n\ttorture_kthread_stopping(\"rcu_torture_fakewriter\");\n\treturn 0;\n}\n\nstatic void rcu_torture_timer_cb(struct rcu_head *rhp)\n{\n\tkfree(rhp);\n}\n\n\nstatic void rcu_torture_reader_do_mbchk(long myid, struct rcu_torture *rtp,\n\t\t\t\t\tstruct torture_random_state *trsp)\n{\n\tunsigned long loops;\n\tint noc = torture_num_online_cpus();\n\tint rdrchked;\n\tint rdrchker;\n\tstruct rcu_torture_reader_check *rtrcp; \n\tstruct rcu_torture_reader_check *rtrcp_assigner; \n\tstruct rcu_torture_reader_check *rtrcp_chked; \n\tstruct rcu_torture_reader_check *rtrcp_chker; \n\n\tif (myid < 0)\n\t\treturn; \n\n\t\n\trtrcp = &rcu_torture_reader_mbchk[myid];\n\tWRITE_ONCE(rtrcp->rtc_myloops, rtrcp->rtc_myloops + 1);\n\n\t\n\trdrchked = torture_random(trsp) % nrealreaders;\n\trtrcp_chked = &rcu_torture_reader_mbchk[rdrchked];\n\trdrchker = torture_random(trsp) % nrealreaders;\n\trtrcp_chker = &rcu_torture_reader_mbchk[rdrchker];\n\tif (rdrchked != myid && rdrchked != rdrchker && noc >= rdrchked && noc >= rdrchker &&\n\t    smp_load_acquire(&rtrcp->rtc_chkrdr) < 0 && \n\t    !READ_ONCE(rtp->rtort_chkp) &&\n\t    !smp_load_acquire(&rtrcp_chker->rtc_assigner)) { \n\t\trtrcp->rtc_chkloops = READ_ONCE(rtrcp_chked->rtc_myloops);\n\t\tWARN_ON_ONCE(rtrcp->rtc_chkrdr >= 0);\n\t\trtrcp->rtc_chkrdr = rdrchked;\n\t\tWARN_ON_ONCE(rtrcp->rtc_ready); \n\t\tif (cmpxchg_relaxed(&rtrcp_chker->rtc_assigner, NULL, rtrcp) ||\n\t\t    cmpxchg_relaxed(&rtp->rtort_chkp, NULL, rtrcp))\n\t\t\t(void)cmpxchg_relaxed(&rtrcp_chker->rtc_assigner, rtrcp, NULL); \n\t}\n\n\t\n\trtrcp_assigner = READ_ONCE(rtrcp->rtc_assigner);\n\tif (!rtrcp_assigner || !smp_load_acquire(&rtrcp_assigner->rtc_ready))\n\t\treturn; \n\trdrchked = rtrcp_assigner->rtc_chkrdr;\n\tif (WARN_ON_ONCE(rdrchked < 0))\n\t\treturn;\n\trtrcp_chked = &rcu_torture_reader_mbchk[rdrchked];\n\tloops = READ_ONCE(rtrcp_chked->rtc_myloops);\n\tatomic_inc(&n_rcu_torture_mbchk_tries);\n\tif (ULONG_CMP_LT(loops, rtrcp_assigner->rtc_chkloops))\n\t\tatomic_inc(&n_rcu_torture_mbchk_fail);\n\trtrcp_assigner->rtc_chkloops = loops + ULONG_MAX / 2;\n\trtrcp_assigner->rtc_ready = 0;\n\tsmp_store_release(&rtrcp->rtc_assigner, NULL); \n\tsmp_store_release(&rtrcp_assigner->rtc_chkrdr, -1); \n}\n\n \nstatic void rcutorture_one_extend(int *readstate, int newstate,\n\t\t\t\t  struct torture_random_state *trsp,\n\t\t\t\t  struct rt_read_seg *rtrsp)\n{\n\tunsigned long flags;\n\tint idxnew1 = -1;\n\tint idxnew2 = -1;\n\tint idxold1 = *readstate;\n\tint idxold2 = idxold1;\n\tint statesnew = ~*readstate & newstate;\n\tint statesold = *readstate & ~newstate;\n\n\tWARN_ON_ONCE(idxold2 < 0);\n\tWARN_ON_ONCE((idxold2 >> RCUTORTURE_RDR_SHIFT_2) > 1);\n\trtrsp->rt_readstate = newstate;\n\n\t \n\tif (statesnew & RCUTORTURE_RDR_BH)\n\t\tlocal_bh_disable();\n\tif (statesnew & RCUTORTURE_RDR_RBH)\n\t\trcu_read_lock_bh();\n\tif (statesnew & RCUTORTURE_RDR_IRQ)\n\t\tlocal_irq_disable();\n\tif (statesnew & RCUTORTURE_RDR_PREEMPT)\n\t\tpreempt_disable();\n\tif (statesnew & RCUTORTURE_RDR_SCHED)\n\t\trcu_read_lock_sched();\n\tif (statesnew & RCUTORTURE_RDR_RCU_1)\n\t\tidxnew1 = (cur_ops->readlock() & 0x1) << RCUTORTURE_RDR_SHIFT_1;\n\tif (statesnew & RCUTORTURE_RDR_RCU_2)\n\t\tidxnew2 = (cur_ops->readlock() & 0x1) << RCUTORTURE_RDR_SHIFT_2;\n\n\t \n\tif (statesold & RCUTORTURE_RDR_IRQ)\n\t\tlocal_irq_enable();\n\tif (statesold & RCUTORTURE_RDR_PREEMPT)\n\t\tpreempt_enable();\n\tif (statesold & RCUTORTURE_RDR_SCHED)\n\t\trcu_read_unlock_sched();\n\tif (statesold & RCUTORTURE_RDR_BH)\n\t\tlocal_bh_enable();\n\tif (statesold & RCUTORTURE_RDR_RBH)\n\t\trcu_read_unlock_bh();\n\tif (statesold & RCUTORTURE_RDR_RCU_2) {\n\t\tcur_ops->readunlock((idxold2 >> RCUTORTURE_RDR_SHIFT_2) & 0x1);\n\t\tWARN_ON_ONCE(idxnew2 != -1);\n\t\tidxold2 = 0;\n\t}\n\tif (statesold & RCUTORTURE_RDR_RCU_1) {\n\t\tbool lockit;\n\n\t\tlockit = !cur_ops->no_pi_lock && !statesnew && !(torture_random(trsp) & 0xffff);\n\t\tif (lockit)\n\t\t\traw_spin_lock_irqsave(&current->pi_lock, flags);\n\t\tcur_ops->readunlock((idxold1 >> RCUTORTURE_RDR_SHIFT_1) & 0x1);\n\t\tWARN_ON_ONCE(idxnew1 != -1);\n\t\tidxold1 = 0;\n\t\tif (lockit)\n\t\t\traw_spin_unlock_irqrestore(&current->pi_lock, flags);\n\t}\n\n\t \n\tif ((statesnew || statesold) && *readstate && newstate)\n\t\tcur_ops->read_delay(trsp, rtrsp);\n\n\t \n\tif (idxnew1 == -1)\n\t\tidxnew1 = idxold1 & RCUTORTURE_RDR_MASK_1;\n\tWARN_ON_ONCE(idxnew1 < 0);\n\tif (WARN_ON_ONCE((idxnew1 >> RCUTORTURE_RDR_SHIFT_1) > 1))\n\t\tpr_info(\"Unexpected idxnew1 value of %#x\\n\", idxnew1);\n\tif (idxnew2 == -1)\n\t\tidxnew2 = idxold2 & RCUTORTURE_RDR_MASK_2;\n\tWARN_ON_ONCE(idxnew2 < 0);\n\tWARN_ON_ONCE((idxnew2 >> RCUTORTURE_RDR_SHIFT_2) > 1);\n\t*readstate = idxnew1 | idxnew2 | newstate;\n\tWARN_ON_ONCE(*readstate < 0);\n\tif (WARN_ON_ONCE((*readstate >> RCUTORTURE_RDR_SHIFT_2) > 1))\n\t\tpr_info(\"Unexpected idxnew2 value of %#x\\n\", idxnew2);\n}\n\n \nstatic int rcutorture_extend_mask_max(void)\n{\n\tint mask;\n\n\tWARN_ON_ONCE(extendables & ~RCUTORTURE_MAX_EXTEND);\n\tmask = extendables & RCUTORTURE_MAX_EXTEND & cur_ops->extendables;\n\tmask = mask | RCUTORTURE_RDR_RCU_1 | RCUTORTURE_RDR_RCU_2;\n\treturn mask;\n}\n\n \nstatic int\nrcutorture_extend_mask(int oldmask, struct torture_random_state *trsp)\n{\n\tint mask = rcutorture_extend_mask_max();\n\tunsigned long randmask1 = torture_random(trsp);\n\tunsigned long randmask2 = randmask1 >> 3;\n\tunsigned long preempts = RCUTORTURE_RDR_PREEMPT | RCUTORTURE_RDR_SCHED;\n\tunsigned long preempts_irq = preempts | RCUTORTURE_RDR_IRQ;\n\tunsigned long bhs = RCUTORTURE_RDR_BH | RCUTORTURE_RDR_RBH;\n\n\tWARN_ON_ONCE(mask >> RCUTORTURE_RDR_SHIFT_1);\n\t \n\tif (!(randmask1 & 0x7))\n\t\tmask = mask & randmask2;\n\telse\n\t\tmask = mask & (1 << (randmask2 % RCUTORTURE_RDR_NBITS));\n\n\t \n\tif (!(mask & RCUTORTURE_RDR_RCU_1) && (mask & RCUTORTURE_RDR_RCU_2)) {\n\t\tif (oldmask & RCUTORTURE_RDR_RCU_1)\n\t\t\tmask &= ~RCUTORTURE_RDR_RCU_2;\n\t\telse\n\t\t\tmask |= RCUTORTURE_RDR_RCU_1;\n\t}\n\n\t \n\tif (mask & RCUTORTURE_RDR_IRQ)\n\t\tmask |= oldmask & bhs;\n\n\t \n\tif (IS_ENABLED(CONFIG_PREEMPT_RT)) {\n\t\t \n\t\tif (oldmask & preempts_irq)\n\t\t\tmask &= ~bhs;\n\t\tif ((oldmask | mask) & preempts_irq)\n\t\t\tmask |= oldmask & bhs;\n\t}\n\n\treturn mask ?: RCUTORTURE_RDR_RCU_1;\n}\n\n \nstatic struct rt_read_seg *\nrcutorture_loop_extend(int *readstate, struct torture_random_state *trsp,\n\t\t       struct rt_read_seg *rtrsp)\n{\n\tint i;\n\tint j;\n\tint mask = rcutorture_extend_mask_max();\n\n\tWARN_ON_ONCE(!*readstate);  \n\tif (!((mask - 1) & mask))\n\t\treturn rtrsp;   \n\t \n\ti = torture_random(trsp);\n\ti = ((i | (i >> 3)) & RCUTORTURE_RDR_MAX_LOOPS) + 1;\n\tfor (j = 0; j < i; j++) {\n\t\tmask = rcutorture_extend_mask(*readstate, trsp);\n\t\trcutorture_one_extend(readstate, mask, trsp, &rtrsp[j]);\n\t}\n\treturn &rtrsp[j];\n}\n\n \nstatic bool rcu_torture_one_read(struct torture_random_state *trsp, long myid)\n{\n\tbool checkpolling = !(torture_random(trsp) & 0xfff);\n\tunsigned long cookie;\n\tstruct rcu_gp_oldstate cookie_full;\n\tint i;\n\tunsigned long started;\n\tunsigned long completed;\n\tint newstate;\n\tstruct rcu_torture *p;\n\tint pipe_count;\n\tint readstate = 0;\n\tstruct rt_read_seg rtseg[RCUTORTURE_RDR_MAX_SEGS] = { { 0 } };\n\tstruct rt_read_seg *rtrsp = &rtseg[0];\n\tstruct rt_read_seg *rtrsp1;\n\tunsigned long long ts;\n\n\tWARN_ON_ONCE(!rcu_is_watching());\n\tnewstate = rcutorture_extend_mask(readstate, trsp);\n\trcutorture_one_extend(&readstate, newstate, trsp, rtrsp++);\n\tif (checkpolling) {\n\t\tif (cur_ops->get_gp_state && cur_ops->poll_gp_state)\n\t\t\tcookie = cur_ops->get_gp_state();\n\t\tif (cur_ops->get_gp_state_full && cur_ops->poll_gp_state_full)\n\t\t\tcur_ops->get_gp_state_full(&cookie_full);\n\t}\n\tstarted = cur_ops->get_gp_seq();\n\tts = rcu_trace_clock_local();\n\tp = rcu_dereference_check(rcu_torture_current,\n\t\t\t\t  !cur_ops->readlock_held || cur_ops->readlock_held());\n\tif (p == NULL) {\n\t\t \n\t\trcutorture_one_extend(&readstate, 0, trsp, rtrsp);\n\t\treturn false;\n\t}\n\tif (p->rtort_mbtest == 0)\n\t\tatomic_inc(&n_rcu_torture_mberror);\n\trcu_torture_reader_do_mbchk(myid, p, trsp);\n\trtrsp = rcutorture_loop_extend(&readstate, trsp, rtrsp);\n\tpreempt_disable();\n\tpipe_count = READ_ONCE(p->rtort_pipe_count);\n\tif (pipe_count > RCU_TORTURE_PIPE_LEN) {\n\t\t \n\t\tpipe_count = RCU_TORTURE_PIPE_LEN;\n\t}\n\tcompleted = cur_ops->get_gp_seq();\n\tif (pipe_count > 1) {\n\t\tdo_trace_rcu_torture_read(cur_ops->name, &p->rtort_rcu,\n\t\t\t\t\t  ts, started, completed);\n\t\trcu_ftrace_dump(DUMP_ALL);\n\t}\n\t__this_cpu_inc(rcu_torture_count[pipe_count]);\n\tcompleted = rcutorture_seq_diff(completed, started);\n\tif (completed > RCU_TORTURE_PIPE_LEN) {\n\t\t \n\t\tcompleted = RCU_TORTURE_PIPE_LEN;\n\t}\n\t__this_cpu_inc(rcu_torture_batch[completed]);\n\tpreempt_enable();\n\tif (checkpolling) {\n\t\tif (cur_ops->get_gp_state && cur_ops->poll_gp_state)\n\t\t\tWARN_ONCE(cur_ops->poll_gp_state(cookie),\n\t\t\t\t  \"%s: Cookie check 2 failed %s(%d) %lu->%lu\\n\",\n\t\t\t\t  __func__,\n\t\t\t\t  rcu_torture_writer_state_getname(),\n\t\t\t\t  rcu_torture_writer_state,\n\t\t\t\t  cookie, cur_ops->get_gp_state());\n\t\tif (cur_ops->get_gp_state_full && cur_ops->poll_gp_state_full)\n\t\t\tWARN_ONCE(cur_ops->poll_gp_state_full(&cookie_full),\n\t\t\t\t  \"%s: Cookie check 6 failed %s(%d) online %*pbl\\n\",\n\t\t\t\t  __func__,\n\t\t\t\t  rcu_torture_writer_state_getname(),\n\t\t\t\t  rcu_torture_writer_state,\n\t\t\t\t  cpumask_pr_args(cpu_online_mask));\n\t}\n\trcutorture_one_extend(&readstate, 0, trsp, rtrsp);\n\tWARN_ON_ONCE(readstate);\n\t \n\t \n\tWARN_ON_ONCE(leakpointer && READ_ONCE(p->rtort_pipe_count) > 1);\n\n\t \n\tif ((pipe_count > 1 || completed > 1) && !xchg(&err_segs_recorded, 1)) {\n\t\ti = 0;\n\t\tfor (rtrsp1 = &rtseg[0]; rtrsp1 < rtrsp; rtrsp1++)\n\t\t\terr_segs[i++] = *rtrsp1;\n\t\trt_read_nsegs = i;\n\t}\n\n\treturn true;\n}\n\nstatic DEFINE_TORTURE_RANDOM_PERCPU(rcu_torture_timer_rand);\n\n \nstatic void rcu_torture_timer(struct timer_list *unused)\n{\n\tatomic_long_inc(&n_rcu_torture_timers);\n\t(void)rcu_torture_one_read(this_cpu_ptr(&rcu_torture_timer_rand), -1);\n\n\t \n\tif (cur_ops->call) {\n\t\tstruct rcu_head *rhp = kmalloc(sizeof(*rhp), GFP_NOWAIT);\n\n\t\tif (rhp)\n\t\t\tcur_ops->call(rhp, rcu_torture_timer_cb);\n\t}\n}\n\n \nstatic int\nrcu_torture_reader(void *arg)\n{\n\tunsigned long lastsleep = jiffies;\n\tlong myid = (long)arg;\n\tint mynumonline = myid;\n\tDEFINE_TORTURE_RANDOM(rand);\n\tstruct timer_list t;\n\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_reader task started\");\n\tset_user_nice(current, MAX_NICE);\n\tif (irqreader && cur_ops->irq_capable)\n\t\ttimer_setup_on_stack(&t, rcu_torture_timer, 0);\n\ttick_dep_set_task(current, TICK_DEP_BIT_RCU);\n\tdo {\n\t\tif (irqreader && cur_ops->irq_capable) {\n\t\t\tif (!timer_pending(&t))\n\t\t\t\tmod_timer(&t, jiffies + 1);\n\t\t}\n\t\tif (!rcu_torture_one_read(&rand, myid) && !torture_must_stop())\n\t\t\tschedule_timeout_interruptible(HZ);\n\t\tif (time_after(jiffies, lastsleep) && !torture_must_stop()) {\n\t\t\ttorture_hrtimeout_us(500, 1000, &rand);\n\t\t\tlastsleep = jiffies + 10;\n\t\t}\n\t\twhile (torture_num_online_cpus() < mynumonline && !torture_must_stop())\n\t\t\tschedule_timeout_interruptible(HZ / 5);\n\t\tstutter_wait(\"rcu_torture_reader\");\n\t} while (!torture_must_stop());\n\tif (irqreader && cur_ops->irq_capable) {\n\t\tdel_timer_sync(&t);\n\t\tdestroy_timer_on_stack(&t);\n\t}\n\ttick_dep_clear_task(current, TICK_DEP_BIT_RCU);\n\ttorture_kthread_stopping(\"rcu_torture_reader\");\n\treturn 0;\n}\n\n \nstatic int rcu_nocb_toggle(void *arg)\n{\n\tint cpu;\n\tint maxcpu = -1;\n\tint oldnice = task_nice(current);\n\tlong r;\n\tDEFINE_TORTURE_RANDOM(rand);\n\tktime_t toggle_delay;\n\tunsigned long toggle_fuzz;\n\tktime_t toggle_interval = ms_to_ktime(nocbs_toggle);\n\n\tVERBOSE_TOROUT_STRING(\"rcu_nocb_toggle task started\");\n\twhile (!rcu_inkernel_boot_has_ended())\n\t\tschedule_timeout_interruptible(HZ / 10);\n\tfor_each_online_cpu(cpu)\n\t\tmaxcpu = cpu;\n\tWARN_ON(maxcpu < 0);\n\tif (toggle_interval > ULONG_MAX)\n\t\ttoggle_fuzz = ULONG_MAX >> 3;\n\telse\n\t\ttoggle_fuzz = toggle_interval >> 3;\n\tif (toggle_fuzz <= 0)\n\t\ttoggle_fuzz = NSEC_PER_USEC;\n\tdo {\n\t\tr = torture_random(&rand);\n\t\tcpu = (r >> 1) % (maxcpu + 1);\n\t\tif (r & 0x1) {\n\t\t\trcu_nocb_cpu_offload(cpu);\n\t\t\tatomic_long_inc(&n_nocb_offload);\n\t\t} else {\n\t\t\trcu_nocb_cpu_deoffload(cpu);\n\t\t\tatomic_long_inc(&n_nocb_deoffload);\n\t\t}\n\t\ttoggle_delay = torture_random(&rand) % toggle_fuzz + toggle_interval;\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tschedule_hrtimeout(&toggle_delay, HRTIMER_MODE_REL);\n\t\tif (stutter_wait(\"rcu_nocb_toggle\"))\n\t\t\tsched_set_normal(current, oldnice);\n\t} while (!torture_must_stop());\n\ttorture_kthread_stopping(\"rcu_nocb_toggle\");\n\treturn 0;\n}\n\n \nstatic void\nrcu_torture_stats_print(void)\n{\n\tint cpu;\n\tint i;\n\tlong pipesummary[RCU_TORTURE_PIPE_LEN + 1] = { 0 };\n\tlong batchsummary[RCU_TORTURE_PIPE_LEN + 1] = { 0 };\n\tstruct rcu_torture *rtcp;\n\tstatic unsigned long rtcv_snap = ULONG_MAX;\n\tstatic bool splatted;\n\tstruct task_struct *wtp;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++) {\n\t\t\tpipesummary[i] += READ_ONCE(per_cpu(rcu_torture_count, cpu)[i]);\n\t\t\tbatchsummary[i] += READ_ONCE(per_cpu(rcu_torture_batch, cpu)[i]);\n\t\t}\n\t}\n\tfor (i = RCU_TORTURE_PIPE_LEN; i >= 0; i--) {\n\t\tif (pipesummary[i] != 0)\n\t\t\tbreak;\n\t}\n\n\tpr_alert(\"%s%s \", torture_type, TORTURE_FLAG);\n\trtcp = rcu_access_pointer(rcu_torture_current);\n\tpr_cont(\"rtc: %p %s: %lu tfle: %d rta: %d rtaf: %d rtf: %d \",\n\t\trtcp,\n\t\trtcp && !rcu_stall_is_suppressed_at_boot() ? \"ver\" : \"VER\",\n\t\trcu_torture_current_version,\n\t\tlist_empty(&rcu_torture_freelist),\n\t\tatomic_read(&n_rcu_torture_alloc),\n\t\tatomic_read(&n_rcu_torture_alloc_fail),\n\t\tatomic_read(&n_rcu_torture_free));\n\tpr_cont(\"rtmbe: %d rtmbkf: %d/%d rtbe: %ld rtbke: %ld \",\n\t\tatomic_read(&n_rcu_torture_mberror),\n\t\tatomic_read(&n_rcu_torture_mbchk_fail), atomic_read(&n_rcu_torture_mbchk_tries),\n\t\tn_rcu_torture_barrier_error,\n\t\tn_rcu_torture_boost_ktrerror);\n\tpr_cont(\"rtbf: %ld rtb: %ld nt: %ld \",\n\t\tn_rcu_torture_boost_failure,\n\t\tn_rcu_torture_boosts,\n\t\tatomic_long_read(&n_rcu_torture_timers));\n\ttorture_onoff_stats();\n\tpr_cont(\"barrier: %ld/%ld:%ld \",\n\t\tdata_race(n_barrier_successes),\n\t\tdata_race(n_barrier_attempts),\n\t\tdata_race(n_rcu_torture_barrier_error));\n\tpr_cont(\"read-exits: %ld \", data_race(n_read_exits)); \n\tpr_cont(\"nocb-toggles: %ld:%ld\\n\",\n\t\tatomic_long_read(&n_nocb_offload), atomic_long_read(&n_nocb_deoffload));\n\n\tpr_alert(\"%s%s \", torture_type, TORTURE_FLAG);\n\tif (atomic_read(&n_rcu_torture_mberror) ||\n\t    atomic_read(&n_rcu_torture_mbchk_fail) ||\n\t    n_rcu_torture_barrier_error || n_rcu_torture_boost_ktrerror ||\n\t    n_rcu_torture_boost_failure || i > 1) {\n\t\tpr_cont(\"%s\", \"!!! \");\n\t\tatomic_inc(&n_rcu_torture_error);\n\t\tWARN_ON_ONCE(atomic_read(&n_rcu_torture_mberror));\n\t\tWARN_ON_ONCE(atomic_read(&n_rcu_torture_mbchk_fail));\n\t\tWARN_ON_ONCE(n_rcu_torture_barrier_error);  \n\t\tWARN_ON_ONCE(n_rcu_torture_boost_ktrerror); \n\t\tWARN_ON_ONCE(n_rcu_torture_boost_failure); \n\t\tWARN_ON_ONCE(i > 1); \n\t}\n\tpr_cont(\"Reader Pipe: \");\n\tfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++)\n\t\tpr_cont(\" %ld\", pipesummary[i]);\n\tpr_cont(\"\\n\");\n\n\tpr_alert(\"%s%s \", torture_type, TORTURE_FLAG);\n\tpr_cont(\"Reader Batch: \");\n\tfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++)\n\t\tpr_cont(\" %ld\", batchsummary[i]);\n\tpr_cont(\"\\n\");\n\n\tpr_alert(\"%s%s \", torture_type, TORTURE_FLAG);\n\tpr_cont(\"Free-Block Circulation: \");\n\tfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++) {\n\t\tpr_cont(\" %d\", atomic_read(&rcu_torture_wcount[i]));\n\t}\n\tpr_cont(\"\\n\");\n\n\tif (cur_ops->stats)\n\t\tcur_ops->stats();\n\tif (rtcv_snap == rcu_torture_current_version &&\n\t    rcu_access_pointer(rcu_torture_current) &&\n\t    !rcu_stall_is_suppressed()) {\n\t\tint __maybe_unused flags = 0;\n\t\tunsigned long __maybe_unused gp_seq = 0;\n\n\t\trcutorture_get_gp_data(cur_ops->ttype,\n\t\t\t\t       &flags, &gp_seq);\n\t\tsrcutorture_get_gp_data(cur_ops->ttype, srcu_ctlp,\n\t\t\t\t\t&flags, &gp_seq);\n\t\twtp = READ_ONCE(writer_task);\n\t\tpr_alert(\"??? Writer stall state %s(%d) g%lu f%#x ->state %#x cpu %d\\n\",\n\t\t\t rcu_torture_writer_state_getname(),\n\t\t\t rcu_torture_writer_state, gp_seq, flags,\n\t\t\t wtp == NULL ? ~0U : wtp->__state,\n\t\t\t wtp == NULL ? -1 : (int)task_cpu(wtp));\n\t\tif (!splatted && wtp) {\n\t\t\tsched_show_task(wtp);\n\t\t\tsplatted = true;\n\t\t}\n\t\tif (cur_ops->gp_kthread_dbg)\n\t\t\tcur_ops->gp_kthread_dbg();\n\t\trcu_ftrace_dump(DUMP_ALL);\n\t}\n\trtcv_snap = rcu_torture_current_version;\n}\n\n \nstatic int\nrcu_torture_stats(void *arg)\n{\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_stats task started\");\n\tdo {\n\t\tschedule_timeout_interruptible(stat_interval * HZ);\n\t\trcu_torture_stats_print();\n\t\ttorture_shutdown_absorb(\"rcu_torture_stats\");\n\t} while (!torture_must_stop());\n\ttorture_kthread_stopping(\"rcu_torture_stats\");\n\treturn 0;\n}\n\n \nstatic void rcu_torture_mem_dump_obj(void)\n{\n\tstruct rcu_head *rhp;\n\tstruct kmem_cache *kcp;\n\tstatic int z;\n\n\tkcp = kmem_cache_create(\"rcuscale\", 136, 8, SLAB_STORE_USER, NULL);\n\tif (WARN_ON_ONCE(!kcp))\n\t\treturn;\n\trhp = kmem_cache_alloc(kcp, GFP_KERNEL);\n\tif (WARN_ON_ONCE(!rhp)) {\n\t\tkmem_cache_destroy(kcp);\n\t\treturn;\n\t}\n\tpr_alert(\"mem_dump_obj() slab test: rcu_torture_stats = %px, &rhp = %px, rhp = %px, &z = %px\\n\", stats_task, &rhp, rhp, &z);\n\tpr_alert(\"mem_dump_obj(ZERO_SIZE_PTR):\");\n\tmem_dump_obj(ZERO_SIZE_PTR);\n\tpr_alert(\"mem_dump_obj(NULL):\");\n\tmem_dump_obj(NULL);\n\tpr_alert(\"mem_dump_obj(%px):\", &rhp);\n\tmem_dump_obj(&rhp);\n\tpr_alert(\"mem_dump_obj(%px):\", rhp);\n\tmem_dump_obj(rhp);\n\tpr_alert(\"mem_dump_obj(%px):\", &rhp->func);\n\tmem_dump_obj(&rhp->func);\n\tpr_alert(\"mem_dump_obj(%px):\", &z);\n\tmem_dump_obj(&z);\n\tkmem_cache_free(kcp, rhp);\n\tkmem_cache_destroy(kcp);\n\trhp = kmalloc(sizeof(*rhp), GFP_KERNEL);\n\tif (WARN_ON_ONCE(!rhp))\n\t\treturn;\n\tpr_alert(\"mem_dump_obj() kmalloc test: rcu_torture_stats = %px, &rhp = %px, rhp = %px\\n\", stats_task, &rhp, rhp);\n\tpr_alert(\"mem_dump_obj(kmalloc %px):\", rhp);\n\tmem_dump_obj(rhp);\n\tpr_alert(\"mem_dump_obj(kmalloc %px):\", &rhp->func);\n\tmem_dump_obj(&rhp->func);\n\tkfree(rhp);\n\trhp = vmalloc(4096);\n\tif (WARN_ON_ONCE(!rhp))\n\t\treturn;\n\tpr_alert(\"mem_dump_obj() vmalloc test: rcu_torture_stats = %px, &rhp = %px, rhp = %px\\n\", stats_task, &rhp, rhp);\n\tpr_alert(\"mem_dump_obj(vmalloc %px):\", rhp);\n\tmem_dump_obj(rhp);\n\tpr_alert(\"mem_dump_obj(vmalloc %px):\", &rhp->func);\n\tmem_dump_obj(&rhp->func);\n\tvfree(rhp);\n}\n\nstatic void\nrcu_torture_print_module_parms(struct rcu_torture_ops *cur_ops, const char *tag)\n{\n\tpr_alert(\"%s\" TORTURE_FLAG\n\t\t \"--- %s: nreaders=%d nfakewriters=%d \"\n\t\t \"stat_interval=%d verbose=%d test_no_idle_hz=%d \"\n\t\t \"shuffle_interval=%d stutter=%d irqreader=%d \"\n\t\t \"fqs_duration=%d fqs_holdoff=%d fqs_stutter=%d \"\n\t\t \"test_boost=%d/%d test_boost_interval=%d \"\n\t\t \"test_boost_duration=%d shutdown_secs=%d \"\n\t\t \"stall_cpu=%d stall_cpu_holdoff=%d stall_cpu_irqsoff=%d \"\n\t\t \"stall_cpu_block=%d \"\n\t\t \"n_barrier_cbs=%d \"\n\t\t \"onoff_interval=%d onoff_holdoff=%d \"\n\t\t \"read_exit_delay=%d read_exit_burst=%d \"\n\t\t \"nocbs_nthreads=%d nocbs_toggle=%d \"\n\t\t \"test_nmis=%d\\n\",\n\t\t torture_type, tag, nrealreaders, nfakewriters,\n\t\t stat_interval, verbose, test_no_idle_hz, shuffle_interval,\n\t\t stutter, irqreader, fqs_duration, fqs_holdoff, fqs_stutter,\n\t\t test_boost, cur_ops->can_boost,\n\t\t test_boost_interval, test_boost_duration, shutdown_secs,\n\t\t stall_cpu, stall_cpu_holdoff, stall_cpu_irqsoff,\n\t\t stall_cpu_block,\n\t\t n_barrier_cbs,\n\t\t onoff_interval, onoff_holdoff,\n\t\t read_exit_delay, read_exit_burst,\n\t\t nocbs_nthreads, nocbs_toggle,\n\t\t test_nmis);\n}\n\nstatic int rcutorture_booster_cleanup(unsigned int cpu)\n{\n\tstruct task_struct *t;\n\n\tif (boost_tasks[cpu] == NULL)\n\t\treturn 0;\n\tmutex_lock(&boost_mutex);\n\tt = boost_tasks[cpu];\n\tboost_tasks[cpu] = NULL;\n\trcu_torture_enable_rt_throttle();\n\tmutex_unlock(&boost_mutex);\n\n\t \n\ttorture_stop_kthread(rcu_torture_boost, t);\n\treturn 0;\n}\n\nstatic int rcutorture_booster_init(unsigned int cpu)\n{\n\tint retval;\n\n\tif (boost_tasks[cpu] != NULL)\n\t\treturn 0;   \n\n\t\n\t\n\t\n\tif (IS_BUILTIN(CONFIG_RCU_TORTURE_TEST)) {\n\t\tstruct sched_param sp;\n\t\tstruct task_struct *t;\n\n\t\tt = per_cpu(ksoftirqd, cpu);\n\t\tWARN_ON_ONCE(!t);\n\t\tsp.sched_priority = 2;\n\t\tsched_setscheduler_nocheck(t, SCHED_FIFO, &sp);\n\t}\n\n\t \n\tmutex_lock(&boost_mutex);\n\trcu_torture_disable_rt_throttle();\n\tVERBOSE_TOROUT_STRING(\"Creating rcu_torture_boost task\");\n\tboost_tasks[cpu] = kthread_run_on_cpu(rcu_torture_boost, NULL,\n\t\t\t\t\t      cpu, \"rcu_torture_boost_%u\");\n\tif (IS_ERR(boost_tasks[cpu])) {\n\t\tretval = PTR_ERR(boost_tasks[cpu]);\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_boost task create failed\");\n\t\tn_rcu_torture_boost_ktrerror++;\n\t\tboost_tasks[cpu] = NULL;\n\t\tmutex_unlock(&boost_mutex);\n\t\treturn retval;\n\t}\n\tmutex_unlock(&boost_mutex);\n\treturn 0;\n}\n\n \nstatic int rcu_torture_stall(void *args)\n{\n\tint idx;\n\tunsigned long stop_at;\n\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_stall task started\");\n\tif (stall_cpu_holdoff > 0) {\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_stall begin holdoff\");\n\t\tschedule_timeout_interruptible(stall_cpu_holdoff * HZ);\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_stall end holdoff\");\n\t}\n\tif (!kthread_should_stop() && stall_gp_kthread > 0) {\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_stall begin GP stall\");\n\t\trcu_gp_set_torture_wait(stall_gp_kthread * HZ);\n\t\tfor (idx = 0; idx < stall_gp_kthread + 2; idx++) {\n\t\t\tif (kthread_should_stop())\n\t\t\t\tbreak;\n\t\t\tschedule_timeout_uninterruptible(HZ);\n\t\t}\n\t}\n\tif (!kthread_should_stop() && stall_cpu > 0) {\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_stall begin CPU stall\");\n\t\tstop_at = ktime_get_seconds() + stall_cpu;\n\t\t \n\t\tidx = cur_ops->readlock();\n\t\tif (stall_cpu_irqsoff)\n\t\t\tlocal_irq_disable();\n\t\telse if (!stall_cpu_block)\n\t\t\tpreempt_disable();\n\t\tpr_alert(\"%s start on CPU %d.\\n\",\n\t\t\t  __func__, raw_smp_processor_id());\n\t\twhile (ULONG_CMP_LT((unsigned long)ktime_get_seconds(),\n\t\t\t\t    stop_at))\n\t\t\tif (stall_cpu_block) {\n#ifdef CONFIG_PREEMPTION\n\t\t\t\tpreempt_schedule();\n#else\n\t\t\t\tschedule_timeout_uninterruptible(HZ);\n#endif\n\t\t\t} else if (stall_no_softlockup) {\n\t\t\t\ttouch_softlockup_watchdog();\n\t\t\t}\n\t\tif (stall_cpu_irqsoff)\n\t\t\tlocal_irq_enable();\n\t\telse if (!stall_cpu_block)\n\t\t\tpreempt_enable();\n\t\tcur_ops->readunlock(idx);\n\t}\n\tpr_alert(\"%s end.\\n\", __func__);\n\ttorture_shutdown_absorb(\"rcu_torture_stall\");\n\twhile (!kthread_should_stop())\n\t\tschedule_timeout_interruptible(10 * HZ);\n\treturn 0;\n}\n\n \nstatic int __init rcu_torture_stall_init(void)\n{\n\tif (stall_cpu <= 0 && stall_gp_kthread <= 0)\n\t\treturn 0;\n\treturn torture_create_kthread(rcu_torture_stall, NULL, stall_task);\n}\n\n \nstruct fwd_cb_state {\n\tstruct rcu_head rh;\n\tint stop;\n};\n\n \nstatic void rcu_torture_fwd_prog_cb(struct rcu_head *rhp)\n{\n\tstruct fwd_cb_state *fcsp = container_of(rhp, struct fwd_cb_state, rh);\n\n\tif (READ_ONCE(fcsp->stop)) {\n\t\tWRITE_ONCE(fcsp->stop, 2);\n\t\treturn;\n\t}\n\tcur_ops->call(&fcsp->rh, rcu_torture_fwd_prog_cb);\n}\n\n \nstruct rcu_fwd_cb {\n\tstruct rcu_head rh;\n\tstruct rcu_fwd_cb *rfc_next;\n\tstruct rcu_fwd *rfc_rfp;\n\tint rfc_gps;\n};\n\n#define MAX_FWD_CB_JIFFIES\t(8 * HZ)  \n#define MIN_FWD_CB_LAUNDERS\t3\t \n#define MIN_FWD_CBS_LAUNDERED\t100\t \n#define FWD_CBS_HIST_DIV\t10\t \n#define N_LAUNDERS_HIST (2 * MAX_FWD_CB_JIFFIES / (HZ / FWD_CBS_HIST_DIV))\n\nstruct rcu_launder_hist {\n\tlong n_launders;\n\tunsigned long launder_gp_seq;\n};\n\nstruct rcu_fwd {\n\tspinlock_t rcu_fwd_lock;\n\tstruct rcu_fwd_cb *rcu_fwd_cb_head;\n\tstruct rcu_fwd_cb **rcu_fwd_cb_tail;\n\tlong n_launders_cb;\n\tunsigned long rcu_fwd_startat;\n\tstruct rcu_launder_hist n_launders_hist[N_LAUNDERS_HIST];\n\tunsigned long rcu_launder_gp_seq_start;\n\tint rcu_fwd_id;\n};\n\nstatic DEFINE_MUTEX(rcu_fwd_mutex);\nstatic struct rcu_fwd *rcu_fwds;\nstatic unsigned long rcu_fwd_seq;\nstatic atomic_long_t rcu_fwd_max_cbs;\nstatic bool rcu_fwd_emergency_stop;\n\nstatic void rcu_torture_fwd_cb_hist(struct rcu_fwd *rfp)\n{\n\tunsigned long gps;\n\tunsigned long gps_old;\n\tint i;\n\tint j;\n\n\tfor (i = ARRAY_SIZE(rfp->n_launders_hist) - 1; i > 0; i--)\n\t\tif (rfp->n_launders_hist[i].n_launders > 0)\n\t\t\tbreak;\n\tpr_alert(\"%s: Callback-invocation histogram %d (duration %lu jiffies):\",\n\t\t __func__, rfp->rcu_fwd_id, jiffies - rfp->rcu_fwd_startat);\n\tgps_old = rfp->rcu_launder_gp_seq_start;\n\tfor (j = 0; j <= i; j++) {\n\t\tgps = rfp->n_launders_hist[j].launder_gp_seq;\n\t\tpr_cont(\" %ds/%d: %ld:%ld\",\n\t\t\tj + 1, FWD_CBS_HIST_DIV,\n\t\t\trfp->n_launders_hist[j].n_launders,\n\t\t\trcutorture_seq_diff(gps, gps_old));\n\t\tgps_old = gps;\n\t}\n\tpr_cont(\"\\n\");\n}\n\n \nstatic void rcu_torture_fwd_cb_cr(struct rcu_head *rhp)\n{\n\tunsigned long flags;\n\tint i;\n\tstruct rcu_fwd_cb *rfcp = container_of(rhp, struct rcu_fwd_cb, rh);\n\tstruct rcu_fwd_cb **rfcpp;\n\tstruct rcu_fwd *rfp = rfcp->rfc_rfp;\n\n\trfcp->rfc_next = NULL;\n\trfcp->rfc_gps++;\n\tspin_lock_irqsave(&rfp->rcu_fwd_lock, flags);\n\trfcpp = rfp->rcu_fwd_cb_tail;\n\trfp->rcu_fwd_cb_tail = &rfcp->rfc_next;\n\tWRITE_ONCE(*rfcpp, rfcp);\n\tWRITE_ONCE(rfp->n_launders_cb, rfp->n_launders_cb + 1);\n\ti = ((jiffies - rfp->rcu_fwd_startat) / (HZ / FWD_CBS_HIST_DIV));\n\tif (i >= ARRAY_SIZE(rfp->n_launders_hist))\n\t\ti = ARRAY_SIZE(rfp->n_launders_hist) - 1;\n\trfp->n_launders_hist[i].n_launders++;\n\trfp->n_launders_hist[i].launder_gp_seq = cur_ops->get_gp_seq();\n\tspin_unlock_irqrestore(&rfp->rcu_fwd_lock, flags);\n}\n\n \nstatic void rcu_torture_fwd_prog_cond_resched(unsigned long iter)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPTION) && IS_ENABLED(CONFIG_NO_HZ_FULL)) {\n\t\t \n\t\tif (need_resched() || (iter & 0xfff))\n\t\t\tschedule();\n\t\treturn;\n\t}\n\t \n\tcond_resched();\n}\n\n \nstatic unsigned long rcu_torture_fwd_prog_cbfree(struct rcu_fwd *rfp)\n{\n\tunsigned long flags;\n\tunsigned long freed = 0;\n\tstruct rcu_fwd_cb *rfcp;\n\n\tfor (;;) {\n\t\tspin_lock_irqsave(&rfp->rcu_fwd_lock, flags);\n\t\trfcp = rfp->rcu_fwd_cb_head;\n\t\tif (!rfcp) {\n\t\t\tspin_unlock_irqrestore(&rfp->rcu_fwd_lock, flags);\n\t\t\tbreak;\n\t\t}\n\t\trfp->rcu_fwd_cb_head = rfcp->rfc_next;\n\t\tif (!rfp->rcu_fwd_cb_head)\n\t\t\trfp->rcu_fwd_cb_tail = &rfp->rcu_fwd_cb_head;\n\t\tspin_unlock_irqrestore(&rfp->rcu_fwd_lock, flags);\n\t\tkfree(rfcp);\n\t\tfreed++;\n\t\trcu_torture_fwd_prog_cond_resched(freed);\n\t\tif (tick_nohz_full_enabled()) {\n\t\t\tlocal_irq_save(flags);\n\t\t\trcu_momentary_dyntick_idle();\n\t\t\tlocal_irq_restore(flags);\n\t\t}\n\t}\n\treturn freed;\n}\n\n \nstatic void rcu_torture_fwd_prog_nr(struct rcu_fwd *rfp,\n\t\t\t\t    int *tested, int *tested_tries)\n{\n\tunsigned long cver;\n\tunsigned long dur;\n\tstruct fwd_cb_state fcs;\n\tunsigned long gps;\n\tint idx;\n\tint sd;\n\tint sd4;\n\tbool selfpropcb = false;\n\tunsigned long stopat;\n\tstatic DEFINE_TORTURE_RANDOM(trs);\n\n\tpr_alert(\"%s: Starting forward-progress test %d\\n\", __func__, rfp->rcu_fwd_id);\n\tif (!cur_ops->sync)\n\t\treturn;  \n\tif (cur_ops->call && cur_ops->cb_barrier) {\n\t\tinit_rcu_head_on_stack(&fcs.rh);\n\t\tselfpropcb = true;\n\t}\n\n\t \n\tatomic_inc(&rcu_fwd_cb_nodelay);\n\tcur_ops->sync();  \n\tif  (selfpropcb) {\n\t\tWRITE_ONCE(fcs.stop, 0);\n\t\tcur_ops->call(&fcs.rh, rcu_torture_fwd_prog_cb);\n\t}\n\tcver = READ_ONCE(rcu_torture_current_version);\n\tgps = cur_ops->get_gp_seq();\n\tsd = cur_ops->stall_dur() + 1;\n\tsd4 = (sd + fwd_progress_div - 1) / fwd_progress_div;\n\tdur = sd4 + torture_random(&trs) % (sd - sd4);\n\tWRITE_ONCE(rfp->rcu_fwd_startat, jiffies);\n\tstopat = rfp->rcu_fwd_startat + dur;\n\twhile (time_before(jiffies, stopat) &&\n\t       !shutdown_time_arrived() &&\n\t       !READ_ONCE(rcu_fwd_emergency_stop) && !torture_must_stop()) {\n\t\tidx = cur_ops->readlock();\n\t\tudelay(10);\n\t\tcur_ops->readunlock(idx);\n\t\tif (!fwd_progress_need_resched || need_resched())\n\t\t\tcond_resched();\n\t}\n\t(*tested_tries)++;\n\tif (!time_before(jiffies, stopat) &&\n\t    !shutdown_time_arrived() &&\n\t    !READ_ONCE(rcu_fwd_emergency_stop) && !torture_must_stop()) {\n\t\t(*tested)++;\n\t\tcver = READ_ONCE(rcu_torture_current_version) - cver;\n\t\tgps = rcutorture_seq_diff(cur_ops->get_gp_seq(), gps);\n\t\tWARN_ON(!cver && gps < 2);\n\t\tpr_alert(\"%s: %d Duration %ld cver %ld gps %ld\\n\", __func__,\n\t\t\t rfp->rcu_fwd_id, dur, cver, gps);\n\t}\n\tif (selfpropcb) {\n\t\tWRITE_ONCE(fcs.stop, 1);\n\t\tcur_ops->sync();  \n\t\tpr_alert(\"%s: Waiting for CBs: %pS() %d\\n\", __func__, cur_ops->cb_barrier, rfp->rcu_fwd_id);\n\t\tcur_ops->cb_barrier();  \n\t}\n\n\tif (selfpropcb) {\n\t\tWARN_ON(READ_ONCE(fcs.stop) != 2);\n\t\tdestroy_rcu_head_on_stack(&fcs.rh);\n\t}\n\tschedule_timeout_uninterruptible(HZ / 10);  \n\tatomic_dec(&rcu_fwd_cb_nodelay);\n}\n\n \nstatic void rcu_torture_fwd_prog_cr(struct rcu_fwd *rfp)\n{\n\tunsigned long cver;\n\tunsigned long flags;\n\tunsigned long gps;\n\tint i;\n\tlong n_launders;\n\tlong n_launders_cb_snap;\n\tlong n_launders_sa;\n\tlong n_max_cbs;\n\tlong n_max_gps;\n\tstruct rcu_fwd_cb *rfcp;\n\tstruct rcu_fwd_cb *rfcpn;\n\tunsigned long stopat;\n\tunsigned long stoppedat;\n\n\tpr_alert(\"%s: Starting forward-progress test %d\\n\", __func__, rfp->rcu_fwd_id);\n\tif (READ_ONCE(rcu_fwd_emergency_stop))\n\t\treturn;  \n\tif (!cur_ops->call)\n\t\treturn;  \n\n\t \n\tatomic_inc(&rcu_fwd_cb_nodelay);\n\tcur_ops->sync();  \n\tWRITE_ONCE(rfp->rcu_fwd_startat, jiffies);\n\tstopat = rfp->rcu_fwd_startat + MAX_FWD_CB_JIFFIES;\n\tn_launders = 0;\n\trfp->n_launders_cb = 0; \n\tn_launders_sa = 0;\n\tn_max_cbs = 0;\n\tn_max_gps = 0;\n\tfor (i = 0; i < ARRAY_SIZE(rfp->n_launders_hist); i++)\n\t\trfp->n_launders_hist[i].n_launders = 0;\n\tcver = READ_ONCE(rcu_torture_current_version);\n\tgps = cur_ops->get_gp_seq();\n\trfp->rcu_launder_gp_seq_start = gps;\n\ttick_dep_set_task(current, TICK_DEP_BIT_RCU);\n\twhile (time_before(jiffies, stopat) &&\n\t       !shutdown_time_arrived() &&\n\t       !READ_ONCE(rcu_fwd_emergency_stop) && !torture_must_stop()) {\n\t\trfcp = READ_ONCE(rfp->rcu_fwd_cb_head);\n\t\trfcpn = NULL;\n\t\tif (rfcp)\n\t\t\trfcpn = READ_ONCE(rfcp->rfc_next);\n\t\tif (rfcpn) {\n\t\t\tif (rfcp->rfc_gps >= MIN_FWD_CB_LAUNDERS &&\n\t\t\t    ++n_max_gps >= MIN_FWD_CBS_LAUNDERED)\n\t\t\t\tbreak;\n\t\t\trfp->rcu_fwd_cb_head = rfcpn;\n\t\t\tn_launders++;\n\t\t\tn_launders_sa++;\n\t\t} else if (!cur_ops->cbflood_max || cur_ops->cbflood_max > n_max_cbs) {\n\t\t\trfcp = kmalloc(sizeof(*rfcp), GFP_KERNEL);\n\t\t\tif (WARN_ON_ONCE(!rfcp)) {\n\t\t\t\tschedule_timeout_interruptible(1);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tn_max_cbs++;\n\t\t\tn_launders_sa = 0;\n\t\t\trfcp->rfc_gps = 0;\n\t\t\trfcp->rfc_rfp = rfp;\n\t\t} else {\n\t\t\trfcp = NULL;\n\t\t}\n\t\tif (rfcp)\n\t\t\tcur_ops->call(&rfcp->rh, rcu_torture_fwd_cb_cr);\n\t\trcu_torture_fwd_prog_cond_resched(n_launders + n_max_cbs);\n\t\tif (tick_nohz_full_enabled()) {\n\t\t\tlocal_irq_save(flags);\n\t\t\trcu_momentary_dyntick_idle();\n\t\t\tlocal_irq_restore(flags);\n\t\t}\n\t}\n\tstoppedat = jiffies;\n\tn_launders_cb_snap = READ_ONCE(rfp->n_launders_cb);\n\tcver = READ_ONCE(rcu_torture_current_version) - cver;\n\tgps = rcutorture_seq_diff(cur_ops->get_gp_seq(), gps);\n\tpr_alert(\"%s: Waiting for CBs: %pS() %d\\n\", __func__, cur_ops->cb_barrier, rfp->rcu_fwd_id);\n\tcur_ops->cb_barrier();  \n\t(void)rcu_torture_fwd_prog_cbfree(rfp);\n\n\tif (!torture_must_stop() && !READ_ONCE(rcu_fwd_emergency_stop) &&\n\t    !shutdown_time_arrived()) {\n\t\tWARN_ON(n_max_gps < MIN_FWD_CBS_LAUNDERED);\n\t\tpr_alert(\"%s Duration %lu barrier: %lu pending %ld n_launders: %ld n_launders_sa: %ld n_max_gps: %ld n_max_cbs: %ld cver %ld gps %ld\\n\",\n\t\t\t __func__,\n\t\t\t stoppedat - rfp->rcu_fwd_startat, jiffies - stoppedat,\n\t\t\t n_launders + n_max_cbs - n_launders_cb_snap,\n\t\t\t n_launders, n_launders_sa,\n\t\t\t n_max_gps, n_max_cbs, cver, gps);\n\t\tatomic_long_add(n_max_cbs, &rcu_fwd_max_cbs);\n\t\tmutex_lock(&rcu_fwd_mutex); \n\t\trcu_torture_fwd_cb_hist(rfp);\n\t\tmutex_unlock(&rcu_fwd_mutex);\n\t}\n\tschedule_timeout_uninterruptible(HZ);  \n\ttick_dep_clear_task(current, TICK_DEP_BIT_RCU);\n\tatomic_dec(&rcu_fwd_cb_nodelay);\n}\n\n\n \nstatic int rcutorture_oom_notify(struct notifier_block *self,\n\t\t\t\t unsigned long notused, void *nfreed)\n{\n\tint i;\n\tlong ncbs;\n\tstruct rcu_fwd *rfp;\n\n\tmutex_lock(&rcu_fwd_mutex);\n\trfp = rcu_fwds;\n\tif (!rfp) {\n\t\tmutex_unlock(&rcu_fwd_mutex);\n\t\treturn NOTIFY_OK;\n\t}\n\tWARN(1, \"%s invoked upon OOM during forward-progress testing.\\n\",\n\t     __func__);\n\tfor (i = 0; i < fwd_progress; i++) {\n\t\trcu_torture_fwd_cb_hist(&rfp[i]);\n\t\trcu_fwd_progress_check(1 + (jiffies - READ_ONCE(rfp[i].rcu_fwd_startat)) / 2);\n\t}\n\tWRITE_ONCE(rcu_fwd_emergency_stop, true);\n\tsmp_mb();  \n\tncbs = 0;\n\tfor (i = 0; i < fwd_progress; i++)\n\t\tncbs += rcu_torture_fwd_prog_cbfree(&rfp[i]);\n\tpr_info(\"%s: Freed %lu RCU callbacks.\\n\", __func__, ncbs);\n\tcur_ops->cb_barrier();\n\tncbs = 0;\n\tfor (i = 0; i < fwd_progress; i++)\n\t\tncbs += rcu_torture_fwd_prog_cbfree(&rfp[i]);\n\tpr_info(\"%s: Freed %lu RCU callbacks.\\n\", __func__, ncbs);\n\tcur_ops->cb_barrier();\n\tncbs = 0;\n\tfor (i = 0; i < fwd_progress; i++)\n\t\tncbs += rcu_torture_fwd_prog_cbfree(&rfp[i]);\n\tpr_info(\"%s: Freed %lu RCU callbacks.\\n\", __func__, ncbs);\n\tsmp_mb();  \n\t(*(unsigned long *)nfreed)++;  \n\tpr_info(\"%s returning after OOM processing.\\n\", __func__);\n\tmutex_unlock(&rcu_fwd_mutex);\n\treturn NOTIFY_OK;\n}\n\nstatic struct notifier_block rcutorture_oom_nb = {\n\t.notifier_call = rcutorture_oom_notify\n};\n\n \nstatic int rcu_torture_fwd_prog(void *args)\n{\n\tbool firsttime = true;\n\tlong max_cbs;\n\tint oldnice = task_nice(current);\n\tunsigned long oldseq = READ_ONCE(rcu_fwd_seq);\n\tstruct rcu_fwd *rfp = args;\n\tint tested = 0;\n\tint tested_tries = 0;\n\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_fwd_progress task started\");\n\trcu_bind_current_to_nocb();\n\tif (!IS_ENABLED(CONFIG_SMP) || !IS_ENABLED(CONFIG_RCU_BOOST))\n\t\tset_user_nice(current, MAX_NICE);\n\tdo {\n\t\tif (!rfp->rcu_fwd_id) {\n\t\t\tschedule_timeout_interruptible(fwd_progress_holdoff * HZ);\n\t\t\tWRITE_ONCE(rcu_fwd_emergency_stop, false);\n\t\t\tif (!firsttime) {\n\t\t\t\tmax_cbs = atomic_long_xchg(&rcu_fwd_max_cbs, 0);\n\t\t\t\tpr_alert(\"%s n_max_cbs: %ld\\n\", __func__, max_cbs);\n\t\t\t}\n\t\t\tfirsttime = false;\n\t\t\tWRITE_ONCE(rcu_fwd_seq, rcu_fwd_seq + 1);\n\t\t} else {\n\t\t\twhile (READ_ONCE(rcu_fwd_seq) == oldseq && !torture_must_stop())\n\t\t\t\tschedule_timeout_interruptible(1);\n\t\t\toldseq = READ_ONCE(rcu_fwd_seq);\n\t\t}\n\t\tpr_alert(\"%s: Starting forward-progress test %d\\n\", __func__, rfp->rcu_fwd_id);\n\t\tif (rcu_inkernel_boot_has_ended() && torture_num_online_cpus() > rfp->rcu_fwd_id)\n\t\t\trcu_torture_fwd_prog_cr(rfp);\n\t\tif ((cur_ops->stall_dur && cur_ops->stall_dur() > 0) &&\n\t\t    (!IS_ENABLED(CONFIG_TINY_RCU) ||\n\t\t     (rcu_inkernel_boot_has_ended() &&\n\t\t      torture_num_online_cpus() > rfp->rcu_fwd_id)))\n\t\t\trcu_torture_fwd_prog_nr(rfp, &tested, &tested_tries);\n\n\t\t \n\t\tif (stutter_wait(\"rcu_torture_fwd_prog\"))\n\t\t\tsched_set_normal(current, oldnice);\n\t} while (!torture_must_stop());\n\t \n\tif (!rfp->rcu_fwd_id) {\n\t\tWARN_ON(!tested && tested_tries >= 5);\n\t\tpr_alert(\"%s: tested %d tested_tries %d\\n\", __func__, tested, tested_tries);\n\t}\n\ttorture_kthread_stopping(\"rcu_torture_fwd_prog\");\n\treturn 0;\n}\n\n \nstatic int __init rcu_torture_fwd_prog_init(void)\n{\n\tint i;\n\tint ret = 0;\n\tstruct rcu_fwd *rfp;\n\n\tif (!fwd_progress)\n\t\treturn 0;  \n\tif (fwd_progress >= nr_cpu_ids) {\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_fwd_prog_init: Limiting fwd_progress to # CPUs.\\n\");\n\t\tfwd_progress = nr_cpu_ids;\n\t} else if (fwd_progress < 0) {\n\t\tfwd_progress = nr_cpu_ids;\n\t}\n\tif ((!cur_ops->sync && !cur_ops->call) ||\n\t    (!cur_ops->cbflood_max && (!cur_ops->stall_dur || cur_ops->stall_dur() <= 0)) ||\n\t    cur_ops == &rcu_busted_ops) {\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_fwd_prog_init: Disabled, unsupported by RCU flavor under test\");\n\t\tfwd_progress = 0;\n\t\treturn 0;\n\t}\n\tif (stall_cpu > 0) {\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_fwd_prog_init: Disabled, conflicts with CPU-stall testing\");\n\t\tfwd_progress = 0;\n\t\tif (IS_MODULE(CONFIG_RCU_TORTURE_TEST))\n\t\t\treturn -EINVAL;  \n\t\tWARN_ON(1);  \n\t\treturn 0;\n\t}\n\tif (fwd_progress_holdoff <= 0)\n\t\tfwd_progress_holdoff = 1;\n\tif (fwd_progress_div <= 0)\n\t\tfwd_progress_div = 4;\n\trfp = kcalloc(fwd_progress, sizeof(*rfp), GFP_KERNEL);\n\tfwd_prog_tasks = kcalloc(fwd_progress, sizeof(*fwd_prog_tasks), GFP_KERNEL);\n\tif (!rfp || !fwd_prog_tasks) {\n\t\tkfree(rfp);\n\t\tkfree(fwd_prog_tasks);\n\t\tfwd_prog_tasks = NULL;\n\t\tfwd_progress = 0;\n\t\treturn -ENOMEM;\n\t}\n\tfor (i = 0; i < fwd_progress; i++) {\n\t\tspin_lock_init(&rfp[i].rcu_fwd_lock);\n\t\trfp[i].rcu_fwd_cb_tail = &rfp[i].rcu_fwd_cb_head;\n\t\trfp[i].rcu_fwd_id = i;\n\t}\n\tmutex_lock(&rcu_fwd_mutex);\n\trcu_fwds = rfp;\n\tmutex_unlock(&rcu_fwd_mutex);\n\tregister_oom_notifier(&rcutorture_oom_nb);\n\tfor (i = 0; i < fwd_progress; i++) {\n\t\tret = torture_create_kthread(rcu_torture_fwd_prog, &rcu_fwds[i], fwd_prog_tasks[i]);\n\t\tif (ret) {\n\t\t\tfwd_progress = i;\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic void rcu_torture_fwd_prog_cleanup(void)\n{\n\tint i;\n\tstruct rcu_fwd *rfp;\n\n\tif (!rcu_fwds || !fwd_prog_tasks)\n\t\treturn;\n\tfor (i = 0; i < fwd_progress; i++)\n\t\ttorture_stop_kthread(rcu_torture_fwd_prog, fwd_prog_tasks[i]);\n\tunregister_oom_notifier(&rcutorture_oom_nb);\n\tmutex_lock(&rcu_fwd_mutex);\n\trfp = rcu_fwds;\n\trcu_fwds = NULL;\n\tmutex_unlock(&rcu_fwd_mutex);\n\tkfree(rfp);\n\tkfree(fwd_prog_tasks);\n\tfwd_prog_tasks = NULL;\n}\n\n \nstatic void rcu_torture_barrier_cbf(struct rcu_head *rcu)\n{\n\tatomic_inc(&barrier_cbs_invoked);\n}\n\n \nstatic void rcu_torture_barrier1cb(void *rcu_void)\n{\n\tstruct rcu_head *rhp = rcu_void;\n\n\tcur_ops->call(rhp, rcu_torture_barrier_cbf);\n}\n\n \nstatic int rcu_torture_barrier_cbs(void *arg)\n{\n\tlong myid = (long)arg;\n\tbool lastphase = false;\n\tbool newphase;\n\tstruct rcu_head rcu;\n\n\tinit_rcu_head_on_stack(&rcu);\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_barrier_cbs task started\");\n\tset_user_nice(current, MAX_NICE);\n\tdo {\n\t\twait_event(barrier_cbs_wq[myid],\n\t\t\t   (newphase =\n\t\t\t    smp_load_acquire(&barrier_phase)) != lastphase ||\n\t\t\t   torture_must_stop());\n\t\tlastphase = newphase;\n\t\tif (torture_must_stop())\n\t\t\tbreak;\n\t\t \n\t\tif (smp_call_function_single(myid, rcu_torture_barrier1cb,\n\t\t\t\t\t     &rcu, 1)) {\n\t\t\t \n\t\t\tcur_ops->call(&rcu, rcu_torture_barrier_cbf);\n\t\t}\n\t\tif (atomic_dec_and_test(&barrier_cbs_count))\n\t\t\twake_up(&barrier_wq);\n\t} while (!torture_must_stop());\n\tif (cur_ops->cb_barrier != NULL)\n\t\tcur_ops->cb_barrier();\n\tdestroy_rcu_head_on_stack(&rcu);\n\ttorture_kthread_stopping(\"rcu_torture_barrier_cbs\");\n\treturn 0;\n}\n\n \nstatic int rcu_torture_barrier(void *arg)\n{\n\tint i;\n\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_barrier task starting\");\n\tdo {\n\t\tatomic_set(&barrier_cbs_invoked, 0);\n\t\tatomic_set(&barrier_cbs_count, n_barrier_cbs);\n\t\t \n\t\tsmp_store_release(&barrier_phase, !barrier_phase);\n\t\tfor (i = 0; i < n_barrier_cbs; i++)\n\t\t\twake_up(&barrier_cbs_wq[i]);\n\t\twait_event(barrier_wq,\n\t\t\t   atomic_read(&barrier_cbs_count) == 0 ||\n\t\t\t   torture_must_stop());\n\t\tif (torture_must_stop())\n\t\t\tbreak;\n\t\tn_barrier_attempts++;\n\t\tcur_ops->cb_barrier();  \n\t\tif (atomic_read(&barrier_cbs_invoked) != n_barrier_cbs) {\n\t\t\tn_rcu_torture_barrier_error++;\n\t\t\tpr_err(\"barrier_cbs_invoked = %d, n_barrier_cbs = %d\\n\",\n\t\t\t       atomic_read(&barrier_cbs_invoked),\n\t\t\t       n_barrier_cbs);\n\t\t\tWARN_ON(1);\n\t\t\t \n\t\t\ti = 0;\n\t\t\tdo {\n\t\t\t\tif (WARN_ON(i++ > HZ))\n\t\t\t\t\ti = INT_MIN;\n\t\t\t\tschedule_timeout_interruptible(1);\n\t\t\t\tcur_ops->cb_barrier();\n\t\t\t} while (atomic_read(&barrier_cbs_invoked) !=\n\t\t\t\t n_barrier_cbs &&\n\t\t\t\t !torture_must_stop());\n\t\t\tsmp_mb();  \n\t\t\tif (!torture_must_stop())\n\t\t\t\tpr_err(\"Recovered: barrier_cbs_invoked = %d\\n\",\n\t\t\t\t       atomic_read(&barrier_cbs_invoked));\n\t\t} else {\n\t\t\tn_barrier_successes++;\n\t\t}\n\t\tschedule_timeout_interruptible(HZ / 10);\n\t} while (!torture_must_stop());\n\ttorture_kthread_stopping(\"rcu_torture_barrier\");\n\treturn 0;\n}\n\n \nstatic int rcu_torture_barrier_init(void)\n{\n\tint i;\n\tint ret;\n\n\tif (n_barrier_cbs <= 0)\n\t\treturn 0;\n\tif (cur_ops->call == NULL || cur_ops->cb_barrier == NULL) {\n\t\tpr_alert(\"%s\" TORTURE_FLAG\n\t\t\t \" Call or barrier ops missing for %s,\\n\",\n\t\t\t torture_type, cur_ops->name);\n\t\tpr_alert(\"%s\" TORTURE_FLAG\n\t\t\t \" RCU barrier testing omitted from run.\\n\",\n\t\t\t torture_type);\n\t\treturn 0;\n\t}\n\tatomic_set(&barrier_cbs_count, 0);\n\tatomic_set(&barrier_cbs_invoked, 0);\n\tbarrier_cbs_tasks =\n\t\tkcalloc(n_barrier_cbs, sizeof(barrier_cbs_tasks[0]),\n\t\t\tGFP_KERNEL);\n\tbarrier_cbs_wq =\n\t\tkcalloc(n_barrier_cbs, sizeof(barrier_cbs_wq[0]), GFP_KERNEL);\n\tif (barrier_cbs_tasks == NULL || !barrier_cbs_wq)\n\t\treturn -ENOMEM;\n\tfor (i = 0; i < n_barrier_cbs; i++) {\n\t\tinit_waitqueue_head(&barrier_cbs_wq[i]);\n\t\tret = torture_create_kthread(rcu_torture_barrier_cbs,\n\t\t\t\t\t     (void *)(long)i,\n\t\t\t\t\t     barrier_cbs_tasks[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\treturn torture_create_kthread(rcu_torture_barrier, NULL, barrier_task);\n}\n\n \nstatic void rcu_torture_barrier_cleanup(void)\n{\n\tint i;\n\n\ttorture_stop_kthread(rcu_torture_barrier, barrier_task);\n\tif (barrier_cbs_tasks != NULL) {\n\t\tfor (i = 0; i < n_barrier_cbs; i++)\n\t\t\ttorture_stop_kthread(rcu_torture_barrier_cbs,\n\t\t\t\t\t     barrier_cbs_tasks[i]);\n\t\tkfree(barrier_cbs_tasks);\n\t\tbarrier_cbs_tasks = NULL;\n\t}\n\tif (barrier_cbs_wq != NULL) {\n\t\tkfree(barrier_cbs_wq);\n\t\tbarrier_cbs_wq = NULL;\n\t}\n}\n\nstatic bool rcu_torture_can_boost(void)\n{\n\tstatic int boost_warn_once;\n\tint prio;\n\n\tif (!(test_boost == 1 && cur_ops->can_boost) && test_boost != 2)\n\t\treturn false;\n\tif (!cur_ops->start_gp_poll || !cur_ops->poll_gp_state)\n\t\treturn false;\n\n\tprio = rcu_get_gp_kthreads_prio();\n\tif (!prio)\n\t\treturn false;\n\n\tif (prio < 2) {\n\t\tif (boost_warn_once == 1)\n\t\t\treturn false;\n\n\t\tpr_alert(\"%s: WARN: RCU kthread priority too low to test boosting.  Skipping RCU boost test. Try passing rcutree.kthread_prio > 1 on the kernel command line.\\n\", KBUILD_MODNAME);\n\t\tboost_warn_once = 1;\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool read_exit_child_stop;\nstatic bool read_exit_child_stopped;\nstatic wait_queue_head_t read_exit_wq;\n\n\nstatic int rcu_torture_read_exit_child(void *trsp_in)\n{\n\tstruct torture_random_state *trsp = trsp_in;\n\n\tset_user_nice(current, MAX_NICE);\n\t\n\twhile (!kthread_should_stop())\n\t\tschedule_timeout_uninterruptible(1);\n\t(void)rcu_torture_one_read(trsp, -1);\n\treturn 0;\n}\n\n\nstatic int rcu_torture_read_exit(void *unused)\n{\n\tbool errexit = false;\n\tint i;\n\tstruct task_struct *tsp;\n\tDEFINE_TORTURE_RANDOM(trs);\n\n\t\n\tset_user_nice(current, MAX_NICE);\n\tVERBOSE_TOROUT_STRING(\"rcu_torture_read_exit: Start of test\");\n\n\t\n\tdo {\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_read_exit: Start of episode\");\n\t\tfor (i = 0; i < read_exit_burst; i++) {\n\t\t\tif (READ_ONCE(read_exit_child_stop))\n\t\t\t\tbreak;\n\t\t\tstutter_wait(\"rcu_torture_read_exit\");\n\t\t\t\n\t\t\ttsp = kthread_run(rcu_torture_read_exit_child,\n\t\t\t\t\t  &trs, \"%s\", \"rcu_torture_read_exit_child\");\n\t\t\tif (IS_ERR(tsp)) {\n\t\t\t\tTOROUT_ERRSTRING(\"out of memory\");\n\t\t\t\terrexit = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcond_resched();\n\t\t\tkthread_stop(tsp);\n\t\t\tn_read_exits++;\n\t\t}\n\t\tVERBOSE_TOROUT_STRING(\"rcu_torture_read_exit: End of episode\");\n\t\trcu_barrier(); \n\t\ti = 0;\n\t\tfor (; !errexit && !READ_ONCE(read_exit_child_stop) && i < read_exit_delay; i++)\n\t\t\tschedule_timeout_uninterruptible(HZ);\n\t} while (!errexit && !READ_ONCE(read_exit_child_stop));\n\n\t\n\tsmp_store_release(&read_exit_child_stopped, true); \n\tsmp_mb(); \n\twake_up(&read_exit_wq);\n\twhile (!torture_must_stop())\n\t\tschedule_timeout_uninterruptible(1);\n\ttorture_kthread_stopping(\"rcu_torture_read_exit\");\n\treturn 0;\n}\n\nstatic int rcu_torture_read_exit_init(void)\n{\n\tif (read_exit_burst <= 0)\n\t\treturn 0;\n\tinit_waitqueue_head(&read_exit_wq);\n\tread_exit_child_stop = false;\n\tread_exit_child_stopped = false;\n\treturn torture_create_kthread(rcu_torture_read_exit, NULL,\n\t\t\t\t      read_exit_task);\n}\n\nstatic void rcu_torture_read_exit_cleanup(void)\n{\n\tif (!read_exit_task)\n\t\treturn;\n\tWRITE_ONCE(read_exit_child_stop, true);\n\tsmp_mb(); \n\twait_event(read_exit_wq, smp_load_acquire(&read_exit_child_stopped));\n\ttorture_stop_kthread(rcutorture_read_exit, read_exit_task);\n}\n\nstatic void rcutorture_test_nmis(int n)\n{\n#if IS_BUILTIN(CONFIG_RCU_TORTURE_TEST)\n\tint cpu;\n\tint dumpcpu;\n\tint i;\n\n\tfor (i = 0; i < n; i++) {\n\t\tpreempt_disable();\n\t\tcpu = smp_processor_id();\n\t\tdumpcpu = cpu + 1;\n\t\tif (dumpcpu >= nr_cpu_ids)\n\t\t\tdumpcpu = 0;\n\t\tpr_alert(\"%s: CPU %d invoking dump_cpu_task(%d)\\n\", __func__, cpu, dumpcpu);\n\t\tdump_cpu_task(dumpcpu);\n\t\tpreempt_enable();\n\t\tschedule_timeout_uninterruptible(15 * HZ);\n\t}\n#else \n\tWARN_ONCE(n, \"Non-zero rcutorture.test_nmis=%d permitted only when rcutorture is built in.\\n\", test_nmis);\n#endif \n}\n\nstatic enum cpuhp_state rcutor_hp;\n\nstatic void\nrcu_torture_cleanup(void)\n{\n\tint firsttime;\n\tint flags = 0;\n\tunsigned long gp_seq = 0;\n\tint i;\n\n\tif (torture_cleanup_begin()) {\n\t\tif (cur_ops->cb_barrier != NULL) {\n\t\t\tpr_info(\"%s: Invoking %pS().\\n\", __func__, cur_ops->cb_barrier);\n\t\t\tcur_ops->cb_barrier();\n\t\t}\n\t\trcu_gp_slow_unregister(NULL);\n\t\treturn;\n\t}\n\tif (!cur_ops) {\n\t\ttorture_cleanup_end();\n\t\trcu_gp_slow_unregister(NULL);\n\t\treturn;\n\t}\n\n\trcutorture_test_nmis(test_nmis);\n\n\tif (cur_ops->gp_kthread_dbg)\n\t\tcur_ops->gp_kthread_dbg();\n\trcu_torture_read_exit_cleanup();\n\trcu_torture_barrier_cleanup();\n\trcu_torture_fwd_prog_cleanup();\n\ttorture_stop_kthread(rcu_torture_stall, stall_task);\n\ttorture_stop_kthread(rcu_torture_writer, writer_task);\n\n\tif (nocb_tasks) {\n\t\tfor (i = 0; i < nrealnocbers; i++)\n\t\t\ttorture_stop_kthread(rcu_nocb_toggle, nocb_tasks[i]);\n\t\tkfree(nocb_tasks);\n\t\tnocb_tasks = NULL;\n\t}\n\n\tif (reader_tasks) {\n\t\tfor (i = 0; i < nrealreaders; i++)\n\t\t\ttorture_stop_kthread(rcu_torture_reader,\n\t\t\t\t\t     reader_tasks[i]);\n\t\tkfree(reader_tasks);\n\t\treader_tasks = NULL;\n\t}\n\tkfree(rcu_torture_reader_mbchk);\n\trcu_torture_reader_mbchk = NULL;\n\n\tif (fakewriter_tasks) {\n\t\tfor (i = 0; i < nfakewriters; i++)\n\t\t\ttorture_stop_kthread(rcu_torture_fakewriter,\n\t\t\t\t\t     fakewriter_tasks[i]);\n\t\tkfree(fakewriter_tasks);\n\t\tfakewriter_tasks = NULL;\n\t}\n\n\trcutorture_get_gp_data(cur_ops->ttype, &flags, &gp_seq);\n\tsrcutorture_get_gp_data(cur_ops->ttype, srcu_ctlp, &flags, &gp_seq);\n\tpr_alert(\"%s:  End-test grace-period state: g%ld f%#x total-gps=%ld\\n\",\n\t\t cur_ops->name, (long)gp_seq, flags,\n\t\t rcutorture_seq_diff(gp_seq, start_gp_seq));\n\ttorture_stop_kthread(rcu_torture_stats, stats_task);\n\ttorture_stop_kthread(rcu_torture_fqs, fqs_task);\n\tif (rcu_torture_can_boost() && rcutor_hp >= 0)\n\t\tcpuhp_remove_state(rcutor_hp);\n\n\t \n\tif (cur_ops->cb_barrier != NULL) {\n\t\tpr_info(\"%s: Invoking %pS().\\n\", __func__, cur_ops->cb_barrier);\n\t\tcur_ops->cb_barrier();\n\t}\n\tif (cur_ops->cleanup != NULL)\n\t\tcur_ops->cleanup();\n\n\trcu_torture_mem_dump_obj();\n\n\trcu_torture_stats_print();   \n\n\tif (err_segs_recorded) {\n\t\tpr_alert(\"Failure/close-call rcutorture reader segments:\\n\");\n\t\tif (rt_read_nsegs == 0)\n\t\t\tpr_alert(\"\\t: No segments recorded!!!\\n\");\n\t\tfirsttime = 1;\n\t\tfor (i = 0; i < rt_read_nsegs; i++) {\n\t\t\tpr_alert(\"\\t%d: %#x \", i, err_segs[i].rt_readstate);\n\t\t\tif (err_segs[i].rt_delay_jiffies != 0) {\n\t\t\t\tpr_cont(\"%s%ldjiffies\", firsttime ? \"\" : \"+\",\n\t\t\t\t\terr_segs[i].rt_delay_jiffies);\n\t\t\t\tfirsttime = 0;\n\t\t\t}\n\t\t\tif (err_segs[i].rt_delay_ms != 0) {\n\t\t\t\tpr_cont(\"%s%ldms\", firsttime ? \"\" : \"+\",\n\t\t\t\t\terr_segs[i].rt_delay_ms);\n\t\t\t\tfirsttime = 0;\n\t\t\t}\n\t\t\tif (err_segs[i].rt_delay_us != 0) {\n\t\t\t\tpr_cont(\"%s%ldus\", firsttime ? \"\" : \"+\",\n\t\t\t\t\terr_segs[i].rt_delay_us);\n\t\t\t\tfirsttime = 0;\n\t\t\t}\n\t\t\tpr_cont(\"%s\\n\",\n\t\t\t\terr_segs[i].rt_preempted ? \"preempted\" : \"\");\n\n\t\t}\n\t}\n\tif (atomic_read(&n_rcu_torture_error) || n_rcu_torture_barrier_error)\n\t\trcu_torture_print_module_parms(cur_ops, \"End of test: FAILURE\");\n\telse if (torture_onoff_failures())\n\t\trcu_torture_print_module_parms(cur_ops,\n\t\t\t\t\t       \"End of test: RCU_HOTPLUG\");\n\telse\n\t\trcu_torture_print_module_parms(cur_ops, \"End of test: SUCCESS\");\n\ttorture_cleanup_end();\n\trcu_gp_slow_unregister(&rcu_fwd_cb_nodelay);\n}\n\n#ifdef CONFIG_DEBUG_OBJECTS_RCU_HEAD\nstatic void rcu_torture_leak_cb(struct rcu_head *rhp)\n{\n}\n\nstatic void rcu_torture_err_cb(struct rcu_head *rhp)\n{\n\t \n\tpr_alert(\"%s: duplicated callback was invoked.\\n\", KBUILD_MODNAME);\n}\n#endif  \n\n \nstatic void rcu_test_debug_objects(void)\n{\n#ifdef CONFIG_DEBUG_OBJECTS_RCU_HEAD\n\tstruct rcu_head rh1;\n\tstruct rcu_head rh2;\n\tstruct rcu_head *rhp = kmalloc(sizeof(*rhp), GFP_KERNEL);\n\n\tinit_rcu_head_on_stack(&rh1);\n\tinit_rcu_head_on_stack(&rh2);\n\tpr_alert(\"%s: WARN: Duplicate call_rcu() test starting.\\n\", KBUILD_MODNAME);\n\n\t \n\tpreempt_disable();  \n\trcu_read_lock();  \n\tcall_rcu_hurry(&rh1, rcu_torture_leak_cb);  \n\tlocal_irq_disable();  \n\tcall_rcu_hurry(&rh2, rcu_torture_leak_cb);\n\tcall_rcu_hurry(&rh2, rcu_torture_err_cb);  \n\tif (rhp) {\n\t\tcall_rcu_hurry(rhp, rcu_torture_leak_cb);\n\t\tcall_rcu_hurry(rhp, rcu_torture_err_cb);  \n\t}\n\tlocal_irq_enable();\n\trcu_read_unlock();\n\tpreempt_enable();\n\n\t \n\trcu_barrier();\n\tpr_alert(\"%s: WARN: Duplicate call_rcu() test complete.\\n\", KBUILD_MODNAME);\n\tdestroy_rcu_head_on_stack(&rh1);\n\tdestroy_rcu_head_on_stack(&rh2);\n\tkfree(rhp);\n#else  \n\tpr_alert(\"%s: !CONFIG_DEBUG_OBJECTS_RCU_HEAD, not testing duplicate call_rcu()\\n\", KBUILD_MODNAME);\n#endif  \n}\n\nstatic void rcutorture_sync(void)\n{\n\tstatic unsigned long n;\n\n\tif (cur_ops->sync && !(++n & 0xfff))\n\t\tcur_ops->sync();\n}\n\nstatic DEFINE_MUTEX(mut0);\nstatic DEFINE_MUTEX(mut1);\nstatic DEFINE_MUTEX(mut2);\nstatic DEFINE_MUTEX(mut3);\nstatic DEFINE_MUTEX(mut4);\nstatic DEFINE_MUTEX(mut5);\nstatic DEFINE_MUTEX(mut6);\nstatic DEFINE_MUTEX(mut7);\nstatic DEFINE_MUTEX(mut8);\nstatic DEFINE_MUTEX(mut9);\n\nstatic DECLARE_RWSEM(rwsem0);\nstatic DECLARE_RWSEM(rwsem1);\nstatic DECLARE_RWSEM(rwsem2);\nstatic DECLARE_RWSEM(rwsem3);\nstatic DECLARE_RWSEM(rwsem4);\nstatic DECLARE_RWSEM(rwsem5);\nstatic DECLARE_RWSEM(rwsem6);\nstatic DECLARE_RWSEM(rwsem7);\nstatic DECLARE_RWSEM(rwsem8);\nstatic DECLARE_RWSEM(rwsem9);\n\nDEFINE_STATIC_SRCU(srcu0);\nDEFINE_STATIC_SRCU(srcu1);\nDEFINE_STATIC_SRCU(srcu2);\nDEFINE_STATIC_SRCU(srcu3);\nDEFINE_STATIC_SRCU(srcu4);\nDEFINE_STATIC_SRCU(srcu5);\nDEFINE_STATIC_SRCU(srcu6);\nDEFINE_STATIC_SRCU(srcu7);\nDEFINE_STATIC_SRCU(srcu8);\nDEFINE_STATIC_SRCU(srcu9);\n\nstatic int srcu_lockdep_next(const char *f, const char *fl, const char *fs, const char *fu, int i,\n\t\t\t     int cyclelen, int deadlock)\n{\n\tint j = i + 1;\n\n\tif (j >= cyclelen)\n\t\tj = deadlock ? 0 : -1;\n\tif (j >= 0)\n\t\tpr_info(\"%s: %s(%d), %s(%d), %s(%d)\\n\", f, fl, i, fs, j, fu, i);\n\telse\n\t\tpr_info(\"%s: %s(%d), %s(%d)\\n\", f, fl, i, fu, i);\n\treturn j;\n}\n\n\nstatic void rcu_torture_init_srcu_lockdep(void)\n{\n\tint cyclelen;\n\tint deadlock;\n\tbool err = false;\n\tint i;\n\tint j;\n\tint idx;\n\tstruct mutex *muts[] = { &mut0, &mut1, &mut2, &mut3, &mut4,\n\t\t\t\t &mut5, &mut6, &mut7, &mut8, &mut9 };\n\tstruct rw_semaphore *rwsems[] = { &rwsem0, &rwsem1, &rwsem2, &rwsem3, &rwsem4,\n\t\t\t\t\t  &rwsem5, &rwsem6, &rwsem7, &rwsem8, &rwsem9 };\n\tstruct srcu_struct *srcus[] = { &srcu0, &srcu1, &srcu2, &srcu3, &srcu4,\n\t\t\t\t\t&srcu5, &srcu6, &srcu7, &srcu8, &srcu9 };\n\tint testtype;\n\n\tif (!test_srcu_lockdep)\n\t\treturn;\n\n\tdeadlock = test_srcu_lockdep / 1000;\n\ttesttype = (test_srcu_lockdep / 10) % 100;\n\tcyclelen = test_srcu_lockdep % 10;\n\tWARN_ON_ONCE(ARRAY_SIZE(muts) != ARRAY_SIZE(srcus));\n\tif (WARN_ONCE(deadlock != !!deadlock,\n\t\t      \"%s: test_srcu_lockdep=%d and deadlock digit %d must be zero or one.\\n\",\n\t\t      __func__, test_srcu_lockdep, deadlock))\n\t\terr = true;\n\tif (WARN_ONCE(cyclelen <= 0,\n\t\t      \"%s: test_srcu_lockdep=%d and cycle-length digit %d must be greater than zero.\\n\",\n\t\t      __func__, test_srcu_lockdep, cyclelen))\n\t\terr = true;\n\tif (err)\n\t\tgoto err_out;\n\n\tif (testtype == 0) {\n\t\tpr_info(\"%s: test_srcu_lockdep = %05d: SRCU %d-way %sdeadlock.\\n\",\n\t\t\t__func__, test_srcu_lockdep, cyclelen, deadlock ? \"\" : \"non-\");\n\t\tif (deadlock && cyclelen == 1)\n\t\t\tpr_info(\"%s: Expect hang.\\n\", __func__);\n\t\tfor (i = 0; i < cyclelen; i++) {\n\t\t\tj = srcu_lockdep_next(__func__, \"srcu_read_lock\", \"synchronize_srcu\",\n\t\t\t\t\t      \"srcu_read_unlock\", i, cyclelen, deadlock);\n\t\t\tidx = srcu_read_lock(srcus[i]);\n\t\t\tif (j >= 0)\n\t\t\t\tsynchronize_srcu(srcus[j]);\n\t\t\tsrcu_read_unlock(srcus[i], idx);\n\t\t}\n\t\treturn;\n\t}\n\n\tif (testtype == 1) {\n\t\tpr_info(\"%s: test_srcu_lockdep = %05d: SRCU/mutex %d-way %sdeadlock.\\n\",\n\t\t\t__func__, test_srcu_lockdep, cyclelen, deadlock ? \"\" : \"non-\");\n\t\tfor (i = 0; i < cyclelen; i++) {\n\t\t\tpr_info(\"%s: srcu_read_lock(%d), mutex_lock(%d), mutex_unlock(%d), srcu_read_unlock(%d)\\n\",\n\t\t\t\t__func__, i, i, i, i);\n\t\t\tidx = srcu_read_lock(srcus[i]);\n\t\t\tmutex_lock(muts[i]);\n\t\t\tmutex_unlock(muts[i]);\n\t\t\tsrcu_read_unlock(srcus[i], idx);\n\n\t\t\tj = srcu_lockdep_next(__func__, \"mutex_lock\", \"synchronize_srcu\",\n\t\t\t\t\t      \"mutex_unlock\", i, cyclelen, deadlock);\n\t\t\tmutex_lock(muts[i]);\n\t\t\tif (j >= 0)\n\t\t\t\tsynchronize_srcu(srcus[j]);\n\t\t\tmutex_unlock(muts[i]);\n\t\t}\n\t\treturn;\n\t}\n\n\tif (testtype == 2) {\n\t\tpr_info(\"%s: test_srcu_lockdep = %05d: SRCU/rwsem %d-way %sdeadlock.\\n\",\n\t\t\t__func__, test_srcu_lockdep, cyclelen, deadlock ? \"\" : \"non-\");\n\t\tfor (i = 0; i < cyclelen; i++) {\n\t\t\tpr_info(\"%s: srcu_read_lock(%d), down_read(%d), up_read(%d), srcu_read_unlock(%d)\\n\",\n\t\t\t\t__func__, i, i, i, i);\n\t\t\tidx = srcu_read_lock(srcus[i]);\n\t\t\tdown_read(rwsems[i]);\n\t\t\tup_read(rwsems[i]);\n\t\t\tsrcu_read_unlock(srcus[i], idx);\n\n\t\t\tj = srcu_lockdep_next(__func__, \"down_write\", \"synchronize_srcu\",\n\t\t\t\t\t      \"up_write\", i, cyclelen, deadlock);\n\t\t\tdown_write(rwsems[i]);\n\t\t\tif (j >= 0)\n\t\t\t\tsynchronize_srcu(srcus[j]);\n\t\t\tup_write(rwsems[i]);\n\t\t}\n\t\treturn;\n\t}\n\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tif (testtype == 3) {\n\t\tpr_info(\"%s: test_srcu_lockdep = %05d: SRCU and Tasks Trace RCU %d-way %sdeadlock.\\n\",\n\t\t\t__func__, test_srcu_lockdep, cyclelen, deadlock ? \"\" : \"non-\");\n\t\tif (deadlock && cyclelen == 1)\n\t\t\tpr_info(\"%s: Expect hang.\\n\", __func__);\n\t\tfor (i = 0; i < cyclelen; i++) {\n\t\t\tchar *fl = i == 0 ? \"rcu_read_lock_trace\" : \"srcu_read_lock\";\n\t\t\tchar *fs = i == cyclelen - 1 ? \"synchronize_rcu_tasks_trace\"\n\t\t\t\t\t\t     : \"synchronize_srcu\";\n\t\t\tchar *fu = i == 0 ? \"rcu_read_unlock_trace\" : \"srcu_read_unlock\";\n\n\t\t\tj = srcu_lockdep_next(__func__, fl, fs, fu, i, cyclelen, deadlock);\n\t\t\tif (i == 0)\n\t\t\t\trcu_read_lock_trace();\n\t\t\telse\n\t\t\t\tidx = srcu_read_lock(srcus[i]);\n\t\t\tif (j >= 0) {\n\t\t\t\tif (i == cyclelen - 1)\n\t\t\t\t\tsynchronize_rcu_tasks_trace();\n\t\t\t\telse\n\t\t\t\t\tsynchronize_srcu(srcus[j]);\n\t\t\t}\n\t\t\tif (i == 0)\n\t\t\t\trcu_read_unlock_trace();\n\t\t\telse\n\t\t\t\tsrcu_read_unlock(srcus[i], idx);\n\t\t}\n\t\treturn;\n\t}\n#endif \n\nerr_out:\n\tpr_info(\"%s: test_srcu_lockdep = %05d does nothing.\\n\", __func__, test_srcu_lockdep);\n\tpr_info(\"%s: test_srcu_lockdep = DNNL.\\n\", __func__);\n\tpr_info(\"%s: D: Deadlock if nonzero.\\n\", __func__);\n\tpr_info(\"%s: NN: Test number, 0=SRCU, 1=SRCU/mutex, 2=SRCU/rwsem, 3=SRCU/Tasks Trace RCU.\\n\", __func__);\n\tpr_info(\"%s: L: Cycle length.\\n\", __func__);\n\tif (!IS_ENABLED(CONFIG_TASKS_TRACE_RCU))\n\t\tpr_info(\"%s: NN=3 disallowed because kernel is built with CONFIG_TASKS_TRACE_RCU=n\\n\", __func__);\n}\n\nstatic int __init\nrcu_torture_init(void)\n{\n\tlong i;\n\tint cpu;\n\tint firsterr = 0;\n\tint flags = 0;\n\tunsigned long gp_seq = 0;\n\tstatic struct rcu_torture_ops *torture_ops[] = {\n\t\t&rcu_ops, &rcu_busted_ops, &srcu_ops, &srcud_ops, &busted_srcud_ops,\n\t\tTASKS_OPS TASKS_RUDE_OPS TASKS_TRACING_OPS\n\t\t&trivial_ops,\n\t};\n\n\tif (!torture_init_begin(torture_type, verbose))\n\t\treturn -EBUSY;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(torture_ops); i++) {\n\t\tcur_ops = torture_ops[i];\n\t\tif (strcmp(torture_type, cur_ops->name) == 0)\n\t\t\tbreak;\n\t}\n\tif (i == ARRAY_SIZE(torture_ops)) {\n\t\tpr_alert(\"rcu-torture: invalid torture type: \\\"%s\\\"\\n\",\n\t\t\t torture_type);\n\t\tpr_alert(\"rcu-torture types:\");\n\t\tfor (i = 0; i < ARRAY_SIZE(torture_ops); i++)\n\t\t\tpr_cont(\" %s\", torture_ops[i]->name);\n\t\tpr_cont(\"\\n\");\n\t\tfirsterr = -EINVAL;\n\t\tcur_ops = NULL;\n\t\tgoto unwind;\n\t}\n\tif (cur_ops->fqs == NULL && fqs_duration != 0) {\n\t\tpr_alert(\"rcu-torture: ->fqs NULL and non-zero fqs_duration, fqs disabled.\\n\");\n\t\tfqs_duration = 0;\n\t}\n\tif (nocbs_nthreads != 0 && (cur_ops != &rcu_ops ||\n\t\t\t\t    !IS_ENABLED(CONFIG_RCU_NOCB_CPU))) {\n\t\tpr_alert(\"rcu-torture types: %s and CONFIG_RCU_NOCB_CPU=%d, nocb toggle disabled.\\n\",\n\t\t\t cur_ops->name, IS_ENABLED(CONFIG_RCU_NOCB_CPU));\n\t\tnocbs_nthreads = 0;\n\t}\n\tif (cur_ops->init)\n\t\tcur_ops->init();\n\n\trcu_torture_init_srcu_lockdep();\n\n\tif (nreaders >= 0) {\n\t\tnrealreaders = nreaders;\n\t} else {\n\t\tnrealreaders = num_online_cpus() - 2 - nreaders;\n\t\tif (nrealreaders <= 0)\n\t\t\tnrealreaders = 1;\n\t}\n\trcu_torture_print_module_parms(cur_ops, \"Start of test\");\n\trcutorture_get_gp_data(cur_ops->ttype, &flags, &gp_seq);\n\tsrcutorture_get_gp_data(cur_ops->ttype, srcu_ctlp, &flags, &gp_seq);\n\tstart_gp_seq = gp_seq;\n\tpr_alert(\"%s:  Start-test grace-period state: g%ld f%#x\\n\",\n\t\t cur_ops->name, (long)gp_seq, flags);\n\n\t \n\n\tINIT_LIST_HEAD(&rcu_torture_freelist);\n\tfor (i = 0; i < ARRAY_SIZE(rcu_tortures); i++) {\n\t\trcu_tortures[i].rtort_mbtest = 0;\n\t\tlist_add_tail(&rcu_tortures[i].rtort_free,\n\t\t\t      &rcu_torture_freelist);\n\t}\n\n\t \n\n\trcu_torture_current = NULL;\n\trcu_torture_current_version = 0;\n\tatomic_set(&n_rcu_torture_alloc, 0);\n\tatomic_set(&n_rcu_torture_alloc_fail, 0);\n\tatomic_set(&n_rcu_torture_free, 0);\n\tatomic_set(&n_rcu_torture_mberror, 0);\n\tatomic_set(&n_rcu_torture_mbchk_fail, 0);\n\tatomic_set(&n_rcu_torture_mbchk_tries, 0);\n\tatomic_set(&n_rcu_torture_error, 0);\n\tn_rcu_torture_barrier_error = 0;\n\tn_rcu_torture_boost_ktrerror = 0;\n\tn_rcu_torture_boost_failure = 0;\n\tn_rcu_torture_boosts = 0;\n\tfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++)\n\t\tatomic_set(&rcu_torture_wcount[i], 0);\n\tfor_each_possible_cpu(cpu) {\n\t\tfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++) {\n\t\t\tper_cpu(rcu_torture_count, cpu)[i] = 0;\n\t\t\tper_cpu(rcu_torture_batch, cpu)[i] = 0;\n\t\t}\n\t}\n\terr_segs_recorded = 0;\n\trt_read_nsegs = 0;\n\n\t \n\n\trcu_torture_write_types();\n\tfirsterr = torture_create_kthread(rcu_torture_writer, NULL,\n\t\t\t\t\t  writer_task);\n\tif (torture_init_error(firsterr))\n\t\tgoto unwind;\n\tif (nfakewriters > 0) {\n\t\tfakewriter_tasks = kcalloc(nfakewriters,\n\t\t\t\t\t   sizeof(fakewriter_tasks[0]),\n\t\t\t\t\t   GFP_KERNEL);\n\t\tif (fakewriter_tasks == NULL) {\n\t\t\tTOROUT_ERRSTRING(\"out of memory\");\n\t\t\tfirsterr = -ENOMEM;\n\t\t\tgoto unwind;\n\t\t}\n\t}\n\tfor (i = 0; i < nfakewriters; i++) {\n\t\tfirsterr = torture_create_kthread(rcu_torture_fakewriter,\n\t\t\t\t\t\t  NULL, fakewriter_tasks[i]);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\treader_tasks = kcalloc(nrealreaders, sizeof(reader_tasks[0]),\n\t\t\t       GFP_KERNEL);\n\trcu_torture_reader_mbchk = kcalloc(nrealreaders, sizeof(*rcu_torture_reader_mbchk),\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!reader_tasks || !rcu_torture_reader_mbchk) {\n\t\tTOROUT_ERRSTRING(\"out of memory\");\n\t\tfirsterr = -ENOMEM;\n\t\tgoto unwind;\n\t}\n\tfor (i = 0; i < nrealreaders; i++) {\n\t\trcu_torture_reader_mbchk[i].rtc_chkrdr = -1;\n\t\tfirsterr = torture_create_kthread(rcu_torture_reader, (void *)i,\n\t\t\t\t\t\t  reader_tasks[i]);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tnrealnocbers = nocbs_nthreads;\n\tif (WARN_ON(nrealnocbers < 0))\n\t\tnrealnocbers = 1;\n\tif (WARN_ON(nocbs_toggle < 0))\n\t\tnocbs_toggle = HZ;\n\tif (nrealnocbers > 0) {\n\t\tnocb_tasks = kcalloc(nrealnocbers, sizeof(nocb_tasks[0]), GFP_KERNEL);\n\t\tif (nocb_tasks == NULL) {\n\t\t\tTOROUT_ERRSTRING(\"out of memory\");\n\t\t\tfirsterr = -ENOMEM;\n\t\t\tgoto unwind;\n\t\t}\n\t} else {\n\t\tnocb_tasks = NULL;\n\t}\n\tfor (i = 0; i < nrealnocbers; i++) {\n\t\tfirsterr = torture_create_kthread(rcu_nocb_toggle, NULL, nocb_tasks[i]);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tif (stat_interval > 0) {\n\t\tfirsterr = torture_create_kthread(rcu_torture_stats, NULL,\n\t\t\t\t\t\t  stats_task);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tif (test_no_idle_hz && shuffle_interval > 0) {\n\t\tfirsterr = torture_shuffle_init(shuffle_interval * HZ);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tif (stutter < 0)\n\t\tstutter = 0;\n\tif (stutter) {\n\t\tint t;\n\n\t\tt = cur_ops->stall_dur ? cur_ops->stall_dur() : stutter * HZ;\n\t\tfirsterr = torture_stutter_init(stutter * HZ, t);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tif (fqs_duration < 0)\n\t\tfqs_duration = 0;\n\tif (fqs_duration) {\n\t\t \n\t\tfirsterr = torture_create_kthread(rcu_torture_fqs, NULL,\n\t\t\t\t\t\t  fqs_task);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tif (test_boost_interval < 1)\n\t\ttest_boost_interval = 1;\n\tif (test_boost_duration < 2)\n\t\ttest_boost_duration = 2;\n\tif (rcu_torture_can_boost()) {\n\n\t\tboost_starttime = jiffies + test_boost_interval * HZ;\n\n\t\tfirsterr = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, \"RCU_TORTURE\",\n\t\t\t\t\t     rcutorture_booster_init,\n\t\t\t\t\t     rcutorture_booster_cleanup);\n\t\trcutor_hp = firsterr;\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tshutdown_jiffies = jiffies + shutdown_secs * HZ;\n\tfirsterr = torture_shutdown_init(shutdown_secs, rcu_torture_cleanup);\n\tif (torture_init_error(firsterr))\n\t\tgoto unwind;\n\tfirsterr = torture_onoff_init(onoff_holdoff * HZ, onoff_interval,\n\t\t\t\t      rcutorture_sync);\n\tif (torture_init_error(firsterr))\n\t\tgoto unwind;\n\tfirsterr = rcu_torture_stall_init();\n\tif (torture_init_error(firsterr))\n\t\tgoto unwind;\n\tfirsterr = rcu_torture_fwd_prog_init();\n\tif (torture_init_error(firsterr))\n\t\tgoto unwind;\n\tfirsterr = rcu_torture_barrier_init();\n\tif (torture_init_error(firsterr))\n\t\tgoto unwind;\n\tfirsterr = rcu_torture_read_exit_init();\n\tif (torture_init_error(firsterr))\n\t\tgoto unwind;\n\tif (object_debug)\n\t\trcu_test_debug_objects();\n\ttorture_init_end();\n\trcu_gp_slow_register(&rcu_fwd_cb_nodelay);\n\treturn 0;\n\nunwind:\n\ttorture_init_end();\n\trcu_torture_cleanup();\n\tif (shutdown_secs) {\n\t\tWARN_ON(!IS_MODULE(CONFIG_RCU_TORTURE_TEST));\n\t\tkernel_power_off();\n\t}\n\treturn firsterr;\n}\n\nmodule_init(rcu_torture_init);\nmodule_exit(rcu_torture_cleanup);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}