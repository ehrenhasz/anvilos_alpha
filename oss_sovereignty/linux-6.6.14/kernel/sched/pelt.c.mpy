{
  "module_name": "pelt.c",
  "hash_id": "4e321551f0ea64a646c68d1aa31f6776786da9ec0d3b902b1e5bc4ad39436bf8",
  "original_prompt": "Ingested from linux-6.6.14/kernel/sched/pelt.c",
  "human_readable_source": "\n \n\n \nstatic u64 decay_load(u64 val, u64 n)\n{\n\tunsigned int local_n;\n\n\tif (unlikely(n > LOAD_AVG_PERIOD * 63))\n\t\treturn 0;\n\n\t \n\tlocal_n = n;\n\n\t \n\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {\n\t\tval >>= local_n / LOAD_AVG_PERIOD;\n\t\tlocal_n %= LOAD_AVG_PERIOD;\n\t}\n\n\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);\n\treturn val;\n}\n\nstatic u32 __accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)\n{\n\tu32 c1, c2, c3 = d3;  \n\n\t \n\tc1 = decay_load((u64)d1, periods);\n\n\t \n\tc2 = LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024;\n\n\treturn c1 + c2 + c3;\n}\n\n \nstatic __always_inline u32\naccumulate_sum(u64 delta, struct sched_avg *sa,\n\t       unsigned long load, unsigned long runnable, int running)\n{\n\tu32 contrib = (u32)delta;  \n\tu64 periods;\n\n\tdelta += sa->period_contrib;\n\tperiods = delta / 1024;  \n\n\t \n\tif (periods) {\n\t\tsa->load_sum = decay_load(sa->load_sum, periods);\n\t\tsa->runnable_sum =\n\t\t\tdecay_load(sa->runnable_sum, periods);\n\t\tsa->util_sum = decay_load((u64)(sa->util_sum), periods);\n\n\t\t \n\t\tdelta %= 1024;\n\t\tif (load) {\n\t\t\t \n\t\t\tcontrib = __accumulate_pelt_segments(periods,\n\t\t\t\t\t1024 - sa->period_contrib, delta);\n\t\t}\n\t}\n\tsa->period_contrib = delta;\n\n\tif (load)\n\t\tsa->load_sum += load * contrib;\n\tif (runnable)\n\t\tsa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;\n\tif (running)\n\t\tsa->util_sum += contrib << SCHED_CAPACITY_SHIFT;\n\n\treturn periods;\n}\n\n \nstatic __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t \n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t \n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t \n\tif (!load)\n\t\trunnable = running = 0;\n\n\t \n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}\n\n \nstatic __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t \n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}\n\n \n\nint __update_load_avg_blocked_se(u64 now, struct sched_entity *se)\n{\n\tif (___update_load_sum(now, &se->avg, 0, 0, 0)) {\n\t\t___update_load_avg(&se->avg, se_weight(se));\n\t\ttrace_pelt_se_tp(se);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nint __update_load_avg_se(u64 now, struct cfs_rq *cfs_rq, struct sched_entity *se)\n{\n\tif (___update_load_sum(now, &se->avg, !!se->on_rq, se_runnable(se),\n\t\t\t\tcfs_rq->curr == se)) {\n\n\t\t___update_load_avg(&se->avg, se_weight(se));\n\t\tcfs_se_util_change(&se->avg);\n\t\ttrace_pelt_se_tp(se);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nint __update_load_avg_cfs_rq(u64 now, struct cfs_rq *cfs_rq)\n{\n\tif (___update_load_sum(now, &cfs_rq->avg,\n\t\t\t\tscale_load_down(cfs_rq->load.weight),\n\t\t\t\tcfs_rq->h_nr_running,\n\t\t\t\tcfs_rq->curr != NULL)) {\n\n\t\t___update_load_avg(&cfs_rq->avg, 1);\n\t\ttrace_pelt_cfs_tp(cfs_rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n \n\nint update_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\tif (___update_load_sum(now, &rq->avg_rt,\n\t\t\t\trunning,\n\t\t\t\trunning,\n\t\t\t\trunning)) {\n\n\t\t___update_load_avg(&rq->avg_rt, 1);\n\t\ttrace_pelt_rt_tp(rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n \n\nint update_dl_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\tif (___update_load_sum(now, &rq->avg_dl,\n\t\t\t\trunning,\n\t\t\t\trunning,\n\t\t\t\trunning)) {\n\n\t\t___update_load_avg(&rq->avg_dl, 1);\n\t\ttrace_pelt_dl_tp(rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n#ifdef CONFIG_SCHED_THERMAL_PRESSURE\n \n\nint update_thermal_load_avg(u64 now, struct rq *rq, u64 capacity)\n{\n\tif (___update_load_sum(now, &rq->avg_thermal,\n\t\t\t       capacity,\n\t\t\t       capacity,\n\t\t\t       capacity)) {\n\t\t___update_load_avg(&rq->avg_thermal, 1);\n\t\ttrace_pelt_thermal_tp(rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n#endif\n\n#ifdef CONFIG_HAVE_SCHED_AVG_IRQ\n \n\nint update_irq_load_avg(struct rq *rq, u64 running)\n{\n\tint ret = 0;\n\n\t \n\trunning = cap_scale(running, arch_scale_freq_capacity(cpu_of(rq)));\n\trunning = cap_scale(running, arch_scale_cpu_capacity(cpu_of(rq)));\n\n\t \n\tret = ___update_load_sum(rq->clock - running, &rq->avg_irq,\n\t\t\t\t0,\n\t\t\t\t0,\n\t\t\t\t0);\n\tret += ___update_load_sum(rq->clock, &rq->avg_irq,\n\t\t\t\t1,\n\t\t\t\t1,\n\t\t\t\t1);\n\n\tif (ret) {\n\t\t___update_load_avg(&rq->avg_irq, 1);\n\t\ttrace_pelt_irq_tp(rq);\n\t}\n\n\treturn ret;\n}\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}