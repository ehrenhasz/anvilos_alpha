{
  "module_name": "stats.c",
  "hash_id": "ddcad397da61dd1641983ea5353fc50162b453ad987845536c90d5df87ee59de",
  "original_prompt": "Ingested from linux-6.6.14/kernel/sched/stats.c",
  "human_readable_source": "\n \n\nvoid __update_stats_wait_start(struct rq *rq, struct task_struct *p,\n\t\t\t       struct sched_statistics *stats)\n{\n\tu64 wait_start, prev_wait_start;\n\n\twait_start = rq_clock(rq);\n\tprev_wait_start = schedstat_val(stats->wait_start);\n\n\tif (p && likely(wait_start > prev_wait_start))\n\t\twait_start -= prev_wait_start;\n\n\t__schedstat_set(stats->wait_start, wait_start);\n}\n\nvoid __update_stats_wait_end(struct rq *rq, struct task_struct *p,\n\t\t\t     struct sched_statistics *stats)\n{\n\tu64 delta = rq_clock(rq) - schedstat_val(stats->wait_start);\n\n\tif (p) {\n\t\tif (task_on_rq_migrating(p)) {\n\t\t\t \n\t\t\t__schedstat_set(stats->wait_start, delta);\n\n\t\t\treturn;\n\t\t}\n\n\t\ttrace_sched_stat_wait(p, delta);\n\t}\n\n\t__schedstat_set(stats->wait_max,\n\t\t\tmax(schedstat_val(stats->wait_max), delta));\n\t__schedstat_inc(stats->wait_count);\n\t__schedstat_add(stats->wait_sum, delta);\n\t__schedstat_set(stats->wait_start, 0);\n}\n\nvoid __update_stats_enqueue_sleeper(struct rq *rq, struct task_struct *p,\n\t\t\t\t    struct sched_statistics *stats)\n{\n\tu64 sleep_start, block_start;\n\n\tsleep_start = schedstat_val(stats->sleep_start);\n\tblock_start = schedstat_val(stats->block_start);\n\n\tif (sleep_start) {\n\t\tu64 delta = rq_clock(rq) - sleep_start;\n\n\t\tif ((s64)delta < 0)\n\t\t\tdelta = 0;\n\n\t\tif (unlikely(delta > schedstat_val(stats->sleep_max)))\n\t\t\t__schedstat_set(stats->sleep_max, delta);\n\n\t\t__schedstat_set(stats->sleep_start, 0);\n\t\t__schedstat_add(stats->sum_sleep_runtime, delta);\n\n\t\tif (p) {\n\t\t\taccount_scheduler_latency(p, delta >> 10, 1);\n\t\t\ttrace_sched_stat_sleep(p, delta);\n\t\t}\n\t}\n\n\tif (block_start) {\n\t\tu64 delta = rq_clock(rq) - block_start;\n\n\t\tif ((s64)delta < 0)\n\t\t\tdelta = 0;\n\n\t\tif (unlikely(delta > schedstat_val(stats->block_max)))\n\t\t\t__schedstat_set(stats->block_max, delta);\n\n\t\t__schedstat_set(stats->block_start, 0);\n\t\t__schedstat_add(stats->sum_sleep_runtime, delta);\n\t\t__schedstat_add(stats->sum_block_runtime, delta);\n\n\t\tif (p) {\n\t\t\tif (p->in_iowait) {\n\t\t\t\t__schedstat_add(stats->iowait_sum, delta);\n\t\t\t\t__schedstat_inc(stats->iowait_count);\n\t\t\t\ttrace_sched_stat_iowait(p, delta);\n\t\t\t}\n\n\t\t\ttrace_sched_stat_blocked(p, delta);\n\n\t\t\t \n\t\t\tif (unlikely(prof_on == SLEEP_PROFILING)) {\n\t\t\t\tprofile_hits(SLEEP_PROFILING,\n\t\t\t\t\t     (void *)get_wchan(p),\n\t\t\t\t\t     delta >> 20);\n\t\t\t}\n\t\t\taccount_scheduler_latency(p, delta >> 10, 0);\n\t\t}\n\t}\n}\n\n \n#define SCHEDSTAT_VERSION 15\n\nstatic int show_schedstat(struct seq_file *seq, void *v)\n{\n\tint cpu;\n\n\tif (v == (void *)1) {\n\t\tseq_printf(seq, \"version %d\\n\", SCHEDSTAT_VERSION);\n\t\tseq_printf(seq, \"timestamp %lu\\n\", jiffies);\n\t} else {\n\t\tstruct rq *rq;\n#ifdef CONFIG_SMP\n\t\tstruct sched_domain *sd;\n\t\tint dcount = 0;\n#endif\n\t\tcpu = (unsigned long)(v - 2);\n\t\trq = cpu_rq(cpu);\n\n\t\t \n\t\tseq_printf(seq,\n\t\t    \"cpu%d %u 0 %u %u %u %u %llu %llu %lu\",\n\t\t    cpu, rq->yld_count,\n\t\t    rq->sched_count, rq->sched_goidle,\n\t\t    rq->ttwu_count, rq->ttwu_local,\n\t\t    rq->rq_cpu_time,\n\t\t    rq->rq_sched_info.run_delay, rq->rq_sched_info.pcount);\n\n\t\tseq_printf(seq, \"\\n\");\n\n#ifdef CONFIG_SMP\n\t\t \n\t\trcu_read_lock();\n\t\tfor_each_domain(cpu, sd) {\n\t\t\tenum cpu_idle_type itype;\n\n\t\t\tseq_printf(seq, \"domain%d %*pb\", dcount++,\n\t\t\t\t   cpumask_pr_args(sched_domain_span(sd)));\n\t\t\tfor (itype = CPU_IDLE; itype < CPU_MAX_IDLE_TYPES;\n\t\t\t\t\titype++) {\n\t\t\t\tseq_printf(seq, \" %u %u %u %u %u %u %u %u\",\n\t\t\t\t    sd->lb_count[itype],\n\t\t\t\t    sd->lb_balanced[itype],\n\t\t\t\t    sd->lb_failed[itype],\n\t\t\t\t    sd->lb_imbalance[itype],\n\t\t\t\t    sd->lb_gained[itype],\n\t\t\t\t    sd->lb_hot_gained[itype],\n\t\t\t\t    sd->lb_nobusyq[itype],\n\t\t\t\t    sd->lb_nobusyg[itype]);\n\t\t\t}\n\t\t\tseq_printf(seq,\n\t\t\t\t   \" %u %u %u %u %u %u %u %u %u %u %u %u\\n\",\n\t\t\t    sd->alb_count, sd->alb_failed, sd->alb_pushed,\n\t\t\t    sd->sbe_count, sd->sbe_balanced, sd->sbe_pushed,\n\t\t\t    sd->sbf_count, sd->sbf_balanced, sd->sbf_pushed,\n\t\t\t    sd->ttwu_wake_remote, sd->ttwu_move_affine,\n\t\t\t    sd->ttwu_move_balance);\n\t\t}\n\t\trcu_read_unlock();\n#endif\n\t}\n\treturn 0;\n}\n\n \nstatic void *schedstat_start(struct seq_file *file, loff_t *offset)\n{\n\tunsigned long n = *offset;\n\n\tif (n == 0)\n\t\treturn (void *) 1;\n\n\tn--;\n\n\tif (n > 0)\n\t\tn = cpumask_next(n - 1, cpu_online_mask);\n\telse\n\t\tn = cpumask_first(cpu_online_mask);\n\n\t*offset = n + 1;\n\n\tif (n < nr_cpu_ids)\n\t\treturn (void *)(unsigned long)(n + 2);\n\n\treturn NULL;\n}\n\nstatic void *schedstat_next(struct seq_file *file, void *data, loff_t *offset)\n{\n\t(*offset)++;\n\n\treturn schedstat_start(file, offset);\n}\n\nstatic void schedstat_stop(struct seq_file *file, void *data)\n{\n}\n\nstatic const struct seq_operations schedstat_sops = {\n\t.start = schedstat_start,\n\t.next  = schedstat_next,\n\t.stop  = schedstat_stop,\n\t.show  = show_schedstat,\n};\n\nstatic int __init proc_schedstat_init(void)\n{\n\tproc_create_seq(\"schedstat\", 0, NULL, &schedstat_sops);\n\treturn 0;\n}\nsubsys_initcall(proc_schedstat_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}