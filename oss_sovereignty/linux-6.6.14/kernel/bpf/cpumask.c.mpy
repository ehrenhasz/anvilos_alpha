{
  "module_name": "cpumask.c",
  "hash_id": "666b22ce44145d2da272ec42f08b52ef4ae67e992fa6bf1806705e9ddf16974e",
  "original_prompt": "Ingested from linux-6.6.14/kernel/bpf/cpumask.c",
  "human_readable_source": "\n \n#include <linux/bpf.h>\n#include <linux/bpf_mem_alloc.h>\n#include <linux/btf.h>\n#include <linux/btf_ids.h>\n#include <linux/cpumask.h>\n\n \nstruct bpf_cpumask {\n\tcpumask_t cpumask;\n\trefcount_t usage;\n};\n\nstatic struct bpf_mem_alloc bpf_cpumask_ma;\n\nstatic bool cpu_valid(u32 cpu)\n{\n\treturn cpu < nr_cpu_ids;\n}\n\n__diag_push();\n__diag_ignore_all(\"-Wmissing-prototypes\",\n\t\t  \"Global kfuncs as their definitions will be in BTF\");\n\n \n__bpf_kfunc struct bpf_cpumask *bpf_cpumask_create(void)\n{\n\tstruct bpf_cpumask *cpumask;\n\n\t \n\tBUILD_BUG_ON(offsetof(struct bpf_cpumask, cpumask) != 0);\n\n\tcpumask = bpf_mem_cache_alloc(&bpf_cpumask_ma);\n\tif (!cpumask)\n\t\treturn NULL;\n\n\tmemset(cpumask, 0, sizeof(*cpumask));\n\trefcount_set(&cpumask->usage, 1);\n\n\treturn cpumask;\n}\n\n \n__bpf_kfunc struct bpf_cpumask *bpf_cpumask_acquire(struct bpf_cpumask *cpumask)\n{\n\trefcount_inc(&cpumask->usage);\n\treturn cpumask;\n}\n\n \n__bpf_kfunc void bpf_cpumask_release(struct bpf_cpumask *cpumask)\n{\n\tif (!refcount_dec_and_test(&cpumask->usage))\n\t\treturn;\n\n\tmigrate_disable();\n\tbpf_mem_cache_free_rcu(&bpf_cpumask_ma, cpumask);\n\tmigrate_enable();\n}\n\n \n__bpf_kfunc u32 bpf_cpumask_first(const struct cpumask *cpumask)\n{\n\treturn cpumask_first(cpumask);\n}\n\n \n__bpf_kfunc u32 bpf_cpumask_first_zero(const struct cpumask *cpumask)\n{\n\treturn cpumask_first_zero(cpumask);\n}\n\n \n__bpf_kfunc u32 bpf_cpumask_first_and(const struct cpumask *src1,\n\t\t\t\t      const struct cpumask *src2)\n{\n\treturn cpumask_first_and(src1, src2);\n}\n\n \n__bpf_kfunc void bpf_cpumask_set_cpu(u32 cpu, struct bpf_cpumask *cpumask)\n{\n\tif (!cpu_valid(cpu))\n\t\treturn;\n\n\tcpumask_set_cpu(cpu, (struct cpumask *)cpumask);\n}\n\n \n__bpf_kfunc void bpf_cpumask_clear_cpu(u32 cpu, struct bpf_cpumask *cpumask)\n{\n\tif (!cpu_valid(cpu))\n\t\treturn;\n\n\tcpumask_clear_cpu(cpu, (struct cpumask *)cpumask);\n}\n\n \n__bpf_kfunc bool bpf_cpumask_test_cpu(u32 cpu, const struct cpumask *cpumask)\n{\n\tif (!cpu_valid(cpu))\n\t\treturn false;\n\n\treturn cpumask_test_cpu(cpu, (struct cpumask *)cpumask);\n}\n\n \n__bpf_kfunc bool bpf_cpumask_test_and_set_cpu(u32 cpu, struct bpf_cpumask *cpumask)\n{\n\tif (!cpu_valid(cpu))\n\t\treturn false;\n\n\treturn cpumask_test_and_set_cpu(cpu, (struct cpumask *)cpumask);\n}\n\n \n__bpf_kfunc bool bpf_cpumask_test_and_clear_cpu(u32 cpu, struct bpf_cpumask *cpumask)\n{\n\tif (!cpu_valid(cpu))\n\t\treturn false;\n\n\treturn cpumask_test_and_clear_cpu(cpu, (struct cpumask *)cpumask);\n}\n\n \n__bpf_kfunc void bpf_cpumask_setall(struct bpf_cpumask *cpumask)\n{\n\tcpumask_setall((struct cpumask *)cpumask);\n}\n\n \n__bpf_kfunc void bpf_cpumask_clear(struct bpf_cpumask *cpumask)\n{\n\tcpumask_clear((struct cpumask *)cpumask);\n}\n\n \n__bpf_kfunc bool bpf_cpumask_and(struct bpf_cpumask *dst,\n\t\t\t\t const struct cpumask *src1,\n\t\t\t\t const struct cpumask *src2)\n{\n\treturn cpumask_and((struct cpumask *)dst, src1, src2);\n}\n\n \n__bpf_kfunc void bpf_cpumask_or(struct bpf_cpumask *dst,\n\t\t\t\tconst struct cpumask *src1,\n\t\t\t\tconst struct cpumask *src2)\n{\n\tcpumask_or((struct cpumask *)dst, src1, src2);\n}\n\n \n__bpf_kfunc void bpf_cpumask_xor(struct bpf_cpumask *dst,\n\t\t\t\t const struct cpumask *src1,\n\t\t\t\t const struct cpumask *src2)\n{\n\tcpumask_xor((struct cpumask *)dst, src1, src2);\n}\n\n \n__bpf_kfunc bool bpf_cpumask_equal(const struct cpumask *src1, const struct cpumask *src2)\n{\n\treturn cpumask_equal(src1, src2);\n}\n\n \n__bpf_kfunc bool bpf_cpumask_intersects(const struct cpumask *src1, const struct cpumask *src2)\n{\n\treturn cpumask_intersects(src1, src2);\n}\n\n \n__bpf_kfunc bool bpf_cpumask_subset(const struct cpumask *src1, const struct cpumask *src2)\n{\n\treturn cpumask_subset(src1, src2);\n}\n\n \n__bpf_kfunc bool bpf_cpumask_empty(const struct cpumask *cpumask)\n{\n\treturn cpumask_empty(cpumask);\n}\n\n \n__bpf_kfunc bool bpf_cpumask_full(const struct cpumask *cpumask)\n{\n\treturn cpumask_full(cpumask);\n}\n\n \n__bpf_kfunc void bpf_cpumask_copy(struct bpf_cpumask *dst, const struct cpumask *src)\n{\n\tcpumask_copy((struct cpumask *)dst, src);\n}\n\n \n__bpf_kfunc u32 bpf_cpumask_any_distribute(const struct cpumask *cpumask)\n{\n\treturn cpumask_any_distribute(cpumask);\n}\n\n \n__bpf_kfunc u32 bpf_cpumask_any_and_distribute(const struct cpumask *src1,\n\t\t\t\t\t       const struct cpumask *src2)\n{\n\treturn cpumask_any_and_distribute(src1, src2);\n}\n\n__diag_pop();\n\nBTF_SET8_START(cpumask_kfunc_btf_ids)\nBTF_ID_FLAGS(func, bpf_cpumask_create, KF_ACQUIRE | KF_RET_NULL)\nBTF_ID_FLAGS(func, bpf_cpumask_release, KF_RELEASE)\nBTF_ID_FLAGS(func, bpf_cpumask_acquire, KF_ACQUIRE | KF_TRUSTED_ARGS)\nBTF_ID_FLAGS(func, bpf_cpumask_first, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_first_zero, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_first_and, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_set_cpu, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_clear_cpu, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_test_cpu, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_test_and_set_cpu, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_test_and_clear_cpu, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_setall, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_clear, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_and, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_or, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_xor, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_equal, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_intersects, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_subset, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_empty, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_full, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_copy, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_any_distribute, KF_RCU)\nBTF_ID_FLAGS(func, bpf_cpumask_any_and_distribute, KF_RCU)\nBTF_SET8_END(cpumask_kfunc_btf_ids)\n\nstatic const struct btf_kfunc_id_set cpumask_kfunc_set = {\n\t.owner = THIS_MODULE,\n\t.set   = &cpumask_kfunc_btf_ids,\n};\n\nBTF_ID_LIST(cpumask_dtor_ids)\nBTF_ID(struct, bpf_cpumask)\nBTF_ID(func, bpf_cpumask_release)\n\nstatic int __init cpumask_kfunc_init(void)\n{\n\tint ret;\n\tconst struct btf_id_dtor_kfunc cpumask_dtors[] = {\n\t\t{\n\t\t\t.btf_id\t      = cpumask_dtor_ids[0],\n\t\t\t.kfunc_btf_id = cpumask_dtor_ids[1]\n\t\t},\n\t};\n\n\tret = bpf_mem_alloc_init(&bpf_cpumask_ma, sizeof(struct bpf_cpumask), false);\n\tret = ret ?: register_btf_kfunc_id_set(BPF_PROG_TYPE_TRACING, &cpumask_kfunc_set);\n\tret = ret ?: register_btf_kfunc_id_set(BPF_PROG_TYPE_STRUCT_OPS, &cpumask_kfunc_set);\n\treturn  ret ?: register_btf_id_dtor_kfuncs(cpumask_dtors,\n\t\t\t\t\t\t   ARRAY_SIZE(cpumask_dtors),\n\t\t\t\t\t\t   THIS_MODULE);\n}\n\nlate_initcall(cpumask_kfunc_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}