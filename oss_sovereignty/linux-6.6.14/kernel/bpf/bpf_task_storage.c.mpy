{
  "module_name": "bpf_task_storage.c",
  "hash_id": "c7f1ebc37b482d294085f2456b62b1c7e1a3dbd45dcd20b39fca24a8d5c3076b",
  "original_prompt": "Ingested from linux-6.6.14/kernel/bpf/bpf_task_storage.c",
  "human_readable_source": "\n \n\n#include <linux/pid.h>\n#include <linux/sched.h>\n#include <linux/rculist.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/types.h>\n#include <linux/spinlock.h>\n#include <linux/bpf.h>\n#include <linux/bpf_local_storage.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n#include <linux/btf_ids.h>\n#include <linux/fdtable.h>\n#include <linux/rcupdate_trace.h>\n\nDEFINE_BPF_STORAGE_CACHE(task_cache);\n\nstatic DEFINE_PER_CPU(int, bpf_task_storage_busy);\n\nstatic void bpf_task_storage_lock(void)\n{\n\tmigrate_disable();\n\tthis_cpu_inc(bpf_task_storage_busy);\n}\n\nstatic void bpf_task_storage_unlock(void)\n{\n\tthis_cpu_dec(bpf_task_storage_busy);\n\tmigrate_enable();\n}\n\nstatic bool bpf_task_storage_trylock(void)\n{\n\tmigrate_disable();\n\tif (unlikely(this_cpu_inc_return(bpf_task_storage_busy) != 1)) {\n\t\tthis_cpu_dec(bpf_task_storage_busy);\n\t\tmigrate_enable();\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic struct bpf_local_storage __rcu **task_storage_ptr(void *owner)\n{\n\tstruct task_struct *task = owner;\n\n\treturn &task->bpf_storage;\n}\n\nstatic struct bpf_local_storage_data *\ntask_storage_lookup(struct task_struct *task, struct bpf_map *map,\n\t\t    bool cacheit_lockit)\n{\n\tstruct bpf_local_storage *task_storage;\n\tstruct bpf_local_storage_map *smap;\n\n\ttask_storage =\n\t\trcu_dereference_check(task->bpf_storage, bpf_rcu_lock_held());\n\tif (!task_storage)\n\t\treturn NULL;\n\n\tsmap = (struct bpf_local_storage_map *)map;\n\treturn bpf_local_storage_lookup(task_storage, smap, cacheit_lockit);\n}\n\nvoid bpf_task_storage_free(struct task_struct *task)\n{\n\tstruct bpf_local_storage *local_storage;\n\n\trcu_read_lock();\n\n\tlocal_storage = rcu_dereference(task->bpf_storage);\n\tif (!local_storage) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tbpf_task_storage_lock();\n\tbpf_local_storage_destroy(local_storage);\n\tbpf_task_storage_unlock();\n\trcu_read_unlock();\n}\n\nstatic void *bpf_pid_task_storage_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_local_storage_data *sdata;\n\tstruct task_struct *task;\n\tunsigned int f_flags;\n\tstruct pid *pid;\n\tint fd, err;\n\n\tfd = *(int *)key;\n\tpid = pidfd_get_pid(fd, &f_flags);\n\tif (IS_ERR(pid))\n\t\treturn ERR_CAST(pid);\n\n\t \n\tWARN_ON_ONCE(!rcu_read_lock_held());\n\ttask = pid_task(pid, PIDTYPE_PID);\n\tif (!task) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tbpf_task_storage_lock();\n\tsdata = task_storage_lookup(task, map, true);\n\tbpf_task_storage_unlock();\n\tput_pid(pid);\n\treturn sdata ? sdata->data : NULL;\nout:\n\tput_pid(pid);\n\treturn ERR_PTR(err);\n}\n\nstatic long bpf_pid_task_storage_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, u64 map_flags)\n{\n\tstruct bpf_local_storage_data *sdata;\n\tstruct task_struct *task;\n\tunsigned int f_flags;\n\tstruct pid *pid;\n\tint fd, err;\n\n\tfd = *(int *)key;\n\tpid = pidfd_get_pid(fd, &f_flags);\n\tif (IS_ERR(pid))\n\t\treturn PTR_ERR(pid);\n\n\t \n\tWARN_ON_ONCE(!rcu_read_lock_held());\n\ttask = pid_task(pid, PIDTYPE_PID);\n\tif (!task) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tbpf_task_storage_lock();\n\tsdata = bpf_local_storage_update(\n\t\ttask, (struct bpf_local_storage_map *)map, value, map_flags,\n\t\tGFP_ATOMIC);\n\tbpf_task_storage_unlock();\n\n\terr = PTR_ERR_OR_ZERO(sdata);\nout:\n\tput_pid(pid);\n\treturn err;\n}\n\nstatic int task_storage_delete(struct task_struct *task, struct bpf_map *map,\n\t\t\t       bool nobusy)\n{\n\tstruct bpf_local_storage_data *sdata;\n\n\tsdata = task_storage_lookup(task, map, false);\n\tif (!sdata)\n\t\treturn -ENOENT;\n\n\tif (!nobusy)\n\t\treturn -EBUSY;\n\n\tbpf_selem_unlink(SELEM(sdata), false);\n\n\treturn 0;\n}\n\nstatic long bpf_pid_task_storage_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct task_struct *task;\n\tunsigned int f_flags;\n\tstruct pid *pid;\n\tint fd, err;\n\n\tfd = *(int *)key;\n\tpid = pidfd_get_pid(fd, &f_flags);\n\tif (IS_ERR(pid))\n\t\treturn PTR_ERR(pid);\n\n\t \n\tWARN_ON_ONCE(!rcu_read_lock_held());\n\ttask = pid_task(pid, PIDTYPE_PID);\n\tif (!task) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tbpf_task_storage_lock();\n\terr = task_storage_delete(task, map, true);\n\tbpf_task_storage_unlock();\nout:\n\tput_pid(pid);\n\treturn err;\n}\n\n \nstatic void *__bpf_task_storage_get(struct bpf_map *map,\n\t\t\t\t    struct task_struct *task, void *value,\n\t\t\t\t    u64 flags, gfp_t gfp_flags, bool nobusy)\n{\n\tstruct bpf_local_storage_data *sdata;\n\n\tsdata = task_storage_lookup(task, map, nobusy);\n\tif (sdata)\n\t\treturn sdata->data;\n\n\t \n\tif (refcount_read(&task->usage) &&\n\t    (flags & BPF_LOCAL_STORAGE_GET_F_CREATE) && nobusy) {\n\t\tsdata = bpf_local_storage_update(\n\t\t\ttask, (struct bpf_local_storage_map *)map, value,\n\t\t\tBPF_NOEXIST, gfp_flags);\n\t\treturn IS_ERR(sdata) ? NULL : sdata->data;\n\t}\n\n\treturn NULL;\n}\n\n \nBPF_CALL_5(bpf_task_storage_get_recur, struct bpf_map *, map, struct task_struct *,\n\t   task, void *, value, u64, flags, gfp_t, gfp_flags)\n{\n\tbool nobusy;\n\tvoid *data;\n\n\tWARN_ON_ONCE(!bpf_rcu_lock_held());\n\tif (flags & ~BPF_LOCAL_STORAGE_GET_F_CREATE || !task)\n\t\treturn (unsigned long)NULL;\n\n\tnobusy = bpf_task_storage_trylock();\n\tdata = __bpf_task_storage_get(map, task, value, flags,\n\t\t\t\t      gfp_flags, nobusy);\n\tif (nobusy)\n\t\tbpf_task_storage_unlock();\n\treturn (unsigned long)data;\n}\n\n \nBPF_CALL_5(bpf_task_storage_get, struct bpf_map *, map, struct task_struct *,\n\t   task, void *, value, u64, flags, gfp_t, gfp_flags)\n{\n\tvoid *data;\n\n\tWARN_ON_ONCE(!bpf_rcu_lock_held());\n\tif (flags & ~BPF_LOCAL_STORAGE_GET_F_CREATE || !task)\n\t\treturn (unsigned long)NULL;\n\n\tbpf_task_storage_lock();\n\tdata = __bpf_task_storage_get(map, task, value, flags,\n\t\t\t\t      gfp_flags, true);\n\tbpf_task_storage_unlock();\n\treturn (unsigned long)data;\n}\n\nBPF_CALL_2(bpf_task_storage_delete_recur, struct bpf_map *, map, struct task_struct *,\n\t   task)\n{\n\tbool nobusy;\n\tint ret;\n\n\tWARN_ON_ONCE(!bpf_rcu_lock_held());\n\tif (!task)\n\t\treturn -EINVAL;\n\n\tnobusy = bpf_task_storage_trylock();\n\t \n\tret = task_storage_delete(task, map, nobusy);\n\tif (nobusy)\n\t\tbpf_task_storage_unlock();\n\treturn ret;\n}\n\nBPF_CALL_2(bpf_task_storage_delete, struct bpf_map *, map, struct task_struct *,\n\t   task)\n{\n\tint ret;\n\n\tWARN_ON_ONCE(!bpf_rcu_lock_held());\n\tif (!task)\n\t\treturn -EINVAL;\n\n\tbpf_task_storage_lock();\n\t \n\tret = task_storage_delete(task, map, true);\n\tbpf_task_storage_unlock();\n\treturn ret;\n}\n\nstatic int notsupp_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\treturn -ENOTSUPP;\n}\n\nstatic struct bpf_map *task_storage_map_alloc(union bpf_attr *attr)\n{\n\treturn bpf_local_storage_map_alloc(attr, &task_cache, true);\n}\n\nstatic void task_storage_map_free(struct bpf_map *map)\n{\n\tbpf_local_storage_map_free(map, &task_cache, &bpf_task_storage_busy);\n}\n\nBTF_ID_LIST_GLOBAL_SINGLE(bpf_local_storage_map_btf_id, struct, bpf_local_storage_map)\nconst struct bpf_map_ops task_storage_map_ops = {\n\t.map_meta_equal = bpf_map_meta_equal,\n\t.map_alloc_check = bpf_local_storage_map_alloc_check,\n\t.map_alloc = task_storage_map_alloc,\n\t.map_free = task_storage_map_free,\n\t.map_get_next_key = notsupp_get_next_key,\n\t.map_lookup_elem = bpf_pid_task_storage_lookup_elem,\n\t.map_update_elem = bpf_pid_task_storage_update_elem,\n\t.map_delete_elem = bpf_pid_task_storage_delete_elem,\n\t.map_check_btf = bpf_local_storage_map_check_btf,\n\t.map_mem_usage = bpf_local_storage_map_mem_usage,\n\t.map_btf_id = &bpf_local_storage_map_btf_id[0],\n\t.map_owner_storage_ptr = task_storage_ptr,\n};\n\nconst struct bpf_func_proto bpf_task_storage_get_recur_proto = {\n\t.func = bpf_task_storage_get_recur,\n\t.gpl_only = false,\n\t.ret_type = RET_PTR_TO_MAP_VALUE_OR_NULL,\n\t.arg1_type = ARG_CONST_MAP_PTR,\n\t.arg2_type = ARG_PTR_TO_BTF_ID_OR_NULL,\n\t.arg2_btf_id = &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.arg3_type = ARG_PTR_TO_MAP_VALUE_OR_NULL,\n\t.arg4_type = ARG_ANYTHING,\n};\n\nconst struct bpf_func_proto bpf_task_storage_get_proto = {\n\t.func = bpf_task_storage_get,\n\t.gpl_only = false,\n\t.ret_type = RET_PTR_TO_MAP_VALUE_OR_NULL,\n\t.arg1_type = ARG_CONST_MAP_PTR,\n\t.arg2_type = ARG_PTR_TO_BTF_ID_OR_NULL,\n\t.arg2_btf_id = &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.arg3_type = ARG_PTR_TO_MAP_VALUE_OR_NULL,\n\t.arg4_type = ARG_ANYTHING,\n};\n\nconst struct bpf_func_proto bpf_task_storage_delete_recur_proto = {\n\t.func = bpf_task_storage_delete_recur,\n\t.gpl_only = false,\n\t.ret_type = RET_INTEGER,\n\t.arg1_type = ARG_CONST_MAP_PTR,\n\t.arg2_type = ARG_PTR_TO_BTF_ID_OR_NULL,\n\t.arg2_btf_id = &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};\n\nconst struct bpf_func_proto bpf_task_storage_delete_proto = {\n\t.func = bpf_task_storage_delete,\n\t.gpl_only = false,\n\t.ret_type = RET_INTEGER,\n\t.arg1_type = ARG_CONST_MAP_PTR,\n\t.arg2_type = ARG_PTR_TO_BTF_ID_OR_NULL,\n\t.arg2_btf_id = &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}