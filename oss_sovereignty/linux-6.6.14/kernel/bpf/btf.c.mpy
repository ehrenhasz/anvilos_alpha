{
  "module_name": "btf.c",
  "hash_id": "f5ff9aecc89a9f8ba572fc3568fab3e9076bedd7959d4fa6be22aeefb359f7e5",
  "original_prompt": "Ingested from linux-6.6.14/kernel/bpf/btf.c",
  "human_readable_source": "\n \n\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <uapi/linux/bpf_perf_event.h>\n#include <uapi/linux/types.h>\n#include <linux/seq_file.h>\n#include <linux/compiler.h>\n#include <linux/ctype.h>\n#include <linux/errno.h>\n#include <linux/slab.h>\n#include <linux/anon_inodes.h>\n#include <linux/file.h>\n#include <linux/uaccess.h>\n#include <linux/kernel.h>\n#include <linux/idr.h>\n#include <linux/sort.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/btf_ids.h>\n#include <linux/bpf_lsm.h>\n#include <linux/skmsg.h>\n#include <linux/perf_event.h>\n#include <linux/bsearch.h>\n#include <linux/kobject.h>\n#include <linux/sysfs.h>\n\n#include <net/netfilter/nf_bpf_link.h>\n\n#include <net/sock.h>\n#include <net/xdp.h>\n#include \"../tools/lib/bpf/relo_core.h\"\n\n \n\n \n\n#define BITS_PER_U128 (sizeof(u64) * BITS_PER_BYTE * 2)\n#define BITS_PER_BYTE_MASK (BITS_PER_BYTE - 1)\n#define BITS_PER_BYTE_MASKED(bits) ((bits) & BITS_PER_BYTE_MASK)\n#define BITS_ROUNDDOWN_BYTES(bits) ((bits) >> 3)\n#define BITS_ROUNDUP_BYTES(bits) \\\n\t(BITS_ROUNDDOWN_BYTES(bits) + !!BITS_PER_BYTE_MASKED(bits))\n\n#define BTF_INFO_MASK 0x9f00ffff\n#define BTF_INT_MASK 0x0fffffff\n#define BTF_TYPE_ID_VALID(type_id) ((type_id) <= BTF_MAX_TYPE)\n#define BTF_STR_OFFSET_VALID(name_off) ((name_off) <= BTF_MAX_NAME_OFFSET)\n\n \n#define BTF_MAX_SIZE (16 * 1024 * 1024)\n\n#define for_each_member_from(i, from, struct_type, member)\t\t\\\n\tfor (i = from, member = btf_type_member(struct_type) + from;\t\\\n\t     i < btf_type_vlen(struct_type);\t\t\t\t\\\n\t     i++, member++)\n\n#define for_each_vsi_from(i, from, struct_type, member)\t\t\t\t\\\n\tfor (i = from, member = btf_type_var_secinfo(struct_type) + from;\t\\\n\t     i < btf_type_vlen(struct_type);\t\t\t\t\t\\\n\t     i++, member++)\n\nDEFINE_IDR(btf_idr);\nDEFINE_SPINLOCK(btf_idr_lock);\n\nenum btf_kfunc_hook {\n\tBTF_KFUNC_HOOK_COMMON,\n\tBTF_KFUNC_HOOK_XDP,\n\tBTF_KFUNC_HOOK_TC,\n\tBTF_KFUNC_HOOK_STRUCT_OPS,\n\tBTF_KFUNC_HOOK_TRACING,\n\tBTF_KFUNC_HOOK_SYSCALL,\n\tBTF_KFUNC_HOOK_FMODRET,\n\tBTF_KFUNC_HOOK_CGROUP_SKB,\n\tBTF_KFUNC_HOOK_SCHED_ACT,\n\tBTF_KFUNC_HOOK_SK_SKB,\n\tBTF_KFUNC_HOOK_SOCKET_FILTER,\n\tBTF_KFUNC_HOOK_LWT,\n\tBTF_KFUNC_HOOK_NETFILTER,\n\tBTF_KFUNC_HOOK_MAX,\n};\n\nenum {\n\tBTF_KFUNC_SET_MAX_CNT = 256,\n\tBTF_DTOR_KFUNC_MAX_CNT = 256,\n\tBTF_KFUNC_FILTER_MAX_CNT = 16,\n};\n\nstruct btf_kfunc_hook_filter {\n\tbtf_kfunc_filter_t filters[BTF_KFUNC_FILTER_MAX_CNT];\n\tu32 nr_filters;\n};\n\nstruct btf_kfunc_set_tab {\n\tstruct btf_id_set8 *sets[BTF_KFUNC_HOOK_MAX];\n\tstruct btf_kfunc_hook_filter hook_filters[BTF_KFUNC_HOOK_MAX];\n};\n\nstruct btf_id_dtor_kfunc_tab {\n\tu32 cnt;\n\tstruct btf_id_dtor_kfunc dtors[];\n};\n\nstruct btf {\n\tvoid *data;\n\tstruct btf_type **types;\n\tu32 *resolved_ids;\n\tu32 *resolved_sizes;\n\tconst char *strings;\n\tvoid *nohdr_data;\n\tstruct btf_header hdr;\n\tu32 nr_types;  \n\tu32 types_size;\n\tu32 data_size;\n\trefcount_t refcnt;\n\tu32 id;\n\tstruct rcu_head rcu;\n\tstruct btf_kfunc_set_tab *kfunc_set_tab;\n\tstruct btf_id_dtor_kfunc_tab *dtor_kfunc_tab;\n\tstruct btf_struct_metas *struct_meta_tab;\n\n\t \n\tstruct btf *base_btf;\n\tu32 start_id;  \n\tu32 start_str_off;  \n\tchar name[MODULE_NAME_LEN];\n\tbool kernel_btf;\n};\n\nenum verifier_phase {\n\tCHECK_META,\n\tCHECK_TYPE,\n};\n\nstruct resolve_vertex {\n\tconst struct btf_type *t;\n\tu32 type_id;\n\tu16 next_member;\n};\n\nenum visit_state {\n\tNOT_VISITED,\n\tVISITED,\n\tRESOLVED,\n};\n\nenum resolve_mode {\n\tRESOLVE_TBD,\t \n\tRESOLVE_PTR,\t \n\tRESOLVE_STRUCT_OR_ARRAY,\t \n};\n\n#define MAX_RESOLVE_DEPTH 32\n\nstruct btf_sec_info {\n\tu32 off;\n\tu32 len;\n};\n\nstruct btf_verifier_env {\n\tstruct btf *btf;\n\tu8 *visit_states;\n\tstruct resolve_vertex stack[MAX_RESOLVE_DEPTH];\n\tstruct bpf_verifier_log log;\n\tu32 log_type_id;\n\tu32 top_stack;\n\tenum verifier_phase phase;\n\tenum resolve_mode resolve_mode;\n};\n\nstatic const char * const btf_kind_str[NR_BTF_KINDS] = {\n\t[BTF_KIND_UNKN]\t\t= \"UNKNOWN\",\n\t[BTF_KIND_INT]\t\t= \"INT\",\n\t[BTF_KIND_PTR]\t\t= \"PTR\",\n\t[BTF_KIND_ARRAY]\t= \"ARRAY\",\n\t[BTF_KIND_STRUCT]\t= \"STRUCT\",\n\t[BTF_KIND_UNION]\t= \"UNION\",\n\t[BTF_KIND_ENUM]\t\t= \"ENUM\",\n\t[BTF_KIND_FWD]\t\t= \"FWD\",\n\t[BTF_KIND_TYPEDEF]\t= \"TYPEDEF\",\n\t[BTF_KIND_VOLATILE]\t= \"VOLATILE\",\n\t[BTF_KIND_CONST]\t= \"CONST\",\n\t[BTF_KIND_RESTRICT]\t= \"RESTRICT\",\n\t[BTF_KIND_FUNC]\t\t= \"FUNC\",\n\t[BTF_KIND_FUNC_PROTO]\t= \"FUNC_PROTO\",\n\t[BTF_KIND_VAR]\t\t= \"VAR\",\n\t[BTF_KIND_DATASEC]\t= \"DATASEC\",\n\t[BTF_KIND_FLOAT]\t= \"FLOAT\",\n\t[BTF_KIND_DECL_TAG]\t= \"DECL_TAG\",\n\t[BTF_KIND_TYPE_TAG]\t= \"TYPE_TAG\",\n\t[BTF_KIND_ENUM64]\t= \"ENUM64\",\n};\n\nconst char *btf_type_str(const struct btf_type *t)\n{\n\treturn btf_kind_str[BTF_INFO_KIND(t->info)];\n}\n\n \n#define BTF_SHOW_OBJ_SAFE_SIZE\t\t32\n\n \n#define BTF_SHOW_OBJ_BASE_TYPE_SIZE\t16\n\n \n#define BTF_SHOW_NAME_SIZE\t\t80\n\n \n#define NOCAST_ALIAS_SUFFIX\t\t\"___init\"\n\n \nstruct btf_show {\n\tu64 flags;\n\tvoid *target;\t \n\tvoid (*showfn)(struct btf_show *show, const char *fmt, va_list args);\n\tconst struct btf *btf;\n\t \n\tstruct {\n\t\tu8 depth;\n\t\tu8 depth_to_show;\n\t\tu8 depth_check;\n\t\tu8 array_member:1,\n\t\t   array_terminated:1;\n\t\tu16 array_encoding;\n\t\tu32 type_id;\n\t\tint status;\t\t\t \n\t\tconst struct btf_type *type;\n\t\tconst struct btf_member *member;\n\t\tchar name[BTF_SHOW_NAME_SIZE];\t \n\t} state;\n\tstruct {\n\t\tu32 size;\n\t\tvoid *head;\n\t\tvoid *data;\n\t\tu8 safe[BTF_SHOW_OBJ_SAFE_SIZE];\n\t} obj;\n};\n\nstruct btf_kind_operations {\n\ts32 (*check_meta)(struct btf_verifier_env *env,\n\t\t\t  const struct btf_type *t,\n\t\t\t  u32 meta_left);\n\tint (*resolve)(struct btf_verifier_env *env,\n\t\t       const struct resolve_vertex *v);\n\tint (*check_member)(struct btf_verifier_env *env,\n\t\t\t    const struct btf_type *struct_type,\n\t\t\t    const struct btf_member *member,\n\t\t\t    const struct btf_type *member_type);\n\tint (*check_kflag_member)(struct btf_verifier_env *env,\n\t\t\t\t  const struct btf_type *struct_type,\n\t\t\t\t  const struct btf_member *member,\n\t\t\t\t  const struct btf_type *member_type);\n\tvoid (*log_details)(struct btf_verifier_env *env,\n\t\t\t    const struct btf_type *t);\n\tvoid (*show)(const struct btf *btf, const struct btf_type *t,\n\t\t\t u32 type_id, void *data, u8 bits_offsets,\n\t\t\t struct btf_show *show);\n};\n\nstatic const struct btf_kind_operations * const kind_ops[NR_BTF_KINDS];\nstatic struct btf_type btf_void;\n\nstatic int btf_resolve(struct btf_verifier_env *env,\n\t\t       const struct btf_type *t, u32 type_id);\n\nstatic int btf_func_check(struct btf_verifier_env *env,\n\t\t\t  const struct btf_type *t);\n\nstatic bool btf_type_is_modifier(const struct btf_type *t)\n{\n\t \n\tswitch (BTF_INFO_KIND(t->info)) {\n\tcase BTF_KIND_TYPEDEF:\n\tcase BTF_KIND_VOLATILE:\n\tcase BTF_KIND_CONST:\n\tcase BTF_KIND_RESTRICT:\n\tcase BTF_KIND_TYPE_TAG:\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nbool btf_type_is_void(const struct btf_type *t)\n{\n\treturn t == &btf_void;\n}\n\nstatic bool btf_type_is_fwd(const struct btf_type *t)\n{\n\treturn BTF_INFO_KIND(t->info) == BTF_KIND_FWD;\n}\n\nstatic bool btf_type_is_datasec(const struct btf_type *t)\n{\n\treturn BTF_INFO_KIND(t->info) == BTF_KIND_DATASEC;\n}\n\nstatic bool btf_type_is_decl_tag(const struct btf_type *t)\n{\n\treturn BTF_INFO_KIND(t->info) == BTF_KIND_DECL_TAG;\n}\n\nstatic bool btf_type_nosize(const struct btf_type *t)\n{\n\treturn btf_type_is_void(t) || btf_type_is_fwd(t) ||\n\t       btf_type_is_func(t) || btf_type_is_func_proto(t) ||\n\t       btf_type_is_decl_tag(t);\n}\n\nstatic bool btf_type_nosize_or_null(const struct btf_type *t)\n{\n\treturn !t || btf_type_nosize(t);\n}\n\nstatic bool btf_type_is_decl_tag_target(const struct btf_type *t)\n{\n\treturn btf_type_is_func(t) || btf_type_is_struct(t) ||\n\t       btf_type_is_var(t) || btf_type_is_typedef(t);\n}\n\nu32 btf_nr_types(const struct btf *btf)\n{\n\tu32 total = 0;\n\n\twhile (btf) {\n\t\ttotal += btf->nr_types;\n\t\tbtf = btf->base_btf;\n\t}\n\n\treturn total;\n}\n\ns32 btf_find_by_name_kind(const struct btf *btf, const char *name, u8 kind)\n{\n\tconst struct btf_type *t;\n\tconst char *tname;\n\tu32 i, total;\n\n\ttotal = btf_nr_types(btf);\n\tfor (i = 1; i < total; i++) {\n\t\tt = btf_type_by_id(btf, i);\n\t\tif (BTF_INFO_KIND(t->info) != kind)\n\t\t\tcontinue;\n\n\t\ttname = btf_name_by_offset(btf, t->name_off);\n\t\tif (!strcmp(tname, name))\n\t\t\treturn i;\n\t}\n\n\treturn -ENOENT;\n}\n\ns32 bpf_find_btf_id(const char *name, u32 kind, struct btf **btf_p)\n{\n\tstruct btf *btf;\n\ts32 ret;\n\tint id;\n\n\tbtf = bpf_get_btf_vmlinux();\n\tif (IS_ERR(btf))\n\t\treturn PTR_ERR(btf);\n\tif (!btf)\n\t\treturn -EINVAL;\n\n\tret = btf_find_by_name_kind(btf, name, kind);\n\t \n\tif (ret > 0) {\n\t\tbtf_get(btf);\n\t\t*btf_p = btf;\n\t\treturn ret;\n\t}\n\n\t \n\tspin_lock_bh(&btf_idr_lock);\n\tidr_for_each_entry(&btf_idr, btf, id) {\n\t\tif (!btf_is_module(btf))\n\t\t\tcontinue;\n\t\t \n\t\tbtf_get(btf);\n\t\tspin_unlock_bh(&btf_idr_lock);\n\t\tret = btf_find_by_name_kind(btf, name, kind);\n\t\tif (ret > 0) {\n\t\t\t*btf_p = btf;\n\t\t\treturn ret;\n\t\t}\n\t\tbtf_put(btf);\n\t\tspin_lock_bh(&btf_idr_lock);\n\t}\n\tspin_unlock_bh(&btf_idr_lock);\n\treturn ret;\n}\n\nconst struct btf_type *btf_type_skip_modifiers(const struct btf *btf,\n\t\t\t\t\t       u32 id, u32 *res_id)\n{\n\tconst struct btf_type *t = btf_type_by_id(btf, id);\n\n\twhile (btf_type_is_modifier(t)) {\n\t\tid = t->type;\n\t\tt = btf_type_by_id(btf, t->type);\n\t}\n\n\tif (res_id)\n\t\t*res_id = id;\n\n\treturn t;\n}\n\nconst struct btf_type *btf_type_resolve_ptr(const struct btf *btf,\n\t\t\t\t\t    u32 id, u32 *res_id)\n{\n\tconst struct btf_type *t;\n\n\tt = btf_type_skip_modifiers(btf, id, NULL);\n\tif (!btf_type_is_ptr(t))\n\t\treturn NULL;\n\n\treturn btf_type_skip_modifiers(btf, t->type, res_id);\n}\n\nconst struct btf_type *btf_type_resolve_func_ptr(const struct btf *btf,\n\t\t\t\t\t\t u32 id, u32 *res_id)\n{\n\tconst struct btf_type *ptype;\n\n\tptype = btf_type_resolve_ptr(btf, id, res_id);\n\tif (ptype && btf_type_is_func_proto(ptype))\n\t\treturn ptype;\n\n\treturn NULL;\n}\n\n \nstatic bool btf_type_is_resolve_source_only(const struct btf_type *t)\n{\n\treturn btf_type_is_var(t) ||\n\t       btf_type_is_decl_tag(t) ||\n\t       btf_type_is_datasec(t);\n}\n\n \nstatic bool btf_type_needs_resolve(const struct btf_type *t)\n{\n\treturn btf_type_is_modifier(t) ||\n\t       btf_type_is_ptr(t) ||\n\t       btf_type_is_struct(t) ||\n\t       btf_type_is_array(t) ||\n\t       btf_type_is_var(t) ||\n\t       btf_type_is_func(t) ||\n\t       btf_type_is_decl_tag(t) ||\n\t       btf_type_is_datasec(t);\n}\n\n \nstatic bool btf_type_has_size(const struct btf_type *t)\n{\n\tswitch (BTF_INFO_KIND(t->info)) {\n\tcase BTF_KIND_INT:\n\tcase BTF_KIND_STRUCT:\n\tcase BTF_KIND_UNION:\n\tcase BTF_KIND_ENUM:\n\tcase BTF_KIND_DATASEC:\n\tcase BTF_KIND_FLOAT:\n\tcase BTF_KIND_ENUM64:\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic const char *btf_int_encoding_str(u8 encoding)\n{\n\tif (encoding == 0)\n\t\treturn \"(none)\";\n\telse if (encoding == BTF_INT_SIGNED)\n\t\treturn \"SIGNED\";\n\telse if (encoding == BTF_INT_CHAR)\n\t\treturn \"CHAR\";\n\telse if (encoding == BTF_INT_BOOL)\n\t\treturn \"BOOL\";\n\telse\n\t\treturn \"UNKN\";\n}\n\nstatic u32 btf_type_int(const struct btf_type *t)\n{\n\treturn *(u32 *)(t + 1);\n}\n\nstatic const struct btf_array *btf_type_array(const struct btf_type *t)\n{\n\treturn (const struct btf_array *)(t + 1);\n}\n\nstatic const struct btf_enum *btf_type_enum(const struct btf_type *t)\n{\n\treturn (const struct btf_enum *)(t + 1);\n}\n\nstatic const struct btf_var *btf_type_var(const struct btf_type *t)\n{\n\treturn (const struct btf_var *)(t + 1);\n}\n\nstatic const struct btf_decl_tag *btf_type_decl_tag(const struct btf_type *t)\n{\n\treturn (const struct btf_decl_tag *)(t + 1);\n}\n\nstatic const struct btf_enum64 *btf_type_enum64(const struct btf_type *t)\n{\n\treturn (const struct btf_enum64 *)(t + 1);\n}\n\nstatic const struct btf_kind_operations *btf_type_ops(const struct btf_type *t)\n{\n\treturn kind_ops[BTF_INFO_KIND(t->info)];\n}\n\nstatic bool btf_name_offset_valid(const struct btf *btf, u32 offset)\n{\n\tif (!BTF_STR_OFFSET_VALID(offset))\n\t\treturn false;\n\n\twhile (offset < btf->start_str_off)\n\t\tbtf = btf->base_btf;\n\n\toffset -= btf->start_str_off;\n\treturn offset < btf->hdr.str_len;\n}\n\nstatic bool __btf_name_char_ok(char c, bool first)\n{\n\tif ((first ? !isalpha(c) :\n\t\t     !isalnum(c)) &&\n\t    c != '_' &&\n\t    c != '.')\n\t\treturn false;\n\treturn true;\n}\n\nstatic const char *btf_str_by_offset(const struct btf *btf, u32 offset)\n{\n\twhile (offset < btf->start_str_off)\n\t\tbtf = btf->base_btf;\n\n\toffset -= btf->start_str_off;\n\tif (offset < btf->hdr.str_len)\n\t\treturn &btf->strings[offset];\n\n\treturn NULL;\n}\n\nstatic bool __btf_name_valid(const struct btf *btf, u32 offset)\n{\n\t \n\tconst char *src = btf_str_by_offset(btf, offset);\n\tconst char *src_limit;\n\n\tif (!__btf_name_char_ok(*src, true))\n\t\treturn false;\n\n\t \n\tsrc_limit = src + KSYM_NAME_LEN;\n\tsrc++;\n\twhile (*src && src < src_limit) {\n\t\tif (!__btf_name_char_ok(*src, false))\n\t\t\treturn false;\n\t\tsrc++;\n\t}\n\n\treturn !*src;\n}\n\nstatic bool btf_name_valid_identifier(const struct btf *btf, u32 offset)\n{\n\treturn __btf_name_valid(btf, offset);\n}\n\nstatic bool btf_name_valid_section(const struct btf *btf, u32 offset)\n{\n\treturn __btf_name_valid(btf, offset);\n}\n\nstatic const char *__btf_name_by_offset(const struct btf *btf, u32 offset)\n{\n\tconst char *name;\n\n\tif (!offset)\n\t\treturn \"(anon)\";\n\n\tname = btf_str_by_offset(btf, offset);\n\treturn name ?: \"(invalid-name-offset)\";\n}\n\nconst char *btf_name_by_offset(const struct btf *btf, u32 offset)\n{\n\treturn btf_str_by_offset(btf, offset);\n}\n\nconst struct btf_type *btf_type_by_id(const struct btf *btf, u32 type_id)\n{\n\twhile (type_id < btf->start_id)\n\t\tbtf = btf->base_btf;\n\n\ttype_id -= btf->start_id;\n\tif (type_id >= btf->nr_types)\n\t\treturn NULL;\n\treturn btf->types[type_id];\n}\nEXPORT_SYMBOL_GPL(btf_type_by_id);\n\n \nstatic bool btf_type_int_is_regular(const struct btf_type *t)\n{\n\tu8 nr_bits, nr_bytes;\n\tu32 int_data;\n\n\tint_data = btf_type_int(t);\n\tnr_bits = BTF_INT_BITS(int_data);\n\tnr_bytes = BITS_ROUNDUP_BYTES(nr_bits);\n\tif (BITS_PER_BYTE_MASKED(nr_bits) ||\n\t    BTF_INT_OFFSET(int_data) ||\n\t    (nr_bytes != sizeof(u8) && nr_bytes != sizeof(u16) &&\n\t     nr_bytes != sizeof(u32) && nr_bytes != sizeof(u64) &&\n\t     nr_bytes != (2 * sizeof(u64)))) {\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nbool btf_member_is_reg_int(const struct btf *btf, const struct btf_type *s,\n\t\t\t   const struct btf_member *m,\n\t\t\t   u32 expected_offset, u32 expected_size)\n{\n\tconst struct btf_type *t;\n\tu32 id, int_data;\n\tu8 nr_bits;\n\n\tid = m->type;\n\tt = btf_type_id_size(btf, &id, NULL);\n\tif (!t || !btf_type_is_int(t))\n\t\treturn false;\n\n\tint_data = btf_type_int(t);\n\tnr_bits = BTF_INT_BITS(int_data);\n\tif (btf_type_kflag(s)) {\n\t\tu32 bitfield_size = BTF_MEMBER_BITFIELD_SIZE(m->offset);\n\t\tu32 bit_offset = BTF_MEMBER_BIT_OFFSET(m->offset);\n\n\t\t \n\t\treturn !bitfield_size &&\n\t\t       BITS_ROUNDUP_BYTES(bit_offset) == expected_offset &&\n\t\t       BITS_ROUNDUP_BYTES(nr_bits) == expected_size;\n\t}\n\n\tif (BTF_INT_OFFSET(int_data) ||\n\t    BITS_PER_BYTE_MASKED(m->offset) ||\n\t    BITS_ROUNDUP_BYTES(m->offset) != expected_offset ||\n\t    BITS_PER_BYTE_MASKED(nr_bits) ||\n\t    BITS_ROUNDUP_BYTES(nr_bits) != expected_size)\n\t\treturn false;\n\n\treturn true;\n}\n\n \nstatic const struct btf_type *btf_type_skip_qualifiers(const struct btf *btf,\n\t\t\t\t\t\t       u32 id)\n{\n\tconst struct btf_type *t = btf_type_by_id(btf, id);\n\n\twhile (btf_type_is_modifier(t) &&\n\t       BTF_INFO_KIND(t->info) != BTF_KIND_TYPEDEF) {\n\t\tt = btf_type_by_id(btf, t->type);\n\t}\n\n\treturn t;\n}\n\n#define BTF_SHOW_MAX_ITER\t10\n\n#define BTF_KIND_BIT(kind)\t(1ULL << kind)\n\n \nstatic const char *btf_show_name(struct btf_show *show)\n{\n\t \n\tconst char *array_suffixes = \"[][][][][][][][][][]\";\n\tconst char *array_suffix = &array_suffixes[strlen(array_suffixes)];\n\t \n\tconst char *ptr_suffixes = \"**********\";\n\tconst char *ptr_suffix = &ptr_suffixes[strlen(ptr_suffixes)];\n\tconst char *name = NULL, *prefix = \"\", *parens = \"\";\n\tconst struct btf_member *m = show->state.member;\n\tconst struct btf_type *t;\n\tconst struct btf_array *array;\n\tu32 id = show->state.type_id;\n\tconst char *member = NULL;\n\tbool show_member = false;\n\tu64 kinds = 0;\n\tint i;\n\n\tshow->state.name[0] = '\\0';\n\n\t \n\tif (show->state.array_member)\n\t\treturn \"\";\n\n\t \n\tif (m) {\n\t\tmember = btf_name_by_offset(show->btf, m->name_off);\n\t\tshow_member = strlen(member) > 0;\n\t\tid = m->type;\n\t}\n\n\t \n\tt = btf_type_by_id(show->btf, id);\n\tif (!t)\n\t\treturn \"\";\n\n\t \n\tfor (i = 0; i < BTF_SHOW_MAX_ITER; i++) {\n\n\t\tswitch (BTF_INFO_KIND(t->info)) {\n\t\tcase BTF_KIND_TYPEDEF:\n\t\t\tif (!name)\n\t\t\t\tname = btf_name_by_offset(show->btf,\n\t\t\t\t\t\t\t       t->name_off);\n\t\t\tkinds |= BTF_KIND_BIT(BTF_KIND_TYPEDEF);\n\t\t\tid = t->type;\n\t\t\tbreak;\n\t\tcase BTF_KIND_ARRAY:\n\t\t\tkinds |= BTF_KIND_BIT(BTF_KIND_ARRAY);\n\t\t\tparens = \"[\";\n\t\t\tif (!t)\n\t\t\t\treturn \"\";\n\t\t\tarray = btf_type_array(t);\n\t\t\tif (array_suffix > array_suffixes)\n\t\t\t\tarray_suffix -= 2;\n\t\t\tid = array->type;\n\t\t\tbreak;\n\t\tcase BTF_KIND_PTR:\n\t\t\tkinds |= BTF_KIND_BIT(BTF_KIND_PTR);\n\t\t\tif (ptr_suffix > ptr_suffixes)\n\t\t\t\tptr_suffix -= 1;\n\t\t\tid = t->type;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tid = 0;\n\t\t\tbreak;\n\t\t}\n\t\tif (!id)\n\t\t\tbreak;\n\t\tt = btf_type_skip_qualifiers(show->btf, id);\n\t}\n\t \n\tif (i == BTF_SHOW_MAX_ITER)\n\t\treturn \"\";\n\n\tif (!name)\n\t\tname = btf_name_by_offset(show->btf, t->name_off);\n\n\tswitch (BTF_INFO_KIND(t->info)) {\n\tcase BTF_KIND_STRUCT:\n\tcase BTF_KIND_UNION:\n\t\tprefix = BTF_INFO_KIND(t->info) == BTF_KIND_STRUCT ?\n\t\t\t \"struct\" : \"union\";\n\t\t \n\t\tif (!(kinds & (BTF_KIND_BIT(BTF_KIND_ARRAY))))\n\t\t\tparens = \"{\";\n\t\tbreak;\n\tcase BTF_KIND_ENUM:\n\tcase BTF_KIND_ENUM64:\n\t\tprefix = \"enum\";\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tif (kinds & BTF_KIND_BIT(BTF_KIND_PTR))\n\t\tparens = \"\";\n\t \n\tif (kinds & BTF_KIND_BIT(BTF_KIND_TYPEDEF))\n\t\tprefix = \"\";\n\n\tif (!name)\n\t\tname = \"\";\n\n\t \n\tif (show->flags & BTF_SHOW_NONAME)\n\t\tsnprintf(show->state.name, sizeof(show->state.name), \"%s\",\n\t\t\t parens);\n\telse\n\t\tsnprintf(show->state.name, sizeof(show->state.name),\n\t\t\t \"%s%s%s(%s%s%s%s%s%s)%s\",\n\t\t\t  \n\t\t\t show_member ? \".\" : \"\",\n\t\t\t show_member ? member : \"\",\n\t\t\t show_member ? \" = \" : \"\",\n\t\t\t  \n\t\t\t prefix,\n\t\t\t strlen(prefix) > 0 && strlen(name) > 0 ? \" \" : \"\",\n\t\t\t  \n\t\t\t name,\n\t\t\t  \n\t\t\t strlen(ptr_suffix) > 0 ? \" \" : \"\", ptr_suffix,\n\t\t\t array_suffix, parens);\n\n\treturn show->state.name;\n}\n\nstatic const char *__btf_show_indent(struct btf_show *show)\n{\n\tconst char *indents = \"                                \";\n\tconst char *indent = &indents[strlen(indents)];\n\n\tif ((indent - show->state.depth) >= indents)\n\t\treturn indent - show->state.depth;\n\treturn indents;\n}\n\nstatic const char *btf_show_indent(struct btf_show *show)\n{\n\treturn show->flags & BTF_SHOW_COMPACT ? \"\" : __btf_show_indent(show);\n}\n\nstatic const char *btf_show_newline(struct btf_show *show)\n{\n\treturn show->flags & BTF_SHOW_COMPACT ? \"\" : \"\\n\";\n}\n\nstatic const char *btf_show_delim(struct btf_show *show)\n{\n\tif (show->state.depth == 0)\n\t\treturn \"\";\n\n\tif ((show->flags & BTF_SHOW_COMPACT) && show->state.type &&\n\t\tBTF_INFO_KIND(show->state.type->info) == BTF_KIND_UNION)\n\t\treturn \"|\";\n\n\treturn \",\";\n}\n\n__printf(2, 3) static void btf_show(struct btf_show *show, const char *fmt, ...)\n{\n\tva_list args;\n\n\tif (!show->state.depth_check) {\n\t\tva_start(args, fmt);\n\t\tshow->showfn(show, fmt, args);\n\t\tva_end(args);\n\t}\n}\n\n \n#define btf_show_type_value(show, fmt, value)\t\t\t\t       \\\n\tdo {\t\t\t\t\t\t\t\t       \\\n\t\tif ((value) != (__typeof__(value))0 ||\t\t\t       \\\n\t\t    (show->flags & BTF_SHOW_ZERO) ||\t\t\t       \\\n\t\t    show->state.depth == 0) {\t\t\t\t       \\\n\t\t\tbtf_show(show, \"%s%s\" fmt \"%s%s\",\t\t       \\\n\t\t\t\t btf_show_indent(show),\t\t\t       \\\n\t\t\t\t btf_show_name(show),\t\t\t       \\\n\t\t\t\t value, btf_show_delim(show),\t\t       \\\n\t\t\t\t btf_show_newline(show));\t\t       \\\n\t\t\tif (show->state.depth > show->state.depth_to_show)     \\\n\t\t\t\tshow->state.depth_to_show = show->state.depth; \\\n\t\t}\t\t\t\t\t\t\t       \\\n\t} while (0)\n\n#define btf_show_type_values(show, fmt, ...)\t\t\t\t       \\\n\tdo {\t\t\t\t\t\t\t\t       \\\n\t\tbtf_show(show, \"%s%s\" fmt \"%s%s\", btf_show_indent(show),       \\\n\t\t\t btf_show_name(show),\t\t\t\t       \\\n\t\t\t __VA_ARGS__, btf_show_delim(show),\t\t       \\\n\t\t\t btf_show_newline(show));\t\t\t       \\\n\t\tif (show->state.depth > show->state.depth_to_show)\t       \\\n\t\t\tshow->state.depth_to_show = show->state.depth;\t       \\\n\t} while (0)\n\n \nstatic int btf_show_obj_size_left(struct btf_show *show, void *data)\n{\n\treturn show->obj.head + show->obj.size - data;\n}\n\n \nstatic bool btf_show_obj_is_safe(struct btf_show *show, void *data, int size)\n{\n\treturn data >= show->obj.data &&\n\t       (data + size) < (show->obj.data + BTF_SHOW_OBJ_SAFE_SIZE);\n}\n\n \nstatic void *__btf_show_obj_safe(struct btf_show *show, void *data, int size)\n{\n\tif (btf_show_obj_is_safe(show, data, size))\n\t\treturn show->obj.safe + (data - show->obj.data);\n\treturn NULL;\n}\n\n \nstatic void *btf_show_obj_safe(struct btf_show *show,\n\t\t\t       const struct btf_type *t,\n\t\t\t       void *data)\n{\n\tconst struct btf_type *rt;\n\tint size_left, size;\n\tvoid *safe = NULL;\n\n\tif (show->flags & BTF_SHOW_UNSAFE)\n\t\treturn data;\n\n\trt = btf_resolve_size(show->btf, t, &size);\n\tif (IS_ERR(rt)) {\n\t\tshow->state.status = PTR_ERR(rt);\n\t\treturn NULL;\n\t}\n\n\t \n\tif (show->state.depth == 0) {\n\t\tshow->obj.size = size;\n\t\tshow->obj.head = data;\n\t} else {\n\t\t \n\t\tsafe = __btf_show_obj_safe(show, data,\n\t\t\t\t\t   min(size,\n\t\t\t\t\t       BTF_SHOW_OBJ_BASE_TYPE_SIZE));\n\t}\n\n\t \n\tif (!safe) {\n\t\tsize_left = btf_show_obj_size_left(show, data);\n\t\tif (size_left > BTF_SHOW_OBJ_SAFE_SIZE)\n\t\t\tsize_left = BTF_SHOW_OBJ_SAFE_SIZE;\n\t\tshow->state.status = copy_from_kernel_nofault(show->obj.safe,\n\t\t\t\t\t\t\t      data, size_left);\n\t\tif (!show->state.status) {\n\t\t\tshow->obj.data = data;\n\t\t\tsafe = show->obj.safe;\n\t\t}\n\t}\n\n\treturn safe;\n}\n\n \nstatic void *btf_show_start_type(struct btf_show *show,\n\t\t\t\t const struct btf_type *t,\n\t\t\t\t u32 type_id, void *data)\n{\n\tshow->state.type = t;\n\tshow->state.type_id = type_id;\n\tshow->state.name[0] = '\\0';\n\n\treturn btf_show_obj_safe(show, t, data);\n}\n\nstatic void btf_show_end_type(struct btf_show *show)\n{\n\tshow->state.type = NULL;\n\tshow->state.type_id = 0;\n\tshow->state.name[0] = '\\0';\n}\n\nstatic void *btf_show_start_aggr_type(struct btf_show *show,\n\t\t\t\t      const struct btf_type *t,\n\t\t\t\t      u32 type_id, void *data)\n{\n\tvoid *safe_data = btf_show_start_type(show, t, type_id, data);\n\n\tif (!safe_data)\n\t\treturn safe_data;\n\n\tbtf_show(show, \"%s%s%s\", btf_show_indent(show),\n\t\t btf_show_name(show),\n\t\t btf_show_newline(show));\n\tshow->state.depth++;\n\treturn safe_data;\n}\n\nstatic void btf_show_end_aggr_type(struct btf_show *show,\n\t\t\t\t   const char *suffix)\n{\n\tshow->state.depth--;\n\tbtf_show(show, \"%s%s%s%s\", btf_show_indent(show), suffix,\n\t\t btf_show_delim(show), btf_show_newline(show));\n\tbtf_show_end_type(show);\n}\n\nstatic void btf_show_start_member(struct btf_show *show,\n\t\t\t\t  const struct btf_member *m)\n{\n\tshow->state.member = m;\n}\n\nstatic void btf_show_start_array_member(struct btf_show *show)\n{\n\tshow->state.array_member = 1;\n\tbtf_show_start_member(show, NULL);\n}\n\nstatic void btf_show_end_member(struct btf_show *show)\n{\n\tshow->state.member = NULL;\n}\n\nstatic void btf_show_end_array_member(struct btf_show *show)\n{\n\tshow->state.array_member = 0;\n\tbtf_show_end_member(show);\n}\n\nstatic void *btf_show_start_array_type(struct btf_show *show,\n\t\t\t\t       const struct btf_type *t,\n\t\t\t\t       u32 type_id,\n\t\t\t\t       u16 array_encoding,\n\t\t\t\t       void *data)\n{\n\tshow->state.array_encoding = array_encoding;\n\tshow->state.array_terminated = 0;\n\treturn btf_show_start_aggr_type(show, t, type_id, data);\n}\n\nstatic void btf_show_end_array_type(struct btf_show *show)\n{\n\tshow->state.array_encoding = 0;\n\tshow->state.array_terminated = 0;\n\tbtf_show_end_aggr_type(show, \"]\");\n}\n\nstatic void *btf_show_start_struct_type(struct btf_show *show,\n\t\t\t\t\tconst struct btf_type *t,\n\t\t\t\t\tu32 type_id,\n\t\t\t\t\tvoid *data)\n{\n\treturn btf_show_start_aggr_type(show, t, type_id, data);\n}\n\nstatic void btf_show_end_struct_type(struct btf_show *show)\n{\n\tbtf_show_end_aggr_type(show, \"}\");\n}\n\n__printf(2, 3) static void __btf_verifier_log(struct bpf_verifier_log *log,\n\t\t\t\t\t      const char *fmt, ...)\n{\n\tva_list args;\n\n\tva_start(args, fmt);\n\tbpf_verifier_vlog(log, fmt, args);\n\tva_end(args);\n}\n\n__printf(2, 3) static void btf_verifier_log(struct btf_verifier_env *env,\n\t\t\t\t\t    const char *fmt, ...)\n{\n\tstruct bpf_verifier_log *log = &env->log;\n\tva_list args;\n\n\tif (!bpf_verifier_log_needed(log))\n\t\treturn;\n\n\tva_start(args, fmt);\n\tbpf_verifier_vlog(log, fmt, args);\n\tva_end(args);\n}\n\n__printf(4, 5) static void __btf_verifier_log_type(struct btf_verifier_env *env,\n\t\t\t\t\t\t   const struct btf_type *t,\n\t\t\t\t\t\t   bool log_details,\n\t\t\t\t\t\t   const char *fmt, ...)\n{\n\tstruct bpf_verifier_log *log = &env->log;\n\tstruct btf *btf = env->btf;\n\tva_list args;\n\n\tif (!bpf_verifier_log_needed(log))\n\t\treturn;\n\n\tif (log->level == BPF_LOG_KERNEL) {\n\t\t \n\t\tif (!fmt)\n\t\t\treturn;\n\n\t\t \n\t\tif (env->btf->base_btf && IS_ENABLED(CONFIG_MODULE_ALLOW_BTF_MISMATCH))\n\t\t\treturn;\n\t}\n\n\t__btf_verifier_log(log, \"[%u] %s %s%s\",\n\t\t\t   env->log_type_id,\n\t\t\t   btf_type_str(t),\n\t\t\t   __btf_name_by_offset(btf, t->name_off),\n\t\t\t   log_details ? \" \" : \"\");\n\n\tif (log_details)\n\t\tbtf_type_ops(t)->log_details(env, t);\n\n\tif (fmt && *fmt) {\n\t\t__btf_verifier_log(log, \" \");\n\t\tva_start(args, fmt);\n\t\tbpf_verifier_vlog(log, fmt, args);\n\t\tva_end(args);\n\t}\n\n\t__btf_verifier_log(log, \"\\n\");\n}\n\n#define btf_verifier_log_type(env, t, ...) \\\n\t__btf_verifier_log_type((env), (t), true, __VA_ARGS__)\n#define btf_verifier_log_basic(env, t, ...) \\\n\t__btf_verifier_log_type((env), (t), false, __VA_ARGS__)\n\n__printf(4, 5)\nstatic void btf_verifier_log_member(struct btf_verifier_env *env,\n\t\t\t\t    const struct btf_type *struct_type,\n\t\t\t\t    const struct btf_member *member,\n\t\t\t\t    const char *fmt, ...)\n{\n\tstruct bpf_verifier_log *log = &env->log;\n\tstruct btf *btf = env->btf;\n\tva_list args;\n\n\tif (!bpf_verifier_log_needed(log))\n\t\treturn;\n\n\tif (log->level == BPF_LOG_KERNEL) {\n\t\tif (!fmt)\n\t\t\treturn;\n\n\t\t \n\t\tif (env->btf->base_btf && IS_ENABLED(CONFIG_MODULE_ALLOW_BTF_MISMATCH))\n\t\t\treturn;\n\t}\n\n\t \n\tif (env->phase != CHECK_META)\n\t\tbtf_verifier_log_type(env, struct_type, NULL);\n\n\tif (btf_type_kflag(struct_type))\n\t\t__btf_verifier_log(log,\n\t\t\t\t   \"\\t%s type_id=%u bitfield_size=%u bits_offset=%u\",\n\t\t\t\t   __btf_name_by_offset(btf, member->name_off),\n\t\t\t\t   member->type,\n\t\t\t\t   BTF_MEMBER_BITFIELD_SIZE(member->offset),\n\t\t\t\t   BTF_MEMBER_BIT_OFFSET(member->offset));\n\telse\n\t\t__btf_verifier_log(log, \"\\t%s type_id=%u bits_offset=%u\",\n\t\t\t\t   __btf_name_by_offset(btf, member->name_off),\n\t\t\t\t   member->type, member->offset);\n\n\tif (fmt && *fmt) {\n\t\t__btf_verifier_log(log, \" \");\n\t\tva_start(args, fmt);\n\t\tbpf_verifier_vlog(log, fmt, args);\n\t\tva_end(args);\n\t}\n\n\t__btf_verifier_log(log, \"\\n\");\n}\n\n__printf(4, 5)\nstatic void btf_verifier_log_vsi(struct btf_verifier_env *env,\n\t\t\t\t const struct btf_type *datasec_type,\n\t\t\t\t const struct btf_var_secinfo *vsi,\n\t\t\t\t const char *fmt, ...)\n{\n\tstruct bpf_verifier_log *log = &env->log;\n\tva_list args;\n\n\tif (!bpf_verifier_log_needed(log))\n\t\treturn;\n\tif (log->level == BPF_LOG_KERNEL && !fmt)\n\t\treturn;\n\tif (env->phase != CHECK_META)\n\t\tbtf_verifier_log_type(env, datasec_type, NULL);\n\n\t__btf_verifier_log(log, \"\\t type_id=%u offset=%u size=%u\",\n\t\t\t   vsi->type, vsi->offset, vsi->size);\n\tif (fmt && *fmt) {\n\t\t__btf_verifier_log(log, \" \");\n\t\tva_start(args, fmt);\n\t\tbpf_verifier_vlog(log, fmt, args);\n\t\tva_end(args);\n\t}\n\n\t__btf_verifier_log(log, \"\\n\");\n}\n\nstatic void btf_verifier_log_hdr(struct btf_verifier_env *env,\n\t\t\t\t u32 btf_data_size)\n{\n\tstruct bpf_verifier_log *log = &env->log;\n\tconst struct btf *btf = env->btf;\n\tconst struct btf_header *hdr;\n\n\tif (!bpf_verifier_log_needed(log))\n\t\treturn;\n\n\tif (log->level == BPF_LOG_KERNEL)\n\t\treturn;\n\thdr = &btf->hdr;\n\t__btf_verifier_log(log, \"magic: 0x%x\\n\", hdr->magic);\n\t__btf_verifier_log(log, \"version: %u\\n\", hdr->version);\n\t__btf_verifier_log(log, \"flags: 0x%x\\n\", hdr->flags);\n\t__btf_verifier_log(log, \"hdr_len: %u\\n\", hdr->hdr_len);\n\t__btf_verifier_log(log, \"type_off: %u\\n\", hdr->type_off);\n\t__btf_verifier_log(log, \"type_len: %u\\n\", hdr->type_len);\n\t__btf_verifier_log(log, \"str_off: %u\\n\", hdr->str_off);\n\t__btf_verifier_log(log, \"str_len: %u\\n\", hdr->str_len);\n\t__btf_verifier_log(log, \"btf_total_size: %u\\n\", btf_data_size);\n}\n\nstatic int btf_add_type(struct btf_verifier_env *env, struct btf_type *t)\n{\n\tstruct btf *btf = env->btf;\n\n\tif (btf->types_size == btf->nr_types) {\n\t\t \n\n\t\tstruct btf_type **new_types;\n\t\tu32 expand_by, new_size;\n\n\t\tif (btf->start_id + btf->types_size == BTF_MAX_TYPE) {\n\t\t\tbtf_verifier_log(env, \"Exceeded max num of types\");\n\t\t\treturn -E2BIG;\n\t\t}\n\n\t\texpand_by = max_t(u32, btf->types_size >> 2, 16);\n\t\tnew_size = min_t(u32, BTF_MAX_TYPE,\n\t\t\t\t btf->types_size + expand_by);\n\n\t\tnew_types = kvcalloc(new_size, sizeof(*new_types),\n\t\t\t\t     GFP_KERNEL | __GFP_NOWARN);\n\t\tif (!new_types)\n\t\t\treturn -ENOMEM;\n\n\t\tif (btf->nr_types == 0) {\n\t\t\tif (!btf->base_btf) {\n\t\t\t\t \n\t\t\t\tnew_types[0] = &btf_void;\n\t\t\t\tbtf->nr_types++;\n\t\t\t}\n\t\t} else {\n\t\t\tmemcpy(new_types, btf->types,\n\t\t\t       sizeof(*btf->types) * btf->nr_types);\n\t\t}\n\n\t\tkvfree(btf->types);\n\t\tbtf->types = new_types;\n\t\tbtf->types_size = new_size;\n\t}\n\n\tbtf->types[btf->nr_types++] = t;\n\n\treturn 0;\n}\n\nstatic int btf_alloc_id(struct btf *btf)\n{\n\tint id;\n\n\tidr_preload(GFP_KERNEL);\n\tspin_lock_bh(&btf_idr_lock);\n\tid = idr_alloc_cyclic(&btf_idr, btf, 1, INT_MAX, GFP_ATOMIC);\n\tif (id > 0)\n\t\tbtf->id = id;\n\tspin_unlock_bh(&btf_idr_lock);\n\tidr_preload_end();\n\n\tif (WARN_ON_ONCE(!id))\n\t\treturn -ENOSPC;\n\n\treturn id > 0 ? 0 : id;\n}\n\nstatic void btf_free_id(struct btf *btf)\n{\n\tunsigned long flags;\n\n\t \n\tspin_lock_irqsave(&btf_idr_lock, flags);\n\tidr_remove(&btf_idr, btf->id);\n\tspin_unlock_irqrestore(&btf_idr_lock, flags);\n}\n\nstatic void btf_free_kfunc_set_tab(struct btf *btf)\n{\n\tstruct btf_kfunc_set_tab *tab = btf->kfunc_set_tab;\n\tint hook;\n\n\tif (!tab)\n\t\treturn;\n\t \n\tif (btf_is_module(btf))\n\t\tgoto free_tab;\n\tfor (hook = 0; hook < ARRAY_SIZE(tab->sets); hook++)\n\t\tkfree(tab->sets[hook]);\nfree_tab:\n\tkfree(tab);\n\tbtf->kfunc_set_tab = NULL;\n}\n\nstatic void btf_free_dtor_kfunc_tab(struct btf *btf)\n{\n\tstruct btf_id_dtor_kfunc_tab *tab = btf->dtor_kfunc_tab;\n\n\tif (!tab)\n\t\treturn;\n\tkfree(tab);\n\tbtf->dtor_kfunc_tab = NULL;\n}\n\nstatic void btf_struct_metas_free(struct btf_struct_metas *tab)\n{\n\tint i;\n\n\tif (!tab)\n\t\treturn;\n\tfor (i = 0; i < tab->cnt; i++)\n\t\tbtf_record_free(tab->types[i].record);\n\tkfree(tab);\n}\n\nstatic void btf_free_struct_meta_tab(struct btf *btf)\n{\n\tstruct btf_struct_metas *tab = btf->struct_meta_tab;\n\n\tbtf_struct_metas_free(tab);\n\tbtf->struct_meta_tab = NULL;\n}\n\nstatic void btf_free(struct btf *btf)\n{\n\tbtf_free_struct_meta_tab(btf);\n\tbtf_free_dtor_kfunc_tab(btf);\n\tbtf_free_kfunc_set_tab(btf);\n\tkvfree(btf->types);\n\tkvfree(btf->resolved_sizes);\n\tkvfree(btf->resolved_ids);\n\tkvfree(btf->data);\n\tkfree(btf);\n}\n\nstatic void btf_free_rcu(struct rcu_head *rcu)\n{\n\tstruct btf *btf = container_of(rcu, struct btf, rcu);\n\n\tbtf_free(btf);\n}\n\nvoid btf_get(struct btf *btf)\n{\n\trefcount_inc(&btf->refcnt);\n}\n\nvoid btf_put(struct btf *btf)\n{\n\tif (btf && refcount_dec_and_test(&btf->refcnt)) {\n\t\tbtf_free_id(btf);\n\t\tcall_rcu(&btf->rcu, btf_free_rcu);\n\t}\n}\n\nstatic int env_resolve_init(struct btf_verifier_env *env)\n{\n\tstruct btf *btf = env->btf;\n\tu32 nr_types = btf->nr_types;\n\tu32 *resolved_sizes = NULL;\n\tu32 *resolved_ids = NULL;\n\tu8 *visit_states = NULL;\n\n\tresolved_sizes = kvcalloc(nr_types, sizeof(*resolved_sizes),\n\t\t\t\t  GFP_KERNEL | __GFP_NOWARN);\n\tif (!resolved_sizes)\n\t\tgoto nomem;\n\n\tresolved_ids = kvcalloc(nr_types, sizeof(*resolved_ids),\n\t\t\t\tGFP_KERNEL | __GFP_NOWARN);\n\tif (!resolved_ids)\n\t\tgoto nomem;\n\n\tvisit_states = kvcalloc(nr_types, sizeof(*visit_states),\n\t\t\t\tGFP_KERNEL | __GFP_NOWARN);\n\tif (!visit_states)\n\t\tgoto nomem;\n\n\tbtf->resolved_sizes = resolved_sizes;\n\tbtf->resolved_ids = resolved_ids;\n\tenv->visit_states = visit_states;\n\n\treturn 0;\n\nnomem:\n\tkvfree(resolved_sizes);\n\tkvfree(resolved_ids);\n\tkvfree(visit_states);\n\treturn -ENOMEM;\n}\n\nstatic void btf_verifier_env_free(struct btf_verifier_env *env)\n{\n\tkvfree(env->visit_states);\n\tkfree(env);\n}\n\nstatic bool env_type_is_resolve_sink(const struct btf_verifier_env *env,\n\t\t\t\t     const struct btf_type *next_type)\n{\n\tswitch (env->resolve_mode) {\n\tcase RESOLVE_TBD:\n\t\t \n\t\treturn !btf_type_needs_resolve(next_type);\n\tcase RESOLVE_PTR:\n\t\t \n\t\treturn !btf_type_is_modifier(next_type) &&\n\t\t\t!btf_type_is_ptr(next_type);\n\tcase RESOLVE_STRUCT_OR_ARRAY:\n\t\t \n\t\treturn !btf_type_is_modifier(next_type) &&\n\t\t\t!btf_type_is_array(next_type) &&\n\t\t\t!btf_type_is_struct(next_type);\n\tdefault:\n\t\tBUG();\n\t}\n}\n\nstatic bool env_type_is_resolved(const struct btf_verifier_env *env,\n\t\t\t\t u32 type_id)\n{\n\t \n\tif (type_id < env->btf->start_id)\n\t\treturn true;\n\n\treturn env->visit_states[type_id - env->btf->start_id] == RESOLVED;\n}\n\nstatic int env_stack_push(struct btf_verifier_env *env,\n\t\t\t  const struct btf_type *t, u32 type_id)\n{\n\tconst struct btf *btf = env->btf;\n\tstruct resolve_vertex *v;\n\n\tif (env->top_stack == MAX_RESOLVE_DEPTH)\n\t\treturn -E2BIG;\n\n\tif (type_id < btf->start_id\n\t    || env->visit_states[type_id - btf->start_id] != NOT_VISITED)\n\t\treturn -EEXIST;\n\n\tenv->visit_states[type_id - btf->start_id] = VISITED;\n\n\tv = &env->stack[env->top_stack++];\n\tv->t = t;\n\tv->type_id = type_id;\n\tv->next_member = 0;\n\n\tif (env->resolve_mode == RESOLVE_TBD) {\n\t\tif (btf_type_is_ptr(t))\n\t\t\tenv->resolve_mode = RESOLVE_PTR;\n\t\telse if (btf_type_is_struct(t) || btf_type_is_array(t))\n\t\t\tenv->resolve_mode = RESOLVE_STRUCT_OR_ARRAY;\n\t}\n\n\treturn 0;\n}\n\nstatic void env_stack_set_next_member(struct btf_verifier_env *env,\n\t\t\t\t      u16 next_member)\n{\n\tenv->stack[env->top_stack - 1].next_member = next_member;\n}\n\nstatic void env_stack_pop_resolved(struct btf_verifier_env *env,\n\t\t\t\t   u32 resolved_type_id,\n\t\t\t\t   u32 resolved_size)\n{\n\tu32 type_id = env->stack[--(env->top_stack)].type_id;\n\tstruct btf *btf = env->btf;\n\n\ttype_id -= btf->start_id;  \n\tbtf->resolved_sizes[type_id] = resolved_size;\n\tbtf->resolved_ids[type_id] = resolved_type_id;\n\tenv->visit_states[type_id] = RESOLVED;\n}\n\nstatic const struct resolve_vertex *env_stack_peak(struct btf_verifier_env *env)\n{\n\treturn env->top_stack ? &env->stack[env->top_stack - 1] : NULL;\n}\n\n \nstatic const struct btf_type *\n__btf_resolve_size(const struct btf *btf, const struct btf_type *type,\n\t\t   u32 *type_size, const struct btf_type **elem_type,\n\t\t   u32 *elem_id, u32 *total_nelems, u32 *type_id)\n{\n\tconst struct btf_type *array_type = NULL;\n\tconst struct btf_array *array = NULL;\n\tu32 i, size, nelems = 1, id = 0;\n\n\tfor (i = 0; i < MAX_RESOLVE_DEPTH; i++) {\n\t\tswitch (BTF_INFO_KIND(type->info)) {\n\t\t \n\t\tcase BTF_KIND_INT:\n\t\tcase BTF_KIND_STRUCT:\n\t\tcase BTF_KIND_UNION:\n\t\tcase BTF_KIND_ENUM:\n\t\tcase BTF_KIND_FLOAT:\n\t\tcase BTF_KIND_ENUM64:\n\t\t\tsize = type->size;\n\t\t\tgoto resolved;\n\n\t\tcase BTF_KIND_PTR:\n\t\t\tsize = sizeof(void *);\n\t\t\tgoto resolved;\n\n\t\t \n\t\tcase BTF_KIND_TYPEDEF:\n\t\tcase BTF_KIND_VOLATILE:\n\t\tcase BTF_KIND_CONST:\n\t\tcase BTF_KIND_RESTRICT:\n\t\tcase BTF_KIND_TYPE_TAG:\n\t\t\tid = type->type;\n\t\t\ttype = btf_type_by_id(btf, type->type);\n\t\t\tbreak;\n\n\t\tcase BTF_KIND_ARRAY:\n\t\t\tif (!array_type)\n\t\t\t\tarray_type = type;\n\t\t\tarray = btf_type_array(type);\n\t\t\tif (nelems && array->nelems > U32_MAX / nelems)\n\t\t\t\treturn ERR_PTR(-EINVAL);\n\t\t\tnelems *= array->nelems;\n\t\t\ttype = btf_type_by_id(btf, array->type);\n\t\t\tbreak;\n\n\t\t \n\t\tdefault:\n\t\t\treturn ERR_PTR(-EINVAL);\n\t\t}\n\t}\n\n\treturn ERR_PTR(-EINVAL);\n\nresolved:\n\tif (nelems && size > U32_MAX / nelems)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t*type_size = nelems * size;\n\tif (total_nelems)\n\t\t*total_nelems = nelems;\n\tif (elem_type)\n\t\t*elem_type = type;\n\tif (elem_id)\n\t\t*elem_id = array ? array->type : 0;\n\tif (type_id && id)\n\t\t*type_id = id;\n\n\treturn array_type ? : type;\n}\n\nconst struct btf_type *\nbtf_resolve_size(const struct btf *btf, const struct btf_type *type,\n\t\t u32 *type_size)\n{\n\treturn __btf_resolve_size(btf, type, type_size, NULL, NULL, NULL, NULL);\n}\n\nstatic u32 btf_resolved_type_id(const struct btf *btf, u32 type_id)\n{\n\twhile (type_id < btf->start_id)\n\t\tbtf = btf->base_btf;\n\n\treturn btf->resolved_ids[type_id - btf->start_id];\n}\n\n \nstatic const struct btf_type *btf_type_id_resolve(const struct btf *btf,\n\t\t\t\t\t\t  u32 *type_id)\n{\n\t*type_id = btf_resolved_type_id(btf, *type_id);\n\treturn btf_type_by_id(btf, *type_id);\n}\n\nstatic u32 btf_resolved_type_size(const struct btf *btf, u32 type_id)\n{\n\twhile (type_id < btf->start_id)\n\t\tbtf = btf->base_btf;\n\n\treturn btf->resolved_sizes[type_id - btf->start_id];\n}\n\nconst struct btf_type *btf_type_id_size(const struct btf *btf,\n\t\t\t\t\tu32 *type_id, u32 *ret_size)\n{\n\tconst struct btf_type *size_type;\n\tu32 size_type_id = *type_id;\n\tu32 size = 0;\n\n\tsize_type = btf_type_by_id(btf, size_type_id);\n\tif (btf_type_nosize_or_null(size_type))\n\t\treturn NULL;\n\n\tif (btf_type_has_size(size_type)) {\n\t\tsize = size_type->size;\n\t} else if (btf_type_is_array(size_type)) {\n\t\tsize = btf_resolved_type_size(btf, size_type_id);\n\t} else if (btf_type_is_ptr(size_type)) {\n\t\tsize = sizeof(void *);\n\t} else {\n\t\tif (WARN_ON_ONCE(!btf_type_is_modifier(size_type) &&\n\t\t\t\t !btf_type_is_var(size_type)))\n\t\t\treturn NULL;\n\n\t\tsize_type_id = btf_resolved_type_id(btf, size_type_id);\n\t\tsize_type = btf_type_by_id(btf, size_type_id);\n\t\tif (btf_type_nosize_or_null(size_type))\n\t\t\treturn NULL;\n\t\telse if (btf_type_has_size(size_type))\n\t\t\tsize = size_type->size;\n\t\telse if (btf_type_is_array(size_type))\n\t\t\tsize = btf_resolved_type_size(btf, size_type_id);\n\t\telse if (btf_type_is_ptr(size_type))\n\t\t\tsize = sizeof(void *);\n\t\telse\n\t\t\treturn NULL;\n\t}\n\n\t*type_id = size_type_id;\n\tif (ret_size)\n\t\t*ret_size = size;\n\n\treturn size_type;\n}\n\nstatic int btf_df_check_member(struct btf_verifier_env *env,\n\t\t\t       const struct btf_type *struct_type,\n\t\t\t       const struct btf_member *member,\n\t\t\t       const struct btf_type *member_type)\n{\n\tbtf_verifier_log_basic(env, struct_type,\n\t\t\t       \"Unsupported check_member\");\n\treturn -EINVAL;\n}\n\nstatic int btf_df_check_kflag_member(struct btf_verifier_env *env,\n\t\t\t\t     const struct btf_type *struct_type,\n\t\t\t\t     const struct btf_member *member,\n\t\t\t\t     const struct btf_type *member_type)\n{\n\tbtf_verifier_log_basic(env, struct_type,\n\t\t\t       \"Unsupported check_kflag_member\");\n\treturn -EINVAL;\n}\n\n \nstatic int btf_generic_check_kflag_member(struct btf_verifier_env *env,\n\t\t\t\t\t  const struct btf_type *struct_type,\n\t\t\t\t\t  const struct btf_member *member,\n\t\t\t\t\t  const struct btf_type *member_type)\n{\n\tif (BTF_MEMBER_BITFIELD_SIZE(member->offset)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Invalid member bitfield_size\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\treturn btf_type_ops(member_type)->check_member(env, struct_type,\n\t\t\t\t\t\t       member,\n\t\t\t\t\t\t       member_type);\n}\n\nstatic int btf_df_resolve(struct btf_verifier_env *env,\n\t\t\t  const struct resolve_vertex *v)\n{\n\tbtf_verifier_log_basic(env, v->t, \"Unsupported resolve\");\n\treturn -EINVAL;\n}\n\nstatic void btf_df_show(const struct btf *btf, const struct btf_type *t,\n\t\t\tu32 type_id, void *data, u8 bits_offsets,\n\t\t\tstruct btf_show *show)\n{\n\tbtf_show(show, \"<unsupported kind:%u>\", BTF_INFO_KIND(t->info));\n}\n\nstatic int btf_int_check_member(struct btf_verifier_env *env,\n\t\t\t\tconst struct btf_type *struct_type,\n\t\t\t\tconst struct btf_member *member,\n\t\t\t\tconst struct btf_type *member_type)\n{\n\tu32 int_data = btf_type_int(member_type);\n\tu32 struct_bits_off = member->offset;\n\tu32 struct_size = struct_type->size;\n\tu32 nr_copy_bits;\n\tu32 bytes_offset;\n\n\tif (U32_MAX - struct_bits_off < BTF_INT_OFFSET(int_data)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"bits_offset exceeds U32_MAX\");\n\t\treturn -EINVAL;\n\t}\n\n\tstruct_bits_off += BTF_INT_OFFSET(int_data);\n\tbytes_offset = BITS_ROUNDDOWN_BYTES(struct_bits_off);\n\tnr_copy_bits = BTF_INT_BITS(int_data) +\n\t\tBITS_PER_BYTE_MASKED(struct_bits_off);\n\n\tif (nr_copy_bits > BITS_PER_U128) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"nr_copy_bits exceeds 128\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (struct_size < bytes_offset ||\n\t    struct_size - bytes_offset < BITS_ROUNDUP_BYTES(nr_copy_bits)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member exceeds struct_size\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int btf_int_check_kflag_member(struct btf_verifier_env *env,\n\t\t\t\t      const struct btf_type *struct_type,\n\t\t\t\t      const struct btf_member *member,\n\t\t\t\t      const struct btf_type *member_type)\n{\n\tu32 struct_bits_off, nr_bits, nr_int_data_bits, bytes_offset;\n\tu32 int_data = btf_type_int(member_type);\n\tu32 struct_size = struct_type->size;\n\tu32 nr_copy_bits;\n\n\t \n\tif (!btf_type_int_is_regular(member_type)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Invalid member base type\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tnr_bits = BTF_MEMBER_BITFIELD_SIZE(member->offset);\n\tstruct_bits_off = BTF_MEMBER_BIT_OFFSET(member->offset);\n\tnr_int_data_bits = BTF_INT_BITS(int_data);\n\tif (!nr_bits) {\n\t\t \n\t\tif (BITS_PER_BYTE_MASKED(struct_bits_off)) {\n\t\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\t\"Invalid member offset\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tnr_bits = nr_int_data_bits;\n\t} else if (nr_bits > nr_int_data_bits) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Invalid member bitfield_size\");\n\t\treturn -EINVAL;\n\t}\n\n\tbytes_offset = BITS_ROUNDDOWN_BYTES(struct_bits_off);\n\tnr_copy_bits = nr_bits + BITS_PER_BYTE_MASKED(struct_bits_off);\n\tif (nr_copy_bits > BITS_PER_U128) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"nr_copy_bits exceeds 128\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (struct_size < bytes_offset ||\n\t    struct_size - bytes_offset < BITS_ROUNDUP_BYTES(nr_copy_bits)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member exceeds struct_size\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic s32 btf_int_check_meta(struct btf_verifier_env *env,\n\t\t\t      const struct btf_type *t,\n\t\t\t      u32 meta_left)\n{\n\tu32 int_data, nr_bits, meta_needed = sizeof(int_data);\n\tu16 encoding;\n\n\tif (meta_left < meta_needed) {\n\t\tbtf_verifier_log_basic(env, t,\n\t\t\t\t       \"meta_left:%u meta_needed:%u\",\n\t\t\t\t       meta_left, meta_needed);\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_vlen(t)) {\n\t\tbtf_verifier_log_type(env, t, \"vlen != 0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_kflag(t)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info kind_flag\");\n\t\treturn -EINVAL;\n\t}\n\n\tint_data = btf_type_int(t);\n\tif (int_data & ~BTF_INT_MASK) {\n\t\tbtf_verifier_log_basic(env, t, \"Invalid int_data:%x\",\n\t\t\t\t       int_data);\n\t\treturn -EINVAL;\n\t}\n\n\tnr_bits = BTF_INT_BITS(int_data) + BTF_INT_OFFSET(int_data);\n\n\tif (nr_bits > BITS_PER_U128) {\n\t\tbtf_verifier_log_type(env, t, \"nr_bits exceeds %zu\",\n\t\t\t\t      BITS_PER_U128);\n\t\treturn -EINVAL;\n\t}\n\n\tif (BITS_ROUNDUP_BYTES(nr_bits) > t->size) {\n\t\tbtf_verifier_log_type(env, t, \"nr_bits exceeds type_size\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tencoding = BTF_INT_ENCODING(int_data);\n\tif (encoding &&\n\t    encoding != BTF_INT_SIGNED &&\n\t    encoding != BTF_INT_CHAR &&\n\t    encoding != BTF_INT_BOOL) {\n\t\tbtf_verifier_log_type(env, t, \"Unsupported encoding\");\n\t\treturn -ENOTSUPP;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\treturn meta_needed;\n}\n\nstatic void btf_int_log(struct btf_verifier_env *env,\n\t\t\tconst struct btf_type *t)\n{\n\tint int_data = btf_type_int(t);\n\n\tbtf_verifier_log(env,\n\t\t\t \"size=%u bits_offset=%u nr_bits=%u encoding=%s\",\n\t\t\t t->size, BTF_INT_OFFSET(int_data),\n\t\t\t BTF_INT_BITS(int_data),\n\t\t\t btf_int_encoding_str(BTF_INT_ENCODING(int_data)));\n}\n\nstatic void btf_int128_print(struct btf_show *show, void *data)\n{\n\t \n\tu64 upper_num, lower_num;\n\n#ifdef __BIG_ENDIAN_BITFIELD\n\tupper_num = *(u64 *)data;\n\tlower_num = *(u64 *)(data + 8);\n#else\n\tupper_num = *(u64 *)(data + 8);\n\tlower_num = *(u64 *)data;\n#endif\n\tif (upper_num == 0)\n\t\tbtf_show_type_value(show, \"0x%llx\", lower_num);\n\telse\n\t\tbtf_show_type_values(show, \"0x%llx%016llx\", upper_num,\n\t\t\t\t     lower_num);\n}\n\nstatic void btf_int128_shift(u64 *print_num, u16 left_shift_bits,\n\t\t\t     u16 right_shift_bits)\n{\n\tu64 upper_num, lower_num;\n\n#ifdef __BIG_ENDIAN_BITFIELD\n\tupper_num = print_num[0];\n\tlower_num = print_num[1];\n#else\n\tupper_num = print_num[1];\n\tlower_num = print_num[0];\n#endif\n\n\t \n\tif (left_shift_bits >= 64) {\n\t\tupper_num = lower_num << (left_shift_bits - 64);\n\t\tlower_num = 0;\n\t} else {\n\t\tupper_num = (upper_num << left_shift_bits) |\n\t\t\t    (lower_num >> (64 - left_shift_bits));\n\t\tlower_num = lower_num << left_shift_bits;\n\t}\n\n\tif (right_shift_bits >= 64) {\n\t\tlower_num = upper_num >> (right_shift_bits - 64);\n\t\tupper_num = 0;\n\t} else {\n\t\tlower_num = (lower_num >> right_shift_bits) |\n\t\t\t    (upper_num << (64 - right_shift_bits));\n\t\tupper_num = upper_num >> right_shift_bits;\n\t}\n\n#ifdef __BIG_ENDIAN_BITFIELD\n\tprint_num[0] = upper_num;\n\tprint_num[1] = lower_num;\n#else\n\tprint_num[0] = lower_num;\n\tprint_num[1] = upper_num;\n#endif\n}\n\nstatic void btf_bitfield_show(void *data, u8 bits_offset,\n\t\t\t      u8 nr_bits, struct btf_show *show)\n{\n\tu16 left_shift_bits, right_shift_bits;\n\tu8 nr_copy_bytes;\n\tu8 nr_copy_bits;\n\tu64 print_num[2] = {};\n\n\tnr_copy_bits = nr_bits + bits_offset;\n\tnr_copy_bytes = BITS_ROUNDUP_BYTES(nr_copy_bits);\n\n\tmemcpy(print_num, data, nr_copy_bytes);\n\n#ifdef __BIG_ENDIAN_BITFIELD\n\tleft_shift_bits = bits_offset;\n#else\n\tleft_shift_bits = BITS_PER_U128 - nr_copy_bits;\n#endif\n\tright_shift_bits = BITS_PER_U128 - nr_bits;\n\n\tbtf_int128_shift(print_num, left_shift_bits, right_shift_bits);\n\tbtf_int128_print(show, print_num);\n}\n\n\nstatic void btf_int_bits_show(const struct btf *btf,\n\t\t\t      const struct btf_type *t,\n\t\t\t      void *data, u8 bits_offset,\n\t\t\t      struct btf_show *show)\n{\n\tu32 int_data = btf_type_int(t);\n\tu8 nr_bits = BTF_INT_BITS(int_data);\n\tu8 total_bits_offset;\n\n\t \n\ttotal_bits_offset = bits_offset + BTF_INT_OFFSET(int_data);\n\tdata += BITS_ROUNDDOWN_BYTES(total_bits_offset);\n\tbits_offset = BITS_PER_BYTE_MASKED(total_bits_offset);\n\tbtf_bitfield_show(data, bits_offset, nr_bits, show);\n}\n\nstatic void btf_int_show(const struct btf *btf, const struct btf_type *t,\n\t\t\t u32 type_id, void *data, u8 bits_offset,\n\t\t\t struct btf_show *show)\n{\n\tu32 int_data = btf_type_int(t);\n\tu8 encoding = BTF_INT_ENCODING(int_data);\n\tbool sign = encoding & BTF_INT_SIGNED;\n\tu8 nr_bits = BTF_INT_BITS(int_data);\n\tvoid *safe_data;\n\n\tsafe_data = btf_show_start_type(show, t, type_id, data);\n\tif (!safe_data)\n\t\treturn;\n\n\tif (bits_offset || BTF_INT_OFFSET(int_data) ||\n\t    BITS_PER_BYTE_MASKED(nr_bits)) {\n\t\tbtf_int_bits_show(btf, t, safe_data, bits_offset, show);\n\t\tgoto out;\n\t}\n\n\tswitch (nr_bits) {\n\tcase 128:\n\t\tbtf_int128_print(show, safe_data);\n\t\tbreak;\n\tcase 64:\n\t\tif (sign)\n\t\t\tbtf_show_type_value(show, \"%lld\", *(s64 *)safe_data);\n\t\telse\n\t\t\tbtf_show_type_value(show, \"%llu\", *(u64 *)safe_data);\n\t\tbreak;\n\tcase 32:\n\t\tif (sign)\n\t\t\tbtf_show_type_value(show, \"%d\", *(s32 *)safe_data);\n\t\telse\n\t\t\tbtf_show_type_value(show, \"%u\", *(u32 *)safe_data);\n\t\tbreak;\n\tcase 16:\n\t\tif (sign)\n\t\t\tbtf_show_type_value(show, \"%d\", *(s16 *)safe_data);\n\t\telse\n\t\t\tbtf_show_type_value(show, \"%u\", *(u16 *)safe_data);\n\t\tbreak;\n\tcase 8:\n\t\tif (show->state.array_encoding == BTF_INT_CHAR) {\n\t\t\t \n\t\t\tif (show->state.array_terminated)\n\t\t\t\tbreak;\n\t\t\tif (*(char *)data == '\\0') {\n\t\t\t\tshow->state.array_terminated = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (isprint(*(char *)data)) {\n\t\t\t\tbtf_show_type_value(show, \"'%c'\",\n\t\t\t\t\t\t    *(char *)safe_data);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (sign)\n\t\t\tbtf_show_type_value(show, \"%d\", *(s8 *)safe_data);\n\t\telse\n\t\t\tbtf_show_type_value(show, \"%u\", *(u8 *)safe_data);\n\t\tbreak;\n\tdefault:\n\t\tbtf_int_bits_show(btf, t, safe_data, bits_offset, show);\n\t\tbreak;\n\t}\nout:\n\tbtf_show_end_type(show);\n}\n\nstatic const struct btf_kind_operations int_ops = {\n\t.check_meta = btf_int_check_meta,\n\t.resolve = btf_df_resolve,\n\t.check_member = btf_int_check_member,\n\t.check_kflag_member = btf_int_check_kflag_member,\n\t.log_details = btf_int_log,\n\t.show = btf_int_show,\n};\n\nstatic int btf_modifier_check_member(struct btf_verifier_env *env,\n\t\t\t\t     const struct btf_type *struct_type,\n\t\t\t\t     const struct btf_member *member,\n\t\t\t\t     const struct btf_type *member_type)\n{\n\tconst struct btf_type *resolved_type;\n\tu32 resolved_type_id = member->type;\n\tstruct btf_member resolved_member;\n\tstruct btf *btf = env->btf;\n\n\tresolved_type = btf_type_id_size(btf, &resolved_type_id, NULL);\n\tif (!resolved_type) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Invalid member\");\n\t\treturn -EINVAL;\n\t}\n\n\tresolved_member = *member;\n\tresolved_member.type = resolved_type_id;\n\n\treturn btf_type_ops(resolved_type)->check_member(env, struct_type,\n\t\t\t\t\t\t\t &resolved_member,\n\t\t\t\t\t\t\t resolved_type);\n}\n\nstatic int btf_modifier_check_kflag_member(struct btf_verifier_env *env,\n\t\t\t\t\t   const struct btf_type *struct_type,\n\t\t\t\t\t   const struct btf_member *member,\n\t\t\t\t\t   const struct btf_type *member_type)\n{\n\tconst struct btf_type *resolved_type;\n\tu32 resolved_type_id = member->type;\n\tstruct btf_member resolved_member;\n\tstruct btf *btf = env->btf;\n\n\tresolved_type = btf_type_id_size(btf, &resolved_type_id, NULL);\n\tif (!resolved_type) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Invalid member\");\n\t\treturn -EINVAL;\n\t}\n\n\tresolved_member = *member;\n\tresolved_member.type = resolved_type_id;\n\n\treturn btf_type_ops(resolved_type)->check_kflag_member(env, struct_type,\n\t\t\t\t\t\t\t       &resolved_member,\n\t\t\t\t\t\t\t       resolved_type);\n}\n\nstatic int btf_ptr_check_member(struct btf_verifier_env *env,\n\t\t\t\tconst struct btf_type *struct_type,\n\t\t\t\tconst struct btf_member *member,\n\t\t\t\tconst struct btf_type *member_type)\n{\n\tu32 struct_size, struct_bits_off, bytes_offset;\n\n\tstruct_size = struct_type->size;\n\tstruct_bits_off = member->offset;\n\tbytes_offset = BITS_ROUNDDOWN_BYTES(struct_bits_off);\n\n\tif (BITS_PER_BYTE_MASKED(struct_bits_off)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member is not byte aligned\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (struct_size - bytes_offset < sizeof(void *)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member exceeds struct_size\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int btf_ref_type_check_meta(struct btf_verifier_env *env,\n\t\t\t\t   const struct btf_type *t,\n\t\t\t\t   u32 meta_left)\n{\n\tconst char *value;\n\n\tif (btf_type_vlen(t)) {\n\t\tbtf_verifier_log_type(env, t, \"vlen != 0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_kflag(t)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info kind_flag\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!BTF_TYPE_ID_VALID(t->type)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid type_id\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (BTF_INFO_KIND(t->info) == BTF_KIND_TYPEDEF) {\n\t\tif (!t->name_off ||\n\t\t    !btf_name_valid_identifier(env->btf, t->name_off)) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (BTF_INFO_KIND(t->info) == BTF_KIND_TYPE_TAG) {\n\t\tvalue = btf_name_by_offset(env->btf, t->name_off);\n\t\tif (!value || !value[0]) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tif (t->name_off) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\treturn 0;\n}\n\nstatic int btf_modifier_resolve(struct btf_verifier_env *env,\n\t\t\t\tconst struct resolve_vertex *v)\n{\n\tconst struct btf_type *t = v->t;\n\tconst struct btf_type *next_type;\n\tu32 next_type_id = t->type;\n\tstruct btf *btf = env->btf;\n\n\tnext_type = btf_type_by_id(btf, next_type_id);\n\tif (!next_type || btf_type_is_resolve_source_only(next_type)) {\n\t\tbtf_verifier_log_type(env, v->t, \"Invalid type_id\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env_type_is_resolve_sink(env, next_type) &&\n\t    !env_type_is_resolved(env, next_type_id))\n\t\treturn env_stack_push(env, next_type, next_type_id);\n\n\t \n\tif (!btf_type_id_size(btf, &next_type_id, NULL)) {\n\t\tif (env_type_is_resolved(env, next_type_id))\n\t\t\tnext_type = btf_type_id_resolve(btf, &next_type_id);\n\n\t\t \n\t\tif (!btf_type_is_void(next_type) &&\n\t\t    !btf_type_is_fwd(next_type) &&\n\t\t    !btf_type_is_func_proto(next_type)) {\n\t\t\tbtf_verifier_log_type(env, v->t, \"Invalid type_id\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tenv_stack_pop_resolved(env, next_type_id, 0);\n\n\treturn 0;\n}\n\nstatic int btf_var_resolve(struct btf_verifier_env *env,\n\t\t\t   const struct resolve_vertex *v)\n{\n\tconst struct btf_type *next_type;\n\tconst struct btf_type *t = v->t;\n\tu32 next_type_id = t->type;\n\tstruct btf *btf = env->btf;\n\n\tnext_type = btf_type_by_id(btf, next_type_id);\n\tif (!next_type || btf_type_is_resolve_source_only(next_type)) {\n\t\tbtf_verifier_log_type(env, v->t, \"Invalid type_id\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env_type_is_resolve_sink(env, next_type) &&\n\t    !env_type_is_resolved(env, next_type_id))\n\t\treturn env_stack_push(env, next_type, next_type_id);\n\n\tif (btf_type_is_modifier(next_type)) {\n\t\tconst struct btf_type *resolved_type;\n\t\tu32 resolved_type_id;\n\n\t\tresolved_type_id = next_type_id;\n\t\tresolved_type = btf_type_id_resolve(btf, &resolved_type_id);\n\n\t\tif (btf_type_is_ptr(resolved_type) &&\n\t\t    !env_type_is_resolve_sink(env, resolved_type) &&\n\t\t    !env_type_is_resolved(env, resolved_type_id))\n\t\t\treturn env_stack_push(env, resolved_type,\n\t\t\t\t\t      resolved_type_id);\n\t}\n\n\t \n\tif (!btf_type_id_size(btf, &next_type_id, NULL)) {\n\t\tbtf_verifier_log_type(env, v->t, \"Invalid type_id\");\n\t\treturn -EINVAL;\n\t}\n\n\tenv_stack_pop_resolved(env, next_type_id, 0);\n\n\treturn 0;\n}\n\nstatic int btf_ptr_resolve(struct btf_verifier_env *env,\n\t\t\t   const struct resolve_vertex *v)\n{\n\tconst struct btf_type *next_type;\n\tconst struct btf_type *t = v->t;\n\tu32 next_type_id = t->type;\n\tstruct btf *btf = env->btf;\n\n\tnext_type = btf_type_by_id(btf, next_type_id);\n\tif (!next_type || btf_type_is_resolve_source_only(next_type)) {\n\t\tbtf_verifier_log_type(env, v->t, \"Invalid type_id\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env_type_is_resolve_sink(env, next_type) &&\n\t    !env_type_is_resolved(env, next_type_id))\n\t\treturn env_stack_push(env, next_type, next_type_id);\n\n\t \n\tif (btf_type_is_modifier(next_type)) {\n\t\tconst struct btf_type *resolved_type;\n\t\tu32 resolved_type_id;\n\n\t\tresolved_type_id = next_type_id;\n\t\tresolved_type = btf_type_id_resolve(btf, &resolved_type_id);\n\n\t\tif (btf_type_is_ptr(resolved_type) &&\n\t\t    !env_type_is_resolve_sink(env, resolved_type) &&\n\t\t    !env_type_is_resolved(env, resolved_type_id))\n\t\t\treturn env_stack_push(env, resolved_type,\n\t\t\t\t\t      resolved_type_id);\n\t}\n\n\tif (!btf_type_id_size(btf, &next_type_id, NULL)) {\n\t\tif (env_type_is_resolved(env, next_type_id))\n\t\t\tnext_type = btf_type_id_resolve(btf, &next_type_id);\n\n\t\tif (!btf_type_is_void(next_type) &&\n\t\t    !btf_type_is_fwd(next_type) &&\n\t\t    !btf_type_is_func_proto(next_type)) {\n\t\t\tbtf_verifier_log_type(env, v->t, \"Invalid type_id\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tenv_stack_pop_resolved(env, next_type_id, 0);\n\n\treturn 0;\n}\n\nstatic void btf_modifier_show(const struct btf *btf,\n\t\t\t      const struct btf_type *t,\n\t\t\t      u32 type_id, void *data,\n\t\t\t      u8 bits_offset, struct btf_show *show)\n{\n\tif (btf->resolved_ids)\n\t\tt = btf_type_id_resolve(btf, &type_id);\n\telse\n\t\tt = btf_type_skip_modifiers(btf, type_id, NULL);\n\n\tbtf_type_ops(t)->show(btf, t, type_id, data, bits_offset, show);\n}\n\nstatic void btf_var_show(const struct btf *btf, const struct btf_type *t,\n\t\t\t u32 type_id, void *data, u8 bits_offset,\n\t\t\t struct btf_show *show)\n{\n\tt = btf_type_id_resolve(btf, &type_id);\n\n\tbtf_type_ops(t)->show(btf, t, type_id, data, bits_offset, show);\n}\n\nstatic void btf_ptr_show(const struct btf *btf, const struct btf_type *t,\n\t\t\t u32 type_id, void *data, u8 bits_offset,\n\t\t\t struct btf_show *show)\n{\n\tvoid *safe_data;\n\n\tsafe_data = btf_show_start_type(show, t, type_id, data);\n\tif (!safe_data)\n\t\treturn;\n\n\t \n\tif (show->flags & BTF_SHOW_PTR_RAW)\n\t\tbtf_show_type_value(show, \"0x%px\", *(void **)safe_data);\n\telse\n\t\tbtf_show_type_value(show, \"0x%p\", *(void **)safe_data);\n\tbtf_show_end_type(show);\n}\n\nstatic void btf_ref_type_log(struct btf_verifier_env *env,\n\t\t\t     const struct btf_type *t)\n{\n\tbtf_verifier_log(env, \"type_id=%u\", t->type);\n}\n\nstatic struct btf_kind_operations modifier_ops = {\n\t.check_meta = btf_ref_type_check_meta,\n\t.resolve = btf_modifier_resolve,\n\t.check_member = btf_modifier_check_member,\n\t.check_kflag_member = btf_modifier_check_kflag_member,\n\t.log_details = btf_ref_type_log,\n\t.show = btf_modifier_show,\n};\n\nstatic struct btf_kind_operations ptr_ops = {\n\t.check_meta = btf_ref_type_check_meta,\n\t.resolve = btf_ptr_resolve,\n\t.check_member = btf_ptr_check_member,\n\t.check_kflag_member = btf_generic_check_kflag_member,\n\t.log_details = btf_ref_type_log,\n\t.show = btf_ptr_show,\n};\n\nstatic s32 btf_fwd_check_meta(struct btf_verifier_env *env,\n\t\t\t      const struct btf_type *t,\n\t\t\t      u32 meta_left)\n{\n\tif (btf_type_vlen(t)) {\n\t\tbtf_verifier_log_type(env, t, \"vlen != 0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (t->type) {\n\t\tbtf_verifier_log_type(env, t, \"type != 0\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (!t->name_off ||\n\t    !btf_name_valid_identifier(env->btf, t->name_off)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\treturn 0;\n}\n\nstatic void btf_fwd_type_log(struct btf_verifier_env *env,\n\t\t\t     const struct btf_type *t)\n{\n\tbtf_verifier_log(env, \"%s\", btf_type_kflag(t) ? \"union\" : \"struct\");\n}\n\nstatic struct btf_kind_operations fwd_ops = {\n\t.check_meta = btf_fwd_check_meta,\n\t.resolve = btf_df_resolve,\n\t.check_member = btf_df_check_member,\n\t.check_kflag_member = btf_df_check_kflag_member,\n\t.log_details = btf_fwd_type_log,\n\t.show = btf_df_show,\n};\n\nstatic int btf_array_check_member(struct btf_verifier_env *env,\n\t\t\t\t  const struct btf_type *struct_type,\n\t\t\t\t  const struct btf_member *member,\n\t\t\t\t  const struct btf_type *member_type)\n{\n\tu32 struct_bits_off = member->offset;\n\tu32 struct_size, bytes_offset;\n\tu32 array_type_id, array_size;\n\tstruct btf *btf = env->btf;\n\n\tif (BITS_PER_BYTE_MASKED(struct_bits_off)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member is not byte aligned\");\n\t\treturn -EINVAL;\n\t}\n\n\tarray_type_id = member->type;\n\tbtf_type_id_size(btf, &array_type_id, &array_size);\n\tstruct_size = struct_type->size;\n\tbytes_offset = BITS_ROUNDDOWN_BYTES(struct_bits_off);\n\tif (struct_size - bytes_offset < array_size) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member exceeds struct_size\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic s32 btf_array_check_meta(struct btf_verifier_env *env,\n\t\t\t\tconst struct btf_type *t,\n\t\t\t\tu32 meta_left)\n{\n\tconst struct btf_array *array = btf_type_array(t);\n\tu32 meta_needed = sizeof(*array);\n\n\tif (meta_left < meta_needed) {\n\t\tbtf_verifier_log_basic(env, t,\n\t\t\t\t       \"meta_left:%u meta_needed:%u\",\n\t\t\t\t       meta_left, meta_needed);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (t->name_off) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_vlen(t)) {\n\t\tbtf_verifier_log_type(env, t, \"vlen != 0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_kflag(t)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info kind_flag\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (t->size) {\n\t\tbtf_verifier_log_type(env, t, \"size != 0\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (!array->type || !BTF_TYPE_ID_VALID(array->type)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid elem\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!array->index_type || !BTF_TYPE_ID_VALID(array->index_type)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid index\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\treturn meta_needed;\n}\n\nstatic int btf_array_resolve(struct btf_verifier_env *env,\n\t\t\t     const struct resolve_vertex *v)\n{\n\tconst struct btf_array *array = btf_type_array(v->t);\n\tconst struct btf_type *elem_type, *index_type;\n\tu32 elem_type_id, index_type_id;\n\tstruct btf *btf = env->btf;\n\tu32 elem_size;\n\n\t \n\tindex_type_id = array->index_type;\n\tindex_type = btf_type_by_id(btf, index_type_id);\n\tif (btf_type_nosize_or_null(index_type) ||\n\t    btf_type_is_resolve_source_only(index_type)) {\n\t\tbtf_verifier_log_type(env, v->t, \"Invalid index\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env_type_is_resolve_sink(env, index_type) &&\n\t    !env_type_is_resolved(env, index_type_id))\n\t\treturn env_stack_push(env, index_type, index_type_id);\n\n\tindex_type = btf_type_id_size(btf, &index_type_id, NULL);\n\tif (!index_type || !btf_type_is_int(index_type) ||\n\t    !btf_type_int_is_regular(index_type)) {\n\t\tbtf_verifier_log_type(env, v->t, \"Invalid index\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\telem_type_id = array->type;\n\telem_type = btf_type_by_id(btf, elem_type_id);\n\tif (btf_type_nosize_or_null(elem_type) ||\n\t    btf_type_is_resolve_source_only(elem_type)) {\n\t\tbtf_verifier_log_type(env, v->t,\n\t\t\t\t      \"Invalid elem\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env_type_is_resolve_sink(env, elem_type) &&\n\t    !env_type_is_resolved(env, elem_type_id))\n\t\treturn env_stack_push(env, elem_type, elem_type_id);\n\n\telem_type = btf_type_id_size(btf, &elem_type_id, &elem_size);\n\tif (!elem_type) {\n\t\tbtf_verifier_log_type(env, v->t, \"Invalid elem\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_is_int(elem_type) && !btf_type_int_is_regular(elem_type)) {\n\t\tbtf_verifier_log_type(env, v->t, \"Invalid array of int\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (array->nelems && elem_size > U32_MAX / array->nelems) {\n\t\tbtf_verifier_log_type(env, v->t,\n\t\t\t\t      \"Array size overflows U32_MAX\");\n\t\treturn -EINVAL;\n\t}\n\n\tenv_stack_pop_resolved(env, elem_type_id, elem_size * array->nelems);\n\n\treturn 0;\n}\n\nstatic void btf_array_log(struct btf_verifier_env *env,\n\t\t\t  const struct btf_type *t)\n{\n\tconst struct btf_array *array = btf_type_array(t);\n\n\tbtf_verifier_log(env, \"type_id=%u index_type_id=%u nr_elems=%u\",\n\t\t\t array->type, array->index_type, array->nelems);\n}\n\nstatic void __btf_array_show(const struct btf *btf, const struct btf_type *t,\n\t\t\t     u32 type_id, void *data, u8 bits_offset,\n\t\t\t     struct btf_show *show)\n{\n\tconst struct btf_array *array = btf_type_array(t);\n\tconst struct btf_kind_operations *elem_ops;\n\tconst struct btf_type *elem_type;\n\tu32 i, elem_size = 0, elem_type_id;\n\tu16 encoding = 0;\n\n\telem_type_id = array->type;\n\telem_type = btf_type_skip_modifiers(btf, elem_type_id, NULL);\n\tif (elem_type && btf_type_has_size(elem_type))\n\t\telem_size = elem_type->size;\n\n\tif (elem_type && btf_type_is_int(elem_type)) {\n\t\tu32 int_type = btf_type_int(elem_type);\n\n\t\tencoding = BTF_INT_ENCODING(int_type);\n\n\t\t \n\t\tif (elem_size == 1)\n\t\t\tencoding = BTF_INT_CHAR;\n\t}\n\n\tif (!btf_show_start_array_type(show, t, type_id, encoding, data))\n\t\treturn;\n\n\tif (!elem_type)\n\t\tgoto out;\n\telem_ops = btf_type_ops(elem_type);\n\n\tfor (i = 0; i < array->nelems; i++) {\n\n\t\tbtf_show_start_array_member(show);\n\n\t\telem_ops->show(btf, elem_type, elem_type_id, data,\n\t\t\t       bits_offset, show);\n\t\tdata += elem_size;\n\n\t\tbtf_show_end_array_member(show);\n\n\t\tif (show->state.array_terminated)\n\t\t\tbreak;\n\t}\nout:\n\tbtf_show_end_array_type(show);\n}\n\nstatic void btf_array_show(const struct btf *btf, const struct btf_type *t,\n\t\t\t   u32 type_id, void *data, u8 bits_offset,\n\t\t\t   struct btf_show *show)\n{\n\tconst struct btf_member *m = show->state.member;\n\n\t \n\tif (show->state.depth > 0 && !(show->flags & BTF_SHOW_ZERO)) {\n\t\tif (!show->state.depth_check) {\n\t\t\tshow->state.depth_check = show->state.depth + 1;\n\t\t\tshow->state.depth_to_show = 0;\n\t\t}\n\t\t__btf_array_show(btf, t, type_id, data, bits_offset, show);\n\t\tshow->state.member = m;\n\n\t\tif (show->state.depth_check != show->state.depth + 1)\n\t\t\treturn;\n\t\tshow->state.depth_check = 0;\n\n\t\tif (show->state.depth_to_show <= show->state.depth)\n\t\t\treturn;\n\t\t \n\t}\n\t__btf_array_show(btf, t, type_id, data, bits_offset, show);\n}\n\nstatic struct btf_kind_operations array_ops = {\n\t.check_meta = btf_array_check_meta,\n\t.resolve = btf_array_resolve,\n\t.check_member = btf_array_check_member,\n\t.check_kflag_member = btf_generic_check_kflag_member,\n\t.log_details = btf_array_log,\n\t.show = btf_array_show,\n};\n\nstatic int btf_struct_check_member(struct btf_verifier_env *env,\n\t\t\t\t   const struct btf_type *struct_type,\n\t\t\t\t   const struct btf_member *member,\n\t\t\t\t   const struct btf_type *member_type)\n{\n\tu32 struct_bits_off = member->offset;\n\tu32 struct_size, bytes_offset;\n\n\tif (BITS_PER_BYTE_MASKED(struct_bits_off)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member is not byte aligned\");\n\t\treturn -EINVAL;\n\t}\n\n\tstruct_size = struct_type->size;\n\tbytes_offset = BITS_ROUNDDOWN_BYTES(struct_bits_off);\n\tif (struct_size - bytes_offset < member_type->size) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member exceeds struct_size\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic s32 btf_struct_check_meta(struct btf_verifier_env *env,\n\t\t\t\t const struct btf_type *t,\n\t\t\t\t u32 meta_left)\n{\n\tbool is_union = BTF_INFO_KIND(t->info) == BTF_KIND_UNION;\n\tconst struct btf_member *member;\n\tu32 meta_needed, last_offset;\n\tstruct btf *btf = env->btf;\n\tu32 struct_size = t->size;\n\tu32 offset;\n\tu16 i;\n\n\tmeta_needed = btf_type_vlen(t) * sizeof(*member);\n\tif (meta_left < meta_needed) {\n\t\tbtf_verifier_log_basic(env, t,\n\t\t\t\t       \"meta_left:%u meta_needed:%u\",\n\t\t\t\t       meta_left, meta_needed);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (t->name_off &&\n\t    !btf_name_valid_identifier(env->btf, t->name_off)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\tlast_offset = 0;\n\tfor_each_member(i, t, member) {\n\t\tif (!btf_name_offset_valid(btf, member->name_off)) {\n\t\t\tbtf_verifier_log_member(env, t, member,\n\t\t\t\t\t\t\"Invalid member name_offset:%u\",\n\t\t\t\t\t\tmember->name_off);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (member->name_off &&\n\t\t    !btf_name_valid_identifier(btf, member->name_off)) {\n\t\t\tbtf_verifier_log_member(env, t, member, \"Invalid name\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t \n\t\tif (!member->type || !BTF_TYPE_ID_VALID(member->type)) {\n\t\t\tbtf_verifier_log_member(env, t, member,\n\t\t\t\t\t\t\"Invalid type_id\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\toffset = __btf_member_bit_offset(t, member);\n\t\tif (is_union && offset) {\n\t\t\tbtf_verifier_log_member(env, t, member,\n\t\t\t\t\t\t\"Invalid member bits_offset\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (last_offset > offset) {\n\t\t\tbtf_verifier_log_member(env, t, member,\n\t\t\t\t\t\t\"Invalid member bits_offset\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (BITS_ROUNDUP_BYTES(offset) > struct_size) {\n\t\t\tbtf_verifier_log_member(env, t, member,\n\t\t\t\t\t\t\"Member bits_offset exceeds its struct size\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tbtf_verifier_log_member(env, t, member, NULL);\n\t\tlast_offset = offset;\n\t}\n\n\treturn meta_needed;\n}\n\nstatic int btf_struct_resolve(struct btf_verifier_env *env,\n\t\t\t      const struct resolve_vertex *v)\n{\n\tconst struct btf_member *member;\n\tint err;\n\tu16 i;\n\n\t \n\tif (v->next_member) {\n\t\tconst struct btf_type *last_member_type;\n\t\tconst struct btf_member *last_member;\n\t\tu32 last_member_type_id;\n\n\t\tlast_member = btf_type_member(v->t) + v->next_member - 1;\n\t\tlast_member_type_id = last_member->type;\n\t\tif (WARN_ON_ONCE(!env_type_is_resolved(env,\n\t\t\t\t\t\t       last_member_type_id)))\n\t\t\treturn -EINVAL;\n\n\t\tlast_member_type = btf_type_by_id(env->btf,\n\t\t\t\t\t\t  last_member_type_id);\n\t\tif (btf_type_kflag(v->t))\n\t\t\terr = btf_type_ops(last_member_type)->check_kflag_member(env, v->t,\n\t\t\t\t\t\t\t\tlast_member,\n\t\t\t\t\t\t\t\tlast_member_type);\n\t\telse\n\t\t\terr = btf_type_ops(last_member_type)->check_member(env, v->t,\n\t\t\t\t\t\t\t\tlast_member,\n\t\t\t\t\t\t\t\tlast_member_type);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tfor_each_member_from(i, v->next_member, v->t, member) {\n\t\tu32 member_type_id = member->type;\n\t\tconst struct btf_type *member_type = btf_type_by_id(env->btf,\n\t\t\t\t\t\t\t\tmember_type_id);\n\n\t\tif (btf_type_nosize_or_null(member_type) ||\n\t\t    btf_type_is_resolve_source_only(member_type)) {\n\t\t\tbtf_verifier_log_member(env, v->t, member,\n\t\t\t\t\t\t\"Invalid member\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!env_type_is_resolve_sink(env, member_type) &&\n\t\t    !env_type_is_resolved(env, member_type_id)) {\n\t\t\tenv_stack_set_next_member(env, i + 1);\n\t\t\treturn env_stack_push(env, member_type, member_type_id);\n\t\t}\n\n\t\tif (btf_type_kflag(v->t))\n\t\t\terr = btf_type_ops(member_type)->check_kflag_member(env, v->t,\n\t\t\t\t\t\t\t\t\t    member,\n\t\t\t\t\t\t\t\t\t    member_type);\n\t\telse\n\t\t\terr = btf_type_ops(member_type)->check_member(env, v->t,\n\t\t\t\t\t\t\t\t      member,\n\t\t\t\t\t\t\t\t      member_type);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tenv_stack_pop_resolved(env, 0, 0);\n\n\treturn 0;\n}\n\nstatic void btf_struct_log(struct btf_verifier_env *env,\n\t\t\t   const struct btf_type *t)\n{\n\tbtf_verifier_log(env, \"size=%u vlen=%u\", t->size, btf_type_vlen(t));\n}\n\nenum {\n\tBTF_FIELD_IGNORE = 0,\n\tBTF_FIELD_FOUND  = 1,\n};\n\nstruct btf_field_info {\n\tenum btf_field_type type;\n\tu32 off;\n\tunion {\n\t\tstruct {\n\t\t\tu32 type_id;\n\t\t} kptr;\n\t\tstruct {\n\t\t\tconst char *node_name;\n\t\t\tu32 value_btf_id;\n\t\t} graph_root;\n\t};\n};\n\nstatic int btf_find_struct(const struct btf *btf, const struct btf_type *t,\n\t\t\t   u32 off, int sz, enum btf_field_type field_type,\n\t\t\t   struct btf_field_info *info)\n{\n\tif (!__btf_type_is_struct(t))\n\t\treturn BTF_FIELD_IGNORE;\n\tif (t->size != sz)\n\t\treturn BTF_FIELD_IGNORE;\n\tinfo->type = field_type;\n\tinfo->off = off;\n\treturn BTF_FIELD_FOUND;\n}\n\nstatic int btf_find_kptr(const struct btf *btf, const struct btf_type *t,\n\t\t\t u32 off, int sz, struct btf_field_info *info)\n{\n\tenum btf_field_type type;\n\tu32 res_id;\n\n\t \n\tif (btf_type_is_volatile(t))\n\t\tt = btf_type_by_id(btf, t->type);\n\t \n\tif (!btf_type_is_ptr(t))\n\t\treturn BTF_FIELD_IGNORE;\n\tt = btf_type_by_id(btf, t->type);\n\n\tif (!btf_type_is_type_tag(t))\n\t\treturn BTF_FIELD_IGNORE;\n\t \n\tif (btf_type_is_type_tag(btf_type_by_id(btf, t->type)))\n\t\treturn -EINVAL;\n\tif (!strcmp(\"kptr_untrusted\", __btf_name_by_offset(btf, t->name_off)))\n\t\ttype = BPF_KPTR_UNREF;\n\telse if (!strcmp(\"kptr\", __btf_name_by_offset(btf, t->name_off)))\n\t\ttype = BPF_KPTR_REF;\n\telse\n\t\treturn -EINVAL;\n\n\t \n\tt = btf_type_skip_modifiers(btf, t->type, &res_id);\n\t \n\tif (!__btf_type_is_struct(t))\n\t\treturn -EINVAL;\n\n\tinfo->type = type;\n\tinfo->off = off;\n\tinfo->kptr.type_id = res_id;\n\treturn BTF_FIELD_FOUND;\n}\n\nstatic const char *btf_find_decl_tag_value(const struct btf *btf,\n\t\t\t\t\t   const struct btf_type *pt,\n\t\t\t\t\t   int comp_idx, const char *tag_key)\n{\n\tint i;\n\n\tfor (i = 1; i < btf_nr_types(btf); i++) {\n\t\tconst struct btf_type *t = btf_type_by_id(btf, i);\n\t\tint len = strlen(tag_key);\n\n\t\tif (!btf_type_is_decl_tag(t))\n\t\t\tcontinue;\n\t\tif (pt != btf_type_by_id(btf, t->type) ||\n\t\t    btf_type_decl_tag(t)->component_idx != comp_idx)\n\t\t\tcontinue;\n\t\tif (strncmp(__btf_name_by_offset(btf, t->name_off), tag_key, len))\n\t\t\tcontinue;\n\t\treturn __btf_name_by_offset(btf, t->name_off) + len;\n\t}\n\treturn NULL;\n}\n\nstatic int\nbtf_find_graph_root(const struct btf *btf, const struct btf_type *pt,\n\t\t    const struct btf_type *t, int comp_idx, u32 off,\n\t\t    int sz, struct btf_field_info *info,\n\t\t    enum btf_field_type head_type)\n{\n\tconst char *node_field_name;\n\tconst char *value_type;\n\ts32 id;\n\n\tif (!__btf_type_is_struct(t))\n\t\treturn BTF_FIELD_IGNORE;\n\tif (t->size != sz)\n\t\treturn BTF_FIELD_IGNORE;\n\tvalue_type = btf_find_decl_tag_value(btf, pt, comp_idx, \"contains:\");\n\tif (!value_type)\n\t\treturn -EINVAL;\n\tnode_field_name = strstr(value_type, \":\");\n\tif (!node_field_name)\n\t\treturn -EINVAL;\n\tvalue_type = kstrndup(value_type, node_field_name - value_type, GFP_KERNEL | __GFP_NOWARN);\n\tif (!value_type)\n\t\treturn -ENOMEM;\n\tid = btf_find_by_name_kind(btf, value_type, BTF_KIND_STRUCT);\n\tkfree(value_type);\n\tif (id < 0)\n\t\treturn id;\n\tnode_field_name++;\n\tif (str_is_empty(node_field_name))\n\t\treturn -EINVAL;\n\tinfo->type = head_type;\n\tinfo->off = off;\n\tinfo->graph_root.value_btf_id = id;\n\tinfo->graph_root.node_name = node_field_name;\n\treturn BTF_FIELD_FOUND;\n}\n\n#define field_mask_test_name(field_type, field_type_str) \\\n\tif (field_mask & field_type && !strcmp(name, field_type_str)) { \\\n\t\ttype = field_type;\t\t\t\t\t\\\n\t\tgoto end;\t\t\t\t\t\t\\\n\t}\n\nstatic int btf_get_field_type(const char *name, u32 field_mask, u32 *seen_mask,\n\t\t\t      int *align, int *sz)\n{\n\tint type = 0;\n\n\tif (field_mask & BPF_SPIN_LOCK) {\n\t\tif (!strcmp(name, \"bpf_spin_lock\")) {\n\t\t\tif (*seen_mask & BPF_SPIN_LOCK)\n\t\t\t\treturn -E2BIG;\n\t\t\t*seen_mask |= BPF_SPIN_LOCK;\n\t\t\ttype = BPF_SPIN_LOCK;\n\t\t\tgoto end;\n\t\t}\n\t}\n\tif (field_mask & BPF_TIMER) {\n\t\tif (!strcmp(name, \"bpf_timer\")) {\n\t\t\tif (*seen_mask & BPF_TIMER)\n\t\t\t\treturn -E2BIG;\n\t\t\t*seen_mask |= BPF_TIMER;\n\t\t\ttype = BPF_TIMER;\n\t\t\tgoto end;\n\t\t}\n\t}\n\tfield_mask_test_name(BPF_LIST_HEAD, \"bpf_list_head\");\n\tfield_mask_test_name(BPF_LIST_NODE, \"bpf_list_node\");\n\tfield_mask_test_name(BPF_RB_ROOT,   \"bpf_rb_root\");\n\tfield_mask_test_name(BPF_RB_NODE,   \"bpf_rb_node\");\n\tfield_mask_test_name(BPF_REFCOUNT,  \"bpf_refcount\");\n\n\t \n\tif (field_mask & BPF_KPTR) {\n\t\ttype = BPF_KPTR_REF;\n\t\tgoto end;\n\t}\n\treturn 0;\nend:\n\t*sz = btf_field_type_size(type);\n\t*align = btf_field_type_align(type);\n\treturn type;\n}\n\n#undef field_mask_test_name\n\nstatic int btf_find_struct_field(const struct btf *btf,\n\t\t\t\t const struct btf_type *t, u32 field_mask,\n\t\t\t\t struct btf_field_info *info, int info_cnt)\n{\n\tint ret, idx = 0, align, sz, field_type;\n\tconst struct btf_member *member;\n\tstruct btf_field_info tmp;\n\tu32 i, off, seen_mask = 0;\n\n\tfor_each_member(i, t, member) {\n\t\tconst struct btf_type *member_type = btf_type_by_id(btf,\n\t\t\t\t\t\t\t\t    member->type);\n\n\t\tfield_type = btf_get_field_type(__btf_name_by_offset(btf, member_type->name_off),\n\t\t\t\t\t\tfield_mask, &seen_mask, &align, &sz);\n\t\tif (field_type == 0)\n\t\t\tcontinue;\n\t\tif (field_type < 0)\n\t\t\treturn field_type;\n\n\t\toff = __btf_member_bit_offset(t, member);\n\t\tif (off % 8)\n\t\t\t \n\t\t\treturn -EINVAL;\n\t\toff /= 8;\n\t\tif (off % align)\n\t\t\tcontinue;\n\n\t\tswitch (field_type) {\n\t\tcase BPF_SPIN_LOCK:\n\t\tcase BPF_TIMER:\n\t\tcase BPF_LIST_NODE:\n\t\tcase BPF_RB_NODE:\n\t\tcase BPF_REFCOUNT:\n\t\t\tret = btf_find_struct(btf, member_type, off, sz, field_type,\n\t\t\t\t\t      idx < info_cnt ? &info[idx] : &tmp);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase BPF_KPTR_UNREF:\n\t\tcase BPF_KPTR_REF:\n\t\t\tret = btf_find_kptr(btf, member_type, off, sz,\n\t\t\t\t\t    idx < info_cnt ? &info[idx] : &tmp);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase BPF_LIST_HEAD:\n\t\tcase BPF_RB_ROOT:\n\t\t\tret = btf_find_graph_root(btf, t, member_type,\n\t\t\t\t\t\t  i, off, sz,\n\t\t\t\t\t\t  idx < info_cnt ? &info[idx] : &tmp,\n\t\t\t\t\t\t  field_type);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tif (ret == BTF_FIELD_IGNORE)\n\t\t\tcontinue;\n\t\tif (idx >= info_cnt)\n\t\t\treturn -E2BIG;\n\t\t++idx;\n\t}\n\treturn idx;\n}\n\nstatic int btf_find_datasec_var(const struct btf *btf, const struct btf_type *t,\n\t\t\t\tu32 field_mask, struct btf_field_info *info,\n\t\t\t\tint info_cnt)\n{\n\tint ret, idx = 0, align, sz, field_type;\n\tconst struct btf_var_secinfo *vsi;\n\tstruct btf_field_info tmp;\n\tu32 i, off, seen_mask = 0;\n\n\tfor_each_vsi(i, t, vsi) {\n\t\tconst struct btf_type *var = btf_type_by_id(btf, vsi->type);\n\t\tconst struct btf_type *var_type = btf_type_by_id(btf, var->type);\n\n\t\tfield_type = btf_get_field_type(__btf_name_by_offset(btf, var_type->name_off),\n\t\t\t\t\t\tfield_mask, &seen_mask, &align, &sz);\n\t\tif (field_type == 0)\n\t\t\tcontinue;\n\t\tif (field_type < 0)\n\t\t\treturn field_type;\n\n\t\toff = vsi->offset;\n\t\tif (vsi->size != sz)\n\t\t\tcontinue;\n\t\tif (off % align)\n\t\t\tcontinue;\n\n\t\tswitch (field_type) {\n\t\tcase BPF_SPIN_LOCK:\n\t\tcase BPF_TIMER:\n\t\tcase BPF_LIST_NODE:\n\t\tcase BPF_RB_NODE:\n\t\tcase BPF_REFCOUNT:\n\t\t\tret = btf_find_struct(btf, var_type, off, sz, field_type,\n\t\t\t\t\t      idx < info_cnt ? &info[idx] : &tmp);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase BPF_KPTR_UNREF:\n\t\tcase BPF_KPTR_REF:\n\t\t\tret = btf_find_kptr(btf, var_type, off, sz,\n\t\t\t\t\t    idx < info_cnt ? &info[idx] : &tmp);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase BPF_LIST_HEAD:\n\t\tcase BPF_RB_ROOT:\n\t\t\tret = btf_find_graph_root(btf, var, var_type,\n\t\t\t\t\t\t  -1, off, sz,\n\t\t\t\t\t\t  idx < info_cnt ? &info[idx] : &tmp,\n\t\t\t\t\t\t  field_type);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tif (ret == BTF_FIELD_IGNORE)\n\t\t\tcontinue;\n\t\tif (idx >= info_cnt)\n\t\t\treturn -E2BIG;\n\t\t++idx;\n\t}\n\treturn idx;\n}\n\nstatic int btf_find_field(const struct btf *btf, const struct btf_type *t,\n\t\t\t  u32 field_mask, struct btf_field_info *info,\n\t\t\t  int info_cnt)\n{\n\tif (__btf_type_is_struct(t))\n\t\treturn btf_find_struct_field(btf, t, field_mask, info, info_cnt);\n\telse if (btf_type_is_datasec(t))\n\t\treturn btf_find_datasec_var(btf, t, field_mask, info, info_cnt);\n\treturn -EINVAL;\n}\n\nstatic int btf_parse_kptr(const struct btf *btf, struct btf_field *field,\n\t\t\t  struct btf_field_info *info)\n{\n\tstruct module *mod = NULL;\n\tconst struct btf_type *t;\n\t \n\tstruct btf *kptr_btf;\n\tint ret;\n\ts32 id;\n\n\t \n\tt = btf_type_by_id(btf, info->kptr.type_id);\n\tid = bpf_find_btf_id(__btf_name_by_offset(btf, t->name_off), BTF_INFO_KIND(t->info),\n\t\t\t     &kptr_btf);\n\tif (id == -ENOENT) {\n\t\t \n\t\tWARN_ON_ONCE(btf_is_kernel(btf));\n\n\t\t \n\t\tfield->kptr.dtor = NULL;\n\t\tid = info->kptr.type_id;\n\t\tkptr_btf = (struct btf *)btf;\n\t\tbtf_get(kptr_btf);\n\t\tgoto found_dtor;\n\t}\n\tif (id < 0)\n\t\treturn id;\n\n\t \n\tif (info->type == BPF_KPTR_REF) {\n\t\tconst struct btf_type *dtor_func;\n\t\tconst char *dtor_func_name;\n\t\tunsigned long addr;\n\t\ts32 dtor_btf_id;\n\n\t\t \n\t\tdtor_btf_id = btf_find_dtor_kfunc(kptr_btf, id);\n\t\tif (dtor_btf_id < 0) {\n\t\t\tret = dtor_btf_id;\n\t\t\tgoto end_btf;\n\t\t}\n\n\t\tdtor_func = btf_type_by_id(kptr_btf, dtor_btf_id);\n\t\tif (!dtor_func) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto end_btf;\n\t\t}\n\n\t\tif (btf_is_module(kptr_btf)) {\n\t\t\tmod = btf_try_get_module(kptr_btf);\n\t\t\tif (!mod) {\n\t\t\t\tret = -ENXIO;\n\t\t\t\tgoto end_btf;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tdtor_func_name = __btf_name_by_offset(kptr_btf, dtor_func->name_off);\n\t\taddr = kallsyms_lookup_name(dtor_func_name);\n\t\tif (!addr) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto end_mod;\n\t\t}\n\t\tfield->kptr.dtor = (void *)addr;\n\t}\n\nfound_dtor:\n\tfield->kptr.btf_id = id;\n\tfield->kptr.btf = kptr_btf;\n\tfield->kptr.module = mod;\n\treturn 0;\nend_mod:\n\tmodule_put(mod);\nend_btf:\n\tbtf_put(kptr_btf);\n\treturn ret;\n}\n\nstatic int btf_parse_graph_root(const struct btf *btf,\n\t\t\t\tstruct btf_field *field,\n\t\t\t\tstruct btf_field_info *info,\n\t\t\t\tconst char *node_type_name,\n\t\t\t\tsize_t node_type_align)\n{\n\tconst struct btf_type *t, *n = NULL;\n\tconst struct btf_member *member;\n\tu32 offset;\n\tint i;\n\n\tt = btf_type_by_id(btf, info->graph_root.value_btf_id);\n\t \n\tfor_each_member(i, t, member) {\n\t\tif (strcmp(info->graph_root.node_name,\n\t\t\t   __btf_name_by_offset(btf, member->name_off)))\n\t\t\tcontinue;\n\t\t \n\t\tif (n)\n\t\t\treturn -EINVAL;\n\t\tn = btf_type_by_id(btf, member->type);\n\t\tif (!__btf_type_is_struct(n))\n\t\t\treturn -EINVAL;\n\t\tif (strcmp(node_type_name, __btf_name_by_offset(btf, n->name_off)))\n\t\t\treturn -EINVAL;\n\t\toffset = __btf_member_bit_offset(n, member);\n\t\tif (offset % 8)\n\t\t\treturn -EINVAL;\n\t\toffset /= 8;\n\t\tif (offset % node_type_align)\n\t\t\treturn -EINVAL;\n\n\t\tfield->graph_root.btf = (struct btf *)btf;\n\t\tfield->graph_root.value_btf_id = info->graph_root.value_btf_id;\n\t\tfield->graph_root.node_offset = offset;\n\t}\n\tif (!n)\n\t\treturn -ENOENT;\n\treturn 0;\n}\n\nstatic int btf_parse_list_head(const struct btf *btf, struct btf_field *field,\n\t\t\t       struct btf_field_info *info)\n{\n\treturn btf_parse_graph_root(btf, field, info, \"bpf_list_node\",\n\t\t\t\t\t    __alignof__(struct bpf_list_node));\n}\n\nstatic int btf_parse_rb_root(const struct btf *btf, struct btf_field *field,\n\t\t\t     struct btf_field_info *info)\n{\n\treturn btf_parse_graph_root(btf, field, info, \"bpf_rb_node\",\n\t\t\t\t\t    __alignof__(struct bpf_rb_node));\n}\n\nstatic int btf_field_cmp(const void *_a, const void *_b, const void *priv)\n{\n\tconst struct btf_field *a = (const struct btf_field *)_a;\n\tconst struct btf_field *b = (const struct btf_field *)_b;\n\n\tif (a->offset < b->offset)\n\t\treturn -1;\n\telse if (a->offset > b->offset)\n\t\treturn 1;\n\treturn 0;\n}\n\nstruct btf_record *btf_parse_fields(const struct btf *btf, const struct btf_type *t,\n\t\t\t\t    u32 field_mask, u32 value_size)\n{\n\tstruct btf_field_info info_arr[BTF_FIELDS_MAX];\n\tu32 next_off = 0, field_type_size;\n\tstruct btf_record *rec;\n\tint ret, i, cnt;\n\n\tret = btf_find_field(btf, t, field_mask, info_arr, ARRAY_SIZE(info_arr));\n\tif (ret < 0)\n\t\treturn ERR_PTR(ret);\n\tif (!ret)\n\t\treturn NULL;\n\n\tcnt = ret;\n\t \n\trec = kzalloc(offsetof(struct btf_record, fields[cnt]), GFP_KERNEL | __GFP_NOWARN);\n\tif (!rec)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\trec->spin_lock_off = -EINVAL;\n\trec->timer_off = -EINVAL;\n\trec->refcount_off = -EINVAL;\n\tfor (i = 0; i < cnt; i++) {\n\t\tfield_type_size = btf_field_type_size(info_arr[i].type);\n\t\tif (info_arr[i].off + field_type_size > value_size) {\n\t\t\tWARN_ONCE(1, \"verifier bug off %d size %d\", info_arr[i].off, value_size);\n\t\t\tret = -EFAULT;\n\t\t\tgoto end;\n\t\t}\n\t\tif (info_arr[i].off < next_off) {\n\t\t\tret = -EEXIST;\n\t\t\tgoto end;\n\t\t}\n\t\tnext_off = info_arr[i].off + field_type_size;\n\n\t\trec->field_mask |= info_arr[i].type;\n\t\trec->fields[i].offset = info_arr[i].off;\n\t\trec->fields[i].type = info_arr[i].type;\n\t\trec->fields[i].size = field_type_size;\n\n\t\tswitch (info_arr[i].type) {\n\t\tcase BPF_SPIN_LOCK:\n\t\t\tWARN_ON_ONCE(rec->spin_lock_off >= 0);\n\t\t\t \n\t\t\trec->spin_lock_off = rec->fields[i].offset;\n\t\t\tbreak;\n\t\tcase BPF_TIMER:\n\t\t\tWARN_ON_ONCE(rec->timer_off >= 0);\n\t\t\t \n\t\t\trec->timer_off = rec->fields[i].offset;\n\t\t\tbreak;\n\t\tcase BPF_REFCOUNT:\n\t\t\tWARN_ON_ONCE(rec->refcount_off >= 0);\n\t\t\t \n\t\t\trec->refcount_off = rec->fields[i].offset;\n\t\t\tbreak;\n\t\tcase BPF_KPTR_UNREF:\n\t\tcase BPF_KPTR_REF:\n\t\t\tret = btf_parse_kptr(btf, &rec->fields[i], &info_arr[i]);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto end;\n\t\t\tbreak;\n\t\tcase BPF_LIST_HEAD:\n\t\t\tret = btf_parse_list_head(btf, &rec->fields[i], &info_arr[i]);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto end;\n\t\t\tbreak;\n\t\tcase BPF_RB_ROOT:\n\t\t\tret = btf_parse_rb_root(btf, &rec->fields[i], &info_arr[i]);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto end;\n\t\t\tbreak;\n\t\tcase BPF_LIST_NODE:\n\t\tcase BPF_RB_NODE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EFAULT;\n\t\t\tgoto end;\n\t\t}\n\t\trec->cnt++;\n\t}\n\n\t \n\tif ((btf_record_has_field(rec, BPF_LIST_HEAD) ||\n\t     btf_record_has_field(rec, BPF_RB_ROOT)) && rec->spin_lock_off < 0) {\n\t\tret = -EINVAL;\n\t\tgoto end;\n\t}\n\n\tif (rec->refcount_off < 0 &&\n\t    btf_record_has_field(rec, BPF_LIST_NODE) &&\n\t    btf_record_has_field(rec, BPF_RB_NODE)) {\n\t\tret = -EINVAL;\n\t\tgoto end;\n\t}\n\n\tsort_r(rec->fields, rec->cnt, sizeof(struct btf_field), btf_field_cmp,\n\t       NULL, rec);\n\n\treturn rec;\nend:\n\tbtf_record_free(rec);\n\treturn ERR_PTR(ret);\n}\n\n#define GRAPH_ROOT_MASK (BPF_LIST_HEAD | BPF_RB_ROOT)\n#define GRAPH_NODE_MASK (BPF_LIST_NODE | BPF_RB_NODE)\n\nint btf_check_and_fixup_fields(const struct btf *btf, struct btf_record *rec)\n{\n\tint i;\n\n\t \n\tif (IS_ERR_OR_NULL(rec) || !(rec->field_mask & GRAPH_ROOT_MASK))\n\t\treturn 0;\n\tfor (i = 0; i < rec->cnt; i++) {\n\t\tstruct btf_struct_meta *meta;\n\t\tu32 btf_id;\n\n\t\tif (!(rec->fields[i].type & GRAPH_ROOT_MASK))\n\t\t\tcontinue;\n\t\tbtf_id = rec->fields[i].graph_root.value_btf_id;\n\t\tmeta = btf_find_struct_meta(btf, btf_id);\n\t\tif (!meta)\n\t\t\treturn -EFAULT;\n\t\trec->fields[i].graph_root.value_rec = meta->record;\n\n\t\t \n\t\tif (!(rec->field_mask & GRAPH_NODE_MASK))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (meta->record->field_mask & GRAPH_ROOT_MASK)\n\t\t\treturn -ELOOP;\n\t}\n\treturn 0;\n}\n\nstatic void __btf_struct_show(const struct btf *btf, const struct btf_type *t,\n\t\t\t      u32 type_id, void *data, u8 bits_offset,\n\t\t\t      struct btf_show *show)\n{\n\tconst struct btf_member *member;\n\tvoid *safe_data;\n\tu32 i;\n\n\tsafe_data = btf_show_start_struct_type(show, t, type_id, data);\n\tif (!safe_data)\n\t\treturn;\n\n\tfor_each_member(i, t, member) {\n\t\tconst struct btf_type *member_type = btf_type_by_id(btf,\n\t\t\t\t\t\t\t\tmember->type);\n\t\tconst struct btf_kind_operations *ops;\n\t\tu32 member_offset, bitfield_size;\n\t\tu32 bytes_offset;\n\t\tu8 bits8_offset;\n\n\t\tbtf_show_start_member(show, member);\n\n\t\tmember_offset = __btf_member_bit_offset(t, member);\n\t\tbitfield_size = __btf_member_bitfield_size(t, member);\n\t\tbytes_offset = BITS_ROUNDDOWN_BYTES(member_offset);\n\t\tbits8_offset = BITS_PER_BYTE_MASKED(member_offset);\n\t\tif (bitfield_size) {\n\t\t\tsafe_data = btf_show_start_type(show, member_type,\n\t\t\t\t\t\t\tmember->type,\n\t\t\t\t\t\t\tdata + bytes_offset);\n\t\t\tif (safe_data)\n\t\t\t\tbtf_bitfield_show(safe_data,\n\t\t\t\t\t\t  bits8_offset,\n\t\t\t\t\t\t  bitfield_size, show);\n\t\t\tbtf_show_end_type(show);\n\t\t} else {\n\t\t\tops = btf_type_ops(member_type);\n\t\t\tops->show(btf, member_type, member->type,\n\t\t\t\t  data + bytes_offset, bits8_offset, show);\n\t\t}\n\n\t\tbtf_show_end_member(show);\n\t}\n\n\tbtf_show_end_struct_type(show);\n}\n\nstatic void btf_struct_show(const struct btf *btf, const struct btf_type *t,\n\t\t\t    u32 type_id, void *data, u8 bits_offset,\n\t\t\t    struct btf_show *show)\n{\n\tconst struct btf_member *m = show->state.member;\n\n\t \n\tif (show->state.depth > 0 && !(show->flags & BTF_SHOW_ZERO)) {\n\t\tif (!show->state.depth_check) {\n\t\t\tshow->state.depth_check = show->state.depth + 1;\n\t\t\tshow->state.depth_to_show = 0;\n\t\t}\n\t\t__btf_struct_show(btf, t, type_id, data, bits_offset, show);\n\t\t \n\t\tshow->state.member = m;\n\t\tif (show->state.depth_check != show->state.depth + 1)\n\t\t\treturn;\n\t\tshow->state.depth_check = 0;\n\n\t\tif (show->state.depth_to_show <= show->state.depth)\n\t\t\treturn;\n\t\t \n\t}\n\n\t__btf_struct_show(btf, t, type_id, data, bits_offset, show);\n}\n\nstatic struct btf_kind_operations struct_ops = {\n\t.check_meta = btf_struct_check_meta,\n\t.resolve = btf_struct_resolve,\n\t.check_member = btf_struct_check_member,\n\t.check_kflag_member = btf_generic_check_kflag_member,\n\t.log_details = btf_struct_log,\n\t.show = btf_struct_show,\n};\n\nstatic int btf_enum_check_member(struct btf_verifier_env *env,\n\t\t\t\t const struct btf_type *struct_type,\n\t\t\t\t const struct btf_member *member,\n\t\t\t\t const struct btf_type *member_type)\n{\n\tu32 struct_bits_off = member->offset;\n\tu32 struct_size, bytes_offset;\n\n\tif (BITS_PER_BYTE_MASKED(struct_bits_off)) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member is not byte aligned\");\n\t\treturn -EINVAL;\n\t}\n\n\tstruct_size = struct_type->size;\n\tbytes_offset = BITS_ROUNDDOWN_BYTES(struct_bits_off);\n\tif (struct_size - bytes_offset < member_type->size) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member exceeds struct_size\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int btf_enum_check_kflag_member(struct btf_verifier_env *env,\n\t\t\t\t       const struct btf_type *struct_type,\n\t\t\t\t       const struct btf_member *member,\n\t\t\t\t       const struct btf_type *member_type)\n{\n\tu32 struct_bits_off, nr_bits, bytes_end, struct_size;\n\tu32 int_bitsize = sizeof(int) * BITS_PER_BYTE;\n\n\tstruct_bits_off = BTF_MEMBER_BIT_OFFSET(member->offset);\n\tnr_bits = BTF_MEMBER_BITFIELD_SIZE(member->offset);\n\tif (!nr_bits) {\n\t\tif (BITS_PER_BYTE_MASKED(struct_bits_off)) {\n\t\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\t\"Member is not byte aligned\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tnr_bits = int_bitsize;\n\t} else if (nr_bits > int_bitsize) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Invalid member bitfield_size\");\n\t\treturn -EINVAL;\n\t}\n\n\tstruct_size = struct_type->size;\n\tbytes_end = BITS_ROUNDUP_BYTES(struct_bits_off + nr_bits);\n\tif (struct_size < bytes_end) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member exceeds struct_size\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic s32 btf_enum_check_meta(struct btf_verifier_env *env,\n\t\t\t       const struct btf_type *t,\n\t\t\t       u32 meta_left)\n{\n\tconst struct btf_enum *enums = btf_type_enum(t);\n\tstruct btf *btf = env->btf;\n\tconst char *fmt_str;\n\tu16 i, nr_enums;\n\tu32 meta_needed;\n\n\tnr_enums = btf_type_vlen(t);\n\tmeta_needed = nr_enums * sizeof(*enums);\n\n\tif (meta_left < meta_needed) {\n\t\tbtf_verifier_log_basic(env, t,\n\t\t\t\t       \"meta_left:%u meta_needed:%u\",\n\t\t\t\t       meta_left, meta_needed);\n\t\treturn -EINVAL;\n\t}\n\n\tif (t->size > 8 || !is_power_of_2(t->size)) {\n\t\tbtf_verifier_log_type(env, t, \"Unexpected size\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (t->name_off &&\n\t    !btf_name_valid_identifier(env->btf, t->name_off)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\tfor (i = 0; i < nr_enums; i++) {\n\t\tif (!btf_name_offset_valid(btf, enums[i].name_off)) {\n\t\t\tbtf_verifier_log(env, \"\\tInvalid name_offset:%u\",\n\t\t\t\t\t enums[i].name_off);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (!enums[i].name_off ||\n\t\t    !btf_name_valid_identifier(btf, enums[i].name_off)) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (env->log.level == BPF_LOG_KERNEL)\n\t\t\tcontinue;\n\t\tfmt_str = btf_type_kflag(t) ? \"\\t%s val=%d\\n\" : \"\\t%s val=%u\\n\";\n\t\tbtf_verifier_log(env, fmt_str,\n\t\t\t\t __btf_name_by_offset(btf, enums[i].name_off),\n\t\t\t\t enums[i].val);\n\t}\n\n\treturn meta_needed;\n}\n\nstatic void btf_enum_log(struct btf_verifier_env *env,\n\t\t\t const struct btf_type *t)\n{\n\tbtf_verifier_log(env, \"size=%u vlen=%u\", t->size, btf_type_vlen(t));\n}\n\nstatic void btf_enum_show(const struct btf *btf, const struct btf_type *t,\n\t\t\t  u32 type_id, void *data, u8 bits_offset,\n\t\t\t  struct btf_show *show)\n{\n\tconst struct btf_enum *enums = btf_type_enum(t);\n\tu32 i, nr_enums = btf_type_vlen(t);\n\tvoid *safe_data;\n\tint v;\n\n\tsafe_data = btf_show_start_type(show, t, type_id, data);\n\tif (!safe_data)\n\t\treturn;\n\n\tv = *(int *)safe_data;\n\n\tfor (i = 0; i < nr_enums; i++) {\n\t\tif (v != enums[i].val)\n\t\t\tcontinue;\n\n\t\tbtf_show_type_value(show, \"%s\",\n\t\t\t\t    __btf_name_by_offset(btf,\n\t\t\t\t\t\t\t enums[i].name_off));\n\n\t\tbtf_show_end_type(show);\n\t\treturn;\n\t}\n\n\tif (btf_type_kflag(t))\n\t\tbtf_show_type_value(show, \"%d\", v);\n\telse\n\t\tbtf_show_type_value(show, \"%u\", v);\n\tbtf_show_end_type(show);\n}\n\nstatic struct btf_kind_operations enum_ops = {\n\t.check_meta = btf_enum_check_meta,\n\t.resolve = btf_df_resolve,\n\t.check_member = btf_enum_check_member,\n\t.check_kflag_member = btf_enum_check_kflag_member,\n\t.log_details = btf_enum_log,\n\t.show = btf_enum_show,\n};\n\nstatic s32 btf_enum64_check_meta(struct btf_verifier_env *env,\n\t\t\t\t const struct btf_type *t,\n\t\t\t\t u32 meta_left)\n{\n\tconst struct btf_enum64 *enums = btf_type_enum64(t);\n\tstruct btf *btf = env->btf;\n\tconst char *fmt_str;\n\tu16 i, nr_enums;\n\tu32 meta_needed;\n\n\tnr_enums = btf_type_vlen(t);\n\tmeta_needed = nr_enums * sizeof(*enums);\n\n\tif (meta_left < meta_needed) {\n\t\tbtf_verifier_log_basic(env, t,\n\t\t\t\t       \"meta_left:%u meta_needed:%u\",\n\t\t\t\t       meta_left, meta_needed);\n\t\treturn -EINVAL;\n\t}\n\n\tif (t->size > 8 || !is_power_of_2(t->size)) {\n\t\tbtf_verifier_log_type(env, t, \"Unexpected size\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (t->name_off &&\n\t    !btf_name_valid_identifier(env->btf, t->name_off)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\tfor (i = 0; i < nr_enums; i++) {\n\t\tif (!btf_name_offset_valid(btf, enums[i].name_off)) {\n\t\t\tbtf_verifier_log(env, \"\\tInvalid name_offset:%u\",\n\t\t\t\t\t enums[i].name_off);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (!enums[i].name_off ||\n\t\t    !btf_name_valid_identifier(btf, enums[i].name_off)) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (env->log.level == BPF_LOG_KERNEL)\n\t\t\tcontinue;\n\n\t\tfmt_str = btf_type_kflag(t) ? \"\\t%s val=%lld\\n\" : \"\\t%s val=%llu\\n\";\n\t\tbtf_verifier_log(env, fmt_str,\n\t\t\t\t __btf_name_by_offset(btf, enums[i].name_off),\n\t\t\t\t btf_enum64_value(enums + i));\n\t}\n\n\treturn meta_needed;\n}\n\nstatic void btf_enum64_show(const struct btf *btf, const struct btf_type *t,\n\t\t\t    u32 type_id, void *data, u8 bits_offset,\n\t\t\t    struct btf_show *show)\n{\n\tconst struct btf_enum64 *enums = btf_type_enum64(t);\n\tu32 i, nr_enums = btf_type_vlen(t);\n\tvoid *safe_data;\n\ts64 v;\n\n\tsafe_data = btf_show_start_type(show, t, type_id, data);\n\tif (!safe_data)\n\t\treturn;\n\n\tv = *(u64 *)safe_data;\n\n\tfor (i = 0; i < nr_enums; i++) {\n\t\tif (v != btf_enum64_value(enums + i))\n\t\t\tcontinue;\n\n\t\tbtf_show_type_value(show, \"%s\",\n\t\t\t\t    __btf_name_by_offset(btf,\n\t\t\t\t\t\t\t enums[i].name_off));\n\n\t\tbtf_show_end_type(show);\n\t\treturn;\n\t}\n\n\tif (btf_type_kflag(t))\n\t\tbtf_show_type_value(show, \"%lld\", v);\n\telse\n\t\tbtf_show_type_value(show, \"%llu\", v);\n\tbtf_show_end_type(show);\n}\n\nstatic struct btf_kind_operations enum64_ops = {\n\t.check_meta = btf_enum64_check_meta,\n\t.resolve = btf_df_resolve,\n\t.check_member = btf_enum_check_member,\n\t.check_kflag_member = btf_enum_check_kflag_member,\n\t.log_details = btf_enum_log,\n\t.show = btf_enum64_show,\n};\n\nstatic s32 btf_func_proto_check_meta(struct btf_verifier_env *env,\n\t\t\t\t     const struct btf_type *t,\n\t\t\t\t     u32 meta_left)\n{\n\tu32 meta_needed = btf_type_vlen(t) * sizeof(struct btf_param);\n\n\tif (meta_left < meta_needed) {\n\t\tbtf_verifier_log_basic(env, t,\n\t\t\t\t       \"meta_left:%u meta_needed:%u\",\n\t\t\t\t       meta_left, meta_needed);\n\t\treturn -EINVAL;\n\t}\n\n\tif (t->name_off) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_kflag(t)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info kind_flag\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\treturn meta_needed;\n}\n\nstatic void btf_func_proto_log(struct btf_verifier_env *env,\n\t\t\t       const struct btf_type *t)\n{\n\tconst struct btf_param *args = (const struct btf_param *)(t + 1);\n\tu16 nr_args = btf_type_vlen(t), i;\n\n\tbtf_verifier_log(env, \"return=%u args=(\", t->type);\n\tif (!nr_args) {\n\t\tbtf_verifier_log(env, \"void\");\n\t\tgoto done;\n\t}\n\n\tif (nr_args == 1 && !args[0].type) {\n\t\t \n\t\tbtf_verifier_log(env, \"vararg\");\n\t\tgoto done;\n\t}\n\n\tbtf_verifier_log(env, \"%u %s\", args[0].type,\n\t\t\t __btf_name_by_offset(env->btf,\n\t\t\t\t\t      args[0].name_off));\n\tfor (i = 1; i < nr_args - 1; i++)\n\t\tbtf_verifier_log(env, \", %u %s\", args[i].type,\n\t\t\t\t __btf_name_by_offset(env->btf,\n\t\t\t\t\t\t      args[i].name_off));\n\n\tif (nr_args > 1) {\n\t\tconst struct btf_param *last_arg = &args[nr_args - 1];\n\n\t\tif (last_arg->type)\n\t\t\tbtf_verifier_log(env, \", %u %s\", last_arg->type,\n\t\t\t\t\t __btf_name_by_offset(env->btf,\n\t\t\t\t\t\t\t      last_arg->name_off));\n\t\telse\n\t\t\tbtf_verifier_log(env, \", vararg\");\n\t}\n\ndone:\n\tbtf_verifier_log(env, \")\");\n}\n\nstatic struct btf_kind_operations func_proto_ops = {\n\t.check_meta = btf_func_proto_check_meta,\n\t.resolve = btf_df_resolve,\n\t \n\t.check_member = btf_df_check_member,\n\t.check_kflag_member = btf_df_check_kflag_member,\n\t.log_details = btf_func_proto_log,\n\t.show = btf_df_show,\n};\n\nstatic s32 btf_func_check_meta(struct btf_verifier_env *env,\n\t\t\t       const struct btf_type *t,\n\t\t\t       u32 meta_left)\n{\n\tif (!t->name_off ||\n\t    !btf_name_valid_identifier(env->btf, t->name_off)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_vlen(t) > BTF_FUNC_GLOBAL) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid func linkage\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_kflag(t)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info kind_flag\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\treturn 0;\n}\n\nstatic int btf_func_resolve(struct btf_verifier_env *env,\n\t\t\t    const struct resolve_vertex *v)\n{\n\tconst struct btf_type *t = v->t;\n\tu32 next_type_id = t->type;\n\tint err;\n\n\terr = btf_func_check(env, t);\n\tif (err)\n\t\treturn err;\n\n\tenv_stack_pop_resolved(env, next_type_id, 0);\n\treturn 0;\n}\n\nstatic struct btf_kind_operations func_ops = {\n\t.check_meta = btf_func_check_meta,\n\t.resolve = btf_func_resolve,\n\t.check_member = btf_df_check_member,\n\t.check_kflag_member = btf_df_check_kflag_member,\n\t.log_details = btf_ref_type_log,\n\t.show = btf_df_show,\n};\n\nstatic s32 btf_var_check_meta(struct btf_verifier_env *env,\n\t\t\t      const struct btf_type *t,\n\t\t\t      u32 meta_left)\n{\n\tconst struct btf_var *var;\n\tu32 meta_needed = sizeof(*var);\n\n\tif (meta_left < meta_needed) {\n\t\tbtf_verifier_log_basic(env, t,\n\t\t\t\t       \"meta_left:%u meta_needed:%u\",\n\t\t\t\t       meta_left, meta_needed);\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_vlen(t)) {\n\t\tbtf_verifier_log_type(env, t, \"vlen != 0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_kflag(t)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info kind_flag\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!t->name_off ||\n\t    !__btf_name_valid(env->btf, t->name_off)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (!t->type || !BTF_TYPE_ID_VALID(t->type)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid type_id\");\n\t\treturn -EINVAL;\n\t}\n\n\tvar = btf_type_var(t);\n\tif (var->linkage != BTF_VAR_STATIC &&\n\t    var->linkage != BTF_VAR_GLOBAL_ALLOCATED) {\n\t\tbtf_verifier_log_type(env, t, \"Linkage not supported\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\treturn meta_needed;\n}\n\nstatic void btf_var_log(struct btf_verifier_env *env, const struct btf_type *t)\n{\n\tconst struct btf_var *var = btf_type_var(t);\n\n\tbtf_verifier_log(env, \"type_id=%u linkage=%u\", t->type, var->linkage);\n}\n\nstatic const struct btf_kind_operations var_ops = {\n\t.check_meta\t\t= btf_var_check_meta,\n\t.resolve\t\t= btf_var_resolve,\n\t.check_member\t\t= btf_df_check_member,\n\t.check_kflag_member\t= btf_df_check_kflag_member,\n\t.log_details\t\t= btf_var_log,\n\t.show\t\t\t= btf_var_show,\n};\n\nstatic s32 btf_datasec_check_meta(struct btf_verifier_env *env,\n\t\t\t\t  const struct btf_type *t,\n\t\t\t\t  u32 meta_left)\n{\n\tconst struct btf_var_secinfo *vsi;\n\tu64 last_vsi_end_off = 0, sum = 0;\n\tu32 i, meta_needed;\n\n\tmeta_needed = btf_type_vlen(t) * sizeof(*vsi);\n\tif (meta_left < meta_needed) {\n\t\tbtf_verifier_log_basic(env, t,\n\t\t\t\t       \"meta_left:%u meta_needed:%u\",\n\t\t\t\t       meta_left, meta_needed);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!t->size) {\n\t\tbtf_verifier_log_type(env, t, \"size == 0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_kflag(t)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info kind_flag\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!t->name_off ||\n\t    !btf_name_valid_section(env->btf, t->name_off)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid name\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\tfor_each_vsi(i, t, vsi) {\n\t\t \n\t\tif (!vsi->type || !BTF_TYPE_ID_VALID(vsi->type)) {\n\t\t\tbtf_verifier_log_vsi(env, t, vsi,\n\t\t\t\t\t     \"Invalid type_id\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (vsi->offset < last_vsi_end_off || vsi->offset >= t->size) {\n\t\t\tbtf_verifier_log_vsi(env, t, vsi,\n\t\t\t\t\t     \"Invalid offset\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!vsi->size || vsi->size > t->size) {\n\t\t\tbtf_verifier_log_vsi(env, t, vsi,\n\t\t\t\t\t     \"Invalid size\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tlast_vsi_end_off = vsi->offset + vsi->size;\n\t\tif (last_vsi_end_off > t->size) {\n\t\t\tbtf_verifier_log_vsi(env, t, vsi,\n\t\t\t\t\t     \"Invalid offset+size\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tbtf_verifier_log_vsi(env, t, vsi, NULL);\n\t\tsum += vsi->size;\n\t}\n\n\tif (t->size < sum) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info size\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn meta_needed;\n}\n\nstatic int btf_datasec_resolve(struct btf_verifier_env *env,\n\t\t\t       const struct resolve_vertex *v)\n{\n\tconst struct btf_var_secinfo *vsi;\n\tstruct btf *btf = env->btf;\n\tu16 i;\n\n\tenv->resolve_mode = RESOLVE_TBD;\n\tfor_each_vsi_from(i, v->next_member, v->t, vsi) {\n\t\tu32 var_type_id = vsi->type, type_id, type_size = 0;\n\t\tconst struct btf_type *var_type = btf_type_by_id(env->btf,\n\t\t\t\t\t\t\t\t var_type_id);\n\t\tif (!var_type || !btf_type_is_var(var_type)) {\n\t\t\tbtf_verifier_log_vsi(env, v->t, vsi,\n\t\t\t\t\t     \"Not a VAR kind member\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!env_type_is_resolve_sink(env, var_type) &&\n\t\t    !env_type_is_resolved(env, var_type_id)) {\n\t\t\tenv_stack_set_next_member(env, i + 1);\n\t\t\treturn env_stack_push(env, var_type, var_type_id);\n\t\t}\n\n\t\ttype_id = var_type->type;\n\t\tif (!btf_type_id_size(btf, &type_id, &type_size)) {\n\t\t\tbtf_verifier_log_vsi(env, v->t, vsi, \"Invalid type\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (vsi->size < type_size) {\n\t\t\tbtf_verifier_log_vsi(env, v->t, vsi, \"Invalid size\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tenv_stack_pop_resolved(env, 0, 0);\n\treturn 0;\n}\n\nstatic void btf_datasec_log(struct btf_verifier_env *env,\n\t\t\t    const struct btf_type *t)\n{\n\tbtf_verifier_log(env, \"size=%u vlen=%u\", t->size, btf_type_vlen(t));\n}\n\nstatic void btf_datasec_show(const struct btf *btf,\n\t\t\t     const struct btf_type *t, u32 type_id,\n\t\t\t     void *data, u8 bits_offset,\n\t\t\t     struct btf_show *show)\n{\n\tconst struct btf_var_secinfo *vsi;\n\tconst struct btf_type *var;\n\tu32 i;\n\n\tif (!btf_show_start_type(show, t, type_id, data))\n\t\treturn;\n\n\tbtf_show_type_value(show, \"section (\\\"%s\\\") = {\",\n\t\t\t    __btf_name_by_offset(btf, t->name_off));\n\tfor_each_vsi(i, t, vsi) {\n\t\tvar = btf_type_by_id(btf, vsi->type);\n\t\tif (i)\n\t\t\tbtf_show(show, \",\");\n\t\tbtf_type_ops(var)->show(btf, var, vsi->type,\n\t\t\t\t\tdata + vsi->offset, bits_offset, show);\n\t}\n\tbtf_show_end_type(show);\n}\n\nstatic const struct btf_kind_operations datasec_ops = {\n\t.check_meta\t\t= btf_datasec_check_meta,\n\t.resolve\t\t= btf_datasec_resolve,\n\t.check_member\t\t= btf_df_check_member,\n\t.check_kflag_member\t= btf_df_check_kflag_member,\n\t.log_details\t\t= btf_datasec_log,\n\t.show\t\t\t= btf_datasec_show,\n};\n\nstatic s32 btf_float_check_meta(struct btf_verifier_env *env,\n\t\t\t\tconst struct btf_type *t,\n\t\t\t\tu32 meta_left)\n{\n\tif (btf_type_vlen(t)) {\n\t\tbtf_verifier_log_type(env, t, \"vlen != 0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_kflag(t)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info kind_flag\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (t->size != 2 && t->size != 4 && t->size != 8 && t->size != 12 &&\n\t    t->size != 16) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid type_size\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\treturn 0;\n}\n\nstatic int btf_float_check_member(struct btf_verifier_env *env,\n\t\t\t\t  const struct btf_type *struct_type,\n\t\t\t\t  const struct btf_member *member,\n\t\t\t\t  const struct btf_type *member_type)\n{\n\tu64 start_offset_bytes;\n\tu64 end_offset_bytes;\n\tu64 misalign_bits;\n\tu64 align_bytes;\n\tu64 align_bits;\n\n\t \n\talign_bytes = min_t(u64, sizeof(void *), member_type->size);\n\talign_bits = align_bytes * BITS_PER_BYTE;\n\tdiv64_u64_rem(member->offset, align_bits, &misalign_bits);\n\tif (misalign_bits) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member is not properly aligned\");\n\t\treturn -EINVAL;\n\t}\n\n\tstart_offset_bytes = member->offset / BITS_PER_BYTE;\n\tend_offset_bytes = start_offset_bytes + member_type->size;\n\tif (end_offset_bytes > struct_type->size) {\n\t\tbtf_verifier_log_member(env, struct_type, member,\n\t\t\t\t\t\"Member exceeds struct_size\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void btf_float_log(struct btf_verifier_env *env,\n\t\t\t  const struct btf_type *t)\n{\n\tbtf_verifier_log(env, \"size=%u\", t->size);\n}\n\nstatic const struct btf_kind_operations float_ops = {\n\t.check_meta = btf_float_check_meta,\n\t.resolve = btf_df_resolve,\n\t.check_member = btf_float_check_member,\n\t.check_kflag_member = btf_generic_check_kflag_member,\n\t.log_details = btf_float_log,\n\t.show = btf_df_show,\n};\n\nstatic s32 btf_decl_tag_check_meta(struct btf_verifier_env *env,\n\t\t\t      const struct btf_type *t,\n\t\t\t      u32 meta_left)\n{\n\tconst struct btf_decl_tag *tag;\n\tu32 meta_needed = sizeof(*tag);\n\ts32 component_idx;\n\tconst char *value;\n\n\tif (meta_left < meta_needed) {\n\t\tbtf_verifier_log_basic(env, t,\n\t\t\t\t       \"meta_left:%u meta_needed:%u\",\n\t\t\t\t       meta_left, meta_needed);\n\t\treturn -EINVAL;\n\t}\n\n\tvalue = btf_name_by_offset(env->btf, t->name_off);\n\tif (!value || !value[0]) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid value\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_vlen(t)) {\n\t\tbtf_verifier_log_type(env, t, \"vlen != 0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (btf_type_kflag(t)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid btf_info kind_flag\");\n\t\treturn -EINVAL;\n\t}\n\n\tcomponent_idx = btf_type_decl_tag(t)->component_idx;\n\tif (component_idx < -1) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid component_idx\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_verifier_log_type(env, t, NULL);\n\n\treturn meta_needed;\n}\n\nstatic int btf_decl_tag_resolve(struct btf_verifier_env *env,\n\t\t\t   const struct resolve_vertex *v)\n{\n\tconst struct btf_type *next_type;\n\tconst struct btf_type *t = v->t;\n\tu32 next_type_id = t->type;\n\tstruct btf *btf = env->btf;\n\ts32 component_idx;\n\tu32 vlen;\n\n\tnext_type = btf_type_by_id(btf, next_type_id);\n\tif (!next_type || !btf_type_is_decl_tag_target(next_type)) {\n\t\tbtf_verifier_log_type(env, v->t, \"Invalid type_id\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env_type_is_resolve_sink(env, next_type) &&\n\t    !env_type_is_resolved(env, next_type_id))\n\t\treturn env_stack_push(env, next_type, next_type_id);\n\n\tcomponent_idx = btf_type_decl_tag(t)->component_idx;\n\tif (component_idx != -1) {\n\t\tif (btf_type_is_var(next_type) || btf_type_is_typedef(next_type)) {\n\t\t\tbtf_verifier_log_type(env, v->t, \"Invalid component_idx\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (btf_type_is_struct(next_type)) {\n\t\t\tvlen = btf_type_vlen(next_type);\n\t\t} else {\n\t\t\t \n\t\t\tnext_type = btf_type_by_id(btf, next_type->type);\n\t\t\tvlen = btf_type_vlen(next_type);\n\t\t}\n\n\t\tif ((u32)component_idx >= vlen) {\n\t\t\tbtf_verifier_log_type(env, v->t, \"Invalid component_idx\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tenv_stack_pop_resolved(env, next_type_id, 0);\n\n\treturn 0;\n}\n\nstatic void btf_decl_tag_log(struct btf_verifier_env *env, const struct btf_type *t)\n{\n\tbtf_verifier_log(env, \"type=%u component_idx=%d\", t->type,\n\t\t\t btf_type_decl_tag(t)->component_idx);\n}\n\nstatic const struct btf_kind_operations decl_tag_ops = {\n\t.check_meta = btf_decl_tag_check_meta,\n\t.resolve = btf_decl_tag_resolve,\n\t.check_member = btf_df_check_member,\n\t.check_kflag_member = btf_df_check_kflag_member,\n\t.log_details = btf_decl_tag_log,\n\t.show = btf_df_show,\n};\n\nstatic int btf_func_proto_check(struct btf_verifier_env *env,\n\t\t\t\tconst struct btf_type *t)\n{\n\tconst struct btf_type *ret_type;\n\tconst struct btf_param *args;\n\tconst struct btf *btf;\n\tu16 nr_args, i;\n\tint err;\n\n\tbtf = env->btf;\n\targs = (const struct btf_param *)(t + 1);\n\tnr_args = btf_type_vlen(t);\n\n\t \n\tif (t->type) {\n\t\tu32 ret_type_id = t->type;\n\n\t\tret_type = btf_type_by_id(btf, ret_type_id);\n\t\tif (!ret_type) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid return type\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (btf_type_is_resolve_source_only(ret_type)) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid return type\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (btf_type_needs_resolve(ret_type) &&\n\t\t    !env_type_is_resolved(env, ret_type_id)) {\n\t\t\terr = btf_resolve(env, ret_type, ret_type_id);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\t \n\t\tif (!btf_type_id_size(btf, &ret_type_id, NULL)) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid return type\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!nr_args)\n\t\treturn 0;\n\n\t \n\tif (!args[nr_args - 1].type) {\n\t\tif (args[nr_args - 1].name_off) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid arg#%u\",\n\t\t\t\t\t      nr_args);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tnr_args--;\n\t}\n\n\tfor (i = 0; i < nr_args; i++) {\n\t\tconst struct btf_type *arg_type;\n\t\tu32 arg_type_id;\n\n\t\targ_type_id = args[i].type;\n\t\targ_type = btf_type_by_id(btf, arg_type_id);\n\t\tif (!arg_type) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid arg#%u\", i + 1);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (btf_type_is_resolve_source_only(arg_type)) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid arg#%u\", i + 1);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (args[i].name_off &&\n\t\t    (!btf_name_offset_valid(btf, args[i].name_off) ||\n\t\t     !btf_name_valid_identifier(btf, args[i].name_off))) {\n\t\t\tbtf_verifier_log_type(env, t,\n\t\t\t\t\t      \"Invalid arg#%u\", i + 1);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (btf_type_needs_resolve(arg_type) &&\n\t\t    !env_type_is_resolved(env, arg_type_id)) {\n\t\t\terr = btf_resolve(env, arg_type, arg_type_id);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (!btf_type_id_size(btf, &arg_type_id, NULL)) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid arg#%u\", i + 1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int btf_func_check(struct btf_verifier_env *env,\n\t\t\t  const struct btf_type *t)\n{\n\tconst struct btf_type *proto_type;\n\tconst struct btf_param *args;\n\tconst struct btf *btf;\n\tu16 nr_args, i;\n\n\tbtf = env->btf;\n\tproto_type = btf_type_by_id(btf, t->type);\n\n\tif (!proto_type || !btf_type_is_func_proto(proto_type)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid type_id\");\n\t\treturn -EINVAL;\n\t}\n\n\targs = (const struct btf_param *)(proto_type + 1);\n\tnr_args = btf_type_vlen(proto_type);\n\tfor (i = 0; i < nr_args; i++) {\n\t\tif (!args[i].name_off && args[i].type) {\n\t\t\tbtf_verifier_log_type(env, t, \"Invalid arg#%u\", i + 1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic const struct btf_kind_operations * const kind_ops[NR_BTF_KINDS] = {\n\t[BTF_KIND_INT] = &int_ops,\n\t[BTF_KIND_PTR] = &ptr_ops,\n\t[BTF_KIND_ARRAY] = &array_ops,\n\t[BTF_KIND_STRUCT] = &struct_ops,\n\t[BTF_KIND_UNION] = &struct_ops,\n\t[BTF_KIND_ENUM] = &enum_ops,\n\t[BTF_KIND_FWD] = &fwd_ops,\n\t[BTF_KIND_TYPEDEF] = &modifier_ops,\n\t[BTF_KIND_VOLATILE] = &modifier_ops,\n\t[BTF_KIND_CONST] = &modifier_ops,\n\t[BTF_KIND_RESTRICT] = &modifier_ops,\n\t[BTF_KIND_FUNC] = &func_ops,\n\t[BTF_KIND_FUNC_PROTO] = &func_proto_ops,\n\t[BTF_KIND_VAR] = &var_ops,\n\t[BTF_KIND_DATASEC] = &datasec_ops,\n\t[BTF_KIND_FLOAT] = &float_ops,\n\t[BTF_KIND_DECL_TAG] = &decl_tag_ops,\n\t[BTF_KIND_TYPE_TAG] = &modifier_ops,\n\t[BTF_KIND_ENUM64] = &enum64_ops,\n};\n\nstatic s32 btf_check_meta(struct btf_verifier_env *env,\n\t\t\t  const struct btf_type *t,\n\t\t\t  u32 meta_left)\n{\n\tu32 saved_meta_left = meta_left;\n\ts32 var_meta_size;\n\n\tif (meta_left < sizeof(*t)) {\n\t\tbtf_verifier_log(env, \"[%u] meta_left:%u meta_needed:%zu\",\n\t\t\t\t env->log_type_id, meta_left, sizeof(*t));\n\t\treturn -EINVAL;\n\t}\n\tmeta_left -= sizeof(*t);\n\n\tif (t->info & ~BTF_INFO_MASK) {\n\t\tbtf_verifier_log(env, \"[%u] Invalid btf_info:%x\",\n\t\t\t\t env->log_type_id, t->info);\n\t\treturn -EINVAL;\n\t}\n\n\tif (BTF_INFO_KIND(t->info) > BTF_KIND_MAX ||\n\t    BTF_INFO_KIND(t->info) == BTF_KIND_UNKN) {\n\t\tbtf_verifier_log(env, \"[%u] Invalid kind:%u\",\n\t\t\t\t env->log_type_id, BTF_INFO_KIND(t->info));\n\t\treturn -EINVAL;\n\t}\n\n\tif (!btf_name_offset_valid(env->btf, t->name_off)) {\n\t\tbtf_verifier_log(env, \"[%u] Invalid name_offset:%u\",\n\t\t\t\t env->log_type_id, t->name_off);\n\t\treturn -EINVAL;\n\t}\n\n\tvar_meta_size = btf_type_ops(t)->check_meta(env, t, meta_left);\n\tif (var_meta_size < 0)\n\t\treturn var_meta_size;\n\n\tmeta_left -= var_meta_size;\n\n\treturn saved_meta_left - meta_left;\n}\n\nstatic int btf_check_all_metas(struct btf_verifier_env *env)\n{\n\tstruct btf *btf = env->btf;\n\tstruct btf_header *hdr;\n\tvoid *cur, *end;\n\n\thdr = &btf->hdr;\n\tcur = btf->nohdr_data + hdr->type_off;\n\tend = cur + hdr->type_len;\n\n\tenv->log_type_id = btf->base_btf ? btf->start_id : 1;\n\twhile (cur < end) {\n\t\tstruct btf_type *t = cur;\n\t\ts32 meta_size;\n\n\t\tmeta_size = btf_check_meta(env, t, end - cur);\n\t\tif (meta_size < 0)\n\t\t\treturn meta_size;\n\n\t\tbtf_add_type(env, t);\n\t\tcur += meta_size;\n\t\tenv->log_type_id++;\n\t}\n\n\treturn 0;\n}\n\nstatic bool btf_resolve_valid(struct btf_verifier_env *env,\n\t\t\t      const struct btf_type *t,\n\t\t\t      u32 type_id)\n{\n\tstruct btf *btf = env->btf;\n\n\tif (!env_type_is_resolved(env, type_id))\n\t\treturn false;\n\n\tif (btf_type_is_struct(t) || btf_type_is_datasec(t))\n\t\treturn !btf_resolved_type_id(btf, type_id) &&\n\t\t       !btf_resolved_type_size(btf, type_id);\n\n\tif (btf_type_is_decl_tag(t) || btf_type_is_func(t))\n\t\treturn btf_resolved_type_id(btf, type_id) &&\n\t\t       !btf_resolved_type_size(btf, type_id);\n\n\tif (btf_type_is_modifier(t) || btf_type_is_ptr(t) ||\n\t    btf_type_is_var(t)) {\n\t\tt = btf_type_id_resolve(btf, &type_id);\n\t\treturn t &&\n\t\t       !btf_type_is_modifier(t) &&\n\t\t       !btf_type_is_var(t) &&\n\t\t       !btf_type_is_datasec(t);\n\t}\n\n\tif (btf_type_is_array(t)) {\n\t\tconst struct btf_array *array = btf_type_array(t);\n\t\tconst struct btf_type *elem_type;\n\t\tu32 elem_type_id = array->type;\n\t\tu32 elem_size;\n\n\t\telem_type = btf_type_id_size(btf, &elem_type_id, &elem_size);\n\t\treturn elem_type && !btf_type_is_modifier(elem_type) &&\n\t\t\t(array->nelems * elem_size ==\n\t\t\t btf_resolved_type_size(btf, type_id));\n\t}\n\n\treturn false;\n}\n\nstatic int btf_resolve(struct btf_verifier_env *env,\n\t\t       const struct btf_type *t, u32 type_id)\n{\n\tu32 save_log_type_id = env->log_type_id;\n\tconst struct resolve_vertex *v;\n\tint err = 0;\n\n\tenv->resolve_mode = RESOLVE_TBD;\n\tenv_stack_push(env, t, type_id);\n\twhile (!err && (v = env_stack_peak(env))) {\n\t\tenv->log_type_id = v->type_id;\n\t\terr = btf_type_ops(v->t)->resolve(env, v);\n\t}\n\n\tenv->log_type_id = type_id;\n\tif (err == -E2BIG) {\n\t\tbtf_verifier_log_type(env, t,\n\t\t\t\t      \"Exceeded max resolving depth:%u\",\n\t\t\t\t      MAX_RESOLVE_DEPTH);\n\t} else if (err == -EEXIST) {\n\t\tbtf_verifier_log_type(env, t, \"Loop detected\");\n\t}\n\n\t \n\tif (!err && !btf_resolve_valid(env, t, type_id)) {\n\t\tbtf_verifier_log_type(env, t, \"Invalid resolve state\");\n\t\terr = -EINVAL;\n\t}\n\n\tenv->log_type_id = save_log_type_id;\n\treturn err;\n}\n\nstatic int btf_check_all_types(struct btf_verifier_env *env)\n{\n\tstruct btf *btf = env->btf;\n\tconst struct btf_type *t;\n\tu32 type_id, i;\n\tint err;\n\n\terr = env_resolve_init(env);\n\tif (err)\n\t\treturn err;\n\n\tenv->phase++;\n\tfor (i = btf->base_btf ? 0 : 1; i < btf->nr_types; i++) {\n\t\ttype_id = btf->start_id + i;\n\t\tt = btf_type_by_id(btf, type_id);\n\n\t\tenv->log_type_id = type_id;\n\t\tif (btf_type_needs_resolve(t) &&\n\t\t    !env_type_is_resolved(env, type_id)) {\n\t\t\terr = btf_resolve(env, t, type_id);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (btf_type_is_func_proto(t)) {\n\t\t\terr = btf_func_proto_check(env, t);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int btf_parse_type_sec(struct btf_verifier_env *env)\n{\n\tconst struct btf_header *hdr = &env->btf->hdr;\n\tint err;\n\n\t \n\tif (hdr->type_off & (sizeof(u32) - 1)) {\n\t\tbtf_verifier_log(env, \"Unaligned type_off\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env->btf->base_btf && !hdr->type_len) {\n\t\tbtf_verifier_log(env, \"No type found\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = btf_check_all_metas(env);\n\tif (err)\n\t\treturn err;\n\n\treturn btf_check_all_types(env);\n}\n\nstatic int btf_parse_str_sec(struct btf_verifier_env *env)\n{\n\tconst struct btf_header *hdr;\n\tstruct btf *btf = env->btf;\n\tconst char *start, *end;\n\n\thdr = &btf->hdr;\n\tstart = btf->nohdr_data + hdr->str_off;\n\tend = start + hdr->str_len;\n\n\tif (end != btf->data + btf->data_size) {\n\t\tbtf_verifier_log(env, \"String section is not at the end\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf->strings = start;\n\n\tif (btf->base_btf && !hdr->str_len)\n\t\treturn 0;\n\tif (!hdr->str_len || hdr->str_len - 1 > BTF_MAX_NAME_OFFSET || end[-1]) {\n\t\tbtf_verifier_log(env, \"Invalid string section\");\n\t\treturn -EINVAL;\n\t}\n\tif (!btf->base_btf && start[0]) {\n\t\tbtf_verifier_log(env, \"Invalid string section\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic const size_t btf_sec_info_offset[] = {\n\toffsetof(struct btf_header, type_off),\n\toffsetof(struct btf_header, str_off),\n};\n\nstatic int btf_sec_info_cmp(const void *a, const void *b)\n{\n\tconst struct btf_sec_info *x = a;\n\tconst struct btf_sec_info *y = b;\n\n\treturn (int)(x->off - y->off) ? : (int)(x->len - y->len);\n}\n\nstatic int btf_check_sec_info(struct btf_verifier_env *env,\n\t\t\t      u32 btf_data_size)\n{\n\tstruct btf_sec_info secs[ARRAY_SIZE(btf_sec_info_offset)];\n\tu32 total, expected_total, i;\n\tconst struct btf_header *hdr;\n\tconst struct btf *btf;\n\n\tbtf = env->btf;\n\thdr = &btf->hdr;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(btf_sec_info_offset); i++)\n\t\tsecs[i] = *(struct btf_sec_info *)((void *)hdr +\n\t\t\t\t\t\t   btf_sec_info_offset[i]);\n\n\tsort(secs, ARRAY_SIZE(btf_sec_info_offset),\n\t     sizeof(struct btf_sec_info), btf_sec_info_cmp, NULL);\n\n\t \n\ttotal = 0;\n\texpected_total = btf_data_size - hdr->hdr_len;\n\tfor (i = 0; i < ARRAY_SIZE(btf_sec_info_offset); i++) {\n\t\tif (expected_total < secs[i].off) {\n\t\t\tbtf_verifier_log(env, \"Invalid section offset\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (total < secs[i].off) {\n\t\t\t \n\t\t\tbtf_verifier_log(env, \"Unsupported section found\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (total > secs[i].off) {\n\t\t\tbtf_verifier_log(env, \"Section overlap found\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (expected_total - total < secs[i].len) {\n\t\t\tbtf_verifier_log(env,\n\t\t\t\t\t \"Total section length too long\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\ttotal += secs[i].len;\n\t}\n\n\t \n\tif (expected_total != total) {\n\t\tbtf_verifier_log(env, \"Unsupported section found\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int btf_parse_hdr(struct btf_verifier_env *env)\n{\n\tu32 hdr_len, hdr_copy, btf_data_size;\n\tconst struct btf_header *hdr;\n\tstruct btf *btf;\n\n\tbtf = env->btf;\n\tbtf_data_size = btf->data_size;\n\n\tif (btf_data_size < offsetofend(struct btf_header, hdr_len)) {\n\t\tbtf_verifier_log(env, \"hdr_len not found\");\n\t\treturn -EINVAL;\n\t}\n\n\thdr = btf->data;\n\thdr_len = hdr->hdr_len;\n\tif (btf_data_size < hdr_len) {\n\t\tbtf_verifier_log(env, \"btf_header not found\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (hdr_len > sizeof(btf->hdr)) {\n\t\tu8 *expected_zero = btf->data + sizeof(btf->hdr);\n\t\tu8 *end = btf->data + hdr_len;\n\n\t\tfor (; expected_zero < end; expected_zero++) {\n\t\t\tif (*expected_zero) {\n\t\t\t\tbtf_verifier_log(env, \"Unsupported btf_header\");\n\t\t\t\treturn -E2BIG;\n\t\t\t}\n\t\t}\n\t}\n\n\thdr_copy = min_t(u32, hdr_len, sizeof(btf->hdr));\n\tmemcpy(&btf->hdr, btf->data, hdr_copy);\n\n\thdr = &btf->hdr;\n\n\tbtf_verifier_log_hdr(env, btf_data_size);\n\n\tif (hdr->magic != BTF_MAGIC) {\n\t\tbtf_verifier_log(env, \"Invalid magic\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (hdr->version != BTF_VERSION) {\n\t\tbtf_verifier_log(env, \"Unsupported version\");\n\t\treturn -ENOTSUPP;\n\t}\n\n\tif (hdr->flags) {\n\t\tbtf_verifier_log(env, \"Unsupported flags\");\n\t\treturn -ENOTSUPP;\n\t}\n\n\tif (!btf->base_btf && btf_data_size == hdr->hdr_len) {\n\t\tbtf_verifier_log(env, \"No data\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn btf_check_sec_info(env, btf_data_size);\n}\n\nstatic const char *alloc_obj_fields[] = {\n\t\"bpf_spin_lock\",\n\t\"bpf_list_head\",\n\t\"bpf_list_node\",\n\t\"bpf_rb_root\",\n\t\"bpf_rb_node\",\n\t\"bpf_refcount\",\n};\n\nstatic struct btf_struct_metas *\nbtf_parse_struct_metas(struct bpf_verifier_log *log, struct btf *btf)\n{\n\tunion {\n\t\tstruct btf_id_set set;\n\t\tstruct {\n\t\t\tu32 _cnt;\n\t\t\tu32 _ids[ARRAY_SIZE(alloc_obj_fields)];\n\t\t} _arr;\n\t} aof;\n\tstruct btf_struct_metas *tab = NULL;\n\tint i, n, id, ret;\n\n\tBUILD_BUG_ON(offsetof(struct btf_id_set, cnt) != 0);\n\tBUILD_BUG_ON(sizeof(struct btf_id_set) != sizeof(u32));\n\n\tmemset(&aof, 0, sizeof(aof));\n\tfor (i = 0; i < ARRAY_SIZE(alloc_obj_fields); i++) {\n\t\t \n\t\tid = btf_find_by_name_kind(btf, alloc_obj_fields[i], BTF_KIND_STRUCT);\n\t\tif (id < 0)\n\t\t\tcontinue;\n\t\taof.set.ids[aof.set.cnt++] = id;\n\t}\n\n\tif (!aof.set.cnt)\n\t\treturn NULL;\n\tsort(&aof.set.ids, aof.set.cnt, sizeof(aof.set.ids[0]), btf_id_cmp_func, NULL);\n\n\tn = btf_nr_types(btf);\n\tfor (i = 1; i < n; i++) {\n\t\tstruct btf_struct_metas *new_tab;\n\t\tconst struct btf_member *member;\n\t\tstruct btf_struct_meta *type;\n\t\tstruct btf_record *record;\n\t\tconst struct btf_type *t;\n\t\tint j, tab_cnt;\n\n\t\tt = btf_type_by_id(btf, i);\n\t\tif (!t) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto free;\n\t\t}\n\t\tif (!__btf_type_is_struct(t))\n\t\t\tcontinue;\n\n\t\tcond_resched();\n\n\t\tfor_each_member(j, t, member) {\n\t\t\tif (btf_id_set_contains(&aof.set, member->type))\n\t\t\t\tgoto parse;\n\t\t}\n\t\tcontinue;\n\tparse:\n\t\ttab_cnt = tab ? tab->cnt : 0;\n\t\tnew_tab = krealloc(tab, offsetof(struct btf_struct_metas, types[tab_cnt + 1]),\n\t\t\t\t   GFP_KERNEL | __GFP_NOWARN);\n\t\tif (!new_tab) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto free;\n\t\t}\n\t\tif (!tab)\n\t\t\tnew_tab->cnt = 0;\n\t\ttab = new_tab;\n\n\t\ttype = &tab->types[tab->cnt];\n\t\ttype->btf_id = i;\n\t\trecord = btf_parse_fields(btf, t, BPF_SPIN_LOCK | BPF_LIST_HEAD | BPF_LIST_NODE |\n\t\t\t\t\t\t  BPF_RB_ROOT | BPF_RB_NODE | BPF_REFCOUNT, t->size);\n\t\t \n\t\tif (IS_ERR_OR_NULL(record)) {\n\t\t\tret = PTR_ERR_OR_ZERO(record) ?: -EFAULT;\n\t\t\tgoto free;\n\t\t}\n\t\ttype->record = record;\n\t\ttab->cnt++;\n\t}\n\treturn tab;\nfree:\n\tbtf_struct_metas_free(tab);\n\treturn ERR_PTR(ret);\n}\n\nstruct btf_struct_meta *btf_find_struct_meta(const struct btf *btf, u32 btf_id)\n{\n\tstruct btf_struct_metas *tab;\n\n\tBUILD_BUG_ON(offsetof(struct btf_struct_meta, btf_id) != 0);\n\ttab = btf->struct_meta_tab;\n\tif (!tab)\n\t\treturn NULL;\n\treturn bsearch(&btf_id, tab->types, tab->cnt, sizeof(tab->types[0]), btf_id_cmp_func);\n}\n\nstatic int btf_check_type_tags(struct btf_verifier_env *env,\n\t\t\t       struct btf *btf, int start_id)\n{\n\tint i, n, good_id = start_id - 1;\n\tbool in_tags;\n\n\tn = btf_nr_types(btf);\n\tfor (i = start_id; i < n; i++) {\n\t\tconst struct btf_type *t;\n\t\tint chain_limit = 32;\n\t\tu32 cur_id = i;\n\n\t\tt = btf_type_by_id(btf, i);\n\t\tif (!t)\n\t\t\treturn -EINVAL;\n\t\tif (!btf_type_is_modifier(t))\n\t\t\tcontinue;\n\n\t\tcond_resched();\n\n\t\tin_tags = btf_type_is_type_tag(t);\n\t\twhile (btf_type_is_modifier(t)) {\n\t\t\tif (!chain_limit--) {\n\t\t\t\tbtf_verifier_log(env, \"Max chain length or cycle detected\");\n\t\t\t\treturn -ELOOP;\n\t\t\t}\n\t\t\tif (btf_type_is_type_tag(t)) {\n\t\t\t\tif (!in_tags) {\n\t\t\t\t\tbtf_verifier_log(env, \"Type tags don't precede modifiers\");\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t} else if (in_tags) {\n\t\t\t\tin_tags = false;\n\t\t\t}\n\t\t\tif (cur_id <= good_id)\n\t\t\t\tbreak;\n\t\t\t \n\t\t\tcur_id = t->type;\n\t\t\tt = btf_type_by_id(btf, cur_id);\n\t\t\tif (!t)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\tgood_id = i;\n\t}\n\treturn 0;\n}\n\nstatic int finalize_log(struct bpf_verifier_log *log, bpfptr_t uattr, u32 uattr_size)\n{\n\tu32 log_true_size;\n\tint err;\n\n\terr = bpf_vlog_finalize(log, &log_true_size);\n\n\tif (uattr_size >= offsetofend(union bpf_attr, btf_log_true_size) &&\n\t    copy_to_bpfptr_offset(uattr, offsetof(union bpf_attr, btf_log_true_size),\n\t\t\t\t  &log_true_size, sizeof(log_true_size)))\n\t\terr = -EFAULT;\n\n\treturn err;\n}\n\nstatic struct btf *btf_parse(const union bpf_attr *attr, bpfptr_t uattr, u32 uattr_size)\n{\n\tbpfptr_t btf_data = make_bpfptr(attr->btf, uattr.is_kernel);\n\tchar __user *log_ubuf = u64_to_user_ptr(attr->btf_log_buf);\n\tstruct btf_struct_metas *struct_meta_tab;\n\tstruct btf_verifier_env *env = NULL;\n\tstruct btf *btf = NULL;\n\tu8 *data;\n\tint err, ret;\n\n\tif (attr->btf_size > BTF_MAX_SIZE)\n\t\treturn ERR_PTR(-E2BIG);\n\n\tenv = kzalloc(sizeof(*env), GFP_KERNEL | __GFP_NOWARN);\n\tif (!env)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t \n\terr = bpf_vlog_init(&env->log, attr->btf_log_level,\n\t\t\t    log_ubuf, attr->btf_log_size);\n\tif (err)\n\t\tgoto errout_free;\n\n\tbtf = kzalloc(sizeof(*btf), GFP_KERNEL | __GFP_NOWARN);\n\tif (!btf) {\n\t\terr = -ENOMEM;\n\t\tgoto errout;\n\t}\n\tenv->btf = btf;\n\n\tdata = kvmalloc(attr->btf_size, GFP_KERNEL | __GFP_NOWARN);\n\tif (!data) {\n\t\terr = -ENOMEM;\n\t\tgoto errout;\n\t}\n\n\tbtf->data = data;\n\tbtf->data_size = attr->btf_size;\n\n\tif (copy_from_bpfptr(data, btf_data, attr->btf_size)) {\n\t\terr = -EFAULT;\n\t\tgoto errout;\n\t}\n\n\terr = btf_parse_hdr(env);\n\tif (err)\n\t\tgoto errout;\n\n\tbtf->nohdr_data = btf->data + btf->hdr.hdr_len;\n\n\terr = btf_parse_str_sec(env);\n\tif (err)\n\t\tgoto errout;\n\n\terr = btf_parse_type_sec(env);\n\tif (err)\n\t\tgoto errout;\n\n\terr = btf_check_type_tags(env, btf, 1);\n\tif (err)\n\t\tgoto errout;\n\n\tstruct_meta_tab = btf_parse_struct_metas(&env->log, btf);\n\tif (IS_ERR(struct_meta_tab)) {\n\t\terr = PTR_ERR(struct_meta_tab);\n\t\tgoto errout;\n\t}\n\tbtf->struct_meta_tab = struct_meta_tab;\n\n\tif (struct_meta_tab) {\n\t\tint i;\n\n\t\tfor (i = 0; i < struct_meta_tab->cnt; i++) {\n\t\t\terr = btf_check_and_fixup_fields(btf, struct_meta_tab->types[i].record);\n\t\t\tif (err < 0)\n\t\t\t\tgoto errout_meta;\n\t\t}\n\t}\n\n\terr = finalize_log(&env->log, uattr, uattr_size);\n\tif (err)\n\t\tgoto errout_free;\n\n\tbtf_verifier_env_free(env);\n\trefcount_set(&btf->refcnt, 1);\n\treturn btf;\n\nerrout_meta:\n\tbtf_free_struct_meta_tab(btf);\nerrout:\n\t \n\tret = finalize_log(&env->log, uattr, uattr_size);\n\tif (ret)\n\t\terr = ret;\nerrout_free:\n\tbtf_verifier_env_free(env);\n\tif (btf)\n\t\tbtf_free(btf);\n\treturn ERR_PTR(err);\n}\n\nextern char __weak __start_BTF[];\nextern char __weak __stop_BTF[];\nextern struct btf *btf_vmlinux;\n\n#define BPF_MAP_TYPE(_id, _ops)\n#define BPF_LINK_TYPE(_id, _name)\nstatic union {\n\tstruct bpf_ctx_convert {\n#define BPF_PROG_TYPE(_id, _name, prog_ctx_type, kern_ctx_type) \\\n\tprog_ctx_type _id##_prog; \\\n\tkern_ctx_type _id##_kern;\n#include <linux/bpf_types.h>\n#undef BPF_PROG_TYPE\n\t} *__t;\n\t \n\tconst struct btf_type *t;\n} bpf_ctx_convert;\nenum {\n#define BPF_PROG_TYPE(_id, _name, prog_ctx_type, kern_ctx_type) \\\n\t__ctx_convert##_id,\n#include <linux/bpf_types.h>\n#undef BPF_PROG_TYPE\n\t__ctx_convert_unused,  \n};\nstatic u8 bpf_ctx_convert_map[] = {\n#define BPF_PROG_TYPE(_id, _name, prog_ctx_type, kern_ctx_type) \\\n\t[_id] = __ctx_convert##_id,\n#include <linux/bpf_types.h>\n#undef BPF_PROG_TYPE\n\t0,  \n};\n#undef BPF_MAP_TYPE\n#undef BPF_LINK_TYPE\n\nconst struct btf_member *\nbtf_get_prog_ctx_type(struct bpf_verifier_log *log, const struct btf *btf,\n\t\t      const struct btf_type *t, enum bpf_prog_type prog_type,\n\t\t      int arg)\n{\n\tconst struct btf_type *conv_struct;\n\tconst struct btf_type *ctx_struct;\n\tconst struct btf_member *ctx_type;\n\tconst char *tname, *ctx_tname;\n\n\tconv_struct = bpf_ctx_convert.t;\n\tif (!conv_struct) {\n\t\tbpf_log(log, \"btf_vmlinux is malformed\\n\");\n\t\treturn NULL;\n\t}\n\tt = btf_type_by_id(btf, t->type);\n\twhile (btf_type_is_modifier(t))\n\t\tt = btf_type_by_id(btf, t->type);\n\tif (!btf_type_is_struct(t)) {\n\t\t \n\t\treturn NULL;\n\t}\n\ttname = btf_name_by_offset(btf, t->name_off);\n\tif (!tname) {\n\t\tbpf_log(log, \"arg#%d struct doesn't have a name\\n\", arg);\n\t\treturn NULL;\n\t}\n\t \n\tctx_type = btf_type_member(conv_struct) + bpf_ctx_convert_map[prog_type] * 2;\n\t \n\tctx_struct = btf_type_by_id(btf_vmlinux, ctx_type->type);\n\tif (!ctx_struct)\n\t\t \n\t\treturn NULL;\nagain:\n\tctx_tname = btf_name_by_offset(btf_vmlinux, ctx_struct->name_off);\n\tif (!ctx_tname) {\n\t\t \n\t\tbpf_log(log, \"Please fix kernel include/linux/bpf_types.h\\n\");\n\t\treturn NULL;\n\t}\n\t \n\tif (strcmp(ctx_tname, \"__sk_buff\") == 0 && strcmp(tname, \"sk_buff\") == 0)\n\t\treturn ctx_type;\n\tif (strcmp(ctx_tname, \"xdp_md\") == 0 && strcmp(tname, \"xdp_buff\") == 0)\n\t\treturn ctx_type;\n\tif (strcmp(ctx_tname, tname)) {\n\t\t \n\t\tif (!btf_type_is_modifier(ctx_struct))\n\t\t\treturn NULL;\n\t\twhile (btf_type_is_modifier(ctx_struct))\n\t\t\tctx_struct = btf_type_by_id(btf_vmlinux, ctx_struct->type);\n\t\tgoto again;\n\t}\n\treturn ctx_type;\n}\n\nstatic int btf_translate_to_vmlinux(struct bpf_verifier_log *log,\n\t\t\t\t     struct btf *btf,\n\t\t\t\t     const struct btf_type *t,\n\t\t\t\t     enum bpf_prog_type prog_type,\n\t\t\t\t     int arg)\n{\n\tconst struct btf_member *prog_ctx_type, *kern_ctx_type;\n\n\tprog_ctx_type = btf_get_prog_ctx_type(log, btf, t, prog_type, arg);\n\tif (!prog_ctx_type)\n\t\treturn -ENOENT;\n\tkern_ctx_type = prog_ctx_type + 1;\n\treturn kern_ctx_type->type;\n}\n\nint get_kern_ctx_btf_id(struct bpf_verifier_log *log, enum bpf_prog_type prog_type)\n{\n\tconst struct btf_member *kctx_member;\n\tconst struct btf_type *conv_struct;\n\tconst struct btf_type *kctx_type;\n\tu32 kctx_type_id;\n\n\tconv_struct = bpf_ctx_convert.t;\n\t \n\tkctx_member = btf_type_member(conv_struct) + bpf_ctx_convert_map[prog_type] * 2 + 1;\n\tkctx_type_id = kctx_member->type;\n\tkctx_type = btf_type_by_id(btf_vmlinux, kctx_type_id);\n\tif (!btf_type_is_struct(kctx_type)) {\n\t\tbpf_log(log, \"kern ctx type id %u is not a struct\\n\", kctx_type_id);\n\t\treturn -EINVAL;\n\t}\n\n\treturn kctx_type_id;\n}\n\nBTF_ID_LIST(bpf_ctx_convert_btf_id)\nBTF_ID(struct, bpf_ctx_convert)\n\nstruct btf *btf_parse_vmlinux(void)\n{\n\tstruct btf_verifier_env *env = NULL;\n\tstruct bpf_verifier_log *log;\n\tstruct btf *btf = NULL;\n\tint err;\n\n\tenv = kzalloc(sizeof(*env), GFP_KERNEL | __GFP_NOWARN);\n\tif (!env)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tlog = &env->log;\n\tlog->level = BPF_LOG_KERNEL;\n\n\tbtf = kzalloc(sizeof(*btf), GFP_KERNEL | __GFP_NOWARN);\n\tif (!btf) {\n\t\terr = -ENOMEM;\n\t\tgoto errout;\n\t}\n\tenv->btf = btf;\n\n\tbtf->data = __start_BTF;\n\tbtf->data_size = __stop_BTF - __start_BTF;\n\tbtf->kernel_btf = true;\n\tsnprintf(btf->name, sizeof(btf->name), \"vmlinux\");\n\n\terr = btf_parse_hdr(env);\n\tif (err)\n\t\tgoto errout;\n\n\tbtf->nohdr_data = btf->data + btf->hdr.hdr_len;\n\n\terr = btf_parse_str_sec(env);\n\tif (err)\n\t\tgoto errout;\n\n\terr = btf_check_all_metas(env);\n\tif (err)\n\t\tgoto errout;\n\n\terr = btf_check_type_tags(env, btf, 1);\n\tif (err)\n\t\tgoto errout;\n\n\t \n\tbpf_ctx_convert.t = btf_type_by_id(btf, bpf_ctx_convert_btf_id[0]);\n\n\tbpf_struct_ops_init(btf, log);\n\n\trefcount_set(&btf->refcnt, 1);\n\n\terr = btf_alloc_id(btf);\n\tif (err)\n\t\tgoto errout;\n\n\tbtf_verifier_env_free(env);\n\treturn btf;\n\nerrout:\n\tbtf_verifier_env_free(env);\n\tif (btf) {\n\t\tkvfree(btf->types);\n\t\tkfree(btf);\n\t}\n\treturn ERR_PTR(err);\n}\n\n#ifdef CONFIG_DEBUG_INFO_BTF_MODULES\n\nstatic struct btf *btf_parse_module(const char *module_name, const void *data, unsigned int data_size)\n{\n\tstruct btf_verifier_env *env = NULL;\n\tstruct bpf_verifier_log *log;\n\tstruct btf *btf = NULL, *base_btf;\n\tint err;\n\n\tbase_btf = bpf_get_btf_vmlinux();\n\tif (IS_ERR(base_btf))\n\t\treturn base_btf;\n\tif (!base_btf)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tenv = kzalloc(sizeof(*env), GFP_KERNEL | __GFP_NOWARN);\n\tif (!env)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tlog = &env->log;\n\tlog->level = BPF_LOG_KERNEL;\n\n\tbtf = kzalloc(sizeof(*btf), GFP_KERNEL | __GFP_NOWARN);\n\tif (!btf) {\n\t\terr = -ENOMEM;\n\t\tgoto errout;\n\t}\n\tenv->btf = btf;\n\n\tbtf->base_btf = base_btf;\n\tbtf->start_id = base_btf->nr_types;\n\tbtf->start_str_off = base_btf->hdr.str_len;\n\tbtf->kernel_btf = true;\n\tsnprintf(btf->name, sizeof(btf->name), \"%s\", module_name);\n\n\tbtf->data = kvmalloc(data_size, GFP_KERNEL | __GFP_NOWARN);\n\tif (!btf->data) {\n\t\terr = -ENOMEM;\n\t\tgoto errout;\n\t}\n\tmemcpy(btf->data, data, data_size);\n\tbtf->data_size = data_size;\n\n\terr = btf_parse_hdr(env);\n\tif (err)\n\t\tgoto errout;\n\n\tbtf->nohdr_data = btf->data + btf->hdr.hdr_len;\n\n\terr = btf_parse_str_sec(env);\n\tif (err)\n\t\tgoto errout;\n\n\terr = btf_check_all_metas(env);\n\tif (err)\n\t\tgoto errout;\n\n\terr = btf_check_type_tags(env, btf, btf_nr_types(base_btf));\n\tif (err)\n\t\tgoto errout;\n\n\tbtf_verifier_env_free(env);\n\trefcount_set(&btf->refcnt, 1);\n\treturn btf;\n\nerrout:\n\tbtf_verifier_env_free(env);\n\tif (btf) {\n\t\tkvfree(btf->data);\n\t\tkvfree(btf->types);\n\t\tkfree(btf);\n\t}\n\treturn ERR_PTR(err);\n}\n\n#endif  \n\nstruct btf *bpf_prog_get_target_btf(const struct bpf_prog *prog)\n{\n\tstruct bpf_prog *tgt_prog = prog->aux->dst_prog;\n\n\tif (tgt_prog)\n\t\treturn tgt_prog->aux->btf;\n\telse\n\t\treturn prog->aux->attach_btf;\n}\n\nstatic bool is_int_ptr(struct btf *btf, const struct btf_type *t)\n{\n\t \n\tt = btf_type_skip_modifiers(btf, t->type, NULL);\n\n\treturn btf_type_is_int(t);\n}\n\nstatic u32 get_ctx_arg_idx(struct btf *btf, const struct btf_type *func_proto,\n\t\t\t   int off)\n{\n\tconst struct btf_param *args;\n\tconst struct btf_type *t;\n\tu32 offset = 0, nr_args;\n\tint i;\n\n\tif (!func_proto)\n\t\treturn off / 8;\n\n\tnr_args = btf_type_vlen(func_proto);\n\targs = (const struct btf_param *)(func_proto + 1);\n\tfor (i = 0; i < nr_args; i++) {\n\t\tt = btf_type_skip_modifiers(btf, args[i].type, NULL);\n\t\toffset += btf_type_is_ptr(t) ? 8 : roundup(t->size, 8);\n\t\tif (off < offset)\n\t\t\treturn i;\n\t}\n\n\tt = btf_type_skip_modifiers(btf, func_proto->type, NULL);\n\toffset += btf_type_is_ptr(t) ? 8 : roundup(t->size, 8);\n\tif (off < offset)\n\t\treturn nr_args;\n\n\treturn nr_args + 1;\n}\n\nstatic bool prog_args_trusted(const struct bpf_prog *prog)\n{\n\tenum bpf_attach_type atype = prog->expected_attach_type;\n\n\tswitch (prog->type) {\n\tcase BPF_PROG_TYPE_TRACING:\n\t\treturn atype == BPF_TRACE_RAW_TP || atype == BPF_TRACE_ITER;\n\tcase BPF_PROG_TYPE_LSM:\n\t\treturn bpf_lsm_is_trusted(prog);\n\tcase BPF_PROG_TYPE_STRUCT_OPS:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nbool btf_ctx_access(int off, int size, enum bpf_access_type type,\n\t\t    const struct bpf_prog *prog,\n\t\t    struct bpf_insn_access_aux *info)\n{\n\tconst struct btf_type *t = prog->aux->attach_func_proto;\n\tstruct bpf_prog *tgt_prog = prog->aux->dst_prog;\n\tstruct btf *btf = bpf_prog_get_target_btf(prog);\n\tconst char *tname = prog->aux->attach_func_name;\n\tstruct bpf_verifier_log *log = info->log;\n\tconst struct btf_param *args;\n\tconst char *tag_value;\n\tu32 nr_args, arg;\n\tint i, ret;\n\n\tif (off % 8) {\n\t\tbpf_log(log, \"func '%s' offset %d is not multiple of 8\\n\",\n\t\t\ttname, off);\n\t\treturn false;\n\t}\n\targ = get_ctx_arg_idx(btf, t, off);\n\targs = (const struct btf_param *)(t + 1);\n\t \n\tnr_args = t ? btf_type_vlen(t) : MAX_BPF_FUNC_REG_ARGS;\n\tif (prog->aux->attach_btf_trace) {\n\t\t \n\t\targs++;\n\t\tnr_args--;\n\t}\n\n\tif (arg > nr_args) {\n\t\tbpf_log(log, \"func '%s' doesn't have %d-th argument\\n\",\n\t\t\ttname, arg + 1);\n\t\treturn false;\n\t}\n\n\tif (arg == nr_args) {\n\t\tswitch (prog->expected_attach_type) {\n\t\tcase BPF_LSM_CGROUP:\n\t\tcase BPF_LSM_MAC:\n\t\tcase BPF_TRACE_FEXIT:\n\t\t\t \n\t\t\tif (!t)\n\t\t\t\treturn true;\n\t\t\tt = btf_type_by_id(btf, t->type);\n\t\t\tbreak;\n\t\tcase BPF_MODIFY_RETURN:\n\t\t\t \n\t\t\tif (!t)\n\t\t\t\treturn false;\n\n\t\t\tt = btf_type_skip_modifiers(btf, t->type, NULL);\n\t\t\tif (!btf_type_is_small_int(t)) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"ret type %s not allowed for fmod_ret\\n\",\n\t\t\t\t\tbtf_type_str(t));\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbpf_log(log, \"func '%s' doesn't have %d-th argument\\n\",\n\t\t\t\ttname, arg + 1);\n\t\t\treturn false;\n\t\t}\n\t} else {\n\t\tif (!t)\n\t\t\t \n\t\t\treturn true;\n\t\tt = btf_type_by_id(btf, args[arg].type);\n\t}\n\n\t \n\twhile (btf_type_is_modifier(t))\n\t\tt = btf_type_by_id(btf, t->type);\n\tif (btf_type_is_small_int(t) || btf_is_any_enum(t) || __btf_type_is_struct(t))\n\t\t \n\t\treturn true;\n\tif (!btf_type_is_ptr(t)) {\n\t\tbpf_log(log,\n\t\t\t\"func '%s' arg%d '%s' has type %s. Only pointer access is allowed\\n\",\n\t\t\ttname, arg,\n\t\t\t__btf_name_by_offset(btf, t->name_off),\n\t\t\tbtf_type_str(t));\n\t\treturn false;\n\t}\n\n\t \n\tfor (i = 0; i < prog->aux->ctx_arg_info_size; i++) {\n\t\tconst struct bpf_ctx_arg_aux *ctx_arg_info = &prog->aux->ctx_arg_info[i];\n\t\tu32 type, flag;\n\n\t\ttype = base_type(ctx_arg_info->reg_type);\n\t\tflag = type_flag(ctx_arg_info->reg_type);\n\t\tif (ctx_arg_info->offset == off && type == PTR_TO_BUF &&\n\t\t    (flag & PTR_MAYBE_NULL)) {\n\t\t\tinfo->reg_type = ctx_arg_info->reg_type;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tif (t->type == 0)\n\t\t \n\t\treturn true;\n\n\tif (is_int_ptr(btf, t))\n\t\treturn true;\n\n\t \n\tfor (i = 0; i < prog->aux->ctx_arg_info_size; i++) {\n\t\tconst struct bpf_ctx_arg_aux *ctx_arg_info = &prog->aux->ctx_arg_info[i];\n\n\t\tif (ctx_arg_info->offset == off) {\n\t\t\tif (!ctx_arg_info->btf_id) {\n\t\t\t\tbpf_log(log,\"invalid btf_id for context argument offset %u\\n\", off);\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tinfo->reg_type = ctx_arg_info->reg_type;\n\t\t\tinfo->btf = btf_vmlinux;\n\t\t\tinfo->btf_id = ctx_arg_info->btf_id;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tinfo->reg_type = PTR_TO_BTF_ID;\n\tif (prog_args_trusted(prog))\n\t\tinfo->reg_type |= PTR_TRUSTED;\n\n\tif (tgt_prog) {\n\t\tenum bpf_prog_type tgt_type;\n\n\t\tif (tgt_prog->type == BPF_PROG_TYPE_EXT)\n\t\t\ttgt_type = tgt_prog->aux->saved_dst_prog_type;\n\t\telse\n\t\t\ttgt_type = tgt_prog->type;\n\n\t\tret = btf_translate_to_vmlinux(log, btf, t, tgt_type, arg);\n\t\tif (ret > 0) {\n\t\t\tinfo->btf = btf_vmlinux;\n\t\t\tinfo->btf_id = ret;\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tinfo->btf = btf;\n\tinfo->btf_id = t->type;\n\tt = btf_type_by_id(btf, t->type);\n\n\tif (btf_type_is_type_tag(t)) {\n\t\ttag_value = __btf_name_by_offset(btf, t->name_off);\n\t\tif (strcmp(tag_value, \"user\") == 0)\n\t\t\tinfo->reg_type |= MEM_USER;\n\t\tif (strcmp(tag_value, \"percpu\") == 0)\n\t\t\tinfo->reg_type |= MEM_PERCPU;\n\t}\n\n\t \n\twhile (btf_type_is_modifier(t)) {\n\t\tinfo->btf_id = t->type;\n\t\tt = btf_type_by_id(btf, t->type);\n\t}\n\tif (!btf_type_is_struct(t)) {\n\t\tbpf_log(log,\n\t\t\t\"func '%s' arg%d type %s is not a struct\\n\",\n\t\t\ttname, arg, btf_type_str(t));\n\t\treturn false;\n\t}\n\tbpf_log(log, \"func '%s' arg%d has btf_id %d type %s '%s'\\n\",\n\t\ttname, arg, info->btf_id, btf_type_str(t),\n\t\t__btf_name_by_offset(btf, t->name_off));\n\treturn true;\n}\n\nenum bpf_struct_walk_result {\n\t \n\tWALK_SCALAR = 0,\n\tWALK_PTR,\n\tWALK_STRUCT,\n};\n\nstatic int btf_struct_walk(struct bpf_verifier_log *log, const struct btf *btf,\n\t\t\t   const struct btf_type *t, int off, int size,\n\t\t\t   u32 *next_btf_id, enum bpf_type_flag *flag,\n\t\t\t   const char **field_name)\n{\n\tu32 i, moff, mtrue_end, msize = 0, total_nelems = 0;\n\tconst struct btf_type *mtype, *elem_type = NULL;\n\tconst struct btf_member *member;\n\tconst char *tname, *mname, *tag_value;\n\tu32 vlen, elem_id, mid;\n\nagain:\n\tif (btf_type_is_modifier(t))\n\t\tt = btf_type_skip_modifiers(btf, t->type, NULL);\n\ttname = __btf_name_by_offset(btf, t->name_off);\n\tif (!btf_type_is_struct(t)) {\n\t\tbpf_log(log, \"Type '%s' is not a struct\\n\", tname);\n\t\treturn -EINVAL;\n\t}\n\n\tvlen = btf_type_vlen(t);\n\tif (BTF_INFO_KIND(t->info) == BTF_KIND_UNION && vlen != 1 && !(*flag & PTR_UNTRUSTED))\n\t\t \n\t\t*flag |= PTR_UNTRUSTED;\n\n\tif (off + size > t->size) {\n\t\t \n\t\tstruct btf_array *array_elem;\n\n\t\tif (vlen == 0)\n\t\t\tgoto error;\n\n\t\tmember = btf_type_member(t) + vlen - 1;\n\t\tmtype = btf_type_skip_modifiers(btf, member->type,\n\t\t\t\t\t\tNULL);\n\t\tif (!btf_type_is_array(mtype))\n\t\t\tgoto error;\n\n\t\tarray_elem = (struct btf_array *)(mtype + 1);\n\t\tif (array_elem->nelems != 0)\n\t\t\tgoto error;\n\n\t\tmoff = __btf_member_bit_offset(t, member) / 8;\n\t\tif (off < moff)\n\t\t\tgoto error;\n\n\t\t \n\t\tt = btf_type_skip_modifiers(btf, array_elem->type,\n\t\t\t\t\t    NULL);\n\n\t\tif (btf_type_is_int(t))\n\t\t\treturn WALK_SCALAR;\n\n\t\tif (!btf_type_is_struct(t))\n\t\t\tgoto error;\n\n\t\toff = (off - moff) % t->size;\n\t\tgoto again;\n\nerror:\n\t\tbpf_log(log, \"access beyond struct %s at off %u size %u\\n\",\n\t\t\ttname, off, size);\n\t\treturn -EACCES;\n\t}\n\n\tfor_each_member(i, t, member) {\n\t\t \n\t\tmoff = __btf_member_bit_offset(t, member) / 8;\n\t\tif (off + size <= moff)\n\t\t\t \n\t\t\tbreak;\n\n\t\tif (__btf_member_bitfield_size(t, member)) {\n\t\t\tu32 end_bit = __btf_member_bit_offset(t, member) +\n\t\t\t\t__btf_member_bitfield_size(t, member);\n\n\t\t\t \n\t\t\tif (off <= moff &&\n\t\t\t    BITS_ROUNDUP_BYTES(end_bit) <= off + size)\n\t\t\t\treturn WALK_SCALAR;\n\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (off < moff)\n\t\t\tbreak;\n\n\t\t \n\t\tmid = member->type;\n\t\tmtype = btf_type_by_id(btf, member->type);\n\t\tmname = __btf_name_by_offset(btf, member->name_off);\n\n\t\tmtype = __btf_resolve_size(btf, mtype, &msize,\n\t\t\t\t\t   &elem_type, &elem_id, &total_nelems,\n\t\t\t\t\t   &mid);\n\t\tif (IS_ERR(mtype)) {\n\t\t\tbpf_log(log, \"field %s doesn't have size\\n\", mname);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tmtrue_end = moff + msize;\n\t\tif (off >= mtrue_end)\n\t\t\t \n\t\t\tcontinue;\n\n\t\tif (btf_type_is_array(mtype)) {\n\t\t\tu32 elem_idx;\n\n\t\t\t \n\n\t\t\t \n\t\t\tif (moff == mtrue_end)\n\t\t\t\tcontinue;\n\n\t\t\tmsize /= total_nelems;\n\t\t\telem_idx = (off - moff) / msize;\n\t\t\tmoff += elem_idx * msize;\n\t\t\tmtype = elem_type;\n\t\t\tmid = elem_id;\n\t\t}\n\n\t\t \n\t\tif (btf_type_is_struct(mtype)) {\n\t\t\t \n\t\t\tt = mtype;\n\n\t\t\t \n\t\t\tif (off == moff) {\n\t\t\t\t*next_btf_id = mid;\n\t\t\t\treturn WALK_STRUCT;\n\t\t\t}\n\n\t\t\t \n\t\t\toff -= moff;\n\t\t\tgoto again;\n\t\t}\n\n\t\tif (btf_type_is_ptr(mtype)) {\n\t\t\tconst struct btf_type *stype, *t;\n\t\t\tenum bpf_type_flag tmp_flag = 0;\n\t\t\tu32 id;\n\n\t\t\tif (msize != size || off != moff) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"cannot access ptr member %s with moff %u in struct %s with off %u size %u\\n\",\n\t\t\t\t\tmname, moff, tname, off, size);\n\t\t\t\treturn -EACCES;\n\t\t\t}\n\n\t\t\t \n\t\t\tt = btf_type_by_id(btf, mtype->type);\n\t\t\tif (btf_type_is_type_tag(t)) {\n\t\t\t\ttag_value = __btf_name_by_offset(btf, t->name_off);\n\t\t\t\t \n\t\t\t\tif (strcmp(tag_value, \"user\") == 0)\n\t\t\t\t\ttmp_flag = MEM_USER;\n\t\t\t\t \n\t\t\t\tif (strcmp(tag_value, \"percpu\") == 0)\n\t\t\t\t\ttmp_flag = MEM_PERCPU;\n\t\t\t\t \n\t\t\t\tif (strcmp(tag_value, \"rcu\") == 0)\n\t\t\t\t\ttmp_flag = MEM_RCU;\n\t\t\t}\n\n\t\t\tstype = btf_type_skip_modifiers(btf, mtype->type, &id);\n\t\t\tif (btf_type_is_struct(stype)) {\n\t\t\t\t*next_btf_id = id;\n\t\t\t\t*flag |= tmp_flag;\n\t\t\t\tif (field_name)\n\t\t\t\t\t*field_name = mname;\n\t\t\t\treturn WALK_PTR;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (off + size > mtrue_end && !(*flag & PTR_UNTRUSTED)) {\n\t\t\tbpf_log(log,\n\t\t\t\t\"access beyond the end of member %s (mend:%u) in struct %s with off %u size %u\\n\",\n\t\t\t\tmname, mtrue_end, tname, off, size);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\treturn WALK_SCALAR;\n\t}\n\tbpf_log(log, \"struct %s doesn't have field at offset %d\\n\", tname, off);\n\treturn -EINVAL;\n}\n\nint btf_struct_access(struct bpf_verifier_log *log,\n\t\t      const struct bpf_reg_state *reg,\n\t\t      int off, int size, enum bpf_access_type atype __maybe_unused,\n\t\t      u32 *next_btf_id, enum bpf_type_flag *flag,\n\t\t      const char **field_name)\n{\n\tconst struct btf *btf = reg->btf;\n\tenum bpf_type_flag tmp_flag = 0;\n\tconst struct btf_type *t;\n\tu32 id = reg->btf_id;\n\tint err;\n\n\twhile (type_is_alloc(reg->type)) {\n\t\tstruct btf_struct_meta *meta;\n\t\tstruct btf_record *rec;\n\t\tint i;\n\n\t\tmeta = btf_find_struct_meta(btf, id);\n\t\tif (!meta)\n\t\t\tbreak;\n\t\trec = meta->record;\n\t\tfor (i = 0; i < rec->cnt; i++) {\n\t\t\tstruct btf_field *field = &rec->fields[i];\n\t\t\tu32 offset = field->offset;\n\t\t\tif (off < offset + btf_field_type_size(field->type) && offset < off + size) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"direct access to %s is disallowed\\n\",\n\t\t\t\t\tbtf_field_type_name(field->type));\n\t\t\t\treturn -EACCES;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\n\tt = btf_type_by_id(btf, id);\n\tdo {\n\t\terr = btf_struct_walk(log, btf, t, off, size, &id, &tmp_flag, field_name);\n\n\t\tswitch (err) {\n\t\tcase WALK_PTR:\n\t\t\t \n\t\t\tif (type_is_alloc(reg->type))\n\t\t\t\treturn SCALAR_VALUE;\n\t\t\t \n\t\t\t*next_btf_id = id;\n\t\t\t*flag = tmp_flag;\n\t\t\treturn PTR_TO_BTF_ID;\n\t\tcase WALK_SCALAR:\n\t\t\treturn SCALAR_VALUE;\n\t\tcase WALK_STRUCT:\n\t\t\t \n\t\t\tt = btf_type_by_id(btf, id);\n\t\t\toff = 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tif (WARN_ONCE(err > 0, \"unknown btf_struct_walk return value\"))\n\t\t\t\treturn -EINVAL;\n\t\t\treturn err;\n\t\t}\n\t} while (t);\n\n\treturn -EINVAL;\n}\n\n \nbool btf_types_are_same(const struct btf *btf1, u32 id1,\n\t\t\tconst struct btf *btf2, u32 id2)\n{\n\tif (id1 != id2)\n\t\treturn false;\n\tif (btf1 == btf2)\n\t\treturn true;\n\treturn btf_type_by_id(btf1, id1) == btf_type_by_id(btf2, id2);\n}\n\nbool btf_struct_ids_match(struct bpf_verifier_log *log,\n\t\t\t  const struct btf *btf, u32 id, int off,\n\t\t\t  const struct btf *need_btf, u32 need_type_id,\n\t\t\t  bool strict)\n{\n\tconst struct btf_type *type;\n\tenum bpf_type_flag flag = 0;\n\tint err;\n\n\t \n\tif (off == 0 && btf_types_are_same(btf, id, need_btf, need_type_id))\n\t\treturn true;\n\t \n\tif (strict)\n\t\treturn false;\nagain:\n\ttype = btf_type_by_id(btf, id);\n\tif (!type)\n\t\treturn false;\n\terr = btf_struct_walk(log, btf, type, off, 1, &id, &flag, NULL);\n\tif (err != WALK_STRUCT)\n\t\treturn false;\n\n\t \n\tif (!btf_types_are_same(btf, id, need_btf, need_type_id)) {\n\t\toff = 0;\n\t\tgoto again;\n\t}\n\n\treturn true;\n}\n\nstatic int __get_type_size(struct btf *btf, u32 btf_id,\n\t\t\t   const struct btf_type **ret_type)\n{\n\tconst struct btf_type *t;\n\n\t*ret_type = btf_type_by_id(btf, 0);\n\tif (!btf_id)\n\t\t \n\t\treturn 0;\n\tt = btf_type_by_id(btf, btf_id);\n\twhile (t && btf_type_is_modifier(t))\n\t\tt = btf_type_by_id(btf, t->type);\n\tif (!t)\n\t\treturn -EINVAL;\n\t*ret_type = t;\n\tif (btf_type_is_ptr(t))\n\t\t \n\t\treturn sizeof(void *);\n\tif (btf_type_is_int(t) || btf_is_any_enum(t) || __btf_type_is_struct(t))\n\t\treturn t->size;\n\treturn -EINVAL;\n}\n\nstatic u8 __get_type_fmodel_flags(const struct btf_type *t)\n{\n\tu8 flags = 0;\n\n\tif (__btf_type_is_struct(t))\n\t\tflags |= BTF_FMODEL_STRUCT_ARG;\n\tif (btf_type_is_signed_int(t))\n\t\tflags |= BTF_FMODEL_SIGNED_ARG;\n\n\treturn flags;\n}\n\nint btf_distill_func_proto(struct bpf_verifier_log *log,\n\t\t\t   struct btf *btf,\n\t\t\t   const struct btf_type *func,\n\t\t\t   const char *tname,\n\t\t\t   struct btf_func_model *m)\n{\n\tconst struct btf_param *args;\n\tconst struct btf_type *t;\n\tu32 i, nargs;\n\tint ret;\n\n\tif (!func) {\n\t\t \n\t\tfor (i = 0; i < MAX_BPF_FUNC_REG_ARGS; i++) {\n\t\t\tm->arg_size[i] = 8;\n\t\t\tm->arg_flags[i] = 0;\n\t\t}\n\t\tm->ret_size = 8;\n\t\tm->ret_flags = 0;\n\t\tm->nr_args = MAX_BPF_FUNC_REG_ARGS;\n\t\treturn 0;\n\t}\n\targs = (const struct btf_param *)(func + 1);\n\tnargs = btf_type_vlen(func);\n\tif (nargs > MAX_BPF_FUNC_ARGS) {\n\t\tbpf_log(log,\n\t\t\t\"The function %s has %d arguments. Too many.\\n\",\n\t\t\ttname, nargs);\n\t\treturn -EINVAL;\n\t}\n\tret = __get_type_size(btf, func->type, &t);\n\tif (ret < 0 || __btf_type_is_struct(t)) {\n\t\tbpf_log(log,\n\t\t\t\"The function %s return type %s is unsupported.\\n\",\n\t\t\ttname, btf_type_str(t));\n\t\treturn -EINVAL;\n\t}\n\tm->ret_size = ret;\n\tm->ret_flags = __get_type_fmodel_flags(t);\n\n\tfor (i = 0; i < nargs; i++) {\n\t\tif (i == nargs - 1 && args[i].type == 0) {\n\t\t\tbpf_log(log,\n\t\t\t\t\"The function %s with variable args is unsupported.\\n\",\n\t\t\t\ttname);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tret = __get_type_size(btf, args[i].type, &t);\n\n\t\t \n\t\tif (ret < 0 || ret > 16) {\n\t\t\tbpf_log(log,\n\t\t\t\t\"The function %s arg%d type %s is unsupported.\\n\",\n\t\t\t\ttname, i, btf_type_str(t));\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (ret == 0) {\n\t\t\tbpf_log(log,\n\t\t\t\t\"The function %s has malformed void argument.\\n\",\n\t\t\t\ttname);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tm->arg_size[i] = ret;\n\t\tm->arg_flags[i] = __get_type_fmodel_flags(t);\n\t}\n\tm->nr_args = nargs;\n\treturn 0;\n}\n\n \nstatic int btf_check_func_type_match(struct bpf_verifier_log *log,\n\t\t\t\t     struct btf *btf1, const struct btf_type *t1,\n\t\t\t\t     struct btf *btf2, const struct btf_type *t2)\n{\n\tconst struct btf_param *args1, *args2;\n\tconst char *fn1, *fn2, *s1, *s2;\n\tu32 nargs1, nargs2, i;\n\n\tfn1 = btf_name_by_offset(btf1, t1->name_off);\n\tfn2 = btf_name_by_offset(btf2, t2->name_off);\n\n\tif (btf_func_linkage(t1) != BTF_FUNC_GLOBAL) {\n\t\tbpf_log(log, \"%s() is not a global function\\n\", fn1);\n\t\treturn -EINVAL;\n\t}\n\tif (btf_func_linkage(t2) != BTF_FUNC_GLOBAL) {\n\t\tbpf_log(log, \"%s() is not a global function\\n\", fn2);\n\t\treturn -EINVAL;\n\t}\n\n\tt1 = btf_type_by_id(btf1, t1->type);\n\tif (!t1 || !btf_type_is_func_proto(t1))\n\t\treturn -EFAULT;\n\tt2 = btf_type_by_id(btf2, t2->type);\n\tif (!t2 || !btf_type_is_func_proto(t2))\n\t\treturn -EFAULT;\n\n\targs1 = (const struct btf_param *)(t1 + 1);\n\tnargs1 = btf_type_vlen(t1);\n\targs2 = (const struct btf_param *)(t2 + 1);\n\tnargs2 = btf_type_vlen(t2);\n\n\tif (nargs1 != nargs2) {\n\t\tbpf_log(log, \"%s() has %d args while %s() has %d args\\n\",\n\t\t\tfn1, nargs1, fn2, nargs2);\n\t\treturn -EINVAL;\n\t}\n\n\tt1 = btf_type_skip_modifiers(btf1, t1->type, NULL);\n\tt2 = btf_type_skip_modifiers(btf2, t2->type, NULL);\n\tif (t1->info != t2->info) {\n\t\tbpf_log(log,\n\t\t\t\"Return type %s of %s() doesn't match type %s of %s()\\n\",\n\t\t\tbtf_type_str(t1), fn1,\n\t\t\tbtf_type_str(t2), fn2);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < nargs1; i++) {\n\t\tt1 = btf_type_skip_modifiers(btf1, args1[i].type, NULL);\n\t\tt2 = btf_type_skip_modifiers(btf2, args2[i].type, NULL);\n\n\t\tif (t1->info != t2->info) {\n\t\t\tbpf_log(log, \"arg%d in %s() is %s while %s() has %s\\n\",\n\t\t\t\ti, fn1, btf_type_str(t1),\n\t\t\t\tfn2, btf_type_str(t2));\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (btf_type_has_size(t1) && t1->size != t2->size) {\n\t\t\tbpf_log(log,\n\t\t\t\t\"arg%d in %s() has size %d while %s() has %d\\n\",\n\t\t\t\ti, fn1, t1->size,\n\t\t\t\tfn2, t2->size);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (btf_type_is_int(t1) || btf_is_any_enum(t1))\n\t\t\tcontinue;\n\t\tif (!btf_type_is_ptr(t1)) {\n\t\t\tbpf_log(log,\n\t\t\t\t\"arg%d in %s() has unrecognized type\\n\",\n\t\t\t\ti, fn1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tt1 = btf_type_skip_modifiers(btf1, t1->type, NULL);\n\t\tt2 = btf_type_skip_modifiers(btf2, t2->type, NULL);\n\t\tif (!btf_type_is_struct(t1)) {\n\t\t\tbpf_log(log,\n\t\t\t\t\"arg%d in %s() is not a pointer to context\\n\",\n\t\t\t\ti, fn1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!btf_type_is_struct(t2)) {\n\t\t\tbpf_log(log,\n\t\t\t\t\"arg%d in %s() is not a pointer to context\\n\",\n\t\t\t\ti, fn2);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t \n\t\ts1 = btf_name_by_offset(btf1, t1->name_off);\n\t\ts2 = btf_name_by_offset(btf2, t2->name_off);\n\t\tif (strcmp(s1, s2)) {\n\t\t\tbpf_log(log,\n\t\t\t\t\"arg%d %s(struct %s *) doesn't match %s(struct %s *)\\n\",\n\t\t\t\ti, fn1, s1, fn2, s2);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nint btf_check_type_match(struct bpf_verifier_log *log, const struct bpf_prog *prog,\n\t\t\t struct btf *btf2, const struct btf_type *t2)\n{\n\tstruct btf *btf1 = prog->aux->btf;\n\tconst struct btf_type *t1;\n\tu32 btf_id = 0;\n\n\tif (!prog->aux->func_info) {\n\t\tbpf_log(log, \"Program extension requires BTF\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tbtf_id = prog->aux->func_info[0].type_id;\n\tif (!btf_id)\n\t\treturn -EFAULT;\n\n\tt1 = btf_type_by_id(btf1, btf_id);\n\tif (!t1 || !btf_type_is_func(t1))\n\t\treturn -EFAULT;\n\n\treturn btf_check_func_type_match(log, btf1, t1, btf2, t2);\n}\n\nstatic int btf_check_func_arg_match(struct bpf_verifier_env *env,\n\t\t\t\t    const struct btf *btf, u32 func_id,\n\t\t\t\t    struct bpf_reg_state *regs,\n\t\t\t\t    bool ptr_to_mem_ok,\n\t\t\t\t    bool processing_call)\n{\n\tenum bpf_prog_type prog_type = resolve_prog_type(env->prog);\n\tstruct bpf_verifier_log *log = &env->log;\n\tconst char *func_name, *ref_tname;\n\tconst struct btf_type *t, *ref_t;\n\tconst struct btf_param *args;\n\tu32 i, nargs, ref_id;\n\tint ret;\n\n\tt = btf_type_by_id(btf, func_id);\n\tif (!t || !btf_type_is_func(t)) {\n\t\t \n\t\tbpf_log(log, \"BTF of func_id %u doesn't point to KIND_FUNC\\n\",\n\t\t\tfunc_id);\n\t\treturn -EFAULT;\n\t}\n\tfunc_name = btf_name_by_offset(btf, t->name_off);\n\n\tt = btf_type_by_id(btf, t->type);\n\tif (!t || !btf_type_is_func_proto(t)) {\n\t\tbpf_log(log, \"Invalid BTF of func %s\\n\", func_name);\n\t\treturn -EFAULT;\n\t}\n\targs = (const struct btf_param *)(t + 1);\n\tnargs = btf_type_vlen(t);\n\tif (nargs > MAX_BPF_FUNC_REG_ARGS) {\n\t\tbpf_log(log, \"Function %s has %d > %d args\\n\", func_name, nargs,\n\t\t\tMAX_BPF_FUNC_REG_ARGS);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tfor (i = 0; i < nargs; i++) {\n\t\tenum bpf_arg_type arg_type = ARG_DONTCARE;\n\t\tu32 regno = i + 1;\n\t\tstruct bpf_reg_state *reg = &regs[regno];\n\n\t\tt = btf_type_skip_modifiers(btf, args[i].type, NULL);\n\t\tif (btf_type_is_scalar(t)) {\n\t\t\tif (reg->type == SCALAR_VALUE)\n\t\t\t\tcontinue;\n\t\t\tbpf_log(log, \"R%d is not a scalar\\n\", regno);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!btf_type_is_ptr(t)) {\n\t\t\tbpf_log(log, \"Unrecognized arg#%d type %s\\n\",\n\t\t\t\ti, btf_type_str(t));\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tref_t = btf_type_skip_modifiers(btf, t->type, &ref_id);\n\t\tref_tname = btf_name_by_offset(btf, ref_t->name_off);\n\n\t\tret = check_func_arg_reg_off(env, reg, regno, arg_type);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (btf_get_prog_ctx_type(log, btf, t, prog_type, i)) {\n\t\t\t \n\t\t\tif (reg->type != PTR_TO_CTX) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"arg#%d expected pointer to ctx, but got %s\\n\",\n\t\t\t\t\ti, btf_type_str(t));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else if (ptr_to_mem_ok && processing_call) {\n\t\t\tconst struct btf_type *resolve_ret;\n\t\t\tu32 type_size;\n\n\t\t\tresolve_ret = btf_resolve_size(btf, ref_t, &type_size);\n\t\t\tif (IS_ERR(resolve_ret)) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"arg#%d reference type('%s %s') size cannot be determined: %ld\\n\",\n\t\t\t\t\ti, btf_type_str(ref_t), ref_tname,\n\t\t\t\t\tPTR_ERR(resolve_ret));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (check_mem_reg(env, reg, regno, type_size))\n\t\t\t\treturn -EINVAL;\n\t\t} else {\n\t\t\tbpf_log(log, \"reg type unsupported for arg#%d function %s#%d\\n\", i,\n\t\t\t\tfunc_name, func_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nint btf_check_subprog_arg_match(struct bpf_verifier_env *env, int subprog,\n\t\t\t\tstruct bpf_reg_state *regs)\n{\n\tstruct bpf_prog *prog = env->prog;\n\tstruct btf *btf = prog->aux->btf;\n\tbool is_global;\n\tu32 btf_id;\n\tint err;\n\n\tif (!prog->aux->func_info)\n\t\treturn -EINVAL;\n\n\tbtf_id = prog->aux->func_info[subprog].type_id;\n\tif (!btf_id)\n\t\treturn -EFAULT;\n\n\tif (prog->aux->func_info_aux[subprog].unreliable)\n\t\treturn -EINVAL;\n\n\tis_global = prog->aux->func_info_aux[subprog].linkage == BTF_FUNC_GLOBAL;\n\terr = btf_check_func_arg_match(env, btf, btf_id, regs, is_global, false);\n\n\t \n\tif (err)\n\t\tprog->aux->func_info_aux[subprog].unreliable = true;\n\treturn err;\n}\n\n \nint btf_check_subprog_call(struct bpf_verifier_env *env, int subprog,\n\t\t\t   struct bpf_reg_state *regs)\n{\n\tstruct bpf_prog *prog = env->prog;\n\tstruct btf *btf = prog->aux->btf;\n\tbool is_global;\n\tu32 btf_id;\n\tint err;\n\n\tif (!prog->aux->func_info)\n\t\treturn -EINVAL;\n\n\tbtf_id = prog->aux->func_info[subprog].type_id;\n\tif (!btf_id)\n\t\treturn -EFAULT;\n\n\tif (prog->aux->func_info_aux[subprog].unreliable)\n\t\treturn -EINVAL;\n\n\tis_global = prog->aux->func_info_aux[subprog].linkage == BTF_FUNC_GLOBAL;\n\terr = btf_check_func_arg_match(env, btf, btf_id, regs, is_global, true);\n\n\t \n\tif (err)\n\t\tprog->aux->func_info_aux[subprog].unreliable = true;\n\treturn err;\n}\n\n \nint btf_prepare_func_args(struct bpf_verifier_env *env, int subprog,\n\t\t\t  struct bpf_reg_state *regs)\n{\n\tstruct bpf_verifier_log *log = &env->log;\n\tstruct bpf_prog *prog = env->prog;\n\tenum bpf_prog_type prog_type = prog->type;\n\tstruct btf *btf = prog->aux->btf;\n\tconst struct btf_param *args;\n\tconst struct btf_type *t, *ref_t;\n\tu32 i, nargs, btf_id;\n\tconst char *tname;\n\n\tif (!prog->aux->func_info ||\n\t    prog->aux->func_info_aux[subprog].linkage != BTF_FUNC_GLOBAL) {\n\t\tbpf_log(log, \"Verifier bug\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tbtf_id = prog->aux->func_info[subprog].type_id;\n\tif (!btf_id) {\n\t\tbpf_log(log, \"Global functions need valid BTF\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tt = btf_type_by_id(btf, btf_id);\n\tif (!t || !btf_type_is_func(t)) {\n\t\t \n\t\tbpf_log(log, \"BTF of func#%d doesn't point to KIND_FUNC\\n\",\n\t\t\tsubprog);\n\t\treturn -EFAULT;\n\t}\n\ttname = btf_name_by_offset(btf, t->name_off);\n\n\tif (log->level & BPF_LOG_LEVEL)\n\t\tbpf_log(log, \"Validating %s() func#%d...\\n\",\n\t\t\ttname, subprog);\n\n\tif (prog->aux->func_info_aux[subprog].unreliable) {\n\t\tbpf_log(log, \"Verifier bug in function %s()\\n\", tname);\n\t\treturn -EFAULT;\n\t}\n\tif (prog_type == BPF_PROG_TYPE_EXT)\n\t\tprog_type = prog->aux->dst_prog->type;\n\n\tt = btf_type_by_id(btf, t->type);\n\tif (!t || !btf_type_is_func_proto(t)) {\n\t\tbpf_log(log, \"Invalid type of function %s()\\n\", tname);\n\t\treturn -EFAULT;\n\t}\n\targs = (const struct btf_param *)(t + 1);\n\tnargs = btf_type_vlen(t);\n\tif (nargs > MAX_BPF_FUNC_REG_ARGS) {\n\t\tbpf_log(log, \"Global function %s() with %d > %d args. Buggy compiler.\\n\",\n\t\t\ttname, nargs, MAX_BPF_FUNC_REG_ARGS);\n\t\treturn -EINVAL;\n\t}\n\t \n\tt = btf_type_by_id(btf, t->type);\n\twhile (btf_type_is_modifier(t))\n\t\tt = btf_type_by_id(btf, t->type);\n\tif (!btf_type_is_int(t) && !btf_is_any_enum(t)) {\n\t\tbpf_log(log,\n\t\t\t\"Global function %s() doesn't return scalar. Only those are supported.\\n\",\n\t\t\ttname);\n\t\treturn -EINVAL;\n\t}\n\t \n\tfor (i = 0; i < nargs; i++) {\n\t\tstruct bpf_reg_state *reg = &regs[i + 1];\n\n\t\tt = btf_type_by_id(btf, args[i].type);\n\t\twhile (btf_type_is_modifier(t))\n\t\t\tt = btf_type_by_id(btf, t->type);\n\t\tif (btf_type_is_int(t) || btf_is_any_enum(t)) {\n\t\t\treg->type = SCALAR_VALUE;\n\t\t\tcontinue;\n\t\t}\n\t\tif (btf_type_is_ptr(t)) {\n\t\t\tif (btf_get_prog_ctx_type(log, btf, t, prog_type, i)) {\n\t\t\t\treg->type = PTR_TO_CTX;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tt = btf_type_skip_modifiers(btf, t->type, NULL);\n\n\t\t\tref_t = btf_resolve_size(btf, t, &reg->mem_size);\n\t\t\tif (IS_ERR(ref_t)) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t    \"arg#%d reference type('%s %s') size cannot be determined: %ld\\n\",\n\t\t\t\t    i, btf_type_str(t), btf_name_by_offset(btf, t->name_off),\n\t\t\t\t\tPTR_ERR(ref_t));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\treg->type = PTR_TO_MEM | PTR_MAYBE_NULL;\n\t\t\treg->id = ++env->id_gen;\n\n\t\t\tcontinue;\n\t\t}\n\t\tbpf_log(log, \"Arg#%d type %s in %s() is not supported yet.\\n\",\n\t\t\ti, btf_type_str(t), tname);\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic void btf_type_show(const struct btf *btf, u32 type_id, void *obj,\n\t\t\t  struct btf_show *show)\n{\n\tconst struct btf_type *t = btf_type_by_id(btf, type_id);\n\n\tshow->btf = btf;\n\tmemset(&show->state, 0, sizeof(show->state));\n\tmemset(&show->obj, 0, sizeof(show->obj));\n\n\tbtf_type_ops(t)->show(btf, t, type_id, obj, 0, show);\n}\n\nstatic void btf_seq_show(struct btf_show *show, const char *fmt,\n\t\t\t va_list args)\n{\n\tseq_vprintf((struct seq_file *)show->target, fmt, args);\n}\n\nint btf_type_seq_show_flags(const struct btf *btf, u32 type_id,\n\t\t\t    void *obj, struct seq_file *m, u64 flags)\n{\n\tstruct btf_show sseq;\n\n\tsseq.target = m;\n\tsseq.showfn = btf_seq_show;\n\tsseq.flags = flags;\n\n\tbtf_type_show(btf, type_id, obj, &sseq);\n\n\treturn sseq.state.status;\n}\n\nvoid btf_type_seq_show(const struct btf *btf, u32 type_id, void *obj,\n\t\t       struct seq_file *m)\n{\n\t(void) btf_type_seq_show_flags(btf, type_id, obj, m,\n\t\t\t\t       BTF_SHOW_NONAME | BTF_SHOW_COMPACT |\n\t\t\t\t       BTF_SHOW_ZERO | BTF_SHOW_UNSAFE);\n}\n\nstruct btf_show_snprintf {\n\tstruct btf_show show;\n\tint len_left;\t\t \n\tint len;\t\t \n};\n\nstatic void btf_snprintf_show(struct btf_show *show, const char *fmt,\n\t\t\t      va_list args)\n{\n\tstruct btf_show_snprintf *ssnprintf = (struct btf_show_snprintf *)show;\n\tint len;\n\n\tlen = vsnprintf(show->target, ssnprintf->len_left, fmt, args);\n\n\tif (len < 0) {\n\t\tssnprintf->len_left = 0;\n\t\tssnprintf->len = len;\n\t} else if (len >= ssnprintf->len_left) {\n\t\t \n\t\tssnprintf->len_left = 0;\n\t\tssnprintf->len += len;\n\t} else {\n\t\tssnprintf->len_left -= len;\n\t\tssnprintf->len += len;\n\t\tshow->target += len;\n\t}\n}\n\nint btf_type_snprintf_show(const struct btf *btf, u32 type_id, void *obj,\n\t\t\t   char *buf, int len, u64 flags)\n{\n\tstruct btf_show_snprintf ssnprintf;\n\n\tssnprintf.show.target = buf;\n\tssnprintf.show.flags = flags;\n\tssnprintf.show.showfn = btf_snprintf_show;\n\tssnprintf.len_left = len;\n\tssnprintf.len = 0;\n\n\tbtf_type_show(btf, type_id, obj, (struct btf_show *)&ssnprintf);\n\n\t \n\tif (ssnprintf.show.state.status)\n\t\treturn ssnprintf.show.state.status;\n\n\t \n\treturn ssnprintf.len;\n}\n\n#ifdef CONFIG_PROC_FS\nstatic void bpf_btf_show_fdinfo(struct seq_file *m, struct file *filp)\n{\n\tconst struct btf *btf = filp->private_data;\n\n\tseq_printf(m, \"btf_id:\\t%u\\n\", btf->id);\n}\n#endif\n\nstatic int btf_release(struct inode *inode, struct file *filp)\n{\n\tbtf_put(filp->private_data);\n\treturn 0;\n}\n\nconst struct file_operations btf_fops = {\n#ifdef CONFIG_PROC_FS\n\t.show_fdinfo\t= bpf_btf_show_fdinfo,\n#endif\n\t.release\t= btf_release,\n};\n\nstatic int __btf_new_fd(struct btf *btf)\n{\n\treturn anon_inode_getfd(\"btf\", &btf_fops, btf, O_RDONLY | O_CLOEXEC);\n}\n\nint btf_new_fd(const union bpf_attr *attr, bpfptr_t uattr, u32 uattr_size)\n{\n\tstruct btf *btf;\n\tint ret;\n\n\tbtf = btf_parse(attr, uattr, uattr_size);\n\tif (IS_ERR(btf))\n\t\treturn PTR_ERR(btf);\n\n\tret = btf_alloc_id(btf);\n\tif (ret) {\n\t\tbtf_free(btf);\n\t\treturn ret;\n\t}\n\n\t \n\n\tret = __btf_new_fd(btf);\n\tif (ret < 0)\n\t\tbtf_put(btf);\n\n\treturn ret;\n}\n\nstruct btf *btf_get_by_fd(int fd)\n{\n\tstruct btf *btf;\n\tstruct fd f;\n\n\tf = fdget(fd);\n\n\tif (!f.file)\n\t\treturn ERR_PTR(-EBADF);\n\n\tif (f.file->f_op != &btf_fops) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tbtf = f.file->private_data;\n\trefcount_inc(&btf->refcnt);\n\tfdput(f);\n\n\treturn btf;\n}\n\nint btf_get_info_by_fd(const struct btf *btf,\n\t\t       const union bpf_attr *attr,\n\t\t       union bpf_attr __user *uattr)\n{\n\tstruct bpf_btf_info __user *uinfo;\n\tstruct bpf_btf_info info;\n\tu32 info_copy, btf_copy;\n\tvoid __user *ubtf;\n\tchar __user *uname;\n\tu32 uinfo_len, uname_len, name_len;\n\tint ret = 0;\n\n\tuinfo = u64_to_user_ptr(attr->info.info);\n\tuinfo_len = attr->info.info_len;\n\n\tinfo_copy = min_t(u32, uinfo_len, sizeof(info));\n\tmemset(&info, 0, sizeof(info));\n\tif (copy_from_user(&info, uinfo, info_copy))\n\t\treturn -EFAULT;\n\n\tinfo.id = btf->id;\n\tubtf = u64_to_user_ptr(info.btf);\n\tbtf_copy = min_t(u32, btf->data_size, info.btf_size);\n\tif (copy_to_user(ubtf, btf->data, btf_copy))\n\t\treturn -EFAULT;\n\tinfo.btf_size = btf->data_size;\n\n\tinfo.kernel_btf = btf->kernel_btf;\n\n\tuname = u64_to_user_ptr(info.name);\n\tuname_len = info.name_len;\n\tif (!uname ^ !uname_len)\n\t\treturn -EINVAL;\n\n\tname_len = strlen(btf->name);\n\tinfo.name_len = name_len;\n\n\tif (uname) {\n\t\tif (uname_len >= name_len + 1) {\n\t\t\tif (copy_to_user(uname, btf->name, name_len + 1))\n\t\t\t\treturn -EFAULT;\n\t\t} else {\n\t\t\tchar zero = '\\0';\n\n\t\t\tif (copy_to_user(uname, btf->name, uname_len - 1))\n\t\t\t\treturn -EFAULT;\n\t\t\tif (put_user(zero, uname + uname_len - 1))\n\t\t\t\treturn -EFAULT;\n\t\t\t \n\t\t\tret = -ENOSPC;\n\t\t}\n\t}\n\n\tif (copy_to_user(uinfo, &info, info_copy) ||\n\t    put_user(info_copy, &uattr->info.info_len))\n\t\treturn -EFAULT;\n\n\treturn ret;\n}\n\nint btf_get_fd_by_id(u32 id)\n{\n\tstruct btf *btf;\n\tint fd;\n\n\trcu_read_lock();\n\tbtf = idr_find(&btf_idr, id);\n\tif (!btf || !refcount_inc_not_zero(&btf->refcnt))\n\t\tbtf = ERR_PTR(-ENOENT);\n\trcu_read_unlock();\n\n\tif (IS_ERR(btf))\n\t\treturn PTR_ERR(btf);\n\n\tfd = __btf_new_fd(btf);\n\tif (fd < 0)\n\t\tbtf_put(btf);\n\n\treturn fd;\n}\n\nu32 btf_obj_id(const struct btf *btf)\n{\n\treturn btf->id;\n}\n\nbool btf_is_kernel(const struct btf *btf)\n{\n\treturn btf->kernel_btf;\n}\n\nbool btf_is_module(const struct btf *btf)\n{\n\treturn btf->kernel_btf && strcmp(btf->name, \"vmlinux\") != 0;\n}\n\nenum {\n\tBTF_MODULE_F_LIVE = (1 << 0),\n};\n\n#ifdef CONFIG_DEBUG_INFO_BTF_MODULES\nstruct btf_module {\n\tstruct list_head list;\n\tstruct module *module;\n\tstruct btf *btf;\n\tstruct bin_attribute *sysfs_attr;\n\tint flags;\n};\n\nstatic LIST_HEAD(btf_modules);\nstatic DEFINE_MUTEX(btf_module_mutex);\n\nstatic ssize_t\nbtf_module_read(struct file *file, struct kobject *kobj,\n\t\tstruct bin_attribute *bin_attr,\n\t\tchar *buf, loff_t off, size_t len)\n{\n\tconst struct btf *btf = bin_attr->private;\n\n\tmemcpy(buf, btf->data + off, len);\n\treturn len;\n}\n\nstatic void purge_cand_cache(struct btf *btf);\n\nstatic int btf_module_notify(struct notifier_block *nb, unsigned long op,\n\t\t\t     void *module)\n{\n\tstruct btf_module *btf_mod, *tmp;\n\tstruct module *mod = module;\n\tstruct btf *btf;\n\tint err = 0;\n\n\tif (mod->btf_data_size == 0 ||\n\t    (op != MODULE_STATE_COMING && op != MODULE_STATE_LIVE &&\n\t     op != MODULE_STATE_GOING))\n\t\tgoto out;\n\n\tswitch (op) {\n\tcase MODULE_STATE_COMING:\n\t\tbtf_mod = kzalloc(sizeof(*btf_mod), GFP_KERNEL);\n\t\tif (!btf_mod) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tbtf = btf_parse_module(mod->name, mod->btf_data, mod->btf_data_size);\n\t\tif (IS_ERR(btf)) {\n\t\t\tkfree(btf_mod);\n\t\t\tif (!IS_ENABLED(CONFIG_MODULE_ALLOW_BTF_MISMATCH)) {\n\t\t\t\tpr_warn(\"failed to validate module [%s] BTF: %ld\\n\",\n\t\t\t\t\tmod->name, PTR_ERR(btf));\n\t\t\t\terr = PTR_ERR(btf);\n\t\t\t} else {\n\t\t\t\tpr_warn_once(\"Kernel module BTF mismatch detected, BTF debug info may be unavailable for some modules\\n\");\n\t\t\t}\n\t\t\tgoto out;\n\t\t}\n\t\terr = btf_alloc_id(btf);\n\t\tif (err) {\n\t\t\tbtf_free(btf);\n\t\t\tkfree(btf_mod);\n\t\t\tgoto out;\n\t\t}\n\n\t\tpurge_cand_cache(NULL);\n\t\tmutex_lock(&btf_module_mutex);\n\t\tbtf_mod->module = module;\n\t\tbtf_mod->btf = btf;\n\t\tlist_add(&btf_mod->list, &btf_modules);\n\t\tmutex_unlock(&btf_module_mutex);\n\n\t\tif (IS_ENABLED(CONFIG_SYSFS)) {\n\t\t\tstruct bin_attribute *attr;\n\n\t\t\tattr = kzalloc(sizeof(*attr), GFP_KERNEL);\n\t\t\tif (!attr)\n\t\t\t\tgoto out;\n\n\t\t\tsysfs_bin_attr_init(attr);\n\t\t\tattr->attr.name = btf->name;\n\t\t\tattr->attr.mode = 0444;\n\t\t\tattr->size = btf->data_size;\n\t\t\tattr->private = btf;\n\t\t\tattr->read = btf_module_read;\n\n\t\t\terr = sysfs_create_bin_file(btf_kobj, attr);\n\t\t\tif (err) {\n\t\t\t\tpr_warn(\"failed to register module [%s] BTF in sysfs: %d\\n\",\n\t\t\t\t\tmod->name, err);\n\t\t\t\tkfree(attr);\n\t\t\t\terr = 0;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tbtf_mod->sysfs_attr = attr;\n\t\t}\n\n\t\tbreak;\n\tcase MODULE_STATE_LIVE:\n\t\tmutex_lock(&btf_module_mutex);\n\t\tlist_for_each_entry_safe(btf_mod, tmp, &btf_modules, list) {\n\t\t\tif (btf_mod->module != module)\n\t\t\t\tcontinue;\n\n\t\t\tbtf_mod->flags |= BTF_MODULE_F_LIVE;\n\t\t\tbreak;\n\t\t}\n\t\tmutex_unlock(&btf_module_mutex);\n\t\tbreak;\n\tcase MODULE_STATE_GOING:\n\t\tmutex_lock(&btf_module_mutex);\n\t\tlist_for_each_entry_safe(btf_mod, tmp, &btf_modules, list) {\n\t\t\tif (btf_mod->module != module)\n\t\t\t\tcontinue;\n\n\t\t\tlist_del(&btf_mod->list);\n\t\t\tif (btf_mod->sysfs_attr)\n\t\t\t\tsysfs_remove_bin_file(btf_kobj, btf_mod->sysfs_attr);\n\t\t\tpurge_cand_cache(btf_mod->btf);\n\t\t\tbtf_put(btf_mod->btf);\n\t\t\tkfree(btf_mod->sysfs_attr);\n\t\t\tkfree(btf_mod);\n\t\t\tbreak;\n\t\t}\n\t\tmutex_unlock(&btf_module_mutex);\n\t\tbreak;\n\t}\nout:\n\treturn notifier_from_errno(err);\n}\n\nstatic struct notifier_block btf_module_nb = {\n\t.notifier_call = btf_module_notify,\n};\n\nstatic int __init btf_module_init(void)\n{\n\tregister_module_notifier(&btf_module_nb);\n\treturn 0;\n}\n\nfs_initcall(btf_module_init);\n#endif  \n\nstruct module *btf_try_get_module(const struct btf *btf)\n{\n\tstruct module *res = NULL;\n#ifdef CONFIG_DEBUG_INFO_BTF_MODULES\n\tstruct btf_module *btf_mod, *tmp;\n\n\tmutex_lock(&btf_module_mutex);\n\tlist_for_each_entry_safe(btf_mod, tmp, &btf_modules, list) {\n\t\tif (btf_mod->btf != btf)\n\t\t\tcontinue;\n\n\t\t \n\t\tif ((btf_mod->flags & BTF_MODULE_F_LIVE) && try_module_get(btf_mod->module))\n\t\t\tres = btf_mod->module;\n\n\t\tbreak;\n\t}\n\tmutex_unlock(&btf_module_mutex);\n#endif\n\n\treturn res;\n}\n\n \nstatic struct btf *btf_get_module_btf(const struct module *module)\n{\n#ifdef CONFIG_DEBUG_INFO_BTF_MODULES\n\tstruct btf_module *btf_mod, *tmp;\n#endif\n\tstruct btf *btf = NULL;\n\n\tif (!module) {\n\t\tbtf = bpf_get_btf_vmlinux();\n\t\tif (!IS_ERR_OR_NULL(btf))\n\t\t\tbtf_get(btf);\n\t\treturn btf;\n\t}\n\n#ifdef CONFIG_DEBUG_INFO_BTF_MODULES\n\tmutex_lock(&btf_module_mutex);\n\tlist_for_each_entry_safe(btf_mod, tmp, &btf_modules, list) {\n\t\tif (btf_mod->module != module)\n\t\t\tcontinue;\n\n\t\tbtf_get(btf_mod->btf);\n\t\tbtf = btf_mod->btf;\n\t\tbreak;\n\t}\n\tmutex_unlock(&btf_module_mutex);\n#endif\n\n\treturn btf;\n}\n\nBPF_CALL_4(bpf_btf_find_by_name_kind, char *, name, int, name_sz, u32, kind, int, flags)\n{\n\tstruct btf *btf = NULL;\n\tint btf_obj_fd = 0;\n\tlong ret;\n\n\tif (flags)\n\t\treturn -EINVAL;\n\n\tif (name_sz <= 1 || name[name_sz - 1])\n\t\treturn -EINVAL;\n\n\tret = bpf_find_btf_id(name, kind, &btf);\n\tif (ret > 0 && btf_is_module(btf)) {\n\t\tbtf_obj_fd = __btf_new_fd(btf);\n\t\tif (btf_obj_fd < 0) {\n\t\t\tbtf_put(btf);\n\t\t\treturn btf_obj_fd;\n\t\t}\n\t\treturn ret | (((u64)btf_obj_fd) << 32);\n\t}\n\tif (ret > 0)\n\t\tbtf_put(btf);\n\treturn ret;\n}\n\nconst struct bpf_func_proto bpf_btf_find_by_name_kind_proto = {\n\t.func\t\t= bpf_btf_find_by_name_kind,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_ANYTHING,\n};\n\nBTF_ID_LIST_GLOBAL(btf_tracing_ids, MAX_BTF_TRACING_TYPE)\n#define BTF_TRACING_TYPE(name, type) BTF_ID(struct, type)\nBTF_TRACING_TYPE_xxx\n#undef BTF_TRACING_TYPE\n\nstatic int btf_check_iter_kfuncs(struct btf *btf, const char *func_name,\n\t\t\t\t const struct btf_type *func, u32 func_flags)\n{\n\tu32 flags = func_flags & (KF_ITER_NEW | KF_ITER_NEXT | KF_ITER_DESTROY);\n\tconst char *name, *sfx, *iter_name;\n\tconst struct btf_param *arg;\n\tconst struct btf_type *t;\n\tchar exp_name[128];\n\tu32 nr_args;\n\n\t \n\tif (!flags || (flags & (flags - 1)))\n\t\treturn -EINVAL;\n\n\t \n\tnr_args = btf_type_vlen(func);\n\tif (nr_args < 1)\n\t\treturn -EINVAL;\n\n\targ = &btf_params(func)[0];\n\tt = btf_type_skip_modifiers(btf, arg->type, NULL);\n\tif (!t || !btf_type_is_ptr(t))\n\t\treturn -EINVAL;\n\tt = btf_type_skip_modifiers(btf, t->type, NULL);\n\tif (!t || !__btf_type_is_struct(t))\n\t\treturn -EINVAL;\n\n\tname = btf_name_by_offset(btf, t->name_off);\n\tif (!name || strncmp(name, ITER_PREFIX, sizeof(ITER_PREFIX) - 1))\n\t\treturn -EINVAL;\n\n\t \n\tif (t->size == 0 || (t->size % 8))\n\t\treturn -EINVAL;\n\n\t \n\titer_name = name + sizeof(ITER_PREFIX) - 1;\n\tif (flags & KF_ITER_NEW)\n\t\tsfx = \"new\";\n\telse if (flags & KF_ITER_NEXT)\n\t\tsfx = \"next\";\n\telse  \n\t\tsfx = \"destroy\";\n\n\tsnprintf(exp_name, sizeof(exp_name), \"bpf_iter_%s_%s\", iter_name, sfx);\n\tif (strcmp(func_name, exp_name))\n\t\treturn -EINVAL;\n\n\t \n\tif (!(flags & KF_ITER_NEW) && nr_args != 1)\n\t\treturn -EINVAL;\n\n\tif (flags & KF_ITER_NEXT) {\n\t\t \n\t\tt = btf_type_skip_modifiers(btf, func->type, NULL);\n\t\tif (!t || !btf_type_is_ptr(t))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (flags & KF_ITER_DESTROY) {\n\t\t \n\t\tt = btf_type_by_id(btf, func->type);\n\t\tif (!t || !btf_type_is_void(t))\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int btf_check_kfunc_protos(struct btf *btf, u32 func_id, u32 func_flags)\n{\n\tconst struct btf_type *func;\n\tconst char *func_name;\n\tint err;\n\n\t \n\tfunc = btf_type_by_id(btf, func_id);\n\tif (!func || !btf_type_is_func(func))\n\t\treturn -EINVAL;\n\n\t \n\tfunc_name = btf_name_by_offset(btf, func->name_off);\n\tif (!func_name || !func_name[0])\n\t\treturn -EINVAL;\n\n\tfunc = btf_type_by_id(btf, func->type);\n\tif (!func || !btf_type_is_func_proto(func))\n\t\treturn -EINVAL;\n\n\tif (func_flags & (KF_ITER_NEW | KF_ITER_NEXT | KF_ITER_DESTROY)) {\n\t\terr = btf_check_iter_kfuncs(btf, func_name, func, func_flags);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\n \n\nstatic int btf_populate_kfunc_set(struct btf *btf, enum btf_kfunc_hook hook,\n\t\t\t\t  const struct btf_kfunc_id_set *kset)\n{\n\tstruct btf_kfunc_hook_filter *hook_filter;\n\tstruct btf_id_set8 *add_set = kset->set;\n\tbool vmlinux_set = !btf_is_module(btf);\n\tbool add_filter = !!kset->filter;\n\tstruct btf_kfunc_set_tab *tab;\n\tstruct btf_id_set8 *set;\n\tu32 set_cnt;\n\tint ret;\n\n\tif (hook >= BTF_KFUNC_HOOK_MAX) {\n\t\tret = -EINVAL;\n\t\tgoto end;\n\t}\n\n\tif (!add_set->cnt)\n\t\treturn 0;\n\n\ttab = btf->kfunc_set_tab;\n\n\tif (tab && add_filter) {\n\t\tu32 i;\n\n\t\thook_filter = &tab->hook_filters[hook];\n\t\tfor (i = 0; i < hook_filter->nr_filters; i++) {\n\t\t\tif (hook_filter->filters[i] == kset->filter) {\n\t\t\t\tadd_filter = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (add_filter && hook_filter->nr_filters == BTF_KFUNC_FILTER_MAX_CNT) {\n\t\t\tret = -E2BIG;\n\t\t\tgoto end;\n\t\t}\n\t}\n\n\tif (!tab) {\n\t\ttab = kzalloc(sizeof(*tab), GFP_KERNEL | __GFP_NOWARN);\n\t\tif (!tab)\n\t\t\treturn -ENOMEM;\n\t\tbtf->kfunc_set_tab = tab;\n\t}\n\n\tset = tab->sets[hook];\n\t \n\tif (WARN_ON_ONCE(set && !vmlinux_set)) {\n\t\tret = -EINVAL;\n\t\tgoto end;\n\t}\n\n\t \n\tif (!vmlinux_set) {\n\t\ttab->sets[hook] = add_set;\n\t\tgoto do_add_filter;\n\t}\n\n\t \n\tset_cnt = set ? set->cnt : 0;\n\n\tif (set_cnt > U32_MAX - add_set->cnt) {\n\t\tret = -EOVERFLOW;\n\t\tgoto end;\n\t}\n\n\tif (set_cnt + add_set->cnt > BTF_KFUNC_SET_MAX_CNT) {\n\t\tret = -E2BIG;\n\t\tgoto end;\n\t}\n\n\t \n\tset = krealloc(tab->sets[hook],\n\t\t       offsetof(struct btf_id_set8, pairs[set_cnt + add_set->cnt]),\n\t\t       GFP_KERNEL | __GFP_NOWARN);\n\tif (!set) {\n\t\tret = -ENOMEM;\n\t\tgoto end;\n\t}\n\n\t \n\tif (!tab->sets[hook])\n\t\tset->cnt = 0;\n\ttab->sets[hook] = set;\n\n\t \n\tmemcpy(set->pairs + set->cnt, add_set->pairs, add_set->cnt * sizeof(set->pairs[0]));\n\tset->cnt += add_set->cnt;\n\n\tsort(set->pairs, set->cnt, sizeof(set->pairs[0]), btf_id_cmp_func, NULL);\n\ndo_add_filter:\n\tif (add_filter) {\n\t\thook_filter = &tab->hook_filters[hook];\n\t\thook_filter->filters[hook_filter->nr_filters++] = kset->filter;\n\t}\n\treturn 0;\nend:\n\tbtf_free_kfunc_set_tab(btf);\n\treturn ret;\n}\n\nstatic u32 *__btf_kfunc_id_set_contains(const struct btf *btf,\n\t\t\t\t\tenum btf_kfunc_hook hook,\n\t\t\t\t\tu32 kfunc_btf_id,\n\t\t\t\t\tconst struct bpf_prog *prog)\n{\n\tstruct btf_kfunc_hook_filter *hook_filter;\n\tstruct btf_id_set8 *set;\n\tu32 *id, i;\n\n\tif (hook >= BTF_KFUNC_HOOK_MAX)\n\t\treturn NULL;\n\tif (!btf->kfunc_set_tab)\n\t\treturn NULL;\n\thook_filter = &btf->kfunc_set_tab->hook_filters[hook];\n\tfor (i = 0; i < hook_filter->nr_filters; i++) {\n\t\tif (hook_filter->filters[i](prog, kfunc_btf_id))\n\t\t\treturn NULL;\n\t}\n\tset = btf->kfunc_set_tab->sets[hook];\n\tif (!set)\n\t\treturn NULL;\n\tid = btf_id_set8_contains(set, kfunc_btf_id);\n\tif (!id)\n\t\treturn NULL;\n\t \n\treturn id + 1;\n}\n\nstatic int bpf_prog_type_to_kfunc_hook(enum bpf_prog_type prog_type)\n{\n\tswitch (prog_type) {\n\tcase BPF_PROG_TYPE_UNSPEC:\n\t\treturn BTF_KFUNC_HOOK_COMMON;\n\tcase BPF_PROG_TYPE_XDP:\n\t\treturn BTF_KFUNC_HOOK_XDP;\n\tcase BPF_PROG_TYPE_SCHED_CLS:\n\t\treturn BTF_KFUNC_HOOK_TC;\n\tcase BPF_PROG_TYPE_STRUCT_OPS:\n\t\treturn BTF_KFUNC_HOOK_STRUCT_OPS;\n\tcase BPF_PROG_TYPE_TRACING:\n\tcase BPF_PROG_TYPE_LSM:\n\t\treturn BTF_KFUNC_HOOK_TRACING;\n\tcase BPF_PROG_TYPE_SYSCALL:\n\t\treturn BTF_KFUNC_HOOK_SYSCALL;\n\tcase BPF_PROG_TYPE_CGROUP_SKB:\n\t\treturn BTF_KFUNC_HOOK_CGROUP_SKB;\n\tcase BPF_PROG_TYPE_SCHED_ACT:\n\t\treturn BTF_KFUNC_HOOK_SCHED_ACT;\n\tcase BPF_PROG_TYPE_SK_SKB:\n\t\treturn BTF_KFUNC_HOOK_SK_SKB;\n\tcase BPF_PROG_TYPE_SOCKET_FILTER:\n\t\treturn BTF_KFUNC_HOOK_SOCKET_FILTER;\n\tcase BPF_PROG_TYPE_LWT_OUT:\n\tcase BPF_PROG_TYPE_LWT_IN:\n\tcase BPF_PROG_TYPE_LWT_XMIT:\n\tcase BPF_PROG_TYPE_LWT_SEG6LOCAL:\n\t\treturn BTF_KFUNC_HOOK_LWT;\n\tcase BPF_PROG_TYPE_NETFILTER:\n\t\treturn BTF_KFUNC_HOOK_NETFILTER;\n\tdefault:\n\t\treturn BTF_KFUNC_HOOK_MAX;\n\t}\n}\n\n \nu32 *btf_kfunc_id_set_contains(const struct btf *btf,\n\t\t\t       u32 kfunc_btf_id,\n\t\t\t       const struct bpf_prog *prog)\n{\n\tenum bpf_prog_type prog_type = resolve_prog_type(prog);\n\tenum btf_kfunc_hook hook;\n\tu32 *kfunc_flags;\n\n\tkfunc_flags = __btf_kfunc_id_set_contains(btf, BTF_KFUNC_HOOK_COMMON, kfunc_btf_id, prog);\n\tif (kfunc_flags)\n\t\treturn kfunc_flags;\n\n\thook = bpf_prog_type_to_kfunc_hook(prog_type);\n\treturn __btf_kfunc_id_set_contains(btf, hook, kfunc_btf_id, prog);\n}\n\nu32 *btf_kfunc_is_modify_return(const struct btf *btf, u32 kfunc_btf_id,\n\t\t\t\tconst struct bpf_prog *prog)\n{\n\treturn __btf_kfunc_id_set_contains(btf, BTF_KFUNC_HOOK_FMODRET, kfunc_btf_id, prog);\n}\n\nstatic int __register_btf_kfunc_id_set(enum btf_kfunc_hook hook,\n\t\t\t\t       const struct btf_kfunc_id_set *kset)\n{\n\tstruct btf *btf;\n\tint ret, i;\n\n\tbtf = btf_get_module_btf(kset->owner);\n\tif (!btf) {\n\t\tif (!kset->owner && IS_ENABLED(CONFIG_DEBUG_INFO_BTF)) {\n\t\t\tpr_err(\"missing vmlinux BTF, cannot register kfuncs\\n\");\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tif (kset->owner && IS_ENABLED(CONFIG_DEBUG_INFO_BTF_MODULES))\n\t\t\tpr_warn(\"missing module BTF, cannot register kfuncs\\n\");\n\t\treturn 0;\n\t}\n\tif (IS_ERR(btf))\n\t\treturn PTR_ERR(btf);\n\n\tfor (i = 0; i < kset->set->cnt; i++) {\n\t\tret = btf_check_kfunc_protos(btf, kset->set->pairs[i].id,\n\t\t\t\t\t     kset->set->pairs[i].flags);\n\t\tif (ret)\n\t\t\tgoto err_out;\n\t}\n\n\tret = btf_populate_kfunc_set(btf, hook, kset);\n\nerr_out:\n\tbtf_put(btf);\n\treturn ret;\n}\n\n \nint register_btf_kfunc_id_set(enum bpf_prog_type prog_type,\n\t\t\t      const struct btf_kfunc_id_set *kset)\n{\n\tenum btf_kfunc_hook hook;\n\n\thook = bpf_prog_type_to_kfunc_hook(prog_type);\n\treturn __register_btf_kfunc_id_set(hook, kset);\n}\nEXPORT_SYMBOL_GPL(register_btf_kfunc_id_set);\n\n \nint register_btf_fmodret_id_set(const struct btf_kfunc_id_set *kset)\n{\n\treturn __register_btf_kfunc_id_set(BTF_KFUNC_HOOK_FMODRET, kset);\n}\nEXPORT_SYMBOL_GPL(register_btf_fmodret_id_set);\n\ns32 btf_find_dtor_kfunc(struct btf *btf, u32 btf_id)\n{\n\tstruct btf_id_dtor_kfunc_tab *tab = btf->dtor_kfunc_tab;\n\tstruct btf_id_dtor_kfunc *dtor;\n\n\tif (!tab)\n\t\treturn -ENOENT;\n\t \n\tBUILD_BUG_ON(offsetof(struct btf_id_dtor_kfunc, btf_id) != 0);\n\tdtor = bsearch(&btf_id, tab->dtors, tab->cnt, sizeof(tab->dtors[0]), btf_id_cmp_func);\n\tif (!dtor)\n\t\treturn -ENOENT;\n\treturn dtor->kfunc_btf_id;\n}\n\nstatic int btf_check_dtor_kfuncs(struct btf *btf, const struct btf_id_dtor_kfunc *dtors, u32 cnt)\n{\n\tconst struct btf_type *dtor_func, *dtor_func_proto, *t;\n\tconst struct btf_param *args;\n\ts32 dtor_btf_id;\n\tu32 nr_args, i;\n\n\tfor (i = 0; i < cnt; i++) {\n\t\tdtor_btf_id = dtors[i].kfunc_btf_id;\n\n\t\tdtor_func = btf_type_by_id(btf, dtor_btf_id);\n\t\tif (!dtor_func || !btf_type_is_func(dtor_func))\n\t\t\treturn -EINVAL;\n\n\t\tdtor_func_proto = btf_type_by_id(btf, dtor_func->type);\n\t\tif (!dtor_func_proto || !btf_type_is_func_proto(dtor_func_proto))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tt = btf_type_by_id(btf, dtor_func_proto->type);\n\t\tif (!t || !btf_type_is_void(t))\n\t\t\treturn -EINVAL;\n\n\t\tnr_args = btf_type_vlen(dtor_func_proto);\n\t\tif (nr_args != 1)\n\t\t\treturn -EINVAL;\n\t\targs = btf_params(dtor_func_proto);\n\t\tt = btf_type_by_id(btf, args[0].type);\n\t\t \n\t\tif (!t || !btf_type_is_ptr(t))\n\t\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\n \nint register_btf_id_dtor_kfuncs(const struct btf_id_dtor_kfunc *dtors, u32 add_cnt,\n\t\t\t\tstruct module *owner)\n{\n\tstruct btf_id_dtor_kfunc_tab *tab;\n\tstruct btf *btf;\n\tu32 tab_cnt;\n\tint ret;\n\n\tbtf = btf_get_module_btf(owner);\n\tif (!btf) {\n\t\tif (!owner && IS_ENABLED(CONFIG_DEBUG_INFO_BTF)) {\n\t\t\tpr_err(\"missing vmlinux BTF, cannot register dtor kfuncs\\n\");\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tif (owner && IS_ENABLED(CONFIG_DEBUG_INFO_BTF_MODULES)) {\n\t\t\tpr_err(\"missing module BTF, cannot register dtor kfuncs\\n\");\n\t\t\treturn -ENOENT;\n\t\t}\n\t\treturn 0;\n\t}\n\tif (IS_ERR(btf))\n\t\treturn PTR_ERR(btf);\n\n\tif (add_cnt >= BTF_DTOR_KFUNC_MAX_CNT) {\n\t\tpr_err(\"cannot register more than %d kfunc destructors\\n\", BTF_DTOR_KFUNC_MAX_CNT);\n\t\tret = -E2BIG;\n\t\tgoto end;\n\t}\n\n\t \n\tret = btf_check_dtor_kfuncs(btf, dtors, add_cnt);\n\tif (ret < 0)\n\t\tgoto end;\n\n\ttab = btf->dtor_kfunc_tab;\n\t \n\tif (WARN_ON_ONCE(tab && btf_is_module(btf))) {\n\t\tret = -EINVAL;\n\t\tgoto end;\n\t}\n\n\ttab_cnt = tab ? tab->cnt : 0;\n\tif (tab_cnt > U32_MAX - add_cnt) {\n\t\tret = -EOVERFLOW;\n\t\tgoto end;\n\t}\n\tif (tab_cnt + add_cnt >= BTF_DTOR_KFUNC_MAX_CNT) {\n\t\tpr_err(\"cannot register more than %d kfunc destructors\\n\", BTF_DTOR_KFUNC_MAX_CNT);\n\t\tret = -E2BIG;\n\t\tgoto end;\n\t}\n\n\ttab = krealloc(btf->dtor_kfunc_tab,\n\t\t       offsetof(struct btf_id_dtor_kfunc_tab, dtors[tab_cnt + add_cnt]),\n\t\t       GFP_KERNEL | __GFP_NOWARN);\n\tif (!tab) {\n\t\tret = -ENOMEM;\n\t\tgoto end;\n\t}\n\n\tif (!btf->dtor_kfunc_tab)\n\t\ttab->cnt = 0;\n\tbtf->dtor_kfunc_tab = tab;\n\n\tmemcpy(tab->dtors + tab->cnt, dtors, add_cnt * sizeof(tab->dtors[0]));\n\ttab->cnt += add_cnt;\n\n\tsort(tab->dtors, tab->cnt, sizeof(tab->dtors[0]), btf_id_cmp_func, NULL);\n\nend:\n\tif (ret)\n\t\tbtf_free_dtor_kfunc_tab(btf);\n\tbtf_put(btf);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(register_btf_id_dtor_kfuncs);\n\n#define MAX_TYPES_ARE_COMPAT_DEPTH 2\n\n \nint bpf_core_types_are_compat(const struct btf *local_btf, __u32 local_id,\n\t\t\t      const struct btf *targ_btf, __u32 targ_id)\n{\n\treturn __bpf_core_types_are_compat(local_btf, local_id, targ_btf, targ_id,\n\t\t\t\t\t   MAX_TYPES_ARE_COMPAT_DEPTH);\n}\n\n#define MAX_TYPES_MATCH_DEPTH 2\n\nint bpf_core_types_match(const struct btf *local_btf, u32 local_id,\n\t\t\t const struct btf *targ_btf, u32 targ_id)\n{\n\treturn __bpf_core_types_match(local_btf, local_id, targ_btf, targ_id, false,\n\t\t\t\t      MAX_TYPES_MATCH_DEPTH);\n}\n\nstatic bool bpf_core_is_flavor_sep(const char *s)\n{\n\t \n\treturn s[0] != '_' &&\t\t\t\t       \n\t       s[1] == '_' && s[2] == '_' && s[3] == '_' &&    \n\t       s[4] != '_';\t\t\t\t       \n}\n\nsize_t bpf_core_essential_name_len(const char *name)\n{\n\tsize_t n = strlen(name);\n\tint i;\n\n\tfor (i = n - 5; i >= 0; i--) {\n\t\tif (bpf_core_is_flavor_sep(name + i))\n\t\t\treturn i + 1;\n\t}\n\treturn n;\n}\n\nstruct bpf_cand_cache {\n\tconst char *name;\n\tu32 name_len;\n\tu16 kind;\n\tu16 cnt;\n\tstruct {\n\t\tconst struct btf *btf;\n\t\tu32 id;\n\t} cands[];\n};\n\nstatic void bpf_free_cands(struct bpf_cand_cache *cands)\n{\n\tif (!cands->cnt)\n\t\t \n\t\treturn;\n\tkfree(cands);\n}\n\nstatic void bpf_free_cands_from_cache(struct bpf_cand_cache *cands)\n{\n\tkfree(cands->name);\n\tkfree(cands);\n}\n\n#define VMLINUX_CAND_CACHE_SIZE 31\nstatic struct bpf_cand_cache *vmlinux_cand_cache[VMLINUX_CAND_CACHE_SIZE];\n\n#define MODULE_CAND_CACHE_SIZE 31\nstatic struct bpf_cand_cache *module_cand_cache[MODULE_CAND_CACHE_SIZE];\n\nstatic DEFINE_MUTEX(cand_cache_mutex);\n\nstatic void __print_cand_cache(struct bpf_verifier_log *log,\n\t\t\t       struct bpf_cand_cache **cache,\n\t\t\t       int cache_size)\n{\n\tstruct bpf_cand_cache *cc;\n\tint i, j;\n\n\tfor (i = 0; i < cache_size; i++) {\n\t\tcc = cache[i];\n\t\tif (!cc)\n\t\t\tcontinue;\n\t\tbpf_log(log, \"[%d]%s(\", i, cc->name);\n\t\tfor (j = 0; j < cc->cnt; j++) {\n\t\t\tbpf_log(log, \"%d\", cc->cands[j].id);\n\t\t\tif (j < cc->cnt - 1)\n\t\t\t\tbpf_log(log, \" \");\n\t\t}\n\t\tbpf_log(log, \"), \");\n\t}\n}\n\nstatic void print_cand_cache(struct bpf_verifier_log *log)\n{\n\tmutex_lock(&cand_cache_mutex);\n\tbpf_log(log, \"vmlinux_cand_cache:\");\n\t__print_cand_cache(log, vmlinux_cand_cache, VMLINUX_CAND_CACHE_SIZE);\n\tbpf_log(log, \"\\nmodule_cand_cache:\");\n\t__print_cand_cache(log, module_cand_cache, MODULE_CAND_CACHE_SIZE);\n\tbpf_log(log, \"\\n\");\n\tmutex_unlock(&cand_cache_mutex);\n}\n\nstatic u32 hash_cands(struct bpf_cand_cache *cands)\n{\n\treturn jhash(cands->name, cands->name_len, 0);\n}\n\nstatic struct bpf_cand_cache *check_cand_cache(struct bpf_cand_cache *cands,\n\t\t\t\t\t       struct bpf_cand_cache **cache,\n\t\t\t\t\t       int cache_size)\n{\n\tstruct bpf_cand_cache *cc = cache[hash_cands(cands) % cache_size];\n\n\tif (cc && cc->name_len == cands->name_len &&\n\t    !strncmp(cc->name, cands->name, cands->name_len))\n\t\treturn cc;\n\treturn NULL;\n}\n\nstatic size_t sizeof_cands(int cnt)\n{\n\treturn offsetof(struct bpf_cand_cache, cands[cnt]);\n}\n\nstatic struct bpf_cand_cache *populate_cand_cache(struct bpf_cand_cache *cands,\n\t\t\t\t\t\t  struct bpf_cand_cache **cache,\n\t\t\t\t\t\t  int cache_size)\n{\n\tstruct bpf_cand_cache **cc = &cache[hash_cands(cands) % cache_size], *new_cands;\n\n\tif (*cc) {\n\t\tbpf_free_cands_from_cache(*cc);\n\t\t*cc = NULL;\n\t}\n\tnew_cands = kmemdup(cands, sizeof_cands(cands->cnt), GFP_KERNEL);\n\tif (!new_cands) {\n\t\tbpf_free_cands(cands);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\t \n\tnew_cands->name = kmemdup_nul(cands->name, cands->name_len, GFP_KERNEL);\n\tbpf_free_cands(cands);\n\tif (!new_cands->name) {\n\t\tkfree(new_cands);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\t*cc = new_cands;\n\treturn new_cands;\n}\n\n#ifdef CONFIG_DEBUG_INFO_BTF_MODULES\nstatic void __purge_cand_cache(struct btf *btf, struct bpf_cand_cache **cache,\n\t\t\t       int cache_size)\n{\n\tstruct bpf_cand_cache *cc;\n\tint i, j;\n\n\tfor (i = 0; i < cache_size; i++) {\n\t\tcc = cache[i];\n\t\tif (!cc)\n\t\t\tcontinue;\n\t\tif (!btf) {\n\t\t\t \n\t\t\tbpf_free_cands_from_cache(cc);\n\t\t\tcache[i] = NULL;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tfor (j = 0; j < cc->cnt; j++)\n\t\t\tif (cc->cands[j].btf == btf) {\n\t\t\t\tbpf_free_cands_from_cache(cc);\n\t\t\t\tcache[i] = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n}\n\nstatic void purge_cand_cache(struct btf *btf)\n{\n\tmutex_lock(&cand_cache_mutex);\n\t__purge_cand_cache(btf, module_cand_cache, MODULE_CAND_CACHE_SIZE);\n\tmutex_unlock(&cand_cache_mutex);\n}\n#endif\n\nstatic struct bpf_cand_cache *\nbpf_core_add_cands(struct bpf_cand_cache *cands, const struct btf *targ_btf,\n\t\t   int targ_start_id)\n{\n\tstruct bpf_cand_cache *new_cands;\n\tconst struct btf_type *t;\n\tconst char *targ_name;\n\tsize_t targ_essent_len;\n\tint n, i;\n\n\tn = btf_nr_types(targ_btf);\n\tfor (i = targ_start_id; i < n; i++) {\n\t\tt = btf_type_by_id(targ_btf, i);\n\t\tif (btf_kind(t) != cands->kind)\n\t\t\tcontinue;\n\n\t\ttarg_name = btf_name_by_offset(targ_btf, t->name_off);\n\t\tif (!targ_name)\n\t\t\tcontinue;\n\n\t\t \n\t\tcond_resched();\n\n\t\tif (strncmp(cands->name, targ_name, cands->name_len) != 0)\n\t\t\tcontinue;\n\n\t\ttarg_essent_len = bpf_core_essential_name_len(targ_name);\n\t\tif (targ_essent_len != cands->name_len)\n\t\t\tcontinue;\n\n\t\t \n\t\tnew_cands = kmalloc(sizeof_cands(cands->cnt + 1), GFP_KERNEL);\n\t\tif (!new_cands) {\n\t\t\tbpf_free_cands(cands);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\n\t\tmemcpy(new_cands, cands, sizeof_cands(cands->cnt));\n\t\tbpf_free_cands(cands);\n\t\tcands = new_cands;\n\t\tcands->cands[cands->cnt].btf = targ_btf;\n\t\tcands->cands[cands->cnt].id = i;\n\t\tcands->cnt++;\n\t}\n\treturn cands;\n}\n\nstatic struct bpf_cand_cache *\nbpf_core_find_cands(struct bpf_core_ctx *ctx, u32 local_type_id)\n{\n\tstruct bpf_cand_cache *cands, *cc, local_cand = {};\n\tconst struct btf *local_btf = ctx->btf;\n\tconst struct btf_type *local_type;\n\tconst struct btf *main_btf;\n\tsize_t local_essent_len;\n\tstruct btf *mod_btf;\n\tconst char *name;\n\tint id;\n\n\tmain_btf = bpf_get_btf_vmlinux();\n\tif (IS_ERR(main_btf))\n\t\treturn ERR_CAST(main_btf);\n\tif (!main_btf)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tlocal_type = btf_type_by_id(local_btf, local_type_id);\n\tif (!local_type)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tname = btf_name_by_offset(local_btf, local_type->name_off);\n\tif (str_is_empty(name))\n\t\treturn ERR_PTR(-EINVAL);\n\tlocal_essent_len = bpf_core_essential_name_len(name);\n\n\tcands = &local_cand;\n\tcands->name = name;\n\tcands->kind = btf_kind(local_type);\n\tcands->name_len = local_essent_len;\n\n\tcc = check_cand_cache(cands, vmlinux_cand_cache, VMLINUX_CAND_CACHE_SIZE);\n\t \n\tif (cc) {\n\t\tif (cc->cnt)\n\t\t\treturn cc;\n\t\tgoto check_modules;\n\t}\n\n\t \n\tcands = bpf_core_add_cands(cands, main_btf, 1);\n\tif (IS_ERR(cands))\n\t\treturn ERR_CAST(cands);\n\n\t \n\n\t \n\tcc = populate_cand_cache(cands, vmlinux_cand_cache, VMLINUX_CAND_CACHE_SIZE);\n\tif (IS_ERR(cc))\n\t\treturn ERR_CAST(cc);\n\n\t \n\tif (cc->cnt)\n\t\treturn cc;\n\ncheck_modules:\n\t \n\tcc = check_cand_cache(cands, module_cand_cache, MODULE_CAND_CACHE_SIZE);\n\tif (cc)\n\t\t \n\t\treturn cc;\n\n\t \n\tspin_lock_bh(&btf_idr_lock);\n\tidr_for_each_entry(&btf_idr, mod_btf, id) {\n\t\tif (!btf_is_module(mod_btf))\n\t\t\tcontinue;\n\t\t \n\t\tbtf_get(mod_btf);\n\t\tspin_unlock_bh(&btf_idr_lock);\n\t\tcands = bpf_core_add_cands(cands, mod_btf, btf_nr_types(main_btf));\n\t\tbtf_put(mod_btf);\n\t\tif (IS_ERR(cands))\n\t\t\treturn ERR_CAST(cands);\n\t\tspin_lock_bh(&btf_idr_lock);\n\t}\n\tspin_unlock_bh(&btf_idr_lock);\n\t \n\treturn populate_cand_cache(cands, module_cand_cache, MODULE_CAND_CACHE_SIZE);\n}\n\nint bpf_core_apply(struct bpf_core_ctx *ctx, const struct bpf_core_relo *relo,\n\t\t   int relo_idx, void *insn)\n{\n\tbool need_cands = relo->kind != BPF_CORE_TYPE_ID_LOCAL;\n\tstruct bpf_core_cand_list cands = {};\n\tstruct bpf_core_relo_res targ_res;\n\tstruct bpf_core_spec *specs;\n\tint err;\n\n\t \n\tspecs = kcalloc(3, sizeof(*specs), GFP_KERNEL);\n\tif (!specs)\n\t\treturn -ENOMEM;\n\n\tif (need_cands) {\n\t\tstruct bpf_cand_cache *cc;\n\t\tint i;\n\n\t\tmutex_lock(&cand_cache_mutex);\n\t\tcc = bpf_core_find_cands(ctx, relo->type_id);\n\t\tif (IS_ERR(cc)) {\n\t\t\tbpf_log(ctx->log, \"target candidate search failed for %d\\n\",\n\t\t\t\trelo->type_id);\n\t\t\terr = PTR_ERR(cc);\n\t\t\tgoto out;\n\t\t}\n\t\tif (cc->cnt) {\n\t\t\tcands.cands = kcalloc(cc->cnt, sizeof(*cands.cands), GFP_KERNEL);\n\t\t\tif (!cands.cands) {\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tfor (i = 0; i < cc->cnt; i++) {\n\t\t\tbpf_log(ctx->log,\n\t\t\t\t\"CO-RE relocating %s %s: found target candidate [%d]\\n\",\n\t\t\t\tbtf_kind_str[cc->kind], cc->name, cc->cands[i].id);\n\t\t\tcands.cands[i].btf = cc->cands[i].btf;\n\t\t\tcands.cands[i].id = cc->cands[i].id;\n\t\t}\n\t\tcands.len = cc->cnt;\n\t\t \n\t}\n\n\terr = bpf_core_calc_relo_insn((void *)ctx->log, relo, relo_idx, ctx->btf, &cands, specs,\n\t\t\t\t      &targ_res);\n\tif (err)\n\t\tgoto out;\n\n\terr = bpf_core_patch_insn((void *)ctx->log, insn, relo->insn_off / 8, relo, relo_idx,\n\t\t\t\t  &targ_res);\n\nout:\n\tkfree(specs);\n\tif (need_cands) {\n\t\tkfree(cands.cands);\n\t\tmutex_unlock(&cand_cache_mutex);\n\t\tif (ctx->log->level & BPF_LOG_LEVEL2)\n\t\t\tprint_cand_cache(ctx->log);\n\t}\n\treturn err;\n}\n\nbool btf_nested_type_is_trusted(struct bpf_verifier_log *log,\n\t\t\t\tconst struct bpf_reg_state *reg,\n\t\t\t\tconst char *field_name, u32 btf_id, const char *suffix)\n{\n\tstruct btf *btf = reg->btf;\n\tconst struct btf_type *walk_type, *safe_type;\n\tconst char *tname;\n\tchar safe_tname[64];\n\tlong ret, safe_id;\n\tconst struct btf_member *member;\n\tu32 i;\n\n\twalk_type = btf_type_by_id(btf, reg->btf_id);\n\tif (!walk_type)\n\t\treturn false;\n\n\ttname = btf_name_by_offset(btf, walk_type->name_off);\n\n\tret = snprintf(safe_tname, sizeof(safe_tname), \"%s%s\", tname, suffix);\n\tif (ret >= sizeof(safe_tname))\n\t\treturn false;\n\n\tsafe_id = btf_find_by_name_kind(btf, safe_tname, BTF_INFO_KIND(walk_type->info));\n\tif (safe_id < 0)\n\t\treturn false;\n\n\tsafe_type = btf_type_by_id(btf, safe_id);\n\tif (!safe_type)\n\t\treturn false;\n\n\tfor_each_member(i, safe_type, member) {\n\t\tconst char *m_name = __btf_name_by_offset(btf, member->name_off);\n\t\tconst struct btf_type *mtype = btf_type_by_id(btf, member->type);\n\t\tu32 id;\n\n\t\tif (!btf_type_is_ptr(mtype))\n\t\t\tcontinue;\n\n\t\tbtf_type_skip_modifiers(btf, mtype->type, &id);\n\t\t \n\t\tif (btf_id == id && !strcmp(field_name, m_name))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nbool btf_type_ids_nocast_alias(struct bpf_verifier_log *log,\n\t\t\t       const struct btf *reg_btf, u32 reg_id,\n\t\t\t       const struct btf *arg_btf, u32 arg_id)\n{\n\tconst char *reg_name, *arg_name, *search_needle;\n\tconst struct btf_type *reg_type, *arg_type;\n\tint reg_len, arg_len, cmp_len;\n\tsize_t pattern_len = sizeof(NOCAST_ALIAS_SUFFIX) - sizeof(char);\n\n\treg_type = btf_type_by_id(reg_btf, reg_id);\n\tif (!reg_type)\n\t\treturn false;\n\n\targ_type = btf_type_by_id(arg_btf, arg_id);\n\tif (!arg_type)\n\t\treturn false;\n\n\treg_name = btf_name_by_offset(reg_btf, reg_type->name_off);\n\targ_name = btf_name_by_offset(arg_btf, arg_type->name_off);\n\n\treg_len = strlen(reg_name);\n\targ_len = strlen(arg_name);\n\n\t \n\tif (reg_len == arg_len)\n\t\treturn false;\n\n\t \n\tif ((reg_len != arg_len + pattern_len) &&\n\t    (arg_len != reg_len + pattern_len))\n\t\treturn false;\n\n\tif (reg_len < arg_len) {\n\t\tsearch_needle = strstr(arg_name, NOCAST_ALIAS_SUFFIX);\n\t\tcmp_len = reg_len;\n\t} else {\n\t\tsearch_needle = strstr(reg_name, NOCAST_ALIAS_SUFFIX);\n\t\tcmp_len = arg_len;\n\t}\n\n\tif (!search_needle)\n\t\treturn false;\n\n\t \n\tif (*(search_needle + pattern_len) != '\\0')\n\t\treturn false;\n\n\treturn !strncmp(reg_name, arg_name, cmp_len);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}