{
  "module_name": "inode.c",
  "hash_id": "4c9a844800fcf9b4f83ee4acefb089b46f5179ec926a214ff3ca4f7b1a59a08a",
  "original_prompt": "Ingested from linux-6.6.14/kernel/bpf/inode.c",
  "human_readable_source": "\n \n\n#include <linux/init.h>\n#include <linux/magic.h>\n#include <linux/major.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/fs.h>\n#include <linux/fs_context.h>\n#include <linux/fs_parser.h>\n#include <linux/kdev_t.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bpf_trace.h>\n#include \"preload/bpf_preload.h\"\n\nenum bpf_type {\n\tBPF_TYPE_UNSPEC\t= 0,\n\tBPF_TYPE_PROG,\n\tBPF_TYPE_MAP,\n\tBPF_TYPE_LINK,\n};\n\nstatic void *bpf_any_get(void *raw, enum bpf_type type)\n{\n\tswitch (type) {\n\tcase BPF_TYPE_PROG:\n\t\tbpf_prog_inc(raw);\n\t\tbreak;\n\tcase BPF_TYPE_MAP:\n\t\tbpf_map_inc_with_uref(raw);\n\t\tbreak;\n\tcase BPF_TYPE_LINK:\n\t\tbpf_link_inc(raw);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\tbreak;\n\t}\n\n\treturn raw;\n}\n\nstatic void bpf_any_put(void *raw, enum bpf_type type)\n{\n\tswitch (type) {\n\tcase BPF_TYPE_PROG:\n\t\tbpf_prog_put(raw);\n\t\tbreak;\n\tcase BPF_TYPE_MAP:\n\t\tbpf_map_put_with_uref(raw);\n\t\tbreak;\n\tcase BPF_TYPE_LINK:\n\t\tbpf_link_put(raw);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\tbreak;\n\t}\n}\n\nstatic void *bpf_fd_probe_obj(u32 ufd, enum bpf_type *type)\n{\n\tvoid *raw;\n\n\traw = bpf_map_get_with_uref(ufd);\n\tif (!IS_ERR(raw)) {\n\t\t*type = BPF_TYPE_MAP;\n\t\treturn raw;\n\t}\n\n\traw = bpf_prog_get(ufd);\n\tif (!IS_ERR(raw)) {\n\t\t*type = BPF_TYPE_PROG;\n\t\treturn raw;\n\t}\n\n\traw = bpf_link_get_from_fd(ufd);\n\tif (!IS_ERR(raw)) {\n\t\t*type = BPF_TYPE_LINK;\n\t\treturn raw;\n\t}\n\n\treturn ERR_PTR(-EINVAL);\n}\n\nstatic const struct inode_operations bpf_dir_iops;\n\nstatic const struct inode_operations bpf_prog_iops = { };\nstatic const struct inode_operations bpf_map_iops  = { };\nstatic const struct inode_operations bpf_link_iops  = { };\n\nstatic struct inode *bpf_get_inode(struct super_block *sb,\n\t\t\t\t   const struct inode *dir,\n\t\t\t\t   umode_t mode)\n{\n\tstruct inode *inode;\n\n\tswitch (mode & S_IFMT) {\n\tcase S_IFDIR:\n\tcase S_IFREG:\n\tcase S_IFLNK:\n\t\tbreak;\n\tdefault:\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tinode = new_inode(sb);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOSPC);\n\n\tinode->i_ino = get_next_ino();\n\tinode->i_atime = inode_set_ctime_current(inode);\n\tinode->i_mtime = inode->i_atime;\n\n\tinode_init_owner(&nop_mnt_idmap, inode, dir, mode);\n\n\treturn inode;\n}\n\nstatic int bpf_inode_type(const struct inode *inode, enum bpf_type *type)\n{\n\t*type = BPF_TYPE_UNSPEC;\n\tif (inode->i_op == &bpf_prog_iops)\n\t\t*type = BPF_TYPE_PROG;\n\telse if (inode->i_op == &bpf_map_iops)\n\t\t*type = BPF_TYPE_MAP;\n\telse if (inode->i_op == &bpf_link_iops)\n\t\t*type = BPF_TYPE_LINK;\n\telse\n\t\treturn -EACCES;\n\n\treturn 0;\n}\n\nstatic void bpf_dentry_finalize(struct dentry *dentry, struct inode *inode,\n\t\t\t\tstruct inode *dir)\n{\n\td_instantiate(dentry, inode);\n\tdget(dentry);\n\n\tdir->i_mtime = inode_set_ctime_current(dir);\n}\n\nstatic int bpf_mkdir(struct mnt_idmap *idmap, struct inode *dir,\n\t\t     struct dentry *dentry, umode_t mode)\n{\n\tstruct inode *inode;\n\n\tinode = bpf_get_inode(dir->i_sb, dir, mode | S_IFDIR);\n\tif (IS_ERR(inode))\n\t\treturn PTR_ERR(inode);\n\n\tinode->i_op = &bpf_dir_iops;\n\tinode->i_fop = &simple_dir_operations;\n\n\tinc_nlink(inode);\n\tinc_nlink(dir);\n\n\tbpf_dentry_finalize(dentry, inode, dir);\n\treturn 0;\n}\n\nstruct map_iter {\n\tvoid *key;\n\tbool done;\n};\n\nstatic struct map_iter *map_iter(struct seq_file *m)\n{\n\treturn m->private;\n}\n\nstatic struct bpf_map *seq_file_to_map(struct seq_file *m)\n{\n\treturn file_inode(m->file)->i_private;\n}\n\nstatic void map_iter_free(struct map_iter *iter)\n{\n\tif (iter) {\n\t\tkfree(iter->key);\n\t\tkfree(iter);\n\t}\n}\n\nstatic struct map_iter *map_iter_alloc(struct bpf_map *map)\n{\n\tstruct map_iter *iter;\n\n\titer = kzalloc(sizeof(*iter), GFP_KERNEL | __GFP_NOWARN);\n\tif (!iter)\n\t\tgoto error;\n\n\titer->key = kzalloc(map->key_size, GFP_KERNEL | __GFP_NOWARN);\n\tif (!iter->key)\n\t\tgoto error;\n\n\treturn iter;\n\nerror:\n\tmap_iter_free(iter);\n\treturn NULL;\n}\n\nstatic void *map_seq_next(struct seq_file *m, void *v, loff_t *pos)\n{\n\tstruct bpf_map *map = seq_file_to_map(m);\n\tvoid *key = map_iter(m)->key;\n\tvoid *prev_key;\n\n\t(*pos)++;\n\tif (map_iter(m)->done)\n\t\treturn NULL;\n\n\tif (unlikely(v == SEQ_START_TOKEN))\n\t\tprev_key = NULL;\n\telse\n\t\tprev_key = key;\n\n\trcu_read_lock();\n\tif (map->ops->map_get_next_key(map, prev_key, key)) {\n\t\tmap_iter(m)->done = true;\n\t\tkey = NULL;\n\t}\n\trcu_read_unlock();\n\treturn key;\n}\n\nstatic void *map_seq_start(struct seq_file *m, loff_t *pos)\n{\n\tif (map_iter(m)->done)\n\t\treturn NULL;\n\n\treturn *pos ? map_iter(m)->key : SEQ_START_TOKEN;\n}\n\nstatic void map_seq_stop(struct seq_file *m, void *v)\n{\n}\n\nstatic int map_seq_show(struct seq_file *m, void *v)\n{\n\tstruct bpf_map *map = seq_file_to_map(m);\n\tvoid *key = map_iter(m)->key;\n\n\tif (unlikely(v == SEQ_START_TOKEN)) {\n\t\tseq_puts(m, \"# WARNING!! The output is for debug purpose only\\n\");\n\t\tseq_puts(m, \"# WARNING!! The output format will change\\n\");\n\t} else {\n\t\tmap->ops->map_seq_show_elem(map, key, m);\n\t}\n\n\treturn 0;\n}\n\nstatic const struct seq_operations bpffs_map_seq_ops = {\n\t.start\t= map_seq_start,\n\t.next\t= map_seq_next,\n\t.show\t= map_seq_show,\n\t.stop\t= map_seq_stop,\n};\n\nstatic int bpffs_map_open(struct inode *inode, struct file *file)\n{\n\tstruct bpf_map *map = inode->i_private;\n\tstruct map_iter *iter;\n\tstruct seq_file *m;\n\tint err;\n\n\titer = map_iter_alloc(map);\n\tif (!iter)\n\t\treturn -ENOMEM;\n\n\terr = seq_open(file, &bpffs_map_seq_ops);\n\tif (err) {\n\t\tmap_iter_free(iter);\n\t\treturn err;\n\t}\n\n\tm = file->private_data;\n\tm->private = iter;\n\n\treturn 0;\n}\n\nstatic int bpffs_map_release(struct inode *inode, struct file *file)\n{\n\tstruct seq_file *m = file->private_data;\n\n\tmap_iter_free(map_iter(m));\n\n\treturn seq_release(inode, file);\n}\n\n \nstatic const struct file_operations bpffs_map_fops = {\n\t.open\t\t= bpffs_map_open,\n\t.read\t\t= seq_read,\n\t.release\t= bpffs_map_release,\n};\n\nstatic int bpffs_obj_open(struct inode *inode, struct file *file)\n{\n\treturn -EIO;\n}\n\nstatic const struct file_operations bpffs_obj_fops = {\n\t.open\t\t= bpffs_obj_open,\n};\n\nstatic int bpf_mkobj_ops(struct dentry *dentry, umode_t mode, void *raw,\n\t\t\t const struct inode_operations *iops,\n\t\t\t const struct file_operations *fops)\n{\n\tstruct inode *dir = dentry->d_parent->d_inode;\n\tstruct inode *inode = bpf_get_inode(dir->i_sb, dir, mode);\n\tif (IS_ERR(inode))\n\t\treturn PTR_ERR(inode);\n\n\tinode->i_op = iops;\n\tinode->i_fop = fops;\n\tinode->i_private = raw;\n\n\tbpf_dentry_finalize(dentry, inode, dir);\n\treturn 0;\n}\n\nstatic int bpf_mkprog(struct dentry *dentry, umode_t mode, void *arg)\n{\n\treturn bpf_mkobj_ops(dentry, mode, arg, &bpf_prog_iops,\n\t\t\t     &bpffs_obj_fops);\n}\n\nstatic int bpf_mkmap(struct dentry *dentry, umode_t mode, void *arg)\n{\n\tstruct bpf_map *map = arg;\n\n\treturn bpf_mkobj_ops(dentry, mode, arg, &bpf_map_iops,\n\t\t\t     bpf_map_support_seq_show(map) ?\n\t\t\t     &bpffs_map_fops : &bpffs_obj_fops);\n}\n\nstatic int bpf_mklink(struct dentry *dentry, umode_t mode, void *arg)\n{\n\tstruct bpf_link *link = arg;\n\n\treturn bpf_mkobj_ops(dentry, mode, arg, &bpf_link_iops,\n\t\t\t     bpf_link_is_iter(link) ?\n\t\t\t     &bpf_iter_fops : &bpffs_obj_fops);\n}\n\nstatic struct dentry *\nbpf_lookup(struct inode *dir, struct dentry *dentry, unsigned flags)\n{\n\t \n\tif ((dir->i_mode & S_IALLUGO) &&\n\t    strchr(dentry->d_name.name, '.'))\n\t\treturn ERR_PTR(-EPERM);\n\n\treturn simple_lookup(dir, dentry, flags);\n}\n\nstatic int bpf_symlink(struct mnt_idmap *idmap, struct inode *dir,\n\t\t       struct dentry *dentry, const char *target)\n{\n\tchar *link = kstrdup(target, GFP_USER | __GFP_NOWARN);\n\tstruct inode *inode;\n\n\tif (!link)\n\t\treturn -ENOMEM;\n\n\tinode = bpf_get_inode(dir->i_sb, dir, S_IRWXUGO | S_IFLNK);\n\tif (IS_ERR(inode)) {\n\t\tkfree(link);\n\t\treturn PTR_ERR(inode);\n\t}\n\n\tinode->i_op = &simple_symlink_inode_operations;\n\tinode->i_link = link;\n\n\tbpf_dentry_finalize(dentry, inode, dir);\n\treturn 0;\n}\n\nstatic const struct inode_operations bpf_dir_iops = {\n\t.lookup\t\t= bpf_lookup,\n\t.mkdir\t\t= bpf_mkdir,\n\t.symlink\t= bpf_symlink,\n\t.rmdir\t\t= simple_rmdir,\n\t.rename\t\t= simple_rename,\n\t.link\t\t= simple_link,\n\t.unlink\t\t= simple_unlink,\n};\n\n \nstatic int bpf_iter_link_pin_kernel(struct dentry *parent,\n\t\t\t\t    const char *name, struct bpf_link *link)\n{\n\tumode_t mode = S_IFREG | S_IRUSR;\n\tstruct dentry *dentry;\n\tint ret;\n\n\tinode_lock(parent->d_inode);\n\tdentry = lookup_one_len(name, parent, strlen(name));\n\tif (IS_ERR(dentry)) {\n\t\tinode_unlock(parent->d_inode);\n\t\treturn PTR_ERR(dentry);\n\t}\n\tret = bpf_mkobj_ops(dentry, mode, link, &bpf_link_iops,\n\t\t\t    &bpf_iter_fops);\n\tdput(dentry);\n\tinode_unlock(parent->d_inode);\n\treturn ret;\n}\n\nstatic int bpf_obj_do_pin(int path_fd, const char __user *pathname, void *raw,\n\t\t\t  enum bpf_type type)\n{\n\tstruct dentry *dentry;\n\tstruct inode *dir;\n\tstruct path path;\n\tumode_t mode;\n\tint ret;\n\n\tdentry = user_path_create(path_fd, pathname, &path, 0);\n\tif (IS_ERR(dentry))\n\t\treturn PTR_ERR(dentry);\n\n\tdir = d_inode(path.dentry);\n\tif (dir->i_op != &bpf_dir_iops) {\n\t\tret = -EPERM;\n\t\tgoto out;\n\t}\n\n\tmode = S_IFREG | ((S_IRUSR | S_IWUSR) & ~current_umask());\n\tret = security_path_mknod(&path, dentry, mode, 0);\n\tif (ret)\n\t\tgoto out;\n\n\tswitch (type) {\n\tcase BPF_TYPE_PROG:\n\t\tret = vfs_mkobj(dentry, mode, bpf_mkprog, raw);\n\t\tbreak;\n\tcase BPF_TYPE_MAP:\n\t\tret = vfs_mkobj(dentry, mode, bpf_mkmap, raw);\n\t\tbreak;\n\tcase BPF_TYPE_LINK:\n\t\tret = vfs_mkobj(dentry, mode, bpf_mklink, raw);\n\t\tbreak;\n\tdefault:\n\t\tret = -EPERM;\n\t}\nout:\n\tdone_path_create(&path, dentry);\n\treturn ret;\n}\n\nint bpf_obj_pin_user(u32 ufd, int path_fd, const char __user *pathname)\n{\n\tenum bpf_type type;\n\tvoid *raw;\n\tint ret;\n\n\traw = bpf_fd_probe_obj(ufd, &type);\n\tif (IS_ERR(raw))\n\t\treturn PTR_ERR(raw);\n\n\tret = bpf_obj_do_pin(path_fd, pathname, raw, type);\n\tif (ret != 0)\n\t\tbpf_any_put(raw, type);\n\n\treturn ret;\n}\n\nstatic void *bpf_obj_do_get(int path_fd, const char __user *pathname,\n\t\t\t    enum bpf_type *type, int flags)\n{\n\tstruct inode *inode;\n\tstruct path path;\n\tvoid *raw;\n\tint ret;\n\n\tret = user_path_at(path_fd, pathname, LOOKUP_FOLLOW, &path);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tinode = d_backing_inode(path.dentry);\n\tret = path_permission(&path, ACC_MODE(flags));\n\tif (ret)\n\t\tgoto out;\n\n\tret = bpf_inode_type(inode, type);\n\tif (ret)\n\t\tgoto out;\n\n\traw = bpf_any_get(inode->i_private, *type);\n\tif (!IS_ERR(raw))\n\t\ttouch_atime(&path);\n\n\tpath_put(&path);\n\treturn raw;\nout:\n\tpath_put(&path);\n\treturn ERR_PTR(ret);\n}\n\nint bpf_obj_get_user(int path_fd, const char __user *pathname, int flags)\n{\n\tenum bpf_type type = BPF_TYPE_UNSPEC;\n\tint f_flags;\n\tvoid *raw;\n\tint ret;\n\n\tf_flags = bpf_get_file_flag(flags);\n\tif (f_flags < 0)\n\t\treturn f_flags;\n\n\traw = bpf_obj_do_get(path_fd, pathname, &type, f_flags);\n\tif (IS_ERR(raw))\n\t\treturn PTR_ERR(raw);\n\n\tif (type == BPF_TYPE_PROG)\n\t\tret = bpf_prog_new_fd(raw);\n\telse if (type == BPF_TYPE_MAP)\n\t\tret = bpf_map_new_fd(raw, f_flags);\n\telse if (type == BPF_TYPE_LINK)\n\t\tret = (f_flags != O_RDWR) ? -EINVAL : bpf_link_new_fd(raw);\n\telse\n\t\treturn -ENOENT;\n\n\tif (ret < 0)\n\t\tbpf_any_put(raw, type);\n\treturn ret;\n}\n\nstatic struct bpf_prog *__get_prog_inode(struct inode *inode, enum bpf_prog_type type)\n{\n\tstruct bpf_prog *prog;\n\tint ret = inode_permission(&nop_mnt_idmap, inode, MAY_READ);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tif (inode->i_op == &bpf_map_iops)\n\t\treturn ERR_PTR(-EINVAL);\n\tif (inode->i_op == &bpf_link_iops)\n\t\treturn ERR_PTR(-EINVAL);\n\tif (inode->i_op != &bpf_prog_iops)\n\t\treturn ERR_PTR(-EACCES);\n\n\tprog = inode->i_private;\n\n\tret = security_bpf_prog(prog);\n\tif (ret < 0)\n\t\treturn ERR_PTR(ret);\n\n\tif (!bpf_prog_get_ok(prog, &type, false))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tbpf_prog_inc(prog);\n\treturn prog;\n}\n\nstruct bpf_prog *bpf_prog_get_type_path(const char *name, enum bpf_prog_type type)\n{\n\tstruct bpf_prog *prog;\n\tstruct path path;\n\tint ret = kern_path(name, LOOKUP_FOLLOW, &path);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tprog = __get_prog_inode(d_backing_inode(path.dentry), type);\n\tif (!IS_ERR(prog))\n\t\ttouch_atime(&path);\n\tpath_put(&path);\n\treturn prog;\n}\nEXPORT_SYMBOL(bpf_prog_get_type_path);\n\n \nstatic int bpf_show_options(struct seq_file *m, struct dentry *root)\n{\n\tumode_t mode = d_inode(root)->i_mode & S_IALLUGO & ~S_ISVTX;\n\n\tif (mode != S_IRWXUGO)\n\t\tseq_printf(m, \",mode=%o\", mode);\n\treturn 0;\n}\n\nstatic void bpf_free_inode(struct inode *inode)\n{\n\tenum bpf_type type;\n\n\tif (S_ISLNK(inode->i_mode))\n\t\tkfree(inode->i_link);\n\tif (!bpf_inode_type(inode, &type))\n\t\tbpf_any_put(inode->i_private, type);\n\tfree_inode_nonrcu(inode);\n}\n\nstatic const struct super_operations bpf_super_ops = {\n\t.statfs\t\t= simple_statfs,\n\t.drop_inode\t= generic_delete_inode,\n\t.show_options\t= bpf_show_options,\n\t.free_inode\t= bpf_free_inode,\n};\n\nenum {\n\tOPT_MODE,\n};\n\nstatic const struct fs_parameter_spec bpf_fs_parameters[] = {\n\tfsparam_u32oct\t(\"mode\",\t\t\tOPT_MODE),\n\t{}\n};\n\nstruct bpf_mount_opts {\n\tumode_t mode;\n};\n\nstatic int bpf_parse_param(struct fs_context *fc, struct fs_parameter *param)\n{\n\tstruct bpf_mount_opts *opts = fc->fs_private;\n\tstruct fs_parse_result result;\n\tint opt;\n\n\topt = fs_parse(fc, bpf_fs_parameters, param, &result);\n\tif (opt < 0) {\n\t\t \n\t\tif (opt == -ENOPARAM) {\n\t\t\topt = vfs_parse_fs_param_source(fc, param);\n\t\t\tif (opt != -ENOPARAM)\n\t\t\t\treturn opt;\n\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (opt < 0)\n\t\t\treturn opt;\n\t}\n\n\tswitch (opt) {\n\tcase OPT_MODE:\n\t\topts->mode = result.uint_32 & S_IALLUGO;\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstruct bpf_preload_ops *bpf_preload_ops;\nEXPORT_SYMBOL_GPL(bpf_preload_ops);\n\nstatic bool bpf_preload_mod_get(void)\n{\n\t \n\tif (!bpf_preload_ops) {\n\t\trequest_module(\"bpf_preload\");\n\t\tif (!bpf_preload_ops)\n\t\t\treturn false;\n\t}\n\t \n\tif (!try_module_get(bpf_preload_ops->owner)) {\n\t\tpr_err(\"bpf_preload module get failed.\\n\");\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic void bpf_preload_mod_put(void)\n{\n\tif (bpf_preload_ops)\n\t\t \n\t\tmodule_put(bpf_preload_ops->owner);\n}\n\nstatic DEFINE_MUTEX(bpf_preload_lock);\n\nstatic int populate_bpffs(struct dentry *parent)\n{\n\tstruct bpf_preload_info objs[BPF_PRELOAD_LINKS] = {};\n\tint err = 0, i;\n\n\t \n\tmutex_lock(&bpf_preload_lock);\n\n\t \n\tif (!bpf_preload_mod_get())\n\t\tgoto out;\n\n\terr = bpf_preload_ops->preload(objs);\n\tif (err)\n\t\tgoto out_put;\n\tfor (i = 0; i < BPF_PRELOAD_LINKS; i++) {\n\t\tbpf_link_inc(objs[i].link);\n\t\terr = bpf_iter_link_pin_kernel(parent,\n\t\t\t\t\t       objs[i].link_name, objs[i].link);\n\t\tif (err) {\n\t\t\tbpf_link_put(objs[i].link);\n\t\t\tgoto out_put;\n\t\t}\n\t}\nout_put:\n\tbpf_preload_mod_put();\nout:\n\tmutex_unlock(&bpf_preload_lock);\n\treturn err;\n}\n\nstatic int bpf_fill_super(struct super_block *sb, struct fs_context *fc)\n{\n\tstatic const struct tree_descr bpf_rfiles[] = { { \"\" } };\n\tstruct bpf_mount_opts *opts = fc->fs_private;\n\tstruct inode *inode;\n\tint ret;\n\n\tret = simple_fill_super(sb, BPF_FS_MAGIC, bpf_rfiles);\n\tif (ret)\n\t\treturn ret;\n\n\tsb->s_op = &bpf_super_ops;\n\n\tinode = sb->s_root->d_inode;\n\tinode->i_op = &bpf_dir_iops;\n\tinode->i_mode &= ~S_IALLUGO;\n\tpopulate_bpffs(sb->s_root);\n\tinode->i_mode |= S_ISVTX | opts->mode;\n\treturn 0;\n}\n\nstatic int bpf_get_tree(struct fs_context *fc)\n{\n\treturn get_tree_nodev(fc, bpf_fill_super);\n}\n\nstatic void bpf_free_fc(struct fs_context *fc)\n{\n\tkfree(fc->fs_private);\n}\n\nstatic const struct fs_context_operations bpf_context_ops = {\n\t.free\t\t= bpf_free_fc,\n\t.parse_param\t= bpf_parse_param,\n\t.get_tree\t= bpf_get_tree,\n};\n\n \nstatic int bpf_init_fs_context(struct fs_context *fc)\n{\n\tstruct bpf_mount_opts *opts;\n\n\topts = kzalloc(sizeof(struct bpf_mount_opts), GFP_KERNEL);\n\tif (!opts)\n\t\treturn -ENOMEM;\n\n\topts->mode = S_IRWXUGO;\n\n\tfc->fs_private = opts;\n\tfc->ops = &bpf_context_ops;\n\treturn 0;\n}\n\nstatic struct file_system_type bpf_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"bpf\",\n\t.init_fs_context = bpf_init_fs_context,\n\t.parameters\t= bpf_fs_parameters,\n\t.kill_sb\t= kill_litter_super,\n};\n\nstatic int __init bpf_init(void)\n{\n\tint ret;\n\n\tret = sysfs_create_mount_point(fs_kobj, \"bpf\");\n\tif (ret)\n\t\treturn ret;\n\n\tret = register_filesystem(&bpf_fs_type);\n\tif (ret)\n\t\tsysfs_remove_mount_point(fs_kobj, \"bpf\");\n\n\treturn ret;\n}\nfs_initcall(bpf_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}