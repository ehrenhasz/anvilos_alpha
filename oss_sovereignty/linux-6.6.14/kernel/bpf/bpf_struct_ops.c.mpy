{
  "module_name": "bpf_struct_ops.c",
  "hash_id": "4d4fa17c1e204327f671a6c9119a4abb82497b34a39361939d70ae087d12fabf",
  "original_prompt": "Ingested from linux-6.6.14/kernel/bpf/bpf_struct_ops.c",
  "human_readable_source": "\n \n\n#include <linux/bpf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/filter.h>\n#include <linux/slab.h>\n#include <linux/numa.h>\n#include <linux/seq_file.h>\n#include <linux/refcount.h>\n#include <linux/mutex.h>\n#include <linux/btf_ids.h>\n#include <linux/rcupdate_wait.h>\n\nenum bpf_struct_ops_state {\n\tBPF_STRUCT_OPS_STATE_INIT,\n\tBPF_STRUCT_OPS_STATE_INUSE,\n\tBPF_STRUCT_OPS_STATE_TOBEFREE,\n\tBPF_STRUCT_OPS_STATE_READY,\n};\n\n#define BPF_STRUCT_OPS_COMMON_VALUE\t\t\t\\\n\trefcount_t refcnt;\t\t\t\t\\\n\tenum bpf_struct_ops_state state\n\nstruct bpf_struct_ops_value {\n\tBPF_STRUCT_OPS_COMMON_VALUE;\n\tchar data[] ____cacheline_aligned_in_smp;\n};\n\nstruct bpf_struct_ops_map {\n\tstruct bpf_map map;\n\tstruct rcu_head rcu;\n\tconst struct bpf_struct_ops *st_ops;\n\t \n\tstruct mutex lock;\n\t \n\tstruct bpf_link **links;\n\t \n\tvoid *image;\n\t \n\tstruct bpf_struct_ops_value *uvalue;\n\t \n\tstruct bpf_struct_ops_value kvalue;\n};\n\nstruct bpf_struct_ops_link {\n\tstruct bpf_link link;\n\tstruct bpf_map __rcu *map;\n};\n\nstatic DEFINE_MUTEX(update_mutex);\n\n#define VALUE_PREFIX \"bpf_struct_ops_\"\n#define VALUE_PREFIX_LEN (sizeof(VALUE_PREFIX) - 1)\n\n \n#define BPF_STRUCT_OPS_TYPE(_name)\t\t\t\t\\\nextern struct bpf_struct_ops bpf_##_name;\t\t\t\\\n\t\t\t\t\t\t\t\t\\\nstruct bpf_struct_ops_##_name {\t\t\t\t\t\t\\\n\tBPF_STRUCT_OPS_COMMON_VALUE;\t\t\t\t\\\n\tstruct _name data ____cacheline_aligned_in_smp;\t\t\\\n};\n#include \"bpf_struct_ops_types.h\"\n#undef BPF_STRUCT_OPS_TYPE\n\nenum {\n#define BPF_STRUCT_OPS_TYPE(_name) BPF_STRUCT_OPS_TYPE_##_name,\n#include \"bpf_struct_ops_types.h\"\n#undef BPF_STRUCT_OPS_TYPE\n\t__NR_BPF_STRUCT_OPS_TYPE,\n};\n\nstatic struct bpf_struct_ops * const bpf_struct_ops[] = {\n#define BPF_STRUCT_OPS_TYPE(_name)\t\t\t\t\\\n\t[BPF_STRUCT_OPS_TYPE_##_name] = &bpf_##_name,\n#include \"bpf_struct_ops_types.h\"\n#undef BPF_STRUCT_OPS_TYPE\n};\n\nconst struct bpf_verifier_ops bpf_struct_ops_verifier_ops = {\n};\n\nconst struct bpf_prog_ops bpf_struct_ops_prog_ops = {\n#ifdef CONFIG_NET\n\t.test_run = bpf_struct_ops_test_run,\n#endif\n};\n\nstatic const struct btf_type *module_type;\n\nvoid bpf_struct_ops_init(struct btf *btf, struct bpf_verifier_log *log)\n{\n\ts32 type_id, value_id, module_id;\n\tconst struct btf_member *member;\n\tstruct bpf_struct_ops *st_ops;\n\tconst struct btf_type *t;\n\tchar value_name[128];\n\tconst char *mname;\n\tu32 i, j;\n\n\t \n#define BPF_STRUCT_OPS_TYPE(_name) BTF_TYPE_EMIT(struct bpf_struct_ops_##_name);\n#include \"bpf_struct_ops_types.h\"\n#undef BPF_STRUCT_OPS_TYPE\n\n\tmodule_id = btf_find_by_name_kind(btf, \"module\", BTF_KIND_STRUCT);\n\tif (module_id < 0) {\n\t\tpr_warn(\"Cannot find struct module in btf_vmlinux\\n\");\n\t\treturn;\n\t}\n\tmodule_type = btf_type_by_id(btf, module_id);\n\n\tfor (i = 0; i < ARRAY_SIZE(bpf_struct_ops); i++) {\n\t\tst_ops = bpf_struct_ops[i];\n\n\t\tif (strlen(st_ops->name) + VALUE_PREFIX_LEN >=\n\t\t    sizeof(value_name)) {\n\t\t\tpr_warn(\"struct_ops name %s is too long\\n\",\n\t\t\t\tst_ops->name);\n\t\t\tcontinue;\n\t\t}\n\t\tsprintf(value_name, \"%s%s\", VALUE_PREFIX, st_ops->name);\n\n\t\tvalue_id = btf_find_by_name_kind(btf, value_name,\n\t\t\t\t\t\t BTF_KIND_STRUCT);\n\t\tif (value_id < 0) {\n\t\t\tpr_warn(\"Cannot find struct %s in btf_vmlinux\\n\",\n\t\t\t\tvalue_name);\n\t\t\tcontinue;\n\t\t}\n\n\t\ttype_id = btf_find_by_name_kind(btf, st_ops->name,\n\t\t\t\t\t\tBTF_KIND_STRUCT);\n\t\tif (type_id < 0) {\n\t\t\tpr_warn(\"Cannot find struct %s in btf_vmlinux\\n\",\n\t\t\t\tst_ops->name);\n\t\t\tcontinue;\n\t\t}\n\t\tt = btf_type_by_id(btf, type_id);\n\t\tif (btf_type_vlen(t) > BPF_STRUCT_OPS_MAX_NR_MEMBERS) {\n\t\t\tpr_warn(\"Cannot support #%u members in struct %s\\n\",\n\t\t\t\tbtf_type_vlen(t), st_ops->name);\n\t\t\tcontinue;\n\t\t}\n\n\t\tfor_each_member(j, t, member) {\n\t\t\tconst struct btf_type *func_proto;\n\n\t\t\tmname = btf_name_by_offset(btf, member->name_off);\n\t\t\tif (!*mname) {\n\t\t\t\tpr_warn(\"anon member in struct %s is not supported\\n\",\n\t\t\t\t\tst_ops->name);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (__btf_member_bitfield_size(t, member)) {\n\t\t\t\tpr_warn(\"bit field member %s in struct %s is not supported\\n\",\n\t\t\t\t\tmname, st_ops->name);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tfunc_proto = btf_type_resolve_func_ptr(btf,\n\t\t\t\t\t\t\t       member->type,\n\t\t\t\t\t\t\t       NULL);\n\t\t\tif (func_proto &&\n\t\t\t    btf_distill_func_proto(log, btf,\n\t\t\t\t\t\t   func_proto, mname,\n\t\t\t\t\t\t   &st_ops->func_models[j])) {\n\t\t\t\tpr_warn(\"Error in parsing func ptr %s in struct %s\\n\",\n\t\t\t\t\tmname, st_ops->name);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (j == btf_type_vlen(t)) {\n\t\t\tif (st_ops->init(btf)) {\n\t\t\t\tpr_warn(\"Error in init bpf_struct_ops %s\\n\",\n\t\t\t\t\tst_ops->name);\n\t\t\t} else {\n\t\t\t\tst_ops->type_id = type_id;\n\t\t\t\tst_ops->type = t;\n\t\t\t\tst_ops->value_id = value_id;\n\t\t\t\tst_ops->value_type = btf_type_by_id(btf,\n\t\t\t\t\t\t\t\t    value_id);\n\t\t\t}\n\t\t}\n\t}\n}\n\nextern struct btf *btf_vmlinux;\n\nstatic const struct bpf_struct_ops *\nbpf_struct_ops_find_value(u32 value_id)\n{\n\tunsigned int i;\n\n\tif (!value_id || !btf_vmlinux)\n\t\treturn NULL;\n\n\tfor (i = 0; i < ARRAY_SIZE(bpf_struct_ops); i++) {\n\t\tif (bpf_struct_ops[i]->value_id == value_id)\n\t\t\treturn bpf_struct_ops[i];\n\t}\n\n\treturn NULL;\n}\n\nconst struct bpf_struct_ops *bpf_struct_ops_find(u32 type_id)\n{\n\tunsigned int i;\n\n\tif (!type_id || !btf_vmlinux)\n\t\treturn NULL;\n\n\tfor (i = 0; i < ARRAY_SIZE(bpf_struct_ops); i++) {\n\t\tif (bpf_struct_ops[i]->type_id == type_id)\n\t\t\treturn bpf_struct_ops[i];\n\t}\n\n\treturn NULL;\n}\n\nstatic int bpf_struct_ops_map_get_next_key(struct bpf_map *map, void *key,\n\t\t\t\t\t   void *next_key)\n{\n\tif (key && *(u32 *)key == 0)\n\t\treturn -ENOENT;\n\n\t*(u32 *)next_key = 0;\n\treturn 0;\n}\n\nint bpf_struct_ops_map_sys_lookup_elem(struct bpf_map *map, void *key,\n\t\t\t\t       void *value)\n{\n\tstruct bpf_struct_ops_map *st_map = (struct bpf_struct_ops_map *)map;\n\tstruct bpf_struct_ops_value *uvalue, *kvalue;\n\tenum bpf_struct_ops_state state;\n\ts64 refcnt;\n\n\tif (unlikely(*(u32 *)key != 0))\n\t\treturn -ENOENT;\n\n\tkvalue = &st_map->kvalue;\n\t \n\tstate = smp_load_acquire(&kvalue->state);\n\tif (state == BPF_STRUCT_OPS_STATE_INIT) {\n\t\tmemset(value, 0, map->value_size);\n\t\treturn 0;\n\t}\n\n\t \n\tuvalue = value;\n\tmemcpy(uvalue, st_map->uvalue, map->value_size);\n\tuvalue->state = state;\n\n\t \n\trefcnt = atomic64_read(&map->refcnt) - atomic64_read(&map->usercnt);\n\trefcount_set(&uvalue->refcnt, max_t(s64, refcnt, 0));\n\n\treturn 0;\n}\n\nstatic void *bpf_struct_ops_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\treturn ERR_PTR(-EINVAL);\n}\n\nstatic void bpf_struct_ops_map_put_progs(struct bpf_struct_ops_map *st_map)\n{\n\tconst struct btf_type *t = st_map->st_ops->type;\n\tu32 i;\n\n\tfor (i = 0; i < btf_type_vlen(t); i++) {\n\t\tif (st_map->links[i]) {\n\t\t\tbpf_link_put(st_map->links[i]);\n\t\t\tst_map->links[i] = NULL;\n\t\t}\n\t}\n}\n\nstatic int check_zero_holes(const struct btf_type *t, void *data)\n{\n\tconst struct btf_member *member;\n\tu32 i, moff, msize, prev_mend = 0;\n\tconst struct btf_type *mtype;\n\n\tfor_each_member(i, t, member) {\n\t\tmoff = __btf_member_bit_offset(t, member) / 8;\n\t\tif (moff > prev_mend &&\n\t\t    memchr_inv(data + prev_mend, 0, moff - prev_mend))\n\t\t\treturn -EINVAL;\n\n\t\tmtype = btf_type_by_id(btf_vmlinux, member->type);\n\t\tmtype = btf_resolve_size(btf_vmlinux, mtype, &msize);\n\t\tif (IS_ERR(mtype))\n\t\t\treturn PTR_ERR(mtype);\n\t\tprev_mend = moff + msize;\n\t}\n\n\tif (t->size > prev_mend &&\n\t    memchr_inv(data + prev_mend, 0, t->size - prev_mend))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic void bpf_struct_ops_link_release(struct bpf_link *link)\n{\n}\n\nstatic void bpf_struct_ops_link_dealloc(struct bpf_link *link)\n{\n\tstruct bpf_tramp_link *tlink = container_of(link, struct bpf_tramp_link, link);\n\n\tkfree(tlink);\n}\n\nconst struct bpf_link_ops bpf_struct_ops_link_lops = {\n\t.release = bpf_struct_ops_link_release,\n\t.dealloc = bpf_struct_ops_link_dealloc,\n};\n\nint bpf_struct_ops_prepare_trampoline(struct bpf_tramp_links *tlinks,\n\t\t\t\t      struct bpf_tramp_link *link,\n\t\t\t\t      const struct btf_func_model *model,\n\t\t\t\t      void *image, void *image_end)\n{\n\tu32 flags;\n\n\ttlinks[BPF_TRAMP_FENTRY].links[0] = link;\n\ttlinks[BPF_TRAMP_FENTRY].nr_links = 1;\n\t \n\tflags = model->ret_size > 0 ? BPF_TRAMP_F_RET_FENTRY_RET : 0;\n\treturn arch_prepare_bpf_trampoline(NULL, image, image_end,\n\t\t\t\t\t   model, flags, tlinks, NULL);\n}\n\nstatic long bpf_struct_ops_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t   void *value, u64 flags)\n{\n\tstruct bpf_struct_ops_map *st_map = (struct bpf_struct_ops_map *)map;\n\tconst struct bpf_struct_ops *st_ops = st_map->st_ops;\n\tstruct bpf_struct_ops_value *uvalue, *kvalue;\n\tconst struct btf_member *member;\n\tconst struct btf_type *t = st_ops->type;\n\tstruct bpf_tramp_links *tlinks;\n\tvoid *udata, *kdata;\n\tint prog_fd, err;\n\tvoid *image, *image_end;\n\tu32 i;\n\n\tif (flags)\n\t\treturn -EINVAL;\n\n\tif (*(u32 *)key != 0)\n\t\treturn -E2BIG;\n\n\terr = check_zero_holes(st_ops->value_type, value);\n\tif (err)\n\t\treturn err;\n\n\tuvalue = value;\n\terr = check_zero_holes(t, uvalue->data);\n\tif (err)\n\t\treturn err;\n\n\tif (uvalue->state || refcount_read(&uvalue->refcnt))\n\t\treturn -EINVAL;\n\n\ttlinks = kcalloc(BPF_TRAMP_MAX, sizeof(*tlinks), GFP_KERNEL);\n\tif (!tlinks)\n\t\treturn -ENOMEM;\n\n\tuvalue = (struct bpf_struct_ops_value *)st_map->uvalue;\n\tkvalue = (struct bpf_struct_ops_value *)&st_map->kvalue;\n\n\tmutex_lock(&st_map->lock);\n\n\tif (kvalue->state != BPF_STRUCT_OPS_STATE_INIT) {\n\t\terr = -EBUSY;\n\t\tgoto unlock;\n\t}\n\n\tmemcpy(uvalue, value, map->value_size);\n\n\tudata = &uvalue->data;\n\tkdata = &kvalue->data;\n\timage = st_map->image;\n\timage_end = st_map->image + PAGE_SIZE;\n\n\tfor_each_member(i, t, member) {\n\t\tconst struct btf_type *mtype, *ptype;\n\t\tstruct bpf_prog *prog;\n\t\tstruct bpf_tramp_link *link;\n\t\tu32 moff;\n\n\t\tmoff = __btf_member_bit_offset(t, member) / 8;\n\t\tptype = btf_type_resolve_ptr(btf_vmlinux, member->type, NULL);\n\t\tif (ptype == module_type) {\n\t\t\tif (*(void **)(udata + moff))\n\t\t\t\tgoto reset_unlock;\n\t\t\t*(void **)(kdata + moff) = BPF_MODULE_OWNER;\n\t\t\tcontinue;\n\t\t}\n\n\t\terr = st_ops->init_member(t, member, kdata, udata);\n\t\tif (err < 0)\n\t\t\tgoto reset_unlock;\n\n\t\t \n\t\tif (err > 0)\n\t\t\tcontinue;\n\n\t\t \n\n\t\t \n\t\tif (!ptype || !btf_type_is_func_proto(ptype)) {\n\t\t\tu32 msize;\n\n\t\t\tmtype = btf_type_by_id(btf_vmlinux, member->type);\n\t\t\tmtype = btf_resolve_size(btf_vmlinux, mtype, &msize);\n\t\t\tif (IS_ERR(mtype)) {\n\t\t\t\terr = PTR_ERR(mtype);\n\t\t\t\tgoto reset_unlock;\n\t\t\t}\n\n\t\t\tif (memchr_inv(udata + moff, 0, msize)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto reset_unlock;\n\t\t\t}\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tprog_fd = (int)(*(unsigned long *)(udata + moff));\n\t\t \n\t\tif (!prog_fd)\n\t\t\tcontinue;\n\n\t\tprog = bpf_prog_get(prog_fd);\n\t\tif (IS_ERR(prog)) {\n\t\t\terr = PTR_ERR(prog);\n\t\t\tgoto reset_unlock;\n\t\t}\n\n\t\tif (prog->type != BPF_PROG_TYPE_STRUCT_OPS ||\n\t\t    prog->aux->attach_btf_id != st_ops->type_id ||\n\t\t    prog->expected_attach_type != i) {\n\t\t\tbpf_prog_put(prog);\n\t\t\terr = -EINVAL;\n\t\t\tgoto reset_unlock;\n\t\t}\n\n\t\tlink = kzalloc(sizeof(*link), GFP_USER);\n\t\tif (!link) {\n\t\t\tbpf_prog_put(prog);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto reset_unlock;\n\t\t}\n\t\tbpf_link_init(&link->link, BPF_LINK_TYPE_STRUCT_OPS,\n\t\t\t      &bpf_struct_ops_link_lops, prog);\n\t\tst_map->links[i] = &link->link;\n\n\t\terr = bpf_struct_ops_prepare_trampoline(tlinks, link,\n\t\t\t\t\t\t\t&st_ops->func_models[i],\n\t\t\t\t\t\t\timage, image_end);\n\t\tif (err < 0)\n\t\t\tgoto reset_unlock;\n\n\t\t*(void **)(kdata + moff) = image;\n\t\timage += err;\n\n\t\t \n\t\t*(unsigned long *)(udata + moff) = prog->aux->id;\n\t}\n\n\tif (st_map->map.map_flags & BPF_F_LINK) {\n\t\terr = 0;\n\t\tif (st_ops->validate) {\n\t\t\terr = st_ops->validate(kdata);\n\t\t\tif (err)\n\t\t\t\tgoto reset_unlock;\n\t\t}\n\t\tset_memory_rox((long)st_map->image, 1);\n\t\t \n\t\tsmp_store_release(&kvalue->state, BPF_STRUCT_OPS_STATE_READY);\n\t\tgoto unlock;\n\t}\n\n\tset_memory_rox((long)st_map->image, 1);\n\terr = st_ops->reg(kdata);\n\tif (likely(!err)) {\n\t\t \n\t\tbpf_map_inc(map);\n\t\t \n\t\tsmp_store_release(&kvalue->state, BPF_STRUCT_OPS_STATE_INUSE);\n\t\tgoto unlock;\n\t}\n\n\t \n\tset_memory_nx((long)st_map->image, 1);\n\tset_memory_rw((long)st_map->image, 1);\n\nreset_unlock:\n\tbpf_struct_ops_map_put_progs(st_map);\n\tmemset(uvalue, 0, map->value_size);\n\tmemset(kvalue, 0, map->value_size);\nunlock:\n\tkfree(tlinks);\n\tmutex_unlock(&st_map->lock);\n\treturn err;\n}\n\nstatic long bpf_struct_ops_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tenum bpf_struct_ops_state prev_state;\n\tstruct bpf_struct_ops_map *st_map;\n\n\tst_map = (struct bpf_struct_ops_map *)map;\n\tif (st_map->map.map_flags & BPF_F_LINK)\n\t\treturn -EOPNOTSUPP;\n\n\tprev_state = cmpxchg(&st_map->kvalue.state,\n\t\t\t     BPF_STRUCT_OPS_STATE_INUSE,\n\t\t\t     BPF_STRUCT_OPS_STATE_TOBEFREE);\n\tswitch (prev_state) {\n\tcase BPF_STRUCT_OPS_STATE_INUSE:\n\t\tst_map->st_ops->unreg(&st_map->kvalue.data);\n\t\tbpf_map_put(map);\n\t\treturn 0;\n\tcase BPF_STRUCT_OPS_STATE_TOBEFREE:\n\t\treturn -EINPROGRESS;\n\tcase BPF_STRUCT_OPS_STATE_INIT:\n\t\treturn -ENOENT;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\t \n\t\treturn -ENOENT;\n\t}\n}\n\nstatic void bpf_struct_ops_map_seq_show_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     struct seq_file *m)\n{\n\tvoid *value;\n\tint err;\n\n\tvalue = kmalloc(map->value_size, GFP_USER | __GFP_NOWARN);\n\tif (!value)\n\t\treturn;\n\n\terr = bpf_struct_ops_map_sys_lookup_elem(map, key, value);\n\tif (!err) {\n\t\tbtf_type_seq_show(btf_vmlinux, map->btf_vmlinux_value_type_id,\n\t\t\t\t  value, m);\n\t\tseq_puts(m, \"\\n\");\n\t}\n\n\tkfree(value);\n}\n\nstatic void __bpf_struct_ops_map_free(struct bpf_map *map)\n{\n\tstruct bpf_struct_ops_map *st_map = (struct bpf_struct_ops_map *)map;\n\n\tif (st_map->links)\n\t\tbpf_struct_ops_map_put_progs(st_map);\n\tbpf_map_area_free(st_map->links);\n\tbpf_jit_free_exec(st_map->image);\n\tbpf_map_area_free(st_map->uvalue);\n\tbpf_map_area_free(st_map);\n}\n\nstatic void bpf_struct_ops_map_free(struct bpf_map *map)\n{\n\t \n\tsynchronize_rcu_mult(call_rcu, call_rcu_tasks);\n\n\t__bpf_struct_ops_map_free(map);\n}\n\nstatic int bpf_struct_ops_map_alloc_check(union bpf_attr *attr)\n{\n\tif (attr->key_size != sizeof(unsigned int) || attr->max_entries != 1 ||\n\t    (attr->map_flags & ~BPF_F_LINK) || !attr->btf_vmlinux_value_type_id)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic struct bpf_map *bpf_struct_ops_map_alloc(union bpf_attr *attr)\n{\n\tconst struct bpf_struct_ops *st_ops;\n\tsize_t st_map_size;\n\tstruct bpf_struct_ops_map *st_map;\n\tconst struct btf_type *t, *vt;\n\tstruct bpf_map *map;\n\n\tst_ops = bpf_struct_ops_find_value(attr->btf_vmlinux_value_type_id);\n\tif (!st_ops)\n\t\treturn ERR_PTR(-ENOTSUPP);\n\n\tvt = st_ops->value_type;\n\tif (attr->value_size != vt->size)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tt = st_ops->type;\n\n\tst_map_size = sizeof(*st_map) +\n\t\t \n\t\t(vt->size - sizeof(struct bpf_struct_ops_value));\n\n\tst_map = bpf_map_area_alloc(st_map_size, NUMA_NO_NODE);\n\tif (!st_map)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tst_map->st_ops = st_ops;\n\tmap = &st_map->map;\n\n\tst_map->uvalue = bpf_map_area_alloc(vt->size, NUMA_NO_NODE);\n\tst_map->links =\n\t\tbpf_map_area_alloc(btf_type_vlen(t) * sizeof(struct bpf_links *),\n\t\t\t\t   NUMA_NO_NODE);\n\tst_map->image = bpf_jit_alloc_exec(PAGE_SIZE);\n\tif (!st_map->uvalue || !st_map->links || !st_map->image) {\n\t\t__bpf_struct_ops_map_free(map);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tmutex_init(&st_map->lock);\n\tset_vm_flush_reset_perms(st_map->image);\n\tbpf_map_init_from_attr(map, attr);\n\n\treturn map;\n}\n\nstatic u64 bpf_struct_ops_map_mem_usage(const struct bpf_map *map)\n{\n\tstruct bpf_struct_ops_map *st_map = (struct bpf_struct_ops_map *)map;\n\tconst struct bpf_struct_ops *st_ops = st_map->st_ops;\n\tconst struct btf_type *vt = st_ops->value_type;\n\tu64 usage;\n\n\tusage = sizeof(*st_map) +\n\t\t\tvt->size - sizeof(struct bpf_struct_ops_value);\n\tusage += vt->size;\n\tusage += btf_type_vlen(vt) * sizeof(struct bpf_links *);\n\tusage += PAGE_SIZE;\n\treturn usage;\n}\n\nBTF_ID_LIST_SINGLE(bpf_struct_ops_map_btf_ids, struct, bpf_struct_ops_map)\nconst struct bpf_map_ops bpf_struct_ops_map_ops = {\n\t.map_alloc_check = bpf_struct_ops_map_alloc_check,\n\t.map_alloc = bpf_struct_ops_map_alloc,\n\t.map_free = bpf_struct_ops_map_free,\n\t.map_get_next_key = bpf_struct_ops_map_get_next_key,\n\t.map_lookup_elem = bpf_struct_ops_map_lookup_elem,\n\t.map_delete_elem = bpf_struct_ops_map_delete_elem,\n\t.map_update_elem = bpf_struct_ops_map_update_elem,\n\t.map_seq_show_elem = bpf_struct_ops_map_seq_show_elem,\n\t.map_mem_usage = bpf_struct_ops_map_mem_usage,\n\t.map_btf_id = &bpf_struct_ops_map_btf_ids[0],\n};\n\n \nbool bpf_struct_ops_get(const void *kdata)\n{\n\tstruct bpf_struct_ops_value *kvalue;\n\tstruct bpf_struct_ops_map *st_map;\n\tstruct bpf_map *map;\n\n\tkvalue = container_of(kdata, struct bpf_struct_ops_value, data);\n\tst_map = container_of(kvalue, struct bpf_struct_ops_map, kvalue);\n\n\tmap = __bpf_map_inc_not_zero(&st_map->map, false);\n\treturn !IS_ERR(map);\n}\n\nvoid bpf_struct_ops_put(const void *kdata)\n{\n\tstruct bpf_struct_ops_value *kvalue;\n\tstruct bpf_struct_ops_map *st_map;\n\n\tkvalue = container_of(kdata, struct bpf_struct_ops_value, data);\n\tst_map = container_of(kvalue, struct bpf_struct_ops_map, kvalue);\n\n\tbpf_map_put(&st_map->map);\n}\n\nstatic bool bpf_struct_ops_valid_to_reg(struct bpf_map *map)\n{\n\tstruct bpf_struct_ops_map *st_map = (struct bpf_struct_ops_map *)map;\n\n\treturn map->map_type == BPF_MAP_TYPE_STRUCT_OPS &&\n\t\tmap->map_flags & BPF_F_LINK &&\n\t\t \n\t\tsmp_load_acquire(&st_map->kvalue.state) == BPF_STRUCT_OPS_STATE_READY;\n}\n\nstatic void bpf_struct_ops_map_link_dealloc(struct bpf_link *link)\n{\n\tstruct bpf_struct_ops_link *st_link;\n\tstruct bpf_struct_ops_map *st_map;\n\n\tst_link = container_of(link, struct bpf_struct_ops_link, link);\n\tst_map = (struct bpf_struct_ops_map *)\n\t\trcu_dereference_protected(st_link->map, true);\n\tif (st_map) {\n\t\t \n\t\tst_map->st_ops->unreg(&st_map->kvalue.data);\n\t\tbpf_map_put(&st_map->map);\n\t}\n\tkfree(st_link);\n}\n\nstatic void bpf_struct_ops_map_link_show_fdinfo(const struct bpf_link *link,\n\t\t\t\t\t    struct seq_file *seq)\n{\n\tstruct bpf_struct_ops_link *st_link;\n\tstruct bpf_map *map;\n\n\tst_link = container_of(link, struct bpf_struct_ops_link, link);\n\trcu_read_lock();\n\tmap = rcu_dereference(st_link->map);\n\tseq_printf(seq, \"map_id:\\t%d\\n\", map->id);\n\trcu_read_unlock();\n}\n\nstatic int bpf_struct_ops_map_link_fill_link_info(const struct bpf_link *link,\n\t\t\t\t\t       struct bpf_link_info *info)\n{\n\tstruct bpf_struct_ops_link *st_link;\n\tstruct bpf_map *map;\n\n\tst_link = container_of(link, struct bpf_struct_ops_link, link);\n\trcu_read_lock();\n\tmap = rcu_dereference(st_link->map);\n\tinfo->struct_ops.map_id = map->id;\n\trcu_read_unlock();\n\treturn 0;\n}\n\nstatic int bpf_struct_ops_map_link_update(struct bpf_link *link, struct bpf_map *new_map,\n\t\t\t\t\t  struct bpf_map *expected_old_map)\n{\n\tstruct bpf_struct_ops_map *st_map, *old_st_map;\n\tstruct bpf_map *old_map;\n\tstruct bpf_struct_ops_link *st_link;\n\tint err;\n\n\tst_link = container_of(link, struct bpf_struct_ops_link, link);\n\tst_map = container_of(new_map, struct bpf_struct_ops_map, map);\n\n\tif (!bpf_struct_ops_valid_to_reg(new_map))\n\t\treturn -EINVAL;\n\n\tif (!st_map->st_ops->update)\n\t\treturn -EOPNOTSUPP;\n\n\tmutex_lock(&update_mutex);\n\n\told_map = rcu_dereference_protected(st_link->map, lockdep_is_held(&update_mutex));\n\tif (expected_old_map && old_map != expected_old_map) {\n\t\terr = -EPERM;\n\t\tgoto err_out;\n\t}\n\n\told_st_map = container_of(old_map, struct bpf_struct_ops_map, map);\n\t \n\tif (st_map->st_ops != old_st_map->st_ops) {\n\t\terr = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\terr = st_map->st_ops->update(st_map->kvalue.data, old_st_map->kvalue.data);\n\tif (err)\n\t\tgoto err_out;\n\n\tbpf_map_inc(new_map);\n\trcu_assign_pointer(st_link->map, new_map);\n\tbpf_map_put(old_map);\n\nerr_out:\n\tmutex_unlock(&update_mutex);\n\n\treturn err;\n}\n\nstatic const struct bpf_link_ops bpf_struct_ops_map_lops = {\n\t.dealloc = bpf_struct_ops_map_link_dealloc,\n\t.show_fdinfo = bpf_struct_ops_map_link_show_fdinfo,\n\t.fill_link_info = bpf_struct_ops_map_link_fill_link_info,\n\t.update_map = bpf_struct_ops_map_link_update,\n};\n\nint bpf_struct_ops_link_create(union bpf_attr *attr)\n{\n\tstruct bpf_struct_ops_link *link = NULL;\n\tstruct bpf_link_primer link_primer;\n\tstruct bpf_struct_ops_map *st_map;\n\tstruct bpf_map *map;\n\tint err;\n\n\tmap = bpf_map_get(attr->link_create.map_fd);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\n\tst_map = (struct bpf_struct_ops_map *)map;\n\n\tif (!bpf_struct_ops_valid_to_reg(map)) {\n\t\terr = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\tlink = kzalloc(sizeof(*link), GFP_USER);\n\tif (!link) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\tbpf_link_init(&link->link, BPF_LINK_TYPE_STRUCT_OPS, &bpf_struct_ops_map_lops, NULL);\n\n\terr = bpf_link_prime(&link->link, &link_primer);\n\tif (err)\n\t\tgoto err_out;\n\n\terr = st_map->st_ops->reg(st_map->kvalue.data);\n\tif (err) {\n\t\tbpf_link_cleanup(&link_primer);\n\t\tlink = NULL;\n\t\tgoto err_out;\n\t}\n\tRCU_INIT_POINTER(link->map, map);\n\n\treturn bpf_link_settle(&link_primer);\n\nerr_out:\n\tbpf_map_put(map);\n\tkfree(link);\n\treturn err;\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}