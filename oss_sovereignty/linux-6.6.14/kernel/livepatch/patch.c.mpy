{
  "module_name": "patch.c",
  "hash_id": "2e1d100855f466a144b603d1cd63c278c622a5c221e101b44342e77f3bc1caee",
  "original_prompt": "Ingested from linux-6.6.14/kernel/livepatch/patch.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/livepatch.h>\n#include <linux/list.h>\n#include <linux/ftrace.h>\n#include <linux/rculist.h>\n#include <linux/slab.h>\n#include <linux/bug.h>\n#include <linux/printk.h>\n#include \"core.h\"\n#include \"patch.h\"\n#include \"transition.h\"\n\nstatic LIST_HEAD(klp_ops);\n\nstruct klp_ops *klp_find_ops(void *old_func)\n{\n\tstruct klp_ops *ops;\n\tstruct klp_func *func;\n\n\tlist_for_each_entry(ops, &klp_ops, node) {\n\t\tfunc = list_first_entry(&ops->func_stack, struct klp_func,\n\t\t\t\t\tstack_node);\n\t\tif (func->old_func == old_func)\n\t\t\treturn ops;\n\t}\n\n\treturn NULL;\n}\n\nstatic void notrace klp_ftrace_handler(unsigned long ip,\n\t\t\t\t       unsigned long parent_ip,\n\t\t\t\t       struct ftrace_ops *fops,\n\t\t\t\t       struct ftrace_regs *fregs)\n{\n\tstruct klp_ops *ops;\n\tstruct klp_func *func;\n\tint patch_state;\n\tint bit;\n\n\tops = container_of(fops, struct klp_ops, fops);\n\n\t \n\tbit = ftrace_test_recursion_trylock(ip, parent_ip);\n\tif (WARN_ON_ONCE(bit < 0))\n\t\treturn;\n\n\tfunc = list_first_or_null_rcu(&ops->func_stack, struct klp_func,\n\t\t\t\t      stack_node);\n\n\t \n\tif (WARN_ON_ONCE(!func))\n\t\tgoto unlock;\n\n\t \n\tsmp_rmb();\n\n\tif (unlikely(func->transition)) {\n\n\t\t \n\t\tsmp_rmb();\n\n\t\tpatch_state = current->patch_state;\n\n\t\tWARN_ON_ONCE(patch_state == KLP_UNDEFINED);\n\n\t\tif (patch_state == KLP_UNPATCHED) {\n\t\t\t \n\t\t\tfunc = list_entry_rcu(func->stack_node.next,\n\t\t\t\t\t      struct klp_func, stack_node);\n\n\t\t\tif (&func->stack_node == &ops->func_stack)\n\t\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\t \n\tif (func->nop)\n\t\tgoto unlock;\n\n\tftrace_regs_set_instruction_pointer(fregs, (unsigned long)func->new_func);\n\nunlock:\n\tftrace_test_recursion_unlock(bit);\n}\n\nstatic void klp_unpatch_func(struct klp_func *func)\n{\n\tstruct klp_ops *ops;\n\n\tif (WARN_ON(!func->patched))\n\t\treturn;\n\tif (WARN_ON(!func->old_func))\n\t\treturn;\n\n\tops = klp_find_ops(func->old_func);\n\tif (WARN_ON(!ops))\n\t\treturn;\n\n\tif (list_is_singular(&ops->func_stack)) {\n\t\tunsigned long ftrace_loc;\n\n\t\tftrace_loc = ftrace_location((unsigned long)func->old_func);\n\t\tif (WARN_ON(!ftrace_loc))\n\t\t\treturn;\n\n\t\tWARN_ON(unregister_ftrace_function(&ops->fops));\n\t\tWARN_ON(ftrace_set_filter_ip(&ops->fops, ftrace_loc, 1, 0));\n\n\t\tlist_del_rcu(&func->stack_node);\n\t\tlist_del(&ops->node);\n\t\tkfree(ops);\n\t} else {\n\t\tlist_del_rcu(&func->stack_node);\n\t}\n\n\tfunc->patched = false;\n}\n\nstatic int klp_patch_func(struct klp_func *func)\n{\n\tstruct klp_ops *ops;\n\tint ret;\n\n\tif (WARN_ON(!func->old_func))\n\t\treturn -EINVAL;\n\n\tif (WARN_ON(func->patched))\n\t\treturn -EINVAL;\n\n\tops = klp_find_ops(func->old_func);\n\tif (!ops) {\n\t\tunsigned long ftrace_loc;\n\n\t\tftrace_loc = ftrace_location((unsigned long)func->old_func);\n\t\tif (!ftrace_loc) {\n\t\t\tpr_err(\"failed to find location for function '%s'\\n\",\n\t\t\t\tfunc->old_name);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tops = kzalloc(sizeof(*ops), GFP_KERNEL);\n\t\tif (!ops)\n\t\t\treturn -ENOMEM;\n\n\t\tops->fops.func = klp_ftrace_handler;\n\t\tops->fops.flags = FTRACE_OPS_FL_DYNAMIC |\n#ifndef CONFIG_HAVE_DYNAMIC_FTRACE_WITH_ARGS\n\t\t\t\t  FTRACE_OPS_FL_SAVE_REGS |\n#endif\n\t\t\t\t  FTRACE_OPS_FL_IPMODIFY |\n\t\t\t\t  FTRACE_OPS_FL_PERMANENT;\n\n\t\tlist_add(&ops->node, &klp_ops);\n\n\t\tINIT_LIST_HEAD(&ops->func_stack);\n\t\tlist_add_rcu(&func->stack_node, &ops->func_stack);\n\n\t\tret = ftrace_set_filter_ip(&ops->fops, ftrace_loc, 0, 0);\n\t\tif (ret) {\n\t\t\tpr_err(\"failed to set ftrace filter for function '%s' (%d)\\n\",\n\t\t\t       func->old_name, ret);\n\t\t\tgoto err;\n\t\t}\n\n\t\tret = register_ftrace_function(&ops->fops);\n\t\tif (ret) {\n\t\t\tpr_err(\"failed to register ftrace handler for function '%s' (%d)\\n\",\n\t\t\t       func->old_name, ret);\n\t\t\tftrace_set_filter_ip(&ops->fops, ftrace_loc, 1, 0);\n\t\t\tgoto err;\n\t\t}\n\n\n\t} else {\n\t\tlist_add_rcu(&func->stack_node, &ops->func_stack);\n\t}\n\n\tfunc->patched = true;\n\n\treturn 0;\n\nerr:\n\tlist_del_rcu(&func->stack_node);\n\tlist_del(&ops->node);\n\tkfree(ops);\n\treturn ret;\n}\n\nstatic void __klp_unpatch_object(struct klp_object *obj, bool nops_only)\n{\n\tstruct klp_func *func;\n\n\tklp_for_each_func(obj, func) {\n\t\tif (nops_only && !func->nop)\n\t\t\tcontinue;\n\n\t\tif (func->patched)\n\t\t\tklp_unpatch_func(func);\n\t}\n\n\tif (obj->dynamic || !nops_only)\n\t\tobj->patched = false;\n}\n\n\nvoid klp_unpatch_object(struct klp_object *obj)\n{\n\t__klp_unpatch_object(obj, false);\n}\n\nint klp_patch_object(struct klp_object *obj)\n{\n\tstruct klp_func *func;\n\tint ret;\n\n\tif (WARN_ON(obj->patched))\n\t\treturn -EINVAL;\n\n\tklp_for_each_func(obj, func) {\n\t\tret = klp_patch_func(func);\n\t\tif (ret) {\n\t\t\tklp_unpatch_object(obj);\n\t\t\treturn ret;\n\t\t}\n\t}\n\tobj->patched = true;\n\n\treturn 0;\n}\n\nstatic void __klp_unpatch_objects(struct klp_patch *patch, bool nops_only)\n{\n\tstruct klp_object *obj;\n\n\tklp_for_each_object(patch, obj)\n\t\tif (obj->patched)\n\t\t\t__klp_unpatch_object(obj, nops_only);\n}\n\nvoid klp_unpatch_objects(struct klp_patch *patch)\n{\n\t__klp_unpatch_objects(patch, false);\n}\n\nvoid klp_unpatch_objects_dynamic(struct klp_patch *patch)\n{\n\t__klp_unpatch_objects(patch, true);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}