{
  "module_name": "pid_list.c",
  "hash_id": "f15261ac778d7e1006e496912ed489c6caf709f5e6961d9f749b38c3b31e01f0",
  "original_prompt": "Ingested from linux-6.6.14/kernel/trace/pid_list.c",
  "human_readable_source": "\n \n#include <linux/spinlock.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include \"trace.h\"\n\n \n\nstatic inline union lower_chunk *get_lower_chunk(struct trace_pid_list *pid_list)\n{\n\tunion lower_chunk *chunk;\n\n\tlockdep_assert_held(&pid_list->lock);\n\n\tif (!pid_list->lower_list)\n\t\treturn NULL;\n\n\tchunk = pid_list->lower_list;\n\tpid_list->lower_list = chunk->next;\n\tpid_list->free_lower_chunks--;\n\tWARN_ON_ONCE(pid_list->free_lower_chunks < 0);\n\tchunk->next = NULL;\n\t \n\tif (pid_list->free_lower_chunks <= CHUNK_REALLOC)\n\t\tirq_work_queue(&pid_list->refill_irqwork);\n\n\treturn chunk;\n}\n\nstatic inline union upper_chunk *get_upper_chunk(struct trace_pid_list *pid_list)\n{\n\tunion upper_chunk *chunk;\n\n\tlockdep_assert_held(&pid_list->lock);\n\n\tif (!pid_list->upper_list)\n\t\treturn NULL;\n\n\tchunk = pid_list->upper_list;\n\tpid_list->upper_list = chunk->next;\n\tpid_list->free_upper_chunks--;\n\tWARN_ON_ONCE(pid_list->free_upper_chunks < 0);\n\tchunk->next = NULL;\n\t \n\tif (pid_list->free_upper_chunks <= CHUNK_REALLOC)\n\t\tirq_work_queue(&pid_list->refill_irqwork);\n\n\treturn chunk;\n}\n\nstatic inline void put_lower_chunk(struct trace_pid_list *pid_list,\n\t\t\t\t   union lower_chunk *chunk)\n{\n\tlockdep_assert_held(&pid_list->lock);\n\n\tchunk->next = pid_list->lower_list;\n\tpid_list->lower_list = chunk;\n\tpid_list->free_lower_chunks++;\n}\n\nstatic inline void put_upper_chunk(struct trace_pid_list *pid_list,\n\t\t\t\t   union upper_chunk *chunk)\n{\n\tlockdep_assert_held(&pid_list->lock);\n\n\tchunk->next = pid_list->upper_list;\n\tpid_list->upper_list = chunk;\n\tpid_list->free_upper_chunks++;\n}\n\nstatic inline bool upper_empty(union upper_chunk *chunk)\n{\n\t \n\tint bit = find_first_bit((unsigned long *)chunk->data,\n\t\t\t\t sizeof(chunk->data) * 8);\n\treturn bit >= sizeof(chunk->data) * 8;\n}\n\nstatic inline int pid_split(unsigned int pid, unsigned int *upper1,\n\t\t\t     unsigned int *upper2, unsigned int *lower)\n{\n\t \n\tBUILD_BUG_ON(MAX_PID < PID_MAX_LIMIT);\n\n\t \n\tif (unlikely(pid >= MAX_PID))\n\t\treturn -1;\n\n\t*upper1 = (pid >> UPPER1_SHIFT) & UPPER_MASK;\n\t*upper2 = (pid >> UPPER2_SHIFT) & UPPER_MASK;\n\t*lower = pid & LOWER_MASK;\n\n\treturn 0;\n}\n\nstatic inline unsigned int pid_join(unsigned int upper1,\n\t\t\t\t    unsigned int upper2, unsigned int lower)\n{\n\treturn ((upper1 & UPPER_MASK) << UPPER1_SHIFT) |\n\t\t((upper2 & UPPER_MASK) << UPPER2_SHIFT) |\n\t\t(lower & LOWER_MASK);\n}\n\n \nbool trace_pid_list_is_set(struct trace_pid_list *pid_list, unsigned int pid)\n{\n\tunion upper_chunk *upper_chunk;\n\tunion lower_chunk *lower_chunk;\n\tunsigned long flags;\n\tunsigned int upper1;\n\tunsigned int upper2;\n\tunsigned int lower;\n\tbool ret = false;\n\n\tif (!pid_list)\n\t\treturn false;\n\n\tif (pid_split(pid, &upper1, &upper2, &lower) < 0)\n\t\treturn false;\n\n\traw_spin_lock_irqsave(&pid_list->lock, flags);\n\tupper_chunk = pid_list->upper[upper1];\n\tif (upper_chunk) {\n\t\tlower_chunk = upper_chunk->data[upper2];\n\t\tif (lower_chunk)\n\t\t\tret = test_bit(lower, lower_chunk->data);\n\t}\n\traw_spin_unlock_irqrestore(&pid_list->lock, flags);\n\n\treturn ret;\n}\n\n \nint trace_pid_list_set(struct trace_pid_list *pid_list, unsigned int pid)\n{\n\tunion upper_chunk *upper_chunk;\n\tunion lower_chunk *lower_chunk;\n\tunsigned long flags;\n\tunsigned int upper1;\n\tunsigned int upper2;\n\tunsigned int lower;\n\tint ret;\n\n\tif (!pid_list)\n\t\treturn -ENODEV;\n\n\tif (pid_split(pid, &upper1, &upper2, &lower) < 0)\n\t\treturn -EINVAL;\n\n\traw_spin_lock_irqsave(&pid_list->lock, flags);\n\tupper_chunk = pid_list->upper[upper1];\n\tif (!upper_chunk) {\n\t\tupper_chunk = get_upper_chunk(pid_list);\n\t\tif (!upper_chunk) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tpid_list->upper[upper1] = upper_chunk;\n\t}\n\tlower_chunk = upper_chunk->data[upper2];\n\tif (!lower_chunk) {\n\t\tlower_chunk = get_lower_chunk(pid_list);\n\t\tif (!lower_chunk) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tupper_chunk->data[upper2] = lower_chunk;\n\t}\n\tset_bit(lower, lower_chunk->data);\n\tret = 0;\n out:\n\traw_spin_unlock_irqrestore(&pid_list->lock, flags);\n\treturn ret;\n}\n\n \nint trace_pid_list_clear(struct trace_pid_list *pid_list, unsigned int pid)\n{\n\tunion upper_chunk *upper_chunk;\n\tunion lower_chunk *lower_chunk;\n\tunsigned long flags;\n\tunsigned int upper1;\n\tunsigned int upper2;\n\tunsigned int lower;\n\n\tif (!pid_list)\n\t\treturn -ENODEV;\n\n\tif (pid_split(pid, &upper1, &upper2, &lower) < 0)\n\t\treturn -EINVAL;\n\n\traw_spin_lock_irqsave(&pid_list->lock, flags);\n\tupper_chunk = pid_list->upper[upper1];\n\tif (!upper_chunk)\n\t\tgoto out;\n\n\tlower_chunk = upper_chunk->data[upper2];\n\tif (!lower_chunk)\n\t\tgoto out;\n\n\tclear_bit(lower, lower_chunk->data);\n\n\t \n\tif (find_first_bit(lower_chunk->data, LOWER_MAX) >= LOWER_MAX) {\n\t\tput_lower_chunk(pid_list, lower_chunk);\n\t\tupper_chunk->data[upper2] = NULL;\n\t\tif (upper_empty(upper_chunk)) {\n\t\t\tput_upper_chunk(pid_list, upper_chunk);\n\t\t\tpid_list->upper[upper1] = NULL;\n\t\t}\n\t}\n out:\n\traw_spin_unlock_irqrestore(&pid_list->lock, flags);\n\treturn 0;\n}\n\n \nint trace_pid_list_next(struct trace_pid_list *pid_list, unsigned int pid,\n\t\t\tunsigned int *next)\n{\n\tunion upper_chunk *upper_chunk;\n\tunion lower_chunk *lower_chunk;\n\tunsigned long flags;\n\tunsigned int upper1;\n\tunsigned int upper2;\n\tunsigned int lower;\n\n\tif (!pid_list)\n\t\treturn -ENODEV;\n\n\tif (pid_split(pid, &upper1, &upper2, &lower) < 0)\n\t\treturn -EINVAL;\n\n\traw_spin_lock_irqsave(&pid_list->lock, flags);\n\tfor (; upper1 <= UPPER_MASK; upper1++, upper2 = 0) {\n\t\tupper_chunk = pid_list->upper[upper1];\n\n\t\tif (!upper_chunk)\n\t\t\tcontinue;\n\n\t\tfor (; upper2 <= UPPER_MASK; upper2++, lower = 0) {\n\t\t\tlower_chunk = upper_chunk->data[upper2];\n\t\t\tif (!lower_chunk)\n\t\t\t\tcontinue;\n\n\t\t\tlower = find_next_bit(lower_chunk->data, LOWER_MAX,\n\t\t\t\t\t    lower);\n\t\t\tif (lower < LOWER_MAX)\n\t\t\t\tgoto found;\n\t\t}\n\t}\n\n found:\n\traw_spin_unlock_irqrestore(&pid_list->lock, flags);\n\tif (upper1 > UPPER_MASK)\n\t\treturn -1;\n\n\t*next = pid_join(upper1, upper2, lower);\n\treturn 0;\n}\n\n \nint trace_pid_list_first(struct trace_pid_list *pid_list, unsigned int *pid)\n{\n\treturn trace_pid_list_next(pid_list, 0, pid);\n}\n\nstatic void pid_list_refill_irq(struct irq_work *iwork)\n{\n\tstruct trace_pid_list *pid_list = container_of(iwork, struct trace_pid_list,\n\t\t\t\t\t\t       refill_irqwork);\n\tunion upper_chunk *upper = NULL;\n\tunion lower_chunk *lower = NULL;\n\tunion upper_chunk **upper_next = &upper;\n\tunion lower_chunk **lower_next = &lower;\n\tint upper_count;\n\tint lower_count;\n\tint ucnt = 0;\n\tint lcnt = 0;\n\n again:\n\traw_spin_lock(&pid_list->lock);\n\tupper_count = CHUNK_ALLOC - pid_list->free_upper_chunks;\n\tlower_count = CHUNK_ALLOC - pid_list->free_lower_chunks;\n\traw_spin_unlock(&pid_list->lock);\n\n\tif (upper_count <= 0 && lower_count <= 0)\n\t\treturn;\n\n\twhile (upper_count-- > 0) {\n\t\tunion upper_chunk *chunk;\n\n\t\tchunk = kzalloc(sizeof(*chunk), GFP_KERNEL);\n\t\tif (!chunk)\n\t\t\tbreak;\n\t\t*upper_next = chunk;\n\t\tupper_next = &chunk->next;\n\t\tucnt++;\n\t}\n\n\twhile (lower_count-- > 0) {\n\t\tunion lower_chunk *chunk;\n\n\t\tchunk = kzalloc(sizeof(*chunk), GFP_KERNEL);\n\t\tif (!chunk)\n\t\t\tbreak;\n\t\t*lower_next = chunk;\n\t\tlower_next = &chunk->next;\n\t\tlcnt++;\n\t}\n\n\traw_spin_lock(&pid_list->lock);\n\tif (upper) {\n\t\t*upper_next = pid_list->upper_list;\n\t\tpid_list->upper_list = upper;\n\t\tpid_list->free_upper_chunks += ucnt;\n\t}\n\tif (lower) {\n\t\t*lower_next = pid_list->lower_list;\n\t\tpid_list->lower_list = lower;\n\t\tpid_list->free_lower_chunks += lcnt;\n\t}\n\traw_spin_unlock(&pid_list->lock);\n\n\t \n\tif (upper_count >= 0 || lower_count >= 0)\n\t\treturn;\n\t \n\tgoto again;\n}\n\n \nstruct trace_pid_list *trace_pid_list_alloc(void)\n{\n\tstruct trace_pid_list *pid_list;\n\tint i;\n\n\t \n\tWARN_ON_ONCE(pid_max > (1 << 30));\n\n\tpid_list = kzalloc(sizeof(*pid_list), GFP_KERNEL);\n\tif (!pid_list)\n\t\treturn NULL;\n\n\tinit_irq_work(&pid_list->refill_irqwork, pid_list_refill_irq);\n\n\traw_spin_lock_init(&pid_list->lock);\n\n\tfor (i = 0; i < CHUNK_ALLOC; i++) {\n\t\tunion upper_chunk *chunk;\n\n\t\tchunk = kzalloc(sizeof(*chunk), GFP_KERNEL);\n\t\tif (!chunk)\n\t\t\tbreak;\n\t\tchunk->next = pid_list->upper_list;\n\t\tpid_list->upper_list = chunk;\n\t\tpid_list->free_upper_chunks++;\n\t}\n\n\tfor (i = 0; i < CHUNK_ALLOC; i++) {\n\t\tunion lower_chunk *chunk;\n\n\t\tchunk = kzalloc(sizeof(*chunk), GFP_KERNEL);\n\t\tif (!chunk)\n\t\t\tbreak;\n\t\tchunk->next = pid_list->lower_list;\n\t\tpid_list->lower_list = chunk;\n\t\tpid_list->free_lower_chunks++;\n\t}\n\n\treturn pid_list;\n}\n\n \nvoid trace_pid_list_free(struct trace_pid_list *pid_list)\n{\n\tunion upper_chunk *upper;\n\tunion lower_chunk *lower;\n\tint i, j;\n\n\tif (!pid_list)\n\t\treturn;\n\n\tirq_work_sync(&pid_list->refill_irqwork);\n\n\twhile (pid_list->lower_list) {\n\t\tunion lower_chunk *chunk;\n\n\t\tchunk = pid_list->lower_list;\n\t\tpid_list->lower_list = pid_list->lower_list->next;\n\t\tkfree(chunk);\n\t}\n\n\twhile (pid_list->upper_list) {\n\t\tunion upper_chunk *chunk;\n\n\t\tchunk = pid_list->upper_list;\n\t\tpid_list->upper_list = pid_list->upper_list->next;\n\t\tkfree(chunk);\n\t}\n\n\tfor (i = 0; i < UPPER1_SIZE; i++) {\n\t\tupper = pid_list->upper[i];\n\t\tif (upper) {\n\t\t\tfor (j = 0; j < UPPER2_SIZE; j++) {\n\t\t\t\tlower = upper->data[j];\n\t\t\t\tkfree(lower);\n\t\t\t}\n\t\t\tkfree(upper);\n\t\t}\n\t}\n\tkfree(pid_list);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}