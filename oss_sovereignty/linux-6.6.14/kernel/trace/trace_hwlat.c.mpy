{
  "module_name": "trace_hwlat.c",
  "hash_id": "08fb4d9ade45634bfbe9a9e1ff4f8404e75c69b704cdcd66f664e0fb84e96e3a",
  "original_prompt": "Ingested from linux-6.6.14/kernel/trace/trace_hwlat.c",
  "human_readable_source": "\n \n#include <linux/kthread.h>\n#include <linux/tracefs.h>\n#include <linux/uaccess.h>\n#include <linux/cpumask.h>\n#include <linux/delay.h>\n#include <linux/sched/clock.h>\n#include \"trace.h\"\n\nstatic struct trace_array\t*hwlat_trace;\n\n#define U64STR_SIZE\t\t22\t\t\t \n\n#define BANNER\t\t\t\"hwlat_detector: \"\n#define DEFAULT_SAMPLE_WINDOW\t1000000\t\t\t \n#define DEFAULT_SAMPLE_WIDTH\t500000\t\t\t \n#define DEFAULT_LAT_THRESHOLD\t10\t\t\t \n\nstatic struct dentry *hwlat_sample_width;\t \nstatic struct dentry *hwlat_sample_window;\t \nstatic struct dentry *hwlat_thread_mode;\t \n\nenum {\n\tMODE_NONE = 0,\n\tMODE_ROUND_ROBIN,\n\tMODE_PER_CPU,\n\tMODE_MAX\n};\nstatic char *thread_mode_str[] = { \"none\", \"round-robin\", \"per-cpu\" };\n\n \nstatic unsigned long save_tracing_thresh;\n\n \nstruct hwlat_kthread_data {\n\tstruct task_struct\t*kthread;\n\t \n\tu64\t\t\tnmi_ts_start;\n\tu64\t\t\tnmi_total_ts;\n\tint\t\t\tnmi_count;\n\tint\t\t\tnmi_cpu;\n};\n\nstatic struct hwlat_kthread_data hwlat_single_cpu_data;\nstatic DEFINE_PER_CPU(struct hwlat_kthread_data, hwlat_per_cpu_data);\n\n \nbool trace_hwlat_callback_enabled;\n\n \nstatic u64 last_tracing_thresh = DEFAULT_LAT_THRESHOLD * NSEC_PER_USEC;\n\n \nstruct hwlat_sample {\n\tu64\t\t\tseqnum;\t\t \n\tu64\t\t\tduration;\t \n\tu64\t\t\touter_duration;\t \n\tu64\t\t\tnmi_total_ts;\t \n\tstruct timespec64\ttimestamp;\t \n\tint\t\t\tnmi_count;\t \n\tint\t\t\tcount;\t\t \n};\n\n \nstatic struct hwlat_data {\n\n\tstruct mutex lock;\t\t \n\n\tu64\tcount;\t\t\t \n\n\tu64\tsample_window;\t\t \n\tu64\tsample_width;\t\t \n\n\tint\tthread_mode;\t\t \n\n} hwlat_data = {\n\t.sample_window\t\t= DEFAULT_SAMPLE_WINDOW,\n\t.sample_width\t\t= DEFAULT_SAMPLE_WIDTH,\n\t.thread_mode\t\t= MODE_ROUND_ROBIN\n};\n\nstatic struct hwlat_kthread_data *get_cpu_data(void)\n{\n\tif (hwlat_data.thread_mode == MODE_PER_CPU)\n\t\treturn this_cpu_ptr(&hwlat_per_cpu_data);\n\telse\n\t\treturn &hwlat_single_cpu_data;\n}\n\nstatic bool hwlat_busy;\n\nstatic void trace_hwlat_sample(struct hwlat_sample *sample)\n{\n\tstruct trace_array *tr = hwlat_trace;\n\tstruct trace_event_call *call = &event_hwlat;\n\tstruct trace_buffer *buffer = tr->array_buffer.buffer;\n\tstruct ring_buffer_event *event;\n\tstruct hwlat_entry *entry;\n\n\tevent = trace_buffer_lock_reserve(buffer, TRACE_HWLAT, sizeof(*entry),\n\t\t\t\t\t  tracing_gen_ctx());\n\tif (!event)\n\t\treturn;\n\tentry\t= ring_buffer_event_data(event);\n\tentry->seqnum\t\t\t= sample->seqnum;\n\tentry->duration\t\t\t= sample->duration;\n\tentry->outer_duration\t\t= sample->outer_duration;\n\tentry->timestamp\t\t= sample->timestamp;\n\tentry->nmi_total_ts\t\t= sample->nmi_total_ts;\n\tentry->nmi_count\t\t= sample->nmi_count;\n\tentry->count\t\t\t= sample->count;\n\n\tif (!call_filter_check_discard(call, entry, buffer, event))\n\t\ttrace_buffer_unlock_commit_nostack(buffer, event);\n}\n\n \n#define time_type\tu64\n#define time_get()\ttrace_clock_local()\n#define time_to_us(x)\tdiv_u64(x, 1000)\n#define time_sub(a, b)\t((a) - (b))\n#define init_time(a, b)\t(a = b)\n#define time_u64(a)\ta\n\nvoid trace_hwlat_callback(bool enter)\n{\n\tstruct hwlat_kthread_data *kdata = get_cpu_data();\n\n\tif (!kdata->kthread)\n\t\treturn;\n\n\t \n\tif (!IS_ENABLED(CONFIG_GENERIC_SCHED_CLOCK)) {\n\t\tif (enter)\n\t\t\tkdata->nmi_ts_start = time_get();\n\t\telse\n\t\t\tkdata->nmi_total_ts += time_get() - kdata->nmi_ts_start;\n\t}\n\n\tif (enter)\n\t\tkdata->nmi_count++;\n}\n\n \n#define hwlat_err(msg) ({\t\t\t\t\t\t\t\\\n\tstruct trace_array *tr = hwlat_trace;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\t\\\n\ttrace_array_printk_buf(tr->array_buffer.buffer, _THIS_IP_, msg);\t\\\n})\n\n \nstatic int get_sample(void)\n{\n\tstruct hwlat_kthread_data *kdata = get_cpu_data();\n\tstruct trace_array *tr = hwlat_trace;\n\tstruct hwlat_sample s;\n\ttime_type start, t1, t2, last_t2;\n\ts64 diff, outer_diff, total, last_total = 0;\n\tu64 sample = 0;\n\tu64 thresh = tracing_thresh;\n\tu64 outer_sample = 0;\n\tint ret = -1;\n\tunsigned int count = 0;\n\n\tdo_div(thresh, NSEC_PER_USEC);  \n\n\tkdata->nmi_total_ts = 0;\n\tkdata->nmi_count = 0;\n\t \n\tbarrier();\n\n\ttrace_hwlat_callback_enabled = true;\n\n\tinit_time(last_t2, 0);\n\tstart = time_get();  \n\touter_diff = 0;\n\n\tdo {\n\n\t\tt1 = time_get();\t \n\t\tt2 = time_get();\n\n\t\tif (time_u64(last_t2)) {\n\t\t\t \n\t\t\touter_diff = time_to_us(time_sub(t1, last_t2));\n\t\t\t \n\t\t\tif (outer_diff < 0) {\n\t\t\t\thwlat_err(BANNER \"time running backwards\\n\");\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (outer_diff > outer_sample)\n\t\t\t\touter_sample = outer_diff;\n\t\t}\n\t\tlast_t2 = t2;\n\n\t\ttotal = time_to_us(time_sub(t2, start));  \n\n\t\t \n\t\tif (total < last_total) {\n\t\t\thwlat_err(\"Time total overflowed\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tlast_total = total;\n\n\t\t \n\t\tdiff = time_to_us(time_sub(t2, t1));      \n\n\t\tif (diff > thresh || outer_diff > thresh) {\n\t\t\tif (!count)\n\t\t\t\tktime_get_real_ts64(&s.timestamp);\n\t\t\tcount++;\n\t\t}\n\n\t\t \n\t\tif (diff < 0) {\n\t\t\thwlat_err(BANNER \"time running backwards\\n\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (diff > sample)\n\t\t\tsample = diff;  \n\n\t} while (total <= hwlat_data.sample_width);\n\n\tbarrier();  \n\ttrace_hwlat_callback_enabled = false;\n\tbarrier();  \n\n\tret = 0;\n\n\t \n\tif (sample > thresh || outer_sample > thresh) {\n\t\tu64 latency;\n\n\t\tret = 1;\n\n\t\t \n\t\tif (kdata->nmi_total_ts)\n\t\t\tdo_div(kdata->nmi_total_ts, NSEC_PER_USEC);\n\n\t\thwlat_data.count++;\n\t\ts.seqnum = hwlat_data.count;\n\t\ts.duration = sample;\n\t\ts.outer_duration = outer_sample;\n\t\ts.nmi_total_ts = kdata->nmi_total_ts;\n\t\ts.nmi_count = kdata->nmi_count;\n\t\ts.count = count;\n\t\ttrace_hwlat_sample(&s);\n\n\t\tlatency = max(sample, outer_sample);\n\n\t\t \n\t\tif (latency > tr->max_latency) {\n\t\t\ttr->max_latency = latency;\n\t\t\tlatency_fsnotify(tr);\n\t\t}\n\t}\n\nout:\n\treturn ret;\n}\n\nstatic struct cpumask save_cpumask;\n\nstatic void move_to_next_cpu(void)\n{\n\tstruct cpumask *current_mask = &save_cpumask;\n\tstruct trace_array *tr = hwlat_trace;\n\tint next_cpu;\n\n\t \n\tif (!cpumask_equal(current_mask, current->cpus_ptr))\n\t\tgoto change_mode;\n\n\tcpus_read_lock();\n\tcpumask_and(current_mask, cpu_online_mask, tr->tracing_cpumask);\n\tnext_cpu = cpumask_next(raw_smp_processor_id(), current_mask);\n\tcpus_read_unlock();\n\n\tif (next_cpu >= nr_cpu_ids)\n\t\tnext_cpu = cpumask_first(current_mask);\n\n\tif (next_cpu >= nr_cpu_ids)  \n\t\tgoto change_mode;\n\n\tcpumask_clear(current_mask);\n\tcpumask_set_cpu(next_cpu, current_mask);\n\n\tset_cpus_allowed_ptr(current, current_mask);\n\treturn;\n\n change_mode:\n\thwlat_data.thread_mode = MODE_NONE;\n\tpr_info(BANNER \"cpumask changed while in round-robin mode, switching to mode none\\n\");\n}\n\n \nstatic int kthread_fn(void *data)\n{\n\tu64 interval;\n\n\twhile (!kthread_should_stop()) {\n\n\t\tif (hwlat_data.thread_mode == MODE_ROUND_ROBIN)\n\t\t\tmove_to_next_cpu();\n\n\t\tlocal_irq_disable();\n\t\tget_sample();\n\t\tlocal_irq_enable();\n\n\t\tmutex_lock(&hwlat_data.lock);\n\t\tinterval = hwlat_data.sample_window - hwlat_data.sample_width;\n\t\tmutex_unlock(&hwlat_data.lock);\n\n\t\tdo_div(interval, USEC_PER_MSEC);  \n\n\t\t \n\t\tif (interval < 1)\n\t\t\tinterval = 1;\n\n\t\tif (msleep_interruptible(interval))\n\t\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void stop_single_kthread(void)\n{\n\tstruct hwlat_kthread_data *kdata = get_cpu_data();\n\tstruct task_struct *kthread;\n\n\tcpus_read_lock();\n\tkthread = kdata->kthread;\n\n\tif (!kthread)\n\t\tgoto out_put_cpus;\n\n\tkthread_stop(kthread);\n\tkdata->kthread = NULL;\n\nout_put_cpus:\n\tcpus_read_unlock();\n}\n\n\n \nstatic int start_single_kthread(struct trace_array *tr)\n{\n\tstruct hwlat_kthread_data *kdata = get_cpu_data();\n\tstruct cpumask *current_mask = &save_cpumask;\n\tstruct task_struct *kthread;\n\tint next_cpu;\n\n\tcpus_read_lock();\n\tif (kdata->kthread)\n\t\tgoto out_put_cpus;\n\n\tkthread = kthread_create(kthread_fn, NULL, \"hwlatd\");\n\tif (IS_ERR(kthread)) {\n\t\tpr_err(BANNER \"could not start sampling thread\\n\");\n\t\tcpus_read_unlock();\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tcpumask_and(current_mask, cpu_online_mask, tr->tracing_cpumask);\n\n\tif (hwlat_data.thread_mode == MODE_ROUND_ROBIN) {\n\t\tnext_cpu = cpumask_first(current_mask);\n\t\tcpumask_clear(current_mask);\n\t\tcpumask_set_cpu(next_cpu, current_mask);\n\n\t}\n\n\tset_cpus_allowed_ptr(kthread, current_mask);\n\n\tkdata->kthread = kthread;\n\twake_up_process(kthread);\n\nout_put_cpus:\n\tcpus_read_unlock();\n\treturn 0;\n}\n\n \nstatic void stop_cpu_kthread(unsigned int cpu)\n{\n\tstruct task_struct *kthread;\n\n\tkthread = per_cpu(hwlat_per_cpu_data, cpu).kthread;\n\tif (kthread)\n\t\tkthread_stop(kthread);\n\tper_cpu(hwlat_per_cpu_data, cpu).kthread = NULL;\n}\n\n \nstatic void stop_per_cpu_kthreads(void)\n{\n\tunsigned int cpu;\n\n\tcpus_read_lock();\n\tfor_each_online_cpu(cpu)\n\t\tstop_cpu_kthread(cpu);\n\tcpus_read_unlock();\n}\n\n \nstatic int start_cpu_kthread(unsigned int cpu)\n{\n\tstruct task_struct *kthread;\n\n\t \n\tif (per_cpu(hwlat_per_cpu_data, cpu).kthread)\n\t\treturn 0;\n\n\tkthread = kthread_run_on_cpu(kthread_fn, NULL, cpu, \"hwlatd/%u\");\n\tif (IS_ERR(kthread)) {\n\t\tpr_err(BANNER \"could not start sampling thread\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tper_cpu(hwlat_per_cpu_data, cpu).kthread = kthread;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_HOTPLUG_CPU\nstatic void hwlat_hotplug_workfn(struct work_struct *dummy)\n{\n\tstruct trace_array *tr = hwlat_trace;\n\tunsigned int cpu = smp_processor_id();\n\n\tmutex_lock(&trace_types_lock);\n\tmutex_lock(&hwlat_data.lock);\n\tcpus_read_lock();\n\n\tif (!hwlat_busy || hwlat_data.thread_mode != MODE_PER_CPU)\n\t\tgoto out_unlock;\n\n\tif (!cpumask_test_cpu(cpu, tr->tracing_cpumask))\n\t\tgoto out_unlock;\n\n\tstart_cpu_kthread(cpu);\n\nout_unlock:\n\tcpus_read_unlock();\n\tmutex_unlock(&hwlat_data.lock);\n\tmutex_unlock(&trace_types_lock);\n}\n\nstatic DECLARE_WORK(hwlat_hotplug_work, hwlat_hotplug_workfn);\n\n \nstatic int hwlat_cpu_init(unsigned int cpu)\n{\n\tschedule_work_on(cpu, &hwlat_hotplug_work);\n\treturn 0;\n}\n\n \nstatic int hwlat_cpu_die(unsigned int cpu)\n{\n\tstop_cpu_kthread(cpu);\n\treturn 0;\n}\n\nstatic void hwlat_init_hotplug_support(void)\n{\n\tint ret;\n\n\tret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, \"trace/hwlat:online\",\n\t\t\t\thwlat_cpu_init, hwlat_cpu_die);\n\tif (ret < 0)\n\t\tpr_warn(BANNER \"Error to init cpu hotplug support\\n\");\n\n\treturn;\n}\n#else  \nstatic void hwlat_init_hotplug_support(void)\n{\n\treturn;\n}\n#endif  \n\n \nstatic int start_per_cpu_kthreads(struct trace_array *tr)\n{\n\tstruct cpumask *current_mask = &save_cpumask;\n\tunsigned int cpu;\n\tint retval;\n\n\tcpus_read_lock();\n\t \n\tcpumask_and(current_mask, cpu_online_mask, tr->tracing_cpumask);\n\n\tfor_each_cpu(cpu, current_mask) {\n\t\tretval = start_cpu_kthread(cpu);\n\t\tif (retval)\n\t\t\tgoto out_error;\n\t}\n\tcpus_read_unlock();\n\n\treturn 0;\n\nout_error:\n\tcpus_read_unlock();\n\tstop_per_cpu_kthreads();\n\treturn retval;\n}\n\nstatic void *s_mode_start(struct seq_file *s, loff_t *pos)\n{\n\tint mode = *pos;\n\n\tmutex_lock(&hwlat_data.lock);\n\n\tif (mode >= MODE_MAX)\n\t\treturn NULL;\n\n\treturn pos;\n}\n\nstatic void *s_mode_next(struct seq_file *s, void *v, loff_t *pos)\n{\n\tint mode = ++(*pos);\n\n\tif (mode >= MODE_MAX)\n\t\treturn NULL;\n\n\treturn pos;\n}\n\nstatic int s_mode_show(struct seq_file *s, void *v)\n{\n\tloff_t *pos = v;\n\tint mode = *pos;\n\n\tif (mode == hwlat_data.thread_mode)\n\t\tseq_printf(s, \"[%s]\", thread_mode_str[mode]);\n\telse\n\t\tseq_printf(s, \"%s\", thread_mode_str[mode]);\n\n\tif (mode < MODE_MAX - 1)  \n\t\tseq_puts(s, \" \");\n\n\treturn 0;\n}\n\nstatic void s_mode_stop(struct seq_file *s, void *v)\n{\n\tseq_puts(s, \"\\n\");\n\tmutex_unlock(&hwlat_data.lock);\n}\n\nstatic const struct seq_operations thread_mode_seq_ops = {\n\t.start\t\t= s_mode_start,\n\t.next\t\t= s_mode_next,\n\t.show\t\t= s_mode_show,\n\t.stop\t\t= s_mode_stop\n};\n\nstatic int hwlat_mode_open(struct inode *inode, struct file *file)\n{\n\treturn seq_open(file, &thread_mode_seq_ops);\n};\n\nstatic void hwlat_tracer_start(struct trace_array *tr);\nstatic void hwlat_tracer_stop(struct trace_array *tr);\n\n \nstatic ssize_t hwlat_mode_write(struct file *filp, const char __user *ubuf,\n\t\t\t\t size_t cnt, loff_t *ppos)\n{\n\tstruct trace_array *tr = hwlat_trace;\n\tconst char *mode;\n\tchar buf[64];\n\tint ret, i;\n\n\tif (cnt >= sizeof(buf))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(buf, ubuf, cnt))\n\t\treturn -EFAULT;\n\n\tbuf[cnt] = 0;\n\n\tmode = strstrip(buf);\n\n\tret = -EINVAL;\n\n\t \n\tmutex_lock(&trace_types_lock);\n\tif (hwlat_busy)\n\t\thwlat_tracer_stop(tr);\n\n\tmutex_lock(&hwlat_data.lock);\n\n\tfor (i = 0; i < MODE_MAX; i++) {\n\t\tif (strcmp(mode, thread_mode_str[i]) == 0) {\n\t\t\thwlat_data.thread_mode = i;\n\t\t\tret = cnt;\n\t\t}\n\t}\n\n\tmutex_unlock(&hwlat_data.lock);\n\n\tif (hwlat_busy)\n\t\thwlat_tracer_start(tr);\n\tmutex_unlock(&trace_types_lock);\n\n\t*ppos += cnt;\n\n\n\n\treturn ret;\n}\n\n \nstatic struct trace_min_max_param hwlat_width = {\n\t.lock\t\t= &hwlat_data.lock,\n\t.val\t\t= &hwlat_data.sample_width,\n\t.max\t\t= &hwlat_data.sample_window,\n\t.min\t\t= NULL,\n};\n\n \nstatic struct trace_min_max_param hwlat_window = {\n\t.lock\t\t= &hwlat_data.lock,\n\t.val\t\t= &hwlat_data.sample_window,\n\t.max\t\t= NULL,\n\t.min\t\t= &hwlat_data.sample_width,\n};\n\nstatic const struct file_operations thread_mode_fops = {\n\t.open\t\t= hwlat_mode_open,\n\t.read\t\t= seq_read,\n\t.llseek\t\t= seq_lseek,\n\t.release\t= seq_release,\n\t.write\t\t= hwlat_mode_write\n};\n \nstatic int init_tracefs(void)\n{\n\tint ret;\n\tstruct dentry *top_dir;\n\n\tret = tracing_init_dentry();\n\tif (ret)\n\t\treturn -ENOMEM;\n\n\ttop_dir = tracefs_create_dir(\"hwlat_detector\", NULL);\n\tif (!top_dir)\n\t\treturn -ENOMEM;\n\n\thwlat_sample_window = tracefs_create_file(\"window\", TRACE_MODE_WRITE,\n\t\t\t\t\t\t  top_dir,\n\t\t\t\t\t\t  &hwlat_window,\n\t\t\t\t\t\t  &trace_min_max_fops);\n\tif (!hwlat_sample_window)\n\t\tgoto err;\n\n\thwlat_sample_width = tracefs_create_file(\"width\", TRACE_MODE_WRITE,\n\t\t\t\t\t\t top_dir,\n\t\t\t\t\t\t &hwlat_width,\n\t\t\t\t\t\t &trace_min_max_fops);\n\tif (!hwlat_sample_width)\n\t\tgoto err;\n\n\thwlat_thread_mode = trace_create_file(\"mode\", TRACE_MODE_WRITE,\n\t\t\t\t\t      top_dir,\n\t\t\t\t\t      NULL,\n\t\t\t\t\t      &thread_mode_fops);\n\tif (!hwlat_thread_mode)\n\t\tgoto err;\n\n\treturn 0;\n\n err:\n\ttracefs_remove(top_dir);\n\treturn -ENOMEM;\n}\n\nstatic void hwlat_tracer_start(struct trace_array *tr)\n{\n\tint err;\n\n\tif (hwlat_data.thread_mode == MODE_PER_CPU)\n\t\terr = start_per_cpu_kthreads(tr);\n\telse\n\t\terr = start_single_kthread(tr);\n\tif (err)\n\t\tpr_err(BANNER \"Cannot start hwlat kthread\\n\");\n}\n\nstatic void hwlat_tracer_stop(struct trace_array *tr)\n{\n\tif (hwlat_data.thread_mode == MODE_PER_CPU)\n\t\tstop_per_cpu_kthreads();\n\telse\n\t\tstop_single_kthread();\n}\n\nstatic int hwlat_tracer_init(struct trace_array *tr)\n{\n\t \n\tif (hwlat_busy)\n\t\treturn -EBUSY;\n\n\thwlat_trace = tr;\n\n\thwlat_data.count = 0;\n\ttr->max_latency = 0;\n\tsave_tracing_thresh = tracing_thresh;\n\n\t \n\tif (!tracing_thresh)\n\t\ttracing_thresh = last_tracing_thresh;\n\n\tif (tracer_tracing_is_on(tr))\n\t\thwlat_tracer_start(tr);\n\n\thwlat_busy = true;\n\n\treturn 0;\n}\n\nstatic void hwlat_tracer_reset(struct trace_array *tr)\n{\n\thwlat_tracer_stop(tr);\n\n\t \n\tlast_tracing_thresh = tracing_thresh;\n\n\ttracing_thresh = save_tracing_thresh;\n\thwlat_busy = false;\n}\n\nstatic struct tracer hwlat_tracer __read_mostly =\n{\n\t.name\t\t= \"hwlat\",\n\t.init\t\t= hwlat_tracer_init,\n\t.reset\t\t= hwlat_tracer_reset,\n\t.start\t\t= hwlat_tracer_start,\n\t.stop\t\t= hwlat_tracer_stop,\n\t.allow_instances = true,\n};\n\n__init static int init_hwlat_tracer(void)\n{\n\tint ret;\n\n\tmutex_init(&hwlat_data.lock);\n\n\tret = register_tracer(&hwlat_tracer);\n\tif (ret)\n\t\treturn ret;\n\n\thwlat_init_hotplug_support();\n\n\tinit_tracefs();\n\n\treturn 0;\n}\nlate_initcall(init_hwlat_tracer);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}