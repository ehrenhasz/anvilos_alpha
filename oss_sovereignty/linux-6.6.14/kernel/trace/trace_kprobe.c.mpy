{
  "module_name": "trace_kprobe.c",
  "hash_id": "931022aadd32c4fc493fe0a2cfdbc7cef687f9e1bbbbb7c84343282adb90ea13",
  "original_prompt": "Ingested from linux-6.6.14/kernel/trace/trace_kprobe.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt)\t\"trace_kprobe: \" fmt\n\n#include <linux/bpf-cgroup.h>\n#include <linux/security.h>\n#include <linux/module.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/error-injection.h>\n\n#include <asm/setup.h>   \n\n#include \"trace_dynevent.h\"\n#include \"trace_kprobe_selftest.h\"\n#include \"trace_probe.h\"\n#include \"trace_probe_tmpl.h\"\n#include \"trace_probe_kernel.h\"\n\n#define KPROBE_EVENT_SYSTEM \"kprobes\"\n#define KRETPROBE_MAXACTIVE_MAX 4096\n\n \nstatic char kprobe_boot_events_buf[COMMAND_LINE_SIZE] __initdata;\n\nstatic int __init set_kprobe_boot_events(char *str)\n{\n\tstrscpy(kprobe_boot_events_buf, str, COMMAND_LINE_SIZE);\n\tdisable_tracing_selftest(\"running kprobe events\");\n\n\treturn 1;\n}\n__setup(\"kprobe_event=\", set_kprobe_boot_events);\n\nstatic int trace_kprobe_create(const char *raw_command);\nstatic int trace_kprobe_show(struct seq_file *m, struct dyn_event *ev);\nstatic int trace_kprobe_release(struct dyn_event *ev);\nstatic bool trace_kprobe_is_busy(struct dyn_event *ev);\nstatic bool trace_kprobe_match(const char *system, const char *event,\n\t\t\tint argc, const char **argv, struct dyn_event *ev);\n\nstatic struct dyn_event_operations trace_kprobe_ops = {\n\t.create = trace_kprobe_create,\n\t.show = trace_kprobe_show,\n\t.is_busy = trace_kprobe_is_busy,\n\t.free = trace_kprobe_release,\n\t.match = trace_kprobe_match,\n};\n\n \nstruct trace_kprobe {\n\tstruct dyn_event\tdevent;\n\tstruct kretprobe\trp;\t \n\tunsigned long __percpu *nhit;\n\tconst char\t\t*symbol;\t \n\tstruct trace_probe\ttp;\n};\n\nstatic bool is_trace_kprobe(struct dyn_event *ev)\n{\n\treturn ev->ops == &trace_kprobe_ops;\n}\n\nstatic struct trace_kprobe *to_trace_kprobe(struct dyn_event *ev)\n{\n\treturn container_of(ev, struct trace_kprobe, devent);\n}\n\n \n#define for_each_trace_kprobe(pos, dpos)\t\\\n\tfor_each_dyn_event(dpos)\t\t\\\n\t\tif (is_trace_kprobe(dpos) && (pos = to_trace_kprobe(dpos)))\n\nstatic nokprobe_inline bool trace_kprobe_is_return(struct trace_kprobe *tk)\n{\n\treturn tk->rp.handler != NULL;\n}\n\nstatic nokprobe_inline const char *trace_kprobe_symbol(struct trace_kprobe *tk)\n{\n\treturn tk->symbol ? tk->symbol : \"unknown\";\n}\n\nstatic nokprobe_inline unsigned long trace_kprobe_offset(struct trace_kprobe *tk)\n{\n\treturn tk->rp.kp.offset;\n}\n\nstatic nokprobe_inline bool trace_kprobe_has_gone(struct trace_kprobe *tk)\n{\n\treturn kprobe_gone(&tk->rp.kp);\n}\n\nstatic nokprobe_inline bool trace_kprobe_within_module(struct trace_kprobe *tk,\n\t\t\t\t\t\t struct module *mod)\n{\n\tint len = strlen(module_name(mod));\n\tconst char *name = trace_kprobe_symbol(tk);\n\n\treturn strncmp(module_name(mod), name, len) == 0 && name[len] == ':';\n}\n\nstatic nokprobe_inline bool trace_kprobe_module_exist(struct trace_kprobe *tk)\n{\n\tchar *p;\n\tbool ret;\n\n\tif (!tk->symbol)\n\t\treturn false;\n\tp = strchr(tk->symbol, ':');\n\tif (!p)\n\t\treturn true;\n\t*p = '\\0';\n\trcu_read_lock_sched();\n\tret = !!find_module(tk->symbol);\n\trcu_read_unlock_sched();\n\t*p = ':';\n\n\treturn ret;\n}\n\nstatic bool trace_kprobe_is_busy(struct dyn_event *ev)\n{\n\tstruct trace_kprobe *tk = to_trace_kprobe(ev);\n\n\treturn trace_probe_is_enabled(&tk->tp);\n}\n\nstatic bool trace_kprobe_match_command_head(struct trace_kprobe *tk,\n\t\t\t\t\t    int argc, const char **argv)\n{\n\tchar buf[MAX_ARGSTR_LEN + 1];\n\n\tif (!argc)\n\t\treturn true;\n\n\tif (!tk->symbol)\n\t\tsnprintf(buf, sizeof(buf), \"0x%p\", tk->rp.kp.addr);\n\telse if (tk->rp.kp.offset)\n\t\tsnprintf(buf, sizeof(buf), \"%s+%u\",\n\t\t\t trace_kprobe_symbol(tk), tk->rp.kp.offset);\n\telse\n\t\tsnprintf(buf, sizeof(buf), \"%s\", trace_kprobe_symbol(tk));\n\tif (strcmp(buf, argv[0]))\n\t\treturn false;\n\targc--; argv++;\n\n\treturn trace_probe_match_command_args(&tk->tp, argc, argv);\n}\n\nstatic bool trace_kprobe_match(const char *system, const char *event,\n\t\t\tint argc, const char **argv, struct dyn_event *ev)\n{\n\tstruct trace_kprobe *tk = to_trace_kprobe(ev);\n\n\treturn (event[0] == '\\0' ||\n\t\tstrcmp(trace_probe_name(&tk->tp), event) == 0) &&\n\t    (!system || strcmp(trace_probe_group_name(&tk->tp), system) == 0) &&\n\t    trace_kprobe_match_command_head(tk, argc, argv);\n}\n\nstatic nokprobe_inline unsigned long trace_kprobe_nhit(struct trace_kprobe *tk)\n{\n\tunsigned long nhit = 0;\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tnhit += *per_cpu_ptr(tk->nhit, cpu);\n\n\treturn nhit;\n}\n\nstatic nokprobe_inline bool trace_kprobe_is_registered(struct trace_kprobe *tk)\n{\n\treturn !(list_empty(&tk->rp.kp.list) &&\n\t\t hlist_unhashed(&tk->rp.kp.hlist));\n}\n\n \nstatic nokprobe_inline\nunsigned long trace_kprobe_address(struct trace_kprobe *tk)\n{\n\tunsigned long addr;\n\n\tif (tk->symbol) {\n\t\taddr = (unsigned long)\n\t\t\tkallsyms_lookup_name(trace_kprobe_symbol(tk));\n\t\tif (addr)\n\t\t\taddr += tk->rp.kp.offset;\n\t} else {\n\t\taddr = (unsigned long)tk->rp.kp.addr;\n\t}\n\treturn addr;\n}\n\nstatic nokprobe_inline struct trace_kprobe *\ntrace_kprobe_primary_from_call(struct trace_event_call *call)\n{\n\tstruct trace_probe *tp;\n\n\ttp = trace_probe_primary_from_call(call);\n\tif (WARN_ON_ONCE(!tp))\n\t\treturn NULL;\n\n\treturn container_of(tp, struct trace_kprobe, tp);\n}\n\nbool trace_kprobe_on_func_entry(struct trace_event_call *call)\n{\n\tstruct trace_kprobe *tk = trace_kprobe_primary_from_call(call);\n\n\treturn tk ? (kprobe_on_func_entry(tk->rp.kp.addr,\n\t\t\ttk->rp.kp.addr ? NULL : tk->rp.kp.symbol_name,\n\t\t\ttk->rp.kp.addr ? 0 : tk->rp.kp.offset) == 0) : false;\n}\n\nbool trace_kprobe_error_injectable(struct trace_event_call *call)\n{\n\tstruct trace_kprobe *tk = trace_kprobe_primary_from_call(call);\n\n\treturn tk ? within_error_injection_list(trace_kprobe_address(tk)) :\n\t       false;\n}\n\nstatic int register_kprobe_event(struct trace_kprobe *tk);\nstatic int unregister_kprobe_event(struct trace_kprobe *tk);\n\nstatic int kprobe_dispatcher(struct kprobe *kp, struct pt_regs *regs);\nstatic int kretprobe_dispatcher(struct kretprobe_instance *ri,\n\t\t\t\tstruct pt_regs *regs);\n\nstatic void free_trace_kprobe(struct trace_kprobe *tk)\n{\n\tif (tk) {\n\t\ttrace_probe_cleanup(&tk->tp);\n\t\tkfree(tk->symbol);\n\t\tfree_percpu(tk->nhit);\n\t\tkfree(tk);\n\t}\n}\n\n \nstatic struct trace_kprobe *alloc_trace_kprobe(const char *group,\n\t\t\t\t\t     const char *event,\n\t\t\t\t\t     void *addr,\n\t\t\t\t\t     const char *symbol,\n\t\t\t\t\t     unsigned long offs,\n\t\t\t\t\t     int maxactive,\n\t\t\t\t\t     int nargs, bool is_return)\n{\n\tstruct trace_kprobe *tk;\n\tint ret = -ENOMEM;\n\n\ttk = kzalloc(struct_size(tk, tp.args, nargs), GFP_KERNEL);\n\tif (!tk)\n\t\treturn ERR_PTR(ret);\n\n\ttk->nhit = alloc_percpu(unsigned long);\n\tif (!tk->nhit)\n\t\tgoto error;\n\n\tif (symbol) {\n\t\ttk->symbol = kstrdup(symbol, GFP_KERNEL);\n\t\tif (!tk->symbol)\n\t\t\tgoto error;\n\t\ttk->rp.kp.symbol_name = tk->symbol;\n\t\ttk->rp.kp.offset = offs;\n\t} else\n\t\ttk->rp.kp.addr = addr;\n\n\tif (is_return)\n\t\ttk->rp.handler = kretprobe_dispatcher;\n\telse\n\t\ttk->rp.kp.pre_handler = kprobe_dispatcher;\n\n\ttk->rp.maxactive = maxactive;\n\tINIT_HLIST_NODE(&tk->rp.kp.hlist);\n\tINIT_LIST_HEAD(&tk->rp.kp.list);\n\n\tret = trace_probe_init(&tk->tp, event, group, false);\n\tif (ret < 0)\n\t\tgoto error;\n\n\tdyn_event_init(&tk->devent, &trace_kprobe_ops);\n\treturn tk;\nerror:\n\tfree_trace_kprobe(tk);\n\treturn ERR_PTR(ret);\n}\n\nstatic struct trace_kprobe *find_trace_kprobe(const char *event,\n\t\t\t\t\t      const char *group)\n{\n\tstruct dyn_event *pos;\n\tstruct trace_kprobe *tk;\n\n\tfor_each_trace_kprobe(tk, pos)\n\t\tif (strcmp(trace_probe_name(&tk->tp), event) == 0 &&\n\t\t    strcmp(trace_probe_group_name(&tk->tp), group) == 0)\n\t\t\treturn tk;\n\treturn NULL;\n}\n\nstatic inline int __enable_trace_kprobe(struct trace_kprobe *tk)\n{\n\tint ret = 0;\n\n\tif (trace_kprobe_is_registered(tk) && !trace_kprobe_has_gone(tk)) {\n\t\tif (trace_kprobe_is_return(tk))\n\t\t\tret = enable_kretprobe(&tk->rp);\n\t\telse\n\t\t\tret = enable_kprobe(&tk->rp.kp);\n\t}\n\n\treturn ret;\n}\n\nstatic void __disable_trace_kprobe(struct trace_probe *tp)\n{\n\tstruct trace_kprobe *tk;\n\n\tlist_for_each_entry(tk, trace_probe_probe_list(tp), tp.list) {\n\t\tif (!trace_kprobe_is_registered(tk))\n\t\t\tcontinue;\n\t\tif (trace_kprobe_is_return(tk))\n\t\t\tdisable_kretprobe(&tk->rp);\n\t\telse\n\t\t\tdisable_kprobe(&tk->rp.kp);\n\t}\n}\n\n \nstatic int enable_trace_kprobe(struct trace_event_call *call,\n\t\t\t\tstruct trace_event_file *file)\n{\n\tstruct trace_probe *tp;\n\tstruct trace_kprobe *tk;\n\tbool enabled;\n\tint ret = 0;\n\n\ttp = trace_probe_primary_from_call(call);\n\tif (WARN_ON_ONCE(!tp))\n\t\treturn -ENODEV;\n\tenabled = trace_probe_is_enabled(tp);\n\n\t \n\tif (file) {\n\t\tret = trace_probe_add_file(tp, file);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else\n\t\ttrace_probe_set_flag(tp, TP_FLAG_PROFILE);\n\n\tif (enabled)\n\t\treturn 0;\n\n\tlist_for_each_entry(tk, trace_probe_probe_list(tp), tp.list) {\n\t\tif (trace_kprobe_has_gone(tk))\n\t\t\tcontinue;\n\t\tret = __enable_trace_kprobe(tk);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tenabled = true;\n\t}\n\n\tif (ret) {\n\t\t \n\t\tif (enabled)\n\t\t\t__disable_trace_kprobe(tp);\n\t\tif (file)\n\t\t\ttrace_probe_remove_file(tp, file);\n\t\telse\n\t\t\ttrace_probe_clear_flag(tp, TP_FLAG_PROFILE);\n\t}\n\n\treturn ret;\n}\n\n \nstatic int disable_trace_kprobe(struct trace_event_call *call,\n\t\t\t\tstruct trace_event_file *file)\n{\n\tstruct trace_probe *tp;\n\n\ttp = trace_probe_primary_from_call(call);\n\tif (WARN_ON_ONCE(!tp))\n\t\treturn -ENODEV;\n\n\tif (file) {\n\t\tif (!trace_probe_get_file_link(tp, file))\n\t\t\treturn -ENOENT;\n\t\tif (!trace_probe_has_single_file(tp))\n\t\t\tgoto out;\n\t\ttrace_probe_clear_flag(tp, TP_FLAG_TRACE);\n\t} else\n\t\ttrace_probe_clear_flag(tp, TP_FLAG_PROFILE);\n\n\tif (!trace_probe_is_enabled(tp))\n\t\t__disable_trace_kprobe(tp);\n\n out:\n\tif (file)\n\t\t \n\t\ttrace_probe_remove_file(tp, file);\n\n\treturn 0;\n}\n\n#if defined(CONFIG_DYNAMIC_FTRACE) && \\\n\t!defined(CONFIG_KPROBE_EVENTS_ON_NOTRACE)\nstatic bool __within_notrace_func(unsigned long addr)\n{\n\tunsigned long offset, size;\n\n\tif (!addr || !kallsyms_lookup_size_offset(addr, &size, &offset))\n\t\treturn false;\n\n\t \n\taddr -= offset;\n\n\t \n\treturn !ftrace_location_range(addr, addr + size - 1);\n}\n\nstatic bool within_notrace_func(struct trace_kprobe *tk)\n{\n\tunsigned long addr = trace_kprobe_address(tk);\n\tchar symname[KSYM_NAME_LEN], *p;\n\n\tif (!__within_notrace_func(addr))\n\t\treturn false;\n\n\t \n\tif (!lookup_symbol_name(addr, symname)) {\n\t\tp = strchr(symname, '.');\n\t\tif (!p)\n\t\t\treturn true;\n\t\t*p = '\\0';\n\t\taddr = (unsigned long)kprobe_lookup_name(symname, 0);\n\t\tif (addr)\n\t\t\treturn __within_notrace_func(addr);\n\t}\n\n\treturn true;\n}\n#else\n#define within_notrace_func(tk)\t(false)\n#endif\n\n \nstatic int __register_trace_kprobe(struct trace_kprobe *tk)\n{\n\tint i, ret;\n\n\tret = security_locked_down(LOCKDOWN_KPROBES);\n\tif (ret)\n\t\treturn ret;\n\n\tif (trace_kprobe_is_registered(tk))\n\t\treturn -EINVAL;\n\n\tif (within_notrace_func(tk)) {\n\t\tpr_warn(\"Could not probe notrace function %s\\n\",\n\t\t\ttrace_kprobe_symbol(tk));\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < tk->tp.nr_args; i++) {\n\t\tret = traceprobe_update_arg(&tk->tp.args[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t \n\tif (trace_probe_is_enabled(&tk->tp))\n\t\ttk->rp.kp.flags &= ~KPROBE_FLAG_DISABLED;\n\telse\n\t\ttk->rp.kp.flags |= KPROBE_FLAG_DISABLED;\n\n\tif (trace_kprobe_is_return(tk))\n\t\tret = register_kretprobe(&tk->rp);\n\telse\n\t\tret = register_kprobe(&tk->rp.kp);\n\n\treturn ret;\n}\n\n \nstatic void __unregister_trace_kprobe(struct trace_kprobe *tk)\n{\n\tif (trace_kprobe_is_registered(tk)) {\n\t\tif (trace_kprobe_is_return(tk))\n\t\t\tunregister_kretprobe(&tk->rp);\n\t\telse\n\t\t\tunregister_kprobe(&tk->rp.kp);\n\t\t \n\t\tINIT_HLIST_NODE(&tk->rp.kp.hlist);\n\t\tINIT_LIST_HEAD(&tk->rp.kp.list);\n\t\tif (tk->rp.kp.symbol_name)\n\t\t\ttk->rp.kp.addr = NULL;\n\t}\n}\n\n \nstatic int unregister_trace_kprobe(struct trace_kprobe *tk)\n{\n\t \n\tif (trace_probe_has_sibling(&tk->tp))\n\t\tgoto unreg;\n\n\t \n\tif (trace_probe_is_enabled(&tk->tp))\n\t\treturn -EBUSY;\n\n\t \n\tif (trace_event_dyn_busy(trace_probe_event_call(&tk->tp)))\n\t\treturn -EBUSY;\n\n\t \n\tif (unregister_kprobe_event(tk))\n\t\treturn -EBUSY;\n\nunreg:\n\t__unregister_trace_kprobe(tk);\n\tdyn_event_remove(&tk->devent);\n\ttrace_probe_unlink(&tk->tp);\n\n\treturn 0;\n}\n\nstatic bool trace_kprobe_has_same_kprobe(struct trace_kprobe *orig,\n\t\t\t\t\t struct trace_kprobe *comp)\n{\n\tstruct trace_probe_event *tpe = orig->tp.event;\n\tint i;\n\n\tlist_for_each_entry(orig, &tpe->probes, tp.list) {\n\t\tif (strcmp(trace_kprobe_symbol(orig),\n\t\t\t   trace_kprobe_symbol(comp)) ||\n\t\t    trace_kprobe_offset(orig) != trace_kprobe_offset(comp))\n\t\t\tcontinue;\n\n\t\t \n\t\tfor (i = 0; i < orig->tp.nr_args; i++) {\n\t\t\tif (strcmp(orig->tp.args[i].comm,\n\t\t\t\t   comp->tp.args[i].comm))\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (i == orig->tp.nr_args)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int append_trace_kprobe(struct trace_kprobe *tk, struct trace_kprobe *to)\n{\n\tint ret;\n\n\tret = trace_probe_compare_arg_type(&tk->tp, &to->tp);\n\tif (ret) {\n\t\t \n\t\ttrace_probe_log_set_index(ret + 1);\n\t\ttrace_probe_log_err(0, DIFF_ARG_TYPE);\n\t\treturn -EEXIST;\n\t}\n\tif (trace_kprobe_has_same_kprobe(to, tk)) {\n\t\ttrace_probe_log_set_index(0);\n\t\ttrace_probe_log_err(0, SAME_PROBE);\n\t\treturn -EEXIST;\n\t}\n\n\t \n\tret = trace_probe_append(&tk->tp, &to->tp);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = __register_trace_kprobe(tk);\n\tif (ret == -ENOENT && !trace_kprobe_module_exist(tk)) {\n\t\tpr_warn(\"This probe might be able to register after target module is loaded. Continue.\\n\");\n\t\tret = 0;\n\t}\n\n\tif (ret)\n\t\ttrace_probe_unlink(&tk->tp);\n\telse\n\t\tdyn_event_add(&tk->devent, trace_probe_event_call(&tk->tp));\n\n\treturn ret;\n}\n\n \nstatic int register_trace_kprobe(struct trace_kprobe *tk)\n{\n\tstruct trace_kprobe *old_tk;\n\tint ret;\n\n\tmutex_lock(&event_mutex);\n\n\told_tk = find_trace_kprobe(trace_probe_name(&tk->tp),\n\t\t\t\t   trace_probe_group_name(&tk->tp));\n\tif (old_tk) {\n\t\tif (trace_kprobe_is_return(tk) != trace_kprobe_is_return(old_tk)) {\n\t\t\ttrace_probe_log_set_index(0);\n\t\t\ttrace_probe_log_err(0, DIFF_PROBE_TYPE);\n\t\t\tret = -EEXIST;\n\t\t} else {\n\t\t\tret = append_trace_kprobe(tk, old_tk);\n\t\t}\n\t\tgoto end;\n\t}\n\n\t \n\tret = register_kprobe_event(tk);\n\tif (ret) {\n\t\tif (ret == -EEXIST) {\n\t\t\ttrace_probe_log_set_index(0);\n\t\t\ttrace_probe_log_err(0, EVENT_EXIST);\n\t\t} else\n\t\t\tpr_warn(\"Failed to register probe event(%d)\\n\", ret);\n\t\tgoto end;\n\t}\n\n\t \n\tret = __register_trace_kprobe(tk);\n\tif (ret == -ENOENT && !trace_kprobe_module_exist(tk)) {\n\t\tpr_warn(\"This probe might be able to register after target module is loaded. Continue.\\n\");\n\t\tret = 0;\n\t}\n\n\tif (ret < 0)\n\t\tunregister_kprobe_event(tk);\n\telse\n\t\tdyn_event_add(&tk->devent, trace_probe_event_call(&tk->tp));\n\nend:\n\tmutex_unlock(&event_mutex);\n\treturn ret;\n}\n\n \nstatic int trace_kprobe_module_callback(struct notifier_block *nb,\n\t\t\t\t       unsigned long val, void *data)\n{\n\tstruct module *mod = data;\n\tstruct dyn_event *pos;\n\tstruct trace_kprobe *tk;\n\tint ret;\n\n\tif (val != MODULE_STATE_COMING)\n\t\treturn NOTIFY_DONE;\n\n\t \n\tmutex_lock(&event_mutex);\n\tfor_each_trace_kprobe(tk, pos) {\n\t\tif (trace_kprobe_within_module(tk, mod)) {\n\t\t\t \n\t\t\t__unregister_trace_kprobe(tk);\n\t\t\tret = __register_trace_kprobe(tk);\n\t\t\tif (ret)\n\t\t\t\tpr_warn(\"Failed to re-register probe %s on %s: %d\\n\",\n\t\t\t\t\ttrace_probe_name(&tk->tp),\n\t\t\t\t\tmodule_name(mod), ret);\n\t\t}\n\t}\n\tmutex_unlock(&event_mutex);\n\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block trace_kprobe_module_nb = {\n\t.notifier_call = trace_kprobe_module_callback,\n\t.priority = 1\t \n};\n\nstatic int count_symbols(void *data, unsigned long unused)\n{\n\tunsigned int *count = data;\n\n\t(*count)++;\n\n\treturn 0;\n}\n\nstruct sym_count_ctx {\n\tunsigned int count;\n\tconst char *name;\n};\n\nstatic int count_mod_symbols(void *data, const char *name, unsigned long unused)\n{\n\tstruct sym_count_ctx *ctx = data;\n\n\tif (strcmp(name, ctx->name) == 0)\n\t\tctx->count++;\n\n\treturn 0;\n}\n\nstatic unsigned int number_of_same_symbols(char *func_name)\n{\n\tstruct sym_count_ctx ctx = { .count = 0, .name = func_name };\n\n\tkallsyms_on_each_match_symbol(count_symbols, func_name, &ctx.count);\n\n\tmodule_kallsyms_on_each_symbol(NULL, count_mod_symbols, &ctx);\n\n\treturn ctx.count;\n}\n\nstatic int __trace_kprobe_create(int argc, const char *argv[])\n{\n\t \n\tstruct trace_kprobe *tk = NULL;\n\tint i, len, new_argc = 0, ret = 0;\n\tbool is_return = false;\n\tchar *symbol = NULL, *tmp = NULL;\n\tconst char **new_argv = NULL;\n\tconst char *event = NULL, *group = KPROBE_EVENT_SYSTEM;\n\tenum probe_print_type ptype;\n\tint maxactive = 0;\n\tlong offset = 0;\n\tvoid *addr = NULL;\n\tchar buf[MAX_EVENT_NAME_LEN];\n\tchar gbuf[MAX_EVENT_NAME_LEN];\n\tchar abuf[MAX_BTF_ARGS_LEN];\n\tstruct traceprobe_parse_context ctx = { .flags = TPARG_FL_KERNEL };\n\n\tswitch (argv[0][0]) {\n\tcase 'r':\n\t\tis_return = true;\n\t\tbreak;\n\tcase 'p':\n\t\tbreak;\n\tdefault:\n\t\treturn -ECANCELED;\n\t}\n\tif (argc < 2)\n\t\treturn -ECANCELED;\n\n\ttrace_probe_log_init(\"trace_kprobe\", argc, argv);\n\n\tevent = strchr(&argv[0][1], ':');\n\tif (event)\n\t\tevent++;\n\n\tif (isdigit(argv[0][1])) {\n\t\tif (!is_return) {\n\t\t\ttrace_probe_log_err(1, BAD_MAXACT_TYPE);\n\t\t\tgoto parse_error;\n\t\t}\n\t\tif (event)\n\t\t\tlen = event - &argv[0][1] - 1;\n\t\telse\n\t\t\tlen = strlen(&argv[0][1]);\n\t\tif (len > MAX_EVENT_NAME_LEN - 1) {\n\t\t\ttrace_probe_log_err(1, BAD_MAXACT);\n\t\t\tgoto parse_error;\n\t\t}\n\t\tmemcpy(buf, &argv[0][1], len);\n\t\tbuf[len] = '\\0';\n\t\tret = kstrtouint(buf, 0, &maxactive);\n\t\tif (ret || !maxactive) {\n\t\t\ttrace_probe_log_err(1, BAD_MAXACT);\n\t\t\tgoto parse_error;\n\t\t}\n\t\t \n\t\tif (maxactive > KRETPROBE_MAXACTIVE_MAX) {\n\t\t\ttrace_probe_log_err(1, MAXACT_TOO_BIG);\n\t\t\tgoto parse_error;\n\t\t}\n\t}\n\n\t \n\tif (kstrtoul(argv[1], 0, (unsigned long *)&addr)) {\n\t\ttrace_probe_log_set_index(1);\n\t\t \n\t\tif (strchr(argv[1], '/') && strchr(argv[1], ':')) {\n\t\t\tret = -ECANCELED;\n\t\t\tgoto error;\n\t\t}\n\t\t \n\t\tsymbol = kstrdup(argv[1], GFP_KERNEL);\n\t\tif (!symbol)\n\t\t\treturn -ENOMEM;\n\n\t\ttmp = strchr(symbol, '%');\n\t\tif (tmp) {\n\t\t\tif (!strcmp(tmp, \"%return\")) {\n\t\t\t\t*tmp = '\\0';\n\t\t\t\tis_return = true;\n\t\t\t} else {\n\t\t\t\ttrace_probe_log_err(tmp - symbol, BAD_ADDR_SUFFIX);\n\t\t\t\tgoto parse_error;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tret = traceprobe_split_symbol_offset(symbol, &offset);\n\t\tif (ret || offset < 0 || offset > UINT_MAX) {\n\t\t\ttrace_probe_log_err(0, BAD_PROBE_ADDR);\n\t\t\tgoto parse_error;\n\t\t}\n\t\tif (is_return)\n\t\t\tctx.flags |= TPARG_FL_RETURN;\n\t\tret = kprobe_on_func_entry(NULL, symbol, offset);\n\t\tif (ret == 0 && !is_return)\n\t\t\tctx.flags |= TPARG_FL_FENTRY;\n\t\t \n\t\tif (ret == -EINVAL && is_return) {\n\t\t\ttrace_probe_log_err(0, BAD_RETPROBE);\n\t\t\tgoto parse_error;\n\t\t}\n\t}\n\n\tif (symbol && !strchr(symbol, ':')) {\n\t\tunsigned int count;\n\n\t\tcount = number_of_same_symbols(symbol);\n\t\tif (count > 1) {\n\t\t\t \n\t\t\ttrace_probe_log_err(0, NON_UNIQ_SYMBOL);\n\t\t\tret = -EADDRNOTAVAIL;\n\n\t\t\tgoto error;\n\t\t} else if (count == 0) {\n\t\t\t \n\t\t\ttrace_probe_log_err(0, BAD_PROBE_ADDR);\n\t\t\tret = -ENOENT;\n\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\ttrace_probe_log_set_index(0);\n\tif (event) {\n\t\tret = traceprobe_parse_event_name(&event, &group, gbuf,\n\t\t\t\t\t\t  event - argv[0]);\n\t\tif (ret)\n\t\t\tgoto parse_error;\n\t}\n\n\tif (!event) {\n\t\t \n\t\tif (symbol)\n\t\t\tsnprintf(buf, MAX_EVENT_NAME_LEN, \"%c_%s_%ld\",\n\t\t\t\t is_return ? 'r' : 'p', symbol, offset);\n\t\telse\n\t\t\tsnprintf(buf, MAX_EVENT_NAME_LEN, \"%c_0x%p\",\n\t\t\t\t is_return ? 'r' : 'p', addr);\n\t\tsanitize_event_name(buf);\n\t\tevent = buf;\n\t}\n\n\targc -= 2; argv += 2;\n\tctx.funcname = symbol;\n\tnew_argv = traceprobe_expand_meta_args(argc, argv, &new_argc,\n\t\t\t\t\t       abuf, MAX_BTF_ARGS_LEN, &ctx);\n\tif (IS_ERR(new_argv)) {\n\t\tret = PTR_ERR(new_argv);\n\t\tnew_argv = NULL;\n\t\tgoto out;\n\t}\n\tif (new_argv) {\n\t\targc = new_argc;\n\t\targv = new_argv;\n\t}\n\n\t \n\ttk = alloc_trace_kprobe(group, event, addr, symbol, offset, maxactive,\n\t\t\t\targc, is_return);\n\tif (IS_ERR(tk)) {\n\t\tret = PTR_ERR(tk);\n\t\t \n\t\tWARN_ON_ONCE(ret != -ENOMEM);\n\t\tgoto out;\t \n\t}\n\n\t \n\tfor (i = 0; i < argc && i < MAX_TRACE_ARGS; i++) {\n\t\ttrace_probe_log_set_index(i + 2);\n\t\tctx.offset = 0;\n\t\tret = traceprobe_parse_probe_arg(&tk->tp, i, argv[i], &ctx);\n\t\tif (ret)\n\t\t\tgoto error;\t \n\t}\n\n\tptype = is_return ? PROBE_PRINT_RETURN : PROBE_PRINT_NORMAL;\n\tret = traceprobe_set_print_fmt(&tk->tp, ptype);\n\tif (ret < 0)\n\t\tgoto error;\n\n\tret = register_trace_kprobe(tk);\n\tif (ret) {\n\t\ttrace_probe_log_set_index(1);\n\t\tif (ret == -EILSEQ)\n\t\t\ttrace_probe_log_err(0, BAD_INSN_BNDRY);\n\t\telse if (ret == -ENOENT)\n\t\t\ttrace_probe_log_err(0, BAD_PROBE_ADDR);\n\t\telse if (ret != -ENOMEM && ret != -EEXIST)\n\t\t\ttrace_probe_log_err(0, FAIL_REG_PROBE);\n\t\tgoto error;\n\t}\n\nout:\n\ttraceprobe_finish_parse(&ctx);\n\ttrace_probe_log_clear();\n\tkfree(new_argv);\n\tkfree(symbol);\n\treturn ret;\n\nparse_error:\n\tret = -EINVAL;\nerror:\n\tfree_trace_kprobe(tk);\n\tgoto out;\n}\n\nstatic int trace_kprobe_create(const char *raw_command)\n{\n\treturn trace_probe_create(raw_command, __trace_kprobe_create);\n}\n\nstatic int create_or_delete_trace_kprobe(const char *raw_command)\n{\n\tint ret;\n\n\tif (raw_command[0] == '-')\n\t\treturn dyn_event_release(raw_command, &trace_kprobe_ops);\n\n\tret = trace_kprobe_create(raw_command);\n\treturn ret == -ECANCELED ? -EINVAL : ret;\n}\n\nstatic int trace_kprobe_run_command(struct dynevent_cmd *cmd)\n{\n\treturn create_or_delete_trace_kprobe(cmd->seq.buffer);\n}\n\n \nvoid kprobe_event_cmd_init(struct dynevent_cmd *cmd, char *buf, int maxlen)\n{\n\tdynevent_cmd_init(cmd, buf, maxlen, DYNEVENT_TYPE_KPROBE,\n\t\t\t  trace_kprobe_run_command);\n}\nEXPORT_SYMBOL_GPL(kprobe_event_cmd_init);\n\n \nint __kprobe_event_gen_cmd_start(struct dynevent_cmd *cmd, bool kretprobe,\n\t\t\t\t const char *name, const char *loc, ...)\n{\n\tchar buf[MAX_EVENT_NAME_LEN];\n\tstruct dynevent_arg arg;\n\tva_list args;\n\tint ret;\n\n\tif (cmd->type != DYNEVENT_TYPE_KPROBE)\n\t\treturn -EINVAL;\n\n\tif (!loc)\n\t\treturn -EINVAL;\n\n\tif (kretprobe)\n\t\tsnprintf(buf, MAX_EVENT_NAME_LEN, \"r:kprobes/%s\", name);\n\telse\n\t\tsnprintf(buf, MAX_EVENT_NAME_LEN, \"p:kprobes/%s\", name);\n\n\tret = dynevent_str_add(cmd, buf);\n\tif (ret)\n\t\treturn ret;\n\n\tdynevent_arg_init(&arg, 0);\n\targ.str = loc;\n\tret = dynevent_arg_add(cmd, &arg, NULL);\n\tif (ret)\n\t\treturn ret;\n\n\tva_start(args, loc);\n\tfor (;;) {\n\t\tconst char *field;\n\n\t\tfield = va_arg(args, const char *);\n\t\tif (!field)\n\t\t\tbreak;\n\n\t\tif (++cmd->n_fields > MAX_TRACE_ARGS) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\targ.str = field;\n\t\tret = dynevent_arg_add(cmd, &arg, NULL);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\tva_end(args);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(__kprobe_event_gen_cmd_start);\n\n \nint __kprobe_event_add_fields(struct dynevent_cmd *cmd, ...)\n{\n\tstruct dynevent_arg arg;\n\tva_list args;\n\tint ret = 0;\n\n\tif (cmd->type != DYNEVENT_TYPE_KPROBE)\n\t\treturn -EINVAL;\n\n\tdynevent_arg_init(&arg, 0);\n\n\tva_start(args, cmd);\n\tfor (;;) {\n\t\tconst char *field;\n\n\t\tfield = va_arg(args, const char *);\n\t\tif (!field)\n\t\t\tbreak;\n\n\t\tif (++cmd->n_fields > MAX_TRACE_ARGS) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\targ.str = field;\n\t\tret = dynevent_arg_add(cmd, &arg, NULL);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\tva_end(args);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(__kprobe_event_add_fields);\n\n \nint kprobe_event_delete(const char *name)\n{\n\tchar buf[MAX_EVENT_NAME_LEN];\n\n\tsnprintf(buf, MAX_EVENT_NAME_LEN, \"-:%s\", name);\n\n\treturn create_or_delete_trace_kprobe(buf);\n}\nEXPORT_SYMBOL_GPL(kprobe_event_delete);\n\nstatic int trace_kprobe_release(struct dyn_event *ev)\n{\n\tstruct trace_kprobe *tk = to_trace_kprobe(ev);\n\tint ret = unregister_trace_kprobe(tk);\n\n\tif (!ret)\n\t\tfree_trace_kprobe(tk);\n\treturn ret;\n}\n\nstatic int trace_kprobe_show(struct seq_file *m, struct dyn_event *ev)\n{\n\tstruct trace_kprobe *tk = to_trace_kprobe(ev);\n\tint i;\n\n\tseq_putc(m, trace_kprobe_is_return(tk) ? 'r' : 'p');\n\tif (trace_kprobe_is_return(tk) && tk->rp.maxactive)\n\t\tseq_printf(m, \"%d\", tk->rp.maxactive);\n\tseq_printf(m, \":%s/%s\", trace_probe_group_name(&tk->tp),\n\t\t\t\ttrace_probe_name(&tk->tp));\n\n\tif (!tk->symbol)\n\t\tseq_printf(m, \" 0x%p\", tk->rp.kp.addr);\n\telse if (tk->rp.kp.offset)\n\t\tseq_printf(m, \" %s+%u\", trace_kprobe_symbol(tk),\n\t\t\t   tk->rp.kp.offset);\n\telse\n\t\tseq_printf(m, \" %s\", trace_kprobe_symbol(tk));\n\n\tfor (i = 0; i < tk->tp.nr_args; i++)\n\t\tseq_printf(m, \" %s=%s\", tk->tp.args[i].name, tk->tp.args[i].comm);\n\tseq_putc(m, '\\n');\n\n\treturn 0;\n}\n\nstatic int probes_seq_show(struct seq_file *m, void *v)\n{\n\tstruct dyn_event *ev = v;\n\n\tif (!is_trace_kprobe(ev))\n\t\treturn 0;\n\n\treturn trace_kprobe_show(m, ev);\n}\n\nstatic const struct seq_operations probes_seq_op = {\n\t.start  = dyn_event_seq_start,\n\t.next   = dyn_event_seq_next,\n\t.stop   = dyn_event_seq_stop,\n\t.show   = probes_seq_show\n};\n\nstatic int probes_open(struct inode *inode, struct file *file)\n{\n\tint ret;\n\n\tret = security_locked_down(LOCKDOWN_TRACEFS);\n\tif (ret)\n\t\treturn ret;\n\n\tif ((file->f_mode & FMODE_WRITE) && (file->f_flags & O_TRUNC)) {\n\t\tret = dyn_events_release_all(&trace_kprobe_ops);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn seq_open(file, &probes_seq_op);\n}\n\nstatic ssize_t probes_write(struct file *file, const char __user *buffer,\n\t\t\t    size_t count, loff_t *ppos)\n{\n\treturn trace_parse_run_command(file, buffer, count, ppos,\n\t\t\t\t       create_or_delete_trace_kprobe);\n}\n\nstatic const struct file_operations kprobe_events_ops = {\n\t.owner          = THIS_MODULE,\n\t.open           = probes_open,\n\t.read           = seq_read,\n\t.llseek         = seq_lseek,\n\t.release        = seq_release,\n\t.write\t\t= probes_write,\n};\n\n \nstatic int probes_profile_seq_show(struct seq_file *m, void *v)\n{\n\tstruct dyn_event *ev = v;\n\tstruct trace_kprobe *tk;\n\tunsigned long nmissed;\n\n\tif (!is_trace_kprobe(ev))\n\t\treturn 0;\n\n\ttk = to_trace_kprobe(ev);\n\tnmissed = trace_kprobe_is_return(tk) ?\n\t\ttk->rp.kp.nmissed + tk->rp.nmissed : tk->rp.kp.nmissed;\n\tseq_printf(m, \"  %-44s %15lu %15lu\\n\",\n\t\t   trace_probe_name(&tk->tp),\n\t\t   trace_kprobe_nhit(tk),\n\t\t   nmissed);\n\n\treturn 0;\n}\n\nstatic const struct seq_operations profile_seq_op = {\n\t.start  = dyn_event_seq_start,\n\t.next   = dyn_event_seq_next,\n\t.stop   = dyn_event_seq_stop,\n\t.show   = probes_profile_seq_show\n};\n\nstatic int profile_open(struct inode *inode, struct file *file)\n{\n\tint ret;\n\n\tret = security_locked_down(LOCKDOWN_TRACEFS);\n\tif (ret)\n\t\treturn ret;\n\n\treturn seq_open(file, &profile_seq_op);\n}\n\nstatic const struct file_operations kprobe_profile_ops = {\n\t.owner          = THIS_MODULE,\n\t.open           = profile_open,\n\t.read           = seq_read,\n\t.llseek         = seq_lseek,\n\t.release        = seq_release,\n};\n\n \nstatic int\nprocess_fetch_insn(struct fetch_insn *code, void *rec, void *dest,\n\t\t   void *base)\n{\n\tstruct pt_regs *regs = rec;\n\tunsigned long val;\n\tint ret;\n\nretry:\n\t \n\tswitch (code->op) {\n\tcase FETCH_OP_REG:\n\t\tval = regs_get_register(regs, code->param);\n\t\tbreak;\n\tcase FETCH_OP_STACK:\n\t\tval = regs_get_kernel_stack_nth(regs, code->param);\n\t\tbreak;\n\tcase FETCH_OP_STACKP:\n\t\tval = kernel_stack_pointer(regs);\n\t\tbreak;\n\tcase FETCH_OP_RETVAL:\n\t\tval = regs_return_value(regs);\n\t\tbreak;\n#ifdef CONFIG_HAVE_FUNCTION_ARG_ACCESS_API\n\tcase FETCH_OP_ARG:\n\t\tval = regs_get_kernel_argument(regs, code->param);\n\t\tbreak;\n#endif\n\tcase FETCH_NOP_SYMBOL:\t \n\t\tcode++;\n\t\tgoto retry;\n\tdefault:\n\t\tret = process_common_fetch_insn(code, &val);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tcode++;\n\n\treturn process_fetch_insn_bottom(code, val, dest, base);\n}\nNOKPROBE_SYMBOL(process_fetch_insn)\n\n \nstatic nokprobe_inline void\n__kprobe_trace_func(struct trace_kprobe *tk, struct pt_regs *regs,\n\t\t    struct trace_event_file *trace_file)\n{\n\tstruct kprobe_trace_entry_head *entry;\n\tstruct trace_event_call *call = trace_probe_event_call(&tk->tp);\n\tstruct trace_event_buffer fbuffer;\n\tint dsize;\n\n\tWARN_ON(call != trace_file->event_call);\n\n\tif (trace_trigger_soft_disabled(trace_file))\n\t\treturn;\n\n\tdsize = __get_data_size(&tk->tp, regs);\n\n\tentry = trace_event_buffer_reserve(&fbuffer, trace_file,\n\t\t\t\t\t   sizeof(*entry) + tk->tp.size + dsize);\n\tif (!entry)\n\t\treturn;\n\n\tfbuffer.regs = regs;\n\tentry->ip = (unsigned long)tk->rp.kp.addr;\n\tstore_trace_args(&entry[1], &tk->tp, regs, sizeof(*entry), dsize);\n\n\ttrace_event_buffer_commit(&fbuffer);\n}\n\nstatic void\nkprobe_trace_func(struct trace_kprobe *tk, struct pt_regs *regs)\n{\n\tstruct event_file_link *link;\n\n\ttrace_probe_for_each_link_rcu(link, &tk->tp)\n\t\t__kprobe_trace_func(tk, regs, link->file);\n}\nNOKPROBE_SYMBOL(kprobe_trace_func);\n\n \nstatic nokprobe_inline void\n__kretprobe_trace_func(struct trace_kprobe *tk, struct kretprobe_instance *ri,\n\t\t       struct pt_regs *regs,\n\t\t       struct trace_event_file *trace_file)\n{\n\tstruct kretprobe_trace_entry_head *entry;\n\tstruct trace_event_buffer fbuffer;\n\tstruct trace_event_call *call = trace_probe_event_call(&tk->tp);\n\tint dsize;\n\n\tWARN_ON(call != trace_file->event_call);\n\n\tif (trace_trigger_soft_disabled(trace_file))\n\t\treturn;\n\n\tdsize = __get_data_size(&tk->tp, regs);\n\n\tentry = trace_event_buffer_reserve(&fbuffer, trace_file,\n\t\t\t\t\t   sizeof(*entry) + tk->tp.size + dsize);\n\tif (!entry)\n\t\treturn;\n\n\tfbuffer.regs = regs;\n\tentry->func = (unsigned long)tk->rp.kp.addr;\n\tentry->ret_ip = get_kretprobe_retaddr(ri);\n\tstore_trace_args(&entry[1], &tk->tp, regs, sizeof(*entry), dsize);\n\n\ttrace_event_buffer_commit(&fbuffer);\n}\n\nstatic void\nkretprobe_trace_func(struct trace_kprobe *tk, struct kretprobe_instance *ri,\n\t\t     struct pt_regs *regs)\n{\n\tstruct event_file_link *link;\n\n\ttrace_probe_for_each_link_rcu(link, &tk->tp)\n\t\t__kretprobe_trace_func(tk, ri, regs, link->file);\n}\nNOKPROBE_SYMBOL(kretprobe_trace_func);\n\n \nstatic enum print_line_t\nprint_kprobe_event(struct trace_iterator *iter, int flags,\n\t\t   struct trace_event *event)\n{\n\tstruct kprobe_trace_entry_head *field;\n\tstruct trace_seq *s = &iter->seq;\n\tstruct trace_probe *tp;\n\n\tfield = (struct kprobe_trace_entry_head *)iter->ent;\n\ttp = trace_probe_primary_from_call(\n\t\tcontainer_of(event, struct trace_event_call, event));\n\tif (WARN_ON_ONCE(!tp))\n\t\tgoto out;\n\n\ttrace_seq_printf(s, \"%s: (\", trace_probe_name(tp));\n\n\tif (!seq_print_ip_sym(s, field->ip, flags | TRACE_ITER_SYM_OFFSET))\n\t\tgoto out;\n\n\ttrace_seq_putc(s, ')');\n\n\tif (trace_probe_print_args(s, tp->args, tp->nr_args,\n\t\t\t     (u8 *)&field[1], field) < 0)\n\t\tgoto out;\n\n\ttrace_seq_putc(s, '\\n');\n out:\n\treturn trace_handle_return(s);\n}\n\nstatic enum print_line_t\nprint_kretprobe_event(struct trace_iterator *iter, int flags,\n\t\t      struct trace_event *event)\n{\n\tstruct kretprobe_trace_entry_head *field;\n\tstruct trace_seq *s = &iter->seq;\n\tstruct trace_probe *tp;\n\n\tfield = (struct kretprobe_trace_entry_head *)iter->ent;\n\ttp = trace_probe_primary_from_call(\n\t\tcontainer_of(event, struct trace_event_call, event));\n\tif (WARN_ON_ONCE(!tp))\n\t\tgoto out;\n\n\ttrace_seq_printf(s, \"%s: (\", trace_probe_name(tp));\n\n\tif (!seq_print_ip_sym(s, field->ret_ip, flags | TRACE_ITER_SYM_OFFSET))\n\t\tgoto out;\n\n\ttrace_seq_puts(s, \" <- \");\n\n\tif (!seq_print_ip_sym(s, field->func, flags & ~TRACE_ITER_SYM_OFFSET))\n\t\tgoto out;\n\n\ttrace_seq_putc(s, ')');\n\n\tif (trace_probe_print_args(s, tp->args, tp->nr_args,\n\t\t\t     (u8 *)&field[1], field) < 0)\n\t\tgoto out;\n\n\ttrace_seq_putc(s, '\\n');\n\n out:\n\treturn trace_handle_return(s);\n}\n\n\nstatic int kprobe_event_define_fields(struct trace_event_call *event_call)\n{\n\tint ret;\n\tstruct kprobe_trace_entry_head field;\n\tstruct trace_probe *tp;\n\n\ttp = trace_probe_primary_from_call(event_call);\n\tif (WARN_ON_ONCE(!tp))\n\t\treturn -ENOENT;\n\n\tDEFINE_FIELD(unsigned long, ip, FIELD_STRING_IP, 0);\n\n\treturn traceprobe_define_arg_fields(event_call, sizeof(field), tp);\n}\n\nstatic int kretprobe_event_define_fields(struct trace_event_call *event_call)\n{\n\tint ret;\n\tstruct kretprobe_trace_entry_head field;\n\tstruct trace_probe *tp;\n\n\ttp = trace_probe_primary_from_call(event_call);\n\tif (WARN_ON_ONCE(!tp))\n\t\treturn -ENOENT;\n\n\tDEFINE_FIELD(unsigned long, func, FIELD_STRING_FUNC, 0);\n\tDEFINE_FIELD(unsigned long, ret_ip, FIELD_STRING_RETIP, 0);\n\n\treturn traceprobe_define_arg_fields(event_call, sizeof(field), tp);\n}\n\n#ifdef CONFIG_PERF_EVENTS\n\n \nstatic int\nkprobe_perf_func(struct trace_kprobe *tk, struct pt_regs *regs)\n{\n\tstruct trace_event_call *call = trace_probe_event_call(&tk->tp);\n\tstruct kprobe_trace_entry_head *entry;\n\tstruct hlist_head *head;\n\tint size, __size, dsize;\n\tint rctx;\n\n\tif (bpf_prog_array_valid(call)) {\n\t\tunsigned long orig_ip = instruction_pointer(regs);\n\t\tint ret;\n\n\t\tret = trace_call_bpf(call, regs);\n\n\t\t \n\t\tif (orig_ip != instruction_pointer(regs))\n\t\t\treturn 1;\n\t\tif (!ret)\n\t\t\treturn 0;\n\t}\n\n\thead = this_cpu_ptr(call->perf_events);\n\tif (hlist_empty(head))\n\t\treturn 0;\n\n\tdsize = __get_data_size(&tk->tp, regs);\n\t__size = sizeof(*entry) + tk->tp.size + dsize;\n\tsize = ALIGN(__size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\tentry = perf_trace_buf_alloc(size, NULL, &rctx);\n\tif (!entry)\n\t\treturn 0;\n\n\tentry->ip = (unsigned long)tk->rp.kp.addr;\n\tmemset(&entry[1], 0, dsize);\n\tstore_trace_args(&entry[1], &tk->tp, regs, sizeof(*entry), dsize);\n\tperf_trace_buf_submit(entry, size, rctx, call->event.type, 1, regs,\n\t\t\t      head, NULL);\n\treturn 0;\n}\nNOKPROBE_SYMBOL(kprobe_perf_func);\n\n \nstatic void\nkretprobe_perf_func(struct trace_kprobe *tk, struct kretprobe_instance *ri,\n\t\t    struct pt_regs *regs)\n{\n\tstruct trace_event_call *call = trace_probe_event_call(&tk->tp);\n\tstruct kretprobe_trace_entry_head *entry;\n\tstruct hlist_head *head;\n\tint size, __size, dsize;\n\tint rctx;\n\n\tif (bpf_prog_array_valid(call) && !trace_call_bpf(call, regs))\n\t\treturn;\n\n\thead = this_cpu_ptr(call->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\tdsize = __get_data_size(&tk->tp, regs);\n\t__size = sizeof(*entry) + tk->tp.size + dsize;\n\tsize = ALIGN(__size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\tentry = perf_trace_buf_alloc(size, NULL, &rctx);\n\tif (!entry)\n\t\treturn;\n\n\tentry->func = (unsigned long)tk->rp.kp.addr;\n\tentry->ret_ip = get_kretprobe_retaddr(ri);\n\tstore_trace_args(&entry[1], &tk->tp, regs, sizeof(*entry), dsize);\n\tperf_trace_buf_submit(entry, size, rctx, call->event.type, 1, regs,\n\t\t\t      head, NULL);\n}\nNOKPROBE_SYMBOL(kretprobe_perf_func);\n\nint bpf_get_kprobe_info(const struct perf_event *event, u32 *fd_type,\n\t\t\tconst char **symbol, u64 *probe_offset,\n\t\t\tu64 *probe_addr, bool perf_type_tracepoint)\n{\n\tconst char *pevent = trace_event_name(event->tp_event);\n\tconst char *group = event->tp_event->class->system;\n\tstruct trace_kprobe *tk;\n\n\tif (perf_type_tracepoint)\n\t\ttk = find_trace_kprobe(pevent, group);\n\telse\n\t\ttk = trace_kprobe_primary_from_call(event->tp_event);\n\tif (!tk)\n\t\treturn -EINVAL;\n\n\t*fd_type = trace_kprobe_is_return(tk) ? BPF_FD_TYPE_KRETPROBE\n\t\t\t\t\t      : BPF_FD_TYPE_KPROBE;\n\t*probe_offset = tk->rp.kp.offset;\n\t*probe_addr = kallsyms_show_value(current_cred()) ?\n\t\t      (unsigned long)tk->rp.kp.addr : 0;\n\t*symbol = tk->symbol;\n\treturn 0;\n}\n#endif\t \n\n \nstatic int kprobe_register(struct trace_event_call *event,\n\t\t\t   enum trace_reg type, void *data)\n{\n\tstruct trace_event_file *file = data;\n\n\tswitch (type) {\n\tcase TRACE_REG_REGISTER:\n\t\treturn enable_trace_kprobe(event, file);\n\tcase TRACE_REG_UNREGISTER:\n\t\treturn disable_trace_kprobe(event, file);\n\n#ifdef CONFIG_PERF_EVENTS\n\tcase TRACE_REG_PERF_REGISTER:\n\t\treturn enable_trace_kprobe(event, NULL);\n\tcase TRACE_REG_PERF_UNREGISTER:\n\t\treturn disable_trace_kprobe(event, NULL);\n\tcase TRACE_REG_PERF_OPEN:\n\tcase TRACE_REG_PERF_CLOSE:\n\tcase TRACE_REG_PERF_ADD:\n\tcase TRACE_REG_PERF_DEL:\n\t\treturn 0;\n#endif\n\t}\n\treturn 0;\n}\n\nstatic int kprobe_dispatcher(struct kprobe *kp, struct pt_regs *regs)\n{\n\tstruct trace_kprobe *tk = container_of(kp, struct trace_kprobe, rp.kp);\n\tint ret = 0;\n\n\traw_cpu_inc(*tk->nhit);\n\n\tif (trace_probe_test_flag(&tk->tp, TP_FLAG_TRACE))\n\t\tkprobe_trace_func(tk, regs);\n#ifdef CONFIG_PERF_EVENTS\n\tif (trace_probe_test_flag(&tk->tp, TP_FLAG_PROFILE))\n\t\tret = kprobe_perf_func(tk, regs);\n#endif\n\treturn ret;\n}\nNOKPROBE_SYMBOL(kprobe_dispatcher);\n\nstatic int\nkretprobe_dispatcher(struct kretprobe_instance *ri, struct pt_regs *regs)\n{\n\tstruct kretprobe *rp = get_kretprobe(ri);\n\tstruct trace_kprobe *tk;\n\n\t \n\tif (unlikely(!rp))\n\t\treturn 0;\n\n\ttk = container_of(rp, struct trace_kprobe, rp);\n\traw_cpu_inc(*tk->nhit);\n\n\tif (trace_probe_test_flag(&tk->tp, TP_FLAG_TRACE))\n\t\tkretprobe_trace_func(tk, ri, regs);\n#ifdef CONFIG_PERF_EVENTS\n\tif (trace_probe_test_flag(&tk->tp, TP_FLAG_PROFILE))\n\t\tkretprobe_perf_func(tk, ri, regs);\n#endif\n\treturn 0;\t \n}\nNOKPROBE_SYMBOL(kretprobe_dispatcher);\n\nstatic struct trace_event_functions kretprobe_funcs = {\n\t.trace\t\t= print_kretprobe_event\n};\n\nstatic struct trace_event_functions kprobe_funcs = {\n\t.trace\t\t= print_kprobe_event\n};\n\nstatic struct trace_event_fields kretprobe_fields_array[] = {\n\t{ .type = TRACE_FUNCTION_TYPE,\n\t  .define_fields = kretprobe_event_define_fields },\n\t{}\n};\n\nstatic struct trace_event_fields kprobe_fields_array[] = {\n\t{ .type = TRACE_FUNCTION_TYPE,\n\t  .define_fields = kprobe_event_define_fields },\n\t{}\n};\n\nstatic inline void init_trace_event_call(struct trace_kprobe *tk)\n{\n\tstruct trace_event_call *call = trace_probe_event_call(&tk->tp);\n\n\tif (trace_kprobe_is_return(tk)) {\n\t\tcall->event.funcs = &kretprobe_funcs;\n\t\tcall->class->fields_array = kretprobe_fields_array;\n\t} else {\n\t\tcall->event.funcs = &kprobe_funcs;\n\t\tcall->class->fields_array = kprobe_fields_array;\n\t}\n\n\tcall->flags = TRACE_EVENT_FL_KPROBE;\n\tcall->class->reg = kprobe_register;\n}\n\nstatic int register_kprobe_event(struct trace_kprobe *tk)\n{\n\tinit_trace_event_call(tk);\n\n\treturn trace_probe_register_event_call(&tk->tp);\n}\n\nstatic int unregister_kprobe_event(struct trace_kprobe *tk)\n{\n\treturn trace_probe_unregister_event_call(&tk->tp);\n}\n\n#ifdef CONFIG_PERF_EVENTS\n\n \nstruct trace_event_call *\ncreate_local_trace_kprobe(char *func, void *addr, unsigned long offs,\n\t\t\t  bool is_return)\n{\n\tenum probe_print_type ptype;\n\tstruct trace_kprobe *tk;\n\tint ret;\n\tchar *event;\n\n\tif (func) {\n\t\tunsigned int count;\n\n\t\tcount = number_of_same_symbols(func);\n\t\tif (count > 1)\n\t\t\t \n\t\t\treturn ERR_PTR(-EADDRNOTAVAIL);\n\t\telse if (count == 0)\n\t\t\t \n\t\t\treturn ERR_PTR(-ENOENT);\n\t}\n\n\t \n\tevent = func ? func : \"DUMMY_EVENT\";\n\n\ttk = alloc_trace_kprobe(KPROBE_EVENT_SYSTEM, event, (void *)addr, func,\n\t\t\t\toffs, 0  , 0  ,\n\t\t\t\tis_return);\n\n\tif (IS_ERR(tk)) {\n\t\tpr_info(\"Failed to allocate trace_probe.(%d)\\n\",\n\t\t\t(int)PTR_ERR(tk));\n\t\treturn ERR_CAST(tk);\n\t}\n\n\tinit_trace_event_call(tk);\n\n\tptype = trace_kprobe_is_return(tk) ?\n\t\tPROBE_PRINT_RETURN : PROBE_PRINT_NORMAL;\n\tif (traceprobe_set_print_fmt(&tk->tp, ptype) < 0) {\n\t\tret = -ENOMEM;\n\t\tgoto error;\n\t}\n\n\tret = __register_trace_kprobe(tk);\n\tif (ret < 0)\n\t\tgoto error;\n\n\treturn trace_probe_event_call(&tk->tp);\nerror:\n\tfree_trace_kprobe(tk);\n\treturn ERR_PTR(ret);\n}\n\nvoid destroy_local_trace_kprobe(struct trace_event_call *event_call)\n{\n\tstruct trace_kprobe *tk;\n\n\ttk = trace_kprobe_primary_from_call(event_call);\n\tif (unlikely(!tk))\n\t\treturn;\n\n\tif (trace_probe_is_enabled(&tk->tp)) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\t__unregister_trace_kprobe(tk);\n\n\tfree_trace_kprobe(tk);\n}\n#endif  \n\nstatic __init void enable_boot_kprobe_events(void)\n{\n\tstruct trace_array *tr = top_trace_array();\n\tstruct trace_event_file *file;\n\tstruct trace_kprobe *tk;\n\tstruct dyn_event *pos;\n\n\tmutex_lock(&event_mutex);\n\tfor_each_trace_kprobe(tk, pos) {\n\t\tlist_for_each_entry(file, &tr->events, list)\n\t\t\tif (file->event_call == trace_probe_event_call(&tk->tp))\n\t\t\t\ttrace_event_enable_disable(file, 1, 0);\n\t}\n\tmutex_unlock(&event_mutex);\n}\n\nstatic __init void setup_boot_kprobe_events(void)\n{\n\tchar *p, *cmd = kprobe_boot_events_buf;\n\tint ret;\n\n\tstrreplace(kprobe_boot_events_buf, ',', ' ');\n\n\twhile (cmd && *cmd != '\\0') {\n\t\tp = strchr(cmd, ';');\n\t\tif (p)\n\t\t\t*p++ = '\\0';\n\n\t\tret = create_or_delete_trace_kprobe(cmd);\n\t\tif (ret)\n\t\t\tpr_warn(\"Failed to add event(%d): %s\\n\", ret, cmd);\n\n\t\tcmd = p;\n\t}\n\n\tenable_boot_kprobe_events();\n}\n\n \nstatic __init int init_kprobe_trace_early(void)\n{\n\tint ret;\n\n\tret = dyn_event_register(&trace_kprobe_ops);\n\tif (ret)\n\t\treturn ret;\n\n\tif (register_module_notifier(&trace_kprobe_module_nb))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\ncore_initcall(init_kprobe_trace_early);\n\n \nstatic __init int init_kprobe_trace(void)\n{\n\tint ret;\n\n\tret = tracing_init_dentry();\n\tif (ret)\n\t\treturn 0;\n\n\t \n\ttrace_create_file(\"kprobe_events\", TRACE_MODE_WRITE,\n\t\t\t  NULL, NULL, &kprobe_events_ops);\n\n\t \n\ttrace_create_file(\"kprobe_profile\", TRACE_MODE_READ,\n\t\t\t  NULL, NULL, &kprobe_profile_ops);\n\n\tsetup_boot_kprobe_events();\n\n\treturn 0;\n}\nfs_initcall(init_kprobe_trace);\n\n\n#ifdef CONFIG_FTRACE_STARTUP_TEST\nstatic __init struct trace_event_file *\nfind_trace_probe_file(struct trace_kprobe *tk, struct trace_array *tr)\n{\n\tstruct trace_event_file *file;\n\n\tlist_for_each_entry(file, &tr->events, list)\n\t\tif (file->event_call == trace_probe_event_call(&tk->tp))\n\t\t\treturn file;\n\n\treturn NULL;\n}\n\n \nstatic __init int kprobe_trace_self_tests_init(void)\n{\n\tint ret, warn = 0;\n\tint (*target)(int, int, int, int, int, int);\n\tstruct trace_kprobe *tk;\n\tstruct trace_event_file *file;\n\n\tif (tracing_is_disabled())\n\t\treturn -ENODEV;\n\n\tif (tracing_selftest_disabled)\n\t\treturn 0;\n\n\ttarget = kprobe_trace_selftest_target;\n\n\tpr_info(\"Testing kprobe tracing: \");\n\n\tret = create_or_delete_trace_kprobe(\"p:testprobe kprobe_trace_selftest_target $stack $stack0 +0($stack)\");\n\tif (WARN_ON_ONCE(ret)) {\n\t\tpr_warn(\"error on probing function entry.\\n\");\n\t\twarn++;\n\t} else {\n\t\t \n\t\ttk = find_trace_kprobe(\"testprobe\", KPROBE_EVENT_SYSTEM);\n\t\tif (WARN_ON_ONCE(tk == NULL)) {\n\t\t\tpr_warn(\"error on getting new probe.\\n\");\n\t\t\twarn++;\n\t\t} else {\n\t\t\tfile = find_trace_probe_file(tk, top_trace_array());\n\t\t\tif (WARN_ON_ONCE(file == NULL)) {\n\t\t\t\tpr_warn(\"error on getting probe file.\\n\");\n\t\t\t\twarn++;\n\t\t\t} else\n\t\t\t\tenable_trace_kprobe(\n\t\t\t\t\ttrace_probe_event_call(&tk->tp), file);\n\t\t}\n\t}\n\n\tret = create_or_delete_trace_kprobe(\"r:testprobe2 kprobe_trace_selftest_target $retval\");\n\tif (WARN_ON_ONCE(ret)) {\n\t\tpr_warn(\"error on probing function return.\\n\");\n\t\twarn++;\n\t} else {\n\t\t \n\t\ttk = find_trace_kprobe(\"testprobe2\", KPROBE_EVENT_SYSTEM);\n\t\tif (WARN_ON_ONCE(tk == NULL)) {\n\t\t\tpr_warn(\"error on getting 2nd new probe.\\n\");\n\t\t\twarn++;\n\t\t} else {\n\t\t\tfile = find_trace_probe_file(tk, top_trace_array());\n\t\t\tif (WARN_ON_ONCE(file == NULL)) {\n\t\t\t\tpr_warn(\"error on getting probe file.\\n\");\n\t\t\t\twarn++;\n\t\t\t} else\n\t\t\t\tenable_trace_kprobe(\n\t\t\t\t\ttrace_probe_event_call(&tk->tp), file);\n\t\t}\n\t}\n\n\tif (warn)\n\t\tgoto end;\n\n\tret = target(1, 2, 3, 4, 5, 6);\n\n\t \n\tif (ret != 21)\n\t\twarn++;\n\n\t \n\ttk = find_trace_kprobe(\"testprobe\", KPROBE_EVENT_SYSTEM);\n\tif (WARN_ON_ONCE(tk == NULL)) {\n\t\tpr_warn(\"error on getting test probe.\\n\");\n\t\twarn++;\n\t} else {\n\t\tif (trace_kprobe_nhit(tk) != 1) {\n\t\t\tpr_warn(\"incorrect number of testprobe hits\\n\");\n\t\t\twarn++;\n\t\t}\n\n\t\tfile = find_trace_probe_file(tk, top_trace_array());\n\t\tif (WARN_ON_ONCE(file == NULL)) {\n\t\t\tpr_warn(\"error on getting probe file.\\n\");\n\t\t\twarn++;\n\t\t} else\n\t\t\tdisable_trace_kprobe(\n\t\t\t\ttrace_probe_event_call(&tk->tp), file);\n\t}\n\n\ttk = find_trace_kprobe(\"testprobe2\", KPROBE_EVENT_SYSTEM);\n\tif (WARN_ON_ONCE(tk == NULL)) {\n\t\tpr_warn(\"error on getting 2nd test probe.\\n\");\n\t\twarn++;\n\t} else {\n\t\tif (trace_kprobe_nhit(tk) != 1) {\n\t\t\tpr_warn(\"incorrect number of testprobe2 hits\\n\");\n\t\t\twarn++;\n\t\t}\n\n\t\tfile = find_trace_probe_file(tk, top_trace_array());\n\t\tif (WARN_ON_ONCE(file == NULL)) {\n\t\t\tpr_warn(\"error on getting probe file.\\n\");\n\t\t\twarn++;\n\t\t} else\n\t\t\tdisable_trace_kprobe(\n\t\t\t\ttrace_probe_event_call(&tk->tp), file);\n\t}\n\n\tret = create_or_delete_trace_kprobe(\"-:testprobe\");\n\tif (WARN_ON_ONCE(ret)) {\n\t\tpr_warn(\"error on deleting a probe.\\n\");\n\t\twarn++;\n\t}\n\n\tret = create_or_delete_trace_kprobe(\"-:testprobe2\");\n\tif (WARN_ON_ONCE(ret)) {\n\t\tpr_warn(\"error on deleting a probe.\\n\");\n\t\twarn++;\n\t}\n\nend:\n\tret = dyn_events_release_all(&trace_kprobe_ops);\n\tif (WARN_ON_ONCE(ret)) {\n\t\tpr_warn(\"error on cleaning up probes.\\n\");\n\t\twarn++;\n\t}\n\t \n\twait_for_kprobe_optimizer();\n\tif (warn)\n\t\tpr_cont(\"NG: Some tests are failed. Please check them.\\n\");\n\telse\n\t\tpr_cont(\"OK\\n\");\n\treturn 0;\n}\n\nlate_initcall(kprobe_trace_self_tests_init);\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}