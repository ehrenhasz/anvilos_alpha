{
  "module_name": "trace_stack.c",
  "hash_id": "bdf67a74cedd5ea412200518b1f0efbb921bdcb62be4c3f0cefb8f924bbf7c21",
  "original_prompt": "Ingested from linux-6.6.14/kernel/trace/trace_stack.c",
  "human_readable_source": "\n \n#include <linux/sched/task_stack.h>\n#include <linux/stacktrace.h>\n#include <linux/security.h>\n#include <linux/kallsyms.h>\n#include <linux/seq_file.h>\n#include <linux/spinlock.h>\n#include <linux/uaccess.h>\n#include <linux/ftrace.h>\n#include <linux/module.h>\n#include <linux/sysctl.h>\n#include <linux/init.h>\n\n#include <asm/setup.h>\n\n#include \"trace.h\"\n\n#define STACK_TRACE_ENTRIES 500\n\nstatic unsigned long stack_dump_trace[STACK_TRACE_ENTRIES];\nstatic unsigned stack_trace_index[STACK_TRACE_ENTRIES];\n\nstatic unsigned int stack_trace_nr_entries;\nstatic unsigned long stack_trace_max_size;\nstatic arch_spinlock_t stack_trace_max_lock =\n\t(arch_spinlock_t)__ARCH_SPIN_LOCK_UNLOCKED;\n\nDEFINE_PER_CPU(int, disable_stack_tracer);\nstatic DEFINE_MUTEX(stack_sysctl_mutex);\n\nint stack_tracer_enabled;\n\nstatic void print_max_stack(void)\n{\n\tlong i;\n\tint size;\n\n\tpr_emerg(\"        Depth    Size   Location    (%d entries)\\n\"\n\t\t\t   \"        -----    ----   --------\\n\",\n\t\t\t   stack_trace_nr_entries);\n\n\tfor (i = 0; i < stack_trace_nr_entries; i++) {\n\t\tif (i + 1 == stack_trace_nr_entries)\n\t\t\tsize = stack_trace_index[i];\n\t\telse\n\t\t\tsize = stack_trace_index[i] - stack_trace_index[i+1];\n\n\t\tpr_emerg(\"%3ld) %8d   %5d   %pS\\n\", i, stack_trace_index[i],\n\t\t\t\tsize, (void *)stack_dump_trace[i]);\n\t}\n}\n\n \nstatic void check_stack(unsigned long ip, unsigned long *stack)\n{\n\tunsigned long this_size, flags; unsigned long *p, *top, *start;\n\tstatic int tracer_frame;\n\tint frame_size = READ_ONCE(tracer_frame);\n\tint i, x;\n\n\tthis_size = ((unsigned long)stack) & (THREAD_SIZE-1);\n\tthis_size = THREAD_SIZE - this_size;\n\t \n\tthis_size -= frame_size;\n\n\tif (this_size <= stack_trace_max_size)\n\t\treturn;\n\n\t \n\tif (!object_is_on_stack(stack))\n\t\treturn;\n\n\t \n\tif (in_nmi())\n\t\treturn;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&stack_trace_max_lock);\n\n\t \n\tif (unlikely(!frame_size))\n\t\tthis_size -= tracer_frame;\n\n\t \n\tif (this_size <= stack_trace_max_size)\n\t\tgoto out;\n\n\tstack_trace_max_size = this_size;\n\n\tstack_trace_nr_entries = stack_trace_save(stack_dump_trace,\n\t\t\t\t\t       ARRAY_SIZE(stack_dump_trace) - 1,\n\t\t\t\t\t       0);\n\n\t \n\tfor (i = 0; i < stack_trace_nr_entries; i++) {\n\t\tif (stack_dump_trace[i] == ip)\n\t\t\tbreak;\n\t}\n\n\t \n\tif (i == stack_trace_nr_entries)\n\t\ti = 0;\n\n\t \n\tx = 0;\n\tstart = stack;\n\ttop = (unsigned long *)\n\t\t(((unsigned long)start & ~(THREAD_SIZE-1)) + THREAD_SIZE);\n\n\t \n\twhile (i < stack_trace_nr_entries) {\n\t\tint found = 0;\n\n\t\tstack_trace_index[x] = this_size;\n\t\tp = start;\n\n\t\tfor (; p < top && i < stack_trace_nr_entries; p++) {\n\t\t\t \n\t\t\tif ((READ_ONCE_NOCHECK(*p)) == stack_dump_trace[i]) {\n\t\t\t\tstack_dump_trace[x] = stack_dump_trace[i++];\n\t\t\t\tthis_size = stack_trace_index[x++] =\n\t\t\t\t\t(top - p) * sizeof(unsigned long);\n\t\t\t\tfound = 1;\n\t\t\t\t \n\t\t\t\tstart = p + 1;\n\t\t\t\t \n\t\t\t\tif (unlikely(!tracer_frame)) {\n\t\t\t\t\ttracer_frame = (p - stack) *\n\t\t\t\t\t\tsizeof(unsigned long);\n\t\t\t\t\tstack_trace_max_size -= tracer_frame;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (!found)\n\t\t\ti++;\n\t}\n\n#ifdef ARCH_FTRACE_SHIFT_STACK_TRACER\n\t \n\tif (x > 1) {\n\t\tmemmove(&stack_trace_index[0], &stack_trace_index[1],\n\t\t\tsizeof(stack_trace_index[0]) * (x - 1));\n\t\tx--;\n\t}\n#endif\n\n\tstack_trace_nr_entries = x;\n\n\tif (task_stack_end_corrupted(current)) {\n\t\tprint_max_stack();\n\t\tBUG();\n\t}\n\n out:\n\tarch_spin_unlock(&stack_trace_max_lock);\n\tlocal_irq_restore(flags);\n}\n\n \n#ifndef MCOUNT_INSN_SIZE\n# define MCOUNT_INSN_SIZE 0\n#endif\n\nstatic void\nstack_trace_call(unsigned long ip, unsigned long parent_ip,\n\t\t struct ftrace_ops *op, struct ftrace_regs *fregs)\n{\n\tunsigned long stack;\n\n\tpreempt_disable_notrace();\n\n\t \n\t__this_cpu_inc(disable_stack_tracer);\n\tif (__this_cpu_read(disable_stack_tracer) != 1)\n\t\tgoto out;\n\n\t \n\tif (!rcu_is_watching())\n\t\tgoto out;\n\n\tip += MCOUNT_INSN_SIZE;\n\n\tcheck_stack(ip, &stack);\n\n out:\n\t__this_cpu_dec(disable_stack_tracer);\n\t \n\tpreempt_enable_notrace();\n}\n\nstatic struct ftrace_ops trace_ops __read_mostly =\n{\n\t.func = stack_trace_call,\n};\n\nstatic ssize_t\nstack_max_size_read(struct file *filp, char __user *ubuf,\n\t\t    size_t count, loff_t *ppos)\n{\n\tunsigned long *ptr = filp->private_data;\n\tchar buf[64];\n\tint r;\n\n\tr = snprintf(buf, sizeof(buf), \"%ld\\n\", *ptr);\n\tif (r > sizeof(buf))\n\t\tr = sizeof(buf);\n\treturn simple_read_from_buffer(ubuf, count, ppos, buf, r);\n}\n\nstatic ssize_t\nstack_max_size_write(struct file *filp, const char __user *ubuf,\n\t\t     size_t count, loff_t *ppos)\n{\n\tlong *ptr = filp->private_data;\n\tunsigned long val, flags;\n\tint ret;\n\n\tret = kstrtoul_from_user(ubuf, count, 10, &val);\n\tif (ret)\n\t\treturn ret;\n\n\tlocal_irq_save(flags);\n\n\t \n\t__this_cpu_inc(disable_stack_tracer);\n\n\tarch_spin_lock(&stack_trace_max_lock);\n\t*ptr = val;\n\tarch_spin_unlock(&stack_trace_max_lock);\n\n\t__this_cpu_dec(disable_stack_tracer);\n\tlocal_irq_restore(flags);\n\n\treturn count;\n}\n\nstatic const struct file_operations stack_max_size_fops = {\n\t.open\t\t= tracing_open_generic,\n\t.read\t\t= stack_max_size_read,\n\t.write\t\t= stack_max_size_write,\n\t.llseek\t\t= default_llseek,\n};\n\nstatic void *\n__next(struct seq_file *m, loff_t *pos)\n{\n\tlong n = *pos - 1;\n\n\tif (n >= stack_trace_nr_entries)\n\t\treturn NULL;\n\n\tm->private = (void *)n;\n\treturn &m->private;\n}\n\nstatic void *\nt_next(struct seq_file *m, void *v, loff_t *pos)\n{\n\t(*pos)++;\n\treturn __next(m, pos);\n}\n\nstatic void *t_start(struct seq_file *m, loff_t *pos)\n{\n\tlocal_irq_disable();\n\n\t__this_cpu_inc(disable_stack_tracer);\n\n\tarch_spin_lock(&stack_trace_max_lock);\n\n\tif (*pos == 0)\n\t\treturn SEQ_START_TOKEN;\n\n\treturn __next(m, pos);\n}\n\nstatic void t_stop(struct seq_file *m, void *p)\n{\n\tarch_spin_unlock(&stack_trace_max_lock);\n\n\t__this_cpu_dec(disable_stack_tracer);\n\n\tlocal_irq_enable();\n}\n\nstatic void trace_lookup_stack(struct seq_file *m, long i)\n{\n\tunsigned long addr = stack_dump_trace[i];\n\n\tseq_printf(m, \"%pS\\n\", (void *)addr);\n}\n\nstatic void print_disabled(struct seq_file *m)\n{\n\tseq_puts(m, \"#\\n\"\n\t\t \"#  Stack tracer disabled\\n\"\n\t\t \"#\\n\"\n\t\t \"# To enable the stack tracer, either add 'stacktrace' to the\\n\"\n\t\t \"# kernel command line\\n\"\n\t\t \"# or 'echo 1 > /proc/sys/kernel/stack_tracer_enabled'\\n\"\n\t\t \"#\\n\");\n}\n\nstatic int t_show(struct seq_file *m, void *v)\n{\n\tlong i;\n\tint size;\n\n\tif (v == SEQ_START_TOKEN) {\n\t\tseq_printf(m, \"        Depth    Size   Location\"\n\t\t\t   \"    (%d entries)\\n\"\n\t\t\t   \"        -----    ----   --------\\n\",\n\t\t\t   stack_trace_nr_entries);\n\n\t\tif (!stack_tracer_enabled && !stack_trace_max_size)\n\t\t\tprint_disabled(m);\n\n\t\treturn 0;\n\t}\n\n\ti = *(long *)v;\n\n\tif (i >= stack_trace_nr_entries)\n\t\treturn 0;\n\n\tif (i + 1 == stack_trace_nr_entries)\n\t\tsize = stack_trace_index[i];\n\telse\n\t\tsize = stack_trace_index[i] - stack_trace_index[i+1];\n\n\tseq_printf(m, \"%3ld) %8d   %5d   \", i, stack_trace_index[i], size);\n\n\ttrace_lookup_stack(m, i);\n\n\treturn 0;\n}\n\nstatic const struct seq_operations stack_trace_seq_ops = {\n\t.start\t\t= t_start,\n\t.next\t\t= t_next,\n\t.stop\t\t= t_stop,\n\t.show\t\t= t_show,\n};\n\nstatic int stack_trace_open(struct inode *inode, struct file *file)\n{\n\tint ret;\n\n\tret = security_locked_down(LOCKDOWN_TRACEFS);\n\tif (ret)\n\t\treturn ret;\n\n\treturn seq_open(file, &stack_trace_seq_ops);\n}\n\nstatic const struct file_operations stack_trace_fops = {\n\t.open\t\t= stack_trace_open,\n\t.read\t\t= seq_read,\n\t.llseek\t\t= seq_lseek,\n\t.release\t= seq_release,\n};\n\n#ifdef CONFIG_DYNAMIC_FTRACE\n\nstatic int\nstack_trace_filter_open(struct inode *inode, struct file *file)\n{\n\tstruct ftrace_ops *ops = inode->i_private;\n\n\t \n\treturn ftrace_regex_open(ops, FTRACE_ITER_FILTER,\n\t\t\t\t inode, file);\n}\n\nstatic const struct file_operations stack_trace_filter_fops = {\n\t.open = stack_trace_filter_open,\n\t.read = seq_read,\n\t.write = ftrace_filter_write,\n\t.llseek = tracing_lseek,\n\t.release = ftrace_regex_release,\n};\n\n#endif  \n\nint\nstack_trace_sysctl(struct ctl_table *table, int write, void *buffer,\n\t\t   size_t *lenp, loff_t *ppos)\n{\n\tint was_enabled;\n\tint ret;\n\n\tmutex_lock(&stack_sysctl_mutex);\n\twas_enabled = !!stack_tracer_enabled;\n\n\tret = proc_dointvec(table, write, buffer, lenp, ppos);\n\n\tif (ret || !write || (was_enabled == !!stack_tracer_enabled))\n\t\tgoto out;\n\n\tif (stack_tracer_enabled)\n\t\tregister_ftrace_function(&trace_ops);\n\telse\n\t\tunregister_ftrace_function(&trace_ops);\n out:\n\tmutex_unlock(&stack_sysctl_mutex);\n\treturn ret;\n}\n\nstatic char stack_trace_filter_buf[COMMAND_LINE_SIZE+1] __initdata;\n\nstatic __init int enable_stacktrace(char *str)\n{\n\tint len;\n\n\tif ((len = str_has_prefix(str, \"_filter=\")))\n\t\tstrncpy(stack_trace_filter_buf, str + len, COMMAND_LINE_SIZE);\n\n\tstack_tracer_enabled = 1;\n\treturn 1;\n}\n__setup(\"stacktrace\", enable_stacktrace);\n\nstatic __init int stack_trace_init(void)\n{\n\tint ret;\n\n\tret = tracing_init_dentry();\n\tif (ret)\n\t\treturn 0;\n\n\ttrace_create_file(\"stack_max_size\", TRACE_MODE_WRITE, NULL,\n\t\t\t&stack_trace_max_size, &stack_max_size_fops);\n\n\ttrace_create_file(\"stack_trace\", TRACE_MODE_READ, NULL,\n\t\t\tNULL, &stack_trace_fops);\n\n#ifdef CONFIG_DYNAMIC_FTRACE\n\ttrace_create_file(\"stack_trace_filter\", TRACE_MODE_WRITE, NULL,\n\t\t\t  &trace_ops, &stack_trace_filter_fops);\n#endif\n\n\tif (stack_trace_filter_buf[0])\n\t\tftrace_set_early_filter(&trace_ops, stack_trace_filter_buf, 1);\n\n\tif (stack_tracer_enabled)\n\t\tregister_ftrace_function(&trace_ops);\n\n\treturn 0;\n}\n\ndevice_initcall(stack_trace_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}