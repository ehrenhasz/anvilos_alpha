{
  "module_name": "trace_functions.c",
  "hash_id": "5f3c1c4fb8a86a6b5ec211e0878b608f1571a59070829779d84af5d2070e247b",
  "original_prompt": "Ingested from linux-6.6.14/kernel/trace/trace_functions.c",
  "human_readable_source": "\n \n#include <linux/ring_buffer.h>\n#include <linux/debugfs.h>\n#include <linux/uaccess.h>\n#include <linux/ftrace.h>\n#include <linux/slab.h>\n#include <linux/fs.h>\n\n#include \"trace.h\"\n\nstatic void tracing_start_function_trace(struct trace_array *tr);\nstatic void tracing_stop_function_trace(struct trace_array *tr);\nstatic void\nfunction_trace_call(unsigned long ip, unsigned long parent_ip,\n\t\t    struct ftrace_ops *op, struct ftrace_regs *fregs);\nstatic void\nfunction_stack_trace_call(unsigned long ip, unsigned long parent_ip,\n\t\t\t  struct ftrace_ops *op, struct ftrace_regs *fregs);\nstatic void\nfunction_no_repeats_trace_call(unsigned long ip, unsigned long parent_ip,\n\t\t\t       struct ftrace_ops *op, struct ftrace_regs *fregs);\nstatic void\nfunction_stack_no_repeats_trace_call(unsigned long ip, unsigned long parent_ip,\n\t\t\t\t     struct ftrace_ops *op,\n\t\t\t\t     struct ftrace_regs *fregs);\nstatic struct tracer_flags func_flags;\n\n \nenum {\n\n\tTRACE_FUNC_NO_OPTS\t\t= 0x0,  \n\tTRACE_FUNC_OPT_STACK\t\t= 0x1,\n\tTRACE_FUNC_OPT_NO_REPEATS\t= 0x2,\n\n\t \n\tTRACE_FUNC_OPT_HIGHEST_BIT\t= 0x4\n};\n\n#define TRACE_FUNC_OPT_MASK\t(TRACE_FUNC_OPT_HIGHEST_BIT - 1)\n\nint ftrace_allocate_ftrace_ops(struct trace_array *tr)\n{\n\tstruct ftrace_ops *ops;\n\n\t \n\tif (tr->flags & TRACE_ARRAY_FL_GLOBAL)\n\t\treturn 0;\n\n\tops = kzalloc(sizeof(*ops), GFP_KERNEL);\n\tif (!ops)\n\t\treturn -ENOMEM;\n\n\t \n\tops->func = function_trace_call;\n\tops->flags = FTRACE_OPS_FL_PID;\n\n\ttr->ops = ops;\n\tops->private = tr;\n\n\treturn 0;\n}\n\nvoid ftrace_free_ftrace_ops(struct trace_array *tr)\n{\n\tkfree(tr->ops);\n\ttr->ops = NULL;\n}\n\nint ftrace_create_function_files(struct trace_array *tr,\n\t\t\t\t struct dentry *parent)\n{\n\t \n\tif (tr->flags & TRACE_ARRAY_FL_GLOBAL)\n\t\treturn 0;\n\n\tif (!tr->ops)\n\t\treturn -EINVAL;\n\n\tftrace_create_filter_files(tr->ops, parent);\n\n\treturn 0;\n}\n\nvoid ftrace_destroy_function_files(struct trace_array *tr)\n{\n\tftrace_destroy_filter_files(tr->ops);\n\tftrace_free_ftrace_ops(tr);\n}\n\nstatic ftrace_func_t select_trace_function(u32 flags_val)\n{\n\tswitch (flags_val & TRACE_FUNC_OPT_MASK) {\n\tcase TRACE_FUNC_NO_OPTS:\n\t\treturn function_trace_call;\n\tcase TRACE_FUNC_OPT_STACK:\n\t\treturn function_stack_trace_call;\n\tcase TRACE_FUNC_OPT_NO_REPEATS:\n\t\treturn function_no_repeats_trace_call;\n\tcase TRACE_FUNC_OPT_STACK | TRACE_FUNC_OPT_NO_REPEATS:\n\t\treturn function_stack_no_repeats_trace_call;\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic bool handle_func_repeats(struct trace_array *tr, u32 flags_val)\n{\n\tif (!tr->last_func_repeats &&\n\t    (flags_val & TRACE_FUNC_OPT_NO_REPEATS)) {\n\t\ttr->last_func_repeats = alloc_percpu(struct trace_func_repeats);\n\t\tif (!tr->last_func_repeats)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic int function_trace_init(struct trace_array *tr)\n{\n\tftrace_func_t func;\n\t \n\tif (!tr->ops)\n\t\treturn -ENOMEM;\n\n\tfunc = select_trace_function(func_flags.val);\n\tif (!func)\n\t\treturn -EINVAL;\n\n\tif (!handle_func_repeats(tr, func_flags.val))\n\t\treturn -ENOMEM;\n\n\tftrace_init_array_ops(tr, func);\n\n\ttr->array_buffer.cpu = raw_smp_processor_id();\n\n\ttracing_start_cmdline_record();\n\ttracing_start_function_trace(tr);\n\treturn 0;\n}\n\nstatic void function_trace_reset(struct trace_array *tr)\n{\n\ttracing_stop_function_trace(tr);\n\ttracing_stop_cmdline_record();\n\tftrace_reset_array_ops(tr);\n}\n\nstatic void function_trace_start(struct trace_array *tr)\n{\n\ttracing_reset_online_cpus(&tr->array_buffer);\n}\n\nstatic void\nfunction_trace_call(unsigned long ip, unsigned long parent_ip,\n\t\t    struct ftrace_ops *op, struct ftrace_regs *fregs)\n{\n\tstruct trace_array *tr = op->private;\n\tstruct trace_array_cpu *data;\n\tunsigned int trace_ctx;\n\tint bit;\n\tint cpu;\n\n\tif (unlikely(!tr->function_enabled))\n\t\treturn;\n\n\tbit = ftrace_test_recursion_trylock(ip, parent_ip);\n\tif (bit < 0)\n\t\treturn;\n\n\ttrace_ctx = tracing_gen_ctx();\n\n\tcpu = smp_processor_id();\n\tdata = per_cpu_ptr(tr->array_buffer.data, cpu);\n\tif (!atomic_read(&data->disabled))\n\t\ttrace_function(tr, ip, parent_ip, trace_ctx);\n\n\tftrace_test_recursion_unlock(bit);\n}\n\n#ifdef CONFIG_UNWINDER_ORC\n \n#define STACK_SKIP 2\n#else\n \n#define STACK_SKIP 3\n#endif\n\nstatic void\nfunction_stack_trace_call(unsigned long ip, unsigned long parent_ip,\n\t\t\t  struct ftrace_ops *op, struct ftrace_regs *fregs)\n{\n\tstruct trace_array *tr = op->private;\n\tstruct trace_array_cpu *data;\n\tunsigned long flags;\n\tlong disabled;\n\tint cpu;\n\tunsigned int trace_ctx;\n\n\tif (unlikely(!tr->function_enabled))\n\t\treturn;\n\n\t \n\tlocal_irq_save(flags);\n\tcpu = raw_smp_processor_id();\n\tdata = per_cpu_ptr(tr->array_buffer.data, cpu);\n\tdisabled = atomic_inc_return(&data->disabled);\n\n\tif (likely(disabled == 1)) {\n\t\ttrace_ctx = tracing_gen_ctx_flags(flags);\n\t\ttrace_function(tr, ip, parent_ip, trace_ctx);\n\t\t__trace_stack(tr, trace_ctx, STACK_SKIP);\n\t}\n\n\tatomic_dec(&data->disabled);\n\tlocal_irq_restore(flags);\n}\n\nstatic inline bool is_repeat_check(struct trace_array *tr,\n\t\t\t\t   struct trace_func_repeats *last_info,\n\t\t\t\t   unsigned long ip, unsigned long parent_ip)\n{\n\tif (last_info->ip == ip &&\n\t    last_info->parent_ip == parent_ip &&\n\t    last_info->count < U16_MAX) {\n\t\tlast_info->ts_last_call =\n\t\t\tring_buffer_time_stamp(tr->array_buffer.buffer);\n\t\tlast_info->count++;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic inline void process_repeats(struct trace_array *tr,\n\t\t\t\t   unsigned long ip, unsigned long parent_ip,\n\t\t\t\t   struct trace_func_repeats *last_info,\n\t\t\t\t   unsigned int trace_ctx)\n{\n\tif (last_info->count) {\n\t\ttrace_last_func_repeats(tr, last_info, trace_ctx);\n\t\tlast_info->count = 0;\n\t}\n\n\tlast_info->ip = ip;\n\tlast_info->parent_ip = parent_ip;\n}\n\nstatic void\nfunction_no_repeats_trace_call(unsigned long ip, unsigned long parent_ip,\n\t\t\t       struct ftrace_ops *op,\n\t\t\t       struct ftrace_regs *fregs)\n{\n\tstruct trace_func_repeats *last_info;\n\tstruct trace_array *tr = op->private;\n\tstruct trace_array_cpu *data;\n\tunsigned int trace_ctx;\n\tunsigned long flags;\n\tint bit;\n\tint cpu;\n\n\tif (unlikely(!tr->function_enabled))\n\t\treturn;\n\n\tbit = ftrace_test_recursion_trylock(ip, parent_ip);\n\tif (bit < 0)\n\t\treturn;\n\n\tcpu = smp_processor_id();\n\tdata = per_cpu_ptr(tr->array_buffer.data, cpu);\n\tif (atomic_read(&data->disabled))\n\t\tgoto out;\n\n\t \n\tlast_info = per_cpu_ptr(tr->last_func_repeats, cpu);\n\tif (is_repeat_check(tr, last_info, ip, parent_ip))\n\t\tgoto out;\n\n\tlocal_save_flags(flags);\n\ttrace_ctx = tracing_gen_ctx_flags(flags);\n\tprocess_repeats(tr, ip, parent_ip, last_info, trace_ctx);\n\n\ttrace_function(tr, ip, parent_ip, trace_ctx);\n\nout:\n\tftrace_test_recursion_unlock(bit);\n}\n\nstatic void\nfunction_stack_no_repeats_trace_call(unsigned long ip, unsigned long parent_ip,\n\t\t\t\t     struct ftrace_ops *op,\n\t\t\t\t     struct ftrace_regs *fregs)\n{\n\tstruct trace_func_repeats *last_info;\n\tstruct trace_array *tr = op->private;\n\tstruct trace_array_cpu *data;\n\tunsigned long flags;\n\tlong disabled;\n\tint cpu;\n\tunsigned int trace_ctx;\n\n\tif (unlikely(!tr->function_enabled))\n\t\treturn;\n\n\t \n\tlocal_irq_save(flags);\n\tcpu = raw_smp_processor_id();\n\tdata = per_cpu_ptr(tr->array_buffer.data, cpu);\n\tdisabled = atomic_inc_return(&data->disabled);\n\n\tif (likely(disabled == 1)) {\n\t\tlast_info = per_cpu_ptr(tr->last_func_repeats, cpu);\n\t\tif (is_repeat_check(tr, last_info, ip, parent_ip))\n\t\t\tgoto out;\n\n\t\ttrace_ctx = tracing_gen_ctx_flags(flags);\n\t\tprocess_repeats(tr, ip, parent_ip, last_info, trace_ctx);\n\n\t\ttrace_function(tr, ip, parent_ip, trace_ctx);\n\t\t__trace_stack(tr, trace_ctx, STACK_SKIP);\n\t}\n\n out:\n\tatomic_dec(&data->disabled);\n\tlocal_irq_restore(flags);\n}\n\nstatic struct tracer_opt func_opts[] = {\n#ifdef CONFIG_STACKTRACE\n\t{ TRACER_OPT(func_stack_trace, TRACE_FUNC_OPT_STACK) },\n#endif\n\t{ TRACER_OPT(func-no-repeats, TRACE_FUNC_OPT_NO_REPEATS) },\n\t{ }  \n};\n\nstatic struct tracer_flags func_flags = {\n\t.val = TRACE_FUNC_NO_OPTS,  \n\t.opts = func_opts\n};\n\nstatic void tracing_start_function_trace(struct trace_array *tr)\n{\n\ttr->function_enabled = 0;\n\tregister_ftrace_function(tr->ops);\n\ttr->function_enabled = 1;\n}\n\nstatic void tracing_stop_function_trace(struct trace_array *tr)\n{\n\ttr->function_enabled = 0;\n\tunregister_ftrace_function(tr->ops);\n}\n\nstatic struct tracer function_trace;\n\nstatic int\nfunc_set_flag(struct trace_array *tr, u32 old_flags, u32 bit, int set)\n{\n\tftrace_func_t func;\n\tu32 new_flags;\n\n\t \n\tif (!!set == !!(func_flags.val & bit))\n\t\treturn 0;\n\n\t \n\tif (tr->current_trace != &function_trace)\n\t\treturn 0;\n\n\tnew_flags = (func_flags.val & ~bit) | (set ? bit : 0);\n\tfunc = select_trace_function(new_flags);\n\tif (!func)\n\t\treturn -EINVAL;\n\n\t \n\tif (tr->ops->func == func)\n\t\treturn 0;\n\n\tif (!handle_func_repeats(tr, new_flags))\n\t\treturn -ENOMEM;\n\n\tunregister_ftrace_function(tr->ops);\n\ttr->ops->func = func;\n\tregister_ftrace_function(tr->ops);\n\n\treturn 0;\n}\n\nstatic struct tracer function_trace __tracer_data =\n{\n\t.name\t\t= \"function\",\n\t.init\t\t= function_trace_init,\n\t.reset\t\t= function_trace_reset,\n\t.start\t\t= function_trace_start,\n\t.flags\t\t= &func_flags,\n\t.set_flag\t= func_set_flag,\n\t.allow_instances = true,\n#ifdef CONFIG_FTRACE_SELFTEST\n\t.selftest\t= trace_selftest_startup_function,\n#endif\n};\n\n#ifdef CONFIG_DYNAMIC_FTRACE\nstatic void update_traceon_count(struct ftrace_probe_ops *ops,\n\t\t\t\t unsigned long ip,\n\t\t\t\t struct trace_array *tr, bool on,\n\t\t\t\t void *data)\n{\n\tstruct ftrace_func_mapper *mapper = data;\n\tlong *count;\n\tlong old_count;\n\n\t \n\tcount = (long *)ftrace_func_mapper_find_ip(mapper, ip);\n\told_count = *count;\n\n\tif (old_count <= 0)\n\t\treturn;\n\n\t \n\tsmp_rmb();\n\n\tif (on == !!tracer_tracing_is_on(tr))\n\t\treturn;\n\n\tif (on)\n\t\ttracer_tracing_on(tr);\n\telse\n\t\ttracer_tracing_off(tr);\n\n\t \n\tsmp_wmb();\n\n\t*count = old_count - 1;\n}\n\nstatic void\nftrace_traceon_count(unsigned long ip, unsigned long parent_ip,\n\t\t     struct trace_array *tr, struct ftrace_probe_ops *ops,\n\t\t     void *data)\n{\n\tupdate_traceon_count(ops, ip, tr, 1, data);\n}\n\nstatic void\nftrace_traceoff_count(unsigned long ip, unsigned long parent_ip,\n\t\t      struct trace_array *tr, struct ftrace_probe_ops *ops,\n\t\t      void *data)\n{\n\tupdate_traceon_count(ops, ip, tr, 0, data);\n}\n\nstatic void\nftrace_traceon(unsigned long ip, unsigned long parent_ip,\n\t       struct trace_array *tr, struct ftrace_probe_ops *ops,\n\t       void *data)\n{\n\tif (tracer_tracing_is_on(tr))\n\t\treturn;\n\n\ttracer_tracing_on(tr);\n}\n\nstatic void\nftrace_traceoff(unsigned long ip, unsigned long parent_ip,\n\t\tstruct trace_array *tr, struct ftrace_probe_ops *ops,\n\t\tvoid *data)\n{\n\tif (!tracer_tracing_is_on(tr))\n\t\treturn;\n\n\ttracer_tracing_off(tr);\n}\n\n#ifdef CONFIG_UNWINDER_ORC\n \n#define FTRACE_STACK_SKIP 3\n#else\n \n#define FTRACE_STACK_SKIP 5\n#endif\n\nstatic __always_inline void trace_stack(struct trace_array *tr)\n{\n\tunsigned int trace_ctx;\n\n\ttrace_ctx = tracing_gen_ctx();\n\n\t__trace_stack(tr, trace_ctx, FTRACE_STACK_SKIP);\n}\n\nstatic void\nftrace_stacktrace(unsigned long ip, unsigned long parent_ip,\n\t\t  struct trace_array *tr, struct ftrace_probe_ops *ops,\n\t\t  void *data)\n{\n\ttrace_stack(tr);\n}\n\nstatic void\nftrace_stacktrace_count(unsigned long ip, unsigned long parent_ip,\n\t\t\tstruct trace_array *tr, struct ftrace_probe_ops *ops,\n\t\t\tvoid *data)\n{\n\tstruct ftrace_func_mapper *mapper = data;\n\tlong *count;\n\tlong old_count;\n\tlong new_count;\n\n\tif (!tracing_is_on())\n\t\treturn;\n\n\t \n\tif (!mapper) {\n\t\ttrace_stack(tr);\n\t\treturn;\n\t}\n\n\tcount = (long *)ftrace_func_mapper_find_ip(mapper, ip);\n\n\t \n\tdo {\n\t\told_count = *count;\n\n\t\tif (!old_count)\n\t\t\treturn;\n\n\t\tnew_count = old_count - 1;\n\t\tnew_count = cmpxchg(count, old_count, new_count);\n\t\tif (new_count == old_count)\n\t\t\ttrace_stack(tr);\n\n\t\tif (!tracing_is_on())\n\t\t\treturn;\n\n\t} while (new_count != old_count);\n}\n\nstatic int update_count(struct ftrace_probe_ops *ops, unsigned long ip,\n\t\t\tvoid *data)\n{\n\tstruct ftrace_func_mapper *mapper = data;\n\tlong *count = NULL;\n\n\tif (mapper)\n\t\tcount = (long *)ftrace_func_mapper_find_ip(mapper, ip);\n\n\tif (count) {\n\t\tif (*count <= 0)\n\t\t\treturn 0;\n\t\t(*count)--;\n\t}\n\n\treturn 1;\n}\n\nstatic void\nftrace_dump_probe(unsigned long ip, unsigned long parent_ip,\n\t\t  struct trace_array *tr, struct ftrace_probe_ops *ops,\n\t\t  void *data)\n{\n\tif (update_count(ops, ip, data))\n\t\tftrace_dump(DUMP_ALL);\n}\n\n \nstatic void\nftrace_cpudump_probe(unsigned long ip, unsigned long parent_ip,\n\t\t     struct trace_array *tr, struct ftrace_probe_ops *ops,\n\t\t     void *data)\n{\n\tif (update_count(ops, ip, data))\n\t\tftrace_dump(DUMP_ORIG);\n}\n\nstatic int\nftrace_probe_print(const char *name, struct seq_file *m,\n\t\t   unsigned long ip, struct ftrace_probe_ops *ops,\n\t\t   void *data)\n{\n\tstruct ftrace_func_mapper *mapper = data;\n\tlong *count = NULL;\n\n\tseq_printf(m, \"%ps:%s\", (void *)ip, name);\n\n\tif (mapper)\n\t\tcount = (long *)ftrace_func_mapper_find_ip(mapper, ip);\n\n\tif (count)\n\t\tseq_printf(m, \":count=%ld\\n\", *count);\n\telse\n\t\tseq_puts(m, \":unlimited\\n\");\n\n\treturn 0;\n}\n\nstatic int\nftrace_traceon_print(struct seq_file *m, unsigned long ip,\n\t\t     struct ftrace_probe_ops *ops,\n\t\t     void *data)\n{\n\treturn ftrace_probe_print(\"traceon\", m, ip, ops, data);\n}\n\nstatic int\nftrace_traceoff_print(struct seq_file *m, unsigned long ip,\n\t\t\t struct ftrace_probe_ops *ops, void *data)\n{\n\treturn ftrace_probe_print(\"traceoff\", m, ip, ops, data);\n}\n\nstatic int\nftrace_stacktrace_print(struct seq_file *m, unsigned long ip,\n\t\t\tstruct ftrace_probe_ops *ops, void *data)\n{\n\treturn ftrace_probe_print(\"stacktrace\", m, ip, ops, data);\n}\n\nstatic int\nftrace_dump_print(struct seq_file *m, unsigned long ip,\n\t\t\tstruct ftrace_probe_ops *ops, void *data)\n{\n\treturn ftrace_probe_print(\"dump\", m, ip, ops, data);\n}\n\nstatic int\nftrace_cpudump_print(struct seq_file *m, unsigned long ip,\n\t\t\tstruct ftrace_probe_ops *ops, void *data)\n{\n\treturn ftrace_probe_print(\"cpudump\", m, ip, ops, data);\n}\n\n\nstatic int\nftrace_count_init(struct ftrace_probe_ops *ops, struct trace_array *tr,\n\t\t  unsigned long ip, void *init_data, void **data)\n{\n\tstruct ftrace_func_mapper *mapper = *data;\n\n\tif (!mapper) {\n\t\tmapper = allocate_ftrace_func_mapper();\n\t\tif (!mapper)\n\t\t\treturn -ENOMEM;\n\t\t*data = mapper;\n\t}\n\n\treturn ftrace_func_mapper_add_ip(mapper, ip, init_data);\n}\n\nstatic void\nftrace_count_free(struct ftrace_probe_ops *ops, struct trace_array *tr,\n\t\t  unsigned long ip, void *data)\n{\n\tstruct ftrace_func_mapper *mapper = data;\n\n\tif (!ip) {\n\t\tfree_ftrace_func_mapper(mapper, NULL);\n\t\treturn;\n\t}\n\n\tftrace_func_mapper_remove_ip(mapper, ip);\n}\n\nstatic struct ftrace_probe_ops traceon_count_probe_ops = {\n\t.func\t\t\t= ftrace_traceon_count,\n\t.print\t\t\t= ftrace_traceon_print,\n\t.init\t\t\t= ftrace_count_init,\n\t.free\t\t\t= ftrace_count_free,\n};\n\nstatic struct ftrace_probe_ops traceoff_count_probe_ops = {\n\t.func\t\t\t= ftrace_traceoff_count,\n\t.print\t\t\t= ftrace_traceoff_print,\n\t.init\t\t\t= ftrace_count_init,\n\t.free\t\t\t= ftrace_count_free,\n};\n\nstatic struct ftrace_probe_ops stacktrace_count_probe_ops = {\n\t.func\t\t\t= ftrace_stacktrace_count,\n\t.print\t\t\t= ftrace_stacktrace_print,\n\t.init\t\t\t= ftrace_count_init,\n\t.free\t\t\t= ftrace_count_free,\n};\n\nstatic struct ftrace_probe_ops dump_probe_ops = {\n\t.func\t\t\t= ftrace_dump_probe,\n\t.print\t\t\t= ftrace_dump_print,\n\t.init\t\t\t= ftrace_count_init,\n\t.free\t\t\t= ftrace_count_free,\n};\n\nstatic struct ftrace_probe_ops cpudump_probe_ops = {\n\t.func\t\t\t= ftrace_cpudump_probe,\n\t.print\t\t\t= ftrace_cpudump_print,\n};\n\nstatic struct ftrace_probe_ops traceon_probe_ops = {\n\t.func\t\t\t= ftrace_traceon,\n\t.print\t\t\t= ftrace_traceon_print,\n};\n\nstatic struct ftrace_probe_ops traceoff_probe_ops = {\n\t.func\t\t\t= ftrace_traceoff,\n\t.print\t\t\t= ftrace_traceoff_print,\n};\n\nstatic struct ftrace_probe_ops stacktrace_probe_ops = {\n\t.func\t\t\t= ftrace_stacktrace,\n\t.print\t\t\t= ftrace_stacktrace_print,\n};\n\nstatic int\nftrace_trace_probe_callback(struct trace_array *tr,\n\t\t\t    struct ftrace_probe_ops *ops,\n\t\t\t    struct ftrace_hash *hash, char *glob,\n\t\t\t    char *cmd, char *param, int enable)\n{\n\tvoid *count = (void *)-1;\n\tchar *number;\n\tint ret;\n\n\t \n\tif (!enable)\n\t\treturn -EINVAL;\n\n\tif (glob[0] == '!')\n\t\treturn unregister_ftrace_function_probe_func(glob+1, tr, ops);\n\n\tif (!param)\n\t\tgoto out_reg;\n\n\tnumber = strsep(&param, \":\");\n\n\tif (!strlen(number))\n\t\tgoto out_reg;\n\n\t \n\tret = kstrtoul(number, 0, (unsigned long *)&count);\n\tif (ret)\n\t\treturn ret;\n\n out_reg:\n\tret = register_ftrace_function_probe(glob, tr, ops, count);\n\n\treturn ret < 0 ? ret : 0;\n}\n\nstatic int\nftrace_trace_onoff_callback(struct trace_array *tr, struct ftrace_hash *hash,\n\t\t\t    char *glob, char *cmd, char *param, int enable)\n{\n\tstruct ftrace_probe_ops *ops;\n\n\tif (!tr)\n\t\treturn -ENODEV;\n\n\t \n\tif (strcmp(cmd, \"traceon\") == 0)\n\t\tops = param ? &traceon_count_probe_ops : &traceon_probe_ops;\n\telse\n\t\tops = param ? &traceoff_count_probe_ops : &traceoff_probe_ops;\n\n\treturn ftrace_trace_probe_callback(tr, ops, hash, glob, cmd,\n\t\t\t\t\t   param, enable);\n}\n\nstatic int\nftrace_stacktrace_callback(struct trace_array *tr, struct ftrace_hash *hash,\n\t\t\t   char *glob, char *cmd, char *param, int enable)\n{\n\tstruct ftrace_probe_ops *ops;\n\n\tif (!tr)\n\t\treturn -ENODEV;\n\n\tops = param ? &stacktrace_count_probe_ops : &stacktrace_probe_ops;\n\n\treturn ftrace_trace_probe_callback(tr, ops, hash, glob, cmd,\n\t\t\t\t\t   param, enable);\n}\n\nstatic int\nftrace_dump_callback(struct trace_array *tr, struct ftrace_hash *hash,\n\t\t\t   char *glob, char *cmd, char *param, int enable)\n{\n\tstruct ftrace_probe_ops *ops;\n\n\tif (!tr)\n\t\treturn -ENODEV;\n\n\tops = &dump_probe_ops;\n\n\t \n\treturn ftrace_trace_probe_callback(tr, ops, hash, glob, cmd,\n\t\t\t\t\t   \"1\", enable);\n}\n\nstatic int\nftrace_cpudump_callback(struct trace_array *tr, struct ftrace_hash *hash,\n\t\t\t   char *glob, char *cmd, char *param, int enable)\n{\n\tstruct ftrace_probe_ops *ops;\n\n\tif (!tr)\n\t\treturn -ENODEV;\n\n\tops = &cpudump_probe_ops;\n\n\t \n\treturn ftrace_trace_probe_callback(tr, ops, hash, glob, cmd,\n\t\t\t\t\t   \"1\", enable);\n}\n\nstatic struct ftrace_func_command ftrace_traceon_cmd = {\n\t.name\t\t\t= \"traceon\",\n\t.func\t\t\t= ftrace_trace_onoff_callback,\n};\n\nstatic struct ftrace_func_command ftrace_traceoff_cmd = {\n\t.name\t\t\t= \"traceoff\",\n\t.func\t\t\t= ftrace_trace_onoff_callback,\n};\n\nstatic struct ftrace_func_command ftrace_stacktrace_cmd = {\n\t.name\t\t\t= \"stacktrace\",\n\t.func\t\t\t= ftrace_stacktrace_callback,\n};\n\nstatic struct ftrace_func_command ftrace_dump_cmd = {\n\t.name\t\t\t= \"dump\",\n\t.func\t\t\t= ftrace_dump_callback,\n};\n\nstatic struct ftrace_func_command ftrace_cpudump_cmd = {\n\t.name\t\t\t= \"cpudump\",\n\t.func\t\t\t= ftrace_cpudump_callback,\n};\n\nstatic int __init init_func_cmd_traceon(void)\n{\n\tint ret;\n\n\tret = register_ftrace_command(&ftrace_traceoff_cmd);\n\tif (ret)\n\t\treturn ret;\n\n\tret = register_ftrace_command(&ftrace_traceon_cmd);\n\tif (ret)\n\t\tgoto out_free_traceoff;\n\n\tret = register_ftrace_command(&ftrace_stacktrace_cmd);\n\tif (ret)\n\t\tgoto out_free_traceon;\n\n\tret = register_ftrace_command(&ftrace_dump_cmd);\n\tif (ret)\n\t\tgoto out_free_stacktrace;\n\n\tret = register_ftrace_command(&ftrace_cpudump_cmd);\n\tif (ret)\n\t\tgoto out_free_dump;\n\n\treturn 0;\n\n out_free_dump:\n\tunregister_ftrace_command(&ftrace_dump_cmd);\n out_free_stacktrace:\n\tunregister_ftrace_command(&ftrace_stacktrace_cmd);\n out_free_traceon:\n\tunregister_ftrace_command(&ftrace_traceon_cmd);\n out_free_traceoff:\n\tunregister_ftrace_command(&ftrace_traceoff_cmd);\n\n\treturn ret;\n}\n#else\nstatic inline int init_func_cmd_traceon(void)\n{\n\treturn 0;\n}\n#endif  \n\n__init int init_function_trace(void)\n{\n\tinit_func_cmd_traceon();\n\treturn register_tracer(&function_trace);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}