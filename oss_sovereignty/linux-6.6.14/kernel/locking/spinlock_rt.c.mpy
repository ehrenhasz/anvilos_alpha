{
  "module_name": "spinlock_rt.c",
  "hash_id": "acedc42b4b197a5404701f730d2781bd122aaba2f0e6b0dfe5294c58c80908b4",
  "original_prompt": "Ingested from linux-6.6.14/kernel/locking/spinlock_rt.c",
  "human_readable_source": "\n \n#include <linux/spinlock.h>\n#include <linux/export.h>\n\n#define RT_MUTEX_BUILD_SPINLOCKS\n#include \"rtmutex.c\"\n\n \n#define RTLOCK_RESCHED_OFFSETS\t\t\t\t\t\t\\\n\t(rcu_preempt_depth() << MIGHT_RESCHED_RCU_SHIFT)\n\n#define rtlock_might_resched()\t\t\t\t\t\t\\\n\t__might_resched(__FILE__, __LINE__, RTLOCK_RESCHED_OFFSETS)\n\nstatic __always_inline void rtlock_lock(struct rt_mutex_base *rtm)\n{\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\trtlock_slowlock(rtm);\n}\n\nstatic __always_inline void __rt_spin_lock(spinlock_t *lock)\n{\n\trtlock_might_resched();\n\trtlock_lock(&lock->lock);\n\trcu_read_lock();\n\tmigrate_disable();\n}\n\nvoid __sched rt_spin_lock(spinlock_t *lock)\n{\n\tspin_acquire(&lock->dep_map, 0, 0, _RET_IP_);\n\t__rt_spin_lock(lock);\n}\nEXPORT_SYMBOL(rt_spin_lock);\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\nvoid __sched rt_spin_lock_nested(spinlock_t *lock, int subclass)\n{\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\t__rt_spin_lock(lock);\n}\nEXPORT_SYMBOL(rt_spin_lock_nested);\n\nvoid __sched rt_spin_lock_nest_lock(spinlock_t *lock,\n\t\t\t\t    struct lockdep_map *nest_lock)\n{\n\tspin_acquire_nest(&lock->dep_map, 0, 0, nest_lock, _RET_IP_);\n\t__rt_spin_lock(lock);\n}\nEXPORT_SYMBOL(rt_spin_lock_nest_lock);\n#endif\n\nvoid __sched rt_spin_unlock(spinlock_t *lock)\n{\n\tspin_release(&lock->dep_map, _RET_IP_);\n\tmigrate_enable();\n\trcu_read_unlock();\n\n\tif (unlikely(!rt_mutex_cmpxchg_release(&lock->lock, current, NULL)))\n\t\trt_mutex_slowunlock(&lock->lock);\n}\nEXPORT_SYMBOL(rt_spin_unlock);\n\n \nvoid __sched rt_spin_lock_unlock(spinlock_t *lock)\n{\n\tspin_lock(lock);\n\tspin_unlock(lock);\n}\nEXPORT_SYMBOL(rt_spin_lock_unlock);\n\nstatic __always_inline int __rt_spin_trylock(spinlock_t *lock)\n{\n\tint ret = 1;\n\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(&lock->lock, NULL, current)))\n\t\tret = rt_mutex_slowtrylock(&lock->lock);\n\n\tif (ret) {\n\t\tspin_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}\n\nint __sched rt_spin_trylock(spinlock_t *lock)\n{\n\treturn __rt_spin_trylock(lock);\n}\nEXPORT_SYMBOL(rt_spin_trylock);\n\nint __sched rt_spin_trylock_bh(spinlock_t *lock)\n{\n\tint ret;\n\n\tlocal_bh_disable();\n\tret = __rt_spin_trylock(lock);\n\tif (!ret)\n\t\tlocal_bh_enable();\n\treturn ret;\n}\nEXPORT_SYMBOL(rt_spin_trylock_bh);\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\nvoid __rt_spin_lock_init(spinlock_t *lock, const char *name,\n\t\t\t struct lock_class_key *key, bool percpu)\n{\n\tu8 type = percpu ? LD_LOCK_PERCPU : LD_LOCK_NORMAL;\n\n\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));\n\tlockdep_init_map_type(&lock->dep_map, name, key, 0, LD_WAIT_CONFIG,\n\t\t\t      LD_WAIT_INV, type);\n}\nEXPORT_SYMBOL(__rt_spin_lock_init);\n#endif\n\n \n#define rwbase_set_and_save_current_state(state)\t\\\n\tcurrent_save_and_set_rtlock_wait_state()\n\n#define rwbase_restore_current_state()\t\t\t\\\n\tcurrent_restore_rtlock_saved_state()\n\nstatic __always_inline int\nrwbase_rtmutex_lock_state(struct rt_mutex_base *rtm, unsigned int state)\n{\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\trtlock_slowlock(rtm);\n\treturn 0;\n}\n\nstatic __always_inline int\nrwbase_rtmutex_slowlock_locked(struct rt_mutex_base *rtm, unsigned int state)\n{\n\trtlock_slowlock_locked(rtm);\n\treturn 0;\n}\n\nstatic __always_inline void rwbase_rtmutex_unlock(struct rt_mutex_base *rtm)\n{\n\tif (likely(rt_mutex_cmpxchg_acquire(rtm, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(rtm);\n}\n\nstatic __always_inline int  rwbase_rtmutex_trylock(struct rt_mutex_base *rtm)\n{\n\tif (likely(rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\treturn 1;\n\n\treturn rt_mutex_slowtrylock(rtm);\n}\n\n#define rwbase_signal_pending_state(state, current)\t(0)\n\n#define rwbase_schedule()\t\t\t\t\\\n\tschedule_rtlock()\n\n#include \"rwbase_rt.c\"\n \nint __sched rt_read_trylock(rwlock_t *rwlock)\n{\n\tint ret;\n\n\tret = rwbase_read_trylock(&rwlock->rwbase);\n\tif (ret) {\n\t\trwlock_acquire_read(&rwlock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}\nEXPORT_SYMBOL(rt_read_trylock);\n\nint __sched rt_write_trylock(rwlock_t *rwlock)\n{\n\tint ret;\n\n\tret = rwbase_write_trylock(&rwlock->rwbase);\n\tif (ret) {\n\t\trwlock_acquire(&rwlock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}\nEXPORT_SYMBOL(rt_write_trylock);\n\nvoid __sched rt_read_lock(rwlock_t *rwlock)\n{\n\trtlock_might_resched();\n\trwlock_acquire_read(&rwlock->dep_map, 0, 0, _RET_IP_);\n\trwbase_read_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n\trcu_read_lock();\n\tmigrate_disable();\n}\nEXPORT_SYMBOL(rt_read_lock);\n\nvoid __sched rt_write_lock(rwlock_t *rwlock)\n{\n\trtlock_might_resched();\n\trwlock_acquire(&rwlock->dep_map, 0, 0, _RET_IP_);\n\trwbase_write_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n\trcu_read_lock();\n\tmigrate_disable();\n}\nEXPORT_SYMBOL(rt_write_lock);\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\nvoid __sched rt_write_lock_nested(rwlock_t *rwlock, int subclass)\n{\n\trtlock_might_resched();\n\trwlock_acquire(&rwlock->dep_map, subclass, 0, _RET_IP_);\n\trwbase_write_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n\trcu_read_lock();\n\tmigrate_disable();\n}\nEXPORT_SYMBOL(rt_write_lock_nested);\n#endif\n\nvoid __sched rt_read_unlock(rwlock_t *rwlock)\n{\n\trwlock_release(&rwlock->dep_map, _RET_IP_);\n\tmigrate_enable();\n\trcu_read_unlock();\n\trwbase_read_unlock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n}\nEXPORT_SYMBOL(rt_read_unlock);\n\nvoid __sched rt_write_unlock(rwlock_t *rwlock)\n{\n\trwlock_release(&rwlock->dep_map, _RET_IP_);\n\trcu_read_unlock();\n\tmigrate_enable();\n\trwbase_write_unlock(&rwlock->rwbase);\n}\nEXPORT_SYMBOL(rt_write_unlock);\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\nvoid __rt_rwlock_init(rwlock_t *rwlock, const char *name,\n\t\t      struct lock_class_key *key)\n{\n\tdebug_check_no_locks_freed((void *)rwlock, sizeof(*rwlock));\n\tlockdep_init_map_wait(&rwlock->dep_map, name, key, 0, LD_WAIT_CONFIG);\n}\nEXPORT_SYMBOL(__rt_rwlock_init);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}