{
  "module_name": "rtmutex_api.c",
  "hash_id": "b6c3adc69bf4dfd374eebc8fc7b11e8981b0d127beb617ef5677342f20dfcf8b",
  "original_prompt": "Ingested from linux-6.6.14/kernel/locking/rtmutex_api.c",
  "human_readable_source": "\n \n#include <linux/spinlock.h>\n#include <linux/export.h>\n\n#define RT_MUTEX_BUILD_MUTEX\n#include \"rtmutex.c\"\n\n \nint max_lock_depth = 1024;\n\n \nstatic __always_inline int __rt_mutex_lock_common(struct rt_mutex *lock,\n\t\t\t\t\t\t  unsigned int state,\n\t\t\t\t\t\t  struct lockdep_map *nest_lock,\n\t\t\t\t\t\t  unsigned int subclass)\n{\n\tint ret;\n\n\tmight_sleep();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, _RET_IP_);\n\tret = __rt_mutex_lock(&lock->rtmutex, state);\n\tif (ret)\n\t\tmutex_release(&lock->dep_map, _RET_IP_);\n\treturn ret;\n}\n\nvoid rt_mutex_base_init(struct rt_mutex_base *rtb)\n{\n\t__rt_mutex_base_init(rtb);\n}\nEXPORT_SYMBOL(rt_mutex_base_init);\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n \nvoid __sched rt_mutex_lock_nested(struct rt_mutex *lock, unsigned int subclass)\n{\n\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, subclass);\n}\nEXPORT_SYMBOL_GPL(rt_mutex_lock_nested);\n\nvoid __sched _rt_mutex_lock_nest_lock(struct rt_mutex *lock, struct lockdep_map *nest_lock)\n{\n\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, nest_lock, 0);\n}\nEXPORT_SYMBOL_GPL(_rt_mutex_lock_nest_lock);\n\n#else  \n\n \nvoid __sched rt_mutex_lock(struct rt_mutex *lock)\n{\n\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, 0);\n}\nEXPORT_SYMBOL_GPL(rt_mutex_lock);\n#endif\n\n \nint __sched rt_mutex_lock_interruptible(struct rt_mutex *lock)\n{\n\treturn __rt_mutex_lock_common(lock, TASK_INTERRUPTIBLE, NULL, 0);\n}\nEXPORT_SYMBOL_GPL(rt_mutex_lock_interruptible);\n\n \nint __sched rt_mutex_lock_killable(struct rt_mutex *lock)\n{\n\treturn __rt_mutex_lock_common(lock, TASK_KILLABLE, NULL, 0);\n}\nEXPORT_SYMBOL_GPL(rt_mutex_lock_killable);\n\n \nint __sched rt_mutex_trylock(struct rt_mutex *lock)\n{\n\tint ret;\n\n\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))\n\t\treturn 0;\n\n\tret = __rt_mutex_trylock(&lock->rtmutex);\n\tif (ret)\n\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(rt_mutex_trylock);\n\n \nvoid __sched rt_mutex_unlock(struct rt_mutex *lock)\n{\n\tmutex_release(&lock->dep_map, _RET_IP_);\n\t__rt_mutex_unlock(&lock->rtmutex);\n}\nEXPORT_SYMBOL_GPL(rt_mutex_unlock);\n\n \nint __sched rt_mutex_futex_trylock(struct rt_mutex_base *lock)\n{\n\treturn rt_mutex_slowtrylock(lock);\n}\n\nint __sched __rt_mutex_futex_trylock(struct rt_mutex_base *lock)\n{\n\treturn __rt_mutex_slowtrylock(lock);\n}\n\n \nbool __sched __rt_mutex_futex_unlock(struct rt_mutex_base *lock,\n\t\t\t\t     struct rt_wake_q_head *wqh)\n{\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tdebug_rt_mutex_unlock(lock);\n\n\tif (!rt_mutex_has_waiters(lock)) {\n\t\tlock->owner = NULL;\n\t\treturn false;  \n\t}\n\n\t \n\tmark_wakeup_next_waiter(wqh, lock);\n\n\treturn true;  \n}\n\nvoid __sched rt_mutex_futex_unlock(struct rt_mutex_base *lock)\n{\n\tDEFINE_RT_WAKE_Q(wqh);\n\tunsigned long flags;\n\tbool postunlock;\n\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\tpostunlock = __rt_mutex_futex_unlock(lock, &wqh);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\tif (postunlock)\n\t\trt_mutex_postunlock(&wqh);\n}\n\n \nvoid __sched __rt_mutex_init(struct rt_mutex *lock, const char *name,\n\t\t\t     struct lock_class_key *key)\n{\n\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));\n\t__rt_mutex_base_init(&lock->rtmutex);\n\tlockdep_init_map_wait(&lock->dep_map, name, key, 0, LD_WAIT_SLEEP);\n}\nEXPORT_SYMBOL_GPL(__rt_mutex_init);\n\n \nvoid __sched rt_mutex_init_proxy_locked(struct rt_mutex_base *lock,\n\t\t\t\t\tstruct task_struct *proxy_owner)\n{\n\tstatic struct lock_class_key pi_futex_key;\n\n\t__rt_mutex_base_init(lock);\n\t \n\tlockdep_set_class(&lock->wait_lock, &pi_futex_key);\n\trt_mutex_set_owner(lock, proxy_owner);\n}\n\n \nvoid __sched rt_mutex_proxy_unlock(struct rt_mutex_base *lock)\n{\n\tdebug_rt_mutex_proxy_unlock(lock);\n\trt_mutex_clear_owner(lock);\n}\n\n \nint __sched __rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t\tstruct rt_mutex_waiter *waiter,\n\t\t\t\t\tstruct task_struct *task)\n{\n\tint ret;\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tif (try_to_take_rt_mutex(lock, task, NULL))\n\t\treturn 1;\n\n\t \n\tret = task_blocks_on_rt_mutex(lock, waiter, task, NULL,\n\t\t\t\t      RT_MUTEX_FULL_CHAINWALK);\n\n\tif (ret && !rt_mutex_owner(lock)) {\n\t\t \n\t\tret = 0;\n\t}\n\n\treturn ret;\n}\n\n \nint __sched rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t      struct rt_mutex_waiter *waiter,\n\t\t\t\t      struct task_struct *task)\n{\n\tint ret;\n\n\traw_spin_lock_irq(&lock->wait_lock);\n\tret = __rt_mutex_start_proxy_lock(lock, waiter, task);\n\tif (unlikely(ret))\n\t\tremove_waiter(lock, waiter);\n\traw_spin_unlock_irq(&lock->wait_lock);\n\n\treturn ret;\n}\n\n \nint __sched rt_mutex_wait_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t     struct hrtimer_sleeper *to,\n\t\t\t\t     struct rt_mutex_waiter *waiter)\n{\n\tint ret;\n\n\traw_spin_lock_irq(&lock->wait_lock);\n\t \n\tset_current_state(TASK_INTERRUPTIBLE);\n\tret = rt_mutex_slowlock_block(lock, NULL, TASK_INTERRUPTIBLE, to, waiter);\n\t \n\tfixup_rt_mutex_waiters(lock, true);\n\traw_spin_unlock_irq(&lock->wait_lock);\n\n\treturn ret;\n}\n\n \nbool __sched rt_mutex_cleanup_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t\t struct rt_mutex_waiter *waiter)\n{\n\tbool cleanup = false;\n\n\traw_spin_lock_irq(&lock->wait_lock);\n\t \n\ttry_to_take_rt_mutex(lock, current, waiter);\n\t \n\tif (rt_mutex_owner(lock) != current) {\n\t\tremove_waiter(lock, waiter);\n\t\tcleanup = true;\n\t}\n\t \n\tfixup_rt_mutex_waiters(lock, false);\n\n\traw_spin_unlock_irq(&lock->wait_lock);\n\n\treturn cleanup;\n}\n\n \nvoid __sched rt_mutex_adjust_pi(struct task_struct *task)\n{\n\tstruct rt_mutex_waiter *waiter;\n\tstruct rt_mutex_base *next_lock;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&task->pi_lock, flags);\n\n\twaiter = task->pi_blocked_on;\n\tif (!waiter || rt_waiter_node_equal(&waiter->tree, task_to_waiter_node(task))) {\n\t\traw_spin_unlock_irqrestore(&task->pi_lock, flags);\n\t\treturn;\n\t}\n\tnext_lock = waiter->lock;\n\traw_spin_unlock_irqrestore(&task->pi_lock, flags);\n\n\t \n\tget_task_struct(task);\n\n\trt_mutex_adjust_prio_chain(task, RT_MUTEX_MIN_CHAINWALK, NULL,\n\t\t\t\t   next_lock, NULL, task);\n}\n\n \nvoid __sched rt_mutex_postunlock(struct rt_wake_q_head *wqh)\n{\n\trt_mutex_wake_up_q(wqh);\n}\n\n#ifdef CONFIG_DEBUG_RT_MUTEXES\nvoid rt_mutex_debug_task_free(struct task_struct *task)\n{\n\tDEBUG_LOCKS_WARN_ON(!RB_EMPTY_ROOT(&task->pi_waiters.rb_root));\n\tDEBUG_LOCKS_WARN_ON(task->pi_blocked_on);\n}\n#endif\n\n#ifdef CONFIG_PREEMPT_RT\n \nvoid __mutex_rt_init(struct mutex *mutex, const char *name,\n\t\t     struct lock_class_key *key)\n{\n\tdebug_check_no_locks_freed((void *)mutex, sizeof(*mutex));\n\tlockdep_init_map_wait(&mutex->dep_map, name, key, 0, LD_WAIT_SLEEP);\n}\nEXPORT_SYMBOL(__mutex_rt_init);\n\nstatic __always_inline int __mutex_lock_common(struct mutex *lock,\n\t\t\t\t\t       unsigned int state,\n\t\t\t\t\t       unsigned int subclass,\n\t\t\t\t\t       struct lockdep_map *nest_lock,\n\t\t\t\t\t       unsigned long ip)\n{\n\tint ret;\n\n\tmight_sleep();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\tret = __rt_mutex_lock(&lock->rtmutex, state);\n\tif (ret)\n\t\tmutex_release(&lock->dep_map, ip);\n\telse\n\t\tlock_acquired(&lock->dep_map, ip);\n\treturn ret;\n}\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\nvoid __sched mutex_lock_nested(struct mutex *lock, unsigned int subclass)\n{\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}\nEXPORT_SYMBOL_GPL(mutex_lock_nested);\n\nvoid __sched _mutex_lock_nest_lock(struct mutex *lock,\n\t\t\t\t   struct lockdep_map *nest_lock)\n{\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, nest_lock, _RET_IP_);\n}\nEXPORT_SYMBOL_GPL(_mutex_lock_nest_lock);\n\nint __sched mutex_lock_interruptible_nested(struct mutex *lock,\n\t\t\t\t\t    unsigned int subclass)\n{\n\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}\nEXPORT_SYMBOL_GPL(mutex_lock_interruptible_nested);\n\nint __sched mutex_lock_killable_nested(struct mutex *lock,\n\t\t\t\t\t    unsigned int subclass)\n{\n\treturn __mutex_lock_common(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);\n}\nEXPORT_SYMBOL_GPL(mutex_lock_killable_nested);\n\nvoid __sched mutex_lock_io_nested(struct mutex *lock, unsigned int subclass)\n{\n\tint token;\n\n\tmight_sleep();\n\n\ttoken = io_schedule_prepare();\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}\nEXPORT_SYMBOL_GPL(mutex_lock_io_nested);\n\n#else  \n\nvoid __sched mutex_lock(struct mutex *lock)\n{\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n}\nEXPORT_SYMBOL(mutex_lock);\n\nint __sched mutex_lock_interruptible(struct mutex *lock)\n{\n\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}\nEXPORT_SYMBOL(mutex_lock_interruptible);\n\nint __sched mutex_lock_killable(struct mutex *lock)\n{\n\treturn __mutex_lock_common(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);\n}\nEXPORT_SYMBOL(mutex_lock_killable);\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}\nEXPORT_SYMBOL(mutex_lock_io);\n#endif  \n\nint __sched mutex_trylock(struct mutex *lock)\n{\n\tint ret;\n\n\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))\n\t\treturn 0;\n\n\tret = __rt_mutex_trylock(&lock->rtmutex);\n\tif (ret)\n\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(mutex_trylock);\n\nvoid __sched mutex_unlock(struct mutex *lock)\n{\n\tmutex_release(&lock->dep_map, _RET_IP_);\n\t__rt_mutex_unlock(&lock->rtmutex);\n}\nEXPORT_SYMBOL(mutex_unlock);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}