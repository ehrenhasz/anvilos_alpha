{
  "module_name": "ww_mutex.h",
  "hash_id": "64d4022d379ff28ef26aff28ef14b7551427f79590b8933e8c4c6e0f5a8644fd",
  "original_prompt": "Ingested from linux-6.6.14/kernel/locking/ww_mutex.h",
  "human_readable_source": " \n\n#ifndef WW_RT\n\n#define MUTEX\t\tmutex\n#define MUTEX_WAITER\tmutex_waiter\n\nstatic inline struct mutex_waiter *\n__ww_waiter_first(struct mutex *lock)\n{\n\tstruct mutex_waiter *w;\n\n\tw = list_first_entry(&lock->wait_list, struct mutex_waiter, list);\n\tif (list_entry_is_head(w, &lock->wait_list, list))\n\t\treturn NULL;\n\n\treturn w;\n}\n\nstatic inline struct mutex_waiter *\n__ww_waiter_next(struct mutex *lock, struct mutex_waiter *w)\n{\n\tw = list_next_entry(w, list);\n\tif (list_entry_is_head(w, &lock->wait_list, list))\n\t\treturn NULL;\n\n\treturn w;\n}\n\nstatic inline struct mutex_waiter *\n__ww_waiter_prev(struct mutex *lock, struct mutex_waiter *w)\n{\n\tw = list_prev_entry(w, list);\n\tif (list_entry_is_head(w, &lock->wait_list, list))\n\t\treturn NULL;\n\n\treturn w;\n}\n\nstatic inline struct mutex_waiter *\n__ww_waiter_last(struct mutex *lock)\n{\n\tstruct mutex_waiter *w;\n\n\tw = list_last_entry(&lock->wait_list, struct mutex_waiter, list);\n\tif (list_entry_is_head(w, &lock->wait_list, list))\n\t\treturn NULL;\n\n\treturn w;\n}\n\nstatic inline void\n__ww_waiter_add(struct mutex *lock, struct mutex_waiter *waiter, struct mutex_waiter *pos)\n{\n\tstruct list_head *p = &lock->wait_list;\n\tif (pos)\n\t\tp = &pos->list;\n\t__mutex_add_waiter(lock, waiter, p);\n}\n\nstatic inline struct task_struct *\n__ww_mutex_owner(struct mutex *lock)\n{\n\treturn __mutex_owner(lock);\n}\n\nstatic inline bool\n__ww_mutex_has_waiters(struct mutex *lock)\n{\n\treturn atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS;\n}\n\nstatic inline void lock_wait_lock(struct mutex *lock)\n{\n\traw_spin_lock(&lock->wait_lock);\n}\n\nstatic inline void unlock_wait_lock(struct mutex *lock)\n{\n\traw_spin_unlock(&lock->wait_lock);\n}\n\nstatic inline void lockdep_assert_wait_lock_held(struct mutex *lock)\n{\n\tlockdep_assert_held(&lock->wait_lock);\n}\n\n#else  \n\n#define MUTEX\t\trt_mutex\n#define MUTEX_WAITER\trt_mutex_waiter\n\nstatic inline struct rt_mutex_waiter *\n__ww_waiter_first(struct rt_mutex *lock)\n{\n\tstruct rb_node *n = rb_first(&lock->rtmutex.waiters.rb_root);\n\tif (!n)\n\t\treturn NULL;\n\treturn rb_entry(n, struct rt_mutex_waiter, tree.entry);\n}\n\nstatic inline struct rt_mutex_waiter *\n__ww_waiter_next(struct rt_mutex *lock, struct rt_mutex_waiter *w)\n{\n\tstruct rb_node *n = rb_next(&w->tree.entry);\n\tif (!n)\n\t\treturn NULL;\n\treturn rb_entry(n, struct rt_mutex_waiter, tree.entry);\n}\n\nstatic inline struct rt_mutex_waiter *\n__ww_waiter_prev(struct rt_mutex *lock, struct rt_mutex_waiter *w)\n{\n\tstruct rb_node *n = rb_prev(&w->tree.entry);\n\tif (!n)\n\t\treturn NULL;\n\treturn rb_entry(n, struct rt_mutex_waiter, tree.entry);\n}\n\nstatic inline struct rt_mutex_waiter *\n__ww_waiter_last(struct rt_mutex *lock)\n{\n\tstruct rb_node *n = rb_last(&lock->rtmutex.waiters.rb_root);\n\tif (!n)\n\t\treturn NULL;\n\treturn rb_entry(n, struct rt_mutex_waiter, tree.entry);\n}\n\nstatic inline void\n__ww_waiter_add(struct rt_mutex *lock, struct rt_mutex_waiter *waiter, struct rt_mutex_waiter *pos)\n{\n\t \n}\n\nstatic inline struct task_struct *\n__ww_mutex_owner(struct rt_mutex *lock)\n{\n\treturn rt_mutex_owner(&lock->rtmutex);\n}\n\nstatic inline bool\n__ww_mutex_has_waiters(struct rt_mutex *lock)\n{\n\treturn rt_mutex_has_waiters(&lock->rtmutex);\n}\n\nstatic inline void lock_wait_lock(struct rt_mutex *lock)\n{\n\traw_spin_lock(&lock->rtmutex.wait_lock);\n}\n\nstatic inline void unlock_wait_lock(struct rt_mutex *lock)\n{\n\traw_spin_unlock(&lock->rtmutex.wait_lock);\n}\n\nstatic inline void lockdep_assert_wait_lock_held(struct rt_mutex *lock)\n{\n\tlockdep_assert_held(&lock->rtmutex.wait_lock);\n}\n\n#endif  \n\n \n\n \nstatic __always_inline void\nww_mutex_lock_acquired(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)\n{\n#ifdef DEBUG_WW_MUTEXES\n\t \n\tDEBUG_LOCKS_WARN_ON(ww->ctx);\n\n\t \n\tDEBUG_LOCKS_WARN_ON(ww_ctx->done_acquire);\n\n\tif (ww_ctx->contending_lock) {\n\t\t \n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock != ww);\n\n\t\t \n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->acquired > 0);\n\t\tww_ctx->contending_lock = NULL;\n\t}\n\n\t \n\tDEBUG_LOCKS_WARN_ON(ww_ctx->ww_class != ww->ww_class);\n#endif\n\tww_ctx->acquired++;\n\tww->ctx = ww_ctx;\n}\n\n \nstatic inline bool\n__ww_ctx_less(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n \n#ifdef WW_RT\n\t \n\tint a_prio = a->task->prio;\n\tint b_prio = b->task->prio;\n\n\tif (rt_prio(a_prio) || rt_prio(b_prio)) {\n\n\t\tif (a_prio > b_prio)\n\t\t\treturn true;\n\n\t\tif (a_prio < b_prio)\n\t\t\treturn false;\n\n\t\t \n\n\t\tif (dl_prio(a_prio)) {\n\t\t\tif (dl_time_before(b->task->dl.deadline,\n\t\t\t\t\t   a->task->dl.deadline))\n\t\t\t\treturn true;\n\n\t\t\tif (dl_time_before(a->task->dl.deadline,\n\t\t\t\t\t   b->task->dl.deadline))\n\t\t\t\treturn false;\n\t\t}\n\n\t\t \n\t}\n#endif\n\n\t \n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}\n\n \nstatic bool\n__ww_mutex_die(struct MUTEX *lock, struct MUTEX_WAITER *waiter,\n\t       struct ww_acquire_ctx *ww_ctx)\n{\n\tif (!ww_ctx->is_wait_die)\n\t\treturn false;\n\n\tif (waiter->ww_ctx->acquired > 0 && __ww_ctx_less(waiter->ww_ctx, ww_ctx)) {\n#ifndef WW_RT\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n#endif\n\t\twake_up_process(waiter->task);\n\t}\n\n\treturn true;\n}\n\n \nstatic bool __ww_mutex_wound(struct MUTEX *lock,\n\t\t\t     struct ww_acquire_ctx *ww_ctx,\n\t\t\t     struct ww_acquire_ctx *hold_ctx)\n{\n\tstruct task_struct *owner = __ww_mutex_owner(lock);\n\n\tlockdep_assert_wait_lock_held(lock);\n\n\t \n\tif (!hold_ctx)\n\t\treturn false;\n\n\t \n\tif (!owner)\n\t\treturn false;\n\n\tif (ww_ctx->acquired > 0 && __ww_ctx_less(hold_ctx, ww_ctx)) {\n\t\thold_ctx->wounded = 1;\n\n\t\t \n\t\tif (owner != current)\n\t\t\twake_up_process(owner);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nstatic void\n__ww_mutex_check_waiters(struct MUTEX *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct MUTEX_WAITER *cur;\n\n\tlockdep_assert_wait_lock_held(lock);\n\n\tfor (cur = __ww_waiter_first(lock); cur;\n\t     cur = __ww_waiter_next(lock, cur)) {\n\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_mutex_die(lock, cur, ww_ctx) ||\n\t\t    __ww_mutex_wound(lock, cur->ww_ctx, ww_ctx))\n\t\t\tbreak;\n\t}\n}\n\n \nstatic __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t \n\tsmp_mb();  \n\n\t \n\tif (likely(!__ww_mutex_has_waiters(&lock->base)))\n\t\treturn;\n\n\t \n\tlock_wait_lock(&lock->base);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tunlock_wait_lock(&lock->base);\n}\n\nstatic __always_inline int\n__ww_mutex_kill(struct MUTEX *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tif (ww_ctx->acquired > 0) {\n#ifdef DEBUG_WW_MUTEXES\n\t\tstruct ww_mutex *ww;\n\n\t\tww = container_of(lock, struct ww_mutex, base);\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock);\n\t\tww_ctx->contending_lock = ww;\n#endif\n\t\treturn -EDEADLK;\n\t}\n\n\treturn 0;\n}\n\n \nstatic inline int\n__ww_mutex_check_kill(struct MUTEX *lock, struct MUTEX_WAITER *waiter,\n\t\t      struct ww_acquire_ctx *ctx)\n{\n\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\tstruct ww_acquire_ctx *hold_ctx = READ_ONCE(ww->ctx);\n\tstruct MUTEX_WAITER *cur;\n\n\tif (ctx->acquired == 0)\n\t\treturn 0;\n\n\tif (!ctx->is_wait_die) {\n\t\tif (ctx->wounded)\n\t\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t\treturn 0;\n\t}\n\n\tif (hold_ctx && __ww_ctx_less(ctx, hold_ctx))\n\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t \n\tfor (cur = __ww_waiter_prev(lock, waiter); cur;\n\t     cur = __ww_waiter_prev(lock, cur)) {\n\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\treturn __ww_mutex_kill(lock, ctx);\n\t}\n\n\treturn 0;\n}\n\n \nstatic inline int\n__ww_mutex_add_waiter(struct MUTEX_WAITER *waiter,\n\t\t      struct MUTEX *lock,\n\t\t      struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct MUTEX_WAITER *cur, *pos = NULL;\n\tbool is_wait_die;\n\n\tif (!ww_ctx) {\n\t\t__ww_waiter_add(lock, waiter, NULL);\n\t\treturn 0;\n\t}\n\n\tis_wait_die = ww_ctx->is_wait_die;\n\n\t \n\tfor (cur = __ww_waiter_last(lock); cur;\n\t     cur = __ww_waiter_prev(lock, cur)) {\n\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_ctx_less(ww_ctx, cur->ww_ctx)) {\n\t\t\t \n\t\t\tif (is_wait_die) {\n\t\t\t\tint ret = __ww_mutex_kill(lock, ww_ctx);\n\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\n\t\tpos = cur;\n\n\t\t \n\t\t__ww_mutex_die(lock, cur, ww_ctx);\n\t}\n\n\t__ww_waiter_add(lock, waiter, pos);\n\n\t \n\tif (!is_wait_die) {\n\t\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\n\t\t \n\t\tsmp_mb();\n\t\t__ww_mutex_wound(lock, ww_ctx, ww->ctx);\n\t}\n\n\treturn 0;\n}\n\nstatic inline void __ww_mutex_unlock(struct ww_mutex *lock)\n{\n\tif (lock->ctx) {\n#ifdef DEBUG_WW_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}