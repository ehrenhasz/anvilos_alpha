{
  "module_name": "locktorture.c",
  "hash_id": "45213288f1bcb91c44e8fbc9a6af720fcdbe3e2c6f39028eeaf61d9c07d0e0d1",
  "original_prompt": "Ingested from linux-6.6.14/kernel/locking/locktorture.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) fmt\n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\n#include <linux/sched/rt.h>\n#include <linux/spinlock.h>\n#include <linux/mutex.h>\n#include <linux/rwsem.h>\n#include <linux/smp.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/rtmutex.h>\n#include <linux/atomic.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/slab.h>\n#include <linux/torture.h>\n#include <linux/reboot.h>\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Paul E. McKenney <paulmck@linux.ibm.com>\");\n\ntorture_param(int, nwriters_stress, -1, \"Number of write-locking stress-test threads\");\ntorture_param(int, nreaders_stress, -1, \"Number of read-locking stress-test threads\");\ntorture_param(int, long_hold, 100, \"Do occasional long hold of lock (ms), 0=disable\");\ntorture_param(int, onoff_holdoff, 0, \"Time after boot before CPU hotplugs (s)\");\ntorture_param(int, onoff_interval, 0, \"Time between CPU hotplugs (s), 0=disable\");\ntorture_param(int, shuffle_interval, 3, \"Number of jiffies between shuffles, 0=disable\");\ntorture_param(int, shutdown_secs, 0, \"Shutdown time (j), <= zero to disable.\");\ntorture_param(int, stat_interval, 60, \"Number of seconds between stats printk()s\");\ntorture_param(int, stutter, 5, \"Number of jiffies to run/halt test, 0=disable\");\ntorture_param(int, rt_boost, 2,\n\t\t   \"Do periodic rt-boost. 0=Disable, 1=Only for rt_mutex, 2=For all lock types.\");\ntorture_param(int, rt_boost_factor, 50, \"A factor determining how often rt-boost happens.\");\ntorture_param(int, writer_fifo, 0, \"Run writers at sched_set_fifo() priority\");\ntorture_param(int, verbose, 1, \"Enable verbose debugging printk()s\");\ntorture_param(int, nested_locks, 0, \"Number of nested locks (max = 8)\");\n \n#define MAX_NESTED_LOCKS 8\n\nstatic char *torture_type = IS_ENABLED(CONFIG_PREEMPT_RT) ? \"raw_spin_lock\" : \"spin_lock\";\nmodule_param(torture_type, charp, 0444);\nMODULE_PARM_DESC(torture_type,\n\t\t \"Type of lock to torture (spin_lock, spin_lock_irq, mutex_lock, ...)\");\n\nstatic struct task_struct *stats_task;\nstatic struct task_struct **writer_tasks;\nstatic struct task_struct **reader_tasks;\n\nstatic bool lock_is_write_held;\nstatic atomic_t lock_is_read_held;\nstatic unsigned long last_lock_release;\n\nstruct lock_stress_stats {\n\tlong n_lock_fail;\n\tlong n_lock_acquired;\n};\n\n \nstatic void lock_torture_cleanup(void);\n\n \nstruct lock_torture_ops {\n\tvoid (*init)(void);\n\tvoid (*exit)(void);\n\tint (*nested_lock)(int tid, u32 lockset);\n\tint (*writelock)(int tid);\n\tvoid (*write_delay)(struct torture_random_state *trsp);\n\tvoid (*task_boost)(struct torture_random_state *trsp);\n\tvoid (*writeunlock)(int tid);\n\tvoid (*nested_unlock)(int tid, u32 lockset);\n\tint (*readlock)(int tid);\n\tvoid (*read_delay)(struct torture_random_state *trsp);\n\tvoid (*readunlock)(int tid);\n\n\tunsigned long flags;  \n\tconst char *name;\n};\n\nstruct lock_torture_cxt {\n\tint nrealwriters_stress;\n\tint nrealreaders_stress;\n\tbool debug_lock;\n\tbool init_called;\n\tatomic_t n_lock_torture_errors;\n\tstruct lock_torture_ops *cur_ops;\n\tstruct lock_stress_stats *lwsa;  \n\tstruct lock_stress_stats *lrsa;  \n};\nstatic struct lock_torture_cxt cxt = { 0, 0, false, false,\n\t\t\t\t       ATOMIC_INIT(0),\n\t\t\t\t       NULL, NULL};\n \n\nstatic int torture_lock_busted_write_lock(int tid __maybe_unused)\n{\n\treturn 0;   \n}\n\nstatic void torture_lock_busted_write_delay(struct torture_random_state *trsp)\n{\n\tconst unsigned long longdelay_ms = long_hold ? long_hold : ULONG_MAX;\n\n\t \n\tif (!(torture_random(trsp) %\n\t      (cxt.nrealwriters_stress * 2000 * longdelay_ms)))\n\t\tmdelay(longdelay_ms);\n\tif (!(torture_random(trsp) % (cxt.nrealwriters_stress * 20000)))\n\t\ttorture_preempt_schedule();   \n}\n\nstatic void torture_lock_busted_write_unlock(int tid __maybe_unused)\n{\n\t   \n}\n\nstatic void __torture_rt_boost(struct torture_random_state *trsp)\n{\n\tconst unsigned int factor = rt_boost_factor;\n\n\tif (!rt_task(current)) {\n\t\t \n\t\tif (trsp && !(torture_random(trsp) %\n\t\t\t      (cxt.nrealwriters_stress * factor))) {\n\t\t\tsched_set_fifo(current);\n\t\t} else  \n\t\t\treturn;\n\t} else {\n\t\t \n\t\tif (!trsp || !(torture_random(trsp) %\n\t\t\t       (cxt.nrealwriters_stress * factor * 2))) {\n\t\t\tsched_set_normal(current, 0);\n\t\t} else  \n\t\t\treturn;\n\t}\n}\n\nstatic void torture_rt_boost(struct torture_random_state *trsp)\n{\n\tif (rt_boost != 2)\n\t\treturn;\n\n\t__torture_rt_boost(trsp);\n}\n\nstatic struct lock_torture_ops lock_busted_ops = {\n\t.writelock\t= torture_lock_busted_write_lock,\n\t.write_delay\t= torture_lock_busted_write_delay,\n\t.task_boost     = torture_rt_boost,\n\t.writeunlock\t= torture_lock_busted_write_unlock,\n\t.readlock       = NULL,\n\t.read_delay     = NULL,\n\t.readunlock     = NULL,\n\t.name\t\t= \"lock_busted\"\n};\n\nstatic DEFINE_SPINLOCK(torture_spinlock);\n\nstatic int torture_spin_lock_write_lock(int tid __maybe_unused)\n__acquires(torture_spinlock)\n{\n\tspin_lock(&torture_spinlock);\n\treturn 0;\n}\n\nstatic void torture_spin_lock_write_delay(struct torture_random_state *trsp)\n{\n\tconst unsigned long shortdelay_us = 2;\n\tconst unsigned long longdelay_ms = long_hold ? long_hold : ULONG_MAX;\n\tunsigned long j;\n\n\t \n\tif (!(torture_random(trsp) % (cxt.nrealwriters_stress * 2000 * longdelay_ms))) {\n\t\tj = jiffies;\n\t\tmdelay(longdelay_ms);\n\t\tpr_alert(\"%s: delay = %lu jiffies.\\n\", __func__, jiffies - j);\n\t}\n\tif (!(torture_random(trsp) % (cxt.nrealwriters_stress * 200 * shortdelay_us)))\n\t\tudelay(shortdelay_us);\n\tif (!(torture_random(trsp) % (cxt.nrealwriters_stress * 20000)))\n\t\ttorture_preempt_schedule();   \n}\n\nstatic void torture_spin_lock_write_unlock(int tid __maybe_unused)\n__releases(torture_spinlock)\n{\n\tspin_unlock(&torture_spinlock);\n}\n\nstatic struct lock_torture_ops spin_lock_ops = {\n\t.writelock\t= torture_spin_lock_write_lock,\n\t.write_delay\t= torture_spin_lock_write_delay,\n\t.task_boost     = torture_rt_boost,\n\t.writeunlock\t= torture_spin_lock_write_unlock,\n\t.readlock       = NULL,\n\t.read_delay     = NULL,\n\t.readunlock     = NULL,\n\t.name\t\t= \"spin_lock\"\n};\n\nstatic int torture_spin_lock_write_lock_irq(int tid __maybe_unused)\n__acquires(torture_spinlock)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&torture_spinlock, flags);\n\tcxt.cur_ops->flags = flags;\n\treturn 0;\n}\n\nstatic void torture_lock_spin_write_unlock_irq(int tid __maybe_unused)\n__releases(torture_spinlock)\n{\n\tspin_unlock_irqrestore(&torture_spinlock, cxt.cur_ops->flags);\n}\n\nstatic struct lock_torture_ops spin_lock_irq_ops = {\n\t.writelock\t= torture_spin_lock_write_lock_irq,\n\t.write_delay\t= torture_spin_lock_write_delay,\n\t.task_boost     = torture_rt_boost,\n\t.writeunlock\t= torture_lock_spin_write_unlock_irq,\n\t.readlock       = NULL,\n\t.read_delay     = NULL,\n\t.readunlock     = NULL,\n\t.name\t\t= \"spin_lock_irq\"\n};\n\nstatic DEFINE_RAW_SPINLOCK(torture_raw_spinlock);\n\nstatic int torture_raw_spin_lock_write_lock(int tid __maybe_unused)\n__acquires(torture_raw_spinlock)\n{\n\traw_spin_lock(&torture_raw_spinlock);\n\treturn 0;\n}\n\nstatic void torture_raw_spin_lock_write_unlock(int tid __maybe_unused)\n__releases(torture_raw_spinlock)\n{\n\traw_spin_unlock(&torture_raw_spinlock);\n}\n\nstatic struct lock_torture_ops raw_spin_lock_ops = {\n\t.writelock\t= torture_raw_spin_lock_write_lock,\n\t.write_delay\t= torture_spin_lock_write_delay,\n\t.task_boost\t= torture_rt_boost,\n\t.writeunlock\t= torture_raw_spin_lock_write_unlock,\n\t.readlock\t= NULL,\n\t.read_delay\t= NULL,\n\t.readunlock\t= NULL,\n\t.name\t\t= \"raw_spin_lock\"\n};\n\nstatic int torture_raw_spin_lock_write_lock_irq(int tid __maybe_unused)\n__acquires(torture_raw_spinlock)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&torture_raw_spinlock, flags);\n\tcxt.cur_ops->flags = flags;\n\treturn 0;\n}\n\nstatic void torture_raw_spin_lock_write_unlock_irq(int tid __maybe_unused)\n__releases(torture_raw_spinlock)\n{\n\traw_spin_unlock_irqrestore(&torture_raw_spinlock, cxt.cur_ops->flags);\n}\n\nstatic struct lock_torture_ops raw_spin_lock_irq_ops = {\n\t.writelock\t= torture_raw_spin_lock_write_lock_irq,\n\t.write_delay\t= torture_spin_lock_write_delay,\n\t.task_boost\t= torture_rt_boost,\n\t.writeunlock\t= torture_raw_spin_lock_write_unlock_irq,\n\t.readlock\t= NULL,\n\t.read_delay\t= NULL,\n\t.readunlock\t= NULL,\n\t.name\t\t= \"raw_spin_lock_irq\"\n};\n\nstatic DEFINE_RWLOCK(torture_rwlock);\n\nstatic int torture_rwlock_write_lock(int tid __maybe_unused)\n__acquires(torture_rwlock)\n{\n\twrite_lock(&torture_rwlock);\n\treturn 0;\n}\n\nstatic void torture_rwlock_write_delay(struct torture_random_state *trsp)\n{\n\tconst unsigned long shortdelay_us = 2;\n\tconst unsigned long longdelay_ms = long_hold ? long_hold : ULONG_MAX;\n\n\t \n\tif (!(torture_random(trsp) %\n\t      (cxt.nrealwriters_stress * 2000 * longdelay_ms)))\n\t\tmdelay(longdelay_ms);\n\telse\n\t\tudelay(shortdelay_us);\n}\n\nstatic void torture_rwlock_write_unlock(int tid __maybe_unused)\n__releases(torture_rwlock)\n{\n\twrite_unlock(&torture_rwlock);\n}\n\nstatic int torture_rwlock_read_lock(int tid __maybe_unused)\n__acquires(torture_rwlock)\n{\n\tread_lock(&torture_rwlock);\n\treturn 0;\n}\n\nstatic void torture_rwlock_read_delay(struct torture_random_state *trsp)\n{\n\tconst unsigned long shortdelay_us = 10;\n\tconst unsigned long longdelay_ms = 100;\n\n\t \n\tif (!(torture_random(trsp) %\n\t      (cxt.nrealreaders_stress * 2000 * longdelay_ms)))\n\t\tmdelay(longdelay_ms);\n\telse\n\t\tudelay(shortdelay_us);\n}\n\nstatic void torture_rwlock_read_unlock(int tid __maybe_unused)\n__releases(torture_rwlock)\n{\n\tread_unlock(&torture_rwlock);\n}\n\nstatic struct lock_torture_ops rw_lock_ops = {\n\t.writelock\t= torture_rwlock_write_lock,\n\t.write_delay\t= torture_rwlock_write_delay,\n\t.task_boost     = torture_rt_boost,\n\t.writeunlock\t= torture_rwlock_write_unlock,\n\t.readlock       = torture_rwlock_read_lock,\n\t.read_delay     = torture_rwlock_read_delay,\n\t.readunlock     = torture_rwlock_read_unlock,\n\t.name\t\t= \"rw_lock\"\n};\n\nstatic int torture_rwlock_write_lock_irq(int tid __maybe_unused)\n__acquires(torture_rwlock)\n{\n\tunsigned long flags;\n\n\twrite_lock_irqsave(&torture_rwlock, flags);\n\tcxt.cur_ops->flags = flags;\n\treturn 0;\n}\n\nstatic void torture_rwlock_write_unlock_irq(int tid __maybe_unused)\n__releases(torture_rwlock)\n{\n\twrite_unlock_irqrestore(&torture_rwlock, cxt.cur_ops->flags);\n}\n\nstatic int torture_rwlock_read_lock_irq(int tid __maybe_unused)\n__acquires(torture_rwlock)\n{\n\tunsigned long flags;\n\n\tread_lock_irqsave(&torture_rwlock, flags);\n\tcxt.cur_ops->flags = flags;\n\treturn 0;\n}\n\nstatic void torture_rwlock_read_unlock_irq(int tid __maybe_unused)\n__releases(torture_rwlock)\n{\n\tread_unlock_irqrestore(&torture_rwlock, cxt.cur_ops->flags);\n}\n\nstatic struct lock_torture_ops rw_lock_irq_ops = {\n\t.writelock\t= torture_rwlock_write_lock_irq,\n\t.write_delay\t= torture_rwlock_write_delay,\n\t.task_boost     = torture_rt_boost,\n\t.writeunlock\t= torture_rwlock_write_unlock_irq,\n\t.readlock       = torture_rwlock_read_lock_irq,\n\t.read_delay     = torture_rwlock_read_delay,\n\t.readunlock     = torture_rwlock_read_unlock_irq,\n\t.name\t\t= \"rw_lock_irq\"\n};\n\nstatic DEFINE_MUTEX(torture_mutex);\nstatic struct mutex torture_nested_mutexes[MAX_NESTED_LOCKS];\nstatic struct lock_class_key nested_mutex_keys[MAX_NESTED_LOCKS];\n\nstatic void torture_mutex_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < MAX_NESTED_LOCKS; i++)\n\t\t__mutex_init(&torture_nested_mutexes[i], __func__,\n\t\t\t     &nested_mutex_keys[i]);\n}\n\nstatic int torture_mutex_nested_lock(int tid __maybe_unused,\n\t\t\t\t     u32 lockset)\n{\n\tint i;\n\n\tfor (i = 0; i < nested_locks; i++)\n\t\tif (lockset & (1 << i))\n\t\t\tmutex_lock(&torture_nested_mutexes[i]);\n\treturn 0;\n}\n\nstatic int torture_mutex_lock(int tid __maybe_unused)\n__acquires(torture_mutex)\n{\n\tmutex_lock(&torture_mutex);\n\treturn 0;\n}\n\nstatic void torture_mutex_delay(struct torture_random_state *trsp)\n{\n\tconst unsigned long longdelay_ms = long_hold ? long_hold : ULONG_MAX;\n\n\t \n\tif (!(torture_random(trsp) %\n\t      (cxt.nrealwriters_stress * 2000 * longdelay_ms)))\n\t\tmdelay(longdelay_ms * 5);\n\tif (!(torture_random(trsp) % (cxt.nrealwriters_stress * 20000)))\n\t\ttorture_preempt_schedule();   \n}\n\nstatic void torture_mutex_unlock(int tid __maybe_unused)\n__releases(torture_mutex)\n{\n\tmutex_unlock(&torture_mutex);\n}\n\nstatic void torture_mutex_nested_unlock(int tid __maybe_unused,\n\t\t\t\t\tu32 lockset)\n{\n\tint i;\n\n\tfor (i = nested_locks - 1; i >= 0; i--)\n\t\tif (lockset & (1 << i))\n\t\t\tmutex_unlock(&torture_nested_mutexes[i]);\n}\n\nstatic struct lock_torture_ops mutex_lock_ops = {\n\t.init\t\t= torture_mutex_init,\n\t.nested_lock\t= torture_mutex_nested_lock,\n\t.writelock\t= torture_mutex_lock,\n\t.write_delay\t= torture_mutex_delay,\n\t.task_boost     = torture_rt_boost,\n\t.writeunlock\t= torture_mutex_unlock,\n\t.nested_unlock\t= torture_mutex_nested_unlock,\n\t.readlock       = NULL,\n\t.read_delay     = NULL,\n\t.readunlock     = NULL,\n\t.name\t\t= \"mutex_lock\"\n};\n\n#include <linux/ww_mutex.h>\n \nstatic DEFINE_WD_CLASS(torture_ww_class);\nstatic struct ww_mutex torture_ww_mutex_0, torture_ww_mutex_1, torture_ww_mutex_2;\nstatic struct ww_acquire_ctx *ww_acquire_ctxs;\n\nstatic void torture_ww_mutex_init(void)\n{\n\tww_mutex_init(&torture_ww_mutex_0, &torture_ww_class);\n\tww_mutex_init(&torture_ww_mutex_1, &torture_ww_class);\n\tww_mutex_init(&torture_ww_mutex_2, &torture_ww_class);\n\n\tww_acquire_ctxs = kmalloc_array(cxt.nrealwriters_stress,\n\t\t\t\t\tsizeof(*ww_acquire_ctxs),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!ww_acquire_ctxs)\n\t\tVERBOSE_TOROUT_STRING(\"ww_acquire_ctx: Out of memory\");\n}\n\nstatic void torture_ww_mutex_exit(void)\n{\n\tkfree(ww_acquire_ctxs);\n}\n\nstatic int torture_ww_mutex_lock(int tid)\n__acquires(torture_ww_mutex_0)\n__acquires(torture_ww_mutex_1)\n__acquires(torture_ww_mutex_2)\n{\n\tLIST_HEAD(list);\n\tstruct reorder_lock {\n\t\tstruct list_head link;\n\t\tstruct ww_mutex *lock;\n\t} locks[3], *ll, *ln;\n\tstruct ww_acquire_ctx *ctx = &ww_acquire_ctxs[tid];\n\n\tlocks[0].lock = &torture_ww_mutex_0;\n\tlist_add(&locks[0].link, &list);\n\n\tlocks[1].lock = &torture_ww_mutex_1;\n\tlist_add(&locks[1].link, &list);\n\n\tlocks[2].lock = &torture_ww_mutex_2;\n\tlist_add(&locks[2].link, &list);\n\n\tww_acquire_init(ctx, &torture_ww_class);\n\n\tlist_for_each_entry(ll, &list, link) {\n\t\tint err;\n\n\t\terr = ww_mutex_lock(ll->lock, ctx);\n\t\tif (!err)\n\t\t\tcontinue;\n\n\t\tln = ll;\n\t\tlist_for_each_entry_continue_reverse(ln, &list, link)\n\t\t\tww_mutex_unlock(ln->lock);\n\n\t\tif (err != -EDEADLK)\n\t\t\treturn err;\n\n\t\tww_mutex_lock_slow(ll->lock, ctx);\n\t\tlist_move(&ll->link, &list);\n\t}\n\n\treturn 0;\n}\n\nstatic void torture_ww_mutex_unlock(int tid)\n__releases(torture_ww_mutex_0)\n__releases(torture_ww_mutex_1)\n__releases(torture_ww_mutex_2)\n{\n\tstruct ww_acquire_ctx *ctx = &ww_acquire_ctxs[tid];\n\n\tww_mutex_unlock(&torture_ww_mutex_0);\n\tww_mutex_unlock(&torture_ww_mutex_1);\n\tww_mutex_unlock(&torture_ww_mutex_2);\n\tww_acquire_fini(ctx);\n}\n\nstatic struct lock_torture_ops ww_mutex_lock_ops = {\n\t.init\t\t= torture_ww_mutex_init,\n\t.exit\t\t= torture_ww_mutex_exit,\n\t.writelock\t= torture_ww_mutex_lock,\n\t.write_delay\t= torture_mutex_delay,\n\t.task_boost     = torture_rt_boost,\n\t.writeunlock\t= torture_ww_mutex_unlock,\n\t.readlock       = NULL,\n\t.read_delay     = NULL,\n\t.readunlock     = NULL,\n\t.name\t\t= \"ww_mutex_lock\"\n};\n\n#ifdef CONFIG_RT_MUTEXES\nstatic DEFINE_RT_MUTEX(torture_rtmutex);\nstatic struct rt_mutex torture_nested_rtmutexes[MAX_NESTED_LOCKS];\nstatic struct lock_class_key nested_rtmutex_keys[MAX_NESTED_LOCKS];\n\nstatic void torture_rtmutex_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < MAX_NESTED_LOCKS; i++)\n\t\t__rt_mutex_init(&torture_nested_rtmutexes[i], __func__,\n\t\t\t\t&nested_rtmutex_keys[i]);\n}\n\nstatic int torture_rtmutex_nested_lock(int tid __maybe_unused,\n\t\t\t\t       u32 lockset)\n{\n\tint i;\n\n\tfor (i = 0; i < nested_locks; i++)\n\t\tif (lockset & (1 << i))\n\t\t\trt_mutex_lock(&torture_nested_rtmutexes[i]);\n\treturn 0;\n}\n\nstatic int torture_rtmutex_lock(int tid __maybe_unused)\n__acquires(torture_rtmutex)\n{\n\trt_mutex_lock(&torture_rtmutex);\n\treturn 0;\n}\n\nstatic void torture_rtmutex_delay(struct torture_random_state *trsp)\n{\n\tconst unsigned long shortdelay_us = 2;\n\tconst unsigned long longdelay_ms = long_hold ? long_hold : ULONG_MAX;\n\n\t \n\tif (!(torture_random(trsp) %\n\t      (cxt.nrealwriters_stress * 2000 * longdelay_ms)))\n\t\tmdelay(longdelay_ms);\n\tif (!(torture_random(trsp) %\n\t      (cxt.nrealwriters_stress * 200 * shortdelay_us)))\n\t\tudelay(shortdelay_us);\n\tif (!(torture_random(trsp) % (cxt.nrealwriters_stress * 20000)))\n\t\ttorture_preempt_schedule();   \n}\n\nstatic void torture_rtmutex_unlock(int tid __maybe_unused)\n__releases(torture_rtmutex)\n{\n\trt_mutex_unlock(&torture_rtmutex);\n}\n\nstatic void torture_rt_boost_rtmutex(struct torture_random_state *trsp)\n{\n\tif (!rt_boost)\n\t\treturn;\n\n\t__torture_rt_boost(trsp);\n}\n\nstatic void torture_rtmutex_nested_unlock(int tid __maybe_unused,\n\t\t\t\t\t  u32 lockset)\n{\n\tint i;\n\n\tfor (i = nested_locks - 1; i >= 0; i--)\n\t\tif (lockset & (1 << i))\n\t\t\trt_mutex_unlock(&torture_nested_rtmutexes[i]);\n}\n\nstatic struct lock_torture_ops rtmutex_lock_ops = {\n\t.init\t\t= torture_rtmutex_init,\n\t.nested_lock\t= torture_rtmutex_nested_lock,\n\t.writelock\t= torture_rtmutex_lock,\n\t.write_delay\t= torture_rtmutex_delay,\n\t.task_boost     = torture_rt_boost_rtmutex,\n\t.writeunlock\t= torture_rtmutex_unlock,\n\t.nested_unlock\t= torture_rtmutex_nested_unlock,\n\t.readlock       = NULL,\n\t.read_delay     = NULL,\n\t.readunlock     = NULL,\n\t.name\t\t= \"rtmutex_lock\"\n};\n#endif\n\nstatic DECLARE_RWSEM(torture_rwsem);\nstatic int torture_rwsem_down_write(int tid __maybe_unused)\n__acquires(torture_rwsem)\n{\n\tdown_write(&torture_rwsem);\n\treturn 0;\n}\n\nstatic void torture_rwsem_write_delay(struct torture_random_state *trsp)\n{\n\tconst unsigned long longdelay_ms = long_hold ? long_hold : ULONG_MAX;\n\n\t \n\tif (!(torture_random(trsp) %\n\t      (cxt.nrealwriters_stress * 2000 * longdelay_ms)))\n\t\tmdelay(longdelay_ms * 10);\n\tif (!(torture_random(trsp) % (cxt.nrealwriters_stress * 20000)))\n\t\ttorture_preempt_schedule();   \n}\n\nstatic void torture_rwsem_up_write(int tid __maybe_unused)\n__releases(torture_rwsem)\n{\n\tup_write(&torture_rwsem);\n}\n\nstatic int torture_rwsem_down_read(int tid __maybe_unused)\n__acquires(torture_rwsem)\n{\n\tdown_read(&torture_rwsem);\n\treturn 0;\n}\n\nstatic void torture_rwsem_read_delay(struct torture_random_state *trsp)\n{\n\tconst unsigned long longdelay_ms = 100;\n\n\t \n\tif (!(torture_random(trsp) %\n\t      (cxt.nrealreaders_stress * 2000 * longdelay_ms)))\n\t\tmdelay(longdelay_ms * 2);\n\telse\n\t\tmdelay(longdelay_ms / 2);\n\tif (!(torture_random(trsp) % (cxt.nrealreaders_stress * 20000)))\n\t\ttorture_preempt_schedule();   \n}\n\nstatic void torture_rwsem_up_read(int tid __maybe_unused)\n__releases(torture_rwsem)\n{\n\tup_read(&torture_rwsem);\n}\n\nstatic struct lock_torture_ops rwsem_lock_ops = {\n\t.writelock\t= torture_rwsem_down_write,\n\t.write_delay\t= torture_rwsem_write_delay,\n\t.task_boost     = torture_rt_boost,\n\t.writeunlock\t= torture_rwsem_up_write,\n\t.readlock       = torture_rwsem_down_read,\n\t.read_delay     = torture_rwsem_read_delay,\n\t.readunlock     = torture_rwsem_up_read,\n\t.name\t\t= \"rwsem_lock\"\n};\n\n#include <linux/percpu-rwsem.h>\nstatic struct percpu_rw_semaphore pcpu_rwsem;\n\nstatic void torture_percpu_rwsem_init(void)\n{\n\tBUG_ON(percpu_init_rwsem(&pcpu_rwsem));\n}\n\nstatic void torture_percpu_rwsem_exit(void)\n{\n\tpercpu_free_rwsem(&pcpu_rwsem);\n}\n\nstatic int torture_percpu_rwsem_down_write(int tid __maybe_unused)\n__acquires(pcpu_rwsem)\n{\n\tpercpu_down_write(&pcpu_rwsem);\n\treturn 0;\n}\n\nstatic void torture_percpu_rwsem_up_write(int tid __maybe_unused)\n__releases(pcpu_rwsem)\n{\n\tpercpu_up_write(&pcpu_rwsem);\n}\n\nstatic int torture_percpu_rwsem_down_read(int tid __maybe_unused)\n__acquires(pcpu_rwsem)\n{\n\tpercpu_down_read(&pcpu_rwsem);\n\treturn 0;\n}\n\nstatic void torture_percpu_rwsem_up_read(int tid __maybe_unused)\n__releases(pcpu_rwsem)\n{\n\tpercpu_up_read(&pcpu_rwsem);\n}\n\nstatic struct lock_torture_ops percpu_rwsem_lock_ops = {\n\t.init\t\t= torture_percpu_rwsem_init,\n\t.exit\t\t= torture_percpu_rwsem_exit,\n\t.writelock\t= torture_percpu_rwsem_down_write,\n\t.write_delay\t= torture_rwsem_write_delay,\n\t.task_boost     = torture_rt_boost,\n\t.writeunlock\t= torture_percpu_rwsem_up_write,\n\t.readlock       = torture_percpu_rwsem_down_read,\n\t.read_delay     = torture_rwsem_read_delay,\n\t.readunlock     = torture_percpu_rwsem_up_read,\n\t.name\t\t= \"percpu_rwsem_lock\"\n};\n\n \nstatic int lock_torture_writer(void *arg)\n{\n\tstruct lock_stress_stats *lwsp = arg;\n\tint tid = lwsp - cxt.lwsa;\n\tDEFINE_TORTURE_RANDOM(rand);\n\tu32 lockset_mask;\n\tbool skip_main_lock;\n\n\tVERBOSE_TOROUT_STRING(\"lock_torture_writer task started\");\n\tif (!rt_task(current))\n\t\tset_user_nice(current, MAX_NICE);\n\n\tdo {\n\t\tif ((torture_random(&rand) & 0xfffff) == 0)\n\t\t\tschedule_timeout_uninterruptible(1);\n\n\t\tlockset_mask = torture_random(&rand);\n\t\t \n\t\tskip_main_lock = (nested_locks &&\n\t\t\t\t !(torture_random(&rand) % 100));\n\n\t\tcxt.cur_ops->task_boost(&rand);\n\t\tif (cxt.cur_ops->nested_lock)\n\t\t\tcxt.cur_ops->nested_lock(tid, lockset_mask);\n\n\t\tif (!skip_main_lock) {\n\t\t\tcxt.cur_ops->writelock(tid);\n\t\t\tif (WARN_ON_ONCE(lock_is_write_held))\n\t\t\t\tlwsp->n_lock_fail++;\n\t\t\tlock_is_write_held = true;\n\t\t\tif (WARN_ON_ONCE(atomic_read(&lock_is_read_held)))\n\t\t\t\tlwsp->n_lock_fail++;  \n\n\t\t\tlwsp->n_lock_acquired++;\n\t\t}\n\t\tif (!skip_main_lock) {\n\t\t\tcxt.cur_ops->write_delay(&rand);\n\t\t\tlock_is_write_held = false;\n\t\t\tWRITE_ONCE(last_lock_release, jiffies);\n\t\t\tcxt.cur_ops->writeunlock(tid);\n\t\t}\n\t\tif (cxt.cur_ops->nested_unlock)\n\t\t\tcxt.cur_ops->nested_unlock(tid, lockset_mask);\n\n\t\tstutter_wait(\"lock_torture_writer\");\n\t} while (!torture_must_stop());\n\n\tcxt.cur_ops->task_boost(NULL);  \n\ttorture_kthread_stopping(\"lock_torture_writer\");\n\treturn 0;\n}\n\n \nstatic int lock_torture_reader(void *arg)\n{\n\tstruct lock_stress_stats *lrsp = arg;\n\tint tid = lrsp - cxt.lrsa;\n\tDEFINE_TORTURE_RANDOM(rand);\n\n\tVERBOSE_TOROUT_STRING(\"lock_torture_reader task started\");\n\tset_user_nice(current, MAX_NICE);\n\n\tdo {\n\t\tif ((torture_random(&rand) & 0xfffff) == 0)\n\t\t\tschedule_timeout_uninterruptible(1);\n\n\t\tcxt.cur_ops->readlock(tid);\n\t\tatomic_inc(&lock_is_read_held);\n\t\tif (WARN_ON_ONCE(lock_is_write_held))\n\t\t\tlrsp->n_lock_fail++;  \n\n\t\tlrsp->n_lock_acquired++;\n\t\tcxt.cur_ops->read_delay(&rand);\n\t\tatomic_dec(&lock_is_read_held);\n\t\tcxt.cur_ops->readunlock(tid);\n\n\t\tstutter_wait(\"lock_torture_reader\");\n\t} while (!torture_must_stop());\n\ttorture_kthread_stopping(\"lock_torture_reader\");\n\treturn 0;\n}\n\n \nstatic void __torture_print_stats(char *page,\n\t\t\t\t  struct lock_stress_stats *statp, bool write)\n{\n\tlong cur;\n\tbool fail = false;\n\tint i, n_stress;\n\tlong max = 0, min = statp ? data_race(statp[0].n_lock_acquired) : 0;\n\tlong long sum = 0;\n\n\tn_stress = write ? cxt.nrealwriters_stress : cxt.nrealreaders_stress;\n\tfor (i = 0; i < n_stress; i++) {\n\t\tif (data_race(statp[i].n_lock_fail))\n\t\t\tfail = true;\n\t\tcur = data_race(statp[i].n_lock_acquired);\n\t\tsum += cur;\n\t\tif (max < cur)\n\t\t\tmax = cur;\n\t\tif (min > cur)\n\t\t\tmin = cur;\n\t}\n\tpage += sprintf(page,\n\t\t\t\"%s:  Total: %lld  Max/Min: %ld/%ld %s  Fail: %d %s\\n\",\n\t\t\twrite ? \"Writes\" : \"Reads \",\n\t\t\tsum, max, min,\n\t\t\t!onoff_interval && max / 2 > min ? \"???\" : \"\",\n\t\t\tfail, fail ? \"!!!\" : \"\");\n\tif (fail)\n\t\tatomic_inc(&cxt.n_lock_torture_errors);\n}\n\n \nstatic void lock_torture_stats_print(void)\n{\n\tint size = cxt.nrealwriters_stress * 200 + 8192;\n\tchar *buf;\n\n\tif (cxt.cur_ops->readlock)\n\t\tsize += cxt.nrealreaders_stress * 200 + 8192;\n\n\tbuf = kmalloc(size, GFP_KERNEL);\n\tif (!buf) {\n\t\tpr_err(\"lock_torture_stats_print: Out of memory, need: %d\",\n\t\t       size);\n\t\treturn;\n\t}\n\n\t__torture_print_stats(buf, cxt.lwsa, true);\n\tpr_alert(\"%s\", buf);\n\tkfree(buf);\n\n\tif (cxt.cur_ops->readlock) {\n\t\tbuf = kmalloc(size, GFP_KERNEL);\n\t\tif (!buf) {\n\t\t\tpr_err(\"lock_torture_stats_print: Out of memory, need: %d\",\n\t\t\t       size);\n\t\t\treturn;\n\t\t}\n\n\t\t__torture_print_stats(buf, cxt.lrsa, false);\n\t\tpr_alert(\"%s\", buf);\n\t\tkfree(buf);\n\t}\n}\n\n \nstatic int lock_torture_stats(void *arg)\n{\n\tVERBOSE_TOROUT_STRING(\"lock_torture_stats task started\");\n\tdo {\n\t\tschedule_timeout_interruptible(stat_interval * HZ);\n\t\tlock_torture_stats_print();\n\t\ttorture_shutdown_absorb(\"lock_torture_stats\");\n\t} while (!torture_must_stop());\n\ttorture_kthread_stopping(\"lock_torture_stats\");\n\treturn 0;\n}\n\nstatic inline void\nlock_torture_print_module_parms(struct lock_torture_ops *cur_ops,\n\t\t\t\tconst char *tag)\n{\n\tpr_alert(\"%s\" TORTURE_FLAG\n\t\t \"--- %s%s: nwriters_stress=%d nreaders_stress=%d nested_locks=%d stat_interval=%d verbose=%d shuffle_interval=%d stutter=%d shutdown_secs=%d onoff_interval=%d onoff_holdoff=%d\\n\",\n\t\t torture_type, tag, cxt.debug_lock ? \" [debug]\": \"\",\n\t\t cxt.nrealwriters_stress, cxt.nrealreaders_stress,\n\t\t nested_locks, stat_interval, verbose, shuffle_interval,\n\t\t stutter, shutdown_secs, onoff_interval, onoff_holdoff);\n}\n\nstatic void lock_torture_cleanup(void)\n{\n\tint i;\n\n\tif (torture_cleanup_begin())\n\t\treturn;\n\n\t \n\tif (!cxt.lwsa && !cxt.lrsa)\n\t\tgoto end;\n\n\tif (writer_tasks) {\n\t\tfor (i = 0; i < cxt.nrealwriters_stress; i++)\n\t\t\ttorture_stop_kthread(lock_torture_writer, writer_tasks[i]);\n\t\tkfree(writer_tasks);\n\t\twriter_tasks = NULL;\n\t}\n\n\tif (reader_tasks) {\n\t\tfor (i = 0; i < cxt.nrealreaders_stress; i++)\n\t\t\ttorture_stop_kthread(lock_torture_reader,\n\t\t\t\t\t     reader_tasks[i]);\n\t\tkfree(reader_tasks);\n\t\treader_tasks = NULL;\n\t}\n\n\ttorture_stop_kthread(lock_torture_stats, stats_task);\n\tlock_torture_stats_print();   \n\n\tif (atomic_read(&cxt.n_lock_torture_errors))\n\t\tlock_torture_print_module_parms(cxt.cur_ops,\n\t\t\t\t\t\t\"End of test: FAILURE\");\n\telse if (torture_onoff_failures())\n\t\tlock_torture_print_module_parms(cxt.cur_ops,\n\t\t\t\t\t\t\"End of test: LOCK_HOTPLUG\");\n\telse\n\t\tlock_torture_print_module_parms(cxt.cur_ops,\n\t\t\t\t\t\t\"End of test: SUCCESS\");\n\n\tkfree(cxt.lwsa);\n\tcxt.lwsa = NULL;\n\tkfree(cxt.lrsa);\n\tcxt.lrsa = NULL;\n\nend:\n\tif (cxt.init_called) {\n\t\tif (cxt.cur_ops->exit)\n\t\t\tcxt.cur_ops->exit();\n\t\tcxt.init_called = false;\n\t}\n\ttorture_cleanup_end();\n}\n\nstatic int __init lock_torture_init(void)\n{\n\tint i, j;\n\tint firsterr = 0;\n\tstatic struct lock_torture_ops *torture_ops[] = {\n\t\t&lock_busted_ops,\n\t\t&spin_lock_ops, &spin_lock_irq_ops,\n\t\t&raw_spin_lock_ops, &raw_spin_lock_irq_ops,\n\t\t&rw_lock_ops, &rw_lock_irq_ops,\n\t\t&mutex_lock_ops,\n\t\t&ww_mutex_lock_ops,\n#ifdef CONFIG_RT_MUTEXES\n\t\t&rtmutex_lock_ops,\n#endif\n\t\t&rwsem_lock_ops,\n\t\t&percpu_rwsem_lock_ops,\n\t};\n\n\tif (!torture_init_begin(torture_type, verbose))\n\t\treturn -EBUSY;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(torture_ops); i++) {\n\t\tcxt.cur_ops = torture_ops[i];\n\t\tif (strcmp(torture_type, cxt.cur_ops->name) == 0)\n\t\t\tbreak;\n\t}\n\tif (i == ARRAY_SIZE(torture_ops)) {\n\t\tpr_alert(\"lock-torture: invalid torture type: \\\"%s\\\"\\n\",\n\t\t\t torture_type);\n\t\tpr_alert(\"lock-torture types:\");\n\t\tfor (i = 0; i < ARRAY_SIZE(torture_ops); i++)\n\t\t\tpr_alert(\" %s\", torture_ops[i]->name);\n\t\tpr_alert(\"\\n\");\n\t\tfirsterr = -EINVAL;\n\t\tgoto unwind;\n\t}\n\n\tif (nwriters_stress == 0 &&\n\t    (!cxt.cur_ops->readlock || nreaders_stress == 0)) {\n\t\tpr_alert(\"lock-torture: must run at least one locking thread\\n\");\n\t\tfirsterr = -EINVAL;\n\t\tgoto unwind;\n\t}\n\n\tif (nwriters_stress >= 0)\n\t\tcxt.nrealwriters_stress = nwriters_stress;\n\telse\n\t\tcxt.nrealwriters_stress = 2 * num_online_cpus();\n\n\tif (cxt.cur_ops->init) {\n\t\tcxt.cur_ops->init();\n\t\tcxt.init_called = true;\n\t}\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\tif (str_has_prefix(torture_type, \"mutex\"))\n\t\tcxt.debug_lock = true;\n#endif\n#ifdef CONFIG_DEBUG_RT_MUTEXES\n\tif (str_has_prefix(torture_type, \"rtmutex\"))\n\t\tcxt.debug_lock = true;\n#endif\n#ifdef CONFIG_DEBUG_SPINLOCK\n\tif ((str_has_prefix(torture_type, \"spin\")) ||\n\t    (str_has_prefix(torture_type, \"rw_lock\")))\n\t\tcxt.debug_lock = true;\n#endif\n\n\t \n\tif (nwriters_stress) {\n\t\tlock_is_write_held = false;\n\t\tcxt.lwsa = kmalloc_array(cxt.nrealwriters_stress,\n\t\t\t\t\t sizeof(*cxt.lwsa),\n\t\t\t\t\t GFP_KERNEL);\n\t\tif (cxt.lwsa == NULL) {\n\t\t\tVERBOSE_TOROUT_STRING(\"cxt.lwsa: Out of memory\");\n\t\t\tfirsterr = -ENOMEM;\n\t\t\tgoto unwind;\n\t\t}\n\n\t\tfor (i = 0; i < cxt.nrealwriters_stress; i++) {\n\t\t\tcxt.lwsa[i].n_lock_fail = 0;\n\t\t\tcxt.lwsa[i].n_lock_acquired = 0;\n\t\t}\n\t}\n\n\tif (cxt.cur_ops->readlock) {\n\t\tif (nreaders_stress >= 0)\n\t\t\tcxt.nrealreaders_stress = nreaders_stress;\n\t\telse {\n\t\t\t \n\t\t\tif (nwriters_stress < 0)  \n\t\t\t\tcxt.nrealwriters_stress = num_online_cpus();\n\t\t\tcxt.nrealreaders_stress = cxt.nrealwriters_stress;\n\t\t}\n\n\t\tif (nreaders_stress) {\n\t\t\tcxt.lrsa = kmalloc_array(cxt.nrealreaders_stress,\n\t\t\t\t\t\t sizeof(*cxt.lrsa),\n\t\t\t\t\t\t GFP_KERNEL);\n\t\t\tif (cxt.lrsa == NULL) {\n\t\t\t\tVERBOSE_TOROUT_STRING(\"cxt.lrsa: Out of memory\");\n\t\t\t\tfirsterr = -ENOMEM;\n\t\t\t\tkfree(cxt.lwsa);\n\t\t\t\tcxt.lwsa = NULL;\n\t\t\t\tgoto unwind;\n\t\t\t}\n\n\t\t\tfor (i = 0; i < cxt.nrealreaders_stress; i++) {\n\t\t\t\tcxt.lrsa[i].n_lock_fail = 0;\n\t\t\t\tcxt.lrsa[i].n_lock_acquired = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tlock_torture_print_module_parms(cxt.cur_ops, \"Start of test\");\n\n\t \n\tif (onoff_interval > 0) {\n\t\tfirsterr = torture_onoff_init(onoff_holdoff * HZ,\n\t\t\t\t\t      onoff_interval * HZ, NULL);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tif (shuffle_interval > 0) {\n\t\tfirsterr = torture_shuffle_init(shuffle_interval);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tif (shutdown_secs > 0) {\n\t\tfirsterr = torture_shutdown_init(shutdown_secs,\n\t\t\t\t\t\t lock_torture_cleanup);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tif (stutter > 0) {\n\t\tfirsterr = torture_stutter_init(stutter, stutter);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\n\tif (nwriters_stress) {\n\t\twriter_tasks = kcalloc(cxt.nrealwriters_stress,\n\t\t\t\t       sizeof(writer_tasks[0]),\n\t\t\t\t       GFP_KERNEL);\n\t\tif (writer_tasks == NULL) {\n\t\t\tTOROUT_ERRSTRING(\"writer_tasks: Out of memory\");\n\t\t\tfirsterr = -ENOMEM;\n\t\t\tgoto unwind;\n\t\t}\n\t}\n\n\t \n\tif (nested_locks > MAX_NESTED_LOCKS)\n\t\tnested_locks = MAX_NESTED_LOCKS;\n\n\tif (cxt.cur_ops->readlock) {\n\t\treader_tasks = kcalloc(cxt.nrealreaders_stress,\n\t\t\t\t       sizeof(reader_tasks[0]),\n\t\t\t\t       GFP_KERNEL);\n\t\tif (reader_tasks == NULL) {\n\t\t\tTOROUT_ERRSTRING(\"reader_tasks: Out of memory\");\n\t\t\tkfree(writer_tasks);\n\t\t\twriter_tasks = NULL;\n\t\t\tfirsterr = -ENOMEM;\n\t\t\tgoto unwind;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0, j = 0; i < cxt.nrealwriters_stress ||\n\t\t    j < cxt.nrealreaders_stress; i++, j++) {\n\t\tif (i >= cxt.nrealwriters_stress)\n\t\t\tgoto create_reader;\n\n\t\t \n\t\tfirsterr = torture_create_kthread_cb(lock_torture_writer, &cxt.lwsa[i],\n\t\t\t\t\t\t     writer_tasks[i],\n\t\t\t\t\t\t     writer_fifo ? sched_set_fifo : NULL);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\n\tcreate_reader:\n\t\tif (cxt.cur_ops->readlock == NULL || (j >= cxt.nrealreaders_stress))\n\t\t\tcontinue;\n\t\t \n\t\tfirsterr = torture_create_kthread(lock_torture_reader, &cxt.lrsa[j],\n\t\t\t\t\t\t  reader_tasks[j]);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\tif (stat_interval > 0) {\n\t\tfirsterr = torture_create_kthread(lock_torture_stats, NULL,\n\t\t\t\t\t\t  stats_task);\n\t\tif (torture_init_error(firsterr))\n\t\t\tgoto unwind;\n\t}\n\ttorture_init_end();\n\treturn 0;\n\nunwind:\n\ttorture_init_end();\n\tlock_torture_cleanup();\n\tif (shutdown_secs) {\n\t\tWARN_ON(!IS_MODULE(CONFIG_LOCK_TORTURE_TEST));\n\t\tkernel_power_off();\n\t}\n\treturn firsterr;\n}\n\nmodule_init(lock_torture_init);\nmodule_exit(lock_torture_cleanup);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}