{
  "module_name": "stacktrace.c",
  "hash_id": "4be05e46a181cbe938a91953c83df69a5036c12e319b85a2e37539cbb15873a9",
  "original_prompt": "Ingested from linux-6.6.14/kernel/stacktrace.c",
  "human_readable_source": "\n \n#include <linux/sched/task_stack.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n#include <linux/kallsyms.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n\n \nvoid stack_trace_print(const unsigned long *entries, unsigned int nr_entries,\n\t\t       int spaces)\n{\n\tunsigned int i;\n\n\tif (WARN_ON(!entries))\n\t\treturn;\n\n\tfor (i = 0; i < nr_entries; i++)\n\t\tprintk(\"%*c%pS\\n\", 1 + spaces, ' ', (void *)entries[i]);\n}\nEXPORT_SYMBOL_GPL(stack_trace_print);\n\n \nint stack_trace_snprint(char *buf, size_t size, const unsigned long *entries,\n\t\t\tunsigned int nr_entries, int spaces)\n{\n\tunsigned int generated, i, total = 0;\n\n\tif (WARN_ON(!entries))\n\t\treturn 0;\n\n\tfor (i = 0; i < nr_entries && size; i++) {\n\t\tgenerated = snprintf(buf, size, \"%*c%pS\\n\", 1 + spaces, ' ',\n\t\t\t\t     (void *)entries[i]);\n\n\t\ttotal += generated;\n\t\tif (generated >= size) {\n\t\t\tbuf += size;\n\t\t\tsize = 0;\n\t\t} else {\n\t\t\tbuf += generated;\n\t\t\tsize -= generated;\n\t\t}\n\t}\n\n\treturn total;\n}\nEXPORT_SYMBOL_GPL(stack_trace_snprint);\n\n#ifdef CONFIG_ARCH_STACKWALK\n\nstruct stacktrace_cookie {\n\tunsigned long\t*store;\n\tunsigned int\tsize;\n\tunsigned int\tskip;\n\tunsigned int\tlen;\n};\n\nstatic bool stack_trace_consume_entry(void *cookie, unsigned long addr)\n{\n\tstruct stacktrace_cookie *c = cookie;\n\n\tif (c->len >= c->size)\n\t\treturn false;\n\n\tif (c->skip > 0) {\n\t\tc->skip--;\n\t\treturn true;\n\t}\n\tc->store[c->len++] = addr;\n\treturn c->len < c->size;\n}\n\nstatic bool stack_trace_consume_entry_nosched(void *cookie, unsigned long addr)\n{\n\tif (in_sched_functions(addr))\n\t\treturn true;\n\treturn stack_trace_consume_entry(cookie, addr);\n}\n\n \nunsigned int stack_trace_save(unsigned long *store, unsigned int size,\n\t\t\t      unsigned int skipnr)\n{\n\tstack_trace_consume_fn consume_entry = stack_trace_consume_entry;\n\tstruct stacktrace_cookie c = {\n\t\t.store\t= store,\n\t\t.size\t= size,\n\t\t.skip\t= skipnr + 1,\n\t};\n\n\tarch_stack_walk(consume_entry, &c, current, NULL);\n\treturn c.len;\n}\nEXPORT_SYMBOL_GPL(stack_trace_save);\n\n \nunsigned int stack_trace_save_tsk(struct task_struct *tsk, unsigned long *store,\n\t\t\t\t  unsigned int size, unsigned int skipnr)\n{\n\tstack_trace_consume_fn consume_entry = stack_trace_consume_entry_nosched;\n\tstruct stacktrace_cookie c = {\n\t\t.store\t= store,\n\t\t.size\t= size,\n\t\t \n\t\t.skip\t= skipnr + (current == tsk),\n\t};\n\n\tif (!try_get_task_stack(tsk))\n\t\treturn 0;\n\n\tarch_stack_walk(consume_entry, &c, tsk, NULL);\n\tput_task_stack(tsk);\n\treturn c.len;\n}\n\n \nunsigned int stack_trace_save_regs(struct pt_regs *regs, unsigned long *store,\n\t\t\t\t   unsigned int size, unsigned int skipnr)\n{\n\tstack_trace_consume_fn consume_entry = stack_trace_consume_entry;\n\tstruct stacktrace_cookie c = {\n\t\t.store\t= store,\n\t\t.size\t= size,\n\t\t.skip\t= skipnr,\n\t};\n\n\tarch_stack_walk(consume_entry, &c, current, regs);\n\treturn c.len;\n}\n\n#ifdef CONFIG_HAVE_RELIABLE_STACKTRACE\n \nint stack_trace_save_tsk_reliable(struct task_struct *tsk, unsigned long *store,\n\t\t\t\t  unsigned int size)\n{\n\tstack_trace_consume_fn consume_entry = stack_trace_consume_entry;\n\tstruct stacktrace_cookie c = {\n\t\t.store\t= store,\n\t\t.size\t= size,\n\t};\n\tint ret;\n\n\t \n\tif (!try_get_task_stack(tsk))\n\t\treturn 0;\n\n\tret = arch_stack_walk_reliable(consume_entry, &c, tsk);\n\tput_task_stack(tsk);\n\treturn ret ? ret : c.len;\n}\n#endif\n\n#ifdef CONFIG_USER_STACKTRACE_SUPPORT\n \nunsigned int stack_trace_save_user(unsigned long *store, unsigned int size)\n{\n\tstack_trace_consume_fn consume_entry = stack_trace_consume_entry;\n\tstruct stacktrace_cookie c = {\n\t\t.store\t= store,\n\t\t.size\t= size,\n\t};\n\n\t \n\tif (current->flags & PF_KTHREAD)\n\t\treturn 0;\n\n\tarch_stack_walk_user(consume_entry, &c, task_pt_regs(current));\n\n\treturn c.len;\n}\n#endif\n\n#else  \n\n \n__weak void\nsave_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)\n{\n\tWARN_ONCE(1, KERN_INFO \"save_stack_trace_tsk() not implemented yet.\\n\");\n}\n\n__weak void\nsave_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)\n{\n\tWARN_ONCE(1, KERN_INFO \"save_stack_trace_regs() not implemented yet.\\n\");\n}\n\n \nunsigned int stack_trace_save(unsigned long *store, unsigned int size,\n\t\t\t      unsigned int skipnr)\n{\n\tstruct stack_trace trace = {\n\t\t.entries\t= store,\n\t\t.max_entries\t= size,\n\t\t.skip\t\t= skipnr + 1,\n\t};\n\n\tsave_stack_trace(&trace);\n\treturn trace.nr_entries;\n}\nEXPORT_SYMBOL_GPL(stack_trace_save);\n\n \nunsigned int stack_trace_save_tsk(struct task_struct *task,\n\t\t\t\t  unsigned long *store, unsigned int size,\n\t\t\t\t  unsigned int skipnr)\n{\n\tstruct stack_trace trace = {\n\t\t.entries\t= store,\n\t\t.max_entries\t= size,\n\t\t \n\t\t.skip\t= skipnr + (current == task),\n\t};\n\n\tsave_stack_trace_tsk(task, &trace);\n\treturn trace.nr_entries;\n}\n\n \nunsigned int stack_trace_save_regs(struct pt_regs *regs, unsigned long *store,\n\t\t\t\t   unsigned int size, unsigned int skipnr)\n{\n\tstruct stack_trace trace = {\n\t\t.entries\t= store,\n\t\t.max_entries\t= size,\n\t\t.skip\t\t= skipnr,\n\t};\n\n\tsave_stack_trace_regs(regs, &trace);\n\treturn trace.nr_entries;\n}\n\n#ifdef CONFIG_HAVE_RELIABLE_STACKTRACE\n \nint stack_trace_save_tsk_reliable(struct task_struct *tsk, unsigned long *store,\n\t\t\t\t  unsigned int size)\n{\n\tstruct stack_trace trace = {\n\t\t.entries\t= store,\n\t\t.max_entries\t= size,\n\t};\n\tint ret = save_stack_trace_tsk_reliable(tsk, &trace);\n\n\treturn ret ? ret : trace.nr_entries;\n}\n#endif\n\n#ifdef CONFIG_USER_STACKTRACE_SUPPORT\n \nunsigned int stack_trace_save_user(unsigned long *store, unsigned int size)\n{\n\tstruct stack_trace trace = {\n\t\t.entries\t= store,\n\t\t.max_entries\t= size,\n\t};\n\n\tsave_stack_trace_user(&trace);\n\treturn trace.nr_entries;\n}\n#endif  \n\n#endif  \n\nstatic inline bool in_irqentry_text(unsigned long ptr)\n{\n\treturn (ptr >= (unsigned long)&__irqentry_text_start &&\n\t\tptr < (unsigned long)&__irqentry_text_end) ||\n\t\t(ptr >= (unsigned long)&__softirqentry_text_start &&\n\t\t ptr < (unsigned long)&__softirqentry_text_end);\n}\n\n \nunsigned int filter_irq_stacks(unsigned long *entries, unsigned int nr_entries)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < nr_entries; i++) {\n\t\tif (in_irqentry_text(entries[i])) {\n\t\t\t \n\t\t\treturn i + 1;\n\t\t}\n\t}\n\treturn nr_entries;\n}\nEXPORT_SYMBOL_GPL(filter_irq_stacks);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}