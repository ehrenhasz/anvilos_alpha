{
  "module_name": "bugs.c",
  "hash_id": "843dd416d5dbdb8bdcf2c38963ec33b0e22efb59ca4dfc7152e44bb995ff0852",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/lkdtm/bugs.c",
  "human_readable_source": "\n \n#include \"lkdtm.h\"\n#include <linux/list.h>\n#include <linux/sched.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/task_stack.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n\n#if IS_ENABLED(CONFIG_X86_32) && !IS_ENABLED(CONFIG_UML)\n#include <asm/desc.h>\n#endif\n\nstruct lkdtm_list {\n\tstruct list_head node;\n};\n\n \n#if defined(CONFIG_FRAME_WARN) && (CONFIG_FRAME_WARN > 0)\n#define REC_STACK_SIZE (_AC(CONFIG_FRAME_WARN, UL) / 2)\n#else\n#define REC_STACK_SIZE (THREAD_SIZE / 8UL)\n#endif\n#define REC_NUM_DEFAULT ((THREAD_SIZE / REC_STACK_SIZE) * 2)\n\nstatic int recur_count = REC_NUM_DEFAULT;\n\nstatic DEFINE_SPINLOCK(lock_me_up);\n\n \nstatic int noinline recursive_loop(int remaining)\n{\n\tvolatile char buf[REC_STACK_SIZE];\n\tvolatile int ret;\n\n\tmemset((void *)buf, remaining & 0xFF, sizeof(buf));\n\tif (!remaining)\n\t\tret = 0;\n\telse\n\t\tret = recursive_loop((int)buf[remaining % sizeof(buf)] - 1);\n\tmemzero_explicit((void *)buf, sizeof(buf));\n\treturn ret;\n}\n\n \nvoid __init lkdtm_bugs_init(int *recur_param)\n{\n\tif (*recur_param < 0)\n\t\t*recur_param = recur_count;\n\telse\n\t\trecur_count = *recur_param;\n}\n\nstatic void lkdtm_PANIC(void)\n{\n\tpanic(\"dumptest\");\n}\n\nstatic void lkdtm_BUG(void)\n{\n\tBUG();\n}\n\nstatic int warn_counter;\n\nstatic void lkdtm_WARNING(void)\n{\n\tWARN_ON(++warn_counter);\n}\n\nstatic void lkdtm_WARNING_MESSAGE(void)\n{\n\tWARN(1, \"Warning message trigger count: %d\\n\", ++warn_counter);\n}\n\nstatic void lkdtm_EXCEPTION(void)\n{\n\t*((volatile int *) 0) = 0;\n}\n\nstatic void lkdtm_LOOP(void)\n{\n\tfor (;;)\n\t\t;\n}\n\nstatic void lkdtm_EXHAUST_STACK(void)\n{\n\tpr_info(\"Calling function with %lu frame size to depth %d ...\\n\",\n\t\tREC_STACK_SIZE, recur_count);\n\trecursive_loop(recur_count);\n\tpr_info(\"FAIL: survived without exhausting stack?!\\n\");\n}\n\nstatic noinline void __lkdtm_CORRUPT_STACK(void *stack)\n{\n\tmemset(stack, '\\xff', 64);\n}\n\n \nstatic noinline void lkdtm_CORRUPT_STACK(void)\n{\n\t \n\tchar data[8] __aligned(sizeof(void *));\n\n\tpr_info(\"Corrupting stack containing char array ...\\n\");\n\t__lkdtm_CORRUPT_STACK((void *)&data);\n}\n\n \nstatic noinline void lkdtm_CORRUPT_STACK_STRONG(void)\n{\n\tunion {\n\t\tunsigned short shorts[4];\n\t\tunsigned long *ptr;\n\t} data __aligned(sizeof(void *));\n\n\tpr_info(\"Corrupting stack containing union ...\\n\");\n\t__lkdtm_CORRUPT_STACK((void *)&data);\n}\n\nstatic pid_t stack_pid;\nstatic unsigned long stack_addr;\n\nstatic void lkdtm_REPORT_STACK(void)\n{\n\tvolatile uintptr_t magic;\n\tpid_t pid = task_pid_nr(current);\n\n\tif (pid != stack_pid) {\n\t\tpr_info(\"Starting stack offset tracking for pid %d\\n\", pid);\n\t\tstack_pid = pid;\n\t\tstack_addr = (uintptr_t)&magic;\n\t}\n\n\tpr_info(\"Stack offset: %d\\n\", (int)(stack_addr - (uintptr_t)&magic));\n}\n\nstatic pid_t stack_canary_pid;\nstatic unsigned long stack_canary;\nstatic unsigned long stack_canary_offset;\n\nstatic noinline void __lkdtm_REPORT_STACK_CANARY(void *stack)\n{\n\tint i = 0;\n\tpid_t pid = task_pid_nr(current);\n\tunsigned long *canary = (unsigned long *)stack;\n\tunsigned long current_offset = 0, init_offset = 0;\n\n\t \n\tfor (i = 1; i < 16; i++) {\n\t\tcanary = (unsigned long *)stack + i;\n#ifdef CONFIG_STACKPROTECTOR\n\t\tif (*canary == current->stack_canary)\n\t\t\tcurrent_offset = i;\n\t\tif (*canary == init_task.stack_canary)\n\t\t\tinit_offset = i;\n#endif\n\t}\n\n\tif (current_offset == 0) {\n\t\t \n\t\tif (init_offset != 0) {\n\t\t\tpr_err(\"FAIL: global stack canary found at offset %ld (canary for pid %d matches init_task's)!\\n\",\n\t\t\t       init_offset, pid);\n\t\t} else {\n\t\t\tpr_warn(\"FAIL: did not correctly locate stack canary :(\\n\");\n\t\t\tpr_expected_config(CONFIG_STACKPROTECTOR);\n\t\t}\n\n\t\treturn;\n\t} else if (init_offset != 0) {\n\t\tpr_warn(\"WARNING: found both current and init_task canaries nearby?!\\n\");\n\t}\n\n\tcanary = (unsigned long *)stack + current_offset;\n\tif (stack_canary_pid == 0) {\n\t\tstack_canary = *canary;\n\t\tstack_canary_pid = pid;\n\t\tstack_canary_offset = current_offset;\n\t\tpr_info(\"Recorded stack canary for pid %d at offset %ld\\n\",\n\t\t\tstack_canary_pid, stack_canary_offset);\n\t} else if (pid == stack_canary_pid) {\n\t\tpr_warn(\"ERROR: saw pid %d again -- please use a new pid\\n\", pid);\n\t} else {\n\t\tif (current_offset != stack_canary_offset) {\n\t\t\tpr_warn(\"ERROR: canary offset changed from %ld to %ld!?\\n\",\n\t\t\t\tstack_canary_offset, current_offset);\n\t\t\treturn;\n\t\t}\n\n\t\tif (*canary == stack_canary) {\n\t\t\tpr_warn(\"FAIL: canary identical for pid %d and pid %d at offset %ld!\\n\",\n\t\t\t\tstack_canary_pid, pid, current_offset);\n\t\t} else {\n\t\t\tpr_info(\"ok: stack canaries differ between pid %d and pid %d at offset %ld.\\n\",\n\t\t\t\tstack_canary_pid, pid, current_offset);\n\t\t\t \n\t\t\tstack_canary_pid = 0;\n\t\t}\n\t}\n}\n\nstatic void lkdtm_REPORT_STACK_CANARY(void)\n{\n\t \n\tchar data[8] __aligned(sizeof(void *)) = { };\n\n\t__lkdtm_REPORT_STACK_CANARY((void *)&data);\n}\n\nstatic void lkdtm_UNALIGNED_LOAD_STORE_WRITE(void)\n{\n\tstatic u8 data[5] __attribute__((aligned(4))) = {1, 2, 3, 4, 5};\n\tu32 *p;\n\tu32 val = 0x12345678;\n\n\tp = (u32 *)(data + 1);\n\tif (*p == 0)\n\t\tval = 0x87654321;\n\t*p = val;\n\n\tif (IS_ENABLED(CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS))\n\t\tpr_err(\"XFAIL: arch has CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS\\n\");\n}\n\nstatic void lkdtm_SOFTLOCKUP(void)\n{\n\tpreempt_disable();\n\tfor (;;)\n\t\tcpu_relax();\n}\n\nstatic void lkdtm_HARDLOCKUP(void)\n{\n\tlocal_irq_disable();\n\tfor (;;)\n\t\tcpu_relax();\n}\n\nstatic void lkdtm_SPINLOCKUP(void)\n{\n\t \n\tspin_lock(&lock_me_up);\n\t \n\t__release(&lock_me_up);\n}\n\nstatic void lkdtm_HUNG_TASK(void)\n{\n\tset_current_state(TASK_UNINTERRUPTIBLE);\n\tschedule();\n}\n\nstatic volatile unsigned int huge = INT_MAX - 2;\nstatic volatile unsigned int ignored;\n\nstatic void lkdtm_OVERFLOW_SIGNED(void)\n{\n\tint value;\n\n\tvalue = huge;\n\tpr_info(\"Normal signed addition ...\\n\");\n\tvalue += 1;\n\tignored = value;\n\n\tpr_info(\"Overflowing signed addition ...\\n\");\n\tvalue += 4;\n\tignored = value;\n}\n\n\nstatic void lkdtm_OVERFLOW_UNSIGNED(void)\n{\n\tunsigned int value;\n\n\tvalue = huge;\n\tpr_info(\"Normal unsigned addition ...\\n\");\n\tvalue += 1;\n\tignored = value;\n\n\tpr_info(\"Overflowing unsigned addition ...\\n\");\n\tvalue += 4;\n\tignored = value;\n}\n\n \nstruct array_bounds_flex_array {\n\tint one;\n\tint two;\n\tchar data[];\n};\n\nstruct array_bounds {\n\tint one;\n\tint two;\n\tchar data[8];\n\tint three;\n};\n\nstatic void lkdtm_ARRAY_BOUNDS(void)\n{\n\tstruct array_bounds_flex_array *not_checked;\n\tstruct array_bounds *checked;\n\tvolatile int i;\n\n\tnot_checked = kmalloc(sizeof(*not_checked) * 2, GFP_KERNEL);\n\tchecked = kmalloc(sizeof(*checked) * 2, GFP_KERNEL);\n\tif (!not_checked || !checked) {\n\t\tkfree(not_checked);\n\t\tkfree(checked);\n\t\treturn;\n\t}\n\n\tpr_info(\"Array access within bounds ...\\n\");\n\t \n\tfor (i = 0; i < sizeof(checked->data); i++)\n\t\tchecked->data[i] = 'A';\n\t \n\tfor (i = 0; i < 2; i++)\n\t\tnot_checked->data[i] = 'A';\n\n\tpr_info(\"Array access beyond bounds ...\\n\");\n\tfor (i = 0; i < sizeof(checked->data) + 1; i++)\n\t\tchecked->data[i] = 'B';\n\n\tkfree(not_checked);\n\tkfree(checked);\n\tpr_err(\"FAIL: survived array bounds overflow!\\n\");\n\tif (IS_ENABLED(CONFIG_UBSAN_BOUNDS))\n\t\tpr_expected_config(CONFIG_UBSAN_TRAP);\n\telse\n\t\tpr_expected_config(CONFIG_UBSAN_BOUNDS);\n}\n\nstruct lkdtm_annotated {\n\tunsigned long flags;\n\tint count;\n\tint array[] __counted_by(count);\n};\n\nstatic volatile int fam_count = 4;\n\nstatic void lkdtm_FAM_BOUNDS(void)\n{\n\tstruct lkdtm_annotated *inst;\n\n\tinst = kzalloc(struct_size(inst, array, fam_count + 1), GFP_KERNEL);\n\tif (!inst) {\n\t\tpr_err(\"FAIL: could not allocate test struct!\\n\");\n\t\treturn;\n\t}\n\n\tinst->count = fam_count;\n\tpr_info(\"Array access within bounds ...\\n\");\n\tinst->array[1] = fam_count;\n\tignored = inst->array[1];\n\n\tpr_info(\"Array access beyond bounds ...\\n\");\n\tinst->array[fam_count] = fam_count;\n\tignored = inst->array[fam_count];\n\n\tkfree(inst);\n\n\tpr_err(\"FAIL: survived access of invalid flexible array member index!\\n\");\n\n\tif (!__has_attribute(__counted_by__))\n\t\tpr_warn(\"This is expected since this %s was built a compiler supporting __counted_by\\n\",\n\t\t\tlkdtm_kernel_info);\n\telse if (IS_ENABLED(CONFIG_UBSAN_BOUNDS))\n\t\tpr_expected_config(CONFIG_UBSAN_TRAP);\n\telse\n\t\tpr_expected_config(CONFIG_UBSAN_BOUNDS);\n}\n\nstatic void lkdtm_CORRUPT_LIST_ADD(void)\n{\n\t \n\tLIST_HEAD(test_head);\n\tstruct lkdtm_list good, bad;\n\tvoid *target[2] = { };\n\tvoid *redirection = &target;\n\n\tpr_info(\"attempting good list addition\\n\");\n\n\t \n\tlist_add(&good.node, &test_head);\n\n\tpr_info(\"attempting corrupted list addition\\n\");\n\t \n\ttest_head.next = redirection;\n\tlist_add(&bad.node, &test_head);\n\n\tif (target[0] == NULL && target[1] == NULL)\n\t\tpr_err(\"Overwrite did not happen, but no BUG?!\\n\");\n\telse {\n\t\tpr_err(\"list_add() corruption not detected!\\n\");\n\t\tpr_expected_config(CONFIG_LIST_HARDENED);\n\t}\n}\n\nstatic void lkdtm_CORRUPT_LIST_DEL(void)\n{\n\tLIST_HEAD(test_head);\n\tstruct lkdtm_list item;\n\tvoid *target[2] = { };\n\tvoid *redirection = &target;\n\n\tlist_add(&item.node, &test_head);\n\n\tpr_info(\"attempting good list removal\\n\");\n\tlist_del(&item.node);\n\n\tpr_info(\"attempting corrupted list removal\\n\");\n\tlist_add(&item.node, &test_head);\n\n\t \n\titem.node.next = redirection;\n\tlist_del(&item.node);\n\n\tif (target[0] == NULL && target[1] == NULL)\n\t\tpr_err(\"Overwrite did not happen, but no BUG?!\\n\");\n\telse {\n\t\tpr_err(\"list_del() corruption not detected!\\n\");\n\t\tpr_expected_config(CONFIG_LIST_HARDENED);\n\t}\n}\n\n \nstatic void lkdtm_STACK_GUARD_PAGE_LEADING(void)\n{\n\tconst unsigned char *stack = task_stack_page(current);\n\tconst unsigned char *ptr = stack - 1;\n\tvolatile unsigned char byte;\n\n\tpr_info(\"attempting bad read from page below current stack\\n\");\n\n\tbyte = *ptr;\n\n\tpr_err(\"FAIL: accessed page before stack! (byte: %x)\\n\", byte);\n}\n\n \nstatic void lkdtm_STACK_GUARD_PAGE_TRAILING(void)\n{\n\tconst unsigned char *stack = task_stack_page(current);\n\tconst unsigned char *ptr = stack + THREAD_SIZE;\n\tvolatile unsigned char byte;\n\n\tpr_info(\"attempting bad read from page above current stack\\n\");\n\n\tbyte = *ptr;\n\n\tpr_err(\"FAIL: accessed page after stack! (byte: %x)\\n\", byte);\n}\n\nstatic void lkdtm_UNSET_SMEP(void)\n{\n#if IS_ENABLED(CONFIG_X86_64) && !IS_ENABLED(CONFIG_UML)\n#define MOV_CR4_DEPTH\t64\n\tvoid (*direct_write_cr4)(unsigned long val);\n\tunsigned char *insn;\n\tunsigned long cr4;\n\tint i;\n\n\tcr4 = native_read_cr4();\n\n\tif ((cr4 & X86_CR4_SMEP) != X86_CR4_SMEP) {\n\t\tpr_err(\"FAIL: SMEP not in use\\n\");\n\t\treturn;\n\t}\n\tcr4 &= ~(X86_CR4_SMEP);\n\n\tpr_info(\"trying to clear SMEP normally\\n\");\n\tnative_write_cr4(cr4);\n\tif (cr4 == native_read_cr4()) {\n\t\tpr_err(\"FAIL: pinning SMEP failed!\\n\");\n\t\tcr4 |= X86_CR4_SMEP;\n\t\tpr_info(\"restoring SMEP\\n\");\n\t\tnative_write_cr4(cr4);\n\t\treturn;\n\t}\n\tpr_info(\"ok: SMEP did not get cleared\\n\");\n\n\t \n\tinsn = (unsigned char *)native_write_cr4;\n\tOPTIMIZER_HIDE_VAR(insn);\n\tfor (i = 0; i < MOV_CR4_DEPTH; i++) {\n\t\t \n\t\tif (insn[i] == 0x0f && insn[i+1] == 0x22 && insn[i+2] == 0xe7)\n\t\t\tbreak;\n\t\t \n\t\tif (insn[i]   == 0x48 && insn[i+1] == 0x89 &&\n\t\t    insn[i+2] == 0xf8 && insn[i+3] == 0x0f &&\n\t\t    insn[i+4] == 0x22 && insn[i+5] == 0xe0)\n\t\t\tbreak;\n\t}\n\tif (i >= MOV_CR4_DEPTH) {\n\t\tpr_info(\"ok: cannot locate cr4 writing call gadget\\n\");\n\t\treturn;\n\t}\n\tdirect_write_cr4 = (void *)(insn + i);\n\n\tpr_info(\"trying to clear SMEP with call gadget\\n\");\n\tdirect_write_cr4(cr4);\n\tif (native_read_cr4() & X86_CR4_SMEP) {\n\t\tpr_info(\"ok: SMEP removal was reverted\\n\");\n\t} else {\n\t\tpr_err(\"FAIL: cleared SMEP not detected!\\n\");\n\t\tcr4 |= X86_CR4_SMEP;\n\t\tpr_info(\"restoring SMEP\\n\");\n\t\tnative_write_cr4(cr4);\n\t}\n#else\n\tpr_err(\"XFAIL: this test is x86_64-only\\n\");\n#endif\n}\n\nstatic void lkdtm_DOUBLE_FAULT(void)\n{\n#if IS_ENABLED(CONFIG_X86_32) && !IS_ENABLED(CONFIG_UML)\n\t \n\tstruct desc_struct d = {\n\t\t.type = 3,\t \n\t\t.p = 1,\t\t \n\t\t.d = 1,\t\t \n\t\t.g = 0,\t\t \n\t\t.s = 1,\t\t \n\t};\n\n\tlocal_irq_disable();\n\twrite_gdt_entry(get_cpu_gdt_rw(smp_processor_id()),\n\t\t\tGDT_ENTRY_TLS_MIN, &d, DESCTYPE_S);\n\n\t \n\tasm volatile (\"movw %0, %%ss; addl $0, (%%esp)\" ::\n\t\t      \"r\" ((unsigned short)(GDT_ENTRY_TLS_MIN << 3)));\n\n\tpr_err(\"FAIL: tried to double fault but didn't die\\n\");\n#else\n\tpr_err(\"XFAIL: this test is ia32-only\\n\");\n#endif\n}\n\n#ifdef CONFIG_ARM64\nstatic noinline void change_pac_parameters(void)\n{\n\tif (IS_ENABLED(CONFIG_ARM64_PTR_AUTH_KERNEL)) {\n\t\t \n\t\tptrauth_thread_init_kernel(current);\n\t\tptrauth_thread_switch_kernel(current);\n\t}\n}\n#endif\n\nstatic noinline void lkdtm_CORRUPT_PAC(void)\n{\n#ifdef CONFIG_ARM64\n#define CORRUPT_PAC_ITERATE\t10\n\tint i;\n\n\tif (!IS_ENABLED(CONFIG_ARM64_PTR_AUTH_KERNEL))\n\t\tpr_err(\"FAIL: kernel not built with CONFIG_ARM64_PTR_AUTH_KERNEL\\n\");\n\n\tif (!system_supports_address_auth()) {\n\t\tpr_err(\"FAIL: CPU lacks pointer authentication feature\\n\");\n\t\treturn;\n\t}\n\n\tpr_info(\"changing PAC parameters to force function return failure...\\n\");\n\t \n\tfor (i = 0; i < CORRUPT_PAC_ITERATE; i++)\n\t\tchange_pac_parameters();\n\n\tpr_err(\"FAIL: survived PAC changes! Kernel may be unstable from here\\n\");\n#else\n\tpr_err(\"XFAIL: this test is arm64-only\\n\");\n#endif\n}\n\nstatic struct crashtype crashtypes[] = {\n\tCRASHTYPE(PANIC),\n\tCRASHTYPE(BUG),\n\tCRASHTYPE(WARNING),\n\tCRASHTYPE(WARNING_MESSAGE),\n\tCRASHTYPE(EXCEPTION),\n\tCRASHTYPE(LOOP),\n\tCRASHTYPE(EXHAUST_STACK),\n\tCRASHTYPE(CORRUPT_STACK),\n\tCRASHTYPE(CORRUPT_STACK_STRONG),\n\tCRASHTYPE(REPORT_STACK),\n\tCRASHTYPE(REPORT_STACK_CANARY),\n\tCRASHTYPE(UNALIGNED_LOAD_STORE_WRITE),\n\tCRASHTYPE(SOFTLOCKUP),\n\tCRASHTYPE(HARDLOCKUP),\n\tCRASHTYPE(SPINLOCKUP),\n\tCRASHTYPE(HUNG_TASK),\n\tCRASHTYPE(OVERFLOW_SIGNED),\n\tCRASHTYPE(OVERFLOW_UNSIGNED),\n\tCRASHTYPE(ARRAY_BOUNDS),\n\tCRASHTYPE(FAM_BOUNDS),\n\tCRASHTYPE(CORRUPT_LIST_ADD),\n\tCRASHTYPE(CORRUPT_LIST_DEL),\n\tCRASHTYPE(STACK_GUARD_PAGE_LEADING),\n\tCRASHTYPE(STACK_GUARD_PAGE_TRAILING),\n\tCRASHTYPE(UNSET_SMEP),\n\tCRASHTYPE(DOUBLE_FAULT),\n\tCRASHTYPE(CORRUPT_PAC),\n};\n\nstruct crashtype_category bugs_crashtypes = {\n\t.crashtypes = crashtypes,\n\t.len\t    = ARRAY_SIZE(crashtypes),\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}