{
  "module_name": "bcm_vk_msg.c",
  "hash_id": "456587c5191075b36e28224c0474a61118a3d377effaf96dd09eda3a53ae249f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/bcm-vk/bcm_vk_msg.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#include <linux/fs.h>\n#include <linux/hash.h>\n#include <linux/interrupt.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/poll.h>\n#include <linux/sizes.h>\n#include <linux/spinlock.h>\n#include <linux/timer.h>\n\n#include \"bcm_vk.h\"\n#include \"bcm_vk_msg.h\"\n#include \"bcm_vk_sg.h\"\n\n \n#define BCM_VK_MSG_Q_SHIFT\t 4\n#define BCM_VK_MSG_Q_MASK\t 0xF\n#define BCM_VK_MSG_ID_MASK\t 0xFFF\n\n#define BCM_VK_DMA_DRAIN_MAX_MS\t  2000\n\n \n#define BCM_VK_MSG_PROC_MAX_LOOP 2\n\n \nstatic bool hb_mon = true;\nmodule_param(hb_mon, bool, 0444);\nMODULE_PARM_DESC(hb_mon, \"Monitoring heartbeat continuously.\\n\");\nstatic int batch_log = 1;\nmodule_param(batch_log, int, 0444);\nMODULE_PARM_DESC(batch_log, \"Max num of logs per batch operation.\\n\");\n\nstatic bool hb_mon_is_on(void)\n{\n\treturn hb_mon;\n}\n\nstatic u32 get_q_num(const struct vk_msg_blk *msg)\n{\n\tu32 q_num = msg->trans_id & BCM_VK_MSG_Q_MASK;\n\n\tif (q_num >= VK_MSGQ_PER_CHAN_MAX)\n\t\tq_num = VK_MSGQ_NUM_DEFAULT;\n\treturn q_num;\n}\n\nstatic void set_q_num(struct vk_msg_blk *msg, u32 q_num)\n{\n\tu32 trans_q;\n\n\tif (q_num >= VK_MSGQ_PER_CHAN_MAX)\n\t\ttrans_q = VK_MSGQ_NUM_DEFAULT;\n\telse\n\t\ttrans_q = q_num;\n\n\tmsg->trans_id = (msg->trans_id & ~BCM_VK_MSG_Q_MASK) | trans_q;\n}\n\nstatic u32 get_msg_id(const struct vk_msg_blk *msg)\n{\n\treturn ((msg->trans_id >> BCM_VK_MSG_Q_SHIFT) & BCM_VK_MSG_ID_MASK);\n}\n\nstatic void set_msg_id(struct vk_msg_blk *msg, u32 val)\n{\n\tmsg->trans_id = (val << BCM_VK_MSG_Q_SHIFT) | get_q_num(msg);\n}\n\nstatic u32 msgq_inc(const struct bcm_vk_sync_qinfo *qinfo, u32 idx, u32 inc)\n{\n\treturn ((idx + inc) & qinfo->q_mask);\n}\n\nstatic\nstruct vk_msg_blk __iomem *msgq_blk_addr(const struct bcm_vk_sync_qinfo *qinfo,\n\t\t\t\t\t u32 idx)\n{\n\treturn qinfo->q_start + (VK_MSGQ_BLK_SIZE * idx);\n}\n\nstatic u32 msgq_occupied(const struct bcm_vk_msgq __iomem *msgq,\n\t\t\t const struct bcm_vk_sync_qinfo *qinfo)\n{\n\tu32 wr_idx, rd_idx;\n\n\twr_idx = readl_relaxed(&msgq->wr_idx);\n\trd_idx = readl_relaxed(&msgq->rd_idx);\n\n\treturn ((wr_idx - rd_idx) & qinfo->q_mask);\n}\n\nstatic\nu32 msgq_avail_space(const struct bcm_vk_msgq __iomem *msgq,\n\t\t     const struct bcm_vk_sync_qinfo *qinfo)\n{\n\treturn (qinfo->q_size - msgq_occupied(msgq, qinfo) - 1);\n}\n\n \n#define BCM_VK_H2VK_ENQ_RETRY 10\n#define BCM_VK_H2VK_ENQ_RETRY_DELAY_MS 50\n\nbool bcm_vk_drv_access_ok(struct bcm_vk *vk)\n{\n\treturn (!!atomic_read(&vk->msgq_inited));\n}\n\nvoid bcm_vk_set_host_alert(struct bcm_vk *vk, u32 bit_mask)\n{\n\tstruct bcm_vk_alert *alert = &vk->host_alert;\n\tunsigned long flags;\n\n\t \n\tspin_lock_irqsave(&vk->host_alert_lock, flags);\n\talert->notfs |= bit_mask;\n\tspin_unlock_irqrestore(&vk->host_alert_lock, flags);\n\n\tif (test_and_set_bit(BCM_VK_WQ_NOTF_PEND, vk->wq_offload) == 0)\n\t\tqueue_work(vk->wq_thread, &vk->wq_work);\n}\n\n \n#define BCM_VK_HB_TIMER_S 3\n#define BCM_VK_HB_TIMER_VALUE (BCM_VK_HB_TIMER_S * HZ)\n#define BCM_VK_HB_LOST_MAX (27 / BCM_VK_HB_TIMER_S)\n\nstatic void bcm_vk_hb_poll(struct work_struct *work)\n{\n\tu32 uptime_s;\n\tstruct bcm_vk_hb_ctrl *hb = container_of(to_delayed_work(work), struct bcm_vk_hb_ctrl,\n\t\t\t\t\t\t work);\n\tstruct bcm_vk *vk = container_of(hb, struct bcm_vk, hb_ctrl);\n\n\tif (bcm_vk_drv_access_ok(vk) && hb_mon_is_on()) {\n\t\t \n\t\tuptime_s = vkread32(vk, BAR_0, BAR_OS_UPTIME);\n\n\t\tif (uptime_s == hb->last_uptime)\n\t\t\thb->lost_cnt++;\n\t\telse  \n\t\t\thb->lost_cnt = 0;\n\n\t\tdev_dbg(&vk->pdev->dev, \"Last uptime %d current %d, lost %d\\n\",\n\t\t\thb->last_uptime, uptime_s, hb->lost_cnt);\n\n\t\t \n\t\thb->last_uptime = uptime_s;\n\t} else {\n\t\t \n\t\thb->lost_cnt = 0;\n\t}\n\n\t \n\tif (hb->lost_cnt > BCM_VK_HB_LOST_MAX) {\n\t\tdev_err(&vk->pdev->dev, \"Heartbeat Misses %d times, %d s!\\n\",\n\t\t\tBCM_VK_HB_LOST_MAX,\n\t\t\tBCM_VK_HB_LOST_MAX * BCM_VK_HB_TIMER_S);\n\n\t\tbcm_vk_blk_drv_access(vk);\n\t\tbcm_vk_set_host_alert(vk, ERR_LOG_HOST_HB_FAIL);\n\t}\n\t \n\tschedule_delayed_work(&hb->work, BCM_VK_HB_TIMER_VALUE);\n}\n\nvoid bcm_vk_hb_init(struct bcm_vk *vk)\n{\n\tstruct bcm_vk_hb_ctrl *hb = &vk->hb_ctrl;\n\n\tINIT_DELAYED_WORK(&hb->work, bcm_vk_hb_poll);\n\tschedule_delayed_work(&hb->work, BCM_VK_HB_TIMER_VALUE);\n}\n\nvoid bcm_vk_hb_deinit(struct bcm_vk *vk)\n{\n\tstruct bcm_vk_hb_ctrl *hb = &vk->hb_ctrl;\n\n\tcancel_delayed_work_sync(&hb->work);\n}\n\nstatic void bcm_vk_msgid_bitmap_clear(struct bcm_vk *vk,\n\t\t\t\t      unsigned int start,\n\t\t\t\t      unsigned int nbits)\n{\n\tspin_lock(&vk->msg_id_lock);\n\tbitmap_clear(vk->bmap, start, nbits);\n\tspin_unlock(&vk->msg_id_lock);\n}\n\n \nstatic struct bcm_vk_ctx *bcm_vk_get_ctx(struct bcm_vk *vk, const pid_t pid)\n{\n\tu32 i;\n\tstruct bcm_vk_ctx *ctx = NULL;\n\tu32 hash_idx = hash_32(pid, VK_PID_HT_SHIFT_BIT);\n\n\tspin_lock(&vk->ctx_lock);\n\n\t \n\tif (vk->reset_pid) {\n\t\tdev_err(&vk->pdev->dev,\n\t\t\t\"No context allowed during reset by pid %d\\n\",\n\t\t\tvk->reset_pid);\n\n\t\tgoto in_reset_exit;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(vk->ctx); i++) {\n\t\tif (!vk->ctx[i].in_use) {\n\t\t\tvk->ctx[i].in_use = true;\n\t\t\tctx = &vk->ctx[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!ctx) {\n\t\tdev_err(&vk->pdev->dev, \"All context in use\\n\");\n\n\t\tgoto all_in_use_exit;\n\t}\n\n\t \n\tctx->pid = pid;\n\tctx->hash_idx = hash_idx;\n\tlist_add_tail(&ctx->node, &vk->pid_ht[hash_idx].head);\n\n\t \n\tkref_get(&vk->kref);\n\n\t \n\tatomic_set(&ctx->pend_cnt, 0);\n\tatomic_set(&ctx->dma_cnt, 0);\n\tinit_waitqueue_head(&ctx->rd_wq);\n\nall_in_use_exit:\nin_reset_exit:\n\tspin_unlock(&vk->ctx_lock);\n\n\treturn ctx;\n}\n\nstatic u16 bcm_vk_get_msg_id(struct bcm_vk *vk)\n{\n\tu16 rc = VK_MSG_ID_OVERFLOW;\n\tu16 test_bit_count = 0;\n\n\tspin_lock(&vk->msg_id_lock);\n\twhile (test_bit_count < (VK_MSG_ID_BITMAP_SIZE - 1)) {\n\t\t \n\t\tvk->msg_id++;\n\t\tif (vk->msg_id == VK_MSG_ID_BITMAP_SIZE)\n\t\t\tvk->msg_id = 1;\n\n\t\tif (test_bit(vk->msg_id, vk->bmap)) {\n\t\t\ttest_bit_count++;\n\t\t\tcontinue;\n\t\t}\n\t\trc = vk->msg_id;\n\t\tbitmap_set(vk->bmap, vk->msg_id, 1);\n\t\tbreak;\n\t}\n\tspin_unlock(&vk->msg_id_lock);\n\n\treturn rc;\n}\n\nstatic int bcm_vk_free_ctx(struct bcm_vk *vk, struct bcm_vk_ctx *ctx)\n{\n\tu32 idx;\n\tu32 hash_idx;\n\tpid_t pid;\n\tstruct bcm_vk_ctx *entry;\n\tint count = 0;\n\n\tif (!ctx) {\n\t\tdev_err(&vk->pdev->dev, \"NULL context detected\\n\");\n\t\treturn -EINVAL;\n\t}\n\tidx = ctx->idx;\n\tpid = ctx->pid;\n\n\tspin_lock(&vk->ctx_lock);\n\n\tif (!vk->ctx[idx].in_use) {\n\t\tdev_err(&vk->pdev->dev, \"context[%d] not in use!\\n\", idx);\n\t} else {\n\t\tvk->ctx[idx].in_use = false;\n\t\tvk->ctx[idx].miscdev = NULL;\n\n\t\t \n\t\tlist_del(&ctx->node);\n\t\thash_idx = ctx->hash_idx;\n\t\tlist_for_each_entry(entry, &vk->pid_ht[hash_idx].head, node) {\n\t\t\tif (entry->pid == pid)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\tspin_unlock(&vk->ctx_lock);\n\n\treturn count;\n}\n\nstatic void bcm_vk_free_wkent(struct device *dev, struct bcm_vk_wkent *entry)\n{\n\tint proc_cnt;\n\n\tbcm_vk_sg_free(dev, entry->dma, VK_DMA_MAX_ADDRS, &proc_cnt);\n\tif (proc_cnt)\n\t\tatomic_dec(&entry->ctx->dma_cnt);\n\n\tkfree(entry->to_h_msg);\n\tkfree(entry);\n}\n\nstatic void bcm_vk_drain_all_pend(struct device *dev,\n\t\t\t\t  struct bcm_vk_msg_chan *chan,\n\t\t\t\t  struct bcm_vk_ctx *ctx)\n{\n\tu32 num;\n\tstruct bcm_vk_wkent *entry, *tmp;\n\tstruct bcm_vk *vk;\n\tstruct list_head del_q;\n\n\tif (ctx)\n\t\tvk = container_of(ctx->miscdev, struct bcm_vk, miscdev);\n\n\tINIT_LIST_HEAD(&del_q);\n\tspin_lock(&chan->pendq_lock);\n\tfor (num = 0; num < chan->q_nr; num++) {\n\t\tlist_for_each_entry_safe(entry, tmp, &chan->pendq[num], node) {\n\t\t\tif ((!ctx) || (entry->ctx->idx == ctx->idx)) {\n\t\t\t\tlist_move_tail(&entry->node, &del_q);\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock(&chan->pendq_lock);\n\n\t \n\tnum = 0;\n\tlist_for_each_entry_safe(entry, tmp, &del_q, node) {\n\t\tlist_del(&entry->node);\n\t\tnum++;\n\t\tif (ctx) {\n\t\t\tstruct vk_msg_blk *msg;\n\t\t\tint bit_set;\n\t\t\tbool responded;\n\t\t\tu32 msg_id;\n\n\t\t\t \n\t\t\tmsg = entry->to_v_msg;\n\t\t\tmsg_id = get_msg_id(msg);\n\t\t\tbit_set = test_bit(msg_id, vk->bmap);\n\t\t\tresponded = entry->to_h_msg ? true : false;\n\t\t\tif (num <= batch_log)\n\t\t\t\tdev_info(dev,\n\t\t\t\t\t \"Drained: fid %u size %u msg 0x%x(seq-%x) ctx 0x%x[fd-%d] args:[0x%x 0x%x] resp %s, bmap %d\\n\",\n\t\t\t\t\t msg->function_id, msg->size,\n\t\t\t\t\t msg_id, entry->seq_num,\n\t\t\t\t\t msg->context_id, entry->ctx->idx,\n\t\t\t\t\t msg->cmd, msg->arg,\n\t\t\t\t\t responded ? \"T\" : \"F\", bit_set);\n\t\t\tif (responded)\n\t\t\t\tatomic_dec(&ctx->pend_cnt);\n\t\t\telse if (bit_set)\n\t\t\t\tbcm_vk_msgid_bitmap_clear(vk, msg_id, 1);\n\t\t}\n\t\tbcm_vk_free_wkent(dev, entry);\n\t}\n\tif (num && ctx)\n\t\tdev_info(dev, \"Total drained items %d [fd-%d]\\n\",\n\t\t\t num, ctx->idx);\n}\n\nvoid bcm_vk_drain_msg_on_reset(struct bcm_vk *vk)\n{\n\tbcm_vk_drain_all_pend(&vk->pdev->dev, &vk->to_v_msg_chan, NULL);\n\tbcm_vk_drain_all_pend(&vk->pdev->dev, &vk->to_h_msg_chan, NULL);\n}\n\n \nint bcm_vk_sync_msgq(struct bcm_vk *vk, bool force_sync)\n{\n\tstruct bcm_vk_msgq __iomem *msgq;\n\tstruct device *dev = &vk->pdev->dev;\n\tu32 msgq_off;\n\tu32 num_q;\n\tstruct bcm_vk_msg_chan *chan_list[] = {&vk->to_v_msg_chan,\n\t\t\t\t\t       &vk->to_h_msg_chan};\n\tstruct bcm_vk_msg_chan *chan;\n\tint i, j;\n\tint ret = 0;\n\n\t \n\tif (!bcm_vk_msgq_marker_valid(vk)) {\n\t\tdev_info(dev, \"BAR1 msgq marker not initialized.\\n\");\n\t\treturn -EAGAIN;\n\t}\n\n\tmsgq_off = vkread32(vk, BAR_1, VK_BAR1_MSGQ_CTRL_OFF);\n\n\t \n\tnum_q = vkread32(vk, BAR_1, VK_BAR1_MSGQ_NR) / 2;\n\tif (!num_q || (num_q > VK_MSGQ_PER_CHAN_MAX)) {\n\t\tdev_err(dev,\n\t\t\t\"Advertised msgq %d error - max %d allowed\\n\",\n\t\t\tnum_q, VK_MSGQ_PER_CHAN_MAX);\n\t\treturn -EINVAL;\n\t}\n\n\tvk->to_v_msg_chan.q_nr = num_q;\n\tvk->to_h_msg_chan.q_nr = num_q;\n\n\t \n\tmsgq = vk->bar[BAR_1] + msgq_off;\n\n\t \n\tif (bcm_vk_drv_access_ok(vk) && !force_sync) {\n\t\tdev_err(dev, \"Msgq info already in sync\\n\");\n\t\treturn -EPERM;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(chan_list); i++) {\n\t\tchan = chan_list[i];\n\t\tmemset(chan->sync_qinfo, 0, sizeof(chan->sync_qinfo));\n\n\t\tfor (j = 0; j < num_q; j++) {\n\t\t\tstruct bcm_vk_sync_qinfo *qinfo;\n\t\t\tu32 msgq_start;\n\t\t\tu32 msgq_size;\n\t\t\tu32 msgq_nxt;\n\t\t\tu32 msgq_db_offset, q_db_offset;\n\n\t\t\tchan->msgq[j] = msgq;\n\t\t\tmsgq_start = readl_relaxed(&msgq->start);\n\t\t\tmsgq_size = readl_relaxed(&msgq->size);\n\t\t\tmsgq_nxt = readl_relaxed(&msgq->nxt);\n\t\t\tmsgq_db_offset = readl_relaxed(&msgq->db_offset);\n\t\t\tq_db_offset = (msgq_db_offset & ((1 << DB_SHIFT) - 1));\n\t\t\tif (q_db_offset  == (~msgq_db_offset >> DB_SHIFT))\n\t\t\t\tmsgq_db_offset = q_db_offset;\n\t\t\telse\n\t\t\t\t \n\t\t\t\tmsgq_db_offset = VK_BAR0_Q_DB_BASE(j);\n\n\t\t\tdev_info(dev,\n\t\t\t\t \"MsgQ[%d] type %d num %d, @ 0x%x, db_offset 0x%x rd_idx %d wr_idx %d, size %d, nxt 0x%x\\n\",\n\t\t\t\t j,\n\t\t\t\t readw_relaxed(&msgq->type),\n\t\t\t\t readw_relaxed(&msgq->num),\n\t\t\t\t msgq_start,\n\t\t\t\t msgq_db_offset,\n\t\t\t\t readl_relaxed(&msgq->rd_idx),\n\t\t\t\t readl_relaxed(&msgq->wr_idx),\n\t\t\t\t msgq_size,\n\t\t\t\t msgq_nxt);\n\n\t\t\tqinfo = &chan->sync_qinfo[j];\n\t\t\t \n\t\t\tqinfo->q_start = vk->bar[BAR_1] + msgq_start;\n\t\t\tqinfo->q_size = msgq_size;\n\t\t\t \n\t\t\tqinfo->q_low = qinfo->q_size >> 1;\n\t\t\tqinfo->q_mask = qinfo->q_size - 1;\n\t\t\tqinfo->q_db_offset = msgq_db_offset;\n\n\t\t\tmsgq++;\n\t\t}\n\t}\n\tatomic_set(&vk->msgq_inited, 1);\n\n\treturn ret;\n}\n\nstatic int bcm_vk_msg_chan_init(struct bcm_vk_msg_chan *chan)\n{\n\tu32 i;\n\n\tmutex_init(&chan->msgq_mutex);\n\tspin_lock_init(&chan->pendq_lock);\n\tfor (i = 0; i < VK_MSGQ_MAX_NR; i++)\n\t\tINIT_LIST_HEAD(&chan->pendq[i]);\n\n\treturn 0;\n}\n\nstatic void bcm_vk_append_pendq(struct bcm_vk_msg_chan *chan, u16 q_num,\n\t\t\t\tstruct bcm_vk_wkent *entry)\n{\n\tstruct bcm_vk_ctx *ctx;\n\n\tspin_lock(&chan->pendq_lock);\n\tlist_add_tail(&entry->node, &chan->pendq[q_num]);\n\tif (entry->to_h_msg) {\n\t\tctx = entry->ctx;\n\t\tatomic_inc(&ctx->pend_cnt);\n\t\twake_up_interruptible(&ctx->rd_wq);\n\t}\n\tspin_unlock(&chan->pendq_lock);\n}\n\nstatic u32 bcm_vk_append_ib_sgl(struct bcm_vk *vk,\n\t\t\t\tstruct bcm_vk_wkent *entry,\n\t\t\t\tstruct _vk_data *data,\n\t\t\t\tunsigned int num_planes)\n{\n\tunsigned int i;\n\tunsigned int item_cnt = 0;\n\tstruct device *dev = &vk->pdev->dev;\n\tstruct bcm_vk_msg_chan *chan = &vk->to_v_msg_chan;\n\tstruct vk_msg_blk *msg = &entry->to_v_msg[0];\n\tstruct bcm_vk_msgq __iomem *msgq;\n\tstruct bcm_vk_sync_qinfo *qinfo;\n\tu32 ib_sgl_size = 0;\n\tu8 *buf = (u8 *)&entry->to_v_msg[entry->to_v_blks];\n\tu32 avail;\n\tu32 q_num;\n\n\t \n\tq_num = get_q_num(msg);\n\tmsgq = chan->msgq[q_num];\n\tqinfo = &chan->sync_qinfo[q_num];\n\tavail = msgq_avail_space(msgq, qinfo);\n\tif (avail < qinfo->q_low) {\n\t\tdev_dbg(dev, \"Skip inserting inband SGL, [0x%x/0x%x]\\n\",\n\t\t\tavail, qinfo->q_size);\n\t\treturn 0;\n\t}\n\n\tfor (i = 0; i < num_planes; i++) {\n\t\tif (data[i].address &&\n\t\t    (ib_sgl_size + data[i].size) <= vk->ib_sgl_size) {\n\t\t\titem_cnt++;\n\t\t\tmemcpy(buf, entry->dma[i].sglist, data[i].size);\n\t\t\tib_sgl_size += data[i].size;\n\t\t\tbuf += data[i].size;\n\t\t}\n\t}\n\n\tdev_dbg(dev, \"Num %u sgl items appended, size 0x%x, room 0x%x\\n\",\n\t\titem_cnt, ib_sgl_size, vk->ib_sgl_size);\n\n\t \n\tib_sgl_size = (ib_sgl_size + VK_MSGQ_BLK_SIZE - 1)\n\t\t       >> VK_MSGQ_BLK_SZ_SHIFT;\n\n\treturn ib_sgl_size;\n}\n\nvoid bcm_to_v_q_doorbell(struct bcm_vk *vk, u32 q_num, u32 db_val)\n{\n\tstruct bcm_vk_msg_chan *chan = &vk->to_v_msg_chan;\n\tstruct bcm_vk_sync_qinfo *qinfo = &chan->sync_qinfo[q_num];\n\n\tvkwrite32(vk, db_val, BAR_0, qinfo->q_db_offset);\n}\n\nstatic int bcm_to_v_msg_enqueue(struct bcm_vk *vk, struct bcm_vk_wkent *entry)\n{\n\tstatic u32 seq_num;\n\tstruct bcm_vk_msg_chan *chan = &vk->to_v_msg_chan;\n\tstruct device *dev = &vk->pdev->dev;\n\tstruct vk_msg_blk *src = &entry->to_v_msg[0];\n\n\tstruct vk_msg_blk __iomem *dst;\n\tstruct bcm_vk_msgq __iomem *msgq;\n\tstruct bcm_vk_sync_qinfo *qinfo;\n\tu32 q_num = get_q_num(src);\n\tu32 wr_idx;  \n\tu32 i;\n\tu32 avail;\n\tu32 retry;\n\n\tif (entry->to_v_blks != src->size + 1) {\n\t\tdev_err(dev, \"number of blks %d not matching %d MsgId[0x%x]: func %d ctx 0x%x\\n\",\n\t\t\tentry->to_v_blks,\n\t\t\tsrc->size + 1,\n\t\t\tget_msg_id(src),\n\t\t\tsrc->function_id,\n\t\t\tsrc->context_id);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tmsgq = chan->msgq[q_num];\n\tqinfo = &chan->sync_qinfo[q_num];\n\n\tmutex_lock(&chan->msgq_mutex);\n\n\tavail = msgq_avail_space(msgq, qinfo);\n\n\t \n\tretry = 0;\n\twhile ((avail < entry->to_v_blks) &&\n\t       (retry++ < BCM_VK_H2VK_ENQ_RETRY)) {\n\t\tmutex_unlock(&chan->msgq_mutex);\n\n\t\tmsleep(BCM_VK_H2VK_ENQ_RETRY_DELAY_MS);\n\t\tmutex_lock(&chan->msgq_mutex);\n\t\tavail = msgq_avail_space(msgq, qinfo);\n\t}\n\tif (retry > BCM_VK_H2VK_ENQ_RETRY) {\n\t\tmutex_unlock(&chan->msgq_mutex);\n\t\treturn -EAGAIN;\n\t}\n\n\t \n\tentry->seq_num = seq_num++;  \n\twr_idx = readl_relaxed(&msgq->wr_idx);\n\n\tif (wr_idx >= qinfo->q_size) {\n\t\tdev_crit(dev, \"Invalid wr_idx 0x%x => max 0x%x!\",\n\t\t\t wr_idx, qinfo->q_size);\n\t\tbcm_vk_blk_drv_access(vk);\n\t\tbcm_vk_set_host_alert(vk, ERR_LOG_HOST_PCIE_DWN);\n\t\tgoto idx_err;\n\t}\n\n\tdst = msgq_blk_addr(qinfo, wr_idx);\n\tfor (i = 0; i < entry->to_v_blks; i++) {\n\t\tmemcpy_toio(dst, src, sizeof(*dst));\n\n\t\tsrc++;\n\t\twr_idx = msgq_inc(qinfo, wr_idx, 1);\n\t\tdst = msgq_blk_addr(qinfo, wr_idx);\n\t}\n\n\t \n\twritel(wr_idx, &msgq->wr_idx);\n\n\t \n\tdev_dbg(dev,\n\t\t\"MsgQ[%d] [Rd Wr] = [%d %d] blks inserted %d - Q = [u-%d a-%d]/%d\\n\",\n\t\treadl_relaxed(&msgq->num),\n\t\treadl_relaxed(&msgq->rd_idx),\n\t\twr_idx,\n\t\tentry->to_v_blks,\n\t\tmsgq_occupied(msgq, qinfo),\n\t\tmsgq_avail_space(msgq, qinfo),\n\t\treadl_relaxed(&msgq->size));\n\t \n\tbcm_to_v_q_doorbell(vk, q_num, wr_idx + 1);\nidx_err:\n\tmutex_unlock(&chan->msgq_mutex);\n\treturn 0;\n}\n\nint bcm_vk_send_shutdown_msg(struct bcm_vk *vk, u32 shut_type,\n\t\t\t     const pid_t pid, const u32 q_num)\n{\n\tint rc = 0;\n\tstruct bcm_vk_wkent *entry;\n\tstruct device *dev = &vk->pdev->dev;\n\n\t \n\tif (!bcm_vk_msgq_marker_valid(vk)) {\n\t\tdev_info(dev, \"PCIe comm chan - invalid marker (0x%x)!\\n\",\n\t\t\t vkread32(vk, BAR_1, VK_BAR1_MSGQ_DEF_RDY));\n\t\treturn -EINVAL;\n\t}\n\n\tentry = kzalloc(struct_size(entry, to_v_msg, 1), GFP_KERNEL);\n\tif (!entry)\n\t\treturn -ENOMEM;\n\n\t \n\tentry->to_v_msg[0].function_id = VK_FID_SHUTDOWN;\n\tset_q_num(&entry->to_v_msg[0], q_num);\n\tset_msg_id(&entry->to_v_msg[0], VK_SIMPLEX_MSG_ID);\n\tentry->to_v_blks = 1;  \n\n\tentry->to_v_msg[0].cmd = shut_type;\n\tentry->to_v_msg[0].arg = pid;\n\n\trc = bcm_to_v_msg_enqueue(vk, entry);\n\tif (rc)\n\t\tdev_err(dev,\n\t\t\t\"Sending shutdown message to q %d for pid %d fails.\\n\",\n\t\t\tget_q_num(&entry->to_v_msg[0]), pid);\n\n\tkfree(entry);\n\n\treturn rc;\n}\n\nstatic int bcm_vk_handle_last_sess(struct bcm_vk *vk, const pid_t pid,\n\t\t\t\t   const u32 q_num)\n{\n\tint rc = 0;\n\tstruct device *dev = &vk->pdev->dev;\n\n\t \n\tif (!bcm_vk_drv_access_ok(vk)) {\n\t\tif (vk->reset_pid == pid)\n\t\t\tvk->reset_pid = 0;\n\t\treturn -EPERM;\n\t}\n\n\tdev_dbg(dev, \"No more sessions, shut down pid %d\\n\", pid);\n\n\t \n\tif (vk->reset_pid != pid)\n\t\trc = bcm_vk_send_shutdown_msg(vk, VK_SHUTDOWN_PID, pid, q_num);\n\telse\n\t\t \n\t\tvk->reset_pid = 0;\n\n\treturn rc;\n}\n\nstatic struct bcm_vk_wkent *bcm_vk_dequeue_pending(struct bcm_vk *vk,\n\t\t\t\t\t\t   struct bcm_vk_msg_chan *chan,\n\t\t\t\t\t\t   u16 q_num,\n\t\t\t\t\t\t   u16 msg_id)\n{\n\tstruct bcm_vk_wkent *entry = NULL, *iter;\n\n\tspin_lock(&chan->pendq_lock);\n\tlist_for_each_entry(iter, &chan->pendq[q_num], node) {\n\t\tif (get_msg_id(&iter->to_v_msg[0]) == msg_id) {\n\t\t\tlist_del(&iter->node);\n\t\t\tentry = iter;\n\t\t\tbcm_vk_msgid_bitmap_clear(vk, msg_id, 1);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&chan->pendq_lock);\n\treturn entry;\n}\n\ns32 bcm_to_h_msg_dequeue(struct bcm_vk *vk)\n{\n\tstruct device *dev = &vk->pdev->dev;\n\tstruct bcm_vk_msg_chan *chan = &vk->to_h_msg_chan;\n\tstruct vk_msg_blk *data;\n\tstruct vk_msg_blk __iomem *src;\n\tstruct vk_msg_blk *dst;\n\tstruct bcm_vk_msgq __iomem *msgq;\n\tstruct bcm_vk_sync_qinfo *qinfo;\n\tstruct bcm_vk_wkent *entry;\n\tu32 rd_idx, wr_idx;\n\tu32 q_num, msg_id, j;\n\tu32 num_blks;\n\ts32 total = 0;\n\tint cnt = 0;\n\tint msg_processed = 0;\n\tint max_msg_to_process;\n\tbool exit_loop;\n\n\t \n\tmutex_lock(&chan->msgq_mutex);\n\n\tfor (q_num = 0; q_num < chan->q_nr; q_num++) {\n\t\tmsgq = chan->msgq[q_num];\n\t\tqinfo = &chan->sync_qinfo[q_num];\n\t\tmax_msg_to_process = BCM_VK_MSG_PROC_MAX_LOOP * qinfo->q_size;\n\n\t\trd_idx = readl_relaxed(&msgq->rd_idx);\n\t\twr_idx = readl_relaxed(&msgq->wr_idx);\n\t\tmsg_processed = 0;\n\t\texit_loop = false;\n\t\twhile ((rd_idx != wr_idx) && !exit_loop) {\n\t\t\tu8 src_size;\n\n\t\t\t \n\t\t\tsrc = msgq_blk_addr(qinfo, rd_idx & qinfo->q_mask);\n\t\t\tsrc_size = readb(&src->size);\n\n\t\t\tif ((rd_idx >= qinfo->q_size) ||\n\t\t\t    (src_size > (qinfo->q_size - 1))) {\n\t\t\t\tdev_crit(dev,\n\t\t\t\t\t \"Invalid rd_idx 0x%x or size 0x%x => max 0x%x!\",\n\t\t\t\t\t rd_idx, src_size, qinfo->q_size);\n\t\t\t\tbcm_vk_blk_drv_access(vk);\n\t\t\t\tbcm_vk_set_host_alert(vk,\n\t\t\t\t\t\t      ERR_LOG_HOST_PCIE_DWN);\n\t\t\t\tgoto idx_err;\n\t\t\t}\n\n\t\t\tnum_blks = src_size + 1;\n\t\t\tdata = kzalloc(num_blks * VK_MSGQ_BLK_SIZE, GFP_KERNEL);\n\t\t\tif (data) {\n\t\t\t\t \n\t\t\t\tdst = data;\n\t\t\t\tfor (j = 0; j < num_blks; j++) {\n\t\t\t\t\tmemcpy_fromio(dst, src, sizeof(*dst));\n\n\t\t\t\t\tdst++;\n\t\t\t\t\trd_idx = msgq_inc(qinfo, rd_idx, 1);\n\t\t\t\t\tsrc = msgq_blk_addr(qinfo, rd_idx);\n\t\t\t\t}\n\t\t\t\ttotal++;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tdev_crit(dev, \"Kernel mem allocation failure.\\n\");\n\t\t\t\ttotal = -ENOMEM;\n\t\t\t\tgoto idx_err;\n\t\t\t}\n\n\t\t\t \n\t\t\twritel(rd_idx, &msgq->rd_idx);\n\n\t\t\t \n\t\t\tdev_dbg(dev,\n\t\t\t\t\"MsgQ[%d] [Rd Wr] = [%d %d] blks extracted %d - Q = [u-%d a-%d]/%d\\n\",\n\t\t\t\treadl_relaxed(&msgq->num),\n\t\t\t\trd_idx,\n\t\t\t\twr_idx,\n\t\t\t\tnum_blks,\n\t\t\t\tmsgq_occupied(msgq, qinfo),\n\t\t\t\tmsgq_avail_space(msgq, qinfo),\n\t\t\t\treadl_relaxed(&msgq->size));\n\n\t\t\t \n\t\t\tif (data->function_id == VK_FID_SHUTDOWN) {\n\t\t\t\tkfree(data);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tmsg_id = get_msg_id(data);\n\t\t\t \n\t\t\tentry = bcm_vk_dequeue_pending(vk,\n\t\t\t\t\t\t       &vk->to_v_msg_chan,\n\t\t\t\t\t\t       q_num,\n\t\t\t\t\t\t       msg_id);\n\n\t\t\t \n\t\t\tif (entry) {\n\t\t\t\tentry->to_h_blks = num_blks;\n\t\t\t\tentry->to_h_msg = data;\n\t\t\t\tbcm_vk_append_pendq(&vk->to_h_msg_chan,\n\t\t\t\t\t\t    q_num, entry);\n\n\t\t\t} else {\n\t\t\t\tif (cnt++ < batch_log)\n\t\t\t\t\tdev_info(dev,\n\t\t\t\t\t\t \"Could not find MsgId[0x%x] for resp func %d bmap %d\\n\",\n\t\t\t\t\t\t msg_id, data->function_id,\n\t\t\t\t\t\t test_bit(msg_id, vk->bmap));\n\t\t\t\tkfree(data);\n\t\t\t}\n\t\t\t \n\t\t\twr_idx = readl(&msgq->wr_idx);\n\n\t\t\t \n\t\t\tif (++msg_processed >= max_msg_to_process) {\n\t\t\t\tdev_warn(dev, \"Q[%d] Per loop processing exceeds %d\\n\",\n\t\t\t\t\t q_num, max_msg_to_process);\n\t\t\t\texit_loop = true;\n\t\t\t}\n\t\t}\n\t}\nidx_err:\n\tmutex_unlock(&chan->msgq_mutex);\n\tdev_dbg(dev, \"total %d drained from queues\\n\", total);\n\n\treturn total;\n}\n\n \nstatic int bcm_vk_data_init(struct bcm_vk *vk)\n{\n\tint i;\n\n\tspin_lock_init(&vk->ctx_lock);\n\tfor (i = 0; i < ARRAY_SIZE(vk->ctx); i++) {\n\t\tvk->ctx[i].in_use = false;\n\t\tvk->ctx[i].idx = i;\t \n\t\tvk->ctx[i].miscdev = NULL;\n\t}\n\tspin_lock_init(&vk->msg_id_lock);\n\tspin_lock_init(&vk->host_alert_lock);\n\tvk->msg_id = 0;\n\n\t \n\tfor (i = 0; i < VK_PID_HT_SZ; i++)\n\t\tINIT_LIST_HEAD(&vk->pid_ht[i].head);\n\n\treturn 0;\n}\n\nirqreturn_t bcm_vk_msgq_irqhandler(int irq, void *dev_id)\n{\n\tstruct bcm_vk *vk = dev_id;\n\n\tif (!bcm_vk_drv_access_ok(vk)) {\n\t\tdev_err(&vk->pdev->dev,\n\t\t\t\"Interrupt %d received when msgq not inited\\n\", irq);\n\t\tgoto skip_schedule_work;\n\t}\n\n\tqueue_work(vk->wq_thread, &vk->wq_work);\n\nskip_schedule_work:\n\treturn IRQ_HANDLED;\n}\n\nint bcm_vk_open(struct inode *inode, struct file *p_file)\n{\n\tstruct bcm_vk_ctx *ctx;\n\tstruct miscdevice *miscdev = (struct miscdevice *)p_file->private_data;\n\tstruct bcm_vk *vk = container_of(miscdev, struct bcm_vk, miscdev);\n\tstruct device *dev = &vk->pdev->dev;\n\tint rc = 0;\n\n\t \n\tctx = bcm_vk_get_ctx(vk, task_tgid_nr(current));\n\tif (!ctx) {\n\t\tdev_err(dev, \"Error allocating context\\n\");\n\t\trc = -ENOMEM;\n\t} else {\n\t\t \n\t\tctx->miscdev = miscdev;\n\t\tp_file->private_data = ctx;\n\t\tdev_dbg(dev, \"ctx_returned with idx %d, pid %d\\n\",\n\t\t\tctx->idx, ctx->pid);\n\t}\n\treturn rc;\n}\n\nssize_t bcm_vk_read(struct file *p_file,\n\t\t    char __user *buf,\n\t\t    size_t count,\n\t\t    loff_t *f_pos)\n{\n\tssize_t rc = -ENOMSG;\n\tstruct bcm_vk_ctx *ctx = p_file->private_data;\n\tstruct bcm_vk *vk = container_of(ctx->miscdev, struct bcm_vk,\n\t\t\t\t\t miscdev);\n\tstruct device *dev = &vk->pdev->dev;\n\tstruct bcm_vk_msg_chan *chan = &vk->to_h_msg_chan;\n\tstruct bcm_vk_wkent *entry = NULL, *iter;\n\tu32 q_num;\n\tu32 rsp_length;\n\n\tif (!bcm_vk_drv_access_ok(vk))\n\t\treturn -EPERM;\n\n\tdev_dbg(dev, \"Buf count %zu\\n\", count);\n\n\t \n\tspin_lock(&chan->pendq_lock);\n\tfor (q_num = 0; q_num < chan->q_nr; q_num++) {\n\t\tlist_for_each_entry(iter, &chan->pendq[q_num], node) {\n\t\t\tif (iter->ctx->idx == ctx->idx) {\n\t\t\t\tif (count >=\n\t\t\t\t    (iter->to_h_blks * VK_MSGQ_BLK_SIZE)) {\n\t\t\t\t\tlist_del(&iter->node);\n\t\t\t\t\tatomic_dec(&ctx->pend_cnt);\n\t\t\t\t\tentry = iter;\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\trc = -EMSGSIZE;\n\t\t\t\t}\n\t\t\t\tgoto read_loop_exit;\n\t\t\t}\n\t\t}\n\t}\nread_loop_exit:\n\tspin_unlock(&chan->pendq_lock);\n\n\tif (entry) {\n\t\t \n\t\tset_msg_id(&entry->to_h_msg[0], entry->usr_msg_id);\n\t\trsp_length = entry->to_h_blks * VK_MSGQ_BLK_SIZE;\n\t\tif (copy_to_user(buf, entry->to_h_msg, rsp_length) == 0)\n\t\t\trc = rsp_length;\n\n\t\tbcm_vk_free_wkent(dev, entry);\n\t} else if (rc == -EMSGSIZE) {\n\t\tstruct vk_msg_blk tmp_msg = entry->to_h_msg[0];\n\n\t\t \n\t\tset_msg_id(&tmp_msg, entry->usr_msg_id);\n\t\ttmp_msg.size = entry->to_h_blks - 1;\n\t\tif (copy_to_user(buf, &tmp_msg, VK_MSGQ_BLK_SIZE) != 0) {\n\t\t\tdev_err(dev, \"Error return 1st block in -EMSGSIZE\\n\");\n\t\t\trc = -EFAULT;\n\t\t}\n\t}\n\treturn rc;\n}\n\nssize_t bcm_vk_write(struct file *p_file,\n\t\t     const char __user *buf,\n\t\t     size_t count,\n\t\t     loff_t *f_pos)\n{\n\tssize_t rc;\n\tstruct bcm_vk_ctx *ctx = p_file->private_data;\n\tstruct bcm_vk *vk = container_of(ctx->miscdev, struct bcm_vk,\n\t\t\t\t\t miscdev);\n\tstruct bcm_vk_msgq __iomem *msgq;\n\tstruct device *dev = &vk->pdev->dev;\n\tstruct bcm_vk_wkent *entry;\n\tu32 sgl_extra_blks;\n\tu32 q_num;\n\tu32 msg_size;\n\tu32 msgq_size;\n\n\tif (!bcm_vk_drv_access_ok(vk))\n\t\treturn -EPERM;\n\n\tdev_dbg(dev, \"Msg count %zu\\n\", count);\n\n\t \n\tif (count & (VK_MSGQ_BLK_SIZE - 1)) {\n\t\tdev_err(dev, \"Failure with size %zu not multiple of %zu\\n\",\n\t\t\tcount, VK_MSGQ_BLK_SIZE);\n\t\trc = -EINVAL;\n\t\tgoto write_err;\n\t}\n\n\t \n\tentry = kzalloc(sizeof(*entry) + count + vk->ib_sgl_size,\n\t\t\tGFP_KERNEL);\n\tif (!entry) {\n\t\trc = -ENOMEM;\n\t\tgoto write_err;\n\t}\n\n\t \n\tif (copy_from_user(&entry->to_v_msg[0], buf, count)) {\n\t\trc = -EFAULT;\n\t\tgoto write_free_ent;\n\t}\n\n\tentry->to_v_blks = count >> VK_MSGQ_BLK_SZ_SHIFT;\n\tentry->ctx = ctx;\n\n\t \n\tq_num = get_q_num(&entry->to_v_msg[0]);\n\tmsgq = vk->to_v_msg_chan.msgq[q_num];\n\tmsgq_size = readl_relaxed(&msgq->size);\n\tif (entry->to_v_blks + (vk->ib_sgl_size >> VK_MSGQ_BLK_SZ_SHIFT)\n\t    > (msgq_size - 1)) {\n\t\tdev_err(dev, \"Blk size %d exceed max queue size allowed %d\\n\",\n\t\t\tentry->to_v_blks, msgq_size - 1);\n\t\trc = -EINVAL;\n\t\tgoto write_free_ent;\n\t}\n\n\t \n\tentry->usr_msg_id = get_msg_id(&entry->to_v_msg[0]);\n\trc = bcm_vk_get_msg_id(vk);\n\tif (rc == VK_MSG_ID_OVERFLOW) {\n\t\tdev_err(dev, \"msg_id overflow\\n\");\n\t\trc = -EOVERFLOW;\n\t\tgoto write_free_ent;\n\t}\n\tset_msg_id(&entry->to_v_msg[0], rc);\n\tctx->q_num = q_num;\n\n\tdev_dbg(dev,\n\t\t\"[Q-%d]Message ctx id %d, usr_msg_id 0x%x sent msg_id 0x%x\\n\",\n\t\tctx->q_num, ctx->idx, entry->usr_msg_id,\n\t\tget_msg_id(&entry->to_v_msg[0]));\n\n\tif (entry->to_v_msg[0].function_id == VK_FID_TRANS_BUF) {\n\t\t \n\t\tunsigned int num_planes;\n\t\tint dir;\n\t\tstruct _vk_data *data;\n\n\t\t \n\t\tif (vk->reset_pid) {\n\t\t\tdev_dbg(dev, \"No Transfer allowed during reset, pid %d.\\n\",\n\t\t\t\tctx->pid);\n\t\t\trc = -EACCES;\n\t\t\tgoto write_free_msgid;\n\t\t}\n\n\t\tnum_planes = entry->to_v_msg[0].cmd & VK_CMD_PLANES_MASK;\n\t\tif ((entry->to_v_msg[0].cmd & VK_CMD_MASK) == VK_CMD_DOWNLOAD)\n\t\t\tdir = DMA_FROM_DEVICE;\n\t\telse\n\t\t\tdir = DMA_TO_DEVICE;\n\n\t\t \n\t\t \n\t\tmsg_size = entry->to_v_msg[0].size;\n\t\tif (msg_size > entry->to_v_blks) {\n\t\t\trc = -EMSGSIZE;\n\t\t\tgoto write_free_msgid;\n\t\t}\n\n\t\tdata = (struct _vk_data *)&entry->to_v_msg[msg_size + 1];\n\n\t\t \n\t\tdata -= num_planes;\n\n\t\t \n\t\trc = bcm_vk_sg_alloc(dev, entry->dma, dir, data, num_planes);\n\t\tif (rc)\n\t\t\tgoto write_free_msgid;\n\n\t\tatomic_inc(&ctx->dma_cnt);\n\t\t \n\t\tsgl_extra_blks = bcm_vk_append_ib_sgl(vk, entry, data,\n\t\t\t\t\t\t      num_planes);\n\t\tentry->to_v_blks += sgl_extra_blks;\n\t\tentry->to_v_msg[0].size += sgl_extra_blks;\n\t} else if (entry->to_v_msg[0].function_id == VK_FID_INIT &&\n\t\t   entry->to_v_msg[0].context_id == VK_NEW_CTX) {\n\t\t \n\t\tpid_t org_pid, pid;\n\n\t\t \n#define VK_MSG_PID_MASK 0xffffff00\n#define VK_MSG_PID_SH   8\n\t\torg_pid = (entry->to_v_msg[0].arg & VK_MSG_PID_MASK)\n\t\t\t   >> VK_MSG_PID_SH;\n\n\t\tpid = task_tgid_nr(current);\n\t\tentry->to_v_msg[0].arg =\n\t\t\t(entry->to_v_msg[0].arg & ~VK_MSG_PID_MASK) |\n\t\t\t(pid << VK_MSG_PID_SH);\n\t\tif (org_pid != pid)\n\t\t\tdev_dbg(dev, \"In PID 0x%x(%d), converted PID 0x%x(%d)\\n\",\n\t\t\t\torg_pid, org_pid, pid, pid);\n\t}\n\n\t \n\tbcm_vk_append_pendq(&vk->to_v_msg_chan, q_num, entry);\n\n\trc = bcm_to_v_msg_enqueue(vk, entry);\n\tif (rc) {\n\t\tdev_err(dev, \"Fail to enqueue msg to to_v queue\\n\");\n\n\t\t \n\t\tentry = bcm_vk_dequeue_pending\n\t\t\t       (vk,\n\t\t\t\t&vk->to_v_msg_chan,\n\t\t\t\tq_num,\n\t\t\t\tget_msg_id(&entry->to_v_msg[0]));\n\t\tgoto write_free_ent;\n\t}\n\n\treturn count;\n\nwrite_free_msgid:\n\tbcm_vk_msgid_bitmap_clear(vk, get_msg_id(&entry->to_v_msg[0]), 1);\nwrite_free_ent:\n\tkfree(entry);\nwrite_err:\n\treturn rc;\n}\n\n__poll_t bcm_vk_poll(struct file *p_file, struct poll_table_struct *wait)\n{\n\t__poll_t ret = 0;\n\tint cnt;\n\tstruct bcm_vk_ctx *ctx = p_file->private_data;\n\tstruct bcm_vk *vk = container_of(ctx->miscdev, struct bcm_vk, miscdev);\n\tstruct device *dev = &vk->pdev->dev;\n\n\tpoll_wait(p_file, &ctx->rd_wq, wait);\n\n\tcnt = atomic_read(&ctx->pend_cnt);\n\tif (cnt) {\n\t\tret = (__force __poll_t)(POLLIN | POLLRDNORM);\n\t\tif (cnt < 0) {\n\t\t\tdev_err(dev, \"Error cnt %d, setting back to 0\", cnt);\n\t\t\tatomic_set(&ctx->pend_cnt, 0);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nint bcm_vk_release(struct inode *inode, struct file *p_file)\n{\n\tint ret;\n\tstruct bcm_vk_ctx *ctx = p_file->private_data;\n\tstruct bcm_vk *vk = container_of(ctx->miscdev, struct bcm_vk, miscdev);\n\tstruct device *dev = &vk->pdev->dev;\n\tpid_t pid = ctx->pid;\n\tint dma_cnt;\n\tunsigned long timeout, start_time;\n\n\t \n\tstart_time = jiffies;\n\ttimeout = start_time + msecs_to_jiffies(BCM_VK_DMA_DRAIN_MAX_MS);\n\tdo {\n\t\tif (time_after(jiffies, timeout)) {\n\t\t\tdev_warn(dev, \"%d dma still pending for [fd-%d] pid %d\\n\",\n\t\t\t\t dma_cnt, ctx->idx, pid);\n\t\t\tbreak;\n\t\t}\n\t\tdma_cnt = atomic_read(&ctx->dma_cnt);\n\t\tcpu_relax();\n\t\tcond_resched();\n\t} while (dma_cnt);\n\tdev_dbg(dev, \"Draining for [fd-%d] pid %d - delay %d ms\\n\",\n\t\tctx->idx, pid, jiffies_to_msecs(jiffies - start_time));\n\n\tbcm_vk_drain_all_pend(&vk->pdev->dev, &vk->to_v_msg_chan, ctx);\n\tbcm_vk_drain_all_pend(&vk->pdev->dev, &vk->to_h_msg_chan, ctx);\n\n\tret = bcm_vk_free_ctx(vk, ctx);\n\tif (ret == 0)\n\t\tret = bcm_vk_handle_last_sess(vk, pid, ctx->q_num);\n\telse\n\t\tret = 0;\n\n\tkref_put(&vk->kref, bcm_vk_release_data);\n\n\treturn ret;\n}\n\nint bcm_vk_msg_init(struct bcm_vk *vk)\n{\n\tstruct device *dev = &vk->pdev->dev;\n\tint ret;\n\n\tif (bcm_vk_data_init(vk)) {\n\t\tdev_err(dev, \"Error initializing internal data structures\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (bcm_vk_msg_chan_init(&vk->to_v_msg_chan) ||\n\t    bcm_vk_msg_chan_init(&vk->to_h_msg_chan)) {\n\t\tdev_err(dev, \"Error initializing communication channel\\n\");\n\t\treturn -EIO;\n\t}\n\n\t \n\tret = bcm_vk_sync_msgq(vk, false);\n\tif (ret && (ret != -EAGAIN)) {\n\t\tdev_err(dev, \"Error reading comm msg Q info\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nvoid bcm_vk_msg_remove(struct bcm_vk *vk)\n{\n\tbcm_vk_blk_drv_access(vk);\n\n\t \n\tbcm_vk_drain_all_pend(&vk->pdev->dev, &vk->to_v_msg_chan, NULL);\n\tbcm_vk_drain_all_pend(&vk->pdev->dev, &vk->to_h_msg_chan, NULL);\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}