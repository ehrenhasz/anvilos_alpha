{
  "module_name": "vmw_balloon.c",
  "hash_id": "ce6bb91112af05b07fb0239fd597750260a78b34ccac9547424eeb7bfdd66725",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/vmw_balloon.c",
  "human_readable_source": "\n \n\n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/types.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched.h>\n#include <linux/module.h>\n#include <linux/workqueue.h>\n#include <linux/debugfs.h>\n#include <linux/seq_file.h>\n#include <linux/rwsem.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/balloon_compaction.h>\n#include <linux/vmw_vmci_defs.h>\n#include <linux/vmw_vmci_api.h>\n#include <asm/hypervisor.h>\n\nMODULE_AUTHOR(\"VMware, Inc.\");\nMODULE_DESCRIPTION(\"VMware Memory Control (Balloon) Driver\");\nMODULE_ALIAS(\"dmi:*:svnVMware*:*\");\nMODULE_ALIAS(\"vmware_vmmemctl\");\nMODULE_LICENSE(\"GPL\");\n\nstatic bool __read_mostly vmwballoon_shrinker_enable;\nmodule_param(vmwballoon_shrinker_enable, bool, 0444);\nMODULE_PARM_DESC(vmwballoon_shrinker_enable,\n\t\"Enable non-cooperative out-of-memory protection. Disabled by default as it may degrade performance.\");\n\n \n#define VMBALLOON_SHRINK_DELAY\t\t(5)\n\n \n#define VMW_BALLOON_MAX_REFUSED\t\t16\n\n \n#define BALLOON_VMW_MAGIC\t\t0x0ba11007\n\n \n#define VMW_BALLOON_HV_PORT\t\t0x5670\n#define VMW_BALLOON_HV_MAGIC\t\t0x456c6d6f\n#define VMW_BALLOON_GUEST_ID\t\t1\t \n\nenum vmwballoon_capabilities {\n\t \n\tVMW_BALLOON_BASIC_CMDS\t\t\t= (1 << 1),\n\tVMW_BALLOON_BATCHED_CMDS\t\t= (1 << 2),\n\tVMW_BALLOON_BATCHED_2M_CMDS\t\t= (1 << 3),\n\tVMW_BALLOON_SIGNALLED_WAKEUP_CMD\t= (1 << 4),\n\tVMW_BALLOON_64_BIT_TARGET\t\t= (1 << 5)\n};\n\n#define VMW_BALLOON_CAPABILITIES_COMMON\t(VMW_BALLOON_BASIC_CMDS \\\n\t\t\t\t\t| VMW_BALLOON_BATCHED_CMDS \\\n\t\t\t\t\t| VMW_BALLOON_BATCHED_2M_CMDS \\\n\t\t\t\t\t| VMW_BALLOON_SIGNALLED_WAKEUP_CMD)\n\n#define VMW_BALLOON_2M_ORDER\t\t(PMD_SHIFT - PAGE_SHIFT)\n\n \n#ifdef CONFIG_64BIT\n#define VMW_BALLOON_CAPABILITIES\t(VMW_BALLOON_CAPABILITIES_COMMON \\\n\t\t\t\t\t| VMW_BALLOON_64_BIT_TARGET)\n#else\n#define VMW_BALLOON_CAPABILITIES\tVMW_BALLOON_CAPABILITIES_COMMON\n#endif\n\nenum vmballoon_page_size_type {\n\tVMW_BALLOON_4K_PAGE,\n\tVMW_BALLOON_2M_PAGE,\n\tVMW_BALLOON_LAST_SIZE = VMW_BALLOON_2M_PAGE\n};\n\n#define VMW_BALLOON_NUM_PAGE_SIZES\t(VMW_BALLOON_LAST_SIZE + 1)\n\nstatic const char * const vmballoon_page_size_names[] = {\n\t[VMW_BALLOON_4K_PAGE]\t\t\t= \"4k\",\n\t[VMW_BALLOON_2M_PAGE]\t\t\t= \"2M\"\n};\n\nenum vmballoon_op {\n\tVMW_BALLOON_INFLATE,\n\tVMW_BALLOON_DEFLATE\n};\n\nenum vmballoon_op_stat_type {\n\tVMW_BALLOON_OP_STAT,\n\tVMW_BALLOON_OP_FAIL_STAT\n};\n\n#define VMW_BALLOON_OP_STAT_TYPES\t(VMW_BALLOON_OP_FAIL_STAT + 1)\n\n \nenum vmballoon_cmd_type {\n\tVMW_BALLOON_CMD_START,\n\tVMW_BALLOON_CMD_GET_TARGET,\n\tVMW_BALLOON_CMD_LOCK,\n\tVMW_BALLOON_CMD_UNLOCK,\n\tVMW_BALLOON_CMD_GUEST_ID,\n\t \n\tVMW_BALLOON_CMD_BATCHED_LOCK = 6,\n\tVMW_BALLOON_CMD_BATCHED_UNLOCK,\n\tVMW_BALLOON_CMD_BATCHED_2M_LOCK,\n\tVMW_BALLOON_CMD_BATCHED_2M_UNLOCK,\n\tVMW_BALLOON_CMD_VMCI_DOORBELL_SET,\n\tVMW_BALLOON_CMD_LAST = VMW_BALLOON_CMD_VMCI_DOORBELL_SET,\n};\n\n#define VMW_BALLOON_CMD_NUM\t(VMW_BALLOON_CMD_LAST + 1)\n\nenum vmballoon_error_codes {\n\tVMW_BALLOON_SUCCESS,\n\tVMW_BALLOON_ERROR_CMD_INVALID,\n\tVMW_BALLOON_ERROR_PPN_INVALID,\n\tVMW_BALLOON_ERROR_PPN_LOCKED,\n\tVMW_BALLOON_ERROR_PPN_UNLOCKED,\n\tVMW_BALLOON_ERROR_PPN_PINNED,\n\tVMW_BALLOON_ERROR_PPN_NOTNEEDED,\n\tVMW_BALLOON_ERROR_RESET,\n\tVMW_BALLOON_ERROR_BUSY\n};\n\n#define VMW_BALLOON_SUCCESS_WITH_CAPABILITIES\t(0x03000000)\n\n#define VMW_BALLOON_CMD_WITH_TARGET_MASK\t\t\t\\\n\t((1UL << VMW_BALLOON_CMD_GET_TARGET)\t\t|\t\\\n\t (1UL << VMW_BALLOON_CMD_LOCK)\t\t\t|\t\\\n\t (1UL << VMW_BALLOON_CMD_UNLOCK)\t\t|\t\\\n\t (1UL << VMW_BALLOON_CMD_BATCHED_LOCK)\t\t|\t\\\n\t (1UL << VMW_BALLOON_CMD_BATCHED_UNLOCK)\t|\t\\\n\t (1UL << VMW_BALLOON_CMD_BATCHED_2M_LOCK)\t|\t\\\n\t (1UL << VMW_BALLOON_CMD_BATCHED_2M_UNLOCK))\n\nstatic const char * const vmballoon_cmd_names[] = {\n\t[VMW_BALLOON_CMD_START]\t\t\t= \"start\",\n\t[VMW_BALLOON_CMD_GET_TARGET]\t\t= \"target\",\n\t[VMW_BALLOON_CMD_LOCK]\t\t\t= \"lock\",\n\t[VMW_BALLOON_CMD_UNLOCK]\t\t= \"unlock\",\n\t[VMW_BALLOON_CMD_GUEST_ID]\t\t= \"guestType\",\n\t[VMW_BALLOON_CMD_BATCHED_LOCK]\t\t= \"batchLock\",\n\t[VMW_BALLOON_CMD_BATCHED_UNLOCK]\t= \"batchUnlock\",\n\t[VMW_BALLOON_CMD_BATCHED_2M_LOCK]\t= \"2m-lock\",\n\t[VMW_BALLOON_CMD_BATCHED_2M_UNLOCK]\t= \"2m-unlock\",\n\t[VMW_BALLOON_CMD_VMCI_DOORBELL_SET]\t= \"doorbellSet\"\n};\n\nenum vmballoon_stat_page {\n\tVMW_BALLOON_PAGE_STAT_ALLOC,\n\tVMW_BALLOON_PAGE_STAT_ALLOC_FAIL,\n\tVMW_BALLOON_PAGE_STAT_REFUSED_ALLOC,\n\tVMW_BALLOON_PAGE_STAT_REFUSED_FREE,\n\tVMW_BALLOON_PAGE_STAT_FREE,\n\tVMW_BALLOON_PAGE_STAT_LAST = VMW_BALLOON_PAGE_STAT_FREE\n};\n\n#define VMW_BALLOON_PAGE_STAT_NUM\t(VMW_BALLOON_PAGE_STAT_LAST + 1)\n\nenum vmballoon_stat_general {\n\tVMW_BALLOON_STAT_TIMER,\n\tVMW_BALLOON_STAT_DOORBELL,\n\tVMW_BALLOON_STAT_RESET,\n\tVMW_BALLOON_STAT_SHRINK,\n\tVMW_BALLOON_STAT_SHRINK_FREE,\n\tVMW_BALLOON_STAT_LAST = VMW_BALLOON_STAT_SHRINK_FREE\n};\n\n#define VMW_BALLOON_STAT_NUM\t\t(VMW_BALLOON_STAT_LAST + 1)\n\nstatic DEFINE_STATIC_KEY_TRUE(vmw_balloon_batching);\nstatic DEFINE_STATIC_KEY_FALSE(balloon_stat_enabled);\n\nstruct vmballoon_ctl {\n\tstruct list_head pages;\n\tstruct list_head refused_pages;\n\tstruct list_head prealloc_pages;\n\tunsigned int n_refused_pages;\n\tunsigned int n_pages;\n\tenum vmballoon_page_size_type page_size;\n\tenum vmballoon_op op;\n};\n\n \nstruct vmballoon_batch_entry {\n\tu64 status : 5;\n\tu64 reserved : PAGE_SHIFT - 5;\n\tu64 pfn : 52;\n} __packed;\n\nstruct vmballoon {\n\t \n\tenum vmballoon_page_size_type max_page_size;\n\n\t \n\tatomic64_t size;\n\n\t \n\tunsigned long target;\n\n\t \n\tbool reset_required;\n\n\t \n\tunsigned long capabilities;\n\n\t \n\tstruct vmballoon_batch_entry *batch_page;\n\n\t \n\tunsigned int batch_max_pages;\n\n\t \n\tstruct page *page;\n\n\t \n\tunsigned long shrink_timeout;\n\n\t \n\tstruct vmballoon_stats *stats;\n\n\t \n\tstruct balloon_dev_info b_dev_info;\n\n\tstruct delayed_work dwork;\n\n\t \n\tstruct list_head huge_pages;\n\n\t \n\tstruct vmci_handle vmci_doorbell;\n\n\t \n\tstruct rw_semaphore conf_sem;\n\n\t \n\tspinlock_t comm_lock;\n\n\t \n\tstruct shrinker shrinker;\n\n\t \n\tbool shrinker_registered;\n};\n\nstatic struct vmballoon balloon;\n\nstruct vmballoon_stats {\n\t \n\tatomic64_t general_stat[VMW_BALLOON_STAT_NUM];\n\n\t \n\tatomic64_t\n\t       page_stat[VMW_BALLOON_PAGE_STAT_NUM][VMW_BALLOON_NUM_PAGE_SIZES];\n\n\t \n\tatomic64_t ops[VMW_BALLOON_CMD_NUM][VMW_BALLOON_OP_STAT_TYPES];\n};\n\nstatic inline bool is_vmballoon_stats_on(void)\n{\n\treturn IS_ENABLED(CONFIG_DEBUG_FS) &&\n\t\tstatic_branch_unlikely(&balloon_stat_enabled);\n}\n\nstatic inline void vmballoon_stats_op_inc(struct vmballoon *b, unsigned int op,\n\t\t\t\t\t  enum vmballoon_op_stat_type type)\n{\n\tif (is_vmballoon_stats_on())\n\t\tatomic64_inc(&b->stats->ops[op][type]);\n}\n\nstatic inline void vmballoon_stats_gen_inc(struct vmballoon *b,\n\t\t\t\t\t   enum vmballoon_stat_general stat)\n{\n\tif (is_vmballoon_stats_on())\n\t\tatomic64_inc(&b->stats->general_stat[stat]);\n}\n\nstatic inline void vmballoon_stats_gen_add(struct vmballoon *b,\n\t\t\t\t\t   enum vmballoon_stat_general stat,\n\t\t\t\t\t   unsigned int val)\n{\n\tif (is_vmballoon_stats_on())\n\t\tatomic64_add(val, &b->stats->general_stat[stat]);\n}\n\nstatic inline void vmballoon_stats_page_inc(struct vmballoon *b,\n\t\t\t\t\t    enum vmballoon_stat_page stat,\n\t\t\t\t\t    enum vmballoon_page_size_type size)\n{\n\tif (is_vmballoon_stats_on())\n\t\tatomic64_inc(&b->stats->page_stat[stat][size]);\n}\n\nstatic inline void vmballoon_stats_page_add(struct vmballoon *b,\n\t\t\t\t\t    enum vmballoon_stat_page stat,\n\t\t\t\t\t    enum vmballoon_page_size_type size,\n\t\t\t\t\t    unsigned int val)\n{\n\tif (is_vmballoon_stats_on())\n\t\tatomic64_add(val, &b->stats->page_stat[stat][size]);\n}\n\nstatic inline unsigned long\n__vmballoon_cmd(struct vmballoon *b, unsigned long cmd, unsigned long arg1,\n\t\tunsigned long arg2, unsigned long *result)\n{\n\tunsigned long status, dummy1, dummy2, dummy3, local_result;\n\n\tvmballoon_stats_op_inc(b, cmd, VMW_BALLOON_OP_STAT);\n\n\tasm volatile (\"inl %%dx\" :\n\t\t\"=a\"(status),\n\t\t\"=c\"(dummy1),\n\t\t\"=d\"(dummy2),\n\t\t\"=b\"(local_result),\n\t\t\"=S\"(dummy3) :\n\t\t\"0\"(VMW_BALLOON_HV_MAGIC),\n\t\t\"1\"(cmd),\n\t\t\"2\"(VMW_BALLOON_HV_PORT),\n\t\t\"3\"(arg1),\n\t\t\"4\"(arg2) :\n\t\t\"memory\");\n\n\t \n\tif (result)\n\t\t*result = (cmd == VMW_BALLOON_CMD_START) ? dummy1 :\n\t\t\t\t\t\t\t   local_result;\n\n\t \n\tif (status == VMW_BALLOON_SUCCESS &&\n\t    ((1ul << cmd) & VMW_BALLOON_CMD_WITH_TARGET_MASK))\n\t\tWRITE_ONCE(b->target, local_result);\n\n\tif (status != VMW_BALLOON_SUCCESS &&\n\t    status != VMW_BALLOON_SUCCESS_WITH_CAPABILITIES) {\n\t\tvmballoon_stats_op_inc(b, cmd, VMW_BALLOON_OP_FAIL_STAT);\n\t\tpr_debug(\"%s: %s [0x%lx,0x%lx) failed, returned %ld\\n\",\n\t\t\t __func__, vmballoon_cmd_names[cmd], arg1, arg2,\n\t\t\t status);\n\t}\n\n\t \n\tif (status == VMW_BALLOON_ERROR_RESET)\n\t\tb->reset_required = true;\n\n\treturn status;\n}\n\nstatic __always_inline unsigned long\nvmballoon_cmd(struct vmballoon *b, unsigned long cmd, unsigned long arg1,\n\t      unsigned long arg2)\n{\n\tunsigned long dummy;\n\n\treturn __vmballoon_cmd(b, cmd, arg1, arg2, &dummy);\n}\n\n \nstatic int vmballoon_send_start(struct vmballoon *b, unsigned long req_caps)\n{\n\tunsigned long status, capabilities;\n\n\tstatus = __vmballoon_cmd(b, VMW_BALLOON_CMD_START, req_caps, 0,\n\t\t\t\t &capabilities);\n\n\tswitch (status) {\n\tcase VMW_BALLOON_SUCCESS_WITH_CAPABILITIES:\n\t\tb->capabilities = capabilities;\n\t\tbreak;\n\tcase VMW_BALLOON_SUCCESS:\n\t\tb->capabilities = VMW_BALLOON_BASIC_CMDS;\n\t\tbreak;\n\tdefault:\n\t\treturn -EIO;\n\t}\n\n\t \n\tb->max_page_size = VMW_BALLOON_4K_PAGE;\n\tif ((b->capabilities & VMW_BALLOON_BATCHED_2M_CMDS) &&\n\t    (b->capabilities & VMW_BALLOON_BATCHED_CMDS))\n\t\tb->max_page_size = VMW_BALLOON_2M_PAGE;\n\n\n\treturn 0;\n}\n\n \nstatic int vmballoon_send_guest_id(struct vmballoon *b)\n{\n\tunsigned long status;\n\n\tstatus = vmballoon_cmd(b, VMW_BALLOON_CMD_GUEST_ID,\n\t\t\t       VMW_BALLOON_GUEST_ID, 0);\n\n\treturn status == VMW_BALLOON_SUCCESS ? 0 : -EIO;\n}\n\n \nstatic inline\nunsigned int vmballoon_page_order(enum vmballoon_page_size_type page_size)\n{\n\treturn page_size == VMW_BALLOON_2M_PAGE ? VMW_BALLOON_2M_ORDER : 0;\n}\n\n \nstatic inline unsigned int\nvmballoon_page_in_frames(enum vmballoon_page_size_type page_size)\n{\n\treturn 1 << vmballoon_page_order(page_size);\n}\n\n \nstatic void\nvmballoon_mark_page_offline(struct page *page,\n\t\t\t    enum vmballoon_page_size_type page_size)\n{\n\tint i;\n\n\tfor (i = 0; i < vmballoon_page_in_frames(page_size); i++)\n\t\t__SetPageOffline(page + i);\n}\n\n \nstatic void\nvmballoon_mark_page_online(struct page *page,\n\t\t\t   enum vmballoon_page_size_type page_size)\n{\n\tint i;\n\n\tfor (i = 0; i < vmballoon_page_in_frames(page_size); i++)\n\t\t__ClearPageOffline(page + i);\n}\n\n \nstatic int vmballoon_send_get_target(struct vmballoon *b)\n{\n\tunsigned long status;\n\tunsigned long limit;\n\n\tlimit = totalram_pages();\n\n\t \n\tif (!(b->capabilities & VMW_BALLOON_64_BIT_TARGET) &&\n\t    limit != (u32)limit)\n\t\treturn -EINVAL;\n\n\tstatus = vmballoon_cmd(b, VMW_BALLOON_CMD_GET_TARGET, limit, 0);\n\n\treturn status == VMW_BALLOON_SUCCESS ? 0 : -EIO;\n}\n\n \nstatic int vmballoon_alloc_page_list(struct vmballoon *b,\n\t\t\t\t     struct vmballoon_ctl *ctl,\n\t\t\t\t     unsigned int req_n_pages)\n{\n\tstruct page *page;\n\tunsigned int i;\n\n\tfor (i = 0; i < req_n_pages; i++) {\n\t\t \n\t\tif (!list_empty(&ctl->prealloc_pages)) {\n\t\t\tpage = list_first_entry(&ctl->prealloc_pages,\n\t\t\t\t\t\tstruct page, lru);\n\t\t\tlist_del(&page->lru);\n\t\t} else {\n\t\t\tif (ctl->page_size == VMW_BALLOON_2M_PAGE)\n\t\t\t\tpage = alloc_pages(__GFP_HIGHMEM|__GFP_NOWARN|\n\t\t\t\t\t__GFP_NOMEMALLOC, VMW_BALLOON_2M_ORDER);\n\t\t\telse\n\t\t\t\tpage = balloon_page_alloc();\n\n\t\t\tvmballoon_stats_page_inc(b, VMW_BALLOON_PAGE_STAT_ALLOC,\n\t\t\t\t\t\t ctl->page_size);\n\t\t}\n\n\t\tif (page) {\n\t\t\t \n\t\t\tlist_add(&page->lru, &ctl->pages);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tvmballoon_stats_page_inc(b, VMW_BALLOON_PAGE_STAT_ALLOC_FAIL,\n\t\t\t\t\t ctl->page_size);\n\t\tbreak;\n\t}\n\n\tctl->n_pages = i;\n\n\treturn req_n_pages == ctl->n_pages ? 0 : -ENOMEM;\n}\n\n \nstatic int vmballoon_handle_one_result(struct vmballoon *b, struct page *page,\n\t\t\t\t       enum vmballoon_page_size_type page_size,\n\t\t\t\t       unsigned long status)\n{\n\t \n\tif (likely(status == VMW_BALLOON_SUCCESS))\n\t\treturn 0;\n\n\tpr_debug(\"%s: failed comm pfn %lx status %lu page_size %s\\n\", __func__,\n\t\t page_to_pfn(page), status,\n\t\t vmballoon_page_size_names[page_size]);\n\n\t \n\tvmballoon_stats_page_inc(b, VMW_BALLOON_PAGE_STAT_REFUSED_ALLOC,\n\t\t\t\t page_size);\n\n\treturn -EIO;\n}\n\n \nstatic unsigned long vmballoon_status_page(struct vmballoon *b, int idx,\n\t\t\t\t\t   struct page **p)\n{\n\tif (static_branch_likely(&vmw_balloon_batching)) {\n\t\t \n\t\t*p = pfn_to_page(b->batch_page[idx].pfn);\n\t\treturn b->batch_page[idx].status;\n\t}\n\n\t \n\t*p = b->page;\n\n\t \n\treturn VMW_BALLOON_SUCCESS;\n}\n\n \nstatic unsigned long vmballoon_lock_op(struct vmballoon *b,\n\t\t\t\t       unsigned int num_pages,\n\t\t\t\t       enum vmballoon_page_size_type page_size,\n\t\t\t\t       enum vmballoon_op op)\n{\n\tunsigned long cmd, pfn;\n\n\tlockdep_assert_held(&b->comm_lock);\n\n\tif (static_branch_likely(&vmw_balloon_batching)) {\n\t\tif (op == VMW_BALLOON_INFLATE)\n\t\t\tcmd = page_size == VMW_BALLOON_2M_PAGE ?\n\t\t\t\tVMW_BALLOON_CMD_BATCHED_2M_LOCK :\n\t\t\t\tVMW_BALLOON_CMD_BATCHED_LOCK;\n\t\telse\n\t\t\tcmd = page_size == VMW_BALLOON_2M_PAGE ?\n\t\t\t\tVMW_BALLOON_CMD_BATCHED_2M_UNLOCK :\n\t\t\t\tVMW_BALLOON_CMD_BATCHED_UNLOCK;\n\n\t\tpfn = PHYS_PFN(virt_to_phys(b->batch_page));\n\t} else {\n\t\tcmd = op == VMW_BALLOON_INFLATE ? VMW_BALLOON_CMD_LOCK :\n\t\t\t\t\t\t  VMW_BALLOON_CMD_UNLOCK;\n\t\tpfn = page_to_pfn(b->page);\n\n\t\t \n\t\tif (unlikely(pfn != (u32)pfn))\n\t\t\treturn VMW_BALLOON_ERROR_PPN_INVALID;\n\t}\n\n\treturn vmballoon_cmd(b, cmd, pfn, num_pages);\n}\n\n \nstatic void vmballoon_add_page(struct vmballoon *b, unsigned int idx,\n\t\t\t       struct page *p)\n{\n\tlockdep_assert_held(&b->comm_lock);\n\n\tif (static_branch_likely(&vmw_balloon_batching))\n\t\tb->batch_page[idx] = (struct vmballoon_batch_entry)\n\t\t\t\t\t{ .pfn = page_to_pfn(p) };\n\telse\n\t\tb->page = p;\n}\n\n \nstatic int vmballoon_lock(struct vmballoon *b, struct vmballoon_ctl *ctl)\n{\n\tunsigned long batch_status;\n\tstruct page *page;\n\tunsigned int i, num_pages;\n\n\tnum_pages = ctl->n_pages;\n\tif (num_pages == 0)\n\t\treturn 0;\n\n\t \n\tspin_lock(&b->comm_lock);\n\n\ti = 0;\n\tlist_for_each_entry(page, &ctl->pages, lru)\n\t\tvmballoon_add_page(b, i++, page);\n\n\tbatch_status = vmballoon_lock_op(b, ctl->n_pages, ctl->page_size,\n\t\t\t\t\t ctl->op);\n\n\t \n\tfor (i = 0; i < num_pages; i++) {\n\t\tunsigned long status;\n\n\t\tstatus = vmballoon_status_page(b, i, &page);\n\n\t\t \n\t\tif (batch_status != VMW_BALLOON_SUCCESS)\n\t\t\tstatus = batch_status;\n\n\t\t \n\t\tif (!vmballoon_handle_one_result(b, page, ctl->page_size,\n\t\t\t\t\t\t status))\n\t\t\tcontinue;\n\n\t\t \n\t\tlist_move(&page->lru, &ctl->refused_pages);\n\t\tctl->n_pages--;\n\t\tctl->n_refused_pages++;\n\t}\n\n\tspin_unlock(&b->comm_lock);\n\n\treturn batch_status == VMW_BALLOON_SUCCESS ? 0 : -EIO;\n}\n\n \nstatic void vmballoon_release_page_list(struct list_head *page_list,\n\t\t\t\t       int *n_pages,\n\t\t\t\t       enum vmballoon_page_size_type page_size)\n{\n\tstruct page *page, *tmp;\n\n\tlist_for_each_entry_safe(page, tmp, page_list, lru) {\n\t\tlist_del(&page->lru);\n\t\t__free_pages(page, vmballoon_page_order(page_size));\n\t}\n\n\tif (n_pages)\n\t\t*n_pages = 0;\n}\n\n\n \nstatic void vmballoon_release_refused_pages(struct vmballoon *b,\n\t\t\t\t\t    struct vmballoon_ctl *ctl)\n{\n\tvmballoon_stats_page_inc(b, VMW_BALLOON_PAGE_STAT_REFUSED_FREE,\n\t\t\t\t ctl->page_size);\n\n\tvmballoon_release_page_list(&ctl->refused_pages, &ctl->n_refused_pages,\n\t\t\t\t    ctl->page_size);\n}\n\n \nstatic int64_t vmballoon_change(struct vmballoon *b)\n{\n\tint64_t size, target;\n\n\tsize = atomic64_read(&b->size);\n\ttarget = READ_ONCE(b->target);\n\n\t \n\n\tif (b->reset_required)\n\t\treturn 0;\n\n\t \n\tif (target < size && target != 0 &&\n\t    size - target < vmballoon_page_in_frames(VMW_BALLOON_2M_PAGE))\n\t\treturn 0;\n\n\t \n\tif (target > size && time_before(jiffies, READ_ONCE(b->shrink_timeout)))\n\t\treturn 0;\n\n\treturn target - size;\n}\n\n \nstatic void vmballoon_enqueue_page_list(struct vmballoon *b,\n\t\t\t\t\tstruct list_head *pages,\n\t\t\t\t\tunsigned int *n_pages,\n\t\t\t\t\tenum vmballoon_page_size_type page_size)\n{\n\tunsigned long flags;\n\tstruct page *page;\n\n\tif (page_size == VMW_BALLOON_4K_PAGE) {\n\t\tballoon_page_list_enqueue(&b->b_dev_info, pages);\n\t} else {\n\t\t \n\t\tspin_lock_irqsave(&b->b_dev_info.pages_lock, flags);\n\n\t\tlist_for_each_entry(page, pages, lru) {\n\t\t\tvmballoon_mark_page_offline(page, VMW_BALLOON_2M_PAGE);\n\t\t}\n\n\t\tlist_splice_init(pages, &b->huge_pages);\n\t\t__count_vm_events(BALLOON_INFLATE, *n_pages *\n\t\t\t\t  vmballoon_page_in_frames(VMW_BALLOON_2M_PAGE));\n\t\tspin_unlock_irqrestore(&b->b_dev_info.pages_lock, flags);\n\t}\n\n\t*n_pages = 0;\n}\n\n \nstatic void vmballoon_dequeue_page_list(struct vmballoon *b,\n\t\t\t\t\tstruct list_head *pages,\n\t\t\t\t\tunsigned int *n_pages,\n\t\t\t\t\tenum vmballoon_page_size_type page_size,\n\t\t\t\t\tunsigned int n_req_pages)\n{\n\tstruct page *page, *tmp;\n\tunsigned int i = 0;\n\tunsigned long flags;\n\n\t \n\tif (page_size == VMW_BALLOON_4K_PAGE) {\n\t\t*n_pages = balloon_page_list_dequeue(&b->b_dev_info, pages,\n\t\t\t\t\t\t     n_req_pages);\n\t\treturn;\n\t}\n\n\t \n\tspin_lock_irqsave(&b->b_dev_info.pages_lock, flags);\n\tlist_for_each_entry_safe(page, tmp, &b->huge_pages, lru) {\n\t\tvmballoon_mark_page_online(page, VMW_BALLOON_2M_PAGE);\n\n\t\tlist_move(&page->lru, pages);\n\t\tif (++i == n_req_pages)\n\t\t\tbreak;\n\t}\n\n\t__count_vm_events(BALLOON_DEFLATE,\n\t\t\t  i * vmballoon_page_in_frames(VMW_BALLOON_2M_PAGE));\n\tspin_unlock_irqrestore(&b->b_dev_info.pages_lock, flags);\n\t*n_pages = i;\n}\n\n \nstatic void vmballoon_split_refused_pages(struct vmballoon_ctl *ctl)\n{\n\tstruct page *page, *tmp;\n\tunsigned int i, order;\n\n\torder = vmballoon_page_order(ctl->page_size);\n\n\tlist_for_each_entry_safe(page, tmp, &ctl->refused_pages, lru) {\n\t\tlist_del(&page->lru);\n\t\tsplit_page(page, order);\n\t\tfor (i = 0; i < (1 << order); i++)\n\t\t\tlist_add(&page[i].lru, &ctl->prealloc_pages);\n\t}\n\tctl->n_refused_pages = 0;\n}\n\n \nstatic void vmballoon_inflate(struct vmballoon *b)\n{\n\tint64_t to_inflate_frames;\n\tstruct vmballoon_ctl ctl = {\n\t\t.pages = LIST_HEAD_INIT(ctl.pages),\n\t\t.refused_pages = LIST_HEAD_INIT(ctl.refused_pages),\n\t\t.prealloc_pages = LIST_HEAD_INIT(ctl.prealloc_pages),\n\t\t.page_size = b->max_page_size,\n\t\t.op = VMW_BALLOON_INFLATE\n\t};\n\n\twhile ((to_inflate_frames = vmballoon_change(b)) > 0) {\n\t\tunsigned int to_inflate_pages, page_in_frames;\n\t\tint alloc_error, lock_error = 0;\n\n\t\tVM_BUG_ON(!list_empty(&ctl.pages));\n\t\tVM_BUG_ON(ctl.n_pages != 0);\n\n\t\tpage_in_frames = vmballoon_page_in_frames(ctl.page_size);\n\n\t\tto_inflate_pages = min_t(unsigned long, b->batch_max_pages,\n\t\t\t\t\t DIV_ROUND_UP_ULL(to_inflate_frames,\n\t\t\t\t\t\t\t  page_in_frames));\n\n\t\t \n\t\talloc_error = vmballoon_alloc_page_list(b, &ctl,\n\t\t\t\t\t\t\tto_inflate_pages);\n\n\t\t \n\t\tlock_error = vmballoon_lock(b, &ctl);\n\n\t\t \n\t\tif (lock_error)\n\t\t\tbreak;\n\n\t\t \n\t\tatomic64_add(ctl.n_pages * page_in_frames, &b->size);\n\n\t\tvmballoon_enqueue_page_list(b, &ctl.pages, &ctl.n_pages,\n\t\t\t\t\t    ctl.page_size);\n\n\t\t \n\t\tif (alloc_error ||\n\t\t    ctl.n_refused_pages >= VMW_BALLOON_MAX_REFUSED) {\n\t\t\tif (ctl.page_size == VMW_BALLOON_4K_PAGE)\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\tvmballoon_split_refused_pages(&ctl);\n\t\t\tctl.page_size--;\n\t\t}\n\n\t\tcond_resched();\n\t}\n\n\t \n\tif (ctl.n_refused_pages != 0)\n\t\tvmballoon_release_refused_pages(b, &ctl);\n\n\tvmballoon_release_page_list(&ctl.prealloc_pages, NULL, ctl.page_size);\n}\n\n \nstatic unsigned long vmballoon_deflate(struct vmballoon *b, uint64_t n_frames,\n\t\t\t\t       bool coordinated)\n{\n\tunsigned long deflated_frames = 0;\n\tunsigned long tried_frames = 0;\n\tstruct vmballoon_ctl ctl = {\n\t\t.pages = LIST_HEAD_INIT(ctl.pages),\n\t\t.refused_pages = LIST_HEAD_INIT(ctl.refused_pages),\n\t\t.page_size = VMW_BALLOON_4K_PAGE,\n\t\t.op = VMW_BALLOON_DEFLATE\n\t};\n\n\t \n\twhile (true) {\n\t\tunsigned int to_deflate_pages, n_unlocked_frames;\n\t\tunsigned int page_in_frames;\n\t\tint64_t to_deflate_frames;\n\t\tbool deflated_all;\n\n\t\tpage_in_frames = vmballoon_page_in_frames(ctl.page_size);\n\n\t\tVM_BUG_ON(!list_empty(&ctl.pages));\n\t\tVM_BUG_ON(ctl.n_pages);\n\t\tVM_BUG_ON(!list_empty(&ctl.refused_pages));\n\t\tVM_BUG_ON(ctl.n_refused_pages);\n\n\t\t \n\t\tto_deflate_frames = n_frames ? n_frames - tried_frames :\n\t\t\t\t\t       -vmballoon_change(b);\n\n\t\t \n\t\tif (to_deflate_frames <= 0)\n\t\t\tbreak;\n\n\t\t \n\t\tto_deflate_pages = min_t(unsigned long, b->batch_max_pages,\n\t\t\t\t\t DIV_ROUND_UP_ULL(to_deflate_frames,\n\t\t\t\t\t\t\t  page_in_frames));\n\n\t\t \n\t\tvmballoon_dequeue_page_list(b, &ctl.pages, &ctl.n_pages,\n\t\t\t\t\t    ctl.page_size, to_deflate_pages);\n\n\t\t \n\t\ttried_frames += ctl.n_pages * page_in_frames;\n\n\t\t \n\t\tif (coordinated)\n\t\t\tvmballoon_lock(b, &ctl);\n\n\t\t \n\t\tdeflated_all = (ctl.n_pages == to_deflate_pages);\n\n\t\t \n\t\tn_unlocked_frames = ctl.n_pages * page_in_frames;\n\t\tatomic64_sub(n_unlocked_frames, &b->size);\n\t\tdeflated_frames += n_unlocked_frames;\n\n\t\tvmballoon_stats_page_add(b, VMW_BALLOON_PAGE_STAT_FREE,\n\t\t\t\t\t ctl.page_size, ctl.n_pages);\n\n\t\t \n\t\tvmballoon_release_page_list(&ctl.pages, &ctl.n_pages,\n\t\t\t\t\t    ctl.page_size);\n\n\t\t \n\t\tvmballoon_enqueue_page_list(b, &ctl.refused_pages,\n\t\t\t\t\t    &ctl.n_refused_pages,\n\t\t\t\t\t    ctl.page_size);\n\n\t\t \n\t\tif (!deflated_all) {\n\t\t\tif (ctl.page_size == b->max_page_size)\n\t\t\t\tbreak;\n\t\t\tctl.page_size++;\n\t\t}\n\n\t\tcond_resched();\n\t}\n\n\treturn deflated_frames;\n}\n\n \nstatic void vmballoon_deinit_batching(struct vmballoon *b)\n{\n\tfree_page((unsigned long)b->batch_page);\n\tb->batch_page = NULL;\n\tstatic_branch_disable(&vmw_balloon_batching);\n\tb->batch_max_pages = 1;\n}\n\n \nstatic int vmballoon_init_batching(struct vmballoon *b)\n{\n\tstruct page *page;\n\n\tpage = alloc_page(GFP_KERNEL | __GFP_ZERO);\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\tb->batch_page = page_address(page);\n\tb->batch_max_pages = PAGE_SIZE / sizeof(struct vmballoon_batch_entry);\n\n\tstatic_branch_enable(&vmw_balloon_batching);\n\n\treturn 0;\n}\n\n \nstatic void vmballoon_doorbell(void *client_data)\n{\n\tstruct vmballoon *b = client_data;\n\n\tvmballoon_stats_gen_inc(b, VMW_BALLOON_STAT_DOORBELL);\n\n\tmod_delayed_work(system_freezable_wq, &b->dwork, 0);\n}\n\n \nstatic void vmballoon_vmci_cleanup(struct vmballoon *b)\n{\n\tvmballoon_cmd(b, VMW_BALLOON_CMD_VMCI_DOORBELL_SET,\n\t\t      VMCI_INVALID_ID, VMCI_INVALID_ID);\n\n\tif (!vmci_handle_is_invalid(b->vmci_doorbell)) {\n\t\tvmci_doorbell_destroy(b->vmci_doorbell);\n\t\tb->vmci_doorbell = VMCI_INVALID_HANDLE;\n\t}\n}\n\n \nstatic int vmballoon_vmci_init(struct vmballoon *b)\n{\n\tunsigned long error;\n\n\tif ((b->capabilities & VMW_BALLOON_SIGNALLED_WAKEUP_CMD) == 0)\n\t\treturn 0;\n\n\terror = vmci_doorbell_create(&b->vmci_doorbell, VMCI_FLAG_DELAYED_CB,\n\t\t\t\t     VMCI_PRIVILEGE_FLAG_RESTRICTED,\n\t\t\t\t     vmballoon_doorbell, b);\n\n\tif (error != VMCI_SUCCESS)\n\t\tgoto fail;\n\n\terror =\t__vmballoon_cmd(b, VMW_BALLOON_CMD_VMCI_DOORBELL_SET,\n\t\t\t\tb->vmci_doorbell.context,\n\t\t\t\tb->vmci_doorbell.resource, NULL);\n\n\tif (error != VMW_BALLOON_SUCCESS)\n\t\tgoto fail;\n\n\treturn 0;\nfail:\n\tvmballoon_vmci_cleanup(b);\n\treturn -EIO;\n}\n\n \nstatic void vmballoon_pop(struct vmballoon *b)\n{\n\tunsigned long size;\n\n\twhile ((size = atomic64_read(&b->size)))\n\t\tvmballoon_deflate(b, size, false);\n}\n\n \nstatic void vmballoon_reset(struct vmballoon *b)\n{\n\tint error;\n\n\tdown_write(&b->conf_sem);\n\n\tvmballoon_vmci_cleanup(b);\n\n\t \n\tvmballoon_pop(b);\n\n\tif (vmballoon_send_start(b, VMW_BALLOON_CAPABILITIES))\n\t\tgoto unlock;\n\n\tif ((b->capabilities & VMW_BALLOON_BATCHED_CMDS) != 0) {\n\t\tif (vmballoon_init_batching(b)) {\n\t\t\t \n\t\t\tvmballoon_send_start(b, 0);\n\t\t\tgoto unlock;\n\t\t}\n\t} else if ((b->capabilities & VMW_BALLOON_BASIC_CMDS) != 0) {\n\t\tvmballoon_deinit_batching(b);\n\t}\n\n\tvmballoon_stats_gen_inc(b, VMW_BALLOON_STAT_RESET);\n\tb->reset_required = false;\n\n\terror = vmballoon_vmci_init(b);\n\tif (error)\n\t\tpr_err_once(\"failed to initialize vmci doorbell\\n\");\n\n\tif (vmballoon_send_guest_id(b))\n\t\tpr_err_once(\"failed to send guest ID to the host\\n\");\n\nunlock:\n\tup_write(&b->conf_sem);\n}\n\n \nstatic void vmballoon_work(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = to_delayed_work(work);\n\tstruct vmballoon *b = container_of(dwork, struct vmballoon, dwork);\n\tint64_t change = 0;\n\n\tif (b->reset_required)\n\t\tvmballoon_reset(b);\n\n\tdown_read(&b->conf_sem);\n\n\t \n\tvmballoon_stats_gen_inc(b, VMW_BALLOON_STAT_TIMER);\n\n\tif (!vmballoon_send_get_target(b))\n\t\tchange = vmballoon_change(b);\n\n\tif (change != 0) {\n\t\tpr_debug(\"%s - size: %llu, target %lu\\n\", __func__,\n\t\t\t atomic64_read(&b->size), READ_ONCE(b->target));\n\n\t\tif (change > 0)\n\t\t\tvmballoon_inflate(b);\n\t\telse   \n\t\t\tvmballoon_deflate(b, 0, true);\n\t}\n\n\tup_read(&b->conf_sem);\n\n\t \n\tqueue_delayed_work(system_freezable_wq,\n\t\t\t   dwork, round_jiffies_relative(HZ));\n\n}\n\n \nstatic unsigned long vmballoon_shrinker_scan(struct shrinker *shrinker,\n\t\t\t\t\t     struct shrink_control *sc)\n{\n\tstruct vmballoon *b = &balloon;\n\tunsigned long deflated_frames;\n\n\tpr_debug(\"%s - size: %llu\", __func__, atomic64_read(&b->size));\n\n\tvmballoon_stats_gen_inc(b, VMW_BALLOON_STAT_SHRINK);\n\n\t \n\tif (!down_read_trylock(&b->conf_sem))\n\t\treturn 0;\n\n\tdeflated_frames = vmballoon_deflate(b, sc->nr_to_scan, true);\n\n\tvmballoon_stats_gen_add(b, VMW_BALLOON_STAT_SHRINK_FREE,\n\t\t\t\tdeflated_frames);\n\n\t \n\tWRITE_ONCE(b->shrink_timeout, jiffies + HZ * VMBALLOON_SHRINK_DELAY);\n\n\tup_read(&b->conf_sem);\n\n\treturn deflated_frames;\n}\n\n \nstatic unsigned long vmballoon_shrinker_count(struct shrinker *shrinker,\n\t\t\t\t\t      struct shrink_control *sc)\n{\n\tstruct vmballoon *b = &balloon;\n\n\treturn atomic64_read(&b->size);\n}\n\nstatic void vmballoon_unregister_shrinker(struct vmballoon *b)\n{\n\tif (b->shrinker_registered)\n\t\tunregister_shrinker(&b->shrinker);\n\tb->shrinker_registered = false;\n}\n\nstatic int vmballoon_register_shrinker(struct vmballoon *b)\n{\n\tint r;\n\n\t \n\tif (!vmwballoon_shrinker_enable)\n\t\treturn 0;\n\n\tb->shrinker.scan_objects = vmballoon_shrinker_scan;\n\tb->shrinker.count_objects = vmballoon_shrinker_count;\n\tb->shrinker.seeks = DEFAULT_SEEKS;\n\n\tr = register_shrinker(&b->shrinker, \"vmw-balloon\");\n\n\tif (r == 0)\n\t\tb->shrinker_registered = true;\n\n\treturn r;\n}\n\n \n#ifdef CONFIG_DEBUG_FS\n\nstatic const char * const vmballoon_stat_page_names[] = {\n\t[VMW_BALLOON_PAGE_STAT_ALLOC]\t\t= \"alloc\",\n\t[VMW_BALLOON_PAGE_STAT_ALLOC_FAIL]\t= \"allocFail\",\n\t[VMW_BALLOON_PAGE_STAT_REFUSED_ALLOC]\t= \"errAlloc\",\n\t[VMW_BALLOON_PAGE_STAT_REFUSED_FREE]\t= \"errFree\",\n\t[VMW_BALLOON_PAGE_STAT_FREE]\t\t= \"free\"\n};\n\nstatic const char * const vmballoon_stat_names[] = {\n\t[VMW_BALLOON_STAT_TIMER]\t\t= \"timer\",\n\t[VMW_BALLOON_STAT_DOORBELL]\t\t= \"doorbell\",\n\t[VMW_BALLOON_STAT_RESET]\t\t= \"reset\",\n\t[VMW_BALLOON_STAT_SHRINK]\t\t= \"shrink\",\n\t[VMW_BALLOON_STAT_SHRINK_FREE]\t\t= \"shrinkFree\"\n};\n\nstatic int vmballoon_enable_stats(struct vmballoon *b)\n{\n\tint r = 0;\n\n\tdown_write(&b->conf_sem);\n\n\t \n\tif (b->stats)\n\t\tgoto out;\n\n\tb->stats = kzalloc(sizeof(*b->stats), GFP_KERNEL);\n\n\tif (!b->stats) {\n\t\t \n\t\tr = -ENOMEM;\n\t\tgoto out;\n\t}\n\tstatic_key_enable(&balloon_stat_enabled.key);\nout:\n\tup_write(&b->conf_sem);\n\treturn r;\n}\n\n \nstatic int vmballoon_debug_show(struct seq_file *f, void *offset)\n{\n\tstruct vmballoon *b = f->private;\n\tint i, j;\n\n\t \n\tif (!b->stats) {\n\t\tint r = vmballoon_enable_stats(b);\n\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\t \n\tseq_printf(f, \"%-22s: %#16x\\n\", \"balloon capabilities\",\n\t\t   VMW_BALLOON_CAPABILITIES);\n\tseq_printf(f, \"%-22s: %#16lx\\n\", \"used capabilities\", b->capabilities);\n\tseq_printf(f, \"%-22s: %16s\\n\", \"is resetting\",\n\t\t   b->reset_required ? \"y\" : \"n\");\n\n\t \n\tseq_printf(f, \"%-22s: %16lu\\n\", \"target\", READ_ONCE(b->target));\n\tseq_printf(f, \"%-22s: %16llu\\n\", \"current\", atomic64_read(&b->size));\n\n\tfor (i = 0; i < VMW_BALLOON_CMD_NUM; i++) {\n\t\tif (vmballoon_cmd_names[i] == NULL)\n\t\t\tcontinue;\n\n\t\tseq_printf(f, \"%-22s: %16llu (%llu failed)\\n\",\n\t\t\t   vmballoon_cmd_names[i],\n\t\t\t   atomic64_read(&b->stats->ops[i][VMW_BALLOON_OP_STAT]),\n\t\t\t   atomic64_read(&b->stats->ops[i][VMW_BALLOON_OP_FAIL_STAT]));\n\t}\n\n\tfor (i = 0; i < VMW_BALLOON_STAT_NUM; i++)\n\t\tseq_printf(f, \"%-22s: %16llu\\n\",\n\t\t\t   vmballoon_stat_names[i],\n\t\t\t   atomic64_read(&b->stats->general_stat[i]));\n\n\tfor (i = 0; i < VMW_BALLOON_PAGE_STAT_NUM; i++) {\n\t\tfor (j = 0; j < VMW_BALLOON_NUM_PAGE_SIZES; j++)\n\t\t\tseq_printf(f, \"%-18s(%s): %16llu\\n\",\n\t\t\t\t   vmballoon_stat_page_names[i],\n\t\t\t\t   vmballoon_page_size_names[j],\n\t\t\t\t   atomic64_read(&b->stats->page_stat[i][j]));\n\t}\n\n\treturn 0;\n}\n\nDEFINE_SHOW_ATTRIBUTE(vmballoon_debug);\n\nstatic void __init vmballoon_debugfs_init(struct vmballoon *b)\n{\n\tdebugfs_create_file(\"vmmemctl\", S_IRUGO, NULL, b,\n\t\t\t    &vmballoon_debug_fops);\n}\n\nstatic void __exit vmballoon_debugfs_exit(struct vmballoon *b)\n{\n\tstatic_key_disable(&balloon_stat_enabled.key);\n\tdebugfs_lookup_and_remove(\"vmmemctl\", NULL);\n\tkfree(b->stats);\n\tb->stats = NULL;\n}\n\n#else\n\nstatic inline void vmballoon_debugfs_init(struct vmballoon *b)\n{\n}\n\nstatic inline void vmballoon_debugfs_exit(struct vmballoon *b)\n{\n}\n\n#endif\t \n\n\n#ifdef CONFIG_BALLOON_COMPACTION\n \nstatic int vmballoon_migratepage(struct balloon_dev_info *b_dev_info,\n\t\t\t\t struct page *newpage, struct page *page,\n\t\t\t\t enum migrate_mode mode)\n{\n\tunsigned long status, flags;\n\tstruct vmballoon *b;\n\tint ret;\n\n\tb = container_of(b_dev_info, struct vmballoon, b_dev_info);\n\n\t \n\tif (!down_read_trylock(&b->conf_sem))\n\t\treturn -EAGAIN;\n\n\tspin_lock(&b->comm_lock);\n\t \n\tvmballoon_add_page(b, 0, page);\n\tstatus = vmballoon_lock_op(b, 1, VMW_BALLOON_4K_PAGE,\n\t\t\t\t   VMW_BALLOON_DEFLATE);\n\n\tif (status == VMW_BALLOON_SUCCESS)\n\t\tstatus = vmballoon_status_page(b, 0, &page);\n\n\t \n\tif (status != VMW_BALLOON_SUCCESS) {\n\t\tspin_unlock(&b->comm_lock);\n\t\tret = -EBUSY;\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tballoon_page_delete(page);\n\n\tput_page(page);\n\n\t \n\tvmballoon_add_page(b, 0, newpage);\n\tstatus = vmballoon_lock_op(b, 1, VMW_BALLOON_4K_PAGE,\n\t\t\t\t   VMW_BALLOON_INFLATE);\n\n\tif (status == VMW_BALLOON_SUCCESS)\n\t\tstatus = vmballoon_status_page(b, 0, &newpage);\n\n\tspin_unlock(&b->comm_lock);\n\n\tif (status != VMW_BALLOON_SUCCESS) {\n\t\t \n\t\tatomic64_dec(&b->size);\n\t\tret = -EBUSY;\n\t} else {\n\t\t \n\t\tget_page(newpage);\n\t\tret = MIGRATEPAGE_SUCCESS;\n\t}\n\n\t \n\tspin_lock_irqsave(&b->b_dev_info.pages_lock, flags);\n\n\t \n\tif (ret == MIGRATEPAGE_SUCCESS) {\n\t\tballoon_page_insert(&b->b_dev_info, newpage);\n\t\t__count_vm_event(BALLOON_MIGRATE);\n\t}\n\n\t \n\tb->b_dev_info.isolated_pages--;\n\tspin_unlock_irqrestore(&b->b_dev_info.pages_lock, flags);\n\nout_unlock:\n\tup_read(&b->conf_sem);\n\treturn ret;\n}\n\n \nstatic __init void vmballoon_compaction_init(struct vmballoon *b)\n{\n\tb->b_dev_info.migratepage = vmballoon_migratepage;\n}\n\n#else  \nstatic inline void vmballoon_compaction_init(struct vmballoon *b)\n{\n}\n#endif  \n\nstatic int __init vmballoon_init(void)\n{\n\tint error;\n\n\t \n\tif (x86_hyper_type != X86_HYPER_VMWARE)\n\t\treturn -ENODEV;\n\n\tINIT_DELAYED_WORK(&balloon.dwork, vmballoon_work);\n\n\terror = vmballoon_register_shrinker(&balloon);\n\tif (error)\n\t\tgoto fail;\n\n\t \n\tballoon_devinfo_init(&balloon.b_dev_info);\n\tvmballoon_compaction_init(&balloon);\n\n\tINIT_LIST_HEAD(&balloon.huge_pages);\n\tspin_lock_init(&balloon.comm_lock);\n\tinit_rwsem(&balloon.conf_sem);\n\tballoon.vmci_doorbell = VMCI_INVALID_HANDLE;\n\tballoon.batch_page = NULL;\n\tballoon.page = NULL;\n\tballoon.reset_required = true;\n\n\tqueue_delayed_work(system_freezable_wq, &balloon.dwork, 0);\n\n\tvmballoon_debugfs_init(&balloon);\n\n\treturn 0;\nfail:\n\tvmballoon_unregister_shrinker(&balloon);\n\treturn error;\n}\n\n \nlate_initcall(vmballoon_init);\n\nstatic void __exit vmballoon_exit(void)\n{\n\tvmballoon_unregister_shrinker(&balloon);\n\tvmballoon_vmci_cleanup(&balloon);\n\tcancel_delayed_work_sync(&balloon.dwork);\n\n\tvmballoon_debugfs_exit(&balloon);\n\n\t \n\tvmballoon_send_start(&balloon, 0);\n\tvmballoon_pop(&balloon);\n}\nmodule_exit(vmballoon_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}