{
  "module_name": "hw-me.c",
  "hash_id": "2bdd87465fc90d97b924f1496b38b183320797019a065febc23f928661c59a63",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/mei/hw-me.c",
  "human_readable_source": "\n \n\n#include <linux/pci.h>\n\n#include <linux/kthread.h>\n#include <linux/interrupt.h>\n#include <linux/pm_runtime.h>\n#include <linux/sizes.h>\n#include <linux/delay.h>\n\n#include \"mei_dev.h\"\n#include \"hbm.h\"\n\n#include \"hw-me.h\"\n#include \"hw-me-regs.h\"\n\n#include \"mei-trace.h\"\n\n \nstatic inline u32 mei_me_reg_read(const struct mei_me_hw *hw,\n\t\t\t       unsigned long offset)\n{\n\treturn ioread32(hw->mem_addr + offset);\n}\n\n\n \nstatic inline void mei_me_reg_write(const struct mei_me_hw *hw,\n\t\t\t\t unsigned long offset, u32 value)\n{\n\tiowrite32(value, hw->mem_addr + offset);\n}\n\n \nstatic inline u32 mei_me_mecbrw_read(const struct mei_device *dev)\n{\n\treturn mei_me_reg_read(to_me_hw(dev), ME_CB_RW);\n}\n\n \nstatic inline void mei_me_hcbww_write(struct mei_device *dev, u32 data)\n{\n\tmei_me_reg_write(to_me_hw(dev), H_CB_WW, data);\n}\n\n \nstatic inline u32 mei_me_mecsr_read(const struct mei_device *dev)\n{\n\tu32 reg;\n\n\treg = mei_me_reg_read(to_me_hw(dev), ME_CSR_HA);\n\ttrace_mei_reg_read(dev->dev, \"ME_CSR_HA\", ME_CSR_HA, reg);\n\n\treturn reg;\n}\n\n \nstatic inline u32 mei_hcsr_read(const struct mei_device *dev)\n{\n\tu32 reg;\n\n\treg = mei_me_reg_read(to_me_hw(dev), H_CSR);\n\ttrace_mei_reg_read(dev->dev, \"H_CSR\", H_CSR, reg);\n\n\treturn reg;\n}\n\n \nstatic inline void mei_hcsr_write(struct mei_device *dev, u32 reg)\n{\n\ttrace_mei_reg_write(dev->dev, \"H_CSR\", H_CSR, reg);\n\tmei_me_reg_write(to_me_hw(dev), H_CSR, reg);\n}\n\n \nstatic inline void mei_hcsr_set(struct mei_device *dev, u32 reg)\n{\n\treg &= ~H_CSR_IS_MASK;\n\tmei_hcsr_write(dev, reg);\n}\n\n \nstatic inline void mei_hcsr_set_hig(struct mei_device *dev)\n{\n\tu32 hcsr;\n\n\thcsr = mei_hcsr_read(dev) | H_IG;\n\tmei_hcsr_set(dev, hcsr);\n}\n\n \nstatic inline u32 mei_me_d0i3c_read(const struct mei_device *dev)\n{\n\tu32 reg;\n\n\treg = mei_me_reg_read(to_me_hw(dev), H_D0I3C);\n\ttrace_mei_reg_read(dev->dev, \"H_D0I3C\", H_D0I3C, reg);\n\n\treturn reg;\n}\n\n \nstatic inline void mei_me_d0i3c_write(struct mei_device *dev, u32 reg)\n{\n\ttrace_mei_reg_write(dev->dev, \"H_D0I3C\", H_D0I3C, reg);\n\tmei_me_reg_write(to_me_hw(dev), H_D0I3C, reg);\n}\n\n \nstatic int mei_me_trc_status(struct mei_device *dev, u32 *trc)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\n\tif (!hw->cfg->hw_trc_supported)\n\t\treturn -EOPNOTSUPP;\n\n\t*trc = mei_me_reg_read(hw, ME_TRC);\n\ttrace_mei_reg_read(dev->dev, \"ME_TRC\", ME_TRC, *trc);\n\n\treturn 0;\n}\n\n \nstatic int mei_me_fw_status(struct mei_device *dev,\n\t\t\t    struct mei_fw_status *fw_status)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tconst struct mei_fw_status *fw_src = &hw->cfg->fw_status;\n\tint ret;\n\tint i;\n\n\tif (!fw_status || !hw->read_fws)\n\t\treturn -EINVAL;\n\n\tfw_status->count = fw_src->count;\n\tfor (i = 0; i < fw_src->count && i < MEI_FW_STATUS_MAX; i++) {\n\t\tret = hw->read_fws(dev, fw_src->status[i],\n\t\t\t\t   &fw_status->status[i]);\n\t\ttrace_mei_pci_cfg_read(dev->dev, \"PCI_CFG_HFS_X\",\n\t\t\t\t       fw_src->status[i],\n\t\t\t\t       fw_status->status[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int mei_me_hw_config(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tu32 hcsr, reg;\n\n\tif (WARN_ON(!hw->read_fws))\n\t\treturn -EINVAL;\n\n\t \n\thcsr = mei_hcsr_read(dev);\n\thw->hbuf_depth = (hcsr & H_CBD) >> 24;\n\n\treg = 0;\n\thw->read_fws(dev, PCI_CFG_HFS_1, &reg);\n\ttrace_mei_pci_cfg_read(dev->dev, \"PCI_CFG_HFS_1\", PCI_CFG_HFS_1, reg);\n\thw->d0i3_supported =\n\t\t((reg & PCI_CFG_HFS_1_D0I3_MSK) == PCI_CFG_HFS_1_D0I3_MSK);\n\n\thw->pg_state = MEI_PG_OFF;\n\tif (hw->d0i3_supported) {\n\t\treg = mei_me_d0i3c_read(dev);\n\t\tif (reg & H_D0I3C_I3)\n\t\t\thw->pg_state = MEI_PG_ON;\n\t}\n\n\treturn 0;\n}\n\n \nstatic inline enum mei_pg_state mei_me_pg_state(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\n\treturn hw->pg_state;\n}\n\nstatic inline u32 me_intr_src(u32 hcsr)\n{\n\treturn hcsr & H_CSR_IS_MASK;\n}\n\n \nstatic inline void me_intr_disable(struct mei_device *dev, u32 hcsr)\n{\n\thcsr &= ~H_CSR_IE_MASK;\n\tmei_hcsr_set(dev, hcsr);\n}\n\n \nstatic inline void me_intr_clear(struct mei_device *dev, u32 hcsr)\n{\n\tif (me_intr_src(hcsr))\n\t\tmei_hcsr_write(dev, hcsr);\n}\n\n \nstatic void mei_me_intr_clear(struct mei_device *dev)\n{\n\tu32 hcsr = mei_hcsr_read(dev);\n\n\tme_intr_clear(dev, hcsr);\n}\n \nstatic void mei_me_intr_enable(struct mei_device *dev)\n{\n\tu32 hcsr;\n\n\tif (mei_me_hw_use_polling(to_me_hw(dev)))\n\t\treturn;\n\n\thcsr = mei_hcsr_read(dev) | H_CSR_IE_MASK;\n\tmei_hcsr_set(dev, hcsr);\n}\n\n \nstatic void mei_me_intr_disable(struct mei_device *dev)\n{\n\tu32 hcsr = mei_hcsr_read(dev);\n\n\tme_intr_disable(dev, hcsr);\n}\n\n \nstatic void mei_me_synchronize_irq(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\n\tif (mei_me_hw_use_polling(hw))\n\t\treturn;\n\n\tsynchronize_irq(hw->irq);\n}\n\n \nstatic void mei_me_hw_reset_release(struct mei_device *dev)\n{\n\tu32 hcsr = mei_hcsr_read(dev);\n\n\thcsr |= H_IG;\n\thcsr &= ~H_RST;\n\tmei_hcsr_set(dev, hcsr);\n}\n\n \nstatic void mei_me_host_set_ready(struct mei_device *dev)\n{\n\tu32 hcsr = mei_hcsr_read(dev);\n\n\tif (!mei_me_hw_use_polling(to_me_hw(dev)))\n\t\thcsr |= H_CSR_IE_MASK;\n\n\thcsr |=  H_IG | H_RDY;\n\tmei_hcsr_set(dev, hcsr);\n}\n\n \nstatic bool mei_me_host_is_ready(struct mei_device *dev)\n{\n\tu32 hcsr = mei_hcsr_read(dev);\n\n\treturn (hcsr & H_RDY) == H_RDY;\n}\n\n \nstatic bool mei_me_hw_is_ready(struct mei_device *dev)\n{\n\tu32 mecsr = mei_me_mecsr_read(dev);\n\n\treturn (mecsr & ME_RDY_HRA) == ME_RDY_HRA;\n}\n\n \nstatic bool mei_me_hw_is_resetting(struct mei_device *dev)\n{\n\tu32 mecsr = mei_me_mecsr_read(dev);\n\n\treturn (mecsr & ME_RST_HRA) == ME_RST_HRA;\n}\n\n \nstatic void mei_gsc_pxp_check(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tu32 fwsts5 = 0;\n\n\tif (dev->pxp_mode == MEI_DEV_PXP_DEFAULT)\n\t\treturn;\n\n\thw->read_fws(dev, PCI_CFG_HFS_5, &fwsts5);\n\ttrace_mei_pci_cfg_read(dev->dev, \"PCI_CFG_HFS_5\", PCI_CFG_HFS_5, fwsts5);\n\tif ((fwsts5 & GSC_CFG_HFS_5_BOOT_TYPE_MSK) == GSC_CFG_HFS_5_BOOT_TYPE_PXP) {\n\t\tdev_dbg(dev->dev, \"pxp mode is ready 0x%08x\\n\", fwsts5);\n\t\tdev->pxp_mode = MEI_DEV_PXP_READY;\n\t} else {\n\t\tdev_dbg(dev->dev, \"pxp mode is not ready 0x%08x\\n\", fwsts5);\n\t}\n}\n\n \nstatic int mei_me_hw_ready_wait(struct mei_device *dev)\n{\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(dev->wait_hw_ready,\n\t\t\tdev->recvd_hw_ready,\n\t\t\tdev->timeouts.hw_ready);\n\tmutex_lock(&dev->device_lock);\n\tif (!dev->recvd_hw_ready) {\n\t\tdev_err(dev->dev, \"wait hw ready failed\\n\");\n\t\treturn -ETIME;\n\t}\n\n\tmei_gsc_pxp_check(dev);\n\n\tmei_me_hw_reset_release(dev);\n\tdev->recvd_hw_ready = false;\n\treturn 0;\n}\n\n \nstatic int mei_me_hw_start(struct mei_device *dev)\n{\n\tint ret = mei_me_hw_ready_wait(dev);\n\n\tif (ret)\n\t\treturn ret;\n\tdev_dbg(dev->dev, \"hw is ready\\n\");\n\n\tmei_me_host_set_ready(dev);\n\treturn ret;\n}\n\n\n \nstatic unsigned char mei_hbuf_filled_slots(struct mei_device *dev)\n{\n\tu32 hcsr;\n\tchar read_ptr, write_ptr;\n\n\thcsr = mei_hcsr_read(dev);\n\n\tread_ptr = (char) ((hcsr & H_CBRP) >> 8);\n\twrite_ptr = (char) ((hcsr & H_CBWP) >> 16);\n\n\treturn (unsigned char) (write_ptr - read_ptr);\n}\n\n \nstatic bool mei_me_hbuf_is_empty(struct mei_device *dev)\n{\n\treturn mei_hbuf_filled_slots(dev) == 0;\n}\n\n \nstatic int mei_me_hbuf_empty_slots(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tunsigned char filled_slots, empty_slots;\n\n\tfilled_slots = mei_hbuf_filled_slots(dev);\n\tempty_slots = hw->hbuf_depth - filled_slots;\n\n\t \n\tif (filled_slots > hw->hbuf_depth)\n\t\treturn -EOVERFLOW;\n\n\treturn empty_slots;\n}\n\n \nstatic u32 mei_me_hbuf_depth(const struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\n\treturn hw->hbuf_depth;\n}\n\n \nstatic int mei_me_hbuf_write(struct mei_device *dev,\n\t\t\t     const void *hdr, size_t hdr_len,\n\t\t\t     const void *data, size_t data_len)\n{\n\tunsigned long rem;\n\tunsigned long i;\n\tconst u32 *reg_buf;\n\tu32 dw_cnt;\n\tint empty_slots;\n\n\tif (WARN_ON(!hdr || hdr_len & 0x3))\n\t\treturn -EINVAL;\n\n\tif (!data && data_len) {\n\t\tdev_err(dev->dev, \"wrong parameters null data with data_len = %zu\\n\", data_len);\n\t\treturn -EINVAL;\n\t}\n\n\tdev_dbg(dev->dev, MEI_HDR_FMT, MEI_HDR_PRM((struct mei_msg_hdr *)hdr));\n\n\tempty_slots = mei_hbuf_empty_slots(dev);\n\tdev_dbg(dev->dev, \"empty slots = %d.\\n\", empty_slots);\n\n\tif (empty_slots < 0)\n\t\treturn -EOVERFLOW;\n\n\tdw_cnt = mei_data2slots(hdr_len + data_len);\n\tif (dw_cnt > (u32)empty_slots)\n\t\treturn -EMSGSIZE;\n\n\treg_buf = hdr;\n\tfor (i = 0; i < hdr_len / MEI_SLOT_SIZE; i++)\n\t\tmei_me_hcbww_write(dev, reg_buf[i]);\n\n\treg_buf = data;\n\tfor (i = 0; i < data_len / MEI_SLOT_SIZE; i++)\n\t\tmei_me_hcbww_write(dev, reg_buf[i]);\n\n\trem = data_len & 0x3;\n\tif (rem > 0) {\n\t\tu32 reg = 0;\n\n\t\tmemcpy(&reg, (const u8 *)data + data_len - rem, rem);\n\t\tmei_me_hcbww_write(dev, reg);\n\t}\n\n\tmei_hcsr_set_hig(dev);\n\tif (!mei_me_hw_is_ready(dev))\n\t\treturn -EIO;\n\n\treturn 0;\n}\n\n \nstatic int mei_me_count_full_read_slots(struct mei_device *dev)\n{\n\tu32 me_csr;\n\tchar read_ptr, write_ptr;\n\tunsigned char buffer_depth, filled_slots;\n\n\tme_csr = mei_me_mecsr_read(dev);\n\tbuffer_depth = (unsigned char)((me_csr & ME_CBD_HRA) >> 24);\n\tread_ptr = (char) ((me_csr & ME_CBRP_HRA) >> 8);\n\twrite_ptr = (char) ((me_csr & ME_CBWP_HRA) >> 16);\n\tfilled_slots = (unsigned char) (write_ptr - read_ptr);\n\n\t \n\tif (filled_slots > buffer_depth)\n\t\treturn -EOVERFLOW;\n\n\tdev_dbg(dev->dev, \"filled_slots =%08x\\n\", filled_slots);\n\treturn (int)filled_slots;\n}\n\n \nstatic int mei_me_read_slots(struct mei_device *dev, unsigned char *buffer,\n\t\t\t     unsigned long buffer_length)\n{\n\tu32 *reg_buf = (u32 *)buffer;\n\n\tfor (; buffer_length >= MEI_SLOT_SIZE; buffer_length -= MEI_SLOT_SIZE)\n\t\t*reg_buf++ = mei_me_mecbrw_read(dev);\n\n\tif (buffer_length > 0) {\n\t\tu32 reg = mei_me_mecbrw_read(dev);\n\n\t\tmemcpy(reg_buf, &reg, buffer_length);\n\t}\n\n\tmei_hcsr_set_hig(dev);\n\treturn 0;\n}\n\n \nstatic void mei_me_pg_set(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tu32 reg;\n\n\treg = mei_me_reg_read(hw, H_HPG_CSR);\n\ttrace_mei_reg_read(dev->dev, \"H_HPG_CSR\", H_HPG_CSR, reg);\n\n\treg |= H_HPG_CSR_PGI;\n\n\ttrace_mei_reg_write(dev->dev, \"H_HPG_CSR\", H_HPG_CSR, reg);\n\tmei_me_reg_write(hw, H_HPG_CSR, reg);\n}\n\n \nstatic void mei_me_pg_unset(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tu32 reg;\n\n\treg = mei_me_reg_read(hw, H_HPG_CSR);\n\ttrace_mei_reg_read(dev->dev, \"H_HPG_CSR\", H_HPG_CSR, reg);\n\n\tWARN(!(reg & H_HPG_CSR_PGI), \"PGI is not set\\n\");\n\n\treg |= H_HPG_CSR_PGIHEXR;\n\n\ttrace_mei_reg_write(dev->dev, \"H_HPG_CSR\", H_HPG_CSR, reg);\n\tmei_me_reg_write(hw, H_HPG_CSR, reg);\n}\n\n \nstatic int mei_me_pg_legacy_enter_sync(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tint ret;\n\n\tdev->pg_event = MEI_PG_EVENT_WAIT;\n\n\tret = mei_hbm_pg(dev, MEI_PG_ISOLATION_ENTRY_REQ_CMD);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(dev->wait_pg,\n\t\tdev->pg_event == MEI_PG_EVENT_RECEIVED,\n\t\tdev->timeouts.pgi);\n\tmutex_lock(&dev->device_lock);\n\n\tif (dev->pg_event == MEI_PG_EVENT_RECEIVED) {\n\t\tmei_me_pg_set(dev);\n\t\tret = 0;\n\t} else {\n\t\tret = -ETIME;\n\t}\n\n\tdev->pg_event = MEI_PG_EVENT_IDLE;\n\thw->pg_state = MEI_PG_ON;\n\n\treturn ret;\n}\n\n \nstatic int mei_me_pg_legacy_exit_sync(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tint ret;\n\n\tif (dev->pg_event == MEI_PG_EVENT_RECEIVED)\n\t\tgoto reply;\n\n\tdev->pg_event = MEI_PG_EVENT_WAIT;\n\n\tmei_me_pg_unset(dev);\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(dev->wait_pg,\n\t\tdev->pg_event == MEI_PG_EVENT_RECEIVED,\n\t\tdev->timeouts.pgi);\n\tmutex_lock(&dev->device_lock);\n\nreply:\n\tif (dev->pg_event != MEI_PG_EVENT_RECEIVED) {\n\t\tret = -ETIME;\n\t\tgoto out;\n\t}\n\n\tdev->pg_event = MEI_PG_EVENT_INTR_WAIT;\n\tret = mei_hbm_pg(dev, MEI_PG_ISOLATION_EXIT_RES_CMD);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(dev->wait_pg,\n\t\tdev->pg_event == MEI_PG_EVENT_INTR_RECEIVED,\n\t\tdev->timeouts.pgi);\n\tmutex_lock(&dev->device_lock);\n\n\tif (dev->pg_event == MEI_PG_EVENT_INTR_RECEIVED)\n\t\tret = 0;\n\telse\n\t\tret = -ETIME;\n\nout:\n\tdev->pg_event = MEI_PG_EVENT_IDLE;\n\thw->pg_state = MEI_PG_OFF;\n\n\treturn ret;\n}\n\n \nstatic bool mei_me_pg_in_transition(struct mei_device *dev)\n{\n\treturn dev->pg_event >= MEI_PG_EVENT_WAIT &&\n\t       dev->pg_event <= MEI_PG_EVENT_INTR_WAIT;\n}\n\n \nstatic bool mei_me_pg_is_enabled(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tu32 reg = mei_me_mecsr_read(dev);\n\n\tif (hw->d0i3_supported)\n\t\treturn true;\n\n\tif ((reg & ME_PGIC_HRA) == 0)\n\t\tgoto notsupported;\n\n\tif (!dev->hbm_f_pg_supported)\n\t\tgoto notsupported;\n\n\treturn true;\n\nnotsupported:\n\tdev_dbg(dev->dev, \"pg: not supported: d0i3 = %d HGP = %d hbm version %d.%d ?= %d.%d\\n\",\n\t\thw->d0i3_supported,\n\t\t!!(reg & ME_PGIC_HRA),\n\t\tdev->version.major_version,\n\t\tdev->version.minor_version,\n\t\tHBM_MAJOR_VERSION_PGI,\n\t\tHBM_MINOR_VERSION_PGI);\n\n\treturn false;\n}\n\n \nstatic u32 mei_me_d0i3_set(struct mei_device *dev, bool intr)\n{\n\tu32 reg = mei_me_d0i3c_read(dev);\n\n\treg |= H_D0I3C_I3;\n\tif (intr)\n\t\treg |= H_D0I3C_IR;\n\telse\n\t\treg &= ~H_D0I3C_IR;\n\tmei_me_d0i3c_write(dev, reg);\n\t \n\treg = mei_me_d0i3c_read(dev);\n\treturn reg;\n}\n\n \nstatic u32 mei_me_d0i3_unset(struct mei_device *dev)\n{\n\tu32 reg = mei_me_d0i3c_read(dev);\n\n\treg &= ~H_D0I3C_I3;\n\treg |= H_D0I3C_IR;\n\tmei_me_d0i3c_write(dev, reg);\n\t \n\treg = mei_me_d0i3c_read(dev);\n\treturn reg;\n}\n\n \nstatic int mei_me_d0i3_enter_sync(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tint ret;\n\tu32 reg;\n\n\treg = mei_me_d0i3c_read(dev);\n\tif (reg & H_D0I3C_I3) {\n\t\t \n\t\tdev_dbg(dev->dev, \"d0i3 set not needed\\n\");\n\t\tret = 0;\n\t\tgoto on;\n\t}\n\n\t \n\tdev->pg_event = MEI_PG_EVENT_WAIT;\n\n\tret = mei_hbm_pg(dev, MEI_PG_ISOLATION_ENTRY_REQ_CMD);\n\tif (ret)\n\t\t \n\t\tgoto out;\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(dev->wait_pg,\n\t\tdev->pg_event == MEI_PG_EVENT_RECEIVED,\n\t\tdev->timeouts.pgi);\n\tmutex_lock(&dev->device_lock);\n\n\tif (dev->pg_event != MEI_PG_EVENT_RECEIVED) {\n\t\tret = -ETIME;\n\t\tgoto out;\n\t}\n\t \n\n\tdev->pg_event = MEI_PG_EVENT_INTR_WAIT;\n\n\treg = mei_me_d0i3_set(dev, true);\n\tif (!(reg & H_D0I3C_CIP)) {\n\t\tdev_dbg(dev->dev, \"d0i3 enter wait not needed\\n\");\n\t\tret = 0;\n\t\tgoto on;\n\t}\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(dev->wait_pg,\n\t\tdev->pg_event == MEI_PG_EVENT_INTR_RECEIVED,\n\t\tdev->timeouts.d0i3);\n\tmutex_lock(&dev->device_lock);\n\n\tif (dev->pg_event != MEI_PG_EVENT_INTR_RECEIVED) {\n\t\treg = mei_me_d0i3c_read(dev);\n\t\tif (!(reg & H_D0I3C_I3)) {\n\t\t\tret = -ETIME;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = 0;\non:\n\thw->pg_state = MEI_PG_ON;\nout:\n\tdev->pg_event = MEI_PG_EVENT_IDLE;\n\tdev_dbg(dev->dev, \"d0i3 enter ret = %d\\n\", ret);\n\treturn ret;\n}\n\n \nstatic int mei_me_d0i3_enter(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tu32 reg;\n\n\treg = mei_me_d0i3c_read(dev);\n\tif (reg & H_D0I3C_I3) {\n\t\t \n\t\tdev_dbg(dev->dev, \"already d0i3 : set not needed\\n\");\n\t\tgoto on;\n\t}\n\n\tmei_me_d0i3_set(dev, false);\non:\n\thw->pg_state = MEI_PG_ON;\n\tdev->pg_event = MEI_PG_EVENT_IDLE;\n\tdev_dbg(dev->dev, \"d0i3 enter\\n\");\n\treturn 0;\n}\n\n \nstatic int mei_me_d0i3_exit_sync(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tint ret;\n\tu32 reg;\n\n\tdev->pg_event = MEI_PG_EVENT_INTR_WAIT;\n\n\treg = mei_me_d0i3c_read(dev);\n\tif (!(reg & H_D0I3C_I3)) {\n\t\t \n\t\tdev_dbg(dev->dev, \"d0i3 exit not needed\\n\");\n\t\tret = 0;\n\t\tgoto off;\n\t}\n\n\treg = mei_me_d0i3_unset(dev);\n\tif (!(reg & H_D0I3C_CIP)) {\n\t\tdev_dbg(dev->dev, \"d0i3 exit wait not needed\\n\");\n\t\tret = 0;\n\t\tgoto off;\n\t}\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(dev->wait_pg,\n\t\tdev->pg_event == MEI_PG_EVENT_INTR_RECEIVED,\n\t\tdev->timeouts.d0i3);\n\tmutex_lock(&dev->device_lock);\n\n\tif (dev->pg_event != MEI_PG_EVENT_INTR_RECEIVED) {\n\t\treg = mei_me_d0i3c_read(dev);\n\t\tif (reg & H_D0I3C_I3) {\n\t\t\tret = -ETIME;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = 0;\noff:\n\thw->pg_state = MEI_PG_OFF;\nout:\n\tdev->pg_event = MEI_PG_EVENT_IDLE;\n\n\tdev_dbg(dev->dev, \"d0i3 exit ret = %d\\n\", ret);\n\treturn ret;\n}\n\n \nstatic void mei_me_pg_legacy_intr(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\n\tif (dev->pg_event != MEI_PG_EVENT_INTR_WAIT)\n\t\treturn;\n\n\tdev->pg_event = MEI_PG_EVENT_INTR_RECEIVED;\n\thw->pg_state = MEI_PG_OFF;\n\tif (waitqueue_active(&dev->wait_pg))\n\t\twake_up(&dev->wait_pg);\n}\n\n \nstatic void mei_me_d0i3_intr(struct mei_device *dev, u32 intr_source)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\n\tif (dev->pg_event == MEI_PG_EVENT_INTR_WAIT &&\n\t    (intr_source & H_D0I3C_IS)) {\n\t\tdev->pg_event = MEI_PG_EVENT_INTR_RECEIVED;\n\t\tif (hw->pg_state == MEI_PG_ON) {\n\t\t\thw->pg_state = MEI_PG_OFF;\n\t\t\tif (dev->hbm_state != MEI_HBM_IDLE) {\n\t\t\t\t \n\t\t\t\tdev_dbg(dev->dev, \"d0i3 set host ready\\n\");\n\t\t\t\tmei_me_host_set_ready(dev);\n\t\t\t}\n\t\t} else {\n\t\t\thw->pg_state = MEI_PG_ON;\n\t\t}\n\n\t\twake_up(&dev->wait_pg);\n\t}\n\n\tif (hw->pg_state == MEI_PG_ON && (intr_source & H_IS)) {\n\t\t \n\t\tdev_dbg(dev->dev, \"d0i3 want resume\\n\");\n\t\tmei_hbm_pg_resume(dev);\n\t}\n}\n\n \nstatic void mei_me_pg_intr(struct mei_device *dev, u32 intr_source)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\n\tif (hw->d0i3_supported)\n\t\tmei_me_d0i3_intr(dev, intr_source);\n\telse\n\t\tmei_me_pg_legacy_intr(dev);\n}\n\n \nint mei_me_pg_enter_sync(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\n\tif (hw->d0i3_supported)\n\t\treturn mei_me_d0i3_enter_sync(dev);\n\telse\n\t\treturn mei_me_pg_legacy_enter_sync(dev);\n}\n\n \nint mei_me_pg_exit_sync(struct mei_device *dev)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\n\tif (hw->d0i3_supported)\n\t\treturn mei_me_d0i3_exit_sync(dev);\n\telse\n\t\treturn mei_me_pg_legacy_exit_sync(dev);\n}\n\n \nstatic int mei_me_hw_reset(struct mei_device *dev, bool intr_enable)\n{\n\tstruct mei_me_hw *hw = to_me_hw(dev);\n\tint ret;\n\tu32 hcsr;\n\n\tif (intr_enable) {\n\t\tmei_me_intr_enable(dev);\n\t\tif (hw->d0i3_supported) {\n\t\t\tret = mei_me_d0i3_exit_sync(dev);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t} else {\n\t\t\thw->pg_state = MEI_PG_OFF;\n\t\t}\n\t}\n\n\tpm_runtime_set_active(dev->dev);\n\n\thcsr = mei_hcsr_read(dev);\n\t \n\tif ((hcsr & H_RST) == H_RST) {\n\t\tdev_warn(dev->dev, \"H_RST is set = 0x%08X\", hcsr);\n\t\thcsr &= ~H_RST;\n\t\tmei_hcsr_set(dev, hcsr);\n\t\thcsr = mei_hcsr_read(dev);\n\t}\n\n\thcsr |= H_RST | H_IG | H_CSR_IS_MASK;\n\n\tif (!intr_enable || mei_me_hw_use_polling(to_me_hw(dev)))\n\t\thcsr &= ~H_CSR_IE_MASK;\n\n\tdev->recvd_hw_ready = false;\n\tmei_hcsr_write(dev, hcsr);\n\n\t \n\thcsr = mei_hcsr_read(dev);\n\n\tif ((hcsr & H_RST) == 0)\n\t\tdev_warn(dev->dev, \"H_RST is not set = 0x%08X\", hcsr);\n\n\tif ((hcsr & H_RDY) == H_RDY)\n\t\tdev_warn(dev->dev, \"H_RDY is not cleared 0x%08X\", hcsr);\n\n\tif (!intr_enable) {\n\t\tmei_me_hw_reset_release(dev);\n\t\tif (hw->d0i3_supported) {\n\t\t\tret = mei_me_d0i3_enter(dev);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nirqreturn_t mei_me_irq_quick_handler(int irq, void *dev_id)\n{\n\tstruct mei_device *dev = (struct mei_device *)dev_id;\n\tu32 hcsr;\n\n\thcsr = mei_hcsr_read(dev);\n\tif (!me_intr_src(hcsr))\n\t\treturn IRQ_NONE;\n\n\tdev_dbg(dev->dev, \"interrupt source 0x%08X\\n\", me_intr_src(hcsr));\n\n\t \n\tme_intr_disable(dev, hcsr);\n\treturn IRQ_WAKE_THREAD;\n}\nEXPORT_SYMBOL_GPL(mei_me_irq_quick_handler);\n\n \nirqreturn_t mei_me_irq_thread_handler(int irq, void *dev_id)\n{\n\tstruct mei_device *dev = (struct mei_device *) dev_id;\n\tstruct list_head cmpl_list;\n\ts32 slots;\n\tu32 hcsr;\n\tint rets = 0;\n\n\tdev_dbg(dev->dev, \"function called after ISR to handle the interrupt processing.\\n\");\n\t \n\tmutex_lock(&dev->device_lock);\n\n\thcsr = mei_hcsr_read(dev);\n\tme_intr_clear(dev, hcsr);\n\n\tINIT_LIST_HEAD(&cmpl_list);\n\n\t \n\tif (!mei_hw_is_ready(dev) && dev->dev_state != MEI_DEV_RESETTING) {\n\t\tdev_warn(dev->dev, \"FW not ready: resetting: dev_state = %d pxp = %d\\n\",\n\t\t\t dev->dev_state, dev->pxp_mode);\n\t\tif (dev->dev_state == MEI_DEV_POWERING_DOWN ||\n\t\t    dev->dev_state == MEI_DEV_POWER_DOWN)\n\t\t\tmei_cl_all_disconnect(dev);\n\t\telse if (dev->dev_state != MEI_DEV_DISABLED)\n\t\t\tschedule_work(&dev->reset_work);\n\t\tgoto end;\n\t}\n\n\tif (mei_me_hw_is_resetting(dev))\n\t\tmei_hcsr_set_hig(dev);\n\n\tmei_me_pg_intr(dev, me_intr_src(hcsr));\n\n\t \n\tif (!mei_host_is_ready(dev)) {\n\t\tif (mei_hw_is_ready(dev)) {\n\t\t\tdev_dbg(dev->dev, \"we need to start the dev.\\n\");\n\t\t\tdev->recvd_hw_ready = true;\n\t\t\twake_up(&dev->wait_hw_ready);\n\t\t} else {\n\t\t\tdev_dbg(dev->dev, \"Spurious Interrupt\\n\");\n\t\t}\n\t\tgoto end;\n\t}\n\t \n\tslots = mei_count_full_read_slots(dev);\n\twhile (slots > 0) {\n\t\tdev_dbg(dev->dev, \"slots to read = %08x\\n\", slots);\n\t\trets = mei_irq_read_handler(dev, &cmpl_list, &slots);\n\t\t \n\t\tif (rets == -ENODATA)\n\t\t\tbreak;\n\n\t\tif (rets) {\n\t\t\tdev_err(dev->dev, \"mei_irq_read_handler ret = %d, state = %d.\\n\",\n\t\t\t\trets, dev->dev_state);\n\t\t\tif (dev->dev_state != MEI_DEV_RESETTING &&\n\t\t\t    dev->dev_state != MEI_DEV_DISABLED &&\n\t\t\t    dev->dev_state != MEI_DEV_POWERING_DOWN &&\n\t\t\t    dev->dev_state != MEI_DEV_POWER_DOWN)\n\t\t\t\tschedule_work(&dev->reset_work);\n\t\t\tgoto end;\n\t\t}\n\t}\n\n\tdev->hbuf_is_ready = mei_hbuf_is_ready(dev);\n\n\t \n\tif (dev->pg_event != MEI_PG_EVENT_WAIT &&\n\t    dev->pg_event != MEI_PG_EVENT_RECEIVED) {\n\t\trets = mei_irq_write_handler(dev, &cmpl_list);\n\t\tdev->hbuf_is_ready = mei_hbuf_is_ready(dev);\n\t}\n\n\tmei_irq_compl_handler(dev, &cmpl_list);\n\nend:\n\tdev_dbg(dev->dev, \"interrupt thread end ret = %d\\n\", rets);\n\tmei_me_intr_enable(dev);\n\tmutex_unlock(&dev->device_lock);\n\treturn IRQ_HANDLED;\n}\nEXPORT_SYMBOL_GPL(mei_me_irq_thread_handler);\n\n#define MEI_POLLING_TIMEOUT_ACTIVE 100\n#define MEI_POLLING_TIMEOUT_IDLE   500\n\n \nint mei_me_polling_thread(void *_dev)\n{\n\tstruct mei_device *dev = _dev;\n\tirqreturn_t irq_ret;\n\tlong polling_timeout = MEI_POLLING_TIMEOUT_ACTIVE;\n\n\tdev_dbg(dev->dev, \"kernel thread is running\\n\");\n\twhile (!kthread_should_stop()) {\n\t\tstruct mei_me_hw *hw = to_me_hw(dev);\n\t\tu32 hcsr;\n\n\t\twait_event_timeout(hw->wait_active,\n\t\t\t\t   hw->is_active || kthread_should_stop(),\n\t\t\t\t   msecs_to_jiffies(MEI_POLLING_TIMEOUT_IDLE));\n\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\n\t\thcsr = mei_hcsr_read(dev);\n\t\tif (me_intr_src(hcsr)) {\n\t\t\tpolling_timeout = MEI_POLLING_TIMEOUT_ACTIVE;\n\t\t\tirq_ret = mei_me_irq_thread_handler(1, dev);\n\t\t\tif (irq_ret != IRQ_HANDLED)\n\t\t\t\tdev_err(dev->dev, \"irq_ret %d\\n\", irq_ret);\n\t\t} else {\n\t\t\t \n\t\t\tpolling_timeout = clamp_val(polling_timeout + MEI_POLLING_TIMEOUT_ACTIVE,\n\t\t\t\t\t\t    MEI_POLLING_TIMEOUT_ACTIVE,\n\t\t\t\t\t\t    MEI_POLLING_TIMEOUT_IDLE);\n\t\t}\n\n\t\tschedule_timeout_interruptible(msecs_to_jiffies(polling_timeout));\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mei_me_polling_thread);\n\nstatic const struct mei_hw_ops mei_me_hw_ops = {\n\n\t.trc_status = mei_me_trc_status,\n\t.fw_status = mei_me_fw_status,\n\t.pg_state  = mei_me_pg_state,\n\n\t.host_is_ready = mei_me_host_is_ready,\n\n\t.hw_is_ready = mei_me_hw_is_ready,\n\t.hw_reset = mei_me_hw_reset,\n\t.hw_config = mei_me_hw_config,\n\t.hw_start = mei_me_hw_start,\n\n\t.pg_in_transition = mei_me_pg_in_transition,\n\t.pg_is_enabled = mei_me_pg_is_enabled,\n\n\t.intr_clear = mei_me_intr_clear,\n\t.intr_enable = mei_me_intr_enable,\n\t.intr_disable = mei_me_intr_disable,\n\t.synchronize_irq = mei_me_synchronize_irq,\n\n\t.hbuf_free_slots = mei_me_hbuf_empty_slots,\n\t.hbuf_is_ready = mei_me_hbuf_is_empty,\n\t.hbuf_depth = mei_me_hbuf_depth,\n\n\t.write = mei_me_hbuf_write,\n\n\t.rdbuf_full_slots = mei_me_count_full_read_slots,\n\t.read_hdr = mei_me_mecbrw_read,\n\t.read = mei_me_read_slots\n};\n\n \nstatic bool mei_me_fw_type_nm(const struct pci_dev *pdev)\n{\n\tu32 reg;\n\tunsigned int devfn;\n\n\tdevfn = PCI_DEVFN(PCI_SLOT(pdev->devfn), 0);\n\tpci_bus_read_config_dword(pdev->bus, devfn, PCI_CFG_HFS_2, &reg);\n\ttrace_mei_pci_cfg_read(&pdev->dev, \"PCI_CFG_HFS_2\", PCI_CFG_HFS_2, reg);\n\t \n\treturn (reg & 0x600) == 0x200;\n}\n\n#define MEI_CFG_FW_NM                           \\\n\t.quirk_probe = mei_me_fw_type_nm\n\n \nstatic bool mei_me_fw_type_sps_4(const struct pci_dev *pdev)\n{\n\tu32 reg;\n\tunsigned int devfn;\n\n\tdevfn = PCI_DEVFN(PCI_SLOT(pdev->devfn), 0);\n\tpci_bus_read_config_dword(pdev->bus, devfn, PCI_CFG_HFS_1, &reg);\n\ttrace_mei_pci_cfg_read(&pdev->dev, \"PCI_CFG_HFS_1\", PCI_CFG_HFS_1, reg);\n\treturn (reg & PCI_CFG_HFS_1_OPMODE_MSK) == PCI_CFG_HFS_1_OPMODE_SPS;\n}\n\n#define MEI_CFG_FW_SPS_4                          \\\n\t.quirk_probe = mei_me_fw_type_sps_4\n\n \nstatic bool mei_me_fw_type_sps_ign(const struct pci_dev *pdev)\n{\n\tu32 reg;\n\tu32 fw_type;\n\tunsigned int devfn;\n\n\tdevfn = PCI_DEVFN(PCI_SLOT(pdev->devfn), 0);\n\tpci_bus_read_config_dword(pdev->bus, devfn, PCI_CFG_HFS_3, &reg);\n\ttrace_mei_pci_cfg_read(&pdev->dev, \"PCI_CFG_HFS_3\", PCI_CFG_HFS_3, reg);\n\tfw_type = (reg & PCI_CFG_HFS_3_FW_SKU_MSK);\n\n\tdev_dbg(&pdev->dev, \"fw type is %d\\n\", fw_type);\n\n\treturn fw_type == PCI_CFG_HFS_3_FW_SKU_IGN ||\n\t       fw_type == PCI_CFG_HFS_3_FW_SKU_SPS;\n}\n\n#define MEI_CFG_KIND_ITOUCH                     \\\n\t.kind = \"itouch\"\n\n#define MEI_CFG_TYPE_GSC                        \\\n\t.kind = \"gsc\"\n\n#define MEI_CFG_TYPE_GSCFI                      \\\n\t.kind = \"gscfi\"\n\n#define MEI_CFG_FW_SPS_IGN                      \\\n\t.quirk_probe = mei_me_fw_type_sps_ign\n\n#define MEI_CFG_FW_VER_SUPP                     \\\n\t.fw_ver_supported = 1\n\n#define MEI_CFG_ICH_HFS                      \\\n\t.fw_status.count = 0\n\n#define MEI_CFG_ICH10_HFS                        \\\n\t.fw_status.count = 1,                   \\\n\t.fw_status.status[0] = PCI_CFG_HFS_1\n\n#define MEI_CFG_PCH_HFS                         \\\n\t.fw_status.count = 2,                   \\\n\t.fw_status.status[0] = PCI_CFG_HFS_1,   \\\n\t.fw_status.status[1] = PCI_CFG_HFS_2\n\n#define MEI_CFG_PCH8_HFS                        \\\n\t.fw_status.count = 6,                   \\\n\t.fw_status.status[0] = PCI_CFG_HFS_1,   \\\n\t.fw_status.status[1] = PCI_CFG_HFS_2,   \\\n\t.fw_status.status[2] = PCI_CFG_HFS_3,   \\\n\t.fw_status.status[3] = PCI_CFG_HFS_4,   \\\n\t.fw_status.status[4] = PCI_CFG_HFS_5,   \\\n\t.fw_status.status[5] = PCI_CFG_HFS_6\n\n#define MEI_CFG_DMA_128 \\\n\t.dma_size[DMA_DSCR_HOST] = SZ_128K, \\\n\t.dma_size[DMA_DSCR_DEVICE] = SZ_128K, \\\n\t.dma_size[DMA_DSCR_CTRL] = PAGE_SIZE\n\n#define MEI_CFG_TRC \\\n\t.hw_trc_supported = 1\n\n \nstatic const struct mei_cfg mei_me_ich_cfg = {\n\tMEI_CFG_ICH_HFS,\n};\n\n \nstatic const struct mei_cfg mei_me_ich10_cfg = {\n\tMEI_CFG_ICH10_HFS,\n};\n\n \nstatic const struct mei_cfg mei_me_pch6_cfg = {\n\tMEI_CFG_PCH_HFS,\n};\n\n \nstatic const struct mei_cfg mei_me_pch7_cfg = {\n\tMEI_CFG_PCH_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n};\n\n \nstatic const struct mei_cfg mei_me_pch_cpt_pbg_cfg = {\n\tMEI_CFG_PCH_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n\tMEI_CFG_FW_NM,\n};\n\n \nstatic const struct mei_cfg mei_me_pch8_cfg = {\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n};\n\n \nstatic const struct mei_cfg mei_me_pch8_itouch_cfg = {\n\tMEI_CFG_KIND_ITOUCH,\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n};\n\n \nstatic const struct mei_cfg mei_me_pch8_sps_4_cfg = {\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n\tMEI_CFG_FW_SPS_4,\n};\n\n \nstatic const struct mei_cfg mei_me_pch12_sps_4_cfg = {\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n\tMEI_CFG_FW_SPS_4,\n};\n\n \nstatic const struct mei_cfg mei_me_pch12_cfg = {\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n\tMEI_CFG_DMA_128,\n};\n\n \nstatic const struct mei_cfg mei_me_pch12_sps_cfg = {\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n\tMEI_CFG_DMA_128,\n\tMEI_CFG_FW_SPS_IGN,\n};\n\n \nstatic const struct mei_cfg mei_me_pch12_itouch_sps_cfg = {\n\tMEI_CFG_KIND_ITOUCH,\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n\tMEI_CFG_FW_SPS_IGN,\n};\n\n \nstatic const struct mei_cfg mei_me_pch15_cfg = {\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n\tMEI_CFG_DMA_128,\n\tMEI_CFG_TRC,\n};\n\n \nstatic const struct mei_cfg mei_me_pch15_sps_cfg = {\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n\tMEI_CFG_DMA_128,\n\tMEI_CFG_TRC,\n\tMEI_CFG_FW_SPS_IGN,\n};\n\n \nstatic const struct mei_cfg mei_me_gsc_cfg = {\n\tMEI_CFG_TYPE_GSC,\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n};\n\n \nstatic const struct mei_cfg mei_me_gscfi_cfg = {\n\tMEI_CFG_TYPE_GSCFI,\n\tMEI_CFG_PCH8_HFS,\n\tMEI_CFG_FW_VER_SUPP,\n};\n\n \nstatic const struct mei_cfg *const mei_cfg_list[] = {\n\t[MEI_ME_UNDEF_CFG] = NULL,\n\t[MEI_ME_ICH_CFG] = &mei_me_ich_cfg,\n\t[MEI_ME_ICH10_CFG] = &mei_me_ich10_cfg,\n\t[MEI_ME_PCH6_CFG] = &mei_me_pch6_cfg,\n\t[MEI_ME_PCH7_CFG] = &mei_me_pch7_cfg,\n\t[MEI_ME_PCH_CPT_PBG_CFG] = &mei_me_pch_cpt_pbg_cfg,\n\t[MEI_ME_PCH8_CFG] = &mei_me_pch8_cfg,\n\t[MEI_ME_PCH8_ITOUCH_CFG] = &mei_me_pch8_itouch_cfg,\n\t[MEI_ME_PCH8_SPS_4_CFG] = &mei_me_pch8_sps_4_cfg,\n\t[MEI_ME_PCH12_CFG] = &mei_me_pch12_cfg,\n\t[MEI_ME_PCH12_SPS_4_CFG] = &mei_me_pch12_sps_4_cfg,\n\t[MEI_ME_PCH12_SPS_CFG] = &mei_me_pch12_sps_cfg,\n\t[MEI_ME_PCH12_SPS_ITOUCH_CFG] = &mei_me_pch12_itouch_sps_cfg,\n\t[MEI_ME_PCH15_CFG] = &mei_me_pch15_cfg,\n\t[MEI_ME_PCH15_SPS_CFG] = &mei_me_pch15_sps_cfg,\n\t[MEI_ME_GSC_CFG] = &mei_me_gsc_cfg,\n\t[MEI_ME_GSCFI_CFG] = &mei_me_gscfi_cfg,\n};\n\nconst struct mei_cfg *mei_me_get_cfg(kernel_ulong_t idx)\n{\n\tBUILD_BUG_ON(ARRAY_SIZE(mei_cfg_list) != MEI_ME_NUM_CFG);\n\n\tif (idx >= MEI_ME_NUM_CFG)\n\t\treturn NULL;\n\n\treturn mei_cfg_list[idx];\n}\nEXPORT_SYMBOL_GPL(mei_me_get_cfg);\n\n \nstruct mei_device *mei_me_dev_init(struct device *parent,\n\t\t\t\t   const struct mei_cfg *cfg, bool slow_fw)\n{\n\tstruct mei_device *dev;\n\tstruct mei_me_hw *hw;\n\tint i;\n\n\tdev = devm_kzalloc(parent, sizeof(*dev) + sizeof(*hw), GFP_KERNEL);\n\tif (!dev)\n\t\treturn NULL;\n\n\thw = to_me_hw(dev);\n\n\tfor (i = 0; i < DMA_DSCR_NUM; i++)\n\t\tdev->dr_dscr[i].size = cfg->dma_size[i];\n\n\tmei_device_init(dev, parent, slow_fw, &mei_me_hw_ops);\n\thw->cfg = cfg;\n\n\tdev->fw_f_fw_ver_supported = cfg->fw_ver_supported;\n\n\tdev->kind = cfg->kind;\n\n\treturn dev;\n}\nEXPORT_SYMBOL_GPL(mei_me_dev_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}