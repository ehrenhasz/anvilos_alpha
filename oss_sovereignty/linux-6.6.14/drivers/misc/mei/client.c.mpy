{
  "module_name": "client.c",
  "hash_id": "d24e76f81b6191967ddcff1d447235ec42f6e54d692acd2a368e2beef52e4ce3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/mei/client.c",
  "human_readable_source": "\n \n\n#include <linux/sched/signal.h>\n#include <linux/wait.h>\n#include <linux/delay.h>\n#include <linux/slab.h>\n#include <linux/pm_runtime.h>\n#include <linux/dma-mapping.h>\n\n#include <linux/mei.h>\n\n#include \"mei_dev.h\"\n#include \"hbm.h\"\n#include \"client.h\"\n\n \nvoid mei_me_cl_init(struct mei_me_client *me_cl)\n{\n\tINIT_LIST_HEAD(&me_cl->list);\n\tkref_init(&me_cl->refcnt);\n}\n\n \nstruct mei_me_client *mei_me_cl_get(struct mei_me_client *me_cl)\n{\n\tif (me_cl && kref_get_unless_zero(&me_cl->refcnt))\n\t\treturn me_cl;\n\n\treturn NULL;\n}\n\n \nstatic void mei_me_cl_release(struct kref *ref)\n{\n\tstruct mei_me_client *me_cl =\n\t\tcontainer_of(ref, struct mei_me_client, refcnt);\n\n\tkfree(me_cl);\n}\n\n \nvoid mei_me_cl_put(struct mei_me_client *me_cl)\n{\n\tif (me_cl)\n\t\tkref_put(&me_cl->refcnt, mei_me_cl_release);\n}\n\n \nstatic void __mei_me_cl_del(struct mei_device *dev, struct mei_me_client *me_cl)\n{\n\tif (!me_cl)\n\t\treturn;\n\n\tlist_del_init(&me_cl->list);\n\tmei_me_cl_put(me_cl);\n}\n\n \nvoid mei_me_cl_del(struct mei_device *dev, struct mei_me_client *me_cl)\n{\n\tdown_write(&dev->me_clients_rwsem);\n\t__mei_me_cl_del(dev, me_cl);\n\tup_write(&dev->me_clients_rwsem);\n}\n\n \nvoid mei_me_cl_add(struct mei_device *dev, struct mei_me_client *me_cl)\n{\n\tdown_write(&dev->me_clients_rwsem);\n\tlist_add(&me_cl->list, &dev->me_clients);\n\tup_write(&dev->me_clients_rwsem);\n}\n\n \nstatic struct mei_me_client *__mei_me_cl_by_uuid(struct mei_device *dev,\n\t\t\t\t\tconst uuid_le *uuid)\n{\n\tstruct mei_me_client *me_cl;\n\tconst uuid_le *pn;\n\n\tWARN_ON(!rwsem_is_locked(&dev->me_clients_rwsem));\n\n\tlist_for_each_entry(me_cl, &dev->me_clients, list) {\n\t\tpn = &me_cl->props.protocol_name;\n\t\tif (uuid_le_cmp(*uuid, *pn) == 0)\n\t\t\treturn mei_me_cl_get(me_cl);\n\t}\n\n\treturn NULL;\n}\n\n \nstruct mei_me_client *mei_me_cl_by_uuid(struct mei_device *dev,\n\t\t\t\t\tconst uuid_le *uuid)\n{\n\tstruct mei_me_client *me_cl;\n\n\tdown_read(&dev->me_clients_rwsem);\n\tme_cl = __mei_me_cl_by_uuid(dev, uuid);\n\tup_read(&dev->me_clients_rwsem);\n\n\treturn me_cl;\n}\n\n \nstruct mei_me_client *mei_me_cl_by_id(struct mei_device *dev, u8 client_id)\n{\n\n\tstruct mei_me_client *__me_cl, *me_cl = NULL;\n\n\tdown_read(&dev->me_clients_rwsem);\n\tlist_for_each_entry(__me_cl, &dev->me_clients, list) {\n\t\tif (__me_cl->client_id == client_id) {\n\t\t\tme_cl = mei_me_cl_get(__me_cl);\n\t\t\tbreak;\n\t\t}\n\t}\n\tup_read(&dev->me_clients_rwsem);\n\n\treturn me_cl;\n}\n\n \nstatic struct mei_me_client *__mei_me_cl_by_uuid_id(struct mei_device *dev,\n\t\t\t\t\t   const uuid_le *uuid, u8 client_id)\n{\n\tstruct mei_me_client *me_cl;\n\tconst uuid_le *pn;\n\n\tWARN_ON(!rwsem_is_locked(&dev->me_clients_rwsem));\n\n\tlist_for_each_entry(me_cl, &dev->me_clients, list) {\n\t\tpn = &me_cl->props.protocol_name;\n\t\tif (uuid_le_cmp(*uuid, *pn) == 0 &&\n\t\t    me_cl->client_id == client_id)\n\t\t\treturn mei_me_cl_get(me_cl);\n\t}\n\n\treturn NULL;\n}\n\n\n \nstruct mei_me_client *mei_me_cl_by_uuid_id(struct mei_device *dev,\n\t\t\t\t\t   const uuid_le *uuid, u8 client_id)\n{\n\tstruct mei_me_client *me_cl;\n\n\tdown_read(&dev->me_clients_rwsem);\n\tme_cl = __mei_me_cl_by_uuid_id(dev, uuid, client_id);\n\tup_read(&dev->me_clients_rwsem);\n\n\treturn me_cl;\n}\n\n \nvoid mei_me_cl_rm_by_uuid(struct mei_device *dev, const uuid_le *uuid)\n{\n\tstruct mei_me_client *me_cl;\n\n\tdev_dbg(dev->dev, \"remove %pUl\\n\", uuid);\n\n\tdown_write(&dev->me_clients_rwsem);\n\tme_cl = __mei_me_cl_by_uuid(dev, uuid);\n\t__mei_me_cl_del(dev, me_cl);\n\tmei_me_cl_put(me_cl);\n\tup_write(&dev->me_clients_rwsem);\n}\n\n \nvoid mei_me_cl_rm_by_uuid_id(struct mei_device *dev, const uuid_le *uuid, u8 id)\n{\n\tstruct mei_me_client *me_cl;\n\n\tdev_dbg(dev->dev, \"remove %pUl %d\\n\", uuid, id);\n\n\tdown_write(&dev->me_clients_rwsem);\n\tme_cl = __mei_me_cl_by_uuid_id(dev, uuid, id);\n\t__mei_me_cl_del(dev, me_cl);\n\tmei_me_cl_put(me_cl);\n\tup_write(&dev->me_clients_rwsem);\n}\n\n \nvoid mei_me_cl_rm_all(struct mei_device *dev)\n{\n\tstruct mei_me_client *me_cl, *next;\n\n\tdown_write(&dev->me_clients_rwsem);\n\tlist_for_each_entry_safe(me_cl, next, &dev->me_clients, list)\n\t\t__mei_me_cl_del(dev, me_cl);\n\tup_write(&dev->me_clients_rwsem);\n}\n\n \nvoid mei_io_cb_free(struct mei_cl_cb *cb)\n{\n\tif (cb == NULL)\n\t\treturn;\n\n\tlist_del(&cb->list);\n\tkfree(cb->buf.data);\n\tkfree(cb->ext_hdr);\n\tkfree(cb);\n}\n\n \nstatic inline void mei_tx_cb_enqueue(struct mei_cl_cb *cb,\n\t\t\t\t     struct list_head *head)\n{\n\tlist_add_tail(&cb->list, head);\n\tcb->cl->tx_cb_queued++;\n}\n\n \nstatic inline void mei_tx_cb_dequeue(struct mei_cl_cb *cb)\n{\n\tif (!WARN_ON(cb->cl->tx_cb_queued == 0))\n\t\tcb->cl->tx_cb_queued--;\n\n\tmei_io_cb_free(cb);\n}\n\n \nstatic void mei_cl_set_read_by_fp(const struct mei_cl *cl,\n\t\t\t\t  const struct file *fp)\n{\n\tstruct mei_cl_vtag *cl_vtag;\n\n\tlist_for_each_entry(cl_vtag, &cl->vtag_map, list) {\n\t\tif (cl_vtag->fp == fp) {\n\t\t\tcl_vtag->pending_read = true;\n\t\t\treturn;\n\t\t}\n\t}\n}\n\n \nstatic struct mei_cl_cb *mei_io_cb_init(struct mei_cl *cl,\n\t\t\t\t\tenum mei_cb_file_ops type,\n\t\t\t\t\tconst struct file *fp)\n{\n\tstruct mei_cl_cb *cb;\n\n\tcb = kzalloc(sizeof(*cb), GFP_KERNEL);\n\tif (!cb)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&cb->list);\n\tcb->fp = fp;\n\tcb->cl = cl;\n\tcb->buf_idx = 0;\n\tcb->fop_type = type;\n\tcb->vtag = 0;\n\tcb->ext_hdr = NULL;\n\n\treturn cb;\n}\n\n \nstatic void mei_io_list_flush_cl(struct list_head *head,\n\t\t\t\t const struct mei_cl *cl)\n{\n\tstruct mei_cl_cb *cb, *next;\n\n\tlist_for_each_entry_safe(cb, next, head, list) {\n\t\tif (cl == cb->cl) {\n\t\t\tlist_del_init(&cb->list);\n\t\t\tif (cb->fop_type == MEI_FOP_READ)\n\t\t\t\tmei_io_cb_free(cb);\n\t\t}\n\t}\n}\n\n \nstatic void mei_io_tx_list_free_cl(struct list_head *head,\n\t\t\t\t   const struct mei_cl *cl,\n\t\t\t\t   const struct file *fp)\n{\n\tstruct mei_cl_cb *cb, *next;\n\n\tlist_for_each_entry_safe(cb, next, head, list) {\n\t\tif (cl == cb->cl && (!fp || fp == cb->fp))\n\t\t\tmei_tx_cb_dequeue(cb);\n\t}\n}\n\n \nstatic void mei_io_list_free_fp(struct list_head *head, const struct file *fp)\n{\n\tstruct mei_cl_cb *cb, *next;\n\n\tlist_for_each_entry_safe(cb, next, head, list)\n\t\tif (!fp || fp == cb->fp)\n\t\t\tmei_io_cb_free(cb);\n}\n\n \nstatic void mei_cl_free_pending(struct mei_cl *cl)\n{\n\tstruct mei_cl_cb *cb;\n\n\tcb = list_first_entry_or_null(&cl->rd_pending, struct mei_cl_cb, list);\n\tmei_io_cb_free(cb);\n}\n\n \nstruct mei_cl_cb *mei_cl_alloc_cb(struct mei_cl *cl, size_t length,\n\t\t\t\t  enum mei_cb_file_ops fop_type,\n\t\t\t\t  const struct file *fp)\n{\n\tstruct mei_cl_cb *cb;\n\n\tcb = mei_io_cb_init(cl, fop_type, fp);\n\tif (!cb)\n\t\treturn NULL;\n\n\tif (length == 0)\n\t\treturn cb;\n\n\tcb->buf.data = kmalloc(roundup(length, MEI_SLOT_SIZE), GFP_KERNEL);\n\tif (!cb->buf.data) {\n\t\tmei_io_cb_free(cb);\n\t\treturn NULL;\n\t}\n\tcb->buf.size = length;\n\n\treturn cb;\n}\n\n \nstruct mei_cl_cb *mei_cl_enqueue_ctrl_wr_cb(struct mei_cl *cl, size_t length,\n\t\t\t\t\t    enum mei_cb_file_ops fop_type,\n\t\t\t\t\t    const struct file *fp)\n{\n\tstruct mei_cl_cb *cb;\n\n\t \n\tif (length)\n\t\tlength = max_t(size_t, length, mei_cl_mtu(cl));\n\n\tcb = mei_cl_alloc_cb(cl, length, fop_type, fp);\n\tif (!cb)\n\t\treturn NULL;\n\n\tlist_add_tail(&cb->list, &cl->dev->ctrl_wr_list);\n\treturn cb;\n}\n\n \nstruct mei_cl_cb *mei_cl_read_cb(struct mei_cl *cl, const struct file *fp)\n{\n\tstruct mei_cl_cb *cb;\n\tstruct mei_cl_cb *ret_cb = NULL;\n\n\tspin_lock(&cl->rd_completed_lock);\n\tlist_for_each_entry(cb, &cl->rd_completed, list)\n\t\tif (!fp || fp == cb->fp) {\n\t\t\tret_cb = cb;\n\t\t\tbreak;\n\t\t}\n\tspin_unlock(&cl->rd_completed_lock);\n\treturn ret_cb;\n}\n\n \nint mei_cl_flush_queues(struct mei_cl *cl, const struct file *fp)\n{\n\tstruct mei_device *dev;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -EINVAL;\n\n\tdev = cl->dev;\n\n\tcl_dbg(dev, cl, \"remove list entry belonging to cl\\n\");\n\tmei_io_tx_list_free_cl(&cl->dev->write_list, cl, fp);\n\tmei_io_tx_list_free_cl(&cl->dev->write_waiting_list, cl, fp);\n\t \n\tif (!fp) {\n\t\tmei_io_list_flush_cl(&cl->dev->ctrl_wr_list, cl);\n\t\tmei_io_list_flush_cl(&cl->dev->ctrl_rd_list, cl);\n\t\tmei_cl_free_pending(cl);\n\t}\n\tspin_lock(&cl->rd_completed_lock);\n\tmei_io_list_free_fp(&cl->rd_completed, fp);\n\tspin_unlock(&cl->rd_completed_lock);\n\n\treturn 0;\n}\n\n \nstatic void mei_cl_init(struct mei_cl *cl, struct mei_device *dev)\n{\n\tmemset(cl, 0, sizeof(*cl));\n\tinit_waitqueue_head(&cl->wait);\n\tinit_waitqueue_head(&cl->rx_wait);\n\tinit_waitqueue_head(&cl->tx_wait);\n\tinit_waitqueue_head(&cl->ev_wait);\n\tINIT_LIST_HEAD(&cl->vtag_map);\n\tspin_lock_init(&cl->rd_completed_lock);\n\tINIT_LIST_HEAD(&cl->rd_completed);\n\tINIT_LIST_HEAD(&cl->rd_pending);\n\tINIT_LIST_HEAD(&cl->link);\n\tcl->writing_state = MEI_IDLE;\n\tcl->state = MEI_FILE_UNINITIALIZED;\n\tcl->dev = dev;\n}\n\n \nstruct mei_cl *mei_cl_allocate(struct mei_device *dev)\n{\n\tstruct mei_cl *cl;\n\n\tcl = kmalloc(sizeof(*cl), GFP_KERNEL);\n\tif (!cl)\n\t\treturn NULL;\n\n\tmei_cl_init(cl, dev);\n\n\treturn cl;\n}\n\n \nint mei_cl_link(struct mei_cl *cl)\n{\n\tstruct mei_device *dev;\n\tint id;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -EINVAL;\n\n\tdev = cl->dev;\n\n\tid = find_first_zero_bit(dev->host_clients_map, MEI_CLIENTS_MAX);\n\tif (id >= MEI_CLIENTS_MAX) {\n\t\tdev_err(dev->dev, \"id exceeded %d\", MEI_CLIENTS_MAX);\n\t\treturn -EMFILE;\n\t}\n\n\tif (dev->open_handle_count >= MEI_MAX_OPEN_HANDLE_COUNT) {\n\t\tdev_err(dev->dev, \"open_handle_count exceeded %d\",\n\t\t\tMEI_MAX_OPEN_HANDLE_COUNT);\n\t\treturn -EMFILE;\n\t}\n\n\tdev->open_handle_count++;\n\n\tcl->host_client_id = id;\n\tlist_add_tail(&cl->link, &dev->file_list);\n\n\tset_bit(id, dev->host_clients_map);\n\n\tcl->state = MEI_FILE_INITIALIZING;\n\n\tcl_dbg(dev, cl, \"link cl\\n\");\n\treturn 0;\n}\n\n \nint mei_cl_unlink(struct mei_cl *cl)\n{\n\tstruct mei_device *dev;\n\n\t \n\tif (!cl)\n\t\treturn 0;\n\n\tif (WARN_ON(!cl->dev))\n\t\treturn 0;\n\n\tdev = cl->dev;\n\n\tcl_dbg(dev, cl, \"unlink client\");\n\n\tif (cl->state == MEI_FILE_UNINITIALIZED)\n\t\treturn 0;\n\n\tif (dev->open_handle_count > 0)\n\t\tdev->open_handle_count--;\n\n\t \n\tif (cl->host_client_id)\n\t\tclear_bit(cl->host_client_id, dev->host_clients_map);\n\n\tlist_del_init(&cl->link);\n\n\tcl->state = MEI_FILE_UNINITIALIZED;\n\tcl->writing_state = MEI_IDLE;\n\n\tWARN_ON(!list_empty(&cl->rd_completed) ||\n\t\t!list_empty(&cl->rd_pending) ||\n\t\t!list_empty(&cl->link));\n\n\treturn 0;\n}\n\nvoid mei_host_client_init(struct mei_device *dev)\n{\n\tmei_set_devstate(dev, MEI_DEV_ENABLED);\n\tdev->reset_count = 0;\n\n\tschedule_work(&dev->bus_rescan_work);\n\n\tpm_runtime_mark_last_busy(dev->dev);\n\tdev_dbg(dev->dev, \"rpm: autosuspend\\n\");\n\tpm_request_autosuspend(dev->dev);\n}\n\n \nbool mei_hbuf_acquire(struct mei_device *dev)\n{\n\tif (mei_pg_state(dev) == MEI_PG_ON ||\n\t    mei_pg_in_transition(dev)) {\n\t\tdev_dbg(dev->dev, \"device is in pg\\n\");\n\t\treturn false;\n\t}\n\n\tif (!dev->hbuf_is_ready) {\n\t\tdev_dbg(dev->dev, \"hbuf is not ready\\n\");\n\t\treturn false;\n\t}\n\n\tdev->hbuf_is_ready = false;\n\n\treturn true;\n}\n\n \nstatic void mei_cl_wake_all(struct mei_cl *cl)\n{\n\tstruct mei_device *dev = cl->dev;\n\n\t \n\tif (waitqueue_active(&cl->rx_wait)) {\n\t\tcl_dbg(dev, cl, \"Waking up reading client!\\n\");\n\t\twake_up_interruptible(&cl->rx_wait);\n\t}\n\t \n\tif (waitqueue_active(&cl->tx_wait)) {\n\t\tcl_dbg(dev, cl, \"Waking up writing client!\\n\");\n\t\twake_up_interruptible(&cl->tx_wait);\n\t}\n\t \n\tif (waitqueue_active(&cl->ev_wait)) {\n\t\tcl_dbg(dev, cl, \"Waking up waiting for event clients!\\n\");\n\t\twake_up_interruptible(&cl->ev_wait);\n\t}\n\t \n\tif (waitqueue_active(&cl->wait)) {\n\t\tcl_dbg(dev, cl, \"Waking up ctrl write clients!\\n\");\n\t\twake_up(&cl->wait);\n\t}\n}\n\n \nstatic void mei_cl_set_disconnected(struct mei_cl *cl)\n{\n\tstruct mei_device *dev = cl->dev;\n\n\tif (cl->state == MEI_FILE_DISCONNECTED ||\n\t    cl->state <= MEI_FILE_INITIALIZING)\n\t\treturn;\n\n\tcl->state = MEI_FILE_DISCONNECTED;\n\tmei_io_tx_list_free_cl(&dev->write_list, cl, NULL);\n\tmei_io_tx_list_free_cl(&dev->write_waiting_list, cl, NULL);\n\tmei_io_list_flush_cl(&dev->ctrl_rd_list, cl);\n\tmei_io_list_flush_cl(&dev->ctrl_wr_list, cl);\n\tmei_cl_wake_all(cl);\n\tcl->rx_flow_ctrl_creds = 0;\n\tcl->tx_flow_ctrl_creds = 0;\n\tcl->timer_count = 0;\n\n\tif (!cl->me_cl)\n\t\treturn;\n\n\tif (!WARN_ON(cl->me_cl->connect_count == 0))\n\t\tcl->me_cl->connect_count--;\n\n\tif (cl->me_cl->connect_count == 0)\n\t\tcl->me_cl->tx_flow_ctrl_creds = 0;\n\n\tmei_me_cl_put(cl->me_cl);\n\tcl->me_cl = NULL;\n}\n\nstatic int mei_cl_set_connecting(struct mei_cl *cl, struct mei_me_client *me_cl)\n{\n\tif (!mei_me_cl_get(me_cl))\n\t\treturn -ENOENT;\n\n\t \n\tif (me_cl->props.fixed_address) {\n\t\tif (me_cl->connect_count) {\n\t\t\tmei_me_cl_put(me_cl);\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\tcl->me_cl = me_cl;\n\tcl->state = MEI_FILE_CONNECTING;\n\tcl->me_cl->connect_count++;\n\n\treturn 0;\n}\n\n \nstatic int mei_cl_send_disconnect(struct mei_cl *cl, struct mei_cl_cb *cb)\n{\n\tstruct mei_device *dev;\n\tint ret;\n\n\tdev = cl->dev;\n\n\tret = mei_hbm_cl_disconnect_req(dev, cl);\n\tcl->status = ret;\n\tif (ret) {\n\t\tcl->state = MEI_FILE_DISCONNECT_REPLY;\n\t\treturn ret;\n\t}\n\n\tlist_move_tail(&cb->list, &dev->ctrl_rd_list);\n\tcl->timer_count = dev->timeouts.connect;\n\tmei_schedule_stall_timer(dev);\n\n\treturn 0;\n}\n\n \nint mei_cl_irq_disconnect(struct mei_cl *cl, struct mei_cl_cb *cb,\n\t\t\t  struct list_head *cmpl_list)\n{\n\tstruct mei_device *dev = cl->dev;\n\tu32 msg_slots;\n\tint slots;\n\tint ret;\n\n\tmsg_slots = mei_hbm2slots(sizeof(struct hbm_client_connect_request));\n\tslots = mei_hbuf_empty_slots(dev);\n\tif (slots < 0)\n\t\treturn -EOVERFLOW;\n\n\tif ((u32)slots < msg_slots)\n\t\treturn -EMSGSIZE;\n\n\tret = mei_cl_send_disconnect(cl, cb);\n\tif (ret)\n\t\tlist_move_tail(&cb->list, cmpl_list);\n\n\treturn ret;\n}\n\n \nstatic int __mei_cl_disconnect(struct mei_cl *cl)\n{\n\tstruct mei_device *dev;\n\tstruct mei_cl_cb *cb;\n\tint rets;\n\n\tdev = cl->dev;\n\n\tcl->state = MEI_FILE_DISCONNECTING;\n\n\tcb = mei_cl_enqueue_ctrl_wr_cb(cl, 0, MEI_FOP_DISCONNECT, NULL);\n\tif (!cb) {\n\t\trets = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (mei_hbuf_acquire(dev)) {\n\t\trets = mei_cl_send_disconnect(cl, cb);\n\t\tif (rets) {\n\t\t\tcl_err(dev, cl, \"failed to disconnect.\\n\");\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(cl->wait,\n\t\t\t   cl->state == MEI_FILE_DISCONNECT_REPLY ||\n\t\t\t   cl->state == MEI_FILE_DISCONNECTED,\n\t\t\t   dev->timeouts.cl_connect);\n\tmutex_lock(&dev->device_lock);\n\n\trets = cl->status;\n\tif (cl->state != MEI_FILE_DISCONNECT_REPLY &&\n\t    cl->state != MEI_FILE_DISCONNECTED) {\n\t\tcl_dbg(dev, cl, \"timeout on disconnect from FW client.\\n\");\n\t\trets = -ETIME;\n\t}\n\nout:\n\t \n\tmei_cl_set_disconnected(cl);\n\tif (!rets)\n\t\tcl_dbg(dev, cl, \"successfully disconnected from FW client.\\n\");\n\n\tmei_io_cb_free(cb);\n\treturn rets;\n}\n\n \nint mei_cl_disconnect(struct mei_cl *cl)\n{\n\tstruct mei_device *dev;\n\tint rets;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tcl_dbg(dev, cl, \"disconnecting\");\n\n\tif (!mei_cl_is_connected(cl))\n\t\treturn 0;\n\n\tif (mei_cl_is_fixed_address(cl)) {\n\t\tmei_cl_set_disconnected(cl);\n\t\treturn 0;\n\t}\n\n\tif (dev->dev_state == MEI_DEV_POWERING_DOWN ||\n\t    dev->dev_state == MEI_DEV_POWER_DOWN) {\n\t\tcl_dbg(dev, cl, \"Device is powering down, don't bother with disconnection\\n\");\n\t\tmei_cl_set_disconnected(cl);\n\t\treturn 0;\n\t}\n\n\trets = pm_runtime_get(dev->dev);\n\tif (rets < 0 && rets != -EINPROGRESS) {\n\t\tpm_runtime_put_noidle(dev->dev);\n\t\tcl_err(dev, cl, \"rpm: get failed %d\\n\", rets);\n\t\treturn rets;\n\t}\n\n\trets = __mei_cl_disconnect(cl);\n\n\tcl_dbg(dev, cl, \"rpm: autosuspend\\n\");\n\tpm_runtime_mark_last_busy(dev->dev);\n\tpm_runtime_put_autosuspend(dev->dev);\n\n\treturn rets;\n}\n\n\n \nstatic bool mei_cl_is_other_connecting(struct mei_cl *cl)\n{\n\tstruct mei_device *dev;\n\tstruct mei_cl_cb *cb;\n\n\tdev = cl->dev;\n\n\tlist_for_each_entry(cb, &dev->ctrl_rd_list, list) {\n\t\tif (cb->fop_type == MEI_FOP_CONNECT &&\n\t\t    mei_cl_me_id(cl) == mei_cl_me_id(cb->cl))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nstatic int mei_cl_send_connect(struct mei_cl *cl, struct mei_cl_cb *cb)\n{\n\tstruct mei_device *dev;\n\tint ret;\n\n\tdev = cl->dev;\n\n\tret = mei_hbm_cl_connect_req(dev, cl);\n\tcl->status = ret;\n\tif (ret) {\n\t\tcl->state = MEI_FILE_DISCONNECT_REPLY;\n\t\treturn ret;\n\t}\n\n\tlist_move_tail(&cb->list, &dev->ctrl_rd_list);\n\tcl->timer_count = dev->timeouts.connect;\n\tmei_schedule_stall_timer(dev);\n\treturn 0;\n}\n\n \nint mei_cl_irq_connect(struct mei_cl *cl, struct mei_cl_cb *cb,\n\t\t       struct list_head *cmpl_list)\n{\n\tstruct mei_device *dev = cl->dev;\n\tu32 msg_slots;\n\tint slots;\n\tint rets;\n\n\tif (mei_cl_is_other_connecting(cl))\n\t\treturn 0;\n\n\tmsg_slots = mei_hbm2slots(sizeof(struct hbm_client_connect_request));\n\tslots = mei_hbuf_empty_slots(dev);\n\tif (slots < 0)\n\t\treturn -EOVERFLOW;\n\n\tif ((u32)slots < msg_slots)\n\t\treturn -EMSGSIZE;\n\n\trets = mei_cl_send_connect(cl, cb);\n\tif (rets)\n\t\tlist_move_tail(&cb->list, cmpl_list);\n\n\treturn rets;\n}\n\n \nint mei_cl_connect(struct mei_cl *cl, struct mei_me_client *me_cl,\n\t\t   const struct file *fp)\n{\n\tstruct mei_device *dev;\n\tstruct mei_cl_cb *cb;\n\tint rets;\n\n\tif (WARN_ON(!cl || !cl->dev || !me_cl))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\trets = mei_cl_set_connecting(cl, me_cl);\n\tif (rets)\n\t\tgoto nortpm;\n\n\tif (mei_cl_is_fixed_address(cl)) {\n\t\tcl->state = MEI_FILE_CONNECTED;\n\t\trets = 0;\n\t\tgoto nortpm;\n\t}\n\n\trets = pm_runtime_get(dev->dev);\n\tif (rets < 0 && rets != -EINPROGRESS) {\n\t\tpm_runtime_put_noidle(dev->dev);\n\t\tcl_err(dev, cl, \"rpm: get failed %d\\n\", rets);\n\t\tgoto nortpm;\n\t}\n\n\tcb = mei_cl_enqueue_ctrl_wr_cb(cl, 0, MEI_FOP_CONNECT, fp);\n\tif (!cb) {\n\t\trets = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t \n\tif (!mei_cl_is_other_connecting(cl) && mei_hbuf_acquire(dev)) {\n\t\trets = mei_cl_send_connect(cl, cb);\n\t\tif (rets)\n\t\t\tgoto out;\n\t}\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(cl->wait,\n\t\t\t(cl->state == MEI_FILE_CONNECTED ||\n\t\t\t cl->state == MEI_FILE_DISCONNECTED ||\n\t\t\t cl->state == MEI_FILE_DISCONNECT_REQUIRED ||\n\t\t\t cl->state == MEI_FILE_DISCONNECT_REPLY),\n\t\t\tdev->timeouts.cl_connect);\n\tmutex_lock(&dev->device_lock);\n\n\tif (!mei_cl_is_connected(cl)) {\n\t\tif (cl->state == MEI_FILE_DISCONNECT_REQUIRED) {\n\t\t\tmei_io_list_flush_cl(&dev->ctrl_rd_list, cl);\n\t\t\tmei_io_list_flush_cl(&dev->ctrl_wr_list, cl);\n\t\t\t  \n\t\t\t__mei_cl_disconnect(cl);\n\t\t\trets = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tif (!cl->status)\n\t\t\tcl->status = -EFAULT;\n\t}\n\n\trets = cl->status;\nout:\n\tcl_dbg(dev, cl, \"rpm: autosuspend\\n\");\n\tpm_runtime_mark_last_busy(dev->dev);\n\tpm_runtime_put_autosuspend(dev->dev);\n\n\tmei_io_cb_free(cb);\n\nnortpm:\n\tif (!mei_cl_is_connected(cl))\n\t\tmei_cl_set_disconnected(cl);\n\n\treturn rets;\n}\n\n \nstruct mei_cl *mei_cl_alloc_linked(struct mei_device *dev)\n{\n\tstruct mei_cl *cl;\n\tint ret;\n\n\tcl = mei_cl_allocate(dev);\n\tif (!cl) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tret = mei_cl_link(cl);\n\tif (ret)\n\t\tgoto err;\n\n\treturn cl;\nerr:\n\tkfree(cl);\n\treturn ERR_PTR(ret);\n}\n\n \nstatic int mei_cl_tx_flow_ctrl_creds(struct mei_cl *cl)\n{\n\tif (WARN_ON(!cl || !cl->me_cl))\n\t\treturn -EINVAL;\n\n\tif (cl->tx_flow_ctrl_creds > 0)\n\t\treturn 1;\n\n\tif (mei_cl_is_fixed_address(cl))\n\t\treturn 1;\n\n\tif (mei_cl_is_single_recv_buf(cl)) {\n\t\tif (cl->me_cl->tx_flow_ctrl_creds > 0)\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nstatic int mei_cl_tx_flow_ctrl_creds_reduce(struct mei_cl *cl)\n{\n\tif (WARN_ON(!cl || !cl->me_cl))\n\t\treturn -EINVAL;\n\n\tif (mei_cl_is_fixed_address(cl))\n\t\treturn 0;\n\n\tif (mei_cl_is_single_recv_buf(cl)) {\n\t\tif (WARN_ON(cl->me_cl->tx_flow_ctrl_creds <= 0))\n\t\t\treturn -EINVAL;\n\t\tcl->me_cl->tx_flow_ctrl_creds--;\n\t} else {\n\t\tif (WARN_ON(cl->tx_flow_ctrl_creds <= 0))\n\t\t\treturn -EINVAL;\n\t\tcl->tx_flow_ctrl_creds--;\n\t}\n\treturn 0;\n}\n\n \nstruct mei_cl_vtag *mei_cl_vtag_alloc(struct file *fp, u8 vtag)\n{\n\tstruct mei_cl_vtag *cl_vtag;\n\n\tcl_vtag = kzalloc(sizeof(*cl_vtag), GFP_KERNEL);\n\tif (!cl_vtag)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tINIT_LIST_HEAD(&cl_vtag->list);\n\tcl_vtag->vtag = vtag;\n\tcl_vtag->fp = fp;\n\n\treturn cl_vtag;\n}\n\n \nconst struct file *mei_cl_fp_by_vtag(const struct mei_cl *cl, u8 vtag)\n{\n\tstruct mei_cl_vtag *vtag_l;\n\n\tlist_for_each_entry(vtag_l, &cl->vtag_map, list)\n\t\t \n\t\tif ((cl->cldev && mei_cldev_enabled(cl->cldev)) ||\n\t\t    vtag_l->vtag == vtag)\n\t\t\treturn vtag_l->fp;\n\n\treturn ERR_PTR(-ENOENT);\n}\n\n \nstatic void mei_cl_reset_read_by_vtag(const struct mei_cl *cl, u8 vtag)\n{\n\tstruct mei_cl_vtag *vtag_l;\n\n\tlist_for_each_entry(vtag_l, &cl->vtag_map, list) {\n\t\t \n\t\tif ((cl->cldev && mei_cldev_enabled(cl->cldev)) ||\n\t\t    vtag_l->vtag == vtag) {\n\t\t\tvtag_l->pending_read = false;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nstatic void mei_cl_read_vtag_add_fc(struct mei_cl *cl)\n{\n\tstruct mei_cl_vtag *cl_vtag;\n\n\tlist_for_each_entry(cl_vtag, &cl->vtag_map, list) {\n\t\tif (cl_vtag->pending_read) {\n\t\t\tif (mei_cl_enqueue_ctrl_wr_cb(cl,\n\t\t\t\t\t\t      mei_cl_mtu(cl),\n\t\t\t\t\t\t      MEI_FOP_READ,\n\t\t\t\t\t\t      cl_vtag->fp))\n\t\t\t\tcl->rx_flow_ctrl_creds++;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nint mei_cl_vt_support_check(const struct mei_cl *cl)\n{\n\tstruct mei_device *dev = cl->dev;\n\n\tif (!dev->hbm_f_vt_supported)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!cl->me_cl)\n\t\treturn 0;\n\n\treturn cl->me_cl->props.vt_supported ? 0 : -EOPNOTSUPP;\n}\n\n \nvoid mei_cl_add_rd_completed(struct mei_cl *cl, struct mei_cl_cb *cb)\n{\n\tconst struct file *fp;\n\n\tif (!mei_cl_vt_support_check(cl)) {\n\t\tfp = mei_cl_fp_by_vtag(cl, cb->vtag);\n\t\tif (IS_ERR(fp)) {\n\t\t\t \n\t\t\tmei_io_cb_free(cb);\n\t\t\treturn;\n\t\t}\n\t\tcb->fp = fp;\n\t\tmei_cl_reset_read_by_vtag(cl, cb->vtag);\n\t\tmei_cl_read_vtag_add_fc(cl);\n\t}\n\n\tspin_lock(&cl->rd_completed_lock);\n\tlist_add_tail(&cb->list, &cl->rd_completed);\n\tspin_unlock(&cl->rd_completed_lock);\n}\n\n \nvoid mei_cl_del_rd_completed(struct mei_cl *cl, struct mei_cl_cb *cb)\n{\n\tspin_lock(&cl->rd_completed_lock);\n\tmei_io_cb_free(cb);\n\tspin_unlock(&cl->rd_completed_lock);\n}\n\n \nu8 mei_cl_notify_fop2req(enum mei_cb_file_ops fop)\n{\n\tif (fop == MEI_FOP_NOTIFY_START)\n\t\treturn MEI_HBM_NOTIFICATION_START;\n\telse\n\t\treturn MEI_HBM_NOTIFICATION_STOP;\n}\n\n \nenum mei_cb_file_ops mei_cl_notify_req2fop(u8 req)\n{\n\tif (req == MEI_HBM_NOTIFICATION_START)\n\t\treturn MEI_FOP_NOTIFY_START;\n\telse\n\t\treturn MEI_FOP_NOTIFY_STOP;\n}\n\n \nint mei_cl_irq_notify(struct mei_cl *cl, struct mei_cl_cb *cb,\n\t\t      struct list_head *cmpl_list)\n{\n\tstruct mei_device *dev = cl->dev;\n\tu32 msg_slots;\n\tint slots;\n\tint ret;\n\tbool request;\n\n\tmsg_slots = mei_hbm2slots(sizeof(struct hbm_client_connect_request));\n\tslots = mei_hbuf_empty_slots(dev);\n\tif (slots < 0)\n\t\treturn -EOVERFLOW;\n\n\tif ((u32)slots < msg_slots)\n\t\treturn -EMSGSIZE;\n\n\trequest = mei_cl_notify_fop2req(cb->fop_type);\n\tret = mei_hbm_cl_notify_req(dev, cl, request);\n\tif (ret) {\n\t\tcl->status = ret;\n\t\tlist_move_tail(&cb->list, cmpl_list);\n\t\treturn ret;\n\t}\n\n\tlist_move_tail(&cb->list, &dev->ctrl_rd_list);\n\treturn 0;\n}\n\n \nint mei_cl_notify_request(struct mei_cl *cl,\n\t\t\t  const struct file *fp, u8 request)\n{\n\tstruct mei_device *dev;\n\tstruct mei_cl_cb *cb;\n\tenum mei_cb_file_ops fop_type;\n\tint rets;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tif (!dev->hbm_f_ev_supported) {\n\t\tcl_dbg(dev, cl, \"notifications not supported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!mei_cl_is_connected(cl))\n\t\treturn -ENODEV;\n\n\trets = pm_runtime_get(dev->dev);\n\tif (rets < 0 && rets != -EINPROGRESS) {\n\t\tpm_runtime_put_noidle(dev->dev);\n\t\tcl_err(dev, cl, \"rpm: get failed %d\\n\", rets);\n\t\treturn rets;\n\t}\n\n\tfop_type = mei_cl_notify_req2fop(request);\n\tcb = mei_cl_enqueue_ctrl_wr_cb(cl, 0, fop_type, fp);\n\tif (!cb) {\n\t\trets = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (mei_hbuf_acquire(dev)) {\n\t\tif (mei_hbm_cl_notify_req(dev, cl, request)) {\n\t\t\trets = -ENODEV;\n\t\t\tgoto out;\n\t\t}\n\t\tlist_move_tail(&cb->list, &dev->ctrl_rd_list);\n\t}\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(cl->wait,\n\t\t\t   cl->notify_en == request ||\n\t\t\t   cl->status ||\n\t\t\t   !mei_cl_is_connected(cl),\n\t\t\t   dev->timeouts.cl_connect);\n\tmutex_lock(&dev->device_lock);\n\n\tif (cl->notify_en != request && !cl->status)\n\t\tcl->status = -EFAULT;\n\n\trets = cl->status;\n\nout:\n\tcl_dbg(dev, cl, \"rpm: autosuspend\\n\");\n\tpm_runtime_mark_last_busy(dev->dev);\n\tpm_runtime_put_autosuspend(dev->dev);\n\n\tmei_io_cb_free(cb);\n\treturn rets;\n}\n\n \nvoid mei_cl_notify(struct mei_cl *cl)\n{\n\tstruct mei_device *dev;\n\n\tif (!cl || !cl->dev)\n\t\treturn;\n\n\tdev = cl->dev;\n\n\tif (!cl->notify_en)\n\t\treturn;\n\n\tcl_dbg(dev, cl, \"notify event\");\n\tcl->notify_ev = true;\n\tif (!mei_cl_bus_notify_event(cl))\n\t\twake_up_interruptible(&cl->ev_wait);\n\n\tif (cl->ev_async)\n\t\tkill_fasync(&cl->ev_async, SIGIO, POLL_PRI);\n\n}\n\n \nint mei_cl_notify_get(struct mei_cl *cl, bool block, bool *notify_ev)\n{\n\tstruct mei_device *dev;\n\tint rets;\n\n\t*notify_ev = false;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tif (!dev->hbm_f_ev_supported) {\n\t\tcl_dbg(dev, cl, \"notifications not supported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!mei_cl_is_connected(cl))\n\t\treturn -ENODEV;\n\n\tif (cl->notify_ev)\n\t\tgoto out;\n\n\tif (!block)\n\t\treturn -EAGAIN;\n\n\tmutex_unlock(&dev->device_lock);\n\trets = wait_event_interruptible(cl->ev_wait, cl->notify_ev);\n\tmutex_lock(&dev->device_lock);\n\n\tif (rets < 0)\n\t\treturn rets;\n\nout:\n\t*notify_ev = cl->notify_ev;\n\tcl->notify_ev = false;\n\treturn 0;\n}\n\n \nint mei_cl_read_start(struct mei_cl *cl, size_t length, const struct file *fp)\n{\n\tstruct mei_device *dev;\n\tstruct mei_cl_cb *cb;\n\tint rets;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tif (!mei_cl_is_connected(cl))\n\t\treturn -ENODEV;\n\n\tif (!mei_me_cl_is_active(cl->me_cl)) {\n\t\tcl_err(dev, cl, \"no such me client\\n\");\n\t\treturn  -ENOTTY;\n\t}\n\n\tif (mei_cl_is_fixed_address(cl))\n\t\treturn 0;\n\n\t \n\tif (cl->rx_flow_ctrl_creds) {\n\t\tmei_cl_set_read_by_fp(cl, fp);\n\t\treturn -EBUSY;\n\t}\n\n\tcb = mei_cl_enqueue_ctrl_wr_cb(cl, length, MEI_FOP_READ, fp);\n\tif (!cb)\n\t\treturn -ENOMEM;\n\n\tmei_cl_set_read_by_fp(cl, fp);\n\n\trets = pm_runtime_get(dev->dev);\n\tif (rets < 0 && rets != -EINPROGRESS) {\n\t\tpm_runtime_put_noidle(dev->dev);\n\t\tcl_err(dev, cl, \"rpm: get failed %d\\n\", rets);\n\t\tgoto nortpm;\n\t}\n\n\trets = 0;\n\tif (mei_hbuf_acquire(dev)) {\n\t\trets = mei_hbm_cl_flow_control_req(dev, cl);\n\t\tif (rets < 0)\n\t\t\tgoto out;\n\n\t\tlist_move_tail(&cb->list, &cl->rd_pending);\n\t}\n\tcl->rx_flow_ctrl_creds++;\n\nout:\n\tcl_dbg(dev, cl, \"rpm: autosuspend\\n\");\n\tpm_runtime_mark_last_busy(dev->dev);\n\tpm_runtime_put_autosuspend(dev->dev);\nnortpm:\n\tif (rets)\n\t\tmei_io_cb_free(cb);\n\n\treturn rets;\n}\n\nstatic inline u8 mei_ext_hdr_set_vtag(void *ext, u8 vtag)\n{\n\tstruct mei_ext_hdr_vtag *vtag_hdr = ext;\n\n\tvtag_hdr->hdr.type = MEI_EXT_HDR_VTAG;\n\tvtag_hdr->hdr.length = mei_data2slots(sizeof(*vtag_hdr));\n\tvtag_hdr->vtag = vtag;\n\tvtag_hdr->reserved = 0;\n\treturn vtag_hdr->hdr.length;\n}\n\nstatic inline bool mei_ext_hdr_is_gsc(struct mei_ext_hdr *ext)\n{\n\treturn ext && ext->type == MEI_EXT_HDR_GSC;\n}\n\nstatic inline u8 mei_ext_hdr_set_gsc(struct mei_ext_hdr *ext, struct mei_ext_hdr *gsc_hdr)\n{\n\tmemcpy(ext, gsc_hdr, mei_ext_hdr_len(gsc_hdr));\n\treturn ext->length;\n}\n\n \nstatic struct mei_msg_hdr *mei_msg_hdr_init(const struct mei_cl_cb *cb)\n{\n\tsize_t hdr_len;\n\tstruct mei_ext_meta_hdr *meta;\n\tstruct mei_msg_hdr *mei_hdr;\n\tbool is_ext, is_hbm, is_gsc, is_vtag;\n\tstruct mei_ext_hdr *next_ext;\n\n\tif (!cb)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t \n\tis_vtag = (cb->vtag && cb->buf_idx == 0);\n\tis_hbm = cb->cl->me_cl->client_id == 0;\n\tis_gsc = ((!is_hbm) && cb->cl->dev->hbm_f_gsc_supported && mei_ext_hdr_is_gsc(cb->ext_hdr));\n\tis_ext = is_vtag || is_gsc;\n\n\t \n\thdr_len = sizeof(*mei_hdr);\n\n\tif (!is_ext)\n\t\tgoto setup_hdr;\n\n\thdr_len += sizeof(*meta);\n\tif (is_vtag)\n\t\thdr_len += sizeof(struct mei_ext_hdr_vtag);\n\n\tif (is_gsc)\n\t\thdr_len += mei_ext_hdr_len(cb->ext_hdr);\n\nsetup_hdr:\n\tmei_hdr = kzalloc(hdr_len, GFP_KERNEL);\n\tif (!mei_hdr)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmei_hdr->host_addr = mei_cl_host_addr(cb->cl);\n\tmei_hdr->me_addr = mei_cl_me_id(cb->cl);\n\tmei_hdr->internal = cb->internal;\n\tmei_hdr->extended = is_ext;\n\n\tif (!is_ext)\n\t\tgoto out;\n\n\tmeta = (struct mei_ext_meta_hdr *)mei_hdr->extension;\n\tmeta->size = 0;\n\tnext_ext = (struct mei_ext_hdr *)meta->hdrs;\n\tif (is_vtag) {\n\t\tmeta->count++;\n\t\tmeta->size += mei_ext_hdr_set_vtag(next_ext, cb->vtag);\n\t\tnext_ext = mei_ext_next(next_ext);\n\t}\n\n\tif (is_gsc) {\n\t\tmeta->count++;\n\t\tmeta->size += mei_ext_hdr_set_gsc(next_ext, cb->ext_hdr);\n\t\tnext_ext = mei_ext_next(next_ext);\n\t}\n\nout:\n\tmei_hdr->length = hdr_len - sizeof(*mei_hdr);\n\treturn mei_hdr;\n}\n\n \nint mei_cl_irq_write(struct mei_cl *cl, struct mei_cl_cb *cb,\n\t\t     struct list_head *cmpl_list)\n{\n\tstruct mei_device *dev;\n\tstruct mei_msg_data *buf;\n\tstruct mei_msg_hdr *mei_hdr = NULL;\n\tsize_t hdr_len;\n\tsize_t hbuf_len, dr_len;\n\tsize_t buf_len = 0;\n\tsize_t data_len;\n\tint hbuf_slots;\n\tu32 dr_slots;\n\tu32 dma_len;\n\tint rets;\n\tbool first_chunk;\n\tconst void *data = NULL;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tbuf = &cb->buf;\n\n\tfirst_chunk = cb->buf_idx == 0;\n\n\trets = first_chunk ? mei_cl_tx_flow_ctrl_creds(cl) : 1;\n\tif (rets < 0)\n\t\tgoto err;\n\n\tif (rets == 0) {\n\t\tcl_dbg(dev, cl, \"No flow control credentials: not sending.\\n\");\n\t\treturn 0;\n\t}\n\n\tif (buf->data) {\n\t\tbuf_len = buf->size - cb->buf_idx;\n\t\tdata = buf->data + cb->buf_idx;\n\t}\n\thbuf_slots = mei_hbuf_empty_slots(dev);\n\tif (hbuf_slots < 0) {\n\t\trets = -EOVERFLOW;\n\t\tgoto err;\n\t}\n\n\thbuf_len = mei_slots2data(hbuf_slots) & MEI_MSG_MAX_LEN_MASK;\n\tdr_slots = mei_dma_ring_empty_slots(dev);\n\tdr_len = mei_slots2data(dr_slots);\n\n\tmei_hdr = mei_msg_hdr_init(cb);\n\tif (IS_ERR(mei_hdr)) {\n\t\trets = PTR_ERR(mei_hdr);\n\t\tmei_hdr = NULL;\n\t\tgoto err;\n\t}\n\n\thdr_len = sizeof(*mei_hdr) + mei_hdr->length;\n\n\t \n\tif (hdr_len + buf_len <= hbuf_len) {\n\t\tdata_len = buf_len;\n\t\tmei_hdr->msg_complete = 1;\n\t} else if (dr_slots && hbuf_len >= hdr_len + sizeof(dma_len)) {\n\t\tmei_hdr->dma_ring = 1;\n\t\tif (buf_len > dr_len)\n\t\t\tbuf_len = dr_len;\n\t\telse\n\t\t\tmei_hdr->msg_complete = 1;\n\n\t\tdata_len = sizeof(dma_len);\n\t\tdma_len = buf_len;\n\t\tdata = &dma_len;\n\t} else if ((u32)hbuf_slots == mei_hbuf_depth(dev)) {\n\t\tbuf_len = hbuf_len - hdr_len;\n\t\tdata_len = buf_len;\n\t} else {\n\t\tkfree(mei_hdr);\n\t\treturn 0;\n\t}\n\tmei_hdr->length += data_len;\n\n\tif (mei_hdr->dma_ring && buf->data)\n\t\tmei_dma_ring_write(dev, buf->data + cb->buf_idx, buf_len);\n\trets = mei_write_message(dev, mei_hdr, hdr_len, data, data_len);\n\n\tif (rets)\n\t\tgoto err;\n\n\tcl->status = 0;\n\tcl->writing_state = MEI_WRITING;\n\tcb->buf_idx += buf_len;\n\n\tif (first_chunk) {\n\t\tif (mei_cl_tx_flow_ctrl_creds_reduce(cl)) {\n\t\t\trets = -EIO;\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tif (mei_hdr->msg_complete)\n\t\tlist_move_tail(&cb->list, &dev->write_waiting_list);\n\n\tkfree(mei_hdr);\n\treturn 0;\n\nerr:\n\tkfree(mei_hdr);\n\tcl->status = rets;\n\tlist_move_tail(&cb->list, cmpl_list);\n\treturn rets;\n}\n\n \nssize_t mei_cl_write(struct mei_cl *cl, struct mei_cl_cb *cb, unsigned long timeout)\n{\n\tstruct mei_device *dev;\n\tstruct mei_msg_data *buf;\n\tstruct mei_msg_hdr *mei_hdr = NULL;\n\tsize_t hdr_len;\n\tsize_t hbuf_len, dr_len;\n\tsize_t buf_len;\n\tsize_t data_len;\n\tint hbuf_slots;\n\tu32 dr_slots;\n\tu32 dma_len;\n\tssize_t rets;\n\tbool blocking;\n\tconst void *data;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tif (WARN_ON(!cb))\n\t\treturn -EINVAL;\n\n\tdev = cl->dev;\n\n\tbuf = &cb->buf;\n\tbuf_len = buf->size;\n\n\tcl_dbg(dev, cl, \"buf_len=%zd\\n\", buf_len);\n\n\tblocking = cb->blocking;\n\tdata = buf->data;\n\n\trets = pm_runtime_get(dev->dev);\n\tif (rets < 0 && rets != -EINPROGRESS) {\n\t\tpm_runtime_put_noidle(dev->dev);\n\t\tcl_err(dev, cl, \"rpm: get failed %zd\\n\", rets);\n\t\tgoto free;\n\t}\n\n\tcb->buf_idx = 0;\n\tcl->writing_state = MEI_IDLE;\n\n\n\trets = mei_cl_tx_flow_ctrl_creds(cl);\n\tif (rets < 0)\n\t\tgoto err;\n\n\tmei_hdr = mei_msg_hdr_init(cb);\n\tif (IS_ERR(mei_hdr)) {\n\t\trets = PTR_ERR(mei_hdr);\n\t\tmei_hdr = NULL;\n\t\tgoto err;\n\t}\n\n\thdr_len = sizeof(*mei_hdr) + mei_hdr->length;\n\n\tif (rets == 0) {\n\t\tcl_dbg(dev, cl, \"No flow control credentials: not sending.\\n\");\n\t\trets = buf_len;\n\t\tgoto out;\n\t}\n\n\tif (!mei_hbuf_acquire(dev)) {\n\t\tcl_dbg(dev, cl, \"Cannot acquire the host buffer: not sending.\\n\");\n\t\trets = buf_len;\n\t\tgoto out;\n\t}\n\n\thbuf_slots = mei_hbuf_empty_slots(dev);\n\tif (hbuf_slots < 0) {\n\t\tbuf_len = -EOVERFLOW;\n\t\tgoto out;\n\t}\n\n\thbuf_len = mei_slots2data(hbuf_slots) & MEI_MSG_MAX_LEN_MASK;\n\tdr_slots = mei_dma_ring_empty_slots(dev);\n\tdr_len =  mei_slots2data(dr_slots);\n\n\tif (hdr_len + buf_len <= hbuf_len) {\n\t\tdata_len = buf_len;\n\t\tmei_hdr->msg_complete = 1;\n\t} else if (dr_slots && hbuf_len >= hdr_len + sizeof(dma_len)) {\n\t\tmei_hdr->dma_ring = 1;\n\t\tif (buf_len > dr_len)\n\t\t\tbuf_len = dr_len;\n\t\telse\n\t\t\tmei_hdr->msg_complete = 1;\n\n\t\tdata_len = sizeof(dma_len);\n\t\tdma_len = buf_len;\n\t\tdata = &dma_len;\n\t} else {\n\t\tbuf_len = hbuf_len - hdr_len;\n\t\tdata_len = buf_len;\n\t}\n\n\tmei_hdr->length += data_len;\n\n\tif (mei_hdr->dma_ring && buf->data)\n\t\tmei_dma_ring_write(dev, buf->data, buf_len);\n\trets = mei_write_message(dev, mei_hdr, hdr_len, data, data_len);\n\n\tif (rets)\n\t\tgoto err;\n\n\trets = mei_cl_tx_flow_ctrl_creds_reduce(cl);\n\tif (rets)\n\t\tgoto err;\n\n\tcl->writing_state = MEI_WRITING;\n\tcb->buf_idx = buf_len;\n\t \n\tbuf_len = buf->size;\n\nout:\n\tif (mei_hdr->msg_complete)\n\t\tmei_tx_cb_enqueue(cb, &dev->write_waiting_list);\n\telse\n\t\tmei_tx_cb_enqueue(cb, &dev->write_list);\n\n\tcb = NULL;\n\tif (blocking && cl->writing_state != MEI_WRITE_COMPLETE) {\n\n\t\tmutex_unlock(&dev->device_lock);\n\t\trets = wait_event_interruptible_timeout(cl->tx_wait,\n\t\t\t\t\t\t\tcl->writing_state == MEI_WRITE_COMPLETE ||\n\t\t\t\t\t\t\t(!mei_cl_is_connected(cl)),\n\t\t\t\t\t\t\tmsecs_to_jiffies(timeout));\n\t\tmutex_lock(&dev->device_lock);\n\t\t \n\t\tif (rets == 0) {\n\t\t\trets = -ETIME;\n\t\t\tmei_io_tx_list_free_cl(&dev->write_list, cl, NULL);\n\t\t\tmei_io_tx_list_free_cl(&dev->write_waiting_list, cl, NULL);\n\t\t}\n\t\t \n\t\tif (rets > 0)\n\t\t\trets = 0;\n\t\tif (rets) {\n\t\t\tif (signal_pending(current))\n\t\t\t\trets = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\t\tif (cl->writing_state != MEI_WRITE_COMPLETE) {\n\t\t\trets = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\trets = buf_len;\nerr:\n\tcl_dbg(dev, cl, \"rpm: autosuspend\\n\");\n\tpm_runtime_mark_last_busy(dev->dev);\n\tpm_runtime_put_autosuspend(dev->dev);\nfree:\n\tmei_io_cb_free(cb);\n\n\tkfree(mei_hdr);\n\n\treturn rets;\n}\n\n \nvoid mei_cl_complete(struct mei_cl *cl, struct mei_cl_cb *cb)\n{\n\tstruct mei_device *dev = cl->dev;\n\n\tswitch (cb->fop_type) {\n\tcase MEI_FOP_WRITE:\n\t\tmei_tx_cb_dequeue(cb);\n\t\tcl->writing_state = MEI_WRITE_COMPLETE;\n\t\tif (waitqueue_active(&cl->tx_wait)) {\n\t\t\twake_up_interruptible(&cl->tx_wait);\n\t\t} else {\n\t\t\tpm_runtime_mark_last_busy(dev->dev);\n\t\t\tpm_request_autosuspend(dev->dev);\n\t\t}\n\t\tbreak;\n\n\tcase MEI_FOP_READ:\n\t\tmei_cl_add_rd_completed(cl, cb);\n\t\tif (!mei_cl_is_fixed_address(cl) &&\n\t\t    !WARN_ON(!cl->rx_flow_ctrl_creds))\n\t\t\tcl->rx_flow_ctrl_creds--;\n\t\tif (!mei_cl_bus_rx_event(cl))\n\t\t\twake_up_interruptible(&cl->rx_wait);\n\t\tbreak;\n\n\tcase MEI_FOP_CONNECT:\n\tcase MEI_FOP_DISCONNECT:\n\tcase MEI_FOP_NOTIFY_STOP:\n\tcase MEI_FOP_NOTIFY_START:\n\tcase MEI_FOP_DMA_MAP:\n\tcase MEI_FOP_DMA_UNMAP:\n\t\tif (waitqueue_active(&cl->wait))\n\t\t\twake_up(&cl->wait);\n\n\t\tbreak;\n\tcase MEI_FOP_DISCONNECT_RSP:\n\t\tmei_io_cb_free(cb);\n\t\tmei_cl_set_disconnected(cl);\n\t\tbreak;\n\tdefault:\n\t\tBUG_ON(0);\n\t}\n}\n\n\n \nvoid mei_cl_all_disconnect(struct mei_device *dev)\n{\n\tstruct mei_cl *cl;\n\n\tlist_for_each_entry(cl, &dev->file_list, link)\n\t\tmei_cl_set_disconnected(cl);\n}\nEXPORT_SYMBOL_GPL(mei_cl_all_disconnect);\n\nstatic struct mei_cl *mei_cl_dma_map_find(struct mei_device *dev, u8 buffer_id)\n{\n\tstruct mei_cl *cl;\n\n\tlist_for_each_entry(cl, &dev->file_list, link)\n\t\tif (cl->dma.buffer_id == buffer_id)\n\t\t\treturn cl;\n\treturn NULL;\n}\n\n \nint mei_cl_irq_dma_map(struct mei_cl *cl, struct mei_cl_cb *cb,\n\t\t       struct list_head *cmpl_list)\n{\n\tstruct mei_device *dev = cl->dev;\n\tu32 msg_slots;\n\tint slots;\n\tint ret;\n\n\tmsg_slots = mei_hbm2slots(sizeof(struct hbm_client_dma_map_request));\n\tslots = mei_hbuf_empty_slots(dev);\n\tif (slots < 0)\n\t\treturn -EOVERFLOW;\n\n\tif ((u32)slots < msg_slots)\n\t\treturn -EMSGSIZE;\n\n\tret = mei_hbm_cl_dma_map_req(dev, cl);\n\tif (ret) {\n\t\tcl->status = ret;\n\t\tlist_move_tail(&cb->list, cmpl_list);\n\t\treturn ret;\n\t}\n\n\tlist_move_tail(&cb->list, &dev->ctrl_rd_list);\n\treturn 0;\n}\n\n \nint mei_cl_irq_dma_unmap(struct mei_cl *cl, struct mei_cl_cb *cb,\n\t\t\t struct list_head *cmpl_list)\n{\n\tstruct mei_device *dev = cl->dev;\n\tu32 msg_slots;\n\tint slots;\n\tint ret;\n\n\tmsg_slots = mei_hbm2slots(sizeof(struct hbm_client_dma_unmap_request));\n\tslots = mei_hbuf_empty_slots(dev);\n\tif (slots < 0)\n\t\treturn -EOVERFLOW;\n\n\tif ((u32)slots < msg_slots)\n\t\treturn -EMSGSIZE;\n\n\tret = mei_hbm_cl_dma_unmap_req(dev, cl);\n\tif (ret) {\n\t\tcl->status = ret;\n\t\tlist_move_tail(&cb->list, cmpl_list);\n\t\treturn ret;\n\t}\n\n\tlist_move_tail(&cb->list, &dev->ctrl_rd_list);\n\treturn 0;\n}\n\nstatic int mei_cl_dma_alloc(struct mei_cl *cl, u8 buf_id, size_t size)\n{\n\tcl->dma.vaddr = dmam_alloc_coherent(cl->dev->dev, size,\n\t\t\t\t\t    &cl->dma.daddr, GFP_KERNEL);\n\tif (!cl->dma.vaddr)\n\t\treturn -ENOMEM;\n\n\tcl->dma.buffer_id = buf_id;\n\tcl->dma.size = size;\n\n\treturn 0;\n}\n\nstatic void mei_cl_dma_free(struct mei_cl *cl)\n{\n\tcl->dma.buffer_id = 0;\n\tdmam_free_coherent(cl->dev->dev,\n\t\t\t   cl->dma.size, cl->dma.vaddr, cl->dma.daddr);\n\tcl->dma.size = 0;\n\tcl->dma.vaddr = NULL;\n\tcl->dma.daddr = 0;\n}\n\n \nint mei_cl_dma_alloc_and_map(struct mei_cl *cl, const struct file *fp,\n\t\t\t     u8 buffer_id, size_t size)\n{\n\tstruct mei_device *dev;\n\tstruct mei_cl_cb *cb;\n\tint rets;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tif (!dev->hbm_f_cd_supported) {\n\t\tcl_dbg(dev, cl, \"client dma is not supported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (buffer_id == 0)\n\t\treturn -EINVAL;\n\n\tif (mei_cl_is_connected(cl))\n\t\treturn -EPROTO;\n\n\tif (cl->dma_mapped)\n\t\treturn -EPROTO;\n\n\tif (mei_cl_dma_map_find(dev, buffer_id)) {\n\t\tcl_dbg(dev, cl, \"client dma with id %d is already allocated\\n\",\n\t\t       cl->dma.buffer_id);\n\t\treturn -EPROTO;\n\t}\n\n\trets = pm_runtime_get(dev->dev);\n\tif (rets < 0 && rets != -EINPROGRESS) {\n\t\tpm_runtime_put_noidle(dev->dev);\n\t\tcl_err(dev, cl, \"rpm: get failed %d\\n\", rets);\n\t\treturn rets;\n\t}\n\n\trets = mei_cl_dma_alloc(cl, buffer_id, size);\n\tif (rets) {\n\t\tpm_runtime_put_noidle(dev->dev);\n\t\treturn rets;\n\t}\n\n\tcb = mei_cl_enqueue_ctrl_wr_cb(cl, 0, MEI_FOP_DMA_MAP, fp);\n\tif (!cb) {\n\t\trets = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (mei_hbuf_acquire(dev)) {\n\t\tif (mei_hbm_cl_dma_map_req(dev, cl)) {\n\t\t\trets = -ENODEV;\n\t\t\tgoto out;\n\t\t}\n\t\tlist_move_tail(&cb->list, &dev->ctrl_rd_list);\n\t}\n\n\tcl->status = 0;\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(cl->wait,\n\t\t\t   cl->dma_mapped || cl->status,\n\t\t\t   dev->timeouts.cl_connect);\n\tmutex_lock(&dev->device_lock);\n\n\tif (!cl->dma_mapped && !cl->status)\n\t\tcl->status = -EFAULT;\n\n\trets = cl->status;\n\nout:\n\tif (rets)\n\t\tmei_cl_dma_free(cl);\n\n\tcl_dbg(dev, cl, \"rpm: autosuspend\\n\");\n\tpm_runtime_mark_last_busy(dev->dev);\n\tpm_runtime_put_autosuspend(dev->dev);\n\n\tmei_io_cb_free(cb);\n\treturn rets;\n}\n\n \nint mei_cl_dma_unmap(struct mei_cl *cl, const struct file *fp)\n{\n\tstruct mei_device *dev;\n\tstruct mei_cl_cb *cb;\n\tint rets;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tif (!dev->hbm_f_cd_supported) {\n\t\tcl_dbg(dev, cl, \"client dma is not supported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\t \n\tif (mei_cl_is_connected(cl))\n\t\treturn -EPROTO;\n\n\tif (!cl->dma_mapped)\n\t\treturn -EPROTO;\n\n\trets = pm_runtime_get(dev->dev);\n\tif (rets < 0 && rets != -EINPROGRESS) {\n\t\tpm_runtime_put_noidle(dev->dev);\n\t\tcl_err(dev, cl, \"rpm: get failed %d\\n\", rets);\n\t\treturn rets;\n\t}\n\n\tcb = mei_cl_enqueue_ctrl_wr_cb(cl, 0, MEI_FOP_DMA_UNMAP, fp);\n\tif (!cb) {\n\t\trets = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (mei_hbuf_acquire(dev)) {\n\t\tif (mei_hbm_cl_dma_unmap_req(dev, cl)) {\n\t\t\trets = -ENODEV;\n\t\t\tgoto out;\n\t\t}\n\t\tlist_move_tail(&cb->list, &dev->ctrl_rd_list);\n\t}\n\n\tcl->status = 0;\n\n\tmutex_unlock(&dev->device_lock);\n\twait_event_timeout(cl->wait,\n\t\t\t   !cl->dma_mapped || cl->status,\n\t\t\t   dev->timeouts.cl_connect);\n\tmutex_lock(&dev->device_lock);\n\n\tif (cl->dma_mapped && !cl->status)\n\t\tcl->status = -EFAULT;\n\n\trets = cl->status;\n\n\tif (!rets)\n\t\tmei_cl_dma_free(cl);\nout:\n\tcl_dbg(dev, cl, \"rpm: autosuspend\\n\");\n\tpm_runtime_mark_last_busy(dev->dev);\n\tpm_runtime_put_autosuspend(dev->dev);\n\n\tmei_io_cb_free(cb);\n\treturn rets;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}