{
  "module_name": "uacce.c",
  "hash_id": "dd9edf466a7db662c16ea82f452924c30ee8192927d0fc3c868e60135b09e568",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/uacce/uacce.c",
  "human_readable_source": "\n#include <linux/compat.h>\n#include <linux/dma-mapping.h>\n#include <linux/iommu.h>\n#include <linux/module.h>\n#include <linux/poll.h>\n#include <linux/slab.h>\n#include <linux/uacce.h>\n\nstatic struct class *uacce_class;\nstatic dev_t uacce_devt;\nstatic DEFINE_XARRAY_ALLOC(uacce_xa);\n\n \nstatic bool uacce_queue_is_valid(struct uacce_queue *q)\n{\n\treturn q->state == UACCE_Q_INIT || q->state == UACCE_Q_STARTED;\n}\n\nstatic int uacce_start_queue(struct uacce_queue *q)\n{\n\tint ret;\n\n\tif (q->state != UACCE_Q_INIT)\n\t\treturn -EINVAL;\n\n\tif (q->uacce->ops->start_queue) {\n\t\tret = q->uacce->ops->start_queue(q);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tq->state = UACCE_Q_STARTED;\n\treturn 0;\n}\n\nstatic int uacce_put_queue(struct uacce_queue *q)\n{\n\tstruct uacce_device *uacce = q->uacce;\n\n\tif ((q->state == UACCE_Q_STARTED) && uacce->ops->stop_queue)\n\t\tuacce->ops->stop_queue(q);\n\n\tif ((q->state == UACCE_Q_INIT || q->state == UACCE_Q_STARTED) &&\n\t     uacce->ops->put_queue)\n\t\tuacce->ops->put_queue(q);\n\n\tq->state = UACCE_Q_ZOMBIE;\n\n\treturn 0;\n}\n\nstatic long uacce_fops_unl_ioctl(struct file *filep,\n\t\t\t\t unsigned int cmd, unsigned long arg)\n{\n\tstruct uacce_queue *q = filep->private_data;\n\tstruct uacce_device *uacce = q->uacce;\n\tlong ret = -ENXIO;\n\n\t \n\tmutex_lock(&uacce->mutex);\n\tif (!uacce_queue_is_valid(q))\n\t\tgoto out_unlock;\n\n\tswitch (cmd) {\n\tcase UACCE_CMD_START_Q:\n\t\tret = uacce_start_queue(q);\n\t\tbreak;\n\tcase UACCE_CMD_PUT_Q:\n\t\tret = uacce_put_queue(q);\n\t\tbreak;\n\tdefault:\n\t\tif (uacce->ops->ioctl)\n\t\t\tret = uacce->ops->ioctl(q, cmd, arg);\n\t\telse\n\t\t\tret = -EINVAL;\n\t}\nout_unlock:\n\tmutex_unlock(&uacce->mutex);\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic long uacce_fops_compat_ioctl(struct file *filep,\n\t\t\t\t   unsigned int cmd, unsigned long arg)\n{\n\targ = (unsigned long)compat_ptr(arg);\n\n\treturn uacce_fops_unl_ioctl(filep, cmd, arg);\n}\n#endif\n\nstatic int uacce_bind_queue(struct uacce_device *uacce, struct uacce_queue *q)\n{\n\tu32 pasid;\n\tstruct iommu_sva *handle;\n\n\tif (!(uacce->flags & UACCE_DEV_SVA))\n\t\treturn 0;\n\n\thandle = iommu_sva_bind_device(uacce->parent, current->mm);\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\n\tpasid = iommu_sva_get_pasid(handle);\n\tif (pasid == IOMMU_PASID_INVALID) {\n\t\tiommu_sva_unbind_device(handle);\n\t\treturn -ENODEV;\n\t}\n\n\tq->handle = handle;\n\tq->pasid = pasid;\n\treturn 0;\n}\n\nstatic void uacce_unbind_queue(struct uacce_queue *q)\n{\n\tif (!q->handle)\n\t\treturn;\n\tiommu_sva_unbind_device(q->handle);\n\tq->handle = NULL;\n}\n\nstatic int uacce_fops_open(struct inode *inode, struct file *filep)\n{\n\tstruct uacce_device *uacce;\n\tstruct uacce_queue *q;\n\tint ret;\n\n\tuacce = xa_load(&uacce_xa, iminor(inode));\n\tif (!uacce)\n\t\treturn -ENODEV;\n\n\tq = kzalloc(sizeof(struct uacce_queue), GFP_KERNEL);\n\tif (!q)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&uacce->mutex);\n\n\tif (!uacce->parent) {\n\t\tret = -EINVAL;\n\t\tgoto out_with_mem;\n\t}\n\n\tret = uacce_bind_queue(uacce, q);\n\tif (ret)\n\t\tgoto out_with_mem;\n\n\tq->uacce = uacce;\n\n\tif (uacce->ops->get_queue) {\n\t\tret = uacce->ops->get_queue(uacce, q->pasid, q);\n\t\tif (ret < 0)\n\t\t\tgoto out_with_bond;\n\t}\n\n\tinit_waitqueue_head(&q->wait);\n\tfilep->private_data = q;\n\tq->state = UACCE_Q_INIT;\n\tq->mapping = filep->f_mapping;\n\tmutex_init(&q->mutex);\n\tlist_add(&q->list, &uacce->queues);\n\tmutex_unlock(&uacce->mutex);\n\n\treturn 0;\n\nout_with_bond:\n\tuacce_unbind_queue(q);\nout_with_mem:\n\tkfree(q);\n\tmutex_unlock(&uacce->mutex);\n\treturn ret;\n}\n\nstatic int uacce_fops_release(struct inode *inode, struct file *filep)\n{\n\tstruct uacce_queue *q = filep->private_data;\n\tstruct uacce_device *uacce = q->uacce;\n\n\tmutex_lock(&uacce->mutex);\n\tuacce_put_queue(q);\n\tuacce_unbind_queue(q);\n\tlist_del(&q->list);\n\tmutex_unlock(&uacce->mutex);\n\tkfree(q);\n\n\treturn 0;\n}\n\nstatic void uacce_vma_close(struct vm_area_struct *vma)\n{\n\tstruct uacce_queue *q = vma->vm_private_data;\n\n\tif (vma->vm_pgoff < UACCE_MAX_REGION) {\n\t\tstruct uacce_qfile_region *qfr = q->qfrs[vma->vm_pgoff];\n\n\t\tmutex_lock(&q->mutex);\n\t\tq->qfrs[vma->vm_pgoff] = NULL;\n\t\tmutex_unlock(&q->mutex);\n\t\tkfree(qfr);\n\t}\n}\n\nstatic const struct vm_operations_struct uacce_vm_ops = {\n\t.close = uacce_vma_close,\n};\n\nstatic int uacce_fops_mmap(struct file *filep, struct vm_area_struct *vma)\n{\n\tstruct uacce_queue *q = filep->private_data;\n\tstruct uacce_device *uacce = q->uacce;\n\tstruct uacce_qfile_region *qfr;\n\tenum uacce_qfrt type = UACCE_MAX_REGION;\n\tint ret = 0;\n\n\tif (vma->vm_pgoff < UACCE_MAX_REGION)\n\t\ttype = vma->vm_pgoff;\n\telse\n\t\treturn -EINVAL;\n\n\tqfr = kzalloc(sizeof(*qfr), GFP_KERNEL);\n\tif (!qfr)\n\t\treturn -ENOMEM;\n\n\tvm_flags_set(vma, VM_DONTCOPY | VM_DONTEXPAND | VM_WIPEONFORK);\n\tvma->vm_ops = &uacce_vm_ops;\n\tvma->vm_private_data = q;\n\tqfr->type = type;\n\n\tmutex_lock(&q->mutex);\n\tif (!uacce_queue_is_valid(q)) {\n\t\tret = -ENXIO;\n\t\tgoto out_with_lock;\n\t}\n\n\tif (q->qfrs[type]) {\n\t\tret = -EEXIST;\n\t\tgoto out_with_lock;\n\t}\n\n\tswitch (type) {\n\tcase UACCE_QFRT_MMIO:\n\tcase UACCE_QFRT_DUS:\n\t\tif (!uacce->ops->mmap) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_with_lock;\n\t\t}\n\n\t\tret = uacce->ops->mmap(q, vma, qfr);\n\t\tif (ret)\n\t\t\tgoto out_with_lock;\n\t\tbreak;\n\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto out_with_lock;\n\t}\n\n\tq->qfrs[type] = qfr;\n\tmutex_unlock(&q->mutex);\n\n\treturn ret;\n\nout_with_lock:\n\tmutex_unlock(&q->mutex);\n\tkfree(qfr);\n\treturn ret;\n}\n\nstatic __poll_t uacce_fops_poll(struct file *file, poll_table *wait)\n{\n\tstruct uacce_queue *q = file->private_data;\n\tstruct uacce_device *uacce = q->uacce;\n\t__poll_t ret = 0;\n\n\tmutex_lock(&q->mutex);\n\tif (!uacce_queue_is_valid(q))\n\t\tgoto out_unlock;\n\n\tpoll_wait(file, &q->wait, wait);\n\n\tif (uacce->ops->is_q_updated && uacce->ops->is_q_updated(q))\n\t\tret = EPOLLIN | EPOLLRDNORM;\n\nout_unlock:\n\tmutex_unlock(&q->mutex);\n\treturn ret;\n}\n\nstatic const struct file_operations uacce_fops = {\n\t.owner\t\t= THIS_MODULE,\n\t.open\t\t= uacce_fops_open,\n\t.release\t= uacce_fops_release,\n\t.unlocked_ioctl\t= uacce_fops_unl_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl\t= uacce_fops_compat_ioctl,\n#endif\n\t.mmap\t\t= uacce_fops_mmap,\n\t.poll\t\t= uacce_fops_poll,\n};\n\n#define to_uacce_device(dev) container_of(dev, struct uacce_device, dev)\n\nstatic ssize_t api_show(struct device *dev,\n\t\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\", uacce->api_ver);\n}\n\nstatic ssize_t flags_show(struct device *dev,\n\t\t\t  struct device_attribute *attr, char *buf)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\n\treturn sysfs_emit(buf, \"%u\\n\", uacce->flags);\n}\n\nstatic ssize_t available_instances_show(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\n\tif (!uacce->ops->get_available_instances)\n\t\treturn -ENODEV;\n\n\treturn sysfs_emit(buf, \"%d\\n\",\n\t\t       uacce->ops->get_available_instances(uacce));\n}\n\nstatic ssize_t algorithms_show(struct device *dev,\n\t\t\t       struct device_attribute *attr, char *buf)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\", uacce->algs);\n}\n\nstatic ssize_t region_mmio_size_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr, char *buf)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\n\treturn sysfs_emit(buf, \"%lu\\n\",\n\t\t       uacce->qf_pg_num[UACCE_QFRT_MMIO] << PAGE_SHIFT);\n}\n\nstatic ssize_t region_dus_size_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\n\treturn sysfs_emit(buf, \"%lu\\n\",\n\t\t       uacce->qf_pg_num[UACCE_QFRT_DUS] << PAGE_SHIFT);\n}\n\nstatic ssize_t isolate_show(struct device *dev,\n\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\", uacce->ops->get_isolate_state(uacce));\n}\n\nstatic ssize_t isolate_strategy_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\tu32 val;\n\n\tval = uacce->ops->isolate_err_threshold_read(uacce);\n\n\treturn sysfs_emit(buf, \"%u\\n\", val);\n}\n\nstatic ssize_t isolate_strategy_store(struct device *dev, struct device_attribute *attr,\n\t\t\t\t   const char *buf, size_t count)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\tunsigned long val;\n\tint ret;\n\n\tif (kstrtoul(buf, 0, &val) < 0)\n\t\treturn -EINVAL;\n\n\tif (val > UACCE_MAX_ERR_THRESHOLD)\n\t\treturn -EINVAL;\n\n\tret = uacce->ops->isolate_err_threshold_write(uacce, val);\n\tif (ret)\n\t\treturn ret;\n\n\treturn count;\n}\n\nstatic DEVICE_ATTR_RO(api);\nstatic DEVICE_ATTR_RO(flags);\nstatic DEVICE_ATTR_RO(available_instances);\nstatic DEVICE_ATTR_RO(algorithms);\nstatic DEVICE_ATTR_RO(region_mmio_size);\nstatic DEVICE_ATTR_RO(region_dus_size);\nstatic DEVICE_ATTR_RO(isolate);\nstatic DEVICE_ATTR_RW(isolate_strategy);\n\nstatic struct attribute *uacce_dev_attrs[] = {\n\t&dev_attr_api.attr,\n\t&dev_attr_flags.attr,\n\t&dev_attr_available_instances.attr,\n\t&dev_attr_algorithms.attr,\n\t&dev_attr_region_mmio_size.attr,\n\t&dev_attr_region_dus_size.attr,\n\t&dev_attr_isolate.attr,\n\t&dev_attr_isolate_strategy.attr,\n\tNULL,\n};\n\nstatic umode_t uacce_dev_is_visible(struct kobject *kobj,\n\t\t\t\t    struct attribute *attr, int n)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\n\tif (((attr == &dev_attr_region_mmio_size.attr) &&\n\t    (!uacce->qf_pg_num[UACCE_QFRT_MMIO])) ||\n\t    ((attr == &dev_attr_region_dus_size.attr) &&\n\t    (!uacce->qf_pg_num[UACCE_QFRT_DUS])))\n\t\treturn 0;\n\n\tif (attr == &dev_attr_isolate_strategy.attr &&\n\t    (!uacce->ops->isolate_err_threshold_read &&\n\t     !uacce->ops->isolate_err_threshold_write))\n\t\treturn 0;\n\n\tif (attr == &dev_attr_isolate.attr && !uacce->ops->get_isolate_state)\n\t\treturn 0;\n\n\treturn attr->mode;\n}\n\nstatic struct attribute_group uacce_dev_group = {\n\t.is_visible\t= uacce_dev_is_visible,\n\t.attrs\t\t= uacce_dev_attrs,\n};\n\n__ATTRIBUTE_GROUPS(uacce_dev);\n\nstatic void uacce_release(struct device *dev)\n{\n\tstruct uacce_device *uacce = to_uacce_device(dev);\n\n\tkfree(uacce);\n}\n\nstatic unsigned int uacce_enable_sva(struct device *parent, unsigned int flags)\n{\n\tint ret;\n\n\tif (!(flags & UACCE_DEV_SVA))\n\t\treturn flags;\n\n\tflags &= ~UACCE_DEV_SVA;\n\n\tret = iommu_dev_enable_feature(parent, IOMMU_DEV_FEAT_IOPF);\n\tif (ret) {\n\t\tdev_err(parent, \"failed to enable IOPF feature! ret = %pe\\n\", ERR_PTR(ret));\n\t\treturn flags;\n\t}\n\n\tret = iommu_dev_enable_feature(parent, IOMMU_DEV_FEAT_SVA);\n\tif (ret) {\n\t\tdev_err(parent, \"failed to enable SVA feature! ret = %pe\\n\", ERR_PTR(ret));\n\t\tiommu_dev_disable_feature(parent, IOMMU_DEV_FEAT_IOPF);\n\t\treturn flags;\n\t}\n\n\treturn flags | UACCE_DEV_SVA;\n}\n\nstatic void uacce_disable_sva(struct uacce_device *uacce)\n{\n\tif (!(uacce->flags & UACCE_DEV_SVA))\n\t\treturn;\n\n\tiommu_dev_disable_feature(uacce->parent, IOMMU_DEV_FEAT_SVA);\n\tiommu_dev_disable_feature(uacce->parent, IOMMU_DEV_FEAT_IOPF);\n}\n\n \nstruct uacce_device *uacce_alloc(struct device *parent,\n\t\t\t\t struct uacce_interface *interface)\n{\n\tunsigned int flags = interface->flags;\n\tstruct uacce_device *uacce;\n\tint ret;\n\n\tuacce = kzalloc(sizeof(struct uacce_device), GFP_KERNEL);\n\tif (!uacce)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tflags = uacce_enable_sva(parent, flags);\n\n\tuacce->parent = parent;\n\tuacce->flags = flags;\n\tuacce->ops = interface->ops;\n\n\tret = xa_alloc(&uacce_xa, &uacce->dev_id, uacce, xa_limit_32b,\n\t\t       GFP_KERNEL);\n\tif (ret < 0)\n\t\tgoto err_with_uacce;\n\n\tINIT_LIST_HEAD(&uacce->queues);\n\tmutex_init(&uacce->mutex);\n\tdevice_initialize(&uacce->dev);\n\tuacce->dev.devt = MKDEV(MAJOR(uacce_devt), uacce->dev_id);\n\tuacce->dev.class = uacce_class;\n\tuacce->dev.groups = uacce_dev_groups;\n\tuacce->dev.parent = uacce->parent;\n\tuacce->dev.release = uacce_release;\n\tdev_set_name(&uacce->dev, \"%s-%d\", interface->name, uacce->dev_id);\n\n\treturn uacce;\n\nerr_with_uacce:\n\tuacce_disable_sva(uacce);\n\tkfree(uacce);\n\treturn ERR_PTR(ret);\n}\nEXPORT_SYMBOL_GPL(uacce_alloc);\n\n \nint uacce_register(struct uacce_device *uacce)\n{\n\tif (!uacce)\n\t\treturn -ENODEV;\n\n\tuacce->cdev = cdev_alloc();\n\tif (!uacce->cdev)\n\t\treturn -ENOMEM;\n\n\tuacce->cdev->ops = &uacce_fops;\n\tuacce->cdev->owner = THIS_MODULE;\n\n\treturn cdev_device_add(uacce->cdev, &uacce->dev);\n}\nEXPORT_SYMBOL_GPL(uacce_register);\n\n \nvoid uacce_remove(struct uacce_device *uacce)\n{\n\tstruct uacce_queue *q, *next_q;\n\n\tif (!uacce)\n\t\treturn;\n\n\t \n\tmutex_lock(&uacce->mutex);\n\t \n\tlist_for_each_entry_safe(q, next_q, &uacce->queues, list) {\n\t\t \n\t\tmutex_lock(&q->mutex);\n\t\tuacce_put_queue(q);\n\t\tmutex_unlock(&q->mutex);\n\t\tuacce_unbind_queue(q);\n\n\t\t \n\t\tunmap_mapping_range(q->mapping, 0, 0, 1);\n\t}\n\n\t \n\tuacce_disable_sva(uacce);\n\n\tif (uacce->cdev)\n\t\tcdev_device_del(uacce->cdev, &uacce->dev);\n\txa_erase(&uacce_xa, uacce->dev_id);\n\t \n\tuacce->ops = NULL;\n\tuacce->parent = NULL;\n\tmutex_unlock(&uacce->mutex);\n\tput_device(&uacce->dev);\n}\nEXPORT_SYMBOL_GPL(uacce_remove);\n\nstatic int __init uacce_init(void)\n{\n\tint ret;\n\n\tuacce_class = class_create(UACCE_NAME);\n\tif (IS_ERR(uacce_class))\n\t\treturn PTR_ERR(uacce_class);\n\n\tret = alloc_chrdev_region(&uacce_devt, 0, MINORMASK, UACCE_NAME);\n\tif (ret)\n\t\tclass_destroy(uacce_class);\n\n\treturn ret;\n}\n\nstatic __exit void uacce_exit(void)\n{\n\tunregister_chrdev_region(uacce_devt, MINORMASK);\n\tclass_destroy(uacce_class);\n}\n\nsubsys_initcall(uacce_init);\nmodule_exit(uacce_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"HiSilicon Tech. Co., Ltd.\");\nMODULE_DESCRIPTION(\"Accelerator interface for Userland applications\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}