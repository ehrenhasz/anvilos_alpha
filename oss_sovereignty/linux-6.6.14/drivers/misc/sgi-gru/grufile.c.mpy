{
  "module_name": "grufile.c",
  "hash_id": "7658715fc11040471de8c4932180a437407016ce9a4dcd6ebca986f93211f3e5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/sgi-gru/grufile.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/errno.h>\n#include <linux/slab.h>\n#include <linux/mm.h>\n#include <linux/io.h>\n#include <linux/spinlock.h>\n#include <linux/device.h>\n#include <linux/miscdevice.h>\n#include <linux/interrupt.h>\n#include <linux/proc_fs.h>\n#include <linux/uaccess.h>\n#ifdef CONFIG_X86_64\n#include <asm/uv/uv_irq.h>\n#endif\n#include <asm/uv/uv.h>\n#include \"gru.h\"\n#include \"grulib.h\"\n#include \"grutables.h\"\n\n#include <asm/uv/uv_hub.h>\n#include <asm/uv/uv_mmrs.h>\n\nstruct gru_blade_state *gru_base[GRU_MAX_BLADES] __read_mostly;\nunsigned long gru_start_paddr __read_mostly;\nvoid *gru_start_vaddr __read_mostly;\nunsigned long gru_end_paddr __read_mostly;\nunsigned int gru_max_gids __read_mostly;\nstruct gru_stats_s gru_stats;\n\n \nstatic int max_user_cbrs, max_user_dsr_bytes;\n\nstatic struct miscdevice gru_miscdev;\n\nstatic int gru_supported(void)\n{\n\treturn is_uv_system() &&\n\t\t(uv_hub_info->hub_revision < UV3_HUB_REVISION_BASE);\n}\n\n \nstatic void gru_vma_close(struct vm_area_struct *vma)\n{\n\tstruct gru_vma_data *vdata;\n\tstruct gru_thread_state *gts;\n\tstruct list_head *entry, *next;\n\n\tif (!vma->vm_private_data)\n\t\treturn;\n\n\tvdata = vma->vm_private_data;\n\tvma->vm_private_data = NULL;\n\tgru_dbg(grudev, \"vma %p, file %p, vdata %p\\n\", vma, vma->vm_file,\n\t\t\t\tvdata);\n\tlist_for_each_safe(entry, next, &vdata->vd_head) {\n\t\tgts =\n\t\t    list_entry(entry, struct gru_thread_state, ts_next);\n\t\tlist_del(&gts->ts_next);\n\t\tmutex_lock(&gts->ts_ctxlock);\n\t\tif (gts->ts_gru)\n\t\t\tgru_unload_context(gts, 0);\n\t\tmutex_unlock(&gts->ts_ctxlock);\n\t\tgts_drop(gts);\n\t}\n\tkfree(vdata);\n\tSTAT(vdata_free);\n}\n\n \nstatic int gru_file_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tif ((vma->vm_flags & (VM_SHARED | VM_WRITE)) != (VM_SHARED | VM_WRITE))\n\t\treturn -EPERM;\n\n\tif (vma->vm_start & (GRU_GSEG_PAGESIZE - 1) ||\n\t\t\t\tvma->vm_end & (GRU_GSEG_PAGESIZE - 1))\n\t\treturn -EINVAL;\n\n\tvm_flags_set(vma, VM_IO | VM_PFNMAP | VM_LOCKED |\n\t\t\t VM_DONTCOPY | VM_DONTEXPAND | VM_DONTDUMP);\n\tvma->vm_page_prot = PAGE_SHARED;\n\tvma->vm_ops = &gru_vm_ops;\n\n\tvma->vm_private_data = gru_alloc_vma_data(vma, 0);\n\tif (!vma->vm_private_data)\n\t\treturn -ENOMEM;\n\n\tgru_dbg(grudev, \"file %p, vaddr 0x%lx, vma %p, vdata %p\\n\",\n\t\tfile, vma->vm_start, vma, vma->vm_private_data);\n\treturn 0;\n}\n\n \nstatic int gru_create_new_context(unsigned long arg)\n{\n\tstruct gru_create_context_req req;\n\tstruct vm_area_struct *vma;\n\tstruct gru_vma_data *vdata;\n\tint ret = -EINVAL;\n\n\tif (copy_from_user(&req, (void __user *)arg, sizeof(req)))\n\t\treturn -EFAULT;\n\n\tif (req.data_segment_bytes > max_user_dsr_bytes)\n\t\treturn -EINVAL;\n\tif (req.control_blocks > max_user_cbrs || !req.maximum_thread_count)\n\t\treturn -EINVAL;\n\n\tif (!(req.options & GRU_OPT_MISS_MASK))\n\t\treq.options |= GRU_OPT_MISS_FMM_INTR;\n\n\tmmap_write_lock(current->mm);\n\tvma = gru_find_vma(req.gseg);\n\tif (vma) {\n\t\tvdata = vma->vm_private_data;\n\t\tvdata->vd_user_options = req.options;\n\t\tvdata->vd_dsr_au_count =\n\t\t    GRU_DS_BYTES_TO_AU(req.data_segment_bytes);\n\t\tvdata->vd_cbr_au_count = GRU_CB_COUNT_TO_AU(req.control_blocks);\n\t\tvdata->vd_tlb_preload_count = req.tlb_preload_count;\n\t\tret = 0;\n\t}\n\tmmap_write_unlock(current->mm);\n\n\treturn ret;\n}\n\n \nstatic long gru_get_config_info(unsigned long arg)\n{\n\tstruct gru_config_info info;\n\tint nodesperblade;\n\n\tif (num_online_nodes() > 1 &&\n\t\t\t(uv_node_to_blade_id(1) == uv_node_to_blade_id(0)))\n\t\tnodesperblade = 2;\n\telse\n\t\tnodesperblade = 1;\n\tmemset(&info, 0, sizeof(info));\n\tinfo.cpus = num_online_cpus();\n\tinfo.nodes = num_online_nodes();\n\tinfo.blades = info.nodes / nodesperblade;\n\tinfo.chiplets = GRU_CHIPLETS_PER_BLADE * info.blades;\n\n\tif (copy_to_user((void __user *)arg, &info, sizeof(info)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\n \nstatic long gru_file_unlocked_ioctl(struct file *file, unsigned int req,\n\t\t\t\t    unsigned long arg)\n{\n\tint err = -EBADRQC;\n\n\tgru_dbg(grudev, \"file %p, req 0x%x, 0x%lx\\n\", file, req, arg);\n\n\tswitch (req) {\n\tcase GRU_CREATE_CONTEXT:\n\t\terr = gru_create_new_context(arg);\n\t\tbreak;\n\tcase GRU_SET_CONTEXT_OPTION:\n\t\terr = gru_set_context_option(arg);\n\t\tbreak;\n\tcase GRU_USER_GET_EXCEPTION_DETAIL:\n\t\terr = gru_get_exception_detail(arg);\n\t\tbreak;\n\tcase GRU_USER_UNLOAD_CONTEXT:\n\t\terr = gru_user_unload_context(arg);\n\t\tbreak;\n\tcase GRU_USER_FLUSH_TLB:\n\t\terr = gru_user_flush_tlb(arg);\n\t\tbreak;\n\tcase GRU_USER_CALL_OS:\n\t\terr = gru_handle_user_call_os(arg);\n\t\tbreak;\n\tcase GRU_GET_GSEG_STATISTICS:\n\t\terr = gru_get_gseg_statistics(arg);\n\t\tbreak;\n\tcase GRU_KTEST:\n\t\terr = gru_ktest(arg);\n\t\tbreak;\n\tcase GRU_GET_CONFIG_INFO:\n\t\terr = gru_get_config_info(arg);\n\t\tbreak;\n\tcase GRU_DUMP_CHIPLET_STATE:\n\t\terr = gru_dump_chiplet_request(arg);\n\t\tbreak;\n\t}\n\treturn err;\n}\n\n \nstatic void gru_init_chiplet(struct gru_state *gru, unsigned long paddr,\n\t\t\t     void *vaddr, int blade_id, int chiplet_id)\n{\n\tspin_lock_init(&gru->gs_lock);\n\tspin_lock_init(&gru->gs_asid_lock);\n\tgru->gs_gru_base_paddr = paddr;\n\tgru->gs_gru_base_vaddr = vaddr;\n\tgru->gs_gid = blade_id * GRU_CHIPLETS_PER_BLADE + chiplet_id;\n\tgru->gs_blade = gru_base[blade_id];\n\tgru->gs_blade_id = blade_id;\n\tgru->gs_chiplet_id = chiplet_id;\n\tgru->gs_cbr_map = (GRU_CBR_AU == 64) ? ~0 : (1UL << GRU_CBR_AU) - 1;\n\tgru->gs_dsr_map = (1UL << GRU_DSR_AU) - 1;\n\tgru->gs_asid_limit = MAX_ASID;\n\tgru_tgh_flush_init(gru);\n\tif (gru->gs_gid >= gru_max_gids)\n\t\tgru_max_gids = gru->gs_gid + 1;\n\tgru_dbg(grudev, \"bid %d, gid %d, vaddr %p (0x%lx)\\n\",\n\t\tblade_id, gru->gs_gid, gru->gs_gru_base_vaddr,\n\t\tgru->gs_gru_base_paddr);\n}\n\nstatic int gru_init_tables(unsigned long gru_base_paddr, void *gru_base_vaddr)\n{\n\tint pnode, nid, bid, chip;\n\tint cbrs, dsrbytes, n;\n\tint order = get_order(sizeof(struct gru_blade_state));\n\tstruct page *page;\n\tstruct gru_state *gru;\n\tunsigned long paddr;\n\tvoid *vaddr;\n\n\tmax_user_cbrs = GRU_NUM_CB;\n\tmax_user_dsr_bytes = GRU_NUM_DSR_BYTES;\n\tfor_each_possible_blade(bid) {\n\t\tpnode = uv_blade_to_pnode(bid);\n\t\tnid = uv_blade_to_memory_nid(bid); \n\t\tpage = alloc_pages_node(nid, GFP_KERNEL, order);\n\t\tif (!page)\n\t\t\tgoto fail;\n\t\tgru_base[bid] = page_address(page);\n\t\tmemset(gru_base[bid], 0, sizeof(struct gru_blade_state));\n\t\tgru_base[bid]->bs_lru_gru = &gru_base[bid]->bs_grus[0];\n\t\tspin_lock_init(&gru_base[bid]->bs_lock);\n\t\tinit_rwsem(&gru_base[bid]->bs_kgts_sema);\n\n\t\tdsrbytes = 0;\n\t\tcbrs = 0;\n\t\tfor (gru = gru_base[bid]->bs_grus, chip = 0;\n\t\t\t\tchip < GRU_CHIPLETS_PER_BLADE;\n\t\t\t\tchip++, gru++) {\n\t\t\tpaddr = gru_chiplet_paddr(gru_base_paddr, pnode, chip);\n\t\t\tvaddr = gru_chiplet_vaddr(gru_base_vaddr, pnode, chip);\n\t\t\tgru_init_chiplet(gru, paddr, vaddr, bid, chip);\n\t\t\tn = hweight64(gru->gs_cbr_map) * GRU_CBR_AU_SIZE;\n\t\t\tcbrs = max(cbrs, n);\n\t\t\tn = hweight64(gru->gs_dsr_map) * GRU_DSR_AU_BYTES;\n\t\t\tdsrbytes = max(dsrbytes, n);\n\t\t}\n\t\tmax_user_cbrs = min(max_user_cbrs, cbrs);\n\t\tmax_user_dsr_bytes = min(max_user_dsr_bytes, dsrbytes);\n\t}\n\n\treturn 0;\n\nfail:\n\tfor (bid--; bid >= 0; bid--)\n\t\tfree_pages((unsigned long)gru_base[bid], order);\n\treturn -ENOMEM;\n}\n\nstatic void gru_free_tables(void)\n{\n\tint bid;\n\tint order = get_order(sizeof(struct gru_state) *\n\t\t\t      GRU_CHIPLETS_PER_BLADE);\n\n\tfor (bid = 0; bid < GRU_MAX_BLADES; bid++)\n\t\tfree_pages((unsigned long)gru_base[bid], order);\n}\n\nstatic unsigned long gru_chiplet_cpu_to_mmr(int chiplet, int cpu, int *corep)\n{\n\tunsigned long mmr = 0;\n\tint core;\n\n\t \n\tcore = uv_cpu_core_number(cpu) + UV_MAX_INT_CORES * uv_cpu_socket_number(cpu);\n\tif (core >= GRU_NUM_TFM || uv_cpu_ht_number(cpu))\n\t\treturn 0;\n\n\tif (chiplet == 0) {\n\t\tmmr = UVH_GR0_TLB_INT0_CONFIG +\n\t\t    core * (UVH_GR0_TLB_INT1_CONFIG - UVH_GR0_TLB_INT0_CONFIG);\n\t} else if (chiplet == 1) {\n\t\tmmr = UVH_GR1_TLB_INT0_CONFIG +\n\t\t    core * (UVH_GR1_TLB_INT1_CONFIG - UVH_GR1_TLB_INT0_CONFIG);\n\t} else {\n\t\tBUG();\n\t}\n\n\t*corep = core;\n\treturn mmr;\n}\n\n#ifdef CONFIG_IA64\n\nstatic int gru_irq_count[GRU_CHIPLETS_PER_BLADE];\n\nstatic void gru_noop(struct irq_data *d)\n{\n}\n\nstatic struct irq_chip gru_chip[GRU_CHIPLETS_PER_BLADE] = {\n\t[0 ... GRU_CHIPLETS_PER_BLADE - 1] {\n\t\t.irq_mask\t= gru_noop,\n\t\t.irq_unmask\t= gru_noop,\n\t\t.irq_ack\t= gru_noop\n\t}\n};\n\nstatic int gru_chiplet_setup_tlb_irq(int chiplet, char *irq_name,\n\t\t\tirq_handler_t irq_handler, int cpu, int blade)\n{\n\tunsigned long mmr;\n\tint irq = IRQ_GRU + chiplet;\n\tint ret, core;\n\n\tmmr = gru_chiplet_cpu_to_mmr(chiplet, cpu, &core);\n\tif (mmr == 0)\n\t\treturn 0;\n\n\tif (gru_irq_count[chiplet] == 0) {\n\t\tgru_chip[chiplet].name = irq_name;\n\t\tret = irq_set_chip(irq, &gru_chip[chiplet]);\n\t\tif (ret) {\n\t\t\tprintk(KERN_ERR \"%s: set_irq_chip failed, errno=%d\\n\",\n\t\t\t       GRU_DRIVER_ID_STR, -ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = request_irq(irq, irq_handler, 0, irq_name, NULL);\n\t\tif (ret) {\n\t\t\tprintk(KERN_ERR \"%s: request_irq failed, errno=%d\\n\",\n\t\t\t       GRU_DRIVER_ID_STR, -ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\tgru_irq_count[chiplet]++;\n\n\treturn 0;\n}\n\nstatic void gru_chiplet_teardown_tlb_irq(int chiplet, int cpu, int blade)\n{\n\tunsigned long mmr;\n\tint core, irq = IRQ_GRU + chiplet;\n\n\tif (gru_irq_count[chiplet] == 0)\n\t\treturn;\n\n\tmmr = gru_chiplet_cpu_to_mmr(chiplet, cpu, &core);\n\tif (mmr == 0)\n\t\treturn;\n\n\tif (--gru_irq_count[chiplet] == 0)\n\t\tfree_irq(irq, NULL);\n}\n\n#elif defined CONFIG_X86_64\n\nstatic int gru_chiplet_setup_tlb_irq(int chiplet, char *irq_name,\n\t\t\tirq_handler_t irq_handler, int cpu, int blade)\n{\n\tunsigned long mmr;\n\tint irq, core;\n\tint ret;\n\n\tmmr = gru_chiplet_cpu_to_mmr(chiplet, cpu, &core);\n\tif (mmr == 0)\n\t\treturn 0;\n\n\tirq = uv_setup_irq(irq_name, cpu, blade, mmr, UV_AFFINITY_CPU);\n\tif (irq < 0) {\n\t\tprintk(KERN_ERR \"%s: uv_setup_irq failed, errno=%d\\n\",\n\t\t       GRU_DRIVER_ID_STR, -irq);\n\t\treturn irq;\n\t}\n\n\tret = request_irq(irq, irq_handler, 0, irq_name, NULL);\n\tif (ret) {\n\t\tuv_teardown_irq(irq);\n\t\tprintk(KERN_ERR \"%s: request_irq failed, errno=%d\\n\",\n\t\t       GRU_DRIVER_ID_STR, -ret);\n\t\treturn ret;\n\t}\n\tgru_base[blade]->bs_grus[chiplet].gs_irq[core] = irq;\n\treturn 0;\n}\n\nstatic void gru_chiplet_teardown_tlb_irq(int chiplet, int cpu, int blade)\n{\n\tint irq, core;\n\tunsigned long mmr;\n\n\tmmr = gru_chiplet_cpu_to_mmr(chiplet, cpu, &core);\n\tif (mmr) {\n\t\tirq = gru_base[blade]->bs_grus[chiplet].gs_irq[core];\n\t\tif (irq) {\n\t\t\tfree_irq(irq, NULL);\n\t\t\tuv_teardown_irq(irq);\n\t\t}\n\t}\n}\n\n#endif\n\nstatic void gru_teardown_tlb_irqs(void)\n{\n\tint blade;\n\tint cpu;\n\n\tfor_each_online_cpu(cpu) {\n\t\tblade = uv_cpu_to_blade_id(cpu);\n\t\tgru_chiplet_teardown_tlb_irq(0, cpu, blade);\n\t\tgru_chiplet_teardown_tlb_irq(1, cpu, blade);\n\t}\n\tfor_each_possible_blade(blade) {\n\t\tif (uv_blade_nr_possible_cpus(blade))\n\t\t\tcontinue;\n\t\tgru_chiplet_teardown_tlb_irq(0, 0, blade);\n\t\tgru_chiplet_teardown_tlb_irq(1, 0, blade);\n\t}\n}\n\nstatic int gru_setup_tlb_irqs(void)\n{\n\tint blade;\n\tint cpu;\n\tint ret;\n\n\tfor_each_online_cpu(cpu) {\n\t\tblade = uv_cpu_to_blade_id(cpu);\n\t\tret = gru_chiplet_setup_tlb_irq(0, \"GRU0_TLB\", gru0_intr, cpu, blade);\n\t\tif (ret != 0)\n\t\t\tgoto exit1;\n\n\t\tret = gru_chiplet_setup_tlb_irq(1, \"GRU1_TLB\", gru1_intr, cpu, blade);\n\t\tif (ret != 0)\n\t\t\tgoto exit1;\n\t}\n\tfor_each_possible_blade(blade) {\n\t\tif (uv_blade_nr_possible_cpus(blade))\n\t\t\tcontinue;\n\t\tret = gru_chiplet_setup_tlb_irq(0, \"GRU0_TLB\", gru_intr_mblade, 0, blade);\n\t\tif (ret != 0)\n\t\t\tgoto exit1;\n\n\t\tret = gru_chiplet_setup_tlb_irq(1, \"GRU1_TLB\", gru_intr_mblade, 0, blade);\n\t\tif (ret != 0)\n\t\t\tgoto exit1;\n\t}\n\n\treturn 0;\n\nexit1:\n\tgru_teardown_tlb_irqs();\n\treturn ret;\n}\n\n \nstatic int __init gru_init(void)\n{\n\tint ret;\n\n\tif (!gru_supported())\n\t\treturn 0;\n\n#if defined CONFIG_IA64\n\tgru_start_paddr = 0xd000000000UL;  \n#else\n\tgru_start_paddr = uv_read_local_mmr(UVH_RH_GAM_GRU_OVERLAY_CONFIG) &\n\t\t\t\t0x7fffffffffffUL;\n#endif\n\tgru_start_vaddr = __va(gru_start_paddr);\n\tgru_end_paddr = gru_start_paddr + GRU_MAX_BLADES * GRU_SIZE;\n\tprintk(KERN_INFO \"GRU space: 0x%lx - 0x%lx\\n\",\n\t       gru_start_paddr, gru_end_paddr);\n\tret = misc_register(&gru_miscdev);\n\tif (ret) {\n\t\tprintk(KERN_ERR \"%s: misc_register failed\\n\",\n\t\t       GRU_DRIVER_ID_STR);\n\t\tgoto exit0;\n\t}\n\n\tret = gru_proc_init();\n\tif (ret) {\n\t\tprintk(KERN_ERR \"%s: proc init failed\\n\", GRU_DRIVER_ID_STR);\n\t\tgoto exit1;\n\t}\n\n\tret = gru_init_tables(gru_start_paddr, gru_start_vaddr);\n\tif (ret) {\n\t\tprintk(KERN_ERR \"%s: init tables failed\\n\", GRU_DRIVER_ID_STR);\n\t\tgoto exit2;\n\t}\n\n\tret = gru_setup_tlb_irqs();\n\tif (ret != 0)\n\t\tgoto exit3;\n\n\tgru_kservices_init();\n\n\tprintk(KERN_INFO \"%s: v%s\\n\", GRU_DRIVER_ID_STR,\n\t       GRU_DRIVER_VERSION_STR);\n\treturn 0;\n\nexit3:\n\tgru_free_tables();\nexit2:\n\tgru_proc_exit();\nexit1:\n\tmisc_deregister(&gru_miscdev);\nexit0:\n\treturn ret;\n\n}\n\nstatic void __exit gru_exit(void)\n{\n\tif (!gru_supported())\n\t\treturn;\n\n\tgru_teardown_tlb_irqs();\n\tgru_kservices_exit();\n\tgru_free_tables();\n\tmisc_deregister(&gru_miscdev);\n\tgru_proc_exit();\n\tmmu_notifier_synchronize();\n}\n\nstatic const struct file_operations gru_fops = {\n\t.owner\t\t= THIS_MODULE,\n\t.unlocked_ioctl\t= gru_file_unlocked_ioctl,\n\t.mmap\t\t= gru_file_mmap,\n\t.llseek\t\t= noop_llseek,\n};\n\nstatic struct miscdevice gru_miscdev = {\n\t.minor\t\t= MISC_DYNAMIC_MINOR,\n\t.name\t\t= \"gru\",\n\t.fops\t\t= &gru_fops,\n};\n\nconst struct vm_operations_struct gru_vm_ops = {\n\t.close\t\t= gru_vma_close,\n\t.fault\t\t= gru_fault,\n};\n\n#ifndef MODULE\nfs_initcall(gru_init);\n#else\nmodule_init(gru_init);\n#endif\nmodule_exit(gru_exit);\n\nmodule_param(gru_options, ulong, 0644);\nMODULE_PARM_DESC(gru_options, \"Various debug options\");\n\nMODULE_AUTHOR(\"Silicon Graphics, Inc.\");\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(GRU_DRIVER_ID_STR GRU_DRIVER_VERSION_STR);\nMODULE_VERSION(GRU_DRIVER_VERSION_STR);\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}