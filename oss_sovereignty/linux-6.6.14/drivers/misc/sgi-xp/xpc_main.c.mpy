{
  "module_name": "xpc_main.c",
  "hash_id": "37904bb6ceb9533949517bbe45e14514ff57a71087908d4e80e873409977159f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/sgi-xp/xpc_main.c",
  "human_readable_source": " \n\n \n\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n#include <linux/device.h>\n#include <linux/delay.h>\n#include <linux/reboot.h>\n#include <linux/kdebug.h>\n#include <linux/kthread.h>\n#include \"xpc.h\"\n\n#ifdef CONFIG_X86_64\n#include <asm/traps.h>\n#endif\n\n \n\nstatic struct device_driver xpc_dbg_name = {\n\t.name = \"xpc\"\n};\n\nstatic struct device xpc_part_dbg_subname = {\n\t.init_name = \"\",\t \n\t.driver = &xpc_dbg_name\n};\n\nstatic struct device xpc_chan_dbg_subname = {\n\t.init_name = \"\",\t \n\t.driver = &xpc_dbg_name\n};\n\nstruct device *xpc_part = &xpc_part_dbg_subname;\nstruct device *xpc_chan = &xpc_chan_dbg_subname;\n\nstatic int xpc_kdebug_ignore;\n\n \n\nstatic int xpc_hb_interval = XPC_HB_DEFAULT_INTERVAL;\nstatic int xpc_hb_min_interval = 1;\nstatic int xpc_hb_max_interval = 10;\n\nstatic int xpc_hb_check_interval = XPC_HB_CHECK_DEFAULT_INTERVAL;\nstatic int xpc_hb_check_min_interval = 10;\nstatic int xpc_hb_check_max_interval = 120;\n\nint xpc_disengage_timelimit = XPC_DISENGAGE_DEFAULT_TIMELIMIT;\nstatic int xpc_disengage_min_timelimit;\t \nstatic int xpc_disengage_max_timelimit = 120;\n\nstatic struct ctl_table xpc_sys_xpc_hb[] = {\n\t{\n\t .procname = \"hb_interval\",\n\t .data = &xpc_hb_interval,\n\t .maxlen = sizeof(int),\n\t .mode = 0644,\n\t .proc_handler = proc_dointvec_minmax,\n\t .extra1 = &xpc_hb_min_interval,\n\t .extra2 = &xpc_hb_max_interval},\n\t{\n\t .procname = \"hb_check_interval\",\n\t .data = &xpc_hb_check_interval,\n\t .maxlen = sizeof(int),\n\t .mode = 0644,\n\t .proc_handler = proc_dointvec_minmax,\n\t .extra1 = &xpc_hb_check_min_interval,\n\t .extra2 = &xpc_hb_check_max_interval},\n\t{}\n};\nstatic struct ctl_table xpc_sys_xpc[] = {\n\t{\n\t .procname = \"disengage_timelimit\",\n\t .data = &xpc_disengage_timelimit,\n\t .maxlen = sizeof(int),\n\t .mode = 0644,\n\t .proc_handler = proc_dointvec_minmax,\n\t .extra1 = &xpc_disengage_min_timelimit,\n\t .extra2 = &xpc_disengage_max_timelimit},\n\t{}\n};\n\nstatic struct ctl_table_header *xpc_sysctl;\nstatic struct ctl_table_header *xpc_sysctl_hb;\n\n \nint xpc_disengage_timedout;\n\n \nint xpc_activate_IRQ_rcvd;\nDEFINE_SPINLOCK(xpc_activate_IRQ_rcvd_lock);\n\n \nDECLARE_WAIT_QUEUE_HEAD(xpc_activate_IRQ_wq);\n\nstatic unsigned long xpc_hb_check_timeout;\nstatic struct timer_list xpc_hb_timer;\n\n \nstatic DECLARE_COMPLETION(xpc_hb_checker_exited);\n\n \nstatic DECLARE_COMPLETION(xpc_discovery_exited);\n\nstatic void xpc_kthread_waitmsgs(struct xpc_partition *, struct xpc_channel *);\n\nstatic int xpc_system_reboot(struct notifier_block *, unsigned long, void *);\nstatic struct notifier_block xpc_reboot_notifier = {\n\t.notifier_call = xpc_system_reboot,\n};\n\nstatic int xpc_system_die(struct notifier_block *, unsigned long, void *);\nstatic struct notifier_block xpc_die_notifier = {\n\t.notifier_call = xpc_system_die,\n};\n\nstruct xpc_arch_operations xpc_arch_ops;\n\n \nstatic void\nxpc_timeout_partition_disengage(struct timer_list *t)\n{\n\tstruct xpc_partition *part = from_timer(part, t, disengage_timer);\n\n\tDBUG_ON(time_is_after_jiffies(part->disengage_timeout));\n\n\txpc_partition_disengaged_from_timer(part);\n\n\tDBUG_ON(part->disengage_timeout != 0);\n\tDBUG_ON(xpc_arch_ops.partition_engaged(XPC_PARTID(part)));\n}\n\n \nstatic void\nxpc_hb_beater(struct timer_list *unused)\n{\n\txpc_arch_ops.increment_heartbeat();\n\n\tif (time_is_before_eq_jiffies(xpc_hb_check_timeout))\n\t\twake_up_interruptible(&xpc_activate_IRQ_wq);\n\n\txpc_hb_timer.expires = jiffies + (xpc_hb_interval * HZ);\n\tadd_timer(&xpc_hb_timer);\n}\n\nstatic void\nxpc_start_hb_beater(void)\n{\n\txpc_arch_ops.heartbeat_init();\n\ttimer_setup(&xpc_hb_timer, xpc_hb_beater, 0);\n\txpc_hb_beater(NULL);\n}\n\nstatic void\nxpc_stop_hb_beater(void)\n{\n\tdel_timer_sync(&xpc_hb_timer);\n\txpc_arch_ops.heartbeat_exit();\n}\n\n \nstatic void\nxpc_check_remote_hb(void)\n{\n\tstruct xpc_partition *part;\n\tshort partid;\n\tenum xp_retval ret;\n\n\tfor (partid = 0; partid < xp_max_npartitions; partid++) {\n\n\t\tif (xpc_exiting)\n\t\t\tbreak;\n\n\t\tif (partid == xp_partition_id)\n\t\t\tcontinue;\n\n\t\tpart = &xpc_partitions[partid];\n\n\t\tif (part->act_state == XPC_P_AS_INACTIVE ||\n\t\t    part->act_state == XPC_P_AS_DEACTIVATING) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = xpc_arch_ops.get_remote_heartbeat(part);\n\t\tif (ret != xpSuccess)\n\t\t\tXPC_DEACTIVATE_PARTITION(part, ret);\n\t}\n}\n\n \nstatic int\nxpc_hb_checker(void *ignore)\n{\n\tint force_IRQ = 0;\n\n\t \n\n\tset_cpus_allowed_ptr(current, cpumask_of(XPC_HB_CHECK_CPU));\n\n\t \n\txpc_hb_check_timeout = jiffies + (xpc_hb_check_interval * HZ);\n\txpc_start_hb_beater();\n\n\twhile (!xpc_exiting) {\n\n\t\tdev_dbg(xpc_part, \"woke up with %d ticks rem; %d IRQs have \"\n\t\t\t\"been received\\n\",\n\t\t\t(int)(xpc_hb_check_timeout - jiffies),\n\t\t\txpc_activate_IRQ_rcvd);\n\n\t\t \n\t\tif (time_is_before_eq_jiffies(xpc_hb_check_timeout)) {\n\t\t\txpc_hb_check_timeout = jiffies +\n\t\t\t    (xpc_hb_check_interval * HZ);\n\n\t\t\tdev_dbg(xpc_part, \"checking remote heartbeats\\n\");\n\t\t\txpc_check_remote_hb();\n\t\t}\n\n\t\t \n\t\tif (xpc_activate_IRQ_rcvd > 0 || force_IRQ != 0) {\n\t\t\tforce_IRQ = 0;\n\t\t\tdev_dbg(xpc_part, \"processing activate IRQs \"\n\t\t\t\t\"received\\n\");\n\t\t\txpc_arch_ops.process_activate_IRQ_rcvd();\n\t\t}\n\n\t\t \n\t\t(void)wait_event_interruptible(xpc_activate_IRQ_wq,\n\t\t\t\t\t       (time_is_before_eq_jiffies(\n\t\t\t\t\t\txpc_hb_check_timeout) ||\n\t\t\t\t\t\txpc_activate_IRQ_rcvd > 0 ||\n\t\t\t\t\t\txpc_exiting));\n\t}\n\n\txpc_stop_hb_beater();\n\n\tdev_dbg(xpc_part, \"heartbeat checker is exiting\\n\");\n\n\t \n\tcomplete(&xpc_hb_checker_exited);\n\treturn 0;\n}\n\n \nstatic int\nxpc_initiate_discovery(void *ignore)\n{\n\txpc_discovery();\n\n\tdev_dbg(xpc_part, \"discovery thread is exiting\\n\");\n\n\t \n\tcomplete(&xpc_discovery_exited);\n\treturn 0;\n}\n\n \nstatic void\nxpc_channel_mgr(struct xpc_partition *part)\n{\n\twhile (part->act_state != XPC_P_AS_DEACTIVATING ||\n\t       atomic_read(&part->nchannels_active) > 0 ||\n\t       !xpc_partition_disengaged(part)) {\n\n\t\txpc_process_sent_chctl_flags(part);\n\n\t\t \n\t\tatomic_dec(&part->channel_mgr_requests);\n\t\t(void)wait_event_interruptible(part->channel_mgr_wq,\n\t\t\t\t(atomic_read(&part->channel_mgr_requests) > 0 ||\n\t\t\t\t part->chctl.all_flags != 0 ||\n\t\t\t\t (part->act_state == XPC_P_AS_DEACTIVATING &&\n\t\t\t\t atomic_read(&part->nchannels_active) == 0 &&\n\t\t\t\t xpc_partition_disengaged(part))));\n\t\tatomic_set(&part->channel_mgr_requests, 1);\n\t}\n}\n\n \nvoid *\nxpc_kzalloc_cacheline_aligned(size_t size, gfp_t flags, void **base)\n{\n\t \n\t*base = kzalloc(size, flags);\n\tif (*base == NULL)\n\t\treturn NULL;\n\n\tif ((u64)*base == L1_CACHE_ALIGN((u64)*base))\n\t\treturn *base;\n\n\tkfree(*base);\n\n\t \n\t*base = kzalloc(size + L1_CACHE_BYTES, flags);\n\tif (*base == NULL)\n\t\treturn NULL;\n\n\treturn (void *)L1_CACHE_ALIGN((u64)*base);\n}\n\n \nstatic enum xp_retval\nxpc_setup_ch_structures(struct xpc_partition *part)\n{\n\tenum xp_retval ret;\n\tint ch_number;\n\tstruct xpc_channel *ch;\n\tshort partid = XPC_PARTID(part);\n\n\t \n\tDBUG_ON(part->channels != NULL);\n\tpart->channels = kcalloc(XPC_MAX_NCHANNELS,\n\t\t\t\t sizeof(struct xpc_channel),\n\t\t\t\t GFP_KERNEL);\n\tif (part->channels == NULL) {\n\t\tdev_err(xpc_chan, \"can't get memory for channels\\n\");\n\t\treturn xpNoMemory;\n\t}\n\n\t \n\n\tpart->remote_openclose_args =\n\t    xpc_kzalloc_cacheline_aligned(XPC_OPENCLOSE_ARGS_SIZE,\n\t\t\t\t\t  GFP_KERNEL, &part->\n\t\t\t\t\t  remote_openclose_args_base);\n\tif (part->remote_openclose_args == NULL) {\n\t\tdev_err(xpc_chan, \"can't get memory for remote connect args\\n\");\n\t\tret = xpNoMemory;\n\t\tgoto out_1;\n\t}\n\n\tpart->chctl.all_flags = 0;\n\tspin_lock_init(&part->chctl_lock);\n\n\tatomic_set(&part->channel_mgr_requests, 1);\n\tinit_waitqueue_head(&part->channel_mgr_wq);\n\n\tpart->nchannels = XPC_MAX_NCHANNELS;\n\n\tatomic_set(&part->nchannels_active, 0);\n\tatomic_set(&part->nchannels_engaged, 0);\n\n\tfor (ch_number = 0; ch_number < part->nchannels; ch_number++) {\n\t\tch = &part->channels[ch_number];\n\n\t\tch->partid = partid;\n\t\tch->number = ch_number;\n\t\tch->flags = XPC_C_DISCONNECTED;\n\n\t\tatomic_set(&ch->kthreads_assigned, 0);\n\t\tatomic_set(&ch->kthreads_idle, 0);\n\t\tatomic_set(&ch->kthreads_active, 0);\n\n\t\tatomic_set(&ch->references, 0);\n\t\tatomic_set(&ch->n_to_notify, 0);\n\n\t\tspin_lock_init(&ch->lock);\n\t\tinit_completion(&ch->wdisconnect_wait);\n\n\t\tatomic_set(&ch->n_on_msg_allocate_wq, 0);\n\t\tinit_waitqueue_head(&ch->msg_allocate_wq);\n\t\tinit_waitqueue_head(&ch->idle_wq);\n\t}\n\n\tret = xpc_arch_ops.setup_ch_structures(part);\n\tif (ret != xpSuccess)\n\t\tgoto out_2;\n\n\t \n\tpart->setup_state = XPC_P_SS_SETUP;\n\n\treturn xpSuccess;\n\n\t \nout_2:\n\tkfree(part->remote_openclose_args_base);\n\tpart->remote_openclose_args = NULL;\nout_1:\n\tkfree(part->channels);\n\tpart->channels = NULL;\n\treturn ret;\n}\n\n \nstatic void\nxpc_teardown_ch_structures(struct xpc_partition *part)\n{\n\tDBUG_ON(atomic_read(&part->nchannels_engaged) != 0);\n\tDBUG_ON(atomic_read(&part->nchannels_active) != 0);\n\n\t \n\tDBUG_ON(part->setup_state != XPC_P_SS_SETUP);\n\tpart->setup_state = XPC_P_SS_WTEARDOWN;\n\n\twait_event(part->teardown_wq, (atomic_read(&part->references) == 0));\n\n\t \n\n\txpc_arch_ops.teardown_ch_structures(part);\n\n\tkfree(part->remote_openclose_args_base);\n\tpart->remote_openclose_args = NULL;\n\tkfree(part->channels);\n\tpart->channels = NULL;\n\n\tpart->setup_state = XPC_P_SS_TORNDOWN;\n}\n\n \nstatic int\nxpc_activating(void *__partid)\n{\n\tshort partid = (u64)__partid;\n\tstruct xpc_partition *part = &xpc_partitions[partid];\n\tunsigned long irq_flags;\n\n\tDBUG_ON(partid < 0 || partid >= xp_max_npartitions);\n\n\tspin_lock_irqsave(&part->act_lock, irq_flags);\n\n\tif (part->act_state == XPC_P_AS_DEACTIVATING) {\n\t\tpart->act_state = XPC_P_AS_INACTIVE;\n\t\tspin_unlock_irqrestore(&part->act_lock, irq_flags);\n\t\tpart->remote_rp_pa = 0;\n\t\treturn 0;\n\t}\n\n\t \n\tDBUG_ON(part->act_state != XPC_P_AS_ACTIVATION_REQ);\n\tpart->act_state = XPC_P_AS_ACTIVATING;\n\n\tXPC_SET_REASON(part, 0, 0);\n\tspin_unlock_irqrestore(&part->act_lock, irq_flags);\n\n\tdev_dbg(xpc_part, \"activating partition %d\\n\", partid);\n\n\txpc_arch_ops.allow_hb(partid);\n\n\tif (xpc_setup_ch_structures(part) == xpSuccess) {\n\t\t(void)xpc_part_ref(part);\t \n\n\t\tif (xpc_arch_ops.make_first_contact(part) == xpSuccess) {\n\t\t\txpc_mark_partition_active(part);\n\t\t\txpc_channel_mgr(part);\n\t\t\t \n\t\t}\n\n\t\txpc_part_deref(part);\n\t\txpc_teardown_ch_structures(part);\n\t}\n\n\txpc_arch_ops.disallow_hb(partid);\n\txpc_mark_partition_inactive(part);\n\n\tif (part->reason == xpReactivating) {\n\t\t \n\t\txpc_arch_ops.request_partition_reactivation(part);\n\t}\n\n\treturn 0;\n}\n\nvoid\nxpc_activate_partition(struct xpc_partition *part)\n{\n\tshort partid = XPC_PARTID(part);\n\tunsigned long irq_flags;\n\tstruct task_struct *kthread;\n\n\tspin_lock_irqsave(&part->act_lock, irq_flags);\n\n\tDBUG_ON(part->act_state != XPC_P_AS_INACTIVE);\n\n\tpart->act_state = XPC_P_AS_ACTIVATION_REQ;\n\tXPC_SET_REASON(part, xpCloneKThread, __LINE__);\n\n\tspin_unlock_irqrestore(&part->act_lock, irq_flags);\n\n\tkthread = kthread_run(xpc_activating, (void *)((u64)partid), \"xpc%02d\",\n\t\t\t      partid);\n\tif (IS_ERR(kthread)) {\n\t\tspin_lock_irqsave(&part->act_lock, irq_flags);\n\t\tpart->act_state = XPC_P_AS_INACTIVE;\n\t\tXPC_SET_REASON(part, xpCloneKThreadFailed, __LINE__);\n\t\tspin_unlock_irqrestore(&part->act_lock, irq_flags);\n\t}\n}\n\nvoid\nxpc_activate_kthreads(struct xpc_channel *ch, int needed)\n{\n\tint idle = atomic_read(&ch->kthreads_idle);\n\tint assigned = atomic_read(&ch->kthreads_assigned);\n\tint wakeup;\n\n\tDBUG_ON(needed <= 0);\n\n\tif (idle > 0) {\n\t\twakeup = (needed > idle) ? idle : needed;\n\t\tneeded -= wakeup;\n\n\t\tdev_dbg(xpc_chan, \"wakeup %d idle kthreads, partid=%d, \"\n\t\t\t\"channel=%d\\n\", wakeup, ch->partid, ch->number);\n\n\t\t \n\t\twake_up_nr(&ch->idle_wq, wakeup);\n\t}\n\n\tif (needed <= 0)\n\t\treturn;\n\n\tif (needed + assigned > ch->kthreads_assigned_limit) {\n\t\tneeded = ch->kthreads_assigned_limit - assigned;\n\t\tif (needed <= 0)\n\t\t\treturn;\n\t}\n\n\tdev_dbg(xpc_chan, \"create %d new kthreads, partid=%d, channel=%d\\n\",\n\t\tneeded, ch->partid, ch->number);\n\n\txpc_create_kthreads(ch, needed, 0);\n}\n\n \nstatic void\nxpc_kthread_waitmsgs(struct xpc_partition *part, struct xpc_channel *ch)\n{\n\tint (*n_of_deliverable_payloads) (struct xpc_channel *) =\n\t\txpc_arch_ops.n_of_deliverable_payloads;\n\n\tdo {\n\t\t \n\n\t\twhile (n_of_deliverable_payloads(ch) > 0 &&\n\t\t       !(ch->flags & XPC_C_DISCONNECTING)) {\n\t\t\txpc_deliver_payload(ch);\n\t\t}\n\n\t\tif (atomic_inc_return(&ch->kthreads_idle) >\n\t\t    ch->kthreads_idle_limit) {\n\t\t\t \n\t\t\tatomic_dec(&ch->kthreads_idle);\n\t\t\tbreak;\n\t\t}\n\n\t\tdev_dbg(xpc_chan, \"idle kthread calling \"\n\t\t\t\"wait_event_interruptible_exclusive()\\n\");\n\n\t\t(void)wait_event_interruptible_exclusive(ch->idle_wq,\n\t\t\t\t(n_of_deliverable_payloads(ch) > 0 ||\n\t\t\t\t (ch->flags & XPC_C_DISCONNECTING)));\n\n\t\tatomic_dec(&ch->kthreads_idle);\n\n\t} while (!(ch->flags & XPC_C_DISCONNECTING));\n}\n\nstatic int\nxpc_kthread_start(void *args)\n{\n\tshort partid = XPC_UNPACK_ARG1(args);\n\tu16 ch_number = XPC_UNPACK_ARG2(args);\n\tstruct xpc_partition *part = &xpc_partitions[partid];\n\tstruct xpc_channel *ch;\n\tint n_needed;\n\tunsigned long irq_flags;\n\tint (*n_of_deliverable_payloads) (struct xpc_channel *) =\n\t\txpc_arch_ops.n_of_deliverable_payloads;\n\n\tdev_dbg(xpc_chan, \"kthread starting, partid=%d, channel=%d\\n\",\n\t\tpartid, ch_number);\n\n\tch = &part->channels[ch_number];\n\n\tif (!(ch->flags & XPC_C_DISCONNECTING)) {\n\n\t\t \n\n\t\tspin_lock_irqsave(&ch->lock, irq_flags);\n\t\tif (!(ch->flags & XPC_C_CONNECTEDCALLOUT)) {\n\t\t\tch->flags |= XPC_C_CONNECTEDCALLOUT;\n\t\t\tspin_unlock_irqrestore(&ch->lock, irq_flags);\n\n\t\t\txpc_connected_callout(ch);\n\n\t\t\tspin_lock_irqsave(&ch->lock, irq_flags);\n\t\t\tch->flags |= XPC_C_CONNECTEDCALLOUT_MADE;\n\t\t\tspin_unlock_irqrestore(&ch->lock, irq_flags);\n\n\t\t\t \n\t\t\tn_needed = n_of_deliverable_payloads(ch) - 1;\n\t\t\tif (n_needed > 0 && !(ch->flags & XPC_C_DISCONNECTING))\n\t\t\t\txpc_activate_kthreads(ch, n_needed);\n\n\t\t} else {\n\t\t\tspin_unlock_irqrestore(&ch->lock, irq_flags);\n\t\t}\n\n\t\txpc_kthread_waitmsgs(part, ch);\n\t}\n\n\t \n\n\tspin_lock_irqsave(&ch->lock, irq_flags);\n\tif ((ch->flags & XPC_C_CONNECTEDCALLOUT_MADE) &&\n\t    !(ch->flags & XPC_C_DISCONNECTINGCALLOUT)) {\n\t\tch->flags |= XPC_C_DISCONNECTINGCALLOUT;\n\t\tspin_unlock_irqrestore(&ch->lock, irq_flags);\n\n\t\txpc_disconnect_callout(ch, xpDisconnecting);\n\n\t\tspin_lock_irqsave(&ch->lock, irq_flags);\n\t\tch->flags |= XPC_C_DISCONNECTINGCALLOUT_MADE;\n\t}\n\tspin_unlock_irqrestore(&ch->lock, irq_flags);\n\n\tif (atomic_dec_return(&ch->kthreads_assigned) == 0 &&\n\t    atomic_dec_return(&part->nchannels_engaged) == 0) {\n\t\txpc_arch_ops.indicate_partition_disengaged(part);\n\t}\n\n\txpc_msgqueue_deref(ch);\n\n\tdev_dbg(xpc_chan, \"kthread exiting, partid=%d, channel=%d\\n\",\n\t\tpartid, ch_number);\n\n\txpc_part_deref(part);\n\treturn 0;\n}\n\n \nvoid\nxpc_create_kthreads(struct xpc_channel *ch, int needed,\n\t\t    int ignore_disconnecting)\n{\n\tunsigned long irq_flags;\n\tu64 args = XPC_PACK_ARGS(ch->partid, ch->number);\n\tstruct xpc_partition *part = &xpc_partitions[ch->partid];\n\tstruct task_struct *kthread;\n\tvoid (*indicate_partition_disengaged) (struct xpc_partition *) =\n\t\txpc_arch_ops.indicate_partition_disengaged;\n\n\twhile (needed-- > 0) {\n\n\t\t \n\t\tif (ignore_disconnecting) {\n\t\t\tif (!atomic_inc_not_zero(&ch->kthreads_assigned)) {\n\t\t\t\t \n\t\t\t\tBUG_ON(!(ch->flags &\n\t\t\t\t\t XPC_C_DISCONNECTINGCALLOUT_MADE));\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t} else if (ch->flags & XPC_C_DISCONNECTING) {\n\t\t\tbreak;\n\n\t\t} else if (atomic_inc_return(&ch->kthreads_assigned) == 1 &&\n\t\t\t   atomic_inc_return(&part->nchannels_engaged) == 1) {\n\t\t\txpc_arch_ops.indicate_partition_engaged(part);\n\t\t}\n\t\t(void)xpc_part_ref(part);\n\t\txpc_msgqueue_ref(ch);\n\n\t\tkthread = kthread_run(xpc_kthread_start, (void *)args,\n\t\t\t\t      \"xpc%02dc%d\", ch->partid, ch->number);\n\t\tif (IS_ERR(kthread)) {\n\t\t\t \n\n\t\t\t \n\n\t\t\tif (atomic_dec_return(&ch->kthreads_assigned) == 0 &&\n\t\t\t    atomic_dec_return(&part->nchannels_engaged) == 0) {\n\t\t\t\tindicate_partition_disengaged(part);\n\t\t\t}\n\t\t\txpc_msgqueue_deref(ch);\n\t\t\txpc_part_deref(part);\n\n\t\t\tif (atomic_read(&ch->kthreads_assigned) <\n\t\t\t    ch->kthreads_idle_limit) {\n\t\t\t\t \n\t\t\t\tspin_lock_irqsave(&ch->lock, irq_flags);\n\t\t\t\tXPC_DISCONNECT_CHANNEL(ch, xpLackOfResources,\n\t\t\t\t\t\t       &irq_flags);\n\t\t\t\tspin_unlock_irqrestore(&ch->lock, irq_flags);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nvoid\nxpc_disconnect_wait(int ch_number)\n{\n\tunsigned long irq_flags;\n\tshort partid;\n\tstruct xpc_partition *part;\n\tstruct xpc_channel *ch;\n\tint wakeup_channel_mgr;\n\n\t \n\tfor (partid = 0; partid < xp_max_npartitions; partid++) {\n\t\tpart = &xpc_partitions[partid];\n\n\t\tif (!xpc_part_ref(part))\n\t\t\tcontinue;\n\n\t\tch = &part->channels[ch_number];\n\n\t\tif (!(ch->flags & XPC_C_WDISCONNECT)) {\n\t\t\txpc_part_deref(part);\n\t\t\tcontinue;\n\t\t}\n\n\t\twait_for_completion(&ch->wdisconnect_wait);\n\n\t\tspin_lock_irqsave(&ch->lock, irq_flags);\n\t\tDBUG_ON(!(ch->flags & XPC_C_DISCONNECTED));\n\t\twakeup_channel_mgr = 0;\n\n\t\tif (ch->delayed_chctl_flags) {\n\t\t\tif (part->act_state != XPC_P_AS_DEACTIVATING) {\n\t\t\t\tspin_lock(&part->chctl_lock);\n\t\t\t\tpart->chctl.flags[ch->number] |=\n\t\t\t\t    ch->delayed_chctl_flags;\n\t\t\t\tspin_unlock(&part->chctl_lock);\n\t\t\t\twakeup_channel_mgr = 1;\n\t\t\t}\n\t\t\tch->delayed_chctl_flags = 0;\n\t\t}\n\n\t\tch->flags &= ~XPC_C_WDISCONNECT;\n\t\tspin_unlock_irqrestore(&ch->lock, irq_flags);\n\n\t\tif (wakeup_channel_mgr)\n\t\t\txpc_wakeup_channel_mgr(part);\n\n\t\txpc_part_deref(part);\n\t}\n}\n\nstatic int\nxpc_setup_partitions(void)\n{\n\tshort partid;\n\tstruct xpc_partition *part;\n\n\txpc_partitions = kcalloc(xp_max_npartitions,\n\t\t\t\t sizeof(struct xpc_partition),\n\t\t\t\t GFP_KERNEL);\n\tif (xpc_partitions == NULL) {\n\t\tdev_err(xpc_part, \"can't get memory for partition structure\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tfor (partid = 0; partid < xp_max_npartitions; partid++) {\n\t\tpart = &xpc_partitions[partid];\n\n\t\tDBUG_ON((u64)part != L1_CACHE_ALIGN((u64)part));\n\n\t\tpart->activate_IRQ_rcvd = 0;\n\t\tspin_lock_init(&part->act_lock);\n\t\tpart->act_state = XPC_P_AS_INACTIVE;\n\t\tXPC_SET_REASON(part, 0, 0);\n\n\t\ttimer_setup(&part->disengage_timer,\n\t\t\t    xpc_timeout_partition_disengage, 0);\n\n\t\tpart->setup_state = XPC_P_SS_UNSET;\n\t\tinit_waitqueue_head(&part->teardown_wq);\n\t\tatomic_set(&part->references, 0);\n\t}\n\n\treturn xpc_arch_ops.setup_partitions();\n}\n\nstatic void\nxpc_teardown_partitions(void)\n{\n\txpc_arch_ops.teardown_partitions();\n\tkfree(xpc_partitions);\n}\n\nstatic void\nxpc_do_exit(enum xp_retval reason)\n{\n\tshort partid;\n\tint active_part_count, printed_waiting_msg = 0;\n\tstruct xpc_partition *part;\n\tunsigned long printmsg_time, disengage_timeout = 0;\n\n\t \n\tDBUG_ON(xpc_exiting == 1);\n\n\t \n\txpc_exiting = 1;\n\twake_up_interruptible(&xpc_activate_IRQ_wq);\n\n\t \n\twait_for_completion(&xpc_discovery_exited);\n\n\t \n\twait_for_completion(&xpc_hb_checker_exited);\n\n\t \n\t(void)msleep_interruptible(300);\n\n\t \n\n\tprintmsg_time = jiffies + (XPC_DEACTIVATE_PRINTMSG_INTERVAL * HZ);\n\txpc_disengage_timedout = 0;\n\n\tdo {\n\t\tactive_part_count = 0;\n\n\t\tfor (partid = 0; partid < xp_max_npartitions; partid++) {\n\t\t\tpart = &xpc_partitions[partid];\n\n\t\t\tif (xpc_partition_disengaged(part) &&\n\t\t\t    part->act_state == XPC_P_AS_INACTIVE) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tactive_part_count++;\n\n\t\t\tXPC_DEACTIVATE_PARTITION(part, reason);\n\n\t\t\tif (part->disengage_timeout > disengage_timeout)\n\t\t\t\tdisengage_timeout = part->disengage_timeout;\n\t\t}\n\n\t\tif (xpc_arch_ops.any_partition_engaged()) {\n\t\t\tif (time_is_before_jiffies(printmsg_time)) {\n\t\t\t\tdev_info(xpc_part, \"waiting for remote \"\n\t\t\t\t\t \"partitions to deactivate, timeout in \"\n\t\t\t\t\t \"%ld seconds\\n\", (disengage_timeout -\n\t\t\t\t\t jiffies) / HZ);\n\t\t\t\tprintmsg_time = jiffies +\n\t\t\t\t    (XPC_DEACTIVATE_PRINTMSG_INTERVAL * HZ);\n\t\t\t\tprinted_waiting_msg = 1;\n\t\t\t}\n\n\t\t} else if (active_part_count > 0) {\n\t\t\tif (printed_waiting_msg) {\n\t\t\t\tdev_info(xpc_part, \"waiting for local partition\"\n\t\t\t\t\t \" to deactivate\\n\");\n\t\t\t\tprinted_waiting_msg = 0;\n\t\t\t}\n\n\t\t} else {\n\t\t\tif (!xpc_disengage_timedout) {\n\t\t\t\tdev_info(xpc_part, \"all partitions have \"\n\t\t\t\t\t \"deactivated\\n\");\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\t(void)msleep_interruptible(300);\n\n\t} while (1);\n\n\tDBUG_ON(xpc_arch_ops.any_partition_engaged());\n\n\txpc_teardown_rsvd_page();\n\n\tif (reason == xpUnloading) {\n\t\t(void)unregister_die_notifier(&xpc_die_notifier);\n\t\t(void)unregister_reboot_notifier(&xpc_reboot_notifier);\n\t}\n\n\t \n\txpc_clear_interface();\n\n\tif (xpc_sysctl)\n\t\tunregister_sysctl_table(xpc_sysctl);\n\tif (xpc_sysctl_hb)\n\t\tunregister_sysctl_table(xpc_sysctl_hb);\n\n\txpc_teardown_partitions();\n\n\tif (is_uv_system())\n\t\txpc_exit_uv();\n}\n\n \nstatic int\nxpc_system_reboot(struct notifier_block *nb, unsigned long event, void *unused)\n{\n\tenum xp_retval reason;\n\n\tswitch (event) {\n\tcase SYS_RESTART:\n\t\treason = xpSystemReboot;\n\t\tbreak;\n\tcase SYS_HALT:\n\t\treason = xpSystemHalt;\n\t\tbreak;\n\tcase SYS_POWER_OFF:\n\t\treason = xpSystemPoweroff;\n\t\tbreak;\n\tdefault:\n\t\treason = xpSystemGoingDown;\n\t}\n\n\txpc_do_exit(reason);\n\treturn NOTIFY_DONE;\n}\n\n \nstatic unsigned int xpc_die_disconnecting;\n\n \nstatic void\nxpc_die_deactivate(void)\n{\n\tstruct xpc_partition *part;\n\tshort partid;\n\tint any_engaged;\n\tlong keep_waiting;\n\tlong wait_to_print;\n\n\tif (cmpxchg(&xpc_die_disconnecting, 0, 1))\n\t\treturn;\n\n\t \n\txpc_exiting = 1;\n\n\txpc_arch_ops.disallow_all_hbs();    \n\n\tfor (partid = 0; partid < xp_max_npartitions; partid++) {\n\t\tpart = &xpc_partitions[partid];\n\n\t\tif (xpc_arch_ops.partition_engaged(partid) ||\n\t\t    part->act_state != XPC_P_AS_INACTIVE) {\n\t\t\txpc_arch_ops.request_partition_deactivation(part);\n\t\t\txpc_arch_ops.indicate_partition_disengaged(part);\n\t\t}\n\t}\n\n\t \n\tkeep_waiting = xpc_disengage_timelimit * 1000 * 5;\n\twait_to_print = XPC_DEACTIVATE_PRINTMSG_INTERVAL * 1000 * 5;\n\n\twhile (1) {\n\t\tany_engaged = xpc_arch_ops.any_partition_engaged();\n\t\tif (!any_engaged) {\n\t\t\tdev_info(xpc_part, \"all partitions have deactivated\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!keep_waiting--) {\n\t\t\tfor (partid = 0; partid < xp_max_npartitions;\n\t\t\t     partid++) {\n\t\t\t\tif (xpc_arch_ops.partition_engaged(partid)) {\n\t\t\t\t\tdev_info(xpc_part, \"deactivate from \"\n\t\t\t\t\t\t \"remote partition %d timed \"\n\t\t\t\t\t\t \"out\\n\", partid);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!wait_to_print--) {\n\t\t\tdev_info(xpc_part, \"waiting for remote partitions to \"\n\t\t\t\t \"deactivate, timeout in %ld seconds\\n\",\n\t\t\t\t keep_waiting / (1000 * 5));\n\t\t\twait_to_print = XPC_DEACTIVATE_PRINTMSG_INTERVAL *\n\t\t\t    1000 * 5;\n\t\t}\n\n\t\tudelay(200);\n\t}\n}\n\n \nstatic int\nxpc_system_die(struct notifier_block *nb, unsigned long event, void *_die_args)\n{\n#ifdef CONFIG_IA64\t\t \n\tswitch (event) {\n\tcase DIE_MACHINE_RESTART:\n\tcase DIE_MACHINE_HALT:\n\t\txpc_die_deactivate();\n\t\tbreak;\n\n\tcase DIE_KDEBUG_ENTER:\n\t\t \n\t\tif (!xpc_kdebug_ignore)\n\t\t\tbreak;\n\n\t\tfallthrough;\n\tcase DIE_MCA_MONARCH_ENTER:\n\tcase DIE_INIT_MONARCH_ENTER:\n\t\txpc_arch_ops.offline_heartbeat();\n\t\tbreak;\n\n\tcase DIE_KDEBUG_LEAVE:\n\t\t \n\t\tif (!xpc_kdebug_ignore)\n\t\t\tbreak;\n\n\t\tfallthrough;\n\tcase DIE_MCA_MONARCH_LEAVE:\n\tcase DIE_INIT_MONARCH_LEAVE:\n\t\txpc_arch_ops.online_heartbeat();\n\t\tbreak;\n\t}\n#else\n\tstruct die_args *die_args = _die_args;\n\n\tswitch (event) {\n\tcase DIE_TRAP:\n\t\tif (die_args->trapnr == X86_TRAP_DF)\n\t\t\txpc_die_deactivate();\n\n\t\tif (((die_args->trapnr == X86_TRAP_MF) ||\n\t\t     (die_args->trapnr == X86_TRAP_XF)) &&\n\t\t    !user_mode(die_args->regs))\n\t\t\txpc_die_deactivate();\n\n\t\tbreak;\n\tcase DIE_INT3:\n\tcase DIE_DEBUG:\n\t\tbreak;\n\tcase DIE_OOPS:\n\tcase DIE_GPF:\n\tdefault:\n\t\txpc_die_deactivate();\n\t}\n#endif\n\n\treturn NOTIFY_DONE;\n}\n\nstatic int __init\nxpc_init(void)\n{\n\tint ret;\n\tstruct task_struct *kthread;\n\n\tdev_set_name(xpc_part, \"part\");\n\tdev_set_name(xpc_chan, \"chan\");\n\n\tif (is_uv_system()) {\n\t\tret = xpc_init_uv();\n\n\t} else {\n\t\tret = -ENODEV;\n\t}\n\n\tif (ret != 0)\n\t\treturn ret;\n\n\tret = xpc_setup_partitions();\n\tif (ret != 0) {\n\t\tdev_err(xpc_part, \"can't get memory for partition structure\\n\");\n\t\tgoto out_1;\n\t}\n\n\txpc_sysctl = register_sysctl(\"xpc\", xpc_sys_xpc);\n\txpc_sysctl_hb = register_sysctl(\"xpc/hb\", xpc_sys_xpc_hb);\n\n\t \n\tret = xpc_setup_rsvd_page();\n\tif (ret != 0) {\n\t\tdev_err(xpc_part, \"can't setup our reserved page\\n\");\n\t\tgoto out_2;\n\t}\n\n\t \n\tret = register_reboot_notifier(&xpc_reboot_notifier);\n\tif (ret != 0)\n\t\tdev_warn(xpc_part, \"can't register reboot notifier\\n\");\n\n\t \n\tret = register_die_notifier(&xpc_die_notifier);\n\tif (ret != 0)\n\t\tdev_warn(xpc_part, \"can't register die notifier\\n\");\n\n\t \n\tkthread = kthread_run(xpc_hb_checker, NULL, XPC_HB_CHECK_THREAD_NAME);\n\tif (IS_ERR(kthread)) {\n\t\tdev_err(xpc_part, \"failed while forking hb check thread\\n\");\n\t\tret = -EBUSY;\n\t\tgoto out_3;\n\t}\n\n\t \n\tkthread = kthread_run(xpc_initiate_discovery, NULL,\n\t\t\t      XPC_DISCOVERY_THREAD_NAME);\n\tif (IS_ERR(kthread)) {\n\t\tdev_err(xpc_part, \"failed while forking discovery thread\\n\");\n\n\t\t \n\t\tcomplete(&xpc_discovery_exited);\n\n\t\txpc_do_exit(xpUnloading);\n\t\treturn -EBUSY;\n\t}\n\n\t \n\txpc_set_interface(xpc_initiate_connect, xpc_initiate_disconnect,\n\t\t\t  xpc_initiate_send, xpc_initiate_send_notify,\n\t\t\t  xpc_initiate_received, xpc_initiate_partid_to_nasids);\n\n\treturn 0;\n\n\t \nout_3:\n\txpc_teardown_rsvd_page();\n\n\t(void)unregister_die_notifier(&xpc_die_notifier);\n\t(void)unregister_reboot_notifier(&xpc_reboot_notifier);\nout_2:\n\tif (xpc_sysctl_hb)\n\t\tunregister_sysctl_table(xpc_sysctl_hb);\n\tif (xpc_sysctl)\n\t\tunregister_sysctl_table(xpc_sysctl);\n\n\txpc_teardown_partitions();\nout_1:\n\tif (is_uv_system())\n\t\txpc_exit_uv();\n\treturn ret;\n}\n\nmodule_init(xpc_init);\n\nstatic void __exit\nxpc_exit(void)\n{\n\txpc_do_exit(xpUnloading);\n}\n\nmodule_exit(xpc_exit);\n\nMODULE_AUTHOR(\"Silicon Graphics, Inc.\");\nMODULE_DESCRIPTION(\"Cross Partition Communication (XPC) support\");\nMODULE_LICENSE(\"GPL\");\n\nmodule_param(xpc_hb_interval, int, 0);\nMODULE_PARM_DESC(xpc_hb_interval, \"Number of seconds between \"\n\t\t \"heartbeat increments.\");\n\nmodule_param(xpc_hb_check_interval, int, 0);\nMODULE_PARM_DESC(xpc_hb_check_interval, \"Number of seconds between \"\n\t\t \"heartbeat checks.\");\n\nmodule_param(xpc_disengage_timelimit, int, 0);\nMODULE_PARM_DESC(xpc_disengage_timelimit, \"Number of seconds to wait \"\n\t\t \"for disengage to complete.\");\n\nmodule_param(xpc_kdebug_ignore, int, 0);\nMODULE_PARM_DESC(xpc_kdebug_ignore, \"Should lack of heartbeat be ignored by \"\n\t\t \"other partitions when dropping into kdebug.\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}