{
  "module_name": "api.c",
  "hash_id": "ec7c5f4d1244265810d364dcc6f39dad7cf54cd59372d477ae65a7431b316496",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/cxl/api.c",
  "human_readable_source": "\n \n\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include <linux/file.h>\n#include <misc/cxl.h>\n#include <linux/module.h>\n#include <linux/mount.h>\n#include <linux/pseudo_fs.h>\n#include <linux/sched/mm.h>\n#include <linux/mmu_context.h>\n#include <linux/irqdomain.h>\n\n#include \"cxl.h\"\n\n \n\n#define CXL_PSEUDO_FS_MAGIC\t0x1697697f\n\nstatic int cxl_fs_cnt;\nstatic struct vfsmount *cxl_vfs_mount;\n\nstatic int cxl_fs_init_fs_context(struct fs_context *fc)\n{\n\treturn init_pseudo(fc, CXL_PSEUDO_FS_MAGIC) ? 0 : -ENOMEM;\n}\n\nstatic struct file_system_type cxl_fs_type = {\n\t.name\t\t= \"cxl\",\n\t.owner\t\t= THIS_MODULE,\n\t.init_fs_context = cxl_fs_init_fs_context,\n\t.kill_sb\t= kill_anon_super,\n};\n\n\nvoid cxl_release_mapping(struct cxl_context *ctx)\n{\n\tif (ctx->kernelapi && ctx->mapping)\n\t\tsimple_release_fs(&cxl_vfs_mount, &cxl_fs_cnt);\n}\n\nstatic struct file *cxl_getfile(const char *name,\n\t\t\t\tconst struct file_operations *fops,\n\t\t\t\tvoid *priv, int flags)\n{\n\tstruct file *file;\n\tstruct inode *inode;\n\tint rc;\n\n\t \n\n\tif (fops->owner && !try_module_get(fops->owner))\n\t\treturn ERR_PTR(-ENOENT);\n\n\trc = simple_pin_fs(&cxl_fs_type, &cxl_vfs_mount, &cxl_fs_cnt);\n\tif (rc < 0) {\n\t\tpr_err(\"Cannot mount cxl pseudo filesystem: %d\\n\", rc);\n\t\tfile = ERR_PTR(rc);\n\t\tgoto err_module;\n\t}\n\n\tinode = alloc_anon_inode(cxl_vfs_mount->mnt_sb);\n\tif (IS_ERR(inode)) {\n\t\tfile = ERR_CAST(inode);\n\t\tgoto err_fs;\n\t}\n\n\tfile = alloc_file_pseudo(inode, cxl_vfs_mount, name,\n\t\t\t\t flags & (O_ACCMODE | O_NONBLOCK), fops);\n\tif (IS_ERR(file))\n\t\tgoto err_inode;\n\n\tfile->private_data = priv;\n\n\treturn file;\n\nerr_inode:\n\tiput(inode);\nerr_fs:\n\tsimple_release_fs(&cxl_vfs_mount, &cxl_fs_cnt);\nerr_module:\n\tmodule_put(fops->owner);\n\treturn file;\n}\n\nstruct cxl_context *cxl_dev_context_init(struct pci_dev *dev)\n{\n\tstruct cxl_afu *afu;\n\tstruct cxl_context  *ctx;\n\tint rc;\n\n\tafu = cxl_pci_to_afu(dev);\n\tif (IS_ERR(afu))\n\t\treturn ERR_CAST(afu);\n\n\tctx = cxl_context_alloc();\n\tif (!ctx)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tctx->kernelapi = true;\n\n\t \n\trc = cxl_context_init(ctx, afu, false);\n\tif (rc)\n\t\tgoto err_ctx;\n\n\treturn ctx;\n\nerr_ctx:\n\tkfree(ctx);\n\treturn ERR_PTR(rc);\n}\nEXPORT_SYMBOL_GPL(cxl_dev_context_init);\n\nstruct cxl_context *cxl_get_context(struct pci_dev *dev)\n{\n\treturn dev->dev.archdata.cxl_ctx;\n}\nEXPORT_SYMBOL_GPL(cxl_get_context);\n\nint cxl_release_context(struct cxl_context *ctx)\n{\n\tif (ctx->status >= STARTED)\n\t\treturn -EBUSY;\n\n\tcxl_context_free(ctx);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(cxl_release_context);\n\nstatic irq_hw_number_t cxl_find_afu_irq(struct cxl_context *ctx, int num)\n{\n\t__u16 range;\n\tint r;\n\n\tfor (r = 0; r < CXL_IRQ_RANGES; r++) {\n\t\trange = ctx->irqs.range[r];\n\t\tif (num < range) {\n\t\t\treturn ctx->irqs.offset[r] + num;\n\t\t}\n\t\tnum -= range;\n\t}\n\treturn 0;\n}\n\n\nint cxl_set_priv(struct cxl_context *ctx, void *priv)\n{\n\tif (!ctx)\n\t\treturn -EINVAL;\n\n\tctx->priv = priv;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(cxl_set_priv);\n\nvoid *cxl_get_priv(struct cxl_context *ctx)\n{\n\tif (!ctx)\n\t\treturn ERR_PTR(-EINVAL);\n\n\treturn ctx->priv;\n}\nEXPORT_SYMBOL_GPL(cxl_get_priv);\n\nint cxl_allocate_afu_irqs(struct cxl_context *ctx, int num)\n{\n\tint res;\n\tirq_hw_number_t hwirq;\n\n\tif (num == 0)\n\t\tnum = ctx->afu->pp_irqs;\n\tres = afu_allocate_irqs(ctx, num);\n\tif (res)\n\t\treturn res;\n\n\tif (!cpu_has_feature(CPU_FTR_HVMODE)) {\n\t\t \n\t\thwirq = cxl_find_afu_irq(ctx, 0);\n\t\tif (hwirq)\n\t\t\tcxl_map_irq(ctx->afu->adapter, hwirq, cxl_ops->psl_interrupt, ctx, \"psl\");\n\t}\n\n\tif (ctx->status == STARTED) {\n\t\tif (cxl_ops->update_ivtes)\n\t\t\tcxl_ops->update_ivtes(ctx);\n\t\telse WARN(1, \"BUG: cxl_allocate_afu_irqs must be called prior to starting the context on this platform\\n\");\n\t}\n\n\treturn res;\n}\nEXPORT_SYMBOL_GPL(cxl_allocate_afu_irqs);\n\nvoid cxl_free_afu_irqs(struct cxl_context *ctx)\n{\n\tirq_hw_number_t hwirq;\n\tunsigned int virq;\n\n\tif (!cpu_has_feature(CPU_FTR_HVMODE)) {\n\t\thwirq = cxl_find_afu_irq(ctx, 0);\n\t\tif (hwirq) {\n\t\t\tvirq = irq_find_mapping(NULL, hwirq);\n\t\t\tif (virq)\n\t\t\t\tcxl_unmap_irq(virq, ctx);\n\t\t}\n\t}\n\tafu_irq_name_free(ctx);\n\tcxl_ops->release_irq_ranges(&ctx->irqs, ctx->afu->adapter);\n}\nEXPORT_SYMBOL_GPL(cxl_free_afu_irqs);\n\nint cxl_map_afu_irq(struct cxl_context *ctx, int num,\n\t\t    irq_handler_t handler, void *cookie, char *name)\n{\n\tirq_hw_number_t hwirq;\n\n\t \n\thwirq = cxl_find_afu_irq(ctx, num);\n\tif (!hwirq)\n\t\treturn -ENOENT;\n\n\treturn cxl_map_irq(ctx->afu->adapter, hwirq, handler, cookie, name);\n}\nEXPORT_SYMBOL_GPL(cxl_map_afu_irq);\n\nvoid cxl_unmap_afu_irq(struct cxl_context *ctx, int num, void *cookie)\n{\n\tirq_hw_number_t hwirq;\n\tunsigned int virq;\n\n\thwirq = cxl_find_afu_irq(ctx, num);\n\tif (!hwirq)\n\t\treturn;\n\n\tvirq = irq_find_mapping(NULL, hwirq);\n\tif (virq)\n\t\tcxl_unmap_irq(virq, cookie);\n}\nEXPORT_SYMBOL_GPL(cxl_unmap_afu_irq);\n\n \nint cxl_start_context(struct cxl_context *ctx, u64 wed,\n\t\t      struct task_struct *task)\n{\n\tint rc = 0;\n\tbool kernel = true;\n\n\tpr_devel(\"%s: pe: %i\\n\", __func__, ctx->pe);\n\n\tmutex_lock(&ctx->status_mutex);\n\tif (ctx->status == STARTED)\n\t\tgoto out;  \n\n\t \n\trc = cxl_adapter_context_get(ctx->afu->adapter);\n\tif (rc)\n\t\tgoto out;\n\n\tif (task) {\n\t\tctx->pid = get_task_pid(task, PIDTYPE_PID);\n\t\tkernel = false;\n\n\t\t \n\t\tctx->mm = get_task_mm(current);\n\n\t\t \n\t\tcxl_context_mm_count_get(ctx);\n\n\t\tif (ctx->mm) {\n\t\t\t \n\t\t\tmmput(ctx->mm);\n\t\t\t \n\t\t\tmm_context_add_copro(ctx->mm);\n\t\t}\n\t}\n\n\t \n\tcxl_ctx_get();\n\n\t \n\tsmp_mb();\n\n\tif ((rc = cxl_ops->attach_process(ctx, kernel, wed, 0))) {\n\t\tput_pid(ctx->pid);\n\t\tctx->pid = NULL;\n\t\tcxl_adapter_context_put(ctx->afu->adapter);\n\t\tcxl_ctx_put();\n\t\tif (task) {\n\t\t\tcxl_context_mm_count_put(ctx);\n\t\t\tif (ctx->mm)\n\t\t\t\tmm_context_remove_copro(ctx->mm);\n\t\t}\n\t\tgoto out;\n\t}\n\n\tctx->status = STARTED;\nout:\n\tmutex_unlock(&ctx->status_mutex);\n\treturn rc;\n}\nEXPORT_SYMBOL_GPL(cxl_start_context);\n\nint cxl_process_element(struct cxl_context *ctx)\n{\n\treturn ctx->external_pe;\n}\nEXPORT_SYMBOL_GPL(cxl_process_element);\n\n \nint cxl_stop_context(struct cxl_context *ctx)\n{\n\treturn __detach_context(ctx);\n}\nEXPORT_SYMBOL_GPL(cxl_stop_context);\n\nvoid cxl_set_master(struct cxl_context *ctx)\n{\n\tctx->master = true;\n}\nEXPORT_SYMBOL_GPL(cxl_set_master);\n\n \nint cxl_fd_open(struct inode *inode, struct file *file)\n{\n\treturn afu_open(inode, file);\n}\nEXPORT_SYMBOL_GPL(cxl_fd_open);\nint cxl_fd_release(struct inode *inode, struct file *file)\n{\n\treturn afu_release(inode, file);\n}\nEXPORT_SYMBOL_GPL(cxl_fd_release);\nlong cxl_fd_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\treturn afu_ioctl(file, cmd, arg);\n}\nEXPORT_SYMBOL_GPL(cxl_fd_ioctl);\nint cxl_fd_mmap(struct file *file, struct vm_area_struct *vm)\n{\n\treturn afu_mmap(file, vm);\n}\nEXPORT_SYMBOL_GPL(cxl_fd_mmap);\n__poll_t cxl_fd_poll(struct file *file, struct poll_table_struct *poll)\n{\n\treturn afu_poll(file, poll);\n}\nEXPORT_SYMBOL_GPL(cxl_fd_poll);\nssize_t cxl_fd_read(struct file *file, char __user *buf, size_t count,\n\t\t\tloff_t *off)\n{\n\treturn afu_read(file, buf, count, off);\n}\nEXPORT_SYMBOL_GPL(cxl_fd_read);\n\n#define PATCH_FOPS(NAME) if (!fops->NAME) fops->NAME = afu_fops.NAME\n\n \nstruct file *cxl_get_fd(struct cxl_context *ctx, struct file_operations *fops,\n\t\t\tint *fd)\n{\n\tstruct file *file;\n\tint rc, flags, fdtmp;\n\tchar *name = NULL;\n\n\t \n\tif (ctx->mapping)\n\t\treturn ERR_PTR(-EEXIST);\n\n\tflags = O_RDWR | O_CLOEXEC;\n\n\t \n\trc = get_unused_fd_flags(flags);\n\tif (rc < 0)\n\t\treturn ERR_PTR(rc);\n\tfdtmp = rc;\n\n\t \n\tif (fops) {\n\t\tPATCH_FOPS(open);\n\t\tPATCH_FOPS(poll);\n\t\tPATCH_FOPS(read);\n\t\tPATCH_FOPS(release);\n\t\tPATCH_FOPS(unlocked_ioctl);\n\t\tPATCH_FOPS(compat_ioctl);\n\t\tPATCH_FOPS(mmap);\n\t} else  \n\t\tfops = (struct file_operations *)&afu_fops;\n\n\tname = kasprintf(GFP_KERNEL, \"cxl:%d\", ctx->pe);\n\tfile = cxl_getfile(name, fops, ctx, flags);\n\tkfree(name);\n\tif (IS_ERR(file))\n\t\tgoto err_fd;\n\n\tcxl_context_set_mapping(ctx, file->f_mapping);\n\t*fd = fdtmp;\n\treturn file;\n\nerr_fd:\n\tput_unused_fd(fdtmp);\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(cxl_get_fd);\n\nstruct cxl_context *cxl_fops_get_context(struct file *file)\n{\n\treturn file->private_data;\n}\nEXPORT_SYMBOL_GPL(cxl_fops_get_context);\n\nvoid cxl_set_driver_ops(struct cxl_context *ctx,\n\t\t\tstruct cxl_afu_driver_ops *ops)\n{\n\tWARN_ON(!ops->fetch_event || !ops->event_delivered);\n\tatomic_set(&ctx->afu_driver_events, 0);\n\tctx->afu_driver_ops = ops;\n}\nEXPORT_SYMBOL_GPL(cxl_set_driver_ops);\n\nvoid cxl_context_events_pending(struct cxl_context *ctx,\n\t\t\t\tunsigned int new_events)\n{\n\tatomic_add(new_events, &ctx->afu_driver_events);\n\twake_up_all(&ctx->wq);\n}\nEXPORT_SYMBOL_GPL(cxl_context_events_pending);\n\nint cxl_start_work(struct cxl_context *ctx,\n\t\t   struct cxl_ioctl_start_work *work)\n{\n\tint rc;\n\n\t \n\tif (!(work->flags & CXL_START_WORK_NUM_IRQS))\n\t\twork->num_interrupts = ctx->afu->pp_irqs;\n\telse if ((work->num_interrupts < ctx->afu->pp_irqs) ||\n\t\t (work->num_interrupts > ctx->afu->irqs_max)) {\n\t\treturn -EINVAL;\n\t}\n\n\trc = afu_register_irqs(ctx, work->num_interrupts);\n\tif (rc)\n\t\treturn rc;\n\n\trc = cxl_start_context(ctx, work->work_element_descriptor, current);\n\tif (rc < 0) {\n\t\tafu_release_irqs(ctx, ctx);\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(cxl_start_work);\n\nvoid __iomem *cxl_psa_map(struct cxl_context *ctx)\n{\n\tif (ctx->status != STARTED)\n\t\treturn NULL;\n\n\tpr_devel(\"%s: psn_phys%llx size:%llx\\n\",\n\t\t__func__, ctx->psn_phys, ctx->psn_size);\n\treturn ioremap(ctx->psn_phys, ctx->psn_size);\n}\nEXPORT_SYMBOL_GPL(cxl_psa_map);\n\nvoid cxl_psa_unmap(void __iomem *addr)\n{\n\tiounmap(addr);\n}\nEXPORT_SYMBOL_GPL(cxl_psa_unmap);\n\nint cxl_afu_reset(struct cxl_context *ctx)\n{\n\tstruct cxl_afu *afu = ctx->afu;\n\tint rc;\n\n\trc = cxl_ops->afu_reset(afu);\n\tif (rc)\n\t\treturn rc;\n\n\treturn cxl_ops->afu_check_and_enable(afu);\n}\nEXPORT_SYMBOL_GPL(cxl_afu_reset);\n\nvoid cxl_perst_reloads_same_image(struct cxl_afu *afu,\n\t\t\t\t  bool perst_reloads_same_image)\n{\n\tafu->adapter->perst_same_image = perst_reloads_same_image;\n}\nEXPORT_SYMBOL_GPL(cxl_perst_reloads_same_image);\n\nssize_t cxl_read_adapter_vpd(struct pci_dev *dev, void *buf, size_t count)\n{\n\tstruct cxl_afu *afu = cxl_pci_to_afu(dev);\n\tif (IS_ERR(afu))\n\t\treturn -ENODEV;\n\n\treturn cxl_ops->read_adapter_vpd(afu->adapter, buf, count);\n}\nEXPORT_SYMBOL_GPL(cxl_read_adapter_vpd);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}