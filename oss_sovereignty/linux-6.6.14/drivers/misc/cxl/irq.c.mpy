{
  "module_name": "irq.c",
  "hash_id": "178b3b72ac5dda3671bd6003c3c7bce3c62b584210a6d106d703f249976fede8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/cxl/irq.c",
  "human_readable_source": "\n \n\n#include <linux/interrupt.h>\n#include <linux/irqdomain.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <linux/wait.h>\n#include <linux/slab.h>\n#include <linux/pid.h>\n#include <asm/cputable.h>\n#include <misc/cxl-base.h>\n\n#include \"cxl.h\"\n#include \"trace.h\"\n\nstatic int afu_irq_range_start(void)\n{\n\tif (cpu_has_feature(CPU_FTR_HVMODE))\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic irqreturn_t schedule_cxl_fault(struct cxl_context *ctx, u64 dsisr, u64 dar)\n{\n\tctx->dsisr = dsisr;\n\tctx->dar = dar;\n\tschedule_work(&ctx->fault_work);\n\treturn IRQ_HANDLED;\n}\n\nirqreturn_t cxl_irq_psl9(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info)\n{\n\tu64 dsisr, dar;\n\n\tdsisr = irq_info->dsisr;\n\tdar = irq_info->dar;\n\n\ttrace_cxl_psl9_irq(ctx, irq, dsisr, dar);\n\n\tpr_devel(\"CXL interrupt %i for afu pe: %i DSISR: %#llx DAR: %#llx\\n\", irq, ctx->pe, dsisr, dar);\n\n\tif (dsisr & CXL_PSL9_DSISR_An_TF) {\n\t\tpr_devel(\"CXL interrupt: Scheduling translation fault handling for later (pe: %i)\\n\", ctx->pe);\n\t\treturn schedule_cxl_fault(ctx, dsisr, dar);\n\t}\n\n\tif (dsisr & CXL_PSL9_DSISR_An_PE)\n\t\treturn cxl_ops->handle_psl_slice_error(ctx, dsisr,\n\t\t\t\t\t\tirq_info->errstat);\n\tif (dsisr & CXL_PSL9_DSISR_An_AE) {\n\t\tpr_devel(\"CXL interrupt: AFU Error 0x%016llx\\n\", irq_info->afu_err);\n\n\t\tif (ctx->pending_afu_err) {\n\t\t\t \n\t\t\tdev_err_ratelimited(&ctx->afu->dev, \"CXL AFU Error undelivered to pe %i: 0x%016llx\\n\",\n\t\t\t\t\t    ctx->pe, irq_info->afu_err);\n\t\t} else {\n\t\t\tspin_lock(&ctx->lock);\n\t\t\tctx->afu_err = irq_info->afu_err;\n\t\t\tctx->pending_afu_err = 1;\n\t\t\tspin_unlock(&ctx->lock);\n\n\t\t\twake_up_all(&ctx->wq);\n\t\t}\n\n\t\tcxl_ops->ack_irq(ctx, CXL_PSL_TFC_An_A, 0);\n\t\treturn IRQ_HANDLED;\n\t}\n\tif (dsisr & CXL_PSL9_DSISR_An_OC)\n\t\tpr_devel(\"CXL interrupt: OS Context Warning\\n\");\n\n\tWARN(1, \"Unhandled CXL PSL IRQ\\n\");\n\treturn IRQ_HANDLED;\n}\n\nirqreturn_t cxl_irq_psl8(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info)\n{\n\tu64 dsisr, dar;\n\n\tdsisr = irq_info->dsisr;\n\tdar = irq_info->dar;\n\n\ttrace_cxl_psl_irq(ctx, irq, dsisr, dar);\n\n\tpr_devel(\"CXL interrupt %i for afu pe: %i DSISR: %#llx DAR: %#llx\\n\", irq, ctx->pe, dsisr, dar);\n\n\tif (dsisr & CXL_PSL_DSISR_An_DS) {\n\t\t \n\t\tpr_devel(\"Scheduling segment miss handling for later pe: %i\\n\", ctx->pe);\n\t\treturn schedule_cxl_fault(ctx, dsisr, dar);\n\t}\n\n\tif (dsisr & CXL_PSL_DSISR_An_M)\n\t\tpr_devel(\"CXL interrupt: PTE not found\\n\");\n\tif (dsisr & CXL_PSL_DSISR_An_P)\n\t\tpr_devel(\"CXL interrupt: Storage protection violation\\n\");\n\tif (dsisr & CXL_PSL_DSISR_An_A)\n\t\tpr_devel(\"CXL interrupt: AFU lock access to write through or cache inhibited storage\\n\");\n\tif (dsisr & CXL_PSL_DSISR_An_S)\n\t\tpr_devel(\"CXL interrupt: Access was afu_wr or afu_zero\\n\");\n\tif (dsisr & CXL_PSL_DSISR_An_K)\n\t\tpr_devel(\"CXL interrupt: Access not permitted by virtual page class key protection\\n\");\n\n\tif (dsisr & CXL_PSL_DSISR_An_DM) {\n\t\t \n\t\tpr_devel(\"Scheduling page fault handling for later pe: %i\\n\", ctx->pe);\n\t\treturn schedule_cxl_fault(ctx, dsisr, dar);\n\t}\n\tif (dsisr & CXL_PSL_DSISR_An_ST)\n\t\tWARN(1, \"CXL interrupt: Segment Table PTE not found\\n\");\n\tif (dsisr & CXL_PSL_DSISR_An_UR)\n\t\tpr_devel(\"CXL interrupt: AURP PTE not found\\n\");\n\tif (dsisr & CXL_PSL_DSISR_An_PE)\n\t\treturn cxl_ops->handle_psl_slice_error(ctx, dsisr,\n\t\t\t\t\t\tirq_info->errstat);\n\tif (dsisr & CXL_PSL_DSISR_An_AE) {\n\t\tpr_devel(\"CXL interrupt: AFU Error 0x%016llx\\n\", irq_info->afu_err);\n\n\t\tif (ctx->pending_afu_err) {\n\t\t\t \n\t\t\tdev_err_ratelimited(&ctx->afu->dev, \"CXL AFU Error \"\n\t\t\t\t\t    \"undelivered to pe %i: 0x%016llx\\n\",\n\t\t\t\t\t    ctx->pe, irq_info->afu_err);\n\t\t} else {\n\t\t\tspin_lock(&ctx->lock);\n\t\t\tctx->afu_err = irq_info->afu_err;\n\t\t\tctx->pending_afu_err = true;\n\t\t\tspin_unlock(&ctx->lock);\n\n\t\t\twake_up_all(&ctx->wq);\n\t\t}\n\n\t\tcxl_ops->ack_irq(ctx, CXL_PSL_TFC_An_A, 0);\n\t\treturn IRQ_HANDLED;\n\t}\n\tif (dsisr & CXL_PSL_DSISR_An_OC)\n\t\tpr_devel(\"CXL interrupt: OS Context Warning\\n\");\n\n\tWARN(1, \"Unhandled CXL PSL IRQ\\n\");\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t cxl_irq_afu(int irq, void *data)\n{\n\tstruct cxl_context *ctx = data;\n\tirq_hw_number_t hwirq = irqd_to_hwirq(irq_get_irq_data(irq));\n\tint irq_off, afu_irq = 0;\n\t__u16 range;\n\tint r;\n\n\t \n\tfor (r = 0; r < CXL_IRQ_RANGES; r++) {\n\t\tirq_off = hwirq - ctx->irqs.offset[r];\n\t\trange = ctx->irqs.range[r];\n\t\tif (irq_off >= 0 && irq_off < range) {\n\t\t\tafu_irq += irq_off;\n\t\t\tbreak;\n\t\t}\n\t\tafu_irq += range;\n\t}\n\tif (unlikely(r >= CXL_IRQ_RANGES)) {\n\t\tWARN(1, \"Received AFU IRQ out of range for pe %i (virq %i hwirq %lx)\\n\",\n\t\t     ctx->pe, irq, hwirq);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\ttrace_cxl_afu_irq(ctx, afu_irq, irq, hwirq);\n\tpr_devel(\"Received AFU interrupt %i for pe: %i (virq %i hwirq %lx)\\n\",\n\t       afu_irq, ctx->pe, irq, hwirq);\n\n\tif (unlikely(!ctx->irq_bitmap)) {\n\t\tWARN(1, \"Received AFU IRQ for context with no IRQ bitmap\\n\");\n\t\treturn IRQ_HANDLED;\n\t}\n\tspin_lock(&ctx->lock);\n\tset_bit(afu_irq - 1, ctx->irq_bitmap);\n\tctx->pending_irq = true;\n\tspin_unlock(&ctx->lock);\n\n\twake_up_all(&ctx->wq);\n\n\treturn IRQ_HANDLED;\n}\n\nunsigned int cxl_map_irq(struct cxl *adapter, irq_hw_number_t hwirq,\n\t\t\t irq_handler_t handler, void *cookie, const char *name)\n{\n\tunsigned int virq;\n\tint result;\n\n\t \n\tvirq = irq_create_mapping(NULL, hwirq);\n\tif (!virq) {\n\t\tdev_warn(&adapter->dev, \"cxl_map_irq: irq_create_mapping failed\\n\");\n\t\treturn 0;\n\t}\n\n\tif (cxl_ops->setup_irq)\n\t\tcxl_ops->setup_irq(adapter, hwirq, virq);\n\n\tpr_devel(\"hwirq %#lx mapped to virq %u\\n\", hwirq, virq);\n\n\tresult = request_irq(virq, handler, 0, name, cookie);\n\tif (result) {\n\t\tdev_warn(&adapter->dev, \"cxl_map_irq: request_irq failed: %i\\n\", result);\n\t\treturn 0;\n\t}\n\n\treturn virq;\n}\n\nvoid cxl_unmap_irq(unsigned int virq, void *cookie)\n{\n\tfree_irq(virq, cookie);\n}\n\nint cxl_register_one_irq(struct cxl *adapter,\n\t\t\tirq_handler_t handler,\n\t\t\tvoid *cookie,\n\t\t\tirq_hw_number_t *dest_hwirq,\n\t\t\tunsigned int *dest_virq,\n\t\t\tconst char *name)\n{\n\tint hwirq, virq;\n\n\tif ((hwirq = cxl_ops->alloc_one_irq(adapter)) < 0)\n\t\treturn hwirq;\n\n\tif (!(virq = cxl_map_irq(adapter, hwirq, handler, cookie, name)))\n\t\tgoto err;\n\n\t*dest_hwirq = hwirq;\n\t*dest_virq = virq;\n\n\treturn 0;\n\nerr:\n\tcxl_ops->release_one_irq(adapter, hwirq);\n\treturn -ENOMEM;\n}\n\nvoid afu_irq_name_free(struct cxl_context *ctx)\n{\n\tstruct cxl_irq_name *irq_name, *tmp;\n\n\tlist_for_each_entry_safe(irq_name, tmp, &ctx->irq_names, list) {\n\t\tkfree(irq_name->name);\n\t\tlist_del(&irq_name->list);\n\t\tkfree(irq_name);\n\t}\n}\n\nint afu_allocate_irqs(struct cxl_context *ctx, u32 count)\n{\n\tint rc, r, i, j = 1;\n\tstruct cxl_irq_name *irq_name;\n\tint alloc_count;\n\n\t \n\tif (cpu_has_feature(CPU_FTR_HVMODE))\n\t\talloc_count = count;\n\telse\n\t\talloc_count = count + 1;\n\n\tif ((rc = cxl_ops->alloc_irq_ranges(&ctx->irqs, ctx->afu->adapter,\n\t\t\t\t\t\t\talloc_count)))\n\t\treturn rc;\n\n\tif (cpu_has_feature(CPU_FTR_HVMODE)) {\n\t\t \n\t\tctx->irqs.offset[0] = ctx->afu->native->psl_hwirq;\n\t\tctx->irqs.range[0] = 1;\n\t}\n\n\tctx->irq_count = count;\n\tctx->irq_bitmap = bitmap_zalloc(count, GFP_KERNEL);\n\tif (!ctx->irq_bitmap)\n\t\tgoto out;\n\n\t \n\tfor (r = afu_irq_range_start(); r < CXL_IRQ_RANGES; r++) {\n\t\tfor (i = 0; i < ctx->irqs.range[r]; i++) {\n\t\t\tirq_name = kmalloc(sizeof(struct cxl_irq_name),\n\t\t\t\t\t   GFP_KERNEL);\n\t\t\tif (!irq_name)\n\t\t\t\tgoto out;\n\t\t\tirq_name->name = kasprintf(GFP_KERNEL, \"cxl-%s-pe%i-%i\",\n\t\t\t\t\t\t   dev_name(&ctx->afu->dev),\n\t\t\t\t\t\t   ctx->pe, j);\n\t\t\tif (!irq_name->name) {\n\t\t\t\tkfree(irq_name);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\t \n\t\t\tlist_add_tail(&irq_name->list, &ctx->irq_names);\n\t\t\tj++;\n\t\t}\n\t}\n\treturn 0;\n\nout:\n\tcxl_ops->release_irq_ranges(&ctx->irqs, ctx->afu->adapter);\n\tbitmap_free(ctx->irq_bitmap);\n\tafu_irq_name_free(ctx);\n\treturn -ENOMEM;\n}\n\nstatic void afu_register_hwirqs(struct cxl_context *ctx)\n{\n\tirq_hw_number_t hwirq;\n\tstruct cxl_irq_name *irq_name;\n\tint r, i;\n\tirqreturn_t (*handler)(int irq, void *data);\n\n\t \n\tirq_name = list_first_entry(&ctx->irq_names, struct cxl_irq_name, list);\n\tfor (r = afu_irq_range_start(); r < CXL_IRQ_RANGES; r++) {\n\t\thwirq = ctx->irqs.offset[r];\n\t\tfor (i = 0; i < ctx->irqs.range[r]; hwirq++, i++) {\n\t\t\tif (r == 0 && i == 0)\n\t\t\t\t \n\t\t\t\thandler = cxl_ops->psl_interrupt;\n\t\t\telse\n\t\t\t\thandler = cxl_irq_afu;\n\t\t\tcxl_map_irq(ctx->afu->adapter, hwirq, handler, ctx,\n\t\t\t\tirq_name->name);\n\t\t\tirq_name = list_next_entry(irq_name, list);\n\t\t}\n\t}\n}\n\nint afu_register_irqs(struct cxl_context *ctx, u32 count)\n{\n\tint rc;\n\n\trc = afu_allocate_irqs(ctx, count);\n\tif (rc)\n\t\treturn rc;\n\n\tafu_register_hwirqs(ctx);\n\treturn 0;\n}\n\nvoid afu_release_irqs(struct cxl_context *ctx, void *cookie)\n{\n\tirq_hw_number_t hwirq;\n\tunsigned int virq;\n\tint r, i;\n\n\tfor (r = afu_irq_range_start(); r < CXL_IRQ_RANGES; r++) {\n\t\thwirq = ctx->irqs.offset[r];\n\t\tfor (i = 0; i < ctx->irqs.range[r]; hwirq++, i++) {\n\t\t\tvirq = irq_find_mapping(NULL, hwirq);\n\t\t\tif (virq)\n\t\t\t\tcxl_unmap_irq(virq, cookie);\n\t\t}\n\t}\n\n\tafu_irq_name_free(ctx);\n\tcxl_ops->release_irq_ranges(&ctx->irqs, ctx->afu->adapter);\n\n\tctx->irq_count = 0;\n}\n\nvoid cxl_afu_decode_psl_serr(struct cxl_afu *afu, u64 serr)\n{\n\tdev_crit(&afu->dev,\n\t\t \"PSL Slice error received. Check AFU for root cause.\\n\");\n\tdev_crit(&afu->dev, \"PSL_SERR_An: 0x%016llx\\n\", serr);\n\tif (serr & CXL_PSL_SERR_An_afuto)\n\t\tdev_crit(&afu->dev, \"AFU MMIO Timeout\\n\");\n\tif (serr & CXL_PSL_SERR_An_afudis)\n\t\tdev_crit(&afu->dev,\n\t\t\t \"MMIO targeted Accelerator that was not enabled\\n\");\n\tif (serr & CXL_PSL_SERR_An_afuov)\n\t\tdev_crit(&afu->dev, \"AFU CTAG Overflow\\n\");\n\tif (serr & CXL_PSL_SERR_An_badsrc)\n\t\tdev_crit(&afu->dev, \"Bad Interrupt Source\\n\");\n\tif (serr & CXL_PSL_SERR_An_badctx)\n\t\tdev_crit(&afu->dev, \"Bad Context Handle\\n\");\n\tif (serr & CXL_PSL_SERR_An_llcmdis)\n\t\tdev_crit(&afu->dev, \"LLCMD to Disabled AFU\\n\");\n\tif (serr & CXL_PSL_SERR_An_llcmdto)\n\t\tdev_crit(&afu->dev, \"LLCMD Timeout to AFU\\n\");\n\tif (serr & CXL_PSL_SERR_An_afupar)\n\t\tdev_crit(&afu->dev, \"AFU MMIO Parity Error\\n\");\n\tif (serr & CXL_PSL_SERR_An_afudup)\n\t\tdev_crit(&afu->dev, \"AFU MMIO Duplicate CTAG Error\\n\");\n\tif (serr & CXL_PSL_SERR_An_AE)\n\t\tdev_crit(&afu->dev,\n\t\t\t \"AFU asserted JDONE with JERROR in AFU Directed Mode\\n\");\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}