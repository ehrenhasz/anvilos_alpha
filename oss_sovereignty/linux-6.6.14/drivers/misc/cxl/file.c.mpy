{
  "module_name": "file.c",
  "hash_id": "ebac9812ebc1324e11a74f68cea37e513548d3fafbff5f481a9c15dd5d797f63",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/cxl/file.c",
  "human_readable_source": "\n \n\n#include <linux/spinlock.h>\n#include <linux/module.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bitmap.h>\n#include <linux/sched/signal.h>\n#include <linux/poll.h>\n#include <linux/pid.h>\n#include <linux/fs.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/sched/mm.h>\n#include <linux/mmu_context.h>\n#include <asm/cputable.h>\n#include <asm/current.h>\n#include <asm/copro.h>\n\n#include \"cxl.h\"\n#include \"trace.h\"\n\n#define CXL_NUM_MINORS 256  \n\n#define CXL_AFU_MINOR_D(afu) (CXL_CARD_MINOR(afu->adapter) + 1 + (3 * afu->slice))\n#define CXL_AFU_MINOR_M(afu) (CXL_AFU_MINOR_D(afu) + 1)\n#define CXL_AFU_MINOR_S(afu) (CXL_AFU_MINOR_D(afu) + 2)\n#define CXL_AFU_MKDEV_D(afu) MKDEV(MAJOR(cxl_dev), CXL_AFU_MINOR_D(afu))\n#define CXL_AFU_MKDEV_M(afu) MKDEV(MAJOR(cxl_dev), CXL_AFU_MINOR_M(afu))\n#define CXL_AFU_MKDEV_S(afu) MKDEV(MAJOR(cxl_dev), CXL_AFU_MINOR_S(afu))\n\n#define CXL_DEVT_AFU(dev) ((MINOR(dev) % CXL_DEV_MINORS - 1) / 3)\n\n#define CXL_DEVT_IS_CARD(dev) (MINOR(dev) % CXL_DEV_MINORS == 0)\n\nstatic dev_t cxl_dev;\n\nstatic struct class *cxl_class;\n\nstatic int __afu_open(struct inode *inode, struct file *file, bool master)\n{\n\tstruct cxl *adapter;\n\tstruct cxl_afu *afu;\n\tstruct cxl_context *ctx;\n\tint adapter_num = CXL_DEVT_ADAPTER(inode->i_rdev);\n\tint slice = CXL_DEVT_AFU(inode->i_rdev);\n\tint rc = -ENODEV;\n\n\tpr_devel(\"afu_open afu%i.%i\\n\", slice, adapter_num);\n\n\tif (!(adapter = get_cxl_adapter(adapter_num)))\n\t\treturn -ENODEV;\n\n\tif (slice > adapter->slices)\n\t\tgoto err_put_adapter;\n\n\tspin_lock(&adapter->afu_list_lock);\n\tif (!(afu = adapter->afu[slice])) {\n\t\tspin_unlock(&adapter->afu_list_lock);\n\t\tgoto err_put_adapter;\n\t}\n\n\t \n\tcxl_afu_get(afu);\n\tspin_unlock(&adapter->afu_list_lock);\n\n\tif (!afu->current_mode)\n\t\tgoto err_put_afu;\n\n\tif (!cxl_ops->link_ok(adapter, afu)) {\n\t\trc = -EIO;\n\t\tgoto err_put_afu;\n\t}\n\n\tif (!(ctx = cxl_context_alloc())) {\n\t\trc = -ENOMEM;\n\t\tgoto err_put_afu;\n\t}\n\n\trc = cxl_context_init(ctx, afu, master);\n\tif (rc)\n\t\tgoto err_put_afu;\n\n\tcxl_context_set_mapping(ctx, inode->i_mapping);\n\n\tpr_devel(\"afu_open pe: %i\\n\", ctx->pe);\n\tfile->private_data = ctx;\n\n\t \n\trc = 0;\n\nerr_put_afu:\n\t \n\tcxl_afu_put(afu);\nerr_put_adapter:\n\tput_device(&adapter->dev);\n\treturn rc;\n}\n\nint afu_open(struct inode *inode, struct file *file)\n{\n\treturn __afu_open(inode, file, false);\n}\n\nstatic int afu_master_open(struct inode *inode, struct file *file)\n{\n\treturn __afu_open(inode, file, true);\n}\n\nint afu_release(struct inode *inode, struct file *file)\n{\n\tstruct cxl_context *ctx = file->private_data;\n\n\tpr_devel(\"%s: closing cxl file descriptor. pe: %i\\n\",\n\t\t __func__, ctx->pe);\n\tcxl_context_detach(ctx);\n\n\n\t \n\tif (!ctx->kernelapi) {\n\t\tmutex_lock(&ctx->mapping_lock);\n\t\tctx->mapping = NULL;\n\t\tmutex_unlock(&ctx->mapping_lock);\n\t}\n\n\t \n\tcxl_context_free(ctx);\n\n\treturn 0;\n}\n\nstatic long afu_ioctl_start_work(struct cxl_context *ctx,\n\t\t\t\t struct cxl_ioctl_start_work __user *uwork)\n{\n\tstruct cxl_ioctl_start_work work;\n\tu64 amr = 0;\n\tint rc;\n\n\tpr_devel(\"%s: pe: %i\\n\", __func__, ctx->pe);\n\n\t \n\tif (copy_from_user(&work, uwork, sizeof(work)))\n\t\treturn -EFAULT;\n\n\tmutex_lock(&ctx->status_mutex);\n\tif (ctx->status != OPENED) {\n\t\trc = -EIO;\n\t\tgoto out;\n\t}\n\n\t \n\tif (work.reserved1 || work.reserved2 || work.reserved3 ||\n\t    work.reserved4 || work.reserved5 ||\n\t    (work.flags & ~CXL_START_WORK_ALL)) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!(work.flags & CXL_START_WORK_NUM_IRQS))\n\t\twork.num_interrupts = ctx->afu->pp_irqs;\n\telse if ((work.num_interrupts < ctx->afu->pp_irqs) ||\n\t\t (work.num_interrupts > ctx->afu->irqs_max)) {\n\t\trc =  -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif ((rc = afu_register_irqs(ctx, work.num_interrupts)))\n\t\tgoto out;\n\n\tif (work.flags & CXL_START_WORK_AMR)\n\t\tamr = work.amr & mfspr(SPRN_UAMOR);\n\n\tif (work.flags & CXL_START_WORK_TID)\n\t\tctx->assign_tidr = true;\n\n\tctx->mmio_err_ff = !!(work.flags & CXL_START_WORK_ERR_FF);\n\n\t \n\trc = cxl_adapter_context_get(ctx->afu->adapter);\n\tif (rc) {\n\t\tafu_release_irqs(ctx, ctx);\n\t\tgoto out;\n\t}\n\n\t \n\tctx->pid = get_task_pid(current, PIDTYPE_PID);\n\n\t \n\tctx->mm = get_task_mm(current);\n\n\t \n\tcxl_context_mm_count_get(ctx);\n\n\tif (ctx->mm) {\n\t\t \n\t\tmmput(ctx->mm);\n\t\t \n\t\tmm_context_add_copro(ctx->mm);\n\t}\n\n\t \n\tcxl_ctx_get();\n\n\t \n\tsmp_mb();\n\n\ttrace_cxl_attach(ctx, work.work_element_descriptor, work.num_interrupts, amr);\n\n\tif ((rc = cxl_ops->attach_process(ctx, false, work.work_element_descriptor,\n\t\t\t\t\t\t\tamr))) {\n\t\tafu_release_irqs(ctx, ctx);\n\t\tcxl_adapter_context_put(ctx->afu->adapter);\n\t\tput_pid(ctx->pid);\n\t\tctx->pid = NULL;\n\t\tcxl_ctx_put();\n\t\tcxl_context_mm_count_put(ctx);\n\t\tif (ctx->mm)\n\t\t\tmm_context_remove_copro(ctx->mm);\n\t\tgoto out;\n\t}\n\n\trc = 0;\n\tif (work.flags & CXL_START_WORK_TID) {\n\t\twork.tid = ctx->tidr;\n\t\tif (copy_to_user(uwork, &work, sizeof(work)))\n\t\t\trc = -EFAULT;\n\t}\n\n\tctx->status = STARTED;\n\nout:\n\tmutex_unlock(&ctx->status_mutex);\n\treturn rc;\n}\n\nstatic long afu_ioctl_process_element(struct cxl_context *ctx,\n\t\t\t\t      int __user *upe)\n{\n\tpr_devel(\"%s: pe: %i\\n\", __func__, ctx->pe);\n\n\tif (copy_to_user(upe, &ctx->external_pe, sizeof(__u32)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic long afu_ioctl_get_afu_id(struct cxl_context *ctx,\n\t\t\t\t struct cxl_afu_id __user *upafuid)\n{\n\tstruct cxl_afu_id afuid = { 0 };\n\n\tafuid.card_id = ctx->afu->adapter->adapter_num;\n\tafuid.afu_offset = ctx->afu->slice;\n\tafuid.afu_mode = ctx->afu->current_mode;\n\n\t \n\tif (ctx->afu->current_mode == CXL_MODE_DIRECTED && !ctx->master)\n\t\tafuid.flags |= CXL_AFUID_FLAG_SLAVE;\n\n\tif (copy_to_user(upafuid, &afuid, sizeof(afuid)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nlong afu_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct cxl_context *ctx = file->private_data;\n\n\tif (ctx->status == CLOSED)\n\t\treturn -EIO;\n\n\tif (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu))\n\t\treturn -EIO;\n\n\tpr_devel(\"afu_ioctl\\n\");\n\tswitch (cmd) {\n\tcase CXL_IOCTL_START_WORK:\n\t\treturn afu_ioctl_start_work(ctx, (struct cxl_ioctl_start_work __user *)arg);\n\tcase CXL_IOCTL_GET_PROCESS_ELEMENT:\n\t\treturn afu_ioctl_process_element(ctx, (__u32 __user *)arg);\n\tcase CXL_IOCTL_GET_AFU_ID:\n\t\treturn afu_ioctl_get_afu_id(ctx, (struct cxl_afu_id __user *)\n\t\t\t\t\t    arg);\n\t}\n\treturn -EINVAL;\n}\n\nstatic long afu_compat_ioctl(struct file *file, unsigned int cmd,\n\t\t\t     unsigned long arg)\n{\n\treturn afu_ioctl(file, cmd, arg);\n}\n\nint afu_mmap(struct file *file, struct vm_area_struct *vm)\n{\n\tstruct cxl_context *ctx = file->private_data;\n\n\t \n\tif (ctx->status != STARTED)\n\t\treturn -EIO;\n\n\tif (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu))\n\t\treturn -EIO;\n\n\treturn cxl_context_iomap(ctx, vm);\n}\n\nstatic inline bool ctx_event_pending(struct cxl_context *ctx)\n{\n\tif (ctx->pending_irq || ctx->pending_fault || ctx->pending_afu_err)\n\t\treturn true;\n\n\tif (ctx->afu_driver_ops && atomic_read(&ctx->afu_driver_events))\n\t\treturn true;\n\n\treturn false;\n}\n\n__poll_t afu_poll(struct file *file, struct poll_table_struct *poll)\n{\n\tstruct cxl_context *ctx = file->private_data;\n\t__poll_t mask = 0;\n\tunsigned long flags;\n\n\n\tpoll_wait(file, &ctx->wq, poll);\n\n\tpr_devel(\"afu_poll wait done pe: %i\\n\", ctx->pe);\n\n\tspin_lock_irqsave(&ctx->lock, flags);\n\tif (ctx_event_pending(ctx))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;\n\telse if (ctx->status == CLOSED)\n\t\t \n\t\tmask |= EPOLLERR;\n\tspin_unlock_irqrestore(&ctx->lock, flags);\n\n\tpr_devel(\"afu_poll pe: %i returning %#x\\n\", ctx->pe, mask);\n\n\treturn mask;\n}\n\nstatic ssize_t afu_driver_event_copy(struct cxl_context *ctx,\n\t\t\t\t     char __user *buf,\n\t\t\t\t     struct cxl_event *event,\n\t\t\t\t     struct cxl_event_afu_driver_reserved *pl)\n{\n\t \n\tif (!pl) {\n\t\tctx->afu_driver_ops->event_delivered(ctx, pl, -EINVAL);\n\t\treturn -EFAULT;\n\t}\n\n\t \n\tevent->header.size += pl->data_size;\n\tif (event->header.size > CXL_READ_MIN_SIZE) {\n\t\tctx->afu_driver_ops->event_delivered(ctx, pl, -EINVAL);\n\t\treturn -EFAULT;\n\t}\n\n\t \n\tif (copy_to_user(buf, event, sizeof(struct cxl_event_header))) {\n\t\tctx->afu_driver_ops->event_delivered(ctx, pl, -EFAULT);\n\t\treturn -EFAULT;\n\t}\n\n\t \n\tbuf += sizeof(struct cxl_event_header);\n\tif (copy_to_user(buf, &pl->data, pl->data_size)) {\n\t\tctx->afu_driver_ops->event_delivered(ctx, pl, -EFAULT);\n\t\treturn -EFAULT;\n\t}\n\n\tctx->afu_driver_ops->event_delivered(ctx, pl, 0);  \n\treturn event->header.size;\n}\n\nssize_t afu_read(struct file *file, char __user *buf, size_t count,\n\t\t\tloff_t *off)\n{\n\tstruct cxl_context *ctx = file->private_data;\n\tstruct cxl_event_afu_driver_reserved *pl = NULL;\n\tstruct cxl_event event;\n\tunsigned long flags;\n\tint rc;\n\tDEFINE_WAIT(wait);\n\n\tif (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu))\n\t\treturn -EIO;\n\n\tif (count < CXL_READ_MIN_SIZE)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&ctx->lock, flags);\n\n\tfor (;;) {\n\t\tprepare_to_wait(&ctx->wq, &wait, TASK_INTERRUPTIBLE);\n\t\tif (ctx_event_pending(ctx) || (ctx->status == CLOSED))\n\t\t\tbreak;\n\n\t\tif (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu)) {\n\t\t\trc = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (file->f_flags & O_NONBLOCK) {\n\t\t\trc = -EAGAIN;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (signal_pending(current)) {\n\t\t\trc = -ERESTARTSYS;\n\t\t\tgoto out;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&ctx->lock, flags);\n\t\tpr_devel(\"afu_read going to sleep...\\n\");\n\t\tschedule();\n\t\tpr_devel(\"afu_read woken up\\n\");\n\t\tspin_lock_irqsave(&ctx->lock, flags);\n\t}\n\n\tfinish_wait(&ctx->wq, &wait);\n\n\tmemset(&event, 0, sizeof(event));\n\tevent.header.process_element = ctx->pe;\n\tevent.header.size = sizeof(struct cxl_event_header);\n\tif (ctx->afu_driver_ops && atomic_read(&ctx->afu_driver_events)) {\n\t\tpr_devel(\"afu_read delivering AFU driver specific event\\n\");\n\t\tpl = ctx->afu_driver_ops->fetch_event(ctx);\n\t\tatomic_dec(&ctx->afu_driver_events);\n\t\tevent.header.type = CXL_EVENT_AFU_DRIVER;\n\t} else if (ctx->pending_irq) {\n\t\tpr_devel(\"afu_read delivering AFU interrupt\\n\");\n\t\tevent.header.size += sizeof(struct cxl_event_afu_interrupt);\n\t\tevent.header.type = CXL_EVENT_AFU_INTERRUPT;\n\t\tevent.irq.irq = find_first_bit(ctx->irq_bitmap, ctx->irq_count) + 1;\n\t\tclear_bit(event.irq.irq - 1, ctx->irq_bitmap);\n\t\tif (bitmap_empty(ctx->irq_bitmap, ctx->irq_count))\n\t\t\tctx->pending_irq = false;\n\t} else if (ctx->pending_fault) {\n\t\tpr_devel(\"afu_read delivering data storage fault\\n\");\n\t\tevent.header.size += sizeof(struct cxl_event_data_storage);\n\t\tevent.header.type = CXL_EVENT_DATA_STORAGE;\n\t\tevent.fault.addr = ctx->fault_addr;\n\t\tevent.fault.dsisr = ctx->fault_dsisr;\n\t\tctx->pending_fault = false;\n\t} else if (ctx->pending_afu_err) {\n\t\tpr_devel(\"afu_read delivering afu error\\n\");\n\t\tevent.header.size += sizeof(struct cxl_event_afu_error);\n\t\tevent.header.type = CXL_EVENT_AFU_ERROR;\n\t\tevent.afu_error.error = ctx->afu_err;\n\t\tctx->pending_afu_err = false;\n\t} else if (ctx->status == CLOSED) {\n\t\tpr_devel(\"afu_read fatal error\\n\");\n\t\tspin_unlock_irqrestore(&ctx->lock, flags);\n\t\treturn -EIO;\n\t} else\n\t\tWARN(1, \"afu_read must be buggy\\n\");\n\n\tspin_unlock_irqrestore(&ctx->lock, flags);\n\n\tif (event.header.type == CXL_EVENT_AFU_DRIVER)\n\t\treturn afu_driver_event_copy(ctx, buf, &event, pl);\n\n\tif (copy_to_user(buf, &event, event.header.size))\n\t\treturn -EFAULT;\n\treturn event.header.size;\n\nout:\n\tfinish_wait(&ctx->wq, &wait);\n\tspin_unlock_irqrestore(&ctx->lock, flags);\n\treturn rc;\n}\n\n \nconst struct file_operations afu_fops = {\n\t.owner\t\t= THIS_MODULE,\n\t.open           = afu_open,\n\t.poll\t\t= afu_poll,\n\t.read\t\t= afu_read,\n\t.release        = afu_release,\n\t.unlocked_ioctl = afu_ioctl,\n\t.compat_ioctl   = afu_compat_ioctl,\n\t.mmap           = afu_mmap,\n};\n\nstatic const struct file_operations afu_master_fops = {\n\t.owner\t\t= THIS_MODULE,\n\t.open           = afu_master_open,\n\t.poll\t\t= afu_poll,\n\t.read\t\t= afu_read,\n\t.release        = afu_release,\n\t.unlocked_ioctl = afu_ioctl,\n\t.compat_ioctl   = afu_compat_ioctl,\n\t.mmap           = afu_mmap,\n};\n\n\nstatic char *cxl_devnode(const struct device *dev, umode_t *mode)\n{\n\tif (cpu_has_feature(CPU_FTR_HVMODE) &&\n\t    CXL_DEVT_IS_CARD(dev->devt)) {\n\t\t \n\t\treturn NULL;\n\t}\n\treturn kasprintf(GFP_KERNEL, \"cxl/%s\", dev_name(dev));\n}\n\nextern struct class *cxl_class;\n\nstatic int cxl_add_chardev(struct cxl_afu *afu, dev_t devt, struct cdev *cdev,\n\t\t\t   struct device **chardev, char *postfix, char *desc,\n\t\t\t   const struct file_operations *fops)\n{\n\tstruct device *dev;\n\tint rc;\n\n\tcdev_init(cdev, fops);\n\trc = cdev_add(cdev, devt, 1);\n\tif (rc) {\n\t\tdev_err(&afu->dev, \"Unable to add %s chardev: %i\\n\", desc, rc);\n\t\treturn rc;\n\t}\n\n\tdev = device_create(cxl_class, &afu->dev, devt, afu,\n\t\t\t\"afu%i.%i%s\", afu->adapter->adapter_num, afu->slice, postfix);\n\tif (IS_ERR(dev)) {\n\t\trc = PTR_ERR(dev);\n\t\tdev_err(&afu->dev, \"Unable to create %s chardev in sysfs: %i\\n\", desc, rc);\n\t\tgoto err;\n\t}\n\n\t*chardev = dev;\n\n\treturn 0;\nerr:\n\tcdev_del(cdev);\n\treturn rc;\n}\n\nint cxl_chardev_d_afu_add(struct cxl_afu *afu)\n{\n\treturn cxl_add_chardev(afu, CXL_AFU_MKDEV_D(afu), &afu->afu_cdev_d,\n\t\t\t       &afu->chardev_d, \"d\", \"dedicated\",\n\t\t\t       &afu_master_fops);  \n}\n\nint cxl_chardev_m_afu_add(struct cxl_afu *afu)\n{\n\treturn cxl_add_chardev(afu, CXL_AFU_MKDEV_M(afu), &afu->afu_cdev_m,\n\t\t\t       &afu->chardev_m, \"m\", \"master\",\n\t\t\t       &afu_master_fops);\n}\n\nint cxl_chardev_s_afu_add(struct cxl_afu *afu)\n{\n\treturn cxl_add_chardev(afu, CXL_AFU_MKDEV_S(afu), &afu->afu_cdev_s,\n\t\t\t       &afu->chardev_s, \"s\", \"shared\",\n\t\t\t       &afu_fops);\n}\n\nvoid cxl_chardev_afu_remove(struct cxl_afu *afu)\n{\n\tif (afu->chardev_d) {\n\t\tcdev_del(&afu->afu_cdev_d);\n\t\tdevice_unregister(afu->chardev_d);\n\t\tafu->chardev_d = NULL;\n\t}\n\tif (afu->chardev_m) {\n\t\tcdev_del(&afu->afu_cdev_m);\n\t\tdevice_unregister(afu->chardev_m);\n\t\tafu->chardev_m = NULL;\n\t}\n\tif (afu->chardev_s) {\n\t\tcdev_del(&afu->afu_cdev_s);\n\t\tdevice_unregister(afu->chardev_s);\n\t\tafu->chardev_s = NULL;\n\t}\n}\n\nint cxl_register_afu(struct cxl_afu *afu)\n{\n\tafu->dev.class = cxl_class;\n\n\treturn device_register(&afu->dev);\n}\n\nint cxl_register_adapter(struct cxl *adapter)\n{\n\tadapter->dev.class = cxl_class;\n\n\t \n\n\treturn device_register(&adapter->dev);\n}\n\ndev_t cxl_get_dev(void)\n{\n\treturn cxl_dev;\n}\n\nint __init cxl_file_init(void)\n{\n\tint rc;\n\n\t \n\tBUILD_BUG_ON(CXL_API_VERSION != 3);\n\tBUILD_BUG_ON(sizeof(struct cxl_ioctl_start_work) != 64);\n\tBUILD_BUG_ON(sizeof(struct cxl_event_header) != 8);\n\tBUILD_BUG_ON(sizeof(struct cxl_event_afu_interrupt) != 8);\n\tBUILD_BUG_ON(sizeof(struct cxl_event_data_storage) != 32);\n\tBUILD_BUG_ON(sizeof(struct cxl_event_afu_error) != 16);\n\n\tif ((rc = alloc_chrdev_region(&cxl_dev, 0, CXL_NUM_MINORS, \"cxl\"))) {\n\t\tpr_err(\"Unable to allocate CXL major number: %i\\n\", rc);\n\t\treturn rc;\n\t}\n\n\tpr_devel(\"CXL device allocated, MAJOR %i\\n\", MAJOR(cxl_dev));\n\n\tcxl_class = class_create(\"cxl\");\n\tif (IS_ERR(cxl_class)) {\n\t\tpr_err(\"Unable to create CXL class\\n\");\n\t\trc = PTR_ERR(cxl_class);\n\t\tgoto err;\n\t}\n\tcxl_class->devnode = cxl_devnode;\n\n\treturn 0;\n\nerr:\n\tunregister_chrdev_region(cxl_dev, CXL_NUM_MINORS);\n\treturn rc;\n}\n\nvoid cxl_file_exit(void)\n{\n\tunregister_chrdev_region(cxl_dev, CXL_NUM_MINORS);\n\tclass_destroy(cxl_class);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}