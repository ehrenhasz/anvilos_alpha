{
  "module_name": "vmci_guest.c",
  "hash_id": "58eeac3174cb6d67af6dc035dd300ac7098967d7f4704040fda7f05f8bb975dd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/vmw_vmci/vmci_guest.c",
  "human_readable_source": "\n \n\n#include <linux/vmw_vmci_defs.h>\n#include <linux/vmw_vmci_api.h>\n#include <linux/moduleparam.h>\n#include <linux/interrupt.h>\n#include <linux/highmem.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/processor.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/pci.h>\n#include <linux/smp.h>\n#include <linux/io.h>\n#include <linux/vmalloc.h>\n\n#include \"vmci_datagram.h\"\n#include \"vmci_doorbell.h\"\n#include \"vmci_context.h\"\n#include \"vmci_driver.h\"\n#include \"vmci_event.h\"\n\n#define PCI_DEVICE_ID_VMWARE_VMCI\t0x0740\n\n#define VMCI_UTIL_NUM_RESOURCES 1\n\n \n#define VMCI_DMA_DG_BUFFER_SIZE (VMCI_MAX_DG_SIZE + PAGE_SIZE)\n\nstatic bool vmci_disable_msi;\nmodule_param_named(disable_msi, vmci_disable_msi, bool, 0);\nMODULE_PARM_DESC(disable_msi, \"Disable MSI use in driver - (default=0)\");\n\nstatic bool vmci_disable_msix;\nmodule_param_named(disable_msix, vmci_disable_msix, bool, 0);\nMODULE_PARM_DESC(disable_msix, \"Disable MSI-X use in driver - (default=0)\");\n\nstatic u32 ctx_update_sub_id = VMCI_INVALID_ID;\nstatic u32 vm_context_id = VMCI_INVALID_ID;\n\nstruct vmci_guest_device {\n\tstruct device *dev;\t \n\tvoid __iomem *iobase;\n\tvoid __iomem *mmio_base;\n\n\tbool exclusive_vectors;\n\n\tstruct wait_queue_head inout_wq;\n\n\tvoid *data_buffer;\n\tdma_addr_t data_buffer_base;\n\tvoid *tx_buffer;\n\tdma_addr_t tx_buffer_base;\n\tvoid *notification_bitmap;\n\tdma_addr_t notification_base;\n};\n\nstatic bool use_ppn64;\n\nbool vmci_use_ppn64(void)\n{\n\treturn use_ppn64;\n}\n\n \nstruct pci_dev *vmci_pdev;\nstatic struct vmci_guest_device *vmci_dev_g;\nstatic DEFINE_SPINLOCK(vmci_dev_spinlock);\n\nstatic atomic_t vmci_num_guest_devices = ATOMIC_INIT(0);\n\nbool vmci_guest_code_active(void)\n{\n\treturn atomic_read(&vmci_num_guest_devices) != 0;\n}\n\nu32 vmci_get_vm_context_id(void)\n{\n\tif (vm_context_id == VMCI_INVALID_ID) {\n\t\tstruct vmci_datagram get_cid_msg;\n\t\tget_cid_msg.dst =\n\t\t    vmci_make_handle(VMCI_HYPERVISOR_CONTEXT_ID,\n\t\t\t\t     VMCI_GET_CONTEXT_ID);\n\t\tget_cid_msg.src = VMCI_ANON_SRC_HANDLE;\n\t\tget_cid_msg.payload_size = 0;\n\t\tvm_context_id = vmci_send_datagram(&get_cid_msg);\n\t}\n\treturn vm_context_id;\n}\n\nstatic unsigned int vmci_read_reg(struct vmci_guest_device *dev, u32 reg)\n{\n\tif (dev->mmio_base != NULL)\n\t\treturn readl(dev->mmio_base + reg);\n\treturn ioread32(dev->iobase + reg);\n}\n\nstatic void vmci_write_reg(struct vmci_guest_device *dev, u32 val, u32 reg)\n{\n\tif (dev->mmio_base != NULL)\n\t\twritel(val, dev->mmio_base + reg);\n\telse\n\t\tiowrite32(val, dev->iobase + reg);\n}\n\nstatic void vmci_read_data(struct vmci_guest_device *vmci_dev,\n\t\t\t   void *dest, size_t size)\n{\n\tif (vmci_dev->mmio_base == NULL)\n\t\tioread8_rep(vmci_dev->iobase + VMCI_DATA_IN_ADDR,\n\t\t\t    dest, size);\n\telse {\n\t\t \n\t\tstruct vmci_data_in_out_header *buffer_header = vmci_dev->data_buffer;\n\t\tstruct vmci_sg_elem *sg_array = (struct vmci_sg_elem *)(buffer_header + 1);\n\t\tsize_t buffer_offset = dest - vmci_dev->data_buffer;\n\n\t\tbuffer_header->opcode = 1;\n\t\tbuffer_header->size = 1;\n\t\tbuffer_header->busy = 0;\n\t\tsg_array[0].addr = vmci_dev->data_buffer_base + buffer_offset;\n\t\tsg_array[0].size = size;\n\n\t\tvmci_write_reg(vmci_dev, lower_32_bits(vmci_dev->data_buffer_base),\n\t\t\t       VMCI_DATA_IN_LOW_ADDR);\n\n\t\twait_event(vmci_dev->inout_wq, buffer_header->busy == 1);\n\t}\n}\n\nstatic int vmci_write_data(struct vmci_guest_device *dev,\n\t\t\t   struct vmci_datagram *dg)\n{\n\tint result;\n\n\tif (dev->mmio_base != NULL) {\n\t\tstruct vmci_data_in_out_header *buffer_header = dev->tx_buffer;\n\t\tu8 *dg_out_buffer = (u8 *)(buffer_header + 1);\n\n\t\tif (VMCI_DG_SIZE(dg) > VMCI_MAX_DG_SIZE)\n\t\t\treturn VMCI_ERROR_INVALID_ARGS;\n\n\t\t \n\t\tmemcpy(dg_out_buffer, dg, VMCI_DG_SIZE(dg));\n\t\tbuffer_header->opcode = 0;\n\t\tbuffer_header->size = VMCI_DG_SIZE(dg);\n\t\tbuffer_header->busy = 1;\n\n\t\tvmci_write_reg(dev, lower_32_bits(dev->tx_buffer_base),\n\t\t\t       VMCI_DATA_OUT_LOW_ADDR);\n\n\t\t \n\t\tspin_until_cond(buffer_header->busy == 0);\n\n\t\tresult = vmci_read_reg(vmci_dev_g, VMCI_RESULT_LOW_ADDR);\n\t\tif (result == VMCI_SUCCESS)\n\t\t\tresult = (int)buffer_header->result;\n\t} else {\n\t\tiowrite8_rep(dev->iobase + VMCI_DATA_OUT_ADDR,\n\t\t\t     dg, VMCI_DG_SIZE(dg));\n\t\tresult = vmci_read_reg(vmci_dev_g, VMCI_RESULT_LOW_ADDR);\n\t}\n\n\treturn result;\n}\n\n \nint vmci_send_datagram(struct vmci_datagram *dg)\n{\n\tunsigned long flags;\n\tint result;\n\n\t \n\tif (dg == NULL)\n\t\treturn VMCI_ERROR_INVALID_ARGS;\n\n\t \n\tspin_lock_irqsave(&vmci_dev_spinlock, flags);\n\n\tif (vmci_dev_g) {\n\t\tvmci_write_data(vmci_dev_g, dg);\n\t\tresult = vmci_read_reg(vmci_dev_g, VMCI_RESULT_LOW_ADDR);\n\t} else {\n\t\tresult = VMCI_ERROR_UNAVAILABLE;\n\t}\n\n\tspin_unlock_irqrestore(&vmci_dev_spinlock, flags);\n\n\treturn result;\n}\nEXPORT_SYMBOL_GPL(vmci_send_datagram);\n\n \nstatic void vmci_guest_cid_update(u32 sub_id,\n\t\t\t\t  const struct vmci_event_data *event_data,\n\t\t\t\t  void *client_data)\n{\n\tconst struct vmci_event_payld_ctx *ev_payload =\n\t\t\t\tvmci_event_data_const_payload(event_data);\n\n\tif (sub_id != ctx_update_sub_id) {\n\t\tpr_devel(\"Invalid subscriber (ID=0x%x)\\n\", sub_id);\n\t\treturn;\n\t}\n\n\tif (!event_data || ev_payload->context_id == VMCI_INVALID_ID) {\n\t\tpr_devel(\"Invalid event data\\n\");\n\t\treturn;\n\t}\n\n\tpr_devel(\"Updating context from (ID=0x%x) to (ID=0x%x) on event (type=%d)\\n\",\n\t\t vm_context_id, ev_payload->context_id, event_data->event);\n\n\tvm_context_id = ev_payload->context_id;\n}\n\n \nstatic int vmci_check_host_caps(struct pci_dev *pdev)\n{\n\tbool result;\n\tstruct vmci_resource_query_msg *msg;\n\tu32 msg_size = sizeof(struct vmci_resource_query_hdr) +\n\t\t\t\tVMCI_UTIL_NUM_RESOURCES * sizeof(u32);\n\tstruct vmci_datagram *check_msg;\n\n\tcheck_msg = kzalloc(msg_size, GFP_KERNEL);\n\tif (!check_msg) {\n\t\tdev_err(&pdev->dev, \"%s: Insufficient memory\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tcheck_msg->dst = vmci_make_handle(VMCI_HYPERVISOR_CONTEXT_ID,\n\t\t\t\t\t  VMCI_RESOURCES_QUERY);\n\tcheck_msg->src = VMCI_ANON_SRC_HANDLE;\n\tcheck_msg->payload_size = msg_size - VMCI_DG_HEADERSIZE;\n\tmsg = (struct vmci_resource_query_msg *)VMCI_DG_PAYLOAD(check_msg);\n\n\tmsg->num_resources = VMCI_UTIL_NUM_RESOURCES;\n\tmsg->resources[0] = VMCI_GET_CONTEXT_ID;\n\n\t \n\tresult = vmci_send_datagram(check_msg) == 0x01;\n\tkfree(check_msg);\n\n\tdev_dbg(&pdev->dev, \"%s: Host capability check: %s\\n\",\n\t\t__func__, result ? \"PASSED\" : \"FAILED\");\n\n\t \n\treturn result ? 0 : -ENXIO;\n}\n\n \nstatic void vmci_dispatch_dgs(struct vmci_guest_device *vmci_dev)\n{\n\tu8 *dg_in_buffer = vmci_dev->data_buffer;\n\tstruct vmci_datagram *dg;\n\tsize_t dg_in_buffer_size = VMCI_MAX_DG_SIZE;\n\tsize_t current_dg_in_buffer_size;\n\tsize_t remaining_bytes;\n\tbool is_io_port = vmci_dev->mmio_base == NULL;\n\n\tBUILD_BUG_ON(VMCI_MAX_DG_SIZE < PAGE_SIZE);\n\n\tif (!is_io_port) {\n\t\t \n\t\tdg_in_buffer += PAGE_SIZE;\n\n\t\t \n\t\tcurrent_dg_in_buffer_size = VMCI_MAX_DG_SIZE;\n\t} else {\n\t\tcurrent_dg_in_buffer_size = PAGE_SIZE;\n\t}\n\tvmci_read_data(vmci_dev, dg_in_buffer, current_dg_in_buffer_size);\n\tdg = (struct vmci_datagram *)dg_in_buffer;\n\tremaining_bytes = current_dg_in_buffer_size;\n\n\t \n\twhile (dg->dst.resource != VMCI_INVALID_ID ||\n\t       (is_io_port && remaining_bytes > PAGE_SIZE)) {\n\t\tunsigned dg_in_size;\n\n\t\t \n\t\tif (dg->dst.resource == VMCI_INVALID_ID) {\n\t\t\tdg = (struct vmci_datagram *)roundup(\n\t\t\t\t(uintptr_t)dg + 1, PAGE_SIZE);\n\t\t\tremaining_bytes =\n\t\t\t\t(size_t)(dg_in_buffer +\n\t\t\t\t\t current_dg_in_buffer_size -\n\t\t\t\t\t (u8 *)dg);\n\t\t\tcontinue;\n\t\t}\n\n\t\tdg_in_size = VMCI_DG_SIZE_ALIGNED(dg);\n\n\t\tif (dg_in_size <= dg_in_buffer_size) {\n\t\t\tint result;\n\n\t\t\t \n\t\t\tif (dg_in_size > remaining_bytes) {\n\t\t\t\tif (remaining_bytes !=\n\t\t\t\t    current_dg_in_buffer_size) {\n\n\t\t\t\t\t \n\t\t\t\t\tmemmove(dg_in_buffer, dg_in_buffer +\n\t\t\t\t\t\tcurrent_dg_in_buffer_size -\n\t\t\t\t\t\tremaining_bytes,\n\t\t\t\t\t\tremaining_bytes);\n\t\t\t\t\tdg = (struct vmci_datagram *)\n\t\t\t\t\t    dg_in_buffer;\n\t\t\t\t}\n\n\t\t\t\tif (current_dg_in_buffer_size !=\n\t\t\t\t    dg_in_buffer_size)\n\t\t\t\t\tcurrent_dg_in_buffer_size =\n\t\t\t\t\t    dg_in_buffer_size;\n\n\t\t\t\tvmci_read_data(vmci_dev,\n\t\t\t\t\t       dg_in_buffer +\n\t\t\t\t\t\tremaining_bytes,\n\t\t\t\t\t       current_dg_in_buffer_size -\n\t\t\t\t\t\tremaining_bytes);\n\t\t\t}\n\n\t\t\t \n\t\t\tif (dg->src.context == VMCI_HYPERVISOR_CONTEXT_ID &&\n\t\t\t    dg->dst.resource == VMCI_EVENT_HANDLER) {\n\t\t\t\tresult = vmci_event_dispatch(dg);\n\t\t\t} else {\n\t\t\t\tresult = vmci_datagram_invoke_guest_handler(dg);\n\t\t\t}\n\t\t\tif (result < VMCI_SUCCESS)\n\t\t\t\tdev_dbg(vmci_dev->dev,\n\t\t\t\t\t\"Datagram with resource (ID=0x%x) failed (err=%d)\\n\",\n\t\t\t\t\t dg->dst.resource, result);\n\n\t\t\t \n\t\t\tdg = (struct vmci_datagram *)((u8 *)dg +\n\t\t\t\t\t\t      dg_in_size);\n\t\t} else {\n\t\t\tsize_t bytes_to_skip;\n\n\t\t\t \n\t\t\tdev_dbg(vmci_dev->dev,\n\t\t\t\t\"Failed to receive datagram (size=%u bytes)\\n\",\n\t\t\t\t dg_in_size);\n\n\t\t\tbytes_to_skip = dg_in_size - remaining_bytes;\n\t\t\tif (current_dg_in_buffer_size != dg_in_buffer_size)\n\t\t\t\tcurrent_dg_in_buffer_size = dg_in_buffer_size;\n\n\t\t\tfor (;;) {\n\t\t\t\tvmci_read_data(vmci_dev, dg_in_buffer,\n\t\t\t\t\t       current_dg_in_buffer_size);\n\t\t\t\tif (bytes_to_skip <= current_dg_in_buffer_size)\n\t\t\t\t\tbreak;\n\n\t\t\t\tbytes_to_skip -= current_dg_in_buffer_size;\n\t\t\t}\n\t\t\tdg = (struct vmci_datagram *)(dg_in_buffer +\n\t\t\t\t\t\t      bytes_to_skip);\n\t\t}\n\n\t\tremaining_bytes =\n\t\t    (size_t) (dg_in_buffer + current_dg_in_buffer_size -\n\t\t\t      (u8 *)dg);\n\n\t\tif (remaining_bytes < VMCI_DG_HEADERSIZE) {\n\t\t\t \n\n\t\t\tvmci_read_data(vmci_dev, dg_in_buffer,\n\t\t\t\t    current_dg_in_buffer_size);\n\t\t\tdg = (struct vmci_datagram *)dg_in_buffer;\n\t\t\tremaining_bytes = current_dg_in_buffer_size;\n\t\t}\n\t}\n}\n\n \nstatic void vmci_process_bitmap(struct vmci_guest_device *dev)\n{\n\tif (!dev->notification_bitmap) {\n\t\tdev_dbg(dev->dev, \"No bitmap present in %s\\n\", __func__);\n\t\treturn;\n\t}\n\n\tvmci_dbell_scan_notification_entries(dev->notification_bitmap);\n}\n\n \nstatic irqreturn_t vmci_interrupt(int irq, void *_dev)\n{\n\tstruct vmci_guest_device *dev = _dev;\n\n\t \n\n\tif (dev->exclusive_vectors) {\n\t\tvmci_dispatch_dgs(dev);\n\t} else {\n\t\tunsigned int icr;\n\n\t\t \n\t\ticr = vmci_read_reg(dev, VMCI_ICR_ADDR);\n\t\tif (icr == 0 || icr == ~0)\n\t\t\treturn IRQ_NONE;\n\n\t\tif (icr & VMCI_ICR_DATAGRAM) {\n\t\t\tvmci_dispatch_dgs(dev);\n\t\t\ticr &= ~VMCI_ICR_DATAGRAM;\n\t\t}\n\n\t\tif (icr & VMCI_ICR_NOTIFICATION) {\n\t\t\tvmci_process_bitmap(dev);\n\t\t\ticr &= ~VMCI_ICR_NOTIFICATION;\n\t\t}\n\n\n\t\tif (icr & VMCI_ICR_DMA_DATAGRAM) {\n\t\t\twake_up_all(&dev->inout_wq);\n\t\t\ticr &= ~VMCI_ICR_DMA_DATAGRAM;\n\t\t}\n\n\t\tif (icr != 0)\n\t\t\tdev_warn(dev->dev,\n\t\t\t\t \"Ignoring unknown interrupt cause (%d)\\n\",\n\t\t\t\t icr);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t vmci_interrupt_bm(int irq, void *_dev)\n{\n\tstruct vmci_guest_device *dev = _dev;\n\n\t \n\tvmci_process_bitmap(dev);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t vmci_interrupt_dma_datagram(int irq, void *_dev)\n{\n\tstruct vmci_guest_device *dev = _dev;\n\n\twake_up_all(&dev->inout_wq);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void vmci_free_dg_buffers(struct vmci_guest_device *vmci_dev)\n{\n\tif (vmci_dev->mmio_base != NULL) {\n\t\tif (vmci_dev->tx_buffer != NULL)\n\t\t\tdma_free_coherent(vmci_dev->dev,\n\t\t\t\t\t  VMCI_DMA_DG_BUFFER_SIZE,\n\t\t\t\t\t  vmci_dev->tx_buffer,\n\t\t\t\t\t  vmci_dev->tx_buffer_base);\n\t\tif (vmci_dev->data_buffer != NULL)\n\t\t\tdma_free_coherent(vmci_dev->dev,\n\t\t\t\t\t  VMCI_DMA_DG_BUFFER_SIZE,\n\t\t\t\t\t  vmci_dev->data_buffer,\n\t\t\t\t\t  vmci_dev->data_buffer_base);\n\t} else {\n\t\tvfree(vmci_dev->data_buffer);\n\t}\n}\n\n \nstatic int vmci_guest_probe_device(struct pci_dev *pdev,\n\t\t\t\t   const struct pci_device_id *id)\n{\n\tstruct vmci_guest_device *vmci_dev;\n\tvoid __iomem *iobase = NULL;\n\tvoid __iomem *mmio_base = NULL;\n\tunsigned int num_irq_vectors;\n\tunsigned int capabilities;\n\tunsigned int caps_in_use;\n\tunsigned long cmd;\n\tint vmci_err;\n\tint error;\n\n\tdev_dbg(&pdev->dev, \"Probing for vmci/PCI guest device\\n\");\n\n\terror = pcim_enable_device(pdev);\n\tif (error) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Failed to enable VMCI device: %d\\n\", error);\n\t\treturn error;\n\t}\n\n\t \n\n\tif (pci_resource_len(pdev, 1) == VMCI_WITH_MMIO_ACCESS_BAR_SIZE) {\n\t\tdev_info(&pdev->dev, \"MMIO register access is available\\n\");\n\t\tmmio_base = pci_iomap_range(pdev, 1, VMCI_MMIO_ACCESS_OFFSET,\n\t\t\t\t\t    VMCI_MMIO_ACCESS_SIZE);\n\t\t \n\t\tif (!mmio_base)\n\t\t\tdev_warn(&pdev->dev, \"Failed to map MMIO register access\\n\");\n\t}\n\n\tif (!mmio_base) {\n\t\tif (IS_ENABLED(CONFIG_ARM64)) {\n\t\t\tdev_err(&pdev->dev, \"MMIO base is invalid\\n\");\n\t\t\treturn -ENXIO;\n\t\t}\n\t\terror = pcim_iomap_regions(pdev, BIT(0), KBUILD_MODNAME);\n\t\tif (error) {\n\t\t\tdev_err(&pdev->dev, \"Failed to reserve/map IO regions\\n\");\n\t\t\treturn error;\n\t\t}\n\t\tiobase = pcim_iomap_table(pdev)[0];\n\t}\n\n\tvmci_dev = devm_kzalloc(&pdev->dev, sizeof(*vmci_dev), GFP_KERNEL);\n\tif (!vmci_dev) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Can't allocate memory for VMCI device\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tvmci_dev->dev = &pdev->dev;\n\tvmci_dev->exclusive_vectors = false;\n\tvmci_dev->iobase = iobase;\n\tvmci_dev->mmio_base = mmio_base;\n\n\tinit_waitqueue_head(&vmci_dev->inout_wq);\n\n\tif (mmio_base != NULL) {\n\t\tvmci_dev->tx_buffer = dma_alloc_coherent(&pdev->dev, VMCI_DMA_DG_BUFFER_SIZE,\n\t\t\t\t\t\t\t &vmci_dev->tx_buffer_base,\n\t\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (!vmci_dev->tx_buffer) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Can't allocate memory for datagram tx buffer\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tvmci_dev->data_buffer = dma_alloc_coherent(&pdev->dev, VMCI_DMA_DG_BUFFER_SIZE,\n\t\t\t\t\t\t\t   &vmci_dev->data_buffer_base,\n\t\t\t\t\t\t\t   GFP_KERNEL);\n\t} else {\n\t\tvmci_dev->data_buffer = vmalloc(VMCI_MAX_DG_SIZE);\n\t}\n\tif (!vmci_dev->data_buffer) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Can't allocate memory for datagram buffer\\n\");\n\t\terror = -ENOMEM;\n\t\tgoto err_free_data_buffers;\n\t}\n\n\tpci_set_master(pdev);\t \n\n\t \n\tcapabilities = vmci_read_reg(vmci_dev, VMCI_CAPS_ADDR);\n\tif (!(capabilities & VMCI_CAPS_DATAGRAM)) {\n\t\tdev_err(&pdev->dev, \"Device does not support datagrams\\n\");\n\t\terror = -ENXIO;\n\t\tgoto err_free_data_buffers;\n\t}\n\tcaps_in_use = VMCI_CAPS_DATAGRAM;\n\n\t \n\tif (capabilities & VMCI_CAPS_PPN64) {\n\t\tdma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\t\tuse_ppn64 = true;\n\t\tcaps_in_use |= VMCI_CAPS_PPN64;\n\t} else {\n\t\tdma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(44));\n\t\tuse_ppn64 = false;\n\t}\n\n\t \n\tif (capabilities & VMCI_CAPS_NOTIFICATIONS) {\n\t\tvmci_dev->notification_bitmap = dma_alloc_coherent(\n\t\t\t&pdev->dev, PAGE_SIZE, &vmci_dev->notification_base,\n\t\t\tGFP_KERNEL);\n\t\tif (!vmci_dev->notification_bitmap)\n\t\t\tdev_warn(&pdev->dev,\n\t\t\t\t \"Unable to allocate notification bitmap\\n\");\n\t\telse\n\t\t\tcaps_in_use |= VMCI_CAPS_NOTIFICATIONS;\n\t}\n\n\tif (mmio_base != NULL) {\n\t\tif (capabilities & VMCI_CAPS_DMA_DATAGRAM) {\n\t\t\tcaps_in_use |= VMCI_CAPS_DMA_DATAGRAM;\n\t\t} else {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Missing capability: VMCI_CAPS_DMA_DATAGRAM\\n\");\n\t\t\terror = -ENXIO;\n\t\t\tgoto err_free_notification_bitmap;\n\t\t}\n\t}\n\n\tdev_info(&pdev->dev, \"Using capabilities 0x%x\\n\", caps_in_use);\n\n\t \n\tvmci_write_reg(vmci_dev, caps_in_use, VMCI_CAPS_ADDR);\n\n\tif (caps_in_use & VMCI_CAPS_DMA_DATAGRAM) {\n\t\t \n\t\tvmci_write_reg(vmci_dev, PAGE_SHIFT, VMCI_GUEST_PAGE_SHIFT);\n\n\t\t \n\t\tvmci_write_reg(vmci_dev, upper_32_bits(vmci_dev->data_buffer_base),\n\t\t\t       VMCI_DATA_IN_HIGH_ADDR);\n\t\tvmci_write_reg(vmci_dev, upper_32_bits(vmci_dev->tx_buffer_base),\n\t\t\t       VMCI_DATA_OUT_HIGH_ADDR);\n\t}\n\n\t \n\tspin_lock_irq(&vmci_dev_spinlock);\n\tvmci_dev_g = vmci_dev;\n\tvmci_pdev = pdev;\n\tspin_unlock_irq(&vmci_dev_spinlock);\n\n\t \n\tif (caps_in_use & VMCI_CAPS_NOTIFICATIONS) {\n\t\tunsigned long bitmap_ppn =\n\t\t\tvmci_dev->notification_base >> PAGE_SHIFT;\n\t\tif (!vmci_dbell_register_notification_bitmap(bitmap_ppn)) {\n\t\t\tdev_warn(&pdev->dev,\n\t\t\t\t \"VMCI device unable to register notification bitmap with PPN 0x%lx\\n\",\n\t\t\t\t bitmap_ppn);\n\t\t\terror = -ENXIO;\n\t\t\tgoto err_remove_vmci_dev_g;\n\t\t}\n\t}\n\n\t \n\terror = vmci_check_host_caps(pdev);\n\tif (error)\n\t\tgoto err_remove_vmci_dev_g;\n\n\t \n\n\t \n\tvmci_err = vmci_event_subscribe(VMCI_EVENT_CTX_ID_UPDATE,\n\t\t\t\t\tvmci_guest_cid_update, NULL,\n\t\t\t\t\t&ctx_update_sub_id);\n\tif (vmci_err < VMCI_SUCCESS)\n\t\tdev_warn(&pdev->dev,\n\t\t\t \"Failed to subscribe to event (type=%d): %d\\n\",\n\t\t\t VMCI_EVENT_CTX_ID_UPDATE, vmci_err);\n\n\t \n\tif (vmci_dev->mmio_base != NULL)\n\t\tnum_irq_vectors = VMCI_MAX_INTRS;\n\telse\n\t\tnum_irq_vectors = VMCI_MAX_INTRS_NOTIFICATION;\n\terror = pci_alloc_irq_vectors(pdev, num_irq_vectors, num_irq_vectors,\n\t\t\t\t      PCI_IRQ_MSIX);\n\tif (error < 0) {\n\t\terror = pci_alloc_irq_vectors(pdev, 1, 1,\n\t\t\t\tPCI_IRQ_MSIX | PCI_IRQ_MSI | PCI_IRQ_LEGACY);\n\t\tif (error < 0)\n\t\t\tgoto err_unsubscribe_event;\n\t} else {\n\t\tvmci_dev->exclusive_vectors = true;\n\t}\n\n\t \n\terror = request_threaded_irq(pci_irq_vector(pdev, 0), NULL,\n\t\t\t\t     vmci_interrupt, IRQF_SHARED,\n\t\t\t\t     KBUILD_MODNAME, vmci_dev);\n\tif (error) {\n\t\tdev_err(&pdev->dev, \"Irq %u in use: %d\\n\",\n\t\t\tpci_irq_vector(pdev, 0), error);\n\t\tgoto err_disable_msi;\n\t}\n\n\t \n\tif (vmci_dev->exclusive_vectors) {\n\t\terror = request_threaded_irq(pci_irq_vector(pdev, 1), NULL,\n\t\t\t\t\t     vmci_interrupt_bm, 0,\n\t\t\t\t\t     KBUILD_MODNAME, vmci_dev);\n\t\tif (error) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Failed to allocate irq %u: %d\\n\",\n\t\t\t\tpci_irq_vector(pdev, 1), error);\n\t\t\tgoto err_free_irq;\n\t\t}\n\t\tif (caps_in_use & VMCI_CAPS_DMA_DATAGRAM) {\n\t\t\terror = request_threaded_irq(pci_irq_vector(pdev, 2),\n\t\t\t\t\t\t     NULL,\n\t\t\t\t\t\t    vmci_interrupt_dma_datagram,\n\t\t\t\t\t\t     0, KBUILD_MODNAME,\n\t\t\t\t\t\t     vmci_dev);\n\t\t\tif (error) {\n\t\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\t\"Failed to allocate irq %u: %d\\n\",\n\t\t\t\t\tpci_irq_vector(pdev, 2), error);\n\t\t\t\tgoto err_free_bm_irq;\n\t\t\t}\n\t\t}\n\t}\n\n\tdev_dbg(&pdev->dev, \"Registered device\\n\");\n\n\tatomic_inc(&vmci_num_guest_devices);\n\n\t \n\tcmd = VMCI_IMR_DATAGRAM;\n\tif (caps_in_use & VMCI_CAPS_NOTIFICATIONS)\n\t\tcmd |= VMCI_IMR_NOTIFICATION;\n\tif (caps_in_use & VMCI_CAPS_DMA_DATAGRAM)\n\t\tcmd |= VMCI_IMR_DMA_DATAGRAM;\n\tvmci_write_reg(vmci_dev, cmd, VMCI_IMR_ADDR);\n\n\t \n\tvmci_write_reg(vmci_dev, VMCI_CONTROL_INT_ENABLE, VMCI_CONTROL_ADDR);\n\n\tpci_set_drvdata(pdev, vmci_dev);\n\n\tvmci_call_vsock_callback(false);\n\treturn 0;\n\nerr_free_bm_irq:\n\tif (vmci_dev->exclusive_vectors)\n\t\tfree_irq(pci_irq_vector(pdev, 1), vmci_dev);\n\nerr_free_irq:\n\tfree_irq(pci_irq_vector(pdev, 0), vmci_dev);\n\nerr_disable_msi:\n\tpci_free_irq_vectors(pdev);\n\nerr_unsubscribe_event:\n\tvmci_err = vmci_event_unsubscribe(ctx_update_sub_id);\n\tif (vmci_err < VMCI_SUCCESS)\n\t\tdev_warn(&pdev->dev,\n\t\t\t \"Failed to unsubscribe from event (type=%d) with subscriber (ID=0x%x): %d\\n\",\n\t\t\t VMCI_EVENT_CTX_ID_UPDATE, ctx_update_sub_id, vmci_err);\n\nerr_remove_vmci_dev_g:\n\tspin_lock_irq(&vmci_dev_spinlock);\n\tvmci_pdev = NULL;\n\tvmci_dev_g = NULL;\n\tspin_unlock_irq(&vmci_dev_spinlock);\n\nerr_free_notification_bitmap:\n\tif (vmci_dev->notification_bitmap) {\n\t\tvmci_write_reg(vmci_dev, VMCI_CONTROL_RESET, VMCI_CONTROL_ADDR);\n\t\tdma_free_coherent(&pdev->dev, PAGE_SIZE,\n\t\t\t\t  vmci_dev->notification_bitmap,\n\t\t\t\t  vmci_dev->notification_base);\n\t}\n\nerr_free_data_buffers:\n\tvmci_free_dg_buffers(vmci_dev);\n\n\t \n\treturn error;\n}\n\nstatic void vmci_guest_remove_device(struct pci_dev *pdev)\n{\n\tstruct vmci_guest_device *vmci_dev = pci_get_drvdata(pdev);\n\tint vmci_err;\n\n\tdev_dbg(&pdev->dev, \"Removing device\\n\");\n\n\tatomic_dec(&vmci_num_guest_devices);\n\n\tvmci_qp_guest_endpoints_exit();\n\n\tvmci_err = vmci_event_unsubscribe(ctx_update_sub_id);\n\tif (vmci_err < VMCI_SUCCESS)\n\t\tdev_warn(&pdev->dev,\n\t\t\t \"Failed to unsubscribe from event (type=%d) with subscriber (ID=0x%x): %d\\n\",\n\t\t\t VMCI_EVENT_CTX_ID_UPDATE, ctx_update_sub_id, vmci_err);\n\n\tspin_lock_irq(&vmci_dev_spinlock);\n\tvmci_dev_g = NULL;\n\tvmci_pdev = NULL;\n\tspin_unlock_irq(&vmci_dev_spinlock);\n\n\tdev_dbg(&pdev->dev, \"Resetting vmci device\\n\");\n\tvmci_write_reg(vmci_dev, VMCI_CONTROL_RESET, VMCI_CONTROL_ADDR);\n\n\t \n\tif (vmci_dev->exclusive_vectors) {\n\t\tfree_irq(pci_irq_vector(pdev, 1), vmci_dev);\n\t\tif (vmci_dev->mmio_base != NULL)\n\t\t\tfree_irq(pci_irq_vector(pdev, 2), vmci_dev);\n\t}\n\tfree_irq(pci_irq_vector(pdev, 0), vmci_dev);\n\tpci_free_irq_vectors(pdev);\n\n\tif (vmci_dev->notification_bitmap) {\n\t\t \n\n\t\tdma_free_coherent(&pdev->dev, PAGE_SIZE,\n\t\t\t\t  vmci_dev->notification_bitmap,\n\t\t\t\t  vmci_dev->notification_base);\n\t}\n\n\tvmci_free_dg_buffers(vmci_dev);\n\n\tif (vmci_dev->mmio_base != NULL)\n\t\tpci_iounmap(pdev, vmci_dev->mmio_base);\n\n\t \n}\n\nstatic const struct pci_device_id vmci_ids[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_VMWARE, PCI_DEVICE_ID_VMWARE_VMCI), },\n\t{ 0 },\n};\nMODULE_DEVICE_TABLE(pci, vmci_ids);\n\nstatic struct pci_driver vmci_guest_driver = {\n\t.name\t\t= KBUILD_MODNAME,\n\t.id_table\t= vmci_ids,\n\t.probe\t\t= vmci_guest_probe_device,\n\t.remove\t\t= vmci_guest_remove_device,\n};\n\nint __init vmci_guest_init(void)\n{\n\treturn pci_register_driver(&vmci_guest_driver);\n}\n\nvoid __exit vmci_guest_exit(void)\n{\n\tpci_unregister_driver(&vmci_guest_driver);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}