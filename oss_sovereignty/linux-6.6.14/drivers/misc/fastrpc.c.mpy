{
  "module_name": "fastrpc.c",
  "hash_id": "f9bf0c40d5a1e3d73bcc25f6ec7c686957bf4fda08163869125440f18e55765b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/misc/fastrpc.c",
  "human_readable_source": "\n\n\n\n#include <linux/completion.h>\n#include <linux/device.h>\n#include <linux/dma-buf.h>\n#include <linux/dma-mapping.h>\n#include <linux/dma-resv.h>\n#include <linux/idr.h>\n#include <linux/list.h>\n#include <linux/miscdevice.h>\n#include <linux/module.h>\n#include <linux/of_address.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/sort.h>\n#include <linux/of_platform.h>\n#include <linux/rpmsg.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/firmware/qcom/qcom_scm.h>\n#include <uapi/misc/fastrpc.h>\n#include <linux/of_reserved_mem.h>\n\n#define ADSP_DOMAIN_ID (0)\n#define MDSP_DOMAIN_ID (1)\n#define SDSP_DOMAIN_ID (2)\n#define CDSP_DOMAIN_ID (3)\n#define FASTRPC_DEV_MAX\t\t4  \n#define FASTRPC_MAX_SESSIONS\t14\n#define FASTRPC_MAX_VMIDS\t16\n#define FASTRPC_ALIGN\t\t128\n#define FASTRPC_MAX_FDLIST\t16\n#define FASTRPC_MAX_CRCLIST\t64\n#define FASTRPC_PHYS(p)\t((p) & 0xffffffff)\n#define FASTRPC_CTX_MAX (256)\n#define FASTRPC_INIT_HANDLE\t1\n#define FASTRPC_DSP_UTILITIES_HANDLE\t2\n#define FASTRPC_CTXID_MASK (0xFF0)\n#define INIT_FILELEN_MAX (2 * 1024 * 1024)\n#define INIT_FILE_NAMELEN_MAX (128)\n#define FASTRPC_DEVICE_NAME\t\"fastrpc\"\n\n \n#define ADSP_MMAP_HEAP_ADDR  4\n \n#define ADSP_MMAP_DMA_BUFFER  6\n \n#define ADSP_MMAP_REMOTE_HEAP_ADDR  8\n \n#define ADSP_MMAP_ADD_PAGES 0x1000\n \n#define ADSP_MMAP_ADD_PAGES_LLC 0x3000,\n\n#define DSP_UNSUPPORTED_API (0x80000414)\n \n#define FASTRPC_MAX_DSP_ATTRIBUTES (256)\n#define FASTRPC_MAX_DSP_ATTRIBUTES_LEN (sizeof(u32) * FASTRPC_MAX_DSP_ATTRIBUTES)\n\n \n#define REMOTE_SCALARS_INBUFS(sc)\t(((sc) >> 16) & 0x0ff)\n\n \n#define REMOTE_SCALARS_OUTBUFS(sc)\t(((sc) >> 8) & 0x0ff)\n\n \n#define REMOTE_SCALARS_INHANDLES(sc)\t(((sc) >> 4) & 0x0f)\n\n \n#define REMOTE_SCALARS_OUTHANDLES(sc)\t((sc) & 0x0f)\n\n#define REMOTE_SCALARS_LENGTH(sc)\t(REMOTE_SCALARS_INBUFS(sc) +   \\\n\t\t\t\t\t REMOTE_SCALARS_OUTBUFS(sc) +  \\\n\t\t\t\t\t REMOTE_SCALARS_INHANDLES(sc)+ \\\n\t\t\t\t\t REMOTE_SCALARS_OUTHANDLES(sc))\n#define FASTRPC_BUILD_SCALARS(attr, method, in, out, oin, oout)  \\\n\t\t\t\t(((attr & 0x07) << 29) |\t\t\\\n\t\t\t\t((method & 0x1f) << 24) |\t\\\n\t\t\t\t((in & 0xff) << 16) |\t\t\\\n\t\t\t\t((out & 0xff) <<  8) |\t\t\\\n\t\t\t\t((oin & 0x0f) <<  4) |\t\t\\\n\t\t\t\t(oout & 0x0f))\n\n#define FASTRPC_SCALARS(method, in, out) \\\n\t\tFASTRPC_BUILD_SCALARS(0, method, in, out, 0, 0)\n\n#define FASTRPC_CREATE_PROCESS_NARGS\t6\n#define FASTRPC_CREATE_STATIC_PROCESS_NARGS\t3\n \n#define FASTRPC_RMID_INIT_ATTACH\t0\n#define FASTRPC_RMID_INIT_RELEASE\t1\n#define FASTRPC_RMID_INIT_MMAP\t\t4\n#define FASTRPC_RMID_INIT_MUNMAP\t5\n#define FASTRPC_RMID_INIT_CREATE\t6\n#define FASTRPC_RMID_INIT_CREATE_ATTR\t7\n#define FASTRPC_RMID_INIT_CREATE_STATIC\t8\n#define FASTRPC_RMID_INIT_MEM_MAP      10\n#define FASTRPC_RMID_INIT_MEM_UNMAP    11\n\n \n#define ROOT_PD\t\t(0)\n#define USER_PD\t\t(1)\n#define SENSORS_PD\t(2)\n\n#define miscdev_to_fdevice(d) container_of(d, struct fastrpc_device, miscdev)\n\nstatic const char *domains[FASTRPC_DEV_MAX] = { \"adsp\", \"mdsp\",\n\t\t\t\t\t\t\"sdsp\", \"cdsp\"};\nstruct fastrpc_phy_page {\n\tu64 addr;\t\t \n\tu64 size;\t\t \n};\n\nstruct fastrpc_invoke_buf {\n\tu32 num;\t\t \n\tu32 pgidx;\t\t \n};\n\nstruct fastrpc_remote_dmahandle {\n\ts32 fd;\t\t \n\tu32 offset;\t \n\tu32 len;\t \n};\n\nstruct fastrpc_remote_buf {\n\tu64 pv;\t\t \n\tu64 len;\t \n};\n\nunion fastrpc_remote_arg {\n\tstruct fastrpc_remote_buf buf;\n\tstruct fastrpc_remote_dmahandle dma;\n};\n\nstruct fastrpc_mmap_rsp_msg {\n\tu64 vaddr;\n};\n\nstruct fastrpc_mmap_req_msg {\n\ts32 pgid;\n\tu32 flags;\n\tu64 vaddr;\n\ts32 num;\n};\n\nstruct fastrpc_mem_map_req_msg {\n\ts32 pgid;\n\ts32 fd;\n\ts32 offset;\n\tu32 flags;\n\tu64 vaddrin;\n\ts32 num;\n\ts32 data_len;\n};\n\nstruct fastrpc_munmap_req_msg {\n\ts32 pgid;\n\tu64 vaddr;\n\tu64 size;\n};\n\nstruct fastrpc_mem_unmap_req_msg {\n\ts32 pgid;\n\ts32 fd;\n\tu64 vaddrin;\n\tu64 len;\n};\n\nstruct fastrpc_msg {\n\tint pid;\t\t \n\tint tid;\t\t \n\tu64 ctx;\t\t \n\tu32 handle;\t \n\tu32 sc;\t\t \n\tu64 addr;\t\t \n\tu64 size;\t\t \n};\n\nstruct fastrpc_invoke_rsp {\n\tu64 ctx;\t\t \n\tint retval;\t\t \n};\n\nstruct fastrpc_buf_overlap {\n\tu64 start;\n\tu64 end;\n\tint raix;\n\tu64 mstart;\n\tu64 mend;\n\tu64 offset;\n};\n\nstruct fastrpc_buf {\n\tstruct fastrpc_user *fl;\n\tstruct dma_buf *dmabuf;\n\tstruct device *dev;\n\tvoid *virt;\n\tu64 phys;\n\tu64 size;\n\t \n\tstruct mutex lock;\n\tstruct list_head attachments;\n\t \n\tstruct list_head node;  \n\tuintptr_t raddr;\n};\n\nstruct fastrpc_dma_buf_attachment {\n\tstruct device *dev;\n\tstruct sg_table sgt;\n\tstruct list_head node;\n};\n\nstruct fastrpc_map {\n\tstruct list_head node;\n\tstruct fastrpc_user *fl;\n\tint fd;\n\tstruct dma_buf *buf;\n\tstruct sg_table *table;\n\tstruct dma_buf_attachment *attach;\n\tu64 phys;\n\tu64 size;\n\tvoid *va;\n\tu64 len;\n\tu64 raddr;\n\tu32 attr;\n\tstruct kref refcount;\n};\n\nstruct fastrpc_invoke_ctx {\n\tint nscalars;\n\tint nbufs;\n\tint retval;\n\tint pid;\n\tint tgid;\n\tu32 sc;\n\tu32 *crc;\n\tu64 ctxid;\n\tu64 msg_sz;\n\tstruct kref refcount;\n\tstruct list_head node;  \n\tstruct completion work;\n\tstruct work_struct put_work;\n\tstruct fastrpc_msg msg;\n\tstruct fastrpc_user *fl;\n\tunion fastrpc_remote_arg *rpra;\n\tstruct fastrpc_map **maps;\n\tstruct fastrpc_buf *buf;\n\tstruct fastrpc_invoke_args *args;\n\tstruct fastrpc_buf_overlap *olaps;\n\tstruct fastrpc_channel_ctx *cctx;\n};\n\nstruct fastrpc_session_ctx {\n\tstruct device *dev;\n\tint sid;\n\tbool used;\n\tbool valid;\n};\n\nstruct fastrpc_channel_ctx {\n\tint domain_id;\n\tint sesscount;\n\tint vmcount;\n\tu64 perms;\n\tstruct qcom_scm_vmperm vmperms[FASTRPC_MAX_VMIDS];\n\tstruct rpmsg_device *rpdev;\n\tstruct fastrpc_session_ctx session[FASTRPC_MAX_SESSIONS];\n\tspinlock_t lock;\n\tstruct idr ctx_idr;\n\tstruct list_head users;\n\tstruct kref refcount;\n\t \n\tbool valid_attributes;\n\tu32 dsp_attributes[FASTRPC_MAX_DSP_ATTRIBUTES];\n\tstruct fastrpc_device *secure_fdevice;\n\tstruct fastrpc_device *fdevice;\n\tstruct fastrpc_buf *remote_heap;\n\tstruct list_head invoke_interrupted_mmaps;\n\tbool secure;\n\tbool unsigned_support;\n\tu64 dma_mask;\n};\n\nstruct fastrpc_device {\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct miscdevice miscdev;\n\tbool secure;\n};\n\nstruct fastrpc_user {\n\tstruct list_head user;\n\tstruct list_head maps;\n\tstruct list_head pending;\n\tstruct list_head mmaps;\n\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_session_ctx *sctx;\n\tstruct fastrpc_buf *init_mem;\n\n\tint tgid;\n\tint pd;\n\tbool is_secure_dev;\n\t \n\tspinlock_t lock;\n\t \n\tstruct mutex mutex;\n};\n\nstatic void fastrpc_free_map(struct kref *ref)\n{\n\tstruct fastrpc_map *map;\n\n\tmap = container_of(ref, struct fastrpc_map, refcount);\n\n\tif (map->table) {\n\t\tif (map->attr & FASTRPC_ATTR_SECUREMAP) {\n\t\t\tstruct qcom_scm_vmperm perm;\n\t\t\tint vmid = map->fl->cctx->vmperms[0].vmid;\n\t\t\tu64 src_perms = BIT(QCOM_SCM_VMID_HLOS) | BIT(vmid);\n\t\t\tint err = 0;\n\n\t\t\tperm.vmid = QCOM_SCM_VMID_HLOS;\n\t\t\tperm.perm = QCOM_SCM_PERM_RWX;\n\t\t\terr = qcom_scm_assign_mem(map->phys, map->size,\n\t\t\t\t&src_perms, &perm, 1);\n\t\t\tif (err) {\n\t\t\t\tdev_err(map->fl->sctx->dev, \"Failed to assign memory phys 0x%llx size 0x%llx err %d\",\n\t\t\t\t\t\tmap->phys, map->size, err);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tdma_buf_unmap_attachment_unlocked(map->attach, map->table,\n\t\t\t\t\t\t  DMA_BIDIRECTIONAL);\n\t\tdma_buf_detach(map->buf, map->attach);\n\t\tdma_buf_put(map->buf);\n\t}\n\n\tif (map->fl) {\n\t\tspin_lock(&map->fl->lock);\n\t\tlist_del(&map->node);\n\t\tspin_unlock(&map->fl->lock);\n\t\tmap->fl = NULL;\n\t}\n\n\tkfree(map);\n}\n\nstatic void fastrpc_map_put(struct fastrpc_map *map)\n{\n\tif (map)\n\t\tkref_put(&map->refcount, fastrpc_free_map);\n}\n\nstatic int fastrpc_map_get(struct fastrpc_map *map)\n{\n\tif (!map)\n\t\treturn -ENOENT;\n\n\treturn kref_get_unless_zero(&map->refcount) ? 0 : -ENOENT;\n}\n\n\nstatic int fastrpc_map_lookup(struct fastrpc_user *fl, int fd,\n\t\t\t    struct fastrpc_map **ppmap, bool take_ref)\n{\n\tstruct fastrpc_session_ctx *sess = fl->sctx;\n\tstruct fastrpc_map *map = NULL;\n\tint ret = -ENOENT;\n\n\tspin_lock(&fl->lock);\n\tlist_for_each_entry(map, &fl->maps, node) {\n\t\tif (map->fd != fd)\n\t\t\tcontinue;\n\n\t\tif (take_ref) {\n\t\t\tret = fastrpc_map_get(map);\n\t\t\tif (ret) {\n\t\t\t\tdev_dbg(sess->dev, \"%s: Failed to get map fd=%d ret=%d\\n\",\n\t\t\t\t\t__func__, fd, ret);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t*ppmap = map;\n\t\tret = 0;\n\t\tbreak;\n\t}\n\tspin_unlock(&fl->lock);\n\n\treturn ret;\n}\n\nstatic void fastrpc_buf_free(struct fastrpc_buf *buf)\n{\n\tdma_free_coherent(buf->dev, buf->size, buf->virt,\n\t\t\t  FASTRPC_PHYS(buf->phys));\n\tkfree(buf);\n}\n\nstatic int __fastrpc_buf_alloc(struct fastrpc_user *fl, struct device *dev,\n\t\t\t     u64 size, struct fastrpc_buf **obuf)\n{\n\tstruct fastrpc_buf *buf;\n\n\tbuf = kzalloc(sizeof(*buf), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&buf->attachments);\n\tINIT_LIST_HEAD(&buf->node);\n\tmutex_init(&buf->lock);\n\n\tbuf->fl = fl;\n\tbuf->virt = NULL;\n\tbuf->phys = 0;\n\tbuf->size = size;\n\tbuf->dev = dev;\n\tbuf->raddr = 0;\n\n\tbuf->virt = dma_alloc_coherent(dev, buf->size, (dma_addr_t *)&buf->phys,\n\t\t\t\t       GFP_KERNEL);\n\tif (!buf->virt) {\n\t\tmutex_destroy(&buf->lock);\n\t\tkfree(buf);\n\t\treturn -ENOMEM;\n\t}\n\n\t*obuf = buf;\n\n\treturn 0;\n}\n\nstatic int fastrpc_buf_alloc(struct fastrpc_user *fl, struct device *dev,\n\t\t\t     u64 size, struct fastrpc_buf **obuf)\n{\n\tint ret;\n\tstruct fastrpc_buf *buf;\n\n\tret = __fastrpc_buf_alloc(fl, dev, size, obuf);\n\tif (ret)\n\t\treturn ret;\n\n\tbuf = *obuf;\n\n\tif (fl->sctx && fl->sctx->sid)\n\t\tbuf->phys += ((u64)fl->sctx->sid << 32);\n\n\treturn 0;\n}\n\nstatic int fastrpc_remote_heap_alloc(struct fastrpc_user *fl, struct device *dev,\n\t\t\t\t     u64 size, struct fastrpc_buf **obuf)\n{\n\tstruct device *rdev = &fl->cctx->rpdev->dev;\n\n\treturn  __fastrpc_buf_alloc(fl, rdev, size, obuf);\n}\n\nstatic void fastrpc_channel_ctx_free(struct kref *ref)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\n\tcctx = container_of(ref, struct fastrpc_channel_ctx, refcount);\n\n\tkfree(cctx);\n}\n\nstatic void fastrpc_channel_ctx_get(struct fastrpc_channel_ctx *cctx)\n{\n\tkref_get(&cctx->refcount);\n}\n\nstatic void fastrpc_channel_ctx_put(struct fastrpc_channel_ctx *cctx)\n{\n\tkref_put(&cctx->refcount, fastrpc_channel_ctx_free);\n}\n\nstatic void fastrpc_context_free(struct kref *ref)\n{\n\tstruct fastrpc_invoke_ctx *ctx;\n\tstruct fastrpc_channel_ctx *cctx;\n\tunsigned long flags;\n\tint i;\n\n\tctx = container_of(ref, struct fastrpc_invoke_ctx, refcount);\n\tcctx = ctx->cctx;\n\n\tfor (i = 0; i < ctx->nbufs; i++)\n\t\tfastrpc_map_put(ctx->maps[i]);\n\n\tif (ctx->buf)\n\t\tfastrpc_buf_free(ctx->buf);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tidr_remove(&cctx->ctx_idr, ctx->ctxid >> 4);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tkfree(ctx->maps);\n\tkfree(ctx->olaps);\n\tkfree(ctx);\n\n\tfastrpc_channel_ctx_put(cctx);\n}\n\nstatic void fastrpc_context_get(struct fastrpc_invoke_ctx *ctx)\n{\n\tkref_get(&ctx->refcount);\n}\n\nstatic void fastrpc_context_put(struct fastrpc_invoke_ctx *ctx)\n{\n\tkref_put(&ctx->refcount, fastrpc_context_free);\n}\n\nstatic void fastrpc_context_put_wq(struct work_struct *work)\n{\n\tstruct fastrpc_invoke_ctx *ctx =\n\t\t\tcontainer_of(work, struct fastrpc_invoke_ctx, put_work);\n\n\tfastrpc_context_put(ctx);\n}\n\n#define CMP(aa, bb) ((aa) == (bb) ? 0 : (aa) < (bb) ? -1 : 1)\nstatic int olaps_cmp(const void *a, const void *b)\n{\n\tstruct fastrpc_buf_overlap *pa = (struct fastrpc_buf_overlap *)a;\n\tstruct fastrpc_buf_overlap *pb = (struct fastrpc_buf_overlap *)b;\n\t \n\tint st = CMP(pa->start, pb->start);\n\t \n\tint ed = CMP(pb->end, pa->end);\n\n\treturn st == 0 ? ed : st;\n}\n\nstatic void fastrpc_get_buff_overlaps(struct fastrpc_invoke_ctx *ctx)\n{\n\tu64 max_end = 0;\n\tint i;\n\n\tfor (i = 0; i < ctx->nbufs; ++i) {\n\t\tctx->olaps[i].start = ctx->args[i].ptr;\n\t\tctx->olaps[i].end = ctx->olaps[i].start + ctx->args[i].length;\n\t\tctx->olaps[i].raix = i;\n\t}\n\n\tsort(ctx->olaps, ctx->nbufs, sizeof(*ctx->olaps), olaps_cmp, NULL);\n\n\tfor (i = 0; i < ctx->nbufs; ++i) {\n\t\t \n\t\tif (ctx->olaps[i].start < max_end) {\n\t\t\tctx->olaps[i].mstart = max_end;\n\t\t\tctx->olaps[i].mend = ctx->olaps[i].end;\n\t\t\tctx->olaps[i].offset = max_end - ctx->olaps[i].start;\n\n\t\t\tif (ctx->olaps[i].end > max_end) {\n\t\t\t\tmax_end = ctx->olaps[i].end;\n\t\t\t} else {\n\t\t\t\tctx->olaps[i].mend = 0;\n\t\t\t\tctx->olaps[i].mstart = 0;\n\t\t\t}\n\n\t\t} else  {\n\t\t\tctx->olaps[i].mend = ctx->olaps[i].end;\n\t\t\tctx->olaps[i].mstart = ctx->olaps[i].start;\n\t\t\tctx->olaps[i].offset = 0;\n\t\t\tmax_end = ctx->olaps[i].end;\n\t\t}\n\t}\n}\n\nstatic struct fastrpc_invoke_ctx *fastrpc_context_alloc(\n\t\t\tstruct fastrpc_user *user, u32 kernel, u32 sc,\n\t\t\tstruct fastrpc_invoke_args *args)\n{\n\tstruct fastrpc_channel_ctx *cctx = user->cctx;\n\tstruct fastrpc_invoke_ctx *ctx = NULL;\n\tunsigned long flags;\n\tint ret;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tINIT_LIST_HEAD(&ctx->node);\n\tctx->fl = user;\n\tctx->nscalars = REMOTE_SCALARS_LENGTH(sc);\n\tctx->nbufs = REMOTE_SCALARS_INBUFS(sc) +\n\t\t     REMOTE_SCALARS_OUTBUFS(sc);\n\n\tif (ctx->nscalars) {\n\t\tctx->maps = kcalloc(ctx->nscalars,\n\t\t\t\t    sizeof(*ctx->maps), GFP_KERNEL);\n\t\tif (!ctx->maps) {\n\t\t\tkfree(ctx);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tctx->olaps = kcalloc(ctx->nscalars,\n\t\t\t\t    sizeof(*ctx->olaps), GFP_KERNEL);\n\t\tif (!ctx->olaps) {\n\t\t\tkfree(ctx->maps);\n\t\t\tkfree(ctx);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tctx->args = args;\n\t\tfastrpc_get_buff_overlaps(ctx);\n\t}\n\n\t \n\tfastrpc_channel_ctx_get(cctx);\n\n\tctx->sc = sc;\n\tctx->retval = -1;\n\tctx->pid = current->pid;\n\tctx->tgid = user->tgid;\n\tctx->cctx = cctx;\n\tinit_completion(&ctx->work);\n\tINIT_WORK(&ctx->put_work, fastrpc_context_put_wq);\n\n\tspin_lock(&user->lock);\n\tlist_add_tail(&ctx->node, &user->pending);\n\tspin_unlock(&user->lock);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tret = idr_alloc_cyclic(&cctx->ctx_idr, ctx, 1,\n\t\t\t       FASTRPC_CTX_MAX, GFP_ATOMIC);\n\tif (ret < 0) {\n\t\tspin_unlock_irqrestore(&cctx->lock, flags);\n\t\tgoto err_idr;\n\t}\n\tctx->ctxid = ret << 4;\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tkref_init(&ctx->refcount);\n\n\treturn ctx;\nerr_idr:\n\tspin_lock(&user->lock);\n\tlist_del(&ctx->node);\n\tspin_unlock(&user->lock);\n\tfastrpc_channel_ctx_put(cctx);\n\tkfree(ctx->maps);\n\tkfree(ctx->olaps);\n\tkfree(ctx);\n\n\treturn ERR_PTR(ret);\n}\n\nstatic struct sg_table *\nfastrpc_map_dma_buf(struct dma_buf_attachment *attachment,\n\t\t    enum dma_data_direction dir)\n{\n\tstruct fastrpc_dma_buf_attachment *a = attachment->priv;\n\tstruct sg_table *table;\n\tint ret;\n\n\ttable = &a->sgt;\n\n\tret = dma_map_sgtable(attachment->dev, table, dir, 0);\n\tif (ret)\n\t\ttable = ERR_PTR(ret);\n\treturn table;\n}\n\nstatic void fastrpc_unmap_dma_buf(struct dma_buf_attachment *attach,\n\t\t\t\t  struct sg_table *table,\n\t\t\t\t  enum dma_data_direction dir)\n{\n\tdma_unmap_sgtable(attach->dev, table, dir, 0);\n}\n\nstatic void fastrpc_release(struct dma_buf *dmabuf)\n{\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\n\tfastrpc_buf_free(buffer);\n}\n\nstatic int fastrpc_dma_buf_attach(struct dma_buf *dmabuf,\n\t\t\t\t  struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\tint ret;\n\n\ta = kzalloc(sizeof(*a), GFP_KERNEL);\n\tif (!a)\n\t\treturn -ENOMEM;\n\n\tret = dma_get_sgtable(buffer->dev, &a->sgt, buffer->virt,\n\t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n\tif (ret < 0) {\n\t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n\t\tkfree(a);\n\t\treturn -EINVAL;\n\t}\n\n\ta->dev = attachment->dev;\n\tINIT_LIST_HEAD(&a->node);\n\tattachment->priv = a;\n\n\tmutex_lock(&buffer->lock);\n\tlist_add(&a->node, &buffer->attachments);\n\tmutex_unlock(&buffer->lock);\n\n\treturn 0;\n}\n\nstatic void fastrpc_dma_buf_detatch(struct dma_buf *dmabuf,\n\t\t\t\t    struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a = attachment->priv;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\n\tmutex_lock(&buffer->lock);\n\tlist_del(&a->node);\n\tmutex_unlock(&buffer->lock);\n\tsg_free_table(&a->sgt);\n\tkfree(a);\n}\n\nstatic int fastrpc_vmap(struct dma_buf *dmabuf, struct iosys_map *map)\n{\n\tstruct fastrpc_buf *buf = dmabuf->priv;\n\n\tiosys_map_set_vaddr(map, buf->virt);\n\n\treturn 0;\n}\n\nstatic int fastrpc_mmap(struct dma_buf *dmabuf,\n\t\t\tstruct vm_area_struct *vma)\n{\n\tstruct fastrpc_buf *buf = dmabuf->priv;\n\tsize_t size = vma->vm_end - vma->vm_start;\n\n\tdma_resv_assert_held(dmabuf->resv);\n\n\treturn dma_mmap_coherent(buf->dev, vma, buf->virt,\n\t\t\t\t FASTRPC_PHYS(buf->phys), size);\n}\n\nstatic const struct dma_buf_ops fastrpc_dma_buf_ops = {\n\t.attach = fastrpc_dma_buf_attach,\n\t.detach = fastrpc_dma_buf_detatch,\n\t.map_dma_buf = fastrpc_map_dma_buf,\n\t.unmap_dma_buf = fastrpc_unmap_dma_buf,\n\t.mmap = fastrpc_mmap,\n\t.vmap = fastrpc_vmap,\n\t.release = fastrpc_release,\n};\n\nstatic int fastrpc_map_create(struct fastrpc_user *fl, int fd,\n\t\t\t      u64 len, u32 attr, struct fastrpc_map **ppmap)\n{\n\tstruct fastrpc_session_ctx *sess = fl->sctx;\n\tstruct fastrpc_map *map = NULL;\n\tstruct sg_table *table;\n\tint err = 0;\n\n\tif (!fastrpc_map_lookup(fl, fd, ppmap, true))\n\t\treturn 0;\n\n\tmap = kzalloc(sizeof(*map), GFP_KERNEL);\n\tif (!map)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&map->node);\n\tkref_init(&map->refcount);\n\n\tmap->fl = fl;\n\tmap->fd = fd;\n\tmap->buf = dma_buf_get(fd);\n\tif (IS_ERR(map->buf)) {\n\t\terr = PTR_ERR(map->buf);\n\t\tgoto get_err;\n\t}\n\n\tmap->attach = dma_buf_attach(map->buf, sess->dev);\n\tif (IS_ERR(map->attach)) {\n\t\tdev_err(sess->dev, \"Failed to attach dmabuf\\n\");\n\t\terr = PTR_ERR(map->attach);\n\t\tgoto attach_err;\n\t}\n\n\ttable = dma_buf_map_attachment_unlocked(map->attach, DMA_BIDIRECTIONAL);\n\tif (IS_ERR(table)) {\n\t\terr = PTR_ERR(table);\n\t\tgoto map_err;\n\t}\n\tmap->table = table;\n\n\tif (attr & FASTRPC_ATTR_SECUREMAP) {\n\t\tmap->phys = sg_phys(map->table->sgl);\n\t} else {\n\t\tmap->phys = sg_dma_address(map->table->sgl);\n\t\tmap->phys += ((u64)fl->sctx->sid << 32);\n\t}\n\tmap->size = len;\n\tmap->va = sg_virt(map->table->sgl);\n\tmap->len = len;\n\n\tif (attr & FASTRPC_ATTR_SECUREMAP) {\n\t\t \n\t\tu64 src_perms = BIT(QCOM_SCM_VMID_HLOS);\n\t\tstruct qcom_scm_vmperm dst_perms[2] = {0};\n\n\t\tdst_perms[0].vmid = QCOM_SCM_VMID_HLOS;\n\t\tdst_perms[0].perm = QCOM_SCM_PERM_RW;\n\t\tdst_perms[1].vmid = fl->cctx->vmperms[0].vmid;\n\t\tdst_perms[1].perm = QCOM_SCM_PERM_RWX;\n\t\tmap->attr = attr;\n\t\terr = qcom_scm_assign_mem(map->phys, (u64)map->size, &src_perms, dst_perms, 2);\n\t\tif (err) {\n\t\t\tdev_err(sess->dev, \"Failed to assign memory with phys 0x%llx size 0x%llx err %d\",\n\t\t\t\t\tmap->phys, map->size, err);\n\t\t\tgoto map_err;\n\t\t}\n\t}\n\tspin_lock(&fl->lock);\n\tlist_add_tail(&map->node, &fl->maps);\n\tspin_unlock(&fl->lock);\n\t*ppmap = map;\n\n\treturn 0;\n\nmap_err:\n\tdma_buf_detach(map->buf, map->attach);\nattach_err:\n\tdma_buf_put(map->buf);\nget_err:\n\tfastrpc_map_put(map);\n\n\treturn err;\n}\n\n \n\nstatic int fastrpc_get_meta_size(struct fastrpc_invoke_ctx *ctx)\n{\n\tint size = 0;\n\n\tsize = (sizeof(struct fastrpc_remote_buf) +\n\t\tsizeof(struct fastrpc_invoke_buf) +\n\t\tsizeof(struct fastrpc_phy_page)) * ctx->nscalars +\n\t\tsizeof(u64) * FASTRPC_MAX_FDLIST +\n\t\tsizeof(u32) * FASTRPC_MAX_CRCLIST;\n\n\treturn size;\n}\n\nstatic u64 fastrpc_get_payload_size(struct fastrpc_invoke_ctx *ctx, int metalen)\n{\n\tu64 size = 0;\n\tint oix;\n\n\tsize = ALIGN(metalen, FASTRPC_ALIGN);\n\tfor (oix = 0; oix < ctx->nbufs; oix++) {\n\t\tint i = ctx->olaps[oix].raix;\n\n\t\tif (ctx->args[i].fd == 0 || ctx->args[i].fd == -1) {\n\n\t\t\tif (ctx->olaps[oix].offset == 0)\n\t\t\t\tsize = ALIGN(size, FASTRPC_ALIGN);\n\n\t\t\tsize += (ctx->olaps[oix].mend - ctx->olaps[oix].mstart);\n\t\t}\n\t}\n\n\treturn size;\n}\n\nstatic int fastrpc_create_maps(struct fastrpc_invoke_ctx *ctx)\n{\n\tstruct device *dev = ctx->fl->sctx->dev;\n\tint i, err;\n\n\tfor (i = 0; i < ctx->nscalars; ++i) {\n\n\t\tif (ctx->args[i].fd == 0 || ctx->args[i].fd == -1 ||\n\t\t    ctx->args[i].length == 0)\n\t\t\tcontinue;\n\n\t\terr = fastrpc_map_create(ctx->fl, ctx->args[i].fd,\n\t\t\t ctx->args[i].length, ctx->args[i].attr, &ctx->maps[i]);\n\t\tif (err) {\n\t\t\tdev_err(dev, \"Error Creating map %d\\n\", err);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t}\n\treturn 0;\n}\n\nstatic struct fastrpc_invoke_buf *fastrpc_invoke_buf_start(union fastrpc_remote_arg *pra, int len)\n{\n\treturn (struct fastrpc_invoke_buf *)(&pra[len]);\n}\n\nstatic struct fastrpc_phy_page *fastrpc_phy_page_start(struct fastrpc_invoke_buf *buf, int len)\n{\n\treturn (struct fastrpc_phy_page *)(&buf[len]);\n}\n\nstatic int fastrpc_get_args(u32 kernel, struct fastrpc_invoke_ctx *ctx)\n{\n\tstruct device *dev = ctx->fl->sctx->dev;\n\tunion fastrpc_remote_arg *rpra;\n\tstruct fastrpc_invoke_buf *list;\n\tstruct fastrpc_phy_page *pages;\n\tint inbufs, i, oix, err = 0;\n\tu64 len, rlen, pkt_size;\n\tu64 pg_start, pg_end;\n\tuintptr_t args;\n\tint metalen;\n\n\tinbufs = REMOTE_SCALARS_INBUFS(ctx->sc);\n\tmetalen = fastrpc_get_meta_size(ctx);\n\tpkt_size = fastrpc_get_payload_size(ctx, metalen);\n\n\terr = fastrpc_create_maps(ctx);\n\tif (err)\n\t\treturn err;\n\n\tctx->msg_sz = pkt_size;\n\n\terr = fastrpc_buf_alloc(ctx->fl, dev, pkt_size, &ctx->buf);\n\tif (err)\n\t\treturn err;\n\n\tmemset(ctx->buf->virt, 0, pkt_size);\n\trpra = ctx->buf->virt;\n\tlist = fastrpc_invoke_buf_start(rpra, ctx->nscalars);\n\tpages = fastrpc_phy_page_start(list, ctx->nscalars);\n\targs = (uintptr_t)ctx->buf->virt + metalen;\n\trlen = pkt_size - metalen;\n\tctx->rpra = rpra;\n\n\tfor (oix = 0; oix < ctx->nbufs; ++oix) {\n\t\tint mlen;\n\n\t\ti = ctx->olaps[oix].raix;\n\t\tlen = ctx->args[i].length;\n\n\t\trpra[i].buf.pv = 0;\n\t\trpra[i].buf.len = len;\n\t\tlist[i].num = len ? 1 : 0;\n\t\tlist[i].pgidx = i;\n\n\t\tif (!len)\n\t\t\tcontinue;\n\n\t\tif (ctx->maps[i]) {\n\t\t\tstruct vm_area_struct *vma = NULL;\n\n\t\t\trpra[i].buf.pv = (u64) ctx->args[i].ptr;\n\t\t\tpages[i].addr = ctx->maps[i]->phys;\n\n\t\t\tmmap_read_lock(current->mm);\n\t\t\tvma = find_vma(current->mm, ctx->args[i].ptr);\n\t\t\tif (vma)\n\t\t\t\tpages[i].addr += ctx->args[i].ptr -\n\t\t\t\t\t\t vma->vm_start;\n\t\t\tmmap_read_unlock(current->mm);\n\n\t\t\tpg_start = (ctx->args[i].ptr & PAGE_MASK) >> PAGE_SHIFT;\n\t\t\tpg_end = ((ctx->args[i].ptr + len - 1) & PAGE_MASK) >>\n\t\t\t\t  PAGE_SHIFT;\n\t\t\tpages[i].size = (pg_end - pg_start + 1) * PAGE_SIZE;\n\n\t\t} else {\n\n\t\t\tif (ctx->olaps[oix].offset == 0) {\n\t\t\t\trlen -= ALIGN(args, FASTRPC_ALIGN) - args;\n\t\t\t\targs = ALIGN(args, FASTRPC_ALIGN);\n\t\t\t}\n\n\t\t\tmlen = ctx->olaps[oix].mend - ctx->olaps[oix].mstart;\n\n\t\t\tif (rlen < mlen)\n\t\t\t\tgoto bail;\n\n\t\t\trpra[i].buf.pv = args - ctx->olaps[oix].offset;\n\t\t\tpages[i].addr = ctx->buf->phys -\n\t\t\t\t\tctx->olaps[oix].offset +\n\t\t\t\t\t(pkt_size - rlen);\n\t\t\tpages[i].addr = pages[i].addr &\tPAGE_MASK;\n\n\t\t\tpg_start = (args & PAGE_MASK) >> PAGE_SHIFT;\n\t\t\tpg_end = ((args + len - 1) & PAGE_MASK) >> PAGE_SHIFT;\n\t\t\tpages[i].size = (pg_end - pg_start + 1) * PAGE_SIZE;\n\t\t\targs = args + mlen;\n\t\t\trlen -= mlen;\n\t\t}\n\n\t\tif (i < inbufs && !ctx->maps[i]) {\n\t\t\tvoid *dst = (void *)(uintptr_t)rpra[i].buf.pv;\n\t\t\tvoid *src = (void *)(uintptr_t)ctx->args[i].ptr;\n\n\t\t\tif (!kernel) {\n\t\t\t\tif (copy_from_user(dst, (void __user *)src,\n\t\t\t\t\t\t   len)) {\n\t\t\t\t\terr = -EFAULT;\n\t\t\t\t\tgoto bail;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tmemcpy(dst, src, len);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i = ctx->nbufs; i < ctx->nscalars; ++i) {\n\t\tlist[i].num = ctx->args[i].length ? 1 : 0;\n\t\tlist[i].pgidx = i;\n\t\tif (ctx->maps[i]) {\n\t\t\tpages[i].addr = ctx->maps[i]->phys;\n\t\t\tpages[i].size = ctx->maps[i]->size;\n\t\t}\n\t\trpra[i].dma.fd = ctx->args[i].fd;\n\t\trpra[i].dma.len = ctx->args[i].length;\n\t\trpra[i].dma.offset = (u64) ctx->args[i].ptr;\n\t}\n\nbail:\n\tif (err)\n\t\tdev_err(dev, \"Error: get invoke args failed:%d\\n\", err);\n\n\treturn err;\n}\n\nstatic int fastrpc_put_args(struct fastrpc_invoke_ctx *ctx,\n\t\t\t    u32 kernel)\n{\n\tunion fastrpc_remote_arg *rpra = ctx->rpra;\n\tstruct fastrpc_user *fl = ctx->fl;\n\tstruct fastrpc_map *mmap = NULL;\n\tstruct fastrpc_invoke_buf *list;\n\tstruct fastrpc_phy_page *pages;\n\tu64 *fdlist;\n\tint i, inbufs, outbufs, handles;\n\n\tinbufs = REMOTE_SCALARS_INBUFS(ctx->sc);\n\toutbufs = REMOTE_SCALARS_OUTBUFS(ctx->sc);\n\thandles = REMOTE_SCALARS_INHANDLES(ctx->sc) + REMOTE_SCALARS_OUTHANDLES(ctx->sc);\n\tlist = fastrpc_invoke_buf_start(rpra, ctx->nscalars);\n\tpages = fastrpc_phy_page_start(list, ctx->nscalars);\n\tfdlist = (uint64_t *)(pages + inbufs + outbufs + handles);\n\n\tfor (i = inbufs; i < ctx->nbufs; ++i) {\n\t\tif (!ctx->maps[i]) {\n\t\t\tvoid *src = (void *)(uintptr_t)rpra[i].buf.pv;\n\t\t\tvoid *dst = (void *)(uintptr_t)ctx->args[i].ptr;\n\t\t\tu64 len = rpra[i].buf.len;\n\n\t\t\tif (!kernel) {\n\t\t\t\tif (copy_to_user((void __user *)dst, src, len))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t} else {\n\t\t\t\tmemcpy(dst, src, len);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < FASTRPC_MAX_FDLIST; i++) {\n\t\tif (!fdlist[i])\n\t\t\tbreak;\n\t\tif (!fastrpc_map_lookup(fl, (int)fdlist[i], &mmap, false))\n\t\t\tfastrpc_map_put(mmap);\n\t}\n\n\treturn 0;\n}\n\nstatic int fastrpc_invoke_send(struct fastrpc_session_ctx *sctx,\n\t\t\t       struct fastrpc_invoke_ctx *ctx,\n\t\t\t       u32 kernel, uint32_t handle)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_user *fl = ctx->fl;\n\tstruct fastrpc_msg *msg = &ctx->msg;\n\tint ret;\n\n\tcctx = fl->cctx;\n\tmsg->pid = fl->tgid;\n\tmsg->tid = current->pid;\n\n\tif (kernel)\n\t\tmsg->pid = 0;\n\n\tmsg->ctx = ctx->ctxid | fl->pd;\n\tmsg->handle = handle;\n\tmsg->sc = ctx->sc;\n\tmsg->addr = ctx->buf ? ctx->buf->phys : 0;\n\tmsg->size = roundup(ctx->msg_sz, PAGE_SIZE);\n\tfastrpc_context_get(ctx);\n\n\tret = rpmsg_send(cctx->rpdev->ept, (void *)msg, sizeof(*msg));\n\n\tif (ret)\n\t\tfastrpc_context_put(ctx);\n\n\treturn ret;\n\n}\n\nstatic int fastrpc_internal_invoke(struct fastrpc_user *fl,  u32 kernel,\n\t\t\t\t   u32 handle, u32 sc,\n\t\t\t\t   struct fastrpc_invoke_args *args)\n{\n\tstruct fastrpc_invoke_ctx *ctx = NULL;\n\tstruct fastrpc_buf *buf, *b;\n\n\tint err = 0;\n\n\tif (!fl->sctx)\n\t\treturn -EINVAL;\n\n\tif (!fl->cctx->rpdev)\n\t\treturn -EPIPE;\n\n\tif (handle == FASTRPC_INIT_HANDLE && !kernel) {\n\t\tdev_warn_ratelimited(fl->sctx->dev, \"user app trying to send a kernel RPC message (%d)\\n\",  handle);\n\t\treturn -EPERM;\n\t}\n\n\tctx = fastrpc_context_alloc(fl, kernel, sc, args);\n\tif (IS_ERR(ctx))\n\t\treturn PTR_ERR(ctx);\n\n\terr = fastrpc_get_args(kernel, ctx);\n\tif (err)\n\t\tgoto bail;\n\n\t \n\tdma_wmb();\n\t \n\terr = fastrpc_invoke_send(fl->sctx, ctx, kernel, handle);\n\tif (err)\n\t\tgoto bail;\n\n\tif (kernel) {\n\t\tif (!wait_for_completion_timeout(&ctx->work, 10 * HZ))\n\t\t\terr = -ETIMEDOUT;\n\t} else {\n\t\terr = wait_for_completion_interruptible(&ctx->work);\n\t}\n\n\tif (err)\n\t\tgoto bail;\n\n\t \n\tdma_rmb();\n\t \n\terr = fastrpc_put_args(ctx, kernel);\n\tif (err)\n\t\tgoto bail;\n\n\t \n\terr = ctx->retval;\n\tif (err)\n\t\tgoto bail;\n\nbail:\n\tif (err != -ERESTARTSYS && err != -ETIMEDOUT) {\n\t\t \n\t\tspin_lock(&fl->lock);\n\t\tlist_del(&ctx->node);\n\t\tspin_unlock(&fl->lock);\n\t\tfastrpc_context_put(ctx);\n\t}\n\n\tif (err == -ERESTARTSYS) {\n\t\tlist_for_each_entry_safe(buf, b, &fl->mmaps, node) {\n\t\t\tlist_del(&buf->node);\n\t\t\tlist_add_tail(&buf->node, &fl->cctx->invoke_interrupted_mmaps);\n\t\t}\n\t}\n\n\tif (err)\n\t\tdev_dbg(fl->sctx->dev, \"Error: Invoke Failed %d\\n\", err);\n\n\treturn err;\n}\n\nstatic bool is_session_rejected(struct fastrpc_user *fl, bool unsigned_pd_request)\n{\n\t \n\tif (!fl->is_secure_dev && fl->cctx->secure) {\n\t\t \n\t\tif (!fl->cctx->unsigned_support || !unsigned_pd_request) {\n\t\t\tdev_err(&fl->cctx->rpdev->dev, \"Error: Untrusted application trying to offload to signed PD\");\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\nstatic int fastrpc_init_create_static_process(struct fastrpc_user *fl,\n\t\t\t\t\t      char __user *argp)\n{\n\tstruct fastrpc_init_create_static init;\n\tstruct fastrpc_invoke_args *args;\n\tstruct fastrpc_phy_page pages[1];\n\tchar *name;\n\tint err;\n\tstruct {\n\t\tint pgid;\n\t\tu32 namelen;\n\t\tu32 pageslen;\n\t} inbuf;\n\tu32 sc;\n\n\targs = kcalloc(FASTRPC_CREATE_STATIC_PROCESS_NARGS, sizeof(*args), GFP_KERNEL);\n\tif (!args)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(&init, argp, sizeof(init))) {\n\t\terr = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tif (init.namelen > INIT_FILE_NAMELEN_MAX) {\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tname = kzalloc(init.namelen, GFP_KERNEL);\n\tif (!name) {\n\t\terr = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tif (copy_from_user(name, (void __user *)(uintptr_t)init.name, init.namelen)) {\n\t\terr = -EFAULT;\n\t\tgoto err_name;\n\t}\n\n\tif (!fl->cctx->remote_heap) {\n\t\terr = fastrpc_remote_heap_alloc(fl, fl->sctx->dev, init.memlen,\n\t\t\t\t\t\t&fl->cctx->remote_heap);\n\t\tif (err)\n\t\t\tgoto err_name;\n\n\t\t \n\t\tif (fl->cctx->vmcount) {\n\t\t\terr = qcom_scm_assign_mem(fl->cctx->remote_heap->phys,\n\t\t\t\t\t\t\t(u64)fl->cctx->remote_heap->size,\n\t\t\t\t\t\t\t&fl->cctx->perms,\n\t\t\t\t\t\t\tfl->cctx->vmperms, fl->cctx->vmcount);\n\t\t\tif (err) {\n\t\t\t\tdev_err(fl->sctx->dev, \"Failed to assign memory with phys 0x%llx size 0x%llx err %d\",\n\t\t\t\t\tfl->cctx->remote_heap->phys, fl->cctx->remote_heap->size, err);\n\t\t\t\tgoto err_map;\n\t\t\t}\n\t\t}\n\t}\n\n\tinbuf.pgid = fl->tgid;\n\tinbuf.namelen = init.namelen;\n\tinbuf.pageslen = 0;\n\tfl->pd = USER_PD;\n\n\targs[0].ptr = (u64)(uintptr_t)&inbuf;\n\targs[0].length = sizeof(inbuf);\n\targs[0].fd = -1;\n\n\targs[1].ptr = (u64)(uintptr_t)name;\n\targs[1].length = inbuf.namelen;\n\targs[1].fd = -1;\n\n\tpages[0].addr = fl->cctx->remote_heap->phys;\n\tpages[0].size = fl->cctx->remote_heap->size;\n\n\targs[2].ptr = (u64)(uintptr_t) pages;\n\targs[2].length = sizeof(*pages);\n\targs[2].fd = -1;\n\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_CREATE_STATIC, 3, 0);\n\n\terr = fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t      sc, args);\n\tif (err)\n\t\tgoto err_invoke;\n\n\tkfree(args);\n\n\treturn 0;\nerr_invoke:\n\tif (fl->cctx->vmcount) {\n\t\tu64 src_perms = 0;\n\t\tstruct qcom_scm_vmperm dst_perms;\n\t\tu32 i;\n\n\t\tfor (i = 0; i < fl->cctx->vmcount; i++)\n\t\t\tsrc_perms |= BIT(fl->cctx->vmperms[i].vmid);\n\n\t\tdst_perms.vmid = QCOM_SCM_VMID_HLOS;\n\t\tdst_perms.perm = QCOM_SCM_PERM_RWX;\n\t\terr = qcom_scm_assign_mem(fl->cctx->remote_heap->phys,\n\t\t\t\t\t\t(u64)fl->cctx->remote_heap->size,\n\t\t\t\t\t\t&src_perms, &dst_perms, 1);\n\t\tif (err)\n\t\t\tdev_err(fl->sctx->dev, \"Failed to assign memory phys 0x%llx size 0x%llx err %d\",\n\t\t\t\tfl->cctx->remote_heap->phys, fl->cctx->remote_heap->size, err);\n\t}\nerr_map:\n\tfastrpc_buf_free(fl->cctx->remote_heap);\nerr_name:\n\tkfree(name);\nerr:\n\tkfree(args);\n\n\treturn err;\n}\n\nstatic int fastrpc_init_create_process(struct fastrpc_user *fl,\n\t\t\t\t\tchar __user *argp)\n{\n\tstruct fastrpc_init_create init;\n\tstruct fastrpc_invoke_args *args;\n\tstruct fastrpc_phy_page pages[1];\n\tstruct fastrpc_map *map = NULL;\n\tstruct fastrpc_buf *imem = NULL;\n\tint memlen;\n\tint err;\n\tstruct {\n\t\tint pgid;\n\t\tu32 namelen;\n\t\tu32 filelen;\n\t\tu32 pageslen;\n\t\tu32 attrs;\n\t\tu32 siglen;\n\t} inbuf;\n\tu32 sc;\n\tbool unsigned_module = false;\n\n\targs = kcalloc(FASTRPC_CREATE_PROCESS_NARGS, sizeof(*args), GFP_KERNEL);\n\tif (!args)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(&init, argp, sizeof(init))) {\n\t\terr = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tif (init.attrs & FASTRPC_MODE_UNSIGNED_MODULE)\n\t\tunsigned_module = true;\n\n\tif (is_session_rejected(fl, unsigned_module)) {\n\t\terr = -ECONNREFUSED;\n\t\tgoto err;\n\t}\n\n\tif (init.filelen > INIT_FILELEN_MAX) {\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tinbuf.pgid = fl->tgid;\n\tinbuf.namelen = strlen(current->comm) + 1;\n\tinbuf.filelen = init.filelen;\n\tinbuf.pageslen = 1;\n\tinbuf.attrs = init.attrs;\n\tinbuf.siglen = init.siglen;\n\tfl->pd = USER_PD;\n\n\tif (init.filelen && init.filefd) {\n\t\terr = fastrpc_map_create(fl, init.filefd, init.filelen, 0, &map);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tmemlen = ALIGN(max(INIT_FILELEN_MAX, (int)init.filelen * 4),\n\t\t       1024 * 1024);\n\terr = fastrpc_buf_alloc(fl, fl->sctx->dev, memlen,\n\t\t\t\t&imem);\n\tif (err)\n\t\tgoto err_alloc;\n\n\tfl->init_mem = imem;\n\targs[0].ptr = (u64)(uintptr_t)&inbuf;\n\targs[0].length = sizeof(inbuf);\n\targs[0].fd = -1;\n\n\targs[1].ptr = (u64)(uintptr_t)current->comm;\n\targs[1].length = inbuf.namelen;\n\targs[1].fd = -1;\n\n\targs[2].ptr = (u64) init.file;\n\targs[2].length = inbuf.filelen;\n\targs[2].fd = init.filefd;\n\n\tpages[0].addr = imem->phys;\n\tpages[0].size = imem->size;\n\n\targs[3].ptr = (u64)(uintptr_t) pages;\n\targs[3].length = 1 * sizeof(*pages);\n\targs[3].fd = -1;\n\n\targs[4].ptr = (u64)(uintptr_t)&inbuf.attrs;\n\targs[4].length = sizeof(inbuf.attrs);\n\targs[4].fd = -1;\n\n\targs[5].ptr = (u64)(uintptr_t) &inbuf.siglen;\n\targs[5].length = sizeof(inbuf.siglen);\n\targs[5].fd = -1;\n\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_CREATE, 4, 0);\n\tif (init.attrs)\n\t\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_CREATE_ATTR, 4, 0);\n\n\terr = fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t      sc, args);\n\tif (err)\n\t\tgoto err_invoke;\n\n\tkfree(args);\n\n\treturn 0;\n\nerr_invoke:\n\tfl->init_mem = NULL;\n\tfastrpc_buf_free(imem);\nerr_alloc:\n\tfastrpc_map_put(map);\nerr:\n\tkfree(args);\n\n\treturn err;\n}\n\nstatic struct fastrpc_session_ctx *fastrpc_session_alloc(\n\t\t\t\t\tstruct fastrpc_channel_ctx *cctx)\n{\n\tstruct fastrpc_session_ctx *session = NULL;\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tfor (i = 0; i < cctx->sesscount; i++) {\n\t\tif (!cctx->session[i].used && cctx->session[i].valid) {\n\t\t\tcctx->session[i].used = true;\n\t\t\tsession = &cctx->session[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\treturn session;\n}\n\nstatic void fastrpc_session_free(struct fastrpc_channel_ctx *cctx,\n\t\t\t\t struct fastrpc_session_ctx *session)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tsession->used = false;\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n}\n\nstatic int fastrpc_release_current_dsp_process(struct fastrpc_user *fl)\n{\n\tstruct fastrpc_invoke_args args[1];\n\tint tgid = 0;\n\tu32 sc;\n\n\ttgid = fl->tgid;\n\targs[0].ptr = (u64)(uintptr_t) &tgid;\n\targs[0].length = sizeof(tgid);\n\targs[0].fd = -1;\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_RELEASE, 1, 0);\n\n\treturn fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t       sc, &args[0]);\n}\n\nstatic int fastrpc_device_release(struct inode *inode, struct file *file)\n{\n\tstruct fastrpc_user *fl = (struct fastrpc_user *)file->private_data;\n\tstruct fastrpc_channel_ctx *cctx = fl->cctx;\n\tstruct fastrpc_invoke_ctx *ctx, *n;\n\tstruct fastrpc_map *map, *m;\n\tstruct fastrpc_buf *buf, *b;\n\tunsigned long flags;\n\n\tfastrpc_release_current_dsp_process(fl);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tlist_del(&fl->user);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tif (fl->init_mem)\n\t\tfastrpc_buf_free(fl->init_mem);\n\n\tlist_for_each_entry_safe(ctx, n, &fl->pending, node) {\n\t\tlist_del(&ctx->node);\n\t\tfastrpc_context_put(ctx);\n\t}\n\n\tlist_for_each_entry_safe(map, m, &fl->maps, node)\n\t\tfastrpc_map_put(map);\n\n\tlist_for_each_entry_safe(buf, b, &fl->mmaps, node) {\n\t\tlist_del(&buf->node);\n\t\tfastrpc_buf_free(buf);\n\t}\n\n\tfastrpc_session_free(cctx, fl->sctx);\n\tfastrpc_channel_ctx_put(cctx);\n\n\tmutex_destroy(&fl->mutex);\n\tkfree(fl);\n\tfile->private_data = NULL;\n\n\treturn 0;\n}\n\nstatic int fastrpc_device_open(struct inode *inode, struct file *filp)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_device *fdevice;\n\tstruct fastrpc_user *fl = NULL;\n\tunsigned long flags;\n\n\tfdevice = miscdev_to_fdevice(filp->private_data);\n\tcctx = fdevice->cctx;\n\n\tfl = kzalloc(sizeof(*fl), GFP_KERNEL);\n\tif (!fl)\n\t\treturn -ENOMEM;\n\n\t \n\tfastrpc_channel_ctx_get(cctx);\n\n\tfilp->private_data = fl;\n\tspin_lock_init(&fl->lock);\n\tmutex_init(&fl->mutex);\n\tINIT_LIST_HEAD(&fl->pending);\n\tINIT_LIST_HEAD(&fl->maps);\n\tINIT_LIST_HEAD(&fl->mmaps);\n\tINIT_LIST_HEAD(&fl->user);\n\tfl->tgid = current->tgid;\n\tfl->cctx = cctx;\n\tfl->is_secure_dev = fdevice->secure;\n\n\tfl->sctx = fastrpc_session_alloc(cctx);\n\tif (!fl->sctx) {\n\t\tdev_err(&cctx->rpdev->dev, \"No session available\\n\");\n\t\tmutex_destroy(&fl->mutex);\n\t\tkfree(fl);\n\n\t\treturn -EBUSY;\n\t}\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tlist_add_tail(&fl->user, &cctx->users);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\treturn 0;\n}\n\nstatic int fastrpc_dmabuf_alloc(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_alloc_dma_buf bp;\n\tDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\n\tstruct fastrpc_buf *buf = NULL;\n\tint err;\n\n\tif (copy_from_user(&bp, argp, sizeof(bp)))\n\t\treturn -EFAULT;\n\n\terr = fastrpc_buf_alloc(fl, fl->sctx->dev, bp.size, &buf);\n\tif (err)\n\t\treturn err;\n\texp_info.ops = &fastrpc_dma_buf_ops;\n\texp_info.size = bp.size;\n\texp_info.flags = O_RDWR;\n\texp_info.priv = buf;\n\tbuf->dmabuf = dma_buf_export(&exp_info);\n\tif (IS_ERR(buf->dmabuf)) {\n\t\terr = PTR_ERR(buf->dmabuf);\n\t\tfastrpc_buf_free(buf);\n\t\treturn err;\n\t}\n\n\tbp.fd = dma_buf_fd(buf->dmabuf, O_ACCMODE);\n\tif (bp.fd < 0) {\n\t\tdma_buf_put(buf->dmabuf);\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_to_user(argp, &bp, sizeof(bp))) {\n\t\t \n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n\nstatic int fastrpc_init_attach(struct fastrpc_user *fl, int pd)\n{\n\tstruct fastrpc_invoke_args args[1];\n\tint tgid = fl->tgid;\n\tu32 sc;\n\n\targs[0].ptr = (u64)(uintptr_t) &tgid;\n\targs[0].length = sizeof(tgid);\n\targs[0].fd = -1;\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_ATTACH, 1, 0);\n\tfl->pd = pd;\n\n\treturn fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t       sc, &args[0]);\n}\n\nstatic int fastrpc_invoke(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_invoke_args *args = NULL;\n\tstruct fastrpc_invoke inv;\n\tu32 nscalars;\n\tint err;\n\n\tif (copy_from_user(&inv, argp, sizeof(inv)))\n\t\treturn -EFAULT;\n\n\t \n\tnscalars = REMOTE_SCALARS_LENGTH(inv.sc);\n\tif (nscalars) {\n\t\targs = kcalloc(nscalars, sizeof(*args), GFP_KERNEL);\n\t\tif (!args)\n\t\t\treturn -ENOMEM;\n\n\t\tif (copy_from_user(args, (void __user *)(uintptr_t)inv.args,\n\t\t\t\t   nscalars * sizeof(*args))) {\n\t\t\tkfree(args);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\terr = fastrpc_internal_invoke(fl, false, inv.handle, inv.sc, args);\n\tkfree(args);\n\n\treturn err;\n}\n\nstatic int fastrpc_get_info_from_dsp(struct fastrpc_user *fl, uint32_t *dsp_attr_buf,\n\t\t\t\t     uint32_t dsp_attr_buf_len)\n{\n\tstruct fastrpc_invoke_args args[2] = { 0 };\n\n\t \n\tdsp_attr_buf[0] = 0;\n\n\targs[0].ptr = (u64)(uintptr_t)&dsp_attr_buf_len;\n\targs[0].length = sizeof(dsp_attr_buf_len);\n\targs[0].fd = -1;\n\targs[1].ptr = (u64)(uintptr_t)&dsp_attr_buf[1];\n\targs[1].length = dsp_attr_buf_len;\n\targs[1].fd = -1;\n\tfl->pd = USER_PD;\n\n\treturn fastrpc_internal_invoke(fl, true, FASTRPC_DSP_UTILITIES_HANDLE,\n\t\t\t\t       FASTRPC_SCALARS(0, 1, 1), args);\n}\n\nstatic int fastrpc_get_info_from_kernel(struct fastrpc_ioctl_capability *cap,\n\t\t\t\t\tstruct fastrpc_user *fl)\n{\n\tstruct fastrpc_channel_ctx *cctx = fl->cctx;\n\tuint32_t attribute_id = cap->attribute_id;\n\tuint32_t *dsp_attributes;\n\tunsigned long flags;\n\tuint32_t domain = cap->domain;\n\tint err;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\t \n\tif (cctx->valid_attributes) {\n\t\tspin_unlock_irqrestore(&cctx->lock, flags);\n\t\tgoto done;\n\t}\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tdsp_attributes = kzalloc(FASTRPC_MAX_DSP_ATTRIBUTES_LEN, GFP_KERNEL);\n\tif (!dsp_attributes)\n\t\treturn -ENOMEM;\n\n\terr = fastrpc_get_info_from_dsp(fl, dsp_attributes, FASTRPC_MAX_DSP_ATTRIBUTES_LEN);\n\tif (err == DSP_UNSUPPORTED_API) {\n\t\tdev_info(&cctx->rpdev->dev,\n\t\t\t \"Warning: DSP capabilities not supported on domain: %d\\n\", domain);\n\t\tkfree(dsp_attributes);\n\t\treturn -EOPNOTSUPP;\n\t} else if (err) {\n\t\tdev_err(&cctx->rpdev->dev, \"Error: dsp information is incorrect err: %d\\n\", err);\n\t\tkfree(dsp_attributes);\n\t\treturn err;\n\t}\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tmemcpy(cctx->dsp_attributes, dsp_attributes, FASTRPC_MAX_DSP_ATTRIBUTES_LEN);\n\tcctx->valid_attributes = true;\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\tkfree(dsp_attributes);\ndone:\n\tcap->capability = cctx->dsp_attributes[attribute_id];\n\treturn 0;\n}\n\nstatic int fastrpc_get_dsp_info(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_ioctl_capability cap = {0};\n\tint err = 0;\n\n\tif (copy_from_user(&cap, argp, sizeof(cap)))\n\t\treturn  -EFAULT;\n\n\tcap.capability = 0;\n\tif (cap.domain >= FASTRPC_DEV_MAX) {\n\t\tdev_err(&fl->cctx->rpdev->dev, \"Error: Invalid domain id:%d, err:%d\\n\",\n\t\t\tcap.domain, err);\n\t\treturn -ECHRNG;\n\t}\n\n\t \n\tif (cap.domain == MDSP_DOMAIN_ID) {\n\t\tdev_err(&fl->cctx->rpdev->dev, \"Error: modem not supported %d\\n\", err);\n\t\treturn -ECHRNG;\n\t}\n\n\tif (cap.attribute_id >= FASTRPC_MAX_DSP_ATTRIBUTES) {\n\t\tdev_err(&fl->cctx->rpdev->dev, \"Error: invalid attribute: %d, err: %d\\n\",\n\t\t\tcap.attribute_id, err);\n\t\treturn -EOVERFLOW;\n\t}\n\n\terr = fastrpc_get_info_from_kernel(&cap, fl);\n\tif (err)\n\t\treturn err;\n\n\tif (copy_to_user(argp, &cap.capability, sizeof(cap.capability)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int fastrpc_req_munmap_impl(struct fastrpc_user *fl, struct fastrpc_buf *buf)\n{\n\tstruct fastrpc_invoke_args args[1] = { [0] = { 0 } };\n\tstruct fastrpc_munmap_req_msg req_msg;\n\tstruct device *dev = fl->sctx->dev;\n\tint err;\n\tu32 sc;\n\n\treq_msg.pgid = fl->tgid;\n\treq_msg.size = buf->size;\n\treq_msg.vaddr = buf->raddr;\n\n\targs[0].ptr = (u64) (uintptr_t) &req_msg;\n\targs[0].length = sizeof(req_msg);\n\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_MUNMAP, 1, 0);\n\terr = fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE, sc,\n\t\t\t\t      &args[0]);\n\tif (!err) {\n\t\tdev_dbg(dev, \"unmmap\\tpt 0x%09lx OK\\n\", buf->raddr);\n\t\tspin_lock(&fl->lock);\n\t\tlist_del(&buf->node);\n\t\tspin_unlock(&fl->lock);\n\t\tfastrpc_buf_free(buf);\n\t} else {\n\t\tdev_err(dev, \"unmmap\\tpt 0x%09lx ERROR\\n\", buf->raddr);\n\t}\n\n\treturn err;\n}\n\nstatic int fastrpc_req_munmap(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_buf *buf = NULL, *iter, *b;\n\tstruct fastrpc_req_munmap req;\n\tstruct device *dev = fl->sctx->dev;\n\n\tif (copy_from_user(&req, argp, sizeof(req)))\n\t\treturn -EFAULT;\n\n\tspin_lock(&fl->lock);\n\tlist_for_each_entry_safe(iter, b, &fl->mmaps, node) {\n\t\tif ((iter->raddr == req.vaddrout) && (iter->size == req.size)) {\n\t\t\tbuf = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&fl->lock);\n\n\tif (!buf) {\n\t\tdev_err(dev, \"mmap\\t\\tpt 0x%09llx [len 0x%08llx] not in list\\n\",\n\t\t\treq.vaddrout, req.size);\n\t\treturn -EINVAL;\n\t}\n\n\treturn fastrpc_req_munmap_impl(fl, buf);\n}\n\nstatic int fastrpc_req_mmap(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_invoke_args args[3] = { [0 ... 2] = { 0 } };\n\tstruct fastrpc_buf *buf = NULL;\n\tstruct fastrpc_mmap_req_msg req_msg;\n\tstruct fastrpc_mmap_rsp_msg rsp_msg;\n\tstruct fastrpc_phy_page pages;\n\tstruct fastrpc_req_mmap req;\n\tstruct device *dev = fl->sctx->dev;\n\tint err;\n\tu32 sc;\n\n\tif (copy_from_user(&req, argp, sizeof(req)))\n\t\treturn -EFAULT;\n\n\tif (req.flags != ADSP_MMAP_ADD_PAGES && req.flags != ADSP_MMAP_REMOTE_HEAP_ADDR) {\n\t\tdev_err(dev, \"flag not supported 0x%x\\n\", req.flags);\n\n\t\treturn -EINVAL;\n\t}\n\n\tif (req.vaddrin) {\n\t\tdev_err(dev, \"adding user allocated pages is not supported\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (req.flags == ADSP_MMAP_REMOTE_HEAP_ADDR)\n\t\terr = fastrpc_remote_heap_alloc(fl, dev, req.size, &buf);\n\telse\n\t\terr = fastrpc_buf_alloc(fl, dev, req.size, &buf);\n\n\tif (err) {\n\t\tdev_err(dev, \"failed to allocate buffer\\n\");\n\t\treturn err;\n\t}\n\n\treq_msg.pgid = fl->tgid;\n\treq_msg.flags = req.flags;\n\treq_msg.vaddr = req.vaddrin;\n\treq_msg.num = sizeof(pages);\n\n\targs[0].ptr = (u64) (uintptr_t) &req_msg;\n\targs[0].length = sizeof(req_msg);\n\n\tpages.addr = buf->phys;\n\tpages.size = buf->size;\n\n\targs[1].ptr = (u64) (uintptr_t) &pages;\n\targs[1].length = sizeof(pages);\n\n\targs[2].ptr = (u64) (uintptr_t) &rsp_msg;\n\targs[2].length = sizeof(rsp_msg);\n\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_MMAP, 2, 1);\n\terr = fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE, sc,\n\t\t\t\t      &args[0]);\n\tif (err) {\n\t\tdev_err(dev, \"mmap error (len 0x%08llx)\\n\", buf->size);\n\t\tgoto err_invoke;\n\t}\n\n\t \n\tbuf->raddr = (uintptr_t) rsp_msg.vaddr;\n\n\t \n\treq.vaddrout = rsp_msg.vaddr;\n\n\t \n\tif (req.flags == ADSP_MMAP_REMOTE_HEAP_ADDR && fl->cctx->vmcount) {\n\t\terr = qcom_scm_assign_mem(buf->phys, (u64)buf->size,\n\t\t\t&fl->cctx->perms, fl->cctx->vmperms, fl->cctx->vmcount);\n\t\tif (err) {\n\t\t\tdev_err(fl->sctx->dev, \"Failed to assign memory phys 0x%llx size 0x%llx err %d\",\n\t\t\t\t\tbuf->phys, buf->size, err);\n\t\t\tgoto err_assign;\n\t\t}\n\t}\n\n\tspin_lock(&fl->lock);\n\tlist_add_tail(&buf->node, &fl->mmaps);\n\tspin_unlock(&fl->lock);\n\n\tif (copy_to_user((void __user *)argp, &req, sizeof(req))) {\n\t\terr = -EFAULT;\n\t\tgoto err_assign;\n\t}\n\n\tdev_dbg(dev, \"mmap\\t\\tpt 0x%09lx OK [len 0x%08llx]\\n\",\n\t\tbuf->raddr, buf->size);\n\n\treturn 0;\n\nerr_assign:\n\tfastrpc_req_munmap_impl(fl, buf);\nerr_invoke:\n\tfastrpc_buf_free(buf);\n\n\treturn err;\n}\n\nstatic int fastrpc_req_mem_unmap_impl(struct fastrpc_user *fl, struct fastrpc_mem_unmap *req)\n{\n\tstruct fastrpc_invoke_args args[1] = { [0] = { 0 } };\n\tstruct fastrpc_map *map = NULL, *iter, *m;\n\tstruct fastrpc_mem_unmap_req_msg req_msg = { 0 };\n\tint err = 0;\n\tu32 sc;\n\tstruct device *dev = fl->sctx->dev;\n\n\tspin_lock(&fl->lock);\n\tlist_for_each_entry_safe(iter, m, &fl->maps, node) {\n\t\tif ((req->fd < 0 || iter->fd == req->fd) && (iter->raddr == req->vaddr)) {\n\t\t\tmap = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tspin_unlock(&fl->lock);\n\n\tif (!map) {\n\t\tdev_err(dev, \"map not in list\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treq_msg.pgid = fl->tgid;\n\treq_msg.len = map->len;\n\treq_msg.vaddrin = map->raddr;\n\treq_msg.fd = map->fd;\n\n\targs[0].ptr = (u64) (uintptr_t) &req_msg;\n\targs[0].length = sizeof(req_msg);\n\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_MEM_UNMAP, 1, 0);\n\terr = fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE, sc,\n\t\t\t\t      &args[0]);\n\tif (err) {\n\t\tdev_err(dev, \"unmmap\\tpt fd = %d, 0x%09llx error\\n\",  map->fd, map->raddr);\n\t\treturn err;\n\t}\n\tfastrpc_map_put(map);\n\n\treturn 0;\n}\n\nstatic int fastrpc_req_mem_unmap(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_mem_unmap req;\n\n\tif (copy_from_user(&req, argp, sizeof(req)))\n\t\treturn -EFAULT;\n\n\treturn fastrpc_req_mem_unmap_impl(fl, &req);\n}\n\nstatic int fastrpc_req_mem_map(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_invoke_args args[4] = { [0 ... 3] = { 0 } };\n\tstruct fastrpc_mem_map_req_msg req_msg = { 0 };\n\tstruct fastrpc_mmap_rsp_msg rsp_msg = { 0 };\n\tstruct fastrpc_mem_unmap req_unmap = { 0 };\n\tstruct fastrpc_phy_page pages = { 0 };\n\tstruct fastrpc_mem_map req;\n\tstruct device *dev = fl->sctx->dev;\n\tstruct fastrpc_map *map = NULL;\n\tint err;\n\tu32 sc;\n\n\tif (copy_from_user(&req, argp, sizeof(req)))\n\t\treturn -EFAULT;\n\n\t \n\terr = fastrpc_map_create(fl, req.fd, req.length, 0, &map);\n\tif (err) {\n\t\tdev_err(dev, \"failed to map buffer, fd = %d\\n\", req.fd);\n\t\treturn err;\n\t}\n\n\treq_msg.pgid = fl->tgid;\n\treq_msg.fd = req.fd;\n\treq_msg.offset = req.offset;\n\treq_msg.vaddrin = req.vaddrin;\n\tmap->va = (void *) (uintptr_t) req.vaddrin;\n\treq_msg.flags = req.flags;\n\treq_msg.num = sizeof(pages);\n\treq_msg.data_len = 0;\n\n\targs[0].ptr = (u64) (uintptr_t) &req_msg;\n\targs[0].length = sizeof(req_msg);\n\n\tpages.addr = map->phys;\n\tpages.size = map->size;\n\n\targs[1].ptr = (u64) (uintptr_t) &pages;\n\targs[1].length = sizeof(pages);\n\n\targs[2].ptr = (u64) (uintptr_t) &pages;\n\targs[2].length = 0;\n\n\targs[3].ptr = (u64) (uintptr_t) &rsp_msg;\n\targs[3].length = sizeof(rsp_msg);\n\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_MEM_MAP, 3, 1);\n\terr = fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE, sc, &args[0]);\n\tif (err) {\n\t\tdev_err(dev, \"mem mmap error, fd %d, vaddr %llx, size %lld\\n\",\n\t\t\treq.fd, req.vaddrin, map->size);\n\t\tgoto err_invoke;\n\t}\n\n\t \n\tmap->raddr = rsp_msg.vaddr;\n\n\t \n\treq.vaddrout = rsp_msg.vaddr;\n\n\tif (copy_to_user((void __user *)argp, &req, sizeof(req))) {\n\t\t \n\t\treq_unmap.vaddr = (uintptr_t) rsp_msg.vaddr;\n\t\treq_unmap.length = map->size;\n\t\tfastrpc_req_mem_unmap_impl(fl, &req_unmap);\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n\nerr_invoke:\n\tfastrpc_map_put(map);\n\n\treturn err;\n}\n\nstatic long fastrpc_device_ioctl(struct file *file, unsigned int cmd,\n\t\t\t\t unsigned long arg)\n{\n\tstruct fastrpc_user *fl = (struct fastrpc_user *)file->private_data;\n\tchar __user *argp = (char __user *)arg;\n\tint err;\n\n\tswitch (cmd) {\n\tcase FASTRPC_IOCTL_INVOKE:\n\t\terr = fastrpc_invoke(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_INIT_ATTACH:\n\t\terr = fastrpc_init_attach(fl, ROOT_PD);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_INIT_ATTACH_SNS:\n\t\terr = fastrpc_init_attach(fl, SENSORS_PD);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_INIT_CREATE_STATIC:\n\t\terr = fastrpc_init_create_static_process(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_INIT_CREATE:\n\t\terr = fastrpc_init_create_process(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_ALLOC_DMA_BUFF:\n\t\terr = fastrpc_dmabuf_alloc(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_MMAP:\n\t\terr = fastrpc_req_mmap(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_MUNMAP:\n\t\terr = fastrpc_req_munmap(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_MEM_MAP:\n\t\terr = fastrpc_req_mem_map(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_MEM_UNMAP:\n\t\terr = fastrpc_req_mem_unmap(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_GET_DSP_INFO:\n\t\terr = fastrpc_get_dsp_info(fl, argp);\n\t\tbreak;\n\tdefault:\n\t\terr = -ENOTTY;\n\t\tbreak;\n\t}\n\n\treturn err;\n}\n\nstatic const struct file_operations fastrpc_fops = {\n\t.open = fastrpc_device_open,\n\t.release = fastrpc_device_release,\n\t.unlocked_ioctl = fastrpc_device_ioctl,\n\t.compat_ioctl = fastrpc_device_ioctl,\n};\n\nstatic int fastrpc_cb_probe(struct platform_device *pdev)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_session_ctx *sess;\n\tstruct device *dev = &pdev->dev;\n\tint i, sessions = 0;\n\tunsigned long flags;\n\tint rc;\n\n\tcctx = dev_get_drvdata(dev->parent);\n\tif (!cctx)\n\t\treturn -EINVAL;\n\n\tof_property_read_u32(dev->of_node, \"qcom,nsessions\", &sessions);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tif (cctx->sesscount >= FASTRPC_MAX_SESSIONS) {\n\t\tdev_err(&pdev->dev, \"too many sessions\\n\");\n\t\tspin_unlock_irqrestore(&cctx->lock, flags);\n\t\treturn -ENOSPC;\n\t}\n\tsess = &cctx->session[cctx->sesscount++];\n\tsess->used = false;\n\tsess->valid = true;\n\tsess->dev = dev;\n\tdev_set_drvdata(dev, sess);\n\n\tif (of_property_read_u32(dev->of_node, \"reg\", &sess->sid))\n\t\tdev_info(dev, \"FastRPC Session ID not specified in DT\\n\");\n\n\tif (sessions > 0) {\n\t\tstruct fastrpc_session_ctx *dup_sess;\n\n\t\tfor (i = 1; i < sessions; i++) {\n\t\t\tif (cctx->sesscount >= FASTRPC_MAX_SESSIONS)\n\t\t\t\tbreak;\n\t\t\tdup_sess = &cctx->session[cctx->sesscount++];\n\t\t\tmemcpy(dup_sess, sess, sizeof(*dup_sess));\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\trc = dma_set_mask(dev, DMA_BIT_MASK(32));\n\tif (rc) {\n\t\tdev_err(dev, \"32-bit DMA enable failed\\n\");\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int fastrpc_cb_remove(struct platform_device *pdev)\n{\n\tstruct fastrpc_channel_ctx *cctx = dev_get_drvdata(pdev->dev.parent);\n\tstruct fastrpc_session_ctx *sess = dev_get_drvdata(&pdev->dev);\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tfor (i = 1; i < FASTRPC_MAX_SESSIONS; i++) {\n\t\tif (cctx->session[i].sid == sess->sid) {\n\t\t\tcctx->session[i].valid = false;\n\t\t\tcctx->sesscount--;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id fastrpc_match_table[] = {\n\t{ .compatible = \"qcom,fastrpc-compute-cb\", },\n\t{}\n};\n\nstatic struct platform_driver fastrpc_cb_driver = {\n\t.probe = fastrpc_cb_probe,\n\t.remove = fastrpc_cb_remove,\n\t.driver = {\n\t\t.name = \"qcom,fastrpc-cb\",\n\t\t.of_match_table = fastrpc_match_table,\n\t\t.suppress_bind_attrs = true,\n\t},\n};\n\nstatic int fastrpc_device_register(struct device *dev, struct fastrpc_channel_ctx *cctx,\n\t\t\t\t   bool is_secured, const char *domain)\n{\n\tstruct fastrpc_device *fdev;\n\tint err;\n\n\tfdev = devm_kzalloc(dev, sizeof(*fdev), GFP_KERNEL);\n\tif (!fdev)\n\t\treturn -ENOMEM;\n\n\tfdev->secure = is_secured;\n\tfdev->cctx = cctx;\n\tfdev->miscdev.minor = MISC_DYNAMIC_MINOR;\n\tfdev->miscdev.fops = &fastrpc_fops;\n\tfdev->miscdev.name = devm_kasprintf(dev, GFP_KERNEL, \"fastrpc-%s%s\",\n\t\t\t\t\t    domain, is_secured ? \"-secure\" : \"\");\n\tif (!fdev->miscdev.name)\n\t\treturn -ENOMEM;\n\n\terr = misc_register(&fdev->miscdev);\n\tif (!err) {\n\t\tif (is_secured)\n\t\t\tcctx->secure_fdevice = fdev;\n\t\telse\n\t\t\tcctx->fdevice = fdev;\n\t}\n\n\treturn err;\n}\n\nstatic int fastrpc_rpmsg_probe(struct rpmsg_device *rpdev)\n{\n\tstruct device *rdev = &rpdev->dev;\n\tstruct fastrpc_channel_ctx *data;\n\tint i, err, domain_id = -1, vmcount;\n\tconst char *domain;\n\tbool secure_dsp;\n\tunsigned int vmids[FASTRPC_MAX_VMIDS];\n\n\terr = of_property_read_string(rdev->of_node, \"label\", &domain);\n\tif (err) {\n\t\tdev_info(rdev, \"FastRPC Domain not specified in DT\\n\");\n\t\treturn err;\n\t}\n\n\tfor (i = 0; i <= CDSP_DOMAIN_ID; i++) {\n\t\tif (!strcmp(domains[i], domain)) {\n\t\t\tdomain_id = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (domain_id < 0) {\n\t\tdev_info(rdev, \"FastRPC Invalid Domain ID %d\\n\", domain_id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (of_reserved_mem_device_init_by_idx(rdev, rdev->of_node, 0))\n\t\tdev_info(rdev, \"no reserved DMA memory for FASTRPC\\n\");\n\n\tvmcount = of_property_read_variable_u32_array(rdev->of_node,\n\t\t\t\t\"qcom,vmids\", &vmids[0], 0, FASTRPC_MAX_VMIDS);\n\tif (vmcount < 0)\n\t\tvmcount = 0;\n\telse if (!qcom_scm_is_available())\n\t\treturn -EPROBE_DEFER;\n\n\tdata = kzalloc(sizeof(*data), GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tif (vmcount) {\n\t\tdata->vmcount = vmcount;\n\t\tdata->perms = BIT(QCOM_SCM_VMID_HLOS);\n\t\tfor (i = 0; i < data->vmcount; i++) {\n\t\t\tdata->vmperms[i].vmid = vmids[i];\n\t\t\tdata->vmperms[i].perm = QCOM_SCM_PERM_RWX;\n\t\t}\n\t}\n\n\tsecure_dsp = !(of_property_read_bool(rdev->of_node, \"qcom,non-secure-domain\"));\n\tdata->secure = secure_dsp;\n\n\tswitch (domain_id) {\n\tcase ADSP_DOMAIN_ID:\n\tcase MDSP_DOMAIN_ID:\n\tcase SDSP_DOMAIN_ID:\n\t\t \n\t\tdata->unsigned_support = false;\n\t\terr = fastrpc_device_register(rdev, data, secure_dsp, domains[domain_id]);\n\t\tif (err)\n\t\t\tgoto fdev_error;\n\t\tbreak;\n\tcase CDSP_DOMAIN_ID:\n\t\tdata->unsigned_support = true;\n\t\t \n\t\terr = fastrpc_device_register(rdev, data, true, domains[domain_id]);\n\t\tif (err)\n\t\t\tgoto fdev_error;\n\n\t\terr = fastrpc_device_register(rdev, data, false, domains[domain_id]);\n\t\tif (err)\n\t\t\tgoto fdev_error;\n\t\tbreak;\n\tdefault:\n\t\terr = -EINVAL;\n\t\tgoto fdev_error;\n\t}\n\n\tkref_init(&data->refcount);\n\n\tdev_set_drvdata(&rpdev->dev, data);\n\trdev->dma_mask = &data->dma_mask;\n\tdma_set_mask_and_coherent(rdev, DMA_BIT_MASK(32));\n\tINIT_LIST_HEAD(&data->users);\n\tINIT_LIST_HEAD(&data->invoke_interrupted_mmaps);\n\tspin_lock_init(&data->lock);\n\tidr_init(&data->ctx_idr);\n\tdata->domain_id = domain_id;\n\tdata->rpdev = rpdev;\n\n\terr = of_platform_populate(rdev->of_node, NULL, NULL, rdev);\n\tif (err)\n\t\tgoto populate_error;\n\n\treturn 0;\n\npopulate_error:\n\tif (data->fdevice)\n\t\tmisc_deregister(&data->fdevice->miscdev);\n\tif (data->secure_fdevice)\n\t\tmisc_deregister(&data->secure_fdevice->miscdev);\n\nfdev_error:\n\tkfree(data);\n\treturn err;\n}\n\nstatic void fastrpc_notify_users(struct fastrpc_user *user)\n{\n\tstruct fastrpc_invoke_ctx *ctx;\n\n\tspin_lock(&user->lock);\n\tlist_for_each_entry(ctx, &user->pending, node) {\n\t\tctx->retval = -EPIPE;\n\t\tcomplete(&ctx->work);\n\t}\n\tspin_unlock(&user->lock);\n}\n\nstatic void fastrpc_rpmsg_remove(struct rpmsg_device *rpdev)\n{\n\tstruct fastrpc_channel_ctx *cctx = dev_get_drvdata(&rpdev->dev);\n\tstruct fastrpc_buf *buf, *b;\n\tstruct fastrpc_user *user;\n\tunsigned long flags;\n\n\t \n\tspin_lock_irqsave(&cctx->lock, flags);\n\tcctx->rpdev = NULL;\n\tlist_for_each_entry(user, &cctx->users, user)\n\t\tfastrpc_notify_users(user);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tif (cctx->fdevice)\n\t\tmisc_deregister(&cctx->fdevice->miscdev);\n\n\tif (cctx->secure_fdevice)\n\t\tmisc_deregister(&cctx->secure_fdevice->miscdev);\n\n\tlist_for_each_entry_safe(buf, b, &cctx->invoke_interrupted_mmaps, node)\n\t\tlist_del(&buf->node);\n\n\tif (cctx->remote_heap)\n\t\tfastrpc_buf_free(cctx->remote_heap);\n\n\tof_platform_depopulate(&rpdev->dev);\n\n\tfastrpc_channel_ctx_put(cctx);\n}\n\nstatic int fastrpc_rpmsg_callback(struct rpmsg_device *rpdev, void *data,\n\t\t\t\t  int len, void *priv, u32 addr)\n{\n\tstruct fastrpc_channel_ctx *cctx = dev_get_drvdata(&rpdev->dev);\n\tstruct fastrpc_invoke_rsp *rsp = data;\n\tstruct fastrpc_invoke_ctx *ctx;\n\tunsigned long flags;\n\tunsigned long ctxid;\n\n\tif (len < sizeof(*rsp))\n\t\treturn -EINVAL;\n\n\tctxid = ((rsp->ctx & FASTRPC_CTXID_MASK) >> 4);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tctx = idr_find(&cctx->ctx_idr, ctxid);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tif (!ctx) {\n\t\tdev_err(&rpdev->dev, \"No context ID matches response\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\tctx->retval = rsp->retval;\n\tcomplete(&ctx->work);\n\n\t \n\tschedule_work(&ctx->put_work);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id fastrpc_rpmsg_of_match[] = {\n\t{ .compatible = \"qcom,fastrpc\" },\n\t{ },\n};\nMODULE_DEVICE_TABLE(of, fastrpc_rpmsg_of_match);\n\nstatic struct rpmsg_driver fastrpc_driver = {\n\t.probe = fastrpc_rpmsg_probe,\n\t.remove = fastrpc_rpmsg_remove,\n\t.callback = fastrpc_rpmsg_callback,\n\t.drv = {\n\t\t.name = \"qcom,fastrpc\",\n\t\t.of_match_table = fastrpc_rpmsg_of_match,\n\t},\n};\n\nstatic int fastrpc_init(void)\n{\n\tint ret;\n\n\tret = platform_driver_register(&fastrpc_cb_driver);\n\tif (ret < 0) {\n\t\tpr_err(\"fastrpc: failed to register cb driver\\n\");\n\t\treturn ret;\n\t}\n\n\tret = register_rpmsg_driver(&fastrpc_driver);\n\tif (ret < 0) {\n\t\tpr_err(\"fastrpc: failed to register rpmsg driver\\n\");\n\t\tplatform_driver_unregister(&fastrpc_cb_driver);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nmodule_init(fastrpc_init);\n\nstatic void fastrpc_exit(void)\n{\n\tplatform_driver_unregister(&fastrpc_cb_driver);\n\tunregister_rpmsg_driver(&fastrpc_driver);\n}\nmodule_exit(fastrpc_exit);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_IMPORT_NS(DMA_BUF);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}