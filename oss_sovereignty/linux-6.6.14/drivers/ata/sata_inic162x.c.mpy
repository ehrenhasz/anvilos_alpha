{
  "module_name": "sata_inic162x.c",
  "hash_id": "e43d6c65c650b0052a92462555be69408a19c57758b474b4a7e9abb0b7b669f6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/ata/sata_inic162x.c",
  "human_readable_source": "\n \n\n#include <linux/gfp.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <scsi/scsi_host.h>\n#include <linux/libata.h>\n#include <linux/blkdev.h>\n#include <scsi/scsi_device.h>\n\n#define DRV_NAME\t\"sata_inic162x\"\n#define DRV_VERSION\t\"0.4\"\n\nenum {\n\tMMIO_BAR_PCI\t\t= 5,\n\tMMIO_BAR_CARDBUS\t= 1,\n\n\tNR_PORTS\t\t= 2,\n\n\tIDMA_CPB_TBL_SIZE\t= 4 * 32,\n\n\tINIC_DMA_BOUNDARY\t= 0xffffff,\n\n\tHOST_ACTRL\t\t= 0x08,\n\tHOST_CTL\t\t= 0x7c,\n\tHOST_STAT\t\t= 0x7e,\n\tHOST_IRQ_STAT\t\t= 0xbc,\n\tHOST_IRQ_MASK\t\t= 0xbe,\n\n\tPORT_SIZE\t\t= 0x40,\n\n\t \n\tPORT_TF_DATA\t\t= 0x00,\n\tPORT_TF_FEATURE\t\t= 0x01,\n\tPORT_TF_NSECT\t\t= 0x02,\n\tPORT_TF_LBAL\t\t= 0x03,\n\tPORT_TF_LBAM\t\t= 0x04,\n\tPORT_TF_LBAH\t\t= 0x05,\n\tPORT_TF_DEVICE\t\t= 0x06,\n\tPORT_TF_COMMAND\t\t= 0x07,\n\tPORT_TF_ALT_STAT\t= 0x08,\n\tPORT_IRQ_STAT\t\t= 0x09,\n\tPORT_IRQ_MASK\t\t= 0x0a,\n\tPORT_PRD_CTL\t\t= 0x0b,\n\tPORT_PRD_ADDR\t\t= 0x0c,\n\tPORT_PRD_XFERLEN\t= 0x10,\n\tPORT_CPB_CPBLAR\t\t= 0x18,\n\tPORT_CPB_PTQFIFO\t= 0x1c,\n\n\t \n\tPORT_IDMA_CTL\t\t= 0x14,\n\tPORT_IDMA_STAT\t\t= 0x16,\n\n\tPORT_RPQ_FIFO\t\t= 0x1e,\n\tPORT_RPQ_CNT\t\t= 0x1f,\n\n\tPORT_SCR\t\t= 0x20,\n\n\t \n\tHCTL_LEDEN\t\t= (1 << 3),   \n\tHCTL_IRQOFF\t\t= (1 << 8),   \n\tHCTL_FTHD0\t\t= (1 << 10),  \n\tHCTL_FTHD1\t\t= (1 << 11),  \n\tHCTL_PWRDWN\t\t= (1 << 12),  \n\tHCTL_SOFTRST\t\t= (1 << 13),  \n\tHCTL_RPGSEL\t\t= (1 << 15),  \n\n\tHCTL_KNOWN_BITS\t\t= HCTL_IRQOFF | HCTL_PWRDWN | HCTL_SOFTRST |\n\t\t\t\t  HCTL_RPGSEL,\n\n\t \n\tHIRQ_PORT0\t\t= (1 << 0),\n\tHIRQ_PORT1\t\t= (1 << 1),\n\tHIRQ_SOFT\t\t= (1 << 14),\n\tHIRQ_GLOBAL\t\t= (1 << 15),  \n\n\t \n\tPIRQ_OFFLINE\t\t= (1 << 0),   \n\tPIRQ_ONLINE\t\t= (1 << 1),   \n\tPIRQ_COMPLETE\t\t= (1 << 2),   \n\tPIRQ_FATAL\t\t= (1 << 3),   \n\tPIRQ_ATA\t\t= (1 << 4),   \n\tPIRQ_REPLY\t\t= (1 << 5),   \n\tPIRQ_PENDING\t\t= (1 << 7),   \n\n\tPIRQ_ERR\t\t= PIRQ_OFFLINE | PIRQ_ONLINE | PIRQ_FATAL,\n\tPIRQ_MASK_DEFAULT\t= PIRQ_REPLY | PIRQ_ATA,\n\tPIRQ_MASK_FREEZE\t= 0xff,\n\n\t \n\tPRD_CTL_START\t\t= (1 << 0),\n\tPRD_CTL_WR\t\t= (1 << 3),\n\tPRD_CTL_DMAEN\t\t= (1 << 7),   \n\n\t \n\tIDMA_CTL_RST_ATA\t= (1 << 2),   \n\tIDMA_CTL_RST_IDMA\t= (1 << 5),   \n\tIDMA_CTL_GO\t\t= (1 << 7),   \n\tIDMA_CTL_ATA_NIEN\t= (1 << 8),   \n\n\t \n\tIDMA_STAT_PERR\t\t= (1 << 0),   \n\tIDMA_STAT_CPBERR\t= (1 << 1),   \n\tIDMA_STAT_LGCY\t\t= (1 << 3),   \n\tIDMA_STAT_UIRQ\t\t= (1 << 4),   \n\tIDMA_STAT_STPD\t\t= (1 << 5),   \n\tIDMA_STAT_PSD\t\t= (1 << 6),   \n\tIDMA_STAT_DONE\t\t= (1 << 7),   \n\n\tIDMA_STAT_ERR\t\t= IDMA_STAT_PERR | IDMA_STAT_CPBERR,\n\n\t \n\tCPB_CTL_VALID\t\t= (1 << 0),   \n\tCPB_CTL_QUEUED\t\t= (1 << 1),   \n\tCPB_CTL_DATA\t\t= (1 << 2),   \n\tCPB_CTL_IEN\t\t= (1 << 3),   \n\tCPB_CTL_DEVDIR\t\t= (1 << 4),   \n\n\t \n\tCPB_RESP_DONE\t\t= (1 << 0),   \n\tCPB_RESP_REL\t\t= (1 << 1),   \n\tCPB_RESP_IGNORED\t= (1 << 2),   \n\tCPB_RESP_ATA_ERR\t= (1 << 3),   \n\tCPB_RESP_SPURIOUS\t= (1 << 4),   \n\tCPB_RESP_UNDERFLOW\t= (1 << 5),   \n\tCPB_RESP_OVERFLOW\t= (1 << 6),   \n\tCPB_RESP_CPB_ERR\t= (1 << 7),   \n\n\t \n\tPRD_DRAIN\t\t= (1 << 1),   \n\tPRD_CDB\t\t\t= (1 << 2),   \n\tPRD_DIRECT_INTR\t\t= (1 << 3),   \n\tPRD_DMA\t\t\t= (1 << 4),   \n\tPRD_WRITE\t\t= (1 << 5),   \n\tPRD_IOM\t\t\t= (1 << 6),   \n\tPRD_END\t\t\t= (1 << 7),   \n};\n\n \nstruct inic_cpb {\n\tu8\t\tresp_flags;\t \n\tu8\t\terror;\t\t \n\tu8\t\tstatus;\t\t \n\tu8\t\tctl_flags;\t \n\t__le32\t\tlen;\t\t \n\t__le32\t\tprd;\t\t \n\tu8\t\trsvd[4];\n\t \n\tu8\t\tfeature;\t \n\tu8\t\thob_feature;\t \n\tu8\t\tdevice;\t\t \n\tu8\t\tmirctl;\t\t \n\tu8\t\tnsect;\t\t \n\tu8\t\thob_nsect;\t \n\tu8\t\tlbal;\t\t \n\tu8\t\thob_lbal;\t \n\tu8\t\tlbam;\t\t \n\tu8\t\thob_lbam;\t \n\tu8\t\tlbah;\t\t \n\tu8\t\thob_lbah;\t \n\tu8\t\tcommand;\t \n\tu8\t\tctl;\t\t \n\tu8\t\tslave_error;\t \n\tu8\t\tslave_status;\t \n\t \n} __packed;\n\n \nstruct inic_prd {\n\t__le32\t\tmad;\t\t \n\t__le16\t\tlen;\t\t \n\tu8\t\trsvd;\n\tu8\t\tflags;\t\t \n} __packed;\n\nstruct inic_pkt {\n\tstruct inic_cpb\tcpb;\n\tstruct inic_prd\tprd[LIBATA_MAX_PRD + 1];\t \n\tu8\t\tcdb[ATAPI_CDB_LEN];\n} __packed;\n\nstruct inic_host_priv {\n\tvoid __iomem\t*mmio_base;\n\tu16\t\tcached_hctl;\n};\n\nstruct inic_port_priv {\n\tstruct inic_pkt\t*pkt;\n\tdma_addr_t\tpkt_dma;\n\tu32\t\t*cpb_tbl;\n\tdma_addr_t\tcpb_tbl_dma;\n};\n\nstatic const struct scsi_host_template inic_sht = {\n\tATA_BASE_SHT(DRV_NAME),\n\t.sg_tablesize\t\t= LIBATA_MAX_PRD,  \n\n\t \n\t.dma_boundary\t\t= INIC_DMA_BOUNDARY,\n\t.max_segment_size\t= 65536 - 512,\n};\n\nstatic const int scr_map[] = {\n\t[SCR_STATUS]\t= 0,\n\t[SCR_ERROR]\t= 1,\n\t[SCR_CONTROL]\t= 2,\n};\n\nstatic void __iomem *inic_port_base(struct ata_port *ap)\n{\n\tstruct inic_host_priv *hpriv = ap->host->private_data;\n\n\treturn hpriv->mmio_base + ap->port_no * PORT_SIZE;\n}\n\nstatic void inic_reset_port(void __iomem *port_base)\n{\n\tvoid __iomem *idma_ctl = port_base + PORT_IDMA_CTL;\n\n\t \n\treadw(idma_ctl);  \n\tmsleep(1);\n\n\t \n\twritew(IDMA_CTL_RST_IDMA, idma_ctl);\n\treadw(idma_ctl);  \n\tmsleep(1);\n\n\t \n\twritew(0, idma_ctl);\n\n\t \n\twriteb(0xff, port_base + PORT_IRQ_STAT);\n}\n\nstatic int inic_scr_read(struct ata_link *link, unsigned sc_reg, u32 *val)\n{\n\tvoid __iomem *scr_addr = inic_port_base(link->ap) + PORT_SCR;\n\n\tif (unlikely(sc_reg >= ARRAY_SIZE(scr_map)))\n\t\treturn -EINVAL;\n\n\t*val = readl(scr_addr + scr_map[sc_reg] * 4);\n\n\t \n\tif (sc_reg == SCR_ERROR)\n\t\t*val &= ~SERR_PHYRDY_CHG;\n\treturn 0;\n}\n\nstatic int inic_scr_write(struct ata_link *link, unsigned sc_reg, u32 val)\n{\n\tvoid __iomem *scr_addr = inic_port_base(link->ap) + PORT_SCR;\n\n\tif (unlikely(sc_reg >= ARRAY_SIZE(scr_map)))\n\t\treturn -EINVAL;\n\n\twritel(val, scr_addr + scr_map[sc_reg] * 4);\n\treturn 0;\n}\n\nstatic void inic_stop_idma(struct ata_port *ap)\n{\n\tvoid __iomem *port_base = inic_port_base(ap);\n\n\treadb(port_base + PORT_RPQ_FIFO);\n\treadb(port_base + PORT_RPQ_CNT);\n\twritew(0, port_base + PORT_IDMA_CTL);\n}\n\nstatic void inic_host_err_intr(struct ata_port *ap, u8 irq_stat, u16 idma_stat)\n{\n\tstruct ata_eh_info *ehi = &ap->link.eh_info;\n\tstruct inic_port_priv *pp = ap->private_data;\n\tstruct inic_cpb *cpb = &pp->pkt->cpb;\n\tbool freeze = false;\n\n\tata_ehi_clear_desc(ehi);\n\tata_ehi_push_desc(ehi, \"irq_stat=0x%x idma_stat=0x%x\",\n\t\t\t  irq_stat, idma_stat);\n\n\tinic_stop_idma(ap);\n\n\tif (irq_stat & (PIRQ_OFFLINE | PIRQ_ONLINE)) {\n\t\tata_ehi_push_desc(ehi, \"hotplug\");\n\t\tata_ehi_hotplugged(ehi);\n\t\tfreeze = true;\n\t}\n\n\tif (idma_stat & IDMA_STAT_PERR) {\n\t\tata_ehi_push_desc(ehi, \"PCI error\");\n\t\tfreeze = true;\n\t}\n\n\tif (idma_stat & IDMA_STAT_CPBERR) {\n\t\tata_ehi_push_desc(ehi, \"CPB error\");\n\n\t\tif (cpb->resp_flags & CPB_RESP_IGNORED) {\n\t\t\t__ata_ehi_push_desc(ehi, \" ignored\");\n\t\t\tehi->err_mask |= AC_ERR_INVALID;\n\t\t\tfreeze = true;\n\t\t}\n\n\t\tif (cpb->resp_flags & CPB_RESP_ATA_ERR)\n\t\t\tehi->err_mask |= AC_ERR_DEV;\n\n\t\tif (cpb->resp_flags & CPB_RESP_SPURIOUS) {\n\t\t\t__ata_ehi_push_desc(ehi, \" spurious-intr\");\n\t\t\tehi->err_mask |= AC_ERR_HSM;\n\t\t\tfreeze = true;\n\t\t}\n\n\t\tif (cpb->resp_flags &\n\t\t    (CPB_RESP_UNDERFLOW | CPB_RESP_OVERFLOW)) {\n\t\t\t__ata_ehi_push_desc(ehi, \" data-over/underflow\");\n\t\t\tehi->err_mask |= AC_ERR_HSM;\n\t\t\tfreeze = true;\n\t\t}\n\t}\n\n\tif (freeze)\n\t\tata_port_freeze(ap);\n\telse\n\t\tata_port_abort(ap);\n}\n\nstatic void inic_host_intr(struct ata_port *ap)\n{\n\tvoid __iomem *port_base = inic_port_base(ap);\n\tstruct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->link.active_tag);\n\tu8 irq_stat;\n\tu16 idma_stat;\n\n\t \n\tirq_stat = readb(port_base + PORT_IRQ_STAT);\n\twriteb(irq_stat, port_base + PORT_IRQ_STAT);\n\tidma_stat = readw(port_base + PORT_IDMA_STAT);\n\n\tif (unlikely((irq_stat & PIRQ_ERR) || (idma_stat & IDMA_STAT_ERR)))\n\t\tinic_host_err_intr(ap, irq_stat, idma_stat);\n\n\tif (unlikely(!qc))\n\t\tgoto spurious;\n\n\tif (likely(idma_stat & IDMA_STAT_DONE)) {\n\t\tinic_stop_idma(ap);\n\n\t\t \n\t\tif (unlikely(readb(port_base + PORT_TF_COMMAND) &\n\t\t\t     (ATA_DF | ATA_ERR)))\n\t\t\tqc->err_mask |= AC_ERR_DEV;\n\n\t\tata_qc_complete(qc);\n\t\treturn;\n\t}\n\n spurious:\n\tata_port_warn(ap, \"unhandled interrupt: cmd=0x%x irq_stat=0x%x idma_stat=0x%x\\n\",\n\t\t      qc ? qc->tf.command : 0xff, irq_stat, idma_stat);\n}\n\nstatic irqreturn_t inic_interrupt(int irq, void *dev_instance)\n{\n\tstruct ata_host *host = dev_instance;\n\tstruct inic_host_priv *hpriv = host->private_data;\n\tu16 host_irq_stat;\n\tint i, handled = 0;\n\n\thost_irq_stat = readw(hpriv->mmio_base + HOST_IRQ_STAT);\n\n\tif (unlikely(!(host_irq_stat & HIRQ_GLOBAL)))\n\t\tgoto out;\n\n\tspin_lock(&host->lock);\n\n\tfor (i = 0; i < NR_PORTS; i++)\n\t\tif (host_irq_stat & (HIRQ_PORT0 << i)) {\n\t\t\tinic_host_intr(host->ports[i]);\n\t\t\thandled++;\n\t\t}\n\n\tspin_unlock(&host->lock);\n\n out:\n\treturn IRQ_RETVAL(handled);\n}\n\nstatic int inic_check_atapi_dma(struct ata_queued_cmd *qc)\n{\n\t \n\tif (atapi_cmd_type(qc->cdb[0]) == READ)\n\t\treturn 0;\n\treturn 1;\n}\n\nstatic void inic_fill_sg(struct inic_prd *prd, struct ata_queued_cmd *qc)\n{\n\tstruct scatterlist *sg;\n\tunsigned int si;\n\tu8 flags = 0;\n\n\tif (qc->tf.flags & ATA_TFLAG_WRITE)\n\t\tflags |= PRD_WRITE;\n\n\tif (ata_is_dma(qc->tf.protocol))\n\t\tflags |= PRD_DMA;\n\n\tfor_each_sg(qc->sg, sg, qc->n_elem, si) {\n\t\tprd->mad = cpu_to_le32(sg_dma_address(sg));\n\t\tprd->len = cpu_to_le16(sg_dma_len(sg));\n\t\tprd->flags = flags;\n\t\tprd++;\n\t}\n\n\tWARN_ON(!si);\n\tprd[-1].flags |= PRD_END;\n}\n\nstatic enum ata_completion_errors inic_qc_prep(struct ata_queued_cmd *qc)\n{\n\tstruct inic_port_priv *pp = qc->ap->private_data;\n\tstruct inic_pkt *pkt = pp->pkt;\n\tstruct inic_cpb *cpb = &pkt->cpb;\n\tstruct inic_prd *prd = pkt->prd;\n\tbool is_atapi = ata_is_atapi(qc->tf.protocol);\n\tbool is_data = ata_is_data(qc->tf.protocol);\n\tunsigned int cdb_len = 0;\n\n\tif (is_atapi)\n\t\tcdb_len = qc->dev->cdb_len;\n\n\t \n\tmemset(pkt, 0, sizeof(struct inic_pkt));\n\n\tcpb->ctl_flags = CPB_CTL_VALID | CPB_CTL_IEN;\n\tif (is_atapi || is_data)\n\t\tcpb->ctl_flags |= CPB_CTL_DATA;\n\n\tcpb->len = cpu_to_le32(qc->nbytes + cdb_len);\n\tcpb->prd = cpu_to_le32(pp->pkt_dma + offsetof(struct inic_pkt, prd));\n\n\tcpb->device = qc->tf.device;\n\tcpb->feature = qc->tf.feature;\n\tcpb->nsect = qc->tf.nsect;\n\tcpb->lbal = qc->tf.lbal;\n\tcpb->lbam = qc->tf.lbam;\n\tcpb->lbah = qc->tf.lbah;\n\n\tif (qc->tf.flags & ATA_TFLAG_LBA48) {\n\t\tcpb->hob_feature = qc->tf.hob_feature;\n\t\tcpb->hob_nsect = qc->tf.hob_nsect;\n\t\tcpb->hob_lbal = qc->tf.hob_lbal;\n\t\tcpb->hob_lbam = qc->tf.hob_lbam;\n\t\tcpb->hob_lbah = qc->tf.hob_lbah;\n\t}\n\n\tcpb->command = qc->tf.command;\n\t \n\n\t \n\tif (is_atapi) {\n\t\tmemcpy(pkt->cdb, qc->cdb, ATAPI_CDB_LEN);\n\t\tprd->mad = cpu_to_le32(pp->pkt_dma +\n\t\t\t\t       offsetof(struct inic_pkt, cdb));\n\t\tprd->len = cpu_to_le16(cdb_len);\n\t\tprd->flags = PRD_CDB | PRD_WRITE;\n\t\tif (!is_data)\n\t\t\tprd->flags |= PRD_END;\n\t\tprd++;\n\t}\n\n\t \n\tif (is_data)\n\t\tinic_fill_sg(prd, qc);\n\n\tpp->cpb_tbl[0] = pp->pkt_dma;\n\n\treturn AC_ERR_OK;\n}\n\nstatic unsigned int inic_qc_issue(struct ata_queued_cmd *qc)\n{\n\tstruct ata_port *ap = qc->ap;\n\tvoid __iomem *port_base = inic_port_base(ap);\n\n\t \n\twritew(HCTL_FTHD0 | HCTL_LEDEN, port_base + HOST_CTL);\n\twritew(IDMA_CTL_GO, port_base + PORT_IDMA_CTL);\n\twriteb(0, port_base + PORT_CPB_PTQFIFO);\n\n\treturn 0;\n}\n\nstatic void inic_tf_read(struct ata_port *ap, struct ata_taskfile *tf)\n{\n\tvoid __iomem *port_base = inic_port_base(ap);\n\n\ttf->error\t= readb(port_base + PORT_TF_FEATURE);\n\ttf->nsect\t= readb(port_base + PORT_TF_NSECT);\n\ttf->lbal\t= readb(port_base + PORT_TF_LBAL);\n\ttf->lbam\t= readb(port_base + PORT_TF_LBAM);\n\ttf->lbah\t= readb(port_base + PORT_TF_LBAH);\n\ttf->device\t= readb(port_base + PORT_TF_DEVICE);\n\ttf->status\t= readb(port_base + PORT_TF_COMMAND);\n}\n\nstatic void inic_qc_fill_rtf(struct ata_queued_cmd *qc)\n{\n\tstruct ata_taskfile *rtf = &qc->result_tf;\n\tstruct ata_taskfile tf;\n\n\t \n\tinic_tf_read(qc->ap, &tf);\n\n\tif (tf.status & ATA_ERR) {\n\t\trtf->status = tf.status;\n\t\trtf->error = tf.error;\n\t}\n}\n\nstatic void inic_freeze(struct ata_port *ap)\n{\n\tvoid __iomem *port_base = inic_port_base(ap);\n\n\twriteb(PIRQ_MASK_FREEZE, port_base + PORT_IRQ_MASK);\n\twriteb(0xff, port_base + PORT_IRQ_STAT);\n}\n\nstatic void inic_thaw(struct ata_port *ap)\n{\n\tvoid __iomem *port_base = inic_port_base(ap);\n\n\twriteb(0xff, port_base + PORT_IRQ_STAT);\n\twriteb(PIRQ_MASK_DEFAULT, port_base + PORT_IRQ_MASK);\n}\n\nstatic int inic_check_ready(struct ata_link *link)\n{\n\tvoid __iomem *port_base = inic_port_base(link->ap);\n\n\treturn ata_check_ready(readb(port_base + PORT_TF_COMMAND));\n}\n\n \nstatic int inic_hardreset(struct ata_link *link, unsigned int *class,\n\t\t\t  unsigned long deadline)\n{\n\tstruct ata_port *ap = link->ap;\n\tvoid __iomem *port_base = inic_port_base(ap);\n\tvoid __iomem *idma_ctl = port_base + PORT_IDMA_CTL;\n\tconst unsigned int *timing = sata_ehc_deb_timing(&link->eh_context);\n\tint rc;\n\n\t \n\tinic_reset_port(port_base);\n\n\twritew(IDMA_CTL_RST_ATA, idma_ctl);\n\treadw(idma_ctl);\t \n\tata_msleep(ap, 1);\n\twritew(0, idma_ctl);\n\n\trc = sata_link_resume(link, timing, deadline);\n\tif (rc) {\n\t\tata_link_warn(link,\n\t\t\t      \"failed to resume link after reset (errno=%d)\\n\",\n\t\t\t      rc);\n\t\treturn rc;\n\t}\n\n\t*class = ATA_DEV_NONE;\n\tif (ata_link_online(link)) {\n\t\tstruct ata_taskfile tf;\n\n\t\t \n\t\trc = ata_wait_after_reset(link, deadline, inic_check_ready);\n\t\t \n\t\tif (rc) {\n\t\t\tata_link_warn(link,\n\t\t\t\t      \"device not ready after hardreset (errno=%d)\\n\",\n\t\t\t\t      rc);\n\t\t\treturn rc;\n\t\t}\n\n\t\tinic_tf_read(ap, &tf);\n\t\t*class = ata_port_classify(ap, &tf);\n\t}\n\n\treturn 0;\n}\n\nstatic void inic_error_handler(struct ata_port *ap)\n{\n\tvoid __iomem *port_base = inic_port_base(ap);\n\n\tinic_reset_port(port_base);\n\tata_std_error_handler(ap);\n}\n\nstatic void inic_post_internal_cmd(struct ata_queued_cmd *qc)\n{\n\t \n\tif (qc->flags & ATA_QCFLAG_EH)\n\t\tinic_reset_port(inic_port_base(qc->ap));\n}\n\nstatic void init_port(struct ata_port *ap)\n{\n\tvoid __iomem *port_base = inic_port_base(ap);\n\tstruct inic_port_priv *pp = ap->private_data;\n\n\t \n\tmemset(pp->pkt, 0, sizeof(struct inic_pkt));\n\tmemset(pp->cpb_tbl, 0, IDMA_CPB_TBL_SIZE);\n\n\t \n\twritel(pp->cpb_tbl_dma, port_base + PORT_CPB_CPBLAR);\n}\n\nstatic int inic_port_resume(struct ata_port *ap)\n{\n\tinit_port(ap);\n\treturn 0;\n}\n\nstatic int inic_port_start(struct ata_port *ap)\n{\n\tstruct device *dev = ap->host->dev;\n\tstruct inic_port_priv *pp;\n\n\t \n\tpp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);\n\tif (!pp)\n\t\treturn -ENOMEM;\n\tap->private_data = pp;\n\n\t \n\tpp->pkt = dmam_alloc_coherent(dev, sizeof(struct inic_pkt),\n\t\t\t\t      &pp->pkt_dma, GFP_KERNEL);\n\tif (!pp->pkt)\n\t\treturn -ENOMEM;\n\n\tpp->cpb_tbl = dmam_alloc_coherent(dev, IDMA_CPB_TBL_SIZE,\n\t\t\t\t\t  &pp->cpb_tbl_dma, GFP_KERNEL);\n\tif (!pp->cpb_tbl)\n\t\treturn -ENOMEM;\n\n\tinit_port(ap);\n\n\treturn 0;\n}\n\nstatic struct ata_port_operations inic_port_ops = {\n\t.inherits\t\t= &sata_port_ops,\n\n\t.check_atapi_dma\t= inic_check_atapi_dma,\n\t.qc_prep\t\t= inic_qc_prep,\n\t.qc_issue\t\t= inic_qc_issue,\n\t.qc_fill_rtf\t\t= inic_qc_fill_rtf,\n\n\t.freeze\t\t\t= inic_freeze,\n\t.thaw\t\t\t= inic_thaw,\n\t.hardreset\t\t= inic_hardreset,\n\t.error_handler\t\t= inic_error_handler,\n\t.post_internal_cmd\t= inic_post_internal_cmd,\n\n\t.scr_read\t\t= inic_scr_read,\n\t.scr_write\t\t= inic_scr_write,\n\n\t.port_resume\t\t= inic_port_resume,\n\t.port_start\t\t= inic_port_start,\n};\n\nstatic const struct ata_port_info inic_port_info = {\n\t.flags\t\t\t= ATA_FLAG_SATA | ATA_FLAG_PIO_DMA,\n\t.pio_mask\t\t= ATA_PIO4,\n\t.mwdma_mask\t\t= ATA_MWDMA2,\n\t.udma_mask\t\t= ATA_UDMA6,\n\t.port_ops\t\t= &inic_port_ops\n};\n\nstatic int init_controller(void __iomem *mmio_base, u16 hctl)\n{\n\tint i;\n\tu16 val;\n\n\thctl &= ~HCTL_KNOWN_BITS;\n\n\t \n\twritew(hctl | HCTL_SOFTRST, mmio_base + HOST_CTL);\n\treadw(mmio_base + HOST_CTL);  \n\n\tfor (i = 0; i < 10; i++) {\n\t\tmsleep(1);\n\t\tval = readw(mmio_base + HOST_CTL);\n\t\tif (!(val & HCTL_SOFTRST))\n\t\t\tbreak;\n\t}\n\n\tif (val & HCTL_SOFTRST)\n\t\treturn -EIO;\n\n\t \n\tfor (i = 0; i < NR_PORTS; i++) {\n\t\tvoid __iomem *port_base = mmio_base + i * PORT_SIZE;\n\n\t\twriteb(0xff, port_base + PORT_IRQ_MASK);\n\t\tinic_reset_port(port_base);\n\t}\n\n\t \n\twritew(hctl & ~HCTL_IRQOFF, mmio_base + HOST_CTL);\n\tval = readw(mmio_base + HOST_IRQ_MASK);\n\tval &= ~(HIRQ_PORT0 | HIRQ_PORT1);\n\twritew(val, mmio_base + HOST_IRQ_MASK);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int inic_pci_device_resume(struct pci_dev *pdev)\n{\n\tstruct ata_host *host = pci_get_drvdata(pdev);\n\tstruct inic_host_priv *hpriv = host->private_data;\n\tint rc;\n\n\trc = ata_pci_device_do_resume(pdev);\n\tif (rc)\n\t\treturn rc;\n\n\tif (pdev->dev.power.power_state.event == PM_EVENT_SUSPEND) {\n\t\trc = init_controller(hpriv->mmio_base, hpriv->cached_hctl);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tata_host_resume(host);\n\n\treturn 0;\n}\n#endif\n\nstatic int inic_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tconst struct ata_port_info *ppi[] = { &inic_port_info, NULL };\n\tstruct ata_host *host;\n\tstruct inic_host_priv *hpriv;\n\tvoid __iomem * const *iomap;\n\tint mmio_bar;\n\tint i, rc;\n\n\tata_print_version_once(&pdev->dev, DRV_VERSION);\n\n\tdev_alert(&pdev->dev, \"inic162x support is broken with common data corruption issues and will be disabled by default, contact linux-ide@vger.kernel.org if in production use\\n\");\n\n\t \n\thost = ata_host_alloc_pinfo(&pdev->dev, ppi, NR_PORTS);\n\thpriv = devm_kzalloc(&pdev->dev, sizeof(*hpriv), GFP_KERNEL);\n\tif (!host || !hpriv)\n\t\treturn -ENOMEM;\n\n\thost->private_data = hpriv;\n\n\t \n\trc = pcim_enable_device(pdev);\n\tif (rc)\n\t\treturn rc;\n\n\tif (pci_resource_flags(pdev, MMIO_BAR_PCI) & IORESOURCE_MEM)\n\t\tmmio_bar = MMIO_BAR_PCI;\n\telse\n\t\tmmio_bar = MMIO_BAR_CARDBUS;\n\n\trc = pcim_iomap_regions(pdev, 1 << mmio_bar, DRV_NAME);\n\tif (rc)\n\t\treturn rc;\n\thost->iomap = iomap = pcim_iomap_table(pdev);\n\thpriv->mmio_base = iomap[mmio_bar];\n\thpriv->cached_hctl = readw(hpriv->mmio_base + HOST_CTL);\n\n\tfor (i = 0; i < NR_PORTS; i++) {\n\t\tstruct ata_port *ap = host->ports[i];\n\n\t\tata_port_pbar_desc(ap, mmio_bar, -1, \"mmio\");\n\t\tata_port_pbar_desc(ap, mmio_bar, i * PORT_SIZE, \"port\");\n\t}\n\n\t \n\trc = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"32-bit DMA enable failed\\n\");\n\t\treturn rc;\n\t}\n\n\trc = init_controller(hpriv->mmio_base, hpriv->cached_hctl);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"failed to initialize controller\\n\");\n\t\treturn rc;\n\t}\n\n\tpci_set_master(pdev);\n\treturn ata_host_activate(host, pdev->irq, inic_interrupt, IRQF_SHARED,\n\t\t\t\t &inic_sht);\n}\n\nstatic const struct pci_device_id inic_pci_tbl[] = {\n\t{ PCI_VDEVICE(INIT, 0x1622), },\n\t{ },\n};\n\nstatic struct pci_driver inic_pci_driver = {\n\t.name \t\t= DRV_NAME,\n\t.id_table\t= inic_pci_tbl,\n#ifdef CONFIG_PM_SLEEP\n\t.suspend\t= ata_pci_device_suspend,\n\t.resume\t\t= inic_pci_device_resume,\n#endif\n\t.probe \t\t= inic_init_one,\n\t.remove\t\t= ata_pci_remove_one,\n};\n\nmodule_pci_driver(inic_pci_driver);\n\nMODULE_AUTHOR(\"Tejun Heo\");\nMODULE_DESCRIPTION(\"low-level driver for Initio 162x SATA\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DEVICE_TABLE(pci, inic_pci_tbl);\nMODULE_VERSION(DRV_VERSION);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}