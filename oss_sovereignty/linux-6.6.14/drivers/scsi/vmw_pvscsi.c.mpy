{
  "module_name": "vmw_pvscsi.c",
  "hash_id": "b2710417c6cbf46d0921e7dd363254433d7a47d8cd2d8a1cb0b3f0776e85d16b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/vmw_pvscsi.c",
  "human_readable_source": " \n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/pci.h>\n\n#include <scsi/scsi.h>\n#include <scsi/scsi_host.h>\n#include <scsi/scsi_cmnd.h>\n#include <scsi/scsi_device.h>\n#include <scsi/scsi_tcq.h>\n\n#include \"vmw_pvscsi.h\"\n\n#define PVSCSI_LINUX_DRIVER_DESC \"VMware PVSCSI driver\"\n\nMODULE_DESCRIPTION(PVSCSI_LINUX_DRIVER_DESC);\nMODULE_AUTHOR(\"VMware, Inc.\");\nMODULE_LICENSE(\"GPL\");\nMODULE_VERSION(PVSCSI_DRIVER_VERSION_STRING);\n\n#define PVSCSI_DEFAULT_NUM_PAGES_PER_RING\t8\n#define PVSCSI_DEFAULT_NUM_PAGES_MSG_RING\t1\n#define PVSCSI_DEFAULT_QUEUE_DEPTH\t\t254\n#define SGL_SIZE\t\t\t\tPAGE_SIZE\n\nstruct pvscsi_sg_list {\n\tstruct PVSCSISGElement sge[PVSCSI_MAX_NUM_SG_ENTRIES_PER_SEGMENT];\n};\n\nstruct pvscsi_ctx {\n\t \n\tstruct scsi_cmnd\t*cmd;\n\tstruct pvscsi_sg_list\t*sgl;\n\tstruct list_head\tlist;\n\tdma_addr_t\t\tdataPA;\n\tdma_addr_t\t\tsensePA;\n\tdma_addr_t\t\tsglPA;\n\tstruct completion\t*abort_cmp;\n};\n\nstruct pvscsi_adapter {\n\tchar\t\t\t\t*mmioBase;\n\tu8\t\t\t\trev;\n\tbool\t\t\t\tuse_msg;\n\tbool\t\t\t\tuse_req_threshold;\n\n\tspinlock_t\t\t\thw_lock;\n\n\tstruct workqueue_struct\t\t*workqueue;\n\tstruct work_struct\t\twork;\n\n\tstruct PVSCSIRingReqDesc\t*req_ring;\n\tunsigned\t\t\treq_pages;\n\tunsigned\t\t\treq_depth;\n\tdma_addr_t\t\t\treqRingPA;\n\n\tstruct PVSCSIRingCmpDesc\t*cmp_ring;\n\tunsigned\t\t\tcmp_pages;\n\tdma_addr_t\t\t\tcmpRingPA;\n\n\tstruct PVSCSIRingMsgDesc\t*msg_ring;\n\tunsigned\t\t\tmsg_pages;\n\tdma_addr_t\t\t\tmsgRingPA;\n\n\tstruct PVSCSIRingsState\t\t*rings_state;\n\tdma_addr_t\t\t\tringStatePA;\n\n\tstruct pci_dev\t\t\t*dev;\n\tstruct Scsi_Host\t\t*host;\n\n\tstruct list_head\t\tcmd_pool;\n\tstruct pvscsi_ctx\t\t*cmd_map;\n};\n\n\n \nstatic int pvscsi_ring_pages;\nstatic int pvscsi_msg_ring_pages = PVSCSI_DEFAULT_NUM_PAGES_MSG_RING;\nstatic int pvscsi_cmd_per_lun    = PVSCSI_DEFAULT_QUEUE_DEPTH;\nstatic bool pvscsi_disable_msi;\nstatic bool pvscsi_disable_msix;\nstatic bool pvscsi_use_msg       = true;\nstatic bool pvscsi_use_req_threshold = true;\n\n#define PVSCSI_RW (S_IRUSR | S_IWUSR)\n\nmodule_param_named(ring_pages, pvscsi_ring_pages, int, PVSCSI_RW);\nMODULE_PARM_DESC(ring_pages, \"Number of pages per req/cmp ring - (default=\"\n\t\t __stringify(PVSCSI_DEFAULT_NUM_PAGES_PER_RING)\n\t\t \"[up to 16 targets],\"\n\t\t __stringify(PVSCSI_SETUP_RINGS_MAX_NUM_PAGES)\n\t\t \"[for 16+ targets])\");\n\nmodule_param_named(msg_ring_pages, pvscsi_msg_ring_pages, int, PVSCSI_RW);\nMODULE_PARM_DESC(msg_ring_pages, \"Number of pages for the msg ring - (default=\"\n\t\t __stringify(PVSCSI_DEFAULT_NUM_PAGES_MSG_RING) \")\");\n\nmodule_param_named(cmd_per_lun, pvscsi_cmd_per_lun, int, PVSCSI_RW);\nMODULE_PARM_DESC(cmd_per_lun, \"Maximum commands per lun - (default=\"\n\t\t __stringify(PVSCSI_DEFAULT_QUEUE_DEPTH) \")\");\n\nmodule_param_named(disable_msi, pvscsi_disable_msi, bool, PVSCSI_RW);\nMODULE_PARM_DESC(disable_msi, \"Disable MSI use in driver - (default=0)\");\n\nmodule_param_named(disable_msix, pvscsi_disable_msix, bool, PVSCSI_RW);\nMODULE_PARM_DESC(disable_msix, \"Disable MSI-X use in driver - (default=0)\");\n\nmodule_param_named(use_msg, pvscsi_use_msg, bool, PVSCSI_RW);\nMODULE_PARM_DESC(use_msg, \"Use msg ring when available - (default=1)\");\n\nmodule_param_named(use_req_threshold, pvscsi_use_req_threshold,\n\t\t   bool, PVSCSI_RW);\nMODULE_PARM_DESC(use_req_threshold, \"Use driver-based request coalescing if configured - (default=1)\");\n\nstatic const struct pci_device_id pvscsi_pci_tbl[] = {\n\t{ PCI_VDEVICE(VMWARE, PCI_DEVICE_ID_VMWARE_PVSCSI) },\n\t{ 0 }\n};\n\nMODULE_DEVICE_TABLE(pci, pvscsi_pci_tbl);\n\nstatic struct device *\npvscsi_dev(const struct pvscsi_adapter *adapter)\n{\n\treturn &(adapter->dev->dev);\n}\n\nstatic struct pvscsi_ctx *\npvscsi_find_context(const struct pvscsi_adapter *adapter, struct scsi_cmnd *cmd)\n{\n\tstruct pvscsi_ctx *ctx, *end;\n\n\tend = &adapter->cmd_map[adapter->req_depth];\n\tfor (ctx = adapter->cmd_map; ctx < end; ctx++)\n\t\tif (ctx->cmd == cmd)\n\t\t\treturn ctx;\n\n\treturn NULL;\n}\n\nstatic struct pvscsi_ctx *\npvscsi_acquire_context(struct pvscsi_adapter *adapter, struct scsi_cmnd *cmd)\n{\n\tstruct pvscsi_ctx *ctx;\n\n\tif (list_empty(&adapter->cmd_pool))\n\t\treturn NULL;\n\n\tctx = list_first_entry(&adapter->cmd_pool, struct pvscsi_ctx, list);\n\tctx->cmd = cmd;\n\tlist_del(&ctx->list);\n\n\treturn ctx;\n}\n\nstatic void pvscsi_release_context(struct pvscsi_adapter *adapter,\n\t\t\t\t   struct pvscsi_ctx *ctx)\n{\n\tctx->cmd = NULL;\n\tctx->abort_cmp = NULL;\n\tlist_add(&ctx->list, &adapter->cmd_pool);\n}\n\n \nstatic u64 pvscsi_map_context(const struct pvscsi_adapter *adapter,\n\t\t\t      const struct pvscsi_ctx *ctx)\n{\n\treturn ctx - adapter->cmd_map + 1;\n}\n\nstatic struct pvscsi_ctx *\npvscsi_get_context(const struct pvscsi_adapter *adapter, u64 context)\n{\n\treturn &adapter->cmd_map[context - 1];\n}\n\nstatic void pvscsi_reg_write(const struct pvscsi_adapter *adapter,\n\t\t\t     u32 offset, u32 val)\n{\n\twritel(val, adapter->mmioBase + offset);\n}\n\nstatic u32 pvscsi_reg_read(const struct pvscsi_adapter *adapter, u32 offset)\n{\n\treturn readl(adapter->mmioBase + offset);\n}\n\nstatic u32 pvscsi_read_intr_status(const struct pvscsi_adapter *adapter)\n{\n\treturn pvscsi_reg_read(adapter, PVSCSI_REG_OFFSET_INTR_STATUS);\n}\n\nstatic void pvscsi_write_intr_status(const struct pvscsi_adapter *adapter,\n\t\t\t\t     u32 val)\n{\n\tpvscsi_reg_write(adapter, PVSCSI_REG_OFFSET_INTR_STATUS, val);\n}\n\nstatic void pvscsi_unmask_intr(const struct pvscsi_adapter *adapter)\n{\n\tu32 intr_bits;\n\n\tintr_bits = PVSCSI_INTR_CMPL_MASK;\n\tif (adapter->use_msg)\n\t\tintr_bits |= PVSCSI_INTR_MSG_MASK;\n\n\tpvscsi_reg_write(adapter, PVSCSI_REG_OFFSET_INTR_MASK, intr_bits);\n}\n\nstatic void pvscsi_mask_intr(const struct pvscsi_adapter *adapter)\n{\n\tpvscsi_reg_write(adapter, PVSCSI_REG_OFFSET_INTR_MASK, 0);\n}\n\nstatic void pvscsi_write_cmd_desc(const struct pvscsi_adapter *adapter,\n\t\t\t\t  u32 cmd, const void *desc, size_t len)\n{\n\tconst u32 *ptr = desc;\n\tsize_t i;\n\n\tlen /= sizeof(*ptr);\n\tpvscsi_reg_write(adapter, PVSCSI_REG_OFFSET_COMMAND, cmd);\n\tfor (i = 0; i < len; i++)\n\t\tpvscsi_reg_write(adapter,\n\t\t\t\t PVSCSI_REG_OFFSET_COMMAND_DATA, ptr[i]);\n}\n\nstatic void pvscsi_abort_cmd(const struct pvscsi_adapter *adapter,\n\t\t\t     const struct pvscsi_ctx *ctx)\n{\n\tstruct PVSCSICmdDescAbortCmd cmd = { 0 };\n\n\tcmd.target = ctx->cmd->device->id;\n\tcmd.context = pvscsi_map_context(adapter, ctx);\n\n\tpvscsi_write_cmd_desc(adapter, PVSCSI_CMD_ABORT_CMD, &cmd, sizeof(cmd));\n}\n\nstatic void pvscsi_kick_rw_io(const struct pvscsi_adapter *adapter)\n{\n\tpvscsi_reg_write(adapter, PVSCSI_REG_OFFSET_KICK_RW_IO, 0);\n}\n\nstatic void pvscsi_process_request_ring(const struct pvscsi_adapter *adapter)\n{\n\tpvscsi_reg_write(adapter, PVSCSI_REG_OFFSET_KICK_NON_RW_IO, 0);\n}\n\nstatic int scsi_is_rw(unsigned char op)\n{\n\treturn op == READ_6  || op == WRITE_6 ||\n\t       op == READ_10 || op == WRITE_10 ||\n\t       op == READ_12 || op == WRITE_12 ||\n\t       op == READ_16 || op == WRITE_16;\n}\n\nstatic void pvscsi_kick_io(const struct pvscsi_adapter *adapter,\n\t\t\t   unsigned char op)\n{\n\tif (scsi_is_rw(op)) {\n\t\tstruct PVSCSIRingsState *s = adapter->rings_state;\n\n\t\tif (!adapter->use_req_threshold ||\n\t\t    s->reqProdIdx - s->reqConsIdx >= s->reqCallThreshold)\n\t\t\tpvscsi_kick_rw_io(adapter);\n\t} else {\n\t\tpvscsi_process_request_ring(adapter);\n\t}\n}\n\nstatic void ll_adapter_reset(const struct pvscsi_adapter *adapter)\n{\n\tdev_dbg(pvscsi_dev(adapter), \"Adapter Reset on %p\\n\", adapter);\n\n\tpvscsi_write_cmd_desc(adapter, PVSCSI_CMD_ADAPTER_RESET, NULL, 0);\n}\n\nstatic void ll_bus_reset(const struct pvscsi_adapter *adapter)\n{\n\tdev_dbg(pvscsi_dev(adapter), \"Resetting bus on %p\\n\", adapter);\n\n\tpvscsi_write_cmd_desc(adapter, PVSCSI_CMD_RESET_BUS, NULL, 0);\n}\n\nstatic void ll_device_reset(const struct pvscsi_adapter *adapter, u32 target)\n{\n\tstruct PVSCSICmdDescResetDevice cmd = { 0 };\n\n\tdev_dbg(pvscsi_dev(adapter), \"Resetting device: target=%u\\n\", target);\n\n\tcmd.target = target;\n\n\tpvscsi_write_cmd_desc(adapter, PVSCSI_CMD_RESET_DEVICE,\n\t\t\t      &cmd, sizeof(cmd));\n}\n\nstatic void pvscsi_create_sg(struct pvscsi_ctx *ctx,\n\t\t\t     struct scatterlist *sg, unsigned count)\n{\n\tunsigned i;\n\tstruct PVSCSISGElement *sge;\n\n\tBUG_ON(count > PVSCSI_MAX_NUM_SG_ENTRIES_PER_SEGMENT);\n\n\tsge = &ctx->sgl->sge[0];\n\tfor (i = 0; i < count; i++, sg = sg_next(sg)) {\n\t\tsge[i].addr   = sg_dma_address(sg);\n\t\tsge[i].length = sg_dma_len(sg);\n\t\tsge[i].flags  = 0;\n\t}\n}\n\n \nstatic int pvscsi_map_buffers(struct pvscsi_adapter *adapter,\n\t\t\t      struct pvscsi_ctx *ctx, struct scsi_cmnd *cmd,\n\t\t\t      struct PVSCSIRingReqDesc *e)\n{\n\tunsigned count;\n\tunsigned bufflen = scsi_bufflen(cmd);\n\tstruct scatterlist *sg;\n\n\te->dataLen = bufflen;\n\te->dataAddr = 0;\n\tif (bufflen == 0)\n\t\treturn 0;\n\n\tsg = scsi_sglist(cmd);\n\tcount = scsi_sg_count(cmd);\n\tif (count != 0) {\n\t\tint segs = scsi_dma_map(cmd);\n\n\t\tif (segs == -ENOMEM) {\n\t\t\tscmd_printk(KERN_DEBUG, cmd,\n\t\t\t\t    \"vmw_pvscsi: Failed to map cmd sglist for DMA.\\n\");\n\t\t\treturn -ENOMEM;\n\t\t} else if (segs > 1) {\n\t\t\tpvscsi_create_sg(ctx, sg, segs);\n\n\t\t\te->flags |= PVSCSI_FLAG_CMD_WITH_SG_LIST;\n\t\t\tctx->sglPA = dma_map_single(&adapter->dev->dev,\n\t\t\t\t\tctx->sgl, SGL_SIZE, DMA_TO_DEVICE);\n\t\t\tif (dma_mapping_error(&adapter->dev->dev, ctx->sglPA)) {\n\t\t\t\tscmd_printk(KERN_ERR, cmd,\n\t\t\t\t\t    \"vmw_pvscsi: Failed to map ctx sglist for DMA.\\n\");\n\t\t\t\tscsi_dma_unmap(cmd);\n\t\t\t\tctx->sglPA = 0;\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\te->dataAddr = ctx->sglPA;\n\t\t} else\n\t\t\te->dataAddr = sg_dma_address(sg);\n\t} else {\n\t\t \n\t\tctx->dataPA = dma_map_single(&adapter->dev->dev, sg, bufflen,\n\t\t\t\t\t     cmd->sc_data_direction);\n\t\tif (dma_mapping_error(&adapter->dev->dev, ctx->dataPA)) {\n\t\t\tscmd_printk(KERN_DEBUG, cmd,\n\t\t\t\t    \"vmw_pvscsi: Failed to map direct data buffer for DMA.\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\te->dataAddr = ctx->dataPA;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void pvscsi_patch_sense(struct scsi_cmnd *cmd)\n{\n\tif (cmd->sense_buffer)\n\t\tcmd->sense_buffer[0] = 0;\n}\n\nstatic void pvscsi_unmap_buffers(const struct pvscsi_adapter *adapter,\n\t\t\t\t struct pvscsi_ctx *ctx)\n{\n\tstruct scsi_cmnd *cmd;\n\tunsigned bufflen;\n\n\tcmd = ctx->cmd;\n\tbufflen = scsi_bufflen(cmd);\n\n\tif (bufflen != 0) {\n\t\tunsigned count = scsi_sg_count(cmd);\n\n\t\tif (count != 0) {\n\t\t\tscsi_dma_unmap(cmd);\n\t\t\tif (ctx->sglPA) {\n\t\t\t\tdma_unmap_single(&adapter->dev->dev, ctx->sglPA,\n\t\t\t\t\t\t SGL_SIZE, DMA_TO_DEVICE);\n\t\t\t\tctx->sglPA = 0;\n\t\t\t}\n\t\t} else\n\t\t\tdma_unmap_single(&adapter->dev->dev, ctx->dataPA,\n\t\t\t\t\t bufflen, cmd->sc_data_direction);\n\t}\n\tif (cmd->sense_buffer)\n\t\tdma_unmap_single(&adapter->dev->dev, ctx->sensePA,\n\t\t\t\t SCSI_SENSE_BUFFERSIZE, DMA_FROM_DEVICE);\n}\n\nstatic int pvscsi_allocate_rings(struct pvscsi_adapter *adapter)\n{\n\tadapter->rings_state = dma_alloc_coherent(&adapter->dev->dev, PAGE_SIZE,\n\t\t\t&adapter->ringStatePA, GFP_KERNEL);\n\tif (!adapter->rings_state)\n\t\treturn -ENOMEM;\n\n\tadapter->req_pages = min(PVSCSI_MAX_NUM_PAGES_REQ_RING,\n\t\t\t\t pvscsi_ring_pages);\n\tadapter->req_depth = adapter->req_pages\n\t\t\t\t\t* PVSCSI_MAX_NUM_REQ_ENTRIES_PER_PAGE;\n\tadapter->req_ring = dma_alloc_coherent(&adapter->dev->dev,\n\t\t\tadapter->req_pages * PAGE_SIZE, &adapter->reqRingPA,\n\t\t\tGFP_KERNEL);\n\tif (!adapter->req_ring)\n\t\treturn -ENOMEM;\n\n\tadapter->cmp_pages = min(PVSCSI_MAX_NUM_PAGES_CMP_RING,\n\t\t\t\t pvscsi_ring_pages);\n\tadapter->cmp_ring = dma_alloc_coherent(&adapter->dev->dev,\n\t\t\tadapter->cmp_pages * PAGE_SIZE, &adapter->cmpRingPA,\n\t\t\tGFP_KERNEL);\n\tif (!adapter->cmp_ring)\n\t\treturn -ENOMEM;\n\n\tBUG_ON(!IS_ALIGNED(adapter->ringStatePA, PAGE_SIZE));\n\tBUG_ON(!IS_ALIGNED(adapter->reqRingPA, PAGE_SIZE));\n\tBUG_ON(!IS_ALIGNED(adapter->cmpRingPA, PAGE_SIZE));\n\n\tif (!adapter->use_msg)\n\t\treturn 0;\n\n\tadapter->msg_pages = min(PVSCSI_MAX_NUM_PAGES_MSG_RING,\n\t\t\t\t pvscsi_msg_ring_pages);\n\tadapter->msg_ring = dma_alloc_coherent(&adapter->dev->dev,\n\t\t\tadapter->msg_pages * PAGE_SIZE, &adapter->msgRingPA,\n\t\t\tGFP_KERNEL);\n\tif (!adapter->msg_ring)\n\t\treturn -ENOMEM;\n\tBUG_ON(!IS_ALIGNED(adapter->msgRingPA, PAGE_SIZE));\n\n\treturn 0;\n}\n\nstatic void pvscsi_setup_all_rings(const struct pvscsi_adapter *adapter)\n{\n\tstruct PVSCSICmdDescSetupRings cmd = { 0 };\n\tdma_addr_t base;\n\tunsigned i;\n\n\tcmd.ringsStatePPN   = adapter->ringStatePA >> PAGE_SHIFT;\n\tcmd.reqRingNumPages = adapter->req_pages;\n\tcmd.cmpRingNumPages = adapter->cmp_pages;\n\n\tbase = adapter->reqRingPA;\n\tfor (i = 0; i < adapter->req_pages; i++) {\n\t\tcmd.reqRingPPNs[i] = base >> PAGE_SHIFT;\n\t\tbase += PAGE_SIZE;\n\t}\n\n\tbase = adapter->cmpRingPA;\n\tfor (i = 0; i < adapter->cmp_pages; i++) {\n\t\tcmd.cmpRingPPNs[i] = base >> PAGE_SHIFT;\n\t\tbase += PAGE_SIZE;\n\t}\n\n\tmemset(adapter->rings_state, 0, PAGE_SIZE);\n\tmemset(adapter->req_ring, 0, adapter->req_pages * PAGE_SIZE);\n\tmemset(adapter->cmp_ring, 0, adapter->cmp_pages * PAGE_SIZE);\n\n\tpvscsi_write_cmd_desc(adapter, PVSCSI_CMD_SETUP_RINGS,\n\t\t\t      &cmd, sizeof(cmd));\n\n\tif (adapter->use_msg) {\n\t\tstruct PVSCSICmdDescSetupMsgRing cmd_msg = { 0 };\n\n\t\tcmd_msg.numPages = adapter->msg_pages;\n\n\t\tbase = adapter->msgRingPA;\n\t\tfor (i = 0; i < adapter->msg_pages; i++) {\n\t\t\tcmd_msg.ringPPNs[i] = base >> PAGE_SHIFT;\n\t\t\tbase += PAGE_SIZE;\n\t\t}\n\t\tmemset(adapter->msg_ring, 0, adapter->msg_pages * PAGE_SIZE);\n\n\t\tpvscsi_write_cmd_desc(adapter, PVSCSI_CMD_SETUP_MSG_RING,\n\t\t\t\t      &cmd_msg, sizeof(cmd_msg));\n\t}\n}\n\nstatic int pvscsi_change_queue_depth(struct scsi_device *sdev, int qdepth)\n{\n\tif (!sdev->tagged_supported)\n\t\tqdepth = 1;\n\treturn scsi_change_queue_depth(sdev, qdepth);\n}\n\n \nstatic void pvscsi_complete_request(struct pvscsi_adapter *adapter,\n\t\t\t\t    const struct PVSCSIRingCmpDesc *e)\n{\n\tstruct pvscsi_ctx *ctx;\n\tstruct scsi_cmnd *cmd;\n\tstruct completion *abort_cmp;\n\tu32 btstat = e->hostStatus;\n\tu32 sdstat = e->scsiStatus;\n\n\tctx = pvscsi_get_context(adapter, e->context);\n\tcmd = ctx->cmd;\n\tabort_cmp = ctx->abort_cmp;\n\tpvscsi_unmap_buffers(adapter, ctx);\n\tif (sdstat != SAM_STAT_CHECK_CONDITION)\n\t\tpvscsi_patch_sense(cmd);\n\tpvscsi_release_context(adapter, ctx);\n\tif (abort_cmp) {\n\t\t \n\t\tcomplete(abort_cmp);\n\t\treturn;\n\t}\n\n\tcmd->result = 0;\n\tif (sdstat != SAM_STAT_GOOD &&\n\t    (btstat == BTSTAT_SUCCESS ||\n\t     btstat == BTSTAT_LINKED_COMMAND_COMPLETED ||\n\t     btstat == BTSTAT_LINKED_COMMAND_COMPLETED_WITH_FLAG)) {\n\t\tif (sdstat == SAM_STAT_COMMAND_TERMINATED) {\n\t\t\tcmd->result = (DID_RESET << 16);\n\t\t} else {\n\t\t\tcmd->result = (DID_OK << 16) | sdstat;\n\t\t}\n\t} else\n\t\tswitch (btstat) {\n\t\tcase BTSTAT_SUCCESS:\n\t\tcase BTSTAT_LINKED_COMMAND_COMPLETED:\n\t\tcase BTSTAT_LINKED_COMMAND_COMPLETED_WITH_FLAG:\n\t\t\t \n\t\t\tif (e->dataLen && (e->dataLen < scsi_bufflen(cmd)))\n\t\t\t\tscsi_set_resid(cmd, scsi_bufflen(cmd) - e->dataLen);\n\t\t\tcmd->result = (DID_OK << 16);\n\t\t\tbreak;\n\n\t\tcase BTSTAT_DATARUN:\n\t\tcase BTSTAT_DATA_UNDERRUN:\n\t\t\t \n\t\t\tscsi_set_resid(cmd, scsi_bufflen(cmd) - e->dataLen);\n\t\t\tcmd->result = (DID_ERROR << 16);\n\t\t\tbreak;\n\n\t\tcase BTSTAT_SELTIMEO:\n\t\t\t \n\t\t\tcmd->result = (DID_BAD_TARGET << 16);\n\t\t\tbreak;\n\n\t\tcase BTSTAT_LUNMISMATCH:\n\t\tcase BTSTAT_TAGREJECT:\n\t\tcase BTSTAT_BADMSG:\n\t\tcase BTSTAT_HAHARDWARE:\n\t\tcase BTSTAT_INVPHASE:\n\t\tcase BTSTAT_HATIMEOUT:\n\t\tcase BTSTAT_NORESPONSE:\n\t\tcase BTSTAT_DISCONNECT:\n\t\tcase BTSTAT_HASOFTWARE:\n\t\tcase BTSTAT_BUSFREE:\n\t\tcase BTSTAT_SENSFAILED:\n\t\t\tcmd->result |= (DID_ERROR << 16);\n\t\t\tbreak;\n\n\t\tcase BTSTAT_SENTRST:\n\t\tcase BTSTAT_RECVRST:\n\t\tcase BTSTAT_BUSRESET:\n\t\t\tcmd->result = (DID_RESET << 16);\n\t\t\tbreak;\n\n\t\tcase BTSTAT_ABORTQUEUE:\n\t\t\tcmd->result = (DID_BUS_BUSY << 16);\n\t\t\tbreak;\n\n\t\tcase BTSTAT_SCSIPARITY:\n\t\t\tcmd->result = (DID_PARITY << 16);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tcmd->result = (DID_ERROR << 16);\n\t\t\tscmd_printk(KERN_DEBUG, cmd,\n\t\t\t\t    \"Unknown completion status: 0x%x\\n\",\n\t\t\t\t    btstat);\n\t}\n\n\tdev_dbg(&cmd->device->sdev_gendev,\n\t\t\"cmd=%p %x ctx=%p result=0x%x status=0x%x,%x\\n\",\n\t\tcmd, cmd->cmnd[0], ctx, cmd->result, btstat, sdstat);\n\n\tscsi_done(cmd);\n}\n\n \nstatic void pvscsi_process_completion_ring(struct pvscsi_adapter *adapter)\n{\n\tstruct PVSCSIRingsState *s = adapter->rings_state;\n\tstruct PVSCSIRingCmpDesc *ring = adapter->cmp_ring;\n\tu32 cmp_entries = s->cmpNumEntriesLog2;\n\n\twhile (s->cmpConsIdx != s->cmpProdIdx) {\n\t\tstruct PVSCSIRingCmpDesc *e = ring + (s->cmpConsIdx &\n\t\t\t\t\t\t      MASK(cmp_entries));\n\t\t \n\t\tbarrier();\n\t\tpvscsi_complete_request(adapter, e);\n\t\t \n\t\tbarrier();\n\t\ts->cmpConsIdx++;\n\t}\n}\n\n \nstatic int pvscsi_queue_ring(struct pvscsi_adapter *adapter,\n\t\t\t     struct pvscsi_ctx *ctx, struct scsi_cmnd *cmd)\n{\n\tstruct PVSCSIRingsState *s;\n\tstruct PVSCSIRingReqDesc *e;\n\tstruct scsi_device *sdev;\n\tu32 req_entries;\n\n\ts = adapter->rings_state;\n\tsdev = cmd->device;\n\treq_entries = s->reqNumEntriesLog2;\n\n\t \n\tif (s->reqProdIdx - s->cmpConsIdx >= 1 << req_entries) {\n\t\tscmd_printk(KERN_ERR, cmd, \"vmw_pvscsi: \"\n\t\t\t    \"ring full: reqProdIdx=%d cmpConsIdx=%d\\n\",\n\t\t\t    s->reqProdIdx, s->cmpConsIdx);\n\t\treturn -1;\n\t}\n\n\te = adapter->req_ring + (s->reqProdIdx & MASK(req_entries));\n\n\te->bus    = sdev->channel;\n\te->target = sdev->id;\n\tmemset(e->lun, 0, sizeof(e->lun));\n\te->lun[1] = sdev->lun;\n\n\tif (cmd->sense_buffer) {\n\t\tctx->sensePA = dma_map_single(&adapter->dev->dev,\n\t\t\t\tcmd->sense_buffer, SCSI_SENSE_BUFFERSIZE,\n\t\t\t\tDMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(&adapter->dev->dev, ctx->sensePA)) {\n\t\t\tscmd_printk(KERN_DEBUG, cmd,\n\t\t\t\t    \"vmw_pvscsi: Failed to map sense buffer for DMA.\\n\");\n\t\t\tctx->sensePA = 0;\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\te->senseAddr = ctx->sensePA;\n\t\te->senseLen = SCSI_SENSE_BUFFERSIZE;\n\t} else {\n\t\te->senseLen  = 0;\n\t\te->senseAddr = 0;\n\t}\n\te->cdbLen   = cmd->cmd_len;\n\te->vcpuHint = smp_processor_id();\n\tmemcpy(e->cdb, cmd->cmnd, e->cdbLen);\n\n\te->tag = SIMPLE_QUEUE_TAG;\n\n\tif (cmd->sc_data_direction == DMA_FROM_DEVICE)\n\t\te->flags = PVSCSI_FLAG_CMD_DIR_TOHOST;\n\telse if (cmd->sc_data_direction == DMA_TO_DEVICE)\n\t\te->flags = PVSCSI_FLAG_CMD_DIR_TODEVICE;\n\telse if (cmd->sc_data_direction == DMA_NONE)\n\t\te->flags = PVSCSI_FLAG_CMD_DIR_NONE;\n\telse\n\t\te->flags = 0;\n\n\tif (pvscsi_map_buffers(adapter, ctx, cmd, e) != 0) {\n\t\tif (cmd->sense_buffer) {\n\t\t\tdma_unmap_single(&adapter->dev->dev, ctx->sensePA,\n\t\t\t\t\t SCSI_SENSE_BUFFERSIZE,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tctx->sensePA = 0;\n\t\t}\n\t\treturn -ENOMEM;\n\t}\n\n\te->context = pvscsi_map_context(adapter, ctx);\n\n\tbarrier();\n\n\ts->reqProdIdx++;\n\n\treturn 0;\n}\n\nstatic int pvscsi_queue_lck(struct scsi_cmnd *cmd)\n{\n\tstruct Scsi_Host *host = cmd->device->host;\n\tstruct pvscsi_adapter *adapter = shost_priv(host);\n\tstruct pvscsi_ctx *ctx;\n\tunsigned long flags;\n\tunsigned char op;\n\n\tspin_lock_irqsave(&adapter->hw_lock, flags);\n\n\tctx = pvscsi_acquire_context(adapter, cmd);\n\tif (!ctx || pvscsi_queue_ring(adapter, ctx, cmd) != 0) {\n\t\tif (ctx)\n\t\t\tpvscsi_release_context(adapter, ctx);\n\t\tspin_unlock_irqrestore(&adapter->hw_lock, flags);\n\t\treturn SCSI_MLQUEUE_HOST_BUSY;\n\t}\n\n\top = cmd->cmnd[0];\n\n\tdev_dbg(&cmd->device->sdev_gendev,\n\t\t\"queued cmd %p, ctx %p, op=%x\\n\", cmd, ctx, op);\n\n\tspin_unlock_irqrestore(&adapter->hw_lock, flags);\n\n\tpvscsi_kick_io(adapter, op);\n\n\treturn 0;\n}\n\nstatic DEF_SCSI_QCMD(pvscsi_queue)\n\nstatic int pvscsi_abort(struct scsi_cmnd *cmd)\n{\n\tstruct pvscsi_adapter *adapter = shost_priv(cmd->device->host);\n\tstruct pvscsi_ctx *ctx;\n\tunsigned long flags;\n\tint result = SUCCESS;\n\tDECLARE_COMPLETION_ONSTACK(abort_cmp);\n\tint done;\n\n\tscmd_printk(KERN_DEBUG, cmd, \"task abort on host %u, %p\\n\",\n\t\t    adapter->host->host_no, cmd);\n\n\tspin_lock_irqsave(&adapter->hw_lock, flags);\n\n\t \n\tpvscsi_process_completion_ring(adapter);\n\n\t \n\tctx = pvscsi_find_context(adapter, cmd);\n\tif (!ctx) {\n\t\tscmd_printk(KERN_DEBUG, cmd, \"Failed to abort cmd %p\\n\", cmd);\n\t\tgoto out;\n\t}\n\n\t \n\tctx->abort_cmp = &abort_cmp;\n\n\tpvscsi_abort_cmd(adapter, ctx);\n\tspin_unlock_irqrestore(&adapter->hw_lock, flags);\n\t \n\tdone = wait_for_completion_timeout(&abort_cmp, msecs_to_jiffies(2000));\n\tspin_lock_irqsave(&adapter->hw_lock, flags);\n\n\tif (!done) {\n\t\t \n\t\tctx->abort_cmp = NULL;\n\t\tresult = FAILED;\n\t\tscmd_printk(KERN_DEBUG, cmd,\n\t\t\t    \"Failed to get completion for aborted cmd %p\\n\",\n\t\t\t    cmd);\n\t\tgoto out;\n\t}\n\n\t \n\tcmd->result = (DID_ABORT << 16);\n\tscsi_done(cmd);\n\nout:\n\tspin_unlock_irqrestore(&adapter->hw_lock, flags);\n\treturn result;\n}\n\n \nstatic void pvscsi_reset_all(struct pvscsi_adapter *adapter)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < adapter->req_depth; i++) {\n\t\tstruct pvscsi_ctx *ctx = &adapter->cmd_map[i];\n\t\tstruct scsi_cmnd *cmd = ctx->cmd;\n\t\tif (cmd) {\n\t\t\tscmd_printk(KERN_ERR, cmd,\n\t\t\t\t    \"Forced reset on cmd %p\\n\", cmd);\n\t\t\tpvscsi_unmap_buffers(adapter, ctx);\n\t\t\tpvscsi_patch_sense(cmd);\n\t\t\tpvscsi_release_context(adapter, ctx);\n\t\t\tcmd->result = (DID_RESET << 16);\n\t\t\tscsi_done(cmd);\n\t\t}\n\t}\n}\n\nstatic int pvscsi_host_reset(struct scsi_cmnd *cmd)\n{\n\tstruct Scsi_Host *host = cmd->device->host;\n\tstruct pvscsi_adapter *adapter = shost_priv(host);\n\tunsigned long flags;\n\tbool use_msg;\n\n\tscmd_printk(KERN_INFO, cmd, \"SCSI Host reset\\n\");\n\n\tspin_lock_irqsave(&adapter->hw_lock, flags);\n\n\tuse_msg = adapter->use_msg;\n\n\tif (use_msg) {\n\t\tadapter->use_msg = false;\n\t\tspin_unlock_irqrestore(&adapter->hw_lock, flags);\n\n\t\t \n\t\tflush_workqueue(adapter->workqueue);\n\t\tspin_lock_irqsave(&adapter->hw_lock, flags);\n\t}\n\n\t \n\n\tpvscsi_process_request_ring(adapter);\n\n\tll_adapter_reset(adapter);\n\n\t \n\tpvscsi_process_completion_ring(adapter);\n\n\tpvscsi_reset_all(adapter);\n\tadapter->use_msg = use_msg;\n\tpvscsi_setup_all_rings(adapter);\n\tpvscsi_unmask_intr(adapter);\n\n\tspin_unlock_irqrestore(&adapter->hw_lock, flags);\n\n\treturn SUCCESS;\n}\n\nstatic int pvscsi_bus_reset(struct scsi_cmnd *cmd)\n{\n\tstruct Scsi_Host *host = cmd->device->host;\n\tstruct pvscsi_adapter *adapter = shost_priv(host);\n\tunsigned long flags;\n\n\tscmd_printk(KERN_INFO, cmd, \"SCSI Bus reset\\n\");\n\n\t \n\tspin_lock_irqsave(&adapter->hw_lock, flags);\n\n\tpvscsi_process_request_ring(adapter);\n\tll_bus_reset(adapter);\n\tpvscsi_process_completion_ring(adapter);\n\n\tspin_unlock_irqrestore(&adapter->hw_lock, flags);\n\n\treturn SUCCESS;\n}\n\nstatic int pvscsi_device_reset(struct scsi_cmnd *cmd)\n{\n\tstruct Scsi_Host *host = cmd->device->host;\n\tstruct pvscsi_adapter *adapter = shost_priv(host);\n\tunsigned long flags;\n\n\tscmd_printk(KERN_INFO, cmd, \"SCSI device reset on scsi%u:%u\\n\",\n\t\t    host->host_no, cmd->device->id);\n\n\t \n\tspin_lock_irqsave(&adapter->hw_lock, flags);\n\n\tpvscsi_process_request_ring(adapter);\n\tll_device_reset(adapter, cmd->device->id);\n\tpvscsi_process_completion_ring(adapter);\n\n\tspin_unlock_irqrestore(&adapter->hw_lock, flags);\n\n\treturn SUCCESS;\n}\n\nstatic struct scsi_host_template pvscsi_template;\n\nstatic const char *pvscsi_info(struct Scsi_Host *host)\n{\n\tstruct pvscsi_adapter *adapter = shost_priv(host);\n\tstatic char buf[256];\n\n\tsprintf(buf, \"VMware PVSCSI storage adapter rev %d, req/cmp/msg rings: \"\n\t\t\"%u/%u/%u pages, cmd_per_lun=%u\", adapter->rev,\n\t\tadapter->req_pages, adapter->cmp_pages, adapter->msg_pages,\n\t\tpvscsi_template.cmd_per_lun);\n\n\treturn buf;\n}\n\nstatic struct scsi_host_template pvscsi_template = {\n\t.module\t\t\t\t= THIS_MODULE,\n\t.name\t\t\t\t= \"VMware PVSCSI Host Adapter\",\n\t.proc_name\t\t\t= \"vmw_pvscsi\",\n\t.info\t\t\t\t= pvscsi_info,\n\t.queuecommand\t\t\t= pvscsi_queue,\n\t.this_id\t\t\t= -1,\n\t.sg_tablesize\t\t\t= PVSCSI_MAX_NUM_SG_ENTRIES_PER_SEGMENT,\n\t.dma_boundary\t\t\t= UINT_MAX,\n\t.max_sectors\t\t\t= 0xffff,\n\t.change_queue_depth\t\t= pvscsi_change_queue_depth,\n\t.eh_abort_handler\t\t= pvscsi_abort,\n\t.eh_device_reset_handler\t= pvscsi_device_reset,\n\t.eh_bus_reset_handler\t\t= pvscsi_bus_reset,\n\t.eh_host_reset_handler\t\t= pvscsi_host_reset,\n};\n\nstatic void pvscsi_process_msg(const struct pvscsi_adapter *adapter,\n\t\t\t       const struct PVSCSIRingMsgDesc *e)\n{\n\tstruct PVSCSIRingsState *s = adapter->rings_state;\n\tstruct Scsi_Host *host = adapter->host;\n\tstruct scsi_device *sdev;\n\n\tprintk(KERN_INFO \"vmw_pvscsi: msg type: 0x%x - MSG RING: %u/%u (%u) \\n\",\n\t       e->type, s->msgProdIdx, s->msgConsIdx, s->msgNumEntriesLog2);\n\n\tBUILD_BUG_ON(PVSCSI_MSG_LAST != 2);\n\n\tif (e->type == PVSCSI_MSG_DEV_ADDED) {\n\t\tstruct PVSCSIMsgDescDevStatusChanged *desc;\n\t\tdesc = (struct PVSCSIMsgDescDevStatusChanged *)e;\n\n\t\tprintk(KERN_INFO\n\t\t       \"vmw_pvscsi: msg: device added at scsi%u:%u:%u\\n\",\n\t\t       desc->bus, desc->target, desc->lun[1]);\n\n\t\tif (!scsi_host_get(host))\n\t\t\treturn;\n\n\t\tsdev = scsi_device_lookup(host, desc->bus, desc->target,\n\t\t\t\t\t  desc->lun[1]);\n\t\tif (sdev) {\n\t\t\tprintk(KERN_INFO \"vmw_pvscsi: device already exists\\n\");\n\t\t\tscsi_device_put(sdev);\n\t\t} else\n\t\t\tscsi_add_device(adapter->host, desc->bus,\n\t\t\t\t\tdesc->target, desc->lun[1]);\n\n\t\tscsi_host_put(host);\n\t} else if (e->type == PVSCSI_MSG_DEV_REMOVED) {\n\t\tstruct PVSCSIMsgDescDevStatusChanged *desc;\n\t\tdesc = (struct PVSCSIMsgDescDevStatusChanged *)e;\n\n\t\tprintk(KERN_INFO\n\t\t       \"vmw_pvscsi: msg: device removed at scsi%u:%u:%u\\n\",\n\t\t       desc->bus, desc->target, desc->lun[1]);\n\n\t\tif (!scsi_host_get(host))\n\t\t\treturn;\n\n\t\tsdev = scsi_device_lookup(host, desc->bus, desc->target,\n\t\t\t\t\t  desc->lun[1]);\n\t\tif (sdev) {\n\t\t\tscsi_remove_device(sdev);\n\t\t\tscsi_device_put(sdev);\n\t\t} else\n\t\t\tprintk(KERN_INFO\n\t\t\t       \"vmw_pvscsi: failed to lookup scsi%u:%u:%u\\n\",\n\t\t\t       desc->bus, desc->target, desc->lun[1]);\n\n\t\tscsi_host_put(host);\n\t}\n}\n\nstatic int pvscsi_msg_pending(const struct pvscsi_adapter *adapter)\n{\n\tstruct PVSCSIRingsState *s = adapter->rings_state;\n\n\treturn s->msgProdIdx != s->msgConsIdx;\n}\n\nstatic void pvscsi_process_msg_ring(const struct pvscsi_adapter *adapter)\n{\n\tstruct PVSCSIRingsState *s = adapter->rings_state;\n\tstruct PVSCSIRingMsgDesc *ring = adapter->msg_ring;\n\tu32 msg_entries = s->msgNumEntriesLog2;\n\n\twhile (pvscsi_msg_pending(adapter)) {\n\t\tstruct PVSCSIRingMsgDesc *e = ring + (s->msgConsIdx &\n\t\t\t\t\t\t      MASK(msg_entries));\n\n\t\tbarrier();\n\t\tpvscsi_process_msg(adapter, e);\n\t\tbarrier();\n\t\ts->msgConsIdx++;\n\t}\n}\n\nstatic void pvscsi_msg_workqueue_handler(struct work_struct *data)\n{\n\tstruct pvscsi_adapter *adapter;\n\n\tadapter = container_of(data, struct pvscsi_adapter, work);\n\n\tpvscsi_process_msg_ring(adapter);\n}\n\nstatic int pvscsi_setup_msg_workqueue(struct pvscsi_adapter *adapter)\n{\n\tchar name[32];\n\n\tif (!pvscsi_use_msg)\n\t\treturn 0;\n\n\tpvscsi_reg_write(adapter, PVSCSI_REG_OFFSET_COMMAND,\n\t\t\t PVSCSI_CMD_SETUP_MSG_RING);\n\n\tif (pvscsi_reg_read(adapter, PVSCSI_REG_OFFSET_COMMAND_STATUS) == -1)\n\t\treturn 0;\n\n\tsnprintf(name, sizeof(name),\n\t\t \"vmw_pvscsi_wq_%u\", adapter->host->host_no);\n\n\tadapter->workqueue = create_singlethread_workqueue(name);\n\tif (!adapter->workqueue) {\n\t\tprintk(KERN_ERR \"vmw_pvscsi: failed to create work queue\\n\");\n\t\treturn 0;\n\t}\n\tINIT_WORK(&adapter->work, pvscsi_msg_workqueue_handler);\n\n\treturn 1;\n}\n\nstatic bool pvscsi_setup_req_threshold(struct pvscsi_adapter *adapter,\n\t\t\t\t      bool enable)\n{\n\tu32 val;\n\n\tif (!pvscsi_use_req_threshold)\n\t\treturn false;\n\n\tpvscsi_reg_write(adapter, PVSCSI_REG_OFFSET_COMMAND,\n\t\t\t PVSCSI_CMD_SETUP_REQCALLTHRESHOLD);\n\tval = pvscsi_reg_read(adapter, PVSCSI_REG_OFFSET_COMMAND_STATUS);\n\tif (val == -1) {\n\t\tprintk(KERN_INFO \"vmw_pvscsi: device does not support req_threshold\\n\");\n\t\treturn false;\n\t} else {\n\t\tstruct PVSCSICmdDescSetupReqCall cmd_msg = { 0 };\n\t\tcmd_msg.enable = enable;\n\t\tprintk(KERN_INFO\n\t\t       \"vmw_pvscsi: %sabling reqCallThreshold\\n\",\n\t\t\tenable ? \"en\" : \"dis\");\n\t\tpvscsi_write_cmd_desc(adapter,\n\t\t\t\t      PVSCSI_CMD_SETUP_REQCALLTHRESHOLD,\n\t\t\t\t      &cmd_msg, sizeof(cmd_msg));\n\t\treturn pvscsi_reg_read(adapter,\n\t\t\t\t       PVSCSI_REG_OFFSET_COMMAND_STATUS) != 0;\n\t}\n}\n\nstatic irqreturn_t pvscsi_isr(int irq, void *devp)\n{\n\tstruct pvscsi_adapter *adapter = devp;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&adapter->hw_lock, flags);\n\tpvscsi_process_completion_ring(adapter);\n\tif (adapter->use_msg && pvscsi_msg_pending(adapter))\n\t\tqueue_work(adapter->workqueue, &adapter->work);\n\tspin_unlock_irqrestore(&adapter->hw_lock, flags);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t pvscsi_shared_isr(int irq, void *devp)\n{\n\tstruct pvscsi_adapter *adapter = devp;\n\tu32 val = pvscsi_read_intr_status(adapter);\n\n\tif (!(val & PVSCSI_INTR_ALL_SUPPORTED))\n\t\treturn IRQ_NONE;\n\tpvscsi_write_intr_status(devp, val);\n\treturn pvscsi_isr(irq, devp);\n}\n\nstatic void pvscsi_free_sgls(const struct pvscsi_adapter *adapter)\n{\n\tstruct pvscsi_ctx *ctx = adapter->cmd_map;\n\tunsigned i;\n\n\tfor (i = 0; i < adapter->req_depth; ++i, ++ctx)\n\t\tfree_pages((unsigned long)ctx->sgl, get_order(SGL_SIZE));\n}\n\nstatic void pvscsi_shutdown_intr(struct pvscsi_adapter *adapter)\n{\n\tfree_irq(pci_irq_vector(adapter->dev, 0), adapter);\n\tpci_free_irq_vectors(adapter->dev);\n}\n\nstatic void pvscsi_release_resources(struct pvscsi_adapter *adapter)\n{\n\tif (adapter->workqueue)\n\t\tdestroy_workqueue(adapter->workqueue);\n\n\tif (adapter->mmioBase)\n\t\tpci_iounmap(adapter->dev, adapter->mmioBase);\n\n\tpci_release_regions(adapter->dev);\n\n\tif (adapter->cmd_map) {\n\t\tpvscsi_free_sgls(adapter);\n\t\tkfree(adapter->cmd_map);\n\t}\n\n\tif (adapter->rings_state)\n\t\tdma_free_coherent(&adapter->dev->dev, PAGE_SIZE,\n\t\t\t\t    adapter->rings_state, adapter->ringStatePA);\n\n\tif (adapter->req_ring)\n\t\tdma_free_coherent(&adapter->dev->dev,\n\t\t\t\t    adapter->req_pages * PAGE_SIZE,\n\t\t\t\t    adapter->req_ring, adapter->reqRingPA);\n\n\tif (adapter->cmp_ring)\n\t\tdma_free_coherent(&adapter->dev->dev,\n\t\t\t\t    adapter->cmp_pages * PAGE_SIZE,\n\t\t\t\t    adapter->cmp_ring, adapter->cmpRingPA);\n\n\tif (adapter->msg_ring)\n\t\tdma_free_coherent(&adapter->dev->dev,\n\t\t\t\t    adapter->msg_pages * PAGE_SIZE,\n\t\t\t\t    adapter->msg_ring, adapter->msgRingPA);\n}\n\n \nstatic int pvscsi_allocate_sg(struct pvscsi_adapter *adapter)\n{\n\tstruct pvscsi_ctx *ctx;\n\tint i;\n\n\tctx = adapter->cmd_map;\n\tBUILD_BUG_ON(sizeof(struct pvscsi_sg_list) > SGL_SIZE);\n\n\tfor (i = 0; i < adapter->req_depth; ++i, ++ctx) {\n\t\tctx->sgl = (void *)__get_free_pages(GFP_KERNEL,\n\t\t\t\t\t\t    get_order(SGL_SIZE));\n\t\tctx->sglPA = 0;\n\t\tBUG_ON(!IS_ALIGNED(((unsigned long)ctx->sgl), PAGE_SIZE));\n\t\tif (!ctx->sgl) {\n\t\t\tfor (; i >= 0; --i, --ctx) {\n\t\t\t\tfree_pages((unsigned long)ctx->sgl,\n\t\t\t\t\t   get_order(SGL_SIZE));\n\t\t\t\tctx->sgl = NULL;\n\t\t\t}\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic u32 pvscsi_get_max_targets(struct pvscsi_adapter *adapter)\n{\n\tstruct PVSCSICmdDescConfigCmd cmd;\n\tstruct PVSCSIConfigPageHeader *header;\n\tstruct device *dev;\n\tdma_addr_t configPagePA;\n\tvoid *config_page;\n\tu32 numPhys = 16;\n\n\tdev = pvscsi_dev(adapter);\n\tconfig_page = dma_alloc_coherent(&adapter->dev->dev, PAGE_SIZE,\n\t\t\t&configPagePA, GFP_KERNEL);\n\tif (!config_page) {\n\t\tdev_warn(dev, \"vmw_pvscsi: failed to allocate memory for config page\\n\");\n\t\tgoto exit;\n\t}\n\tBUG_ON(configPagePA & ~PAGE_MASK);\n\n\t \n\tcmd.configPageAddress = ((u64)PVSCSI_CONFIG_CONTROLLER_ADDRESS) << 32;\n\tcmd.configPageNum = PVSCSI_CONFIG_PAGE_CONTROLLER;\n\tcmd.cmpAddr = configPagePA;\n\tcmd._pad = 0;\n\n\t \n\theader = config_page;\n\theader->hostStatus = BTSTAT_INVPARAM;\n\theader->scsiStatus = SDSTAT_CHECK;\n\n\tpvscsi_write_cmd_desc(adapter, PVSCSI_CMD_CONFIG, &cmd, sizeof cmd);\n\n\tif (header->hostStatus == BTSTAT_SUCCESS &&\n\t    header->scsiStatus == SDSTAT_GOOD) {\n\t\tstruct PVSCSIConfigPageController *config;\n\n\t\tconfig = config_page;\n\t\tnumPhys = config->numPhys;\n\t} else\n\t\tdev_warn(dev, \"vmw_pvscsi: PVSCSI_CMD_CONFIG failed. hostStatus = 0x%x, scsiStatus = 0x%x\\n\",\n\t\t\t header->hostStatus, header->scsiStatus);\n\tdma_free_coherent(&adapter->dev->dev, PAGE_SIZE, config_page,\n\t\t\t  configPagePA);\nexit:\n\treturn numPhys;\n}\n\nstatic int pvscsi_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tunsigned int irq_flag = PCI_IRQ_MSIX | PCI_IRQ_MSI | PCI_IRQ_LEGACY;\n\tstruct pvscsi_adapter *adapter;\n\tstruct pvscsi_adapter adapter_temp;\n\tstruct Scsi_Host *host = NULL;\n\tunsigned int i;\n\tint error;\n\tu32 max_id;\n\n\terror = -ENODEV;\n\n\tif (pci_enable_device(pdev))\n\t\treturn error;\n\n\tif (!dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64))) {\n\t\tprintk(KERN_INFO \"vmw_pvscsi: using 64bit dma\\n\");\n\t} else if (!dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32))) {\n\t\tprintk(KERN_INFO \"vmw_pvscsi: using 32bit dma\\n\");\n\t} else {\n\t\tprintk(KERN_ERR \"vmw_pvscsi: failed to set DMA mask\\n\");\n\t\tgoto out_disable_device;\n\t}\n\n\t \n\tadapter = &adapter_temp;\n\tmemset(adapter, 0, sizeof(*adapter));\n\tadapter->dev  = pdev;\n\tadapter->rev = pdev->revision;\n\n\tif (pci_request_regions(pdev, \"vmw_pvscsi\")) {\n\t\tprintk(KERN_ERR \"vmw_pvscsi: pci memory selection failed\\n\");\n\t\tgoto out_disable_device;\n\t}\n\n\tfor (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {\n\t\tif ((pci_resource_flags(pdev, i) & PCI_BASE_ADDRESS_SPACE_IO))\n\t\t\tcontinue;\n\n\t\tif (pci_resource_len(pdev, i) < PVSCSI_MEM_SPACE_SIZE)\n\t\t\tcontinue;\n\n\t\tbreak;\n\t}\n\n\tif (i == DEVICE_COUNT_RESOURCE) {\n\t\tprintk(KERN_ERR\n\t\t       \"vmw_pvscsi: adapter has no suitable MMIO region\\n\");\n\t\tgoto out_release_resources_and_disable;\n\t}\n\n\tadapter->mmioBase = pci_iomap(pdev, i, PVSCSI_MEM_SPACE_SIZE);\n\n\tif (!adapter->mmioBase) {\n\t\tprintk(KERN_ERR\n\t\t       \"vmw_pvscsi: can't iomap for BAR %d memsize %lu\\n\",\n\t\t       i, PVSCSI_MEM_SPACE_SIZE);\n\t\tgoto out_release_resources_and_disable;\n\t}\n\n\tpci_set_master(pdev);\n\n\t \n\tmax_id = pvscsi_get_max_targets(adapter);\n\tprintk(KERN_INFO \"vmw_pvscsi: max_id: %u\\n\", max_id);\n\n\tif (pvscsi_ring_pages == 0)\n\t\t \n\t\tpvscsi_ring_pages = (max_id > 16) ?\n\t\t\tPVSCSI_SETUP_RINGS_MAX_NUM_PAGES :\n\t\t\tPVSCSI_DEFAULT_NUM_PAGES_PER_RING;\n\tprintk(KERN_INFO\n\t       \"vmw_pvscsi: setting ring_pages to %d\\n\",\n\t       pvscsi_ring_pages);\n\n\tpvscsi_template.can_queue =\n\t\tmin(PVSCSI_MAX_NUM_PAGES_REQ_RING, pvscsi_ring_pages) *\n\t\tPVSCSI_MAX_NUM_REQ_ENTRIES_PER_PAGE;\n\tpvscsi_template.cmd_per_lun =\n\t\tmin(pvscsi_template.can_queue, pvscsi_cmd_per_lun);\n\thost = scsi_host_alloc(&pvscsi_template, sizeof(struct pvscsi_adapter));\n\tif (!host) {\n\t\tprintk(KERN_ERR \"vmw_pvscsi: failed to allocate host\\n\");\n\t\tgoto out_release_resources_and_disable;\n\t}\n\n\t \n\tadapter = shost_priv(host);\n\tmemset(adapter, 0, sizeof(*adapter));\n\tadapter->dev  = pdev;\n\tadapter->host = host;\n\t \n\tadapter->rev = adapter_temp.rev;\n\tadapter->mmioBase = adapter_temp.mmioBase;\n\n\tspin_lock_init(&adapter->hw_lock);\n\thost->max_channel = 0;\n\thost->max_lun     = 1;\n\thost->max_cmd_len = 16;\n\thost->max_id      = max_id;\n\n\tpci_set_drvdata(pdev, host);\n\n\tll_adapter_reset(adapter);\n\n\tadapter->use_msg = pvscsi_setup_msg_workqueue(adapter);\n\n\terror = pvscsi_allocate_rings(adapter);\n\tif (error) {\n\t\tprintk(KERN_ERR \"vmw_pvscsi: unable to allocate ring memory\\n\");\n\t\tgoto out_release_resources;\n\t}\n\n\t \n\tpvscsi_setup_all_rings(adapter);\n\n\tadapter->cmd_map = kcalloc(adapter->req_depth,\n\t\t\t\t   sizeof(struct pvscsi_ctx), GFP_KERNEL);\n\tif (!adapter->cmd_map) {\n\t\tprintk(KERN_ERR \"vmw_pvscsi: failed to allocate memory.\\n\");\n\t\terror = -ENOMEM;\n\t\tgoto out_reset_adapter;\n\t}\n\n\tINIT_LIST_HEAD(&adapter->cmd_pool);\n\tfor (i = 0; i < adapter->req_depth; i++) {\n\t\tstruct pvscsi_ctx *ctx = adapter->cmd_map + i;\n\t\tlist_add(&ctx->list, &adapter->cmd_pool);\n\t}\n\n\terror = pvscsi_allocate_sg(adapter);\n\tif (error) {\n\t\tprintk(KERN_ERR \"vmw_pvscsi: unable to allocate s/g table\\n\");\n\t\tgoto out_reset_adapter;\n\t}\n\n\tif (pvscsi_disable_msix)\n\t\tirq_flag &= ~PCI_IRQ_MSIX;\n\tif (pvscsi_disable_msi)\n\t\tirq_flag &= ~PCI_IRQ_MSI;\n\n\terror = pci_alloc_irq_vectors(adapter->dev, 1, 1, irq_flag);\n\tif (error < 0)\n\t\tgoto out_reset_adapter;\n\n\tadapter->use_req_threshold = pvscsi_setup_req_threshold(adapter, true);\n\tprintk(KERN_DEBUG \"vmw_pvscsi: driver-based request coalescing %sabled\\n\",\n\t       adapter->use_req_threshold ? \"en\" : \"dis\");\n\n\tif (adapter->dev->msix_enabled || adapter->dev->msi_enabled) {\n\t\tprintk(KERN_INFO \"vmw_pvscsi: using MSI%s\\n\",\n\t\t\tadapter->dev->msix_enabled ? \"-X\" : \"\");\n\t\terror = request_irq(pci_irq_vector(pdev, 0), pvscsi_isr,\n\t\t\t\t0, \"vmw_pvscsi\", adapter);\n\t} else {\n\t\tprintk(KERN_INFO \"vmw_pvscsi: using INTx\\n\");\n\t\terror = request_irq(pci_irq_vector(pdev, 0), pvscsi_shared_isr,\n\t\t\t\tIRQF_SHARED, \"vmw_pvscsi\", adapter);\n\t}\n\n\tif (error) {\n\t\tprintk(KERN_ERR\n\t\t       \"vmw_pvscsi: unable to request IRQ: %d\\n\", error);\n\t\tgoto out_reset_adapter;\n\t}\n\n\terror = scsi_add_host(host, &pdev->dev);\n\tif (error) {\n\t\tprintk(KERN_ERR\n\t\t       \"vmw_pvscsi: scsi_add_host failed: %d\\n\", error);\n\t\tgoto out_reset_adapter;\n\t}\n\n\tdev_info(&pdev->dev, \"VMware PVSCSI rev %d host #%u\\n\",\n\t\t adapter->rev, host->host_no);\n\n\tpvscsi_unmask_intr(adapter);\n\n\tscsi_scan_host(host);\n\n\treturn 0;\n\nout_reset_adapter:\n\tll_adapter_reset(adapter);\nout_release_resources:\n\tpvscsi_shutdown_intr(adapter);\n\tpvscsi_release_resources(adapter);\n\tscsi_host_put(host);\nout_disable_device:\n\tpci_disable_device(pdev);\n\n\treturn error;\n\nout_release_resources_and_disable:\n\tpvscsi_shutdown_intr(adapter);\n\tpvscsi_release_resources(adapter);\n\tgoto out_disable_device;\n}\n\nstatic void __pvscsi_shutdown(struct pvscsi_adapter *adapter)\n{\n\tpvscsi_mask_intr(adapter);\n\n\tif (adapter->workqueue)\n\t\tflush_workqueue(adapter->workqueue);\n\n\tpvscsi_shutdown_intr(adapter);\n\n\tpvscsi_process_request_ring(adapter);\n\tpvscsi_process_completion_ring(adapter);\n\tll_adapter_reset(adapter);\n}\n\nstatic void pvscsi_shutdown(struct pci_dev *dev)\n{\n\tstruct Scsi_Host *host = pci_get_drvdata(dev);\n\tstruct pvscsi_adapter *adapter = shost_priv(host);\n\n\t__pvscsi_shutdown(adapter);\n}\n\nstatic void pvscsi_remove(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *host = pci_get_drvdata(pdev);\n\tstruct pvscsi_adapter *adapter = shost_priv(host);\n\n\tscsi_remove_host(host);\n\n\t__pvscsi_shutdown(adapter);\n\tpvscsi_release_resources(adapter);\n\n\tscsi_host_put(host);\n\n\tpci_disable_device(pdev);\n}\n\nstatic struct pci_driver pvscsi_pci_driver = {\n\t.name\t\t= \"vmw_pvscsi\",\n\t.id_table\t= pvscsi_pci_tbl,\n\t.probe\t\t= pvscsi_probe,\n\t.remove\t\t= pvscsi_remove,\n\t.shutdown       = pvscsi_shutdown,\n};\n\nstatic int __init pvscsi_init(void)\n{\n\tpr_info(\"%s - version %s\\n\",\n\t\tPVSCSI_LINUX_DRIVER_DESC, PVSCSI_DRIVER_VERSION_STRING);\n\treturn pci_register_driver(&pvscsi_pci_driver);\n}\n\nstatic void __exit pvscsi_exit(void)\n{\n\tpci_unregister_driver(&pvscsi_pci_driver);\n}\n\nmodule_init(pvscsi_init);\nmodule_exit(pvscsi_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}