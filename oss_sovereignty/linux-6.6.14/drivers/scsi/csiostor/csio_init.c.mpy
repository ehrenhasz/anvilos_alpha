{
  "module_name": "csio_init.c",
  "hash_id": "3f90627495dc425261606c941a128cafbd39f0dadcd41f8035d49e1aa772135d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/csiostor/csio_init.c",
  "human_readable_source": " \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/pci.h>\n#include <linux/mm.h>\n#include <linux/notifier.h>\n#include <linux/kdebug.h>\n#include <linux/seq_file.h>\n#include <linux/debugfs.h>\n#include <linux/string.h>\n#include <linux/export.h>\n\n#include \"csio_init.h\"\n#include \"csio_defs.h\"\n\n#define CSIO_MIN_MEMPOOL_SZ\t64\n\nstatic struct dentry *csio_debugfs_root;\n\nstatic struct scsi_transport_template *csio_fcoe_transport;\nstatic struct scsi_transport_template *csio_fcoe_transport_vport;\n\n \nstatic ssize_t\ncsio_mem_read(struct file *file, char __user *buf, size_t count, loff_t *ppos)\n{\n\tloff_t pos = *ppos;\n\tloff_t avail = file_inode(file)->i_size;\n\tunsigned int mem = (uintptr_t)file->private_data & 3;\n\tstruct csio_hw *hw = file->private_data - mem;\n\n\tif (pos < 0)\n\t\treturn -EINVAL;\n\tif (pos >= avail)\n\t\treturn 0;\n\tif (count > avail - pos)\n\t\tcount = avail - pos;\n\n\twhile (count) {\n\t\tsize_t len;\n\t\tint ret, ofst;\n\t\t__be32 data[16];\n\n\t\tif (mem == MEM_MC)\n\t\t\tret = hw->chip_ops->chip_mc_read(hw, 0, pos,\n\t\t\t\t\t\t\t data, NULL);\n\t\telse\n\t\t\tret = hw->chip_ops->chip_edc_read(hw, mem, pos,\n\t\t\t\t\t\t\t  data, NULL);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tofst = pos % sizeof(data);\n\t\tlen = min(count, sizeof(data) - ofst);\n\t\tif (copy_to_user(buf, (u8 *)data + ofst, len))\n\t\t\treturn -EFAULT;\n\n\t\tbuf += len;\n\t\tpos += len;\n\t\tcount -= len;\n\t}\n\tcount = pos - *ppos;\n\t*ppos = pos;\n\treturn count;\n}\n\nstatic const struct file_operations csio_mem_debugfs_fops = {\n\t.owner   = THIS_MODULE,\n\t.open    = simple_open,\n\t.read    = csio_mem_read,\n\t.llseek  = default_llseek,\n};\n\nvoid csio_add_debugfs_mem(struct csio_hw *hw, const char *name,\n\t\t\t\t unsigned int idx, unsigned int size_mb)\n{\n\tdebugfs_create_file_size(name, S_IRUSR, hw->debugfs_root,\n\t\t\t\t (void *)hw + idx, &csio_mem_debugfs_fops,\n\t\t\t\t size_mb << 20);\n}\n\nstatic int csio_setup_debugfs(struct csio_hw *hw)\n{\n\tint i;\n\n\tif (IS_ERR_OR_NULL(hw->debugfs_root))\n\t\treturn -1;\n\n\ti = csio_rd_reg32(hw, MA_TARGET_MEM_ENABLE_A);\n\tif (i & EDRAM0_ENABLE_F)\n\t\tcsio_add_debugfs_mem(hw, \"edc0\", MEM_EDC0, 5);\n\tif (i & EDRAM1_ENABLE_F)\n\t\tcsio_add_debugfs_mem(hw, \"edc1\", MEM_EDC1, 5);\n\n\thw->chip_ops->chip_dfs_create_ext_mem(hw);\n\treturn 0;\n}\n\n \nstatic int\ncsio_dfs_create(struct csio_hw *hw)\n{\n\tif (csio_debugfs_root) {\n\t\thw->debugfs_root = debugfs_create_dir(pci_name(hw->pdev),\n\t\t\t\t\t\t\tcsio_debugfs_root);\n\t\tcsio_setup_debugfs(hw);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void\ncsio_dfs_destroy(struct csio_hw *hw)\n{\n\tdebugfs_remove_recursive(hw->debugfs_root);\n}\n\n \nstatic void\ncsio_dfs_init(void)\n{\n\tcsio_debugfs_root = debugfs_create_dir(KBUILD_MODNAME, NULL);\n}\n\n \nstatic void\ncsio_dfs_exit(void)\n{\n\tdebugfs_remove(csio_debugfs_root);\n}\n\n \nstatic int\ncsio_pci_init(struct pci_dev *pdev, int *bars)\n{\n\tint rv = -ENODEV;\n\n\t*bars = pci_select_bars(pdev, IORESOURCE_MEM);\n\n\tif (pci_enable_device_mem(pdev))\n\t\tgoto err;\n\n\tif (pci_request_selected_regions(pdev, *bars, KBUILD_MODNAME))\n\t\tgoto err_disable_device;\n\n\tpci_set_master(pdev);\n\tpci_try_set_mwi(pdev);\n\n\trv = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (rv)\n\t\trv = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (rv) {\n\t\trv = -ENODEV;\n\t\tdev_err(&pdev->dev, \"No suitable DMA available.\\n\");\n\t\tgoto err_release_regions;\n\t}\n\n\treturn 0;\n\nerr_release_regions:\n\tpci_release_selected_regions(pdev, *bars);\nerr_disable_device:\n\tpci_disable_device(pdev);\nerr:\n\treturn rv;\n\n}\n\n \nstatic void\ncsio_pci_exit(struct pci_dev *pdev, int *bars)\n{\n\tpci_release_selected_regions(pdev, *bars);\n\tpci_disable_device(pdev);\n}\n\n \nstatic void\ncsio_hw_init_workers(struct csio_hw *hw)\n{\n\tINIT_WORK(&hw->evtq_work, csio_evtq_worker);\n}\n\nstatic void\ncsio_hw_exit_workers(struct csio_hw *hw)\n{\n\tcancel_work_sync(&hw->evtq_work);\n}\n\nstatic int\ncsio_create_queues(struct csio_hw *hw)\n{\n\tint i, j;\n\tstruct csio_mgmtm *mgmtm = csio_hw_to_mgmtm(hw);\n\tint rv;\n\tstruct csio_scsi_cpu_info *info;\n\n\tif (hw->flags & CSIO_HWF_Q_FW_ALLOCED)\n\t\treturn 0;\n\n\tif (hw->intr_mode != CSIO_IM_MSIX) {\n\t\trv = csio_wr_iq_create(hw, NULL, hw->intr_iq_idx,\n\t\t\t\t\t0, hw->pport[0].portid, false, NULL);\n\t\tif (rv != 0) {\n\t\t\tcsio_err(hw, \" Forward Interrupt IQ failed!: %d\\n\", rv);\n\t\t\treturn rv;\n\t\t}\n\t}\n\n\t \n\trv = csio_wr_iq_create(hw, NULL, hw->fwevt_iq_idx,\n\t\t\t       csio_get_fwevt_intr_idx(hw),\n\t\t\t       hw->pport[0].portid, true, NULL);\n\tif (rv != 0) {\n\t\tcsio_err(hw, \"FW event IQ config failed!: %d\\n\", rv);\n\t\treturn rv;\n\t}\n\n\t \n\trv = csio_wr_eq_create(hw, NULL, mgmtm->eq_idx,\n\t\t\tmgmtm->iq_idx, hw->pport[0].portid, NULL);\n\n\tif (rv != 0) {\n\t\tcsio_err(hw, \"Mgmt EQ create failed!: %d\\n\", rv);\n\t\tgoto err;\n\t}\n\n\t \n\tfor (i = 0; i < hw->num_pports; i++) {\n\t\tinfo = &hw->scsi_cpu_info[i];\n\n\t\tfor (j = 0; j < info->max_cpus; j++) {\n\t\t\tstruct csio_scsi_qset *sqset = &hw->sqset[i][j];\n\n\t\t\trv = csio_wr_iq_create(hw, NULL, sqset->iq_idx,\n\t\t\t\t\t       sqset->intr_idx, i, false, NULL);\n\t\t\tif (rv != 0) {\n\t\t\t\tcsio_err(hw,\n\t\t\t\t   \"SCSI module IQ config failed [%d][%d]:%d\\n\",\n\t\t\t\t   i, j, rv);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\trv = csio_wr_eq_create(hw, NULL, sqset->eq_idx,\n\t\t\t\t\t       sqset->iq_idx, i, NULL);\n\t\t\tif (rv != 0) {\n\t\t\t\tcsio_err(hw,\n\t\t\t\t   \"SCSI module EQ config failed [%d][%d]:%d\\n\",\n\t\t\t\t   i, j, rv);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}  \n\t}  \n\n\thw->flags |= CSIO_HWF_Q_FW_ALLOCED;\n\treturn 0;\nerr:\n\tcsio_wr_destroy_queues(hw, true);\n\treturn -EINVAL;\n}\n\n \nint\ncsio_config_queues(struct csio_hw *hw)\n{\n\tint i, j, idx, k = 0;\n\tint rv;\n\tstruct csio_scsi_qset *sqset;\n\tstruct csio_mgmtm *mgmtm = csio_hw_to_mgmtm(hw);\n\tstruct csio_scsi_qset *orig;\n\tstruct csio_scsi_cpu_info *info;\n\n\tif (hw->flags & CSIO_HWF_Q_MEM_ALLOCED)\n\t\treturn csio_create_queues(hw);\n\n\t \n\thw->num_scsi_msix_cpus = num_online_cpus();\n\thw->num_sqsets = num_online_cpus() * hw->num_pports;\n\n\tif (hw->num_sqsets > CSIO_MAX_SCSI_QSETS) {\n\t\thw->num_sqsets = CSIO_MAX_SCSI_QSETS;\n\t\thw->num_scsi_msix_cpus = CSIO_MAX_SCSI_CPU;\n\t}\n\n\t \n\tfor (i = 0; i < hw->num_pports; i++)\n\t\thw->scsi_cpu_info[i].max_cpus = hw->num_scsi_msix_cpus;\n\n\tcsio_dbg(hw, \"nsqsets:%d scpus:%d\\n\",\n\t\t    hw->num_sqsets, hw->num_scsi_msix_cpus);\n\n\tcsio_intr_enable(hw);\n\n\tif (hw->intr_mode != CSIO_IM_MSIX) {\n\n\t\t \n\t\thw->intr_iq_idx = csio_wr_alloc_q(hw, CSIO_INTR_IQSIZE,\n\t\t\t\t\t\tCSIO_INTR_WRSIZE, CSIO_INGRESS,\n\t\t\t\t\t\t(void *)hw, 0, 0, NULL);\n\t\tif (hw->intr_iq_idx == -1) {\n\t\t\tcsio_err(hw,\n\t\t\t\t \"Forward interrupt queue creation failed\\n\");\n\t\t\tgoto intr_disable;\n\t\t}\n\t}\n\n\t \n\thw->fwevt_iq_idx = csio_wr_alloc_q(hw, CSIO_FWEVT_IQSIZE,\n\t\t\t\t\t   CSIO_FWEVT_WRSIZE,\n\t\t\t\t\t   CSIO_INGRESS, (void *)hw,\n\t\t\t\t\t   CSIO_FWEVT_FLBUFS, 0,\n\t\t\t\t\t   csio_fwevt_intx_handler);\n\tif (hw->fwevt_iq_idx == -1) {\n\t\tcsio_err(hw, \"FW evt queue creation failed\\n\");\n\t\tgoto intr_disable;\n\t}\n\n\t \n\tmgmtm->eq_idx = csio_wr_alloc_q(hw, CSIO_MGMT_EQSIZE,\n\t\t\t\t      CSIO_MGMT_EQ_WRSIZE,\n\t\t\t\t      CSIO_EGRESS, (void *)hw, 0, 0, NULL);\n\tif (mgmtm->eq_idx == -1) {\n\t\tcsio_err(hw, \"Failed to alloc egress queue for mgmt module\\n\");\n\t\tgoto intr_disable;\n\t}\n\n\t \n\tmgmtm->iq_idx = hw->fwevt_iq_idx;\n\n\t \n\tfor (i = 0; i < hw->num_pports; i++) {\n\t\tinfo = &hw->scsi_cpu_info[i];\n\n\t\tfor (j = 0; j < hw->num_scsi_msix_cpus; j++) {\n\t\t\tsqset = &hw->sqset[i][j];\n\n\t\t\tif (j >= info->max_cpus) {\n\t\t\t\tk = j % info->max_cpus;\n\t\t\t\torig = &hw->sqset[i][k];\n\t\t\t\tsqset->eq_idx = orig->eq_idx;\n\t\t\t\tsqset->iq_idx = orig->iq_idx;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tidx = csio_wr_alloc_q(hw, csio_scsi_eqsize, 0,\n\t\t\t\t\t      CSIO_EGRESS, (void *)hw, 0, 0,\n\t\t\t\t\t      NULL);\n\t\t\tif (idx == -1) {\n\t\t\t\tcsio_err(hw, \"EQ creation failed for idx:%d\\n\",\n\t\t\t\t\t    idx);\n\t\t\t\tgoto intr_disable;\n\t\t\t}\n\n\t\t\tsqset->eq_idx = idx;\n\n\t\t\tidx = csio_wr_alloc_q(hw, CSIO_SCSI_IQSIZE,\n\t\t\t\t\t     CSIO_SCSI_IQ_WRSZ, CSIO_INGRESS,\n\t\t\t\t\t     (void *)hw, 0, 0,\n\t\t\t\t\t     csio_scsi_intx_handler);\n\t\t\tif (idx == -1) {\n\t\t\t\tcsio_err(hw, \"IQ creation failed for idx:%d\\n\",\n\t\t\t\t\t    idx);\n\t\t\t\tgoto intr_disable;\n\t\t\t}\n\t\t\tsqset->iq_idx = idx;\n\t\t}  \n\t}  \n\n\thw->flags |= CSIO_HWF_Q_MEM_ALLOCED;\n\n\trv = csio_create_queues(hw);\n\tif (rv != 0)\n\t\tgoto intr_disable;\n\n\t \n\trv = csio_request_irqs(hw);\n\tif (rv != 0)\n\t\treturn -EINVAL;\n\n\treturn 0;\n\nintr_disable:\n\tcsio_intr_disable(hw, false);\n\n\treturn -EINVAL;\n}\n\nstatic int\ncsio_resource_alloc(struct csio_hw *hw)\n{\n\tstruct csio_wrm *wrm = csio_hw_to_wrm(hw);\n\tint rv = -ENOMEM;\n\n\twrm->num_q = ((CSIO_MAX_SCSI_QSETS * 2) + CSIO_HW_NIQ +\n\t\t       CSIO_HW_NEQ + CSIO_HW_NFLQ + CSIO_HW_NINTXQ);\n\n\thw->mb_mempool = mempool_create_kmalloc_pool(CSIO_MIN_MEMPOOL_SZ,\n\t\t\t\t\t\t  sizeof(struct csio_mb));\n\tif (!hw->mb_mempool)\n\t\tgoto err;\n\n\thw->rnode_mempool = mempool_create_kmalloc_pool(CSIO_MIN_MEMPOOL_SZ,\n\t\t\t\t\t\t     sizeof(struct csio_rnode));\n\tif (!hw->rnode_mempool)\n\t\tgoto err_free_mb_mempool;\n\n\thw->scsi_dma_pool = dma_pool_create(\"csio_scsi_dma_pool\",\n\t\t\t\t\t    &hw->pdev->dev, CSIO_SCSI_RSP_LEN,\n\t\t\t\t\t    8, 0);\n\tif (!hw->scsi_dma_pool)\n\t\tgoto err_free_rn_pool;\n\n\treturn 0;\n\nerr_free_rn_pool:\n\tmempool_destroy(hw->rnode_mempool);\n\thw->rnode_mempool = NULL;\nerr_free_mb_mempool:\n\tmempool_destroy(hw->mb_mempool);\n\thw->mb_mempool = NULL;\nerr:\n\treturn rv;\n}\n\nstatic void\ncsio_resource_free(struct csio_hw *hw)\n{\n\tdma_pool_destroy(hw->scsi_dma_pool);\n\thw->scsi_dma_pool = NULL;\n\tmempool_destroy(hw->rnode_mempool);\n\thw->rnode_mempool = NULL;\n\tmempool_destroy(hw->mb_mempool);\n\thw->mb_mempool = NULL;\n}\n\n \nstatic struct csio_hw *csio_hw_alloc(struct pci_dev *pdev)\n{\n\tstruct csio_hw *hw;\n\n\thw = kzalloc(sizeof(struct csio_hw), GFP_KERNEL);\n\tif (!hw)\n\t\tgoto err;\n\n\thw->pdev = pdev;\n\tstrncpy(hw->drv_version, CSIO_DRV_VERSION, 32);\n\n\t \n\tif (csio_resource_alloc(hw))\n\t\tgoto err_free_hw;\n\n\t \n\thw->regstart = ioremap(pci_resource_start(pdev, 0),\n\t\t\t\t       pci_resource_len(pdev, 0));\n\tif (!hw->regstart) {\n\t\tcsio_err(hw, \"Could not map BAR 0, regstart = %p\\n\",\n\t\t\t hw->regstart);\n\t\tgoto err_resource_free;\n\t}\n\n\tcsio_hw_init_workers(hw);\n\n\tif (csio_hw_init(hw))\n\t\tgoto err_unmap_bar;\n\n\tcsio_dfs_create(hw);\n\n\tcsio_dbg(hw, \"hw:%p\\n\", hw);\n\n\treturn hw;\n\nerr_unmap_bar:\n\tcsio_hw_exit_workers(hw);\n\tiounmap(hw->regstart);\nerr_resource_free:\n\tcsio_resource_free(hw);\nerr_free_hw:\n\tkfree(hw);\nerr:\n\treturn NULL;\n}\n\n \nstatic void\ncsio_hw_free(struct csio_hw *hw)\n{\n\tcsio_intr_disable(hw, true);\n\tcsio_hw_exit_workers(hw);\n\tcsio_hw_exit(hw);\n\tiounmap(hw->regstart);\n\tcsio_dfs_destroy(hw);\n\tcsio_resource_free(hw);\n\tkfree(hw);\n}\n\n \nstruct csio_lnode *\ncsio_shost_init(struct csio_hw *hw, struct device *dev,\n\t\t  bool probe, struct csio_lnode *pln)\n{\n\tstruct Scsi_Host  *shost = NULL;\n\tstruct csio_lnode *ln;\n\n\tcsio_fcoe_shost_template.cmd_per_lun = csio_lun_qdepth;\n\tcsio_fcoe_shost_vport_template.cmd_per_lun = csio_lun_qdepth;\n\n\t \n\tif (dev == &hw->pdev->dev)\n\t\tshost = scsi_host_alloc(\n\t\t\t\t&csio_fcoe_shost_template,\n\t\t\t\tsizeof(struct csio_lnode));\n\telse\n\t\tshost = scsi_host_alloc(\n\t\t\t\t&csio_fcoe_shost_vport_template,\n\t\t\t\tsizeof(struct csio_lnode));\n\n\tif (!shost)\n\t\tgoto err;\n\n\tln = shost_priv(shost);\n\tmemset(ln, 0, sizeof(struct csio_lnode));\n\n\t \n\tln->dev_num = (shost->host_no << 16);\n\n\tshost->can_queue = CSIO_MAX_QUEUE;\n\tshost->this_id = -1;\n\tshost->unique_id = shost->host_no;\n\tshost->max_cmd_len = 16;  \n\tshost->max_id = min_t(uint32_t, csio_fcoe_rnodes,\n\t\t\t      hw->fres_info.max_ssns);\n\tshost->max_lun = CSIO_MAX_LUN;\n\tif (dev == &hw->pdev->dev)\n\t\tshost->transportt = csio_fcoe_transport;\n\telse\n\t\tshost->transportt = csio_fcoe_transport_vport;\n\n\t \n\tif (!hw->rln)\n\t\thw->rln = ln;\n\n\t \n\tif (csio_lnode_init(ln, hw, pln))\n\t\tgoto err_shost_put;\n\n\tif (scsi_add_host_with_dma(shost, dev, &hw->pdev->dev))\n\t\tgoto err_lnode_exit;\n\n\treturn ln;\n\nerr_lnode_exit:\n\tcsio_lnode_exit(ln);\nerr_shost_put:\n\tscsi_host_put(shost);\nerr:\n\treturn NULL;\n}\n\n \nvoid\ncsio_shost_exit(struct csio_lnode *ln)\n{\n\tstruct Scsi_Host *shost = csio_ln_to_shost(ln);\n\tstruct csio_hw *hw = csio_lnode_to_hw(ln);\n\n\t \n\tfc_remove_host(shost);\n\n\t \n\tscsi_remove_host(shost);\n\n\t \n\tspin_lock_irq(&hw->lock);\n\tcsio_evtq_flush(hw);\n\tspin_unlock_irq(&hw->lock);\n\n\tcsio_lnode_exit(ln);\n\tscsi_host_put(shost);\n}\n\nstruct csio_lnode *\ncsio_lnode_alloc(struct csio_hw *hw)\n{\n\treturn csio_shost_init(hw, &hw->pdev->dev, false, NULL);\n}\n\nvoid\ncsio_lnodes_block_request(struct csio_hw *hw)\n{\n\tstruct Scsi_Host  *shost;\n\tstruct csio_lnode *sln;\n\tstruct csio_lnode *ln;\n\tstruct list_head *cur_ln, *cur_cln;\n\tstruct csio_lnode **lnode_list;\n\tint cur_cnt = 0, ii;\n\n\tlnode_list = kzalloc((sizeof(struct csio_lnode *) * hw->num_lns),\n\t\t\tGFP_KERNEL);\n\tif (!lnode_list) {\n\t\tcsio_err(hw, \"Failed to allocate lnodes_list\");\n\t\treturn;\n\t}\n\n\tspin_lock_irq(&hw->lock);\n\t \n\tlist_for_each(cur_ln, &hw->sln_head) {\n\t\tsln = (struct csio_lnode *) cur_ln;\n\t\tlnode_list[cur_cnt++] = sln;\n\n\t\t \n\t\tlist_for_each(cur_cln, &sln->cln_head)\n\t\t\tlnode_list[cur_cnt++] = (struct csio_lnode *) cur_cln;\n\t}\n\tspin_unlock_irq(&hw->lock);\n\n\tfor (ii = 0; ii < cur_cnt; ii++) {\n\t\tcsio_dbg(hw, \"Blocking IOs on lnode: %p\\n\", lnode_list[ii]);\n\t\tln = lnode_list[ii];\n\t\tshost = csio_ln_to_shost(ln);\n\t\tscsi_block_requests(shost);\n\n\t}\n\tkfree(lnode_list);\n}\n\nvoid\ncsio_lnodes_unblock_request(struct csio_hw *hw)\n{\n\tstruct csio_lnode *ln;\n\tstruct Scsi_Host  *shost;\n\tstruct csio_lnode *sln;\n\tstruct list_head *cur_ln, *cur_cln;\n\tstruct csio_lnode **lnode_list;\n\tint cur_cnt = 0, ii;\n\n\tlnode_list = kzalloc((sizeof(struct csio_lnode *) * hw->num_lns),\n\t\t\tGFP_KERNEL);\n\tif (!lnode_list) {\n\t\tcsio_err(hw, \"Failed to allocate lnodes_list\");\n\t\treturn;\n\t}\n\n\tspin_lock_irq(&hw->lock);\n\t \n\tlist_for_each(cur_ln, &hw->sln_head) {\n\t\tsln = (struct csio_lnode *) cur_ln;\n\t\tlnode_list[cur_cnt++] = sln;\n\n\t\t \n\t\tlist_for_each(cur_cln, &sln->cln_head)\n\t\t\tlnode_list[cur_cnt++] = (struct csio_lnode *) cur_cln;\n\t}\n\tspin_unlock_irq(&hw->lock);\n\n\tfor (ii = 0; ii < cur_cnt; ii++) {\n\t\tcsio_dbg(hw, \"unblocking IOs on lnode: %p\\n\", lnode_list[ii]);\n\t\tln = lnode_list[ii];\n\t\tshost = csio_ln_to_shost(ln);\n\t\tscsi_unblock_requests(shost);\n\t}\n\tkfree(lnode_list);\n}\n\nvoid\ncsio_lnodes_block_by_port(struct csio_hw *hw, uint8_t portid)\n{\n\tstruct csio_lnode *ln;\n\tstruct Scsi_Host  *shost;\n\tstruct csio_lnode *sln;\n\tstruct list_head *cur_ln, *cur_cln;\n\tstruct csio_lnode **lnode_list;\n\tint cur_cnt = 0, ii;\n\n\tlnode_list = kzalloc((sizeof(struct csio_lnode *) * hw->num_lns),\n\t\t\tGFP_KERNEL);\n\tif (!lnode_list) {\n\t\tcsio_err(hw, \"Failed to allocate lnodes_list\");\n\t\treturn;\n\t}\n\n\tspin_lock_irq(&hw->lock);\n\t \n\tlist_for_each(cur_ln, &hw->sln_head) {\n\t\tsln = (struct csio_lnode *) cur_ln;\n\t\tif (sln->portid != portid)\n\t\t\tcontinue;\n\n\t\tlnode_list[cur_cnt++] = sln;\n\n\t\t \n\t\tlist_for_each(cur_cln, &sln->cln_head)\n\t\t\tlnode_list[cur_cnt++] = (struct csio_lnode *) cur_cln;\n\t}\n\tspin_unlock_irq(&hw->lock);\n\n\tfor (ii = 0; ii < cur_cnt; ii++) {\n\t\tcsio_dbg(hw, \"Blocking IOs on lnode: %p\\n\", lnode_list[ii]);\n\t\tln = lnode_list[ii];\n\t\tshost = csio_ln_to_shost(ln);\n\t\tscsi_block_requests(shost);\n\t}\n\tkfree(lnode_list);\n}\n\nvoid\ncsio_lnodes_unblock_by_port(struct csio_hw *hw, uint8_t portid)\n{\n\tstruct csio_lnode *ln;\n\tstruct Scsi_Host  *shost;\n\tstruct csio_lnode *sln;\n\tstruct list_head *cur_ln, *cur_cln;\n\tstruct csio_lnode **lnode_list;\n\tint cur_cnt = 0, ii;\n\n\tlnode_list = kzalloc((sizeof(struct csio_lnode *) * hw->num_lns),\n\t\t\tGFP_KERNEL);\n\tif (!lnode_list) {\n\t\tcsio_err(hw, \"Failed to allocate lnodes_list\");\n\t\treturn;\n\t}\n\n\tspin_lock_irq(&hw->lock);\n\t \n\tlist_for_each(cur_ln, &hw->sln_head) {\n\t\tsln = (struct csio_lnode *) cur_ln;\n\t\tif (sln->portid != portid)\n\t\t\tcontinue;\n\t\tlnode_list[cur_cnt++] = sln;\n\n\t\t \n\t\tlist_for_each(cur_cln, &sln->cln_head)\n\t\t\tlnode_list[cur_cnt++] = (struct csio_lnode *) cur_cln;\n\t}\n\tspin_unlock_irq(&hw->lock);\n\n\tfor (ii = 0; ii < cur_cnt; ii++) {\n\t\tcsio_dbg(hw, \"unblocking IOs on lnode: %p\\n\", lnode_list[ii]);\n\t\tln = lnode_list[ii];\n\t\tshost = csio_ln_to_shost(ln);\n\t\tscsi_unblock_requests(shost);\n\t}\n\tkfree(lnode_list);\n}\n\nvoid\ncsio_lnodes_exit(struct csio_hw *hw, bool npiv)\n{\n\tstruct csio_lnode *sln;\n\tstruct csio_lnode *ln;\n\tstruct list_head *cur_ln, *cur_cln;\n\tstruct csio_lnode **lnode_list;\n\tint cur_cnt = 0, ii;\n\n\tlnode_list = kzalloc((sizeof(struct csio_lnode *) * hw->num_lns),\n\t\t\tGFP_KERNEL);\n\tif (!lnode_list) {\n\t\tcsio_err(hw, \"lnodes_exit: Failed to allocate lnodes_list.\\n\");\n\t\treturn;\n\t}\n\n\t \n\tspin_lock_irq(&hw->lock);\n\tlist_for_each(cur_ln, &hw->sln_head) {\n\t\tsln = (struct csio_lnode *) cur_ln;\n\n\t\t \n\t\tlist_for_each(cur_cln, &sln->cln_head)\n\t\t\tlnode_list[cur_cnt++] = (struct csio_lnode *) cur_cln;\n\t}\n\tspin_unlock_irq(&hw->lock);\n\n\t \n\tfor (ii = 0; ii < cur_cnt; ii++) {\n\t\tcsio_dbg(hw, \"Deleting child lnode: %p\\n\", lnode_list[ii]);\n\t\tln = lnode_list[ii];\n\t\tfc_vport_terminate(ln->fc_vport);\n\t}\n\n\t \n\tif (npiv)\n\t\tgoto free_lnodes;\n\n\tcur_cnt = 0;\n\t \n\tspin_lock_irq(&hw->lock);\n\t \n\tlist_for_each(cur_ln, &hw->sln_head) {\n\t\tsln = (struct csio_lnode *) cur_ln;\n\t\tlnode_list[cur_cnt++] = sln;\n\t}\n\tspin_unlock_irq(&hw->lock);\n\n\t \n\tfor (ii = 0; ii < cur_cnt; ii++) {\n\t\tcsio_dbg(hw, \"Deleting parent lnode: %p\\n\", lnode_list[ii]);\n\t\tcsio_shost_exit(lnode_list[ii]);\n\t}\n\nfree_lnodes:\n\tkfree(lnode_list);\n}\n\n \nstatic void\ncsio_lnode_init_post(struct csio_lnode *ln)\n{\n\tstruct Scsi_Host  *shost = csio_ln_to_shost(ln);\n\n\tcsio_fchost_attr_init(ln);\n\n\tscsi_scan_host(shost);\n}\n\n \nstatic int csio_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tint rv;\n\tint bars;\n\tint i;\n\tstruct csio_hw *hw;\n\tstruct csio_lnode *ln;\n\n\t \n\tif (!csio_is_t5((pdev->device & CSIO_HW_CHIP_MASK)) &&\n\t    !csio_is_t6((pdev->device & CSIO_HW_CHIP_MASK)))\n\t\treturn -ENODEV;\n\n\trv = csio_pci_init(pdev, &bars);\n\tif (rv)\n\t\tgoto err;\n\n\thw = csio_hw_alloc(pdev);\n\tif (!hw) {\n\t\trv = -ENODEV;\n\t\tgoto err_pci_exit;\n\t}\n\n\tif (!pcie_relaxed_ordering_enabled(pdev))\n\t\thw->flags |= CSIO_HWF_ROOT_NO_RELAXED_ORDERING;\n\n\tpci_set_drvdata(pdev, hw);\n\n\trv = csio_hw_start(hw);\n\tif (rv) {\n\t\tif (rv == -EINVAL) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Failed to start FW, continuing in debug mode.\\n\");\n\t\t\treturn 0;\n\t\t}\n\t\tgoto err_lnode_exit;\n\t}\n\n\tsprintf(hw->fwrev_str, \"%u.%u.%u.%u\\n\",\n\t\t    FW_HDR_FW_VER_MAJOR_G(hw->fwrev),\n\t\t    FW_HDR_FW_VER_MINOR_G(hw->fwrev),\n\t\t    FW_HDR_FW_VER_MICRO_G(hw->fwrev),\n\t\t    FW_HDR_FW_VER_BUILD_G(hw->fwrev));\n\n\tfor (i = 0; i < hw->num_pports; i++) {\n\t\tln = csio_shost_init(hw, &pdev->dev, true, NULL);\n\t\tif (!ln) {\n\t\t\trv = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tln->portid = hw->pport[i].portid;\n\n\t\tspin_lock_irq(&hw->lock);\n\t\tif (csio_lnode_start(ln) != 0)\n\t\t\trv = -ENODEV;\n\t\tspin_unlock_irq(&hw->lock);\n\n\t\tif (rv)\n\t\t\tbreak;\n\n\t\tcsio_lnode_init_post(ln);\n\t}\n\n\tif (rv)\n\t\tgoto err_lnode_exit;\n\n\treturn 0;\n\nerr_lnode_exit:\n\tcsio_lnodes_block_request(hw);\n\tspin_lock_irq(&hw->lock);\n\tcsio_hw_stop(hw);\n\tspin_unlock_irq(&hw->lock);\n\tcsio_lnodes_unblock_request(hw);\n\tcsio_lnodes_exit(hw, 0);\n\tcsio_hw_free(hw);\nerr_pci_exit:\n\tcsio_pci_exit(pdev, &bars);\nerr:\n\tdev_err(&pdev->dev, \"probe of device failed: %d\\n\", rv);\n\treturn rv;\n}\n\n \nstatic void csio_remove_one(struct pci_dev *pdev)\n{\n\tstruct csio_hw *hw = pci_get_drvdata(pdev);\n\tint bars = pci_select_bars(pdev, IORESOURCE_MEM);\n\n\tcsio_lnodes_block_request(hw);\n\tspin_lock_irq(&hw->lock);\n\n\t \n\tcsio_hw_stop(hw);\n\tspin_unlock_irq(&hw->lock);\n\tcsio_lnodes_unblock_request(hw);\n\n\tcsio_lnodes_exit(hw, 0);\n\tcsio_hw_free(hw);\n\tcsio_pci_exit(pdev, &bars);\n}\n\n \nstatic pci_ers_result_t\ncsio_pci_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\n{\n\tstruct csio_hw *hw = pci_get_drvdata(pdev);\n\n\tcsio_lnodes_block_request(hw);\n\tspin_lock_irq(&hw->lock);\n\n\t \n\tcsio_post_event(&hw->sm, CSIO_HWE_PCIERR_DETECTED);\n\tspin_unlock_irq(&hw->lock);\n\tcsio_lnodes_unblock_request(hw);\n\tcsio_lnodes_exit(hw, 0);\n\tcsio_intr_disable(hw, true);\n\tpci_disable_device(pdev);\n\treturn state == pci_channel_io_perm_failure ?\n\t\tPCI_ERS_RESULT_DISCONNECT : PCI_ERS_RESULT_NEED_RESET;\n}\n\n \nstatic pci_ers_result_t\ncsio_pci_slot_reset(struct pci_dev *pdev)\n{\n\tstruct csio_hw *hw = pci_get_drvdata(pdev);\n\tint ready;\n\n\tif (pci_enable_device(pdev)) {\n\t\tdev_err(&pdev->dev, \"cannot re-enable device in slot reset\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\tpci_set_master(pdev);\n\tpci_restore_state(pdev);\n\tpci_save_state(pdev);\n\n\t \n\tspin_lock_irq(&hw->lock);\n\tcsio_post_event(&hw->sm, CSIO_HWE_PCIERR_SLOT_RESET);\n\tready = csio_is_hw_ready(hw);\n\tspin_unlock_irq(&hw->lock);\n\n\tif (ready) {\n\t\treturn PCI_ERS_RESULT_RECOVERED;\n\t} else {\n\t\tdev_err(&pdev->dev, \"Can't initialize HW when in slot reset\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n}\n\n \nstatic void\ncsio_pci_resume(struct pci_dev *pdev)\n{\n\tstruct csio_hw *hw = pci_get_drvdata(pdev);\n\tstruct csio_lnode *ln;\n\tint rv = 0;\n\tint i;\n\n\t \n\n\tfor (i = 0; i < hw->num_pports; i++) {\n\t\tln = csio_shost_init(hw, &pdev->dev, true, NULL);\n\t\tif (!ln) {\n\t\t\trv = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tln->portid = hw->pport[i].portid;\n\n\t\tspin_lock_irq(&hw->lock);\n\t\tif (csio_lnode_start(ln) != 0)\n\t\t\trv = -ENODEV;\n\t\tspin_unlock_irq(&hw->lock);\n\n\t\tif (rv)\n\t\t\tbreak;\n\n\t\tcsio_lnode_init_post(ln);\n\t}\n\n\tif (rv)\n\t\tgoto err_resume_exit;\n\n\treturn;\n\nerr_resume_exit:\n\tcsio_lnodes_block_request(hw);\n\tspin_lock_irq(&hw->lock);\n\tcsio_hw_stop(hw);\n\tspin_unlock_irq(&hw->lock);\n\tcsio_lnodes_unblock_request(hw);\n\tcsio_lnodes_exit(hw, 0);\n\tcsio_hw_free(hw);\n\tdev_err(&pdev->dev, \"resume of device failed: %d\\n\", rv);\n}\n\nstatic struct pci_error_handlers csio_err_handler = {\n\t.error_detected = csio_pci_error_detected,\n\t.slot_reset\t= csio_pci_slot_reset,\n\t.resume\t\t= csio_pci_resume,\n};\n\n \n#define CH_PCI_DEVICE_ID_TABLE_DEFINE_BEGIN \\\n\tstatic const struct pci_device_id csio_pci_tbl[] = {\n \n#define CH_PCI_DEVICE_ID_FUNCTION\t0x6\n\n#define CH_PCI_ID_TABLE_ENTRY(devid) \\\n\t\t{ PCI_VDEVICE(CHELSIO, (devid)), 0 }\n\n#define CH_PCI_DEVICE_ID_TABLE_DEFINE_END { 0, } }\n\n#include \"t4_pci_id_tbl.h\"\n\nstatic struct pci_driver csio_pci_driver = {\n\t.name\t\t= KBUILD_MODNAME,\n\t.driver\t\t= {\n\t\t.owner\t= THIS_MODULE,\n\t},\n\t.id_table\t= csio_pci_tbl,\n\t.probe\t\t= csio_probe_one,\n\t.remove\t\t= csio_remove_one,\n\t.err_handler\t= &csio_err_handler,\n};\n\n \nstatic int __init\ncsio_init(void)\n{\n\tint rv = -ENOMEM;\n\n\tpr_info(\"%s %s\\n\", CSIO_DRV_DESC, CSIO_DRV_VERSION);\n\n\tcsio_dfs_init();\n\n\tcsio_fcoe_transport = fc_attach_transport(&csio_fc_transport_funcs);\n\tif (!csio_fcoe_transport)\n\t\tgoto err;\n\n\tcsio_fcoe_transport_vport =\n\t\t\tfc_attach_transport(&csio_fc_transport_vport_funcs);\n\tif (!csio_fcoe_transport_vport)\n\t\tgoto err_vport;\n\n\trv = pci_register_driver(&csio_pci_driver);\n\tif (rv)\n\t\tgoto err_pci;\n\n\treturn 0;\n\nerr_pci:\n\tfc_release_transport(csio_fcoe_transport_vport);\nerr_vport:\n\tfc_release_transport(csio_fcoe_transport);\nerr:\n\tcsio_dfs_exit();\n\treturn rv;\n}\n\n \nstatic void __exit\ncsio_exit(void)\n{\n\tpci_unregister_driver(&csio_pci_driver);\n\tcsio_dfs_exit();\n\tfc_release_transport(csio_fcoe_transport_vport);\n\tfc_release_transport(csio_fcoe_transport);\n}\n\nmodule_init(csio_init);\nmodule_exit(csio_exit);\nMODULE_AUTHOR(CSIO_DRV_AUTHOR);\nMODULE_DESCRIPTION(CSIO_DRV_DESC);\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_DEVICE_TABLE(pci, csio_pci_tbl);\nMODULE_VERSION(CSIO_DRV_VERSION);\nMODULE_FIRMWARE(FW_FNAME_T5);\nMODULE_FIRMWARE(FW_FNAME_T6);\nMODULE_SOFTDEP(\"pre: cxgb4\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}