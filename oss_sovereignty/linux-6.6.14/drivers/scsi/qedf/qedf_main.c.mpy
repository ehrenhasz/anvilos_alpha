{
  "module_name": "qedf_main.c",
  "hash_id": "0fb077a253a2339fe74550912e1153cec0d4765a8715db66473f9d3a9387c041",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/qedf/qedf_main.c",
  "human_readable_source": "\n \n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/device.h>\n#include <linux/highmem.h>\n#include <linux/crc32.h>\n#include <linux/interrupt.h>\n#include <linux/list.h>\n#include <linux/kthread.h>\n#include <linux/phylink.h>\n#include <scsi/libfc.h>\n#include <scsi/scsi_host.h>\n#include <scsi/fc_frame.h>\n#include <linux/if_ether.h>\n#include <linux/if_vlan.h>\n#include <linux/cpu.h>\n#include \"qedf.h\"\n#include \"qedf_dbg.h\"\n#include <uapi/linux/pci_regs.h>\n\nconst struct qed_fcoe_ops *qed_ops;\n\nstatic int qedf_probe(struct pci_dev *pdev, const struct pci_device_id *id);\nstatic void qedf_remove(struct pci_dev *pdev);\nstatic void qedf_shutdown(struct pci_dev *pdev);\nstatic void qedf_schedule_recovery_handler(void *dev);\nstatic void qedf_recovery_handler(struct work_struct *work);\nstatic int qedf_suspend(struct pci_dev *pdev, pm_message_t state);\n\n \nstatic unsigned int qedf_dev_loss_tmo = 60;\nmodule_param_named(dev_loss_tmo, qedf_dev_loss_tmo, int, S_IRUGO);\nMODULE_PARM_DESC(dev_loss_tmo,  \" dev_loss_tmo setting for attached \"\n\t\"remote ports (default 60)\");\n\nuint qedf_debug = QEDF_LOG_INFO;\nmodule_param_named(debug, qedf_debug, uint, S_IRUGO|S_IWUSR);\nMODULE_PARM_DESC(debug, \" Debug mask. Pass '1' to enable default debugging\"\n\t\" mask\");\n\nstatic uint qedf_fipvlan_retries = 60;\nmodule_param_named(fipvlan_retries, qedf_fipvlan_retries, int, S_IRUGO);\nMODULE_PARM_DESC(fipvlan_retries, \" Number of FIP VLAN requests to attempt \"\n\t\"before giving up (default 60)\");\n\nstatic uint qedf_fallback_vlan = QEDF_FALLBACK_VLAN;\nmodule_param_named(fallback_vlan, qedf_fallback_vlan, int, S_IRUGO);\nMODULE_PARM_DESC(fallback_vlan, \" VLAN ID to try if fip vlan request fails \"\n\t\"(default 1002).\");\n\nstatic int qedf_default_prio = -1;\nmodule_param_named(default_prio, qedf_default_prio, int, S_IRUGO);\nMODULE_PARM_DESC(default_prio, \" Override 802.1q priority for FIP and FCoE\"\n\t\" traffic (value between 0 and 7, default 3).\");\n\nuint qedf_dump_frames;\nmodule_param_named(dump_frames, qedf_dump_frames, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(dump_frames, \" Print the skb data of FIP and FCoE frames \"\n\t\"(default off)\");\n\nstatic uint qedf_queue_depth;\nmodule_param_named(queue_depth, qedf_queue_depth, int, S_IRUGO);\nMODULE_PARM_DESC(queue_depth, \" Sets the queue depth for all LUNs discovered \"\n\t\"by the qedf driver. Default is 0 (use OS default).\");\n\nuint qedf_io_tracing;\nmodule_param_named(io_tracing, qedf_io_tracing, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(io_tracing, \" Enable logging of SCSI requests/completions \"\n\t\"into trace buffer. (default off).\");\n\nstatic uint qedf_max_lun = MAX_FIBRE_LUNS;\nmodule_param_named(max_lun, qedf_max_lun, int, S_IRUGO);\nMODULE_PARM_DESC(max_lun, \" Sets the maximum luns per target that the driver \"\n\t\"supports. (default 0xffffffff)\");\n\nuint qedf_link_down_tmo;\nmodule_param_named(link_down_tmo, qedf_link_down_tmo, int, S_IRUGO);\nMODULE_PARM_DESC(link_down_tmo, \" Delays informing the fcoe transport that the \"\n\t\"link is down by N seconds.\");\n\nbool qedf_retry_delay;\nmodule_param_named(retry_delay, qedf_retry_delay, bool, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(retry_delay, \" Enable/disable handling of FCP_RSP IU retry \"\n\t\"delay handling (default off).\");\n\nstatic bool qedf_dcbx_no_wait;\nmodule_param_named(dcbx_no_wait, qedf_dcbx_no_wait, bool, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(dcbx_no_wait, \" Do not wait for DCBX convergence to start \"\n\t\"sending FIP VLAN requests on link up (Default: off).\");\n\nstatic uint qedf_dp_module;\nmodule_param_named(dp_module, qedf_dp_module, uint, S_IRUGO);\nMODULE_PARM_DESC(dp_module, \" bit flags control for verbose printk passed \"\n\t\"qed module during probe.\");\n\nstatic uint qedf_dp_level = QED_LEVEL_NOTICE;\nmodule_param_named(dp_level, qedf_dp_level, uint, S_IRUGO);\nMODULE_PARM_DESC(dp_level, \" printk verbosity control passed to qed module  \"\n\t\"during probe (0-3: 0 more verbose).\");\n\nstatic bool qedf_enable_recovery = true;\nmodule_param_named(enable_recovery, qedf_enable_recovery,\n\t\tbool, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(enable_recovery, \"Enable/disable recovery on driver/firmware \"\n\t\t\"interface level errors 0 = Disabled, 1 = Enabled (Default: 1).\");\n\nstruct workqueue_struct *qedf_io_wq;\n\nstatic struct fcoe_percpu_s qedf_global;\nstatic DEFINE_SPINLOCK(qedf_global_lock);\n\nstatic struct kmem_cache *qedf_io_work_cache;\n\nvoid qedf_set_vlan_id(struct qedf_ctx *qedf, int vlan_id)\n{\n\tint vlan_id_tmp = 0;\n\n\tvlan_id_tmp = vlan_id  | (qedf->prio << VLAN_PRIO_SHIFT);\n\tqedf->vlan_id = vlan_id_tmp;\n\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t  \"Setting vlan_id=0x%04x prio=%d.\\n\",\n\t\t  vlan_id_tmp, qedf->prio);\n}\n\n \nstatic bool qedf_initiate_fipvlan_req(struct qedf_ctx *qedf)\n{\n\n\twhile (qedf->fipvlan_retries--) {\n\t\t \n\t\tif (atomic_read(&qedf->link_state) == QEDF_LINK_DOWN) {\n\t\t\tQEDF_ERR(&qedf->dbg_ctx, \"Link not up.\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\tif (test_bit(QEDF_UNLOADING, &qedf->flags)) {\n\t\t\tQEDF_ERR(&qedf->dbg_ctx, \"Driver unloading.\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\tif (qedf->vlan_id > 0) {\n\t\t\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t\t\t  \"vlan = 0x%x already set, calling ctlr_link_up.\\n\",\n\t\t\t\t  qedf->vlan_id);\n\t\t\tif (atomic_read(&qedf->link_state) == QEDF_LINK_UP)\n\t\t\t\tfcoe_ctlr_link_up(&qedf->ctlr);\n\t\t\treturn true;\n\t\t}\n\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t   \"Retry %d.\\n\", qedf->fipvlan_retries);\n\t\tinit_completion(&qedf->fipvlan_compl);\n\t\tqedf_fcoe_send_vlan_req(qedf);\n\t\twait_for_completion_timeout(&qedf->fipvlan_compl, 1 * HZ);\n\t}\n\n\treturn false;\n}\n\nstatic void qedf_handle_link_update(struct work_struct *work)\n{\n\tstruct qedf_ctx *qedf =\n\t    container_of(work, struct qedf_ctx, link_update.work);\n\tint rc;\n\n\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC, \"Entered. link_state=%d.\\n\",\n\t\t  atomic_read(&qedf->link_state));\n\n\tif (atomic_read(&qedf->link_state) == QEDF_LINK_UP) {\n\t\trc = qedf_initiate_fipvlan_req(qedf);\n\t\tif (rc)\n\t\t\treturn;\n\n\t\tif (atomic_read(&qedf->link_state) != QEDF_LINK_UP) {\n\t\t\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t\t\t  \"Link is down, resetting vlan_id.\\n\");\n\t\t\tqedf->vlan_id = 0;\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Did not receive FIP VLAN \"\n\t\t\t   \"response, falling back to default VLAN %d.\\n\",\n\t\t\t   qedf_fallback_vlan);\n\t\tqedf_set_vlan_id(qedf, qedf_fallback_vlan);\n\n\t\t \n\t\teth_zero_addr(qedf->data_src_addr);\n\t\tfcoe_ctlr_link_up(&qedf->ctlr);\n\t} else if (atomic_read(&qedf->link_state) == QEDF_LINK_DOWN) {\n\t\t \n\t\tatomic_set(&qedf->link_down_tmo_valid, 0);\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t    \"Calling fcoe_ctlr_link_down().\\n\");\n\t\tfcoe_ctlr_link_down(&qedf->ctlr);\n\t\tif (qedf_wait_for_upload(qedf) == false)\n\t\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t\t \"Could not upload all sessions.\\n\");\n\t\t \n\t\tqedf->fipvlan_retries = qedf_fipvlan_retries;\n\t}\n}\n\n#define\tQEDF_FCOE_MAC_METHOD_GRANGED_MAC\t\t1\n#define QEDF_FCOE_MAC_METHOD_FCF_MAP\t\t\t2\n#define QEDF_FCOE_MAC_METHOD_FCOE_SET_MAC\t\t3\nstatic void qedf_set_data_src_addr(struct qedf_ctx *qedf, struct fc_frame *fp)\n{\n\tu8 *granted_mac;\n\tstruct fc_frame_header *fh = fc_frame_header_get(fp);\n\tu8 fc_map[3];\n\tint method = 0;\n\n\t \n\tgranted_mac = fr_cb(fp)->granted_mac;\n\n\t \n\tif (!is_zero_ether_addr(granted_mac)) {\n\t\tether_addr_copy(qedf->data_src_addr, granted_mac);\n\t\tmethod = QEDF_FCOE_MAC_METHOD_GRANGED_MAC;\n\t} else if (qedf->ctlr.sel_fcf->fc_map != 0) {\n\t\thton24(fc_map, qedf->ctlr.sel_fcf->fc_map);\n\t\tqedf->data_src_addr[0] = fc_map[0];\n\t\tqedf->data_src_addr[1] = fc_map[1];\n\t\tqedf->data_src_addr[2] = fc_map[2];\n\t\tqedf->data_src_addr[3] = fh->fh_d_id[0];\n\t\tqedf->data_src_addr[4] = fh->fh_d_id[1];\n\t\tqedf->data_src_addr[5] = fh->fh_d_id[2];\n\t\tmethod = QEDF_FCOE_MAC_METHOD_FCF_MAP;\n\t} else {\n\t\tfc_fcoe_set_mac(qedf->data_src_addr, fh->fh_d_id);\n\t\tmethod = QEDF_FCOE_MAC_METHOD_FCOE_SET_MAC;\n\t}\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t    \"QEDF data_src_mac=%pM method=%d.\\n\", qedf->data_src_addr, method);\n}\n\nstatic void qedf_flogi_resp(struct fc_seq *seq, struct fc_frame *fp,\n\tvoid *arg)\n{\n\tstruct fc_exch *exch = fc_seq_exch(seq);\n\tstruct fc_lport *lport = exch->lp;\n\tstruct qedf_ctx *qedf = lport_priv(lport);\n\n\tif (!qedf) {\n\t\tQEDF_ERR(NULL, \"qedf is NULL.\\n\");\n\t\treturn;\n\t}\n\n\t \n\tif (IS_ERR(fp)) {\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_ELS,\n\t\t    \"fp has IS_ERR() set.\\n\");\n\t\tgoto skip_stat;\n\t}\n\n\t \n\tif (fc_frame_payload_op(fp) == ELS_LS_RJT)\n\t\tqedf->flogi_failed++;\n\telse if (fc_frame_payload_op(fp) == ELS_LS_ACC) {\n\t\t \n\t\tqedf_set_data_src_addr(qedf, fp);\n\t\tqedf->flogi_pending = 0;\n\t}\n\n\t \n\tcomplete(&qedf->flogi_compl);\n\nskip_stat:\n\t \n\tfc_lport_flogi_resp(seq, fp, lport);\n}\n\nstatic struct fc_seq *qedf_elsct_send(struct fc_lport *lport, u32 did,\n\tstruct fc_frame *fp, unsigned int op,\n\tvoid (*resp)(struct fc_seq *,\n\tstruct fc_frame *,\n\tvoid *),\n\tvoid *arg, u32 timeout)\n{\n\tstruct qedf_ctx *qedf = lport_priv(lport);\n\n\t \n\tif (resp == fc_lport_flogi_resp) {\n\t\tqedf->flogi_cnt++;\n\t\tif (qedf->flogi_pending >= QEDF_FLOGI_RETRY_CNT) {\n\t\t\tschedule_delayed_work(&qedf->stag_work, 2);\n\t\t\treturn NULL;\n\t\t}\n\t\tqedf->flogi_pending++;\n\t\treturn fc_elsct_send(lport, did, fp, op, qedf_flogi_resp,\n\t\t    arg, timeout);\n\t}\n\n\treturn fc_elsct_send(lport, did, fp, op, resp, arg, timeout);\n}\n\nint qedf_send_flogi(struct qedf_ctx *qedf)\n{\n\tstruct fc_lport *lport;\n\tstruct fc_frame *fp;\n\n\tlport = qedf->lport;\n\n\tif (!lport->tt.elsct_send) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"tt.elsct_send not set.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tfp = fc_frame_alloc(lport, sizeof(struct fc_els_flogi));\n\tif (!fp) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"fc_frame_alloc failed.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_ELS,\n\t    \"Sending FLOGI to reestablish session with switch.\\n\");\n\tlport->tt.elsct_send(lport, FC_FID_FLOGI, fp,\n\t    ELS_FLOGI, qedf_flogi_resp, lport, lport->r_a_tov);\n\n\tinit_completion(&qedf->flogi_compl);\n\n\treturn 0;\n}\n\n \nstatic void qedf_link_recovery(struct work_struct *work)\n{\n\tstruct qedf_ctx *qedf =\n\t    container_of(work, struct qedf_ctx, link_recovery.work);\n\tstruct fc_lport *lport = qedf->lport;\n\tstruct fc_rport_priv *rdata;\n\tbool rc;\n\tint retries = 30;\n\tint rval, i;\n\tstruct list_head rdata_login_list;\n\n\tINIT_LIST_HEAD(&rdata_login_list);\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t    \"Link down tmo did not expire.\\n\");\n\n\t \n\tqedf->ctlr.state = FIP_ST_LINK_WAIT;\n\tfcoe_ctlr_link_down(&qedf->ctlr);\n\n\t \n\tfcoe_ctlr_link_up(&qedf->ctlr);\n\n\t \n\tqedf->fipvlan_retries = qedf_fipvlan_retries;\n\trc = qedf_initiate_fipvlan_req(qedf);\n\t \n\tif (!rc)\n\t\tqedf_set_vlan_id(qedf, qedf_fallback_vlan);\n\n\t \n\twhile (retries > 0) {\n\t\tif (qedf->ctlr.sel_fcf) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"FCF reselected, proceeding with FLOGI.\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tmsleep(500);\n\t\tretries--;\n\t}\n\n\tif (retries < 1) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Exhausted retries waiting for \"\n\t\t    \"FCF selection.\\n\");\n\t\treturn;\n\t}\n\n\trval = qedf_send_flogi(qedf);\n\tif (rval)\n\t\treturn;\n\n\t \n\ti = wait_for_completion_timeout(&qedf->flogi_compl,\n\t    qedf->lport->r_a_tov);\n\tif (i == 0) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"FLOGI timed out.\\n\");\n\t\treturn;\n\t}\n\n\t \n\tmutex_lock(&lport->disc.disc_mutex);\n\tlist_for_each_entry_rcu(rdata, &lport->disc.rports, peers) {\n\t\tif (kref_get_unless_zero(&rdata->kref)) {\n\t\t\tfc_rport_login(rdata);\n\t\t\tkref_put(&rdata->kref, fc_rport_destroy);\n\t\t}\n\t}\n\tmutex_unlock(&lport->disc.disc_mutex);\n}\n\nstatic void qedf_update_link_speed(struct qedf_ctx *qedf,\n\tstruct qed_link_output *link)\n{\n\t__ETHTOOL_DECLARE_LINK_MODE_MASK(sup_caps);\n\tstruct fc_lport *lport = qedf->lport;\n\n\tlport->link_speed = FC_PORTSPEED_UNKNOWN;\n\tlport->link_supported_speeds = FC_PORTSPEED_UNKNOWN;\n\n\t \n\tswitch (link->speed) {\n\tcase 10000:\n\t\tlport->link_speed = FC_PORTSPEED_10GBIT;\n\t\tbreak;\n\tcase 25000:\n\t\tlport->link_speed = FC_PORTSPEED_25GBIT;\n\t\tbreak;\n\tcase 40000:\n\t\tlport->link_speed = FC_PORTSPEED_40GBIT;\n\t\tbreak;\n\tcase 50000:\n\t\tlport->link_speed = FC_PORTSPEED_50GBIT;\n\t\tbreak;\n\tcase 100000:\n\t\tlport->link_speed = FC_PORTSPEED_100GBIT;\n\t\tbreak;\n\tcase 20000:\n\t\tlport->link_speed = FC_PORTSPEED_20GBIT;\n\t\tbreak;\n\tdefault:\n\t\tlport->link_speed = FC_PORTSPEED_UNKNOWN;\n\t\tbreak;\n\t}\n\n\t \n\n\tphylink_zero(sup_caps);\n\tphylink_set(sup_caps, 10000baseT_Full);\n\tphylink_set(sup_caps, 10000baseKX4_Full);\n\tphylink_set(sup_caps, 10000baseR_FEC);\n\tphylink_set(sup_caps, 10000baseCR_Full);\n\tphylink_set(sup_caps, 10000baseSR_Full);\n\tphylink_set(sup_caps, 10000baseLR_Full);\n\tphylink_set(sup_caps, 10000baseLRM_Full);\n\tphylink_set(sup_caps, 10000baseKR_Full);\n\n\tif (linkmode_intersects(link->supported_caps, sup_caps))\n\t\tlport->link_supported_speeds |= FC_PORTSPEED_10GBIT;\n\n\tphylink_zero(sup_caps);\n\tphylink_set(sup_caps, 25000baseKR_Full);\n\tphylink_set(sup_caps, 25000baseCR_Full);\n\tphylink_set(sup_caps, 25000baseSR_Full);\n\n\tif (linkmode_intersects(link->supported_caps, sup_caps))\n\t\tlport->link_supported_speeds |= FC_PORTSPEED_25GBIT;\n\n\tphylink_zero(sup_caps);\n\tphylink_set(sup_caps, 40000baseLR4_Full);\n\tphylink_set(sup_caps, 40000baseKR4_Full);\n\tphylink_set(sup_caps, 40000baseCR4_Full);\n\tphylink_set(sup_caps, 40000baseSR4_Full);\n\n\tif (linkmode_intersects(link->supported_caps, sup_caps))\n\t\tlport->link_supported_speeds |= FC_PORTSPEED_40GBIT;\n\n\tphylink_zero(sup_caps);\n\tphylink_set(sup_caps, 50000baseKR2_Full);\n\tphylink_set(sup_caps, 50000baseCR2_Full);\n\tphylink_set(sup_caps, 50000baseSR2_Full);\n\n\tif (linkmode_intersects(link->supported_caps, sup_caps))\n\t\tlport->link_supported_speeds |= FC_PORTSPEED_50GBIT;\n\n\tphylink_zero(sup_caps);\n\tphylink_set(sup_caps, 100000baseKR4_Full);\n\tphylink_set(sup_caps, 100000baseSR4_Full);\n\tphylink_set(sup_caps, 100000baseCR4_Full);\n\tphylink_set(sup_caps, 100000baseLR4_ER4_Full);\n\n\tif (linkmode_intersects(link->supported_caps, sup_caps))\n\t\tlport->link_supported_speeds |= FC_PORTSPEED_100GBIT;\n\n\tphylink_zero(sup_caps);\n\tphylink_set(sup_caps, 20000baseKR2_Full);\n\n\tif (linkmode_intersects(link->supported_caps, sup_caps))\n\t\tlport->link_supported_speeds |= FC_PORTSPEED_20GBIT;\n\n\tif (lport->host && lport->host->shost_data)\n\t\tfc_host_supported_speeds(lport->host) =\n\t\t\tlport->link_supported_speeds;\n}\n\nstatic void qedf_bw_update(void *dev)\n{\n\tstruct qedf_ctx *qedf = (struct qedf_ctx *)dev;\n\tstruct qed_link_output link;\n\n\t \n\tqed_ops->common->get_link(qedf->cdev, &link);\n\n\tif (test_bit(QEDF_UNLOADING, &qedf->flags)) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"Ignore link update, driver getting unload.\\n\");\n\t\treturn;\n\t}\n\n\tif (link.link_up) {\n\t\tif (atomic_read(&qedf->link_state) == QEDF_LINK_UP)\n\t\t\tqedf_update_link_speed(qedf, &link);\n\t\telse\n\t\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t\t \"Ignore bw update, link is down.\\n\");\n\n\t} else {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"link_up is not set.\\n\");\n\t}\n}\n\nstatic void qedf_link_update(void *dev, struct qed_link_output *link)\n{\n\tstruct qedf_ctx *qedf = (struct qedf_ctx *)dev;\n\n\t \n\tif (test_bit(QEDF_UNLOADING, &qedf->flags)) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"Ignore link update, driver getting unload.\\n\");\n\t\treturn;\n\t}\n\n\tif (link->link_up) {\n\t\tif (atomic_read(&qedf->link_state) == QEDF_LINK_UP) {\n\t\t\tQEDF_INFO((&qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"Ignoring link up event as link is already up.\\n\");\n\t\t\treturn;\n\t\t}\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"LINK UP (%d GB/s).\\n\",\n\t\t    link->speed / 1000);\n\n\t\t \n\t\tcancel_delayed_work(&qedf->link_update);\n\n\t\tatomic_set(&qedf->link_state, QEDF_LINK_UP);\n\t\tqedf_update_link_speed(qedf, link);\n\n\t\tif (atomic_read(&qedf->dcbx) == QEDF_DCBX_DONE ||\n\t\t    qedf_dcbx_no_wait) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t     \"DCBx done.\\n\");\n\t\t\tif (atomic_read(&qedf->link_down_tmo_valid) > 0)\n\t\t\t\tqueue_delayed_work(qedf->link_update_wq,\n\t\t\t\t    &qedf->link_recovery, 0);\n\t\t\telse\n\t\t\t\tqueue_delayed_work(qedf->link_update_wq,\n\t\t\t\t    &qedf->link_update, 0);\n\t\t\tatomic_set(&qedf->link_down_tmo_valid, 0);\n\t\t}\n\n\t} else {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"LINK DOWN.\\n\");\n\n\t\tatomic_set(&qedf->link_state, QEDF_LINK_DOWN);\n\t\tatomic_set(&qedf->dcbx, QEDF_DCBX_PENDING);\n\t\t \n\t\tif (qedf_link_down_tmo > 0) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"Starting link down tmo.\\n\");\n\t\t\tatomic_set(&qedf->link_down_tmo_valid, 1);\n\t\t}\n\t\tqedf->vlan_id = 0;\n\t\tqedf_update_link_speed(qedf, link);\n\t\tqueue_delayed_work(qedf->link_update_wq, &qedf->link_update,\n\t\t    qedf_link_down_tmo * HZ);\n\t}\n}\n\n\nstatic void qedf_dcbx_handler(void *dev, struct qed_dcbx_get *get, u32 mib_type)\n{\n\tstruct qedf_ctx *qedf = (struct qedf_ctx *)dev;\n\tu8 tmp_prio;\n\n\tQEDF_ERR(&(qedf->dbg_ctx), \"DCBx event valid=%d enabled=%d fcoe \"\n\t    \"prio=%d.\\n\", get->operational.valid, get->operational.enabled,\n\t    get->operational.app_prio.fcoe);\n\n\tif (get->operational.enabled && get->operational.valid) {\n\t\t \n\t\tif (atomic_read(&qedf->dcbx) == QEDF_DCBX_DONE) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"DCBX already set on link up.\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\tatomic_set(&qedf->dcbx, QEDF_DCBX_DONE);\n\n\t\t \n\t\ttmp_prio = get->operational.app_prio.fcoe;\n\t\tif (qedf_default_prio > -1)\n\t\t\tqedf->prio = qedf_default_prio;\n\t\telse if (tmp_prio > 7) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"FIP/FCoE prio %d out of range, setting to %d.\\n\",\n\t\t\t    tmp_prio, QEDF_DEFAULT_PRIO);\n\t\t\tqedf->prio = QEDF_DEFAULT_PRIO;\n\t\t} else\n\t\t\tqedf->prio = tmp_prio;\n\n\t\tif (atomic_read(&qedf->link_state) == QEDF_LINK_UP &&\n\t\t    !qedf_dcbx_no_wait) {\n\t\t\tif (atomic_read(&qedf->link_down_tmo_valid) > 0)\n\t\t\t\tqueue_delayed_work(qedf->link_update_wq,\n\t\t\t\t    &qedf->link_recovery, 0);\n\t\t\telse\n\t\t\t\tqueue_delayed_work(qedf->link_update_wq,\n\t\t\t\t    &qedf->link_update, 0);\n\t\t\tatomic_set(&qedf->link_down_tmo_valid, 0);\n\t\t}\n\t}\n\n}\n\nstatic u32 qedf_get_login_failures(void *cookie)\n{\n\tstruct qedf_ctx *qedf;\n\n\tqedf = (struct qedf_ctx *)cookie;\n\treturn qedf->flogi_failed;\n}\n\nstatic struct qed_fcoe_cb_ops qedf_cb_ops = {\n\t{\n\t\t.link_update = qedf_link_update,\n\t\t.bw_update = qedf_bw_update,\n\t\t.schedule_recovery_handler = qedf_schedule_recovery_handler,\n\t\t.dcbx_aen = qedf_dcbx_handler,\n\t\t.get_generic_tlv_data = qedf_get_generic_tlv_data,\n\t\t.get_protocol_tlv_data = qedf_get_protocol_tlv_data,\n\t\t.schedule_hw_err_handler = qedf_schedule_hw_err_handler,\n\t}\n};\n\n \n\nstatic struct scsi_transport_template *qedf_fc_transport_template;\nstatic struct scsi_transport_template *qedf_fc_vport_transport_template;\n\n \nstatic int qedf_eh_abort(struct scsi_cmnd *sc_cmd)\n{\n\tstruct fc_rport *rport = starget_to_rport(scsi_target(sc_cmd->device));\n\tstruct fc_lport *lport;\n\tstruct qedf_ctx *qedf;\n\tstruct qedf_ioreq *io_req;\n\tstruct fc_rport_libfc_priv *rp = rport->dd_data;\n\tstruct fc_rport_priv *rdata;\n\tstruct qedf_rport *fcport = NULL;\n\tint rc = FAILED;\n\tint wait_count = 100;\n\tint refcount = 0;\n\tint rval;\n\tint got_ref = 0;\n\n\tlport = shost_priv(sc_cmd->device->host);\n\tqedf = (struct qedf_ctx *)lport_priv(lport);\n\n\t \n\tfcport = (struct qedf_rport *)&rp[1];\n\trdata = fcport->rdata;\n\tif (!rdata || !kref_get_unless_zero(&rdata->kref)) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"stale rport, sc_cmd=%p\\n\", sc_cmd);\n\t\trc = SUCCESS;\n\t\tgoto out;\n\t}\n\n\n\tio_req = qedf_priv(sc_cmd)->io_req;\n\tif (!io_req) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"sc_cmd not queued with lld, sc_cmd=%p op=0x%02x, port_id=%06x\\n\",\n\t\t\t sc_cmd, sc_cmd->cmnd[0],\n\t\t\t rdata->ids.port_id);\n\t\trc = SUCCESS;\n\t\tgoto drop_rdata_kref;\n\t}\n\n\trval = kref_get_unless_zero(&io_req->refcount);\t \n\tif (rval)\n\t\tgot_ref = 1;\n\n\t \n\tif (!rval || io_req->sc_cmd != sc_cmd) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"Freed/Incorrect io_req, io_req->sc_cmd=%p, sc_cmd=%p, port_id=%06x, bailing out.\\n\",\n\t\t\t io_req->sc_cmd, sc_cmd, rdata->ids.port_id);\n\n\t\tgoto drop_rdata_kref;\n\t}\n\n\tif (fc_remote_port_chkready(rport)) {\n\t\trefcount = kref_read(&io_req->refcount);\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"rport not ready, io_req=%p, xid=0x%x sc_cmd=%p op=0x%02x, refcount=%d, port_id=%06x\\n\",\n\t\t\t io_req, io_req->xid, sc_cmd, sc_cmd->cmnd[0],\n\t\t\t refcount, rdata->ids.port_id);\n\n\t\tgoto drop_rdata_kref;\n\t}\n\n\trc = fc_block_scsi_eh(sc_cmd);\n\tif (rc)\n\t\tgoto drop_rdata_kref;\n\n\tif (test_bit(QEDF_RPORT_UPLOADING_CONNECTION, &fcport->flags)) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"Connection uploading, xid=0x%x., port_id=%06x\\n\",\n\t\t\t io_req->xid, rdata->ids.port_id);\n\t\twhile (io_req->sc_cmd && (wait_count != 0)) {\n\t\t\tmsleep(100);\n\t\t\twait_count--;\n\t\t}\n\t\tif (wait_count) {\n\t\t\tQEDF_ERR(&qedf->dbg_ctx, \"ABTS succeeded\\n\");\n\t\t\trc = SUCCESS;\n\t\t} else {\n\t\t\tQEDF_ERR(&qedf->dbg_ctx, \"ABTS failed\\n\");\n\t\t\trc = FAILED;\n\t\t}\n\t\tgoto drop_rdata_kref;\n\t}\n\n\tif (lport->state != LPORT_ST_READY || !(lport->link_up)) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"link not ready.\\n\");\n\t\tgoto drop_rdata_kref;\n\t}\n\n\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t \"Aborting io_req=%p sc_cmd=%p xid=0x%x fp_idx=%d, port_id=%06x.\\n\",\n\t\t io_req, sc_cmd, io_req->xid, io_req->fp_idx,\n\t\t rdata->ids.port_id);\n\n\tif (qedf->stop_io_on_error) {\n\t\tqedf_stop_all_io(qedf);\n\t\trc = SUCCESS;\n\t\tgoto drop_rdata_kref;\n\t}\n\n\tinit_completion(&io_req->abts_done);\n\trval = qedf_initiate_abts(io_req, true);\n\tif (rval) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Failed to queue ABTS.\\n\");\n\t\t \n\t\trc = SUCCESS;\n\t\tqedf_scsi_done(qedf, io_req, DID_ERROR);\n\t\tgoto drop_rdata_kref;\n\t}\n\n\twait_for_completion(&io_req->abts_done);\n\n\tif (io_req->event == QEDF_IOREQ_EV_ABORT_SUCCESS ||\n\t    io_req->event == QEDF_IOREQ_EV_ABORT_FAILED ||\n\t    io_req->event == QEDF_IOREQ_EV_CLEANUP_SUCCESS) {\n\t\t \n\t\trc = SUCCESS;\n\t} else {\n\t\t \n\t\trc = FAILED;\n\t}\n\n\tif (rc == SUCCESS)\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"ABTS succeeded, xid=0x%x.\\n\",\n\t\t\t  io_req->xid);\n\telse\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"ABTS failed, xid=0x%x.\\n\",\n\t\t\t  io_req->xid);\n\ndrop_rdata_kref:\n\tkref_put(&rdata->kref, fc_rport_destroy);\nout:\n\tif (got_ref)\n\t\tkref_put(&io_req->refcount, qedf_release_cmd);\n\treturn rc;\n}\n\nstatic int qedf_eh_target_reset(struct scsi_cmnd *sc_cmd)\n{\n\tQEDF_ERR(NULL, \"%d:0:%d:%lld: TARGET RESET Issued...\",\n\t\t sc_cmd->device->host->host_no, sc_cmd->device->id,\n\t\t sc_cmd->device->lun);\n\treturn qedf_initiate_tmf(sc_cmd, FCP_TMF_TGT_RESET);\n}\n\nstatic int qedf_eh_device_reset(struct scsi_cmnd *sc_cmd)\n{\n\tQEDF_ERR(NULL, \"%d:0:%d:%lld: LUN RESET Issued... \",\n\t\t sc_cmd->device->host->host_no, sc_cmd->device->id,\n\t\t sc_cmd->device->lun);\n\treturn qedf_initiate_tmf(sc_cmd, FCP_TMF_LUN_RESET);\n}\n\nbool qedf_wait_for_upload(struct qedf_ctx *qedf)\n{\n\tstruct qedf_rport *fcport;\n\tint wait_cnt = 120;\n\n\twhile (wait_cnt--) {\n\t\tif (atomic_read(&qedf->num_offloads))\n\t\t\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t\t\t  \"Waiting for all uploads to complete num_offloads = 0x%x.\\n\",\n\t\t\t\t  atomic_read(&qedf->num_offloads));\n\t\telse\n\t\t\treturn true;\n\t\tmsleep(500);\n\t}\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(fcport, &qedf->fcports, peers) {\n\t\tif (test_bit(QEDF_RPORT_SESSION_READY,\n\t\t\t\t       &fcport->flags)) {\n\t\t\tif (fcport->rdata)\n\t\t\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t\t\t \"Waiting for fcport %p portid=%06x.\\n\",\n\t\t\t\t\t fcport, fcport->rdata->ids.port_id);\n\t\t\t} else {\n\t\t\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t\t\t \"Waiting for fcport %p.\\n\", fcport);\n\t\t\t}\n\t}\n\n\trcu_read_unlock();\n\treturn false;\n}\n\n \nvoid qedf_ctx_soft_reset(struct fc_lport *lport)\n{\n\tstruct qedf_ctx *qedf;\n\tstruct qed_link_output if_link;\n\n\tif (lport->vport) {\n\t\tprintk_ratelimited(\"Cannot issue host reset on NPIV port.\\n\");\n\t\treturn;\n\t}\n\n\tqedf = lport_priv(lport);\n\n\tqedf->flogi_pending = 0;\n\t \n\tatomic_set(&qedf->link_state, QEDF_LINK_DOWN);\n\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t  \"Queuing link down work.\\n\");\n\tqueue_delayed_work(qedf->link_update_wq, &qedf->link_update,\n\t    0);\n\n\tif (qedf_wait_for_upload(qedf) == false) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"Could not upload all sessions.\\n\");\n\t\tWARN_ON(atomic_read(&qedf->num_offloads));\n\t}\n\n\t \n\tqed_ops->common->get_link(qedf->cdev, &if_link);\n\t \n\tif (!if_link.link_up) {\n\t\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t\t  \"Physical link is not up.\\n\");\n\t\treturn;\n\t}\n\t \n\tflush_delayed_work(&qedf->link_update);\n\tmsleep(500);\n\n\tatomic_set(&qedf->link_state, QEDF_LINK_UP);\n\tqedf->vlan_id  = 0;\n\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t  \"Queue link up work.\\n\");\n\tqueue_delayed_work(qedf->link_update_wq, &qedf->link_update,\n\t    0);\n}\n\n \nstatic int qedf_eh_host_reset(struct scsi_cmnd *sc_cmd)\n{\n\tstruct fc_lport *lport;\n\tstruct qedf_ctx *qedf;\n\n\tlport = shost_priv(sc_cmd->device->host);\n\tqedf = lport_priv(lport);\n\n\tif (atomic_read(&qedf->link_state) == QEDF_LINK_DOWN ||\n\t    test_bit(QEDF_UNLOADING, &qedf->flags))\n\t\treturn FAILED;\n\n\tQEDF_ERR(&(qedf->dbg_ctx), \"HOST RESET Issued...\");\n\n\tqedf_ctx_soft_reset(lport);\n\n\treturn SUCCESS;\n}\n\nstatic int qedf_slave_configure(struct scsi_device *sdev)\n{\n\tif (qedf_queue_depth) {\n\t\tscsi_change_queue_depth(sdev, qedf_queue_depth);\n\t}\n\n\treturn 0;\n}\n\nstatic const struct scsi_host_template qedf_host_template = {\n\t.module \t= THIS_MODULE,\n\t.name \t\t= QEDF_MODULE_NAME,\n\t.this_id \t= -1,\n\t.cmd_per_lun\t= 32,\n\t.max_sectors \t= 0xffff,\n\t.queuecommand \t= qedf_queuecommand,\n\t.shost_groups\t= qedf_host_groups,\n\t.eh_abort_handler\t= qedf_eh_abort,\n\t.eh_device_reset_handler = qedf_eh_device_reset,  \n\t.eh_target_reset_handler = qedf_eh_target_reset,  \n\t.eh_host_reset_handler  = qedf_eh_host_reset,\n\t.slave_configure\t= qedf_slave_configure,\n\t.dma_boundary = QED_HW_DMA_BOUNDARY,\n\t.sg_tablesize = QEDF_MAX_BDS_PER_CMD,\n\t.can_queue = FCOE_PARAMS_NUM_TASKS,\n\t.change_queue_depth = scsi_change_queue_depth,\n\t.cmd_size = sizeof(struct qedf_cmd_priv),\n};\n\nstatic int qedf_get_paged_crc_eof(struct sk_buff *skb, int tlen)\n{\n\tint rc;\n\n\tspin_lock(&qedf_global_lock);\n\trc = fcoe_get_paged_crc_eof(skb, tlen, &qedf_global);\n\tspin_unlock(&qedf_global_lock);\n\n\treturn rc;\n}\n\nstatic struct qedf_rport *qedf_fcport_lookup(struct qedf_ctx *qedf, u32 port_id)\n{\n\tstruct qedf_rport *fcport;\n\tstruct fc_rport_priv *rdata;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(fcport, &qedf->fcports, peers) {\n\t\trdata = fcport->rdata;\n\t\tif (rdata == NULL)\n\t\t\tcontinue;\n\t\tif (rdata->ids.port_id == port_id) {\n\t\t\trcu_read_unlock();\n\t\t\treturn fcport;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t \n\treturn NULL;\n}\n\n \nstatic int qedf_xmit_l2_frame(struct qedf_rport *fcport, struct fc_frame *fp)\n{\n\tstruct fc_frame_header *fh;\n\tint rc = 0;\n\n\tfh = fc_frame_header_get(fp);\n\tif ((fh->fh_type == FC_TYPE_ELS) &&\n\t    (fh->fh_r_ctl == FC_RCTL_ELS_REQ)) {\n\t\tswitch (fc_frame_payload_op(fp)) {\n\t\tcase ELS_ADISC:\n\t\t\tqedf_send_adisc(fcport, fp);\n\t\t\trc = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn rc;\n}\n\n \nstatic int qedf_xmit(struct fc_lport *lport, struct fc_frame *fp)\n{\n\tstruct fc_lport\t\t*base_lport;\n\tstruct qedf_ctx\t\t*qedf;\n\tstruct ethhdr\t\t*eh;\n\tstruct fcoe_crc_eof\t*cp;\n\tstruct sk_buff\t\t*skb;\n\tstruct fc_frame_header\t*fh;\n\tstruct fcoe_hdr\t\t*hp;\n\tu8\t\t\tsof, eof;\n\tu32\t\t\tcrc;\n\tunsigned int\t\thlen, tlen, elen;\n\tint\t\t\twlen;\n\tstruct fc_lport *tmp_lport;\n\tstruct fc_lport *vn_port = NULL;\n\tstruct qedf_rport *fcport;\n\tint rc;\n\tu16 vlan_tci = 0;\n\n\tqedf = (struct qedf_ctx *)lport_priv(lport);\n\n\tfh = fc_frame_header_get(fp);\n\tskb = fp_skb(fp);\n\n\t \n\tif (lport->vport)\n\t\tbase_lport = shost_priv(vport_to_shost(lport->vport));\n\telse\n\t\tbase_lport = lport;\n\n\t \n\tif (base_lport->port_id == ntoh24(fh->fh_d_id)) {\n\t\tvn_port = base_lport;\n\t} else {\n\t\t \n\t\tlist_for_each_entry(tmp_lport, &base_lport->vports, list) {\n\t\t\tif (tmp_lport->port_id == ntoh24(fh->fh_d_id)) {\n\t\t\t\tvn_port = tmp_lport;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tif (vn_port && ntoh24(fh->fh_d_id) != FC_FID_FLOGI) {\n\t\tstruct fc_rport_priv *rdata = NULL;\n\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_LL2,\n\t\t    \"Dropping FCoE frame to %06x.\\n\", ntoh24(fh->fh_d_id));\n\t\tkfree_skb(skb);\n\t\trdata = fc_rport_lookup(lport, ntoh24(fh->fh_d_id));\n\t\tif (rdata) {\n\t\t\trdata->retries = lport->max_rport_retry_count;\n\t\t\tkref_put(&rdata->kref, fc_rport_destroy);\n\t\t}\n\t\treturn -EINVAL;\n\t}\n\t \n\n\tif (!qedf->ctlr.sel_fcf) {\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\tif (!test_bit(QEDF_LL2_STARTED, &qedf->flags)) {\n\t\tQEDF_WARN(&(qedf->dbg_ctx), \"LL2 not started\\n\");\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\tif (atomic_read(&qedf->link_state) != QEDF_LINK_UP) {\n\t\tQEDF_WARN(&(qedf->dbg_ctx), \"qedf link down\\n\");\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\tif (unlikely(fh->fh_r_ctl == FC_RCTL_ELS_REQ)) {\n\t\tif (fcoe_ctlr_els_send(&qedf->ctlr, lport, skb))\n\t\t\treturn 0;\n\t}\n\n\t \n\tfcport = qedf_fcport_lookup(qedf, ntoh24(fh->fh_d_id));\n\n\tif (fcport && test_bit(QEDF_RPORT_SESSION_READY, &fcport->flags)) {\n\t\trc = qedf_xmit_l2_frame(fcport, fp);\n\t\t \n\t\tif (rc)\n\t\t\treturn 0;\n\t}\n\n\tsof = fr_sof(fp);\n\teof = fr_eof(fp);\n\n\telen = sizeof(struct ethhdr);\n\thlen = sizeof(struct fcoe_hdr);\n\ttlen = sizeof(struct fcoe_crc_eof);\n\twlen = (skb->len - tlen + sizeof(crc)) / FCOE_WORD_TO_BYTE;\n\n\tskb->ip_summed = CHECKSUM_NONE;\n\tcrc = fcoe_fc_crc(fp);\n\n\t \n\tif (skb_is_nonlinear(skb)) {\n\t\tskb_frag_t *frag;\n\n\t\tif (qedf_get_paged_crc_eof(skb, tlen)) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tfrag = &skb_shinfo(skb)->frags[skb_shinfo(skb)->nr_frags - 1];\n\t\tcp = kmap_atomic(skb_frag_page(frag)) + skb_frag_off(frag);\n\t} else {\n\t\tcp = skb_put(skb, tlen);\n\t}\n\n\tmemset(cp, 0, sizeof(*cp));\n\tcp->fcoe_eof = eof;\n\tcp->fcoe_crc32 = cpu_to_le32(~crc);\n\tif (skb_is_nonlinear(skb)) {\n\t\tkunmap_atomic(cp);\n\t\tcp = NULL;\n\t}\n\n\n\t \n\tskb_push(skb, elen + hlen);\n\tskb_reset_mac_header(skb);\n\tskb_reset_network_header(skb);\n\tskb->mac_len = elen;\n\tskb->protocol = htons(ETH_P_FCOE);\n\n\t \n\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), qedf->vlan_id);\n\n\t \n\teh = eth_hdr(skb);\n\teh->h_proto = htons(ETH_P_FCOE);\n\tif (qedf->ctlr.map_dest)\n\t\tfc_fcoe_set_mac(eh->h_dest, fh->fh_d_id);\n\telse\n\t\t \n\t\tether_addr_copy(eh->h_dest, qedf->ctlr.dest_addr);\n\n\t \n\tether_addr_copy(eh->h_source, qedf->data_src_addr);\n\n\thp = (struct fcoe_hdr *)(eh + 1);\n\tmemset(hp, 0, sizeof(*hp));\n\tif (FC_FCOE_VER)\n\t\tFC_FCOE_ENCAPS_VER(hp, FC_FCOE_VER);\n\thp->fcoe_sof = sof;\n\n\t \n\tthis_cpu_inc(lport->stats->TxFrames);\n\tthis_cpu_add(lport->stats->TxWords, wlen);\n\n\t \n\t__vlan_hwaccel_get_tag(skb, &vlan_tci);\n\n\t \n\tfr_dev(fp) = lport;\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_LL2, \"FCoE frame send: \"\n\t    \"src=%06x dest=%06x r_ctl=%x type=%x vlan=%04x.\\n\",\n\t    ntoh24(fh->fh_s_id), ntoh24(fh->fh_d_id), fh->fh_r_ctl, fh->fh_type,\n\t    vlan_tci);\n\tif (qedf_dump_frames)\n\t\tprint_hex_dump(KERN_WARNING, \"fcoe: \", DUMP_PREFIX_OFFSET, 16,\n\t\t    1, skb->data, skb->len, false);\n\trc = qed_ops->ll2->start_xmit(qedf->cdev, skb, 0);\n\tif (rc) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"start_xmit failed rc = %d.\\n\", rc);\n\t\tkfree_skb(skb);\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int qedf_alloc_sq(struct qedf_ctx *qedf, struct qedf_rport *fcport)\n{\n\tint rval = 0;\n\tu32 *pbl;\n\tdma_addr_t page;\n\tint num_pages;\n\n\t \n\tfcport->sq_mem_size = SQ_NUM_ENTRIES * sizeof(struct fcoe_wqe);\n\tfcport->sq_mem_size = ALIGN(fcport->sq_mem_size, QEDF_PAGE_SIZE);\n\tfcport->sq_pbl_size = (fcport->sq_mem_size / QEDF_PAGE_SIZE) *\n\t    sizeof(void *);\n\tfcport->sq_pbl_size = fcport->sq_pbl_size + QEDF_PAGE_SIZE;\n\n\tfcport->sq = dma_alloc_coherent(&qedf->pdev->dev, fcport->sq_mem_size,\n\t\t\t\t\t&fcport->sq_dma, GFP_KERNEL);\n\tif (!fcport->sq) {\n\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Could not allocate send queue.\\n\");\n\t\trval = 1;\n\t\tgoto out;\n\t}\n\n\tfcport->sq_pbl = dma_alloc_coherent(&qedf->pdev->dev,\n\t\t\t\t\t    fcport->sq_pbl_size,\n\t\t\t\t\t    &fcport->sq_pbl_dma, GFP_KERNEL);\n\tif (!fcport->sq_pbl) {\n\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Could not allocate send queue PBL.\\n\");\n\t\trval = 1;\n\t\tgoto out_free_sq;\n\t}\n\n\t \n\tnum_pages = fcport->sq_mem_size / QEDF_PAGE_SIZE;\n\tpage = fcport->sq_dma;\n\tpbl = (u32 *)fcport->sq_pbl;\n\n\twhile (num_pages--) {\n\t\t*pbl = U64_LO(page);\n\t\tpbl++;\n\t\t*pbl = U64_HI(page);\n\t\tpbl++;\n\t\tpage += QEDF_PAGE_SIZE;\n\t}\n\n\treturn rval;\n\nout_free_sq:\n\tdma_free_coherent(&qedf->pdev->dev, fcport->sq_mem_size, fcport->sq,\n\t    fcport->sq_dma);\nout:\n\treturn rval;\n}\n\nstatic void qedf_free_sq(struct qedf_ctx *qedf, struct qedf_rport *fcport)\n{\n\tif (fcport->sq_pbl)\n\t\tdma_free_coherent(&qedf->pdev->dev, fcport->sq_pbl_size,\n\t\t    fcport->sq_pbl, fcport->sq_pbl_dma);\n\tif (fcport->sq)\n\t\tdma_free_coherent(&qedf->pdev->dev, fcport->sq_mem_size,\n\t\t    fcport->sq, fcport->sq_dma);\n}\n\nstatic int qedf_offload_connection(struct qedf_ctx *qedf,\n\tstruct qedf_rport *fcport)\n{\n\tstruct qed_fcoe_params_offload conn_info;\n\tu32 port_id;\n\tint rval;\n\tuint16_t total_sqe = (fcport->sq_mem_size / sizeof(struct fcoe_wqe));\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_CONN, \"Offloading connection \"\n\t\t   \"portid=%06x.\\n\", fcport->rdata->ids.port_id);\n\trval = qed_ops->acquire_conn(qedf->cdev, &fcport->handle,\n\t    &fcport->fw_cid, &fcport->p_doorbell);\n\tif (rval) {\n\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Could not acquire connection \"\n\t\t\t   \"for portid=%06x.\\n\", fcport->rdata->ids.port_id);\n\t\trval = 1;  \n\t\tgoto out;\n\t}\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_CONN, \"portid=%06x \"\n\t\t   \"fw_cid=%08x handle=%d.\\n\", fcport->rdata->ids.port_id,\n\t\t   fcport->fw_cid, fcport->handle);\n\n\tmemset(&conn_info, 0, sizeof(struct qed_fcoe_params_offload));\n\n\t \n\tconn_info.sq_pbl_addr = fcport->sq_pbl_dma;\n\n\tconn_info.sq_curr_page_addr = (dma_addr_t)(*(u64 *)fcport->sq_pbl);\n\tconn_info.sq_next_page_addr =\n\t    (dma_addr_t)(*(u64 *)(fcport->sq_pbl + 8));\n\n\t \n\tether_addr_copy(conn_info.src_mac, qedf->data_src_addr);\n\n\tether_addr_copy(conn_info.dst_mac, qedf->ctlr.dest_addr);\n\n\tconn_info.tx_max_fc_pay_len = fcport->rdata->maxframe_size;\n\tconn_info.e_d_tov_timer_val = qedf->lport->e_d_tov;\n\tconn_info.rec_tov_timer_val = 3;  \n\tconn_info.rx_max_fc_pay_len = fcport->rdata->maxframe_size;\n\n\t \n\tconn_info.vlan_tag = qedf->vlan_id <<\n\t    FCOE_CONN_OFFLOAD_RAMROD_DATA_VLAN_ID_SHIFT;\n\tconn_info.vlan_tag |=\n\t    qedf->prio << FCOE_CONN_OFFLOAD_RAMROD_DATA_PRIORITY_SHIFT;\n\tconn_info.flags |= (FCOE_CONN_OFFLOAD_RAMROD_DATA_B_VLAN_FLAG_MASK <<\n\t    FCOE_CONN_OFFLOAD_RAMROD_DATA_B_VLAN_FLAG_SHIFT);\n\n\t \n\tport_id = fc_host_port_id(qedf->lport->host);\n\tfcport->sid = port_id;\n\tconn_info.s_id.addr_hi = (port_id & 0x000000FF);\n\tconn_info.s_id.addr_mid = (port_id & 0x0000FF00) >> 8;\n\tconn_info.s_id.addr_lo = (port_id & 0x00FF0000) >> 16;\n\n\tconn_info.max_conc_seqs_c3 = fcport->rdata->max_seq;\n\n\t \n\tport_id = fcport->rdata->rport->port_id;\n\tconn_info.d_id.addr_hi = (port_id & 0x000000FF);\n\tconn_info.d_id.addr_mid = (port_id & 0x0000FF00) >> 8;\n\tconn_info.d_id.addr_lo = (port_id & 0x00FF0000) >> 16;\n\n\tconn_info.def_q_idx = 0;  \n\n\t \n\tif (fcport->dev_type == QEDF_RPORT_TYPE_TAPE) {\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_CONN,\n\t\t    \"Enable CONF, REC for portid=%06x.\\n\",\n\t\t    fcport->rdata->ids.port_id);\n\t\tconn_info.flags |= 1 <<\n\t\t    FCOE_CONN_OFFLOAD_RAMROD_DATA_B_CONF_REQ_SHIFT;\n\t\tconn_info.flags |=\n\t\t    ((fcport->rdata->sp_features & FC_SP_FT_SEQC) ? 1 : 0) <<\n\t\t    FCOE_CONN_OFFLOAD_RAMROD_DATA_B_REC_VALID_SHIFT;\n\t}\n\n\trval = qed_ops->offload_conn(qedf->cdev, fcport->handle, &conn_info);\n\tif (rval) {\n\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Could not offload connection \"\n\t\t\t   \"for portid=%06x.\\n\", fcport->rdata->ids.port_id);\n\t\tgoto out_free_conn;\n\t} else\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_CONN, \"Offload \"\n\t\t\t   \"succeeded portid=%06x total_sqe=%d.\\n\",\n\t\t\t   fcport->rdata->ids.port_id, total_sqe);\n\n\tspin_lock_init(&fcport->rport_lock);\n\tatomic_set(&fcport->free_sqes, total_sqe);\n\treturn 0;\nout_free_conn:\n\tqed_ops->release_conn(qedf->cdev, fcport->handle);\nout:\n\treturn rval;\n}\n\n#define QEDF_TERM_BUFF_SIZE\t\t10\nstatic void qedf_upload_connection(struct qedf_ctx *qedf,\n\tstruct qedf_rport *fcport)\n{\n\tvoid *term_params;\n\tdma_addr_t term_params_dma;\n\n\t \n\tterm_params = dma_alloc_coherent(&qedf->pdev->dev, QEDF_TERM_BUFF_SIZE,\n\t\t&term_params_dma, GFP_KERNEL);\n\tif (!term_params)\n\t\treturn;\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_CONN, \"Uploading connection \"\n\t\t   \"port_id=%06x.\\n\", fcport->rdata->ids.port_id);\n\n\tqed_ops->destroy_conn(qedf->cdev, fcport->handle, term_params_dma);\n\tqed_ops->release_conn(qedf->cdev, fcport->handle);\n\n\tdma_free_coherent(&qedf->pdev->dev, QEDF_TERM_BUFF_SIZE, term_params,\n\t    term_params_dma);\n}\n\nstatic void qedf_cleanup_fcport(struct qedf_ctx *qedf,\n\tstruct qedf_rport *fcport)\n{\n\tstruct fc_rport_priv *rdata = fcport->rdata;\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_CONN, \"Cleaning up portid=%06x.\\n\",\n\t    fcport->rdata->ids.port_id);\n\n\t \n\tqedf_flush_active_ios(fcport, -1);\n\n\tif (test_and_clear_bit(QEDF_RPORT_SESSION_READY, &fcport->flags))\n\t\tqedf_upload_connection(qedf, fcport);\n\tqedf_free_sq(qedf, fcport);\n\tfcport->rdata = NULL;\n\tfcport->qedf = NULL;\n\tkref_put(&rdata->kref, fc_rport_destroy);\n}\n\n \nstatic void qedf_rport_event_handler(struct fc_lport *lport,\n\t\t\t\tstruct fc_rport_priv *rdata,\n\t\t\t\tenum fc_rport_event event)\n{\n\tstruct qedf_ctx *qedf = lport_priv(lport);\n\tstruct fc_rport *rport = rdata->rport;\n\tstruct fc_rport_libfc_priv *rp;\n\tstruct qedf_rport *fcport;\n\tu32 port_id;\n\tint rval;\n\tunsigned long flags;\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC, \"event = %d, \"\n\t\t   \"port_id = 0x%x\\n\", event, rdata->ids.port_id);\n\n\tswitch (event) {\n\tcase RPORT_EV_READY:\n\t\tif (!rport) {\n\t\t\tQEDF_WARN(&(qedf->dbg_ctx), \"rport is NULL.\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\trp = rport->dd_data;\n\t\tfcport = (struct qedf_rport *)&rp[1];\n\t\tfcport->qedf = qedf;\n\n\t\tif (atomic_read(&qedf->num_offloads) >= QEDF_MAX_SESSIONS) {\n\t\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Not offloading \"\n\t\t\t    \"portid=0x%x as max number of offloaded sessions \"\n\t\t\t    \"reached.\\n\", rdata->ids.port_id);\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tif (test_bit(QEDF_RPORT_SESSION_READY, &fcport->flags)) {\n\t\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Session already \"\n\t\t\t\t   \"offloaded, portid=0x%x.\\n\",\n\t\t\t\t   rdata->ids.port_id);\n\t\t\treturn;\n\t\t}\n\n\t\tif (rport->port_id == FC_FID_DIR_SERV) {\n\t\t\t \n\t\t\tQEDF_WARN(&(qedf->dbg_ctx), \"rport struct does not \"\n\t\t\t    \"exist for dir server port_id=%x\\n\",\n\t\t\t    rdata->ids.port_id);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (rdata->spp_type != FC_TYPE_FCP) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"Not offloading since spp type isn't FCP\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tif (!(rdata->ids.roles & FC_RPORT_ROLE_FCP_TARGET)) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"Not FCP target so not offloading\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tkref_get(&rdata->kref);\n\t\tfcport->rdata = rdata;\n\t\tfcport->rport = rport;\n\n\t\trval = qedf_alloc_sq(qedf, fcport);\n\t\tif (rval) {\n\t\t\tqedf_cleanup_fcport(qedf, fcport);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (rdata->flags & FC_RP_FLAGS_RETRY &&\n\t\t    rdata->ids.roles & FC_RPORT_ROLE_FCP_TARGET &&\n\t\t    !(rdata->ids.roles & FC_RPORT_ROLE_FCP_INITIATOR)) {\n\t\t\tfcport->dev_type = QEDF_RPORT_TYPE_TAPE;\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"portid=%06x is a TAPE device.\\n\",\n\t\t\t    rdata->ids.port_id);\n\t\t} else {\n\t\t\tfcport->dev_type = QEDF_RPORT_TYPE_DISK;\n\t\t}\n\n\t\trval = qedf_offload_connection(qedf, fcport);\n\t\tif (rval) {\n\t\t\tqedf_cleanup_fcport(qedf, fcport);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tspin_lock_irqsave(&qedf->hba_lock, flags);\n\t\tlist_add_rcu(&fcport->peers, &qedf->fcports);\n\t\tspin_unlock_irqrestore(&qedf->hba_lock, flags);\n\n\t\t \n\t\tset_bit(QEDF_RPORT_SESSION_READY, &fcport->flags);\n\t\tatomic_inc(&qedf->num_offloads);\n\n\t\tbreak;\n\tcase RPORT_EV_LOGO:\n\tcase RPORT_EV_FAILED:\n\tcase RPORT_EV_STOP:\n\t\tport_id = rdata->ids.port_id;\n\t\tif (port_id == FC_FID_DIR_SERV)\n\t\t\tbreak;\n\n\t\tif (rdata->spp_type != FC_TYPE_FCP) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"No action since spp type isn't FCP\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tif (!(rdata->ids.roles & FC_RPORT_ROLE_FCP_TARGET)) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"Not FCP target so no action\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!rport) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"port_id=%x - rport notcreated Yet!!\\n\", port_id);\n\t\t\tbreak;\n\t\t}\n\t\trp = rport->dd_data;\n\t\t \n\t\tfcport = (struct qedf_rport *)&rp[1];\n\n\t\tspin_lock_irqsave(&fcport->rport_lock, flags);\n\t\t \n\t\tif (test_bit(QEDF_RPORT_SESSION_READY, &fcport->flags) &&\n\t\t    !test_bit(QEDF_RPORT_UPLOADING_CONNECTION,\n\t\t    &fcport->flags)) {\n\t\t\tset_bit(QEDF_RPORT_UPLOADING_CONNECTION,\n\t\t\t\t&fcport->flags);\n\t\t\tspin_unlock_irqrestore(&fcport->rport_lock, flags);\n\t\t\tqedf_cleanup_fcport(qedf, fcport);\n\t\t\t \n\t\t\tspin_lock_irqsave(&qedf->hba_lock, flags);\n\t\t\tlist_del_rcu(&fcport->peers);\n\t\t\tspin_unlock_irqrestore(&qedf->hba_lock, flags);\n\n\t\t\tclear_bit(QEDF_RPORT_UPLOADING_CONNECTION,\n\t\t\t    &fcport->flags);\n\t\t\tatomic_dec(&qedf->num_offloads);\n\t\t} else {\n\t\t\tspin_unlock_irqrestore(&fcport->rport_lock, flags);\n\t\t}\n\t\tbreak;\n\n\tcase RPORT_EV_NONE:\n\t\tbreak;\n\t}\n}\n\nstatic void qedf_abort_io(struct fc_lport *lport)\n{\n\t \n}\n\nstatic void qedf_fcp_cleanup(struct fc_lport *lport)\n{\n\t \n}\n\nstatic struct libfc_function_template qedf_lport_template = {\n\t.frame_send\t\t= qedf_xmit,\n\t.fcp_abort_io\t\t= qedf_abort_io,\n\t.fcp_cleanup\t\t= qedf_fcp_cleanup,\n\t.rport_event_callback\t= qedf_rport_event_handler,\n\t.elsct_send\t\t= qedf_elsct_send,\n};\n\nstatic void qedf_fcoe_ctlr_setup(struct qedf_ctx *qedf)\n{\n\tfcoe_ctlr_init(&qedf->ctlr, FIP_MODE_AUTO);\n\n\tqedf->ctlr.send = qedf_fip_send;\n\tqedf->ctlr.get_src_addr = qedf_get_src_mac;\n\tether_addr_copy(qedf->ctlr.ctl_src_addr, qedf->mac);\n}\n\nstatic void qedf_setup_fdmi(struct qedf_ctx *qedf)\n{\n\tstruct fc_lport *lport = qedf->lport;\n\tu8 buf[8];\n\tint pos;\n\tuint32_t i;\n\n\t \n\tlport->fdmi_enabled = 1;\n\n\t \n\n\t \n\tpos = pci_find_ext_capability(qedf->pdev, PCI_EXT_CAP_ID_DSN);\n\tif (pos) {\n\t\tpos += 4;\n\t\tfor (i = 0; i < 8; i++)\n\t\t\tpci_read_config_byte(qedf->pdev, pos + i, &buf[i]);\n\n\t\tsnprintf(fc_host_serial_number(lport->host),\n\t\t    FC_SERIAL_NUMBER_SIZE,\n\t\t    \"%02X%02X%02X%02X%02X%02X%02X%02X\",\n\t\t    buf[7], buf[6], buf[5], buf[4],\n\t\t    buf[3], buf[2], buf[1], buf[0]);\n\t} else\n\t\tsnprintf(fc_host_serial_number(lport->host),\n\t\t    FC_SERIAL_NUMBER_SIZE, \"Unknown\");\n\n\tsnprintf(fc_host_manufacturer(lport->host),\n\t    FC_SERIAL_NUMBER_SIZE, \"%s\", \"Marvell Semiconductor Inc.\");\n\n\tif (qedf->pdev->device == QL45xxx) {\n\t\tsnprintf(fc_host_model(lport->host),\n\t\t\tFC_SYMBOLIC_NAME_SIZE, \"%s\", \"QL45xxx\");\n\n\t\tsnprintf(fc_host_model_description(lport->host),\n\t\t\tFC_SYMBOLIC_NAME_SIZE, \"%s\",\n\t\t\t\"Marvell FastLinQ QL45xxx FCoE Adapter\");\n\t}\n\n\tif (qedf->pdev->device == QL41xxx) {\n\t\tsnprintf(fc_host_model(lport->host),\n\t\t\tFC_SYMBOLIC_NAME_SIZE, \"%s\", \"QL41xxx\");\n\n\t\tsnprintf(fc_host_model_description(lport->host),\n\t\t\tFC_SYMBOLIC_NAME_SIZE, \"%s\",\n\t\t\t\"Marvell FastLinQ QL41xxx FCoE Adapter\");\n\t}\n\n\tsnprintf(fc_host_hardware_version(lport->host),\n\t    FC_VERSION_STRING_SIZE, \"Rev %d\", qedf->pdev->revision);\n\n\tsnprintf(fc_host_driver_version(lport->host),\n\t    FC_VERSION_STRING_SIZE, \"%s\", QEDF_VERSION);\n\n\tsnprintf(fc_host_firmware_version(lport->host),\n\t    FC_VERSION_STRING_SIZE, \"%d.%d.%d.%d\",\n\t    FW_MAJOR_VERSION, FW_MINOR_VERSION, FW_REVISION_VERSION,\n\t    FW_ENGINEERING_VERSION);\n\n\tsnprintf(fc_host_vendor_identifier(lport->host),\n\t\tFC_VENDOR_IDENTIFIER, \"%s\", \"Marvell\");\n\n}\n\nstatic int qedf_lport_setup(struct qedf_ctx *qedf)\n{\n\tstruct fc_lport *lport = qedf->lport;\n\n\tlport->link_up = 0;\n\tlport->max_retry_count = QEDF_FLOGI_RETRY_CNT;\n\tlport->max_rport_retry_count = QEDF_RPORT_RETRY_CNT;\n\tlport->service_params = (FCP_SPPF_INIT_FCN | FCP_SPPF_RD_XRDY_DIS |\n\t    FCP_SPPF_RETRY | FCP_SPPF_CONF_COMPL);\n\tlport->boot_time = jiffies;\n\tlport->e_d_tov = 2 * 1000;\n\tlport->r_a_tov = 10 * 1000;\n\n\t \n\tlport->does_npiv = 1;\n\tfc_host_max_npiv_vports(lport->host) = QEDF_MAX_NPIV;\n\n\tfc_set_wwnn(lport, qedf->wwnn);\n\tfc_set_wwpn(lport, qedf->wwpn);\n\n\tif (fcoe_libfc_config(lport, &qedf->ctlr, &qedf_lport_template, 0)) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"fcoe_libfc_config failed.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tfc_exch_mgr_alloc(lport, FC_CLASS_3, FCOE_PARAMS_NUM_TASKS,\n\t\t\t  0xfffe, NULL);\n\n\tif (fc_lport_init_stats(lport))\n\t\treturn -ENOMEM;\n\n\t \n\tfc_lport_config(lport);\n\n\t \n\tfc_set_mfs(lport, QEDF_MFS);\n\tfc_host_maxframe_size(lport->host) = lport->mfs;\n\n\t \n\tfc_host_dev_loss_tmo(lport->host) = qedf_dev_loss_tmo;\n\n\t \n\tif (qedf->pdev->device == QL45xxx)\n\t\tsnprintf(fc_host_symbolic_name(lport->host), 256,\n\t\t\t\"Marvell FastLinQ 45xxx FCoE v%s\", QEDF_VERSION);\n\n\tif (qedf->pdev->device == QL41xxx)\n\t\tsnprintf(fc_host_symbolic_name(lport->host), 256,\n\t\t\t\"Marvell FastLinQ 41xxx FCoE v%s\", QEDF_VERSION);\n\n\tqedf_setup_fdmi(qedf);\n\n\treturn 0;\n}\n\n \n\nstatic int qedf_vport_libfc_config(struct fc_vport *vport,\n\tstruct fc_lport *lport)\n{\n\tlport->link_up = 0;\n\tlport->qfull = 0;\n\tlport->max_retry_count = QEDF_FLOGI_RETRY_CNT;\n\tlport->max_rport_retry_count = QEDF_RPORT_RETRY_CNT;\n\tlport->service_params = (FCP_SPPF_INIT_FCN | FCP_SPPF_RD_XRDY_DIS |\n\t    FCP_SPPF_RETRY | FCP_SPPF_CONF_COMPL);\n\tlport->boot_time = jiffies;\n\tlport->e_d_tov = 2 * 1000;\n\tlport->r_a_tov = 10 * 1000;\n\tlport->does_npiv = 1;  \n\n\t \n\tif (fc_lport_init_stats(lport))\n\t\treturn -ENOMEM;\n\n\t \n\tfc_lport_config(lport);\n\n\t \n\tlport->crc_offload = 0;\n\tlport->seq_offload = 0;\n\tlport->lro_enabled = 0;\n\tlport->lro_xid = 0;\n\tlport->lso_max = 0;\n\n\treturn 0;\n}\n\nstatic int qedf_vport_create(struct fc_vport *vport, bool disabled)\n{\n\tstruct Scsi_Host *shost = vport_to_shost(vport);\n\tstruct fc_lport *n_port = shost_priv(shost);\n\tstruct fc_lport *vn_port;\n\tstruct qedf_ctx *base_qedf = lport_priv(n_port);\n\tstruct qedf_ctx *vport_qedf;\n\n\tchar buf[32];\n\tint rc = 0;\n\n\trc = fcoe_validate_vport_create(vport);\n\tif (rc) {\n\t\tfcoe_wwn_to_str(vport->port_name, buf, sizeof(buf));\n\t\tQEDF_WARN(&(base_qedf->dbg_ctx), \"Failed to create vport, \"\n\t\t\t   \"WWPN (0x%s) already exists.\\n\", buf);\n\t\treturn rc;\n\t}\n\n\tif (atomic_read(&base_qedf->link_state) != QEDF_LINK_UP) {\n\t\tQEDF_WARN(&(base_qedf->dbg_ctx), \"Cannot create vport \"\n\t\t\t   \"because link is not up.\\n\");\n\t\treturn -EIO;\n\t}\n\n\tvn_port = libfc_vport_create(vport, sizeof(struct qedf_ctx));\n\tif (!vn_port) {\n\t\tQEDF_WARN(&(base_qedf->dbg_ctx), \"Could not create lport \"\n\t\t\t   \"for vport.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tfcoe_wwn_to_str(vport->port_name, buf, sizeof(buf));\n\tQEDF_ERR(&(base_qedf->dbg_ctx), \"Creating NPIV port, WWPN=%s.\\n\",\n\t    buf);\n\n\t \n\tvport_qedf = lport_priv(vn_port);\n\tmemcpy(vport_qedf, base_qedf, sizeof(struct qedf_ctx));\n\n\t \n\tvport_qedf->lport = vn_port;\n\t \n\tvport_qedf->hba_lock = base_qedf->hba_lock;\n\tvport_qedf->pdev = base_qedf->pdev;\n\tvport_qedf->cmd_mgr = base_qedf->cmd_mgr;\n\tinit_completion(&vport_qedf->flogi_compl);\n\tINIT_LIST_HEAD(&vport_qedf->fcports);\n\tINIT_DELAYED_WORK(&vport_qedf->stag_work, qedf_stag_change_work);\n\n\trc = qedf_vport_libfc_config(vport, vn_port);\n\tif (rc) {\n\t\tQEDF_ERR(&(base_qedf->dbg_ctx), \"Could not allocate memory \"\n\t\t    \"for lport stats.\\n\");\n\t\tgoto err;\n\t}\n\n\tfc_set_wwnn(vn_port, vport->node_name);\n\tfc_set_wwpn(vn_port, vport->port_name);\n\tvport_qedf->wwnn = vn_port->wwnn;\n\tvport_qedf->wwpn = vn_port->wwpn;\n\n\tvn_port->host->transportt = qedf_fc_vport_transport_template;\n\tvn_port->host->can_queue = FCOE_PARAMS_NUM_TASKS;\n\tvn_port->host->max_lun = qedf_max_lun;\n\tvn_port->host->sg_tablesize = QEDF_MAX_BDS_PER_CMD;\n\tvn_port->host->max_cmd_len = QEDF_MAX_CDB_LEN;\n\tvn_port->host->max_id = QEDF_MAX_SESSIONS;\n\n\trc = scsi_add_host(vn_port->host, &vport->dev);\n\tif (rc) {\n\t\tQEDF_WARN(&base_qedf->dbg_ctx,\n\t\t\t  \"Error adding Scsi_Host rc=0x%x.\\n\", rc);\n\t\tgoto err;\n\t}\n\n\t \n\tfc_host_dev_loss_tmo(vn_port->host) = qedf_dev_loss_tmo;\n\n\t \n\tmemcpy(&vn_port->tt, &qedf_lport_template,\n\t\tsizeof(qedf_lport_template));\n\tfc_exch_init(vn_port);\n\tfc_elsct_init(vn_port);\n\tfc_lport_init(vn_port);\n\tfc_disc_init(vn_port);\n\tfc_disc_config(vn_port, vn_port);\n\n\n\t \n\tshost = vport_to_shost(vport);\n\tn_port = shost_priv(shost);\n\tfc_exch_mgr_list_clone(n_port, vn_port);\n\n\t \n\tfc_set_mfs(vn_port, QEDF_MFS);\n\n\tfc_host_port_type(vn_port->host) = FC_PORTTYPE_UNKNOWN;\n\n\tif (disabled) {\n\t\tfc_vport_set_state(vport, FC_VPORT_DISABLED);\n\t} else {\n\t\tvn_port->boot_time = jiffies;\n\t\tfc_fabric_login(vn_port);\n\t\tfc_vport_setlink(vn_port);\n\t}\n\n\t \n\tif (base_qedf->pdev->device == QL45xxx)\n\t\tsnprintf(fc_host_symbolic_name(vn_port->host), 256,\n\t\t\t \"Marvell FastLinQ 45xxx FCoE v%s\", QEDF_VERSION);\n\n\tif (base_qedf->pdev->device == QL41xxx)\n\t\tsnprintf(fc_host_symbolic_name(vn_port->host), 256,\n\t\t\t \"Marvell FastLinQ 41xxx FCoE v%s\", QEDF_VERSION);\n\n\t \n\tfc_host_supported_speeds(vn_port->host) = n_port->link_supported_speeds;\n\n\t \n\tvn_port->link_speed = n_port->link_speed;\n\n\t \n\tfc_host_port_type(vn_port->host) = FC_PORTTYPE_NPIV;\n\n\t \n\tfc_host_maxframe_size(vn_port->host) = n_port->mfs;\n\n\tQEDF_INFO(&(base_qedf->dbg_ctx), QEDF_LOG_NPIV, \"vn_port=%p.\\n\",\n\t\t   vn_port);\n\n\t \n\tvport_qedf->dbg_ctx.host_no = vn_port->host->host_no;\n\tvport_qedf->dbg_ctx.pdev = base_qedf->pdev;\n\n\treturn 0;\n\nerr:\n\tscsi_host_put(vn_port->host);\n\treturn rc;\n}\n\nstatic int qedf_vport_destroy(struct fc_vport *vport)\n{\n\tstruct Scsi_Host *shost = vport_to_shost(vport);\n\tstruct fc_lport *n_port = shost_priv(shost);\n\tstruct fc_lport *vn_port = vport->dd_data;\n\tstruct qedf_ctx *qedf = lport_priv(vn_port);\n\n\tif (!qedf) {\n\t\tQEDF_ERR(NULL, \"qedf is NULL.\\n\");\n\t\tgoto out;\n\t}\n\n\t \n\tset_bit(QEDF_UNLOADING, &qedf->flags);\n\n\tmutex_lock(&n_port->lp_mutex);\n\tlist_del(&vn_port->list);\n\tmutex_unlock(&n_port->lp_mutex);\n\n\tfc_fabric_logoff(vn_port);\n\tfc_lport_destroy(vn_port);\n\n\t \n\tfc_remove_host(vn_port->host);\n\tscsi_remove_host(vn_port->host);\n\n\t \n\tif (vn_port->state == LPORT_ST_READY)\n\t\tfc_exch_mgr_free(vn_port);\n\n\t \n\tfc_lport_free_stats(vn_port);\n\n\t \n\tscsi_host_put(vn_port->host);\n\nout:\n\treturn 0;\n}\n\nstatic int qedf_vport_disable(struct fc_vport *vport, bool disable)\n{\n\tstruct fc_lport *lport = vport->dd_data;\n\n\tif (disable) {\n\t\tfc_vport_set_state(vport, FC_VPORT_DISABLED);\n\t\tfc_fabric_logoff(lport);\n\t} else {\n\t\tlport->boot_time = jiffies;\n\t\tfc_fabric_login(lport);\n\t\tfc_vport_setlink(lport);\n\t}\n\treturn 0;\n}\n\n \nstatic void qedf_wait_for_vport_destroy(struct qedf_ctx *qedf)\n{\n\tstruct fc_host_attrs *fc_host = shost_to_fc_host(qedf->lport->host);\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_NPIV,\n\t    \"Entered.\\n\");\n\twhile (fc_host->npiv_vports_inuse > 0) {\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_NPIV,\n\t\t    \"Waiting for all vports to be reaped.\\n\");\n\t\tmsleep(1000);\n\t}\n}\n\n \nstatic int qedf_fcoe_reset(struct Scsi_Host *shost)\n{\n\tstruct fc_lport *lport = shost_priv(shost);\n\n\tqedf_ctx_soft_reset(lport);\n\treturn 0;\n}\n\nstatic void qedf_get_host_port_id(struct Scsi_Host *shost)\n{\n\tstruct fc_lport *lport = shost_priv(shost);\n\n\tfc_host_port_id(shost) = lport->port_id;\n}\n\nstatic struct fc_host_statistics *qedf_fc_get_host_stats(struct Scsi_Host\n\t*shost)\n{\n\tstruct fc_host_statistics *qedf_stats;\n\tstruct fc_lport *lport = shost_priv(shost);\n\tstruct qedf_ctx *qedf = lport_priv(lport);\n\tstruct qed_fcoe_stats *fw_fcoe_stats;\n\n\tqedf_stats = fc_get_host_stats(shost);\n\n\t \n\tif (lport->vport)\n\t\tgoto out;\n\n\tfw_fcoe_stats = kmalloc(sizeof(struct qed_fcoe_stats), GFP_KERNEL);\n\tif (!fw_fcoe_stats) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Could not allocate memory for \"\n\t\t    \"fw_fcoe_stats.\\n\");\n\t\tgoto out;\n\t}\n\n\tmutex_lock(&qedf->stats_mutex);\n\n\t \n\tqed_ops->get_stats(qedf->cdev, fw_fcoe_stats);\n\n\t \n\tqedf_stats->tx_frames += fw_fcoe_stats->fcoe_tx_data_pkt_cnt +\n\t    fw_fcoe_stats->fcoe_tx_xfer_pkt_cnt +\n\t    fw_fcoe_stats->fcoe_tx_other_pkt_cnt;\n\tqedf_stats->rx_frames += fw_fcoe_stats->fcoe_rx_data_pkt_cnt +\n\t    fw_fcoe_stats->fcoe_rx_xfer_pkt_cnt +\n\t    fw_fcoe_stats->fcoe_rx_other_pkt_cnt;\n\tqedf_stats->fcp_input_megabytes +=\n\t    do_div(fw_fcoe_stats->fcoe_rx_byte_cnt, 1000000);\n\tqedf_stats->fcp_output_megabytes +=\n\t    do_div(fw_fcoe_stats->fcoe_tx_byte_cnt, 1000000);\n\tqedf_stats->rx_words += fw_fcoe_stats->fcoe_rx_byte_cnt / 4;\n\tqedf_stats->tx_words += fw_fcoe_stats->fcoe_tx_byte_cnt / 4;\n\tqedf_stats->invalid_crc_count +=\n\t    fw_fcoe_stats->fcoe_silent_drop_pkt_crc_error_cnt;\n\tqedf_stats->dumped_frames =\n\t    fw_fcoe_stats->fcoe_silent_drop_total_pkt_cnt;\n\tqedf_stats->error_frames +=\n\t    fw_fcoe_stats->fcoe_silent_drop_total_pkt_cnt;\n\tqedf_stats->fcp_input_requests += qedf->input_requests;\n\tqedf_stats->fcp_output_requests += qedf->output_requests;\n\tqedf_stats->fcp_control_requests += qedf->control_requests;\n\tqedf_stats->fcp_packet_aborts += qedf->packet_aborts;\n\tqedf_stats->fcp_frame_alloc_failures += qedf->alloc_failures;\n\n\tmutex_unlock(&qedf->stats_mutex);\n\tkfree(fw_fcoe_stats);\nout:\n\treturn qedf_stats;\n}\n\nstatic struct fc_function_template qedf_fc_transport_fn = {\n\t.show_host_node_name = 1,\n\t.show_host_port_name = 1,\n\t.show_host_supported_classes = 1,\n\t.show_host_supported_fc4s = 1,\n\t.show_host_active_fc4s = 1,\n\t.show_host_maxframe_size = 1,\n\n\t.get_host_port_id = qedf_get_host_port_id,\n\t.show_host_port_id = 1,\n\t.show_host_supported_speeds = 1,\n\t.get_host_speed = fc_get_host_speed,\n\t.show_host_speed = 1,\n\t.show_host_port_type = 1,\n\t.get_host_port_state = fc_get_host_port_state,\n\t.show_host_port_state = 1,\n\t.show_host_symbolic_name = 1,\n\n\t \n\t.dd_fcrport_size = (sizeof(struct fc_rport_libfc_priv) +\n\t\t\t\tsizeof(struct qedf_rport)),\n\t.show_rport_maxframe_size = 1,\n\t.show_rport_supported_classes = 1,\n\t.show_host_fabric_name = 1,\n\t.show_starget_node_name = 1,\n\t.show_starget_port_name = 1,\n\t.show_starget_port_id = 1,\n\t.set_rport_dev_loss_tmo = fc_set_rport_loss_tmo,\n\t.show_rport_dev_loss_tmo = 1,\n\t.get_fc_host_stats = qedf_fc_get_host_stats,\n\t.issue_fc_host_lip = qedf_fcoe_reset,\n\t.vport_create = qedf_vport_create,\n\t.vport_delete = qedf_vport_destroy,\n\t.vport_disable = qedf_vport_disable,\n\t.bsg_request = fc_lport_bsg_request,\n};\n\nstatic struct fc_function_template qedf_fc_vport_transport_fn = {\n\t.show_host_node_name = 1,\n\t.show_host_port_name = 1,\n\t.show_host_supported_classes = 1,\n\t.show_host_supported_fc4s = 1,\n\t.show_host_active_fc4s = 1,\n\t.show_host_maxframe_size = 1,\n\t.show_host_port_id = 1,\n\t.show_host_supported_speeds = 1,\n\t.get_host_speed = fc_get_host_speed,\n\t.show_host_speed = 1,\n\t.show_host_port_type = 1,\n\t.get_host_port_state = fc_get_host_port_state,\n\t.show_host_port_state = 1,\n\t.show_host_symbolic_name = 1,\n\t.dd_fcrport_size = (sizeof(struct fc_rport_libfc_priv) +\n\t\t\t\tsizeof(struct qedf_rport)),\n\t.show_rport_maxframe_size = 1,\n\t.show_rport_supported_classes = 1,\n\t.show_host_fabric_name = 1,\n\t.show_starget_node_name = 1,\n\t.show_starget_port_name = 1,\n\t.show_starget_port_id = 1,\n\t.set_rport_dev_loss_tmo = fc_set_rport_loss_tmo,\n\t.show_rport_dev_loss_tmo = 1,\n\t.get_fc_host_stats = fc_get_host_stats,\n\t.issue_fc_host_lip = qedf_fcoe_reset,\n\t.bsg_request = fc_lport_bsg_request,\n};\n\nstatic bool qedf_fp_has_work(struct qedf_fastpath *fp)\n{\n\tstruct qedf_ctx *qedf = fp->qedf;\n\tstruct global_queue *que;\n\tstruct qed_sb_info *sb_info = fp->sb_info;\n\tstruct status_block *sb = sb_info->sb_virt;\n\tu16 prod_idx;\n\n\t \n\tque = qedf->global_queues[fp->sb_id];\n\n\t \n\trmb();\n\n\t \n\tprod_idx = sb->pi_array[QEDF_FCOE_PARAMS_GL_RQ_PI];\n\n\treturn (que->cq_prod_idx != prod_idx);\n}\n\n \n\n \nstatic bool qedf_process_completions(struct qedf_fastpath *fp)\n{\n\tstruct qedf_ctx *qedf = fp->qedf;\n\tstruct qed_sb_info *sb_info = fp->sb_info;\n\tstruct status_block *sb = sb_info->sb_virt;\n\tstruct global_queue *que;\n\tu16 prod_idx;\n\tstruct fcoe_cqe *cqe;\n\tstruct qedf_io_work *io_work;\n\tunsigned int cpu;\n\tstruct qedf_ioreq *io_req = NULL;\n\tu16 xid;\n\tu16 new_cqes;\n\tu32 comp_type;\n\n\t \n\tprod_idx = sb->pi_array[QEDF_FCOE_PARAMS_GL_RQ_PI];\n\n\t \n\tque = qedf->global_queues[fp->sb_id];\n\n\t \n\tnew_cqes = (prod_idx >= que->cq_prod_idx) ?\n\t    (prod_idx - que->cq_prod_idx) :\n\t    0x10000 - que->cq_prod_idx + prod_idx;\n\n\t \n\tque->cq_prod_idx = prod_idx;\n\n\twhile (new_cqes) {\n\t\tfp->completions++;\n\t\tcqe = &que->cq[que->cq_cons_idx];\n\n\t\tcomp_type = (cqe->cqe_data >> FCOE_CQE_CQE_TYPE_SHIFT) &\n\t\t    FCOE_CQE_CQE_TYPE_MASK;\n\n\t\t \n\t\tif (comp_type == FCOE_UNSOLIC_CQE_TYPE) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_UNSOL,\n\t\t\t   \"Unsolicated CQE.\\n\");\n\t\t\tqedf_process_unsol_compl(qedf, fp->sb_id, cqe);\n\t\t\t \n\t\t\tgoto inc_idx;\n\t\t}\n\n\t\txid = cqe->cqe_data & FCOE_CQE_TASK_ID_MASK;\n\t\tio_req = &qedf->cmd_mgr->cmds[xid];\n\n\t\t \n\t\tif (!io_req)\n\t\t\t \n\t\t\tcpu = 0;\n\t\telse {\n\t\t\tcpu = io_req->cpu;\n\t\t\tio_req->int_cpu = smp_processor_id();\n\t\t}\n\n\t\tio_work = mempool_alloc(qedf->io_mempool, GFP_ATOMIC);\n\t\tif (!io_work) {\n\t\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Could not allocate \"\n\t\t\t\t   \"work for I/O completion.\\n\");\n\t\t\tcontinue;\n\t\t}\n\t\tmemset(io_work, 0, sizeof(struct qedf_io_work));\n\n\t\tINIT_WORK(&io_work->work, qedf_fp_io_handler);\n\n\t\t \n\t\tmemcpy(&io_work->cqe, cqe, sizeof(struct fcoe_cqe));\n\n\t\tio_work->qedf = fp->qedf;\n\t\tio_work->fp = NULL;  \n\n\t\tqueue_work_on(cpu, qedf_io_wq, &io_work->work);\n\ninc_idx:\n\t\tque->cq_cons_idx++;\n\t\tif (que->cq_cons_idx == fp->cq_num_entries)\n\t\t\tque->cq_cons_idx = 0;\n\t\tnew_cqes--;\n\t}\n\n\treturn true;\n}\n\n\n \nstatic irqreturn_t qedf_msix_handler(int irq, void *dev_id)\n{\n\tstruct qedf_fastpath *fp = dev_id;\n\n\tif (!fp) {\n\t\tQEDF_ERR(NULL, \"fp is null.\\n\");\n\t\treturn IRQ_HANDLED;\n\t}\n\tif (!fp->sb_info) {\n\t\tQEDF_ERR(NULL, \"fp->sb_info in null.\");\n\t\treturn IRQ_HANDLED;\n\t}\n\n\t \n\tqed_sb_ack(fp->sb_info, IGU_INT_DISABLE, 0  );\n\n\twhile (1) {\n\t\tqedf_process_completions(fp);\n\n\t\tif (qedf_fp_has_work(fp) == 0) {\n\t\t\t \n\t\t\tqed_sb_update_sb_idx(fp->sb_info);\n\n\t\t\t \n\t\t\trmb();\n\n\t\t\tif (qedf_fp_has_work(fp) == 0) {\n\t\t\t\t \n\t\t\t\tqed_sb_ack(fp->sb_info, IGU_INT_ENABLE, 1);\n\t\t\t\treturn IRQ_HANDLED;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\treturn IRQ_HANDLED;\n}\n\n \nstatic void qedf_simd_int_handler(void *cookie)\n{\n\t \n\tstruct qedf_ctx *qedf = (struct qedf_ctx *)cookie;\n\n\tQEDF_WARN(&(qedf->dbg_ctx), \"qedf=%p.\\n\", qedf);\n}\n\n#define QEDF_SIMD_HANDLER_NUM\t\t0\nstatic void qedf_sync_free_irqs(struct qedf_ctx *qedf)\n{\n\tint i;\n\tu16 vector_idx = 0;\n\tu32 vector;\n\n\tif (qedf->int_info.msix_cnt) {\n\t\tfor (i = 0; i < qedf->int_info.used_cnt; i++) {\n\t\t\tvector_idx = i * qedf->dev_info.common.num_hwfns +\n\t\t\t\tqed_ops->common->get_affin_hwfn_idx(qedf->cdev);\n\t\t\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t\t\t  \"Freeing IRQ #%d vector_idx=%d.\\n\",\n\t\t\t\t  i, vector_idx);\n\t\t\tvector = qedf->int_info.msix[vector_idx].vector;\n\t\t\tsynchronize_irq(vector);\n\t\t\tirq_set_affinity_hint(vector, NULL);\n\t\t\tirq_set_affinity_notifier(vector, NULL);\n\t\t\tfree_irq(vector, &qedf->fp_array[i]);\n\t\t}\n\t} else\n\t\tqed_ops->common->simd_handler_clean(qedf->cdev,\n\t\t    QEDF_SIMD_HANDLER_NUM);\n\n\tqedf->int_info.used_cnt = 0;\n\tqed_ops->common->set_fp_int(qedf->cdev, 0);\n}\n\nstatic int qedf_request_msix_irq(struct qedf_ctx *qedf)\n{\n\tint i, rc, cpu;\n\tu16 vector_idx = 0;\n\tu32 vector;\n\n\tcpu = cpumask_first(cpu_online_mask);\n\tfor (i = 0; i < qedf->num_queues; i++) {\n\t\tvector_idx = i * qedf->dev_info.common.num_hwfns +\n\t\t\tqed_ops->common->get_affin_hwfn_idx(qedf->cdev);\n\t\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t\t  \"Requesting IRQ #%d vector_idx=%d.\\n\",\n\t\t\t  i, vector_idx);\n\t\tvector = qedf->int_info.msix[vector_idx].vector;\n\t\trc = request_irq(vector, qedf_msix_handler, 0, \"qedf\",\n\t\t\t\t &qedf->fp_array[i]);\n\n\t\tif (rc) {\n\t\t\tQEDF_WARN(&(qedf->dbg_ctx), \"request_irq failed.\\n\");\n\t\t\tqedf_sync_free_irqs(qedf);\n\t\t\treturn rc;\n\t\t}\n\n\t\tqedf->int_info.used_cnt++;\n\t\trc = irq_set_affinity_hint(vector, get_cpu_mask(cpu));\n\t\tcpu = cpumask_next(cpu, cpu_online_mask);\n\t}\n\n\treturn 0;\n}\n\nstatic int qedf_setup_int(struct qedf_ctx *qedf)\n{\n\tint rc = 0;\n\n\t \n\trc = qed_ops->common->set_fp_int(qedf->cdev, num_online_cpus());\n\tif (rc <= 0)\n\t\treturn 0;\n\n\trc  = qed_ops->common->get_fp_int(qedf->cdev, &qedf->int_info);\n\tif (rc)\n\t\treturn 0;\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC, \"Number of msix_cnt = \"\n\t\t   \"0x%x num of cpus = 0x%x\\n\", qedf->int_info.msix_cnt,\n\t\t   num_online_cpus());\n\n\tif (qedf->int_info.msix_cnt)\n\t\treturn qedf_request_msix_irq(qedf);\n\n\tqed_ops->common->simd_handler_config(qedf->cdev, &qedf,\n\t    QEDF_SIMD_HANDLER_NUM, qedf_simd_int_handler);\n\tqedf->int_info.used_cnt = 1;\n\n\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t \"Cannot load driver due to a lack of MSI-X vectors.\\n\");\n\treturn -EINVAL;\n}\n\n \nstatic void qedf_recv_frame(struct qedf_ctx *qedf,\n\tstruct sk_buff *skb)\n{\n\tu32 fr_len;\n\tstruct fc_lport *lport;\n\tstruct fc_frame_header *fh;\n\tstruct fcoe_crc_eof crc_eof;\n\tstruct fc_frame *fp;\n\tu8 *mac = NULL;\n\tu8 *dest_mac = NULL;\n\tstruct fcoe_hdr *hp;\n\tstruct qedf_rport *fcport;\n\tstruct fc_lport *vn_port;\n\tu32 f_ctl;\n\n\tlport = qedf->lport;\n\tif (lport == NULL || lport->state == LPORT_ST_DISABLED) {\n\t\tQEDF_WARN(NULL, \"Invalid lport struct or lport disabled.\\n\");\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tif (skb_is_nonlinear(skb))\n\t\tskb_linearize(skb);\n\tmac = eth_hdr(skb)->h_source;\n\tdest_mac = eth_hdr(skb)->h_dest;\n\n\t \n\thp = (struct fcoe_hdr *)skb->data;\n\tfh = (struct fc_frame_header *) skb_transport_header(skb);\n\tskb_pull(skb, sizeof(struct fcoe_hdr));\n\tfr_len = skb->len - sizeof(struct fcoe_crc_eof);\n\n\tfp = (struct fc_frame *)skb;\n\tfc_frame_init(fp);\n\tfr_dev(fp) = lport;\n\tfr_sof(fp) = hp->fcoe_sof;\n\tif (skb_copy_bits(skb, fr_len, &crc_eof, sizeof(crc_eof))) {\n\t\tQEDF_INFO(NULL, QEDF_LOG_LL2, \"skb_copy_bits failed.\\n\");\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\tfr_eof(fp) = crc_eof.fcoe_eof;\n\tfr_crc(fp) = crc_eof.fcoe_crc32;\n\tif (pskb_trim(skb, fr_len)) {\n\t\tQEDF_INFO(NULL, QEDF_LOG_LL2, \"pskb_trim failed.\\n\");\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tfh = fc_frame_header_get(fp);\n\n\t \n\n\tif (fh->fh_r_ctl == FC_RCTL_DD_SOL_DATA &&\n\t    fh->fh_type == FC_TYPE_FCP) {\n\t\t \n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\tif (fh->fh_r_ctl == FC_RCTL_ELS_REQ &&\n\t    fh->fh_type == FC_TYPE_ELS) {\n\t\tswitch (fc_frame_payload_op(fp)) {\n\t\tcase ELS_LOGO:\n\t\t\tif (ntoh24(fh->fh_s_id) == FC_FID_FLOGI) {\n\t\t\t\t \n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (fh->fh_r_ctl == FC_RCTL_BA_ABTS) {\n\t\t \n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tif (ntoh24(&dest_mac[3]) != ntoh24(fh->fh_d_id)) {\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_LL2,\n\t\t    \"FC frame d_id mismatch with MAC %pM.\\n\", dest_mac);\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tif (qedf->ctlr.state) {\n\t\tif (!ether_addr_equal(mac, qedf->ctlr.dest_addr)) {\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_LL2,\n\t\t\t    \"Wrong source address: mac:%pM dest_addr:%pM.\\n\",\n\t\t\t    mac, qedf->ctlr.dest_addr);\n\t\t\tkfree_skb(skb);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tvn_port = fc_vport_id_lookup(lport, ntoh24(fh->fh_d_id));\n\n\t \n\tif (lport->port_id != ntoh24(fh->fh_d_id) && !vn_port) {\n\t\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_LL2,\n\t\t\t  \"Dropping frame due to destination mismatch: lport->port_id=0x%x fh->d_id=0x%x.\\n\",\n\t\t\t  lport->port_id, ntoh24(fh->fh_d_id));\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tf_ctl = ntoh24(fh->fh_f_ctl);\n\tif ((fh->fh_type == FC_TYPE_BLS) && (f_ctl & FC_FC_SEQ_CTX) &&\n\t    (f_ctl & FC_FC_EX_CTX)) {\n\t\t \n\t\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_LL2,\n\t\t\t  \"Dropping ABTS response as both SEQ/EX CTX set.\\n\");\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\t \n\n\t \n\tfcport = qedf_fcport_lookup(qedf, ntoh24(fh->fh_d_id));\n\n\tif (fcport && test_bit(QEDF_RPORT_UPLOADING_CONNECTION,\n\t    &fcport->flags)) {\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_LL2,\n\t\t    \"Connection uploading, dropping fp=%p.\\n\", fp);\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_LL2, \"FCoE frame receive: \"\n\t    \"skb=%p fp=%p src=%06x dest=%06x r_ctl=%x fh_type=%x.\\n\", skb, fp,\n\t    ntoh24(fh->fh_s_id), ntoh24(fh->fh_d_id), fh->fh_r_ctl,\n\t    fh->fh_type);\n\tif (qedf_dump_frames)\n\t\tprint_hex_dump(KERN_WARNING, \"fcoe: \", DUMP_PREFIX_OFFSET, 16,\n\t\t    1, skb->data, skb->len, false);\n\tfc_exch_recv(lport, fp);\n}\n\nstatic void qedf_ll2_process_skb(struct work_struct *work)\n{\n\tstruct qedf_skb_work *skb_work =\n\t    container_of(work, struct qedf_skb_work, work);\n\tstruct qedf_ctx *qedf = skb_work->qedf;\n\tstruct sk_buff *skb = skb_work->skb;\n\tstruct ethhdr *eh;\n\n\tif (!qedf) {\n\t\tQEDF_ERR(NULL, \"qedf is NULL\\n\");\n\t\tgoto err_out;\n\t}\n\n\teh = (struct ethhdr *)skb->data;\n\n\t \n\tif (eh->h_proto == htons(ETH_P_8021Q)) {\n\t\tmemmove((u8 *)eh + VLAN_HLEN, eh, ETH_ALEN * 2);\n\t\teh = skb_pull(skb, VLAN_HLEN);\n\t\tskb_reset_mac_header(skb);\n\t}\n\n\t \n\tif (eh->h_proto == htons(ETH_P_FIP)) {\n\t\tqedf_fip_recv(qedf, skb);\n\t\tgoto out;\n\t} else if (eh->h_proto == htons(ETH_P_FCOE)) {\n\t\t__skb_pull(skb, ETH_HLEN);\n\t\tqedf_recv_frame(qedf, skb);\n\t\tgoto out;\n\t} else\n\t\tgoto err_out;\n\nerr_out:\n\tkfree_skb(skb);\nout:\n\tkfree(skb_work);\n\treturn;\n}\n\nstatic int qedf_ll2_rx(void *cookie, struct sk_buff *skb,\n\tu32 arg1, u32 arg2)\n{\n\tstruct qedf_ctx *qedf = (struct qedf_ctx *)cookie;\n\tstruct qedf_skb_work *skb_work;\n\n\tif (atomic_read(&qedf->link_state) == QEDF_LINK_DOWN) {\n\t\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_LL2,\n\t\t\t  \"Dropping frame as link state is down.\\n\");\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\tskb_work = kzalloc(sizeof(struct qedf_skb_work), GFP_ATOMIC);\n\tif (!skb_work) {\n\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Could not allocate skb_work so \"\n\t\t\t   \"dropping frame.\\n\");\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\tINIT_WORK(&skb_work->work, qedf_ll2_process_skb);\n\tskb_work->skb = skb;\n\tskb_work->qedf = qedf;\n\tqueue_work(qedf->ll2_recv_wq, &skb_work->work);\n\n\treturn 0;\n}\n\nstatic struct qed_ll2_cb_ops qedf_ll2_cb_ops = {\n\t.rx_cb = qedf_ll2_rx,\n\t.tx_cb = NULL,\n};\n\n \nvoid qedf_fp_io_handler(struct work_struct *work)\n{\n\tstruct qedf_io_work *io_work =\n\t    container_of(work, struct qedf_io_work, work);\n\tu32 comp_type;\n\n\t \n\tcomp_type = (io_work->cqe.cqe_data >>\n\t    FCOE_CQE_CQE_TYPE_SHIFT) &\n\t    FCOE_CQE_CQE_TYPE_MASK;\n\tif (comp_type == FCOE_UNSOLIC_CQE_TYPE &&\n\t    io_work->fp)\n\t\tfc_exch_recv(io_work->qedf->lport, io_work->fp);\n\telse\n\t\tqedf_process_cqe(io_work->qedf, &io_work->cqe);\n\n\tkfree(io_work);\n}\n\nstatic int qedf_alloc_and_init_sb(struct qedf_ctx *qedf,\n\tstruct qed_sb_info *sb_info, u16 sb_id)\n{\n\tstruct status_block *sb_virt;\n\tdma_addr_t sb_phys;\n\tint ret;\n\n\tsb_virt = dma_alloc_coherent(&qedf->pdev->dev,\n\t    sizeof(struct status_block), &sb_phys, GFP_KERNEL);\n\n\tif (!sb_virt) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"Status block allocation failed for id = %d.\\n\",\n\t\t\t sb_id);\n\t\treturn -ENOMEM;\n\t}\n\n\tret = qed_ops->common->sb_init(qedf->cdev, sb_info, sb_virt, sb_phys,\n\t    sb_id, QED_SB_TYPE_STORAGE);\n\n\tif (ret) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"Status block initialization failed (0x%x) for id = %d.\\n\",\n\t\t\t ret, sb_id);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void qedf_free_sb(struct qedf_ctx *qedf, struct qed_sb_info *sb_info)\n{\n\tif (sb_info->sb_virt)\n\t\tdma_free_coherent(&qedf->pdev->dev, sizeof(*sb_info->sb_virt),\n\t\t    (void *)sb_info->sb_virt, sb_info->sb_phys);\n}\n\nstatic void qedf_destroy_sb(struct qedf_ctx *qedf)\n{\n\tint id;\n\tstruct qedf_fastpath *fp = NULL;\n\n\tfor (id = 0; id < qedf->num_queues; id++) {\n\t\tfp = &(qedf->fp_array[id]);\n\t\tif (fp->sb_id == QEDF_SB_ID_NULL)\n\t\t\tbreak;\n\t\tqedf_free_sb(qedf, fp->sb_info);\n\t\tkfree(fp->sb_info);\n\t}\n\tkfree(qedf->fp_array);\n}\n\nstatic int qedf_prepare_sb(struct qedf_ctx *qedf)\n{\n\tint id;\n\tstruct qedf_fastpath *fp;\n\tint ret;\n\n\tqedf->fp_array =\n\t    kcalloc(qedf->num_queues, sizeof(struct qedf_fastpath),\n\t\tGFP_KERNEL);\n\n\tif (!qedf->fp_array) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"fastpath array allocation \"\n\t\t\t  \"failed.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tfor (id = 0; id < qedf->num_queues; id++) {\n\t\tfp = &(qedf->fp_array[id]);\n\t\tfp->sb_id = QEDF_SB_ID_NULL;\n\t\tfp->sb_info = kcalloc(1, sizeof(*fp->sb_info), GFP_KERNEL);\n\t\tif (!fp->sb_info) {\n\t\t\tQEDF_ERR(&(qedf->dbg_ctx), \"SB info struct \"\n\t\t\t\t  \"allocation failed.\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\tret = qedf_alloc_and_init_sb(qedf, fp->sb_info, id);\n\t\tif (ret) {\n\t\t\tQEDF_ERR(&(qedf->dbg_ctx), \"SB allocation and \"\n\t\t\t\t  \"initialization failed.\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\tfp->sb_id = id;\n\t\tfp->qedf = qedf;\n\t\tfp->cq_num_entries =\n\t\t    qedf->global_queues[id]->cq_mem_size /\n\t\t    sizeof(struct fcoe_cqe);\n\t}\nerr:\n\treturn 0;\n}\n\nvoid qedf_process_cqe(struct qedf_ctx *qedf, struct fcoe_cqe *cqe)\n{\n\tu16 xid;\n\tstruct qedf_ioreq *io_req;\n\tstruct qedf_rport *fcport;\n\tu32 comp_type;\n\tu8 io_comp_type;\n\tunsigned long flags;\n\n\tcomp_type = (cqe->cqe_data >> FCOE_CQE_CQE_TYPE_SHIFT) &\n\t    FCOE_CQE_CQE_TYPE_MASK;\n\n\txid = cqe->cqe_data & FCOE_CQE_TASK_ID_MASK;\n\tio_req = &qedf->cmd_mgr->cmds[xid];\n\n\t \n\tif (!io_req) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"io_req is NULL for xid=0x%x.\\n\", xid);\n\t\treturn;\n\t}\n\n\tfcport = io_req->fcport;\n\n\tif (fcport == NULL) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"fcport is NULL for xid=0x%x io_req=%p.\\n\",\n\t\t\t xid, io_req);\n\t\treturn;\n\t}\n\n\t \n\tif (!test_bit(QEDF_RPORT_SESSION_READY, &fcport->flags)) {\n\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t \"Session not offloaded yet, fcport = %p.\\n\", fcport);\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&fcport->rport_lock, flags);\n\tio_comp_type = io_req->cmd_type;\n\tspin_unlock_irqrestore(&fcport->rport_lock, flags);\n\n\tswitch (comp_type) {\n\tcase FCOE_GOOD_COMPLETION_CQE_TYPE:\n\t\tatomic_inc(&fcport->free_sqes);\n\t\tswitch (io_comp_type) {\n\t\tcase QEDF_SCSI_CMD:\n\t\t\tqedf_scsi_completion(qedf, cqe, io_req);\n\t\t\tbreak;\n\t\tcase QEDF_ELS:\n\t\t\tqedf_process_els_compl(qedf, cqe, io_req);\n\t\t\tbreak;\n\t\tcase QEDF_TASK_MGMT_CMD:\n\t\t\tqedf_process_tmf_compl(qedf, cqe, io_req);\n\t\t\tbreak;\n\t\tcase QEDF_SEQ_CLEANUP:\n\t\t\tqedf_process_seq_cleanup_compl(qedf, cqe, io_req);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase FCOE_ERROR_DETECTION_CQE_TYPE:\n\t\tatomic_inc(&fcport->free_sqes);\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_IO,\n\t\t    \"Error detect CQE.\\n\");\n\t\tqedf_process_error_detect(qedf, cqe, io_req);\n\t\tbreak;\n\tcase FCOE_EXCH_CLEANUP_CQE_TYPE:\n\t\tatomic_inc(&fcport->free_sqes);\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_IO,\n\t\t    \"Cleanup CQE.\\n\");\n\t\tqedf_process_cleanup_compl(qedf, cqe, io_req);\n\t\tbreak;\n\tcase FCOE_ABTS_CQE_TYPE:\n\t\tatomic_inc(&fcport->free_sqes);\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_IO,\n\t\t    \"Abort CQE.\\n\");\n\t\tqedf_process_abts_compl(qedf, cqe, io_req);\n\t\tbreak;\n\tcase FCOE_DUMMY_CQE_TYPE:\n\t\tatomic_inc(&fcport->free_sqes);\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_IO,\n\t\t    \"Dummy CQE.\\n\");\n\t\tbreak;\n\tcase FCOE_LOCAL_COMP_CQE_TYPE:\n\t\tatomic_inc(&fcport->free_sqes);\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_IO,\n\t\t    \"Local completion CQE.\\n\");\n\t\tbreak;\n\tcase FCOE_WARNING_CQE_TYPE:\n\t\tatomic_inc(&fcport->free_sqes);\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_IO,\n\t\t    \"Warning CQE.\\n\");\n\t\tqedf_process_warning_compl(qedf, cqe, io_req);\n\t\tbreak;\n\tcase MAX_FCOE_CQE_TYPE:\n\t\tatomic_inc(&fcport->free_sqes);\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_IO,\n\t\t    \"Max FCoE CQE.\\n\");\n\t\tbreak;\n\tdefault:\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_IO,\n\t\t    \"Default CQE.\\n\");\n\t\tbreak;\n\t}\n}\n\nstatic void qedf_free_bdq(struct qedf_ctx *qedf)\n{\n\tint i;\n\n\tif (qedf->bdq_pbl_list)\n\t\tdma_free_coherent(&qedf->pdev->dev, QEDF_PAGE_SIZE,\n\t\t    qedf->bdq_pbl_list, qedf->bdq_pbl_list_dma);\n\n\tif (qedf->bdq_pbl)\n\t\tdma_free_coherent(&qedf->pdev->dev, qedf->bdq_pbl_mem_size,\n\t\t    qedf->bdq_pbl, qedf->bdq_pbl_dma);\n\n\tfor (i = 0; i < QEDF_BDQ_SIZE; i++) {\n\t\tif (qedf->bdq[i].buf_addr) {\n\t\t\tdma_free_coherent(&qedf->pdev->dev, QEDF_BDQ_BUF_SIZE,\n\t\t\t    qedf->bdq[i].buf_addr, qedf->bdq[i].buf_dma);\n\t\t}\n\t}\n}\n\nstatic void qedf_free_global_queues(struct qedf_ctx *qedf)\n{\n\tint i;\n\tstruct global_queue **gl = qedf->global_queues;\n\n\tfor (i = 0; i < qedf->num_queues; i++) {\n\t\tif (!gl[i])\n\t\t\tcontinue;\n\n\t\tif (gl[i]->cq)\n\t\t\tdma_free_coherent(&qedf->pdev->dev,\n\t\t\t    gl[i]->cq_mem_size, gl[i]->cq, gl[i]->cq_dma);\n\t\tif (gl[i]->cq_pbl)\n\t\t\tdma_free_coherent(&qedf->pdev->dev, gl[i]->cq_pbl_size,\n\t\t\t    gl[i]->cq_pbl, gl[i]->cq_pbl_dma);\n\n\t\tkfree(gl[i]);\n\t}\n\n\tqedf_free_bdq(qedf);\n}\n\nstatic int qedf_alloc_bdq(struct qedf_ctx *qedf)\n{\n\tint i;\n\tstruct scsi_bd *pbl;\n\tu64 *list;\n\n\t \n\tfor (i = 0; i < QEDF_BDQ_SIZE; i++) {\n\t\tqedf->bdq[i].buf_addr = dma_alloc_coherent(&qedf->pdev->dev,\n\t\t    QEDF_BDQ_BUF_SIZE, &qedf->bdq[i].buf_dma, GFP_KERNEL);\n\t\tif (!qedf->bdq[i].buf_addr) {\n\t\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Could not allocate BDQ \"\n\t\t\t    \"buffer %d.\\n\", i);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\t \n\tqedf->bdq_pbl_mem_size =\n\t    QEDF_BDQ_SIZE * sizeof(struct scsi_bd);\n\tqedf->bdq_pbl_mem_size =\n\t    ALIGN(qedf->bdq_pbl_mem_size, QEDF_PAGE_SIZE);\n\n\tqedf->bdq_pbl = dma_alloc_coherent(&qedf->pdev->dev,\n\t    qedf->bdq_pbl_mem_size, &qedf->bdq_pbl_dma, GFP_KERNEL);\n\tif (!qedf->bdq_pbl) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Could not allocate BDQ PBL.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t  \"BDQ PBL addr=0x%p dma=%pad\\n\",\n\t\t  qedf->bdq_pbl, &qedf->bdq_pbl_dma);\n\n\t \n\tpbl = (struct scsi_bd *)qedf->bdq_pbl;\n\tfor (i = 0; i < QEDF_BDQ_SIZE; i++) {\n\t\tpbl->address.hi = cpu_to_le32(U64_HI(qedf->bdq[i].buf_dma));\n\t\tpbl->address.lo = cpu_to_le32(U64_LO(qedf->bdq[i].buf_dma));\n\t\tpbl->opaque.fcoe_opaque.hi = 0;\n\t\t \n\t\tpbl->opaque.fcoe_opaque.lo = cpu_to_le32(i);\n\t\tpbl++;\n\t}\n\n\t \n\tqedf->bdq_pbl_list = dma_alloc_coherent(&qedf->pdev->dev,\n\t\t\t\t\t\tQEDF_PAGE_SIZE,\n\t\t\t\t\t\t&qedf->bdq_pbl_list_dma,\n\t\t\t\t\t\tGFP_KERNEL);\n\tif (!qedf->bdq_pbl_list) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Could not allocate list of PBL pages.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tqedf->bdq_pbl_list_num_entries = qedf->bdq_pbl_mem_size /\n\t    QEDF_PAGE_SIZE;\n\tlist = (u64 *)qedf->bdq_pbl_list;\n\tfor (i = 0; i < qedf->bdq_pbl_list_num_entries; i++) {\n\t\t*list = qedf->bdq_pbl_dma;\n\t\tlist++;\n\t}\n\n\treturn 0;\n}\n\nstatic int qedf_alloc_global_queues(struct qedf_ctx *qedf)\n{\n\tu32 *list;\n\tint i;\n\tint status;\n\tu32 *pbl;\n\tdma_addr_t page;\n\tint num_pages;\n\n\t \n\t \n\tif (!qedf->num_queues) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"No MSI-X vectors available!\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tif (!qedf->p_cpuq) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"p_cpuq is NULL.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tqedf->global_queues = kzalloc((sizeof(struct global_queue *)\n\t    * qedf->num_queues), GFP_KERNEL);\n\tif (!qedf->global_queues) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Unable to allocate global \"\n\t\t\t  \"queues array ptr memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t   \"qedf->global_queues=%p.\\n\", qedf->global_queues);\n\n\t \n\tstatus = qedf_alloc_bdq(qedf);\n\tif (status) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"Unable to allocate bdq.\\n\");\n\t\tgoto mem_alloc_failure;\n\t}\n\n\t \n\tfor (i = 0; i < qedf->num_queues; i++) {\n\t\tqedf->global_queues[i] = kzalloc(sizeof(struct global_queue),\n\t\t    GFP_KERNEL);\n\t\tif (!qedf->global_queues[i]) {\n\t\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Unable to allocate \"\n\t\t\t\t   \"global queue %d.\\n\", i);\n\t\t\tstatus = -ENOMEM;\n\t\t\tgoto mem_alloc_failure;\n\t\t}\n\n\t\tqedf->global_queues[i]->cq_mem_size =\n\t\t    FCOE_PARAMS_CQ_NUM_ENTRIES * sizeof(struct fcoe_cqe);\n\t\tqedf->global_queues[i]->cq_mem_size =\n\t\t    ALIGN(qedf->global_queues[i]->cq_mem_size, QEDF_PAGE_SIZE);\n\n\t\tqedf->global_queues[i]->cq_pbl_size =\n\t\t    (qedf->global_queues[i]->cq_mem_size /\n\t\t    PAGE_SIZE) * sizeof(void *);\n\t\tqedf->global_queues[i]->cq_pbl_size =\n\t\t    ALIGN(qedf->global_queues[i]->cq_pbl_size, QEDF_PAGE_SIZE);\n\n\t\tqedf->global_queues[i]->cq =\n\t\t    dma_alloc_coherent(&qedf->pdev->dev,\n\t\t\t\t       qedf->global_queues[i]->cq_mem_size,\n\t\t\t\t       &qedf->global_queues[i]->cq_dma,\n\t\t\t\t       GFP_KERNEL);\n\n\t\tif (!qedf->global_queues[i]->cq) {\n\t\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Could not allocate cq.\\n\");\n\t\t\tstatus = -ENOMEM;\n\t\t\tgoto mem_alloc_failure;\n\t\t}\n\n\t\tqedf->global_queues[i]->cq_pbl =\n\t\t    dma_alloc_coherent(&qedf->pdev->dev,\n\t\t\t\t       qedf->global_queues[i]->cq_pbl_size,\n\t\t\t\t       &qedf->global_queues[i]->cq_pbl_dma,\n\t\t\t\t       GFP_KERNEL);\n\n\t\tif (!qedf->global_queues[i]->cq_pbl) {\n\t\t\tQEDF_WARN(&(qedf->dbg_ctx), \"Could not allocate cq PBL.\\n\");\n\t\t\tstatus = -ENOMEM;\n\t\t\tgoto mem_alloc_failure;\n\t\t}\n\n\t\t \n\t\tnum_pages = qedf->global_queues[i]->cq_mem_size /\n\t\t    QEDF_PAGE_SIZE;\n\t\tpage = qedf->global_queues[i]->cq_dma;\n\t\tpbl = (u32 *)qedf->global_queues[i]->cq_pbl;\n\n\t\twhile (num_pages--) {\n\t\t\t*pbl = U64_LO(page);\n\t\t\tpbl++;\n\t\t\t*pbl = U64_HI(page);\n\t\t\tpbl++;\n\t\t\tpage += QEDF_PAGE_SIZE;\n\t\t}\n\t\t \n\t\tqedf->global_queues[i]->cq_cons_idx = 0;\n\t}\n\n\tlist = (u32 *)qedf->p_cpuq;\n\n\t \n\tfor (i = 0; i < qedf->num_queues; i++) {\n\t\t*list = U64_LO(qedf->global_queues[i]->cq_pbl_dma);\n\t\tlist++;\n\t\t*list = U64_HI(qedf->global_queues[i]->cq_pbl_dma);\n\t\tlist++;\n\t\t*list = U64_LO(0);\n\t\tlist++;\n\t\t*list = U64_HI(0);\n\t\tlist++;\n\t}\n\n\treturn 0;\n\nmem_alloc_failure:\n\tqedf_free_global_queues(qedf);\n\treturn status;\n}\n\nstatic int qedf_set_fcoe_pf_param(struct qedf_ctx *qedf)\n{\n\tu8 sq_num_pbl_pages;\n\tu32 sq_mem_size;\n\tu32 cq_mem_size;\n\tu32 cq_num_entries;\n\tint rval;\n\n\t \n\tqedf->num_queues = MIN_NUM_CPUS_MSIX(qedf);\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC, \"Number of CQs is %d.\\n\",\n\t\t   qedf->num_queues);\n\n\tqedf->p_cpuq = dma_alloc_coherent(&qedf->pdev->dev,\n\t    qedf->num_queues * sizeof(struct qedf_glbl_q_params),\n\t    &qedf->hw_p_cpuq, GFP_KERNEL);\n\n\tif (!qedf->p_cpuq) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"dma_alloc_coherent failed.\\n\");\n\t\treturn 1;\n\t}\n\n\trval = qedf_alloc_global_queues(qedf);\n\tif (rval) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Global queue allocation \"\n\t\t\t  \"failed.\\n\");\n\t\treturn 1;\n\t}\n\n\t \n\tsq_mem_size = SQ_NUM_ENTRIES * sizeof(struct fcoe_wqe);\n\tsq_mem_size = ALIGN(sq_mem_size, QEDF_PAGE_SIZE);\n\tsq_num_pbl_pages = (sq_mem_size / QEDF_PAGE_SIZE);\n\n\t \n\tcq_mem_size = FCOE_PARAMS_CQ_NUM_ENTRIES * sizeof(struct fcoe_cqe);\n\tcq_mem_size = ALIGN(cq_mem_size, QEDF_PAGE_SIZE);\n\tcq_num_entries = cq_mem_size / sizeof(struct fcoe_cqe);\n\n\tmemset(&(qedf->pf_params), 0, sizeof(qedf->pf_params));\n\n\t \n\tqedf->pf_params.fcoe_pf_params.num_cons = QEDF_MAX_SESSIONS;\n\tqedf->pf_params.fcoe_pf_params.num_tasks = FCOE_PARAMS_NUM_TASKS;\n\tqedf->pf_params.fcoe_pf_params.glbl_q_params_addr =\n\t    (u64)qedf->hw_p_cpuq;\n\tqedf->pf_params.fcoe_pf_params.sq_num_pbl_pages = sq_num_pbl_pages;\n\n\tqedf->pf_params.fcoe_pf_params.rq_buffer_log_size = 0;\n\n\tqedf->pf_params.fcoe_pf_params.cq_num_entries = cq_num_entries;\n\tqedf->pf_params.fcoe_pf_params.num_cqs = qedf->num_queues;\n\n\t \n\tqedf->pf_params.fcoe_pf_params.log_page_size = ilog2(QEDF_PAGE_SIZE);\n\n\tqedf->pf_params.fcoe_pf_params.mtu = 9000;\n\tqedf->pf_params.fcoe_pf_params.gl_rq_pi = QEDF_FCOE_PARAMS_GL_RQ_PI;\n\tqedf->pf_params.fcoe_pf_params.gl_cmd_pi = QEDF_FCOE_PARAMS_GL_CMD_PI;\n\n\t \n\tqedf->pf_params.fcoe_pf_params.bdq_pbl_base_addr[0] =\n\t    qedf->bdq_pbl_list_dma;\n\tqedf->pf_params.fcoe_pf_params.bdq_pbl_num_entries[0] =\n\t    qedf->bdq_pbl_list_num_entries;\n\tqedf->pf_params.fcoe_pf_params.rq_buffer_size = QEDF_BDQ_BUF_SIZE;\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t    \"bdq_list=%p bdq_pbl_list_dma=%llx bdq_pbl_list_entries=%d.\\n\",\n\t    qedf->bdq_pbl_list,\n\t    qedf->pf_params.fcoe_pf_params.bdq_pbl_base_addr[0],\n\t    qedf->pf_params.fcoe_pf_params.bdq_pbl_num_entries[0]);\n\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t    \"cq_num_entries=%d.\\n\",\n\t    qedf->pf_params.fcoe_pf_params.cq_num_entries);\n\n\treturn 0;\n}\n\n \nstatic void qedf_free_fcoe_pf_param(struct qedf_ctx *qedf)\n{\n\tsize_t size = 0;\n\n\tif (qedf->p_cpuq) {\n\t\tsize = qedf->num_queues * sizeof(struct qedf_glbl_q_params);\n\t\tdma_free_coherent(&qedf->pdev->dev, size, qedf->p_cpuq,\n\t\t    qedf->hw_p_cpuq);\n\t}\n\n\tqedf_free_global_queues(qedf);\n\n\tkfree(qedf->global_queues);\n}\n\n \n\nstatic const struct pci_device_id qedf_pci_tbl[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_QLOGIC, 0x165c) },\n\t{ PCI_DEVICE(PCI_VENDOR_ID_QLOGIC, 0x8080) },\n\t{0}\n};\nMODULE_DEVICE_TABLE(pci, qedf_pci_tbl);\n\nstatic struct pci_driver qedf_pci_driver = {\n\t.name = QEDF_MODULE_NAME,\n\t.id_table = qedf_pci_tbl,\n\t.probe = qedf_probe,\n\t.remove = qedf_remove,\n\t.shutdown = qedf_shutdown,\n\t.suspend = qedf_suspend,\n};\n\nstatic int __qedf_probe(struct pci_dev *pdev, int mode)\n{\n\tint rc = -EINVAL;\n\tstruct fc_lport *lport;\n\tstruct qedf_ctx *qedf = NULL;\n\tstruct Scsi_Host *host;\n\tbool is_vf = false;\n\tstruct qed_ll2_params params;\n\tchar host_buf[20];\n\tstruct qed_link_params link_params;\n\tint status;\n\tvoid *task_start, *task_end;\n\tstruct qed_slowpath_params slowpath_params;\n\tstruct qed_probe_params qed_params;\n\tu16 retry_cnt = 10;\n\n\t \nretry_probe:\n\tif (mode == QEDF_MODE_RECOVERY)\n\t\tmsleep(2000);\n\n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\tlport = libfc_host_alloc(&qedf_host_template,\n\t\t    sizeof(struct qedf_ctx));\n\n\t\tif (!lport) {\n\t\t\tQEDF_ERR(NULL, \"Could not allocate lport.\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err0;\n\t\t}\n\n\t\tfc_disc_init(lport);\n\n\t\t \n\t\tqedf = lport_priv(lport);\n\t\tset_bit(QEDF_PROBING, &qedf->flags);\n\t\tqedf->lport = lport;\n\t\tqedf->ctlr.lp = lport;\n\t\tqedf->pdev = pdev;\n\t\tqedf->dbg_ctx.pdev = pdev;\n\t\tqedf->dbg_ctx.host_no = lport->host->host_no;\n\t\tspin_lock_init(&qedf->hba_lock);\n\t\tINIT_LIST_HEAD(&qedf->fcports);\n\t\tqedf->curr_conn_id = QEDF_MAX_SESSIONS - 1;\n\t\tatomic_set(&qedf->num_offloads, 0);\n\t\tqedf->stop_io_on_error = false;\n\t\tpci_set_drvdata(pdev, qedf);\n\t\tinit_completion(&qedf->fipvlan_compl);\n\t\tmutex_init(&qedf->stats_mutex);\n\t\tmutex_init(&qedf->flush_mutex);\n\t\tqedf->flogi_pending = 0;\n\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_INFO,\n\t\t   \"QLogic FastLinQ FCoE Module qedf %s, \"\n\t\t   \"FW %d.%d.%d.%d\\n\", QEDF_VERSION,\n\t\t   FW_MAJOR_VERSION, FW_MINOR_VERSION, FW_REVISION_VERSION,\n\t\t   FW_ENGINEERING_VERSION);\n\t} else {\n\t\t \n\t\tqedf = pci_get_drvdata(pdev);\n\t\tset_bit(QEDF_PROBING, &qedf->flags);\n\t\tlport = qedf->lport;\n\t}\n\n\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC, \"Probe started.\\n\");\n\n\thost = lport->host;\n\n\t \n\tqedf->io_mempool = mempool_create_slab_pool(QEDF_IO_WORK_MIN,\n\t    qedf_io_work_cache);\n\tif (qedf->io_mempool == NULL) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"qedf->io_mempool is NULL.\\n\");\n\t\tgoto err1;\n\t}\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_INFO, \"qedf->io_mempool=%p.\\n\",\n\t    qedf->io_mempool);\n\n\tsprintf(host_buf, \"qedf_%u_link\",\n\t    qedf->lport->host->host_no);\n\tqedf->link_update_wq = create_workqueue(host_buf);\n\tINIT_DELAYED_WORK(&qedf->link_update, qedf_handle_link_update);\n\tINIT_DELAYED_WORK(&qedf->link_recovery, qedf_link_recovery);\n\tINIT_DELAYED_WORK(&qedf->grcdump_work, qedf_wq_grcdump);\n\tINIT_DELAYED_WORK(&qedf->stag_work, qedf_stag_change_work);\n\tqedf->fipvlan_retries = qedf_fipvlan_retries;\n\t \n\tif (qedf_default_prio > -1) {\n\t\t \n\t\tqedf->prio = qedf_default_prio;\n\t} else\n\t\tqedf->prio = QEDF_DEFAULT_PRIO;\n\n\t \n\tmemset(&qed_params, 0, sizeof(qed_params));\n\tqed_params.protocol = QED_PROTOCOL_FCOE;\n\tqed_params.dp_module = qedf_dp_module;\n\tqed_params.dp_level = qedf_dp_level;\n\tqed_params.is_vf = is_vf;\n\tqedf->cdev = qed_ops->common->probe(pdev, &qed_params);\n\tif (!qedf->cdev) {\n\t\tif ((mode == QEDF_MODE_RECOVERY) && retry_cnt) {\n\t\t\tQEDF_ERR(&qedf->dbg_ctx,\n\t\t\t\t\"Retry %d initialize hardware\\n\", retry_cnt);\n\t\t\tretry_cnt--;\n\t\t\tgoto retry_probe;\n\t\t}\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"common probe failed.\\n\");\n\t\trc = -ENODEV;\n\t\tgoto err1;\n\t}\n\n\t \n\trc = qed_ops->fill_dev_info(qedf->cdev, &qedf->dev_info);\n\tif (rc) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Failed to dev info.\\n\");\n\t\tgoto err1;\n\t}\n\n\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC,\n\t\t  \"dev_info: num_hwfns=%d affin_hwfn_idx=%d.\\n\",\n\t\t  qedf->dev_info.common.num_hwfns,\n\t\t  qed_ops->common->get_affin_hwfn_idx(qedf->cdev));\n\n\t \n\trc = qedf_set_fcoe_pf_param(qedf);\n\tif (rc) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Cannot set fcoe pf param.\\n\");\n\t\tgoto err2;\n\t}\n\tqed_ops->common->update_pf_params(qedf->cdev, &qedf->pf_params);\n\n\t \n\trc = qed_ops->fill_dev_info(qedf->cdev, &qedf->dev_info);\n\tif (rc) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"Failed to fill dev info.\\n\");\n\t\tgoto err2;\n\t}\n\n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\tqedf->devlink = qed_ops->common->devlink_register(qedf->cdev);\n\t\tif (IS_ERR(qedf->devlink)) {\n\t\t\tQEDF_ERR(&qedf->dbg_ctx, \"Cannot register devlink\\n\");\n\t\t\trc = PTR_ERR(qedf->devlink);\n\t\t\tqedf->devlink = NULL;\n\t\t\tgoto err2;\n\t\t}\n\t}\n\n\t \n\tqedf->bdq_primary_prod = qedf->dev_info.primary_dbq_rq_addr;\n\tqedf->bdq_secondary_prod = qedf->dev_info.secondary_bdq_rq_addr;\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t    \"BDQ primary_prod=%p secondary_prod=%p.\\n\", qedf->bdq_primary_prod,\n\t    qedf->bdq_secondary_prod);\n\n\tqed_ops->register_ops(qedf->cdev, &qedf_cb_ops, qedf);\n\n\trc = qedf_prepare_sb(qedf);\n\tif (rc) {\n\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Cannot start slowpath.\\n\");\n\t\tgoto err2;\n\t}\n\n\t \n\tslowpath_params.int_mode = QED_INT_MODE_MSIX;\n\tslowpath_params.drv_major = QEDF_DRIVER_MAJOR_VER;\n\tslowpath_params.drv_minor = QEDF_DRIVER_MINOR_VER;\n\tslowpath_params.drv_rev = QEDF_DRIVER_REV_VER;\n\tslowpath_params.drv_eng = QEDF_DRIVER_ENG_VER;\n\tstrncpy(slowpath_params.name, \"qedf\", QED_DRV_VER_STR_SIZE);\n\trc = qed_ops->common->slowpath_start(qedf->cdev, &slowpath_params);\n\tif (rc) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Cannot start slowpath.\\n\");\n\t\tgoto err2;\n\t}\n\n\t \n\tqed_ops->common->update_pf_params(qedf->cdev, &qedf->pf_params);\n\n\t \n\trc = qedf_setup_int(qedf);\n\tif (rc) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"Setup interrupts failed.\\n\");\n\t\tgoto err3;\n\t}\n\n\trc = qed_ops->start(qedf->cdev, &qedf->tasks);\n\tif (rc) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Cannot start FCoE function.\\n\");\n\t\tgoto err4;\n\t}\n\ttask_start = qedf_get_task_mem(&qedf->tasks, 0);\n\ttask_end = qedf_get_task_mem(&qedf->tasks, MAX_TID_BLOCKS_FCOE - 1);\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC, \"Task context start=%p, \"\n\t\t   \"end=%p block_size=%u.\\n\", task_start, task_end,\n\t\t   qedf->tasks.size);\n\n\t \n\tqedf->bdq_prod_idx = QEDF_BDQ_SIZE;\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t    \"Writing %d to primary and secondary BDQ doorbell registers.\\n\",\n\t    qedf->bdq_prod_idx);\n\twritew(qedf->bdq_prod_idx, qedf->bdq_primary_prod);\n\treadw(qedf->bdq_primary_prod);\n\twritew(qedf->bdq_prod_idx, qedf->bdq_secondary_prod);\n\treadw(qedf->bdq_secondary_prod);\n\n\tqed_ops->common->set_power_state(qedf->cdev, PCI_D0);\n\n\t \n\tether_addr_copy(qedf->mac, qedf->dev_info.common.hw_mac);\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC, \"MAC address is %pM.\\n\",\n\t\t   qedf->mac);\n\n\t \n\tif (qedf->dev_info.wwnn != 0 && qedf->dev_info.wwpn != 0) {\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t    \"Setting WWPN and WWNN from qed dev_info.\\n\");\n\t\tqedf->wwnn = qedf->dev_info.wwnn;\n\t\tqedf->wwpn = qedf->dev_info.wwpn;\n\t} else {\n\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t    \"Setting WWPN and WWNN using fcoe_wwn_from_mac().\\n\");\n\t\tqedf->wwnn = fcoe_wwn_from_mac(qedf->mac, 1, 0);\n\t\tqedf->wwpn = fcoe_wwn_from_mac(qedf->mac, 2, 0);\n\t}\n\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,  \"WWNN=%016llx \"\n\t\t   \"WWPN=%016llx.\\n\", qedf->wwnn, qedf->wwpn);\n\n\tsprintf(host_buf, \"host_%d\", host->host_no);\n\tqed_ops->common->set_name(qedf->cdev, host_buf);\n\n\t \n\tqedf->cmd_mgr = qedf_cmd_mgr_alloc(qedf);\n\tif (!qedf->cmd_mgr) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Failed to allocate cmd mgr.\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto err5;\n\t}\n\n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\thost->transportt = qedf_fc_transport_template;\n\t\thost->max_lun = qedf_max_lun;\n\t\thost->max_cmd_len = QEDF_MAX_CDB_LEN;\n\t\thost->max_id = QEDF_MAX_SESSIONS;\n\t\thost->can_queue = FCOE_PARAMS_NUM_TASKS;\n\t\trc = scsi_add_host(host, &pdev->dev);\n\t\tif (rc) {\n\t\t\tQEDF_WARN(&qedf->dbg_ctx,\n\t\t\t\t  \"Error adding Scsi_Host rc=0x%x.\\n\", rc);\n\t\t\tgoto err6;\n\t\t}\n\t}\n\n\tmemset(&params, 0, sizeof(params));\n\tparams.mtu = QEDF_LL2_BUF_SIZE;\n\tether_addr_copy(params.ll2_mac_address, qedf->mac);\n\n\t \n\tsnprintf(host_buf, 20, \"qedf_%d_ll2\", host->host_no);\n\tqedf->ll2_recv_wq =\n\t\tcreate_workqueue(host_buf);\n\tif (!qedf->ll2_recv_wq) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Failed to LL2 workqueue.\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto err7;\n\t}\n\n#ifdef CONFIG_DEBUG_FS\n\tqedf_dbg_host_init(&(qedf->dbg_ctx), qedf_debugfs_ops,\n\t\t\t    qedf_dbg_fops);\n#endif\n\n\t \n\tqed_ops->ll2->register_cb_ops(qedf->cdev, &qedf_ll2_cb_ops, qedf);\n\trc = qed_ops->ll2->start(qedf->cdev, &params);\n\tif (rc) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Could not start Light L2.\\n\");\n\t\tgoto err7;\n\t}\n\tset_bit(QEDF_LL2_STARTED, &qedf->flags);\n\n\t \n\tqedf->vlan_id = 0;\n\n\t \n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\t \n\t\tqedf_fcoe_ctlr_setup(qedf);\n\n\t\t \n\t\trc = qedf_lport_setup(qedf);\n\t\tif (rc) {\n\t\t\tQEDF_ERR(&(qedf->dbg_ctx),\n\t\t\t    \"qedf_lport_setup failed.\\n\");\n\t\t\tgoto err7;\n\t\t}\n\t}\n\n\tsprintf(host_buf, \"qedf_%u_timer\", qedf->lport->host->host_no);\n\tqedf->timer_work_queue =\n\t\tcreate_workqueue(host_buf);\n\tif (!qedf->timer_work_queue) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx), \"Failed to start timer \"\n\t\t\t  \"workqueue.\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto err7;\n\t}\n\n\t \n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\tsprintf(host_buf, \"qedf_%u_dpc\",\n\t\t    qedf->lport->host->host_no);\n\t\tqedf->dpc_wq = create_workqueue(host_buf);\n\t}\n\tINIT_DELAYED_WORK(&qedf->recovery_work, qedf_recovery_handler);\n\n\t \n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\tqedf->grcdump_size =\n\t\t    qed_ops->common->dbg_all_data_size(qedf->cdev);\n\t\tif (qedf->grcdump_size) {\n\t\t\trc = qedf_alloc_grc_dump_buf(&qedf->grcdump,\n\t\t\t    qedf->grcdump_size);\n\t\t\tif (rc) {\n\t\t\t\tQEDF_ERR(&(qedf->dbg_ctx),\n\t\t\t\t    \"GRC Dump buffer alloc failed.\\n\");\n\t\t\t\tqedf->grcdump = NULL;\n\t\t\t}\n\n\t\t\tQEDF_INFO(&(qedf->dbg_ctx), QEDF_LOG_DISC,\n\t\t\t    \"grcdump: addr=%p, size=%u.\\n\",\n\t\t\t    qedf->grcdump, qedf->grcdump_size);\n\t\t}\n\t\tqedf_create_sysfs_ctx_attr(qedf);\n\n\t\t \n\t\tspin_lock_init(&qedf->io_trace_lock);\n\t\tqedf->io_trace_idx = 0;\n\t}\n\n\tinit_completion(&qedf->flogi_compl);\n\n\tstatus = qed_ops->common->update_drv_state(qedf->cdev, true);\n\tif (status)\n\t\tQEDF_ERR(&(qedf->dbg_ctx),\n\t\t\t\"Failed to send drv state to MFW.\\n\");\n\n\tmemset(&link_params, 0, sizeof(struct qed_link_params));\n\tlink_params.link_up = true;\n\tstatus = qed_ops->common->set_link(qedf->cdev, &link_params);\n\tif (status)\n\t\tQEDF_WARN(&(qedf->dbg_ctx), \"set_link failed.\\n\");\n\n\t \n\tif (mode == QEDF_MODE_RECOVERY)\n\t\tfcoe_ctlr_link_up(&qedf->ctlr);\n\telse\n\t\tfc_fabric_login(lport);\n\n\tQEDF_INFO(&qedf->dbg_ctx, QEDF_LOG_DISC, \"Probe done.\\n\");\n\n\tclear_bit(QEDF_PROBING, &qedf->flags);\n\n\t \n\treturn 0;\n\nerr7:\n\tif (qedf->ll2_recv_wq)\n\t\tdestroy_workqueue(qedf->ll2_recv_wq);\n\tfc_remove_host(qedf->lport->host);\n\tscsi_remove_host(qedf->lport->host);\n#ifdef CONFIG_DEBUG_FS\n\tqedf_dbg_host_exit(&(qedf->dbg_ctx));\n#endif\nerr6:\n\tqedf_cmd_mgr_free(qedf->cmd_mgr);\nerr5:\n\tqed_ops->stop(qedf->cdev);\nerr4:\n\tqedf_free_fcoe_pf_param(qedf);\n\tqedf_sync_free_irqs(qedf);\nerr3:\n\tqed_ops->common->slowpath_stop(qedf->cdev);\nerr2:\n\tqed_ops->common->remove(qedf->cdev);\nerr1:\n\tscsi_host_put(lport->host);\nerr0:\n\treturn rc;\n}\n\nstatic int qedf_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\treturn __qedf_probe(pdev, QEDF_MODE_NORMAL);\n}\n\nstatic void __qedf_remove(struct pci_dev *pdev, int mode)\n{\n\tstruct qedf_ctx *qedf;\n\tint rc;\n\n\tif (!pdev) {\n\t\tQEDF_ERR(NULL, \"pdev is NULL.\\n\");\n\t\treturn;\n\t}\n\n\tqedf = pci_get_drvdata(pdev);\n\n\t \n\tif (test_bit(QEDF_UNLOADING, &qedf->flags)) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"Already removing PCI function.\\n\");\n\t\treturn;\n\t}\n\n\tif (mode != QEDF_MODE_RECOVERY)\n\t\tset_bit(QEDF_UNLOADING, &qedf->flags);\n\n\t \n\tif (mode == QEDF_MODE_RECOVERY)\n\t\tfcoe_ctlr_link_down(&qedf->ctlr);\n\telse\n\t\tfc_fabric_logoff(qedf->lport);\n\n\tif (!qedf_wait_for_upload(qedf))\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"Could not upload all sessions.\\n\");\n\n#ifdef CONFIG_DEBUG_FS\n\tqedf_dbg_host_exit(&(qedf->dbg_ctx));\n#endif\n\n\t \n\tcancel_delayed_work_sync(&qedf->link_update);\n\tdestroy_workqueue(qedf->link_update_wq);\n\tqedf->link_update_wq = NULL;\n\n\tif (qedf->timer_work_queue)\n\t\tdestroy_workqueue(qedf->timer_work_queue);\n\n\t \n\tclear_bit(QEDF_LL2_STARTED, &qedf->flags);\n\tqed_ops->ll2->stop(qedf->cdev);\n\tif (qedf->ll2_recv_wq)\n\t\tdestroy_workqueue(qedf->ll2_recv_wq);\n\n\t \n\tqedf_sync_free_irqs(qedf);\n\tqedf_destroy_sb(qedf);\n\n\t \n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\tqedf_free_grc_dump_buf(&qedf->grcdump);\n\t\tqedf_remove_sysfs_ctx_attr(qedf);\n\n\t\t \n\t\tfcoe_ctlr_destroy(&qedf->ctlr);\n\t\tfc_lport_destroy(qedf->lport);\n\t\tfc_remove_host(qedf->lport->host);\n\t\tscsi_remove_host(qedf->lport->host);\n\t}\n\n\tqedf_cmd_mgr_free(qedf->cmd_mgr);\n\n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\tfc_exch_mgr_free(qedf->lport);\n\t\tfc_lport_free_stats(qedf->lport);\n\n\t\t \n\t\tqedf_wait_for_vport_destroy(qedf);\n\t}\n\n\t \n\tqed_ops->stop(qedf->cdev);\n\n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\tif (qedf->dpc_wq) {\n\t\t\t \n\t\t\tdestroy_workqueue(qedf->dpc_wq);\n\t\t\tqedf->dpc_wq = NULL;\n\t\t}\n\t}\n\n\t \n\tqedf_free_fcoe_pf_param(qedf);\n\tif (mode != QEDF_MODE_RECOVERY) {\n\t\tqed_ops->common->set_power_state(qedf->cdev, PCI_D0);\n\t\tpci_set_drvdata(pdev, NULL);\n\t}\n\n\trc = qed_ops->common->update_drv_state(qedf->cdev, false);\n\tif (rc)\n\t\tQEDF_ERR(&(qedf->dbg_ctx),\n\t\t\t\"Failed to send drv state to MFW.\\n\");\n\n\tif (mode != QEDF_MODE_RECOVERY && qedf->devlink) {\n\t\tqed_ops->common->devlink_unregister(qedf->devlink);\n\t\tqedf->devlink = NULL;\n\t}\n\n\tqed_ops->common->slowpath_stop(qedf->cdev);\n\tqed_ops->common->remove(qedf->cdev);\n\n\tmempool_destroy(qedf->io_mempool);\n\n\t \n\tif (mode != QEDF_MODE_RECOVERY)\n\t\tscsi_host_put(qedf->lport->host);\n}\n\nstatic void qedf_remove(struct pci_dev *pdev)\n{\n\t \n\tif (!atomic_read(&pdev->enable_cnt))\n\t\treturn;\n\n\t__qedf_remove(pdev, QEDF_MODE_NORMAL);\n}\n\nvoid qedf_wq_grcdump(struct work_struct *work)\n{\n\tstruct qedf_ctx *qedf =\n\t    container_of(work, struct qedf_ctx, grcdump_work.work);\n\n\tQEDF_ERR(&(qedf->dbg_ctx), \"Collecting GRC dump.\\n\");\n\tqedf_capture_grc_dump(qedf);\n}\n\nvoid qedf_schedule_hw_err_handler(void *dev, enum qed_hw_err_type err_type)\n{\n\tstruct qedf_ctx *qedf = dev;\n\n\tQEDF_ERR(&(qedf->dbg_ctx),\n\t\t\t\"Hardware error handler scheduled, event=%d.\\n\",\n\t\t\terr_type);\n\n\tif (test_bit(QEDF_IN_RECOVERY, &qedf->flags)) {\n\t\tQEDF_ERR(&(qedf->dbg_ctx),\n\t\t\t\t\"Already in recovery, not scheduling board disable work.\\n\");\n\t\treturn;\n\t}\n\n\tswitch (err_type) {\n\tcase QED_HW_ERR_FAN_FAIL:\n\t\tschedule_delayed_work(&qedf->board_disable_work, 0);\n\t\tbreak;\n\tcase QED_HW_ERR_MFW_RESP_FAIL:\n\tcase QED_HW_ERR_HW_ATTN:\n\tcase QED_HW_ERR_DMAE_FAIL:\n\tcase QED_HW_ERR_FW_ASSERT:\n\t\t \n\t\tqed_ops->common->attn_clr_enable(qedf->cdev, true);\n\t\tbreak;\n\tcase QED_HW_ERR_RAMROD_FAIL:\n\t\t \n\t\tqed_ops->common->attn_clr_enable(qedf->cdev, true);\n\n\t\tif (qedf_enable_recovery && qedf->devlink)\n\t\t\tqed_ops->common->report_fatal_error(qedf->devlink,\n\t\t\t\terr_type);\n\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n \nvoid qedf_get_protocol_tlv_data(void *dev, void *data)\n{\n\tstruct qedf_ctx *qedf = dev;\n\tstruct qed_mfw_tlv_fcoe *fcoe = data;\n\tstruct fc_lport *lport;\n\tstruct Scsi_Host *host;\n\tstruct fc_host_attrs *fc_host;\n\tstruct fc_host_statistics *hst;\n\n\tif (!qedf) {\n\t\tQEDF_ERR(NULL, \"qedf is null.\\n\");\n\t\treturn;\n\t}\n\n\tif (test_bit(QEDF_PROBING, &qedf->flags)) {\n\t\tQEDF_ERR(&qedf->dbg_ctx, \"Function is still probing.\\n\");\n\t\treturn;\n\t}\n\n\tlport = qedf->lport;\n\thost = lport->host;\n\tfc_host = shost_to_fc_host(host);\n\n\t \n\thst = qedf_fc_get_host_stats(host);\n\n\tfcoe->qos_pri_set = true;\n\tfcoe->qos_pri = 3;  \n\n\tfcoe->ra_tov_set = true;\n\tfcoe->ra_tov = lport->r_a_tov;\n\n\tfcoe->ed_tov_set = true;\n\tfcoe->ed_tov = lport->e_d_tov;\n\n\tfcoe->npiv_state_set = true;\n\tfcoe->npiv_state = 1;  \n\n\tfcoe->num_npiv_ids_set = true;\n\tfcoe->num_npiv_ids = fc_host->npiv_vports_inuse;\n\n\t \n\tif (qedf->ctlr.sel_fcf) {\n\t\tfcoe->switch_name_set = true;\n\t\tu64_to_wwn(qedf->ctlr.sel_fcf->switch_name, fcoe->switch_name);\n\t}\n\n\tfcoe->port_state_set = true;\n\t \n\tif (lport->link_up)\n\t\tfcoe->port_state = QED_MFW_TLV_PORT_STATE_FABRIC;\n\telse\n\t\tfcoe->port_state = QED_MFW_TLV_PORT_STATE_OFFLINE;\n\n\tfcoe->link_failures_set = true;\n\tfcoe->link_failures = (u16)hst->link_failure_count;\n\n\tfcoe->fcoe_txq_depth_set = true;\n\tfcoe->fcoe_rxq_depth_set = true;\n\tfcoe->fcoe_rxq_depth = FCOE_PARAMS_NUM_TASKS;\n\tfcoe->fcoe_txq_depth = FCOE_PARAMS_NUM_TASKS;\n\n\tfcoe->fcoe_rx_frames_set = true;\n\tfcoe->fcoe_rx_frames = hst->rx_frames;\n\n\tfcoe->fcoe_tx_frames_set = true;\n\tfcoe->fcoe_tx_frames = hst->tx_frames;\n\n\tfcoe->fcoe_rx_bytes_set = true;\n\tfcoe->fcoe_rx_bytes = hst->fcp_input_megabytes * 1000000;\n\n\tfcoe->fcoe_tx_bytes_set = true;\n\tfcoe->fcoe_tx_bytes = hst->fcp_output_megabytes * 1000000;\n\n\tfcoe->crc_count_set = true;\n\tfcoe->crc_count = hst->invalid_crc_count;\n\n\tfcoe->tx_abts_set = true;\n\tfcoe->tx_abts = hst->fcp_packet_aborts;\n\n\tfcoe->tx_lun_rst_set = true;\n\tfcoe->tx_lun_rst = qedf->lun_resets;\n\n\tfcoe->abort_task_sets_set = true;\n\tfcoe->abort_task_sets = qedf->packet_aborts;\n\n\tfcoe->scsi_busy_set = true;\n\tfcoe->scsi_busy = qedf->busy;\n\n\tfcoe->scsi_tsk_full_set = true;\n\tfcoe->scsi_tsk_full = qedf->task_set_fulls;\n}\n\n \nvoid qedf_stag_change_work(struct work_struct *work)\n{\n\tstruct qedf_ctx *qedf =\n\t    container_of(work, struct qedf_ctx, stag_work.work);\n\n\tprintk_ratelimited(\"[%s]:[%s:%d]:%d: Performing software context reset.\",\n\t\t\tdev_name(&qedf->pdev->dev), __func__, __LINE__,\n\t\t\tqedf->dbg_ctx.host_no);\n\tqedf_ctx_soft_reset(qedf->lport);\n}\n\nstatic void qedf_shutdown(struct pci_dev *pdev)\n{\n\t__qedf_remove(pdev, QEDF_MODE_NORMAL);\n}\n\nstatic int qedf_suspend(struct pci_dev *pdev, pm_message_t state)\n{\n\tstruct qedf_ctx *qedf;\n\n\tif (!pdev) {\n\t\tQEDF_ERR(NULL, \"pdev is NULL.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tqedf = pci_get_drvdata(pdev);\n\n\tQEDF_ERR(&qedf->dbg_ctx, \"%s: Device does not support suspend operation\\n\", __func__);\n\n\treturn -EPERM;\n}\n\n \nstatic void qedf_schedule_recovery_handler(void *dev)\n{\n\tstruct qedf_ctx *qedf = dev;\n\n\tQEDF_ERR(&qedf->dbg_ctx, \"Recovery handler scheduled.\\n\");\n\tschedule_delayed_work(&qedf->recovery_work, 0);\n}\n\nstatic void qedf_recovery_handler(struct work_struct *work)\n{\n\tstruct qedf_ctx *qedf =\n\t    container_of(work, struct qedf_ctx, recovery_work.work);\n\n\tif (test_and_set_bit(QEDF_IN_RECOVERY, &qedf->flags))\n\t\treturn;\n\n\t \n\tqed_ops->common->recovery_prolog(qedf->cdev);\n\n\tQEDF_ERR(&qedf->dbg_ctx, \"Recovery work start.\\n\");\n\t__qedf_remove(qedf->pdev, QEDF_MODE_RECOVERY);\n\t \n\tatomic_set(&qedf->link_state, QEDF_LINK_DOWN);\n\tatomic_set(&qedf->dcbx, QEDF_DCBX_PENDING);\n\t__qedf_probe(qedf->pdev, QEDF_MODE_RECOVERY);\n\tclear_bit(QEDF_IN_RECOVERY, &qedf->flags);\n\tQEDF_ERR(&qedf->dbg_ctx, \"Recovery work complete.\\n\");\n}\n\n \nvoid qedf_get_generic_tlv_data(void *dev, struct qed_generic_tlvs *data)\n{\n\tstruct qedf_ctx *qedf;\n\n\tif (!dev) {\n\t\tQEDF_INFO(NULL, QEDF_LOG_EVT,\n\t\t\t  \"dev is NULL so ignoring get_generic_tlv_data request.\\n\");\n\t\treturn;\n\t}\n\tqedf = (struct qedf_ctx *)dev;\n\n\tmemset(data, 0, sizeof(struct qed_generic_tlvs));\n\tether_addr_copy(data->mac[0], qedf->mac);\n}\n\n \n\nstatic int __init qedf_init(void)\n{\n\tint ret;\n\n\t \n\tif (qedf_debug == QEDF_LOG_DEFAULT)\n\t\tqedf_debug = QEDF_DEFAULT_LOG_MASK;\n\n\t \n\tif (qedf_default_prio > -1)\n\t\tif (qedf_default_prio > 7) {\n\t\t\tqedf_default_prio = QEDF_DEFAULT_PRIO;\n\t\t\tQEDF_ERR(NULL, \"FCoE/FIP priority out of range, resetting to %d.\\n\",\n\t\t\t    QEDF_DEFAULT_PRIO);\n\t\t}\n\n\t \n\tQEDF_INFO(NULL, QEDF_LOG_INFO, \"%s v%s.\\n\", QEDF_DESCR,\n\t\t   QEDF_VERSION);\n\n\t \n\tqedf_io_work_cache = kmem_cache_create(\"qedf_io_work_cache\",\n\t    sizeof(struct qedf_io_work), 0, SLAB_HWCACHE_ALIGN, NULL);\n\tif (qedf_io_work_cache == NULL) {\n\t\tQEDF_ERR(NULL, \"qedf_io_work_cache is NULL.\\n\");\n\t\tgoto err1;\n\t}\n\tQEDF_INFO(NULL, QEDF_LOG_DISC, \"qedf_io_work_cache=%p.\\n\",\n\t    qedf_io_work_cache);\n\n\tqed_ops = qed_get_fcoe_ops();\n\tif (!qed_ops) {\n\t\tQEDF_ERR(NULL, \"Failed to get qed fcoe operations\\n\");\n\t\tgoto err1;\n\t}\n\n#ifdef CONFIG_DEBUG_FS\n\tqedf_dbg_init(\"qedf\");\n#endif\n\n\tqedf_fc_transport_template =\n\t    fc_attach_transport(&qedf_fc_transport_fn);\n\tif (!qedf_fc_transport_template) {\n\t\tQEDF_ERR(NULL, \"Could not register with FC transport\\n\");\n\t\tgoto err2;\n\t}\n\n\tqedf_fc_vport_transport_template =\n\t\tfc_attach_transport(&qedf_fc_vport_transport_fn);\n\tif (!qedf_fc_vport_transport_template) {\n\t\tQEDF_ERR(NULL, \"Could not register vport template with FC \"\n\t\t\t  \"transport\\n\");\n\t\tgoto err3;\n\t}\n\n\tqedf_io_wq = create_workqueue(\"qedf_io_wq\");\n\tif (!qedf_io_wq) {\n\t\tQEDF_ERR(NULL, \"Could not create qedf_io_wq.\\n\");\n\t\tgoto err4;\n\t}\n\n\tqedf_cb_ops.get_login_failures = qedf_get_login_failures;\n\n\tret = pci_register_driver(&qedf_pci_driver);\n\tif (ret) {\n\t\tQEDF_ERR(NULL, \"Failed to register driver\\n\");\n\t\tgoto err5;\n\t}\n\n\treturn 0;\n\nerr5:\n\tdestroy_workqueue(qedf_io_wq);\nerr4:\n\tfc_release_transport(qedf_fc_vport_transport_template);\nerr3:\n\tfc_release_transport(qedf_fc_transport_template);\nerr2:\n#ifdef CONFIG_DEBUG_FS\n\tqedf_dbg_exit();\n#endif\n\tqed_put_fcoe_ops();\nerr1:\n\treturn -EINVAL;\n}\n\nstatic void __exit qedf_cleanup(void)\n{\n\tpci_unregister_driver(&qedf_pci_driver);\n\n\tdestroy_workqueue(qedf_io_wq);\n\n\tfc_release_transport(qedf_fc_vport_transport_template);\n\tfc_release_transport(qedf_fc_transport_template);\n#ifdef CONFIG_DEBUG_FS\n\tqedf_dbg_exit();\n#endif\n\tqed_put_fcoe_ops();\n\n\tkmem_cache_destroy(qedf_io_work_cache);\n}\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"QLogic FastLinQ 4xxxx FCoE Module\");\nMODULE_AUTHOR(\"QLogic Corporation\");\nMODULE_VERSION(QEDF_VERSION);\nmodule_init(qedf_init);\nmodule_exit(qedf_cleanup);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}