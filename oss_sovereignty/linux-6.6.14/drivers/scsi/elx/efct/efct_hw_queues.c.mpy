{
  "module_name": "efct_hw_queues.c",
  "hash_id": "8b77701fe0195ceb10947237b5877578c151f855046cebe4de4d2ebaa8c6636f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/elx/efct/efct_hw_queues.c",
  "human_readable_source": "\n \n\n#include \"efct_driver.h\"\n#include \"efct_hw.h\"\n#include \"efct_unsol.h\"\n\nint\nefct_hw_init_queues(struct efct_hw *hw)\n{\n\tstruct hw_eq *eq = NULL;\n\tstruct hw_cq *cq = NULL;\n\tstruct hw_wq *wq = NULL;\n\tstruct hw_mq *mq = NULL;\n\n\tstruct hw_eq *eqs[EFCT_HW_MAX_NUM_EQ];\n\tstruct hw_cq *cqs[EFCT_HW_MAX_NUM_EQ];\n\tstruct hw_rq *rqs[EFCT_HW_MAX_NUM_EQ];\n\tu32 i = 0, j;\n\n\thw->eq_count = 0;\n\thw->cq_count = 0;\n\thw->mq_count = 0;\n\thw->wq_count = 0;\n\thw->rq_count = 0;\n\thw->hw_rq_count = 0;\n\tINIT_LIST_HEAD(&hw->eq_list);\n\n\tfor (i = 0; i < hw->config.n_eq; i++) {\n\t\t \n\t\teq = efct_hw_new_eq(hw, EFCT_HW_EQ_DEPTH);\n\t\tif (!eq) {\n\t\t\tefct_hw_queue_teardown(hw);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\teqs[i] = eq;\n\n\t\t \n\t\tif (!i) {\n\t\t\tcq = efct_hw_new_cq(eq,\n\t\t\t\t\t    hw->num_qentries[SLI4_QTYPE_CQ]);\n\t\t\tif (!cq) {\n\t\t\t\tefct_hw_queue_teardown(hw);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\tmq = efct_hw_new_mq(cq, EFCT_HW_MQ_DEPTH);\n\t\t\tif (!mq) {\n\t\t\t\tefct_hw_queue_teardown(hw);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tcq = efct_hw_new_cq(eq, hw->num_qentries[SLI4_QTYPE_CQ]);\n\t\tif (!cq) {\n\t\t\tefct_hw_queue_teardown(hw);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\twq = efct_hw_new_wq(cq, hw->num_qentries[SLI4_QTYPE_WQ]);\n\t\tif (!wq) {\n\t\t\tefct_hw_queue_teardown(hw);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\t \n\tif (efct_hw_new_cq_set(eqs, cqs, i, hw->num_qentries[SLI4_QTYPE_CQ])) {\n\t\tefct_hw_queue_teardown(hw);\n\t\treturn -EIO;\n\t}\n\n\t \n\tif (efct_hw_new_rq_set(cqs, rqs, i, EFCT_HW_RQ_ENTRIES_DEF)) {\n\t\tefct_hw_queue_teardown(hw);\n\t\treturn -EIO;\n\t}\n\n\tfor (j = 0; j < i ; j++) {\n\t\trqs[j]->filter_mask = 0;\n\t\trqs[j]->is_mrq = true;\n\t\trqs[j]->base_mrq_id = rqs[0]->hdr->id;\n\t}\n\n\thw->hw_mrq_count = i;\n\n\treturn 0;\n}\n\nint\nefct_hw_map_wq_cpu(struct efct_hw *hw)\n{\n\tstruct efct *efct = hw->os;\n\tu32 cpu = 0, i;\n\n\t \n\thw->wq_cpu_array = kcalloc(num_possible_cpus(), sizeof(void *),\n\t\t\t\t   GFP_KERNEL);\n\tif (!hw->wq_cpu_array)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < hw->config.n_eq; i++) {\n\t\tconst struct cpumask *maskp;\n\n\t\t \n\t\tmaskp = pci_irq_get_affinity(efct->pci, i);\n\t\tif (!maskp) {\n\t\t\tefc_log_debug(efct, \"maskp null for vector:%d\\n\", i);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tfor_each_cpu_and(cpu, maskp, cpu_present_mask) {\n\t\t\tefc_log_debug(efct, \"CPU:%d irq vector:%d\\n\", cpu, i);\n\t\t\thw->wq_cpu_array[cpu] = hw->hw_wq[i];\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstruct hw_eq *\nefct_hw_new_eq(struct efct_hw *hw, u32 entry_count)\n{\n\tstruct hw_eq *eq = kzalloc(sizeof(*eq), GFP_KERNEL);\n\n\tif (!eq)\n\t\treturn NULL;\n\n\teq->type = SLI4_QTYPE_EQ;\n\teq->hw = hw;\n\teq->entry_count = entry_count;\n\teq->instance = hw->eq_count++;\n\teq->queue = &hw->eq[eq->instance];\n\tINIT_LIST_HEAD(&eq->cq_list);\n\n\tif (sli_queue_alloc(&hw->sli, SLI4_QTYPE_EQ, eq->queue,\tentry_count,\n\t\t\t    NULL)) {\n\t\tefc_log_err(hw->os, \"EQ[%d] alloc failure\\n\", eq->instance);\n\t\tkfree(eq);\n\t\treturn NULL;\n\t}\n\n\tsli_eq_modify_delay(&hw->sli, eq->queue, 1, 0, 8);\n\thw->hw_eq[eq->instance] = eq;\n\tINIT_LIST_HEAD(&eq->list_entry);\n\tlist_add_tail(&eq->list_entry, &hw->eq_list);\n\tefc_log_debug(hw->os, \"create eq[%2d] id %3d len %4d\\n\", eq->instance,\n\t\t      eq->queue->id, eq->entry_count);\n\treturn eq;\n}\n\nstruct hw_cq *\nefct_hw_new_cq(struct hw_eq *eq, u32 entry_count)\n{\n\tstruct efct_hw *hw = eq->hw;\n\tstruct hw_cq *cq = kzalloc(sizeof(*cq), GFP_KERNEL);\n\n\tif (!cq)\n\t\treturn NULL;\n\n\tcq->eq = eq;\n\tcq->type = SLI4_QTYPE_CQ;\n\tcq->instance = eq->hw->cq_count++;\n\tcq->entry_count = entry_count;\n\tcq->queue = &hw->cq[cq->instance];\n\n\tINIT_LIST_HEAD(&cq->q_list);\n\n\tif (sli_queue_alloc(&hw->sli, SLI4_QTYPE_CQ, cq->queue,\n\t\t\t    cq->entry_count, eq->queue)) {\n\t\tefc_log_err(hw->os, \"CQ[%d] allocation failure len=%d\\n\",\n\t\t\t    eq->instance, eq->entry_count);\n\t\tkfree(cq);\n\t\treturn NULL;\n\t}\n\n\thw->hw_cq[cq->instance] = cq;\n\tINIT_LIST_HEAD(&cq->list_entry);\n\tlist_add_tail(&cq->list_entry, &eq->cq_list);\n\tefc_log_debug(hw->os, \"create cq[%2d] id %3d len %4d\\n\", cq->instance,\n\t\t      cq->queue->id, cq->entry_count);\n\treturn cq;\n}\n\nu32\nefct_hw_new_cq_set(struct hw_eq *eqs[], struct hw_cq *cqs[],\n\t\t   u32 num_cqs, u32 entry_count)\n{\n\tu32 i;\n\tstruct efct_hw *hw = eqs[0]->hw;\n\tstruct sli4 *sli4 = &hw->sli;\n\tstruct hw_cq *cq = NULL;\n\tstruct sli4_queue *qs[SLI4_MAX_CQ_SET_COUNT];\n\tstruct sli4_queue *assefct[SLI4_MAX_CQ_SET_COUNT];\n\n\t \n\tfor (i = 0; i < num_cqs; i++)\n\t\tcqs[i] = NULL;\n\n\tfor (i = 0; i < num_cqs; i++) {\n\t\tcq = kzalloc(sizeof(*cq), GFP_KERNEL);\n\t\tif (!cq)\n\t\t\tgoto error;\n\n\t\tcqs[i]          = cq;\n\t\tcq->eq          = eqs[i];\n\t\tcq->type        = SLI4_QTYPE_CQ;\n\t\tcq->instance    = hw->cq_count++;\n\t\tcq->entry_count = entry_count;\n\t\tcq->queue       = &hw->cq[cq->instance];\n\t\tqs[i]           = cq->queue;\n\t\tassefct[i]       = eqs[i]->queue;\n\t\tINIT_LIST_HEAD(&cq->q_list);\n\t}\n\n\tif (sli_cq_alloc_set(sli4, qs, num_cqs, entry_count, assefct)) {\n\t\tefc_log_err(hw->os, \"Failed to create CQ Set.\\n\");\n\t\tgoto error;\n\t}\n\n\tfor (i = 0; i < num_cqs; i++) {\n\t\thw->hw_cq[cqs[i]->instance] = cqs[i];\n\t\tINIT_LIST_HEAD(&cqs[i]->list_entry);\n\t\tlist_add_tail(&cqs[i]->list_entry, &cqs[i]->eq->cq_list);\n\t}\n\n\treturn 0;\n\nerror:\n\tfor (i = 0; i < num_cqs; i++) {\n\t\tkfree(cqs[i]);\n\t\tcqs[i] = NULL;\n\t}\n\treturn -EIO;\n}\n\nstruct hw_mq *\nefct_hw_new_mq(struct hw_cq *cq, u32 entry_count)\n{\n\tstruct efct_hw *hw = cq->eq->hw;\n\tstruct hw_mq *mq = kzalloc(sizeof(*mq), GFP_KERNEL);\n\n\tif (!mq)\n\t\treturn NULL;\n\n\tmq->cq = cq;\n\tmq->type = SLI4_QTYPE_MQ;\n\tmq->instance = cq->eq->hw->mq_count++;\n\tmq->entry_count = entry_count;\n\tmq->entry_size = EFCT_HW_MQ_DEPTH;\n\tmq->queue = &hw->mq[mq->instance];\n\n\tif (sli_queue_alloc(&hw->sli, SLI4_QTYPE_MQ, mq->queue, mq->entry_size,\n\t\t\t    cq->queue)) {\n\t\tefc_log_err(hw->os, \"MQ allocation failure\\n\");\n\t\tkfree(mq);\n\t\treturn NULL;\n\t}\n\n\thw->hw_mq[mq->instance] = mq;\n\tINIT_LIST_HEAD(&mq->list_entry);\n\tlist_add_tail(&mq->list_entry, &cq->q_list);\n\tefc_log_debug(hw->os, \"create mq[%2d] id %3d len %4d\\n\", mq->instance,\n\t\t      mq->queue->id, mq->entry_count);\n\treturn mq;\n}\n\nstruct hw_wq *\nefct_hw_new_wq(struct hw_cq *cq, u32 entry_count)\n{\n\tstruct efct_hw *hw = cq->eq->hw;\n\tstruct hw_wq *wq = kzalloc(sizeof(*wq), GFP_KERNEL);\n\n\tif (!wq)\n\t\treturn NULL;\n\n\twq->hw = cq->eq->hw;\n\twq->cq = cq;\n\twq->type = SLI4_QTYPE_WQ;\n\twq->instance = cq->eq->hw->wq_count++;\n\twq->entry_count = entry_count;\n\twq->queue = &hw->wq[wq->instance];\n\twq->wqec_set_count = EFCT_HW_WQEC_SET_COUNT;\n\twq->wqec_count = wq->wqec_set_count;\n\twq->free_count = wq->entry_count - 1;\n\tINIT_LIST_HEAD(&wq->pending_list);\n\n\tif (sli_queue_alloc(&hw->sli, SLI4_QTYPE_WQ, wq->queue,\n\t\t\t    wq->entry_count, cq->queue)) {\n\t\tefc_log_err(hw->os, \"WQ allocation failure\\n\");\n\t\tkfree(wq);\n\t\treturn NULL;\n\t}\n\n\thw->hw_wq[wq->instance] = wq;\n\tINIT_LIST_HEAD(&wq->list_entry);\n\tlist_add_tail(&wq->list_entry, &cq->q_list);\n\tefc_log_debug(hw->os, \"create wq[%2d] id %3d len %4d cls %d\\n\",\n\t\t      wq->instance, wq->queue->id, wq->entry_count, wq->class);\n\treturn wq;\n}\n\nu32\nefct_hw_new_rq_set(struct hw_cq *cqs[], struct hw_rq *rqs[],\n\t\t   u32 num_rq_pairs, u32 entry_count)\n{\n\tstruct efct_hw *hw = cqs[0]->eq->hw;\n\tstruct hw_rq *rq = NULL;\n\tstruct sli4_queue *qs[SLI4_MAX_RQ_SET_COUNT * 2] = { NULL };\n\tu32 i, q_count, size;\n\n\t \n\tfor (i = 0; i < num_rq_pairs; i++)\n\t\trqs[i] = NULL;\n\n\t \n\tfor (i = 0, q_count = 0; i < num_rq_pairs; i++, q_count += 2) {\n\t\trq = kzalloc(sizeof(*rq), GFP_KERNEL);\n\t\tif (!rq)\n\t\t\tgoto error;\n\n\t\trqs[i] = rq;\n\t\trq->instance = hw->hw_rq_count++;\n\t\trq->cq = cqs[i];\n\t\trq->type = SLI4_QTYPE_RQ;\n\t\trq->entry_count = entry_count;\n\n\t\t \n\t\trq->hdr = &hw->rq[hw->rq_count];\n\t\trq->hdr_entry_size = EFCT_HW_RQ_HEADER_SIZE;\n\t\thw->hw_rq_lookup[hw->rq_count] = rq->instance;\n\t\thw->rq_count++;\n\t\tqs[q_count] = rq->hdr;\n\n\t\t \n\t\trq->data = &hw->rq[hw->rq_count];\n\t\trq->data_entry_size = hw->config.rq_default_buffer_size;\n\t\thw->hw_rq_lookup[hw->rq_count] = rq->instance;\n\t\thw->rq_count++;\n\t\tqs[q_count + 1] = rq->data;\n\n\t\trq->rq_tracker = NULL;\n\t}\n\n\tif (sli_fc_rq_set_alloc(&hw->sli, num_rq_pairs, qs,\n\t\t\t\tcqs[0]->queue->id,\n\t\t\t    rqs[0]->entry_count,\n\t\t\t    rqs[0]->hdr_entry_size,\n\t\t\t    rqs[0]->data_entry_size)) {\n\t\tefc_log_err(hw->os, \"RQ Set alloc failure for base CQ=%d\\n\",\n\t\t\t    cqs[0]->queue->id);\n\t\tgoto error;\n\t}\n\n\tfor (i = 0; i < num_rq_pairs; i++) {\n\t\thw->hw_rq[rqs[i]->instance] = rqs[i];\n\t\tINIT_LIST_HEAD(&rqs[i]->list_entry);\n\t\tlist_add_tail(&rqs[i]->list_entry, &cqs[i]->q_list);\n\t\tsize = sizeof(struct efc_hw_sequence *) * rqs[i]->entry_count;\n\t\trqs[i]->rq_tracker = kzalloc(size, GFP_KERNEL);\n\t\tif (!rqs[i]->rq_tracker)\n\t\t\tgoto error;\n\t}\n\n\treturn 0;\n\nerror:\n\tfor (i = 0; i < num_rq_pairs; i++) {\n\t\tif (rqs[i]) {\n\t\t\tkfree(rqs[i]->rq_tracker);\n\t\t\tkfree(rqs[i]);\n\t\t}\n\t}\n\n\treturn -EIO;\n}\n\nvoid\nefct_hw_del_eq(struct hw_eq *eq)\n{\n\tstruct hw_cq *cq;\n\tstruct hw_cq *cq_next;\n\n\tif (!eq)\n\t\treturn;\n\n\tlist_for_each_entry_safe(cq, cq_next, &eq->cq_list, list_entry)\n\t\tefct_hw_del_cq(cq);\n\tlist_del(&eq->list_entry);\n\teq->hw->hw_eq[eq->instance] = NULL;\n\tkfree(eq);\n}\n\nvoid\nefct_hw_del_cq(struct hw_cq *cq)\n{\n\tstruct hw_q *q;\n\tstruct hw_q *q_next;\n\n\tif (!cq)\n\t\treturn;\n\n\tlist_for_each_entry_safe(q, q_next, &cq->q_list, list_entry) {\n\t\tswitch (q->type) {\n\t\tcase SLI4_QTYPE_MQ:\n\t\t\tefct_hw_del_mq((struct hw_mq *)q);\n\t\t\tbreak;\n\t\tcase SLI4_QTYPE_WQ:\n\t\t\tefct_hw_del_wq((struct hw_wq *)q);\n\t\t\tbreak;\n\t\tcase SLI4_QTYPE_RQ:\n\t\t\tefct_hw_del_rq((struct hw_rq *)q);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tlist_del(&cq->list_entry);\n\tcq->eq->hw->hw_cq[cq->instance] = NULL;\n\tkfree(cq);\n}\n\nvoid\nefct_hw_del_mq(struct hw_mq *mq)\n{\n\tif (!mq)\n\t\treturn;\n\n\tlist_del(&mq->list_entry);\n\tmq->cq->eq->hw->hw_mq[mq->instance] = NULL;\n\tkfree(mq);\n}\n\nvoid\nefct_hw_del_wq(struct hw_wq *wq)\n{\n\tif (!wq)\n\t\treturn;\n\n\tlist_del(&wq->list_entry);\n\twq->cq->eq->hw->hw_wq[wq->instance] = NULL;\n\tkfree(wq);\n}\n\nvoid\nefct_hw_del_rq(struct hw_rq *rq)\n{\n\tstruct efct_hw *hw = NULL;\n\n\tif (!rq)\n\t\treturn;\n\t \n\tkfree(rq->rq_tracker);\n\trq->rq_tracker = NULL;\n\tlist_del(&rq->list_entry);\n\thw = rq->cq->eq->hw;\n\thw->hw_rq[rq->instance] = NULL;\n\tkfree(rq);\n}\n\nvoid\nefct_hw_queue_teardown(struct efct_hw *hw)\n{\n\tstruct hw_eq *eq;\n\tstruct hw_eq *eq_next;\n\n\tif (!hw->eq_list.next)\n\t\treturn;\n\n\tlist_for_each_entry_safe(eq, eq_next, &hw->eq_list, list_entry)\n\t\tefct_hw_del_eq(eq);\n}\n\nstatic inline int\nefct_hw_rqpair_find(struct efct_hw *hw, u16 rq_id)\n{\n\treturn efct_hw_queue_hash_find(hw->rq_hash, rq_id);\n}\n\nstatic struct efc_hw_sequence *\nefct_hw_rqpair_get(struct efct_hw *hw, u16 rqindex, u16 bufindex)\n{\n\tstruct sli4_queue *rq_hdr = &hw->rq[rqindex];\n\tstruct efc_hw_sequence *seq = NULL;\n\tstruct hw_rq *rq = hw->hw_rq[hw->hw_rq_lookup[rqindex]];\n\tunsigned long flags = 0;\n\n\tif (bufindex >= rq_hdr->length) {\n\t\tefc_log_err(hw->os,\n\t\t\t    \"RQidx %d bufidx %d exceed ring len %d for id %d\\n\",\n\t\t\t    rqindex, bufindex, rq_hdr->length, rq_hdr->id);\n\t\treturn NULL;\n\t}\n\n\t \n\tspin_lock_irqsave(&rq_hdr->lock, flags);\n\n\tseq = rq->rq_tracker[bufindex];\n\trq->rq_tracker[bufindex] = NULL;\n\n\tif (!seq) {\n\t\tefc_log_err(hw->os,\n\t\t\t    \"RQbuf NULL, rqidx %d, bufidx %d, cur q idx = %d\\n\",\n\t\t\t    rqindex, bufindex, rq_hdr->index);\n\t}\n\n\tspin_unlock_irqrestore(&rq_hdr->lock, flags);\n\treturn seq;\n}\n\nint\nefct_hw_rqpair_process_rq(struct efct_hw *hw, struct hw_cq *cq,\n\t\t\t  u8 *cqe)\n{\n\tu16 rq_id;\n\tu32 index;\n\tint rqindex;\n\tint rq_status;\n\tu32 h_len;\n\tu32 p_len;\n\tstruct efc_hw_sequence *seq;\n\tstruct hw_rq *rq;\n\n\trq_status = sli_fc_rqe_rqid_and_index(&hw->sli, cqe,\n\t\t\t\t\t      &rq_id, &index);\n\tif (rq_status != 0) {\n\t\tswitch (rq_status) {\n\t\tcase SLI4_FC_ASYNC_RQ_BUF_LEN_EXCEEDED:\n\t\tcase SLI4_FC_ASYNC_RQ_DMA_FAILURE:\n\t\t\t \n\t\t\trqindex = efct_hw_rqpair_find(hw, rq_id);\n\t\t\tif (rqindex < 0) {\n\t\t\t\tefc_log_debug(hw->os,\n\t\t\t\t\t      \"status=%#x: lookup fail id=%#x\\n\",\n\t\t\t\t\t     rq_status, rq_id);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tseq = efct_hw_rqpair_get(hw, rqindex, index);\n\n\t\t\t \n\t\t\tif (efct_hw_rqpair_sequence_free(hw, seq)) {\n\t\t\t\tefc_log_debug(hw->os,\n\t\t\t\t\t      \"status=%#x,fail rtrn buf to RQ\\n\",\n\t\t\t\t\t     rq_status);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase SLI4_FC_ASYNC_RQ_INSUFF_BUF_NEEDED:\n\t\tcase SLI4_FC_ASYNC_RQ_INSUFF_BUF_FRM_DISC:\n\t\t\t \n\t\t\tefc_log_debug(hw->os, \"Warning: RCQE status=%#x,\\n\",\n\t\t\t\t      rq_status);\n\t\t\tfallthrough;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\treturn -EIO;\n\t}\n\n\trqindex = efct_hw_rqpair_find(hw, rq_id);\n\tif (rqindex < 0) {\n\t\tefc_log_debug(hw->os, \"Error: rq_id lookup failed for id=%#x\\n\",\n\t\t\t      rq_id);\n\t\treturn -EIO;\n\t}\n\n\trq = hw->hw_rq[hw->hw_rq_lookup[rqindex]];\n\trq->use_count++;\n\n\tseq = efct_hw_rqpair_get(hw, rqindex, index);\n\tif (WARN_ON(!seq))\n\t\treturn -EIO;\n\n\tseq->hw = hw;\n\n\tsli_fc_rqe_length(&hw->sli, cqe, &h_len, &p_len);\n\tseq->header->dma.len = h_len;\n\tseq->payload->dma.len = p_len;\n\tseq->fcfi = sli_fc_rqe_fcfi(&hw->sli, cqe);\n\tseq->hw_priv = cq->eq;\n\n\tefct_unsolicited_cb(hw->os, seq);\n\n\treturn 0;\n}\n\nstatic int\nefct_hw_rqpair_put(struct efct_hw *hw, struct efc_hw_sequence *seq)\n{\n\tstruct sli4_queue *rq_hdr = &hw->rq[seq->header->rqindex];\n\tstruct sli4_queue *rq_payload = &hw->rq[seq->payload->rqindex];\n\tu32 hw_rq_index = hw->hw_rq_lookup[seq->header->rqindex];\n\tstruct hw_rq *rq = hw->hw_rq[hw_rq_index];\n\tu32 phys_hdr[2];\n\tu32 phys_payload[2];\n\tint qindex_hdr;\n\tint qindex_payload;\n\tunsigned long flags = 0;\n\n\t \n\tphys_hdr[0] = upper_32_bits(seq->header->dma.phys);\n\tphys_hdr[1] = lower_32_bits(seq->header->dma.phys);\n\tphys_payload[0] = upper_32_bits(seq->payload->dma.phys);\n\tphys_payload[1] = lower_32_bits(seq->payload->dma.phys);\n\n\t \n\tspin_lock_irqsave(&rq_hdr->lock, flags);\n\n\t \n\tqindex_payload = sli_rq_write(&hw->sli, rq_payload,\n\t\t\t\t      (void *)phys_payload);\n\tqindex_hdr = sli_rq_write(&hw->sli, rq_hdr, (void *)phys_hdr);\n\tif (qindex_hdr < 0 ||\n\t    qindex_payload < 0) {\n\t\tefc_log_err(hw->os, \"RQ_ID=%#x write failed\\n\", rq_hdr->id);\n\t\tspin_unlock_irqrestore(&rq_hdr->lock, flags);\n\t\treturn -EIO;\n\t}\n\n\t \n\tWARN_ON(qindex_hdr != qindex_payload);\n\n\t \n\tif (!rq->rq_tracker[qindex_hdr]) {\n\t\trq->rq_tracker[qindex_hdr] = seq;\n\t} else {\n\t\tefc_log_debug(hw->os,\n\t\t\t      \"expected rq_tracker[%d][%d] buffer to be NULL\\n\",\n\t\t\t      hw_rq_index, qindex_hdr);\n\t}\n\n\tspin_unlock_irqrestore(&rq_hdr->lock, flags);\n\treturn 0;\n}\n\nint\nefct_hw_rqpair_sequence_free(struct efct_hw *hw, struct efc_hw_sequence *seq)\n{\n\tint rc = 0;\n\n\t \n\tif (efct_hw_rqpair_put(hw, seq)) {\n\t\tefc_log_err(hw->os, \"error writing buffers\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn rc;\n}\n\nint\nefct_efc_hw_sequence_free(struct efc *efc, struct efc_hw_sequence *seq)\n{\n\tstruct efct *efct = efc->base;\n\n\treturn efct_hw_rqpair_sequence_free(&efct->hw, seq);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}