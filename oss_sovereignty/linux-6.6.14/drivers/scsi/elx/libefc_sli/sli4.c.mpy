{
  "module_name": "sli4.c",
  "hash_id": "506821405a7d194504281e07bc6851e9bc62d85032499158d815bdfb8978c2ec",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/elx/libefc_sli/sli4.c",
  "human_readable_source": "\n \n\n \n#include \"sli4.h\"\n\nstatic struct sli4_asic_entry_t sli4_asic_table[] = {\n\t{ SLI4_ASIC_REV_B0, SLI4_ASIC_GEN_5},\n\t{ SLI4_ASIC_REV_D0, SLI4_ASIC_GEN_5},\n\t{ SLI4_ASIC_REV_A3, SLI4_ASIC_GEN_6},\n\t{ SLI4_ASIC_REV_A0, SLI4_ASIC_GEN_6},\n\t{ SLI4_ASIC_REV_A1, SLI4_ASIC_GEN_6},\n\t{ SLI4_ASIC_REV_A3, SLI4_ASIC_GEN_6},\n\t{ SLI4_ASIC_REV_A1, SLI4_ASIC_GEN_7},\n\t{ SLI4_ASIC_REV_A0, SLI4_ASIC_GEN_7},\n};\n\n \nstatic char *SLI4_QNAME[] = {\n\t\"Event Queue\",\n\t\"Completion Queue\",\n\t\"Mailbox Queue\",\n\t\"Work Queue\",\n\t\"Receive Queue\",\n\t\"Undefined\"\n};\n\n \nstatic void *\nsli_config_cmd_init(struct sli4 *sli4, void *buf, u32 length,\n\t\t    struct efc_dma *dma)\n{\n\tstruct sli4_cmd_sli_config *config;\n\tu32 flags;\n\n\tif (length > sizeof(config->payload.embed) && !dma) {\n\t\tefc_log_err(sli4, \"Too big for an embedded cmd with len(%d)\\n\",\n\t\t\t    length);\n\t\treturn NULL;\n\t}\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tconfig = buf;\n\n\tconfig->hdr.command = SLI4_MBX_CMD_SLI_CONFIG;\n\tif (!dma) {\n\t\tflags = SLI4_SLICONF_EMB;\n\t\tconfig->dw1_flags = cpu_to_le32(flags);\n\t\tconfig->payload_len = cpu_to_le32(length);\n\t\treturn config->payload.embed;\n\t}\n\n\tflags = SLI4_SLICONF_PMDCMD_VAL_1;\n\tflags &= ~SLI4_SLICONF_EMB;\n\tconfig->dw1_flags = cpu_to_le32(flags);\n\n\tconfig->payload.mem.addr.low = cpu_to_le32(lower_32_bits(dma->phys));\n\tconfig->payload.mem.addr.high =\tcpu_to_le32(upper_32_bits(dma->phys));\n\tconfig->payload.mem.length =\n\t\t\t\tcpu_to_le32(dma->size & SLI4_SLICONF_PMD_LEN);\n\tconfig->payload_len = cpu_to_le32(dma->size);\n\t \n\tsli4->bmbx_non_emb_pmd = dma;\n\treturn dma->virt;\n}\n\n \nstatic int\nsli_cmd_common_create_cq(struct sli4 *sli4, void *buf, struct efc_dma *qmem,\n\t\t\t u16 eq_id)\n{\n\tstruct sli4_rqst_cmn_create_cq_v2 *cqv2 = NULL;\n\tu32 p;\n\tuintptr_t addr;\n\tu32 num_pages = 0;\n\tsize_t cmd_size = 0;\n\tu32 page_size = 0;\n\tu32 n_cqe = 0;\n\tu32 dw5_flags = 0;\n\tu16 dw6w1_arm = 0;\n\t__le32 len;\n\n\t \n\tn_cqe = qmem->size / SLI4_CQE_BYTES;\n\tswitch (n_cqe) {\n\tcase 256:\n\tcase 512:\n\tcase 1024:\n\tcase 2048:\n\t\tpage_size = SZ_4K;\n\t\tbreak;\n\tcase 4096:\n\t\tpage_size = SZ_8K;\n\t\tbreak;\n\tdefault:\n\t\treturn -EIO;\n\t}\n\tnum_pages = sli_page_count(qmem->size, page_size);\n\n\tcmd_size = SLI4_RQST_CMDSZ(cmn_create_cq_v2)\n\t\t   + SZ_DMAADDR * num_pages;\n\n\tcqv2 = sli_config_cmd_init(sli4, buf, cmd_size, NULL);\n\tif (!cqv2)\n\t\treturn -EIO;\n\n\tlen = SLI4_RQST_PYLD_LEN_VAR(cmn_create_cq_v2, SZ_DMAADDR * num_pages);\n\tsli_cmd_fill_hdr(&cqv2->hdr, SLI4_CMN_CREATE_CQ, SLI4_SUBSYSTEM_COMMON,\n\t\t\t CMD_V2, len);\n\tcqv2->page_size = page_size / SLI_PAGE_SIZE;\n\n\t \n\tcqv2->num_pages = cpu_to_le16(num_pages);\n\tif (!num_pages || num_pages > SLI4_CREATE_CQV2_MAX_PAGES)\n\t\treturn -EIO;\n\n\tswitch (num_pages) {\n\tcase 1:\n\t\tdw5_flags |= SLI4_CQ_CNT_VAL(256);\n\t\tbreak;\n\tcase 2:\n\t\tdw5_flags |= SLI4_CQ_CNT_VAL(512);\n\t\tbreak;\n\tcase 4:\n\t\tdw5_flags |= SLI4_CQ_CNT_VAL(1024);\n\t\tbreak;\n\tcase 8:\n\t\tdw5_flags |= SLI4_CQ_CNT_VAL(LARGE);\n\t\tcqv2->cqe_count = cpu_to_le16(n_cqe);\n\t\tbreak;\n\tdefault:\n\t\tefc_log_err(sli4, \"num_pages %d not valid\\n\", num_pages);\n\t\treturn -EIO;\n\t}\n\n\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\tdw5_flags |= SLI4_CREATE_CQV2_AUTOVALID;\n\n\tdw5_flags |= SLI4_CREATE_CQV2_EVT;\n\tdw5_flags |= SLI4_CREATE_CQV2_VALID;\n\n\tcqv2->dw5_flags = cpu_to_le32(dw5_flags);\n\tcqv2->dw6w1_arm = cpu_to_le16(dw6w1_arm);\n\tcqv2->eq_id = cpu_to_le16(eq_id);\n\n\tfor (p = 0, addr = qmem->phys; p < num_pages; p++, addr += page_size) {\n\t\tcqv2->page_phys_addr[p].low = cpu_to_le32(lower_32_bits(addr));\n\t\tcqv2->page_phys_addr[p].high = cpu_to_le32(upper_32_bits(addr));\n\t}\n\n\treturn 0;\n}\n\nstatic int\nsli_cmd_common_create_eq(struct sli4 *sli4, void *buf, struct efc_dma *qmem)\n{\n\tstruct sli4_rqst_cmn_create_eq *eq;\n\tu32 p;\n\tuintptr_t addr;\n\tu16 num_pages;\n\tu32 dw5_flags = 0;\n\tu32 dw6_flags = 0, ver;\n\n\teq = sli_config_cmd_init(sli4, buf, SLI4_CFG_PYLD_LENGTH(cmn_create_eq),\n\t\t\t\t NULL);\n\tif (!eq)\n\t\treturn -EIO;\n\n\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\tver = CMD_V2;\n\telse\n\t\tver = CMD_V0;\n\n\tsli_cmd_fill_hdr(&eq->hdr, SLI4_CMN_CREATE_EQ, SLI4_SUBSYSTEM_COMMON,\n\t\t\t ver, SLI4_RQST_PYLD_LEN(cmn_create_eq));\n\n\t \n\tnum_pages = qmem->size / SLI_PAGE_SIZE;\n\teq->num_pages = cpu_to_le16(num_pages);\n\n\tswitch (num_pages) {\n\tcase 1:\n\t\tdw5_flags |= SLI4_EQE_SIZE_4;\n\t\tdw6_flags |= SLI4_EQ_CNT_VAL(1024);\n\t\tbreak;\n\tcase 2:\n\t\tdw5_flags |= SLI4_EQE_SIZE_4;\n\t\tdw6_flags |= SLI4_EQ_CNT_VAL(2048);\n\t\tbreak;\n\tcase 4:\n\t\tdw5_flags |= SLI4_EQE_SIZE_4;\n\t\tdw6_flags |= SLI4_EQ_CNT_VAL(4096);\n\t\tbreak;\n\tdefault:\n\t\tefc_log_err(sli4, \"num_pages %d not valid\\n\", num_pages);\n\t\treturn -EIO;\n\t}\n\n\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\tdw5_flags |= SLI4_CREATE_EQ_AUTOVALID;\n\n\tdw5_flags |= SLI4_CREATE_EQ_VALID;\n\tdw6_flags &= (~SLI4_CREATE_EQ_ARM);\n\teq->dw5_flags = cpu_to_le32(dw5_flags);\n\teq->dw6_flags = cpu_to_le32(dw6_flags);\n\teq->dw7_delaymulti = cpu_to_le32(SLI4_CREATE_EQ_DELAYMULTI);\n\n\tfor (p = 0, addr = qmem->phys; p < num_pages;\n\t     p++, addr += SLI_PAGE_SIZE) {\n\t\teq->page_address[p].low = cpu_to_le32(lower_32_bits(addr));\n\t\teq->page_address[p].high = cpu_to_le32(upper_32_bits(addr));\n\t}\n\n\treturn 0;\n}\n\nstatic int\nsli_cmd_common_create_mq_ext(struct sli4 *sli4, void *buf, struct efc_dma *qmem,\n\t\t\t     u16 cq_id)\n{\n\tstruct sli4_rqst_cmn_create_mq_ext *mq;\n\tu32 p;\n\tuintptr_t addr;\n\tu32 num_pages;\n\tu16 dw6w1_flags = 0;\n\n\tmq = sli_config_cmd_init(sli4, buf,\n\t\t\t\t SLI4_CFG_PYLD_LENGTH(cmn_create_mq_ext), NULL);\n\tif (!mq)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&mq->hdr, SLI4_CMN_CREATE_MQ_EXT,\n\t\t\t SLI4_SUBSYSTEM_COMMON, CMD_V0,\n\t\t\t SLI4_RQST_PYLD_LEN(cmn_create_mq_ext));\n\n\t \n\tnum_pages = qmem->size / SLI_PAGE_SIZE;\n\tmq->num_pages = cpu_to_le16(num_pages);\n\tswitch (num_pages) {\n\tcase 1:\n\t\tdw6w1_flags |= SLI4_MQE_SIZE_16;\n\t\tbreak;\n\tcase 2:\n\t\tdw6w1_flags |= SLI4_MQE_SIZE_32;\n\t\tbreak;\n\tcase 4:\n\t\tdw6w1_flags |= SLI4_MQE_SIZE_64;\n\t\tbreak;\n\tcase 8:\n\t\tdw6w1_flags |= SLI4_MQE_SIZE_128;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"num_pages %d not valid\\n\", num_pages);\n\t\treturn -EIO;\n\t}\n\n\tmq->async_event_bitmap = cpu_to_le32(SLI4_ASYNC_EVT_FC_ALL);\n\n\tif (sli4->params.mq_create_version) {\n\t\tmq->cq_id_v1 = cpu_to_le16(cq_id);\n\t\tmq->hdr.dw3_version = cpu_to_le32(CMD_V1);\n\t} else {\n\t\tdw6w1_flags |= (cq_id << SLI4_CREATE_MQEXT_CQID_SHIFT);\n\t}\n\tmq->dw7_val = cpu_to_le32(SLI4_CREATE_MQEXT_VAL);\n\n\tmq->dw6w1_flags = cpu_to_le16(dw6w1_flags);\n\tfor (p = 0, addr = qmem->phys; p < num_pages;\n\t     p++, addr += SLI_PAGE_SIZE) {\n\t\tmq->page_phys_addr[p].low = cpu_to_le32(lower_32_bits(addr));\n\t\tmq->page_phys_addr[p].high = cpu_to_le32(upper_32_bits(addr));\n\t}\n\n\treturn 0;\n}\n\nint\nsli_cmd_wq_create(struct sli4 *sli4, void *buf, struct efc_dma *qmem, u16 cq_id)\n{\n\tstruct sli4_rqst_wq_create *wq;\n\tu32 p;\n\tuintptr_t addr;\n\tu32 page_size = 0;\n\tu32 n_wqe = 0;\n\tu16 num_pages;\n\n\twq = sli_config_cmd_init(sli4, buf, SLI4_CFG_PYLD_LENGTH(wq_create),\n\t\t\t\t NULL);\n\tif (!wq)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&wq->hdr, SLI4_OPC_WQ_CREATE, SLI4_SUBSYSTEM_FC,\n\t\t\t CMD_V1, SLI4_RQST_PYLD_LEN(wq_create));\n\tn_wqe = qmem->size / sli4->wqe_size;\n\n\tswitch (qmem->size) {\n\tcase 4096:\n\tcase 8192:\n\tcase 16384:\n\tcase 32768:\n\t\tpage_size = SZ_4K;\n\t\tbreak;\n\tcase 65536:\n\t\tpage_size = SZ_8K;\n\t\tbreak;\n\tcase 131072:\n\t\tpage_size = SZ_16K;\n\t\tbreak;\n\tcase 262144:\n\t\tpage_size = SZ_32K;\n\t\tbreak;\n\tcase 524288:\n\t\tpage_size = SZ_64K;\n\t\tbreak;\n\tdefault:\n\t\treturn -EIO;\n\t}\n\n\t \n\tnum_pages = sli_page_count(qmem->size, page_size);\n\twq->num_pages = cpu_to_le16(num_pages);\n\tif (!num_pages || num_pages > SLI4_WQ_CREATE_MAX_PAGES)\n\t\treturn -EIO;\n\n\twq->cq_id = cpu_to_le16(cq_id);\n\n\twq->page_size = page_size / SLI_PAGE_SIZE;\n\n\tif (sli4->wqe_size == SLI4_WQE_EXT_BYTES)\n\t\twq->wqe_size_byte |= SLI4_WQE_EXT_SIZE;\n\telse\n\t\twq->wqe_size_byte |= SLI4_WQE_SIZE;\n\n\twq->wqe_count = cpu_to_le16(n_wqe);\n\n\tfor (p = 0, addr = qmem->phys; p < num_pages; p++, addr += page_size) {\n\t\twq->page_phys_addr[p].low  = cpu_to_le32(lower_32_bits(addr));\n\t\twq->page_phys_addr[p].high = cpu_to_le32(upper_32_bits(addr));\n\t}\n\n\treturn 0;\n}\n\nstatic int\nsli_cmd_rq_create_v1(struct sli4 *sli4, void *buf, struct efc_dma *qmem,\n\t\t     u16 cq_id, u16 buffer_size)\n{\n\tstruct sli4_rqst_rq_create_v1 *rq;\n\tu32 p;\n\tuintptr_t addr;\n\tu32 num_pages;\n\n\trq = sli_config_cmd_init(sli4, buf, SLI4_CFG_PYLD_LENGTH(rq_create_v1),\n\t\t\t\t NULL);\n\tif (!rq)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&rq->hdr, SLI4_OPC_RQ_CREATE, SLI4_SUBSYSTEM_FC,\n\t\t\t CMD_V1, SLI4_RQST_PYLD_LEN(rq_create_v1));\n\t \n\trq->dim_dfd_dnb |= SLI4_RQ_CREATE_V1_DNB;\n\n\t \n\tnum_pages = sli_page_count(qmem->size, SLI_PAGE_SIZE);\n\trq->num_pages = cpu_to_le16(num_pages);\n\tif (!num_pages ||\n\t    num_pages > SLI4_RQ_CREATE_V1_MAX_PAGES) {\n\t\tefc_log_info(sli4, \"num_pages %d not valid, max %d\\n\",\n\t\t\t     num_pages, SLI4_RQ_CREATE_V1_MAX_PAGES);\n\t\treturn -EIO;\n\t}\n\n\t \n\trq->rqe_count = cpu_to_le16(qmem->size / SLI4_RQE_SIZE);\n\n\trq->rqe_size_byte |= SLI4_RQE_SIZE_8;\n\n\trq->page_size = SLI4_RQ_PAGE_SIZE_4096;\n\n\tif (buffer_size < sli4->rq_min_buf_size ||\n\t    buffer_size > sli4->rq_max_buf_size) {\n\t\tefc_log_err(sli4, \"buffer_size %d out of range (%d-%d)\\n\",\n\t\t\t    buffer_size, sli4->rq_min_buf_size,\n\t\t\t    sli4->rq_max_buf_size);\n\t\treturn -EIO;\n\t}\n\trq->buffer_size = cpu_to_le32(buffer_size);\n\n\trq->cq_id = cpu_to_le16(cq_id);\n\n\tfor (p = 0, addr = qmem->phys;\n\t\t\tp < num_pages;\n\t\t\tp++, addr += SLI_PAGE_SIZE) {\n\t\trq->page_phys_addr[p].low  = cpu_to_le32(lower_32_bits(addr));\n\t\trq->page_phys_addr[p].high = cpu_to_le32(upper_32_bits(addr));\n\t}\n\n\treturn 0;\n}\n\nstatic int\nsli_cmd_rq_create_v2(struct sli4 *sli4, u32 num_rqs,\n\t\t     struct sli4_queue *qs[], u32 base_cq_id,\n\t\t     u32 header_buffer_size,\n\t\t     u32 payload_buffer_size, struct efc_dma *dma)\n{\n\tstruct sli4_rqst_rq_create_v2 *req = NULL;\n\tu32 i, p, offset = 0;\n\tu32 payload_size, page_count;\n\tuintptr_t addr;\n\tu32 num_pages;\n\t__le32 len;\n\n\tpage_count =  sli_page_count(qs[0]->dma.size, SLI_PAGE_SIZE) * num_rqs;\n\n\t \n\tpayload_size = max(SLI4_RQST_CMDSZ(rq_create_v2) +\n\t\t\t   SZ_DMAADDR * page_count,\n\t\t\t   sizeof(struct sli4_rsp_cmn_create_queue_set));\n\n\tdma->size = payload_size;\n\tdma->virt = dma_alloc_coherent(&sli4->pci->dev, dma->size,\n\t\t\t\t       &dma->phys, GFP_KERNEL);\n\tif (!dma->virt)\n\t\treturn -EIO;\n\n\tmemset(dma->virt, 0, payload_size);\n\n\treq = sli_config_cmd_init(sli4, sli4->bmbx.virt, payload_size, dma);\n\tif (!req)\n\t\treturn -EIO;\n\n\tlen =  SLI4_RQST_PYLD_LEN_VAR(rq_create_v2, SZ_DMAADDR * page_count);\n\tsli_cmd_fill_hdr(&req->hdr, SLI4_OPC_RQ_CREATE, SLI4_SUBSYSTEM_FC,\n\t\t\t CMD_V2, len);\n\t \n\treq->dim_dfd_dnb |= SLI4_RQCREATEV2_DNB;\n\tnum_pages = sli_page_count(qs[0]->dma.size, SLI_PAGE_SIZE);\n\treq->num_pages = cpu_to_le16(num_pages);\n\treq->rqe_count = cpu_to_le16(qs[0]->dma.size / SLI4_RQE_SIZE);\n\treq->rqe_size_byte |= SLI4_RQE_SIZE_8;\n\treq->page_size = SLI4_RQ_PAGE_SIZE_4096;\n\treq->rq_count = num_rqs;\n\treq->base_cq_id = cpu_to_le16(base_cq_id);\n\treq->hdr_buffer_size = cpu_to_le16(header_buffer_size);\n\treq->payload_buffer_size = cpu_to_le16(payload_buffer_size);\n\n\tfor (i = 0; i < num_rqs; i++) {\n\t\tfor (p = 0, addr = qs[i]->dma.phys; p < num_pages;\n\t\t     p++, addr += SLI_PAGE_SIZE) {\n\t\t\treq->page_phys_addr[offset].low =\n\t\t\t\t\tcpu_to_le32(lower_32_bits(addr));\n\t\t\treq->page_phys_addr[offset].high =\n\t\t\t\t\tcpu_to_le32(upper_32_bits(addr));\n\t\t\toffset++;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void\n__sli_queue_destroy(struct sli4 *sli4, struct sli4_queue *q)\n{\n\tif (!q->dma.size)\n\t\treturn;\n\n\tdma_free_coherent(&sli4->pci->dev, q->dma.size,\n\t\t\t  q->dma.virt, q->dma.phys);\n\tmemset(&q->dma, 0, sizeof(struct efc_dma));\n}\n\nint\n__sli_queue_init(struct sli4 *sli4, struct sli4_queue *q, u32 qtype,\n\t\t size_t size, u32 n_entries, u32 align)\n{\n\tif (q->dma.virt) {\n\t\tefc_log_err(sli4, \"%s failed\\n\", __func__);\n\t\treturn -EIO;\n\t}\n\n\tmemset(q, 0, sizeof(struct sli4_queue));\n\n\tq->dma.size = size * n_entries;\n\tq->dma.virt = dma_alloc_coherent(&sli4->pci->dev, q->dma.size,\n\t\t\t\t\t &q->dma.phys, GFP_KERNEL);\n\tif (!q->dma.virt) {\n\t\tmemset(&q->dma, 0, sizeof(struct efc_dma));\n\t\tefc_log_err(sli4, \"%s allocation failed\\n\", SLI4_QNAME[qtype]);\n\t\treturn -EIO;\n\t}\n\n\tmemset(q->dma.virt, 0, size * n_entries);\n\n\tspin_lock_init(&q->lock);\n\n\tq->type = qtype;\n\tq->size = size;\n\tq->length = n_entries;\n\n\tif (q->type == SLI4_QTYPE_EQ || q->type == SLI4_QTYPE_CQ) {\n\t\t \n\t\tq->phase = 1;\n\t}\n\n\t \n\tq->proc_limit = n_entries / 2;\n\n\tif (q->type == SLI4_QTYPE_EQ)\n\t\tq->posted_limit = q->length / 2;\n\telse\n\t\tq->posted_limit = 64;\n\n\treturn 0;\n}\n\nint\nsli_fc_rq_alloc(struct sli4 *sli4, struct sli4_queue *q,\n\t\tu32 n_entries, u32 buffer_size,\n\t\tstruct sli4_queue *cq, bool is_hdr)\n{\n\tif (__sli_queue_init(sli4, q, SLI4_QTYPE_RQ, SLI4_RQE_SIZE,\n\t\t\t     n_entries, SLI_PAGE_SIZE))\n\t\treturn -EIO;\n\n\tif (sli_cmd_rq_create_v1(sli4, sli4->bmbx.virt, &q->dma, cq->id,\n\t\t\t\t buffer_size))\n\t\tgoto error;\n\n\tif (__sli_create_queue(sli4, q))\n\t\tgoto error;\n\n\tif (is_hdr && q->id & 1) {\n\t\tefc_log_info(sli4, \"bad header RQ_ID %d\\n\", q->id);\n\t\tgoto error;\n\t} else if (!is_hdr  && (q->id & 1) == 0) {\n\t\tefc_log_info(sli4, \"bad data RQ_ID %d\\n\", q->id);\n\t\tgoto error;\n\t}\n\n\tif (is_hdr)\n\t\tq->u.flag |= SLI4_QUEUE_FLAG_HDR;\n\telse\n\t\tq->u.flag &= ~SLI4_QUEUE_FLAG_HDR;\n\n\treturn 0;\n\nerror:\n\t__sli_queue_destroy(sli4, q);\n\treturn -EIO;\n}\n\nint\nsli_fc_rq_set_alloc(struct sli4 *sli4, u32 num_rq_pairs,\n\t\t    struct sli4_queue *qs[], u32 base_cq_id,\n\t\t    u32 n_entries, u32 header_buffer_size,\n\t\t    u32 payload_buffer_size)\n{\n\tu32 i;\n\tstruct efc_dma dma = {0};\n\tstruct sli4_rsp_cmn_create_queue_set *rsp = NULL;\n\tvoid __iomem *db_regaddr = NULL;\n\tu32 num_rqs = num_rq_pairs * 2;\n\n\tfor (i = 0; i < num_rqs; i++) {\n\t\tif (__sli_queue_init(sli4, qs[i], SLI4_QTYPE_RQ,\n\t\t\t\t     SLI4_RQE_SIZE, n_entries,\n\t\t\t\t     SLI_PAGE_SIZE)) {\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\tif (sli_cmd_rq_create_v2(sli4, num_rqs, qs, base_cq_id,\n\t\t\t\t header_buffer_size, payload_buffer_size,\n\t\t\t\t &dma)) {\n\t\tgoto error;\n\t}\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_err(sli4, \"bootstrap mailbox write failed RQSet\\n\");\n\t\tgoto error;\n\t}\n\n\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\tdb_regaddr = sli4->reg[1] + SLI4_IF6_RQ_DB_REG;\n\telse\n\t\tdb_regaddr = sli4->reg[0] + SLI4_RQ_DB_REG;\n\n\trsp = dma.virt;\n\tif (rsp->hdr.status) {\n\t\tefc_log_err(sli4, \"bad create RQSet status=%#x addl=%#x\\n\",\n\t\t\t    rsp->hdr.status, rsp->hdr.additional_status);\n\t\tgoto error;\n\t}\n\n\tfor (i = 0; i < num_rqs; i++) {\n\t\tqs[i]->id = i + le16_to_cpu(rsp->q_id);\n\t\tif ((qs[i]->id & 1) == 0)\n\t\t\tqs[i]->u.flag |= SLI4_QUEUE_FLAG_HDR;\n\t\telse\n\t\t\tqs[i]->u.flag &= ~SLI4_QUEUE_FLAG_HDR;\n\n\t\tqs[i]->db_regaddr = db_regaddr;\n\t}\n\n\tdma_free_coherent(&sli4->pci->dev, dma.size, dma.virt, dma.phys);\n\n\treturn 0;\n\nerror:\n\tfor (i = 0; i < num_rqs; i++)\n\t\t__sli_queue_destroy(sli4, qs[i]);\n\n\tif (dma.virt)\n\t\tdma_free_coherent(&sli4->pci->dev, dma.size, dma.virt,\n\t\t\t\t  dma.phys);\n\n\treturn -EIO;\n}\n\nstatic int\nsli_res_sli_config(struct sli4 *sli4, void *buf)\n{\n\tstruct sli4_cmd_sli_config *sli_config = buf;\n\n\t \n\tif (!buf || sli_config->hdr.command !=\n\t\t    SLI4_MBX_CMD_SLI_CONFIG) {\n\t\tefc_log_err(sli4, \"bad parameter buf=%p cmd=%#x\\n\", buf,\n\t\t\t    buf ? sli_config->hdr.command : -1);\n\t\treturn -EIO;\n\t}\n\n\tif (le16_to_cpu(sli_config->hdr.status))\n\t\treturn le16_to_cpu(sli_config->hdr.status);\n\n\tif (le32_to_cpu(sli_config->dw1_flags) & SLI4_SLICONF_EMB)\n\t\treturn sli_config->payload.embed[4];\n\n\tefc_log_info(sli4, \"external buffers not supported\\n\");\n\treturn -EIO;\n}\n\nint\n__sli_create_queue(struct sli4 *sli4, struct sli4_queue *q)\n{\n\tstruct sli4_rsp_cmn_create_queue *res_q = NULL;\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"bootstrap mailbox write fail %s\\n\",\n\t\t\t     SLI4_QNAME[q->type]);\n\t\treturn -EIO;\n\t}\n\tif (sli_res_sli_config(sli4, sli4->bmbx.virt)) {\n\t\tefc_log_err(sli4, \"bad status create %s\\n\",\n\t\t\t    SLI4_QNAME[q->type]);\n\t\treturn -EIO;\n\t}\n\tres_q = (void *)((u8 *)sli4->bmbx.virt +\n\t\t\toffsetof(struct sli4_cmd_sli_config, payload));\n\n\tif (res_q->hdr.status) {\n\t\tefc_log_err(sli4, \"bad create %s status=%#x addl=%#x\\n\",\n\t\t\t    SLI4_QNAME[q->type], res_q->hdr.status,\n\t\t\t    res_q->hdr.additional_status);\n\t\treturn -EIO;\n\t}\n\tq->id = le16_to_cpu(res_q->q_id);\n\tswitch (q->type) {\n\tcase SLI4_QTYPE_EQ:\n\t\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\t\tq->db_regaddr = sli4->reg[1] + SLI4_IF6_EQ_DB_REG;\n\t\telse\n\t\t\tq->db_regaddr =\tsli4->reg[0] + SLI4_EQCQ_DB_REG;\n\t\tbreak;\n\tcase SLI4_QTYPE_CQ:\n\t\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\t\tq->db_regaddr = sli4->reg[1] + SLI4_IF6_CQ_DB_REG;\n\t\telse\n\t\t\tq->db_regaddr =\tsli4->reg[0] + SLI4_EQCQ_DB_REG;\n\t\tbreak;\n\tcase SLI4_QTYPE_MQ:\n\t\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\t\tq->db_regaddr = sli4->reg[1] + SLI4_IF6_MQ_DB_REG;\n\t\telse\n\t\t\tq->db_regaddr =\tsli4->reg[0] + SLI4_MQ_DB_REG;\n\t\tbreak;\n\tcase SLI4_QTYPE_RQ:\n\t\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\t\tq->db_regaddr = sli4->reg[1] + SLI4_IF6_RQ_DB_REG;\n\t\telse\n\t\t\tq->db_regaddr =\tsli4->reg[0] + SLI4_RQ_DB_REG;\n\t\tbreak;\n\tcase SLI4_QTYPE_WQ:\n\t\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\t\tq->db_regaddr = sli4->reg[1] + SLI4_IF6_WQ_DB_REG;\n\t\telse\n\t\t\tq->db_regaddr =\tsli4->reg[0] + SLI4_IO_WQ_DB_REG;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nint\nsli_get_queue_entry_size(struct sli4 *sli4, u32 qtype)\n{\n\tu32 size = 0;\n\n\tswitch (qtype) {\n\tcase SLI4_QTYPE_EQ:\n\t\tsize = sizeof(u32);\n\t\tbreak;\n\tcase SLI4_QTYPE_CQ:\n\t\tsize = 16;\n\t\tbreak;\n\tcase SLI4_QTYPE_MQ:\n\t\tsize = 256;\n\t\tbreak;\n\tcase SLI4_QTYPE_WQ:\n\t\tsize = sli4->wqe_size;\n\t\tbreak;\n\tcase SLI4_QTYPE_RQ:\n\t\tsize = SLI4_RQE_SIZE;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"unknown queue type %d\\n\", qtype);\n\t\treturn -1;\n\t}\n\treturn size;\n}\n\nint\nsli_queue_alloc(struct sli4 *sli4, u32 qtype,\n\t\tstruct sli4_queue *q, u32 n_entries,\n\t\t     struct sli4_queue *assoc)\n{\n\tint size;\n\tu32 align = 0;\n\n\t \n\tsize = sli_get_queue_entry_size(sli4, qtype);\n\tif (size < 0)\n\t\treturn -EIO;\n\talign = SLI_PAGE_SIZE;\n\n\tif (__sli_queue_init(sli4, q, qtype, size, n_entries, align))\n\t\treturn -EIO;\n\n\tswitch (qtype) {\n\tcase SLI4_QTYPE_EQ:\n\t\tif (!sli_cmd_common_create_eq(sli4, sli4->bmbx.virt, &q->dma) &&\n\t\t    !__sli_create_queue(sli4, q))\n\t\t\treturn 0;\n\n\t\tbreak;\n\tcase SLI4_QTYPE_CQ:\n\t\tif (!sli_cmd_common_create_cq(sli4, sli4->bmbx.virt, &q->dma,\n\t\t\t\t\t      assoc ? assoc->id : 0) &&\n\t\t    !__sli_create_queue(sli4, q))\n\t\t\treturn 0;\n\n\t\tbreak;\n\tcase SLI4_QTYPE_MQ:\n\t\tassoc->u.flag |= SLI4_QUEUE_FLAG_MQ;\n\t\tif (!sli_cmd_common_create_mq_ext(sli4, sli4->bmbx.virt,\n\t\t\t\t\t\t  &q->dma, assoc->id) &&\n\t\t    !__sli_create_queue(sli4, q))\n\t\t\treturn 0;\n\n\t\tbreak;\n\tcase SLI4_QTYPE_WQ:\n\t\tif (!sli_cmd_wq_create(sli4, sli4->bmbx.virt, &q->dma,\n\t\t\t\t       assoc ? assoc->id : 0) &&\n\t\t    !__sli_create_queue(sli4, q))\n\t\t\treturn 0;\n\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"unknown queue type %d\\n\", qtype);\n\t}\n\n\t__sli_queue_destroy(sli4, q);\n\treturn -EIO;\n}\n\nstatic int sli_cmd_cq_set_create(struct sli4 *sli4,\n\t\t\t\t struct sli4_queue *qs[], u32 num_cqs,\n\t\t\t\t struct sli4_queue *eqs[],\n\t\t\t\t struct efc_dma *dma)\n{\n\tstruct sli4_rqst_cmn_create_cq_set_v0 *req = NULL;\n\tuintptr_t addr;\n\tu32 i, offset = 0,  page_bytes = 0, payload_size;\n\tu32 p = 0, page_size = 0, n_cqe = 0, num_pages_cq;\n\tu32 dw5_flags = 0;\n\tu16 dw6w1_flags = 0;\n\t__le32 req_len;\n\n\tn_cqe = qs[0]->dma.size / SLI4_CQE_BYTES;\n\tswitch (n_cqe) {\n\tcase 256:\n\tcase 512:\n\tcase 1024:\n\tcase 2048:\n\t\tpage_size = 1;\n\t\tbreak;\n\tcase 4096:\n\t\tpage_size = 2;\n\t\tbreak;\n\tdefault:\n\t\treturn -EIO;\n\t}\n\n\tpage_bytes = page_size * SLI_PAGE_SIZE;\n\tnum_pages_cq = sli_page_count(qs[0]->dma.size, page_bytes);\n\tpayload_size = max(SLI4_RQST_CMDSZ(cmn_create_cq_set_v0) +\n\t\t\t   (SZ_DMAADDR * num_pages_cq * num_cqs),\n\t\t\t   sizeof(struct sli4_rsp_cmn_create_queue_set));\n\n\tdma->size = payload_size;\n\tdma->virt = dma_alloc_coherent(&sli4->pci->dev, dma->size,\n\t\t\t\t       &dma->phys, GFP_KERNEL);\n\tif (!dma->virt)\n\t\treturn -EIO;\n\n\tmemset(dma->virt, 0, payload_size);\n\n\treq = sli_config_cmd_init(sli4, sli4->bmbx.virt, payload_size, dma);\n\tif (!req)\n\t\treturn -EIO;\n\n\treq_len = SLI4_RQST_PYLD_LEN_VAR(cmn_create_cq_set_v0,\n\t\t\t\t\t SZ_DMAADDR * num_pages_cq * num_cqs);\n\tsli_cmd_fill_hdr(&req->hdr, SLI4_CMN_CREATE_CQ_SET, SLI4_SUBSYSTEM_FC,\n\t\t\t CMD_V0, req_len);\n\treq->page_size = page_size;\n\n\treq->num_pages = cpu_to_le16(num_pages_cq);\n\tswitch (num_pages_cq) {\n\tcase 1:\n\t\tdw5_flags |= SLI4_CQ_CNT_VAL(256);\n\t\tbreak;\n\tcase 2:\n\t\tdw5_flags |= SLI4_CQ_CNT_VAL(512);\n\t\tbreak;\n\tcase 4:\n\t\tdw5_flags |= SLI4_CQ_CNT_VAL(1024);\n\t\tbreak;\n\tcase 8:\n\t\tdw5_flags |= SLI4_CQ_CNT_VAL(LARGE);\n\t\tdw6w1_flags |= (n_cqe & SLI4_CREATE_CQSETV0_CQE_COUNT);\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"num_pages %d not valid\\n\", num_pages_cq);\n\t\treturn -EIO;\n\t}\n\n\tdw5_flags |= SLI4_CREATE_CQSETV0_EVT;\n\tdw5_flags |= SLI4_CREATE_CQSETV0_VALID;\n\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\tdw5_flags |= SLI4_CREATE_CQSETV0_AUTOVALID;\n\n\tdw6w1_flags &= ~SLI4_CREATE_CQSETV0_ARM;\n\n\treq->dw5_flags = cpu_to_le32(dw5_flags);\n\treq->dw6w1_flags = cpu_to_le16(dw6w1_flags);\n\n\treq->num_cq_req = cpu_to_le16(num_cqs);\n\n\t \n\tfor (i = 0; i < num_cqs; i++) {\n\t\treq->eq_id[i] = cpu_to_le16(eqs[i]->id);\n\t\tfor (p = 0, addr = qs[i]->dma.phys; p < num_pages_cq;\n\t\t     p++, addr += page_bytes) {\n\t\t\treq->page_phys_addr[offset].low =\n\t\t\t\tcpu_to_le32(lower_32_bits(addr));\n\t\t\treq->page_phys_addr[offset].high =\n\t\t\t\tcpu_to_le32(upper_32_bits(addr));\n\t\t\toffset++;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint\nsli_cq_alloc_set(struct sli4 *sli4, struct sli4_queue *qs[],\n\t\t u32 num_cqs, u32 n_entries, struct sli4_queue *eqs[])\n{\n\tu32 i;\n\tstruct efc_dma dma = {0};\n\tstruct sli4_rsp_cmn_create_queue_set *res;\n\tvoid __iomem *db_regaddr;\n\n\t \n\tfor (i = 0; i < num_cqs; i++) {\n\t\tif (__sli_queue_init(sli4, qs[i], SLI4_QTYPE_CQ, SLI4_CQE_BYTES,\n\t\t\t\t     n_entries, SLI_PAGE_SIZE))\n\t\t\tgoto error;\n\t}\n\n\tif (sli_cmd_cq_set_create(sli4, qs, num_cqs, eqs, &dma))\n\t\tgoto error;\n\n\tif (sli_bmbx_command(sli4))\n\t\tgoto error;\n\n\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\tdb_regaddr = sli4->reg[1] + SLI4_IF6_CQ_DB_REG;\n\telse\n\t\tdb_regaddr = sli4->reg[0] + SLI4_EQCQ_DB_REG;\n\n\tres = dma.virt;\n\tif (res->hdr.status) {\n\t\tefc_log_err(sli4, \"bad create CQSet status=%#x addl=%#x\\n\",\n\t\t\t    res->hdr.status, res->hdr.additional_status);\n\t\tgoto error;\n\t}\n\n\t \n\tif (le16_to_cpu(res->num_q_allocated) != num_cqs) {\n\t\tefc_log_crit(sli4, \"Requested count CQs doesn't match.\\n\");\n\t\tgoto error;\n\t}\n\t \n\tfor (i = 0; i < num_cqs; i++) {\n\t\tqs[i]->id = le16_to_cpu(res->q_id) + i;\n\t\tqs[i]->db_regaddr = db_regaddr;\n\t}\n\n\tdma_free_coherent(&sli4->pci->dev, dma.size, dma.virt, dma.phys);\n\n\treturn 0;\n\nerror:\n\tfor (i = 0; i < num_cqs; i++)\n\t\t__sli_queue_destroy(sli4, qs[i]);\n\n\tif (dma.virt)\n\t\tdma_free_coherent(&sli4->pci->dev, dma.size, dma.virt,\n\t\t\t\t  dma.phys);\n\n\treturn -EIO;\n}\n\nstatic int\nsli_cmd_common_destroy_q(struct sli4 *sli4, u8 opc, u8 subsystem, u16 q_id)\n{\n\tstruct sli4_rqst_cmn_destroy_q *req;\n\n\t \n\treq = sli_config_cmd_init(sli4, sli4->bmbx.virt,\n\t\t\t\t  SLI4_CFG_PYLD_LENGTH(cmn_destroy_q), NULL);\n\tif (!req)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&req->hdr, opc, subsystem,\n\t\t\t CMD_V0, SLI4_RQST_PYLD_LEN(cmn_destroy_q));\n\treq->q_id = cpu_to_le16(q_id);\n\n\treturn 0;\n}\n\nint\nsli_queue_free(struct sli4 *sli4, struct sli4_queue *q,\n\t       u32 destroy_queues, u32 free_memory)\n{\n\tint rc = 0;\n\tu8 opcode, subsystem;\n\tstruct sli4_rsp_hdr *res;\n\n\tif (!q) {\n\t\tefc_log_err(sli4, \"bad parameter sli4=%p q=%p\\n\", sli4, q);\n\t\treturn -EIO;\n\t}\n\n\tif (!destroy_queues)\n\t\tgoto free_mem;\n\n\tswitch (q->type) {\n\tcase SLI4_QTYPE_EQ:\n\t\topcode = SLI4_CMN_DESTROY_EQ;\n\t\tsubsystem = SLI4_SUBSYSTEM_COMMON;\n\t\tbreak;\n\tcase SLI4_QTYPE_CQ:\n\t\topcode = SLI4_CMN_DESTROY_CQ;\n\t\tsubsystem = SLI4_SUBSYSTEM_COMMON;\n\t\tbreak;\n\tcase SLI4_QTYPE_MQ:\n\t\topcode = SLI4_CMN_DESTROY_MQ;\n\t\tsubsystem = SLI4_SUBSYSTEM_COMMON;\n\t\tbreak;\n\tcase SLI4_QTYPE_WQ:\n\t\topcode = SLI4_OPC_WQ_DESTROY;\n\t\tsubsystem = SLI4_SUBSYSTEM_FC;\n\t\tbreak;\n\tcase SLI4_QTYPE_RQ:\n\t\topcode = SLI4_OPC_RQ_DESTROY;\n\t\tsubsystem = SLI4_SUBSYSTEM_FC;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"bad queue type %d\\n\", q->type);\n\t\trc = -EIO;\n\t\tgoto free_mem;\n\t}\n\n\trc = sli_cmd_common_destroy_q(sli4, opcode, subsystem, q->id);\n\tif (rc)\n\t\tgoto free_mem;\n\n\trc = sli_bmbx_command(sli4);\n\tif (rc)\n\t\tgoto free_mem;\n\n\trc = sli_res_sli_config(sli4, sli4->bmbx.virt);\n\tif (rc)\n\t\tgoto free_mem;\n\n\tres = (void *)((u8 *)sli4->bmbx.virt +\n\t\t\t     offsetof(struct sli4_cmd_sli_config, payload));\n\tif (res->status) {\n\t\tefc_log_err(sli4, \"destroy %s st=%#x addl=%#x\\n\",\n\t\t\t    SLI4_QNAME[q->type], res->status,\n\t\t\t    res->additional_status);\n\t\trc = -EIO;\n\t\tgoto free_mem;\n\t}\n\nfree_mem:\n\tif (free_memory)\n\t\t__sli_queue_destroy(sli4, q);\n\n\treturn rc;\n}\n\nint\nsli_queue_eq_arm(struct sli4 *sli4, struct sli4_queue *q, bool arm)\n{\n\tu32 val;\n\tunsigned long flags = 0;\n\tu32 a = arm ? SLI4_EQCQ_ARM : SLI4_EQCQ_UNARM;\n\n\tspin_lock_irqsave(&q->lock, flags);\n\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\tval = sli_format_if6_eq_db_data(q->n_posted, q->id, a);\n\telse\n\t\tval = sli_format_eq_db_data(q->n_posted, q->id, a);\n\n\twritel(val, q->db_regaddr);\n\tq->n_posted = 0;\n\tspin_unlock_irqrestore(&q->lock, flags);\n\n\treturn 0;\n}\n\nint\nsli_queue_arm(struct sli4 *sli4, struct sli4_queue *q, bool arm)\n{\n\tu32 val = 0;\n\tunsigned long flags = 0;\n\tu32 a = arm ? SLI4_EQCQ_ARM : SLI4_EQCQ_UNARM;\n\n\tspin_lock_irqsave(&q->lock, flags);\n\n\tswitch (q->type) {\n\tcase SLI4_QTYPE_EQ:\n\t\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\t\tval = sli_format_if6_eq_db_data(q->n_posted, q->id, a);\n\t\telse\n\t\t\tval = sli_format_eq_db_data(q->n_posted, q->id, a);\n\n\t\twritel(val, q->db_regaddr);\n\t\tq->n_posted = 0;\n\t\tbreak;\n\tcase SLI4_QTYPE_CQ:\n\t\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6)\n\t\t\tval = sli_format_if6_cq_db_data(q->n_posted, q->id, a);\n\t\telse\n\t\t\tval = sli_format_cq_db_data(q->n_posted, q->id, a);\n\n\t\twritel(val, q->db_regaddr);\n\t\tq->n_posted = 0;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"should only be used for EQ/CQ, not %s\\n\",\n\t\t\t     SLI4_QNAME[q->type]);\n\t}\n\n\tspin_unlock_irqrestore(&q->lock, flags);\n\n\treturn 0;\n}\n\nint\nsli_wq_write(struct sli4 *sli4, struct sli4_queue *q, u8 *entry)\n{\n\tu8 *qe = q->dma.virt;\n\tu32 qindex;\n\tu32 val = 0;\n\n\tqindex = q->index;\n\tqe += q->index * q->size;\n\n\tif (sli4->params.perf_wq_id_association)\n\t\tsli_set_wq_id_association(entry, q->id);\n\n\tmemcpy(qe, entry, q->size);\n\tval = sli_format_wq_db_data(q->id);\n\n\twritel(val, q->db_regaddr);\n\tq->index = (q->index + 1) & (q->length - 1);\n\n\treturn qindex;\n}\n\nint\nsli_mq_write(struct sli4 *sli4, struct sli4_queue *q, u8 *entry)\n{\n\tu8 *qe = q->dma.virt;\n\tu32 qindex;\n\tu32 val = 0;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&q->lock, flags);\n\tqindex = q->index;\n\tqe += q->index * q->size;\n\n\tmemcpy(qe, entry, q->size);\n\tval = sli_format_mq_db_data(q->id);\n\twritel(val, q->db_regaddr);\n\tq->index = (q->index + 1) & (q->length - 1);\n\tspin_unlock_irqrestore(&q->lock, flags);\n\n\treturn qindex;\n}\n\nint\nsli_rq_write(struct sli4 *sli4, struct sli4_queue *q, u8 *entry)\n{\n\tu8 *qe = q->dma.virt;\n\tu32 qindex;\n\tu32 val = 0;\n\n\tqindex = q->index;\n\tqe += q->index * q->size;\n\n\tmemcpy(qe, entry, q->size);\n\n\t \n\tif (!(q->u.flag & SLI4_QUEUE_FLAG_HDR))\n\t\tgoto skip;\n\n\tval = sli_format_rq_db_data(q->id);\n\twritel(val, q->db_regaddr);\nskip:\n\tq->index = (q->index + 1) & (q->length - 1);\n\n\treturn qindex;\n}\n\nint\nsli_eq_read(struct sli4 *sli4, struct sli4_queue *q, u8 *entry)\n{\n\tu8 *qe = q->dma.virt;\n\tunsigned long flags = 0;\n\tu16 wflags = 0;\n\n\tspin_lock_irqsave(&q->lock, flags);\n\n\tqe += q->index * q->size;\n\n\t \n\twflags = le16_to_cpu(((struct sli4_eqe *)qe)->dw0w0_flags);\n\n\tif ((wflags & SLI4_EQE_VALID) != q->phase) {\n\t\tspin_unlock_irqrestore(&q->lock, flags);\n\t\treturn -EIO;\n\t}\n\n\tif (sli4->if_type != SLI4_INTF_IF_TYPE_6) {\n\t\twflags &= ~SLI4_EQE_VALID;\n\t\t((struct sli4_eqe *)qe)->dw0w0_flags = cpu_to_le16(wflags);\n\t}\n\n\tmemcpy(entry, qe, q->size);\n\tq->index = (q->index + 1) & (q->length - 1);\n\tq->n_posted++;\n\t \n\n\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6 && q->index == 0)\n\t\tq->phase ^= (u16)0x1;\n\n\tspin_unlock_irqrestore(&q->lock, flags);\n\n\treturn 0;\n}\n\nint\nsli_cq_read(struct sli4 *sli4, struct sli4_queue *q, u8 *entry)\n{\n\tu8 *qe = q->dma.virt;\n\tunsigned long flags = 0;\n\tu32 dwflags = 0;\n\tbool valid_bit_set;\n\n\tspin_lock_irqsave(&q->lock, flags);\n\n\tqe += q->index * q->size;\n\n\t \n\tdwflags = le32_to_cpu(((struct sli4_mcqe *)qe)->dw3_flags);\n\tvalid_bit_set = (dwflags & SLI4_MCQE_VALID) != 0;\n\n\tif (valid_bit_set != q->phase) {\n\t\tspin_unlock_irqrestore(&q->lock, flags);\n\t\treturn -EIO;\n\t}\n\n\tif (sli4->if_type != SLI4_INTF_IF_TYPE_6) {\n\t\tdwflags &= ~SLI4_MCQE_VALID;\n\t\t((struct sli4_mcqe *)qe)->dw3_flags = cpu_to_le32(dwflags);\n\t}\n\n\tmemcpy(entry, qe, q->size);\n\tq->index = (q->index + 1) & (q->length - 1);\n\tq->n_posted++;\n\t \n\n\tif (sli4->if_type == SLI4_INTF_IF_TYPE_6 && q->index == 0)\n\t\tq->phase ^= (u16)0x1;\n\n\tspin_unlock_irqrestore(&q->lock, flags);\n\n\treturn 0;\n}\n\nint\nsli_mq_read(struct sli4 *sli4, struct sli4_queue *q, u8 *entry)\n{\n\tu8 *qe = q->dma.virt;\n\tunsigned long flags = 0;\n\n\tspin_lock_irqsave(&q->lock, flags);\n\n\tqe += q->u.r_idx * q->size;\n\n\t \n\tif (q->index == q->u.r_idx) {\n\t\tspin_unlock_irqrestore(&q->lock, flags);\n\t\treturn -EIO;\n\t}\n\n\tmemcpy(entry, qe, q->size);\n\tq->u.r_idx = (q->u.r_idx + 1) & (q->length - 1);\n\n\tspin_unlock_irqrestore(&q->lock, flags);\n\n\treturn 0;\n}\n\nint\nsli_eq_parse(struct sli4 *sli4, u8 *buf, u16 *cq_id)\n{\n\tstruct sli4_eqe *eqe = (void *)buf;\n\tint rc = 0;\n\tu16 flags = 0;\n\tu16 majorcode;\n\tu16 minorcode;\n\n\tif (!buf || !cq_id) {\n\t\tefc_log_err(sli4, \"bad parameters sli4=%p buf=%p cq_id=%p\\n\",\n\t\t\t    sli4, buf, cq_id);\n\t\treturn -EIO;\n\t}\n\n\tflags = le16_to_cpu(eqe->dw0w0_flags);\n\tmajorcode = (flags & SLI4_EQE_MJCODE) >> 1;\n\tminorcode = (flags & SLI4_EQE_MNCODE) >> 4;\n\tswitch (majorcode) {\n\tcase SLI4_MAJOR_CODE_STANDARD:\n\t\t*cq_id = le16_to_cpu(eqe->resource_id);\n\t\tbreak;\n\tcase SLI4_MAJOR_CODE_SENTINEL:\n\t\tefc_log_info(sli4, \"sentinel EQE\\n\");\n\t\trc = SLI4_EQE_STATUS_EQ_FULL;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"Unsupported EQE: major %x minor %x\\n\",\n\t\t\t     majorcode, minorcode);\n\t\trc = -EIO;\n\t}\n\n\treturn rc;\n}\n\nint\nsli_cq_parse(struct sli4 *sli4, struct sli4_queue *cq, u8 *cqe,\n\t     enum sli4_qentry *etype, u16 *q_id)\n{\n\tint rc = 0;\n\n\tif (!cq || !cqe || !etype) {\n\t\tefc_log_err(sli4, \"bad params sli4=%p cq=%p cqe=%p etype=%p q_id=%p\\n\",\n\t\t\t    sli4, cq, cqe, etype, q_id);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (cq->u.flag & SLI4_QUEUE_FLAG_MQ) {\n\t\tstruct sli4_mcqe\t*mcqe = (void *)cqe;\n\n\t\tif (le32_to_cpu(mcqe->dw3_flags) & SLI4_MCQE_AE) {\n\t\t\t*etype = SLI4_QENTRY_ASYNC;\n\t\t} else {\n\t\t\t*etype = SLI4_QENTRY_MQ;\n\t\t\trc = sli_cqe_mq(sli4, mcqe);\n\t\t}\n\t\t*q_id = -1;\n\t} else {\n\t\trc = sli_fc_cqe_parse(sli4, cq, cqe, etype, q_id);\n\t}\n\n\treturn rc;\n}\n\nint\nsli_abort_wqe(struct sli4 *sli, void *buf, enum sli4_abort_type type,\n\t      bool send_abts, u32 ids, u32 mask, u16 tag, u16 cq_id)\n{\n\tstruct sli4_abort_wqe *abort = buf;\n\n\tmemset(buf, 0, sli->wqe_size);\n\n\tswitch (type) {\n\tcase SLI4_ABORT_XRI:\n\t\tabort->criteria = SLI4_ABORT_CRITERIA_XRI_TAG;\n\t\tif (mask) {\n\t\t\tefc_log_warn(sli, \"%#x aborting XRI %#x warning non-zero mask\",\n\t\t\t\t     mask, ids);\n\t\t\tmask = 0;\n\t\t}\n\t\tbreak;\n\tcase SLI4_ABORT_ABORT_ID:\n\t\tabort->criteria = SLI4_ABORT_CRITERIA_ABORT_TAG;\n\t\tbreak;\n\tcase SLI4_ABORT_REQUEST_ID:\n\t\tabort->criteria = SLI4_ABORT_CRITERIA_REQUEST_TAG;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli, \"unsupported type %#x\\n\", type);\n\t\treturn -EIO;\n\t}\n\n\tabort->ia_ir_byte |= send_abts ? 0 : 1;\n\n\t \n\tabort->ia_ir_byte |= SLI4_ABRT_WQE_IR;\n\n\tabort->t_mask = cpu_to_le32(mask);\n\tabort->t_tag  = cpu_to_le32(ids);\n\tabort->command = SLI4_WQE_ABORT;\n\tabort->request_tag = cpu_to_le16(tag);\n\n\tabort->dw10w0_flags = cpu_to_le16(SLI4_ABRT_WQE_QOSD);\n\n\tabort->cq_id = cpu_to_le16(cq_id);\n\tabort->cmdtype_wqec_byte |= SLI4_CMD_ABORT_WQE;\n\n\treturn 0;\n}\n\nint\nsli_els_request64_wqe(struct sli4 *sli, void *buf, struct efc_dma *sgl,\n\t\t      struct sli_els_params *params)\n{\n\tstruct sli4_els_request64_wqe *els = buf;\n\tstruct sli4_sge *sge = sgl->virt;\n\tbool is_fabric = false;\n\tstruct sli4_bde *bptr;\n\n\tmemset(buf, 0, sli->wqe_size);\n\n\tbptr = &els->els_request_payload;\n\tif (sli->params.sgl_pre_registered) {\n\t\tels->qosd_xbl_hlm_iod_dbde_wqes &= ~SLI4_REQ_WQE_XBL;\n\n\t\tels->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_REQ_WQE_DBDE;\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t    (params->xmit_len & SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.data.low  = sge[0].buffer_address_low;\n\t\tbptr->u.data.high = sge[0].buffer_address_high;\n\t} else {\n\t\tels->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_REQ_WQE_XBL;\n\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(BLP)) |\n\t\t\t\t    ((2 * sizeof(struct sli4_sge)) &\n\t\t\t\t     SLI4_BDE_LEN_MASK));\n\t\tbptr->u.blp.low  = cpu_to_le32(lower_32_bits(sgl->phys));\n\t\tbptr->u.blp.high = cpu_to_le32(upper_32_bits(sgl->phys));\n\t}\n\n\tels->els_request_payload_length = cpu_to_le32(params->xmit_len);\n\tels->max_response_payload_length = cpu_to_le32(params->rsp_len);\n\n\tels->xri_tag = cpu_to_le16(params->xri);\n\tels->timer = params->timeout;\n\tels->class_byte |= SLI4_GENERIC_CLASS_CLASS_3;\n\n\tels->command = SLI4_WQE_ELS_REQUEST64;\n\n\tels->request_tag = cpu_to_le16(params->tag);\n\n\tels->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_REQ_WQE_IOD;\n\n\tels->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_REQ_WQE_QOSD;\n\n\t \n\n\tswitch (params->cmd) {\n\tcase ELS_LOGO:\n\t\tels->cmdtype_elsid_byte |=\n\t\t\tSLI4_ELS_REQUEST64_LOGO << SLI4_REQ_WQE_ELSID_SHFT;\n\t\tif (params->rpi_registered) {\n\t\t\tels->ct_byte |=\n\t\t\tSLI4_GENERIC_CONTEXT_RPI << SLI4_REQ_WQE_CT_SHFT;\n\t\t\tels->context_tag = cpu_to_le16(params->rpi);\n\t\t} else {\n\t\t\tels->ct_byte |=\n\t\t\tSLI4_GENERIC_CONTEXT_VPI << SLI4_REQ_WQE_CT_SHFT;\n\t\t\tels->context_tag = cpu_to_le16(params->vpi);\n\t\t}\n\t\tif (params->d_id == FC_FID_FLOGI)\n\t\t\tis_fabric = true;\n\t\tbreak;\n\tcase ELS_FDISC:\n\t\tif (params->d_id == FC_FID_FLOGI)\n\t\t\tis_fabric = true;\n\t\tif (params->s_id == 0) {\n\t\t\tels->cmdtype_elsid_byte |=\n\t\t\tSLI4_ELS_REQUEST64_FDISC << SLI4_REQ_WQE_ELSID_SHFT;\n\t\t\tis_fabric = true;\n\t\t} else {\n\t\t\tels->cmdtype_elsid_byte |=\n\t\t\tSLI4_ELS_REQUEST64_OTHER << SLI4_REQ_WQE_ELSID_SHFT;\n\t\t}\n\t\tels->ct_byte |=\n\t\t\tSLI4_GENERIC_CONTEXT_VPI << SLI4_REQ_WQE_CT_SHFT;\n\t\tels->context_tag = cpu_to_le16(params->vpi);\n\t\tels->sid_sp_dword |= cpu_to_le32(1 << SLI4_REQ_WQE_SP_SHFT);\n\t\tbreak;\n\tcase ELS_FLOGI:\n\t\tels->ct_byte |=\n\t\t\tSLI4_GENERIC_CONTEXT_VPI << SLI4_REQ_WQE_CT_SHFT;\n\t\tels->context_tag = cpu_to_le16(params->vpi);\n\t\t \n\t\tels->sid_sp_dword |= cpu_to_le32(1 << SLI4_REQ_WQE_SP_SHFT);\n\t\tif (params->s_id != U32_MAX)\n\t\t\tels->sid_sp_dword |= cpu_to_le32(params->s_id);\n\t\tbreak;\n\tcase ELS_PLOGI:\n\t\tels->cmdtype_elsid_byte |=\n\t\t\tSLI4_ELS_REQUEST64_PLOGI << SLI4_REQ_WQE_ELSID_SHFT;\n\t\tels->ct_byte |=\n\t\t\tSLI4_GENERIC_CONTEXT_VPI << SLI4_REQ_WQE_CT_SHFT;\n\t\tels->context_tag = cpu_to_le16(params->vpi);\n\t\tbreak;\n\tcase ELS_SCR:\n\t\tels->cmdtype_elsid_byte |=\n\t\t\tSLI4_ELS_REQUEST64_OTHER << SLI4_REQ_WQE_ELSID_SHFT;\n\t\tels->ct_byte |=\n\t\t\tSLI4_GENERIC_CONTEXT_VPI << SLI4_REQ_WQE_CT_SHFT;\n\t\tels->context_tag = cpu_to_le16(params->vpi);\n\t\tbreak;\n\tdefault:\n\t\tels->cmdtype_elsid_byte |=\n\t\t\tSLI4_ELS_REQUEST64_OTHER << SLI4_REQ_WQE_ELSID_SHFT;\n\t\tif (params->rpi_registered) {\n\t\t\tels->ct_byte |= (SLI4_GENERIC_CONTEXT_RPI <<\n\t\t\t\t\t SLI4_REQ_WQE_CT_SHFT);\n\t\t\tels->context_tag = cpu_to_le16(params->vpi);\n\t\t} else {\n\t\t\tels->ct_byte |=\n\t\t\tSLI4_GENERIC_CONTEXT_VPI << SLI4_REQ_WQE_CT_SHFT;\n\t\t\tels->context_tag = cpu_to_le16(params->vpi);\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (is_fabric)\n\t\tels->cmdtype_elsid_byte |= SLI4_ELS_REQUEST64_CMD_FABRIC;\n\telse\n\t\tels->cmdtype_elsid_byte |= SLI4_ELS_REQUEST64_CMD_NON_FABRIC;\n\n\tels->cq_id = cpu_to_le16(SLI4_CQ_DEFAULT);\n\n\tif (((els->ct_byte & SLI4_REQ_WQE_CT) >> SLI4_REQ_WQE_CT_SHFT) !=\n\t\t\t\t\tSLI4_GENERIC_CONTEXT_RPI)\n\t\tels->remote_id_dword = cpu_to_le32(params->d_id);\n\n\tif (((els->ct_byte & SLI4_REQ_WQE_CT) >> SLI4_REQ_WQE_CT_SHFT) ==\n\t\t\t\t\tSLI4_GENERIC_CONTEXT_VPI)\n\t\tels->temporary_rpi = cpu_to_le16(params->rpi);\n\n\treturn 0;\n}\n\nint\nsli_fcp_icmnd64_wqe(struct sli4 *sli, void *buf, struct efc_dma *sgl, u16 xri,\n\t\t    u16 tag, u16 cq_id, u32 rpi, u32 rnode_fcid, u8 timeout)\n{\n\tstruct sli4_fcp_icmnd64_wqe *icmnd = buf;\n\tstruct sli4_sge *sge = NULL;\n\tstruct sli4_bde *bptr;\n\tu32 len;\n\n\tmemset(buf, 0, sli->wqe_size);\n\n\tif (!sgl || !sgl->virt) {\n\t\tefc_log_err(sli, \"bad parameter sgl=%p virt=%p\\n\",\n\t\t\t    sgl, sgl ? sgl->virt : NULL);\n\t\treturn -EIO;\n\t}\n\tsge = sgl->virt;\n\tbptr = &icmnd->bde;\n\tif (sli->params.sgl_pre_registered) {\n\t\ticmnd->qosd_xbl_hlm_iod_dbde_wqes &= ~SLI4_ICMD_WQE_XBL;\n\n\t\ticmnd->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_ICMD_WQE_DBDE;\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t    (le32_to_cpu(sge[0].buffer_length) &\n\t\t\t\t     SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.data.low  = sge[0].buffer_address_low;\n\t\tbptr->u.data.high = sge[0].buffer_address_high;\n\t} else {\n\t\ticmnd->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_ICMD_WQE_XBL;\n\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(BLP)) |\n\t\t\t\t    (sgl->size & SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.blp.low  = cpu_to_le32(lower_32_bits(sgl->phys));\n\t\tbptr->u.blp.high = cpu_to_le32(upper_32_bits(sgl->phys));\n\t}\n\n\tlen = le32_to_cpu(sge[0].buffer_length) +\n\t      le32_to_cpu(sge[1].buffer_length);\n\ticmnd->payload_offset_length = cpu_to_le16(len);\n\ticmnd->xri_tag = cpu_to_le16(xri);\n\ticmnd->context_tag = cpu_to_le16(rpi);\n\ticmnd->timer = timeout;\n\n\t \n\ticmnd->class_pu_byte |= 2 << SLI4_ICMD_WQE_PU_SHFT;\n\ticmnd->class_pu_byte |= SLI4_GENERIC_CLASS_CLASS_3;\n\ticmnd->command = SLI4_WQE_FCP_ICMND64;\n\ticmnd->dif_ct_bs_byte |=\n\t\tSLI4_GENERIC_CONTEXT_RPI << SLI4_ICMD_WQE_CT_SHFT;\n\n\ticmnd->abort_tag = cpu_to_le32(xri);\n\n\ticmnd->request_tag = cpu_to_le16(tag);\n\ticmnd->len_loc1_byte |= SLI4_ICMD_WQE_LEN_LOC_BIT1;\n\ticmnd->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_ICMD_WQE_LEN_LOC_BIT2;\n\ticmnd->cmd_type_byte |= SLI4_CMD_FCP_ICMND64_WQE;\n\ticmnd->cq_id = cpu_to_le16(cq_id);\n\n\treturn  0;\n}\n\nint\nsli_fcp_iread64_wqe(struct sli4 *sli, void *buf, struct efc_dma *sgl,\n\t\t    u32 first_data_sge, u32 xfer_len, u16 xri, u16 tag,\n\t\t    u16 cq_id, u32 rpi, u32 rnode_fcid,\n\t\t    u8 dif, u8 bs, u8 timeout)\n{\n\tstruct sli4_fcp_iread64_wqe *iread = buf;\n\tstruct sli4_sge *sge = NULL;\n\tstruct sli4_bde *bptr;\n\tu32 sge_flags, len;\n\n\tmemset(buf, 0, sli->wqe_size);\n\n\tif (!sgl || !sgl->virt) {\n\t\tefc_log_err(sli, \"bad parameter sgl=%p virt=%p\\n\",\n\t\t\t    sgl, sgl ? sgl->virt : NULL);\n\t\treturn -EIO;\n\t}\n\n\tsge = sgl->virt;\n\tbptr = &iread->bde;\n\tif (sli->params.sgl_pre_registered) {\n\t\tiread->qosd_xbl_hlm_iod_dbde_wqes &= ~SLI4_IR_WQE_XBL;\n\n\t\tiread->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_IR_WQE_DBDE;\n\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t    (le32_to_cpu(sge[0].buffer_length) &\n\t\t\t\t     SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.blp.low  = sge[0].buffer_address_low;\n\t\tbptr->u.blp.high = sge[0].buffer_address_high;\n\t} else {\n\t\tiread->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_IR_WQE_XBL;\n\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(BLP)) |\n\t\t\t\t    (sgl->size & SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.blp.low  =\n\t\t\t\tcpu_to_le32(lower_32_bits(sgl->phys));\n\t\tbptr->u.blp.high =\n\t\t\t\tcpu_to_le32(upper_32_bits(sgl->phys));\n\n\t\t \n\t\tlen = le32_to_cpu(sge[0].buffer_length);\n\t\tiread->fcp_cmd_buffer_length = cpu_to_le16(len);\n\n\t\tsge_flags = le32_to_cpu(sge[1].dw2_flags);\n\t\tsge_flags &= (~SLI4_SGE_TYPE_MASK);\n\t\tsge_flags |= (SLI4_SGE_TYPE_SKIP << SLI4_SGE_TYPE_SHIFT);\n\t\tsge[1].dw2_flags = cpu_to_le32(sge_flags);\n\t}\n\n\tlen = le32_to_cpu(sge[0].buffer_length) +\n\t      le32_to_cpu(sge[1].buffer_length);\n\tiread->payload_offset_length = cpu_to_le16(len);\n\tiread->total_transfer_length = cpu_to_le32(xfer_len);\n\n\tiread->xri_tag = cpu_to_le16(xri);\n\tiread->context_tag = cpu_to_le16(rpi);\n\n\tiread->timer = timeout;\n\n\t \n\tiread->class_pu_byte |= 2 << SLI4_IR_WQE_PU_SHFT;\n\tiread->class_pu_byte |= SLI4_GENERIC_CLASS_CLASS_3;\n\tiread->command = SLI4_WQE_FCP_IREAD64;\n\tiread->dif_ct_bs_byte |=\n\t\tSLI4_GENERIC_CONTEXT_RPI << SLI4_IR_WQE_CT_SHFT;\n\tiread->dif_ct_bs_byte |= dif;\n\tiread->dif_ct_bs_byte  |= bs << SLI4_IR_WQE_BS_SHFT;\n\n\tiread->abort_tag = cpu_to_le32(xri);\n\n\tiread->request_tag = cpu_to_le16(tag);\n\tiread->len_loc1_byte |= SLI4_IR_WQE_LEN_LOC_BIT1;\n\tiread->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_IR_WQE_LEN_LOC_BIT2;\n\tiread->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_IR_WQE_IOD;\n\tiread->cmd_type_byte |= SLI4_CMD_FCP_IREAD64_WQE;\n\tiread->cq_id = cpu_to_le16(cq_id);\n\n\tif (sli->params.perf_hint) {\n\t\tbptr = &iread->first_data_bde;\n\t\tbptr->bde_type_buflen =\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t  (le32_to_cpu(sge[first_data_sge].buffer_length) &\n\t\t\t     SLI4_BDE_LEN_MASK));\n\t\tbptr->u.data.low =\n\t\t\tsge[first_data_sge].buffer_address_low;\n\t\tbptr->u.data.high =\n\t\t\tsge[first_data_sge].buffer_address_high;\n\t}\n\n\treturn  0;\n}\n\nint\nsli_fcp_iwrite64_wqe(struct sli4 *sli, void *buf, struct efc_dma *sgl,\n\t\t     u32 first_data_sge, u32 xfer_len,\n\t\t     u32 first_burst, u16 xri, u16 tag,\n\t\t     u16 cq_id, u32 rpi,\n\t\t     u32 rnode_fcid,\n\t\t     u8 dif, u8 bs, u8 timeout)\n{\n\tstruct sli4_fcp_iwrite64_wqe *iwrite = buf;\n\tstruct sli4_sge *sge = NULL;\n\tstruct sli4_bde *bptr;\n\tu32 sge_flags, min, len;\n\n\tmemset(buf, 0, sli->wqe_size);\n\n\tif (!sgl || !sgl->virt) {\n\t\tefc_log_err(sli, \"bad parameter sgl=%p virt=%p\\n\",\n\t\t\t    sgl, sgl ? sgl->virt : NULL);\n\t\treturn -EIO;\n\t}\n\tsge = sgl->virt;\n\tbptr = &iwrite->bde;\n\tif (sli->params.sgl_pre_registered) {\n\t\tiwrite->qosd_xbl_hlm_iod_dbde_wqes &= ~SLI4_IWR_WQE_XBL;\n\n\t\tiwrite->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_IWR_WQE_DBDE;\n\t\tbptr->bde_type_buflen = cpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t       (le32_to_cpu(sge[0].buffer_length) & SLI4_BDE_LEN_MASK));\n\t\tbptr->u.data.low  = sge[0].buffer_address_low;\n\t\tbptr->u.data.high = sge[0].buffer_address_high;\n\t} else {\n\t\tiwrite->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_IWR_WQE_XBL;\n\n\t\tbptr->bde_type_buflen =\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t\t(sgl->size & SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.blp.low  = cpu_to_le32(lower_32_bits(sgl->phys));\n\t\tbptr->u.blp.high = cpu_to_le32(upper_32_bits(sgl->phys));\n\n\t\t \n\t\tlen = le32_to_cpu(sge[0].buffer_length);\n\t\tiwrite->fcp_cmd_buffer_length = cpu_to_le16(len);\n\t\tsge_flags = le32_to_cpu(sge[1].dw2_flags);\n\t\tsge_flags &= ~SLI4_SGE_TYPE_MASK;\n\t\tsge_flags |= (SLI4_SGE_TYPE_SKIP << SLI4_SGE_TYPE_SHIFT);\n\t\tsge[1].dw2_flags = cpu_to_le32(sge_flags);\n\t}\n\n\tlen = le32_to_cpu(sge[0].buffer_length) +\n\t      le32_to_cpu(sge[1].buffer_length);\n\tiwrite->payload_offset_length = cpu_to_le16(len);\n\tiwrite->total_transfer_length = cpu_to_le16(xfer_len);\n\tmin = (xfer_len < first_burst) ? xfer_len : first_burst;\n\tiwrite->initial_transfer_length = cpu_to_le16(min);\n\n\tiwrite->xri_tag = cpu_to_le16(xri);\n\tiwrite->context_tag = cpu_to_le16(rpi);\n\n\tiwrite->timer = timeout;\n\t \n\tiwrite->class_pu_byte |= 2 << SLI4_IWR_WQE_PU_SHFT;\n\tiwrite->class_pu_byte |= SLI4_GENERIC_CLASS_CLASS_3;\n\tiwrite->command = SLI4_WQE_FCP_IWRITE64;\n\tiwrite->dif_ct_bs_byte |=\n\t\t\tSLI4_GENERIC_CONTEXT_RPI << SLI4_IWR_WQE_CT_SHFT;\n\tiwrite->dif_ct_bs_byte |= dif;\n\tiwrite->dif_ct_bs_byte |= bs << SLI4_IWR_WQE_BS_SHFT;\n\n\tiwrite->abort_tag = cpu_to_le32(xri);\n\n\tiwrite->request_tag = cpu_to_le16(tag);\n\tiwrite->len_loc1_byte |= SLI4_IWR_WQE_LEN_LOC_BIT1;\n\tiwrite->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_IWR_WQE_LEN_LOC_BIT2;\n\tiwrite->cmd_type_byte |= SLI4_CMD_FCP_IWRITE64_WQE;\n\tiwrite->cq_id = cpu_to_le16(cq_id);\n\n\tif (sli->params.perf_hint) {\n\t\tbptr = &iwrite->first_data_bde;\n\n\t\tbptr->bde_type_buflen =\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t (le32_to_cpu(sge[first_data_sge].buffer_length) &\n\t\t\t     SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.data.low = sge[first_data_sge].buffer_address_low;\n\t\tbptr->u.data.high = sge[first_data_sge].buffer_address_high;\n\t}\n\n\treturn  0;\n}\n\nint\nsli_fcp_treceive64_wqe(struct sli4 *sli, void *buf, struct efc_dma *sgl,\n\t\t       u32 first_data_sge, u16 cq_id, u8 dif, u8 bs,\n\t\t       struct sli_fcp_tgt_params *params)\n{\n\tstruct sli4_fcp_treceive64_wqe *trecv = buf;\n\tstruct sli4_fcp_128byte_wqe *trecv_128 = buf;\n\tstruct sli4_sge *sge = NULL;\n\tstruct sli4_bde *bptr;\n\n\tmemset(buf, 0, sli->wqe_size);\n\n\tif (!sgl || !sgl->virt) {\n\t\tefc_log_err(sli, \"bad parameter sgl=%p virt=%p\\n\",\n\t\t\t    sgl, sgl ? sgl->virt : NULL);\n\t\treturn -EIO;\n\t}\n\tsge = sgl->virt;\n\tbptr = &trecv->bde;\n\tif (sli->params.sgl_pre_registered) {\n\t\ttrecv->qosd_xbl_hlm_iod_dbde_wqes &= ~SLI4_TRCV_WQE_XBL;\n\n\t\ttrecv->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_TRCV_WQE_DBDE;\n\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t    (le32_to_cpu(sge[0].buffer_length)\n\t\t\t\t\t& SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.data.low  = sge[0].buffer_address_low;\n\t\tbptr->u.data.high = sge[0].buffer_address_high;\n\n\t\ttrecv->payload_offset_length = sge[0].buffer_length;\n\t} else {\n\t\ttrecv->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_TRCV_WQE_XBL;\n\n\t\t \n\t\tif (!dif &&\n\t\t    params->xmit_len <= le32_to_cpu(sge[2].buffer_length)) {\n\t\t\ttrecv->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_TRCV_WQE_DBDE;\n\t\t\tbptr->bde_type_buflen =\n\t\t\t      cpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t\t  (le32_to_cpu(sge[2].buffer_length)\n\t\t\t\t\t  & SLI4_BDE_LEN_MASK));\n\n\t\t\tbptr->u.data.low = sge[2].buffer_address_low;\n\t\t\tbptr->u.data.high = sge[2].buffer_address_high;\n\t\t} else {\n\t\t\tbptr->bde_type_buflen =\n\t\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(BLP)) |\n\t\t\t\t(sgl->size & SLI4_BDE_LEN_MASK));\n\t\t\tbptr->u.blp.low = cpu_to_le32(lower_32_bits(sgl->phys));\n\t\t\tbptr->u.blp.high =\n\t\t\t\tcpu_to_le32(upper_32_bits(sgl->phys));\n\t\t}\n\t}\n\n\ttrecv->relative_offset = cpu_to_le32(params->offset);\n\n\tif (params->flags & SLI4_IO_CONTINUATION)\n\t\ttrecv->eat_xc_ccpe |= SLI4_TRCV_WQE_XC;\n\n\ttrecv->xri_tag = cpu_to_le16(params->xri);\n\n\ttrecv->context_tag = cpu_to_le16(params->rpi);\n\n\t \n\ttrecv->class_ar_pu_byte |= 1 << SLI4_TRCV_WQE_PU_SHFT;\n\n\tif (params->flags & SLI4_IO_AUTO_GOOD_RESPONSE)\n\t\ttrecv->class_ar_pu_byte |= SLI4_TRCV_WQE_AR;\n\n\ttrecv->command = SLI4_WQE_FCP_TRECEIVE64;\n\ttrecv->class_ar_pu_byte |= SLI4_GENERIC_CLASS_CLASS_3;\n\ttrecv->dif_ct_bs_byte |=\n\t\tSLI4_GENERIC_CONTEXT_RPI << SLI4_TRCV_WQE_CT_SHFT;\n\ttrecv->dif_ct_bs_byte |= bs << SLI4_TRCV_WQE_BS_SHFT;\n\n\ttrecv->remote_xid = cpu_to_le16(params->ox_id);\n\n\ttrecv->request_tag = cpu_to_le16(params->tag);\n\n\ttrecv->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_TRCV_WQE_IOD;\n\n\ttrecv->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_TRCV_WQE_LEN_LOC_BIT2;\n\n\ttrecv->cmd_type_byte |= SLI4_CMD_FCP_TRECEIVE64_WQE;\n\n\ttrecv->cq_id = cpu_to_le16(cq_id);\n\n\ttrecv->fcp_data_receive_length = cpu_to_le32(params->xmit_len);\n\n\tif (sli->params.perf_hint) {\n\t\tbptr = &trecv->first_data_bde;\n\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t    (le32_to_cpu(sge[first_data_sge].buffer_length) &\n\t\t\t     SLI4_BDE_LEN_MASK));\n\t\tbptr->u.data.low = sge[first_data_sge].buffer_address_low;\n\t\tbptr->u.data.high = sge[first_data_sge].buffer_address_high;\n\t}\n\n\t \n\tif (params->cs_ctl & SLI4_MASK_CCP) {\n\t\ttrecv->eat_xc_ccpe |= SLI4_TRCV_WQE_CCPE;\n\t\ttrecv->ccp = (params->cs_ctl & SLI4_MASK_CCP);\n\t}\n\n\tif (params->app_id && sli->wqe_size == SLI4_WQE_EXT_BYTES &&\n\t    !(trecv->eat_xc_ccpe & SLI4_TRSP_WQE_EAT)) {\n\t\ttrecv->lloc1_appid |= SLI4_TRCV_WQE_APPID;\n\t\ttrecv->qosd_xbl_hlm_iod_dbde_wqes |= SLI4_TRCV_WQE_WQES;\n\t\ttrecv_128->dw[31] = params->app_id;\n\t}\n\treturn 0;\n}\n\nint\nsli_fcp_cont_treceive64_wqe(struct sli4 *sli, void *buf,\n\t\t\t    struct efc_dma *sgl, u32 first_data_sge,\n\t\t\t    u16 sec_xri, u16 cq_id, u8 dif, u8 bs,\n\t\t\t    struct sli_fcp_tgt_params *params)\n{\n\tint rc;\n\n\trc = sli_fcp_treceive64_wqe(sli, buf, sgl, first_data_sge,\n\t\t\t\t    cq_id, dif, bs, params);\n\tif (!rc) {\n\t\tstruct sli4_fcp_treceive64_wqe *trecv = buf;\n\n\t\ttrecv->command = SLI4_WQE_FCP_CONT_TRECEIVE64;\n\t\ttrecv->dword5.sec_xri_tag = cpu_to_le16(sec_xri);\n\t}\n\treturn rc;\n}\n\nint\nsli_fcp_trsp64_wqe(struct sli4 *sli4, void *buf, struct efc_dma *sgl,\n\t\t   u16 cq_id, u8 port_owned, struct sli_fcp_tgt_params *params)\n{\n\tstruct sli4_fcp_trsp64_wqe *trsp = buf;\n\tstruct sli4_fcp_128byte_wqe *trsp_128 = buf;\n\n\tmemset(buf, 0, sli4->wqe_size);\n\n\tif (params->flags & SLI4_IO_AUTO_GOOD_RESPONSE) {\n\t\ttrsp->class_ag_byte |= SLI4_TRSP_WQE_AG;\n\t} else {\n\t\tstruct sli4_sge\t*sge = sgl->virt;\n\t\tstruct sli4_bde *bptr;\n\n\t\tif (sli4->params.sgl_pre_registered || port_owned)\n\t\t\ttrsp->qosd_xbl_hlm_dbde_wqes |= SLI4_TRSP_WQE_DBDE;\n\t\telse\n\t\t\ttrsp->qosd_xbl_hlm_dbde_wqes |= SLI4_TRSP_WQE_XBL;\n\t\tbptr = &trsp->bde;\n\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t     (le32_to_cpu(sge[0].buffer_length) &\n\t\t\t\t      SLI4_BDE_LEN_MASK));\n\t\tbptr->u.data.low  = sge[0].buffer_address_low;\n\t\tbptr->u.data.high = sge[0].buffer_address_high;\n\n\t\ttrsp->fcp_response_length = cpu_to_le32(params->xmit_len);\n\t}\n\n\tif (params->flags & SLI4_IO_CONTINUATION)\n\t\ttrsp->eat_xc_ccpe |= SLI4_TRSP_WQE_XC;\n\n\ttrsp->xri_tag = cpu_to_le16(params->xri);\n\ttrsp->rpi = cpu_to_le16(params->rpi);\n\n\ttrsp->command = SLI4_WQE_FCP_TRSP64;\n\ttrsp->class_ag_byte |= SLI4_GENERIC_CLASS_CLASS_3;\n\n\ttrsp->remote_xid = cpu_to_le16(params->ox_id);\n\ttrsp->request_tag = cpu_to_le16(params->tag);\n\tif (params->flags & SLI4_IO_DNRX)\n\t\ttrsp->ct_dnrx_byte |= SLI4_TRSP_WQE_DNRX;\n\telse\n\t\ttrsp->ct_dnrx_byte &= ~SLI4_TRSP_WQE_DNRX;\n\n\ttrsp->lloc1_appid |= 0x1;\n\ttrsp->cq_id = cpu_to_le16(cq_id);\n\ttrsp->cmd_type_byte = SLI4_CMD_FCP_TRSP64_WQE;\n\n\t \n\tif (params->cs_ctl & SLI4_MASK_CCP) {\n\t\ttrsp->eat_xc_ccpe |= SLI4_TRSP_WQE_CCPE;\n\t\ttrsp->ccp = (params->cs_ctl & SLI4_MASK_CCP);\n\t}\n\n\tif (params->app_id && sli4->wqe_size == SLI4_WQE_EXT_BYTES &&\n\t    !(trsp->eat_xc_ccpe & SLI4_TRSP_WQE_EAT)) {\n\t\ttrsp->lloc1_appid |= SLI4_TRSP_WQE_APPID;\n\t\ttrsp->qosd_xbl_hlm_dbde_wqes |= SLI4_TRSP_WQE_WQES;\n\t\ttrsp_128->dw[31] = params->app_id;\n\t}\n\treturn 0;\n}\n\nint\nsli_fcp_tsend64_wqe(struct sli4 *sli4, void *buf, struct efc_dma *sgl,\n\t\t    u32 first_data_sge, u16 cq_id, u8 dif, u8 bs,\n\t\t    struct sli_fcp_tgt_params *params)\n{\n\tstruct sli4_fcp_tsend64_wqe *tsend = buf;\n\tstruct sli4_fcp_128byte_wqe *tsend_128 = buf;\n\tstruct sli4_sge *sge = NULL;\n\tstruct sli4_bde *bptr;\n\n\tmemset(buf, 0, sli4->wqe_size);\n\n\tif (!sgl || !sgl->virt) {\n\t\tefc_log_err(sli4, \"bad parameter sgl=%p virt=%p\\n\",\n\t\t\t    sgl, sgl ? sgl->virt : NULL);\n\t\treturn -EIO;\n\t}\n\tsge = sgl->virt;\n\n\tbptr = &tsend->bde;\n\tif (sli4->params.sgl_pre_registered) {\n\t\ttsend->ll_qd_xbl_hlm_iod_dbde &= ~SLI4_TSEND_WQE_XBL;\n\n\t\ttsend->ll_qd_xbl_hlm_iod_dbde |= SLI4_TSEND_WQE_DBDE;\n\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t   (le32_to_cpu(sge[2].buffer_length) &\n\t\t\t\t    SLI4_BDE_LEN_MASK));\n\n\t\t \n\t\tbptr->u.data.low  = sge[2].buffer_address_low;\n\t\tbptr->u.data.high = sge[2].buffer_address_high;\n\t} else {\n\t\ttsend->ll_qd_xbl_hlm_iod_dbde |= SLI4_TSEND_WQE_XBL;\n\n\t\t \n\t\tif (!dif &&\n\t\t    params->xmit_len <= le32_to_cpu(sge[2].buffer_length)) {\n\t\t\ttsend->ll_qd_xbl_hlm_iod_dbde |= SLI4_TSEND_WQE_DBDE;\n\n\t\t\tbptr->bde_type_buflen =\n\t\t\t    cpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t\t(le32_to_cpu(sge[2].buffer_length) &\n\t\t\t\t\tSLI4_BDE_LEN_MASK));\n\t\t\t \n\t\t\tbptr->u.data.low =\n\t\t\t\tsge[2].buffer_address_low;\n\t\t\tbptr->u.data.high =\n\t\t\t\tsge[2].buffer_address_high;\n\t\t} else {\n\t\t\tbptr->bde_type_buflen =\n\t\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(BLP)) |\n\t\t\t\t\t    (sgl->size &\n\t\t\t\t\t     SLI4_BDE_LEN_MASK));\n\t\t\tbptr->u.blp.low =\n\t\t\t\tcpu_to_le32(lower_32_bits(sgl->phys));\n\t\t\tbptr->u.blp.high =\n\t\t\t\tcpu_to_le32(upper_32_bits(sgl->phys));\n\t\t}\n\t}\n\n\ttsend->relative_offset = cpu_to_le32(params->offset);\n\n\tif (params->flags & SLI4_IO_CONTINUATION)\n\t\ttsend->dw10byte2 |= SLI4_TSEND_XC;\n\n\ttsend->xri_tag = cpu_to_le16(params->xri);\n\n\ttsend->rpi = cpu_to_le16(params->rpi);\n\t \n\ttsend->class_pu_ar_byte |= 1 << SLI4_TSEND_WQE_PU_SHFT;\n\n\tif (params->flags & SLI4_IO_AUTO_GOOD_RESPONSE)\n\t\ttsend->class_pu_ar_byte |= SLI4_TSEND_WQE_AR;\n\n\ttsend->command = SLI4_WQE_FCP_TSEND64;\n\ttsend->class_pu_ar_byte |= SLI4_GENERIC_CLASS_CLASS_3;\n\ttsend->ct_byte |= SLI4_GENERIC_CONTEXT_RPI << SLI4_TSEND_CT_SHFT;\n\ttsend->ct_byte |= dif;\n\ttsend->ct_byte |= bs << SLI4_TSEND_BS_SHFT;\n\n\ttsend->remote_xid = cpu_to_le16(params->ox_id);\n\n\ttsend->request_tag = cpu_to_le16(params->tag);\n\n\ttsend->ll_qd_xbl_hlm_iod_dbde |= SLI4_TSEND_LEN_LOC_BIT2;\n\n\ttsend->cq_id = cpu_to_le16(cq_id);\n\n\ttsend->cmd_type_byte |= SLI4_CMD_FCP_TSEND64_WQE;\n\n\ttsend->fcp_data_transmit_length = cpu_to_le32(params->xmit_len);\n\n\tif (sli4->params.perf_hint) {\n\t\tbptr = &tsend->first_data_bde;\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t    (le32_to_cpu(sge[first_data_sge].buffer_length) &\n\t\t\t     SLI4_BDE_LEN_MASK));\n\t\tbptr->u.data.low =\n\t\t\tsge[first_data_sge].buffer_address_low;\n\t\tbptr->u.data.high =\n\t\t\tsge[first_data_sge].buffer_address_high;\n\t}\n\n\t \n\tif (params->cs_ctl & SLI4_MASK_CCP) {\n\t\ttsend->dw10byte2 |= SLI4_TSEND_CCPE;\n\t\ttsend->ccp = (params->cs_ctl & SLI4_MASK_CCP);\n\t}\n\n\tif (params->app_id && sli4->wqe_size == SLI4_WQE_EXT_BYTES &&\n\t    !(tsend->dw10byte2 & SLI4_TSEND_EAT)) {\n\t\ttsend->dw10byte0 |= SLI4_TSEND_APPID_VALID;\n\t\ttsend->ll_qd_xbl_hlm_iod_dbde |= SLI4_TSEND_WQES;\n\t\ttsend_128->dw[31] = params->app_id;\n\t}\n\treturn 0;\n}\n\nint\nsli_gen_request64_wqe(struct sli4 *sli4, void *buf, struct efc_dma *sgl,\n\t\t      struct sli_ct_params *params)\n{\n\tstruct sli4_gen_request64_wqe *gen = buf;\n\tstruct sli4_sge *sge = NULL;\n\tstruct sli4_bde *bptr;\n\n\tmemset(buf, 0, sli4->wqe_size);\n\n\tif (!sgl || !sgl->virt) {\n\t\tefc_log_err(sli4, \"bad parameter sgl=%p virt=%p\\n\",\n\t\t\t    sgl, sgl ? sgl->virt : NULL);\n\t\treturn -EIO;\n\t}\n\tsge = sgl->virt;\n\tbptr = &gen->bde;\n\n\tif (sli4->params.sgl_pre_registered) {\n\t\tgen->dw10flags1 &= ~SLI4_GEN_REQ64_WQE_XBL;\n\n\t\tgen->dw10flags1 |= SLI4_GEN_REQ64_WQE_DBDE;\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t    (params->xmit_len & SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.data.low  = sge[0].buffer_address_low;\n\t\tbptr->u.data.high = sge[0].buffer_address_high;\n\t} else {\n\t\tgen->dw10flags1 |= SLI4_GEN_REQ64_WQE_XBL;\n\n\t\tbptr->bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(BLP)) |\n\t\t\t\t    ((2 * sizeof(struct sli4_sge)) &\n\t\t\t\t     SLI4_BDE_LEN_MASK));\n\n\t\tbptr->u.blp.low =\n\t\t\tcpu_to_le32(lower_32_bits(sgl->phys));\n\t\tbptr->u.blp.high =\n\t\t\tcpu_to_le32(upper_32_bits(sgl->phys));\n\t}\n\n\tgen->request_payload_length = cpu_to_le32(params->xmit_len);\n\tgen->max_response_payload_length = cpu_to_le32(params->rsp_len);\n\n\tgen->df_ctl = params->df_ctl;\n\tgen->type = params->type;\n\tgen->r_ctl = params->r_ctl;\n\n\tgen->xri_tag = cpu_to_le16(params->xri);\n\n\tgen->ct_byte = SLI4_GENERIC_CONTEXT_RPI << SLI4_GEN_REQ64_CT_SHFT;\n\tgen->context_tag = cpu_to_le16(params->rpi);\n\n\tgen->class_byte = SLI4_GENERIC_CLASS_CLASS_3;\n\n\tgen->command = SLI4_WQE_GEN_REQUEST64;\n\n\tgen->timer = params->timeout;\n\n\tgen->request_tag = cpu_to_le16(params->tag);\n\n\tgen->dw10flags1 |= SLI4_GEN_REQ64_WQE_IOD;\n\n\tgen->dw10flags0 |= SLI4_GEN_REQ64_WQE_QOSD;\n\n\tgen->cmd_type_byte = SLI4_CMD_GEN_REQUEST64_WQE;\n\n\tgen->cq_id = cpu_to_le16(SLI4_CQ_DEFAULT);\n\n\treturn 0;\n}\n\nint\nsli_send_frame_wqe(struct sli4 *sli, void *buf, u8 sof, u8 eof, u32 *hdr,\n\t\t   struct efc_dma *payload, u32 req_len, u8 timeout, u16 xri,\n\t\t   u16 req_tag)\n{\n\tstruct sli4_send_frame_wqe *sf = buf;\n\n\tmemset(buf, 0, sli->wqe_size);\n\n\tsf->dw10flags1 |= SLI4_SF_WQE_DBDE;\n\tsf->bde.bde_type_buflen = cpu_to_le32(req_len &\n\t\t\t\t\t      SLI4_BDE_LEN_MASK);\n\tsf->bde.u.data.low = cpu_to_le32(lower_32_bits(payload->phys));\n\tsf->bde.u.data.high = cpu_to_le32(upper_32_bits(payload->phys));\n\n\t \n\tsf->fc_header_0_1[0] = cpu_to_le32(hdr[0]);\n\tsf->fc_header_0_1[1] = cpu_to_le32(hdr[1]);\n\tsf->fc_header_2_5[0] = cpu_to_le32(hdr[2]);\n\tsf->fc_header_2_5[1] = cpu_to_le32(hdr[3]);\n\tsf->fc_header_2_5[2] = cpu_to_le32(hdr[4]);\n\tsf->fc_header_2_5[3] = cpu_to_le32(hdr[5]);\n\n\tsf->frame_length = cpu_to_le32(req_len);\n\n\tsf->xri_tag = cpu_to_le16(xri);\n\tsf->dw7flags0 &= ~SLI4_SF_PU;\n\tsf->context_tag = 0;\n\n\tsf->ct_byte &= ~SLI4_SF_CT;\n\tsf->command = SLI4_WQE_SEND_FRAME;\n\tsf->dw7flags0 |= SLI4_GENERIC_CLASS_CLASS_3;\n\tsf->timer = timeout;\n\n\tsf->request_tag = cpu_to_le16(req_tag);\n\tsf->eof = eof;\n\tsf->sof = sof;\n\n\tsf->dw10flags1 &= ~SLI4_SF_QOSD;\n\tsf->dw10flags0 |= SLI4_SF_LEN_LOC_BIT1;\n\tsf->dw10flags2 &= ~SLI4_SF_XC;\n\n\tsf->dw10flags1 |= SLI4_SF_XBL;\n\n\tsf->cmd_type_byte |= SLI4_CMD_SEND_FRAME_WQE;\n\tsf->cq_id = cpu_to_le16(0xffff);\n\n\treturn 0;\n}\n\nint\nsli_xmit_bls_rsp64_wqe(struct sli4 *sli, void *buf,\n\t\t       struct sli_bls_payload *payload,\n\t\t       struct sli_bls_params *params)\n{\n\tstruct sli4_xmit_bls_rsp_wqe *bls = buf;\n\tu32 dw_ridflags = 0;\n\n\t \n\tif (params->rpi_registered && params->s_id != U32_MAX) {\n\t\tefc_log_info(sli, \"S_ID specified for attached remote node %d\\n\",\n\t\t\t     params->rpi);\n\t\treturn -EIO;\n\t}\n\n\tmemset(buf, 0, sli->wqe_size);\n\n\tif (payload->type == SLI4_SLI_BLS_ACC) {\n\t\tbls->payload_word0 =\n\t\t\tcpu_to_le32((payload->u.acc.seq_id_last << 16) |\n\t\t\t\t    (payload->u.acc.seq_id_validity << 24));\n\t\tbls->high_seq_cnt = payload->u.acc.high_seq_cnt;\n\t\tbls->low_seq_cnt = payload->u.acc.low_seq_cnt;\n\t} else if (payload->type == SLI4_SLI_BLS_RJT) {\n\t\tbls->payload_word0 =\n\t\t\t\tcpu_to_le32(*((u32 *)&payload->u.rjt));\n\t\tdw_ridflags |= SLI4_BLS_RSP_WQE_AR;\n\t} else {\n\t\tefc_log_info(sli, \"bad BLS type %#x\\n\", payload->type);\n\t\treturn -EIO;\n\t}\n\n\tbls->ox_id = payload->ox_id;\n\tbls->rx_id = payload->rx_id;\n\n\tif (params->rpi_registered) {\n\t\tbls->dw8flags0 |=\n\t\tSLI4_GENERIC_CONTEXT_RPI << SLI4_BLS_RSP_WQE_CT_SHFT;\n\t\tbls->context_tag = cpu_to_le16(params->rpi);\n\t} else {\n\t\tbls->dw8flags0 |=\n\t\tSLI4_GENERIC_CONTEXT_VPI << SLI4_BLS_RSP_WQE_CT_SHFT;\n\t\tbls->context_tag = cpu_to_le16(params->vpi);\n\n\t\tbls->local_n_port_id_dword |=\n\t\t\tcpu_to_le32(params->s_id & 0x00ffffff);\n\n\t\tdw_ridflags = (dw_ridflags & ~SLI4_BLS_RSP_RID) |\n\t\t\t       (params->d_id & SLI4_BLS_RSP_RID);\n\n\t\tbls->temporary_rpi = cpu_to_le16(params->rpi);\n\t}\n\n\tbls->xri_tag = cpu_to_le16(params->xri);\n\n\tbls->dw8flags1 |= SLI4_GENERIC_CLASS_CLASS_3;\n\n\tbls->command = SLI4_WQE_XMIT_BLS_RSP;\n\n\tbls->request_tag = cpu_to_le16(params->tag);\n\n\tbls->dw11flags1 |= SLI4_BLS_RSP_WQE_QOSD;\n\n\tbls->remote_id_dword = cpu_to_le32(dw_ridflags);\n\tbls->cq_id = cpu_to_le16(SLI4_CQ_DEFAULT);\n\n\tbls->dw12flags0 |= SLI4_CMD_XMIT_BLS_RSP64_WQE;\n\n\treturn 0;\n}\n\nint\nsli_xmit_els_rsp64_wqe(struct sli4 *sli, void *buf, struct efc_dma *rsp,\n\t\t       struct sli_els_params *params)\n{\n\tstruct sli4_xmit_els_rsp64_wqe *els = buf;\n\n\tmemset(buf, 0, sli->wqe_size);\n\n\tif (sli->params.sgl_pre_registered)\n\t\tels->flags2 |= SLI4_ELS_DBDE;\n\telse\n\t\tels->flags2 |= SLI4_ELS_XBL;\n\n\tels->els_response_payload.bde_type_buflen =\n\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t    (params->rsp_len & SLI4_BDE_LEN_MASK));\n\tels->els_response_payload.u.data.low =\n\t\tcpu_to_le32(lower_32_bits(rsp->phys));\n\tels->els_response_payload.u.data.high =\n\t\tcpu_to_le32(upper_32_bits(rsp->phys));\n\n\tels->els_response_payload_length = cpu_to_le32(params->rsp_len);\n\n\tels->xri_tag = cpu_to_le16(params->xri);\n\n\tels->class_byte |= SLI4_GENERIC_CLASS_CLASS_3;\n\n\tels->command = SLI4_WQE_ELS_RSP64;\n\n\tels->request_tag = cpu_to_le16(params->tag);\n\n\tels->ox_id = cpu_to_le16(params->ox_id);\n\n\tels->flags2 |= SLI4_ELS_QOSD;\n\n\tels->cmd_type_wqec = SLI4_ELS_REQUEST64_CMD_GEN;\n\n\tels->cq_id = cpu_to_le16(SLI4_CQ_DEFAULT);\n\n\tif (params->rpi_registered) {\n\t\tels->ct_byte |=\n\t\t\tSLI4_GENERIC_CONTEXT_RPI << SLI4_ELS_CT_OFFSET;\n\t\tels->context_tag = cpu_to_le16(params->rpi);\n\t\treturn 0;\n\t}\n\n\tels->ct_byte |= SLI4_GENERIC_CONTEXT_VPI << SLI4_ELS_CT_OFFSET;\n\tels->context_tag = cpu_to_le16(params->vpi);\n\tels->rid_dw = cpu_to_le32(params->d_id & SLI4_ELS_RID);\n\tels->temporary_rpi = cpu_to_le16(params->rpi);\n\tif (params->s_id != U32_MAX) {\n\t\tels->sid_dw |=\n\t\t      cpu_to_le32(SLI4_ELS_SP | (params->s_id & SLI4_ELS_SID));\n\t}\n\n\treturn 0;\n}\n\nint\nsli_xmit_sequence64_wqe(struct sli4 *sli4, void *buf, struct efc_dma *payload,\n\t\t\tstruct sli_ct_params *params)\n{\n\tstruct sli4_xmit_sequence64_wqe *xmit = buf;\n\n\tmemset(buf, 0, sli4->wqe_size);\n\n\tif (!payload || !payload->virt) {\n\t\tefc_log_err(sli4, \"bad parameter sgl=%p virt=%p\\n\",\n\t\t\t    payload, payload ? payload->virt : NULL);\n\t\treturn -EIO;\n\t}\n\n\tif (sli4->params.sgl_pre_registered)\n\t\txmit->dw10w0 |= cpu_to_le16(SLI4_SEQ_WQE_DBDE);\n\telse\n\t\txmit->dw10w0 |= cpu_to_le16(SLI4_SEQ_WQE_XBL);\n\n\txmit->bde.bde_type_buflen =\n\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t(params->rsp_len & SLI4_BDE_LEN_MASK));\n\txmit->bde.u.data.low  =\n\t\t\tcpu_to_le32(lower_32_bits(payload->phys));\n\txmit->bde.u.data.high =\n\t\t\tcpu_to_le32(upper_32_bits(payload->phys));\n\txmit->sequence_payload_len = cpu_to_le32(params->rsp_len);\n\n\txmit->remote_n_port_id_dword |= cpu_to_le32(params->d_id & 0x00ffffff);\n\n\txmit->relative_offset = 0;\n\n\t \n\txmit->dw5flags0 &= (~SLI4_SEQ_WQE_SI);\n\txmit->dw5flags0 &= (~SLI4_SEQ_WQE_FT); \n\txmit->dw5flags0 &= (~SLI4_SEQ_WQE_XO); \n\txmit->dw5flags0 |= SLI4_SEQ_WQE_LS; \n\txmit->df_ctl = params->df_ctl;\n\txmit->type = params->type;\n\txmit->r_ctl = params->r_ctl;\n\n\txmit->xri_tag = cpu_to_le16(params->xri);\n\txmit->context_tag = cpu_to_le16(params->rpi);\n\n\txmit->dw7flags0 &= ~SLI4_SEQ_WQE_DIF;\n\txmit->dw7flags0 |=\n\t\tSLI4_GENERIC_CONTEXT_RPI << SLI4_SEQ_WQE_CT_SHIFT;\n\txmit->dw7flags0 &= ~SLI4_SEQ_WQE_BS;\n\n\txmit->command = SLI4_WQE_XMIT_SEQUENCE64;\n\txmit->dw7flags1 |= SLI4_GENERIC_CLASS_CLASS_3;\n\txmit->dw7flags1 &= ~SLI4_SEQ_WQE_PU;\n\txmit->timer = params->timeout;\n\n\txmit->abort_tag = 0;\n\txmit->request_tag = cpu_to_le16(params->tag);\n\txmit->remote_xid = cpu_to_le16(params->ox_id);\n\n\txmit->dw10w0 |=\n\tcpu_to_le16(SLI4_ELS_REQUEST64_DIR_READ << SLI4_SEQ_WQE_IOD_SHIFT);\n\n\txmit->cmd_type_wqec_byte |= SLI4_CMD_XMIT_SEQUENCE64_WQE;\n\n\txmit->dw10w0 |= cpu_to_le16(2 << SLI4_SEQ_WQE_LEN_LOC_SHIFT);\n\n\txmit->cq_id = cpu_to_le16(0xFFFF);\n\n\treturn 0;\n}\n\nint\nsli_requeue_xri_wqe(struct sli4 *sli4, void *buf, u16 xri, u16 tag, u16 cq_id)\n{\n\tstruct sli4_requeue_xri_wqe *requeue = buf;\n\n\tmemset(buf, 0, sli4->wqe_size);\n\n\trequeue->command = SLI4_WQE_REQUEUE_XRI;\n\trequeue->xri_tag = cpu_to_le16(xri);\n\trequeue->request_tag = cpu_to_le16(tag);\n\trequeue->flags2 |= cpu_to_le16(SLI4_REQU_XRI_WQE_XC);\n\trequeue->flags1 |= cpu_to_le16(SLI4_REQU_XRI_WQE_QOSD);\n\trequeue->cq_id = cpu_to_le16(cq_id);\n\trequeue->cmd_type_wqec_byte = SLI4_CMD_REQUEUE_XRI_WQE;\n\treturn 0;\n}\n\nint\nsli_fc_process_link_attention(struct sli4 *sli4, void *acqe)\n{\n\tstruct sli4_link_attention *link_attn = acqe;\n\tstruct sli4_link_event event = { 0 };\n\n\tefc_log_info(sli4, \"link=%d attn_type=%#x top=%#x speed=%#x pfault=%#x\\n\",\n\t\t     link_attn->link_number, link_attn->attn_type,\n\t\t     link_attn->topology, link_attn->port_speed,\n\t\t     link_attn->port_fault);\n\tefc_log_info(sli4, \"shared_lnk_status=%#x logl_lnk_speed=%#x evttag=%#x\\n\",\n\t\t     link_attn->shared_link_status,\n\t\t     le16_to_cpu(link_attn->logical_link_speed),\n\t\t     le32_to_cpu(link_attn->event_tag));\n\n\tif (!sli4->link)\n\t\treturn -EIO;\n\n\tevent.medium   = SLI4_LINK_MEDIUM_FC;\n\n\tswitch (link_attn->attn_type) {\n\tcase SLI4_LNK_ATTN_TYPE_LINK_UP:\n\t\tevent.status = SLI4_LINK_STATUS_UP;\n\t\tbreak;\n\tcase SLI4_LNK_ATTN_TYPE_LINK_DOWN:\n\t\tevent.status = SLI4_LINK_STATUS_DOWN;\n\t\tbreak;\n\tcase SLI4_LNK_ATTN_TYPE_NO_HARD_ALPA:\n\t\tefc_log_info(sli4, \"attn_type: no hard alpa\\n\");\n\t\tevent.status = SLI4_LINK_STATUS_NO_ALPA;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"attn_type: unknown\\n\");\n\t\tbreak;\n\t}\n\n\tswitch (link_attn->event_type) {\n\tcase SLI4_EVENT_LINK_ATTENTION:\n\t\tbreak;\n\tcase SLI4_EVENT_SHARED_LINK_ATTENTION:\n\t\tefc_log_info(sli4, \"event_type: FC shared link event\\n\");\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"event_type: unknown\\n\");\n\t\tbreak;\n\t}\n\n\tswitch (link_attn->topology) {\n\tcase SLI4_LNK_ATTN_P2P:\n\t\tevent.topology = SLI4_LINK_TOPO_NON_FC_AL;\n\t\tbreak;\n\tcase SLI4_LNK_ATTN_FC_AL:\n\t\tevent.topology = SLI4_LINK_TOPO_FC_AL;\n\t\tbreak;\n\tcase SLI4_LNK_ATTN_INTERNAL_LOOPBACK:\n\t\tefc_log_info(sli4, \"topology Internal loopback\\n\");\n\t\tevent.topology = SLI4_LINK_TOPO_LOOPBACK_INTERNAL;\n\t\tbreak;\n\tcase SLI4_LNK_ATTN_SERDES_LOOPBACK:\n\t\tefc_log_info(sli4, \"topology serdes loopback\\n\");\n\t\tevent.topology = SLI4_LINK_TOPO_LOOPBACK_EXTERNAL;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"topology: unknown\\n\");\n\t\tbreak;\n\t}\n\n\tevent.speed = link_attn->port_speed * 1000;\n\n\tsli4->link(sli4->link_arg, (void *)&event);\n\n\treturn 0;\n}\n\nint\nsli_fc_cqe_parse(struct sli4 *sli4, struct sli4_queue *cq,\n\t\t u8 *cqe, enum sli4_qentry *etype, u16 *r_id)\n{\n\tu8 code = cqe[SLI4_CQE_CODE_OFFSET];\n\tint rc;\n\n\tswitch (code) {\n\tcase SLI4_CQE_CODE_WORK_REQUEST_COMPLETION:\n\t{\n\t\tstruct sli4_fc_wcqe *wcqe = (void *)cqe;\n\n\t\t*etype = SLI4_QENTRY_WQ;\n\t\t*r_id = le16_to_cpu(wcqe->request_tag);\n\t\trc = wcqe->status;\n\n\t\t \n\t\tif (rc && rc != SLI4_FC_WCQE_STATUS_FCP_RSP_FAILURE) {\n\t\t\tefc_log_info(sli4, \"WCQE: status=%#x hw_status=%#x tag=%#x\\n\",\n\t\t\t\t     wcqe->status, wcqe->hw_status,\n\t\t\t\t     le16_to_cpu(wcqe->request_tag));\n\t\t\tefc_log_info(sli4, \"w1=%#x w2=%#x xb=%d\\n\",\n\t\t\t\t     le32_to_cpu(wcqe->wqe_specific_1),\n\t\t\t\t     le32_to_cpu(wcqe->wqe_specific_2),\n\t\t\t\t     (wcqe->flags & SLI4_WCQE_XB));\n\t\t\tefc_log_info(sli4, \"      %08X %08X %08X %08X\\n\",\n\t\t\t\t     ((u32 *)cqe)[0], ((u32 *)cqe)[1],\n\t\t\t\t     ((u32 *)cqe)[2], ((u32 *)cqe)[3]);\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase SLI4_CQE_CODE_RQ_ASYNC:\n\t{\n\t\tstruct sli4_fc_async_rcqe *rcqe = (void *)cqe;\n\n\t\t*etype = SLI4_QENTRY_RQ;\n\t\t*r_id = le16_to_cpu(rcqe->fcfi_rq_id_word) & SLI4_RACQE_RQ_ID;\n\t\trc = rcqe->status;\n\t\tbreak;\n\t}\n\tcase SLI4_CQE_CODE_RQ_ASYNC_V1:\n\t{\n\t\tstruct sli4_fc_async_rcqe_v1 *rcqe = (void *)cqe;\n\n\t\t*etype = SLI4_QENTRY_RQ;\n\t\t*r_id = le16_to_cpu(rcqe->rq_id);\n\t\trc = rcqe->status;\n\t\tbreak;\n\t}\n\tcase SLI4_CQE_CODE_OPTIMIZED_WRITE_CMD:\n\t{\n\t\tstruct sli4_fc_optimized_write_cmd_cqe *optcqe = (void *)cqe;\n\n\t\t*etype = SLI4_QENTRY_OPT_WRITE_CMD;\n\t\t*r_id = le16_to_cpu(optcqe->rq_id);\n\t\trc = optcqe->status;\n\t\tbreak;\n\t}\n\tcase SLI4_CQE_CODE_OPTIMIZED_WRITE_DATA:\n\t{\n\t\tstruct sli4_fc_optimized_write_data_cqe *dcqe = (void *)cqe;\n\n\t\t*etype = SLI4_QENTRY_OPT_WRITE_DATA;\n\t\t*r_id = le16_to_cpu(dcqe->xri);\n\t\trc = dcqe->status;\n\n\t\t \n\t\tif (rc != SLI4_FC_WCQE_STATUS_SUCCESS) {\n\t\t\tefc_log_info(sli4, \"Optimized DATA CQE: status=%#x\\n\",\n\t\t\t\t     dcqe->status);\n\t\t\tefc_log_info(sli4, \"hstat=%#x xri=%#x dpl=%#x w3=%#x xb=%d\\n\",\n\t\t\t\t     dcqe->hw_status, le16_to_cpu(dcqe->xri),\n\t\t\t\t     le32_to_cpu(dcqe->total_data_placed),\n\t\t\t\t     ((u32 *)cqe)[3],\n\t\t\t\t     (dcqe->flags & SLI4_OCQE_XB));\n\t\t}\n\t\tbreak;\n\t}\n\tcase SLI4_CQE_CODE_RQ_COALESCING:\n\t{\n\t\tstruct sli4_fc_coalescing_rcqe *rcqe = (void *)cqe;\n\n\t\t*etype = SLI4_QENTRY_RQ;\n\t\t*r_id = le16_to_cpu(rcqe->rq_id);\n\t\trc = rcqe->status;\n\t\tbreak;\n\t}\n\tcase SLI4_CQE_CODE_XRI_ABORTED:\n\t{\n\t\tstruct sli4_fc_xri_aborted_cqe *xa = (void *)cqe;\n\n\t\t*etype = SLI4_QENTRY_XABT;\n\t\t*r_id = le16_to_cpu(xa->xri);\n\t\trc = 0;\n\t\tbreak;\n\t}\n\tcase SLI4_CQE_CODE_RELEASE_WQE:\n\t{\n\t\tstruct sli4_fc_wqec *wqec = (void *)cqe;\n\n\t\t*etype = SLI4_QENTRY_WQ_RELEASE;\n\t\t*r_id = le16_to_cpu(wqec->wq_id);\n\t\trc = 0;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tefc_log_info(sli4, \"CQE completion code %d not handled\\n\",\n\t\t\t     code);\n\t\t*etype = SLI4_QENTRY_MAX;\n\t\t*r_id = U16_MAX;\n\t\trc = -EINVAL;\n\t}\n\n\treturn rc;\n}\n\nu32\nsli_fc_response_length(struct sli4 *sli4, u8 *cqe)\n{\n\tstruct sli4_fc_wcqe *wcqe = (void *)cqe;\n\n\treturn le32_to_cpu(wcqe->wqe_specific_1);\n}\n\nu32\nsli_fc_io_length(struct sli4 *sli4, u8 *cqe)\n{\n\tstruct sli4_fc_wcqe *wcqe = (void *)cqe;\n\n\treturn le32_to_cpu(wcqe->wqe_specific_1);\n}\n\nint\nsli_fc_els_did(struct sli4 *sli4, u8 *cqe, u32 *d_id)\n{\n\tstruct sli4_fc_wcqe *wcqe = (void *)cqe;\n\n\t*d_id = 0;\n\n\tif (wcqe->status)\n\t\treturn -EIO;\n\t*d_id = le32_to_cpu(wcqe->wqe_specific_2) & 0x00ffffff;\n\treturn 0;\n}\n\nu32\nsli_fc_ext_status(struct sli4 *sli4, u8 *cqe)\n{\n\tstruct sli4_fc_wcqe *wcqe = (void *)cqe;\n\tu32\tmask;\n\n\tswitch (wcqe->status) {\n\tcase SLI4_FC_WCQE_STATUS_FCP_RSP_FAILURE:\n\t\tmask = U32_MAX;\n\t\tbreak;\n\tcase SLI4_FC_WCQE_STATUS_LOCAL_REJECT:\n\tcase SLI4_FC_WCQE_STATUS_CMD_REJECT:\n\t\tmask = 0xff;\n\t\tbreak;\n\tcase SLI4_FC_WCQE_STATUS_NPORT_RJT:\n\tcase SLI4_FC_WCQE_STATUS_FABRIC_RJT:\n\tcase SLI4_FC_WCQE_STATUS_NPORT_BSY:\n\tcase SLI4_FC_WCQE_STATUS_FABRIC_BSY:\n\tcase SLI4_FC_WCQE_STATUS_LS_RJT:\n\t\tmask = U32_MAX;\n\t\tbreak;\n\tcase SLI4_FC_WCQE_STATUS_DI_ERROR:\n\t\tmask = U32_MAX;\n\t\tbreak;\n\tdefault:\n\t\tmask = 0;\n\t}\n\n\treturn le32_to_cpu(wcqe->wqe_specific_2) & mask;\n}\n\nint\nsli_fc_rqe_rqid_and_index(struct sli4 *sli4, u8 *cqe, u16 *rq_id, u32 *index)\n{\n\tint rc = -EIO;\n\tu8 code = 0;\n\tu16 rq_element_index;\n\n\t*rq_id = 0;\n\t*index = U32_MAX;\n\n\tcode = cqe[SLI4_CQE_CODE_OFFSET];\n\n\t \n\tif (code == SLI4_CQE_CODE_RQ_ASYNC) {\n\t\tstruct sli4_fc_async_rcqe *rcqe = (void *)cqe;\n\n\t\t*rq_id = le16_to_cpu(rcqe->fcfi_rq_id_word) & SLI4_RACQE_RQ_ID;\n\t\trq_element_index =\n\t\tle16_to_cpu(rcqe->rq_elmt_indx_word) & SLI4_RACQE_RQ_EL_INDX;\n\t\t*index = rq_element_index;\n\t\tif (rcqe->status == SLI4_FC_ASYNC_RQ_SUCCESS) {\n\t\t\trc = 0;\n\t\t} else {\n\t\t\trc = rcqe->status;\n\t\t\tefc_log_info(sli4, \"status=%02x (%s) rq_id=%d\\n\",\n\t\t\t\t     rcqe->status,\n\t\t\t\t     sli_fc_get_status_string(rcqe->status),\n\t\t\t\t     le16_to_cpu(rcqe->fcfi_rq_id_word) &\n\t\t\t\t     SLI4_RACQE_RQ_ID);\n\n\t\t\tefc_log_info(sli4, \"pdpl=%x sof=%02x eof=%02x hdpl=%x\\n\",\n\t\t\t\t     le16_to_cpu(rcqe->data_placement_length),\n\t\t\t\t     rcqe->sof_byte, rcqe->eof_byte,\n\t\t\t\t     rcqe->hdpl_byte & SLI4_RACQE_HDPL);\n\t\t}\n\t} else if (code == SLI4_CQE_CODE_RQ_ASYNC_V1) {\n\t\tstruct sli4_fc_async_rcqe_v1 *rcqe_v1 = (void *)cqe;\n\n\t\t*rq_id = le16_to_cpu(rcqe_v1->rq_id);\n\t\trq_element_index =\n\t\t\t(le16_to_cpu(rcqe_v1->rq_elmt_indx_word) &\n\t\t\t SLI4_RACQE_RQ_EL_INDX);\n\t\t*index = rq_element_index;\n\t\tif (rcqe_v1->status == SLI4_FC_ASYNC_RQ_SUCCESS) {\n\t\t\trc = 0;\n\t\t} else {\n\t\t\trc = rcqe_v1->status;\n\t\t\tefc_log_info(sli4, \"status=%02x (%s) rq_id=%d, index=%x\\n\",\n\t\t\t\t     rcqe_v1->status,\n\t\t\t\t     sli_fc_get_status_string(rcqe_v1->status),\n\t\t\t\t     le16_to_cpu(rcqe_v1->rq_id), rq_element_index);\n\n\t\t\tefc_log_info(sli4, \"pdpl=%x sof=%02x eof=%02x hdpl=%x\\n\",\n\t\t\t\t     le16_to_cpu(rcqe_v1->data_placement_length),\n\t\t\trcqe_v1->sof_byte, rcqe_v1->eof_byte,\n\t\t\trcqe_v1->hdpl_byte & SLI4_RACQE_HDPL);\n\t\t}\n\t} else if (code == SLI4_CQE_CODE_OPTIMIZED_WRITE_CMD) {\n\t\tstruct sli4_fc_optimized_write_cmd_cqe *optcqe = (void *)cqe;\n\n\t\t*rq_id = le16_to_cpu(optcqe->rq_id);\n\t\t*index = le16_to_cpu(optcqe->w1) & SLI4_OCQE_RQ_EL_INDX;\n\t\tif (optcqe->status == SLI4_FC_ASYNC_RQ_SUCCESS) {\n\t\t\trc = 0;\n\t\t} else {\n\t\t\trc = optcqe->status;\n\t\t\tefc_log_info(sli4, \"stat=%02x (%s) rqid=%d, idx=%x pdpl=%x\\n\",\n\t\t\t\t     optcqe->status,\n\t\t\t\t     sli_fc_get_status_string(optcqe->status),\n\t\t\t\t     le16_to_cpu(optcqe->rq_id), *index,\n\t\t\t\t     le16_to_cpu(optcqe->data_placement_length));\n\n\t\t\tefc_log_info(sli4, \"hdpl=%x oox=%d agxr=%d xri=0x%x rpi=%x\\n\",\n\t\t\t\t     (optcqe->hdpl_vld & SLI4_OCQE_HDPL),\n\t\t\t\t     (optcqe->flags1 & SLI4_OCQE_OOX),\n\t\t\t\t     (optcqe->flags1 & SLI4_OCQE_AGXR),\n\t\t\t\t     optcqe->xri, le16_to_cpu(optcqe->rpi));\n\t\t}\n\t} else if (code == SLI4_CQE_CODE_RQ_COALESCING) {\n\t\tstruct sli4_fc_coalescing_rcqe  *rcqe = (void *)cqe;\n\n\t\trq_element_index = (le16_to_cpu(rcqe->rq_elmt_indx_word) &\n\t\t\t\t    SLI4_RCQE_RQ_EL_INDX);\n\n\t\t*rq_id = le16_to_cpu(rcqe->rq_id);\n\t\tif (rcqe->status == SLI4_FC_COALESCE_RQ_SUCCESS) {\n\t\t\t*index = rq_element_index;\n\t\t\trc = 0;\n\t\t} else {\n\t\t\t*index = U32_MAX;\n\t\t\trc = rcqe->status;\n\n\t\t\tefc_log_info(sli4, \"stat=%02x (%s) rq_id=%d, idx=%x\\n\",\n\t\t\t\t     rcqe->status,\n\t\t\t\t     sli_fc_get_status_string(rcqe->status),\n\t\t\t\t     le16_to_cpu(rcqe->rq_id), rq_element_index);\n\t\t\tefc_log_info(sli4, \"rq_id=%#x sdpl=%x\\n\",\n\t\t\t\t     le16_to_cpu(rcqe->rq_id),\n\t\t\t\t     le16_to_cpu(rcqe->seq_placement_length));\n\t\t}\n\t} else {\n\t\tstruct sli4_fc_async_rcqe *rcqe = (void *)cqe;\n\n\t\t*index = U32_MAX;\n\t\trc = rcqe->status;\n\n\t\tefc_log_info(sli4, \"status=%02x rq_id=%d, index=%x pdpl=%x\\n\",\n\t\t\t     rcqe->status,\n\t\t\t     le16_to_cpu(rcqe->fcfi_rq_id_word) & SLI4_RACQE_RQ_ID,\n\t\t\t     (le16_to_cpu(rcqe->rq_elmt_indx_word) & SLI4_RACQE_RQ_EL_INDX),\n\t\t\t     le16_to_cpu(rcqe->data_placement_length));\n\t\tefc_log_info(sli4, \"sof=%02x eof=%02x hdpl=%x\\n\",\n\t\t\t     rcqe->sof_byte, rcqe->eof_byte,\n\t\t\t     rcqe->hdpl_byte & SLI4_RACQE_HDPL);\n\t}\n\n\treturn rc;\n}\n\nstatic int\nsli_bmbx_wait(struct sli4 *sli4, u32 msec)\n{\n\tu32 val;\n\tunsigned long end;\n\n\t \n\tend = jiffies + msecs_to_jiffies(msec);\n\tdo {\n\t\tval = readl(sli4->reg[0] + SLI4_BMBX_REG);\n\t\tif (val & SLI4_BMBX_RDY)\n\t\t\treturn 0;\n\n\t\tusleep_range(1000, 2000);\n\t} while (time_before(jiffies, end));\n\n\treturn -EIO;\n}\n\nstatic int\nsli_bmbx_write(struct sli4 *sli4)\n{\n\tu32 val;\n\n\t \n\tval = sli_bmbx_write_hi(sli4->bmbx.phys);\n\twritel(val, (sli4->reg[0] + SLI4_BMBX_REG));\n\n\tif (sli_bmbx_wait(sli4, SLI4_BMBX_DELAY_US)) {\n\t\tefc_log_crit(sli4, \"BMBX WRITE_HI failed\\n\");\n\t\treturn -EIO;\n\t}\n\tval = sli_bmbx_write_lo(sli4->bmbx.phys);\n\twritel(val, (sli4->reg[0] + SLI4_BMBX_REG));\n\n\t \n\treturn sli_bmbx_wait(sli4, SLI4_BMBX_TIMEOUT_MSEC);\n}\n\nint\nsli_bmbx_command(struct sli4 *sli4)\n{\n\tvoid *cqe = (u8 *)sli4->bmbx.virt + SLI4_BMBX_SIZE;\n\n\tif (sli_fw_error_status(sli4) > 0) {\n\t\tefc_log_crit(sli4, \"Chip is in an error state -Mailbox command rejected\");\n\t\tefc_log_crit(sli4, \" status=%#x error1=%#x error2=%#x\\n\",\n\t\t\t     sli_reg_read_status(sli4),\n\t\t\t     sli_reg_read_err1(sli4),\n\t\t\t     sli_reg_read_err2(sli4));\n\t\treturn -EIO;\n\t}\n\n\t \n\tif (sli_bmbx_write(sli4)) {\n\t\tefc_log_crit(sli4, \"bmbx write fail phys=%pad reg=%#x\\n\",\n\t\t\t     &sli4->bmbx.phys, readl(sli4->reg[0] + SLI4_BMBX_REG));\n\t\treturn -EIO;\n\t}\n\n\t \n\tif (le32_to_cpu(((struct sli4_mcqe *)cqe)->dw3_flags) &\n\t    SLI4_MCQE_VALID) {\n\t\treturn sli_cqe_mq(sli4, cqe);\n\t}\n\tefc_log_crit(sli4, \"invalid or wrong type\\n\");\n\treturn -EIO;\n}\n\nint\nsli_cmd_config_link(struct sli4 *sli4, void *buf)\n{\n\tstruct sli4_cmd_config_link *config_link = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tconfig_link->hdr.command = SLI4_MBX_CMD_CONFIG_LINK;\n\n\t \n\n\treturn 0;\n}\n\nint\nsli_cmd_down_link(struct sli4 *sli4, void *buf)\n{\n\tstruct sli4_mbox_command_header *hdr = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\thdr->command = SLI4_MBX_CMD_DOWN_LINK;\n\n\t \n\n\treturn 0;\n}\n\nint\nsli_cmd_dump_type4(struct sli4 *sli4, void *buf, u16 wki)\n{\n\tstruct sli4_cmd_dump4 *cmd = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tcmd->hdr.command = SLI4_MBX_CMD_DUMP;\n\tcmd->type_dword = cpu_to_le32(0x4);\n\tcmd->wki_selection = cpu_to_le16(wki);\n\treturn 0;\n}\n\nint\nsli_cmd_common_read_transceiver_data(struct sli4 *sli4, void *buf, u32 page_num,\n\t\t\t\t     struct efc_dma *dma)\n{\n\tstruct sli4_rqst_cmn_read_transceiver_data *req = NULL;\n\tu32 psize;\n\n\tif (!dma)\n\t\tpsize = SLI4_CFG_PYLD_LENGTH(cmn_read_transceiver_data);\n\telse\n\t\tpsize = dma->size;\n\n\treq = sli_config_cmd_init(sli4, buf, psize, dma);\n\tif (!req)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&req->hdr, SLI4_CMN_READ_TRANS_DATA,\n\t\t\t SLI4_SUBSYSTEM_COMMON, CMD_V0,\n\t\t\t SLI4_RQST_PYLD_LEN(cmn_read_transceiver_data));\n\n\treq->page_number = cpu_to_le32(page_num);\n\treq->port = cpu_to_le32(sli4->port_number);\n\n\treturn 0;\n}\n\nint\nsli_cmd_read_link_stats(struct sli4 *sli4, void *buf, u8 req_ext_counters,\n\t\t\tu8 clear_overflow_flags,\n\t\t\tu8 clear_all_counters)\n{\n\tstruct sli4_cmd_read_link_stats *cmd = buf;\n\tu32 flags;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tcmd->hdr.command = SLI4_MBX_CMD_READ_LNK_STAT;\n\n\tflags = 0;\n\tif (req_ext_counters)\n\t\tflags |= SLI4_READ_LNKSTAT_REC;\n\tif (clear_all_counters)\n\t\tflags |= SLI4_READ_LNKSTAT_CLRC;\n\tif (clear_overflow_flags)\n\t\tflags |= SLI4_READ_LNKSTAT_CLOF;\n\n\tcmd->dw1_flags = cpu_to_le32(flags);\n\treturn 0;\n}\n\nint\nsli_cmd_read_status(struct sli4 *sli4, void *buf, u8 clear_counters)\n{\n\tstruct sli4_cmd_read_status *cmd = buf;\n\tu32 flags = 0;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tcmd->hdr.command = SLI4_MBX_CMD_READ_STATUS;\n\tif (clear_counters)\n\t\tflags |= SLI4_READSTATUS_CLEAR_COUNTERS;\n\telse\n\t\tflags &= ~SLI4_READSTATUS_CLEAR_COUNTERS;\n\n\tcmd->dw1_flags = cpu_to_le32(flags);\n\treturn 0;\n}\n\nint\nsli_cmd_init_link(struct sli4 *sli4, void *buf, u32 speed, u8 reset_alpa)\n{\n\tstruct sli4_cmd_init_link *init_link = buf;\n\tu32 flags = 0;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tinit_link->hdr.command = SLI4_MBX_CMD_INIT_LINK;\n\n\tinit_link->sel_reset_al_pa_dword =\n\t\t\t\tcpu_to_le32(reset_alpa);\n\tflags &= ~SLI4_INIT_LINK_F_LOOPBACK;\n\n\tinit_link->link_speed_sel_code = cpu_to_le32(speed);\n\tswitch (speed) {\n\tcase SLI4_LINK_SPEED_1G:\n\tcase SLI4_LINK_SPEED_2G:\n\tcase SLI4_LINK_SPEED_4G:\n\tcase SLI4_LINK_SPEED_8G:\n\tcase SLI4_LINK_SPEED_16G:\n\tcase SLI4_LINK_SPEED_32G:\n\tcase SLI4_LINK_SPEED_64G:\n\t\tflags |= SLI4_INIT_LINK_F_FIXED_SPEED;\n\t\tbreak;\n\tcase SLI4_LINK_SPEED_10G:\n\t\tefc_log_info(sli4, \"unsupported FC speed %d\\n\", speed);\n\t\tinit_link->flags0 = cpu_to_le32(flags);\n\t\treturn -EIO;\n\t}\n\n\tswitch (sli4->topology) {\n\tcase SLI4_READ_CFG_TOPO_FC:\n\t\t \n\t\tflags |= SLI4_INIT_LINK_F_FAIL_OVER;\n\t\tflags |= SLI4_INIT_LINK_F_P2P_FAIL_OVER;\n\t\tbreak;\n\tcase SLI4_READ_CFG_TOPO_FC_AL:\n\t\tflags |= SLI4_INIT_LINK_F_FCAL_ONLY;\n\t\tif (speed == SLI4_LINK_SPEED_16G ||\n\t\t    speed == SLI4_LINK_SPEED_32G) {\n\t\t\tefc_log_info(sli4, \"unsupported FC-AL speed %d\\n\",\n\t\t\t\t     speed);\n\t\t\tinit_link->flags0 = cpu_to_le32(flags);\n\t\t\treturn -EIO;\n\t\t}\n\t\tbreak;\n\tcase SLI4_READ_CFG_TOPO_NON_FC_AL:\n\t\tflags |= SLI4_INIT_LINK_F_P2P_ONLY;\n\t\tbreak;\n\tdefault:\n\n\t\tefc_log_info(sli4, \"unsupported topology %#x\\n\", sli4->topology);\n\n\t\tinit_link->flags0 = cpu_to_le32(flags);\n\t\treturn -EIO;\n\t}\n\n\tflags &= ~SLI4_INIT_LINK_F_UNFAIR;\n\tflags &= ~SLI4_INIT_LINK_F_NO_LIRP;\n\tflags &= ~SLI4_INIT_LINK_F_LOOP_VALID_CHK;\n\tflags &= ~SLI4_INIT_LINK_F_NO_LISA;\n\tflags &= ~SLI4_INIT_LINK_F_PICK_HI_ALPA;\n\tinit_link->flags0 = cpu_to_le32(flags);\n\n\treturn 0;\n}\n\nint\nsli_cmd_init_vfi(struct sli4 *sli4, void *buf, u16 vfi, u16 fcfi, u16 vpi)\n{\n\tstruct sli4_cmd_init_vfi *init_vfi = buf;\n\tu16 flags = 0;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tinit_vfi->hdr.command = SLI4_MBX_CMD_INIT_VFI;\n\tinit_vfi->vfi = cpu_to_le16(vfi);\n\tinit_vfi->fcfi = cpu_to_le16(fcfi);\n\n\t \n\tif (vpi != U16_MAX) {\n\t\tflags |= SLI4_INIT_VFI_FLAG_VP;\n\t\tinit_vfi->flags0_word = cpu_to_le16(flags);\n\t\tinit_vfi->vpi = cpu_to_le16(vpi);\n\t}\n\n\treturn 0;\n}\n\nint\nsli_cmd_init_vpi(struct sli4 *sli4, void *buf, u16 vpi, u16 vfi)\n{\n\tstruct sli4_cmd_init_vpi *init_vpi = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tinit_vpi->hdr.command = SLI4_MBX_CMD_INIT_VPI;\n\tinit_vpi->vpi = cpu_to_le16(vpi);\n\tinit_vpi->vfi = cpu_to_le16(vfi);\n\n\treturn 0;\n}\n\nint\nsli_cmd_post_xri(struct sli4 *sli4, void *buf, u16 xri_base, u16 xri_count)\n{\n\tstruct sli4_cmd_post_xri *post_xri = buf;\n\tu16 xri_count_flags = 0;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tpost_xri->hdr.command = SLI4_MBX_CMD_POST_XRI;\n\tpost_xri->xri_base = cpu_to_le16(xri_base);\n\txri_count_flags = xri_count & SLI4_POST_XRI_COUNT;\n\txri_count_flags |= SLI4_POST_XRI_FLAG_ENX;\n\txri_count_flags |= SLI4_POST_XRI_FLAG_VAL;\n\tpost_xri->xri_count_flags = cpu_to_le16(xri_count_flags);\n\n\treturn 0;\n}\n\nint\nsli_cmd_release_xri(struct sli4 *sli4, void *buf, u8 num_xri)\n{\n\tstruct sli4_cmd_release_xri *release_xri = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\trelease_xri->hdr.command = SLI4_MBX_CMD_RELEASE_XRI;\n\trelease_xri->xri_count_word = cpu_to_le16(num_xri &\n\t\t\t\t\tSLI4_RELEASE_XRI_COUNT);\n\n\treturn 0;\n}\n\nstatic int\nsli_cmd_read_config(struct sli4 *sli4, void *buf)\n{\n\tstruct sli4_cmd_read_config *read_config = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tread_config->hdr.command = SLI4_MBX_CMD_READ_CONFIG;\n\n\treturn 0;\n}\n\nint\nsli_cmd_read_nvparms(struct sli4 *sli4, void *buf)\n{\n\tstruct sli4_cmd_read_nvparms *read_nvparms = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tread_nvparms->hdr.command = SLI4_MBX_CMD_READ_NVPARMS;\n\n\treturn 0;\n}\n\nint\nsli_cmd_write_nvparms(struct sli4 *sli4, void *buf, u8 *wwpn, u8 *wwnn,\n\t\t      u8 hard_alpa, u32 preferred_d_id)\n{\n\tstruct sli4_cmd_write_nvparms *write_nvparms = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\twrite_nvparms->hdr.command = SLI4_MBX_CMD_WRITE_NVPARMS;\n\tmemcpy(write_nvparms->wwpn, wwpn, 8);\n\tmemcpy(write_nvparms->wwnn, wwnn, 8);\n\n\twrite_nvparms->hard_alpa_d_id =\n\t\t\tcpu_to_le32((preferred_d_id << 8) | hard_alpa);\n\treturn 0;\n}\n\nstatic int\nsli_cmd_read_rev(struct sli4 *sli4, void *buf, struct efc_dma *vpd)\n{\n\tstruct sli4_cmd_read_rev *read_rev = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tread_rev->hdr.command = SLI4_MBX_CMD_READ_REV;\n\n\tif (vpd && vpd->size) {\n\t\tread_rev->flags0_word |= cpu_to_le16(SLI4_READ_REV_FLAG_VPD);\n\n\t\tread_rev->available_length_dword =\n\t\t\tcpu_to_le32(vpd->size &\n\t\t\t\t    SLI4_READ_REV_AVAILABLE_LENGTH);\n\n\t\tread_rev->hostbuf.low =\n\t\t\t\tcpu_to_le32(lower_32_bits(vpd->phys));\n\t\tread_rev->hostbuf.high =\n\t\t\t\tcpu_to_le32(upper_32_bits(vpd->phys));\n\t}\n\n\treturn 0;\n}\n\nint\nsli_cmd_read_sparm64(struct sli4 *sli4, void *buf, struct efc_dma *dma, u16 vpi)\n{\n\tstruct sli4_cmd_read_sparm64 *read_sparm64 = buf;\n\n\tif (vpi == U16_MAX) {\n\t\tefc_log_err(sli4, \"special VPI not supported!!!\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (!dma || !dma->phys) {\n\t\tefc_log_err(sli4, \"bad DMA buffer\\n\");\n\t\treturn -EIO;\n\t}\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tread_sparm64->hdr.command = SLI4_MBX_CMD_READ_SPARM64;\n\n\tread_sparm64->bde_64.bde_type_buflen =\n\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t    (dma->size & SLI4_BDE_LEN_MASK));\n\tread_sparm64->bde_64.u.data.low =\n\t\t\tcpu_to_le32(lower_32_bits(dma->phys));\n\tread_sparm64->bde_64.u.data.high =\n\t\t\tcpu_to_le32(upper_32_bits(dma->phys));\n\n\tread_sparm64->vpi = cpu_to_le16(vpi);\n\n\treturn 0;\n}\n\nint\nsli_cmd_read_topology(struct sli4 *sli4, void *buf, struct efc_dma *dma)\n{\n\tstruct sli4_cmd_read_topology *read_topo = buf;\n\n\tif (!dma || !dma->size)\n\t\treturn -EIO;\n\n\tif (dma->size < SLI4_MIN_LOOP_MAP_BYTES) {\n\t\tefc_log_err(sli4, \"loop map buffer too small %zx\\n\", dma->size);\n\t\treturn -EIO;\n\t}\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tread_topo->hdr.command = SLI4_MBX_CMD_READ_TOPOLOGY;\n\n\tmemset(dma->virt, 0, dma->size);\n\n\tread_topo->bde_loop_map.bde_type_buflen =\n\t\t\t\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t\t\t(dma->size & SLI4_BDE_LEN_MASK));\n\tread_topo->bde_loop_map.u.data.low  =\n\t\t\t\tcpu_to_le32(lower_32_bits(dma->phys));\n\tread_topo->bde_loop_map.u.data.high =\n\t\t\t\tcpu_to_le32(upper_32_bits(dma->phys));\n\n\treturn 0;\n}\n\nint\nsli_cmd_reg_fcfi(struct sli4 *sli4, void *buf, u16 index,\n\t\t struct sli4_cmd_rq_cfg *rq_cfg)\n{\n\tstruct sli4_cmd_reg_fcfi *reg_fcfi = buf;\n\tu32 i;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\treg_fcfi->hdr.command = SLI4_MBX_CMD_REG_FCFI;\n\n\treg_fcfi->fcf_index = cpu_to_le16(index);\n\n\tfor (i = 0; i < SLI4_CMD_REG_FCFI_NUM_RQ_CFG; i++) {\n\t\tswitch (i) {\n\t\tcase 0:\n\t\t\treg_fcfi->rqid0 = rq_cfg[0].rq_id;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\treg_fcfi->rqid1 = rq_cfg[1].rq_id;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\treg_fcfi->rqid2 = rq_cfg[2].rq_id;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\treg_fcfi->rqid3 = rq_cfg[3].rq_id;\n\t\t\tbreak;\n\t\t}\n\t\treg_fcfi->rq_cfg[i].r_ctl_mask = rq_cfg[i].r_ctl_mask;\n\t\treg_fcfi->rq_cfg[i].r_ctl_match = rq_cfg[i].r_ctl_match;\n\t\treg_fcfi->rq_cfg[i].type_mask = rq_cfg[i].type_mask;\n\t\treg_fcfi->rq_cfg[i].type_match = rq_cfg[i].type_match;\n\t}\n\n\treturn 0;\n}\n\nint\nsli_cmd_reg_fcfi_mrq(struct sli4 *sli4, void *buf, u8 mode, u16 fcf_index,\n\t\t     u8 rq_selection_policy, u8 mrq_bit_mask, u16 num_mrqs,\n\t\t     struct sli4_cmd_rq_cfg *rq_cfg)\n{\n\tstruct sli4_cmd_reg_fcfi_mrq *reg_fcfi_mrq = buf;\n\tu32 i;\n\tu32 mrq_flags = 0;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\treg_fcfi_mrq->hdr.command = SLI4_MBX_CMD_REG_FCFI_MRQ;\n\tif (mode == SLI4_CMD_REG_FCFI_SET_FCFI_MODE) {\n\t\treg_fcfi_mrq->fcf_index = cpu_to_le16(fcf_index);\n\t\tgoto done;\n\t}\n\n\treg_fcfi_mrq->dw8_vlan = cpu_to_le32(SLI4_REGFCFI_MRQ_MODE);\n\n\tfor (i = 0; i < SLI4_CMD_REG_FCFI_NUM_RQ_CFG; i++) {\n\t\treg_fcfi_mrq->rq_cfg[i].r_ctl_mask = rq_cfg[i].r_ctl_mask;\n\t\treg_fcfi_mrq->rq_cfg[i].r_ctl_match = rq_cfg[i].r_ctl_match;\n\t\treg_fcfi_mrq->rq_cfg[i].type_mask = rq_cfg[i].type_mask;\n\t\treg_fcfi_mrq->rq_cfg[i].type_match = rq_cfg[i].type_match;\n\n\t\tswitch (i) {\n\t\tcase 3:\n\t\t\treg_fcfi_mrq->rqid3 = rq_cfg[i].rq_id;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\treg_fcfi_mrq->rqid2 = rq_cfg[i].rq_id;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\treg_fcfi_mrq->rqid1 = rq_cfg[i].rq_id;\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\treg_fcfi_mrq->rqid0 = rq_cfg[i].rq_id;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmrq_flags = num_mrqs & SLI4_REGFCFI_MRQ_MASK_NUM_PAIRS;\n\tmrq_flags |= (mrq_bit_mask << 8);\n\tmrq_flags |= (rq_selection_policy << 12);\n\treg_fcfi_mrq->dw9_mrqflags = cpu_to_le32(mrq_flags);\ndone:\n\treturn 0;\n}\n\nint\nsli_cmd_reg_rpi(struct sli4 *sli4, void *buf, u32 rpi, u32 vpi, u32 fc_id,\n\t\tstruct efc_dma *dma, u8 update, u8 enable_t10_pi)\n{\n\tstruct sli4_cmd_reg_rpi *reg_rpi = buf;\n\tu32 rportid_flags = 0;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\treg_rpi->hdr.command = SLI4_MBX_CMD_REG_RPI;\n\n\treg_rpi->rpi = cpu_to_le16(rpi);\n\n\trportid_flags = fc_id & SLI4_REGRPI_REMOTE_N_PORTID;\n\n\tif (update)\n\t\trportid_flags |= SLI4_REGRPI_UPD;\n\telse\n\t\trportid_flags &= ~SLI4_REGRPI_UPD;\n\n\tif (enable_t10_pi)\n\t\trportid_flags |= SLI4_REGRPI_ETOW;\n\telse\n\t\trportid_flags &= ~SLI4_REGRPI_ETOW;\n\n\treg_rpi->dw2_rportid_flags = cpu_to_le32(rportid_flags);\n\n\treg_rpi->bde_64.bde_type_buflen =\n\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t    (SLI4_REG_RPI_BUF_LEN & SLI4_BDE_LEN_MASK));\n\treg_rpi->bde_64.u.data.low  =\n\t\tcpu_to_le32(lower_32_bits(dma->phys));\n\treg_rpi->bde_64.u.data.high =\n\t\tcpu_to_le32(upper_32_bits(dma->phys));\n\n\treg_rpi->vpi = cpu_to_le16(vpi);\n\n\treturn 0;\n}\n\nint\nsli_cmd_reg_vfi(struct sli4 *sli4, void *buf, size_t size,\n\t\tu16 vfi, u16 fcfi, struct efc_dma dma,\n\t\tu16 vpi, __be64 sli_wwpn, u32 fc_id)\n{\n\tstruct sli4_cmd_reg_vfi *reg_vfi = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\treg_vfi->hdr.command = SLI4_MBX_CMD_REG_VFI;\n\n\treg_vfi->vfi = cpu_to_le16(vfi);\n\n\treg_vfi->fcfi = cpu_to_le16(fcfi);\n\n\treg_vfi->sparm.bde_type_buflen =\n\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t    (SLI4_REG_RPI_BUF_LEN & SLI4_BDE_LEN_MASK));\n\treg_vfi->sparm.u.data.low  =\n\t\tcpu_to_le32(lower_32_bits(dma.phys));\n\treg_vfi->sparm.u.data.high =\n\t\tcpu_to_le32(upper_32_bits(dma.phys));\n\n\treg_vfi->e_d_tov = cpu_to_le32(sli4->e_d_tov);\n\treg_vfi->r_a_tov = cpu_to_le32(sli4->r_a_tov);\n\n\treg_vfi->dw0w1_flags |= cpu_to_le16(SLI4_REGVFI_VP);\n\treg_vfi->vpi = cpu_to_le16(vpi);\n\tmemcpy(reg_vfi->wwpn, &sli_wwpn, sizeof(reg_vfi->wwpn));\n\treg_vfi->dw10_lportid_flags = cpu_to_le32(fc_id);\n\n\treturn 0;\n}\n\nint\nsli_cmd_reg_vpi(struct sli4 *sli4, void *buf, u32 fc_id, __be64 sli_wwpn,\n\t\tu16 vpi, u16 vfi, bool update)\n{\n\tstruct sli4_cmd_reg_vpi *reg_vpi = buf;\n\tu32 flags = 0;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\treg_vpi->hdr.command = SLI4_MBX_CMD_REG_VPI;\n\n\tflags = (fc_id & SLI4_REGVPI_LOCAL_N_PORTID);\n\tif (update)\n\t\tflags |= SLI4_REGVPI_UPD;\n\telse\n\t\tflags &= ~SLI4_REGVPI_UPD;\n\n\treg_vpi->dw2_lportid_flags = cpu_to_le32(flags);\n\tmemcpy(reg_vpi->wwpn, &sli_wwpn, sizeof(reg_vpi->wwpn));\n\treg_vpi->vpi = cpu_to_le16(vpi);\n\treg_vpi->vfi = cpu_to_le16(vfi);\n\n\treturn 0;\n}\n\nstatic int\nsli_cmd_request_features(struct sli4 *sli4, void *buf, u32 features_mask,\n\t\t\t bool query)\n{\n\tstruct sli4_cmd_request_features *req_features = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\treq_features->hdr.command = SLI4_MBX_CMD_RQST_FEATURES;\n\n\tif (query)\n\t\treq_features->dw1_qry = cpu_to_le32(SLI4_REQFEAT_QRY);\n\n\treq_features->cmd = cpu_to_le32(features_mask);\n\n\treturn 0;\n}\n\nint\nsli_cmd_unreg_fcfi(struct sli4 *sli4, void *buf, u16 indicator)\n{\n\tstruct sli4_cmd_unreg_fcfi *unreg_fcfi = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tunreg_fcfi->hdr.command = SLI4_MBX_CMD_UNREG_FCFI;\n\tunreg_fcfi->fcfi = cpu_to_le16(indicator);\n\n\treturn 0;\n}\n\nint\nsli_cmd_unreg_rpi(struct sli4 *sli4, void *buf, u16 indicator,\n\t\t  enum sli4_resource which, u32 fc_id)\n{\n\tstruct sli4_cmd_unreg_rpi *unreg_rpi = buf;\n\tu32 flags = 0;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tunreg_rpi->hdr.command = SLI4_MBX_CMD_UNREG_RPI;\n\tswitch (which) {\n\tcase SLI4_RSRC_RPI:\n\t\tflags |= SLI4_UNREG_RPI_II_RPI;\n\t\tif (fc_id == U32_MAX)\n\t\t\tbreak;\n\n\t\tflags |= SLI4_UNREG_RPI_DP;\n\t\tunreg_rpi->dw2_dest_n_portid =\n\t\t\tcpu_to_le32(fc_id & SLI4_UNREG_RPI_DEST_N_PORTID_MASK);\n\t\tbreak;\n\tcase SLI4_RSRC_VPI:\n\t\tflags |= SLI4_UNREG_RPI_II_VPI;\n\t\tbreak;\n\tcase SLI4_RSRC_VFI:\n\t\tflags |= SLI4_UNREG_RPI_II_VFI;\n\t\tbreak;\n\tcase SLI4_RSRC_FCFI:\n\t\tflags |= SLI4_UNREG_RPI_II_FCFI;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"unknown type %#x\\n\", which);\n\t\treturn -EIO;\n\t}\n\n\tunreg_rpi->dw1w1_flags = cpu_to_le16(flags);\n\tunreg_rpi->index = cpu_to_le16(indicator);\n\n\treturn 0;\n}\n\nint\nsli_cmd_unreg_vfi(struct sli4 *sli4, void *buf, u16 index, u32 which)\n{\n\tstruct sli4_cmd_unreg_vfi *unreg_vfi = buf;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tunreg_vfi->hdr.command = SLI4_MBX_CMD_UNREG_VFI;\n\tswitch (which) {\n\tcase SLI4_UNREG_TYPE_DOMAIN:\n\t\tunreg_vfi->index = cpu_to_le16(index);\n\t\tbreak;\n\tcase SLI4_UNREG_TYPE_FCF:\n\t\tunreg_vfi->index = cpu_to_le16(index);\n\t\tbreak;\n\tcase SLI4_UNREG_TYPE_ALL:\n\t\tunreg_vfi->index = cpu_to_le16(U32_MAX);\n\t\tbreak;\n\tdefault:\n\t\treturn -EIO;\n\t}\n\n\tif (which != SLI4_UNREG_TYPE_DOMAIN)\n\t\tunreg_vfi->dw2_flags = cpu_to_le16(SLI4_UNREG_VFI_II_FCFI);\n\n\treturn 0;\n}\n\nint\nsli_cmd_unreg_vpi(struct sli4 *sli4, void *buf, u16 indicator, u32 which)\n{\n\tstruct sli4_cmd_unreg_vpi *unreg_vpi = buf;\n\tu32 flags = 0;\n\n\tmemset(buf, 0, SLI4_BMBX_SIZE);\n\n\tunreg_vpi->hdr.command = SLI4_MBX_CMD_UNREG_VPI;\n\tunreg_vpi->index = cpu_to_le16(indicator);\n\tswitch (which) {\n\tcase SLI4_UNREG_TYPE_PORT:\n\t\tflags |= SLI4_UNREG_VPI_II_VPI;\n\t\tbreak;\n\tcase SLI4_UNREG_TYPE_DOMAIN:\n\t\tflags |= SLI4_UNREG_VPI_II_VFI;\n\t\tbreak;\n\tcase SLI4_UNREG_TYPE_FCF:\n\t\tflags |= SLI4_UNREG_VPI_II_FCFI;\n\t\tbreak;\n\tcase SLI4_UNREG_TYPE_ALL:\n\t\t \n\t\tunreg_vpi->index = cpu_to_le16(U32_MAX);\n\t\tflags |= SLI4_UNREG_VPI_II_FCFI;\n\t\tbreak;\n\tdefault:\n\t\treturn -EIO;\n\t}\n\n\tunreg_vpi->dw2w0_flags = cpu_to_le16(flags);\n\treturn 0;\n}\n\nstatic int\nsli_cmd_common_modify_eq_delay(struct sli4 *sli4, void *buf,\n\t\t\t       struct sli4_queue *q, int num_q, u32 shift,\n\t\t\t       u32 delay_mult)\n{\n\tstruct sli4_rqst_cmn_modify_eq_delay *req = NULL;\n\tint i;\n\n\treq = sli_config_cmd_init(sli4, buf,\n\t\t\tSLI4_CFG_PYLD_LENGTH(cmn_modify_eq_delay), NULL);\n\tif (!req)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&req->hdr, SLI4_CMN_MODIFY_EQ_DELAY,\n\t\t\t SLI4_SUBSYSTEM_COMMON, CMD_V0,\n\t\t\t SLI4_RQST_PYLD_LEN(cmn_modify_eq_delay));\n\treq->num_eq = cpu_to_le32(num_q);\n\n\tfor (i = 0; i < num_q; i++) {\n\t\treq->eq_delay_record[i].eq_id = cpu_to_le32(q[i].id);\n\t\treq->eq_delay_record[i].phase = cpu_to_le32(shift);\n\t\treq->eq_delay_record[i].delay_multiplier =\n\t\t\tcpu_to_le32(delay_mult);\n\t}\n\n\treturn 0;\n}\n\nvoid\nsli4_cmd_lowlevel_set_watchdog(struct sli4 *sli4, void *buf,\n\t\t\t       size_t size, u16 timeout)\n{\n\tstruct sli4_rqst_lowlevel_set_watchdog *req = NULL;\n\n\treq = sli_config_cmd_init(sli4, buf,\n\t\t\tSLI4_CFG_PYLD_LENGTH(lowlevel_set_watchdog), NULL);\n\tif (!req)\n\t\treturn;\n\n\tsli_cmd_fill_hdr(&req->hdr, SLI4_OPC_LOWLEVEL_SET_WATCHDOG,\n\t\t\t SLI4_SUBSYSTEM_LOWLEVEL, CMD_V0,\n\t\t\t SLI4_RQST_PYLD_LEN(lowlevel_set_watchdog));\n\treq->watchdog_timeout = cpu_to_le16(timeout);\n}\n\nstatic int\nsli_cmd_common_get_cntl_attributes(struct sli4 *sli4, void *buf,\n\t\t\t\t   struct efc_dma *dma)\n{\n\tstruct sli4_rqst_hdr *hdr = NULL;\n\n\thdr = sli_config_cmd_init(sli4, buf, SLI4_RQST_CMDSZ(hdr), dma);\n\tif (!hdr)\n\t\treturn -EIO;\n\n\thdr->opcode = SLI4_CMN_GET_CNTL_ATTRIBUTES;\n\thdr->subsystem = SLI4_SUBSYSTEM_COMMON;\n\thdr->request_length = cpu_to_le32(dma->size);\n\n\treturn 0;\n}\n\nstatic int\nsli_cmd_common_get_cntl_addl_attributes(struct sli4 *sli4, void *buf,\n\t\t\t\t\tstruct efc_dma *dma)\n{\n\tstruct sli4_rqst_hdr *hdr = NULL;\n\n\thdr = sli_config_cmd_init(sli4, buf, SLI4_RQST_CMDSZ(hdr), dma);\n\tif (!hdr)\n\t\treturn -EIO;\n\n\thdr->opcode = SLI4_CMN_GET_CNTL_ADDL_ATTRS;\n\thdr->subsystem = SLI4_SUBSYSTEM_COMMON;\n\thdr->request_length = cpu_to_le32(dma->size);\n\n\treturn 0;\n}\n\nint\nsli_cmd_common_nop(struct sli4 *sli4, void *buf, uint64_t context)\n{\n\tstruct sli4_rqst_cmn_nop *nop = NULL;\n\n\tnop = sli_config_cmd_init(sli4, buf, SLI4_CFG_PYLD_LENGTH(cmn_nop),\n\t\t\t\t  NULL);\n\tif (!nop)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&nop->hdr, SLI4_CMN_NOP, SLI4_SUBSYSTEM_COMMON,\n\t\t\t CMD_V0, SLI4_RQST_PYLD_LEN(cmn_nop));\n\n\tmemcpy(&nop->context, &context, sizeof(context));\n\n\treturn 0;\n}\n\nint\nsli_cmd_common_get_resource_extent_info(struct sli4 *sli4, void *buf, u16 rtype)\n{\n\tstruct sli4_rqst_cmn_get_resource_extent_info *ext = NULL;\n\n\text = sli_config_cmd_init(sli4, buf,\n\t\t\tSLI4_RQST_CMDSZ(cmn_get_resource_extent_info), NULL);\n\tif (!ext)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&ext->hdr, SLI4_CMN_GET_RSC_EXTENT_INFO,\n\t\t\t SLI4_SUBSYSTEM_COMMON, CMD_V0,\n\t\t\t SLI4_RQST_PYLD_LEN(cmn_get_resource_extent_info));\n\n\text->resource_type = cpu_to_le16(rtype);\n\n\treturn 0;\n}\n\nint\nsli_cmd_common_get_sli4_parameters(struct sli4 *sli4, void *buf)\n{\n\tstruct sli4_rqst_hdr *hdr = NULL;\n\n\thdr = sli_config_cmd_init(sli4, buf,\n\t\t\tSLI4_CFG_PYLD_LENGTH(cmn_get_sli4_params), NULL);\n\tif (!hdr)\n\t\treturn -EIO;\n\n\thdr->opcode = SLI4_CMN_GET_SLI4_PARAMS;\n\thdr->subsystem = SLI4_SUBSYSTEM_COMMON;\n\thdr->request_length = SLI4_RQST_PYLD_LEN(cmn_get_sli4_params);\n\n\treturn 0;\n}\n\nstatic int\nsli_cmd_common_get_port_name(struct sli4 *sli4, void *buf)\n{\n\tstruct sli4_rqst_cmn_get_port_name *pname;\n\n\tpname = sli_config_cmd_init(sli4, buf,\n\t\t\tSLI4_CFG_PYLD_LENGTH(cmn_get_port_name), NULL);\n\tif (!pname)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&pname->hdr, SLI4_CMN_GET_PORT_NAME,\n\t\t\t SLI4_SUBSYSTEM_COMMON, CMD_V1,\n\t\t\t SLI4_RQST_PYLD_LEN(cmn_get_port_name));\n\n\t \n\tpname->port_type = SLI4_PORT_TYPE_FC;\n\n\treturn 0;\n}\n\nint\nsli_cmd_common_write_object(struct sli4 *sli4, void *buf, u16 noc,\n\t\t\t    u16 eof, u32 desired_write_length,\n\t\t\t    u32 offset, char *obj_name,\n\t\t\t    struct efc_dma *dma)\n{\n\tstruct sli4_rqst_cmn_write_object *wr_obj = NULL;\n\tstruct sli4_bde *bde;\n\tu32 dwflags = 0;\n\n\twr_obj = sli_config_cmd_init(sli4, buf,\n\t\t\tSLI4_RQST_CMDSZ(cmn_write_object) + sizeof(*bde), NULL);\n\tif (!wr_obj)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&wr_obj->hdr, SLI4_CMN_WRITE_OBJECT,\n\t\tSLI4_SUBSYSTEM_COMMON, CMD_V0,\n\t\tSLI4_RQST_PYLD_LEN_VAR(cmn_write_object, sizeof(*bde)));\n\n\tif (noc)\n\t\tdwflags |= SLI4_RQ_DES_WRITE_LEN_NOC;\n\tif (eof)\n\t\tdwflags |= SLI4_RQ_DES_WRITE_LEN_EOF;\n\tdwflags |= (desired_write_length & SLI4_RQ_DES_WRITE_LEN);\n\n\twr_obj->desired_write_len_dword = cpu_to_le32(dwflags);\n\n\twr_obj->write_offset = cpu_to_le32(offset);\n\tstrncpy(wr_obj->object_name, obj_name, sizeof(wr_obj->object_name) - 1);\n\twr_obj->host_buffer_descriptor_count = cpu_to_le32(1);\n\n\tbde = (struct sli4_bde *)wr_obj->host_buffer_descriptor;\n\n\t \n\tbde->bde_type_buflen =\n\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t    (desired_write_length & SLI4_BDE_LEN_MASK));\n\tbde->u.data.low = cpu_to_le32(lower_32_bits(dma->phys));\n\tbde->u.data.high = cpu_to_le32(upper_32_bits(dma->phys));\n\n\treturn 0;\n}\n\nint\nsli_cmd_common_delete_object(struct sli4 *sli4, void *buf, char *obj_name)\n{\n\tstruct sli4_rqst_cmn_delete_object *req = NULL;\n\n\treq = sli_config_cmd_init(sli4, buf,\n\t\t\t\t  SLI4_RQST_CMDSZ(cmn_delete_object), NULL);\n\tif (!req)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&req->hdr, SLI4_CMN_DELETE_OBJECT,\n\t\t\t SLI4_SUBSYSTEM_COMMON, CMD_V0,\n\t\t\t SLI4_RQST_PYLD_LEN(cmn_delete_object));\n\n\tstrncpy(req->object_name, obj_name, sizeof(req->object_name) - 1);\n\treturn 0;\n}\n\nint\nsli_cmd_common_read_object(struct sli4 *sli4, void *buf, u32 desired_read_len,\n\t\t\t   u32 offset, char *obj_name, struct efc_dma *dma)\n{\n\tstruct sli4_rqst_cmn_read_object *rd_obj = NULL;\n\tstruct sli4_bde *bde;\n\n\trd_obj = sli_config_cmd_init(sli4, buf,\n\t\t\tSLI4_RQST_CMDSZ(cmn_read_object) + sizeof(*bde), NULL);\n\tif (!rd_obj)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&rd_obj->hdr, SLI4_CMN_READ_OBJECT,\n\t\tSLI4_SUBSYSTEM_COMMON, CMD_V0,\n\t\tSLI4_RQST_PYLD_LEN_VAR(cmn_read_object, sizeof(*bde)));\n\trd_obj->desired_read_length_dword =\n\t\tcpu_to_le32(desired_read_len & SLI4_REQ_DESIRE_READLEN);\n\n\trd_obj->read_offset = cpu_to_le32(offset);\n\tstrncpy(rd_obj->object_name, obj_name, sizeof(rd_obj->object_name) - 1);\n\trd_obj->host_buffer_descriptor_count = cpu_to_le32(1);\n\n\tbde = (struct sli4_bde *)rd_obj->host_buffer_descriptor;\n\n\t \n\tbde->bde_type_buflen =\n\t\tcpu_to_le32((SLI4_BDE_TYPE_VAL(64)) |\n\t\t\t    (desired_read_len & SLI4_BDE_LEN_MASK));\n\tif (dma) {\n\t\tbde->u.data.low = cpu_to_le32(lower_32_bits(dma->phys));\n\t\tbde->u.data.high = cpu_to_le32(upper_32_bits(dma->phys));\n\t} else {\n\t\tbde->u.data.low = 0;\n\t\tbde->u.data.high = 0;\n\t}\n\n\treturn 0;\n}\n\nint\nsli_cmd_dmtf_exec_clp_cmd(struct sli4 *sli4, void *buf, struct efc_dma *cmd,\n\t\t\t  struct efc_dma *resp)\n{\n\tstruct sli4_rqst_dmtf_exec_clp_cmd *clp_cmd = NULL;\n\n\tclp_cmd = sli_config_cmd_init(sli4, buf,\n\t\t\t\tSLI4_RQST_CMDSZ(dmtf_exec_clp_cmd), NULL);\n\tif (!clp_cmd)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&clp_cmd->hdr, DMTF_EXEC_CLP_CMD, SLI4_SUBSYSTEM_DMTF,\n\t\t\t CMD_V0, SLI4_RQST_PYLD_LEN(dmtf_exec_clp_cmd));\n\n\tclp_cmd->cmd_buf_length = cpu_to_le32(cmd->size);\n\tclp_cmd->cmd_buf_addr_low =  cpu_to_le32(lower_32_bits(cmd->phys));\n\tclp_cmd->cmd_buf_addr_high =  cpu_to_le32(upper_32_bits(cmd->phys));\n\tclp_cmd->resp_buf_length = cpu_to_le32(resp->size);\n\tclp_cmd->resp_buf_addr_low =  cpu_to_le32(lower_32_bits(resp->phys));\n\tclp_cmd->resp_buf_addr_high =  cpu_to_le32(upper_32_bits(resp->phys));\n\treturn 0;\n}\n\nint\nsli_cmd_common_set_dump_location(struct sli4 *sli4, void *buf, bool query,\n\t\t\t\t bool is_buffer_list,\n\t\t\t\t struct efc_dma *buffer, u8 fdb)\n{\n\tstruct sli4_rqst_cmn_set_dump_location *set_dump_loc = NULL;\n\tu32 buffer_length_flag = 0;\n\n\tset_dump_loc = sli_config_cmd_init(sli4, buf,\n\t\t\t\tSLI4_RQST_CMDSZ(cmn_set_dump_location), NULL);\n\tif (!set_dump_loc)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&set_dump_loc->hdr, SLI4_CMN_SET_DUMP_LOCATION,\n\t\t\t SLI4_SUBSYSTEM_COMMON, CMD_V0,\n\t\t\t SLI4_RQST_PYLD_LEN(cmn_set_dump_location));\n\n\tif (is_buffer_list)\n\t\tbuffer_length_flag |= SLI4_CMN_SET_DUMP_BLP;\n\n\tif (query)\n\t\tbuffer_length_flag |= SLI4_CMN_SET_DUMP_QRY;\n\n\tif (fdb)\n\t\tbuffer_length_flag |= SLI4_CMN_SET_DUMP_FDB;\n\n\tif (buffer) {\n\t\tset_dump_loc->buf_addr_low =\n\t\t\tcpu_to_le32(lower_32_bits(buffer->phys));\n\t\tset_dump_loc->buf_addr_high =\n\t\t\tcpu_to_le32(upper_32_bits(buffer->phys));\n\n\t\tbuffer_length_flag |=\n\t\t\tbuffer->len & SLI4_CMN_SET_DUMP_BUFFER_LEN;\n\t} else {\n\t\tset_dump_loc->buf_addr_low = 0;\n\t\tset_dump_loc->buf_addr_high = 0;\n\t\tset_dump_loc->buffer_length_dword = 0;\n\t}\n\tset_dump_loc->buffer_length_dword = cpu_to_le32(buffer_length_flag);\n\treturn 0;\n}\n\nint\nsli_cmd_common_set_features(struct sli4 *sli4, void *buf, u32 feature,\n\t\t\t    u32 param_len, void *parameter)\n{\n\tstruct sli4_rqst_cmn_set_features *cmd = NULL;\n\n\tcmd = sli_config_cmd_init(sli4, buf,\n\t\t\t\t  SLI4_RQST_CMDSZ(cmn_set_features), NULL);\n\tif (!cmd)\n\t\treturn -EIO;\n\n\tsli_cmd_fill_hdr(&cmd->hdr, SLI4_CMN_SET_FEATURES,\n\t\t\t SLI4_SUBSYSTEM_COMMON, CMD_V0,\n\t\t\t SLI4_RQST_PYLD_LEN(cmn_set_features));\n\n\tcmd->feature = cpu_to_le32(feature);\n\tcmd->param_len = cpu_to_le32(param_len);\n\tmemcpy(cmd->params, parameter, param_len);\n\n\treturn 0;\n}\n\nint\nsli_cqe_mq(struct sli4 *sli4, void *buf)\n{\n\tstruct sli4_mcqe *mcqe = buf;\n\tu32 dwflags = le32_to_cpu(mcqe->dw3_flags);\n\t \n\tif (!(dwflags & SLI4_MCQE_COMPLETED))\n\t\treturn SLI4_MCQE_STATUS_NOT_COMPLETED;\n\n\tif (le16_to_cpu(mcqe->completion_status)) {\n\t\tefc_log_info(sli4, \"status(st=%#x ext=%#x con=%d cmp=%d ae=%d val=%d)\\n\",\n\t\t\t     le16_to_cpu(mcqe->completion_status),\n\t\t\t     le16_to_cpu(mcqe->extended_status),\n\t\t\t     (dwflags & SLI4_MCQE_CONSUMED),\n\t\t\t     (dwflags & SLI4_MCQE_COMPLETED),\n\t\t\t     (dwflags & SLI4_MCQE_AE),\n\t\t\t     (dwflags & SLI4_MCQE_VALID));\n\t}\n\n\treturn le16_to_cpu(mcqe->completion_status);\n}\n\nint\nsli_cqe_async(struct sli4 *sli4, void *buf)\n{\n\tstruct sli4_acqe *acqe = buf;\n\tint rc = -EIO;\n\n\tif (!buf) {\n\t\tefc_log_err(sli4, \"bad parameter sli4=%p buf=%p\\n\", sli4, buf);\n\t\treturn -EIO;\n\t}\n\n\tswitch (acqe->event_code) {\n\tcase SLI4_ACQE_EVENT_CODE_LINK_STATE:\n\t\tefc_log_info(sli4, \"Unsupported by FC link, evt code:%#x\\n\",\n\t\t\t     acqe->event_code);\n\t\tbreak;\n\tcase SLI4_ACQE_EVENT_CODE_GRP_5:\n\t\tefc_log_info(sli4, \"ACQE GRP5\\n\");\n\t\tbreak;\n\tcase SLI4_ACQE_EVENT_CODE_SLI_PORT_EVENT:\n\t\tefc_log_info(sli4, \"ACQE SLI Port, type=0x%x, data1,2=0x%08x,0x%08x\\n\",\n\t\t\t     acqe->event_type,\n\t\t\t     le32_to_cpu(acqe->event_data[0]),\n\t\t\t     le32_to_cpu(acqe->event_data[1]));\n\t\tbreak;\n\tcase SLI4_ACQE_EVENT_CODE_FC_LINK_EVENT:\n\t\trc = sli_fc_process_link_attention(sli4, buf);\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"ACQE unknown=%#x\\n\", acqe->event_code);\n\t}\n\n\treturn rc;\n}\n\nbool\nsli_fw_ready(struct sli4 *sli4)\n{\n\tu32 val;\n\n\t \n\tval = sli_reg_read_status(sli4);\n\treturn (val & SLI4_PORT_STATUS_RDY) ? 1 : 0;\n}\n\nstatic bool\nsli_wait_for_fw_ready(struct sli4 *sli4, u32 timeout_ms)\n{\n\tunsigned long end;\n\n\tend = jiffies + msecs_to_jiffies(timeout_ms);\n\n\tdo {\n\t\tif (sli_fw_ready(sli4))\n\t\t\treturn true;\n\n\t\tusleep_range(1000, 2000);\n\t} while (time_before(jiffies, end));\n\n\treturn false;\n}\n\nstatic bool\nsli_sliport_reset(struct sli4 *sli4)\n{\n\tbool rc;\n\tu32 val;\n\n\tval = SLI4_PORT_CTRL_IP;\n\t \n\twritel(val, (sli4->reg[0] + SLI4_PORT_CTRL_REG));\n\n\trc = sli_wait_for_fw_ready(sli4, SLI4_FW_READY_TIMEOUT_MSEC);\n\tif (!rc)\n\t\tefc_log_crit(sli4, \"port failed to become ready after initialization\\n\");\n\n\treturn rc;\n}\n\nstatic bool\nsli_fw_init(struct sli4 *sli4)\n{\n\t \n\tif (!sli_wait_for_fw_ready(sli4, SLI4_FW_READY_TIMEOUT_MSEC)) {\n\t\tefc_log_crit(sli4, \"FW status is NOT ready\\n\");\n\t\treturn false;\n\t}\n\n\t \n\treturn sli_sliport_reset(sli4);\n}\n\nstatic int\nsli_request_features(struct sli4 *sli4, u32 *features, bool query)\n{\n\tstruct sli4_cmd_request_features *req_features = sli4->bmbx.virt;\n\n\tif (sli_cmd_request_features(sli4, sli4->bmbx.virt, *features, query)) {\n\t\tefc_log_err(sli4, \"bad REQUEST_FEATURES write\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"bootstrap mailbox write fail\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (le16_to_cpu(req_features->hdr.status)) {\n\t\tefc_log_err(sli4, \"REQUEST_FEATURES bad status %#x\\n\",\n\t\t\t    le16_to_cpu(req_features->hdr.status));\n\t\treturn -EIO;\n\t}\n\n\t*features = le32_to_cpu(req_features->resp);\n\treturn 0;\n}\n\nvoid\nsli_calc_max_qentries(struct sli4 *sli4)\n{\n\tenum sli4_qtype q;\n\tu32 qentries;\n\n\tfor (q = SLI4_QTYPE_EQ; q < SLI4_QTYPE_MAX; q++) {\n\t\tsli4->qinfo.max_qentries[q] =\n\t\t\tsli_convert_mask_to_count(sli4->qinfo.count_method[q],\n\t\t\t\t\t\t  sli4->qinfo.count_mask[q]);\n\t}\n\n\t \n\tfor (q = SLI4_QTYPE_EQ; q < SLI4_QTYPE_MAX; q++) {\n\t\tqentries = sli4->qinfo.max_qentries[q];\n\n\t\tefc_log_info(sli4, \"[%s]: max_qentries from %d to %d\\n\",\n\t\t\t     SLI4_QNAME[q],\n\t\t\t     sli4->qinfo.max_qentries[q], qentries);\n\t\tsli4->qinfo.max_qentries[q] = qentries;\n\t}\n}\n\nstatic int\nsli_get_read_config(struct sli4 *sli4)\n{\n\tstruct sli4_rsp_read_config *conf = sli4->bmbx.virt;\n\tu32 i, total;\n\tu32 *base;\n\n\tif (sli_cmd_read_config(sli4, sli4->bmbx.virt)) {\n\t\tefc_log_err(sli4, \"bad READ_CONFIG write\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"bootstrap mailbox fail (READ_CONFIG)\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (le16_to_cpu(conf->hdr.status)) {\n\t\tefc_log_err(sli4, \"READ_CONFIG bad status %#x\\n\",\n\t\t\t    le16_to_cpu(conf->hdr.status));\n\t\treturn -EIO;\n\t}\n\n\tsli4->params.has_extents =\n\t  le32_to_cpu(conf->ext_dword) & SLI4_READ_CFG_RESP_RESOURCE_EXT;\n\tif (sli4->params.has_extents) {\n\t\tefc_log_err(sli4, \"extents not supported\\n\");\n\t\treturn -EIO;\n\t}\n\n\tbase = sli4->ext[0].base;\n\tif (!base) {\n\t\tint size = SLI4_RSRC_MAX * sizeof(u32);\n\n\t\tbase = kzalloc(size, GFP_KERNEL);\n\t\tif (!base)\n\t\t\treturn -EIO;\n\t}\n\n\tfor (i = 0; i < SLI4_RSRC_MAX; i++) {\n\t\tsli4->ext[i].number = 1;\n\t\tsli4->ext[i].n_alloc = 0;\n\t\tsli4->ext[i].base = &base[i];\n\t}\n\n\tsli4->ext[SLI4_RSRC_VFI].base[0] = le16_to_cpu(conf->vfi_base);\n\tsli4->ext[SLI4_RSRC_VFI].size = le16_to_cpu(conf->vfi_count);\n\n\tsli4->ext[SLI4_RSRC_VPI].base[0] = le16_to_cpu(conf->vpi_base);\n\tsli4->ext[SLI4_RSRC_VPI].size = le16_to_cpu(conf->vpi_count);\n\n\tsli4->ext[SLI4_RSRC_RPI].base[0] = le16_to_cpu(conf->rpi_base);\n\tsli4->ext[SLI4_RSRC_RPI].size = le16_to_cpu(conf->rpi_count);\n\n\tsli4->ext[SLI4_RSRC_XRI].base[0] = le16_to_cpu(conf->xri_base);\n\tsli4->ext[SLI4_RSRC_XRI].size = le16_to_cpu(conf->xri_count);\n\n\tsli4->ext[SLI4_RSRC_FCFI].base[0] = 0;\n\tsli4->ext[SLI4_RSRC_FCFI].size = le16_to_cpu(conf->fcfi_count);\n\n\tfor (i = 0; i < SLI4_RSRC_MAX; i++) {\n\t\ttotal = sli4->ext[i].number * sli4->ext[i].size;\n\t\tsli4->ext[i].use_map = bitmap_zalloc(total, GFP_KERNEL);\n\t\tif (!sli4->ext[i].use_map) {\n\t\t\tefc_log_err(sli4, \"bitmap memory allocation failed %d\\n\",\n\t\t\t\t    i);\n\t\t\treturn -EIO;\n\t\t}\n\t\tsli4->ext[i].map_size = total;\n\t}\n\n\tsli4->topology = (le32_to_cpu(conf->topology_dword) &\n\t\t\t  SLI4_READ_CFG_RESP_TOPOLOGY) >> 24;\n\tswitch (sli4->topology) {\n\tcase SLI4_READ_CFG_TOPO_FC:\n\t\tefc_log_info(sli4, \"FC (unknown)\\n\");\n\t\tbreak;\n\tcase SLI4_READ_CFG_TOPO_NON_FC_AL:\n\t\tefc_log_info(sli4, \"FC (direct attach)\\n\");\n\t\tbreak;\n\tcase SLI4_READ_CFG_TOPO_FC_AL:\n\t\tefc_log_info(sli4, \"FC (arbitrated loop)\\n\");\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"bad topology %#x\\n\", sli4->topology);\n\t}\n\n\tsli4->e_d_tov = le16_to_cpu(conf->e_d_tov);\n\tsli4->r_a_tov = le16_to_cpu(conf->r_a_tov);\n\n\tsli4->link_module_type = le16_to_cpu(conf->lmt);\n\n\tsli4->qinfo.max_qcount[SLI4_QTYPE_EQ] =\tle16_to_cpu(conf->eq_count);\n\tsli4->qinfo.max_qcount[SLI4_QTYPE_CQ] =\tle16_to_cpu(conf->cq_count);\n\tsli4->qinfo.max_qcount[SLI4_QTYPE_WQ] =\tle16_to_cpu(conf->wq_count);\n\tsli4->qinfo.max_qcount[SLI4_QTYPE_RQ] =\tle16_to_cpu(conf->rq_count);\n\n\t \n\tsli4->qinfo.max_qcount[SLI4_QTYPE_MQ] = SLI4_USER_MQ_COUNT;\n\treturn 0;\n}\n\nstatic int\nsli_get_sli4_parameters(struct sli4 *sli4)\n{\n\tstruct sli4_rsp_cmn_get_sli4_params *parms;\n\tu32 dw_loopback;\n\tu32 dw_eq_pg_cnt;\n\tu32 dw_cq_pg_cnt;\n\tu32 dw_mq_pg_cnt;\n\tu32 dw_wq_pg_cnt;\n\tu32 dw_rq_pg_cnt;\n\tu32 dw_sgl_pg_cnt;\n\n\tif (sli_cmd_common_get_sli4_parameters(sli4, sli4->bmbx.virt))\n\t\treturn -EIO;\n\n\tparms = (struct sli4_rsp_cmn_get_sli4_params *)\n\t\t (((u8 *)sli4->bmbx.virt) +\n\t\t  offsetof(struct sli4_cmd_sli_config, payload.embed));\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"bootstrap mailbox write fail\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (parms->hdr.status) {\n\t\tefc_log_err(sli4, \"COMMON_GET_SLI4_PARAMETERS bad status %#x\",\n\t\t\t    parms->hdr.status);\n\t\tefc_log_err(sli4, \"additional status %#x\\n\",\n\t\t\t    parms->hdr.additional_status);\n\t\treturn -EIO;\n\t}\n\n\tdw_loopback = le32_to_cpu(parms->dw16_loopback_scope);\n\tdw_eq_pg_cnt = le32_to_cpu(parms->dw6_eq_page_cnt);\n\tdw_cq_pg_cnt = le32_to_cpu(parms->dw8_cq_page_cnt);\n\tdw_mq_pg_cnt = le32_to_cpu(parms->dw10_mq_page_cnt);\n\tdw_wq_pg_cnt = le32_to_cpu(parms->dw12_wq_page_cnt);\n\tdw_rq_pg_cnt = le32_to_cpu(parms->dw14_rq_page_cnt);\n\n\tsli4->params.auto_reg =\t(dw_loopback & SLI4_PARAM_AREG);\n\tsli4->params.auto_xfer_rdy = (dw_loopback & SLI4_PARAM_AGXF);\n\tsli4->params.hdr_template_req =\t(dw_loopback & SLI4_PARAM_HDRR);\n\tsli4->params.t10_dif_inline_capable = (dw_loopback & SLI4_PARAM_TIMM);\n\tsli4->params.t10_dif_separate_capable =\t(dw_loopback & SLI4_PARAM_TSMM);\n\n\tsli4->params.mq_create_version = GET_Q_CREATE_VERSION(dw_mq_pg_cnt);\n\tsli4->params.cq_create_version = GET_Q_CREATE_VERSION(dw_cq_pg_cnt);\n\n\tsli4->rq_min_buf_size =\tle16_to_cpu(parms->min_rq_buffer_size);\n\tsli4->rq_max_buf_size = le32_to_cpu(parms->max_rq_buffer_size);\n\n\tsli4->qinfo.qpage_count[SLI4_QTYPE_EQ] =\n\t\t(dw_eq_pg_cnt & SLI4_PARAM_EQ_PAGE_CNT_MASK);\n\tsli4->qinfo.qpage_count[SLI4_QTYPE_CQ] =\n\t\t(dw_cq_pg_cnt & SLI4_PARAM_CQ_PAGE_CNT_MASK);\n\tsli4->qinfo.qpage_count[SLI4_QTYPE_MQ] =\n\t\t(dw_mq_pg_cnt & SLI4_PARAM_MQ_PAGE_CNT_MASK);\n\tsli4->qinfo.qpage_count[SLI4_QTYPE_WQ] =\n\t\t(dw_wq_pg_cnt & SLI4_PARAM_WQ_PAGE_CNT_MASK);\n\tsli4->qinfo.qpage_count[SLI4_QTYPE_RQ] =\n\t\t(dw_rq_pg_cnt & SLI4_PARAM_RQ_PAGE_CNT_MASK);\n\n\t \n\n\tsli4->qinfo.count_mask[SLI4_QTYPE_EQ] =\n\t\t\tle16_to_cpu(parms->eqe_count_mask);\n\tsli4->qinfo.count_method[SLI4_QTYPE_EQ] =\n\t\t\tGET_Q_CNT_METHOD(dw_eq_pg_cnt);\n\n\tsli4->qinfo.count_mask[SLI4_QTYPE_CQ] =\n\t\t\tle16_to_cpu(parms->cqe_count_mask);\n\tsli4->qinfo.count_method[SLI4_QTYPE_CQ] =\n\t\t\tGET_Q_CNT_METHOD(dw_cq_pg_cnt);\n\n\tsli4->qinfo.count_mask[SLI4_QTYPE_MQ] =\n\t\t\tle16_to_cpu(parms->mqe_count_mask);\n\tsli4->qinfo.count_method[SLI4_QTYPE_MQ] =\n\t\t\tGET_Q_CNT_METHOD(dw_mq_pg_cnt);\n\n\tsli4->qinfo.count_mask[SLI4_QTYPE_WQ] =\n\t\t\tle16_to_cpu(parms->wqe_count_mask);\n\tsli4->qinfo.count_method[SLI4_QTYPE_WQ] =\n\t\t\tGET_Q_CNT_METHOD(dw_wq_pg_cnt);\n\n\tsli4->qinfo.count_mask[SLI4_QTYPE_RQ] =\n\t\t\tle16_to_cpu(parms->rqe_count_mask);\n\tsli4->qinfo.count_method[SLI4_QTYPE_RQ] =\n\t\t\tGET_Q_CNT_METHOD(dw_rq_pg_cnt);\n\n\t \n\tsli_calc_max_qentries(sli4);\n\n\tdw_sgl_pg_cnt = le32_to_cpu(parms->dw18_sgl_page_cnt);\n\n\t \n\tsli4->max_sgl_pages = (dw_sgl_pg_cnt & SLI4_PARAM_SGL_PAGE_CNT_MASK);\n\n\t \n\tsli4->sgl_page_sizes = (dw_sgl_pg_cnt &\n\t\t\t\tSLI4_PARAM_SGL_PAGE_SZS_MASK) >> 8;\n\t \n\tsli4->sge_supported_length = le32_to_cpu(parms->sge_supported_length);\n\tsli4->params.sgl_pre_reg_required = (dw_loopback & SLI4_PARAM_SGLR);\n\t \n\tsli4->params.sgl_pre_registered = true;\n\n\tsli4->params.perf_hint = dw_loopback & SLI4_PARAM_PHON;\n\tsli4->params.perf_wq_id_association = (dw_loopback & SLI4_PARAM_PHWQ);\n\n\tsli4->rq_batch = (le16_to_cpu(parms->dw15w1_rq_db_window) &\n\t\t\t  SLI4_PARAM_RQ_DB_WINDOW_MASK) >> 12;\n\n\t \n\tif (((dw_wq_pg_cnt & SLI4_PARAM_WQE_SZS_MASK) >> 8) &\n\t    SLI4_128BYTE_WQE_SUPPORT)\n\t\tsli4->wqe_size = SLI4_WQE_EXT_BYTES;\n\telse\n\t\tsli4->wqe_size = SLI4_WQE_BYTES;\n\n\treturn 0;\n}\n\nstatic int\nsli_get_ctrl_attributes(struct sli4 *sli4)\n{\n\tstruct sli4_rsp_cmn_get_cntl_attributes *attr;\n\tstruct sli4_rsp_cmn_get_cntl_addl_attributes *add_attr;\n\tstruct efc_dma data;\n\tu32 psize;\n\n\t \n\tmemset(sli4->vpd_data.virt, 0, sli4->vpd_data.size);\n\tif (sli_cmd_common_get_cntl_attributes(sli4, sli4->bmbx.virt,\n\t\t\t\t\t       &sli4->vpd_data)) {\n\t\tefc_log_err(sli4, \"bad COMMON_GET_CNTL_ATTRIBUTES write\\n\");\n\t\treturn -EIO;\n\t}\n\n\tattr =\tsli4->vpd_data.virt;\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"bootstrap mailbox write fail\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (attr->hdr.status) {\n\t\tefc_log_err(sli4, \"COMMON_GET_CNTL_ATTRIBUTES bad status %#x\",\n\t\t\t    attr->hdr.status);\n\t\tefc_log_err(sli4, \"additional status %#x\\n\",\n\t\t\t    attr->hdr.additional_status);\n\t\treturn -EIO;\n\t}\n\n\tsli4->port_number = attr->port_num_type_flags & SLI4_CNTL_ATTR_PORTNUM;\n\n\tmemcpy(sli4->bios_version_string, attr->bios_version_str,\n\t       sizeof(sli4->bios_version_string));\n\n\t \n\tpsize = sizeof(struct sli4_rsp_cmn_get_cntl_addl_attributes);\n\tdata.size = psize;\n\tdata.virt = dma_alloc_coherent(&sli4->pci->dev, data.size,\n\t\t\t\t       &data.phys, GFP_KERNEL);\n\tif (!data.virt) {\n\t\tmemset(&data, 0, sizeof(struct efc_dma));\n\t\tefc_log_err(sli4, \"Failed to allocate memory for GET_CNTL_ADDL_ATTR\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (sli_cmd_common_get_cntl_addl_attributes(sli4, sli4->bmbx.virt,\n\t\t\t\t\t\t    &data)) {\n\t\tefc_log_err(sli4, \"bad GET_CNTL_ADDL_ATTR write\\n\");\n\t\tdma_free_coherent(&sli4->pci->dev, data.size,\n\t\t\t\t  data.virt, data.phys);\n\t\treturn -EIO;\n\t}\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"mailbox fail (GET_CNTL_ADDL_ATTR)\\n\");\n\t\tdma_free_coherent(&sli4->pci->dev, data.size,\n\t\t\t\t  data.virt, data.phys);\n\t\treturn -EIO;\n\t}\n\n\tadd_attr = data.virt;\n\tif (add_attr->hdr.status) {\n\t\tefc_log_err(sli4, \"GET_CNTL_ADDL_ATTR bad status %#x\\n\",\n\t\t\t    add_attr->hdr.status);\n\t\tdma_free_coherent(&sli4->pci->dev, data.size,\n\t\t\t\t  data.virt, data.phys);\n\t\treturn -EIO;\n\t}\n\n\tmemcpy(sli4->ipl_name, add_attr->ipl_file_name, sizeof(sli4->ipl_name));\n\n\tefc_log_info(sli4, \"IPL:%s\\n\", (char *)sli4->ipl_name);\n\n\tdma_free_coherent(&sli4->pci->dev, data.size, data.virt,\n\t\t\t  data.phys);\n\tmemset(&data, 0, sizeof(struct efc_dma));\n\treturn 0;\n}\n\nstatic int\nsli_get_fw_rev(struct sli4 *sli4)\n{\n\tstruct sli4_cmd_read_rev\t*read_rev = sli4->bmbx.virt;\n\n\tif (sli_cmd_read_rev(sli4, sli4->bmbx.virt, &sli4->vpd_data))\n\t\treturn -EIO;\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"bootstrap mailbox write fail (READ_REV)\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (le16_to_cpu(read_rev->hdr.status)) {\n\t\tefc_log_err(sli4, \"READ_REV bad status %#x\\n\",\n\t\t\t    le16_to_cpu(read_rev->hdr.status));\n\t\treturn -EIO;\n\t}\n\n\tsli4->fw_rev[0] = le32_to_cpu(read_rev->first_fw_id);\n\tmemcpy(sli4->fw_name[0], read_rev->first_fw_name,\n\t       sizeof(sli4->fw_name[0]));\n\n\tsli4->fw_rev[1] = le32_to_cpu(read_rev->second_fw_id);\n\tmemcpy(sli4->fw_name[1], read_rev->second_fw_name,\n\t       sizeof(sli4->fw_name[1]));\n\n\tsli4->hw_rev[0] = le32_to_cpu(read_rev->first_hw_rev);\n\tsli4->hw_rev[1] = le32_to_cpu(read_rev->second_hw_rev);\n\tsli4->hw_rev[2] = le32_to_cpu(read_rev->third_hw_rev);\n\n\tefc_log_info(sli4, \"FW1:%s (%08x) / FW2:%s (%08x)\\n\",\n\t\t     read_rev->first_fw_name, le32_to_cpu(read_rev->first_fw_id),\n\t\t     read_rev->second_fw_name, le32_to_cpu(read_rev->second_fw_id));\n\n\tefc_log_info(sli4, \"HW1: %08x / HW2: %08x\\n\",\n\t\t     le32_to_cpu(read_rev->first_hw_rev),\n\t\t     le32_to_cpu(read_rev->second_hw_rev));\n\n\t \n\tif (le32_to_cpu(read_rev->returned_vpd_length) !=\n\t    le32_to_cpu(read_rev->actual_vpd_length)) {\n\t\tefc_log_info(sli4, \"VPD length: avail=%d return=%d actual=%d\\n\",\n\t\t\t     le32_to_cpu(read_rev->available_length_dword) &\n\t\t\t\t    SLI4_READ_REV_AVAILABLE_LENGTH,\n\t\t\t     le32_to_cpu(read_rev->returned_vpd_length),\n\t\t\t     le32_to_cpu(read_rev->actual_vpd_length));\n\t}\n\tsli4->vpd_length = le32_to_cpu(read_rev->returned_vpd_length);\n\treturn 0;\n}\n\nstatic int\nsli_get_config(struct sli4 *sli4)\n{\n\tstruct sli4_rsp_cmn_get_port_name *port_name;\n\tstruct sli4_cmd_read_nvparms *read_nvparms;\n\n\t \n\tif (sli_get_read_config(sli4))\n\t\treturn -EIO;\n\n\tif (sli_get_sli4_parameters(sli4))\n\t\treturn -EIO;\n\n\tif (sli_get_ctrl_attributes(sli4))\n\t\treturn -EIO;\n\n\tif (sli_cmd_common_get_port_name(sli4, sli4->bmbx.virt))\n\t\treturn -EIO;\n\n\tport_name = (struct sli4_rsp_cmn_get_port_name *)\n\t\t    (((u8 *)sli4->bmbx.virt) +\n\t\t    offsetof(struct sli4_cmd_sli_config, payload.embed));\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"bootstrap mailbox fail (GET_PORT_NAME)\\n\");\n\t\treturn -EIO;\n\t}\n\n\tsli4->port_name[0] = port_name->port_name[sli4->port_number];\n\tsli4->port_name[1] = '\\0';\n\n\tif (sli_get_fw_rev(sli4))\n\t\treturn -EIO;\n\n\tif (sli_cmd_read_nvparms(sli4, sli4->bmbx.virt)) {\n\t\tefc_log_err(sli4, \"bad READ_NVPARMS write\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"bootstrap mailbox fail (READ_NVPARMS)\\n\");\n\t\treturn -EIO;\n\t}\n\n\tread_nvparms = sli4->bmbx.virt;\n\tif (le16_to_cpu(read_nvparms->hdr.status)) {\n\t\tefc_log_err(sli4, \"READ_NVPARMS bad status %#x\\n\",\n\t\t\t    le16_to_cpu(read_nvparms->hdr.status));\n\t\treturn -EIO;\n\t}\n\n\tmemcpy(sli4->wwpn, read_nvparms->wwpn, sizeof(sli4->wwpn));\n\tmemcpy(sli4->wwnn, read_nvparms->wwnn, sizeof(sli4->wwnn));\n\n\tefc_log_info(sli4, \"WWPN %02x:%02x:%02x:%02x:%02x:%02x:%02x:%02x\\n\",\n\t\t     sli4->wwpn[0], sli4->wwpn[1], sli4->wwpn[2], sli4->wwpn[3],\n\t\t     sli4->wwpn[4], sli4->wwpn[5], sli4->wwpn[6], sli4->wwpn[7]);\n\tefc_log_info(sli4, \"WWNN %02x:%02x:%02x:%02x:%02x:%02x:%02x:%02x\\n\",\n\t\t     sli4->wwnn[0], sli4->wwnn[1], sli4->wwnn[2], sli4->wwnn[3],\n\t\t     sli4->wwnn[4], sli4->wwnn[5], sli4->wwnn[6], sli4->wwnn[7]);\n\n\treturn 0;\n}\n\nint\nsli_setup(struct sli4 *sli4, void *os, struct pci_dev  *pdev,\n\t  void __iomem *reg[])\n{\n\tu32 intf = U32_MAX;\n\tu32 pci_class_rev = 0;\n\tu32 rev_id = 0;\n\tu32 family = 0;\n\tu32 asic_id = 0;\n\tu32 i;\n\tstruct sli4_asic_entry_t *asic;\n\n\tmemset(sli4, 0, sizeof(struct sli4));\n\n\tsli4->os = os;\n\tsli4->pci = pdev;\n\n\tfor (i = 0; i < 6; i++)\n\t\tsli4->reg[i] = reg[i];\n\t \n\tif (pci_read_config_dword(pdev, SLI4_INTF_REG, &intf))\n\t\treturn -EIO;\n\n\tif ((intf & SLI4_INTF_VALID_MASK) != (u32)SLI4_INTF_VALID_VALUE) {\n\t\tefc_log_err(sli4, \"SLI_INTF is not valid\\n\");\n\t\treturn -EIO;\n\t}\n\n\t \n\tif ((intf & SLI4_INTF_REV_MASK) != SLI4_INTF_REV_S4) {\n\t\tefc_log_err(sli4, \"Unsupported SLI revision (intf=%#x)\\n\", intf);\n\t\treturn -EIO;\n\t}\n\n\tsli4->sli_family = intf & SLI4_INTF_FAMILY_MASK;\n\n\tsli4->if_type = intf & SLI4_INTF_IF_TYPE_MASK;\n\tefc_log_info(sli4, \"status=%#x error1=%#x error2=%#x\\n\",\n\t\t     sli_reg_read_status(sli4),\n\t\t     sli_reg_read_err1(sli4),\n\t\t     sli_reg_read_err2(sli4));\n\n\t \n\tif (pci_read_config_dword(pdev, PCI_CLASS_REVISION, &pci_class_rev))\n\t\treturn -EIO;\n\n\trev_id = pci_class_rev & 0xff;\n\tfamily = sli4->sli_family;\n\tif (family == SLI4_FAMILY_CHECK_ASIC_TYPE) {\n\t\tif (!pci_read_config_dword(pdev, SLI4_ASIC_ID_REG, &asic_id))\n\t\t\tfamily = asic_id & SLI4_ASIC_GEN_MASK;\n\t}\n\n\tfor (i = 0, asic = sli4_asic_table; i < ARRAY_SIZE(sli4_asic_table);\n\t     i++, asic++) {\n\t\tif (rev_id == asic->rev_id && family == asic->family) {\n\t\t\tsli4->asic_type = family;\n\t\t\tsli4->asic_rev = rev_id;\n\t\t\tbreak;\n\t\t}\n\t}\n\t \n\tif (!sli4->asic_type) {\n\t\tefc_log_err(sli4, \"no matching asic family/rev found: %02x/%02x\\n\",\n\t\t\t    family, rev_id);\n\t\treturn -EIO;\n\t}\n\n\t \n\tsli4->bmbx.size = SLI4_BMBX_SIZE + sizeof(struct sli4_mcqe);\n\tsli4->bmbx.virt = dma_alloc_coherent(&pdev->dev, sli4->bmbx.size,\n\t\t\t\t\t     &sli4->bmbx.phys, GFP_KERNEL);\n\tif (!sli4->bmbx.virt) {\n\t\tmemset(&sli4->bmbx, 0, sizeof(struct efc_dma));\n\t\tefc_log_err(sli4, \"bootstrap mailbox allocation failed\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (sli4->bmbx.phys & SLI4_BMBX_MASK_LO) {\n\t\tefc_log_err(sli4, \"bad alignment for bootstrap mailbox\\n\");\n\t\treturn -EIO;\n\t}\n\n\tefc_log_info(sli4, \"bmbx v=%p p=0x%x %08x s=%zd\\n\", sli4->bmbx.virt,\n\t\t     upper_32_bits(sli4->bmbx.phys),\n\t\t     lower_32_bits(sli4->bmbx.phys), sli4->bmbx.size);\n\n\t \n\tsli4->vpd_data.size = 4096;\n\tsli4->vpd_data.virt = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t\t sli4->vpd_data.size,\n\t\t\t\t\t\t &sli4->vpd_data.phys,\n\t\t\t\t\t\t GFP_KERNEL);\n\tif (!sli4->vpd_data.virt) {\n\t\tmemset(&sli4->vpd_data, 0, sizeof(struct efc_dma));\n\t\t \n\t\tefc_log_info(sli4, \"VPD buffer allocation failed\\n\");\n\t}\n\n\tif (!sli_fw_init(sli4)) {\n\t\tefc_log_err(sli4, \"FW initialization failed\\n\");\n\t\treturn -EIO;\n\t}\n\n\t \n\tsli4->features = (SLI4_REQFEAT_IAAB | SLI4_REQFEAT_NPIV |\n\t\t\t\t SLI4_REQFEAT_DIF | SLI4_REQFEAT_VF |\n\t\t\t\t SLI4_REQFEAT_FCPC | SLI4_REQFEAT_IAAR |\n\t\t\t\t SLI4_REQFEAT_HLM | SLI4_REQFEAT_PERFH |\n\t\t\t\t SLI4_REQFEAT_RXSEQ | SLI4_REQFEAT_RXRI |\n\t\t\t\t SLI4_REQFEAT_MRQP);\n\n\t \n\tif (sli4->params.perf_hint)\n\t\tsli4->features |= SLI4_REQFEAT_PERFH;\n\n\tif (sli_request_features(sli4, &sli4->features, true))\n\t\treturn -EIO;\n\n\tif (sli_get_config(sli4))\n\t\treturn -EIO;\n\n\treturn 0;\n}\n\nint\nsli_init(struct sli4 *sli4)\n{\n\tif (sli4->params.has_extents) {\n\t\tefc_log_info(sli4, \"extend allocation not supported\\n\");\n\t\treturn -EIO;\n\t}\n\n\tsli4->features &= (~SLI4_REQFEAT_HLM);\n\tsli4->features &= (~SLI4_REQFEAT_RXSEQ);\n\tsli4->features &= (~SLI4_REQFEAT_RXRI);\n\n\tif (sli_request_features(sli4, &sli4->features, false))\n\t\treturn -EIO;\n\n\treturn 0;\n}\n\nint\nsli_reset(struct sli4 *sli4)\n{\n\tu32\ti;\n\n\tif (!sli_fw_init(sli4)) {\n\t\tefc_log_crit(sli4, \"FW initialization failed\\n\");\n\t\treturn -EIO;\n\t}\n\n\tkfree(sli4->ext[0].base);\n\tsli4->ext[0].base = NULL;\n\n\tfor (i = 0; i < SLI4_RSRC_MAX; i++) {\n\t\tbitmap_free(sli4->ext[i].use_map);\n\t\tsli4->ext[i].use_map = NULL;\n\t\tsli4->ext[i].base = NULL;\n\t}\n\n\treturn sli_get_config(sli4);\n}\n\nint\nsli_fw_reset(struct sli4 *sli4)\n{\n\t \n\tif (!sli_wait_for_fw_ready(sli4, SLI4_FW_READY_TIMEOUT_MSEC)) {\n\t\tefc_log_crit(sli4, \"FW status is NOT ready\\n\");\n\t\treturn -EIO;\n\t}\n\n\t \n\twritel(SLI4_PHYDEV_CTRL_FRST, (sli4->reg[0] + SLI4_PHYDEV_CTRL_REG));\n\n\t \n\tif (!sli_wait_for_fw_ready(sli4, SLI4_FW_READY_TIMEOUT_MSEC)) {\n\t\tefc_log_crit(sli4, \"Failed to be ready after firmware reset\\n\");\n\t\treturn -EIO;\n\t}\n\treturn 0;\n}\n\nvoid\nsli_teardown(struct sli4 *sli4)\n{\n\tu32 i;\n\n\tkfree(sli4->ext[0].base);\n\tsli4->ext[0].base = NULL;\n\n\tfor (i = 0; i < SLI4_RSRC_MAX; i++) {\n\t\tsli4->ext[i].base = NULL;\n\n\t\tbitmap_free(sli4->ext[i].use_map);\n\t\tsli4->ext[i].use_map = NULL;\n\t}\n\n\tif (!sli_sliport_reset(sli4))\n\t\tefc_log_err(sli4, \"FW deinitialization failed\\n\");\n\n\tdma_free_coherent(&sli4->pci->dev, sli4->vpd_data.size,\n\t\t\t  sli4->vpd_data.virt, sli4->vpd_data.phys);\n\tmemset(&sli4->vpd_data, 0, sizeof(struct efc_dma));\n\n\tdma_free_coherent(&sli4->pci->dev, sli4->bmbx.size,\n\t\t\t  sli4->bmbx.virt, sli4->bmbx.phys);\n\tmemset(&sli4->bmbx, 0, sizeof(struct efc_dma));\n}\n\nint\nsli_callback(struct sli4 *sli4, enum sli4_callback which,\n\t     void *func, void *arg)\n{\n\tif (!func) {\n\t\tefc_log_err(sli4, \"bad parameter sli4=%p which=%#x func=%p\\n\",\n\t\t\t    sli4, which, func);\n\t\treturn -EIO;\n\t}\n\n\tswitch (which) {\n\tcase SLI4_CB_LINK:\n\t\tsli4->link = func;\n\t\tsli4->link_arg = arg;\n\t\tbreak;\n\tdefault:\n\t\tefc_log_info(sli4, \"unknown callback %#x\\n\", which);\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nint\nsli_eq_modify_delay(struct sli4 *sli4, struct sli4_queue *eq,\n\t\t    u32 num_eq, u32 shift, u32 delay_mult)\n{\n\tsli_cmd_common_modify_eq_delay(sli4, sli4->bmbx.virt, eq, num_eq,\n\t\t\t\t       shift, delay_mult);\n\n\tif (sli_bmbx_command(sli4)) {\n\t\tefc_log_crit(sli4, \"bootstrap mailbox write fail (MODIFY EQ DELAY)\\n\");\n\t\treturn -EIO;\n\t}\n\tif (sli_res_sli_config(sli4, sli4->bmbx.virt)) {\n\t\tefc_log_err(sli4, \"bad status MODIFY EQ DELAY\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nint\nsli_resource_alloc(struct sli4 *sli4, enum sli4_resource rtype,\n\t\t   u32 *rid, u32 *index)\n{\n\tint rc = 0;\n\tu32 size;\n\tu32 ext_idx;\n\tu32 item_idx;\n\tu32 position;\n\n\t*rid = U32_MAX;\n\t*index = U32_MAX;\n\n\tswitch (rtype) {\n\tcase SLI4_RSRC_VFI:\n\tcase SLI4_RSRC_VPI:\n\tcase SLI4_RSRC_RPI:\n\tcase SLI4_RSRC_XRI:\n\t\tposition =\n\t\tfind_first_zero_bit(sli4->ext[rtype].use_map,\n\t\t\t\t    sli4->ext[rtype].map_size);\n\t\tif (position >= sli4->ext[rtype].map_size) {\n\t\t\tefc_log_err(sli4, \"out of resource %d (alloc=%d)\\n\",\n\t\t\t\t    rtype, sli4->ext[rtype].n_alloc);\n\t\t\trc = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tset_bit(position, sli4->ext[rtype].use_map);\n\t\t*index = position;\n\n\t\tsize = sli4->ext[rtype].size;\n\n\t\text_idx = *index / size;\n\t\titem_idx   = *index % size;\n\n\t\t*rid = sli4->ext[rtype].base[ext_idx] + item_idx;\n\n\t\tsli4->ext[rtype].n_alloc++;\n\t\tbreak;\n\tdefault:\n\t\trc = -EIO;\n\t}\n\n\treturn rc;\n}\n\nint\nsli_resource_free(struct sli4 *sli4, enum sli4_resource rtype, u32 rid)\n{\n\tint rc = -EIO;\n\tu32 x;\n\tu32 size, *base;\n\n\tswitch (rtype) {\n\tcase SLI4_RSRC_VFI:\n\tcase SLI4_RSRC_VPI:\n\tcase SLI4_RSRC_RPI:\n\tcase SLI4_RSRC_XRI:\n\t\t \n\t\tbase = sli4->ext[rtype].base;\n\t\tsize = sli4->ext[rtype].size;\n\n\t\t \n\t\tif (!base)\n\t\t\tbreak;\n\n\t\tfor (x = 0; x < sli4->ext[rtype].number; x++) {\n\t\t\tif ((rid < base[x] || (rid >= (base[x] + size))))\n\t\t\t\tcontinue;\n\n\t\t\trid -= base[x];\n\t\t\tclear_bit((x * size) + rid, sli4->ext[rtype].use_map);\n\t\t\trc = 0;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn rc;\n}\n\nint\nsli_resource_reset(struct sli4 *sli4, enum sli4_resource rtype)\n{\n\tint rc = -EIO;\n\tu32 i;\n\n\tswitch (rtype) {\n\tcase SLI4_RSRC_VFI:\n\tcase SLI4_RSRC_VPI:\n\tcase SLI4_RSRC_RPI:\n\tcase SLI4_RSRC_XRI:\n\t\tfor (i = 0; i < sli4->ext[rtype].map_size; i++)\n\t\t\tclear_bit(i, sli4->ext[rtype].use_map);\n\t\trc = 0;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn rc;\n}\n\nint sli_raise_ue(struct sli4 *sli4, u8 dump)\n{\n\tu32 val = 0;\n\n\tif (dump == SLI4_FUNC_DESC_DUMP) {\n\t\tval = SLI4_PORT_CTRL_FDD | SLI4_PORT_CTRL_IP;\n\t\twritel(val, (sli4->reg[0] + SLI4_PORT_CTRL_REG));\n\t} else {\n\t\tval = SLI4_PHYDEV_CTRL_FRST;\n\n\t\tif (dump == SLI4_CHIP_LEVEL_DUMP)\n\t\t\tval |= SLI4_PHYDEV_CTRL_DD;\n\t\twritel(val, (sli4->reg[0] + SLI4_PHYDEV_CTRL_REG));\n\t}\n\n\treturn 0;\n}\n\nint sli_dump_is_ready(struct sli4 *sli4)\n{\n\tint rc = SLI4_DUMP_READY_STATUS_NOT_READY;\n\tu32 port_val;\n\tu32 bmbx_val;\n\n\t \n\tport_val = sli_reg_read_status(sli4);\n\tbmbx_val = readl(sli4->reg[0] + SLI4_BMBX_REG);\n\n\tif ((bmbx_val & SLI4_BMBX_RDY) &&\n\t    (port_val & SLI4_PORT_STATUS_RDY)) {\n\t\tif (port_val & SLI4_PORT_STATUS_DIP)\n\t\t\trc = SLI4_DUMP_READY_STATUS_DD_PRESENT;\n\t\telse if (port_val & SLI4_PORT_STATUS_FDP)\n\t\t\trc = SLI4_DUMP_READY_STATUS_FDB_PRESENT;\n\t}\n\n\treturn rc;\n}\n\nbool sli_reset_required(struct sli4 *sli4)\n{\n\tu32 val;\n\n\tval = sli_reg_read_status(sli4);\n\treturn (val & SLI4_PORT_STATUS_RN);\n}\n\nint\nsli_cmd_post_sgl_pages(struct sli4 *sli4, void *buf, u16 xri,\n\t\t       u32 xri_count, struct efc_dma *page0[],\n\t\t       struct efc_dma *page1[], struct efc_dma *dma)\n{\n\tstruct sli4_rqst_post_sgl_pages *post = NULL;\n\tu32 i;\n\t__le32 req_len;\n\n\tpost = sli_config_cmd_init(sli4, buf,\n\t\t\t\t   SLI4_CFG_PYLD_LENGTH(post_sgl_pages), dma);\n\tif (!post)\n\t\treturn -EIO;\n\n\t \n\t \n\t \n\t \n\t \n\treq_len = cpu_to_le32(4 + (xri_count * (sizeof(uint64_t) * 2)));\n\tsli_cmd_fill_hdr(&post->hdr, SLI4_OPC_POST_SGL_PAGES, SLI4_SUBSYSTEM_FC,\n\t\t\t CMD_V0, req_len);\n\tpost->xri_start = cpu_to_le16(xri);\n\tpost->xri_count = cpu_to_le16(xri_count);\n\n\tfor (i = 0; i < xri_count; i++) {\n\t\tpost->page_set[i].page0_low  =\n\t\t\t\tcpu_to_le32(lower_32_bits(page0[i]->phys));\n\t\tpost->page_set[i].page0_high =\n\t\t\t\tcpu_to_le32(upper_32_bits(page0[i]->phys));\n\t}\n\n\tif (page1) {\n\t\tfor (i = 0; i < xri_count; i++) {\n\t\t\tpost->page_set[i].page1_low =\n\t\t\t\tcpu_to_le32(lower_32_bits(page1[i]->phys));\n\t\t\tpost->page_set[i].page1_high =\n\t\t\t\tcpu_to_le32(upper_32_bits(page1[i]->phys));\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint\nsli_cmd_post_hdr_templates(struct sli4 *sli4, void *buf, struct efc_dma *dma,\n\t\t\t   u16 rpi, struct efc_dma *payload_dma)\n{\n\tstruct sli4_rqst_post_hdr_templates *req = NULL;\n\tuintptr_t phys = 0;\n\tu32 i = 0;\n\tu32 page_count, payload_size;\n\n\tpage_count = sli_page_count(dma->size, SLI_PAGE_SIZE);\n\n\tpayload_size = ((sizeof(struct sli4_rqst_post_hdr_templates) +\n\t\t(page_count * SZ_DMAADDR)) - sizeof(struct sli4_rqst_hdr));\n\n\tif (page_count > 16) {\n\t\t \n\t\tpayload_dma->size = payload_size;\n\t\tpayload_dma->virt = dma_alloc_coherent(&sli4->pci->dev,\n\t\t\t\t\t\t       payload_dma->size,\n\t\t\t\t\t     &payload_dma->phys, GFP_KERNEL);\n\t\tif (!payload_dma->virt) {\n\t\t\tmemset(payload_dma, 0, sizeof(struct efc_dma));\n\t\t\tefc_log_err(sli4, \"mbox payload memory allocation fail\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\treq = sli_config_cmd_init(sli4, buf, payload_size, payload_dma);\n\t} else {\n\t\treq = sli_config_cmd_init(sli4, buf, payload_size, NULL);\n\t}\n\n\tif (!req)\n\t\treturn -EIO;\n\n\tif (rpi == U16_MAX)\n\t\trpi = sli4->ext[SLI4_RSRC_RPI].base[0];\n\n\tsli_cmd_fill_hdr(&req->hdr, SLI4_OPC_POST_HDR_TEMPLATES,\n\t\t\t SLI4_SUBSYSTEM_FC, CMD_V0,\n\t\t\t SLI4_RQST_PYLD_LEN(post_hdr_templates));\n\n\treq->rpi_offset = cpu_to_le16(rpi);\n\treq->page_count = cpu_to_le16(page_count);\n\tphys = dma->phys;\n\tfor (i = 0; i < page_count; i++) {\n\t\treq->page_descriptor[i].low  = cpu_to_le32(lower_32_bits(phys));\n\t\treq->page_descriptor[i].high = cpu_to_le32(upper_32_bits(phys));\n\n\t\tphys += SLI_PAGE_SIZE;\n\t}\n\n\treturn 0;\n}\n\nu32\nsli_fc_get_rpi_requirements(struct sli4 *sli4, u32 n_rpi)\n{\n\tu32 bytes = 0;\n\n\t \n\tif (sli4->params.hdr_template_req)\n\t\t \n\t\tbytes = round_up(n_rpi * SLI4_HDR_TEMPLATE_SIZE, SLI_PAGE_SIZE);\n\n\treturn bytes;\n}\n\nconst char *\nsli_fc_get_status_string(u32 status)\n{\n\tstatic struct {\n\t\tu32 code;\n\t\tconst char *label;\n\t} lookup[] = {\n\t\t{SLI4_FC_WCQE_STATUS_SUCCESS,\t\t\"SUCCESS\"},\n\t\t{SLI4_FC_WCQE_STATUS_FCP_RSP_FAILURE,\t\"FCP_RSP_FAILURE\"},\n\t\t{SLI4_FC_WCQE_STATUS_REMOTE_STOP,\t\"REMOTE_STOP\"},\n\t\t{SLI4_FC_WCQE_STATUS_LOCAL_REJECT,\t\"LOCAL_REJECT\"},\n\t\t{SLI4_FC_WCQE_STATUS_NPORT_RJT,\t\t\"NPORT_RJT\"},\n\t\t{SLI4_FC_WCQE_STATUS_FABRIC_RJT,\t\"FABRIC_RJT\"},\n\t\t{SLI4_FC_WCQE_STATUS_NPORT_BSY,\t\t\"NPORT_BSY\"},\n\t\t{SLI4_FC_WCQE_STATUS_FABRIC_BSY,\t\"FABRIC_BSY\"},\n\t\t{SLI4_FC_WCQE_STATUS_LS_RJT,\t\t\"LS_RJT\"},\n\t\t{SLI4_FC_WCQE_STATUS_CMD_REJECT,\t\"CMD_REJECT\"},\n\t\t{SLI4_FC_WCQE_STATUS_FCP_TGT_LENCHECK,\t\"FCP_TGT_LENCHECK\"},\n\t\t{SLI4_FC_WCQE_STATUS_RQ_BUF_LEN_EXCEEDED, \"BUF_LEN_EXCEEDED\"},\n\t\t{SLI4_FC_WCQE_STATUS_RQ_INSUFF_BUF_NEEDED,\n\t\t\t\t\"RQ_INSUFF_BUF_NEEDED\"},\n\t\t{SLI4_FC_WCQE_STATUS_RQ_INSUFF_FRM_DISC, \"RQ_INSUFF_FRM_DESC\"},\n\t\t{SLI4_FC_WCQE_STATUS_RQ_DMA_FAILURE,\t\"RQ_DMA_FAILURE\"},\n\t\t{SLI4_FC_WCQE_STATUS_FCP_RSP_TRUNCATE,\t\"FCP_RSP_TRUNCATE\"},\n\t\t{SLI4_FC_WCQE_STATUS_DI_ERROR,\t\t\"DI_ERROR\"},\n\t\t{SLI4_FC_WCQE_STATUS_BA_RJT,\t\t\"BA_RJT\"},\n\t\t{SLI4_FC_WCQE_STATUS_RQ_INSUFF_XRI_NEEDED,\n\t\t\t\t\"RQ_INSUFF_XRI_NEEDED\"},\n\t\t{SLI4_FC_WCQE_STATUS_RQ_INSUFF_XRI_DISC, \"INSUFF_XRI_DISC\"},\n\t\t{SLI4_FC_WCQE_STATUS_RX_ERROR_DETECT,\t\"RX_ERROR_DETECT\"},\n\t\t{SLI4_FC_WCQE_STATUS_RX_ABORT_REQUEST,\t\"RX_ABORT_REQUEST\"},\n\t\t};\n\tu32 i;\n\n\tfor (i = 0; i < ARRAY_SIZE(lookup); i++) {\n\t\tif (status == lookup[i].code)\n\t\t\treturn lookup[i].label;\n\t}\n\treturn \"unknown\";\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}