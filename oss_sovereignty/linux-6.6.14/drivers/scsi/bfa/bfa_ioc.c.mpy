{
  "module_name": "bfa_ioc.c",
  "hash_id": "df5e3b47a56b0424dc5848acd9abc7d59e26f312a8327f84804fbb7e054f7ac3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/bfa/bfa_ioc.c",
  "human_readable_source": "\n \n\n#include \"bfad_drv.h\"\n#include \"bfad_im.h\"\n#include \"bfa_ioc.h\"\n#include \"bfi_reg.h\"\n#include \"bfa_defs.h\"\n#include \"bfa_defs_svc.h\"\n#include \"bfi.h\"\n\nBFA_TRC_FILE(CNA, IOC);\n\n \n#define BFA_IOC_TOV\t\t3000\t \n#define BFA_IOC_HWSEM_TOV\t500\t \n#define BFA_IOC_HB_TOV\t\t500\t \n#define BFA_IOC_TOV_RECOVER\t BFA_IOC_HB_TOV\n#define BFA_IOC_POLL_TOV\tBFA_TIMER_FREQ\n\n#define bfa_ioc_timer_start(__ioc)\t\t\t\t\t\\\n\tbfa_timer_begin((__ioc)->timer_mod, &(__ioc)->ioc_timer,\t\\\n\t\t\tbfa_ioc_timeout, (__ioc), BFA_IOC_TOV)\n#define bfa_ioc_timer_stop(__ioc)   bfa_timer_stop(&(__ioc)->ioc_timer)\n\n#define bfa_hb_timer_start(__ioc)\t\t\t\t\t\\\n\tbfa_timer_begin((__ioc)->timer_mod, &(__ioc)->hb_timer,\t\t\\\n\t\t\tbfa_ioc_hb_check, (__ioc), BFA_IOC_HB_TOV)\n#define bfa_hb_timer_stop(__ioc)\tbfa_timer_stop(&(__ioc)->hb_timer)\n\n#define BFA_DBG_FWTRC_OFF(_fn)\t(BFI_IOC_TRC_OFF + BFA_DBG_FWTRC_LEN * (_fn))\n\n#define bfa_ioc_state_disabled(__sm)\t\t\\\n\t(((__sm) == BFI_IOC_UNINIT) ||\t\t\\\n\t((__sm) == BFI_IOC_INITING) ||\t\t\\\n\t((__sm) == BFI_IOC_HWINIT) ||\t\t\\\n\t((__sm) == BFI_IOC_DISABLED) ||\t\t\\\n\t((__sm) == BFI_IOC_FAIL) ||\t\t\\\n\t((__sm) == BFI_IOC_CFG_DISABLED))\n\n \n\n#define bfa_ioc_firmware_lock(__ioc)\t\t\t\\\n\t\t\t((__ioc)->ioc_hwif->ioc_firmware_lock(__ioc))\n#define bfa_ioc_firmware_unlock(__ioc)\t\t\t\\\n\t\t\t((__ioc)->ioc_hwif->ioc_firmware_unlock(__ioc))\n#define bfa_ioc_reg_init(__ioc) ((__ioc)->ioc_hwif->ioc_reg_init(__ioc))\n#define bfa_ioc_map_port(__ioc) ((__ioc)->ioc_hwif->ioc_map_port(__ioc))\n#define bfa_ioc_notify_fail(__ioc)              \\\n\t\t\t((__ioc)->ioc_hwif->ioc_notify_fail(__ioc))\n#define bfa_ioc_sync_start(__ioc)               \\\n\t\t\t((__ioc)->ioc_hwif->ioc_sync_start(__ioc))\n#define bfa_ioc_sync_join(__ioc)                \\\n\t\t\t((__ioc)->ioc_hwif->ioc_sync_join(__ioc))\n#define bfa_ioc_sync_leave(__ioc)               \\\n\t\t\t((__ioc)->ioc_hwif->ioc_sync_leave(__ioc))\n#define bfa_ioc_sync_ack(__ioc)                 \\\n\t\t\t((__ioc)->ioc_hwif->ioc_sync_ack(__ioc))\n#define bfa_ioc_sync_complete(__ioc)            \\\n\t\t\t((__ioc)->ioc_hwif->ioc_sync_complete(__ioc))\n#define bfa_ioc_set_cur_ioc_fwstate(__ioc, __fwstate)\t\t\\\n\t\t\t((__ioc)->ioc_hwif->ioc_set_fwstate(__ioc, __fwstate))\n#define bfa_ioc_get_cur_ioc_fwstate(__ioc)\t\t\\\n\t\t\t((__ioc)->ioc_hwif->ioc_get_fwstate(__ioc))\n#define bfa_ioc_set_alt_ioc_fwstate(__ioc, __fwstate)\t\t\\\n\t\t((__ioc)->ioc_hwif->ioc_set_alt_fwstate(__ioc, __fwstate))\n#define bfa_ioc_get_alt_ioc_fwstate(__ioc)\t\t\\\n\t\t\t((__ioc)->ioc_hwif->ioc_get_alt_fwstate(__ioc))\n\n#define bfa_ioc_mbox_cmd_pending(__ioc)\t\t\\\n\t\t\t(!list_empty(&((__ioc)->mbox_mod.cmd_q)) || \\\n\t\t\treadl((__ioc)->ioc_regs.hfn_mbox_cmd))\n\nbfa_boolean_t bfa_auto_recover = BFA_TRUE;\n\n \nstatic void bfa_ioc_hw_sem_get(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_hwinit(struct bfa_ioc_s *ioc, bfa_boolean_t force);\nstatic void bfa_ioc_timeout(void *ioc);\nstatic void bfa_ioc_poll_fwinit(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_send_enable(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_send_disable(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_send_getattr(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_hb_monitor(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_mbox_poll(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_mbox_flush(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_recover(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_event_notify(struct bfa_ioc_s *ioc ,\n\t\t\t\tenum bfa_ioc_event_e event);\nstatic void bfa_ioc_disable_comp(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_lpu_stop(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_fail_notify(struct bfa_ioc_s *ioc);\nstatic void bfa_ioc_pf_fwmismatch(struct bfa_ioc_s *ioc);\nstatic enum bfi_ioc_img_ver_cmp_e bfa_ioc_fw_ver_patch_cmp(\n\t\t\t\tstruct bfi_ioc_image_hdr_s *base_fwhdr,\n\t\t\t\tstruct bfi_ioc_image_hdr_s *fwhdr_to_cmp);\nstatic enum bfi_ioc_img_ver_cmp_e bfa_ioc_flash_fwver_cmp(\n\t\t\t\tstruct bfa_ioc_s *ioc,\n\t\t\t\tstruct bfi_ioc_image_hdr_s *base_fwhdr);\n\n \nenum ioc_event {\n\tIOC_E_RESET\t\t= 1,\t \n\tIOC_E_ENABLE\t\t= 2,\t \n\tIOC_E_DISABLE\t\t= 3,\t \n\tIOC_E_DETACH\t\t= 4,\t \n\tIOC_E_ENABLED\t\t= 5,\t \n\tIOC_E_FWRSP_GETATTR\t= 6,\t \n\tIOC_E_DISABLED\t\t= 7,\t \n\tIOC_E_PFFAILED\t\t= 8,\t \n\tIOC_E_HBFAIL\t\t= 9,\t \n\tIOC_E_HWERROR\t\t= 10,\t \n\tIOC_E_TIMEOUT\t\t= 11,\t \n\tIOC_E_HWFAILED\t\t= 12,\t \n};\n\nbfa_fsm_state_decl(bfa_ioc, uninit, struct bfa_ioc_s, enum ioc_event);\nbfa_fsm_state_decl(bfa_ioc, reset, struct bfa_ioc_s, enum ioc_event);\nbfa_fsm_state_decl(bfa_ioc, enabling, struct bfa_ioc_s, enum ioc_event);\nbfa_fsm_state_decl(bfa_ioc, getattr, struct bfa_ioc_s, enum ioc_event);\nbfa_fsm_state_decl(bfa_ioc, op, struct bfa_ioc_s, enum ioc_event);\nbfa_fsm_state_decl(bfa_ioc, fail_retry, struct bfa_ioc_s, enum ioc_event);\nbfa_fsm_state_decl(bfa_ioc, fail, struct bfa_ioc_s, enum ioc_event);\nbfa_fsm_state_decl(bfa_ioc, disabling, struct bfa_ioc_s, enum ioc_event);\nbfa_fsm_state_decl(bfa_ioc, disabled, struct bfa_ioc_s, enum ioc_event);\nbfa_fsm_state_decl(bfa_ioc, hwfail, struct bfa_ioc_s, enum ioc_event);\n\nstatic struct bfa_sm_table_s ioc_sm_table[] = {\n\t{BFA_SM(bfa_ioc_sm_uninit), BFA_IOC_UNINIT},\n\t{BFA_SM(bfa_ioc_sm_reset), BFA_IOC_RESET},\n\t{BFA_SM(bfa_ioc_sm_enabling), BFA_IOC_ENABLING},\n\t{BFA_SM(bfa_ioc_sm_getattr), BFA_IOC_GETATTR},\n\t{BFA_SM(bfa_ioc_sm_op), BFA_IOC_OPERATIONAL},\n\t{BFA_SM(bfa_ioc_sm_fail_retry), BFA_IOC_INITFAIL},\n\t{BFA_SM(bfa_ioc_sm_fail), BFA_IOC_FAIL},\n\t{BFA_SM(bfa_ioc_sm_disabling), BFA_IOC_DISABLING},\n\t{BFA_SM(bfa_ioc_sm_disabled), BFA_IOC_DISABLED},\n\t{BFA_SM(bfa_ioc_sm_hwfail), BFA_IOC_HWFAIL},\n};\n\n \n\n#define bfa_iocpf_timer_start(__ioc)\t\t\t\t\t\\\n\tbfa_timer_begin((__ioc)->timer_mod, &(__ioc)->ioc_timer,\t\\\n\t\t\tbfa_iocpf_timeout, (__ioc), BFA_IOC_TOV)\n#define bfa_iocpf_timer_stop(__ioc)\tbfa_timer_stop(&(__ioc)->ioc_timer)\n\n#define bfa_iocpf_poll_timer_start(__ioc)\t\t\t\t\\\n\tbfa_timer_begin((__ioc)->timer_mod, &(__ioc)->ioc_timer,\t\\\n\t\t\tbfa_iocpf_poll_timeout, (__ioc), BFA_IOC_POLL_TOV)\n\n#define bfa_sem_timer_start(__ioc)\t\t\t\t\t\\\n\tbfa_timer_begin((__ioc)->timer_mod, &(__ioc)->sem_timer,\t\\\n\t\t\tbfa_iocpf_sem_timeout, (__ioc), BFA_IOC_HWSEM_TOV)\n#define bfa_sem_timer_stop(__ioc)\tbfa_timer_stop(&(__ioc)->sem_timer)\n\n \nstatic void bfa_iocpf_timeout(void *ioc_arg);\nstatic void bfa_iocpf_sem_timeout(void *ioc_arg);\nstatic void bfa_iocpf_poll_timeout(void *ioc_arg);\n\n \nenum iocpf_event {\n\tIOCPF_E_ENABLE\t\t= 1,\t \n\tIOCPF_E_DISABLE\t\t= 2,\t \n\tIOCPF_E_STOP\t\t= 3,\t \n\tIOCPF_E_FWREADY\t\t= 4,\t \n\tIOCPF_E_FWRSP_ENABLE\t= 5,\t \n\tIOCPF_E_FWRSP_DISABLE\t= 6,\t \n\tIOCPF_E_FAIL\t\t= 7,\t \n\tIOCPF_E_INITFAIL\t= 8,\t \n\tIOCPF_E_GETATTRFAIL\t= 9,\t \n\tIOCPF_E_SEMLOCKED\t= 10,\t \n\tIOCPF_E_TIMEOUT\t\t= 11,\t \n\tIOCPF_E_SEM_ERROR\t= 12,\t \n};\n\n \nenum bfa_iocpf_state {\n\tBFA_IOCPF_RESET\t\t= 1,\t \n\tBFA_IOCPF_SEMWAIT\t= 2,\t \n\tBFA_IOCPF_HWINIT\t= 3,\t \n\tBFA_IOCPF_READY\t\t= 4,\t \n\tBFA_IOCPF_INITFAIL\t= 5,\t \n\tBFA_IOCPF_FAIL\t\t= 6,\t \n\tBFA_IOCPF_DISABLING\t= 7,\t \n\tBFA_IOCPF_DISABLED\t= 8,\t \n\tBFA_IOCPF_FWMISMATCH\t= 9,\t \n};\n\nbfa_fsm_state_decl(bfa_iocpf, reset, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, fwcheck, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, mismatch, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, semwait, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, hwinit, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, enabling, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, ready, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, initfail_sync, struct bfa_iocpf_s,\n\t\t\t\t\t\tenum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, initfail, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, fail_sync, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, fail, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, disabling, struct bfa_iocpf_s, enum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, disabling_sync, struct bfa_iocpf_s,\n\t\t\t\t\t\tenum iocpf_event);\nbfa_fsm_state_decl(bfa_iocpf, disabled, struct bfa_iocpf_s, enum iocpf_event);\n\nstatic struct bfa_sm_table_s iocpf_sm_table[] = {\n\t{BFA_SM(bfa_iocpf_sm_reset), BFA_IOCPF_RESET},\n\t{BFA_SM(bfa_iocpf_sm_fwcheck), BFA_IOCPF_FWMISMATCH},\n\t{BFA_SM(bfa_iocpf_sm_mismatch), BFA_IOCPF_FWMISMATCH},\n\t{BFA_SM(bfa_iocpf_sm_semwait), BFA_IOCPF_SEMWAIT},\n\t{BFA_SM(bfa_iocpf_sm_hwinit), BFA_IOCPF_HWINIT},\n\t{BFA_SM(bfa_iocpf_sm_enabling), BFA_IOCPF_HWINIT},\n\t{BFA_SM(bfa_iocpf_sm_ready), BFA_IOCPF_READY},\n\t{BFA_SM(bfa_iocpf_sm_initfail_sync), BFA_IOCPF_INITFAIL},\n\t{BFA_SM(bfa_iocpf_sm_initfail), BFA_IOCPF_INITFAIL},\n\t{BFA_SM(bfa_iocpf_sm_fail_sync), BFA_IOCPF_FAIL},\n\t{BFA_SM(bfa_iocpf_sm_fail), BFA_IOCPF_FAIL},\n\t{BFA_SM(bfa_iocpf_sm_disabling), BFA_IOCPF_DISABLING},\n\t{BFA_SM(bfa_iocpf_sm_disabling_sync), BFA_IOCPF_DISABLING},\n\t{BFA_SM(bfa_iocpf_sm_disabled), BFA_IOCPF_DISABLED},\n};\n\n \n\n \n\nstatic void\nbfa_ioc_sm_uninit_entry(struct bfa_ioc_s *ioc)\n{\n}\n\n \nstatic void\nbfa_ioc_sm_uninit(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOC_E_RESET:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_reset);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n \nstatic void\nbfa_ioc_sm_reset_entry(struct bfa_ioc_s *ioc)\n{\n\tbfa_fsm_set_state(&ioc->iocpf, bfa_iocpf_sm_reset);\n}\n\n \nstatic void\nbfa_ioc_sm_reset(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOC_E_ENABLE:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_enabling);\n\t\tbreak;\n\n\tcase IOC_E_DISABLE:\n\t\tbfa_ioc_disable_comp(ioc);\n\t\tbreak;\n\n\tcase IOC_E_DETACH:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_uninit);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n\nstatic void\nbfa_ioc_sm_enabling_entry(struct bfa_ioc_s *ioc)\n{\n\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_ENABLE);\n}\n\n \nstatic void\nbfa_ioc_sm_enabling(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOC_E_ENABLED:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_getattr);\n\t\tbreak;\n\n\tcase IOC_E_PFFAILED:\n\t\t \n\tcase IOC_E_HWERROR:\n\t\tioc->cbfn->enable_cbfn(ioc->bfa, BFA_STATUS_IOC_FAILURE);\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_fail);\n\t\tif (event != IOC_E_PFFAILED)\n\t\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_INITFAIL);\n\t\tbreak;\n\n\tcase IOC_E_HWFAILED:\n\t\tioc->cbfn->enable_cbfn(ioc->bfa, BFA_STATUS_IOC_FAILURE);\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_hwfail);\n\t\tbreak;\n\n\tcase IOC_E_DISABLE:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_disabling);\n\t\tbreak;\n\n\tcase IOC_E_DETACH:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_uninit);\n\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_STOP);\n\t\tbreak;\n\n\tcase IOC_E_ENABLE:\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n\nstatic void\nbfa_ioc_sm_getattr_entry(struct bfa_ioc_s *ioc)\n{\n\tbfa_ioc_timer_start(ioc);\n\tbfa_ioc_send_getattr(ioc);\n}\n\n \nstatic void\nbfa_ioc_sm_getattr(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOC_E_FWRSP_GETATTR:\n\t\tbfa_ioc_timer_stop(ioc);\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_op);\n\t\tbreak;\n\n\tcase IOC_E_PFFAILED:\n\tcase IOC_E_HWERROR:\n\t\tbfa_ioc_timer_stop(ioc);\n\t\tfallthrough;\n\tcase IOC_E_TIMEOUT:\n\t\tioc->cbfn->enable_cbfn(ioc->bfa, BFA_STATUS_IOC_FAILURE);\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_fail);\n\t\tif (event != IOC_E_PFFAILED)\n\t\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_GETATTRFAIL);\n\t\tbreak;\n\n\tcase IOC_E_DISABLE:\n\t\tbfa_ioc_timer_stop(ioc);\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_disabling);\n\t\tbreak;\n\n\tcase IOC_E_ENABLE:\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_ioc_sm_op_entry(struct bfa_ioc_s *ioc)\n{\n\tstruct bfad_s *bfad = (struct bfad_s *)ioc->bfa->bfad;\n\n\tioc->cbfn->enable_cbfn(ioc->bfa, BFA_STATUS_OK);\n\tbfa_ioc_event_notify(ioc, BFA_IOC_E_ENABLED);\n\tbfa_ioc_hb_monitor(ioc);\n\tBFA_LOG(KERN_INFO, bfad, bfa_log_level, \"IOC enabled\\n\");\n\tbfa_ioc_aen_post(ioc, BFA_IOC_AEN_ENABLE);\n}\n\nstatic void\nbfa_ioc_sm_op(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOC_E_ENABLE:\n\t\tbreak;\n\n\tcase IOC_E_DISABLE:\n\t\tbfa_hb_timer_stop(ioc);\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_disabling);\n\t\tbreak;\n\n\tcase IOC_E_PFFAILED:\n\tcase IOC_E_HWERROR:\n\t\tbfa_hb_timer_stop(ioc);\n\t\tfallthrough;\n\tcase IOC_E_HBFAIL:\n\t\tif (ioc->iocpf.auto_recover)\n\t\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_fail_retry);\n\t\telse\n\t\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_fail);\n\n\t\tbfa_ioc_fail_notify(ioc);\n\n\t\tif (event != IOC_E_PFFAILED)\n\t\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_FAIL);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n\nstatic void\nbfa_ioc_sm_disabling_entry(struct bfa_ioc_s *ioc)\n{\n\tstruct bfad_s *bfad = (struct bfad_s *)ioc->bfa->bfad;\n\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_DISABLE);\n\tBFA_LOG(KERN_INFO, bfad, bfa_log_level, \"IOC disabled\\n\");\n\tbfa_ioc_aen_post(ioc, BFA_IOC_AEN_DISABLE);\n}\n\n \nstatic void\nbfa_ioc_sm_disabling(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOC_E_DISABLED:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_disabled);\n\t\tbreak;\n\n\tcase IOC_E_HWERROR:\n\t\t \n\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_FAIL);\n\t\tbreak;\n\n\tcase IOC_E_HWFAILED:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_hwfail);\n\t\tbfa_ioc_disable_comp(ioc);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n \nstatic void\nbfa_ioc_sm_disabled_entry(struct bfa_ioc_s *ioc)\n{\n\tbfa_ioc_disable_comp(ioc);\n}\n\nstatic void\nbfa_ioc_sm_disabled(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOC_E_ENABLE:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_enabling);\n\t\tbreak;\n\n\tcase IOC_E_DISABLE:\n\t\tioc->cbfn->disable_cbfn(ioc->bfa);\n\t\tbreak;\n\n\tcase IOC_E_DETACH:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_uninit);\n\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_STOP);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n\nstatic void\nbfa_ioc_sm_fail_retry_entry(struct bfa_ioc_s *ioc)\n{\n\tbfa_trc(ioc, 0);\n}\n\n \nstatic void\nbfa_ioc_sm_fail_retry(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOC_E_ENABLED:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_getattr);\n\t\tbreak;\n\n\tcase IOC_E_PFFAILED:\n\tcase IOC_E_HWERROR:\n\t\t \n\t\tioc->cbfn->enable_cbfn(ioc->bfa, BFA_STATUS_IOC_FAILURE);\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_fail);\n\t\tif (event != IOC_E_PFFAILED)\n\t\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_INITFAIL);\n\t\tbreak;\n\n\tcase IOC_E_HWFAILED:\n\t\tioc->cbfn->enable_cbfn(ioc->bfa, BFA_STATUS_IOC_FAILURE);\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_hwfail);\n\t\tbreak;\n\n\tcase IOC_E_ENABLE:\n\t\tbreak;\n\n\tcase IOC_E_DISABLE:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_disabling);\n\t\tbreak;\n\n\tcase IOC_E_DETACH:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_uninit);\n\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_STOP);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n\nstatic void\nbfa_ioc_sm_fail_entry(struct bfa_ioc_s *ioc)\n{\n\tbfa_trc(ioc, 0);\n}\n\n \nstatic void\nbfa_ioc_sm_fail(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\n\tcase IOC_E_ENABLE:\n\t\tioc->cbfn->enable_cbfn(ioc->bfa, BFA_STATUS_IOC_FAILURE);\n\t\tbreak;\n\n\tcase IOC_E_DISABLE:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_disabling);\n\t\tbreak;\n\n\tcase IOC_E_DETACH:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_uninit);\n\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_STOP);\n\t\tbreak;\n\n\tcase IOC_E_HWERROR:\n\tcase IOC_E_HWFAILED:\n\t\t \n\t\tbreak;\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_ioc_sm_hwfail_entry(struct bfa_ioc_s *ioc)\n{\n\tbfa_trc(ioc, 0);\n}\n\nstatic void\nbfa_ioc_sm_hwfail(struct bfa_ioc_s *ioc, enum ioc_event event)\n{\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOC_E_ENABLE:\n\t\tioc->cbfn->enable_cbfn(ioc->bfa, BFA_STATUS_IOC_FAILURE);\n\t\tbreak;\n\n\tcase IOC_E_DISABLE:\n\t\tioc->cbfn->disable_cbfn(ioc->bfa);\n\t\tbreak;\n\n\tcase IOC_E_DETACH:\n\t\tbfa_fsm_set_state(ioc, bfa_ioc_sm_uninit);\n\t\tbreak;\n\n\tcase IOC_E_HWERROR:\n\t\t \n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n \n\n \nstatic void\nbfa_iocpf_sm_reset_entry(struct bfa_iocpf_s *iocpf)\n{\n\tiocpf->fw_mismatch_notified = BFA_FALSE;\n\tiocpf->auto_recover = bfa_auto_recover;\n}\n\n \nstatic void\nbfa_iocpf_sm_reset(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_ENABLE:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_fwcheck);\n\t\tbreak;\n\n\tcase IOCPF_E_STOP:\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n \nstatic void\nbfa_iocpf_sm_fwcheck_entry(struct bfa_iocpf_s *iocpf)\n{\n\tstruct bfi_ioc_image_hdr_s\tfwhdr;\n\tu32\tr32, fwstate, pgnum, loff = 0;\n\tint\ti;\n\n\t \n\tr32 = readl(iocpf->ioc->ioc_regs.ioc_init_sem_reg);\n\twhile (r32 & 0x1) {\n\t\tudelay(20);\n\t\tr32 = readl(iocpf->ioc->ioc_regs.ioc_init_sem_reg);\n\t}\n\n\t \n\tfwstate = bfa_ioc_get_cur_ioc_fwstate(iocpf->ioc);\n\tif (fwstate == BFI_IOC_UNINIT) {\n\t\twritel(1, iocpf->ioc->ioc_regs.ioc_init_sem_reg);\n\t\tgoto sem_get;\n\t}\n\n\tbfa_ioc_fwver_get(iocpf->ioc, &fwhdr);\n\n\tif (swab32(fwhdr.exec) == BFI_FWBOOT_TYPE_NORMAL) {\n\t\twritel(1, iocpf->ioc->ioc_regs.ioc_init_sem_reg);\n\t\tgoto sem_get;\n\t}\n\n\t \n\tpgnum = PSS_SMEM_PGNUM(iocpf->ioc->ioc_regs.smem_pg0, loff);\n\twritel(pgnum, iocpf->ioc->ioc_regs.host_page_num_fn);\n\n\tfor (i = 0; i < sizeof(struct bfi_ioc_image_hdr_s) / sizeof(u32); i++) {\n\t\tbfa_mem_write(iocpf->ioc->ioc_regs.smem_page_start, loff, 0);\n\t\tloff += sizeof(u32);\n\t}\n\n\tbfa_trc(iocpf->ioc, fwstate);\n\tbfa_trc(iocpf->ioc, swab32(fwhdr.exec));\n\tbfa_ioc_set_cur_ioc_fwstate(iocpf->ioc, BFI_IOC_UNINIT);\n\tbfa_ioc_set_alt_ioc_fwstate(iocpf->ioc, BFI_IOC_UNINIT);\n\n\t \n\tbfa_ioc_ownership_reset(iocpf->ioc);\n\n\t \n\twritel(1, iocpf->ioc->ioc_regs.ioc_init_sem_reg);\n\nsem_get:\n\tbfa_ioc_hw_sem_get(iocpf->ioc);\n}\n\n \nstatic void\nbfa_iocpf_sm_fwcheck(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_SEMLOCKED:\n\t\tif (bfa_ioc_firmware_lock(ioc)) {\n\t\t\tif (bfa_ioc_sync_start(ioc)) {\n\t\t\t\tbfa_ioc_sync_join(ioc);\n\t\t\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_hwinit);\n\t\t\t} else {\n\t\t\t\tbfa_ioc_firmware_unlock(ioc);\n\t\t\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\t\t\tbfa_sem_timer_start(ioc);\n\t\t\t}\n\t\t} else {\n\t\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_mismatch);\n\t\t}\n\t\tbreak;\n\n\tcase IOCPF_E_SEM_ERROR:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_fail);\n\t\tbfa_fsm_send_event(ioc, IOC_E_HWFAILED);\n\t\tbreak;\n\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_sem_timer_stop(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_reset);\n\t\tbfa_fsm_send_event(ioc, IOC_E_DISABLED);\n\t\tbreak;\n\n\tcase IOCPF_E_STOP:\n\t\tbfa_sem_timer_stop(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_reset);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n \nstatic void\nbfa_iocpf_sm_mismatch_entry(struct bfa_iocpf_s *iocpf)\n{\n\t \n\tif (iocpf->fw_mismatch_notified == BFA_FALSE)\n\t\tbfa_ioc_pf_fwmismatch(iocpf->ioc);\n\n\tiocpf->fw_mismatch_notified = BFA_TRUE;\n\tbfa_iocpf_timer_start(iocpf->ioc);\n}\n\n \nstatic void\nbfa_iocpf_sm_mismatch(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_TIMEOUT:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_fwcheck);\n\t\tbreak;\n\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_iocpf_timer_stop(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_reset);\n\t\tbfa_fsm_send_event(ioc, IOC_E_DISABLED);\n\t\tbreak;\n\n\tcase IOCPF_E_STOP:\n\t\tbfa_iocpf_timer_stop(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_reset);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n \nstatic void\nbfa_iocpf_sm_semwait_entry(struct bfa_iocpf_s *iocpf)\n{\n\tbfa_ioc_hw_sem_get(iocpf->ioc);\n}\n\n \nstatic void\nbfa_iocpf_sm_semwait(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_SEMLOCKED:\n\t\tif (bfa_ioc_sync_complete(ioc)) {\n\t\t\tbfa_ioc_sync_join(ioc);\n\t\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_hwinit);\n\t\t} else {\n\t\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\t\tbfa_sem_timer_start(ioc);\n\t\t}\n\t\tbreak;\n\n\tcase IOCPF_E_SEM_ERROR:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_fail);\n\t\tbfa_fsm_send_event(ioc, IOC_E_HWFAILED);\n\t\tbreak;\n\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_sem_timer_stop(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabling_sync);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_iocpf_sm_hwinit_entry(struct bfa_iocpf_s *iocpf)\n{\n\tiocpf->poll_time = 0;\n\tbfa_ioc_hwinit(iocpf->ioc, BFA_FALSE);\n}\n\n \nstatic void\nbfa_iocpf_sm_hwinit(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_FWREADY:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_enabling);\n\t\tbreak;\n\n\tcase IOCPF_E_TIMEOUT:\n\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\tbfa_fsm_send_event(ioc, IOC_E_PFFAILED);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_initfail_sync);\n\t\tbreak;\n\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_iocpf_timer_stop(ioc);\n\t\tbfa_ioc_sync_leave(ioc);\n\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabled);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_iocpf_sm_enabling_entry(struct bfa_iocpf_s *iocpf)\n{\n\tbfa_iocpf_timer_start(iocpf->ioc);\n\t \n\tiocpf->ioc->cbfn->reset_cbfn(iocpf->ioc->bfa);\n\tbfa_ioc_send_enable(iocpf->ioc);\n}\n\n \nstatic void\nbfa_iocpf_sm_enabling(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_FWRSP_ENABLE:\n\t\tbfa_iocpf_timer_stop(ioc);\n\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_ready);\n\t\tbreak;\n\n\tcase IOCPF_E_INITFAIL:\n\t\tbfa_iocpf_timer_stop(ioc);\n\t\tfallthrough;\n\n\tcase IOCPF_E_TIMEOUT:\n\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\tif (event == IOCPF_E_TIMEOUT)\n\t\t\tbfa_fsm_send_event(ioc, IOC_E_PFFAILED);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_initfail_sync);\n\t\tbreak;\n\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_iocpf_timer_stop(ioc);\n\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabling);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_iocpf_sm_ready_entry(struct bfa_iocpf_s *iocpf)\n{\n\tbfa_fsm_send_event(iocpf->ioc, IOC_E_ENABLED);\n}\n\nstatic void\nbfa_iocpf_sm_ready(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabling);\n\t\tbreak;\n\n\tcase IOCPF_E_GETATTRFAIL:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_initfail_sync);\n\t\tbreak;\n\n\tcase IOCPF_E_FAIL:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_fail_sync);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_iocpf_sm_disabling_entry(struct bfa_iocpf_s *iocpf)\n{\n\tbfa_iocpf_timer_start(iocpf->ioc);\n\tbfa_ioc_send_disable(iocpf->ioc);\n}\n\n \nstatic void\nbfa_iocpf_sm_disabling(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_FWRSP_DISABLE:\n\t\tbfa_iocpf_timer_stop(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabling_sync);\n\t\tbreak;\n\n\tcase IOCPF_E_FAIL:\n\t\tbfa_iocpf_timer_stop(ioc);\n\t\tfallthrough;\n\n\tcase IOCPF_E_TIMEOUT:\n\t\tbfa_ioc_set_cur_ioc_fwstate(ioc, BFI_IOC_FAIL);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabling_sync);\n\t\tbreak;\n\n\tcase IOCPF_E_FWRSP_ENABLE:\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_iocpf_sm_disabling_sync_entry(struct bfa_iocpf_s *iocpf)\n{\n\tbfa_ioc_hw_sem_get(iocpf->ioc);\n}\n\n \nstatic void\nbfa_iocpf_sm_disabling_sync(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_SEMLOCKED:\n\t\tbfa_ioc_sync_leave(ioc);\n\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabled);\n\t\tbreak;\n\n\tcase IOCPF_E_SEM_ERROR:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_fail);\n\t\tbfa_fsm_send_event(ioc, IOC_E_HWFAILED);\n\t\tbreak;\n\n\tcase IOCPF_E_FAIL:\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n \nstatic void\nbfa_iocpf_sm_disabled_entry(struct bfa_iocpf_s *iocpf)\n{\n\tbfa_ioc_mbox_flush(iocpf->ioc);\n\tbfa_fsm_send_event(iocpf->ioc, IOC_E_DISABLED);\n}\n\nstatic void\nbfa_iocpf_sm_disabled(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_ENABLE:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_semwait);\n\t\tbreak;\n\n\tcase IOCPF_E_STOP:\n\t\tbfa_ioc_firmware_unlock(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_reset);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_iocpf_sm_initfail_sync_entry(struct bfa_iocpf_s *iocpf)\n{\n\tbfa_ioc_debug_save_ftrc(iocpf->ioc);\n\tbfa_ioc_hw_sem_get(iocpf->ioc);\n}\n\n \nstatic void\nbfa_iocpf_sm_initfail_sync(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_SEMLOCKED:\n\t\tbfa_ioc_notify_fail(ioc);\n\t\tbfa_ioc_sync_leave(ioc);\n\t\tbfa_ioc_set_cur_ioc_fwstate(ioc, BFI_IOC_FAIL);\n\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_initfail);\n\t\tbreak;\n\n\tcase IOCPF_E_SEM_ERROR:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_fail);\n\t\tbfa_fsm_send_event(ioc, IOC_E_HWFAILED);\n\t\tbreak;\n\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_sem_timer_stop(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabling_sync);\n\t\tbreak;\n\n\tcase IOCPF_E_STOP:\n\t\tbfa_sem_timer_stop(ioc);\n\t\tbfa_ioc_firmware_unlock(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_reset);\n\t\tbreak;\n\n\tcase IOCPF_E_FAIL:\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_iocpf_sm_initfail_entry(struct bfa_iocpf_s *iocpf)\n{\n\tbfa_trc(iocpf->ioc, 0);\n}\n\n \nstatic void\nbfa_iocpf_sm_initfail(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabled);\n\t\tbreak;\n\n\tcase IOCPF_E_STOP:\n\t\tbfa_ioc_firmware_unlock(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_reset);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_iocpf_sm_fail_sync_entry(struct bfa_iocpf_s *iocpf)\n{\n\t \n\tbfa_ioc_lpu_stop(iocpf->ioc);\n\n\t \n\tbfa_ioc_mbox_flush(iocpf->ioc);\n\n\tbfa_ioc_hw_sem_get(iocpf->ioc);\n}\n\nstatic void\nbfa_iocpf_sm_fail_sync(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_SEMLOCKED:\n\t\tbfa_ioc_sync_ack(ioc);\n\t\tbfa_ioc_notify_fail(ioc);\n\t\tif (!iocpf->auto_recover) {\n\t\t\tbfa_ioc_sync_leave(ioc);\n\t\t\tbfa_ioc_set_cur_ioc_fwstate(ioc, BFI_IOC_FAIL);\n\t\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_fail);\n\t\t} else {\n\t\t\tif (bfa_ioc_sync_complete(ioc))\n\t\t\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_hwinit);\n\t\t\telse {\n\t\t\t\twritel(1, ioc->ioc_regs.ioc_sem_reg);\n\t\t\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_semwait);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase IOCPF_E_SEM_ERROR:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_fail);\n\t\tbfa_fsm_send_event(ioc, IOC_E_HWFAILED);\n\t\tbreak;\n\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_sem_timer_stop(ioc);\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabling_sync);\n\t\tbreak;\n\n\tcase IOCPF_E_FAIL:\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\nstatic void\nbfa_iocpf_sm_fail_entry(struct bfa_iocpf_s *iocpf)\n{\n\tbfa_trc(iocpf->ioc, 0);\n}\n\n \nstatic void\nbfa_iocpf_sm_fail(struct bfa_iocpf_s *iocpf, enum iocpf_event event)\n{\n\tstruct bfa_ioc_s *ioc = iocpf->ioc;\n\n\tbfa_trc(ioc, event);\n\n\tswitch (event) {\n\tcase IOCPF_E_DISABLE:\n\t\tbfa_fsm_set_state(iocpf, bfa_iocpf_sm_disabled);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(ioc, event);\n\t}\n}\n\n \n\n \nstatic void\nbfa_ioc_event_notify(struct bfa_ioc_s *ioc, enum bfa_ioc_event_e event)\n{\n\tstruct bfa_ioc_notify_s\t*notify;\n\tstruct list_head\t*qe;\n\n\tlist_for_each(qe, &ioc->notify_q) {\n\t\tnotify = (struct bfa_ioc_notify_s *)qe;\n\t\tnotify->cbfn(notify->cbarg, event);\n\t}\n}\n\nstatic void\nbfa_ioc_disable_comp(struct bfa_ioc_s *ioc)\n{\n\tioc->cbfn->disable_cbfn(ioc->bfa);\n\tbfa_ioc_event_notify(ioc, BFA_IOC_E_DISABLED);\n}\n\nbfa_boolean_t\nbfa_ioc_sem_get(void __iomem *sem_reg)\n{\n\tu32 r32;\n\tint cnt = 0;\n#define BFA_SEM_SPINCNT\t3000\n\n\tr32 = readl(sem_reg);\n\n\twhile ((r32 & 1) && (cnt < BFA_SEM_SPINCNT)) {\n\t\tcnt++;\n\t\tudelay(2);\n\t\tr32 = readl(sem_reg);\n\t}\n\n\tif (!(r32 & 1))\n\t\treturn BFA_TRUE;\n\n\treturn BFA_FALSE;\n}\n\nstatic void\nbfa_ioc_hw_sem_get(struct bfa_ioc_s *ioc)\n{\n\tu32\tr32;\n\n\t \n\tr32 = readl(ioc->ioc_regs.ioc_sem_reg);\n\tif (r32 == ~0) {\n\t\tWARN_ON(r32 == ~0);\n\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_SEM_ERROR);\n\t\treturn;\n\t}\n\tif (!(r32 & 1)) {\n\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_SEMLOCKED);\n\t\treturn;\n\t}\n\n\tbfa_sem_timer_start(ioc);\n}\n\n \nstatic void\nbfa_ioc_lmem_init(struct bfa_ioc_s *ioc)\n{\n\tu32\tpss_ctl;\n\tint\t\ti;\n#define PSS_LMEM_INIT_TIME  10000\n\n\tpss_ctl = readl(ioc->ioc_regs.pss_ctl_reg);\n\tpss_ctl &= ~__PSS_LMEM_RESET;\n\tpss_ctl |= __PSS_LMEM_INIT_EN;\n\n\t \n\tpss_ctl |= __PSS_I2C_CLK_DIV(3UL);\n\twritel(pss_ctl, ioc->ioc_regs.pss_ctl_reg);\n\n\t \n\ti = 0;\n\tdo {\n\t\tpss_ctl = readl(ioc->ioc_regs.pss_ctl_reg);\n\t\ti++;\n\t} while (!(pss_ctl & __PSS_LMEM_INIT_DONE) && (i < PSS_LMEM_INIT_TIME));\n\n\t \n\tWARN_ON(!(pss_ctl & __PSS_LMEM_INIT_DONE));\n\tbfa_trc(ioc, pss_ctl);\n\n\tpss_ctl &= ~(__PSS_LMEM_INIT_DONE | __PSS_LMEM_INIT_EN);\n\twritel(pss_ctl, ioc->ioc_regs.pss_ctl_reg);\n}\n\nstatic void\nbfa_ioc_lpu_start(struct bfa_ioc_s *ioc)\n{\n\tu32\tpss_ctl;\n\n\t \n\tpss_ctl = readl(ioc->ioc_regs.pss_ctl_reg);\n\tpss_ctl &= ~__PSS_LPU0_RESET;\n\n\twritel(pss_ctl, ioc->ioc_regs.pss_ctl_reg);\n}\n\nstatic void\nbfa_ioc_lpu_stop(struct bfa_ioc_s *ioc)\n{\n\tu32\tpss_ctl;\n\n\t \n\tpss_ctl = readl(ioc->ioc_regs.pss_ctl_reg);\n\tpss_ctl |= (__PSS_LPU0_RESET | __PSS_LPU1_RESET);\n\n\twritel(pss_ctl, ioc->ioc_regs.pss_ctl_reg);\n}\n\n \nvoid\nbfa_ioc_fwver_get(struct bfa_ioc_s *ioc, struct bfi_ioc_image_hdr_s *fwhdr)\n{\n\tu32\tpgnum;\n\tu32\tloff = 0;\n\tint\t\ti;\n\tu32\t*fwsig = (u32 *) fwhdr;\n\n\tpgnum = PSS_SMEM_PGNUM(ioc->ioc_regs.smem_pg0, loff);\n\twritel(pgnum, ioc->ioc_regs.host_page_num_fn);\n\n\tfor (i = 0; i < (sizeof(struct bfi_ioc_image_hdr_s) / sizeof(u32));\n\t     i++) {\n\t\tfwsig[i] =\n\t\t\tbfa_mem_read(ioc->ioc_regs.smem_page_start, loff);\n\t\tloff += sizeof(u32);\n\t}\n}\n\n \nbfa_boolean_t\nbfa_ioc_fwver_cmp(struct bfa_ioc_s *ioc,\n\t\tstruct bfi_ioc_image_hdr_s *smem_fwhdr)\n{\n\tstruct bfi_ioc_image_hdr_s *drv_fwhdr;\n\tenum bfi_ioc_img_ver_cmp_e smem_flash_cmp, drv_smem_cmp;\n\n\tdrv_fwhdr = (struct bfi_ioc_image_hdr_s *)\n\t\tbfa_cb_image_get_chunk(bfa_ioc_asic_gen(ioc), 0);\n\n\t \n\tdrv_smem_cmp = bfa_ioc_fw_ver_patch_cmp(drv_fwhdr, smem_fwhdr);\n\tif (drv_smem_cmp == BFI_IOC_IMG_VER_INCOMP ||\n\t\tdrv_smem_cmp == BFI_IOC_IMG_VER_OLD) {\n\t\treturn BFA_FALSE;\n\t}\n\n\t \n\tsmem_flash_cmp = bfa_ioc_flash_fwver_cmp(ioc, smem_fwhdr);\n\n\tif (smem_flash_cmp == BFI_IOC_IMG_VER_BETTER) {\n\t\treturn BFA_FALSE;\n\t} else if (smem_flash_cmp == BFI_IOC_IMG_VER_SAME) {\n\t\treturn BFA_TRUE;\n\t} else {\n\t\treturn (drv_smem_cmp == BFI_IOC_IMG_VER_SAME) ?\n\t\t\tBFA_TRUE : BFA_FALSE;\n\t}\n}\n\n \nstatic bfa_boolean_t\nbfa_ioc_fwver_valid(struct bfa_ioc_s *ioc, u32 boot_env)\n{\n\tstruct bfi_ioc_image_hdr_s fwhdr;\n\n\tbfa_ioc_fwver_get(ioc, &fwhdr);\n\n\tif (swab32(fwhdr.bootenv) != boot_env) {\n\t\tbfa_trc(ioc, fwhdr.bootenv);\n\t\tbfa_trc(ioc, boot_env);\n\t\treturn BFA_FALSE;\n\t}\n\n\treturn bfa_ioc_fwver_cmp(ioc, &fwhdr);\n}\n\nstatic bfa_boolean_t\nbfa_ioc_fwver_md5_check(struct bfi_ioc_image_hdr_s *fwhdr_1,\n\t\t\t\tstruct bfi_ioc_image_hdr_s *fwhdr_2)\n{\n\tint i;\n\n\tfor (i = 0; i < BFI_IOC_MD5SUM_SZ; i++)\n\t\tif (fwhdr_1->md5sum[i] != fwhdr_2->md5sum[i])\n\t\t\treturn BFA_FALSE;\n\n\treturn BFA_TRUE;\n}\n\n \nstatic bfa_boolean_t\nbfa_ioc_fw_ver_compatible(struct bfi_ioc_image_hdr_s *drv_fwhdr,\n\t\t\t\tstruct bfi_ioc_image_hdr_s *fwhdr_to_cmp)\n{\n\tif (drv_fwhdr->signature != fwhdr_to_cmp->signature)\n\t\treturn BFA_FALSE;\n\n\tif (drv_fwhdr->fwver.major != fwhdr_to_cmp->fwver.major)\n\t\treturn BFA_FALSE;\n\n\tif (drv_fwhdr->fwver.minor != fwhdr_to_cmp->fwver.minor)\n\t\treturn BFA_FALSE;\n\n\tif (drv_fwhdr->fwver.maint != fwhdr_to_cmp->fwver.maint)\n\t\treturn BFA_FALSE;\n\n\tif (drv_fwhdr->fwver.patch == fwhdr_to_cmp->fwver.patch &&\n\t\tdrv_fwhdr->fwver.phase == fwhdr_to_cmp->fwver.phase &&\n\t\tdrv_fwhdr->fwver.build == fwhdr_to_cmp->fwver.build) {\n\t\treturn bfa_ioc_fwver_md5_check(drv_fwhdr, fwhdr_to_cmp);\n\t}\n\n\treturn BFA_TRUE;\n}\n\nstatic bfa_boolean_t\nbfa_ioc_flash_fwver_valid(struct bfi_ioc_image_hdr_s *flash_fwhdr)\n{\n\tif (flash_fwhdr->fwver.major == 0 || flash_fwhdr->fwver.major == 0xFF)\n\t\treturn BFA_FALSE;\n\n\treturn BFA_TRUE;\n}\n\nstatic bfa_boolean_t fwhdr_is_ga(struct bfi_ioc_image_hdr_s *fwhdr)\n{\n\tif (fwhdr->fwver.phase == 0 &&\n\t\tfwhdr->fwver.build == 0)\n\t\treturn BFA_TRUE;\n\n\treturn BFA_FALSE;\n}\n\n \nstatic enum bfi_ioc_img_ver_cmp_e\nbfa_ioc_fw_ver_patch_cmp(struct bfi_ioc_image_hdr_s *base_fwhdr,\n\t\t\t\tstruct bfi_ioc_image_hdr_s *fwhdr_to_cmp)\n{\n\tif (bfa_ioc_fw_ver_compatible(base_fwhdr, fwhdr_to_cmp) == BFA_FALSE)\n\t\treturn BFI_IOC_IMG_VER_INCOMP;\n\n\tif (fwhdr_to_cmp->fwver.patch > base_fwhdr->fwver.patch)\n\t\treturn BFI_IOC_IMG_VER_BETTER;\n\n\telse if (fwhdr_to_cmp->fwver.patch < base_fwhdr->fwver.patch)\n\t\treturn BFI_IOC_IMG_VER_OLD;\n\n\t \n\n\tif (fwhdr_is_ga(base_fwhdr) == BFA_TRUE) {\n\t\tif (fwhdr_is_ga(fwhdr_to_cmp))\n\t\t\treturn BFI_IOC_IMG_VER_SAME;\n\t\telse\n\t\t\treturn BFI_IOC_IMG_VER_OLD;\n\t} else {\n\t\tif (fwhdr_is_ga(fwhdr_to_cmp))\n\t\t\treturn BFI_IOC_IMG_VER_BETTER;\n\t}\n\n\tif (fwhdr_to_cmp->fwver.phase > base_fwhdr->fwver.phase)\n\t\treturn BFI_IOC_IMG_VER_BETTER;\n\telse if (fwhdr_to_cmp->fwver.phase < base_fwhdr->fwver.phase)\n\t\treturn BFI_IOC_IMG_VER_OLD;\n\n\tif (fwhdr_to_cmp->fwver.build > base_fwhdr->fwver.build)\n\t\treturn BFI_IOC_IMG_VER_BETTER;\n\telse if (fwhdr_to_cmp->fwver.build < base_fwhdr->fwver.build)\n\t\treturn BFI_IOC_IMG_VER_OLD;\n\n\t \n\treturn BFI_IOC_IMG_VER_SAME;\n}\n\n#define BFA_FLASH_PART_FWIMG_ADDR\t0x100000  \n\nbfa_status_t\nbfa_ioc_flash_img_get_chnk(struct bfa_ioc_s *ioc, u32 off,\n\t\t\t\tu32 *fwimg)\n{\n\treturn bfa_flash_raw_read(ioc->pcidev.pci_bar_kva,\n\t\t\tBFA_FLASH_PART_FWIMG_ADDR + (off * sizeof(u32)),\n\t\t\t(char *)fwimg, BFI_FLASH_CHUNK_SZ);\n}\n\nstatic enum bfi_ioc_img_ver_cmp_e\nbfa_ioc_flash_fwver_cmp(struct bfa_ioc_s *ioc,\n\t\t\tstruct bfi_ioc_image_hdr_s *base_fwhdr)\n{\n\tstruct bfi_ioc_image_hdr_s *flash_fwhdr;\n\tbfa_status_t status;\n\tu32 fwimg[BFI_FLASH_CHUNK_SZ_WORDS];\n\n\tstatus = bfa_ioc_flash_img_get_chnk(ioc, 0, fwimg);\n\tif (status != BFA_STATUS_OK)\n\t\treturn BFI_IOC_IMG_VER_INCOMP;\n\n\tflash_fwhdr = (struct bfi_ioc_image_hdr_s *) fwimg;\n\tif (bfa_ioc_flash_fwver_valid(flash_fwhdr) == BFA_TRUE)\n\t\treturn bfa_ioc_fw_ver_patch_cmp(base_fwhdr, flash_fwhdr);\n\telse\n\t\treturn BFI_IOC_IMG_VER_INCOMP;\n}\n\n\n \nbfa_status_t\nbfa_ioc_fwsig_invalidate(struct bfa_ioc_s *ioc)\n{\n\n\tu32\tpgnum;\n\tu32\tloff = 0;\n\tenum bfi_ioc_state ioc_fwstate;\n\n\tioc_fwstate = bfa_ioc_get_cur_ioc_fwstate(ioc);\n\tif (!bfa_ioc_state_disabled(ioc_fwstate))\n\t\treturn BFA_STATUS_ADAPTER_ENABLED;\n\n\tpgnum = PSS_SMEM_PGNUM(ioc->ioc_regs.smem_pg0, loff);\n\twritel(pgnum, ioc->ioc_regs.host_page_num_fn);\n\tbfa_mem_write(ioc->ioc_regs.smem_page_start, loff, BFA_IOC_FW_INV_SIGN);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nstatic void\nbfa_ioc_msgflush(struct bfa_ioc_s *ioc)\n{\n\tu32\tr32;\n\n\tr32 = readl(ioc->ioc_regs.lpu_mbox_cmd);\n\tif (r32)\n\t\twritel(1, ioc->ioc_regs.lpu_mbox_cmd);\n}\n\nstatic void\nbfa_ioc_hwinit(struct bfa_ioc_s *ioc, bfa_boolean_t force)\n{\n\tenum bfi_ioc_state ioc_fwstate;\n\tbfa_boolean_t fwvalid;\n\tu32 boot_type;\n\tu32 boot_env;\n\n\tioc_fwstate = bfa_ioc_get_cur_ioc_fwstate(ioc);\n\n\tif (force)\n\t\tioc_fwstate = BFI_IOC_UNINIT;\n\n\tbfa_trc(ioc, ioc_fwstate);\n\n\tboot_type = BFI_FWBOOT_TYPE_NORMAL;\n\tboot_env = BFI_FWBOOT_ENV_OS;\n\n\t \n\tfwvalid = (ioc_fwstate == BFI_IOC_UNINIT) ?\n\t\tBFA_FALSE : bfa_ioc_fwver_valid(ioc, boot_env);\n\n\tif (!fwvalid) {\n\t\tif (bfa_ioc_boot(ioc, boot_type, boot_env) == BFA_STATUS_OK)\n\t\t\tbfa_ioc_poll_fwinit(ioc);\n\t\treturn;\n\t}\n\n\t \n\tif (ioc_fwstate == BFI_IOC_INITING) {\n\t\tbfa_ioc_poll_fwinit(ioc);\n\t\treturn;\n\t}\n\n\t \n\tif (ioc_fwstate == BFI_IOC_DISABLED || ioc_fwstate == BFI_IOC_OP) {\n\n\t\t \n\t\tbfa_ioc_msgflush(ioc);\n\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_FWREADY);\n\t\treturn;\n\t}\n\n\t \n\tif (bfa_ioc_boot(ioc, boot_type, boot_env) == BFA_STATUS_OK)\n\t\tbfa_ioc_poll_fwinit(ioc);\n}\n\nstatic void\nbfa_ioc_timeout(void *ioc_arg)\n{\n\tstruct bfa_ioc_s  *ioc = (struct bfa_ioc_s *) ioc_arg;\n\n\tbfa_trc(ioc, 0);\n\tbfa_fsm_send_event(ioc, IOC_E_TIMEOUT);\n}\n\nvoid\nbfa_ioc_mbox_send(struct bfa_ioc_s *ioc, void *ioc_msg, int len)\n{\n\tu32 *msgp = (u32 *) ioc_msg;\n\tu32 i;\n\n\tbfa_trc(ioc, msgp[0]);\n\tbfa_trc(ioc, len);\n\n\tWARN_ON(len > BFI_IOC_MSGLEN_MAX);\n\n\t \n\tfor (i = 0; i < len / sizeof(u32); i++)\n\t\twritel(cpu_to_le32(msgp[i]),\n\t\t\tioc->ioc_regs.hfn_mbox + i * sizeof(u32));\n\n\tfor (; i < BFI_IOC_MSGLEN_MAX / sizeof(u32); i++)\n\t\twritel(0, ioc->ioc_regs.hfn_mbox + i * sizeof(u32));\n\n\t \n\twritel(1, ioc->ioc_regs.hfn_mbox_cmd);\n\t(void) readl(ioc->ioc_regs.hfn_mbox_cmd);\n}\n\nstatic void\nbfa_ioc_send_enable(struct bfa_ioc_s *ioc)\n{\n\tstruct bfi_ioc_ctrl_req_s enable_req;\n\n\tbfi_h2i_set(enable_req.mh, BFI_MC_IOC, BFI_IOC_H2I_ENABLE_REQ,\n\t\t    bfa_ioc_portid(ioc));\n\tenable_req.clscode = cpu_to_be16(ioc->clscode);\n\t \n\tenable_req.tv_sec = be32_to_cpu(ktime_get_real_seconds());\n\tbfa_ioc_mbox_send(ioc, &enable_req, sizeof(struct bfi_ioc_ctrl_req_s));\n}\n\nstatic void\nbfa_ioc_send_disable(struct bfa_ioc_s *ioc)\n{\n\tstruct bfi_ioc_ctrl_req_s disable_req;\n\n\tbfi_h2i_set(disable_req.mh, BFI_MC_IOC, BFI_IOC_H2I_DISABLE_REQ,\n\t\t    bfa_ioc_portid(ioc));\n\tdisable_req.clscode = cpu_to_be16(ioc->clscode);\n\t \n\tdisable_req.tv_sec = be32_to_cpu(ktime_get_real_seconds());\n\tbfa_ioc_mbox_send(ioc, &disable_req, sizeof(struct bfi_ioc_ctrl_req_s));\n}\n\nstatic void\nbfa_ioc_send_getattr(struct bfa_ioc_s *ioc)\n{\n\tstruct bfi_ioc_getattr_req_s\tattr_req;\n\n\tbfi_h2i_set(attr_req.mh, BFI_MC_IOC, BFI_IOC_H2I_GETATTR_REQ,\n\t\t    bfa_ioc_portid(ioc));\n\tbfa_dma_be_addr_set(attr_req.attr_addr, ioc->attr_dma.pa);\n\tbfa_ioc_mbox_send(ioc, &attr_req, sizeof(attr_req));\n}\n\nstatic void\nbfa_ioc_hb_check(void *cbarg)\n{\n\tstruct bfa_ioc_s  *ioc = cbarg;\n\tu32\thb_count;\n\n\thb_count = readl(ioc->ioc_regs.heartbeat);\n\tif (ioc->hb_count == hb_count) {\n\t\tbfa_ioc_recover(ioc);\n\t\treturn;\n\t} else {\n\t\tioc->hb_count = hb_count;\n\t}\n\n\tbfa_ioc_mbox_poll(ioc);\n\tbfa_hb_timer_start(ioc);\n}\n\nstatic void\nbfa_ioc_hb_monitor(struct bfa_ioc_s *ioc)\n{\n\tioc->hb_count = readl(ioc->ioc_regs.heartbeat);\n\tbfa_hb_timer_start(ioc);\n}\n\n \nstatic bfa_status_t\nbfa_ioc_download_fw(struct bfa_ioc_s *ioc, u32 boot_type,\n\t\t    u32 boot_env)\n{\n\tu32 *fwimg;\n\tu32 pgnum;\n\tu32 loff = 0;\n\tu32 chunkno = 0;\n\tu32 i;\n\tu32 asicmode;\n\tu32 fwimg_size;\n\tu32 fwimg_buf[BFI_FLASH_CHUNK_SZ_WORDS];\n\tbfa_status_t status;\n\n\tif (boot_env == BFI_FWBOOT_ENV_OS &&\n\t\tboot_type == BFI_FWBOOT_TYPE_FLASH) {\n\t\tfwimg_size = BFI_FLASH_IMAGE_SZ/sizeof(u32);\n\n\t\tstatus = bfa_ioc_flash_img_get_chnk(ioc,\n\t\t\tBFA_IOC_FLASH_CHUNK_ADDR(chunkno), fwimg_buf);\n\t\tif (status != BFA_STATUS_OK)\n\t\t\treturn status;\n\n\t\tfwimg = fwimg_buf;\n\t} else {\n\t\tfwimg_size = bfa_cb_image_get_size(bfa_ioc_asic_gen(ioc));\n\t\tfwimg = bfa_cb_image_get_chunk(bfa_ioc_asic_gen(ioc),\n\t\t\t\t\tBFA_IOC_FLASH_CHUNK_ADDR(chunkno));\n\t}\n\n\tbfa_trc(ioc, fwimg_size);\n\n\n\tpgnum = PSS_SMEM_PGNUM(ioc->ioc_regs.smem_pg0, loff);\n\twritel(pgnum, ioc->ioc_regs.host_page_num_fn);\n\n\tfor (i = 0; i < fwimg_size; i++) {\n\n\t\tif (BFA_IOC_FLASH_CHUNK_NO(i) != chunkno) {\n\t\t\tchunkno = BFA_IOC_FLASH_CHUNK_NO(i);\n\n\t\t\tif (boot_env == BFI_FWBOOT_ENV_OS &&\n\t\t\t\tboot_type == BFI_FWBOOT_TYPE_FLASH) {\n\t\t\t\tstatus = bfa_ioc_flash_img_get_chnk(ioc,\n\t\t\t\t\tBFA_IOC_FLASH_CHUNK_ADDR(chunkno),\n\t\t\t\t\tfwimg_buf);\n\t\t\t\tif (status != BFA_STATUS_OK)\n\t\t\t\t\treturn status;\n\n\t\t\t\tfwimg = fwimg_buf;\n\t\t\t} else {\n\t\t\t\tfwimg = bfa_cb_image_get_chunk(\n\t\t\t\t\tbfa_ioc_asic_gen(ioc),\n\t\t\t\t\tBFA_IOC_FLASH_CHUNK_ADDR(chunkno));\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tbfa_mem_write(ioc->ioc_regs.smem_page_start, loff,\n\t\t\t      fwimg[BFA_IOC_FLASH_OFFSET_IN_CHUNK(i)]);\n\n\t\tloff += sizeof(u32);\n\n\t\t \n\t\tloff = PSS_SMEM_PGOFF(loff);\n\t\tif (loff == 0) {\n\t\t\tpgnum++;\n\t\t\twritel(pgnum, ioc->ioc_regs.host_page_num_fn);\n\t\t}\n\t}\n\n\twritel(PSS_SMEM_PGNUM(ioc->ioc_regs.smem_pg0, 0),\n\t\t\tioc->ioc_regs.host_page_num_fn);\n\n\t \n\tif (boot_env == BFI_FWBOOT_ENV_OS &&\n\t\tboot_type == BFI_FWBOOT_TYPE_FLASH) {\n\t\tboot_type = BFI_FWBOOT_TYPE_NORMAL;\n\t}\n\tasicmode = BFI_FWBOOT_DEVMODE(ioc->asic_gen, ioc->asic_mode,\n\t\t\t\tioc->port0_mode, ioc->port1_mode);\n\tbfa_mem_write(ioc->ioc_regs.smem_page_start, BFI_FWBOOT_DEVMODE_OFF,\n\t\t\tswab32(asicmode));\n\tbfa_mem_write(ioc->ioc_regs.smem_page_start, BFI_FWBOOT_TYPE_OFF,\n\t\t\tswab32(boot_type));\n\tbfa_mem_write(ioc->ioc_regs.smem_page_start, BFI_FWBOOT_ENV_OFF,\n\t\t\tswab32(boot_env));\n\treturn BFA_STATUS_OK;\n}\n\n\n \nstatic void\nbfa_ioc_getattr_reply(struct bfa_ioc_s *ioc)\n{\n\tstruct bfi_ioc_attr_s\t*attr = ioc->attr;\n\n\tattr->adapter_prop  = be32_to_cpu(attr->adapter_prop);\n\tattr->card_type     = be32_to_cpu(attr->card_type);\n\tattr->maxfrsize\t    = be16_to_cpu(attr->maxfrsize);\n\tioc->fcmode\t= (attr->port_mode == BFI_PORT_MODE_FC);\n\tattr->mfg_year\t= be16_to_cpu(attr->mfg_year);\n\n\tbfa_fsm_send_event(ioc, IOC_E_FWRSP_GETATTR);\n}\n\n \nstatic void\nbfa_ioc_mbox_attach(struct bfa_ioc_s *ioc)\n{\n\tstruct bfa_ioc_mbox_mod_s\t*mod = &ioc->mbox_mod;\n\tint\tmc;\n\n\tINIT_LIST_HEAD(&mod->cmd_q);\n\tfor (mc = 0; mc < BFI_MC_MAX; mc++) {\n\t\tmod->mbhdlr[mc].cbfn = NULL;\n\t\tmod->mbhdlr[mc].cbarg = ioc->bfa;\n\t}\n}\n\n \nstatic void\nbfa_ioc_mbox_poll(struct bfa_ioc_s *ioc)\n{\n\tstruct bfa_ioc_mbox_mod_s\t*mod = &ioc->mbox_mod;\n\tstruct bfa_mbox_cmd_s\t\t*cmd;\n\tu32\t\t\tstat;\n\n\t \n\tif (list_empty(&mod->cmd_q))\n\t\treturn;\n\n\t \n\tstat = readl(ioc->ioc_regs.hfn_mbox_cmd);\n\tif (stat)\n\t\treturn;\n\n\t \n\tbfa_q_deq(&mod->cmd_q, &cmd);\n\tbfa_ioc_mbox_send(ioc, cmd->msg, sizeof(cmd->msg));\n}\n\n \nstatic void\nbfa_ioc_mbox_flush(struct bfa_ioc_s *ioc)\n{\n\tstruct bfa_ioc_mbox_mod_s\t*mod = &ioc->mbox_mod;\n\tstruct bfa_mbox_cmd_s\t\t*cmd;\n\n\twhile (!list_empty(&mod->cmd_q))\n\t\tbfa_q_deq(&mod->cmd_q, &cmd);\n}\n\n \nstatic bfa_status_t\nbfa_ioc_smem_read(struct bfa_ioc_s *ioc, void *tbuf, u32 soff, u32 sz)\n{\n\tu32 pgnum, loff;\n\t__be32 r32;\n\tint i, len;\n\tu32 *buf = tbuf;\n\n\tpgnum = PSS_SMEM_PGNUM(ioc->ioc_regs.smem_pg0, soff);\n\tloff = PSS_SMEM_PGOFF(soff);\n\tbfa_trc(ioc, pgnum);\n\tbfa_trc(ioc, loff);\n\tbfa_trc(ioc, sz);\n\n\t \n\tif (BFA_FALSE == bfa_ioc_sem_get(ioc->ioc_regs.ioc_init_sem_reg)) {\n\t\tbfa_trc(ioc, 0);\n\t\treturn BFA_STATUS_FAILED;\n\t}\n\n\twritel(pgnum, ioc->ioc_regs.host_page_num_fn);\n\n\tlen = sz/sizeof(u32);\n\tbfa_trc(ioc, len);\n\tfor (i = 0; i < len; i++) {\n\t\tr32 = bfa_mem_read(ioc->ioc_regs.smem_page_start, loff);\n\t\tbuf[i] = swab32(r32);\n\t\tloff += sizeof(u32);\n\n\t\t \n\t\tloff = PSS_SMEM_PGOFF(loff);\n\t\tif (loff == 0) {\n\t\t\tpgnum++;\n\t\t\twritel(pgnum, ioc->ioc_regs.host_page_num_fn);\n\t\t}\n\t}\n\twritel(PSS_SMEM_PGNUM(ioc->ioc_regs.smem_pg0, 0),\n\t\t\tioc->ioc_regs.host_page_num_fn);\n\t \n\treadl(ioc->ioc_regs.ioc_init_sem_reg);\n\twritel(1, ioc->ioc_regs.ioc_init_sem_reg);\n\n\tbfa_trc(ioc, pgnum);\n\treturn BFA_STATUS_OK;\n}\n\n \nstatic bfa_status_t\nbfa_ioc_smem_clr(struct bfa_ioc_s *ioc, u32 soff, u32 sz)\n{\n\tint i, len;\n\tu32 pgnum, loff;\n\n\tpgnum = PSS_SMEM_PGNUM(ioc->ioc_regs.smem_pg0, soff);\n\tloff = PSS_SMEM_PGOFF(soff);\n\tbfa_trc(ioc, pgnum);\n\tbfa_trc(ioc, loff);\n\tbfa_trc(ioc, sz);\n\n\t \n\tif (BFA_FALSE == bfa_ioc_sem_get(ioc->ioc_regs.ioc_init_sem_reg)) {\n\t\tbfa_trc(ioc, 0);\n\t\treturn BFA_STATUS_FAILED;\n\t}\n\n\twritel(pgnum, ioc->ioc_regs.host_page_num_fn);\n\n\tlen = sz/sizeof(u32);  \n\tbfa_trc(ioc, len);\n\tfor (i = 0; i < len; i++) {\n\t\tbfa_mem_write(ioc->ioc_regs.smem_page_start, loff, 0);\n\t\tloff += sizeof(u32);\n\n\t\t \n\t\tloff = PSS_SMEM_PGOFF(loff);\n\t\tif (loff == 0) {\n\t\t\tpgnum++;\n\t\t\twritel(pgnum, ioc->ioc_regs.host_page_num_fn);\n\t\t}\n\t}\n\twritel(PSS_SMEM_PGNUM(ioc->ioc_regs.smem_pg0, 0),\n\t\t\tioc->ioc_regs.host_page_num_fn);\n\n\t \n\treadl(ioc->ioc_regs.ioc_init_sem_reg);\n\twritel(1, ioc->ioc_regs.ioc_init_sem_reg);\n\tbfa_trc(ioc, pgnum);\n\treturn BFA_STATUS_OK;\n}\n\nstatic void\nbfa_ioc_fail_notify(struct bfa_ioc_s *ioc)\n{\n\tstruct bfad_s *bfad = (struct bfad_s *)ioc->bfa->bfad;\n\n\t \n\tioc->cbfn->hbfail_cbfn(ioc->bfa);\n\tbfa_ioc_event_notify(ioc, BFA_IOC_E_FAILED);\n\n\tbfa_ioc_debug_save_ftrc(ioc);\n\n\tBFA_LOG(KERN_CRIT, bfad, bfa_log_level,\n\t\t\"Heart Beat of IOC has failed\\n\");\n\tbfa_ioc_aen_post(ioc, BFA_IOC_AEN_HBFAIL);\n\n}\n\nstatic void\nbfa_ioc_pf_fwmismatch(struct bfa_ioc_s *ioc)\n{\n\tstruct bfad_s *bfad = (struct bfad_s *)ioc->bfa->bfad;\n\t \n\tioc->cbfn->enable_cbfn(ioc->bfa, BFA_STATUS_IOC_FAILURE);\n\tBFA_LOG(KERN_WARNING, bfad, bfa_log_level,\n\t\t\"Running firmware version is incompatible \"\n\t\t\"with the driver version\\n\");\n\tbfa_ioc_aen_post(ioc, BFA_IOC_AEN_FWMISMATCH);\n}\n\nbfa_status_t\nbfa_ioc_pll_init(struct bfa_ioc_s *ioc)\n{\n\n\t \n\tbfa_ioc_sem_get(ioc->ioc_regs.ioc_init_sem_reg);\n\n\tbfa_ioc_pll_init_asic(ioc);\n\n\tioc->pllinit = BFA_TRUE;\n\n\t \n\tbfa_ioc_lmem_init(ioc);\n\n\t \n\treadl(ioc->ioc_regs.ioc_init_sem_reg);\n\twritel(1, ioc->ioc_regs.ioc_init_sem_reg);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_ioc_boot(struct bfa_ioc_s *ioc, u32 boot_type, u32 boot_env)\n{\n\tstruct bfi_ioc_image_hdr_s *drv_fwhdr;\n\tbfa_status_t status;\n\tbfa_ioc_stats(ioc, ioc_boots);\n\n\tif (bfa_ioc_pll_init(ioc) != BFA_STATUS_OK)\n\t\treturn BFA_STATUS_FAILED;\n\n\tif (boot_env == BFI_FWBOOT_ENV_OS &&\n\t\tboot_type == BFI_FWBOOT_TYPE_NORMAL) {\n\n\t\tdrv_fwhdr = (struct bfi_ioc_image_hdr_s *)\n\t\t\tbfa_cb_image_get_chunk(bfa_ioc_asic_gen(ioc), 0);\n\n\t\t \n\t\tif (bfa_ioc_flash_fwver_cmp(ioc, drv_fwhdr) ==\n\t\t\t\t\t\tBFI_IOC_IMG_VER_BETTER)\n\t\t\tboot_type = BFI_FWBOOT_TYPE_FLASH;\n\t}\n\n\t \n\tif (boot_type == BFI_FWBOOT_TYPE_MEMTEST) {\n\t\tbfa_ioc_set_cur_ioc_fwstate(ioc, BFI_IOC_MEMTEST);\n\t\tbfa_ioc_set_alt_ioc_fwstate(ioc, BFI_IOC_MEMTEST);\n\t} else {\n\t\tbfa_ioc_set_cur_ioc_fwstate(ioc, BFI_IOC_INITING);\n\t\tbfa_ioc_set_alt_ioc_fwstate(ioc, BFI_IOC_INITING);\n\t}\n\n\tbfa_ioc_msgflush(ioc);\n\tstatus = bfa_ioc_download_fw(ioc, boot_type, boot_env);\n\tif (status == BFA_STATUS_OK)\n\t\tbfa_ioc_lpu_start(ioc);\n\telse {\n\t\tWARN_ON(boot_type == BFI_FWBOOT_TYPE_MEMTEST);\n\t\tbfa_iocpf_timeout(ioc);\n\t}\n\treturn status;\n}\n\n \nvoid\nbfa_ioc_auto_recover(bfa_boolean_t auto_recover)\n{\n\tbfa_auto_recover = auto_recover;\n}\n\n\n\nbfa_boolean_t\nbfa_ioc_is_operational(struct bfa_ioc_s *ioc)\n{\n\treturn bfa_fsm_cmp_state(ioc, bfa_ioc_sm_op);\n}\n\nbfa_boolean_t\nbfa_ioc_is_initialized(struct bfa_ioc_s *ioc)\n{\n\tu32 r32 = bfa_ioc_get_cur_ioc_fwstate(ioc);\n\n\treturn ((r32 != BFI_IOC_UNINIT) &&\n\t\t(r32 != BFI_IOC_INITING) &&\n\t\t(r32 != BFI_IOC_MEMTEST));\n}\n\nbfa_boolean_t\nbfa_ioc_msgget(struct bfa_ioc_s *ioc, void *mbmsg)\n{\n\t__be32\t*msgp = mbmsg;\n\tu32\tr32;\n\tint\t\ti;\n\n\tr32 = readl(ioc->ioc_regs.lpu_mbox_cmd);\n\tif ((r32 & 1) == 0)\n\t\treturn BFA_FALSE;\n\n\t \n\tfor (i = 0; i < (sizeof(union bfi_ioc_i2h_msg_u) / sizeof(u32));\n\t     i++) {\n\t\tr32 = readl(ioc->ioc_regs.lpu_mbox +\n\t\t\t\t   i * sizeof(u32));\n\t\tmsgp[i] = cpu_to_be32(r32);\n\t}\n\n\t \n\twritel(1, ioc->ioc_regs.lpu_mbox_cmd);\n\treadl(ioc->ioc_regs.lpu_mbox_cmd);\n\n\treturn BFA_TRUE;\n}\n\nvoid\nbfa_ioc_isr(struct bfa_ioc_s *ioc, struct bfi_mbmsg_s *m)\n{\n\tunion bfi_ioc_i2h_msg_u\t*msg;\n\tstruct bfa_iocpf_s *iocpf = &ioc->iocpf;\n\n\tmsg = (union bfi_ioc_i2h_msg_u *) m;\n\n\tbfa_ioc_stats(ioc, ioc_isrs);\n\n\tswitch (msg->mh.msg_id) {\n\tcase BFI_IOC_I2H_HBEAT:\n\t\tbreak;\n\n\tcase BFI_IOC_I2H_ENABLE_REPLY:\n\t\tioc->port_mode = ioc->port_mode_cfg =\n\t\t\t\t(enum bfa_mode_s)msg->fw_event.port_mode;\n\t\tioc->ad_cap_bm = msg->fw_event.cap_bm;\n\t\tbfa_fsm_send_event(iocpf, IOCPF_E_FWRSP_ENABLE);\n\t\tbreak;\n\n\tcase BFI_IOC_I2H_DISABLE_REPLY:\n\t\tbfa_fsm_send_event(iocpf, IOCPF_E_FWRSP_DISABLE);\n\t\tbreak;\n\n\tcase BFI_IOC_I2H_GETATTR_REPLY:\n\t\tbfa_ioc_getattr_reply(ioc);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_trc(ioc, msg->mh.msg_id);\n\t\tWARN_ON(1);\n\t}\n}\n\n \nvoid\nbfa_ioc_attach(struct bfa_ioc_s *ioc, void *bfa, struct bfa_ioc_cbfn_s *cbfn,\n\t       struct bfa_timer_mod_s *timer_mod)\n{\n\tioc->bfa\t= bfa;\n\tioc->cbfn\t= cbfn;\n\tioc->timer_mod\t= timer_mod;\n\tioc->fcmode\t= BFA_FALSE;\n\tioc->pllinit\t= BFA_FALSE;\n\tioc->dbg_fwsave_once = BFA_TRUE;\n\tioc->iocpf.ioc\t= ioc;\n\n\tbfa_ioc_mbox_attach(ioc);\n\tINIT_LIST_HEAD(&ioc->notify_q);\n\n\tbfa_fsm_set_state(ioc, bfa_ioc_sm_uninit);\n\tbfa_fsm_send_event(ioc, IOC_E_RESET);\n}\n\n \nvoid\nbfa_ioc_detach(struct bfa_ioc_s *ioc)\n{\n\tbfa_fsm_send_event(ioc, IOC_E_DETACH);\n\tINIT_LIST_HEAD(&ioc->notify_q);\n}\n\n \nvoid\nbfa_ioc_pci_init(struct bfa_ioc_s *ioc, struct bfa_pcidev_s *pcidev,\n\t\tenum bfi_pcifn_class clscode)\n{\n\tioc->clscode\t= clscode;\n\tioc->pcidev\t= *pcidev;\n\n\t \n\tioc->port0_mode = ioc->port1_mode = BFI_PORT_MODE_FC;\n\tioc->asic_mode  = BFI_ASIC_MODE_FC;\n\n\tswitch (pcidev->device_id) {\n\tcase BFA_PCI_DEVICE_ID_FC_8G1P:\n\tcase BFA_PCI_DEVICE_ID_FC_8G2P:\n\t\tioc->asic_gen = BFI_ASIC_GEN_CB;\n\t\tioc->fcmode = BFA_TRUE;\n\t\tioc->port_mode = ioc->port_mode_cfg = BFA_MODE_HBA;\n\t\tioc->ad_cap_bm = BFA_CM_HBA;\n\t\tbreak;\n\n\tcase BFA_PCI_DEVICE_ID_CT:\n\t\tioc->asic_gen = BFI_ASIC_GEN_CT;\n\t\tioc->port0_mode = ioc->port1_mode = BFI_PORT_MODE_ETH;\n\t\tioc->asic_mode  = BFI_ASIC_MODE_ETH;\n\t\tioc->port_mode = ioc->port_mode_cfg = BFA_MODE_CNA;\n\t\tioc->ad_cap_bm = BFA_CM_CNA;\n\t\tbreak;\n\n\tcase BFA_PCI_DEVICE_ID_CT_FC:\n\t\tioc->asic_gen = BFI_ASIC_GEN_CT;\n\t\tioc->fcmode = BFA_TRUE;\n\t\tioc->port_mode = ioc->port_mode_cfg = BFA_MODE_HBA;\n\t\tioc->ad_cap_bm = BFA_CM_HBA;\n\t\tbreak;\n\n\tcase BFA_PCI_DEVICE_ID_CT2:\n\tcase BFA_PCI_DEVICE_ID_CT2_QUAD:\n\t\tioc->asic_gen = BFI_ASIC_GEN_CT2;\n\t\tif (clscode == BFI_PCIFN_CLASS_FC &&\n\t\t    pcidev->ssid == BFA_PCI_CT2_SSID_FC) {\n\t\t\tioc->asic_mode  = BFI_ASIC_MODE_FC16;\n\t\t\tioc->fcmode = BFA_TRUE;\n\t\t\tioc->port_mode = ioc->port_mode_cfg = BFA_MODE_HBA;\n\t\t\tioc->ad_cap_bm = BFA_CM_HBA;\n\t\t} else {\n\t\t\tioc->port0_mode = ioc->port1_mode = BFI_PORT_MODE_ETH;\n\t\t\tioc->asic_mode  = BFI_ASIC_MODE_ETH;\n\t\t\tif (pcidev->ssid == BFA_PCI_CT2_SSID_FCoE) {\n\t\t\t\tioc->port_mode =\n\t\t\t\tioc->port_mode_cfg = BFA_MODE_CNA;\n\t\t\t\tioc->ad_cap_bm = BFA_CM_CNA;\n\t\t\t} else {\n\t\t\t\tioc->port_mode =\n\t\t\t\tioc->port_mode_cfg = BFA_MODE_NIC;\n\t\t\t\tioc->ad_cap_bm = BFA_CM_NIC;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON(1);\n\t}\n\n\t \n\tif (ioc->asic_gen == BFI_ASIC_GEN_CB)\n\t\tbfa_ioc_set_cb_hwif(ioc);\n\telse if (ioc->asic_gen == BFI_ASIC_GEN_CT)\n\t\tbfa_ioc_set_ct_hwif(ioc);\n\telse {\n\t\tWARN_ON(ioc->asic_gen != BFI_ASIC_GEN_CT2);\n\t\tbfa_ioc_set_ct2_hwif(ioc);\n\t\tbfa_ioc_ct2_poweron(ioc);\n\t}\n\n\tbfa_ioc_map_port(ioc);\n\tbfa_ioc_reg_init(ioc);\n}\n\n \nvoid\nbfa_ioc_mem_claim(struct bfa_ioc_s *ioc,  u8 *dm_kva, u64 dm_pa)\n{\n\t \n\tioc->attr_dma.kva = dm_kva;\n\tioc->attr_dma.pa = dm_pa;\n\tioc->attr = (struct bfi_ioc_attr_s *) dm_kva;\n}\n\nvoid\nbfa_ioc_enable(struct bfa_ioc_s *ioc)\n{\n\tbfa_ioc_stats(ioc, ioc_enables);\n\tioc->dbg_fwsave_once = BFA_TRUE;\n\n\tbfa_fsm_send_event(ioc, IOC_E_ENABLE);\n}\n\nvoid\nbfa_ioc_disable(struct bfa_ioc_s *ioc)\n{\n\tbfa_ioc_stats(ioc, ioc_disables);\n\tbfa_fsm_send_event(ioc, IOC_E_DISABLE);\n}\n\nvoid\nbfa_ioc_suspend(struct bfa_ioc_s *ioc)\n{\n\tioc->dbg_fwsave_once = BFA_TRUE;\n\tbfa_fsm_send_event(ioc, IOC_E_HWERROR);\n}\n\n \nvoid\nbfa_ioc_debug_memclaim(struct bfa_ioc_s *ioc, void *dbg_fwsave)\n{\n\tioc->dbg_fwsave\t    = dbg_fwsave;\n\tioc->dbg_fwsave_len = BFA_DBG_FWTRC_LEN;\n}\n\n \nvoid\nbfa_ioc_mbox_register(struct bfa_ioc_s *ioc, bfa_ioc_mbox_mcfunc_t *mcfuncs)\n{\n\tstruct bfa_ioc_mbox_mod_s\t*mod = &ioc->mbox_mod;\n\tint\t\t\t\tmc;\n\n\tfor (mc = 0; mc < BFI_MC_MAX; mc++)\n\t\tmod->mbhdlr[mc].cbfn = mcfuncs[mc];\n}\n\n \nvoid\nbfa_ioc_mbox_regisr(struct bfa_ioc_s *ioc, enum bfi_mclass mc,\n\t\t    bfa_ioc_mbox_mcfunc_t cbfn, void *cbarg)\n{\n\tstruct bfa_ioc_mbox_mod_s\t*mod = &ioc->mbox_mod;\n\n\tmod->mbhdlr[mc].cbfn\t= cbfn;\n\tmod->mbhdlr[mc].cbarg\t= cbarg;\n}\n\n \nvoid\nbfa_ioc_mbox_queue(struct bfa_ioc_s *ioc, struct bfa_mbox_cmd_s *cmd)\n{\n\tstruct bfa_ioc_mbox_mod_s\t*mod = &ioc->mbox_mod;\n\tu32\t\t\tstat;\n\n\t \n\tif (!list_empty(&mod->cmd_q)) {\n\t\tlist_add_tail(&cmd->qe, &mod->cmd_q);\n\t\treturn;\n\t}\n\n\t \n\tstat = readl(ioc->ioc_regs.hfn_mbox_cmd);\n\tif (stat) {\n\t\tlist_add_tail(&cmd->qe, &mod->cmd_q);\n\t\treturn;\n\t}\n\n\t \n\tbfa_ioc_mbox_send(ioc, cmd->msg, sizeof(cmd->msg));\n}\n\n \nvoid\nbfa_ioc_mbox_isr(struct bfa_ioc_s *ioc)\n{\n\tstruct bfa_ioc_mbox_mod_s\t*mod = &ioc->mbox_mod;\n\tstruct bfi_mbmsg_s\t\tm;\n\tint\t\t\t\tmc;\n\n\tif (bfa_ioc_msgget(ioc, &m)) {\n\t\t \n\t\tmc = m.mh.msg_class;\n\t\tif (mc == BFI_MC_IOC) {\n\t\t\tbfa_ioc_isr(ioc, &m);\n\t\t\treturn;\n\t\t}\n\n\t\tif ((mc >= BFI_MC_MAX) || (mod->mbhdlr[mc].cbfn == NULL))\n\t\t\treturn;\n\n\t\tmod->mbhdlr[mc].cbfn(mod->mbhdlr[mc].cbarg, &m);\n\t}\n\n\tbfa_ioc_lpu_read_stat(ioc);\n\n\t \n\tbfa_ioc_mbox_poll(ioc);\n}\n\nvoid\nbfa_ioc_error_isr(struct bfa_ioc_s *ioc)\n{\n\tbfa_ioc_stats(ioc, ioc_hbfails);\n\tioc->stats.hb_count = ioc->hb_count;\n\tbfa_fsm_send_event(ioc, IOC_E_HWERROR);\n}\n\n \nbfa_boolean_t\nbfa_ioc_is_disabled(struct bfa_ioc_s *ioc)\n{\n\treturn bfa_fsm_cmp_state(ioc, bfa_ioc_sm_disabling) ||\n\t\tbfa_fsm_cmp_state(ioc, bfa_ioc_sm_disabled);\n}\n\n \nbfa_boolean_t\nbfa_ioc_fw_mismatch(struct bfa_ioc_s *ioc)\n{\n\treturn bfa_fsm_cmp_state(ioc, bfa_ioc_sm_reset) ||\n\t\tbfa_fsm_cmp_state(&ioc->iocpf, bfa_iocpf_sm_fwcheck) ||\n\t\tbfa_fsm_cmp_state(&ioc->iocpf, bfa_iocpf_sm_mismatch);\n}\n\n \nbfa_boolean_t\nbfa_ioc_adapter_is_disabled(struct bfa_ioc_s *ioc)\n{\n\tu32\tioc_state;\n\n\tif (!bfa_fsm_cmp_state(ioc, bfa_ioc_sm_disabled))\n\t\treturn BFA_FALSE;\n\n\tioc_state = bfa_ioc_get_cur_ioc_fwstate(ioc);\n\tif (!bfa_ioc_state_disabled(ioc_state))\n\t\treturn BFA_FALSE;\n\n\tif (ioc->pcidev.device_id != BFA_PCI_DEVICE_ID_FC_8G1P) {\n\t\tioc_state = bfa_ioc_get_cur_ioc_fwstate(ioc);\n\t\tif (!bfa_ioc_state_disabled(ioc_state))\n\t\t\treturn BFA_FALSE;\n\t}\n\n\treturn BFA_TRUE;\n}\n\n \nvoid\nbfa_ioc_reset_fwstate(struct bfa_ioc_s *ioc)\n{\n\tbfa_ioc_set_cur_ioc_fwstate(ioc, BFI_IOC_UNINIT);\n\tbfa_ioc_set_alt_ioc_fwstate(ioc, BFI_IOC_UNINIT);\n}\n\n#define BFA_MFG_NAME \"QLogic\"\nvoid\nbfa_ioc_get_adapter_attr(struct bfa_ioc_s *ioc,\n\t\t\t struct bfa_adapter_attr_s *ad_attr)\n{\n\tstruct bfi_ioc_attr_s\t*ioc_attr;\n\n\tioc_attr = ioc->attr;\n\n\tbfa_ioc_get_adapter_serial_num(ioc, ad_attr->serial_num);\n\tbfa_ioc_get_adapter_fw_ver(ioc, ad_attr->fw_ver);\n\tbfa_ioc_get_adapter_optrom_ver(ioc, ad_attr->optrom_ver);\n\tbfa_ioc_get_adapter_manufacturer(ioc, ad_attr->manufacturer);\n\tmemcpy(&ad_attr->vpd, &ioc_attr->vpd,\n\t\t      sizeof(struct bfa_mfg_vpd_s));\n\n\tad_attr->nports = bfa_ioc_get_nports(ioc);\n\tad_attr->max_speed = bfa_ioc_speed_sup(ioc);\n\n\tbfa_ioc_get_adapter_model(ioc, ad_attr->model);\n\t \n\tbfa_ioc_get_adapter_model(ioc, ad_attr->model_descr);\n\n\tad_attr->card_type = ioc_attr->card_type;\n\tad_attr->is_mezz = bfa_mfg_is_mezz(ioc_attr->card_type);\n\n\tif (BFI_ADAPTER_IS_SPECIAL(ioc_attr->adapter_prop))\n\t\tad_attr->prototype = 1;\n\telse\n\t\tad_attr->prototype = 0;\n\n\tad_attr->pwwn = ioc->attr->pwwn;\n\tad_attr->mac  = bfa_ioc_get_mac(ioc);\n\n\tad_attr->pcie_gen = ioc_attr->pcie_gen;\n\tad_attr->pcie_lanes = ioc_attr->pcie_lanes;\n\tad_attr->pcie_lanes_orig = ioc_attr->pcie_lanes_orig;\n\tad_attr->asic_rev = ioc_attr->asic_rev;\n\n\tbfa_ioc_get_pci_chip_rev(ioc, ad_attr->hw_ver);\n\n\tad_attr->cna_capable = bfa_ioc_is_cna(ioc);\n\tad_attr->trunk_capable = (ad_attr->nports > 1) &&\n\t\t\t\t  !bfa_ioc_is_cna(ioc) && !ad_attr->is_mezz;\n\tad_attr->mfg_day = ioc_attr->mfg_day;\n\tad_attr->mfg_month = ioc_attr->mfg_month;\n\tad_attr->mfg_year = ioc_attr->mfg_year;\n\tmemcpy(ad_attr->uuid, ioc_attr->uuid, BFA_ADAPTER_UUID_LEN);\n}\n\nenum bfa_ioc_type_e\nbfa_ioc_get_type(struct bfa_ioc_s *ioc)\n{\n\tif (ioc->clscode == BFI_PCIFN_CLASS_ETH)\n\t\treturn BFA_IOC_TYPE_LL;\n\n\tWARN_ON(ioc->clscode != BFI_PCIFN_CLASS_FC);\n\n\treturn (ioc->attr->port_mode == BFI_PORT_MODE_FC)\n\t\t? BFA_IOC_TYPE_FC : BFA_IOC_TYPE_FCoE;\n}\n\nvoid\nbfa_ioc_get_adapter_serial_num(struct bfa_ioc_s *ioc, char *serial_num)\n{\n\tmemset((void *)serial_num, 0, BFA_ADAPTER_SERIAL_NUM_LEN);\n\tmemcpy((void *)serial_num,\n\t\t\t(void *)ioc->attr->brcd_serialnum,\n\t\t\tBFA_ADAPTER_SERIAL_NUM_LEN);\n}\n\nvoid\nbfa_ioc_get_adapter_fw_ver(struct bfa_ioc_s *ioc, char *fw_ver)\n{\n\tmemset((void *)fw_ver, 0, BFA_VERSION_LEN);\n\tmemcpy(fw_ver, ioc->attr->fw_version, BFA_VERSION_LEN);\n}\n\nvoid\nbfa_ioc_get_pci_chip_rev(struct bfa_ioc_s *ioc, char *chip_rev)\n{\n\tWARN_ON(!chip_rev);\n\n\tmemset((void *)chip_rev, 0, BFA_IOC_CHIP_REV_LEN);\n\n\tchip_rev[0] = 'R';\n\tchip_rev[1] = 'e';\n\tchip_rev[2] = 'v';\n\tchip_rev[3] = '-';\n\tchip_rev[4] = ioc->attr->asic_rev;\n\tchip_rev[5] = '\\0';\n}\n\nvoid\nbfa_ioc_get_adapter_optrom_ver(struct bfa_ioc_s *ioc, char *optrom_ver)\n{\n\tmemset((void *)optrom_ver, 0, BFA_VERSION_LEN);\n\tmemcpy(optrom_ver, ioc->attr->optrom_version,\n\t\t      BFA_VERSION_LEN);\n}\n\nvoid\nbfa_ioc_get_adapter_manufacturer(struct bfa_ioc_s *ioc, char *manufacturer)\n{\n\tmemset((void *)manufacturer, 0, BFA_ADAPTER_MFG_NAME_LEN);\n\tstrscpy(manufacturer, BFA_MFG_NAME, BFA_ADAPTER_MFG_NAME_LEN);\n}\n\nvoid\nbfa_ioc_get_adapter_model(struct bfa_ioc_s *ioc, char *model)\n{\n\tstruct bfi_ioc_attr_s\t*ioc_attr;\n\tu8 nports = bfa_ioc_get_nports(ioc);\n\n\tWARN_ON(!model);\n\tmemset((void *)model, 0, BFA_ADAPTER_MODEL_NAME_LEN);\n\n\tioc_attr = ioc->attr;\n\n\tif (bfa_asic_id_ct2(ioc->pcidev.device_id) &&\n\t\t(!bfa_mfg_is_mezz(ioc_attr->card_type)))\n\t\tsnprintf(model, BFA_ADAPTER_MODEL_NAME_LEN, \"%s-%u-%u%s\",\n\t\t\tBFA_MFG_NAME, ioc_attr->card_type, nports, \"p\");\n\telse\n\t\tsnprintf(model, BFA_ADAPTER_MODEL_NAME_LEN, \"%s-%u\",\n\t\t\tBFA_MFG_NAME, ioc_attr->card_type);\n}\n\nenum bfa_ioc_state\nbfa_ioc_get_state(struct bfa_ioc_s *ioc)\n{\n\tenum bfa_iocpf_state iocpf_st;\n\tenum bfa_ioc_state ioc_st = bfa_sm_to_state(ioc_sm_table, ioc->fsm);\n\n\tif (ioc_st == BFA_IOC_ENABLING ||\n\t\tioc_st == BFA_IOC_FAIL || ioc_st == BFA_IOC_INITFAIL) {\n\n\t\tiocpf_st = bfa_sm_to_state(iocpf_sm_table, ioc->iocpf.fsm);\n\n\t\tswitch (iocpf_st) {\n\t\tcase BFA_IOCPF_SEMWAIT:\n\t\t\tioc_st = BFA_IOC_SEMWAIT;\n\t\t\tbreak;\n\n\t\tcase BFA_IOCPF_HWINIT:\n\t\t\tioc_st = BFA_IOC_HWINIT;\n\t\t\tbreak;\n\n\t\tcase BFA_IOCPF_FWMISMATCH:\n\t\t\tioc_st = BFA_IOC_FWMISMATCH;\n\t\t\tbreak;\n\n\t\tcase BFA_IOCPF_FAIL:\n\t\t\tioc_st = BFA_IOC_FAIL;\n\t\t\tbreak;\n\n\t\tcase BFA_IOCPF_INITFAIL:\n\t\t\tioc_st = BFA_IOC_INITFAIL;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ioc_st;\n}\n\nvoid\nbfa_ioc_get_attr(struct bfa_ioc_s *ioc, struct bfa_ioc_attr_s *ioc_attr)\n{\n\tmemset((void *)ioc_attr, 0, sizeof(struct bfa_ioc_attr_s));\n\n\tioc_attr->state = bfa_ioc_get_state(ioc);\n\tioc_attr->port_id = bfa_ioc_portid(ioc);\n\tioc_attr->port_mode = ioc->port_mode;\n\tioc_attr->port_mode_cfg = ioc->port_mode_cfg;\n\tioc_attr->cap_bm = ioc->ad_cap_bm;\n\n\tioc_attr->ioc_type = bfa_ioc_get_type(ioc);\n\n\tbfa_ioc_get_adapter_attr(ioc, &ioc_attr->adapter_attr);\n\n\tioc_attr->pci_attr.device_id = bfa_ioc_devid(ioc);\n\tioc_attr->pci_attr.pcifn = bfa_ioc_pcifn(ioc);\n\tioc_attr->def_fn = (bfa_ioc_pcifn(ioc) == bfa_ioc_portid(ioc));\n\tbfa_ioc_get_pci_chip_rev(ioc, ioc_attr->pci_attr.chip_rev);\n}\n\nmac_t\nbfa_ioc_get_mac(struct bfa_ioc_s *ioc)\n{\n\t \n\tif (bfa_ioc_get_type(ioc) == BFA_IOC_TYPE_FCoE)\n\t\treturn ioc->attr->fcoe_mac;\n\telse\n\t\treturn ioc->attr->mac;\n}\n\nmac_t\nbfa_ioc_get_mfg_mac(struct bfa_ioc_s *ioc)\n{\n\tmac_t\tm;\n\n\tm = ioc->attr->mfg_mac;\n\tif (bfa_mfg_is_old_wwn_mac_model(ioc->attr->card_type))\n\t\tm.mac[MAC_ADDRLEN - 1] += bfa_ioc_pcifn(ioc);\n\telse\n\t\tbfa_mfg_increment_wwn_mac(&(m.mac[MAC_ADDRLEN-3]),\n\t\t\tbfa_ioc_pcifn(ioc));\n\n\treturn m;\n}\n\n \nvoid\nbfa_ioc_aen_post(struct bfa_ioc_s *ioc, enum bfa_ioc_aen_event event)\n{\n\tstruct bfad_s *bfad = (struct bfad_s *)ioc->bfa->bfad;\n\tstruct bfa_aen_entry_s\t*aen_entry;\n\tenum bfa_ioc_type_e ioc_type;\n\n\tbfad_get_aen_entry(bfad, aen_entry);\n\tif (!aen_entry)\n\t\treturn;\n\n\tioc_type = bfa_ioc_get_type(ioc);\n\tswitch (ioc_type) {\n\tcase BFA_IOC_TYPE_FC:\n\t\taen_entry->aen_data.ioc.pwwn = ioc->attr->pwwn;\n\t\tbreak;\n\tcase BFA_IOC_TYPE_FCoE:\n\t\taen_entry->aen_data.ioc.pwwn = ioc->attr->pwwn;\n\t\taen_entry->aen_data.ioc.mac = bfa_ioc_get_mac(ioc);\n\t\tbreak;\n\tcase BFA_IOC_TYPE_LL:\n\t\taen_entry->aen_data.ioc.mac = bfa_ioc_get_mac(ioc);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(ioc_type != BFA_IOC_TYPE_FC);\n\t\tbreak;\n\t}\n\n\t \n\taen_entry->aen_data.ioc.ioc_type = ioc_type;\n\tbfad_im_post_vendor_event(aen_entry, bfad, ++ioc->ioc_aen_seq,\n\t\t\t\t  BFA_AEN_CAT_IOC, event);\n}\n\n \nbfa_status_t\nbfa_ioc_debug_fwsave(struct bfa_ioc_s *ioc, void *trcdata, int *trclen)\n{\n\tint\ttlen;\n\n\tif (ioc->dbg_fwsave_len == 0)\n\t\treturn BFA_STATUS_ENOFSAVE;\n\n\ttlen = *trclen;\n\tif (tlen > ioc->dbg_fwsave_len)\n\t\ttlen = ioc->dbg_fwsave_len;\n\n\tmemcpy(trcdata, ioc->dbg_fwsave, tlen);\n\t*trclen = tlen;\n\treturn BFA_STATUS_OK;\n}\n\n\n \nbfa_status_t\nbfa_ioc_debug_fwtrc(struct bfa_ioc_s *ioc, void *trcdata, int *trclen)\n{\n\tu32 loff = BFA_DBG_FWTRC_OFF(bfa_ioc_portid(ioc));\n\tint tlen;\n\tbfa_status_t status;\n\n\tbfa_trc(ioc, *trclen);\n\n\ttlen = *trclen;\n\tif (tlen > BFA_DBG_FWTRC_LEN)\n\t\ttlen = BFA_DBG_FWTRC_LEN;\n\n\tstatus = bfa_ioc_smem_read(ioc, trcdata, loff, tlen);\n\t*trclen = tlen;\n\treturn status;\n}\n\nstatic void\nbfa_ioc_send_fwsync(struct bfa_ioc_s *ioc)\n{\n\tstruct bfa_mbox_cmd_s cmd;\n\tstruct bfi_ioc_ctrl_req_s *req = (struct bfi_ioc_ctrl_req_s *) cmd.msg;\n\n\tbfi_h2i_set(req->mh, BFI_MC_IOC, BFI_IOC_H2I_DBG_SYNC,\n\t\t    bfa_ioc_portid(ioc));\n\treq->clscode = cpu_to_be16(ioc->clscode);\n\tbfa_ioc_mbox_queue(ioc, &cmd);\n}\n\nstatic void\nbfa_ioc_fwsync(struct bfa_ioc_s *ioc)\n{\n\tu32 fwsync_iter = 1000;\n\n\tbfa_ioc_send_fwsync(ioc);\n\n\t \n\twhile (bfa_ioc_mbox_cmd_pending(ioc) && fwsync_iter > 0)\n\t\tfwsync_iter--;\n}\n\n \nbfa_status_t\nbfa_ioc_debug_fwcore(struct bfa_ioc_s *ioc, void *buf,\n\t\t\t\tu32 *offset, int *buflen)\n{\n\tu32 loff;\n\tint dlen;\n\tbfa_status_t status;\n\tu32 smem_len = BFA_IOC_FW_SMEM_SIZE(ioc);\n\n\tif (*offset >= smem_len) {\n\t\t*offset = *buflen = 0;\n\t\treturn BFA_STATUS_EINVAL;\n\t}\n\n\tloff = *offset;\n\tdlen = *buflen;\n\n\t \n\tif (loff == 0)\n\t\tbfa_ioc_fwsync(ioc);\n\n\tif ((loff + dlen) >= smem_len)\n\t\tdlen = smem_len - loff;\n\n\tstatus = bfa_ioc_smem_read(ioc, buf, loff, dlen);\n\n\tif (status != BFA_STATUS_OK) {\n\t\t*offset = *buflen = 0;\n\t\treturn status;\n\t}\n\n\t*offset += dlen;\n\n\tif (*offset >= smem_len)\n\t\t*offset = 0;\n\n\t*buflen = dlen;\n\n\treturn status;\n}\n\n \nbfa_status_t\nbfa_ioc_fw_stats_get(struct bfa_ioc_s *ioc, void *stats)\n{\n\tu32 loff = BFI_IOC_FWSTATS_OFF + \\\n\t\tBFI_IOC_FWSTATS_SZ * (bfa_ioc_portid(ioc));\n\tint tlen;\n\tbfa_status_t status;\n\n\tif (ioc->stats_busy) {\n\t\tbfa_trc(ioc, ioc->stats_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\tioc->stats_busy = BFA_TRUE;\n\n\ttlen = sizeof(struct bfa_fw_stats_s);\n\tstatus = bfa_ioc_smem_read(ioc, stats, loff, tlen);\n\n\tioc->stats_busy = BFA_FALSE;\n\treturn status;\n}\n\nbfa_status_t\nbfa_ioc_fw_stats_clear(struct bfa_ioc_s *ioc)\n{\n\tu32 loff = BFI_IOC_FWSTATS_OFF + \\\n\t\tBFI_IOC_FWSTATS_SZ * (bfa_ioc_portid(ioc));\n\tint tlen;\n\tbfa_status_t status;\n\n\tif (ioc->stats_busy) {\n\t\tbfa_trc(ioc, ioc->stats_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\tioc->stats_busy = BFA_TRUE;\n\n\ttlen = sizeof(struct bfa_fw_stats_s);\n\tstatus = bfa_ioc_smem_clr(ioc, loff, tlen);\n\n\tioc->stats_busy = BFA_FALSE;\n\treturn status;\n}\n\n \nvoid\nbfa_ioc_debug_save_ftrc(struct bfa_ioc_s *ioc)\n{\n\tint\t\ttlen;\n\n\tif (ioc->dbg_fwsave_once) {\n\t\tioc->dbg_fwsave_once = BFA_FALSE;\n\t\tif (ioc->dbg_fwsave_len) {\n\t\t\ttlen = ioc->dbg_fwsave_len;\n\t\t\tbfa_ioc_debug_fwtrc(ioc, ioc->dbg_fwsave, &tlen);\n\t\t}\n\t}\n}\n\n \nstatic void\nbfa_ioc_recover(struct bfa_ioc_s *ioc)\n{\n\tbfa_ioc_stats(ioc, ioc_hbfails);\n\tioc->stats.hb_count = ioc->hb_count;\n\tbfa_fsm_send_event(ioc, IOC_E_HBFAIL);\n}\n\n \nstatic void\nbfa_iocpf_timeout(void *ioc_arg)\n{\n\tstruct bfa_ioc_s  *ioc = (struct bfa_ioc_s *) ioc_arg;\n\n\tbfa_trc(ioc, 0);\n\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_TIMEOUT);\n}\n\nstatic void\nbfa_iocpf_sem_timeout(void *ioc_arg)\n{\n\tstruct bfa_ioc_s  *ioc = (struct bfa_ioc_s *) ioc_arg;\n\n\tbfa_ioc_hw_sem_get(ioc);\n}\n\nstatic void\nbfa_ioc_poll_fwinit(struct bfa_ioc_s *ioc)\n{\n\tu32 fwstate = bfa_ioc_get_cur_ioc_fwstate(ioc);\n\n\tbfa_trc(ioc, fwstate);\n\n\tif (fwstate == BFI_IOC_DISABLED) {\n\t\tbfa_fsm_send_event(&ioc->iocpf, IOCPF_E_FWREADY);\n\t\treturn;\n\t}\n\n\tif (ioc->iocpf.poll_time >= (3 * BFA_IOC_TOV))\n\t\tbfa_iocpf_timeout(ioc);\n\telse {\n\t\tioc->iocpf.poll_time += BFA_IOC_POLL_TOV;\n\t\tbfa_iocpf_poll_timer_start(ioc);\n\t}\n}\n\nstatic void\nbfa_iocpf_poll_timeout(void *ioc_arg)\n{\n\tstruct bfa_ioc_s *ioc = (struct bfa_ioc_s *) ioc_arg;\n\n\tbfa_ioc_poll_fwinit(ioc);\n}\n\n \nvoid\nbfa_timer_beat(struct bfa_timer_mod_s *mod)\n{\n\tstruct list_head *qh = &mod->timer_q;\n\tstruct list_head *qe, *qe_next;\n\tstruct bfa_timer_s *elem;\n\tstruct list_head timedout_q;\n\n\tINIT_LIST_HEAD(&timedout_q);\n\n\tqe = bfa_q_next(qh);\n\n\twhile (qe != qh) {\n\t\tqe_next = bfa_q_next(qe);\n\n\t\telem = (struct bfa_timer_s *) qe;\n\t\tif (elem->timeout <= BFA_TIMER_FREQ) {\n\t\t\telem->timeout = 0;\n\t\t\tlist_del(&elem->qe);\n\t\t\tlist_add_tail(&elem->qe, &timedout_q);\n\t\t} else {\n\t\t\telem->timeout -= BFA_TIMER_FREQ;\n\t\t}\n\n\t\tqe = qe_next;\t \n\t}\n\n\t \n\twhile (!list_empty(&timedout_q)) {\n\t\tbfa_q_deq(&timedout_q, &elem);\n\t\telem->timercb(elem->arg);\n\t}\n}\n\n \nvoid\nbfa_timer_begin(struct bfa_timer_mod_s *mod, struct bfa_timer_s *timer,\n\t\t    void (*timercb) (void *), void *arg, unsigned int timeout)\n{\n\n\tWARN_ON(timercb == NULL);\n\tWARN_ON(bfa_q_is_on_q(&mod->timer_q, timer));\n\n\ttimer->timeout = timeout;\n\ttimer->timercb = timercb;\n\ttimer->arg = arg;\n\n\tlist_add_tail(&timer->qe, &mod->timer_q);\n}\n\n \nvoid\nbfa_timer_stop(struct bfa_timer_s *timer)\n{\n\tWARN_ON(list_empty(&timer->qe));\n\n\tlist_del(&timer->qe);\n}\n\n \nstatic void\nbfa_ablk_config_swap(struct bfa_ablk_cfg_s *cfg)\n{\n\tstruct bfa_ablk_cfg_inst_s *cfg_inst;\n\tint i, j;\n\tu16\tbe16;\n\n\tfor (i = 0; i < BFA_ABLK_MAX; i++) {\n\t\tcfg_inst = &cfg->inst[i];\n\t\tfor (j = 0; j < BFA_ABLK_MAX_PFS; j++) {\n\t\t\tbe16 = cfg_inst->pf_cfg[j].pers;\n\t\t\tcfg_inst->pf_cfg[j].pers = be16_to_cpu(be16);\n\t\t\tbe16 = cfg_inst->pf_cfg[j].num_qpairs;\n\t\t\tcfg_inst->pf_cfg[j].num_qpairs = be16_to_cpu(be16);\n\t\t\tbe16 = cfg_inst->pf_cfg[j].num_vectors;\n\t\t\tcfg_inst->pf_cfg[j].num_vectors = be16_to_cpu(be16);\n\t\t\tbe16 = cfg_inst->pf_cfg[j].bw_min;\n\t\t\tcfg_inst->pf_cfg[j].bw_min = be16_to_cpu(be16);\n\t\t\tbe16 = cfg_inst->pf_cfg[j].bw_max;\n\t\t\tcfg_inst->pf_cfg[j].bw_max = be16_to_cpu(be16);\n\t\t}\n\t}\n}\n\nstatic void\nbfa_ablk_isr(void *cbarg, struct bfi_mbmsg_s *msg)\n{\n\tstruct bfa_ablk_s *ablk = (struct bfa_ablk_s *)cbarg;\n\tstruct bfi_ablk_i2h_rsp_s *rsp = (struct bfi_ablk_i2h_rsp_s *)msg;\n\tbfa_ablk_cbfn_t cbfn;\n\n\tWARN_ON(msg->mh.msg_class != BFI_MC_ABLK);\n\tbfa_trc(ablk->ioc, msg->mh.msg_id);\n\n\tswitch (msg->mh.msg_id) {\n\tcase BFI_ABLK_I2H_QUERY:\n\t\tif (rsp->status == BFA_STATUS_OK) {\n\t\t\tmemcpy(ablk->cfg, ablk->dma_addr.kva,\n\t\t\t\tsizeof(struct bfa_ablk_cfg_s));\n\t\t\tbfa_ablk_config_swap(ablk->cfg);\n\t\t\tablk->cfg = NULL;\n\t\t}\n\t\tbreak;\n\n\tcase BFI_ABLK_I2H_ADPT_CONFIG:\n\tcase BFI_ABLK_I2H_PORT_CONFIG:\n\t\t \n\t\tablk->ioc->port_mode_cfg = rsp->port_mode;\n\t\tbreak;\n\n\tcase BFI_ABLK_I2H_PF_DELETE:\n\tcase BFI_ABLK_I2H_PF_UPDATE:\n\tcase BFI_ABLK_I2H_OPTROM_ENABLE:\n\tcase BFI_ABLK_I2H_OPTROM_DISABLE:\n\t\t \n\t\tbreak;\n\n\tcase BFI_ABLK_I2H_PF_CREATE:\n\t\t*(ablk->pcifn) = rsp->pcifn;\n\t\tablk->pcifn = NULL;\n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON(1);\n\t}\n\n\tablk->busy = BFA_FALSE;\n\tif (ablk->cbfn) {\n\t\tcbfn = ablk->cbfn;\n\t\tablk->cbfn = NULL;\n\t\tcbfn(ablk->cbarg, rsp->status);\n\t}\n}\n\nstatic void\nbfa_ablk_notify(void *cbarg, enum bfa_ioc_event_e event)\n{\n\tstruct bfa_ablk_s *ablk = (struct bfa_ablk_s *)cbarg;\n\n\tbfa_trc(ablk->ioc, event);\n\n\tswitch (event) {\n\tcase BFA_IOC_E_ENABLED:\n\t\tWARN_ON(ablk->busy != BFA_FALSE);\n\t\tbreak;\n\n\tcase BFA_IOC_E_DISABLED:\n\tcase BFA_IOC_E_FAILED:\n\t\t \n\t\tablk->pcifn = NULL;\n\t\tif (ablk->busy) {\n\t\t\tif (ablk->cbfn)\n\t\t\t\tablk->cbfn(ablk->cbarg, BFA_STATUS_FAILED);\n\t\t\tablk->cbfn = NULL;\n\t\t\tablk->busy = BFA_FALSE;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON(1);\n\t\tbreak;\n\t}\n}\n\nu32\nbfa_ablk_meminfo(void)\n{\n\treturn BFA_ROUNDUP(sizeof(struct bfa_ablk_cfg_s), BFA_DMA_ALIGN_SZ);\n}\n\nvoid\nbfa_ablk_memclaim(struct bfa_ablk_s *ablk, u8 *dma_kva, u64 dma_pa)\n{\n\tablk->dma_addr.kva = dma_kva;\n\tablk->dma_addr.pa  = dma_pa;\n}\n\nvoid\nbfa_ablk_attach(struct bfa_ablk_s *ablk, struct bfa_ioc_s *ioc)\n{\n\tablk->ioc = ioc;\n\n\tbfa_ioc_mbox_regisr(ablk->ioc, BFI_MC_ABLK, bfa_ablk_isr, ablk);\n\tbfa_q_qe_init(&ablk->ioc_notify);\n\tbfa_ioc_notify_init(&ablk->ioc_notify, bfa_ablk_notify, ablk);\n\tlist_add_tail(&ablk->ioc_notify.qe, &ablk->ioc->notify_q);\n}\n\nbfa_status_t\nbfa_ablk_query(struct bfa_ablk_s *ablk, struct bfa_ablk_cfg_s *ablk_cfg,\n\t\tbfa_ablk_cbfn_t cbfn, void *cbarg)\n{\n\tstruct bfi_ablk_h2i_query_s *m;\n\n\tWARN_ON(!ablk_cfg);\n\n\tif (!bfa_ioc_is_operational(ablk->ioc)) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_IOC_FAILURE);\n\t\treturn BFA_STATUS_IOC_FAILURE;\n\t}\n\n\tif (ablk->busy) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_DEVBUSY);\n\t\treturn  BFA_STATUS_DEVBUSY;\n\t}\n\n\tablk->cfg = ablk_cfg;\n\tablk->cbfn  = cbfn;\n\tablk->cbarg = cbarg;\n\tablk->busy  = BFA_TRUE;\n\n\tm = (struct bfi_ablk_h2i_query_s *)ablk->mb.msg;\n\tbfi_h2i_set(m->mh, BFI_MC_ABLK, BFI_ABLK_H2I_QUERY,\n\t\t    bfa_ioc_portid(ablk->ioc));\n\tbfa_dma_be_addr_set(m->addr, ablk->dma_addr.pa);\n\tbfa_ioc_mbox_queue(ablk->ioc, &ablk->mb);\n\n\treturn BFA_STATUS_OK;\n}\n\nbfa_status_t\nbfa_ablk_pf_create(struct bfa_ablk_s *ablk, u16 *pcifn,\n\t\tu8 port, enum bfi_pcifn_class personality,\n\t\tu16 bw_min, u16 bw_max,\n\t\tbfa_ablk_cbfn_t cbfn, void *cbarg)\n{\n\tstruct bfi_ablk_h2i_pf_req_s *m;\n\n\tif (!bfa_ioc_is_operational(ablk->ioc)) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_IOC_FAILURE);\n\t\treturn BFA_STATUS_IOC_FAILURE;\n\t}\n\n\tif (ablk->busy) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_DEVBUSY);\n\t\treturn  BFA_STATUS_DEVBUSY;\n\t}\n\n\tablk->pcifn = pcifn;\n\tablk->cbfn = cbfn;\n\tablk->cbarg = cbarg;\n\tablk->busy  = BFA_TRUE;\n\n\tm = (struct bfi_ablk_h2i_pf_req_s *)ablk->mb.msg;\n\tbfi_h2i_set(m->mh, BFI_MC_ABLK, BFI_ABLK_H2I_PF_CREATE,\n\t\t    bfa_ioc_portid(ablk->ioc));\n\tm->pers = cpu_to_be16((u16)personality);\n\tm->bw_min = cpu_to_be16(bw_min);\n\tm->bw_max = cpu_to_be16(bw_max);\n\tm->port = port;\n\tbfa_ioc_mbox_queue(ablk->ioc, &ablk->mb);\n\n\treturn BFA_STATUS_OK;\n}\n\nbfa_status_t\nbfa_ablk_pf_delete(struct bfa_ablk_s *ablk, int pcifn,\n\t\tbfa_ablk_cbfn_t cbfn, void *cbarg)\n{\n\tstruct bfi_ablk_h2i_pf_req_s *m;\n\n\tif (!bfa_ioc_is_operational(ablk->ioc)) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_IOC_FAILURE);\n\t\treturn BFA_STATUS_IOC_FAILURE;\n\t}\n\n\tif (ablk->busy) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_DEVBUSY);\n\t\treturn  BFA_STATUS_DEVBUSY;\n\t}\n\n\tablk->cbfn  = cbfn;\n\tablk->cbarg = cbarg;\n\tablk->busy  = BFA_TRUE;\n\n\tm = (struct bfi_ablk_h2i_pf_req_s *)ablk->mb.msg;\n\tbfi_h2i_set(m->mh, BFI_MC_ABLK, BFI_ABLK_H2I_PF_DELETE,\n\t\t    bfa_ioc_portid(ablk->ioc));\n\tm->pcifn = (u8)pcifn;\n\tbfa_ioc_mbox_queue(ablk->ioc, &ablk->mb);\n\n\treturn BFA_STATUS_OK;\n}\n\nbfa_status_t\nbfa_ablk_adapter_config(struct bfa_ablk_s *ablk, enum bfa_mode_s mode,\n\t\tint max_pf, int max_vf, bfa_ablk_cbfn_t cbfn, void *cbarg)\n{\n\tstruct bfi_ablk_h2i_cfg_req_s *m;\n\n\tif (!bfa_ioc_is_operational(ablk->ioc)) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_IOC_FAILURE);\n\t\treturn BFA_STATUS_IOC_FAILURE;\n\t}\n\n\tif (ablk->busy) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_DEVBUSY);\n\t\treturn  BFA_STATUS_DEVBUSY;\n\t}\n\n\tablk->cbfn  = cbfn;\n\tablk->cbarg = cbarg;\n\tablk->busy  = BFA_TRUE;\n\n\tm = (struct bfi_ablk_h2i_cfg_req_s *)ablk->mb.msg;\n\tbfi_h2i_set(m->mh, BFI_MC_ABLK, BFI_ABLK_H2I_ADPT_CONFIG,\n\t\t    bfa_ioc_portid(ablk->ioc));\n\tm->mode = (u8)mode;\n\tm->max_pf = (u8)max_pf;\n\tm->max_vf = (u8)max_vf;\n\tbfa_ioc_mbox_queue(ablk->ioc, &ablk->mb);\n\n\treturn BFA_STATUS_OK;\n}\n\nbfa_status_t\nbfa_ablk_port_config(struct bfa_ablk_s *ablk, int port, enum bfa_mode_s mode,\n\t\tint max_pf, int max_vf, bfa_ablk_cbfn_t cbfn, void *cbarg)\n{\n\tstruct bfi_ablk_h2i_cfg_req_s *m;\n\n\tif (!bfa_ioc_is_operational(ablk->ioc)) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_IOC_FAILURE);\n\t\treturn BFA_STATUS_IOC_FAILURE;\n\t}\n\n\tif (ablk->busy) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_DEVBUSY);\n\t\treturn  BFA_STATUS_DEVBUSY;\n\t}\n\n\tablk->cbfn  = cbfn;\n\tablk->cbarg = cbarg;\n\tablk->busy  = BFA_TRUE;\n\n\tm = (struct bfi_ablk_h2i_cfg_req_s *)ablk->mb.msg;\n\tbfi_h2i_set(m->mh, BFI_MC_ABLK, BFI_ABLK_H2I_PORT_CONFIG,\n\t\tbfa_ioc_portid(ablk->ioc));\n\tm->port = (u8)port;\n\tm->mode = (u8)mode;\n\tm->max_pf = (u8)max_pf;\n\tm->max_vf = (u8)max_vf;\n\tbfa_ioc_mbox_queue(ablk->ioc, &ablk->mb);\n\n\treturn BFA_STATUS_OK;\n}\n\nbfa_status_t\nbfa_ablk_pf_update(struct bfa_ablk_s *ablk, int pcifn, u16 bw_min,\n\t\t   u16 bw_max, bfa_ablk_cbfn_t cbfn, void *cbarg)\n{\n\tstruct bfi_ablk_h2i_pf_req_s *m;\n\n\tif (!bfa_ioc_is_operational(ablk->ioc)) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_IOC_FAILURE);\n\t\treturn BFA_STATUS_IOC_FAILURE;\n\t}\n\n\tif (ablk->busy) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_DEVBUSY);\n\t\treturn  BFA_STATUS_DEVBUSY;\n\t}\n\n\tablk->cbfn  = cbfn;\n\tablk->cbarg = cbarg;\n\tablk->busy  = BFA_TRUE;\n\n\tm = (struct bfi_ablk_h2i_pf_req_s *)ablk->mb.msg;\n\tbfi_h2i_set(m->mh, BFI_MC_ABLK, BFI_ABLK_H2I_PF_UPDATE,\n\t\tbfa_ioc_portid(ablk->ioc));\n\tm->pcifn = (u8)pcifn;\n\tm->bw_min = cpu_to_be16(bw_min);\n\tm->bw_max = cpu_to_be16(bw_max);\n\tbfa_ioc_mbox_queue(ablk->ioc, &ablk->mb);\n\n\treturn BFA_STATUS_OK;\n}\n\nbfa_status_t\nbfa_ablk_optrom_en(struct bfa_ablk_s *ablk, bfa_ablk_cbfn_t cbfn, void *cbarg)\n{\n\tstruct bfi_ablk_h2i_optrom_s *m;\n\n\tif (!bfa_ioc_is_operational(ablk->ioc)) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_IOC_FAILURE);\n\t\treturn BFA_STATUS_IOC_FAILURE;\n\t}\n\n\tif (ablk->busy) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_DEVBUSY);\n\t\treturn  BFA_STATUS_DEVBUSY;\n\t}\n\n\tablk->cbfn  = cbfn;\n\tablk->cbarg = cbarg;\n\tablk->busy  = BFA_TRUE;\n\n\tm = (struct bfi_ablk_h2i_optrom_s *)ablk->mb.msg;\n\tbfi_h2i_set(m->mh, BFI_MC_ABLK, BFI_ABLK_H2I_OPTROM_ENABLE,\n\t\tbfa_ioc_portid(ablk->ioc));\n\tbfa_ioc_mbox_queue(ablk->ioc, &ablk->mb);\n\n\treturn BFA_STATUS_OK;\n}\n\nbfa_status_t\nbfa_ablk_optrom_dis(struct bfa_ablk_s *ablk, bfa_ablk_cbfn_t cbfn, void *cbarg)\n{\n\tstruct bfi_ablk_h2i_optrom_s *m;\n\n\tif (!bfa_ioc_is_operational(ablk->ioc)) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_IOC_FAILURE);\n\t\treturn BFA_STATUS_IOC_FAILURE;\n\t}\n\n\tif (ablk->busy) {\n\t\tbfa_trc(ablk->ioc, BFA_STATUS_DEVBUSY);\n\t\treturn  BFA_STATUS_DEVBUSY;\n\t}\n\n\tablk->cbfn  = cbfn;\n\tablk->cbarg = cbarg;\n\tablk->busy  = BFA_TRUE;\n\n\tm = (struct bfi_ablk_h2i_optrom_s *)ablk->mb.msg;\n\tbfi_h2i_set(m->mh, BFI_MC_ABLK, BFI_ABLK_H2I_OPTROM_DISABLE,\n\t\tbfa_ioc_portid(ablk->ioc));\n\tbfa_ioc_mbox_queue(ablk->ioc, &ablk->mb);\n\n\treturn BFA_STATUS_OK;\n}\n\n \n\n \nstatic void bfa_sfp_getdata_send(struct bfa_sfp_s *sfp);\nstatic void bfa_sfp_media_get(struct bfa_sfp_s *sfp);\nstatic bfa_status_t bfa_sfp_speed_valid(struct bfa_sfp_s *sfp,\n\t\t\t\tenum bfa_port_speed portspeed);\n\nstatic void\nbfa_cb_sfp_show(struct bfa_sfp_s *sfp)\n{\n\tbfa_trc(sfp, sfp->lock);\n\tif (sfp->cbfn)\n\t\tsfp->cbfn(sfp->cbarg, sfp->status);\n\tsfp->lock = 0;\n\tsfp->cbfn = NULL;\n}\n\nstatic void\nbfa_cb_sfp_state_query(struct bfa_sfp_s *sfp)\n{\n\tbfa_trc(sfp, sfp->portspeed);\n\tif (sfp->media) {\n\t\tbfa_sfp_media_get(sfp);\n\t\tif (sfp->state_query_cbfn)\n\t\t\tsfp->state_query_cbfn(sfp->state_query_cbarg,\n\t\t\t\t\tsfp->status);\n\t\tsfp->media = NULL;\n\t}\n\n\tif (sfp->portspeed) {\n\t\tsfp->status = bfa_sfp_speed_valid(sfp, sfp->portspeed);\n\t\tif (sfp->state_query_cbfn)\n\t\t\tsfp->state_query_cbfn(sfp->state_query_cbarg,\n\t\t\t\t\tsfp->status);\n\t\tsfp->portspeed = BFA_PORT_SPEED_UNKNOWN;\n\t}\n\n\tsfp->state_query_lock = 0;\n\tsfp->state_query_cbfn = NULL;\n}\n\n \nstatic void\nbfa_sfp_notify(void *sfp_arg, enum bfa_ioc_event_e event)\n{\n\tstruct bfa_sfp_s *sfp = sfp_arg;\n\n\tbfa_trc(sfp, event);\n\tbfa_trc(sfp, sfp->lock);\n\tbfa_trc(sfp, sfp->state_query_lock);\n\n\tswitch (event) {\n\tcase BFA_IOC_E_DISABLED:\n\tcase BFA_IOC_E_FAILED:\n\t\tif (sfp->lock) {\n\t\t\tsfp->status = BFA_STATUS_IOC_FAILURE;\n\t\t\tbfa_cb_sfp_show(sfp);\n\t\t}\n\n\t\tif (sfp->state_query_lock) {\n\t\t\tsfp->status = BFA_STATUS_IOC_FAILURE;\n\t\t\tbfa_cb_sfp_state_query(sfp);\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n \nstatic void\nbfa_sfp_scn_aen_post(struct bfa_sfp_s *sfp, struct bfi_sfp_scn_s *rsp)\n{\n\tstruct bfad_s *bfad = (struct bfad_s *)sfp->ioc->bfa->bfad;\n\tstruct bfa_aen_entry_s  *aen_entry;\n\tenum bfa_port_aen_event aen_evt = 0;\n\n\tbfa_trc(sfp, (((u64)rsp->pomlvl) << 16) | (((u64)rsp->sfpid) << 8) |\n\t\t      ((u64)rsp->event));\n\n\tbfad_get_aen_entry(bfad, aen_entry);\n\tif (!aen_entry)\n\t\treturn;\n\n\taen_entry->aen_data.port.ioc_type = bfa_ioc_get_type(sfp->ioc);\n\taen_entry->aen_data.port.pwwn = sfp->ioc->attr->pwwn;\n\taen_entry->aen_data.port.mac = bfa_ioc_get_mac(sfp->ioc);\n\n\tswitch (rsp->event) {\n\tcase BFA_SFP_SCN_INSERTED:\n\t\taen_evt = BFA_PORT_AEN_SFP_INSERT;\n\t\tbreak;\n\tcase BFA_SFP_SCN_REMOVED:\n\t\taen_evt = BFA_PORT_AEN_SFP_REMOVE;\n\t\tbreak;\n\tcase BFA_SFP_SCN_FAILED:\n\t\taen_evt = BFA_PORT_AEN_SFP_ACCESS_ERROR;\n\t\tbreak;\n\tcase BFA_SFP_SCN_UNSUPPORT:\n\t\taen_evt = BFA_PORT_AEN_SFP_UNSUPPORT;\n\t\tbreak;\n\tcase BFA_SFP_SCN_POM:\n\t\taen_evt = BFA_PORT_AEN_SFP_POM;\n\t\taen_entry->aen_data.port.level = rsp->pomlvl;\n\t\tbreak;\n\tdefault:\n\t\tbfa_trc(sfp, rsp->event);\n\t\tWARN_ON(1);\n\t}\n\n\t \n\tbfad_im_post_vendor_event(aen_entry, bfad, ++sfp->ioc->ioc_aen_seq,\n\t\t\t\t  BFA_AEN_CAT_PORT, aen_evt);\n}\n\n \nstatic void\nbfa_sfp_getdata_send(struct bfa_sfp_s *sfp)\n{\n\tstruct bfi_sfp_req_s *req = (struct bfi_sfp_req_s *)sfp->mbcmd.msg;\n\n\tbfa_trc(sfp, req->memtype);\n\n\t \n\tbfi_h2i_set(req->mh, BFI_MC_SFP, BFI_SFP_H2I_SHOW,\n\t\t\tbfa_ioc_portid(sfp->ioc));\n\n\t \n\tbfa_ioc_mbox_queue(sfp->ioc, &sfp->mbcmd);\n}\n\n \nstatic void\nbfa_sfp_getdata(struct bfa_sfp_s *sfp, enum bfi_sfp_mem_e memtype)\n{\n\tstruct bfi_sfp_req_s *req = (struct bfi_sfp_req_s *)sfp->mbcmd.msg;\n\n\tWARN_ON(sfp->lock != 0);\n\tbfa_trc(sfp, sfp->state);\n\n\tsfp->lock = 1;\n\tsfp->memtype = memtype;\n\treq->memtype = memtype;\n\n\t \n\tbfa_alen_set(&req->alen, sizeof(struct sfp_mem_s), sfp->dbuf_pa);\n\n\tbfa_sfp_getdata_send(sfp);\n}\n\n \nstatic void\nbfa_sfp_scn(struct bfa_sfp_s *sfp, struct bfi_mbmsg_s *msg)\n{\n\tstruct bfi_sfp_scn_s *rsp = (struct bfi_sfp_scn_s *) msg;\n\n\tswitch (rsp->event) {\n\tcase BFA_SFP_SCN_INSERTED:\n\t\tsfp->state = BFA_SFP_STATE_INSERTED;\n\t\tsfp->data_valid = 0;\n\t\tbfa_sfp_scn_aen_post(sfp, rsp);\n\t\tbreak;\n\tcase BFA_SFP_SCN_REMOVED:\n\t\tsfp->state = BFA_SFP_STATE_REMOVED;\n\t\tsfp->data_valid = 0;\n\t\tbfa_sfp_scn_aen_post(sfp, rsp);\n\t\tbreak;\n\tcase BFA_SFP_SCN_FAILED:\n\t\tsfp->state = BFA_SFP_STATE_FAILED;\n\t\tsfp->data_valid = 0;\n\t\tbfa_sfp_scn_aen_post(sfp, rsp);\n\t\tbreak;\n\tcase BFA_SFP_SCN_UNSUPPORT:\n\t\tsfp->state = BFA_SFP_STATE_UNSUPPORT;\n\t\tbfa_sfp_scn_aen_post(sfp, rsp);\n\t\tif (!sfp->lock)\n\t\t\tbfa_sfp_getdata(sfp, BFI_SFP_MEM_ALL);\n\t\tbreak;\n\tcase BFA_SFP_SCN_POM:\n\t\tbfa_sfp_scn_aen_post(sfp, rsp);\n\t\tbreak;\n\tcase BFA_SFP_SCN_VALID:\n\t\tsfp->state = BFA_SFP_STATE_VALID;\n\t\tif (!sfp->lock)\n\t\t\tbfa_sfp_getdata(sfp, BFI_SFP_MEM_ALL);\n\t\tbreak;\n\tdefault:\n\t\tbfa_trc(sfp, rsp->event);\n\t\tWARN_ON(1);\n\t}\n}\n\n \nstatic void\nbfa_sfp_show_comp(struct bfa_sfp_s *sfp, struct bfi_mbmsg_s *msg)\n{\n\tstruct bfi_sfp_rsp_s *rsp = (struct bfi_sfp_rsp_s *) msg;\n\n\tif (!sfp->lock) {\n\t\t \n\t\tbfa_trc(sfp, sfp->lock);\n\t\treturn;\n\t}\n\n\tbfa_trc(sfp, rsp->status);\n\tif (rsp->status == BFA_STATUS_OK) {\n\t\tsfp->data_valid = 1;\n\t\tif (sfp->state == BFA_SFP_STATE_VALID)\n\t\t\tsfp->status = BFA_STATUS_OK;\n\t\telse if (sfp->state == BFA_SFP_STATE_UNSUPPORT)\n\t\t\tsfp->status = BFA_STATUS_SFP_UNSUPP;\n\t\telse\n\t\t\tbfa_trc(sfp, sfp->state);\n\t} else {\n\t\tsfp->data_valid = 0;\n\t\tsfp->status = rsp->status;\n\t\t \n\t}\n\n\tbfa_trc(sfp, sfp->memtype);\n\tif (sfp->memtype == BFI_SFP_MEM_DIAGEXT) {\n\t\tbfa_trc(sfp, sfp->data_valid);\n\t\tif (sfp->data_valid) {\n\t\t\tu32\tsize = sizeof(struct sfp_mem_s);\n\t\t\tu8 *des = (u8 *)(sfp->sfpmem);\n\t\t\tmemcpy(des, sfp->dbuf_kva, size);\n\t\t}\n\t\t \n\t\tbfa_cb_sfp_show(sfp);\n\t} else\n\t\tsfp->lock = 0;\n\n\tbfa_trc(sfp, sfp->state_query_lock);\n\tif (sfp->state_query_lock) {\n\t\tsfp->state = rsp->state;\n\t\t \n\t\tbfa_cb_sfp_state_query(sfp);\n\t}\n}\n\n \nstatic void\nbfa_sfp_state_query(struct bfa_sfp_s *sfp)\n{\n\tstruct bfi_sfp_req_s *req = (struct bfi_sfp_req_s *)sfp->mbcmd.msg;\n\n\t \n\tWARN_ON(sfp->state != BFA_SFP_STATE_INIT);\n\tWARN_ON(sfp->state_query_lock != 0);\n\tbfa_trc(sfp, sfp->state);\n\n\tsfp->state_query_lock = 1;\n\treq->memtype = 0;\n\n\tif (!sfp->lock)\n\t\tbfa_sfp_getdata(sfp, BFI_SFP_MEM_ALL);\n}\n\nstatic void\nbfa_sfp_media_get(struct bfa_sfp_s *sfp)\n{\n\tenum bfa_defs_sfp_media_e *media = sfp->media;\n\n\t*media = BFA_SFP_MEDIA_UNKNOWN;\n\n\tif (sfp->state == BFA_SFP_STATE_UNSUPPORT)\n\t\t*media = BFA_SFP_MEDIA_UNSUPPORT;\n\telse if (sfp->state == BFA_SFP_STATE_VALID) {\n\t\tunion sfp_xcvr_e10g_code_u e10g;\n\t\tstruct sfp_mem_s *sfpmem = (struct sfp_mem_s *)sfp->dbuf_kva;\n\t\tu16 xmtr_tech = (sfpmem->srlid_base.xcvr[4] & 0x3) << 7 |\n\t\t\t\t(sfpmem->srlid_base.xcvr[5] >> 1);\n\n\t\te10g.b = sfpmem->srlid_base.xcvr[0];\n\t\tbfa_trc(sfp, e10g.b);\n\t\tbfa_trc(sfp, xmtr_tech);\n\t\t \n\t\tif ((xmtr_tech & SFP_XMTR_TECH_CU) ||\n\t\t    (xmtr_tech & SFP_XMTR_TECH_CP) ||\n\t\t    (xmtr_tech & SFP_XMTR_TECH_CA))\n\t\t\t*media = BFA_SFP_MEDIA_CU;\n\t\telse if ((xmtr_tech & SFP_XMTR_TECH_EL_INTRA) ||\n\t\t\t (xmtr_tech & SFP_XMTR_TECH_EL_INTER))\n\t\t\t*media = BFA_SFP_MEDIA_EL;\n\t\telse if ((xmtr_tech & SFP_XMTR_TECH_LL) ||\n\t\t\t (xmtr_tech & SFP_XMTR_TECH_LC))\n\t\t\t*media = BFA_SFP_MEDIA_LW;\n\t\telse if ((xmtr_tech & SFP_XMTR_TECH_SL) ||\n\t\t\t (xmtr_tech & SFP_XMTR_TECH_SN) ||\n\t\t\t (xmtr_tech & SFP_XMTR_TECH_SA))\n\t\t\t*media = BFA_SFP_MEDIA_SW;\n\t\t \n\t\telse if (e10g.r.e10g_sr)\n\t\t\t*media = BFA_SFP_MEDIA_SW;\n\t\telse if (e10g.r.e10g_lrm && e10g.r.e10g_lr)\n\t\t\t*media = BFA_SFP_MEDIA_LW;\n\t\telse if (e10g.r.e10g_unall)\n\t\t\t*media = BFA_SFP_MEDIA_UNKNOWN;\n\t\telse\n\t\t\tbfa_trc(sfp, 0);\n\t} else\n\t\tbfa_trc(sfp, sfp->state);\n}\n\nstatic bfa_status_t\nbfa_sfp_speed_valid(struct bfa_sfp_s *sfp, enum bfa_port_speed portspeed)\n{\n\tstruct sfp_mem_s *sfpmem = (struct sfp_mem_s *)sfp->dbuf_kva;\n\tstruct sfp_xcvr_s *xcvr = (struct sfp_xcvr_s *) sfpmem->srlid_base.xcvr;\n\tunion sfp_xcvr_fc3_code_u fc3 = xcvr->fc3;\n\tunion sfp_xcvr_e10g_code_u e10g = xcvr->e10g;\n\n\tif (portspeed == BFA_PORT_SPEED_10GBPS) {\n\t\tif (e10g.r.e10g_sr || e10g.r.e10g_lr)\n\t\t\treturn BFA_STATUS_OK;\n\t\telse {\n\t\t\tbfa_trc(sfp, e10g.b);\n\t\t\treturn BFA_STATUS_UNSUPP_SPEED;\n\t\t}\n\t}\n\tif (((portspeed & BFA_PORT_SPEED_16GBPS) && fc3.r.mb1600) ||\n\t    ((portspeed & BFA_PORT_SPEED_8GBPS) && fc3.r.mb800) ||\n\t    ((portspeed & BFA_PORT_SPEED_4GBPS) && fc3.r.mb400) ||\n\t    ((portspeed & BFA_PORT_SPEED_2GBPS) && fc3.r.mb200) ||\n\t    ((portspeed & BFA_PORT_SPEED_1GBPS) && fc3.r.mb100))\n\t\treturn BFA_STATUS_OK;\n\telse {\n\t\tbfa_trc(sfp, portspeed);\n\t\tbfa_trc(sfp, fc3.b);\n\t\tbfa_trc(sfp, e10g.b);\n\t\treturn BFA_STATUS_UNSUPP_SPEED;\n\t}\n}\n\n \nvoid\nbfa_sfp_intr(void *sfparg, struct bfi_mbmsg_s *msg)\n{\n\tstruct bfa_sfp_s *sfp = sfparg;\n\n\tswitch (msg->mh.msg_id) {\n\tcase BFI_SFP_I2H_SHOW:\n\t\tbfa_sfp_show_comp(sfp, msg);\n\t\tbreak;\n\n\tcase BFI_SFP_I2H_SCN:\n\t\tbfa_sfp_scn(sfp, msg);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_trc(sfp, msg->mh.msg_id);\n\t\tWARN_ON(1);\n\t}\n}\n\n \nu32\nbfa_sfp_meminfo(void)\n{\n\treturn BFA_ROUNDUP(sizeof(struct sfp_mem_s), BFA_DMA_ALIGN_SZ);\n}\n\n \nvoid\nbfa_sfp_attach(struct bfa_sfp_s *sfp, struct bfa_ioc_s *ioc, void *dev,\n\t\tstruct bfa_trc_mod_s *trcmod)\n{\n\tsfp->dev = dev;\n\tsfp->ioc = ioc;\n\tsfp->trcmod = trcmod;\n\n\tsfp->cbfn = NULL;\n\tsfp->cbarg = NULL;\n\tsfp->sfpmem = NULL;\n\tsfp->lock = 0;\n\tsfp->data_valid = 0;\n\tsfp->state = BFA_SFP_STATE_INIT;\n\tsfp->state_query_lock = 0;\n\tsfp->state_query_cbfn = NULL;\n\tsfp->state_query_cbarg = NULL;\n\tsfp->media = NULL;\n\tsfp->portspeed = BFA_PORT_SPEED_UNKNOWN;\n\tsfp->is_elb = BFA_FALSE;\n\n\tbfa_ioc_mbox_regisr(sfp->ioc, BFI_MC_SFP, bfa_sfp_intr, sfp);\n\tbfa_q_qe_init(&sfp->ioc_notify);\n\tbfa_ioc_notify_init(&sfp->ioc_notify, bfa_sfp_notify, sfp);\n\tlist_add_tail(&sfp->ioc_notify.qe, &sfp->ioc->notify_q);\n}\n\n \nvoid\nbfa_sfp_memclaim(struct bfa_sfp_s *sfp, u8 *dm_kva, u64 dm_pa)\n{\n\tsfp->dbuf_kva   = dm_kva;\n\tsfp->dbuf_pa    = dm_pa;\n\tmemset(sfp->dbuf_kva, 0, sizeof(struct sfp_mem_s));\n\n\tdm_kva += BFA_ROUNDUP(sizeof(struct sfp_mem_s), BFA_DMA_ALIGN_SZ);\n\tdm_pa += BFA_ROUNDUP(sizeof(struct sfp_mem_s), BFA_DMA_ALIGN_SZ);\n}\n\n \nbfa_status_t\nbfa_sfp_show(struct bfa_sfp_s *sfp, struct sfp_mem_s *sfpmem,\n\t\tbfa_cb_sfp_t cbfn, void *cbarg)\n{\n\n\tif (!bfa_ioc_is_operational(sfp->ioc)) {\n\t\tbfa_trc(sfp, 0);\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\t}\n\n\tif (sfp->lock) {\n\t\tbfa_trc(sfp, 0);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tsfp->cbfn = cbfn;\n\tsfp->cbarg = cbarg;\n\tsfp->sfpmem = sfpmem;\n\n\tbfa_sfp_getdata(sfp, BFI_SFP_MEM_DIAGEXT);\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_sfp_media(struct bfa_sfp_s *sfp, enum bfa_defs_sfp_media_e *media,\n\t\tbfa_cb_sfp_t cbfn, void *cbarg)\n{\n\tif (!bfa_ioc_is_operational(sfp->ioc)) {\n\t\tbfa_trc(sfp, 0);\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\t}\n\n\tsfp->media = media;\n\tif (sfp->state == BFA_SFP_STATE_INIT) {\n\t\tif (sfp->state_query_lock) {\n\t\t\tbfa_trc(sfp, 0);\n\t\t\treturn BFA_STATUS_DEVBUSY;\n\t\t} else {\n\t\t\tsfp->state_query_cbfn = cbfn;\n\t\t\tsfp->state_query_cbarg = cbarg;\n\t\t\tbfa_sfp_state_query(sfp);\n\t\t\treturn BFA_STATUS_SFP_NOT_READY;\n\t\t}\n\t}\n\n\tbfa_sfp_media_get(sfp);\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_sfp_speed(struct bfa_sfp_s *sfp, enum bfa_port_speed portspeed,\n\t\tbfa_cb_sfp_t cbfn, void *cbarg)\n{\n\tWARN_ON(portspeed == BFA_PORT_SPEED_UNKNOWN);\n\n\tif (!bfa_ioc_is_operational(sfp->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\t \n\tif (bfa_mfg_is_mezz(sfp->ioc->attr->card_type))\n\t\treturn BFA_STATUS_OK;\n\n\t \n\tsfp->portspeed = portspeed;\n\tif (sfp->state == BFA_SFP_STATE_INIT) {\n\t\tif (sfp->state_query_lock) {\n\t\t\tbfa_trc(sfp, 0);\n\t\t\treturn BFA_STATUS_DEVBUSY;\n\t\t} else {\n\t\t\tsfp->state_query_cbfn = cbfn;\n\t\t\tsfp->state_query_cbarg = cbarg;\n\t\t\tbfa_sfp_state_query(sfp);\n\t\t\treturn BFA_STATUS_SFP_NOT_READY;\n\t\t}\n\t}\n\n\tif (sfp->state == BFA_SFP_STATE_REMOVED ||\n\t    sfp->state == BFA_SFP_STATE_FAILED) {\n\t\tbfa_trc(sfp, sfp->state);\n\t\treturn BFA_STATUS_NO_SFP_DEV;\n\t}\n\n\tif (sfp->state == BFA_SFP_STATE_INSERTED) {\n\t\tbfa_trc(sfp, sfp->state);\n\t\treturn BFA_STATUS_DEVBUSY;   \n\t}\n\n\t \n\tif (sfp->is_elb)\n\t\treturn BFA_STATUS_OK;\n\n\treturn bfa_sfp_speed_valid(sfp, portspeed);\n}\n\n \n\n \n#define BFA_FLASH_SEG_SZ\t2048\n#define BFA_FLASH_DMA_BUF_SZ\t\\\n\tBFA_ROUNDUP(0x010000 + sizeof(struct bfa_mfg_block_s), BFA_FLASH_SEG_SZ)\n\nstatic void\nbfa_flash_aen_audit_post(struct bfa_ioc_s *ioc, enum bfa_audit_aen_event event,\n\t\t\tint inst, int type)\n{\n\tstruct bfad_s *bfad = (struct bfad_s *)ioc->bfa->bfad;\n\tstruct bfa_aen_entry_s  *aen_entry;\n\n\tbfad_get_aen_entry(bfad, aen_entry);\n\tif (!aen_entry)\n\t\treturn;\n\n\taen_entry->aen_data.audit.pwwn = ioc->attr->pwwn;\n\taen_entry->aen_data.audit.partition_inst = inst;\n\taen_entry->aen_data.audit.partition_type = type;\n\n\t \n\tbfad_im_post_vendor_event(aen_entry, bfad, ++ioc->ioc_aen_seq,\n\t\t\t\t  BFA_AEN_CAT_AUDIT, event);\n}\n\nstatic void\nbfa_flash_cb(struct bfa_flash_s *flash)\n{\n\tflash->op_busy = 0;\n\tif (flash->cbfn)\n\t\tflash->cbfn(flash->cbarg, flash->status);\n}\n\nstatic void\nbfa_flash_notify(void *cbarg, enum bfa_ioc_event_e event)\n{\n\tstruct bfa_flash_s\t*flash = cbarg;\n\n\tbfa_trc(flash, event);\n\tswitch (event) {\n\tcase BFA_IOC_E_DISABLED:\n\tcase BFA_IOC_E_FAILED:\n\t\tif (flash->op_busy) {\n\t\t\tflash->status = BFA_STATUS_IOC_FAILURE;\n\t\t\tflash->cbfn(flash->cbarg, flash->status);\n\t\t\tflash->op_busy = 0;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n \nstatic void\nbfa_flash_query_send(void *cbarg)\n{\n\tstruct bfa_flash_s *flash = cbarg;\n\tstruct bfi_flash_query_req_s *msg =\n\t\t\t(struct bfi_flash_query_req_s *) flash->mb.msg;\n\n\tbfi_h2i_set(msg->mh, BFI_MC_FLASH, BFI_FLASH_H2I_QUERY_REQ,\n\t\tbfa_ioc_portid(flash->ioc));\n\tbfa_alen_set(&msg->alen, sizeof(struct bfa_flash_attr_s),\n\t\tflash->dbuf_pa);\n\tbfa_ioc_mbox_queue(flash->ioc, &flash->mb);\n}\n\n \nstatic void\nbfa_flash_write_send(struct bfa_flash_s *flash)\n{\n\tstruct bfi_flash_write_req_s *msg =\n\t\t\t(struct bfi_flash_write_req_s *) flash->mb.msg;\n\tu32\tlen;\n\n\tmsg->type = be32_to_cpu(flash->type);\n\tmsg->instance = flash->instance;\n\tmsg->offset = be32_to_cpu(flash->addr_off + flash->offset);\n\tlen = (flash->residue < BFA_FLASH_DMA_BUF_SZ) ?\n\t\tflash->residue : BFA_FLASH_DMA_BUF_SZ;\n\tmsg->length = be32_to_cpu(len);\n\n\t \n\tmsg->last = (len == flash->residue) ? 1 : 0;\n\n\tbfi_h2i_set(msg->mh, BFI_MC_FLASH, BFI_FLASH_H2I_WRITE_REQ,\n\t\t\tbfa_ioc_portid(flash->ioc));\n\tbfa_alen_set(&msg->alen, len, flash->dbuf_pa);\n\tmemcpy(flash->dbuf_kva, flash->ubuf + flash->offset, len);\n\tbfa_ioc_mbox_queue(flash->ioc, &flash->mb);\n\n\tflash->residue -= len;\n\tflash->offset += len;\n}\n\n \nstatic void\nbfa_flash_read_send(void *cbarg)\n{\n\tstruct bfa_flash_s *flash = cbarg;\n\tstruct bfi_flash_read_req_s *msg =\n\t\t\t(struct bfi_flash_read_req_s *) flash->mb.msg;\n\tu32\tlen;\n\n\tmsg->type = be32_to_cpu(flash->type);\n\tmsg->instance = flash->instance;\n\tmsg->offset = be32_to_cpu(flash->addr_off + flash->offset);\n\tlen = (flash->residue < BFA_FLASH_DMA_BUF_SZ) ?\n\t\t\tflash->residue : BFA_FLASH_DMA_BUF_SZ;\n\tmsg->length = be32_to_cpu(len);\n\tbfi_h2i_set(msg->mh, BFI_MC_FLASH, BFI_FLASH_H2I_READ_REQ,\n\t\tbfa_ioc_portid(flash->ioc));\n\tbfa_alen_set(&msg->alen, len, flash->dbuf_pa);\n\tbfa_ioc_mbox_queue(flash->ioc, &flash->mb);\n}\n\n \nstatic void\nbfa_flash_erase_send(void *cbarg)\n{\n\tstruct bfa_flash_s *flash = cbarg;\n\tstruct bfi_flash_erase_req_s *msg =\n\t\t\t(struct bfi_flash_erase_req_s *) flash->mb.msg;\n\n\tmsg->type = be32_to_cpu(flash->type);\n\tmsg->instance = flash->instance;\n\tbfi_h2i_set(msg->mh, BFI_MC_FLASH, BFI_FLASH_H2I_ERASE_REQ,\n\t\t\tbfa_ioc_portid(flash->ioc));\n\tbfa_ioc_mbox_queue(flash->ioc, &flash->mb);\n}\n\n \nstatic void\nbfa_flash_intr(void *flasharg, struct bfi_mbmsg_s *msg)\n{\n\tstruct bfa_flash_s *flash = flasharg;\n\tu32\tstatus;\n\n\tunion {\n\t\tstruct bfi_flash_query_rsp_s *query;\n\t\tstruct bfi_flash_erase_rsp_s *erase;\n\t\tstruct bfi_flash_write_rsp_s *write;\n\t\tstruct bfi_flash_read_rsp_s *read;\n\t\tstruct bfi_flash_event_s *event;\n\t\tstruct bfi_mbmsg_s   *msg;\n\t} m;\n\n\tm.msg = msg;\n\tbfa_trc(flash, msg->mh.msg_id);\n\n\tif (!flash->op_busy && msg->mh.msg_id != BFI_FLASH_I2H_EVENT) {\n\t\t \n\t\tbfa_trc(flash, 0x9999);\n\t\treturn;\n\t}\n\n\tswitch (msg->mh.msg_id) {\n\tcase BFI_FLASH_I2H_QUERY_RSP:\n\t\tstatus = be32_to_cpu(m.query->status);\n\t\tbfa_trc(flash, status);\n\t\tif (status == BFA_STATUS_OK) {\n\t\t\tu32\ti;\n\t\t\tstruct bfa_flash_attr_s *attr, *f;\n\n\t\t\tattr = (struct bfa_flash_attr_s *) flash->ubuf;\n\t\t\tf = (struct bfa_flash_attr_s *) flash->dbuf_kva;\n\t\t\tattr->status = be32_to_cpu(f->status);\n\t\t\tattr->npart = be32_to_cpu(f->npart);\n\t\t\tbfa_trc(flash, attr->status);\n\t\t\tbfa_trc(flash, attr->npart);\n\t\t\tfor (i = 0; i < attr->npart; i++) {\n\t\t\t\tattr->part[i].part_type =\n\t\t\t\t\tbe32_to_cpu(f->part[i].part_type);\n\t\t\t\tattr->part[i].part_instance =\n\t\t\t\t\tbe32_to_cpu(f->part[i].part_instance);\n\t\t\t\tattr->part[i].part_off =\n\t\t\t\t\tbe32_to_cpu(f->part[i].part_off);\n\t\t\t\tattr->part[i].part_size =\n\t\t\t\t\tbe32_to_cpu(f->part[i].part_size);\n\t\t\t\tattr->part[i].part_len =\n\t\t\t\t\tbe32_to_cpu(f->part[i].part_len);\n\t\t\t\tattr->part[i].part_status =\n\t\t\t\t\tbe32_to_cpu(f->part[i].part_status);\n\t\t\t}\n\t\t}\n\t\tflash->status = status;\n\t\tbfa_flash_cb(flash);\n\t\tbreak;\n\tcase BFI_FLASH_I2H_ERASE_RSP:\n\t\tstatus = be32_to_cpu(m.erase->status);\n\t\tbfa_trc(flash, status);\n\t\tflash->status = status;\n\t\tbfa_flash_cb(flash);\n\t\tbreak;\n\tcase BFI_FLASH_I2H_WRITE_RSP:\n\t\tstatus = be32_to_cpu(m.write->status);\n\t\tbfa_trc(flash, status);\n\t\tif (status != BFA_STATUS_OK || flash->residue == 0) {\n\t\t\tflash->status = status;\n\t\t\tbfa_flash_cb(flash);\n\t\t} else {\n\t\t\tbfa_trc(flash, flash->offset);\n\t\t\tbfa_flash_write_send(flash);\n\t\t}\n\t\tbreak;\n\tcase BFI_FLASH_I2H_READ_RSP:\n\t\tstatus = be32_to_cpu(m.read->status);\n\t\tbfa_trc(flash, status);\n\t\tif (status != BFA_STATUS_OK) {\n\t\t\tflash->status = status;\n\t\t\tbfa_flash_cb(flash);\n\t\t} else {\n\t\t\tu32 len = be32_to_cpu(m.read->length);\n\t\t\tbfa_trc(flash, flash->offset);\n\t\t\tbfa_trc(flash, len);\n\t\t\tmemcpy(flash->ubuf + flash->offset,\n\t\t\t\tflash->dbuf_kva, len);\n\t\t\tflash->residue -= len;\n\t\t\tflash->offset += len;\n\t\t\tif (flash->residue == 0) {\n\t\t\t\tflash->status = status;\n\t\t\t\tbfa_flash_cb(flash);\n\t\t\t} else\n\t\t\t\tbfa_flash_read_send(flash);\n\t\t}\n\t\tbreak;\n\tcase BFI_FLASH_I2H_BOOT_VER_RSP:\n\t\tbreak;\n\tcase BFI_FLASH_I2H_EVENT:\n\t\tstatus = be32_to_cpu(m.event->status);\n\t\tbfa_trc(flash, status);\n\t\tif (status == BFA_STATUS_BAD_FWCFG)\n\t\t\tbfa_ioc_aen_post(flash->ioc, BFA_IOC_AEN_FWCFG_ERROR);\n\t\telse if (status == BFA_STATUS_INVALID_VENDOR) {\n\t\t\tu32 param;\n\t\t\tparam = be32_to_cpu(m.event->param);\n\t\t\tbfa_trc(flash, param);\n\t\t\tbfa_ioc_aen_post(flash->ioc,\n\t\t\t\tBFA_IOC_AEN_INVALID_VENDOR);\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON(1);\n\t}\n}\n\n \nu32\nbfa_flash_meminfo(bfa_boolean_t mincfg)\n{\n\t \n\tif (mincfg)\n\t\treturn 0;\n\treturn BFA_ROUNDUP(BFA_FLASH_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n}\n\n \nvoid\nbfa_flash_attach(struct bfa_flash_s *flash, struct bfa_ioc_s *ioc, void *dev,\n\t\tstruct bfa_trc_mod_s *trcmod, bfa_boolean_t mincfg)\n{\n\tflash->ioc = ioc;\n\tflash->trcmod = trcmod;\n\tflash->cbfn = NULL;\n\tflash->cbarg = NULL;\n\tflash->op_busy = 0;\n\n\tbfa_ioc_mbox_regisr(flash->ioc, BFI_MC_FLASH, bfa_flash_intr, flash);\n\tbfa_q_qe_init(&flash->ioc_notify);\n\tbfa_ioc_notify_init(&flash->ioc_notify, bfa_flash_notify, flash);\n\tlist_add_tail(&flash->ioc_notify.qe, &flash->ioc->notify_q);\n\n\t \n\tif (mincfg) {\n\t\tflash->dbuf_kva = NULL;\n\t\tflash->dbuf_pa = 0;\n\t}\n}\n\n \nvoid\nbfa_flash_memclaim(struct bfa_flash_s *flash, u8 *dm_kva, u64 dm_pa,\n\t\tbfa_boolean_t mincfg)\n{\n\tif (mincfg)\n\t\treturn;\n\n\tflash->dbuf_kva = dm_kva;\n\tflash->dbuf_pa = dm_pa;\n\tmemset(flash->dbuf_kva, 0, BFA_FLASH_DMA_BUF_SZ);\n\tdm_kva += BFA_ROUNDUP(BFA_FLASH_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n\tdm_pa += BFA_ROUNDUP(BFA_FLASH_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n}\n\n \nbfa_status_t\nbfa_flash_get_attr(struct bfa_flash_s *flash, struct bfa_flash_attr_s *attr,\n\t\tbfa_cb_flash_t cbfn, void *cbarg)\n{\n\tbfa_trc(flash, BFI_FLASH_H2I_QUERY_REQ);\n\n\tif (!bfa_ioc_is_operational(flash->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (flash->op_busy) {\n\t\tbfa_trc(flash, flash->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tflash->op_busy = 1;\n\tflash->cbfn = cbfn;\n\tflash->cbarg = cbarg;\n\tflash->ubuf = (u8 *) attr;\n\tbfa_flash_query_send(flash);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_flash_erase_part(struct bfa_flash_s *flash, enum bfa_flash_part_type type,\n\t\tu8 instance, bfa_cb_flash_t cbfn, void *cbarg)\n{\n\tbfa_trc(flash, BFI_FLASH_H2I_ERASE_REQ);\n\tbfa_trc(flash, type);\n\tbfa_trc(flash, instance);\n\n\tif (!bfa_ioc_is_operational(flash->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (flash->op_busy) {\n\t\tbfa_trc(flash, flash->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tflash->op_busy = 1;\n\tflash->cbfn = cbfn;\n\tflash->cbarg = cbarg;\n\tflash->type = type;\n\tflash->instance = instance;\n\n\tbfa_flash_erase_send(flash);\n\tbfa_flash_aen_audit_post(flash->ioc, BFA_AUDIT_AEN_FLASH_ERASE,\n\t\t\t\tinstance, type);\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_flash_update_part(struct bfa_flash_s *flash, enum bfa_flash_part_type type,\n\t\tu8 instance, void *buf, u32 len, u32 offset,\n\t\tbfa_cb_flash_t cbfn, void *cbarg)\n{\n\tbfa_trc(flash, BFI_FLASH_H2I_WRITE_REQ);\n\tbfa_trc(flash, type);\n\tbfa_trc(flash, instance);\n\tbfa_trc(flash, len);\n\tbfa_trc(flash, offset);\n\n\tif (!bfa_ioc_is_operational(flash->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\t \n\tif (!len || (len & 0x03) || (offset & 0x00003FFF))\n\t\treturn BFA_STATUS_FLASH_BAD_LEN;\n\n\tif (type == BFA_FLASH_PART_MFG)\n\t\treturn BFA_STATUS_EINVAL;\n\n\tif (flash->op_busy) {\n\t\tbfa_trc(flash, flash->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tflash->op_busy = 1;\n\tflash->cbfn = cbfn;\n\tflash->cbarg = cbarg;\n\tflash->type = type;\n\tflash->instance = instance;\n\tflash->residue = len;\n\tflash->offset = 0;\n\tflash->addr_off = offset;\n\tflash->ubuf = buf;\n\n\tbfa_flash_write_send(flash);\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_flash_read_part(struct bfa_flash_s *flash, enum bfa_flash_part_type type,\n\t\tu8 instance, void *buf, u32 len, u32 offset,\n\t\tbfa_cb_flash_t cbfn, void *cbarg)\n{\n\tbfa_trc(flash, BFI_FLASH_H2I_READ_REQ);\n\tbfa_trc(flash, type);\n\tbfa_trc(flash, instance);\n\tbfa_trc(flash, len);\n\tbfa_trc(flash, offset);\n\n\tif (!bfa_ioc_is_operational(flash->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\t \n\tif (!len || (len & 0x03) || (offset & 0x00003FFF))\n\t\treturn BFA_STATUS_FLASH_BAD_LEN;\n\n\tif (flash->op_busy) {\n\t\tbfa_trc(flash, flash->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tflash->op_busy = 1;\n\tflash->cbfn = cbfn;\n\tflash->cbarg = cbarg;\n\tflash->type = type;\n\tflash->instance = instance;\n\tflash->residue = len;\n\tflash->offset = 0;\n\tflash->addr_off = offset;\n\tflash->ubuf = buf;\n\tbfa_flash_read_send(flash);\n\n\treturn BFA_STATUS_OK;\n}\n\n \n\n#define BFA_DIAG_MEMTEST_TOV\t50000\t \n#define CT2_BFA_DIAG_MEMTEST_TOV\t(9*30*1000)   \n\n \nstatic void\nbfa_diag_notify(void *diag_arg, enum bfa_ioc_event_e event)\n{\n\tstruct bfa_diag_s *diag = diag_arg;\n\n\tbfa_trc(diag, event);\n\tbfa_trc(diag, diag->block);\n\tbfa_trc(diag, diag->fwping.lock);\n\tbfa_trc(diag, diag->tsensor.lock);\n\n\tswitch (event) {\n\tcase BFA_IOC_E_DISABLED:\n\tcase BFA_IOC_E_FAILED:\n\t\tif (diag->fwping.lock) {\n\t\t\tdiag->fwping.status = BFA_STATUS_IOC_FAILURE;\n\t\t\tdiag->fwping.cbfn(diag->fwping.cbarg,\n\t\t\t\t\tdiag->fwping.status);\n\t\t\tdiag->fwping.lock = 0;\n\t\t}\n\n\t\tif (diag->tsensor.lock) {\n\t\t\tdiag->tsensor.status = BFA_STATUS_IOC_FAILURE;\n\t\t\tdiag->tsensor.cbfn(diag->tsensor.cbarg,\n\t\t\t\t\t   diag->tsensor.status);\n\t\t\tdiag->tsensor.lock = 0;\n\t\t}\n\n\t\tif (diag->block) {\n\t\t\tif (diag->timer_active) {\n\t\t\t\tbfa_timer_stop(&diag->timer);\n\t\t\t\tdiag->timer_active = 0;\n\t\t\t}\n\n\t\t\tdiag->status = BFA_STATUS_IOC_FAILURE;\n\t\t\tdiag->cbfn(diag->cbarg, diag->status);\n\t\t\tdiag->block = 0;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void\nbfa_diag_memtest_done(void *cbarg)\n{\n\tstruct bfa_diag_s *diag = cbarg;\n\tstruct bfa_ioc_s  *ioc = diag->ioc;\n\tstruct bfa_diag_memtest_result *res = diag->result;\n\tu32\tloff = BFI_BOOT_MEMTEST_RES_ADDR;\n\tu32\tpgnum, i;\n\n\tpgnum = PSS_SMEM_PGNUM(ioc->ioc_regs.smem_pg0, loff);\n\twritel(pgnum, ioc->ioc_regs.host_page_num_fn);\n\n\tfor (i = 0; i < (sizeof(struct bfa_diag_memtest_result) /\n\t\t\t sizeof(u32)); i++) {\n\t\t \n\t\t*((u32 *) res + i) =\n\t\t\tbfa_mem_read(ioc->ioc_regs.smem_page_start, loff);\n\t\tloff += sizeof(u32);\n\t}\n\n\t \n\tbfa_ioc_reset_fwstate(ioc);\n\n\tres->status = swab32(res->status);\n\tbfa_trc(diag, res->status);\n\n\tif (res->status == BFI_BOOT_MEMTEST_RES_SIG)\n\t\tdiag->status = BFA_STATUS_OK;\n\telse {\n\t\tdiag->status = BFA_STATUS_MEMTEST_FAILED;\n\t\tres->addr = swab32(res->addr);\n\t\tres->exp = swab32(res->exp);\n\t\tres->act = swab32(res->act);\n\t\tres->err_status = swab32(res->err_status);\n\t\tres->err_status1 = swab32(res->err_status1);\n\t\tres->err_addr = swab32(res->err_addr);\n\t\tbfa_trc(diag, res->addr);\n\t\tbfa_trc(diag, res->exp);\n\t\tbfa_trc(diag, res->act);\n\t\tbfa_trc(diag, res->err_status);\n\t\tbfa_trc(diag, res->err_status1);\n\t\tbfa_trc(diag, res->err_addr);\n\t}\n\tdiag->timer_active = 0;\n\tdiag->cbfn(diag->cbarg, diag->status);\n\tdiag->block = 0;\n}\n\n \n\n \nstatic void\ndiag_fwping_send(struct bfa_diag_s *diag)\n{\n\tstruct bfi_diag_fwping_req_s *fwping_req;\n\tu32\ti;\n\n\tbfa_trc(diag, diag->fwping.dbuf_pa);\n\n\t \n\tfor (i = 0; i < (BFI_DIAG_DMA_BUF_SZ >> 2); i++)\n\t\t*((u32 *)diag->fwping.dbuf_kva + i) = diag->fwping.data;\n\n\t \n\tfwping_req = (struct bfi_diag_fwping_req_s *)diag->fwping.mbcmd.msg;\n\n\t \n\tbfa_alen_set(&fwping_req->alen, BFI_DIAG_DMA_BUF_SZ,\n\t\t\tdiag->fwping.dbuf_pa);\n\t \n\tfwping_req->count = cpu_to_be32(diag->fwping.count);\n\t \n\tfwping_req->data = diag->fwping.data;\n\n\t \n\tbfi_h2i_set(fwping_req->mh, BFI_MC_DIAG, BFI_DIAG_H2I_FWPING,\n\t\tbfa_ioc_portid(diag->ioc));\n\n\t \n\tbfa_ioc_mbox_queue(diag->ioc, &diag->fwping.mbcmd);\n}\n\nstatic void\ndiag_fwping_comp(struct bfa_diag_s *diag,\n\t\t struct bfi_diag_fwping_rsp_s *diag_rsp)\n{\n\tu32\trsp_data = diag_rsp->data;\n\tu8\trsp_dma_status = diag_rsp->dma_status;\n\n\tbfa_trc(diag, rsp_data);\n\tbfa_trc(diag, rsp_dma_status);\n\n\tif (rsp_dma_status == BFA_STATUS_OK) {\n\t\tu32\ti, pat;\n\t\tpat = (diag->fwping.count & 0x1) ? ~(diag->fwping.data) :\n\t\t\tdiag->fwping.data;\n\t\t \n\t\tif (diag->fwping.data != rsp_data) {\n\t\t\tbfa_trc(diag, rsp_data);\n\t\t\tdiag->fwping.result->dmastatus =\n\t\t\t\t\tBFA_STATUS_DATACORRUPTED;\n\t\t\tdiag->fwping.status = BFA_STATUS_DATACORRUPTED;\n\t\t\tdiag->fwping.cbfn(diag->fwping.cbarg,\n\t\t\t\t\tdiag->fwping.status);\n\t\t\tdiag->fwping.lock = 0;\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tfor (i = 0; i < (BFI_DIAG_DMA_BUF_SZ >> 2); i++) {\n\t\t\tif (*((u32 *)diag->fwping.dbuf_kva + i) != pat) {\n\t\t\t\tbfa_trc(diag, i);\n\t\t\t\tbfa_trc(diag, pat);\n\t\t\t\tbfa_trc(diag,\n\t\t\t\t\t*((u32 *)diag->fwping.dbuf_kva + i));\n\t\t\t\tdiag->fwping.result->dmastatus =\n\t\t\t\t\t\tBFA_STATUS_DATACORRUPTED;\n\t\t\t\tdiag->fwping.status = BFA_STATUS_DATACORRUPTED;\n\t\t\t\tdiag->fwping.cbfn(diag->fwping.cbarg,\n\t\t\t\t\t\tdiag->fwping.status);\n\t\t\t\tdiag->fwping.lock = 0;\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tdiag->fwping.result->dmastatus = BFA_STATUS_OK;\n\t\tdiag->fwping.status = BFA_STATUS_OK;\n\t\tdiag->fwping.cbfn(diag->fwping.cbarg, diag->fwping.status);\n\t\tdiag->fwping.lock = 0;\n\t} else {\n\t\tdiag->fwping.status = BFA_STATUS_HDMA_FAILED;\n\t\tdiag->fwping.cbfn(diag->fwping.cbarg, diag->fwping.status);\n\t\tdiag->fwping.lock = 0;\n\t}\n}\n\n \n\nstatic void\ndiag_tempsensor_send(struct bfa_diag_s *diag)\n{\n\tstruct bfi_diag_ts_req_s *msg;\n\n\tmsg = (struct bfi_diag_ts_req_s *)diag->tsensor.mbcmd.msg;\n\tbfa_trc(diag, msg->temp);\n\t \n\tbfi_h2i_set(msg->mh, BFI_MC_DIAG, BFI_DIAG_H2I_TEMPSENSOR,\n\t\tbfa_ioc_portid(diag->ioc));\n\t \n\tbfa_ioc_mbox_queue(diag->ioc, &diag->tsensor.mbcmd);\n}\n\nstatic void\ndiag_tempsensor_comp(struct bfa_diag_s *diag, bfi_diag_ts_rsp_t *rsp)\n{\n\tif (!diag->tsensor.lock) {\n\t\t \n\t\tbfa_trc(diag, diag->tsensor.lock);\n\t\treturn;\n\t}\n\n\t \n\tdiag->tsensor.temp->temp = be16_to_cpu(rsp->temp);\n\tdiag->tsensor.temp->ts_junc = rsp->ts_junc;\n\tdiag->tsensor.temp->ts_brd = rsp->ts_brd;\n\n\tif (rsp->ts_brd) {\n\t\t \n\t\tdiag->tsensor.temp->status = rsp->status;\n\t\tif (rsp->status == BFA_STATUS_OK) {\n\t\t\tdiag->tsensor.temp->brd_temp =\n\t\t\t\tbe16_to_cpu(rsp->brd_temp);\n\t\t} else\n\t\t\tdiag->tsensor.temp->brd_temp = 0;\n\t}\n\n\tbfa_trc(diag, rsp->status);\n\tbfa_trc(diag, rsp->ts_junc);\n\tbfa_trc(diag, rsp->temp);\n\tbfa_trc(diag, rsp->ts_brd);\n\tbfa_trc(diag, rsp->brd_temp);\n\n\t \n\tdiag->tsensor.status = BFA_STATUS_OK;\n\tdiag->tsensor.cbfn(diag->tsensor.cbarg, diag->tsensor.status);\n\tdiag->tsensor.lock = 0;\n}\n\n \nstatic void\ndiag_ledtest_send(struct bfa_diag_s *diag, struct bfa_diag_ledtest_s *ledtest)\n{\n\tstruct bfi_diag_ledtest_req_s  *msg;\n\n\tmsg = (struct bfi_diag_ledtest_req_s *)diag->ledtest.mbcmd.msg;\n\t \n\tbfi_h2i_set(msg->mh, BFI_MC_DIAG, BFI_DIAG_H2I_LEDTEST,\n\t\t\tbfa_ioc_portid(diag->ioc));\n\n\t \n\tif (ledtest->freq)\n\t\tledtest->freq = 500 / ledtest->freq;\n\n\tif (ledtest->freq == 0)\n\t\tledtest->freq = 1;\n\n\tbfa_trc(diag, ledtest->freq);\n\t \n\tmsg->cmd = (u8) ledtest->cmd;\n\tmsg->color = (u8) ledtest->color;\n\tmsg->portid = bfa_ioc_portid(diag->ioc);\n\tmsg->led = ledtest->led;\n\tmsg->freq = cpu_to_be16(ledtest->freq);\n\n\t \n\tbfa_ioc_mbox_queue(diag->ioc, &diag->ledtest.mbcmd);\n}\n\nstatic void\ndiag_ledtest_comp(struct bfa_diag_s *diag, struct bfi_diag_ledtest_rsp_s *msg)\n{\n\tbfa_trc(diag, diag->ledtest.lock);\n\tdiag->ledtest.lock = BFA_FALSE;\n\t \n}\n\n \nstatic void\ndiag_portbeacon_send(struct bfa_diag_s *diag, bfa_boolean_t beacon, u32 sec)\n{\n\tstruct bfi_diag_portbeacon_req_s *msg;\n\n\tmsg = (struct bfi_diag_portbeacon_req_s *)diag->beacon.mbcmd.msg;\n\t \n\tbfi_h2i_set(msg->mh, BFI_MC_DIAG, BFI_DIAG_H2I_PORTBEACON,\n\t\tbfa_ioc_portid(diag->ioc));\n\tmsg->beacon = beacon;\n\tmsg->period = cpu_to_be32(sec);\n\t \n\tbfa_ioc_mbox_queue(diag->ioc, &diag->beacon.mbcmd);\n}\n\nstatic void\ndiag_portbeacon_comp(struct bfa_diag_s *diag)\n{\n\tbfa_trc(diag, diag->beacon.state);\n\tdiag->beacon.state = BFA_FALSE;\n\tif (diag->cbfn_beacon)\n\t\tdiag->cbfn_beacon(diag->dev, BFA_FALSE, diag->beacon.link_e2e);\n}\n\n \nstatic void\nbfa_diag_intr(void *diagarg, struct bfi_mbmsg_s *msg)\n{\n\tstruct bfa_diag_s *diag = diagarg;\n\n\tswitch (msg->mh.msg_id) {\n\tcase BFI_DIAG_I2H_PORTBEACON:\n\t\tdiag_portbeacon_comp(diag);\n\t\tbreak;\n\tcase BFI_DIAG_I2H_FWPING:\n\t\tdiag_fwping_comp(diag, (struct bfi_diag_fwping_rsp_s *) msg);\n\t\tbreak;\n\tcase BFI_DIAG_I2H_TEMPSENSOR:\n\t\tdiag_tempsensor_comp(diag, (bfi_diag_ts_rsp_t *) msg);\n\t\tbreak;\n\tcase BFI_DIAG_I2H_LEDTEST:\n\t\tdiag_ledtest_comp(diag, (struct bfi_diag_ledtest_rsp_s *) msg);\n\t\tbreak;\n\tdefault:\n\t\tbfa_trc(diag, msg->mh.msg_id);\n\t\tWARN_ON(1);\n\t}\n}\n\n \nbfa_status_t\nbfa_diag_memtest(struct bfa_diag_s *diag, struct bfa_diag_memtest_s *memtest,\n\t\tu32 pattern, struct bfa_diag_memtest_result *result,\n\t\tbfa_cb_diag_t cbfn, void *cbarg)\n{\n\tu32\tmemtest_tov;\n\n\tbfa_trc(diag, pattern);\n\n\tif (!bfa_ioc_adapter_is_disabled(diag->ioc))\n\t\treturn BFA_STATUS_ADAPTER_ENABLED;\n\n\t \n\tif (diag->block) {\n\t\tbfa_trc(diag, diag->block);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t} else\n\t\tdiag->block = 1;\n\n\tdiag->result = result;\n\tdiag->cbfn = cbfn;\n\tdiag->cbarg = cbarg;\n\n\t \n\tbfa_ioc_boot(diag->ioc, BFI_FWBOOT_TYPE_MEMTEST, BFI_FWBOOT_ENV_OS);\n\n\tmemtest_tov = (bfa_ioc_asic_gen(diag->ioc) == BFI_ASIC_GEN_CT2) ?\n\t\t       CT2_BFA_DIAG_MEMTEST_TOV : BFA_DIAG_MEMTEST_TOV;\n\tbfa_timer_begin(diag->ioc->timer_mod, &diag->timer,\n\t\t\tbfa_diag_memtest_done, diag, memtest_tov);\n\tdiag->timer_active = 1;\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_diag_fwping(struct bfa_diag_s *diag, u32 cnt, u32 data,\n\t\tstruct bfa_diag_results_fwping *result, bfa_cb_diag_t cbfn,\n\t\tvoid *cbarg)\n{\n\tbfa_trc(diag, cnt);\n\tbfa_trc(diag, data);\n\n\tif (!bfa_ioc_is_operational(diag->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (bfa_asic_id_ct2(bfa_ioc_devid((diag->ioc))) &&\n\t    ((diag->ioc)->clscode == BFI_PCIFN_CLASS_ETH))\n\t\treturn BFA_STATUS_CMD_NOTSUPP;\n\n\t \n\tif (diag->block || diag->fwping.lock) {\n\t\tbfa_trc(diag, diag->block);\n\t\tbfa_trc(diag, diag->fwping.lock);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\t \n\tdiag->fwping.lock = 1;\n\tdiag->fwping.cbfn = cbfn;\n\tdiag->fwping.cbarg = cbarg;\n\tdiag->fwping.result = result;\n\tdiag->fwping.data = data;\n\tdiag->fwping.count = cnt;\n\n\t \n\tdiag->fwping.result->data = 0;\n\tdiag->fwping.result->status = BFA_STATUS_OK;\n\n\t \n\tdiag_fwping_send(diag);\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_diag_tsensor_query(struct bfa_diag_s *diag,\n\t\tstruct bfa_diag_results_tempsensor_s *result,\n\t\tbfa_cb_diag_t cbfn, void *cbarg)\n{\n\t \n\tif (diag->block || diag->tsensor.lock) {\n\t\tbfa_trc(diag, diag->block);\n\t\tbfa_trc(diag, diag->tsensor.lock);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tif (!bfa_ioc_is_operational(diag->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\t \n\tdiag->tsensor.lock = 1;\n\tdiag->tsensor.temp = result;\n\tdiag->tsensor.cbfn = cbfn;\n\tdiag->tsensor.cbarg = cbarg;\n\tdiag->tsensor.status = BFA_STATUS_OK;\n\n\t \n\tdiag_tempsensor_send(diag);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_diag_ledtest(struct bfa_diag_s *diag, struct bfa_diag_ledtest_s *ledtest)\n{\n\tbfa_trc(diag, ledtest->cmd);\n\n\tif (!bfa_ioc_is_operational(diag->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (diag->beacon.state)\n\t\treturn BFA_STATUS_BEACON_ON;\n\n\tif (diag->ledtest.lock)\n\t\treturn BFA_STATUS_LEDTEST_OP;\n\n\t \n\tdiag->ledtest.lock = BFA_TRUE;\n\tdiag_ledtest_send(diag, ledtest);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_diag_beacon_port(struct bfa_diag_s *diag, bfa_boolean_t beacon,\n\t\tbfa_boolean_t link_e2e_beacon, uint32_t sec)\n{\n\tbfa_trc(diag, beacon);\n\tbfa_trc(diag, link_e2e_beacon);\n\tbfa_trc(diag, sec);\n\n\tif (!bfa_ioc_is_operational(diag->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (diag->ledtest.lock)\n\t\treturn BFA_STATUS_LEDTEST_OP;\n\n\tif (diag->beacon.state && beacon)        \n\t\treturn BFA_STATUS_BEACON_ON;\n\n\tdiag->beacon.state\t= beacon;\n\tdiag->beacon.link_e2e\t= link_e2e_beacon;\n\tif (diag->cbfn_beacon)\n\t\tdiag->cbfn_beacon(diag->dev, beacon, link_e2e_beacon);\n\n\t \n\tdiag_portbeacon_send(diag, beacon, sec);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nu32\nbfa_diag_meminfo(void)\n{\n\treturn BFA_ROUNDUP(BFI_DIAG_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n}\n\n \nvoid\nbfa_diag_attach(struct bfa_diag_s *diag, struct bfa_ioc_s *ioc, void *dev,\n\tbfa_cb_diag_beacon_t cbfn_beacon, struct bfa_trc_mod_s *trcmod)\n{\n\tdiag->dev = dev;\n\tdiag->ioc = ioc;\n\tdiag->trcmod = trcmod;\n\n\tdiag->block = 0;\n\tdiag->cbfn = NULL;\n\tdiag->cbarg = NULL;\n\tdiag->result = NULL;\n\tdiag->cbfn_beacon = cbfn_beacon;\n\n\tbfa_ioc_mbox_regisr(diag->ioc, BFI_MC_DIAG, bfa_diag_intr, diag);\n\tbfa_q_qe_init(&diag->ioc_notify);\n\tbfa_ioc_notify_init(&diag->ioc_notify, bfa_diag_notify, diag);\n\tlist_add_tail(&diag->ioc_notify.qe, &diag->ioc->notify_q);\n}\n\nvoid\nbfa_diag_memclaim(struct bfa_diag_s *diag, u8 *dm_kva, u64 dm_pa)\n{\n\tdiag->fwping.dbuf_kva = dm_kva;\n\tdiag->fwping.dbuf_pa = dm_pa;\n\tmemset(diag->fwping.dbuf_kva, 0, BFI_DIAG_DMA_BUF_SZ);\n}\n\n \n#define BFA_PHY_DMA_BUF_SZ\t0x02000          \n#define BFA_PHY_LOCK_STATUS\t0x018878         \n\nstatic void\nbfa_phy_ntoh32(u32 *obuf, u32 *ibuf, int sz)\n{\n\tint i, m = sz >> 2;\n\n\tfor (i = 0; i < m; i++)\n\t\tobuf[i] = be32_to_cpu(ibuf[i]);\n}\n\nstatic bfa_boolean_t\nbfa_phy_present(struct bfa_phy_s *phy)\n{\n\treturn (phy->ioc->attr->card_type == BFA_MFG_TYPE_LIGHTNING);\n}\n\nstatic void\nbfa_phy_notify(void *cbarg, enum bfa_ioc_event_e event)\n{\n\tstruct bfa_phy_s *phy = cbarg;\n\n\tbfa_trc(phy, event);\n\n\tswitch (event) {\n\tcase BFA_IOC_E_DISABLED:\n\tcase BFA_IOC_E_FAILED:\n\t\tif (phy->op_busy) {\n\t\t\tphy->status = BFA_STATUS_IOC_FAILURE;\n\t\t\tphy->cbfn(phy->cbarg, phy->status);\n\t\t\tphy->op_busy = 0;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n \nstatic void\nbfa_phy_query_send(void *cbarg)\n{\n\tstruct bfa_phy_s *phy = cbarg;\n\tstruct bfi_phy_query_req_s *msg =\n\t\t\t(struct bfi_phy_query_req_s *) phy->mb.msg;\n\n\tmsg->instance = phy->instance;\n\tbfi_h2i_set(msg->mh, BFI_MC_PHY, BFI_PHY_H2I_QUERY_REQ,\n\t\tbfa_ioc_portid(phy->ioc));\n\tbfa_alen_set(&msg->alen, sizeof(struct bfa_phy_attr_s), phy->dbuf_pa);\n\tbfa_ioc_mbox_queue(phy->ioc, &phy->mb);\n}\n\n \nstatic void\nbfa_phy_write_send(void *cbarg)\n{\n\tstruct bfa_phy_s *phy = cbarg;\n\tstruct bfi_phy_write_req_s *msg =\n\t\t\t(struct bfi_phy_write_req_s *) phy->mb.msg;\n\tu32\tlen;\n\tu16\t*buf, *dbuf;\n\tint\ti, sz;\n\n\tmsg->instance = phy->instance;\n\tmsg->offset = cpu_to_be32(phy->addr_off + phy->offset);\n\tlen = (phy->residue < BFA_PHY_DMA_BUF_SZ) ?\n\t\t\tphy->residue : BFA_PHY_DMA_BUF_SZ;\n\tmsg->length = cpu_to_be32(len);\n\n\t \n\tmsg->last = (len == phy->residue) ? 1 : 0;\n\n\tbfi_h2i_set(msg->mh, BFI_MC_PHY, BFI_PHY_H2I_WRITE_REQ,\n\t\tbfa_ioc_portid(phy->ioc));\n\tbfa_alen_set(&msg->alen, len, phy->dbuf_pa);\n\n\tbuf = (u16 *) (phy->ubuf + phy->offset);\n\tdbuf = (u16 *)phy->dbuf_kva;\n\tsz = len >> 1;\n\tfor (i = 0; i < sz; i++)\n\t\tbuf[i] = cpu_to_be16(dbuf[i]);\n\n\tbfa_ioc_mbox_queue(phy->ioc, &phy->mb);\n\n\tphy->residue -= len;\n\tphy->offset += len;\n}\n\n \nstatic void\nbfa_phy_read_send(void *cbarg)\n{\n\tstruct bfa_phy_s *phy = cbarg;\n\tstruct bfi_phy_read_req_s *msg =\n\t\t\t(struct bfi_phy_read_req_s *) phy->mb.msg;\n\tu32\tlen;\n\n\tmsg->instance = phy->instance;\n\tmsg->offset = cpu_to_be32(phy->addr_off + phy->offset);\n\tlen = (phy->residue < BFA_PHY_DMA_BUF_SZ) ?\n\t\t\tphy->residue : BFA_PHY_DMA_BUF_SZ;\n\tmsg->length = cpu_to_be32(len);\n\tbfi_h2i_set(msg->mh, BFI_MC_PHY, BFI_PHY_H2I_READ_REQ,\n\t\tbfa_ioc_portid(phy->ioc));\n\tbfa_alen_set(&msg->alen, len, phy->dbuf_pa);\n\tbfa_ioc_mbox_queue(phy->ioc, &phy->mb);\n}\n\n \nstatic void\nbfa_phy_stats_send(void *cbarg)\n{\n\tstruct bfa_phy_s *phy = cbarg;\n\tstruct bfi_phy_stats_req_s *msg =\n\t\t\t(struct bfi_phy_stats_req_s *) phy->mb.msg;\n\n\tmsg->instance = phy->instance;\n\tbfi_h2i_set(msg->mh, BFI_MC_PHY, BFI_PHY_H2I_STATS_REQ,\n\t\tbfa_ioc_portid(phy->ioc));\n\tbfa_alen_set(&msg->alen, sizeof(struct bfa_phy_stats_s), phy->dbuf_pa);\n\tbfa_ioc_mbox_queue(phy->ioc, &phy->mb);\n}\n\n \nu32\nbfa_phy_meminfo(bfa_boolean_t mincfg)\n{\n\t \n\tif (mincfg)\n\t\treturn 0;\n\n\treturn BFA_ROUNDUP(BFA_PHY_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n}\n\n \nvoid\nbfa_phy_attach(struct bfa_phy_s *phy, struct bfa_ioc_s *ioc, void *dev,\n\t\tstruct bfa_trc_mod_s *trcmod, bfa_boolean_t mincfg)\n{\n\tphy->ioc = ioc;\n\tphy->trcmod = trcmod;\n\tphy->cbfn = NULL;\n\tphy->cbarg = NULL;\n\tphy->op_busy = 0;\n\n\tbfa_ioc_mbox_regisr(phy->ioc, BFI_MC_PHY, bfa_phy_intr, phy);\n\tbfa_q_qe_init(&phy->ioc_notify);\n\tbfa_ioc_notify_init(&phy->ioc_notify, bfa_phy_notify, phy);\n\tlist_add_tail(&phy->ioc_notify.qe, &phy->ioc->notify_q);\n\n\t \n\tif (mincfg) {\n\t\tphy->dbuf_kva = NULL;\n\t\tphy->dbuf_pa = 0;\n\t}\n}\n\n \nvoid\nbfa_phy_memclaim(struct bfa_phy_s *phy, u8 *dm_kva, u64 dm_pa,\n\t\tbfa_boolean_t mincfg)\n{\n\tif (mincfg)\n\t\treturn;\n\n\tphy->dbuf_kva = dm_kva;\n\tphy->dbuf_pa = dm_pa;\n\tmemset(phy->dbuf_kva, 0, BFA_PHY_DMA_BUF_SZ);\n\tdm_kva += BFA_ROUNDUP(BFA_PHY_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n\tdm_pa += BFA_ROUNDUP(BFA_PHY_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n}\n\nbfa_boolean_t\nbfa_phy_busy(struct bfa_ioc_s *ioc)\n{\n\tvoid __iomem\t*rb;\n\n\trb = bfa_ioc_bar0(ioc);\n\treturn readl(rb + BFA_PHY_LOCK_STATUS);\n}\n\n \nbfa_status_t\nbfa_phy_get_attr(struct bfa_phy_s *phy, u8 instance,\n\t\tstruct bfa_phy_attr_s *attr, bfa_cb_phy_t cbfn, void *cbarg)\n{\n\tbfa_trc(phy, BFI_PHY_H2I_QUERY_REQ);\n\tbfa_trc(phy, instance);\n\n\tif (!bfa_phy_present(phy))\n\t\treturn BFA_STATUS_PHY_NOT_PRESENT;\n\n\tif (!bfa_ioc_is_operational(phy->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (phy->op_busy || bfa_phy_busy(phy->ioc)) {\n\t\tbfa_trc(phy, phy->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tphy->op_busy = 1;\n\tphy->cbfn = cbfn;\n\tphy->cbarg = cbarg;\n\tphy->instance = instance;\n\tphy->ubuf = (uint8_t *) attr;\n\tbfa_phy_query_send(phy);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_phy_get_stats(struct bfa_phy_s *phy, u8 instance,\n\t\tstruct bfa_phy_stats_s *stats,\n\t\tbfa_cb_phy_t cbfn, void *cbarg)\n{\n\tbfa_trc(phy, BFI_PHY_H2I_STATS_REQ);\n\tbfa_trc(phy, instance);\n\n\tif (!bfa_phy_present(phy))\n\t\treturn BFA_STATUS_PHY_NOT_PRESENT;\n\n\tif (!bfa_ioc_is_operational(phy->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (phy->op_busy || bfa_phy_busy(phy->ioc)) {\n\t\tbfa_trc(phy, phy->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tphy->op_busy = 1;\n\tphy->cbfn = cbfn;\n\tphy->cbarg = cbarg;\n\tphy->instance = instance;\n\tphy->ubuf = (u8 *) stats;\n\tbfa_phy_stats_send(phy);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_phy_update(struct bfa_phy_s *phy, u8 instance,\n\t\tvoid *buf, u32 len, u32 offset,\n\t\tbfa_cb_phy_t cbfn, void *cbarg)\n{\n\tbfa_trc(phy, BFI_PHY_H2I_WRITE_REQ);\n\tbfa_trc(phy, instance);\n\tbfa_trc(phy, len);\n\tbfa_trc(phy, offset);\n\n\tif (!bfa_phy_present(phy))\n\t\treturn BFA_STATUS_PHY_NOT_PRESENT;\n\n\tif (!bfa_ioc_is_operational(phy->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\t \n\tif (!len || (len & 0x03))\n\t\treturn BFA_STATUS_FAILED;\n\n\tif (phy->op_busy || bfa_phy_busy(phy->ioc)) {\n\t\tbfa_trc(phy, phy->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tphy->op_busy = 1;\n\tphy->cbfn = cbfn;\n\tphy->cbarg = cbarg;\n\tphy->instance = instance;\n\tphy->residue = len;\n\tphy->offset = 0;\n\tphy->addr_off = offset;\n\tphy->ubuf = buf;\n\n\tbfa_phy_write_send(phy);\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_phy_read(struct bfa_phy_s *phy, u8 instance,\n\t\tvoid *buf, u32 len, u32 offset,\n\t\tbfa_cb_phy_t cbfn, void *cbarg)\n{\n\tbfa_trc(phy, BFI_PHY_H2I_READ_REQ);\n\tbfa_trc(phy, instance);\n\tbfa_trc(phy, len);\n\tbfa_trc(phy, offset);\n\n\tif (!bfa_phy_present(phy))\n\t\treturn BFA_STATUS_PHY_NOT_PRESENT;\n\n\tif (!bfa_ioc_is_operational(phy->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\t \n\tif (!len || (len & 0x03))\n\t\treturn BFA_STATUS_FAILED;\n\n\tif (phy->op_busy || bfa_phy_busy(phy->ioc)) {\n\t\tbfa_trc(phy, phy->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tphy->op_busy = 1;\n\tphy->cbfn = cbfn;\n\tphy->cbarg = cbarg;\n\tphy->instance = instance;\n\tphy->residue = len;\n\tphy->offset = 0;\n\tphy->addr_off = offset;\n\tphy->ubuf = buf;\n\tbfa_phy_read_send(phy);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nvoid\nbfa_phy_intr(void *phyarg, struct bfi_mbmsg_s *msg)\n{\n\tstruct bfa_phy_s *phy = phyarg;\n\tu32\tstatus;\n\n\tunion {\n\t\tstruct bfi_phy_query_rsp_s *query;\n\t\tstruct bfi_phy_stats_rsp_s *stats;\n\t\tstruct bfi_phy_write_rsp_s *write;\n\t\tstruct bfi_phy_read_rsp_s *read;\n\t\tstruct bfi_mbmsg_s   *msg;\n\t} m;\n\n\tm.msg = msg;\n\tbfa_trc(phy, msg->mh.msg_id);\n\n\tif (!phy->op_busy) {\n\t\t \n\t\tbfa_trc(phy, 0x9999);\n\t\treturn;\n\t}\n\n\tswitch (msg->mh.msg_id) {\n\tcase BFI_PHY_I2H_QUERY_RSP:\n\t\tstatus = be32_to_cpu(m.query->status);\n\t\tbfa_trc(phy, status);\n\n\t\tif (status == BFA_STATUS_OK) {\n\t\t\tstruct bfa_phy_attr_s *attr =\n\t\t\t\t(struct bfa_phy_attr_s *) phy->ubuf;\n\t\t\tbfa_phy_ntoh32((u32 *)attr, (u32 *)phy->dbuf_kva,\n\t\t\t\t\tsizeof(struct bfa_phy_attr_s));\n\t\t\tbfa_trc(phy, attr->status);\n\t\t\tbfa_trc(phy, attr->length);\n\t\t}\n\n\t\tphy->status = status;\n\t\tphy->op_busy = 0;\n\t\tif (phy->cbfn)\n\t\t\tphy->cbfn(phy->cbarg, phy->status);\n\t\tbreak;\n\tcase BFI_PHY_I2H_STATS_RSP:\n\t\tstatus = be32_to_cpu(m.stats->status);\n\t\tbfa_trc(phy, status);\n\n\t\tif (status == BFA_STATUS_OK) {\n\t\t\tstruct bfa_phy_stats_s *stats =\n\t\t\t\t(struct bfa_phy_stats_s *) phy->ubuf;\n\t\t\tbfa_phy_ntoh32((u32 *)stats, (u32 *)phy->dbuf_kva,\n\t\t\t\tsizeof(struct bfa_phy_stats_s));\n\t\t\tbfa_trc(phy, stats->status);\n\t\t}\n\n\t\tphy->status = status;\n\t\tphy->op_busy = 0;\n\t\tif (phy->cbfn)\n\t\t\tphy->cbfn(phy->cbarg, phy->status);\n\t\tbreak;\n\tcase BFI_PHY_I2H_WRITE_RSP:\n\t\tstatus = be32_to_cpu(m.write->status);\n\t\tbfa_trc(phy, status);\n\n\t\tif (status != BFA_STATUS_OK || phy->residue == 0) {\n\t\t\tphy->status = status;\n\t\t\tphy->op_busy = 0;\n\t\t\tif (phy->cbfn)\n\t\t\t\tphy->cbfn(phy->cbarg, phy->status);\n\t\t} else {\n\t\t\tbfa_trc(phy, phy->offset);\n\t\t\tbfa_phy_write_send(phy);\n\t\t}\n\t\tbreak;\n\tcase BFI_PHY_I2H_READ_RSP:\n\t\tstatus = be32_to_cpu(m.read->status);\n\t\tbfa_trc(phy, status);\n\n\t\tif (status != BFA_STATUS_OK) {\n\t\t\tphy->status = status;\n\t\t\tphy->op_busy = 0;\n\t\t\tif (phy->cbfn)\n\t\t\t\tphy->cbfn(phy->cbarg, phy->status);\n\t\t} else {\n\t\t\tu32 len = be32_to_cpu(m.read->length);\n\t\t\tu16 *buf = (u16 *)(phy->ubuf + phy->offset);\n\t\t\tu16 *dbuf = (u16 *)phy->dbuf_kva;\n\t\t\tint i, sz = len >> 1;\n\n\t\t\tbfa_trc(phy, phy->offset);\n\t\t\tbfa_trc(phy, len);\n\n\t\t\tfor (i = 0; i < sz; i++)\n\t\t\t\tbuf[i] = be16_to_cpu(dbuf[i]);\n\n\t\t\tphy->residue -= len;\n\t\t\tphy->offset += len;\n\n\t\t\tif (phy->residue == 0) {\n\t\t\t\tphy->status = status;\n\t\t\t\tphy->op_busy = 0;\n\t\t\t\tif (phy->cbfn)\n\t\t\t\t\tphy->cbfn(phy->cbarg, phy->status);\n\t\t\t} else\n\t\t\t\tbfa_phy_read_send(phy);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t}\n}\n\n \nenum bfa_dconf_event {\n\tBFA_DCONF_SM_INIT\t\t= 1,\t \n\tBFA_DCONF_SM_FLASH_COMP\t\t= 2,\t \n\tBFA_DCONF_SM_WR\t\t\t= 3,\t \n\tBFA_DCONF_SM_TIMEOUT\t\t= 4,\t \n\tBFA_DCONF_SM_EXIT\t\t= 5,\t \n\tBFA_DCONF_SM_IOCDISABLE\t\t= 6,\t \n};\n\n \nstatic void bfa_dconf_sm_uninit(struct bfa_dconf_mod_s *dconf,\n\t\t\t\tenum bfa_dconf_event event);\nstatic void bfa_dconf_sm_flash_read(struct bfa_dconf_mod_s *dconf,\n\t\t\t\tenum bfa_dconf_event event);\nstatic void bfa_dconf_sm_ready(struct bfa_dconf_mod_s *dconf,\n\t\t\t\tenum bfa_dconf_event event);\nstatic void bfa_dconf_sm_dirty(struct bfa_dconf_mod_s *dconf,\n\t\t\t\tenum bfa_dconf_event event);\nstatic void bfa_dconf_sm_sync(struct bfa_dconf_mod_s *dconf,\n\t\t\t\tenum bfa_dconf_event event);\nstatic void bfa_dconf_sm_final_sync(struct bfa_dconf_mod_s *dconf,\n\t\t\t\tenum bfa_dconf_event event);\nstatic void bfa_dconf_sm_iocdown_dirty(struct bfa_dconf_mod_s *dconf,\n\t\t\t\tenum bfa_dconf_event event);\n\nstatic void bfa_dconf_cbfn(void *dconf, bfa_status_t status);\nstatic void bfa_dconf_timer(void *cbarg);\nstatic bfa_status_t bfa_dconf_flash_write(struct bfa_dconf_mod_s *dconf);\nstatic void bfa_dconf_init_cb(void *arg, bfa_status_t status);\n\n \nstatic void\nbfa_dconf_sm_uninit(struct bfa_dconf_mod_s *dconf, enum bfa_dconf_event event)\n{\n\tbfa_status_t bfa_status;\n\tbfa_trc(dconf->bfa, event);\n\n\tswitch (event) {\n\tcase BFA_DCONF_SM_INIT:\n\t\tif (dconf->min_cfg) {\n\t\t\tbfa_trc(dconf->bfa, dconf->min_cfg);\n\t\t\tbfa_fsm_send_event(&dconf->bfa->iocfc,\n\t\t\t\t\tIOCFC_E_DCONF_DONE);\n\t\t\treturn;\n\t\t}\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_flash_read);\n\t\tbfa_timer_start(dconf->bfa, &dconf->timer,\n\t\t\tbfa_dconf_timer, dconf, 2 * BFA_DCONF_UPDATE_TOV);\n\t\tbfa_status = bfa_flash_read_part(BFA_FLASH(dconf->bfa),\n\t\t\t\t\tBFA_FLASH_PART_DRV, dconf->instance,\n\t\t\t\t\tdconf->dconf,\n\t\t\t\t\tsizeof(struct bfa_dconf_s), 0,\n\t\t\t\t\tbfa_dconf_init_cb, dconf->bfa);\n\t\tif (bfa_status != BFA_STATUS_OK) {\n\t\t\tbfa_timer_stop(&dconf->timer);\n\t\t\tbfa_dconf_init_cb(dconf->bfa, BFA_STATUS_FAILED);\n\t\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_uninit);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\tcase BFA_DCONF_SM_EXIT:\n\t\tbfa_fsm_send_event(&dconf->bfa->iocfc, IOCFC_E_DCONF_DONE);\n\t\tbreak;\n\tcase BFA_DCONF_SM_IOCDISABLE:\n\tcase BFA_DCONF_SM_WR:\n\tcase BFA_DCONF_SM_FLASH_COMP:\n\t\tbreak;\n\tdefault:\n\t\tbfa_sm_fault(dconf->bfa, event);\n\t}\n}\n\n \nstatic void\nbfa_dconf_sm_flash_read(struct bfa_dconf_mod_s *dconf,\n\t\t\tenum bfa_dconf_event event)\n{\n\tbfa_trc(dconf->bfa, event);\n\n\tswitch (event) {\n\tcase BFA_DCONF_SM_FLASH_COMP:\n\t\tbfa_timer_stop(&dconf->timer);\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_ready);\n\t\tbreak;\n\tcase BFA_DCONF_SM_TIMEOUT:\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_ready);\n\t\tbfa_ioc_suspend(&dconf->bfa->ioc);\n\t\tbreak;\n\tcase BFA_DCONF_SM_EXIT:\n\t\tbfa_timer_stop(&dconf->timer);\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_uninit);\n\t\tbfa_fsm_send_event(&dconf->bfa->iocfc, IOCFC_E_DCONF_DONE);\n\t\tbreak;\n\tcase BFA_DCONF_SM_IOCDISABLE:\n\t\tbfa_timer_stop(&dconf->timer);\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_uninit);\n\t\tbreak;\n\tdefault:\n\t\tbfa_sm_fault(dconf->bfa, event);\n\t}\n}\n\n \nstatic void\nbfa_dconf_sm_ready(struct bfa_dconf_mod_s *dconf, enum bfa_dconf_event event)\n{\n\tbfa_trc(dconf->bfa, event);\n\n\tswitch (event) {\n\tcase BFA_DCONF_SM_WR:\n\t\tbfa_timer_start(dconf->bfa, &dconf->timer,\n\t\t\tbfa_dconf_timer, dconf, BFA_DCONF_UPDATE_TOV);\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_dirty);\n\t\tbreak;\n\tcase BFA_DCONF_SM_EXIT:\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_uninit);\n\t\tbfa_fsm_send_event(&dconf->bfa->iocfc, IOCFC_E_DCONF_DONE);\n\t\tbreak;\n\tcase BFA_DCONF_SM_INIT:\n\tcase BFA_DCONF_SM_IOCDISABLE:\n\t\tbreak;\n\tdefault:\n\t\tbfa_sm_fault(dconf->bfa, event);\n\t}\n}\n\n \n\nstatic void\nbfa_dconf_sm_dirty(struct bfa_dconf_mod_s *dconf, enum bfa_dconf_event event)\n{\n\tbfa_trc(dconf->bfa, event);\n\n\tswitch (event) {\n\tcase BFA_DCONF_SM_TIMEOUT:\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_sync);\n\t\tbfa_dconf_flash_write(dconf);\n\t\tbreak;\n\tcase BFA_DCONF_SM_WR:\n\t\tbfa_timer_stop(&dconf->timer);\n\t\tbfa_timer_start(dconf->bfa, &dconf->timer,\n\t\t\tbfa_dconf_timer, dconf, BFA_DCONF_UPDATE_TOV);\n\t\tbreak;\n\tcase BFA_DCONF_SM_EXIT:\n\t\tbfa_timer_stop(&dconf->timer);\n\t\tbfa_timer_start(dconf->bfa, &dconf->timer,\n\t\t\tbfa_dconf_timer, dconf, BFA_DCONF_UPDATE_TOV);\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_final_sync);\n\t\tbfa_dconf_flash_write(dconf);\n\t\tbreak;\n\tcase BFA_DCONF_SM_FLASH_COMP:\n\t\tbreak;\n\tcase BFA_DCONF_SM_IOCDISABLE:\n\t\tbfa_timer_stop(&dconf->timer);\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_iocdown_dirty);\n\t\tbreak;\n\tdefault:\n\t\tbfa_sm_fault(dconf->bfa, event);\n\t}\n}\n\n \nstatic void\nbfa_dconf_sm_final_sync(struct bfa_dconf_mod_s *dconf,\n\t\t\tenum bfa_dconf_event event)\n{\n\tbfa_trc(dconf->bfa, event);\n\n\tswitch (event) {\n\tcase BFA_DCONF_SM_IOCDISABLE:\n\tcase BFA_DCONF_SM_FLASH_COMP:\n\t\tbfa_timer_stop(&dconf->timer);\n\t\tfallthrough;\n\tcase BFA_DCONF_SM_TIMEOUT:\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_uninit);\n\t\tbfa_fsm_send_event(&dconf->bfa->iocfc, IOCFC_E_DCONF_DONE);\n\t\tbreak;\n\tdefault:\n\t\tbfa_sm_fault(dconf->bfa, event);\n\t}\n}\n\nstatic void\nbfa_dconf_sm_sync(struct bfa_dconf_mod_s *dconf, enum bfa_dconf_event event)\n{\n\tbfa_trc(dconf->bfa, event);\n\n\tswitch (event) {\n\tcase BFA_DCONF_SM_FLASH_COMP:\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_ready);\n\t\tbreak;\n\tcase BFA_DCONF_SM_WR:\n\t\tbfa_timer_start(dconf->bfa, &dconf->timer,\n\t\t\tbfa_dconf_timer, dconf, BFA_DCONF_UPDATE_TOV);\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_dirty);\n\t\tbreak;\n\tcase BFA_DCONF_SM_EXIT:\n\t\tbfa_timer_start(dconf->bfa, &dconf->timer,\n\t\t\tbfa_dconf_timer, dconf, BFA_DCONF_UPDATE_TOV);\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_final_sync);\n\t\tbreak;\n\tcase BFA_DCONF_SM_IOCDISABLE:\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_iocdown_dirty);\n\t\tbreak;\n\tdefault:\n\t\tbfa_sm_fault(dconf->bfa, event);\n\t}\n}\n\nstatic void\nbfa_dconf_sm_iocdown_dirty(struct bfa_dconf_mod_s *dconf,\n\t\t\tenum bfa_dconf_event event)\n{\n\tbfa_trc(dconf->bfa, event);\n\n\tswitch (event) {\n\tcase BFA_DCONF_SM_INIT:\n\t\tbfa_timer_start(dconf->bfa, &dconf->timer,\n\t\t\tbfa_dconf_timer, dconf, BFA_DCONF_UPDATE_TOV);\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_dirty);\n\t\tbreak;\n\tcase BFA_DCONF_SM_EXIT:\n\t\tbfa_sm_set_state(dconf, bfa_dconf_sm_uninit);\n\t\tbfa_fsm_send_event(&dconf->bfa->iocfc, IOCFC_E_DCONF_DONE);\n\t\tbreak;\n\tcase BFA_DCONF_SM_IOCDISABLE:\n\t\tbreak;\n\tdefault:\n\t\tbfa_sm_fault(dconf->bfa, event);\n\t}\n}\n\n \nvoid\nbfa_dconf_meminfo(struct bfa_iocfc_cfg_s *cfg, struct bfa_meminfo_s *meminfo,\n\t\t  struct bfa_s *bfa)\n{\n\tstruct bfa_mem_kva_s *dconf_kva = BFA_MEM_DCONF_KVA(bfa);\n\n\tif (cfg->drvcfg.min_cfg)\n\t\tbfa_mem_kva_setup(meminfo, dconf_kva,\n\t\t\t\tsizeof(struct bfa_dconf_hdr_s));\n\telse\n\t\tbfa_mem_kva_setup(meminfo, dconf_kva,\n\t\t\t\tsizeof(struct bfa_dconf_s));\n}\n\nvoid\nbfa_dconf_attach(struct bfa_s *bfa, void *bfad, struct bfa_iocfc_cfg_s *cfg)\n{\n\tstruct bfa_dconf_mod_s *dconf = BFA_DCONF_MOD(bfa);\n\n\tdconf->bfad = bfad;\n\tdconf->bfa = bfa;\n\tdconf->instance = bfa->ioc.port_id;\n\tbfa_trc(bfa, dconf->instance);\n\n\tdconf->dconf = (struct bfa_dconf_s *) bfa_mem_kva_curp(dconf);\n\tif (cfg->drvcfg.min_cfg) {\n\t\tbfa_mem_kva_curp(dconf) += sizeof(struct bfa_dconf_hdr_s);\n\t\tdconf->min_cfg = BFA_TRUE;\n\t} else {\n\t\tdconf->min_cfg = BFA_FALSE;\n\t\tbfa_mem_kva_curp(dconf) += sizeof(struct bfa_dconf_s);\n\t}\n\n\tbfa_dconf_read_data_valid(bfa) = BFA_FALSE;\n\tbfa_sm_set_state(dconf, bfa_dconf_sm_uninit);\n}\n\nstatic void\nbfa_dconf_init_cb(void *arg, bfa_status_t status)\n{\n\tstruct bfa_s *bfa = arg;\n\tstruct bfa_dconf_mod_s *dconf = BFA_DCONF_MOD(bfa);\n\n\tif (status == BFA_STATUS_OK) {\n\t\tbfa_dconf_read_data_valid(bfa) = BFA_TRUE;\n\t\tif (dconf->dconf->hdr.signature != BFI_DCONF_SIGNATURE)\n\t\t\tdconf->dconf->hdr.signature = BFI_DCONF_SIGNATURE;\n\t\tif (dconf->dconf->hdr.version != BFI_DCONF_VERSION)\n\t\t\tdconf->dconf->hdr.version = BFI_DCONF_VERSION;\n\t}\n\tbfa_sm_send_event(dconf, BFA_DCONF_SM_FLASH_COMP);\n\tbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_DCONF_DONE);\n}\n\nvoid\nbfa_dconf_modinit(struct bfa_s *bfa)\n{\n\tstruct bfa_dconf_mod_s *dconf = BFA_DCONF_MOD(bfa);\n\tbfa_sm_send_event(dconf, BFA_DCONF_SM_INIT);\n}\n\nstatic void bfa_dconf_timer(void *cbarg)\n{\n\tstruct bfa_dconf_mod_s *dconf = cbarg;\n\tbfa_sm_send_event(dconf, BFA_DCONF_SM_TIMEOUT);\n}\n\nvoid\nbfa_dconf_iocdisable(struct bfa_s *bfa)\n{\n\tstruct bfa_dconf_mod_s *dconf = BFA_DCONF_MOD(bfa);\n\tbfa_sm_send_event(dconf, BFA_DCONF_SM_IOCDISABLE);\n}\n\nstatic bfa_status_t\nbfa_dconf_flash_write(struct bfa_dconf_mod_s *dconf)\n{\n\tbfa_status_t bfa_status;\n\tbfa_trc(dconf->bfa, 0);\n\n\tbfa_status = bfa_flash_update_part(BFA_FLASH(dconf->bfa),\n\t\t\t\tBFA_FLASH_PART_DRV, dconf->instance,\n\t\t\t\tdconf->dconf,  sizeof(struct bfa_dconf_s), 0,\n\t\t\t\tbfa_dconf_cbfn, dconf);\n\tif (bfa_status != BFA_STATUS_OK)\n\t\tWARN_ON(bfa_status);\n\tbfa_trc(dconf->bfa, bfa_status);\n\n\treturn bfa_status;\n}\n\nbfa_status_t\nbfa_dconf_update(struct bfa_s *bfa)\n{\n\tstruct bfa_dconf_mod_s *dconf = BFA_DCONF_MOD(bfa);\n\tbfa_trc(dconf->bfa, 0);\n\tif (bfa_sm_cmp_state(dconf, bfa_dconf_sm_iocdown_dirty))\n\t\treturn BFA_STATUS_FAILED;\n\n\tif (dconf->min_cfg) {\n\t\tbfa_trc(dconf->bfa, dconf->min_cfg);\n\t\treturn BFA_STATUS_FAILED;\n\t}\n\n\tbfa_sm_send_event(dconf, BFA_DCONF_SM_WR);\n\treturn BFA_STATUS_OK;\n}\n\nstatic void\nbfa_dconf_cbfn(void *arg, bfa_status_t status)\n{\n\tstruct bfa_dconf_mod_s *dconf = arg;\n\tWARN_ON(status);\n\tbfa_sm_send_event(dconf, BFA_DCONF_SM_FLASH_COMP);\n}\n\nvoid\nbfa_dconf_modexit(struct bfa_s *bfa)\n{\n\tstruct bfa_dconf_mod_s *dconf = BFA_DCONF_MOD(bfa);\n\tbfa_sm_send_event(dconf, BFA_DCONF_SM_EXIT);\n}\n\n \n\n#define BFA_FRU_DMA_BUF_SZ\t0x02000\t\t \n#define BFA_FRU_CHINOOK_MAX_SIZE 0x10000\n#define BFA_FRU_LIGHTNING_MAX_SIZE 0x200\n\nstatic void\nbfa_fru_notify(void *cbarg, enum bfa_ioc_event_e event)\n{\n\tstruct bfa_fru_s *fru = cbarg;\n\n\tbfa_trc(fru, event);\n\n\tswitch (event) {\n\tcase BFA_IOC_E_DISABLED:\n\tcase BFA_IOC_E_FAILED:\n\t\tif (fru->op_busy) {\n\t\t\tfru->status = BFA_STATUS_IOC_FAILURE;\n\t\t\tfru->cbfn(fru->cbarg, fru->status);\n\t\t\tfru->op_busy = 0;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n \nstatic void\nbfa_fru_write_send(void *cbarg, enum bfi_fru_h2i_msgs msg_type)\n{\n\tstruct bfa_fru_s *fru = cbarg;\n\tstruct bfi_fru_write_req_s *msg =\n\t\t\t(struct bfi_fru_write_req_s *) fru->mb.msg;\n\tu32 len;\n\n\tmsg->offset = cpu_to_be32(fru->addr_off + fru->offset);\n\tlen = (fru->residue < BFA_FRU_DMA_BUF_SZ) ?\n\t\t\t\tfru->residue : BFA_FRU_DMA_BUF_SZ;\n\tmsg->length = cpu_to_be32(len);\n\n\t \n\tmsg->last = (len == fru->residue) ? 1 : 0;\n\n\tmsg->trfr_cmpl = (len == fru->residue) ? fru->trfr_cmpl : 0;\n\tbfi_h2i_set(msg->mh, BFI_MC_FRU, msg_type, bfa_ioc_portid(fru->ioc));\n\tbfa_alen_set(&msg->alen, len, fru->dbuf_pa);\n\n\tmemcpy(fru->dbuf_kva, fru->ubuf + fru->offset, len);\n\tbfa_ioc_mbox_queue(fru->ioc, &fru->mb);\n\n\tfru->residue -= len;\n\tfru->offset += len;\n}\n\n \nstatic void\nbfa_fru_read_send(void *cbarg, enum bfi_fru_h2i_msgs msg_type)\n{\n\tstruct bfa_fru_s *fru = cbarg;\n\tstruct bfi_fru_read_req_s *msg =\n\t\t\t(struct bfi_fru_read_req_s *) fru->mb.msg;\n\tu32 len;\n\n\tmsg->offset = cpu_to_be32(fru->addr_off + fru->offset);\n\tlen = (fru->residue < BFA_FRU_DMA_BUF_SZ) ?\n\t\t\t\tfru->residue : BFA_FRU_DMA_BUF_SZ;\n\tmsg->length = cpu_to_be32(len);\n\tbfi_h2i_set(msg->mh, BFI_MC_FRU, msg_type, bfa_ioc_portid(fru->ioc));\n\tbfa_alen_set(&msg->alen, len, fru->dbuf_pa);\n\tbfa_ioc_mbox_queue(fru->ioc, &fru->mb);\n}\n\n \nu32\nbfa_fru_meminfo(bfa_boolean_t mincfg)\n{\n\t \n\tif (mincfg)\n\t\treturn 0;\n\n\treturn BFA_ROUNDUP(BFA_FRU_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n}\n\n \nvoid\nbfa_fru_attach(struct bfa_fru_s *fru, struct bfa_ioc_s *ioc, void *dev,\n\tstruct bfa_trc_mod_s *trcmod, bfa_boolean_t mincfg)\n{\n\tfru->ioc = ioc;\n\tfru->trcmod = trcmod;\n\tfru->cbfn = NULL;\n\tfru->cbarg = NULL;\n\tfru->op_busy = 0;\n\n\tbfa_ioc_mbox_regisr(fru->ioc, BFI_MC_FRU, bfa_fru_intr, fru);\n\tbfa_q_qe_init(&fru->ioc_notify);\n\tbfa_ioc_notify_init(&fru->ioc_notify, bfa_fru_notify, fru);\n\tlist_add_tail(&fru->ioc_notify.qe, &fru->ioc->notify_q);\n\n\t \n\tif (mincfg) {\n\t\tfru->dbuf_kva = NULL;\n\t\tfru->dbuf_pa = 0;\n\t}\n}\n\n \nvoid\nbfa_fru_memclaim(struct bfa_fru_s *fru, u8 *dm_kva, u64 dm_pa,\n\tbfa_boolean_t mincfg)\n{\n\tif (mincfg)\n\t\treturn;\n\n\tfru->dbuf_kva = dm_kva;\n\tfru->dbuf_pa = dm_pa;\n\tmemset(fru->dbuf_kva, 0, BFA_FRU_DMA_BUF_SZ);\n\tdm_kva += BFA_ROUNDUP(BFA_FRU_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n\tdm_pa += BFA_ROUNDUP(BFA_FRU_DMA_BUF_SZ, BFA_DMA_ALIGN_SZ);\n}\n\n \nbfa_status_t\nbfa_fruvpd_update(struct bfa_fru_s *fru, void *buf, u32 len, u32 offset,\n\t\t  bfa_cb_fru_t cbfn, void *cbarg, u8 trfr_cmpl)\n{\n\tbfa_trc(fru, BFI_FRUVPD_H2I_WRITE_REQ);\n\tbfa_trc(fru, len);\n\tbfa_trc(fru, offset);\n\n\tif (fru->ioc->asic_gen != BFI_ASIC_GEN_CT2 &&\n\t\tfru->ioc->attr->card_type != BFA_MFG_TYPE_CHINOOK2)\n\t\treturn BFA_STATUS_FRU_NOT_PRESENT;\n\n\tif (fru->ioc->attr->card_type != BFA_MFG_TYPE_CHINOOK)\n\t\treturn BFA_STATUS_CMD_NOTSUPP;\n\n\tif (!bfa_ioc_is_operational(fru->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (fru->op_busy) {\n\t\tbfa_trc(fru, fru->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tfru->op_busy = 1;\n\n\tfru->cbfn = cbfn;\n\tfru->cbarg = cbarg;\n\tfru->residue = len;\n\tfru->offset = 0;\n\tfru->addr_off = offset;\n\tfru->ubuf = buf;\n\tfru->trfr_cmpl = trfr_cmpl;\n\n\tbfa_fru_write_send(fru, BFI_FRUVPD_H2I_WRITE_REQ);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_fruvpd_read(struct bfa_fru_s *fru, void *buf, u32 len, u32 offset,\n\t\tbfa_cb_fru_t cbfn, void *cbarg)\n{\n\tbfa_trc(fru, BFI_FRUVPD_H2I_READ_REQ);\n\tbfa_trc(fru, len);\n\tbfa_trc(fru, offset);\n\n\tif (fru->ioc->asic_gen != BFI_ASIC_GEN_CT2)\n\t\treturn BFA_STATUS_FRU_NOT_PRESENT;\n\n\tif (fru->ioc->attr->card_type != BFA_MFG_TYPE_CHINOOK &&\n\t\tfru->ioc->attr->card_type != BFA_MFG_TYPE_CHINOOK2)\n\t\treturn BFA_STATUS_CMD_NOTSUPP;\n\n\tif (!bfa_ioc_is_operational(fru->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (fru->op_busy) {\n\t\tbfa_trc(fru, fru->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tfru->op_busy = 1;\n\n\tfru->cbfn = cbfn;\n\tfru->cbarg = cbarg;\n\tfru->residue = len;\n\tfru->offset = 0;\n\tfru->addr_off = offset;\n\tfru->ubuf = buf;\n\tbfa_fru_read_send(fru, BFI_FRUVPD_H2I_READ_REQ);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_fruvpd_get_max_size(struct bfa_fru_s *fru, u32 *max_size)\n{\n\tif (fru->ioc->asic_gen != BFI_ASIC_GEN_CT2)\n\t\treturn BFA_STATUS_FRU_NOT_PRESENT;\n\n\tif (!bfa_ioc_is_operational(fru->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (fru->ioc->attr->card_type == BFA_MFG_TYPE_CHINOOK ||\n\t\tfru->ioc->attr->card_type == BFA_MFG_TYPE_CHINOOK2)\n\t\t*max_size = BFA_FRU_CHINOOK_MAX_SIZE;\n\telse\n\t\treturn BFA_STATUS_CMD_NOTSUPP;\n\treturn BFA_STATUS_OK;\n}\n \nbfa_status_t\nbfa_tfru_write(struct bfa_fru_s *fru, void *buf, u32 len, u32 offset,\n\t       bfa_cb_fru_t cbfn, void *cbarg)\n{\n\tbfa_trc(fru, BFI_TFRU_H2I_WRITE_REQ);\n\tbfa_trc(fru, len);\n\tbfa_trc(fru, offset);\n\tbfa_trc(fru, *((u8 *) buf));\n\n\tif (fru->ioc->asic_gen != BFI_ASIC_GEN_CT2)\n\t\treturn BFA_STATUS_FRU_NOT_PRESENT;\n\n\tif (!bfa_ioc_is_operational(fru->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (fru->op_busy) {\n\t\tbfa_trc(fru, fru->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tfru->op_busy = 1;\n\n\tfru->cbfn = cbfn;\n\tfru->cbarg = cbarg;\n\tfru->residue = len;\n\tfru->offset = 0;\n\tfru->addr_off = offset;\n\tfru->ubuf = buf;\n\n\tbfa_fru_write_send(fru, BFI_TFRU_H2I_WRITE_REQ);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nbfa_status_t\nbfa_tfru_read(struct bfa_fru_s *fru, void *buf, u32 len, u32 offset,\n\t      bfa_cb_fru_t cbfn, void *cbarg)\n{\n\tbfa_trc(fru, BFI_TFRU_H2I_READ_REQ);\n\tbfa_trc(fru, len);\n\tbfa_trc(fru, offset);\n\n\tif (fru->ioc->asic_gen != BFI_ASIC_GEN_CT2)\n\t\treturn BFA_STATUS_FRU_NOT_PRESENT;\n\n\tif (!bfa_ioc_is_operational(fru->ioc))\n\t\treturn BFA_STATUS_IOC_NON_OP;\n\n\tif (fru->op_busy) {\n\t\tbfa_trc(fru, fru->op_busy);\n\t\treturn BFA_STATUS_DEVBUSY;\n\t}\n\n\tfru->op_busy = 1;\n\n\tfru->cbfn = cbfn;\n\tfru->cbarg = cbarg;\n\tfru->residue = len;\n\tfru->offset = 0;\n\tfru->addr_off = offset;\n\tfru->ubuf = buf;\n\tbfa_fru_read_send(fru, BFI_TFRU_H2I_READ_REQ);\n\n\treturn BFA_STATUS_OK;\n}\n\n \nvoid\nbfa_fru_intr(void *fruarg, struct bfi_mbmsg_s *msg)\n{\n\tstruct bfa_fru_s *fru = fruarg;\n\tstruct bfi_fru_rsp_s *rsp = (struct bfi_fru_rsp_s *)msg;\n\tu32 status;\n\n\tbfa_trc(fru, msg->mh.msg_id);\n\n\tif (!fru->op_busy) {\n\t\t \n\t\tbfa_trc(fru, 0x9999);\n\t\treturn;\n\t}\n\n\tswitch (msg->mh.msg_id) {\n\tcase BFI_FRUVPD_I2H_WRITE_RSP:\n\tcase BFI_TFRU_I2H_WRITE_RSP:\n\t\tstatus = be32_to_cpu(rsp->status);\n\t\tbfa_trc(fru, status);\n\n\t\tif (status != BFA_STATUS_OK || fru->residue == 0) {\n\t\t\tfru->status = status;\n\t\t\tfru->op_busy = 0;\n\t\t\tif (fru->cbfn)\n\t\t\t\tfru->cbfn(fru->cbarg, fru->status);\n\t\t} else {\n\t\t\tbfa_trc(fru, fru->offset);\n\t\t\tif (msg->mh.msg_id == BFI_FRUVPD_I2H_WRITE_RSP)\n\t\t\t\tbfa_fru_write_send(fru,\n\t\t\t\t\tBFI_FRUVPD_H2I_WRITE_REQ);\n\t\t\telse\n\t\t\t\tbfa_fru_write_send(fru,\n\t\t\t\t\tBFI_TFRU_H2I_WRITE_REQ);\n\t\t}\n\t\tbreak;\n\tcase BFI_FRUVPD_I2H_READ_RSP:\n\tcase BFI_TFRU_I2H_READ_RSP:\n\t\tstatus = be32_to_cpu(rsp->status);\n\t\tbfa_trc(fru, status);\n\n\t\tif (status != BFA_STATUS_OK) {\n\t\t\tfru->status = status;\n\t\t\tfru->op_busy = 0;\n\t\t\tif (fru->cbfn)\n\t\t\t\tfru->cbfn(fru->cbarg, fru->status);\n\t\t} else {\n\t\t\tu32 len = be32_to_cpu(rsp->length);\n\n\t\t\tbfa_trc(fru, fru->offset);\n\t\t\tbfa_trc(fru, len);\n\n\t\t\tmemcpy(fru->ubuf + fru->offset, fru->dbuf_kva, len);\n\t\t\tfru->residue -= len;\n\t\t\tfru->offset += len;\n\n\t\t\tif (fru->residue == 0) {\n\t\t\t\tfru->status = status;\n\t\t\t\tfru->op_busy = 0;\n\t\t\t\tif (fru->cbfn)\n\t\t\t\t\tfru->cbfn(fru->cbarg, fru->status);\n\t\t\t} else {\n\t\t\t\tif (msg->mh.msg_id == BFI_FRUVPD_I2H_READ_RSP)\n\t\t\t\t\tbfa_fru_read_send(fru,\n\t\t\t\t\t\tBFI_FRUVPD_H2I_READ_REQ);\n\t\t\t\telse\n\t\t\t\t\tbfa_fru_read_send(fru,\n\t\t\t\t\t\tBFI_TFRU_H2I_READ_REQ);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t}\n}\n\n \n#define FLI_CMD_REG\t\t\t0x0001d000\n#define FLI_RDDATA_REG\t\t\t0x0001d010\n#define FLI_ADDR_REG\t\t\t0x0001d004\n#define FLI_DEV_STATUS_REG\t\t0x0001d014\n\n#define BFA_FLASH_FIFO_SIZE\t\t128\t \n#define BFA_FLASH_CHECK_MAX\t\t10000\t \n#define BFA_FLASH_BLOCKING_OP_MAX\t1000000\t \n#define BFA_FLASH_WIP_MASK\t\t0x01\t \n\nenum bfa_flash_cmd {\n\tBFA_FLASH_FAST_READ\t= 0x0b,\t \n\tBFA_FLASH_READ_STATUS\t= 0x05,\t \n};\n\n \nenum bfa_flash_err {\n\tBFA_FLASH_NOT_PRESENT\t= -1,\t \n\tBFA_FLASH_UNINIT\t= -2,\t \n\tBFA_FLASH_BAD\t\t= -3,\t \n\tBFA_FLASH_BUSY\t\t= -4,\t \n\tBFA_FLASH_ERR_CMD_ACT\t= -5,\t \n\tBFA_FLASH_ERR_FIFO_CNT\t= -6,\t \n\tBFA_FLASH_ERR_WIP\t= -7,\t \n\tBFA_FLASH_ERR_TIMEOUT\t= -8,\t \n\tBFA_FLASH_ERR_LEN\t= -9,\t \n};\n\n \nunion bfa_flash_cmd_reg_u {\n\tstruct {\n#ifdef __BIG_ENDIAN\n\t\tu32\tact:1;\n\t\tu32\trsv:1;\n\t\tu32\twrite_cnt:9;\n\t\tu32\tread_cnt:9;\n\t\tu32\taddr_cnt:4;\n\t\tu32\tcmd:8;\n#else\n\t\tu32\tcmd:8;\n\t\tu32\taddr_cnt:4;\n\t\tu32\tread_cnt:9;\n\t\tu32\twrite_cnt:9;\n\t\tu32\trsv:1;\n\t\tu32\tact:1;\n#endif\n\t} r;\n\tu32\ti;\n};\n\n \nunion bfa_flash_dev_status_reg_u {\n\tstruct {\n#ifdef __BIG_ENDIAN\n\t\tu32\trsv:21;\n\t\tu32\tfifo_cnt:6;\n\t\tu32\tbusy:1;\n\t\tu32\tinit_status:1;\n\t\tu32\tpresent:1;\n\t\tu32\tbad:1;\n\t\tu32\tgood:1;\n#else\n\t\tu32\tgood:1;\n\t\tu32\tbad:1;\n\t\tu32\tpresent:1;\n\t\tu32\tinit_status:1;\n\t\tu32\tbusy:1;\n\t\tu32\tfifo_cnt:6;\n\t\tu32\trsv:21;\n#endif\n\t} r;\n\tu32\ti;\n};\n\n \nunion bfa_flash_addr_reg_u {\n\tstruct {\n#ifdef __BIG_ENDIAN\n\t\tu32\taddr:24;\n\t\tu32\tdummy:8;\n#else\n\t\tu32\tdummy:8;\n\t\tu32\taddr:24;\n#endif\n\t} r;\n\tu32\ti;\n};\n\n \nstatic void\nbfa_flash_set_cmd(void __iomem *pci_bar, u8 wr_cnt,\n\t\t  u8 rd_cnt, u8 ad_cnt, u8 op)\n{\n\tunion bfa_flash_cmd_reg_u cmd;\n\n\tcmd.i = 0;\n\tcmd.r.act = 1;\n\tcmd.r.write_cnt = wr_cnt;\n\tcmd.r.read_cnt = rd_cnt;\n\tcmd.r.addr_cnt = ad_cnt;\n\tcmd.r.cmd = op;\n\twritel(cmd.i, (pci_bar + FLI_CMD_REG));\n}\n\nstatic void\nbfa_flash_set_addr(void __iomem *pci_bar, u32 address)\n{\n\tunion bfa_flash_addr_reg_u addr;\n\n\taddr.r.addr = address & 0x00ffffff;\n\taddr.r.dummy = 0;\n\twritel(addr.i, (pci_bar + FLI_ADDR_REG));\n}\n\nstatic int\nbfa_flash_cmd_act_check(void __iomem *pci_bar)\n{\n\tunion bfa_flash_cmd_reg_u cmd;\n\n\tcmd.i = readl(pci_bar + FLI_CMD_REG);\n\n\tif (cmd.r.act)\n\t\treturn BFA_FLASH_ERR_CMD_ACT;\n\n\treturn 0;\n}\n\n \nstatic u32\nbfa_flash_fifo_flush(void __iomem *pci_bar)\n{\n\tu32 i;\n\tunion bfa_flash_dev_status_reg_u dev_status;\n\n\tdev_status.i = readl(pci_bar + FLI_DEV_STATUS_REG);\n\n\tif (!dev_status.r.fifo_cnt)\n\t\treturn 0;\n\n\t \n\tfor (i = 0; i < dev_status.r.fifo_cnt; i++)\n\t\treadl(pci_bar + FLI_RDDATA_REG);\n\n\t \n\tfor (i = 0; i < BFA_FLASH_CHECK_MAX; i++) {\n\t\tdev_status.i = readl(pci_bar + FLI_DEV_STATUS_REG);\n\t\tif (!dev_status.r.fifo_cnt)\n\t\t\tbreak;\n\t}\n\n\tif (dev_status.r.fifo_cnt)\n\t\treturn BFA_FLASH_ERR_FIFO_CNT;\n\n\treturn 0;\n}\n\n \nstatic u32\nbfa_flash_status_read(void __iomem *pci_bar)\n{\n\tunion bfa_flash_dev_status_reg_u\tdev_status;\n\tint\t\t\t\tstatus;\n\tu32\t\t\tret_status;\n\tint\t\t\t\ti;\n\n\tstatus = bfa_flash_fifo_flush(pci_bar);\n\tif (status < 0)\n\t\treturn status;\n\n\tbfa_flash_set_cmd(pci_bar, 0, 4, 0, BFA_FLASH_READ_STATUS);\n\n\tfor (i = 0; i < BFA_FLASH_CHECK_MAX; i++) {\n\t\tstatus = bfa_flash_cmd_act_check(pci_bar);\n\t\tif (!status)\n\t\t\tbreak;\n\t}\n\n\tif (status)\n\t\treturn status;\n\n\tdev_status.i = readl(pci_bar + FLI_DEV_STATUS_REG);\n\tif (!dev_status.r.fifo_cnt)\n\t\treturn BFA_FLASH_BUSY;\n\n\tret_status = readl(pci_bar + FLI_RDDATA_REG);\n\tret_status >>= 24;\n\n\tstatus = bfa_flash_fifo_flush(pci_bar);\n\tif (status < 0)\n\t\treturn status;\n\n\treturn ret_status;\n}\n\n \nstatic u32\nbfa_flash_read_start(void __iomem *pci_bar, u32 offset, u32 len,\n\t\t\t char *buf)\n{\n\tint status;\n\n\t \n\tif (len == 0 || len > BFA_FLASH_FIFO_SIZE || (len & 0x03) != 0)\n\t\treturn BFA_FLASH_ERR_LEN;\n\n\t \n\tstatus = bfa_flash_status_read(pci_bar);\n\tif (status == BFA_FLASH_BUSY)\n\t\tstatus = bfa_flash_status_read(pci_bar);\n\n\tif (status < 0)\n\t\treturn status;\n\n\t \n\tif (status & BFA_FLASH_WIP_MASK)\n\t\treturn BFA_FLASH_ERR_WIP;\n\n\tbfa_flash_set_addr(pci_bar, offset);\n\n\tbfa_flash_set_cmd(pci_bar, 0, (u8)len, 4, BFA_FLASH_FAST_READ);\n\n\treturn 0;\n}\n\n \nstatic u32\nbfa_flash_read_check(void __iomem *pci_bar)\n{\n\tif (bfa_flash_cmd_act_check(pci_bar))\n\t\treturn 1;\n\n\treturn 0;\n}\n\n \nstatic void\nbfa_flash_read_end(void __iomem *pci_bar, u32 len, char *buf)\n{\n\n\tu32 i;\n\n\t \n\tfor (i = 0; i < len; i += 4) {\n\t\tu32 w = readl(pci_bar + FLI_RDDATA_REG);\n\t\t*((u32 *) (buf + i)) = swab32(w);\n\t}\n\n\tbfa_flash_fifo_flush(pci_bar);\n}\n\n \n\n\n#define FLASH_BLOCKING_OP_MAX   500\n#define FLASH_SEM_LOCK_REG\t0x18820\n\nstatic int\nbfa_raw_sem_get(void __iomem *bar)\n{\n\tint\tlocked;\n\n\tlocked = readl((bar + FLASH_SEM_LOCK_REG));\n\treturn !locked;\n\n}\n\nstatic bfa_status_t\nbfa_flash_sem_get(void __iomem *bar)\n{\n\tu32 n = FLASH_BLOCKING_OP_MAX;\n\n\twhile (!bfa_raw_sem_get(bar)) {\n\t\tif (--n <= 0)\n\t\t\treturn BFA_STATUS_BADFLASH;\n\t\tmdelay(10);\n\t}\n\treturn BFA_STATUS_OK;\n}\n\nstatic void\nbfa_flash_sem_put(void __iomem *bar)\n{\n\twritel(0, (bar + FLASH_SEM_LOCK_REG));\n}\n\nbfa_status_t\nbfa_flash_raw_read(void __iomem *pci_bar, u32 offset, char *buf,\n\t\t       u32 len)\n{\n\tu32 n;\n\tint status;\n\tu32 off, l, s, residue, fifo_sz;\n\n\tresidue = len;\n\toff = 0;\n\tfifo_sz = BFA_FLASH_FIFO_SIZE;\n\tstatus = bfa_flash_sem_get(pci_bar);\n\tif (status != BFA_STATUS_OK)\n\t\treturn status;\n\n\twhile (residue) {\n\t\ts = offset + off;\n\t\tn = s / fifo_sz;\n\t\tl = (n + 1) * fifo_sz - s;\n\t\tif (l > residue)\n\t\t\tl = residue;\n\n\t\tstatus = bfa_flash_read_start(pci_bar, offset + off, l,\n\t\t\t\t\t\t\t\t&buf[off]);\n\t\tif (status < 0) {\n\t\t\tbfa_flash_sem_put(pci_bar);\n\t\t\treturn BFA_STATUS_FAILED;\n\t\t}\n\n\t\tn = BFA_FLASH_BLOCKING_OP_MAX;\n\t\twhile (bfa_flash_read_check(pci_bar)) {\n\t\t\tif (--n <= 0) {\n\t\t\t\tbfa_flash_sem_put(pci_bar);\n\t\t\t\treturn BFA_STATUS_FAILED;\n\t\t\t}\n\t\t}\n\n\t\tbfa_flash_read_end(pci_bar, l, &buf[off]);\n\n\t\tresidue -= l;\n\t\toff += l;\n\t}\n\tbfa_flash_sem_put(pci_bar);\n\n\treturn BFA_STATUS_OK;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}