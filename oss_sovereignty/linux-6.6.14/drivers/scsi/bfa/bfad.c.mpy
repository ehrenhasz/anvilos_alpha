{
  "module_name": "bfad.c",
  "hash_id": "6500d7d2e957b119b378964a7cc42edfc8df6818a8002eb26e124e3277d672b4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/bfa/bfad.c",
  "human_readable_source": "\n \n\n \n#include <linux/module.h>\n#include <linux/kthread.h>\n#include <linux/errno.h>\n#include <linux/sched.h>\n#include <linux/init.h>\n#include <linux/fs.h>\n#include <linux/pci.h>\n#include <linux/firmware.h>\n#include <linux/uaccess.h>\n#include <asm/fcntl.h>\n\n#include \"bfad_drv.h\"\n#include \"bfad_im.h\"\n#include \"bfa_fcs.h\"\n#include \"bfa_defs.h\"\n#include \"bfa.h\"\n\nBFA_TRC_FILE(LDRV, BFAD);\nDEFINE_MUTEX(bfad_mutex);\nLIST_HEAD(bfad_list);\n\nstatic int\tbfad_inst;\nstatic int      num_sgpgs_parm;\nint\t\tsupported_fc4s;\nchar\t\t*host_name, *os_name, *os_patch;\nint\t\tnum_rports, num_ios, num_tms;\nint\t\tnum_fcxps, num_ufbufs;\nint\t\treqq_size, rspq_size, num_sgpgs;\nint\t\trport_del_timeout = BFA_FCS_RPORT_DEF_DEL_TIMEOUT;\nint\t\tbfa_lun_queue_depth = BFAD_LUN_QUEUE_DEPTH;\nint\t\tbfa_io_max_sge = BFAD_IO_MAX_SGE;\nint\t\tbfa_log_level = 3;  \nint\t\tioc_auto_recover = BFA_TRUE;\nint\t\tbfa_linkup_delay = -1;\nint\t\tfdmi_enable = BFA_TRUE;\nint\t\tpcie_max_read_reqsz;\nint\t\tbfa_debugfs_enable = 1;\nint\t\tmsix_disable_cb = 0, msix_disable_ct = 0;\nint\t\tmax_xfer_size = BFAD_MAX_SECTORS >> 1;\nstatic int\tmax_rport_logins = BFA_FCS_MAX_RPORT_LOGINS;\n\n \nu32\tbfi_image_cb_size, bfi_image_ct_size, bfi_image_ct2_size;\nu32\t*bfi_image_cb, *bfi_image_ct, *bfi_image_ct2;\n\n#define BFAD_FW_FILE_CB\t\t\"cbfw-3.2.5.1.bin\"\n#define BFAD_FW_FILE_CT\t\t\"ctfw-3.2.5.1.bin\"\n#define BFAD_FW_FILE_CT2\t\"ct2fw-3.2.5.1.bin\"\n\nstatic u32 *bfad_load_fwimg(struct pci_dev *pdev);\nstatic void bfad_free_fwimg(void);\nstatic void bfad_read_firmware(struct pci_dev *pdev, u32 **bfi_image,\n\t\tu32 *bfi_image_size, char *fw_name);\n\nstatic const char *msix_name_ct[] = {\n\t\"ctrl\",\n\t\"cpe0\", \"cpe1\", \"cpe2\", \"cpe3\",\n\t\"rme0\", \"rme1\", \"rme2\", \"rme3\" };\n\nstatic const char *msix_name_cb[] = {\n\t\"cpe0\", \"cpe1\", \"cpe2\", \"cpe3\",\n\t\"rme0\", \"rme1\", \"rme2\", \"rme3\",\n\t\"eemc\", \"elpu0\", \"elpu1\", \"epss\", \"mlpu\" };\n\nMODULE_FIRMWARE(BFAD_FW_FILE_CB);\nMODULE_FIRMWARE(BFAD_FW_FILE_CT);\nMODULE_FIRMWARE(BFAD_FW_FILE_CT2);\n\nmodule_param(os_name, charp, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(os_name, \"OS name of the hba host machine\");\nmodule_param(os_patch, charp, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(os_patch, \"OS patch level of the hba host machine\");\nmodule_param(host_name, charp, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(host_name, \"Hostname of the hba host machine\");\nmodule_param(num_rports, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(num_rports, \"Max number of rports supported per port \"\n\t\t\t\t\"(physical/logical), default=1024\");\nmodule_param(num_ios, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(num_ios, \"Max number of ioim requests, default=2000\");\nmodule_param(num_tms, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(num_tms, \"Max number of task im requests, default=128\");\nmodule_param(num_fcxps, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(num_fcxps, \"Max number of fcxp requests, default=64\");\nmodule_param(num_ufbufs, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(num_ufbufs, \"Max number of unsolicited frame \"\n\t\t\t\t\"buffers, default=64\");\nmodule_param(reqq_size, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(reqq_size, \"Max number of request queue elements, \"\n\t\t\t\t\"default=256\");\nmodule_param(rspq_size, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(rspq_size, \"Max number of response queue elements, \"\n\t\t\t\t\"default=64\");\nmodule_param(num_sgpgs, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(num_sgpgs, \"Number of scatter/gather pages, default=2048\");\nmodule_param(rport_del_timeout, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(rport_del_timeout, \"Rport delete timeout, default=90 secs, \"\n\t\t\t\t\t\"Range[>0]\");\nmodule_param(bfa_lun_queue_depth, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(bfa_lun_queue_depth, \"Lun queue depth, default=32, Range[>0]\");\nmodule_param(bfa_io_max_sge, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(bfa_io_max_sge, \"Max io scatter/gather elements, default=255\");\nmodule_param(bfa_log_level, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(bfa_log_level, \"Driver log level, default=3, \"\n\t\t\t\t\"Range[Critical:1|Error:2|Warning:3|Info:4]\");\nmodule_param(ioc_auto_recover, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(ioc_auto_recover, \"IOC auto recovery, default=1, \"\n\t\t\t\t\"Range[off:0|on:1]\");\nmodule_param(bfa_linkup_delay, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(bfa_linkup_delay, \"Link up delay, default=30 secs for \"\n\t\t\t\"boot port. Otherwise 10 secs in RHEL4 & 0 for \"\n\t\t\t\"[RHEL5, SLES10, ESX40] Range[>0]\");\nmodule_param(msix_disable_cb, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(msix_disable_cb, \"Disable Message Signaled Interrupts for QLogic-415/425/815/825 cards, default=0 Range[false:0|true:1]\");\nmodule_param(msix_disable_ct, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(msix_disable_ct, \"Disable Message Signaled Interrupts if possible for QLogic-1010/1020/804/1007/902/1741 cards, default=0, Range[false:0|true:1]\");\nmodule_param(fdmi_enable, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(fdmi_enable, \"Enables fdmi registration, default=1, \"\n\t\t\t\t\"Range[false:0|true:1]\");\nmodule_param(pcie_max_read_reqsz, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(pcie_max_read_reqsz, \"PCIe max read request size, default=0 \"\n\t\t\"(use system setting), Range[128|256|512|1024|2048|4096]\");\nmodule_param(bfa_debugfs_enable, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(bfa_debugfs_enable, \"Enables debugfs feature, default=1,\"\n\t\t\" Range[false:0|true:1]\");\nmodule_param(max_xfer_size, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(max_xfer_size, \"default=32MB,\"\n\t\t\" Range[64k|128k|256k|512k|1024k|2048k]\");\nmodule_param(max_rport_logins, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(max_rport_logins, \"Max number of logins to initiator and target rports on a port (physical/logical), default=1024\");\n\nstatic void\nbfad_sm_uninit(struct bfad_s *bfad, enum bfad_sm_event event);\nstatic void\nbfad_sm_created(struct bfad_s *bfad, enum bfad_sm_event event);\nstatic void\nbfad_sm_initializing(struct bfad_s *bfad, enum bfad_sm_event event);\nstatic void\nbfad_sm_operational(struct bfad_s *bfad, enum bfad_sm_event event);\nstatic void\nbfad_sm_stopping(struct bfad_s *bfad, enum bfad_sm_event event);\nstatic void\nbfad_sm_failed(struct bfad_s *bfad, enum bfad_sm_event event);\nstatic void\nbfad_sm_fcs_exit(struct bfad_s *bfad, enum bfad_sm_event event);\n\n \nstatic void\nbfad_sm_uninit(struct bfad_s *bfad, enum bfad_sm_event event)\n{\n\tbfa_trc(bfad, event);\n\n\tswitch (event) {\n\tcase BFAD_E_CREATE:\n\t\tbfa_sm_set_state(bfad, bfad_sm_created);\n\t\tbfad->bfad_tsk = kthread_create(bfad_worker, (void *) bfad,\n\t\t\t\t\t\t\"%s\", \"bfad_worker\");\n\t\tif (IS_ERR(bfad->bfad_tsk)) {\n\t\t\tprintk(KERN_INFO \"bfad[%d]: Kernel thread \"\n\t\t\t\t\"creation failed!\\n\", bfad->inst_no);\n\t\t\tbfa_sm_send_event(bfad, BFAD_E_KTHREAD_CREATE_FAILED);\n\t\t}\n\t\tbfa_sm_send_event(bfad, BFAD_E_INIT);\n\t\tbreak;\n\n\tcase BFAD_E_STOP:\n\t\t \n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(bfad, event);\n\t}\n}\n\n \nstatic void\nbfad_sm_created(struct bfad_s *bfad, enum bfad_sm_event event)\n{\n\tunsigned long flags;\n\tbfa_status_t ret;\n\n\tbfa_trc(bfad, event);\n\n\tswitch (event) {\n\tcase BFAD_E_INIT:\n\t\tbfa_sm_set_state(bfad, bfad_sm_initializing);\n\n\t\tinit_completion(&bfad->comp);\n\n\t\t \n\t\tif (bfad_setup_intr(bfad)) {\n\t\t\tprintk(KERN_WARNING \"bfad%d: bfad_setup_intr failed\\n\",\n\t\t\t\t\tbfad->inst_no);\n\t\t\tbfa_sm_send_event(bfad, BFAD_E_INIT_FAILED);\n\t\t\tbreak;\n\t\t}\n\n\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\tbfa_iocfc_init(&bfad->bfa);\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\t\t \n\t\tif ((bfad->bfad_flags & BFAD_MSIX_ON) &&\n\t\t\tbfad_install_msix_handler(bfad)) {\n\t\t\tprintk(KERN_WARNING \"%s: install_msix failed, bfad%d\\n\",\n\t\t\t\t__func__, bfad->inst_no);\n\t\t}\n\n\t\tbfad_init_timer(bfad);\n\n\t\twait_for_completion(&bfad->comp);\n\n\t\tif ((bfad->bfad_flags & BFAD_HAL_INIT_DONE)) {\n\t\t\tbfa_sm_send_event(bfad, BFAD_E_INIT_SUCCESS);\n\t\t} else {\n\t\t\tprintk(KERN_WARNING\n\t\t\t\t\"bfa %s: bfa init failed\\n\",\n\t\t\t\tbfad->pci_name);\n\t\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\t\tbfa_fcs_init(&bfad->bfa_fcs);\n\t\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\t\t\tret = bfad_cfg_pport(bfad, BFA_LPORT_ROLE_FCP_IM);\n\t\t\tif (ret != BFA_STATUS_OK) {\n\t\t\t\tinit_completion(&bfad->comp);\n\n\t\t\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\t\t\tbfad->pport.flags |= BFAD_PORT_DELETE;\n\t\t\t\tbfa_fcs_exit(&bfad->bfa_fcs);\n\t\t\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\t\t\t\twait_for_completion(&bfad->comp);\n\n\t\t\t\tbfa_sm_send_event(bfad, BFAD_E_INIT_FAILED);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbfad->bfad_flags |= BFAD_HAL_INIT_FAIL;\n\t\t\tbfa_sm_send_event(bfad, BFAD_E_HAL_INIT_FAILED);\n\t\t}\n\n\t\tbreak;\n\n\tcase BFAD_E_KTHREAD_CREATE_FAILED:\n\t\tbfa_sm_set_state(bfad, bfad_sm_uninit);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(bfad, event);\n\t}\n}\n\nstatic void\nbfad_sm_initializing(struct bfad_s *bfad, enum bfad_sm_event event)\n{\n\tint\tretval;\n\tunsigned long\tflags;\n\n\tbfa_trc(bfad, event);\n\n\tswitch (event) {\n\tcase BFAD_E_INIT_SUCCESS:\n\t\tkthread_stop(bfad->bfad_tsk);\n\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\tbfad->bfad_tsk = NULL;\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\t\tretval = bfad_start_ops(bfad);\n\t\tif (retval != BFA_STATUS_OK) {\n\t\t\tbfa_sm_set_state(bfad, bfad_sm_failed);\n\t\t\tbreak;\n\t\t}\n\t\tbfa_sm_set_state(bfad, bfad_sm_operational);\n\t\tbreak;\n\n\tcase BFAD_E_INIT_FAILED:\n\t\tbfa_sm_set_state(bfad, bfad_sm_uninit);\n\t\tkthread_stop(bfad->bfad_tsk);\n\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\tbfad->bfad_tsk = NULL;\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\t\tbreak;\n\n\tcase BFAD_E_HAL_INIT_FAILED:\n\t\tbfa_sm_set_state(bfad, bfad_sm_failed);\n\t\tbreak;\n\tdefault:\n\t\tbfa_sm_fault(bfad, event);\n\t}\n}\n\nstatic void\nbfad_sm_failed(struct bfad_s *bfad, enum bfad_sm_event event)\n{\n\tint\tretval;\n\n\tbfa_trc(bfad, event);\n\n\tswitch (event) {\n\tcase BFAD_E_INIT_SUCCESS:\n\t\tretval = bfad_start_ops(bfad);\n\t\tif (retval != BFA_STATUS_OK)\n\t\t\tbreak;\n\t\tbfa_sm_set_state(bfad, bfad_sm_operational);\n\t\tbreak;\n\n\tcase BFAD_E_STOP:\n\t\tbfa_sm_set_state(bfad, bfad_sm_fcs_exit);\n\t\tbfa_sm_send_event(bfad, BFAD_E_FCS_EXIT_COMP);\n\t\tbreak;\n\n\tcase BFAD_E_EXIT_COMP:\n\t\tbfa_sm_set_state(bfad, bfad_sm_uninit);\n\t\tbfad_remove_intr(bfad);\n\t\tdel_timer_sync(&bfad->hal_tmo);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(bfad, event);\n\t}\n}\n\nstatic void\nbfad_sm_operational(struct bfad_s *bfad, enum bfad_sm_event event)\n{\n\tbfa_trc(bfad, event);\n\n\tswitch (event) {\n\tcase BFAD_E_STOP:\n\t\tbfa_sm_set_state(bfad, bfad_sm_fcs_exit);\n\t\tbfad_fcs_stop(bfad);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(bfad, event);\n\t}\n}\n\nstatic void\nbfad_sm_fcs_exit(struct bfad_s *bfad, enum bfad_sm_event event)\n{\n\tbfa_trc(bfad, event);\n\n\tswitch (event) {\n\tcase BFAD_E_FCS_EXIT_COMP:\n\t\tbfa_sm_set_state(bfad, bfad_sm_stopping);\n\t\tbfad_stop(bfad);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(bfad, event);\n\t}\n}\n\nstatic void\nbfad_sm_stopping(struct bfad_s *bfad, enum bfad_sm_event event)\n{\n\tbfa_trc(bfad, event);\n\n\tswitch (event) {\n\tcase BFAD_E_EXIT_COMP:\n\t\tbfa_sm_set_state(bfad, bfad_sm_uninit);\n\t\tbfad_remove_intr(bfad);\n\t\tdel_timer_sync(&bfad->hal_tmo);\n\t\tbfad_im_probe_undo(bfad);\n\t\tbfad->bfad_flags &= ~BFAD_FC4_PROBE_DONE;\n\t\tbfad_uncfg_pport(bfad);\n\t\tbreak;\n\n\tdefault:\n\t\tbfa_sm_fault(bfad, event);\n\t\tbreak;\n\t}\n}\n\n \nvoid\nbfad_hcb_comp(void *arg, bfa_status_t status)\n{\n\tstruct bfad_hal_comp *fcomp = (struct bfad_hal_comp *)arg;\n\n\tfcomp->status = status;\n\tcomplete(&fcomp->comp);\n}\n\n \nvoid\nbfa_cb_init(void *drv, bfa_status_t init_status)\n{\n\tstruct bfad_s\t      *bfad = drv;\n\n\tif (init_status == BFA_STATUS_OK) {\n\t\tbfad->bfad_flags |= BFAD_HAL_INIT_DONE;\n\n\t\t \n\t\tif ((bfad->bfad_flags & BFAD_HAL_INIT_FAIL)) {\n\t\t\tbfad->bfad_flags &= ~BFAD_HAL_INIT_FAIL;\n\t\t\twake_up_process(bfad->bfad_tsk);\n\t\t}\n\t}\n\n\tcomplete(&bfad->comp);\n}\n\n \nstruct bfad_port_s *\nbfa_fcb_lport_new(struct bfad_s *bfad, struct bfa_fcs_lport_s *port,\n\t\t enum bfa_lport_role roles, struct bfad_vf_s *vf_drv,\n\t\t struct bfad_vport_s *vp_drv)\n{\n\tbfa_status_t\trc;\n\tstruct bfad_port_s    *port_drv;\n\n\tif (!vp_drv && !vf_drv) {\n\t\tport_drv = &bfad->pport;\n\t\tport_drv->pvb_type = BFAD_PORT_PHYS_BASE;\n\t} else if (!vp_drv && vf_drv) {\n\t\tport_drv = &vf_drv->base_port;\n\t\tport_drv->pvb_type = BFAD_PORT_VF_BASE;\n\t} else if (vp_drv && !vf_drv) {\n\t\tport_drv = &vp_drv->drv_port;\n\t\tport_drv->pvb_type = BFAD_PORT_PHYS_VPORT;\n\t} else {\n\t\tport_drv = &vp_drv->drv_port;\n\t\tport_drv->pvb_type = BFAD_PORT_VF_VPORT;\n\t}\n\n\tport_drv->fcs_port = port;\n\tport_drv->roles = roles;\n\n\tif (roles & BFA_LPORT_ROLE_FCP_IM) {\n\t\trc = bfad_im_port_new(bfad, port_drv);\n\t\tif (rc != BFA_STATUS_OK) {\n\t\t\tbfad_im_port_delete(bfad, port_drv);\n\t\t\tport_drv = NULL;\n\t\t}\n\t}\n\n\treturn port_drv;\n}\n\n \nbfa_status_t\nbfa_fcb_rport_alloc(struct bfad_s *bfad, struct bfa_fcs_rport_s **rport,\n\t\t    struct bfad_rport_s **rport_drv)\n{\n\tbfa_status_t\trc = BFA_STATUS_OK;\n\n\t*rport_drv = kzalloc(sizeof(struct bfad_rport_s), GFP_ATOMIC);\n\tif (*rport_drv == NULL) {\n\t\trc = BFA_STATUS_ENOMEM;\n\t\tgoto ext;\n\t}\n\n\t*rport = &(*rport_drv)->fcs_rport;\n\next:\n\treturn rc;\n}\n\n \nvoid\nbfa_fcb_pbc_vport_create(struct bfad_s *bfad, struct bfi_pbc_vport_s pbc_vport)\n{\n\n\tstruct bfa_lport_cfg_s port_cfg = {0};\n\tstruct bfad_vport_s   *vport;\n\tint rc;\n\n\tvport = kzalloc(sizeof(struct bfad_vport_s), GFP_ATOMIC);\n\tif (!vport) {\n\t\tbfa_trc(bfad, 0);\n\t\treturn;\n\t}\n\n\tvport->drv_port.bfad = bfad;\n\tport_cfg.roles = BFA_LPORT_ROLE_FCP_IM;\n\tport_cfg.pwwn = pbc_vport.vp_pwwn;\n\tport_cfg.nwwn = pbc_vport.vp_nwwn;\n\tport_cfg.preboot_vp  = BFA_TRUE;\n\n\trc = bfa_fcs_pbc_vport_create(&vport->fcs_vport, &bfad->bfa_fcs, 0,\n\t\t\t\t  &port_cfg, vport);\n\n\tif (rc != BFA_STATUS_OK) {\n\t\tbfa_trc(bfad, 0);\n\t\treturn;\n\t}\n\n\tlist_add_tail(&vport->list_entry, &bfad->pbc_vport_list);\n}\n\nvoid\nbfad_hal_mem_release(struct bfad_s *bfad)\n{\n\tstruct bfa_meminfo_s *hal_meminfo = &bfad->meminfo;\n\tstruct bfa_mem_dma_s *dma_info, *dma_elem;\n\tstruct bfa_mem_kva_s *kva_info, *kva_elem;\n\tstruct list_head *dm_qe, *km_qe;\n\n\tdma_info = &hal_meminfo->dma_info;\n\tkva_info = &hal_meminfo->kva_info;\n\n\t \n\tlist_for_each(km_qe, &kva_info->qe) {\n\t\tkva_elem = (struct bfa_mem_kva_s *) km_qe;\n\t\tvfree(kva_elem->kva);\n\t}\n\n\t \n\tlist_for_each(dm_qe, &dma_info->qe) {\n\t\tdma_elem = (struct bfa_mem_dma_s *) dm_qe;\n\t\tdma_free_coherent(&bfad->pcidev->dev,\n\t\t\t\tdma_elem->mem_len, dma_elem->kva,\n\t\t\t\t(dma_addr_t) dma_elem->dma);\n\t}\n\n\tmemset(hal_meminfo, 0, sizeof(struct bfa_meminfo_s));\n}\n\nvoid\nbfad_update_hal_cfg(struct bfa_iocfc_cfg_s *bfa_cfg)\n{\n\tif (num_rports > 0)\n\t\tbfa_cfg->fwcfg.num_rports = num_rports;\n\tif (num_ios > 0)\n\t\tbfa_cfg->fwcfg.num_ioim_reqs = num_ios;\n\tif (num_tms > 0)\n\t\tbfa_cfg->fwcfg.num_tskim_reqs = num_tms;\n\tif (num_fcxps > 0 && num_fcxps <= BFA_FCXP_MAX)\n\t\tbfa_cfg->fwcfg.num_fcxp_reqs = num_fcxps;\n\tif (num_ufbufs > 0 && num_ufbufs <= BFA_UF_MAX)\n\t\tbfa_cfg->fwcfg.num_uf_bufs = num_ufbufs;\n\tif (reqq_size > 0)\n\t\tbfa_cfg->drvcfg.num_reqq_elems = reqq_size;\n\tif (rspq_size > 0)\n\t\tbfa_cfg->drvcfg.num_rspq_elems = rspq_size;\n\tif (num_sgpgs > 0 && num_sgpgs <= BFA_SGPG_MAX)\n\t\tbfa_cfg->drvcfg.num_sgpgs = num_sgpgs;\n\n\t \n\tnum_rports = bfa_cfg->fwcfg.num_rports;\n\tnum_ios = bfa_cfg->fwcfg.num_ioim_reqs;\n\tnum_tms = bfa_cfg->fwcfg.num_tskim_reqs;\n\tnum_fcxps = bfa_cfg->fwcfg.num_fcxp_reqs;\n\tnum_ufbufs = bfa_cfg->fwcfg.num_uf_bufs;\n\treqq_size = bfa_cfg->drvcfg.num_reqq_elems;\n\trspq_size = bfa_cfg->drvcfg.num_rspq_elems;\n\tnum_sgpgs = bfa_cfg->drvcfg.num_sgpgs;\n}\n\nbfa_status_t\nbfad_hal_mem_alloc(struct bfad_s *bfad)\n{\n\tstruct bfa_meminfo_s *hal_meminfo = &bfad->meminfo;\n\tstruct bfa_mem_dma_s *dma_info, *dma_elem;\n\tstruct bfa_mem_kva_s *kva_info, *kva_elem;\n\tstruct list_head *dm_qe, *km_qe;\n\tbfa_status_t\trc = BFA_STATUS_OK;\n\tdma_addr_t\tphys_addr;\n\n\tbfa_cfg_get_default(&bfad->ioc_cfg);\n\tbfad_update_hal_cfg(&bfad->ioc_cfg);\n\tbfad->cfg_data.ioc_queue_depth = bfad->ioc_cfg.fwcfg.num_ioim_reqs;\n\tbfa_cfg_get_meminfo(&bfad->ioc_cfg, hal_meminfo, &bfad->bfa);\n\n\tdma_info = &hal_meminfo->dma_info;\n\tkva_info = &hal_meminfo->kva_info;\n\n\t \n\tlist_for_each(km_qe, &kva_info->qe) {\n\t\tkva_elem = (struct bfa_mem_kva_s *) km_qe;\n\t\tkva_elem->kva = vzalloc(kva_elem->mem_len);\n\t\tif (kva_elem->kva == NULL) {\n\t\t\tbfad_hal_mem_release(bfad);\n\t\t\trc = BFA_STATUS_ENOMEM;\n\t\t\tgoto ext;\n\t\t}\n\t}\n\n\t \n\tlist_for_each(dm_qe, &dma_info->qe) {\n\t\tdma_elem = (struct bfa_mem_dma_s *) dm_qe;\n\t\tdma_elem->kva = dma_alloc_coherent(&bfad->pcidev->dev,\n\t\t\t\t\t\tdma_elem->mem_len,\n\t\t\t\t\t\t&phys_addr, GFP_KERNEL);\n\t\tif (dma_elem->kva == NULL) {\n\t\t\tbfad_hal_mem_release(bfad);\n\t\t\trc = BFA_STATUS_ENOMEM;\n\t\t\tgoto ext;\n\t\t}\n\t\tdma_elem->dma = phys_addr;\n\t\tmemset(dma_elem->kva, 0, dma_elem->mem_len);\n\t}\next:\n\treturn rc;\n}\n\n \nbfa_status_t\nbfad_vport_create(struct bfad_s *bfad, u16 vf_id,\n\t\t  struct bfa_lport_cfg_s *port_cfg, struct device *dev)\n{\n\tstruct bfad_vport_s   *vport;\n\tint\t\trc = BFA_STATUS_OK;\n\tunsigned long\tflags;\n\tstruct completion fcomp;\n\n\tvport = kzalloc(sizeof(struct bfad_vport_s), GFP_KERNEL);\n\tif (!vport) {\n\t\trc = BFA_STATUS_ENOMEM;\n\t\tgoto ext;\n\t}\n\n\tvport->drv_port.bfad = bfad;\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\trc = bfa_fcs_vport_create(&vport->fcs_vport, &bfad->bfa_fcs, vf_id,\n\t\t\t\t  port_cfg, vport);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\tif (rc != BFA_STATUS_OK)\n\t\tgoto ext_free_vport;\n\n\tif (port_cfg->roles & BFA_LPORT_ROLE_FCP_IM) {\n\t\trc = bfad_im_scsi_host_alloc(bfad, vport->drv_port.im_port,\n\t\t\t\t\t\t\tdev);\n\t\tif (rc != BFA_STATUS_OK)\n\t\t\tgoto ext_free_fcs_vport;\n\t}\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tbfa_fcs_vport_start(&vport->fcs_vport);\n\tlist_add_tail(&vport->list_entry, &bfad->vport_list);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\treturn BFA_STATUS_OK;\n\next_free_fcs_vport:\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tvport->comp_del = &fcomp;\n\tinit_completion(vport->comp_del);\n\tbfa_fcs_vport_delete(&vport->fcs_vport);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\twait_for_completion(vport->comp_del);\next_free_vport:\n\tkfree(vport);\next:\n\treturn rc;\n}\n\nvoid\nbfad_bfa_tmo(struct timer_list *t)\n{\n\tstruct bfad_s\t      *bfad = from_timer(bfad, t, hal_tmo);\n\tunsigned long\tflags;\n\tstruct list_head\t       doneq;\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\n\tbfa_timer_beat(&bfad->bfa.timer_mod);\n\n\tbfa_comp_deq(&bfad->bfa, &doneq);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\tif (!list_empty(&doneq)) {\n\t\tbfa_comp_process(&bfad->bfa, &doneq);\n\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\tbfa_comp_free(&bfad->bfa, &doneq);\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\t}\n\n\tmod_timer(&bfad->hal_tmo,\n\t\t  jiffies + msecs_to_jiffies(BFA_TIMER_FREQ));\n}\n\nvoid\nbfad_init_timer(struct bfad_s *bfad)\n{\n\ttimer_setup(&bfad->hal_tmo, bfad_bfa_tmo, 0);\n\n\tmod_timer(&bfad->hal_tmo,\n\t\t  jiffies + msecs_to_jiffies(BFA_TIMER_FREQ));\n}\n\nint\nbfad_pci_init(struct pci_dev *pdev, struct bfad_s *bfad)\n{\n\tint rc = -ENODEV;\n\n\tif (pci_enable_device(pdev)) {\n\t\tprintk(KERN_ERR \"pci_enable_device fail %p\\n\", pdev);\n\t\tgoto out;\n\t}\n\n\tif (pci_request_regions(pdev, BFAD_DRIVER_NAME))\n\t\tgoto out_disable_device;\n\n\tpci_set_master(pdev);\n\n\trc = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (rc) {\n\t\trc = -ENODEV;\n\t\tprintk(KERN_ERR \"dma_set_mask_and_coherent fail %p\\n\", pdev);\n\t\tgoto out_release_region;\n\t}\n\n\tbfad->pci_bar0_kva = pci_iomap(pdev, 0, pci_resource_len(pdev, 0));\n\tbfad->pci_bar2_kva = pci_iomap(pdev, 2, pci_resource_len(pdev, 2));\n\n\tif (bfad->pci_bar0_kva == NULL) {\n\t\tprintk(KERN_ERR \"Fail to map bar0\\n\");\n\t\trc = -ENODEV;\n\t\tgoto out_release_region;\n\t}\n\n\tbfad->hal_pcidev.pci_slot = PCI_SLOT(pdev->devfn);\n\tbfad->hal_pcidev.pci_func = PCI_FUNC(pdev->devfn);\n\tbfad->hal_pcidev.pci_bar_kva = bfad->pci_bar0_kva;\n\tbfad->hal_pcidev.device_id = pdev->device;\n\tbfad->hal_pcidev.ssid = pdev->subsystem_device;\n\tbfad->pci_name = pci_name(pdev);\n\n\tbfad->pci_attr.vendor_id = pdev->vendor;\n\tbfad->pci_attr.device_id = pdev->device;\n\tbfad->pci_attr.ssid = pdev->subsystem_device;\n\tbfad->pci_attr.ssvid = pdev->subsystem_vendor;\n\tbfad->pci_attr.pcifn = PCI_FUNC(pdev->devfn);\n\n\tbfad->pcidev = pdev;\n\n\t \n\tif (pci_is_pcie(pdev) && pcie_max_read_reqsz) {\n\t\tif (pcie_max_read_reqsz >= 128 &&\n\t\t    pcie_max_read_reqsz <= 4096 &&\n\t\t    is_power_of_2(pcie_max_read_reqsz)) {\n\t\t\tint max_rq = pcie_get_readrq(pdev);\n\t\t\tprintk(KERN_WARNING \"BFA[%s]: \"\n\t\t\t\t\"pcie_max_read_request_size is %d, \"\n\t\t\t\t\"reset to %d\\n\", bfad->pci_name, max_rq,\n\t\t\t\tpcie_max_read_reqsz);\n\t\t\tpcie_set_readrq(pdev, pcie_max_read_reqsz);\n\t\t} else {\n\t\t\tprintk(KERN_WARNING \"BFA[%s]: invalid \"\n\t\t\t       \"pcie_max_read_request_size %d ignored\\n\",\n\t\t\t       bfad->pci_name, pcie_max_read_reqsz);\n\t\t}\n\t}\n\n\tpci_save_state(pdev);\n\n\treturn 0;\n\nout_release_region:\n\tpci_release_regions(pdev);\nout_disable_device:\n\tpci_disable_device(pdev);\nout:\n\treturn rc;\n}\n\nvoid\nbfad_pci_uninit(struct pci_dev *pdev, struct bfad_s *bfad)\n{\n\tpci_iounmap(pdev, bfad->pci_bar0_kva);\n\tpci_iounmap(pdev, bfad->pci_bar2_kva);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n}\n\nbfa_status_t\nbfad_drv_init(struct bfad_s *bfad)\n{\n\tbfa_status_t\trc;\n\tunsigned long\tflags;\n\n\tbfad->cfg_data.rport_del_timeout = rport_del_timeout;\n\tbfad->cfg_data.lun_queue_depth = bfa_lun_queue_depth;\n\tbfad->cfg_data.io_max_sge = bfa_io_max_sge;\n\tbfad->cfg_data.binding_method = FCP_PWWN_BINDING;\n\n\trc = bfad_hal_mem_alloc(bfad);\n\tif (rc != BFA_STATUS_OK) {\n\t\tprintk(KERN_WARNING \"bfad%d bfad_hal_mem_alloc failure\\n\",\n\t\t       bfad->inst_no);\n\t\tprintk(KERN_WARNING\n\t\t\t\"Not enough memory to attach all QLogic BR-series HBA ports. System may need more memory.\\n\");\n\t\treturn BFA_STATUS_FAILED;\n\t}\n\n\tbfad->bfa.trcmod = bfad->trcmod;\n\tbfad->bfa.plog = &bfad->plog_buf;\n\tbfa_plog_init(&bfad->plog_buf);\n\tbfa_plog_str(&bfad->plog_buf, BFA_PL_MID_DRVR, BFA_PL_EID_DRIVER_START,\n\t\t     0, \"Driver Attach\");\n\n\tbfa_attach(&bfad->bfa, bfad, &bfad->ioc_cfg, &bfad->meminfo,\n\t\t   &bfad->hal_pcidev);\n\n\t \n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tbfad->bfa_fcs.trcmod = bfad->trcmod;\n\tbfa_fcs_attach(&bfad->bfa_fcs, &bfad->bfa, bfad, BFA_FALSE);\n\tbfad->bfa_fcs.fdmi_enabled = fdmi_enable;\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\tbfad->bfad_flags |= BFAD_DRV_INIT_DONE;\n\n\treturn BFA_STATUS_OK;\n}\n\nvoid\nbfad_drv_uninit(struct bfad_s *bfad)\n{\n\tunsigned long   flags;\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tinit_completion(&bfad->comp);\n\tbfa_iocfc_stop(&bfad->bfa);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\twait_for_completion(&bfad->comp);\n\n\tdel_timer_sync(&bfad->hal_tmo);\n\tbfa_isr_disable(&bfad->bfa);\n\tbfa_detach(&bfad->bfa);\n\tbfad_remove_intr(bfad);\n\tbfad_hal_mem_release(bfad);\n\n\tbfad->bfad_flags &= ~BFAD_DRV_INIT_DONE;\n}\n\nvoid\nbfad_drv_start(struct bfad_s *bfad)\n{\n\tunsigned long\tflags;\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tbfa_iocfc_start(&bfad->bfa);\n\tbfa_fcs_pbc_vport_init(&bfad->bfa_fcs);\n\tbfa_fcs_fabric_modstart(&bfad->bfa_fcs);\n\tbfad->bfad_flags |= BFAD_HAL_START_DONE;\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\tif (bfad->im)\n\t\tflush_workqueue(bfad->im->drv_workq);\n}\n\nvoid\nbfad_fcs_stop(struct bfad_s *bfad)\n{\n\tunsigned long\tflags;\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tinit_completion(&bfad->comp);\n\tbfad->pport.flags |= BFAD_PORT_DELETE;\n\tbfa_fcs_exit(&bfad->bfa_fcs);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\twait_for_completion(&bfad->comp);\n\n\tbfa_sm_send_event(bfad, BFAD_E_FCS_EXIT_COMP);\n}\n\nvoid\nbfad_stop(struct bfad_s *bfad)\n{\n\tunsigned long\tflags;\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tinit_completion(&bfad->comp);\n\tbfa_iocfc_stop(&bfad->bfa);\n\tbfad->bfad_flags &= ~BFAD_HAL_START_DONE;\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\twait_for_completion(&bfad->comp);\n\n\tbfa_sm_send_event(bfad, BFAD_E_EXIT_COMP);\n}\n\nbfa_status_t\nbfad_cfg_pport(struct bfad_s *bfad, enum bfa_lport_role role)\n{\n\tint\t\trc = BFA_STATUS_OK;\n\n\t \n\tif ((supported_fc4s & BFA_LPORT_ROLE_FCP_IM) &&\n\t    (role & BFA_LPORT_ROLE_FCP_IM)) {\n\t\tif (bfad->pport.im_port == NULL) {\n\t\t\trc = BFA_STATUS_FAILED;\n\t\t\tgoto out;\n\t\t}\n\n\t\trc = bfad_im_scsi_host_alloc(bfad, bfad->pport.im_port,\n\t\t\t\t\t\t&bfad->pcidev->dev);\n\t\tif (rc != BFA_STATUS_OK)\n\t\t\tgoto out;\n\n\t\tbfad->pport.roles |= BFA_LPORT_ROLE_FCP_IM;\n\t}\n\n\tbfad->bfad_flags |= BFAD_CFG_PPORT_DONE;\n\nout:\n\treturn rc;\n}\n\nvoid\nbfad_uncfg_pport(struct bfad_s *bfad)\n{\n\tif ((supported_fc4s & BFA_LPORT_ROLE_FCP_IM) &&\n\t    (bfad->pport.roles & BFA_LPORT_ROLE_FCP_IM)) {\n\t\tbfad_im_scsi_host_free(bfad, bfad->pport.im_port);\n\t\tbfad_im_port_clean(bfad->pport.im_port);\n\t\tkfree(bfad->pport.im_port);\n\t\tbfad->pport.roles &= ~BFA_LPORT_ROLE_FCP_IM;\n\t}\n\n\tbfad->bfad_flags &= ~BFAD_CFG_PPORT_DONE;\n}\n\nbfa_status_t\nbfad_start_ops(struct bfad_s *bfad) {\n\n\tint\tretval;\n\tunsigned long\tflags;\n\tstruct bfad_vport_s *vport, *vport_new;\n\tstruct bfa_fcs_driver_info_s driver_info;\n\n\t \n\tif (max_xfer_size < BFAD_MIN_SECTORS >> 1)\n\t\tmax_xfer_size = BFAD_MIN_SECTORS >> 1;\n\tif (max_xfer_size > BFAD_MAX_SECTORS >> 1)\n\t\tmax_xfer_size = BFAD_MAX_SECTORS >> 1;\n\n\t \n\tmemset(&driver_info, 0, sizeof(driver_info));\n\tstrscpy(driver_info.version, BFAD_DRIVER_VERSION,\n\t\tsizeof(driver_info.version));\n\tif (host_name)\n\t\tstrscpy(driver_info.host_machine_name, host_name,\n\t\t\tsizeof(driver_info.host_machine_name));\n\tif (os_name)\n\t\tstrscpy(driver_info.host_os_name, os_name,\n\t\t\tsizeof(driver_info.host_os_name));\n\tif (os_patch)\n\t\tstrscpy(driver_info.host_os_patch, os_patch,\n\t\t\tsizeof(driver_info.host_os_patch));\n\n\tstrscpy(driver_info.os_device_name, bfad->pci_name,\n\t\tsizeof(driver_info.os_device_name));\n\n\t \n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tbfa_fcs_driver_info_init(&bfad->bfa_fcs, &driver_info);\n\n\tif (bfad->bfad_flags & BFAD_CFG_PPORT_DONE)\n\t\tbfa_fcs_update_cfg(&bfad->bfa_fcs);\n\telse\n\t\tbfa_fcs_init(&bfad->bfa_fcs);\n\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\tif (!(bfad->bfad_flags & BFAD_CFG_PPORT_DONE)) {\n\t\tretval = bfad_cfg_pport(bfad, BFA_LPORT_ROLE_FCP_IM);\n\t\tif (retval != BFA_STATUS_OK)\n\t\t\treturn BFA_STATUS_FAILED;\n\t}\n\n\t \n\tbfad_fc_host_init(bfad->pport.im_port);\n\n\t \n\tretval = bfad_im_probe(bfad);\n\tif (retval != BFA_STATUS_OK) {\n\t\tprintk(KERN_WARNING \"bfad_im_probe failed\\n\");\n\t\tif (bfa_sm_cmp_state(bfad, bfad_sm_initializing))\n\t\t\tbfa_sm_set_state(bfad, bfad_sm_failed);\n\t\treturn BFA_STATUS_FAILED;\n\t} else\n\t\tbfad->bfad_flags |= BFAD_FC4_PROBE_DONE;\n\n\tbfad_drv_start(bfad);\n\n\t \n\tlist_for_each_entry_safe(vport, vport_new, &bfad->pbc_vport_list,\n\t\t\t\tlist_entry) {\n\t\tstruct fc_vport_identifiers vid;\n\t\tstruct fc_vport *fc_vport;\n\t\tchar pwwn_buf[BFA_STRING_32];\n\n\t\tmemset(&vid, 0, sizeof(vid));\n\t\tvid.roles = FC_PORT_ROLE_FCP_INITIATOR;\n\t\tvid.vport_type = FC_PORTTYPE_NPIV;\n\t\tvid.disable = false;\n\t\tvid.node_name = wwn_to_u64((u8 *)\n\t\t\t\t(&((vport->fcs_vport).lport.port_cfg.nwwn)));\n\t\tvid.port_name = wwn_to_u64((u8 *)\n\t\t\t\t(&((vport->fcs_vport).lport.port_cfg.pwwn)));\n\t\tfc_vport = fc_vport_create(bfad->pport.im_port->shost, 0, &vid);\n\t\tif (!fc_vport) {\n\t\t\twwn2str(pwwn_buf, vid.port_name);\n\t\t\tprintk(KERN_WARNING \"bfad%d: failed to create pbc vport\"\n\t\t\t\t\" %s\\n\", bfad->inst_no, pwwn_buf);\n\t\t}\n\t\tlist_del(&vport->list_entry);\n\t\tkfree(vport);\n\t}\n\n\t \n\tif (bfa_linkup_delay < 0) {\n\t\tbfa_linkup_delay = bfad_get_linkup_delay(bfad);\n\t\tbfad_rport_online_wait(bfad);\n\t\tbfa_linkup_delay = -1;\n\t} else\n\t\tbfad_rport_online_wait(bfad);\n\n\tBFA_LOG(KERN_INFO, bfad, bfa_log_level, \"bfa device claimed\\n\");\n\n\treturn BFA_STATUS_OK;\n}\n\nint\nbfad_worker(void *ptr)\n{\n\tstruct bfad_s *bfad = ptr;\n\tunsigned long flags;\n\n\tif (kthread_should_stop())\n\t\treturn 0;\n\n\t \n\tbfa_sm_send_event(bfad, BFAD_E_INIT_SUCCESS);\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tbfad->bfad_tsk = NULL;\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\treturn 0;\n}\n\n \nirqreturn_t\nbfad_intx(int irq, void *dev_id)\n{\n\tstruct bfad_s\t*bfad = dev_id;\n\tstruct list_head\tdoneq;\n\tunsigned long\tflags;\n\tbfa_boolean_t rc;\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\trc = bfa_intx(&bfad->bfa);\n\tif (!rc) {\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\t\treturn IRQ_NONE;\n\t}\n\n\tbfa_comp_deq(&bfad->bfa, &doneq);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\tif (!list_empty(&doneq)) {\n\t\tbfa_comp_process(&bfad->bfa, &doneq);\n\n\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\tbfa_comp_free(&bfad->bfa, &doneq);\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\t}\n\n\treturn IRQ_HANDLED;\n\n}\n\nstatic irqreturn_t\nbfad_msix(int irq, void *dev_id)\n{\n\tstruct bfad_msix_s *vec = dev_id;\n\tstruct bfad_s *bfad = vec->bfad;\n\tstruct list_head doneq;\n\tunsigned long   flags;\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\n\tbfa_msix(&bfad->bfa, vec->msix.entry);\n\tbfa_comp_deq(&bfad->bfa, &doneq);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\tif (!list_empty(&doneq)) {\n\t\tbfa_comp_process(&bfad->bfa, &doneq);\n\n\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\tbfa_comp_free(&bfad->bfa, &doneq);\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void\nbfad_init_msix_entry(struct bfad_s *bfad, struct msix_entry *msix_entries,\n\t\t\t int mask, int max_bit)\n{\n\tint\ti;\n\tint\tmatch = 0x00000001;\n\n\tfor (i = 0, bfad->nvec = 0; i < MAX_MSIX_ENTRY; i++) {\n\t\tif (mask & match) {\n\t\t\tbfad->msix_tab[bfad->nvec].msix.entry = i;\n\t\t\tbfad->msix_tab[bfad->nvec].bfad = bfad;\n\t\t\tmsix_entries[bfad->nvec].entry = i;\n\t\t\tbfad->nvec++;\n\t\t}\n\n\t\tmatch <<= 1;\n\t}\n\n}\n\nint\nbfad_install_msix_handler(struct bfad_s *bfad)\n{\n\tint i, error = 0;\n\n\tfor (i = 0; i < bfad->nvec; i++) {\n\t\tsprintf(bfad->msix_tab[i].name, \"bfa-%s-%s\",\n\t\t\t\tbfad->pci_name,\n\t\t\t\t((bfa_asic_id_cb(bfad->hal_pcidev.device_id)) ?\n\t\t\t\tmsix_name_cb[i] : msix_name_ct[i]));\n\n\t\terror = request_irq(bfad->msix_tab[i].msix.vector,\n\t\t\t\t    (irq_handler_t) bfad_msix, 0,\n\t\t\t\t    bfad->msix_tab[i].name, &bfad->msix_tab[i]);\n\t\tbfa_trc(bfad, i);\n\t\tbfa_trc(bfad, bfad->msix_tab[i].msix.vector);\n\t\tif (error) {\n\t\t\tint\tj;\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tfree_irq(bfad->msix_tab[j].msix.vector,\n\t\t\t\t\t\t&bfad->msix_tab[j]);\n\n\t\t\tbfad->bfad_flags &= ~BFAD_MSIX_ON;\n\t\t\tpci_disable_msix(bfad->pcidev);\n\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nint\nbfad_setup_intr(struct bfad_s *bfad)\n{\n\tint error;\n\tu32 mask = 0, i, num_bit = 0, max_bit = 0;\n\tstruct msix_entry msix_entries[MAX_MSIX_ENTRY];\n\tstruct pci_dev *pdev = bfad->pcidev;\n\tu16\treg;\n\n\t \n\tbfa_msix_getvecs(&bfad->bfa, &mask, &num_bit, &max_bit);\n\n\t \n\tbfad_init_msix_entry(bfad, msix_entries, mask, max_bit);\n\n\tif ((bfa_asic_id_ctc(pdev->device) && !msix_disable_ct) ||\n\t   (bfa_asic_id_cb(pdev->device) && !msix_disable_cb)) {\n\n\t\terror = pci_enable_msix_exact(bfad->pcidev,\n\t\t\t\t\t      msix_entries, bfad->nvec);\n\t\t \n\t\tif (error == -ENOSPC && bfa_asic_id_ctc(pdev->device)) {\n\t\t\tprintk(KERN_WARNING \"bfa %s: trying one msix \"\n\t\t\t       \"vector failed to allocate %d[%d]\\n\",\n\t\t\t       bfad->pci_name, bfad->nvec, error);\n\t\t\tbfad->nvec = 1;\n\t\t\terror = pci_enable_msix_exact(bfad->pcidev,\n\t\t\t\t\t\t      msix_entries, 1);\n\t\t}\n\n\t\tif (error) {\n\t\t\tprintk(KERN_WARNING \"bfad%d: \"\n\t\t\t       \"pci_enable_msix_exact failed (%d), \"\n\t\t\t       \"use line based.\\n\",\n\t\t\t\tbfad->inst_no, error);\n\t\t\tgoto line_based;\n\t\t}\n\n\t\t \n\t\tpci_read_config_word(pdev, PCI_COMMAND, &reg);\n\n\t\tif (!(reg & PCI_COMMAND_INTX_DISABLE))\n\t\t\tpci_write_config_word(pdev, PCI_COMMAND,\n\t\t\t\treg | PCI_COMMAND_INTX_DISABLE);\n\n\t\t \n\t\tfor (i = 0; i < bfad->nvec; i++) {\n\t\t\tbfa_trc(bfad, msix_entries[i].vector);\n\t\t\tbfad->msix_tab[i].msix.vector = msix_entries[i].vector;\n\t\t}\n\n\t\tbfa_msix_init(&bfad->bfa, bfad->nvec);\n\n\t\tbfad->bfad_flags |= BFAD_MSIX_ON;\n\n\t\treturn 0;\n\t}\n\nline_based:\n\terror = request_irq(bfad->pcidev->irq, (irq_handler_t)bfad_intx,\n\t\t\t    BFAD_IRQ_FLAGS, BFAD_DRIVER_NAME, bfad);\n\tif (error)\n\t\treturn error;\n\n\tbfad->bfad_flags |= BFAD_INTX_ON;\n\n\treturn 0;\n}\n\nvoid\nbfad_remove_intr(struct bfad_s *bfad)\n{\n\tint\ti;\n\n\tif (bfad->bfad_flags & BFAD_MSIX_ON) {\n\t\tfor (i = 0; i < bfad->nvec; i++)\n\t\t\tfree_irq(bfad->msix_tab[i].msix.vector,\n\t\t\t\t\t&bfad->msix_tab[i]);\n\n\t\tpci_disable_msix(bfad->pcidev);\n\t\tbfad->bfad_flags &= ~BFAD_MSIX_ON;\n\t} else if (bfad->bfad_flags & BFAD_INTX_ON) {\n\t\tfree_irq(bfad->pcidev->irq, bfad);\n\t}\n}\n\n \nint\nbfad_pci_probe(struct pci_dev *pdev, const struct pci_device_id *pid)\n{\n\tstruct bfad_s\t*bfad;\n\tint\t\terror = -ENODEV, retval, i;\n\n\t \n\tif ((pdev->device == BFA_PCI_DEVICE_ID_FC_8G1P) &&\n\t\t(PCI_FUNC(pdev->devfn) != 0))\n\t\treturn -ENODEV;\n\n\tbfad = kzalloc(sizeof(struct bfad_s), GFP_KERNEL);\n\tif (!bfad) {\n\t\terror = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tbfad->trcmod = kzalloc(sizeof(struct bfa_trc_mod_s), GFP_KERNEL);\n\tif (!bfad->trcmod) {\n\t\tprintk(KERN_WARNING \"Error alloc trace buffer!\\n\");\n\t\terror = -ENOMEM;\n\t\tgoto out_alloc_trace_failure;\n\t}\n\n\t \n\tbfa_trc_init(bfad->trcmod);\n\tbfa_trc(bfad, bfad_inst);\n\n\t \n\tINIT_LIST_HEAD(&bfad->free_aen_q);\n\tINIT_LIST_HEAD(&bfad->active_aen_q);\n\tfor (i = 0; i < BFA_AEN_MAX_ENTRY; i++)\n\t\tlist_add_tail(&bfad->aen_list[i].qe, &bfad->free_aen_q);\n\n\tif (!(bfad_load_fwimg(pdev))) {\n\t\tkfree(bfad->trcmod);\n\t\tgoto out_alloc_trace_failure;\n\t}\n\n\tretval = bfad_pci_init(pdev, bfad);\n\tif (retval) {\n\t\tprintk(KERN_WARNING \"bfad_pci_init failure!\\n\");\n\t\terror = retval;\n\t\tgoto out_pci_init_failure;\n\t}\n\n\tmutex_lock(&bfad_mutex);\n\tbfad->inst_no = bfad_inst++;\n\tlist_add_tail(&bfad->list_entry, &bfad_list);\n\tmutex_unlock(&bfad_mutex);\n\n\t \n\tbfa_sm_set_state(bfad, bfad_sm_uninit);\n\n\tspin_lock_init(&bfad->bfad_lock);\n\tspin_lock_init(&bfad->bfad_aen_spinlock);\n\n\tpci_set_drvdata(pdev, bfad);\n\n\tbfad->ref_count = 0;\n\tbfad->pport.bfad = bfad;\n\tINIT_LIST_HEAD(&bfad->pbc_vport_list);\n\tINIT_LIST_HEAD(&bfad->vport_list);\n\n\t \n\tif (bfa_debugfs_enable)\n\t\tbfad_debugfs_init(&bfad->pport);\n\n\tretval = bfad_drv_init(bfad);\n\tif (retval != BFA_STATUS_OK)\n\t\tgoto out_drv_init_failure;\n\n\tbfa_sm_send_event(bfad, BFAD_E_CREATE);\n\n\tif (bfa_sm_cmp_state(bfad, bfad_sm_uninit))\n\t\tgoto out_bfad_sm_failure;\n\n\treturn 0;\n\nout_bfad_sm_failure:\n\tbfad_hal_mem_release(bfad);\nout_drv_init_failure:\n\t \n\tkfree(bfad->regdata);\n\tbfad_debugfs_exit(&bfad->pport);\n\tmutex_lock(&bfad_mutex);\n\tbfad_inst--;\n\tlist_del(&bfad->list_entry);\n\tmutex_unlock(&bfad_mutex);\n\tbfad_pci_uninit(pdev, bfad);\nout_pci_init_failure:\n\tkfree(bfad->trcmod);\nout_alloc_trace_failure:\n\tkfree(bfad);\nout:\n\treturn error;\n}\n\n \nvoid\nbfad_pci_remove(struct pci_dev *pdev)\n{\n\tstruct bfad_s\t      *bfad = pci_get_drvdata(pdev);\n\tunsigned long\tflags;\n\n\tbfa_trc(bfad, bfad->inst_no);\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tif (bfad->bfad_tsk != NULL) {\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\t\tkthread_stop(bfad->bfad_tsk);\n\t} else {\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\t}\n\n\t \n\tbfa_sm_send_event(bfad, BFAD_E_STOP);\n\n\t \n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tbfa_detach(&bfad->bfa);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\tbfad_hal_mem_release(bfad);\n\n\t \n\tkfree(bfad->regdata);\n\tbfad_debugfs_exit(&bfad->pport);\n\n\t \n\tmutex_lock(&bfad_mutex);\n\tbfad_inst--;\n\tlist_del(&bfad->list_entry);\n\tmutex_unlock(&bfad_mutex);\n\tbfad_pci_uninit(pdev, bfad);\n\n\tkfree(bfad->trcmod);\n\tkfree(bfad);\n}\n\n \nstatic pci_ers_result_t\nbfad_pci_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\n{\n\tstruct bfad_s *bfad = pci_get_drvdata(pdev);\n\tunsigned long\tflags;\n\tpci_ers_result_t ret = PCI_ERS_RESULT_NONE;\n\n\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t   \"error detected state: %d - flags: 0x%x\\n\",\n\t\t   state, bfad->bfad_flags);\n\n\tswitch (state) {\n\tcase pci_channel_io_normal:  \n\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\tbfad->bfad_flags &= ~BFAD_EEH_BUSY;\n\t\t \n\t\tbfa_ioc_suspend(&bfad->bfa.ioc);\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\t\tdel_timer_sync(&bfad->hal_tmo);\n\t\tret = PCI_ERS_RESULT_CAN_RECOVER;\n\t\tbreak;\n\tcase pci_channel_io_frozen:  \n\t\tinit_completion(&bfad->comp);\n\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\tbfad->bfad_flags |= BFAD_EEH_BUSY;\n\t\t \n\t\tbfa_ioc_suspend(&bfad->bfa.ioc);\n\t\tbfa_fcs_stop(&bfad->bfa_fcs);\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\t\twait_for_completion(&bfad->comp);\n\n\t\tbfad_remove_intr(bfad);\n\t\tdel_timer_sync(&bfad->hal_tmo);\n\t\tpci_disable_device(pdev);\n\t\tret = PCI_ERS_RESULT_NEED_RESET;\n\t\tbreak;\n\tcase pci_channel_io_perm_failure:  \n\t\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\t\tbfad->bfad_flags |= BFAD_EEH_BUSY |\n\t\t\t\t    BFAD_EEH_PCI_CHANNEL_IO_PERM_FAILURE;\n\t\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\t\t \n\t\tret = PCI_ERS_RESULT_DISCONNECT;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t}\n\n\treturn ret;\n}\n\nstatic int restart_bfa(struct bfad_s *bfad)\n{\n\tunsigned long flags;\n\tstruct pci_dev *pdev = bfad->pcidev;\n\n\tbfa_attach(&bfad->bfa, bfad, &bfad->ioc_cfg,\n\t\t   &bfad->meminfo, &bfad->hal_pcidev);\n\n\t \n\tif (bfad_setup_intr(bfad)) {\n\t\tdev_printk(KERN_WARNING, &pdev->dev,\n\t\t\t   \"%s: bfad_setup_intr failed\\n\", bfad->pci_name);\n\t\tbfa_sm_send_event(bfad, BFAD_E_INIT_FAILED);\n\t\treturn -1;\n\t}\n\n\tinit_completion(&bfad->comp);\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tbfa_iocfc_init(&bfad->bfa);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\n\t \n\tif ((bfad->bfad_flags & BFAD_MSIX_ON) &&\n\t    bfad_install_msix_handler(bfad))\n\t\tdev_printk(KERN_WARNING, &pdev->dev,\n\t\t\t   \"%s: install_msix failed.\\n\", bfad->pci_name);\n\n\tbfad_init_timer(bfad);\n\twait_for_completion(&bfad->comp);\n\tbfad_drv_start(bfad);\n\n\treturn 0;\n}\n\n \nstatic pci_ers_result_t\nbfad_pci_slot_reset(struct pci_dev *pdev)\n{\n\tstruct bfad_s *bfad = pci_get_drvdata(pdev);\n\tu8 byte;\n\tint rc;\n\n\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t   \"bfad_pci_slot_reset flags: 0x%x\\n\", bfad->bfad_flags);\n\n\tif (pci_enable_device(pdev)) {\n\t\tdev_printk(KERN_ERR, &pdev->dev, \"Cannot re-enable \"\n\t\t\t   \"PCI device after reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\tpci_restore_state(pdev);\n\n\t \n\tpci_read_config_byte(pdev, 0x68, &byte);\n\tif (byte == 0xff) {\n\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t   \"slot_reset failed ... got another PCI error !\\n\");\n\t\tgoto out_disable_device;\n\t}\n\n\tpci_save_state(pdev);\n\tpci_set_master(pdev);\n\n\trc = dma_set_mask_and_coherent(&bfad->pcidev->dev, DMA_BIT_MASK(64));\n\tif (rc)\n\t\tgoto out_disable_device;\n\n\tif (restart_bfa(bfad) == -1)\n\t\tgoto out_disable_device;\n\n\tdev_printk(KERN_WARNING, &pdev->dev,\n\t\t   \"slot_reset completed  flags: 0x%x!\\n\", bfad->bfad_flags);\n\n\treturn PCI_ERS_RESULT_RECOVERED;\n\nout_disable_device:\n\tpci_disable_device(pdev);\n\treturn PCI_ERS_RESULT_DISCONNECT;\n}\n\nstatic pci_ers_result_t\nbfad_pci_mmio_enabled(struct pci_dev *pdev)\n{\n\tunsigned long\tflags;\n\tstruct bfad_s *bfad = pci_get_drvdata(pdev);\n\n\tdev_printk(KERN_INFO, &pdev->dev, \"mmio_enabled\\n\");\n\n\t \n\tbfa_ioc_debug_save_ftrc(&bfad->bfa.ioc);\n\n\t \n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tinit_completion(&bfad->comp);\n\tbfa_fcs_stop(&bfad->bfa_fcs);\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n\twait_for_completion(&bfad->comp);\n\n\tbfad_remove_intr(bfad);\n\tdel_timer_sync(&bfad->hal_tmo);\n\tpci_disable_device(pdev);\n\n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\n\nstatic void\nbfad_pci_resume(struct pci_dev *pdev)\n{\n\tunsigned long\tflags;\n\tstruct bfad_s *bfad = pci_get_drvdata(pdev);\n\n\tdev_printk(KERN_WARNING, &pdev->dev, \"resume\\n\");\n\n\t \n\tbfad_rport_online_wait(bfad);\n\n\tspin_lock_irqsave(&bfad->bfad_lock, flags);\n\tbfad->bfad_flags &= ~BFAD_EEH_BUSY;\n\tspin_unlock_irqrestore(&bfad->bfad_lock, flags);\n}\n\nstruct pci_device_id bfad_id_table[] = {\n\t{\n\t\t.vendor = BFA_PCI_VENDOR_ID_BROCADE,\n\t\t.device = BFA_PCI_DEVICE_ID_FC_8G2P,\n\t\t.subvendor = PCI_ANY_ID,\n\t\t.subdevice = PCI_ANY_ID,\n\t},\n\t{\n\t\t.vendor = BFA_PCI_VENDOR_ID_BROCADE,\n\t\t.device = BFA_PCI_DEVICE_ID_FC_8G1P,\n\t\t.subvendor = PCI_ANY_ID,\n\t\t.subdevice = PCI_ANY_ID,\n\t},\n\t{\n\t\t.vendor = BFA_PCI_VENDOR_ID_BROCADE,\n\t\t.device = BFA_PCI_DEVICE_ID_CT,\n\t\t.subvendor = PCI_ANY_ID,\n\t\t.subdevice = PCI_ANY_ID,\n\t\t.class = (PCI_CLASS_SERIAL_FIBER << 8),\n\t\t.class_mask = ~0,\n\t},\n\t{\n\t\t.vendor = BFA_PCI_VENDOR_ID_BROCADE,\n\t\t.device = BFA_PCI_DEVICE_ID_CT_FC,\n\t\t.subvendor = PCI_ANY_ID,\n\t\t.subdevice = PCI_ANY_ID,\n\t\t.class = (PCI_CLASS_SERIAL_FIBER << 8),\n\t\t.class_mask = ~0,\n\t},\n\t{\n\t\t.vendor = BFA_PCI_VENDOR_ID_BROCADE,\n\t\t.device = BFA_PCI_DEVICE_ID_CT2,\n\t\t.subvendor = PCI_ANY_ID,\n\t\t.subdevice = PCI_ANY_ID,\n\t\t.class = (PCI_CLASS_SERIAL_FIBER << 8),\n\t\t.class_mask = ~0,\n\t},\n\n\t{\n\t\t.vendor = BFA_PCI_VENDOR_ID_BROCADE,\n\t\t.device = BFA_PCI_DEVICE_ID_CT2_QUAD,\n\t\t.subvendor = PCI_ANY_ID,\n\t\t.subdevice = PCI_ANY_ID,\n\t\t.class = (PCI_CLASS_SERIAL_FIBER << 8),\n\t\t.class_mask = ~0,\n\t},\n\t{0, 0},\n};\n\nMODULE_DEVICE_TABLE(pci, bfad_id_table);\n\n \nstatic struct pci_error_handlers bfad_err_handler = {\n\t.error_detected = bfad_pci_error_detected,\n\t.slot_reset = bfad_pci_slot_reset,\n\t.mmio_enabled = bfad_pci_mmio_enabled,\n\t.resume = bfad_pci_resume,\n};\n\nstatic struct pci_driver bfad_pci_driver = {\n\t.name = BFAD_DRIVER_NAME,\n\t.id_table = bfad_id_table,\n\t.probe = bfad_pci_probe,\n\t.remove = bfad_pci_remove,\n\t.err_handler = &bfad_err_handler,\n};\n\n \nstatic int __init\nbfad_init(void)\n{\n\tint\t\terror = 0;\n\n\tpr_info(\"QLogic BR-series BFA FC/FCOE SCSI driver - version: %s\\n\",\n\t\t\tBFAD_DRIVER_VERSION);\n\n\tif (num_sgpgs > 0)\n\t\tnum_sgpgs_parm = num_sgpgs;\n\n\terror = bfad_im_module_init();\n\tif (error) {\n\t\terror = -ENOMEM;\n\t\tprintk(KERN_WARNING \"bfad_im_module_init failure\\n\");\n\t\tgoto ext;\n\t}\n\n\tif (strcmp(FCPI_NAME, \" fcpim\") == 0)\n\t\tsupported_fc4s |= BFA_LPORT_ROLE_FCP_IM;\n\n\tbfa_auto_recover = ioc_auto_recover;\n\tbfa_fcs_rport_set_del_timeout(rport_del_timeout);\n\tbfa_fcs_rport_set_max_logins(max_rport_logins);\n\n\terror = pci_register_driver(&bfad_pci_driver);\n\tif (error) {\n\t\tprintk(KERN_WARNING \"pci_register_driver failure\\n\");\n\t\tgoto ext;\n\t}\n\n\treturn 0;\n\next:\n\tbfad_im_module_exit();\n\treturn error;\n}\n\n \nstatic void __exit\nbfad_exit(void)\n{\n\tpci_unregister_driver(&bfad_pci_driver);\n\tbfad_im_module_exit();\n\tbfad_free_fwimg();\n}\n\n \nstatic void\nbfad_read_firmware(struct pci_dev *pdev, u32 **bfi_image,\n\t\tu32 *bfi_image_size, char *fw_name)\n{\n\tconst struct firmware *fw;\n\n\tif (request_firmware(&fw, fw_name, &pdev->dev)) {\n\t\tprintk(KERN_ALERT \"Can't locate firmware %s\\n\", fw_name);\n\t\t*bfi_image = NULL;\n\t\tgoto out;\n\t}\n\n\t*bfi_image = vmalloc(fw->size);\n\tif (NULL == *bfi_image) {\n\t\tprintk(KERN_ALERT \"Fail to allocate buffer for fw image \"\n\t\t\t\"size=%x!\\n\", (u32) fw->size);\n\t\tgoto out;\n\t}\n\n\tmemcpy(*bfi_image, fw->data, fw->size);\n\t*bfi_image_size = fw->size/sizeof(u32);\nout:\n\trelease_firmware(fw);\n}\n\nstatic u32 *\nbfad_load_fwimg(struct pci_dev *pdev)\n{\n\tif (bfa_asic_id_ct2(pdev->device)) {\n\t\tif (bfi_image_ct2_size == 0)\n\t\t\tbfad_read_firmware(pdev, &bfi_image_ct2,\n\t\t\t\t&bfi_image_ct2_size, BFAD_FW_FILE_CT2);\n\t\treturn bfi_image_ct2;\n\t} else if (bfa_asic_id_ct(pdev->device)) {\n\t\tif (bfi_image_ct_size == 0)\n\t\t\tbfad_read_firmware(pdev, &bfi_image_ct,\n\t\t\t\t&bfi_image_ct_size, BFAD_FW_FILE_CT);\n\t\treturn bfi_image_ct;\n\t} else if (bfa_asic_id_cb(pdev->device)) {\n\t\tif (bfi_image_cb_size == 0)\n\t\t\tbfad_read_firmware(pdev, &bfi_image_cb,\n\t\t\t\t&bfi_image_cb_size, BFAD_FW_FILE_CB);\n\t\treturn bfi_image_cb;\n\t}\n\n\treturn NULL;\n}\n\nstatic void\nbfad_free_fwimg(void)\n{\n\tif (bfi_image_ct2_size && bfi_image_ct2)\n\t\tvfree(bfi_image_ct2);\n\tif (bfi_image_ct_size && bfi_image_ct)\n\t\tvfree(bfi_image_ct);\n\tif (bfi_image_cb_size && bfi_image_cb)\n\t\tvfree(bfi_image_cb);\n}\n\nmodule_init(bfad_init);\nmodule_exit(bfad_exit);\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"QLogic BR-series Fibre Channel HBA Driver\" BFAD_PROTO_NAME);\nMODULE_AUTHOR(\"QLogic Corporation\");\nMODULE_VERSION(BFAD_DRIVER_VERSION);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}