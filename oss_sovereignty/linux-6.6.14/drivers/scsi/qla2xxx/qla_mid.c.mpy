{
  "module_name": "qla_mid.c",
  "hash_id": "83fbdf642c07adfc8945f56b25b16a120bb2aa8e12b6a99e3d6c9f2f7d47b748",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/qla2xxx/qla_mid.c",
  "human_readable_source": "\n \n#include \"qla_def.h\"\n#include \"qla_gbl.h\"\n#include \"qla_target.h\"\n\n#include <linux/moduleparam.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n\n#include <scsi/scsi_tcq.h>\n#include <scsi/scsicam.h>\n#include <linux/delay.h>\n\nvoid\nqla2x00_vp_stop_timer(scsi_qla_host_t *vha)\n{\n\tif (vha->vp_idx && vha->timer_active) {\n\t\tdel_timer_sync(&vha->timer);\n\t\tvha->timer_active = 0;\n\t}\n}\n\nstatic uint32_t\nqla24xx_allocate_vp_id(scsi_qla_host_t *vha)\n{\n\tuint32_t vp_id;\n\tstruct qla_hw_data *ha = vha->hw;\n\tunsigned long flags;\n\n\t \n\tmutex_lock(&ha->vport_lock);\n\tvp_id = find_first_zero_bit(ha->vp_idx_map, ha->max_npiv_vports + 1);\n\tif (vp_id > ha->max_npiv_vports) {\n\t\tql_dbg(ql_dbg_vport, vha, 0xa000,\n\t\t    \"vp_id %d is bigger than max-supported %d.\\n\",\n\t\t    vp_id, ha->max_npiv_vports);\n\t\tmutex_unlock(&ha->vport_lock);\n\t\treturn vp_id;\n\t}\n\n\tset_bit(vp_id, ha->vp_idx_map);\n\tha->num_vhosts++;\n\tvha->vp_idx = vp_id;\n\n\tspin_lock_irqsave(&ha->vport_slock, flags);\n\tlist_add_tail(&vha->list, &ha->vp_list);\n\tspin_unlock_irqrestore(&ha->vport_slock, flags);\n\n\tspin_lock_irqsave(&ha->hardware_lock, flags);\n\tqla_update_vp_map(vha, SET_VP_IDX);\n\tspin_unlock_irqrestore(&ha->hardware_lock, flags);\n\n\tmutex_unlock(&ha->vport_lock);\n\treturn vp_id;\n}\n\nvoid\nqla24xx_deallocate_vp_id(scsi_qla_host_t *vha)\n{\n\tuint16_t vp_id;\n\tstruct qla_hw_data *ha = vha->hw;\n\tunsigned long flags = 0;\n\tu32 i, bailout;\n\n\tmutex_lock(&ha->vport_lock);\n\t \n\tbailout = 0;\n\tfor (i = 0; i < 500; i++) {\n\t\tspin_lock_irqsave(&ha->vport_slock, flags);\n\t\tif (atomic_read(&vha->vref_count) == 0) {\n\t\t\tlist_del(&vha->list);\n\t\t\tqla_update_vp_map(vha, RESET_VP_IDX);\n\t\t\tbailout = 1;\n\t\t}\n\t\tspin_unlock_irqrestore(&ha->vport_slock, flags);\n\n\t\tif (bailout)\n\t\t\tbreak;\n\t\telse\n\t\t\tmsleep(20);\n\t}\n\tif (!bailout) {\n\t\tql_log(ql_log_info, vha, 0xfffa,\n\t\t\t\"vha->vref_count=%u timeout\\n\", vha->vref_count.counter);\n\t\tspin_lock_irqsave(&ha->vport_slock, flags);\n\t\tlist_del(&vha->list);\n\t\tqla_update_vp_map(vha, RESET_VP_IDX);\n\t\tspin_unlock_irqrestore(&ha->vport_slock, flags);\n\t}\n\n\tvp_id = vha->vp_idx;\n\tha->num_vhosts--;\n\tclear_bit(vp_id, ha->vp_idx_map);\n\n\tmutex_unlock(&ha->vport_lock);\n}\n\nstatic scsi_qla_host_t *\nqla24xx_find_vhost_by_name(struct qla_hw_data *ha, uint8_t *port_name)\n{\n\tscsi_qla_host_t *vha;\n\tstruct scsi_qla_host *tvha;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ha->vport_slock, flags);\n\t \n\tlist_for_each_entry_safe(vha, tvha, &ha->vp_list, list) {\n\t\tif (!memcmp(port_name, vha->port_name, WWN_SIZE)) {\n\t\t\tspin_unlock_irqrestore(&ha->vport_slock, flags);\n\t\t\treturn vha;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&ha->vport_slock, flags);\n\treturn NULL;\n}\n\n \nstatic void\nqla2x00_mark_vp_devices_dead(scsi_qla_host_t *vha)\n{\n\t \n\tfc_port_t *fcport;\n\n\tlist_for_each_entry(fcport, &vha->vp_fcports, list) {\n\t\tql_dbg(ql_dbg_vport, vha, 0xa001,\n\t\t    \"Marking port dead, loop_id=0x%04x : %x.\\n\",\n\t\t    fcport->loop_id, fcport->vha->vp_idx);\n\n\t\tqla2x00_mark_device_lost(vha, fcport, 0);\n\t\tqla2x00_set_fcport_state(fcport, FCS_UNCONFIGURED);\n\t}\n}\n\nint\nqla24xx_disable_vp(scsi_qla_host_t *vha)\n{\n\tunsigned long flags;\n\tint ret = QLA_SUCCESS;\n\tfc_port_t *fcport;\n\n\tif (vha->hw->flags.edif_enabled) {\n\t\tif (DBELL_ACTIVE(vha))\n\t\t\tqla2x00_post_aen_work(vha, FCH_EVT_VENDOR_UNIQUE,\n\t\t\t    FCH_EVT_VENDOR_UNIQUE_VPORT_DOWN);\n\t\t \n\t\tqla2x00_wait_for_sess_deletion(vha);\n\t}\n\n\tif (vha->hw->flags.fw_started)\n\t\tret = qla24xx_control_vp(vha, VCE_COMMAND_DISABLE_VPS_LOGO_ALL);\n\n\tatomic_set(&vha->loop_state, LOOP_DOWN);\n\tatomic_set(&vha->loop_down_timer, LOOP_DOWN_TIME);\n\tlist_for_each_entry(fcport, &vha->vp_fcports, list)\n\t\tfcport->logout_on_delete = 0;\n\n\tif (!vha->hw->flags.edif_enabled)\n\t\tqla2x00_wait_for_sess_deletion(vha);\n\n\t \n\tspin_lock_irqsave(&vha->hw->hardware_lock, flags);\n\tqla_update_vp_map(vha, RESET_AL_PA);\n\tspin_unlock_irqrestore(&vha->hw->hardware_lock, flags);\n\n\tqla2x00_mark_vp_devices_dead(vha);\n\tatomic_set(&vha->vp_state, VP_FAILED);\n\tvha->flags.management_server_logged_in = 0;\n\tif (ret == QLA_SUCCESS) {\n\t\tfc_vport_set_state(vha->fc_vport, FC_VPORT_DISABLED);\n\t} else {\n\t\tfc_vport_set_state(vha->fc_vport, FC_VPORT_FAILED);\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\nint\nqla24xx_enable_vp(scsi_qla_host_t *vha)\n{\n\tint ret;\n\tstruct qla_hw_data *ha = vha->hw;\n\tscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\n\n\t \n\tif (atomic_read(&base_vha->loop_state) == LOOP_DOWN  ||\n\t\tatomic_read(&base_vha->loop_state) == LOOP_DEAD ||\n\t\t!(ha->current_topology & ISP_CFG_F)) {\n\t\tvha->vp_err_state =  VP_ERR_PORTDWN;\n\t\tfc_vport_set_state(vha->fc_vport, FC_VPORT_LINKDOWN);\n\t\tql_dbg(ql_dbg_taskm, vha, 0x800b,\n\t\t    \"%s skip enable. loop_state %x topo %x\\n\",\n\t\t    __func__, base_vha->loop_state.counter,\n\t\t    ha->current_topology);\n\n\t\tgoto enable_failed;\n\t}\n\n\t \n\tmutex_lock(&ha->vport_lock);\n\tret = qla24xx_modify_vp_config(vha);\n\tmutex_unlock(&ha->vport_lock);\n\n\tif (ret != QLA_SUCCESS) {\n\t\tfc_vport_set_state(vha->fc_vport, FC_VPORT_FAILED);\n\t\tgoto enable_failed;\n\t}\n\n\tql_dbg(ql_dbg_taskm, vha, 0x801a,\n\t    \"Virtual port with id: %d - Enabled.\\n\", vha->vp_idx);\n\treturn 0;\n\nenable_failed:\n\tql_dbg(ql_dbg_taskm, vha, 0x801b,\n\t    \"Virtual port with id: %d - Disabled.\\n\", vha->vp_idx);\n\treturn 1;\n}\n\nstatic void\nqla24xx_configure_vp(scsi_qla_host_t *vha)\n{\n\tstruct fc_vport *fc_vport;\n\tint ret;\n\n\tfc_vport = vha->fc_vport;\n\n\tql_dbg(ql_dbg_vport, vha, 0xa002,\n\t    \"%s: change request #3.\\n\", __func__);\n\tret = qla2x00_send_change_request(vha, 0x3, vha->vp_idx);\n\tif (ret != QLA_SUCCESS) {\n\t\tql_dbg(ql_dbg_vport, vha, 0xa003, \"Failed to enable \"\n\t\t    \"receiving of RSCN requests: 0x%x.\\n\", ret);\n\t\treturn;\n\t} else {\n\t\t \n\t\tclear_bit(VP_SCR_NEEDED, &vha->vp_flags);\n\t}\n\n\tvha->flags.online = 1;\n\tif (qla24xx_configure_vhba(vha))\n\t\treturn;\n\n\tatomic_set(&vha->vp_state, VP_ACTIVE);\n\tfc_vport_set_state(fc_vport, FC_VPORT_ACTIVE);\n}\n\nvoid\nqla2x00_alert_all_vps(struct rsp_que *rsp, uint16_t *mb)\n{\n\tscsi_qla_host_t *vha, *tvp;\n\tstruct qla_hw_data *ha = rsp->hw;\n\tint i = 0;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ha->vport_slock, flags);\n\tlist_for_each_entry_safe(vha, tvp, &ha->vp_list, list) {\n\t\tif (vha->vp_idx) {\n\t\t\tif (test_bit(VPORT_DELETE, &vha->dpc_flags))\n\t\t\t\tcontinue;\n\n\t\t\tatomic_inc(&vha->vref_count);\n\t\t\tspin_unlock_irqrestore(&ha->vport_slock, flags);\n\n\t\t\tswitch (mb[0]) {\n\t\t\tcase MBA_LIP_OCCURRED:\n\t\t\tcase MBA_LOOP_UP:\n\t\t\tcase MBA_LOOP_DOWN:\n\t\t\tcase MBA_LIP_RESET:\n\t\t\tcase MBA_POINT_TO_POINT:\n\t\t\tcase MBA_CHG_IN_CONNECTION:\n\t\t\t\tql_dbg(ql_dbg_async, vha, 0x5024,\n\t\t\t\t    \"Async_event for VP[%d], mb=0x%x vha=%p.\\n\",\n\t\t\t\t    i, *mb, vha);\n\t\t\t\tqla2x00_async_event(vha, rsp, mb);\n\t\t\t\tbreak;\n\t\t\tcase MBA_PORT_UPDATE:\n\t\t\tcase MBA_RSCN_UPDATE:\n\t\t\t\tif ((mb[3] & 0xff) == vha->vp_idx) {\n\t\t\t\t\tql_dbg(ql_dbg_async, vha, 0x5024,\n\t\t\t\t\t    \"Async_event for VP[%d], mb=0x%x vha=%p\\n\",\n\t\t\t\t\t    i, *mb, vha);\n\t\t\t\t\tqla2x00_async_event(vha, rsp, mb);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tspin_lock_irqsave(&ha->vport_slock, flags);\n\t\t\tatomic_dec(&vha->vref_count);\n\t\t\twake_up(&vha->vref_waitq);\n\t\t}\n\t\ti++;\n\t}\n\tspin_unlock_irqrestore(&ha->vport_slock, flags);\n}\n\nint\nqla2x00_vp_abort_isp(scsi_qla_host_t *vha)\n{\n\tfc_port_t *fcport;\n\n\t \n\tif (!test_bit(ABORT_ISP_ACTIVE, &vha->dpc_flags)) {\n\t\tqla24xx_control_vp(vha, VCE_COMMAND_DISABLE_VPS_LOGO_ALL);\n\t\tlist_for_each_entry(fcport, &vha->vp_fcports, list)\n\t\t\tfcport->logout_on_delete = 0;\n\t}\n\n\t \n\tif (atomic_read(&vha->loop_state) != LOOP_DOWN) {\n\t\tatomic_set(&vha->loop_state, LOOP_DOWN);\n\t\tqla2x00_mark_all_devices_lost(vha);\n\t} else {\n\t\tif (!atomic_read(&vha->loop_down_timer))\n\t\t\tatomic_set(&vha->loop_down_timer, LOOP_DOWN_TIME);\n\t}\n\n\tql_dbg(ql_dbg_taskm, vha, 0x801d,\n\t    \"Scheduling enable of Vport %d.\\n\", vha->vp_idx);\n\n\treturn qla24xx_enable_vp(vha);\n}\n\nstatic int\nqla2x00_do_dpc_vp(scsi_qla_host_t *vha)\n{\n\tstruct qla_hw_data *ha = vha->hw;\n\tscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\n\n\tql_dbg(ql_dbg_dpc + ql_dbg_verbose, vha, 0x4012,\n\t    \"Entering %s vp_flags: 0x%lx.\\n\", __func__, vha->vp_flags);\n\n\t \n\tif (test_bit(VP_CONFIG_OK, &base_vha->vp_flags)) {\n\t\tif (test_and_clear_bit(VP_IDX_ACQUIRED, &vha->vp_flags)) {\n\t\t\t \n\t\t\tql_dbg(ql_dbg_dpc, vha, 0x4014,\n\t\t\t    \"Configure VP scheduled.\\n\");\n\t\t\tqla24xx_configure_vp(vha);\n\t\t\tql_dbg(ql_dbg_dpc, vha, 0x4015,\n\t\t\t    \"Configure VP end.\\n\");\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (test_bit(PROCESS_PUREX_IOCB, &vha->dpc_flags)) {\n\t\tif (atomic_read(&vha->loop_state) == LOOP_READY) {\n\t\t\tqla24xx_process_purex_list(&vha->purex_list);\n\t\t\tclear_bit(PROCESS_PUREX_IOCB, &vha->dpc_flags);\n\t\t}\n\t}\n\n\tif (test_bit(RELOGIN_NEEDED, &vha->dpc_flags) &&\n\t    !test_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags) &&\n\t    atomic_read(&vha->loop_state) != LOOP_DOWN) {\n\n\t\tif (!vha->relogin_jif ||\n\t\t    time_after_eq(jiffies, vha->relogin_jif)) {\n\t\t\tvha->relogin_jif = jiffies + HZ;\n\t\t\tclear_bit(RELOGIN_NEEDED, &vha->dpc_flags);\n\n\t\t\tql_dbg(ql_dbg_dpc, vha, 0x4018,\n\t\t\t    \"Relogin needed scheduled.\\n\");\n\t\t\tqla24xx_post_relogin_work(vha);\n\t\t}\n\t}\n\n\tif (test_and_clear_bit(RESET_MARKER_NEEDED, &vha->dpc_flags) &&\n\t    (!(test_and_set_bit(RESET_ACTIVE, &vha->dpc_flags)))) {\n\t\tclear_bit(RESET_ACTIVE, &vha->dpc_flags);\n\t}\n\n\tif (test_and_clear_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags)) {\n\t\tif (!(test_and_set_bit(LOOP_RESYNC_ACTIVE, &vha->dpc_flags))) {\n\t\t\tql_dbg(ql_dbg_dpc, vha, 0x401a,\n\t\t\t    \"Loop resync scheduled.\\n\");\n\t\t\tqla2x00_loop_resync(vha);\n\t\t\tclear_bit(LOOP_RESYNC_ACTIVE, &vha->dpc_flags);\n\t\t\tql_dbg(ql_dbg_dpc, vha, 0x401b,\n\t\t\t    \"Loop resync end.\\n\");\n\t\t}\n\t}\n\n\tql_dbg(ql_dbg_dpc + ql_dbg_verbose, vha, 0x401c,\n\t    \"Exiting %s.\\n\", __func__);\n\treturn 0;\n}\n\nvoid\nqla2x00_do_dpc_all_vps(scsi_qla_host_t *vha)\n{\n\tstruct qla_hw_data *ha = vha->hw;\n\tscsi_qla_host_t *vp, *tvp;\n\tunsigned long flags = 0;\n\n\tif (vha->vp_idx)\n\t\treturn;\n\tif (list_empty(&ha->vp_list))\n\t\treturn;\n\n\tclear_bit(VP_DPC_NEEDED, &vha->dpc_flags);\n\n\tif (!(ha->current_topology & ISP_CFG_F))\n\t\treturn;\n\n\tspin_lock_irqsave(&ha->vport_slock, flags);\n\tlist_for_each_entry_safe(vp, tvp, &ha->vp_list, list) {\n\t\tif (vp->vp_idx) {\n\t\t\tatomic_inc(&vp->vref_count);\n\t\t\tspin_unlock_irqrestore(&ha->vport_slock, flags);\n\n\t\t\tqla2x00_do_dpc_vp(vp);\n\n\t\t\tspin_lock_irqsave(&ha->vport_slock, flags);\n\t\t\tatomic_dec(&vp->vref_count);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&ha->vport_slock, flags);\n}\n\nint\nqla24xx_vport_create_req_sanity_check(struct fc_vport *fc_vport)\n{\n\tscsi_qla_host_t *base_vha = shost_priv(fc_vport->shost);\n\tstruct qla_hw_data *ha = base_vha->hw;\n\tscsi_qla_host_t *vha;\n\tuint8_t port_name[WWN_SIZE];\n\n\tif (fc_vport->roles != FC_PORT_ROLE_FCP_INITIATOR)\n\t\treturn VPCERR_UNSUPPORTED;\n\n\t \n\tif (!ha->flags.npiv_supported)\n\t\treturn VPCERR_UNSUPPORTED;\n\n\t \n\tif (!(ha->switch_cap & FLOGI_MID_SUPPORT))\n\t\treturn VPCERR_NO_FABRIC_SUPP;\n\n\t \n\tu64_to_wwn(fc_vport->port_name, port_name);\n\tif (!memcmp(port_name, base_vha->port_name, WWN_SIZE))\n\t\treturn VPCERR_BAD_WWN;\n\tvha = qla24xx_find_vhost_by_name(ha, port_name);\n\tif (vha)\n\t\treturn VPCERR_BAD_WWN;\n\n\t \n\tif (ha->num_vhosts > ha->max_npiv_vports) {\n\t\tql_dbg(ql_dbg_vport, vha, 0xa004,\n\t\t    \"num_vhosts %ud is bigger \"\n\t\t    \"than max_npiv_vports %ud.\\n\",\n\t\t    ha->num_vhosts, ha->max_npiv_vports);\n\t\treturn VPCERR_UNSUPPORTED;\n\t}\n\treturn 0;\n}\n\nscsi_qla_host_t *\nqla24xx_create_vhost(struct fc_vport *fc_vport)\n{\n\tscsi_qla_host_t *base_vha = shost_priv(fc_vport->shost);\n\tstruct qla_hw_data *ha = base_vha->hw;\n\tscsi_qla_host_t *vha;\n\tconst struct scsi_host_template *sht = &qla2xxx_driver_template;\n\tstruct Scsi_Host *host;\n\n\tvha = qla2x00_create_host(sht, ha);\n\tif (!vha) {\n\t\tql_log(ql_log_warn, vha, 0xa005,\n\t\t    \"scsi_host_alloc() failed for vport.\\n\");\n\t\treturn(NULL);\n\t}\n\n\thost = vha->host;\n\tfc_vport->dd_data = vha;\n\t \n\tu64_to_wwn(fc_vport->node_name, vha->node_name);\n\tu64_to_wwn(fc_vport->port_name, vha->port_name);\n\n\tvha->fc_vport = fc_vport;\n\tvha->device_flags = 0;\n\tvha->vp_idx = qla24xx_allocate_vp_id(vha);\n\tif (vha->vp_idx > ha->max_npiv_vports) {\n\t\tql_dbg(ql_dbg_vport, vha, 0xa006,\n\t\t    \"Couldn't allocate vp_id.\\n\");\n\t\tgoto create_vhost_failed;\n\t}\n\tvha->mgmt_svr_loop_id = qla2x00_reserve_mgmt_server_loop_id(vha);\n\n\tvha->dpc_flags = 0L;\n\tha->dpc_active = 0;\n\tset_bit(REGISTER_FDMI_NEEDED, &vha->dpc_flags);\n\tset_bit(REGISTER_FC4_NEEDED, &vha->dpc_flags);\n\n\t \n\tset_bit(VP_SCR_NEEDED, &vha->vp_flags);\n\tatomic_set(&vha->loop_state, LOOP_DOWN);\n\tatomic_set(&vha->loop_down_timer, LOOP_DOWN_TIME);\n\n\tqla2x00_start_timer(vha, WATCH_INTERVAL);\n\n\tvha->req = base_vha->req;\n\tvha->flags.nvme_enabled = base_vha->flags.nvme_enabled;\n\thost->can_queue = base_vha->req->length + 128;\n\thost->cmd_per_lun = 3;\n\tif (IS_T10_PI_CAPABLE(ha) && ql2xenabledif)\n\t\thost->max_cmd_len = 32;\n\telse\n\t\thost->max_cmd_len = MAX_CMDSZ;\n\thost->max_channel = MAX_BUSES - 1;\n\thost->max_lun = ql2xmaxlun;\n\thost->unique_id = host->host_no;\n\thost->max_id = ha->max_fibre_devices;\n\thost->transportt = qla2xxx_transport_vport_template;\n\n\tql_dbg(ql_dbg_vport, vha, 0xa007,\n\t    \"Detect vport hba %ld at address = %p.\\n\",\n\t    vha->host_no, vha);\n\n\tvha->flags.init_done = 1;\n\n\tmutex_lock(&ha->vport_lock);\n\tset_bit(vha->vp_idx, ha->vp_idx_map);\n\tha->cur_vport_count++;\n\tmutex_unlock(&ha->vport_lock);\n\n\treturn vha;\n\ncreate_vhost_failed:\n\treturn NULL;\n}\n\nstatic void\nqla25xx_free_req_que(struct scsi_qla_host *vha, struct req_que *req)\n{\n\tstruct qla_hw_data *ha = vha->hw;\n\tuint16_t que_id = req->id;\n\n\tdma_free_coherent(&ha->pdev->dev, (req->length + 1) *\n\t\tsizeof(request_t), req->ring, req->dma);\n\treq->ring = NULL;\n\treq->dma = 0;\n\tif (que_id) {\n\t\tha->req_q_map[que_id] = NULL;\n\t\tmutex_lock(&ha->vport_lock);\n\t\tclear_bit(que_id, ha->req_qid_map);\n\t\tmutex_unlock(&ha->vport_lock);\n\t}\n\tkfree(req->outstanding_cmds);\n\tkfree(req);\n}\n\nstatic void\nqla25xx_free_rsp_que(struct scsi_qla_host *vha, struct rsp_que *rsp)\n{\n\tstruct qla_hw_data *ha = vha->hw;\n\tuint16_t que_id = rsp->id;\n\n\tif (rsp->msix && rsp->msix->have_irq) {\n\t\tfree_irq(rsp->msix->vector, rsp->msix->handle);\n\t\trsp->msix->have_irq = 0;\n\t\trsp->msix->in_use = 0;\n\t\trsp->msix->handle = NULL;\n\t}\n\tdma_free_coherent(&ha->pdev->dev, (rsp->length + 1) *\n\t\tsizeof(response_t), rsp->ring, rsp->dma);\n\trsp->ring = NULL;\n\trsp->dma = 0;\n\tif (que_id) {\n\t\tha->rsp_q_map[que_id] = NULL;\n\t\tmutex_lock(&ha->vport_lock);\n\t\tclear_bit(que_id, ha->rsp_qid_map);\n\t\tmutex_unlock(&ha->vport_lock);\n\t}\n\tkfree(rsp);\n}\n\nint\nqla25xx_delete_req_que(struct scsi_qla_host *vha, struct req_que *req)\n{\n\tint ret = QLA_SUCCESS;\n\n\tif (req && vha->flags.qpairs_req_created) {\n\t\treq->options |= BIT_0;\n\t\tret = qla25xx_init_req_que(vha, req);\n\t\tif (ret != QLA_SUCCESS)\n\t\t\treturn QLA_FUNCTION_FAILED;\n\n\t\tqla25xx_free_req_que(vha, req);\n\t}\n\n\treturn ret;\n}\n\nint\nqla25xx_delete_rsp_que(struct scsi_qla_host *vha, struct rsp_que *rsp)\n{\n\tint ret = QLA_SUCCESS;\n\n\tif (rsp && vha->flags.qpairs_rsp_created) {\n\t\trsp->options |= BIT_0;\n\t\tret = qla25xx_init_rsp_que(vha, rsp);\n\t\tif (ret != QLA_SUCCESS)\n\t\t\treturn QLA_FUNCTION_FAILED;\n\n\t\tqla25xx_free_rsp_que(vha, rsp);\n\t}\n\n\treturn ret;\n}\n\n \nint\nqla25xx_delete_queues(struct scsi_qla_host *vha)\n{\n\tint cnt, ret = 0;\n\tstruct req_que *req = NULL;\n\tstruct rsp_que *rsp = NULL;\n\tstruct qla_hw_data *ha = vha->hw;\n\tstruct qla_qpair *qpair, *tqpair;\n\n\tif (ql2xmqsupport || ql2xnvmeenable) {\n\t\tlist_for_each_entry_safe(qpair, tqpair, &vha->qp_list,\n\t\t    qp_list_elem)\n\t\t\tqla2xxx_delete_qpair(vha, qpair);\n\t} else {\n\t\t \n\t\tfor (cnt = 1; cnt < ha->max_req_queues; cnt++) {\n\t\t\treq = ha->req_q_map[cnt];\n\t\t\tif (req && test_bit(cnt, ha->req_qid_map)) {\n\t\t\t\tret = qla25xx_delete_req_que(vha, req);\n\t\t\t\tif (ret != QLA_SUCCESS) {\n\t\t\t\t\tql_log(ql_log_warn, vha, 0x00ea,\n\t\t\t\t\t    \"Couldn't delete req que %d.\\n\",\n\t\t\t\t\t    req->id);\n\t\t\t\t\treturn ret;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tfor (cnt = 1; cnt < ha->max_rsp_queues; cnt++) {\n\t\t\trsp = ha->rsp_q_map[cnt];\n\t\t\tif (rsp && test_bit(cnt, ha->rsp_qid_map)) {\n\t\t\t\tret = qla25xx_delete_rsp_que(vha, rsp);\n\t\t\t\tif (ret != QLA_SUCCESS) {\n\t\t\t\t\tql_log(ql_log_warn, vha, 0x00eb,\n\t\t\t\t\t    \"Couldn't delete rsp que %d.\\n\",\n\t\t\t\t\t    rsp->id);\n\t\t\t\t\treturn ret;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nint\nqla25xx_create_req_que(struct qla_hw_data *ha, uint16_t options,\n    uint8_t vp_idx, uint16_t rid, int rsp_que, uint8_t qos, bool startqp)\n{\n\tint ret = 0;\n\tstruct req_que *req = NULL;\n\tstruct scsi_qla_host *base_vha = pci_get_drvdata(ha->pdev);\n\tstruct scsi_qla_host *vha = pci_get_drvdata(ha->pdev);\n\tuint16_t que_id = 0;\n\tdevice_reg_t *reg;\n\tuint32_t cnt;\n\n\treq = kzalloc(sizeof(struct req_que), GFP_KERNEL);\n\tif (req == NULL) {\n\t\tql_log(ql_log_fatal, base_vha, 0x00d9,\n\t\t    \"Failed to allocate memory for request queue.\\n\");\n\t\tgoto failed;\n\t}\n\n\treq->length = REQUEST_ENTRY_CNT_24XX;\n\treq->ring = dma_alloc_coherent(&ha->pdev->dev,\n\t\t\t(req->length + 1) * sizeof(request_t),\n\t\t\t&req->dma, GFP_KERNEL);\n\tif (req->ring == NULL) {\n\t\tql_log(ql_log_fatal, base_vha, 0x00da,\n\t\t    \"Failed to allocate memory for request_ring.\\n\");\n\t\tgoto que_failed;\n\t}\n\n\tret = qla2x00_alloc_outstanding_cmds(ha, req);\n\tif (ret != QLA_SUCCESS)\n\t\tgoto que_failed;\n\n\tmutex_lock(&ha->mq_lock);\n\tque_id = find_first_zero_bit(ha->req_qid_map, ha->max_req_queues);\n\tif (que_id >= ha->max_req_queues) {\n\t\tmutex_unlock(&ha->mq_lock);\n\t\tql_log(ql_log_warn, base_vha, 0x00db,\n\t\t    \"No resources to create additional request queue.\\n\");\n\t\tgoto que_failed;\n\t}\n\tset_bit(que_id, ha->req_qid_map);\n\tha->req_q_map[que_id] = req;\n\treq->rid = rid;\n\treq->vp_idx = vp_idx;\n\treq->qos = qos;\n\n\tql_dbg(ql_dbg_multiq, base_vha, 0xc002,\n\t    \"queue_id=%d rid=%d vp_idx=%d qos=%d.\\n\",\n\t    que_id, req->rid, req->vp_idx, req->qos);\n\tql_dbg(ql_dbg_init, base_vha, 0x00dc,\n\t    \"queue_id=%d rid=%d vp_idx=%d qos=%d.\\n\",\n\t    que_id, req->rid, req->vp_idx, req->qos);\n\tif (rsp_que < 0)\n\t\treq->rsp = NULL;\n\telse\n\t\treq->rsp = ha->rsp_q_map[rsp_que];\n\t \n\tif (MSB(req->rid))\n\t\toptions |= BIT_4;\n\t \n\tif (LSB(req->rid))\n\t\toptions |= BIT_5;\n\treq->options = options;\n\n\tql_dbg(ql_dbg_multiq, base_vha, 0xc003,\n\t    \"options=0x%x.\\n\", req->options);\n\tql_dbg(ql_dbg_init, base_vha, 0x00dd,\n\t    \"options=0x%x.\\n\", req->options);\n\tfor (cnt = 1; cnt < req->num_outstanding_cmds; cnt++)\n\t\treq->outstanding_cmds[cnt] = NULL;\n\treq->current_outstanding_cmd = 1;\n\n\treq->ring_ptr = req->ring;\n\treq->ring_index = 0;\n\treq->cnt = req->length;\n\treq->id = que_id;\n\treg = ISP_QUE_REG(ha, que_id);\n\treq->req_q_in = &reg->isp25mq.req_q_in;\n\treq->req_q_out = &reg->isp25mq.req_q_out;\n\treq->max_q_depth = ha->req_q_map[0]->max_q_depth;\n\treq->out_ptr = (uint16_t *)(req->ring + req->length);\n\tmutex_unlock(&ha->mq_lock);\n\tql_dbg(ql_dbg_multiq, base_vha, 0xc004,\n\t    \"ring_ptr=%p ring_index=%d, \"\n\t    \"cnt=%d id=%d max_q_depth=%d.\\n\",\n\t    req->ring_ptr, req->ring_index,\n\t    req->cnt, req->id, req->max_q_depth);\n\tql_dbg(ql_dbg_init, base_vha, 0x00de,\n\t    \"ring_ptr=%p ring_index=%d, \"\n\t    \"cnt=%d id=%d max_q_depth=%d.\\n\",\n\t    req->ring_ptr, req->ring_index, req->cnt,\n\t    req->id, req->max_q_depth);\n\n\tif (startqp) {\n\t\tret = qla25xx_init_req_que(base_vha, req);\n\t\tif (ret != QLA_SUCCESS) {\n\t\t\tql_log(ql_log_fatal, base_vha, 0x00df,\n\t\t\t    \"%s failed.\\n\", __func__);\n\t\t\tmutex_lock(&ha->mq_lock);\n\t\t\tclear_bit(que_id, ha->req_qid_map);\n\t\t\tmutex_unlock(&ha->mq_lock);\n\t\t\tgoto que_failed;\n\t\t}\n\t\tvha->flags.qpairs_req_created = 1;\n\t}\n\n\treturn req->id;\n\nque_failed:\n\tqla25xx_free_req_que(base_vha, req);\nfailed:\n\treturn 0;\n}\n\nstatic void qla_do_work(struct work_struct *work)\n{\n\tunsigned long flags;\n\tstruct qla_qpair *qpair = container_of(work, struct qla_qpair, q_work);\n\tstruct scsi_qla_host *vha = qpair->vha;\n\n\tspin_lock_irqsave(&qpair->qp_lock, flags);\n\tqla24xx_process_response_queue(vha, qpair->rsp);\n\tspin_unlock_irqrestore(&qpair->qp_lock, flags);\n\n}\n\n \nint\nqla25xx_create_rsp_que(struct qla_hw_data *ha, uint16_t options,\n    uint8_t vp_idx, uint16_t rid, struct qla_qpair *qpair, bool startqp)\n{\n\tint ret = 0;\n\tstruct rsp_que *rsp = NULL;\n\tstruct scsi_qla_host *base_vha = pci_get_drvdata(ha->pdev);\n\tstruct scsi_qla_host *vha = pci_get_drvdata(ha->pdev);\n\tuint16_t que_id = 0;\n\tdevice_reg_t *reg;\n\n\trsp = kzalloc(sizeof(struct rsp_que), GFP_KERNEL);\n\tif (rsp == NULL) {\n\t\tql_log(ql_log_warn, base_vha, 0x0066,\n\t\t    \"Failed to allocate memory for response queue.\\n\");\n\t\tgoto failed;\n\t}\n\n\trsp->length = RESPONSE_ENTRY_CNT_MQ;\n\trsp->ring = dma_alloc_coherent(&ha->pdev->dev,\n\t\t\t(rsp->length + 1) * sizeof(response_t),\n\t\t\t&rsp->dma, GFP_KERNEL);\n\tif (rsp->ring == NULL) {\n\t\tql_log(ql_log_warn, base_vha, 0x00e1,\n\t\t    \"Failed to allocate memory for response ring.\\n\");\n\t\tgoto que_failed;\n\t}\n\n\tmutex_lock(&ha->mq_lock);\n\tque_id = find_first_zero_bit(ha->rsp_qid_map, ha->max_rsp_queues);\n\tif (que_id >= ha->max_rsp_queues) {\n\t\tmutex_unlock(&ha->mq_lock);\n\t\tql_log(ql_log_warn, base_vha, 0x00e2,\n\t\t    \"No resources to create additional request queue.\\n\");\n\t\tgoto que_failed;\n\t}\n\tset_bit(que_id, ha->rsp_qid_map);\n\n\trsp->msix = qpair->msix;\n\n\tha->rsp_q_map[que_id] = rsp;\n\trsp->rid = rid;\n\trsp->vp_idx = vp_idx;\n\trsp->hw = ha;\n\tql_dbg(ql_dbg_init, base_vha, 0x00e4,\n\t    \"rsp queue_id=%d rid=%d vp_idx=%d hw=%p.\\n\",\n\t    que_id, rsp->rid, rsp->vp_idx, rsp->hw);\n\t \n\tif (MSB(rsp->rid))\n\t\toptions |= BIT_4;\n\t \n\tif (LSB(rsp->rid))\n\t\toptions |= BIT_5;\n\t \n\tif (!IS_MSIX_NACK_CAPABLE(ha))\n\t\toptions |= BIT_6;\n\n\t \n\toptions |= BIT_1;\n\n\trsp->options = options;\n\trsp->id = que_id;\n\treg = ISP_QUE_REG(ha, que_id);\n\trsp->rsp_q_in = &reg->isp25mq.rsp_q_in;\n\trsp->rsp_q_out = &reg->isp25mq.rsp_q_out;\n\trsp->in_ptr = (uint16_t *)(rsp->ring + rsp->length);\n\tmutex_unlock(&ha->mq_lock);\n\tql_dbg(ql_dbg_multiq, base_vha, 0xc00b,\n\t    \"options=%x id=%d rsp_q_in=%p rsp_q_out=%p\\n\",\n\t    rsp->options, rsp->id, rsp->rsp_q_in,\n\t    rsp->rsp_q_out);\n\tql_dbg(ql_dbg_init, base_vha, 0x00e5,\n\t    \"options=%x id=%d rsp_q_in=%p rsp_q_out=%p\\n\",\n\t    rsp->options, rsp->id, rsp->rsp_q_in,\n\t    rsp->rsp_q_out);\n\n\tret = qla25xx_request_irq(ha, qpair, qpair->msix,\n\t\tha->flags.disable_msix_handshake ?\n\t\tQLA_MSIX_QPAIR_MULTIQ_RSP_Q : QLA_MSIX_QPAIR_MULTIQ_RSP_Q_HS);\n\tif (ret)\n\t\tgoto que_failed;\n\n\tif (startqp) {\n\t\tret = qla25xx_init_rsp_que(base_vha, rsp);\n\t\tif (ret != QLA_SUCCESS) {\n\t\t\tql_log(ql_log_fatal, base_vha, 0x00e7,\n\t\t\t    \"%s failed.\\n\", __func__);\n\t\t\tmutex_lock(&ha->mq_lock);\n\t\t\tclear_bit(que_id, ha->rsp_qid_map);\n\t\t\tmutex_unlock(&ha->mq_lock);\n\t\t\tgoto que_failed;\n\t\t}\n\t\tvha->flags.qpairs_rsp_created = 1;\n\t}\n\trsp->req = NULL;\n\n\tqla2x00_init_response_q_entries(rsp);\n\tif (qpair->hw->wq)\n\t\tINIT_WORK(&qpair->q_work, qla_do_work);\n\treturn rsp->id;\n\nque_failed:\n\tqla25xx_free_rsp_que(base_vha, rsp);\nfailed:\n\treturn 0;\n}\n\nstatic void qla_ctrlvp_sp_done(srb_t *sp, int res)\n{\n\tif (sp->comp)\n\t\tcomplete(sp->comp);\n\t \n}\n\n \nint qla24xx_control_vp(scsi_qla_host_t *vha, int cmd)\n{\n\tint rval = QLA_MEMORY_ALLOC_FAILED;\n\tstruct qla_hw_data *ha = vha->hw;\n\tint\tvp_index = vha->vp_idx;\n\tstruct scsi_qla_host *base_vha = pci_get_drvdata(ha->pdev);\n\tDECLARE_COMPLETION_ONSTACK(comp);\n\tsrb_t *sp;\n\n\tql_dbg(ql_dbg_vport, vha, 0x10c1,\n\t    \"Entered %s cmd %x index %d.\\n\", __func__, cmd, vp_index);\n\n\tif (vp_index == 0 || vp_index >= ha->max_npiv_vports)\n\t\treturn QLA_PARAMETER_ERROR;\n\n\t \n\tsp = qla2x00_get_sp(base_vha, NULL, GFP_KERNEL);\n\tif (!sp)\n\t\treturn rval;\n\n\tsp->type = SRB_CTRL_VP;\n\tsp->name = \"ctrl_vp\";\n\tsp->comp = &comp;\n\tqla2x00_init_async_sp(sp, qla2x00_get_async_timeout(vha) + 2,\n\t\t\t      qla_ctrlvp_sp_done);\n\tsp->u.iocb_cmd.u.ctrlvp.cmd = cmd;\n\tsp->u.iocb_cmd.u.ctrlvp.vp_index = vp_index;\n\n\trval = qla2x00_start_sp(sp);\n\tif (rval != QLA_SUCCESS) {\n\t\tql_dbg(ql_dbg_async, vha, 0xffff,\n\t\t    \"%s: %s Failed submission. %x.\\n\",\n\t\t    __func__, sp->name, rval);\n\t\tgoto done;\n\t}\n\n\tql_dbg(ql_dbg_vport, vha, 0x113f, \"%s hndl %x submitted\\n\",\n\t    sp->name, sp->handle);\n\n\twait_for_completion(&comp);\n\tsp->comp = NULL;\n\n\trval = sp->rc;\n\tswitch (rval) {\n\tcase QLA_FUNCTION_TIMEOUT:\n\t\tql_dbg(ql_dbg_vport, vha, 0xffff, \"%s: %s Timeout. %x.\\n\",\n\t\t    __func__, sp->name, rval);\n\t\tbreak;\n\tcase QLA_SUCCESS:\n\t\tql_dbg(ql_dbg_vport, vha, 0xffff, \"%s: %s done.\\n\",\n\t\t    __func__, sp->name);\n\t\tbreak;\n\tdefault:\n\t\tql_dbg(ql_dbg_vport, vha, 0xffff, \"%s: %s Failed. %x.\\n\",\n\t\t    __func__, sp->name, rval);\n\t\tbreak;\n\t}\ndone:\n\t \n\tkref_put(&sp->cmd_kref, qla2x00_sp_release);\n\treturn rval;\n}\n\nstruct scsi_qla_host *qla_find_host_by_vp_idx(struct scsi_qla_host *vha, uint16_t vp_idx)\n{\n\tstruct qla_hw_data *ha = vha->hw;\n\n\tif (vha->vp_idx == vp_idx)\n\t\treturn vha;\n\n\tBUG_ON(ha->vp_map == NULL);\n\tif (likely(test_bit(vp_idx, ha->vp_idx_map)))\n\t\treturn ha->vp_map[vp_idx].vha;\n\n\treturn NULL;\n}\n\n \nvoid\nqla_update_vp_map(struct scsi_qla_host *vha, int cmd)\n{\n\tvoid *slot;\n\tu32 key;\n\tint rc;\n\n\tif (!vha->hw->vp_map)\n\t\treturn;\n\n\tkey = vha->d_id.b24;\n\n\tswitch (cmd) {\n\tcase SET_VP_IDX:\n\t\tvha->hw->vp_map[vha->vp_idx].vha = vha;\n\t\tbreak;\n\tcase SET_AL_PA:\n\t\tslot = btree_lookup32(&vha->hw->host_map, key);\n\t\tif (!slot) {\n\t\t\tql_dbg(ql_dbg_disc, vha, 0xf018,\n\t\t\t    \"Save vha in host_map %p %06x\\n\", vha, key);\n\t\t\trc = btree_insert32(&vha->hw->host_map,\n\t\t\t    key, vha, GFP_ATOMIC);\n\t\t\tif (rc)\n\t\t\t\tql_log(ql_log_info, vha, 0xd03e,\n\t\t\t\t    \"Unable to insert s_id into host_map: %06x\\n\",\n\t\t\t\t    key);\n\t\t\treturn;\n\t\t}\n\t\tql_dbg(ql_dbg_disc, vha, 0xf019,\n\t\t    \"replace existing vha in host_map %p %06x\\n\", vha, key);\n\t\tbtree_update32(&vha->hw->host_map, key, vha);\n\t\tbreak;\n\tcase RESET_VP_IDX:\n\t\tvha->hw->vp_map[vha->vp_idx].vha = NULL;\n\t\tbreak;\n\tcase RESET_AL_PA:\n\t\tql_dbg(ql_dbg_disc, vha, 0xf01a,\n\t\t    \"clear vha in host_map %p %06x\\n\", vha, key);\n\t\tslot = btree_lookup32(&vha->hw->host_map, key);\n\t\tif (slot)\n\t\t\tbtree_remove32(&vha->hw->host_map, key);\n\t\tvha->d_id.b24 = 0;\n\t\tbreak;\n\t}\n}\n\nvoid qla_update_host_map(struct scsi_qla_host *vha, port_id_t id)\n{\n\n\tif (!vha->d_id.b24) {\n\t\tvha->d_id = id;\n\t\tqla_update_vp_map(vha, SET_AL_PA);\n\t} else if (vha->d_id.b24 != id.b24) {\n\t\tqla_update_vp_map(vha, RESET_AL_PA);\n\t\tvha->d_id = id;\n\t\tqla_update_vp_map(vha, SET_AL_PA);\n\t}\n}\n\nint qla_create_buf_pool(struct scsi_qla_host *vha, struct qla_qpair *qp)\n{\n\tint sz;\n\n\tqp->buf_pool.num_bufs = qp->req->length;\n\n\tsz = BITS_TO_LONGS(qp->req->length);\n\tqp->buf_pool.buf_map   = kcalloc(sz, sizeof(long), GFP_KERNEL);\n\tif (!qp->buf_pool.buf_map) {\n\t\tql_log(ql_log_warn, vha, 0x0186,\n\t\t    \"Failed to allocate buf_map(%zd).\\n\", sz * sizeof(unsigned long));\n\t\treturn -ENOMEM;\n\t}\n\tsz = qp->req->length * sizeof(void *);\n\tqp->buf_pool.buf_array = kcalloc(qp->req->length, sizeof(void *), GFP_KERNEL);\n\tif (!qp->buf_pool.buf_array) {\n\t\tql_log(ql_log_warn, vha, 0x0186,\n\t\t    \"Failed to allocate buf_array(%d).\\n\", sz);\n\t\tkfree(qp->buf_pool.buf_map);\n\t\treturn -ENOMEM;\n\t}\n\tsz = qp->req->length * sizeof(dma_addr_t);\n\tqp->buf_pool.dma_array = kcalloc(qp->req->length, sizeof(dma_addr_t), GFP_KERNEL);\n\tif (!qp->buf_pool.dma_array) {\n\t\tql_log(ql_log_warn, vha, 0x0186,\n\t\t    \"Failed to allocate dma_array(%d).\\n\", sz);\n\t\tkfree(qp->buf_pool.buf_map);\n\t\tkfree(qp->buf_pool.buf_array);\n\t\treturn -ENOMEM;\n\t}\n\tset_bit(0, qp->buf_pool.buf_map);\n\treturn 0;\n}\n\nvoid qla_free_buf_pool(struct qla_qpair *qp)\n{\n\tint i;\n\tstruct qla_hw_data *ha = qp->vha->hw;\n\n\tfor (i = 0; i < qp->buf_pool.num_bufs; i++) {\n\t\tif (qp->buf_pool.buf_array[i] && qp->buf_pool.dma_array[i])\n\t\t\tdma_pool_free(ha->fcp_cmnd_dma_pool, qp->buf_pool.buf_array[i],\n\t\t\t    qp->buf_pool.dma_array[i]);\n\t\tqp->buf_pool.buf_array[i] = NULL;\n\t\tqp->buf_pool.dma_array[i] = 0;\n\t}\n\n\tkfree(qp->buf_pool.dma_array);\n\tkfree(qp->buf_pool.buf_array);\n\tkfree(qp->buf_pool.buf_map);\n}\n\n \nint qla_get_buf(struct scsi_qla_host *vha, struct qla_qpair *qp, struct qla_buf_dsc *dsc)\n{\n\tu16 tag, i = 0;\n\tvoid *buf;\n\tdma_addr_t buf_dma;\n\tstruct qla_hw_data *ha = vha->hw;\n\n\tdsc->tag = TAG_FREED;\nagain:\n\ttag = find_first_zero_bit(qp->buf_pool.buf_map, qp->buf_pool.num_bufs);\n\tif (tag >= qp->buf_pool.num_bufs) {\n\t\tql_dbg(ql_dbg_io, vha, 0x00e2,\n\t\t    \"qp(%d) ran out of buf resource.\\n\", qp->id);\n\t\treturn  -EIO;\n\t}\n\tif (tag == 0) {\n\t\tset_bit(0, qp->buf_pool.buf_map);\n\t\ti++;\n\t\tif (i == 5) {\n\t\t\tql_dbg(ql_dbg_io, vha, 0x00e3,\n\t\t\t    \"qp(%d) unable to get tag.\\n\", qp->id);\n\t\t\treturn -EIO;\n\t\t}\n\t\tgoto again;\n\t}\n\n\tif (!qp->buf_pool.buf_array[tag]) {\n\t\tbuf = dma_pool_zalloc(ha->fcp_cmnd_dma_pool, GFP_ATOMIC, &buf_dma);\n\t\tif (!buf) {\n\t\t\tql_log(ql_log_fatal, vha, 0x13b1,\n\t\t\t    \"Failed to allocate buf.\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tdsc->buf = qp->buf_pool.buf_array[tag] = buf;\n\t\tdsc->buf_dma = qp->buf_pool.dma_array[tag] = buf_dma;\n\t\tqp->buf_pool.num_alloc++;\n\t} else {\n\t\tdsc->buf = qp->buf_pool.buf_array[tag];\n\t\tdsc->buf_dma = qp->buf_pool.dma_array[tag];\n\t\tmemset(dsc->buf, 0, FCP_CMND_DMA_POOL_SIZE);\n\t}\n\n\tqp->buf_pool.num_active++;\n\tif (qp->buf_pool.num_active > qp->buf_pool.max_used)\n\t\tqp->buf_pool.max_used = qp->buf_pool.num_active;\n\n\tdsc->tag = tag;\n\tset_bit(tag, qp->buf_pool.buf_map);\n\treturn 0;\n}\n\nstatic void qla_trim_buf(struct qla_qpair *qp, u16 trim)\n{\n\tint i, j;\n\tstruct qla_hw_data *ha = qp->vha->hw;\n\n\tif (!trim)\n\t\treturn;\n\n\tfor (i = 0; i < trim; i++) {\n\t\tj = qp->buf_pool.num_alloc - 1;\n\t\tif (test_bit(j, qp->buf_pool.buf_map)) {\n\t\t\tql_dbg(ql_dbg_io + ql_dbg_verbose, qp->vha, 0x300b,\n\t\t\t       \"QP id(%d): trim active buf[%d]. Remain %d bufs\\n\",\n\t\t\t       qp->id, j, qp->buf_pool.num_alloc);\n\t\t\treturn;\n\t\t}\n\n\t\tif (qp->buf_pool.buf_array[j]) {\n\t\t\tdma_pool_free(ha->fcp_cmnd_dma_pool, qp->buf_pool.buf_array[j],\n\t\t\t\t      qp->buf_pool.dma_array[j]);\n\t\t\tqp->buf_pool.buf_array[j] = NULL;\n\t\t\tqp->buf_pool.dma_array[j] = 0;\n\t\t}\n\t\tqp->buf_pool.num_alloc--;\n\t\tif (!qp->buf_pool.num_alloc)\n\t\t\tbreak;\n\t}\n\tql_dbg(ql_dbg_io + ql_dbg_verbose, qp->vha, 0x3010,\n\t       \"QP id(%d): trimmed %d bufs. Remain %d bufs\\n\",\n\t       qp->id, trim, qp->buf_pool.num_alloc);\n}\n\nstatic void __qla_adjust_buf(struct qla_qpair *qp)\n{\n\tu32 trim;\n\n\tqp->buf_pool.take_snapshot = 0;\n\tqp->buf_pool.prev_max = qp->buf_pool.max_used;\n\tqp->buf_pool.max_used = qp->buf_pool.num_active;\n\n\tif (qp->buf_pool.prev_max > qp->buf_pool.max_used &&\n\t    qp->buf_pool.num_alloc > qp->buf_pool.max_used) {\n\t\t \n\t\ttrim = qp->buf_pool.num_alloc - qp->buf_pool.max_used;\n\t\ttrim  = (trim * 10) / 100;\n\t\ttrim = trim ? trim : 1;\n\t\tqla_trim_buf(qp, trim);\n\t} else if (!qp->buf_pool.prev_max  && !qp->buf_pool.max_used) {\n\t\t \n\t\tqla_trim_buf(qp, qp->buf_pool.num_alloc);\n\t}\n}\n\n \nvoid qla_put_buf(struct qla_qpair *qp, struct qla_buf_dsc *dsc)\n{\n\tif (dsc->tag == TAG_FREED)\n\t\treturn;\n\tlockdep_assert_held(qp->qp_lock_ptr);\n\n\tclear_bit(dsc->tag, qp->buf_pool.buf_map);\n\tqp->buf_pool.num_active--;\n\tdsc->tag = TAG_FREED;\n\n\tif (qp->buf_pool.take_snapshot)\n\t\t__qla_adjust_buf(qp);\n}\n\n#define EXPIRE (60 * HZ)\nvoid qla_adjust_buf(struct scsi_qla_host *vha)\n{\n\tunsigned long flags;\n\tint i;\n\tstruct qla_qpair *qp;\n\n\tif (vha->vp_idx)\n\t\treturn;\n\n\tif (!vha->buf_expired) {\n\t\tvha->buf_expired = jiffies + EXPIRE;\n\t\treturn;\n\t}\n\tif (time_before(jiffies, vha->buf_expired))\n\t\treturn;\n\n\tvha->buf_expired = jiffies + EXPIRE;\n\n\tfor (i = 0; i < vha->hw->num_qpairs; i++) {\n\t\tqp = vha->hw->queue_pair_map[i];\n\t\tif (!qp)\n\t\t\tcontinue;\n\t\tif (!qp->buf_pool.num_alloc)\n\t\t\tcontinue;\n\n\t\tif (qp->buf_pool.take_snapshot) {\n\t\t\t \n\t\t\tspin_lock_irqsave(qp->qp_lock_ptr, flags);\n\t\t\t__qla_adjust_buf(qp);\n\t\t\tspin_unlock_irqrestore(qp->qp_lock_ptr, flags);\n\t\t} else {\n\t\t\tqp->buf_pool.take_snapshot = 1;\n\t\t}\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}