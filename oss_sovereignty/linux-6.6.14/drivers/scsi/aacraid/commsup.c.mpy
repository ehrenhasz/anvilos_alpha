{
  "module_name": "commsup.c",
  "hash_id": "afd90b55993ea3d57c3710ab27dfa3c9e31147a2f536ce22251a2d6766c4350b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/aacraid/commsup.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/crash_dump.h>\n#include <linux/types.h>\n#include <linux/sched.h>\n#include <linux/pci.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/completion.h>\n#include <linux/blkdev.h>\n#include <linux/delay.h>\n#include <linux/kthread.h>\n#include <linux/interrupt.h>\n#include <linux/bcd.h>\n#include <scsi/scsi.h>\n#include <scsi/scsi_host.h>\n#include <scsi/scsi_device.h>\n#include <scsi/scsi_cmnd.h>\n\n#include \"aacraid.h\"\n\n \n\nstatic int fib_map_alloc(struct aac_dev *dev)\n{\n\tif (dev->max_fib_size > AAC_MAX_NATIVE_SIZE)\n\t\tdev->max_cmd_size = AAC_MAX_NATIVE_SIZE;\n\telse\n\t\tdev->max_cmd_size = dev->max_fib_size;\n\tif (dev->max_fib_size < AAC_MAX_NATIVE_SIZE) {\n\t\tdev->max_cmd_size = AAC_MAX_NATIVE_SIZE;\n\t} else {\n\t\tdev->max_cmd_size = dev->max_fib_size;\n\t}\n\n\tdprintk((KERN_INFO\n\t  \"allocate hardware fibs dma_alloc_coherent(%p, %d * (%d + %d), %p)\\n\",\n\t  &dev->pdev->dev, dev->max_cmd_size, dev->scsi_host_ptr->can_queue,\n\t  AAC_NUM_MGT_FIB, &dev->hw_fib_pa));\n\tdev->hw_fib_va = dma_alloc_coherent(&dev->pdev->dev,\n\t\t(dev->max_cmd_size + sizeof(struct aac_fib_xporthdr))\n\t\t* (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB) + (ALIGN32 - 1),\n\t\t&dev->hw_fib_pa, GFP_KERNEL);\n\tif (dev->hw_fib_va == NULL)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\n \n\nvoid aac_fib_map_free(struct aac_dev *dev)\n{\n\tsize_t alloc_size;\n\tsize_t fib_size;\n\tint num_fibs;\n\n\tif(!dev->hw_fib_va || !dev->max_cmd_size)\n\t\treturn;\n\n\tnum_fibs = dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB;\n\tfib_size = dev->max_fib_size + sizeof(struct aac_fib_xporthdr);\n\talloc_size = fib_size * num_fibs + ALIGN32 - 1;\n\n\tdma_free_coherent(&dev->pdev->dev, alloc_size, dev->hw_fib_va,\n\t\t\t  dev->hw_fib_pa);\n\n\tdev->hw_fib_va = NULL;\n\tdev->hw_fib_pa = 0;\n}\n\nvoid aac_fib_vector_assign(struct aac_dev *dev)\n{\n\tu32 i = 0;\n\tu32 vector = 1;\n\tstruct fib *fibptr = NULL;\n\n\tfor (i = 0, fibptr = &dev->fibs[i];\n\t\ti < (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB);\n\t\ti++, fibptr++) {\n\t\tif ((dev->max_msix == 1) ||\n\t\t  (i > ((dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB - 1)\n\t\t\t- dev->vector_cap))) {\n\t\t\tfibptr->vector_no = 0;\n\t\t} else {\n\t\t\tfibptr->vector_no = vector;\n\t\t\tvector++;\n\t\t\tif (vector == dev->max_msix)\n\t\t\t\tvector = 1;\n\t\t}\n\t}\n}\n\n \n\nint aac_fib_setup(struct aac_dev * dev)\n{\n\tstruct fib *fibptr;\n\tstruct hw_fib *hw_fib;\n\tdma_addr_t hw_fib_pa;\n\tint i;\n\tu32 max_cmds;\n\n\twhile (((i = fib_map_alloc(dev)) == -ENOMEM)\n\t && (dev->scsi_host_ptr->can_queue > (64 - AAC_NUM_MGT_FIB))) {\n\t\tmax_cmds = (dev->scsi_host_ptr->can_queue+AAC_NUM_MGT_FIB) >> 1;\n\t\tdev->scsi_host_ptr->can_queue = max_cmds - AAC_NUM_MGT_FIB;\n\t\tif (dev->comm_interface != AAC_COMM_MESSAGE_TYPE3)\n\t\t\tdev->init->r7.max_io_commands = cpu_to_le32(max_cmds);\n\t}\n\tif (i<0)\n\t\treturn -ENOMEM;\n\n\tmemset(dev->hw_fib_va, 0,\n\t\t(dev->max_cmd_size + sizeof(struct aac_fib_xporthdr)) *\n\t\t(dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB));\n\n\t \n\thw_fib_pa = (dev->hw_fib_pa + (ALIGN32 - 1)) & ~(ALIGN32 - 1);\n\thw_fib    = (struct hw_fib *)((unsigned char *)dev->hw_fib_va +\n\t\t\t\t\t(hw_fib_pa - dev->hw_fib_pa));\n\n\t \n\thw_fib = (struct hw_fib *)((unsigned char *)hw_fib +\n\t\tsizeof(struct aac_fib_xporthdr));\n\thw_fib_pa += sizeof(struct aac_fib_xporthdr);\n\n\t \n\tfor (i = 0, fibptr = &dev->fibs[i];\n\t\ti < (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB);\n\t\ti++, fibptr++)\n\t{\n\t\tfibptr->flags = 0;\n\t\tfibptr->size = sizeof(struct fib);\n\t\tfibptr->dev = dev;\n\t\tfibptr->hw_fib_va = hw_fib;\n\t\tfibptr->data = (void *) fibptr->hw_fib_va->data;\n\t\tfibptr->next = fibptr+1;\t \n\t\tinit_completion(&fibptr->event_wait);\n\t\tspin_lock_init(&fibptr->event_lock);\n\t\thw_fib->header.XferState = cpu_to_le32(0xffffffff);\n\t\thw_fib->header.SenderSize =\n\t\t\tcpu_to_le16(dev->max_fib_size);\t \n\t\tfibptr->hw_fib_pa = hw_fib_pa;\n\t\tfibptr->hw_sgl_pa = hw_fib_pa +\n\t\t\toffsetof(struct aac_hba_cmd_req, sge[2]);\n\t\t \n\t\tfibptr->hw_error_pa = hw_fib_pa +\n\t\t\toffsetof(struct aac_native_hba, resp.resp_bytes[0]);\n\n\t\thw_fib = (struct hw_fib *)((unsigned char *)hw_fib +\n\t\t\tdev->max_cmd_size + sizeof(struct aac_fib_xporthdr));\n\t\thw_fib_pa = hw_fib_pa +\n\t\t\tdev->max_cmd_size + sizeof(struct aac_fib_xporthdr);\n\t}\n\n\t \n\taac_fib_vector_assign(dev);\n\n\t \n\tdev->fibs[dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB - 1].next = NULL;\n\t \n\tdev->free_fib = &dev->fibs[dev->scsi_host_ptr->can_queue];\n\treturn 0;\n}\n\n \n\nstruct fib *aac_fib_alloc_tag(struct aac_dev *dev, struct scsi_cmnd *scmd)\n{\n\tstruct fib *fibptr;\n\n\tfibptr = &dev->fibs[scsi_cmd_to_rq(scmd)->tag];\n\t \n\tfibptr->hw_fib_va->header.XferState = 0;\n\tfibptr->type = FSAFS_NTC_FIB_CONTEXT;\n\tfibptr->callback_data = NULL;\n\tfibptr->callback = NULL;\n\tfibptr->flags = 0;\n\n\treturn fibptr;\n}\n\n \n\nstruct fib *aac_fib_alloc(struct aac_dev *dev)\n{\n\tstruct fib * fibptr;\n\tunsigned long flags;\n\tspin_lock_irqsave(&dev->fib_lock, flags);\n\tfibptr = dev->free_fib;\n\tif(!fibptr){\n\t\tspin_unlock_irqrestore(&dev->fib_lock, flags);\n\t\treturn fibptr;\n\t}\n\tdev->free_fib = fibptr->next;\n\tspin_unlock_irqrestore(&dev->fib_lock, flags);\n\t \n\tfibptr->type = FSAFS_NTC_FIB_CONTEXT;\n\tfibptr->size = sizeof(struct fib);\n\t \n\tfibptr->hw_fib_va->header.XferState = 0;\n\tfibptr->flags = 0;\n\tfibptr->callback = NULL;\n\tfibptr->callback_data = NULL;\n\n\treturn fibptr;\n}\n\n \n\nvoid aac_fib_free(struct fib *fibptr)\n{\n\tunsigned long flags;\n\n\tif (fibptr->done == 2)\n\t\treturn;\n\n\tspin_lock_irqsave(&fibptr->dev->fib_lock, flags);\n\tif (unlikely(fibptr->flags & FIB_CONTEXT_FLAG_TIMED_OUT))\n\t\taac_config.fib_timeouts++;\n\tif (!(fibptr->flags & FIB_CONTEXT_FLAG_NATIVE_HBA) &&\n\t\tfibptr->hw_fib_va->header.XferState != 0) {\n\t\tprintk(KERN_WARNING \"aac_fib_free, XferState != 0, fibptr = 0x%p, XferState = 0x%x\\n\",\n\t\t\t (void*)fibptr,\n\t\t\t le32_to_cpu(fibptr->hw_fib_va->header.XferState));\n\t}\n\tfibptr->next = fibptr->dev->free_fib;\n\tfibptr->dev->free_fib = fibptr;\n\tspin_unlock_irqrestore(&fibptr->dev->fib_lock, flags);\n}\n\n \n\nvoid aac_fib_init(struct fib *fibptr)\n{\n\tstruct hw_fib *hw_fib = fibptr->hw_fib_va;\n\n\tmemset(&hw_fib->header, 0, sizeof(struct aac_fibhdr));\n\thw_fib->header.StructType = FIB_MAGIC;\n\thw_fib->header.Size = cpu_to_le16(fibptr->dev->max_fib_size);\n\thw_fib->header.XferState = cpu_to_le32(HostOwned | FibInitialized | FibEmpty | FastResponseCapable);\n\thw_fib->header.u.ReceiverFibAddress = cpu_to_le32(fibptr->hw_fib_pa);\n\thw_fib->header.SenderSize = cpu_to_le16(fibptr->dev->max_fib_size);\n}\n\n \n\nstatic void fib_dealloc(struct fib * fibptr)\n{\n\tstruct hw_fib *hw_fib = fibptr->hw_fib_va;\n\thw_fib->header.XferState = 0;\n}\n\n \n\n \n\nstatic int aac_get_entry (struct aac_dev * dev, u32 qid, struct aac_entry **entry, u32 * index, unsigned long *nonotify)\n{\n\tstruct aac_queue * q;\n\tunsigned long idx;\n\n\t \n\n\tq = &dev->queues->queue[qid];\n\n\tidx = *index = le32_to_cpu(*(q->headers.producer));\n\t \n\tif (idx != le32_to_cpu(*(q->headers.consumer))) {\n\t\tif (--idx == 0) {\n\t\t\tif (qid == AdapNormCmdQueue)\n\t\t\t\tidx = ADAP_NORM_CMD_ENTRIES;\n\t\t\telse\n\t\t\t\tidx = ADAP_NORM_RESP_ENTRIES;\n\t\t}\n\t\tif (idx != le32_to_cpu(*(q->headers.consumer)))\n\t\t\t*nonotify = 1;\n\t}\n\n\tif (qid == AdapNormCmdQueue) {\n\t\tif (*index >= ADAP_NORM_CMD_ENTRIES)\n\t\t\t*index = 0;  \n\t} else {\n\t\tif (*index >= ADAP_NORM_RESP_ENTRIES)\n\t\t\t*index = 0;  \n\t}\n\n\t \n\tif ((*index + 1) == le32_to_cpu(*(q->headers.consumer))) {\n\t\tprintk(KERN_WARNING \"Queue %d full, %u outstanding.\\n\",\n\t\t\t\tqid, atomic_read(&q->numpending));\n\t\treturn 0;\n\t} else {\n\t\t*entry = q->base + *index;\n\t\treturn 1;\n\t}\n}\n\n \n\nint aac_queue_get(struct aac_dev * dev, u32 * index, u32 qid, struct hw_fib * hw_fib, int wait, struct fib * fibptr, unsigned long *nonotify)\n{\n\tstruct aac_entry * entry = NULL;\n\tint map = 0;\n\n\tif (qid == AdapNormCmdQueue) {\n\t\t \n\t\twhile (!aac_get_entry(dev, qid, &entry, index, nonotify)) {\n\t\t\tprintk(KERN_ERR \"GetEntries failed\\n\");\n\t\t}\n\t\t \n\t\tentry->size = cpu_to_le32(le16_to_cpu(hw_fib->header.Size));\n\t\tmap = 1;\n\t} else {\n\t\twhile (!aac_get_entry(dev, qid, &entry, index, nonotify)) {\n\t\t\t \n\t\t}\n\t\t \n\t\tentry->size = cpu_to_le32(le16_to_cpu(hw_fib->header.Size));\n\t\tentry->addr = hw_fib->header.SenderFibAddress;\n\t\t\t \n\t\thw_fib->header.u.ReceiverFibAddress = hw_fib->header.SenderFibAddress;   \n\t\tmap = 0;\n\t}\n\t \n\tif (map)\n\t\tentry->addr = cpu_to_le32(fibptr->hw_fib_pa);\n\treturn 0;\n}\n\n \n\n \n\nint aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,\n\t\tint priority, int wait, int reply, fib_callback callback,\n\t\tvoid *callback_data)\n{\n\tstruct aac_dev * dev = fibptr->dev;\n\tstruct hw_fib * hw_fib = fibptr->hw_fib_va;\n\tunsigned long flags = 0;\n\tunsigned long mflags = 0;\n\tunsigned long sflags = 0;\n\n\tif (!(hw_fib->header.XferState & cpu_to_le32(HostOwned)))\n\t\treturn -EBUSY;\n\n\tif (hw_fib->header.XferState & cpu_to_le32(AdapterProcessed))\n\t\treturn -EINVAL;\n\n\t \n\tfibptr->flags = 0;\n\tif (wait && !reply) {\n\t\treturn -EINVAL;\n\t} else if (!wait && reply) {\n\t\thw_fib->header.XferState |= cpu_to_le32(Async | ResponseExpected);\n\t\tFIB_COUNTER_INCREMENT(aac_config.AsyncSent);\n\t} else if (!wait && !reply) {\n\t\thw_fib->header.XferState |= cpu_to_le32(NoResponseExpected);\n\t\tFIB_COUNTER_INCREMENT(aac_config.NoResponseSent);\n\t} else if (wait && reply) {\n\t\thw_fib->header.XferState |= cpu_to_le32(ResponseExpected);\n\t\tFIB_COUNTER_INCREMENT(aac_config.NormalSent);\n\t}\n\t \n\n\thw_fib->header.SenderFibAddress =\n\t\tcpu_to_le32(((u32)(fibptr - dev->fibs)) << 2);\n\n\t \n\thw_fib->header.Handle =\n\t\tcpu_to_le32((((u32)(fibptr - dev->fibs)) << 2) + 1);\n\n\t \n\thw_fib->header.Command = cpu_to_le16(command);\n\thw_fib->header.XferState |= cpu_to_le32(SentFromHost);\n\t \n\thw_fib->header.Size = cpu_to_le16(sizeof(struct aac_fibhdr) + size);\n\tif (le16_to_cpu(hw_fib->header.Size) > le16_to_cpu(hw_fib->header.SenderSize)) {\n\t\treturn -EMSGSIZE;\n\t}\n\t \n\thw_fib->header.XferState |= cpu_to_le32(NormalPriority);\n\n\t \n\tif (!wait) {\n\t\tfibptr->callback = callback;\n\t\tfibptr->callback_data = callback_data;\n\t\tfibptr->flags = FIB_CONTEXT_FLAG;\n\t}\n\n\tfibptr->done = 0;\n\n\tFIB_COUNTER_INCREMENT(aac_config.FibsSent);\n\n\tdprintk((KERN_DEBUG \"Fib contents:.\\n\"));\n\tdprintk((KERN_DEBUG \"  Command =               %d.\\n\", le32_to_cpu(hw_fib->header.Command)));\n\tdprintk((KERN_DEBUG \"  SubCommand =            %d.\\n\", le32_to_cpu(((struct aac_query_mount *)fib_data(fibptr))->command)));\n\tdprintk((KERN_DEBUG \"  XferState  =            %x.\\n\", le32_to_cpu(hw_fib->header.XferState)));\n\tdprintk((KERN_DEBUG \"  hw_fib va being sent=%p\\n\",fibptr->hw_fib_va));\n\tdprintk((KERN_DEBUG \"  hw_fib pa being sent=%lx\\n\",(ulong)fibptr->hw_fib_pa));\n\tdprintk((KERN_DEBUG \"  fib being sent=%p\\n\",fibptr));\n\n\tif (!dev->queues)\n\t\treturn -EBUSY;\n\n\tif (wait) {\n\n\t\tspin_lock_irqsave(&dev->manage_lock, mflags);\n\t\tif (dev->management_fib_count >= AAC_NUM_MGT_FIB) {\n\t\t\tprintk(KERN_INFO \"No management Fibs Available:%d\\n\",\n\t\t\t\t\t\tdev->management_fib_count);\n\t\t\tspin_unlock_irqrestore(&dev->manage_lock, mflags);\n\t\t\treturn -EBUSY;\n\t\t}\n\t\tdev->management_fib_count++;\n\t\tspin_unlock_irqrestore(&dev->manage_lock, mflags);\n\t\tspin_lock_irqsave(&fibptr->event_lock, flags);\n\t}\n\n\tif (dev->sync_mode) {\n\t\tif (wait)\n\t\t\tspin_unlock_irqrestore(&fibptr->event_lock, flags);\n\t\tspin_lock_irqsave(&dev->sync_lock, sflags);\n\t\tif (dev->sync_fib) {\n\t\t\tlist_add_tail(&fibptr->fiblink, &dev->sync_fib_list);\n\t\t\tspin_unlock_irqrestore(&dev->sync_lock, sflags);\n\t\t} else {\n\t\t\tdev->sync_fib = fibptr;\n\t\t\tspin_unlock_irqrestore(&dev->sync_lock, sflags);\n\t\t\taac_adapter_sync_cmd(dev, SEND_SYNCHRONOUS_FIB,\n\t\t\t\t(u32)fibptr->hw_fib_pa, 0, 0, 0, 0, 0,\n\t\t\t\tNULL, NULL, NULL, NULL, NULL);\n\t\t}\n\t\tif (wait) {\n\t\t\tfibptr->flags |= FIB_CONTEXT_FLAG_WAIT;\n\t\t\tif (wait_for_completion_interruptible(&fibptr->event_wait)) {\n\t\t\t\tfibptr->flags &= ~FIB_CONTEXT_FLAG_WAIT;\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t\treturn -EINPROGRESS;\n\t}\n\n\tif (aac_adapter_deliver(fibptr) != 0) {\n\t\tprintk(KERN_ERR \"aac_fib_send: returned -EBUSY\\n\");\n\t\tif (wait) {\n\t\t\tspin_unlock_irqrestore(&fibptr->event_lock, flags);\n\t\t\tspin_lock_irqsave(&dev->manage_lock, mflags);\n\t\t\tdev->management_fib_count--;\n\t\t\tspin_unlock_irqrestore(&dev->manage_lock, mflags);\n\t\t}\n\t\treturn -EBUSY;\n\t}\n\n\n\t \n\n\tif (wait) {\n\t\tspin_unlock_irqrestore(&fibptr->event_lock, flags);\n\t\t \n\t\tif (wait < 0) {\n\t\t\t \n\t\t\tunsigned long timeout = jiffies + (180 * HZ);  \n\t\t\twhile (!try_wait_for_completion(&fibptr->event_wait)) {\n\t\t\t\tint blink;\n\t\t\t\tif (time_is_before_eq_jiffies(timeout)) {\n\t\t\t\t\tstruct aac_queue * q = &dev->queues->queue[AdapNormCmdQueue];\n\t\t\t\t\tatomic_dec(&q->numpending);\n\t\t\t\t\tif (wait == -1) {\n\t        \t\t\t\tprintk(KERN_ERR \"aacraid: aac_fib_send: first asynchronous command timed out.\\n\"\n\t\t\t\t\t\t  \"Usually a result of a PCI interrupt routing problem;\\n\"\n\t\t\t\t\t\t  \"update mother board BIOS or consider utilizing one of\\n\"\n\t\t\t\t\t\t  \"the SAFE mode kernel options (acpi, apic etc)\\n\");\n\t\t\t\t\t}\n\t\t\t\t\treturn -ETIMEDOUT;\n\t\t\t\t}\n\n\t\t\t\tif (unlikely(aac_pci_offline(dev)))\n\t\t\t\t\treturn -EFAULT;\n\n\t\t\t\tif ((blink = aac_adapter_check_health(dev)) > 0) {\n\t\t\t\t\tif (wait == -1) {\n\t        \t\t\t\tprintk(KERN_ERR \"aacraid: aac_fib_send: adapter blinkLED 0x%x.\\n\"\n\t\t\t\t\t\t  \"Usually a result of a serious unrecoverable hardware problem\\n\",\n\t\t\t\t\t\t  blink);\n\t\t\t\t\t}\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\tschedule();\n\t\t\t}\n\t\t} else if (wait_for_completion_interruptible(&fibptr->event_wait)) {\n\t\t\t \n\t\t}\n\n\t\tspin_lock_irqsave(&fibptr->event_lock, flags);\n\t\tif (fibptr->done == 0) {\n\t\t\tfibptr->done = 2;  \n\t\t\tspin_unlock_irqrestore(&fibptr->event_lock, flags);\n\t\t\treturn -ERESTARTSYS;\n\t\t}\n\t\tspin_unlock_irqrestore(&fibptr->event_lock, flags);\n\t\tBUG_ON(fibptr->done == 0);\n\n\t\tif(unlikely(fibptr->flags & FIB_CONTEXT_FLAG_TIMED_OUT))\n\t\t\treturn -ETIMEDOUT;\n\t\treturn 0;\n\t}\n\t \n\tif (reply)\n\t\treturn -EINPROGRESS;\n\telse\n\t\treturn 0;\n}\n\nint aac_hba_send(u8 command, struct fib *fibptr, fib_callback callback,\n\t\tvoid *callback_data)\n{\n\tstruct aac_dev *dev = fibptr->dev;\n\tint wait;\n\tunsigned long flags = 0;\n\tunsigned long mflags = 0;\n\tstruct aac_hba_cmd_req *hbacmd = (struct aac_hba_cmd_req *)\n\t\t\tfibptr->hw_fib_va;\n\n\tfibptr->flags = (FIB_CONTEXT_FLAG | FIB_CONTEXT_FLAG_NATIVE_HBA);\n\tif (callback) {\n\t\twait = 0;\n\t\tfibptr->callback = callback;\n\t\tfibptr->callback_data = callback_data;\n\t} else\n\t\twait = 1;\n\n\n\thbacmd->iu_type = command;\n\n\tif (command == HBA_IU_TYPE_SCSI_CMD_REQ) {\n\t\t \n\t\thbacmd->request_id =\n\t\t\tcpu_to_le32((((u32)(fibptr - dev->fibs)) << 2) + 1);\n\t\tfibptr->flags |= FIB_CONTEXT_FLAG_SCSI_CMD;\n\t} else\n\t\treturn -EINVAL;\n\n\n\tif (wait) {\n\t\tspin_lock_irqsave(&dev->manage_lock, mflags);\n\t\tif (dev->management_fib_count >= AAC_NUM_MGT_FIB) {\n\t\t\tspin_unlock_irqrestore(&dev->manage_lock, mflags);\n\t\t\treturn -EBUSY;\n\t\t}\n\t\tdev->management_fib_count++;\n\t\tspin_unlock_irqrestore(&dev->manage_lock, mflags);\n\t\tspin_lock_irqsave(&fibptr->event_lock, flags);\n\t}\n\n\tif (aac_adapter_deliver(fibptr) != 0) {\n\t\tif (wait) {\n\t\t\tspin_unlock_irqrestore(&fibptr->event_lock, flags);\n\t\t\tspin_lock_irqsave(&dev->manage_lock, mflags);\n\t\t\tdev->management_fib_count--;\n\t\t\tspin_unlock_irqrestore(&dev->manage_lock, mflags);\n\t\t}\n\t\treturn -EBUSY;\n\t}\n\tFIB_COUNTER_INCREMENT(aac_config.NativeSent);\n\n\tif (wait) {\n\n\t\tspin_unlock_irqrestore(&fibptr->event_lock, flags);\n\n\t\tif (unlikely(aac_pci_offline(dev)))\n\t\t\treturn -EFAULT;\n\n\t\tfibptr->flags |= FIB_CONTEXT_FLAG_WAIT;\n\t\tif (wait_for_completion_interruptible(&fibptr->event_wait))\n\t\t\tfibptr->done = 2;\n\t\tfibptr->flags &= ~(FIB_CONTEXT_FLAG_WAIT);\n\n\t\tspin_lock_irqsave(&fibptr->event_lock, flags);\n\t\tif ((fibptr->done == 0) || (fibptr->done == 2)) {\n\t\t\tfibptr->done = 2;  \n\t\t\tspin_unlock_irqrestore(&fibptr->event_lock, flags);\n\t\t\treturn -ERESTARTSYS;\n\t\t}\n\t\tspin_unlock_irqrestore(&fibptr->event_lock, flags);\n\t\tWARN_ON(fibptr->done == 0);\n\n\t\tif (unlikely(fibptr->flags & FIB_CONTEXT_FLAG_TIMED_OUT))\n\t\t\treturn -ETIMEDOUT;\n\n\t\treturn 0;\n\t}\n\n\treturn -EINPROGRESS;\n}\n\n \n\nint aac_consumer_get(struct aac_dev * dev, struct aac_queue * q, struct aac_entry **entry)\n{\n\tu32 index;\n\tint status;\n\tif (le32_to_cpu(*q->headers.producer) == le32_to_cpu(*q->headers.consumer)) {\n\t\tstatus = 0;\n\t} else {\n\t\t \n\t\tif (le32_to_cpu(*q->headers.consumer) >= q->entries)\n\t\t\tindex = 0;\n\t\telse\n\t\t\tindex = le32_to_cpu(*q->headers.consumer);\n\t\t*entry = q->base + index;\n\t\tstatus = 1;\n\t}\n\treturn(status);\n}\n\n \n\nvoid aac_consumer_free(struct aac_dev * dev, struct aac_queue *q, u32 qid)\n{\n\tint wasfull = 0;\n\tu32 notify;\n\n\tif ((le32_to_cpu(*q->headers.producer)+1) == le32_to_cpu(*q->headers.consumer))\n\t\twasfull = 1;\n\n\tif (le32_to_cpu(*q->headers.consumer) >= q->entries)\n\t\t*q->headers.consumer = cpu_to_le32(1);\n\telse\n\t\tle32_add_cpu(q->headers.consumer, 1);\n\n\tif (wasfull) {\n\t\tswitch (qid) {\n\n\t\tcase HostNormCmdQueue:\n\t\t\tnotify = HostNormCmdNotFull;\n\t\t\tbreak;\n\t\tcase HostNormRespQueue:\n\t\t\tnotify = HostNormRespNotFull;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t\treturn;\n\t\t}\n\t\taac_adapter_notify(dev, notify);\n\t}\n}\n\n \n\nint aac_fib_adapter_complete(struct fib *fibptr, unsigned short size)\n{\n\tstruct hw_fib * hw_fib = fibptr->hw_fib_va;\n\tstruct aac_dev * dev = fibptr->dev;\n\tstruct aac_queue * q;\n\tunsigned long nointr = 0;\n\tunsigned long qflags;\n\n\tif (dev->comm_interface == AAC_COMM_MESSAGE_TYPE1 ||\n\t\tdev->comm_interface == AAC_COMM_MESSAGE_TYPE2 ||\n\t\tdev->comm_interface == AAC_COMM_MESSAGE_TYPE3) {\n\t\tkfree(hw_fib);\n\t\treturn 0;\n\t}\n\n\tif (hw_fib->header.XferState == 0) {\n\t\tif (dev->comm_interface == AAC_COMM_MESSAGE)\n\t\t\tkfree(hw_fib);\n\t\treturn 0;\n\t}\n\t \n\tif (hw_fib->header.StructType != FIB_MAGIC &&\n\t    hw_fib->header.StructType != FIB_MAGIC2 &&\n\t    hw_fib->header.StructType != FIB_MAGIC2_64) {\n\t\tif (dev->comm_interface == AAC_COMM_MESSAGE)\n\t\t\tkfree(hw_fib);\n\t\treturn -EINVAL;\n\t}\n\t \n\tif (hw_fib->header.XferState & cpu_to_le32(SentFromAdapter)) {\n\t\tif (dev->comm_interface == AAC_COMM_MESSAGE) {\n\t\t\tkfree (hw_fib);\n\t\t} else {\n\t\t\tu32 index;\n\t\t\thw_fib->header.XferState |= cpu_to_le32(HostProcessed);\n\t\t\tif (size) {\n\t\t\t\tsize += sizeof(struct aac_fibhdr);\n\t\t\t\tif (size > le16_to_cpu(hw_fib->header.SenderSize))\n\t\t\t\t\treturn -EMSGSIZE;\n\t\t\t\thw_fib->header.Size = cpu_to_le16(size);\n\t\t\t}\n\t\t\tq = &dev->queues->queue[AdapNormRespQueue];\n\t\t\tspin_lock_irqsave(q->lock, qflags);\n\t\t\taac_queue_get(dev, &index, AdapNormRespQueue, hw_fib, 1, NULL, &nointr);\n\t\t\t*(q->headers.producer) = cpu_to_le32(index + 1);\n\t\t\tspin_unlock_irqrestore(q->lock, qflags);\n\t\t\tif (!(nointr & (int)aac_config.irq_mod))\n\t\t\t\taac_adapter_notify(dev, AdapNormRespQueue);\n\t\t}\n\t} else {\n\t\tprintk(KERN_WARNING \"aac_fib_adapter_complete: \"\n\t\t\t\"Unknown xferstate detected.\\n\");\n\t\tBUG();\n\t}\n\treturn 0;\n}\n\n \n\nint aac_fib_complete(struct fib *fibptr)\n{\n\tstruct hw_fib * hw_fib = fibptr->hw_fib_va;\n\n\tif (fibptr->flags & FIB_CONTEXT_FLAG_NATIVE_HBA) {\n\t\tfib_dealloc(fibptr);\n\t\treturn 0;\n\t}\n\n\t \n\n\tif (hw_fib->header.XferState == 0 || fibptr->done == 2)\n\t\treturn 0;\n\t \n\n\tif (hw_fib->header.StructType != FIB_MAGIC &&\n\t    hw_fib->header.StructType != FIB_MAGIC2 &&\n\t    hw_fib->header.StructType != FIB_MAGIC2_64)\n\t\treturn -EINVAL;\n\t \n\n\tif((hw_fib->header.XferState & cpu_to_le32(SentFromHost)) &&\n\t\t(hw_fib->header.XferState & cpu_to_le32(AdapterProcessed)))\n\t{\n\t\tfib_dealloc(fibptr);\n\t}\n\telse if(hw_fib->header.XferState & cpu_to_le32(SentFromHost))\n\t{\n\t\t \n\t\tfib_dealloc(fibptr);\n\t} else if(hw_fib->header.XferState & cpu_to_le32(HostOwned)) {\n\t\tfib_dealloc(fibptr);\n\t} else {\n\t\tBUG();\n\t}\n\treturn 0;\n}\n\n \n\nvoid aac_printf(struct aac_dev *dev, u32 val)\n{\n\tchar *cp = dev->printfbuf;\n\tif (dev->printf_enabled)\n\t{\n\t\tint length = val & 0xffff;\n\t\tint level = (val >> 16) & 0xffff;\n\n\t\t \n\t\tif (length > 255)\n\t\t\tlength = 255;\n\t\tif (cp[length] != 0)\n\t\t\tcp[length] = 0;\n\t\tif (level == LOG_AAC_HIGH_ERROR)\n\t\t\tprintk(KERN_WARNING \"%s:%s\", dev->name, cp);\n\t\telse\n\t\t\tprintk(KERN_INFO \"%s:%s\", dev->name, cp);\n\t}\n\tmemset(cp, 0, 256);\n}\n\nstatic inline int aac_aif_data(struct aac_aifcmd *aifcmd, uint32_t index)\n{\n\treturn le32_to_cpu(((__le32 *)aifcmd->data)[index]);\n}\n\n\nstatic void aac_handle_aif_bu(struct aac_dev *dev, struct aac_aifcmd *aifcmd)\n{\n\tswitch (aac_aif_data(aifcmd, 1)) {\n\tcase AifBuCacheDataLoss:\n\t\tif (aac_aif_data(aifcmd, 2))\n\t\t\tdev_info(&dev->pdev->dev, \"Backup unit had cache data loss - [%d]\\n\",\n\t\t\taac_aif_data(aifcmd, 2));\n\t\telse\n\t\t\tdev_info(&dev->pdev->dev, \"Backup Unit had cache data loss\\n\");\n\t\tbreak;\n\tcase AifBuCacheDataRecover:\n\t\tif (aac_aif_data(aifcmd, 2))\n\t\t\tdev_info(&dev->pdev->dev, \"DDR cache data recovered successfully - [%d]\\n\",\n\t\t\taac_aif_data(aifcmd, 2));\n\t\telse\n\t\t\tdev_info(&dev->pdev->dev, \"DDR cache data recovered successfully\\n\");\n\t\tbreak;\n\t}\n}\n\n#define AIF_SNIFF_TIMEOUT\t(500*HZ)\n \nstatic void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)\n{\n\tstruct hw_fib * hw_fib = fibptr->hw_fib_va;\n\tstruct aac_aifcmd * aifcmd = (struct aac_aifcmd *)hw_fib->data;\n\tu32 channel, id, lun, container;\n\tstruct scsi_device *device;\n\tenum {\n\t\tNOTHING,\n\t\tDELETE,\n\t\tADD,\n\t\tCHANGE\n\t} device_config_needed = NOTHING;\n\n\t \n\n\tif (!dev || !dev->fsa_dev)\n\t\treturn;\n\tcontainer = channel = id = lun = (u32)-1;\n\n\t \n\tswitch (le32_to_cpu(aifcmd->command)) {\n\tcase AifCmdDriverNotify:\n\t\tswitch (le32_to_cpu(((__le32 *)aifcmd->data)[0])) {\n\t\tcase AifRawDeviceRemove:\n\t\t\tcontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\n\t\t\tif ((container >> 28)) {\n\t\t\t\tcontainer = (u32)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tchannel = (container >> 24) & 0xF;\n\t\t\tif (channel >= dev->maximum_num_channels) {\n\t\t\t\tcontainer = (u32)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tid = container & 0xFFFF;\n\t\t\tif (id >= dev->maximum_num_physicals) {\n\t\t\t\tcontainer = (u32)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tlun = (container >> 16) & 0xFF;\n\t\t\tcontainer = (u32)-1;\n\t\t\tchannel = aac_phys_to_logical(channel);\n\t\t\tdevice_config_needed = DELETE;\n\t\t\tbreak;\n\n\t\t \n\t\tcase AifDenMorphComplete:\n\t\tcase AifDenVolumeExtendComplete:\n\t\t\tcontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\n\t\t\tif (container >= dev->maximum_num_containers)\n\t\t\t\tbreak;\n\n\t\t\t \n\n\t\t\tif ((dev != NULL) && (dev->scsi_host_ptr != NULL)) {\n\t\t\t\tdevice = scsi_device_lookup(dev->scsi_host_ptr,\n\t\t\t\t\tCONTAINER_TO_CHANNEL(container),\n\t\t\t\t\tCONTAINER_TO_ID(container),\n\t\t\t\t\tCONTAINER_TO_LUN(container));\n\t\t\t\tif (device) {\n\t\t\t\t\tdev->fsa_dev[container].config_needed = CHANGE;\n\t\t\t\t\tdev->fsa_dev[container].config_waiting_on = AifEnConfigChange;\n\t\t\t\t\tdev->fsa_dev[container].config_waiting_stamp = jiffies;\n\t\t\t\t\tscsi_device_put(device);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (container != (u32)-1) {\n\t\t\tif (container >= dev->maximum_num_containers)\n\t\t\t\tbreak;\n\t\t\tif ((dev->fsa_dev[container].config_waiting_on ==\n\t\t\t    le32_to_cpu(*(__le32 *)aifcmd->data)) &&\n\t\t\t time_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\n\t\t\t\tdev->fsa_dev[container].config_waiting_on = 0;\n\t\t} else for (container = 0;\n\t\t    container < dev->maximum_num_containers; ++container) {\n\t\t\tif ((dev->fsa_dev[container].config_waiting_on ==\n\t\t\t    le32_to_cpu(*(__le32 *)aifcmd->data)) &&\n\t\t\t time_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\n\t\t\t\tdev->fsa_dev[container].config_waiting_on = 0;\n\t\t}\n\t\tbreak;\n\n\tcase AifCmdEventNotify:\n\t\tswitch (le32_to_cpu(((__le32 *)aifcmd->data)[0])) {\n\t\tcase AifEnBatteryEvent:\n\t\t\tdev->cache_protected =\n\t\t\t\t(((__le32 *)aifcmd->data)[1] == cpu_to_le32(3));\n\t\t\tbreak;\n\t\t \n\t\tcase AifEnAddContainer:\n\t\t\tcontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\n\t\t\tif (container >= dev->maximum_num_containers)\n\t\t\t\tbreak;\n\t\t\tdev->fsa_dev[container].config_needed = ADD;\n\t\t\tdev->fsa_dev[container].config_waiting_on =\n\t\t\t\tAifEnConfigChange;\n\t\t\tdev->fsa_dev[container].config_waiting_stamp = jiffies;\n\t\t\tbreak;\n\n\t\t \n\t\tcase AifEnDeleteContainer:\n\t\t\tcontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\n\t\t\tif (container >= dev->maximum_num_containers)\n\t\t\t\tbreak;\n\t\t\tdev->fsa_dev[container].config_needed = DELETE;\n\t\t\tdev->fsa_dev[container].config_waiting_on =\n\t\t\t\tAifEnConfigChange;\n\t\t\tdev->fsa_dev[container].config_waiting_stamp = jiffies;\n\t\t\tbreak;\n\n\t\t \n\t\tcase AifEnContainerChange:\n\t\t\tcontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\n\t\t\tif (container >= dev->maximum_num_containers)\n\t\t\t\tbreak;\n\t\t\tif (dev->fsa_dev[container].config_waiting_on &&\n\t\t\t time_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\n\t\t\t\tbreak;\n\t\t\tdev->fsa_dev[container].config_needed = CHANGE;\n\t\t\tdev->fsa_dev[container].config_waiting_on =\n\t\t\t\tAifEnConfigChange;\n\t\t\tdev->fsa_dev[container].config_waiting_stamp = jiffies;\n\t\t\tbreak;\n\n\t\tcase AifEnConfigChange:\n\t\t\tbreak;\n\n\t\tcase AifEnAddJBOD:\n\t\tcase AifEnDeleteJBOD:\n\t\t\tcontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\n\t\t\tif ((container >> 28)) {\n\t\t\t\tcontainer = (u32)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tchannel = (container >> 24) & 0xF;\n\t\t\tif (channel >= dev->maximum_num_channels) {\n\t\t\t\tcontainer = (u32)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tid = container & 0xFFFF;\n\t\t\tif (id >= dev->maximum_num_physicals) {\n\t\t\t\tcontainer = (u32)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tlun = (container >> 16) & 0xFF;\n\t\t\tcontainer = (u32)-1;\n\t\t\tchannel = aac_phys_to_logical(channel);\n\t\t\tdevice_config_needed =\n\t\t\t  (((__le32 *)aifcmd->data)[0] ==\n\t\t\t    cpu_to_le32(AifEnAddJBOD)) ? ADD : DELETE;\n\t\t\tif (device_config_needed == ADD) {\n\t\t\t\tdevice = scsi_device_lookup(dev->scsi_host_ptr,\n\t\t\t\t\tchannel,\n\t\t\t\t\tid,\n\t\t\t\t\tlun);\n\t\t\t\tif (device) {\n\t\t\t\t\tscsi_remove_device(device);\n\t\t\t\t\tscsi_device_put(device);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase AifEnEnclosureManagement:\n\t\t\t \n\t\t\tif (dev->jbod)\n\t\t\t\tbreak;\n\t\t\tswitch (le32_to_cpu(((__le32 *)aifcmd->data)[3])) {\n\t\t\tcase EM_DRIVE_INSERTION:\n\t\t\tcase EM_DRIVE_REMOVAL:\n\t\t\tcase EM_SES_DRIVE_INSERTION:\n\t\t\tcase EM_SES_DRIVE_REMOVAL:\n\t\t\t\tcontainer = le32_to_cpu(\n\t\t\t\t\t((__le32 *)aifcmd->data)[2]);\n\t\t\t\tif ((container >> 28)) {\n\t\t\t\t\tcontainer = (u32)-1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tchannel = (container >> 24) & 0xF;\n\t\t\t\tif (channel >= dev->maximum_num_channels) {\n\t\t\t\t\tcontainer = (u32)-1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tid = container & 0xFFFF;\n\t\t\t\tlun = (container >> 16) & 0xFF;\n\t\t\t\tcontainer = (u32)-1;\n\t\t\t\tif (id >= dev->maximum_num_physicals) {\n\t\t\t\t\t \n\t\t\t\t\tif ((0x2000 <= id) || lun || channel ||\n\t\t\t\t\t  ((channel = (id >> 7) & 0x3F) >=\n\t\t\t\t\t  dev->maximum_num_channels))\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tlun = (id >> 4) & 7;\n\t\t\t\t\tid &= 0xF;\n\t\t\t\t}\n\t\t\t\tchannel = aac_phys_to_logical(channel);\n\t\t\t\tdevice_config_needed =\n\t\t\t\t  ((((__le32 *)aifcmd->data)[3]\n\t\t\t\t    == cpu_to_le32(EM_DRIVE_INSERTION)) ||\n\t\t\t\t    (((__le32 *)aifcmd->data)[3]\n\t\t\t\t    == cpu_to_le32(EM_SES_DRIVE_INSERTION))) ?\n\t\t\t\t  ADD : DELETE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase AifBuManagerEvent:\n\t\t\taac_handle_aif_bu(dev, aifcmd);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (container != (u32)-1) {\n\t\t\tif (container >= dev->maximum_num_containers)\n\t\t\t\tbreak;\n\t\t\tif ((dev->fsa_dev[container].config_waiting_on ==\n\t\t\t    le32_to_cpu(*(__le32 *)aifcmd->data)) &&\n\t\t\t time_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\n\t\t\t\tdev->fsa_dev[container].config_waiting_on = 0;\n\t\t} else for (container = 0;\n\t\t    container < dev->maximum_num_containers; ++container) {\n\t\t\tif ((dev->fsa_dev[container].config_waiting_on ==\n\t\t\t    le32_to_cpu(*(__le32 *)aifcmd->data)) &&\n\t\t\t time_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\n\t\t\t\tdev->fsa_dev[container].config_waiting_on = 0;\n\t\t}\n\t\tbreak;\n\n\tcase AifCmdJobProgress:\n\t\t \n\n\t\tif (((__le32 *)aifcmd->data)[1] == cpu_to_le32(AifJobCtrZero) &&\n\t\t    (((__le32 *)aifcmd->data)[6] == ((__le32 *)aifcmd->data)[5] ||\n\t\t     ((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsSuccess))) {\n\t\t\tfor (container = 0;\n\t\t\t    container < dev->maximum_num_containers;\n\t\t\t    ++container) {\n\t\t\t\t \n\t\t\t\tdev->fsa_dev[container].config_waiting_on =\n\t\t\t\t\tAifEnContainerChange;\n\t\t\t\tdev->fsa_dev[container].config_needed = ADD;\n\t\t\t\tdev->fsa_dev[container].config_waiting_stamp =\n\t\t\t\t\tjiffies;\n\t\t\t}\n\t\t}\n\t\tif (((__le32 *)aifcmd->data)[1] == cpu_to_le32(AifJobCtrZero) &&\n\t\t    ((__le32 *)aifcmd->data)[6] == 0 &&\n\t\t    ((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsRunning)) {\n\t\t\tfor (container = 0;\n\t\t\t    container < dev->maximum_num_containers;\n\t\t\t    ++container) {\n\t\t\t\t \n\t\t\t\tdev->fsa_dev[container].config_waiting_on =\n\t\t\t\t\tAifEnContainerChange;\n\t\t\t\tdev->fsa_dev[container].config_needed = DELETE;\n\t\t\t\tdev->fsa_dev[container].config_waiting_stamp =\n\t\t\t\t\tjiffies;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\n\tcontainer = 0;\nretry_next:\n\tif (device_config_needed == NOTHING) {\n\t\tfor (; container < dev->maximum_num_containers; ++container) {\n\t\t\tif ((dev->fsa_dev[container].config_waiting_on == 0) &&\n\t\t\t    (dev->fsa_dev[container].config_needed != NOTHING) &&\n\t\t\t    time_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT)) {\n\t\t\t\tdevice_config_needed =\n\t\t\t\t\tdev->fsa_dev[container].config_needed;\n\t\t\t\tdev->fsa_dev[container].config_needed = NOTHING;\n\t\t\t\tchannel = CONTAINER_TO_CHANNEL(container);\n\t\t\t\tid = CONTAINER_TO_ID(container);\n\t\t\t\tlun = CONTAINER_TO_LUN(container);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tif (device_config_needed == NOTHING)\n\t\treturn;\n\n\t \n\n\t \n\n\tif (!dev || !dev->scsi_host_ptr)\n\t\treturn;\n\t \n\tif ((channel == CONTAINER_CHANNEL) &&\n\t  (device_config_needed != NOTHING)) {\n\t\tif (dev->fsa_dev[container].valid == 1)\n\t\t\tdev->fsa_dev[container].valid = 2;\n\t\taac_probe_container(dev, container);\n\t}\n\tdevice = scsi_device_lookup(dev->scsi_host_ptr, channel, id, lun);\n\tif (device) {\n\t\tswitch (device_config_needed) {\n\t\tcase DELETE:\n#if (defined(AAC_DEBUG_INSTRUMENT_AIF_DELETE))\n\t\t\tscsi_remove_device(device);\n#else\n\t\t\tif (scsi_device_online(device)) {\n\t\t\t\tscsi_device_set_state(device, SDEV_OFFLINE);\n\t\t\t\tsdev_printk(KERN_INFO, device,\n\t\t\t\t\t\"Device offlined - %s\\n\",\n\t\t\t\t\t(channel == CONTAINER_CHANNEL) ?\n\t\t\t\t\t\t\"array deleted\" :\n\t\t\t\t\t\t\"enclosure services event\");\n\t\t\t}\n#endif\n\t\t\tbreak;\n\t\tcase ADD:\n\t\t\tif (!scsi_device_online(device)) {\n\t\t\t\tsdev_printk(KERN_INFO, device,\n\t\t\t\t\t\"Device online - %s\\n\",\n\t\t\t\t\t(channel == CONTAINER_CHANNEL) ?\n\t\t\t\t\t\t\"array created\" :\n\t\t\t\t\t\t\"enclosure services event\");\n\t\t\t\tscsi_device_set_state(device, SDEV_RUNNING);\n\t\t\t}\n\t\t\tfallthrough;\n\t\tcase CHANGE:\n\t\t\tif ((channel == CONTAINER_CHANNEL)\n\t\t\t && (!dev->fsa_dev[container].valid)) {\n#if (defined(AAC_DEBUG_INSTRUMENT_AIF_DELETE))\n\t\t\t\tscsi_remove_device(device);\n#else\n\t\t\t\tif (!scsi_device_online(device))\n\t\t\t\t\tbreak;\n\t\t\t\tscsi_device_set_state(device, SDEV_OFFLINE);\n\t\t\t\tsdev_printk(KERN_INFO, device,\n\t\t\t\t\t\"Device offlined - %s\\n\",\n\t\t\t\t\t\"array failed\");\n#endif\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tscsi_rescan_device(device);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tscsi_device_put(device);\n\t\tdevice_config_needed = NOTHING;\n\t}\n\tif (device_config_needed == ADD)\n\t\tscsi_add_device(dev->scsi_host_ptr, channel, id, lun);\n\tif (channel == CONTAINER_CHANNEL) {\n\t\tcontainer++;\n\t\tdevice_config_needed = NOTHING;\n\t\tgoto retry_next;\n\t}\n}\n\nstatic void aac_schedule_bus_scan(struct aac_dev *aac)\n{\n\tif (aac->sa_firmware)\n\t\taac_schedule_safw_scan_worker(aac);\n\telse\n\t\taac_schedule_src_reinit_aif_worker(aac);\n}\n\nstatic int _aac_reset_adapter(struct aac_dev *aac, int forced, u8 reset_type)\n{\n\tint index, quirks;\n\tint retval;\n\tstruct Scsi_Host *host = aac->scsi_host_ptr;\n\tint jafo = 0;\n\tint bled;\n\tu64 dmamask;\n\tint num_of_fibs = 0;\n\n\t \n\taac_adapter_disable_int(aac);\n\tif (aac->thread && aac->thread->pid != current->pid) {\n\t\tspin_unlock_irq(host->host_lock);\n\t\tkthread_stop(aac->thread);\n\t\taac->thread = NULL;\n\t\tjafo = 1;\n\t}\n\n\t \n\tbled = forced ? 0 : aac_adapter_check_health(aac);\n\tretval = aac_adapter_restart(aac, bled, reset_type);\n\n\tif (retval)\n\t\tgoto out;\n\n\t \n\tretval = 1;\n\tnum_of_fibs = aac->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB;\n\tfor (index = 0; index <  num_of_fibs; index++) {\n\n\t\tstruct fib *fib = &aac->fibs[index];\n\t\t__le32 XferState = fib->hw_fib_va->header.XferState;\n\t\tbool is_response_expected = false;\n\n\t\tif (!(XferState & cpu_to_le32(NoResponseExpected | Async)) &&\n\t\t   (XferState & cpu_to_le32(ResponseExpected)))\n\t\t\tis_response_expected = true;\n\n\t\tif (is_response_expected\n\t\t  || fib->flags & FIB_CONTEXT_FLAG_WAIT) {\n\t\t\tunsigned long flagv;\n\t\t\tspin_lock_irqsave(&fib->event_lock, flagv);\n\t\t\tcomplete(&fib->event_wait);\n\t\t\tspin_unlock_irqrestore(&fib->event_lock, flagv);\n\t\t\tschedule();\n\t\t\tretval = 0;\n\t\t}\n\t}\n\t \n\tif (retval == 0)\n\t\tssleep(2);\n\tindex = aac->cardtype;\n\n\t \n\taac_free_irq(aac);\n\taac_fib_map_free(aac);\n\tdma_free_coherent(&aac->pdev->dev, aac->comm_size, aac->comm_addr,\n\t\t\t  aac->comm_phys);\n\taac_adapter_ioremap(aac, 0);\n\taac->comm_addr = NULL;\n\taac->comm_phys = 0;\n\tkfree(aac->queues);\n\taac->queues = NULL;\n\tkfree(aac->fsa_dev);\n\taac->fsa_dev = NULL;\n\n\tdmamask = DMA_BIT_MASK(32);\n\tquirks = aac_get_driver_ident(index)->quirks;\n\tif (quirks & AAC_QUIRK_31BIT)\n\t\tretval = dma_set_mask(&aac->pdev->dev, dmamask);\n\telse if (!(quirks & AAC_QUIRK_SRC))\n\t\tretval = dma_set_mask(&aac->pdev->dev, dmamask);\n\telse\n\t\tretval = dma_set_coherent_mask(&aac->pdev->dev, dmamask);\n\n\tif (quirks & AAC_QUIRK_31BIT && !retval) {\n\t\tdmamask = DMA_BIT_MASK(31);\n\t\tretval = dma_set_coherent_mask(&aac->pdev->dev, dmamask);\n\t}\n\n\tif (retval)\n\t\tgoto out;\n\n\tif ((retval = (*(aac_get_driver_ident(index)->init))(aac)))\n\t\tgoto out;\n\n\tif (jafo) {\n\t\taac->thread = kthread_run(aac_command_thread, aac, \"%s\",\n\t\t\t\t\t  aac->name);\n\t\tif (IS_ERR(aac->thread)) {\n\t\t\tretval = PTR_ERR(aac->thread);\n\t\t\taac->thread = NULL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\t(void)aac_get_adapter_info(aac);\n\tif ((quirks & AAC_QUIRK_34SG) && (host->sg_tablesize > 34)) {\n\t\thost->sg_tablesize = 34;\n\t\thost->max_sectors = (host->sg_tablesize * 8) + 112;\n\t}\n\tif ((quirks & AAC_QUIRK_17SG) && (host->sg_tablesize > 17)) {\n\t\thost->sg_tablesize = 17;\n\t\thost->max_sectors = (host->sg_tablesize * 8) + 112;\n\t}\n\taac_get_config_status(aac, 1);\n\taac_get_containers(aac);\n\t \n\tscsi_host_complete_all_commands(host, DID_RESET);\n\n\tretval = 0;\nout:\n\taac->in_reset = 0;\n\n\t \n\tif (!retval && !is_kdump_kernel()) {\n\t\tdev_info(&aac->pdev->dev, \"Scheduling bus rescan\\n\");\n\t\taac_schedule_bus_scan(aac);\n\t}\n\n\tif (jafo) {\n\t\tspin_lock_irq(host->host_lock);\n\t}\n\treturn retval;\n}\n\nint aac_reset_adapter(struct aac_dev *aac, int forced, u8 reset_type)\n{\n\tunsigned long flagv = 0;\n\tint retval, unblock_retval;\n\tstruct Scsi_Host *host = aac->scsi_host_ptr;\n\tint bled;\n\n\tif (spin_trylock_irqsave(&aac->fib_lock, flagv) == 0)\n\t\treturn -EBUSY;\n\n\tif (aac->in_reset) {\n\t\tspin_unlock_irqrestore(&aac->fib_lock, flagv);\n\t\treturn -EBUSY;\n\t}\n\taac->in_reset = 1;\n\tspin_unlock_irqrestore(&aac->fib_lock, flagv);\n\n\t \n\tscsi_host_block(host);\n\n\t \n\tif (forced < 2)\n\t\taac_send_shutdown(aac);\n\tspin_lock_irqsave(host->host_lock, flagv);\n\tbled = forced ? forced :\n\t\t\t(aac_check_reset != 0 && aac_check_reset != 1);\n\tretval = _aac_reset_adapter(aac, bled, reset_type);\n\tspin_unlock_irqrestore(host->host_lock, flagv);\n\n\tunblock_retval = scsi_host_unblock(host, SDEV_RUNNING);\n\tif (!retval)\n\t\tretval = unblock_retval;\n\tif ((forced < 2) && (retval == -ENODEV)) {\n\t\t \n\t\tstruct fib * fibctx = aac_fib_alloc(aac);\n\t\tif (fibctx) {\n\t\t\tstruct aac_pause *cmd;\n\t\t\tint status;\n\n\t\t\taac_fib_init(fibctx);\n\n\t\t\tcmd = (struct aac_pause *) fib_data(fibctx);\n\n\t\t\tcmd->command = cpu_to_le32(VM_ContainerConfig);\n\t\t\tcmd->type = cpu_to_le32(CT_PAUSE_IO);\n\t\t\tcmd->timeout = cpu_to_le32(1);\n\t\t\tcmd->min = cpu_to_le32(1);\n\t\t\tcmd->noRescan = cpu_to_le32(1);\n\t\t\tcmd->count = cpu_to_le32(0);\n\n\t\t\tstatus = aac_fib_send(ContainerCommand,\n\t\t\t  fibctx,\n\t\t\t  sizeof(struct aac_pause),\n\t\t\t  FsaNormal,\n\t\t\t  -2  , 1,\n\t\t\t  NULL, NULL);\n\n\t\t\tif (status >= 0)\n\t\t\t\taac_fib_complete(fibctx);\n\t\t\t \n\t\t\tif (status != -ERESTARTSYS)\n\t\t\t\taac_fib_free(fibctx);\n\t\t}\n\t}\n\n\treturn retval;\n}\n\nint aac_check_health(struct aac_dev * aac)\n{\n\tint BlinkLED;\n\tunsigned long time_now, flagv = 0;\n\tstruct list_head * entry;\n\n\t \n\tif (spin_trylock_irqsave(&aac->fib_lock, flagv) == 0)\n\t\treturn 0;\n\n\tif (aac->in_reset || !(BlinkLED = aac_adapter_check_health(aac))) {\n\t\tspin_unlock_irqrestore(&aac->fib_lock, flagv);\n\t\treturn 0;  \n\t}\n\n\taac->in_reset = 1;\n\n\t \n\n\ttime_now = jiffies/HZ;\n\tentry = aac->fib_list.next;\n\n\t \n\twhile (entry != &aac->fib_list) {\n\t\t \n\t\tstruct aac_fib_context *fibctx = list_entry(entry, struct aac_fib_context, next);\n\t\tstruct hw_fib * hw_fib;\n\t\tstruct fib * fib;\n\t\t \n\t\tif (fibctx->count > 20) {\n\t\t\t \n\t\t\tu32 time_last = fibctx->jiffies;\n\t\t\t \n\t\t\tif ((time_now - time_last) > aif_timeout) {\n\t\t\t\tentry = entry->next;\n\t\t\t\taac_close_fib_context(aac, fibctx);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\t \n\t\thw_fib = kzalloc(sizeof(struct hw_fib), GFP_ATOMIC);\n\t\tfib = kzalloc(sizeof(struct fib), GFP_ATOMIC);\n\t\tif (fib && hw_fib) {\n\t\t\tstruct aac_aifcmd * aif;\n\n\t\t\tfib->hw_fib_va = hw_fib;\n\t\t\tfib->dev = aac;\n\t\t\taac_fib_init(fib);\n\t\t\tfib->type = FSAFS_NTC_FIB_CONTEXT;\n\t\t\tfib->size = sizeof (struct fib);\n\t\t\tfib->data = hw_fib->data;\n\t\t\taif = (struct aac_aifcmd *)hw_fib->data;\n\t\t\taif->command = cpu_to_le32(AifCmdEventNotify);\n\t\t\taif->seqnum = cpu_to_le32(0xFFFFFFFF);\n\t\t\t((__le32 *)aif->data)[0] = cpu_to_le32(AifEnExpEvent);\n\t\t\t((__le32 *)aif->data)[1] = cpu_to_le32(AifExeFirmwarePanic);\n\t\t\t((__le32 *)aif->data)[2] = cpu_to_le32(AifHighPriority);\n\t\t\t((__le32 *)aif->data)[3] = cpu_to_le32(BlinkLED);\n\n\t\t\t \n\t\t\tlist_add_tail(&fib->fiblink, &fibctx->fib_list);\n\t\t\tfibctx->count++;\n\t\t\t \n\t\t\tcomplete(&fibctx->completion);\n\t\t} else {\n\t\t\tprintk(KERN_WARNING \"aifd: didn't allocate NewFib.\\n\");\n\t\t\tkfree(fib);\n\t\t\tkfree(hw_fib);\n\t\t}\n\t\tentry = entry->next;\n\t}\n\n\tspin_unlock_irqrestore(&aac->fib_lock, flagv);\n\n\tif (BlinkLED < 0) {\n\t\tprintk(KERN_ERR \"%s: Host adapter is dead (or got a PCI error) %d\\n\",\n\t\t\t\taac->name, BlinkLED);\n\t\tgoto out;\n\t}\n\n\tprintk(KERN_ERR \"%s: Host adapter BLINK LED 0x%x\\n\", aac->name, BlinkLED);\n\nout:\n\taac->in_reset = 0;\n\treturn BlinkLED;\n}\n\nstatic inline int is_safw_raid_volume(struct aac_dev *aac, int bus, int target)\n{\n\treturn bus == CONTAINER_CHANNEL && target < aac->maximum_num_containers;\n}\n\nstatic struct scsi_device *aac_lookup_safw_scsi_device(struct aac_dev *dev,\n\t\t\t\t\t\t\t\tint bus,\n\t\t\t\t\t\t\t\tint target)\n{\n\tif (bus != CONTAINER_CHANNEL)\n\t\tbus = aac_phys_to_logical(bus);\n\n\treturn scsi_device_lookup(dev->scsi_host_ptr, bus, target, 0);\n}\n\nstatic int aac_add_safw_device(struct aac_dev *dev, int bus, int target)\n{\n\tif (bus != CONTAINER_CHANNEL)\n\t\tbus = aac_phys_to_logical(bus);\n\n\treturn scsi_add_device(dev->scsi_host_ptr, bus, target, 0);\n}\n\nstatic void aac_put_safw_scsi_device(struct scsi_device *sdev)\n{\n\tif (sdev)\n\t\tscsi_device_put(sdev);\n}\n\nstatic void aac_remove_safw_device(struct aac_dev *dev, int bus, int target)\n{\n\tstruct scsi_device *sdev;\n\n\tsdev = aac_lookup_safw_scsi_device(dev, bus, target);\n\tscsi_remove_device(sdev);\n\taac_put_safw_scsi_device(sdev);\n}\n\nstatic inline int aac_is_safw_scan_count_equal(struct aac_dev *dev,\n\tint bus, int target)\n{\n\treturn dev->hba_map[bus][target].scan_counter == dev->scan_counter;\n}\n\nstatic int aac_is_safw_target_valid(struct aac_dev *dev, int bus, int target)\n{\n\tif (is_safw_raid_volume(dev, bus, target))\n\t\treturn dev->fsa_dev[target].valid;\n\telse\n\t\treturn aac_is_safw_scan_count_equal(dev, bus, target);\n}\n\nstatic int aac_is_safw_device_exposed(struct aac_dev *dev, int bus, int target)\n{\n\tint is_exposed = 0;\n\tstruct scsi_device *sdev;\n\n\tsdev = aac_lookup_safw_scsi_device(dev, bus, target);\n\tif (sdev)\n\t\tis_exposed = 1;\n\taac_put_safw_scsi_device(sdev);\n\n\treturn is_exposed;\n}\n\nstatic int aac_update_safw_host_devices(struct aac_dev *dev)\n{\n\tint i;\n\tint bus;\n\tint target;\n\tint is_exposed = 0;\n\tint rcode = 0;\n\n\trcode = aac_setup_safw_adapter(dev);\n\tif (unlikely(rcode < 0)) {\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < AAC_BUS_TARGET_LOOP; i++) {\n\n\t\tbus = get_bus_number(i);\n\t\ttarget = get_target_number(i);\n\n\t\tis_exposed = aac_is_safw_device_exposed(dev, bus, target);\n\n\t\tif (aac_is_safw_target_valid(dev, bus, target) && !is_exposed)\n\t\t\taac_add_safw_device(dev, bus, target);\n\t\telse if (!aac_is_safw_target_valid(dev, bus, target) &&\n\t\t\t\t\t\t\t\tis_exposed)\n\t\t\taac_remove_safw_device(dev, bus, target);\n\t}\nout:\n\treturn rcode;\n}\n\nstatic int aac_scan_safw_host(struct aac_dev *dev)\n{\n\tint rcode = 0;\n\n\trcode = aac_update_safw_host_devices(dev);\n\tif (rcode)\n\t\taac_schedule_safw_scan_worker(dev);\n\n\treturn rcode;\n}\n\nint aac_scan_host(struct aac_dev *dev)\n{\n\tint rcode = 0;\n\n\tmutex_lock(&dev->scan_mutex);\n\tif (dev->sa_firmware)\n\t\trcode = aac_scan_safw_host(dev);\n\telse\n\t\tscsi_scan_host(dev->scsi_host_ptr);\n\tmutex_unlock(&dev->scan_mutex);\n\n\treturn rcode;\n}\n\nvoid aac_src_reinit_aif_worker(struct work_struct *work)\n{\n\tstruct aac_dev *dev = container_of(to_delayed_work(work),\n\t\t\t\tstruct aac_dev, src_reinit_aif_worker);\n\n\twait_event(dev->scsi_host_ptr->host_wait,\n\t\t\t!scsi_host_in_recovery(dev->scsi_host_ptr));\n\taac_reinit_aif(dev, dev->cardtype);\n}\n\n \nstatic void aac_handle_sa_aif(struct aac_dev *dev, struct fib *fibptr)\n{\n\tint i;\n\tu32 events = 0;\n\n\tif (fibptr->hbacmd_size & SA_AIF_HOTPLUG)\n\t\tevents = SA_AIF_HOTPLUG;\n\telse if (fibptr->hbacmd_size & SA_AIF_HARDWARE)\n\t\tevents = SA_AIF_HARDWARE;\n\telse if (fibptr->hbacmd_size & SA_AIF_PDEV_CHANGE)\n\t\tevents = SA_AIF_PDEV_CHANGE;\n\telse if (fibptr->hbacmd_size & SA_AIF_LDEV_CHANGE)\n\t\tevents = SA_AIF_LDEV_CHANGE;\n\telse if (fibptr->hbacmd_size & SA_AIF_BPSTAT_CHANGE)\n\t\tevents = SA_AIF_BPSTAT_CHANGE;\n\telse if (fibptr->hbacmd_size & SA_AIF_BPCFG_CHANGE)\n\t\tevents = SA_AIF_BPCFG_CHANGE;\n\n\tswitch (events) {\n\tcase SA_AIF_HOTPLUG:\n\tcase SA_AIF_HARDWARE:\n\tcase SA_AIF_PDEV_CHANGE:\n\tcase SA_AIF_LDEV_CHANGE:\n\tcase SA_AIF_BPCFG_CHANGE:\n\n\t\taac_scan_host(dev);\n\n\t\tbreak;\n\n\tcase SA_AIF_BPSTAT_CHANGE:\n\t\t \n\t\tbreak;\n\t}\n\n\tfor (i = 1; i <= 10; ++i) {\n\t\tevents = src_readl(dev, MUnit.IDR);\n\t\tif (events & (1<<23)) {\n\t\t\tpr_warn(\" AIF not cleared by firmware - %d/%d)\\n\",\n\t\t\t\ti, 10);\n\t\t\tssleep(1);\n\t\t}\n\t}\n}\n\nstatic int get_fib_count(struct aac_dev *dev)\n{\n\tunsigned int num = 0;\n\tstruct list_head *entry;\n\tunsigned long flagv;\n\n\t \n\tnum = le32_to_cpu(dev->init->r7.adapter_fibs_size)\n\t\t\t/ sizeof(struct hw_fib);  \n\tspin_lock_irqsave(&dev->fib_lock, flagv);\n\tentry = dev->fib_list.next;\n\twhile (entry != &dev->fib_list) {\n\t\tentry = entry->next;\n\t\t++num;\n\t}\n\tspin_unlock_irqrestore(&dev->fib_lock, flagv);\n\n\treturn num;\n}\n\nstatic int fillup_pools(struct aac_dev *dev, struct hw_fib **hw_fib_pool,\n\t\t\t\t\t\tstruct fib **fib_pool,\n\t\t\t\t\t\tunsigned int num)\n{\n\tstruct hw_fib **hw_fib_p;\n\tstruct fib **fib_p;\n\n\thw_fib_p = hw_fib_pool;\n\tfib_p = fib_pool;\n\twhile (hw_fib_p < &hw_fib_pool[num]) {\n\t\t*(hw_fib_p) = kmalloc(sizeof(struct hw_fib), GFP_KERNEL);\n\t\tif (!(*(hw_fib_p++))) {\n\t\t\t--hw_fib_p;\n\t\t\tbreak;\n\t\t}\n\n\t\t*(fib_p) = kmalloc(sizeof(struct fib), GFP_KERNEL);\n\t\tif (!(*(fib_p++))) {\n\t\t\tkfree(*(--hw_fib_p));\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tnum = hw_fib_p - hw_fib_pool;\n\treturn num;\n}\n\nstatic void wakeup_fibctx_threads(struct aac_dev *dev,\n\t\t\t\t\t\tstruct hw_fib **hw_fib_pool,\n\t\t\t\t\t\tstruct fib **fib_pool,\n\t\t\t\t\t\tstruct fib *fib,\n\t\t\t\t\t\tstruct hw_fib *hw_fib,\n\t\t\t\t\t\tunsigned int num)\n{\n\tunsigned long flagv;\n\tstruct list_head *entry;\n\tstruct hw_fib **hw_fib_p;\n\tstruct fib **fib_p;\n\tu32 time_now, time_last;\n\tstruct hw_fib *hw_newfib;\n\tstruct fib *newfib;\n\tstruct aac_fib_context *fibctx;\n\n\ttime_now = jiffies/HZ;\n\tspin_lock_irqsave(&dev->fib_lock, flagv);\n\tentry = dev->fib_list.next;\n\t \n\n\thw_fib_p = hw_fib_pool;\n\tfib_p = fib_pool;\n\twhile (entry != &dev->fib_list) {\n\t\t \n\t\tfibctx = list_entry(entry, struct aac_fib_context,\n\t\t\t\tnext);\n\t\t \n\t\tif (fibctx->count > 20) {\n\t\t\t \n\t\t\ttime_last = fibctx->jiffies;\n\t\t\t \n\t\t\tif ((time_now - time_last) > aif_timeout) {\n\t\t\t\tentry = entry->next;\n\t\t\t\taac_close_fib_context(dev, fibctx);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\t \n\t\tif (hw_fib_p >= &hw_fib_pool[num]) {\n\t\t\tpr_warn(\"aifd: didn't allocate NewFib\\n\");\n\t\t\tentry = entry->next;\n\t\t\tcontinue;\n\t\t}\n\n\t\thw_newfib = *hw_fib_p;\n\t\t*(hw_fib_p++) = NULL;\n\t\tnewfib = *fib_p;\n\t\t*(fib_p++) = NULL;\n\t\t \n\t\tmemcpy(hw_newfib, hw_fib, sizeof(struct hw_fib));\n\t\tmemcpy(newfib, fib, sizeof(struct fib));\n\t\tnewfib->hw_fib_va = hw_newfib;\n\t\t \n\t\tlist_add_tail(&newfib->fiblink, &fibctx->fib_list);\n\t\tfibctx->count++;\n\t\t \n\t\tcomplete(&fibctx->completion);\n\n\t\tentry = entry->next;\n\t}\n\t \n\t*(__le32 *)hw_fib->data = cpu_to_le32(ST_OK);\n\taac_fib_adapter_complete(fib, sizeof(u32));\n\tspin_unlock_irqrestore(&dev->fib_lock, flagv);\n\n}\n\nstatic void aac_process_events(struct aac_dev *dev)\n{\n\tstruct hw_fib *hw_fib;\n\tstruct fib *fib;\n\tunsigned long flags;\n\tspinlock_t *t_lock;\n\n\tt_lock = dev->queues->queue[HostNormCmdQueue].lock;\n\tspin_lock_irqsave(t_lock, flags);\n\n\twhile (!list_empty(&(dev->queues->queue[HostNormCmdQueue].cmdq))) {\n\t\tstruct list_head *entry;\n\t\tstruct aac_aifcmd *aifcmd;\n\t\tunsigned int  num;\n\t\tstruct hw_fib **hw_fib_pool, **hw_fib_p;\n\t\tstruct fib **fib_pool, **fib_p;\n\n\t\tset_current_state(TASK_RUNNING);\n\n\t\tentry = dev->queues->queue[HostNormCmdQueue].cmdq.next;\n\t\tlist_del(entry);\n\n\t\tt_lock = dev->queues->queue[HostNormCmdQueue].lock;\n\t\tspin_unlock_irqrestore(t_lock, flags);\n\n\t\tfib = list_entry(entry, struct fib, fiblink);\n\t\thw_fib = fib->hw_fib_va;\n\t\tif (dev->sa_firmware) {\n\t\t\t \n\t\t\taac_handle_sa_aif(dev, fib);\n\t\t\taac_fib_adapter_complete(fib, (u16)sizeof(u32));\n\t\t\tgoto free_fib;\n\t\t}\n\t\t \n\t\tmemset(fib, 0, sizeof(struct fib));\n\t\tfib->type = FSAFS_NTC_FIB_CONTEXT;\n\t\tfib->size = sizeof(struct fib);\n\t\tfib->hw_fib_va = hw_fib;\n\t\tfib->data = hw_fib->data;\n\t\tfib->dev = dev;\n\t\t \n\n\t\taifcmd = (struct aac_aifcmd *) hw_fib->data;\n\t\tif (aifcmd->command == cpu_to_le32(AifCmdDriverNotify)) {\n\t\t\t \n\t\t\taac_handle_aif(dev, fib);\n\t\t\t*(__le32 *)hw_fib->data = cpu_to_le32(ST_OK);\n\t\t\taac_fib_adapter_complete(fib, (u16)sizeof(u32));\n\t\t\tgoto free_fib;\n\t\t}\n\t\t \n\n\t\t \n\t\tif (aifcmd->command == cpu_to_le32(AifCmdEventNotify)\n\t\t || aifcmd->command == cpu_to_le32(AifCmdJobProgress)) {\n\t\t\taac_handle_aif(dev, fib);\n\t\t}\n\n\t\t \n\t\tnum = get_fib_count(dev);\n\t\tif (!num)\n\t\t\tgoto free_fib;\n\n\t\thw_fib_pool = kmalloc_array(num, sizeof(struct hw_fib *),\n\t\t\t\t\t\tGFP_KERNEL);\n\t\tif (!hw_fib_pool)\n\t\t\tgoto free_fib;\n\n\t\tfib_pool = kmalloc_array(num, sizeof(struct fib *), GFP_KERNEL);\n\t\tif (!fib_pool)\n\t\t\tgoto free_hw_fib_pool;\n\n\t\t \n\t\tnum = fillup_pools(dev, hw_fib_pool, fib_pool, num);\n\t\tif (!num)\n\t\t\tgoto free_mem;\n\n\t\t \n\t\twakeup_fibctx_threads(dev, hw_fib_pool, fib_pool,\n\t\t\t\t\t\t\t    fib, hw_fib, num);\n\nfree_mem:\n\t\t \n\t\thw_fib_p = hw_fib_pool;\n\t\tfib_p = fib_pool;\n\t\twhile (hw_fib_p < &hw_fib_pool[num]) {\n\t\t\tkfree(*hw_fib_p);\n\t\t\tkfree(*fib_p);\n\t\t\t++fib_p;\n\t\t\t++hw_fib_p;\n\t\t}\n\t\tkfree(fib_pool);\nfree_hw_fib_pool:\n\t\tkfree(hw_fib_pool);\nfree_fib:\n\t\tkfree(fib);\n\t\tt_lock = dev->queues->queue[HostNormCmdQueue].lock;\n\t\tspin_lock_irqsave(t_lock, flags);\n\t}\n\t \n\tt_lock = dev->queues->queue[HostNormCmdQueue].lock;\n\tspin_unlock_irqrestore(t_lock, flags);\n}\n\nstatic int aac_send_wellness_command(struct aac_dev *dev, char *wellness_str,\n\t\t\t\t\t\t\tu32 datasize)\n{\n\tstruct aac_srb *srbcmd;\n\tstruct sgmap64 *sg64;\n\tdma_addr_t addr;\n\tchar *dma_buf;\n\tstruct fib *fibptr;\n\tint ret = -ENOMEM;\n\tu32 vbus, vid;\n\n\tfibptr = aac_fib_alloc(dev);\n\tif (!fibptr)\n\t\tgoto out;\n\n\tdma_buf = dma_alloc_coherent(&dev->pdev->dev, datasize, &addr,\n\t\t\t\t     GFP_KERNEL);\n\tif (!dma_buf)\n\t\tgoto fib_free_out;\n\n\taac_fib_init(fibptr);\n\n\tvbus = (u32)le16_to_cpu(dev->supplement_adapter_info.virt_device_bus);\n\tvid = (u32)le16_to_cpu(dev->supplement_adapter_info.virt_device_target);\n\n\tsrbcmd = (struct aac_srb *)fib_data(fibptr);\n\n\tsrbcmd->function = cpu_to_le32(SRBF_ExecuteScsi);\n\tsrbcmd->channel = cpu_to_le32(vbus);\n\tsrbcmd->id = cpu_to_le32(vid);\n\tsrbcmd->lun = 0;\n\tsrbcmd->flags = cpu_to_le32(SRB_DataOut);\n\tsrbcmd->timeout = cpu_to_le32(10);\n\tsrbcmd->retry_limit = 0;\n\tsrbcmd->cdb_size = cpu_to_le32(12);\n\tsrbcmd->count = cpu_to_le32(datasize);\n\n\tmemset(srbcmd->cdb, 0, sizeof(srbcmd->cdb));\n\tsrbcmd->cdb[0] = BMIC_OUT;\n\tsrbcmd->cdb[6] = WRITE_HOST_WELLNESS;\n\tmemcpy(dma_buf, (char *)wellness_str, datasize);\n\n\tsg64 = (struct sgmap64 *)&srbcmd->sg;\n\tsg64->count = cpu_to_le32(1);\n\tsg64->sg[0].addr[1] = cpu_to_le32((u32)(((addr) >> 16) >> 16));\n\tsg64->sg[0].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));\n\tsg64->sg[0].count = cpu_to_le32(datasize);\n\n\tret = aac_fib_send(ScsiPortCommand64, fibptr, sizeof(struct aac_srb),\n\t\t\t\tFsaNormal, 1, 1, NULL, NULL);\n\n\tdma_free_coherent(&dev->pdev->dev, datasize, dma_buf, addr);\n\n\t \n\tif (ret >= 0)\n\t\taac_fib_complete(fibptr);\n\n\t \n\tif (ret != -ERESTARTSYS)\n\t\tgoto fib_free_out;\n\nout:\n\treturn ret;\nfib_free_out:\n\taac_fib_free(fibptr);\n\tgoto out;\n}\n\nstatic int aac_send_safw_hostttime(struct aac_dev *dev, struct timespec64 *now)\n{\n\tstruct tm cur_tm;\n\tchar wellness_str[] = \"<HW>TD\\010\\0\\0\\0\\0\\0\\0\\0\\0\\0DW\\0\\0ZZ\";\n\tu32 datasize = sizeof(wellness_str);\n\ttime64_t local_time;\n\tint ret = -ENODEV;\n\n\tif (!dev->sa_firmware)\n\t\tgoto out;\n\n\tlocal_time = (now->tv_sec - (sys_tz.tz_minuteswest * 60));\n\ttime64_to_tm(local_time, 0, &cur_tm);\n\tcur_tm.tm_mon += 1;\n\tcur_tm.tm_year += 1900;\n\twellness_str[8] = bin2bcd(cur_tm.tm_hour);\n\twellness_str[9] = bin2bcd(cur_tm.tm_min);\n\twellness_str[10] = bin2bcd(cur_tm.tm_sec);\n\twellness_str[12] = bin2bcd(cur_tm.tm_mon);\n\twellness_str[13] = bin2bcd(cur_tm.tm_mday);\n\twellness_str[14] = bin2bcd(cur_tm.tm_year / 100);\n\twellness_str[15] = bin2bcd(cur_tm.tm_year % 100);\n\n\tret = aac_send_wellness_command(dev, wellness_str, datasize);\n\nout:\n\treturn ret;\n}\n\nstatic int aac_send_hosttime(struct aac_dev *dev, struct timespec64 *now)\n{\n\tint ret = -ENOMEM;\n\tstruct fib *fibptr;\n\t__le32 *info;\n\n\tfibptr = aac_fib_alloc(dev);\n\tif (!fibptr)\n\t\tgoto out;\n\n\taac_fib_init(fibptr);\n\tinfo = (__le32 *)fib_data(fibptr);\n\t*info = cpu_to_le32(now->tv_sec);  \n\tret = aac_fib_send(SendHostTime, fibptr, sizeof(*info), FsaNormal,\n\t\t\t\t\t1, 1, NULL, NULL);\n\n\t \n\tif (ret >= 0)\n\t\taac_fib_complete(fibptr);\n\n\t \n\tif (ret != -ERESTARTSYS)\n\t\taac_fib_free(fibptr);\n\nout:\n\treturn ret;\n}\n\n \n\nint aac_command_thread(void *data)\n{\n\tstruct aac_dev *dev = data;\n\tDECLARE_WAITQUEUE(wait, current);\n\tunsigned long next_jiffies = jiffies + HZ;\n\tunsigned long next_check_jiffies = next_jiffies;\n\tlong difference = HZ;\n\n\t \n\tif (dev->aif_thread)\n\t\treturn -EINVAL;\n\n\t \n\tdev->aif_thread = 1;\n\tadd_wait_queue(&dev->queues->queue[HostNormCmdQueue].cmdready, &wait);\n\tset_current_state(TASK_INTERRUPTIBLE);\n\tdprintk ((KERN_INFO \"aac_command_thread start\\n\"));\n\twhile (1) {\n\n\t\taac_process_events(dev);\n\n\t\t \n\t\tif ((time_before(next_check_jiffies,next_jiffies))\n\t\t && ((difference = next_check_jiffies - jiffies) <= 0)) {\n\t\t\tnext_check_jiffies = next_jiffies;\n\t\t\tif (aac_adapter_check_health(dev) == 0) {\n\t\t\t\tdifference = ((long)(unsigned)check_interval)\n\t\t\t\t\t   * HZ;\n\t\t\t\tnext_check_jiffies = jiffies + difference;\n\t\t\t} else if (!dev->queues)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!time_before(next_check_jiffies,next_jiffies)\n\t\t && ((difference = next_jiffies - jiffies) <= 0)) {\n\t\t\tstruct timespec64 now;\n\t\t\tint ret;\n\n\t\t\t \n\t\t\tret = aac_adapter_check_health(dev);\n\t\t\tif (ret || !dev->queues)\n\t\t\t\tbreak;\n\t\t\tnext_check_jiffies = jiffies\n\t\t\t\t\t   + ((long)(unsigned)check_interval)\n\t\t\t\t\t   * HZ;\n\t\t\tktime_get_real_ts64(&now);\n\n\t\t\t \n\t\t\tif (((NSEC_PER_SEC - (NSEC_PER_SEC / HZ)) > now.tv_nsec)\n\t\t\t && (now.tv_nsec > (NSEC_PER_SEC / HZ)))\n\t\t\t\tdifference = HZ + HZ / 2 -\n\t\t\t\t\t     now.tv_nsec / (NSEC_PER_SEC / HZ);\n\t\t\telse {\n\t\t\t\tif (now.tv_nsec > NSEC_PER_SEC / 2)\n\t\t\t\t\t++now.tv_sec;\n\n\t\t\t\tif (dev->sa_firmware)\n\t\t\t\t\tret =\n\t\t\t\t\taac_send_safw_hostttime(dev, &now);\n\t\t\t\telse\n\t\t\t\t\tret = aac_send_hosttime(dev, &now);\n\n\t\t\t\tdifference = (long)(unsigned)update_interval*HZ;\n\t\t\t}\n\t\t\tnext_jiffies = jiffies + difference;\n\t\t\tif (time_before(next_check_jiffies,next_jiffies))\n\t\t\t\tdifference = next_check_jiffies - jiffies;\n\t\t}\n\t\tif (difference <= 0)\n\t\t\tdifference = 1;\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\n\t\t \n\t\tschedule_timeout(difference);\n\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\t}\n\tif (dev->queues)\n\t\tremove_wait_queue(&dev->queues->queue[HostNormCmdQueue].cmdready, &wait);\n\tdev->aif_thread = 0;\n\treturn 0;\n}\n\nint aac_acquire_irq(struct aac_dev *dev)\n{\n\tint i;\n\tint j;\n\tint ret = 0;\n\n\tif (!dev->sync_mode && dev->msi_enabled && dev->max_msix > 1) {\n\t\tfor (i = 0; i < dev->max_msix; i++) {\n\t\t\tdev->aac_msix[i].vector_no = i;\n\t\t\tdev->aac_msix[i].dev = dev;\n\t\t\tif (request_irq(pci_irq_vector(dev->pdev, i),\n\t\t\t\t\tdev->a_ops.adapter_intr,\n\t\t\t\t\t0, \"aacraid\", &(dev->aac_msix[i]))) {\n\t\t\t\tprintk(KERN_ERR \"%s%d: Failed to register IRQ for vector %d.\\n\",\n\t\t\t\t\t\tdev->name, dev->id, i);\n\t\t\t\tfor (j = 0 ; j < i ; j++)\n\t\t\t\t\tfree_irq(pci_irq_vector(dev->pdev, j),\n\t\t\t\t\t\t &(dev->aac_msix[j]));\n\t\t\t\tpci_disable_msix(dev->pdev);\n\t\t\t\tret = -1;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tdev->aac_msix[0].vector_no = 0;\n\t\tdev->aac_msix[0].dev = dev;\n\n\t\tif (request_irq(dev->pdev->irq, dev->a_ops.adapter_intr,\n\t\t\tIRQF_SHARED, \"aacraid\",\n\t\t\t&(dev->aac_msix[0])) < 0) {\n\t\t\tif (dev->msi)\n\t\t\t\tpci_disable_msi(dev->pdev);\n\t\t\tprintk(KERN_ERR \"%s%d: Interrupt unavailable.\\n\",\n\t\t\t\t\tdev->name, dev->id);\n\t\t\tret = -1;\n\t\t}\n\t}\n\treturn ret;\n}\n\nvoid aac_free_irq(struct aac_dev *dev)\n{\n\tint i;\n\n\tif (aac_is_src(dev)) {\n\t\tif (dev->max_msix > 1) {\n\t\t\tfor (i = 0; i < dev->max_msix; i++)\n\t\t\t\tfree_irq(pci_irq_vector(dev->pdev, i),\n\t\t\t\t\t &(dev->aac_msix[i]));\n\t\t} else {\n\t\t\tfree_irq(dev->pdev->irq, &(dev->aac_msix[0]));\n\t\t}\n\t} else {\n\t\tfree_irq(dev->pdev->irq, dev);\n\t}\n\tif (dev->msi)\n\t\tpci_disable_msi(dev->pdev);\n\telse if (dev->max_msix > 1)\n\t\tpci_disable_msix(dev->pdev);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}