{
  "module_name": "cxgb3i.c",
  "hash_id": "41e28545403e0f5ffa0e5b6cdd682f3e8418cbcf6c78d44635013120fc6f6751",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/cxgbi/cxgb3i/cxgb3i.c",
  "human_readable_source": " \n\n#define pr_fmt(fmt) KBUILD_MODNAME \":%s: \" fmt, __func__\n\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <scsi/scsi_host.h>\n\n#include \"common.h\"\n#include \"t3_cpl.h\"\n#include \"t3cdev.h\"\n#include \"cxgb3_defs.h\"\n#include \"cxgb3_ctl_defs.h\"\n#include \"cxgb3_offload.h\"\n#include \"firmware_exports.h\"\n#include \"cxgb3i.h\"\n\nstatic unsigned int dbg_level;\n#include \"../libcxgbi.h\"\n\n#define DRV_MODULE_NAME         \"cxgb3i\"\n#define DRV_MODULE_DESC         \"Chelsio T3 iSCSI Driver\"\n#define DRV_MODULE_VERSION\t\"2.0.1-ko\"\n#define DRV_MODULE_RELDATE\t\"Apr. 2015\"\n\nstatic char version[] =\n\tDRV_MODULE_DESC \" \" DRV_MODULE_NAME\n\t\" v\" DRV_MODULE_VERSION \" (\" DRV_MODULE_RELDATE \")\\n\";\n\nMODULE_AUTHOR(\"Chelsio Communications, Inc.\");\nMODULE_DESCRIPTION(DRV_MODULE_DESC);\nMODULE_VERSION(DRV_MODULE_VERSION);\nMODULE_LICENSE(\"GPL\");\n\nmodule_param(dbg_level, uint, 0644);\nMODULE_PARM_DESC(dbg_level, \"debug flag (default=0)\");\n\nstatic int cxgb3i_rcv_win = 256 * 1024;\nmodule_param(cxgb3i_rcv_win, int, 0644);\nMODULE_PARM_DESC(cxgb3i_rcv_win, \"TCP receive window in bytes (default=256KB)\");\n\nstatic int cxgb3i_snd_win = 128 * 1024;\nmodule_param(cxgb3i_snd_win, int, 0644);\nMODULE_PARM_DESC(cxgb3i_snd_win, \"TCP send window in bytes (default=128KB)\");\n\nstatic int cxgb3i_rx_credit_thres = 10 * 1024;\nmodule_param(cxgb3i_rx_credit_thres, int, 0644);\nMODULE_PARM_DESC(cxgb3i_rx_credit_thres,\n\t\t \"RX credits return threshold in bytes (default=10KB)\");\n\nstatic unsigned int cxgb3i_max_connect = 8 * 1024;\nmodule_param(cxgb3i_max_connect, uint, 0644);\nMODULE_PARM_DESC(cxgb3i_max_connect, \"Max. # of connections (default=8092)\");\n\nstatic unsigned int cxgb3i_sport_base = 20000;\nmodule_param(cxgb3i_sport_base, uint, 0644);\nMODULE_PARM_DESC(cxgb3i_sport_base, \"starting port number (default=20000)\");\n\nstatic void cxgb3i_dev_open(struct t3cdev *);\nstatic void cxgb3i_dev_close(struct t3cdev *);\nstatic void cxgb3i_dev_event_handler(struct t3cdev *, u32, u32);\n\nstatic struct cxgb3_client t3_client = {\n\t.name = DRV_MODULE_NAME,\n\t.handlers = cxgb3i_cpl_handlers,\n\t.add = cxgb3i_dev_open,\n\t.remove = cxgb3i_dev_close,\n\t.event_handler = cxgb3i_dev_event_handler,\n};\n\nstatic const struct scsi_host_template cxgb3i_host_template = {\n\t.module\t\t= THIS_MODULE,\n\t.name\t\t= DRV_MODULE_NAME,\n\t.proc_name\t= DRV_MODULE_NAME,\n\t.can_queue\t= CXGB3I_SCSI_HOST_QDEPTH,\n\t.queuecommand\t= iscsi_queuecommand,\n\t.change_queue_depth = scsi_change_queue_depth,\n\t.sg_tablesize\t= SG_ALL,\n\t.max_sectors\t= 0xFFFF,\n\t.cmd_per_lun\t= ISCSI_DEF_CMD_PER_LUN,\n\t.eh_timed_out\t= iscsi_eh_cmd_timed_out,\n\t.eh_abort_handler = iscsi_eh_abort,\n\t.eh_device_reset_handler = iscsi_eh_device_reset,\n\t.eh_target_reset_handler = iscsi_eh_recover_target,\n\t.target_alloc\t= iscsi_target_alloc,\n\t.dma_boundary\t= PAGE_SIZE - 1,\n\t.this_id\t= -1,\n\t.track_queue_depth = 1,\n\t.cmd_size\t= sizeof(struct iscsi_cmd),\n};\n\nstatic struct iscsi_transport cxgb3i_iscsi_transport = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= DRV_MODULE_NAME,\n\t \n\t.caps\t\t= CAP_RECOVERY_L0 | CAP_MULTI_R2T | CAP_HDRDGST\n\t\t\t\t| CAP_DATADGST | CAP_DIGEST_OFFLOAD |\n\t\t\t\tCAP_PADDING_OFFLOAD | CAP_TEXT_NEGO,\n\t.attr_is_visible\t= cxgbi_attr_is_visible,\n\t.get_host_param\t= cxgbi_get_host_param,\n\t.set_host_param\t= cxgbi_set_host_param,\n\t \n\t.create_session\t= cxgbi_create_session,\n\t.destroy_session\t= cxgbi_destroy_session,\n\t.get_session_param = iscsi_session_get_param,\n\t \n\t.create_conn\t= cxgbi_create_conn,\n\t.bind_conn\t= cxgbi_bind_conn,\n\t.unbind_conn\t= iscsi_conn_unbind,\n\t.destroy_conn\t= iscsi_tcp_conn_teardown,\n\t.start_conn\t= iscsi_conn_start,\n\t.stop_conn\t= iscsi_conn_stop,\n\t.get_conn_param\t= iscsi_conn_get_param,\n\t.set_param\t= cxgbi_set_conn_param,\n\t.get_stats\t= cxgbi_get_conn_stats,\n\t \n\t.send_pdu\t= iscsi_conn_send_pdu,\n\t \n\t.init_task\t= iscsi_tcp_task_init,\n\t.xmit_task\t= iscsi_tcp_task_xmit,\n\t.cleanup_task\t= cxgbi_cleanup_task,\n\t \n\t.alloc_pdu\t= cxgbi_conn_alloc_pdu,\n\t.init_pdu\t= cxgbi_conn_init_pdu,\n\t.xmit_pdu\t= cxgbi_conn_xmit_pdu,\n\t.parse_pdu_itt\t= cxgbi_parse_pdu_itt,\n\t \n\t.get_ep_param\t= cxgbi_get_ep_param,\n\t.ep_connect\t= cxgbi_ep_connect,\n\t.ep_poll\t= cxgbi_ep_poll,\n\t.ep_disconnect\t= cxgbi_ep_disconnect,\n\t \n\t.session_recovery_timedout = iscsi_session_recovery_timedout,\n};\n\nstatic struct scsi_transport_template *cxgb3i_stt;\n\n \n\nstatic int push_tx_frames(struct cxgbi_sock *csk, int req_completion);\n\nstatic void send_act_open_req(struct cxgbi_sock *csk, struct sk_buff *skb,\n\t\t\t      const struct l2t_entry *e)\n{\n\tunsigned int wscale = cxgbi_sock_compute_wscale(csk->rcv_win);\n\tstruct cpl_act_open_req *req = (struct cpl_act_open_req *)skb->head;\n\n\tskb->priority = CPL_PRIORITY_SETUP;\n\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_ACT_OPEN_REQ, csk->atid));\n\treq->local_port = csk->saddr.sin_port;\n\treq->peer_port = csk->daddr.sin_port;\n\treq->local_ip = csk->saddr.sin_addr.s_addr;\n\treq->peer_ip = csk->daddr.sin_addr.s_addr;\n\n\treq->opt0h = htonl(V_KEEP_ALIVE(1) | F_TCAM_BYPASS |\n\t\t\tV_WND_SCALE(wscale) | V_MSS_IDX(csk->mss_idx) |\n\t\t\tV_L2T_IDX(e->idx) | V_TX_CHANNEL(e->smt_idx));\n\treq->opt0l = htonl(V_ULP_MODE(ULP2_MODE_ISCSI) |\n\t\t\tV_RCV_BUFSIZ(csk->rcv_win >> 10));\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx,%u, %pI4:%u-%pI4:%u, %u,%u,%u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->atid,\n\t\t&req->local_ip, ntohs(req->local_port),\n\t\t&req->peer_ip, ntohs(req->peer_port),\n\t\tcsk->mss_idx, e->idx, e->smt_idx);\n\n\tl2t_send(csk->cdev->lldev, skb, csk->l2t);\n}\n\nstatic inline void act_open_arp_failure(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tcxgbi_sock_act_open_req_arp_failure(NULL, skb);\n}\n\n \nstatic void send_close_req(struct cxgbi_sock *csk)\n{\n\tstruct sk_buff *skb = csk->cpl_close;\n\tstruct cpl_close_con_req *req = (struct cpl_close_con_req *)skb->head;\n\tunsigned int tid = csk->tid;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx,%u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid);\n\n\tcsk->cpl_close = NULL;\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_CLOSE_CON));\n\treq->wr.wr_lo = htonl(V_WR_TID(tid));\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_CLOSE_CON_REQ, tid));\n\treq->rsvd = htonl(csk->write_seq);\n\n\tcxgbi_sock_skb_entail(csk, skb);\n\tif (csk->state >= CTP_ESTABLISHED)\n\t\tpush_tx_frames(csk, 1);\n}\n\n \nstatic void abort_arp_failure(struct t3cdev *tdev, struct sk_buff *skb)\n{\n\tstruct cpl_abort_req *req = cplhdr(skb);\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"t3dev 0x%p, tid %u, skb 0x%p.\\n\",\n\t\ttdev, GET_TID(req), skb);\n\treq->cmd = CPL_ABORT_NO_RST;\n\tcxgb3_ofld_send(tdev, skb);\n}\n\nstatic void send_abort_req(struct cxgbi_sock *csk)\n{\n\tstruct sk_buff *skb = csk->cpl_abort_req;\n\tstruct cpl_abort_req *req;\n\n\tif (unlikely(csk->state == CTP_ABORTING || !skb))\n\t\treturn;\n\tcxgbi_sock_set_state(csk, CTP_ABORTING);\n\tcxgbi_sock_set_flag(csk, CTPF_ABORT_RPL_PENDING);\n\t \n\tcxgbi_sock_purge_write_queue(csk);\n\n\tcsk->cpl_abort_req = NULL;\n\treq = (struct cpl_abort_req *)skb->head;\n\tskb->priority = CPL_PRIORITY_DATA;\n\tset_arp_failure_handler(skb, abort_arp_failure);\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_HOST_ABORT_CON_REQ));\n\treq->wr.wr_lo = htonl(V_WR_TID(csk->tid));\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_ABORT_REQ, csk->tid));\n\treq->rsvd0 = htonl(csk->snd_nxt);\n\treq->rsvd1 = !cxgbi_sock_flag(csk, CTPF_TX_DATA_SENT);\n\treq->cmd = CPL_ABORT_SEND_RST;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx,%u, snd_nxt %u, 0x%x.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid, csk->snd_nxt,\n\t\treq->rsvd1);\n\n\tl2t_send(csk->cdev->lldev, skb, csk->l2t);\n}\n\n \nstatic void send_abort_rpl(struct cxgbi_sock *csk, int rst_status)\n{\n\tstruct sk_buff *skb = csk->cpl_abort_rpl;\n\tstruct cpl_abort_rpl *rpl = (struct cpl_abort_rpl *)skb->head;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx,%u, status %d.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid, rst_status);\n\n\tcsk->cpl_abort_rpl = NULL;\n\tskb->priority = CPL_PRIORITY_DATA;\n\trpl->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_HOST_ABORT_CON_RPL));\n\trpl->wr.wr_lo = htonl(V_WR_TID(csk->tid));\n\tOPCODE_TID(rpl) = htonl(MK_OPCODE_TID(CPL_ABORT_RPL, csk->tid));\n\trpl->cmd = rst_status;\n\tcxgb3_ofld_send(csk->cdev->lldev, skb);\n}\n\n \nstatic u32 send_rx_credits(struct cxgbi_sock *csk, u32 credits)\n{\n\tstruct sk_buff *skb;\n\tstruct cpl_rx_data_ack *req;\n\tu32 dack = F_RX_DACK_CHANGE | V_RX_DACK_MODE(1);\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_PDU_RX,\n\t\t\"csk 0x%p,%u,0x%lx,%u, credit %u, dack %u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid, credits, dack);\n\n\tskb = alloc_wr(sizeof(*req), 0, GFP_ATOMIC);\n\tif (!skb) {\n\t\tpr_info(\"csk 0x%p, credit %u, OOM.\\n\", csk, credits);\n\t\treturn 0;\n\t}\n\treq = (struct cpl_rx_data_ack *)skb->head;\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_RX_DATA_ACK, csk->tid));\n\treq->credit_dack = htonl(F_RX_DACK_CHANGE | V_RX_DACK_MODE(1) |\n\t\t\t\tV_RX_CREDITS(credits));\n\tskb->priority = CPL_PRIORITY_ACK;\n\tcxgb3_ofld_send(csk->cdev->lldev, skb);\n\treturn credits;\n}\n\n \n\nstatic unsigned int wrlen __read_mostly;\nstatic unsigned int skb_wrs[SKB_WR_LIST_SIZE] __read_mostly;\n\nstatic void init_wr_tab(unsigned int wr_len)\n{\n\tint i;\n\n\tif (skb_wrs[1])\t\t \n\t\treturn;\n\tfor (i = 1; i < SKB_WR_LIST_SIZE; i++) {\n\t\tint sgl_len = (3 * i) / 2 + (i & 1);\n\n\t\tsgl_len += 3;\n\t\tskb_wrs[i] = (sgl_len <= wr_len\n\t\t\t      ? 1 : 1 + (sgl_len - 2) / (wr_len - 1));\n\t}\n\twrlen = wr_len * 8;\n}\n\nstatic inline void make_tx_data_wr(struct cxgbi_sock *csk, struct sk_buff *skb,\n\t\t\t\t   int len, int req_completion)\n{\n\tstruct tx_data_wr *req;\n\tstruct l2t_entry *l2t = csk->l2t;\n\n\tskb_reset_transport_header(skb);\n\treq = __skb_push(skb, sizeof(*req));\n\treq->wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_TX_DATA) |\n\t\t\t(req_completion ? F_WR_COMPL : 0));\n\treq->wr_lo = htonl(V_WR_TID(csk->tid));\n\t \n\treq->len = htonl(len);\n\t \n\treq->flags = htonl(V_TX_ULP_SUBMODE(cxgbi_skcb_tx_ulp_mode(skb)) |\n\t\t\t   V_TX_SHOVE((skb_peek(&csk->write_queue) ? 0 : 1)));\n\treq->sndseq = htonl(csk->snd_nxt);\n\treq->param = htonl(V_TX_PORT(l2t->smt_idx));\n\n\tif (!cxgbi_sock_flag(csk, CTPF_TX_DATA_SENT)) {\n\t\treq->flags |= htonl(V_TX_ACK_PAGES(2) | F_TX_INIT |\n\t\t\t\t    V_TX_CPU_IDX(csk->rss_qid));\n\t\t \n\t\treq->param |= htonl(V_TX_SNDBUF(csk->snd_win >> 15));\n\t\tcxgbi_sock_set_flag(csk, CTPF_TX_DATA_SENT);\n\t}\n}\n\n \n\nstatic void arp_failure_skb_discard(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tkfree_skb(skb);\n}\n\nstatic int push_tx_frames(struct cxgbi_sock *csk, int req_completion)\n{\n\tint total_size = 0;\n\tstruct sk_buff *skb;\n\n\tif (unlikely(csk->state < CTP_ESTABLISHED ||\n\t\tcsk->state == CTP_CLOSE_WAIT_1 || csk->state >= CTP_ABORTING)) {\n\t\t\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_PDU_TX,\n\t\t\t\t\"csk 0x%p,%u,0x%lx,%u, in closing state.\\n\",\n\t\t\t\tcsk, csk->state, csk->flags, csk->tid);\n\t\treturn 0;\n\t}\n\n\twhile (csk->wr_cred && (skb = skb_peek(&csk->write_queue)) != NULL) {\n\t\tint len = skb->len;\t \n\t\tint frags = skb_shinfo(skb)->nr_frags + (len != skb->data_len);\n\t\tint wrs_needed = skb_wrs[frags];\n\n\t\tif (wrs_needed > 1 && len + sizeof(struct tx_data_wr) <= wrlen)\n\t\t\twrs_needed = 1;\n\n\t\tWARN_ON(frags >= SKB_WR_LIST_SIZE || wrs_needed < 1);\n\n\t\tif (csk->wr_cred < wrs_needed) {\n\t\t\tlog_debug(1 << CXGBI_DBG_PDU_TX,\n\t\t\t\t\"csk 0x%p, skb len %u/%u, frag %u, wr %d<%u.\\n\",\n\t\t\t\tcsk, skb->len, skb->data_len, frags,\n\t\t\t\twrs_needed, csk->wr_cred);\n\t\t\tbreak;\n\t\t}\n\n\t\t__skb_unlink(skb, &csk->write_queue);\n\t\tskb->priority = CPL_PRIORITY_DATA;\n\t\tskb->csum = wrs_needed;\t \n\t\tcsk->wr_cred -= wrs_needed;\n\t\tcsk->wr_una_cred += wrs_needed;\n\t\tcxgbi_sock_enqueue_wr(csk, skb);\n\n\t\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_PDU_TX,\n\t\t\t\"csk 0x%p, enqueue, skb len %u/%u, frag %u, wr %d, \"\n\t\t\t\"left %u, unack %u.\\n\",\n\t\t\tcsk, skb->len, skb->data_len, frags, skb->csum,\n\t\t\tcsk->wr_cred, csk->wr_una_cred);\n\n\t\tif (likely(cxgbi_skcb_test_flag(skb, SKCBF_TX_NEED_HDR))) {\n\t\t\tif ((req_completion &&\n\t\t\t\tcsk->wr_una_cred == wrs_needed) ||\n\t\t\t     csk->wr_una_cred >= csk->wr_max_cred / 2) {\n\t\t\t\treq_completion = 1;\n\t\t\t\tcsk->wr_una_cred = 0;\n\t\t\t}\n\t\t\tlen += cxgbi_ulp_extra_len(cxgbi_skcb_tx_ulp_mode(skb));\n\t\t\tmake_tx_data_wr(csk, skb, len, req_completion);\n\t\t\tcsk->snd_nxt += len;\n\t\t\tcxgbi_skcb_clear_flag(skb, SKCBF_TX_NEED_HDR);\n\t\t}\n\t\ttotal_size += skb->truesize;\n\t\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_PDU_TX,\n\t\t\t\"csk 0x%p, tid 0x%x, send skb 0x%p.\\n\",\n\t\t\tcsk, csk->tid, skb);\n\t\tset_arp_failure_handler(skb, arp_failure_skb_discard);\n\t\tl2t_send(csk->cdev->lldev, skb, csk->l2t);\n\t}\n\treturn total_size;\n}\n\n \n\nstatic inline void free_atid(struct cxgbi_sock *csk)\n{\n\tif (cxgbi_sock_flag(csk, CTPF_HAS_ATID)) {\n\t\tcxgb3_free_atid(csk->cdev->lldev, csk->atid);\n\t\tcxgbi_sock_clear_flag(csk, CTPF_HAS_ATID);\n\t\tcxgbi_sock_put(csk);\n\t}\n}\n\nstatic int do_act_establish(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\n{\n\tstruct cxgbi_sock *csk = ctx;\n\tstruct cpl_act_establish *req = cplhdr(skb);\n\tunsigned int tid = GET_TID(req);\n\tunsigned int atid = G_PASS_OPEN_TID(ntohl(req->tos_tid));\n\tu32 rcv_isn = ntohl(req->rcv_isn);\t \n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"atid 0x%x,tid 0x%x, csk 0x%p,%u,0x%lx, isn %u.\\n\",\n\t\tatid, atid, csk, csk->state, csk->flags, rcv_isn);\n\n\tcxgbi_sock_get(csk);\n\tcxgbi_sock_set_flag(csk, CTPF_HAS_TID);\n\tcsk->tid = tid;\n\tcxgb3_insert_tid(csk->cdev->lldev, &t3_client, csk, tid);\n\n\tfree_atid(csk);\n\n\tcsk->rss_qid = G_QNUM(ntohs(skb->csum));\n\n\tspin_lock_bh(&csk->lock);\n\tif (csk->retry_timer.function) {\n\t\tdel_timer(&csk->retry_timer);\n\t\tcsk->retry_timer.function = NULL;\n\t}\n\n\tif (unlikely(csk->state != CTP_ACTIVE_OPEN))\n\t\tpr_info(\"csk 0x%p,%u,0x%lx,%u, got EST.\\n\",\n\t\t\tcsk, csk->state, csk->flags, csk->tid);\n\n\tcsk->copied_seq = csk->rcv_wup = csk->rcv_nxt = rcv_isn;\n\tif (csk->rcv_win > (M_RCV_BUFSIZ << 10))\n\t\tcsk->rcv_wup -= csk->rcv_win - (M_RCV_BUFSIZ << 10);\n\n\tcxgbi_sock_established(csk, ntohl(req->snd_isn), ntohs(req->tcp_opt));\n\n\tif (unlikely(cxgbi_sock_flag(csk, CTPF_ACTIVE_CLOSE_NEEDED)))\n\t\t \n\t\tsend_abort_req(csk);\n\telse {\n\t\tif (skb_queue_len(&csk->write_queue))\n\t\t\tpush_tx_frames(csk, 1);\n\t\tcxgbi_conn_tx_open(csk);\n\t}\n\n\tspin_unlock_bh(&csk->lock);\n\t__kfree_skb(skb);\n\treturn 0;\n}\n\n \nstatic int act_open_rpl_status_to_errno(int status)\n{\n\tswitch (status) {\n\tcase CPL_ERR_CONN_RESET:\n\t\treturn -ECONNREFUSED;\n\tcase CPL_ERR_ARP_MISS:\n\t\treturn -EHOSTUNREACH;\n\tcase CPL_ERR_CONN_TIMEDOUT:\n\t\treturn -ETIMEDOUT;\n\tcase CPL_ERR_TCAM_FULL:\n\t\treturn -ENOMEM;\n\tcase CPL_ERR_CONN_EXIST:\n\t\treturn -EADDRINUSE;\n\tdefault:\n\t\treturn -EIO;\n\t}\n}\n\nstatic void act_open_retry_timer(struct timer_list *t)\n{\n\tstruct cxgbi_sock *csk = from_timer(csk, t, retry_timer);\n\tstruct sk_buff *skb;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx,%u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid);\n\n\tcxgbi_sock_get(csk);\n\tspin_lock_bh(&csk->lock);\n\tskb = alloc_wr(sizeof(struct cpl_act_open_req), 0, GFP_ATOMIC);\n\tif (!skb)\n\t\tcxgbi_sock_fail_act_open(csk, -ENOMEM);\n\telse {\n\t\tskb->sk = (struct sock *)csk;\n\t\tset_arp_failure_handler(skb, act_open_arp_failure);\n\t\tsend_act_open_req(csk, skb, csk->l2t);\n\t}\n\tspin_unlock_bh(&csk->lock);\n\tcxgbi_sock_put(csk);\n}\n\nstatic int do_act_open_rpl(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\n{\n\tstruct cxgbi_sock *csk = ctx;\n\tstruct cpl_act_open_rpl *rpl = cplhdr(skb);\n\n\tpr_info(\"csk 0x%p,%u,0x%lx,%u, status %u, %pI4:%u-%pI4:%u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->atid, rpl->status,\n\t\t&csk->saddr.sin_addr.s_addr, ntohs(csk->saddr.sin_port),\n\t\t&csk->daddr.sin_addr.s_addr, ntohs(csk->daddr.sin_port));\n\n\tif (rpl->status != CPL_ERR_TCAM_FULL &&\n\t    rpl->status != CPL_ERR_CONN_EXIST &&\n\t    rpl->status != CPL_ERR_ARP_MISS)\n\t\tcxgb3_queue_tid_release(tdev, GET_TID(rpl));\n\n\tcxgbi_sock_get(csk);\n\tspin_lock_bh(&csk->lock);\n\tif (rpl->status == CPL_ERR_CONN_EXIST &&\n\t    csk->retry_timer.function != act_open_retry_timer) {\n\t\tcsk->retry_timer.function = act_open_retry_timer;\n\t\tmod_timer(&csk->retry_timer, jiffies + HZ / 2);\n\t} else\n\t\tcxgbi_sock_fail_act_open(csk,\n\t\t\t\tact_open_rpl_status_to_errno(rpl->status));\n\n\tspin_unlock_bh(&csk->lock);\n\tcxgbi_sock_put(csk);\n\t__kfree_skb(skb);\n\treturn 0;\n}\n\n \nstatic int do_peer_close(struct t3cdev *cdev, struct sk_buff *skb, void *ctx)\n{\n\tstruct cxgbi_sock *csk = ctx;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx,%u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid);\n\n\tcxgbi_sock_rcv_peer_close(csk);\n\t__kfree_skb(skb);\n\treturn 0;\n}\n\n \nstatic int do_close_con_rpl(struct t3cdev *cdev, struct sk_buff *skb,\n\t\t\t    void *ctx)\n{\n\tstruct cxgbi_sock *csk = ctx;\n\tstruct cpl_close_con_rpl *rpl = cplhdr(skb);\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx,%u, snxt %u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid, ntohl(rpl->snd_nxt));\n\n\tcxgbi_sock_rcv_close_conn_rpl(csk, ntohl(rpl->snd_nxt));\n\t__kfree_skb(skb);\n\treturn 0;\n}\n\n \n\nstatic int abort_status_to_errno(struct cxgbi_sock *csk, int abort_reason,\n\t\t\t\t int *need_rst)\n{\n\tswitch (abort_reason) {\n\tcase CPL_ERR_BAD_SYN:\n\tcase CPL_ERR_CONN_RESET:\n\t\treturn csk->state > CTP_ESTABLISHED ? -EPIPE : -ECONNRESET;\n\tcase CPL_ERR_XMIT_TIMEDOUT:\n\tcase CPL_ERR_PERSIST_TIMEDOUT:\n\tcase CPL_ERR_FINWAIT2_TIMEDOUT:\n\tcase CPL_ERR_KEEPALIVE_TIMEDOUT:\n\t\treturn -ETIMEDOUT;\n\tdefault:\n\t\treturn -EIO;\n\t}\n}\n\nstatic int do_abort_req(struct t3cdev *cdev, struct sk_buff *skb, void *ctx)\n{\n\tconst struct cpl_abort_req_rss *req = cplhdr(skb);\n\tstruct cxgbi_sock *csk = ctx;\n\tint rst_status = CPL_ABORT_NO_RST;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx,%u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid);\n\n\tif (req->status == CPL_ERR_RTX_NEG_ADVICE ||\n\t    req->status == CPL_ERR_PERSIST_NEG_ADVICE) {\n\t\tgoto done;\n\t}\n\n\tcxgbi_sock_get(csk);\n\tspin_lock_bh(&csk->lock);\n\n\tif (!cxgbi_sock_flag(csk, CTPF_ABORT_REQ_RCVD)) {\n\t\tcxgbi_sock_set_flag(csk, CTPF_ABORT_REQ_RCVD);\n\t\tcxgbi_sock_set_state(csk, CTP_ABORTING);\n\t\tgoto out;\n\t}\n\n\tcxgbi_sock_clear_flag(csk, CTPF_ABORT_REQ_RCVD);\n\tsend_abort_rpl(csk, rst_status);\n\n\tif (!cxgbi_sock_flag(csk, CTPF_ABORT_RPL_PENDING)) {\n\t\tcsk->err = abort_status_to_errno(csk, req->status, &rst_status);\n\t\tcxgbi_sock_closed(csk);\n\t}\n\nout:\n\tspin_unlock_bh(&csk->lock);\n\tcxgbi_sock_put(csk);\ndone:\n\t__kfree_skb(skb);\n\treturn 0;\n}\n\n \nstatic int do_abort_rpl(struct t3cdev *cdev, struct sk_buff *skb, void *ctx)\n{\n\tstruct cpl_abort_rpl_rss *rpl = cplhdr(skb);\n\tstruct cxgbi_sock *csk = ctx;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"status 0x%x, csk 0x%p, s %u, 0x%lx.\\n\",\n\t\trpl->status, csk, csk ? csk->state : 0,\n\t\tcsk ? csk->flags : 0UL);\n\t \n\tif (rpl->status == CPL_ERR_ABORT_FAILED)\n\t\tgoto rel_skb;\n\t \n\tif (csk)\n\t\tcxgbi_sock_rcv_abort_rpl(csk);\nrel_skb:\n\t__kfree_skb(skb);\n\treturn 0;\n}\n\n \nstatic int do_iscsi_hdr(struct t3cdev *t3dev, struct sk_buff *skb, void *ctx)\n{\n\tstruct cxgbi_sock *csk = ctx;\n\tstruct cpl_iscsi_hdr *hdr_cpl = cplhdr(skb);\n\tstruct cpl_iscsi_hdr_norss data_cpl;\n\tstruct cpl_rx_data_ddp_norss ddp_cpl;\n\tunsigned int hdr_len, data_len, status;\n\tunsigned int len;\n\tint err;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_PDU_RX,\n\t\t\"csk 0x%p,%u,0x%lx,%u, skb 0x%p,%u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid, skb, skb->len);\n\n\tspin_lock_bh(&csk->lock);\n\n\tif (unlikely(csk->state >= CTP_PASSIVE_CLOSE)) {\n\t\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\t\"csk 0x%p,%u,0x%lx,%u, bad state.\\n\",\n\t\t\tcsk, csk->state, csk->flags, csk->tid);\n\t\tif (csk->state != CTP_ABORTING)\n\t\t\tgoto abort_conn;\n\t\telse\n\t\t\tgoto discard;\n\t}\n\n\tcxgbi_skcb_tcp_seq(skb) = ntohl(hdr_cpl->seq);\n\tcxgbi_skcb_flags(skb) = 0;\n\n\tskb_reset_transport_header(skb);\n\t__skb_pull(skb, sizeof(struct cpl_iscsi_hdr));\n\n\tlen = hdr_len = ntohs(hdr_cpl->len);\n\t \n\tif (skb->len <= hdr_len) {\n\t\tpr_err(\"%s: tid %u, CPL_ISCSI_HDR, skb len %u < %u.\\n\",\n\t\t\tcsk->cdev->ports[csk->port_id]->name, csk->tid,\n\t\t\tskb->len, hdr_len);\n\t\tgoto abort_conn;\n\t}\n\tcxgbi_skcb_set_flag(skb, SKCBF_RX_COALESCED);\n\n\terr = skb_copy_bits(skb, skb->len - sizeof(ddp_cpl), &ddp_cpl,\n\t\t\t    sizeof(ddp_cpl));\n\tif (err < 0) {\n\t\tpr_err(\"%s: tid %u, copy cpl_ddp %u-%zu failed %d.\\n\",\n\t\t\tcsk->cdev->ports[csk->port_id]->name, csk->tid,\n\t\t\tskb->len, sizeof(ddp_cpl), err);\n\t\tgoto abort_conn;\n\t}\n\n\tcxgbi_skcb_set_flag(skb, SKCBF_RX_STATUS);\n\tcxgbi_skcb_rx_pdulen(skb) = ntohs(ddp_cpl.len);\n\tcxgbi_skcb_rx_ddigest(skb) = ntohl(ddp_cpl.ulp_crc);\n\tstatus = ntohl(ddp_cpl.ddp_status);\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_PDU_RX,\n\t\t\"csk 0x%p, skb 0x%p,%u, pdulen %u, status 0x%x.\\n\",\n\t\tcsk, skb, skb->len, cxgbi_skcb_rx_pdulen(skb), status);\n\n\tif (status & (1 << CPL_RX_DDP_STATUS_HCRC_SHIFT))\n\t\tcxgbi_skcb_set_flag(skb, SKCBF_RX_HCRC_ERR);\n\tif (status & (1 << CPL_RX_DDP_STATUS_DCRC_SHIFT))\n\t\tcxgbi_skcb_set_flag(skb, SKCBF_RX_DCRC_ERR);\n\tif (status & (1 << CPL_RX_DDP_STATUS_PAD_SHIFT))\n\t\tcxgbi_skcb_set_flag(skb, SKCBF_RX_PAD_ERR);\n\n\tif (skb->len > (hdr_len + sizeof(ddp_cpl))) {\n\t\terr = skb_copy_bits(skb, hdr_len, &data_cpl, sizeof(data_cpl));\n\t\tif (err < 0) {\n\t\t\tpr_err(\"%s: tid %u, cp %zu/%u failed %d.\\n\",\n\t\t\t\tcsk->cdev->ports[csk->port_id]->name,\n\t\t\t\tcsk->tid, sizeof(data_cpl), skb->len, err);\n\t\t\tgoto abort_conn;\n\t\t}\n\t\tdata_len = ntohs(data_cpl.len);\n\t\tlog_debug(1 << CXGBI_DBG_DDP | 1 << CXGBI_DBG_PDU_RX,\n\t\t\t\"skb 0x%p, pdu not ddp'ed %u/%u, status 0x%x.\\n\",\n\t\t\tskb, data_len, cxgbi_skcb_rx_pdulen(skb), status);\n\t\tlen += sizeof(data_cpl) + data_len;\n\t} else if (status & (1 << CPL_RX_DDP_STATUS_DDP_SHIFT))\n\t\tcxgbi_skcb_set_flag(skb, SKCBF_RX_DATA_DDPD);\n\n\tcsk->rcv_nxt = ntohl(ddp_cpl.seq) + cxgbi_skcb_rx_pdulen(skb);\n\t__pskb_trim(skb, len);\n\t__skb_queue_tail(&csk->receive_queue, skb);\n\tcxgbi_conn_pdu_ready(csk);\n\n\tspin_unlock_bh(&csk->lock);\n\treturn 0;\n\nabort_conn:\n\tsend_abort_req(csk);\ndiscard:\n\tspin_unlock_bh(&csk->lock);\n\t__kfree_skb(skb);\n\treturn 0;\n}\n\n \nstatic int do_wr_ack(struct t3cdev *cdev, struct sk_buff *skb, void *ctx)\n{\n\tstruct cxgbi_sock *csk = ctx;\n\tstruct cpl_wr_ack *hdr = cplhdr(skb);\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_PDU_RX,\n\t\t\"csk 0x%p,%u,0x%lx,%u, cr %u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid, ntohs(hdr->credits));\n\n\tcxgbi_sock_rcv_wr_ack(csk, ntohs(hdr->credits), ntohl(hdr->snd_una), 1);\n\t__kfree_skb(skb);\n\treturn 0;\n}\n\n \nstatic int alloc_cpls(struct cxgbi_sock *csk)\n{\n\tcsk->cpl_close = alloc_wr(sizeof(struct cpl_close_con_req), 0,\n\t\t\t\t\tGFP_KERNEL);\n\tif (!csk->cpl_close)\n\t\treturn -ENOMEM;\n\tcsk->cpl_abort_req = alloc_wr(sizeof(struct cpl_abort_req), 0,\n\t\t\t\t\tGFP_KERNEL);\n\tif (!csk->cpl_abort_req)\n\t\tgoto free_cpl_skbs;\n\n\tcsk->cpl_abort_rpl = alloc_wr(sizeof(struct cpl_abort_rpl), 0,\n\t\t\t\t\tGFP_KERNEL);\n\tif (!csk->cpl_abort_rpl)\n\t\tgoto free_cpl_skbs;\n\n\treturn 0;\n\nfree_cpl_skbs:\n\tcxgbi_sock_free_cpl_skbs(csk);\n\treturn -ENOMEM;\n}\n\nstatic void l2t_put(struct cxgbi_sock *csk)\n{\n\tstruct t3cdev *t3dev = (struct t3cdev *)csk->cdev->lldev;\n\n\tif (csk->l2t) {\n\t\tl2t_release(t3dev, csk->l2t);\n\t\tcsk->l2t = NULL;\n\t\tcxgbi_sock_put(csk);\n\t}\n}\n\n \nstatic void release_offload_resources(struct cxgbi_sock *csk)\n{\n\tstruct t3cdev *t3dev = (struct t3cdev *)csk->cdev->lldev;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx,%u.\\n\",\n\t\tcsk, csk->state, csk->flags, csk->tid);\n\n\tcsk->rss_qid = 0;\n\tcxgbi_sock_free_cpl_skbs(csk);\n\n\tif (csk->wr_cred != csk->wr_max_cred) {\n\t\tcxgbi_sock_purge_wr_queue(csk);\n\t\tcxgbi_sock_reset_wr_list(csk);\n\t}\n\tl2t_put(csk);\n\tif (cxgbi_sock_flag(csk, CTPF_HAS_ATID))\n\t\tfree_atid(csk);\n\telse if (cxgbi_sock_flag(csk, CTPF_HAS_TID)) {\n\t\tcxgb3_remove_tid(t3dev, (void *)csk, csk->tid);\n\t\tcxgbi_sock_clear_flag(csk, CTPF_HAS_TID);\n\t\tcxgbi_sock_put(csk);\n\t}\n\tcsk->dst = NULL;\n\tcsk->cdev = NULL;\n}\n\nstatic void update_address(struct cxgbi_hba *chba)\n{\n\tif (chba->ipv4addr) {\n\t\tif (chba->vdev &&\n\t\t    chba->ipv4addr != cxgb3i_get_private_ipv4addr(chba->vdev)) {\n\t\t\tcxgb3i_set_private_ipv4addr(chba->vdev, chba->ipv4addr);\n\t\t\tcxgb3i_set_private_ipv4addr(chba->ndev, 0);\n\t\t\tpr_info(\"%s set %pI4.\\n\",\n\t\t\t\tchba->vdev->name, &chba->ipv4addr);\n\t\t} else if (chba->ipv4addr !=\n\t\t\t\tcxgb3i_get_private_ipv4addr(chba->ndev)) {\n\t\t\tcxgb3i_set_private_ipv4addr(chba->ndev, chba->ipv4addr);\n\t\t\tpr_info(\"%s set %pI4.\\n\",\n\t\t\t\tchba->ndev->name, &chba->ipv4addr);\n\t\t}\n\t} else if (cxgb3i_get_private_ipv4addr(chba->ndev)) {\n\t\tif (chba->vdev)\n\t\t\tcxgb3i_set_private_ipv4addr(chba->vdev, 0);\n\t\tcxgb3i_set_private_ipv4addr(chba->ndev, 0);\n\t}\n}\n\nstatic int init_act_open(struct cxgbi_sock *csk)\n{\n\tstruct dst_entry *dst = csk->dst;\n\tstruct cxgbi_device *cdev = csk->cdev;\n\tstruct t3cdev *t3dev = (struct t3cdev *)cdev->lldev;\n\tstruct net_device *ndev = cdev->ports[csk->port_id];\n\tstruct cxgbi_hba *chba = cdev->hbas[csk->port_id];\n\tstruct sk_buff *skb = NULL;\n\tint ret;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx.\\n\", csk, csk->state, csk->flags);\n\n\tupdate_address(chba);\n\tif (chba->ipv4addr)\n\t\tcsk->saddr.sin_addr.s_addr = chba->ipv4addr;\n\n\tcsk->rss_qid = 0;\n\tcsk->l2t = t3_l2t_get(t3dev, dst, ndev,\n\t\t\t      &csk->daddr.sin_addr.s_addr);\n\tif (!csk->l2t) {\n\t\tpr_err(\"NO l2t available.\\n\");\n\t\treturn -EINVAL;\n\t}\n\tcxgbi_sock_get(csk);\n\n\tcsk->atid = cxgb3_alloc_atid(t3dev, &t3_client, csk);\n\tif (csk->atid < 0) {\n\t\tpr_err(\"NO atid available.\\n\");\n\t\tret = -EINVAL;\n\t\tgoto put_sock;\n\t}\n\tcxgbi_sock_set_flag(csk, CTPF_HAS_ATID);\n\tcxgbi_sock_get(csk);\n\n\tskb = alloc_wr(sizeof(struct cpl_act_open_req), 0, GFP_KERNEL);\n\tif (!skb) {\n\t\tret = -ENOMEM;\n\t\tgoto free_atid;\n\t}\n\tskb->sk = (struct sock *)csk;\n\tset_arp_failure_handler(skb, act_open_arp_failure);\n\tcsk->snd_win = cxgb3i_snd_win;\n\tcsk->rcv_win = cxgb3i_rcv_win;\n\n\tcsk->wr_max_cred = csk->wr_cred = T3C_DATA(t3dev)->max_wrs - 1;\n\tcsk->wr_una_cred = 0;\n\tcsk->mss_idx = cxgbi_sock_select_mss(csk, dst_mtu(dst));\n\tcxgbi_sock_reset_wr_list(csk);\n\tcsk->err = 0;\n\n\tlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\n\t\t\"csk 0x%p,%u,0x%lx, %pI4:%u-%pI4:%u.\\n\",\n\t\tcsk, csk->state, csk->flags,\n\t\t&csk->saddr.sin_addr.s_addr, ntohs(csk->saddr.sin_port),\n\t\t&csk->daddr.sin_addr.s_addr, ntohs(csk->daddr.sin_port));\n\n\tcxgbi_sock_set_state(csk, CTP_ACTIVE_OPEN);\n\tsend_act_open_req(csk, skb, csk->l2t);\n\treturn 0;\n\nfree_atid:\n\tcxgb3_free_atid(t3dev, csk->atid);\nput_sock:\n\tcxgbi_sock_put(csk);\n\tl2t_release(t3dev, csk->l2t);\n\tcsk->l2t = NULL;\n\n\treturn ret;\n}\n\ncxgb3_cpl_handler_func cxgb3i_cpl_handlers[NUM_CPL_CMDS] = {\n\t[CPL_ACT_ESTABLISH] = do_act_establish,\n\t[CPL_ACT_OPEN_RPL] = do_act_open_rpl,\n\t[CPL_PEER_CLOSE] = do_peer_close,\n\t[CPL_ABORT_REQ_RSS] = do_abort_req,\n\t[CPL_ABORT_RPL_RSS] = do_abort_rpl,\n\t[CPL_CLOSE_CON_RPL] = do_close_con_rpl,\n\t[CPL_TX_DMA_ACK] = do_wr_ack,\n\t[CPL_ISCSI_HDR] = do_iscsi_hdr,\n};\n\n \nstatic int cxgb3i_ofld_init(struct cxgbi_device *cdev)\n{\n\tstruct t3cdev *t3dev = (struct t3cdev *)cdev->lldev;\n\tstruct adap_ports port;\n\tstruct ofld_page_info rx_page_info;\n\tunsigned int wr_len;\n\tint rc;\n\n\tif (t3dev->ctl(t3dev, GET_WR_LEN, &wr_len) < 0 ||\n\t    t3dev->ctl(t3dev, GET_PORTS, &port) < 0 ||\n\t    t3dev->ctl(t3dev, GET_RX_PAGE_INFO, &rx_page_info) < 0) {\n\t\tpr_warn(\"t3 0x%p, offload up, ioctl failed.\\n\", t3dev);\n\t\treturn -EINVAL;\n\t}\n\n\tif (cxgb3i_max_connect > CXGBI_MAX_CONN)\n\t\tcxgb3i_max_connect = CXGBI_MAX_CONN;\n\n\trc = cxgbi_device_portmap_create(cdev, cxgb3i_sport_base,\n\t\t\t\t\tcxgb3i_max_connect);\n\tif (rc < 0)\n\t\treturn rc;\n\n\tinit_wr_tab(wr_len);\n\tcdev->csk_release_offload_resources = release_offload_resources;\n\tcdev->csk_push_tx_frames = push_tx_frames;\n\tcdev->csk_send_abort_req = send_abort_req;\n\tcdev->csk_send_close_req = send_close_req;\n\tcdev->csk_send_rx_credits = send_rx_credits;\n\tcdev->csk_alloc_cpls = alloc_cpls;\n\tcdev->csk_init_act_open = init_act_open;\n\n\tpr_info(\"cdev 0x%p, offload up, added.\\n\", cdev);\n\treturn 0;\n}\n\n \nstatic inline void ulp_mem_io_set_hdr(struct sk_buff *skb, unsigned int addr)\n{\n\tstruct ulp_mem_io *req = (struct ulp_mem_io *)skb->head;\n\n\tmemset(req, 0, sizeof(*req));\n\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_BYPASS));\n\treq->cmd_lock_addr = htonl(V_ULP_MEMIO_ADDR(addr >> 5) |\n\t\t\t\t   V_ULPTX_CMD(ULP_MEM_WRITE));\n\treq->len = htonl(V_ULP_MEMIO_DATA_LEN(IPPOD_SIZE >> 5) |\n\t\t\t V_ULPTX_NFLITS((IPPOD_SIZE >> 3) + 1));\n}\n\nstatic struct cxgbi_ppm *cdev2ppm(struct cxgbi_device *cdev)\n{\n\treturn ((struct t3cdev *)cdev->lldev)->ulp_iscsi;\n}\n\nstatic int ddp_set_map(struct cxgbi_ppm *ppm, struct cxgbi_sock *csk,\n\t\t       struct cxgbi_task_tag_info *ttinfo)\n{\n\tunsigned int idx = ttinfo->idx;\n\tunsigned int npods = ttinfo->npods;\n\tstruct scatterlist *sg = ttinfo->sgl;\n\tstruct cxgbi_pagepod *ppod;\n\tstruct ulp_mem_io *req;\n\tunsigned int sg_off;\n\tunsigned int pm_addr = (idx << PPOD_SIZE_SHIFT) + ppm->llimit;\n\tint i;\n\n\tfor (i = 0; i < npods; i++, idx++, pm_addr += IPPOD_SIZE) {\n\t\tstruct sk_buff *skb = alloc_wr(sizeof(struct ulp_mem_io) +\n\t\t\t\t\t       IPPOD_SIZE, 0, GFP_ATOMIC);\n\n\t\tif (!skb)\n\t\t\treturn -ENOMEM;\n\t\tulp_mem_io_set_hdr(skb, pm_addr);\n\t\treq = (struct ulp_mem_io *)skb->head;\n\t\tppod = (struct cxgbi_pagepod *)(req + 1);\n\t\tsg_off = i * PPOD_PAGES_MAX;\n\t\tcxgbi_ddp_set_one_ppod(ppod, ttinfo, &sg,\n\t\t\t\t       &sg_off);\n\t\tskb->priority = CPL_PRIORITY_CONTROL;\n\t\tcxgb3_ofld_send(ppm->lldev, skb);\n\t}\n\treturn 0;\n}\n\nstatic void ddp_clear_map(struct cxgbi_device *cdev, struct cxgbi_ppm *ppm,\n\t\t\t  struct cxgbi_task_tag_info *ttinfo)\n{\n\tunsigned int idx = ttinfo->idx;\n\tunsigned int pm_addr = (idx << PPOD_SIZE_SHIFT) + ppm->llimit;\n\tunsigned int npods = ttinfo->npods;\n\tint i;\n\n\tlog_debug(1 << CXGBI_DBG_DDP,\n\t\t  \"cdev 0x%p, clear idx %u, npods %u.\\n\",\n\t\t  cdev, idx, npods);\n\n\tfor (i = 0; i < npods; i++, idx++, pm_addr += IPPOD_SIZE) {\n\t\tstruct sk_buff *skb = alloc_wr(sizeof(struct ulp_mem_io) +\n\t\t\t\t\t       IPPOD_SIZE, 0, GFP_ATOMIC);\n\n\t\tif (!skb) {\n\t\t\tpr_err(\"cdev 0x%p, clear ddp, %u,%d/%u, skb OOM.\\n\",\n\t\t\t       cdev, idx, i, npods);\n\t\t\tcontinue;\n\t\t}\n\t\tulp_mem_io_set_hdr(skb, pm_addr);\n\t\tskb->priority = CPL_PRIORITY_CONTROL;\n\t\tcxgb3_ofld_send(ppm->lldev, skb);\n\t}\n}\n\nstatic int ddp_setup_conn_pgidx(struct cxgbi_sock *csk,\n\t\t\t\tunsigned int tid, int pg_idx)\n{\n\tstruct sk_buff *skb = alloc_wr(sizeof(struct cpl_set_tcb_field), 0,\n\t\t\t\t\tGFP_KERNEL);\n\tstruct cpl_set_tcb_field *req;\n\tu64 val = pg_idx < DDP_PGIDX_MAX ? pg_idx : 0;\n\n\tlog_debug(1 << CXGBI_DBG_DDP,\n\t\t\"csk 0x%p, tid %u, pg_idx %d.\\n\", csk, tid, pg_idx);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\t \n\treq = (struct cpl_set_tcb_field *)skb->head;\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_SET_TCB_FIELD, tid));\n\treq->reply = V_NO_REPLY(1);\n\treq->cpu_idx = 0;\n\treq->word = htons(31);\n\treq->mask = cpu_to_be64(0xF0000000);\n\treq->val = cpu_to_be64(val << 28);\n\tskb->priority = CPL_PRIORITY_CONTROL;\n\n\tcxgb3_ofld_send(csk->cdev->lldev, skb);\n\treturn 0;\n}\n\n \nstatic int ddp_setup_conn_digest(struct cxgbi_sock *csk, unsigned int tid,\n\t\t\t\t int hcrc, int dcrc)\n{\n\tstruct sk_buff *skb = alloc_wr(sizeof(struct cpl_set_tcb_field), 0,\n\t\t\t\t\tGFP_KERNEL);\n\tstruct cpl_set_tcb_field *req;\n\tu64 val = (hcrc ? 1 : 0) | (dcrc ? 2 : 0);\n\n\tlog_debug(1 << CXGBI_DBG_DDP,\n\t\t\"csk 0x%p, tid %u, crc %d,%d.\\n\", csk, tid, hcrc, dcrc);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\t \n\treq = (struct cpl_set_tcb_field *)skb->head;\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_SET_TCB_FIELD, tid));\n\treq->reply = V_NO_REPLY(1);\n\treq->cpu_idx = 0;\n\treq->word = htons(31);\n\treq->mask = cpu_to_be64(0x0F000000);\n\treq->val = cpu_to_be64(val << 24);\n\tskb->priority = CPL_PRIORITY_CONTROL;\n\n\tcxgb3_ofld_send(csk->cdev->lldev, skb);\n\treturn 0;\n}\n\n \nstatic int cxgb3i_ddp_init(struct cxgbi_device *cdev)\n{\n\tstruct t3cdev *tdev = (struct t3cdev *)cdev->lldev;\n\tstruct net_device *ndev = cdev->ports[0];\n\tstruct cxgbi_tag_format tformat;\n\tunsigned int ppmax, tagmask = 0;\n\tstruct ulp_iscsi_info uinfo;\n\tint i, err;\n\n\terr = tdev->ctl(tdev, ULP_ISCSI_GET_PARAMS, &uinfo);\n\tif (err < 0) {\n\t\tpr_err(\"%s, failed to get iscsi param %d.\\n\",\n\t\t       ndev->name, err);\n\t\treturn err;\n\t}\n\tif (uinfo.llimit >= uinfo.ulimit) {\n\t\tpr_warn(\"T3 %s, iscsi NOT enabled %u ~ %u!\\n\",\n\t\t\tndev->name, uinfo.llimit, uinfo.ulimit);\n\t\treturn -EACCES;\n\t}\n\n\tppmax = (uinfo.ulimit - uinfo.llimit + 1) >> PPOD_SIZE_SHIFT;\n\ttagmask = cxgbi_tagmask_set(ppmax);\n\n\tpr_info(\"T3 %s: 0x%x~0x%x, 0x%x, tagmask 0x%x -> 0x%x.\\n\",\n\t\tndev->name, uinfo.llimit, uinfo.ulimit, ppmax, uinfo.tagmask,\n\t\ttagmask);\n\n\tmemset(&tformat, 0, sizeof(struct cxgbi_tag_format));\n\tfor (i = 0; i < 4; i++)\n\t\ttformat.pgsz_order[i] = uinfo.pgsz_factor[i];\n\tcxgbi_tagmask_check(tagmask, &tformat);\n\n\terr = cxgbi_ddp_ppm_setup(&tdev->ulp_iscsi, cdev, &tformat,\n\t\t\t\t  (uinfo.ulimit - uinfo.llimit + 1),\n\t\t\t\t  uinfo.llimit, uinfo.llimit, 0, 0, 0);\n\tif (err)\n\t\treturn err;\n\n\tif (!(cdev->flags & CXGBI_FLAG_DDP_OFF)) {\n\t\tuinfo.tagmask = tagmask;\n\t\tuinfo.ulimit = uinfo.llimit + (ppmax << PPOD_SIZE_SHIFT);\n\n\t\terr = tdev->ctl(tdev, ULP_ISCSI_SET_PARAMS, &uinfo);\n\t\tif (err < 0) {\n\t\t\tpr_err(\"T3 %s fail to set iscsi param %d.\\n\",\n\t\t\t       ndev->name, err);\n\t\t\tcdev->flags |= CXGBI_FLAG_DDP_OFF;\n\t\t}\n\t\terr = 0;\n\t}\n\n\tcdev->csk_ddp_setup_digest = ddp_setup_conn_digest;\n\tcdev->csk_ddp_setup_pgidx = ddp_setup_conn_pgidx;\n\tcdev->csk_ddp_set_map = ddp_set_map;\n\tcdev->csk_ddp_clear_map = ddp_clear_map;\n\tcdev->cdev2ppm = cdev2ppm;\n\tcdev->tx_max_size = min_t(unsigned int, ULP2_MAX_PDU_PAYLOAD,\n\t\t\t\t  uinfo.max_txsz - ISCSI_PDU_NONPAYLOAD_LEN);\n\tcdev->rx_max_size = min_t(unsigned int, ULP2_MAX_PDU_PAYLOAD,\n\t\t\t\t  uinfo.max_rxsz - ISCSI_PDU_NONPAYLOAD_LEN);\n\n\treturn 0;\n}\n\nstatic void cxgb3i_dev_close(struct t3cdev *t3dev)\n{\n\tstruct cxgbi_device *cdev = cxgbi_device_find_by_lldev(t3dev);\n\n\tif (!cdev || cdev->flags & CXGBI_FLAG_ADAPTER_RESET) {\n\t\tpr_info(\"0x%p close, f 0x%x.\\n\", cdev, cdev ? cdev->flags : 0);\n\t\treturn;\n\t}\n\n\tcxgbi_device_unregister(cdev);\n}\n\n \nstatic void cxgb3i_dev_open(struct t3cdev *t3dev)\n{\n\tstruct cxgbi_device *cdev = cxgbi_device_find_by_lldev(t3dev);\n\tstruct adapter *adapter = tdev2adap(t3dev);\n\tint i, err;\n\n\tif (cdev) {\n\t\tpr_info(\"0x%p, updating.\\n\", cdev);\n\t\treturn;\n\t}\n\n\tcdev = cxgbi_device_register(0, adapter->params.nports);\n\tif (!cdev) {\n\t\tpr_warn(\"device 0x%p register failed.\\n\", t3dev);\n\t\treturn;\n\t}\n\n\tcdev->flags = CXGBI_FLAG_DEV_T3 | CXGBI_FLAG_IPV4_SET;\n\tcdev->lldev = t3dev;\n\tcdev->pdev = adapter->pdev;\n\tcdev->ports = adapter->port;\n\tcdev->nports = adapter->params.nports;\n\tcdev->mtus = adapter->params.mtus;\n\tcdev->nmtus = NMTUS;\n\tcdev->rx_credit_thres = cxgb3i_rx_credit_thres;\n\tcdev->skb_tx_rsvd = CXGB3I_TX_HEADER_LEN;\n\tcdev->skb_rx_extra = sizeof(struct cpl_iscsi_hdr_norss);\n\tcdev->itp = &cxgb3i_iscsi_transport;\n\n\terr = cxgb3i_ddp_init(cdev);\n\tif (err) {\n\t\tpr_info(\"0x%p ddp init failed %d\\n\", cdev, err);\n\t\tgoto err_out;\n\t}\n\n\terr = cxgb3i_ofld_init(cdev);\n\tif (err) {\n\t\tpr_info(\"0x%p offload init failed\\n\", cdev);\n\t\tgoto err_out;\n\t}\n\n\terr = cxgbi_hbas_add(cdev, CXGB3I_MAX_LUN, CXGBI_MAX_CONN,\n\t\t\t\t&cxgb3i_host_template, cxgb3i_stt);\n\tif (err)\n\t\tgoto err_out;\n\n\tfor (i = 0; i < cdev->nports; i++)\n\t\tcdev->hbas[i]->ipv4addr =\n\t\t\tcxgb3i_get_private_ipv4addr(cdev->ports[i]);\n\n\tpr_info(\"cdev 0x%p, f 0x%x, t3dev 0x%p open, err %d.\\n\",\n\t\tcdev, cdev ? cdev->flags : 0, t3dev, err);\n\treturn;\n\nerr_out:\n\tcxgbi_device_unregister(cdev);\n}\n\nstatic void cxgb3i_dev_event_handler(struct t3cdev *t3dev, u32 event, u32 port)\n{\n\tstruct cxgbi_device *cdev = cxgbi_device_find_by_lldev(t3dev);\n\n\tlog_debug(1 << CXGBI_DBG_TOE,\n\t\t\"0x%p, cdev 0x%p, event 0x%x, port 0x%x.\\n\",\n\t\tt3dev, cdev, event, port);\n\tif (!cdev)\n\t\treturn;\n\n\tswitch (event) {\n\tcase OFFLOAD_STATUS_DOWN:\n\t\tcdev->flags |= CXGBI_FLAG_ADAPTER_RESET;\n\t\tbreak;\n\tcase OFFLOAD_STATUS_UP:\n\t\tcdev->flags &= ~CXGBI_FLAG_ADAPTER_RESET;\n\t\tbreak;\n\t}\n}\n\n \nstatic int __init cxgb3i_init_module(void)\n{\n\tint rc;\n\n\tprintk(KERN_INFO \"%s\", version);\n\n\trc = cxgbi_iscsi_init(&cxgb3i_iscsi_transport, &cxgb3i_stt);\n\tif (rc < 0)\n\t\treturn rc;\n\n\tcxgb3_register_client(&t3_client);\n\treturn 0;\n}\n\n \nstatic void __exit cxgb3i_exit_module(void)\n{\n\tcxgb3_unregister_client(&t3_client);\n\tcxgbi_device_unregister_all(CXGBI_FLAG_DEV_T3);\n\tcxgbi_iscsi_cleanup(&cxgb3i_iscsi_transport, &cxgb3i_stt);\n}\n\nmodule_init(cxgb3i_init_module);\nmodule_exit(cxgb3i_exit_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}