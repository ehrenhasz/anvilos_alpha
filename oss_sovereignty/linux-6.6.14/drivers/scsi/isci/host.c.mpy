{
  "module_name": "host.c",
  "hash_id": "ce9316f5dad39cbe918800f9e233ad3cd5620ac96f3c86559e83bf2fc2d7fea8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/isci/host.c",
  "human_readable_source": " \n#include <linux/circ_buf.h>\n#include <linux/device.h>\n#include <scsi/sas.h>\n#include \"host.h\"\n#include \"isci.h\"\n#include \"port.h\"\n#include \"probe_roms.h\"\n#include \"remote_device.h\"\n#include \"request.h\"\n#include \"scu_completion_codes.h\"\n#include \"scu_event_codes.h\"\n#include \"registers.h\"\n#include \"scu_remote_node_context.h\"\n#include \"scu_task_context.h\"\n\n#define SCU_CONTEXT_RAM_INIT_STALL_TIME      200\n\n#define smu_max_ports(dcc_value) \\\n\t(\\\n\t\t(((dcc_value) & SMU_DEVICE_CONTEXT_CAPACITY_MAX_LP_MASK) \\\n\t\t >> SMU_DEVICE_CONTEXT_CAPACITY_MAX_LP_SHIFT) + 1 \\\n\t)\n\n#define smu_max_task_contexts(dcc_value)\t\\\n\t(\\\n\t\t(((dcc_value) & SMU_DEVICE_CONTEXT_CAPACITY_MAX_TC_MASK) \\\n\t\t >> SMU_DEVICE_CONTEXT_CAPACITY_MAX_TC_SHIFT) + 1 \\\n\t)\n\n#define smu_max_rncs(dcc_value) \\\n\t(\\\n\t\t(((dcc_value) & SMU_DEVICE_CONTEXT_CAPACITY_MAX_RNC_MASK) \\\n\t\t >> SMU_DEVICE_CONTEXT_CAPACITY_MAX_RNC_SHIFT) + 1 \\\n\t)\n\n#define SCIC_SDS_CONTROLLER_PHY_START_TIMEOUT      100\n\n \n#define SCIC_SDS_CONTROLLER_POWER_CONTROL_INTERVAL 500\n\n \n#define NORMALIZE_PUT_POINTER(x) \\\n\t((x) & SMU_COMPLETION_QUEUE_PUT_POINTER_MASK)\n\n\n \n#define NORMALIZE_EVENT_POINTER(x) \\\n\t(\\\n\t\t((x) & SMU_COMPLETION_QUEUE_GET_EVENT_POINTER_MASK) \\\n\t\t>> SMU_COMPLETION_QUEUE_GET_EVENT_POINTER_SHIFT\t\\\n\t)\n\n \n#define NORMALIZE_GET_POINTER(x) \\\n\t((x) & SMU_COMPLETION_QUEUE_GET_POINTER_MASK)\n\n \n#define NORMALIZE_GET_POINTER_CYCLE_BIT(x) \\\n\t((SMU_CQGR_CYCLE_BIT & (x)) << (31 - SMU_COMPLETION_QUEUE_GET_CYCLE_BIT_SHIFT))\n\n \n#define COMPLETION_QUEUE_CYCLE_BIT(x) ((x) & 0x80000000)\n\n \nvoid sci_init_sm(struct sci_base_state_machine *sm,\n\t\t const struct sci_base_state *state_table, u32 initial_state)\n{\n\tsci_state_transition_t handler;\n\n\tsm->initial_state_id    = initial_state;\n\tsm->previous_state_id   = initial_state;\n\tsm->current_state_id    = initial_state;\n\tsm->state_table         = state_table;\n\n\thandler = sm->state_table[initial_state].enter_state;\n\tif (handler)\n\t\thandler(sm);\n}\n\n \nvoid sci_change_state(struct sci_base_state_machine *sm, u32 next_state)\n{\n\tsci_state_transition_t handler;\n\n\thandler = sm->state_table[sm->current_state_id].exit_state;\n\tif (handler)\n\t\thandler(sm);\n\n\tsm->previous_state_id = sm->current_state_id;\n\tsm->current_state_id = next_state;\n\n\thandler = sm->state_table[sm->current_state_id].enter_state;\n\tif (handler)\n\t\thandler(sm);\n}\n\nstatic bool sci_controller_completion_queue_has_entries(struct isci_host *ihost)\n{\n\tu32 get_value = ihost->completion_queue_get;\n\tu32 get_index = get_value & SMU_COMPLETION_QUEUE_GET_POINTER_MASK;\n\n\tif (NORMALIZE_GET_POINTER_CYCLE_BIT(get_value) ==\n\t    COMPLETION_QUEUE_CYCLE_BIT(ihost->completion_queue[get_index]))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic bool sci_controller_isr(struct isci_host *ihost)\n{\n\tif (sci_controller_completion_queue_has_entries(ihost))\n\t\treturn true;\n\n\t \n\twritel(SMU_ISR_COMPLETION, &ihost->smu_registers->interrupt_status);\n\n\t \n\tspin_lock(&ihost->scic_lock);\n\tif (test_bit(IHOST_IRQ_ENABLED, &ihost->flags)) {\n\t\twritel(0xFF000000, &ihost->smu_registers->interrupt_mask);\n\t\twritel(0, &ihost->smu_registers->interrupt_mask);\n\t}\n\tspin_unlock(&ihost->scic_lock);\n\n\treturn false;\n}\n\nirqreturn_t isci_msix_isr(int vec, void *data)\n{\n\tstruct isci_host *ihost = data;\n\n\tif (sci_controller_isr(ihost))\n\t\ttasklet_schedule(&ihost->completion_tasklet);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic bool sci_controller_error_isr(struct isci_host *ihost)\n{\n\tu32 interrupt_status;\n\n\tinterrupt_status =\n\t\treadl(&ihost->smu_registers->interrupt_status);\n\tinterrupt_status &= (SMU_ISR_QUEUE_ERROR | SMU_ISR_QUEUE_SUSPEND);\n\n\tif (interrupt_status != 0) {\n\t\t \n\t\treturn true;\n\t}\n\n\t \n\twritel(0xff, &ihost->smu_registers->interrupt_mask);\n\twritel(0, &ihost->smu_registers->interrupt_mask);\n\n\treturn false;\n}\n\nstatic void sci_controller_task_completion(struct isci_host *ihost, u32 ent)\n{\n\tu32 index = SCU_GET_COMPLETION_INDEX(ent);\n\tstruct isci_request *ireq = ihost->reqs[index];\n\n\t \n\tif (test_bit(IREQ_ACTIVE, &ireq->flags) &&\n\t    ireq->io_tag != SCI_CONTROLLER_INVALID_IO_TAG &&\n\t    ISCI_TAG_SEQ(ireq->io_tag) == ihost->io_request_sequence[index])\n\t\t \n\t\tsci_io_request_tc_completion(ireq, ent);\n}\n\nstatic void sci_controller_sdma_completion(struct isci_host *ihost, u32 ent)\n{\n\tu32 index;\n\tstruct isci_request *ireq;\n\tstruct isci_remote_device *idev;\n\n\tindex = SCU_GET_COMPLETION_INDEX(ent);\n\n\tswitch (scu_get_command_request_type(ent)) {\n\tcase SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC:\n\tcase SCU_CONTEXT_COMMAND_REQUEST_TYPE_DUMP_TC:\n\t\tireq = ihost->reqs[index];\n\t\tdev_warn(&ihost->pdev->dev, \"%s: %x for io request %p\\n\",\n\t\t\t __func__, ent, ireq);\n\t\t \n\t\tbreak;\n\tcase SCU_CONTEXT_COMMAND_REQUEST_TYPE_DUMP_RNC:\n\tcase SCU_CONTEXT_COMMAND_REQUEST_TYPE_OTHER_RNC:\n\tcase SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_RNC:\n\t\tidev = ihost->device_table[index];\n\t\tdev_warn(&ihost->pdev->dev, \"%s: %x for device %p\\n\",\n\t\t\t __func__, ent, idev);\n\t\t \n\t\tbreak;\n\tdefault:\n\t\tdev_warn(&ihost->pdev->dev, \"%s: unknown completion type %x\\n\",\n\t\t\t __func__, ent);\n\t\tbreak;\n\t}\n}\n\nstatic void sci_controller_unsolicited_frame(struct isci_host *ihost, u32 ent)\n{\n\tu32 index;\n\tu32 frame_index;\n\n\tstruct scu_unsolicited_frame_header *frame_header;\n\tstruct isci_phy *iphy;\n\tstruct isci_remote_device *idev;\n\n\tenum sci_status result = SCI_FAILURE;\n\n\tframe_index = SCU_GET_FRAME_INDEX(ent);\n\n\tframe_header = ihost->uf_control.buffers.array[frame_index].header;\n\tihost->uf_control.buffers.array[frame_index].state = UNSOLICITED_FRAME_IN_USE;\n\n\tif (SCU_GET_FRAME_ERROR(ent)) {\n\t\t \n\t\tsci_controller_release_frame(ihost, frame_index);\n\t\treturn;\n\t}\n\n\tif (frame_header->is_address_frame) {\n\t\tindex = SCU_GET_PROTOCOL_ENGINE_INDEX(ent);\n\t\tiphy = &ihost->phys[index];\n\t\tresult = sci_phy_frame_handler(iphy, frame_index);\n\t} else {\n\n\t\tindex = SCU_GET_COMPLETION_INDEX(ent);\n\n\t\tif (index == SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX) {\n\t\t\t \n\t\t\tindex = SCU_GET_PROTOCOL_ENGINE_INDEX(ent);\n\t\t\tiphy = &ihost->phys[index];\n\t\t\tresult = sci_phy_frame_handler(iphy, frame_index);\n\t\t} else {\n\t\t\tif (index < ihost->remote_node_entries)\n\t\t\t\tidev = ihost->device_table[index];\n\t\t\telse\n\t\t\t\tidev = NULL;\n\n\t\t\tif (idev != NULL)\n\t\t\t\tresult = sci_remote_device_frame_handler(idev, frame_index);\n\t\t\telse\n\t\t\t\tsci_controller_release_frame(ihost, frame_index);\n\t\t}\n\t}\n\n\tif (result != SCI_SUCCESS) {\n\t\t \n\t}\n}\n\nstatic void sci_controller_event_completion(struct isci_host *ihost, u32 ent)\n{\n\tstruct isci_remote_device *idev;\n\tstruct isci_request *ireq;\n\tstruct isci_phy *iphy;\n\tu32 index;\n\n\tindex = SCU_GET_COMPLETION_INDEX(ent);\n\n\tswitch (scu_get_event_type(ent)) {\n\tcase SCU_EVENT_TYPE_SMU_COMMAND_ERROR:\n\t\t \n\t\tdev_err(&ihost->pdev->dev,\n\t\t\t\"%s: SCIC Controller 0x%p received SMU command error \"\n\t\t\t\"0x%x\\n\",\n\t\t\t__func__,\n\t\t\tihost,\n\t\t\tent);\n\t\tbreak;\n\n\tcase SCU_EVENT_TYPE_SMU_PCQ_ERROR:\n\tcase SCU_EVENT_TYPE_SMU_ERROR:\n\tcase SCU_EVENT_TYPE_FATAL_MEMORY_ERROR:\n\t\t \n\t\tdev_err(&ihost->pdev->dev,\n\t\t\t\"%s: SCIC Controller 0x%p received fatal controller \"\n\t\t\t\"event  0x%x\\n\",\n\t\t\t__func__,\n\t\t\tihost,\n\t\t\tent);\n\t\tbreak;\n\n\tcase SCU_EVENT_TYPE_TRANSPORT_ERROR:\n\t\tireq = ihost->reqs[index];\n\t\tsci_io_request_event_handler(ireq, ent);\n\t\tbreak;\n\n\tcase SCU_EVENT_TYPE_PTX_SCHEDULE_EVENT:\n\t\tswitch (scu_get_event_specifier(ent)) {\n\t\tcase SCU_EVENT_SPECIFIC_SMP_RESPONSE_NO_PE:\n\t\tcase SCU_EVENT_SPECIFIC_TASK_TIMEOUT:\n\t\t\tireq = ihost->reqs[index];\n\t\t\tif (ireq != NULL)\n\t\t\t\tsci_io_request_event_handler(ireq, ent);\n\t\t\telse\n\t\t\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t\t\t \"%s: SCIC Controller 0x%p received \"\n\t\t\t\t\t \"event 0x%x for io request object \"\n\t\t\t\t\t \"that doesn't exist.\\n\",\n\t\t\t\t\t __func__,\n\t\t\t\t\t ihost,\n\t\t\t\t\t ent);\n\n\t\t\tbreak;\n\n\t\tcase SCU_EVENT_SPECIFIC_IT_NEXUS_TIMEOUT:\n\t\t\tidev = ihost->device_table[index];\n\t\t\tif (idev != NULL)\n\t\t\t\tsci_remote_device_event_handler(idev, ent);\n\t\t\telse\n\t\t\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t\t\t \"%s: SCIC Controller 0x%p received \"\n\t\t\t\t\t \"event 0x%x for remote device object \"\n\t\t\t\t\t \"that doesn't exist.\\n\",\n\t\t\t\t\t __func__,\n\t\t\t\t\t ihost,\n\t\t\t\t\t ent);\n\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tcase SCU_EVENT_TYPE_BROADCAST_CHANGE:\n\t \n\tcase SCU_EVENT_TYPE_ERR_CNT_EVENT:\n\t \n\tcase SCU_EVENT_TYPE_OSSP_EVENT:\n\t\tindex = SCU_GET_PROTOCOL_ENGINE_INDEX(ent);\n\t\tiphy = &ihost->phys[index];\n\t\tsci_phy_event_handler(iphy, ent);\n\t\tbreak;\n\n\tcase SCU_EVENT_TYPE_RNC_SUSPEND_TX:\n\tcase SCU_EVENT_TYPE_RNC_SUSPEND_TX_RX:\n\tcase SCU_EVENT_TYPE_RNC_OPS_MISC:\n\t\tif (index < ihost->remote_node_entries) {\n\t\t\tidev = ihost->device_table[index];\n\n\t\t\tif (idev != NULL)\n\t\t\t\tsci_remote_device_event_handler(idev, ent);\n\t\t} else\n\t\t\tdev_err(&ihost->pdev->dev,\n\t\t\t\t\"%s: SCIC Controller 0x%p received event 0x%x \"\n\t\t\t\t\"for remote device object 0x%0x that doesn't \"\n\t\t\t\t\"exist.\\n\",\n\t\t\t\t__func__,\n\t\t\t\tihost,\n\t\t\t\tent,\n\t\t\t\tindex);\n\n\t\tbreak;\n\n\tdefault:\n\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t \"%s: SCIC Controller received unknown event code %x\\n\",\n\t\t\t __func__,\n\t\t\t ent);\n\t\tbreak;\n\t}\n}\n\nstatic void sci_controller_process_completions(struct isci_host *ihost)\n{\n\tu32 completion_count = 0;\n\tu32 ent;\n\tu32 get_index;\n\tu32 get_cycle;\n\tu32 event_get;\n\tu32 event_cycle;\n\n\tdev_dbg(&ihost->pdev->dev,\n\t\t\"%s: completion queue beginning get:0x%08x\\n\",\n\t\t__func__,\n\t\tihost->completion_queue_get);\n\n\t \n\tget_index = NORMALIZE_GET_POINTER(ihost->completion_queue_get);\n\tget_cycle = SMU_CQGR_CYCLE_BIT & ihost->completion_queue_get;\n\n\tevent_get = NORMALIZE_EVENT_POINTER(ihost->completion_queue_get);\n\tevent_cycle = SMU_CQGR_EVENT_CYCLE_BIT & ihost->completion_queue_get;\n\n\twhile (\n\t\tNORMALIZE_GET_POINTER_CYCLE_BIT(get_cycle)\n\t\t== COMPLETION_QUEUE_CYCLE_BIT(ihost->completion_queue[get_index])\n\t\t) {\n\t\tcompletion_count++;\n\n\t\tent = ihost->completion_queue[get_index];\n\n\t\t \n\t\tget_cycle ^= ((get_index+1) & SCU_MAX_COMPLETION_QUEUE_ENTRIES) <<\n\t\t\t     (SMU_COMPLETION_QUEUE_GET_CYCLE_BIT_SHIFT - SCU_MAX_COMPLETION_QUEUE_SHIFT);\n\t\tget_index = (get_index+1) & (SCU_MAX_COMPLETION_QUEUE_ENTRIES-1);\n\n\t\tdev_dbg(&ihost->pdev->dev,\n\t\t\t\"%s: completion queue entry:0x%08x\\n\",\n\t\t\t__func__,\n\t\t\tent);\n\n\t\tswitch (SCU_GET_COMPLETION_TYPE(ent)) {\n\t\tcase SCU_COMPLETION_TYPE_TASK:\n\t\t\tsci_controller_task_completion(ihost, ent);\n\t\t\tbreak;\n\n\t\tcase SCU_COMPLETION_TYPE_SDMA:\n\t\t\tsci_controller_sdma_completion(ihost, ent);\n\t\t\tbreak;\n\n\t\tcase SCU_COMPLETION_TYPE_UFI:\n\t\t\tsci_controller_unsolicited_frame(ihost, ent);\n\t\t\tbreak;\n\n\t\tcase SCU_COMPLETION_TYPE_EVENT:\n\t\t\tsci_controller_event_completion(ihost, ent);\n\t\t\tbreak;\n\n\t\tcase SCU_COMPLETION_TYPE_NOTIFY: {\n\t\t\tevent_cycle ^= ((event_get+1) & SCU_MAX_EVENTS) <<\n\t\t\t\t       (SMU_COMPLETION_QUEUE_GET_EVENT_CYCLE_BIT_SHIFT - SCU_MAX_EVENTS_SHIFT);\n\t\t\tevent_get = (event_get+1) & (SCU_MAX_EVENTS-1);\n\n\t\t\tsci_controller_event_completion(ihost, ent);\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t\t \"%s: SCIC Controller received unknown \"\n\t\t\t\t \"completion type %x\\n\",\n\t\t\t\t __func__,\n\t\t\t\t ent);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (completion_count > 0) {\n\t\tihost->completion_queue_get =\n\t\t\tSMU_CQGR_GEN_BIT(ENABLE) |\n\t\t\tSMU_CQGR_GEN_BIT(EVENT_ENABLE) |\n\t\t\tevent_cycle |\n\t\t\tSMU_CQGR_GEN_VAL(EVENT_POINTER, event_get) |\n\t\t\tget_cycle |\n\t\t\tSMU_CQGR_GEN_VAL(POINTER, get_index);\n\n\t\twritel(ihost->completion_queue_get,\n\t\t       &ihost->smu_registers->completion_queue_get);\n\n\t}\n\n\tdev_dbg(&ihost->pdev->dev,\n\t\t\"%s: completion queue ending get:0x%08x\\n\",\n\t\t__func__,\n\t\tihost->completion_queue_get);\n\n}\n\nstatic void sci_controller_error_handler(struct isci_host *ihost)\n{\n\tu32 interrupt_status;\n\n\tinterrupt_status =\n\t\treadl(&ihost->smu_registers->interrupt_status);\n\n\tif ((interrupt_status & SMU_ISR_QUEUE_SUSPEND) &&\n\t    sci_controller_completion_queue_has_entries(ihost)) {\n\n\t\tsci_controller_process_completions(ihost);\n\t\twritel(SMU_ISR_QUEUE_SUSPEND, &ihost->smu_registers->interrupt_status);\n\t} else {\n\t\tdev_err(&ihost->pdev->dev, \"%s: status: %#x\\n\", __func__,\n\t\t\tinterrupt_status);\n\n\t\tsci_change_state(&ihost->sm, SCIC_FAILED);\n\n\t\treturn;\n\t}\n\n\t \n\twritel(0, &ihost->smu_registers->interrupt_mask);\n}\n\nirqreturn_t isci_intx_isr(int vec, void *data)\n{\n\tirqreturn_t ret = IRQ_NONE;\n\tstruct isci_host *ihost = data;\n\n\tif (sci_controller_isr(ihost)) {\n\t\twritel(SMU_ISR_COMPLETION, &ihost->smu_registers->interrupt_status);\n\t\ttasklet_schedule(&ihost->completion_tasklet);\n\t\tret = IRQ_HANDLED;\n\t} else if (sci_controller_error_isr(ihost)) {\n\t\tspin_lock(&ihost->scic_lock);\n\t\tsci_controller_error_handler(ihost);\n\t\tspin_unlock(&ihost->scic_lock);\n\t\tret = IRQ_HANDLED;\n\t}\n\n\treturn ret;\n}\n\nirqreturn_t isci_error_isr(int vec, void *data)\n{\n\tstruct isci_host *ihost = data;\n\n\tif (sci_controller_error_isr(ihost))\n\t\tsci_controller_error_handler(ihost);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void isci_host_start_complete(struct isci_host *ihost, enum sci_status completion_status)\n{\n\tif (completion_status != SCI_SUCCESS)\n\t\tdev_info(&ihost->pdev->dev,\n\t\t\t\"controller start timed out, continuing...\\n\");\n\tclear_bit(IHOST_START_PENDING, &ihost->flags);\n\twake_up(&ihost->eventq);\n}\n\nint isci_host_scan_finished(struct Scsi_Host *shost, unsigned long time)\n{\n\tstruct sas_ha_struct *ha = SHOST_TO_SAS_HA(shost);\n\tstruct isci_host *ihost = ha->lldd_ha;\n\n\tif (test_bit(IHOST_START_PENDING, &ihost->flags))\n\t\treturn 0;\n\n\tsas_drain_work(ha);\n\n\treturn 1;\n}\n\n \nstatic u32 sci_controller_get_suggested_start_timeout(struct isci_host *ihost)\n{\n\t \n\tif (!ihost)\n\t\treturn 0;\n\n\t \n\n\treturn SCIC_SDS_SIGNATURE_FIS_TIMEOUT\n\t\t+ SCIC_SDS_CONTROLLER_PHY_START_TIMEOUT\n\t\t+ ((SCI_MAX_PHYS - 1) * SCIC_SDS_CONTROLLER_POWER_CONTROL_INTERVAL);\n}\n\nstatic void sci_controller_enable_interrupts(struct isci_host *ihost)\n{\n\tset_bit(IHOST_IRQ_ENABLED, &ihost->flags);\n\twritel(0, &ihost->smu_registers->interrupt_mask);\n}\n\nvoid sci_controller_disable_interrupts(struct isci_host *ihost)\n{\n\tclear_bit(IHOST_IRQ_ENABLED, &ihost->flags);\n\twritel(0xffffffff, &ihost->smu_registers->interrupt_mask);\n\treadl(&ihost->smu_registers->interrupt_mask);  \n}\n\nstatic void sci_controller_enable_port_task_scheduler(struct isci_host *ihost)\n{\n\tu32 port_task_scheduler_value;\n\n\tport_task_scheduler_value =\n\t\treadl(&ihost->scu_registers->peg0.ptsg.control);\n\tport_task_scheduler_value |=\n\t\t(SCU_PTSGCR_GEN_BIT(ETM_ENABLE) |\n\t\t SCU_PTSGCR_GEN_BIT(PTSG_ENABLE));\n\twritel(port_task_scheduler_value,\n\t       &ihost->scu_registers->peg0.ptsg.control);\n}\n\nstatic void sci_controller_assign_task_entries(struct isci_host *ihost)\n{\n\tu32 task_assignment;\n\n\t \n\n\ttask_assignment =\n\t\treadl(&ihost->smu_registers->task_context_assignment[0]);\n\n\ttask_assignment |= (SMU_TCA_GEN_VAL(STARTING, 0)) |\n\t\t(SMU_TCA_GEN_VAL(ENDING,  ihost->task_context_entries - 1)) |\n\t\t(SMU_TCA_GEN_BIT(RANGE_CHECK_ENABLE));\n\n\twritel(task_assignment,\n\t\t&ihost->smu_registers->task_context_assignment[0]);\n\n}\n\nstatic void sci_controller_initialize_completion_queue(struct isci_host *ihost)\n{\n\tu32 index;\n\tu32 completion_queue_control_value;\n\tu32 completion_queue_get_value;\n\tu32 completion_queue_put_value;\n\n\tihost->completion_queue_get = 0;\n\n\tcompletion_queue_control_value =\n\t\t(SMU_CQC_QUEUE_LIMIT_SET(SCU_MAX_COMPLETION_QUEUE_ENTRIES - 1) |\n\t\t SMU_CQC_EVENT_LIMIT_SET(SCU_MAX_EVENTS - 1));\n\n\twritel(completion_queue_control_value,\n\t       &ihost->smu_registers->completion_queue_control);\n\n\n\t \n\tcompletion_queue_get_value = (\n\t\t(SMU_CQGR_GEN_VAL(POINTER, 0))\n\t\t| (SMU_CQGR_GEN_VAL(EVENT_POINTER, 0))\n\t\t| (SMU_CQGR_GEN_BIT(ENABLE))\n\t\t| (SMU_CQGR_GEN_BIT(EVENT_ENABLE))\n\t\t);\n\n\twritel(completion_queue_get_value,\n\t       &ihost->smu_registers->completion_queue_get);\n\n\t \n\tcompletion_queue_put_value = (\n\t\t(SMU_CQPR_GEN_VAL(POINTER, 0))\n\t\t| (SMU_CQPR_GEN_VAL(EVENT_POINTER, 0))\n\t\t);\n\n\twritel(completion_queue_put_value,\n\t       &ihost->smu_registers->completion_queue_put);\n\n\t \n\tfor (index = 0; index < SCU_MAX_COMPLETION_QUEUE_ENTRIES; index++) {\n\t\t \n\t\tihost->completion_queue[index] = 0x80000000;\n\t}\n}\n\nstatic void sci_controller_initialize_unsolicited_frame_queue(struct isci_host *ihost)\n{\n\tu32 frame_queue_control_value;\n\tu32 frame_queue_get_value;\n\tu32 frame_queue_put_value;\n\n\t \n\tframe_queue_control_value =\n\t\tSCU_UFQC_GEN_VAL(QUEUE_SIZE, SCU_MAX_UNSOLICITED_FRAMES);\n\n\twritel(frame_queue_control_value,\n\t       &ihost->scu_registers->sdma.unsolicited_frame_queue_control);\n\n\t \n\tframe_queue_get_value = (\n\t\tSCU_UFQGP_GEN_VAL(POINTER, 0)\n\t\t|  SCU_UFQGP_GEN_BIT(ENABLE_BIT)\n\t\t);\n\n\twritel(frame_queue_get_value,\n\t       &ihost->scu_registers->sdma.unsolicited_frame_get_pointer);\n\t \n\tframe_queue_put_value = SCU_UFQPP_GEN_VAL(POINTER, 0);\n\twritel(frame_queue_put_value,\n\t       &ihost->scu_registers->sdma.unsolicited_frame_put_pointer);\n}\n\nvoid sci_controller_transition_to_ready(struct isci_host *ihost, enum sci_status status)\n{\n\tif (ihost->sm.current_state_id == SCIC_STARTING) {\n\t\t \n\t\tsci_change_state(&ihost->sm, SCIC_READY);\n\n\t\tisci_host_start_complete(ihost, status);\n\t}\n}\n\nstatic bool is_phy_starting(struct isci_phy *iphy)\n{\n\tenum sci_phy_states state;\n\n\tstate = iphy->sm.current_state_id;\n\tswitch (state) {\n\tcase SCI_PHY_STARTING:\n\tcase SCI_PHY_SUB_INITIAL:\n\tcase SCI_PHY_SUB_AWAIT_SAS_SPEED_EN:\n\tcase SCI_PHY_SUB_AWAIT_IAF_UF:\n\tcase SCI_PHY_SUB_AWAIT_SAS_POWER:\n\tcase SCI_PHY_SUB_AWAIT_SATA_POWER:\n\tcase SCI_PHY_SUB_AWAIT_SATA_PHY_EN:\n\tcase SCI_PHY_SUB_AWAIT_SATA_SPEED_EN:\n\tcase SCI_PHY_SUB_AWAIT_OSSP_EN:\n\tcase SCI_PHY_SUB_AWAIT_SIG_FIS_UF:\n\tcase SCI_PHY_SUB_FINAL:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nbool is_controller_start_complete(struct isci_host *ihost)\n{\n\tint i;\n\n\tfor (i = 0; i < SCI_MAX_PHYS; i++) {\n\t\tstruct isci_phy *iphy = &ihost->phys[i];\n\t\tu32 state = iphy->sm.current_state_id;\n\n\t\t \n\t\tif (is_port_config_apc(ihost))\n\t\t\t ;\n\t\telse if (!phy_get_non_dummy_port(iphy))\n\t\t\tcontinue;\n\n\t\t \n\t\tif ((iphy->is_in_link_training == false && state == SCI_PHY_INITIAL) ||\n\t\t    (iphy->is_in_link_training == false && state == SCI_PHY_STOPPED) ||\n\t\t    (iphy->is_in_link_training == true && is_phy_starting(iphy)) ||\n\t\t    (ihost->port_agent.phy_ready_mask != ihost->port_agent.phy_configured_mask))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic enum sci_status sci_controller_start_next_phy(struct isci_host *ihost)\n{\n\tstruct sci_oem_params *oem = &ihost->oem_parameters;\n\tstruct isci_phy *iphy;\n\tenum sci_status status;\n\n\tstatus = SCI_SUCCESS;\n\n\tif (ihost->phy_startup_timer_pending)\n\t\treturn status;\n\n\tif (ihost->next_phy_to_start >= SCI_MAX_PHYS) {\n\t\tif (is_controller_start_complete(ihost)) {\n\t\t\tsci_controller_transition_to_ready(ihost, SCI_SUCCESS);\n\t\t\tsci_del_timer(&ihost->phy_timer);\n\t\t\tihost->phy_startup_timer_pending = false;\n\t\t}\n\t} else {\n\t\tiphy = &ihost->phys[ihost->next_phy_to_start];\n\n\t\tif (oem->controller.mode_type == SCIC_PORT_MANUAL_CONFIGURATION_MODE) {\n\t\t\tif (phy_get_non_dummy_port(iphy) == NULL) {\n\t\t\t\tihost->next_phy_to_start++;\n\n\t\t\t\t \n\t\t\t\treturn sci_controller_start_next_phy(ihost);\n\t\t\t}\n\t\t}\n\n\t\tstatus = sci_phy_start(iphy);\n\n\t\tif (status == SCI_SUCCESS) {\n\t\t\tsci_mod_timer(&ihost->phy_timer,\n\t\t\t\t      SCIC_SDS_CONTROLLER_PHY_START_TIMEOUT);\n\t\t\tihost->phy_startup_timer_pending = true;\n\t\t} else {\n\t\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t\t \"%s: Controller stop operation failed \"\n\t\t\t\t \"to stop phy %d because of status \"\n\t\t\t\t \"%d.\\n\",\n\t\t\t\t __func__,\n\t\t\t\t ihost->phys[ihost->next_phy_to_start].phy_index,\n\t\t\t\t status);\n\t\t}\n\n\t\tihost->next_phy_to_start++;\n\t}\n\n\treturn status;\n}\n\nstatic void phy_startup_timeout(struct timer_list *t)\n{\n\tstruct sci_timer *tmr = from_timer(tmr, t, timer);\n\tstruct isci_host *ihost = container_of(tmr, typeof(*ihost), phy_timer);\n\tunsigned long flags;\n\tenum sci_status status;\n\n\tspin_lock_irqsave(&ihost->scic_lock, flags);\n\n\tif (tmr->cancel)\n\t\tgoto done;\n\n\tihost->phy_startup_timer_pending = false;\n\n\tdo {\n\t\tstatus = sci_controller_start_next_phy(ihost);\n\t} while (status != SCI_SUCCESS);\n\ndone:\n\tspin_unlock_irqrestore(&ihost->scic_lock, flags);\n}\n\nstatic u16 isci_tci_active(struct isci_host *ihost)\n{\n\treturn CIRC_CNT(ihost->tci_head, ihost->tci_tail, SCI_MAX_IO_REQUESTS);\n}\n\nstatic enum sci_status sci_controller_start(struct isci_host *ihost,\n\t\t\t\t\t     u32 timeout)\n{\n\tenum sci_status result;\n\tu16 index;\n\n\tif (ihost->sm.current_state_id != SCIC_INITIALIZED) {\n\t\tdev_warn(&ihost->pdev->dev, \"%s invalid state: %d\\n\",\n\t\t\t __func__, ihost->sm.current_state_id);\n\t\treturn SCI_FAILURE_INVALID_STATE;\n\t}\n\n\t \n\tBUILD_BUG_ON(SCI_MAX_IO_REQUESTS > 1 << sizeof(ihost->tci_pool[0]) * 8);\n\tihost->tci_head = 0;\n\tihost->tci_tail = 0;\n\tfor (index = 0; index < ihost->task_context_entries; index++)\n\t\tisci_tci_free(ihost, index);\n\n\t \n\tsci_remote_node_table_initialize(&ihost->available_remote_nodes,\n\t\t\t\t\t ihost->remote_node_entries);\n\n\t \n\tsci_controller_disable_interrupts(ihost);\n\n\t \n\tsci_controller_enable_port_task_scheduler(ihost);\n\n\t \n\tsci_controller_assign_task_entries(ihost);\n\n\t \n\tsci_controller_initialize_completion_queue(ihost);\n\n\t \n\tsci_controller_initialize_unsolicited_frame_queue(ihost);\n\n\t \n\tfor (index = 0; index < ihost->logical_port_entries; index++) {\n\t\tstruct isci_port *iport = &ihost->ports[index];\n\n\t\tresult = sci_port_start(iport);\n\t\tif (result)\n\t\t\treturn result;\n\t}\n\n\tsci_controller_start_next_phy(ihost);\n\n\tsci_mod_timer(&ihost->timer, timeout);\n\n\tsci_change_state(&ihost->sm, SCIC_STARTING);\n\n\treturn SCI_SUCCESS;\n}\n\nvoid isci_host_start(struct Scsi_Host *shost)\n{\n\tstruct isci_host *ihost = SHOST_TO_SAS_HA(shost)->lldd_ha;\n\tunsigned long tmo = sci_controller_get_suggested_start_timeout(ihost);\n\n\tset_bit(IHOST_START_PENDING, &ihost->flags);\n\n\tspin_lock_irq(&ihost->scic_lock);\n\tsci_controller_start(ihost, tmo);\n\tsci_controller_enable_interrupts(ihost);\n\tspin_unlock_irq(&ihost->scic_lock);\n}\n\nstatic void isci_host_stop_complete(struct isci_host *ihost)\n{\n\tsci_controller_disable_interrupts(ihost);\n\tclear_bit(IHOST_STOP_PENDING, &ihost->flags);\n\twake_up(&ihost->eventq);\n}\n\nstatic void sci_controller_completion_handler(struct isci_host *ihost)\n{\n\t \n\tif (sci_controller_completion_queue_has_entries(ihost))\n\t\tsci_controller_process_completions(ihost);\n\n\t \n\twritel(SMU_ISR_COMPLETION, &ihost->smu_registers->interrupt_status);\n\t \n\twritel(0xFF000000, &ihost->smu_registers->interrupt_mask);\n\twritel(0, &ihost->smu_registers->interrupt_mask);\n}\n\nvoid ireq_done(struct isci_host *ihost, struct isci_request *ireq, struct sas_task *task)\n{\n\tif (!test_bit(IREQ_ABORT_PATH_ACTIVE, &ireq->flags) &&\n\t    !(task->task_state_flags & SAS_TASK_STATE_ABORTED)) {\n\t\tif (test_bit(IREQ_COMPLETE_IN_TARGET, &ireq->flags)) {\n\t\t\t \n\t\t\tdev_dbg(&ihost->pdev->dev,\n\t\t\t\t\"%s: Normal - ireq/task = %p/%p\\n\",\n\t\t\t\t__func__, ireq, task);\n\t\t\ttask->lldd_task = NULL;\n\t\t\ttask->task_done(task);\n\t\t} else {\n\t\t\tdev_dbg(&ihost->pdev->dev,\n\t\t\t\t\"%s: Error - ireq/task = %p/%p\\n\",\n\t\t\t\t__func__, ireq, task);\n\t\t\tif (sas_protocol_ata(task->task_proto))\n\t\t\t\ttask->lldd_task = NULL;\n\t\t\tsas_task_abort(task);\n\t\t}\n\t} else\n\t\ttask->lldd_task = NULL;\n\n\tif (test_and_clear_bit(IREQ_ABORT_PATH_ACTIVE, &ireq->flags))\n\t\twake_up_all(&ihost->eventq);\n\n\tif (!test_bit(IREQ_NO_AUTO_FREE_TAG, &ireq->flags))\n\t\tisci_free_tag(ihost, ireq->io_tag);\n}\n \nvoid isci_host_completion_routine(unsigned long data)\n{\n\tstruct isci_host *ihost = (struct isci_host *)data;\n\tu16 active;\n\n\tspin_lock_irq(&ihost->scic_lock);\n\tsci_controller_completion_handler(ihost);\n\tspin_unlock_irq(&ihost->scic_lock);\n\n\t \n\tactive = isci_tci_active(ihost) - SCI_MAX_PORTS;\n\n\t \n\twritel(SMU_ICC_GEN_VAL(NUMBER, active) |\n\t       SMU_ICC_GEN_VAL(TIMER, ISCI_COALESCE_BASE + ilog2(active)),\n\t       &ihost->smu_registers->interrupt_coalesce_control);\n}\n\n \nstatic enum sci_status sci_controller_stop(struct isci_host *ihost, u32 timeout)\n{\n\tif (ihost->sm.current_state_id != SCIC_READY) {\n\t\tdev_warn(&ihost->pdev->dev, \"%s invalid state: %d\\n\",\n\t\t\t __func__, ihost->sm.current_state_id);\n\t\treturn SCI_FAILURE_INVALID_STATE;\n\t}\n\n\tsci_mod_timer(&ihost->timer, timeout);\n\tsci_change_state(&ihost->sm, SCIC_STOPPING);\n\treturn SCI_SUCCESS;\n}\n\n \nstatic enum sci_status sci_controller_reset(struct isci_host *ihost)\n{\n\tswitch (ihost->sm.current_state_id) {\n\tcase SCIC_RESET:\n\tcase SCIC_READY:\n\tcase SCIC_STOPPING:\n\tcase SCIC_FAILED:\n\t\t \n\t\tsci_change_state(&ihost->sm, SCIC_RESETTING);\n\t\treturn SCI_SUCCESS;\n\tdefault:\n\t\tdev_warn(&ihost->pdev->dev, \"%s invalid state: %d\\n\",\n\t\t\t __func__, ihost->sm.current_state_id);\n\t\treturn SCI_FAILURE_INVALID_STATE;\n\t}\n}\n\nstatic enum sci_status sci_controller_stop_phys(struct isci_host *ihost)\n{\n\tu32 index;\n\tenum sci_status status;\n\tenum sci_status phy_status;\n\n\tstatus = SCI_SUCCESS;\n\n\tfor (index = 0; index < SCI_MAX_PHYS; index++) {\n\t\tphy_status = sci_phy_stop(&ihost->phys[index]);\n\n\t\tif (phy_status != SCI_SUCCESS &&\n\t\t    phy_status != SCI_FAILURE_INVALID_STATE) {\n\t\t\tstatus = SCI_FAILURE;\n\n\t\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t\t \"%s: Controller stop operation failed to stop \"\n\t\t\t\t \"phy %d because of status %d.\\n\",\n\t\t\t\t __func__,\n\t\t\t\t ihost->phys[index].phy_index, phy_status);\n\t\t}\n\t}\n\n\treturn status;\n}\n\n\n \nvoid isci_host_deinit(struct isci_host *ihost)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < isci_gpio_count(ihost); i++)\n\t\twritel(SGPIO_HW_CONTROL, &ihost->scu_registers->peg0.sgpio.output_data_select[i]);\n\n\tset_bit(IHOST_STOP_PENDING, &ihost->flags);\n\n\tspin_lock_irq(&ihost->scic_lock);\n\tsci_controller_stop(ihost, SCIC_CONTROLLER_STOP_TIMEOUT);\n\tspin_unlock_irq(&ihost->scic_lock);\n\n\twait_for_stop(ihost);\n\n\t \n\tsci_controller_stop_phys(ihost);\n\n\t \n\twritel(0, &ihost->scu_registers->peg0.sgpio.interface_control);\n\n\tspin_lock_irq(&ihost->scic_lock);\n\tsci_controller_reset(ihost);\n\tspin_unlock_irq(&ihost->scic_lock);\n\n\t \n\tfor (i = 0; i < ihost->logical_port_entries; i++) {\n\t\tstruct isci_port *iport = &ihost->ports[i];\n\t\tdel_timer_sync(&iport->timer.timer);\n\t}\n\n\t \n\tfor (i = 0; i < SCI_MAX_PHYS; i++) {\n\t\tstruct isci_phy *iphy = &ihost->phys[i];\n\t\tdel_timer_sync(&iphy->sata_timer.timer);\n\t}\n\n\tdel_timer_sync(&ihost->port_agent.timer.timer);\n\n\tdel_timer_sync(&ihost->power_control.timer.timer);\n\n\tdel_timer_sync(&ihost->timer.timer);\n\n\tdel_timer_sync(&ihost->phy_timer.timer);\n}\n\nstatic void __iomem *scu_base(struct isci_host *isci_host)\n{\n\tstruct pci_dev *pdev = isci_host->pdev;\n\tint id = isci_host->id;\n\n\treturn pcim_iomap_table(pdev)[SCI_SCU_BAR * 2] + SCI_SCU_BAR_SIZE * id;\n}\n\nstatic void __iomem *smu_base(struct isci_host *isci_host)\n{\n\tstruct pci_dev *pdev = isci_host->pdev;\n\tint id = isci_host->id;\n\n\treturn pcim_iomap_table(pdev)[SCI_SMU_BAR * 2] + SCI_SMU_BAR_SIZE * id;\n}\n\nstatic void sci_controller_initial_state_enter(struct sci_base_state_machine *sm)\n{\n\tstruct isci_host *ihost = container_of(sm, typeof(*ihost), sm);\n\n\tsci_change_state(&ihost->sm, SCIC_RESET);\n}\n\nstatic inline void sci_controller_starting_state_exit(struct sci_base_state_machine *sm)\n{\n\tstruct isci_host *ihost = container_of(sm, typeof(*ihost), sm);\n\n\tsci_del_timer(&ihost->timer);\n}\n\n#define INTERRUPT_COALESCE_TIMEOUT_BASE_RANGE_LOWER_BOUND_NS 853\n#define INTERRUPT_COALESCE_TIMEOUT_BASE_RANGE_UPPER_BOUND_NS 1280\n#define INTERRUPT_COALESCE_TIMEOUT_MAX_US                    2700000\n#define INTERRUPT_COALESCE_NUMBER_MAX                        256\n#define INTERRUPT_COALESCE_TIMEOUT_ENCODE_MIN                7\n#define INTERRUPT_COALESCE_TIMEOUT_ENCODE_MAX                28\n\n \nstatic enum sci_status\nsci_controller_set_interrupt_coalescence(struct isci_host *ihost,\n\t\t\t\t\t u32 coalesce_number,\n\t\t\t\t\t u32 coalesce_timeout)\n{\n\tu8 timeout_encode = 0;\n\tu32 min = 0;\n\tu32 max = 0;\n\n\t \n\tif (coalesce_number > INTERRUPT_COALESCE_NUMBER_MAX)\n\t\treturn SCI_FAILURE_INVALID_PARAMETER_VALUE;\n\n\t \n\n\t \n\tif (coalesce_timeout == 0)\n\t\ttimeout_encode = 0;\n\telse{\n\t\t \n\t\tcoalesce_timeout = coalesce_timeout * 100;\n\t\tmin = INTERRUPT_COALESCE_TIMEOUT_BASE_RANGE_LOWER_BOUND_NS / 10;\n\t\tmax = INTERRUPT_COALESCE_TIMEOUT_BASE_RANGE_UPPER_BOUND_NS / 10;\n\n\t\t \n\t\tfor (timeout_encode = INTERRUPT_COALESCE_TIMEOUT_ENCODE_MIN;\n\t\t      timeout_encode <= INTERRUPT_COALESCE_TIMEOUT_ENCODE_MAX;\n\t\t      timeout_encode++) {\n\t\t\tif (min <= coalesce_timeout &&  max > coalesce_timeout)\n\t\t\t\tbreak;\n\t\t\telse if (coalesce_timeout >= max && coalesce_timeout < min * 2\n\t\t\t\t && coalesce_timeout <= INTERRUPT_COALESCE_TIMEOUT_MAX_US * 100) {\n\t\t\t\tif ((coalesce_timeout - max) < (2 * min - coalesce_timeout))\n\t\t\t\t\tbreak;\n\t\t\t\telse{\n\t\t\t\t\ttimeout_encode++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tmax = max * 2;\n\t\t\t\tmin = min * 2;\n\t\t\t}\n\t\t}\n\n\t\tif (timeout_encode == INTERRUPT_COALESCE_TIMEOUT_ENCODE_MAX + 1)\n\t\t\t \n\t\t\treturn SCI_FAILURE_INVALID_PARAMETER_VALUE;\n\t}\n\n\twritel(SMU_ICC_GEN_VAL(NUMBER, coalesce_number) |\n\t       SMU_ICC_GEN_VAL(TIMER, timeout_encode),\n\t       &ihost->smu_registers->interrupt_coalesce_control);\n\n\n\tihost->interrupt_coalesce_number = (u16)coalesce_number;\n\tihost->interrupt_coalesce_timeout = coalesce_timeout / 100;\n\n\treturn SCI_SUCCESS;\n}\n\n\nstatic void sci_controller_ready_state_enter(struct sci_base_state_machine *sm)\n{\n\tstruct isci_host *ihost = container_of(sm, typeof(*ihost), sm);\n\tu32 val;\n\n\t \n\tval = readl(&ihost->smu_registers->clock_gating_control);\n\tval &= ~(SMU_CGUCR_GEN_BIT(REGCLK_ENABLE) |\n\t\t SMU_CGUCR_GEN_BIT(TXCLK_ENABLE) |\n\t\t SMU_CGUCR_GEN_BIT(XCLK_ENABLE));\n\tval |= SMU_CGUCR_GEN_BIT(IDLE_ENABLE);\n\twritel(val, &ihost->smu_registers->clock_gating_control);\n\n\t \n\tsci_controller_set_interrupt_coalescence(ihost, 0, 0);\n}\n\nstatic void sci_controller_ready_state_exit(struct sci_base_state_machine *sm)\n{\n\tstruct isci_host *ihost = container_of(sm, typeof(*ihost), sm);\n\n\t \n\tsci_controller_set_interrupt_coalescence(ihost, 0, 0);\n}\n\nstatic enum sci_status sci_controller_stop_ports(struct isci_host *ihost)\n{\n\tu32 index;\n\tenum sci_status port_status;\n\tenum sci_status status = SCI_SUCCESS;\n\n\tfor (index = 0; index < ihost->logical_port_entries; index++) {\n\t\tstruct isci_port *iport = &ihost->ports[index];\n\n\t\tport_status = sci_port_stop(iport);\n\n\t\tif ((port_status != SCI_SUCCESS) &&\n\t\t    (port_status != SCI_FAILURE_INVALID_STATE)) {\n\t\t\tstatus = SCI_FAILURE;\n\n\t\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t\t \"%s: Controller stop operation failed to \"\n\t\t\t\t \"stop port %d because of status %d.\\n\",\n\t\t\t\t __func__,\n\t\t\t\t iport->logical_port_index,\n\t\t\t\t port_status);\n\t\t}\n\t}\n\n\treturn status;\n}\n\nstatic enum sci_status sci_controller_stop_devices(struct isci_host *ihost)\n{\n\tu32 index;\n\tenum sci_status status;\n\tenum sci_status device_status;\n\n\tstatus = SCI_SUCCESS;\n\n\tfor (index = 0; index < ihost->remote_node_entries; index++) {\n\t\tif (ihost->device_table[index] != NULL) {\n\t\t\t \n\t\t\tdevice_status = sci_remote_device_stop(ihost->device_table[index], 0);\n\n\t\t\tif ((device_status != SCI_SUCCESS) &&\n\t\t\t    (device_status != SCI_FAILURE_INVALID_STATE)) {\n\t\t\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t\t\t \"%s: Controller stop operation failed \"\n\t\t\t\t\t \"to stop device 0x%p because of \"\n\t\t\t\t\t \"status %d.\\n\",\n\t\t\t\t\t __func__,\n\t\t\t\t\t ihost->device_table[index], device_status);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn status;\n}\n\nstatic void sci_controller_stopping_state_enter(struct sci_base_state_machine *sm)\n{\n\tstruct isci_host *ihost = container_of(sm, typeof(*ihost), sm);\n\n\tsci_controller_stop_devices(ihost);\n\tsci_controller_stop_ports(ihost);\n\n\tif (!sci_controller_has_remote_devices_stopping(ihost))\n\t\tisci_host_stop_complete(ihost);\n}\n\nstatic void sci_controller_stopping_state_exit(struct sci_base_state_machine *sm)\n{\n\tstruct isci_host *ihost = container_of(sm, typeof(*ihost), sm);\n\n\tsci_del_timer(&ihost->timer);\n}\n\nstatic void sci_controller_reset_hardware(struct isci_host *ihost)\n{\n\t \n\tsci_controller_disable_interrupts(ihost);\n\n\t \n\twritel(0xFFFFFFFF, &ihost->smu_registers->soft_reset_control);\n\n\t \n\tudelay(1000);\n\n\t \n\twritel(0x00000000, &ihost->smu_registers->completion_queue_get);\n\n\t \n\twritel(0, &ihost->scu_registers->sdma.unsolicited_frame_get_pointer);\n\n\t \n\twritel(~SMU_INTERRUPT_STATUS_RESERVED_MASK, &ihost->smu_registers->interrupt_status);\n}\n\nstatic void sci_controller_resetting_state_enter(struct sci_base_state_machine *sm)\n{\n\tstruct isci_host *ihost = container_of(sm, typeof(*ihost), sm);\n\n\tsci_controller_reset_hardware(ihost);\n\tsci_change_state(&ihost->sm, SCIC_RESET);\n}\n\nstatic const struct sci_base_state sci_controller_state_table[] = {\n\t[SCIC_INITIAL] = {\n\t\t.enter_state = sci_controller_initial_state_enter,\n\t},\n\t[SCIC_RESET] = {},\n\t[SCIC_INITIALIZING] = {},\n\t[SCIC_INITIALIZED] = {},\n\t[SCIC_STARTING] = {\n\t\t.exit_state  = sci_controller_starting_state_exit,\n\t},\n\t[SCIC_READY] = {\n\t\t.enter_state = sci_controller_ready_state_enter,\n\t\t.exit_state  = sci_controller_ready_state_exit,\n\t},\n\t[SCIC_RESETTING] = {\n\t\t.enter_state = sci_controller_resetting_state_enter,\n\t},\n\t[SCIC_STOPPING] = {\n\t\t.enter_state = sci_controller_stopping_state_enter,\n\t\t.exit_state = sci_controller_stopping_state_exit,\n\t},\n\t[SCIC_FAILED] = {}\n};\n\nstatic void controller_timeout(struct timer_list *t)\n{\n\tstruct sci_timer *tmr = from_timer(tmr, t, timer);\n\tstruct isci_host *ihost = container_of(tmr, typeof(*ihost), timer);\n\tstruct sci_base_state_machine *sm = &ihost->sm;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ihost->scic_lock, flags);\n\n\tif (tmr->cancel)\n\t\tgoto done;\n\n\tif (sm->current_state_id == SCIC_STARTING)\n\t\tsci_controller_transition_to_ready(ihost, SCI_FAILURE_TIMEOUT);\n\telse if (sm->current_state_id == SCIC_STOPPING) {\n\t\tsci_change_state(sm, SCIC_FAILED);\n\t\tisci_host_stop_complete(ihost);\n\t} else\t \n\t\tdev_err(&ihost->pdev->dev,\n\t\t\t\"%s: Controller timer fired when controller was not \"\n\t\t\t\"in a state being timed.\\n\",\n\t\t\t__func__);\n\ndone:\n\tspin_unlock_irqrestore(&ihost->scic_lock, flags);\n}\n\nstatic enum sci_status sci_controller_construct(struct isci_host *ihost,\n\t\t\t\t\t\tvoid __iomem *scu_base,\n\t\t\t\t\t\tvoid __iomem *smu_base)\n{\n\tu8 i;\n\n\tsci_init_sm(&ihost->sm, sci_controller_state_table, SCIC_INITIAL);\n\n\tihost->scu_registers = scu_base;\n\tihost->smu_registers = smu_base;\n\n\tsci_port_configuration_agent_construct(&ihost->port_agent);\n\n\t \n\tfor (i = 0; i < SCI_MAX_PORTS; i++)\n\t\tsci_port_construct(&ihost->ports[i], i, ihost);\n\tsci_port_construct(&ihost->ports[i], SCIC_SDS_DUMMY_PORT, ihost);\n\n\t \n\tfor (i = 0; i < SCI_MAX_PHYS; i++) {\n\t\t \n\t\tsci_phy_construct(&ihost->phys[i],\n\t\t\t\t  &ihost->ports[SCI_MAX_PORTS], i);\n\t}\n\n\tihost->invalid_phy_mask = 0;\n\n\tsci_init_timer(&ihost->timer, controller_timeout);\n\n\treturn sci_controller_reset(ihost);\n}\n\nint sci_oem_parameters_validate(struct sci_oem_params *oem, u8 version)\n{\n\tint i;\n\n\tfor (i = 0; i < SCI_MAX_PORTS; i++)\n\t\tif (oem->ports[i].phy_mask > SCIC_SDS_PARM_PHY_MASK_MAX)\n\t\t\treturn -EINVAL;\n\n\tfor (i = 0; i < SCI_MAX_PHYS; i++)\n\t\tif (oem->phys[i].sas_address.high == 0 &&\n\t\t    oem->phys[i].sas_address.low == 0)\n\t\t\treturn -EINVAL;\n\n\tif (oem->controller.mode_type == SCIC_PORT_AUTOMATIC_CONFIGURATION_MODE) {\n\t\tfor (i = 0; i < SCI_MAX_PHYS; i++)\n\t\t\tif (oem->ports[i].phy_mask != 0)\n\t\t\t\treturn -EINVAL;\n\t} else if (oem->controller.mode_type == SCIC_PORT_MANUAL_CONFIGURATION_MODE) {\n\t\tu8 phy_mask = 0;\n\n\t\tfor (i = 0; i < SCI_MAX_PHYS; i++)\n\t\t\tphy_mask |= oem->ports[i].phy_mask;\n\n\t\tif (phy_mask == 0)\n\t\t\treturn -EINVAL;\n\t} else\n\t\treturn -EINVAL;\n\n\tif (oem->controller.max_concurr_spin_up > MAX_CONCURRENT_DEVICE_SPIN_UP_COUNT ||\n\t    oem->controller.max_concurr_spin_up < 1)\n\t\treturn -EINVAL;\n\n\tif (oem->controller.do_enable_ssc) {\n\t\tif (version < ISCI_ROM_VER_1_1 && oem->controller.do_enable_ssc != 1)\n\t\t\treturn -EINVAL;\n\n\t\tif (version >= ISCI_ROM_VER_1_1) {\n\t\t\tu8 test = oem->controller.ssc_sata_tx_spread_level;\n\n\t\t\tswitch (test) {\n\t\t\tcase 0:\n\t\t\tcase 2:\n\t\t\tcase 3:\n\t\t\tcase 6:\n\t\t\tcase 7:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\ttest = oem->controller.ssc_sas_tx_spread_level;\n\t\t\tif (oem->controller.ssc_sas_tx_type == 0) {\n\t\t\t\tswitch (test) {\n\t\t\t\tcase 0:\n\t\t\t\tcase 2:\n\t\t\t\tcase 3:\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t} else if (oem->controller.ssc_sas_tx_type == 1) {\n\t\t\t\tswitch (test) {\n\t\t\t\tcase 0:\n\t\t\t\tcase 3:\n\t\t\t\tcase 6:\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic u8 max_spin_up(struct isci_host *ihost)\n{\n\tif (ihost->user_parameters.max_concurr_spinup)\n\t\treturn min_t(u8, ihost->user_parameters.max_concurr_spinup,\n\t\t\t     MAX_CONCURRENT_DEVICE_SPIN_UP_COUNT);\n\telse\n\t\treturn min_t(u8, ihost->oem_parameters.controller.max_concurr_spin_up,\n\t\t\t     MAX_CONCURRENT_DEVICE_SPIN_UP_COUNT);\n}\n\nstatic void power_control_timeout(struct timer_list *t)\n{\n\tstruct sci_timer *tmr = from_timer(tmr, t, timer);\n\tstruct isci_host *ihost = container_of(tmr, typeof(*ihost), power_control.timer);\n\tstruct isci_phy *iphy;\n\tunsigned long flags;\n\tu8 i;\n\n\tspin_lock_irqsave(&ihost->scic_lock, flags);\n\n\tif (tmr->cancel)\n\t\tgoto done;\n\n\tihost->power_control.phys_granted_power = 0;\n\n\tif (ihost->power_control.phys_waiting == 0) {\n\t\tihost->power_control.timer_started = false;\n\t\tgoto done;\n\t}\n\n\tfor (i = 0; i < SCI_MAX_PHYS; i++) {\n\n\t\tif (ihost->power_control.phys_waiting == 0)\n\t\t\tbreak;\n\n\t\tiphy = ihost->power_control.requesters[i];\n\t\tif (iphy == NULL)\n\t\t\tcontinue;\n\n\t\tif (ihost->power_control.phys_granted_power >= max_spin_up(ihost))\n\t\t\tbreak;\n\n\t\tihost->power_control.requesters[i] = NULL;\n\t\tihost->power_control.phys_waiting--;\n\t\tihost->power_control.phys_granted_power++;\n\t\tsci_phy_consume_power_handler(iphy);\n\n\t\tif (iphy->protocol == SAS_PROTOCOL_SSP) {\n\t\t\tu8 j;\n\n\t\t\tfor (j = 0; j < SCI_MAX_PHYS; j++) {\n\t\t\t\tstruct isci_phy *requester = ihost->power_control.requesters[j];\n\n\t\t\t\t \n\t\t\t\tif (requester != NULL && requester != iphy) {\n\t\t\t\t\tu8 other = memcmp(requester->frame_rcvd.iaf.sas_addr,\n\t\t\t\t\t\t\t  iphy->frame_rcvd.iaf.sas_addr,\n\t\t\t\t\t\t\t  sizeof(requester->frame_rcvd.iaf.sas_addr));\n\n\t\t\t\t\tif (other == 0) {\n\t\t\t\t\t\tihost->power_control.requesters[j] = NULL;\n\t\t\t\t\t\tihost->power_control.phys_waiting--;\n\t\t\t\t\t\tsci_phy_consume_power_handler(requester);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tsci_mod_timer(tmr, SCIC_SDS_CONTROLLER_POWER_CONTROL_INTERVAL);\n\tihost->power_control.timer_started = true;\n\ndone:\n\tspin_unlock_irqrestore(&ihost->scic_lock, flags);\n}\n\nvoid sci_controller_power_control_queue_insert(struct isci_host *ihost,\n\t\t\t\t\t       struct isci_phy *iphy)\n{\n\tBUG_ON(iphy == NULL);\n\n\tif (ihost->power_control.phys_granted_power < max_spin_up(ihost)) {\n\t\tihost->power_control.phys_granted_power++;\n\t\tsci_phy_consume_power_handler(iphy);\n\n\t\t \n\t\tif (ihost->power_control.timer_started)\n\t\t\tsci_del_timer(&ihost->power_control.timer);\n\n\t\tsci_mod_timer(&ihost->power_control.timer,\n\t\t\t\t SCIC_SDS_CONTROLLER_POWER_CONTROL_INTERVAL);\n\t\tihost->power_control.timer_started = true;\n\n\t} else {\n\t\t \n\t\tu8 i;\n\t\tstruct isci_phy *current_phy;\n\n\t\tfor (i = 0; i < SCI_MAX_PHYS; i++) {\n\t\t\tu8 other;\n\t\t\tcurrent_phy = &ihost->phys[i];\n\n\t\t\tother = memcmp(current_phy->frame_rcvd.iaf.sas_addr,\n\t\t\t\t       iphy->frame_rcvd.iaf.sas_addr,\n\t\t\t\t       sizeof(current_phy->frame_rcvd.iaf.sas_addr));\n\n\t\t\tif (current_phy->sm.current_state_id == SCI_PHY_READY &&\n\t\t\t    current_phy->protocol == SAS_PROTOCOL_SSP &&\n\t\t\t    other == 0) {\n\t\t\t\tsci_phy_consume_power_handler(iphy);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (i == SCI_MAX_PHYS) {\n\t\t\t \n\t\t\tihost->power_control.requesters[iphy->phy_index] = iphy;\n\t\t\tihost->power_control.phys_waiting++;\n\t\t}\n\t}\n}\n\nvoid sci_controller_power_control_queue_remove(struct isci_host *ihost,\n\t\t\t\t\t       struct isci_phy *iphy)\n{\n\tBUG_ON(iphy == NULL);\n\n\tif (ihost->power_control.requesters[iphy->phy_index])\n\t\tihost->power_control.phys_waiting--;\n\n\tihost->power_control.requesters[iphy->phy_index] = NULL;\n}\n\nstatic int is_long_cable(int phy, unsigned char selection_byte)\n{\n\treturn !!(selection_byte & (1 << phy));\n}\n\nstatic int is_medium_cable(int phy, unsigned char selection_byte)\n{\n\treturn !!(selection_byte & (1 << (phy + 4)));\n}\n\nstatic enum cable_selections decode_selection_byte(\n\tint phy,\n\tunsigned char selection_byte)\n{\n\treturn ((selection_byte & (1 << phy)) ? 1 : 0)\n\t\t+ (selection_byte & (1 << (phy + 4)) ? 2 : 0);\n}\n\nstatic unsigned char *to_cable_select(struct isci_host *ihost)\n{\n\tif (is_cable_select_overridden())\n\t\treturn ((unsigned char *)&cable_selection_override)\n\t\t\t+ ihost->id;\n\telse\n\t\treturn &ihost->oem_parameters.controller.cable_selection_mask;\n}\n\nenum cable_selections decode_cable_selection(struct isci_host *ihost, int phy)\n{\n\treturn decode_selection_byte(phy, *to_cable_select(ihost));\n}\n\nchar *lookup_cable_names(enum cable_selections selection)\n{\n\tstatic char *cable_names[] = {\n\t\t[short_cable]     = \"short\",\n\t\t[long_cable]      = \"long\",\n\t\t[medium_cable]    = \"medium\",\n\t\t[undefined_cable] = \"<undefined, assumed long>\"  \n\t};\n\treturn (selection <= undefined_cable) ? cable_names[selection]\n\t\t\t\t\t      : cable_names[undefined_cable];\n}\n\n#define AFE_REGISTER_WRITE_DELAY 10\n\nstatic void sci_controller_afe_initialization(struct isci_host *ihost)\n{\n\tstruct scu_afe_registers __iomem *afe = &ihost->scu_registers->afe;\n\tconst struct sci_oem_params *oem = &ihost->oem_parameters;\n\tstruct pci_dev *pdev = ihost->pdev;\n\tu32 afe_status;\n\tu32 phy_id;\n\tunsigned char cable_selection_mask = *to_cable_select(ihost);\n\n\t \n\twritel(0x0081000f, &afe->afe_dfx_master_control0);\n\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\tif (is_b0(pdev) || is_c0(pdev) || is_c1(pdev)) {\n\t\t \n\t\twritel(0x0007FFFF, &afe->afe_pmsn_master_control2);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t}\n\n\t \n\tif (is_a2(pdev))\n\t\twritel(0x00005A00, &afe->afe_bias_control);\n\telse if (is_b0(pdev) || is_c0(pdev))\n\t\twritel(0x00005F00, &afe->afe_bias_control);\n\telse if (is_c1(pdev))\n\t\twritel(0x00005500, &afe->afe_bias_control);\n\n\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t \n\tif (is_a2(pdev))\n\t\twritel(0x80040908, &afe->afe_pll_control0);\n\telse if (is_b0(pdev) || is_c0(pdev))\n\t\twritel(0x80040A08, &afe->afe_pll_control0);\n\telse if (is_c1(pdev)) {\n\t\twritel(0x80000B08, &afe->afe_pll_control0);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t\twritel(0x00000B08, &afe->afe_pll_control0);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t\twritel(0x80000B08, &afe->afe_pll_control0);\n\t}\n\n\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t \n\tdo {\n\t\tafe_status = readl(&afe->afe_common_block_status);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t} while ((afe_status & 0x00001000) == 0);\n\n\tif (is_a2(pdev)) {\n\t\t \n\t\twritel(0x7bcc96ad, &afe->afe_pmsn_master_control0);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t}\n\n\tfor (phy_id = 0; phy_id < SCI_MAX_PHYS; phy_id++) {\n\t\tstruct scu_afe_transceiver __iomem *xcvr = &afe->scu_afe_xcvr[phy_id];\n\t\tconst struct sci_phy_oem_params *oem_phy = &oem->phys[phy_id];\n\t\tint cable_length_long =\n\t\t\tis_long_cable(phy_id, cable_selection_mask);\n\t\tint cable_length_medium =\n\t\t\tis_medium_cable(phy_id, cable_selection_mask);\n\n\t\tif (is_a2(pdev)) {\n\t\t\t \n\t\t\twritel(0x00004512, &xcvr->afe_xcvr_control0);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\twritel(0x0050100F, &xcvr->afe_xcvr_control1);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t\t} else if (is_b0(pdev)) {\n\t\t\t \n\t\t\twritel(0x00030000, &xcvr->afe_tx_ssc_control);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t\t} else if (is_c0(pdev)) {\n\t\t\t \n\t\t\twritel(0x00010202, &xcvr->afe_tx_ssc_control);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\t \n\t\t\twritel(0x00014500, &xcvr->afe_xcvr_control0);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t\t} else if (is_c1(pdev)) {\n\t\t\t \n\t\t\twritel(0x00010202, &xcvr->afe_tx_ssc_control);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\t \n\t\t\twritel(0x0001C500, &xcvr->afe_xcvr_control0);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t\t}\n\n\t\t \n\t\tif (is_a2(pdev))\n\t\t\twritel(0x000003F0, &xcvr->afe_channel_control);\n\t\telse if (is_b0(pdev)) {\n\t\t\twritel(0x000003D7, &xcvr->afe_channel_control);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\twritel(0x000003D4, &xcvr->afe_channel_control);\n\t\t} else if (is_c0(pdev)) {\n\t\t\twritel(0x000001E7, &xcvr->afe_channel_control);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\twritel(0x000001E4, &xcvr->afe_channel_control);\n\t\t} else if (is_c1(pdev)) {\n\t\t\twritel(cable_length_long ? 0x000002F7 : 0x000001F7,\n\t\t\t       &xcvr->afe_channel_control);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\twritel(cable_length_long ? 0x000002F4 : 0x000001F4,\n\t\t\t       &xcvr->afe_channel_control);\n\t\t}\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\tif (is_a2(pdev)) {\n\t\t\t \n\t\t\twritel(0x00040000, &xcvr->afe_tx_control);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t\t}\n\n\t\tif (is_a2(pdev) || is_b0(pdev))\n\t\t\t \n\t\t\twritel(0x00004100, &xcvr->afe_xcvr_control0);\n\t\telse if (is_c0(pdev))\n\t\t\twritel(0x00014100, &xcvr->afe_xcvr_control0);\n\t\telse if (is_c1(pdev))\n\t\t\twritel(0x0001C100, &xcvr->afe_xcvr_control0);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t \n\t\tif (is_a2(pdev))\n\t\t\twritel(0x3F11103F, &xcvr->afe_rx_ssc_control0);\n\t\telse if (is_b0(pdev)) {\n\t\t\twritel(0x3F11103F, &xcvr->afe_rx_ssc_control0);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t\t\t \n\t\t\twritel(0x00040000, &xcvr->afe_tx_control);\n\t\t} else if (is_c0(pdev)) {\n\t\t\twritel(0x01400C0F, &xcvr->afe_rx_ssc_control1);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\twritel(0x3F6F103F, &xcvr->afe_rx_ssc_control0);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\t \n\t\t\twritel(0x00040000, &xcvr->afe_tx_control);\n\t\t} else if (is_c1(pdev)) {\n\t\t\twritel(cable_length_long ? 0x01500C0C :\n\t\t\t       cable_length_medium ? 0x01400C0D : 0x02400C0D,\n\t\t\t       &xcvr->afe_xcvr_control1);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\twritel(0x000003E0, &xcvr->afe_dfx_rx_control1);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\twritel(cable_length_long ? 0x33091C1F :\n\t\t\t       cable_length_medium ? 0x3315181F : 0x2B17161F,\n\t\t\t       &xcvr->afe_rx_ssc_control0);\n\t\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\t\t \n\t\t\twritel(0x00040000, &xcvr->afe_tx_control);\n\t\t}\n\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\twritel(oem_phy->afe_tx_amp_control0, &xcvr->afe_tx_amp_control0);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\twritel(oem_phy->afe_tx_amp_control1, &xcvr->afe_tx_amp_control1);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\twritel(oem_phy->afe_tx_amp_control2, &xcvr->afe_tx_amp_control2);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\n\t\twritel(oem_phy->afe_tx_amp_control3, &xcvr->afe_tx_amp_control3);\n\t\tudelay(AFE_REGISTER_WRITE_DELAY);\n\t}\n\n\t \n\twritel(0x00010f00, &afe->afe_dfx_master_control0);\n\tudelay(AFE_REGISTER_WRITE_DELAY);\n}\n\nstatic void sci_controller_initialize_power_control(struct isci_host *ihost)\n{\n\tsci_init_timer(&ihost->power_control.timer, power_control_timeout);\n\n\tmemset(ihost->power_control.requesters, 0,\n\t       sizeof(ihost->power_control.requesters));\n\n\tihost->power_control.phys_waiting = 0;\n\tihost->power_control.phys_granted_power = 0;\n}\n\nstatic enum sci_status sci_controller_initialize(struct isci_host *ihost)\n{\n\tstruct sci_base_state_machine *sm = &ihost->sm;\n\tenum sci_status result = SCI_FAILURE;\n\tunsigned long i, state, val;\n\n\tif (ihost->sm.current_state_id != SCIC_RESET) {\n\t\tdev_warn(&ihost->pdev->dev, \"%s invalid state: %d\\n\",\n\t\t\t __func__, ihost->sm.current_state_id);\n\t\treturn SCI_FAILURE_INVALID_STATE;\n\t}\n\n\tsci_change_state(sm, SCIC_INITIALIZING);\n\n\tsci_init_timer(&ihost->phy_timer, phy_startup_timeout);\n\n\tihost->next_phy_to_start = 0;\n\tihost->phy_startup_timer_pending = false;\n\n\tsci_controller_initialize_power_control(ihost);\n\n\t \n\tsci_controller_afe_initialization(ihost);\n\n\n\t \n\twritel(0, &ihost->smu_registers->soft_reset_control);\n\n\t \n\tfor (i = 100; i >= 1; i--) {\n\t\tu32 status;\n\n\t\t \n\t\tudelay(SCU_CONTEXT_RAM_INIT_STALL_TIME);\n\t\tstatus = readl(&ihost->smu_registers->control_status);\n\n\t\tif ((status & SCU_RAM_INIT_COMPLETED) == SCU_RAM_INIT_COMPLETED)\n\t\t\tbreak;\n\t}\n\tif (i == 0)\n\t\tgoto out;\n\n\t \n\tval = readl(&ihost->smu_registers->device_context_capacity);\n\n\t \n\tihost->logical_port_entries = min(smu_max_ports(val), SCI_MAX_PORTS);\n\tihost->task_context_entries = min(smu_max_task_contexts(val), SCI_MAX_IO_REQUESTS);\n\tihost->remote_node_entries = min(smu_max_rncs(val), SCI_MAX_REMOTE_DEVICES);\n\n\t \n\tfor (i = 0; i < ihost->logical_port_entries; i++) {\n\t\tstruct scu_port_task_scheduler_group_registers __iomem\n\t\t\t*ptsg = &ihost->scu_registers->peg0.ptsg;\n\n\t\twritel(i, &ptsg->protocol_engine[i]);\n\t}\n\n\t \n\tval = readl(&ihost->scu_registers->sdma.pdma_configuration);\n\tval |= SCU_PDMACR_GEN_BIT(PCI_RELAXED_ORDERING_ENABLE);\n\twritel(val, &ihost->scu_registers->sdma.pdma_configuration);\n\n\tval = readl(&ihost->scu_registers->sdma.cdma_configuration);\n\tval |= SCU_CDMACR_GEN_BIT(PCI_RELAXED_ORDERING_ENABLE);\n\twritel(val, &ihost->scu_registers->sdma.cdma_configuration);\n\n\t \n\tfor (i = 0; i < SCI_MAX_PHYS; i++) {\n\t\tresult = sci_phy_initialize(&ihost->phys[i],\n\t\t\t\t\t    &ihost->scu_registers->peg0.pe[i].tl,\n\t\t\t\t\t    &ihost->scu_registers->peg0.pe[i].ll);\n\t\tif (result != SCI_SUCCESS)\n\t\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < ihost->logical_port_entries; i++) {\n\t\tstruct isci_port *iport = &ihost->ports[i];\n\n\t\tiport->port_task_scheduler_registers = &ihost->scu_registers->peg0.ptsg.port[i];\n\t\tiport->port_pe_configuration_register = &ihost->scu_registers->peg0.ptsg.protocol_engine[0];\n\t\tiport->viit_registers = &ihost->scu_registers->peg0.viit[i];\n\t}\n\n\tresult = sci_port_configuration_agent_initialize(ihost, &ihost->port_agent);\n\n out:\n\t \n\tif (result == SCI_SUCCESS)\n\t\tstate = SCIC_INITIALIZED;\n\telse\n\t\tstate = SCIC_FAILED;\n\tsci_change_state(sm, state);\n\n\treturn result;\n}\n\nstatic int sci_controller_dma_alloc(struct isci_host *ihost)\n{\n\tstruct device *dev = &ihost->pdev->dev;\n\tsize_t size;\n\tint i;\n\n\t \n\tif (ihost->completion_queue)\n\t\treturn 0;\n\n\tsize = SCU_MAX_COMPLETION_QUEUE_ENTRIES * sizeof(u32);\n\tihost->completion_queue = dmam_alloc_coherent(dev, size, &ihost->cq_dma,\n\t\t\t\t\t\t      GFP_KERNEL);\n\tif (!ihost->completion_queue)\n\t\treturn -ENOMEM;\n\n\tsize = ihost->remote_node_entries * sizeof(union scu_remote_node_context);\n\tihost->remote_node_context_table = dmam_alloc_coherent(dev, size, &ihost->rnc_dma,\n\t\t\t\t\t\t\t       GFP_KERNEL);\n\n\tif (!ihost->remote_node_context_table)\n\t\treturn -ENOMEM;\n\n\tsize = ihost->task_context_entries * sizeof(struct scu_task_context),\n\tihost->task_context_table = dmam_alloc_coherent(dev, size, &ihost->tc_dma,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\tif (!ihost->task_context_table)\n\t\treturn -ENOMEM;\n\n\tsize = SCI_UFI_TOTAL_SIZE;\n\tihost->ufi_buf = dmam_alloc_coherent(dev, size, &ihost->ufi_dma, GFP_KERNEL);\n\tif (!ihost->ufi_buf)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < SCI_MAX_IO_REQUESTS; i++) {\n\t\tstruct isci_request *ireq;\n\t\tdma_addr_t dma;\n\n\t\tireq = dmam_alloc_coherent(dev, sizeof(*ireq), &dma, GFP_KERNEL);\n\t\tif (!ireq)\n\t\t\treturn -ENOMEM;\n\n\t\tireq->tc = &ihost->task_context_table[i];\n\t\tireq->owning_controller = ihost;\n\t\tireq->request_daddr = dma;\n\t\tireq->isci_host = ihost;\n\t\tihost->reqs[i] = ireq;\n\t}\n\n\treturn 0;\n}\n\nstatic int sci_controller_mem_init(struct isci_host *ihost)\n{\n\tint err = sci_controller_dma_alloc(ihost);\n\n\tif (err)\n\t\treturn err;\n\n\twritel(lower_32_bits(ihost->cq_dma), &ihost->smu_registers->completion_queue_lower);\n\twritel(upper_32_bits(ihost->cq_dma), &ihost->smu_registers->completion_queue_upper);\n\n\twritel(lower_32_bits(ihost->rnc_dma), &ihost->smu_registers->remote_node_context_lower);\n\twritel(upper_32_bits(ihost->rnc_dma), &ihost->smu_registers->remote_node_context_upper);\n\n\twritel(lower_32_bits(ihost->tc_dma), &ihost->smu_registers->host_task_table_lower);\n\twritel(upper_32_bits(ihost->tc_dma), &ihost->smu_registers->host_task_table_upper);\n\n\tsci_unsolicited_frame_control_construct(ihost);\n\n\t \n\twritel(lower_32_bits(ihost->uf_control.headers.physical_address),\n\t\t&ihost->scu_registers->sdma.uf_header_base_address_lower);\n\twritel(upper_32_bits(ihost->uf_control.headers.physical_address),\n\t\t&ihost->scu_registers->sdma.uf_header_base_address_upper);\n\n\twritel(lower_32_bits(ihost->uf_control.address_table.physical_address),\n\t\t&ihost->scu_registers->sdma.uf_address_table_lower);\n\twritel(upper_32_bits(ihost->uf_control.address_table.physical_address),\n\t\t&ihost->scu_registers->sdma.uf_address_table_upper);\n\n\treturn 0;\n}\n\n \nint isci_host_init(struct isci_host *ihost)\n{\n\tint i, err;\n\tenum sci_status status;\n\n\tspin_lock_irq(&ihost->scic_lock);\n\tstatus = sci_controller_construct(ihost, scu_base(ihost), smu_base(ihost));\n\tspin_unlock_irq(&ihost->scic_lock);\n\tif (status != SCI_SUCCESS) {\n\t\tdev_err(&ihost->pdev->dev,\n\t\t\t\"%s: sci_controller_construct failed - status = %x\\n\",\n\t\t\t__func__,\n\t\t\tstatus);\n\t\treturn -ENODEV;\n\t}\n\n\tspin_lock_irq(&ihost->scic_lock);\n\tstatus = sci_controller_initialize(ihost);\n\tspin_unlock_irq(&ihost->scic_lock);\n\tif (status != SCI_SUCCESS) {\n\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t \"%s: sci_controller_initialize failed -\"\n\t\t\t \" status = 0x%x\\n\",\n\t\t\t __func__, status);\n\t\treturn -ENODEV;\n\t}\n\n\terr = sci_controller_mem_init(ihost);\n\tif (err)\n\t\treturn err;\n\n\t \n\twritel(1, &ihost->scu_registers->peg0.sgpio.interface_control);\n\tfor (i = 0; i < isci_gpio_count(ihost); i++)\n\t\twritel(SGPIO_HW_CONTROL, &ihost->scu_registers->peg0.sgpio.output_data_select[i]);\n\twritel(0, &ihost->scu_registers->peg0.sgpio.vendor_specific_code);\n\n\treturn 0;\n}\n\nvoid sci_controller_link_up(struct isci_host *ihost, struct isci_port *iport,\n\t\t\t    struct isci_phy *iphy)\n{\n\tswitch (ihost->sm.current_state_id) {\n\tcase SCIC_STARTING:\n\t\tsci_del_timer(&ihost->phy_timer);\n\t\tihost->phy_startup_timer_pending = false;\n\t\tihost->port_agent.link_up_handler(ihost, &ihost->port_agent,\n\t\t\t\t\t\t  iport, iphy);\n\t\tsci_controller_start_next_phy(ihost);\n\t\tbreak;\n\tcase SCIC_READY:\n\t\tihost->port_agent.link_up_handler(ihost, &ihost->port_agent,\n\t\t\t\t\t\t  iport, iphy);\n\t\tbreak;\n\tdefault:\n\t\tdev_dbg(&ihost->pdev->dev,\n\t\t\t\"%s: SCIC Controller linkup event from phy %d in \"\n\t\t\t\"unexpected state %d\\n\", __func__, iphy->phy_index,\n\t\t\tihost->sm.current_state_id);\n\t}\n}\n\nvoid sci_controller_link_down(struct isci_host *ihost, struct isci_port *iport,\n\t\t\t      struct isci_phy *iphy)\n{\n\tswitch (ihost->sm.current_state_id) {\n\tcase SCIC_STARTING:\n\tcase SCIC_READY:\n\t\tihost->port_agent.link_down_handler(ihost, &ihost->port_agent,\n\t\t\t\t\t\t   iport, iphy);\n\t\tbreak;\n\tdefault:\n\t\tdev_dbg(&ihost->pdev->dev,\n\t\t\t\"%s: SCIC Controller linkdown event from phy %d in \"\n\t\t\t\"unexpected state %d\\n\",\n\t\t\t__func__,\n\t\t\tiphy->phy_index,\n\t\t\tihost->sm.current_state_id);\n\t}\n}\n\nbool sci_controller_has_remote_devices_stopping(struct isci_host *ihost)\n{\n\tu32 index;\n\n\tfor (index = 0; index < ihost->remote_node_entries; index++) {\n\t\tif ((ihost->device_table[index] != NULL) &&\n\t\t   (ihost->device_table[index]->sm.current_state_id == SCI_DEV_STOPPING))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nvoid sci_controller_remote_device_stopped(struct isci_host *ihost,\n\t\t\t\t\t  struct isci_remote_device *idev)\n{\n\tif (ihost->sm.current_state_id != SCIC_STOPPING) {\n\t\tdev_dbg(&ihost->pdev->dev,\n\t\t\t\"SCIC Controller 0x%p remote device stopped event \"\n\t\t\t\"from device 0x%p in unexpected state %d\\n\",\n\t\t\tihost, idev,\n\t\t\tihost->sm.current_state_id);\n\t\treturn;\n\t}\n\n\tif (!sci_controller_has_remote_devices_stopping(ihost))\n\t\tisci_host_stop_complete(ihost);\n}\n\nvoid sci_controller_post_request(struct isci_host *ihost, u32 request)\n{\n\tdev_dbg(&ihost->pdev->dev, \"%s[%d]: %#x\\n\",\n\t\t__func__, ihost->id, request);\n\n\twritel(request, &ihost->smu_registers->post_context_port);\n}\n\nstruct isci_request *sci_request_by_tag(struct isci_host *ihost, u16 io_tag)\n{\n\tu16 task_index;\n\tu16 task_sequence;\n\n\ttask_index = ISCI_TAG_TCI(io_tag);\n\n\tif (task_index < ihost->task_context_entries) {\n\t\tstruct isci_request *ireq = ihost->reqs[task_index];\n\n\t\tif (test_bit(IREQ_ACTIVE, &ireq->flags)) {\n\t\t\ttask_sequence = ISCI_TAG_SEQ(io_tag);\n\n\t\t\tif (task_sequence == ihost->io_request_sequence[task_index])\n\t\t\t\treturn ireq;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\n \nenum sci_status sci_controller_allocate_remote_node_context(struct isci_host *ihost,\n\t\t\t\t\t\t\t    struct isci_remote_device *idev,\n\t\t\t\t\t\t\t    u16 *node_id)\n{\n\tu16 node_index;\n\tu32 remote_node_count = sci_remote_device_node_count(idev);\n\n\tnode_index = sci_remote_node_table_allocate_remote_node(\n\t\t&ihost->available_remote_nodes, remote_node_count\n\t\t);\n\n\tif (node_index != SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX) {\n\t\tihost->device_table[node_index] = idev;\n\n\t\t*node_id = node_index;\n\n\t\treturn SCI_SUCCESS;\n\t}\n\n\treturn SCI_FAILURE_INSUFFICIENT_RESOURCES;\n}\n\nvoid sci_controller_free_remote_node_context(struct isci_host *ihost,\n\t\t\t\t\t     struct isci_remote_device *idev,\n\t\t\t\t\t     u16 node_id)\n{\n\tu32 remote_node_count = sci_remote_device_node_count(idev);\n\n\tif (ihost->device_table[node_id] == idev) {\n\t\tihost->device_table[node_id] = NULL;\n\n\t\tsci_remote_node_table_release_remote_node_index(\n\t\t\t&ihost->available_remote_nodes, remote_node_count, node_id\n\t\t\t);\n\t}\n}\n\nvoid sci_controller_copy_sata_response(void *response_buffer,\n\t\t\t\t       void *frame_header,\n\t\t\t\t       void *frame_buffer)\n{\n\t \n\tmemcpy(response_buffer, frame_header, sizeof(u32));\n\n\tmemcpy(response_buffer + sizeof(u32),\n\t       frame_buffer,\n\t       sizeof(struct dev_to_host_fis) - sizeof(u32));\n}\n\nvoid sci_controller_release_frame(struct isci_host *ihost, u32 frame_index)\n{\n\tif (sci_unsolicited_frame_control_release_frame(&ihost->uf_control, frame_index))\n\t\twritel(ihost->uf_control.get,\n\t\t\t&ihost->scu_registers->sdma.unsolicited_frame_get_pointer);\n}\n\nvoid isci_tci_free(struct isci_host *ihost, u16 tci)\n{\n\tu16 tail = ihost->tci_tail & (SCI_MAX_IO_REQUESTS-1);\n\n\tihost->tci_pool[tail] = tci;\n\tihost->tci_tail = tail + 1;\n}\n\nstatic u16 isci_tci_alloc(struct isci_host *ihost)\n{\n\tu16 head = ihost->tci_head & (SCI_MAX_IO_REQUESTS-1);\n\tu16 tci = ihost->tci_pool[head];\n\n\tihost->tci_head = head + 1;\n\treturn tci;\n}\n\nstatic u16 isci_tci_space(struct isci_host *ihost)\n{\n\treturn CIRC_SPACE(ihost->tci_head, ihost->tci_tail, SCI_MAX_IO_REQUESTS);\n}\n\nu16 isci_alloc_tag(struct isci_host *ihost)\n{\n\tif (isci_tci_space(ihost)) {\n\t\tu16 tci = isci_tci_alloc(ihost);\n\t\tu8 seq = ihost->io_request_sequence[tci];\n\n\t\treturn ISCI_TAG(seq, tci);\n\t}\n\n\treturn SCI_CONTROLLER_INVALID_IO_TAG;\n}\n\nenum sci_status isci_free_tag(struct isci_host *ihost, u16 io_tag)\n{\n\tu16 tci = ISCI_TAG_TCI(io_tag);\n\tu16 seq = ISCI_TAG_SEQ(io_tag);\n\n\t \n\tif (isci_tci_active(ihost) == 0)\n\t\treturn SCI_FAILURE_INVALID_IO_TAG;\n\n\tif (seq == ihost->io_request_sequence[tci]) {\n\t\tihost->io_request_sequence[tci] = (seq+1) & (SCI_MAX_SEQ-1);\n\n\t\tisci_tci_free(ihost, tci);\n\n\t\treturn SCI_SUCCESS;\n\t}\n\treturn SCI_FAILURE_INVALID_IO_TAG;\n}\n\nenum sci_status sci_controller_start_io(struct isci_host *ihost,\n\t\t\t\t\tstruct isci_remote_device *idev,\n\t\t\t\t\tstruct isci_request *ireq)\n{\n\tenum sci_status status;\n\n\tif (ihost->sm.current_state_id != SCIC_READY) {\n\t\tdev_warn(&ihost->pdev->dev, \"%s invalid state: %d\\n\",\n\t\t\t __func__, ihost->sm.current_state_id);\n\t\treturn SCI_FAILURE_INVALID_STATE;\n\t}\n\n\tstatus = sci_remote_device_start_io(ihost, idev, ireq);\n\tif (status != SCI_SUCCESS)\n\t\treturn status;\n\n\tset_bit(IREQ_ACTIVE, &ireq->flags);\n\tsci_controller_post_request(ihost, ireq->post_context);\n\treturn SCI_SUCCESS;\n}\n\nenum sci_status sci_controller_terminate_request(struct isci_host *ihost,\n\t\t\t\t\t\t struct isci_remote_device *idev,\n\t\t\t\t\t\t struct isci_request *ireq)\n{\n\t \n\tenum sci_status status;\n\n\tif (ihost->sm.current_state_id != SCIC_READY) {\n\t\tdev_warn(&ihost->pdev->dev, \"%s invalid state: %d\\n\",\n\t\t\t __func__, ihost->sm.current_state_id);\n\t\treturn SCI_FAILURE_INVALID_STATE;\n\t}\n\tstatus = sci_io_request_terminate(ireq);\n\n\tdev_dbg(&ihost->pdev->dev, \"%s: status=%d; ireq=%p; flags=%lx\\n\",\n\t\t__func__, status, ireq, ireq->flags);\n\n\tif ((status == SCI_SUCCESS) &&\n\t    !test_bit(IREQ_PENDING_ABORT, &ireq->flags) &&\n\t    !test_and_set_bit(IREQ_TC_ABORT_POSTED, &ireq->flags)) {\n\t\t \n\t\tsci_controller_post_request(\n\t\t\tihost, ireq->post_context |\n\t\t\t\tSCU_CONTEXT_COMMAND_REQUEST_POST_TC_ABORT);\n\t}\n\treturn status;\n}\n\n \nenum sci_status sci_controller_complete_io(struct isci_host *ihost,\n\t\t\t\t\t   struct isci_remote_device *idev,\n\t\t\t\t\t   struct isci_request *ireq)\n{\n\tenum sci_status status;\n\n\tswitch (ihost->sm.current_state_id) {\n\tcase SCIC_STOPPING:\n\t\t \n\t\treturn SCI_FAILURE;\n\tcase SCIC_READY:\n\t\tstatus = sci_remote_device_complete_io(ihost, idev, ireq);\n\t\tif (status != SCI_SUCCESS)\n\t\t\treturn status;\n\n\t\tclear_bit(IREQ_ACTIVE, &ireq->flags);\n\t\treturn SCI_SUCCESS;\n\tdefault:\n\t\tdev_warn(&ihost->pdev->dev, \"%s invalid state: %d\\n\",\n\t\t\t __func__, ihost->sm.current_state_id);\n\t\treturn SCI_FAILURE_INVALID_STATE;\n\t}\n\n}\n\nenum sci_status sci_controller_continue_io(struct isci_request *ireq)\n{\n\tstruct isci_host *ihost = ireq->owning_controller;\n\n\tif (ihost->sm.current_state_id != SCIC_READY) {\n\t\tdev_warn(&ihost->pdev->dev, \"%s invalid state: %d\\n\",\n\t\t\t __func__, ihost->sm.current_state_id);\n\t\treturn SCI_FAILURE_INVALID_STATE;\n\t}\n\n\tset_bit(IREQ_ACTIVE, &ireq->flags);\n\tsci_controller_post_request(ihost, ireq->post_context);\n\treturn SCI_SUCCESS;\n}\n\n \nenum sci_status sci_controller_start_task(struct isci_host *ihost,\n\t\t\t\t\t  struct isci_remote_device *idev,\n\t\t\t\t\t  struct isci_request *ireq)\n{\n\tenum sci_status status;\n\n\tif (ihost->sm.current_state_id != SCIC_READY) {\n\t\tdev_warn(&ihost->pdev->dev,\n\t\t\t \"%s: SCIC Controller starting task from invalid \"\n\t\t\t \"state\\n\",\n\t\t\t __func__);\n\t\treturn SCI_FAILURE_INVALID_STATE;\n\t}\n\n\tstatus = sci_remote_device_start_task(ihost, idev, ireq);\n\tswitch (status) {\n\tcase SCI_FAILURE_RESET_DEVICE_PARTIAL_SUCCESS:\n\t\tset_bit(IREQ_ACTIVE, &ireq->flags);\n\n\t\t \n\t\treturn SCI_SUCCESS;\n\tcase SCI_SUCCESS:\n\t\tset_bit(IREQ_ACTIVE, &ireq->flags);\n\t\tsci_controller_post_request(ihost, ireq->post_context);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn status;\n}\n\nstatic int sci_write_gpio_tx_gp(struct isci_host *ihost, u8 reg_index, u8 reg_count, u8 *write_data)\n{\n\tint d;\n\n\t \n\tif (reg_index == 0)\n\t\treturn -EINVAL;\n\n\tfor (d = 0; d < isci_gpio_count(ihost); d++) {\n\t\tu32 val = 0x444;  \n\t\tint i;\n\n\t\tfor (i = 0; i < 3; i++) {\n\t\t\tint bit;\n\n\t\t\tbit = try_test_sas_gpio_gp_bit(to_sas_gpio_od(d, i),\n\t\t\t\t\t\t       write_data, reg_index,\n\t\t\t\t\t\t       reg_count);\n\t\t\tif (bit < 0)\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\tval &= ~(bit << ((i << 2) + 2));\n\t\t}\n\n\t\tif (i < 3)\n\t\t\tbreak;\n\t\twritel(val, &ihost->scu_registers->peg0.sgpio.output_data_select[d]);\n\t}\n\n\t \n\treturn d > 0;\n}\n\nint isci_gpio_write(struct sas_ha_struct *sas_ha, u8 reg_type, u8 reg_index,\n\t\t    u8 reg_count, u8 *write_data)\n{\n\tstruct isci_host *ihost = sas_ha->lldd_ha;\n\tint written;\n\n\tswitch (reg_type) {\n\tcase SAS_GPIO_REG_TX_GP:\n\t\twritten = sci_write_gpio_tx_gp(ihost, reg_index, reg_count, write_data);\n\t\tbreak;\n\tdefault:\n\t\twritten = -EINVAL;\n\t}\n\n\treturn written;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}