{
  "module_name": "lpfc_init.c",
  "hash_id": "a80142b299b46241b71d6a09688adedd82aa9c2946a378624b53bff323715e71",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/lpfc/lpfc_init.c",
  "human_readable_source": " \n\n#include <linux/blkdev.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/idr.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\n#include <linux/pci.h>\n#include <linux/spinlock.h>\n#include <linux/sched/clock.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/firmware.h>\n#include <linux/miscdevice.h>\n#include <linux/percpu.h>\n#include <linux/irq.h>\n#include <linux/bitops.h>\n#include <linux/crash_dump.h>\n#include <linux/cpu.h>\n#include <linux/cpuhotplug.h>\n\n#include <scsi/scsi.h>\n#include <scsi/scsi_device.h>\n#include <scsi/scsi_host.h>\n#include <scsi/scsi_transport_fc.h>\n#include <scsi/scsi_tcq.h>\n#include <scsi/fc/fc_fs.h>\n\n#include \"lpfc_hw4.h\"\n#include \"lpfc_hw.h\"\n#include \"lpfc_sli.h\"\n#include \"lpfc_sli4.h\"\n#include \"lpfc_nl.h\"\n#include \"lpfc_disc.h\"\n#include \"lpfc.h\"\n#include \"lpfc_scsi.h\"\n#include \"lpfc_nvme.h\"\n#include \"lpfc_logmsg.h\"\n#include \"lpfc_crtn.h\"\n#include \"lpfc_vport.h\"\n#include \"lpfc_version.h\"\n#include \"lpfc_ids.h\"\n\nstatic enum cpuhp_state lpfc_cpuhp_state;\n \nstatic uint32_t lpfc_present_cpu;\nstatic bool lpfc_pldv_detect;\n\nstatic void __lpfc_cpuhp_remove(struct lpfc_hba *phba);\nstatic void lpfc_cpuhp_remove(struct lpfc_hba *phba);\nstatic void lpfc_cpuhp_add(struct lpfc_hba *phba);\nstatic void lpfc_get_hba_model_desc(struct lpfc_hba *, uint8_t *, uint8_t *);\nstatic int lpfc_post_rcv_buf(struct lpfc_hba *);\nstatic int lpfc_sli4_queue_verify(struct lpfc_hba *);\nstatic int lpfc_create_bootstrap_mbox(struct lpfc_hba *);\nstatic int lpfc_setup_endian_order(struct lpfc_hba *);\nstatic void lpfc_destroy_bootstrap_mbox(struct lpfc_hba *);\nstatic void lpfc_free_els_sgl_list(struct lpfc_hba *);\nstatic void lpfc_free_nvmet_sgl_list(struct lpfc_hba *);\nstatic void lpfc_init_sgl_list(struct lpfc_hba *);\nstatic int lpfc_init_active_sgl_array(struct lpfc_hba *);\nstatic void lpfc_free_active_sgl(struct lpfc_hba *);\nstatic int lpfc_hba_down_post_s3(struct lpfc_hba *phba);\nstatic int lpfc_hba_down_post_s4(struct lpfc_hba *phba);\nstatic int lpfc_sli4_cq_event_pool_create(struct lpfc_hba *);\nstatic void lpfc_sli4_cq_event_pool_destroy(struct lpfc_hba *);\nstatic void lpfc_sli4_cq_event_release_all(struct lpfc_hba *);\nstatic void lpfc_sli4_disable_intr(struct lpfc_hba *);\nstatic uint32_t lpfc_sli4_enable_intr(struct lpfc_hba *, uint32_t);\nstatic void lpfc_sli4_oas_verify(struct lpfc_hba *phba);\nstatic uint16_t lpfc_find_cpu_handle(struct lpfc_hba *, uint16_t, int);\nstatic void lpfc_setup_bg(struct lpfc_hba *, struct Scsi_Host *);\nstatic int lpfc_sli4_cgn_parm_chg_evt(struct lpfc_hba *);\nstatic void lpfc_sli4_prep_dev_for_reset(struct lpfc_hba *phba);\n\nstatic struct scsi_transport_template *lpfc_transport_template = NULL;\nstatic struct scsi_transport_template *lpfc_vport_transport_template = NULL;\nstatic DEFINE_IDR(lpfc_hba_index);\n#define LPFC_NVMET_BUF_POST 254\nstatic int lpfc_vmid_res_alloc(struct lpfc_hba *phba, struct lpfc_vport *vport);\nstatic void lpfc_cgn_update_tstamp(struct lpfc_hba *phba, struct lpfc_cgn_ts *ts);\n\n \nint\nlpfc_config_port_prep(struct lpfc_hba *phba)\n{\n\tlpfc_vpd_t *vp = &phba->vpd;\n\tint i = 0, rc;\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tchar *lpfc_vpd_data = NULL;\n\tuint16_t offset = 0;\n\tstatic char licensed[56] =\n\t\t    \"key unlock for use with gnu public licensed code only\\0\";\n\tstatic int init_key = 1;\n\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\n\tmb = &pmb->u.mb;\n\tphba->link_state = LPFC_INIT_MBX_CMDS;\n\n\tif (lpfc_is_LC_HBA(phba->pcidev->device)) {\n\t\tif (init_key) {\n\t\t\tuint32_t *ptext = (uint32_t *) licensed;\n\n\t\t\tfor (i = 0; i < 56; i += sizeof (uint32_t), ptext++)\n\t\t\t\t*ptext = cpu_to_be32(*ptext);\n\t\t\tinit_key = 0;\n\t\t}\n\n\t\tlpfc_read_nv(phba, pmb);\n\t\tmemset((char*)mb->un.varRDnvp.rsvd3, 0,\n\t\t\tsizeof (mb->un.varRDnvp.rsvd3));\n\t\tmemcpy((char*)mb->un.varRDnvp.rsvd3, licensed,\n\t\t\t sizeof (licensed));\n\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0324 Config Port initialization \"\n\t\t\t\t\t\"error, mbxCmd x%x READ_NVPARM, \"\n\t\t\t\t\t\"mbxStatus x%x\\n\",\n\t\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\t\treturn -ERESTART;\n\t\t}\n\t\tmemcpy(phba->wwnn, (char *)mb->un.varRDnvp.nodename,\n\t\t       sizeof(phba->wwnn));\n\t\tmemcpy(phba->wwpn, (char *)mb->un.varRDnvp.portname,\n\t\t       sizeof(phba->wwpn));\n\t}\n\n\t \n\tphba->sli3_options &= (uint32_t)LPFC_SLI3_BG_ENABLED;\n\n\t \n\tlpfc_read_rev(phba, pmb);\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0439 Adapter failed to init, mbxCmd x%x \"\n\t\t\t\t\"READ_REV, mbxStatus x%x\\n\",\n\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\tmempool_free( pmb, phba->mbox_mem_pool);\n\t\treturn -ERESTART;\n\t}\n\n\n\t \n\tif (mb->un.varRdRev.rr == 0) {\n\t\tvp->rev.rBit = 0;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0440 Adapter failed to init, READ_REV has \"\n\t\t\t\t\"missing revision information.\\n\");\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -ERESTART;\n\t}\n\n\tif (phba->sli_rev == 3 && !mb->un.varRdRev.v3rsp) {\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tvp->rev.rBit = 1;\n\tmemcpy(&vp->sli3Feat, &mb->un.varRdRev.sli3Feat, sizeof(uint32_t));\n\tvp->rev.sli1FwRev = mb->un.varRdRev.sli1FwRev;\n\tmemcpy(vp->rev.sli1FwName, (char*) mb->un.varRdRev.sli1FwName, 16);\n\tvp->rev.sli2FwRev = mb->un.varRdRev.sli2FwRev;\n\tmemcpy(vp->rev.sli2FwName, (char *) mb->un.varRdRev.sli2FwName, 16);\n\tvp->rev.biuRev = mb->un.varRdRev.biuRev;\n\tvp->rev.smRev = mb->un.varRdRev.smRev;\n\tvp->rev.smFwRev = mb->un.varRdRev.un.smFwRev;\n\tvp->rev.endecRev = mb->un.varRdRev.endecRev;\n\tvp->rev.fcphHigh = mb->un.varRdRev.fcphHigh;\n\tvp->rev.fcphLow = mb->un.varRdRev.fcphLow;\n\tvp->rev.feaLevelHigh = mb->un.varRdRev.feaLevelHigh;\n\tvp->rev.feaLevelLow = mb->un.varRdRev.feaLevelLow;\n\tvp->rev.postKernRev = mb->un.varRdRev.postKernRev;\n\tvp->rev.opFwRev = mb->un.varRdRev.opFwRev;\n\n\t \n\tif (vp->rev.feaLevelHigh < 9)\n\t\tphba->sli3_options |= LPFC_SLI3_VPORT_TEARDOWN;\n\n\tif (lpfc_is_LC_HBA(phba->pcidev->device))\n\t\tmemcpy(phba->RandomData, (char *)&mb->un.varWords[24],\n\t\t\t\t\t\tsizeof (phba->RandomData));\n\n\t \n\tlpfc_vpd_data = kmalloc(DMP_VPD_SIZE, GFP_KERNEL);\n\tif (!lpfc_vpd_data)\n\t\tgoto out_free_mbox;\n\tdo {\n\t\tlpfc_dump_mem(phba, pmb, offset, DMP_REGION_VPD);\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"0441 VPD not present on adapter, \"\n\t\t\t\t\t\"mbxCmd x%x DUMP VPD, mbxStatus x%x\\n\",\n\t\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\t\tmb->un.varDmp.word_cnt = 0;\n\t\t}\n\t\t \n\t\tif (mb->un.varDmp.word_cnt == 0)\n\t\t\tbreak;\n\n\t\tif (mb->un.varDmp.word_cnt > DMP_VPD_SIZE - offset)\n\t\t\tmb->un.varDmp.word_cnt = DMP_VPD_SIZE - offset;\n\t\tlpfc_sli_pcimem_bcopy(((uint8_t *)mb) + DMP_RSP_OFFSET,\n\t\t\t\t      lpfc_vpd_data + offset,\n\t\t\t\t      mb->un.varDmp.word_cnt);\n\t\toffset += mb->un.varDmp.word_cnt;\n\t} while (mb->un.varDmp.word_cnt && offset < DMP_VPD_SIZE);\n\n\tlpfc_parse_vpd(phba, lpfc_vpd_data, offset);\n\n\tkfree(lpfc_vpd_data);\nout_free_mbox:\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\treturn 0;\n}\n\n \nstatic void\nlpfc_config_async_cmpl(struct lpfc_hba * phba, LPFC_MBOXQ_t * pmboxq)\n{\n\tif (pmboxq->u.mb.mbxStatus == MBX_SUCCESS)\n\t\tphba->temp_sensor_support = 1;\n\telse\n\t\tphba->temp_sensor_support = 0;\n\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\treturn;\n}\n\n \nstatic void\nlpfc_dump_wakeup_param_cmpl(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmboxq)\n{\n\tstruct prog_id *prg;\n\tuint32_t prog_id_word;\n\tchar dist = ' ';\n\t \n\tchar dist_char[] = \"nabx\";\n\n\tif (pmboxq->u.mb.mbxStatus != MBX_SUCCESS) {\n\t\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\t\treturn;\n\t}\n\n\tprg = (struct prog_id *) &prog_id_word;\n\n\t \n\tprog_id_word = pmboxq->u.mb.un.varWords[7];\n\n\t \n\tdist = dist_char[prg->dist];\n\n\tif ((prg->dist == 3) && (prg->num == 0))\n\t\tsnprintf(phba->OptionROMVersion, 32, \"%d.%d%d\",\n\t\t\tprg->ver, prg->rev, prg->lev);\n\telse\n\t\tsnprintf(phba->OptionROMVersion, 32, \"%d.%d%d%c%d\",\n\t\t\tprg->ver, prg->rev, prg->lev,\n\t\t\tdist, prg->num);\n\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\treturn;\n}\n\n \nvoid\nlpfc_update_vport_wwn(struct lpfc_vport *vport)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\n\t \n\tif (vport->fc_nodename.u.wwn[0] == 0)\n\t\tmemcpy(&vport->fc_nodename, &vport->fc_sparam.nodeName,\n\t\t\tsizeof(struct lpfc_name));\n\telse\n\t\tmemcpy(&vport->fc_sparam.nodeName, &vport->fc_nodename,\n\t\t\tsizeof(struct lpfc_name));\n\n\t \n\tif (vport->fc_portname.u.wwn[0] != 0 &&\n\t\tmemcmp(&vport->fc_portname, &vport->fc_sparam.portName,\n\t\t       sizeof(struct lpfc_name))) {\n\t\tvport->vport_flag |= FAWWPN_PARAM_CHG;\n\n\t\tif (phba->sli_rev == LPFC_SLI_REV4 &&\n\t\t    vport->port_type == LPFC_PHYSICAL_PORT &&\n\t\t    phba->sli4_hba.fawwpn_flag & LPFC_FAWWPN_FABRIC) {\n\t\t\tif (!(phba->sli4_hba.fawwpn_flag & LPFC_FAWWPN_CONFIG))\n\t\t\t\tphba->sli4_hba.fawwpn_flag &=\n\t\t\t\t\t\t~LPFC_FAWWPN_FABRIC;\n\t\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\t\tLOG_SLI | LOG_DISCOVERY | LOG_ELS,\n\t\t\t\t\t\"2701 FA-PWWN change WWPN from %llx to \"\n\t\t\t\t\t\"%llx: vflag x%x fawwpn_flag x%x\\n\",\n\t\t\t\t\twwn_to_u64(vport->fc_portname.u.wwn),\n\t\t\t\t\twwn_to_u64\n\t\t\t\t\t   (vport->fc_sparam.portName.u.wwn),\n\t\t\t\t\tvport->vport_flag,\n\t\t\t\t\tphba->sli4_hba.fawwpn_flag);\n\t\t\tmemcpy(&vport->fc_portname, &vport->fc_sparam.portName,\n\t\t\t       sizeof(struct lpfc_name));\n\t\t}\n\t}\n\n\tif (vport->fc_portname.u.wwn[0] == 0)\n\t\tmemcpy(&vport->fc_portname, &vport->fc_sparam.portName,\n\t\t       sizeof(struct lpfc_name));\n\telse\n\t\tmemcpy(&vport->fc_sparam.portName, &vport->fc_portname,\n\t\t       sizeof(struct lpfc_name));\n}\n\n \nint\nlpfc_config_port_post(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tstruct lpfc_dmabuf *mp;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tuint32_t status, timeout;\n\tint i, j;\n\tint rc;\n\n\tspin_lock_irq(&phba->hbalock);\n\t \n\tif (phba->over_temp_state == HBA_OVER_TEMP)\n\t\tphba->over_temp_state = HBA_NORMAL_TEMP;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\tmb = &pmb->u.mb;\n\n\t \n\trc = lpfc_read_sparam(phba, pmb, 0);\n\tif (rc) {\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -ENOMEM;\n\t}\n\n\tpmb->vport = vport;\n\tif (lpfc_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0448 Adapter failed init, mbxCmd x%x \"\n\t\t\t\t\"READ_SPARM mbxStatus x%x\\n\",\n\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tlpfc_mbox_rsrc_cleanup(phba, pmb, MBOX_THD_UNLOCKED);\n\t\treturn -EIO;\n\t}\n\n\tmp = (struct lpfc_dmabuf *)pmb->ctx_buf;\n\n\t \n\tmemcpy(&vport->fc_sparam, mp->virt, sizeof (struct serv_parm));\n\tlpfc_mbuf_free(phba, mp->virt, mp->phys);\n\tkfree(mp);\n\tpmb->ctx_buf = NULL;\n\tlpfc_update_vport_wwn(vport);\n\n\t \n\tfc_host_node_name(shost) = wwn_to_u64(vport->fc_nodename.u.wwn);\n\tfc_host_port_name(shost) = wwn_to_u64(vport->fc_portname.u.wwn);\n\tfc_host_max_npiv_vports(shost) = phba->max_vpi;\n\n\t \n\t \n\tif (phba->SerialNumber[0] == 0) {\n\t\tuint8_t *outptr;\n\n\t\toutptr = &vport->fc_nodename.u.s.IEEE[0];\n\t\tfor (i = 0; i < 12; i++) {\n\t\t\tstatus = *outptr++;\n\t\t\tj = ((status & 0xf0) >> 4);\n\t\t\tif (j <= 9)\n\t\t\t\tphba->SerialNumber[i] =\n\t\t\t\t    (char)((uint8_t) 0x30 + (uint8_t) j);\n\t\t\telse\n\t\t\t\tphba->SerialNumber[i] =\n\t\t\t\t    (char)((uint8_t) 0x61 + (uint8_t) (j - 10));\n\t\t\ti++;\n\t\t\tj = (status & 0xf);\n\t\t\tif (j <= 9)\n\t\t\t\tphba->SerialNumber[i] =\n\t\t\t\t    (char)((uint8_t) 0x30 + (uint8_t) j);\n\t\t\telse\n\t\t\t\tphba->SerialNumber[i] =\n\t\t\t\t    (char)((uint8_t) 0x61 + (uint8_t) (j - 10));\n\t\t}\n\t}\n\n\tlpfc_read_config(phba, pmb);\n\tpmb->vport = vport;\n\tif (lpfc_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0453 Adapter failed to init, mbxCmd x%x \"\n\t\t\t\t\"READ_CONFIG, mbxStatus x%x\\n\",\n\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tmempool_free( pmb, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\n\t \n\tlpfc_sli_read_link_ste(phba);\n\n\t \n\tif (phba->cfg_hba_queue_depth > mb->un.varRdConfig.max_xri) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"3359 HBA queue depth changed from %d to %d\\n\",\n\t\t\t\tphba->cfg_hba_queue_depth,\n\t\t\t\tmb->un.varRdConfig.max_xri);\n\t\tphba->cfg_hba_queue_depth = mb->un.varRdConfig.max_xri;\n\t}\n\n\tphba->lmt = mb->un.varRdConfig.lmt;\n\n\t \n\tlpfc_get_hba_model_desc(phba, phba->ModelName, phba->ModelDesc);\n\n\tphba->link_state = LPFC_LINK_DOWN;\n\n\t \n\tif (psli->sli3_ring[LPFC_EXTRA_RING].sli.sli3.cmdringaddr)\n\t\tpsli->sli3_ring[LPFC_EXTRA_RING].flag |= LPFC_STOP_IOCB_EVENT;\n\tif (psli->sli3_ring[LPFC_FCP_RING].sli.sli3.cmdringaddr)\n\t\tpsli->sli3_ring[LPFC_FCP_RING].flag |= LPFC_STOP_IOCB_EVENT;\n\n\t \n\tif (phba->sli_rev != 3)\n\t\tlpfc_post_rcv_buf(phba);\n\n\t \n\tif (phba->intr_type == MSIX) {\n\t\trc = lpfc_config_msi(phba, pmb);\n\t\tif (rc) {\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\t\treturn -EIO;\n\t\t}\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0352 Config MSI mailbox command \"\n\t\t\t\t\t\"failed, mbxCmd x%x, mbxStatus x%x\\n\",\n\t\t\t\t\tpmb->u.mb.mbxCommand,\n\t\t\t\t\tpmb->u.mb.mbxStatus);\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\n\tspin_lock_irq(&phba->hbalock);\n\t \n\tphba->hba_flag &= ~HBA_ERATT_HANDLED;\n\n\t \n\tif (lpfc_readl(phba->HCregaddr, &status)) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn -EIO;\n\t}\n\tstatus |= HC_MBINT_ENA | HC_ERINT_ENA | HC_LAINT_ENA;\n\tif (psli->num_rings > 0)\n\t\tstatus |= HC_R0INT_ENA;\n\tif (psli->num_rings > 1)\n\t\tstatus |= HC_R1INT_ENA;\n\tif (psli->num_rings > 2)\n\t\tstatus |= HC_R2INT_ENA;\n\tif (psli->num_rings > 3)\n\t\tstatus |= HC_R3INT_ENA;\n\n\tif ((phba->cfg_poll & ENABLE_FCP_RING_POLLING) &&\n\t    (phba->cfg_poll & DISABLE_FCP_RING_INT))\n\t\tstatus &= ~(HC_R0INT_ENA);\n\n\twritel(status, phba->HCregaddr);\n\treadl(phba->HCregaddr);  \n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\ttimeout = phba->fc_ratov * 2;\n\tmod_timer(&vport->els_tmofunc,\n\t\t  jiffies + msecs_to_jiffies(1000 * timeout));\n\t \n\tmod_timer(&phba->hb_tmofunc,\n\t\t  jiffies + msecs_to_jiffies(1000 * LPFC_HB_MBOX_INTERVAL));\n\tphba->hba_flag &= ~(HBA_HBEAT_INP | HBA_HBEAT_TMO);\n\tphba->last_completion_time = jiffies;\n\t \n\tmod_timer(&phba->eratt_poll,\n\t\t  jiffies + msecs_to_jiffies(1000 * phba->eratt_poll_interval));\n\n\tif (phba->hba_flag & LINK_DISABLED) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2598 Adapter Link is disabled.\\n\");\n\t\tlpfc_down_link(phba, pmb);\n\t\tpmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\t\tif ((rc != MBX_SUCCESS) && (rc != MBX_BUSY)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2599 Adapter failed to issue DOWN_LINK\"\n\t\t\t\t\t\" mbox command rc 0x%x\\n\", rc);\n\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\t\treturn -EIO;\n\t\t}\n\t} else if (phba->cfg_suppress_link_up == LPFC_INITIALIZE_LINK) {\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\trc = phba->lpfc_hba_init_link(phba, MBX_NOWAIT);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\t \n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\n\tlpfc_config_async(phba, pmb, LPFC_ELS_RING);\n\tpmb->mbox_cmpl = lpfc_config_async_cmpl;\n\tpmb->vport = phba->pport;\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\n\tif ((rc != MBX_BUSY) && (rc != MBX_SUCCESS)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0456 Adapter failed to issue \"\n\t\t\t\t\"ASYNCEVT_ENABLE mbox status x%x\\n\",\n\t\t\t\trc);\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t}\n\n\t \n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\n\tlpfc_dump_wakeup_param(phba, pmb);\n\tpmb->mbox_cmpl = lpfc_dump_wakeup_param_cmpl;\n\tpmb->vport = phba->pport;\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\n\tif ((rc != MBX_BUSY) && (rc != MBX_SUCCESS)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0435 Adapter failed \"\n\t\t\t\t\"to get Option ROM version status x%x\\n\", rc);\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t}\n\n\treturn 0;\n}\n\n \nint\nlpfc_sli4_refresh_params(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct lpfc_mqe *mqe;\n\tstruct lpfc_sli4_parameters *mbx_sli4_parameters;\n\tint length, rc;\n\n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\n\tmqe = &mboxq->u.mqe;\n\t \n\tlength = (sizeof(struct lpfc_mbx_get_sli4_parameters) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_GET_SLI4_PARAMETERS,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tif (unlikely(rc)) {\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\treturn rc;\n\t}\n\tmbx_sli4_parameters = &mqe->un.get_sli4_parameters.sli4_parameters;\n\tphba->sli4_hba.pc_sli4_params.mi_cap =\n\t\tbf_get(cfg_mi_ver, mbx_sli4_parameters);\n\n\t \n\tif (phba->cfg_enable_mi)\n\t\tphba->sli4_hba.pc_sli4_params.mi_ver =\n\t\t\tbf_get(cfg_mi_ver, mbx_sli4_parameters);\n\telse\n\t\tphba->sli4_hba.pc_sli4_params.mi_ver = 0;\n\n\tphba->sli4_hba.pc_sli4_params.cmf =\n\t\t\tbf_get(cfg_cmf, mbx_sli4_parameters);\n\tphba->sli4_hba.pc_sli4_params.pls =\n\t\t\tbf_get(cfg_pvl, mbx_sli4_parameters);\n\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\treturn rc;\n}\n\n \nstatic int\nlpfc_hba_init_link(struct lpfc_hba *phba, uint32_t flag)\n{\n\treturn lpfc_hba_init_link_fc_topology(phba, phba->cfg_topology, flag);\n}\n\n \nint\nlpfc_hba_init_link_fc_topology(struct lpfc_hba *phba, uint32_t fc_topology,\n\t\t\t       uint32_t flag)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tint rc;\n\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\tmb = &pmb->u.mb;\n\tpmb->vport = vport;\n\n\tif ((phba->cfg_link_speed > LPFC_USER_LINK_SPEED_MAX) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_1G) &&\n\t     !(phba->lmt & LMT_1Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_2G) &&\n\t     !(phba->lmt & LMT_2Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_4G) &&\n\t     !(phba->lmt & LMT_4Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_8G) &&\n\t     !(phba->lmt & LMT_8Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_10G) &&\n\t     !(phba->lmt & LMT_10Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_16G) &&\n\t     !(phba->lmt & LMT_16Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_32G) &&\n\t     !(phba->lmt & LMT_32Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_64G) &&\n\t     !(phba->lmt & LMT_64Gb))) {\n\t\t \n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1302 Invalid speed for this board:%d \"\n\t\t\t\t\"Reset link speed to auto.\\n\",\n\t\t\t\tphba->cfg_link_speed);\n\t\t\tphba->cfg_link_speed = LPFC_USER_LINK_SPEED_AUTO;\n\t}\n\tlpfc_init_link(phba, pmb, fc_topology, phba->cfg_link_speed);\n\tpmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\tif (phba->sli_rev < LPFC_SLI_REV4)\n\t\tlpfc_set_loopback_flag(phba);\n\trc = lpfc_sli_issue_mbox(phba, pmb, flag);\n\tif ((rc != MBX_BUSY) && (rc != MBX_SUCCESS)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0498 Adapter failed to init, mbxCmd x%x \"\n\t\t\t\t\"INIT_LINK, mbxStatus x%x\\n\",\n\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\tif (phba->sli_rev <= LPFC_SLI_REV3) {\n\t\t\t \n\t\t\twritel(0, phba->HCregaddr);\n\t\t\treadl(phba->HCregaddr);  \n\t\t\t \n\t\t\twritel(0xffffffff, phba->HAregaddr);\n\t\t\treadl(phba->HAregaddr);  \n\t\t}\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tif (rc != MBX_BUSY || flag == MBX_POLL)\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\tphba->cfg_suppress_link_up = LPFC_INITIALIZE_LINK;\n\tif (flag == MBX_POLL)\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\n\treturn 0;\n}\n\n \nstatic int\nlpfc_hba_down_link(struct lpfc_hba *phba, uint32_t flag)\n{\n\tLPFC_MBOXQ_t *pmb;\n\tint rc;\n\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0491 Adapter Link is disabled.\\n\");\n\tlpfc_down_link(phba, pmb);\n\tpmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\trc = lpfc_sli_issue_mbox(phba, pmb, flag);\n\tif ((rc != MBX_SUCCESS) && (rc != MBX_BUSY)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2522 Adapter failed to issue DOWN_LINK\"\n\t\t\t\t\" mbox command rc 0x%x\\n\", rc);\n\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\tif (flag == MBX_POLL)\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\n\treturn 0;\n}\n\n \nint\nlpfc_hba_down_prep(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport **vports;\n\tint i;\n\n\tif (phba->sli_rev <= LPFC_SLI_REV3) {\n\t\t \n\t\twritel(0, phba->HCregaddr);\n\t\treadl(phba->HCregaddr);  \n\t}\n\n\tif (phba->pport->load_flag & FC_UNLOADING)\n\t\tlpfc_cleanup_discovery_resources(phba->pport);\n\telse {\n\t\tvports = lpfc_create_vport_work_array(phba);\n\t\tif (vports != NULL)\n\t\t\tfor (i = 0; i <= phba->max_vports &&\n\t\t\t\tvports[i] != NULL; i++)\n\t\t\t\tlpfc_cleanup_discovery_resources(vports[i]);\n\t\tlpfc_destroy_vport_work_array(phba, vports);\n\t}\n\treturn 0;\n}\n\n \nstatic void\nlpfc_sli4_free_sp_events(struct lpfc_hba *phba)\n{\n\tstruct lpfc_iocbq *rspiocbq;\n\tstruct hbq_dmabuf *dmabuf;\n\tstruct lpfc_cq_event *cq_event;\n\n\tspin_lock_irq(&phba->hbalock);\n\tphba->hba_flag &= ~HBA_SP_QUEUE_EVT;\n\tspin_unlock_irq(&phba->hbalock);\n\n\twhile (!list_empty(&phba->sli4_hba.sp_queue_event)) {\n\t\t \n\t\tspin_lock_irq(&phba->hbalock);\n\t\tlist_remove_head(&phba->sli4_hba.sp_queue_event,\n\t\t\t\t cq_event, struct lpfc_cq_event, list);\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\tswitch (bf_get(lpfc_wcqe_c_code, &cq_event->cqe.wcqe_cmpl)) {\n\t\tcase CQE_CODE_COMPL_WQE:\n\t\t\trspiocbq = container_of(cq_event, struct lpfc_iocbq,\n\t\t\t\t\t\t cq_event);\n\t\t\tlpfc_sli_release_iocbq(phba, rspiocbq);\n\t\t\tbreak;\n\t\tcase CQE_CODE_RECEIVE:\n\t\tcase CQE_CODE_RECEIVE_V1:\n\t\t\tdmabuf = container_of(cq_event, struct hbq_dmabuf,\n\t\t\t\t\t      cq_event);\n\t\t\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n\t\t}\n\t}\n}\n\n \nstatic void\nlpfc_hba_free_post_buf(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_sli_ring *pring;\n\tstruct lpfc_dmabuf *mp, *next_mp;\n\tLIST_HEAD(buflist);\n\tint count;\n\n\tif (phba->sli3_options & LPFC_SLI3_HBQ_ENABLED)\n\t\tlpfc_sli_hbqbuf_free_all(phba);\n\telse {\n\t\t \n\t\tpring = &psli->sli3_ring[LPFC_ELS_RING];\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tlist_splice_init(&pring->postbufq, &buflist);\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\tcount = 0;\n\t\tlist_for_each_entry_safe(mp, next_mp, &buflist, list) {\n\t\t\tlist_del(&mp->list);\n\t\t\tcount++;\n\t\t\tlpfc_mbuf_free(phba, mp->virt, mp->phys);\n\t\t\tkfree(mp);\n\t\t}\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tpring->postbufq_cnt -= count;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n}\n\n \nstatic void\nlpfc_hba_clean_txcmplq(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_queue *qp = NULL;\n\tstruct lpfc_sli_ring *pring;\n\tLIST_HEAD(completions);\n\tint i;\n\tstruct lpfc_iocbq *piocb, *next_iocb;\n\n\tif (phba->sli_rev != LPFC_SLI_REV4) {\n\t\tfor (i = 0; i < psli->num_rings; i++) {\n\t\t\tpring = &psli->sli3_ring[i];\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\t \n\t\t\tlist_splice_init(&pring->txcmplq, &completions);\n\t\t\tpring->txcmplq_cnt = 0;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t\tlpfc_sli_abort_iocb_ring(phba, pring);\n\t\t}\n\t\t \n\t\tlpfc_sli_cancel_iocbs(phba, &completions,\n\t\t\t\t      IOSTAT_LOCAL_REJECT, IOERR_SLI_ABORTED);\n\t\treturn;\n\t}\n\tlist_for_each_entry(qp, &phba->sli4_hba.lpfc_wq_list, wq_list) {\n\t\tpring = qp->pring;\n\t\tif (!pring)\n\t\t\tcontinue;\n\t\tspin_lock_irq(&pring->ring_lock);\n\t\tlist_for_each_entry_safe(piocb, next_iocb,\n\t\t\t\t\t &pring->txcmplq, list)\n\t\t\tpiocb->cmd_flag &= ~LPFC_IO_ON_TXCMPLQ;\n\t\tlist_splice_init(&pring->txcmplq, &completions);\n\t\tpring->txcmplq_cnt = 0;\n\t\tspin_unlock_irq(&pring->ring_lock);\n\t\tlpfc_sli_abort_iocb_ring(phba, pring);\n\t}\n\t \n\tlpfc_sli_cancel_iocbs(phba, &completions,\n\t\t\t      IOSTAT_LOCAL_REJECT, IOERR_SLI_ABORTED);\n}\n\n \nstatic int\nlpfc_hba_down_post_s3(struct lpfc_hba *phba)\n{\n\tlpfc_hba_free_post_buf(phba);\n\tlpfc_hba_clean_txcmplq(phba);\n\treturn 0;\n}\n\n \nstatic int\nlpfc_hba_down_post_s4(struct lpfc_hba *phba)\n{\n\tstruct lpfc_io_buf *psb, *psb_next;\n\tstruct lpfc_async_xchg_ctx *ctxp, *ctxp_next;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tLIST_HEAD(aborts);\n\tLIST_HEAD(nvme_aborts);\n\tLIST_HEAD(nvmet_aborts);\n\tstruct lpfc_sglq *sglq_entry = NULL;\n\tint cnt, idx;\n\n\n\tlpfc_sli_hbqbuf_free_all(phba);\n\tlpfc_hba_clean_txcmplq(phba);\n\n\t \n\n\t \n\tspin_lock_irq(&phba->sli4_hba.sgl_list_lock);\n\tlist_for_each_entry(sglq_entry,\n\t\t&phba->sli4_hba.lpfc_abts_els_sgl_list, list)\n\t\tsglq_entry->state = SGL_FREED;\n\n\tlist_splice_init(&phba->sli4_hba.lpfc_abts_els_sgl_list,\n\t\t\t&phba->sli4_hba.lpfc_els_sgl_list);\n\n\n\tspin_unlock_irq(&phba->sli4_hba.sgl_list_lock);\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tcnt = 0;\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tqp = &phba->sli4_hba.hdwq[idx];\n\n\t\tspin_lock(&qp->abts_io_buf_list_lock);\n\t\tlist_splice_init(&qp->lpfc_abts_io_buf_list,\n\t\t\t\t &aborts);\n\n\t\tlist_for_each_entry_safe(psb, psb_next, &aborts, list) {\n\t\t\tpsb->pCmd = NULL;\n\t\t\tpsb->status = IOSTAT_SUCCESS;\n\t\t\tcnt++;\n\t\t}\n\t\tspin_lock(&qp->io_buf_list_put_lock);\n\t\tlist_splice_init(&aborts, &qp->lpfc_io_buf_list_put);\n\t\tqp->put_io_bufs += qp->abts_scsi_io_bufs;\n\t\tqp->put_io_bufs += qp->abts_nvme_io_bufs;\n\t\tqp->abts_scsi_io_bufs = 0;\n\t\tqp->abts_nvme_io_bufs = 0;\n\t\tspin_unlock(&qp->io_buf_list_put_lock);\n\t\tspin_unlock(&qp->abts_io_buf_list_lock);\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tspin_lock_irq(&phba->sli4_hba.abts_nvmet_buf_list_lock);\n\t\tlist_splice_init(&phba->sli4_hba.lpfc_abts_nvmet_ctx_list,\n\t\t\t\t &nvmet_aborts);\n\t\tspin_unlock_irq(&phba->sli4_hba.abts_nvmet_buf_list_lock);\n\t\tlist_for_each_entry_safe(ctxp, ctxp_next, &nvmet_aborts, list) {\n\t\t\tctxp->flag &= ~(LPFC_NVME_XBUSY | LPFC_NVME_ABORT_OP);\n\t\t\tlpfc_nvmet_ctxbuf_post(phba, ctxp->ctxbuf);\n\t\t}\n\t}\n\n\tlpfc_sli4_free_sp_events(phba);\n\treturn cnt;\n}\n\n \nint\nlpfc_hba_down_post(struct lpfc_hba *phba)\n{\n\treturn (*phba->lpfc_hba_down_post)(phba);\n}\n\n \nstatic void\nlpfc_hb_timeout(struct timer_list *t)\n{\n\tstruct lpfc_hba *phba;\n\tuint32_t tmo_posted;\n\tunsigned long iflag;\n\n\tphba = from_timer(phba, t, hb_tmofunc);\n\n\t \n\tspin_lock_irqsave(&phba->pport->work_port_lock, iflag);\n\ttmo_posted = phba->pport->work_port_events & WORKER_HB_TMO;\n\tif (!tmo_posted)\n\t\tphba->pport->work_port_events |= WORKER_HB_TMO;\n\tspin_unlock_irqrestore(&phba->pport->work_port_lock, iflag);\n\n\t \n\tif (!tmo_posted)\n\t\tlpfc_worker_wake_up(phba);\n\treturn;\n}\n\n \nstatic void\nlpfc_rrq_timeout(struct timer_list *t)\n{\n\tstruct lpfc_hba *phba;\n\tunsigned long iflag;\n\n\tphba = from_timer(phba, t, rrq_tmr);\n\tspin_lock_irqsave(&phba->pport->work_port_lock, iflag);\n\tif (!(phba->pport->load_flag & FC_UNLOADING))\n\t\tphba->hba_flag |= HBA_RRQ_ACTIVE;\n\telse\n\t\tphba->hba_flag &= ~HBA_RRQ_ACTIVE;\n\tspin_unlock_irqrestore(&phba->pport->work_port_lock, iflag);\n\n\tif (!(phba->pport->load_flag & FC_UNLOADING))\n\t\tlpfc_worker_wake_up(phba);\n}\n\n \nstatic void\nlpfc_hb_mbox_cmpl(struct lpfc_hba * phba, LPFC_MBOXQ_t * pmboxq)\n{\n\tunsigned long drvr_flag;\n\n\tspin_lock_irqsave(&phba->hbalock, drvr_flag);\n\tphba->hba_flag &= ~(HBA_HBEAT_INP | HBA_HBEAT_TMO);\n\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\n\t \n\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\tif (!(phba->pport->fc_flag & FC_OFFLINE_MODE) &&\n\t\t!(phba->link_state == LPFC_HBA_ERROR) &&\n\t\t!(phba->pport->load_flag & FC_UNLOADING))\n\t\tmod_timer(&phba->hb_tmofunc,\n\t\t\t  jiffies +\n\t\t\t  msecs_to_jiffies(1000 * LPFC_HB_MBOX_INTERVAL));\n\treturn;\n}\n\n \nstatic void\nlpfc_idle_stat_delay_work(struct work_struct *work)\n{\n\tstruct lpfc_hba *phba = container_of(to_delayed_work(work),\n\t\t\t\t\t     struct lpfc_hba,\n\t\t\t\t\t     idle_stat_delay_work);\n\tstruct lpfc_queue *eq;\n\tstruct lpfc_sli4_hdw_queue *hdwq;\n\tstruct lpfc_idle_stat *idle_stat;\n\tu32 i, idle_percent;\n\tu64 wall, wall_idle, diff_wall, diff_idle, busy_time;\n\n\tif (phba->pport->load_flag & FC_UNLOADING)\n\t\treturn;\n\n\tif (phba->link_state == LPFC_HBA_ERROR ||\n\t    phba->pport->fc_flag & FC_OFFLINE_MODE ||\n\t    phba->cmf_active_mode != LPFC_CFG_OFF)\n\t\tgoto requeue;\n\n\tfor_each_present_cpu(i) {\n\t\thdwq = &phba->sli4_hba.hdwq[phba->sli4_hba.cpu_map[i].hdwq];\n\t\teq = hdwq->hba_eq;\n\n\t\t \n\t\tif (eq->chann != i)\n\t\t\tcontinue;\n\n\t\tidle_stat = &phba->sli4_hba.idle_stat[i];\n\n\t\t \n\t\twall_idle = get_cpu_idle_time(i, &wall, 1);\n\t\tdiff_idle = wall_idle - idle_stat->prev_idle;\n\t\tdiff_wall = wall - idle_stat->prev_wall;\n\n\t\tif (diff_wall <= diff_idle)\n\t\t\tbusy_time = 0;\n\t\telse\n\t\t\tbusy_time = diff_wall - diff_idle;\n\n\t\tidle_percent = div64_u64(100 * busy_time, diff_wall);\n\t\tidle_percent = 100 - idle_percent;\n\n\t\tif (idle_percent < 15)\n\t\t\teq->poll_mode = LPFC_QUEUE_WORK;\n\t\telse\n\t\t\teq->poll_mode = LPFC_THREADED_IRQ;\n\n\t\tidle_stat->prev_idle = wall_idle;\n\t\tidle_stat->prev_wall = wall;\n\t}\n\nrequeue:\n\tschedule_delayed_work(&phba->idle_stat_delay_work,\n\t\t\t      msecs_to_jiffies(LPFC_IDLE_STAT_DELAY));\n}\n\nstatic void\nlpfc_hb_eq_delay_work(struct work_struct *work)\n{\n\tstruct lpfc_hba *phba = container_of(to_delayed_work(work),\n\t\t\t\t\t     struct lpfc_hba, eq_delay_work);\n\tstruct lpfc_eq_intr_info *eqi, *eqi_new;\n\tstruct lpfc_queue *eq, *eq_next;\n\tunsigned char *ena_delay = NULL;\n\tuint32_t usdelay;\n\tint i;\n\n\tif (!phba->cfg_auto_imax || phba->pport->load_flag & FC_UNLOADING)\n\t\treturn;\n\n\tif (phba->link_state == LPFC_HBA_ERROR ||\n\t    phba->pport->fc_flag & FC_OFFLINE_MODE)\n\t\tgoto requeue;\n\n\tena_delay = kcalloc(phba->sli4_hba.num_possible_cpu, sizeof(*ena_delay),\n\t\t\t    GFP_KERNEL);\n\tif (!ena_delay)\n\t\tgoto requeue;\n\n\tfor (i = 0; i < phba->cfg_irq_chann; i++) {\n\t\t \n\t\teq = phba->sli4_hba.hba_eq_hdl[i].eq;\n\t\tif (!eq)\n\t\t\tcontinue;\n\t\tif (eq->q_mode || eq->q_flag & HBA_EQ_DELAY_CHK) {\n\t\t\teq->q_flag &= ~HBA_EQ_DELAY_CHK;\n\t\t\tena_delay[eq->last_cpu] = 1;\n\t\t}\n\t}\n\n\tfor_each_present_cpu(i) {\n\t\teqi = per_cpu_ptr(phba->sli4_hba.eq_info, i);\n\t\tif (ena_delay[i]) {\n\t\t\tusdelay = (eqi->icnt >> 10) * LPFC_EQ_DELAY_STEP;\n\t\t\tif (usdelay > LPFC_MAX_AUTO_EQ_DELAY)\n\t\t\t\tusdelay = LPFC_MAX_AUTO_EQ_DELAY;\n\t\t} else {\n\t\t\tusdelay = 0;\n\t\t}\n\n\t\teqi->icnt = 0;\n\n\t\tlist_for_each_entry_safe(eq, eq_next, &eqi->list, cpu_list) {\n\t\t\tif (unlikely(eq->last_cpu != i)) {\n\t\t\t\teqi_new = per_cpu_ptr(phba->sli4_hba.eq_info,\n\t\t\t\t\t\t      eq->last_cpu);\n\t\t\t\tlist_move_tail(&eq->cpu_list, &eqi_new->list);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (usdelay != eq->q_mode)\n\t\t\t\tlpfc_modify_hba_eq_delay(phba, eq->hdwq, 1,\n\t\t\t\t\t\t\t usdelay);\n\t\t}\n\t}\n\n\tkfree(ena_delay);\n\nrequeue:\n\tqueue_delayed_work(phba->wq, &phba->eq_delay_work,\n\t\t\t   msecs_to_jiffies(LPFC_EQ_DELAY_MSECS));\n}\n\n \nstatic void lpfc_hb_mxp_handler(struct lpfc_hba *phba)\n{\n\tu32 i;\n\tu32 hwq_count;\n\n\thwq_count = phba->cfg_hdw_queue;\n\tfor (i = 0; i < hwq_count; i++) {\n\t\t \n\t\tlpfc_adjust_pvt_pool_count(phba, i);\n\n\t\t \n\t\tlpfc_adjust_high_watermark(phba, i);\n\n#ifdef LPFC_MXP_STAT\n\t\t \n\t\tlpfc_snapshot_mxp(phba, i);\n#endif\n\t}\n}\n\n \nint\nlpfc_issue_hb_mbox(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *pmboxq;\n\tint retval;\n\n\t \n\tif (phba->hba_flag & HBA_HBEAT_INP)\n\t\treturn 0;\n\n\tpmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmboxq)\n\t\treturn -ENOMEM;\n\n\tlpfc_heart_beat(phba, pmboxq);\n\tpmboxq->mbox_cmpl = lpfc_hb_mbox_cmpl;\n\tpmboxq->vport = phba->pport;\n\tretval = lpfc_sli_issue_mbox(phba, pmboxq, MBX_NOWAIT);\n\n\tif (retval != MBX_BUSY && retval != MBX_SUCCESS) {\n\t\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\t\treturn -ENXIO;\n\t}\n\tphba->hba_flag |= HBA_HBEAT_INP;\n\n\treturn 0;\n}\n\n \nvoid\nlpfc_issue_hb_tmo(struct lpfc_hba *phba)\n{\n\tif (phba->cfg_enable_hba_heartbeat)\n\t\treturn;\n\tphba->hba_flag |= HBA_HBEAT_TMO;\n}\n\n \nvoid\nlpfc_hb_timeout_handler(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport **vports;\n\tstruct lpfc_dmabuf *buf_ptr;\n\tint retval = 0;\n\tint i, tmo;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tLIST_HEAD(completions);\n\n\tif (phba->cfg_xri_rebalancing) {\n\t\t \n\t\tlpfc_hb_mxp_handler(phba);\n\t}\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tlpfc_rcv_seq_check_edtov(vports[i]);\n\t\t\tlpfc_fdmi_change_check(vports[i]);\n\t\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\tif ((phba->link_state == LPFC_HBA_ERROR) ||\n\t\t(phba->pport->load_flag & FC_UNLOADING) ||\n\t\t(phba->pport->fc_flag & FC_OFFLINE_MODE))\n\t\treturn;\n\n\tif (phba->elsbuf_cnt &&\n\t\t(phba->elsbuf_cnt == phba->elsbuf_prev_cnt)) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tlist_splice_init(&phba->elsbuf, &completions);\n\t\tphba->elsbuf_cnt = 0;\n\t\tphba->elsbuf_prev_cnt = 0;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\twhile (!list_empty(&completions)) {\n\t\t\tlist_remove_head(&completions, buf_ptr,\n\t\t\t\tstruct lpfc_dmabuf, list);\n\t\t\tlpfc_mbuf_free(phba, buf_ptr->virt, buf_ptr->phys);\n\t\t\tkfree(buf_ptr);\n\t\t}\n\t}\n\tphba->elsbuf_prev_cnt = phba->elsbuf_cnt;\n\n\t \n\tif (phba->cfg_enable_hba_heartbeat) {\n\t\t \n\t\tspin_lock_irq(&phba->pport->work_port_lock);\n\t\tif (time_after(phba->last_completion_time +\n\t\t\t\tmsecs_to_jiffies(1000 * LPFC_HB_MBOX_INTERVAL),\n\t\t\t\tjiffies)) {\n\t\t\tspin_unlock_irq(&phba->pport->work_port_lock);\n\t\t\tif (phba->hba_flag & HBA_HBEAT_INP)\n\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_TIMEOUT);\n\t\t\telse\n\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_INTERVAL);\n\t\t\tgoto out;\n\t\t}\n\t\tspin_unlock_irq(&phba->pport->work_port_lock);\n\n\t\t \n\t\tif (phba->hba_flag & HBA_HBEAT_INP) {\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0459 Adapter heartbeat still outstanding: \"\n\t\t\t\t\"last compl time was %d ms.\\n\",\n\t\t\t\tjiffies_to_msecs(jiffies\n\t\t\t\t\t - phba->last_completion_time));\n\t\t\ttmo = (1000 * LPFC_HB_MBOX_TIMEOUT);\n\t\t} else {\n\t\t\tif ((!(psli->sli_flag & LPFC_SLI_MBOX_ACTIVE)) &&\n\t\t\t\t(list_empty(&psli->mboxq))) {\n\n\t\t\t\tretval = lpfc_issue_hb_mbox(phba);\n\t\t\t\tif (retval) {\n\t\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_INTERVAL);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tphba->skipped_hb = 0;\n\t\t\t} else if (time_before_eq(phba->last_completion_time,\n\t\t\t\t\tphba->skipped_hb)) {\n\t\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"2857 Last completion time not \"\n\t\t\t\t\t\" updated in %d ms\\n\",\n\t\t\t\t\tjiffies_to_msecs(jiffies\n\t\t\t\t\t\t - phba->last_completion_time));\n\t\t\t} else\n\t\t\t\tphba->skipped_hb = jiffies;\n\n\t\t\ttmo = (1000 * LPFC_HB_MBOX_TIMEOUT);\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t \n\t\tif (phba->hba_flag & HBA_HBEAT_TMO) {\n\t\t\tretval = lpfc_issue_hb_mbox(phba);\n\t\t\tif (retval)\n\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_INTERVAL);\n\t\t\telse\n\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_TIMEOUT);\n\t\t\tgoto out;\n\t\t}\n\t\ttmo = (1000 * LPFC_HB_MBOX_INTERVAL);\n\t}\nout:\n\tmod_timer(&phba->hb_tmofunc, jiffies + msecs_to_jiffies(tmo));\n}\n\n \nstatic void\nlpfc_offline_eratt(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli   *psli = &phba->sli;\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_offline_prep(phba, LPFC_MBX_NO_WAIT);\n\n\tlpfc_offline(phba);\n\tlpfc_reset_barrier(phba);\n\tspin_lock_irq(&phba->hbalock);\n\tlpfc_sli_brdreset(phba);\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_hba_down_post(phba);\n\tlpfc_sli_brdready(phba, HS_MBRDY);\n\tlpfc_unblock_mgmt_io(phba);\n\tphba->link_state = LPFC_HBA_ERROR;\n\treturn;\n}\n\n \nvoid\nlpfc_sli4_offline_eratt(struct lpfc_hba *phba)\n{\n\tspin_lock_irq(&phba->hbalock);\n\tif (phba->link_state == LPFC_HBA_ERROR &&\n\t\ttest_bit(HBA_PCI_ERR, &phba->bit_flags)) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\tphba->link_state = LPFC_HBA_ERROR;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_offline_prep(phba, LPFC_MBX_NO_WAIT);\n\tlpfc_sli_flush_io_rings(phba);\n\tlpfc_offline(phba);\n\tlpfc_hba_down_post(phba);\n\tlpfc_unblock_mgmt_io(phba);\n}\n\n \nstatic void\nlpfc_handle_deferred_eratt(struct lpfc_hba *phba)\n{\n\tuint32_t old_host_status = phba->work_hs;\n\tstruct lpfc_sli *psli = &phba->sli;\n\n\t \n\tif (pci_channel_offline(phba->pcidev)) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->hba_flag &= ~DEFER_ERATT;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0479 Deferred Adapter Hardware Error \"\n\t\t\t\"Data: x%x x%x x%x\\n\",\n\t\t\tphba->work_hs, phba->work_status[0],\n\t\t\tphba->work_status[1]);\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\n\t \n\tlpfc_sli_abort_fcp_rings(phba);\n\n\t \n\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\tlpfc_offline(phba);\n\n\t \n\twhile (phba->work_hs & HS_FFER1) {\n\t\tmsleep(100);\n\t\tif (lpfc_readl(phba->HSregaddr, &phba->work_hs)) {\n\t\t\tphba->work_hs = UNPLUG_ERR ;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tif (phba->pport->load_flag & FC_UNLOADING) {\n\t\t\tphba->work_hs = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif ((!phba->work_hs) && (!(phba->pport->load_flag & FC_UNLOADING)))\n\t\tphba->work_hs = old_host_status & ~HS_FFER1;\n\n\tspin_lock_irq(&phba->hbalock);\n\tphba->hba_flag &= ~DEFER_ERATT;\n\tspin_unlock_irq(&phba->hbalock);\n\tphba->work_status[0] = readl(phba->MBslimaddr + 0xa8);\n\tphba->work_status[1] = readl(phba->MBslimaddr + 0xac);\n}\n\nstatic void\nlpfc_board_errevt_to_mgmt(struct lpfc_hba *phba)\n{\n\tstruct lpfc_board_event_header board_event;\n\tstruct Scsi_Host *shost;\n\n\tboard_event.event_type = FC_REG_BOARD_EVENT;\n\tboard_event.subcategory = LPFC_EVENT_PORTINTERR;\n\tshost = lpfc_shost_from_vport(phba->pport);\n\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t  sizeof(board_event),\n\t\t\t\t  (char *) &board_event,\n\t\t\t\t  LPFC_NL_VENDOR_ID);\n}\n\n \nstatic void\nlpfc_handle_eratt_s3(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct lpfc_sli   *psli = &phba->sli;\n\tuint32_t event_data;\n\tunsigned long temperature;\n\tstruct temp_event temp_event_data;\n\tstruct Scsi_Host  *shost;\n\n\t \n\tif (pci_channel_offline(phba->pcidev)) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->hba_flag &= ~DEFER_ERATT;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\n\t \n\tif (!phba->cfg_enable_hba_reset)\n\t\treturn;\n\n\t \n\tlpfc_board_errevt_to_mgmt(phba);\n\n\tif (phba->hba_flag & DEFER_ERATT)\n\t\tlpfc_handle_deferred_eratt(phba);\n\n\tif ((phba->work_hs & HS_FFER6) || (phba->work_hs & HS_FFER8)) {\n\t\tif (phba->work_hs & HS_FFER6)\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_LINK_EVENT,\n\t\t\t\t\t\"1301 Re-establishing Link \"\n\t\t\t\t\t\"Data: x%x x%x x%x\\n\",\n\t\t\t\t\tphba->work_hs, phba->work_status[0],\n\t\t\t\t\tphba->work_status[1]);\n\t\tif (phba->work_hs & HS_FFER8)\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_LINK_EVENT,\n\t\t\t\t\t\"2861 Host Authentication device \"\n\t\t\t\t\t\"zeroization Data:x%x x%x x%x\\n\",\n\t\t\t\t\tphba->work_hs, phba->work_status[0],\n\t\t\t\t\tphba->work_status[1]);\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t \n\t\tlpfc_sli_abort_fcp_rings(phba);\n\n\t\t \n\t\tlpfc_offline_prep(phba, LPFC_MBX_NO_WAIT);\n\t\tlpfc_offline(phba);\n\t\tlpfc_sli_brdrestart(phba);\n\t\tif (lpfc_online(phba) == 0) {\t \n\t\t\tlpfc_unblock_mgmt_io(phba);\n\t\t\treturn;\n\t\t}\n\t\tlpfc_unblock_mgmt_io(phba);\n\t} else if (phba->work_hs & HS_CRIT_TEMP) {\n\t\ttemperature = readl(phba->MBslimaddr + TEMPERATURE_OFFSET);\n\t\ttemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\n\t\ttemp_event_data.event_code = LPFC_CRIT_TEMP;\n\t\ttemp_event_data.data = (uint32_t)temperature;\n\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0406 Adapter maximum temperature exceeded \"\n\t\t\t\t\"(%ld), taking this port offline \"\n\t\t\t\t\"Data: x%x x%x x%x\\n\",\n\t\t\t\ttemperature, phba->work_hs,\n\t\t\t\tphba->work_status[0], phba->work_status[1]);\n\n\t\tshost = lpfc_shost_from_vport(phba->pport);\n\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t\t  sizeof(temp_event_data),\n\t\t\t\t\t  (char *) &temp_event_data,\n\t\t\t\t\t  SCSI_NL_VID_TYPE_PCI\n\t\t\t\t\t  | PCI_VENDOR_ID_EMULEX);\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->over_temp_state = HBA_OVER_TEMP;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tlpfc_offline_eratt(phba);\n\n\t} else {\n\t\t \n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0457 Adapter Hardware Error \"\n\t\t\t\t\"Data: x%x x%x x%x\\n\",\n\t\t\t\tphba->work_hs,\n\t\t\t\tphba->work_status[0], phba->work_status[1]);\n\n\t\tevent_data = FC_REG_DUMP_EVENT;\n\t\tshost = lpfc_shost_from_vport(vport);\n\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\tsizeof(event_data), (char *) &event_data,\n\t\t\t\tSCSI_NL_VID_TYPE_PCI | PCI_VENDOR_ID_EMULEX);\n\n\t\tlpfc_offline_eratt(phba);\n\t}\n\treturn;\n}\n\n \nstatic int\nlpfc_sli4_port_sta_fn_reset(struct lpfc_hba *phba, int mbx_action,\n\t\t\t    bool en_rn_msg)\n{\n\tint rc;\n\tuint32_t intr_mode;\n\tLPFC_MBOXQ_t *mboxq;\n\n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) >=\n\t    LPFC_SLI_INTF_IF_TYPE_2) {\n\t\t \n\t\trc = lpfc_sli4_pdev_status_reg_wait(phba);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t \n\tif (en_rn_msg)\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\"2887 Reset Needed: Attempting Port \"\n\t\t\t\t\"Recovery...\\n\");\n\n\t \n\tif (mbx_action == LPFC_MBX_NO_WAIT) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->sli.sli_flag &= ~LPFC_SLI_ACTIVE;\n\t\tif (phba->sli.mbox_active) {\n\t\t\tmboxq = phba->sli.mbox_active;\n\t\t\tmboxq->u.mb.mbxStatus = MBX_NOT_FINISHED;\n\t\t\t__lpfc_mbox_cmpl_put(phba, mboxq);\n\t\t\tphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\t\tphba->sli.mbox_active = NULL;\n\t\t}\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\n\tlpfc_offline_prep(phba, mbx_action);\n\tlpfc_sli_flush_io_rings(phba);\n\tlpfc_offline(phba);\n\t \n\tlpfc_sli4_disable_intr(phba);\n\trc = lpfc_sli_brdrestart(phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6309 Failed to restart board\\n\");\n\t\treturn rc;\n\t}\n\t \n\tintr_mode = lpfc_sli4_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3175 Failed to enable interrupt\\n\");\n\t\treturn -EIO;\n\t}\n\tphba->intr_mode = intr_mode;\n\trc = lpfc_online(phba);\n\tif (rc == 0)\n\t\tlpfc_unblock_mgmt_io(phba);\n\n\treturn rc;\n}\n\n \nstatic void\nlpfc_handle_eratt_s4(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tuint32_t event_data;\n\tstruct Scsi_Host *shost;\n\tuint32_t if_type;\n\tstruct lpfc_register portstat_reg = {0};\n\tuint32_t reg_err1, reg_err2;\n\tuint32_t uerrlo_reg, uemasklo_reg;\n\tuint32_t smphr_port_status = 0, pci_rd_rc1, pci_rd_rc2;\n\tbool en_rn_msg = true;\n\tstruct temp_event temp_event_data;\n\tstruct lpfc_register portsmphr_reg;\n\tint rc, i;\n\n\t \n\tif (pci_channel_offline(phba->pcidev)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3166 pci channel is offline\\n\");\n\t\tlpfc_sli_flush_io_rings(phba);\n\t\treturn;\n\t}\n\n\tmemset(&portsmphr_reg, 0, sizeof(portsmphr_reg));\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tpci_rd_rc1 = lpfc_readl(\n\t\t\t\tphba->sli4_hba.u.if_type0.UERRLOregaddr,\n\t\t\t\t&uerrlo_reg);\n\t\tpci_rd_rc2 = lpfc_readl(\n\t\t\t\tphba->sli4_hba.u.if_type0.UEMASKLOregaddr,\n\t\t\t\t&uemasklo_reg);\n\t\t \n\t\tif (pci_rd_rc1 == -EIO && pci_rd_rc2 == -EIO)\n\t\t\treturn;\n\t\tif (!(phba->hba_flag & HBA_RECOVERABLE_UE)) {\n\t\t\tlpfc_sli4_offline_eratt(phba);\n\t\t\treturn;\n\t\t}\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"7623 Checking UE recoverable\");\n\n\t\tfor (i = 0; i < phba->sli4_hba.ue_to_sr / 1000; i++) {\n\t\t\tif (lpfc_readl(phba->sli4_hba.PSMPHRregaddr,\n\t\t\t\t       &portsmphr_reg.word0))\n\t\t\t\tcontinue;\n\n\t\t\tsmphr_port_status = bf_get(lpfc_port_smphr_port_status,\n\t\t\t\t\t\t   &portsmphr_reg);\n\t\t\tif ((smphr_port_status & LPFC_PORT_SEM_MASK) ==\n\t\t\t    LPFC_PORT_SEM_UE_RECOVERABLE)\n\t\t\t\tbreak;\n\t\t\t \n\t\t\tmsleep(1000);\n\t\t}\n\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"4827 smphr_port_status x%x : Waited %dSec\",\n\t\t\t\tsmphr_port_status, i);\n\n\t\t \n\t\tif ((smphr_port_status & LPFC_PORT_SEM_MASK) ==\n\t\t    LPFC_PORT_SEM_UE_RECOVERABLE) {\n\t\t\tfor (i = 0; i < 20; i++) {\n\t\t\t\tmsleep(1000);\n\t\t\t\tif (!lpfc_readl(phba->sli4_hba.PSMPHRregaddr,\n\t\t\t\t    &portsmphr_reg.word0) &&\n\t\t\t\t    (LPFC_POST_STAGE_PORT_READY ==\n\t\t\t\t     bf_get(lpfc_port_smphr_port_status,\n\t\t\t\t     &portsmphr_reg))) {\n\t\t\t\t\trc = lpfc_sli4_port_sta_fn_reset(phba,\n\t\t\t\t\t\tLPFC_MBX_NO_WAIT, en_rn_msg);\n\t\t\t\t\tif (rc == 0)\n\t\t\t\t\t\treturn;\n\t\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"4215 Failed to recover UE\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"7624 Firmware not ready: Failing UE recovery,\"\n\t\t\t\t\" waited %dSec\", i);\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tbreak;\n\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tpci_rd_rc1 = lpfc_readl(\n\t\t\t\tphba->sli4_hba.u.if_type2.STATUSregaddr,\n\t\t\t\t&portstat_reg.word0);\n\t\t \n\t\tif (pci_rd_rc1 == -EIO) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3151 PCI bus read access failure: x%x\\n\",\n\t\t\t\treadl(phba->sli4_hba.u.if_type2.STATUSregaddr));\n\t\t\tlpfc_sli4_offline_eratt(phba);\n\t\t\treturn;\n\t\t}\n\t\treg_err1 = readl(phba->sli4_hba.u.if_type2.ERR1regaddr);\n\t\treg_err2 = readl(phba->sli4_hba.u.if_type2.ERR2regaddr);\n\t\tif (bf_get(lpfc_sliport_status_oti, &portstat_reg)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2889 Port Overtemperature event, \"\n\t\t\t\t\t\"taking port offline Data: x%x x%x\\n\",\n\t\t\t\t\treg_err1, reg_err2);\n\n\t\t\tphba->sfp_alarm |= LPFC_TRANSGRESSION_HIGH_TEMPERATURE;\n\t\t\ttemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\n\t\t\ttemp_event_data.event_code = LPFC_CRIT_TEMP;\n\t\t\ttemp_event_data.data = 0xFFFFFFFF;\n\n\t\t\tshost = lpfc_shost_from_vport(phba->pport);\n\t\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t\t\t  sizeof(temp_event_data),\n\t\t\t\t\t\t  (char *)&temp_event_data,\n\t\t\t\t\t\t  SCSI_NL_VID_TYPE_PCI\n\t\t\t\t\t\t  | PCI_VENDOR_ID_EMULEX);\n\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tphba->over_temp_state = HBA_OVER_TEMP;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tlpfc_sli4_offline_eratt(phba);\n\t\t\treturn;\n\t\t}\n\t\tif (reg_err1 == SLIPORT_ERR1_REG_ERR_CODE_2 &&\n\t\t    reg_err2 == SLIPORT_ERR2_REG_FW_RESTART) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\t\"3143 Port Down: Firmware Update \"\n\t\t\t\t\t\"Detected\\n\");\n\t\t\ten_rn_msg = false;\n\t\t} else if (reg_err1 == SLIPORT_ERR1_REG_ERR_CODE_2 &&\n\t\t\t reg_err2 == SLIPORT_ERR2_REG_FORCED_DUMP)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\t\"3144 Port Down: Debug Dump\\n\");\n\t\telse if (reg_err1 == SLIPORT_ERR1_REG_ERR_CODE_2 &&\n\t\t\t reg_err2 == SLIPORT_ERR2_REG_FUNC_PROVISON)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3145 Port Down: Provisioning\\n\");\n\n\t\t \n\t\tif (!phba->cfg_enable_hba_reset)\n\t\t\treturn;\n\n\t\t \n\t\trc = lpfc_sli4_port_sta_fn_reset(phba, LPFC_MBX_NO_WAIT,\n\t\t\t\ten_rn_msg);\n\t\tif (rc == 0) {\n\t\t\t \n\t\t\tif (reg_err1 == SLIPORT_ERR1_REG_ERR_CODE_2 &&\n\t\t\t    reg_err2 == SLIPORT_ERR2_REG_FORCED_DUMP)\n\t\t\t\treturn;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\t\t \n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3152 Unrecoverable error\\n\");\n\t\tlpfc_sli4_offline_eratt(phba);\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tbreak;\n\t}\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\"3123 Report dump event to upper layer\\n\");\n\t \n\tlpfc_board_errevt_to_mgmt(phba);\n\n\tevent_data = FC_REG_DUMP_EVENT;\n\tshost = lpfc_shost_from_vport(vport);\n\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t  sizeof(event_data), (char *) &event_data,\n\t\t\t\t  SCSI_NL_VID_TYPE_PCI | PCI_VENDOR_ID_EMULEX);\n}\n\n \nvoid\nlpfc_handle_eratt(struct lpfc_hba *phba)\n{\n\t(*phba->lpfc_handle_eratt)(phba);\n}\n\n \nvoid\nlpfc_handle_latt(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct lpfc_sli   *psli = &phba->sli;\n\tLPFC_MBOXQ_t *pmb;\n\tvolatile uint32_t control;\n\tint rc = 0;\n\n\tpmb = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\trc = 1;\n\t\tgoto lpfc_handle_latt_err_exit;\n\t}\n\n\trc = lpfc_mbox_rsrc_prep(phba, pmb);\n\tif (rc) {\n\t\trc = 2;\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\tgoto lpfc_handle_latt_err_exit;\n\t}\n\n\t \n\tlpfc_els_flush_all_cmd(phba);\n\tpsli->slistat.link_event++;\n\tlpfc_read_topology(phba, pmb, (struct lpfc_dmabuf *)pmb->ctx_buf);\n\tpmb->mbox_cmpl = lpfc_mbx_cmpl_read_topology;\n\tpmb->vport = vport;\n\t \n\tphba->sli.sli3_ring[LPFC_ELS_RING].flag |= LPFC_STOP_IOCB_EVENT;\n\trc = lpfc_sli_issue_mbox (phba, pmb, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED) {\n\t\trc = 4;\n\t\tgoto lpfc_handle_latt_free_mbuf;\n\t}\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\twritel(HA_LATT, phba->HAregaddr);\n\treadl(phba->HAregaddr);  \n\tspin_unlock_irq(&phba->hbalock);\n\n\treturn;\n\nlpfc_handle_latt_free_mbuf:\n\tphba->sli.sli3_ring[LPFC_ELS_RING].flag &= ~LPFC_STOP_IOCB_EVENT;\n\tlpfc_mbox_rsrc_cleanup(phba, pmb, MBOX_THD_UNLOCKED);\nlpfc_handle_latt_err_exit:\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag |= LPFC_PROCESS_LA;\n\tcontrol = readl(phba->HCregaddr);\n\tcontrol |= HC_LAINT_ENA;\n\twritel(control, phba->HCregaddr);\n\treadl(phba->HCregaddr);  \n\n\t \n\twritel(HA_LATT, phba->HAregaddr);\n\treadl(phba->HAregaddr);  \n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_linkdown(phba);\n\tphba->link_state = LPFC_HBA_ERROR;\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0300 LATT: Cannot issue READ_LA: Data:%d\\n\", rc);\n\n\treturn;\n}\n\nstatic void\nlpfc_fill_vpd(struct lpfc_hba *phba, uint8_t *vpd, int length, int *pindex)\n{\n\tint i, j;\n\n\twhile (length > 0) {\n\t\t \n\t\tif ((vpd[*pindex] == 'S') && (vpd[*pindex + 1] == 'N')) {\n\t\t\t*pindex += 2;\n\t\t\ti = vpd[*pindex];\n\t\t\t*pindex += 1;\n\t\t\tj = 0;\n\t\t\tlength -= (3+i);\n\t\t\twhile (i--) {\n\t\t\t\tphba->SerialNumber[j++] = vpd[(*pindex)++];\n\t\t\t\tif (j == 31)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tphba->SerialNumber[j] = 0;\n\t\t\tcontinue;\n\t\t} else if ((vpd[*pindex] == 'V') && (vpd[*pindex + 1] == '1')) {\n\t\t\tphba->vpd_flag |= VPD_MODEL_DESC;\n\t\t\t*pindex += 2;\n\t\t\ti = vpd[*pindex];\n\t\t\t*pindex += 1;\n\t\t\tj = 0;\n\t\t\tlength -= (3+i);\n\t\t\twhile (i--) {\n\t\t\t\tphba->ModelDesc[j++] = vpd[(*pindex)++];\n\t\t\t\tif (j == 255)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tphba->ModelDesc[j] = 0;\n\t\t\tcontinue;\n\t\t} else if ((vpd[*pindex] == 'V') && (vpd[*pindex + 1] == '2')) {\n\t\t\tphba->vpd_flag |= VPD_MODEL_NAME;\n\t\t\t*pindex += 2;\n\t\t\ti = vpd[*pindex];\n\t\t\t*pindex += 1;\n\t\t\tj = 0;\n\t\t\tlength -= (3+i);\n\t\t\twhile (i--) {\n\t\t\t\tphba->ModelName[j++] = vpd[(*pindex)++];\n\t\t\t\tif (j == 79)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tphba->ModelName[j] = 0;\n\t\t\tcontinue;\n\t\t} else if ((vpd[*pindex] == 'V') && (vpd[*pindex + 1] == '3')) {\n\t\t\tphba->vpd_flag |= VPD_PROGRAM_TYPE;\n\t\t\t*pindex += 2;\n\t\t\ti = vpd[*pindex];\n\t\t\t*pindex += 1;\n\t\t\tj = 0;\n\t\t\tlength -= (3+i);\n\t\t\twhile (i--) {\n\t\t\t\tphba->ProgramType[j++] = vpd[(*pindex)++];\n\t\t\t\tif (j == 255)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tphba->ProgramType[j] = 0;\n\t\t\tcontinue;\n\t\t} else if ((vpd[*pindex] == 'V') && (vpd[*pindex + 1] == '4')) {\n\t\t\tphba->vpd_flag |= VPD_PORT;\n\t\t\t*pindex += 2;\n\t\t\ti = vpd[*pindex];\n\t\t\t*pindex += 1;\n\t\t\tj = 0;\n\t\t\tlength -= (3 + i);\n\t\t\twhile (i--) {\n\t\t\t\tif ((phba->sli_rev == LPFC_SLI_REV4) &&\n\t\t\t\t    (phba->sli4_hba.pport_name_sta ==\n\t\t\t\t     LPFC_SLI4_PPNAME_GET)) {\n\t\t\t\t\tj++;\n\t\t\t\t\t(*pindex)++;\n\t\t\t\t} else\n\t\t\t\t\tphba->Port[j++] = vpd[(*pindex)++];\n\t\t\t\tif (j == 19)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ((phba->sli_rev != LPFC_SLI_REV4) ||\n\t\t\t    (phba->sli4_hba.pport_name_sta ==\n\t\t\t     LPFC_SLI4_PPNAME_NON))\n\t\t\t\tphba->Port[j] = 0;\n\t\t\tcontinue;\n\t\t} else {\n\t\t\t*pindex += 2;\n\t\t\ti = vpd[*pindex];\n\t\t\t*pindex += 1;\n\t\t\t*pindex += i;\n\t\t\tlength -= (3 + i);\n\t\t}\n\t}\n}\n\n \nint\nlpfc_parse_vpd(struct lpfc_hba *phba, uint8_t *vpd, int len)\n{\n\tuint8_t lenlo, lenhi;\n\tint Length;\n\tint i;\n\tint finished = 0;\n\tint index = 0;\n\n\tif (!vpd)\n\t\treturn 0;\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0455 Vital Product Data: x%x x%x x%x x%x\\n\",\n\t\t\t(uint32_t) vpd[0], (uint32_t) vpd[1], (uint32_t) vpd[2],\n\t\t\t(uint32_t) vpd[3]);\n\twhile (!finished && (index < (len - 4))) {\n\t\tswitch (vpd[index]) {\n\t\tcase 0x82:\n\t\tcase 0x91:\n\t\t\tindex += 1;\n\t\t\tlenlo = vpd[index];\n\t\t\tindex += 1;\n\t\t\tlenhi = vpd[index];\n\t\t\tindex += 1;\n\t\t\ti = ((((unsigned short)lenhi) << 8) + lenlo);\n\t\t\tindex += i;\n\t\t\tbreak;\n\t\tcase 0x90:\n\t\t\tindex += 1;\n\t\t\tlenlo = vpd[index];\n\t\t\tindex += 1;\n\t\t\tlenhi = vpd[index];\n\t\t\tindex += 1;\n\t\t\tLength = ((((unsigned short)lenhi) << 8) + lenlo);\n\t\t\tif (Length > len - index)\n\t\t\t\tLength = len - index;\n\n\t\t\tlpfc_fill_vpd(phba, vpd, Length, &index);\n\t\t\tfinished = 0;\n\t\t\tbreak;\n\t\tcase 0x78:\n\t\t\tfinished = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tindex ++;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn(1);\n}\n\n \nstatic void\nlpfc_get_atto_model_desc(struct lpfc_hba *phba, uint8_t *mdp, uint8_t *descp)\n{\n\tuint16_t sub_dev_id = phba->pcidev->subsystem_device;\n\tchar *model = \"<Unknown>\";\n\tint tbolt = 0;\n\n\tswitch (sub_dev_id) {\n\tcase PCI_DEVICE_ID_CLRY_161E:\n\t\tmodel = \"161E\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_162E:\n\t\tmodel = \"162E\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_164E:\n\t\tmodel = \"164E\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_161P:\n\t\tmodel = \"161P\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_162P:\n\t\tmodel = \"162P\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_164P:\n\t\tmodel = \"164P\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_321E:\n\t\tmodel = \"321E\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_322E:\n\t\tmodel = \"322E\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_324E:\n\t\tmodel = \"324E\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_321P:\n\t\tmodel = \"321P\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_322P:\n\t\tmodel = \"322P\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CLRY_324P:\n\t\tmodel = \"324P\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_TLFC_2XX2:\n\t\tmodel = \"2XX2\";\n\t\ttbolt = 1;\n\t\tbreak;\n\tcase PCI_DEVICE_ID_TLFC_3162:\n\t\tmodel = \"3162\";\n\t\ttbolt = 1;\n\t\tbreak;\n\tcase PCI_DEVICE_ID_TLFC_3322:\n\t\tmodel = \"3322\";\n\t\ttbolt = 1;\n\t\tbreak;\n\tdefault:\n\t\tmodel = \"Unknown\";\n\t\tbreak;\n\t}\n\n\tif (mdp && mdp[0] == '\\0')\n\t\tsnprintf(mdp, 79, \"%s\", model);\n\n\tif (descp && descp[0] == '\\0')\n\t\tsnprintf(descp, 255,\n\t\t\t \"ATTO %s%s, Fibre Channel Adapter Initiator, Port %s\",\n\t\t\t (tbolt) ? \"ThunderLink FC \" : \"Celerity FC-\",\n\t\t\t model,\n\t\t\t phba->Port);\n}\n\n \nstatic void\nlpfc_get_hba_model_desc(struct lpfc_hba *phba, uint8_t *mdp, uint8_t *descp)\n{\n\tlpfc_vpd_t *vp;\n\tuint16_t dev_id = phba->pcidev->device;\n\tint max_speed;\n\tint GE = 0;\n\tint oneConnect = 0;  \n\tstruct {\n\t\tchar *name;\n\t\tchar *bus;\n\t\tchar *function;\n\t} m = {\"<Unknown>\", \"\", \"\"};\n\n\tif (mdp && mdp[0] != '\\0'\n\t\t&& descp && descp[0] != '\\0')\n\t\treturn;\n\n\tif (phba->pcidev->vendor == PCI_VENDOR_ID_ATTO) {\n\t\tlpfc_get_atto_model_desc(phba, mdp, descp);\n\t\treturn;\n\t}\n\n\tif (phba->lmt & LMT_64Gb)\n\t\tmax_speed = 64;\n\telse if (phba->lmt & LMT_32Gb)\n\t\tmax_speed = 32;\n\telse if (phba->lmt & LMT_16Gb)\n\t\tmax_speed = 16;\n\telse if (phba->lmt & LMT_10Gb)\n\t\tmax_speed = 10;\n\telse if (phba->lmt & LMT_8Gb)\n\t\tmax_speed = 8;\n\telse if (phba->lmt & LMT_4Gb)\n\t\tmax_speed = 4;\n\telse if (phba->lmt & LMT_2Gb)\n\t\tmax_speed = 2;\n\telse if (phba->lmt & LMT_1Gb)\n\t\tmax_speed = 1;\n\telse\n\t\tmax_speed = 0;\n\n\tvp = &phba->vpd;\n\n\tswitch (dev_id) {\n\tcase PCI_DEVICE_ID_FIREFLY:\n\t\tm = (typeof(m)){\"LP6000\", \"PCI\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SUPERFLY:\n\t\tif (vp->rev.biuRev >= 1 && vp->rev.biuRev <= 3)\n\t\t\tm = (typeof(m)){\"LP7000\", \"PCI\", \"\"};\n\t\telse\n\t\t\tm = (typeof(m)){\"LP7000E\", \"PCI\", \"\"};\n\t\tm.function = \"Obsolete, Unsupported Fibre Channel Adapter\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_DRAGONFLY:\n\t\tm = (typeof(m)){\"LP8000\", \"PCI\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CENTAUR:\n\t\tif (FC_JEDEC_ID(vp->rev.biuRev) == CENTAUR_2G_JEDEC_ID)\n\t\t\tm = (typeof(m)){\"LP9002\", \"PCI\", \"\"};\n\t\telse\n\t\t\tm = (typeof(m)){\"LP9000\", \"PCI\", \"\"};\n\t\tm.function = \"Obsolete, Unsupported Fibre Channel Adapter\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_RFLY:\n\t\tm = (typeof(m)){\"LP952\", \"PCI\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PEGASUS:\n\t\tm = (typeof(m)){\"LP9802\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_THOR:\n\t\tm = (typeof(m)){\"LP10000\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_VIPER:\n\t\tm = (typeof(m)){\"LPX1000\",  \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PFLY:\n\t\tm = (typeof(m)){\"LP982\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_TFLY:\n\t\tm = (typeof(m)){\"LP1050\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_HELIOS:\n\t\tm = (typeof(m)){\"LP11000\", \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_HELIOS_SCSP:\n\t\tm = (typeof(m)){\"LP11000-SP\", \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_HELIOS_DCSP:\n\t\tm = (typeof(m)){\"LP11002-SP\",  \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_NEPTUNE:\n\t\tm = (typeof(m)){\"LPe1000\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_NEPTUNE_SCSP:\n\t\tm = (typeof(m)){\"LPe1000-SP\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_NEPTUNE_DCSP:\n\t\tm = (typeof(m)){\"LPe1002-SP\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_BMID:\n\t\tm = (typeof(m)){\"LP1150\", \"PCI-X2\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_BSMB:\n\t\tm = (typeof(m)){\"LP111\", \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZEPHYR:\n\t\tm = (typeof(m)){\"LPe11000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZEPHYR_SCSP:\n\t\tm = (typeof(m)){\"LPe11000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZEPHYR_DCSP:\n\t\tm = (typeof(m)){\"LP2105\", \"PCIe\", \"FCoE Adapter\"};\n\t\tGE = 1;\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZMID:\n\t\tm = (typeof(m)){\"LPe1150\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZSMB:\n\t\tm = (typeof(m)){\"LPe111\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LP101:\n\t\tm = (typeof(m)){\"LP101\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LP10000S:\n\t\tm = (typeof(m)){\"LP10000-S\", \"PCI\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LP11000S:\n\t\tm = (typeof(m)){\"LP11000-S\", \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LPE11000S:\n\t\tm = (typeof(m)){\"LPe11000-S\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT:\n\t\tm = (typeof(m)){\"LPe12000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_MID:\n\t\tm = (typeof(m)){\"LPe1250\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_SMB:\n\t\tm = (typeof(m)){\"LPe121\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_DCSP:\n\t\tm = (typeof(m)){\"LPe12002-SP\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_SCSP:\n\t\tm = (typeof(m)){\"LPe12000-SP\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_S:\n\t\tm = (typeof(m)){\"LPe12000-S\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PROTEUS_VF:\n\t\tm = (typeof(m)){\"LPev12000\", \"PCIe IOV\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PROTEUS_PF:\n\t\tm = (typeof(m)){\"LPev12000\", \"PCIe IOV\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PROTEUS_S:\n\t\tm = (typeof(m)){\"LPemv12002-S\", \"PCIe IOV\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_TIGERSHARK:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe10100\", \"PCIe\", \"FCoE\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_TOMCAT:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe11100\", \"PCIe\", \"FCoE\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_FALCON:\n\t\tm = (typeof(m)){\"LPSe12002-ML1-E\", \"PCIe\",\n\t\t\t\t\"EmulexSecure Fibre\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_BALIUS:\n\t\tm = (typeof(m)){\"LPVe12002\", \"PCIe Shared I/O\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_FC:\n\t\tm = (typeof(m)){\"LPe16000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_FC_VF:\n\t\tm = (typeof(m)){\"LPe16000\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_FCOE:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe15100\", \"PCIe\", \"FCoE\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_FCOE_VF:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe15100\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported FCoE\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_G6_FC:\n\t\tm = (typeof(m)){\"LPe32000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_G7_FC:\n\t\tm = (typeof(m)){\"LPe36000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_G7P_FC:\n\t\tm = (typeof(m)){\"LPe38000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SKYHAWK:\n\tcase PCI_DEVICE_ID_SKYHAWK_VF:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe14000\", \"PCIe\", \"FCoE\"};\n\t\tbreak;\n\tdefault:\n\t\tm = (typeof(m)){\"Unknown\", \"\", \"\"};\n\t\tbreak;\n\t}\n\n\tif (mdp && mdp[0] == '\\0')\n\t\tsnprintf(mdp, 79,\"%s\", m.name);\n\t \n\tif (descp && descp[0] == '\\0') {\n\t\tif (oneConnect)\n\t\t\tsnprintf(descp, 255,\n\t\t\t\t\"Emulex OneConnect %s, %s Initiator %s\",\n\t\t\t\tm.name, m.function,\n\t\t\t\tphba->Port);\n\t\telse if (max_speed == 0)\n\t\t\tsnprintf(descp, 255,\n\t\t\t\t\"Emulex %s %s %s\",\n\t\t\t\tm.name, m.bus, m.function);\n\t\telse\n\t\t\tsnprintf(descp, 255,\n\t\t\t\t\"Emulex %s %d%s %s %s\",\n\t\t\t\tm.name, max_speed, (GE) ? \"GE\" : \"Gb\",\n\t\t\t\tm.bus, m.function);\n\t}\n}\n\n \nint\nlpfc_sli3_post_buffer(struct lpfc_hba *phba, struct lpfc_sli_ring *pring, int cnt)\n{\n\tIOCB_t *icmd;\n\tstruct lpfc_iocbq *iocb;\n\tstruct lpfc_dmabuf *mp1, *mp2;\n\n\tcnt += pring->missbufcnt;\n\n\t \n\twhile (cnt > 0) {\n\t\t \n\t\tiocb = lpfc_sli_get_iocbq(phba);\n\t\tif (iocb == NULL) {\n\t\t\tpring->missbufcnt = cnt;\n\t\t\treturn cnt;\n\t\t}\n\t\ticmd = &iocb->iocb;\n\n\t\t \n\t\t \n\t\tmp1 = kmalloc(sizeof (struct lpfc_dmabuf), GFP_KERNEL);\n\t\tif (mp1)\n\t\t    mp1->virt = lpfc_mbuf_alloc(phba, MEM_PRI, &mp1->phys);\n\t\tif (!mp1 || !mp1->virt) {\n\t\t\tkfree(mp1);\n\t\t\tlpfc_sli_release_iocbq(phba, iocb);\n\t\t\tpring->missbufcnt = cnt;\n\t\t\treturn cnt;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&mp1->list);\n\t\t \n\t\tif (cnt > 1) {\n\t\t\tmp2 = kmalloc(sizeof (struct lpfc_dmabuf), GFP_KERNEL);\n\t\t\tif (mp2)\n\t\t\t\tmp2->virt = lpfc_mbuf_alloc(phba, MEM_PRI,\n\t\t\t\t\t\t\t    &mp2->phys);\n\t\t\tif (!mp2 || !mp2->virt) {\n\t\t\t\tkfree(mp2);\n\t\t\t\tlpfc_mbuf_free(phba, mp1->virt, mp1->phys);\n\t\t\t\tkfree(mp1);\n\t\t\t\tlpfc_sli_release_iocbq(phba, iocb);\n\t\t\t\tpring->missbufcnt = cnt;\n\t\t\t\treturn cnt;\n\t\t\t}\n\n\t\t\tINIT_LIST_HEAD(&mp2->list);\n\t\t} else {\n\t\t\tmp2 = NULL;\n\t\t}\n\n\t\ticmd->un.cont64[0].addrHigh = putPaddrHigh(mp1->phys);\n\t\ticmd->un.cont64[0].addrLow = putPaddrLow(mp1->phys);\n\t\ticmd->un.cont64[0].tus.f.bdeSize = FCELSSIZE;\n\t\ticmd->ulpBdeCount = 1;\n\t\tcnt--;\n\t\tif (mp2) {\n\t\t\ticmd->un.cont64[1].addrHigh = putPaddrHigh(mp2->phys);\n\t\t\ticmd->un.cont64[1].addrLow = putPaddrLow(mp2->phys);\n\t\t\ticmd->un.cont64[1].tus.f.bdeSize = FCELSSIZE;\n\t\t\tcnt--;\n\t\t\ticmd->ulpBdeCount = 2;\n\t\t}\n\n\t\ticmd->ulpCommand = CMD_QUE_RING_BUF64_CN;\n\t\ticmd->ulpLe = 1;\n\n\t\tif (lpfc_sli_issue_iocb(phba, pring->ringno, iocb, 0) ==\n\t\t    IOCB_ERROR) {\n\t\t\tlpfc_mbuf_free(phba, mp1->virt, mp1->phys);\n\t\t\tkfree(mp1);\n\t\t\tcnt++;\n\t\t\tif (mp2) {\n\t\t\t\tlpfc_mbuf_free(phba, mp2->virt, mp2->phys);\n\t\t\t\tkfree(mp2);\n\t\t\t\tcnt++;\n\t\t\t}\n\t\t\tlpfc_sli_release_iocbq(phba, iocb);\n\t\t\tpring->missbufcnt = cnt;\n\t\t\treturn cnt;\n\t\t}\n\t\tlpfc_sli_ringpostbuf_put(phba, pring, mp1);\n\t\tif (mp2)\n\t\t\tlpfc_sli_ringpostbuf_put(phba, pring, mp2);\n\t}\n\tpring->missbufcnt = 0;\n\treturn 0;\n}\n\n \nstatic int\nlpfc_post_rcv_buf(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\n\t \n\tlpfc_sli3_post_buffer(phba, &psli->sli3_ring[LPFC_ELS_RING], LPFC_BUF_RING0);\n\t \n\n\treturn 0;\n}\n\n#define S(N,V) (((V)<<(N))|((V)>>(32-(N))))\n\n \nstatic void\nlpfc_sha_init(uint32_t * HashResultPointer)\n{\n\tHashResultPointer[0] = 0x67452301;\n\tHashResultPointer[1] = 0xEFCDAB89;\n\tHashResultPointer[2] = 0x98BADCFE;\n\tHashResultPointer[3] = 0x10325476;\n\tHashResultPointer[4] = 0xC3D2E1F0;\n}\n\n \nstatic void\nlpfc_sha_iterate(uint32_t * HashResultPointer, uint32_t * HashWorkingPointer)\n{\n\tint t;\n\tuint32_t TEMP;\n\tuint32_t A, B, C, D, E;\n\tt = 16;\n\tdo {\n\t\tHashWorkingPointer[t] =\n\t\t    S(1,\n\t\t      HashWorkingPointer[t - 3] ^ HashWorkingPointer[t -\n\t\t\t\t\t\t\t\t     8] ^\n\t\t      HashWorkingPointer[t - 14] ^ HashWorkingPointer[t - 16]);\n\t} while (++t <= 79);\n\tt = 0;\n\tA = HashResultPointer[0];\n\tB = HashResultPointer[1];\n\tC = HashResultPointer[2];\n\tD = HashResultPointer[3];\n\tE = HashResultPointer[4];\n\n\tdo {\n\t\tif (t < 20) {\n\t\t\tTEMP = ((B & C) | ((~B) & D)) + 0x5A827999;\n\t\t} else if (t < 40) {\n\t\t\tTEMP = (B ^ C ^ D) + 0x6ED9EBA1;\n\t\t} else if (t < 60) {\n\t\t\tTEMP = ((B & C) | (B & D) | (C & D)) + 0x8F1BBCDC;\n\t\t} else {\n\t\t\tTEMP = (B ^ C ^ D) + 0xCA62C1D6;\n\t\t}\n\t\tTEMP += S(5, A) + E + HashWorkingPointer[t];\n\t\tE = D;\n\t\tD = C;\n\t\tC = S(30, B);\n\t\tB = A;\n\t\tA = TEMP;\n\t} while (++t <= 79);\n\n\tHashResultPointer[0] += A;\n\tHashResultPointer[1] += B;\n\tHashResultPointer[2] += C;\n\tHashResultPointer[3] += D;\n\tHashResultPointer[4] += E;\n\n}\n\n \nstatic void\nlpfc_challenge_key(uint32_t * RandomChallenge, uint32_t * HashWorking)\n{\n\t*HashWorking = (*RandomChallenge ^ *HashWorking);\n}\n\n \nvoid\nlpfc_hba_init(struct lpfc_hba *phba, uint32_t *hbainit)\n{\n\tint t;\n\tuint32_t *HashWorking;\n\tuint32_t *pwwnn = (uint32_t *) phba->wwnn;\n\n\tHashWorking = kcalloc(80, sizeof(uint32_t), GFP_KERNEL);\n\tif (!HashWorking)\n\t\treturn;\n\n\tHashWorking[0] = HashWorking[78] = *pwwnn++;\n\tHashWorking[1] = HashWorking[79] = *pwwnn;\n\n\tfor (t = 0; t < 7; t++)\n\t\tlpfc_challenge_key(phba->RandomData + t, HashWorking + t);\n\n\tlpfc_sha_init(hbainit);\n\tlpfc_sha_iterate(hbainit, HashWorking);\n\tkfree(HashWorking);\n}\n\n \nvoid\nlpfc_cleanup(struct lpfc_vport *vport)\n{\n\tstruct lpfc_hba   *phba = vport->phba;\n\tstruct lpfc_nodelist *ndlp, *next_ndlp;\n\tint i = 0;\n\n\tif (phba->link_state > LPFC_LINK_DOWN)\n\t\tlpfc_port_link_failure(vport);\n\n\t \n\tif (lpfc_is_vmid_enabled(phba))\n\t\tlpfc_vmid_vport_cleanup(vport);\n\n\tlist_for_each_entry_safe(ndlp, next_ndlp, &vport->fc_nodes, nlp_listp) {\n\t\tif (vport->port_type != LPFC_PHYSICAL_PORT &&\n\t\t    ndlp->nlp_DID == Fabric_DID) {\n\t\t\t \n\t\t\tlpfc_nlp_put(ndlp);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (ndlp->nlp_DID == Fabric_Cntl_DID &&\n\t\t    ndlp->nlp_state == NLP_STE_UNUSED_NODE) {\n\t\t\tlpfc_nlp_put(ndlp);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (ndlp->nlp_type & NLP_FABRIC &&\n\t\t    ndlp->nlp_state == NLP_STE_UNMAPPED_NODE)\n\t\t\tlpfc_disc_state_machine(vport, ndlp, NULL,\n\t\t\t\t\tNLP_EVT_DEVICE_RECOVERY);\n\n\t\tif (!(ndlp->fc4_xpt_flags & (NVME_XPT_REGD|SCSI_XPT_REGD)))\n\t\t\tlpfc_disc_state_machine(vport, ndlp, NULL,\n\t\t\t\t\tNLP_EVT_DEVICE_RM);\n\t}\n\n\t \n\tif (vport->load_flag & FC_UNLOADING &&\n\t    pci_channel_offline(phba->pcidev))\n\t\tlpfc_sli_flush_io_rings(vport->phba);\n\n\t \n\twhile (!list_empty(&vport->fc_nodes)) {\n\t\tif (i++ > 3000) {\n\t\t\tlpfc_printf_vlog(vport, KERN_ERR,\n\t\t\t\t\t LOG_TRACE_EVENT,\n\t\t\t\t\"0233 Nodelist not empty\\n\");\n\t\t\tlist_for_each_entry_safe(ndlp, next_ndlp,\n\t\t\t\t\t\t&vport->fc_nodes, nlp_listp) {\n\t\t\t\tlpfc_printf_vlog(ndlp->vport, KERN_ERR,\n\t\t\t\t\t\t LOG_DISCOVERY,\n\t\t\t\t\t\t \"0282 did:x%x ndlp:x%px \"\n\t\t\t\t\t\t \"refcnt:%d xflags x%x nflag x%x\\n\",\n\t\t\t\t\t\t ndlp->nlp_DID, (void *)ndlp,\n\t\t\t\t\t\t kref_read(&ndlp->kref),\n\t\t\t\t\t\t ndlp->fc4_xpt_flags,\n\t\t\t\t\t\t ndlp->nlp_flag);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tmsleep(10);\n\t}\n\tlpfc_cleanup_vports_rrqs(vport, NULL);\n}\n\n \nvoid\nlpfc_stop_vport_timers(struct lpfc_vport *vport)\n{\n\tdel_timer_sync(&vport->els_tmofunc);\n\tdel_timer_sync(&vport->delayed_disc_tmo);\n\tlpfc_can_disctmo(vport);\n\treturn;\n}\n\n \nvoid\n__lpfc_sli4_stop_fcf_redisc_wait_timer(struct lpfc_hba *phba)\n{\n\t \n\tphba->fcf.fcf_flag &= ~FCF_REDISC_PEND;\n\n\t \n\tdel_timer(&phba->fcf.redisc_wait);\n}\n\n \nvoid\nlpfc_sli4_stop_fcf_redisc_wait_timer(struct lpfc_hba *phba)\n{\n\tspin_lock_irq(&phba->hbalock);\n\tif (!(phba->fcf.fcf_flag & FCF_REDISC_PEND)) {\n\t\t \n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\t__lpfc_sli4_stop_fcf_redisc_wait_timer(phba);\n\t \n\tphba->fcf.fcf_flag &= ~(FCF_DEAD_DISC | FCF_ACVL_DISC);\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n \nvoid\nlpfc_cmf_stop(struct lpfc_hba *phba)\n{\n\tint cpu;\n\tstruct lpfc_cgn_stat *cgs;\n\n\t \n\tif (!phba->sli4_hba.pc_sli4_params.cmf)\n\t\treturn;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\"6221 Stop CMF / Cancel Timer\\n\");\n\n\t \n\thrtimer_cancel(&phba->cmf_stats_timer);\n\thrtimer_cancel(&phba->cmf_timer);\n\n\t \n\tatomic_set(&phba->cmf_busy, 0);\n\tfor_each_present_cpu(cpu) {\n\t\tcgs = per_cpu_ptr(phba->cmf_stat, cpu);\n\t\tatomic64_set(&cgs->total_bytes, 0);\n\t\tatomic64_set(&cgs->rcv_bytes, 0);\n\t\tatomic_set(&cgs->rx_io_cnt, 0);\n\t\tatomic64_set(&cgs->rx_latency, 0);\n\t}\n\tatomic_set(&phba->cmf_bw_wait, 0);\n\n\t \n\tqueue_work(phba->wq, &phba->unblock_request_work);\n}\n\nstatic inline uint64_t\nlpfc_get_max_line_rate(struct lpfc_hba *phba)\n{\n\tuint64_t rate = lpfc_sli_port_speed_get(phba);\n\n\treturn ((((unsigned long)rate) * 1024 * 1024) / 10);\n}\n\nvoid\nlpfc_cmf_signal_init(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\"6223 Signal CMF init\\n\");\n\n\t \n\tphba->cmf_interval_rate = LPFC_CMF_INTERVAL;\n\tphba->cmf_max_line_rate = lpfc_get_max_line_rate(phba);\n\tphba->cmf_link_byte_count = div_u64(phba->cmf_max_line_rate *\n\t\t\t\t\t    phba->cmf_interval_rate, 1000);\n\tphba->cmf_max_bytes_per_interval = phba->cmf_link_byte_count;\n\n\t \n\tlpfc_issue_cmf_sync_wqe(phba, 0, 0);\n}\n\n \nvoid\nlpfc_cmf_start(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cgn_stat *cgs;\n\tint cpu;\n\n\t \n\tif (!phba->sli4_hba.pc_sli4_params.cmf ||\n\t    phba->cmf_active_mode == LPFC_CFG_OFF)\n\t\treturn;\n\n\t \n\tlpfc_init_congestion_buf(phba);\n\n\tatomic_set(&phba->cgn_fabric_warn_cnt, 0);\n\tatomic_set(&phba->cgn_fabric_alarm_cnt, 0);\n\tatomic_set(&phba->cgn_sync_alarm_cnt, 0);\n\tatomic_set(&phba->cgn_sync_warn_cnt, 0);\n\n\tatomic_set(&phba->cmf_busy, 0);\n\tfor_each_present_cpu(cpu) {\n\t\tcgs = per_cpu_ptr(phba->cmf_stat, cpu);\n\t\tatomic64_set(&cgs->total_bytes, 0);\n\t\tatomic64_set(&cgs->rcv_bytes, 0);\n\t\tatomic_set(&cgs->rx_io_cnt, 0);\n\t\tatomic64_set(&cgs->rx_latency, 0);\n\t}\n\tphba->cmf_latency.tv_sec = 0;\n\tphba->cmf_latency.tv_nsec = 0;\n\n\tlpfc_cmf_signal_init(phba);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\"6222 Start CMF / Timer\\n\");\n\n\tphba->cmf_timer_cnt = 0;\n\thrtimer_start(&phba->cmf_timer,\n\t\t      ktime_set(0, LPFC_CMF_INTERVAL * NSEC_PER_MSEC),\n\t\t      HRTIMER_MODE_REL);\n\thrtimer_start(&phba->cmf_stats_timer,\n\t\t      ktime_set(0, LPFC_SEC_MIN * NSEC_PER_SEC),\n\t\t      HRTIMER_MODE_REL);\n\t \n\tktime_get_real_ts64(&phba->cmf_latency);\n\n\tatomic_set(&phba->cmf_bw_wait, 0);\n\tatomic_set(&phba->cmf_stop_io, 0);\n}\n\n \nvoid\nlpfc_stop_hba_timers(struct lpfc_hba *phba)\n{\n\tif (phba->pport)\n\t\tlpfc_stop_vport_timers(phba->pport);\n\tcancel_delayed_work_sync(&phba->eq_delay_work);\n\tcancel_delayed_work_sync(&phba->idle_stat_delay_work);\n\tdel_timer_sync(&phba->sli.mbox_tmo);\n\tdel_timer_sync(&phba->fabric_block_timer);\n\tdel_timer_sync(&phba->eratt_poll);\n\tdel_timer_sync(&phba->hb_tmofunc);\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tdel_timer_sync(&phba->rrq_tmr);\n\t\tphba->hba_flag &= ~HBA_RRQ_ACTIVE;\n\t}\n\tphba->hba_flag &= ~(HBA_HBEAT_INP | HBA_HBEAT_TMO);\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\t \n\t\tdel_timer_sync(&phba->fcp_poll_timer);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\t \n\t\tlpfc_sli4_stop_fcf_redisc_wait_timer(phba);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0297 Invalid device group (x%x)\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn;\n}\n\n \nstatic void\nlpfc_block_mgmt_io(struct lpfc_hba *phba, int mbx_action)\n{\n\tunsigned long iflag;\n\tuint8_t actcmd = MBX_HEARTBEAT;\n\tunsigned long timeout;\n\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tphba->sli.sli_flag |= LPFC_BLOCK_MGMT_IO;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\tif (mbx_action == LPFC_MBX_NO_WAIT)\n\t\treturn;\n\ttimeout = msecs_to_jiffies(LPFC_MBOX_TMO * 1000) + jiffies;\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tif (phba->sli.mbox_active) {\n\t\tactcmd = phba->sli.mbox_active->u.mb.mbxCommand;\n\t\t \n\t\ttimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba,\n\t\t\t\tphba->sli.mbox_active) * 1000) + jiffies;\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\n\t \n\twhile (phba->sli.mbox_active) {\n\t\t \n\t\tmsleep(2);\n\t\tif (time_after(jiffies, timeout)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2813 Mgmt IO is Blocked %x \"\n\t\t\t\t\t\"- mbox cmd %x still active\\n\",\n\t\t\t\t\tphba->sli.sli_flag, actcmd);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nvoid\nlpfc_sli4_node_prep(struct lpfc_hba *phba)\n{\n\tstruct lpfc_nodelist  *ndlp, *next_ndlp;\n\tstruct lpfc_vport **vports;\n\tint i, rpi;\n\n\tif (phba->sli_rev != LPFC_SLI_REV4)\n\t\treturn;\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports == NULL)\n\t\treturn;\n\n\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\tif (vports[i]->load_flag & FC_UNLOADING)\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(ndlp, next_ndlp,\n\t\t\t\t\t &vports[i]->fc_nodes,\n\t\t\t\t\t nlp_listp) {\n\t\t\trpi = lpfc_sli4_alloc_rpi(phba);\n\t\t\tif (rpi == LPFC_RPI_ALLOC_ERROR) {\n\t\t\t\t \n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tndlp->nlp_rpi = rpi;\n\t\t\tlpfc_printf_vlog(ndlp->vport, KERN_INFO,\n\t\t\t\t\t LOG_NODE | LOG_DISCOVERY,\n\t\t\t\t\t \"0009 Assign RPI x%x to ndlp x%px \"\n\t\t\t\t\t \"DID:x%06x flg:x%x\\n\",\n\t\t\t\t\t ndlp->nlp_rpi, ndlp, ndlp->nlp_DID,\n\t\t\t\t\t ndlp->nlp_flag);\n\t\t}\n\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n}\n\n \nstatic void lpfc_create_expedite_pool(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tstruct lpfc_epd_pool *epd_pool;\n\tunsigned long iflag;\n\n\tepd_pool = &phba->epd_pool;\n\tqp = &phba->sli4_hba.hdwq[0];\n\n\tspin_lock_init(&epd_pool->lock);\n\tspin_lock_irqsave(&qp->io_buf_list_put_lock, iflag);\n\tspin_lock(&epd_pool->lock);\n\tINIT_LIST_HEAD(&epd_pool->list);\n\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t &qp->lpfc_io_buf_list_put, list) {\n\t\tlist_move_tail(&lpfc_ncmd->list, &epd_pool->list);\n\t\tlpfc_ncmd->expedite = true;\n\t\tqp->put_io_bufs--;\n\t\tepd_pool->count++;\n\t\tif (epd_pool->count >= XRI_BATCH)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&epd_pool->lock);\n\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock, iflag);\n}\n\n \nstatic void lpfc_destroy_expedite_pool(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tstruct lpfc_epd_pool *epd_pool;\n\tunsigned long iflag;\n\n\tepd_pool = &phba->epd_pool;\n\tqp = &phba->sli4_hba.hdwq[0];\n\n\tspin_lock_irqsave(&qp->io_buf_list_put_lock, iflag);\n\tspin_lock(&epd_pool->lock);\n\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t &epd_pool->list, list) {\n\t\tlist_move_tail(&lpfc_ncmd->list,\n\t\t\t       &qp->lpfc_io_buf_list_put);\n\t\tlpfc_ncmd->flags = false;\n\t\tqp->put_io_bufs++;\n\t\tepd_pool->count--;\n\t}\n\tspin_unlock(&epd_pool->lock);\n\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock, iflag);\n}\n\n \nvoid lpfc_create_multixri_pools(struct lpfc_hba *phba)\n{\n\tu32 i, j;\n\tu32 hwq_count;\n\tu32 count_per_hwq;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tunsigned long iflag;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tstruct lpfc_pbl_pool *pbl_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"1234 num_hdw_queue=%d num_present_cpu=%d common_xri_cnt=%d\\n\",\n\t\t\tphba->cfg_hdw_queue, phba->sli4_hba.num_present_cpu,\n\t\t\tphba->sli4_hba.io_xri_cnt);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\tlpfc_create_expedite_pool(phba);\n\n\thwq_count = phba->cfg_hdw_queue;\n\tcount_per_hwq = phba->sli4_hba.io_xri_cnt / hwq_count;\n\n\tfor (i = 0; i < hwq_count; i++) {\n\t\tmultixri_pool = kzalloc(sizeof(*multixri_pool), GFP_KERNEL);\n\n\t\tif (!multixri_pool) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"1238 Failed to allocate memory for \"\n\t\t\t\t\t\"multixri_pool\\n\");\n\n\t\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\t\t\tlpfc_destroy_expedite_pool(phba);\n\n\t\t\tj = 0;\n\t\t\twhile (j < i) {\n\t\t\t\tqp = &phba->sli4_hba.hdwq[j];\n\t\t\t\tkfree(qp->p_multixri_pool);\n\t\t\t\tj++;\n\t\t\t}\n\t\t\tphba->cfg_xri_rebalancing = 0;\n\t\t\treturn;\n\t\t}\n\n\t\tqp = &phba->sli4_hba.hdwq[i];\n\t\tqp->p_multixri_pool = multixri_pool;\n\n\t\tmultixri_pool->xri_limit = count_per_hwq;\n\t\tmultixri_pool->rrb_next_hwqid = i;\n\n\t\t \n\t\tpbl_pool = &multixri_pool->pbl_pool;\n\t\tspin_lock_init(&pbl_pool->lock);\n\t\tspin_lock_irqsave(&qp->io_buf_list_put_lock, iflag);\n\t\tspin_lock(&pbl_pool->lock);\n\t\tINIT_LIST_HEAD(&pbl_pool->list);\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &qp->lpfc_io_buf_list_put, list) {\n\t\t\tlist_move_tail(&lpfc_ncmd->list, &pbl_pool->list);\n\t\t\tqp->put_io_bufs--;\n\t\t\tpbl_pool->count++;\n\t\t}\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"1235 Moved %d buffers from PUT list over to pbl_pool[%d]\\n\",\n\t\t\t\tpbl_pool->count, i);\n\t\tspin_unlock(&pbl_pool->lock);\n\t\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock, iflag);\n\n\t\t \n\t\tpvt_pool = &multixri_pool->pvt_pool;\n\t\tpvt_pool->high_watermark = multixri_pool->xri_limit / 2;\n\t\tpvt_pool->low_watermark = XRI_BATCH;\n\t\tspin_lock_init(&pvt_pool->lock);\n\t\tspin_lock_irqsave(&pvt_pool->lock, iflag);\n\t\tINIT_LIST_HEAD(&pvt_pool->list);\n\t\tpvt_pool->count = 0;\n\t\tspin_unlock_irqrestore(&pvt_pool->lock, iflag);\n\t}\n}\n\n \nstatic void lpfc_destroy_multixri_pools(struct lpfc_hba *phba)\n{\n\tu32 i;\n\tu32 hwq_count;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tunsigned long iflag;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tstruct lpfc_pbl_pool *pbl_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\tlpfc_destroy_expedite_pool(phba);\n\n\tif (!(phba->pport->load_flag & FC_UNLOADING))\n\t\tlpfc_sli_flush_io_rings(phba);\n\n\thwq_count = phba->cfg_hdw_queue;\n\n\tfor (i = 0; i < hwq_count; i++) {\n\t\tqp = &phba->sli4_hba.hdwq[i];\n\t\tmultixri_pool = qp->p_multixri_pool;\n\t\tif (!multixri_pool)\n\t\t\tcontinue;\n\n\t\tqp->p_multixri_pool = NULL;\n\n\t\tspin_lock_irqsave(&qp->io_buf_list_put_lock, iflag);\n\n\t\t \n\t\tpbl_pool = &multixri_pool->pbl_pool;\n\t\tspin_lock(&pbl_pool->lock);\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"1236 Moving %d buffers from pbl_pool[%d] TO PUT list\\n\",\n\t\t\t\tpbl_pool->count, i);\n\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &pbl_pool->list, list) {\n\t\t\tlist_move_tail(&lpfc_ncmd->list,\n\t\t\t\t       &qp->lpfc_io_buf_list_put);\n\t\t\tqp->put_io_bufs++;\n\t\t\tpbl_pool->count--;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&pbl_pool->list);\n\t\tpbl_pool->count = 0;\n\n\t\tspin_unlock(&pbl_pool->lock);\n\n\t\t \n\t\tpvt_pool = &multixri_pool->pvt_pool;\n\t\tspin_lock(&pvt_pool->lock);\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"1237 Moving %d buffers from pvt_pool[%d] TO PUT list\\n\",\n\t\t\t\tpvt_pool->count, i);\n\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &pvt_pool->list, list) {\n\t\t\tlist_move_tail(&lpfc_ncmd->list,\n\t\t\t\t       &qp->lpfc_io_buf_list_put);\n\t\t\tqp->put_io_bufs++;\n\t\t\tpvt_pool->count--;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&pvt_pool->list);\n\t\tpvt_pool->count = 0;\n\n\t\tspin_unlock(&pvt_pool->lock);\n\t\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock, iflag);\n\n\t\tkfree(multixri_pool);\n\t}\n}\n\n \nint\nlpfc_online(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport;\n\tstruct lpfc_vport **vports;\n\tint i, error = 0;\n\tbool vpis_cleared = false;\n\n\tif (!phba)\n\t\treturn 0;\n\tvport = phba->pport;\n\n\tif (!(vport->fc_flag & FC_OFFLINE_MODE))\n\t\treturn 0;\n\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\"0458 Bring Adapter online\\n\");\n\n\tlpfc_block_mgmt_io(phba, LPFC_MBX_WAIT);\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tif (lpfc_sli4_hba_setup(phba)) {  \n\t\t\tlpfc_unblock_mgmt_io(phba);\n\t\t\treturn 1;\n\t\t}\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tif (!phba->sli4_hba.max_cfg_param.vpi_used)\n\t\t\tvpis_cleared = true;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t \n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME &&\n\t\t\t\t!phba->nvmet_support) {\n\t\t\terror = lpfc_nvme_create_localport(phba->pport);\n\t\t\tif (error)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6132 NVME restore reg failed \"\n\t\t\t\t\t\"on nvmei error x%x\\n\", error);\n\t\t}\n\t} else {\n\t\tlpfc_sli_queue_init(phba);\n\t\tif (lpfc_sli_hba_setup(phba)) {\t \n\t\t\tlpfc_unblock_mgmt_io(phba);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL) {\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tstruct Scsi_Host *shost;\n\t\t\tshost = lpfc_shost_from_vport(vports[i]);\n\t\t\tspin_lock_irq(shost->host_lock);\n\t\t\tvports[i]->fc_flag &= ~FC_OFFLINE_MODE;\n\t\t\tif (phba->sli3_options & LPFC_SLI3_NPIV_ENABLED)\n\t\t\t\tvports[i]->fc_flag |= FC_VPORT_NEEDS_REG_VPI;\n\t\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\t\tvports[i]->fc_flag |= FC_VPORT_NEEDS_INIT_VPI;\n\t\t\t\tif ((vpis_cleared) &&\n\t\t\t\t    (vports[i]->port_type !=\n\t\t\t\t\tLPFC_PHYSICAL_PORT))\n\t\t\t\t\tvports[i]->vpi = 0;\n\t\t\t}\n\t\t\tspin_unlock_irq(shost->host_lock);\n\t\t}\n\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\tif (phba->cfg_xri_rebalancing)\n\t\tlpfc_create_multixri_pools(phba);\n\n\tlpfc_cpuhp_add(phba);\n\n\tlpfc_unblock_mgmt_io(phba);\n\treturn 0;\n}\n\n \nvoid\nlpfc_unblock_mgmt_io(struct lpfc_hba * phba)\n{\n\tunsigned long iflag;\n\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tphba->sli.sli_flag &= ~LPFC_BLOCK_MGMT_IO;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n}\n\n \nvoid\nlpfc_offline_prep(struct lpfc_hba *phba, int mbx_action)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct lpfc_nodelist  *ndlp, *next_ndlp;\n\tstruct lpfc_vport **vports;\n\tstruct Scsi_Host *shost;\n\tint i;\n\tint offline;\n\tbool hba_pci_err;\n\n\tif (vport->fc_flag & FC_OFFLINE_MODE)\n\t\treturn;\n\n\tlpfc_block_mgmt_io(phba, mbx_action);\n\n\tlpfc_linkdown(phba);\n\n\toffline =  pci_channel_offline(phba->pcidev);\n\thba_pci_err = test_bit(HBA_PCI_ERR, &phba->bit_flags);\n\n\t \n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL) {\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tif (vports[i]->load_flag & FC_UNLOADING)\n\t\t\t\tcontinue;\n\t\t\tshost = lpfc_shost_from_vport(vports[i]);\n\t\t\tspin_lock_irq(shost->host_lock);\n\t\t\tvports[i]->vpi_state &= ~LPFC_VPI_REGISTERED;\n\t\t\tvports[i]->fc_flag |= FC_VPORT_NEEDS_REG_VPI;\n\t\t\tvports[i]->fc_flag &= ~FC_VFI_REGISTERED;\n\t\t\tspin_unlock_irq(shost->host_lock);\n\n\t\t\tshost =\tlpfc_shost_from_vport(vports[i]);\n\t\t\tlist_for_each_entry_safe(ndlp, next_ndlp,\n\t\t\t\t\t\t &vports[i]->fc_nodes,\n\t\t\t\t\t\t nlp_listp) {\n\n\t\t\t\tspin_lock_irq(&ndlp->lock);\n\t\t\t\tndlp->nlp_flag &= ~NLP_NPR_ADISC;\n\t\t\t\tspin_unlock_irq(&ndlp->lock);\n\n\t\t\t\tif (offline || hba_pci_err) {\n\t\t\t\t\tspin_lock_irq(&ndlp->lock);\n\t\t\t\t\tndlp->nlp_flag &= ~(NLP_UNREG_INP |\n\t\t\t\t\t\t\t    NLP_RPI_REGISTERED);\n\t\t\t\t\tspin_unlock_irq(&ndlp->lock);\n\t\t\t\t\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\t\t\t\t\tlpfc_sli_rpi_release(vports[i],\n\t\t\t\t\t\t\t\t     ndlp);\n\t\t\t\t} else {\n\t\t\t\t\tlpfc_unreg_rpi(vports[i], ndlp);\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\t\t\tlpfc_printf_vlog(vports[i], KERN_INFO,\n\t\t\t\t\t\t LOG_NODE | LOG_DISCOVERY,\n\t\t\t\t\t\t \"0011 Free RPI x%x on \"\n\t\t\t\t\t\t \"ndlp: x%px did x%x\\n\",\n\t\t\t\t\t\t ndlp->nlp_rpi, ndlp,\n\t\t\t\t\t\t ndlp->nlp_DID);\n\t\t\t\t\tlpfc_sli4_free_rpi(phba, ndlp->nlp_rpi);\n\t\t\t\t\tndlp->nlp_rpi = LPFC_RPI_ALLOC_ERROR;\n\t\t\t\t}\n\n\t\t\t\tif (ndlp->nlp_type & NLP_FABRIC) {\n\t\t\t\t\tlpfc_disc_state_machine(vports[i], ndlp,\n\t\t\t\t\t\tNULL, NLP_EVT_DEVICE_RECOVERY);\n\n\t\t\t\t\t \n\t\t\t\t\tif (!(ndlp->save_flags &\n\t\t\t\t\t      NLP_IN_RECOV_POST_DEV_LOSS) &&\n\t\t\t\t\t    !(ndlp->fc4_xpt_flags &\n\t\t\t\t\t      (NVME_XPT_REGD | SCSI_XPT_REGD)))\n\t\t\t\t\t\tlpfc_disc_state_machine\n\t\t\t\t\t\t\t(vports[i], ndlp,\n\t\t\t\t\t\t\t NULL,\n\t\t\t\t\t\t\t NLP_EVT_DEVICE_RM);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\tlpfc_sli_mbox_sys_shutdown(phba, mbx_action);\n\n\tif (phba->wq)\n\t\tflush_workqueue(phba->wq);\n}\n\n \nvoid\nlpfc_offline(struct lpfc_hba *phba)\n{\n\tstruct Scsi_Host  *shost;\n\tstruct lpfc_vport **vports;\n\tint i;\n\n\tif (phba->pport->fc_flag & FC_OFFLINE_MODE)\n\t\treturn;\n\n\t \n\tlpfc_stop_port(phba);\n\n\t \n\tlpfc_nvmet_destroy_targetport(phba);\n\tlpfc_nvme_destroy_localport(phba->pport);\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++)\n\t\t\tlpfc_stop_vport_timers(vports[i]);\n\tlpfc_destroy_vport_work_array(phba, vports);\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\"0460 Bring Adapter offline\\n\");\n\t \n\tlpfc_sli_hba_down(phba);\n\tspin_lock_irq(&phba->hbalock);\n\tphba->work_ha = 0;\n\tspin_unlock_irq(&phba->hbalock);\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tshost = lpfc_shost_from_vport(vports[i]);\n\t\t\tspin_lock_irq(shost->host_lock);\n\t\t\tvports[i]->work_port_events = 0;\n\t\t\tvports[i]->fc_flag |= FC_OFFLINE_MODE;\n\t\t\tspin_unlock_irq(shost->host_lock);\n\t\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\t \n\tif (phba->pport->fc_flag & FC_OFFLINE_MODE)\n\t\t__lpfc_cpuhp_remove(phba);\n\n\tif (phba->cfg_xri_rebalancing)\n\t\tlpfc_destroy_multixri_pools(phba);\n}\n\n \nstatic void\nlpfc_scsi_free(struct lpfc_hba *phba)\n{\n\tstruct lpfc_io_buf *sb, *sb_next;\n\n\tif (!(phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP))\n\t\treturn;\n\n\tspin_lock_irq(&phba->hbalock);\n\n\t \n\n\tspin_lock(&phba->scsi_buf_list_put_lock);\n\tlist_for_each_entry_safe(sb, sb_next, &phba->lpfc_scsi_buf_list_put,\n\t\t\t\t list) {\n\t\tlist_del(&sb->list);\n\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool, sb->data,\n\t\t\t      sb->dma_handle);\n\t\tkfree(sb);\n\t\tphba->total_scsi_bufs--;\n\t}\n\tspin_unlock(&phba->scsi_buf_list_put_lock);\n\n\tspin_lock(&phba->scsi_buf_list_get_lock);\n\tlist_for_each_entry_safe(sb, sb_next, &phba->lpfc_scsi_buf_list_get,\n\t\t\t\t list) {\n\t\tlist_del(&sb->list);\n\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool, sb->data,\n\t\t\t      sb->dma_handle);\n\t\tkfree(sb);\n\t\tphba->total_scsi_bufs--;\n\t}\n\tspin_unlock(&phba->scsi_buf_list_get_lock);\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n \nvoid\nlpfc_io_free(struct lpfc_hba *phba)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd, *lpfc_ncmd_next;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tint idx;\n\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\t \n\t\tspin_lock(&qp->io_buf_list_put_lock);\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &qp->lpfc_io_buf_list_put,\n\t\t\t\t\t list) {\n\t\t\tlist_del(&lpfc_ncmd->list);\n\t\t\tqp->put_io_bufs--;\n\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t      lpfc_ncmd->data, lpfc_ncmd->dma_handle);\n\t\t\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\t\t\tlpfc_put_sgl_per_hdwq(phba, lpfc_ncmd);\n\t\t\tlpfc_put_cmd_rsp_buf_per_hdwq(phba, lpfc_ncmd);\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tqp->total_io_bufs--;\n\t\t}\n\t\tspin_unlock(&qp->io_buf_list_put_lock);\n\n\t\tspin_lock(&qp->io_buf_list_get_lock);\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &qp->lpfc_io_buf_list_get,\n\t\t\t\t\t list) {\n\t\t\tlist_del(&lpfc_ncmd->list);\n\t\t\tqp->get_io_bufs--;\n\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t      lpfc_ncmd->data, lpfc_ncmd->dma_handle);\n\t\t\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\t\t\tlpfc_put_sgl_per_hdwq(phba, lpfc_ncmd);\n\t\t\tlpfc_put_cmd_rsp_buf_per_hdwq(phba, lpfc_ncmd);\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tqp->total_io_bufs--;\n\t\t}\n\t\tspin_unlock(&qp->io_buf_list_get_lock);\n\t}\n}\n\n \nint\nlpfc_sli4_els_sgl_update(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL, *sglq_entry_next = NULL;\n\tuint16_t i, lxri, xri_cnt, els_xri_cnt;\n\tLIST_HEAD(els_sgl_list);\n\tint rc;\n\n\t \n\tels_xri_cnt = lpfc_sli4_get_els_iocb_cnt(phba);\n\n\tif (els_xri_cnt > phba->sli4_hba.els_xri_cnt) {\n\t\t \n\t\txri_cnt = els_xri_cnt - phba->sli4_hba.els_xri_cnt;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3157 ELS xri-sgl count increased from \"\n\t\t\t\t\"%d to %d\\n\", phba->sli4_hba.els_xri_cnt,\n\t\t\t\tels_xri_cnt);\n\t\t \n\t\tfor (i = 0; i < xri_cnt; i++) {\n\t\t\tsglq_entry = kzalloc(sizeof(struct lpfc_sglq),\n\t\t\t\t\t     GFP_KERNEL);\n\t\t\tif (sglq_entry == NULL) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"2562 Failure to allocate an \"\n\t\t\t\t\t\t\"ELS sgl entry:%d\\n\", i);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out_free_mem;\n\t\t\t}\n\t\t\tsglq_entry->buff_type = GEN_BUFF_TYPE;\n\t\t\tsglq_entry->virt = lpfc_mbuf_alloc(phba, 0,\n\t\t\t\t\t\t\t   &sglq_entry->phys);\n\t\t\tif (sglq_entry->virt == NULL) {\n\t\t\t\tkfree(sglq_entry);\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"2563 Failure to allocate an \"\n\t\t\t\t\t\t\"ELS mbuf:%d\\n\", i);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out_free_mem;\n\t\t\t}\n\t\t\tsglq_entry->sgl = sglq_entry->virt;\n\t\t\tmemset(sglq_entry->sgl, 0, LPFC_BPL_SIZE);\n\t\t\tsglq_entry->state = SGL_FREED;\n\t\t\tlist_add_tail(&sglq_entry->list, &els_sgl_list);\n\t\t}\n\t\tspin_lock_irq(&phba->sli4_hba.sgl_list_lock);\n\t\tlist_splice_init(&els_sgl_list,\n\t\t\t\t &phba->sli4_hba.lpfc_els_sgl_list);\n\t\tspin_unlock_irq(&phba->sli4_hba.sgl_list_lock);\n\t} else if (els_xri_cnt < phba->sli4_hba.els_xri_cnt) {\n\t\t \n\t\txri_cnt = phba->sli4_hba.els_xri_cnt - els_xri_cnt;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3158 ELS xri-sgl count decreased from \"\n\t\t\t\t\"%d to %d\\n\", phba->sli4_hba.els_xri_cnt,\n\t\t\t\tels_xri_cnt);\n\t\tspin_lock_irq(&phba->sli4_hba.sgl_list_lock);\n\t\tlist_splice_init(&phba->sli4_hba.lpfc_els_sgl_list,\n\t\t\t\t &els_sgl_list);\n\t\t \n\t\tfor (i = 0; i < xri_cnt; i++) {\n\t\t\tlist_remove_head(&els_sgl_list,\n\t\t\t\t\t sglq_entry, struct lpfc_sglq, list);\n\t\t\tif (sglq_entry) {\n\t\t\t\t__lpfc_mbuf_free(phba, sglq_entry->virt,\n\t\t\t\t\t\t sglq_entry->phys);\n\t\t\t\tkfree(sglq_entry);\n\t\t\t}\n\t\t}\n\t\tlist_splice_init(&els_sgl_list,\n\t\t\t\t &phba->sli4_hba.lpfc_els_sgl_list);\n\t\tspin_unlock_irq(&phba->sli4_hba.sgl_list_lock);\n\t} else\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3163 ELS xri-sgl count unchanged: %d\\n\",\n\t\t\t\tels_xri_cnt);\n\tphba->sli4_hba.els_xri_cnt = els_xri_cnt;\n\n\t \n\tsglq_entry = NULL;\n\tsglq_entry_next = NULL;\n\tlist_for_each_entry_safe(sglq_entry, sglq_entry_next,\n\t\t\t\t &phba->sli4_hba.lpfc_els_sgl_list, list) {\n\t\tlxri = lpfc_sli4_next_xritag(phba);\n\t\tif (lxri == NO_XRI) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"2400 Failed to allocate xri for \"\n\t\t\t\t\t\"ELS sgl\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_free_mem;\n\t\t}\n\t\tsglq_entry->sli4_lxritag = lxri;\n\t\tsglq_entry->sli4_xritag = phba->sli4_hba.xri_ids[lxri];\n\t}\n\treturn 0;\n\nout_free_mem:\n\tlpfc_free_els_sgl_list(phba);\n\treturn rc;\n}\n\n \nint\nlpfc_sli4_nvmet_sgl_update(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL, *sglq_entry_next = NULL;\n\tuint16_t i, lxri, xri_cnt, els_xri_cnt;\n\tuint16_t nvmet_xri_cnt;\n\tLIST_HEAD(nvmet_sgl_list);\n\tint rc;\n\n\t \n\tels_xri_cnt = lpfc_sli4_get_els_iocb_cnt(phba);\n\n\t \n\tnvmet_xri_cnt = phba->sli4_hba.max_cfg_param.max_xri - els_xri_cnt;\n\tif (nvmet_xri_cnt > phba->sli4_hba.nvmet_xri_cnt) {\n\t\t \n\t\txri_cnt = nvmet_xri_cnt - phba->sli4_hba.nvmet_xri_cnt;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"6302 NVMET xri-sgl cnt grew from %d to %d\\n\",\n\t\t\t\tphba->sli4_hba.nvmet_xri_cnt, nvmet_xri_cnt);\n\t\t \n\t\tfor (i = 0; i < xri_cnt; i++) {\n\t\t\tsglq_entry = kzalloc(sizeof(struct lpfc_sglq),\n\t\t\t\t\t     GFP_KERNEL);\n\t\t\tif (sglq_entry == NULL) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6303 Failure to allocate an \"\n\t\t\t\t\t\t\"NVMET sgl entry:%d\\n\", i);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out_free_mem;\n\t\t\t}\n\t\t\tsglq_entry->buff_type = NVMET_BUFF_TYPE;\n\t\t\tsglq_entry->virt = lpfc_nvmet_buf_alloc(phba, 0,\n\t\t\t\t\t\t\t   &sglq_entry->phys);\n\t\t\tif (sglq_entry->virt == NULL) {\n\t\t\t\tkfree(sglq_entry);\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6304 Failure to allocate an \"\n\t\t\t\t\t\t\"NVMET buf:%d\\n\", i);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out_free_mem;\n\t\t\t}\n\t\t\tsglq_entry->sgl = sglq_entry->virt;\n\t\t\tmemset(sglq_entry->sgl, 0,\n\t\t\t       phba->cfg_sg_dma_buf_size);\n\t\t\tsglq_entry->state = SGL_FREED;\n\t\t\tlist_add_tail(&sglq_entry->list, &nvmet_sgl_list);\n\t\t}\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\t\tlist_splice_init(&nvmet_sgl_list,\n\t\t\t\t &phba->sli4_hba.lpfc_nvmet_sgl_list);\n\t\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\t\tspin_unlock_irq(&phba->hbalock);\n\t} else if (nvmet_xri_cnt < phba->sli4_hba.nvmet_xri_cnt) {\n\t\t \n\t\txri_cnt = phba->sli4_hba.nvmet_xri_cnt - nvmet_xri_cnt;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"6305 NVMET xri-sgl count decreased from \"\n\t\t\t\t\"%d to %d\\n\", phba->sli4_hba.nvmet_xri_cnt,\n\t\t\t\tnvmet_xri_cnt);\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\t\tlist_splice_init(&phba->sli4_hba.lpfc_nvmet_sgl_list,\n\t\t\t\t &nvmet_sgl_list);\n\t\t \n\t\tfor (i = 0; i < xri_cnt; i++) {\n\t\t\tlist_remove_head(&nvmet_sgl_list,\n\t\t\t\t\t sglq_entry, struct lpfc_sglq, list);\n\t\t\tif (sglq_entry) {\n\t\t\t\tlpfc_nvmet_buf_free(phba, sglq_entry->virt,\n\t\t\t\t\t\t    sglq_entry->phys);\n\t\t\t\tkfree(sglq_entry);\n\t\t\t}\n\t\t}\n\t\tlist_splice_init(&nvmet_sgl_list,\n\t\t\t\t &phba->sli4_hba.lpfc_nvmet_sgl_list);\n\t\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\t\tspin_unlock_irq(&phba->hbalock);\n\t} else\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"6306 NVMET xri-sgl count unchanged: %d\\n\",\n\t\t\t\tnvmet_xri_cnt);\n\tphba->sli4_hba.nvmet_xri_cnt = nvmet_xri_cnt;\n\n\t \n\tsglq_entry = NULL;\n\tsglq_entry_next = NULL;\n\tlist_for_each_entry_safe(sglq_entry, sglq_entry_next,\n\t\t\t\t &phba->sli4_hba.lpfc_nvmet_sgl_list, list) {\n\t\tlxri = lpfc_sli4_next_xritag(phba);\n\t\tif (lxri == NO_XRI) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"6307 Failed to allocate xri for \"\n\t\t\t\t\t\"NVMET sgl\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_free_mem;\n\t\t}\n\t\tsglq_entry->sli4_lxritag = lxri;\n\t\tsglq_entry->sli4_xritag = phba->sli4_hba.xri_ids[lxri];\n\t}\n\treturn 0;\n\nout_free_mem:\n\tlpfc_free_nvmet_sgl_list(phba);\n\treturn rc;\n}\n\nint\nlpfc_io_buf_flush(struct lpfc_hba *phba, struct list_head *cbuf)\n{\n\tLIST_HEAD(blist);\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_cmd;\n\tstruct lpfc_io_buf *iobufp, *prev_iobufp;\n\tint idx, cnt, xri, inserted;\n\n\tcnt = 0;\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\tspin_lock_irq(&qp->io_buf_list_get_lock);\n\t\tspin_lock(&qp->io_buf_list_put_lock);\n\n\t\t \n\t\tlist_splice_init(&qp->lpfc_io_buf_list_get, &blist);\n\t\tlist_splice(&qp->lpfc_io_buf_list_put, &blist);\n\t\tINIT_LIST_HEAD(&qp->lpfc_io_buf_list_get);\n\t\tINIT_LIST_HEAD(&qp->lpfc_io_buf_list_put);\n\t\tcnt += qp->get_io_bufs + qp->put_io_bufs;\n\t\tqp->get_io_bufs = 0;\n\t\tqp->put_io_bufs = 0;\n\t\tqp->total_io_bufs = 0;\n\t\tspin_unlock(&qp->io_buf_list_put_lock);\n\t\tspin_unlock_irq(&qp->io_buf_list_get_lock);\n\t}\n\n\t \n\tfor (idx = 0; idx < cnt; idx++) {\n\t\tlist_remove_head(&blist, lpfc_cmd, struct lpfc_io_buf, list);\n\t\tif (!lpfc_cmd)\n\t\t\treturn cnt;\n\t\tif (idx == 0) {\n\t\t\tlist_add_tail(&lpfc_cmd->list, cbuf);\n\t\t\tcontinue;\n\t\t}\n\t\txri = lpfc_cmd->cur_iocbq.sli4_xritag;\n\t\tinserted = 0;\n\t\tprev_iobufp = NULL;\n\t\tlist_for_each_entry(iobufp, cbuf, list) {\n\t\t\tif (xri < iobufp->cur_iocbq.sli4_xritag) {\n\t\t\t\tif (prev_iobufp)\n\t\t\t\t\tlist_add(&lpfc_cmd->list,\n\t\t\t\t\t\t &prev_iobufp->list);\n\t\t\t\telse\n\t\t\t\t\tlist_add(&lpfc_cmd->list, cbuf);\n\t\t\t\tinserted = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tprev_iobufp = iobufp;\n\t\t}\n\t\tif (!inserted)\n\t\t\tlist_add_tail(&lpfc_cmd->list, cbuf);\n\t}\n\treturn cnt;\n}\n\nint\nlpfc_io_buf_replenish(struct lpfc_hba *phba, struct list_head *cbuf)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_cmd;\n\tint idx, cnt;\n\tunsigned long iflags;\n\n\tqp = phba->sli4_hba.hdwq;\n\tcnt = 0;\n\twhile (!list_empty(cbuf)) {\n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tlist_remove_head(cbuf, lpfc_cmd,\n\t\t\t\t\t struct lpfc_io_buf, list);\n\t\t\tif (!lpfc_cmd)\n\t\t\t\treturn cnt;\n\t\t\tcnt++;\n\t\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\t\tlpfc_cmd->hdwq_no = idx;\n\t\t\tlpfc_cmd->hdwq = qp;\n\t\t\tlpfc_cmd->cur_iocbq.cmd_cmpl = NULL;\n\t\t\tspin_lock_irqsave(&qp->io_buf_list_put_lock, iflags);\n\t\t\tlist_add_tail(&lpfc_cmd->list,\n\t\t\t\t      &qp->lpfc_io_buf_list_put);\n\t\t\tqp->put_io_bufs++;\n\t\t\tqp->total_io_bufs++;\n\t\t\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock,\n\t\t\t\t\t       iflags);\n\t\t}\n\t}\n\treturn cnt;\n}\n\n \nint\nlpfc_sli4_io_sgl_update(struct lpfc_hba *phba)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd = NULL, *lpfc_ncmd_next = NULL;\n\tuint16_t i, lxri, els_xri_cnt;\n\tuint16_t io_xri_cnt, io_xri_max;\n\tLIST_HEAD(io_sgl_list);\n\tint rc, cnt;\n\n\t \n\n\t \n\tels_xri_cnt = lpfc_sli4_get_els_iocb_cnt(phba);\n\tio_xri_max = phba->sli4_hba.max_cfg_param.max_xri - els_xri_cnt;\n\tphba->sli4_hba.io_xri_max = io_xri_max;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"6074 Current allocated XRI sgl count:%d, \"\n\t\t\t\"maximum XRI count:%d els_xri_cnt:%d\\n\\n\",\n\t\t\tphba->sli4_hba.io_xri_cnt,\n\t\t\tphba->sli4_hba.io_xri_max,\n\t\t\tels_xri_cnt);\n\n\tcnt = lpfc_io_buf_flush(phba, &io_sgl_list);\n\n\tif (phba->sli4_hba.io_xri_cnt > phba->sli4_hba.io_xri_max) {\n\t\t \n\t\tio_xri_cnt = phba->sli4_hba.io_xri_cnt -\n\t\t\t\t\tphba->sli4_hba.io_xri_max;\n\t\t \n\t\tfor (i = 0; i < io_xri_cnt; i++) {\n\t\t\tlist_remove_head(&io_sgl_list, lpfc_ncmd,\n\t\t\t\t\t struct lpfc_io_buf, list);\n\t\t\tif (lpfc_ncmd) {\n\t\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t\t      lpfc_ncmd->data,\n\t\t\t\t\t      lpfc_ncmd->dma_handle);\n\t\t\t\tkfree(lpfc_ncmd);\n\t\t\t}\n\t\t}\n\t\tphba->sli4_hba.io_xri_cnt -= io_xri_cnt;\n\t}\n\n\t \n\tlpfc_ncmd = NULL;\n\tlpfc_ncmd_next = NULL;\n\tphba->sli4_hba.io_xri_cnt = cnt;\n\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t &io_sgl_list, list) {\n\t\tlxri = lpfc_sli4_next_xritag(phba);\n\t\tif (lxri == NO_XRI) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"6075 Failed to allocate xri for \"\n\t\t\t\t\t\"nvme buffer\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_free_mem;\n\t\t}\n\t\tlpfc_ncmd->cur_iocbq.sli4_lxritag = lxri;\n\t\tlpfc_ncmd->cur_iocbq.sli4_xritag = phba->sli4_hba.xri_ids[lxri];\n\t}\n\tcnt = lpfc_io_buf_replenish(phba, &io_sgl_list);\n\treturn 0;\n\nout_free_mem:\n\tlpfc_io_free(phba);\n\treturn rc;\n}\n\n \nint\nlpfc_new_io_buf(struct lpfc_hba *phba, int num_to_alloc)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_iocbq *pwqeq;\n\tuint16_t iotag, lxri = 0;\n\tint bcnt, num_posted;\n\tLIST_HEAD(prep_nblist);\n\tLIST_HEAD(post_nblist);\n\tLIST_HEAD(nvme_nblist);\n\n\tphba->sli4_hba.io_xri_cnt = 0;\n\tfor (bcnt = 0; bcnt < num_to_alloc; bcnt++) {\n\t\tlpfc_ncmd = kzalloc(sizeof(*lpfc_ncmd), GFP_KERNEL);\n\t\tif (!lpfc_ncmd)\n\t\t\tbreak;\n\t\t \n\t\tlpfc_ncmd->data = dma_pool_zalloc(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t\t\t  GFP_KERNEL,\n\t\t\t\t\t\t  &lpfc_ncmd->dma_handle);\n\t\tif (!lpfc_ncmd->data) {\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (phba->cfg_xpsgl && !phba->nvmet_support) {\n\t\t\tINIT_LIST_HEAD(&lpfc_ncmd->dma_sgl_xtra_list);\n\t\t} else {\n\t\t\t \n\t\t\tif ((phba->sli3_options & LPFC_SLI3_BG_ENABLED) &&\n\t\t\t    (((unsigned long)(lpfc_ncmd->data) &\n\t\t\t    (unsigned long)(SLI4_PAGE_SIZE - 1)) != 0)) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3369 Memory alignment err: \"\n\t\t\t\t\t\t\"addr=%lx\\n\",\n\t\t\t\t\t\t(unsigned long)lpfc_ncmd->data);\n\t\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t\t      lpfc_ncmd->data,\n\t\t\t\t\t      lpfc_ncmd->dma_handle);\n\t\t\t\tkfree(lpfc_ncmd);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tINIT_LIST_HEAD(&lpfc_ncmd->dma_cmd_rsp_list);\n\n\t\tlxri = lpfc_sli4_next_xritag(phba);\n\t\tif (lxri == NO_XRI) {\n\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t      lpfc_ncmd->data, lpfc_ncmd->dma_handle);\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tbreak;\n\t\t}\n\t\tpwqeq = &lpfc_ncmd->cur_iocbq;\n\n\t\t \n\t\tiotag = lpfc_sli_next_iotag(phba, pwqeq);\n\t\tif (iotag == 0) {\n\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t      lpfc_ncmd->data, lpfc_ncmd->dma_handle);\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6121 Failed to allocate IOTAG for\"\n\t\t\t\t\t\" XRI:0x%x\\n\", lxri);\n\t\t\tlpfc_sli4_free_xri(phba, lxri);\n\t\t\tbreak;\n\t\t}\n\t\tpwqeq->sli4_lxritag = lxri;\n\t\tpwqeq->sli4_xritag = phba->sli4_hba.xri_ids[lxri];\n\n\t\t \n\t\tlpfc_ncmd->dma_sgl = lpfc_ncmd->data;\n\t\tlpfc_ncmd->dma_phys_sgl = lpfc_ncmd->dma_handle;\n\t\tlpfc_ncmd->cur_iocbq.io_buf = lpfc_ncmd;\n\t\tspin_lock_init(&lpfc_ncmd->buf_lock);\n\n\t\t \n\t\tlist_add_tail(&lpfc_ncmd->list, &post_nblist);\n\t\tphba->sli4_hba.io_xri_cnt++;\n\t}\n\tlpfc_printf_log(phba, KERN_INFO, LOG_NVME,\n\t\t\t\"6114 Allocate %d out of %d requested new NVME \"\n\t\t\t\"buffers of size x%zu bytes\\n\", bcnt, num_to_alloc,\n\t\t\tsizeof(*lpfc_ncmd));\n\n\n\t \n\tif (!list_empty(&post_nblist))\n\t\tnum_posted = lpfc_sli4_post_io_sgl_list(\n\t\t\t\tphba, &post_nblist, bcnt);\n\telse\n\t\tnum_posted = 0;\n\n\treturn num_posted;\n}\n\nstatic uint64_t\nlpfc_get_wwpn(struct lpfc_hba *phba)\n{\n\tuint64_t wwn;\n\tint rc;\n\tLPFC_MBOXQ_t *mboxq;\n\tMAILBOX_t *mb;\n\n\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool,\n\t\t\t\t\t\tGFP_KERNEL);\n\tif (!mboxq)\n\t\treturn (uint64_t)-1;\n\n\t \n\tlpfc_read_nv(phba, mboxq);\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6019 Mailbox failed , mbxCmd x%x \"\n\t\t\t\t\"READ_NV, mbxStatus x%x\\n\",\n\t\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\t\tbf_get(lpfc_mqe_status, &mboxq->u.mqe));\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\treturn (uint64_t) -1;\n\t}\n\tmb = &mboxq->u.mb;\n\tmemcpy(&wwn, (char *)mb->un.varRDnvp.portname, sizeof(uint64_t));\n\t \n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\treturn be64_to_cpu(wwn);\n\telse\n\t\treturn rol64(wwn, 32);\n}\n\nstatic unsigned short lpfc_get_sg_tablesize(struct lpfc_hba *phba)\n{\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\t\treturn LPFC_MAX_SG_TABLESIZE;\n\t\telse\n\t\t\treturn phba->cfg_scsi_seg_cnt;\n\telse\n\t\treturn phba->cfg_sg_seg_cnt;\n}\n\n \nstatic int\nlpfc_vmid_res_alloc(struct lpfc_hba *phba, struct lpfc_vport *vport)\n{\n\t \n\tif (phba->sli_rev == LPFC_SLI_REV3) {\n\t\tphba->cfg_vmid_app_header = 0;\n\t\tphba->cfg_vmid_priority_tagging = 0;\n\t}\n\n\tif (lpfc_is_vmid_enabled(phba)) {\n\t\tvport->vmid =\n\t\t    kcalloc(phba->cfg_max_vmid, sizeof(struct lpfc_vmid),\n\t\t\t    GFP_KERNEL);\n\t\tif (!vport->vmid)\n\t\t\treturn -ENOMEM;\n\n\t\trwlock_init(&vport->vmid_lock);\n\n\t\t \n\t\tvport->vmid_priority_tagging = phba->cfg_vmid_priority_tagging;\n\t\tvport->vmid_inactivity_timeout =\n\t\t    phba->cfg_vmid_inactivity_timeout;\n\t\tvport->max_vmid = phba->cfg_max_vmid;\n\t\tvport->cur_vmid_cnt = 0;\n\n\t\tvport->vmid_priority_range = bitmap_zalloc\n\t\t\t(LPFC_VMID_MAX_PRIORITY_RANGE, GFP_KERNEL);\n\n\t\tif (!vport->vmid_priority_range) {\n\t\t\tkfree(vport->vmid);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\thash_init(vport->hash_table);\n\t}\n\treturn 0;\n}\n\n \nstruct lpfc_vport *\nlpfc_create_port(struct lpfc_hba *phba, int instance, struct device *dev)\n{\n\tstruct lpfc_vport *vport;\n\tstruct Scsi_Host  *shost = NULL;\n\tstruct scsi_host_template *template;\n\tint error = 0;\n\tint i;\n\tuint64_t wwn;\n\tbool use_no_reset_hba = false;\n\tint rc;\n\n\tif (lpfc_no_hba_reset_cnt) {\n\t\tif (phba->sli_rev < LPFC_SLI_REV4 &&\n\t\t    dev == &phba->pcidev->dev) {\n\t\t\t \n\t\t\tlpfc_sli_brdrestart(phba);\n\t\t\trc = lpfc_sli_chipset_init(phba);\n\t\t\tif (rc)\n\t\t\t\treturn NULL;\n\t\t}\n\t\twwn = lpfc_get_wwpn(phba);\n\t}\n\n\tfor (i = 0; i < lpfc_no_hba_reset_cnt; i++) {\n\t\tif (wwn == lpfc_no_hba_reset[i]) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"6020 Setting use_no_reset port=%llx\\n\",\n\t\t\t\t\twwn);\n\t\t\tuse_no_reset_hba = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (dev == &phba->pcidev->dev) {\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP) {\n\t\t\t \n\t\t\ttemplate = &lpfc_template;\n\n\t\t\tif (use_no_reset_hba)\n\t\t\t\t \n\t\t\t\ttemplate->eh_host_reset_handler = NULL;\n\n\t\t\t \n\t\t\ttemplate->sg_tablesize = lpfc_get_sg_tablesize(phba);\n\t\t} else {\n\t\t\t \n\t\t\ttemplate = &lpfc_template_nvme;\n\t\t}\n\t} else {\n\t\t \n\t\ttemplate = &lpfc_vport_template;\n\n\t\t \n\t\ttemplate->sg_tablesize = lpfc_get_sg_tablesize(phba);\n\t}\n\n\tshost = scsi_host_alloc(template, sizeof(struct lpfc_vport));\n\tif (!shost)\n\t\tgoto out;\n\n\tvport = (struct lpfc_vport *) shost->hostdata;\n\tvport->phba = phba;\n\tvport->load_flag |= FC_LOADING;\n\tvport->fc_flag |= FC_VPORT_NEEDS_REG_VPI;\n\tvport->fc_rscn_flush = 0;\n\tlpfc_get_vport_cfgparam(vport);\n\n\t \n\tvport->cfg_enable_fc4_type = phba->cfg_enable_fc4_type;\n\n\tshost->unique_id = instance;\n\tshost->max_id = LPFC_MAX_TARGET;\n\tshost->max_lun = vport->cfg_max_luns;\n\tshost->this_id = -1;\n\tshost->max_cmd_len = 16;\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tif (!phba->cfg_fcp_mq_threshold ||\n\t\t    phba->cfg_fcp_mq_threshold > phba->cfg_hdw_queue)\n\t\t\tphba->cfg_fcp_mq_threshold = phba->cfg_hdw_queue;\n\n\t\tshost->nr_hw_queues = min_t(int, 2 * num_possible_nodes(),\n\t\t\t\t\t    phba->cfg_fcp_mq_threshold);\n\n\t\tshost->dma_boundary =\n\t\t\tphba->sli4_hba.pc_sli4_params.sge_supp_len-1;\n\t} else\n\t\t \n\t\tshost->nr_hw_queues = 1;\n\n\t \n\tshost->can_queue = phba->cfg_hba_queue_depth - 10;\n\tif (dev != &phba->pcidev->dev) {\n\t\tshost->transportt = lpfc_vport_transport_template;\n\t\tvport->port_type = LPFC_NPIV_PORT;\n\t} else {\n\t\tshost->transportt = lpfc_transport_template;\n\t\tvport->port_type = LPFC_PHYSICAL_PORT;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_FCP,\n\t\t\t\"9081 CreatePort TMPLATE type %x TBLsize %d \"\n\t\t\t\"SEGcnt %d/%d\\n\",\n\t\t\tvport->port_type, shost->sg_tablesize,\n\t\t\tphba->cfg_scsi_seg_cnt, phba->cfg_sg_seg_cnt);\n\n\t \n\trc = lpfc_vmid_res_alloc(phba, vport);\n\n\tif (rc)\n\t\tgoto out_put_shost;\n\n\t \n\tINIT_LIST_HEAD(&vport->fc_nodes);\n\tINIT_LIST_HEAD(&vport->rcv_buffer_list);\n\tspin_lock_init(&vport->work_port_lock);\n\n\ttimer_setup(&vport->fc_disctmo, lpfc_disc_timeout, 0);\n\n\ttimer_setup(&vport->els_tmofunc, lpfc_els_timeout, 0);\n\n\ttimer_setup(&vport->delayed_disc_tmo, lpfc_delayed_disc_tmo, 0);\n\n\tif (phba->sli3_options & LPFC_SLI3_BG_ENABLED)\n\t\tlpfc_setup_bg(phba, shost);\n\n\terror = scsi_add_host_with_dma(shost, dev, &phba->pcidev->dev);\n\tif (error)\n\t\tgoto out_free_vmid;\n\n\tspin_lock_irq(&phba->port_list_lock);\n\tlist_add_tail(&vport->listentry, &phba->port_list);\n\tspin_unlock_irq(&phba->port_list_lock);\n\treturn vport;\n\nout_free_vmid:\n\tkfree(vport->vmid);\n\tbitmap_free(vport->vmid_priority_range);\nout_put_shost:\n\tscsi_host_put(shost);\nout:\n\treturn NULL;\n}\n\n \nvoid\ndestroy_port(struct lpfc_vport *vport)\n{\n\tstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\n\tstruct lpfc_hba  *phba = vport->phba;\n\n\tlpfc_debugfs_terminate(vport);\n\tfc_remove_host(shost);\n\tscsi_remove_host(shost);\n\n\tspin_lock_irq(&phba->port_list_lock);\n\tlist_del_init(&vport->listentry);\n\tspin_unlock_irq(&phba->port_list_lock);\n\n\tlpfc_cleanup(vport);\n\treturn;\n}\n\n \nint\nlpfc_get_instance(void)\n{\n\tint ret;\n\n\tret = idr_alloc(&lpfc_hba_index, NULL, 0, 0, GFP_KERNEL);\n\treturn ret < 0 ? -1 : ret;\n}\n\n \nint lpfc_scan_finished(struct Scsi_Host *shost, unsigned long time)\n{\n\tstruct lpfc_vport *vport = (struct lpfc_vport *) shost->hostdata;\n\tstruct lpfc_hba   *phba = vport->phba;\n\tint stat = 0;\n\n\tspin_lock_irq(shost->host_lock);\n\n\tif (vport->load_flag & FC_UNLOADING) {\n\t\tstat = 1;\n\t\tgoto finished;\n\t}\n\tif (time >= msecs_to_jiffies(30 * 1000)) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0461 Scanning longer than 30 \"\n\t\t\t\t\"seconds.  Continuing initialization\\n\");\n\t\tstat = 1;\n\t\tgoto finished;\n\t}\n\tif (time >= msecs_to_jiffies(15 * 1000) &&\n\t    phba->link_state <= LPFC_LINK_DOWN) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0465 Link down longer than 15 \"\n\t\t\t\t\"seconds.  Continuing initialization\\n\");\n\t\tstat = 1;\n\t\tgoto finished;\n\t}\n\n\tif (vport->port_state != LPFC_VPORT_READY)\n\t\tgoto finished;\n\tif (vport->num_disc_nodes || vport->fc_prli_sent)\n\t\tgoto finished;\n\tif (vport->fc_map_cnt == 0 && time < msecs_to_jiffies(2 * 1000))\n\t\tgoto finished;\n\tif ((phba->sli.sli_flag & LPFC_SLI_MBOX_ACTIVE) != 0)\n\t\tgoto finished;\n\n\tstat = 1;\n\nfinished:\n\tspin_unlock_irq(shost->host_lock);\n\treturn stat;\n}\n\nstatic void lpfc_host_supported_speeds_set(struct Scsi_Host *shost)\n{\n\tstruct lpfc_vport *vport = (struct lpfc_vport *)shost->hostdata;\n\tstruct lpfc_hba   *phba = vport->phba;\n\n\tfc_host_supported_speeds(shost) = 0;\n\t \n\tif (phba->hba_flag & HBA_FCOE_MODE)\n\t\treturn;\n\n\tif (phba->lmt & LMT_256Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_256GBIT;\n\tif (phba->lmt & LMT_128Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_128GBIT;\n\tif (phba->lmt & LMT_64Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_64GBIT;\n\tif (phba->lmt & LMT_32Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_32GBIT;\n\tif (phba->lmt & LMT_16Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_16GBIT;\n\tif (phba->lmt & LMT_10Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_10GBIT;\n\tif (phba->lmt & LMT_8Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_8GBIT;\n\tif (phba->lmt & LMT_4Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_4GBIT;\n\tif (phba->lmt & LMT_2Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_2GBIT;\n\tif (phba->lmt & LMT_1Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_1GBIT;\n}\n\n \nvoid lpfc_host_attrib_init(struct Scsi_Host *shost)\n{\n\tstruct lpfc_vport *vport = (struct lpfc_vport *) shost->hostdata;\n\tstruct lpfc_hba   *phba = vport->phba;\n\t \n\n\tfc_host_node_name(shost) = wwn_to_u64(vport->fc_nodename.u.wwn);\n\tfc_host_port_name(shost) = wwn_to_u64(vport->fc_portname.u.wwn);\n\tfc_host_supported_classes(shost) = FC_COS_CLASS3;\n\n\tmemset(fc_host_supported_fc4s(shost), 0,\n\t       sizeof(fc_host_supported_fc4s(shost)));\n\tfc_host_supported_fc4s(shost)[2] = 1;\n\tfc_host_supported_fc4s(shost)[7] = 1;\n\n\tlpfc_vport_symbolic_node_name(vport, fc_host_symbolic_name(shost),\n\t\t\t\t sizeof fc_host_symbolic_name(shost));\n\n\tlpfc_host_supported_speeds_set(shost);\n\n\tfc_host_maxframe_size(shost) =\n\t\t(((uint32_t) vport->fc_sparam.cmn.bbRcvSizeMsb & 0x0F) << 8) |\n\t\t(uint32_t) vport->fc_sparam.cmn.bbRcvSizeLsb;\n\n\tfc_host_dev_loss_tmo(shost) = vport->cfg_devloss_tmo;\n\n\t \n\tmemset(fc_host_active_fc4s(shost), 0,\n\t       sizeof(fc_host_active_fc4s(shost)));\n\tfc_host_active_fc4s(shost)[2] = 1;\n\tfc_host_active_fc4s(shost)[7] = 1;\n\n\tfc_host_max_npiv_vports(shost) = phba->max_vpi;\n\tspin_lock_irq(shost->host_lock);\n\tvport->load_flag &= ~FC_LOADING;\n\tspin_unlock_irq(shost->host_lock);\n}\n\n \nstatic void\nlpfc_stop_port_s3(struct lpfc_hba *phba)\n{\n\t \n\twritel(0, phba->HCregaddr);\n\treadl(phba->HCregaddr);  \n\t \n\twritel(0xffffffff, phba->HAregaddr);\n\treadl(phba->HAregaddr);  \n\n\t \n\tlpfc_stop_hba_timers(phba);\n\tphba->pport->work_port_events = 0;\n}\n\n \nstatic void\nlpfc_stop_port_s4(struct lpfc_hba *phba)\n{\n\t \n\tlpfc_stop_hba_timers(phba);\n\tif (phba->pport)\n\t\tphba->pport->work_port_events = 0;\n\tphba->sli4_hba.intr_enable = 0;\n}\n\n \nvoid\nlpfc_stop_port(struct lpfc_hba *phba)\n{\n\tphba->lpfc_stop_port(phba);\n\n\tif (phba->wq)\n\t\tflush_workqueue(phba->wq);\n}\n\n \nvoid\nlpfc_fcf_redisc_wait_start_timer(struct lpfc_hba *phba)\n{\n\tunsigned long fcf_redisc_wait_tmo =\n\t\t(jiffies + msecs_to_jiffies(LPFC_FCF_REDISCOVER_WAIT_TMO));\n\t \n\tmod_timer(&phba->fcf.redisc_wait, fcf_redisc_wait_tmo);\n\tspin_lock_irq(&phba->hbalock);\n\t \n\tphba->fcf.fcf_flag &= ~(FCF_AVAILABLE | FCF_SCAN_DONE);\n\t \n\tphba->fcf.fcf_flag |= FCF_REDISC_PEND;\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n \nstatic void\nlpfc_sli4_fcf_redisc_wait_tmo(struct timer_list *t)\n{\n\tstruct lpfc_hba *phba = from_timer(phba, t, fcf.redisc_wait);\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tif (!(phba->fcf.fcf_flag & FCF_REDISC_PEND)) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\t \n\tphba->fcf.fcf_flag &= ~FCF_REDISC_PEND;\n\t \n\tphba->fcf.fcf_flag |= FCF_REDISC_EVT;\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\n\t\t\t\"2776 FCF rediscover quiescent timer expired\\n\");\n\t \n\tlpfc_worker_wake_up(phba);\n}\n\n \nstatic void\nlpfc_vmid_poll(struct timer_list *t)\n{\n\tstruct lpfc_hba *phba = from_timer(phba, t, inactive_vmid_poll);\n\tu32 wake_up = 0;\n\n\t \n\tif (phba->pport->vmid_priority_tagging) {\n\t\twake_up = 1;\n\t\tphba->pport->work_port_events |= WORKER_CHECK_VMID_ISSUE_QFPA;\n\t}\n\n\t \n\tif (phba->pport->vmid_inactivity_timeout ||\n\t    phba->pport->load_flag & FC_DEREGISTER_ALL_APP_ID) {\n\t\twake_up = 1;\n\t\tphba->pport->work_port_events |= WORKER_CHECK_INACTIVE_VMID;\n\t}\n\n\tif (wake_up)\n\t\tlpfc_worker_wake_up(phba);\n\n\t \n\tmod_timer(&phba->inactive_vmid_poll, jiffies + msecs_to_jiffies(1000 *\n\t\t\t\t\t\t\tLPFC_VMID_TIMER));\n}\n\n \nstatic void\nlpfc_sli4_parse_latt_fault(struct lpfc_hba *phba,\n\t\t\t   struct lpfc_acqe_link *acqe_link)\n{\n\tswitch (bf_get(lpfc_acqe_fc_la_att_type, acqe_link)) {\n\tcase LPFC_FC_LA_TYPE_LINK_DOWN:\n\tcase LPFC_FC_LA_TYPE_TRUNKING_EVENT:\n\tcase LPFC_FC_LA_TYPE_ACTIVATE_FAIL:\n\tcase LPFC_FC_LA_TYPE_LINK_RESET_PRTCL_EVT:\n\t\tbreak;\n\tdefault:\n\t\tswitch (bf_get(lpfc_acqe_link_fault, acqe_link)) {\n\t\tcase LPFC_ASYNC_LINK_FAULT_NONE:\n\t\tcase LPFC_ASYNC_LINK_FAULT_LOCAL:\n\t\tcase LPFC_ASYNC_LINK_FAULT_REMOTE:\n\t\tcase LPFC_ASYNC_LINK_FAULT_LR_LRR:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0398 Unknown link fault code: x%x\\n\",\n\t\t\t\t\tbf_get(lpfc_acqe_link_fault, acqe_link));\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n}\n\n \nstatic uint8_t\nlpfc_sli4_parse_latt_type(struct lpfc_hba *phba,\n\t\t\t  struct lpfc_acqe_link *acqe_link)\n{\n\tuint8_t att_type;\n\n\tswitch (bf_get(lpfc_acqe_link_status, acqe_link)) {\n\tcase LPFC_ASYNC_LINK_STATUS_DOWN:\n\tcase LPFC_ASYNC_LINK_STATUS_LOGICAL_DOWN:\n\t\tatt_type = LPFC_ATT_LINK_DOWN;\n\t\tbreak;\n\tcase LPFC_ASYNC_LINK_STATUS_UP:\n\t\t \n\t\tatt_type = LPFC_ATT_RESERVED;\n\t\tbreak;\n\tcase LPFC_ASYNC_LINK_STATUS_LOGICAL_UP:\n\t\tatt_type = LPFC_ATT_LINK_UP;\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0399 Invalid link attention type: x%x\\n\",\n\t\t\t\tbf_get(lpfc_acqe_link_status, acqe_link));\n\t\tatt_type = LPFC_ATT_RESERVED;\n\t\tbreak;\n\t}\n\treturn att_type;\n}\n\n \nuint32_t\nlpfc_sli_port_speed_get(struct lpfc_hba *phba)\n{\n\tuint32_t link_speed;\n\n\tif (!lpfc_is_link_up(phba))\n\t\treturn 0;\n\n\tif (phba->sli_rev <= LPFC_SLI_REV3) {\n\t\tswitch (phba->fc_linkspeed) {\n\t\tcase LPFC_LINK_SPEED_1GHZ:\n\t\t\tlink_speed = 1000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_2GHZ:\n\t\t\tlink_speed = 2000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_4GHZ:\n\t\t\tlink_speed = 4000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_8GHZ:\n\t\t\tlink_speed = 8000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_10GHZ:\n\t\t\tlink_speed = 10000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_16GHZ:\n\t\t\tlink_speed = 16000;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlink_speed = 0;\n\t\t}\n\t} else {\n\t\tif (phba->sli4_hba.link_state.logical_speed)\n\t\t\tlink_speed =\n\t\t\t      phba->sli4_hba.link_state.logical_speed;\n\t\telse\n\t\t\tlink_speed = phba->sli4_hba.link_state.speed;\n\t}\n\treturn link_speed;\n}\n\n \nstatic uint32_t\nlpfc_sli4_port_speed_parse(struct lpfc_hba *phba, uint32_t evt_code,\n\t\t\t   uint8_t speed_code)\n{\n\tuint32_t port_speed;\n\n\tswitch (evt_code) {\n\tcase LPFC_TRAILER_CODE_LINK:\n\t\tswitch (speed_code) {\n\t\tcase LPFC_ASYNC_LINK_SPEED_ZERO:\n\t\t\tport_speed = 0;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_10MBPS:\n\t\t\tport_speed = 10;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_100MBPS:\n\t\t\tport_speed = 100;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_1GBPS:\n\t\t\tport_speed = 1000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_10GBPS:\n\t\t\tport_speed = 10000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_20GBPS:\n\t\t\tport_speed = 20000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_25GBPS:\n\t\t\tport_speed = 25000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_40GBPS:\n\t\t\tport_speed = 40000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_100GBPS:\n\t\t\tport_speed = 100000;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tport_speed = 0;\n\t\t}\n\t\tbreak;\n\tcase LPFC_TRAILER_CODE_FC:\n\t\tswitch (speed_code) {\n\t\tcase LPFC_FC_LA_SPEED_UNKNOWN:\n\t\t\tport_speed = 0;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_1G:\n\t\t\tport_speed = 1000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_2G:\n\t\t\tport_speed = 2000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_4G:\n\t\t\tport_speed = 4000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_8G:\n\t\t\tport_speed = 8000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_10G:\n\t\t\tport_speed = 10000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_16G:\n\t\t\tport_speed = 16000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_32G:\n\t\t\tport_speed = 32000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_64G:\n\t\t\tport_speed = 64000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_128G:\n\t\t\tport_speed = 128000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_256G:\n\t\t\tport_speed = 256000;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tport_speed = 0;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tport_speed = 0;\n\t}\n\treturn port_speed;\n}\n\n \nstatic void\nlpfc_sli4_async_link_evt(struct lpfc_hba *phba,\n\t\t\t struct lpfc_acqe_link *acqe_link)\n{\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tstruct lpfc_mbx_read_top *la;\n\tuint8_t att_type;\n\tint rc;\n\n\tatt_type = lpfc_sli4_parse_latt_type(phba, acqe_link);\n\tif (att_type != LPFC_ATT_LINK_DOWN && att_type != LPFC_ATT_LINK_UP)\n\t\treturn;\n\tphba->fcoe_eventtag = acqe_link->event_tag;\n\tpmb = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0395 The mboxq allocation failed\\n\");\n\t\treturn;\n\t}\n\n\trc = lpfc_mbox_rsrc_prep(phba, pmb);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0396 mailbox allocation failed\\n\");\n\t\tgoto out_free_pmb;\n\t}\n\n\t \n\tlpfc_els_flush_all_cmd(phba);\n\n\t \n\tphba->sli4_hba.els_wq->pring->flag |= LPFC_STOP_IOCB_EVENT;\n\n\t \n\tphba->sli.slistat.link_event++;\n\n\t \n\tlpfc_read_topology(phba, pmb, (struct lpfc_dmabuf *)pmb->ctx_buf);\n\tpmb->mbox_cmpl = lpfc_mbx_cmpl_read_topology;\n\tpmb->vport = phba->pport;\n\n\t \n\tphba->sli4_hba.link_state.speed =\n\t\t\tlpfc_sli4_port_speed_parse(phba, LPFC_TRAILER_CODE_LINK,\n\t\t\t\tbf_get(lpfc_acqe_link_speed, acqe_link));\n\tphba->sli4_hba.link_state.duplex =\n\t\t\t\tbf_get(lpfc_acqe_link_duplex, acqe_link);\n\tphba->sli4_hba.link_state.status =\n\t\t\t\tbf_get(lpfc_acqe_link_status, acqe_link);\n\tphba->sli4_hba.link_state.type =\n\t\t\t\tbf_get(lpfc_acqe_link_type, acqe_link);\n\tphba->sli4_hba.link_state.number =\n\t\t\t\tbf_get(lpfc_acqe_link_number, acqe_link);\n\tphba->sli4_hba.link_state.fault =\n\t\t\t\tbf_get(lpfc_acqe_link_fault, acqe_link);\n\tphba->sli4_hba.link_state.logical_speed =\n\t\t\tbf_get(lpfc_acqe_logical_link_speed, acqe_link) * 10;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2900 Async FC/FCoE Link event - Speed:%dGBit \"\n\t\t\t\"duplex:x%x LA Type:x%x Port Type:%d Port Number:%d \"\n\t\t\t\"Logical speed:%dMbps Fault:%d\\n\",\n\t\t\tphba->sli4_hba.link_state.speed,\n\t\t\tphba->sli4_hba.link_state.topology,\n\t\t\tphba->sli4_hba.link_state.status,\n\t\t\tphba->sli4_hba.link_state.type,\n\t\t\tphba->sli4_hba.link_state.number,\n\t\t\tphba->sli4_hba.link_state.logical_speed,\n\t\t\tphba->sli4_hba.link_state.fault);\n\t \n\tif (!(phba->hba_flag & HBA_FCOE_MODE)) {\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\t\tif (rc == MBX_NOT_FINISHED)\n\t\t\tgoto out_free_pmb;\n\t\treturn;\n\t}\n\t \n\t \n\tmb = &pmb->u.mb;\n\tmb->mbxStatus = MBX_SUCCESS;\n\n\t \n\tlpfc_sli4_parse_latt_fault(phba, acqe_link);\n\n\t \n\tla = (struct lpfc_mbx_read_top *) &pmb->u.mb.un.varReadTop;\n\tla->eventTag = acqe_link->event_tag;\n\tbf_set(lpfc_mbx_read_top_att_type, la, att_type);\n\tbf_set(lpfc_mbx_read_top_link_spd, la,\n\t       (bf_get(lpfc_acqe_link_speed, acqe_link)));\n\n\t \n\tbf_set(lpfc_mbx_read_top_topology, la, LPFC_TOPOLOGY_PT_PT);\n\tbf_set(lpfc_mbx_read_top_alpa_granted, la, 0);\n\tbf_set(lpfc_mbx_read_top_il, la, 0);\n\tbf_set(lpfc_mbx_read_top_pb, la, 0);\n\tbf_set(lpfc_mbx_read_top_fa, la, 0);\n\tbf_set(lpfc_mbx_read_top_mm, la, 0);\n\n\t \n\tlpfc_mbx_cmpl_read_topology(phba, pmb);\n\n\treturn;\n\nout_free_pmb:\n\tlpfc_mbox_rsrc_cleanup(phba, pmb, MBOX_THD_UNLOCKED);\n}\n\n \nstatic uint8_t\nlpfc_async_link_speed_to_read_top(struct lpfc_hba *phba, uint8_t speed_code)\n{\n\tuint8_t port_speed;\n\n\tswitch (speed_code) {\n\tcase LPFC_FC_LA_SPEED_1G:\n\t\tport_speed = LPFC_LINK_SPEED_1GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_2G:\n\t\tport_speed = LPFC_LINK_SPEED_2GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_4G:\n\t\tport_speed = LPFC_LINK_SPEED_4GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_8G:\n\t\tport_speed = LPFC_LINK_SPEED_8GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_16G:\n\t\tport_speed = LPFC_LINK_SPEED_16GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_32G:\n\t\tport_speed = LPFC_LINK_SPEED_32GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_64G:\n\t\tport_speed = LPFC_LINK_SPEED_64GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_128G:\n\t\tport_speed = LPFC_LINK_SPEED_128GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_256G:\n\t\tport_speed = LPFC_LINK_SPEED_256GHZ;\n\t\tbreak;\n\tdefault:\n\t\tport_speed = 0;\n\t\tbreak;\n\t}\n\n\treturn port_speed;\n}\n\nvoid\nlpfc_cgn_dump_rxmonitor(struct lpfc_hba *phba)\n{\n\tif (!phba->rx_monitor) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"4411 Rx Monitor Info is empty.\\n\");\n\t} else {\n\t\tlpfc_rx_monitor_report(phba, phba->rx_monitor, NULL, 0,\n\t\t\t\t       LPFC_MAX_RXMONITOR_DUMP);\n\t}\n}\n\n \nvoid\nlpfc_cgn_update_stat(struct lpfc_hba *phba, uint32_t dtag)\n{\n\tstruct lpfc_cgn_info *cp;\n\tu32 value;\n\n\t \n\tif (!phba->cgn_i)\n\t\treturn;\n\tcp = (struct lpfc_cgn_info *)phba->cgn_i->virt;\n\n\t \n\tswitch (dtag) {\n\tcase ELS_DTAG_LNK_INTEGRITY:\n\t\tle32_add_cpu(&cp->link_integ_notification, 1);\n\t\tlpfc_cgn_update_tstamp(phba, &cp->stat_lnk);\n\t\tbreak;\n\tcase ELS_DTAG_DELIVERY:\n\t\tle32_add_cpu(&cp->delivery_notification, 1);\n\t\tlpfc_cgn_update_tstamp(phba, &cp->stat_delivery);\n\t\tbreak;\n\tcase ELS_DTAG_PEER_CONGEST:\n\t\tle32_add_cpu(&cp->cgn_peer_notification, 1);\n\t\tlpfc_cgn_update_tstamp(phba, &cp->stat_peer);\n\t\tbreak;\n\tcase ELS_DTAG_CONGESTION:\n\t\tle32_add_cpu(&cp->cgn_notification, 1);\n\t\tlpfc_cgn_update_tstamp(phba, &cp->stat_fpin);\n\t}\n\tif (phba->cgn_fpin_frequency &&\n\t    phba->cgn_fpin_frequency != LPFC_FPIN_INIT_FREQ) {\n\t\tvalue = LPFC_CGN_TIMER_TO_MIN / phba->cgn_fpin_frequency;\n\t\tcp->cgn_stat_npm = value;\n\t}\n\n\tvalue = lpfc_cgn_calc_crc32(cp, LPFC_CGN_INFO_SZ,\n\t\t\t\t    LPFC_CGN_CRC32_SEED);\n\tcp->cgn_info_crc = cpu_to_le32(value);\n}\n\n \nvoid\nlpfc_cgn_update_tstamp(struct lpfc_hba *phba, struct lpfc_cgn_ts *ts)\n{\n\tstruct timespec64 cur_time;\n\tstruct tm tm_val;\n\n\tktime_get_real_ts64(&cur_time);\n\ttime64_to_tm(cur_time.tv_sec, 0, &tm_val);\n\n\tts->month = tm_val.tm_mon + 1;\n\tts->day\t= tm_val.tm_mday;\n\tts->year = tm_val.tm_year - 100;\n\tts->hour = tm_val.tm_hour;\n\tts->minute = tm_val.tm_min;\n\tts->second = tm_val.tm_sec;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\"2646 Updated CMF timestamp : \"\n\t\t\t\"%u/%u/%u %u:%u:%u\\n\",\n\t\t\tts->day, ts->month,\n\t\t\tts->year, ts->hour,\n\t\t\tts->minute, ts->second);\n}\n\n \nstatic enum hrtimer_restart\nlpfc_cmf_stats_timer(struct hrtimer *timer)\n{\n\tstruct lpfc_hba *phba;\n\tstruct lpfc_cgn_info *cp;\n\tuint32_t i, index;\n\tuint16_t value, mvalue;\n\tuint64_t bps;\n\tuint32_t mbps;\n\tuint32_t dvalue, wvalue, lvalue, avalue;\n\tuint64_t latsum;\n\t__le16 *ptr;\n\t__le32 *lptr;\n\t__le16 *mptr;\n\n\tphba = container_of(timer, struct lpfc_hba, cmf_stats_timer);\n\t \n\tif (!phba->cgn_i)\n\t\treturn HRTIMER_NORESTART;\n\tcp = (struct lpfc_cgn_info *)phba->cgn_i->virt;\n\n\tphba->cgn_evt_timestamp = jiffies +\n\t\t\tmsecs_to_jiffies(LPFC_CGN_TIMER_TO_MIN);\n\tphba->cgn_evt_minute++;\n\n\t \n\tlpfc_cgn_update_tstamp(phba, &cp->base_time);\n\n\tif (phba->cgn_fpin_frequency &&\n\t    phba->cgn_fpin_frequency != LPFC_FPIN_INIT_FREQ) {\n\t\tvalue = LPFC_CGN_TIMER_TO_MIN / phba->cgn_fpin_frequency;\n\t\tcp->cgn_stat_npm = value;\n\t}\n\n\t \n\tlvalue = atomic_read(&phba->cgn_latency_evt_cnt);\n\tlatsum = atomic64_read(&phba->cgn_latency_evt);\n\tatomic_set(&phba->cgn_latency_evt_cnt, 0);\n\tatomic64_set(&phba->cgn_latency_evt, 0);\n\n\t \n\tbps = div_u64(phba->rx_block_cnt, LPFC_SEC_MIN) * 512;\n\tphba->rx_block_cnt = 0;\n\tmvalue = bps / (1024 * 1024);  \n\n\t \n\t \n\tcp->cgn_info_mode = phba->cgn_p.cgn_param_mode;\n\tcp->cgn_info_level0 = phba->cgn_p.cgn_param_level0;\n\tcp->cgn_info_level1 = phba->cgn_p.cgn_param_level1;\n\tcp->cgn_info_level2 = phba->cgn_p.cgn_param_level2;\n\n\t \n\tvalue = (uint16_t)(phba->pport->cfg_lun_queue_depth);\n\tcp->cgn_lunq = cpu_to_le16(value);\n\n\t \n\tindex = ++cp->cgn_index_minute;\n\tif (cp->cgn_index_minute == LPFC_MIN_HOUR) {\n\t\tcp->cgn_index_minute = 0;\n\t\tindex = 0;\n\t}\n\n\t \n\tdvalue = atomic_read(&phba->cgn_driver_evt_cnt);\n\tatomic_set(&phba->cgn_driver_evt_cnt, 0);\n\n\t \n\twvalue = 0;\n\tif ((phba->cgn_reg_fpin & LPFC_CGN_FPIN_WARN) ||\n\t    phba->cgn_reg_signal == EDC_CG_SIG_WARN_ONLY ||\n\t    phba->cgn_reg_signal == EDC_CG_SIG_WARN_ALARM)\n\t\twvalue = atomic_read(&phba->cgn_fabric_warn_cnt);\n\tatomic_set(&phba->cgn_fabric_warn_cnt, 0);\n\n\t \n\tavalue = 0;\n\tif ((phba->cgn_reg_fpin & LPFC_CGN_FPIN_ALARM) ||\n\t    phba->cgn_reg_signal == EDC_CG_SIG_WARN_ALARM)\n\t\tavalue = atomic_read(&phba->cgn_fabric_alarm_cnt);\n\tatomic_set(&phba->cgn_fabric_alarm_cnt, 0);\n\n\t \n\tptr = &cp->cgn_drvr_min[index];\n\tvalue = (uint16_t)dvalue;\n\t*ptr = cpu_to_le16(value);\n\n\tptr = &cp->cgn_warn_min[index];\n\tvalue = (uint16_t)wvalue;\n\t*ptr = cpu_to_le16(value);\n\n\tptr = &cp->cgn_alarm_min[index];\n\tvalue = (uint16_t)avalue;\n\t*ptr = cpu_to_le16(value);\n\n\tlptr = &cp->cgn_latency_min[index];\n\tif (lvalue) {\n\t\tlvalue = (uint32_t)div_u64(latsum, lvalue);\n\t\t*lptr = cpu_to_le32(lvalue);\n\t} else {\n\t\t*lptr = 0;\n\t}\n\n\t \n\tmptr = &cp->cgn_bw_min[index];\n\t*mptr = cpu_to_le16(mvalue);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\"2418 Congestion Info - minute (%d): %d %d %d %d %d\\n\",\n\t\t\tindex, dvalue, wvalue, *lptr, mvalue, avalue);\n\n\t \n\tif ((phba->cgn_evt_minute % LPFC_MIN_HOUR) == 0) {\n\t\t \n\t\tindex = ++cp->cgn_index_hour;\n\t\tif (cp->cgn_index_hour == LPFC_HOUR_DAY) {\n\t\t\tcp->cgn_index_hour = 0;\n\t\t\tindex = 0;\n\t\t}\n\n\t\tdvalue = 0;\n\t\twvalue = 0;\n\t\tlvalue = 0;\n\t\tavalue = 0;\n\t\tmvalue = 0;\n\t\tmbps = 0;\n\t\tfor (i = 0; i < LPFC_MIN_HOUR; i++) {\n\t\t\tdvalue += le16_to_cpu(cp->cgn_drvr_min[i]);\n\t\t\twvalue += le16_to_cpu(cp->cgn_warn_min[i]);\n\t\t\tlvalue += le32_to_cpu(cp->cgn_latency_min[i]);\n\t\t\tmbps += le16_to_cpu(cp->cgn_bw_min[i]);\n\t\t\tavalue += le16_to_cpu(cp->cgn_alarm_min[i]);\n\t\t}\n\t\tif (lvalue)\t\t \n\t\t\tlvalue /= LPFC_MIN_HOUR;\n\t\tif (mbps)\t\t \n\t\t\tmvalue = mbps / LPFC_MIN_HOUR;\n\n\t\tlptr = &cp->cgn_drvr_hr[index];\n\t\t*lptr = cpu_to_le32(dvalue);\n\t\tlptr = &cp->cgn_warn_hr[index];\n\t\t*lptr = cpu_to_le32(wvalue);\n\t\tlptr = &cp->cgn_latency_hr[index];\n\t\t*lptr = cpu_to_le32(lvalue);\n\t\tmptr = &cp->cgn_bw_hr[index];\n\t\t*mptr = cpu_to_le16(mvalue);\n\t\tlptr = &cp->cgn_alarm_hr[index];\n\t\t*lptr = cpu_to_le32(avalue);\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"2419 Congestion Info - hour \"\n\t\t\t\t\"(%d): %d %d %d %d %d\\n\",\n\t\t\t\tindex, dvalue, wvalue, lvalue, mvalue, avalue);\n\t}\n\n\t \n\tif ((phba->cgn_evt_minute % LPFC_MIN_DAY) == 0) {\n\t\t \n\t\tindex = ++cp->cgn_index_day;\n\t\tif (cp->cgn_index_day == LPFC_MAX_CGN_DAYS) {\n\t\t\tcp->cgn_index_day = 0;\n\t\t\tindex = 0;\n\t\t}\n\n\t\tdvalue = 0;\n\t\twvalue = 0;\n\t\tlvalue = 0;\n\t\tmvalue = 0;\n\t\tmbps = 0;\n\t\tavalue = 0;\n\t\tfor (i = 0; i < LPFC_HOUR_DAY; i++) {\n\t\t\tdvalue += le32_to_cpu(cp->cgn_drvr_hr[i]);\n\t\t\twvalue += le32_to_cpu(cp->cgn_warn_hr[i]);\n\t\t\tlvalue += le32_to_cpu(cp->cgn_latency_hr[i]);\n\t\t\tmbps += le16_to_cpu(cp->cgn_bw_hr[i]);\n\t\t\tavalue += le32_to_cpu(cp->cgn_alarm_hr[i]);\n\t\t}\n\t\tif (lvalue)\t\t \n\t\t\tlvalue /= LPFC_HOUR_DAY;\n\t\tif (mbps)\t\t \n\t\t\tmvalue = mbps / LPFC_HOUR_DAY;\n\n\t\tlptr = &cp->cgn_drvr_day[index];\n\t\t*lptr = cpu_to_le32(dvalue);\n\t\tlptr = &cp->cgn_warn_day[index];\n\t\t*lptr = cpu_to_le32(wvalue);\n\t\tlptr = &cp->cgn_latency_day[index];\n\t\t*lptr = cpu_to_le32(lvalue);\n\t\tmptr = &cp->cgn_bw_day[index];\n\t\t*mptr = cpu_to_le16(mvalue);\n\t\tlptr = &cp->cgn_alarm_day[index];\n\t\t*lptr = cpu_to_le32(avalue);\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"2420 Congestion Info - daily (%d): \"\n\t\t\t\t\"%d %d %d %d %d\\n\",\n\t\t\t\tindex, dvalue, wvalue, lvalue, mvalue, avalue);\n\t}\n\n\t \n\tvalue = phba->cgn_fpin_frequency;\n\tcp->cgn_warn_freq = cpu_to_le16(value);\n\tcp->cgn_alarm_freq = cpu_to_le16(value);\n\n\tlvalue = lpfc_cgn_calc_crc32(cp, LPFC_CGN_INFO_SZ,\n\t\t\t\t     LPFC_CGN_CRC32_SEED);\n\tcp->cgn_info_crc = cpu_to_le32(lvalue);\n\n\thrtimer_forward_now(timer, ktime_set(0, LPFC_SEC_MIN * NSEC_PER_SEC));\n\n\treturn HRTIMER_RESTART;\n}\n\n \nuint32_t\nlpfc_calc_cmf_latency(struct lpfc_hba *phba)\n{\n\tstruct timespec64 cmpl_time;\n\tuint32_t msec = 0;\n\n\tktime_get_real_ts64(&cmpl_time);\n\n\t \n\tif (cmpl_time.tv_sec == phba->cmf_latency.tv_sec) {\n\t\tmsec = (cmpl_time.tv_nsec - phba->cmf_latency.tv_nsec) /\n\t\t\tNSEC_PER_MSEC;\n\t} else {\n\t\tif (cmpl_time.tv_nsec >= phba->cmf_latency.tv_nsec) {\n\t\t\tmsec = (cmpl_time.tv_sec -\n\t\t\t\tphba->cmf_latency.tv_sec) * MSEC_PER_SEC;\n\t\t\tmsec += ((cmpl_time.tv_nsec -\n\t\t\t\t  phba->cmf_latency.tv_nsec) / NSEC_PER_MSEC);\n\t\t} else {\n\t\t\tmsec = (cmpl_time.tv_sec - phba->cmf_latency.tv_sec -\n\t\t\t\t1) * MSEC_PER_SEC;\n\t\t\tmsec += (((NSEC_PER_SEC - phba->cmf_latency.tv_nsec) +\n\t\t\t\t cmpl_time.tv_nsec) / NSEC_PER_MSEC);\n\t\t}\n\t}\n\treturn msec;\n}\n\n \nstatic enum hrtimer_restart\nlpfc_cmf_timer(struct hrtimer *timer)\n{\n\tstruct lpfc_hba *phba = container_of(timer, struct lpfc_hba,\n\t\t\t\t\t     cmf_timer);\n\tstruct rx_info_entry entry;\n\tuint32_t io_cnt;\n\tuint32_t busy, max_read;\n\tuint64_t total, rcv, lat, mbpi, extra, cnt;\n\tint timer_interval = LPFC_CMF_INTERVAL;\n\tuint32_t ms;\n\tstruct lpfc_cgn_stat *cgs;\n\tint cpu;\n\n\t \n\tif (phba->cmf_active_mode == LPFC_CFG_OFF ||\n\t    !phba->cmf_latency.tv_sec) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"6224 CMF timer exit: %d %lld\\n\",\n\t\t\t\tphba->cmf_active_mode,\n\t\t\t\t(uint64_t)phba->cmf_latency.tv_sec);\n\t\treturn HRTIMER_NORESTART;\n\t}\n\n\t \n\tif (!phba->pport)\n\t\tgoto skip;\n\n\t \n\tatomic_set(&phba->cmf_stop_io, 1);\n\n\t \n\tms = lpfc_calc_cmf_latency(phba);\n\n\n\t \n\tktime_get_real_ts64(&phba->cmf_latency);\n\n\tphba->cmf_link_byte_count =\n\t\tdiv_u64(phba->cmf_max_line_rate * LPFC_CMF_INTERVAL, 1000);\n\n\t \n\ttotal = 0;\n\tio_cnt = 0;\n\tlat = 0;\n\trcv = 0;\n\tfor_each_present_cpu(cpu) {\n\t\tcgs = per_cpu_ptr(phba->cmf_stat, cpu);\n\t\ttotal += atomic64_xchg(&cgs->total_bytes, 0);\n\t\tio_cnt += atomic_xchg(&cgs->rx_io_cnt, 0);\n\t\tlat += atomic64_xchg(&cgs->rx_latency, 0);\n\t\trcv += atomic64_xchg(&cgs->rcv_bytes, 0);\n\t}\n\n\t \n\tif (phba->cmf_active_mode == LPFC_CFG_MANAGED &&\n\t    phba->link_state != LPFC_LINK_DOWN &&\n\t    phba->hba_flag & HBA_SETUP) {\n\t\tmbpi = phba->cmf_last_sync_bw;\n\t\tphba->cmf_last_sync_bw = 0;\n\t\textra = 0;\n\n\t\t \n\t\tif (ms && ms < LPFC_CMF_INTERVAL) {\n\t\t\tcnt = div_u64(total, ms);  \n\t\t\tcnt *= LPFC_CMF_INTERVAL;  \n\t\t\textra = cnt - total;\n\t\t}\n\t\tlpfc_issue_cmf_sync_wqe(phba, LPFC_CMF_INTERVAL, total + extra);\n\t} else {\n\t\t \n\t\tmbpi = phba->cmf_link_byte_count;\n\t\textra = 0;\n\t}\n\tphba->cmf_timer_cnt++;\n\n\tif (io_cnt) {\n\t\t \n\t\tatomic_add(io_cnt, &phba->cgn_latency_evt_cnt);\n\t\tatomic64_add(lat, &phba->cgn_latency_evt);\n\t}\n\tbusy = atomic_xchg(&phba->cmf_busy, 0);\n\tmax_read = atomic_xchg(&phba->rx_max_read_cnt, 0);\n\n\t \n\tif (mbpi) {\n\t\tif (mbpi > phba->cmf_link_byte_count ||\n\t\t    phba->cmf_active_mode == LPFC_CFG_MONITOR)\n\t\t\tmbpi = phba->cmf_link_byte_count;\n\n\t\t \n\t\tif (mbpi != phba->cmf_max_bytes_per_interval)\n\t\t\tphba->cmf_max_bytes_per_interval = mbpi;\n\t}\n\n\t \n\tif (phba->rx_monitor) {\n\t\tentry.total_bytes = total;\n\t\tentry.cmf_bytes = total + extra;\n\t\tentry.rcv_bytes = rcv;\n\t\tentry.cmf_busy = busy;\n\t\tentry.cmf_info = phba->cmf_active_info;\n\t\tif (io_cnt) {\n\t\t\tentry.avg_io_latency = div_u64(lat, io_cnt);\n\t\t\tentry.avg_io_size = div_u64(rcv, io_cnt);\n\t\t} else {\n\t\t\tentry.avg_io_latency = 0;\n\t\t\tentry.avg_io_size = 0;\n\t\t}\n\t\tentry.max_read_cnt = max_read;\n\t\tentry.io_cnt = io_cnt;\n\t\tentry.max_bytes_per_interval = mbpi;\n\t\tif (phba->cmf_active_mode == LPFC_CFG_MANAGED)\n\t\t\tentry.timer_utilization = phba->cmf_last_ts;\n\t\telse\n\t\t\tentry.timer_utilization = ms;\n\t\tentry.timer_interval = ms;\n\t\tphba->cmf_last_ts = 0;\n\n\t\tlpfc_rx_monitor_record(phba->rx_monitor, &entry);\n\t}\n\n\tif (phba->cmf_active_mode == LPFC_CFG_MONITOR) {\n\t\t \n\t\tif (mbpi && total > mbpi)\n\t\t\tatomic_inc(&phba->cgn_driver_evt_cnt);\n\t}\n\tphba->rx_block_cnt += div_u64(rcv, 512);   \n\n\t \n\tif (atomic_xchg(&phba->cmf_bw_wait, 0))\n\t\tqueue_work(phba->wq, &phba->unblock_request_work);\n\n\t \n\tatomic_set(&phba->cmf_stop_io, 0);\n\nskip:\n\thrtimer_forward_now(timer,\n\t\t\t    ktime_set(0, timer_interval * NSEC_PER_MSEC));\n\treturn HRTIMER_RESTART;\n}\n\n#define trunk_link_status(__idx)\\\n\tbf_get(lpfc_acqe_fc_la_trunk_config_port##__idx, acqe_fc) ?\\\n\t       ((phba->trunk_link.link##__idx.state == LPFC_LINK_UP) ?\\\n\t\t\"Link up\" : \"Link down\") : \"NA\"\n \n#define trunk_port_fault(__idx)\\\n\tbf_get(lpfc_acqe_fc_la_trunk_config_port##__idx, acqe_fc) ?\\\n\t       (port_fault & (1 << __idx) ? \"YES\" : \"NO\") : \"NA\"\n\nstatic void\nlpfc_update_trunk_link_status(struct lpfc_hba *phba,\n\t\t\t      struct lpfc_acqe_fc_la *acqe_fc)\n{\n\tuint8_t port_fault = bf_get(lpfc_acqe_fc_la_trunk_linkmask, acqe_fc);\n\tuint8_t err = bf_get(lpfc_acqe_fc_la_trunk_fault, acqe_fc);\n\tu8 cnt = 0;\n\n\tphba->sli4_hba.link_state.speed =\n\t\tlpfc_sli4_port_speed_parse(phba, LPFC_TRAILER_CODE_FC,\n\t\t\t\tbf_get(lpfc_acqe_fc_la_speed, acqe_fc));\n\n\tphba->sli4_hba.link_state.logical_speed =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_llink_spd, acqe_fc) * 10;\n\t \n\tphba->fc_linkspeed =\n\t\t lpfc_async_link_speed_to_read_top(\n\t\t\t\tphba,\n\t\t\t\tbf_get(lpfc_acqe_fc_la_speed, acqe_fc));\n\n\tif (bf_get(lpfc_acqe_fc_la_trunk_config_port0, acqe_fc)) {\n\t\tphba->trunk_link.link0.state =\n\t\t\tbf_get(lpfc_acqe_fc_la_trunk_link_status_port0, acqe_fc)\n\t\t\t? LPFC_LINK_UP : LPFC_LINK_DOWN;\n\t\tphba->trunk_link.link0.fault = port_fault & 0x1 ? err : 0;\n\t\tcnt++;\n\t}\n\tif (bf_get(lpfc_acqe_fc_la_trunk_config_port1, acqe_fc)) {\n\t\tphba->trunk_link.link1.state =\n\t\t\tbf_get(lpfc_acqe_fc_la_trunk_link_status_port1, acqe_fc)\n\t\t\t? LPFC_LINK_UP : LPFC_LINK_DOWN;\n\t\tphba->trunk_link.link1.fault = port_fault & 0x2 ? err : 0;\n\t\tcnt++;\n\t}\n\tif (bf_get(lpfc_acqe_fc_la_trunk_config_port2, acqe_fc)) {\n\t\tphba->trunk_link.link2.state =\n\t\t\tbf_get(lpfc_acqe_fc_la_trunk_link_status_port2, acqe_fc)\n\t\t\t? LPFC_LINK_UP : LPFC_LINK_DOWN;\n\t\tphba->trunk_link.link2.fault = port_fault & 0x4 ? err : 0;\n\t\tcnt++;\n\t}\n\tif (bf_get(lpfc_acqe_fc_la_trunk_config_port3, acqe_fc)) {\n\t\tphba->trunk_link.link3.state =\n\t\t\tbf_get(lpfc_acqe_fc_la_trunk_link_status_port3, acqe_fc)\n\t\t\t? LPFC_LINK_UP : LPFC_LINK_DOWN;\n\t\tphba->trunk_link.link3.fault = port_fault & 0x8 ? err : 0;\n\t\tcnt++;\n\t}\n\n\tif (cnt)\n\t\tphba->trunk_link.phy_lnk_speed =\n\t\t\tphba->sli4_hba.link_state.logical_speed / (cnt * 1000);\n\telse\n\t\tphba->trunk_link.phy_lnk_speed = LPFC_LINK_SPEED_UNKNOWN;\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2910 Async FC Trunking Event - Speed:%d\\n\"\n\t\t\t\"\\tLogical speed:%d \"\n\t\t\t\"port0: %s port1: %s port2: %s port3: %s\\n\",\n\t\t\tphba->sli4_hba.link_state.speed,\n\t\t\tphba->sli4_hba.link_state.logical_speed,\n\t\t\ttrunk_link_status(0), trunk_link_status(1),\n\t\t\ttrunk_link_status(2), trunk_link_status(3));\n\n\tif (phba->cmf_active_mode != LPFC_CFG_OFF)\n\t\tlpfc_cmf_signal_init(phba);\n\n\tif (port_fault)\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3202 trunk error:0x%x (%s) seen on port0:%s \"\n\t\t\t\t \n\t\t\t\t\"port1:%s port2:%s port3:%s\\n\", err, err > 0xA ?\n\t\t\t\t\"UNDEFINED. update driver.\" : trunk_errmsg[err],\n\t\t\t\ttrunk_port_fault(0), trunk_port_fault(1),\n\t\t\t\ttrunk_port_fault(2), trunk_port_fault(3));\n}\n\n\n \nstatic void\nlpfc_sli4_async_fc_evt(struct lpfc_hba *phba, struct lpfc_acqe_fc_la *acqe_fc)\n{\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tstruct lpfc_mbx_read_top *la;\n\tchar *log_level;\n\tint rc;\n\n\tif (bf_get(lpfc_trailer_type, acqe_fc) !=\n\t    LPFC_FC_LA_EVENT_TYPE_FC_LINK) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2895 Non FC link Event detected.(%d)\\n\",\n\t\t\t\tbf_get(lpfc_trailer_type, acqe_fc));\n\t\treturn;\n\t}\n\n\tif (bf_get(lpfc_acqe_fc_la_att_type, acqe_fc) ==\n\t    LPFC_FC_LA_TYPE_TRUNKING_EVENT) {\n\t\tlpfc_update_trunk_link_status(phba, acqe_fc);\n\t\treturn;\n\t}\n\n\t \n\tphba->sli4_hba.link_state.speed =\n\t\t\tlpfc_sli4_port_speed_parse(phba, LPFC_TRAILER_CODE_FC,\n\t\t\t\tbf_get(lpfc_acqe_fc_la_speed, acqe_fc));\n\tphba->sli4_hba.link_state.duplex = LPFC_ASYNC_LINK_DUPLEX_FULL;\n\tphba->sli4_hba.link_state.topology =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_topology, acqe_fc);\n\tphba->sli4_hba.link_state.status =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_att_type, acqe_fc);\n\tphba->sli4_hba.link_state.type =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_port_type, acqe_fc);\n\tphba->sli4_hba.link_state.number =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_port_number, acqe_fc);\n\tphba->sli4_hba.link_state.fault =\n\t\t\t\tbf_get(lpfc_acqe_link_fault, acqe_fc);\n\tphba->sli4_hba.link_state.link_status =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_link_status, acqe_fc);\n\n\t \n\tif (phba->sli4_hba.link_state.status >= LPFC_FC_LA_TYPE_LINK_UP &&\n\t    phba->sli4_hba.link_state.status < LPFC_FC_LA_TYPE_ACTIVATE_FAIL) {\n\t\tif (bf_get(lpfc_acqe_fc_la_att_type, acqe_fc) ==\n\t\t    LPFC_FC_LA_TYPE_LINK_DOWN)\n\t\t\tphba->sli4_hba.link_state.logical_speed = 0;\n\t\telse if (!phba->sli4_hba.conf_trunk)\n\t\t\tphba->sli4_hba.link_state.logical_speed =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_llink_spd, acqe_fc) * 10;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2896 Async FC event - Speed:%dGBaud Topology:x%x \"\n\t\t\t\"LA Type:x%x Port Type:%d Port Number:%d Logical speed:\"\n\t\t\t\"%dMbps Fault:x%x Link Status:x%x\\n\",\n\t\t\tphba->sli4_hba.link_state.speed,\n\t\t\tphba->sli4_hba.link_state.topology,\n\t\t\tphba->sli4_hba.link_state.status,\n\t\t\tphba->sli4_hba.link_state.type,\n\t\t\tphba->sli4_hba.link_state.number,\n\t\t\tphba->sli4_hba.link_state.logical_speed,\n\t\t\tphba->sli4_hba.link_state.fault,\n\t\t\tphba->sli4_hba.link_state.link_status);\n\n\t \n\tif (phba->sli4_hba.link_state.status >= LPFC_FC_LA_TYPE_ACTIVATE_FAIL) {\n\t\tswitch (phba->sli4_hba.link_state.status) {\n\t\tcase LPFC_FC_LA_TYPE_ACTIVATE_FAIL:\n\t\t\tlog_level = KERN_WARNING;\n\t\t\tphba->sli4_hba.link_state.status =\n\t\t\t\t\tLPFC_FC_LA_TYPE_LINK_DOWN;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_TYPE_LINK_RESET_PRTCL_EVT:\n\t\t\t \n\t\t\tlog_level = KERN_INFO;\n\t\t\tphba->sli4_hba.link_state.status =\n\t\t\t\t\tLPFC_FC_LA_TYPE_LINK_UP;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlog_level = KERN_INFO;\n\t\t\tbreak;\n\t\t}\n\t\tlpfc_log_msg(phba, log_level, LOG_SLI,\n\t\t\t     \"2992 Async FC event - Informational Link \"\n\t\t\t     \"Attention Type x%x\\n\",\n\t\t\t     bf_get(lpfc_acqe_fc_la_att_type, acqe_fc));\n\t\treturn;\n\t}\n\n\tpmb = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2897 The mboxq allocation failed\\n\");\n\t\treturn;\n\t}\n\trc = lpfc_mbox_rsrc_prep(phba, pmb);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2898 The mboxq prep failed\\n\");\n\t\tgoto out_free_pmb;\n\t}\n\n\t \n\tlpfc_els_flush_all_cmd(phba);\n\n\t \n\tphba->sli4_hba.els_wq->pring->flag |= LPFC_STOP_IOCB_EVENT;\n\n\t \n\tphba->sli.slistat.link_event++;\n\n\t \n\tlpfc_read_topology(phba, pmb, (struct lpfc_dmabuf *)pmb->ctx_buf);\n\tpmb->mbox_cmpl = lpfc_mbx_cmpl_read_topology;\n\tpmb->vport = phba->pport;\n\n\tif (phba->sli4_hba.link_state.status != LPFC_FC_LA_TYPE_LINK_UP) {\n\t\tphba->link_flag &= ~(LS_MDS_LINK_DOWN | LS_MDS_LOOPBACK);\n\n\t\tswitch (phba->sli4_hba.link_state.status) {\n\t\tcase LPFC_FC_LA_TYPE_MDS_LINK_DOWN:\n\t\t\tphba->link_flag |= LS_MDS_LINK_DOWN;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_TYPE_MDS_LOOPBACK:\n\t\t\tphba->link_flag |= LS_MDS_LOOPBACK;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tmb = &pmb->u.mb;\n\t\tmb->mbxStatus = MBX_SUCCESS;\n\n\t\t \n\t\tlpfc_sli4_parse_latt_fault(phba, (void *)acqe_fc);\n\n\t\t \n\t\tla = (struct lpfc_mbx_read_top *)&pmb->u.mb.un.varReadTop;\n\t\tla->eventTag = acqe_fc->event_tag;\n\n\t\tif (phba->sli4_hba.link_state.status ==\n\t\t    LPFC_FC_LA_TYPE_UNEXP_WWPN) {\n\t\t\tbf_set(lpfc_mbx_read_top_att_type, la,\n\t\t\t       LPFC_FC_LA_TYPE_UNEXP_WWPN);\n\t\t} else {\n\t\t\tbf_set(lpfc_mbx_read_top_att_type, la,\n\t\t\t       LPFC_FC_LA_TYPE_LINK_DOWN);\n\t\t}\n\t\t \n\t\tlpfc_mbx_cmpl_read_topology(phba, pmb);\n\n\t\treturn;\n\t}\n\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED)\n\t\tgoto out_free_pmb;\n\treturn;\n\nout_free_pmb:\n\tlpfc_mbox_rsrc_cleanup(phba, pmb, MBOX_THD_UNLOCKED);\n}\n\n \nstatic void\nlpfc_sli4_async_sli_evt(struct lpfc_hba *phba, struct lpfc_acqe_sli *acqe_sli)\n{\n\tchar port_name;\n\tchar message[128];\n\tuint8_t status;\n\tuint8_t evt_type;\n\tuint8_t operational = 0;\n\tstruct temp_event temp_event_data;\n\tstruct lpfc_acqe_misconfigured_event *misconfigured;\n\tstruct lpfc_acqe_cgn_signal *cgn_signal;\n\tstruct Scsi_Host  *shost;\n\tstruct lpfc_vport **vports;\n\tint rc, i, cnt;\n\n\tevt_type = bf_get(lpfc_trailer_type, acqe_sli);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2901 Async SLI event - Type:%d, Event Data: x%08x \"\n\t\t\t\"x%08x x%08x x%08x\\n\", evt_type,\n\t\t\tacqe_sli->event_data1, acqe_sli->event_data2,\n\t\t\tacqe_sli->event_data3, acqe_sli->trailer);\n\n\tport_name = phba->Port[0];\n\tif (port_name == 0x00)\n\t\tport_name = '?';  \n\n\tswitch (evt_type) {\n\tcase LPFC_SLI_EVENT_TYPE_OVER_TEMP:\n\t\ttemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\n\t\ttemp_event_data.event_code = LPFC_THRESHOLD_TEMP;\n\t\ttemp_event_data.data = (uint32_t)acqe_sli->event_data1;\n\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"3190 Over Temperature:%d Celsius- Port Name %c\\n\",\n\t\t\t\tacqe_sli->event_data1, port_name);\n\n\t\tphba->sfp_warning |= LPFC_TRANSGRESSION_HIGH_TEMPERATURE;\n\t\tshost = lpfc_shost_from_vport(phba->pport);\n\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t\t  sizeof(temp_event_data),\n\t\t\t\t\t  (char *)&temp_event_data,\n\t\t\t\t\t  SCSI_NL_VID_TYPE_PCI\n\t\t\t\t\t  | PCI_VENDOR_ID_EMULEX);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_NORM_TEMP:\n\t\ttemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\n\t\ttemp_event_data.event_code = LPFC_NORMAL_TEMP;\n\t\ttemp_event_data.data = (uint32_t)acqe_sli->event_data1;\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI | LOG_LDS_EVENT,\n\t\t\t\t\"3191 Normal Temperature:%d Celsius - Port Name %c\\n\",\n\t\t\t\tacqe_sli->event_data1, port_name);\n\n\t\tshost = lpfc_shost_from_vport(phba->pport);\n\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t\t  sizeof(temp_event_data),\n\t\t\t\t\t  (char *)&temp_event_data,\n\t\t\t\t\t  SCSI_NL_VID_TYPE_PCI\n\t\t\t\t\t  | PCI_VENDOR_ID_EMULEX);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_MISCONFIGURED:\n\t\tmisconfigured = (struct lpfc_acqe_misconfigured_event *)\n\t\t\t\t\t&acqe_sli->event_data1;\n\n\t\t \n\t\tswitch (phba->sli4_hba.lnk_info.lnk_no) {\n\t\tcase LPFC_LINK_NUMBER_0:\n\t\t\tstatus = bf_get(lpfc_sli_misconfigured_port0_state,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\toperational = bf_get(lpfc_sli_misconfigured_port0_op,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\tbreak;\n\t\tcase LPFC_LINK_NUMBER_1:\n\t\t\tstatus = bf_get(lpfc_sli_misconfigured_port1_state,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\toperational = bf_get(lpfc_sli_misconfigured_port1_op,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\tbreak;\n\t\tcase LPFC_LINK_NUMBER_2:\n\t\t\tstatus = bf_get(lpfc_sli_misconfigured_port2_state,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\toperational = bf_get(lpfc_sli_misconfigured_port2_op,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\tbreak;\n\t\tcase LPFC_LINK_NUMBER_3:\n\t\t\tstatus = bf_get(lpfc_sli_misconfigured_port3_state,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\toperational = bf_get(lpfc_sli_misconfigured_port3_op,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3296 \"\n\t\t\t\t\t\"LPFC_SLI_EVENT_TYPE_MISCONFIGURED \"\n\t\t\t\t\t\"event: Invalid link %d\",\n\t\t\t\t\tphba->sli4_hba.lnk_info.lnk_no);\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tif (phba->sli4_hba.lnk_info.optic_state == status)\n\t\t\treturn;\n\n\t\tswitch (status) {\n\t\tcase LPFC_SLI_EVENT_STATUS_VALID:\n\t\t\tsprintf(message, \"Physical Link is functional\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_NOT_PRESENT:\n\t\t\tsprintf(message, \"Optics faulted/incorrectly \"\n\t\t\t\t\"installed/not installed - Reseat optics, \"\n\t\t\t\t\"if issue not resolved, replace.\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_WRONG_TYPE:\n\t\t\tsprintf(message,\n\t\t\t\t\"Optics of two types installed - Remove one \"\n\t\t\t\t\"optic or install matching pair of optics.\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_UNSUPPORTED:\n\t\t\tsprintf(message, \"Incompatible optics - Replace with \"\n\t\t\t\t\"compatible optics for card to function.\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_UNQUALIFIED:\n\t\t\tsprintf(message, \"Unqualified optics - Replace with \"\n\t\t\t\t\"Avago optics for Warranty and Technical \"\n\t\t\t\t\"Support - Link is%s operational\",\n\t\t\t\t(operational) ? \" not\" : \"\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_UNCERTIFIED:\n\t\t\tsprintf(message, \"Uncertified optics - Replace with \"\n\t\t\t\t\"Avago-certified optics to enable link \"\n\t\t\t\t\"operation - Link is%s operational\",\n\t\t\t\t(operational) ? \" not\" : \"\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tsprintf(message, \"Unknown event status x%02x\", status);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\trc = lpfc_sli4_read_config(phba);\n\t\tif (rc) {\n\t\t\tphba->lmt = 0;\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"3194 Unable to retrieve supported \"\n\t\t\t\t\t\"speeds, rc = 0x%x\\n\", rc);\n\t\t}\n\t\trc = lpfc_sli4_refresh_params(phba);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\t\"3174 Unable to update pls support, \"\n\t\t\t\t\t\"rc x%x\\n\", rc);\n\t\t}\n\t\tvports = lpfc_create_vport_work_array(phba);\n\t\tif (vports != NULL) {\n\t\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL;\n\t\t\t\t\ti++) {\n\t\t\t\tshost = lpfc_shost_from_vport(vports[i]);\n\t\t\t\tlpfc_host_supported_speeds_set(shost);\n\t\t\t}\n\t\t}\n\t\tlpfc_destroy_vport_work_array(phba, vports);\n\n\t\tphba->sli4_hba.lnk_info.optic_state = status;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\"3176 Port Name %c %s\\n\", port_name, message);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_REMOTE_DPORT:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3192 Remote DPort Test Initiated - \"\n\t\t\t\t\"Event Data1:x%08x Event Data2: x%08x\\n\",\n\t\t\t\tacqe_sli->event_data1, acqe_sli->event_data2);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_PORT_PARAMS_CHG:\n\t\t \n\t\tlpfc_sli4_cgn_parm_chg_evt(phba);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_MISCONF_FAWWN:\n\t\t \n\t\tlpfc_log_msg(phba, KERN_WARNING, LOG_SLI | LOG_DISCOVERY,\n\t\t\t     \"2699 Misconfigured FA-PWWN - Attached device \"\n\t\t\t     \"does not support FA-PWWN\\n\");\n\t\tphba->sli4_hba.fawwpn_flag &= ~LPFC_FAWWPN_FABRIC;\n\t\tmemset(phba->pport->fc_portname.u.wwn, 0,\n\t\t       sizeof(struct lpfc_name));\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_EEPROM_FAILURE:\n\t\t \n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t     \"2518 EEPROM failure - \"\n\t\t\t     \"Event Data1: x%08x Event Data2: x%08x\\n\",\n\t\t\t     acqe_sli->event_data1, acqe_sli->event_data2);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_CGN_SIGNAL:\n\t\tif (phba->cmf_active_mode == LPFC_CFG_OFF)\n\t\t\tbreak;\n\t\tcgn_signal = (struct lpfc_acqe_cgn_signal *)\n\t\t\t\t\t&acqe_sli->event_data1;\n\t\tphba->cgn_acqe_cnt++;\n\n\t\tcnt = bf_get(lpfc_warn_acqe, cgn_signal);\n\t\tatomic64_add(cnt, &phba->cgn_acqe_stat.warn);\n\t\tatomic64_add(cgn_signal->alarm_cnt, &phba->cgn_acqe_stat.alarm);\n\n\t\t \n\n\t\t \n\t\tif (cgn_signal->alarm_cnt) {\n\t\t\tif (phba->cgn_reg_signal == EDC_CG_SIG_WARN_ALARM) {\n\t\t\t\t \n\t\t\t\tatomic_add(cgn_signal->alarm_cnt,\n\t\t\t\t\t   &phba->cgn_sync_alarm_cnt);\n\t\t\t}\n\t\t} else if (cnt) {\n\t\t\t \n\t\t\tif (phba->cgn_reg_signal == EDC_CG_SIG_WARN_ONLY ||\n\t\t\t    phba->cgn_reg_signal == EDC_CG_SIG_WARN_ALARM) {\n\t\t\t\t \n\t\t\t\tatomic_add(cnt, &phba->cgn_sync_warn_cnt);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_RD_SIGNAL:\n\t\t \n\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\tLOG_SLI | LOG_LINK_EVENT | LOG_LDS_EVENT,\n\t\t\t\t\"2902 Remote Degrade Signaling: x%08x x%08x \"\n\t\t\t\t\"x%08x\\n\",\n\t\t\t\tacqe_sli->event_data1, acqe_sli->event_data2,\n\t\t\t\tacqe_sli->event_data3);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3193 Unrecognized SLI event, type: 0x%x\",\n\t\t\t\tevt_type);\n\t\tbreak;\n\t}\n}\n\n \nstatic struct lpfc_nodelist *\nlpfc_sli4_perform_vport_cvl(struct lpfc_vport *vport)\n{\n\tstruct lpfc_nodelist *ndlp;\n\tstruct Scsi_Host *shost;\n\tstruct lpfc_hba *phba;\n\n\tif (!vport)\n\t\treturn NULL;\n\tphba = vport->phba;\n\tif (!phba)\n\t\treturn NULL;\n\tndlp = lpfc_findnode_did(vport, Fabric_DID);\n\tif (!ndlp) {\n\t\t \n\t\tndlp = lpfc_nlp_init(vport, Fabric_DID);\n\t\tif (!ndlp)\n\t\t\treturn NULL;\n\t\t \n\t\tndlp->nlp_type |= NLP_FABRIC;\n\t\t \n\t\tlpfc_enqueue_node(vport, ndlp);\n\t}\n\tif ((phba->pport->port_state < LPFC_FLOGI) &&\n\t\t(phba->pport->port_state != LPFC_VPORT_FAILED))\n\t\treturn NULL;\n\t \n\tif ((vport != phba->pport) && (vport->port_state < LPFC_FDISC)\n\t\t&& (vport->port_state != LPFC_VPORT_FAILED))\n\t\treturn NULL;\n\tshost = lpfc_shost_from_vport(vport);\n\tif (!shost)\n\t\treturn NULL;\n\tlpfc_linkdown_port(vport);\n\tlpfc_cleanup_pending_mbox(vport);\n\tspin_lock_irq(shost->host_lock);\n\tvport->fc_flag |= FC_VPORT_CVL_RCVD;\n\tspin_unlock_irq(shost->host_lock);\n\n\treturn ndlp;\n}\n\n \nstatic void\nlpfc_sli4_perform_all_vport_cvl(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport **vports;\n\tint i;\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++)\n\t\t\tlpfc_sli4_perform_vport_cvl(vports[i]);\n\tlpfc_destroy_vport_work_array(phba, vports);\n}\n\n \nstatic void\nlpfc_sli4_async_fip_evt(struct lpfc_hba *phba,\n\t\t\tstruct lpfc_acqe_fip *acqe_fip)\n{\n\tuint8_t event_type = bf_get(lpfc_trailer_type, acqe_fip);\n\tint rc;\n\tstruct lpfc_vport *vport;\n\tstruct lpfc_nodelist *ndlp;\n\tint active_vlink_present;\n\tstruct lpfc_vport **vports;\n\tint i;\n\n\tphba->fc_eventTag = acqe_fip->event_tag;\n\tphba->fcoe_eventtag = acqe_fip->event_tag;\n\tswitch (event_type) {\n\tcase LPFC_FIP_EVENT_TYPE_NEW_FCF:\n\tcase LPFC_FIP_EVENT_TYPE_FCF_PARAM_MOD:\n\t\tif (event_type == LPFC_FIP_EVENT_TYPE_NEW_FCF)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2546 New FCF event, evt_tag:x%x, \"\n\t\t\t\t\t\"index:x%x\\n\",\n\t\t\t\t\tacqe_fip->event_tag,\n\t\t\t\t\tacqe_fip->index);\n\t\telse\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_FIP |\n\t\t\t\t\tLOG_DISCOVERY,\n\t\t\t\t\t\"2788 FCF param modified event, \"\n\t\t\t\t\t\"evt_tag:x%x, index:x%x\\n\",\n\t\t\t\t\tacqe_fip->event_tag,\n\t\t\t\t\tacqe_fip->index);\n\t\tif (phba->fcf.fcf_flag & FCF_DISCOVERY) {\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP |\n\t\t\t\t\tLOG_DISCOVERY,\n\t\t\t\t\t\"2779 Read FCF (x%x) for updating \"\n\t\t\t\t\t\"roundrobin FCF failover bmask\\n\",\n\t\t\t\t\tacqe_fip->index);\n\t\t\trc = lpfc_sli4_read_fcf_rec(phba, acqe_fip->index);\n\t\t}\n\n\t\t \n\t\tspin_lock_irq(&phba->hbalock);\n\t\tif (phba->hba_flag & FCF_TS_INPROG) {\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tif (phba->fcf.fcf_flag & (FCF_REDISC_EVT | FCF_REDISC_PEND)) {\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (phba->fcf.fcf_flag & FCF_SCAN_DONE) {\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t \n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_DISCOVERY,\n\t\t\t\t\"2770 Start FCF table scan per async FCF \"\n\t\t\t\t\"event, evt_tag:x%x, index:x%x\\n\",\n\t\t\t\tacqe_fip->event_tag, acqe_fip->index);\n\t\trc = lpfc_sli4_fcf_scan_read_fcf_rec(phba,\n\t\t\t\t\t\t     LPFC_FCOE_FCF_GET_FIRST);\n\t\tif (rc)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2547 Issue FCF scan read FCF mailbox \"\n\t\t\t\t\t\"command failed (x%x)\\n\", rc);\n\t\tbreak;\n\n\tcase LPFC_FIP_EVENT_TYPE_FCF_TABLE_FULL:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2548 FCF Table full count 0x%x tag 0x%x\\n\",\n\t\t\t\tbf_get(lpfc_acqe_fip_fcf_count, acqe_fip),\n\t\t\t\tacqe_fip->event_tag);\n\t\tbreak;\n\n\tcase LPFC_FIP_EVENT_TYPE_FCF_DEAD:\n\t\tphba->fcoe_cvl_eventtag = acqe_fip->event_tag;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2549 FCF (x%x) disconnected from network, \"\n\t\t\t\t \"tag:x%x\\n\", acqe_fip->index,\n\t\t\t\t acqe_fip->event_tag);\n\t\t \n\t\tspin_lock_irq(&phba->hbalock);\n\t\tif ((phba->fcf.fcf_flag & FCF_DISCOVERY) &&\n\t\t    (phba->fcf.current_rec.fcf_indx != acqe_fip->index)) {\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t \n\t\t\tlpfc_sli4_fcf_rr_index_clear(phba, acqe_fip->index);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t \n\t\tif (phba->fcf.current_rec.fcf_indx != acqe_fip->index)\n\t\t\tbreak;\n\n\t\t \n\t\tspin_lock_irq(&phba->hbalock);\n\t\t \n\t\tphba->fcf.fcf_flag |= FCF_DEAD_DISC;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_DISCOVERY,\n\t\t\t\t\"2771 Start FCF fast failover process due to \"\n\t\t\t\t\"FCF DEAD event: evt_tag:x%x, fcf_index:x%x \"\n\t\t\t\t\"\\n\", acqe_fip->event_tag, acqe_fip->index);\n\t\trc = lpfc_sli4_redisc_fcf_table(phba);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP |\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"2772 Issue FCF rediscover mailbox \"\n\t\t\t\t\t\"command failed, fail through to FCF \"\n\t\t\t\t\t\"dead event\\n\");\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tphba->fcf.fcf_flag &= ~FCF_DEAD_DISC;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t \n\t\t\tlpfc_sli4_fcf_dead_failthrough(phba);\n\t\t} else {\n\t\t\t \n\t\t\tlpfc_sli4_clear_fcf_rr_bmask(phba);\n\t\t\t \n\t\t\tlpfc_sli4_perform_all_vport_cvl(phba);\n\t\t}\n\t\tbreak;\n\tcase LPFC_FIP_EVENT_TYPE_CVL:\n\t\tphba->fcoe_cvl_eventtag = acqe_fip->event_tag;\n\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\"2718 Clear Virtual Link Received for VPI 0x%x\"\n\t\t\t\" tag 0x%x\\n\", acqe_fip->index, acqe_fip->event_tag);\n\n\t\tvport = lpfc_find_vport_by_vpid(phba,\n\t\t\t\t\t\tacqe_fip->index);\n\t\tndlp = lpfc_sli4_perform_vport_cvl(vport);\n\t\tif (!ndlp)\n\t\t\tbreak;\n\t\tactive_vlink_present = 0;\n\n\t\tvports = lpfc_create_vport_work_array(phba);\n\t\tif (vports) {\n\t\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL;\n\t\t\t\t\ti++) {\n\t\t\t\tif ((!(vports[i]->fc_flag &\n\t\t\t\t\tFC_VPORT_CVL_RCVD)) &&\n\t\t\t\t\t(vports[i]->port_state > LPFC_FDISC)) {\n\t\t\t\t\tactive_vlink_present = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlpfc_destroy_vport_work_array(phba, vports);\n\t\t}\n\n\t\t \n\t\tif (!(vport->load_flag & FC_UNLOADING) &&\n\t\t\t\t\tactive_vlink_present) {\n\t\t\t \n\t\t\tmod_timer(&ndlp->nlp_delayfunc,\n\t\t\t\t  jiffies + msecs_to_jiffies(1000));\n\t\t\tspin_lock_irq(&ndlp->lock);\n\t\t\tndlp->nlp_flag |= NLP_DELAY_TMO;\n\t\t\tspin_unlock_irq(&ndlp->lock);\n\t\t\tndlp->nlp_last_elscmd = ELS_CMD_FDISC;\n\t\t\tvport->port_state = LPFC_FDISC;\n\t\t} else {\n\t\t\t \n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tif (phba->fcf.fcf_flag & FCF_DISCOVERY) {\n\t\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t \n\t\t\tphba->fcf.fcf_flag |= FCF_ACVL_DISC;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP |\n\t\t\t\t\tLOG_DISCOVERY,\n\t\t\t\t\t\"2773 Start FCF failover per CVL, \"\n\t\t\t\t\t\"evt_tag:x%x\\n\", acqe_fip->event_tag);\n\t\t\trc = lpfc_sli4_redisc_fcf_table(phba);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP |\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"2774 Issue FCF rediscover \"\n\t\t\t\t\t\t\"mailbox command failed, \"\n\t\t\t\t\t\t\"through to CVL event\\n\");\n\t\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\t\tphba->fcf.fcf_flag &= ~FCF_ACVL_DISC;\n\t\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t\t \n\t\t\t\tlpfc_retry_pport_discovery(phba);\n\t\t\t} else\n\t\t\t\t \n\t\t\t\tlpfc_sli4_clear_fcf_rr_bmask(phba);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0288 Unknown FCoE event type 0x%x event tag \"\n\t\t\t\t\"0x%x\\n\", event_type, acqe_fip->event_tag);\n\t\tbreak;\n\t}\n}\n\n \nstatic void\nlpfc_sli4_async_dcbx_evt(struct lpfc_hba *phba,\n\t\t\t struct lpfc_acqe_dcbx *acqe_dcbx)\n{\n\tphba->fc_eventTag = acqe_dcbx->event_tag;\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0290 The SLI4 DCBX asynchronous event is not \"\n\t\t\t\"handled yet\\n\");\n}\n\n \nstatic void\nlpfc_sli4_async_grp5_evt(struct lpfc_hba *phba,\n\t\t\t struct lpfc_acqe_grp5 *acqe_grp5)\n{\n\tuint16_t prev_ll_spd;\n\n\tphba->fc_eventTag = acqe_grp5->event_tag;\n\tphba->fcoe_eventtag = acqe_grp5->event_tag;\n\tprev_ll_spd = phba->sli4_hba.link_state.logical_speed;\n\tphba->sli4_hba.link_state.logical_speed =\n\t\t(bf_get(lpfc_acqe_grp5_llink_spd, acqe_grp5)) * 10;\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2789 GRP5 Async Event: Updating logical link speed \"\n\t\t\t\"from %dMbps to %dMbps\\n\", prev_ll_spd,\n\t\t\tphba->sli4_hba.link_state.logical_speed);\n}\n\n \nstatic void\nlpfc_sli4_async_cmstat_evt(struct lpfc_hba *phba)\n{\n\tif (!phba->cgn_i)\n\t\treturn;\n\tlpfc_init_congestion_stat(phba);\n}\n\n \nstatic void\nlpfc_cgn_params_val(struct lpfc_hba *phba, struct lpfc_cgn_param *p_cfg_param)\n{\n\tspin_lock_irq(&phba->hbalock);\n\n\tif (!lpfc_rangecheck(p_cfg_param->cgn_param_mode, LPFC_CFG_OFF,\n\t\t\t     LPFC_CFG_MONITOR)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_CGN_MGMT,\n\t\t\t\t\"6225 CMF mode param out of range: %d\\n\",\n\t\t\t\t p_cfg_param->cgn_param_mode);\n\t\tp_cfg_param->cgn_param_mode = LPFC_CFG_OFF;\n\t}\n\n\tspin_unlock_irq(&phba->hbalock);\n}\n\nstatic const char * const lpfc_cmf_mode_to_str[] = {\n\t\"OFF\",\n\t\"MANAGED\",\n\t\"MONITOR\",\n};\n\n \nstatic void\nlpfc_cgn_params_parse(struct lpfc_hba *phba,\n\t\t      struct lpfc_cgn_param *p_cgn_param, uint32_t len)\n{\n\tstruct lpfc_cgn_info *cp;\n\tuint32_t crc, oldmode;\n\tchar acr_string[4] = {0};\n\n\t \n\tif (p_cgn_param->cgn_param_magic == LPFC_CFG_PARAM_MAGIC_NUM) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\"4668 FW cgn parm buffer data: \"\n\t\t\t\t\"magic 0x%x version %d mode %d \"\n\t\t\t\t\"level0 %d level1 %d \"\n\t\t\t\t\"level2 %d byte13 %d \"\n\t\t\t\t\"byte14 %d byte15 %d \"\n\t\t\t\t\"byte11 %d byte12 %d activeMode %d\\n\",\n\t\t\t\tp_cgn_param->cgn_param_magic,\n\t\t\t\tp_cgn_param->cgn_param_version,\n\t\t\t\tp_cgn_param->cgn_param_mode,\n\t\t\t\tp_cgn_param->cgn_param_level0,\n\t\t\t\tp_cgn_param->cgn_param_level1,\n\t\t\t\tp_cgn_param->cgn_param_level2,\n\t\t\t\tp_cgn_param->byte13,\n\t\t\t\tp_cgn_param->byte14,\n\t\t\t\tp_cgn_param->byte15,\n\t\t\t\tp_cgn_param->byte11,\n\t\t\t\tp_cgn_param->byte12,\n\t\t\t\tphba->cmf_active_mode);\n\n\t\toldmode = phba->cmf_active_mode;\n\n\t\t \n\t\tlpfc_cgn_params_val(phba, p_cgn_param);\n\n\t\t \n\t\tspin_lock_irq(&phba->hbalock);\n\t\tmemcpy(&phba->cgn_p, p_cgn_param,\n\t\t       sizeof(struct lpfc_cgn_param));\n\n\t\t \n\t\tif (phba->cgn_i) {\n\t\t\tcp = (struct lpfc_cgn_info *)phba->cgn_i->virt;\n\t\t\tcp->cgn_info_mode = phba->cgn_p.cgn_param_mode;\n\t\t\tcp->cgn_info_level0 = phba->cgn_p.cgn_param_level0;\n\t\t\tcp->cgn_info_level1 = phba->cgn_p.cgn_param_level1;\n\t\t\tcp->cgn_info_level2 = phba->cgn_p.cgn_param_level2;\n\t\t\tcrc = lpfc_cgn_calc_crc32(cp, LPFC_CGN_INFO_SZ,\n\t\t\t\t\t\t  LPFC_CGN_CRC32_SEED);\n\t\t\tcp->cgn_info_crc = cpu_to_le32(crc);\n\t\t}\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\tphba->cmf_active_mode = phba->cgn_p.cgn_param_mode;\n\n\t\tswitch (oldmode) {\n\t\tcase LPFC_CFG_OFF:\n\t\t\tif (phba->cgn_p.cgn_param_mode != LPFC_CFG_OFF) {\n\t\t\t\t \n\t\t\t\tlpfc_cmf_start(phba);\n\n\t\t\t\tif (phba->link_state >= LPFC_LINK_UP) {\n\t\t\t\t\tphba->cgn_reg_fpin =\n\t\t\t\t\t\tphba->cgn_init_reg_fpin;\n\t\t\t\t\tphba->cgn_reg_signal =\n\t\t\t\t\t\tphba->cgn_init_reg_signal;\n\t\t\t\t\tlpfc_issue_els_edc(phba->pport, 0);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase LPFC_CFG_MANAGED:\n\t\t\tswitch (phba->cgn_p.cgn_param_mode) {\n\t\t\tcase LPFC_CFG_OFF:\n\t\t\t\t \n\t\t\t\tlpfc_cmf_stop(phba);\n\t\t\t\tif (phba->link_state >= LPFC_LINK_UP)\n\t\t\t\t\tlpfc_issue_els_edc(phba->pport, 0);\n\t\t\t\tbreak;\n\t\t\tcase LPFC_CFG_MONITOR:\n\t\t\t\tphba->cmf_max_bytes_per_interval =\n\t\t\t\t\tphba->cmf_link_byte_count;\n\n\t\t\t\t \n\t\t\t\tqueue_work(phba->wq,\n\t\t\t\t\t   &phba->unblock_request_work);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase LPFC_CFG_MONITOR:\n\t\t\tswitch (phba->cgn_p.cgn_param_mode) {\n\t\t\tcase LPFC_CFG_OFF:\n\t\t\t\t \n\t\t\t\tlpfc_cmf_stop(phba);\n\t\t\t\tif (phba->link_state >= LPFC_LINK_UP)\n\t\t\t\t\tlpfc_issue_els_edc(phba->pport, 0);\n\t\t\t\tbreak;\n\t\t\tcase LPFC_CFG_MANAGED:\n\t\t\t\tlpfc_cmf_signal_init(phba);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (oldmode != LPFC_CFG_OFF ||\n\t\t    oldmode != phba->cgn_p.cgn_param_mode) {\n\t\t\tif (phba->cgn_p.cgn_param_mode == LPFC_CFG_MANAGED)\n\t\t\t\tscnprintf(acr_string, sizeof(acr_string), \"%u\",\n\t\t\t\t\t  phba->cgn_p.cgn_param_level0);\n\t\t\telse\n\t\t\t\tscnprintf(acr_string, sizeof(acr_string), \"NA\");\n\n\t\t\tdev_info(&phba->pcidev->dev, \"%d: \"\n\t\t\t\t \"4663 CMF: Mode %s acr %s\\n\",\n\t\t\t\t phba->brd_no,\n\t\t\t\t lpfc_cmf_mode_to_str\n\t\t\t\t [phba->cgn_p.cgn_param_mode],\n\t\t\t\t acr_string);\n\t\t}\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\"4669 FW cgn parm buf wrong magic 0x%x \"\n\t\t\t\t\"version %d\\n\", p_cgn_param->cgn_param_magic,\n\t\t\t\tp_cgn_param->cgn_param_version);\n\t}\n}\n\n \nint\nlpfc_sli4_cgn_params_read(struct lpfc_hba *phba)\n{\n\tint ret = 0;\n\tstruct lpfc_cgn_param *p_cgn_param = NULL;\n\tu32 *pdata = NULL;\n\tu32 len = 0;\n\n\t \n\tlen = sizeof(struct lpfc_cgn_param);\n\tpdata = kzalloc(len, GFP_KERNEL);\n\tif (!pdata)\n\t\treturn -ENOMEM;\n\tret = lpfc_read_object(phba, (char *)LPFC_PORT_CFG_NAME,\n\t\t\t       pdata, len);\n\n\t \n\tif (!ret) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\"4670 CGN RD OBJ returns no data\\n\");\n\t\tgoto rd_obj_err;\n\t} else if (ret < 0) {\n\t\t \n\t\tgoto rd_obj_err;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT | LOG_INIT,\n\t\t\t\"6234 READ CGN PARAMS Successful %d\\n\", len);\n\n\t \n\tp_cgn_param = (struct lpfc_cgn_param *)pdata;\n\tlpfc_cgn_params_parse(phba, p_cgn_param, len);\n\n rd_obj_err:\n\tkfree(pdata);\n\treturn ret;\n}\n\n \nstatic int\nlpfc_sli4_cgn_parm_chg_evt(struct lpfc_hba *phba)\n{\n\tint ret = 0;\n\n\tif (!phba->sli4_hba.pc_sli4_params.cmf) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\"4664 Cgn Evt when E2E off. Drop event\\n\");\n\t\treturn -EACCES;\n\t}\n\n\t \n\tret = lpfc_sli4_cgn_params_read(phba);\n\tif (ret < 0) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\"4667 Error reading Cgn Params (%d)\\n\",\n\t\t\t\tret);\n\t} else if (!ret) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\"4673 CGN Event empty object.\\n\");\n\t}\n\treturn ret;\n}\n\n \nvoid lpfc_sli4_async_event_proc(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflags;\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tphba->hba_flag &= ~ASYNC_EVENT;\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\t \n\tspin_lock_irqsave(&phba->sli4_hba.asynce_list_lock, iflags);\n\twhile (!list_empty(&phba->sli4_hba.sp_asynce_work_queue)) {\n\t\tlist_remove_head(&phba->sli4_hba.sp_asynce_work_queue,\n\t\t\t\t cq_event, struct lpfc_cq_event, list);\n\t\tspin_unlock_irqrestore(&phba->sli4_hba.asynce_list_lock,\n\t\t\t\t       iflags);\n\n\t\t \n\t\tswitch (bf_get(lpfc_trailer_code, &cq_event->cqe.mcqe_cmpl)) {\n\t\tcase LPFC_TRAILER_CODE_LINK:\n\t\t\tlpfc_sli4_async_link_evt(phba,\n\t\t\t\t\t\t &cq_event->cqe.acqe_link);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_FCOE:\n\t\t\tlpfc_sli4_async_fip_evt(phba, &cq_event->cqe.acqe_fip);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_DCBX:\n\t\t\tlpfc_sli4_async_dcbx_evt(phba,\n\t\t\t\t\t\t &cq_event->cqe.acqe_dcbx);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_GRP5:\n\t\t\tlpfc_sli4_async_grp5_evt(phba,\n\t\t\t\t\t\t &cq_event->cqe.acqe_grp5);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_FC:\n\t\t\tlpfc_sli4_async_fc_evt(phba, &cq_event->cqe.acqe_fc);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_SLI:\n\t\t\tlpfc_sli4_async_sli_evt(phba, &cq_event->cqe.acqe_sli);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_CMSTAT:\n\t\t\tlpfc_sli4_async_cmstat_evt(phba);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"1804 Invalid asynchronous event code: \"\n\t\t\t\t\t\"x%x\\n\", bf_get(lpfc_trailer_code,\n\t\t\t\t\t&cq_event->cqe.mcqe_cmpl));\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tlpfc_sli4_cq_event_release(phba, cq_event);\n\t\tspin_lock_irqsave(&phba->sli4_hba.asynce_list_lock, iflags);\n\t}\n\tspin_unlock_irqrestore(&phba->sli4_hba.asynce_list_lock, iflags);\n}\n\n \nvoid lpfc_sli4_fcf_redisc_event_proc(struct lpfc_hba *phba)\n{\n\tint rc;\n\n\tspin_lock_irq(&phba->hbalock);\n\t \n\tphba->fcf.fcf_flag &= ~FCF_REDISC_EVT;\n\t \n\tphba->fcf.failover_rec.flag = 0;\n\t \n\tphba->fcf.fcf_flag |= FCF_REDISC_FOV;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_DISCOVERY,\n\t\t\t\"2777 Start post-quiescent FCF table scan\\n\");\n\trc = lpfc_sli4_fcf_scan_read_fcf_rec(phba, LPFC_FCOE_FCF_GET_FIRST);\n\tif (rc)\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2747 Issue FCF scan read FCF mailbox \"\n\t\t\t\t\"command failed 0x%x\\n\", rc);\n}\n\n \nint\nlpfc_api_table_setup(struct lpfc_hba *phba, uint8_t dev_grp)\n{\n\tint rc;\n\n\t \n\tphba->pci_dev_grp = dev_grp;\n\n\t \n\tif (dev_grp == LPFC_PCI_DEV_OC)\n\t\tphba->sli_rev = LPFC_SLI_REV4;\n\n\t \n\trc = lpfc_init_api_table_setup(phba, dev_grp);\n\tif (rc)\n\t\treturn -ENODEV;\n\t \n\trc = lpfc_scsi_api_table_setup(phba, dev_grp);\n\tif (rc)\n\t\treturn -ENODEV;\n\t \n\trc = lpfc_sli_api_table_setup(phba, dev_grp);\n\tif (rc)\n\t\treturn -ENODEV;\n\t \n\trc = lpfc_mbox_api_table_setup(phba, dev_grp);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\treturn 0;\n}\n\n \nstatic void lpfc_log_intr_mode(struct lpfc_hba *phba, uint32_t intr_mode)\n{\n\tswitch (intr_mode) {\n\tcase 0:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0470 Enable INTx interrupt mode.\\n\");\n\t\tbreak;\n\tcase 1:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0481 Enabled MSI interrupt mode.\\n\");\n\t\tbreak;\n\tcase 2:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0480 Enabled MSI-X interrupt mode.\\n\");\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0482 Illegal interrupt mode.\\n\");\n\t\tbreak;\n\t}\n\treturn;\n}\n\n \nstatic int\nlpfc_enable_pci_dev(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev;\n\n\t \n\tif (!phba->pcidev)\n\t\tgoto out_error;\n\telse\n\t\tpdev = phba->pcidev;\n\t \n\tif (pci_enable_device_mem(pdev))\n\t\tgoto out_error;\n\t \n\tif (pci_request_mem_regions(pdev, LPFC_DRIVER_NAME))\n\t\tgoto out_disable_device;\n\t \n\tpci_set_master(pdev);\n\tpci_try_set_mwi(pdev);\n\tpci_save_state(pdev);\n\n\t \n\tif (pci_is_pcie(pdev))\n\t\tpdev->needs_freset = 1;\n\n\treturn 0;\n\nout_disable_device:\n\tpci_disable_device(pdev);\nout_error:\n\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\"1401 Failed to enable pci device\\n\");\n\treturn -ENODEV;\n}\n\n \nstatic void\nlpfc_disable_pci_dev(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev;\n\n\t \n\tif (!phba->pcidev)\n\t\treturn;\n\telse\n\t\tpdev = phba->pcidev;\n\t \n\tpci_release_mem_regions(pdev);\n\tpci_disable_device(pdev);\n\n\treturn;\n}\n\n \nvoid\nlpfc_reset_hba(struct lpfc_hba *phba)\n{\n\tint rc = 0;\n\n\t \n\tif (!phba->cfg_enable_hba_reset) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn;\n\t}\n\n\t \n\tif (phba->sli.sli_flag & LPFC_SLI_ACTIVE) {\n\t\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\t} else {\n\t\tif (test_bit(MBX_TMO_ERR, &phba->bit_flags)) {\n\t\t\t \n\t\t\trc = lpfc_pci_function_reset(phba);\n\t\t\tlpfc_els_flush_all_cmd(phba);\n\t\t}\n\t\tlpfc_offline_prep(phba, LPFC_MBX_NO_WAIT);\n\t\tlpfc_sli_flush_io_rings(phba);\n\t}\n\tlpfc_offline(phba);\n\tclear_bit(MBX_TMO_ERR, &phba->bit_flags);\n\tif (unlikely(rc)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\"8888 PCI function reset failed rc %x\\n\",\n\t\t\t\trc);\n\t} else {\n\t\tlpfc_sli_brdrestart(phba);\n\t\tlpfc_online(phba);\n\t\tlpfc_unblock_mgmt_io(phba);\n\t}\n}\n\n \nuint16_t\nlpfc_sli_sriov_nr_virtfn_get(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev = phba->pcidev;\n\tuint16_t nr_virtfn;\n\tint pos;\n\n\tpos = pci_find_ext_capability(pdev, PCI_EXT_CAP_ID_SRIOV);\n\tif (pos == 0)\n\t\treturn 0;\n\n\tpci_read_config_word(pdev, pos + PCI_SRIOV_TOTAL_VF, &nr_virtfn);\n\treturn nr_virtfn;\n}\n\n \nint\nlpfc_sli_probe_sriov_nr_virtfn(struct lpfc_hba *phba, int nr_vfn)\n{\n\tstruct pci_dev *pdev = phba->pcidev;\n\tuint16_t max_nr_vfn;\n\tint rc;\n\n\tmax_nr_vfn = lpfc_sli_sriov_nr_virtfn_get(phba);\n\tif (nr_vfn > max_nr_vfn) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3057 Requested vfs (%d) greater than \"\n\t\t\t\t\"supported vfs (%d)\", nr_vfn, max_nr_vfn);\n\t\treturn -EINVAL;\n\t}\n\n\trc = pci_enable_sriov(pdev, nr_vfn);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"2806 Failed to enable sriov on this device \"\n\t\t\t\t\"with vfn number nr_vf:%d, rc:%d\\n\",\n\t\t\t\tnr_vfn, rc);\n\t} else\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"2807 Successful enable sriov on this device \"\n\t\t\t\t\"with vfn number nr_vf:%d\\n\", nr_vfn);\n\treturn rc;\n}\n\nstatic void\nlpfc_unblock_requests_work(struct work_struct *work)\n{\n\tstruct lpfc_hba *phba = container_of(work, struct lpfc_hba,\n\t\t\t\t\t     unblock_request_work);\n\n\tlpfc_unblock_requests(phba);\n}\n\n \nstatic int\nlpfc_setup_driver_resource_phase1(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\n\t \n\tatomic_set(&phba->fast_event_count, 0);\n\tatomic_set(&phba->dbg_log_idx, 0);\n\tatomic_set(&phba->dbg_log_cnt, 0);\n\tatomic_set(&phba->dbg_log_dmping, 0);\n\tspin_lock_init(&phba->hbalock);\n\n\t \n\tspin_lock_init(&phba->port_list_lock);\n\tINIT_LIST_HEAD(&phba->port_list);\n\n\tINIT_LIST_HEAD(&phba->work_list);\n\n\t \n\tinit_waitqueue_head(&phba->work_waitq);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"1403 Protocols supported %s %s %s\\n\",\n\t\t\t((phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP) ?\n\t\t\t\t\"SCSI\" : \" \"),\n\t\t\t((phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) ?\n\t\t\t\t\"NVME\" : \" \"),\n\t\t\t(phba->nvmet_support ? \"NVMET\" : \" \"));\n\n\t \n\tspin_lock_init(&phba->scsi_buf_list_get_lock);\n\tINIT_LIST_HEAD(&phba->lpfc_scsi_buf_list_get);\n\tspin_lock_init(&phba->scsi_buf_list_put_lock);\n\tINIT_LIST_HEAD(&phba->lpfc_scsi_buf_list_put);\n\n\t \n\tINIT_LIST_HEAD(&phba->fabric_iocb_list);\n\n\t \n\tINIT_LIST_HEAD(&phba->elsbuf);\n\n\t \n\tINIT_LIST_HEAD(&phba->fcf_conn_rec_list);\n\n\t \n\tspin_lock_init(&phba->devicelock);\n\tINIT_LIST_HEAD(&phba->luns);\n\n\t \n\ttimer_setup(&psli->mbox_tmo, lpfc_mbox_timeout, 0);\n\t \n\ttimer_setup(&phba->fabric_block_timer, lpfc_fabric_block_timeout, 0);\n\t \n\ttimer_setup(&phba->eratt_poll, lpfc_poll_eratt, 0);\n\t \n\ttimer_setup(&phba->hb_tmofunc, lpfc_hb_timeout, 0);\n\n\tINIT_DELAYED_WORK(&phba->eq_delay_work, lpfc_hb_eq_delay_work);\n\n\tINIT_DELAYED_WORK(&phba->idle_stat_delay_work,\n\t\t\t  lpfc_idle_stat_delay_work);\n\tINIT_WORK(&phba->unblock_request_work, lpfc_unblock_requests_work);\n\treturn 0;\n}\n\n \nstatic int\nlpfc_sli_driver_resource_setup(struct lpfc_hba *phba)\n{\n\tint rc, entry_sz;\n\n\t \n\n\t \n\ttimer_setup(&phba->fcp_poll_timer, lpfc_poll_timeout, 0);\n\n\t \n\tphba->work_ha_mask = (HA_ERATT | HA_MBATT | HA_LATT);\n\tphba->work_ha_mask |= (HA_RXMASK << (LPFC_ELS_RING * 4));\n\n\t \n\tlpfc_get_cfgparam(phba);\n\t \n\n\trc = lpfc_setup_driver_resource_phase1(phba);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\tif (!phba->sli.sli3_ring)\n\t\tphba->sli.sli3_ring = kcalloc(LPFC_SLI3_MAX_RING,\n\t\t\t\t\t      sizeof(struct lpfc_sli_ring),\n\t\t\t\t\t      GFP_KERNEL);\n\tif (!phba->sli.sli3_ring)\n\t\treturn -ENOMEM;\n\n\t \n\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tentry_sz = sizeof(struct sli4_sge);\n\telse\n\t\tentry_sz = sizeof(struct ulp_bde64);\n\n\t \n\tif (phba->cfg_enable_bg) {\n\t\t \n\t\tphba->cfg_sg_dma_buf_size = sizeof(struct fcp_cmnd) +\n\t\t\tsizeof(struct fcp_rsp) +\n\t\t\t(LPFC_MAX_SG_SEG_CNT * entry_sz);\n\n\t\tif (phba->cfg_sg_seg_cnt > LPFC_MAX_SG_SEG_CNT_DIF)\n\t\t\tphba->cfg_sg_seg_cnt = LPFC_MAX_SG_SEG_CNT_DIF;\n\n\t\t \n\t\tphba->cfg_total_seg_cnt = LPFC_MAX_SG_SEG_CNT;\n\t} else {\n\t\t \n\t\tphba->cfg_sg_dma_buf_size = sizeof(struct fcp_cmnd) +\n\t\t\tsizeof(struct fcp_rsp) +\n\t\t\t((phba->cfg_sg_seg_cnt + 2) * entry_sz);\n\n\t\t \n\t\tphba->cfg_total_seg_cnt = phba->cfg_sg_seg_cnt + 2;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_FCP,\n\t\t\t\"9088 INIT sg_tablesize:%d dmabuf_size:%d total_bde:%d\\n\",\n\t\t\tphba->cfg_sg_seg_cnt, phba->cfg_sg_dma_buf_size,\n\t\t\tphba->cfg_total_seg_cnt);\n\n\tphba->max_vpi = LPFC_MAX_VPI;\n\t \n\tphba->max_vports = 0;\n\n\t \n\tlpfc_sli_setup(phba);\n\tlpfc_sli_queue_init(phba);\n\n\t \n\tif (lpfc_mem_alloc(phba, BPL_ALIGN_SZ))\n\t\treturn -ENOMEM;\n\n\tphba->lpfc_sg_dma_buf_pool =\n\t\tdma_pool_create(\"lpfc_sg_dma_buf_pool\",\n\t\t\t\t&phba->pcidev->dev, phba->cfg_sg_dma_buf_size,\n\t\t\t\tBPL_ALIGN_SZ, 0);\n\n\tif (!phba->lpfc_sg_dma_buf_pool)\n\t\tgoto fail_free_mem;\n\n\tphba->lpfc_cmd_rsp_buf_pool =\n\t\t\tdma_pool_create(\"lpfc_cmd_rsp_buf_pool\",\n\t\t\t\t\t&phba->pcidev->dev,\n\t\t\t\t\tsizeof(struct fcp_cmnd) +\n\t\t\t\t\tsizeof(struct fcp_rsp),\n\t\t\t\t\tBPL_ALIGN_SZ, 0);\n\n\tif (!phba->lpfc_cmd_rsp_buf_pool)\n\t\tgoto fail_free_dma_buf_pool;\n\n\t \n\tif (phba->cfg_sriov_nr_virtfn > 0) {\n\t\trc = lpfc_sli_probe_sriov_nr_virtfn(phba,\n\t\t\t\t\t\t phba->cfg_sriov_nr_virtfn);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"2808 Requested number of SR-IOV \"\n\t\t\t\t\t\"virtual functions (%d) is not \"\n\t\t\t\t\t\"supported\\n\",\n\t\t\t\t\tphba->cfg_sriov_nr_virtfn);\n\t\t\tphba->cfg_sriov_nr_virtfn = 0;\n\t\t}\n\t}\n\n\treturn 0;\n\nfail_free_dma_buf_pool:\n\tdma_pool_destroy(phba->lpfc_sg_dma_buf_pool);\n\tphba->lpfc_sg_dma_buf_pool = NULL;\nfail_free_mem:\n\tlpfc_mem_free(phba);\n\treturn -ENOMEM;\n}\n\n \nstatic void\nlpfc_sli_driver_resource_unset(struct lpfc_hba *phba)\n{\n\t \n\tlpfc_mem_free_all(phba);\n\n\treturn;\n}\n\n \nstatic int\nlpfc_sli4_driver_resource_setup(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tMAILBOX_t *mb;\n\tint rc, i, max_buf_size;\n\tint longs;\n\tint extra;\n\tuint64_t wwn;\n\tu32 if_type;\n\tu32 if_fam;\n\n\tphba->sli4_hba.num_present_cpu = lpfc_present_cpu;\n\tphba->sli4_hba.num_possible_cpu = cpumask_last(cpu_possible_mask) + 1;\n\tphba->sli4_hba.curr_disp_cpu = 0;\n\n\t \n\tlpfc_get_cfgparam(phba);\n\n\t \n\trc = lpfc_setup_driver_resource_phase1(phba);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\t \n\trc = lpfc_sli4_post_status_check(phba);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\t \n\n\t \n\tphba->wq = alloc_workqueue(\"lpfc_wq\", WQ_MEM_RECLAIM, 0);\n\tif (!phba->wq)\n\t\treturn -ENOMEM;\n\n\t \n\n\ttimer_setup(&phba->rrq_tmr, lpfc_rrq_timeout, 0);\n\n\t \n\ttimer_setup(&phba->fcf.redisc_wait, lpfc_sli4_fcf_redisc_wait_tmo, 0);\n\n\t \n\thrtimer_init(&phba->cmf_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\tphba->cmf_timer.function = lpfc_cmf_timer;\n\t \n\thrtimer_init(&phba->cmf_stats_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\tphba->cmf_stats_timer.function = lpfc_cmf_stats_timer;\n\n\t \n\tmemset((uint8_t *)&phba->mbox_ext_buf_ctx, 0,\n\t\tsizeof(struct lpfc_mbox_ext_buf_ctx));\n\tINIT_LIST_HEAD(&phba->mbox_ext_buf_ctx.ext_dmabuf_list);\n\n\tphba->max_vpi = LPFC_MAX_VPI;\n\n\t \n\tphba->max_vports = 0;\n\n\t \n\tphba->valid_vlan = 0;\n\tphba->fc_map[0] = LPFC_FCOE_FCF_MAP0;\n\tphba->fc_map[1] = LPFC_FCOE_FCF_MAP1;\n\tphba->fc_map[2] = LPFC_FCOE_FCF_MAP2;\n\n\t \n\n\t \n\tINIT_LIST_HEAD(&phba->hbqs[LPFC_ELS_HBQ].hbq_buffer_list);\n\tphba->hbqs[LPFC_ELS_HBQ].hbq_alloc_buffer = lpfc_sli4_rb_alloc;\n\tphba->hbqs[LPFC_ELS_HBQ].hbq_free_buffer = lpfc_sli4_rb_free;\n\n\t \n\tif (lpfc_is_vmid_enabled(phba))\n\t\ttimer_setup(&phba->inactive_vmid_poll, lpfc_vmid_poll, 0);\n\n\t \n\t \n\tspin_lock_init(&phba->sli4_hba.abts_io_buf_list_lock);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_abts_io_buf_list);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t \n\t\tspin_lock_init(&phba->sli4_hba.abts_nvmet_buf_list_lock);\n\t\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_abts_nvmet_ctx_list);\n\t\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_nvmet_io_wait_list);\n\t\tspin_lock_init(&phba->sli4_hba.t_active_list_lock);\n\t\tINIT_LIST_HEAD(&phba->sli4_hba.t_active_ctx_list);\n\t}\n\n\t \n\tspin_lock_init(&phba->sli4_hba.sgl_list_lock);\n\tspin_lock_init(&phba->sli4_hba.nvmet_io_wait_lock);\n\tspin_lock_init(&phba->sli4_hba.asynce_list_lock);\n\tspin_lock_init(&phba->sli4_hba.els_xri_abrt_list_lock);\n\n\t \n\n\t \n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_cqe_event_pool);\n\t \n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_queue_event);\n\t \n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_asynce_work_queue);\n\t \n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_els_xri_aborted_work_queue);\n\t \n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_unsol_work_queue);\n\n\t \n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_rpi_blk_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_xri_blk_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_vfi_blk_list);\n\tINIT_LIST_HEAD(&phba->lpfc_vpi_blk_list);\n\n\t \n\tINIT_LIST_HEAD(&phba->sli.mboxq);\n\tINIT_LIST_HEAD(&phba->sli.mboxq_cmpl);\n\n\t \n\tphba->sli4_hba.lnk_info.optic_state = 0xff;\n\n\t \n\trc = lpfc_mem_alloc(phba, SGL_ALIGN_SZ);\n\tif (rc)\n\t\tgoto out_destroy_workqueue;\n\n\t \n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) >=\n\t    LPFC_SLI_INTF_IF_TYPE_2) {\n\t\trc = lpfc_pci_function_reset(phba);\n\t\tif (unlikely(rc)) {\n\t\t\trc = -ENODEV;\n\t\t\tgoto out_free_mem;\n\t\t}\n\t\tphba->temp_sensor_support = 1;\n\t}\n\n\t \n\trc = lpfc_create_bootstrap_mbox(phba);\n\tif (unlikely(rc))\n\t\tgoto out_free_mem;\n\n\t \n\trc = lpfc_setup_endian_order(phba);\n\tif (unlikely(rc))\n\t\tgoto out_free_bsmbx;\n\n\t \n\trc = lpfc_sli4_read_config(phba);\n\tif (unlikely(rc))\n\t\tgoto out_free_bsmbx;\n\n\tif (phba->sli4_hba.fawwpn_flag & LPFC_FAWWPN_CONFIG) {\n\t\t \n\t\tphba->sli4_hba.fawwpn_flag |= LPFC_FAWWPN_FABRIC;\n\t}\n\n\trc = lpfc_mem_alloc_active_rrq_pool_s4(phba);\n\tif (unlikely(rc))\n\t\tgoto out_free_bsmbx;\n\n\t \n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) ==\n\t    LPFC_SLI_INTF_IF_TYPE_0) {\n\t\trc = lpfc_pci_function_reset(phba);\n\t\tif (unlikely(rc))\n\t\t\tgoto out_free_bsmbx;\n\t}\n\n\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool,\n\t\t\t\t\t\t       GFP_KERNEL);\n\tif (!mboxq) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free_bsmbx;\n\t}\n\n\t \n\tphba->nvmet_support = 0;\n\tif (lpfc_enable_nvmet_cnt) {\n\n\t\t \n\t\tlpfc_read_nv(phba, mboxq);\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"6016 Mailbox failed , mbxCmd x%x \"\n\t\t\t\t\t\"READ_NV, mbxStatus x%x\\n\",\n\t\t\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\t\t\tbf_get(lpfc_mqe_status, &mboxq->u.mqe));\n\t\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\t\trc = -EIO;\n\t\t\tgoto out_free_bsmbx;\n\t\t}\n\t\tmb = &mboxq->u.mb;\n\t\tmemcpy(&wwn, (char *)mb->un.varRDnvp.nodename,\n\t\t       sizeof(uint64_t));\n\t\twwn = cpu_to_be64(wwn);\n\t\tphba->sli4_hba.wwnn.u.name = wwn;\n\t\tmemcpy(&wwn, (char *)mb->un.varRDnvp.portname,\n\t\t       sizeof(uint64_t));\n\t\t \n\t\twwn = cpu_to_be64(wwn);\n\t\tphba->sli4_hba.wwpn.u.name = wwn;\n\n\t\t \n\t\tfor (i = 0; i < lpfc_enable_nvmet_cnt; i++) {\n\t\t\tif (wwn == lpfc_enable_nvmet[i]) {\n#if (IS_ENABLED(CONFIG_NVME_TARGET_FC))\n\t\t\t\tif (lpfc_nvmet_mem_alloc(phba))\n\t\t\t\t\tbreak;\n\n\t\t\t\tphba->nvmet_support = 1;  \n\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6017 NVME Target %016llx\\n\",\n\t\t\t\t\t\twwn);\n#else\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6021 Can't enable NVME Target.\"\n\t\t\t\t\t\t\" NVME_TARGET_FC infrastructure\"\n\t\t\t\t\t\t\" is not in kernel\\n\");\n#endif\n\t\t\t\t \n\t\t\t\tphba->cfg_xri_rebalancing = 0;\n\t\t\t\tif (phba->irq_chann_mode == NHT_MODE) {\n\t\t\t\t\tphba->cfg_irq_chann =\n\t\t\t\t\t\tphba->sli4_hba.num_present_cpu;\n\t\t\t\t\tphba->cfg_hdw_queue =\n\t\t\t\t\t\tphba->sli4_hba.num_present_cpu;\n\t\t\t\t\tphba->irq_chann_mode = NORMAL_MODE;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tlpfc_nvme_mod_param_dep(phba);\n\n\t \n\trc = lpfc_get_sli4_parameters(phba, mboxq);\n\tif (rc) {\n\t\tif_type = bf_get(lpfc_sli_intf_if_type,\n\t\t\t\t &phba->sli4_hba.sli_intf);\n\t\tif_fam = bf_get(lpfc_sli_intf_sli_family,\n\t\t\t\t&phba->sli4_hba.sli_intf);\n\t\tif (phba->sli4_hba.extents_in_use &&\n\t\t    phba->sli4_hba.rpi_hdrs_in_use) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2999 Unsupported SLI4 Parameters \"\n\t\t\t\t\t\"Extents and RPI headers enabled.\\n\");\n\t\t\tif (if_type == LPFC_SLI_INTF_IF_TYPE_0 &&\n\t\t\t    if_fam ==  LPFC_SLI_INTF_FAMILY_BE2) {\n\t\t\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\t\t\trc = -EIO;\n\t\t\t\tgoto out_free_bsmbx;\n\t\t\t}\n\t\t}\n\t\tif (!(if_type == LPFC_SLI_INTF_IF_TYPE_0 &&\n\t\t      if_fam == LPFC_SLI_INTF_FAMILY_BE2)) {\n\t\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\t\trc = -EIO;\n\t\t\tgoto out_free_bsmbx;\n\t\t}\n\t}\n\n\t \n\textra = 2;\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\textra++;\n\n\t \n\tmax_buf_size = (2 * SLI4_PAGE_SIZE);\n\n\t \n\tif (phba->sli3_options & LPFC_SLI3_BG_ENABLED) {\n\t\t \n\n\t\t \n\t\tphba->cfg_sg_dma_buf_size = sizeof(struct fcp_cmnd) +\n\t\t\t\tsizeof(struct fcp_rsp) + max_buf_size;\n\n\t\t \n\t\tphba->cfg_total_seg_cnt = LPFC_MAX_SGL_SEG_CNT;\n\n\t\t \n\t\tif (phba->cfg_enable_bg &&\n\t\t    phba->cfg_sg_seg_cnt > LPFC_MAX_BG_SLI4_SEG_CNT_DIF)\n\t\t\tphba->cfg_scsi_seg_cnt = LPFC_MAX_BG_SLI4_SEG_CNT_DIF;\n\t\telse\n\t\t\tphba->cfg_scsi_seg_cnt = phba->cfg_sg_seg_cnt;\n\n\t} else {\n\t\t \n\t\tphba->cfg_sg_dma_buf_size = sizeof(struct fcp_cmnd) +\n\t\t\t\tsizeof(struct fcp_rsp) +\n\t\t\t\t((phba->cfg_sg_seg_cnt + extra) *\n\t\t\t\tsizeof(struct sli4_sge));\n\n\t\t \n\t\tphba->cfg_total_seg_cnt = phba->cfg_sg_seg_cnt + extra;\n\t\tphba->cfg_scsi_seg_cnt = phba->cfg_sg_seg_cnt;\n\n\t\t \n\t}\n\n\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\tphba->cfg_sg_dma_buf_size = LPFC_DEFAULT_XPSGL_SIZE;\n\telse if (phba->cfg_sg_dma_buf_size  <= LPFC_MIN_SG_SLI4_BUF_SZ)\n\t\tphba->cfg_sg_dma_buf_size = LPFC_MIN_SG_SLI4_BUF_SZ;\n\telse\n\t\tphba->cfg_sg_dma_buf_size =\n\t\t\t\tSLI4_PAGE_ALIGN(phba->cfg_sg_dma_buf_size);\n\n\tphba->border_sge_num = phba->cfg_sg_dma_buf_size /\n\t\t\t       sizeof(struct sli4_sge);\n\n\t \n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tif (phba->cfg_sg_seg_cnt > LPFC_MAX_NVME_SEG_CNT) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_NVME | LOG_INIT,\n\t\t\t\t\t\"6300 Reducing NVME sg segment \"\n\t\t\t\t\t\"cnt to %d\\n\",\n\t\t\t\t\tLPFC_MAX_NVME_SEG_CNT);\n\t\t\tphba->cfg_nvme_seg_cnt = LPFC_MAX_NVME_SEG_CNT;\n\t\t} else\n\t\t\tphba->cfg_nvme_seg_cnt = phba->cfg_sg_seg_cnt;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_FCP,\n\t\t\t\"9087 sg_seg_cnt:%d dmabuf_size:%d \"\n\t\t\t\"total:%d scsi:%d nvme:%d\\n\",\n\t\t\tphba->cfg_sg_seg_cnt, phba->cfg_sg_dma_buf_size,\n\t\t\tphba->cfg_total_seg_cnt,  phba->cfg_scsi_seg_cnt,\n\t\t\tphba->cfg_nvme_seg_cnt);\n\n\tif (phba->cfg_sg_dma_buf_size < SLI4_PAGE_SIZE)\n\t\ti = phba->cfg_sg_dma_buf_size;\n\telse\n\t\ti = SLI4_PAGE_SIZE;\n\n\tphba->lpfc_sg_dma_buf_pool =\n\t\t\tdma_pool_create(\"lpfc_sg_dma_buf_pool\",\n\t\t\t\t\t&phba->pcidev->dev,\n\t\t\t\t\tphba->cfg_sg_dma_buf_size,\n\t\t\t\t\ti, 0);\n\tif (!phba->lpfc_sg_dma_buf_pool) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free_bsmbx;\n\t}\n\n\tphba->lpfc_cmd_rsp_buf_pool =\n\t\t\tdma_pool_create(\"lpfc_cmd_rsp_buf_pool\",\n\t\t\t\t\t&phba->pcidev->dev,\n\t\t\t\t\tsizeof(struct fcp_cmnd) +\n\t\t\t\t\tsizeof(struct fcp_rsp),\n\t\t\t\t\ti, 0);\n\tif (!phba->lpfc_cmd_rsp_buf_pool) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free_sg_dma_buf;\n\t}\n\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\n\t \n\tlpfc_sli4_oas_verify(phba);\n\n\t \n\tlpfc_sli4_ras_init(phba);\n\n\t \n\trc = lpfc_sli4_queue_verify(phba);\n\tif (rc)\n\t\tgoto out_free_cmd_rsp_buf;\n\n\t \n\trc = lpfc_sli4_cq_event_pool_create(phba);\n\tif (rc)\n\t\tgoto out_free_cmd_rsp_buf;\n\n\t \n\tlpfc_init_sgl_list(phba);\n\n\t \n\trc = lpfc_init_active_sgl_array(phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1430 Failed to initialize sgl list.\\n\");\n\t\tgoto out_destroy_cq_event_pool;\n\t}\n\trc = lpfc_sli4_init_rpi_hdrs(phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1432 Failed to initialize rpi headers.\\n\");\n\t\tgoto out_free_active_sgl;\n\t}\n\n\t \n\tlongs = (LPFC_SLI4_FCF_TBL_INDX_MAX + BITS_PER_LONG - 1)/BITS_PER_LONG;\n\tphba->fcf.fcf_rr_bmask = kcalloc(longs, sizeof(unsigned long),\n\t\t\t\t\t GFP_KERNEL);\n\tif (!phba->fcf.fcf_rr_bmask) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2759 Failed allocate memory for FCF round \"\n\t\t\t\t\"robin failover bmask\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_remove_rpi_hdrs;\n\t}\n\n\tphba->sli4_hba.hba_eq_hdl = kcalloc(phba->cfg_irq_chann,\n\t\t\t\t\t    sizeof(struct lpfc_hba_eq_hdl),\n\t\t\t\t\t    GFP_KERNEL);\n\tif (!phba->sli4_hba.hba_eq_hdl) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2572 Failed allocate memory for \"\n\t\t\t\t\"fast-path per-EQ handle array\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_fcf_rr_bmask;\n\t}\n\n\tphba->sli4_hba.cpu_map = kcalloc(phba->sli4_hba.num_possible_cpu,\n\t\t\t\t\tsizeof(struct lpfc_vector_map_info),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!phba->sli4_hba.cpu_map) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3327 Failed allocate memory for msi-x \"\n\t\t\t\t\"interrupt vector mapping\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_hba_eq_hdl;\n\t}\n\n\tphba->sli4_hba.eq_info = alloc_percpu(struct lpfc_eq_intr_info);\n\tif (!phba->sli4_hba.eq_info) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3321 Failed allocation for per_cpu stats\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_hba_cpu_map;\n\t}\n\n\tphba->sli4_hba.idle_stat = kcalloc(phba->sli4_hba.num_possible_cpu,\n\t\t\t\t\t   sizeof(*phba->sli4_hba.idle_stat),\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!phba->sli4_hba.idle_stat) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3390 Failed allocation for idle_stat\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_hba_eq_info;\n\t}\n\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\tphba->sli4_hba.c_stat = alloc_percpu(struct lpfc_hdwq_stat);\n\tif (!phba->sli4_hba.c_stat) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3332 Failed allocating per cpu hdwq stats\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_hba_idle_stat;\n\t}\n#endif\n\n\tphba->cmf_stat = alloc_percpu(struct lpfc_cgn_stat);\n\tif (!phba->cmf_stat) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3331 Failed allocating per cpu cgn stats\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_hba_hdwq_info;\n\t}\n\n\t \n\tif (phba->cfg_sriov_nr_virtfn > 0) {\n\t\trc = lpfc_sli_probe_sriov_nr_virtfn(phba,\n\t\t\t\t\t\t phba->cfg_sriov_nr_virtfn);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"3020 Requested number of SR-IOV \"\n\t\t\t\t\t\"virtual functions (%d) is not \"\n\t\t\t\t\t\"supported\\n\",\n\t\t\t\t\tphba->cfg_sriov_nr_virtfn);\n\t\t\tphba->cfg_sriov_nr_virtfn = 0;\n\t\t}\n\t}\n\n\treturn 0;\n\nout_free_hba_hdwq_info:\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\tfree_percpu(phba->sli4_hba.c_stat);\nout_free_hba_idle_stat:\n#endif\n\tkfree(phba->sli4_hba.idle_stat);\nout_free_hba_eq_info:\n\tfree_percpu(phba->sli4_hba.eq_info);\nout_free_hba_cpu_map:\n\tkfree(phba->sli4_hba.cpu_map);\nout_free_hba_eq_hdl:\n\tkfree(phba->sli4_hba.hba_eq_hdl);\nout_free_fcf_rr_bmask:\n\tkfree(phba->fcf.fcf_rr_bmask);\nout_remove_rpi_hdrs:\n\tlpfc_sli4_remove_rpi_hdrs(phba);\nout_free_active_sgl:\n\tlpfc_free_active_sgl(phba);\nout_destroy_cq_event_pool:\n\tlpfc_sli4_cq_event_pool_destroy(phba);\nout_free_cmd_rsp_buf:\n\tdma_pool_destroy(phba->lpfc_cmd_rsp_buf_pool);\n\tphba->lpfc_cmd_rsp_buf_pool = NULL;\nout_free_sg_dma_buf:\n\tdma_pool_destroy(phba->lpfc_sg_dma_buf_pool);\n\tphba->lpfc_sg_dma_buf_pool = NULL;\nout_free_bsmbx:\n\tlpfc_destroy_bootstrap_mbox(phba);\nout_free_mem:\n\tlpfc_mem_free(phba);\nout_destroy_workqueue:\n\tdestroy_workqueue(phba->wq);\n\tphba->wq = NULL;\n\treturn rc;\n}\n\n \nstatic void\nlpfc_sli4_driver_resource_unset(struct lpfc_hba *phba)\n{\n\tstruct lpfc_fcf_conn_entry *conn_entry, *next_conn_entry;\n\n\tfree_percpu(phba->sli4_hba.eq_info);\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\tfree_percpu(phba->sli4_hba.c_stat);\n#endif\n\tfree_percpu(phba->cmf_stat);\n\tkfree(phba->sli4_hba.idle_stat);\n\n\t \n\tkfree(phba->sli4_hba.cpu_map);\n\tphba->sli4_hba.num_possible_cpu = 0;\n\tphba->sli4_hba.num_present_cpu = 0;\n\tphba->sli4_hba.curr_disp_cpu = 0;\n\tcpumask_clear(&phba->sli4_hba.irq_aff_mask);\n\n\t \n\tkfree(phba->sli4_hba.hba_eq_hdl);\n\n\t \n\tlpfc_sli4_remove_rpi_hdrs(phba);\n\tlpfc_sli4_remove_rpis(phba);\n\n\t \n\tkfree(phba->fcf.fcf_rr_bmask);\n\n\t \n\tlpfc_free_active_sgl(phba);\n\tlpfc_free_els_sgl_list(phba);\n\tlpfc_free_nvmet_sgl_list(phba);\n\n\t \n\tlpfc_sli4_cq_event_release_all(phba);\n\tlpfc_sli4_cq_event_pool_destroy(phba);\n\n\t \n\tlpfc_sli4_dealloc_resource_identifiers(phba);\n\n\t \n\tlpfc_destroy_bootstrap_mbox(phba);\n\n\t \n\tlpfc_mem_free_all(phba);\n\n\t \n\tlist_for_each_entry_safe(conn_entry, next_conn_entry,\n\t\t&phba->fcf_conn_rec_list, list) {\n\t\tlist_del_init(&conn_entry->list);\n\t\tkfree(conn_entry);\n\t}\n\n\treturn;\n}\n\n \nint\nlpfc_init_api_table_setup(struct lpfc_hba *phba, uint8_t dev_grp)\n{\n\tphba->lpfc_hba_init_link = lpfc_hba_init_link;\n\tphba->lpfc_hba_down_link = lpfc_hba_down_link;\n\tphba->lpfc_selective_reset = lpfc_selective_reset;\n\tswitch (dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\tphba->lpfc_hba_down_post = lpfc_hba_down_post_s3;\n\t\tphba->lpfc_handle_eratt = lpfc_handle_eratt_s3;\n\t\tphba->lpfc_stop_port = lpfc_stop_port_s3;\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\tphba->lpfc_hba_down_post = lpfc_hba_down_post_s4;\n\t\tphba->lpfc_handle_eratt = lpfc_handle_eratt_s4;\n\t\tphba->lpfc_stop_port = lpfc_stop_port_s4;\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1431 Invalid HBA PCI-device group: 0x%x\\n\",\n\t\t\t\tdev_grp);\n\t\treturn -ENODEV;\n\t}\n\treturn 0;\n}\n\n \nstatic int\nlpfc_setup_driver_resource_phase2(struct lpfc_hba *phba)\n{\n\tint error;\n\n\t \n\tphba->worker_thread = kthread_run(lpfc_do_work, phba,\n\t\t\t\t\t  \"lpfc_worker_%d\", phba->brd_no);\n\tif (IS_ERR(phba->worker_thread)) {\n\t\terror = PTR_ERR(phba->worker_thread);\n\t\treturn error;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void\nlpfc_unset_driver_resource_phase2(struct lpfc_hba *phba)\n{\n\tif (phba->wq) {\n\t\tdestroy_workqueue(phba->wq);\n\t\tphba->wq = NULL;\n\t}\n\n\t \n\tif (phba->worker_thread)\n\t\tkthread_stop(phba->worker_thread);\n}\n\n \nvoid\nlpfc_free_iocb_list(struct lpfc_hba *phba)\n{\n\tstruct lpfc_iocbq *iocbq_entry = NULL, *iocbq_next = NULL;\n\n\tspin_lock_irq(&phba->hbalock);\n\tlist_for_each_entry_safe(iocbq_entry, iocbq_next,\n\t\t\t\t &phba->lpfc_iocb_list, list) {\n\t\tlist_del(&iocbq_entry->list);\n\t\tkfree(iocbq_entry);\n\t\tphba->total_iocbq_bufs--;\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\n\treturn;\n}\n\n \nint\nlpfc_init_iocb_list(struct lpfc_hba *phba, int iocb_count)\n{\n\tstruct lpfc_iocbq *iocbq_entry = NULL;\n\tuint16_t iotag;\n\tint i;\n\n\t \n\tINIT_LIST_HEAD(&phba->lpfc_iocb_list);\n\tfor (i = 0; i < iocb_count; i++) {\n\t\tiocbq_entry = kzalloc(sizeof(struct lpfc_iocbq), GFP_KERNEL);\n\t\tif (iocbq_entry == NULL) {\n\t\t\tprintk(KERN_ERR \"%s: only allocated %d iocbs of \"\n\t\t\t\t\"expected %d count. Unloading driver.\\n\",\n\t\t\t\t__func__, i, iocb_count);\n\t\t\tgoto out_free_iocbq;\n\t\t}\n\n\t\tiotag = lpfc_sli_next_iotag(phba, iocbq_entry);\n\t\tif (iotag == 0) {\n\t\t\tkfree(iocbq_entry);\n\t\t\tprintk(KERN_ERR \"%s: failed to allocate IOTAG. \"\n\t\t\t\t\"Unloading driver.\\n\", __func__);\n\t\t\tgoto out_free_iocbq;\n\t\t}\n\t\tiocbq_entry->sli4_lxritag = NO_XRI;\n\t\tiocbq_entry->sli4_xritag = NO_XRI;\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tlist_add(&iocbq_entry->list, &phba->lpfc_iocb_list);\n\t\tphba->total_iocbq_bufs++;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\n\treturn 0;\n\nout_free_iocbq:\n\tlpfc_free_iocb_list(phba);\n\n\treturn -ENOMEM;\n}\n\n \nvoid\nlpfc_free_sgl_list(struct lpfc_hba *phba, struct list_head *sglq_list)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL, *sglq_next = NULL;\n\n\tlist_for_each_entry_safe(sglq_entry, sglq_next, sglq_list, list) {\n\t\tlist_del(&sglq_entry->list);\n\t\tlpfc_mbuf_free(phba, sglq_entry->virt, sglq_entry->phys);\n\t\tkfree(sglq_entry);\n\t}\n}\n\n \nstatic void\nlpfc_free_els_sgl_list(struct lpfc_hba *phba)\n{\n\tLIST_HEAD(sglq_list);\n\n\t \n\tspin_lock_irq(&phba->sli4_hba.sgl_list_lock);\n\tlist_splice_init(&phba->sli4_hba.lpfc_els_sgl_list, &sglq_list);\n\tspin_unlock_irq(&phba->sli4_hba.sgl_list_lock);\n\n\t \n\tlpfc_free_sgl_list(phba, &sglq_list);\n}\n\n \nstatic void\nlpfc_free_nvmet_sgl_list(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL, *sglq_next = NULL;\n\tLIST_HEAD(sglq_list);\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\tlist_splice_init(&phba->sli4_hba.lpfc_nvmet_sgl_list, &sglq_list);\n\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tlist_for_each_entry_safe(sglq_entry, sglq_next, &sglq_list, list) {\n\t\tlist_del(&sglq_entry->list);\n\t\tlpfc_nvmet_buf_free(phba, sglq_entry->virt, sglq_entry->phys);\n\t\tkfree(sglq_entry);\n\t}\n\n\t \n\tphba->sli4_hba.nvmet_xri_cnt = 0;\n}\n\n \nstatic int\nlpfc_init_active_sgl_array(struct lpfc_hba *phba)\n{\n\tint size;\n\tsize = sizeof(struct lpfc_sglq *);\n\tsize *= phba->sli4_hba.max_cfg_param.max_xri;\n\n\tphba->sli4_hba.lpfc_sglq_active_list =\n\t\tkzalloc(size, GFP_KERNEL);\n\tif (!phba->sli4_hba.lpfc_sglq_active_list)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\n \nstatic void\nlpfc_free_active_sgl(struct lpfc_hba *phba)\n{\n\tkfree(phba->sli4_hba.lpfc_sglq_active_list);\n}\n\n \nstatic void\nlpfc_init_sgl_list(struct lpfc_hba *phba)\n{\n\t \n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_els_sgl_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_abts_els_sgl_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_nvmet_sgl_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_abts_nvmet_ctx_list);\n\n\t \n\tphba->sli4_hba.els_xri_cnt = 0;\n\n\t \n\tphba->sli4_hba.io_xri_cnt = 0;\n}\n\n \nint\nlpfc_sli4_init_rpi_hdrs(struct lpfc_hba *phba)\n{\n\tint rc = 0;\n\tstruct lpfc_rpi_hdr *rpi_hdr;\n\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_rpi_hdr_list);\n\tif (!phba->sli4_hba.rpi_hdrs_in_use)\n\t\treturn rc;\n\tif (phba->sli4_hba.extents_in_use)\n\t\treturn -EIO;\n\n\trpi_hdr = lpfc_sli4_create_rpi_hdr(phba);\n\tif (!rpi_hdr) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0391 Error during rpi post operation\\n\");\n\t\tlpfc_sli4_remove_rpis(phba);\n\t\trc = -ENODEV;\n\t}\n\n\treturn rc;\n}\n\n \nstruct lpfc_rpi_hdr *\nlpfc_sli4_create_rpi_hdr(struct lpfc_hba *phba)\n{\n\tuint16_t rpi_limit, curr_rpi_range;\n\tstruct lpfc_dmabuf *dmabuf;\n\tstruct lpfc_rpi_hdr *rpi_hdr;\n\n\t \n\tif (!phba->sli4_hba.rpi_hdrs_in_use)\n\t\treturn NULL;\n\tif (phba->sli4_hba.extents_in_use)\n\t\treturn NULL;\n\n\t \n\trpi_limit = phba->sli4_hba.max_cfg_param.max_rpi;\n\n\tspin_lock_irq(&phba->hbalock);\n\t \n\tcurr_rpi_range = phba->sli4_hba.next_rpi;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tif (curr_rpi_range == rpi_limit)\n\t\treturn NULL;\n\n\t \n\tdmabuf = kzalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\n\tif (!dmabuf)\n\t\treturn NULL;\n\n\tdmabuf->virt = dma_alloc_coherent(&phba->pcidev->dev,\n\t\t\t\t\t  LPFC_HDR_TEMPLATE_SIZE,\n\t\t\t\t\t  &dmabuf->phys, GFP_KERNEL);\n\tif (!dmabuf->virt) {\n\t\trpi_hdr = NULL;\n\t\tgoto err_free_dmabuf;\n\t}\n\n\tif (!IS_ALIGNED(dmabuf->phys, LPFC_HDR_TEMPLATE_SIZE)) {\n\t\trpi_hdr = NULL;\n\t\tgoto err_free_coherent;\n\t}\n\n\t \n\trpi_hdr = kzalloc(sizeof(struct lpfc_rpi_hdr), GFP_KERNEL);\n\tif (!rpi_hdr)\n\t\tgoto err_free_coherent;\n\n\trpi_hdr->dmabuf = dmabuf;\n\trpi_hdr->len = LPFC_HDR_TEMPLATE_SIZE;\n\trpi_hdr->page_count = 1;\n\tspin_lock_irq(&phba->hbalock);\n\n\t \n\trpi_hdr->start_rpi = curr_rpi_range;\n\trpi_hdr->next_rpi = phba->sli4_hba.next_rpi + LPFC_RPI_HDR_COUNT;\n\tlist_add_tail(&rpi_hdr->list, &phba->sli4_hba.lpfc_rpi_hdr_list);\n\n\tspin_unlock_irq(&phba->hbalock);\n\treturn rpi_hdr;\n\n err_free_coherent:\n\tdma_free_coherent(&phba->pcidev->dev, LPFC_HDR_TEMPLATE_SIZE,\n\t\t\t  dmabuf->virt, dmabuf->phys);\n err_free_dmabuf:\n\tkfree(dmabuf);\n\treturn NULL;\n}\n\n \nvoid\nlpfc_sli4_remove_rpi_hdrs(struct lpfc_hba *phba)\n{\n\tstruct lpfc_rpi_hdr *rpi_hdr, *next_rpi_hdr;\n\n\tif (!phba->sli4_hba.rpi_hdrs_in_use)\n\t\tgoto exit;\n\n\tlist_for_each_entry_safe(rpi_hdr, next_rpi_hdr,\n\t\t\t\t &phba->sli4_hba.lpfc_rpi_hdr_list, list) {\n\t\tlist_del(&rpi_hdr->list);\n\t\tdma_free_coherent(&phba->pcidev->dev, rpi_hdr->len,\n\t\t\t\t  rpi_hdr->dmabuf->virt, rpi_hdr->dmabuf->phys);\n\t\tkfree(rpi_hdr->dmabuf);\n\t\tkfree(rpi_hdr);\n\t}\n exit:\n\t \n\tphba->sli4_hba.next_rpi = 0;\n}\n\n \nstatic struct lpfc_hba *\nlpfc_hba_alloc(struct pci_dev *pdev)\n{\n\tstruct lpfc_hba *phba;\n\n\t \n\tphba = kzalloc(sizeof(struct lpfc_hba), GFP_KERNEL);\n\tif (!phba) {\n\t\tdev_err(&pdev->dev, \"failed to allocate hba struct\\n\");\n\t\treturn NULL;\n\t}\n\n\t \n\tphba->pcidev = pdev;\n\n\t \n\tphba->brd_no = lpfc_get_instance();\n\tif (phba->brd_no < 0) {\n\t\tkfree(phba);\n\t\treturn NULL;\n\t}\n\tphba->eratt_poll_interval = LPFC_ERATT_POLL_INTERVAL;\n\n\tspin_lock_init(&phba->ct_ev_lock);\n\tINIT_LIST_HEAD(&phba->ct_ev_waiters);\n\n\treturn phba;\n}\n\n \nstatic void\nlpfc_hba_free(struct lpfc_hba *phba)\n{\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tkfree(phba->sli4_hba.hdwq);\n\n\t \n\tidr_remove(&lpfc_hba_index, phba->brd_no);\n\n\t \n\tkfree(phba->sli.sli3_ring);\n\tphba->sli.sli3_ring = NULL;\n\n\tkfree(phba);\n\treturn;\n}\n\n \nvoid\nlpfc_setup_fdmi_mask(struct lpfc_vport *vport)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\n\tvport->load_flag |= FC_ALLOW_FDMI;\n\tif (phba->cfg_enable_SmartSAN ||\n\t    phba->cfg_fdmi_on == LPFC_FDMI_SUPPORT) {\n\t\t \n\t\tvport->fdmi_hba_mask = LPFC_FDMI2_HBA_ATTR;\n\t\tif (phba->cfg_enable_SmartSAN)\n\t\t\tvport->fdmi_port_mask = LPFC_FDMI2_SMART_ATTR;\n\t\telse\n\t\t\tvport->fdmi_port_mask = LPFC_FDMI2_PORT_ATTR;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_DISCOVERY,\n\t\t\t\"6077 Setup FDMI mask: hba x%x port x%x\\n\",\n\t\t\tvport->fdmi_hba_mask, vport->fdmi_port_mask);\n}\n\n \nstatic int\nlpfc_create_shost(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport;\n\tstruct Scsi_Host  *shost;\n\n\t \n\tphba->fc_edtov = FF_DEF_EDTOV;\n\tphba->fc_ratov = FF_DEF_RATOV;\n\tphba->fc_altov = FF_DEF_ALTOV;\n\tphba->fc_arbtov = FF_DEF_ARBTOV;\n\n\tatomic_set(&phba->sdev_cnt, 0);\n\tvport = lpfc_create_port(phba, phba->brd_no, &phba->pcidev->dev);\n\tif (!vport)\n\t\treturn -ENODEV;\n\n\tshost = lpfc_shost_from_vport(vport);\n\tphba->pport = vport;\n\n\tif (phba->nvmet_support) {\n\t\t \n\t\tphba->targetport = NULL;\n\t\tphba->cfg_enable_fc4_type = LPFC_ENABLE_NVME;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_NVME_DISC,\n\t\t\t\t\"6076 NVME Target Found\\n\");\n\t}\n\n\tlpfc_debugfs_initialize(vport);\n\t \n\tpci_set_drvdata(phba->pcidev, shost);\n\n\tlpfc_setup_fdmi_mask(vport);\n\n\t \n\treturn 0;\n}\n\n \nstatic void\nlpfc_destroy_shost(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\n\t \n\tdestroy_port(vport);\n\n\treturn;\n}\n\n \nstatic void\nlpfc_setup_bg(struct lpfc_hba *phba, struct Scsi_Host *shost)\n{\n\tuint32_t old_mask;\n\tuint32_t old_guard;\n\n\tif (phba->cfg_prot_mask && phba->cfg_prot_guard) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"1478 Registering BlockGuard with the \"\n\t\t\t\t\"SCSI layer\\n\");\n\n\t\told_mask = phba->cfg_prot_mask;\n\t\told_guard = phba->cfg_prot_guard;\n\n\t\t \n\t\tphba->cfg_prot_mask &= (SHOST_DIF_TYPE1_PROTECTION |\n\t\t\tSHOST_DIX_TYPE0_PROTECTION |\n\t\t\tSHOST_DIX_TYPE1_PROTECTION);\n\t\tphba->cfg_prot_guard &= (SHOST_DIX_GUARD_IP |\n\t\t\t\t\t SHOST_DIX_GUARD_CRC);\n\n\t\t \n\t\tif (phba->cfg_prot_mask == SHOST_DIX_TYPE1_PROTECTION)\n\t\t\tphba->cfg_prot_mask |= SHOST_DIF_TYPE1_PROTECTION;\n\n\t\tif (phba->cfg_prot_mask && phba->cfg_prot_guard) {\n\t\t\tif ((old_mask != phba->cfg_prot_mask) ||\n\t\t\t\t(old_guard != phba->cfg_prot_guard))\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"1475 Registering BlockGuard with the \"\n\t\t\t\t\t\"SCSI layer: mask %d  guard %d\\n\",\n\t\t\t\t\tphba->cfg_prot_mask,\n\t\t\t\t\tphba->cfg_prot_guard);\n\n\t\t\tscsi_host_set_prot(shost, phba->cfg_prot_mask);\n\t\t\tscsi_host_set_guard(shost, phba->cfg_prot_guard);\n\t\t} else\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1479 Not Registering BlockGuard with the SCSI \"\n\t\t\t\t\"layer, Bad protection parameters: %d %d\\n\",\n\t\t\t\told_mask, old_guard);\n\t}\n}\n\n \nstatic void\nlpfc_post_init_setup(struct lpfc_hba *phba)\n{\n\tstruct Scsi_Host  *shost;\n\tstruct lpfc_adapter_event_header adapter_event;\n\n\t \n\tlpfc_get_hba_model_desc(phba, phba->ModelName, phba->ModelDesc);\n\n\t \n\tshost = pci_get_drvdata(phba->pcidev);\n\tshost->can_queue = phba->cfg_hba_queue_depth - 10;\n\n\tlpfc_host_attrib_init(shost);\n\n\tif (phba->cfg_poll & DISABLE_FCP_RING_INT) {\n\t\tspin_lock_irq(shost->host_lock);\n\t\tlpfc_poll_start_timer(phba);\n\t\tspin_unlock_irq(shost->host_lock);\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0428 Perform SCSI scan\\n\");\n\t \n\tadapter_event.event_type = FC_REG_ADAPTER_EVENT;\n\tadapter_event.subcategory = LPFC_EVENT_ARRIVAL;\n\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t  sizeof(adapter_event),\n\t\t\t\t  (char *) &adapter_event,\n\t\t\t\t  LPFC_NL_VENDOR_ID);\n\treturn;\n}\n\n \nstatic int\nlpfc_sli_pci_mem_setup(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev = phba->pcidev;\n\tunsigned long bar0map_len, bar2map_len;\n\tint i, hbq_count;\n\tvoid *ptr;\n\tint error;\n\n\tif (!pdev)\n\t\treturn -ENODEV;\n\n\t \n\terror = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (error)\n\t\terror = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (error)\n\t\treturn error;\n\terror = -ENODEV;\n\n\t \n\tphba->pci_bar0_map = pci_resource_start(pdev, 0);\n\tbar0map_len = pci_resource_len(pdev, 0);\n\n\tphba->pci_bar2_map = pci_resource_start(pdev, 2);\n\tbar2map_len = pci_resource_len(pdev, 2);\n\n\t \n\tphba->slim_memmap_p = ioremap(phba->pci_bar0_map, bar0map_len);\n\tif (!phba->slim_memmap_p) {\n\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t   \"ioremap failed for SLIM memory.\\n\");\n\t\tgoto out;\n\t}\n\n\t \n\tphba->ctrl_regs_memmap_p = ioremap(phba->pci_bar2_map, bar2map_len);\n\tif (!phba->ctrl_regs_memmap_p) {\n\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t   \"ioremap failed for HBA control registers.\\n\");\n\t\tgoto out_iounmap_slim;\n\t}\n\n\t \n\tphba->slim2p.virt = dma_alloc_coherent(&pdev->dev, SLI2_SLIM_SIZE,\n\t\t\t\t\t       &phba->slim2p.phys, GFP_KERNEL);\n\tif (!phba->slim2p.virt)\n\t\tgoto out_iounmap;\n\n\tphba->mbox = phba->slim2p.virt + offsetof(struct lpfc_sli2_slim, mbx);\n\tphba->mbox_ext = (phba->slim2p.virt +\n\t\toffsetof(struct lpfc_sli2_slim, mbx_ext_words));\n\tphba->pcb = (phba->slim2p.virt + offsetof(struct lpfc_sli2_slim, pcb));\n\tphba->IOCBs = (phba->slim2p.virt +\n\t\t       offsetof(struct lpfc_sli2_slim, IOCBs));\n\n\tphba->hbqslimp.virt = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t\t lpfc_sli_hbq_size(),\n\t\t\t\t\t\t &phba->hbqslimp.phys,\n\t\t\t\t\t\t GFP_KERNEL);\n\tif (!phba->hbqslimp.virt)\n\t\tgoto out_free_slim;\n\n\thbq_count = lpfc_sli_hbq_count();\n\tptr = phba->hbqslimp.virt;\n\tfor (i = 0; i < hbq_count; ++i) {\n\t\tphba->hbqs[i].hbq_virt = ptr;\n\t\tINIT_LIST_HEAD(&phba->hbqs[i].hbq_buffer_list);\n\t\tptr += (lpfc_hbq_defs[i]->entry_count *\n\t\t\tsizeof(struct lpfc_hbq_entry));\n\t}\n\tphba->hbqs[LPFC_ELS_HBQ].hbq_alloc_buffer = lpfc_els_hbq_alloc;\n\tphba->hbqs[LPFC_ELS_HBQ].hbq_free_buffer = lpfc_els_hbq_free;\n\n\tmemset(phba->hbqslimp.virt, 0, lpfc_sli_hbq_size());\n\n\tphba->MBslimaddr = phba->slim_memmap_p;\n\tphba->HAregaddr = phba->ctrl_regs_memmap_p + HA_REG_OFFSET;\n\tphba->CAregaddr = phba->ctrl_regs_memmap_p + CA_REG_OFFSET;\n\tphba->HSregaddr = phba->ctrl_regs_memmap_p + HS_REG_OFFSET;\n\tphba->HCregaddr = phba->ctrl_regs_memmap_p + HC_REG_OFFSET;\n\n\treturn 0;\n\nout_free_slim:\n\tdma_free_coherent(&pdev->dev, SLI2_SLIM_SIZE,\n\t\t\t  phba->slim2p.virt, phba->slim2p.phys);\nout_iounmap:\n\tiounmap(phba->ctrl_regs_memmap_p);\nout_iounmap_slim:\n\tiounmap(phba->slim_memmap_p);\nout:\n\treturn error;\n}\n\n \nstatic void\nlpfc_sli_pci_mem_unset(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev;\n\n\t \n\tif (!phba->pcidev)\n\t\treturn;\n\telse\n\t\tpdev = phba->pcidev;\n\n\t \n\tdma_free_coherent(&pdev->dev, lpfc_sli_hbq_size(),\n\t\t\t  phba->hbqslimp.virt, phba->hbqslimp.phys);\n\tdma_free_coherent(&pdev->dev, SLI2_SLIM_SIZE,\n\t\t\t  phba->slim2p.virt, phba->slim2p.phys);\n\n\t \n\tiounmap(phba->ctrl_regs_memmap_p);\n\tiounmap(phba->slim_memmap_p);\n\n\treturn;\n}\n\n \nint\nlpfc_sli4_post_status_check(struct lpfc_hba *phba)\n{\n\tstruct lpfc_register portsmphr_reg, uerrlo_reg, uerrhi_reg;\n\tstruct lpfc_register reg_data;\n\tint i, port_error = 0;\n\tuint32_t if_type;\n\n\tmemset(&portsmphr_reg, 0, sizeof(portsmphr_reg));\n\tmemset(&reg_data, 0, sizeof(reg_data));\n\tif (!phba->sli4_hba.PSMPHRregaddr)\n\t\treturn -ENODEV;\n\n\t \n\tfor (i = 0; i < 3000; i++) {\n\t\tif (lpfc_readl(phba->sli4_hba.PSMPHRregaddr,\n\t\t\t&portsmphr_reg.word0) ||\n\t\t\t(bf_get(lpfc_port_smphr_perr, &portsmphr_reg))) {\n\t\t\t \n\t\t\tport_error = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\t\tif (LPFC_POST_STAGE_PORT_READY ==\n\t\t    bf_get(lpfc_port_smphr_port_status, &portsmphr_reg))\n\t\t\tbreak;\n\t\tmsleep(10);\n\t}\n\n\t \n\tif (port_error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"1408 Port Failed POST - portsmphr=0x%x, \"\n\t\t\t\"perr=x%x, sfi=x%x, nip=x%x, ipc=x%x, scr1=x%x, \"\n\t\t\t\"scr2=x%x, hscratch=x%x, pstatus=x%x\\n\",\n\t\t\tportsmphr_reg.word0,\n\t\t\tbf_get(lpfc_port_smphr_perr, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_sfi, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_nip, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_ipc, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_scr1, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_scr2, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_host_scratch, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_port_status, &portsmphr_reg));\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"2534 Device Info: SLIFamily=0x%x, \"\n\t\t\t\t\"SLIRev=0x%x, IFType=0x%x, SLIHint_1=0x%x, \"\n\t\t\t\t\"SLIHint_2=0x%x, FT=0x%x\\n\",\n\t\t\t\tbf_get(lpfc_sli_intf_sli_family,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_slirev,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_if_type,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_sli_hint1,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_sli_hint2,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_func_type,\n\t\t\t\t       &phba->sli4_hba.sli_intf));\n\t\t \n\t\tif_type = bf_get(lpfc_sli_intf_if_type,\n\t\t\t\t &phba->sli4_hba.sli_intf);\n\t\tswitch (if_type) {\n\t\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\t\tphba->sli4_hba.ue_mask_lo =\n\t\t\t      readl(phba->sli4_hba.u.if_type0.UEMASKLOregaddr);\n\t\t\tphba->sli4_hba.ue_mask_hi =\n\t\t\t      readl(phba->sli4_hba.u.if_type0.UEMASKHIregaddr);\n\t\t\tuerrlo_reg.word0 =\n\t\t\t      readl(phba->sli4_hba.u.if_type0.UERRLOregaddr);\n\t\t\tuerrhi_reg.word0 =\n\t\t\t\treadl(phba->sli4_hba.u.if_type0.UERRHIregaddr);\n\t\t\tif ((~phba->sli4_hba.ue_mask_lo & uerrlo_reg.word0) ||\n\t\t\t    (~phba->sli4_hba.ue_mask_hi & uerrhi_reg.word0)) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"1422 Unrecoverable Error \"\n\t\t\t\t\t\t\"Detected during POST \"\n\t\t\t\t\t\t\"uerr_lo_reg=0x%x, \"\n\t\t\t\t\t\t\"uerr_hi_reg=0x%x, \"\n\t\t\t\t\t\t\"ue_mask_lo_reg=0x%x, \"\n\t\t\t\t\t\t\"ue_mask_hi_reg=0x%x\\n\",\n\t\t\t\t\t\tuerrlo_reg.word0,\n\t\t\t\t\t\tuerrhi_reg.word0,\n\t\t\t\t\t\tphba->sli4_hba.ue_mask_lo,\n\t\t\t\t\t\tphba->sli4_hba.ue_mask_hi);\n\t\t\t\tport_error = -ENODEV;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\t\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\t\t \n\t\t\tif (lpfc_readl(phba->sli4_hba.u.if_type2.STATUSregaddr,\n\t\t\t\t&reg_data.word0) ||\n\t\t\t\tlpfc_sli4_unrecoverable_port(&reg_data)) {\n\t\t\t\tphba->work_status[0] =\n\t\t\t\t\treadl(phba->sli4_hba.u.if_type2.\n\t\t\t\t\t      ERR1regaddr);\n\t\t\t\tphba->work_status[1] =\n\t\t\t\t\treadl(phba->sli4_hba.u.if_type2.\n\t\t\t\t\t      ERR2regaddr);\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2888 Unrecoverable port error \"\n\t\t\t\t\t\"following POST: port status reg \"\n\t\t\t\t\t\"0x%x, port_smphr reg 0x%x, \"\n\t\t\t\t\t\"error 1=0x%x, error 2=0x%x\\n\",\n\t\t\t\t\treg_data.word0,\n\t\t\t\t\tportsmphr_reg.word0,\n\t\t\t\t\tphba->work_status[0],\n\t\t\t\t\tphba->work_status[1]);\n\t\t\t\tport_error = -ENODEV;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (lpfc_pldv_detect &&\n\t\t\t    bf_get(lpfc_sli_intf_sli_family,\n\t\t\t\t   &phba->sli4_hba.sli_intf) ==\n\t\t\t\t\tLPFC_SLI_INTF_FAMILY_G6)\n\t\t\t\tpci_write_config_byte(phba->pcidev,\n\t\t\t\t\t\t      LPFC_SLI_INTF, CFG_PLD);\n\t\t\tbreak;\n\t\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn port_error;\n}\n\n \nstatic void\nlpfc_sli4_bar0_register_memmap(struct lpfc_hba *phba, uint32_t if_type)\n{\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tphba->sli4_hba.u.if_type0.UERRLOregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_UERR_STATUS_LO;\n\t\tphba->sli4_hba.u.if_type0.UERRHIregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_UERR_STATUS_HI;\n\t\tphba->sli4_hba.u.if_type0.UEMASKLOregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_UE_MASK_LO;\n\t\tphba->sli4_hba.u.if_type0.UEMASKHIregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_UE_MASK_HI;\n\t\tphba->sli4_hba.SLIINTFregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_SLI_INTF;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\t\tphba->sli4_hba.u.if_type2.EQDregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_EQ_DELAY_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.ERR1regaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_ER1_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.ERR2regaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_ER2_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.CTRLregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_CTL_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.STATUSregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_STA_OFFSET;\n\t\tphba->sli4_hba.SLIINTFregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_SLI_INTF;\n\t\tphba->sli4_hba.PSMPHRregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_SEM_OFFSET;\n\t\tphba->sli4_hba.RQDBregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_ULP0_RQ_DOORBELL;\n\t\tphba->sli4_hba.WQDBregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_ULP0_WQ_DOORBELL;\n\t\tphba->sli4_hba.CQDBregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_EQCQ_DOORBELL;\n\t\tphba->sli4_hba.EQDBregaddr = phba->sli4_hba.CQDBregaddr;\n\t\tphba->sli4_hba.MQDBregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_MQ_DOORBELL;\n\t\tphba->sli4_hba.BMBXregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_BMBX;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tphba->sli4_hba.u.if_type2.EQDregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_EQ_DELAY_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.ERR1regaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_ER1_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.ERR2regaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_ER2_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.CTRLregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_CTL_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.STATUSregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_STA_OFFSET;\n\t\tphba->sli4_hba.PSMPHRregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_SEM_OFFSET;\n\t\tphba->sli4_hba.BMBXregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_BMBX;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tdev_printk(KERN_ERR, &phba->pcidev->dev,\n\t\t\t   \"FATAL - unsupported SLI4 interface type - %d\\n\",\n\t\t\t   if_type);\n\t\tbreak;\n\t}\n}\n\n \nstatic void\nlpfc_sli4_bar1_register_memmap(struct lpfc_hba *phba, uint32_t if_type)\n{\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tphba->sli4_hba.PSMPHRregaddr =\n\t\t\tphba->sli4_hba.ctrl_regs_memmap_p +\n\t\t\tLPFC_SLIPORT_IF0_SMPHR;\n\t\tphba->sli4_hba.ISRregaddr = phba->sli4_hba.ctrl_regs_memmap_p +\n\t\t\tLPFC_HST_ISR0;\n\t\tphba->sli4_hba.IMRregaddr = phba->sli4_hba.ctrl_regs_memmap_p +\n\t\t\tLPFC_HST_IMR0;\n\t\tphba->sli4_hba.ISCRregaddr = phba->sli4_hba.ctrl_regs_memmap_p +\n\t\t\tLPFC_HST_ISCR0;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tphba->sli4_hba.RQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_RQ_DOORBELL;\n\t\tphba->sli4_hba.WQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_WQ_DOORBELL;\n\t\tphba->sli4_hba.CQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_CQ_DOORBELL;\n\t\tphba->sli4_hba.EQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_EQ_DOORBELL;\n\t\tphba->sli4_hba.MQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_MQ_DOORBELL;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tdev_err(&phba->pcidev->dev,\n\t\t\t   \"FATAL - unsupported SLI4 interface type - %d\\n\",\n\t\t\t   if_type);\n\t\tbreak;\n\t}\n}\n\n \nstatic int\nlpfc_sli4_bar2_register_memmap(struct lpfc_hba *phba, uint32_t vf)\n{\n\tif (vf > LPFC_VIR_FUNC_MAX)\n\t\treturn -ENODEV;\n\n\tphba->sli4_hba.RQDBregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE +\n\t\t\t\t\tLPFC_ULP0_RQ_DOORBELL);\n\tphba->sli4_hba.WQDBregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE +\n\t\t\t\t\tLPFC_ULP0_WQ_DOORBELL);\n\tphba->sli4_hba.CQDBregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE +\n\t\t\t\t\tLPFC_EQCQ_DOORBELL);\n\tphba->sli4_hba.EQDBregaddr = phba->sli4_hba.CQDBregaddr;\n\tphba->sli4_hba.MQDBregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE + LPFC_MQ_DOORBELL);\n\tphba->sli4_hba.BMBXregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE + LPFC_BMBX);\n\treturn 0;\n}\n\n \nstatic int\nlpfc_create_bootstrap_mbox(struct lpfc_hba *phba)\n{\n\tuint32_t bmbx_size;\n\tstruct lpfc_dmabuf *dmabuf;\n\tstruct dma_address *dma_address;\n\tuint32_t pa_addr;\n\tuint64_t phys_addr;\n\n\tdmabuf = kzalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\n\tif (!dmabuf)\n\t\treturn -ENOMEM;\n\n\t \n\tbmbx_size = sizeof(struct lpfc_bmbx_create) + (LPFC_ALIGN_16_BYTE - 1);\n\tdmabuf->virt = dma_alloc_coherent(&phba->pcidev->dev, bmbx_size,\n\t\t\t\t\t  &dmabuf->phys, GFP_KERNEL);\n\tif (!dmabuf->virt) {\n\t\tkfree(dmabuf);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tphba->sli4_hba.bmbx.dmabuf = dmabuf;\n\tphba->sli4_hba.bmbx.bmbx_size = bmbx_size;\n\n\tphba->sli4_hba.bmbx.avirt = PTR_ALIGN(dmabuf->virt,\n\t\t\t\t\t      LPFC_ALIGN_16_BYTE);\n\tphba->sli4_hba.bmbx.aphys = ALIGN(dmabuf->phys,\n\t\t\t\t\t      LPFC_ALIGN_16_BYTE);\n\n\t \n\tdma_address = &phba->sli4_hba.bmbx.dma_address;\n\tphys_addr = (uint64_t)phba->sli4_hba.bmbx.aphys;\n\tpa_addr = (uint32_t) ((phys_addr >> 34) & 0x3fffffff);\n\tdma_address->addr_hi = (uint32_t) ((pa_addr << 2) |\n\t\t\t\t\t   LPFC_BMBX_BIT1_ADDR_HI);\n\n\tpa_addr = (uint32_t) ((phba->sli4_hba.bmbx.aphys >> 4) & 0x3fffffff);\n\tdma_address->addr_lo = (uint32_t) ((pa_addr << 2) |\n\t\t\t\t\t   LPFC_BMBX_BIT1_ADDR_LO);\n\treturn 0;\n}\n\n \nstatic void\nlpfc_destroy_bootstrap_mbox(struct lpfc_hba *phba)\n{\n\tdma_free_coherent(&phba->pcidev->dev,\n\t\t\t  phba->sli4_hba.bmbx.bmbx_size,\n\t\t\t  phba->sli4_hba.bmbx.dmabuf->virt,\n\t\t\t  phba->sli4_hba.bmbx.dmabuf->phys);\n\n\tkfree(phba->sli4_hba.bmbx.dmabuf);\n\tmemset(&phba->sli4_hba.bmbx, 0, sizeof(struct lpfc_bmbx));\n}\n\nstatic const char * const lpfc_topo_to_str[] = {\n\t\"Loop then P2P\",\n\t\"Loopback\",\n\t\"P2P Only\",\n\t\"Unsupported\",\n\t\"Loop Only\",\n\t\"Unsupported\",\n\t\"P2P then Loop\",\n};\n\n#define\tLINK_FLAGS_DEF\t0x0\n#define\tLINK_FLAGS_P2P\t0x1\n#define\tLINK_FLAGS_LOOP\t0x2\n \nstatic void\nlpfc_map_topology(struct lpfc_hba *phba, struct lpfc_mbx_read_config *rd_config)\n{\n\tu8 ptv, tf, pt;\n\n\tptv = bf_get(lpfc_mbx_rd_conf_ptv, rd_config);\n\ttf = bf_get(lpfc_mbx_rd_conf_tf, rd_config);\n\tpt = bf_get(lpfc_mbx_rd_conf_pt, rd_config);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2027 Read Config Data : ptv:0x%x, tf:0x%x pt:0x%x\",\n\t\t\t ptv, tf, pt);\n\tif (!ptv) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"2019 FW does not support persistent topology \"\n\t\t\t\t\"Using driver parameter defined value [%s]\",\n\t\t\t\tlpfc_topo_to_str[phba->cfg_topology]);\n\t\treturn;\n\t}\n\t \n\tphba->hba_flag |= HBA_PERSISTENT_TOPO;\n\n\t \n\tif ((bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) ==\n\t\t    LPFC_SLI_INTF_IF_TYPE_6) ||\n\t    (bf_get(lpfc_sli_intf_sli_family, &phba->sli4_hba.sli_intf) ==\n\t\t    LPFC_SLI_INTF_FAMILY_G6)) {\n\t\tif (!tf) {\n\t\t\tphba->cfg_topology = ((pt == LINK_FLAGS_LOOP)\n\t\t\t\t\t? FLAGS_TOPOLOGY_MODE_LOOP\n\t\t\t\t\t: FLAGS_TOPOLOGY_MODE_PT_PT);\n\t\t} else {\n\t\t\tphba->hba_flag &= ~HBA_PERSISTENT_TOPO;\n\t\t}\n\t} else {  \n\t\tif (tf) {\n\t\t\t \n\t\t\tphba->cfg_topology = (pt ? FLAGS_TOPOLOGY_MODE_PT_LOOP :\n\t\t\t\t\t      FLAGS_TOPOLOGY_MODE_LOOP_PT);\n\t\t} else {\n\t\t\tphba->cfg_topology = ((pt == LINK_FLAGS_P2P)\n\t\t\t\t\t? FLAGS_TOPOLOGY_MODE_PT_PT\n\t\t\t\t\t: FLAGS_TOPOLOGY_MODE_LOOP);\n\t\t}\n\t}\n\tif (phba->hba_flag & HBA_PERSISTENT_TOPO) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"2020 Using persistent topology value [%s]\",\n\t\t\t\tlpfc_topo_to_str[phba->cfg_topology]);\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"2021 Invalid topology values from FW \"\n\t\t\t\t\"Using driver parameter defined value [%s]\",\n\t\t\t\tlpfc_topo_to_str[phba->cfg_topology]);\n\t}\n}\n\n \nint\nlpfc_sli4_read_config(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *pmb;\n\tstruct lpfc_mbx_read_config *rd_config;\n\tunion  lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t shdr_status, shdr_add_status;\n\tstruct lpfc_mbx_get_func_cfg *get_func_cfg;\n\tstruct lpfc_rsrc_desc_fcfcoe *desc;\n\tchar *pdesc_0;\n\tuint16_t forced_link_speed;\n\tuint32_t if_type, qmin, fawwpn;\n\tint length, i, rc = 0, rc2;\n\n\tpmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2011 Unable to allocate memory for issuing \"\n\t\t\t\t\"SLI_CONFIG_SPECIAL mailbox command\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tlpfc_read_config(phba, pmb);\n\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2012 Mailbox failed , mbxCmd x%x \"\n\t\t\t\t\"READ_CONFIG, mbxStatus x%x\\n\",\n\t\t\t\tbf_get(lpfc_mqe_command, &pmb->u.mqe),\n\t\t\t\tbf_get(lpfc_mqe_status, &pmb->u.mqe));\n\t\trc = -EIO;\n\t} else {\n\t\trd_config = &pmb->u.mqe.un.rd_config;\n\t\tif (bf_get(lpfc_mbx_rd_conf_lnk_ldv, rd_config)) {\n\t\t\tphba->sli4_hba.lnk_info.lnk_dv = LPFC_LNK_DAT_VAL;\n\t\t\tphba->sli4_hba.lnk_info.lnk_tp =\n\t\t\t\tbf_get(lpfc_mbx_rd_conf_lnk_type, rd_config);\n\t\t\tphba->sli4_hba.lnk_info.lnk_no =\n\t\t\t\tbf_get(lpfc_mbx_rd_conf_lnk_numb, rd_config);\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\t\"3081 lnk_type:%d, lnk_numb:%d\\n\",\n\t\t\t\t\tphba->sli4_hba.lnk_info.lnk_tp,\n\t\t\t\t\tphba->sli4_hba.lnk_info.lnk_no);\n\t\t} else\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\t\"3082 Mailbox (x%x) returned ldv:x0\\n\",\n\t\t\t\t\tbf_get(lpfc_mqe_command, &pmb->u.mqe));\n\t\tif (bf_get(lpfc_mbx_rd_conf_bbscn_def, rd_config)) {\n\t\t\tphba->bbcredit_support = 1;\n\t\t\tphba->sli4_hba.bbscn_params.word0 = rd_config->word8;\n\t\t}\n\n\t\tfawwpn = bf_get(lpfc_mbx_rd_conf_fawwpn, rd_config);\n\n\t\tif (fawwpn) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\t\tLOG_INIT | LOG_DISCOVERY,\n\t\t\t\t\t\"2702 READ_CONFIG: FA-PWWN is \"\n\t\t\t\t\t\"configured on\\n\");\n\t\t\tphba->sli4_hba.fawwpn_flag |= LPFC_FAWWPN_CONFIG;\n\t\t} else {\n\t\t\t \n\t\t\tphba->sli4_hba.fawwpn_flag &= ~LPFC_FAWWPN_CONFIG;\n\t\t}\n\n\t\tphba->sli4_hba.conf_trunk =\n\t\t\tbf_get(lpfc_mbx_rd_conf_trunk, rd_config);\n\t\tphba->sli4_hba.extents_in_use =\n\t\t\tbf_get(lpfc_mbx_rd_conf_extnts_inuse, rd_config);\n\n\t\tphba->sli4_hba.max_cfg_param.max_xri =\n\t\t\tbf_get(lpfc_mbx_rd_conf_xri_count, rd_config);\n\t\t \n\t\tif (is_kdump_kernel() &&\n\t\t    phba->sli4_hba.max_cfg_param.max_xri > 512)\n\t\t\tphba->sli4_hba.max_cfg_param.max_xri = 512;\n\t\tphba->sli4_hba.max_cfg_param.xri_base =\n\t\t\tbf_get(lpfc_mbx_rd_conf_xri_base, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_vpi =\n\t\t\tbf_get(lpfc_mbx_rd_conf_vpi_count, rd_config);\n\t\t \n\t\tif (phba->sli4_hba.max_cfg_param.max_vpi > LPFC_MAX_VPORTS)\n\t\t\tphba->sli4_hba.max_cfg_param.max_vpi = LPFC_MAX_VPORTS;\n\t\tphba->sli4_hba.max_cfg_param.vpi_base =\n\t\t\tbf_get(lpfc_mbx_rd_conf_vpi_base, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_rpi =\n\t\t\tbf_get(lpfc_mbx_rd_conf_rpi_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.rpi_base =\n\t\t\tbf_get(lpfc_mbx_rd_conf_rpi_base, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_vfi =\n\t\t\tbf_get(lpfc_mbx_rd_conf_vfi_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.vfi_base =\n\t\t\tbf_get(lpfc_mbx_rd_conf_vfi_base, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_fcfi =\n\t\t\tbf_get(lpfc_mbx_rd_conf_fcfi_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_eq =\n\t\t\tbf_get(lpfc_mbx_rd_conf_eq_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_rq =\n\t\t\tbf_get(lpfc_mbx_rd_conf_rq_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_wq =\n\t\t\tbf_get(lpfc_mbx_rd_conf_wq_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_cq =\n\t\t\tbf_get(lpfc_mbx_rd_conf_cq_count, rd_config);\n\t\tphba->lmt = bf_get(lpfc_mbx_rd_conf_lmt, rd_config);\n\t\tphba->sli4_hba.next_xri = phba->sli4_hba.max_cfg_param.xri_base;\n\t\tphba->vpi_base = phba->sli4_hba.max_cfg_param.vpi_base;\n\t\tphba->vfi_base = phba->sli4_hba.max_cfg_param.vfi_base;\n\t\tphba->max_vpi = (phba->sli4_hba.max_cfg_param.max_vpi > 0) ?\n\t\t\t\t(phba->sli4_hba.max_cfg_param.max_vpi - 1) : 0;\n\t\tphba->max_vports = phba->max_vpi;\n\n\t\t \n\t\tphba->cgn_reg_fpin = LPFC_CGN_FPIN_BOTH;\n\t\tphba->cgn_reg_signal = EDC_CG_SIG_NOTSUPPORTED;\n\t\tphba->cgn_sig_freq = lpfc_fabric_cgn_frequency;\n\n\t\tif (lpfc_use_cgn_signal) {\n\t\t\tif (bf_get(lpfc_mbx_rd_conf_wcs, rd_config)) {\n\t\t\t\tphba->cgn_reg_signal = EDC_CG_SIG_WARN_ONLY;\n\t\t\t\tphba->cgn_reg_fpin &= ~LPFC_CGN_FPIN_WARN;\n\t\t\t}\n\t\t\tif (bf_get(lpfc_mbx_rd_conf_acs, rd_config)) {\n\t\t\t\t \n\t\t\t\tif (phba->cgn_reg_signal !=\n\t\t\t\t    EDC_CG_SIG_WARN_ONLY) {\n\t\t\t\t\t \n\t\t\t\t\tphba->cgn_reg_fpin = LPFC_CGN_FPIN_BOTH;\n\t\t\t\t\tphba->cgn_reg_signal =\n\t\t\t\t\t\tEDC_CG_SIG_NOTSUPPORTED;\n\t\t\t\t} else {\n\t\t\t\t\tphba->cgn_reg_signal =\n\t\t\t\t\t\tEDC_CG_SIG_WARN_ALARM;\n\t\t\t\t\tphba->cgn_reg_fpin =\n\t\t\t\t\t\tLPFC_CGN_FPIN_NONE;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tphba->cgn_init_reg_fpin = phba->cgn_reg_fpin;\n\t\tphba->cgn_init_reg_signal = phba->cgn_reg_signal;\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"6446 READ_CONFIG reg_sig x%x reg_fpin:x%x\\n\",\n\t\t\t\tphba->cgn_reg_signal, phba->cgn_reg_fpin);\n\n\t\tlpfc_map_topology(phba, rd_config);\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"2003 cfg params Extents? %d \"\n\t\t\t\t\"XRI(B:%d M:%d), \"\n\t\t\t\t\"VPI(B:%d M:%d) \"\n\t\t\t\t\"VFI(B:%d M:%d) \"\n\t\t\t\t\"RPI(B:%d M:%d) \"\n\t\t\t\t\"FCFI:%d EQ:%d CQ:%d WQ:%d RQ:%d lmt:x%x\\n\",\n\t\t\t\tphba->sli4_hba.extents_in_use,\n\t\t\t\tphba->sli4_hba.max_cfg_param.xri_base,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_xri,\n\t\t\t\tphba->sli4_hba.max_cfg_param.vpi_base,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_vpi,\n\t\t\t\tphba->sli4_hba.max_cfg_param.vfi_base,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_vfi,\n\t\t\t\tphba->sli4_hba.max_cfg_param.rpi_base,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_rpi,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_fcfi,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_eq,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_cq,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_wq,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_rq,\n\t\t\t\tphba->lmt);\n\n\t\t \n\t\tqmin = phba->sli4_hba.max_cfg_param.max_wq;\n\t\tif (phba->sli4_hba.max_cfg_param.max_cq < qmin)\n\t\t\tqmin = phba->sli4_hba.max_cfg_param.max_cq;\n\t\t \n\t\tqmin -= 4;\n\t\tif (phba->sli4_hba.max_cfg_param.max_eq < qmin)\n\t\t\tqmin = phba->sli4_hba.max_cfg_param.max_eq;\n\n\t\t \n\t\tif ((phba->cfg_irq_chann > qmin) ||\n\t\t    (phba->cfg_hdw_queue > qmin)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2005 Reducing Queues - \"\n\t\t\t\t\t\"FW resource limitation: \"\n\t\t\t\t\t\"WQ %d CQ %d EQ %d: min %d: \"\n\t\t\t\t\t\"IRQ %d HDWQ %d\\n\",\n\t\t\t\t\tphba->sli4_hba.max_cfg_param.max_wq,\n\t\t\t\t\tphba->sli4_hba.max_cfg_param.max_cq,\n\t\t\t\t\tphba->sli4_hba.max_cfg_param.max_eq,\n\t\t\t\t\tqmin, phba->cfg_irq_chann,\n\t\t\t\t\tphba->cfg_hdw_queue);\n\n\t\t\tif (phba->cfg_irq_chann > qmin)\n\t\t\t\tphba->cfg_irq_chann = qmin;\n\t\t\tif (phba->cfg_hdw_queue > qmin)\n\t\t\t\tphba->cfg_hdw_queue = qmin;\n\t\t}\n\t}\n\n\tif (rc)\n\t\tgoto read_cfg_out;\n\n\t \n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tif (if_type >= LPFC_SLI_INTF_IF_TYPE_2) {\n\t\tforced_link_speed =\n\t\t\tbf_get(lpfc_mbx_rd_conf_link_speed, rd_config);\n\t\tif (forced_link_speed) {\n\t\t\tphba->hba_flag |= HBA_FORCED_LINK_SPEED;\n\n\t\t\tswitch (forced_link_speed) {\n\t\t\tcase LINK_SPEED_1G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_1G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_2G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_2G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_4G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_4G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_8G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_8G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_10G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_10G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_16G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_16G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_32G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_32G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_64G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_64G;\n\t\t\t\tbreak;\n\t\t\tcase 0xffff:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_AUTO;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"0047 Unrecognized link \"\n\t\t\t\t\t\t\"speed : %d\\n\",\n\t\t\t\t\t\tforced_link_speed);\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_AUTO;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tlength = phba->sli4_hba.max_cfg_param.max_xri -\n\t\t\tlpfc_sli4_get_els_iocb_cnt(phba);\n\tif (phba->cfg_hba_queue_depth > length) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"3361 HBA queue depth changed from %d to %d\\n\",\n\t\t\t\tphba->cfg_hba_queue_depth, length);\n\t\tphba->cfg_hba_queue_depth = length;\n\t}\n\n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) <\n\t    LPFC_SLI_INTF_IF_TYPE_2)\n\t\tgoto read_cfg_out;\n\n\t \n\tlength = (sizeof(struct lpfc_mbx_get_func_cfg) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, pmb, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_GET_FUNCTION_CONFIG,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\n\trc2 = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t\t\t&pmb->u.mqe.un.sli4_config.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (rc2 || shdr_status || shdr_add_status) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3026 Mailbox failed , mbxCmd x%x \"\n\t\t\t\t\"GET_FUNCTION_CONFIG, mbxStatus x%x\\n\",\n\t\t\t\tbf_get(lpfc_mqe_command, &pmb->u.mqe),\n\t\t\t\tbf_get(lpfc_mqe_status, &pmb->u.mqe));\n\t\tgoto read_cfg_out;\n\t}\n\n\t \n\tget_func_cfg = &pmb->u.mqe.un.get_func_cfg;\n\n\tpdesc_0 = (char *)&get_func_cfg->func_cfg.desc[0];\n\tdesc = (struct lpfc_rsrc_desc_fcfcoe *)pdesc_0;\n\tlength = bf_get(lpfc_rsrc_desc_fcfcoe_length, desc);\n\tif (length == LPFC_RSRC_DESC_TYPE_FCFCOE_V0_RSVD)\n\t\tlength = LPFC_RSRC_DESC_TYPE_FCFCOE_V0_LENGTH;\n\telse if (length != LPFC_RSRC_DESC_TYPE_FCFCOE_V1_LENGTH)\n\t\tgoto read_cfg_out;\n\n\tfor (i = 0; i < LPFC_RSRC_DESC_MAX_NUM; i++) {\n\t\tdesc = (struct lpfc_rsrc_desc_fcfcoe *)(pdesc_0 + length * i);\n\t\tif (LPFC_RSRC_DESC_TYPE_FCFCOE ==\n\t\t    bf_get(lpfc_rsrc_desc_fcfcoe_type, desc)) {\n\t\t\tphba->sli4_hba.iov.pf_number =\n\t\t\t\tbf_get(lpfc_rsrc_desc_fcfcoe_pfnum, desc);\n\t\t\tphba->sli4_hba.iov.vf_number =\n\t\t\t\tbf_get(lpfc_rsrc_desc_fcfcoe_vfnum, desc);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i < LPFC_RSRC_DESC_MAX_NUM)\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3027 GET_FUNCTION_CONFIG: pf_number:%d, \"\n\t\t\t\t\"vf_number:%d\\n\", phba->sli4_hba.iov.pf_number,\n\t\t\t\tphba->sli4_hba.iov.vf_number);\n\telse\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3028 GET_FUNCTION_CONFIG: failed to find \"\n\t\t\t\t\"Resource Descriptor:x%x\\n\",\n\t\t\t\tLPFC_RSRC_DESC_TYPE_FCFCOE);\n\nread_cfg_out:\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\treturn rc;\n}\n\n \nstatic int\nlpfc_setup_endian_order(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tuint32_t if_type, rc = 0;\n\tuint32_t endian_mb_data[2] = {HOST_ENDIAN_LOW_WORD0,\n\t\t\t\t      HOST_ENDIAN_HIGH_WORD1};\n\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool,\n\t\t\t\t\t\t       GFP_KERNEL);\n\t\tif (!mboxq) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0492 Unable to allocate memory for \"\n\t\t\t\t\t\"issuing SLI_CONFIG_SPECIAL mailbox \"\n\t\t\t\t\t\"command\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t \n\t\tmemset(mboxq, 0, sizeof(LPFC_MBOXQ_t));\n\t\tmemcpy(&mboxq->u.mqe, &endian_mb_data, sizeof(endian_mb_data));\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0493 SLI_CONFIG_SPECIAL mailbox \"\n\t\t\t\t\t\"failed with status x%x\\n\",\n\t\t\t\t\trc);\n\t\t\trc = -EIO;\n\t\t}\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_queue_verify(struct lpfc_hba *phba)\n{\n\t \n\n\tif (phba->nvmet_support) {\n\t\tif (phba->cfg_hdw_queue < phba->cfg_nvmet_mrq)\n\t\t\tphba->cfg_nvmet_mrq = phba->cfg_hdw_queue;\n\t\tif (phba->cfg_nvmet_mrq > LPFC_NVMET_MRQ_MAX)\n\t\t\tphba->cfg_nvmet_mrq = LPFC_NVMET_MRQ_MAX;\n\t}\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\"2574 IO channels: hdwQ %d IRQ %d MRQ: %d\\n\",\n\t\t\tphba->cfg_hdw_queue, phba->cfg_irq_chann,\n\t\t\tphba->cfg_nvmet_mrq);\n\n\t \n\tphba->sli4_hba.eq_esize = LPFC_EQE_SIZE_4B;\n\tphba->sli4_hba.eq_ecount = LPFC_EQE_DEF_COUNT;\n\n\t \n\tphba->sli4_hba.cq_esize = LPFC_CQE_SIZE;\n\tphba->sli4_hba.cq_ecount = LPFC_CQE_DEF_COUNT;\n\treturn 0;\n}\n\nstatic int\nlpfc_alloc_io_wq_cq(struct lpfc_hba *phba, int idx)\n{\n\tstruct lpfc_queue *qdesc;\n\tu32 wqesize;\n\tint cpu;\n\n\tcpu = lpfc_find_cpu_handle(phba, idx, LPFC_FIND_BY_HDWQ);\n\t \n\tif (phba->enab_exp_wqcq_pages)\n\t\t \n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_EXPANDED_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t\t      LPFC_CQE_EXP_COUNT, cpu);\n\n\telse\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t\t      phba->sli4_hba.cq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0499 Failed allocate fast-path IO CQ (%d)\\n\",\n\t\t\t\tidx);\n\t\treturn 1;\n\t}\n\tqdesc->qe_valid = 1;\n\tqdesc->hdwq = idx;\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.hdwq[idx].io_cq = qdesc;\n\n\t \n\tif (phba->enab_exp_wqcq_pages) {\n\t\t \n\t\twqesize = (phba->fcp_embed_io) ?\n\t\t\tLPFC_WQE128_SIZE : phba->sli4_hba.wq_esize;\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_EXPANDED_PAGE_SIZE,\n\t\t\t\t\t      wqesize,\n\t\t\t\t\t      LPFC_WQE_EXP_COUNT, cpu);\n\t} else\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.wq_esize,\n\t\t\t\t\t      phba->sli4_hba.wq_ecount, cpu);\n\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0503 Failed allocate fast-path IO WQ (%d)\\n\",\n\t\t\t\tidx);\n\t\treturn 1;\n\t}\n\tqdesc->hdwq = idx;\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.hdwq[idx].io_wq = qdesc;\n\tlist_add_tail(&qdesc->wq_list, &phba->sli4_hba.lpfc_wq_list);\n\treturn 0;\n}\n\n \nint\nlpfc_sli4_queue_create(struct lpfc_hba *phba)\n{\n\tstruct lpfc_queue *qdesc;\n\tint idx, cpu, eqcpu;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_vector_map_info *eqcpup;\n\tstruct lpfc_eq_intr_info *eqi;\n\n\t \n\tphba->sli4_hba.mq_esize = LPFC_MQE_SIZE;\n\tphba->sli4_hba.mq_ecount = LPFC_MQE_DEF_COUNT;\n\tphba->sli4_hba.wq_esize = LPFC_WQE_SIZE;\n\tphba->sli4_hba.wq_ecount = LPFC_WQE_DEF_COUNT;\n\tphba->sli4_hba.rq_esize = LPFC_RQE_SIZE;\n\tphba->sli4_hba.rq_ecount = LPFC_RQE_DEF_COUNT;\n\tphba->sli4_hba.eq_esize = LPFC_EQE_SIZE_4B;\n\tphba->sli4_hba.eq_ecount = LPFC_EQE_DEF_COUNT;\n\tphba->sli4_hba.cq_esize = LPFC_CQE_SIZE;\n\tphba->sli4_hba.cq_ecount = LPFC_CQE_DEF_COUNT;\n\n\tif (!phba->sli4_hba.hdwq) {\n\t\tphba->sli4_hba.hdwq = kcalloc(\n\t\t\tphba->cfg_hdw_queue, sizeof(struct lpfc_sli4_hdw_queue),\n\t\t\tGFP_KERNEL);\n\t\tif (!phba->sli4_hba.hdwq) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6427 Failed allocate memory for \"\n\t\t\t\t\t\"fast-path Hardware Queue array\\n\");\n\t\t\tgoto out_error;\n\t\t}\n\t\t \n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\t\tspin_lock_init(&qp->io_buf_list_get_lock);\n\t\t\tspin_lock_init(&qp->io_buf_list_put_lock);\n\t\t\tINIT_LIST_HEAD(&qp->lpfc_io_buf_list_get);\n\t\t\tINIT_LIST_HEAD(&qp->lpfc_io_buf_list_put);\n\t\t\tqp->get_io_bufs = 0;\n\t\t\tqp->put_io_bufs = 0;\n\t\t\tqp->total_io_bufs = 0;\n\t\t\tspin_lock_init(&qp->abts_io_buf_list_lock);\n\t\t\tINIT_LIST_HEAD(&qp->lpfc_abts_io_buf_list);\n\t\t\tqp->abts_scsi_io_bufs = 0;\n\t\t\tqp->abts_nvme_io_bufs = 0;\n\t\t\tINIT_LIST_HEAD(&qp->sgl_list);\n\t\t\tINIT_LIST_HEAD(&qp->cmd_rsp_buf_list);\n\t\t\tspin_lock_init(&qp->hdwq_lock);\n\t\t}\n\t}\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tif (phba->nvmet_support) {\n\t\t\tphba->sli4_hba.nvmet_cqset = kcalloc(\n\t\t\t\t\tphba->cfg_nvmet_mrq,\n\t\t\t\t\tsizeof(struct lpfc_queue *),\n\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!phba->sli4_hba.nvmet_cqset) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3121 Fail allocate memory for \"\n\t\t\t\t\t\"fast-path CQ set array\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tphba->sli4_hba.nvmet_mrq_hdr = kcalloc(\n\t\t\t\t\tphba->cfg_nvmet_mrq,\n\t\t\t\t\tsizeof(struct lpfc_queue *),\n\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!phba->sli4_hba.nvmet_mrq_hdr) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3122 Fail allocate memory for \"\n\t\t\t\t\t\"fast-path RQ set hdr array\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tphba->sli4_hba.nvmet_mrq_data = kcalloc(\n\t\t\t\t\tphba->cfg_nvmet_mrq,\n\t\t\t\t\tsizeof(struct lpfc_queue *),\n\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!phba->sli4_hba.nvmet_mrq_data) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3124 Fail allocate memory for \"\n\t\t\t\t\t\"fast-path RQ set data array\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t}\n\t}\n\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_wq_list);\n\n\t \n\tfor_each_present_cpu(cpu) {\n\t\t \n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\t\tif (!(cpup->flag & LPFC_CPU_FIRST_IRQ))\n\t\t\tcontinue;\n\n\t\t \n\t\tqp = &phba->sli4_hba.hdwq[cpup->hdwq];\n\n\t\t \n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.eq_esize,\n\t\t\t\t\t      phba->sli4_hba.eq_ecount, cpu);\n\t\tif (!qdesc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0497 Failed allocate EQ (%d)\\n\",\n\t\t\t\t\tcpup->hdwq);\n\t\t\tgoto out_error;\n\t\t}\n\t\tqdesc->qe_valid = 1;\n\t\tqdesc->hdwq = cpup->hdwq;\n\t\tqdesc->chann = cpu;  \n\t\tqdesc->last_cpu = qdesc->chann;\n\n\t\t \n\t\tqp->hba_eq = qdesc;\n\n\t\teqi = per_cpu_ptr(phba->sli4_hba.eq_info, qdesc->last_cpu);\n\t\tlist_add(&qdesc->cpu_list, &eqi->list);\n\t}\n\n\t \n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t \n\t\tif (cpup->flag & LPFC_CPU_FIRST_IRQ)\n\t\t\tcontinue;\n\n\t\t \n\t\tqp = &phba->sli4_hba.hdwq[cpup->hdwq];\n\t\tif (qp->hba_eq)\n\t\t\tcontinue;\n\n\t\t \n\t\teqcpu = lpfc_find_cpu_handle(phba, cpup->eq, LPFC_FIND_BY_EQ);\n\t\teqcpup = &phba->sli4_hba.cpu_map[eqcpu];\n\t\tqp->hba_eq = phba->sli4_hba.hdwq[eqcpup->hdwq].hba_eq;\n\t}\n\n\t \n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tif (lpfc_alloc_io_wq_cq(phba, idx))\n\t\t\tgoto out_error;\n\t}\n\n\tif (phba->nvmet_support) {\n\t\tfor (idx = 0; idx < phba->cfg_nvmet_mrq; idx++) {\n\t\t\tcpu = lpfc_find_cpu_handle(phba, idx,\n\t\t\t\t\t\t   LPFC_FIND_BY_HDWQ);\n\t\t\tqdesc = lpfc_sli4_queue_alloc(phba,\n\t\t\t\t\t\t      LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t\t\t      phba->sli4_hba.cq_ecount,\n\t\t\t\t\t\t      cpu);\n\t\t\tif (!qdesc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3142 Failed allocate NVME \"\n\t\t\t\t\t\t\"CQ Set (%d)\\n\", idx);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tqdesc->qe_valid = 1;\n\t\t\tqdesc->hdwq = idx;\n\t\t\tqdesc->chann = cpu;\n\t\t\tphba->sli4_hba.nvmet_cqset[idx] = qdesc;\n\t\t}\n\t}\n\n\t \n\n\tcpu = lpfc_find_cpu_handle(phba, 0, LPFC_FIND_BY_EQ);\n\t \n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t      phba->sli4_hba.cq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0500 Failed allocate slow-path mailbox CQ\\n\");\n\t\tgoto out_error;\n\t}\n\tqdesc->qe_valid = 1;\n\tphba->sli4_hba.mbx_cq = qdesc;\n\n\t \n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t      phba->sli4_hba.cq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0501 Failed allocate slow-path ELS CQ\\n\");\n\t\tgoto out_error;\n\t}\n\tqdesc->qe_valid = 1;\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.els_cq = qdesc;\n\n\n\t \n\n\t \n\n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.mq_esize,\n\t\t\t\t      phba->sli4_hba.mq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0505 Failed allocate slow-path MQ\\n\");\n\t\tgoto out_error;\n\t}\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.mbx_wq = qdesc;\n\n\t \n\n\t \n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.wq_esize,\n\t\t\t\t      phba->sli4_hba.wq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0504 Failed allocate slow-path ELS WQ\\n\");\n\t\tgoto out_error;\n\t}\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.els_wq = qdesc;\n\tlist_add_tail(&qdesc->wq_list, &phba->sli4_hba.lpfc_wq_list);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t \n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t\t      phba->sli4_hba.cq_ecount, cpu);\n\t\tif (!qdesc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6079 Failed allocate NVME LS CQ\\n\");\n\t\t\tgoto out_error;\n\t\t}\n\t\tqdesc->chann = cpu;\n\t\tqdesc->qe_valid = 1;\n\t\tphba->sli4_hba.nvmels_cq = qdesc;\n\n\t\t \n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.wq_esize,\n\t\t\t\t\t      phba->sli4_hba.wq_ecount, cpu);\n\t\tif (!qdesc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6080 Failed allocate NVME LS WQ\\n\");\n\t\t\tgoto out_error;\n\t\t}\n\t\tqdesc->chann = cpu;\n\t\tphba->sli4_hba.nvmels_wq = qdesc;\n\t\tlist_add_tail(&qdesc->wq_list, &phba->sli4_hba.lpfc_wq_list);\n\t}\n\n\t \n\n\t \n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.rq_esize,\n\t\t\t\t      phba->sli4_hba.rq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0506 Failed allocate receive HRQ\\n\");\n\t\tgoto out_error;\n\t}\n\tphba->sli4_hba.hdr_rq = qdesc;\n\n\t \n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.rq_esize,\n\t\t\t\t      phba->sli4_hba.rq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0507 Failed allocate receive DRQ\\n\");\n\t\tgoto out_error;\n\t}\n\tphba->sli4_hba.dat_rq = qdesc;\n\n\tif ((phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) &&\n\t    phba->nvmet_support) {\n\t\tfor (idx = 0; idx < phba->cfg_nvmet_mrq; idx++) {\n\t\t\tcpu = lpfc_find_cpu_handle(phba, idx,\n\t\t\t\t\t\t   LPFC_FIND_BY_HDWQ);\n\t\t\t \n\t\t\tqdesc = lpfc_sli4_queue_alloc(phba,\n\t\t\t\t\t\t      LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t\t      phba->sli4_hba.rq_esize,\n\t\t\t\t\t\t      LPFC_NVMET_RQE_DEF_COUNT,\n\t\t\t\t\t\t      cpu);\n\t\t\tif (!qdesc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3146 Failed allocate \"\n\t\t\t\t\t\t\"receive HRQ\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tqdesc->hdwq = idx;\n\t\t\tphba->sli4_hba.nvmet_mrq_hdr[idx] = qdesc;\n\n\t\t\t \n\t\t\tqdesc->rqbp = kzalloc_node(sizeof(*qdesc->rqbp),\n\t\t\t\t\t\t   GFP_KERNEL,\n\t\t\t\t\t\t   cpu_to_node(cpu));\n\t\t\tif (qdesc->rqbp == NULL) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6131 Failed allocate \"\n\t\t\t\t\t\t\"Header RQBP\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\n\t\t\t \n\t\t\tINIT_LIST_HEAD(&qdesc->rqbp->rqb_buffer_list);\n\n\t\t\t \n\t\t\tqdesc = lpfc_sli4_queue_alloc(phba,\n\t\t\t\t\t\t      LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t\t      phba->sli4_hba.rq_esize,\n\t\t\t\t\t\t      LPFC_NVMET_RQE_DEF_COUNT,\n\t\t\t\t\t\t      cpu);\n\t\t\tif (!qdesc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3156 Failed allocate \"\n\t\t\t\t\t\t\"receive DRQ\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tqdesc->hdwq = idx;\n\t\t\tphba->sli4_hba.nvmet_mrq_data[idx] = qdesc;\n\t\t}\n\t}\n\n\t \n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tmemset(&phba->sli4_hba.hdwq[idx].nvme_cstat, 0,\n\t\t\t       sizeof(phba->sli4_hba.hdwq[idx].nvme_cstat));\n\t\t}\n\t}\n\n\t \n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP) {\n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tmemset(&phba->sli4_hba.hdwq[idx].scsi_cstat, 0,\n\t\t\t       sizeof(phba->sli4_hba.hdwq[idx].scsi_cstat));\n\t\t}\n\t}\n\n\treturn 0;\n\nout_error:\n\tlpfc_sli4_queue_destroy(phba);\n\treturn -ENOMEM;\n}\n\nstatic inline void\n__lpfc_sli4_release_queue(struct lpfc_queue **qp)\n{\n\tif (*qp != NULL) {\n\t\tlpfc_sli4_queue_free(*qp);\n\t\t*qp = NULL;\n\t}\n}\n\nstatic inline void\nlpfc_sli4_release_queues(struct lpfc_queue ***qs, int max)\n{\n\tint idx;\n\n\tif (*qs == NULL)\n\t\treturn;\n\n\tfor (idx = 0; idx < max; idx++)\n\t\t__lpfc_sli4_release_queue(&(*qs)[idx]);\n\n\tkfree(*qs);\n\t*qs = NULL;\n}\n\nstatic inline void\nlpfc_sli4_release_hdwq(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *hdwq;\n\tstruct lpfc_queue *eq;\n\tuint32_t idx;\n\n\thdwq = phba->sli4_hba.hdwq;\n\n\t \n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t \n\t\tlpfc_sli4_queue_free(hdwq[idx].io_cq);\n\t\tlpfc_sli4_queue_free(hdwq[idx].io_wq);\n\t\thdwq[idx].hba_eq = NULL;\n\t\thdwq[idx].io_cq = NULL;\n\t\thdwq[idx].io_wq = NULL;\n\t\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\t\tlpfc_free_sgl_per_hdwq(phba, &hdwq[idx]);\n\t\tlpfc_free_cmd_rsp_buf_per_hdwq(phba, &hdwq[idx]);\n\t}\n\t \n\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++) {\n\t\t \n\t\teq = phba->sli4_hba.hba_eq_hdl[idx].eq;\n\t\tlpfc_sli4_queue_free(eq);\n\t\tphba->sli4_hba.hba_eq_hdl[idx].eq = NULL;\n\t}\n}\n\n \nvoid\nlpfc_sli4_queue_destroy(struct lpfc_hba *phba)\n{\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tphba->sli.sli_flag |= LPFC_QUEUE_FREE_INIT;\n\twhile (phba->sli.sli_flag & LPFC_QUEUE_FREE_WAIT) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tmsleep(20);\n\t\tspin_lock_irq(&phba->hbalock);\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_sli4_cleanup_poll_list(phba);\n\n\t \n\tif (phba->sli4_hba.hdwq)\n\t\tlpfc_sli4_release_hdwq(phba);\n\n\tif (phba->nvmet_support) {\n\t\tlpfc_sli4_release_queues(&phba->sli4_hba.nvmet_cqset,\n\t\t\t\t\t phba->cfg_nvmet_mrq);\n\n\t\tlpfc_sli4_release_queues(&phba->sli4_hba.nvmet_mrq_hdr,\n\t\t\t\t\t phba->cfg_nvmet_mrq);\n\t\tlpfc_sli4_release_queues(&phba->sli4_hba.nvmet_mrq_data,\n\t\t\t\t\t phba->cfg_nvmet_mrq);\n\t}\n\n\t \n\t__lpfc_sli4_release_queue(&phba->sli4_hba.mbx_wq);\n\n\t \n\t__lpfc_sli4_release_queue(&phba->sli4_hba.els_wq);\n\n\t \n\t__lpfc_sli4_release_queue(&phba->sli4_hba.nvmels_wq);\n\n\t \n\t__lpfc_sli4_release_queue(&phba->sli4_hba.hdr_rq);\n\t__lpfc_sli4_release_queue(&phba->sli4_hba.dat_rq);\n\n\t \n\t__lpfc_sli4_release_queue(&phba->sli4_hba.els_cq);\n\n\t \n\t__lpfc_sli4_release_queue(&phba->sli4_hba.nvmels_cq);\n\n\t \n\t__lpfc_sli4_release_queue(&phba->sli4_hba.mbx_cq);\n\n\t \n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_wq_list);\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tphba->sli.sli_flag &= ~LPFC_QUEUE_FREE_INIT;\n\tspin_unlock_irq(&phba->hbalock);\n}\n\nint\nlpfc_free_rq_buffer(struct lpfc_hba *phba, struct lpfc_queue *rq)\n{\n\tstruct lpfc_rqb *rqbp;\n\tstruct lpfc_dmabuf *h_buf;\n\tstruct rqb_dmabuf *rqb_buffer;\n\n\trqbp = rq->rqbp;\n\twhile (!list_empty(&rqbp->rqb_buffer_list)) {\n\t\tlist_remove_head(&rqbp->rqb_buffer_list, h_buf,\n\t\t\t\t struct lpfc_dmabuf, list);\n\n\t\trqb_buffer = container_of(h_buf, struct rqb_dmabuf, hbuf);\n\t\t(rqbp->rqb_free_buffer)(phba, rqb_buffer);\n\t\trqbp->buffer_count--;\n\t}\n\treturn 1;\n}\n\nstatic int\nlpfc_create_wq_cq(struct lpfc_hba *phba, struct lpfc_queue *eq,\n\tstruct lpfc_queue *cq, struct lpfc_queue *wq, uint16_t *cq_map,\n\tint qidx, uint32_t qtype)\n{\n\tstruct lpfc_sli_ring *pring;\n\tint rc;\n\n\tif (!eq || !cq || !wq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"6085 Fast-path %s (%d) not allocated\\n\",\n\t\t\t((eq) ? ((cq) ? \"WQ\" : \"CQ\") : \"EQ\"), qidx);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\trc = lpfc_cq_create(phba, cq, eq,\n\t\t\t(qtype == LPFC_MBOX) ? LPFC_MCQ : LPFC_WCQ, qtype);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6086 Failed setup of CQ (%d), rc = 0x%x\\n\",\n\t\t\t\tqidx, (uint32_t)rc);\n\t\treturn rc;\n\t}\n\n\tif (qtype != LPFC_MBOX) {\n\t\t \n\t\tif (cq_map)\n\t\t\t*cq_map = cq->queue_id;\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"6087 CQ setup: cq[%d]-id=%d, parent eq[%d]-id=%d\\n\",\n\t\t\tqidx, cq->queue_id, qidx, eq->queue_id);\n\n\t\t \n\t\trc = lpfc_wq_create(phba, wq, cq, qtype);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"4618 Fail setup fastpath WQ (%d), rc = 0x%x\\n\",\n\t\t\t\tqidx, (uint32_t)rc);\n\t\t\t \n\t\t\treturn rc;\n\t\t}\n\n\t\t \n\t\tpring = wq->pring;\n\t\tpring->sli.sli4.wqp = (void *)wq;\n\t\tcq->pring = pring;\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2593 WQ setup: wq[%d]-id=%d assoc=%d, cq[%d]-id=%d\\n\",\n\t\t\tqidx, wq->queue_id, wq->assoc_qid, qidx, cq->queue_id);\n\t} else {\n\t\trc = lpfc_mq_create(phba, wq, cq, LPFC_MBOX);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0539 Failed setup of slow-path MQ: \"\n\t\t\t\t\t\"rc = 0x%x\\n\", rc);\n\t\t\t \n\t\t\treturn rc;\n\t\t}\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2589 MBX MQ setup: wq-id=%d, parent cq-id=%d\\n\",\n\t\t\tphba->sli4_hba.mbx_wq->queue_id,\n\t\t\tphba->sli4_hba.mbx_cq->queue_id);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void\nlpfc_setup_cq_lookup(struct lpfc_hba *phba)\n{\n\tstruct lpfc_queue *eq, *childq;\n\tint qidx;\n\n\tmemset(phba->sli4_hba.cq_lookup, 0,\n\t       (sizeof(struct lpfc_queue *) * (phba->sli4_hba.cq_max + 1)));\n\t \n\tfor (qidx = 0; qidx < phba->cfg_irq_chann; qidx++) {\n\t\t \n\t\teq = phba->sli4_hba.hba_eq_hdl[qidx].eq;\n\t\tif (!eq)\n\t\t\tcontinue;\n\t\t \n\t\tlist_for_each_entry(childq, &eq->child_list, list) {\n\t\t\tif (childq->queue_id > phba->sli4_hba.cq_max)\n\t\t\t\tcontinue;\n\t\t\tif (childq->subtype == LPFC_IO)\n\t\t\t\tphba->sli4_hba.cq_lookup[childq->queue_id] =\n\t\t\t\t\tchildq;\n\t\t}\n\t}\n}\n\n \nint\nlpfc_sli4_queue_setup(struct lpfc_hba *phba)\n{\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tLPFC_MBOXQ_t *mboxq;\n\tint qidx, cpu;\n\tuint32_t length, usdelay;\n\tint rc = -ENOMEM;\n\n\t \n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3249 Unable to allocate memory for \"\n\t\t\t\t\"QUERY_FW_CFG mailbox command\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tlength = (sizeof(struct lpfc_mbx_query_fw_config) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_QUERY_FW_CFG,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t\t&mboxq->u.mqe.un.sli4_config.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3250 QUERY_FW_CFG mailbox failed with status \"\n\t\t\t\t\"x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\trc = -ENXIO;\n\t\tgoto out_error;\n\t}\n\n\tphba->sli4_hba.fw_func_mode =\n\t\t\tmboxq->u.mqe.un.query_fw_cfg.rsp.function_mode;\n\tphba->sli4_hba.ulp0_mode = mboxq->u.mqe.un.query_fw_cfg.rsp.ulp0_mode;\n\tphba->sli4_hba.ulp1_mode = mboxq->u.mqe.un.query_fw_cfg.rsp.ulp1_mode;\n\tphba->sli4_hba.physical_port =\n\t\t\tmboxq->u.mqe.un.query_fw_cfg.rsp.physical_port;\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"3251 QUERY_FW_CFG: func_mode:x%x, ulp0_mode:x%x, \"\n\t\t\t\"ulp1_mode:x%x\\n\", phba->sli4_hba.fw_func_mode,\n\t\t\tphba->sli4_hba.ulp0_mode, phba->sli4_hba.ulp1_mode);\n\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\n\t \n\tqp = phba->sli4_hba.hdwq;\n\n\t \n\tif (!qp) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3147 Fast-path EQs not allocated\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_error;\n\t}\n\n\t \n\tfor (qidx = 0; qidx < phba->cfg_irq_chann; qidx++) {\n\t\t \n\t\tfor_each_present_cpu(cpu) {\n\t\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t\t \n\t\t\tif (!(cpup->flag & LPFC_CPU_FIRST_IRQ))\n\t\t\t\tcontinue;\n\t\t\tif (qidx != cpup->eq)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\trc = lpfc_eq_create(phba, qp[cpup->hdwq].hba_eq,\n\t\t\t\t\t    phba->cfg_fcp_imax);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"0523 Failed setup of fast-path\"\n\t\t\t\t\t\t\" EQ (%d), rc = 0x%x\\n\",\n\t\t\t\t\t\tcpup->eq, (uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\n\t\t\t \n\t\t\tphba->sli4_hba.hba_eq_hdl[cpup->eq].eq =\n\t\t\t\tqp[cpup->hdwq].hba_eq;\n\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"2584 HBA EQ setup: queue[%d]-id=%d\\n\",\n\t\t\t\t\tcpup->eq,\n\t\t\t\t\tqp[cpup->hdwq].hba_eq->queue_id);\n\t\t}\n\t}\n\n\t \n\tfor (qidx = 0; qidx < phba->cfg_hdw_queue; qidx++) {\n\t\tcpu = lpfc_find_cpu_handle(phba, qidx, LPFC_FIND_BY_HDWQ);\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t \n\t\trc = lpfc_create_wq_cq(phba,\n\t\t\t\t       phba->sli4_hba.hdwq[cpup->hdwq].hba_eq,\n\t\t\t\t       qp[qidx].io_cq,\n\t\t\t\t       qp[qidx].io_wq,\n\t\t\t\t       &phba->sli4_hba.hdwq[qidx].io_cq_map,\n\t\t\t\t       qidx,\n\t\t\t\t       LPFC_IO);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0535 Failed to setup fastpath \"\n\t\t\t\t\t\"IO WQ/CQ (%d), rc = 0x%x\\n\",\n\t\t\t\t\tqidx, (uint32_t)rc);\n\t\t\tgoto out_destroy;\n\t\t}\n\t}\n\n\t \n\n\t \n\n\tif (!phba->sli4_hba.mbx_cq || !phba->sli4_hba.mbx_wq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0528 %s not allocated\\n\",\n\t\t\t\tphba->sli4_hba.mbx_cq ?\n\t\t\t\t\"Mailbox WQ\" : \"Mailbox CQ\");\n\t\trc = -ENOMEM;\n\t\tgoto out_destroy;\n\t}\n\n\trc = lpfc_create_wq_cq(phba, qp[0].hba_eq,\n\t\t\t       phba->sli4_hba.mbx_cq,\n\t\t\t       phba->sli4_hba.mbx_wq,\n\t\t\t       NULL, 0, LPFC_MBOX);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0529 Failed setup of mailbox WQ/CQ: rc = 0x%x\\n\",\n\t\t\t(uint32_t)rc);\n\t\tgoto out_destroy;\n\t}\n\tif (phba->nvmet_support) {\n\t\tif (!phba->sli4_hba.nvmet_cqset) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3165 Fast-path NVME CQ Set \"\n\t\t\t\t\t\"array not allocated\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_destroy;\n\t\t}\n\t\tif (phba->cfg_nvmet_mrq > 1) {\n\t\t\trc = lpfc_cq_create_set(phba,\n\t\t\t\t\tphba->sli4_hba.nvmet_cqset,\n\t\t\t\t\tqp,\n\t\t\t\t\tLPFC_WCQ, LPFC_NVMET);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3164 Failed setup of NVME CQ \"\n\t\t\t\t\t\t\"Set, rc = 0x%x\\n\",\n\t\t\t\t\t\t(uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\trc = lpfc_cq_create(phba, phba->sli4_hba.nvmet_cqset[0],\n\t\t\t\t\t    qp[0].hba_eq,\n\t\t\t\t\t    LPFC_WCQ, LPFC_NVMET);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6089 Failed setup NVMET CQ: \"\n\t\t\t\t\t\t\"rc = 0x%x\\n\", (uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\t\t\tphba->sli4_hba.nvmet_cqset[0]->chann = 0;\n\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"6090 NVMET CQ setup: cq-id=%d, \"\n\t\t\t\t\t\"parent eq-id=%d\\n\",\n\t\t\t\t\tphba->sli4_hba.nvmet_cqset[0]->queue_id,\n\t\t\t\t\tqp[0].hba_eq->queue_id);\n\t\t}\n\t}\n\n\t \n\tif (!phba->sli4_hba.els_cq || !phba->sli4_hba.els_wq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0530 ELS %s not allocated\\n\",\n\t\t\t\tphba->sli4_hba.els_cq ? \"WQ\" : \"CQ\");\n\t\trc = -ENOMEM;\n\t\tgoto out_destroy;\n\t}\n\trc = lpfc_create_wq_cq(phba, qp[0].hba_eq,\n\t\t\t       phba->sli4_hba.els_cq,\n\t\t\t       phba->sli4_hba.els_wq,\n\t\t\t       NULL, 0, LPFC_ELS);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0525 Failed setup of ELS WQ/CQ: rc = 0x%x\\n\",\n\t\t\t\t(uint32_t)rc);\n\t\tgoto out_destroy;\n\t}\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2590 ELS WQ setup: wq-id=%d, parent cq-id=%d\\n\",\n\t\t\tphba->sli4_hba.els_wq->queue_id,\n\t\t\tphba->sli4_hba.els_cq->queue_id);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t \n\t\tif (!phba->sli4_hba.nvmels_cq || !phba->sli4_hba.nvmels_wq) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6091 LS %s not allocated\\n\",\n\t\t\t\t\tphba->sli4_hba.nvmels_cq ? \"WQ\" : \"CQ\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_destroy;\n\t\t}\n\t\trc = lpfc_create_wq_cq(phba, qp[0].hba_eq,\n\t\t\t\t       phba->sli4_hba.nvmels_cq,\n\t\t\t\t       phba->sli4_hba.nvmels_wq,\n\t\t\t\t       NULL, 0, LPFC_NVME_LS);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0526 Failed setup of NVVME LS WQ/CQ: \"\n\t\t\t\t\t\"rc = 0x%x\\n\", (uint32_t)rc);\n\t\t\tgoto out_destroy;\n\t\t}\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"6096 ELS WQ setup: wq-id=%d, \"\n\t\t\t\t\"parent cq-id=%d\\n\",\n\t\t\t\tphba->sli4_hba.nvmels_wq->queue_id,\n\t\t\t\tphba->sli4_hba.nvmels_cq->queue_id);\n\t}\n\n\t \n\tif (phba->nvmet_support) {\n\t\tif ((!phba->sli4_hba.nvmet_cqset) ||\n\t\t    (!phba->sli4_hba.nvmet_mrq_hdr) ||\n\t\t    (!phba->sli4_hba.nvmet_mrq_data)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6130 MRQ CQ Queues not \"\n\t\t\t\t\t\"allocated\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_destroy;\n\t\t}\n\t\tif (phba->cfg_nvmet_mrq > 1) {\n\t\t\trc = lpfc_mrq_create(phba,\n\t\t\t\t\t     phba->sli4_hba.nvmet_mrq_hdr,\n\t\t\t\t\t     phba->sli4_hba.nvmet_mrq_data,\n\t\t\t\t\t     phba->sli4_hba.nvmet_cqset,\n\t\t\t\t\t     LPFC_NVMET);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6098 Failed setup of NVMET \"\n\t\t\t\t\t\t\"MRQ: rc = 0x%x\\n\",\n\t\t\t\t\t\t(uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\n\t\t} else {\n\t\t\trc = lpfc_rq_create(phba,\n\t\t\t\t\t    phba->sli4_hba.nvmet_mrq_hdr[0],\n\t\t\t\t\t    phba->sli4_hba.nvmet_mrq_data[0],\n\t\t\t\t\t    phba->sli4_hba.nvmet_cqset[0],\n\t\t\t\t\t    LPFC_NVMET);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6057 Failed setup of NVMET \"\n\t\t\t\t\t\t\"Receive Queue: rc = 0x%x\\n\",\n\t\t\t\t\t\t(uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\n\t\t\tlpfc_printf_log(\n\t\t\t\tphba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"6099 NVMET RQ setup: hdr-rq-id=%d, \"\n\t\t\t\t\"dat-rq-id=%d parent cq-id=%d\\n\",\n\t\t\t\tphba->sli4_hba.nvmet_mrq_hdr[0]->queue_id,\n\t\t\t\tphba->sli4_hba.nvmet_mrq_data[0]->queue_id,\n\t\t\t\tphba->sli4_hba.nvmet_cqset[0]->queue_id);\n\n\t\t}\n\t}\n\n\tif (!phba->sli4_hba.hdr_rq || !phba->sli4_hba.dat_rq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0540 Receive Queue not allocated\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_destroy;\n\t}\n\n\trc = lpfc_rq_create(phba, phba->sli4_hba.hdr_rq, phba->sli4_hba.dat_rq,\n\t\t\t    phba->sli4_hba.els_cq, LPFC_USOL);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0541 Failed setup of Receive Queue: \"\n\t\t\t\t\"rc = 0x%x\\n\", (uint32_t)rc);\n\t\tgoto out_destroy;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2592 USL RQ setup: hdr-rq-id=%d, dat-rq-id=%d \"\n\t\t\t\"parent cq-id=%d\\n\",\n\t\t\tphba->sli4_hba.hdr_rq->queue_id,\n\t\t\tphba->sli4_hba.dat_rq->queue_id,\n\t\t\tphba->sli4_hba.els_cq->queue_id);\n\n\tif (phba->cfg_fcp_imax)\n\t\tusdelay = LPFC_SEC_TO_USEC / phba->cfg_fcp_imax;\n\telse\n\t\tusdelay = 0;\n\n\tfor (qidx = 0; qidx < phba->cfg_irq_chann;\n\t     qidx += LPFC_MAX_EQ_DELAY_EQID_CNT)\n\t\tlpfc_modify_hba_eq_delay(phba, qidx, LPFC_MAX_EQ_DELAY_EQID_CNT,\n\t\t\t\t\t usdelay);\n\n\tif (phba->sli4_hba.cq_max) {\n\t\tkfree(phba->sli4_hba.cq_lookup);\n\t\tphba->sli4_hba.cq_lookup = kcalloc((phba->sli4_hba.cq_max + 1),\n\t\t\tsizeof(struct lpfc_queue *), GFP_KERNEL);\n\t\tif (!phba->sli4_hba.cq_lookup) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0549 Failed setup of CQ Lookup table: \"\n\t\t\t\t\t\"size 0x%x\\n\", phba->sli4_hba.cq_max);\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_destroy;\n\t\t}\n\t\tlpfc_setup_cq_lookup(phba);\n\t}\n\treturn 0;\n\nout_destroy:\n\tlpfc_sli4_queue_unset(phba);\nout_error:\n\treturn rc;\n}\n\n \nvoid\nlpfc_sli4_queue_unset(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_queue *eq;\n\tint qidx;\n\n\t \n\tif (phba->sli4_hba.mbx_wq)\n\t\tlpfc_mq_destroy(phba, phba->sli4_hba.mbx_wq);\n\n\t \n\tif (phba->sli4_hba.nvmels_wq)\n\t\tlpfc_wq_destroy(phba, phba->sli4_hba.nvmels_wq);\n\n\t \n\tif (phba->sli4_hba.els_wq)\n\t\tlpfc_wq_destroy(phba, phba->sli4_hba.els_wq);\n\n\t \n\tif (phba->sli4_hba.hdr_rq)\n\t\tlpfc_rq_destroy(phba, phba->sli4_hba.hdr_rq,\n\t\t\t\tphba->sli4_hba.dat_rq);\n\n\t \n\tif (phba->sli4_hba.mbx_cq)\n\t\tlpfc_cq_destroy(phba, phba->sli4_hba.mbx_cq);\n\n\t \n\tif (phba->sli4_hba.els_cq)\n\t\tlpfc_cq_destroy(phba, phba->sli4_hba.els_cq);\n\n\t \n\tif (phba->sli4_hba.nvmels_cq)\n\t\tlpfc_cq_destroy(phba, phba->sli4_hba.nvmels_cq);\n\n\tif (phba->nvmet_support) {\n\t\t \n\t\tif (phba->sli4_hba.nvmet_mrq_hdr) {\n\t\t\tfor (qidx = 0; qidx < phba->cfg_nvmet_mrq; qidx++)\n\t\t\t\tlpfc_rq_destroy(\n\t\t\t\t\tphba,\n\t\t\t\t\tphba->sli4_hba.nvmet_mrq_hdr[qidx],\n\t\t\t\t\tphba->sli4_hba.nvmet_mrq_data[qidx]);\n\t\t}\n\n\t\t \n\t\tif (phba->sli4_hba.nvmet_cqset) {\n\t\t\tfor (qidx = 0; qidx < phba->cfg_nvmet_mrq; qidx++)\n\t\t\t\tlpfc_cq_destroy(\n\t\t\t\t\tphba, phba->sli4_hba.nvmet_cqset[qidx]);\n\t\t}\n\t}\n\n\t \n\tif (phba->sli4_hba.hdwq) {\n\t\t \n\t\tfor (qidx = 0; qidx < phba->cfg_hdw_queue; qidx++) {\n\t\t\t \n\t\t\tqp = &phba->sli4_hba.hdwq[qidx];\n\t\t\tlpfc_wq_destroy(phba, qp->io_wq);\n\t\t\tlpfc_cq_destroy(phba, qp->io_cq);\n\t\t}\n\t\t \n\t\tfor (qidx = 0; qidx < phba->cfg_irq_chann; qidx++) {\n\t\t\t \n\t\t\teq = phba->sli4_hba.hba_eq_hdl[qidx].eq;\n\t\t\tlpfc_eq_destroy(phba, eq);\n\t\t}\n\t}\n\n\tkfree(phba->sli4_hba.cq_lookup);\n\tphba->sli4_hba.cq_lookup = NULL;\n\tphba->sli4_hba.cq_max = 0;\n}\n\n \nstatic int\nlpfc_sli4_cq_event_pool_create(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event;\n\tint i;\n\n\tfor (i = 0; i < (4 * phba->sli4_hba.cq_ecount); i++) {\n\t\tcq_event = kmalloc(sizeof(struct lpfc_cq_event), GFP_KERNEL);\n\t\tif (!cq_event)\n\t\t\tgoto out_pool_create_fail;\n\t\tlist_add_tail(&cq_event->list,\n\t\t\t      &phba->sli4_hba.sp_cqe_event_pool);\n\t}\n\treturn 0;\n\nout_pool_create_fail:\n\tlpfc_sli4_cq_event_pool_destroy(phba);\n\treturn -ENOMEM;\n}\n\n \nstatic void\nlpfc_sli4_cq_event_pool_destroy(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event, *next_cq_event;\n\n\tlist_for_each_entry_safe(cq_event, next_cq_event,\n\t\t\t\t &phba->sli4_hba.sp_cqe_event_pool, list) {\n\t\tlist_del(&cq_event->list);\n\t\tkfree(cq_event);\n\t}\n}\n\n \nstruct lpfc_cq_event *\n__lpfc_sli4_cq_event_alloc(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event = NULL;\n\n\tlist_remove_head(&phba->sli4_hba.sp_cqe_event_pool, cq_event,\n\t\t\t struct lpfc_cq_event, list);\n\treturn cq_event;\n}\n\n \nstruct lpfc_cq_event *\nlpfc_sli4_cq_event_alloc(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflags;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tcq_event = __lpfc_sli4_cq_event_alloc(phba);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn cq_event;\n}\n\n \nvoid\n__lpfc_sli4_cq_event_release(struct lpfc_hba *phba,\n\t\t\t     struct lpfc_cq_event *cq_event)\n{\n\tlist_add_tail(&cq_event->list, &phba->sli4_hba.sp_cqe_event_pool);\n}\n\n \nvoid\nlpfc_sli4_cq_event_release(struct lpfc_hba *phba,\n\t\t\t   struct lpfc_cq_event *cq_event)\n{\n\tunsigned long iflags;\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t__lpfc_sli4_cq_event_release(phba, cq_event);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n}\n\n \nstatic void\nlpfc_sli4_cq_event_release_all(struct lpfc_hba *phba)\n{\n\tLIST_HEAD(cq_event_list);\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflags;\n\n\t \n\n\t \n\tspin_lock_irqsave(&phba->sli4_hba.els_xri_abrt_list_lock, iflags);\n\tlist_splice_init(&phba->sli4_hba.sp_els_xri_aborted_work_queue,\n\t\t\t &cq_event_list);\n\tspin_unlock_irqrestore(&phba->sli4_hba.els_xri_abrt_list_lock, iflags);\n\n\t \n\tspin_lock_irqsave(&phba->sli4_hba.asynce_list_lock, iflags);\n\tlist_splice_init(&phba->sli4_hba.sp_asynce_work_queue,\n\t\t\t &cq_event_list);\n\tspin_unlock_irqrestore(&phba->sli4_hba.asynce_list_lock, iflags);\n\n\twhile (!list_empty(&cq_event_list)) {\n\t\tlist_remove_head(&cq_event_list, cq_event,\n\t\t\t\t struct lpfc_cq_event, list);\n\t\tlpfc_sli4_cq_event_release(phba, cq_event);\n\t}\n}\n\n \nint\nlpfc_pci_function_reset(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tuint32_t rc = 0, if_type;\n\tuint32_t shdr_status, shdr_add_status;\n\tuint32_t rdy_chk;\n\tuint32_t port_reset = 0;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tstruct lpfc_register reg_data;\n\tuint16_t devid;\n\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool,\n\t\t\t\t\t\t       GFP_KERNEL);\n\t\tif (!mboxq) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0494 Unable to allocate memory for \"\n\t\t\t\t\t\"issuing SLI_FUNCTION_RESET mailbox \"\n\t\t\t\t\t\"command\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t \n\t\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t\t LPFC_MBOX_OPCODE_FUNCTION_RESET, 0,\n\t\t\t\t LPFC_SLI4_MBX_EMBED);\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t\t&mboxq->u.mqe.un.sli4_config.header.cfg_shdr;\n\t\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\t\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status,\n\t\t\t\t\t &shdr->response);\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\tif (shdr_status || shdr_add_status || rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0495 SLI_FUNCTION_RESET mailbox \"\n\t\t\t\t\t\"failed with status x%x add_status x%x,\"\n\t\t\t\t\t\" mbx status x%x\\n\",\n\t\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\t\trc = -ENXIO;\n\t\t}\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\nwait:\n\t\t \n\t\tfor (rdy_chk = 0; rdy_chk < 1500; rdy_chk++) {\n\t\t\tif (lpfc_readl(phba->sli4_hba.u.if_type2.\n\t\t\t\tSTATUSregaddr, &reg_data.word0)) {\n\t\t\t\trc = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (bf_get(lpfc_sliport_status_rdy, &reg_data))\n\t\t\t\tbreak;\n\t\t\tmsleep(20);\n\t\t}\n\n\t\tif (!bf_get(lpfc_sliport_status_rdy, &reg_data)) {\n\t\t\tphba->work_status[0] = readl(\n\t\t\t\tphba->sli4_hba.u.if_type2.ERR1regaddr);\n\t\t\tphba->work_status[1] = readl(\n\t\t\t\tphba->sli4_hba.u.if_type2.ERR2regaddr);\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2890 Port not ready, port status reg \"\n\t\t\t\t\t\"0x%x error 1=0x%x, error 2=0x%x\\n\",\n\t\t\t\t\treg_data.word0,\n\t\t\t\t\tphba->work_status[0],\n\t\t\t\t\tphba->work_status[1]);\n\t\t\trc = -ENODEV;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (bf_get(lpfc_sliport_status_pldv, &reg_data))\n\t\t\tlpfc_pldv_detect = true;\n\n\t\tif (!port_reset) {\n\t\t\t \n\t\t\treg_data.word0 = 0;\n\t\t\tbf_set(lpfc_sliport_ctrl_end, &reg_data,\n\t\t\t       LPFC_SLIPORT_LITTLE_ENDIAN);\n\t\t\tbf_set(lpfc_sliport_ctrl_ip, &reg_data,\n\t\t\t       LPFC_SLIPORT_INIT_PORT);\n\t\t\twritel(reg_data.word0, phba->sli4_hba.u.if_type2.\n\t\t\t       CTRLregaddr);\n\t\t\t \n\t\t\tpci_read_config_word(phba->pcidev,\n\t\t\t\t\t     PCI_DEVICE_ID, &devid);\n\n\t\t\tport_reset = 1;\n\t\t\tmsleep(20);\n\t\t\tgoto wait;\n\t\t} else if (bf_get(lpfc_sliport_status_rn, &reg_data)) {\n\t\t\trc = -ENODEV;\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tbreak;\n\t}\n\nout:\n\t \n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3317 HBA not functional: IP Reset Failed \"\n\t\t\t\t\"try: echo fw_reset > board_mode\\n\");\n\t\trc = -ENODEV;\n\t}\n\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_pci_mem_setup(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev = phba->pcidev;\n\tunsigned long bar0map_len, bar1map_len, bar2map_len;\n\tint error;\n\tuint32_t if_type;\n\n\tif (!pdev)\n\t\treturn -ENODEV;\n\n\t \n\terror = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (error)\n\t\terror = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (error)\n\t\treturn error;\n\n\t \n\tif (pci_read_config_dword(pdev, LPFC_SLI_INTF,\n\t\t\t\t  &phba->sli4_hba.sli_intf.word0)) {\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tif (bf_get(lpfc_sli_intf_valid, &phba->sli4_hba.sli_intf) !=\n\t    LPFC_SLI_INTF_VALID) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"2894 SLI_INTF reg contents invalid \"\n\t\t\t\t\"sli_intf reg 0x%x\\n\",\n\t\t\t\tphba->sli4_hba.sli_intf.word0);\n\t\treturn -ENODEV;\n\t}\n\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\t \n\tif (pci_resource_start(pdev, PCI_64BIT_BAR0)) {\n\t\tphba->pci_bar0_map = pci_resource_start(pdev, PCI_64BIT_BAR0);\n\t\tbar0map_len = pci_resource_len(pdev, PCI_64BIT_BAR0);\n\n\t\t \n\t\tphba->sli4_hba.conf_regs_memmap_p =\n\t\t\tioremap(phba->pci_bar0_map, bar0map_len);\n\t\tif (!phba->sli4_hba.conf_regs_memmap_p) {\n\t\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t\t   \"ioremap failed for SLI4 PCI config \"\n\t\t\t\t   \"registers.\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tphba->pci_bar0_memmap_p = phba->sli4_hba.conf_regs_memmap_p;\n\t\t \n\t\tlpfc_sli4_bar0_register_memmap(phba, if_type);\n\t} else {\n\t\tphba->pci_bar0_map = pci_resource_start(pdev, 1);\n\t\tbar0map_len = pci_resource_len(pdev, 1);\n\t\tif (if_type >= LPFC_SLI_INTF_IF_TYPE_2) {\n\t\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t   \"FATAL - No BAR0 mapping for SLI4, if_type 2\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tphba->sli4_hba.conf_regs_memmap_p =\n\t\t\t\tioremap(phba->pci_bar0_map, bar0map_len);\n\t\tif (!phba->sli4_hba.conf_regs_memmap_p) {\n\t\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t\t\"ioremap failed for SLI4 PCI config \"\n\t\t\t\t\"registers.\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tlpfc_sli4_bar0_register_memmap(phba, if_type);\n\t}\n\n\tif (if_type == LPFC_SLI_INTF_IF_TYPE_0) {\n\t\tif (pci_resource_start(pdev, PCI_64BIT_BAR2)) {\n\t\t\t \n\t\t\tphba->pci_bar1_map = pci_resource_start(pdev,\n\t\t\t\t\t\t\t\tPCI_64BIT_BAR2);\n\t\t\tbar1map_len = pci_resource_len(pdev, PCI_64BIT_BAR2);\n\t\t\tphba->sli4_hba.ctrl_regs_memmap_p =\n\t\t\t\t\tioremap(phba->pci_bar1_map,\n\t\t\t\t\t\tbar1map_len);\n\t\t\tif (!phba->sli4_hba.ctrl_regs_memmap_p) {\n\t\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\t   \"ioremap failed for SLI4 HBA \"\n\t\t\t\t\t    \"control registers.\\n\");\n\t\t\t\terror = -ENOMEM;\n\t\t\t\tgoto out_iounmap_conf;\n\t\t\t}\n\t\t\tphba->pci_bar2_memmap_p =\n\t\t\t\t\t phba->sli4_hba.ctrl_regs_memmap_p;\n\t\t\tlpfc_sli4_bar1_register_memmap(phba, if_type);\n\t\t} else {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_iounmap_conf;\n\t\t}\n\t}\n\n\tif ((if_type == LPFC_SLI_INTF_IF_TYPE_6) &&\n\t    (pci_resource_start(pdev, PCI_64BIT_BAR2))) {\n\t\t \n\t\tphba->pci_bar1_map = pci_resource_start(pdev, PCI_64BIT_BAR2);\n\t\tbar1map_len = pci_resource_len(pdev, PCI_64BIT_BAR2);\n\t\tphba->sli4_hba.drbl_regs_memmap_p =\n\t\t\t\tioremap(phba->pci_bar1_map, bar1map_len);\n\t\tif (!phba->sli4_hba.drbl_regs_memmap_p) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t   \"ioremap failed for SLI4 HBA doorbell registers.\\n\");\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_iounmap_conf;\n\t\t}\n\t\tphba->pci_bar2_memmap_p = phba->sli4_hba.drbl_regs_memmap_p;\n\t\tlpfc_sli4_bar1_register_memmap(phba, if_type);\n\t}\n\n\tif (if_type == LPFC_SLI_INTF_IF_TYPE_0) {\n\t\tif (pci_resource_start(pdev, PCI_64BIT_BAR4)) {\n\t\t\t \n\t\t\tphba->pci_bar2_map = pci_resource_start(pdev,\n\t\t\t\t\t\t\t\tPCI_64BIT_BAR4);\n\t\t\tbar2map_len = pci_resource_len(pdev, PCI_64BIT_BAR4);\n\t\t\tphba->sli4_hba.drbl_regs_memmap_p =\n\t\t\t\t\tioremap(phba->pci_bar2_map,\n\t\t\t\t\t\tbar2map_len);\n\t\t\tif (!phba->sli4_hba.drbl_regs_memmap_p) {\n\t\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\t   \"ioremap failed for SLI4 HBA\"\n\t\t\t\t\t   \" doorbell registers.\\n\");\n\t\t\t\terror = -ENOMEM;\n\t\t\t\tgoto out_iounmap_ctrl;\n\t\t\t}\n\t\t\tphba->pci_bar4_memmap_p =\n\t\t\t\t\tphba->sli4_hba.drbl_regs_memmap_p;\n\t\t\terror = lpfc_sli4_bar2_register_memmap(phba, LPFC_VF0);\n\t\t\tif (error)\n\t\t\t\tgoto out_iounmap_all;\n\t\t} else {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_iounmap_ctrl;\n\t\t}\n\t}\n\n\tif (if_type == LPFC_SLI_INTF_IF_TYPE_6 &&\n\t    pci_resource_start(pdev, PCI_64BIT_BAR4)) {\n\t\t \n\t\tphba->pci_bar2_map = pci_resource_start(pdev, PCI_64BIT_BAR4);\n\t\tbar2map_len = pci_resource_len(pdev, PCI_64BIT_BAR4);\n\t\tphba->sli4_hba.dpp_regs_memmap_p =\n\t\t\t\tioremap(phba->pci_bar2_map, bar2map_len);\n\t\tif (!phba->sli4_hba.dpp_regs_memmap_p) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t   \"ioremap failed for SLI4 HBA dpp registers.\\n\");\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_iounmap_all;\n\t\t}\n\t\tphba->pci_bar4_memmap_p = phba->sli4_hba.dpp_regs_memmap_p;\n\t}\n\n\t \n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\t\tphba->sli4_hba.sli4_eq_clr_intr = lpfc_sli4_eq_clr_intr;\n\t\tphba->sli4_hba.sli4_write_eq_db = lpfc_sli4_write_eq_db;\n\t\tphba->sli4_hba.sli4_write_cq_db = lpfc_sli4_write_cq_db;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tphba->sli4_hba.sli4_eq_clr_intr = lpfc_sli4_if6_eq_clr_intr;\n\t\tphba->sli4_hba.sli4_write_eq_db = lpfc_sli4_if6_write_eq_db;\n\t\tphba->sli4_hba.sli4_write_cq_db = lpfc_sli4_if6_write_cq_db;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n\nout_iounmap_all:\n\tif (phba->sli4_hba.drbl_regs_memmap_p)\n\t\tiounmap(phba->sli4_hba.drbl_regs_memmap_p);\nout_iounmap_ctrl:\n\tif (phba->sli4_hba.ctrl_regs_memmap_p)\n\t\tiounmap(phba->sli4_hba.ctrl_regs_memmap_p);\nout_iounmap_conf:\n\tiounmap(phba->sli4_hba.conf_regs_memmap_p);\n\n\treturn error;\n}\n\n \nstatic void\nlpfc_sli4_pci_mem_unset(struct lpfc_hba *phba)\n{\n\tuint32_t if_type;\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tiounmap(phba->sli4_hba.drbl_regs_memmap_p);\n\t\tiounmap(phba->sli4_hba.ctrl_regs_memmap_p);\n\t\tiounmap(phba->sli4_hba.conf_regs_memmap_p);\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\t\tiounmap(phba->sli4_hba.conf_regs_memmap_p);\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tiounmap(phba->sli4_hba.drbl_regs_memmap_p);\n\t\tiounmap(phba->sli4_hba.conf_regs_memmap_p);\n\t\tif (phba->sli4_hba.dpp_regs_memmap_p)\n\t\t\tiounmap(phba->sli4_hba.dpp_regs_memmap_p);\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\t\tbreak;\n\tdefault:\n\t\tdev_printk(KERN_ERR, &phba->pcidev->dev,\n\t\t\t   \"FATAL - unsupported SLI4 interface type - %d\\n\",\n\t\t\t   if_type);\n\t\tbreak;\n\t}\n}\n\n \nstatic int\nlpfc_sli_enable_msix(struct lpfc_hba *phba)\n{\n\tint rc;\n\tLPFC_MBOXQ_t *pmb;\n\n\t \n\trc = pci_alloc_irq_vectors(phba->pcidev,\n\t\t\tLPFC_MSIX_VECTORS, LPFC_MSIX_VECTORS, PCI_IRQ_MSIX);\n\tif (rc < 0) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0420 PCI enable MSI-X failed (%d)\\n\", rc);\n\t\tgoto vec_fail_out;\n\t}\n\n\t \n\n\t \n\trc = request_irq(pci_irq_vector(phba->pcidev, 0),\n\t\t\t &lpfc_sli_sp_intr_handler, 0,\n\t\t\t LPFC_SP_DRIVER_HANDLER_NAME, phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0421 MSI-X slow-path request_irq failed \"\n\t\t\t\t\"(%d)\\n\", rc);\n\t\tgoto msi_fail_out;\n\t}\n\n\t \n\trc = request_irq(pci_irq_vector(phba->pcidev, 1),\n\t\t\t &lpfc_sli_fp_intr_handler, 0,\n\t\t\t LPFC_FP_DRIVER_HANDLER_NAME, phba);\n\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0429 MSI-X fast-path request_irq failed \"\n\t\t\t\t\"(%d)\\n\", rc);\n\t\tgoto irq_fail_out;\n\t}\n\n\t \n\tpmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\n\tif (!pmb) {\n\t\trc = -ENOMEM;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0474 Unable to allocate memory for issuing \"\n\t\t\t\t\"MBOX_CONFIG_MSI command\\n\");\n\t\tgoto mem_fail_out;\n\t}\n\trc = lpfc_config_msi(phba, pmb);\n\tif (rc)\n\t\tgoto mbx_fail_out;\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX,\n\t\t\t\t\"0351 Config MSI mailbox command failed, \"\n\t\t\t\t\"mbxCmd x%x, mbxStatus x%x\\n\",\n\t\t\t\tpmb->u.mb.mbxCommand, pmb->u.mb.mbxStatus);\n\t\tgoto mbx_fail_out;\n\t}\n\n\t \n\tmempool_free(pmb, phba->mbox_mem_pool);\n\treturn rc;\n\nmbx_fail_out:\n\t \n\tmempool_free(pmb, phba->mbox_mem_pool);\n\nmem_fail_out:\n\t \n\tfree_irq(pci_irq_vector(phba->pcidev, 1), phba);\n\nirq_fail_out:\n\t \n\tfree_irq(pci_irq_vector(phba->pcidev, 0), phba);\n\nmsi_fail_out:\n\t \n\tpci_free_irq_vectors(phba->pcidev);\n\nvec_fail_out:\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli_enable_msi(struct lpfc_hba *phba)\n{\n\tint rc;\n\n\trc = pci_enable_msi(phba->pcidev);\n\tif (!rc)\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0012 PCI enable MSI mode success.\\n\");\n\telse {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0471 PCI enable MSI mode failed (%d)\\n\", rc);\n\t\treturn rc;\n\t}\n\n\trc = request_irq(phba->pcidev->irq, lpfc_sli_intr_handler,\n\t\t\t 0, LPFC_DRIVER_NAME, phba);\n\tif (rc) {\n\t\tpci_disable_msi(phba->pcidev);\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0478 MSI request_irq failed (%d)\\n\", rc);\n\t}\n\treturn rc;\n}\n\n \nstatic uint32_t\nlpfc_sli_enable_intr(struct lpfc_hba *phba, uint32_t cfg_mode)\n{\n\tuint32_t intr_mode = LPFC_INTR_ERROR;\n\tint retval;\n\n\t \n\tretval = lpfc_sli_config_port(phba, LPFC_SLI_REV3);\n\tif (retval)\n\t\treturn intr_mode;\n\tphba->hba_flag &= ~HBA_NEEDS_CFG_PORT;\n\n\tif (cfg_mode == 2) {\n\t\t \n\t\tretval = lpfc_sli_enable_msix(phba);\n\t\tif (!retval) {\n\t\t\t \n\t\t\tphba->intr_type = MSIX;\n\t\t\tintr_mode = 2;\n\t\t}\n\t}\n\n\t \n\tif (cfg_mode >= 1 && phba->intr_type == NONE) {\n\t\tretval = lpfc_sli_enable_msi(phba);\n\t\tif (!retval) {\n\t\t\t \n\t\t\tphba->intr_type = MSI;\n\t\t\tintr_mode = 1;\n\t\t}\n\t}\n\n\t \n\tif (phba->intr_type == NONE) {\n\t\tretval = request_irq(phba->pcidev->irq, lpfc_sli_intr_handler,\n\t\t\t\t     IRQF_SHARED, LPFC_DRIVER_NAME, phba);\n\t\tif (!retval) {\n\t\t\t \n\t\t\tphba->intr_type = INTx;\n\t\t\tintr_mode = 0;\n\t\t}\n\t}\n\treturn intr_mode;\n}\n\n \nstatic void\nlpfc_sli_disable_intr(struct lpfc_hba *phba)\n{\n\tint nr_irqs, i;\n\n\tif (phba->intr_type == MSIX)\n\t\tnr_irqs = LPFC_MSIX_VECTORS;\n\telse\n\t\tnr_irqs = 1;\n\n\tfor (i = 0; i < nr_irqs; i++)\n\t\tfree_irq(pci_irq_vector(phba->pcidev, i), phba);\n\tpci_free_irq_vectors(phba->pcidev);\n\n\t \n\tphba->intr_type = NONE;\n\tphba->sli.slistat.sli_intr = 0;\n}\n\n \nstatic uint16_t\nlpfc_find_cpu_handle(struct lpfc_hba *phba, uint16_t id, int match)\n{\n\tstruct lpfc_vector_map_info *cpup;\n\tint cpu;\n\n\t \n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t \n\t\tif ((match == LPFC_FIND_BY_EQ) &&\n\t\t    (cpup->flag & LPFC_CPU_FIRST_IRQ) &&\n\t\t    (cpup->eq == id))\n\t\t\treturn cpu;\n\n\t\t \n\t\tif ((match == LPFC_FIND_BY_HDWQ) && (cpup->hdwq == id))\n\t\t\treturn cpu;\n\t}\n\treturn 0;\n}\n\n#ifdef CONFIG_X86\n \nstatic int\nlpfc_find_hyper(struct lpfc_hba *phba, int cpu,\n\t\tuint16_t phys_id, uint16_t core_id)\n{\n\tstruct lpfc_vector_map_info *cpup;\n\tint idx;\n\n\tfor_each_present_cpu(idx) {\n\t\tcpup = &phba->sli4_hba.cpu_map[idx];\n\t\t \n\t\tif ((cpup->phys_id == phys_id) &&\n\t\t    (cpup->core_id == core_id) &&\n\t\t    (cpu != idx))\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n#endif\n\n \nstatic inline void\nlpfc_assign_eq_map_info(struct lpfc_hba *phba, uint16_t eqidx, uint16_t flag,\n\t\t\tunsigned int cpu)\n{\n\tstruct lpfc_vector_map_info *cpup = &phba->sli4_hba.cpu_map[cpu];\n\tstruct lpfc_hba_eq_hdl *eqhdl = lpfc_get_eq_hdl(eqidx);\n\n\tcpup->eq = eqidx;\n\tcpup->flag |= flag;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"3336 Set Affinity: CPU %d irq %d eq %d flag x%x\\n\",\n\t\t\tcpu, eqhdl->irq, cpup->eq, cpup->flag);\n}\n\n \nstatic void\nlpfc_cpu_map_array_init(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_eq_intr_info *eqi;\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\t\tcpup->phys_id = LPFC_VECTOR_MAP_EMPTY;\n\t\tcpup->core_id = LPFC_VECTOR_MAP_EMPTY;\n\t\tcpup->hdwq = LPFC_VECTOR_MAP_EMPTY;\n\t\tcpup->eq = LPFC_VECTOR_MAP_EMPTY;\n\t\tcpup->flag = 0;\n\t\teqi = per_cpu_ptr(phba->sli4_hba.eq_info, cpu);\n\t\tINIT_LIST_HEAD(&eqi->list);\n\t\teqi->icnt = 0;\n\t}\n}\n\n \nstatic void\nlpfc_hba_eq_hdl_array_init(struct lpfc_hba *phba)\n{\n\tstruct lpfc_hba_eq_hdl *eqhdl;\n\tint i;\n\n\tfor (i = 0; i < phba->cfg_irq_chann; i++) {\n\t\teqhdl = lpfc_get_eq_hdl(i);\n\t\teqhdl->irq = LPFC_IRQ_EMPTY;\n\t\teqhdl->phba = phba;\n\t}\n}\n\n \nstatic void\nlpfc_cpu_affinity_check(struct lpfc_hba *phba, int vectors)\n{\n\tint i, cpu, idx, next_idx, new_cpu, start_cpu, first_cpu;\n\tint max_phys_id, min_phys_id;\n\tint max_core_id, min_core_id;\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_vector_map_info *new_cpup;\n#ifdef CONFIG_X86\n\tstruct cpuinfo_x86 *cpuinfo;\n#endif\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\tstruct lpfc_hdwq_stat *c_stat;\n#endif\n\n\tmax_phys_id = 0;\n\tmin_phys_id = LPFC_VECTOR_MAP_EMPTY;\n\tmax_core_id = 0;\n\tmin_core_id = LPFC_VECTOR_MAP_EMPTY;\n\n\t \n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n#ifdef CONFIG_X86\n\t\tcpuinfo = &cpu_data(cpu);\n\t\tcpup->phys_id = cpuinfo->phys_proc_id;\n\t\tcpup->core_id = cpuinfo->cpu_core_id;\n\t\tif (lpfc_find_hyper(phba, cpu, cpup->phys_id, cpup->core_id))\n\t\t\tcpup->flag |= LPFC_CPU_MAP_HYPER;\n#else\n\t\t \n\t\tcpup->phys_id = 0;\n\t\tcpup->core_id = cpu;\n#endif\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3328 CPU %d physid %d coreid %d flag x%x\\n\",\n\t\t\t\tcpu, cpup->phys_id, cpup->core_id, cpup->flag);\n\n\t\tif (cpup->phys_id > max_phys_id)\n\t\t\tmax_phys_id = cpup->phys_id;\n\t\tif (cpup->phys_id < min_phys_id)\n\t\t\tmin_phys_id = cpup->phys_id;\n\n\t\tif (cpup->core_id > max_core_id)\n\t\t\tmax_core_id = cpup->core_id;\n\t\tif (cpup->core_id < min_core_id)\n\t\t\tmin_core_id = cpup->core_id;\n\t}\n\n\t \n\tfirst_cpu = cpumask_first(cpu_present_mask);\n\tstart_cpu = first_cpu;\n\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t \n\t\tif (cpup->eq == LPFC_VECTOR_MAP_EMPTY) {\n\t\t\t \n\t\t\tcpup->flag |= LPFC_CPU_MAP_UNASSIGN;\n\n\t\t\t \n\t\t\tnew_cpu = start_cpu;\n\t\t\tfor (i = 0; i < phba->sli4_hba.num_present_cpu; i++) {\n\t\t\t\tnew_cpup = &phba->sli4_hba.cpu_map[new_cpu];\n\t\t\t\tif (!(new_cpup->flag & LPFC_CPU_MAP_UNASSIGN) &&\n\t\t\t\t    (new_cpup->eq != LPFC_VECTOR_MAP_EMPTY) &&\n\t\t\t\t    (new_cpup->phys_id == cpup->phys_id))\n\t\t\t\t\tgoto found_same;\n\t\t\t\tnew_cpu = lpfc_next_present_cpu(new_cpu);\n\t\t\t}\n\t\t\t \n\t\t\tcontinue;\nfound_same:\n\t\t\t \n\t\t\tcpup->eq = new_cpup->eq;\n\n\t\t\t \n\t\t\tstart_cpu = lpfc_next_present_cpu(new_cpu);\n\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"3337 Set Affinity: CPU %d \"\n\t\t\t\t\t\"eq %d from peer cpu %d same \"\n\t\t\t\t\t\"phys_id (%d)\\n\",\n\t\t\t\t\tcpu, cpup->eq, new_cpu,\n\t\t\t\t\tcpup->phys_id);\n\t\t}\n\t}\n\n\t \n\tstart_cpu = first_cpu;\n\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t \n\t\tif (cpup->eq == LPFC_VECTOR_MAP_EMPTY) {\n\t\t\t \n\t\t\tcpup->flag |= LPFC_CPU_MAP_UNASSIGN;\n\n\t\t\t \n\t\t\tnew_cpu = start_cpu;\n\t\t\tfor (i = 0; i < phba->sli4_hba.num_present_cpu; i++) {\n\t\t\t\tnew_cpup = &phba->sli4_hba.cpu_map[new_cpu];\n\t\t\t\tif (!(new_cpup->flag & LPFC_CPU_MAP_UNASSIGN) &&\n\t\t\t\t    (new_cpup->eq != LPFC_VECTOR_MAP_EMPTY))\n\t\t\t\t\tgoto found_any;\n\t\t\t\tnew_cpu = lpfc_next_present_cpu(new_cpu);\n\t\t\t}\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\t\"3339 Set Affinity: CPU %d \"\n\t\t\t\t\t\"eq %d UNASSIGNED\\n\",\n\t\t\t\t\tcpup->hdwq, cpup->eq);\n\t\t\tcontinue;\nfound_any:\n\t\t\t \n\t\t\tcpup->eq = new_cpup->eq;\n\n\t\t\t \n\t\t\tstart_cpu = lpfc_next_present_cpu(new_cpu);\n\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"3338 Set Affinity: CPU %d \"\n\t\t\t\t\t\"eq %d from peer cpu %d (%d/%d)\\n\",\n\t\t\t\t\tcpu, cpup->eq, new_cpu,\n\t\t\t\t\tnew_cpup->phys_id, new_cpup->core_id);\n\t\t}\n\t}\n\n\t \n\tidx = 0;\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t \n\t\tif (!(cpup->flag & LPFC_CPU_FIRST_IRQ))\n\t\t\tcontinue;\n\n\t\t \n\t\tcpup->hdwq = idx;\n\t\tidx++;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3333 Set Affinity: CPU %d (phys %d core %d): \"\n\t\t\t\t\"hdwq %d eq %d flg x%x\\n\",\n\t\t\t\tcpu, cpup->phys_id, cpup->core_id,\n\t\t\t\tcpup->hdwq, cpup->eq, cpup->flag);\n\t}\n\t \n\tnext_idx = idx;\n\tstart_cpu = 0;\n\tidx = 0;\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t \n\t\tif (cpup->flag & LPFC_CPU_FIRST_IRQ)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (next_idx < phba->cfg_hdw_queue) {\n\t\t\tcpup->hdwq = next_idx;\n\t\t\tnext_idx++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tnew_cpu = start_cpu;\n\t\tfor (i = 0; i < phba->sli4_hba.num_present_cpu; i++) {\n\t\t\tnew_cpup = &phba->sli4_hba.cpu_map[new_cpu];\n\t\t\tif (new_cpup->hdwq != LPFC_VECTOR_MAP_EMPTY &&\n\t\t\t    new_cpup->phys_id == cpup->phys_id &&\n\t\t\t    new_cpup->core_id == cpup->core_id) {\n\t\t\t\tgoto found_hdwq;\n\t\t\t}\n\t\t\tnew_cpu = lpfc_next_present_cpu(new_cpu);\n\t\t}\n\n\t\t \n\t\tnew_cpu = start_cpu;\n\t\tfor (i = 0; i < phba->sli4_hba.num_present_cpu; i++) {\n\t\t\tnew_cpup = &phba->sli4_hba.cpu_map[new_cpu];\n\t\t\tif (new_cpup->hdwq != LPFC_VECTOR_MAP_EMPTY &&\n\t\t\t    new_cpup->phys_id == cpup->phys_id)\n\t\t\t\tgoto found_hdwq;\n\t\t\tnew_cpu = lpfc_next_present_cpu(new_cpu);\n\t\t}\n\n\t\t \n\t\tcpup->hdwq = idx % phba->cfg_hdw_queue;\n\t\tidx++;\n\t\tgoto logit;\n found_hdwq:\n\t\t \n\t\tstart_cpu = lpfc_next_present_cpu(new_cpu);\n\t\tcpup->hdwq = new_cpup->hdwq;\n logit:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3335 Set Affinity: CPU %d (phys %d core %d): \"\n\t\t\t\t\"hdwq %d eq %d flg x%x\\n\",\n\t\t\t\tcpu, cpup->phys_id, cpup->core_id,\n\t\t\t\tcpup->hdwq, cpup->eq, cpup->flag);\n\t}\n\n\t \n\tidx = 0;\n\tfor_each_possible_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\t\tc_stat = per_cpu_ptr(phba->sli4_hba.c_stat, cpu);\n\t\tc_stat->hdwq_no = cpup->hdwq;\n#endif\n\t\tif (cpup->hdwq != LPFC_VECTOR_MAP_EMPTY)\n\t\t\tcontinue;\n\n\t\tcpup->hdwq = idx++ % phba->cfg_hdw_queue;\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\t\tc_stat->hdwq_no = cpup->hdwq;\n#endif\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3340 Set Affinity: not present \"\n\t\t\t\t\"CPU %d hdwq %d\\n\",\n\t\t\t\tcpu, cpup->hdwq);\n\t}\n\n\t \n\treturn;\n}\n\n \nstatic int\nlpfc_cpuhp_get_eq(struct lpfc_hba *phba, unsigned int cpu,\n\t\t  struct list_head *eqlist)\n{\n\tconst struct cpumask *maskp;\n\tstruct lpfc_queue *eq;\n\tstruct cpumask *tmp;\n\tu16 idx;\n\n\ttmp = kzalloc(cpumask_size(), GFP_KERNEL);\n\tif (!tmp)\n\t\treturn -ENOMEM;\n\n\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++) {\n\t\tmaskp = pci_irq_get_affinity(phba->pcidev, idx);\n\t\tif (!maskp)\n\t\t\tcontinue;\n\t\t \n\t\tif (!cpumask_and(tmp, maskp, cpumask_of(cpu)))\n\t\t\tcontinue;\n\t\t \n\t\tcpumask_and(tmp, maskp, cpu_online_mask);\n\t\tif (cpumask_weight(tmp) > 1)\n\t\t\tcontinue;\n\n\t\t \n\t\teq = phba->sli4_hba.hba_eq_hdl[idx].eq;\n\t\tlist_add(&eq->_poll_list, eqlist);\n\t}\n\tkfree(tmp);\n\treturn 0;\n}\n\nstatic void __lpfc_cpuhp_remove(struct lpfc_hba *phba)\n{\n\tif (phba->sli_rev != LPFC_SLI_REV4)\n\t\treturn;\n\n\tcpuhp_state_remove_instance_nocalls(lpfc_cpuhp_state,\n\t\t\t\t\t    &phba->cpuhp);\n\t \n\tsynchronize_rcu();\n\tdel_timer_sync(&phba->cpuhp_poll_timer);\n}\n\nstatic void lpfc_cpuhp_remove(struct lpfc_hba *phba)\n{\n\tif (phba->pport && (phba->pport->fc_flag & FC_OFFLINE_MODE))\n\t\treturn;\n\n\t__lpfc_cpuhp_remove(phba);\n}\n\nstatic void lpfc_cpuhp_add(struct lpfc_hba *phba)\n{\n\tif (phba->sli_rev != LPFC_SLI_REV4)\n\t\treturn;\n\n\trcu_read_lock();\n\n\tif (!list_empty(&phba->poll_list))\n\t\tmod_timer(&phba->cpuhp_poll_timer,\n\t\t\t  jiffies + msecs_to_jiffies(LPFC_POLL_HB));\n\n\trcu_read_unlock();\n\n\tcpuhp_state_add_instance_nocalls(lpfc_cpuhp_state,\n\t\t\t\t\t &phba->cpuhp);\n}\n\nstatic int __lpfc_cpuhp_checks(struct lpfc_hba *phba, int *retval)\n{\n\tif (phba->pport->load_flag & FC_UNLOADING) {\n\t\t*retval = -EAGAIN;\n\t\treturn true;\n\t}\n\n\tif (phba->sli_rev != LPFC_SLI_REV4) {\n\t\t*retval = 0;\n\t\treturn true;\n\t}\n\n\t \n\treturn false;\n}\n\n \nstatic inline void\nlpfc_irq_set_aff(struct lpfc_hba_eq_hdl *eqhdl, unsigned int cpu)\n{\n\tcpumask_clear(&eqhdl->aff_mask);\n\tcpumask_set_cpu(cpu, &eqhdl->aff_mask);\n\tirq_set_status_flags(eqhdl->irq, IRQ_NO_BALANCING);\n\tirq_set_affinity(eqhdl->irq, &eqhdl->aff_mask);\n}\n\n \nstatic inline void\nlpfc_irq_clear_aff(struct lpfc_hba_eq_hdl *eqhdl)\n{\n\tcpumask_clear(&eqhdl->aff_mask);\n\tirq_clear_status_flags(eqhdl->irq, IRQ_NO_BALANCING);\n}\n\n \nstatic void\nlpfc_irq_rebalance(struct lpfc_hba *phba, unsigned int cpu, bool offline)\n{\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct cpumask *aff_mask;\n\tunsigned int cpu_select, cpu_next, idx;\n\tconst struct cpumask *orig_mask;\n\n\tif (phba->irq_chann_mode == NORMAL_MODE)\n\t\treturn;\n\n\torig_mask = &phba->sli4_hba.irq_aff_mask;\n\n\tif (!cpumask_test_cpu(cpu, orig_mask))\n\t\treturn;\n\n\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\tif (!(cpup->flag & LPFC_CPU_FIRST_IRQ))\n\t\treturn;\n\n\tif (offline) {\n\t\t \n\t\tcpu_next = cpumask_next_wrap(cpu, orig_mask, cpu, true);\n\t\tcpu_select = lpfc_next_online_cpu(orig_mask, cpu_next);\n\n\t\t \n\t\tif ((cpu_select < nr_cpu_ids) && (cpu_select != cpu)) {\n\t\t\t \n\t\t\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++) {\n\t\t\t\taff_mask = lpfc_get_aff_mask(idx);\n\n\t\t\t\t \n\t\t\t\tif (cpumask_test_cpu(cpu, aff_mask))\n\t\t\t\t\tlpfc_irq_set_aff(lpfc_get_eq_hdl(idx),\n\t\t\t\t\t\t\t cpu_select);\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++)\n\t\t\t\tlpfc_irq_clear_aff(lpfc_get_eq_hdl(idx));\n\t\t}\n\t} else {\n\t\t \n\t\tlpfc_irq_set_aff(lpfc_get_eq_hdl(cpup->eq), cpu);\n\t}\n}\n\nstatic int lpfc_cpu_offline(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct lpfc_hba *phba = hlist_entry_safe(node, struct lpfc_hba, cpuhp);\n\tstruct lpfc_queue *eq, *next;\n\tLIST_HEAD(eqlist);\n\tint retval;\n\n\tif (!phba) {\n\t\tWARN_ONCE(!phba, \"cpu: %u. phba:NULL\", raw_smp_processor_id());\n\t\treturn 0;\n\t}\n\n\tif (__lpfc_cpuhp_checks(phba, &retval))\n\t\treturn retval;\n\n\tlpfc_irq_rebalance(phba, cpu, true);\n\n\tretval = lpfc_cpuhp_get_eq(phba, cpu, &eqlist);\n\tif (retval)\n\t\treturn retval;\n\n\t \n\tlist_for_each_entry_safe(eq, next, &eqlist, _poll_list) {\n\t\tlist_del_init(&eq->_poll_list);\n\t\tlpfc_sli4_start_polling(eq);\n\t}\n\n\treturn 0;\n}\n\nstatic int lpfc_cpu_online(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct lpfc_hba *phba = hlist_entry_safe(node, struct lpfc_hba, cpuhp);\n\tstruct lpfc_queue *eq, *next;\n\tunsigned int n;\n\tint retval;\n\n\tif (!phba) {\n\t\tWARN_ONCE(!phba, \"cpu: %u. phba:NULL\", raw_smp_processor_id());\n\t\treturn 0;\n\t}\n\n\tif (__lpfc_cpuhp_checks(phba, &retval))\n\t\treturn retval;\n\n\tlpfc_irq_rebalance(phba, cpu, false);\n\n\tlist_for_each_entry_safe(eq, next, &phba->poll_list, _poll_list) {\n\t\tn = lpfc_find_cpu_handle(phba, eq->hdwq, LPFC_FIND_BY_HDWQ);\n\t\tif (n == cpu)\n\t\t\tlpfc_sli4_stop_polling(eq);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nlpfc_sli4_enable_msix(struct lpfc_hba *phba)\n{\n\tint vectors, rc, index;\n\tchar *name;\n\tconst struct cpumask *aff_mask = NULL;\n\tunsigned int cpu = 0, cpu_cnt = 0, cpu_select = nr_cpu_ids;\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_hba_eq_hdl *eqhdl;\n\tconst struct cpumask *maskp;\n\tunsigned int flags = PCI_IRQ_MSIX;\n\n\t \n\tvectors = phba->cfg_irq_chann;\n\n\tif (phba->irq_chann_mode != NORMAL_MODE)\n\t\taff_mask = &phba->sli4_hba.irq_aff_mask;\n\n\tif (aff_mask) {\n\t\tcpu_cnt = cpumask_weight(aff_mask);\n\t\tvectors = min(phba->cfg_irq_chann, cpu_cnt);\n\n\t\t \n\t\tcpu = cpumask_first(aff_mask);\n\t\tcpu_select = lpfc_next_online_cpu(aff_mask, cpu);\n\t} else {\n\t\tflags |= PCI_IRQ_AFFINITY;\n\t}\n\n\trc = pci_alloc_irq_vectors(phba->pcidev, 1, vectors, flags);\n\tif (rc < 0) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0484 PCI enable MSI-X failed (%d)\\n\", rc);\n\t\tgoto vec_fail_out;\n\t}\n\tvectors = rc;\n\n\t \n\tfor (index = 0; index < vectors; index++) {\n\t\teqhdl = lpfc_get_eq_hdl(index);\n\t\tname = eqhdl->handler_name;\n\t\tmemset(name, 0, LPFC_SLI4_HANDLER_NAME_SZ);\n\t\tsnprintf(name, LPFC_SLI4_HANDLER_NAME_SZ,\n\t\t\t LPFC_DRIVER_HANDLER_NAME\"%d\", index);\n\n\t\teqhdl->idx = index;\n\t\trc = pci_irq_vector(phba->pcidev, index);\n\t\tif (rc < 0) {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"0489 MSI-X fast-path (%d) \"\n\t\t\t\t\t\"pci_irq_vec failed (%d)\\n\", index, rc);\n\t\t\tgoto cfg_fail_out;\n\t\t}\n\t\teqhdl->irq = rc;\n\n\t\trc = request_threaded_irq(eqhdl->irq,\n\t\t\t\t\t  &lpfc_sli4_hba_intr_handler,\n\t\t\t\t\t  &lpfc_sli4_hba_intr_handler_th,\n\t\t\t\t\t  IRQF_ONESHOT, name, eqhdl);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"0486 MSI-X fast-path (%d) \"\n\t\t\t\t\t\"request_irq failed (%d)\\n\", index, rc);\n\t\t\tgoto cfg_fail_out;\n\t\t}\n\n\t\tif (aff_mask) {\n\t\t\t \n\t\t\tif (cpu_select < nr_cpu_ids)\n\t\t\t\tlpfc_irq_set_aff(eqhdl, cpu_select);\n\n\t\t\t \n\t\t\tlpfc_assign_eq_map_info(phba, index,\n\t\t\t\t\t\tLPFC_CPU_FIRST_IRQ,\n\t\t\t\t\t\tcpu);\n\n\t\t\t \n\t\t\tcpu = cpumask_next(cpu, aff_mask);\n\n\t\t\t \n\t\t\tcpu_select = lpfc_next_online_cpu(aff_mask, cpu);\n\t\t} else if (vectors == 1) {\n\t\t\tcpu = cpumask_first(cpu_present_mask);\n\t\t\tlpfc_assign_eq_map_info(phba, index, LPFC_CPU_FIRST_IRQ,\n\t\t\t\t\t\tcpu);\n\t\t} else {\n\t\t\tmaskp = pci_irq_get_affinity(phba->pcidev, index);\n\n\t\t\t \n\t\t\tfor_each_cpu_and(cpu, maskp, cpu_present_mask) {\n\t\t\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t\t\t \n\t\t\t\tif (cpup->eq != LPFC_VECTOR_MAP_EMPTY)\n\t\t\t\t\tcontinue;\n\t\t\t\tlpfc_assign_eq_map_info(phba, index,\n\t\t\t\t\t\t\tLPFC_CPU_FIRST_IRQ,\n\t\t\t\t\t\t\tcpu);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (vectors != phba->cfg_irq_chann) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3238 Reducing IO channels to match number of \"\n\t\t\t\t\"MSI-X vectors, requested %d got %d\\n\",\n\t\t\t\tphba->cfg_irq_chann, vectors);\n\t\tif (phba->cfg_irq_chann > vectors)\n\t\t\tphba->cfg_irq_chann = vectors;\n\t}\n\n\treturn rc;\n\ncfg_fail_out:\n\t \n\tfor (--index; index >= 0; index--) {\n\t\teqhdl = lpfc_get_eq_hdl(index);\n\t\tlpfc_irq_clear_aff(eqhdl);\n\t\tfree_irq(eqhdl->irq, eqhdl);\n\t}\n\n\t \n\tpci_free_irq_vectors(phba->pcidev);\n\nvec_fail_out:\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_enable_msi(struct lpfc_hba *phba)\n{\n\tint rc, index;\n\tunsigned int cpu;\n\tstruct lpfc_hba_eq_hdl *eqhdl;\n\n\trc = pci_alloc_irq_vectors(phba->pcidev, 1, 1,\n\t\t\t\t   PCI_IRQ_MSI | PCI_IRQ_AFFINITY);\n\tif (rc > 0)\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0487 PCI enable MSI mode success.\\n\");\n\telse {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0488 PCI enable MSI mode failed (%d)\\n\", rc);\n\t\treturn rc ? rc : -1;\n\t}\n\n\trc = request_irq(phba->pcidev->irq, lpfc_sli4_intr_handler,\n\t\t\t 0, LPFC_DRIVER_NAME, phba);\n\tif (rc) {\n\t\tpci_free_irq_vectors(phba->pcidev);\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0490 MSI request_irq failed (%d)\\n\", rc);\n\t\treturn rc;\n\t}\n\n\teqhdl = lpfc_get_eq_hdl(0);\n\trc = pci_irq_vector(phba->pcidev, 0);\n\tif (rc < 0) {\n\t\tpci_free_irq_vectors(phba->pcidev);\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0496 MSI pci_irq_vec failed (%d)\\n\", rc);\n\t\treturn rc;\n\t}\n\teqhdl->irq = rc;\n\n\tcpu = cpumask_first(cpu_present_mask);\n\tlpfc_assign_eq_map_info(phba, 0, LPFC_CPU_FIRST_IRQ, cpu);\n\n\tfor (index = 0; index < phba->cfg_irq_chann; index++) {\n\t\teqhdl = lpfc_get_eq_hdl(index);\n\t\teqhdl->idx = index;\n\t}\n\n\treturn 0;\n}\n\n \nstatic uint32_t\nlpfc_sli4_enable_intr(struct lpfc_hba *phba, uint32_t cfg_mode)\n{\n\tuint32_t intr_mode = LPFC_INTR_ERROR;\n\tint retval, idx;\n\n\tif (cfg_mode == 2) {\n\t\t \n\t\tretval = 0;\n\t\tif (!retval) {\n\t\t\t \n\t\t\tretval = lpfc_sli4_enable_msix(phba);\n\t\t\tif (!retval) {\n\t\t\t\t \n\t\t\t\tphba->intr_type = MSIX;\n\t\t\t\tintr_mode = 2;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (cfg_mode >= 1 && phba->intr_type == NONE) {\n\t\tretval = lpfc_sli4_enable_msi(phba);\n\t\tif (!retval) {\n\t\t\t \n\t\t\tphba->intr_type = MSI;\n\t\t\tintr_mode = 1;\n\t\t}\n\t}\n\n\t \n\tif (phba->intr_type == NONE) {\n\t\tretval = request_irq(phba->pcidev->irq, lpfc_sli4_intr_handler,\n\t\t\t\t     IRQF_SHARED, LPFC_DRIVER_NAME, phba);\n\t\tif (!retval) {\n\t\t\tstruct lpfc_hba_eq_hdl *eqhdl;\n\t\t\tunsigned int cpu;\n\n\t\t\t \n\t\t\tphba->intr_type = INTx;\n\t\t\tintr_mode = 0;\n\n\t\t\teqhdl = lpfc_get_eq_hdl(0);\n\t\t\tretval = pci_irq_vector(phba->pcidev, 0);\n\t\t\tif (retval < 0) {\n\t\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"0502 INTR pci_irq_vec failed (%d)\\n\",\n\t\t\t\t\t retval);\n\t\t\t\treturn LPFC_INTR_ERROR;\n\t\t\t}\n\t\t\teqhdl->irq = retval;\n\n\t\t\tcpu = cpumask_first(cpu_present_mask);\n\t\t\tlpfc_assign_eq_map_info(phba, 0, LPFC_CPU_FIRST_IRQ,\n\t\t\t\t\t\tcpu);\n\t\t\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++) {\n\t\t\t\teqhdl = lpfc_get_eq_hdl(idx);\n\t\t\t\teqhdl->idx = idx;\n\t\t\t}\n\t\t}\n\t}\n\treturn intr_mode;\n}\n\n \nstatic void\nlpfc_sli4_disable_intr(struct lpfc_hba *phba)\n{\n\t \n\tif (phba->intr_type == MSIX) {\n\t\tint index;\n\t\tstruct lpfc_hba_eq_hdl *eqhdl;\n\n\t\t \n\t\tfor (index = 0; index < phba->cfg_irq_chann; index++) {\n\t\t\teqhdl = lpfc_get_eq_hdl(index);\n\t\t\tlpfc_irq_clear_aff(eqhdl);\n\t\t\tfree_irq(eqhdl->irq, eqhdl);\n\t\t}\n\t} else {\n\t\tfree_irq(phba->pcidev->irq, phba);\n\t}\n\n\tpci_free_irq_vectors(phba->pcidev);\n\n\t \n\tphba->intr_type = NONE;\n\tphba->sli.slistat.sli_intr = 0;\n}\n\n \nstatic void\nlpfc_unset_hba(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct Scsi_Host  *shost = lpfc_shost_from_vport(vport);\n\n\tspin_lock_irq(shost->host_lock);\n\tvport->load_flag |= FC_UNLOADING;\n\tspin_unlock_irq(shost->host_lock);\n\n\tkfree(phba->vpi_bmask);\n\tkfree(phba->vpi_ids);\n\n\tlpfc_stop_hba_timers(phba);\n\n\tphba->pport->work_port_events = 0;\n\n\tlpfc_sli_hba_down(phba);\n\n\tlpfc_sli_brdrestart(phba);\n\n\tlpfc_sli_disable_intr(phba);\n\n\treturn;\n}\n\n \nstatic void\nlpfc_sli4_xri_exchange_busy_wait(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tint idx, ccnt;\n\tint wait_time = 0;\n\tint io_xri_cmpl = 1;\n\tint nvmet_xri_cmpl = 1;\n\tint els_xri_cmpl = list_empty(&phba->sli4_hba.lpfc_abts_els_sgl_list);\n\n\t \n\tmsleep(LPFC_XRI_EXCH_BUSY_WAIT_T1 * 5);\n\n\t \n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\tlpfc_nvme_wait_for_io_drain(phba);\n\n\tccnt = 0;\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\tio_xri_cmpl = list_empty(&qp->lpfc_abts_io_buf_list);\n\t\tif (!io_xri_cmpl)  \n\t\t\tccnt++;\n\t}\n\tif (ccnt)\n\t\tio_xri_cmpl = 0;\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tnvmet_xri_cmpl =\n\t\t\tlist_empty(&phba->sli4_hba.lpfc_abts_nvmet_ctx_list);\n\t}\n\n\twhile (!els_xri_cmpl || !io_xri_cmpl || !nvmet_xri_cmpl) {\n\t\tif (wait_time > LPFC_XRI_EXCH_BUSY_WAIT_TMO) {\n\t\t\tif (!nvmet_xri_cmpl)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6424 NVMET XRI exchange busy \"\n\t\t\t\t\t\t\"wait time: %d seconds.\\n\",\n\t\t\t\t\t\twait_time/1000);\n\t\t\tif (!io_xri_cmpl)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6100 IO XRI exchange busy \"\n\t\t\t\t\t\t\"wait time: %d seconds.\\n\",\n\t\t\t\t\t\twait_time/1000);\n\t\t\tif (!els_xri_cmpl)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"2878 ELS XRI exchange busy \"\n\t\t\t\t\t\t\"wait time: %d seconds.\\n\",\n\t\t\t\t\t\twait_time/1000);\n\t\t\tmsleep(LPFC_XRI_EXCH_BUSY_WAIT_T2);\n\t\t\twait_time += LPFC_XRI_EXCH_BUSY_WAIT_T2;\n\t\t} else {\n\t\t\tmsleep(LPFC_XRI_EXCH_BUSY_WAIT_T1);\n\t\t\twait_time += LPFC_XRI_EXCH_BUSY_WAIT_T1;\n\t\t}\n\n\t\tccnt = 0;\n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\t\tio_xri_cmpl = list_empty(\n\t\t\t    &qp->lpfc_abts_io_buf_list);\n\t\t\tif (!io_xri_cmpl)  \n\t\t\t\tccnt++;\n\t\t}\n\t\tif (ccnt)\n\t\t\tio_xri_cmpl = 0;\n\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t\tnvmet_xri_cmpl = list_empty(\n\t\t\t\t&phba->sli4_hba.lpfc_abts_nvmet_ctx_list);\n\t\t}\n\t\tels_xri_cmpl =\n\t\t\tlist_empty(&phba->sli4_hba.lpfc_abts_els_sgl_list);\n\n\t}\n}\n\n \nstatic void\nlpfc_sli4_hba_unset(struct lpfc_hba *phba)\n{\n\tint wait_cnt = 0;\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct pci_dev *pdev = phba->pcidev;\n\n\tlpfc_stop_hba_timers(phba);\n\thrtimer_cancel(&phba->cmf_stats_timer);\n\thrtimer_cancel(&phba->cmf_timer);\n\n\tif (phba->pport)\n\t\tphba->sli4_hba.intr_enable = 0;\n\n\t \n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tphba->sli.sli_flag |= LPFC_SLI_ASYNC_MBX_BLK;\n\tspin_unlock_irq(&phba->hbalock);\n\t \n\twhile (phba->sli.sli_flag & LPFC_SLI_MBOX_ACTIVE) {\n\t\tmsleep(10);\n\t\tif (++wait_cnt > LPFC_ACTIVE_MBOX_WAIT_CNT)\n\t\t\tbreak;\n\t}\n\t \n\tif (phba->sli.sli_flag & LPFC_SLI_MBOX_ACTIVE) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tmboxq = phba->sli.mbox_active;\n\t\tmboxq->u.mb.mbxStatus = MBX_NOT_FINISHED;\n\t\t__lpfc_mbox_cmpl_put(phba, mboxq);\n\t\tphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\tphba->sli.mbox_active = NULL;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\n\t \n\tlpfc_sli_hba_iocb_abort(phba);\n\n\tif (!pci_channel_offline(phba->pcidev))\n\t\t \n\t\tlpfc_sli4_xri_exchange_busy_wait(phba);\n\n\t \n\tif (phba->pport)\n\t\tlpfc_cpuhp_remove(phba);\n\n\t \n\tlpfc_sli4_disable_intr(phba);\n\n\t \n\tif (phba->cfg_sriov_nr_virtfn)\n\t\tpci_disable_sriov(pdev);\n\n\t \n\tkthread_stop(phba->worker_thread);\n\n\t \n\tlpfc_ras_stop_fwlog(phba);\n\n\t \n\tlpfc_pci_function_reset(phba);\n\n\t \n\tlpfc_sli4_queue_destroy(phba);\n\n\t \n\tif (phba->ras_fwlog.ras_enabled)\n\t\tlpfc_sli4_ras_dma_free(phba);\n\n\t \n\tif (phba->pport)\n\t\tphba->pport->work_port_events = 0;\n}\n\nstatic uint32_t\nlpfc_cgn_crc32(uint32_t crc, u8 byte)\n{\n\tuint32_t msb = 0;\n\tuint32_t bit;\n\n\tfor (bit = 0; bit < 8; bit++) {\n\t\tmsb = (crc >> 31) & 1;\n\t\tcrc <<= 1;\n\n\t\tif (msb ^ (byte & 1)) {\n\t\t\tcrc ^= LPFC_CGN_CRC32_MAGIC_NUMBER;\n\t\t\tcrc |= 1;\n\t\t}\n\t\tbyte >>= 1;\n\t}\n\treturn crc;\n}\n\nstatic uint32_t\nlpfc_cgn_reverse_bits(uint32_t wd)\n{\n\tuint32_t result = 0;\n\tuint32_t i;\n\n\tfor (i = 0; i < 32; i++) {\n\t\tresult <<= 1;\n\t\tresult |= (1 & (wd >> i));\n\t}\n\treturn result;\n}\n\n \nuint32_t\nlpfc_cgn_calc_crc32(void *ptr, uint32_t byteLen, uint32_t crc)\n{\n\tuint32_t  i;\n\tuint32_t result;\n\tuint8_t  *data = (uint8_t *)ptr;\n\n\tfor (i = 0; i < byteLen; ++i)\n\t\tcrc = lpfc_cgn_crc32(crc, data[i]);\n\n\tresult = ~lpfc_cgn_reverse_bits(crc);\n\treturn result;\n}\n\nvoid\nlpfc_init_congestion_buf(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cgn_info *cp;\n\tuint16_t size;\n\tuint32_t crc;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\"6235 INIT Congestion Buffer %p\\n\", phba->cgn_i);\n\n\tif (!phba->cgn_i)\n\t\treturn;\n\tcp = (struct lpfc_cgn_info *)phba->cgn_i->virt;\n\n\tatomic_set(&phba->cgn_fabric_warn_cnt, 0);\n\tatomic_set(&phba->cgn_fabric_alarm_cnt, 0);\n\tatomic_set(&phba->cgn_sync_alarm_cnt, 0);\n\tatomic_set(&phba->cgn_sync_warn_cnt, 0);\n\n\tatomic_set(&phba->cgn_driver_evt_cnt, 0);\n\tatomic_set(&phba->cgn_latency_evt_cnt, 0);\n\tatomic64_set(&phba->cgn_latency_evt, 0);\n\tphba->cgn_evt_minute = 0;\n\n\tmemset(cp, 0xff, offsetof(struct lpfc_cgn_info, cgn_stat));\n\tcp->cgn_info_size = cpu_to_le16(LPFC_CGN_INFO_SZ);\n\tcp->cgn_info_version = LPFC_CGN_INFO_V4;\n\n\t \n\tcp->cgn_info_mode = phba->cgn_p.cgn_param_mode;\n\tcp->cgn_info_level0 = phba->cgn_p.cgn_param_level0;\n\tcp->cgn_info_level1 = phba->cgn_p.cgn_param_level1;\n\tcp->cgn_info_level2 = phba->cgn_p.cgn_param_level2;\n\n\tlpfc_cgn_update_tstamp(phba, &cp->base_time);\n\n\t \n\tif (phba->pport) {\n\t\tsize = (uint16_t)(phba->pport->cfg_lun_queue_depth);\n\t\tcp->cgn_lunq = cpu_to_le16(size);\n\t}\n\n\t \n\n\tcp->cgn_warn_freq = cpu_to_le16(LPFC_FPIN_INIT_FREQ);\n\tcp->cgn_alarm_freq = cpu_to_le16(LPFC_FPIN_INIT_FREQ);\n\tcrc = lpfc_cgn_calc_crc32(cp, LPFC_CGN_INFO_SZ, LPFC_CGN_CRC32_SEED);\n\tcp->cgn_info_crc = cpu_to_le32(crc);\n\n\tphba->cgn_evt_timestamp = jiffies +\n\t\tmsecs_to_jiffies(LPFC_CGN_TIMER_TO_MIN);\n}\n\nvoid\nlpfc_init_congestion_stat(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cgn_info *cp;\n\tuint32_t crc;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\"6236 INIT Congestion Stat %p\\n\", phba->cgn_i);\n\n\tif (!phba->cgn_i)\n\t\treturn;\n\n\tcp = (struct lpfc_cgn_info *)phba->cgn_i->virt;\n\tmemset(&cp->cgn_stat, 0, sizeof(cp->cgn_stat));\n\n\tlpfc_cgn_update_tstamp(phba, &cp->stat_start);\n\tcrc = lpfc_cgn_calc_crc32(cp, LPFC_CGN_INFO_SZ, LPFC_CGN_CRC32_SEED);\n\tcp->cgn_info_crc = cpu_to_le32(crc);\n}\n\n \nstatic int\n__lpfc_reg_congestion_buf(struct lpfc_hba *phba, int reg)\n{\n\tstruct lpfc_mbx_reg_congestion_buf *reg_congestion_buf;\n\tunion  lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t shdr_status, shdr_add_status;\n\tLPFC_MBOXQ_t *mboxq;\n\tint length, rc;\n\n\tif (!phba->cgn_i)\n\t\treturn -ENXIO;\n\n\tmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_MBOX,\n\t\t\t\t\"2641 REG_CONGESTION_BUF mbox allocation fail: \"\n\t\t\t\t\"HBA state x%x reg %d\\n\",\n\t\t\t\tphba->pport->port_state, reg);\n\t\treturn -ENOMEM;\n\t}\n\n\tlength = (sizeof(struct lpfc_mbx_reg_congestion_buf) -\n\t\tsizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_REG_CONGESTION_BUF, length,\n\t\t\t LPFC_SLI4_MBX_EMBED);\n\treg_congestion_buf = &mboxq->u.mqe.un.reg_congestion_buf;\n\tbf_set(lpfc_mbx_reg_cgn_buf_type, reg_congestion_buf, 1);\n\tif (reg > 0)\n\t\tbf_set(lpfc_mbx_reg_cgn_buf_cnt, reg_congestion_buf, 1);\n\telse\n\t\tbf_set(lpfc_mbx_reg_cgn_buf_cnt, reg_congestion_buf, 0);\n\treg_congestion_buf->length = sizeof(struct lpfc_cgn_info);\n\treg_congestion_buf->addr_lo =\n\t\tputPaddrLow(phba->cgn_i->phys);\n\treg_congestion_buf->addr_hi =\n\t\tputPaddrHigh(phba->cgn_i->phys);\n\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&mboxq->u.mqe.un.sli4_config.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status,\n\t\t\t\t &shdr->response);\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"2642 REG_CONGESTION_BUF mailbox \"\n\t\t\t\t\"failed with status x%x add_status x%x,\"\n\t\t\t\t\" mbx status x%x reg %d\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc, reg);\n\t\treturn -ENXIO;\n\t}\n\treturn 0;\n}\n\nint\nlpfc_unreg_congestion_buf(struct lpfc_hba *phba)\n{\n\tlpfc_cmf_stop(phba);\n\treturn __lpfc_reg_congestion_buf(phba, 0);\n}\n\nint\nlpfc_reg_congestion_buf(struct lpfc_hba *phba)\n{\n\treturn __lpfc_reg_congestion_buf(phba, 1);\n}\n\n \nint\nlpfc_get_sli4_parameters(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\n{\n\tint rc;\n\tstruct lpfc_mqe *mqe = &mboxq->u.mqe;\n\tstruct lpfc_pc_sli4_params *sli4_params;\n\tuint32_t mbox_tmo;\n\tint length;\n\tbool exp_wqcq_pages = true;\n\tstruct lpfc_sli4_parameters *mbx_sli4_parameters;\n\n\t \n\tphba->sli4_hba.rpi_hdrs_in_use = 1;\n\n\t \n\tlength = (sizeof(struct lpfc_mbx_get_sli4_parameters) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_GET_SLI4_PARAMETERS,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tif (!phba->sli4_hba.intr_enable)\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mboxq);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mboxq, mbox_tmo);\n\t}\n\tif (unlikely(rc))\n\t\treturn rc;\n\tsli4_params = &phba->sli4_hba.pc_sli4_params;\n\tmbx_sli4_parameters = &mqe->un.get_sli4_parameters.sli4_parameters;\n\tsli4_params->if_type = bf_get(cfg_if_type, mbx_sli4_parameters);\n\tsli4_params->sli_rev = bf_get(cfg_sli_rev, mbx_sli4_parameters);\n\tsli4_params->sli_family = bf_get(cfg_sli_family, mbx_sli4_parameters);\n\tsli4_params->featurelevel_1 = bf_get(cfg_sli_hint_1,\n\t\t\t\t\t     mbx_sli4_parameters);\n\tsli4_params->featurelevel_2 = bf_get(cfg_sli_hint_2,\n\t\t\t\t\t     mbx_sli4_parameters);\n\tif (bf_get(cfg_phwq, mbx_sli4_parameters))\n\t\tphba->sli3_options |= LPFC_SLI4_PHWQ_ENABLED;\n\telse\n\t\tphba->sli3_options &= ~LPFC_SLI4_PHWQ_ENABLED;\n\tsli4_params->sge_supp_len = mbx_sli4_parameters->sge_supp_len;\n\tsli4_params->loopbk_scope = bf_get(cfg_loopbk_scope,\n\t\t\t\t\t   mbx_sli4_parameters);\n\tsli4_params->oas_supported = bf_get(cfg_oas, mbx_sli4_parameters);\n\tsli4_params->cqv = bf_get(cfg_cqv, mbx_sli4_parameters);\n\tsli4_params->mqv = bf_get(cfg_mqv, mbx_sli4_parameters);\n\tsli4_params->wqv = bf_get(cfg_wqv, mbx_sli4_parameters);\n\tsli4_params->rqv = bf_get(cfg_rqv, mbx_sli4_parameters);\n\tsli4_params->eqav = bf_get(cfg_eqav, mbx_sli4_parameters);\n\tsli4_params->cqav = bf_get(cfg_cqav, mbx_sli4_parameters);\n\tsli4_params->wqsize = bf_get(cfg_wqsize, mbx_sli4_parameters);\n\tsli4_params->bv1s = bf_get(cfg_bv1s, mbx_sli4_parameters);\n\tsli4_params->pls = bf_get(cfg_pvl, mbx_sli4_parameters);\n\tsli4_params->sgl_pages_max = bf_get(cfg_sgl_page_cnt,\n\t\t\t\t\t    mbx_sli4_parameters);\n\tsli4_params->wqpcnt = bf_get(cfg_wqpcnt, mbx_sli4_parameters);\n\tsli4_params->sgl_pp_align = bf_get(cfg_sgl_pp_align,\n\t\t\t\t\t   mbx_sli4_parameters);\n\tphba->sli4_hba.extents_in_use = bf_get(cfg_ext, mbx_sli4_parameters);\n\tphba->sli4_hba.rpi_hdrs_in_use = bf_get(cfg_hdrr, mbx_sli4_parameters);\n\tsli4_params->mi_cap = bf_get(cfg_mi_ver, mbx_sli4_parameters);\n\n\t \n\tphba->cfg_xpsgl = bf_get(cfg_xpsgl, mbx_sli4_parameters);\n\n\t \n\trc = (bf_get(cfg_nvme, mbx_sli4_parameters) &&\n\t\t     bf_get(cfg_xib, mbx_sli4_parameters));\n\n\tif (rc) {\n\t\t \n\t\tsli4_params->nvme = 1;\n\n\t\t \n\t\tif (phba->cfg_enable_fc4_type == LPFC_ENABLE_FCP) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_NVME,\n\t\t\t\t\t\"6133 Disabling NVME support: \"\n\t\t\t\t\t\"FC4 type not supported: x%x\\n\",\n\t\t\t\t\tphba->cfg_enable_fc4_type);\n\t\t\tgoto fcponly;\n\t\t}\n\t} else {\n\t\t \n\t\tsli4_params->nvme = 0;\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_NVME,\n\t\t\t\t\t\"6101 Disabling NVME support: Not \"\n\t\t\t\t\t\"supported by firmware (%d %d) x%x\\n\",\n\t\t\t\t\tbf_get(cfg_nvme, mbx_sli4_parameters),\n\t\t\t\t\tbf_get(cfg_xib, mbx_sli4_parameters),\n\t\t\t\t\tphba->cfg_enable_fc4_type);\nfcponly:\n\t\t\tphba->nvmet_support = 0;\n\t\t\tphba->cfg_nvmet_mrq = 0;\n\t\t\tphba->cfg_nvme_seg_cnt = 0;\n\n\t\t\t \n\t\t\tif (!(phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP))\n\t\t\t\treturn -ENODEV;\n\t\t\tphba->cfg_enable_fc4_type = LPFC_ENABLE_FCP;\n\t\t}\n\t}\n\n\t \n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\tphba->cfg_sg_seg_cnt = LPFC_MAX_NVME_SEG_CNT;\n\n\t \n\tif (bf_get(cfg_pbde, mbx_sli4_parameters))\n\t\tphba->cfg_enable_pbde = 1;\n\telse\n\t\tphba->cfg_enable_pbde = 0;\n\n\t \n\tif (phba->cfg_suppress_rsp && bf_get(cfg_xib, mbx_sli4_parameters) &&\n\t    !(bf_get(cfg_nosr, mbx_sli4_parameters)))\n\t\tphba->sli.sli_flag |= LPFC_SLI_SUPPRESS_RSP;\n\telse\n\t\tphba->cfg_suppress_rsp = 0;\n\n\tif (bf_get(cfg_eqdr, mbx_sli4_parameters))\n\t\tphba->sli.sli_flag |= LPFC_SLI_USE_EQDR;\n\n\t \n\tif (sli4_params->sge_supp_len > LPFC_MAX_SGE_SIZE)\n\t\tsli4_params->sge_supp_len = LPFC_MAX_SGE_SIZE;\n\n\trc = dma_set_max_seg_size(&phba->pcidev->dev, sli4_params->sge_supp_len);\n\tif (unlikely(rc)) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"6400 Can't set dma maximum segment size\\n\");\n\t\treturn rc;\n\t}\n\n\t \n\tif (bf_get(cfg_ext_embed_cb, mbx_sli4_parameters))\n\t\tphba->fcp_embed_io = 1;\n\telse\n\t\tphba->fcp_embed_io = 0;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_NVME,\n\t\t\t\"6422 XIB %d PBDE %d: FCP %d NVME %d %d %d\\n\",\n\t\t\tbf_get(cfg_xib, mbx_sli4_parameters),\n\t\t\tphba->cfg_enable_pbde,\n\t\t\tphba->fcp_embed_io, sli4_params->nvme,\n\t\t\tphba->cfg_nvme_embed_cmd, phba->cfg_suppress_rsp);\n\n\tif ((bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) ==\n\t    LPFC_SLI_INTF_IF_TYPE_2) &&\n\t    (bf_get(lpfc_sli_intf_sli_family, &phba->sli4_hba.sli_intf) ==\n\t\t LPFC_SLI_INTF_FAMILY_LNCR_A0))\n\t\texp_wqcq_pages = false;\n\n\tif ((bf_get(cfg_cqpsize, mbx_sli4_parameters) & LPFC_CQ_16K_PAGE_SZ) &&\n\t    (bf_get(cfg_wqpsize, mbx_sli4_parameters) & LPFC_WQ_16K_PAGE_SZ) &&\n\t    exp_wqcq_pages &&\n\t    (sli4_params->wqsize & LPFC_WQ_SZ128_SUPPORT))\n\t\tphba->enab_exp_wqcq_pages = 1;\n\telse\n\t\tphba->enab_exp_wqcq_pages = 0;\n\t \n\tif (bf_get(cfg_mds_diags, mbx_sli4_parameters))\n\t\tphba->mds_diags_support = 1;\n\telse\n\t\tphba->mds_diags_support = 0;\n\n\t \n\tif (bf_get(cfg_nsler, mbx_sli4_parameters))\n\t\tphba->nsler = 1;\n\telse\n\t\tphba->nsler = 0;\n\n\treturn 0;\n}\n\n \nstatic int\nlpfc_pci_probe_one_s3(struct pci_dev *pdev, const struct pci_device_id *pid)\n{\n\tstruct lpfc_hba   *phba;\n\tstruct lpfc_vport *vport = NULL;\n\tstruct Scsi_Host  *shost = NULL;\n\tint error;\n\tuint32_t cfg_mode, intr_mode;\n\n\t \n\tphba = lpfc_hba_alloc(pdev);\n\tif (!phba)\n\t\treturn -ENOMEM;\n\n\t \n\terror = lpfc_enable_pci_dev(phba);\n\tif (error)\n\t\tgoto out_free_phba;\n\n\t \n\terror = lpfc_api_table_setup(phba, LPFC_PCI_DEV_LP);\n\tif (error)\n\t\tgoto out_disable_pci_dev;\n\n\t \n\terror = lpfc_sli_pci_mem_setup(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1402 Failed to set up pci memory space.\\n\");\n\t\tgoto out_disable_pci_dev;\n\t}\n\n\t \n\terror = lpfc_sli_driver_resource_setup(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1404 Failed to set up driver resource.\\n\");\n\t\tgoto out_unset_pci_mem_s3;\n\t}\n\n\t \n\n\terror = lpfc_init_iocb_list(phba, LPFC_IOCB_LIST_CNT);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1405 Failed to initialize iocb list.\\n\");\n\t\tgoto out_unset_driver_resource_s3;\n\t}\n\n\t \n\terror = lpfc_setup_driver_resource_phase2(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1406 Failed to set up driver resource.\\n\");\n\t\tgoto out_free_iocb_list;\n\t}\n\n\t \n\tlpfc_get_hba_model_desc(phba, phba->ModelName, phba->ModelDesc);\n\n\t \n\terror = lpfc_create_shost(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1407 Failed to create scsi host.\\n\");\n\t\tgoto out_unset_driver_resource;\n\t}\n\n\t \n\tvport = phba->pport;\n\terror = lpfc_alloc_sysfs_attr(vport);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1476 Failed to allocate sysfs attr\\n\");\n\t\tgoto out_destroy_shost;\n\t}\n\n\tshost = lpfc_shost_from_vport(vport);  \n\t \n\tcfg_mode = phba->cfg_use_msi;\n\twhile (true) {\n\t\t \n\t\tlpfc_stop_port(phba);\n\t\t \n\t\tintr_mode = lpfc_sli_enable_intr(phba, cfg_mode);\n\t\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0431 Failed to enable interrupt.\\n\");\n\t\t\terror = -ENODEV;\n\t\t\tgoto out_free_sysfs_attr;\n\t\t}\n\t\t \n\t\tif (lpfc_sli_hba_setup(phba)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"1477 Failed to set up hba\\n\");\n\t\t\terror = -ENODEV;\n\t\t\tgoto out_remove_device;\n\t\t}\n\n\t\t \n\t\tmsleep(50);\n\t\t \n\t\tif (intr_mode == 0 ||\n\t\t    phba->sli.slistat.sli_intr > LPFC_MSIX_VECTORS) {\n\t\t\t \n\t\t\tphba->intr_mode = intr_mode;\n\t\t\tlpfc_log_intr_mode(phba, intr_mode);\n\t\t\tbreak;\n\t\t} else {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"0447 Configure interrupt mode (%d) \"\n\t\t\t\t\t\"failed active interrupt test.\\n\",\n\t\t\t\t\tintr_mode);\n\t\t\t \n\t\t\tlpfc_sli_disable_intr(phba);\n\t\t\t \n\t\t\tcfg_mode = --intr_mode;\n\t\t}\n\t}\n\n\t \n\tlpfc_post_init_setup(phba);\n\n\t \n\tlpfc_create_static_vport(phba);\n\n\treturn 0;\n\nout_remove_device:\n\tlpfc_unset_hba(phba);\nout_free_sysfs_attr:\n\tlpfc_free_sysfs_attr(vport);\nout_destroy_shost:\n\tlpfc_destroy_shost(phba);\nout_unset_driver_resource:\n\tlpfc_unset_driver_resource_phase2(phba);\nout_free_iocb_list:\n\tlpfc_free_iocb_list(phba);\nout_unset_driver_resource_s3:\n\tlpfc_sli_driver_resource_unset(phba);\nout_unset_pci_mem_s3:\n\tlpfc_sli_pci_mem_unset(phba);\nout_disable_pci_dev:\n\tlpfc_disable_pci_dev(phba);\n\tif (shost)\n\t\tscsi_host_put(shost);\nout_free_phba:\n\tlpfc_hba_free(phba);\n\treturn error;\n}\n\n \nstatic void\nlpfc_pci_remove_one_s3(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host  *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_vport *vport = (struct lpfc_vport *) shost->hostdata;\n\tstruct lpfc_vport **vports;\n\tstruct lpfc_hba   *phba = vport->phba;\n\tint i;\n\n\tspin_lock_irq(&phba->hbalock);\n\tvport->load_flag |= FC_UNLOADING;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_free_sysfs_attr(vport);\n\n\t \n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tif (vports[i]->port_type == LPFC_PHYSICAL_PORT)\n\t\t\t\tcontinue;\n\t\t\tfc_vport_terminate(vports[i]->fc_vport);\n\t\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\t \n\tfc_remove_host(shost);\n\tscsi_remove_host(shost);\n\n\t \n\tlpfc_cleanup(vport);\n\n\t \n\n\t \n\tlpfc_sli_hba_down(phba);\n\t \n\tkthread_stop(phba->worker_thread);\n\t \n\tlpfc_sli_brdrestart(phba);\n\n\tkfree(phba->vpi_bmask);\n\tkfree(phba->vpi_ids);\n\n\tlpfc_stop_hba_timers(phba);\n\tspin_lock_irq(&phba->port_list_lock);\n\tlist_del_init(&vport->listentry);\n\tspin_unlock_irq(&phba->port_list_lock);\n\n\tlpfc_debugfs_terminate(vport);\n\n\t \n\tif (phba->cfg_sriov_nr_virtfn)\n\t\tpci_disable_sriov(pdev);\n\n\t \n\tlpfc_sli_disable_intr(phba);\n\n\tscsi_host_put(shost);\n\n\t \n\tlpfc_scsi_free(phba);\n\tlpfc_free_iocb_list(phba);\n\n\tlpfc_mem_free_all(phba);\n\n\tdma_free_coherent(&pdev->dev, lpfc_sli_hbq_size(),\n\t\t\t  phba->hbqslimp.virt, phba->hbqslimp.phys);\n\n\t \n\tdma_free_coherent(&pdev->dev, SLI2_SLIM_SIZE,\n\t\t\t  phba->slim2p.virt, phba->slim2p.phys);\n\n\t \n\tiounmap(phba->ctrl_regs_memmap_p);\n\tiounmap(phba->slim_memmap_p);\n\n\tlpfc_hba_free(phba);\n\n\tpci_release_mem_regions(pdev);\n\tpci_disable_device(pdev);\n}\n\n \nstatic int __maybe_unused\nlpfc_pci_suspend_one_s3(struct device *dev_d)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev_d);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0473 PCI device Power Management suspend.\\n\");\n\n\t \n\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\tlpfc_offline(phba);\n\tkthread_stop(phba->worker_thread);\n\n\t \n\tlpfc_sli_disable_intr(phba);\n\n\treturn 0;\n}\n\n \nstatic int __maybe_unused\nlpfc_pci_resume_one_s3(struct device *dev_d)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev_d);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tuint32_t intr_mode;\n\tint error;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0452 PCI device Power Management resume.\\n\");\n\n\t \n\tphba->worker_thread = kthread_run(lpfc_do_work, phba,\n\t\t\t\t\t\"lpfc_worker_%d\", phba->brd_no);\n\tif (IS_ERR(phba->worker_thread)) {\n\t\terror = PTR_ERR(phba->worker_thread);\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"0434 PM resume failed to start worker \"\n\t\t\t\t\"thread: error=x%x.\\n\", error);\n\t\treturn error;\n\t}\n\n\t \n\tlpfc_cpu_map_array_init(phba);\n\t \n\tlpfc_hba_eq_hdl_array_init(phba);\n\t \n\tintr_mode = lpfc_sli_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0430 PM resume Failed to enable interrupt\\n\");\n\t\treturn -EIO;\n\t} else\n\t\tphba->intr_mode = intr_mode;\n\n\t \n\tlpfc_sli_brdrestart(phba);\n\tlpfc_online(phba);\n\n\t \n\tlpfc_log_intr_mode(phba, phba->intr_mode);\n\n\treturn 0;\n}\n\n \nstatic void\nlpfc_sli_prep_dev_for_recover(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2723 PCI channel I/O abort preparing for recovery\\n\");\n\n\t \n\tlpfc_sli_abort_fcp_rings(phba);\n}\n\n \nstatic void\nlpfc_sli_prep_dev_for_reset(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2710 PCI channel disable preparing for reset\\n\");\n\n\t \n\tlpfc_block_mgmt_io(phba, LPFC_MBX_WAIT);\n\n\t \n\tlpfc_scsi_dev_block(phba);\n\n\t \n\tlpfc_sli_flush_io_rings(phba);\n\n\t \n\tlpfc_stop_hba_timers(phba);\n\n\t \n\tlpfc_sli_disable_intr(phba);\n\tpci_disable_device(phba->pcidev);\n}\n\n \nstatic void\nlpfc_sli_prep_dev_for_perm_failure(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2711 PCI channel permanent disable for failure\\n\");\n\t \n\tlpfc_scsi_dev_block(phba);\n\tlpfc_sli4_prep_dev_for_reset(phba);\n\n\t \n\tlpfc_stop_hba_timers(phba);\n\n\t \n\tlpfc_sli_flush_io_rings(phba);\n}\n\n \nstatic pci_ers_result_t\nlpfc_io_error_detected_s3(struct pci_dev *pdev, pci_channel_state_t state)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tswitch (state) {\n\tcase pci_channel_io_normal:\n\t\t \n\t\tlpfc_sli_prep_dev_for_recover(phba);\n\t\treturn PCI_ERS_RESULT_CAN_RECOVER;\n\tcase pci_channel_io_frozen:\n\t\t \n\t\tlpfc_sli_prep_dev_for_reset(phba);\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\tcase pci_channel_io_perm_failure:\n\t\t \n\t\tlpfc_sli_prep_dev_for_perm_failure(phba);\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\tdefault:\n\t\t \n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0472 Unknown PCI error state: x%x\\n\", state);\n\t\tlpfc_sli_prep_dev_for_reset(phba);\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\t}\n}\n\n \nstatic pci_ers_result_t\nlpfc_io_slot_reset_s3(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tuint32_t intr_mode;\n\n\tdev_printk(KERN_INFO, &pdev->dev, \"recovering from a slot reset.\\n\");\n\tif (pci_enable_device_mem(pdev)) {\n\t\tprintk(KERN_ERR \"lpfc: Cannot re-enable \"\n\t\t\t\"PCI device after reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\tpci_restore_state(pdev);\n\n\t \n\tpci_save_state(pdev);\n\n\tif (pdev->is_busmaster)\n\t\tpci_set_master(pdev);\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tintr_mode = lpfc_sli_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0427 Cannot re-enable interrupt after \"\n\t\t\t\t\"slot reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t} else\n\t\tphba->intr_mode = intr_mode;\n\n\t \n\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\tlpfc_offline(phba);\n\tlpfc_sli_brdrestart(phba);\n\n\t \n\tlpfc_log_intr_mode(phba, phba->intr_mode);\n\n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\n \nstatic void\nlpfc_io_resume_s3(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\t \n\tlpfc_online(phba);\n}\n\n \nint\nlpfc_sli4_get_els_iocb_cnt(struct lpfc_hba *phba)\n{\n\tint max_xri = phba->sli4_hba.max_cfg_param.max_xri;\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tif (max_xri <= 100)\n\t\t\treturn 10;\n\t\telse if (max_xri <= 256)\n\t\t\treturn 25;\n\t\telse if (max_xri <= 512)\n\t\t\treturn 50;\n\t\telse if (max_xri <= 1024)\n\t\t\treturn 100;\n\t\telse if (max_xri <= 1536)\n\t\t\treturn 150;\n\t\telse if (max_xri <= 2048)\n\t\t\treturn 200;\n\t\telse\n\t\t\treturn 250;\n\t} else\n\t\treturn 0;\n}\n\n \nint\nlpfc_sli4_get_iocb_cnt(struct lpfc_hba *phba)\n{\n\tint max_xri = lpfc_sli4_get_els_iocb_cnt(phba);\n\n\tif (phba->nvmet_support)\n\t\tmax_xri += LPFC_NVMET_BUF_POST;\n\treturn max_xri;\n}\n\n\nstatic int\nlpfc_log_write_firmware_error(struct lpfc_hba *phba, uint32_t offset,\n\tuint32_t magic_number, uint32_t ftype, uint32_t fid, uint32_t fsize,\n\tconst struct firmware *fw)\n{\n\tint rc;\n\tu8 sli_family;\n\n\tsli_family = bf_get(lpfc_sli_intf_sli_family, &phba->sli4_hba.sli_intf);\n\t \n\tif (offset == ADD_STATUS_FW_NOT_SUPPORTED ||\n\t    (sli_family == LPFC_SLI_INTF_FAMILY_G6 &&\n\t     magic_number != MAGIC_NUMBER_G6) ||\n\t    (sli_family == LPFC_SLI_INTF_FAMILY_G7 &&\n\t     magic_number != MAGIC_NUMBER_G7) ||\n\t    (sli_family == LPFC_SLI_INTF_FAMILY_G7P &&\n\t     magic_number != MAGIC_NUMBER_G7P)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3030 This firmware version is not supported on\"\n\t\t\t\t\" this HBA model. Device:%x Magic:%x Type:%x \"\n\t\t\t\t\"ID:%x Size %d %zd\\n\",\n\t\t\t\tphba->pcidev->device, magic_number, ftype, fid,\n\t\t\t\tfsize, fw->size);\n\t\trc = -EINVAL;\n\t} else if (offset == ADD_STATUS_FW_DOWNLOAD_HW_DISABLED) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3021 Firmware downloads have been prohibited \"\n\t\t\t\t\"by a system configuration setting on \"\n\t\t\t\t\"Device:%x Magic:%x Type:%x ID:%x Size %d \"\n\t\t\t\t\"%zd\\n\",\n\t\t\t\tphba->pcidev->device, magic_number, ftype, fid,\n\t\t\t\tfsize, fw->size);\n\t\trc = -EACCES;\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3022 FW Download failed. Add Status x%x \"\n\t\t\t\t\"Device:%x Magic:%x Type:%x ID:%x Size %d \"\n\t\t\t\t\"%zd\\n\",\n\t\t\t\toffset, phba->pcidev->device, magic_number,\n\t\t\t\tftype, fid, fsize, fw->size);\n\t\trc = -EIO;\n\t}\n\treturn rc;\n}\n\n \nstatic void\nlpfc_write_firmware(const struct firmware *fw, void *context)\n{\n\tstruct lpfc_hba *phba = (struct lpfc_hba *)context;\n\tchar fwrev[FW_REV_STR_SIZE];\n\tstruct lpfc_grp_hdr *image;\n\tstruct list_head dma_buffer_list;\n\tint i, rc = 0;\n\tstruct lpfc_dmabuf *dmabuf, *next;\n\tuint32_t offset = 0, temp_offset = 0;\n\tuint32_t magic_number, ftype, fid, fsize;\n\n\t \n\tif (!fw) {\n\t\trc = -ENXIO;\n\t\tgoto out;\n\t}\n\timage = (struct lpfc_grp_hdr *)fw->data;\n\n\tmagic_number = be32_to_cpu(image->magic_number);\n\tftype = bf_get_be32(lpfc_grp_hdr_file_type, image);\n\tfid = bf_get_be32(lpfc_grp_hdr_id, image);\n\tfsize = be32_to_cpu(image->size);\n\n\tINIT_LIST_HEAD(&dma_buffer_list);\n\tlpfc_decode_firmware_rev(phba, fwrev, 1);\n\tif (strncmp(fwrev, image->revision, strnlen(image->revision, 16))) {\n\t\tlpfc_log_msg(phba, KERN_NOTICE, LOG_INIT | LOG_SLI,\n\t\t\t     \"3023 Updating Firmware, Current Version:%s \"\n\t\t\t     \"New Version:%s\\n\",\n\t\t\t     fwrev, image->revision);\n\t\tfor (i = 0; i < LPFC_MBX_WR_CONFIG_MAX_BDE; i++) {\n\t\t\tdmabuf = kzalloc(sizeof(struct lpfc_dmabuf),\n\t\t\t\t\t GFP_KERNEL);\n\t\t\tif (!dmabuf) {\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto release_out;\n\t\t\t}\n\t\t\tdmabuf->virt = dma_alloc_coherent(&phba->pcidev->dev,\n\t\t\t\t\t\t\t  SLI4_PAGE_SIZE,\n\t\t\t\t\t\t\t  &dmabuf->phys,\n\t\t\t\t\t\t\t  GFP_KERNEL);\n\t\t\tif (!dmabuf->virt) {\n\t\t\t\tkfree(dmabuf);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto release_out;\n\t\t\t}\n\t\t\tlist_add_tail(&dmabuf->list, &dma_buffer_list);\n\t\t}\n\t\twhile (offset < fw->size) {\n\t\t\ttemp_offset = offset;\n\t\t\tlist_for_each_entry(dmabuf, &dma_buffer_list, list) {\n\t\t\t\tif (temp_offset + SLI4_PAGE_SIZE > fw->size) {\n\t\t\t\t\tmemcpy(dmabuf->virt,\n\t\t\t\t\t       fw->data + temp_offset,\n\t\t\t\t\t       fw->size - temp_offset);\n\t\t\t\t\ttemp_offset = fw->size;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tmemcpy(dmabuf->virt, fw->data + temp_offset,\n\t\t\t\t       SLI4_PAGE_SIZE);\n\t\t\t\ttemp_offset += SLI4_PAGE_SIZE;\n\t\t\t}\n\t\t\trc = lpfc_wr_object(phba, &dma_buffer_list,\n\t\t\t\t    (fw->size - offset), &offset);\n\t\t\tif (rc) {\n\t\t\t\trc = lpfc_log_write_firmware_error(phba, offset,\n\t\t\t\t\t\t\t\t   magic_number,\n\t\t\t\t\t\t\t\t   ftype,\n\t\t\t\t\t\t\t\t   fid,\n\t\t\t\t\t\t\t\t   fsize,\n\t\t\t\t\t\t\t\t   fw);\n\t\t\t\tgoto release_out;\n\t\t\t}\n\t\t}\n\t\trc = offset;\n\t} else\n\t\tlpfc_log_msg(phba, KERN_NOTICE, LOG_INIT | LOG_SLI,\n\t\t\t     \"3029 Skipped Firmware update, Current \"\n\t\t\t     \"Version:%s New Version:%s\\n\",\n\t\t\t     fwrev, image->revision);\n\nrelease_out:\n\tlist_for_each_entry_safe(dmabuf, next, &dma_buffer_list, list) {\n\t\tlist_del(&dmabuf->list);\n\t\tdma_free_coherent(&phba->pcidev->dev, SLI4_PAGE_SIZE,\n\t\t\t\t  dmabuf->virt, dmabuf->phys);\n\t\tkfree(dmabuf);\n\t}\n\trelease_firmware(fw);\nout:\n\tif (rc < 0)\n\t\tlpfc_log_msg(phba, KERN_ERR, LOG_INIT | LOG_SLI,\n\t\t\t     \"3062 Firmware update error, status %d.\\n\", rc);\n\telse\n\t\tlpfc_log_msg(phba, KERN_NOTICE, LOG_INIT | LOG_SLI,\n\t\t\t     \"3024 Firmware update success: size %d.\\n\", rc);\n}\n\n \nint\nlpfc_sli4_request_firmware_update(struct lpfc_hba *phba, uint8_t fw_upgrade)\n{\n\tuint8_t file_name[ELX_MODEL_NAME_SIZE];\n\tint ret;\n\tconst struct firmware *fw;\n\n\t \n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) <\n\t    LPFC_SLI_INTF_IF_TYPE_2)\n\t\treturn -EPERM;\n\n\tsnprintf(file_name, ELX_MODEL_NAME_SIZE, \"%s.grp\", phba->ModelName);\n\n\tif (fw_upgrade == INT_FW_UPGRADE) {\n\t\tret = request_firmware_nowait(THIS_MODULE, FW_ACTION_UEVENT,\n\t\t\t\t\tfile_name, &phba->pcidev->dev,\n\t\t\t\t\tGFP_KERNEL, (void *)phba,\n\t\t\t\t\tlpfc_write_firmware);\n\t} else if (fw_upgrade == RUN_FW_UPGRADE) {\n\t\tret = request_firmware(&fw, file_name, &phba->pcidev->dev);\n\t\tif (!ret)\n\t\t\tlpfc_write_firmware(fw, (void *)phba);\n\t} else {\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\n \nstatic int\nlpfc_pci_probe_one_s4(struct pci_dev *pdev, const struct pci_device_id *pid)\n{\n\tstruct lpfc_hba   *phba;\n\tstruct lpfc_vport *vport = NULL;\n\tstruct Scsi_Host  *shost = NULL;\n\tint error;\n\tuint32_t cfg_mode, intr_mode;\n\n\t \n\tphba = lpfc_hba_alloc(pdev);\n\tif (!phba)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&phba->poll_list);\n\n\t \n\terror = lpfc_enable_pci_dev(phba);\n\tif (error)\n\t\tgoto out_free_phba;\n\n\t \n\terror = lpfc_api_table_setup(phba, LPFC_PCI_DEV_OC);\n\tif (error)\n\t\tgoto out_disable_pci_dev;\n\n\t \n\terror = lpfc_sli4_pci_mem_setup(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1410 Failed to set up pci memory space.\\n\");\n\t\tgoto out_disable_pci_dev;\n\t}\n\n\t \n\terror = lpfc_sli4_driver_resource_setup(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1412 Failed to set up driver resource.\\n\");\n\t\tgoto out_unset_pci_mem_s4;\n\t}\n\n\tINIT_LIST_HEAD(&phba->active_rrq_list);\n\tINIT_LIST_HEAD(&phba->fcf.fcf_pri_list);\n\n\t \n\terror = lpfc_setup_driver_resource_phase2(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1414 Failed to set up driver resource.\\n\");\n\t\tgoto out_unset_driver_resource_s4;\n\t}\n\n\t \n\tlpfc_get_hba_model_desc(phba, phba->ModelName, phba->ModelDesc);\n\n\t \n\tcfg_mode = phba->cfg_use_msi;\n\n\t \n\tphba->pport = NULL;\n\tlpfc_stop_port(phba);\n\n\t \n\tlpfc_cpu_map_array_init(phba);\n\n\t \n\tlpfc_hba_eq_hdl_array_init(phba);\n\n\t \n\tintr_mode = lpfc_sli4_enable_intr(phba, cfg_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0426 Failed to enable interrupt.\\n\");\n\t\terror = -ENODEV;\n\t\tgoto out_unset_driver_resource;\n\t}\n\t \n\tif (phba->intr_type != MSIX) {\n\t\tphba->cfg_irq_chann = 1;\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t\tif (phba->nvmet_support)\n\t\t\t\tphba->cfg_nvmet_mrq = 1;\n\t\t}\n\t}\n\tlpfc_cpu_affinity_check(phba, phba->cfg_irq_chann);\n\n\t \n\terror = lpfc_create_shost(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1415 Failed to create scsi host.\\n\");\n\t\tgoto out_disable_intr;\n\t}\n\tvport = phba->pport;\n\tshost = lpfc_shost_from_vport(vport);  \n\n\t \n\terror = lpfc_alloc_sysfs_attr(vport);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1416 Failed to allocate sysfs attr\\n\");\n\t\tgoto out_destroy_shost;\n\t}\n\n\t \n\tif (lpfc_sli4_hba_setup(phba)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1421 Failed to set up hba\\n\");\n\t\terror = -ENODEV;\n\t\tgoto out_free_sysfs_attr;\n\t}\n\n\t \n\tphba->intr_mode = intr_mode;\n\tlpfc_log_intr_mode(phba, intr_mode);\n\n\t \n\tlpfc_post_init_setup(phba);\n\n\t \n\tif (phba->nvmet_support == 0) {\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t\t \n\t\t\terror = lpfc_nvme_create_localport(vport);\n\t\t\tif (error) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6004 NVME registration \"\n\t\t\t\t\t\t\"failed, error x%x\\n\",\n\t\t\t\t\t\terror);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (phba->cfg_request_firmware_upgrade)\n\t\tlpfc_sli4_request_firmware_update(phba, INT_FW_UPGRADE);\n\n\t \n\tlpfc_create_static_vport(phba);\n\n\ttimer_setup(&phba->cpuhp_poll_timer, lpfc_sli4_poll_hbtimer, 0);\n\tcpuhp_state_add_instance_nocalls(lpfc_cpuhp_state, &phba->cpuhp);\n\n\treturn 0;\n\nout_free_sysfs_attr:\n\tlpfc_free_sysfs_attr(vport);\nout_destroy_shost:\n\tlpfc_destroy_shost(phba);\nout_disable_intr:\n\tlpfc_sli4_disable_intr(phba);\nout_unset_driver_resource:\n\tlpfc_unset_driver_resource_phase2(phba);\nout_unset_driver_resource_s4:\n\tlpfc_sli4_driver_resource_unset(phba);\nout_unset_pci_mem_s4:\n\tlpfc_sli4_pci_mem_unset(phba);\nout_disable_pci_dev:\n\tlpfc_disable_pci_dev(phba);\n\tif (shost)\n\t\tscsi_host_put(shost);\nout_free_phba:\n\tlpfc_hba_free(phba);\n\treturn error;\n}\n\n \nstatic void\nlpfc_pci_remove_one_s4(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_vport *vport = (struct lpfc_vport *) shost->hostdata;\n\tstruct lpfc_vport **vports;\n\tstruct lpfc_hba *phba = vport->phba;\n\tint i;\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tvport->load_flag |= FC_UNLOADING;\n\tspin_unlock_irq(&phba->hbalock);\n\tif (phba->cgn_i)\n\t\tlpfc_unreg_congestion_buf(phba);\n\n\tlpfc_free_sysfs_attr(vport);\n\n\t \n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tif (vports[i]->port_type == LPFC_PHYSICAL_PORT)\n\t\t\t\tcontinue;\n\t\t\tfc_vport_terminate(vports[i]->fc_vport);\n\t\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\t \n\tfc_remove_host(shost);\n\tscsi_remove_host(shost);\n\n\t \n\tlpfc_cleanup(vport);\n\tlpfc_nvmet_destroy_targetport(phba);\n\tlpfc_nvme_destroy_localport(vport);\n\n\t \n\tif (phba->cfg_xri_rebalancing)\n\t\tlpfc_destroy_multixri_pools(phba);\n\n\t \n\tlpfc_debugfs_terminate(vport);\n\n\tlpfc_stop_hba_timers(phba);\n\tspin_lock_irq(&phba->port_list_lock);\n\tlist_del_init(&vport->listentry);\n\tspin_unlock_irq(&phba->port_list_lock);\n\n\t \n\tlpfc_io_free(phba);\n\tlpfc_free_iocb_list(phba);\n\tlpfc_sli4_hba_unset(phba);\n\n\tlpfc_unset_driver_resource_phase2(phba);\n\tlpfc_sli4_driver_resource_unset(phba);\n\n\t \n\tlpfc_sli4_pci_mem_unset(phba);\n\n\t \n\tscsi_host_put(shost);\n\tlpfc_disable_pci_dev(phba);\n\n\t \n\tlpfc_hba_free(phba);\n\n\treturn;\n}\n\n \nstatic int __maybe_unused\nlpfc_pci_suspend_one_s4(struct device *dev_d)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev_d);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2843 PCI device Power Management suspend.\\n\");\n\n\t \n\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\tlpfc_offline(phba);\n\tkthread_stop(phba->worker_thread);\n\n\t \n\tlpfc_sli4_disable_intr(phba);\n\tlpfc_sli4_queue_destroy(phba);\n\n\treturn 0;\n}\n\n \nstatic int __maybe_unused\nlpfc_pci_resume_one_s4(struct device *dev_d)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev_d);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tuint32_t intr_mode;\n\tint error;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0292 PCI device Power Management resume.\\n\");\n\n\t  \n\tphba->worker_thread = kthread_run(lpfc_do_work, phba,\n\t\t\t\t\t\"lpfc_worker_%d\", phba->brd_no);\n\tif (IS_ERR(phba->worker_thread)) {\n\t\terror = PTR_ERR(phba->worker_thread);\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"0293 PM resume failed to start worker \"\n\t\t\t\t\"thread: error=x%x.\\n\", error);\n\t\treturn error;\n\t}\n\n\t \n\tintr_mode = lpfc_sli4_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0294 PM resume Failed to enable interrupt\\n\");\n\t\treturn -EIO;\n\t} else\n\t\tphba->intr_mode = intr_mode;\n\n\t \n\tlpfc_sli_brdrestart(phba);\n\tlpfc_online(phba);\n\n\t \n\tlpfc_log_intr_mode(phba, phba->intr_mode);\n\n\treturn 0;\n}\n\n \nstatic void\nlpfc_sli4_prep_dev_for_recover(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2828 PCI channel I/O abort preparing for recovery\\n\");\n\t \n\tlpfc_sli_abort_fcp_rings(phba);\n}\n\n \nstatic void\nlpfc_sli4_prep_dev_for_reset(struct lpfc_hba *phba)\n{\n\tint offline =  pci_channel_offline(phba->pcidev);\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\"2826 PCI channel disable preparing for reset offline\"\n\t\t\t\" %d\\n\", offline);\n\n\t \n\tlpfc_block_mgmt_io(phba, LPFC_MBX_NO_WAIT);\n\n\n\t \n\tlpfc_offline_prep(phba, LPFC_MBX_NO_WAIT);\n\t \n\tlpfc_sli_flush_io_rings(phba);\n\tlpfc_offline(phba);\n\n\t \n\tlpfc_stop_hba_timers(phba);\n\n\tlpfc_sli4_queue_destroy(phba);\n\t \n\tlpfc_sli4_disable_intr(phba);\n\tpci_disable_device(phba->pcidev);\n}\n\n \nstatic void\nlpfc_sli4_prep_dev_for_perm_failure(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2827 PCI channel permanent disable for failure\\n\");\n\n\t \n\tlpfc_scsi_dev_block(phba);\n\n\t \n\tlpfc_stop_hba_timers(phba);\n\n\t \n\tlpfc_sli_flush_io_rings(phba);\n}\n\n \nstatic pci_ers_result_t\nlpfc_io_error_detected_s4(struct pci_dev *pdev, pci_channel_state_t state)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tbool hba_pci_err;\n\n\tswitch (state) {\n\tcase pci_channel_io_normal:\n\t\t \n\t\tlpfc_sli4_prep_dev_for_recover(phba);\n\t\treturn PCI_ERS_RESULT_CAN_RECOVER;\n\tcase pci_channel_io_frozen:\n\t\thba_pci_err = test_and_set_bit(HBA_PCI_ERR, &phba->bit_flags);\n\t\t \n\t\tif (!hba_pci_err)\n\t\t\tlpfc_sli4_prep_dev_for_reset(phba);\n\t\telse\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\t\"2832  Already handling PCI error \"\n\t\t\t\t\t\"state: x%x\\n\", state);\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\tcase pci_channel_io_perm_failure:\n\t\tset_bit(HBA_PCI_ERR, &phba->bit_flags);\n\t\t \n\t\tlpfc_sli4_prep_dev_for_perm_failure(phba);\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\tdefault:\n\t\thba_pci_err = test_and_set_bit(HBA_PCI_ERR, &phba->bit_flags);\n\t\tif (!hba_pci_err)\n\t\t\tlpfc_sli4_prep_dev_for_reset(phba);\n\t\t \n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2825 Unknown PCI error state: x%x\\n\", state);\n\t\tlpfc_sli4_prep_dev_for_reset(phba);\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\t}\n}\n\n \nstatic pci_ers_result_t\nlpfc_io_slot_reset_s4(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tuint32_t intr_mode;\n\tbool hba_pci_err;\n\n\tdev_printk(KERN_INFO, &pdev->dev, \"recovering from a slot reset.\\n\");\n\tif (pci_enable_device_mem(pdev)) {\n\t\tprintk(KERN_ERR \"lpfc: Cannot re-enable \"\n\t\t       \"PCI device after reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\tpci_restore_state(pdev);\n\n\thba_pci_err = test_and_clear_bit(HBA_PCI_ERR, &phba->bit_flags);\n\tif (!hba_pci_err)\n\t\tdev_info(&pdev->dev,\n\t\t\t \"hba_pci_err was not set, recovering slot reset.\\n\");\n\t \n\tpci_save_state(pdev);\n\n\tif (pdev->is_busmaster)\n\t\tpci_set_master(pdev);\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tlpfc_cpu_map_array_init(phba);\n\t \n\tintr_mode = lpfc_sli4_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2824 Cannot re-enable interrupt after \"\n\t\t\t\t\"slot reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t} else\n\t\tphba->intr_mode = intr_mode;\n\tlpfc_cpu_affinity_check(phba, phba->cfg_irq_chann);\n\n\t \n\tlpfc_log_intr_mode(phba, phba->intr_mode);\n\n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\n \nstatic void\nlpfc_io_resume_s4(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\t \n\tif (!(phba->sli.sli_flag & LPFC_SLI_ACTIVE)) {\n\t\t \n\t\tlpfc_sli_brdrestart(phba);\n\t\t \n\t\tlpfc_online(phba);\n\t}\n}\n\n \nstatic int\nlpfc_pci_probe_one(struct pci_dev *pdev, const struct pci_device_id *pid)\n{\n\tint rc;\n\tstruct lpfc_sli_intf intf;\n\n\tif (pci_read_config_dword(pdev, LPFC_SLI_INTF, &intf.word0))\n\t\treturn -ENODEV;\n\n\tif ((bf_get(lpfc_sli_intf_valid, &intf) == LPFC_SLI_INTF_VALID) &&\n\t    (bf_get(lpfc_sli_intf_slirev, &intf) == LPFC_SLI_INTF_REV_SLI4))\n\t\trc = lpfc_pci_probe_one_s4(pdev, pid);\n\telse\n\t\trc = lpfc_pci_probe_one_s3(pdev, pid);\n\n\treturn rc;\n}\n\n \nstatic void\nlpfc_pci_remove_one(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\tlpfc_pci_remove_one_s3(pdev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\tlpfc_pci_remove_one_s4(pdev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1424 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn;\n}\n\n \nstatic int __maybe_unused\nlpfc_pci_suspend_one(struct device *dev)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tint rc = -ENODEV;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\trc = lpfc_pci_suspend_one_s3(dev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\trc = lpfc_pci_suspend_one_s4(dev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1425 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n \nstatic int __maybe_unused\nlpfc_pci_resume_one(struct device *dev)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tint rc = -ENODEV;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\trc = lpfc_pci_resume_one_s3(dev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\trc = lpfc_pci_resume_one_s4(dev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1426 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n \nstatic pci_ers_result_t\nlpfc_io_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tpci_ers_result_t rc = PCI_ERS_RESULT_DISCONNECT;\n\n\tif (phba->link_state == LPFC_HBA_ERROR &&\n\t    phba->hba_flag & HBA_IOQ_FLUSH)\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\trc = lpfc_io_error_detected_s3(pdev, state);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\trc = lpfc_io_error_detected_s4(pdev, state);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1427 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n \nstatic pci_ers_result_t\nlpfc_io_slot_reset(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tpci_ers_result_t rc = PCI_ERS_RESULT_DISCONNECT;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\trc = lpfc_io_slot_reset_s3(pdev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\trc = lpfc_io_slot_reset_s4(pdev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1428 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n \nstatic void\nlpfc_io_resume(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\tlpfc_io_resume_s3(pdev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\tlpfc_io_resume_s4(pdev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1429 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn;\n}\n\n \nstatic void\nlpfc_sli4_oas_verify(struct lpfc_hba *phba)\n{\n\n\tif (!phba->cfg_EnableXLane)\n\t\treturn;\n\n\tif (phba->sli4_hba.pc_sli4_params.oas_supported) {\n\t\tphba->cfg_fof = 1;\n\t} else {\n\t\tphba->cfg_fof = 0;\n\t\tmempool_destroy(phba->device_data_mem_pool);\n\t\tphba->device_data_mem_pool = NULL;\n\t}\n\n\treturn;\n}\n\n \nvoid\nlpfc_sli4_ras_init(struct lpfc_hba *phba)\n{\n\t \n\tif ((bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) ==\n\t\t    LPFC_SLI_INTF_IF_TYPE_6) ||\n\t    (bf_get(lpfc_sli_intf_sli_family, &phba->sli4_hba.sli_intf) ==\n\t\t    LPFC_SLI_INTF_FAMILY_G6)) {\n\t\tphba->ras_fwlog.ras_hwsupport = true;\n\t\tif (phba->cfg_ras_fwlog_func == PCI_FUNC(phba->pcidev->devfn) &&\n\t\t    phba->cfg_ras_fwlog_buffsize)\n\t\t\tphba->ras_fwlog.ras_enabled = true;\n\t\telse\n\t\t\tphba->ras_fwlog.ras_enabled = false;\n\t} else {\n\t\tphba->ras_fwlog.ras_hwsupport = false;\n\t}\n}\n\n\nMODULE_DEVICE_TABLE(pci, lpfc_id_table);\n\nstatic const struct pci_error_handlers lpfc_err_handler = {\n\t.error_detected = lpfc_io_error_detected,\n\t.slot_reset = lpfc_io_slot_reset,\n\t.resume = lpfc_io_resume,\n};\n\nstatic SIMPLE_DEV_PM_OPS(lpfc_pci_pm_ops_one,\n\t\t\t lpfc_pci_suspend_one,\n\t\t\t lpfc_pci_resume_one);\n\nstatic struct pci_driver lpfc_driver = {\n\t.name\t\t= LPFC_DRIVER_NAME,\n\t.id_table\t= lpfc_id_table,\n\t.probe\t\t= lpfc_pci_probe_one,\n\t.remove\t\t= lpfc_pci_remove_one,\n\t.shutdown\t= lpfc_pci_remove_one,\n\t.driver.pm\t= &lpfc_pci_pm_ops_one,\n\t.err_handler    = &lpfc_err_handler,\n};\n\nstatic const struct file_operations lpfc_mgmt_fop = {\n\t.owner = THIS_MODULE,\n};\n\nstatic struct miscdevice lpfc_mgmt_dev = {\n\t.minor = MISC_DYNAMIC_MINOR,\n\t.name = \"lpfcmgmt\",\n\t.fops = &lpfc_mgmt_fop,\n};\n\n \nstatic int __init\nlpfc_init(void)\n{\n\tint error = 0;\n\n\tpr_info(LPFC_MODULE_DESC \"\\n\");\n\tpr_info(LPFC_COPYRIGHT \"\\n\");\n\n\terror = misc_register(&lpfc_mgmt_dev);\n\tif (error)\n\t\tprintk(KERN_ERR \"Could not register lpfcmgmt device, \"\n\t\t\t\"misc_register returned with status %d\", error);\n\n\terror = -ENOMEM;\n\tlpfc_transport_functions.vport_create = lpfc_vport_create;\n\tlpfc_transport_functions.vport_delete = lpfc_vport_delete;\n\tlpfc_transport_template =\n\t\t\t\tfc_attach_transport(&lpfc_transport_functions);\n\tif (lpfc_transport_template == NULL)\n\t\tgoto unregister;\n\tlpfc_vport_transport_template =\n\t\tfc_attach_transport(&lpfc_vport_transport_functions);\n\tif (lpfc_vport_transport_template == NULL) {\n\t\tfc_release_transport(lpfc_transport_template);\n\t\tgoto unregister;\n\t}\n\tlpfc_wqe_cmd_template();\n\tlpfc_nvmet_cmd_template();\n\n\t \n\tlpfc_present_cpu = num_present_cpus();\n\n\tlpfc_pldv_detect = false;\n\n\terror = cpuhp_setup_state_multi(CPUHP_AP_ONLINE_DYN,\n\t\t\t\t\t\"lpfc/sli4:online\",\n\t\t\t\t\tlpfc_cpu_online, lpfc_cpu_offline);\n\tif (error < 0)\n\t\tgoto cpuhp_failure;\n\tlpfc_cpuhp_state = error;\n\n\terror = pci_register_driver(&lpfc_driver);\n\tif (error)\n\t\tgoto unwind;\n\n\treturn error;\n\nunwind:\n\tcpuhp_remove_multi_state(lpfc_cpuhp_state);\ncpuhp_failure:\n\tfc_release_transport(lpfc_transport_template);\n\tfc_release_transport(lpfc_vport_transport_template);\nunregister:\n\tmisc_deregister(&lpfc_mgmt_dev);\n\n\treturn error;\n}\n\nvoid lpfc_dmp_dbg(struct lpfc_hba *phba)\n{\n\tunsigned int start_idx;\n\tunsigned int dbg_cnt;\n\tunsigned int temp_idx;\n\tint i;\n\tint j = 0;\n\tunsigned long rem_nsec;\n\n\tif (atomic_cmpxchg(&phba->dbg_log_dmping, 0, 1) != 0)\n\t\treturn;\n\n\tstart_idx = (unsigned int)atomic_read(&phba->dbg_log_idx) % DBG_LOG_SZ;\n\tdbg_cnt = (unsigned int)atomic_read(&phba->dbg_log_cnt);\n\tif (!dbg_cnt)\n\t\tgoto out;\n\ttemp_idx = start_idx;\n\tif (dbg_cnt >= DBG_LOG_SZ) {\n\t\tdbg_cnt = DBG_LOG_SZ;\n\t\ttemp_idx -= 1;\n\t} else {\n\t\tif ((start_idx + dbg_cnt) > (DBG_LOG_SZ - 1)) {\n\t\t\ttemp_idx = (start_idx + dbg_cnt) % DBG_LOG_SZ;\n\t\t} else {\n\t\t\tif (start_idx < dbg_cnt)\n\t\t\t\tstart_idx = DBG_LOG_SZ - (dbg_cnt - start_idx);\n\t\t\telse\n\t\t\t\tstart_idx -= dbg_cnt;\n\t\t}\n\t}\n\tdev_info(&phba->pcidev->dev, \"start %d end %d cnt %d\\n\",\n\t\t start_idx, temp_idx, dbg_cnt);\n\n\tfor (i = 0; i < dbg_cnt; i++) {\n\t\tif ((start_idx + i) < DBG_LOG_SZ)\n\t\t\ttemp_idx = (start_idx + i) % DBG_LOG_SZ;\n\t\telse\n\t\t\ttemp_idx = j++;\n\t\trem_nsec = do_div(phba->dbg_log[temp_idx].t_ns, NSEC_PER_SEC);\n\t\tdev_info(&phba->pcidev->dev, \"%d: [%5lu.%06lu] %s\",\n\t\t\t temp_idx,\n\t\t\t (unsigned long)phba->dbg_log[temp_idx].t_ns,\n\t\t\t rem_nsec / 1000,\n\t\t\t phba->dbg_log[temp_idx].log);\n\t}\nout:\n\tatomic_set(&phba->dbg_log_cnt, 0);\n\tatomic_set(&phba->dbg_log_dmping, 0);\n}\n\n__printf(2, 3)\nvoid lpfc_dbg_print(struct lpfc_hba *phba, const char *fmt, ...)\n{\n\tunsigned int idx;\n\tva_list args;\n\tint dbg_dmping = atomic_read(&phba->dbg_log_dmping);\n\tstruct va_format vaf;\n\n\n\tva_start(args, fmt);\n\tif (unlikely(dbg_dmping)) {\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tdev_info(&phba->pcidev->dev, \"%pV\", &vaf);\n\t\tva_end(args);\n\t\treturn;\n\t}\n\tidx = (unsigned int)atomic_fetch_add(1, &phba->dbg_log_idx) %\n\t\tDBG_LOG_SZ;\n\n\tatomic_inc(&phba->dbg_log_cnt);\n\n\tvscnprintf(phba->dbg_log[idx].log,\n\t\t   sizeof(phba->dbg_log[idx].log), fmt, args);\n\tva_end(args);\n\n\tphba->dbg_log[idx].t_ns = local_clock();\n}\n\n \nstatic void __exit\nlpfc_exit(void)\n{\n\tmisc_deregister(&lpfc_mgmt_dev);\n\tpci_unregister_driver(&lpfc_driver);\n\tcpuhp_remove_multi_state(lpfc_cpuhp_state);\n\tfc_release_transport(lpfc_transport_template);\n\tfc_release_transport(lpfc_vport_transport_template);\n\tidr_destroy(&lpfc_hba_index);\n}\n\nmodule_init(lpfc_init);\nmodule_exit(lpfc_exit);\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(LPFC_MODULE_DESC);\nMODULE_AUTHOR(\"Broadcom\");\nMODULE_VERSION(\"0:\" LPFC_DRIVER_VERSION);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}