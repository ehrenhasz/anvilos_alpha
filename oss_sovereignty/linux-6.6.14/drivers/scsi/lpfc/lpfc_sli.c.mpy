{
  "module_name": "lpfc_sli.c",
  "hash_id": "a6ea14f82fdc32fbdfe63b39ca86de1cb6a0ab367cc2aa5995706c5238757759",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/lpfc/lpfc_sli.c",
  "human_readable_source": " \n\n#include <linux/blkdev.h>\n#include <linux/pci.h>\n#include <linux/interrupt.h>\n#include <linux/delay.h>\n#include <linux/slab.h>\n#include <linux/lockdep.h>\n\n#include <scsi/scsi.h>\n#include <scsi/scsi_cmnd.h>\n#include <scsi/scsi_device.h>\n#include <scsi/scsi_host.h>\n#include <scsi/scsi_transport_fc.h>\n#include <scsi/fc/fc_fs.h>\n#include <linux/crash_dump.h>\n#ifdef CONFIG_X86\n#include <asm/set_memory.h>\n#endif\n\n#include \"lpfc_hw4.h\"\n#include \"lpfc_hw.h\"\n#include \"lpfc_sli.h\"\n#include \"lpfc_sli4.h\"\n#include \"lpfc_nl.h\"\n#include \"lpfc_disc.h\"\n#include \"lpfc.h\"\n#include \"lpfc_scsi.h\"\n#include \"lpfc_nvme.h\"\n#include \"lpfc_crtn.h\"\n#include \"lpfc_logmsg.h\"\n#include \"lpfc_compat.h\"\n#include \"lpfc_debugfs.h\"\n#include \"lpfc_vport.h\"\n#include \"lpfc_version.h\"\n\n \ntypedef enum _lpfc_iocb_type {\n\tLPFC_UNKNOWN_IOCB,\n\tLPFC_UNSOL_IOCB,\n\tLPFC_SOL_IOCB,\n\tLPFC_ABORT_IOCB\n} lpfc_iocb_type;\n\n\n \nstatic int lpfc_sli_issue_mbox_s4(struct lpfc_hba *, LPFC_MBOXQ_t *,\n\t\t\t\t  uint32_t);\nstatic int lpfc_sli4_read_rev(struct lpfc_hba *, LPFC_MBOXQ_t *,\n\t\t\t      uint8_t *, uint32_t *);\nstatic struct lpfc_iocbq *\nlpfc_sli4_els_preprocess_rspiocbq(struct lpfc_hba *phba,\n\t\t\t\t  struct lpfc_iocbq *rspiocbq);\nstatic void lpfc_sli4_send_seq_to_ulp(struct lpfc_vport *,\n\t\t\t\t      struct hbq_dmabuf *);\nstatic void lpfc_sli4_handle_mds_loopback(struct lpfc_vport *vport,\n\t\t\t\t\t  struct hbq_dmabuf *dmabuf);\nstatic bool lpfc_sli4_fp_handle_cqe(struct lpfc_hba *phba,\n\t\t\t\t   struct lpfc_queue *cq, struct lpfc_cqe *cqe);\nstatic int lpfc_sli4_post_sgl_list(struct lpfc_hba *, struct list_head *,\n\t\t\t\t       int);\nstatic void lpfc_sli4_hba_handle_eqe(struct lpfc_hba *phba,\n\t\t\t\t     struct lpfc_queue *eq,\n\t\t\t\t     struct lpfc_eqe *eqe,\n\t\t\t\t     enum lpfc_poll_mode poll_mode);\nstatic bool lpfc_sli4_mbox_completions_pending(struct lpfc_hba *phba);\nstatic bool lpfc_sli4_process_missed_mbox_completions(struct lpfc_hba *phba);\nstatic struct lpfc_cqe *lpfc_sli4_cq_get(struct lpfc_queue *q);\nstatic void __lpfc_sli4_consume_cqe(struct lpfc_hba *phba,\n\t\t\t\t    struct lpfc_queue *cq,\n\t\t\t\t    struct lpfc_cqe *cqe);\nstatic uint16_t lpfc_wqe_bpl2sgl(struct lpfc_hba *phba,\n\t\t\t\t struct lpfc_iocbq *pwqeq,\n\t\t\t\t struct lpfc_sglq *sglq);\n\nunion lpfc_wqe128 lpfc_iread_cmd_template;\nunion lpfc_wqe128 lpfc_iwrite_cmd_template;\nunion lpfc_wqe128 lpfc_icmnd_cmd_template;\n\n \nvoid lpfc_wqe_cmd_template(void)\n{\n\tunion lpfc_wqe128 *wqe;\n\n\t \n\twqe = &lpfc_iread_cmd_template;\n\tmemset(wqe, 0, sizeof(union lpfc_wqe128));\n\n\t \n\n\t \n\n\t \n\n\t \n\n\t \n\n\t \n\tbf_set(wqe_cmnd, &wqe->fcp_iread.wqe_com, CMD_FCP_IREAD64_WQE);\n\tbf_set(wqe_pu, &wqe->fcp_iread.wqe_com, PARM_READ_CHECK);\n\tbf_set(wqe_class, &wqe->fcp_iread.wqe_com, CLASS3);\n\tbf_set(wqe_ct, &wqe->fcp_iread.wqe_com, SLI4_CT_RPI);\n\n\t \n\n\t \n\n\t \n\tbf_set(wqe_qosd, &wqe->fcp_iread.wqe_com, 0);\n\tbf_set(wqe_iod, &wqe->fcp_iread.wqe_com, LPFC_WQE_IOD_READ);\n\tbf_set(wqe_lenloc, &wqe->fcp_iread.wqe_com, LPFC_WQE_LENLOC_WORD4);\n\tbf_set(wqe_dbde, &wqe->fcp_iread.wqe_com, 0);\n\tbf_set(wqe_wqes, &wqe->fcp_iread.wqe_com, 1);\n\n\t \n\tbf_set(wqe_cmd_type, &wqe->fcp_iread.wqe_com, COMMAND_DATA_IN);\n\tbf_set(wqe_cqid, &wqe->fcp_iread.wqe_com, LPFC_WQE_CQ_ID_DEFAULT);\n\tbf_set(wqe_pbde, &wqe->fcp_iread.wqe_com, 0);\n\n\t \n\n\t \n\n\t \n\twqe = &lpfc_iwrite_cmd_template;\n\tmemset(wqe, 0, sizeof(union lpfc_wqe128));\n\n\t \n\n\t \n\n\t \n\n\t \n\n\t \n\n\t \n\tbf_set(wqe_cmnd, &wqe->fcp_iwrite.wqe_com, CMD_FCP_IWRITE64_WQE);\n\tbf_set(wqe_pu, &wqe->fcp_iwrite.wqe_com, PARM_READ_CHECK);\n\tbf_set(wqe_class, &wqe->fcp_iwrite.wqe_com, CLASS3);\n\tbf_set(wqe_ct, &wqe->fcp_iwrite.wqe_com, SLI4_CT_RPI);\n\n\t \n\n\t \n\n\t \n\tbf_set(wqe_qosd, &wqe->fcp_iwrite.wqe_com, 0);\n\tbf_set(wqe_iod, &wqe->fcp_iwrite.wqe_com, LPFC_WQE_IOD_WRITE);\n\tbf_set(wqe_lenloc, &wqe->fcp_iwrite.wqe_com, LPFC_WQE_LENLOC_WORD4);\n\tbf_set(wqe_dbde, &wqe->fcp_iwrite.wqe_com, 0);\n\tbf_set(wqe_wqes, &wqe->fcp_iwrite.wqe_com, 1);\n\n\t \n\tbf_set(wqe_cmd_type, &wqe->fcp_iwrite.wqe_com, COMMAND_DATA_OUT);\n\tbf_set(wqe_cqid, &wqe->fcp_iwrite.wqe_com, LPFC_WQE_CQ_ID_DEFAULT);\n\tbf_set(wqe_pbde, &wqe->fcp_iwrite.wqe_com, 0);\n\n\t \n\n\t \n\n\t \n\twqe = &lpfc_icmnd_cmd_template;\n\tmemset(wqe, 0, sizeof(union lpfc_wqe128));\n\n\t \n\n\t \n\n\t \n\n\t \n\n\t \n\tbf_set(wqe_cmnd, &wqe->fcp_icmd.wqe_com, CMD_FCP_ICMND64_WQE);\n\tbf_set(wqe_pu, &wqe->fcp_icmd.wqe_com, 0);\n\tbf_set(wqe_class, &wqe->fcp_icmd.wqe_com, CLASS3);\n\tbf_set(wqe_ct, &wqe->fcp_icmd.wqe_com, SLI4_CT_RPI);\n\n\t \n\n\t \n\n\t \n\tbf_set(wqe_qosd, &wqe->fcp_icmd.wqe_com, 1);\n\tbf_set(wqe_iod, &wqe->fcp_icmd.wqe_com, LPFC_WQE_IOD_NONE);\n\tbf_set(wqe_lenloc, &wqe->fcp_icmd.wqe_com, LPFC_WQE_LENLOC_NONE);\n\tbf_set(wqe_dbde, &wqe->fcp_icmd.wqe_com, 0);\n\tbf_set(wqe_wqes, &wqe->fcp_icmd.wqe_com, 1);\n\n\t \n\tbf_set(wqe_cmd_type, &wqe->fcp_icmd.wqe_com, COMMAND_DATA_IN);\n\tbf_set(wqe_cqid, &wqe->fcp_icmd.wqe_com, LPFC_WQE_CQ_ID_DEFAULT);\n\tbf_set(wqe_pbde, &wqe->fcp_icmd.wqe_com, 0);\n\n\t \n}\n\n#if defined(CONFIG_64BIT) && defined(__LITTLE_ENDIAN)\n \nstatic void\nlpfc_sli4_pcimem_bcopy(void *srcp, void *destp, uint32_t cnt)\n{\n\tuint64_t *src = srcp;\n\tuint64_t *dest = destp;\n\tint i;\n\n\tfor (i = 0; i < (int)cnt; i += sizeof(uint64_t))\n\t\t*dest++ = *src++;\n}\n#else\n#define lpfc_sli4_pcimem_bcopy(a, b, c) lpfc_sli_pcimem_bcopy(a, b, c)\n#endif\n\n \nstatic int\nlpfc_sli4_wq_put(struct lpfc_queue *q, union lpfc_wqe128 *wqe)\n{\n\tunion lpfc_wqe *temp_wqe;\n\tstruct lpfc_register doorbell;\n\tuint32_t host_index;\n\tuint32_t idx;\n\tuint32_t i = 0;\n\tuint8_t *tmp;\n\tu32 if_type;\n\n\t \n\tif (unlikely(!q))\n\t\treturn -ENOMEM;\n\n\ttemp_wqe = lpfc_sli4_qe(q, q->host_index);\n\n\t \n\tidx = ((q->host_index + 1) % q->entry_count);\n\tif (idx == q->hba_index) {\n\t\tq->WQ_overflow++;\n\t\treturn -EBUSY;\n\t}\n\tq->WQ_posted++;\n\t \n\tif (!((q->host_index + 1) % q->notify_interval))\n\t\tbf_set(wqe_wqec, &wqe->generic.wqe_com, 1);\n\telse\n\t\tbf_set(wqe_wqec, &wqe->generic.wqe_com, 0);\n\tif (q->phba->sli3_options & LPFC_SLI4_PHWQ_ENABLED)\n\t\tbf_set(wqe_wqid, &wqe->generic.wqe_com, q->queue_id);\n\tlpfc_sli4_pcimem_bcopy(wqe, temp_wqe, q->entry_size);\n\tif (q->dpp_enable && q->phba->cfg_enable_dpp) {\n\t\t \n\t\ttmp = (uint8_t *)temp_wqe;\n#ifdef __raw_writeq\n\t\tfor (i = 0; i < q->entry_size; i += sizeof(uint64_t))\n\t\t\t__raw_writeq(*((uint64_t *)(tmp + i)),\n\t\t\t\t\tq->dpp_regaddr + i);\n#else\n\t\tfor (i = 0; i < q->entry_size; i += sizeof(uint32_t))\n\t\t\t__raw_writel(*((uint32_t *)(tmp + i)),\n\t\t\t\t\tq->dpp_regaddr + i);\n#endif\n\t}\n\t \n\twmb();\n\n\t \n\thost_index = q->host_index;\n\n\tq->host_index = idx;\n\n\t \n\tdoorbell.word0 = 0;\n\tif (q->db_format == LPFC_DB_LIST_FORMAT) {\n\t\tif (q->dpp_enable && q->phba->cfg_enable_dpp) {\n\t\t\tbf_set(lpfc_if6_wq_db_list_fm_num_posted, &doorbell, 1);\n\t\t\tbf_set(lpfc_if6_wq_db_list_fm_dpp, &doorbell, 1);\n\t\t\tbf_set(lpfc_if6_wq_db_list_fm_dpp_id, &doorbell,\n\t\t\t    q->dpp_id);\n\t\t\tbf_set(lpfc_if6_wq_db_list_fm_id, &doorbell,\n\t\t\t    q->queue_id);\n\t\t} else {\n\t\t\tbf_set(lpfc_wq_db_list_fm_num_posted, &doorbell, 1);\n\t\t\tbf_set(lpfc_wq_db_list_fm_id, &doorbell, q->queue_id);\n\n\t\t\t \n\t\t\tif_type = bf_get(lpfc_sli_intf_if_type,\n\t\t\t\t\t &q->phba->sli4_hba.sli_intf);\n\t\t\tif (if_type != LPFC_SLI_INTF_IF_TYPE_6)\n\t\t\t\tbf_set(lpfc_wq_db_list_fm_index, &doorbell,\n\t\t\t\t       host_index);\n\t\t}\n\t} else if (q->db_format == LPFC_DB_RING_FORMAT) {\n\t\tbf_set(lpfc_wq_db_ring_fm_num_posted, &doorbell, 1);\n\t\tbf_set(lpfc_wq_db_ring_fm_id, &doorbell, q->queue_id);\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\twritel(doorbell.word0, q->db_regaddr);\n\n\treturn 0;\n}\n\n \nstatic void\nlpfc_sli4_wq_release(struct lpfc_queue *q, uint32_t index)\n{\n\t \n\tif (unlikely(!q))\n\t\treturn;\n\n\tq->hba_index = index;\n}\n\n \nstatic uint32_t\nlpfc_sli4_mq_put(struct lpfc_queue *q, struct lpfc_mqe *mqe)\n{\n\tstruct lpfc_mqe *temp_mqe;\n\tstruct lpfc_register doorbell;\n\n\t \n\tif (unlikely(!q))\n\t\treturn -ENOMEM;\n\ttemp_mqe = lpfc_sli4_qe(q, q->host_index);\n\n\t \n\tif (((q->host_index + 1) % q->entry_count) == q->hba_index)\n\t\treturn -ENOMEM;\n\tlpfc_sli4_pcimem_bcopy(mqe, temp_mqe, q->entry_size);\n\t \n\tq->phba->mbox = (MAILBOX_t *)temp_mqe;\n\n\t \n\tq->host_index = ((q->host_index + 1) % q->entry_count);\n\n\t \n\tdoorbell.word0 = 0;\n\tbf_set(lpfc_mq_doorbell_num_posted, &doorbell, 1);\n\tbf_set(lpfc_mq_doorbell_id, &doorbell, q->queue_id);\n\twritel(doorbell.word0, q->phba->sli4_hba.MQDBregaddr);\n\treturn 0;\n}\n\n \nstatic uint32_t\nlpfc_sli4_mq_release(struct lpfc_queue *q)\n{\n\t \n\tif (unlikely(!q))\n\t\treturn 0;\n\n\t \n\tq->phba->mbox = NULL;\n\tq->hba_index = ((q->hba_index + 1) % q->entry_count);\n\treturn 1;\n}\n\n \nstatic struct lpfc_eqe *\nlpfc_sli4_eq_get(struct lpfc_queue *q)\n{\n\tstruct lpfc_eqe *eqe;\n\n\t \n\tif (unlikely(!q))\n\t\treturn NULL;\n\teqe = lpfc_sli4_qe(q, q->host_index);\n\n\t \n\tif (bf_get_le32(lpfc_eqe_valid, eqe) != q->qe_valid)\n\t\treturn NULL;\n\n\t \n\tmb();\n\treturn eqe;\n}\n\n \nvoid\nlpfc_sli4_eq_clr_intr(struct lpfc_queue *q)\n{\n\tstruct lpfc_register doorbell;\n\n\tdoorbell.word0 = 0;\n\tbf_set(lpfc_eqcq_doorbell_eqci, &doorbell, 1);\n\tbf_set(lpfc_eqcq_doorbell_qt, &doorbell, LPFC_QUEUE_TYPE_EVENT);\n\tbf_set(lpfc_eqcq_doorbell_eqid_hi, &doorbell,\n\t\t(q->queue_id >> LPFC_EQID_HI_FIELD_SHIFT));\n\tbf_set(lpfc_eqcq_doorbell_eqid_lo, &doorbell, q->queue_id);\n\twritel(doorbell.word0, q->phba->sli4_hba.EQDBregaddr);\n}\n\n \nvoid\nlpfc_sli4_if6_eq_clr_intr(struct lpfc_queue *q)\n{\n\tstruct lpfc_register doorbell;\n\n\tdoorbell.word0 = 0;\n\tbf_set(lpfc_if6_eq_doorbell_eqid, &doorbell, q->queue_id);\n\twritel(doorbell.word0, q->phba->sli4_hba.EQDBregaddr);\n}\n\n \nvoid\nlpfc_sli4_write_eq_db(struct lpfc_hba *phba, struct lpfc_queue *q,\n\t\t     uint32_t count, bool arm)\n{\n\tstruct lpfc_register doorbell;\n\n\t \n\tif (unlikely(!q || (count == 0 && !arm)))\n\t\treturn;\n\n\t \n\tdoorbell.word0 = 0;\n\tif (arm) {\n\t\tbf_set(lpfc_eqcq_doorbell_arm, &doorbell, 1);\n\t\tbf_set(lpfc_eqcq_doorbell_eqci, &doorbell, 1);\n\t}\n\tbf_set(lpfc_eqcq_doorbell_num_released, &doorbell, count);\n\tbf_set(lpfc_eqcq_doorbell_qt, &doorbell, LPFC_QUEUE_TYPE_EVENT);\n\tbf_set(lpfc_eqcq_doorbell_eqid_hi, &doorbell,\n\t\t\t(q->queue_id >> LPFC_EQID_HI_FIELD_SHIFT));\n\tbf_set(lpfc_eqcq_doorbell_eqid_lo, &doorbell, q->queue_id);\n\twritel(doorbell.word0, q->phba->sli4_hba.EQDBregaddr);\n\t \n\tif ((q->phba->intr_type == INTx) && (arm == LPFC_QUEUE_REARM))\n\t\treadl(q->phba->sli4_hba.EQDBregaddr);\n}\n\n \nvoid\nlpfc_sli4_if6_write_eq_db(struct lpfc_hba *phba, struct lpfc_queue *q,\n\t\t\t  uint32_t count, bool arm)\n{\n\tstruct lpfc_register doorbell;\n\n\t \n\tif (unlikely(!q || (count == 0 && !arm)))\n\t\treturn;\n\n\t \n\tdoorbell.word0 = 0;\n\tif (arm)\n\t\tbf_set(lpfc_if6_eq_doorbell_arm, &doorbell, 1);\n\tbf_set(lpfc_if6_eq_doorbell_num_released, &doorbell, count);\n\tbf_set(lpfc_if6_eq_doorbell_eqid, &doorbell, q->queue_id);\n\twritel(doorbell.word0, q->phba->sli4_hba.EQDBregaddr);\n\t \n\tif ((q->phba->intr_type == INTx) && (arm == LPFC_QUEUE_REARM))\n\t\treadl(q->phba->sli4_hba.EQDBregaddr);\n}\n\nstatic void\n__lpfc_sli4_consume_eqe(struct lpfc_hba *phba, struct lpfc_queue *eq,\n\t\t\tstruct lpfc_eqe *eqe)\n{\n\tif (!phba->sli4_hba.pc_sli4_params.eqav)\n\t\tbf_set_le32(lpfc_eqe_valid, eqe, 0);\n\n\teq->host_index = ((eq->host_index + 1) % eq->entry_count);\n\n\t \n\tif (phba->sli4_hba.pc_sli4_params.eqav && !eq->host_index)\n\t\teq->qe_valid = (eq->qe_valid) ? 0 : 1;\n}\n\nstatic void\nlpfc_sli4_eqcq_flush(struct lpfc_hba *phba, struct lpfc_queue *eq)\n{\n\tstruct lpfc_eqe *eqe = NULL;\n\tu32 eq_count = 0, cq_count = 0;\n\tstruct lpfc_cqe *cqe = NULL;\n\tstruct lpfc_queue *cq = NULL, *childq = NULL;\n\tint cqid = 0;\n\n\t \n\teqe = lpfc_sli4_eq_get(eq);\n\twhile (eqe) {\n\t\t \n\t\tcqid = bf_get_le32(lpfc_eqe_resource_id, eqe);\n\t\tcq = NULL;\n\n\t\tlist_for_each_entry(childq, &eq->child_list, list) {\n\t\t\tif (childq->queue_id == cqid) {\n\t\t\t\tcq = childq;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t \n\t\tif (cq) {\n\t\t\tcqe = lpfc_sli4_cq_get(cq);\n\t\t\twhile (cqe) {\n\t\t\t\t__lpfc_sli4_consume_cqe(phba, cq, cqe);\n\t\t\t\tcq_count++;\n\t\t\t\tcqe = lpfc_sli4_cq_get(cq);\n\t\t\t}\n\t\t\t \n\t\t\tphba->sli4_hba.sli4_write_cq_db(phba, cq, cq_count,\n\t\t\t    LPFC_QUEUE_REARM);\n\t\t\tcq_count = 0;\n\t\t}\n\t\t__lpfc_sli4_consume_eqe(phba, eq, eqe);\n\t\teq_count++;\n\t\teqe = lpfc_sli4_eq_get(eq);\n\t}\n\n\t \n\tphba->sli4_hba.sli4_write_eq_db(phba, eq, eq_count, LPFC_QUEUE_REARM);\n}\n\nstatic int\nlpfc_sli4_process_eq(struct lpfc_hba *phba, struct lpfc_queue *eq,\n\t\t     u8 rearm, enum lpfc_poll_mode poll_mode)\n{\n\tstruct lpfc_eqe *eqe;\n\tint count = 0, consumed = 0;\n\n\tif (cmpxchg(&eq->queue_claimed, 0, 1) != 0)\n\t\tgoto rearm_and_exit;\n\n\teqe = lpfc_sli4_eq_get(eq);\n\twhile (eqe) {\n\t\tlpfc_sli4_hba_handle_eqe(phba, eq, eqe, poll_mode);\n\t\t__lpfc_sli4_consume_eqe(phba, eq, eqe);\n\n\t\tconsumed++;\n\t\tif (!(++count % eq->max_proc_limit))\n\t\t\tbreak;\n\n\t\tif (!(count % eq->notify_interval)) {\n\t\t\tphba->sli4_hba.sli4_write_eq_db(phba, eq, consumed,\n\t\t\t\t\t\t\tLPFC_QUEUE_NOARM);\n\t\t\tconsumed = 0;\n\t\t}\n\n\t\teqe = lpfc_sli4_eq_get(eq);\n\t}\n\teq->EQ_processed += count;\n\n\t \n\tif (count > eq->EQ_max_eqe)\n\t\teq->EQ_max_eqe = count;\n\n\txchg(&eq->queue_claimed, 0);\n\nrearm_and_exit:\n\t \n\tphba->sli4_hba.sli4_write_eq_db(phba, eq, consumed, rearm);\n\n\treturn count;\n}\n\n \nstatic struct lpfc_cqe *\nlpfc_sli4_cq_get(struct lpfc_queue *q)\n{\n\tstruct lpfc_cqe *cqe;\n\n\t \n\tif (unlikely(!q))\n\t\treturn NULL;\n\tcqe = lpfc_sli4_qe(q, q->host_index);\n\n\t \n\tif (bf_get_le32(lpfc_cqe_valid, cqe) != q->qe_valid)\n\t\treturn NULL;\n\n\t \n\tmb();\n\treturn cqe;\n}\n\nstatic void\n__lpfc_sli4_consume_cqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\t\t\tstruct lpfc_cqe *cqe)\n{\n\tif (!phba->sli4_hba.pc_sli4_params.cqav)\n\t\tbf_set_le32(lpfc_cqe_valid, cqe, 0);\n\n\tcq->host_index = ((cq->host_index + 1) % cq->entry_count);\n\n\t \n\tif (phba->sli4_hba.pc_sli4_params.cqav && !cq->host_index)\n\t\tcq->qe_valid = (cq->qe_valid) ? 0 : 1;\n}\n\n \nvoid\nlpfc_sli4_write_cq_db(struct lpfc_hba *phba, struct lpfc_queue *q,\n\t\t     uint32_t count, bool arm)\n{\n\tstruct lpfc_register doorbell;\n\n\t \n\tif (unlikely(!q || (count == 0 && !arm)))\n\t\treturn;\n\n\t \n\tdoorbell.word0 = 0;\n\tif (arm)\n\t\tbf_set(lpfc_eqcq_doorbell_arm, &doorbell, 1);\n\tbf_set(lpfc_eqcq_doorbell_num_released, &doorbell, count);\n\tbf_set(lpfc_eqcq_doorbell_qt, &doorbell, LPFC_QUEUE_TYPE_COMPLETION);\n\tbf_set(lpfc_eqcq_doorbell_cqid_hi, &doorbell,\n\t\t\t(q->queue_id >> LPFC_CQID_HI_FIELD_SHIFT));\n\tbf_set(lpfc_eqcq_doorbell_cqid_lo, &doorbell, q->queue_id);\n\twritel(doorbell.word0, q->phba->sli4_hba.CQDBregaddr);\n}\n\n \nvoid\nlpfc_sli4_if6_write_cq_db(struct lpfc_hba *phba, struct lpfc_queue *q,\n\t\t\t uint32_t count, bool arm)\n{\n\tstruct lpfc_register doorbell;\n\n\t \n\tif (unlikely(!q || (count == 0 && !arm)))\n\t\treturn;\n\n\t \n\tdoorbell.word0 = 0;\n\tif (arm)\n\t\tbf_set(lpfc_if6_cq_doorbell_arm, &doorbell, 1);\n\tbf_set(lpfc_if6_cq_doorbell_num_released, &doorbell, count);\n\tbf_set(lpfc_if6_cq_doorbell_cqid, &doorbell, q->queue_id);\n\twritel(doorbell.word0, q->phba->sli4_hba.CQDBregaddr);\n}\n\n \nint\nlpfc_sli4_rq_put(struct lpfc_queue *hq, struct lpfc_queue *dq,\n\t\t struct lpfc_rqe *hrqe, struct lpfc_rqe *drqe)\n{\n\tstruct lpfc_rqe *temp_hrqe;\n\tstruct lpfc_rqe *temp_drqe;\n\tstruct lpfc_register doorbell;\n\tint hq_put_index;\n\tint dq_put_index;\n\n\t \n\tif (unlikely(!hq) || unlikely(!dq))\n\t\treturn -ENOMEM;\n\thq_put_index = hq->host_index;\n\tdq_put_index = dq->host_index;\n\ttemp_hrqe = lpfc_sli4_qe(hq, hq_put_index);\n\ttemp_drqe = lpfc_sli4_qe(dq, dq_put_index);\n\n\tif (hq->type != LPFC_HRQ || dq->type != LPFC_DRQ)\n\t\treturn -EINVAL;\n\tif (hq_put_index != dq_put_index)\n\t\treturn -EINVAL;\n\t \n\tif (((hq_put_index + 1) % hq->entry_count) == hq->hba_index)\n\t\treturn -EBUSY;\n\tlpfc_sli4_pcimem_bcopy(hrqe, temp_hrqe, hq->entry_size);\n\tlpfc_sli4_pcimem_bcopy(drqe, temp_drqe, dq->entry_size);\n\n\t \n\thq->host_index = ((hq_put_index + 1) % hq->entry_count);\n\tdq->host_index = ((dq_put_index + 1) % dq->entry_count);\n\thq->RQ_buf_posted++;\n\n\t \n\tif (!(hq->host_index % hq->notify_interval)) {\n\t\tdoorbell.word0 = 0;\n\t\tif (hq->db_format == LPFC_DB_RING_FORMAT) {\n\t\t\tbf_set(lpfc_rq_db_ring_fm_num_posted, &doorbell,\n\t\t\t       hq->notify_interval);\n\t\t\tbf_set(lpfc_rq_db_ring_fm_id, &doorbell, hq->queue_id);\n\t\t} else if (hq->db_format == LPFC_DB_LIST_FORMAT) {\n\t\t\tbf_set(lpfc_rq_db_list_fm_num_posted, &doorbell,\n\t\t\t       hq->notify_interval);\n\t\t\tbf_set(lpfc_rq_db_list_fm_index, &doorbell,\n\t\t\t       hq->host_index);\n\t\t\tbf_set(lpfc_rq_db_list_fm_id, &doorbell, hq->queue_id);\n\t\t} else {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\twritel(doorbell.word0, hq->db_regaddr);\n\t}\n\treturn hq_put_index;\n}\n\n \nstatic uint32_t\nlpfc_sli4_rq_release(struct lpfc_queue *hq, struct lpfc_queue *dq)\n{\n\t \n\tif (unlikely(!hq) || unlikely(!dq))\n\t\treturn 0;\n\n\tif ((hq->type != LPFC_HRQ) || (dq->type != LPFC_DRQ))\n\t\treturn 0;\n\thq->hba_index = ((hq->hba_index + 1) % hq->entry_count);\n\tdq->hba_index = ((dq->hba_index + 1) % dq->entry_count);\n\treturn 1;\n}\n\n \nstatic inline IOCB_t *\nlpfc_cmd_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\n{\n\treturn (IOCB_t *) (((char *) pring->sli.sli3.cmdringaddr) +\n\t\t\t   pring->sli.sli3.cmdidx * phba->iocb_cmd_size);\n}\n\n \nstatic inline IOCB_t *\nlpfc_resp_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\n{\n\treturn (IOCB_t *) (((char *) pring->sli.sli3.rspringaddr) +\n\t\t\t   pring->sli.sli3.rspidx * phba->iocb_rsp_size);\n}\n\n \nstruct lpfc_iocbq *\n__lpfc_sli_get_iocbq(struct lpfc_hba *phba)\n{\n\tstruct list_head *lpfc_iocb_list = &phba->lpfc_iocb_list;\n\tstruct lpfc_iocbq * iocbq = NULL;\n\n\tlockdep_assert_held(&phba->hbalock);\n\n\tlist_remove_head(lpfc_iocb_list, iocbq, struct lpfc_iocbq, list);\n\tif (iocbq)\n\t\tphba->iocb_cnt++;\n\tif (phba->iocb_cnt > phba->iocb_max)\n\t\tphba->iocb_max = phba->iocb_cnt;\n\treturn iocbq;\n}\n\n \nstruct lpfc_sglq *\n__lpfc_clear_active_sglq(struct lpfc_hba *phba, uint16_t xritag)\n{\n\tstruct lpfc_sglq *sglq;\n\n\tsglq = phba->sli4_hba.lpfc_sglq_active_list[xritag];\n\tphba->sli4_hba.lpfc_sglq_active_list[xritag] = NULL;\n\treturn sglq;\n}\n\n \nstruct lpfc_sglq *\n__lpfc_get_active_sglq(struct lpfc_hba *phba, uint16_t xritag)\n{\n\tstruct lpfc_sglq *sglq;\n\n\tsglq =  phba->sli4_hba.lpfc_sglq_active_list[xritag];\n\treturn sglq;\n}\n\n \nvoid\nlpfc_clr_rrq_active(struct lpfc_hba *phba,\n\t\t    uint16_t xritag,\n\t\t    struct lpfc_node_rrq *rrq)\n{\n\tstruct lpfc_nodelist *ndlp = NULL;\n\n\t \n\tif (rrq->vport)\n\t\tndlp = lpfc_findnode_did(rrq->vport, rrq->nlp_DID);\n\n\tif (!ndlp)\n\t\tgoto out;\n\n\tif (test_and_clear_bit(xritag, ndlp->active_rrqs_xri_bitmap)) {\n\t\trrq->send_rrq = 0;\n\t\trrq->xritag = 0;\n\t\trrq->rrq_stop_time = 0;\n\t}\nout:\n\tmempool_free(rrq, phba->rrq_pool);\n}\n\n \nvoid\nlpfc_handle_rrq_active(struct lpfc_hba *phba)\n{\n\tstruct lpfc_node_rrq *rrq;\n\tstruct lpfc_node_rrq *nextrrq;\n\tunsigned long next_time;\n\tunsigned long iflags;\n\tLIST_HEAD(send_rrq);\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tphba->hba_flag &= ~HBA_RRQ_ACTIVE;\n\tnext_time = jiffies + msecs_to_jiffies(1000 * (phba->fc_ratov + 1));\n\tlist_for_each_entry_safe(rrq, nextrrq,\n\t\t\t\t &phba->active_rrq_list, list) {\n\t\tif (time_after(jiffies, rrq->rrq_stop_time))\n\t\t\tlist_move(&rrq->list, &send_rrq);\n\t\telse if (time_before(rrq->rrq_stop_time, next_time))\n\t\t\tnext_time = rrq->rrq_stop_time;\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\tif ((!list_empty(&phba->active_rrq_list)) &&\n\t    (!(phba->pport->load_flag & FC_UNLOADING)))\n\t\tmod_timer(&phba->rrq_tmr, next_time);\n\tlist_for_each_entry_safe(rrq, nextrrq, &send_rrq, list) {\n\t\tlist_del(&rrq->list);\n\t\tif (!rrq->send_rrq) {\n\t\t\t \n\t\t\tlpfc_clr_rrq_active(phba, rrq->xritag, rrq);\n\t\t} else if (lpfc_send_rrq(phba, rrq)) {\n\t\t\t \n\t\t\tlpfc_clr_rrq_active(phba, rrq->xritag,\n\t\t\t\t\t    rrq);\n\t\t}\n\t}\n}\n\n \nstruct lpfc_node_rrq *\nlpfc_get_active_rrq(struct lpfc_vport *vport, uint16_t xri, uint32_t did)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tstruct lpfc_node_rrq *rrq;\n\tstruct lpfc_node_rrq *nextrrq;\n\tunsigned long iflags;\n\n\tif (phba->sli_rev != LPFC_SLI_REV4)\n\t\treturn NULL;\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tlist_for_each_entry_safe(rrq, nextrrq, &phba->active_rrq_list, list) {\n\t\tif (rrq->vport == vport && rrq->xritag == xri &&\n\t\t\t\trrq->nlp_DID == did){\n\t\t\tlist_del(&rrq->list);\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\t\treturn rrq;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn NULL;\n}\n\n \nvoid\nlpfc_cleanup_vports_rrqs(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\n\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tstruct lpfc_node_rrq *rrq;\n\tstruct lpfc_node_rrq *nextrrq;\n\tunsigned long iflags;\n\tLIST_HEAD(rrq_list);\n\n\tif (phba->sli_rev != LPFC_SLI_REV4)\n\t\treturn;\n\tif (!ndlp) {\n\t\tlpfc_sli4_vport_delete_els_xri_aborted(vport);\n\t\tlpfc_sli4_vport_delete_fcp_xri_aborted(vport);\n\t}\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tlist_for_each_entry_safe(rrq, nextrrq, &phba->active_rrq_list, list) {\n\t\tif (rrq->vport != vport)\n\t\t\tcontinue;\n\n\t\tif (!ndlp || ndlp == lpfc_findnode_did(vport, rrq->nlp_DID))\n\t\t\tlist_move(&rrq->list, &rrq_list);\n\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\tlist_for_each_entry_safe(rrq, nextrrq, &rrq_list, list) {\n\t\tlist_del(&rrq->list);\n\t\tlpfc_clr_rrq_active(phba, rrq->xritag, rrq);\n\t}\n}\n\n \nint\nlpfc_test_rrq_active(struct lpfc_hba *phba, struct lpfc_nodelist *ndlp,\n\t\t\tuint16_t  xritag)\n{\n\tif (!ndlp)\n\t\treturn 0;\n\tif (!ndlp->active_rrqs_xri_bitmap)\n\t\treturn 0;\n\tif (test_bit(xritag, ndlp->active_rrqs_xri_bitmap))\n\t\treturn 1;\n\telse\n\t\treturn 0;\n}\n\n \nint\nlpfc_set_rrq_active(struct lpfc_hba *phba, struct lpfc_nodelist *ndlp,\n\t\t    uint16_t xritag, uint16_t rxid, uint16_t send_rrq)\n{\n\tunsigned long iflags;\n\tstruct lpfc_node_rrq *rrq;\n\tint empty;\n\n\tif (!ndlp)\n\t\treturn -EINVAL;\n\n\tif (!phba->cfg_enable_rrq)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tif (phba->pport->load_flag & FC_UNLOADING) {\n\t\tphba->hba_flag &= ~HBA_RRQ_ACTIVE;\n\t\tgoto out;\n\t}\n\n\tif (ndlp->vport && (ndlp->vport->load_flag & FC_UNLOADING))\n\t\tgoto out;\n\n\tif (!ndlp->active_rrqs_xri_bitmap)\n\t\tgoto out;\n\n\tif (test_and_set_bit(xritag, ndlp->active_rrqs_xri_bitmap))\n\t\tgoto out;\n\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\trrq = mempool_alloc(phba->rrq_pool, GFP_ATOMIC);\n\tif (!rrq) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3155 Unable to allocate RRQ xri:0x%x rxid:0x%x\"\n\t\t\t\t\" DID:0x%x Send:%d\\n\",\n\t\t\t\txritag, rxid, ndlp->nlp_DID, send_rrq);\n\t\treturn -EINVAL;\n\t}\n\tif (phba->cfg_enable_rrq == 1)\n\t\trrq->send_rrq = send_rrq;\n\telse\n\t\trrq->send_rrq = 0;\n\trrq->xritag = xritag;\n\trrq->rrq_stop_time = jiffies +\n\t\t\t\tmsecs_to_jiffies(1000 * (phba->fc_ratov + 1));\n\trrq->nlp_DID = ndlp->nlp_DID;\n\trrq->vport = ndlp->vport;\n\trrq->rxid = rxid;\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tempty = list_empty(&phba->active_rrq_list);\n\tlist_add_tail(&rrq->list, &phba->active_rrq_list);\n\tphba->hba_flag |= HBA_RRQ_ACTIVE;\n\tif (empty)\n\t\tlpfc_worker_wake_up(phba);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn 0;\nout:\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2921 Can't set rrq active xri:0x%x rxid:0x%x\"\n\t\t\t\" DID:0x%x Send:%d\\n\",\n\t\t\txritag, rxid, ndlp->nlp_DID, send_rrq);\n\treturn -EINVAL;\n}\n\n \nstatic struct lpfc_sglq *\n__lpfc_sli_get_els_sglq(struct lpfc_hba *phba, struct lpfc_iocbq *piocbq)\n{\n\tstruct list_head *lpfc_els_sgl_list = &phba->sli4_hba.lpfc_els_sgl_list;\n\tstruct lpfc_sglq *sglq = NULL;\n\tstruct lpfc_sglq *start_sglq = NULL;\n\tstruct lpfc_io_buf *lpfc_cmd;\n\tstruct lpfc_nodelist *ndlp;\n\tint found = 0;\n\tu8 cmnd;\n\n\tcmnd = get_job_cmnd(phba, piocbq);\n\n\tif (piocbq->cmd_flag & LPFC_IO_FCP) {\n\t\tlpfc_cmd = piocbq->io_buf;\n\t\tndlp = lpfc_cmd->rdata->pnode;\n\t} else  if ((cmnd == CMD_GEN_REQUEST64_CR) &&\n\t\t\t!(piocbq->cmd_flag & LPFC_IO_LIBDFC)) {\n\t\tndlp = piocbq->ndlp;\n\t} else  if (piocbq->cmd_flag & LPFC_IO_LIBDFC) {\n\t\tif (piocbq->cmd_flag & LPFC_IO_LOOPBACK)\n\t\t\tndlp = NULL;\n\t\telse\n\t\t\tndlp = piocbq->ndlp;\n\t} else {\n\t\tndlp = piocbq->ndlp;\n\t}\n\n\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\tlist_remove_head(lpfc_els_sgl_list, sglq, struct lpfc_sglq, list);\n\tstart_sglq = sglq;\n\twhile (!found) {\n\t\tif (!sglq)\n\t\t\tbreak;\n\t\tif (ndlp && ndlp->active_rrqs_xri_bitmap &&\n\t\t    test_bit(sglq->sli4_lxritag,\n\t\t    ndlp->active_rrqs_xri_bitmap)) {\n\t\t\t \n\t\t\tlist_add_tail(&sglq->list, lpfc_els_sgl_list);\n\t\t\tsglq = NULL;\n\t\t\tlist_remove_head(lpfc_els_sgl_list, sglq,\n\t\t\t\t\t\tstruct lpfc_sglq, list);\n\t\t\tif (sglq == start_sglq) {\n\t\t\t\tlist_add_tail(&sglq->list, lpfc_els_sgl_list);\n\t\t\t\tsglq = NULL;\n\t\t\t\tbreak;\n\t\t\t} else\n\t\t\t\tcontinue;\n\t\t}\n\t\tsglq->ndlp = ndlp;\n\t\tfound = 1;\n\t\tphba->sli4_hba.lpfc_sglq_active_list[sglq->sli4_lxritag] = sglq;\n\t\tsglq->state = SGL_ALLOCATED;\n\t}\n\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\treturn sglq;\n}\n\n \nstruct lpfc_sglq *\n__lpfc_sli_get_nvmet_sglq(struct lpfc_hba *phba, struct lpfc_iocbq *piocbq)\n{\n\tstruct list_head *lpfc_nvmet_sgl_list;\n\tstruct lpfc_sglq *sglq = NULL;\n\n\tlpfc_nvmet_sgl_list = &phba->sli4_hba.lpfc_nvmet_sgl_list;\n\n\tlockdep_assert_held(&phba->sli4_hba.sgl_list_lock);\n\n\tlist_remove_head(lpfc_nvmet_sgl_list, sglq, struct lpfc_sglq, list);\n\tif (!sglq)\n\t\treturn NULL;\n\tphba->sli4_hba.lpfc_sglq_active_list[sglq->sli4_lxritag] = sglq;\n\tsglq->state = SGL_ALLOCATED;\n\treturn sglq;\n}\n\n \nstruct lpfc_iocbq *\nlpfc_sli_get_iocbq(struct lpfc_hba *phba)\n{\n\tstruct lpfc_iocbq * iocbq = NULL;\n\tunsigned long iflags;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tiocbq = __lpfc_sli_get_iocbq(phba);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn iocbq;\n}\n\n \nstatic void\n__lpfc_sli_release_iocbq_s4(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\n{\n\tstruct lpfc_sglq *sglq;\n\tunsigned long iflag = 0;\n\tstruct lpfc_sli_ring *pring;\n\n\tif (iocbq->sli4_xritag == NO_XRI)\n\t\tsglq = NULL;\n\telse\n\t\tsglq = __lpfc_clear_active_sglq(phba, iocbq->sli4_lxritag);\n\n\n\tif (sglq)  {\n\t\tif (iocbq->cmd_flag & LPFC_IO_NVMET) {\n\t\t\tspin_lock_irqsave(&phba->sli4_hba.sgl_list_lock,\n\t\t\t\t\t  iflag);\n\t\t\tsglq->state = SGL_FREED;\n\t\t\tsglq->ndlp = NULL;\n\t\t\tlist_add_tail(&sglq->list,\n\t\t\t\t      &phba->sli4_hba.lpfc_nvmet_sgl_list);\n\t\t\tspin_unlock_irqrestore(\n\t\t\t\t&phba->sli4_hba.sgl_list_lock, iflag);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif ((iocbq->cmd_flag & LPFC_EXCHANGE_BUSY) &&\n\t\t    (!(unlikely(pci_channel_offline(phba->pcidev)))) &&\n\t\t    sglq->state != SGL_XRI_ABORTED) {\n\t\t\tspin_lock_irqsave(&phba->sli4_hba.sgl_list_lock,\n\t\t\t\t\t  iflag);\n\n\t\t\t \n\t\t\tif (sglq->ndlp && !lpfc_nlp_get(sglq->ndlp))\n\t\t\t\tsglq->ndlp = NULL;\n\n\t\t\tlist_add(&sglq->list,\n\t\t\t\t &phba->sli4_hba.lpfc_abts_els_sgl_list);\n\t\t\tspin_unlock_irqrestore(\n\t\t\t\t&phba->sli4_hba.sgl_list_lock, iflag);\n\t\t} else {\n\t\t\tspin_lock_irqsave(&phba->sli4_hba.sgl_list_lock,\n\t\t\t\t\t  iflag);\n\t\t\tsglq->state = SGL_FREED;\n\t\t\tsglq->ndlp = NULL;\n\t\t\tlist_add_tail(&sglq->list,\n\t\t\t\t      &phba->sli4_hba.lpfc_els_sgl_list);\n\t\t\tspin_unlock_irqrestore(\n\t\t\t\t&phba->sli4_hba.sgl_list_lock, iflag);\n\t\t\tpring = lpfc_phba_elsring(phba);\n\t\t\t \n\t\t\tif (pring && (!list_empty(&pring->txq)))\n\t\t\t\tlpfc_worker_wake_up(phba);\n\t\t}\n\t}\n\nout:\n\t \n\tmemset_startat(iocbq, 0, wqe);\n\tiocbq->sli4_lxritag = NO_XRI;\n\tiocbq->sli4_xritag = NO_XRI;\n\tiocbq->cmd_flag &= ~(LPFC_IO_NVME | LPFC_IO_NVMET | LPFC_IO_CMF |\n\t\t\t      LPFC_IO_NVME_LS);\n\tlist_add_tail(&iocbq->list, &phba->lpfc_iocb_list);\n}\n\n\n \nstatic void\n__lpfc_sli_release_iocbq_s3(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\n{\n\n\t \n\tmemset_startat(iocbq, 0, iocb);\n\tiocbq->sli4_xritag = NO_XRI;\n\tlist_add_tail(&iocbq->list, &phba->lpfc_iocb_list);\n}\n\n \nstatic void\n__lpfc_sli_release_iocbq(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\n{\n\tlockdep_assert_held(&phba->hbalock);\n\n\tphba->__lpfc_sli_release_iocbq(phba, iocbq);\n\tphba->iocb_cnt--;\n}\n\n \nvoid\nlpfc_sli_release_iocbq(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\n{\n\tunsigned long iflags;\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t__lpfc_sli_release_iocbq(phba, iocbq);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n}\n\n \nvoid\nlpfc_sli_cancel_iocbs(struct lpfc_hba *phba, struct list_head *iocblist,\n\t\t      uint32_t ulpstatus, uint32_t ulpWord4)\n{\n\tstruct lpfc_iocbq *piocb;\n\n\twhile (!list_empty(iocblist)) {\n\t\tlist_remove_head(iocblist, piocb, struct lpfc_iocbq, list);\n\t\tif (piocb->cmd_cmpl) {\n\t\t\tif (piocb->cmd_flag & LPFC_IO_NVME) {\n\t\t\t\tlpfc_nvme_cancel_iocb(phba, piocb,\n\t\t\t\t\t\t      ulpstatus, ulpWord4);\n\t\t\t} else {\n\t\t\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\t\t\tbf_set(lpfc_wcqe_c_status,\n\t\t\t\t\t       &piocb->wcqe_cmpl, ulpstatus);\n\t\t\t\t\tpiocb->wcqe_cmpl.parameter = ulpWord4;\n\t\t\t\t} else {\n\t\t\t\t\tpiocb->iocb.ulpStatus = ulpstatus;\n\t\t\t\t\tpiocb->iocb.un.ulpWord[4] = ulpWord4;\n\t\t\t\t}\n\t\t\t\t(piocb->cmd_cmpl) (phba, piocb, piocb);\n\t\t\t}\n\t\t} else {\n\t\t\tlpfc_sli_release_iocbq(phba, piocb);\n\t\t}\n\t}\n\treturn;\n}\n\n \nstatic lpfc_iocb_type\nlpfc_sli_iocb_cmd_type(uint8_t iocb_cmnd)\n{\n\tlpfc_iocb_type type = LPFC_UNKNOWN_IOCB;\n\n\tif (iocb_cmnd > CMD_MAX_IOCB_CMD)\n\t\treturn 0;\n\n\tswitch (iocb_cmnd) {\n\tcase CMD_XMIT_SEQUENCE_CR:\n\tcase CMD_XMIT_SEQUENCE_CX:\n\tcase CMD_XMIT_BCAST_CN:\n\tcase CMD_XMIT_BCAST_CX:\n\tcase CMD_ELS_REQUEST_CR:\n\tcase CMD_ELS_REQUEST_CX:\n\tcase CMD_CREATE_XRI_CR:\n\tcase CMD_CREATE_XRI_CX:\n\tcase CMD_GET_RPI_CN:\n\tcase CMD_XMIT_ELS_RSP_CX:\n\tcase CMD_GET_RPI_CR:\n\tcase CMD_FCP_IWRITE_CR:\n\tcase CMD_FCP_IWRITE_CX:\n\tcase CMD_FCP_IREAD_CR:\n\tcase CMD_FCP_IREAD_CX:\n\tcase CMD_FCP_ICMND_CR:\n\tcase CMD_FCP_ICMND_CX:\n\tcase CMD_FCP_TSEND_CX:\n\tcase CMD_FCP_TRSP_CX:\n\tcase CMD_FCP_TRECEIVE_CX:\n\tcase CMD_FCP_AUTO_TRSP_CX:\n\tcase CMD_ADAPTER_MSG:\n\tcase CMD_ADAPTER_DUMP:\n\tcase CMD_XMIT_SEQUENCE64_CR:\n\tcase CMD_XMIT_SEQUENCE64_CX:\n\tcase CMD_XMIT_BCAST64_CN:\n\tcase CMD_XMIT_BCAST64_CX:\n\tcase CMD_ELS_REQUEST64_CR:\n\tcase CMD_ELS_REQUEST64_CX:\n\tcase CMD_FCP_IWRITE64_CR:\n\tcase CMD_FCP_IWRITE64_CX:\n\tcase CMD_FCP_IREAD64_CR:\n\tcase CMD_FCP_IREAD64_CX:\n\tcase CMD_FCP_ICMND64_CR:\n\tcase CMD_FCP_ICMND64_CX:\n\tcase CMD_FCP_TSEND64_CX:\n\tcase CMD_FCP_TRSP64_CX:\n\tcase CMD_FCP_TRECEIVE64_CX:\n\tcase CMD_GEN_REQUEST64_CR:\n\tcase CMD_GEN_REQUEST64_CX:\n\tcase CMD_XMIT_ELS_RSP64_CX:\n\tcase DSSCMD_IWRITE64_CR:\n\tcase DSSCMD_IWRITE64_CX:\n\tcase DSSCMD_IREAD64_CR:\n\tcase DSSCMD_IREAD64_CX:\n\tcase CMD_SEND_FRAME:\n\t\ttype = LPFC_SOL_IOCB;\n\t\tbreak;\n\tcase CMD_ABORT_XRI_CN:\n\tcase CMD_ABORT_XRI_CX:\n\tcase CMD_CLOSE_XRI_CN:\n\tcase CMD_CLOSE_XRI_CX:\n\tcase CMD_XRI_ABORTED_CX:\n\tcase CMD_ABORT_MXRI64_CN:\n\tcase CMD_XMIT_BLS_RSP64_CX:\n\t\ttype = LPFC_ABORT_IOCB;\n\t\tbreak;\n\tcase CMD_RCV_SEQUENCE_CX:\n\tcase CMD_RCV_ELS_REQ_CX:\n\tcase CMD_RCV_SEQUENCE64_CX:\n\tcase CMD_RCV_ELS_REQ64_CX:\n\tcase CMD_ASYNC_STATUS:\n\tcase CMD_IOCB_RCV_SEQ64_CX:\n\tcase CMD_IOCB_RCV_ELS64_CX:\n\tcase CMD_IOCB_RCV_CONT64_CX:\n\tcase CMD_IOCB_RET_XRI64_CX:\n\t\ttype = LPFC_UNSOL_IOCB;\n\t\tbreak;\n\tcase CMD_IOCB_XMIT_MSEQ64_CR:\n\tcase CMD_IOCB_XMIT_MSEQ64_CX:\n\tcase CMD_IOCB_RCV_SEQ_LIST64_CX:\n\tcase CMD_IOCB_RCV_ELS_LIST64_CX:\n\tcase CMD_IOCB_CLOSE_EXTENDED_CN:\n\tcase CMD_IOCB_ABORT_EXTENDED_CN:\n\tcase CMD_IOCB_RET_HBQE64_CN:\n\tcase CMD_IOCB_FCP_IBIDIR64_CR:\n\tcase CMD_IOCB_FCP_IBIDIR64_CX:\n\tcase CMD_IOCB_FCP_ITASKMGT64_CX:\n\tcase CMD_IOCB_LOGENTRY_CN:\n\tcase CMD_IOCB_LOGENTRY_ASYNC_CN:\n\t\tprintk(\"%s - Unhandled SLI-3 Command x%x\\n\",\n\t\t\t\t__func__, iocb_cmnd);\n\t\ttype = LPFC_UNKNOWN_IOCB;\n\t\tbreak;\n\tdefault:\n\t\ttype = LPFC_UNKNOWN_IOCB;\n\t\tbreak;\n\t}\n\n\treturn type;\n}\n\n \nstatic int\nlpfc_sli_ring_map(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *pmbox;\n\tint i, rc, ret = 0;\n\n\tpmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb)\n\t\treturn -ENOMEM;\n\tpmbox = &pmb->u.mb;\n\tphba->link_state = LPFC_INIT_MBX_CMDS;\n\tfor (i = 0; i < psli->num_rings; i++) {\n\t\tlpfc_config_ring(phba, i, pmb);\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0446 Adapter failed to init (%d), \"\n\t\t\t\t\t\"mbxCmd x%x CFG_RING, mbxStatus x%x, \"\n\t\t\t\t\t\"ring %d\\n\",\n\t\t\t\t\trc, pmbox->mbxCommand,\n\t\t\t\t\tpmbox->mbxStatus, i);\n\t\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\t\tret = -ENXIO;\n\t\t\tbreak;\n\t\t}\n\t}\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\treturn ret;\n}\n\n \nstatic int\nlpfc_sli_ringtxcmpl_put(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t\tstruct lpfc_iocbq *piocb)\n{\n\tu32 ulp_command = 0;\n\n\tBUG_ON(!piocb);\n\tulp_command = get_job_cmnd(phba, piocb);\n\n\tlist_add_tail(&piocb->list, &pring->txcmplq);\n\tpiocb->cmd_flag |= LPFC_IO_ON_TXCMPLQ;\n\tpring->txcmplq_cnt++;\n\tif ((unlikely(pring->ringno == LPFC_ELS_RING)) &&\n\t   (ulp_command != CMD_ABORT_XRI_WQE) &&\n\t   (ulp_command != CMD_ABORT_XRI_CN) &&\n\t   (ulp_command != CMD_CLOSE_XRI_CN)) {\n\t\tBUG_ON(!piocb->vport);\n\t\tif (!(piocb->vport->load_flag & FC_UNLOADING))\n\t\t\tmod_timer(&piocb->vport->els_tmofunc,\n\t\t\t\t  jiffies +\n\t\t\t\t  msecs_to_jiffies(1000 * (phba->fc_ratov << 1)));\n\t}\n\n\treturn 0;\n}\n\n \nstruct lpfc_iocbq *\nlpfc_sli_ringtx_get(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\n{\n\tstruct lpfc_iocbq *cmd_iocb;\n\n\tlockdep_assert_held(&phba->hbalock);\n\n\tlist_remove_head((&pring->txq), cmd_iocb, struct lpfc_iocbq, list);\n\treturn cmd_iocb;\n}\n\n \nstatic void\nlpfc_cmf_sync_cmpl(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,\n\t\t   struct lpfc_iocbq *rspiocb)\n{\n\tunion lpfc_wqe128 *wqe;\n\tuint32_t status, info;\n\tstruct lpfc_wcqe_complete *wcqe = &rspiocb->wcqe_cmpl;\n\tuint64_t bw, bwdif, slop;\n\tuint64_t pcent, bwpcent;\n\tint asig, afpin, sigcnt, fpincnt;\n\tint wsigmax, wfpinmax, cg, tdp;\n\tchar *s;\n\n\t \n\tstatus = bf_get(lpfc_wcqe_c_status, wcqe);\n\tif (status) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"6211 CMF_SYNC_WQE Error \"\n\t\t\t\t\"req_tag x%x status x%x hwstatus x%x \"\n\t\t\t\t\"tdatap x%x parm x%x\\n\",\n\t\t\t\tbf_get(lpfc_wcqe_c_request_tag, wcqe),\n\t\t\t\tbf_get(lpfc_wcqe_c_status, wcqe),\n\t\t\t\tbf_get(lpfc_wcqe_c_hw_status, wcqe),\n\t\t\t\twcqe->total_data_placed,\n\t\t\t\twcqe->parameter);\n\t\tgoto out;\n\t}\n\n\t \n\tinfo = wcqe->parameter;\n\tphba->cmf_active_info = info;\n\n\t \n\tif (info > LPFC_MAX_CMF_INFO || phba->cmf_info_per_interval == info)\n\t\tinfo = 0;\n\telse\n\t\tphba->cmf_info_per_interval = info;\n\n\ttdp = bf_get(lpfc_wcqe_c_cmf_bw, wcqe);\n\tcg = bf_get(lpfc_wcqe_c_cmf_cg, wcqe);\n\n\t \n\tbw = (uint64_t)tdp * LPFC_CMF_BLK_SIZE;\n\tif (!bw) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"6212 CMF_SYNC_WQE x%x: NULL bw\\n\",\n\t\t\t\tbf_get(lpfc_wcqe_c_request_tag, wcqe));\n\t\tgoto out;\n\t}\n\n\t \n\twqe = &cmdiocb->wqe;\n\tasig = bf_get(cmf_sync_asig, &wqe->cmf_sync);\n\tafpin = bf_get(cmf_sync_afpin, &wqe->cmf_sync);\n\tfpincnt = bf_get(cmf_sync_wfpincnt, &wqe->cmf_sync);\n\tsigcnt = bf_get(cmf_sync_wsigcnt, &wqe->cmf_sync);\n\tif (phba->cmf_max_bytes_per_interval != bw ||\n\t    (asig || afpin || sigcnt || fpincnt)) {\n\t\t \n\t\tif (phba->cmf_max_bytes_per_interval <  bw) {\n\t\t\tbwdif = bw - phba->cmf_max_bytes_per_interval;\n\t\t\ts = \"Increase\";\n\t\t} else {\n\t\t\tbwdif = phba->cmf_max_bytes_per_interval - bw;\n\t\t\ts = \"Decrease\";\n\t\t}\n\n\t\t \n\t\tslop = div_u64(phba->cmf_link_byte_count, 200);  \n\t\tpcent = div64_u64(bwdif * 100 + slop,\n\t\t\t\t  phba->cmf_link_byte_count);\n\t\tbwpcent = div64_u64(bw * 100 + slop,\n\t\t\t\t    phba->cmf_link_byte_count);\n\t\t \n\t\tif (bwpcent > 100)\n\t\t\tbwpcent = 100;\n\n\t\tif (phba->cmf_max_bytes_per_interval < bw &&\n\t\t    bwpcent > 95)\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\t\"6208 Congestion bandwidth \"\n\t\t\t\t\t\"limits removed\\n\");\n\t\telse if ((phba->cmf_max_bytes_per_interval > bw) &&\n\t\t\t ((bwpcent + pcent) <= 100) && ((bwpcent + pcent) > 95))\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\t\"6209 Congestion bandwidth \"\n\t\t\t\t\t\"limits in effect\\n\");\n\n\t\tif (asig) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\t\"6237 BW Threshold %lld%% (%lld): \"\n\t\t\t\t\t\"%lld%% %s: Signal Alarm: cg:%d \"\n\t\t\t\t\t\"Info:%u\\n\",\n\t\t\t\t\tbwpcent, bw, pcent, s, cg,\n\t\t\t\t\tphba->cmf_active_info);\n\t\t} else if (afpin) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\t\"6238 BW Threshold %lld%% (%lld): \"\n\t\t\t\t\t\"%lld%% %s: FPIN Alarm: cg:%d \"\n\t\t\t\t\t\"Info:%u\\n\",\n\t\t\t\t\tbwpcent, bw, pcent, s, cg,\n\t\t\t\t\tphba->cmf_active_info);\n\t\t} else if (sigcnt) {\n\t\t\twsigmax = bf_get(cmf_sync_wsigmax, &wqe->cmf_sync);\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\t\"6239 BW Threshold %lld%% (%lld): \"\n\t\t\t\t\t\"%lld%% %s: Signal Warning: \"\n\t\t\t\t\t\"Cnt %d Max %d: cg:%d Info:%u\\n\",\n\t\t\t\t\tbwpcent, bw, pcent, s, sigcnt,\n\t\t\t\t\twsigmax, cg, phba->cmf_active_info);\n\t\t} else if (fpincnt) {\n\t\t\twfpinmax = bf_get(cmf_sync_wfpinmax, &wqe->cmf_sync);\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\t\"6240 BW Threshold %lld%% (%lld): \"\n\t\t\t\t\t\"%lld%% %s: FPIN Warning: \"\n\t\t\t\t\t\"Cnt %d Max %d: cg:%d Info:%u\\n\",\n\t\t\t\t\tbwpcent, bw, pcent, s, fpincnt,\n\t\t\t\t\twfpinmax, cg, phba->cmf_active_info);\n\t\t} else {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\t\"6241 BW Threshold %lld%% (%lld): \"\n\t\t\t\t\t\"CMF %lld%% %s: cg:%d Info:%u\\n\",\n\t\t\t\t\tbwpcent, bw, pcent, s, cg,\n\t\t\t\t\tphba->cmf_active_info);\n\t\t}\n\t} else if (info) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"6246 Info Threshold %u\\n\", info);\n\t}\n\n\t \n\tphba->cmf_last_sync_bw = bw;\nout:\n\tlpfc_sli_release_iocbq(phba, cmdiocb);\n}\n\n \nint\nlpfc_issue_cmf_sync_wqe(struct lpfc_hba *phba, u32 ms, u64 total)\n{\n\tunion lpfc_wqe128 *wqe;\n\tstruct lpfc_iocbq *sync_buf;\n\tunsigned long iflags;\n\tu32 ret_val;\n\tu32 atot, wtot, max;\n\tu8 warn_sync_period = 0;\n\n\t \n\tatot = atomic_xchg(&phba->cgn_sync_alarm_cnt, 0);\n\twtot = atomic_xchg(&phba->cgn_sync_warn_cnt, 0);\n\n\t \n\tif (phba->cmf_active_mode != LPFC_CFG_MANAGED ||\n\t    phba->link_state == LPFC_LINK_DOWN)\n\t\treturn 0;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tsync_buf = __lpfc_sli_get_iocbq(phba);\n\tif (!sync_buf) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_CGN_MGMT,\n\t\t\t\t\"6244 No available WQEs for CMF_SYNC_WQE\\n\");\n\t\tret_val = ENOMEM;\n\t\tgoto out_unlock;\n\t}\n\n\twqe = &sync_buf->wqe;\n\n\t \n\tmemset(wqe, 0, sizeof(*wqe));\n\n\t \n\tif (!ms) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"6441 CMF Init %d - CMF_SYNC_WQE\\n\",\n\t\t\t\tphba->fc_eventTag);\n\t\tbf_set(cmf_sync_op, &wqe->cmf_sync, 1);  \n\t\tbf_set(cmf_sync_interval, &wqe->cmf_sync, LPFC_CMF_INTERVAL);\n\t\tgoto initpath;\n\t}\n\n\tbf_set(cmf_sync_op, &wqe->cmf_sync, 0);  \n\tbf_set(cmf_sync_interval, &wqe->cmf_sync, ms);\n\n\t \n\tif (atot) {\n\t\tif (phba->cgn_reg_signal == EDC_CG_SIG_WARN_ALARM) {\n\t\t\t \n\t\t\tbf_set(cmf_sync_asig, &wqe->cmf_sync, 1);\n\t\t} else {\n\t\t\t \n\t\t\tbf_set(cmf_sync_afpin, &wqe->cmf_sync, 1);\n\t\t}\n\t} else if (wtot) {\n\t\tif (phba->cgn_reg_signal == EDC_CG_SIG_WARN_ONLY ||\n\t\t    phba->cgn_reg_signal == EDC_CG_SIG_WARN_ALARM) {\n\t\t\t \n\t\t\tmax = LPFC_SEC_TO_MSEC / lpfc_fabric_cgn_frequency *\n\t\t\t\tlpfc_acqe_cgn_frequency;\n\t\t\tbf_set(cmf_sync_wsigmax, &wqe->cmf_sync, max);\n\t\t\tbf_set(cmf_sync_wsigcnt, &wqe->cmf_sync, wtot);\n\t\t\twarn_sync_period = lpfc_acqe_cgn_frequency;\n\t\t} else {\n\t\t\t \n\t\t\tbf_set(cmf_sync_wfpinmax, &wqe->cmf_sync, 1);\n\t\t\tbf_set(cmf_sync_wfpincnt, &wqe->cmf_sync, 1);\n\t\t\tif (phba->cgn_fpin_frequency != LPFC_FPIN_INIT_FREQ)\n\t\t\t\twarn_sync_period =\n\t\t\t\tLPFC_MSECS_TO_SECS(phba->cgn_fpin_frequency);\n\t\t}\n\t}\n\n\t \n\twqe->cmf_sync.read_bytes = (u32)(total / LPFC_CMF_BLK_SIZE);\n\ninitpath:\n\tbf_set(cmf_sync_ver, &wqe->cmf_sync, LPFC_CMF_SYNC_VER);\n\twqe->cmf_sync.event_tag = phba->fc_eventTag;\n\tbf_set(cmf_sync_cmnd, &wqe->cmf_sync, CMD_CMF_SYNC_WQE);\n\n\t \n\tbf_set(cmf_sync_reqtag, &wqe->cmf_sync, sync_buf->iotag);\n\n\tbf_set(cmf_sync_qosd, &wqe->cmf_sync, 1);\n\tbf_set(cmf_sync_period, &wqe->cmf_sync, warn_sync_period);\n\n\tbf_set(cmf_sync_cmd_type, &wqe->cmf_sync, CMF_SYNC_COMMAND);\n\tbf_set(cmf_sync_wqec, &wqe->cmf_sync, 1);\n\tbf_set(cmf_sync_cqid, &wqe->cmf_sync, LPFC_WQE_CQ_ID_DEFAULT);\n\n\tsync_buf->vport = phba->pport;\n\tsync_buf->cmd_cmpl = lpfc_cmf_sync_cmpl;\n\tsync_buf->cmd_dmabuf = NULL;\n\tsync_buf->rsp_dmabuf = NULL;\n\tsync_buf->bpl_dmabuf = NULL;\n\tsync_buf->sli4_xritag = NO_XRI;\n\n\tsync_buf->cmd_flag |= LPFC_IO_CMF;\n\tret_val = lpfc_sli4_issue_wqe(phba, &phba->sli4_hba.hdwq[0], sync_buf);\n\tif (ret_val) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\"6214 Cannot issue CMF_SYNC_WQE: x%x\\n\",\n\t\t\t\tret_val);\n\t\t__lpfc_sli_release_iocbq(phba, sync_buf);\n\t}\nout_unlock:\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn ret_val;\n}\n\n \nstatic IOCB_t *\nlpfc_sli_next_iocb_slot (struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\n{\n\tstruct lpfc_pgp *pgp = &phba->port_gp[pring->ringno];\n\tuint32_t  max_cmd_idx = pring->sli.sli3.numCiocb;\n\n\tlockdep_assert_held(&phba->hbalock);\n\n\tif ((pring->sli.sli3.next_cmdidx == pring->sli.sli3.cmdidx) &&\n\t   (++pring->sli.sli3.next_cmdidx >= max_cmd_idx))\n\t\tpring->sli.sli3.next_cmdidx = 0;\n\n\tif (unlikely(pring->sli.sli3.local_getidx ==\n\t\tpring->sli.sli3.next_cmdidx)) {\n\n\t\tpring->sli.sli3.local_getidx = le32_to_cpu(pgp->cmdGetInx);\n\n\t\tif (unlikely(pring->sli.sli3.local_getidx >= max_cmd_idx)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0315 Ring %d issue: portCmdGet %d \"\n\t\t\t\t\t\"is bigger than cmd ring %d\\n\",\n\t\t\t\t\tpring->ringno,\n\t\t\t\t\tpring->sli.sli3.local_getidx,\n\t\t\t\t\tmax_cmd_idx);\n\n\t\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\t\t \n\t\t\tphba->work_ha |= HA_ERATT;\n\t\t\tphba->work_hs = HS_FFER3;\n\n\t\t\tlpfc_worker_wake_up(phba);\n\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (pring->sli.sli3.local_getidx == pring->sli.sli3.next_cmdidx)\n\t\t\treturn NULL;\n\t}\n\n\treturn lpfc_cmd_iocb(phba, pring);\n}\n\n \nuint16_t\nlpfc_sli_next_iotag(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\n{\n\tstruct lpfc_iocbq **new_arr;\n\tstruct lpfc_iocbq **old_arr;\n\tsize_t new_len;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tuint16_t iotag;\n\n\tspin_lock_irq(&phba->hbalock);\n\tiotag = psli->last_iotag;\n\tif(++iotag < psli->iocbq_lookup_len) {\n\t\tpsli->last_iotag = iotag;\n\t\tpsli->iocbq_lookup[iotag] = iocbq;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tiocbq->iotag = iotag;\n\t\treturn iotag;\n\t} else if (psli->iocbq_lookup_len < (0xffff\n\t\t\t\t\t   - LPFC_IOCBQ_LOOKUP_INCREMENT)) {\n\t\tnew_len = psli->iocbq_lookup_len + LPFC_IOCBQ_LOOKUP_INCREMENT;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tnew_arr = kcalloc(new_len, sizeof(struct lpfc_iocbq *),\n\t\t\t\t  GFP_KERNEL);\n\t\tif (new_arr) {\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\told_arr = psli->iocbq_lookup;\n\t\t\tif (new_len <= psli->iocbq_lookup_len) {\n\t\t\t\t \n\t\t\t\tkfree(new_arr);\n\t\t\t\tiotag = psli->last_iotag;\n\t\t\t\tif(++iotag < psli->iocbq_lookup_len) {\n\t\t\t\t\tpsli->last_iotag = iotag;\n\t\t\t\t\tpsli->iocbq_lookup[iotag] = iocbq;\n\t\t\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t\t\tiocbq->iotag = iotag;\n\t\t\t\t\treturn iotag;\n\t\t\t\t}\n\t\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif (psli->iocbq_lookup)\n\t\t\t\tmemcpy(new_arr, old_arr,\n\t\t\t\t       ((psli->last_iotag  + 1) *\n\t\t\t\t\tsizeof (struct lpfc_iocbq *)));\n\t\t\tpsli->iocbq_lookup = new_arr;\n\t\t\tpsli->iocbq_lookup_len = new_len;\n\t\t\tpsli->last_iotag = iotag;\n\t\t\tpsli->iocbq_lookup[iotag] = iocbq;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tiocbq->iotag = iotag;\n\t\t\tkfree(old_arr);\n\t\t\treturn iotag;\n\t\t}\n\t} else\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\"0318 Failed to allocate IOTAG.last IOTAG is %d\\n\",\n\t\t\tpsli->last_iotag);\n\n\treturn 0;\n}\n\n \nstatic void\nlpfc_sli_submit_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\tIOCB_t *iocb, struct lpfc_iocbq *nextiocb)\n{\n\t \n\tnextiocb->iocb.ulpIoTag = (nextiocb->cmd_cmpl) ? nextiocb->iotag : 0;\n\n\n\tif (pring->ringno == LPFC_ELS_RING) {\n\t\tlpfc_debugfs_slow_ring_trc(phba,\n\t\t\t\"IOCB cmd ring:   wd4:x%08x wd6:x%08x wd7:x%08x\",\n\t\t\t*(((uint32_t *) &nextiocb->iocb) + 4),\n\t\t\t*(((uint32_t *) &nextiocb->iocb) + 6),\n\t\t\t*(((uint32_t *) &nextiocb->iocb) + 7));\n\t}\n\n\t \n\tlpfc_sli_pcimem_bcopy(&nextiocb->iocb, iocb, phba->iocb_cmd_size);\n\twmb();\n\tpring->stats.iocb_cmd++;\n\n\t \n\tif (nextiocb->cmd_cmpl)\n\t\tlpfc_sli_ringtxcmpl_put(phba, pring, nextiocb);\n\telse\n\t\t__lpfc_sli_release_iocbq(phba, nextiocb);\n\n\t \n\tpring->sli.sli3.cmdidx = pring->sli.sli3.next_cmdidx;\n\twritel(pring->sli.sli3.cmdidx, &phba->host_gp[pring->ringno].cmdPutInx);\n}\n\n \nstatic void\nlpfc_sli_update_full_ring(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\n{\n\tint ringno = pring->ringno;\n\n\tpring->flag |= LPFC_CALL_RING_AVAILABLE;\n\n\twmb();\n\n\t \n\twritel((CA_R0ATT|CA_R0CE_REQ) << (ringno*4), phba->CAregaddr);\n\treadl(phba->CAregaddr);  \n\n\tpring->stats.iocb_cmd_full++;\n}\n\n \nstatic void\nlpfc_sli_update_ring(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\n{\n\tint ringno = pring->ringno;\n\n\t \n\tif (!(phba->sli3_options & LPFC_SLI3_CRP_ENABLED)) {\n\t\twmb();\n\t\twritel(CA_R0ATT << (ringno * 4), phba->CAregaddr);\n\t\treadl(phba->CAregaddr);  \n\t}\n}\n\n \nstatic void\nlpfc_sli_resume_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\n{\n\tIOCB_t *iocb;\n\tstruct lpfc_iocbq *nextiocb;\n\n\tlockdep_assert_held(&phba->hbalock);\n\n\t \n\n\tif (lpfc_is_link_up(phba) &&\n\t    (!list_empty(&pring->txq)) &&\n\t    (pring->ringno != LPFC_FCP_RING ||\n\t     phba->sli.sli_flag & LPFC_PROCESS_LA)) {\n\n\t\twhile ((iocb = lpfc_sli_next_iocb_slot(phba, pring)) &&\n\t\t       (nextiocb = lpfc_sli_ringtx_get(phba, pring)))\n\t\t\tlpfc_sli_submit_iocb(phba, pring, iocb, nextiocb);\n\n\t\tif (iocb)\n\t\t\tlpfc_sli_update_ring(phba, pring);\n\t\telse\n\t\t\tlpfc_sli_update_full_ring(phba, pring);\n\t}\n\n\treturn;\n}\n\n \nstatic struct lpfc_hbq_entry *\nlpfc_sli_next_hbq_slot(struct lpfc_hba *phba, uint32_t hbqno)\n{\n\tstruct hbq_s *hbqp = &phba->hbqs[hbqno];\n\n\tlockdep_assert_held(&phba->hbalock);\n\n\tif (hbqp->next_hbqPutIdx == hbqp->hbqPutIdx &&\n\t    ++hbqp->next_hbqPutIdx >= hbqp->entry_count)\n\t\thbqp->next_hbqPutIdx = 0;\n\n\tif (unlikely(hbqp->local_hbqGetIdx == hbqp->next_hbqPutIdx)) {\n\t\tuint32_t raw_index = phba->hbq_get[hbqno];\n\t\tuint32_t getidx = le32_to_cpu(raw_index);\n\n\t\thbqp->local_hbqGetIdx = getidx;\n\n\t\tif (unlikely(hbqp->local_hbqGetIdx >= hbqp->entry_count)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"1802 HBQ %d: local_hbqGetIdx \"\n\t\t\t\t\t\"%u is > than hbqp->entry_count %u\\n\",\n\t\t\t\t\thbqno, hbqp->local_hbqGetIdx,\n\t\t\t\t\thbqp->entry_count);\n\n\t\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (hbqp->local_hbqGetIdx == hbqp->next_hbqPutIdx)\n\t\t\treturn NULL;\n\t}\n\n\treturn (struct lpfc_hbq_entry *) phba->hbqs[hbqno].hbq_virt +\n\t\t\thbqp->hbqPutIdx;\n}\n\n \nvoid\nlpfc_sli_hbqbuf_free_all(struct lpfc_hba *phba)\n{\n\tstruct lpfc_dmabuf *dmabuf, *next_dmabuf;\n\tstruct hbq_dmabuf *hbq_buf;\n\tunsigned long flags;\n\tint i, hbq_count;\n\n\thbq_count = lpfc_sli_hbq_count();\n\t \n\tspin_lock_irqsave(&phba->hbalock, flags);\n\tfor (i = 0; i < hbq_count; ++i) {\n\t\tlist_for_each_entry_safe(dmabuf, next_dmabuf,\n\t\t\t\t&phba->hbqs[i].hbq_buffer_list, list) {\n\t\t\thbq_buf = container_of(dmabuf, struct hbq_dmabuf, dbuf);\n\t\t\tlist_del(&hbq_buf->dbuf.list);\n\t\t\t(phba->hbqs[i].hbq_free_buffer)(phba, hbq_buf);\n\t\t}\n\t\tphba->hbqs[i].buffer_count = 0;\n\t}\n\n\t \n\tphba->hbq_in_use = 0;\n\tspin_unlock_irqrestore(&phba->hbalock, flags);\n}\n\n \nstatic int\nlpfc_sli_hbq_to_firmware(struct lpfc_hba *phba, uint32_t hbqno,\n\t\t\t struct hbq_dmabuf *hbq_buf)\n{\n\tlockdep_assert_held(&phba->hbalock);\n\treturn phba->lpfc_sli_hbq_to_firmware(phba, hbqno, hbq_buf);\n}\n\n \nstatic int\nlpfc_sli_hbq_to_firmware_s3(struct lpfc_hba *phba, uint32_t hbqno,\n\t\t\t    struct hbq_dmabuf *hbq_buf)\n{\n\tstruct lpfc_hbq_entry *hbqe;\n\tdma_addr_t physaddr = hbq_buf->dbuf.phys;\n\n\tlockdep_assert_held(&phba->hbalock);\n\t \n\thbqe = lpfc_sli_next_hbq_slot(phba, hbqno);\n\tif (hbqe) {\n\t\tstruct hbq_s *hbqp = &phba->hbqs[hbqno];\n\n\t\thbqe->bde.addrHigh = le32_to_cpu(putPaddrHigh(physaddr));\n\t\thbqe->bde.addrLow  = le32_to_cpu(putPaddrLow(physaddr));\n\t\thbqe->bde.tus.f.bdeSize = hbq_buf->total_size;\n\t\thbqe->bde.tus.f.bdeFlags = 0;\n\t\thbqe->bde.tus.w = le32_to_cpu(hbqe->bde.tus.w);\n\t\thbqe->buffer_tag = le32_to_cpu(hbq_buf->tag);\n\t\t\t\t \n\t\thbqp->hbqPutIdx = hbqp->next_hbqPutIdx;\n\t\twritel(hbqp->hbqPutIdx, phba->hbq_put + hbqno);\n\t\t\t\t \n\t\treadl(phba->hbq_put + hbqno);\n\t\tlist_add_tail(&hbq_buf->dbuf.list, &hbqp->hbq_buffer_list);\n\t\treturn 0;\n\t} else\n\t\treturn -ENOMEM;\n}\n\n \nstatic int\nlpfc_sli_hbq_to_firmware_s4(struct lpfc_hba *phba, uint32_t hbqno,\n\t\t\t    struct hbq_dmabuf *hbq_buf)\n{\n\tint rc;\n\tstruct lpfc_rqe hrqe;\n\tstruct lpfc_rqe drqe;\n\tstruct lpfc_queue *hrq;\n\tstruct lpfc_queue *drq;\n\n\tif (hbqno != LPFC_ELS_HBQ)\n\t\treturn 1;\n\thrq = phba->sli4_hba.hdr_rq;\n\tdrq = phba->sli4_hba.dat_rq;\n\n\tlockdep_assert_held(&phba->hbalock);\n\thrqe.address_lo = putPaddrLow(hbq_buf->hbuf.phys);\n\thrqe.address_hi = putPaddrHigh(hbq_buf->hbuf.phys);\n\tdrqe.address_lo = putPaddrLow(hbq_buf->dbuf.phys);\n\tdrqe.address_hi = putPaddrHigh(hbq_buf->dbuf.phys);\n\trc = lpfc_sli4_rq_put(hrq, drq, &hrqe, &drqe);\n\tif (rc < 0)\n\t\treturn rc;\n\thbq_buf->tag = (rc | (hbqno << 16));\n\tlist_add_tail(&hbq_buf->dbuf.list, &phba->hbqs[hbqno].hbq_buffer_list);\n\treturn 0;\n}\n\n \nstatic struct lpfc_hbq_init lpfc_els_hbq = {\n\t.rn = 1,\n\t.entry_count = 256,\n\t.mask_count = 0,\n\t.profile = 0,\n\t.ring_mask = (1 << LPFC_ELS_RING),\n\t.buffer_count = 0,\n\t.init_count = 40,\n\t.add_count = 40,\n};\n\n \nstruct lpfc_hbq_init *lpfc_hbq_defs[] = {\n\t&lpfc_els_hbq,\n};\n\n \nstatic int\nlpfc_sli_hbqbuf_fill_hbqs(struct lpfc_hba *phba, uint32_t hbqno, uint32_t count)\n{\n\tuint32_t i, posted = 0;\n\tunsigned long flags;\n\tstruct hbq_dmabuf *hbq_buffer;\n\tLIST_HEAD(hbq_buf_list);\n\tif (!phba->hbqs[hbqno].hbq_alloc_buffer)\n\t\treturn 0;\n\n\tif ((phba->hbqs[hbqno].buffer_count + count) >\n\t    lpfc_hbq_defs[hbqno]->entry_count)\n\t\tcount = lpfc_hbq_defs[hbqno]->entry_count -\n\t\t\t\t\tphba->hbqs[hbqno].buffer_count;\n\tif (!count)\n\t\treturn 0;\n\t \n\tfor (i = 0; i < count; i++) {\n\t\thbq_buffer = (phba->hbqs[hbqno].hbq_alloc_buffer)(phba);\n\t\tif (!hbq_buffer)\n\t\t\tbreak;\n\t\tlist_add_tail(&hbq_buffer->dbuf.list, &hbq_buf_list);\n\t}\n\t \n\tspin_lock_irqsave(&phba->hbalock, flags);\n\tif (!phba->hbq_in_use)\n\t\tgoto err;\n\twhile (!list_empty(&hbq_buf_list)) {\n\t\tlist_remove_head(&hbq_buf_list, hbq_buffer, struct hbq_dmabuf,\n\t\t\t\t dbuf.list);\n\t\thbq_buffer->tag = (phba->hbqs[hbqno].buffer_count |\n\t\t\t\t      (hbqno << 16));\n\t\tif (!lpfc_sli_hbq_to_firmware(phba, hbqno, hbq_buffer)) {\n\t\t\tphba->hbqs[hbqno].buffer_count++;\n\t\t\tposted++;\n\t\t} else\n\t\t\t(phba->hbqs[hbqno].hbq_free_buffer)(phba, hbq_buffer);\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, flags);\n\treturn posted;\nerr:\n\tspin_unlock_irqrestore(&phba->hbalock, flags);\n\twhile (!list_empty(&hbq_buf_list)) {\n\t\tlist_remove_head(&hbq_buf_list, hbq_buffer, struct hbq_dmabuf,\n\t\t\t\t dbuf.list);\n\t\t(phba->hbqs[hbqno].hbq_free_buffer)(phba, hbq_buffer);\n\t}\n\treturn 0;\n}\n\n \nint\nlpfc_sli_hbqbuf_add_hbqs(struct lpfc_hba *phba, uint32_t qno)\n{\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\treturn 0;\n\telse\n\t\treturn lpfc_sli_hbqbuf_fill_hbqs(phba, qno,\n\t\t\t\t\t lpfc_hbq_defs[qno]->add_count);\n}\n\n \nstatic int\nlpfc_sli_hbqbuf_init_hbqs(struct lpfc_hba *phba, uint32_t qno)\n{\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\treturn lpfc_sli_hbqbuf_fill_hbqs(phba, qno,\n\t\t\t\t\tlpfc_hbq_defs[qno]->entry_count);\n\telse\n\t\treturn lpfc_sli_hbqbuf_fill_hbqs(phba, qno,\n\t\t\t\t\t lpfc_hbq_defs[qno]->init_count);\n}\n\n \nstatic struct hbq_dmabuf *\nlpfc_sli_hbqbuf_get(struct list_head *rb_list)\n{\n\tstruct lpfc_dmabuf *d_buf;\n\n\tlist_remove_head(rb_list, d_buf, struct lpfc_dmabuf, list);\n\tif (!d_buf)\n\t\treturn NULL;\n\treturn container_of(d_buf, struct hbq_dmabuf, dbuf);\n}\n\n \nstatic struct rqb_dmabuf *\nlpfc_sli_rqbuf_get(struct lpfc_hba *phba, struct lpfc_queue *hrq)\n{\n\tstruct lpfc_dmabuf *h_buf;\n\tstruct lpfc_rqb *rqbp;\n\n\trqbp = hrq->rqbp;\n\tlist_remove_head(&rqbp->rqb_buffer_list, h_buf,\n\t\t\t struct lpfc_dmabuf, list);\n\tif (!h_buf)\n\t\treturn NULL;\n\trqbp->buffer_count--;\n\treturn container_of(h_buf, struct rqb_dmabuf, hbuf);\n}\n\n \nstatic struct hbq_dmabuf *\nlpfc_sli_hbqbuf_find(struct lpfc_hba *phba, uint32_t tag)\n{\n\tstruct lpfc_dmabuf *d_buf;\n\tstruct hbq_dmabuf *hbq_buf;\n\tuint32_t hbqno;\n\n\thbqno = tag >> 16;\n\tif (hbqno >= LPFC_MAX_HBQS)\n\t\treturn NULL;\n\n\tspin_lock_irq(&phba->hbalock);\n\tlist_for_each_entry(d_buf, &phba->hbqs[hbqno].hbq_buffer_list, list) {\n\t\thbq_buf = container_of(d_buf, struct hbq_dmabuf, dbuf);\n\t\tif (hbq_buf->tag == tag) {\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\treturn hbq_buf;\n\t\t}\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"1803 Bad hbq tag. Data: x%x x%x\\n\",\n\t\t\ttag, phba->hbqs[tag >> 16].buffer_count);\n\treturn NULL;\n}\n\n \nvoid\nlpfc_sli_free_hbq(struct lpfc_hba *phba, struct hbq_dmabuf *hbq_buffer)\n{\n\tuint32_t hbqno;\n\n\tif (hbq_buffer) {\n\t\thbqno = hbq_buffer->tag >> 16;\n\t\tif (lpfc_sli_hbq_to_firmware(phba, hbqno, hbq_buffer))\n\t\t\t(phba->hbqs[hbqno].hbq_free_buffer)(phba, hbq_buffer);\n\t}\n}\n\n \nstatic int\nlpfc_sli_chk_mbx_command(uint8_t mbxCommand)\n{\n\tuint8_t ret;\n\n\tswitch (mbxCommand) {\n\tcase MBX_LOAD_SM:\n\tcase MBX_READ_NV:\n\tcase MBX_WRITE_NV:\n\tcase MBX_WRITE_VPARMS:\n\tcase MBX_RUN_BIU_DIAG:\n\tcase MBX_INIT_LINK:\n\tcase MBX_DOWN_LINK:\n\tcase MBX_CONFIG_LINK:\n\tcase MBX_CONFIG_RING:\n\tcase MBX_RESET_RING:\n\tcase MBX_READ_CONFIG:\n\tcase MBX_READ_RCONFIG:\n\tcase MBX_READ_SPARM:\n\tcase MBX_READ_STATUS:\n\tcase MBX_READ_RPI:\n\tcase MBX_READ_XRI:\n\tcase MBX_READ_REV:\n\tcase MBX_READ_LNK_STAT:\n\tcase MBX_REG_LOGIN:\n\tcase MBX_UNREG_LOGIN:\n\tcase MBX_CLEAR_LA:\n\tcase MBX_DUMP_MEMORY:\n\tcase MBX_DUMP_CONTEXT:\n\tcase MBX_RUN_DIAGS:\n\tcase MBX_RESTART:\n\tcase MBX_UPDATE_CFG:\n\tcase MBX_DOWN_LOAD:\n\tcase MBX_DEL_LD_ENTRY:\n\tcase MBX_RUN_PROGRAM:\n\tcase MBX_SET_MASK:\n\tcase MBX_SET_VARIABLE:\n\tcase MBX_UNREG_D_ID:\n\tcase MBX_KILL_BOARD:\n\tcase MBX_CONFIG_FARP:\n\tcase MBX_BEACON:\n\tcase MBX_LOAD_AREA:\n\tcase MBX_RUN_BIU_DIAG64:\n\tcase MBX_CONFIG_PORT:\n\tcase MBX_READ_SPARM64:\n\tcase MBX_READ_RPI64:\n\tcase MBX_REG_LOGIN64:\n\tcase MBX_READ_TOPOLOGY:\n\tcase MBX_WRITE_WWN:\n\tcase MBX_SET_DEBUG:\n\tcase MBX_LOAD_EXP_ROM:\n\tcase MBX_ASYNCEVT_ENABLE:\n\tcase MBX_REG_VPI:\n\tcase MBX_UNREG_VPI:\n\tcase MBX_HEARTBEAT:\n\tcase MBX_PORT_CAPABILITIES:\n\tcase MBX_PORT_IOV_CONTROL:\n\tcase MBX_SLI4_CONFIG:\n\tcase MBX_SLI4_REQ_FTRS:\n\tcase MBX_REG_FCFI:\n\tcase MBX_UNREG_FCFI:\n\tcase MBX_REG_VFI:\n\tcase MBX_UNREG_VFI:\n\tcase MBX_INIT_VPI:\n\tcase MBX_INIT_VFI:\n\tcase MBX_RESUME_RPI:\n\tcase MBX_READ_EVENT_LOG_STATUS:\n\tcase MBX_READ_EVENT_LOG:\n\tcase MBX_SECURITY_MGMT:\n\tcase MBX_AUTH_PORT:\n\tcase MBX_ACCESS_VDATA:\n\t\tret = mbxCommand;\n\t\tbreak;\n\tdefault:\n\t\tret = MBX_SHUTDOWN;\n\t\tbreak;\n\t}\n\treturn ret;\n}\n\n \nvoid\nlpfc_sli_wake_mbox_wait(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmboxq)\n{\n\tunsigned long drvr_flag;\n\tstruct completion *pmbox_done;\n\n\t \n\tpmboxq->mbox_flag |= LPFC_MBX_WAKE;\n\tspin_lock_irqsave(&phba->hbalock, drvr_flag);\n\tpmbox_done = (struct completion *)pmboxq->context3;\n\tif (pmbox_done)\n\t\tcomplete(pmbox_done);\n\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\treturn;\n}\n\nstatic void\n__lpfc_sli_rpi_release(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\n{\n\tunsigned long iflags;\n\n\tif (ndlp->nlp_flag & NLP_RELEASE_RPI) {\n\t\tlpfc_sli4_free_rpi(vport->phba, ndlp->nlp_rpi);\n\t\tspin_lock_irqsave(&ndlp->lock, iflags);\n\t\tndlp->nlp_flag &= ~NLP_RELEASE_RPI;\n\t\tndlp->nlp_rpi = LPFC_RPI_ALLOC_ERROR;\n\t\tspin_unlock_irqrestore(&ndlp->lock, iflags);\n\t}\n\tndlp->nlp_flag &= ~NLP_UNREG_INP;\n}\n\nvoid\nlpfc_sli_rpi_release(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\n{\n\t__lpfc_sli_rpi_release(vport, ndlp);\n}\n\n \nvoid\nlpfc_sli_def_mbox_cmpl(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\n{\n\tstruct lpfc_vport  *vport = pmb->vport;\n\tstruct lpfc_dmabuf *mp;\n\tstruct lpfc_nodelist *ndlp;\n\tstruct Scsi_Host *shost;\n\tuint16_t rpi, vpi;\n\tint rc;\n\n\t \n\tif (!(phba->pport->load_flag & FC_UNLOADING) &&\n\t    pmb->u.mb.mbxCommand == MBX_REG_LOGIN64 &&\n\t    !pmb->u.mb.mbxStatus) {\n\t\tmp = (struct lpfc_dmabuf *)pmb->ctx_buf;\n\t\tif (mp) {\n\t\t\tpmb->ctx_buf = NULL;\n\t\t\tlpfc_mbuf_free(phba, mp->virt, mp->phys);\n\t\t\tkfree(mp);\n\t\t}\n\t\trpi = pmb->u.mb.un.varWords[0];\n\t\tvpi = pmb->u.mb.un.varRegLogin.vpi;\n\t\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\t\tvpi -= phba->sli4_hba.max_cfg_param.vpi_base;\n\t\tlpfc_unreg_login(phba, vpi, rpi, pmb);\n\t\tpmb->vport = vport;\n\t\tpmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\t\tif (rc != MBX_NOT_FINISHED)\n\t\t\treturn;\n\t}\n\n\tif ((pmb->u.mb.mbxCommand == MBX_REG_VPI) &&\n\t\t!(phba->pport->load_flag & FC_UNLOADING) &&\n\t\t!pmb->u.mb.mbxStatus) {\n\t\tshost = lpfc_shost_from_vport(vport);\n\t\tspin_lock_irq(shost->host_lock);\n\t\tvport->vpi_state |= LPFC_VPI_REGISTERED;\n\t\tvport->fc_flag &= ~FC_VPORT_NEEDS_REG_VPI;\n\t\tspin_unlock_irq(shost->host_lock);\n\t}\n\n\tif (pmb->u.mb.mbxCommand == MBX_REG_LOGIN64) {\n\t\tndlp = (struct lpfc_nodelist *)pmb->ctx_ndlp;\n\t\tlpfc_nlp_put(ndlp);\n\t}\n\n\tif (pmb->u.mb.mbxCommand == MBX_UNREG_LOGIN) {\n\t\tndlp = (struct lpfc_nodelist *)pmb->ctx_ndlp;\n\n\t\t \n\t\tif (ndlp) {\n\t\t\tlpfc_printf_vlog(\n\t\t\t\tvport,\n\t\t\t\tKERN_INFO, LOG_MBOX | LOG_DISCOVERY,\n\t\t\t\t\"1438 UNREG cmpl deferred mbox x%x \"\n\t\t\t\t\"on NPort x%x Data: x%x x%x x%px x%x x%x\\n\",\n\t\t\t\tndlp->nlp_rpi, ndlp->nlp_DID,\n\t\t\t\tndlp->nlp_flag, ndlp->nlp_defer_did,\n\t\t\t\tndlp, vport->load_flag, kref_read(&ndlp->kref));\n\n\t\t\tif ((ndlp->nlp_flag & NLP_UNREG_INP) &&\n\t\t\t    (ndlp->nlp_defer_did != NLP_EVT_NOTHING_PENDING)) {\n\t\t\t\tndlp->nlp_flag &= ~NLP_UNREG_INP;\n\t\t\t\tndlp->nlp_defer_did = NLP_EVT_NOTHING_PENDING;\n\t\t\t\tlpfc_issue_els_plogi(vport, ndlp->nlp_DID, 0);\n\t\t\t} else {\n\t\t\t\t__lpfc_sli_rpi_release(vport, ndlp);\n\t\t\t}\n\n\t\t\t \n\t\t\tlpfc_nlp_put(ndlp);\n\t\t\tpmb->ctx_ndlp = NULL;\n\t\t}\n\t}\n\n\t \n\tif (pmb->u.mb.mbxCommand == MBX_RESUME_RPI) {\n\t\tndlp = (struct lpfc_nodelist *)pmb->ctx_ndlp;\n\t\tlpfc_nlp_put(ndlp);\n\t}\n\n\t \n\tif ((pmb->u.mb.mbxCommand == MBX_INIT_LINK) &&\n\t    (pmb->u.mb.mbxStatus == MBXERR_SEC_NO_PERMISSION))\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2860 SLI authentication is required \"\n\t\t\t\t\"for INIT_LINK but has not done yet\\n\");\n\n\tif (bf_get(lpfc_mqe_command, &pmb->u.mqe) == MBX_SLI4_CONFIG)\n\t\tlpfc_sli4_mbox_cmd_free(phba, pmb);\n\telse\n\t\tlpfc_mbox_rsrc_cleanup(phba, pmb, MBOX_THD_UNLOCKED);\n}\n  \nvoid\nlpfc_sli4_unreg_rpi_cmpl_clr(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\n{\n\tstruct lpfc_vport  *vport = pmb->vport;\n\tstruct lpfc_nodelist *ndlp;\n\n\tndlp = pmb->ctx_ndlp;\n\tif (pmb->u.mb.mbxCommand == MBX_UNREG_LOGIN) {\n\t\tif (phba->sli_rev == LPFC_SLI_REV4 &&\n\t\t    (bf_get(lpfc_sli_intf_if_type,\n\t\t     &phba->sli4_hba.sli_intf) >=\n\t\t     LPFC_SLI_INTF_IF_TYPE_2)) {\n\t\t\tif (ndlp) {\n\t\t\t\tlpfc_printf_vlog(\n\t\t\t\t\t vport, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\t\t \"0010 UNREG_LOGIN vpi:%x \"\n\t\t\t\t\t \"rpi:%x DID:%x defer x%x flg x%x \"\n\t\t\t\t\t \"x%px\\n\",\n\t\t\t\t\t vport->vpi, ndlp->nlp_rpi,\n\t\t\t\t\t ndlp->nlp_DID, ndlp->nlp_defer_did,\n\t\t\t\t\t ndlp->nlp_flag,\n\t\t\t\t\t ndlp);\n\t\t\t\tndlp->nlp_flag &= ~NLP_LOGO_ACC;\n\n\t\t\t\t \n\t\t\t\tif ((ndlp->nlp_flag & NLP_UNREG_INP) &&\n\t\t\t\t    (ndlp->nlp_defer_did !=\n\t\t\t\t    NLP_EVT_NOTHING_PENDING)) {\n\t\t\t\t\tlpfc_printf_vlog(\n\t\t\t\t\t\tvport, KERN_INFO, LOG_DISCOVERY,\n\t\t\t\t\t\t\"4111 UNREG cmpl deferred \"\n\t\t\t\t\t\t\"clr x%x on \"\n\t\t\t\t\t\t\"NPort x%x Data: x%x x%px\\n\",\n\t\t\t\t\t\tndlp->nlp_rpi, ndlp->nlp_DID,\n\t\t\t\t\t\tndlp->nlp_defer_did, ndlp);\n\t\t\t\t\tndlp->nlp_flag &= ~NLP_UNREG_INP;\n\t\t\t\t\tndlp->nlp_defer_did =\n\t\t\t\t\t\tNLP_EVT_NOTHING_PENDING;\n\t\t\t\t\tlpfc_issue_els_plogi(\n\t\t\t\t\t\tvport, ndlp->nlp_DID, 0);\n\t\t\t\t} else {\n\t\t\t\t\t__lpfc_sli_rpi_release(vport, ndlp);\n\t\t\t\t}\n\t\t\t\tlpfc_nlp_put(ndlp);\n\t\t\t}\n\t\t}\n\t}\n\n\tmempool_free(pmb, phba->mbox_mem_pool);\n}\n\n \nint\nlpfc_sli_handle_mb_event(struct lpfc_hba *phba)\n{\n\tMAILBOX_t *pmbox;\n\tLPFC_MBOXQ_t *pmb;\n\tint rc;\n\tLIST_HEAD(cmplq);\n\n\tphba->sli.slistat.mbox_event++;\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tlist_splice_init(&phba->sli.mboxq_cmpl, &cmplq);\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tdo {\n\t\tlist_remove_head(&cmplq, pmb, LPFC_MBOXQ_t, list);\n\t\tif (pmb == NULL)\n\t\t\tbreak;\n\n\t\tpmbox = &pmb->u.mb;\n\n\t\tif (pmbox->mbxCommand != MBX_HEARTBEAT) {\n\t\t\tif (pmb->vport) {\n\t\t\t\tlpfc_debugfs_disc_trc(pmb->vport,\n\t\t\t\t\tLPFC_DISC_TRC_MBOX_VPORT,\n\t\t\t\t\t\"MBOX cmpl vport: cmd:x%x mb:x%x x%x\",\n\t\t\t\t\t(uint32_t)pmbox->mbxCommand,\n\t\t\t\t\tpmbox->un.varWords[0],\n\t\t\t\t\tpmbox->un.varWords[1]);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tlpfc_debugfs_disc_trc(phba->pport,\n\t\t\t\t\tLPFC_DISC_TRC_MBOX,\n\t\t\t\t\t\"MBOX cmpl:       cmd:x%x mb:x%x x%x\",\n\t\t\t\t\t(uint32_t)pmbox->mbxCommand,\n\t\t\t\t\tpmbox->un.varWords[0],\n\t\t\t\t\tpmbox->un.varWords[1]);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (lpfc_sli_chk_mbx_command(pmbox->mbxCommand) ==\n\t\t    MBX_SHUTDOWN) {\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"(%d):0323 Unknown Mailbox command \"\n\t\t\t\t\t\"x%x (x%x/x%x) Cmpl\\n\",\n\t\t\t\t\tpmb->vport ? pmb->vport->vpi :\n\t\t\t\t\tLPFC_VPORT_UNKNOWN,\n\t\t\t\t\tpmbox->mbxCommand,\n\t\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba,\n\t\t\t\t\t\t\t\t\tpmb),\n\t\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba,\n\t\t\t\t\t\t\t\t\tpmb));\n\t\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\t\tphba->work_hs = HS_FFER3;\n\t\t\tlpfc_handle_eratt(phba);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (pmbox->mbxStatus) {\n\t\t\tphba->sli.slistat.mbox_stat_err++;\n\t\t\tif (pmbox->mbxStatus == MBXERR_NO_RESOURCES) {\n\t\t\t\t \n\t\t\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\t\tLOG_MBOX | LOG_SLI,\n\t\t\t\t\t\"(%d):0305 Mbox cmd cmpl \"\n\t\t\t\t\t\"error - RETRYing Data: x%x \"\n\t\t\t\t\t\"(x%x/x%x) x%x x%x x%x\\n\",\n\t\t\t\t\tpmb->vport ? pmb->vport->vpi :\n\t\t\t\t\tLPFC_VPORT_UNKNOWN,\n\t\t\t\t\tpmbox->mbxCommand,\n\t\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba,\n\t\t\t\t\t\t\t\t\tpmb),\n\t\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba,\n\t\t\t\t\t\t\t\t\tpmb),\n\t\t\t\t\tpmbox->mbxStatus,\n\t\t\t\t\tpmbox->un.varWords[0],\n\t\t\t\t\tpmb->vport ? pmb->vport->port_state :\n\t\t\t\t\tLPFC_VPORT_UNKNOWN);\n\t\t\t\tpmbox->mbxStatus = 0;\n\t\t\t\tpmbox->mbxOwner = OWN_HOST;\n\t\t\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\t\t\t\tif (rc != MBX_NOT_FINISHED)\n\t\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\t\"(%d):0307 Mailbox cmd x%x (x%x/x%x) Cmpl %ps \"\n\t\t\t\t\"Data: x%x x%x x%x x%x x%x x%x x%x x%x x%x \"\n\t\t\t\t\"x%x x%x x%x\\n\",\n\t\t\t\tpmb->vport ? pmb->vport->vpi : 0,\n\t\t\t\tpmbox->mbxCommand,\n\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba, pmb),\n\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba, pmb),\n\t\t\t\tpmb->mbox_cmpl,\n\t\t\t\t*((uint32_t *) pmbox),\n\t\t\t\tpmbox->un.varWords[0],\n\t\t\t\tpmbox->un.varWords[1],\n\t\t\t\tpmbox->un.varWords[2],\n\t\t\t\tpmbox->un.varWords[3],\n\t\t\t\tpmbox->un.varWords[4],\n\t\t\t\tpmbox->un.varWords[5],\n\t\t\t\tpmbox->un.varWords[6],\n\t\t\t\tpmbox->un.varWords[7],\n\t\t\t\tpmbox->un.varWords[8],\n\t\t\t\tpmbox->un.varWords[9],\n\t\t\t\tpmbox->un.varWords[10]);\n\n\t\tif (pmb->mbox_cmpl)\n\t\t\tpmb->mbox_cmpl(phba,pmb);\n\t} while (1);\n\treturn 0;\n}\n\n \nstatic struct lpfc_dmabuf *\nlpfc_sli_get_buff(struct lpfc_hba *phba,\n\t\t  struct lpfc_sli_ring *pring,\n\t\t  uint32_t tag)\n{\n\tstruct hbq_dmabuf *hbq_entry;\n\n\tif (tag & QUE_BUFTAG_BIT)\n\t\treturn lpfc_sli_ring_taggedbuf_get(phba, pring, tag);\n\thbq_entry = lpfc_sli_hbqbuf_find(phba, tag);\n\tif (!hbq_entry)\n\t\treturn NULL;\n\treturn &hbq_entry->dbuf;\n}\n\n \nstatic void\nlpfc_nvme_unsol_ls_handler(struct lpfc_hba *phba, struct lpfc_iocbq *piocb)\n{\n\tstruct lpfc_nodelist *ndlp;\n\tstruct lpfc_dmabuf *d_buf;\n\tstruct hbq_dmabuf *nvmebuf;\n\tstruct fc_frame_header *fc_hdr;\n\tstruct lpfc_async_xchg_ctx *axchg = NULL;\n\tchar *failwhy = NULL;\n\tuint32_t oxid, sid, did, fctl, size;\n\tint ret = 1;\n\n\td_buf = piocb->cmd_dmabuf;\n\n\tnvmebuf = container_of(d_buf, struct hbq_dmabuf, dbuf);\n\tfc_hdr = nvmebuf->hbuf.virt;\n\toxid = be16_to_cpu(fc_hdr->fh_ox_id);\n\tsid = sli4_sid_from_fc_hdr(fc_hdr);\n\tdid = sli4_did_from_fc_hdr(fc_hdr);\n\tfctl = (fc_hdr->fh_f_ctl[0] << 16 |\n\t\tfc_hdr->fh_f_ctl[1] << 8 |\n\t\tfc_hdr->fh_f_ctl[2]);\n\tsize = bf_get(lpfc_rcqe_length, &nvmebuf->cq_event.cqe.rcqe_cmpl);\n\n\tlpfc_nvmeio_data(phba, \"NVME LS    RCV: xri x%x sz %d from %06x\\n\",\n\t\t\t oxid, size, sid);\n\n\tif (phba->pport->load_flag & FC_UNLOADING) {\n\t\tfailwhy = \"Driver Unloading\";\n\t} else if (!(phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)) {\n\t\tfailwhy = \"NVME FC4 Disabled\";\n\t} else if (!phba->nvmet_support && !phba->pport->localport) {\n\t\tfailwhy = \"No Localport\";\n\t} else if (phba->nvmet_support && !phba->targetport) {\n\t\tfailwhy = \"No Targetport\";\n\t} else if (unlikely(fc_hdr->fh_r_ctl != FC_RCTL_ELS4_REQ)) {\n\t\tfailwhy = \"Bad NVME LS R_CTL\";\n\t} else if (unlikely((fctl & 0x00FF0000) !=\n\t\t\t(FC_FC_FIRST_SEQ | FC_FC_END_SEQ | FC_FC_SEQ_INIT))) {\n\t\tfailwhy = \"Bad NVME LS F_CTL\";\n\t} else {\n\t\taxchg = kzalloc(sizeof(*axchg), GFP_ATOMIC);\n\t\tif (!axchg)\n\t\t\tfailwhy = \"No CTX memory\";\n\t}\n\n\tif (unlikely(failwhy)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6154 Drop NVME LS: SID %06X OXID x%X: %s\\n\",\n\t\t\t\tsid, oxid, failwhy);\n\t\tgoto out_fail;\n\t}\n\n\t \n\tndlp = lpfc_findnode_did(phba->pport, sid);\n\tif (!ndlp ||\n\t    ((ndlp->nlp_state != NLP_STE_UNMAPPED_NODE) &&\n\t     (ndlp->nlp_state != NLP_STE_MAPPED_NODE))) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_NVME_DISC,\n\t\t\t\t\"6216 NVME Unsol rcv: No ndlp: \"\n\t\t\t\t\"NPort_ID x%x oxid x%x\\n\",\n\t\t\t\tsid, oxid);\n\t\tgoto out_fail;\n\t}\n\n\taxchg->phba = phba;\n\taxchg->ndlp = ndlp;\n\taxchg->size = size;\n\taxchg->oxid = oxid;\n\taxchg->sid = sid;\n\taxchg->wqeq = NULL;\n\taxchg->state = LPFC_NVME_STE_LS_RCV;\n\taxchg->entry_cnt = 1;\n\taxchg->rqb_buffer = (void *)nvmebuf;\n\taxchg->hdwq = &phba->sli4_hba.hdwq[0];\n\taxchg->payload = nvmebuf->dbuf.virt;\n\tINIT_LIST_HEAD(&axchg->list);\n\n\tif (phba->nvmet_support) {\n\t\tret = lpfc_nvmet_handle_lsreq(phba, axchg);\n\t\tspin_lock_irq(&ndlp->lock);\n\t\tif (!ret && !(ndlp->fc4_xpt_flags & NLP_XPT_HAS_HH)) {\n\t\t\tndlp->fc4_xpt_flags |= NLP_XPT_HAS_HH;\n\t\t\tspin_unlock_irq(&ndlp->lock);\n\n\t\t\t \n\t\t\tif (!lpfc_nlp_get(ndlp))\n\t\t\t\tgoto out_fail;\n\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_NODE,\n\t\t\t\t\t\"6206 NVMET unsol ls_req ndlp x%px \"\n\t\t\t\t\t\"DID x%x xflags x%x refcnt %d\\n\",\n\t\t\t\t\tndlp, ndlp->nlp_DID,\n\t\t\t\t\tndlp->fc4_xpt_flags,\n\t\t\t\t\tkref_read(&ndlp->kref));\n\t\t} else {\n\t\t\tspin_unlock_irq(&ndlp->lock);\n\t\t}\n\t} else {\n\t\tret = lpfc_nvme_handle_lsreq(phba, axchg);\n\t}\n\n\t \n\tif (!ret)\n\t\treturn;\n\nout_fail:\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"6155 Drop NVME LS from DID %06X: SID %06X OXID x%X \"\n\t\t\t\"NVMe%s handler failed %d\\n\",\n\t\t\tdid, sid, oxid,\n\t\t\t(phba->nvmet_support) ? \"T\" : \"I\", ret);\n\n\t \n\tlpfc_in_buf_free(phba, &nvmebuf->dbuf);\n\n\t \n\tif (axchg && (fctl & FC_FC_FIRST_SEQ && !(fctl & FC_FC_EX_CTX)))\n\t\tret = lpfc_nvme_unsol_ls_issue_abort(phba, axchg, sid, oxid);\n\n\tif (ret)\n\t\tkfree(axchg);\n}\n\n \nstatic int\nlpfc_complete_unsol_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t\t struct lpfc_iocbq *saveq, uint32_t fch_r_ctl,\n\t\t\t uint32_t fch_type)\n{\n\tint i;\n\n\tswitch (fch_type) {\n\tcase FC_TYPE_NVME:\n\t\tlpfc_nvme_unsol_ls_handler(phba, saveq);\n\t\treturn 1;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tif (pring->prt[0].profile) {\n\t\tif (pring->prt[0].lpfc_sli_rcv_unsol_event)\n\t\t\t(pring->prt[0].lpfc_sli_rcv_unsol_event) (phba, pring,\n\t\t\t\t\t\t\t\t\tsaveq);\n\t\treturn 1;\n\t}\n\t \n\tfor (i = 0; i < pring->num_mask; i++) {\n\t\tif ((pring->prt[i].rctl == fch_r_ctl) &&\n\t\t    (pring->prt[i].type == fch_type)) {\n\t\t\tif (pring->prt[i].lpfc_sli_rcv_unsol_event)\n\t\t\t\t(pring->prt[i].lpfc_sli_rcv_unsol_event)\n\t\t\t\t\t\t(phba, pring, saveq);\n\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic void\nlpfc_sli_prep_unsol_wqe(struct lpfc_hba *phba,\n\t\t\tstruct lpfc_iocbq *saveq)\n{\n\tIOCB_t *irsp;\n\tunion lpfc_wqe128 *wqe;\n\tu16 i = 0;\n\n\tirsp = &saveq->iocb;\n\twqe = &saveq->wqe;\n\n\t \n\tbf_set(lpfc_wcqe_c_status, &saveq->wcqe_cmpl, irsp->ulpStatus);\n\tsaveq->wcqe_cmpl.word3 = irsp->ulpBdeCount;\n\tsaveq->wcqe_cmpl.parameter = irsp->un.ulpWord[4];\n\tsaveq->wcqe_cmpl.total_data_placed = irsp->unsli3.rcvsli3.acc_len;\n\n\t \n\tbf_set(els_rsp64_sid, &wqe->xmit_els_rsp, irsp->un.rcvels.parmRo);\n\n\t \n\tbf_set(wqe_ctxt_tag, &wqe->xmit_els_rsp.wqe_com, irsp->ulpContext);\n\n\t \n\tbf_set(wqe_rcvoxid, &wqe->xmit_els_rsp.wqe_com,\n\t       irsp->unsli3.rcvsli3.ox_id);\n\n\t \n\tbf_set(wqe_els_did, &wqe->xmit_els_rsp.wqe_dest,\n\t       irsp->un.rcvels.remoteID);\n\n\t \n\tfor (i = 0; i < irsp->ulpBdeCount; i++) {\n\t\tstruct lpfc_hbq_entry *hbqe = NULL;\n\n\t\tif (phba->sli3_options & LPFC_SLI3_HBQ_ENABLED) {\n\t\t\tif (i == 0) {\n\t\t\t\thbqe = (struct lpfc_hbq_entry *)\n\t\t\t\t\t&irsp->un.ulpWord[0];\n\t\t\t\tsaveq->wqe.gen_req.bde.tus.f.bdeSize =\n\t\t\t\t\thbqe->bde.tus.f.bdeSize;\n\t\t\t} else if (i == 1) {\n\t\t\t\thbqe = (struct lpfc_hbq_entry *)\n\t\t\t\t\t&irsp->unsli3.sli3Words[4];\n\t\t\t\tsaveq->unsol_rcv_len = hbqe->bde.tus.f.bdeSize;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic int\nlpfc_sli_process_unsol_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t\t    struct lpfc_iocbq *saveq)\n{\n\tIOCB_t           * irsp;\n\tWORD5            * w5p;\n\tdma_addr_t\t paddr;\n\tuint32_t           Rctl, Type;\n\tstruct lpfc_iocbq *iocbq;\n\tstruct lpfc_dmabuf *dmzbuf;\n\n\tirsp = &saveq->iocb;\n\tsaveq->vport = phba->pport;\n\n\tif (irsp->ulpCommand == CMD_ASYNC_STATUS) {\n\t\tif (pring->lpfc_sli_rcv_async_status)\n\t\t\tpring->lpfc_sli_rcv_async_status(phba, pring, saveq);\n\t\telse\n\t\t\tlpfc_printf_log(phba,\n\t\t\t\t\tKERN_WARNING,\n\t\t\t\t\tLOG_SLI,\n\t\t\t\t\t\"0316 Ring %d handler: unexpected \"\n\t\t\t\t\t\"ASYNC_STATUS iocb received evt_code \"\n\t\t\t\t\t\"0x%x\\n\",\n\t\t\t\t\tpring->ringno,\n\t\t\t\t\tirsp->un.asyncstat.evt_code);\n\t\treturn 1;\n\t}\n\n\tif ((irsp->ulpCommand == CMD_IOCB_RET_XRI64_CX) &&\n\t    (phba->sli3_options & LPFC_SLI3_HBQ_ENABLED)) {\n\t\tif (irsp->ulpBdeCount > 0) {\n\t\t\tdmzbuf = lpfc_sli_get_buff(phba, pring,\n\t\t\t\t\t\t   irsp->un.ulpWord[3]);\n\t\t\tlpfc_in_buf_free(phba, dmzbuf);\n\t\t}\n\n\t\tif (irsp->ulpBdeCount > 1) {\n\t\t\tdmzbuf = lpfc_sli_get_buff(phba, pring,\n\t\t\t\t\t\t   irsp->unsli3.sli3Words[3]);\n\t\t\tlpfc_in_buf_free(phba, dmzbuf);\n\t\t}\n\n\t\tif (irsp->ulpBdeCount > 2) {\n\t\t\tdmzbuf = lpfc_sli_get_buff(phba, pring,\n\t\t\t\t\t\t   irsp->unsli3.sli3Words[7]);\n\t\t\tlpfc_in_buf_free(phba, dmzbuf);\n\t\t}\n\n\t\treturn 1;\n\t}\n\n\tif (phba->sli3_options & LPFC_SLI3_HBQ_ENABLED) {\n\t\tif (irsp->ulpBdeCount != 0) {\n\t\t\tsaveq->cmd_dmabuf = lpfc_sli_get_buff(phba, pring,\n\t\t\t\t\t\tirsp->un.ulpWord[3]);\n\t\t\tif (!saveq->cmd_dmabuf)\n\t\t\t\tlpfc_printf_log(phba,\n\t\t\t\t\tKERN_ERR,\n\t\t\t\t\tLOG_SLI,\n\t\t\t\t\t\"0341 Ring %d Cannot find buffer for \"\n\t\t\t\t\t\"an unsolicited iocb. tag 0x%x\\n\",\n\t\t\t\t\tpring->ringno,\n\t\t\t\t\tirsp->un.ulpWord[3]);\n\t\t}\n\t\tif (irsp->ulpBdeCount == 2) {\n\t\t\tsaveq->bpl_dmabuf = lpfc_sli_get_buff(phba, pring,\n\t\t\t\t\t\tirsp->unsli3.sli3Words[7]);\n\t\t\tif (!saveq->bpl_dmabuf)\n\t\t\t\tlpfc_printf_log(phba,\n\t\t\t\t\tKERN_ERR,\n\t\t\t\t\tLOG_SLI,\n\t\t\t\t\t\"0342 Ring %d Cannot find buffer for an\"\n\t\t\t\t\t\" unsolicited iocb. tag 0x%x\\n\",\n\t\t\t\t\tpring->ringno,\n\t\t\t\t\tirsp->unsli3.sli3Words[7]);\n\t\t}\n\t\tlist_for_each_entry(iocbq, &saveq->list, list) {\n\t\t\tirsp = &iocbq->iocb;\n\t\t\tif (irsp->ulpBdeCount != 0) {\n\t\t\t\tiocbq->cmd_dmabuf = lpfc_sli_get_buff(phba,\n\t\t\t\t\t\t\tpring,\n\t\t\t\t\t\t\tirsp->un.ulpWord[3]);\n\t\t\t\tif (!iocbq->cmd_dmabuf)\n\t\t\t\t\tlpfc_printf_log(phba,\n\t\t\t\t\t\tKERN_ERR,\n\t\t\t\t\t\tLOG_SLI,\n\t\t\t\t\t\t\"0343 Ring %d Cannot find \"\n\t\t\t\t\t\t\"buffer for an unsolicited iocb\"\n\t\t\t\t\t\t\". tag 0x%x\\n\", pring->ringno,\n\t\t\t\t\t\tirsp->un.ulpWord[3]);\n\t\t\t}\n\t\t\tif (irsp->ulpBdeCount == 2) {\n\t\t\t\tiocbq->bpl_dmabuf = lpfc_sli_get_buff(phba,\n\t\t\t\t\t\tpring,\n\t\t\t\t\t\tirsp->unsli3.sli3Words[7]);\n\t\t\t\tif (!iocbq->bpl_dmabuf)\n\t\t\t\t\tlpfc_printf_log(phba,\n\t\t\t\t\t\tKERN_ERR,\n\t\t\t\t\t\tLOG_SLI,\n\t\t\t\t\t\t\"0344 Ring %d Cannot find \"\n\t\t\t\t\t\t\"buffer for an unsolicited \"\n\t\t\t\t\t\t\"iocb. tag 0x%x\\n\",\n\t\t\t\t\t\tpring->ringno,\n\t\t\t\t\t\tirsp->unsli3.sli3Words[7]);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tpaddr = getPaddr(irsp->un.cont64[0].addrHigh,\n\t\t\t\t irsp->un.cont64[0].addrLow);\n\t\tsaveq->cmd_dmabuf = lpfc_sli_ringpostbuf_get(phba, pring,\n\t\t\t\t\t\t\t     paddr);\n\t\tif (irsp->ulpBdeCount == 2) {\n\t\t\tpaddr = getPaddr(irsp->un.cont64[1].addrHigh,\n\t\t\t\t\t irsp->un.cont64[1].addrLow);\n\t\t\tsaveq->bpl_dmabuf = lpfc_sli_ringpostbuf_get(phba,\n\t\t\t\t\t\t\t\t   pring,\n\t\t\t\t\t\t\t\t   paddr);\n\t\t}\n\t}\n\n\tif (irsp->ulpBdeCount != 0 &&\n\t    (irsp->ulpCommand == CMD_IOCB_RCV_CONT64_CX ||\n\t     irsp->ulpStatus == IOSTAT_INTERMED_RSP)) {\n\t\tint found = 0;\n\n\t\t \n\t\tlist_for_each_entry(iocbq, &pring->iocb_continue_saveq, clist) {\n\t\t\tif (iocbq->iocb.unsli3.rcvsli3.ox_id ==\n\t\t\t\tsaveq->iocb.unsli3.rcvsli3.ox_id) {\n\t\t\t\tlist_add_tail(&saveq->list, &iocbq->list);\n\t\t\t\tfound = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!found)\n\t\t\tlist_add_tail(&saveq->clist,\n\t\t\t\t      &pring->iocb_continue_saveq);\n\n\t\tif (saveq->iocb.ulpStatus != IOSTAT_INTERMED_RSP) {\n\t\t\tlist_del_init(&iocbq->clist);\n\t\t\tsaveq = iocbq;\n\t\t\tirsp = &saveq->iocb;\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif ((irsp->ulpCommand == CMD_RCV_ELS_REQ64_CX) ||\n\t    (irsp->ulpCommand == CMD_RCV_ELS_REQ_CX) ||\n\t    (irsp->ulpCommand == CMD_IOCB_RCV_ELS64_CX)) {\n\t\tRctl = FC_RCTL_ELS_REQ;\n\t\tType = FC_TYPE_ELS;\n\t} else {\n\t\tw5p = (WORD5 *)&(saveq->iocb.un.ulpWord[5]);\n\t\tRctl = w5p->hcsw.Rctl;\n\t\tType = w5p->hcsw.Type;\n\n\t\t \n\t\tif ((Rctl == 0) && (pring->ringno == LPFC_ELS_RING) &&\n\t\t\t(irsp->ulpCommand == CMD_RCV_SEQUENCE64_CX ||\n\t\t\t irsp->ulpCommand == CMD_IOCB_RCV_SEQ64_CX)) {\n\t\t\tRctl = FC_RCTL_ELS_REQ;\n\t\t\tType = FC_TYPE_ELS;\n\t\t\tw5p->hcsw.Rctl = Rctl;\n\t\t\tw5p->hcsw.Type = Type;\n\t\t}\n\t}\n\n\tif ((phba->sli3_options & LPFC_SLI3_NPIV_ENABLED) &&\n\t    (irsp->ulpCommand == CMD_IOCB_RCV_ELS64_CX ||\n\t    irsp->ulpCommand == CMD_IOCB_RCV_SEQ64_CX)) {\n\t\tif (irsp->unsli3.rcvsli3.vpi == 0xffff)\n\t\t\tsaveq->vport = phba->pport;\n\t\telse\n\t\t\tsaveq->vport = lpfc_find_vport_by_vpid(phba,\n\t\t\t\t\t       irsp->unsli3.rcvsli3.vpi);\n\t}\n\n\t \n\tlpfc_sli_prep_unsol_wqe(phba, saveq);\n\n\tif (!lpfc_complete_unsol_iocb(phba, pring, saveq, Rctl, Type))\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"0313 Ring %d handler: unexpected Rctl x%x \"\n\t\t\t\t\"Type x%x received\\n\",\n\t\t\t\tpring->ringno, Rctl, Type);\n\n\treturn 1;\n}\n\n \nstatic struct lpfc_iocbq *\nlpfc_sli_iocbq_lookup(struct lpfc_hba *phba,\n\t\t      struct lpfc_sli_ring *pring,\n\t\t      struct lpfc_iocbq *prspiocb)\n{\n\tstruct lpfc_iocbq *cmd_iocb = NULL;\n\tu16 iotag;\n\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tiotag = get_wqe_reqtag(prspiocb);\n\telse\n\t\tiotag = prspiocb->iocb.ulpIoTag;\n\n\tif (iotag != 0 && iotag <= phba->sli.last_iotag) {\n\t\tcmd_iocb = phba->sli.iocbq_lookup[iotag];\n\t\tif (cmd_iocb->cmd_flag & LPFC_IO_ON_TXCMPLQ) {\n\t\t\t \n\t\t\tlist_del_init(&cmd_iocb->list);\n\t\t\tcmd_iocb->cmd_flag &= ~LPFC_IO_ON_TXCMPLQ;\n\t\t\tpring->txcmplq_cnt--;\n\t\t\treturn cmd_iocb;\n\t\t}\n\t}\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0317 iotag x%x is out of \"\n\t\t\t\"range: max iotag x%x\\n\",\n\t\t\tiotag, phba->sli.last_iotag);\n\treturn NULL;\n}\n\n \nstatic struct lpfc_iocbq *\nlpfc_sli_iocbq_lookup_by_tag(struct lpfc_hba *phba,\n\t\t\t     struct lpfc_sli_ring *pring, uint16_t iotag)\n{\n\tstruct lpfc_iocbq *cmd_iocb = NULL;\n\n\tif (iotag != 0 && iotag <= phba->sli.last_iotag) {\n\t\tcmd_iocb = phba->sli.iocbq_lookup[iotag];\n\t\tif (cmd_iocb->cmd_flag & LPFC_IO_ON_TXCMPLQ) {\n\t\t\t \n\t\t\tlist_del_init(&cmd_iocb->list);\n\t\t\tcmd_iocb->cmd_flag &= ~LPFC_IO_ON_TXCMPLQ;\n\t\t\tpring->txcmplq_cnt--;\n\t\t\treturn cmd_iocb;\n\t\t}\n\t}\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0372 iotag x%x lookup error: max iotag (x%x) \"\n\t\t\t\"cmd_flag x%x\\n\",\n\t\t\tiotag, phba->sli.last_iotag,\n\t\t\tcmd_iocb ? cmd_iocb->cmd_flag : 0xffff);\n\treturn NULL;\n}\n\n \nstatic int\nlpfc_sli_process_sol_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t\t  struct lpfc_iocbq *saveq)\n{\n\tstruct lpfc_iocbq *cmdiocbp;\n\tunsigned long iflag;\n\tu32 ulp_command, ulp_status, ulp_word4, ulp_context, iotag;\n\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tspin_lock_irqsave(&pring->ring_lock, iflag);\n\telse\n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tcmdiocbp = lpfc_sli_iocbq_lookup(phba, pring, saveq);\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tspin_unlock_irqrestore(&pring->ring_lock, iflag);\n\telse\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\n\tulp_command = get_job_cmnd(phba, saveq);\n\tulp_status = get_job_ulpstatus(phba, saveq);\n\tulp_word4 = get_job_word4(phba, saveq);\n\tulp_context = get_job_ulpcontext(phba, saveq);\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tiotag = get_wqe_reqtag(saveq);\n\telse\n\t\tiotag = saveq->iocb.ulpIoTag;\n\n\tif (cmdiocbp) {\n\t\tulp_command = get_job_cmnd(phba, cmdiocbp);\n\t\tif (cmdiocbp->cmd_cmpl) {\n\t\t\t \n\t\t\tif (ulp_status &&\n\t\t\t     (pring->ringno == LPFC_ELS_RING) &&\n\t\t\t     (ulp_command == CMD_ELS_REQUEST64_CR))\n\t\t\t\tlpfc_send_els_failure_event(phba,\n\t\t\t\t\tcmdiocbp, saveq);\n\n\t\t\t \n\t\t\tif (pring->ringno == LPFC_ELS_RING) {\n\t\t\t\tif ((phba->sli_rev < LPFC_SLI_REV4) &&\n\t\t\t\t    (cmdiocbp->cmd_flag &\n\t\t\t\t\t\t\tLPFC_DRIVER_ABORTED)) {\n\t\t\t\t\tspin_lock_irqsave(&phba->hbalock,\n\t\t\t\t\t\t\t  iflag);\n\t\t\t\t\tcmdiocbp->cmd_flag &=\n\t\t\t\t\t\t~LPFC_DRIVER_ABORTED;\n\t\t\t\t\tspin_unlock_irqrestore(&phba->hbalock,\n\t\t\t\t\t\t\t       iflag);\n\t\t\t\t\tsaveq->iocb.ulpStatus =\n\t\t\t\t\t\tIOSTAT_LOCAL_REJECT;\n\t\t\t\t\tsaveq->iocb.un.ulpWord[4] =\n\t\t\t\t\t\tIOERR_SLI_ABORTED;\n\n\t\t\t\t\t \n\t\t\t\t\tspin_lock_irqsave(&phba->hbalock,\n\t\t\t\t\t\t\t  iflag);\n\t\t\t\t\tsaveq->cmd_flag |= LPFC_DELAY_MEM_FREE;\n\t\t\t\t\tspin_unlock_irqrestore(&phba->hbalock,\n\t\t\t\t\t\t\t       iflag);\n\t\t\t\t}\n\t\t\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\t\t\tif (saveq->cmd_flag &\n\t\t\t\t\t    LPFC_EXCHANGE_BUSY) {\n\t\t\t\t\t\t \n\t\t\t\t\t\tspin_lock_irqsave(\n\t\t\t\t\t\t\t&phba->hbalock, iflag);\n\t\t\t\t\t\tcmdiocbp->cmd_flag |=\n\t\t\t\t\t\t\tLPFC_EXCHANGE_BUSY;\n\t\t\t\t\t\tspin_unlock_irqrestore(\n\t\t\t\t\t\t\t&phba->hbalock, iflag);\n\t\t\t\t\t}\n\t\t\t\t\tif (cmdiocbp->cmd_flag &\n\t\t\t\t\t    LPFC_DRIVER_ABORTED) {\n\t\t\t\t\t\t \n\t\t\t\t\t\tspin_lock_irqsave(\n\t\t\t\t\t\t\t&phba->hbalock, iflag);\n\t\t\t\t\t\tcmdiocbp->cmd_flag &=\n\t\t\t\t\t\t\t~LPFC_DRIVER_ABORTED;\n\t\t\t\t\t\tspin_unlock_irqrestore(\n\t\t\t\t\t\t\t&phba->hbalock, iflag);\n\t\t\t\t\t\tset_job_ulpstatus(cmdiocbp,\n\t\t\t\t\t\t\t\t  IOSTAT_LOCAL_REJECT);\n\t\t\t\t\t\tset_job_ulpword4(cmdiocbp,\n\t\t\t\t\t\t\t\t IOERR_ABORT_REQUESTED);\n\t\t\t\t\t\t \n\t\t\t\t\t\tset_job_ulpstatus(saveq,\n\t\t\t\t\t\t\t\t  IOSTAT_LOCAL_REJECT);\n\t\t\t\t\t\tset_job_ulpword4(saveq,\n\t\t\t\t\t\t\t\t IOERR_SLI_ABORTED);\n\t\t\t\t\t\tspin_lock_irqsave(\n\t\t\t\t\t\t\t&phba->hbalock, iflag);\n\t\t\t\t\t\tsaveq->cmd_flag |=\n\t\t\t\t\t\t\tLPFC_DELAY_MEM_FREE;\n\t\t\t\t\t\tspin_unlock_irqrestore(\n\t\t\t\t\t\t\t&phba->hbalock, iflag);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcmdiocbp->cmd_cmpl(phba, cmdiocbp, saveq);\n\t\t} else\n\t\t\tlpfc_sli_release_iocbq(phba, cmdiocbp);\n\t} else {\n\t\t \n\t\tif (pring->ringno != LPFC_ELS_RING) {\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\t \"0322 Ring %d handler: \"\n\t\t\t\t\t \"unexpected completion IoTag x%x \"\n\t\t\t\t\t \"Data: x%x x%x x%x x%x\\n\",\n\t\t\t\t\t pring->ringno, iotag, ulp_status,\n\t\t\t\t\t ulp_word4, ulp_command, ulp_context);\n\t\t}\n\t}\n\n\treturn 1;\n}\n\n \nstatic void\nlpfc_sli_rsp_pointers_error(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\n{\n\tstruct lpfc_pgp *pgp = &phba->port_gp[pring->ringno];\n\t \n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0312 Ring %d handler: portRspPut %d \"\n\t\t\t\"is bigger than rsp ring %d\\n\",\n\t\t\tpring->ringno, le32_to_cpu(pgp->rspPutInx),\n\t\t\tpring->sli.sli3.numRiocb);\n\n\tphba->link_state = LPFC_HBA_ERROR;\n\n\t \n\tphba->work_ha |= HA_ERATT;\n\tphba->work_hs = HS_FFER3;\n\n\tlpfc_worker_wake_up(phba);\n\n\treturn;\n}\n\n \nvoid lpfc_poll_eratt(struct timer_list *t)\n{\n\tstruct lpfc_hba *phba;\n\tuint32_t eratt = 0;\n\tuint64_t sli_intr, cnt;\n\n\tphba = from_timer(phba, t, eratt_poll);\n\tif (!(phba->hba_flag & HBA_SETUP))\n\t\treturn;\n\n\t \n\tsli_intr = phba->sli.slistat.sli_intr;\n\n\tif (phba->sli.slistat.sli_prev_intr > sli_intr)\n\t\tcnt = (((uint64_t)(-1) - phba->sli.slistat.sli_prev_intr) +\n\t\t\tsli_intr);\n\telse\n\t\tcnt = (sli_intr - phba->sli.slistat.sli_prev_intr);\n\n\t \n\tdo_div(cnt, phba->eratt_poll_interval);\n\tphba->sli.slistat.sli_ips = cnt;\n\n\tphba->sli.slistat.sli_prev_intr = sli_intr;\n\n\t \n\teratt = lpfc_sli_check_eratt(phba);\n\n\tif (eratt)\n\t\t \n\t\tlpfc_worker_wake_up(phba);\n\telse\n\t\t \n\t\tmod_timer(&phba->eratt_poll,\n\t\t\t  jiffies +\n\t\t\t  msecs_to_jiffies(1000 * phba->eratt_poll_interval));\n\treturn;\n}\n\n\n \nint\nlpfc_sli_handle_fast_ring_event(struct lpfc_hba *phba,\n\t\t\t\tstruct lpfc_sli_ring *pring, uint32_t mask)\n{\n\tstruct lpfc_pgp *pgp = &phba->port_gp[pring->ringno];\n\tIOCB_t *irsp = NULL;\n\tIOCB_t *entry = NULL;\n\tstruct lpfc_iocbq *cmdiocbq = NULL;\n\tstruct lpfc_iocbq rspiocbq;\n\tuint32_t status;\n\tuint32_t portRspPut, portRspMax;\n\tint rc = 1;\n\tlpfc_iocb_type type;\n\tunsigned long iflag;\n\tuint32_t rsp_cmpl = 0;\n\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tpring->stats.iocb_event++;\n\n\t \n\tportRspMax = pring->sli.sli3.numRiocb;\n\tportRspPut = le32_to_cpu(pgp->rspPutInx);\n\tif (unlikely(portRspPut >= portRspMax)) {\n\t\tlpfc_sli_rsp_pointers_error(phba, pring);\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\treturn 1;\n\t}\n\tif (phba->fcp_ring_in_use) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\treturn 1;\n\t} else\n\t\tphba->fcp_ring_in_use = 1;\n\n\trmb();\n\twhile (pring->sli.sli3.rspidx != portRspPut) {\n\t\t \n\t\tentry = lpfc_resp_iocb(phba, pring);\n\t\tphba->last_completion_time = jiffies;\n\n\t\tif (++pring->sli.sli3.rspidx >= portRspMax)\n\t\t\tpring->sli.sli3.rspidx = 0;\n\n\t\tlpfc_sli_pcimem_bcopy((uint32_t *) entry,\n\t\t\t\t      (uint32_t *) &rspiocbq.iocb,\n\t\t\t\t      phba->iocb_rsp_size);\n\t\tINIT_LIST_HEAD(&(rspiocbq.list));\n\t\tirsp = &rspiocbq.iocb;\n\n\t\ttype = lpfc_sli_iocb_cmd_type(irsp->ulpCommand & CMD_IOCB_MASK);\n\t\tpring->stats.iocb_rsp++;\n\t\trsp_cmpl++;\n\n\t\tif (unlikely(irsp->ulpStatus)) {\n\t\t\t \n\t\t\tif ((irsp->ulpStatus == IOSTAT_LOCAL_REJECT) &&\n\t\t\t    ((irsp->un.ulpWord[4] & IOERR_PARAM_MASK) ==\n\t\t\t     IOERR_NO_RESOURCES)) {\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\t\tphba->lpfc_rampdown_queue_depth(phba);\n\t\t\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\t\t}\n\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\t\"0336 Rsp Ring %d error: IOCB Data: \"\n\t\t\t\t\t\"x%x x%x x%x x%x x%x x%x x%x x%x\\n\",\n\t\t\t\t\tpring->ringno,\n\t\t\t\t\tirsp->un.ulpWord[0],\n\t\t\t\t\tirsp->un.ulpWord[1],\n\t\t\t\t\tirsp->un.ulpWord[2],\n\t\t\t\t\tirsp->un.ulpWord[3],\n\t\t\t\t\tirsp->un.ulpWord[4],\n\t\t\t\t\tirsp->un.ulpWord[5],\n\t\t\t\t\t*(uint32_t *)&irsp->un1,\n\t\t\t\t\t*((uint32_t *)&irsp->un1 + 1));\n\t\t}\n\n\t\tswitch (type) {\n\t\tcase LPFC_ABORT_IOCB:\n\t\tcase LPFC_SOL_IOCB:\n\t\t\t \n\t\t\tif (unlikely(irsp->ulpCommand == CMD_XRI_ABORTED_CX)) {\n\t\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\t\t\"0333 IOCB cmd 0x%x\"\n\t\t\t\t\t\t\" processed. Skipping\"\n\t\t\t\t\t\t\" completion\\n\",\n\t\t\t\t\t\tirsp->ulpCommand);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tcmdiocbq = lpfc_sli_iocbq_lookup(phba, pring,\n\t\t\t\t\t\t\t &rspiocbq);\n\t\t\tif (unlikely(!cmdiocbq))\n\t\t\t\tbreak;\n\t\t\tif (cmdiocbq->cmd_flag & LPFC_DRIVER_ABORTED)\n\t\t\t\tcmdiocbq->cmd_flag &= ~LPFC_DRIVER_ABORTED;\n\t\t\tif (cmdiocbq->cmd_cmpl) {\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\t\tcmdiocbq->cmd_cmpl(phba, cmdiocbq, &rspiocbq);\n\t\t\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase LPFC_UNSOL_IOCB:\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\tlpfc_sli_process_unsol_iocb(phba, pring, &rspiocbq);\n\t\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (irsp->ulpCommand == CMD_ADAPTER_MSG) {\n\t\t\t\tchar adaptermsg[LPFC_MAX_ADPTMSG];\n\t\t\t\tmemset(adaptermsg, 0, LPFC_MAX_ADPTMSG);\n\t\t\t\tmemcpy(&adaptermsg[0], (uint8_t *) irsp,\n\t\t\t\t       MAX_MSG_DATA);\n\t\t\t\tdev_warn(&((phba->pcidev)->dev),\n\t\t\t\t\t \"lpfc%d: %s\\n\",\n\t\t\t\t\t phba->brd_no, adaptermsg);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"0334 Unknown IOCB command \"\n\t\t\t\t\t\t\"Data: x%x, x%x x%x x%x x%x\\n\",\n\t\t\t\t\t\ttype, irsp->ulpCommand,\n\t\t\t\t\t\tirsp->ulpStatus,\n\t\t\t\t\t\tirsp->ulpIoTag,\n\t\t\t\t\t\tirsp->ulpContext);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\twritel(pring->sli.sli3.rspidx,\n\t\t\t&phba->host_gp[pring->ringno].rspGetInx);\n\n\t\tif (pring->sli.sli3.rspidx == portRspPut)\n\t\t\tportRspPut = le32_to_cpu(pgp->rspPutInx);\n\t}\n\n\tif ((rsp_cmpl > 0) && (mask & HA_R0RE_REQ)) {\n\t\tpring->stats.iocb_rsp_full++;\n\t\tstatus = ((CA_R0ATT | CA_R0RE_RSP) << (pring->ringno * 4));\n\t\twritel(status, phba->CAregaddr);\n\t\treadl(phba->CAregaddr);\n\t}\n\tif ((mask & HA_R0CE_RSP) && (pring->flag & LPFC_CALL_RING_AVAILABLE)) {\n\t\tpring->flag &= ~LPFC_CALL_RING_AVAILABLE;\n\t\tpring->stats.iocb_cmd_empty++;\n\n\t\t \n\t\tpring->sli.sli3.local_getidx = le32_to_cpu(pgp->cmdGetInx);\n\t\tlpfc_sli_resume_iocb(phba, pring);\n\n\t\tif ((pring->lpfc_sli_cmd_available))\n\t\t\t(pring->lpfc_sli_cmd_available) (phba, pring);\n\n\t}\n\n\tphba->fcp_ring_in_use = 0;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\treturn rc;\n}\n\n \nstatic struct lpfc_iocbq *\nlpfc_sli_sp_handle_rspiocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t\tstruct lpfc_iocbq *rspiocbp)\n{\n\tstruct lpfc_iocbq *saveq;\n\tstruct lpfc_iocbq *cmdiocb;\n\tstruct lpfc_iocbq *next_iocb;\n\tIOCB_t *irsp;\n\tuint32_t free_saveq;\n\tu8 cmd_type;\n\tlpfc_iocb_type type;\n\tunsigned long iflag;\n\tu32 ulp_status = get_job_ulpstatus(phba, rspiocbp);\n\tu32 ulp_word4 = get_job_word4(phba, rspiocbp);\n\tu32 ulp_command = get_job_cmnd(phba, rspiocbp);\n\tint rc;\n\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t \n\tlist_add_tail(&rspiocbp->list, &pring->iocb_continueq);\n\tpring->iocb_continueq_cnt++;\n\n\t \n\tfree_saveq = 1;\n\tsaveq = list_get_first(&pring->iocb_continueq,\n\t\t\t       struct lpfc_iocbq, list);\n\tlist_del_init(&pring->iocb_continueq);\n\tpring->iocb_continueq_cnt = 0;\n\n\tpring->stats.iocb_rsp++;\n\n\t \n\tif (ulp_status == IOSTAT_LOCAL_REJECT &&\n\t    ((ulp_word4 & IOERR_PARAM_MASK) ==\n\t     IOERR_NO_RESOURCES)) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\tphba->lpfc_rampdown_queue_depth(phba);\n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t}\n\n\tif (ulp_status) {\n\t\t \n\t\tif (phba->sli_rev < LPFC_SLI_REV4) {\n\t\t\tirsp = &rspiocbp->iocb;\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\t\"0328 Rsp Ring %d error: ulp_status x%x \"\n\t\t\t\t\t\"IOCB Data: \"\n\t\t\t\t\t\"x%08x x%08x x%08x x%08x \"\n\t\t\t\t\t\"x%08x x%08x x%08x x%08x \"\n\t\t\t\t\t\"x%08x x%08x x%08x x%08x \"\n\t\t\t\t\t\"x%08x x%08x x%08x x%08x\\n\",\n\t\t\t\t\tpring->ringno, ulp_status,\n\t\t\t\t\tget_job_ulpword(rspiocbp, 0),\n\t\t\t\t\tget_job_ulpword(rspiocbp, 1),\n\t\t\t\t\tget_job_ulpword(rspiocbp, 2),\n\t\t\t\t\tget_job_ulpword(rspiocbp, 3),\n\t\t\t\t\tget_job_ulpword(rspiocbp, 4),\n\t\t\t\t\tget_job_ulpword(rspiocbp, 5),\n\t\t\t\t\t*(((uint32_t *)irsp) + 6),\n\t\t\t\t\t*(((uint32_t *)irsp) + 7),\n\t\t\t\t\t*(((uint32_t *)irsp) + 8),\n\t\t\t\t\t*(((uint32_t *)irsp) + 9),\n\t\t\t\t\t*(((uint32_t *)irsp) + 10),\n\t\t\t\t\t*(((uint32_t *)irsp) + 11),\n\t\t\t\t\t*(((uint32_t *)irsp) + 12),\n\t\t\t\t\t*(((uint32_t *)irsp) + 13),\n\t\t\t\t\t*(((uint32_t *)irsp) + 14),\n\t\t\t\t\t*(((uint32_t *)irsp) + 15));\n\t\t} else {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\t\"0321 Rsp Ring %d error: \"\n\t\t\t\t\t\"IOCB Data: \"\n\t\t\t\t\t\"x%x x%x x%x x%x\\n\",\n\t\t\t\t\tpring->ringno,\n\t\t\t\t\trspiocbp->wcqe_cmpl.word0,\n\t\t\t\t\trspiocbp->wcqe_cmpl.total_data_placed,\n\t\t\t\t\trspiocbp->wcqe_cmpl.parameter,\n\t\t\t\t\trspiocbp->wcqe_cmpl.word3);\n\t\t}\n\t}\n\n\n\t \n\tcmd_type = ulp_command & CMD_IOCB_MASK;\n\ttype = lpfc_sli_iocb_cmd_type(cmd_type);\n\tswitch (type) {\n\tcase LPFC_SOL_IOCB:\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\trc = lpfc_sli_process_sol_iocb(phba, pring, saveq);\n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\tbreak;\n\tcase LPFC_UNSOL_IOCB:\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\trc = lpfc_sli_process_unsol_iocb(phba, pring, saveq);\n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\tif (!rc)\n\t\t\tfree_saveq = 0;\n\t\tbreak;\n\tcase LPFC_ABORT_IOCB:\n\t\tcmdiocb = NULL;\n\t\tif (ulp_command != CMD_XRI_ABORTED_CX)\n\t\t\tcmdiocb = lpfc_sli_iocbq_lookup(phba, pring,\n\t\t\t\t\t\t\tsaveq);\n\t\tif (cmdiocb) {\n\t\t\t \n\t\t\tif (cmdiocb->cmd_cmpl) {\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\t\tcmdiocb->cmd_cmpl(phba, cmdiocb, saveq);\n\t\t\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\t\t} else {\n\t\t\t\t__lpfc_sli_release_iocbq(phba, cmdiocb);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase LPFC_UNKNOWN_IOCB:\n\t\tif (ulp_command == CMD_ADAPTER_MSG) {\n\t\t\tchar adaptermsg[LPFC_MAX_ADPTMSG];\n\n\t\t\tmemset(adaptermsg, 0, LPFC_MAX_ADPTMSG);\n\t\t\tmemcpy(&adaptermsg[0], (uint8_t *)&rspiocbp->wqe,\n\t\t\t       MAX_MSG_DATA);\n\t\t\tdev_warn(&((phba->pcidev)->dev),\n\t\t\t\t \"lpfc%d: %s\\n\",\n\t\t\t\t phba->brd_no, adaptermsg);\n\t\t} else {\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0335 Unknown IOCB \"\n\t\t\t\t\t\"command Data: x%x \"\n\t\t\t\t\t\"x%x x%x x%x\\n\",\n\t\t\t\t\tulp_command,\n\t\t\t\t\tulp_status,\n\t\t\t\t\tget_wqe_reqtag(rspiocbp),\n\t\t\t\t\tget_job_ulpcontext(phba, rspiocbp));\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (free_saveq) {\n\t\tlist_for_each_entry_safe(rspiocbp, next_iocb,\n\t\t\t\t\t &saveq->list, list) {\n\t\t\tlist_del_init(&rspiocbp->list);\n\t\t\t__lpfc_sli_release_iocbq(phba, rspiocbp);\n\t\t}\n\t\t__lpfc_sli_release_iocbq(phba, saveq);\n\t}\n\trspiocbp = NULL;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\treturn rspiocbp;\n}\n\n \nvoid\nlpfc_sli_handle_slow_ring_event(struct lpfc_hba *phba,\n\t\t\t\tstruct lpfc_sli_ring *pring, uint32_t mask)\n{\n\tphba->lpfc_sli_handle_slow_ring_event(phba, pring, mask);\n}\n\n \nstatic void\nlpfc_sli_handle_slow_ring_event_s3(struct lpfc_hba *phba,\n\t\t\t\t   struct lpfc_sli_ring *pring, uint32_t mask)\n{\n\tstruct lpfc_pgp *pgp;\n\tIOCB_t *entry;\n\tIOCB_t *irsp = NULL;\n\tstruct lpfc_iocbq *rspiocbp = NULL;\n\tuint32_t portRspPut, portRspMax;\n\tunsigned long iflag;\n\tuint32_t status;\n\n\tpgp = &phba->port_gp[pring->ringno];\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tpring->stats.iocb_event++;\n\n\t \n\tportRspMax = pring->sli.sli3.numRiocb;\n\tportRspPut = le32_to_cpu(pgp->rspPutInx);\n\tif (portRspPut >= portRspMax) {\n\t\t \n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0303 Ring %d handler: portRspPut %d \"\n\t\t\t\t\"is bigger than rsp ring %d\\n\",\n\t\t\t\tpring->ringno, portRspPut, portRspMax);\n\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\n\t\tphba->work_hs = HS_FFER3;\n\t\tlpfc_handle_eratt(phba);\n\n\t\treturn;\n\t}\n\n\trmb();\n\twhile (pring->sli.sli3.rspidx != portRspPut) {\n\t\t \n\t\tentry = lpfc_resp_iocb(phba, pring);\n\n\t\tphba->last_completion_time = jiffies;\n\t\trspiocbp = __lpfc_sli_get_iocbq(phba);\n\t\tif (rspiocbp == NULL) {\n\t\t\tprintk(KERN_ERR \"%s: out of buffers! Failing \"\n\t\t\t       \"completion.\\n\", __func__);\n\t\t\tbreak;\n\t\t}\n\n\t\tlpfc_sli_pcimem_bcopy(entry, &rspiocbp->iocb,\n\t\t\t\t      phba->iocb_rsp_size);\n\t\tirsp = &rspiocbp->iocb;\n\n\t\tif (++pring->sli.sli3.rspidx >= portRspMax)\n\t\t\tpring->sli.sli3.rspidx = 0;\n\n\t\tif (pring->ringno == LPFC_ELS_RING) {\n\t\t\tlpfc_debugfs_slow_ring_trc(phba,\n\t\t\t\"IOCB rsp ring:   wd4:x%08x wd6:x%08x wd7:x%08x\",\n\t\t\t\t*(((uint32_t *) irsp) + 4),\n\t\t\t\t*(((uint32_t *) irsp) + 6),\n\t\t\t\t*(((uint32_t *) irsp) + 7));\n\t\t}\n\n\t\twritel(pring->sli.sli3.rspidx,\n\t\t\t&phba->host_gp[pring->ringno].rspGetInx);\n\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t \n\t\trspiocbp = lpfc_sli_sp_handle_rspiocb(phba, pring, rspiocbp);\n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\n\t\t \n\t\tif (pring->sli.sli3.rspidx == portRspPut) {\n\t\t\tportRspPut = le32_to_cpu(pgp->rspPutInx);\n\t\t}\n\t}  \n\n\tif ((rspiocbp != NULL) && (mask & HA_R0RE_REQ)) {\n\t\t \n\t\tpring->stats.iocb_rsp_full++;\n\t\t \n\t\tstatus = ((CA_R0ATT | CA_R0RE_RSP) << (pring->ringno * 4));\n\t\twritel(status, phba->CAregaddr);\n\t\treadl(phba->CAregaddr);  \n\t}\n\tif ((mask & HA_R0CE_RSP) && (pring->flag & LPFC_CALL_RING_AVAILABLE)) {\n\t\tpring->flag &= ~LPFC_CALL_RING_AVAILABLE;\n\t\tpring->stats.iocb_cmd_empty++;\n\n\t\t \n\t\tpring->sli.sli3.local_getidx = le32_to_cpu(pgp->cmdGetInx);\n\t\tlpfc_sli_resume_iocb(phba, pring);\n\n\t\tif ((pring->lpfc_sli_cmd_available))\n\t\t\t(pring->lpfc_sli_cmd_available) (phba, pring);\n\n\t}\n\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\treturn;\n}\n\n \nstatic void\nlpfc_sli_handle_slow_ring_event_s4(struct lpfc_hba *phba,\n\t\t\t\t   struct lpfc_sli_ring *pring, uint32_t mask)\n{\n\tstruct lpfc_iocbq *irspiocbq;\n\tstruct hbq_dmabuf *dmabuf;\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflag;\n\tint count = 0;\n\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tphba->hba_flag &= ~HBA_SP_QUEUE_EVT;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\twhile (!list_empty(&phba->sli4_hba.sp_queue_event)) {\n\t\t \n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\tlist_remove_head(&phba->sli4_hba.sp_queue_event,\n\t\t\t\t cq_event, struct lpfc_cq_event, list);\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\n\t\tswitch (bf_get(lpfc_wcqe_c_code, &cq_event->cqe.wcqe_cmpl)) {\n\t\tcase CQE_CODE_COMPL_WQE:\n\t\t\tirspiocbq = container_of(cq_event, struct lpfc_iocbq,\n\t\t\t\t\t\t cq_event);\n\t\t\t \n\t\t\tirspiocbq = lpfc_sli4_els_preprocess_rspiocbq(phba,\n\t\t\t\t\t\t\t\t      irspiocbq);\n\t\t\tif (irspiocbq)\n\t\t\t\tlpfc_sli_sp_handle_rspiocb(phba, pring,\n\t\t\t\t\t\t\t   irspiocbq);\n\t\t\tcount++;\n\t\t\tbreak;\n\t\tcase CQE_CODE_RECEIVE:\n\t\tcase CQE_CODE_RECEIVE_V1:\n\t\t\tdmabuf = container_of(cq_event, struct hbq_dmabuf,\n\t\t\t\t\t      cq_event);\n\t\t\tlpfc_sli4_handle_received_buffer(phba, dmabuf);\n\t\t\tcount++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (count == 64)\n\t\t\tbreak;\n\t}\n}\n\n \nvoid\nlpfc_sli_abort_iocb_ring(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\n{\n\tLIST_HEAD(tx_completions);\n\tLIST_HEAD(txcmplq_completions);\n\tstruct lpfc_iocbq *iocb, *next_iocb;\n\tint offline;\n\n\tif (pring->ringno == LPFC_ELS_RING) {\n\t\tlpfc_fabric_abort_hba(phba);\n\t}\n\toffline = pci_channel_offline(phba->pcidev);\n\n\t \n\tif (phba->sli_rev >= LPFC_SLI_REV4) {\n\t\tspin_lock_irq(&pring->ring_lock);\n\t\tlist_splice_init(&pring->txq, &tx_completions);\n\t\tpring->txq_cnt = 0;\n\n\t\tif (offline) {\n\t\t\tlist_splice_init(&pring->txcmplq,\n\t\t\t\t\t &txcmplq_completions);\n\t\t} else {\n\t\t\t \n\t\t\tlist_for_each_entry_safe(iocb, next_iocb,\n\t\t\t\t\t\t &pring->txcmplq, list)\n\t\t\t\tlpfc_sli_issue_abort_iotag(phba, pring,\n\t\t\t\t\t\t\t   iocb, NULL);\n\t\t}\n\t\tspin_unlock_irq(&pring->ring_lock);\n\t} else {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tlist_splice_init(&pring->txq, &tx_completions);\n\t\tpring->txq_cnt = 0;\n\n\t\tif (offline) {\n\t\t\tlist_splice_init(&pring->txcmplq, &txcmplq_completions);\n\t\t} else {\n\t\t\t \n\t\t\tlist_for_each_entry_safe(iocb, next_iocb,\n\t\t\t\t\t\t &pring->txcmplq, list)\n\t\t\t\tlpfc_sli_issue_abort_iotag(phba, pring,\n\t\t\t\t\t\t\t   iocb, NULL);\n\t\t}\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\n\tif (offline) {\n\t\t \n\t\tlpfc_sli_cancel_iocbs(phba, &txcmplq_completions,\n\t\t\t\t      IOSTAT_LOCAL_REJECT, IOERR_SLI_ABORTED);\n\t} else {\n\t\t \n\t\tlpfc_issue_hb_tmo(phba);\n\t}\n\t \n\tlpfc_sli_cancel_iocbs(phba, &tx_completions, IOSTAT_LOCAL_REJECT,\n\t\t\t      IOERR_SLI_ABORTED);\n}\n\n \nvoid\nlpfc_sli_abort_fcp_rings(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_sli_ring  *pring;\n\tuint32_t i;\n\n\t \n\tif (phba->sli_rev >= LPFC_SLI_REV4) {\n\t\tfor (i = 0; i < phba->cfg_hdw_queue; i++) {\n\t\t\tpring = phba->sli4_hba.hdwq[i].io_wq->pring;\n\t\t\tlpfc_sli_abort_iocb_ring(phba, pring);\n\t\t}\n\t} else {\n\t\tpring = &psli->sli3_ring[LPFC_FCP_RING];\n\t\tlpfc_sli_abort_iocb_ring(phba, pring);\n\t}\n}\n\n \nvoid\nlpfc_sli_flush_io_rings(struct lpfc_hba *phba)\n{\n\tLIST_HEAD(txq);\n\tLIST_HEAD(txcmplq);\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_sli_ring  *pring;\n\tuint32_t i;\n\tstruct lpfc_iocbq *piocb, *next_iocb;\n\n\tspin_lock_irq(&phba->hbalock);\n\t \n\tphba->hba_flag |= HBA_IOQ_FLUSH;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tif (phba->sli_rev >= LPFC_SLI_REV4) {\n\t\tfor (i = 0; i < phba->cfg_hdw_queue; i++) {\n\t\t\tpring = phba->sli4_hba.hdwq[i].io_wq->pring;\n\n\t\t\tspin_lock_irq(&pring->ring_lock);\n\t\t\t \n\t\t\tlist_splice_init(&pring->txq, &txq);\n\t\t\tlist_for_each_entry_safe(piocb, next_iocb,\n\t\t\t\t\t\t &pring->txcmplq, list)\n\t\t\t\tpiocb->cmd_flag &= ~LPFC_IO_ON_TXCMPLQ;\n\t\t\t \n\t\t\tlist_splice_init(&pring->txcmplq, &txcmplq);\n\t\t\tpring->txq_cnt = 0;\n\t\t\tpring->txcmplq_cnt = 0;\n\t\t\tspin_unlock_irq(&pring->ring_lock);\n\n\t\t\t \n\t\t\tlpfc_sli_cancel_iocbs(phba, &txq,\n\t\t\t\t\t      IOSTAT_LOCAL_REJECT,\n\t\t\t\t\t      IOERR_SLI_DOWN);\n\t\t\t \n\t\t\tlpfc_sli_cancel_iocbs(phba, &txcmplq,\n\t\t\t\t\t      IOSTAT_LOCAL_REJECT,\n\t\t\t\t\t      IOERR_SLI_DOWN);\n\t\t\tif (unlikely(pci_channel_offline(phba->pcidev)))\n\t\t\t\tlpfc_sli4_io_xri_aborted(phba, NULL, 0);\n\t\t}\n\t} else {\n\t\tpring = &psli->sli3_ring[LPFC_FCP_RING];\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\t \n\t\tlist_splice_init(&pring->txq, &txq);\n\t\tlist_for_each_entry_safe(piocb, next_iocb,\n\t\t\t\t\t &pring->txcmplq, list)\n\t\t\tpiocb->cmd_flag &= ~LPFC_IO_ON_TXCMPLQ;\n\t\t \n\t\tlist_splice_init(&pring->txcmplq, &txcmplq);\n\t\tpring->txq_cnt = 0;\n\t\tpring->txcmplq_cnt = 0;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t \n\t\tlpfc_sli_cancel_iocbs(phba, &txq, IOSTAT_LOCAL_REJECT,\n\t\t\t\t      IOERR_SLI_DOWN);\n\t\t \n\t\tlpfc_sli_cancel_iocbs(phba, &txcmplq, IOSTAT_LOCAL_REJECT,\n\t\t\t\t      IOERR_SLI_DOWN);\n\t}\n}\n\n \nstatic int\nlpfc_sli_brdready_s3(struct lpfc_hba *phba, uint32_t mask)\n{\n\tuint32_t status;\n\tint i = 0;\n\tint retval = 0;\n\n\t \n\tif (lpfc_readl(phba->HSregaddr, &status))\n\t\treturn 1;\n\n\tphba->hba_flag |= HBA_NEEDS_CFG_PORT;\n\n\t \n\twhile (((status & mask) != mask) &&\n\t       !(status & HS_FFERM) &&\n\t       i++ < 20) {\n\n\t\tif (i <= 5)\n\t\t\tmsleep(10);\n\t\telse if (i <= 10)\n\t\t\tmsleep(500);\n\t\telse\n\t\t\tmsleep(2500);\n\n\t\tif (i == 15) {\n\t\t\t\t \n\t\t\tphba->pport->port_state = LPFC_VPORT_UNKNOWN;\n\t\t\tlpfc_sli_brdrestart(phba);\n\t\t}\n\t\t \n\t\tif (lpfc_readl(phba->HSregaddr, &status)) {\n\t\t\tretval = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif ((status & HS_FFERM) || (i >= 20)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2751 Adapter failed to restart, \"\n\t\t\t\t\"status reg x%x, FW Data: A8 x%x AC x%x\\n\",\n\t\t\t\tstatus,\n\t\t\t\treadl(phba->MBslimaddr + 0xa8),\n\t\t\t\treadl(phba->MBslimaddr + 0xac));\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tretval = 1;\n\t}\n\n\treturn retval;\n}\n\n \nstatic int\nlpfc_sli_brdready_s4(struct lpfc_hba *phba, uint32_t mask)\n{\n\tuint32_t status;\n\tint retval = 0;\n\n\t \n\tstatus = lpfc_sli4_post_status_check(phba);\n\n\tif (status) {\n\t\tphba->pport->port_state = LPFC_VPORT_UNKNOWN;\n\t\tlpfc_sli_brdrestart(phba);\n\t\tstatus = lpfc_sli4_post_status_check(phba);\n\t}\n\n\t \n\tif (status) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tretval = 1;\n\t} else\n\t\tphba->sli4_hba.intr_enable = 0;\n\n\tphba->hba_flag &= ~HBA_SETUP;\n\treturn retval;\n}\n\n \nint\nlpfc_sli_brdready(struct lpfc_hba *phba, uint32_t mask)\n{\n\treturn phba->lpfc_sli_brdready(phba, mask);\n}\n\n#define BARRIER_TEST_PATTERN (0xdeadbeef)\n\n \nvoid lpfc_reset_barrier(struct lpfc_hba *phba)\n{\n\tuint32_t __iomem *resp_buf;\n\tuint32_t __iomem *mbox_buf;\n\tvolatile struct MAILBOX_word0 mbox;\n\tuint32_t hc_copy, ha_copy, resp_data;\n\tint  i;\n\tuint8_t hdrtype;\n\n\tlockdep_assert_held(&phba->hbalock);\n\n\tpci_read_config_byte(phba->pcidev, PCI_HEADER_TYPE, &hdrtype);\n\tif (hdrtype != 0x80 ||\n\t    (FC_JEDEC_ID(phba->vpd.rev.biuRev) != HELIOS_JEDEC_ID &&\n\t     FC_JEDEC_ID(phba->vpd.rev.biuRev) != THOR_JEDEC_ID))\n\t\treturn;\n\n\t \n\tresp_buf = phba->MBslimaddr;\n\n\t \n\tif (lpfc_readl(phba->HCregaddr, &hc_copy))\n\t\treturn;\n\twritel((hc_copy & ~HC_ERINT_ENA), phba->HCregaddr);\n\treadl(phba->HCregaddr);  \n\tphba->link_flag |= LS_IGNORE_ERATT;\n\n\tif (lpfc_readl(phba->HAregaddr, &ha_copy))\n\t\treturn;\n\tif (ha_copy & HA_ERATT) {\n\t\t \n\t\twritel(HA_ERATT, phba->HAregaddr);\n\t\tphba->pport->stopped = 1;\n\t}\n\n\tmbox.word0 = 0;\n\tmbox.mbxCommand = MBX_KILL_BOARD;\n\tmbox.mbxOwner = OWN_CHIP;\n\n\twritel(BARRIER_TEST_PATTERN, (resp_buf + 1));\n\tmbox_buf = phba->MBslimaddr;\n\twritel(mbox.word0, mbox_buf);\n\n\tfor (i = 0; i < 50; i++) {\n\t\tif (lpfc_readl((resp_buf + 1), &resp_data))\n\t\t\treturn;\n\t\tif (resp_data != ~(BARRIER_TEST_PATTERN))\n\t\t\tmdelay(1);\n\t\telse\n\t\t\tbreak;\n\t}\n\tresp_data = 0;\n\tif (lpfc_readl((resp_buf + 1), &resp_data))\n\t\treturn;\n\tif (resp_data  != ~(BARRIER_TEST_PATTERN)) {\n\t\tif (phba->sli.sli_flag & LPFC_SLI_ACTIVE ||\n\t\t    phba->pport->stopped)\n\t\t\tgoto restore_hc;\n\t\telse\n\t\t\tgoto clear_errat;\n\t}\n\n\tmbox.mbxOwner = OWN_HOST;\n\tresp_data = 0;\n\tfor (i = 0; i < 500; i++) {\n\t\tif (lpfc_readl(resp_buf, &resp_data))\n\t\t\treturn;\n\t\tif (resp_data != mbox.word0)\n\t\t\tmdelay(1);\n\t\telse\n\t\t\tbreak;\n\t}\n\nclear_errat:\n\n\twhile (++i < 500) {\n\t\tif (lpfc_readl(phba->HAregaddr, &ha_copy))\n\t\t\treturn;\n\t\tif (!(ha_copy & HA_ERATT))\n\t\t\tmdelay(1);\n\t\telse\n\t\t\tbreak;\n\t}\n\n\tif (readl(phba->HAregaddr) & HA_ERATT) {\n\t\twritel(HA_ERATT, phba->HAregaddr);\n\t\tphba->pport->stopped = 1;\n\t}\n\nrestore_hc:\n\tphba->link_flag &= ~LS_IGNORE_ERATT;\n\twritel(hc_copy, phba->HCregaddr);\n\treadl(phba->HCregaddr);  \n}\n\n \nint\nlpfc_sli_brdkill(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli;\n\tLPFC_MBOXQ_t *pmb;\n\tuint32_t status;\n\tuint32_t ha_copy;\n\tint retval;\n\tint i = 0;\n\n\tpsli = &phba->sli;\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"0329 Kill HBA Data: x%x x%x\\n\",\n\t\t\tphba->pport->port_state, psli->sli_flag);\n\n\tpmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb)\n\t\treturn 1;\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tif (lpfc_readl(phba->HCregaddr, &status)) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn 1;\n\t}\n\tstatus &= ~HC_ERINT_ENA;\n\twritel(status, phba->HCregaddr);\n\treadl(phba->HCregaddr);  \n\tphba->link_flag |= LS_IGNORE_ERATT;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_kill_board(phba, pmb);\n\tpmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\tretval = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\n\tif (retval != MBX_SUCCESS) {\n\t\tif (retval != MBX_BUSY)\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2752 KILL_BOARD command failed retval %d\\n\",\n\t\t\t\tretval);\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->link_flag &= ~LS_IGNORE_ERATT;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn 1;\n\t}\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\n\t \n\tif (lpfc_readl(phba->HAregaddr, &ha_copy))\n\t\treturn 1;\n\twhile ((i++ < 30) && !(ha_copy & HA_ERATT)) {\n\t\tmdelay(100);\n\t\tif (lpfc_readl(phba->HAregaddr, &ha_copy))\n\t\t\treturn 1;\n\t}\n\n\tdel_timer_sync(&psli->mbox_tmo);\n\tif (ha_copy & HA_ERATT) {\n\t\twritel(HA_ERATT, phba->HAregaddr);\n\t\tphba->pport->stopped = 1;\n\t}\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\tpsli->mbox_active = NULL;\n\tphba->link_flag &= ~LS_IGNORE_ERATT;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_hba_down_post(phba);\n\tphba->link_state = LPFC_HBA_ERROR;\n\n\treturn ha_copy & HA_ERATT ? 0 : 1;\n}\n\n \nint\nlpfc_sli_brdreset(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli;\n\tstruct lpfc_sli_ring *pring;\n\tuint16_t cfg_value;\n\tint i;\n\n\tpsli = &phba->sli;\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"0325 Reset HBA Data: x%x x%x\\n\",\n\t\t\t(phba->pport) ? phba->pport->port_state : 0,\n\t\t\tpsli->sli_flag);\n\n\t \n\tphba->fc_eventTag = 0;\n\tphba->link_events = 0;\n\tphba->hba_flag |= HBA_NEEDS_CFG_PORT;\n\tif (phba->pport) {\n\t\tphba->pport->fc_myDID = 0;\n\t\tphba->pport->fc_prevDID = 0;\n\t}\n\n\t \n\tif (pci_read_config_word(phba->pcidev, PCI_COMMAND, &cfg_value))\n\t\treturn -EIO;\n\n\tpci_write_config_word(phba->pcidev, PCI_COMMAND,\n\t\t\t      (cfg_value &\n\t\t\t       ~(PCI_COMMAND_PARITY | PCI_COMMAND_SERR)));\n\n\tpsli->sli_flag &= ~(LPFC_SLI_ACTIVE | LPFC_PROCESS_LA);\n\n\t \n\twritel(HC_INITFF, phba->HCregaddr);\n\tmdelay(1);\n\treadl(phba->HCregaddr);  \n\twritel(0, phba->HCregaddr);\n\treadl(phba->HCregaddr);  \n\n\t \n\tpci_write_config_word(phba->pcidev, PCI_COMMAND, cfg_value);\n\n\t \n\tfor (i = 0; i < psli->num_rings; i++) {\n\t\tpring = &psli->sli3_ring[i];\n\t\tpring->flag = 0;\n\t\tpring->sli.sli3.rspidx = 0;\n\t\tpring->sli.sli3.next_cmdidx  = 0;\n\t\tpring->sli.sli3.local_getidx = 0;\n\t\tpring->sli.sli3.cmdidx = 0;\n\t\tpring->missbufcnt = 0;\n\t}\n\n\tphba->link_state = LPFC_WARM_START;\n\treturn 0;\n}\n\n \nint\nlpfc_sli4_brdreset(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tuint16_t cfg_value;\n\tint rc = 0;\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"0295 Reset HBA Data: x%x x%x x%x\\n\",\n\t\t\tphba->pport->port_state, psli->sli_flag,\n\t\t\tphba->hba_flag);\n\n\t \n\tphba->fc_eventTag = 0;\n\tphba->link_events = 0;\n\tphba->pport->fc_myDID = 0;\n\tphba->pport->fc_prevDID = 0;\n\tphba->hba_flag &= ~HBA_SETUP;\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~(LPFC_PROCESS_LA);\n\tphba->fcf.fcf_flag = 0;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0389 Performing PCI function reset!\\n\");\n\n\t \n\tif (pci_read_config_word(phba->pcidev, PCI_COMMAND, &cfg_value)) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3205 PCI read Config failed\\n\");\n\t\treturn -EIO;\n\t}\n\n\tpci_write_config_word(phba->pcidev, PCI_COMMAND, (cfg_value &\n\t\t\t      ~(PCI_COMMAND_PARITY | PCI_COMMAND_SERR)));\n\n\t \n\trc = lpfc_pci_function_reset(phba);\n\n\t \n\tpci_write_config_word(phba->pcidev, PCI_COMMAND, cfg_value);\n\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli_brdrestart_s3(struct lpfc_hba *phba)\n{\n\tvolatile struct MAILBOX_word0 mb;\n\tstruct lpfc_sli *psli;\n\tvoid __iomem *to_slim;\n\n\tspin_lock_irq(&phba->hbalock);\n\n\tpsli = &phba->sli;\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"0337 Restart HBA Data: x%x x%x\\n\",\n\t\t\t(phba->pport) ? phba->pport->port_state : 0,\n\t\t\tpsli->sli_flag);\n\n\tmb.word0 = 0;\n\tmb.mbxCommand = MBX_RESTART;\n\tmb.mbxHc = 1;\n\n\tlpfc_reset_barrier(phba);\n\n\tto_slim = phba->MBslimaddr;\n\twritel(mb.word0, to_slim);\n\treadl(to_slim);  \n\n\t \n\tif (phba->pport && phba->pport->port_state)\n\t\tmb.word0 = 1;\t \n\telse\n\t\tmb.word0 = 0;\t \n\tto_slim = phba->MBslimaddr + sizeof (uint32_t);\n\twritel(mb.word0, to_slim);\n\treadl(to_slim);  \n\n\tlpfc_sli_brdreset(phba);\n\tif (phba->pport)\n\t\tphba->pport->stopped = 0;\n\tphba->link_state = LPFC_INIT_START;\n\tphba->hba_flag = 0;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tmemset(&psli->lnk_stat_offsets, 0, sizeof(psli->lnk_stat_offsets));\n\tpsli->stats_start = ktime_get_seconds();\n\n\t \n\tmdelay(100);\n\n\tlpfc_hba_down_post(phba);\n\n\treturn 0;\n}\n\n \nstatic int\nlpfc_sli_brdrestart_s4(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tint rc;\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"0296 Restart HBA Data: x%x x%x\\n\",\n\t\t\tphba->pport->port_state, psli->sli_flag);\n\n\trc = lpfc_sli4_brdreset(phba);\n\tif (rc) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tgoto hba_down_queue;\n\t}\n\n\tspin_lock_irq(&phba->hbalock);\n\tphba->pport->stopped = 0;\n\tphba->link_state = LPFC_INIT_START;\n\tphba->hba_flag = 0;\n\t \n\tphba->sli4_hba.fawwpn_flag &= LPFC_FAWWPN_FABRIC;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tmemset(&psli->lnk_stat_offsets, 0, sizeof(psli->lnk_stat_offsets));\n\tpsli->stats_start = ktime_get_seconds();\n\nhba_down_queue:\n\tlpfc_hba_down_post(phba);\n\tlpfc_sli4_queue_destroy(phba);\n\n\treturn rc;\n}\n\n \nint\nlpfc_sli_brdrestart(struct lpfc_hba *phba)\n{\n\treturn phba->lpfc_sli_brdrestart(phba);\n}\n\n \nint\nlpfc_sli_chipset_init(struct lpfc_hba *phba)\n{\n\tuint32_t status, i = 0;\n\n\t \n\tif (lpfc_readl(phba->HSregaddr, &status))\n\t\treturn -EIO;\n\n\t \n\ti = 0;\n\twhile ((status & (HS_FFRDY | HS_MBRDY)) != (HS_FFRDY | HS_MBRDY)) {\n\n\t\t \n\t\tif (i++ >= 200) {\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0436 Adapter failed to init, \"\n\t\t\t\t\t\"timeout, status reg x%x, \"\n\t\t\t\t\t\"FW Data: A8 x%x AC x%x\\n\", status,\n\t\t\t\t\treadl(phba->MBslimaddr + 0xa8),\n\t\t\t\t\treadl(phba->MBslimaddr + 0xac));\n\t\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\n\t\t \n\t\tif (status & HS_FFERM) {\n\t\t\t \n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0437 Adapter failed to init, \"\n\t\t\t\t\t\"chipset, status reg x%x, \"\n\t\t\t\t\t\"FW Data: A8 x%x AC x%x\\n\", status,\n\t\t\t\t\treadl(phba->MBslimaddr + 0xa8),\n\t\t\t\t\treadl(phba->MBslimaddr + 0xac));\n\t\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tif (i <= 10)\n\t\t\tmsleep(10);\n\t\telse if (i <= 100)\n\t\t\tmsleep(100);\n\t\telse\n\t\t\tmsleep(1000);\n\n\t\tif (i == 150) {\n\t\t\t \n\t\t\tphba->pport->port_state = LPFC_VPORT_UNKNOWN;\n\t\t\tlpfc_sli_brdrestart(phba);\n\t\t}\n\t\t \n\t\tif (lpfc_readl(phba->HSregaddr, &status))\n\t\t\treturn -EIO;\n\t}\n\n\t \n\tif (status & HS_FFERM) {\n\t\t \n\t\t \n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0438 Adapter failed to init, chipset, \"\n\t\t\t\t\"status reg x%x, \"\n\t\t\t\t\"FW Data: A8 x%x AC x%x\\n\", status,\n\t\t\t\treadl(phba->MBslimaddr + 0xa8),\n\t\t\t\treadl(phba->MBslimaddr + 0xac));\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -EIO;\n\t}\n\n\tphba->hba_flag |= HBA_NEEDS_CFG_PORT;\n\n\t \n\twritel(0, phba->HCregaddr);\n\treadl(phba->HCregaddr);  \n\n\t \n\twritel(0xffffffff, phba->HAregaddr);\n\treadl(phba->HAregaddr);  \n\treturn 0;\n}\n\n \nint\nlpfc_sli_hbq_count(void)\n{\n\treturn ARRAY_SIZE(lpfc_hbq_defs);\n}\n\n \nstatic int\nlpfc_sli_hbq_entry_count(void)\n{\n\tint  hbq_count = lpfc_sli_hbq_count();\n\tint  count = 0;\n\tint  i;\n\n\tfor (i = 0; i < hbq_count; ++i)\n\t\tcount += lpfc_hbq_defs[i]->entry_count;\n\treturn count;\n}\n\n \nint\nlpfc_sli_hbq_size(void)\n{\n\treturn lpfc_sli_hbq_entry_count() * sizeof(struct lpfc_hbq_entry);\n}\n\n \nstatic int\nlpfc_sli_hbq_setup(struct lpfc_hba *phba)\n{\n\tint  hbq_count = lpfc_sli_hbq_count();\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *pmbox;\n\tuint32_t hbqno;\n\tuint32_t hbq_entry_index;\n\n\t\t\t\t \n\tpmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\n\tif (!pmb)\n\t\treturn -ENOMEM;\n\n\tpmbox = &pmb->u.mb;\n\n\t \n\tphba->link_state = LPFC_INIT_MBX_CMDS;\n\tphba->hbq_in_use = 1;\n\n\thbq_entry_index = 0;\n\tfor (hbqno = 0; hbqno < hbq_count; ++hbqno) {\n\t\tphba->hbqs[hbqno].next_hbqPutIdx = 0;\n\t\tphba->hbqs[hbqno].hbqPutIdx      = 0;\n\t\tphba->hbqs[hbqno].local_hbqGetIdx   = 0;\n\t\tphba->hbqs[hbqno].entry_count =\n\t\t\tlpfc_hbq_defs[hbqno]->entry_count;\n\t\tlpfc_config_hbq(phba, hbqno, lpfc_hbq_defs[hbqno],\n\t\t\thbq_entry_index, pmb);\n\t\thbq_entry_index += phba->hbqs[hbqno].entry_count;\n\n\t\tif (lpfc_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {\n\t\t\t \n\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_SLI | LOG_VPORT,\n\t\t\t\t\t\"1805 Adapter failed to init. \"\n\t\t\t\t\t\"Data: x%x x%x x%x\\n\",\n\t\t\t\t\tpmbox->mbxCommand,\n\t\t\t\t\tpmbox->mbxStatus, hbqno);\n\n\t\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\t\treturn -ENXIO;\n\t\t}\n\t}\n\tphba->hbq_count = hbq_count;\n\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\n\t \n\tfor (hbqno = 0; hbqno < hbq_count; ++hbqno)\n\t\tlpfc_sli_hbqbuf_init_hbqs(phba, hbqno);\n\treturn 0;\n}\n\n \nstatic int\nlpfc_sli4_rb_setup(struct lpfc_hba *phba)\n{\n\tphba->hbq_in_use = 1;\n\t \n\tif (phba->cfg_enable_mds_diags && phba->mds_diags_support)\n\t\tphba->hbqs[LPFC_ELS_HBQ].entry_count =\n\t\t\tlpfc_hbq_defs[LPFC_ELS_HBQ]->entry_count >> 1;\n\telse\n\t\tphba->hbqs[LPFC_ELS_HBQ].entry_count =\n\t\t\tlpfc_hbq_defs[LPFC_ELS_HBQ]->entry_count;\n\tphba->hbq_count = 1;\n\tlpfc_sli_hbqbuf_init_hbqs(phba, LPFC_ELS_HBQ);\n\t \n\treturn 0;\n}\n\n \nint\nlpfc_sli_config_port(struct lpfc_hba *phba, int sli_mode)\n{\n\tLPFC_MBOXQ_t *pmb;\n\tuint32_t resetcount = 0, rc = 0, done = 0;\n\n\tpmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\n\tphba->sli_rev = sli_mode;\n\twhile (resetcount < 2 && !done) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->sli.sli_flag |= LPFC_SLI_MBOX_ACTIVE;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tphba->pport->port_state = LPFC_VPORT_UNKNOWN;\n\t\tlpfc_sli_brdrestart(phba);\n\t\trc = lpfc_sli_chipset_init(phba);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tresetcount++;\n\n\t\t \n\t\trc = lpfc_config_port_prep(phba);\n\t\tif (rc == -ERESTART) {\n\t\t\tphba->link_state = LPFC_LINK_UNKNOWN;\n\t\t\tcontinue;\n\t\t} else if (rc)\n\t\t\tbreak;\n\n\t\tphba->link_state = LPFC_INIT_MBX_CMDS;\n\t\tlpfc_config_port(phba, pmb);\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\t\tphba->sli3_options &= ~(LPFC_SLI3_NPIV_ENABLED |\n\t\t\t\t\tLPFC_SLI3_HBQ_ENABLED |\n\t\t\t\t\tLPFC_SLI3_CRP_ENABLED |\n\t\t\t\t\tLPFC_SLI3_DSS_ENABLED);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0442 Adapter failed to init, mbxCmd x%x \"\n\t\t\t\t\"CONFIG_PORT, mbxStatus x%x Data: x%x\\n\",\n\t\t\t\tpmb->u.mb.mbxCommand, pmb->u.mb.mbxStatus, 0);\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tphba->sli.sli_flag &= ~LPFC_SLI_ACTIVE;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\trc = -ENXIO;\n\t\t} else {\n\t\t\t \n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tphba->sli.sli_flag &= ~LPFC_SLI_ASYNC_MBX_BLK;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tdone = 1;\n\n\t\t\tif ((pmb->u.mb.un.varCfgPort.casabt == 1) &&\n\t\t\t    (pmb->u.mb.un.varCfgPort.gasabt == 0))\n\t\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"3110 Port did not grant ASABT\\n\");\n\t\t}\n\t}\n\tif (!done) {\n\t\trc = -EINVAL;\n\t\tgoto do_prep_failed;\n\t}\n\tif (pmb->u.mb.un.varCfgPort.sli_mode == 3) {\n\t\tif (!pmb->u.mb.un.varCfgPort.cMA) {\n\t\t\trc = -ENXIO;\n\t\t\tgoto do_prep_failed;\n\t\t}\n\t\tif (phba->max_vpi && pmb->u.mb.un.varCfgPort.gmv) {\n\t\t\tphba->sli3_options |= LPFC_SLI3_NPIV_ENABLED;\n\t\t\tphba->max_vpi = pmb->u.mb.un.varCfgPort.max_vpi;\n\t\t\tphba->max_vports = (phba->max_vpi > phba->max_vports) ?\n\t\t\t\tphba->max_vpi : phba->max_vports;\n\n\t\t} else\n\t\t\tphba->max_vpi = 0;\n\t\tif (pmb->u.mb.un.varCfgPort.gerbm)\n\t\t\tphba->sli3_options |= LPFC_SLI3_HBQ_ENABLED;\n\t\tif (pmb->u.mb.un.varCfgPort.gcrp)\n\t\t\tphba->sli3_options |= LPFC_SLI3_CRP_ENABLED;\n\n\t\tphba->hbq_get = phba->mbox->us.s3_pgp.hbq_get;\n\t\tphba->port_gp = phba->mbox->us.s3_pgp.port;\n\n\t\tif (phba->sli3_options & LPFC_SLI3_BG_ENABLED) {\n\t\t\tif (pmb->u.mb.un.varCfgPort.gbg == 0) {\n\t\t\t\tphba->cfg_enable_bg = 0;\n\t\t\t\tphba->sli3_options &= ~LPFC_SLI3_BG_ENABLED;\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"0443 Adapter did not grant \"\n\t\t\t\t\t\t\"BlockGuard\\n\");\n\t\t\t}\n\t\t}\n\t} else {\n\t\tphba->hbq_get = NULL;\n\t\tphba->port_gp = phba->mbox->us.s2.port;\n\t\tphba->max_vpi = 0;\n\t}\ndo_prep_failed:\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\treturn rc;\n}\n\n\n \nint\nlpfc_sli_hba_setup(struct lpfc_hba *phba)\n{\n\tuint32_t rc;\n\tint  i;\n\tint longs;\n\n\t \n\tif (phba->hba_flag & HBA_NEEDS_CFG_PORT) {\n\t\trc = lpfc_sli_config_port(phba, LPFC_SLI_REV3);\n\t\tif (rc)\n\t\t\treturn -EIO;\n\t\tphba->hba_flag &= ~HBA_NEEDS_CFG_PORT;\n\t}\n\tphba->fcp_embed_io = 0;\t \n\n\tif (phba->sli_rev == 3) {\n\t\tphba->iocb_cmd_size = SLI3_IOCB_CMD_SIZE;\n\t\tphba->iocb_rsp_size = SLI3_IOCB_RSP_SIZE;\n\t} else {\n\t\tphba->iocb_cmd_size = SLI2_IOCB_CMD_SIZE;\n\t\tphba->iocb_rsp_size = SLI2_IOCB_RSP_SIZE;\n\t\tphba->sli3_options = 0;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0444 Firmware in SLI %x mode. Max_vpi %d\\n\",\n\t\t\tphba->sli_rev, phba->max_vpi);\n\trc = lpfc_sli_ring_map(phba);\n\n\tif (rc)\n\t\tgoto lpfc_sli_hba_setup_error;\n\n\t \n\tif (phba->sli_rev == LPFC_SLI_REV3) {\n\t\t \n\t\tif ((phba->vpi_bmask == NULL) && (phba->vpi_ids == NULL)) {\n\t\t\tlongs = (phba->max_vpi + BITS_PER_LONG) / BITS_PER_LONG;\n\t\t\tphba->vpi_bmask = kcalloc(longs,\n\t\t\t\t\t\t  sizeof(unsigned long),\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\t\tif (!phba->vpi_bmask) {\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto lpfc_sli_hba_setup_error;\n\t\t\t}\n\n\t\t\tphba->vpi_ids = kcalloc(phba->max_vpi + 1,\n\t\t\t\t\t\tsizeof(uint16_t),\n\t\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!phba->vpi_ids) {\n\t\t\t\tkfree(phba->vpi_bmask);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto lpfc_sli_hba_setup_error;\n\t\t\t}\n\t\t\tfor (i = 0; i < phba->max_vpi; i++)\n\t\t\t\tphba->vpi_ids[i] = i;\n\t\t}\n\t}\n\n\t \n\tif (phba->sli3_options & LPFC_SLI3_HBQ_ENABLED) {\n\t\trc = lpfc_sli_hbq_setup(phba);\n\t\tif (rc)\n\t\t\tgoto lpfc_sli_hba_setup_error;\n\t}\n\tspin_lock_irq(&phba->hbalock);\n\tphba->sli.sli_flag |= LPFC_PROCESS_LA;\n\tspin_unlock_irq(&phba->hbalock);\n\n\trc = lpfc_config_port_post(phba);\n\tif (rc)\n\t\tgoto lpfc_sli_hba_setup_error;\n\n\treturn rc;\n\nlpfc_sli_hba_setup_error:\n\tphba->link_state = LPFC_HBA_ERROR;\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0445 Firmware initialization failed\\n\");\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_read_fcoe_params(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct lpfc_dmabuf *mp;\n\tstruct lpfc_mqe *mqe;\n\tuint32_t data_length;\n\tint rc;\n\n\t \n\tphba->valid_vlan = 0;\n\tphba->fc_map[0] = LPFC_FCOE_FCF_MAP0;\n\tphba->fc_map[1] = LPFC_FCOE_FCF_MAP1;\n\tphba->fc_map[2] = LPFC_FCOE_FCF_MAP2;\n\n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\n\tmqe = &mboxq->u.mqe;\n\tif (lpfc_sli4_dump_cfg_rg23(phba, mboxq)) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free_mboxq;\n\t}\n\n\tmp = (struct lpfc_dmabuf *)mboxq->ctx_buf;\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\"(%d):2571 Mailbox cmd x%x Status x%x \"\n\t\t\t\"Data: x%x x%x x%x x%x x%x x%x x%x x%x x%x \"\n\t\t\t\"x%x x%x x%x x%x x%x x%x x%x x%x x%x \"\n\t\t\t\"CQ: x%x x%x x%x x%x\\n\",\n\t\t\tmboxq->vport ? mboxq->vport->vpi : 0,\n\t\t\tbf_get(lpfc_mqe_command, mqe),\n\t\t\tbf_get(lpfc_mqe_status, mqe),\n\t\t\tmqe->un.mb_words[0], mqe->un.mb_words[1],\n\t\t\tmqe->un.mb_words[2], mqe->un.mb_words[3],\n\t\t\tmqe->un.mb_words[4], mqe->un.mb_words[5],\n\t\t\tmqe->un.mb_words[6], mqe->un.mb_words[7],\n\t\t\tmqe->un.mb_words[8], mqe->un.mb_words[9],\n\t\t\tmqe->un.mb_words[10], mqe->un.mb_words[11],\n\t\t\tmqe->un.mb_words[12], mqe->un.mb_words[13],\n\t\t\tmqe->un.mb_words[14], mqe->un.mb_words[15],\n\t\t\tmqe->un.mb_words[16], mqe->un.mb_words[50],\n\t\t\tmboxq->mcqe.word0,\n\t\t\tmboxq->mcqe.mcqe_tag0, \tmboxq->mcqe.mcqe_tag1,\n\t\t\tmboxq->mcqe.trailer);\n\n\tif (rc) {\n\t\trc = -EIO;\n\t\tgoto out_free_mboxq;\n\t}\n\tdata_length = mqe->un.mb_words[5];\n\tif (data_length > DMP_RGN23_SIZE) {\n\t\trc = -EIO;\n\t\tgoto out_free_mboxq;\n\t}\n\n\tlpfc_parse_fcoe_conf(phba, mp->virt, data_length);\n\trc = 0;\n\nout_free_mboxq:\n\tlpfc_mbox_rsrc_cleanup(phba, mboxq, MBOX_THD_UNLOCKED);\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_read_rev(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq,\n\t\t    uint8_t *vpd, uint32_t *vpd_size)\n{\n\tint rc = 0;\n\tuint32_t dma_size;\n\tstruct lpfc_dmabuf *dmabuf;\n\tstruct lpfc_mqe *mqe;\n\n\tdmabuf = kzalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\n\tif (!dmabuf)\n\t\treturn -ENOMEM;\n\n\t \n\tdma_size = *vpd_size;\n\tdmabuf->virt = dma_alloc_coherent(&phba->pcidev->dev, dma_size,\n\t\t\t\t\t  &dmabuf->phys, GFP_KERNEL);\n\tif (!dmabuf->virt) {\n\t\tkfree(dmabuf);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tlpfc_read_rev(phba, mboxq);\n\tmqe = &mboxq->u.mqe;\n\tmqe->un.read_rev.vpd_paddr_high = putPaddrHigh(dmabuf->phys);\n\tmqe->un.read_rev.vpd_paddr_low = putPaddrLow(dmabuf->phys);\n\tmqe->un.read_rev.word1 &= 0x0000FFFF;\n\tbf_set(lpfc_mbx_rd_rev_vpd, &mqe->un.read_rev, 1);\n\tbf_set(lpfc_mbx_rd_rev_avail_len, &mqe->un.read_rev, dma_size);\n\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tif (rc) {\n\t\tdma_free_coherent(&phba->pcidev->dev, dma_size,\n\t\t\t\t  dmabuf->virt, dmabuf->phys);\n\t\tkfree(dmabuf);\n\t\treturn -EIO;\n\t}\n\n\t \n\tif (mqe->un.read_rev.avail_vpd_len < *vpd_size)\n\t\t*vpd_size = mqe->un.read_rev.avail_vpd_len;\n\n\tmemcpy(vpd, dmabuf->virt, *vpd_size);\n\n\tdma_free_coherent(&phba->pcidev->dev, dma_size,\n\t\t\t  dmabuf->virt, dmabuf->phys);\n\tkfree(dmabuf);\n\treturn 0;\n}\n\n \nstatic int\nlpfc_sli4_get_ctl_attr(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct lpfc_mbx_get_cntl_attributes *mbx_cntl_attr;\n\tstruct lpfc_controller_attribute *cntl_attr;\n\tvoid *virtaddr = NULL;\n\tuint32_t alloclen, reqlen;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tint rc;\n\n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\n\t \n\treqlen = sizeof(struct lpfc_mbx_get_cntl_attributes);\n\talloclen = lpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\tLPFC_MBOX_OPCODE_GET_CNTL_ATTRIBUTES, reqlen,\n\t\t\tLPFC_SLI4_MBX_NEMBED);\n\n\tif (alloclen < reqlen) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3084 Allocated DMA memory size (%d) is \"\n\t\t\t\t\"less than the requested DMA memory size \"\n\t\t\t\t\"(%d)\\n\", alloclen, reqlen);\n\t\trc = -ENOMEM;\n\t\tgoto out_free_mboxq;\n\t}\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tvirtaddr = mboxq->sge_array->addr[0];\n\tmbx_cntl_attr = (struct lpfc_mbx_get_cntl_attributes *)virtaddr;\n\tshdr = &mbx_cntl_attr->cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"3085 Mailbox x%x (x%x/x%x) failed, \"\n\t\t\t\t\"rc:x%x, status:x%x, add_status:x%x\\n\",\n\t\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\t\trc, shdr_status, shdr_add_status);\n\t\trc = -ENXIO;\n\t\tgoto out_free_mboxq;\n\t}\n\n\tcntl_attr = &mbx_cntl_attr->cntl_attr;\n\tphba->sli4_hba.lnk_info.lnk_dv = LPFC_LNK_DAT_VAL;\n\tphba->sli4_hba.lnk_info.lnk_tp =\n\t\tbf_get(lpfc_cntl_attr_lnk_type, cntl_attr);\n\tphba->sli4_hba.lnk_info.lnk_no =\n\t\tbf_get(lpfc_cntl_attr_lnk_numb, cntl_attr);\n\tphba->sli4_hba.flash_id = bf_get(lpfc_cntl_attr_flash_id, cntl_attr);\n\tphba->sli4_hba.asic_rev = bf_get(lpfc_cntl_attr_asic_rev, cntl_attr);\n\n\tmemset(phba->BIOSVersion, 0, sizeof(phba->BIOSVersion));\n\tstrlcat(phba->BIOSVersion, (char *)cntl_attr->bios_ver_str,\n\t\tsizeof(phba->BIOSVersion));\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"3086 lnk_type:%d, lnk_numb:%d, bios_ver:%s, \"\n\t\t\t\"flash_id: x%02x, asic_rev: x%02x\\n\",\n\t\t\tphba->sli4_hba.lnk_info.lnk_tp,\n\t\t\tphba->sli4_hba.lnk_info.lnk_no,\n\t\t\tphba->BIOSVersion, phba->sli4_hba.flash_id,\n\t\t\tphba->sli4_hba.asic_rev);\nout_free_mboxq:\n\tif (bf_get(lpfc_mqe_command, &mboxq->u.mqe) == MBX_SLI4_CONFIG)\n\t\tlpfc_sli4_mbox_cmd_free(phba, mboxq);\n\telse\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_retrieve_pport_name(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct lpfc_mbx_get_port_name *get_port_name;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tchar cport_name = 0;\n\tint rc;\n\n\t \n\tphba->sli4_hba.lnk_info.lnk_dv = LPFC_LNK_DAT_INVAL;\n\tphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_NON;\n\n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\t \n\tphba->sli4_hba.lnk_info.lnk_dv = LPFC_LNK_DAT_INVAL;\n\tlpfc_sli4_read_config(phba);\n\n\tif (phba->sli4_hba.fawwpn_flag & LPFC_FAWWPN_CONFIG)\n\t\tphba->sli4_hba.fawwpn_flag |= LPFC_FAWWPN_FABRIC;\n\n\tif (phba->sli4_hba.lnk_info.lnk_dv == LPFC_LNK_DAT_VAL)\n\t\tgoto retrieve_ppname;\n\n\t \n\trc = lpfc_sli4_get_ctl_attr(phba);\n\tif (rc)\n\t\tgoto out_free_mboxq;\n\nretrieve_ppname:\n\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\tLPFC_MBOX_OPCODE_GET_PORT_NAME,\n\t\tsizeof(struct lpfc_mbx_get_port_name) -\n\t\tsizeof(struct lpfc_sli4_cfg_mhdr),\n\t\tLPFC_SLI4_MBX_EMBED);\n\tget_port_name = &mboxq->u.mqe.un.get_port_name;\n\tshdr = (union lpfc_sli4_cfg_shdr *)&get_port_name->header.cfg_shdr;\n\tbf_set(lpfc_mbox_hdr_version, &shdr->request, LPFC_OPCODE_VERSION_1);\n\tbf_set(lpfc_mbx_get_port_name_lnk_type, &get_port_name->u.request,\n\t\tphba->sli4_hba.lnk_info.lnk_tp);\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"3087 Mailbox x%x (x%x/x%x) failed: \"\n\t\t\t\t\"rc:x%x, status:x%x, add_status:x%x\\n\",\n\t\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\t\trc, shdr_status, shdr_add_status);\n\t\trc = -ENXIO;\n\t\tgoto out_free_mboxq;\n\t}\n\tswitch (phba->sli4_hba.lnk_info.lnk_no) {\n\tcase LPFC_LINK_NUMBER_0:\n\t\tcport_name = bf_get(lpfc_mbx_get_port_name_name0,\n\t\t\t\t&get_port_name->u.response);\n\t\tphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_GET;\n\t\tbreak;\n\tcase LPFC_LINK_NUMBER_1:\n\t\tcport_name = bf_get(lpfc_mbx_get_port_name_name1,\n\t\t\t\t&get_port_name->u.response);\n\t\tphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_GET;\n\t\tbreak;\n\tcase LPFC_LINK_NUMBER_2:\n\t\tcport_name = bf_get(lpfc_mbx_get_port_name_name2,\n\t\t\t\t&get_port_name->u.response);\n\t\tphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_GET;\n\t\tbreak;\n\tcase LPFC_LINK_NUMBER_3:\n\t\tcport_name = bf_get(lpfc_mbx_get_port_name_name3,\n\t\t\t\t&get_port_name->u.response);\n\t\tphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_GET;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (phba->sli4_hba.pport_name_sta == LPFC_SLI4_PPNAME_GET) {\n\t\tphba->Port[0] = cport_name;\n\t\tphba->Port[1] = '\\0';\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3091 SLI get port name: %s\\n\", phba->Port);\n\t}\n\nout_free_mboxq:\n\tif (bf_get(lpfc_mqe_command, &mboxq->u.mqe) == MBX_SLI4_CONFIG)\n\t\tlpfc_sli4_mbox_cmd_free(phba, mboxq);\n\telse\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\treturn rc;\n}\n\n \nstatic void\nlpfc_sli4_arm_cqeq_intr(struct lpfc_hba *phba)\n{\n\tint qidx;\n\tstruct lpfc_sli4_hba *sli4_hba = &phba->sli4_hba;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_queue *eq;\n\n\tsli4_hba->sli4_write_cq_db(phba, sli4_hba->mbx_cq, 0, LPFC_QUEUE_REARM);\n\tsli4_hba->sli4_write_cq_db(phba, sli4_hba->els_cq, 0, LPFC_QUEUE_REARM);\n\tif (sli4_hba->nvmels_cq)\n\t\tsli4_hba->sli4_write_cq_db(phba, sli4_hba->nvmels_cq, 0,\n\t\t\t\t\t   LPFC_QUEUE_REARM);\n\n\tif (sli4_hba->hdwq) {\n\t\t \n\t\tfor (qidx = 0; qidx < phba->cfg_hdw_queue; qidx++) {\n\t\t\tqp = &sli4_hba->hdwq[qidx];\n\t\t\t \n\t\t\tsli4_hba->sli4_write_cq_db(phba, qp->io_cq, 0,\n\t\t\t\t\t\tLPFC_QUEUE_REARM);\n\t\t}\n\n\t\t \n\t\tfor (qidx = 0; qidx < phba->cfg_irq_chann; qidx++) {\n\t\t\teq = sli4_hba->hba_eq_hdl[qidx].eq;\n\t\t\t \n\t\t\tsli4_hba->sli4_write_eq_db(phba, eq,\n\t\t\t\t\t\t   0, LPFC_QUEUE_REARM);\n\t\t}\n\t}\n\n\tif (phba->nvmet_support) {\n\t\tfor (qidx = 0; qidx < phba->cfg_nvmet_mrq; qidx++) {\n\t\t\tsli4_hba->sli4_write_cq_db(phba,\n\t\t\t\tsli4_hba->nvmet_cqset[qidx], 0,\n\t\t\t\tLPFC_QUEUE_REARM);\n\t\t}\n\t}\n}\n\n \nint\nlpfc_sli4_get_avail_extnt_rsrc(struct lpfc_hba *phba, uint16_t type,\n\t\t\t       uint16_t *extnt_count, uint16_t *extnt_size)\n{\n\tint rc = 0;\n\tuint32_t length;\n\tuint32_t mbox_tmo;\n\tstruct lpfc_mbx_get_rsrc_extent_info *rsrc_info;\n\tLPFC_MBOXQ_t *mbox;\n\n\t*extnt_count = 0;\n\t*extnt_size = 0;\n\n\tmbox = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\n\t \n\tlength = (sizeof(struct lpfc_mbx_get_rsrc_extent_info) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_GET_RSRC_EXTENT_INFO,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\n\t \n\trc = lpfc_sli4_mbox_rsrc_extent(phba, mbox, 0, type,\n\t\t\t\t\tLPFC_SLI4_MBX_EMBED);\n\tif (unlikely(rc)) {\n\t\trc = -EIO;\n\t\tgoto err_exit;\n\t}\n\n\tif (!phba->sli4_hba.intr_enable)\n\t\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\n\t}\n\tif (unlikely(rc)) {\n\t\trc = -EIO;\n\t\tgoto err_exit;\n\t}\n\n\trsrc_info = &mbox->u.mqe.un.rsrc_extent_info;\n\tif (bf_get(lpfc_mbox_hdr_status,\n\t\t   &rsrc_info->header.cfg_shdr.response)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2930 Failed to get resource extents \"\n\t\t\t\t\"Status 0x%x Add'l Status 0x%x\\n\",\n\t\t\t\tbf_get(lpfc_mbox_hdr_status,\n\t\t\t\t       &rsrc_info->header.cfg_shdr.response),\n\t\t\t\tbf_get(lpfc_mbox_hdr_add_status,\n\t\t\t\t       &rsrc_info->header.cfg_shdr.response));\n\t\trc = -EIO;\n\t\tgoto err_exit;\n\t}\n\n\t*extnt_count = bf_get(lpfc_mbx_get_rsrc_extent_info_cnt,\n\t\t\t      &rsrc_info->u.rsp);\n\t*extnt_size = bf_get(lpfc_mbx_get_rsrc_extent_info_size,\n\t\t\t     &rsrc_info->u.rsp);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"3162 Retrieved extents type-%d from port: count:%d, \"\n\t\t\t\"size:%d\\n\", type, *extnt_count, *extnt_size);\n\nerr_exit:\n\tmempool_free(mbox, phba->mbox_mem_pool);\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_chk_avail_extnt_rsrc(struct lpfc_hba *phba, uint16_t type)\n{\n\tuint16_t curr_ext_cnt, rsrc_ext_cnt;\n\tuint16_t size_diff, rsrc_ext_size;\n\tint rc = 0;\n\tstruct lpfc_rsrc_blks *rsrc_entry;\n\tstruct list_head *rsrc_blk_list = NULL;\n\n\tsize_diff = 0;\n\tcurr_ext_cnt = 0;\n\trc = lpfc_sli4_get_avail_extnt_rsrc(phba, type,\n\t\t\t\t\t    &rsrc_ext_cnt,\n\t\t\t\t\t    &rsrc_ext_size);\n\tif (unlikely(rc))\n\t\treturn -EIO;\n\n\tswitch (type) {\n\tcase LPFC_RSC_TYPE_FCOE_RPI:\n\t\trsrc_blk_list = &phba->sli4_hba.lpfc_rpi_blk_list;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_VPI:\n\t\trsrc_blk_list = &phba->lpfc_vpi_blk_list;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_XRI:\n\t\trsrc_blk_list = &phba->sli4_hba.lpfc_xri_blk_list;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_VFI:\n\t\trsrc_blk_list = &phba->sli4_hba.lpfc_vfi_blk_list;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tlist_for_each_entry(rsrc_entry, rsrc_blk_list, list) {\n\t\tcurr_ext_cnt++;\n\t\tif (rsrc_entry->rsrc_size != rsrc_ext_size)\n\t\t\tsize_diff++;\n\t}\n\n\tif (curr_ext_cnt != rsrc_ext_cnt || size_diff != 0)\n\t\trc = 1;\n\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_cfg_post_extnts(struct lpfc_hba *phba, uint16_t extnt_cnt,\n\t\t\t  uint16_t type, bool *emb, LPFC_MBOXQ_t *mbox)\n{\n\tint rc = 0;\n\tuint32_t req_len;\n\tuint32_t emb_len;\n\tuint32_t alloc_len, mbox_tmo;\n\n\t \n\treq_len = extnt_cnt * sizeof(uint16_t);\n\n\t \n\temb_len = sizeof(MAILBOX_t) - sizeof(struct mbox_header) -\n\t\tsizeof(uint32_t);\n\n\t \n\t*emb = LPFC_SLI4_MBX_EMBED;\n\tif (req_len > emb_len) {\n\t\treq_len = extnt_cnt * sizeof(uint16_t) +\n\t\t\tsizeof(union lpfc_sli4_cfg_shdr) +\n\t\t\tsizeof(uint32_t);\n\t\t*emb = LPFC_SLI4_MBX_NEMBED;\n\t}\n\n\talloc_len = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t\t     LPFC_MBOX_OPCODE_ALLOC_RSRC_EXTENT,\n\t\t\t\t     req_len, *emb);\n\tif (alloc_len < req_len) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2982 Allocated DMA memory size (x%x) is \"\n\t\t\t\"less than the requested DMA memory \"\n\t\t\t\"size (x%x)\\n\", alloc_len, req_len);\n\t\treturn -ENOMEM;\n\t}\n\trc = lpfc_sli4_mbox_rsrc_extent(phba, mbox, extnt_cnt, type, *emb);\n\tif (unlikely(rc))\n\t\treturn -EIO;\n\n\tif (!phba->sli4_hba.intr_enable)\n\t\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\n\t}\n\n\tif (unlikely(rc))\n\t\trc = -EIO;\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_alloc_extent(struct lpfc_hba *phba, uint16_t type)\n{\n\tbool emb = false;\n\tuint16_t rsrc_id_cnt, rsrc_cnt, rsrc_size;\n\tuint16_t rsrc_id, rsrc_start, j, k;\n\tuint16_t *ids;\n\tint i, rc;\n\tunsigned long longs;\n\tunsigned long *bmask;\n\tstruct lpfc_rsrc_blks *rsrc_blks;\n\tLPFC_MBOXQ_t *mbox;\n\tuint32_t length;\n\tstruct lpfc_id_range *id_array = NULL;\n\tvoid *virtaddr = NULL;\n\tstruct lpfc_mbx_nembed_rsrc_extent *n_rsrc;\n\tstruct lpfc_mbx_alloc_rsrc_extents *rsrc_ext;\n\tstruct list_head *ext_blk_list;\n\n\trc = lpfc_sli4_get_avail_extnt_rsrc(phba, type,\n\t\t\t\t\t    &rsrc_cnt,\n\t\t\t\t\t    &rsrc_size);\n\tif (unlikely(rc))\n\t\treturn -EIO;\n\n\tif ((rsrc_cnt == 0) || (rsrc_size == 0)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"3009 No available Resource Extents \"\n\t\t\t\"for resource type 0x%x: Count: 0x%x, \"\n\t\t\t\"Size 0x%x\\n\", type, rsrc_cnt,\n\t\t\trsrc_size);\n\t\treturn -ENOMEM;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_INIT | LOG_SLI,\n\t\t\t\"2903 Post resource extents type-0x%x: \"\n\t\t\t\"count:%d, size %d\\n\", type, rsrc_cnt, rsrc_size);\n\n\tmbox = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\n\trc = lpfc_sli4_cfg_post_extnts(phba, rsrc_cnt, type, &emb, mbox);\n\tif (unlikely(rc)) {\n\t\trc = -EIO;\n\t\tgoto err_exit;\n\t}\n\n\t \n\tif (emb == LPFC_SLI4_MBX_EMBED) {\n\t\trsrc_ext = &mbox->u.mqe.un.alloc_rsrc_extents;\n\t\tid_array = &rsrc_ext->u.rsp.id[0];\n\t\trsrc_cnt = bf_get(lpfc_mbx_rsrc_cnt, &rsrc_ext->u.rsp);\n\t} else {\n\t\tvirtaddr = mbox->sge_array->addr[0];\n\t\tn_rsrc = (struct lpfc_mbx_nembed_rsrc_extent *) virtaddr;\n\t\trsrc_cnt = bf_get(lpfc_mbx_rsrc_cnt, n_rsrc);\n\t\tid_array = &n_rsrc->id;\n\t}\n\n\tlongs = ((rsrc_cnt * rsrc_size) + BITS_PER_LONG - 1) / BITS_PER_LONG;\n\trsrc_id_cnt = rsrc_cnt * rsrc_size;\n\n\t \n\tlength = sizeof(struct lpfc_rsrc_blks);\n\tswitch (type) {\n\tcase LPFC_RSC_TYPE_FCOE_RPI:\n\t\tphba->sli4_hba.rpi_bmask = kcalloc(longs,\n\t\t\t\t\t\t   sizeof(unsigned long),\n\t\t\t\t\t\t   GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.rpi_bmask)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_exit;\n\t\t}\n\t\tphba->sli4_hba.rpi_ids = kcalloc(rsrc_id_cnt,\n\t\t\t\t\t\t sizeof(uint16_t),\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.rpi_ids)) {\n\t\t\tkfree(phba->sli4_hba.rpi_bmask);\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_exit;\n\t\t}\n\n\t\t \n\t\tphba->sli4_hba.next_rpi = rsrc_id_cnt;\n\n\t\t \n\t\tbmask = phba->sli4_hba.rpi_bmask;\n\t\tids = phba->sli4_hba.rpi_ids;\n\t\text_blk_list = &phba->sli4_hba.lpfc_rpi_blk_list;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_VPI:\n\t\tphba->vpi_bmask = kcalloc(longs, sizeof(unsigned long),\n\t\t\t\t\t  GFP_KERNEL);\n\t\tif (unlikely(!phba->vpi_bmask)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_exit;\n\t\t}\n\t\tphba->vpi_ids = kcalloc(rsrc_id_cnt, sizeof(uint16_t),\n\t\t\t\t\t GFP_KERNEL);\n\t\tif (unlikely(!phba->vpi_ids)) {\n\t\t\tkfree(phba->vpi_bmask);\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_exit;\n\t\t}\n\n\t\t \n\t\tbmask = phba->vpi_bmask;\n\t\tids = phba->vpi_ids;\n\t\text_blk_list = &phba->lpfc_vpi_blk_list;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_XRI:\n\t\tphba->sli4_hba.xri_bmask = kcalloc(longs,\n\t\t\t\t\t\t   sizeof(unsigned long),\n\t\t\t\t\t\t   GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.xri_bmask)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_exit;\n\t\t}\n\t\tphba->sli4_hba.max_cfg_param.xri_used = 0;\n\t\tphba->sli4_hba.xri_ids = kcalloc(rsrc_id_cnt,\n\t\t\t\t\t\t sizeof(uint16_t),\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.xri_ids)) {\n\t\t\tkfree(phba->sli4_hba.xri_bmask);\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_exit;\n\t\t}\n\n\t\t \n\t\tbmask = phba->sli4_hba.xri_bmask;\n\t\tids = phba->sli4_hba.xri_ids;\n\t\text_blk_list = &phba->sli4_hba.lpfc_xri_blk_list;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_VFI:\n\t\tphba->sli4_hba.vfi_bmask = kcalloc(longs,\n\t\t\t\t\t\t   sizeof(unsigned long),\n\t\t\t\t\t\t   GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.vfi_bmask)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_exit;\n\t\t}\n\t\tphba->sli4_hba.vfi_ids = kcalloc(rsrc_id_cnt,\n\t\t\t\t\t\t sizeof(uint16_t),\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.vfi_ids)) {\n\t\t\tkfree(phba->sli4_hba.vfi_bmask);\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_exit;\n\t\t}\n\n\t\t \n\t\tbmask = phba->sli4_hba.vfi_bmask;\n\t\tids = phba->sli4_hba.vfi_ids;\n\t\text_blk_list = &phba->sli4_hba.lpfc_vfi_blk_list;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tid_array = NULL;\n\t\tbmask = NULL;\n\t\tids = NULL;\n\t\text_blk_list = NULL;\n\t\tgoto err_exit;\n\t}\n\n\t \n\tfor (i = 0, j = 0, k = 0; i < rsrc_cnt; i++) {\n\t\tif ((i % 2) == 0)\n\t\t\trsrc_id = bf_get(lpfc_mbx_rsrc_id_word4_0,\n\t\t\t\t\t &id_array[k]);\n\t\telse\n\t\t\trsrc_id = bf_get(lpfc_mbx_rsrc_id_word4_1,\n\t\t\t\t\t &id_array[k]);\n\n\t\trsrc_blks = kzalloc(length, GFP_KERNEL);\n\t\tif (unlikely(!rsrc_blks)) {\n\t\t\trc = -ENOMEM;\n\t\t\tkfree(bmask);\n\t\t\tkfree(ids);\n\t\t\tgoto err_exit;\n\t\t}\n\t\trsrc_blks->rsrc_start = rsrc_id;\n\t\trsrc_blks->rsrc_size = rsrc_size;\n\t\tlist_add_tail(&rsrc_blks->list, ext_blk_list);\n\t\trsrc_start = rsrc_id;\n\t\tif ((type == LPFC_RSC_TYPE_FCOE_XRI) && (j == 0)) {\n\t\t\tphba->sli4_hba.io_xri_start = rsrc_start +\n\t\t\t\tlpfc_sli4_get_iocb_cnt(phba);\n\t\t}\n\n\t\twhile (rsrc_id < (rsrc_start + rsrc_size)) {\n\t\t\tids[j] = rsrc_id;\n\t\t\trsrc_id++;\n\t\t\tj++;\n\t\t}\n\t\t \n\t\tif ((i % 2) == 1)\n\t\t\tk++;\n\t}\n err_exit:\n\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\treturn rc;\n}\n\n\n\n \nstatic int\nlpfc_sli4_dealloc_extent(struct lpfc_hba *phba, uint16_t type)\n{\n\tint rc;\n\tuint32_t length, mbox_tmo = 0;\n\tLPFC_MBOXQ_t *mbox;\n\tstruct lpfc_mbx_dealloc_rsrc_extents *dealloc_rsrc;\n\tstruct lpfc_rsrc_blks *rsrc_blk, *rsrc_blk_next;\n\n\tmbox = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\n\t \n\tlength = (sizeof(struct lpfc_mbx_dealloc_rsrc_extents) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_DEALLOC_RSRC_EXTENT,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\n\t \n\trc = lpfc_sli4_mbox_rsrc_extent(phba, mbox, 0, type,\n\t\t\t\t\tLPFC_SLI4_MBX_EMBED);\n\tif (unlikely(rc)) {\n\t\trc = -EIO;\n\t\tgoto out_free_mbox;\n\t}\n\tif (!phba->sli4_hba.intr_enable)\n\t\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\n\t}\n\tif (unlikely(rc)) {\n\t\trc = -EIO;\n\t\tgoto out_free_mbox;\n\t}\n\n\tdealloc_rsrc = &mbox->u.mqe.un.dealloc_rsrc_extents;\n\tif (bf_get(lpfc_mbox_hdr_status,\n\t\t   &dealloc_rsrc->header.cfg_shdr.response)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2919 Failed to release resource extents \"\n\t\t\t\t\"for type %d - Status 0x%x Add'l Status 0x%x. \"\n\t\t\t\t\"Resource memory not released.\\n\",\n\t\t\t\ttype,\n\t\t\t\tbf_get(lpfc_mbox_hdr_status,\n\t\t\t\t    &dealloc_rsrc->header.cfg_shdr.response),\n\t\t\t\tbf_get(lpfc_mbox_hdr_add_status,\n\t\t\t\t    &dealloc_rsrc->header.cfg_shdr.response));\n\t\trc = -EIO;\n\t\tgoto out_free_mbox;\n\t}\n\n\t \n\tswitch (type) {\n\tcase LPFC_RSC_TYPE_FCOE_VPI:\n\t\tkfree(phba->vpi_bmask);\n\t\tkfree(phba->vpi_ids);\n\t\tbf_set(lpfc_vpi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\n\t\tlist_for_each_entry_safe(rsrc_blk, rsrc_blk_next,\n\t\t\t\t    &phba->lpfc_vpi_blk_list, list) {\n\t\t\tlist_del_init(&rsrc_blk->list);\n\t\t\tkfree(rsrc_blk);\n\t\t}\n\t\tphba->sli4_hba.max_cfg_param.vpi_used = 0;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_XRI:\n\t\tkfree(phba->sli4_hba.xri_bmask);\n\t\tkfree(phba->sli4_hba.xri_ids);\n\t\tlist_for_each_entry_safe(rsrc_blk, rsrc_blk_next,\n\t\t\t\t    &phba->sli4_hba.lpfc_xri_blk_list, list) {\n\t\t\tlist_del_init(&rsrc_blk->list);\n\t\t\tkfree(rsrc_blk);\n\t\t}\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_VFI:\n\t\tkfree(phba->sli4_hba.vfi_bmask);\n\t\tkfree(phba->sli4_hba.vfi_ids);\n\t\tbf_set(lpfc_vfi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\n\t\tlist_for_each_entry_safe(rsrc_blk, rsrc_blk_next,\n\t\t\t\t    &phba->sli4_hba.lpfc_vfi_blk_list, list) {\n\t\t\tlist_del_init(&rsrc_blk->list);\n\t\t\tkfree(rsrc_blk);\n\t\t}\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_RPI:\n\t\t \n\t\tlist_for_each_entry_safe(rsrc_blk, rsrc_blk_next,\n\t\t\t\t    &phba->sli4_hba.lpfc_rpi_blk_list, list) {\n\t\t\tlist_del_init(&rsrc_blk->list);\n\t\t\tkfree(rsrc_blk);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tbf_set(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\n\n out_free_mbox:\n\tmempool_free(mbox, phba->mbox_mem_pool);\n\treturn rc;\n}\n\nstatic void\nlpfc_set_features(struct lpfc_hba *phba, LPFC_MBOXQ_t *mbox,\n\t\t  uint32_t feature)\n{\n\tuint32_t len;\n\tu32 sig_freq = 0;\n\n\tlen = sizeof(struct lpfc_mbx_set_feature) -\n\t\tsizeof(struct lpfc_sli4_cfg_mhdr);\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_SET_FEATURES, len,\n\t\t\t LPFC_SLI4_MBX_EMBED);\n\n\tswitch (feature) {\n\tcase LPFC_SET_UE_RECOVERY:\n\t\tbf_set(lpfc_mbx_set_feature_UER,\n\t\t       &mbox->u.mqe.un.set_feature, 1);\n\t\tmbox->u.mqe.un.set_feature.feature = LPFC_SET_UE_RECOVERY;\n\t\tmbox->u.mqe.un.set_feature.param_len = 8;\n\t\tbreak;\n\tcase LPFC_SET_MDS_DIAGS:\n\t\tbf_set(lpfc_mbx_set_feature_mds,\n\t\t       &mbox->u.mqe.un.set_feature, 1);\n\t\tbf_set(lpfc_mbx_set_feature_mds_deep_loopbk,\n\t\t       &mbox->u.mqe.un.set_feature, 1);\n\t\tmbox->u.mqe.un.set_feature.feature = LPFC_SET_MDS_DIAGS;\n\t\tmbox->u.mqe.un.set_feature.param_len = 8;\n\t\tbreak;\n\tcase LPFC_SET_CGN_SIGNAL:\n\t\tif (phba->cmf_active_mode == LPFC_CFG_OFF)\n\t\t\tsig_freq = 0;\n\t\telse\n\t\t\tsig_freq = phba->cgn_sig_freq;\n\n\t\tif (phba->cgn_reg_signal == EDC_CG_SIG_WARN_ALARM) {\n\t\t\tbf_set(lpfc_mbx_set_feature_CGN_alarm_freq,\n\t\t\t       &mbox->u.mqe.un.set_feature, sig_freq);\n\t\t\tbf_set(lpfc_mbx_set_feature_CGN_warn_freq,\n\t\t\t       &mbox->u.mqe.un.set_feature, sig_freq);\n\t\t}\n\n\t\tif (phba->cgn_reg_signal == EDC_CG_SIG_WARN_ONLY)\n\t\t\tbf_set(lpfc_mbx_set_feature_CGN_warn_freq,\n\t\t\t       &mbox->u.mqe.un.set_feature, sig_freq);\n\n\t\tif (phba->cmf_active_mode == LPFC_CFG_OFF ||\n\t\t    phba->cgn_reg_signal == EDC_CG_SIG_NOTSUPPORTED)\n\t\t\tsig_freq = 0;\n\t\telse\n\t\t\tsig_freq = lpfc_acqe_cgn_frequency;\n\n\t\tbf_set(lpfc_mbx_set_feature_CGN_acqe_freq,\n\t\t       &mbox->u.mqe.un.set_feature, sig_freq);\n\n\t\tmbox->u.mqe.un.set_feature.feature = LPFC_SET_CGN_SIGNAL;\n\t\tmbox->u.mqe.un.set_feature.param_len = 12;\n\t\tbreak;\n\tcase LPFC_SET_DUAL_DUMP:\n\t\tbf_set(lpfc_mbx_set_feature_dd,\n\t\t       &mbox->u.mqe.un.set_feature, LPFC_ENABLE_DUAL_DUMP);\n\t\tbf_set(lpfc_mbx_set_feature_ddquery,\n\t\t       &mbox->u.mqe.un.set_feature, 0);\n\t\tmbox->u.mqe.un.set_feature.feature = LPFC_SET_DUAL_DUMP;\n\t\tmbox->u.mqe.un.set_feature.param_len = 4;\n\t\tbreak;\n\tcase LPFC_SET_ENABLE_MI:\n\t\tmbox->u.mqe.un.set_feature.feature = LPFC_SET_ENABLE_MI;\n\t\tmbox->u.mqe.un.set_feature.param_len = 4;\n\t\tbf_set(lpfc_mbx_set_feature_milunq, &mbox->u.mqe.un.set_feature,\n\t\t       phba->pport->cfg_lun_queue_depth);\n\t\tbf_set(lpfc_mbx_set_feature_mi, &mbox->u.mqe.un.set_feature,\n\t\t       phba->sli4_hba.pc_sli4_params.mi_ver);\n\t\tbreak;\n\tcase LPFC_SET_LD_SIGNAL:\n\t\tmbox->u.mqe.un.set_feature.feature = LPFC_SET_LD_SIGNAL;\n\t\tmbox->u.mqe.un.set_feature.param_len = 16;\n\t\tbf_set(lpfc_mbx_set_feature_lds_qry,\n\t\t       &mbox->u.mqe.un.set_feature, LPFC_QUERY_LDS_OP);\n\t\tbreak;\n\tcase LPFC_SET_ENABLE_CMF:\n\t\tmbox->u.mqe.un.set_feature.feature = LPFC_SET_ENABLE_CMF;\n\t\tmbox->u.mqe.un.set_feature.param_len = 4;\n\t\tbf_set(lpfc_mbx_set_feature_cmf,\n\t\t       &mbox->u.mqe.un.set_feature, 1);\n\t\tbreak;\n\t}\n\treturn;\n}\n\n \nvoid\nlpfc_ras_stop_fwlog(struct lpfc_hba *phba)\n{\n\tstruct lpfc_ras_fwlog *ras_fwlog = &phba->ras_fwlog;\n\n\tspin_lock_irq(&phba->hbalock);\n\tras_fwlog->state = INACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\twritel(LPFC_CTL_PDEV_CTL_DDL_RAS,\n\t       phba->sli4_hba.conf_regs_memmap_p + LPFC_CTL_PDEV_CTL_OFFSET);\n\n\t \n\tusleep_range(10 * 1000, 20 * 1000);\n}\n\n \nvoid\nlpfc_sli4_ras_dma_free(struct lpfc_hba *phba)\n{\n\tstruct lpfc_ras_fwlog *ras_fwlog = &phba->ras_fwlog;\n\tstruct lpfc_dmabuf *dmabuf, *next;\n\n\tif (!list_empty(&ras_fwlog->fwlog_buff_list)) {\n\t\tlist_for_each_entry_safe(dmabuf, next,\n\t\t\t\t    &ras_fwlog->fwlog_buff_list,\n\t\t\t\t    list) {\n\t\t\tlist_del(&dmabuf->list);\n\t\t\tdma_free_coherent(&phba->pcidev->dev,\n\t\t\t\t\t  LPFC_RAS_MAX_ENTRY_SIZE,\n\t\t\t\t\t  dmabuf->virt, dmabuf->phys);\n\t\t\tkfree(dmabuf);\n\t\t}\n\t}\n\n\tif (ras_fwlog->lwpd.virt) {\n\t\tdma_free_coherent(&phba->pcidev->dev,\n\t\t\t\t  sizeof(uint32_t) * 2,\n\t\t\t\t  ras_fwlog->lwpd.virt,\n\t\t\t\t  ras_fwlog->lwpd.phys);\n\t\tras_fwlog->lwpd.virt = NULL;\n\t}\n\n\tspin_lock_irq(&phba->hbalock);\n\tras_fwlog->state = INACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n \n\nstatic int\nlpfc_sli4_ras_dma_alloc(struct lpfc_hba *phba,\n\t\t\tuint32_t fwlog_buff_count)\n{\n\tstruct lpfc_ras_fwlog *ras_fwlog = &phba->ras_fwlog;\n\tstruct lpfc_dmabuf *dmabuf;\n\tint rc = 0, i = 0;\n\n\t \n\tINIT_LIST_HEAD(&ras_fwlog->fwlog_buff_list);\n\n\t \n\tras_fwlog->lwpd.virt = dma_alloc_coherent(&phba->pcidev->dev,\n\t\t\t\t\t    sizeof(uint32_t) * 2,\n\t\t\t\t\t    &ras_fwlog->lwpd.phys,\n\t\t\t\t\t    GFP_KERNEL);\n\tif (!ras_fwlog->lwpd.virt) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6185 LWPD Memory Alloc Failed\\n\");\n\n\t\treturn -ENOMEM;\n\t}\n\n\tras_fwlog->fw_buffcount = fwlog_buff_count;\n\tfor (i = 0; i < ras_fwlog->fw_buffcount; i++) {\n\t\tdmabuf = kzalloc(sizeof(struct lpfc_dmabuf),\n\t\t\t\t GFP_KERNEL);\n\t\tif (!dmabuf) {\n\t\t\trc = -ENOMEM;\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"6186 Memory Alloc failed FW logging\");\n\t\t\tgoto free_mem;\n\t\t}\n\n\t\tdmabuf->virt = dma_alloc_coherent(&phba->pcidev->dev,\n\t\t\t\t\t\t  LPFC_RAS_MAX_ENTRY_SIZE,\n\t\t\t\t\t\t  &dmabuf->phys, GFP_KERNEL);\n\t\tif (!dmabuf->virt) {\n\t\t\tkfree(dmabuf);\n\t\t\trc = -ENOMEM;\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"6187 DMA Alloc Failed FW logging\");\n\t\t\tgoto free_mem;\n\t\t}\n\t\tdmabuf->buffer_tag = i;\n\t\tlist_add_tail(&dmabuf->list, &ras_fwlog->fwlog_buff_list);\n\t}\n\nfree_mem:\n\tif (rc)\n\t\tlpfc_sli4_ras_dma_free(phba);\n\n\treturn rc;\n}\n\n \nstatic void\nlpfc_sli4_ras_mbox_cmpl(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\n{\n\tMAILBOX_t *mb;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t shdr_status, shdr_add_status;\n\tstruct lpfc_ras_fwlog *ras_fwlog = &phba->ras_fwlog;\n\n\tmb = &pmb->u.mb;\n\n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&pmb->u.mqe.un.ras_fwlog.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\n\tif (mb->mbxStatus != MBX_SUCCESS || shdr_status) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6188 FW LOG mailbox \"\n\t\t\t\t\"completed with status x%x add_status x%x,\"\n\t\t\t\t\" mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, mb->mbxStatus);\n\n\t\tras_fwlog->ras_hwsupport = false;\n\t\tgoto disable_ras;\n\t}\n\n\tspin_lock_irq(&phba->hbalock);\n\tras_fwlog->state = ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\n\treturn;\n\ndisable_ras:\n\t \n\tlpfc_sli4_ras_dma_free(phba);\n\tmempool_free(pmb, phba->mbox_mem_pool);\n}\n\n \nint\nlpfc_sli4_ras_fwlog_init(struct lpfc_hba *phba,\n\t\t\t uint32_t fwlog_level,\n\t\t\t uint32_t fwlog_enable)\n{\n\tstruct lpfc_ras_fwlog *ras_fwlog = &phba->ras_fwlog;\n\tstruct lpfc_mbx_set_ras_fwlog *mbx_fwlog = NULL;\n\tstruct lpfc_dmabuf *dmabuf;\n\tLPFC_MBOXQ_t *mbox;\n\tuint32_t len = 0, fwlog_buffsize, fwlog_entry_count;\n\tint rc = 0;\n\n\tspin_lock_irq(&phba->hbalock);\n\tras_fwlog->state = INACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tfwlog_buffsize = (LPFC_RAS_MIN_BUFF_POST_SIZE *\n\t\t\t  phba->cfg_ras_fwlog_buffsize);\n\tfwlog_entry_count = (fwlog_buffsize/LPFC_RAS_MAX_ENTRY_SIZE);\n\n\t \n\tif (!ras_fwlog->lwpd.virt) {\n\t\trc = lpfc_sli4_ras_dma_alloc(phba, fwlog_entry_count);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"6189 FW Log Memory Allocation Failed\");\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\t \n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6190 RAS MBX Alloc Failed\");\n\t\trc = -ENOMEM;\n\t\tgoto mem_free;\n\t}\n\n\tras_fwlog->fw_loglevel = fwlog_level;\n\tlen = (sizeof(struct lpfc_mbx_set_ras_fwlog) -\n\t\tsizeof(struct lpfc_sli4_cfg_mhdr));\n\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_LOWLEVEL,\n\t\t\t LPFC_MBOX_OPCODE_SET_DIAG_LOG_OPTION,\n\t\t\t len, LPFC_SLI4_MBX_EMBED);\n\n\tmbx_fwlog = (struct lpfc_mbx_set_ras_fwlog *)&mbox->u.mqe.un.ras_fwlog;\n\tbf_set(lpfc_fwlog_enable, &mbx_fwlog->u.request,\n\t       fwlog_enable);\n\tbf_set(lpfc_fwlog_loglvl, &mbx_fwlog->u.request,\n\t       ras_fwlog->fw_loglevel);\n\tbf_set(lpfc_fwlog_buffcnt, &mbx_fwlog->u.request,\n\t       ras_fwlog->fw_buffcount);\n\tbf_set(lpfc_fwlog_buffsz, &mbx_fwlog->u.request,\n\t       LPFC_RAS_MAX_ENTRY_SIZE/SLI4_PAGE_SIZE);\n\n\t \n\tlist_for_each_entry(dmabuf, &ras_fwlog->fwlog_buff_list, list) {\n\t\tmemset(dmabuf->virt, 0, LPFC_RAS_MAX_ENTRY_SIZE);\n\n\t\tmbx_fwlog->u.request.buff_fwlog[dmabuf->buffer_tag].addr_lo =\n\t\t\tputPaddrLow(dmabuf->phys);\n\n\t\tmbx_fwlog->u.request.buff_fwlog[dmabuf->buffer_tag].addr_hi =\n\t\t\tputPaddrHigh(dmabuf->phys);\n\t}\n\n\t \n\tmbx_fwlog->u.request.lwpd.addr_lo = putPaddrLow(ras_fwlog->lwpd.phys);\n\tmbx_fwlog->u.request.lwpd.addr_hi = putPaddrHigh(ras_fwlog->lwpd.phys);\n\n\tspin_lock_irq(&phba->hbalock);\n\tras_fwlog->state = REG_INPROGRESS;\n\tspin_unlock_irq(&phba->hbalock);\n\tmbox->vport = phba->pport;\n\tmbox->mbox_cmpl = lpfc_sli4_ras_mbox_cmpl;\n\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);\n\n\tif (rc == MBX_NOT_FINISHED) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6191 FW-Log Mailbox failed. \"\n\t\t\t\t\"status %d mbxStatus : x%x\", rc,\n\t\t\t\tbf_get(lpfc_mqe_status, &mbox->u.mqe));\n\t\tmempool_free(mbox, phba->mbox_mem_pool);\n\t\trc = -EIO;\n\t\tgoto mem_free;\n\t} else\n\t\trc = 0;\nmem_free:\n\tif (rc)\n\t\tlpfc_sli4_ras_dma_free(phba);\n\n\treturn rc;\n}\n\n \nvoid\nlpfc_sli4_ras_setup(struct lpfc_hba *phba)\n{\n\t \n\tif (lpfc_check_fwlog_support(phba))\n\t\treturn;\n\n\tlpfc_sli4_ras_fwlog_init(phba, phba->cfg_ras_fwlog_level,\n\t\t\t\t LPFC_RAS_ENABLE_LOGGING);\n}\n\n \nint\nlpfc_sli4_alloc_resource_identifiers(struct lpfc_hba *phba)\n{\n\tint i, rc, error = 0;\n\tuint16_t count, base;\n\tunsigned long longs;\n\n\tif (!phba->sli4_hba.rpi_hdrs_in_use)\n\t\tphba->sli4_hba.next_rpi = phba->sli4_hba.max_cfg_param.max_rpi;\n\tif (phba->sli4_hba.extents_in_use) {\n\t\t \n\t\tif (bf_get(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags) ==\n\t\t    LPFC_IDX_RSRC_RDY) {\n\t\t\t \n\t\t\trc = lpfc_sli4_chk_avail_extnt_rsrc(phba,\n\t\t\t\t\t\t LPFC_RSC_TYPE_FCOE_VFI);\n\t\t\tif (rc != 0)\n\t\t\t\terror++;\n\t\t\trc = lpfc_sli4_chk_avail_extnt_rsrc(phba,\n\t\t\t\t\t\t LPFC_RSC_TYPE_FCOE_VPI);\n\t\t\tif (rc != 0)\n\t\t\t\terror++;\n\t\t\trc = lpfc_sli4_chk_avail_extnt_rsrc(phba,\n\t\t\t\t\t\t LPFC_RSC_TYPE_FCOE_XRI);\n\t\t\tif (rc != 0)\n\t\t\t\terror++;\n\t\t\trc = lpfc_sli4_chk_avail_extnt_rsrc(phba,\n\t\t\t\t\t\t LPFC_RSC_TYPE_FCOE_RPI);\n\t\t\tif (rc != 0)\n\t\t\t\terror++;\n\n\t\t\t \n\t\t\tif (error) {\n\t\t\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\t\t\tLOG_MBOX | LOG_INIT,\n\t\t\t\t\t\t\"2931 Detected extent resource \"\n\t\t\t\t\t\t\"change.  Reallocating all \"\n\t\t\t\t\t\t\"extents.\\n\");\n\t\t\t\trc = lpfc_sli4_dealloc_extent(phba,\n\t\t\t\t\t\t LPFC_RSC_TYPE_FCOE_VFI);\n\t\t\t\trc = lpfc_sli4_dealloc_extent(phba,\n\t\t\t\t\t\t LPFC_RSC_TYPE_FCOE_VPI);\n\t\t\t\trc = lpfc_sli4_dealloc_extent(phba,\n\t\t\t\t\t\t LPFC_RSC_TYPE_FCOE_XRI);\n\t\t\t\trc = lpfc_sli4_dealloc_extent(phba,\n\t\t\t\t\t\t LPFC_RSC_TYPE_FCOE_RPI);\n\t\t\t} else\n\t\t\t\treturn 0;\n\t\t}\n\n\t\trc = lpfc_sli4_alloc_extent(phba, LPFC_RSC_TYPE_FCOE_VFI);\n\t\tif (unlikely(rc))\n\t\t\tgoto err_exit;\n\n\t\trc = lpfc_sli4_alloc_extent(phba, LPFC_RSC_TYPE_FCOE_VPI);\n\t\tif (unlikely(rc))\n\t\t\tgoto err_exit;\n\n\t\trc = lpfc_sli4_alloc_extent(phba, LPFC_RSC_TYPE_FCOE_RPI);\n\t\tif (unlikely(rc))\n\t\t\tgoto err_exit;\n\n\t\trc = lpfc_sli4_alloc_extent(phba, LPFC_RSC_TYPE_FCOE_XRI);\n\t\tif (unlikely(rc))\n\t\t\tgoto err_exit;\n\t\tbf_set(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags,\n\t\t       LPFC_IDX_RSRC_RDY);\n\t\treturn rc;\n\t} else {\n\t\t \n\t\tif (bf_get(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags) ==\n\t\t    LPFC_IDX_RSRC_RDY) {\n\t\t\tlpfc_sli4_dealloc_resource_identifiers(phba);\n\t\t\tlpfc_sli4_remove_rpis(phba);\n\t\t}\n\t\t \n\t\tcount = phba->sli4_hba.max_cfg_param.max_rpi;\n\t\tif (count <= 0) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3279 Invalid provisioning of \"\n\t\t\t\t\t\"rpi:%d\\n\", count);\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_exit;\n\t\t}\n\t\tbase = phba->sli4_hba.max_cfg_param.rpi_base;\n\t\tlongs = (count + BITS_PER_LONG - 1) / BITS_PER_LONG;\n\t\tphba->sli4_hba.rpi_bmask = kcalloc(longs,\n\t\t\t\t\t\t   sizeof(unsigned long),\n\t\t\t\t\t\t   GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.rpi_bmask)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_exit;\n\t\t}\n\t\tphba->sli4_hba.rpi_ids = kcalloc(count, sizeof(uint16_t),\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.rpi_ids)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_rpi_bmask;\n\t\t}\n\n\t\tfor (i = 0; i < count; i++)\n\t\t\tphba->sli4_hba.rpi_ids[i] = base + i;\n\n\t\t \n\t\tcount = phba->sli4_hba.max_cfg_param.max_vpi;\n\t\tif (count <= 0) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3280 Invalid provisioning of \"\n\t\t\t\t\t\"vpi:%d\\n\", count);\n\t\t\trc = -EINVAL;\n\t\t\tgoto free_rpi_ids;\n\t\t}\n\t\tbase = phba->sli4_hba.max_cfg_param.vpi_base;\n\t\tlongs = (count + BITS_PER_LONG - 1) / BITS_PER_LONG;\n\t\tphba->vpi_bmask = kcalloc(longs, sizeof(unsigned long),\n\t\t\t\t\t  GFP_KERNEL);\n\t\tif (unlikely(!phba->vpi_bmask)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_rpi_ids;\n\t\t}\n\t\tphba->vpi_ids = kcalloc(count, sizeof(uint16_t),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (unlikely(!phba->vpi_ids)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_vpi_bmask;\n\t\t}\n\n\t\tfor (i = 0; i < count; i++)\n\t\t\tphba->vpi_ids[i] = base + i;\n\n\t\t \n\t\tcount = phba->sli4_hba.max_cfg_param.max_xri;\n\t\tif (count <= 0) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3281 Invalid provisioning of \"\n\t\t\t\t\t\"xri:%d\\n\", count);\n\t\t\trc = -EINVAL;\n\t\t\tgoto free_vpi_ids;\n\t\t}\n\t\tbase = phba->sli4_hba.max_cfg_param.xri_base;\n\t\tlongs = (count + BITS_PER_LONG - 1) / BITS_PER_LONG;\n\t\tphba->sli4_hba.xri_bmask = kcalloc(longs,\n\t\t\t\t\t\t   sizeof(unsigned long),\n\t\t\t\t\t\t   GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.xri_bmask)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_vpi_ids;\n\t\t}\n\t\tphba->sli4_hba.max_cfg_param.xri_used = 0;\n\t\tphba->sli4_hba.xri_ids = kcalloc(count, sizeof(uint16_t),\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.xri_ids)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_xri_bmask;\n\t\t}\n\n\t\tfor (i = 0; i < count; i++)\n\t\t\tphba->sli4_hba.xri_ids[i] = base + i;\n\n\t\t \n\t\tcount = phba->sli4_hba.max_cfg_param.max_vfi;\n\t\tif (count <= 0) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3282 Invalid provisioning of \"\n\t\t\t\t\t\"vfi:%d\\n\", count);\n\t\t\trc = -EINVAL;\n\t\t\tgoto free_xri_ids;\n\t\t}\n\t\tbase = phba->sli4_hba.max_cfg_param.vfi_base;\n\t\tlongs = (count + BITS_PER_LONG - 1) / BITS_PER_LONG;\n\t\tphba->sli4_hba.vfi_bmask = kcalloc(longs,\n\t\t\t\t\t\t   sizeof(unsigned long),\n\t\t\t\t\t\t   GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.vfi_bmask)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_xri_ids;\n\t\t}\n\t\tphba->sli4_hba.vfi_ids = kcalloc(count, sizeof(uint16_t),\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (unlikely(!phba->sli4_hba.vfi_ids)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_vfi_bmask;\n\t\t}\n\n\t\tfor (i = 0; i < count; i++)\n\t\t\tphba->sli4_hba.vfi_ids[i] = base + i;\n\n\t\t \n\t\tbf_set(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags,\n\t\t       LPFC_IDX_RSRC_RDY);\n\t\treturn 0;\n\t}\n\n free_vfi_bmask:\n\tkfree(phba->sli4_hba.vfi_bmask);\n\tphba->sli4_hba.vfi_bmask = NULL;\n free_xri_ids:\n\tkfree(phba->sli4_hba.xri_ids);\n\tphba->sli4_hba.xri_ids = NULL;\n free_xri_bmask:\n\tkfree(phba->sli4_hba.xri_bmask);\n\tphba->sli4_hba.xri_bmask = NULL;\n free_vpi_ids:\n\tkfree(phba->vpi_ids);\n\tphba->vpi_ids = NULL;\n free_vpi_bmask:\n\tkfree(phba->vpi_bmask);\n\tphba->vpi_bmask = NULL;\n free_rpi_ids:\n\tkfree(phba->sli4_hba.rpi_ids);\n\tphba->sli4_hba.rpi_ids = NULL;\n free_rpi_bmask:\n\tkfree(phba->sli4_hba.rpi_bmask);\n\tphba->sli4_hba.rpi_bmask = NULL;\n err_exit:\n\treturn rc;\n}\n\n \nint\nlpfc_sli4_dealloc_resource_identifiers(struct lpfc_hba *phba)\n{\n\tif (phba->sli4_hba.extents_in_use) {\n\t\tlpfc_sli4_dealloc_extent(phba, LPFC_RSC_TYPE_FCOE_VPI);\n\t\tlpfc_sli4_dealloc_extent(phba, LPFC_RSC_TYPE_FCOE_RPI);\n\t\tlpfc_sli4_dealloc_extent(phba, LPFC_RSC_TYPE_FCOE_XRI);\n\t\tlpfc_sli4_dealloc_extent(phba, LPFC_RSC_TYPE_FCOE_VFI);\n\t} else {\n\t\tkfree(phba->vpi_bmask);\n\t\tphba->sli4_hba.max_cfg_param.vpi_used = 0;\n\t\tkfree(phba->vpi_ids);\n\t\tbf_set(lpfc_vpi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\n\t\tkfree(phba->sli4_hba.xri_bmask);\n\t\tkfree(phba->sli4_hba.xri_ids);\n\t\tkfree(phba->sli4_hba.vfi_bmask);\n\t\tkfree(phba->sli4_hba.vfi_ids);\n\t\tbf_set(lpfc_vfi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\n\t\tbf_set(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\n\t}\n\n\treturn 0;\n}\n\n \nint\nlpfc_sli4_get_allocated_extnts(struct lpfc_hba *phba, uint16_t type,\n\t\t\t       uint16_t *extnt_cnt, uint16_t *extnt_size)\n{\n\tbool emb;\n\tint rc = 0;\n\tuint16_t curr_blks = 0;\n\tuint32_t req_len, emb_len;\n\tuint32_t alloc_len, mbox_tmo;\n\tstruct list_head *blk_list_head;\n\tstruct lpfc_rsrc_blks *rsrc_blk;\n\tLPFC_MBOXQ_t *mbox;\n\tvoid *virtaddr = NULL;\n\tstruct lpfc_mbx_nembed_rsrc_extent *n_rsrc;\n\tstruct lpfc_mbx_alloc_rsrc_extents *rsrc_ext;\n\tunion  lpfc_sli4_cfg_shdr *shdr;\n\n\tswitch (type) {\n\tcase LPFC_RSC_TYPE_FCOE_VPI:\n\t\tblk_list_head = &phba->lpfc_vpi_blk_list;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_XRI:\n\t\tblk_list_head = &phba->sli4_hba.lpfc_xri_blk_list;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_VFI:\n\t\tblk_list_head = &phba->sli4_hba.lpfc_vfi_blk_list;\n\t\tbreak;\n\tcase LPFC_RSC_TYPE_FCOE_RPI:\n\t\tblk_list_head = &phba->sli4_hba.lpfc_rpi_blk_list;\n\t\tbreak;\n\tdefault:\n\t\treturn -EIO;\n\t}\n\n\t \n\tlist_for_each_entry(rsrc_blk, blk_list_head, list) {\n\t\tif (curr_blks == 0) {\n\t\t\t \n\t\t\t*extnt_size = rsrc_blk->rsrc_size;\n\t\t}\n\t\tcurr_blks++;\n\t}\n\n\t \n\temb_len = sizeof(MAILBOX_t) - sizeof(struct mbox_header) -\n\t\tsizeof(uint32_t);\n\n\t \n\temb = LPFC_SLI4_MBX_EMBED;\n\treq_len = emb_len;\n\tif (req_len > emb_len) {\n\t\treq_len = curr_blks * sizeof(uint16_t) +\n\t\t\tsizeof(union lpfc_sli4_cfg_shdr) +\n\t\t\tsizeof(uint32_t);\n\t\temb = LPFC_SLI4_MBX_NEMBED;\n\t}\n\n\tmbox = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tmemset(mbox, 0, sizeof(LPFC_MBOXQ_t));\n\n\talloc_len = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t\t     LPFC_MBOX_OPCODE_GET_ALLOC_RSRC_EXTENT,\n\t\t\t\t     req_len, emb);\n\tif (alloc_len < req_len) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2983 Allocated DMA memory size (x%x) is \"\n\t\t\t\"less than the requested DMA memory \"\n\t\t\t\"size (x%x)\\n\", alloc_len, req_len);\n\t\trc = -ENOMEM;\n\t\tgoto err_exit;\n\t}\n\trc = lpfc_sli4_mbox_rsrc_extent(phba, mbox, curr_blks, type, emb);\n\tif (unlikely(rc)) {\n\t\trc = -EIO;\n\t\tgoto err_exit;\n\t}\n\n\tif (!phba->sli4_hba.intr_enable)\n\t\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\n\t}\n\n\tif (unlikely(rc)) {\n\t\trc = -EIO;\n\t\tgoto err_exit;\n\t}\n\n\t \n\tif (emb == LPFC_SLI4_MBX_EMBED) {\n\t\trsrc_ext = &mbox->u.mqe.un.alloc_rsrc_extents;\n\t\tshdr = &rsrc_ext->header.cfg_shdr;\n\t\t*extnt_cnt = bf_get(lpfc_mbx_rsrc_cnt, &rsrc_ext->u.rsp);\n\t} else {\n\t\tvirtaddr = mbox->sge_array->addr[0];\n\t\tn_rsrc = (struct lpfc_mbx_nembed_rsrc_extent *) virtaddr;\n\t\tshdr = &n_rsrc->cfg_shdr;\n\t\t*extnt_cnt = bf_get(lpfc_mbx_rsrc_cnt, n_rsrc);\n\t}\n\n\tif (bf_get(lpfc_mbox_hdr_status, &shdr->response)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2984 Failed to read allocated resources \"\n\t\t\t\"for type %d - Status 0x%x Add'l Status 0x%x.\\n\",\n\t\t\ttype,\n\t\t\tbf_get(lpfc_mbox_hdr_status, &shdr->response),\n\t\t\tbf_get(lpfc_mbox_hdr_add_status, &shdr->response));\n\t\trc = -EIO;\n\t\tgoto err_exit;\n\t}\n err_exit:\n\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_repost_sgl_list(struct lpfc_hba *phba,\n\t\t\t  struct list_head *sgl_list, int cnt)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL;\n\tstruct lpfc_sglq *sglq_entry_next = NULL;\n\tstruct lpfc_sglq *sglq_entry_first = NULL;\n\tint status, total_cnt;\n\tint post_cnt = 0, num_posted = 0, block_cnt = 0;\n\tint last_xritag = NO_XRI;\n\tLIST_HEAD(prep_sgl_list);\n\tLIST_HEAD(blck_sgl_list);\n\tLIST_HEAD(allc_sgl_list);\n\tLIST_HEAD(post_sgl_list);\n\tLIST_HEAD(free_sgl_list);\n\n\tspin_lock_irq(&phba->hbalock);\n\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\tlist_splice_init(sgl_list, &allc_sgl_list);\n\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\tspin_unlock_irq(&phba->hbalock);\n\n\ttotal_cnt = cnt;\n\tlist_for_each_entry_safe(sglq_entry, sglq_entry_next,\n\t\t\t\t &allc_sgl_list, list) {\n\t\tlist_del_init(&sglq_entry->list);\n\t\tblock_cnt++;\n\t\tif ((last_xritag != NO_XRI) &&\n\t\t    (sglq_entry->sli4_xritag != last_xritag + 1)) {\n\t\t\t \n\t\t\tlist_splice_init(&prep_sgl_list, &blck_sgl_list);\n\t\t\tpost_cnt = block_cnt - 1;\n\t\t\t \n\t\t\tlist_add_tail(&sglq_entry->list, &prep_sgl_list);\n\t\t\tblock_cnt = 1;\n\t\t} else {\n\t\t\t \n\t\t\tlist_add_tail(&sglq_entry->list, &prep_sgl_list);\n\t\t\t \n\t\t\tif (block_cnt == LPFC_NEMBED_MBOX_SGL_CNT) {\n\t\t\t\tlist_splice_init(&prep_sgl_list,\n\t\t\t\t\t\t &blck_sgl_list);\n\t\t\t\tpost_cnt = block_cnt;\n\t\t\t\tblock_cnt = 0;\n\t\t\t}\n\t\t}\n\t\tnum_posted++;\n\n\t\t \n\t\tlast_xritag = sglq_entry->sli4_xritag;\n\n\t\t \n\t\tif (num_posted == total_cnt) {\n\t\t\tif (post_cnt == 0) {\n\t\t\t\tlist_splice_init(&prep_sgl_list,\n\t\t\t\t\t\t &blck_sgl_list);\n\t\t\t\tpost_cnt = block_cnt;\n\t\t\t} else if (block_cnt == 1) {\n\t\t\t\tstatus = lpfc_sli4_post_sgl(phba,\n\t\t\t\t\t\tsglq_entry->phys, 0,\n\t\t\t\t\t\tsglq_entry->sli4_xritag);\n\t\t\t\tif (!status) {\n\t\t\t\t\t \n\t\t\t\t\tlist_add_tail(&sglq_entry->list,\n\t\t\t\t\t\t      &post_sgl_list);\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tlpfc_printf_log(phba, KERN_WARNING,\n\t\t\t\t\t\tLOG_SLI,\n\t\t\t\t\t\t\"3159 Failed to post \"\n\t\t\t\t\t\t\"sgl, xritag:x%x\\n\",\n\t\t\t\t\t\tsglq_entry->sli4_xritag);\n\t\t\t\t\tlist_add_tail(&sglq_entry->list,\n\t\t\t\t\t\t      &free_sgl_list);\n\t\t\t\t\ttotal_cnt--;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (post_cnt == 0)\n\t\t\tcontinue;\n\n\t\t \n\t\tstatus = lpfc_sli4_post_sgl_list(phba, &blck_sgl_list,\n\t\t\t\t\t\t post_cnt);\n\n\t\tif (!status) {\n\t\t\t \n\t\t\tlist_splice_init(&blck_sgl_list, &post_sgl_list);\n\t\t} else {\n\t\t\t \n\t\t\tsglq_entry_first = list_first_entry(&blck_sgl_list,\n\t\t\t\t\t\t\t    struct lpfc_sglq,\n\t\t\t\t\t\t\t    list);\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\t\"3160 Failed to post sgl-list, \"\n\t\t\t\t\t\"xritag:x%x-x%x\\n\",\n\t\t\t\t\tsglq_entry_first->sli4_xritag,\n\t\t\t\t\t(sglq_entry_first->sli4_xritag +\n\t\t\t\t\t post_cnt - 1));\n\t\t\tlist_splice_init(&blck_sgl_list, &free_sgl_list);\n\t\t\ttotal_cnt -= post_cnt;\n\t\t}\n\n\t\t \n\t\tif (block_cnt == 0)\n\t\t\tlast_xritag = NO_XRI;\n\n\t\t \n\t\tpost_cnt = 0;\n\t}\n\n\t \n\tlpfc_free_sgl_list(phba, &free_sgl_list);\n\n\t \n\tif (!list_empty(&post_sgl_list)) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\t\tlist_splice_init(&post_sgl_list, sgl_list);\n\t\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\t\tspin_unlock_irq(&phba->hbalock);\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3161 Failure to post sgl to port,status %x \"\n\t\t\t\t\"blkcnt %d totalcnt %d postcnt %d\\n\",\n\t\t\t\tstatus, block_cnt, total_cnt, post_cnt);\n\t\treturn -EIO;\n\t}\n\n\t \n\treturn total_cnt;\n}\n\n \nstatic int\nlpfc_sli4_repost_io_sgl_list(struct lpfc_hba *phba)\n{\n\tLIST_HEAD(post_nblist);\n\tint num_posted, rc = 0;\n\n\t \n\tlpfc_io_buf_flush(phba, &post_nblist);\n\n\t \n\tif (!list_empty(&post_nblist)) {\n\t\tnum_posted = lpfc_sli4_post_io_sgl_list(\n\t\t\tphba, &post_nblist, phba->sli4_hba.io_xri_cnt);\n\t\t \n\t\tif (num_posted == 0)\n\t\t\trc = -EIO;\n\t}\n\treturn rc;\n}\n\nstatic void\nlpfc_set_host_data(struct lpfc_hba *phba, LPFC_MBOXQ_t *mbox)\n{\n\tuint32_t len;\n\n\tlen = sizeof(struct lpfc_mbx_set_host_data) -\n\t\tsizeof(struct lpfc_sli4_cfg_mhdr);\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_SET_HOST_DATA, len,\n\t\t\t LPFC_SLI4_MBX_EMBED);\n\n\tmbox->u.mqe.un.set_host_data.param_id = LPFC_SET_HOST_OS_DRIVER_VERSION;\n\tmbox->u.mqe.un.set_host_data.param_len =\n\t\t\t\t\tLPFC_HOST_OS_DRIVER_VERSION_SIZE;\n\tsnprintf(mbox->u.mqe.un.set_host_data.un.data,\n\t\t LPFC_HOST_OS_DRIVER_VERSION_SIZE,\n\t\t \"Linux %s v\"LPFC_DRIVER_VERSION,\n\t\t (phba->hba_flag & HBA_FCOE_MODE) ? \"FCoE\" : \"FC\");\n}\n\nint\nlpfc_post_rq_buffer(struct lpfc_hba *phba, struct lpfc_queue *hrq,\n\t\t    struct lpfc_queue *drq, int count, int idx)\n{\n\tint rc, i;\n\tstruct lpfc_rqe hrqe;\n\tstruct lpfc_rqe drqe;\n\tstruct lpfc_rqb *rqbp;\n\tunsigned long flags;\n\tstruct rqb_dmabuf *rqb_buffer;\n\tLIST_HEAD(rqb_buf_list);\n\n\trqbp = hrq->rqbp;\n\tfor (i = 0; i < count; i++) {\n\t\tspin_lock_irqsave(&phba->hbalock, flags);\n\t\t \n\t\tif (rqbp->buffer_count + i >= rqbp->entry_count - 1) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, flags);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock_irqrestore(&phba->hbalock, flags);\n\n\t\trqb_buffer = rqbp->rqb_alloc_buffer(phba);\n\t\tif (!rqb_buffer)\n\t\t\tbreak;\n\t\trqb_buffer->hrq = hrq;\n\t\trqb_buffer->drq = drq;\n\t\trqb_buffer->idx = idx;\n\t\tlist_add_tail(&rqb_buffer->hbuf.list, &rqb_buf_list);\n\t}\n\n\tspin_lock_irqsave(&phba->hbalock, flags);\n\twhile (!list_empty(&rqb_buf_list)) {\n\t\tlist_remove_head(&rqb_buf_list, rqb_buffer, struct rqb_dmabuf,\n\t\t\t\t hbuf.list);\n\n\t\thrqe.address_lo = putPaddrLow(rqb_buffer->hbuf.phys);\n\t\thrqe.address_hi = putPaddrHigh(rqb_buffer->hbuf.phys);\n\t\tdrqe.address_lo = putPaddrLow(rqb_buffer->dbuf.phys);\n\t\tdrqe.address_hi = putPaddrHigh(rqb_buffer->dbuf.phys);\n\t\trc = lpfc_sli4_rq_put(hrq, drq, &hrqe, &drqe);\n\t\tif (rc < 0) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6421 Cannot post to HRQ %d: %x %x %x \"\n\t\t\t\t\t\"DRQ %x %x\\n\",\n\t\t\t\t\thrq->queue_id,\n\t\t\t\t\thrq->host_index,\n\t\t\t\t\thrq->hba_index,\n\t\t\t\t\thrq->entry_count,\n\t\t\t\t\tdrq->host_index,\n\t\t\t\t\tdrq->hba_index);\n\t\t\trqbp->rqb_free_buffer(phba, rqb_buffer);\n\t\t} else {\n\t\t\tlist_add_tail(&rqb_buffer->hbuf.list,\n\t\t\t\t      &rqbp->rqb_buffer_list);\n\t\t\trqbp->buffer_count++;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, flags);\n\treturn 1;\n}\n\nstatic void\nlpfc_mbx_cmpl_read_lds_params(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\n{\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tu32 shdr_status, shdr_add_status;\n\n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&pmb->u.mqe.un.sli4_config.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || pmb->u.mb.mbxStatus) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_LDS_EVENT | LOG_MBOX,\n\t\t\t\t\"4622 SET_FEATURE (x%x) mbox failed, \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tLPFC_SET_LD_SIGNAL, shdr_status,\n\t\t\t\tshdr_add_status, pmb->u.mb.mbxStatus);\n\t\tphba->degrade_activate_threshold = 0;\n\t\tphba->degrade_deactivate_threshold = 0;\n\t\tphba->fec_degrade_interval = 0;\n\t\tgoto out;\n\t}\n\n\tphba->degrade_activate_threshold = pmb->u.mqe.un.set_feature.word7;\n\tphba->degrade_deactivate_threshold = pmb->u.mqe.un.set_feature.word8;\n\tphba->fec_degrade_interval = pmb->u.mqe.un.set_feature.word10;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_LDS_EVENT,\n\t\t\t\"4624 Success: da x%x dd x%x interval x%x\\n\",\n\t\t\tphba->degrade_activate_threshold,\n\t\t\tphba->degrade_deactivate_threshold,\n\t\t\tphba->fec_degrade_interval);\nout:\n\tmempool_free(pmb, phba->mbox_mem_pool);\n}\n\nint\nlpfc_read_lds_params(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tint rc;\n\n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\n\tlpfc_set_features(phba, mboxq, LPFC_SET_LD_SIGNAL);\n\tmboxq->vport = phba->pport;\n\tmboxq->mbox_cmpl = lpfc_mbx_cmpl_read_lds_params;\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED) {\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\treturn 0;\n}\n\nstatic void\nlpfc_mbx_cmpl_cgn_set_ftrs(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\n{\n\tstruct lpfc_vport *vport = pmb->vport;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tu32 shdr_status, shdr_add_status;\n\tu32 sig, acqe;\n\n\t \n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&pmb->u.mqe.un.sli4_config.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || pmb->u.mb.mbxStatus) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_CGN_MGMT,\n\t\t\t\t\"2516 CGN SET_FEATURE mbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x \"\n\t\t\t\t\"Reset Congestion to FPINs only\\n\",\n\t\t\t\tshdr_status, shdr_add_status,\n\t\t\t\tpmb->u.mb.mbxStatus);\n\t\t \n\t\tphba->cgn_reg_signal = EDC_CG_SIG_NOTSUPPORTED;\n\t\tphba->cgn_reg_fpin = LPFC_CGN_FPIN_WARN | LPFC_CGN_FPIN_ALARM;\n\t\tgoto out;\n\t}\n\n\t \n\tphba->cgn_acqe_cnt = 0;\n\n\tacqe = bf_get(lpfc_mbx_set_feature_CGN_acqe_freq,\n\t\t      &pmb->u.mqe.un.set_feature);\n\tsig = bf_get(lpfc_mbx_set_feature_CGN_warn_freq,\n\t\t     &pmb->u.mqe.un.set_feature);\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\"4620 SET_FEATURES Success: Freq: %ds %dms \"\n\t\t\t\" Reg: x%x x%x\\n\", acqe, sig,\n\t\t\tphba->cgn_reg_signal, phba->cgn_reg_fpin);\nout:\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\n\t \n\tlpfc_issue_els_rdf(vport, 0);\n}\n\nint\nlpfc_config_cgn_signal(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tu32 rc;\n\n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\tgoto out_rdf;\n\n\tlpfc_set_features(phba, mboxq, LPFC_SET_CGN_SIGNAL);\n\tmboxq->vport = phba->pport;\n\tmboxq->mbox_cmpl = lpfc_mbx_cmpl_cgn_set_ftrs;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\"4621 SET_FEATURES: FREQ sig x%x acqe x%x: \"\n\t\t\t\"Reg: x%x x%x\\n\",\n\t\t\tphba->cgn_sig_freq, lpfc_acqe_cgn_frequency,\n\t\t\tphba->cgn_reg_signal, phba->cgn_reg_fpin);\n\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED)\n\t\tgoto out;\n\treturn 0;\n\nout:\n\tmempool_free(mboxq, phba->mbox_mem_pool);\nout_rdf:\n\t \n\tphba->cgn_reg_fpin = LPFC_CGN_FPIN_WARN | LPFC_CGN_FPIN_ALARM;\n\tphba->cgn_reg_signal = EDC_CG_SIG_NOTSUPPORTED;\n\tlpfc_issue_els_rdf(phba->pport, 0);\n\treturn -EIO;\n}\n\n \nstatic void lpfc_init_idle_stat_hb(struct lpfc_hba *phba)\n{\n\tint i;\n\tstruct lpfc_sli4_hdw_queue *hdwq;\n\tstruct lpfc_queue *eq;\n\tstruct lpfc_idle_stat *idle_stat;\n\tu64 wall;\n\n\tfor_each_present_cpu(i) {\n\t\thdwq = &phba->sli4_hba.hdwq[phba->sli4_hba.cpu_map[i].hdwq];\n\t\teq = hdwq->hba_eq;\n\n\t\t \n\t\tif (eq->chann != i)\n\t\t\tcontinue;\n\n\t\tidle_stat = &phba->sli4_hba.idle_stat[i];\n\n\t\tidle_stat->prev_idle = get_cpu_idle_time(i, &wall, 1);\n\t\tidle_stat->prev_wall = wall;\n\n\t\tif (phba->nvmet_support ||\n\t\t    phba->cmf_active_mode != LPFC_CFG_OFF ||\n\t\t    phba->intr_type != MSIX)\n\t\t\teq->poll_mode = LPFC_QUEUE_WORK;\n\t\telse\n\t\t\teq->poll_mode = LPFC_THREADED_IRQ;\n\t}\n\n\tif (!phba->nvmet_support && phba->intr_type == MSIX)\n\t\tschedule_delayed_work(&phba->idle_stat_delay_work,\n\t\t\t\t      msecs_to_jiffies(LPFC_IDLE_STAT_DELAY));\n}\n\nstatic void lpfc_sli4_dip(struct lpfc_hba *phba)\n{\n\tuint32_t if_type;\n\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tif (if_type == LPFC_SLI_INTF_IF_TYPE_2 ||\n\t    if_type == LPFC_SLI_INTF_IF_TYPE_6) {\n\t\tstruct lpfc_register reg_data;\n\n\t\tif (lpfc_readl(phba->sli4_hba.u.if_type2.STATUSregaddr,\n\t\t\t       &reg_data.word0))\n\t\t\treturn;\n\n\t\tif (bf_get(lpfc_sliport_status_dip, &reg_data))\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\t\"2904 Firmware Dump Image Present\"\n\t\t\t\t\t\" on Adapter\");\n\t}\n}\n\n \nint lpfc_rx_monitor_create_ring(struct lpfc_rx_info_monitor *rx_monitor,\n\t\t\t\tu32 entries)\n{\n\trx_monitor->ring = kmalloc_array(entries, sizeof(struct rx_info_entry),\n\t\t\t\t\t GFP_KERNEL);\n\tif (!rx_monitor->ring)\n\t\treturn -ENOMEM;\n\n\trx_monitor->head_idx = 0;\n\trx_monitor->tail_idx = 0;\n\tspin_lock_init(&rx_monitor->lock);\n\trx_monitor->entries = entries;\n\n\treturn 0;\n}\n\n \nvoid lpfc_rx_monitor_destroy_ring(struct lpfc_rx_info_monitor *rx_monitor)\n{\n\tkfree(rx_monitor->ring);\n\trx_monitor->ring = NULL;\n\trx_monitor->entries = 0;\n\trx_monitor->head_idx = 0;\n\trx_monitor->tail_idx = 0;\n}\n\n \nvoid lpfc_rx_monitor_record(struct lpfc_rx_info_monitor *rx_monitor,\n\t\t\t    struct rx_info_entry *entry)\n{\n\tstruct rx_info_entry *ring = rx_monitor->ring;\n\tu32 *head_idx = &rx_monitor->head_idx;\n\tu32 *tail_idx = &rx_monitor->tail_idx;\n\tspinlock_t *ring_lock = &rx_monitor->lock;\n\tu32 ring_size = rx_monitor->entries;\n\n\tspin_lock(ring_lock);\n\tmemcpy(&ring[*tail_idx], entry, sizeof(*entry));\n\t*tail_idx = (*tail_idx + 1) % ring_size;\n\n\t \n\tif (*tail_idx == *head_idx)\n\t\t*head_idx = (*head_idx + 1) % ring_size;\n\n\tspin_unlock(ring_lock);\n}\n\n \nu32 lpfc_rx_monitor_report(struct lpfc_hba *phba,\n\t\t\t   struct lpfc_rx_info_monitor *rx_monitor, char *buf,\n\t\t\t   u32 buf_len, u32 max_read_entries)\n{\n\tstruct rx_info_entry *ring = rx_monitor->ring;\n\tstruct rx_info_entry *entry;\n\tu32 *head_idx = &rx_monitor->head_idx;\n\tu32 *tail_idx = &rx_monitor->tail_idx;\n\tspinlock_t *ring_lock = &rx_monitor->lock;\n\tu32 ring_size = rx_monitor->entries;\n\tu32 cnt = 0;\n\tchar tmp[DBG_LOG_STR_SZ] = {0};\n\tbool log_to_kmsg = (!buf || !buf_len) ? true : false;\n\n\tif (!log_to_kmsg) {\n\t\t \n\t\tmemset(buf, 0, buf_len);\n\n\t\tscnprintf(buf, buf_len, \"\\t%-16s%-16s%-16s%-16s%-8s%-8s%-8s\"\n\t\t\t\t\t\"%-8s%-8s%-8s%-16s\\n\",\n\t\t\t\t\t\"MaxBPI\", \"Tot_Data_CMF\",\n\t\t\t\t\t\"Tot_Data_Cmd\", \"Tot_Data_Cmpl\",\n\t\t\t\t\t\"Lat(us)\", \"Avg_IO\", \"Max_IO\", \"Bsy\",\n\t\t\t\t\t\"IO_cnt\", \"Info\", \"BWutil(ms)\");\n\t}\n\n\t \n\tspin_lock_irq(ring_lock);\n\twhile (*head_idx != *tail_idx) {\n\t\tentry = &ring[*head_idx];\n\n\t\t \n\t\tif (!log_to_kmsg) {\n\t\t\t \n\t\t\tscnprintf(tmp, sizeof(tmp),\n\t\t\t\t  \"%03d:\\t%-16llu%-16llu%-16llu%-16llu%-8llu\"\n\t\t\t\t  \"%-8llu%-8llu%-8u%-8u%-8u%u(%u)\\n\",\n\t\t\t\t  *head_idx, entry->max_bytes_per_interval,\n\t\t\t\t  entry->cmf_bytes, entry->total_bytes,\n\t\t\t\t  entry->rcv_bytes, entry->avg_io_latency,\n\t\t\t\t  entry->avg_io_size, entry->max_read_cnt,\n\t\t\t\t  entry->cmf_busy, entry->io_cnt,\n\t\t\t\t  entry->cmf_info, entry->timer_utilization,\n\t\t\t\t  entry->timer_interval);\n\n\t\t\t \n\t\t\tif ((strlen(buf) + strlen(tmp)) >= buf_len)\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\tstrlcat(buf, tmp, buf_len);\n\t\t} else {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_CGN_MGMT,\n\t\t\t\t\t\"4410 %02u: MBPI %llu Xmit %llu \"\n\t\t\t\t\t\"Cmpl %llu Lat %llu ASz %llu Info %02u \"\n\t\t\t\t\t\"BWUtil %u Int %u slot %u\\n\",\n\t\t\t\t\tcnt, entry->max_bytes_per_interval,\n\t\t\t\t\tentry->total_bytes, entry->rcv_bytes,\n\t\t\t\t\tentry->avg_io_latency,\n\t\t\t\t\tentry->avg_io_size, entry->cmf_info,\n\t\t\t\t\tentry->timer_utilization,\n\t\t\t\t\tentry->timer_interval, *head_idx);\n\t\t}\n\n\t\t*head_idx = (*head_idx + 1) % ring_size;\n\n\t\t \n\t\tcnt++;\n\t\tif (cnt >= max_read_entries)\n\t\t\tbreak;\n\t}\n\tspin_unlock_irq(ring_lock);\n\n\treturn cnt;\n}\n\n \nstatic int\nlpfc_cmf_setup(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct lpfc_dmabuf *mp;\n\tstruct lpfc_pc_sli4_params *sli4_params;\n\tint rc, cmf, mi_ver;\n\n\trc = lpfc_sli4_refresh_params(phba);\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\n\tsli4_params = &phba->sli4_hba.pc_sli4_params;\n\n\t \n\tif (sli4_params->mi_ver) {\n\t\tlpfc_set_features(phba, mboxq, LPFC_SET_ENABLE_MI);\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tmi_ver = bf_get(lpfc_mbx_set_feature_mi,\n\t\t\t\t &mboxq->u.mqe.un.set_feature);\n\n\t\tif (rc == MBX_SUCCESS) {\n\t\t\tif (mi_ver) {\n\t\t\t\tlpfc_printf_log(phba,\n\t\t\t\t\t\tKERN_WARNING, LOG_CGN_MGMT,\n\t\t\t\t\t\t\"6215 MI is enabled\\n\");\n\t\t\t\tsli4_params->mi_ver = mi_ver;\n\t\t\t} else {\n\t\t\t\tlpfc_printf_log(phba,\n\t\t\t\t\t\tKERN_WARNING, LOG_CGN_MGMT,\n\t\t\t\t\t\t\"6338 MI is disabled\\n\");\n\t\t\t\tsli4_params->mi_ver = 0;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\t\tLOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\t\"6245 Enable MI Mailbox x%x (x%x/x%x) \"\n\t\t\t\t\t\"failed, rc:x%x mi:x%x\\n\",\n\t\t\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\t\t\tlpfc_sli_config_mbox_subsys_get\n\t\t\t\t\t\t(phba, mboxq),\n\t\t\t\t\tlpfc_sli_config_mbox_opcode_get\n\t\t\t\t\t\t(phba, mboxq),\n\t\t\t\t\trc, sli4_params->mi_ver);\n\t\t}\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_CGN_MGMT,\n\t\t\t\t\"6217 MI is disabled\\n\");\n\t}\n\n\t \n\tif (sli4_params->mi_ver)\n\t\tphba->cfg_fdmi_on = LPFC_FDMI_SUPPORT;\n\n\t \n\tif (sli4_params->cmf) {\n\t\tlpfc_set_features(phba, mboxq, LPFC_SET_ENABLE_CMF);\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tcmf = bf_get(lpfc_mbx_set_feature_cmf,\n\t\t\t     &mboxq->u.mqe.un.set_feature);\n\t\tif (rc == MBX_SUCCESS && cmf) {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_CGN_MGMT,\n\t\t\t\t\t\"6218 CMF is enabled: mode %d\\n\",\n\t\t\t\t\tphba->cmf_active_mode);\n\t\t} else {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING,\n\t\t\t\t\tLOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\t\"6219 Enable CMF Mailbox x%x (x%x/x%x) \"\n\t\t\t\t\t\"failed, rc:x%x dd:x%x\\n\",\n\t\t\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\t\t\tlpfc_sli_config_mbox_subsys_get\n\t\t\t\t\t\t(phba, mboxq),\n\t\t\t\t\tlpfc_sli_config_mbox_opcode_get\n\t\t\t\t\t\t(phba, mboxq),\n\t\t\t\t\trc, cmf);\n\t\t\tsli4_params->cmf = 0;\n\t\t\tphba->cmf_active_mode = LPFC_CFG_OFF;\n\t\t\tgoto no_cmf;\n\t\t}\n\n\t\t \n\t\tif (!phba->cgn_i) {\n\t\t\tmp = kmalloc(sizeof(*mp), GFP_KERNEL);\n\t\t\tif (mp)\n\t\t\t\tmp->virt = dma_alloc_coherent\n\t\t\t\t\t\t(&phba->pcidev->dev,\n\t\t\t\t\t\tsizeof(struct lpfc_cgn_info),\n\t\t\t\t\t\t&mp->phys, GFP_KERNEL);\n\t\t\tif (!mp || !mp->virt) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\t\t\"2640 Failed to alloc memory \"\n\t\t\t\t\t\t\"for Congestion Info\\n\");\n\t\t\t\tkfree(mp);\n\t\t\t\tsli4_params->cmf = 0;\n\t\t\t\tphba->cmf_active_mode = LPFC_CFG_OFF;\n\t\t\t\tgoto no_cmf;\n\t\t\t}\n\t\t\tphba->cgn_i = mp;\n\n\t\t\t \n\t\t\tlpfc_init_congestion_buf(phba);\n\t\t\tlpfc_init_congestion_stat(phba);\n\n\t\t\t \n\t\t\tatomic64_set(&phba->cgn_acqe_stat.alarm, 0);\n\t\t\tatomic64_set(&phba->cgn_acqe_stat.warn, 0);\n\t\t}\n\n\t\trc = lpfc_sli4_cgn_params_read(phba);\n\t\tif (rc < 0) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\t\"6242 Error reading Cgn Params (%d)\\n\",\n\t\t\t\t\trc);\n\t\t\t \n\t\t\tsli4_params->cmf = 0;\n\t\t} else if (!rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_CGN_MGMT | LOG_INIT,\n\t\t\t\t\t\"6243 CGN Event empty object.\\n\");\n\t\t\t \n\t\t\tsli4_params->cmf = 0;\n\t\t}\n\t} else {\nno_cmf:\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_CGN_MGMT,\n\t\t\t\t\"6220 CMF is disabled\\n\");\n\t}\n\n\t \n\tif (sli4_params->cmf && sli4_params->mi_ver) {\n\t\trc = lpfc_reg_congestion_buf(phba);\n\t\tif (rc) {\n\t\t\tdma_free_coherent(&phba->pcidev->dev,\n\t\t\t\t\t  sizeof(struct lpfc_cgn_info),\n\t\t\t\t\t  phba->cgn_i->virt, phba->cgn_i->phys);\n\t\t\tkfree(phba->cgn_i);\n\t\t\tphba->cgn_i = NULL;\n\t\t\t \n\t\t\tphba->cmf_active_mode = LPFC_CFG_OFF;\n\t\t\tsli4_params->cmf = 0;\n\t\t\treturn 0;\n\t\t}\n\t}\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"6470 Setup MI version %d CMF %d mode %d\\n\",\n\t\t\tsli4_params->mi_ver, sli4_params->cmf,\n\t\t\tphba->cmf_active_mode);\n\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\n\t \n\tatomic_set(&phba->cgn_fabric_warn_cnt, 0);\n\tatomic_set(&phba->cgn_fabric_alarm_cnt, 0);\n\tatomic_set(&phba->cgn_sync_alarm_cnt, 0);\n\tatomic_set(&phba->cgn_sync_warn_cnt, 0);\n\tatomic_set(&phba->cgn_driver_evt_cnt, 0);\n\tatomic_set(&phba->cgn_latency_evt_cnt, 0);\n\tatomic64_set(&phba->cgn_latency_evt, 0);\n\n\tphba->cmf_interval_rate = LPFC_CMF_INTERVAL;\n\n\t \n\tif (!phba->rx_monitor) {\n\t\tphba->rx_monitor = kzalloc(sizeof(*phba->rx_monitor),\n\t\t\t\t\t   GFP_KERNEL);\n\n\t\tif (!phba->rx_monitor) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\t\"2644 Failed to alloc memory \"\n\t\t\t\t\t\"for RX Monitor Buffer\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t \n\t\tif (lpfc_rx_monitor_create_ring(phba->rx_monitor,\n\t\t\t\t\t\tLPFC_MAX_RXMONITOR_ENTRY)) {\n\t\t\tkfree(phba->rx_monitor);\n\t\t\tphba->rx_monitor = NULL;\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\t\"2645 Failed to alloc memory \"\n\t\t\t\t\t\"for RX Monitor's Ring\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int\nlpfc_set_host_tm(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tuint32_t len, rc;\n\tstruct timespec64 cur_time;\n\tstruct tm broken;\n\tuint32_t month, day, year;\n\tuint32_t hour, minute, second;\n\tstruct lpfc_mbx_set_host_date_time *tm;\n\n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\n\tlen = sizeof(struct lpfc_mbx_set_host_data) -\n\t\tsizeof(struct lpfc_sli4_cfg_mhdr);\n\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_SET_HOST_DATA, len,\n\t\t\t LPFC_SLI4_MBX_EMBED);\n\n\tmboxq->u.mqe.un.set_host_data.param_id = LPFC_SET_HOST_DATE_TIME;\n\tmboxq->u.mqe.un.set_host_data.param_len =\n\t\t\tsizeof(struct lpfc_mbx_set_host_date_time);\n\ttm = &mboxq->u.mqe.un.set_host_data.un.tm;\n\tktime_get_real_ts64(&cur_time);\n\ttime64_to_tm(cur_time.tv_sec, 0, &broken);\n\tmonth = broken.tm_mon + 1;\n\tday = broken.tm_mday;\n\tyear = broken.tm_year - 100;\n\thour = broken.tm_hour;\n\tminute = broken.tm_min;\n\tsecond = broken.tm_sec;\n\tbf_set(lpfc_mbx_set_host_month, tm, month);\n\tbf_set(lpfc_mbx_set_host_day, tm, day);\n\tbf_set(lpfc_mbx_set_host_year, tm, year);\n\tbf_set(lpfc_mbx_set_host_hour, tm, hour);\n\tbf_set(lpfc_mbx_set_host_min, tm, minute);\n\tbf_set(lpfc_mbx_set_host_sec, tm, second);\n\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\treturn rc;\n}\n\n \nint\nlpfc_sli4_hba_setup(struct lpfc_hba *phba)\n{\n\tint rc, i, cnt, len, dd;\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct lpfc_mqe *mqe;\n\tuint8_t *vpd;\n\tuint32_t vpd_size;\n\tuint32_t ftr_rsp = 0;\n\tstruct Scsi_Host *shost = lpfc_shost_from_vport(phba->pport);\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct lpfc_dmabuf *mp;\n\tstruct lpfc_rqb *rqbp;\n\tu32 flg;\n\n\t \n\trc = lpfc_pci_function_reset(phba);\n\tif (unlikely(rc))\n\t\treturn -ENODEV;\n\n\t \n\trc = lpfc_sli4_post_status_check(phba);\n\tif (unlikely(rc))\n\t\treturn -ENODEV;\n\telse {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->sli.sli_flag |= LPFC_SLI_ACTIVE;\n\t\tflg = phba->sli.sli_flag;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\t \n\t\tfor (i = 0; i < 50 && (flg & LPFC_SLI_MBOX_ACTIVE); i++) {\n\t\t\tmsleep(20);\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tflg = phba->sli.sli_flag;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t}\n\t}\n\tphba->hba_flag &= ~HBA_SETUP;\n\n\tlpfc_sli4_dip(phba);\n\n\t \n\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\n\t \n\tvpd_size = SLI4_PAGE_SIZE;\n\tvpd = kzalloc(vpd_size, GFP_KERNEL);\n\tif (!vpd) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free_mbox;\n\t}\n\n\trc = lpfc_sli4_read_rev(phba, mboxq, vpd, &vpd_size);\n\tif (unlikely(rc)) {\n\t\tkfree(vpd);\n\t\tgoto out_free_mbox;\n\t}\n\n\tmqe = &mboxq->u.mqe;\n\tphba->sli_rev = bf_get(lpfc_mbx_rd_rev_sli_lvl, &mqe->un.read_rev);\n\tif (bf_get(lpfc_mbx_rd_rev_fcoe, &mqe->un.read_rev)) {\n\t\tphba->hba_flag |= HBA_FCOE_MODE;\n\t\tphba->fcp_embed_io = 0;\t \n\t} else {\n\t\tphba->hba_flag &= ~HBA_FCOE_MODE;\n\t}\n\n\tif (bf_get(lpfc_mbx_rd_rev_cee_ver, &mqe->un.read_rev) ==\n\t\tLPFC_DCBX_CEE_MODE)\n\t\tphba->hba_flag |= HBA_FIP_SUPPORT;\n\telse\n\t\tphba->hba_flag &= ~HBA_FIP_SUPPORT;\n\n\tphba->hba_flag &= ~HBA_IOQ_FLUSH;\n\n\tif (phba->sli_rev != LPFC_SLI_REV4) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0376 READ_REV Error. SLI Level %d \"\n\t\t\t\"FCoE enabled %d\\n\",\n\t\t\tphba->sli_rev, phba->hba_flag & HBA_FCOE_MODE);\n\t\trc = -EIO;\n\t\tkfree(vpd);\n\t\tgoto out_free_mbox;\n\t}\n\n\trc = lpfc_set_host_tm(phba);\n\tlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_INIT,\n\t\t\t\"6468 Set host date / time: Status x%x:\\n\", rc);\n\n\t \n\tif (phba->hba_flag & HBA_FCOE_MODE &&\n\t    lpfc_sli4_read_fcoe_params(phba))\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_INIT,\n\t\t\t\"2570 Failed to read FCoE parameters\\n\");\n\n\t \n\trc = lpfc_sli4_retrieve_pport_name(phba);\n\tif (!rc)\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\t\"3080 Successful retrieving SLI4 device \"\n\t\t\t\t\"physical port name: %s.\\n\", phba->Port);\n\n\trc = lpfc_sli4_get_ctl_attr(phba);\n\tif (!rc)\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\t\"8351 Successful retrieving SLI4 device \"\n\t\t\t\t\"CTL ATTR\\n\");\n\n\t \n\trc = lpfc_parse_vpd(phba, vpd, vpd_size);\n\tif (unlikely(!rc)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0377 Error %d parsing vpd. \"\n\t\t\t\t\"Using defaults.\\n\", rc);\n\t\trc = 0;\n\t}\n\tkfree(vpd);\n\n\t \n\tphba->vpd.rev.biuRev = mqe->un.read_rev.first_hw_rev;\n\tphba->vpd.rev.smRev = mqe->un.read_rev.second_hw_rev;\n\n\t \n\tif ((bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) ==\n\t\t\tLPFC_SLI_INTF_IF_TYPE_6) &&\n\t    (phba->vpd.rev.biuRev == LPFC_G7_ASIC_1) &&\n\t    (phba->vpd.rev.smRev == 0) &&\n\t    (phba->cfg_nvme_embed_cmd == 1))\n\t\tphba->cfg_nvme_embed_cmd = 0;\n\n\tphba->vpd.rev.endecRev = mqe->un.read_rev.third_hw_rev;\n\tphba->vpd.rev.fcphHigh = bf_get(lpfc_mbx_rd_rev_fcph_high,\n\t\t\t\t\t &mqe->un.read_rev);\n\tphba->vpd.rev.fcphLow = bf_get(lpfc_mbx_rd_rev_fcph_low,\n\t\t\t\t       &mqe->un.read_rev);\n\tphba->vpd.rev.feaLevelHigh = bf_get(lpfc_mbx_rd_rev_ftr_lvl_high,\n\t\t\t\t\t    &mqe->un.read_rev);\n\tphba->vpd.rev.feaLevelLow = bf_get(lpfc_mbx_rd_rev_ftr_lvl_low,\n\t\t\t\t\t   &mqe->un.read_rev);\n\tphba->vpd.rev.sli1FwRev = mqe->un.read_rev.fw_id_rev;\n\tmemcpy(phba->vpd.rev.sli1FwName, mqe->un.read_rev.fw_name, 16);\n\tphba->vpd.rev.sli2FwRev = mqe->un.read_rev.ulp_fw_id_rev;\n\tmemcpy(phba->vpd.rev.sli2FwName, mqe->un.read_rev.ulp_fw_name, 16);\n\tphba->vpd.rev.opFwRev = mqe->un.read_rev.fw_id_rev;\n\tmemcpy(phba->vpd.rev.opFwName, mqe->un.read_rev.fw_name, 16);\n\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\"(%d):0380 READ_REV Status x%x \"\n\t\t\t\"fw_rev:%s fcphHi:%x fcphLo:%x flHi:%x flLo:%x\\n\",\n\t\t\tmboxq->vport ? mboxq->vport->vpi : 0,\n\t\t\tbf_get(lpfc_mqe_status, mqe),\n\t\t\tphba->vpd.rev.opFwName,\n\t\t\tphba->vpd.rev.fcphHigh, phba->vpd.rev.fcphLow,\n\t\t\tphba->vpd.rev.feaLevelHigh, phba->vpd.rev.feaLevelLow);\n\n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) ==\n\t    LPFC_SLI_INTF_IF_TYPE_0) {\n\t\tlpfc_set_features(phba, mboxq, LPFC_SET_UE_RECOVERY);\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tif (rc == MBX_SUCCESS) {\n\t\t\tphba->hba_flag |= HBA_RECOVERABLE_UE;\n\t\t\t \n\t\t\tphba->eratt_poll_interval = 1;\n\t\t\tphba->sli4_hba.ue_to_sr = bf_get(\n\t\t\t\t\tlpfc_mbx_set_feature_UESR,\n\t\t\t\t\t&mboxq->u.mqe.un.set_feature);\n\t\t\tphba->sli4_hba.ue_to_rp = bf_get(\n\t\t\t\t\tlpfc_mbx_set_feature_UERP,\n\t\t\t\t\t&mboxq->u.mqe.un.set_feature);\n\t\t}\n\t}\n\n\tif (phba->cfg_enable_mds_diags && phba->mds_diags_support) {\n\t\t \n\t\tlpfc_set_features(phba, mboxq, LPFC_SET_MDS_DIAGS);\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tif (rc != MBX_SUCCESS)\n\t\t\tphba->mds_diags_support = 0;\n\t}\n\n\t \n\tlpfc_request_features(phba, mboxq);\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tif (unlikely(rc)) {\n\t\trc = -EIO;\n\t\tgoto out_free_mbox;\n\t}\n\n\t \n\tif (phba->cfg_vmid_app_header && !(bf_get(lpfc_mbx_rq_ftr_rsp_ashdr,\n\t\t\t\t\t\t  &mqe->un.req_ftrs))) {\n\t\tbf_set(lpfc_ftr_ashdr, &phba->sli4_hba.sli4_flags, 0);\n\t\tphba->cfg_vmid_app_header = 0;\n\t\tlpfc_printf_log(phba, KERN_DEBUG, LOG_SLI,\n\t\t\t\t\"1242 vmid feature not supported\\n\");\n\t}\n\n\t \n\tif (!(bf_get(lpfc_mbx_rq_ftr_rsp_fcpi, &mqe->un.req_ftrs))) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\n\t\t\t\t\"0378 No support for fcpi mode.\\n\");\n\t\tftr_rsp++;\n\t}\n\n\t \n\tif (phba->hba_flag & HBA_FCOE_MODE) {\n\t\tif (bf_get(lpfc_mbx_rq_ftr_rsp_perfh, &mqe->un.req_ftrs))\n\t\t\tphba->sli3_options |= LPFC_SLI4_PERFH_ENABLED;\n\t\telse\n\t\t\tphba->sli3_options &= ~LPFC_SLI4_PERFH_ENABLED;\n\t}\n\n\t \n\tif (phba->sli3_options & LPFC_SLI3_BG_ENABLED) {\n\t\tif (!(bf_get(lpfc_mbx_rq_ftr_rsp_dif, &mqe->un.req_ftrs))) {\n\t\t\tphba->cfg_enable_bg = 0;\n\t\t\tphba->sli3_options &= ~LPFC_SLI3_BG_ENABLED;\n\t\t\tftr_rsp++;\n\t\t}\n\t}\n\n\tif (phba->max_vpi && phba->cfg_enable_npiv &&\n\t    !(bf_get(lpfc_mbx_rq_ftr_rsp_npiv, &mqe->un.req_ftrs)))\n\t\tftr_rsp++;\n\n\tif (ftr_rsp) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\n\t\t\t\t\"0379 Feature Mismatch Data: x%08x %08x \"\n\t\t\t\t\"x%x x%x x%x\\n\", mqe->un.req_ftrs.word2,\n\t\t\t\tmqe->un.req_ftrs.word3, phba->cfg_enable_bg,\n\t\t\t\tphba->cfg_enable_npiv, phba->max_vpi);\n\t\tif (!(bf_get(lpfc_mbx_rq_ftr_rsp_dif, &mqe->un.req_ftrs)))\n\t\t\tphba->cfg_enable_bg = 0;\n\t\tif (!(bf_get(lpfc_mbx_rq_ftr_rsp_npiv, &mqe->un.req_ftrs)))\n\t\t\tphba->cfg_enable_npiv = 0;\n\t}\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tphba->sli3_options |= (LPFC_SLI3_NPIV_ENABLED | LPFC_SLI3_HBQ_ENABLED);\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tlpfc_set_features(phba, mboxq, LPFC_SET_DUAL_DUMP);\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tdd = bf_get(lpfc_mbx_set_feature_dd, &mboxq->u.mqe.un.set_feature);\n\tif ((rc == MBX_SUCCESS) && (dd == LPFC_ENABLE_DUAL_DUMP))\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\"6448 Dual Dump is enabled\\n\");\n\telse\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI | LOG_INIT,\n\t\t\t\t\"6447 Dual Dump Mailbox x%x (x%x/x%x) failed, \"\n\t\t\t\t\"rc:x%x dd:x%x\\n\",\n\t\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\t\tlpfc_sli_config_mbox_subsys_get(\n\t\t\t\t\tphba, mboxq),\n\t\t\t\tlpfc_sli_config_mbox_opcode_get(\n\t\t\t\t\tphba, mboxq),\n\t\t\t\trc, dd);\n\t \n\trc = lpfc_sli4_alloc_resource_identifiers(phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2920 Failed to alloc Resource IDs \"\n\t\t\t\t\"rc = x%x\\n\", rc);\n\t\tgoto out_free_mbox;\n\t}\n\n\tlpfc_set_host_data(phba, mboxq);\n\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\n\t\t\t\t\"2134 Failed to set host os driver version %x\",\n\t\t\t\trc);\n\t}\n\n\t \n\trc = lpfc_read_sparam(phba, mboxq, vport->vpi);\n\tif (rc) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\trc = -ENOMEM;\n\t\tgoto out_free_mbox;\n\t}\n\n\tmboxq->vport = vport;\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tmp = (struct lpfc_dmabuf *)mboxq->ctx_buf;\n\tif (rc == MBX_SUCCESS) {\n\t\tmemcpy(&vport->fc_sparam, mp->virt, sizeof(struct serv_parm));\n\t\trc = 0;\n\t}\n\n\t \n\tlpfc_mbuf_free(phba, mp->virt, mp->phys);\n\tkfree(mp);\n\tmboxq->ctx_buf = NULL;\n\tif (unlikely(rc)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0382 READ_SPARAM command failed \"\n\t\t\t\t\"status %d, mbxStatus x%x\\n\",\n\t\t\t\trc, bf_get(lpfc_mqe_status, mqe));\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\trc = -EIO;\n\t\tgoto out_free_mbox;\n\t}\n\n\tlpfc_update_vport_wwn(vport);\n\n\t \n\tfc_host_node_name(shost) = wwn_to_u64(vport->fc_nodename.u.wwn);\n\tfc_host_port_name(shost) = wwn_to_u64(vport->fc_portname.u.wwn);\n\n\t \n\trc = lpfc_sli4_queue_create(phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3089 Failed to allocate queues\\n\");\n\t\trc = -ENODEV;\n\t\tgoto out_free_mbox;\n\t}\n\t \n\trc = lpfc_sli4_queue_setup(phba);\n\tif (unlikely(rc)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0381 Error %d during queue setup.\\n \", rc);\n\t\tgoto out_stop_timers;\n\t}\n\t \n\tlpfc_sli4_setup(phba);\n\tlpfc_sli4_queue_init(phba);\n\n\t \n\trc = lpfc_sli4_els_sgl_update(phba);\n\tif (unlikely(rc)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1400 Failed to update xri-sgl size and \"\n\t\t\t\t\"mapping: %d\\n\", rc);\n\t\tgoto out_destroy_queue;\n\t}\n\n\t \n\trc = lpfc_sli4_repost_sgl_list(phba, &phba->sli4_hba.lpfc_els_sgl_list,\n\t\t\t\t       phba->sli4_hba.els_xri_cnt);\n\tif (unlikely(rc < 0)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0582 Error %d during els sgl post \"\n\t\t\t\t\"operation\\n\", rc);\n\t\trc = -ENODEV;\n\t\tgoto out_destroy_queue;\n\t}\n\tphba->sli4_hba.els_xri_cnt = rc;\n\n\tif (phba->nvmet_support) {\n\t\t \n\t\trc = lpfc_sli4_nvmet_sgl_update(phba);\n\t\tif (unlikely(rc)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6308 Failed to update nvmet-sgl size \"\n\t\t\t\t\t\"and mapping: %d\\n\", rc);\n\t\t\tgoto out_destroy_queue;\n\t\t}\n\n\t\t \n\t\trc = lpfc_sli4_repost_sgl_list(\n\t\t\tphba,\n\t\t\t&phba->sli4_hba.lpfc_nvmet_sgl_list,\n\t\t\tphba->sli4_hba.nvmet_xri_cnt);\n\t\tif (unlikely(rc < 0)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3117 Error %d during nvmet \"\n\t\t\t\t\t\"sgl post\\n\", rc);\n\t\t\trc = -ENODEV;\n\t\t\tgoto out_destroy_queue;\n\t\t}\n\t\tphba->sli4_hba.nvmet_xri_cnt = rc;\n\n\t\t \n\t\tcnt = phba->sli4_hba.nvmet_xri_cnt +\n\t\t\tphba->sli4_hba.max_cfg_param.max_xri;\n\t} else {\n\t\t \n\t\trc = lpfc_sli4_io_sgl_update(phba);\n\t\tif (unlikely(rc)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6082 Failed to update nvme-sgl size \"\n\t\t\t\t\t\"and mapping: %d\\n\", rc);\n\t\t\tgoto out_destroy_queue;\n\t\t}\n\n\t\t \n\t\trc = lpfc_sli4_repost_io_sgl_list(phba);\n\t\tif (unlikely(rc)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6116 Error %d during nvme sgl post \"\n\t\t\t\t\t\"operation\\n\", rc);\n\t\t\t \n\t\t\t \n\t\t\trc = -ENODEV;\n\t\t\tgoto out_destroy_queue;\n\t\t}\n\t\t \n\t\tcnt = phba->sli4_hba.max_cfg_param.max_xri;\n\t}\n\n\tif (!phba->sli.iocbq_lookup) {\n\t\t \n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"2821 initialize iocb list with %d entries\\n\",\n\t\t\t\tcnt);\n\t\trc = lpfc_init_iocb_list(phba, cnt);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"1413 Failed to init iocb list.\\n\");\n\t\t\tgoto out_destroy_queue;\n\t\t}\n\t}\n\n\tif (phba->nvmet_support)\n\t\tlpfc_nvmet_create_targetport(phba);\n\n\tif (phba->nvmet_support && phba->cfg_nvmet_mrq) {\n\t\t \n\t\tfor (i = 0; i < phba->cfg_nvmet_mrq; i++) {\n\t\t\trqbp = phba->sli4_hba.nvmet_mrq_hdr[i]->rqbp;\n\t\t\tINIT_LIST_HEAD(&rqbp->rqb_buffer_list);\n\t\t\trqbp->rqb_alloc_buffer = lpfc_sli4_nvmet_alloc;\n\t\t\trqbp->rqb_free_buffer = lpfc_sli4_nvmet_free;\n\t\t\trqbp->entry_count = LPFC_NVMET_RQE_DEF_COUNT;\n\t\t\trqbp->buffer_count = 0;\n\n\t\t\tlpfc_post_rq_buffer(\n\t\t\t\tphba, phba->sli4_hba.nvmet_mrq_hdr[i],\n\t\t\t\tphba->sli4_hba.nvmet_mrq_data[i],\n\t\t\t\tphba->cfg_nvmet_mrq_post, i);\n\t\t}\n\t}\n\n\t \n\trc = lpfc_sli4_post_all_rpi_hdrs(phba);\n\tif (unlikely(rc)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0393 Error %d during rpi post operation\\n\",\n\t\t\t\trc);\n\t\trc = -ENODEV;\n\t\tgoto out_free_iocblist;\n\t}\n\tlpfc_sli4_node_prep(phba);\n\n\tif (!(phba->hba_flag & HBA_FCOE_MODE)) {\n\t\tif ((phba->nvmet_support == 0) || (phba->cfg_nvmet_mrq == 1)) {\n\t\t\t \n\t\t\tlpfc_reg_fcfi(phba, mboxq);\n\t\t\tmboxq->vport = phba->pport;\n\t\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\t\tif (rc != MBX_SUCCESS)\n\t\t\t\tgoto out_unset_queue;\n\t\t\trc = 0;\n\t\t\tphba->fcf.fcfi = bf_get(lpfc_reg_fcfi_fcfi,\n\t\t\t\t\t\t&mboxq->u.mqe.un.reg_fcfi);\n\t\t} else {\n\t\t\t \n\n\t\t\t \n\t\t\tlpfc_reg_fcfi_mrq(phba, mboxq, 0);\n\t\t\tmboxq->vport = phba->pport;\n\t\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\t\tif (rc != MBX_SUCCESS)\n\t\t\t\tgoto out_unset_queue;\n\t\t\trc = 0;\n\t\t\tphba->fcf.fcfi = bf_get(lpfc_reg_fcfi_mrq_fcfi,\n\t\t\t\t\t\t&mboxq->u.mqe.un.reg_fcfi_mrq);\n\n\t\t\t \n\t\t\tlpfc_reg_fcfi_mrq(phba, mboxq, 1);\n\t\t\tmboxq->vport = phba->pport;\n\t\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\t\tif (rc != MBX_SUCCESS)\n\t\t\t\tgoto out_unset_queue;\n\t\t\trc = 0;\n\t\t}\n\t\t \n\t\tlpfc_sli_read_link_ste(phba);\n\t}\n\n\t \n\tif (phba->nvmet_support == 0) {\n\t\tif (phba->sli4_hba.io_xri_cnt == 0) {\n\t\t\tlen = lpfc_new_io_buf(\n\t\t\t\t\t      phba, phba->sli4_hba.io_xri_max);\n\t\t\tif (len == 0) {\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out_unset_queue;\n\t\t\t}\n\n\t\t\tif (phba->cfg_xri_rebalancing)\n\t\t\t\tlpfc_create_multixri_pools(phba);\n\t\t}\n\t} else {\n\t\tphba->cfg_xri_rebalancing = 0;\n\t}\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tphba->sli.sli_flag &= ~LPFC_SLI_ASYNC_MBX_BLK;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tlpfc_sli4_rb_setup(phba);\n\n\t \n\tphba->fcf.fcf_flag = 0;\n\tphba->fcf.current_rec.flag = 0;\n\n\t \n\tmod_timer(&vport->els_tmofunc,\n\t\t  jiffies + msecs_to_jiffies(1000 * (phba->fc_ratov * 2)));\n\n\t \n\tmod_timer(&phba->hb_tmofunc,\n\t\t  jiffies + msecs_to_jiffies(1000 * LPFC_HB_MBOX_INTERVAL));\n\tphba->hba_flag &= ~(HBA_HBEAT_INP | HBA_HBEAT_TMO);\n\tphba->last_completion_time = jiffies;\n\n\t \n\tif (phba->cfg_auto_imax)\n\t\tqueue_delayed_work(phba->wq, &phba->eq_delay_work,\n\t\t\t\t   msecs_to_jiffies(LPFC_EQ_DELAY_MSECS));\n\n\t \n\tlpfc_init_idle_stat_hb(phba);\n\n\t \n\tmod_timer(&phba->eratt_poll,\n\t\t  jiffies + msecs_to_jiffies(1000 * phba->eratt_poll_interval));\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tphba->link_state = LPFC_LINK_DOWN;\n\n\t \n\tif (bf_get(lpfc_conf_trunk_port0, &phba->sli4_hba))\n\t\tphba->trunk_link.link0.state = LPFC_LINK_DOWN;\n\tif (bf_get(lpfc_conf_trunk_port1, &phba->sli4_hba))\n\t\tphba->trunk_link.link1.state = LPFC_LINK_DOWN;\n\tif (bf_get(lpfc_conf_trunk_port2, &phba->sli4_hba))\n\t\tphba->trunk_link.link2.state = LPFC_LINK_DOWN;\n\tif (bf_get(lpfc_conf_trunk_port3, &phba->sli4_hba))\n\t\tphba->trunk_link.link3.state = LPFC_LINK_DOWN;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tlpfc_sli4_arm_cqeq_intr(phba);\n\n\t \n\tphba->sli4_hba.intr_enable = 1;\n\n\t \n\tlpfc_cmf_setup(phba);\n\n\tif (!(phba->hba_flag & HBA_FCOE_MODE) &&\n\t    (phba->hba_flag & LINK_DISABLED)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3103 Adapter Link is disabled.\\n\");\n\t\tlpfc_down_link(phba, mboxq);\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3104 Adapter failed to issue \"\n\t\t\t\t\t\"DOWN_LINK mbox cmd, rc:x%x\\n\", rc);\n\t\t\tgoto out_io_buff_free;\n\t\t}\n\t} else if (phba->cfg_suppress_link_up == LPFC_INITIALIZE_LINK) {\n\t\t \n\t\tif (!(phba->link_flag & LS_LOOPBACK_MODE)) {\n\t\t\trc = phba->lpfc_hba_init_link(phba, MBX_NOWAIT);\n\t\t\tif (rc)\n\t\t\t\tgoto out_io_buff_free;\n\t\t}\n\t}\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\n\t \n\tlpfc_sli4_ras_setup(phba);\n\n\tphba->hba_flag |= HBA_SETUP;\n\treturn rc;\n\nout_io_buff_free:\n\t \n\tlpfc_io_free(phba);\nout_unset_queue:\n\t \n\tlpfc_sli4_queue_unset(phba);\nout_free_iocblist:\n\tlpfc_free_iocb_list(phba);\nout_destroy_queue:\n\tlpfc_sli4_queue_destroy(phba);\nout_stop_timers:\n\tlpfc_stop_hba_timers(phba);\nout_free_mbox:\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\treturn rc;\n}\n\n \nvoid\nlpfc_mbox_timeout(struct timer_list *t)\n{\n\tstruct lpfc_hba  *phba = from_timer(phba, t, sli.mbox_tmo);\n\tunsigned long iflag;\n\tuint32_t tmo_posted;\n\n\tspin_lock_irqsave(&phba->pport->work_port_lock, iflag);\n\ttmo_posted = phba->pport->work_port_events & WORKER_MBOX_TMO;\n\tif (!tmo_posted)\n\t\tphba->pport->work_port_events |= WORKER_MBOX_TMO;\n\tspin_unlock_irqrestore(&phba->pport->work_port_lock, iflag);\n\n\tif (!tmo_posted)\n\t\tlpfc_worker_wake_up(phba);\n\treturn;\n}\n\n \nstatic bool\nlpfc_sli4_mbox_completions_pending(struct lpfc_hba *phba)\n{\n\n\tuint32_t idx;\n\tstruct lpfc_queue *mcq;\n\tstruct lpfc_mcqe *mcqe;\n\tbool pending_completions = false;\n\tuint8_t\tqe_valid;\n\n\tif (unlikely(!phba) || (phba->sli_rev != LPFC_SLI_REV4))\n\t\treturn false;\n\n\t \n\n\tmcq = phba->sli4_hba.mbx_cq;\n\tidx = mcq->hba_index;\n\tqe_valid = mcq->qe_valid;\n\twhile (bf_get_le32(lpfc_cqe_valid,\n\t       (struct lpfc_cqe *)lpfc_sli4_qe(mcq, idx)) == qe_valid) {\n\t\tmcqe = (struct lpfc_mcqe *)(lpfc_sli4_qe(mcq, idx));\n\t\tif (bf_get_le32(lpfc_trailer_completed, mcqe) &&\n\t\t    (!bf_get_le32(lpfc_trailer_async, mcqe))) {\n\t\t\tpending_completions = true;\n\t\t\tbreak;\n\t\t}\n\t\tidx = (idx + 1) % mcq->entry_count;\n\t\tif (mcq->hba_index == idx)\n\t\t\tbreak;\n\n\t\t \n\t\tif (phba->sli4_hba.pc_sli4_params.cqav && !idx)\n\t\t\tqe_valid = (qe_valid) ? 0 : 1;\n\t}\n\treturn pending_completions;\n\n}\n\n \nstatic bool\nlpfc_sli4_process_missed_mbox_completions(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hba *sli4_hba = &phba->sli4_hba;\n\tuint32_t eqidx;\n\tstruct lpfc_queue *fpeq = NULL;\n\tstruct lpfc_queue *eq;\n\tbool mbox_pending;\n\n\tif (unlikely(!phba) || (phba->sli_rev != LPFC_SLI_REV4))\n\t\treturn false;\n\n\t \n\tif (sli4_hba->hdwq) {\n\t\tfor (eqidx = 0; eqidx < phba->cfg_irq_chann; eqidx++) {\n\t\t\teq = phba->sli4_hba.hba_eq_hdl[eqidx].eq;\n\t\t\tif (eq && eq->queue_id == sli4_hba->mbx_cq->assoc_qid) {\n\t\t\t\tfpeq = eq;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tif (!fpeq)\n\t\treturn false;\n\n\t \n\n\tsli4_hba->sli4_eq_clr_intr(fpeq);\n\n\t \n\n\tmbox_pending = lpfc_sli4_mbox_completions_pending(phba);\n\n\t \n\n\tif (mbox_pending)\n\t\t \n\t\tlpfc_sli4_process_eq(phba, fpeq, LPFC_QUEUE_REARM,\n\t\t\t\t     LPFC_QUEUE_WORK);\n\telse\n\t\t \n\t\tsli4_hba->sli4_write_eq_db(phba, fpeq, 0, LPFC_QUEUE_REARM);\n\n\treturn mbox_pending;\n\n}\n\n \nvoid\nlpfc_mbox_timeout_handler(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *pmbox = phba->sli.mbox_active;\n\tMAILBOX_t *mb = NULL;\n\n\tstruct lpfc_sli *psli = &phba->sli;\n\n\t \n\tlpfc_sli4_process_missed_mbox_completions(phba);\n\n\tif (!(psli->sli_flag & LPFC_SLI_ACTIVE))\n\t\treturn;\n\n\tif (pmbox != NULL)\n\t\tmb = &pmbox->u.mb;\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tif (pmbox == NULL) {\n\t\tlpfc_printf_log(phba, KERN_WARNING,\n\t\t\t\tLOG_MBOX | LOG_SLI,\n\t\t\t\t\"0353 Active Mailbox cleared - mailbox timeout \"\n\t\t\t\t\"exiting\\n\");\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\n\t \n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0310 Mailbox command x%x timeout Data: x%x x%x x%px\\n\",\n\t\t\tmb->mbxCommand,\n\t\t\tphba->pport->port_state,\n\t\t\tphba->sli.sli_flag,\n\t\t\tphba->sli.mbox_active);\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tset_bit(MBX_TMO_ERR, &phba->bit_flags);\n\tspin_lock_irq(&phba->pport->work_port_lock);\n\tphba->pport->work_port_events &= ~WORKER_MBOX_TMO;\n\tspin_unlock_irq(&phba->pport->work_port_lock);\n\tspin_lock_irq(&phba->hbalock);\n\tphba->link_state = LPFC_LINK_UNKNOWN;\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0345 Resetting board due to mailbox timeout\\n\");\n\n\t \n\tlpfc_reset_hba(phba);\n}\n\n \nstatic int\nlpfc_sli_issue_mbox_s3(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmbox,\n\t\t       uint32_t flag)\n{\n\tMAILBOX_t *mbx;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tuint32_t status, evtctr;\n\tuint32_t ha_copy, hc_copy;\n\tint i;\n\tunsigned long timeout;\n\tunsigned long drvr_flag = 0;\n\tuint32_t word0, ldata;\n\tvoid __iomem *to_slim;\n\tint processing_queue = 0;\n\n\tspin_lock_irqsave(&phba->hbalock, drvr_flag);\n\tif (!pmbox) {\n\t\tphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\t \n\t\tif (unlikely(psli->sli_flag & LPFC_SLI_ASYNC_MBX_BLK)) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\t\t\treturn MBX_SUCCESS;\n\t\t}\n\t\tprocessing_queue = 1;\n\t\tpmbox = lpfc_mbox_get(phba);\n\t\tif (!pmbox) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\t\t\treturn MBX_SUCCESS;\n\t\t}\n\t}\n\n\tif (pmbox->mbox_cmpl && pmbox->mbox_cmpl != lpfc_sli_def_mbox_cmpl &&\n\t\tpmbox->mbox_cmpl != lpfc_sli_wake_mbox_wait) {\n\t\tif(!pmbox->vport) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_MBOX | LOG_VPORT,\n\t\t\t\t\t\"1806 Mbox x%x failed. No vport\\n\",\n\t\t\t\t\tpmbox->u.mb.mbxCommand);\n\t\t\tdump_stack();\n\t\t\tgoto out_not_finished;\n\t\t}\n\t}\n\n\t \n\tif (unlikely(pci_channel_offline(phba->pcidev))) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\t\tgoto out_not_finished;\n\t}\n\n\t \n\tif (unlikely(phba->hba_flag & DEFER_ERATT)) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\t\tgoto out_not_finished;\n\t}\n\n\tpsli = &phba->sli;\n\n\tmbx = &pmbox->u.mb;\n\tstatus = MBX_SUCCESS;\n\n\tif (phba->link_state == LPFC_HBA_ERROR) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\n\t\t \n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"(%d):0311 Mailbox command x%x cannot \"\n\t\t\t\t\"issue Data: x%x x%x\\n\",\n\t\t\t\tpmbox->vport ? pmbox->vport->vpi : 0,\n\t\t\t\tpmbox->u.mb.mbxCommand, psli->sli_flag, flag);\n\t\tgoto out_not_finished;\n\t}\n\n\tif (mbx->mbxCommand != MBX_KILL_BOARD && flag & MBX_NOWAIT) {\n\t\tif (lpfc_readl(phba->HCregaddr, &hc_copy) ||\n\t\t\t!(hc_copy & HC_MBINT_ENA)) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"(%d):2528 Mailbox command x%x cannot \"\n\t\t\t\t\"issue Data: x%x x%x\\n\",\n\t\t\t\tpmbox->vport ? pmbox->vport->vpi : 0,\n\t\t\t\tpmbox->u.mb.mbxCommand, psli->sli_flag, flag);\n\t\t\tgoto out_not_finished;\n\t\t}\n\t}\n\n\tif (psli->sli_flag & LPFC_SLI_MBOX_ACTIVE) {\n\t\t \n\n\t\tif (flag & MBX_POLL) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"(%d):2529 Mailbox command x%x \"\n\t\t\t\t\t\"cannot issue Data: x%x x%x\\n\",\n\t\t\t\t\tpmbox->vport ? pmbox->vport->vpi : 0,\n\t\t\t\t\tpmbox->u.mb.mbxCommand,\n\t\t\t\t\tpsli->sli_flag, flag);\n\t\t\tgoto out_not_finished;\n\t\t}\n\n\t\tif (!(psli->sli_flag & LPFC_SLI_ACTIVE)) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"(%d):2530 Mailbox command x%x \"\n\t\t\t\t\t\"cannot issue Data: x%x x%x\\n\",\n\t\t\t\t\tpmbox->vport ? pmbox->vport->vpi : 0,\n\t\t\t\t\tpmbox->u.mb.mbxCommand,\n\t\t\t\t\tpsli->sli_flag, flag);\n\t\t\tgoto out_not_finished;\n\t\t}\n\n\t\t \n\t\tlpfc_mbox_put(phba, pmbox);\n\n\t\t \n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\t\"(%d):0308 Mbox cmd issue - BUSY Data: \"\n\t\t\t\t\"x%x x%x x%x x%x\\n\",\n\t\t\t\tpmbox->vport ? pmbox->vport->vpi : 0xffffff,\n\t\t\t\tmbx->mbxCommand,\n\t\t\t\tphba->pport ? phba->pport->port_state : 0xff,\n\t\t\t\tpsli->sli_flag, flag);\n\n\t\tpsli->slistat.mbox_busy++;\n\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\n\t\tif (pmbox->vport) {\n\t\t\tlpfc_debugfs_disc_trc(pmbox->vport,\n\t\t\t\tLPFC_DISC_TRC_MBOX_VPORT,\n\t\t\t\t\"MBOX Bsy vport:  cmd:x%x mb:x%x x%x\",\n\t\t\t\t(uint32_t)mbx->mbxCommand,\n\t\t\t\tmbx->un.varWords[0], mbx->un.varWords[1]);\n\t\t}\n\t\telse {\n\t\t\tlpfc_debugfs_disc_trc(phba->pport,\n\t\t\t\tLPFC_DISC_TRC_MBOX,\n\t\t\t\t\"MBOX Bsy:        cmd:x%x mb:x%x x%x\",\n\t\t\t\t(uint32_t)mbx->mbxCommand,\n\t\t\t\tmbx->un.varWords[0], mbx->un.varWords[1]);\n\t\t}\n\n\t\treturn MBX_BUSY;\n\t}\n\n\tpsli->sli_flag |= LPFC_SLI_MBOX_ACTIVE;\n\n\t \n\tif (flag != MBX_POLL) {\n\t\tif (!(psli->sli_flag & LPFC_SLI_ACTIVE) &&\n\t\t    (mbx->mbxCommand != MBX_KILL_BOARD)) {\n\t\t\tpsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"(%d):2531 Mailbox command x%x \"\n\t\t\t\t\t\"cannot issue Data: x%x x%x\\n\",\n\t\t\t\t\tpmbox->vport ? pmbox->vport->vpi : 0,\n\t\t\t\t\tpmbox->u.mb.mbxCommand,\n\t\t\t\t\tpsli->sli_flag, flag);\n\t\t\tgoto out_not_finished;\n\t\t}\n\t\t \n\t\ttimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba, pmbox) *\n\t\t\t\t\t   1000);\n\t\tmod_timer(&psli->mbox_tmo, jiffies + timeout);\n\t}\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\"(%d):0309 Mailbox cmd x%x issue Data: x%x x%x \"\n\t\t\t\"x%x\\n\",\n\t\t\tpmbox->vport ? pmbox->vport->vpi : 0,\n\t\t\tmbx->mbxCommand,\n\t\t\tphba->pport ? phba->pport->port_state : 0xff,\n\t\t\tpsli->sli_flag, flag);\n\n\tif (mbx->mbxCommand != MBX_HEARTBEAT) {\n\t\tif (pmbox->vport) {\n\t\t\tlpfc_debugfs_disc_trc(pmbox->vport,\n\t\t\t\tLPFC_DISC_TRC_MBOX_VPORT,\n\t\t\t\t\"MBOX Send vport: cmd:x%x mb:x%x x%x\",\n\t\t\t\t(uint32_t)mbx->mbxCommand,\n\t\t\t\tmbx->un.varWords[0], mbx->un.varWords[1]);\n\t\t}\n\t\telse {\n\t\t\tlpfc_debugfs_disc_trc(phba->pport,\n\t\t\t\tLPFC_DISC_TRC_MBOX,\n\t\t\t\t\"MBOX Send:       cmd:x%x mb:x%x x%x\",\n\t\t\t\t(uint32_t)mbx->mbxCommand,\n\t\t\t\tmbx->un.varWords[0], mbx->un.varWords[1]);\n\t\t}\n\t}\n\n\tpsli->slistat.mbox_cmd++;\n\tevtctr = psli->slistat.mbox_event;\n\n\t \n\tmbx->mbxOwner = OWN_CHIP;\n\n\tif (psli->sli_flag & LPFC_SLI_ACTIVE) {\n\t\t \n\t\tif (pmbox->in_ext_byte_len || pmbox->out_ext_byte_len) {\n\t\t\t*(((uint32_t *)mbx) + pmbox->mbox_offset_word)\n\t\t\t\t= (uint8_t *)phba->mbox_ext\n\t\t\t\t  - (uint8_t *)phba->mbox;\n\t\t}\n\n\t\t \n\t\tif (pmbox->in_ext_byte_len && pmbox->ctx_buf) {\n\t\t\tlpfc_sli_pcimem_bcopy(pmbox->ctx_buf,\n\t\t\t\t\t      (uint8_t *)phba->mbox_ext,\n\t\t\t\t\t      pmbox->in_ext_byte_len);\n\t\t}\n\t\t \n\t\tlpfc_sli_pcimem_bcopy(mbx, phba->mbox, MAILBOX_CMD_SIZE);\n\t} else {\n\t\t \n\t\tif (pmbox->in_ext_byte_len || pmbox->out_ext_byte_len)\n\t\t\t*(((uint32_t *)mbx) + pmbox->mbox_offset_word)\n\t\t\t\t= MAILBOX_HBA_EXT_OFFSET;\n\n\t\t \n\t\tif (pmbox->in_ext_byte_len && pmbox->ctx_buf)\n\t\t\tlpfc_memcpy_to_slim(phba->MBslimaddr +\n\t\t\t\tMAILBOX_HBA_EXT_OFFSET,\n\t\t\t\tpmbox->ctx_buf, pmbox->in_ext_byte_len);\n\n\t\tif (mbx->mbxCommand == MBX_CONFIG_PORT)\n\t\t\t \n\t\t\tlpfc_sli_pcimem_bcopy(mbx, phba->mbox,\n\t\t\t\t\t      MAILBOX_CMD_SIZE);\n\n\t\t \n\t\tto_slim = phba->MBslimaddr + sizeof (uint32_t);\n\t\tlpfc_memcpy_to_slim(to_slim, &mbx->un.varWords[0],\n\t\t\t    MAILBOX_CMD_SIZE - sizeof (uint32_t));\n\n\t\t \n\t\tldata = *((uint32_t *)mbx);\n\t\tto_slim = phba->MBslimaddr;\n\t\twritel(ldata, to_slim);\n\t\treadl(to_slim);  \n\n\t\tif (mbx->mbxCommand == MBX_CONFIG_PORT)\n\t\t\t \n\t\t\tpsli->sli_flag |= LPFC_SLI_ACTIVE;\n\t}\n\n\twmb();\n\n\tswitch (flag) {\n\tcase MBX_NOWAIT:\n\t\t \n\t\tpsli->mbox_active = pmbox;\n\t\t \n\t\twritel(CA_MBATT, phba->CAregaddr);\n\t\treadl(phba->CAregaddr);  \n\t\t \n\t\tbreak;\n\n\tcase MBX_POLL:\n\t\t \n\t\tpsli->mbox_active = NULL;\n\t\t \n\t\twritel(CA_MBATT, phba->CAregaddr);\n\t\treadl(phba->CAregaddr);  \n\n\t\tif (psli->sli_flag & LPFC_SLI_ACTIVE) {\n\t\t\t \n\t\t\tword0 = *((uint32_t *)phba->mbox);\n\t\t\tword0 = le32_to_cpu(word0);\n\t\t} else {\n\t\t\t \n\t\t\tif (lpfc_readl(phba->MBslimaddr, &word0)) {\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock,\n\t\t\t\t\t\t       drvr_flag);\n\t\t\t\tgoto out_not_finished;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (lpfc_readl(phba->HAregaddr, &ha_copy)) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock,\n\t\t\t\t\t\t       drvr_flag);\n\t\t\tgoto out_not_finished;\n\t\t}\n\t\ttimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba, pmbox) *\n\t\t\t\t\t\t\t1000) + jiffies;\n\t\ti = 0;\n\t\t \n\t\twhile (((word0 & OWN_CHIP) == OWN_CHIP) ||\n\t\t       (!(ha_copy & HA_MBATT) &&\n\t\t\t(phba->link_state > LPFC_WARM_START))) {\n\t\t\tif (time_after(jiffies, timeout)) {\n\t\t\t\tpsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock,\n\t\t\t\t\t\t       drvr_flag);\n\t\t\t\tgoto out_not_finished;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (((word0 & OWN_CHIP) != OWN_CHIP)\n\t\t\t    && (evtctr != psli->slistat.mbox_event))\n\t\t\t\tbreak;\n\n\t\t\tif (i++ > 10) {\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock,\n\t\t\t\t\t\t       drvr_flag);\n\t\t\t\tmsleep(1);\n\t\t\t\tspin_lock_irqsave(&phba->hbalock, drvr_flag);\n\t\t\t}\n\n\t\t\tif (psli->sli_flag & LPFC_SLI_ACTIVE) {\n\t\t\t\t \n\t\t\t\tword0 = *((uint32_t *)phba->mbox);\n\t\t\t\tword0 = le32_to_cpu(word0);\n\t\t\t\tif (mbx->mbxCommand == MBX_CONFIG_PORT) {\n\t\t\t\t\tMAILBOX_t *slimmb;\n\t\t\t\t\tuint32_t slimword0;\n\t\t\t\t\t \n\t\t\t\t\tslimword0 = readl(phba->MBslimaddr);\n\t\t\t\t\tslimmb = (MAILBOX_t *) & slimword0;\n\t\t\t\t\tif (((slimword0 & OWN_CHIP) != OWN_CHIP)\n\t\t\t\t\t    && slimmb->mbxStatus) {\n\t\t\t\t\t\tpsli->sli_flag &=\n\t\t\t\t\t\t    ~LPFC_SLI_ACTIVE;\n\t\t\t\t\t\tword0 = slimword0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tword0 = readl(phba->MBslimaddr);\n\t\t\t}\n\t\t\t \n\t\t\tif (lpfc_readl(phba->HAregaddr, &ha_copy)) {\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock,\n\t\t\t\t\t\t       drvr_flag);\n\t\t\t\tgoto out_not_finished;\n\t\t\t}\n\t\t}\n\n\t\tif (psli->sli_flag & LPFC_SLI_ACTIVE) {\n\t\t\t \n\t\t\tlpfc_sli_pcimem_bcopy(phba->mbox, mbx,\n\t\t\t\t\t\tMAILBOX_CMD_SIZE);\n\t\t\t \n\t\t\tif (pmbox->out_ext_byte_len && pmbox->ctx_buf) {\n\t\t\t\tlpfc_sli_pcimem_bcopy(phba->mbox_ext,\n\t\t\t\t\t\t      pmbox->ctx_buf,\n\t\t\t\t\t\t      pmbox->out_ext_byte_len);\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tlpfc_memcpy_from_slim(mbx, phba->MBslimaddr,\n\t\t\t\t\t\tMAILBOX_CMD_SIZE);\n\t\t\t \n\t\t\tif (pmbox->out_ext_byte_len && pmbox->ctx_buf) {\n\t\t\t\tlpfc_memcpy_from_slim(\n\t\t\t\t\tpmbox->ctx_buf,\n\t\t\t\t\tphba->MBslimaddr +\n\t\t\t\t\tMAILBOX_HBA_EXT_OFFSET,\n\t\t\t\t\tpmbox->out_ext_byte_len);\n\t\t\t}\n\t\t}\n\n\t\twritel(HA_MBATT, phba->HAregaddr);\n\t\treadl(phba->HAregaddr);  \n\n\t\tpsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\tstatus = mbx->mbxStatus;\n\t}\n\n\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\treturn status;\n\nout_not_finished:\n\tif (processing_queue) {\n\t\tpmbox->u.mb.mbxStatus = MBX_NOT_FINISHED;\n\t\tlpfc_mbox_cmpl_put(phba, pmbox);\n\t}\n\treturn MBX_NOT_FINISHED;\n}\n\n \nstatic int\nlpfc_sli4_async_mbox_block(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tLPFC_MBOXQ_t *mboxq;\n\tint rc = 0;\n\tunsigned long timeout = 0;\n\tu32 sli_flag;\n\tu8 cmd, subsys, opcode;\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag |= LPFC_SLI_ASYNC_MBX_BLK;\n\t \n\tif (phba->sli.mbox_active)\n\t\ttimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba,\n\t\t\t\t\t\tphba->sli.mbox_active) *\n\t\t\t\t\t\t1000) + jiffies;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tif (timeout)\n\t\tlpfc_sli4_process_missed_mbox_completions(phba);\n\n\t \n\twhile (phba->sli.mbox_active) {\n\t\t \n\t\tmsleep(2);\n\t\tif (time_after(jiffies, timeout)) {\n\t\t\t \n\n\t\t\t \n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tif (phba->sli.mbox_active) {\n\t\t\t\tmboxq = phba->sli.mbox_active;\n\t\t\t\tcmd = mboxq->u.mb.mbxCommand;\n\t\t\t\tsubsys = lpfc_sli_config_mbox_subsys_get(phba,\n\t\t\t\t\t\t\t\t\t mboxq);\n\t\t\t\topcode = lpfc_sli_config_mbox_opcode_get(phba,\n\t\t\t\t\t\t\t\t\t mboxq);\n\t\t\t\tsli_flag = psli->sli_flag;\n\t\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"2352 Mailbox command x%x \"\n\t\t\t\t\t\t\"(x%x/x%x) sli_flag x%x could \"\n\t\t\t\t\t\t\"not complete\\n\",\n\t\t\t\t\t\tcmd, subsys, opcode,\n\t\t\t\t\t\tsli_flag);\n\t\t\t} else {\n\t\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t}\n\n\t\t\trc = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (rc) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tpsli->sli_flag &= ~LPFC_SLI_ASYNC_MBX_BLK;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\treturn rc;\n}\n\n \nstatic void\nlpfc_sli4_async_mbox_unblock(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\n\tspin_lock_irq(&phba->hbalock);\n\tif (!(psli->sli_flag & LPFC_SLI_ASYNC_MBX_BLK)) {\n\t\t \n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\n\t \n\tpsli->sli_flag &= ~LPFC_SLI_ASYNC_MBX_BLK;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\tlpfc_worker_wake_up(phba);\n}\n\n \nstatic int\nlpfc_sli4_wait_bmbx_ready(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\n{\n\tuint32_t db_ready;\n\tunsigned long timeout;\n\tstruct lpfc_register bmbx_reg;\n\tstruct lpfc_register portstat_reg = {-1};\n\n\t \n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) >=\n\t    LPFC_SLI_INTF_IF_TYPE_2) {\n\t\tif (lpfc_readl(phba->sli4_hba.u.if_type2.STATUSregaddr,\n\t\t\t       &portstat_reg.word0) ||\n\t\t    lpfc_sli4_unrecoverable_port(&portstat_reg)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\t\"3858 Skipping bmbx ready because \"\n\t\t\t\t\t\"Port Status x%x\\n\",\n\t\t\t\t\tportstat_reg.word0);\n\t\t\treturn MBXERR_ERROR;\n\t\t}\n\t}\n\n\ttimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba, mboxq)\n\t\t\t\t   * 1000) + jiffies;\n\n\tdo {\n\t\tbmbx_reg.word0 = readl(phba->sli4_hba.BMBXregaddr);\n\t\tdb_ready = bf_get(lpfc_bmbx_rdy, &bmbx_reg);\n\t\tif (!db_ready)\n\t\t\tmdelay(2);\n\n\t\tif (time_after(jiffies, timeout))\n\t\t\treturn MBXERR_ERROR;\n\t} while (!db_ready);\n\n\treturn 0;\n}\n\n \nstatic int\nlpfc_sli4_post_sync_mbox(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\n{\n\tint rc = MBX_SUCCESS;\n\tunsigned long iflag;\n\tuint32_t mcqe_status;\n\tuint32_t mbx_cmnd;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_mqe *mb = &mboxq->u.mqe;\n\tstruct lpfc_bmbx_create *mbox_rgn;\n\tstruct dma_address *dma_address;\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tif (psli->sli_flag & LPFC_SLI_MBOX_ACTIVE) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"(%d):2532 Mailbox command x%x (x%x/x%x) \"\n\t\t\t\t\"cannot issue Data: x%x x%x\\n\",\n\t\t\t\tmboxq->vport ? mboxq->vport->vpi : 0,\n\t\t\t\tmboxq->u.mb.mbxCommand,\n\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\t\tpsli->sli_flag, MBX_POLL);\n\t\treturn MBXERR_ERROR;\n\t}\n\t \n\tpsli->sli_flag |= LPFC_SLI_MBOX_ACTIVE;\n\tphba->sli.mbox_active = mboxq;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\n\t \n\trc = lpfc_sli4_wait_bmbx_ready(phba, mboxq);\n\tif (rc)\n\t\tgoto exit;\n\t \n\tmbx_cmnd = bf_get(lpfc_mqe_command, mb);\n\tmemset(phba->sli4_hba.bmbx.avirt, 0, sizeof(struct lpfc_bmbx_create));\n\tlpfc_sli4_pcimem_bcopy(mb, phba->sli4_hba.bmbx.avirt,\n\t\t\t       sizeof(struct lpfc_mqe));\n\n\t \n\tdma_address = &phba->sli4_hba.bmbx.dma_address;\n\twritel(dma_address->addr_hi, phba->sli4_hba.BMBXregaddr);\n\n\t \n\trc = lpfc_sli4_wait_bmbx_ready(phba, mboxq);\n\tif (rc)\n\t\tgoto exit;\n\n\t \n\twritel(dma_address->addr_lo, phba->sli4_hba.BMBXregaddr);\n\n\t \n\trc = lpfc_sli4_wait_bmbx_ready(phba, mboxq);\n\tif (rc)\n\t\tgoto exit;\n\n\t \n\tlpfc_sli4_pcimem_bcopy(phba->sli4_hba.bmbx.avirt, mb,\n\t\t\t       sizeof(struct lpfc_mqe));\n\tmbox_rgn = (struct lpfc_bmbx_create *) phba->sli4_hba.bmbx.avirt;\n\tlpfc_sli4_pcimem_bcopy(&mbox_rgn->mcqe, &mboxq->mcqe,\n\t\t\t       sizeof(struct lpfc_mcqe));\n\tmcqe_status = bf_get(lpfc_mcqe_status, &mbox_rgn->mcqe);\n\t \n\tif (mcqe_status != MB_CQE_STATUS_SUCCESS) {\n\t\tif (bf_get(lpfc_mqe_status, mb) == MBX_SUCCESS)\n\t\t\tbf_set(lpfc_mqe_status, mb,\n\t\t\t       (LPFC_MBX_ERROR_RANGE | mcqe_status));\n\t\trc = MBXERR_ERROR;\n\t} else\n\t\tlpfc_sli4_swap_str(phba, mboxq);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\"(%d):0356 Mailbox cmd x%x (x%x/x%x) Status x%x \"\n\t\t\t\"Data: x%x x%x x%x x%x x%x x%x x%x x%x x%x x%x x%x\"\n\t\t\t\" x%x x%x CQ: x%x x%x x%x x%x\\n\",\n\t\t\tmboxq->vport ? mboxq->vport->vpi : 0, mbx_cmnd,\n\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\tbf_get(lpfc_mqe_status, mb),\n\t\t\tmb->un.mb_words[0], mb->un.mb_words[1],\n\t\t\tmb->un.mb_words[2], mb->un.mb_words[3],\n\t\t\tmb->un.mb_words[4], mb->un.mb_words[5],\n\t\t\tmb->un.mb_words[6], mb->un.mb_words[7],\n\t\t\tmb->un.mb_words[8], mb->un.mb_words[9],\n\t\t\tmb->un.mb_words[10], mb->un.mb_words[11],\n\t\t\tmb->un.mb_words[12], mboxq->mcqe.word0,\n\t\t\tmboxq->mcqe.mcqe_tag0, \tmboxq->mcqe.mcqe_tag1,\n\t\t\tmboxq->mcqe.trailer);\nexit:\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tpsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\tphba->sli.mbox_active = NULL;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli_issue_mbox_s4(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq,\n\t\t       uint32_t flag)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tunsigned long iflags;\n\tint rc;\n\n\t \n\tlpfc_idiag_mbxacc_dump_issue_mbox(phba, &mboxq->u.mb);\n\n\trc = lpfc_mbox_dev_check(phba);\n\tif (unlikely(rc)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"(%d):2544 Mailbox command x%x (x%x/x%x) \"\n\t\t\t\t\"cannot issue Data: x%x x%x\\n\",\n\t\t\t\tmboxq->vport ? mboxq->vport->vpi : 0,\n\t\t\t\tmboxq->u.mb.mbxCommand,\n\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\t\tpsli->sli_flag, flag);\n\t\tgoto out_not_finished;\n\t}\n\n\t \n\tif (!phba->sli4_hba.intr_enable) {\n\t\tif (flag == MBX_POLL)\n\t\t\trc = lpfc_sli4_post_sync_mbox(phba, mboxq);\n\t\telse\n\t\t\trc = -EIO;\n\t\tif (rc != MBX_SUCCESS)\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\n\t\t\t\t\t\"(%d):2541 Mailbox command x%x \"\n\t\t\t\t\t\"(x%x/x%x) failure: \"\n\t\t\t\t\t\"mqe_sta: x%x mcqe_sta: x%x/x%x \"\n\t\t\t\t\t\"Data: x%x x%x\\n\",\n\t\t\t\t\tmboxq->vport ? mboxq->vport->vpi : 0,\n\t\t\t\t\tmboxq->u.mb.mbxCommand,\n\t\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba,\n\t\t\t\t\t\t\t\t\tmboxq),\n\t\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba,\n\t\t\t\t\t\t\t\t\tmboxq),\n\t\t\t\t\tbf_get(lpfc_mqe_status, &mboxq->u.mqe),\n\t\t\t\t\tbf_get(lpfc_mcqe_status, &mboxq->mcqe),\n\t\t\t\t\tbf_get(lpfc_mcqe_ext_status,\n\t\t\t\t\t       &mboxq->mcqe),\n\t\t\t\t\tpsli->sli_flag, flag);\n\t\treturn rc;\n\t} else if (flag == MBX_POLL) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\n\t\t\t\t\"(%d):2542 Try to issue mailbox command \"\n\t\t\t\t\"x%x (x%x/x%x) synchronously ahead of async \"\n\t\t\t\t\"mailbox command queue: x%x x%x\\n\",\n\t\t\t\tmboxq->vport ? mboxq->vport->vpi : 0,\n\t\t\t\tmboxq->u.mb.mbxCommand,\n\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\t\tpsli->sli_flag, flag);\n\t\t \n\t\trc = lpfc_sli4_async_mbox_block(phba);\n\t\tif (!rc) {\n\t\t\t \n\t\t\trc = lpfc_sli4_post_sync_mbox(phba, mboxq);\n\t\t\tif (rc != MBX_SUCCESS)\n\t\t\t\tlpfc_printf_log(phba, KERN_WARNING,\n\t\t\t\t\tLOG_MBOX | LOG_SLI,\n\t\t\t\t\t\"(%d):2597 Sync Mailbox command \"\n\t\t\t\t\t\"x%x (x%x/x%x) failure: \"\n\t\t\t\t\t\"mqe_sta: x%x mcqe_sta: x%x/x%x \"\n\t\t\t\t\t\"Data: x%x x%x\\n\",\n\t\t\t\t\tmboxq->vport ? mboxq->vport->vpi : 0,\n\t\t\t\t\tmboxq->u.mb.mbxCommand,\n\t\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba,\n\t\t\t\t\t\t\t\t\tmboxq),\n\t\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba,\n\t\t\t\t\t\t\t\t\tmboxq),\n\t\t\t\t\tbf_get(lpfc_mqe_status, &mboxq->u.mqe),\n\t\t\t\t\tbf_get(lpfc_mcqe_status, &mboxq->mcqe),\n\t\t\t\t\tbf_get(lpfc_mcqe_ext_status,\n\t\t\t\t\t       &mboxq->mcqe),\n\t\t\t\t\tpsli->sli_flag, flag);\n\t\t\t \n\t\t\tlpfc_sli4_async_mbox_unblock(phba);\n\t\t}\n\t\treturn rc;\n\t}\n\n\t \n\trc = lpfc_mbox_cmd_check(phba, mboxq);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"(%d):2543 Mailbox command x%x (x%x/x%x) \"\n\t\t\t\t\"cannot issue Data: x%x x%x\\n\",\n\t\t\t\tmboxq->vport ? mboxq->vport->vpi : 0,\n\t\t\t\tmboxq->u.mb.mbxCommand,\n\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\t\tpsli->sli_flag, flag);\n\t\tgoto out_not_finished;\n\t}\n\n\t \n\tpsli->slistat.mbox_busy++;\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tlpfc_mbox_put(phba, mboxq);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\"(%d):0354 Mbox cmd issue - Enqueue Data: \"\n\t\t\t\"x%x (x%x/x%x) x%x x%x x%x\\n\",\n\t\t\tmboxq->vport ? mboxq->vport->vpi : 0xffffff,\n\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\tphba->pport->port_state,\n\t\t\tpsli->sli_flag, MBX_NOWAIT);\n\t \n\tlpfc_worker_wake_up(phba);\n\n\treturn MBX_BUSY;\n\nout_not_finished:\n\treturn MBX_NOT_FINISHED;\n}\n\n \nint\nlpfc_sli4_post_async_mbox(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tLPFC_MBOXQ_t *mboxq;\n\tint rc = MBX_SUCCESS;\n\tunsigned long iflags;\n\tstruct lpfc_mqe *mqe;\n\tuint32_t mbx_cmnd;\n\n\t \n\tif (unlikely(!phba->sli4_hba.intr_enable))\n\t\treturn MBX_NOT_FINISHED;\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tif (unlikely(psli->sli_flag & LPFC_SLI_ASYNC_MBX_BLK)) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\treturn MBX_NOT_FINISHED;\n\t}\n\tif (psli->sli_flag & LPFC_SLI_MBOX_ACTIVE) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\treturn MBX_NOT_FINISHED;\n\t}\n\tif (unlikely(phba->sli.mbox_active)) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0384 There is pending active mailbox cmd\\n\");\n\t\treturn MBX_NOT_FINISHED;\n\t}\n\t \n\tpsli->sli_flag |= LPFC_SLI_MBOX_ACTIVE;\n\n\t \n\tmboxq = lpfc_mbox_get(phba);\n\n\t \n\tif (!mboxq) {\n\t\tpsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\treturn MBX_SUCCESS;\n\t}\n\tphba->sli.mbox_active = mboxq;\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\t \n\trc = lpfc_mbox_dev_check(phba);\n\tif (unlikely(rc))\n\t\t \n\t\tgoto out_not_finished;\n\n\t \n\tmqe = &mboxq->u.mqe;\n\tmbx_cmnd = bf_get(lpfc_mqe_command, mqe);\n\n\t \n\tmod_timer(&psli->mbox_tmo, (jiffies +\n\t\t  msecs_to_jiffies(1000 * lpfc_mbox_tmo_val(phba, mboxq))));\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\"(%d):0355 Mailbox cmd x%x (x%x/x%x) issue Data: \"\n\t\t\t\"x%x x%x\\n\",\n\t\t\tmboxq->vport ? mboxq->vport->vpi : 0, mbx_cmnd,\n\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\tphba->pport->port_state, psli->sli_flag);\n\n\tif (mbx_cmnd != MBX_HEARTBEAT) {\n\t\tif (mboxq->vport) {\n\t\t\tlpfc_debugfs_disc_trc(mboxq->vport,\n\t\t\t\tLPFC_DISC_TRC_MBOX_VPORT,\n\t\t\t\t\"MBOX Send vport: cmd:x%x mb:x%x x%x\",\n\t\t\t\tmbx_cmnd, mqe->un.mb_words[0],\n\t\t\t\tmqe->un.mb_words[1]);\n\t\t} else {\n\t\t\tlpfc_debugfs_disc_trc(phba->pport,\n\t\t\t\tLPFC_DISC_TRC_MBOX,\n\t\t\t\t\"MBOX Send: cmd:x%x mb:x%x x%x\",\n\t\t\t\tmbx_cmnd, mqe->un.mb_words[0],\n\t\t\t\tmqe->un.mb_words[1]);\n\t\t}\n\t}\n\tpsli->slistat.mbox_cmd++;\n\n\t \n\trc = lpfc_sli4_mq_put(phba->sli4_hba.mbx_wq, mqe);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"(%d):2533 Mailbox command x%x (x%x/x%x) \"\n\t\t\t\t\"cannot issue Data: x%x x%x\\n\",\n\t\t\t\tmboxq->vport ? mboxq->vport->vpi : 0,\n\t\t\t\tmboxq->u.mb.mbxCommand,\n\t\t\t\tlpfc_sli_config_mbox_subsys_get(phba, mboxq),\n\t\t\t\tlpfc_sli_config_mbox_opcode_get(phba, mboxq),\n\t\t\t\tpsli->sli_flag, MBX_NOWAIT);\n\t\tgoto out_not_finished;\n\t}\n\n\treturn rc;\n\nout_not_finished:\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tif (phba->sli.mbox_active) {\n\t\tmboxq->u.mb.mbxStatus = MBX_NOT_FINISHED;\n\t\t__lpfc_mbox_cmpl_put(phba, mboxq);\n\t\t \n\t\tpsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\tphba->sli.mbox_active = NULL;\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\treturn MBX_NOT_FINISHED;\n}\n\n \nint\nlpfc_sli_issue_mbox(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmbox, uint32_t flag)\n{\n\treturn phba->lpfc_sli_issue_mbox(phba, pmbox, flag);\n}\n\n \nint\nlpfc_mbox_api_table_setup(struct lpfc_hba *phba, uint8_t dev_grp)\n{\n\n\tswitch (dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\tphba->lpfc_sli_issue_mbox = lpfc_sli_issue_mbox_s3;\n\t\tphba->lpfc_sli_handle_slow_ring_event =\n\t\t\t\tlpfc_sli_handle_slow_ring_event_s3;\n\t\tphba->lpfc_sli_hbq_to_firmware = lpfc_sli_hbq_to_firmware_s3;\n\t\tphba->lpfc_sli_brdrestart = lpfc_sli_brdrestart_s3;\n\t\tphba->lpfc_sli_brdready = lpfc_sli_brdready_s3;\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\tphba->lpfc_sli_issue_mbox = lpfc_sli_issue_mbox_s4;\n\t\tphba->lpfc_sli_handle_slow_ring_event =\n\t\t\t\tlpfc_sli_handle_slow_ring_event_s4;\n\t\tphba->lpfc_sli_hbq_to_firmware = lpfc_sli_hbq_to_firmware_s4;\n\t\tphba->lpfc_sli_brdrestart = lpfc_sli_brdrestart_s4;\n\t\tphba->lpfc_sli_brdready = lpfc_sli_brdready_s4;\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1420 Invalid HBA PCI-device group: 0x%x\\n\",\n\t\t\t\tdev_grp);\n\t\treturn -ENODEV;\n\t}\n\treturn 0;\n}\n\n \nvoid\n__lpfc_sli_ringtx_put(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t    struct lpfc_iocbq *piocb)\n{\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tlockdep_assert_held(&pring->ring_lock);\n\telse\n\t\tlockdep_assert_held(&phba->hbalock);\n\t \n\tlist_add_tail(&piocb->list, &pring->txq);\n}\n\n \nstatic struct lpfc_iocbq *\nlpfc_sli_next_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t   struct lpfc_iocbq **piocb)\n{\n\tstruct lpfc_iocbq * nextiocb;\n\n\tlockdep_assert_held(&phba->hbalock);\n\n\tnextiocb = lpfc_sli_ringtx_get(phba, pring);\n\tif (!nextiocb) {\n\t\tnextiocb = *piocb;\n\t\t*piocb = NULL;\n\t}\n\n\treturn nextiocb;\n}\n\n \nstatic int\n__lpfc_sli_issue_iocb_s3(struct lpfc_hba *phba, uint32_t ring_number,\n\t\t    struct lpfc_iocbq *piocb, uint32_t flag)\n{\n\tstruct lpfc_iocbq *nextiocb;\n\tIOCB_t *iocb;\n\tstruct lpfc_sli_ring *pring = &phba->sli.sli3_ring[ring_number];\n\n\tlockdep_assert_held(&phba->hbalock);\n\n\tif (piocb->cmd_cmpl && (!piocb->vport) &&\n\t   (piocb->iocb.ulpCommand != CMD_ABORT_XRI_CN) &&\n\t   (piocb->iocb.ulpCommand != CMD_CLOSE_XRI_CN)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1807 IOCB x%x failed. No vport\\n\",\n\t\t\t\tpiocb->iocb.ulpCommand);\n\t\tdump_stack();\n\t\treturn IOCB_ERROR;\n\t}\n\n\n\t \n\tif (unlikely(pci_channel_offline(phba->pcidev)))\n\t\treturn IOCB_ERROR;\n\n\t \n\tif (unlikely(phba->hba_flag & DEFER_ERATT))\n\t\treturn IOCB_ERROR;\n\n\t \n\tif (unlikely(phba->link_state < LPFC_LINK_DOWN))\n\t\treturn IOCB_ERROR;\n\n\t \n\tif (unlikely(pring->flag & LPFC_STOP_IOCB_EVENT))\n\t\tgoto iocb_busy;\n\n\tif (unlikely(phba->link_state == LPFC_LINK_DOWN)) {\n\t\t \n\t\tswitch (piocb->iocb.ulpCommand) {\n\t\tcase CMD_QUE_RING_BUF_CN:\n\t\tcase CMD_QUE_RING_BUF64_CN:\n\t\t\t \n\t\t\tif (piocb->cmd_cmpl)\n\t\t\t\tpiocb->cmd_cmpl = NULL;\n\t\t\tfallthrough;\n\t\tcase CMD_CREATE_XRI_CR:\n\t\tcase CMD_CLOSE_XRI_CN:\n\t\tcase CMD_CLOSE_XRI_CX:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto iocb_busy;\n\t\t}\n\n\t \n\t} else if (unlikely(pring->ringno == LPFC_FCP_RING &&\n\t\t\t    !(phba->sli.sli_flag & LPFC_PROCESS_LA))) {\n\t\tgoto iocb_busy;\n\t}\n\n\twhile ((iocb = lpfc_sli_next_iocb_slot(phba, pring)) &&\n\t       (nextiocb = lpfc_sli_next_iocb(phba, pring, &piocb)))\n\t\tlpfc_sli_submit_iocb(phba, pring, iocb, nextiocb);\n\n\tif (iocb)\n\t\tlpfc_sli_update_ring(phba, pring);\n\telse\n\t\tlpfc_sli_update_full_ring(phba, pring);\n\n\tif (!piocb)\n\t\treturn IOCB_SUCCESS;\n\n\tgoto out_busy;\n\n iocb_busy:\n\tpring->stats.iocb_cmd_delay++;\n\n out_busy:\n\n\tif (!(flag & SLI_IOCB_RET_IOCB)) {\n\t\t__lpfc_sli_ringtx_put(phba, pring, piocb);\n\t\treturn IOCB_SUCCESS;\n\t}\n\n\treturn IOCB_BUSY;\n}\n\n \nstatic int\n__lpfc_sli_issue_fcp_io_s3(struct lpfc_hba *phba, uint32_t ring_number,\n\t\t\t   struct lpfc_iocbq *piocb, uint32_t flag)\n{\n\tunsigned long iflags;\n\tint rc;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\trc = __lpfc_sli_issue_iocb_s3(phba, ring_number, piocb, flag);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\treturn rc;\n}\n\n \nstatic int\n__lpfc_sli_issue_fcp_io_s4(struct lpfc_hba *phba, uint32_t ring_number,\n\t\t\t   struct lpfc_iocbq *piocb, uint32_t flag)\n{\n\tstruct lpfc_io_buf *lpfc_cmd = piocb->io_buf;\n\n\tlpfc_prep_embed_io(phba, lpfc_cmd);\n\treturn lpfc_sli4_issue_wqe(phba, lpfc_cmd->hdwq, piocb);\n}\n\nvoid\nlpfc_prep_embed_io(struct lpfc_hba *phba, struct lpfc_io_buf *lpfc_cmd)\n{\n\tstruct lpfc_iocbq *piocb = &lpfc_cmd->cur_iocbq;\n\tunion lpfc_wqe128 *wqe = &lpfc_cmd->cur_iocbq.wqe;\n\tstruct sli4_sge *sgl;\n\n\t \n\tsgl = (struct sli4_sge *)lpfc_cmd->dma_sgl;\n\n\tif (phba->fcp_embed_io) {\n\t\tstruct fcp_cmnd *fcp_cmnd;\n\t\tu32 *ptr;\n\n\t\tfcp_cmnd = lpfc_cmd->fcp_cmnd;\n\n\t\t \n\t\twqe->generic.bde.tus.f.bdeFlags =\n\t\t\tBUFF_TYPE_BDE_IMMED;\n\t\twqe->generic.bde.tus.f.bdeSize = sgl->sge_len;\n\t\twqe->generic.bde.addrHigh = 0;\n\t\twqe->generic.bde.addrLow =  88;   \n\n\t\tbf_set(wqe_wqes, &wqe->fcp_iwrite.wqe_com, 1);\n\t\tbf_set(wqe_dbde, &wqe->fcp_iwrite.wqe_com, 0);\n\n\t\t \n\t\tptr = &wqe->words[22];\n\t\tmemcpy(ptr, fcp_cmnd, sizeof(struct fcp_cmnd));\n\t} else {\n\t\t \n\t\twqe->generic.bde.tus.f.bdeFlags =  BUFF_TYPE_BDE_64;\n\t\twqe->generic.bde.tus.f.bdeSize = sizeof(struct fcp_cmnd);\n\t\twqe->generic.bde.addrHigh = sgl->addr_hi;\n\t\twqe->generic.bde.addrLow =  sgl->addr_lo;\n\n\t\t \n\t\tbf_set(wqe_dbde, &wqe->generic.wqe_com, 1);\n\t\tbf_set(wqe_wqes, &wqe->generic.wqe_com, 0);\n\t}\n\n\t \n\tif (unlikely(piocb->cmd_flag & LPFC_IO_VMID)) {\n\t\tif (phba->pport->vmid_flag & LPFC_VMID_TYPE_PRIO) {\n\t\t\tbf_set(wqe_ccpe, &wqe->fcp_iwrite.wqe_com, 1);\n\t\t\tbf_set(wqe_ccp, &wqe->fcp_iwrite.wqe_com,\n\t\t\t\t\t(piocb->vmid_tag.cs_ctl_vmid));\n\t\t} else if (phba->cfg_vmid_app_header) {\n\t\t\tbf_set(wqe_appid, &wqe->fcp_iwrite.wqe_com, 1);\n\t\t\tbf_set(wqe_wqes, &wqe->fcp_iwrite.wqe_com, 1);\n\t\t\twqe->words[31] = piocb->vmid_tag.app_id;\n\t\t}\n\t}\n}\n\n \nstatic int\n__lpfc_sli_issue_iocb_s4(struct lpfc_hba *phba, uint32_t ring_number,\n\t\t\t struct lpfc_iocbq *piocb, uint32_t flag)\n{\n\tstruct lpfc_sglq *sglq;\n\tunion lpfc_wqe128 *wqe;\n\tstruct lpfc_queue *wq;\n\tstruct lpfc_sli_ring *pring;\n\tu32 ulp_command = get_job_cmnd(phba, piocb);\n\n\t \n\tif ((piocb->cmd_flag & LPFC_IO_FCP) ||\n\t    (piocb->cmd_flag & LPFC_USE_FCPWQIDX)) {\n\t\twq = phba->sli4_hba.hdwq[piocb->hba_wqidx].io_wq;\n\t} else {\n\t\twq = phba->sli4_hba.els_wq;\n\t}\n\n\t \n\tpring = wq->pring;\n\n\t \n\n\tlockdep_assert_held(&pring->ring_lock);\n\twqe = &piocb->wqe;\n\tif (piocb->sli4_xritag == NO_XRI) {\n\t\tif (ulp_command == CMD_ABORT_XRI_CX)\n\t\t\tsglq = NULL;\n\t\telse {\n\t\t\tsglq = __lpfc_sli_get_els_sglq(phba, piocb);\n\t\t\tif (!sglq) {\n\t\t\t\tif (!(flag & SLI_IOCB_RET_IOCB)) {\n\t\t\t\t\t__lpfc_sli_ringtx_put(phba,\n\t\t\t\t\t\t\tpring,\n\t\t\t\t\t\t\tpiocb);\n\t\t\t\t\treturn IOCB_SUCCESS;\n\t\t\t\t} else {\n\t\t\t\t\treturn IOCB_BUSY;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (piocb->cmd_flag &  LPFC_IO_FCP) {\n\t\t \n\t\tsglq = NULL;\n\t}\n\telse {\n\t\t \n\t\tsglq = __lpfc_get_active_sglq(phba, piocb->sli4_lxritag);\n\t\tif (!sglq)\n\t\t\treturn IOCB_ERROR;\n\t}\n\n\tif (sglq) {\n\t\tpiocb->sli4_lxritag = sglq->sli4_lxritag;\n\t\tpiocb->sli4_xritag = sglq->sli4_xritag;\n\n\t\t \n\t\tif (ulp_command == CMD_XMIT_BLS_RSP64_CX &&\n\t\t    piocb->abort_bls == LPFC_ABTS_UNSOL_INT)\n\t\t\tbf_set(xmit_bls_rsp64_rxid, &wqe->xmit_bls_rsp,\n\t\t\t       piocb->sli4_xritag);\n\n\t\tbf_set(wqe_xri_tag, &wqe->generic.wqe_com,\n\t\t       piocb->sli4_xritag);\n\n\t\tif (lpfc_wqe_bpl2sgl(phba, piocb, sglq) == NO_XRI)\n\t\t\treturn IOCB_ERROR;\n\t}\n\n\tif (lpfc_sli4_wq_put(wq, wqe))\n\t\treturn IOCB_ERROR;\n\n\tlpfc_sli_ringtxcmpl_put(phba, pring, piocb);\n\n\treturn 0;\n}\n\n \nint\nlpfc_sli_issue_fcp_io(struct lpfc_hba *phba, uint32_t ring_number,\n\t\t      struct lpfc_iocbq *piocb, uint32_t flag)\n{\n\treturn phba->__lpfc_sli_issue_fcp_io(phba, ring_number, piocb, flag);\n}\n\n \nint\n__lpfc_sli_issue_iocb(struct lpfc_hba *phba, uint32_t ring_number,\n\t\tstruct lpfc_iocbq *piocb, uint32_t flag)\n{\n\treturn phba->__lpfc_sli_issue_iocb(phba, ring_number, piocb, flag);\n}\n\nstatic void\n__lpfc_sli_prep_els_req_rsp_s3(struct lpfc_iocbq *cmdiocbq,\n\t\t\t       struct lpfc_vport *vport,\n\t\t\t       struct lpfc_dmabuf *bmp, u16 cmd_size, u32 did,\n\t\t\t       u32 elscmd, u8 tmo, u8 expect_rsp)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tIOCB_t *cmd;\n\n\tcmd = &cmdiocbq->iocb;\n\tmemset(cmd, 0, sizeof(*cmd));\n\n\tcmd->un.elsreq64.bdl.addrHigh = putPaddrHigh(bmp->phys);\n\tcmd->un.elsreq64.bdl.addrLow = putPaddrLow(bmp->phys);\n\tcmd->un.elsreq64.bdl.bdeFlags = BUFF_TYPE_BLP_64;\n\n\tif (expect_rsp) {\n\t\tcmd->un.elsreq64.bdl.bdeSize = (2 * sizeof(struct ulp_bde64));\n\t\tcmd->un.elsreq64.remoteID = did;  \n\t\tcmd->ulpCommand = CMD_ELS_REQUEST64_CR;\n\t\tcmd->ulpTimeout = tmo;\n\t} else {\n\t\tcmd->un.elsreq64.bdl.bdeSize = sizeof(struct ulp_bde64);\n\t\tcmd->un.genreq64.xmit_els_remoteID = did;  \n\t\tcmd->ulpCommand = CMD_XMIT_ELS_RSP64_CX;\n\t\tcmd->ulpPU = PARM_NPIV_DID;\n\t}\n\tcmd->ulpBdeCount = 1;\n\tcmd->ulpLe = 1;\n\tcmd->ulpClass = CLASS3;\n\n\t \n\tif (phba->sli3_options & LPFC_SLI3_NPIV_ENABLED) {\n\t\tif (expect_rsp) {\n\t\t\tcmd->un.elsreq64.myID = vport->fc_myDID;\n\n\t\t\t \n\t\t\tcmd->ulpContext = phba->vpi_ids[vport->vpi];\n\t\t}\n\n\t\tcmd->ulpCt_h = 0;\n\t\t \n\t\tif (elscmd == ELS_CMD_ECHO)\n\t\t\tcmd->ulpCt_l = 0;  \n\t\telse\n\t\t\tcmd->ulpCt_l = 1;  \n\t}\n}\n\nstatic void\n__lpfc_sli_prep_els_req_rsp_s4(struct lpfc_iocbq *cmdiocbq,\n\t\t\t       struct lpfc_vport *vport,\n\t\t\t       struct lpfc_dmabuf *bmp, u16 cmd_size, u32 did,\n\t\t\t       u32 elscmd, u8 tmo, u8 expect_rsp)\n{\n\tstruct lpfc_hba  *phba = vport->phba;\n\tunion lpfc_wqe128 *wqe;\n\tstruct ulp_bde64_le *bde;\n\tu8 els_id;\n\n\twqe = &cmdiocbq->wqe;\n\tmemset(wqe, 0, sizeof(*wqe));\n\n\t \n\tbde = (struct ulp_bde64_le *)&wqe->generic.bde;\n\tbde->addr_low = cpu_to_le32(putPaddrLow(bmp->phys));\n\tbde->addr_high = cpu_to_le32(putPaddrHigh(bmp->phys));\n\tbde->type_size = cpu_to_le32(cmd_size);\n\tbde->type_size |= cpu_to_le32(ULP_BDE64_TYPE_BDE_64);\n\n\tif (expect_rsp) {\n\t\tbf_set(wqe_cmnd, &wqe->els_req.wqe_com, CMD_ELS_REQUEST64_WQE);\n\n\t\t \n\t\twqe->els_req.payload_len = cmd_size;\n\t\twqe->els_req.max_response_payload_len = FCELSSIZE;\n\n\t\t \n\t\tbf_set(wqe_els_did, &wqe->els_req.wqe_dest, did);\n\n\t\t \n\t\tswitch (elscmd) {\n\t\tcase ELS_CMD_PLOGI:\n\t\t\tels_id = LPFC_ELS_ID_PLOGI;\n\t\t\tbreak;\n\t\tcase ELS_CMD_FLOGI:\n\t\t\tels_id = LPFC_ELS_ID_FLOGI;\n\t\t\tbreak;\n\t\tcase ELS_CMD_LOGO:\n\t\t\tels_id = LPFC_ELS_ID_LOGO;\n\t\t\tbreak;\n\t\tcase ELS_CMD_FDISC:\n\t\t\tif (!vport->fc_myDID) {\n\t\t\t\tels_id = LPFC_ELS_ID_FDISC;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tfallthrough;\n\t\tdefault:\n\t\t\tels_id = LPFC_ELS_ID_DEFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tbf_set(wqe_els_id, &wqe->els_req.wqe_com, els_id);\n\t} else {\n\t\t \n\t\tbf_set(wqe_els_did, &wqe->xmit_els_rsp.wqe_dest, did);\n\n\t\t \n\t\twqe->xmit_els_rsp.response_payload_len = cmd_size;\n\n\t\tbf_set(wqe_cmnd, &wqe->xmit_els_rsp.wqe_com,\n\t\t       CMD_XMIT_ELS_RSP64_WQE);\n\t}\n\n\tbf_set(wqe_tmo, &wqe->generic.wqe_com, tmo);\n\tbf_set(wqe_reqtag, &wqe->generic.wqe_com, cmdiocbq->iotag);\n\tbf_set(wqe_class, &wqe->generic.wqe_com, CLASS3);\n\n\t \n\tif ((phba->sli3_options & LPFC_SLI3_NPIV_ENABLED) ||\n\t    (vport->fc_flag & FC_PT2PT)) {\n\t\tif (expect_rsp) {\n\t\t\tbf_set(els_req64_sid, &wqe->els_req, vport->fc_myDID);\n\n\t\t\t \n\t\t\tbf_set(wqe_ctxt_tag, &wqe->els_req.wqe_com,\n\t\t\t       phba->vpi_ids[vport->vpi]);\n\t\t}\n\n\t\t \n\t\tif (elscmd == ELS_CMD_ECHO)\n\t\t\tbf_set(wqe_ct, &wqe->generic.wqe_com, 0);\n\t\telse\n\t\t\tbf_set(wqe_ct, &wqe->generic.wqe_com, 1);\n\t}\n}\n\nvoid\nlpfc_sli_prep_els_req_rsp(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocbq,\n\t\t\t  struct lpfc_vport *vport, struct lpfc_dmabuf *bmp,\n\t\t\t  u16 cmd_size, u32 did, u32 elscmd, u8 tmo,\n\t\t\t  u8 expect_rsp)\n{\n\tphba->__lpfc_sli_prep_els_req_rsp(cmdiocbq, vport, bmp, cmd_size, did,\n\t\t\t\t\t  elscmd, tmo, expect_rsp);\n}\n\nstatic void\n__lpfc_sli_prep_gen_req_s3(struct lpfc_iocbq *cmdiocbq, struct lpfc_dmabuf *bmp,\n\t\t\t   u16 rpi, u32 num_entry, u8 tmo)\n{\n\tIOCB_t *cmd;\n\n\tcmd = &cmdiocbq->iocb;\n\tmemset(cmd, 0, sizeof(*cmd));\n\n\tcmd->un.genreq64.bdl.addrHigh = putPaddrHigh(bmp->phys);\n\tcmd->un.genreq64.bdl.addrLow = putPaddrLow(bmp->phys);\n\tcmd->un.genreq64.bdl.bdeFlags = BUFF_TYPE_BLP_64;\n\tcmd->un.genreq64.bdl.bdeSize = num_entry * sizeof(struct ulp_bde64);\n\n\tcmd->un.genreq64.w5.hcsw.Rctl = FC_RCTL_DD_UNSOL_CTL;\n\tcmd->un.genreq64.w5.hcsw.Type = FC_TYPE_CT;\n\tcmd->un.genreq64.w5.hcsw.Fctl = (SI | LA);\n\n\tcmd->ulpContext = rpi;\n\tcmd->ulpClass = CLASS3;\n\tcmd->ulpCommand = CMD_GEN_REQUEST64_CR;\n\tcmd->ulpBdeCount = 1;\n\tcmd->ulpLe = 1;\n\tcmd->ulpOwner = OWN_CHIP;\n\tcmd->ulpTimeout = tmo;\n}\n\nstatic void\n__lpfc_sli_prep_gen_req_s4(struct lpfc_iocbq *cmdiocbq, struct lpfc_dmabuf *bmp,\n\t\t\t   u16 rpi, u32 num_entry, u8 tmo)\n{\n\tunion lpfc_wqe128 *cmdwqe;\n\tstruct ulp_bde64_le *bde, *bpl;\n\tu32 xmit_len = 0, total_len = 0, size, type, i;\n\n\tcmdwqe = &cmdiocbq->wqe;\n\tmemset(cmdwqe, 0, sizeof(*cmdwqe));\n\n\t \n\tbpl = (struct ulp_bde64_le *)bmp->virt;\n\tfor (i = 0; i < num_entry; i++) {\n\t\tsize = le32_to_cpu(bpl[i].type_size) & ULP_BDE64_SIZE_MASK;\n\t\ttotal_len += size;\n\t}\n\tfor (i = 0; i < num_entry; i++) {\n\t\tsize = le32_to_cpu(bpl[i].type_size) & ULP_BDE64_SIZE_MASK;\n\t\ttype = le32_to_cpu(bpl[i].type_size) & ULP_BDE64_TYPE_MASK;\n\t\tif (type != ULP_BDE64_TYPE_BDE_64)\n\t\t\tbreak;\n\t\txmit_len += size;\n\t}\n\n\t \n\tbde = (struct ulp_bde64_le *)&cmdwqe->generic.bde;\n\tbde->addr_low = bpl->addr_low;\n\tbde->addr_high = bpl->addr_high;\n\tbde->type_size = cpu_to_le32(xmit_len);\n\tbde->type_size |= cpu_to_le32(ULP_BDE64_TYPE_BDE_64);\n\n\t \n\tcmdwqe->gen_req.request_payload_len = xmit_len;\n\n\t \n\tbf_set(wqe_type, &cmdwqe->gen_req.wge_ctl, FC_TYPE_CT);\n\tbf_set(wqe_rctl, &cmdwqe->gen_req.wge_ctl, FC_RCTL_DD_UNSOL_CTL);\n\tbf_set(wqe_si, &cmdwqe->gen_req.wge_ctl, 1);\n\tbf_set(wqe_la, &cmdwqe->gen_req.wge_ctl, 1);\n\n\t \n\tbf_set(wqe_ctxt_tag, &cmdwqe->gen_req.wqe_com, rpi);\n\n\t \n\tbf_set(wqe_tmo, &cmdwqe->gen_req.wqe_com, tmo);\n\tbf_set(wqe_class, &cmdwqe->gen_req.wqe_com, CLASS3);\n\tbf_set(wqe_cmnd, &cmdwqe->gen_req.wqe_com, CMD_GEN_REQUEST64_CR);\n\tbf_set(wqe_ct, &cmdwqe->gen_req.wqe_com, SLI4_CT_RPI);\n\n\t \n\tcmdwqe->gen_req.max_response_payload_len = total_len - xmit_len;\n}\n\nvoid\nlpfc_sli_prep_gen_req(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocbq,\n\t\t      struct lpfc_dmabuf *bmp, u16 rpi, u32 num_entry, u8 tmo)\n{\n\tphba->__lpfc_sli_prep_gen_req(cmdiocbq, bmp, rpi, num_entry, tmo);\n}\n\nstatic void\n__lpfc_sli_prep_xmit_seq64_s3(struct lpfc_iocbq *cmdiocbq,\n\t\t\t      struct lpfc_dmabuf *bmp, u16 rpi, u16 ox_id,\n\t\t\t      u32 num_entry, u8 rctl, u8 last_seq, u8 cr_cx_cmd)\n{\n\tIOCB_t *icmd;\n\n\ticmd = &cmdiocbq->iocb;\n\tmemset(icmd, 0, sizeof(*icmd));\n\n\ticmd->un.xseq64.bdl.addrHigh = putPaddrHigh(bmp->phys);\n\ticmd->un.xseq64.bdl.addrLow = putPaddrLow(bmp->phys);\n\ticmd->un.xseq64.bdl.bdeFlags = BUFF_TYPE_BLP_64;\n\ticmd->un.xseq64.bdl.bdeSize = (num_entry * sizeof(struct ulp_bde64));\n\ticmd->un.xseq64.w5.hcsw.Fctl = LA;\n\tif (last_seq)\n\t\ticmd->un.xseq64.w5.hcsw.Fctl |= LS;\n\ticmd->un.xseq64.w5.hcsw.Dfctl = 0;\n\ticmd->un.xseq64.w5.hcsw.Rctl = rctl;\n\ticmd->un.xseq64.w5.hcsw.Type = FC_TYPE_CT;\n\n\ticmd->ulpBdeCount = 1;\n\ticmd->ulpLe = 1;\n\ticmd->ulpClass = CLASS3;\n\n\tswitch (cr_cx_cmd) {\n\tcase CMD_XMIT_SEQUENCE64_CR:\n\t\ticmd->ulpContext = rpi;\n\t\ticmd->ulpCommand = CMD_XMIT_SEQUENCE64_CR;\n\t\tbreak;\n\tcase CMD_XMIT_SEQUENCE64_CX:\n\t\ticmd->ulpContext = ox_id;\n\t\ticmd->ulpCommand = CMD_XMIT_SEQUENCE64_CX;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void\n__lpfc_sli_prep_xmit_seq64_s4(struct lpfc_iocbq *cmdiocbq,\n\t\t\t      struct lpfc_dmabuf *bmp, u16 rpi, u16 ox_id,\n\t\t\t      u32 full_size, u8 rctl, u8 last_seq, u8 cr_cx_cmd)\n{\n\tunion lpfc_wqe128 *wqe;\n\tstruct ulp_bde64 *bpl;\n\n\twqe = &cmdiocbq->wqe;\n\tmemset(wqe, 0, sizeof(*wqe));\n\n\t \n\tbpl = (struct ulp_bde64 *)bmp->virt;\n\twqe->xmit_sequence.bde.addrHigh = bpl->addrHigh;\n\twqe->xmit_sequence.bde.addrLow = bpl->addrLow;\n\twqe->xmit_sequence.bde.tus.w = bpl->tus.w;\n\n\t \n\tbf_set(wqe_ls, &wqe->xmit_sequence.wge_ctl, last_seq);\n\tbf_set(wqe_la, &wqe->xmit_sequence.wge_ctl, 1);\n\tbf_set(wqe_dfctl, &wqe->xmit_sequence.wge_ctl, 0);\n\tbf_set(wqe_rctl, &wqe->xmit_sequence.wge_ctl, rctl);\n\tbf_set(wqe_type, &wqe->xmit_sequence.wge_ctl, FC_TYPE_CT);\n\n\t \n\tbf_set(wqe_ctxt_tag, &wqe->xmit_sequence.wqe_com, rpi);\n\n\tbf_set(wqe_cmnd, &wqe->xmit_sequence.wqe_com,\n\t       CMD_XMIT_SEQUENCE64_WQE);\n\n\t \n\tbf_set(wqe_class, &wqe->xmit_sequence.wqe_com, CLASS3);\n\n\t \n\tbf_set(wqe_rcvoxid, &wqe->xmit_sequence.wqe_com, ox_id);\n\n\t \n\tif (cmdiocbq->cmd_flag & (LPFC_IO_LIBDFC | LPFC_IO_LOOPBACK))\n\t\twqe->xmit_sequence.xmit_len = full_size;\n\telse\n\t\twqe->xmit_sequence.xmit_len =\n\t\t\twqe->xmit_sequence.bde.tus.f.bdeSize;\n}\n\nvoid\nlpfc_sli_prep_xmit_seq64(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocbq,\n\t\t\t struct lpfc_dmabuf *bmp, u16 rpi, u16 ox_id,\n\t\t\t u32 num_entry, u8 rctl, u8 last_seq, u8 cr_cx_cmd)\n{\n\tphba->__lpfc_sli_prep_xmit_seq64(cmdiocbq, bmp, rpi, ox_id, num_entry,\n\t\t\t\t\t rctl, last_seq, cr_cx_cmd);\n}\n\nstatic void\n__lpfc_sli_prep_abort_xri_s3(struct lpfc_iocbq *cmdiocbq, u16 ulp_context,\n\t\t\t     u16 iotag, u8 ulp_class, u16 cqid, bool ia,\n\t\t\t     bool wqec)\n{\n\tIOCB_t *icmd = NULL;\n\n\ticmd = &cmdiocbq->iocb;\n\tmemset(icmd, 0, sizeof(*icmd));\n\n\t \n\ticmd->un.acxri.abortContextTag = ulp_context;\n\ticmd->un.acxri.abortIoTag = iotag;\n\n\tif (ia) {\n\t\t \n\t\ticmd->ulpCommand = CMD_CLOSE_XRI_CN;\n\t} else {\n\t\t \n\t\ticmd->un.acxri.abortType = ABORT_TYPE_ABTS;\n\n\t\t \n\t\ticmd->ulpClass = ulp_class;\n\t\ticmd->ulpCommand = CMD_ABORT_XRI_CN;\n\t}\n\n\t \n\ticmd->ulpLe = 1;\n}\n\nstatic void\n__lpfc_sli_prep_abort_xri_s4(struct lpfc_iocbq *cmdiocbq, u16 ulp_context,\n\t\t\t     u16 iotag, u8 ulp_class, u16 cqid, bool ia,\n\t\t\t     bool wqec)\n{\n\tunion lpfc_wqe128 *wqe;\n\n\twqe = &cmdiocbq->wqe;\n\tmemset(wqe, 0, sizeof(*wqe));\n\n\t \n\tbf_set(abort_cmd_criteria, &wqe->abort_cmd, T_XRI_TAG);\n\tif (ia)\n\t\tbf_set(abort_cmd_ia, &wqe->abort_cmd, 1);\n\telse\n\t\tbf_set(abort_cmd_ia, &wqe->abort_cmd, 0);\n\n\t \n\tbf_set(wqe_cmnd, &wqe->abort_cmd.wqe_com, CMD_ABORT_XRI_WQE);\n\n\t \n\twqe->abort_cmd.wqe_com.abort_tag = ulp_context;\n\n\t \n\tbf_set(wqe_reqtag, &wqe->abort_cmd.wqe_com, iotag);\n\n\t \n\tbf_set(wqe_qosd, &wqe->abort_cmd.wqe_com, 1);\n\n\t \n\tif (wqec)\n\t\tbf_set(wqe_wqec, &wqe->abort_cmd.wqe_com, 1);\n\tbf_set(wqe_cqid, &wqe->abort_cmd.wqe_com, cqid);\n\tbf_set(wqe_cmd_type, &wqe->abort_cmd.wqe_com, OTHER_COMMAND);\n}\n\nvoid\nlpfc_sli_prep_abort_xri(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocbq,\n\t\t\tu16 ulp_context, u16 iotag, u8 ulp_class, u16 cqid,\n\t\t\tbool ia, bool wqec)\n{\n\tphba->__lpfc_sli_prep_abort_xri(cmdiocbq, ulp_context, iotag, ulp_class,\n\t\t\t\t\tcqid, ia, wqec);\n}\n\n \nint\nlpfc_sli_api_table_setup(struct lpfc_hba *phba, uint8_t dev_grp)\n{\n\n\tswitch (dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\tphba->__lpfc_sli_issue_iocb = __lpfc_sli_issue_iocb_s3;\n\t\tphba->__lpfc_sli_release_iocbq = __lpfc_sli_release_iocbq_s3;\n\t\tphba->__lpfc_sli_issue_fcp_io = __lpfc_sli_issue_fcp_io_s3;\n\t\tphba->__lpfc_sli_prep_els_req_rsp = __lpfc_sli_prep_els_req_rsp_s3;\n\t\tphba->__lpfc_sli_prep_gen_req = __lpfc_sli_prep_gen_req_s3;\n\t\tphba->__lpfc_sli_prep_xmit_seq64 = __lpfc_sli_prep_xmit_seq64_s3;\n\t\tphba->__lpfc_sli_prep_abort_xri = __lpfc_sli_prep_abort_xri_s3;\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\tphba->__lpfc_sli_issue_iocb = __lpfc_sli_issue_iocb_s4;\n\t\tphba->__lpfc_sli_release_iocbq = __lpfc_sli_release_iocbq_s4;\n\t\tphba->__lpfc_sli_issue_fcp_io = __lpfc_sli_issue_fcp_io_s4;\n\t\tphba->__lpfc_sli_prep_els_req_rsp = __lpfc_sli_prep_els_req_rsp_s4;\n\t\tphba->__lpfc_sli_prep_gen_req = __lpfc_sli_prep_gen_req_s4;\n\t\tphba->__lpfc_sli_prep_xmit_seq64 = __lpfc_sli_prep_xmit_seq64_s4;\n\t\tphba->__lpfc_sli_prep_abort_xri = __lpfc_sli_prep_abort_xri_s4;\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1419 Invalid HBA PCI-device group: 0x%x\\n\",\n\t\t\t\tdev_grp);\n\t\treturn -ENODEV;\n\t}\n\treturn 0;\n}\n\n \nstruct lpfc_sli_ring *\nlpfc_sli4_calc_ring(struct lpfc_hba *phba, struct lpfc_iocbq *piocb)\n{\n\tstruct lpfc_io_buf *lpfc_cmd;\n\n\tif (piocb->cmd_flag & (LPFC_IO_FCP | LPFC_USE_FCPWQIDX)) {\n\t\tif (unlikely(!phba->sli4_hba.hdwq))\n\t\t\treturn NULL;\n\t\t \n\t\tif (!(piocb->cmd_flag & LPFC_USE_FCPWQIDX)) {\n\t\t\tlpfc_cmd = piocb->io_buf;\n\t\t\tpiocb->hba_wqidx = lpfc_cmd->hdwq_no;\n\t\t}\n\t\treturn phba->sli4_hba.hdwq[piocb->hba_wqidx].io_wq->pring;\n\t} else {\n\t\tif (unlikely(!phba->sli4_hba.els_wq))\n\t\t\treturn NULL;\n\t\tpiocb->hba_wqidx = 0;\n\t\treturn phba->sli4_hba.els_wq->pring;\n\t}\n}\n\ninline void lpfc_sli4_poll_eq(struct lpfc_queue *eq)\n{\n\tstruct lpfc_hba *phba = eq->phba;\n\n\t \n\tsmp_rmb();\n\n\tif (READ_ONCE(eq->mode) == LPFC_EQ_POLL)\n\t\t \n\t\tlpfc_sli4_process_eq(phba, eq, LPFC_QUEUE_NOARM,\n\t\t\t\t     LPFC_QUEUE_WORK);\n}\n\n \nint\nlpfc_sli_issue_iocb(struct lpfc_hba *phba, uint32_t ring_number,\n\t\t    struct lpfc_iocbq *piocb, uint32_t flag)\n{\n\tstruct lpfc_sli_ring *pring;\n\tstruct lpfc_queue *eq;\n\tunsigned long iflags;\n\tint rc;\n\n\t \n\tif (unlikely(pci_channel_offline(phba->pcidev)))\n\t\treturn IOCB_ERROR;\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tlpfc_sli_prep_wqe(phba, piocb);\n\n\t\teq = phba->sli4_hba.hdwq[piocb->hba_wqidx].hba_eq;\n\n\t\tpring = lpfc_sli4_calc_ring(phba, piocb);\n\t\tif (unlikely(pring == NULL))\n\t\t\treturn IOCB_ERROR;\n\n\t\tspin_lock_irqsave(&pring->ring_lock, iflags);\n\t\trc = __lpfc_sli_issue_iocb(phba, ring_number, piocb, flag);\n\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\n\t\tlpfc_sli4_poll_eq(eq);\n\t} else {\n\t\t \n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\trc = __lpfc_sli_issue_iocb(phba, ring_number, piocb, flag);\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t}\n\treturn rc;\n}\n\n \nstatic int\nlpfc_extra_ring_setup( struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli;\n\tstruct lpfc_sli_ring *pring;\n\n\tpsli = &phba->sli;\n\n\t \n\n\t \n\tpring = &psli->sli3_ring[LPFC_FCP_RING];\n\tpring->sli.sli3.numCiocb -= SLI2_IOCB_CMD_R1XTRA_ENTRIES;\n\tpring->sli.sli3.numRiocb -= SLI2_IOCB_RSP_R1XTRA_ENTRIES;\n\tpring->sli.sli3.numCiocb -= SLI2_IOCB_CMD_R3XTRA_ENTRIES;\n\tpring->sli.sli3.numRiocb -= SLI2_IOCB_RSP_R3XTRA_ENTRIES;\n\n\t \n\tpring = &psli->sli3_ring[LPFC_EXTRA_RING];\n\n\tpring->sli.sli3.numCiocb += SLI2_IOCB_CMD_R1XTRA_ENTRIES;\n\tpring->sli.sli3.numRiocb += SLI2_IOCB_RSP_R1XTRA_ENTRIES;\n\tpring->sli.sli3.numCiocb += SLI2_IOCB_CMD_R3XTRA_ENTRIES;\n\tpring->sli.sli3.numRiocb += SLI2_IOCB_RSP_R3XTRA_ENTRIES;\n\n\t \n\tpring->iotag_max = 4096;\n\tpring->num_mask = 1;\n\tpring->prt[0].profile = 0;       \n\tpring->prt[0].rctl = phba->cfg_multi_ring_rctl;\n\tpring->prt[0].type = phba->cfg_multi_ring_type;\n\tpring->prt[0].lpfc_sli_rcv_unsol_event = NULL;\n\treturn 0;\n}\n\nstatic void\nlpfc_sli_post_recovery_event(struct lpfc_hba *phba,\n\t\t\t     struct lpfc_nodelist *ndlp)\n{\n\tunsigned long iflags;\n\tstruct lpfc_work_evt  *evtp = &ndlp->recovery_evt;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tif (!list_empty(&evtp->evt_listp)) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\treturn;\n\t}\n\n\t \n\tevtp->evt_arg1  = lpfc_nlp_get(ndlp);\n\tif (!evtp->evt_arg1) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\treturn;\n\t}\n\tevtp->evt = LPFC_EVT_RECOVER_PORT;\n\tlist_add_tail(&evtp->evt_listp, &phba->work_list);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\tlpfc_worker_wake_up(phba);\n}\n\n \nstatic void\nlpfc_sli_abts_err_handler(struct lpfc_hba *phba,\n\t\t\t  struct lpfc_iocbq *iocbq)\n{\n\tstruct lpfc_nodelist *ndlp = NULL;\n\tuint16_t rpi = 0, vpi = 0;\n\tstruct lpfc_vport *vport = NULL;\n\n\t \n\tvpi = iocbq->iocb.un.asyncstat.sub_ctxt_tag;\n\trpi = iocbq->iocb.ulpContext;\n\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\"3092 Port generated ABTS async event \"\n\t\t\t\"on vpi %d rpi %d status 0x%x\\n\",\n\t\t\tvpi, rpi, iocbq->iocb.ulpStatus);\n\n\tvport = lpfc_find_vport_by_vpid(phba, vpi);\n\tif (!vport)\n\t\tgoto err_exit;\n\tndlp = lpfc_findnode_rpi(vport, rpi);\n\tif (!ndlp)\n\t\tgoto err_exit;\n\n\tif (iocbq->iocb.ulpStatus == IOSTAT_LOCAL_REJECT)\n\t\tlpfc_sli_abts_recover_port(vport, ndlp);\n\treturn;\n\n err_exit:\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"3095 Event Context not found, no \"\n\t\t\t\"action on vpi %d rpi %d status 0x%x, reason 0x%x\\n\",\n\t\t\tvpi, rpi, iocbq->iocb.ulpStatus,\n\t\t\tiocbq->iocb.ulpContext);\n}\n\n \nvoid\nlpfc_sli4_abts_err_handler(struct lpfc_hba *phba,\n\t\t\t   struct lpfc_nodelist *ndlp,\n\t\t\t   struct sli4_wcqe_xri_aborted *axri)\n{\n\tuint32_t ext_status = 0;\n\n\tif (!ndlp) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3115 Node Context not found, driver \"\n\t\t\t\t\"ignoring abts err event\\n\");\n\t\treturn;\n\t}\n\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\"3116 Port generated FCP XRI ABORT event on \"\n\t\t\t\"vpi %d rpi %d xri x%x status 0x%x parameter x%x\\n\",\n\t\t\tndlp->vport->vpi, phba->sli4_hba.rpi_ids[ndlp->nlp_rpi],\n\t\t\tbf_get(lpfc_wcqe_xa_xri, axri),\n\t\t\tbf_get(lpfc_wcqe_xa_status, axri),\n\t\t\taxri->parameter);\n\n\t \n\text_status = axri->parameter & IOERR_PARAM_MASK;\n\tif ((bf_get(lpfc_wcqe_xa_status, axri) == IOSTAT_LOCAL_REJECT) &&\n\t    ((ext_status == IOERR_SEQUENCE_TIMEOUT) || (ext_status == 0)))\n\t\tlpfc_sli_post_recovery_event(phba, ndlp);\n}\n\n \nstatic void\nlpfc_sli_async_event_handler(struct lpfc_hba * phba,\n\tstruct lpfc_sli_ring * pring, struct lpfc_iocbq * iocbq)\n{\n\tIOCB_t *icmd;\n\tuint16_t evt_code;\n\tstruct temp_event temp_event_data;\n\tstruct Scsi_Host *shost;\n\tuint32_t *iocb_w;\n\n\ticmd = &iocbq->iocb;\n\tevt_code = icmd->un.asyncstat.evt_code;\n\n\tswitch (evt_code) {\n\tcase ASYNC_TEMP_WARN:\n\tcase ASYNC_TEMP_SAFE:\n\t\ttemp_event_data.data = (uint32_t) icmd->ulpContext;\n\t\ttemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\n\t\tif (evt_code == ASYNC_TEMP_WARN) {\n\t\t\ttemp_event_data.event_code = LPFC_THRESHOLD_TEMP;\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0347 Adapter is very hot, please take \"\n\t\t\t\t\"corrective action. temperature : %d Celsius\\n\",\n\t\t\t\t(uint32_t) icmd->ulpContext);\n\t\t} else {\n\t\t\ttemp_event_data.event_code = LPFC_NORMAL_TEMP;\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0340 Adapter temperature is OK now. \"\n\t\t\t\t\"temperature : %d Celsius\\n\",\n\t\t\t\t(uint32_t) icmd->ulpContext);\n\t\t}\n\n\t\t \n\t\tshost = lpfc_shost_from_vport(phba->pport);\n\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\tsizeof(temp_event_data), (char *) &temp_event_data,\n\t\t\tLPFC_NL_VENDOR_ID);\n\t\tbreak;\n\tcase ASYNC_STATUS_CN:\n\t\tlpfc_sli_abts_err_handler(phba, iocbq);\n\t\tbreak;\n\tdefault:\n\t\tiocb_w = (uint32_t *) icmd;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0346 Ring %d handler: unexpected ASYNC_STATUS\"\n\t\t\t\" evt_code 0x%x\\n\"\n\t\t\t\"W0  0x%08x W1  0x%08x W2  0x%08x W3  0x%08x\\n\"\n\t\t\t\"W4  0x%08x W5  0x%08x W6  0x%08x W7  0x%08x\\n\"\n\t\t\t\"W8  0x%08x W9  0x%08x W10 0x%08x W11 0x%08x\\n\"\n\t\t\t\"W12 0x%08x W13 0x%08x W14 0x%08x W15 0x%08x\\n\",\n\t\t\tpring->ringno, icmd->un.asyncstat.evt_code,\n\t\t\tiocb_w[0], iocb_w[1], iocb_w[2], iocb_w[3],\n\t\t\tiocb_w[4], iocb_w[5], iocb_w[6], iocb_w[7],\n\t\t\tiocb_w[8], iocb_w[9], iocb_w[10], iocb_w[11],\n\t\t\tiocb_w[12], iocb_w[13], iocb_w[14], iocb_w[15]);\n\n\t\tbreak;\n\t}\n}\n\n\n \nint\nlpfc_sli4_setup(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli_ring *pring;\n\n\tpring = phba->sli4_hba.els_wq->pring;\n\tpring->num_mask = LPFC_MAX_RING_MASK;\n\tpring->prt[0].profile = 0;\t \n\tpring->prt[0].rctl = FC_RCTL_ELS_REQ;\n\tpring->prt[0].type = FC_TYPE_ELS;\n\tpring->prt[0].lpfc_sli_rcv_unsol_event =\n\t    lpfc_els_unsol_event;\n\tpring->prt[1].profile = 0;\t \n\tpring->prt[1].rctl = FC_RCTL_ELS_REP;\n\tpring->prt[1].type = FC_TYPE_ELS;\n\tpring->prt[1].lpfc_sli_rcv_unsol_event =\n\t    lpfc_els_unsol_event;\n\tpring->prt[2].profile = 0;\t \n\t \n\tpring->prt[2].rctl = FC_RCTL_DD_UNSOL_CTL;\n\t \n\tpring->prt[2].type = FC_TYPE_CT;\n\tpring->prt[2].lpfc_sli_rcv_unsol_event =\n\t    lpfc_ct_unsol_event;\n\tpring->prt[3].profile = 0;\t \n\t \n\tpring->prt[3].rctl = FC_RCTL_DD_SOL_CTL;\n\t \n\tpring->prt[3].type = FC_TYPE_CT;\n\tpring->prt[3].lpfc_sli_rcv_unsol_event =\n\t    lpfc_ct_unsol_event;\n\treturn 0;\n}\n\n \nint\nlpfc_sli_setup(struct lpfc_hba *phba)\n{\n\tint i, totiocbsize = 0;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_sli_ring *pring;\n\n\tpsli->num_rings = MAX_SLI3_CONFIGURED_RINGS;\n\tpsli->sli_flag = 0;\n\n\tpsli->iocbq_lookup = NULL;\n\tpsli->iocbq_lookup_len = 0;\n\tpsli->last_iotag = 0;\n\n\tfor (i = 0; i < psli->num_rings; i++) {\n\t\tpring = &psli->sli3_ring[i];\n\t\tswitch (i) {\n\t\tcase LPFC_FCP_RING:\t \n\t\t\t \n\t\t\tpring->sli.sli3.numCiocb = SLI2_IOCB_CMD_R0_ENTRIES;\n\t\t\tpring->sli.sli3.numRiocb = SLI2_IOCB_RSP_R0_ENTRIES;\n\t\t\tpring->sli.sli3.numCiocb +=\n\t\t\t\tSLI2_IOCB_CMD_R1XTRA_ENTRIES;\n\t\t\tpring->sli.sli3.numRiocb +=\n\t\t\t\tSLI2_IOCB_RSP_R1XTRA_ENTRIES;\n\t\t\tpring->sli.sli3.numCiocb +=\n\t\t\t\tSLI2_IOCB_CMD_R3XTRA_ENTRIES;\n\t\t\tpring->sli.sli3.numRiocb +=\n\t\t\t\tSLI2_IOCB_RSP_R3XTRA_ENTRIES;\n\t\t\tpring->sli.sli3.sizeCiocb = (phba->sli_rev == 3) ?\n\t\t\t\t\t\t\tSLI3_IOCB_CMD_SIZE :\n\t\t\t\t\t\t\tSLI2_IOCB_CMD_SIZE;\n\t\t\tpring->sli.sli3.sizeRiocb = (phba->sli_rev == 3) ?\n\t\t\t\t\t\t\tSLI3_IOCB_RSP_SIZE :\n\t\t\t\t\t\t\tSLI2_IOCB_RSP_SIZE;\n\t\t\tpring->iotag_ctr = 0;\n\t\t\tpring->iotag_max =\n\t\t\t    (phba->cfg_hba_queue_depth * 2);\n\t\t\tpring->fast_iotag = pring->iotag_max;\n\t\t\tpring->num_mask = 0;\n\t\t\tbreak;\n\t\tcase LPFC_EXTRA_RING:\t \n\t\t\t \n\t\t\tpring->sli.sli3.numCiocb = SLI2_IOCB_CMD_R1_ENTRIES;\n\t\t\tpring->sli.sli3.numRiocb = SLI2_IOCB_RSP_R1_ENTRIES;\n\t\t\tpring->sli.sli3.sizeCiocb = (phba->sli_rev == 3) ?\n\t\t\t\t\t\t\tSLI3_IOCB_CMD_SIZE :\n\t\t\t\t\t\t\tSLI2_IOCB_CMD_SIZE;\n\t\t\tpring->sli.sli3.sizeRiocb = (phba->sli_rev == 3) ?\n\t\t\t\t\t\t\tSLI3_IOCB_RSP_SIZE :\n\t\t\t\t\t\t\tSLI2_IOCB_RSP_SIZE;\n\t\t\tpring->iotag_max = phba->cfg_hba_queue_depth;\n\t\t\tpring->num_mask = 0;\n\t\t\tbreak;\n\t\tcase LPFC_ELS_RING:\t \n\t\t\t \n\t\t\tpring->sli.sli3.numCiocb = SLI2_IOCB_CMD_R2_ENTRIES;\n\t\t\tpring->sli.sli3.numRiocb = SLI2_IOCB_RSP_R2_ENTRIES;\n\t\t\tpring->sli.sli3.sizeCiocb = (phba->sli_rev == 3) ?\n\t\t\t\t\t\t\tSLI3_IOCB_CMD_SIZE :\n\t\t\t\t\t\t\tSLI2_IOCB_CMD_SIZE;\n\t\t\tpring->sli.sli3.sizeRiocb = (phba->sli_rev == 3) ?\n\t\t\t\t\t\t\tSLI3_IOCB_RSP_SIZE :\n\t\t\t\t\t\t\tSLI2_IOCB_RSP_SIZE;\n\t\t\tpring->fast_iotag = 0;\n\t\t\tpring->iotag_ctr = 0;\n\t\t\tpring->iotag_max = 4096;\n\t\t\tpring->lpfc_sli_rcv_async_status =\n\t\t\t\tlpfc_sli_async_event_handler;\n\t\t\tpring->num_mask = LPFC_MAX_RING_MASK;\n\t\t\tpring->prt[0].profile = 0;\t \n\t\t\tpring->prt[0].rctl = FC_RCTL_ELS_REQ;\n\t\t\tpring->prt[0].type = FC_TYPE_ELS;\n\t\t\tpring->prt[0].lpfc_sli_rcv_unsol_event =\n\t\t\t    lpfc_els_unsol_event;\n\t\t\tpring->prt[1].profile = 0;\t \n\t\t\tpring->prt[1].rctl = FC_RCTL_ELS_REP;\n\t\t\tpring->prt[1].type = FC_TYPE_ELS;\n\t\t\tpring->prt[1].lpfc_sli_rcv_unsol_event =\n\t\t\t    lpfc_els_unsol_event;\n\t\t\tpring->prt[2].profile = 0;\t \n\t\t\t \n\t\t\tpring->prt[2].rctl = FC_RCTL_DD_UNSOL_CTL;\n\t\t\t \n\t\t\tpring->prt[2].type = FC_TYPE_CT;\n\t\t\tpring->prt[2].lpfc_sli_rcv_unsol_event =\n\t\t\t    lpfc_ct_unsol_event;\n\t\t\tpring->prt[3].profile = 0;\t \n\t\t\t \n\t\t\tpring->prt[3].rctl = FC_RCTL_DD_SOL_CTL;\n\t\t\t \n\t\t\tpring->prt[3].type = FC_TYPE_CT;\n\t\t\tpring->prt[3].lpfc_sli_rcv_unsol_event =\n\t\t\t    lpfc_ct_unsol_event;\n\t\t\tbreak;\n\t\t}\n\t\ttotiocbsize += (pring->sli.sli3.numCiocb *\n\t\t\tpring->sli.sli3.sizeCiocb) +\n\t\t\t(pring->sli.sli3.numRiocb * pring->sli.sli3.sizeRiocb);\n\t}\n\tif (totiocbsize > MAX_SLIM_IOCB_SIZE) {\n\t\t \n\t\tprintk(KERN_ERR \"%d:0462 Too many cmd / rsp ring entries in \"\n\t\t       \"SLI2 SLIM Data: x%x x%lx\\n\",\n\t\t       phba->brd_no, totiocbsize,\n\t\t       (unsigned long) MAX_SLIM_IOCB_SIZE);\n\t}\n\tif (phba->cfg_multi_ring_support == 2)\n\t\tlpfc_extra_ring_setup(phba);\n\n\treturn 0;\n}\n\n \nvoid\nlpfc_sli4_queue_init(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli;\n\tstruct lpfc_sli_ring *pring;\n\tint i;\n\n\tpsli = &phba->sli;\n\tspin_lock_irq(&phba->hbalock);\n\tINIT_LIST_HEAD(&psli->mboxq);\n\tINIT_LIST_HEAD(&psli->mboxq_cmpl);\n\t \n\tfor (i = 0; i < phba->cfg_hdw_queue; i++) {\n\t\tpring = phba->sli4_hba.hdwq[i].io_wq->pring;\n\t\tpring->flag = 0;\n\t\tpring->ringno = LPFC_FCP_RING;\n\t\tpring->txcmplq_cnt = 0;\n\t\tINIT_LIST_HEAD(&pring->txq);\n\t\tINIT_LIST_HEAD(&pring->txcmplq);\n\t\tINIT_LIST_HEAD(&pring->iocb_continueq);\n\t\tspin_lock_init(&pring->ring_lock);\n\t}\n\tpring = phba->sli4_hba.els_wq->pring;\n\tpring->flag = 0;\n\tpring->ringno = LPFC_ELS_RING;\n\tpring->txcmplq_cnt = 0;\n\tINIT_LIST_HEAD(&pring->txq);\n\tINIT_LIST_HEAD(&pring->txcmplq);\n\tINIT_LIST_HEAD(&pring->iocb_continueq);\n\tspin_lock_init(&pring->ring_lock);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tpring = phba->sli4_hba.nvmels_wq->pring;\n\t\tpring->flag = 0;\n\t\tpring->ringno = LPFC_ELS_RING;\n\t\tpring->txcmplq_cnt = 0;\n\t\tINIT_LIST_HEAD(&pring->txq);\n\t\tINIT_LIST_HEAD(&pring->txcmplq);\n\t\tINIT_LIST_HEAD(&pring->iocb_continueq);\n\t\tspin_lock_init(&pring->ring_lock);\n\t}\n\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n \nvoid\nlpfc_sli_queue_init(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli;\n\tstruct lpfc_sli_ring *pring;\n\tint i;\n\n\tpsli = &phba->sli;\n\tspin_lock_irq(&phba->hbalock);\n\tINIT_LIST_HEAD(&psli->mboxq);\n\tINIT_LIST_HEAD(&psli->mboxq_cmpl);\n\t \n\tfor (i = 0; i < psli->num_rings; i++) {\n\t\tpring = &psli->sli3_ring[i];\n\t\tpring->ringno = i;\n\t\tpring->sli.sli3.next_cmdidx  = 0;\n\t\tpring->sli.sli3.local_getidx = 0;\n\t\tpring->sli.sli3.cmdidx = 0;\n\t\tINIT_LIST_HEAD(&pring->iocb_continueq);\n\t\tINIT_LIST_HEAD(&pring->iocb_continue_saveq);\n\t\tINIT_LIST_HEAD(&pring->postbufq);\n\t\tpring->flag = 0;\n\t\tINIT_LIST_HEAD(&pring->txq);\n\t\tINIT_LIST_HEAD(&pring->txcmplq);\n\t\tspin_lock_init(&pring->ring_lock);\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n \nstatic void\nlpfc_sli_mbox_sys_flush(struct lpfc_hba *phba)\n{\n\tLIST_HEAD(completions);\n\tstruct lpfc_sli *psli = &phba->sli;\n\tLPFC_MBOXQ_t *pmb;\n\tunsigned long iflag;\n\n\t \n\tlocal_bh_disable();\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\n\t \n\tlist_splice_init(&phba->sli.mboxq, &completions);\n\t \n\tif (psli->mbox_active) {\n\t\tlist_add_tail(&psli->mbox_active->list, &completions);\n\t\tpsli->mbox_active = NULL;\n\t\tpsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t}\n\t \n\tlist_splice_init(&phba->sli.mboxq_cmpl, &completions);\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\n\t \n\tlocal_bh_enable();\n\n\t \n\twhile (!list_empty(&completions)) {\n\t\tlist_remove_head(&completions, pmb, LPFC_MBOXQ_t, list);\n\t\tpmb->u.mb.mbxStatus = MBX_NOT_FINISHED;\n\t\tif (pmb->mbox_cmpl)\n\t\t\tpmb->mbox_cmpl(phba, pmb);\n\t}\n}\n\n \nint\nlpfc_sli_host_down(struct lpfc_vport *vport)\n{\n\tLIST_HEAD(completions);\n\tstruct lpfc_hba *phba = vport->phba;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_queue *qp = NULL;\n\tstruct lpfc_sli_ring *pring;\n\tstruct lpfc_iocbq *iocb, *next_iocb;\n\tint i;\n\tunsigned long flags = 0;\n\tuint16_t prev_pring_flag;\n\n\tlpfc_cleanup_discovery_resources(vport);\n\n\tspin_lock_irqsave(&phba->hbalock, flags);\n\n\t \n\tif (phba->sli_rev != LPFC_SLI_REV4) {\n\t\tfor (i = 0; i < psli->num_rings; i++) {\n\t\t\tpring = &psli->sli3_ring[i];\n\t\t\tprev_pring_flag = pring->flag;\n\t\t\t \n\t\t\tif (pring->ringno == LPFC_ELS_RING) {\n\t\t\t\tpring->flag |= LPFC_DEFERRED_RING_EVENT;\n\t\t\t\t \n\t\t\t\tset_bit(LPFC_DATA_READY, &phba->data_flags);\n\t\t\t}\n\t\t\tlist_for_each_entry_safe(iocb, next_iocb,\n\t\t\t\t\t\t &pring->txq, list) {\n\t\t\t\tif (iocb->vport != vport)\n\t\t\t\t\tcontinue;\n\t\t\t\tlist_move_tail(&iocb->list, &completions);\n\t\t\t}\n\t\t\tlist_for_each_entry_safe(iocb, next_iocb,\n\t\t\t\t\t\t &pring->txcmplq, list) {\n\t\t\t\tif (iocb->vport != vport)\n\t\t\t\t\tcontinue;\n\t\t\t\tlpfc_sli_issue_abort_iotag(phba, pring, iocb,\n\t\t\t\t\t\t\t   NULL);\n\t\t\t}\n\t\t\tpring->flag = prev_pring_flag;\n\t\t}\n\t} else {\n\t\tlist_for_each_entry(qp, &phba->sli4_hba.lpfc_wq_list, wq_list) {\n\t\t\tpring = qp->pring;\n\t\t\tif (!pring)\n\t\t\t\tcontinue;\n\t\t\tif (pring == phba->sli4_hba.els_wq->pring) {\n\t\t\t\tpring->flag |= LPFC_DEFERRED_RING_EVENT;\n\t\t\t\t \n\t\t\t\tset_bit(LPFC_DATA_READY, &phba->data_flags);\n\t\t\t}\n\t\t\tprev_pring_flag = pring->flag;\n\t\t\tspin_lock(&pring->ring_lock);\n\t\t\tlist_for_each_entry_safe(iocb, next_iocb,\n\t\t\t\t\t\t &pring->txq, list) {\n\t\t\t\tif (iocb->vport != vport)\n\t\t\t\t\tcontinue;\n\t\t\t\tlist_move_tail(&iocb->list, &completions);\n\t\t\t}\n\t\t\tspin_unlock(&pring->ring_lock);\n\t\t\tlist_for_each_entry_safe(iocb, next_iocb,\n\t\t\t\t\t\t &pring->txcmplq, list) {\n\t\t\t\tif (iocb->vport != vport)\n\t\t\t\t\tcontinue;\n\t\t\t\tlpfc_sli_issue_abort_iotag(phba, pring, iocb,\n\t\t\t\t\t\t\t   NULL);\n\t\t\t}\n\t\t\tpring->flag = prev_pring_flag;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, flags);\n\n\t \n\tlpfc_issue_hb_tmo(phba);\n\n\t \n\tlpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,\n\t\t\t      IOERR_SLI_DOWN);\n\treturn 1;\n}\n\n \nint\nlpfc_sli_hba_down(struct lpfc_hba *phba)\n{\n\tLIST_HEAD(completions);\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_queue *qp = NULL;\n\tstruct lpfc_sli_ring *pring;\n\tstruct lpfc_dmabuf *buf_ptr;\n\tunsigned long flags = 0;\n\tint i;\n\n\t \n\tlpfc_sli_mbox_sys_shutdown(phba, LPFC_MBX_WAIT);\n\n\tlpfc_hba_down_prep(phba);\n\n\t \n\tlocal_bh_disable();\n\n\tlpfc_fabric_abort_hba(phba);\n\n\tspin_lock_irqsave(&phba->hbalock, flags);\n\n\t \n\tif (phba->sli_rev != LPFC_SLI_REV4) {\n\t\tfor (i = 0; i < psli->num_rings; i++) {\n\t\t\tpring = &psli->sli3_ring[i];\n\t\t\t \n\t\t\tif (pring->ringno == LPFC_ELS_RING) {\n\t\t\t\tpring->flag |= LPFC_DEFERRED_RING_EVENT;\n\t\t\t\t \n\t\t\t\tset_bit(LPFC_DATA_READY, &phba->data_flags);\n\t\t\t}\n\t\t\tlist_splice_init(&pring->txq, &completions);\n\t\t}\n\t} else {\n\t\tlist_for_each_entry(qp, &phba->sli4_hba.lpfc_wq_list, wq_list) {\n\t\t\tpring = qp->pring;\n\t\t\tif (!pring)\n\t\t\t\tcontinue;\n\t\t\tspin_lock(&pring->ring_lock);\n\t\t\tlist_splice_init(&pring->txq, &completions);\n\t\t\tspin_unlock(&pring->ring_lock);\n\t\t\tif (pring == phba->sli4_hba.els_wq->pring) {\n\t\t\t\tpring->flag |= LPFC_DEFERRED_RING_EVENT;\n\t\t\t\t \n\t\t\t\tset_bit(LPFC_DATA_READY, &phba->data_flags);\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, flags);\n\n\t \n\tlpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,\n\t\t\t      IOERR_SLI_DOWN);\n\n\tspin_lock_irqsave(&phba->hbalock, flags);\n\tlist_splice_init(&phba->elsbuf, &completions);\n\tphba->elsbuf_cnt = 0;\n\tphba->elsbuf_prev_cnt = 0;\n\tspin_unlock_irqrestore(&phba->hbalock, flags);\n\n\twhile (!list_empty(&completions)) {\n\t\tlist_remove_head(&completions, buf_ptr,\n\t\t\tstruct lpfc_dmabuf, list);\n\t\tlpfc_mbuf_free(phba, buf_ptr->virt, buf_ptr->phys);\n\t\tkfree(buf_ptr);\n\t}\n\n\t \n\tlocal_bh_enable();\n\n\t \n\tdel_timer_sync(&psli->mbox_tmo);\n\n\tspin_lock_irqsave(&phba->pport->work_port_lock, flags);\n\tphba->pport->work_port_events &= ~WORKER_MBOX_TMO;\n\tspin_unlock_irqrestore(&phba->pport->work_port_lock, flags);\n\n\treturn 1;\n}\n\n \nvoid\nlpfc_sli_pcimem_bcopy(void *srcp, void *destp, uint32_t cnt)\n{\n\tuint32_t *src = srcp;\n\tuint32_t *dest = destp;\n\tuint32_t ldata;\n\tint i;\n\n\tfor (i = 0; i < (int)cnt; i += sizeof (uint32_t)) {\n\t\tldata = *src;\n\t\tldata = le32_to_cpu(ldata);\n\t\t*dest = ldata;\n\t\tsrc++;\n\t\tdest++;\n\t}\n}\n\n\n \nvoid\nlpfc_sli_bemem_bcopy(void *srcp, void *destp, uint32_t cnt)\n{\n\tuint32_t *src = srcp;\n\tuint32_t *dest = destp;\n\tuint32_t ldata;\n\tint i;\n\n\tfor (i = 0; i < (int)cnt; i += sizeof(uint32_t)) {\n\t\tldata = *src;\n\t\tldata = be32_to_cpu(ldata);\n\t\t*dest = ldata;\n\t\tsrc++;\n\t\tdest++;\n\t}\n}\n\n \nint\nlpfc_sli_ringpostbuf_put(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t\t struct lpfc_dmabuf *mp)\n{\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tlist_add_tail(&mp->list, &pring->postbufq);\n\tpring->postbufq_cnt++;\n\tspin_unlock_irq(&phba->hbalock);\n\treturn 0;\n}\n\n \nuint32_t\nlpfc_sli_get_buffer_tag(struct lpfc_hba *phba)\n{\n\tspin_lock_irq(&phba->hbalock);\n\tphba->buffer_tag_count++;\n\t \n\tphba->buffer_tag_count |= QUE_BUFTAG_BIT;\n\tspin_unlock_irq(&phba->hbalock);\n\treturn phba->buffer_tag_count;\n}\n\n \nstruct lpfc_dmabuf *\nlpfc_sli_ring_taggedbuf_get(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t\tuint32_t tag)\n{\n\tstruct lpfc_dmabuf *mp, *next_mp;\n\tstruct list_head *slp = &pring->postbufq;\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tlist_for_each_entry_safe(mp, next_mp, &pring->postbufq, list) {\n\t\tif (mp->buffer_tag == tag) {\n\t\t\tlist_del_init(&mp->list);\n\t\t\tpring->postbufq_cnt--;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\treturn mp;\n\t\t}\n\t}\n\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0402 Cannot find virtual addr for buffer tag on \"\n\t\t\t\"ring %d Data x%lx x%px x%px x%x\\n\",\n\t\t\tpring->ringno, (unsigned long) tag,\n\t\t\tslp->next, slp->prev, pring->postbufq_cnt);\n\n\treturn NULL;\n}\n\n \nstruct lpfc_dmabuf *\nlpfc_sli_ringpostbuf_get(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t\t dma_addr_t phys)\n{\n\tstruct lpfc_dmabuf *mp, *next_mp;\n\tstruct list_head *slp = &pring->postbufq;\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tlist_for_each_entry_safe(mp, next_mp, &pring->postbufq, list) {\n\t\tif (mp->phys == phys) {\n\t\t\tlist_del_init(&mp->list);\n\t\t\tpring->postbufq_cnt--;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\treturn mp;\n\t\t}\n\t}\n\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0410 Cannot find virtual addr for mapped buf on \"\n\t\t\t\"ring %d Data x%llx x%px x%px x%x\\n\",\n\t\t\tpring->ringno, (unsigned long long)phys,\n\t\t\tslp->next, slp->prev, pring->postbufq_cnt);\n\treturn NULL;\n}\n\n \nstatic void\nlpfc_sli_abort_els_cmpl(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,\n\t\t\tstruct lpfc_iocbq *rspiocb)\n{\n\tu32 ulp_status = get_job_ulpstatus(phba, rspiocb);\n\tu32 ulp_word4 = get_job_word4(phba, rspiocb);\n\tu8 cmnd = get_job_cmnd(phba, cmdiocb);\n\n\tif (ulp_status) {\n\t\t \n\t\tif (phba->sli_rev < LPFC_SLI_REV4) {\n\t\t\tif (cmnd == CMD_ABORT_XRI_CX &&\n\t\t\t    ulp_status == IOSTAT_LOCAL_REJECT &&\n\t\t\t    ulp_word4 == IOERR_ABORT_REQUESTED) {\n\t\t\t\tgoto release_iocb;\n\t\t\t}\n\t\t}\n\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_ELS | LOG_SLI,\n\t\t\t\t\"0327 Cannot abort els iocb x%px \"\n\t\t\t\t\"with io cmd xri %x abort tag : x%x, \"\n\t\t\t\t\"abort status %x abort code %x\\n\",\n\t\t\t\tcmdiocb, get_job_abtsiotag(phba, cmdiocb),\n\t\t\t\t(phba->sli_rev == LPFC_SLI_REV4) ?\n\t\t\t\tget_wqe_reqtag(cmdiocb) :\n\t\t\t\tcmdiocb->iocb.un.acxri.abortContextTag,\n\t\t\t\tulp_status, ulp_word4);\n\n\t}\nrelease_iocb:\n\tlpfc_sli_release_iocbq(phba, cmdiocb);\n\treturn;\n}\n\n \nvoid\nlpfc_ignore_els_cmpl(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,\n\t\t     struct lpfc_iocbq *rspiocb)\n{\n\tstruct lpfc_nodelist *ndlp = cmdiocb->ndlp;\n\tIOCB_t *irsp;\n\tLPFC_MBOXQ_t *mbox;\n\tu32 ulp_command, ulp_status, ulp_word4, iotag;\n\n\tulp_command = get_job_cmnd(phba, cmdiocb);\n\tulp_status = get_job_ulpstatus(phba, rspiocb);\n\tulp_word4 = get_job_word4(phba, rspiocb);\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tiotag = get_wqe_reqtag(cmdiocb);\n\t} else {\n\t\tirsp = &rspiocb->iocb;\n\t\tiotag = irsp->ulpIoTag;\n\n\t\t \n\t\tif (cmdiocb->context_un.mbox) {\n\t\t\tmbox = cmdiocb->context_un.mbox;\n\t\t\tlpfc_mbox_rsrc_cleanup(phba, mbox, MBOX_THD_UNLOCKED);\n\t\t\tcmdiocb->context_un.mbox = NULL;\n\t\t}\n\t}\n\n\t \n\tlpfc_printf_log(phba, KERN_INFO, LOG_ELS,\n\t\t\t\"0139 Ignoring ELS cmd code x%x completion Data: \"\n\t\t\t\"x%x x%x x%x x%px\\n\",\n\t\t\tulp_command, ulp_status, ulp_word4, iotag,\n\t\t\tcmdiocb->ndlp);\n\t \n\tif (ulp_command == CMD_GEN_REQUEST64_CR)\n\t\tlpfc_ct_free_iocb(phba, cmdiocb);\n\telse\n\t\tlpfc_els_free_iocb(phba, cmdiocb);\n\n\tlpfc_nlp_put(ndlp);\n}\n\n \nint\nlpfc_sli_issue_abort_iotag(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\n\t\t\t   struct lpfc_iocbq *cmdiocb, void *cmpl)\n{\n\tstruct lpfc_vport *vport = cmdiocb->vport;\n\tstruct lpfc_iocbq *abtsiocbp;\n\tint retval = IOCB_ERROR;\n\tunsigned long iflags;\n\tstruct lpfc_nodelist *ndlp = NULL;\n\tu32 ulp_command = get_job_cmnd(phba, cmdiocb);\n\tu16 ulp_context, iotag;\n\tbool ia;\n\n\t \n\tif (ulp_command == CMD_ABORT_XRI_WQE ||\n\t    ulp_command == CMD_ABORT_XRI_CN ||\n\t    ulp_command == CMD_CLOSE_XRI_CN ||\n\t    cmdiocb->cmd_flag & LPFC_DRIVER_ABORTED)\n\t\treturn IOCB_ABORTING;\n\n\tif (!pring) {\n\t\tif (cmdiocb->cmd_flag & LPFC_IO_FABRIC)\n\t\t\tcmdiocb->fabric_cmd_cmpl = lpfc_ignore_els_cmpl;\n\t\telse\n\t\t\tcmdiocb->cmd_cmpl = lpfc_ignore_els_cmpl;\n\t\treturn retval;\n\t}\n\n\t \n\tif ((vport->load_flag & FC_UNLOADING) &&\n\t    pring->ringno == LPFC_ELS_RING) {\n\t\tif (cmdiocb->cmd_flag & LPFC_IO_FABRIC)\n\t\t\tcmdiocb->fabric_cmd_cmpl = lpfc_ignore_els_cmpl;\n\t\telse\n\t\t\tcmdiocb->cmd_cmpl = lpfc_ignore_els_cmpl;\n\t\treturn retval;\n\t}\n\n\t \n\tabtsiocbp = __lpfc_sli_get_iocbq(phba);\n\tif (abtsiocbp == NULL)\n\t\treturn IOCB_NORESOURCE;\n\n\t \n\tcmdiocb->cmd_flag |= LPFC_DRIVER_ABORTED;\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tulp_context = cmdiocb->sli4_xritag;\n\t\tiotag = abtsiocbp->iotag;\n\t} else {\n\t\tiotag = cmdiocb->iocb.ulpIoTag;\n\t\tif (pring->ringno == LPFC_ELS_RING) {\n\t\t\tndlp = cmdiocb->ndlp;\n\t\t\tulp_context = ndlp->nlp_rpi;\n\t\t} else {\n\t\t\tulp_context = cmdiocb->iocb.ulpContext;\n\t\t}\n\t}\n\n\tif (phba->link_state < LPFC_LINK_UP ||\n\t    (phba->sli_rev == LPFC_SLI_REV4 &&\n\t     phba->sli4_hba.link_state.status == LPFC_FC_LA_TYPE_LINK_DOWN) ||\n\t    (phba->link_flag & LS_EXTERNAL_LOOPBACK))\n\t\tia = true;\n\telse\n\t\tia = false;\n\n\tlpfc_sli_prep_abort_xri(phba, abtsiocbp, ulp_context, iotag,\n\t\t\t\tcmdiocb->iocb.ulpClass,\n\t\t\t\tLPFC_WQE_CQ_ID_DEFAULT, ia, false);\n\n\tabtsiocbp->vport = vport;\n\n\t \n\tabtsiocbp->hba_wqidx = cmdiocb->hba_wqidx;\n\tif (cmdiocb->cmd_flag & LPFC_IO_FCP)\n\t\tabtsiocbp->cmd_flag |= (LPFC_IO_FCP | LPFC_USE_FCPWQIDX);\n\n\tif (cmdiocb->cmd_flag & LPFC_IO_FOF)\n\t\tabtsiocbp->cmd_flag |= LPFC_IO_FOF;\n\n\tif (cmpl)\n\t\tabtsiocbp->cmd_cmpl = cmpl;\n\telse\n\t\tabtsiocbp->cmd_cmpl = lpfc_sli_abort_els_cmpl;\n\tabtsiocbp->vport = vport;\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tpring = lpfc_sli4_calc_ring(phba, abtsiocbp);\n\t\tif (unlikely(pring == NULL))\n\t\t\tgoto abort_iotag_exit;\n\t\t \n\t\tspin_lock_irqsave(&pring->ring_lock, iflags);\n\t\tretval = __lpfc_sli_issue_iocb(phba, pring->ringno,\n\t\t\tabtsiocbp, 0);\n\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\t} else {\n\t\tretval = __lpfc_sli_issue_iocb(phba, pring->ringno,\n\t\t\tabtsiocbp, 0);\n\t}\n\nabort_iotag_exit:\n\n\tlpfc_printf_vlog(vport, KERN_INFO, LOG_SLI,\n\t\t\t \"0339 Abort IO XRI x%x, Original iotag x%x, \"\n\t\t\t \"abort tag x%x Cmdjob : x%px Abortjob : x%px \"\n\t\t\t \"retval x%x\\n\",\n\t\t\t ulp_context, (phba->sli_rev == LPFC_SLI_REV4) ?\n\t\t\t cmdiocb->iotag : iotag, iotag, cmdiocb, abtsiocbp,\n\t\t\t retval);\n\tif (retval) {\n\t\tcmdiocb->cmd_flag &= ~LPFC_DRIVER_ABORTED;\n\t\t__lpfc_sli_release_iocbq(phba, abtsiocbp);\n\t}\n\n\t \n\treturn retval;\n}\n\n \nvoid\nlpfc_sli_hba_iocb_abort(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_sli_ring *pring;\n\tstruct lpfc_queue *qp = NULL;\n\tint i;\n\n\tif (phba->sli_rev != LPFC_SLI_REV4) {\n\t\tfor (i = 0; i < psli->num_rings; i++) {\n\t\t\tpring = &psli->sli3_ring[i];\n\t\t\tlpfc_sli_abort_iocb_ring(phba, pring);\n\t\t}\n\t\treturn;\n\t}\n\tlist_for_each_entry(qp, &phba->sli4_hba.lpfc_wq_list, wq_list) {\n\t\tpring = qp->pring;\n\t\tif (!pring)\n\t\t\tcontinue;\n\t\tlpfc_sli_abort_iocb_ring(phba, pring);\n\t}\n}\n\n \nstatic int\nlpfc_sli_validate_fcp_iocb_for_abort(struct lpfc_iocbq *iocbq,\n\t\t\t\t     struct lpfc_vport *vport)\n{\n\tu8 ulp_command;\n\n\t \n\tif (!iocbq || iocbq->vport != vport)\n\t\treturn -ENODEV;\n\n\t \n\tulp_command = get_job_cmnd(vport->phba, iocbq);\n\tif (!(iocbq->cmd_flag & LPFC_IO_FCP) ||\n\t    !(iocbq->cmd_flag & LPFC_IO_ON_TXCMPLQ) ||\n\t    (iocbq->cmd_flag & LPFC_DRIVER_ABORTED) ||\n\t    (ulp_command == CMD_ABORT_XRI_CN ||\n\t     ulp_command == CMD_CLOSE_XRI_CN ||\n\t     ulp_command == CMD_ABORT_XRI_WQE))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\n \nstatic int\nlpfc_sli_validate_fcp_iocb(struct lpfc_iocbq *iocbq, struct lpfc_vport *vport,\n\t\t\t   uint16_t tgt_id, uint64_t lun_id,\n\t\t\t   lpfc_ctx_cmd ctx_cmd)\n{\n\tstruct lpfc_io_buf *lpfc_cmd;\n\tint rc = 1;\n\n\tlpfc_cmd = container_of(iocbq, struct lpfc_io_buf, cur_iocbq);\n\n\tif (lpfc_cmd->pCmd == NULL)\n\t\treturn rc;\n\n\tswitch (ctx_cmd) {\n\tcase LPFC_CTX_LUN:\n\t\tif ((lpfc_cmd->rdata) && (lpfc_cmd->rdata->pnode) &&\n\t\t    (lpfc_cmd->rdata->pnode->nlp_sid == tgt_id) &&\n\t\t    (scsilun_to_int(&lpfc_cmd->fcp_cmnd->fcp_lun) == lun_id))\n\t\t\trc = 0;\n\t\tbreak;\n\tcase LPFC_CTX_TGT:\n\t\tif ((lpfc_cmd->rdata) && (lpfc_cmd->rdata->pnode) &&\n\t\t    (lpfc_cmd->rdata->pnode->nlp_sid == tgt_id))\n\t\t\trc = 0;\n\t\tbreak;\n\tcase LPFC_CTX_HOST:\n\t\trc = 0;\n\t\tbreak;\n\tdefault:\n\t\tprintk(KERN_ERR \"%s: Unknown context cmd type, value %d\\n\",\n\t\t\t__func__, ctx_cmd);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}\n\n \nint\nlpfc_sli_sum_iocb(struct lpfc_vport *vport, uint16_t tgt_id, uint64_t lun_id,\n\t\t  lpfc_ctx_cmd ctx_cmd)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tstruct lpfc_iocbq *iocbq;\n\tint sum, i;\n\tunsigned long iflags;\n\tu8 ulp_command;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tfor (i = 1, sum = 0; i <= phba->sli.last_iotag; i++) {\n\t\tiocbq = phba->sli.iocbq_lookup[i];\n\n\t\tif (!iocbq || iocbq->vport != vport)\n\t\t\tcontinue;\n\t\tif (!(iocbq->cmd_flag & LPFC_IO_FCP) ||\n\t\t    !(iocbq->cmd_flag & LPFC_IO_ON_TXCMPLQ))\n\t\t\tcontinue;\n\n\t\t \n\t\tulp_command = get_job_cmnd(phba, iocbq);\n\t\tif (ulp_command == CMD_ABORT_XRI_CN ||\n\t\t    ulp_command == CMD_CLOSE_XRI_CN ||\n\t\t    ulp_command == CMD_ABORT_XRI_WQE) {\n\t\t\tsum++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (lpfc_sli_validate_fcp_iocb(iocbq, vport, tgt_id, lun_id,\n\t\t\t\t\t       ctx_cmd) == 0)\n\t\t\tsum++;\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\treturn sum;\n}\n\n \nvoid\nlpfc_sli_abort_fcp_cmpl(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,\n\t\t\tstruct lpfc_iocbq *rspiocb)\n{\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"3096 ABORT_XRI_CX completing on rpi x%x \"\n\t\t\t\"original iotag x%x, abort cmd iotag x%x \"\n\t\t\t\"status 0x%x, reason 0x%x\\n\",\n\t\t\t(phba->sli_rev == LPFC_SLI_REV4) ?\n\t\t\tcmdiocb->sli4_xritag :\n\t\t\tcmdiocb->iocb.un.acxri.abortContextTag,\n\t\t\tget_job_abtsiotag(phba, cmdiocb),\n\t\t\tcmdiocb->iotag, get_job_ulpstatus(phba, rspiocb),\n\t\t\tget_job_word4(phba, rspiocb));\n\tlpfc_sli_release_iocbq(phba, cmdiocb);\n\treturn;\n}\n\n \nint\nlpfc_sli_abort_iocb(struct lpfc_vport *vport, u16 tgt_id, u64 lun_id,\n\t\t    lpfc_ctx_cmd abort_cmd)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tstruct lpfc_sli_ring *pring = NULL;\n\tstruct lpfc_iocbq *iocbq;\n\tint errcnt = 0, ret_val = 0;\n\tunsigned long iflags;\n\tint i;\n\n\t \n\tif (phba->hba_flag & HBA_IOQ_FLUSH)\n\t\treturn errcnt;\n\n\tfor (i = 1; i <= phba->sli.last_iotag; i++) {\n\t\tiocbq = phba->sli.iocbq_lookup[i];\n\n\t\tif (lpfc_sli_validate_fcp_iocb_for_abort(iocbq, vport))\n\t\t\tcontinue;\n\n\t\tif (lpfc_sli_validate_fcp_iocb(iocbq, vport, tgt_id, lun_id,\n\t\t\t\t\t       abort_cmd) != 0)\n\t\t\tcontinue;\n\n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tif (phba->sli_rev == LPFC_SLI_REV3) {\n\t\t\tpring = &phba->sli.sli3_ring[LPFC_FCP_RING];\n\t\t} else if (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\tpring = lpfc_sli4_calc_ring(phba, iocbq);\n\t\t}\n\t\tret_val = lpfc_sli_issue_abort_iotag(phba, pring, iocbq,\n\t\t\t\t\t\t     lpfc_sli_abort_fcp_cmpl);\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tif (ret_val != IOCB_SUCCESS)\n\t\t\terrcnt++;\n\t}\n\n\treturn errcnt;\n}\n\n \nint\nlpfc_sli_abort_taskmgmt(struct lpfc_vport *vport, struct lpfc_sli_ring *pring,\n\t\t\tuint16_t tgt_id, uint64_t lun_id, lpfc_ctx_cmd cmd)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tstruct lpfc_io_buf *lpfc_cmd;\n\tstruct lpfc_iocbq *abtsiocbq;\n\tstruct lpfc_nodelist *ndlp = NULL;\n\tstruct lpfc_iocbq *iocbq;\n\tint sum, i, ret_val;\n\tunsigned long iflags;\n\tstruct lpfc_sli_ring *pring_s4 = NULL;\n\tu16 ulp_context, iotag, cqid = LPFC_WQE_CQ_ID_DEFAULT;\n\tbool ia;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\n\t \n\tif (phba->hba_flag & HBA_IOQ_FLUSH) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\treturn 0;\n\t}\n\tsum = 0;\n\n\tfor (i = 1; i <= phba->sli.last_iotag; i++) {\n\t\tiocbq = phba->sli.iocbq_lookup[i];\n\n\t\tif (lpfc_sli_validate_fcp_iocb_for_abort(iocbq, vport))\n\t\t\tcontinue;\n\n\t\tif (lpfc_sli_validate_fcp_iocb(iocbq, vport, tgt_id, lun_id,\n\t\t\t\t\t       cmd) != 0)\n\t\t\tcontinue;\n\n\t\t \n\t\tlpfc_cmd = container_of(iocbq, struct lpfc_io_buf, cur_iocbq);\n\t\tspin_lock(&lpfc_cmd->buf_lock);\n\n\t\tif (!lpfc_cmd->pCmd) {\n\t\t\tspin_unlock(&lpfc_cmd->buf_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\tpring_s4 =\n\t\t\t    phba->sli4_hba.hdwq[iocbq->hba_wqidx].io_wq->pring;\n\t\t\tif (!pring_s4) {\n\t\t\t\tspin_unlock(&lpfc_cmd->buf_lock);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t \n\t\t\tspin_lock(&pring_s4->ring_lock);\n\t\t}\n\n\t\t \n\t\tif ((iocbq->cmd_flag & LPFC_DRIVER_ABORTED) ||\n\t\t    !(iocbq->cmd_flag & LPFC_IO_ON_TXCMPLQ)) {\n\t\t\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\t\t\tspin_unlock(&pring_s4->ring_lock);\n\t\t\tspin_unlock(&lpfc_cmd->buf_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tabtsiocbq = __lpfc_sli_get_iocbq(phba);\n\t\tif (!abtsiocbq) {\n\t\t\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\t\t\tspin_unlock(&pring_s4->ring_lock);\n\t\t\tspin_unlock(&lpfc_cmd->buf_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\tiotag = abtsiocbq->iotag;\n\t\t\tulp_context = iocbq->sli4_xritag;\n\t\t\tcqid = lpfc_cmd->hdwq->io_cq_map;\n\t\t} else {\n\t\t\tiotag = iocbq->iocb.ulpIoTag;\n\t\t\tif (pring->ringno == LPFC_ELS_RING) {\n\t\t\t\tndlp = iocbq->ndlp;\n\t\t\t\tulp_context = ndlp->nlp_rpi;\n\t\t\t} else {\n\t\t\t\tulp_context = iocbq->iocb.ulpContext;\n\t\t\t}\n\t\t}\n\n\t\tndlp = lpfc_cmd->rdata->pnode;\n\n\t\tif (lpfc_is_link_up(phba) &&\n\t\t    (ndlp && ndlp->nlp_state == NLP_STE_MAPPED_NODE) &&\n\t\t    !(phba->link_flag & LS_EXTERNAL_LOOPBACK))\n\t\t\tia = false;\n\t\telse\n\t\t\tia = true;\n\n\t\tlpfc_sli_prep_abort_xri(phba, abtsiocbq, ulp_context, iotag,\n\t\t\t\t\tiocbq->iocb.ulpClass, cqid,\n\t\t\t\t\tia, false);\n\n\t\tabtsiocbq->vport = vport;\n\n\t\t \n\t\tabtsiocbq->hba_wqidx = iocbq->hba_wqidx;\n\t\tif (iocbq->cmd_flag & LPFC_IO_FCP)\n\t\t\tabtsiocbq->cmd_flag |= LPFC_USE_FCPWQIDX;\n\t\tif (iocbq->cmd_flag & LPFC_IO_FOF)\n\t\t\tabtsiocbq->cmd_flag |= LPFC_IO_FOF;\n\n\t\t \n\t\tabtsiocbq->cmd_cmpl = lpfc_sli_abort_fcp_cmpl;\n\n\t\t \n\t\tiocbq->cmd_flag |= LPFC_DRIVER_ABORTED;\n\n\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\tret_val = __lpfc_sli_issue_iocb(phba, pring_s4->ringno,\n\t\t\t\t\t\t\tabtsiocbq, 0);\n\t\t\tspin_unlock(&pring_s4->ring_lock);\n\t\t} else {\n\t\t\tret_val = __lpfc_sli_issue_iocb(phba, pring->ringno,\n\t\t\t\t\t\t\tabtsiocbq, 0);\n\t\t}\n\n\t\tspin_unlock(&lpfc_cmd->buf_lock);\n\n\t\tif (ret_val == IOCB_ERROR)\n\t\t\t__lpfc_sli_release_iocbq(phba, abtsiocbq);\n\t\telse\n\t\t\tsum++;\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn sum;\n}\n\n \nstatic void\nlpfc_sli_wake_iocb_wait(struct lpfc_hba *phba,\n\t\t\tstruct lpfc_iocbq *cmdiocbq,\n\t\t\tstruct lpfc_iocbq *rspiocbq)\n{\n\twait_queue_head_t *pdone_q;\n\tunsigned long iflags;\n\tstruct lpfc_io_buf *lpfc_cmd;\n\tsize_t offset = offsetof(struct lpfc_iocbq, wqe);\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tif (cmdiocbq->cmd_flag & LPFC_IO_WAKE_TMO) {\n\n\t\t \n\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tcmdiocbq->cmd_cmpl = cmdiocbq->wait_cmd_cmpl;\n\t\tcmdiocbq->wait_cmd_cmpl = NULL;\n\t\tif (cmdiocbq->cmd_cmpl)\n\t\t\tcmdiocbq->cmd_cmpl(phba, cmdiocbq, NULL);\n\t\telse\n\t\t\tlpfc_sli_release_iocbq(phba, cmdiocbq);\n\t\treturn;\n\t}\n\n\t \n\tcmdiocbq->cmd_flag |= LPFC_IO_WAKE;\n\tif (cmdiocbq->rsp_iocb && rspiocbq)\n\t\tmemcpy((char *)cmdiocbq->rsp_iocb + offset,\n\t\t       (char *)rspiocbq + offset, sizeof(*rspiocbq) - offset);\n\n\t \n\tif ((cmdiocbq->cmd_flag & LPFC_IO_FCP) &&\n\t    !(cmdiocbq->cmd_flag & LPFC_IO_LIBDFC)) {\n\t\tlpfc_cmd = container_of(cmdiocbq, struct lpfc_io_buf,\n\t\t\t\t\tcur_iocbq);\n\t\tif (rspiocbq && (rspiocbq->cmd_flag & LPFC_EXCHANGE_BUSY))\n\t\t\tlpfc_cmd->flags |= LPFC_SBUF_XBUSY;\n\t\telse\n\t\t\tlpfc_cmd->flags &= ~LPFC_SBUF_XBUSY;\n\t}\n\n\tpdone_q = cmdiocbq->context_un.wait_queue;\n\tif (pdone_q)\n\t\twake_up(pdone_q);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn;\n}\n\n \nstatic int\nlpfc_chk_iocb_flg(struct lpfc_hba *phba,\n\t\t struct lpfc_iocbq *piocbq, uint32_t flag)\n{\n\tunsigned long iflags;\n\tint ret;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tret = piocbq->cmd_flag & flag;\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn ret;\n\n}\n\n \nint\nlpfc_sli_issue_iocb_wait(struct lpfc_hba *phba,\n\t\t\t uint32_t ring_number,\n\t\t\t struct lpfc_iocbq *piocb,\n\t\t\t struct lpfc_iocbq *prspiocbq,\n\t\t\t uint32_t timeout)\n{\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(done_q);\n\tlong timeleft, timeout_req = 0;\n\tint retval = IOCB_SUCCESS;\n\tuint32_t creg_val;\n\tstruct lpfc_iocbq *iocb;\n\tint txq_cnt = 0;\n\tint txcmplq_cnt = 0;\n\tstruct lpfc_sli_ring *pring;\n\tunsigned long iflags;\n\tbool iocb_completed = true;\n\n\tif (phba->sli_rev >= LPFC_SLI_REV4) {\n\t\tlpfc_sli_prep_wqe(phba, piocb);\n\n\t\tpring = lpfc_sli4_calc_ring(phba, piocb);\n\t} else\n\t\tpring = &phba->sli.sli3_ring[ring_number];\n\t \n\tif (prspiocbq) {\n\t\tif (piocb->rsp_iocb)\n\t\t\treturn IOCB_ERROR;\n\t\tpiocb->rsp_iocb = prspiocbq;\n\t}\n\n\tpiocb->wait_cmd_cmpl = piocb->cmd_cmpl;\n\tpiocb->cmd_cmpl = lpfc_sli_wake_iocb_wait;\n\tpiocb->context_un.wait_queue = &done_q;\n\tpiocb->cmd_flag &= ~(LPFC_IO_WAKE | LPFC_IO_WAKE_TMO);\n\n\tif (phba->cfg_poll & DISABLE_FCP_RING_INT) {\n\t\tif (lpfc_readl(phba->HCregaddr, &creg_val))\n\t\t\treturn IOCB_ERROR;\n\t\tcreg_val |= (HC_R0INT_ENA << LPFC_FCP_RING);\n\t\twritel(creg_val, phba->HCregaddr);\n\t\treadl(phba->HCregaddr);  \n\t}\n\n\tretval = lpfc_sli_issue_iocb(phba, ring_number, piocb,\n\t\t\t\t     SLI_IOCB_RET_IOCB);\n\tif (retval == IOCB_SUCCESS) {\n\t\ttimeout_req = msecs_to_jiffies(timeout * 1000);\n\t\ttimeleft = wait_event_timeout(done_q,\n\t\t\t\tlpfc_chk_iocb_flg(phba, piocb, LPFC_IO_WAKE),\n\t\t\t\ttimeout_req);\n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tif (!(piocb->cmd_flag & LPFC_IO_WAKE)) {\n\n\t\t\t \n\n\t\t\tiocb_completed = false;\n\t\t\tpiocb->cmd_flag |= LPFC_IO_WAKE_TMO;\n\t\t}\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tif (iocb_completed) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\t\"0331 IOCB wake signaled\\n\");\n\t\t\t \n\t\t} else if (timeleft == 0) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0338 IOCB wait timeout error - no \"\n\t\t\t\t\t\"wake response Data x%x\\n\", timeout);\n\t\t\tretval = IOCB_TIMEDOUT;\n\t\t} else {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0330 IOCB wake NOT set, \"\n\t\t\t\t\t\"Data x%x x%lx\\n\",\n\t\t\t\t\ttimeout, (timeleft / jiffies));\n\t\t\tretval = IOCB_TIMEDOUT;\n\t\t}\n\t} else if (retval == IOCB_BUSY) {\n\t\tif (phba->cfg_log_verbose & LOG_SLI) {\n\t\t\tlist_for_each_entry(iocb, &pring->txq, list) {\n\t\t\t\ttxq_cnt++;\n\t\t\t}\n\t\t\tlist_for_each_entry(iocb, &pring->txcmplq, list) {\n\t\t\t\ttxcmplq_cnt++;\n\t\t\t}\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"2818 Max IOCBs %d txq cnt %d txcmplq cnt %d\\n\",\n\t\t\t\tphba->iocb_cnt, txq_cnt, txcmplq_cnt);\n\t\t}\n\t\treturn retval;\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"0332 IOCB wait issue failed, Data x%x\\n\",\n\t\t\t\tretval);\n\t\tretval = IOCB_ERROR;\n\t}\n\n\tif (phba->cfg_poll & DISABLE_FCP_RING_INT) {\n\t\tif (lpfc_readl(phba->HCregaddr, &creg_val))\n\t\t\treturn IOCB_ERROR;\n\t\tcreg_val &= ~(HC_R0INT_ENA << LPFC_FCP_RING);\n\t\twritel(creg_val, phba->HCregaddr);\n\t\treadl(phba->HCregaddr);  \n\t}\n\n\tif (prspiocbq)\n\t\tpiocb->rsp_iocb = NULL;\n\n\tpiocb->context_un.wait_queue = NULL;\n\tpiocb->cmd_cmpl = NULL;\n\treturn retval;\n}\n\n \nint\nlpfc_sli_issue_mbox_wait(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmboxq,\n\t\t\t uint32_t timeout)\n{\n\tstruct completion mbox_done;\n\tint retval;\n\tunsigned long flag;\n\n\tpmboxq->mbox_flag &= ~LPFC_MBX_WAKE;\n\t \n\tpmboxq->mbox_cmpl = lpfc_sli_wake_mbox_wait;\n\n\t \n\tinit_completion(&mbox_done);\n\tpmboxq->context3 = &mbox_done;\n\t \n\tretval = lpfc_sli_issue_mbox(phba, pmboxq, MBX_NOWAIT);\n\tif (retval == MBX_BUSY || retval == MBX_SUCCESS) {\n\t\twait_for_completion_timeout(&mbox_done,\n\t\t\t\t\t    msecs_to_jiffies(timeout * 1000));\n\n\t\tspin_lock_irqsave(&phba->hbalock, flag);\n\t\tpmboxq->context3 = NULL;\n\t\t \n\t\tif (pmboxq->mbox_flag & LPFC_MBX_WAKE) {\n\t\t\tretval = MBX_SUCCESS;\n\t\t} else {\n\t\t\tretval = MBX_TIMEOUT;\n\t\t\tpmboxq->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\t\t}\n\t\tspin_unlock_irqrestore(&phba->hbalock, flag);\n\t}\n\treturn retval;\n}\n\n \nvoid\nlpfc_sli_mbox_sys_shutdown(struct lpfc_hba *phba, int mbx_action)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tunsigned long timeout;\n\n\tif (mbx_action == LPFC_MBX_NO_WAIT) {\n\t\t \n\t\tmsleep(100);\n\t\tlpfc_sli_mbox_sys_flush(phba);\n\t\treturn;\n\t}\n\ttimeout = msecs_to_jiffies(LPFC_MBOX_TMO * 1000) + jiffies;\n\n\t \n\tlocal_bh_disable();\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag |= LPFC_SLI_ASYNC_MBX_BLK;\n\n\tif (psli->sli_flag & LPFC_SLI_ACTIVE) {\n\t\t \n\t\tif (phba->sli.mbox_active)\n\t\t\ttimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba,\n\t\t\t\t\t\tphba->sli.mbox_active) *\n\t\t\t\t\t\t1000) + jiffies;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t \n\t\tlocal_bh_enable();\n\n\t\twhile (phba->sli.mbox_active) {\n\t\t\t \n\t\t\tmsleep(2);\n\t\t\tif (time_after(jiffies, timeout))\n\t\t\t\t \n\t\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t \n\t\tlocal_bh_enable();\n\t}\n\n\tlpfc_sli_mbox_sys_flush(phba);\n}\n\n \nstatic int\nlpfc_sli_eratt_read(struct lpfc_hba *phba)\n{\n\tuint32_t ha_copy;\n\n\t \n\tif (lpfc_readl(phba->HAregaddr, &ha_copy))\n\t\tgoto unplug_err;\n\n\tif (ha_copy & HA_ERATT) {\n\t\t \n\t\tif (lpfc_sli_read_hs(phba))\n\t\t\tgoto unplug_err;\n\n\t\t \n\t\tif ((HS_FFER1 & phba->work_hs) &&\n\t\t    ((HS_FFER2 | HS_FFER3 | HS_FFER4 | HS_FFER5 |\n\t\t      HS_FFER6 | HS_FFER7 | HS_FFER8) & phba->work_hs)) {\n\t\t\tphba->hba_flag |= DEFER_ERATT;\n\t\t\t \n\t\t\twritel(0, phba->HCregaddr);\n\t\t\treadl(phba->HCregaddr);\n\t\t}\n\n\t\t \n\t\tphba->work_ha |= HA_ERATT;\n\t\t \n\t\tphba->hba_flag |= HBA_ERATT_HANDLED;\n\t\treturn 1;\n\t}\n\treturn 0;\n\nunplug_err:\n\t \n\tphba->work_hs |= UNPLUG_ERR;\n\t \n\tphba->work_ha |= HA_ERATT;\n\t \n\tphba->hba_flag |= HBA_ERATT_HANDLED;\n\treturn 1;\n}\n\n \nstatic int\nlpfc_sli4_eratt_read(struct lpfc_hba *phba)\n{\n\tuint32_t uerr_sta_hi, uerr_sta_lo;\n\tuint32_t if_type, portsmphr;\n\tstruct lpfc_register portstat_reg;\n\tu32 logmask;\n\n\t \n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tif (lpfc_readl(phba->sli4_hba.u.if_type0.UERRLOregaddr,\n\t\t\t&uerr_sta_lo) ||\n\t\t\tlpfc_readl(phba->sli4_hba.u.if_type0.UERRHIregaddr,\n\t\t\t&uerr_sta_hi)) {\n\t\t\tphba->work_hs |= UNPLUG_ERR;\n\t\t\tphba->work_ha |= HA_ERATT;\n\t\t\tphba->hba_flag |= HBA_ERATT_HANDLED;\n\t\t\treturn 1;\n\t\t}\n\t\tif ((~phba->sli4_hba.ue_mask_lo & uerr_sta_lo) ||\n\t\t    (~phba->sli4_hba.ue_mask_hi & uerr_sta_hi)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"1423 HBA Unrecoverable error: \"\n\t\t\t\t\t\"uerr_lo_reg=0x%x, uerr_hi_reg=0x%x, \"\n\t\t\t\t\t\"ue_mask_lo_reg=0x%x, \"\n\t\t\t\t\t\"ue_mask_hi_reg=0x%x\\n\",\n\t\t\t\t\tuerr_sta_lo, uerr_sta_hi,\n\t\t\t\t\tphba->sli4_hba.ue_mask_lo,\n\t\t\t\t\tphba->sli4_hba.ue_mask_hi);\n\t\t\tphba->work_status[0] = uerr_sta_lo;\n\t\t\tphba->work_status[1] = uerr_sta_hi;\n\t\t\tphba->work_ha |= HA_ERATT;\n\t\t\tphba->hba_flag |= HBA_ERATT_HANDLED;\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tif (lpfc_readl(phba->sli4_hba.u.if_type2.STATUSregaddr,\n\t\t\t&portstat_reg.word0) ||\n\t\t\tlpfc_readl(phba->sli4_hba.PSMPHRregaddr,\n\t\t\t&portsmphr)){\n\t\t\tphba->work_hs |= UNPLUG_ERR;\n\t\t\tphba->work_ha |= HA_ERATT;\n\t\t\tphba->hba_flag |= HBA_ERATT_HANDLED;\n\t\t\treturn 1;\n\t\t}\n\t\tif (bf_get(lpfc_sliport_status_err, &portstat_reg)) {\n\t\t\tphba->work_status[0] =\n\t\t\t\treadl(phba->sli4_hba.u.if_type2.ERR1regaddr);\n\t\t\tphba->work_status[1] =\n\t\t\t\treadl(phba->sli4_hba.u.if_type2.ERR2regaddr);\n\t\t\tlogmask = LOG_TRACE_EVENT;\n\t\t\tif (phba->work_status[0] ==\n\t\t\t\tSLIPORT_ERR1_REG_ERR_CODE_2 &&\n\t\t\t    phba->work_status[1] == SLIPORT_ERR2_REG_FW_RESTART)\n\t\t\t\tlogmask = LOG_SLI;\n\t\t\tlpfc_printf_log(phba, KERN_ERR, logmask,\n\t\t\t\t\t\"2885 Port Status Event: \"\n\t\t\t\t\t\"port status reg 0x%x, \"\n\t\t\t\t\t\"port smphr reg 0x%x, \"\n\t\t\t\t\t\"error 1=0x%x, error 2=0x%x\\n\",\n\t\t\t\t\tportstat_reg.word0,\n\t\t\t\t\tportsmphr,\n\t\t\t\t\tphba->work_status[0],\n\t\t\t\t\tphba->work_status[1]);\n\t\t\tphba->work_ha |= HA_ERATT;\n\t\t\tphba->hba_flag |= HBA_ERATT_HANDLED;\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2886 HBA Error Attention on unsupported \"\n\t\t\t\t\"if type %d.\", if_type);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n \nint\nlpfc_sli_check_eratt(struct lpfc_hba *phba)\n{\n\tuint32_t ha_copy;\n\n\t \n\tif (phba->link_flag & LS_IGNORE_ERATT)\n\t\treturn 0;\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tif (phba->hba_flag & HBA_ERATT_HANDLED) {\n\t\t \n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn 0;\n\t}\n\n\t \n\tif (unlikely(phba->hba_flag & DEFER_ERATT)) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn 0;\n\t}\n\n\t \n\tif (unlikely(pci_channel_offline(phba->pcidev))) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn 0;\n\t}\n\n\tswitch (phba->sli_rev) {\n\tcase LPFC_SLI_REV2:\n\tcase LPFC_SLI_REV3:\n\t\t \n\t\tha_copy = lpfc_sli_eratt_read(phba);\n\t\tbreak;\n\tcase LPFC_SLI_REV4:\n\t\t \n\t\tha_copy = lpfc_sli4_eratt_read(phba);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0299 Invalid SLI revision (%d)\\n\",\n\t\t\t\tphba->sli_rev);\n\t\tha_copy = 0;\n\t\tbreak;\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\n\treturn ha_copy;\n}\n\n \nstatic inline int\nlpfc_intr_state_check(struct lpfc_hba *phba)\n{\n\t \n\tif (unlikely(pci_channel_offline(phba->pcidev)))\n\t\treturn -EIO;\n\n\t \n\tphba->sli.slistat.sli_intr++;\n\n\t \n\tif (unlikely(phba->link_state < LPFC_LINK_DOWN))\n\t\treturn -EIO;\n\n\treturn 0;\n}\n\n \nirqreturn_t\nlpfc_sli_sp_intr_handler(int irq, void *dev_id)\n{\n\tstruct lpfc_hba  *phba;\n\tuint32_t ha_copy, hc_copy;\n\tuint32_t work_ha_copy;\n\tunsigned long status;\n\tunsigned long iflag;\n\tuint32_t control;\n\n\tMAILBOX_t *mbox, *pmbox;\n\tstruct lpfc_vport *vport;\n\tstruct lpfc_nodelist *ndlp;\n\tstruct lpfc_dmabuf *mp;\n\tLPFC_MBOXQ_t *pmb;\n\tint rc;\n\n\t \n\tphba = (struct lpfc_hba *)dev_id;\n\n\tif (unlikely(!phba))\n\t\treturn IRQ_NONE;\n\n\t \n\tif (phba->intr_type == MSIX) {\n\t\t \n\t\tif (lpfc_intr_state_check(phba))\n\t\t\treturn IRQ_NONE;\n\t\t \n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\tif (lpfc_readl(phba->HAregaddr, &ha_copy))\n\t\t\tgoto unplug_error;\n\t\t \n\t\tif (phba->link_flag & LS_IGNORE_ERATT)\n\t\t\tha_copy &= ~HA_ERATT;\n\t\t \n\t\tif (ha_copy & HA_ERATT) {\n\t\t\tif (phba->hba_flag & HBA_ERATT_HANDLED)\n\t\t\t\t \n\t\t\t\tha_copy &= ~HA_ERATT;\n\t\t\telse\n\t\t\t\t \n\t\t\t\tphba->hba_flag |= HBA_ERATT_HANDLED;\n\t\t}\n\n\t\t \n\t\tif (unlikely(phba->hba_flag & DEFER_ERATT)) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\treturn IRQ_NONE;\n\t\t}\n\n\t\t \n\t\tif (lpfc_readl(phba->HCregaddr, &hc_copy))\n\t\t\tgoto unplug_error;\n\n\t\twritel(hc_copy & ~(HC_MBINT_ENA | HC_R2INT_ENA |\n\t\t\tHC_LAINT_ENA | HC_ERINT_ENA),\n\t\t\tphba->HCregaddr);\n\t\twritel((ha_copy & (HA_MBATT | HA_R2_CLR_MSK)),\n\t\t\tphba->HAregaddr);\n\t\twritel(hc_copy, phba->HCregaddr);\n\t\treadl(phba->HAregaddr);  \n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t} else\n\t\tha_copy = phba->ha_copy;\n\n\twork_ha_copy = ha_copy & phba->work_ha_mask;\n\n\tif (work_ha_copy) {\n\t\tif (work_ha_copy & HA_LATT) {\n\t\t\tif (phba->sli.sli_flag & LPFC_PROCESS_LA) {\n\t\t\t\t \n\t\t\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\t\t\tphba->sli.sli_flag &= ~LPFC_PROCESS_LA;\n\t\t\t\tif (lpfc_readl(phba->HCregaddr, &control))\n\t\t\t\t\tgoto unplug_error;\n\t\t\t\tcontrol &= ~HC_LAINT_ENA;\n\t\t\t\twritel(control, phba->HCregaddr);\n\t\t\t\treadl(phba->HCregaddr);  \n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\t}\n\t\t\telse\n\t\t\t\twork_ha_copy &= ~HA_LATT;\n\t\t}\n\n\t\tif (work_ha_copy & ~(HA_ERATT | HA_MBATT | HA_LATT)) {\n\t\t\t \n\t\t\tstatus = (work_ha_copy &\n\t\t\t\t(HA_RXMASK  << (4*LPFC_ELS_RING)));\n\t\t\tstatus >>= (4*LPFC_ELS_RING);\n\t\t\tif (status & HA_RXMASK) {\n\t\t\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\t\t\tif (lpfc_readl(phba->HCregaddr, &control))\n\t\t\t\t\tgoto unplug_error;\n\n\t\t\t\tlpfc_debugfs_slow_ring_trc(phba,\n\t\t\t\t\"ISR slow ring:   ctl:x%x stat:x%x isrcnt:x%x\",\n\t\t\t\tcontrol, status,\n\t\t\t\t(uint32_t)phba->sli.slistat.sli_intr);\n\n\t\t\t\tif (control & (HC_R0INT_ENA << LPFC_ELS_RING)) {\n\t\t\t\t\tlpfc_debugfs_slow_ring_trc(phba,\n\t\t\t\t\t\t\"ISR Disable ring:\"\n\t\t\t\t\t\t\"pwork:x%x hawork:x%x wait:x%x\",\n\t\t\t\t\t\tphba->work_ha, work_ha_copy,\n\t\t\t\t\t\t(uint32_t)((unsigned long)\n\t\t\t\t\t\t&phba->work_waitq));\n\n\t\t\t\t\tcontrol &=\n\t\t\t\t\t    ~(HC_R0INT_ENA << LPFC_ELS_RING);\n\t\t\t\t\twritel(control, phba->HCregaddr);\n\t\t\t\t\treadl(phba->HCregaddr);  \n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlpfc_debugfs_slow_ring_trc(phba,\n\t\t\t\t\t\t\"ISR slow ring:   pwork:\"\n\t\t\t\t\t\t\"x%x hawork:x%x wait:x%x\",\n\t\t\t\t\t\tphba->work_ha, work_ha_copy,\n\t\t\t\t\t\t(uint32_t)((unsigned long)\n\t\t\t\t\t\t&phba->work_waitq));\n\t\t\t\t}\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\t}\n\t\t}\n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\tif (work_ha_copy & HA_ERATT) {\n\t\t\tif (lpfc_sli_read_hs(phba))\n\t\t\t\tgoto unplug_error;\n\t\t\t \n\t\t\tif ((HS_FFER1 & phba->work_hs) &&\n\t\t\t\t((HS_FFER2 | HS_FFER3 | HS_FFER4 | HS_FFER5 |\n\t\t\t\t  HS_FFER6 | HS_FFER7 | HS_FFER8) &\n\t\t\t\t  phba->work_hs)) {\n\t\t\t\tphba->hba_flag |= DEFER_ERATT;\n\t\t\t\t \n\t\t\t\twritel(0, phba->HCregaddr);\n\t\t\t\treadl(phba->HCregaddr);\n\t\t\t}\n\t\t}\n\n\t\tif ((work_ha_copy & HA_MBATT) && (phba->sli.mbox_active)) {\n\t\t\tpmb = phba->sli.mbox_active;\n\t\t\tpmbox = &pmb->u.mb;\n\t\t\tmbox = phba->mbox;\n\t\t\tvport = pmb->vport;\n\n\t\t\t \n\t\t\tlpfc_sli_pcimem_bcopy(mbox, pmbox, sizeof(uint32_t));\n\t\t\tif (pmbox->mbxOwner != OWN_HOST) {\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\t\t \n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"(%d):0304 Stray Mailbox \"\n\t\t\t\t\t\t\"Interrupt mbxCommand x%x \"\n\t\t\t\t\t\t\"mbxStatus x%x\\n\",\n\t\t\t\t\t\t(vport ? vport->vpi : 0),\n\t\t\t\t\t\tpmbox->mbxCommand,\n\t\t\t\t\t\tpmbox->mbxStatus);\n\t\t\t\t \n\t\t\t\twork_ha_copy &= ~HA_MBATT;\n\t\t\t} else {\n\t\t\t\tphba->sli.mbox_active = NULL;\n\t\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\t\tphba->last_completion_time = jiffies;\n\t\t\t\tdel_timer(&phba->sli.mbox_tmo);\n\t\t\t\tif (pmb->mbox_cmpl) {\n\t\t\t\t\tlpfc_sli_pcimem_bcopy(mbox, pmbox,\n\t\t\t\t\t\t\tMAILBOX_CMD_SIZE);\n\t\t\t\t\tif (pmb->out_ext_byte_len &&\n\t\t\t\t\t\tpmb->ctx_buf)\n\t\t\t\t\t\tlpfc_sli_pcimem_bcopy(\n\t\t\t\t\t\tphba->mbox_ext,\n\t\t\t\t\t\tpmb->ctx_buf,\n\t\t\t\t\t\tpmb->out_ext_byte_len);\n\t\t\t\t}\n\t\t\t\tif (pmb->mbox_flag & LPFC_MBX_IMED_UNREG) {\n\t\t\t\t\tpmb->mbox_flag &= ~LPFC_MBX_IMED_UNREG;\n\n\t\t\t\t\tlpfc_debugfs_disc_trc(vport,\n\t\t\t\t\t\tLPFC_DISC_TRC_MBOX_VPORT,\n\t\t\t\t\t\t\"MBOX dflt rpi: : \"\n\t\t\t\t\t\t\"status:x%x rpi:x%x\",\n\t\t\t\t\t\t(uint32_t)pmbox->mbxStatus,\n\t\t\t\t\t\tpmbox->un.varWords[0], 0);\n\n\t\t\t\t\tif (!pmbox->mbxStatus) {\n\t\t\t\t\t\tmp = (struct lpfc_dmabuf *)\n\t\t\t\t\t\t\t(pmb->ctx_buf);\n\t\t\t\t\t\tndlp = (struct lpfc_nodelist *)\n\t\t\t\t\t\t\tpmb->ctx_ndlp;\n\n\t\t\t\t\t\t \n\t\t\t\t\t\tlpfc_unreg_login(phba,\n\t\t\t\t\t\t\tvport->vpi,\n\t\t\t\t\t\t\tpmbox->un.varWords[0],\n\t\t\t\t\t\t\tpmb);\n\t\t\t\t\t\tpmb->mbox_cmpl =\n\t\t\t\t\t\t\tlpfc_mbx_cmpl_dflt_rpi;\n\t\t\t\t\t\tpmb->ctx_buf = mp;\n\t\t\t\t\t\tpmb->ctx_ndlp = ndlp;\n\t\t\t\t\t\tpmb->vport = vport;\n\t\t\t\t\t\trc = lpfc_sli_issue_mbox(phba,\n\t\t\t\t\t\t\t\tpmb,\n\t\t\t\t\t\t\t\tMBX_NOWAIT);\n\t\t\t\t\t\tif (rc != MBX_BUSY)\n\t\t\t\t\t\t\tlpfc_printf_log(phba,\n\t\t\t\t\t\t\tKERN_ERR,\n\t\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\t\"0350 rc should have\"\n\t\t\t\t\t\t\t\"been MBX_BUSY\\n\");\n\t\t\t\t\t\tif (rc != MBX_NOT_FINISHED)\n\t\t\t\t\t\t\tgoto send_current_mbox;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tspin_lock_irqsave(\n\t\t\t\t\t\t&phba->pport->work_port_lock,\n\t\t\t\t\t\tiflag);\n\t\t\t\tphba->pport->work_port_events &=\n\t\t\t\t\t~WORKER_MBOX_TMO;\n\t\t\t\tspin_unlock_irqrestore(\n\t\t\t\t\t\t&phba->pport->work_port_lock,\n\t\t\t\t\t\tiflag);\n\n\t\t\t\t \n\t\t\t\tif (pmbox->mbxCommand == MBX_HEARTBEAT) {\n\t\t\t\t\t \n\t\t\t\t\tphba->sli.mbox_active = NULL;\n\t\t\t\t\tphba->sli.sli_flag &=\n\t\t\t\t\t\t~LPFC_SLI_MBOX_ACTIVE;\n\t\t\t\t\tif (pmb->mbox_cmpl)\n\t\t\t\t\t\tpmb->mbox_cmpl(phba, pmb);\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tlpfc_mbox_cmpl_put(phba, pmb);\n\t\t\t\t}\n\t\t\t}\n\t\t} else\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\n\t\tif ((work_ha_copy & HA_MBATT) &&\n\t\t    (phba->sli.mbox_active == NULL)) {\nsend_current_mbox:\n\t\t\t \n\t\t\tdo {\n\t\t\t\trc = lpfc_sli_issue_mbox(phba, NULL,\n\t\t\t\t\t\t\t MBX_NOWAIT);\n\t\t\t} while (rc == MBX_NOT_FINISHED);\n\t\t\tif (rc != MBX_SUCCESS)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"0349 rc should be \"\n\t\t\t\t\t\t\"MBX_SUCCESS\\n\");\n\t\t}\n\n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\tphba->work_ha |= work_ha_copy;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\tlpfc_worker_wake_up(phba);\n\t}\n\treturn IRQ_HANDLED;\nunplug_error:\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\treturn IRQ_HANDLED;\n\n}  \n\n \nirqreturn_t\nlpfc_sli_fp_intr_handler(int irq, void *dev_id)\n{\n\tstruct lpfc_hba  *phba;\n\tuint32_t ha_copy;\n\tunsigned long status;\n\tunsigned long iflag;\n\tstruct lpfc_sli_ring *pring;\n\n\t \n\tphba = (struct lpfc_hba *) dev_id;\n\n\tif (unlikely(!phba))\n\t\treturn IRQ_NONE;\n\n\t \n\tif (phba->intr_type == MSIX) {\n\t\t \n\t\tif (lpfc_intr_state_check(phba))\n\t\t\treturn IRQ_NONE;\n\t\t \n\t\tif (lpfc_readl(phba->HAregaddr, &ha_copy))\n\t\t\treturn IRQ_HANDLED;\n\t\t \n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\t \n\t\tif (unlikely(phba->hba_flag & DEFER_ERATT)) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\t\treturn IRQ_NONE;\n\t\t}\n\t\twritel((ha_copy & (HA_R0_CLR_MSK | HA_R1_CLR_MSK)),\n\t\t\tphba->HAregaddr);\n\t\treadl(phba->HAregaddr);  \n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t} else\n\t\tha_copy = phba->ha_copy;\n\n\t \n\tha_copy &= ~(phba->work_ha_mask);\n\n\tstatus = (ha_copy & (HA_RXMASK << (4*LPFC_FCP_RING)));\n\tstatus >>= (4*LPFC_FCP_RING);\n\tpring = &phba->sli.sli3_ring[LPFC_FCP_RING];\n\tif (status & HA_RXMASK)\n\t\tlpfc_sli_handle_fast_ring_event(phba, pring, status);\n\n\tif (phba->cfg_multi_ring_support == 2) {\n\t\t \n\t\tstatus = (ha_copy & (HA_RXMASK << (4*LPFC_EXTRA_RING)));\n\t\tstatus >>= (4*LPFC_EXTRA_RING);\n\t\tif (status & HA_RXMASK) {\n\t\t\tlpfc_sli_handle_fast_ring_event(phba,\n\t\t\t\t\t&phba->sli.sli3_ring[LPFC_EXTRA_RING],\n\t\t\t\t\tstatus);\n\t\t}\n\t}\n\treturn IRQ_HANDLED;\n}   \n\n \nirqreturn_t\nlpfc_sli_intr_handler(int irq, void *dev_id)\n{\n\tstruct lpfc_hba  *phba;\n\tirqreturn_t sp_irq_rc, fp_irq_rc;\n\tunsigned long status1, status2;\n\tuint32_t hc_copy;\n\n\t \n\tphba = (struct lpfc_hba *) dev_id;\n\n\tif (unlikely(!phba))\n\t\treturn IRQ_NONE;\n\n\t \n\tif (lpfc_intr_state_check(phba))\n\t\treturn IRQ_NONE;\n\n\tspin_lock(&phba->hbalock);\n\tif (lpfc_readl(phba->HAregaddr, &phba->ha_copy)) {\n\t\tspin_unlock(&phba->hbalock);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tif (unlikely(!phba->ha_copy)) {\n\t\tspin_unlock(&phba->hbalock);\n\t\treturn IRQ_NONE;\n\t} else if (phba->ha_copy & HA_ERATT) {\n\t\tif (phba->hba_flag & HBA_ERATT_HANDLED)\n\t\t\t \n\t\t\tphba->ha_copy &= ~HA_ERATT;\n\t\telse\n\t\t\t \n\t\t\tphba->hba_flag |= HBA_ERATT_HANDLED;\n\t}\n\n\t \n\tif (unlikely(phba->hba_flag & DEFER_ERATT)) {\n\t\tspin_unlock(&phba->hbalock);\n\t\treturn IRQ_NONE;\n\t}\n\n\t \n\tif (lpfc_readl(phba->HCregaddr, &hc_copy)) {\n\t\tspin_unlock(&phba->hbalock);\n\t\treturn IRQ_HANDLED;\n\t}\n\twritel(hc_copy & ~(HC_MBINT_ENA | HC_R0INT_ENA | HC_R1INT_ENA\n\t\t| HC_R2INT_ENA | HC_LAINT_ENA | HC_ERINT_ENA),\n\t\tphba->HCregaddr);\n\twritel((phba->ha_copy & ~(HA_LATT | HA_ERATT)), phba->HAregaddr);\n\twritel(hc_copy, phba->HCregaddr);\n\treadl(phba->HAregaddr);  \n\tspin_unlock(&phba->hbalock);\n\n\t \n\n\t \n\tstatus1 = phba->ha_copy & (HA_MBATT | HA_LATT | HA_ERATT);\n\n\t \n\tstatus2 = (phba->ha_copy & (HA_RXMASK  << (4*LPFC_ELS_RING)));\n\tstatus2 >>= (4*LPFC_ELS_RING);\n\n\tif (status1 || (status2 & HA_RXMASK))\n\t\tsp_irq_rc = lpfc_sli_sp_intr_handler(irq, dev_id);\n\telse\n\t\tsp_irq_rc = IRQ_NONE;\n\n\t \n\n\t \n\tstatus1 = (phba->ha_copy & (HA_RXMASK << (4*LPFC_FCP_RING)));\n\tstatus1 >>= (4*LPFC_FCP_RING);\n\n\t \n\tif (phba->cfg_multi_ring_support == 2) {\n\t\tstatus2 = (phba->ha_copy & (HA_RXMASK << (4*LPFC_EXTRA_RING)));\n\t\tstatus2 >>= (4*LPFC_EXTRA_RING);\n\t} else\n\t\tstatus2 = 0;\n\n\tif ((status1 & HA_RXMASK) || (status2 & HA_RXMASK))\n\t\tfp_irq_rc = lpfc_sli_fp_intr_handler(irq, dev_id);\n\telse\n\t\tfp_irq_rc = IRQ_NONE;\n\n\t \n\treturn (sp_irq_rc == IRQ_HANDLED) ? sp_irq_rc : fp_irq_rc;\n}   \n\n \nvoid lpfc_sli4_els_xri_abort_event_proc(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflags;\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tphba->hba_flag &= ~ELS_XRI_ABORT_EVENT;\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\t \n\tspin_lock_irqsave(&phba->sli4_hba.els_xri_abrt_list_lock, iflags);\n\twhile (!list_empty(&phba->sli4_hba.sp_els_xri_aborted_work_queue)) {\n\t\t \n\t\tlist_remove_head(&phba->sli4_hba.sp_els_xri_aborted_work_queue,\n\t\t\t\t cq_event, struct lpfc_cq_event, list);\n\t\tspin_unlock_irqrestore(&phba->sli4_hba.els_xri_abrt_list_lock,\n\t\t\t\t       iflags);\n\t\t \n\t\tlpfc_sli4_els_xri_aborted(phba, &cq_event->cqe.wcqe_axri);\n\n\t\t \n\t\tlpfc_sli4_cq_event_release(phba, cq_event);\n\t\tspin_lock_irqsave(&phba->sli4_hba.els_xri_abrt_list_lock,\n\t\t\t\t  iflags);\n\t}\n\tspin_unlock_irqrestore(&phba->sli4_hba.els_xri_abrt_list_lock, iflags);\n}\n\n \nstatic struct lpfc_iocbq *\nlpfc_sli4_els_preprocess_rspiocbq(struct lpfc_hba *phba,\n\t\t\t\t  struct lpfc_iocbq *irspiocbq)\n{\n\tstruct lpfc_sli_ring *pring;\n\tstruct lpfc_iocbq *cmdiocbq;\n\tstruct lpfc_wcqe_complete *wcqe;\n\tunsigned long iflags;\n\n\tpring = lpfc_phba_elsring(phba);\n\tif (unlikely(!pring))\n\t\treturn NULL;\n\n\twcqe = &irspiocbq->cq_event.cqe.wcqe_cmpl;\n\tspin_lock_irqsave(&pring->ring_lock, iflags);\n\tpring->stats.iocb_event++;\n\t \n\tcmdiocbq = lpfc_sli_iocbq_lookup_by_tag(phba, pring,\n\t\t\t\tbf_get(lpfc_wcqe_c_request_tag, wcqe));\n\tif (unlikely(!cmdiocbq)) {\n\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"0386 ELS complete with no corresponding \"\n\t\t\t\t\"cmdiocb: 0x%x 0x%x 0x%x 0x%x\\n\",\n\t\t\t\twcqe->word0, wcqe->total_data_placed,\n\t\t\t\twcqe->parameter, wcqe->word3);\n\t\tlpfc_sli_release_iocbq(phba, irspiocbq);\n\t\treturn NULL;\n\t}\n\n\tmemcpy(&irspiocbq->wqe, &cmdiocbq->wqe, sizeof(union lpfc_wqe128));\n\tmemcpy(&irspiocbq->wcqe_cmpl, wcqe, sizeof(*wcqe));\n\n\t \n\tlpfc_sli_ringtxcmpl_put(phba, pring, cmdiocbq);\n\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\n\tif (bf_get(lpfc_wcqe_c_xb, wcqe)) {\n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tirspiocbq->cmd_flag |= LPFC_EXCHANGE_BUSY;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t}\n\n\treturn irspiocbq;\n}\n\ninline struct lpfc_cq_event *\nlpfc_cq_event_setup(struct lpfc_hba *phba, void *entry, int size)\n{\n\tstruct lpfc_cq_event *cq_event;\n\n\t \n\tcq_event = lpfc_sli4_cq_event_alloc(phba);\n\tif (!cq_event) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0602 Failed to alloc CQ_EVENT entry\\n\");\n\t\treturn NULL;\n\t}\n\n\t \n\tmemcpy(&cq_event->cqe, entry, size);\n\treturn cq_event;\n}\n\n \nstatic bool\nlpfc_sli4_sp_handle_async_event(struct lpfc_hba *phba, struct lpfc_mcqe *mcqe)\n{\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflags;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"0392 Async Event: word0:x%x, word1:x%x, \"\n\t\t\t\"word2:x%x, word3:x%x\\n\", mcqe->word0,\n\t\t\tmcqe->mcqe_tag0, mcqe->mcqe_tag1, mcqe->trailer);\n\n\tcq_event = lpfc_cq_event_setup(phba, mcqe, sizeof(struct lpfc_mcqe));\n\tif (!cq_event)\n\t\treturn false;\n\n\tspin_lock_irqsave(&phba->sli4_hba.asynce_list_lock, iflags);\n\tlist_add_tail(&cq_event->list, &phba->sli4_hba.sp_asynce_work_queue);\n\tspin_unlock_irqrestore(&phba->sli4_hba.asynce_list_lock, iflags);\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tphba->hba_flag |= ASYNC_EVENT;\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\treturn true;\n}\n\n \nstatic bool\nlpfc_sli4_sp_handle_mbox_event(struct lpfc_hba *phba, struct lpfc_mcqe *mcqe)\n{\n\tuint32_t mcqe_status;\n\tMAILBOX_t *mbox, *pmbox;\n\tstruct lpfc_mqe *mqe;\n\tstruct lpfc_vport *vport;\n\tstruct lpfc_nodelist *ndlp;\n\tstruct lpfc_dmabuf *mp;\n\tunsigned long iflags;\n\tLPFC_MBOXQ_t *pmb;\n\tbool workposted = false;\n\tint rc;\n\n\t \n\tif (!bf_get(lpfc_trailer_completed, mcqe))\n\t\tgoto out_no_mqe_complete;\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tpmb = phba->sli.mbox_active;\n\tif (unlikely(!pmb)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1832 No pending MBOX command to handle\\n\");\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tgoto out_no_mqe_complete;\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\tmqe = &pmb->u.mqe;\n\tpmbox = (MAILBOX_t *)&pmb->u.mqe;\n\tmbox = phba->mbox;\n\tvport = pmb->vport;\n\n\t \n\tphba->last_completion_time = jiffies;\n\tdel_timer(&phba->sli.mbox_tmo);\n\n\t \n\tif (pmb->mbox_cmpl && mbox)\n\t\tlpfc_sli4_pcimem_bcopy(mbox, mqe, sizeof(struct lpfc_mqe));\n\n\t \n\tmcqe_status = bf_get(lpfc_mcqe_status, mcqe);\n\tif (mcqe_status != MB_CQE_STATUS_SUCCESS) {\n\t\tif (bf_get(lpfc_mqe_status, mqe) == MBX_SUCCESS)\n\t\t\tbf_set(lpfc_mqe_status, mqe,\n\t\t\t       (LPFC_MBX_ERROR_RANGE | mcqe_status));\n\t}\n\tif (pmb->mbox_flag & LPFC_MBX_IMED_UNREG) {\n\t\tpmb->mbox_flag &= ~LPFC_MBX_IMED_UNREG;\n\t\tlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_MBOX_VPORT,\n\t\t\t\t      \"MBOX dflt rpi: status:x%x rpi:x%x\",\n\t\t\t\t      mcqe_status,\n\t\t\t\t      pmbox->un.varWords[0], 0);\n\t\tif (mcqe_status == MB_CQE_STATUS_SUCCESS) {\n\t\t\tmp = (struct lpfc_dmabuf *)(pmb->ctx_buf);\n\t\t\tndlp = (struct lpfc_nodelist *)pmb->ctx_ndlp;\n\n\t\t\t \n\t\t\tspin_lock_irqsave(&ndlp->lock, iflags);\n\t\t\tndlp->nlp_flag |= NLP_UNREG_INP;\n\t\t\tspin_unlock_irqrestore(&ndlp->lock, iflags);\n\t\t\tlpfc_unreg_login(phba, vport->vpi,\n\t\t\t\t\t pmbox->un.varWords[0], pmb);\n\t\t\tpmb->mbox_cmpl = lpfc_mbx_cmpl_dflt_rpi;\n\t\t\tpmb->ctx_buf = mp;\n\n\t\t\t \n\t\t\tpmb->ctx_ndlp = ndlp;\n\t\t\tpmb->vport = vport;\n\t\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\t\t\tif (rc != MBX_BUSY)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"0385 rc should \"\n\t\t\t\t\t\t\"have been MBX_BUSY\\n\");\n\t\t\tif (rc != MBX_NOT_FINISHED)\n\t\t\t\tgoto send_current_mbox;\n\t\t}\n\t}\n\tspin_lock_irqsave(&phba->pport->work_port_lock, iflags);\n\tphba->pport->work_port_events &= ~WORKER_MBOX_TMO;\n\tspin_unlock_irqrestore(&phba->pport->work_port_lock, iflags);\n\n\t \n\tif (pmbox->mbxCommand == MBX_HEARTBEAT) {\n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\t \n\t\tphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\tphba->sli.mbox_active = NULL;\n\t\tif (bf_get(lpfc_trailer_consumed, mcqe))\n\t\t\tlpfc_sli4_mq_release(phba->sli4_hba.mbx_wq);\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\t\t \n\t\tlpfc_sli4_post_async_mbox(phba);\n\n\t\t \n\t\tif (pmb->mbox_cmpl)\n\t\t\tpmb->mbox_cmpl(phba, pmb);\n\t\treturn false;\n\t}\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t__lpfc_mbox_cmpl_put(phba, pmb);\n\tphba->work_ha |= HA_MBATT;\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\tworkposted = true;\n\nsend_current_mbox:\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t \n\tphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t \n\tphba->sli.mbox_active = NULL;\n\tif (bf_get(lpfc_trailer_consumed, mcqe))\n\t\tlpfc_sli4_mq_release(phba->sli4_hba.mbx_wq);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t \n\tlpfc_worker_wake_up(phba);\n\treturn workposted;\n\nout_no_mqe_complete:\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tif (bf_get(lpfc_trailer_consumed, mcqe))\n\t\tlpfc_sli4_mq_release(phba->sli4_hba.mbx_wq);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn false;\n}\n\n \nstatic bool\nlpfc_sli4_sp_handle_mcqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\t\t\t struct lpfc_cqe *cqe)\n{\n\tstruct lpfc_mcqe mcqe;\n\tbool workposted;\n\n\tcq->CQ_mbox++;\n\n\t \n\tlpfc_sli4_pcimem_bcopy(cqe, &mcqe, sizeof(struct lpfc_mcqe));\n\n\t \n\tif (!bf_get(lpfc_trailer_async, &mcqe))\n\t\tworkposted = lpfc_sli4_sp_handle_mbox_event(phba, &mcqe);\n\telse\n\t\tworkposted = lpfc_sli4_sp_handle_async_event(phba, &mcqe);\n\treturn workposted;\n}\n\n \nstatic bool\nlpfc_sli4_sp_handle_els_wcqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\t\t\t     struct lpfc_wcqe_complete *wcqe)\n{\n\tstruct lpfc_iocbq *irspiocbq;\n\tunsigned long iflags;\n\tstruct lpfc_sli_ring *pring = cq->pring;\n\tint txq_cnt = 0;\n\tint txcmplq_cnt = 0;\n\n\t \n\tif (unlikely(bf_get(lpfc_wcqe_c_status, wcqe))) {\n\t\t \n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"0357 ELS CQE error: status=x%x: \"\n\t\t\t\t\"CQE: %08x %08x %08x %08x\\n\",\n\t\t\t\tbf_get(lpfc_wcqe_c_status, wcqe),\n\t\t\t\twcqe->word0, wcqe->total_data_placed,\n\t\t\t\twcqe->parameter, wcqe->word3);\n\t}\n\n\t \n\tirspiocbq = lpfc_sli_get_iocbq(phba);\n\tif (!irspiocbq) {\n\t\tif (!list_empty(&pring->txq))\n\t\t\ttxq_cnt++;\n\t\tif (!list_empty(&pring->txcmplq))\n\t\t\ttxcmplq_cnt++;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0387 NO IOCBQ data: txq_cnt=%d iocb_cnt=%d \"\n\t\t\t\"els_txcmplq_cnt=%d\\n\",\n\t\t\ttxq_cnt, phba->iocb_cnt,\n\t\t\ttxcmplq_cnt);\n\t\treturn false;\n\t}\n\n\t \n\tmemcpy(&irspiocbq->cq_event.cqe.wcqe_cmpl, wcqe, sizeof(*wcqe));\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tlist_add_tail(&irspiocbq->cq_event.list,\n\t\t      &phba->sli4_hba.sp_queue_event);\n\tphba->hba_flag |= HBA_SP_QUEUE_EVT;\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\treturn true;\n}\n\n \nstatic void\nlpfc_sli4_sp_handle_rel_wcqe(struct lpfc_hba *phba,\n\t\t\t     struct lpfc_wcqe_release *wcqe)\n{\n\t \n\tif (unlikely(!phba->sli4_hba.els_wq))\n\t\treturn;\n\t \n\tif (bf_get(lpfc_wcqe_r_wq_id, wcqe) == phba->sli4_hba.els_wq->queue_id)\n\t\tlpfc_sli4_wq_release(phba->sli4_hba.els_wq,\n\t\t\t\t     bf_get(lpfc_wcqe_r_wqe_index, wcqe));\n\telse\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"2579 Slow-path wqe consume event carries \"\n\t\t\t\t\"miss-matched qid: wcqe-qid=x%x, sp-qid=x%x\\n\",\n\t\t\t\tbf_get(lpfc_wcqe_r_wqe_index, wcqe),\n\t\t\t\tphba->sli4_hba.els_wq->queue_id);\n}\n\n \nstatic bool\nlpfc_sli4_sp_handle_abort_xri_wcqe(struct lpfc_hba *phba,\n\t\t\t\t   struct lpfc_queue *cq,\n\t\t\t\t   struct sli4_wcqe_xri_aborted *wcqe)\n{\n\tbool workposted = false;\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflags;\n\n\tswitch (cq->subtype) {\n\tcase LPFC_IO:\n\t\tlpfc_sli4_io_xri_aborted(phba, wcqe, cq->hdwq);\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t\t \n\t\t\tif (phba->nvmet_support)\n\t\t\t\tlpfc_sli4_nvmet_xri_aborted(phba, wcqe);\n\t\t}\n\t\tworkposted = false;\n\t\tbreak;\n\tcase LPFC_NVME_LS:  \n\tcase LPFC_ELS:\n\t\tcq_event = lpfc_cq_event_setup(phba, wcqe, sizeof(*wcqe));\n\t\tif (!cq_event) {\n\t\t\tworkposted = false;\n\t\t\tbreak;\n\t\t}\n\t\tcq_event->hdwq = cq->hdwq;\n\t\tspin_lock_irqsave(&phba->sli4_hba.els_xri_abrt_list_lock,\n\t\t\t\t  iflags);\n\t\tlist_add_tail(&cq_event->list,\n\t\t\t      &phba->sli4_hba.sp_els_xri_aborted_work_queue);\n\t\t \n\t\tphba->hba_flag |= ELS_XRI_ABORT_EVENT;\n\t\tspin_unlock_irqrestore(&phba->sli4_hba.els_xri_abrt_list_lock,\n\t\t\t\t       iflags);\n\t\tworkposted = true;\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0603 Invalid CQ subtype %d: \"\n\t\t\t\t\"%08x %08x %08x %08x\\n\",\n\t\t\t\tcq->subtype, wcqe->word0, wcqe->parameter,\n\t\t\t\twcqe->word2, wcqe->word3);\n\t\tworkposted = false;\n\t\tbreak;\n\t}\n\treturn workposted;\n}\n\n#define FC_RCTL_MDS_DIAGS\t0xF4\n\n \nstatic bool\nlpfc_sli4_sp_handle_rcqe(struct lpfc_hba *phba, struct lpfc_rcqe *rcqe)\n{\n\tbool workposted = false;\n\tstruct fc_frame_header *fc_hdr;\n\tstruct lpfc_queue *hrq = phba->sli4_hba.hdr_rq;\n\tstruct lpfc_queue *drq = phba->sli4_hba.dat_rq;\n\tstruct lpfc_nvmet_tgtport *tgtp;\n\tstruct hbq_dmabuf *dma_buf;\n\tuint32_t status, rq_id;\n\tunsigned long iflags;\n\n\t \n\tif (unlikely(!hrq) || unlikely(!drq))\n\t\treturn workposted;\n\n\tif (bf_get(lpfc_cqe_code, rcqe) == CQE_CODE_RECEIVE_V1)\n\t\trq_id = bf_get(lpfc_rcqe_rq_id_v1, rcqe);\n\telse\n\t\trq_id = bf_get(lpfc_rcqe_rq_id, rcqe);\n\tif (rq_id != hrq->queue_id)\n\t\tgoto out;\n\n\tstatus = bf_get(lpfc_rcqe_status, rcqe);\n\tswitch (status) {\n\tcase FC_STATUS_RQ_BUF_LEN_EXCEEDED:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2537 Receive Frame Truncated!!\\n\");\n\t\tfallthrough;\n\tcase FC_STATUS_RQ_SUCCESS:\n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tlpfc_sli4_rq_release(hrq, drq);\n\t\tdma_buf = lpfc_sli_hbqbuf_get(&phba->hbqs[0].hbq_buffer_list);\n\t\tif (!dma_buf) {\n\t\t\thrq->RQ_no_buf_found++;\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\t\tgoto out;\n\t\t}\n\t\thrq->RQ_rcv_buf++;\n\t\thrq->RQ_buf_posted--;\n\t\tmemcpy(&dma_buf->cq_event.cqe.rcqe_cmpl, rcqe, sizeof(*rcqe));\n\n\t\tfc_hdr = (struct fc_frame_header *)dma_buf->hbuf.virt;\n\n\t\tif (fc_hdr->fh_r_ctl == FC_RCTL_MDS_DIAGS ||\n\t\t    fc_hdr->fh_r_ctl == FC_RCTL_DD_UNSOL_DATA) {\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\t\t \n\t\t\tif  (!(phba->pport->load_flag & FC_UNLOADING))\n\t\t\t\tlpfc_sli4_handle_mds_loopback(phba->pport,\n\t\t\t\t\t\t\t      dma_buf);\n\t\t\telse\n\t\t\t\tlpfc_in_buf_free(phba, &dma_buf->dbuf);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tlist_add_tail(&dma_buf->cq_event.list,\n\t\t\t      &phba->sli4_hba.sp_queue_event);\n\t\t \n\t\tphba->hba_flag |= HBA_SP_QUEUE_EVT;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tworkposted = true;\n\t\tbreak;\n\tcase FC_STATUS_INSUFF_BUF_FRM_DISC:\n\t\tif (phba->nvmet_support) {\n\t\t\ttgtp = phba->targetport->private;\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6402 RQE Error x%x, posted %d err_cnt \"\n\t\t\t\t\t\"%d: %x %x %x\\n\",\n\t\t\t\t\tstatus, hrq->RQ_buf_posted,\n\t\t\t\t\thrq->RQ_no_posted_buf,\n\t\t\t\t\tatomic_read(&tgtp->rcv_fcp_cmd_in),\n\t\t\t\t\tatomic_read(&tgtp->rcv_fcp_cmd_out),\n\t\t\t\t\tatomic_read(&tgtp->xmt_fcp_release));\n\t\t}\n\t\tfallthrough;\n\n\tcase FC_STATUS_INSUFF_BUF_NEED_BUF:\n\t\thrq->RQ_no_posted_buf++;\n\t\t \n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tphba->hba_flag |= HBA_POST_RECEIVE_BUFFER;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tworkposted = true;\n\t\tbreak;\n\tcase FC_STATUS_RQ_DMA_FAILURE:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2564 RQE DMA Error x%x, x%08x x%08x x%08x \"\n\t\t\t\t\"x%08x\\n\",\n\t\t\t\tstatus, rcqe->word0, rcqe->word1,\n\t\t\t\trcqe->word2, rcqe->word3);\n\n\t\t \n\t\tif (bf_get(lpfc_rcqe_iv, rcqe))\n\t\t\tbreak;\n\n\t\t \n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tlpfc_sli4_rq_release(hrq, drq);\n\t\tdma_buf = lpfc_sli_hbqbuf_get(&phba->hbqs[0].hbq_buffer_list);\n\t\tif (!dma_buf) {\n\t\t\thrq->RQ_no_buf_found++;\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\t\tbreak;\n\t\t}\n\t\thrq->RQ_rcv_buf++;\n\t\thrq->RQ_buf_posted--;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tlpfc_in_buf_free(phba, &dma_buf->dbuf);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2565 Unexpected RQE Status x%x, w0-3 x%08x \"\n\t\t\t\t\"x%08x x%08x x%08x\\n\",\n\t\t\t\tstatus, rcqe->word0, rcqe->word1,\n\t\t\t\trcqe->word2, rcqe->word3);\n\t\tbreak;\n\t}\nout:\n\treturn workposted;\n}\n\n \nstatic bool\nlpfc_sli4_sp_handle_cqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\t\t\t struct lpfc_cqe *cqe)\n{\n\tstruct lpfc_cqe cqevt;\n\tbool workposted = false;\n\n\t \n\tlpfc_sli4_pcimem_bcopy(cqe, &cqevt, sizeof(struct lpfc_cqe));\n\n\t \n\tswitch (bf_get(lpfc_cqe_code, &cqevt)) {\n\tcase CQE_CODE_COMPL_WQE:\n\t\t \n\t\tphba->last_completion_time = jiffies;\n\t\tworkposted = lpfc_sli4_sp_handle_els_wcqe(phba, cq,\n\t\t\t\t(struct lpfc_wcqe_complete *)&cqevt);\n\t\tbreak;\n\tcase CQE_CODE_RELEASE_WQE:\n\t\t \n\t\tlpfc_sli4_sp_handle_rel_wcqe(phba,\n\t\t\t\t(struct lpfc_wcqe_release *)&cqevt);\n\t\tbreak;\n\tcase CQE_CODE_XRI_ABORTED:\n\t\t \n\t\tphba->last_completion_time = jiffies;\n\t\tworkposted = lpfc_sli4_sp_handle_abort_xri_wcqe(phba, cq,\n\t\t\t\t(struct sli4_wcqe_xri_aborted *)&cqevt);\n\t\tbreak;\n\tcase CQE_CODE_RECEIVE:\n\tcase CQE_CODE_RECEIVE_V1:\n\t\t \n\t\tphba->last_completion_time = jiffies;\n\t\tworkposted = lpfc_sli4_sp_handle_rcqe(phba,\n\t\t\t\t(struct lpfc_rcqe *)&cqevt);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0388 Not a valid WCQE code: x%x\\n\",\n\t\t\t\tbf_get(lpfc_cqe_code, &cqevt));\n\t\tbreak;\n\t}\n\treturn workposted;\n}\n\n \nstatic void\nlpfc_sli4_sp_handle_eqe(struct lpfc_hba *phba, struct lpfc_eqe *eqe,\n\tstruct lpfc_queue *speq)\n{\n\tstruct lpfc_queue *cq = NULL, *childq;\n\tuint16_t cqid;\n\tint ret = 0;\n\n\t \n\tcqid = bf_get_le32(lpfc_eqe_resource_id, eqe);\n\n\tlist_for_each_entry(childq, &speq->child_list, list) {\n\t\tif (childq->queue_id == cqid) {\n\t\t\tcq = childq;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (unlikely(!cq)) {\n\t\tif (phba->sli.sli_flag & LPFC_SLI_ACTIVE)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0365 Slow-path CQ identifier \"\n\t\t\t\t\t\"(%d) does not exist\\n\", cqid);\n\t\treturn;\n\t}\n\n\t \n\tcq->assoc_qp = speq;\n\n\tif (is_kdump_kernel())\n\t\tret = queue_work(phba->wq, &cq->spwork);\n\telse\n\t\tret = queue_work_on(cq->chann, phba->wq, &cq->spwork);\n\n\tif (!ret)\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0390 Cannot schedule queue work \"\n\t\t\t\t\"for CQ eqcqid=%d, cqid=%d on CPU %d\\n\",\n\t\t\t\tcqid, cq->queue_id, raw_smp_processor_id());\n}\n\n \nstatic bool\n__lpfc_sli4_process_cq(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\tbool (*handler)(struct lpfc_hba *, struct lpfc_queue *,\n\t\t\tstruct lpfc_cqe *), unsigned long *delay)\n{\n\tstruct lpfc_cqe *cqe;\n\tbool workposted = false;\n\tint count = 0, consumed = 0;\n\tbool arm = true;\n\n\t \n\t*delay = 0;\n\n\tif (cmpxchg(&cq->queue_claimed, 0, 1) != 0)\n\t\tgoto rearm_and_exit;\n\n\t \n\tcq->q_flag = 0;\n\tcqe = lpfc_sli4_cq_get(cq);\n\twhile (cqe) {\n\t\tworkposted |= handler(phba, cq, cqe);\n\t\t__lpfc_sli4_consume_cqe(phba, cq, cqe);\n\n\t\tconsumed++;\n\t\tif (!(++count % cq->max_proc_limit))\n\t\t\tbreak;\n\n\t\tif (!(count % cq->notify_interval)) {\n\t\t\tphba->sli4_hba.sli4_write_cq_db(phba, cq, consumed,\n\t\t\t\t\t\tLPFC_QUEUE_NOARM);\n\t\t\tconsumed = 0;\n\t\t\tcq->assoc_qp->q_flag |= HBA_EQ_DELAY_CHK;\n\t\t}\n\n\t\tif (count == LPFC_NVMET_CQ_NOTIFY)\n\t\t\tcq->q_flag |= HBA_NVMET_CQ_NOTIFY;\n\n\t\tcqe = lpfc_sli4_cq_get(cq);\n\t}\n\tif (count >= phba->cfg_cq_poll_threshold) {\n\t\t*delay = 1;\n\t\tarm = false;\n\t}\n\n\t \n\tif (count > cq->CQ_max_cqe)\n\t\tcq->CQ_max_cqe = count;\n\n\tcq->assoc_qp->EQ_cqe_cnt += count;\n\n\t \n\tif (unlikely(count == 0))\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"0369 No entry from completion queue \"\n\t\t\t\t\"qid=%d\\n\", cq->queue_id);\n\n\txchg(&cq->queue_claimed, 0);\n\nrearm_and_exit:\n\tphba->sli4_hba.sli4_write_cq_db(phba, cq, consumed,\n\t\t\tarm ?  LPFC_QUEUE_REARM : LPFC_QUEUE_NOARM);\n\n\treturn workposted;\n}\n\n \nstatic void\n__lpfc_sli4_sp_process_cq(struct lpfc_queue *cq)\n{\n\tstruct lpfc_hba *phba = cq->phba;\n\tunsigned long delay;\n\tbool workposted = false;\n\tint ret = 0;\n\n\t \n\tswitch (cq->type) {\n\tcase LPFC_MCQ:\n\t\tworkposted |= __lpfc_sli4_process_cq(phba, cq,\n\t\t\t\t\t\tlpfc_sli4_sp_handle_mcqe,\n\t\t\t\t\t\t&delay);\n\t\tbreak;\n\tcase LPFC_WCQ:\n\t\tif (cq->subtype == LPFC_IO)\n\t\t\tworkposted |= __lpfc_sli4_process_cq(phba, cq,\n\t\t\t\t\t\tlpfc_sli4_fp_handle_cqe,\n\t\t\t\t\t\t&delay);\n\t\telse\n\t\t\tworkposted |= __lpfc_sli4_process_cq(phba, cq,\n\t\t\t\t\t\tlpfc_sli4_sp_handle_cqe,\n\t\t\t\t\t\t&delay);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0370 Invalid completion queue type (%d)\\n\",\n\t\t\t\tcq->type);\n\t\treturn;\n\t}\n\n\tif (delay) {\n\t\tif (is_kdump_kernel())\n\t\t\tret = queue_delayed_work(phba->wq, &cq->sched_spwork,\n\t\t\t\t\t\tdelay);\n\t\telse\n\t\t\tret = queue_delayed_work_on(cq->chann, phba->wq,\n\t\t\t\t\t\t&cq->sched_spwork, delay);\n\t\tif (!ret)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0394 Cannot schedule queue work \"\n\t\t\t\t\"for cqid=%d on CPU %d\\n\",\n\t\t\t\tcq->queue_id, cq->chann);\n\t}\n\n\t \n\tif (workposted)\n\t\tlpfc_worker_wake_up(phba);\n}\n\n \nstatic void\nlpfc_sli4_sp_process_cq(struct work_struct *work)\n{\n\tstruct lpfc_queue *cq = container_of(work, struct lpfc_queue, spwork);\n\n\t__lpfc_sli4_sp_process_cq(cq);\n}\n\n \nstatic void\nlpfc_sli4_dly_sp_process_cq(struct work_struct *work)\n{\n\tstruct lpfc_queue *cq = container_of(to_delayed_work(work),\n\t\t\t\t\tstruct lpfc_queue, sched_spwork);\n\n\t__lpfc_sli4_sp_process_cq(cq);\n}\n\n \nstatic void\nlpfc_sli4_fp_handle_fcp_wcqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\t\t\t     struct lpfc_wcqe_complete *wcqe)\n{\n\tstruct lpfc_sli_ring *pring = cq->pring;\n\tstruct lpfc_iocbq *cmdiocbq;\n\tunsigned long iflags;\n\n\t \n\tif (unlikely(bf_get(lpfc_wcqe_c_status, wcqe))) {\n\t\t \n\t\tif (((bf_get(lpfc_wcqe_c_status, wcqe) ==\n\t\t     IOSTAT_LOCAL_REJECT)) &&\n\t\t    ((wcqe->parameter & IOERR_PARAM_MASK) ==\n\t\t     IOERR_NO_RESOURCES))\n\t\t\tphba->lpfc_rampdown_queue_depth(phba);\n\n\t\t \n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"0373 FCP CQE cmpl: status=x%x: \"\n\t\t\t\t\"CQE: %08x %08x %08x %08x\\n\",\n\t\t\t\tbf_get(lpfc_wcqe_c_status, wcqe),\n\t\t\t\twcqe->word0, wcqe->total_data_placed,\n\t\t\t\twcqe->parameter, wcqe->word3);\n\t}\n\n\t \n\tspin_lock_irqsave(&pring->ring_lock, iflags);\n\tpring->stats.iocb_event++;\n\tcmdiocbq = lpfc_sli_iocbq_lookup_by_tag(phba, pring,\n\t\t\t\tbf_get(lpfc_wcqe_c_request_tag, wcqe));\n\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\tif (unlikely(!cmdiocbq)) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"0374 FCP complete with no corresponding \"\n\t\t\t\t\"cmdiocb: iotag (%d)\\n\",\n\t\t\t\tbf_get(lpfc_wcqe_c_request_tag, wcqe));\n\t\treturn;\n\t}\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\tcmdiocbq->isr_timestamp = cq->isr_timestamp;\n#endif\n\tif (bf_get(lpfc_wcqe_c_xb, wcqe)) {\n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tcmdiocbq->cmd_flag |= LPFC_EXCHANGE_BUSY;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t}\n\n\tif (cmdiocbq->cmd_cmpl) {\n\t\t \n\t\tif (!(cmdiocbq->cmd_flag & LPFC_IO_FCP) &&\n\t\t    cmdiocbq->cmd_flag & LPFC_DRIVER_ABORTED) {\n\t\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\t\tcmdiocbq->cmd_flag &= ~LPFC_DRIVER_ABORTED;\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\t}\n\n\t\t \n\t\tmemcpy(&cmdiocbq->wcqe_cmpl, wcqe,\n\t\t       sizeof(struct lpfc_wcqe_complete));\n\t\tcmdiocbq->cmd_cmpl(phba, cmdiocbq, cmdiocbq);\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"0375 FCP cmdiocb not callback function \"\n\t\t\t\t\"iotag: (%d)\\n\",\n\t\t\t\tbf_get(lpfc_wcqe_c_request_tag, wcqe));\n\t}\n}\n\n \nstatic void\nlpfc_sli4_fp_handle_rel_wcqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\t\t\t     struct lpfc_wcqe_release *wcqe)\n{\n\tstruct lpfc_queue *childwq;\n\tbool wqid_matched = false;\n\tuint16_t hba_wqid;\n\n\t \n\thba_wqid = bf_get(lpfc_wcqe_r_wq_id, wcqe);\n\tlist_for_each_entry(childwq, &cq->child_list, list) {\n\t\tif (childwq->queue_id == hba_wqid) {\n\t\t\tlpfc_sli4_wq_release(childwq,\n\t\t\t\t\tbf_get(lpfc_wcqe_r_wqe_index, wcqe));\n\t\t\tif (childwq->q_flag & HBA_NVMET_WQFULL)\n\t\t\t\tlpfc_nvmet_wqfull_process(phba, childwq);\n\t\t\twqid_matched = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\t \n\tif (wqid_matched != true)\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"2580 Fast-path wqe consume event carries \"\n\t\t\t\t\"miss-matched qid: wcqe-qid=x%x\\n\", hba_wqid);\n}\n\n \nstatic bool\nlpfc_sli4_nvmet_handle_rcqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\t\t\t    struct lpfc_rcqe *rcqe)\n{\n\tbool workposted = false;\n\tstruct lpfc_queue *hrq;\n\tstruct lpfc_queue *drq;\n\tstruct rqb_dmabuf *dma_buf;\n\tstruct fc_frame_header *fc_hdr;\n\tstruct lpfc_nvmet_tgtport *tgtp;\n\tuint32_t status, rq_id;\n\tunsigned long iflags;\n\tuint32_t fctl, idx;\n\n\tif ((phba->nvmet_support == 0) ||\n\t    (phba->sli4_hba.nvmet_cqset == NULL))\n\t\treturn workposted;\n\n\tidx = cq->queue_id - phba->sli4_hba.nvmet_cqset[0]->queue_id;\n\thrq = phba->sli4_hba.nvmet_mrq_hdr[idx];\n\tdrq = phba->sli4_hba.nvmet_mrq_data[idx];\n\n\t \n\tif (unlikely(!hrq) || unlikely(!drq))\n\t\treturn workposted;\n\n\tif (bf_get(lpfc_cqe_code, rcqe) == CQE_CODE_RECEIVE_V1)\n\t\trq_id = bf_get(lpfc_rcqe_rq_id_v1, rcqe);\n\telse\n\t\trq_id = bf_get(lpfc_rcqe_rq_id, rcqe);\n\n\tif ((phba->nvmet_support == 0) ||\n\t    (rq_id != hrq->queue_id))\n\t\treturn workposted;\n\n\tstatus = bf_get(lpfc_rcqe_status, rcqe);\n\tswitch (status) {\n\tcase FC_STATUS_RQ_BUF_LEN_EXCEEDED:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6126 Receive Frame Truncated!!\\n\");\n\t\tfallthrough;\n\tcase FC_STATUS_RQ_SUCCESS:\n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tlpfc_sli4_rq_release(hrq, drq);\n\t\tdma_buf = lpfc_sli_rqbuf_get(phba, hrq);\n\t\tif (!dma_buf) {\n\t\t\thrq->RQ_no_buf_found++;\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\t\tgoto out;\n\t\t}\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\thrq->RQ_rcv_buf++;\n\t\thrq->RQ_buf_posted--;\n\t\tfc_hdr = (struct fc_frame_header *)dma_buf->hbuf.virt;\n\n\t\t \n\t\tfctl = (fc_hdr->fh_f_ctl[0] << 16 |\n\t\t\tfc_hdr->fh_f_ctl[1] << 8 |\n\t\t\tfc_hdr->fh_f_ctl[2]);\n\t\tif (((fctl &\n\t\t    (FC_FC_FIRST_SEQ | FC_FC_END_SEQ | FC_FC_SEQ_INIT)) !=\n\t\t    (FC_FC_FIRST_SEQ | FC_FC_END_SEQ | FC_FC_SEQ_INIT)) ||\n\t\t    (fc_hdr->fh_seq_cnt != 0))  \n\t\t\tgoto drop;\n\n\t\tif (fc_hdr->fh_type == FC_TYPE_FCP) {\n\t\t\tdma_buf->bytes_recv = bf_get(lpfc_rcqe_length, rcqe);\n\t\t\tlpfc_nvmet_unsol_fcp_event(\n\t\t\t\tphba, idx, dma_buf, cq->isr_timestamp,\n\t\t\t\tcq->q_flag & HBA_NVMET_CQ_NOTIFY);\n\t\t\treturn false;\n\t\t}\ndrop:\n\t\tlpfc_rq_buf_free(phba, &dma_buf->hbuf);\n\t\tbreak;\n\tcase FC_STATUS_INSUFF_BUF_FRM_DISC:\n\t\tif (phba->nvmet_support) {\n\t\t\ttgtp = phba->targetport->private;\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6401 RQE Error x%x, posted %d err_cnt \"\n\t\t\t\t\t\"%d: %x %x %x\\n\",\n\t\t\t\t\tstatus, hrq->RQ_buf_posted,\n\t\t\t\t\thrq->RQ_no_posted_buf,\n\t\t\t\t\tatomic_read(&tgtp->rcv_fcp_cmd_in),\n\t\t\t\t\tatomic_read(&tgtp->rcv_fcp_cmd_out),\n\t\t\t\t\tatomic_read(&tgtp->xmt_fcp_release));\n\t\t}\n\t\tfallthrough;\n\n\tcase FC_STATUS_INSUFF_BUF_NEED_BUF:\n\t\thrq->RQ_no_posted_buf++;\n\t\t \n\t\tbreak;\n\tcase FC_STATUS_RQ_DMA_FAILURE:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2575 RQE DMA Error x%x, x%08x x%08x x%08x \"\n\t\t\t\t\"x%08x\\n\",\n\t\t\t\tstatus, rcqe->word0, rcqe->word1,\n\t\t\t\trcqe->word2, rcqe->word3);\n\n\t\t \n\t\tif (bf_get(lpfc_rcqe_iv, rcqe))\n\t\t\tbreak;\n\n\t\t \n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tlpfc_sli4_rq_release(hrq, drq);\n\t\tdma_buf = lpfc_sli_rqbuf_get(phba, hrq);\n\t\tif (!dma_buf) {\n\t\t\thrq->RQ_no_buf_found++;\n\t\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\t\tbreak;\n\t\t}\n\t\thrq->RQ_rcv_buf++;\n\t\thrq->RQ_buf_posted--;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tlpfc_rq_buf_free(phba, &dma_buf->hbuf);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2576 Unexpected RQE Status x%x, w0-3 x%08x \"\n\t\t\t\t\"x%08x x%08x x%08x\\n\",\n\t\t\t\tstatus, rcqe->word0, rcqe->word1,\n\t\t\t\trcqe->word2, rcqe->word3);\n\t\tbreak;\n\t}\nout:\n\treturn workposted;\n}\n\n \nstatic bool\nlpfc_sli4_fp_handle_cqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\t\t\t struct lpfc_cqe *cqe)\n{\n\tstruct lpfc_wcqe_release wcqe;\n\tbool workposted = false;\n\n\t \n\tlpfc_sli4_pcimem_bcopy(cqe, &wcqe, sizeof(struct lpfc_cqe));\n\n\t \n\tswitch (bf_get(lpfc_wcqe_c_code, &wcqe)) {\n\tcase CQE_CODE_COMPL_WQE:\n\tcase CQE_CODE_NVME_ERSP:\n\t\tcq->CQ_wq++;\n\t\t \n\t\tphba->last_completion_time = jiffies;\n\t\tif (cq->subtype == LPFC_IO || cq->subtype == LPFC_NVME_LS)\n\t\t\tlpfc_sli4_fp_handle_fcp_wcqe(phba, cq,\n\t\t\t\t(struct lpfc_wcqe_complete *)&wcqe);\n\t\tbreak;\n\tcase CQE_CODE_RELEASE_WQE:\n\t\tcq->CQ_release_wqe++;\n\t\t \n\t\tlpfc_sli4_fp_handle_rel_wcqe(phba, cq,\n\t\t\t\t(struct lpfc_wcqe_release *)&wcqe);\n\t\tbreak;\n\tcase CQE_CODE_XRI_ABORTED:\n\t\tcq->CQ_xri_aborted++;\n\t\t \n\t\tphba->last_completion_time = jiffies;\n\t\tworkposted = lpfc_sli4_sp_handle_abort_xri_wcqe(phba, cq,\n\t\t\t\t(struct sli4_wcqe_xri_aborted *)&wcqe);\n\t\tbreak;\n\tcase CQE_CODE_RECEIVE_V1:\n\tcase CQE_CODE_RECEIVE:\n\t\tphba->last_completion_time = jiffies;\n\t\tif (cq->subtype == LPFC_NVMET) {\n\t\t\tworkposted = lpfc_sli4_nvmet_handle_rcqe(\n\t\t\t\tphba, cq, (struct lpfc_rcqe *)&wcqe);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0144 Not a valid CQE code: x%x\\n\",\n\t\t\t\tbf_get(lpfc_wcqe_c_code, &wcqe));\n\t\tbreak;\n\t}\n\treturn workposted;\n}\n\n \nstatic void\n__lpfc_sli4_hba_process_cq(struct lpfc_queue *cq)\n{\n\tstruct lpfc_hba *phba = cq->phba;\n\tunsigned long delay;\n\tbool workposted = false;\n\tint ret;\n\n\t \n\tworkposted |= __lpfc_sli4_process_cq(phba, cq, lpfc_sli4_fp_handle_cqe,\n\t\t\t\t\t     &delay);\n\n\tif (delay) {\n\t\tif (is_kdump_kernel())\n\t\t\tret = queue_delayed_work(phba->wq, &cq->sched_irqwork,\n\t\t\t\t\t\tdelay);\n\t\telse\n\t\t\tret = queue_delayed_work_on(cq->chann, phba->wq,\n\t\t\t\t\t\t&cq->sched_irqwork, delay);\n\t\tif (!ret)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0367 Cannot schedule queue work \"\n\t\t\t\t\t\"for cqid=%d on CPU %d\\n\",\n\t\t\t\t\tcq->queue_id, cq->chann);\n\t}\n\n\t \n\tif (workposted)\n\t\tlpfc_worker_wake_up(phba);\n}\n\n \nstatic void\nlpfc_sli4_hba_process_cq(struct work_struct *work)\n{\n\tstruct lpfc_queue *cq = container_of(work, struct lpfc_queue, irqwork);\n\n\t__lpfc_sli4_hba_process_cq(cq);\n}\n\n \nstatic void\nlpfc_sli4_hba_handle_eqe(struct lpfc_hba *phba, struct lpfc_queue *eq,\n\t\t\t struct lpfc_eqe *eqe, enum lpfc_poll_mode poll_mode)\n{\n\tstruct lpfc_queue *cq = NULL;\n\tuint32_t qidx = eq->hdwq;\n\tuint16_t cqid, id;\n\tint ret;\n\n\tif (unlikely(bf_get_le32(lpfc_eqe_major_code, eqe) != 0)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0366 Not a valid completion \"\n\t\t\t\t\"event: majorcode=x%x, minorcode=x%x\\n\",\n\t\t\t\tbf_get_le32(lpfc_eqe_major_code, eqe),\n\t\t\t\tbf_get_le32(lpfc_eqe_minor_code, eqe));\n\t\treturn;\n\t}\n\n\t \n\tcqid = bf_get_le32(lpfc_eqe_resource_id, eqe);\n\n\t \n\tif (cqid <= phba->sli4_hba.cq_max) {\n\t\tcq = phba->sli4_hba.cq_lookup[cqid];\n\t\tif (cq)\n\t\t\tgoto  work_cq;\n\t}\n\n\t \n\tif (phba->cfg_nvmet_mrq && phba->sli4_hba.nvmet_cqset) {\n\t\tid = phba->sli4_hba.nvmet_cqset[0]->queue_id;\n\t\tif ((cqid >= id) && (cqid < (id + phba->cfg_nvmet_mrq))) {\n\t\t\t \n\t\t\tcq = phba->sli4_hba.nvmet_cqset[cqid - id];\n\t\t\tgoto  process_cq;\n\t\t}\n\t}\n\n\tif (phba->sli4_hba.nvmels_cq &&\n\t    (cqid == phba->sli4_hba.nvmels_cq->queue_id)) {\n\t\t \n\t\tcq = phba->sli4_hba.nvmels_cq;\n\t}\n\n\t \n\tif (cq == NULL) {\n\t\tlpfc_sli4_sp_handle_eqe(phba, eqe,\n\t\t\t\t\tphba->sli4_hba.hdwq[qidx].hba_eq);\n\t\treturn;\n\t}\n\nprocess_cq:\n\tif (unlikely(cqid != cq->queue_id)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0368 Miss-matched fast-path completion \"\n\t\t\t\t\"queue identifier: eqcqid=%d, fcpcqid=%d\\n\",\n\t\t\t\tcqid, cq->queue_id);\n\t\treturn;\n\t}\n\nwork_cq:\n#if defined(CONFIG_SCSI_LPFC_DEBUG_FS)\n\tif (phba->ktime_on)\n\t\tcq->isr_timestamp = ktime_get_ns();\n\telse\n\t\tcq->isr_timestamp = 0;\n#endif\n\n\tswitch (poll_mode) {\n\tcase LPFC_THREADED_IRQ:\n\t\t__lpfc_sli4_hba_process_cq(cq);\n\t\tbreak;\n\tcase LPFC_QUEUE_WORK:\n\tdefault:\n\t\tif (is_kdump_kernel())\n\t\t\tret = queue_work(phba->wq, &cq->irqwork);\n\t\telse\n\t\t\tret = queue_work_on(cq->chann, phba->wq, &cq->irqwork);\n\t\tif (!ret)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0383 Cannot schedule queue work \"\n\t\t\t\t\t\"for CQ eqcqid=%d, cqid=%d on CPU %d\\n\",\n\t\t\t\t\tcqid, cq->queue_id,\n\t\t\t\t\traw_smp_processor_id());\n\t\tbreak;\n\t}\n}\n\n \nstatic void\nlpfc_sli4_dly_hba_process_cq(struct work_struct *work)\n{\n\tstruct lpfc_queue *cq = container_of(to_delayed_work(work),\n\t\t\t\t\tstruct lpfc_queue, sched_irqwork);\n\n\t__lpfc_sli4_hba_process_cq(cq);\n}\n\n \nirqreturn_t\nlpfc_sli4_hba_intr_handler(int irq, void *dev_id)\n{\n\tstruct lpfc_hba *phba;\n\tstruct lpfc_hba_eq_hdl *hba_eq_hdl;\n\tstruct lpfc_queue *fpeq;\n\tunsigned long iflag;\n\tint hba_eqidx;\n\tint ecount = 0;\n\tstruct lpfc_eq_intr_info *eqi;\n\n\t \n\thba_eq_hdl = (struct lpfc_hba_eq_hdl *)dev_id;\n\tphba = hba_eq_hdl->phba;\n\thba_eqidx = hba_eq_hdl->idx;\n\n\tif (unlikely(!phba))\n\t\treturn IRQ_NONE;\n\tif (unlikely(!phba->sli4_hba.hdwq))\n\t\treturn IRQ_NONE;\n\n\t \n\tfpeq = phba->sli4_hba.hba_eq_hdl[hba_eqidx].eq;\n\tif (unlikely(!fpeq))\n\t\treturn IRQ_NONE;\n\n\t \n\tif (unlikely(lpfc_intr_state_check(phba))) {\n\t\t \n\t\tspin_lock_irqsave(&phba->hbalock, iflag);\n\t\tif (phba->link_state < LPFC_LINK_DOWN)\n\t\t\t \n\t\t\tlpfc_sli4_eqcq_flush(phba, fpeq);\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\treturn IRQ_NONE;\n\t}\n\n\tswitch (fpeq->poll_mode) {\n\tcase LPFC_THREADED_IRQ:\n\t\t \n\t\tif (phba->cmf_active_mode == LPFC_CFG_OFF)\n\t\t\treturn IRQ_WAKE_THREAD;\n\t\tfallthrough;\n\tcase LPFC_QUEUE_WORK:\n\tdefault:\n\t\teqi = this_cpu_ptr(phba->sli4_hba.eq_info);\n\t\teqi->icnt++;\n\n\t\tfpeq->last_cpu = raw_smp_processor_id();\n\n\t\tif (eqi->icnt > LPFC_EQD_ISR_TRIGGER &&\n\t\t    fpeq->q_flag & HBA_EQ_DELAY_CHK &&\n\t\t    phba->cfg_auto_imax &&\n\t\t    fpeq->q_mode != LPFC_MAX_AUTO_EQ_DELAY &&\n\t\t    phba->sli.sli_flag & LPFC_SLI_USE_EQDR)\n\t\t\tlpfc_sli4_mod_hba_eq_delay(phba, fpeq,\n\t\t\t\t\t\t   LPFC_MAX_AUTO_EQ_DELAY);\n\n\t\t \n\t\tecount = lpfc_sli4_process_eq(phba, fpeq, LPFC_QUEUE_REARM,\n\t\t\t\t\t      LPFC_QUEUE_WORK);\n\n\t\tif (unlikely(ecount == 0)) {\n\t\t\tfpeq->EQ_no_entry++;\n\t\t\tif (phba->intr_type == MSIX)\n\t\t\t\t \n\t\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\t\t\"0358 MSI-X interrupt with no EQE\\n\");\n\t\t\telse\n\t\t\t\t \n\t\t\t\treturn IRQ_NONE;\n\t\t}\n\t}\n\n\treturn IRQ_HANDLED;\n}  \n\n \nirqreturn_t\nlpfc_sli4_intr_handler(int irq, void *dev_id)\n{\n\tstruct lpfc_hba  *phba;\n\tirqreturn_t hba_irq_rc;\n\tbool hba_handled = false;\n\tint qidx;\n\n\t \n\tphba = (struct lpfc_hba *)dev_id;\n\n\tif (unlikely(!phba))\n\t\treturn IRQ_NONE;\n\n\t \n\tfor (qidx = 0; qidx < phba->cfg_irq_chann; qidx++) {\n\t\thba_irq_rc = lpfc_sli4_hba_intr_handler(irq,\n\t\t\t\t\t&phba->sli4_hba.hba_eq_hdl[qidx]);\n\t\tif (hba_irq_rc == IRQ_HANDLED)\n\t\t\thba_handled |= true;\n\t}\n\n\treturn (hba_handled == true) ? IRQ_HANDLED : IRQ_NONE;\n}  \n\nvoid lpfc_sli4_poll_hbtimer(struct timer_list *t)\n{\n\tstruct lpfc_hba *phba = from_timer(phba, t, cpuhp_poll_timer);\n\tstruct lpfc_queue *eq;\n\n\trcu_read_lock();\n\n\tlist_for_each_entry_rcu(eq, &phba->poll_list, _poll_list)\n\t\tlpfc_sli4_poll_eq(eq);\n\tif (!list_empty(&phba->poll_list))\n\t\tmod_timer(&phba->cpuhp_poll_timer,\n\t\t\t  jiffies + msecs_to_jiffies(LPFC_POLL_HB));\n\n\trcu_read_unlock();\n}\n\nstatic inline void lpfc_sli4_add_to_poll_list(struct lpfc_queue *eq)\n{\n\tstruct lpfc_hba *phba = eq->phba;\n\n\t \n\tif (list_empty(&phba->poll_list))\n\t\tmod_timer(&phba->cpuhp_poll_timer,\n\t\t\t  jiffies + msecs_to_jiffies(LPFC_POLL_HB));\n\n\tlist_add_rcu(&eq->_poll_list, &phba->poll_list);\n\tsynchronize_rcu();\n}\n\nstatic inline void lpfc_sli4_remove_from_poll_list(struct lpfc_queue *eq)\n{\n\tstruct lpfc_hba *phba = eq->phba;\n\n\t \n\tlist_del_rcu(&eq->_poll_list);\n\tsynchronize_rcu();\n\n\tif (list_empty(&phba->poll_list))\n\t\tdel_timer_sync(&phba->cpuhp_poll_timer);\n}\n\nvoid lpfc_sli4_cleanup_poll_list(struct lpfc_hba *phba)\n{\n\tstruct lpfc_queue *eq, *next;\n\n\tlist_for_each_entry_safe(eq, next, &phba->poll_list, _poll_list)\n\t\tlist_del(&eq->_poll_list);\n\n\tINIT_LIST_HEAD(&phba->poll_list);\n\tsynchronize_rcu();\n}\n\nstatic inline void\n__lpfc_sli4_switch_eqmode(struct lpfc_queue *eq, uint8_t mode)\n{\n\tif (mode == eq->mode)\n\t\treturn;\n\t \n\n\t \n\tWRITE_ONCE(eq->mode, mode);\n\t \n\tsmp_wmb();\n\n\t \n\tmode ? lpfc_sli4_add_to_poll_list(eq) :\n\t       lpfc_sli4_remove_from_poll_list(eq);\n}\n\nvoid lpfc_sli4_start_polling(struct lpfc_queue *eq)\n{\n\t__lpfc_sli4_switch_eqmode(eq, LPFC_EQ_POLL);\n}\n\nvoid lpfc_sli4_stop_polling(struct lpfc_queue *eq)\n{\n\tstruct lpfc_hba *phba = eq->phba;\n\n\t__lpfc_sli4_switch_eqmode(eq, LPFC_EQ_INTERRUPT);\n\n\t \n\tphba->sli4_hba.sli4_write_eq_db(phba, eq, 0, LPFC_QUEUE_REARM);\n}\n\n \nvoid\nlpfc_sli4_queue_free(struct lpfc_queue *queue)\n{\n\tstruct lpfc_dmabuf *dmabuf;\n\n\tif (!queue)\n\t\treturn;\n\n\tif (!list_empty(&queue->wq_list))\n\t\tlist_del(&queue->wq_list);\n\n\twhile (!list_empty(&queue->page_list)) {\n\t\tlist_remove_head(&queue->page_list, dmabuf, struct lpfc_dmabuf,\n\t\t\t\t list);\n\t\tdma_free_coherent(&queue->phba->pcidev->dev, queue->page_size,\n\t\t\t\t  dmabuf->virt, dmabuf->phys);\n\t\tkfree(dmabuf);\n\t}\n\tif (queue->rqbp) {\n\t\tlpfc_free_rq_buffer(queue->phba, queue);\n\t\tkfree(queue->rqbp);\n\t}\n\n\tif (!list_empty(&queue->cpu_list))\n\t\tlist_del(&queue->cpu_list);\n\n\tkfree(queue);\n\treturn;\n}\n\n \nstruct lpfc_queue *\nlpfc_sli4_queue_alloc(struct lpfc_hba *phba, uint32_t page_size,\n\t\t      uint32_t entry_size, uint32_t entry_count, int cpu)\n{\n\tstruct lpfc_queue *queue;\n\tstruct lpfc_dmabuf *dmabuf;\n\tuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\n\tuint16_t x, pgcnt;\n\n\tif (!phba->sli4_hba.pc_sli4_params.supported)\n\t\thw_page_size = page_size;\n\n\tpgcnt = ALIGN(entry_size * entry_count, hw_page_size) / hw_page_size;\n\n\t \n\tif (pgcnt > phba->sli4_hba.pc_sli4_params.wqpcnt)\n\t\tpgcnt = phba->sli4_hba.pc_sli4_params.wqpcnt;\n\n\tqueue = kzalloc_node(sizeof(*queue) + (sizeof(void *) * pgcnt),\n\t\t\t     GFP_KERNEL, cpu_to_node(cpu));\n\tif (!queue)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&queue->list);\n\tINIT_LIST_HEAD(&queue->_poll_list);\n\tINIT_LIST_HEAD(&queue->wq_list);\n\tINIT_LIST_HEAD(&queue->wqfull_list);\n\tINIT_LIST_HEAD(&queue->page_list);\n\tINIT_LIST_HEAD(&queue->child_list);\n\tINIT_LIST_HEAD(&queue->cpu_list);\n\n\t \n\tqueue->page_count = pgcnt;\n\tqueue->q_pgs = (void **)&queue[1];\n\tqueue->entry_cnt_per_pg = hw_page_size / entry_size;\n\tqueue->entry_size = entry_size;\n\tqueue->entry_count = entry_count;\n\tqueue->page_size = hw_page_size;\n\tqueue->phba = phba;\n\n\tfor (x = 0; x < queue->page_count; x++) {\n\t\tdmabuf = kzalloc_node(sizeof(*dmabuf), GFP_KERNEL,\n\t\t\t\t      dev_to_node(&phba->pcidev->dev));\n\t\tif (!dmabuf)\n\t\t\tgoto out_fail;\n\t\tdmabuf->virt = dma_alloc_coherent(&phba->pcidev->dev,\n\t\t\t\t\t\t  hw_page_size, &dmabuf->phys,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!dmabuf->virt) {\n\t\t\tkfree(dmabuf);\n\t\t\tgoto out_fail;\n\t\t}\n\t\tdmabuf->buffer_tag = x;\n\t\tlist_add_tail(&dmabuf->list, &queue->page_list);\n\t\t \n\t\tqueue->q_pgs[x] = dmabuf->virt;\n\t}\n\tINIT_WORK(&queue->irqwork, lpfc_sli4_hba_process_cq);\n\tINIT_WORK(&queue->spwork, lpfc_sli4_sp_process_cq);\n\tINIT_DELAYED_WORK(&queue->sched_irqwork, lpfc_sli4_dly_hba_process_cq);\n\tINIT_DELAYED_WORK(&queue->sched_spwork, lpfc_sli4_dly_sp_process_cq);\n\n\t \n\n\treturn queue;\nout_fail:\n\tlpfc_sli4_queue_free(queue);\n\treturn NULL;\n}\n\n \nstatic void __iomem *\nlpfc_dual_chute_pci_bar_map(struct lpfc_hba *phba, uint16_t pci_barset)\n{\n\tif (!phba->pcidev)\n\t\treturn NULL;\n\n\tswitch (pci_barset) {\n\tcase WQ_PCI_BAR_0_AND_1:\n\t\treturn phba->pci_bar0_memmap_p;\n\tcase WQ_PCI_BAR_2_AND_3:\n\t\treturn phba->pci_bar2_memmap_p;\n\tcase WQ_PCI_BAR_4_AND_5:\n\t\treturn phba->pci_bar4_memmap_p;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn NULL;\n}\n\n \nvoid\nlpfc_modify_hba_eq_delay(struct lpfc_hba *phba, uint32_t startq,\n\t\t\t uint32_t numq, uint32_t usdelay)\n{\n\tstruct lpfc_mbx_modify_eq_delay *eq_delay;\n\tLPFC_MBOXQ_t *mbox;\n\tstruct lpfc_queue *eq;\n\tint cnt = 0, rc, length;\n\tuint32_t shdr_status, shdr_add_status;\n\tuint32_t dmult;\n\tint qidx;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\tif (startq >= phba->cfg_irq_chann)\n\t\treturn;\n\n\tif (usdelay > 0xFFFF) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_FCP | LOG_NVME,\n\t\t\t\t\"6429 usdelay %d too large. Scaled down to \"\n\t\t\t\t\"0xFFFF.\\n\", usdelay);\n\t\tusdelay = 0xFFFF;\n\t}\n\n\t \n\tif (phba->sli.sli_flag & LPFC_SLI_USE_EQDR) {\n\t\tfor (qidx = startq; qidx < phba->cfg_irq_chann; qidx++) {\n\t\t\teq = phba->sli4_hba.hba_eq_hdl[qidx].eq;\n\t\t\tif (!eq)\n\t\t\t\tcontinue;\n\n\t\t\tlpfc_sli4_mod_hba_eq_delay(phba, eq, usdelay);\n\n\t\t\tif (++cnt >= numq)\n\t\t\t\tbreak;\n\t\t}\n\t\treturn;\n\t}\n\n\t \n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6428 Failed allocating mailbox cmd buffer.\"\n\t\t\t\t\" EQ delay was not set.\\n\");\n\t\treturn;\n\t}\n\tlength = (sizeof(struct lpfc_mbx_modify_eq_delay) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_MODIFY_EQ_DELAY,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\teq_delay = &mbox->u.mqe.un.eq_delay;\n\n\t \n\tdmult = (usdelay * LPFC_DMULT_CONST) / LPFC_SEC_TO_USEC;\n\tif (dmult)\n\t\tdmult--;\n\tif (dmult > LPFC_DMULT_MAX)\n\t\tdmult = LPFC_DMULT_MAX;\n\n\tfor (qidx = startq; qidx < phba->cfg_irq_chann; qidx++) {\n\t\teq = phba->sli4_hba.hba_eq_hdl[qidx].eq;\n\t\tif (!eq)\n\t\t\tcontinue;\n\t\teq->q_mode = usdelay;\n\t\teq_delay->u.request.eq[cnt].eq_id = eq->queue_id;\n\t\teq_delay->u.request.eq[cnt].phase = 0;\n\t\teq_delay->u.request.eq[cnt].delay_multi = dmult;\n\n\t\tif (++cnt >= numq)\n\t\t\tbreak;\n\t}\n\teq_delay->u.request.num_eq = cnt;\n\n\tmbox->vport = phba->pport;\n\tmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\tmbox->ctx_ndlp = NULL;\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\tshdr = (union lpfc_sli4_cfg_shdr *) &eq_delay->header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2512 MODIFY_EQ_DELAY mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t}\n\tmempool_free(mbox, phba->mbox_mem_pool);\n\treturn;\n}\n\n \nint\nlpfc_eq_create(struct lpfc_hba *phba, struct lpfc_queue *eq, uint32_t imax)\n{\n\tstruct lpfc_mbx_eq_create *eq_create;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tstruct lpfc_dmabuf *dmabuf;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tuint16_t dmult;\n\tuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\n\n\t \n\tif (!eq)\n\t\treturn -ENODEV;\n\tif (!phba->sli4_hba.pc_sli4_params.supported)\n\t\thw_page_size = SLI4_PAGE_SIZE;\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_eq_create) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_EQ_CREATE,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\teq_create = &mbox->u.mqe.un.eq_create;\n\tshdr = (union lpfc_sli4_cfg_shdr *) &eq_create->header.cfg_shdr;\n\tbf_set(lpfc_mbx_eq_create_num_pages, &eq_create->u.request,\n\t       eq->page_count);\n\tbf_set(lpfc_eq_context_size, &eq_create->u.request.context,\n\t       LPFC_EQE_SIZE);\n\tbf_set(lpfc_eq_context_valid, &eq_create->u.request.context, 1);\n\n\t \n\tif (phba->sli4_hba.pc_sli4_params.eqav) {\n\t\tbf_set(lpfc_mbox_hdr_version, &shdr->request,\n\t\t       LPFC_Q_CREATE_VERSION_2);\n\t\tbf_set(lpfc_eq_context_autovalid, &eq_create->u.request.context,\n\t\t       phba->sli4_hba.pc_sli4_params.eqav);\n\t}\n\n\t \n\tdmult = 0;\n\tbf_set(lpfc_eq_context_delay_multi, &eq_create->u.request.context,\n\t       dmult);\n\tswitch (eq->entry_count) {\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0360 Unsupported EQ count. (%d)\\n\",\n\t\t\t\teq->entry_count);\n\t\tif (eq->entry_count < 256) {\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tfallthrough;\t \n\tcase 256:\n\t\tbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\n\t\t       LPFC_EQ_CNT_256);\n\t\tbreak;\n\tcase 512:\n\t\tbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\n\t\t       LPFC_EQ_CNT_512);\n\t\tbreak;\n\tcase 1024:\n\t\tbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\n\t\t       LPFC_EQ_CNT_1024);\n\t\tbreak;\n\tcase 2048:\n\t\tbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\n\t\t       LPFC_EQ_CNT_2048);\n\t\tbreak;\n\tcase 4096:\n\t\tbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\n\t\t       LPFC_EQ_CNT_4096);\n\t\tbreak;\n\t}\n\tlist_for_each_entry(dmabuf, &eq->page_list, list) {\n\t\tmemset(dmabuf->virt, 0, hw_page_size);\n\t\teq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\n\t\t\t\t\tputPaddrLow(dmabuf->phys);\n\t\teq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\n\t\t\t\t\tputPaddrHigh(dmabuf->phys);\n\t}\n\tmbox->vport = phba->pport;\n\tmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\tmbox->ctx_buf = NULL;\n\tmbox->ctx_ndlp = NULL;\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2500 EQ_CREATE mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t}\n\teq->type = LPFC_EQ;\n\teq->subtype = LPFC_NONE;\n\teq->queue_id = bf_get(lpfc_mbx_eq_create_q_id, &eq_create->u.response);\n\tif (eq->queue_id == 0xFFFF)\n\t\tstatus = -ENXIO;\n\teq->host_index = 0;\n\teq->notify_interval = LPFC_EQ_NOTIFY_INTRVL;\n\teq->max_proc_limit = LPFC_EQ_MAX_PROC_LIMIT;\nout:\n\tmempool_free(mbox, phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nirqreturn_t lpfc_sli4_hba_intr_handler_th(int irq, void *dev_id)\n{\n\tstruct lpfc_hba *phba;\n\tstruct lpfc_hba_eq_hdl *hba_eq_hdl;\n\tstruct lpfc_queue *fpeq;\n\tint ecount = 0;\n\tint hba_eqidx;\n\tstruct lpfc_eq_intr_info *eqi;\n\n\t \n\thba_eq_hdl = (struct lpfc_hba_eq_hdl *)dev_id;\n\tphba = hba_eq_hdl->phba;\n\thba_eqidx = hba_eq_hdl->idx;\n\n\tif (unlikely(!phba))\n\t\treturn IRQ_NONE;\n\tif (unlikely(!phba->sli4_hba.hdwq))\n\t\treturn IRQ_NONE;\n\n\t \n\tfpeq = phba->sli4_hba.hba_eq_hdl[hba_eqidx].eq;\n\tif (unlikely(!fpeq))\n\t\treturn IRQ_NONE;\n\n\teqi = per_cpu_ptr(phba->sli4_hba.eq_info, raw_smp_processor_id());\n\teqi->icnt++;\n\n\tfpeq->last_cpu = raw_smp_processor_id();\n\n\tif (eqi->icnt > LPFC_EQD_ISR_TRIGGER &&\n\t    fpeq->q_flag & HBA_EQ_DELAY_CHK &&\n\t    phba->cfg_auto_imax &&\n\t    fpeq->q_mode != LPFC_MAX_AUTO_EQ_DELAY &&\n\t    phba->sli.sli_flag & LPFC_SLI_USE_EQDR)\n\t\tlpfc_sli4_mod_hba_eq_delay(phba, fpeq, LPFC_MAX_AUTO_EQ_DELAY);\n\n\t \n\tecount = lpfc_sli4_process_eq(phba, fpeq, LPFC_QUEUE_REARM,\n\t\t\t\t      LPFC_THREADED_IRQ);\n\n\tif (unlikely(ecount == 0)) {\n\t\tfpeq->EQ_no_entry++;\n\t\tif (phba->intr_type == MSIX)\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\t\"3358 MSI-X interrupt with no EQE\\n\");\n\t\telse\n\t\t\t \n\t\t\treturn IRQ_NONE;\n\t}\n\treturn IRQ_HANDLED;\n}\n\n \nint\nlpfc_cq_create(struct lpfc_hba *phba, struct lpfc_queue *cq,\n\t       struct lpfc_queue *eq, uint32_t type, uint32_t subtype)\n{\n\tstruct lpfc_mbx_cq_create *cq_create;\n\tstruct lpfc_dmabuf *dmabuf;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\t \n\tif (!cq || !eq)\n\t\treturn -ENODEV;\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_cq_create) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_CQ_CREATE,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tcq_create = &mbox->u.mqe.un.cq_create;\n\tshdr = (union lpfc_sli4_cfg_shdr *) &cq_create->header.cfg_shdr;\n\tbf_set(lpfc_mbx_cq_create_num_pages, &cq_create->u.request,\n\t\t    cq->page_count);\n\tbf_set(lpfc_cq_context_event, &cq_create->u.request.context, 1);\n\tbf_set(lpfc_cq_context_valid, &cq_create->u.request.context, 1);\n\tbf_set(lpfc_mbox_hdr_version, &shdr->request,\n\t       phba->sli4_hba.pc_sli4_params.cqv);\n\tif (phba->sli4_hba.pc_sli4_params.cqv == LPFC_Q_CREATE_VERSION_2) {\n\t\tbf_set(lpfc_mbx_cq_create_page_size, &cq_create->u.request,\n\t\t       (cq->page_size / SLI4_PAGE_SIZE));\n\t\tbf_set(lpfc_cq_eq_id_2, &cq_create->u.request.context,\n\t\t       eq->queue_id);\n\t\tbf_set(lpfc_cq_context_autovalid, &cq_create->u.request.context,\n\t\t       phba->sli4_hba.pc_sli4_params.cqav);\n\t} else {\n\t\tbf_set(lpfc_cq_eq_id, &cq_create->u.request.context,\n\t\t       eq->queue_id);\n\t}\n\tswitch (cq->entry_count) {\n\tcase 2048:\n\tcase 4096:\n\t\tif (phba->sli4_hba.pc_sli4_params.cqv ==\n\t\t    LPFC_Q_CREATE_VERSION_2) {\n\t\t\tcq_create->u.request.context.lpfc_cq_context_count =\n\t\t\t\tcq->entry_count;\n\t\t\tbf_set(lpfc_cq_context_count,\n\t\t\t       &cq_create->u.request.context,\n\t\t\t       LPFC_CQ_CNT_WORD7);\n\t\t\tbreak;\n\t\t}\n\t\tfallthrough;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0361 Unsupported CQ count: \"\n\t\t\t\t\"entry cnt %d sz %d pg cnt %d\\n\",\n\t\t\t\tcq->entry_count, cq->entry_size,\n\t\t\t\tcq->page_count);\n\t\tif (cq->entry_count < 256) {\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tfallthrough;\t \n\tcase 256:\n\t\tbf_set(lpfc_cq_context_count, &cq_create->u.request.context,\n\t\t       LPFC_CQ_CNT_256);\n\t\tbreak;\n\tcase 512:\n\t\tbf_set(lpfc_cq_context_count, &cq_create->u.request.context,\n\t\t       LPFC_CQ_CNT_512);\n\t\tbreak;\n\tcase 1024:\n\t\tbf_set(lpfc_cq_context_count, &cq_create->u.request.context,\n\t\t       LPFC_CQ_CNT_1024);\n\t\tbreak;\n\t}\n\tlist_for_each_entry(dmabuf, &cq->page_list, list) {\n\t\tmemset(dmabuf->virt, 0, cq->page_size);\n\t\tcq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\n\t\t\t\t\tputPaddrLow(dmabuf->phys);\n\t\tcq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\n\t\t\t\t\tputPaddrHigh(dmabuf->phys);\n\t}\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\n\t \n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2501 CQ_CREATE mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\tcq->queue_id = bf_get(lpfc_mbx_cq_create_q_id, &cq_create->u.response);\n\tif (cq->queue_id == 0xFFFF) {\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\t \n\tlist_add_tail(&cq->list, &eq->child_list);\n\t \n\tcq->type = type;\n\tcq->subtype = subtype;\n\tcq->queue_id = bf_get(lpfc_mbx_cq_create_q_id, &cq_create->u.response);\n\tcq->assoc_qid = eq->queue_id;\n\tcq->assoc_qp = eq;\n\tcq->host_index = 0;\n\tcq->notify_interval = LPFC_CQ_NOTIFY_INTRVL;\n\tcq->max_proc_limit = min(phba->cfg_cq_max_proc_limit, cq->entry_count);\n\n\tif (cq->queue_id > phba->sli4_hba.cq_max)\n\t\tphba->sli4_hba.cq_max = cq->queue_id;\nout:\n\tmempool_free(mbox, phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nint\nlpfc_cq_create_set(struct lpfc_hba *phba, struct lpfc_queue **cqp,\n\t\t   struct lpfc_sli4_hdw_queue *hdwq, uint32_t type,\n\t\t   uint32_t subtype)\n{\n\tstruct lpfc_queue *cq;\n\tstruct lpfc_queue *eq;\n\tstruct lpfc_mbx_cq_create_set *cq_set;\n\tstruct lpfc_dmabuf *dmabuf;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, alloclen, status = 0;\n\tint cnt, idx, numcq, page_idx = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\n\n\t \n\tnumcq = phba->cfg_nvmet_mrq;\n\tif (!cqp || !hdwq || !numcq)\n\t\treturn -ENODEV;\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\n\tlength = sizeof(struct lpfc_mbx_cq_create_set);\n\tlength += ((numcq * cqp[0]->page_count) *\n\t\t   sizeof(struct dma_address));\n\talloclen = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\tLPFC_MBOX_OPCODE_FCOE_CQ_CREATE_SET, length,\n\t\t\tLPFC_SLI4_MBX_NEMBED);\n\tif (alloclen < length) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3098 Allocated DMA memory size (%d) is \"\n\t\t\t\t\"less than the requested DMA memory size \"\n\t\t\t\t\"(%d)\\n\", alloclen, length);\n\t\tstatus = -ENOMEM;\n\t\tgoto out;\n\t}\n\tcq_set = mbox->sge_array->addr[0];\n\tshdr = (union lpfc_sli4_cfg_shdr *)&cq_set->cfg_shdr;\n\tbf_set(lpfc_mbox_hdr_version, &shdr->request, 0);\n\n\tfor (idx = 0; idx < numcq; idx++) {\n\t\tcq = cqp[idx];\n\t\teq = hdwq[idx].hba_eq;\n\t\tif (!cq || !eq) {\n\t\t\tstatus = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tif (!phba->sli4_hba.pc_sli4_params.supported)\n\t\t\thw_page_size = cq->page_size;\n\n\t\tswitch (idx) {\n\t\tcase 0:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_page_size,\n\t\t\t       &cq_set->u.request,\n\t\t\t       (hw_page_size / SLI4_PAGE_SIZE));\n\t\t\tbf_set(lpfc_mbx_cq_create_set_num_pages,\n\t\t\t       &cq_set->u.request, cq->page_count);\n\t\t\tbf_set(lpfc_mbx_cq_create_set_evt,\n\t\t\t       &cq_set->u.request, 1);\n\t\t\tbf_set(lpfc_mbx_cq_create_set_valid,\n\t\t\t       &cq_set->u.request, 1);\n\t\t\tbf_set(lpfc_mbx_cq_create_set_cqe_size,\n\t\t\t       &cq_set->u.request, 0);\n\t\t\tbf_set(lpfc_mbx_cq_create_set_num_cq,\n\t\t\t       &cq_set->u.request, numcq);\n\t\t\tbf_set(lpfc_mbx_cq_create_set_autovalid,\n\t\t\t       &cq_set->u.request,\n\t\t\t       phba->sli4_hba.pc_sli4_params.cqav);\n\t\t\tswitch (cq->entry_count) {\n\t\t\tcase 2048:\n\t\t\tcase 4096:\n\t\t\t\tif (phba->sli4_hba.pc_sli4_params.cqv ==\n\t\t\t\t    LPFC_Q_CREATE_VERSION_2) {\n\t\t\t\t\tbf_set(lpfc_mbx_cq_create_set_cqe_cnt,\n\t\t\t\t\t       &cq_set->u.request,\n\t\t\t\t\t\tcq->entry_count);\n\t\t\t\t\tbf_set(lpfc_mbx_cq_create_set_cqe_cnt,\n\t\t\t\t\t       &cq_set->u.request,\n\t\t\t\t\t       LPFC_CQ_CNT_WORD7);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tfallthrough;\n\t\t\tdefault:\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3118 Bad CQ count. (%d)\\n\",\n\t\t\t\t\t\tcq->entry_count);\n\t\t\t\tif (cq->entry_count < 256) {\n\t\t\t\t\tstatus = -EINVAL;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tfallthrough;\t \n\t\t\tcase 256:\n\t\t\t\tbf_set(lpfc_mbx_cq_create_set_cqe_cnt,\n\t\t\t\t       &cq_set->u.request, LPFC_CQ_CNT_256);\n\t\t\t\tbreak;\n\t\t\tcase 512:\n\t\t\t\tbf_set(lpfc_mbx_cq_create_set_cqe_cnt,\n\t\t\t\t       &cq_set->u.request, LPFC_CQ_CNT_512);\n\t\t\t\tbreak;\n\t\t\tcase 1024:\n\t\t\t\tbf_set(lpfc_mbx_cq_create_set_cqe_cnt,\n\t\t\t\t       &cq_set->u.request, LPFC_CQ_CNT_1024);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id0,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id1,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id2,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id3,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id4,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 5:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id5,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 6:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id6,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 7:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id7,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id8,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 9:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id9,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 10:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id10,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 11:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id11,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 12:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id12,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 13:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id13,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 14:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id14,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\tcase 15:\n\t\t\tbf_set(lpfc_mbx_cq_create_set_eq_id15,\n\t\t\t       &cq_set->u.request, eq->queue_id);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tlist_add_tail(&cq->list, &eq->child_list);\n\t\t \n\t\tcq->type = type;\n\t\tcq->subtype = subtype;\n\t\tcq->assoc_qid = eq->queue_id;\n\t\tcq->assoc_qp = eq;\n\t\tcq->host_index = 0;\n\t\tcq->notify_interval = LPFC_CQ_NOTIFY_INTRVL;\n\t\tcq->max_proc_limit = min(phba->cfg_cq_max_proc_limit,\n\t\t\t\t\t cq->entry_count);\n\t\tcq->chann = idx;\n\n\t\trc = 0;\n\t\tlist_for_each_entry(dmabuf, &cq->page_list, list) {\n\t\t\tmemset(dmabuf->virt, 0, hw_page_size);\n\t\t\tcnt = page_idx + dmabuf->buffer_tag;\n\t\t\tcq_set->u.request.page[cnt].addr_lo =\n\t\t\t\t\tputPaddrLow(dmabuf->phys);\n\t\t\tcq_set->u.request.page[cnt].addr_hi =\n\t\t\t\t\tputPaddrHigh(dmabuf->phys);\n\t\t\trc++;\n\t\t}\n\t\tpage_idx += rc;\n\t}\n\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\n\t \n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3119 CQ_CREATE_SET mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\trc = bf_get(lpfc_mbx_cq_create_set_base_id, &cq_set->u.response);\n\tif (rc == 0xFFFF) {\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tfor (idx = 0; idx < numcq; idx++) {\n\t\tcq = cqp[idx];\n\t\tcq->queue_id = rc + idx;\n\t\tif (cq->queue_id > phba->sli4_hba.cq_max)\n\t\t\tphba->sli4_hba.cq_max = cq->queue_id;\n\t}\n\nout:\n\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\treturn status;\n}\n\n \nstatic void\nlpfc_mq_create_fb_init(struct lpfc_hba *phba, struct lpfc_queue *mq,\n\t\t       LPFC_MBOXQ_t *mbox, struct lpfc_queue *cq)\n{\n\tstruct lpfc_mbx_mq_create *mq_create;\n\tstruct lpfc_dmabuf *dmabuf;\n\tint length;\n\n\tlength = (sizeof(struct lpfc_mbx_mq_create) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_MQ_CREATE,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tmq_create = &mbox->u.mqe.un.mq_create;\n\tbf_set(lpfc_mbx_mq_create_num_pages, &mq_create->u.request,\n\t       mq->page_count);\n\tbf_set(lpfc_mq_context_cq_id, &mq_create->u.request.context,\n\t       cq->queue_id);\n\tbf_set(lpfc_mq_context_valid, &mq_create->u.request.context, 1);\n\tswitch (mq->entry_count) {\n\tcase 16:\n\t\tbf_set(lpfc_mq_context_ring_size, &mq_create->u.request.context,\n\t\t       LPFC_MQ_RING_SIZE_16);\n\t\tbreak;\n\tcase 32:\n\t\tbf_set(lpfc_mq_context_ring_size, &mq_create->u.request.context,\n\t\t       LPFC_MQ_RING_SIZE_32);\n\t\tbreak;\n\tcase 64:\n\t\tbf_set(lpfc_mq_context_ring_size, &mq_create->u.request.context,\n\t\t       LPFC_MQ_RING_SIZE_64);\n\t\tbreak;\n\tcase 128:\n\t\tbf_set(lpfc_mq_context_ring_size, &mq_create->u.request.context,\n\t\t       LPFC_MQ_RING_SIZE_128);\n\t\tbreak;\n\t}\n\tlist_for_each_entry(dmabuf, &mq->page_list, list) {\n\t\tmq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\n\t\t\tputPaddrLow(dmabuf->phys);\n\t\tmq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\n\t\t\tputPaddrHigh(dmabuf->phys);\n\t}\n}\n\n \nint32_t\nlpfc_mq_create(struct lpfc_hba *phba, struct lpfc_queue *mq,\n\t       struct lpfc_queue *cq, uint32_t subtype)\n{\n\tstruct lpfc_mbx_mq_create *mq_create;\n\tstruct lpfc_mbx_mq_create_ext *mq_create_ext;\n\tstruct lpfc_dmabuf *dmabuf;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\n\n\t \n\tif (!mq || !cq)\n\t\treturn -ENODEV;\n\tif (!phba->sli4_hba.pc_sli4_params.supported)\n\t\thw_page_size = SLI4_PAGE_SIZE;\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_mq_create_ext) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_MQ_CREATE_EXT,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\n\tmq_create_ext = &mbox->u.mqe.un.mq_create_ext;\n\tshdr = (union lpfc_sli4_cfg_shdr *) &mq_create_ext->header.cfg_shdr;\n\tbf_set(lpfc_mbx_mq_create_ext_num_pages,\n\t       &mq_create_ext->u.request, mq->page_count);\n\tbf_set(lpfc_mbx_mq_create_ext_async_evt_link,\n\t       &mq_create_ext->u.request, 1);\n\tbf_set(lpfc_mbx_mq_create_ext_async_evt_fip,\n\t       &mq_create_ext->u.request, 1);\n\tbf_set(lpfc_mbx_mq_create_ext_async_evt_group5,\n\t       &mq_create_ext->u.request, 1);\n\tbf_set(lpfc_mbx_mq_create_ext_async_evt_fc,\n\t       &mq_create_ext->u.request, 1);\n\tbf_set(lpfc_mbx_mq_create_ext_async_evt_sli,\n\t       &mq_create_ext->u.request, 1);\n\tbf_set(lpfc_mq_context_valid, &mq_create_ext->u.request.context, 1);\n\tbf_set(lpfc_mbox_hdr_version, &shdr->request,\n\t       phba->sli4_hba.pc_sli4_params.mqv);\n\tif (phba->sli4_hba.pc_sli4_params.mqv == LPFC_Q_CREATE_VERSION_1)\n\t\tbf_set(lpfc_mbx_mq_create_ext_cq_id, &mq_create_ext->u.request,\n\t\t       cq->queue_id);\n\telse\n\t\tbf_set(lpfc_mq_context_cq_id, &mq_create_ext->u.request.context,\n\t\t       cq->queue_id);\n\tswitch (mq->entry_count) {\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0362 Unsupported MQ count. (%d)\\n\",\n\t\t\t\tmq->entry_count);\n\t\tif (mq->entry_count < 16) {\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tfallthrough;\t \n\tcase 16:\n\t\tbf_set(lpfc_mq_context_ring_size,\n\t\t       &mq_create_ext->u.request.context,\n\t\t       LPFC_MQ_RING_SIZE_16);\n\t\tbreak;\n\tcase 32:\n\t\tbf_set(lpfc_mq_context_ring_size,\n\t\t       &mq_create_ext->u.request.context,\n\t\t       LPFC_MQ_RING_SIZE_32);\n\t\tbreak;\n\tcase 64:\n\t\tbf_set(lpfc_mq_context_ring_size,\n\t\t       &mq_create_ext->u.request.context,\n\t\t       LPFC_MQ_RING_SIZE_64);\n\t\tbreak;\n\tcase 128:\n\t\tbf_set(lpfc_mq_context_ring_size,\n\t\t       &mq_create_ext->u.request.context,\n\t\t       LPFC_MQ_RING_SIZE_128);\n\t\tbreak;\n\t}\n\tlist_for_each_entry(dmabuf, &mq->page_list, list) {\n\t\tmemset(dmabuf->virt, 0, hw_page_size);\n\t\tmq_create_ext->u.request.page[dmabuf->buffer_tag].addr_lo =\n\t\t\t\t\tputPaddrLow(dmabuf->phys);\n\t\tmq_create_ext->u.request.page[dmabuf->buffer_tag].addr_hi =\n\t\t\t\t\tputPaddrHigh(dmabuf->phys);\n\t}\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\tmq->queue_id = bf_get(lpfc_mbx_mq_create_q_id,\n\t\t\t      &mq_create_ext->u.response);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"2795 MQ_CREATE_EXT failed with \"\n\t\t\t\t\"status x%x. Failback to MQ_CREATE.\\n\",\n\t\t\t\trc);\n\t\tlpfc_mq_create_fb_init(phba, mq, mbox, cq);\n\t\tmq_create = &mbox->u.mqe.un.mq_create;\n\t\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\t\tshdr = (union lpfc_sli4_cfg_shdr *) &mq_create->header.cfg_shdr;\n\t\tmq->queue_id = bf_get(lpfc_mbx_mq_create_q_id,\n\t\t\t\t      &mq_create->u.response);\n\t}\n\n\t \n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2502 MQ_CREATE mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\tif (mq->queue_id == 0xFFFF) {\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\tmq->type = LPFC_MQ;\n\tmq->assoc_qid = cq->queue_id;\n\tmq->subtype = subtype;\n\tmq->host_index = 0;\n\tmq->hba_index = 0;\n\n\t \n\tlist_add_tail(&mq->list, &cq->child_list);\nout:\n\tmempool_free(mbox, phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nint\nlpfc_wq_create(struct lpfc_hba *phba, struct lpfc_queue *wq,\n\t       struct lpfc_queue *cq, uint32_t subtype)\n{\n\tstruct lpfc_mbx_wq_create *wq_create;\n\tstruct lpfc_dmabuf *dmabuf;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\n\tstruct dma_address *page;\n\tvoid __iomem *bar_memmap_p;\n\tuint32_t db_offset;\n\tuint16_t pci_barset;\n\tuint8_t dpp_barset;\n\tuint32_t dpp_offset;\n\tuint8_t wq_create_version;\n#ifdef CONFIG_X86\n\tunsigned long pg_addr;\n#endif\n\n\t \n\tif (!wq || !cq)\n\t\treturn -ENODEV;\n\tif (!phba->sli4_hba.pc_sli4_params.supported)\n\t\thw_page_size = wq->page_size;\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_wq_create) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t LPFC_MBOX_OPCODE_FCOE_WQ_CREATE,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\twq_create = &mbox->u.mqe.un.wq_create;\n\tshdr = (union lpfc_sli4_cfg_shdr *) &wq_create->header.cfg_shdr;\n\tbf_set(lpfc_mbx_wq_create_num_pages, &wq_create->u.request,\n\t\t    wq->page_count);\n\tbf_set(lpfc_mbx_wq_create_cq_id, &wq_create->u.request,\n\t\t    cq->queue_id);\n\n\t \n\tbf_set(lpfc_mbox_hdr_version, &shdr->request,\n\t       phba->sli4_hba.pc_sli4_params.wqv);\n\n\tif ((phba->sli4_hba.pc_sli4_params.wqsize & LPFC_WQ_SZ128_SUPPORT) ||\n\t    (wq->page_size > SLI4_PAGE_SIZE))\n\t\twq_create_version = LPFC_Q_CREATE_VERSION_1;\n\telse\n\t\twq_create_version = LPFC_Q_CREATE_VERSION_0;\n\n\tswitch (wq_create_version) {\n\tcase LPFC_Q_CREATE_VERSION_1:\n\t\tbf_set(lpfc_mbx_wq_create_wqe_count, &wq_create->u.request_1,\n\t\t       wq->entry_count);\n\t\tbf_set(lpfc_mbox_hdr_version, &shdr->request,\n\t\t       LPFC_Q_CREATE_VERSION_1);\n\n\t\tswitch (wq->entry_size) {\n\t\tdefault:\n\t\tcase 64:\n\t\t\tbf_set(lpfc_mbx_wq_create_wqe_size,\n\t\t\t       &wq_create->u.request_1,\n\t\t\t       LPFC_WQ_WQE_SIZE_64);\n\t\t\tbreak;\n\t\tcase 128:\n\t\t\tbf_set(lpfc_mbx_wq_create_wqe_size,\n\t\t\t       &wq_create->u.request_1,\n\t\t\t       LPFC_WQ_WQE_SIZE_128);\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tbf_set(lpfc_mbx_wq_create_dpp_req, &wq_create->u.request_1, 1);\n\t\tbf_set(lpfc_mbx_wq_create_page_size,\n\t\t       &wq_create->u.request_1,\n\t\t       (wq->page_size / SLI4_PAGE_SIZE));\n\t\tpage = wq_create->u.request_1.page;\n\t\tbreak;\n\tdefault:\n\t\tpage = wq_create->u.request.page;\n\t\tbreak;\n\t}\n\n\tlist_for_each_entry(dmabuf, &wq->page_list, list) {\n\t\tmemset(dmabuf->virt, 0, hw_page_size);\n\t\tpage[dmabuf->buffer_tag].addr_lo = putPaddrLow(dmabuf->phys);\n\t\tpage[dmabuf->buffer_tag].addr_hi = putPaddrHigh(dmabuf->phys);\n\t}\n\n\tif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE)\n\t\tbf_set(lpfc_mbx_wq_create_dua, &wq_create->u.request, 1);\n\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\t \n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2503 WQ_CREATE mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tif (wq_create_version == LPFC_Q_CREATE_VERSION_0)\n\t\twq->queue_id = bf_get(lpfc_mbx_wq_create_q_id,\n\t\t\t\t\t&wq_create->u.response);\n\telse\n\t\twq->queue_id = bf_get(lpfc_mbx_wq_create_v1_q_id,\n\t\t\t\t\t&wq_create->u.response_1);\n\n\tif (wq->queue_id == 0xFFFF) {\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\n\twq->db_format = LPFC_DB_LIST_FORMAT;\n\tif (wq_create_version == LPFC_Q_CREATE_VERSION_0) {\n\t\tif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE) {\n\t\t\twq->db_format = bf_get(lpfc_mbx_wq_create_db_format,\n\t\t\t\t\t       &wq_create->u.response);\n\t\t\tif ((wq->db_format != LPFC_DB_LIST_FORMAT) &&\n\t\t\t    (wq->db_format != LPFC_DB_RING_FORMAT)) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3265 WQ[%d] doorbell format \"\n\t\t\t\t\t\t\"not supported: x%x\\n\",\n\t\t\t\t\t\twq->queue_id, wq->db_format);\n\t\t\t\tstatus = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tpci_barset = bf_get(lpfc_mbx_wq_create_bar_set,\n\t\t\t\t\t    &wq_create->u.response);\n\t\t\tbar_memmap_p = lpfc_dual_chute_pci_bar_map(phba,\n\t\t\t\t\t\t\t\t   pci_barset);\n\t\t\tif (!bar_memmap_p) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3263 WQ[%d] failed to memmap \"\n\t\t\t\t\t\t\"pci barset:x%x\\n\",\n\t\t\t\t\t\twq->queue_id, pci_barset);\n\t\t\t\tstatus = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tdb_offset = wq_create->u.response.doorbell_offset;\n\t\t\tif ((db_offset != LPFC_ULP0_WQ_DOORBELL) &&\n\t\t\t    (db_offset != LPFC_ULP1_WQ_DOORBELL)) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3252 WQ[%d] doorbell offset \"\n\t\t\t\t\t\t\"not supported: x%x\\n\",\n\t\t\t\t\t\twq->queue_id, db_offset);\n\t\t\t\tstatus = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\twq->db_regaddr = bar_memmap_p + db_offset;\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"3264 WQ[%d]: barset:x%x, offset:x%x, \"\n\t\t\t\t\t\"format:x%x\\n\", wq->queue_id,\n\t\t\t\t\tpci_barset, db_offset, wq->db_format);\n\t\t} else\n\t\t\twq->db_regaddr = phba->sli4_hba.WQDBregaddr;\n\t} else {\n\t\t \n\t\twq->dpp_enable = bf_get(lpfc_mbx_wq_create_dpp_rsp,\n\t\t\t\t    &wq_create->u.response_1);\n\t\tif (wq->dpp_enable) {\n\t\t\tpci_barset = bf_get(lpfc_mbx_wq_create_v1_bar_set,\n\t\t\t\t\t    &wq_create->u.response_1);\n\t\t\tbar_memmap_p = lpfc_dual_chute_pci_bar_map(phba,\n\t\t\t\t\t\t\t\t   pci_barset);\n\t\t\tif (!bar_memmap_p) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3267 WQ[%d] failed to memmap \"\n\t\t\t\t\t\t\"pci barset:x%x\\n\",\n\t\t\t\t\t\twq->queue_id, pci_barset);\n\t\t\t\tstatus = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tdb_offset = wq_create->u.response_1.doorbell_offset;\n\t\t\twq->db_regaddr = bar_memmap_p + db_offset;\n\t\t\twq->dpp_id = bf_get(lpfc_mbx_wq_create_dpp_id,\n\t\t\t\t\t    &wq_create->u.response_1);\n\t\t\tdpp_barset = bf_get(lpfc_mbx_wq_create_dpp_bar,\n\t\t\t\t\t    &wq_create->u.response_1);\n\t\t\tbar_memmap_p = lpfc_dual_chute_pci_bar_map(phba,\n\t\t\t\t\t\t\t\t   dpp_barset);\n\t\t\tif (!bar_memmap_p) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3268 WQ[%d] failed to memmap \"\n\t\t\t\t\t\t\"pci barset:x%x\\n\",\n\t\t\t\t\t\twq->queue_id, dpp_barset);\n\t\t\t\tstatus = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tdpp_offset = wq_create->u.response_1.dpp_offset;\n\t\t\twq->dpp_regaddr = bar_memmap_p + dpp_offset;\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"3271 WQ[%d]: barset:x%x, offset:x%x, \"\n\t\t\t\t\t\"dpp_id:x%x dpp_barset:x%x \"\n\t\t\t\t\t\"dpp_offset:x%x\\n\",\n\t\t\t\t\twq->queue_id, pci_barset, db_offset,\n\t\t\t\t\twq->dpp_id, dpp_barset, dpp_offset);\n\n#ifdef CONFIG_X86\n\t\t\t \n\t\t\tpg_addr = (unsigned long)(wq->dpp_regaddr) & PAGE_MASK;\n\t\t\trc = set_memory_wc(pg_addr, 1);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\t\"3272 Cannot setup Combined \"\n\t\t\t\t\t\"Write on WQ[%d] - disable DPP\\n\",\n\t\t\t\t\twq->queue_id);\n\t\t\t\tphba->cfg_enable_dpp = 0;\n\t\t\t}\n#else\n\t\t\tphba->cfg_enable_dpp = 0;\n#endif\n\t\t} else\n\t\t\twq->db_regaddr = phba->sli4_hba.WQDBregaddr;\n\t}\n\twq->pring = kzalloc(sizeof(struct lpfc_sli_ring), GFP_KERNEL);\n\tif (wq->pring == NULL) {\n\t\tstatus = -ENOMEM;\n\t\tgoto out;\n\t}\n\twq->type = LPFC_WQ;\n\twq->assoc_qid = cq->queue_id;\n\twq->subtype = subtype;\n\twq->host_index = 0;\n\twq->hba_index = 0;\n\twq->notify_interval = LPFC_WQ_NOTIFY_INTRVL;\n\n\t \n\tlist_add_tail(&wq->list, &cq->child_list);\nout:\n\tmempool_free(mbox, phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nint\nlpfc_rq_create(struct lpfc_hba *phba, struct lpfc_queue *hrq,\n\t       struct lpfc_queue *drq, struct lpfc_queue *cq, uint32_t subtype)\n{\n\tstruct lpfc_mbx_rq_create *rq_create;\n\tstruct lpfc_dmabuf *dmabuf;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\n\tvoid __iomem *bar_memmap_p;\n\tuint32_t db_offset;\n\tuint16_t pci_barset;\n\n\t \n\tif (!hrq || !drq || !cq)\n\t\treturn -ENODEV;\n\tif (!phba->sli4_hba.pc_sli4_params.supported)\n\t\thw_page_size = SLI4_PAGE_SIZE;\n\n\tif (hrq->entry_count != drq->entry_count)\n\t\treturn -EINVAL;\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_rq_create) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t LPFC_MBOX_OPCODE_FCOE_RQ_CREATE,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\trq_create = &mbox->u.mqe.un.rq_create;\n\tshdr = (union lpfc_sli4_cfg_shdr *) &rq_create->header.cfg_shdr;\n\tbf_set(lpfc_mbox_hdr_version, &shdr->request,\n\t       phba->sli4_hba.pc_sli4_params.rqv);\n\tif (phba->sli4_hba.pc_sli4_params.rqv == LPFC_Q_CREATE_VERSION_1) {\n\t\tbf_set(lpfc_rq_context_rqe_count_1,\n\t\t       &rq_create->u.request.context,\n\t\t       hrq->entry_count);\n\t\trq_create->u.request.context.buffer_size = LPFC_HDR_BUF_SIZE;\n\t\tbf_set(lpfc_rq_context_rqe_size,\n\t\t       &rq_create->u.request.context,\n\t\t       LPFC_RQE_SIZE_8);\n\t\tbf_set(lpfc_rq_context_page_size,\n\t\t       &rq_create->u.request.context,\n\t\t       LPFC_RQ_PAGE_SIZE_4096);\n\t} else {\n\t\tswitch (hrq->entry_count) {\n\t\tdefault:\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2535 Unsupported RQ count. (%d)\\n\",\n\t\t\t\t\thrq->entry_count);\n\t\t\tif (hrq->entry_count < 512) {\n\t\t\t\tstatus = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tfallthrough;\t \n\t\tcase 512:\n\t\t\tbf_set(lpfc_rq_context_rqe_count,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_RQ_RING_SIZE_512);\n\t\t\tbreak;\n\t\tcase 1024:\n\t\t\tbf_set(lpfc_rq_context_rqe_count,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_RQ_RING_SIZE_1024);\n\t\t\tbreak;\n\t\tcase 2048:\n\t\t\tbf_set(lpfc_rq_context_rqe_count,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_RQ_RING_SIZE_2048);\n\t\t\tbreak;\n\t\tcase 4096:\n\t\t\tbf_set(lpfc_rq_context_rqe_count,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_RQ_RING_SIZE_4096);\n\t\t\tbreak;\n\t\t}\n\t\tbf_set(lpfc_rq_context_buf_size, &rq_create->u.request.context,\n\t\t       LPFC_HDR_BUF_SIZE);\n\t}\n\tbf_set(lpfc_rq_context_cq_id, &rq_create->u.request.context,\n\t       cq->queue_id);\n\tbf_set(lpfc_mbx_rq_create_num_pages, &rq_create->u.request,\n\t       hrq->page_count);\n\tlist_for_each_entry(dmabuf, &hrq->page_list, list) {\n\t\tmemset(dmabuf->virt, 0, hw_page_size);\n\t\trq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\n\t\t\t\t\tputPaddrLow(dmabuf->phys);\n\t\trq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\n\t\t\t\t\tputPaddrHigh(dmabuf->phys);\n\t}\n\tif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE)\n\t\tbf_set(lpfc_mbx_rq_create_dua, &rq_create->u.request, 1);\n\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\t \n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2504 RQ_CREATE mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\thrq->queue_id = bf_get(lpfc_mbx_rq_create_q_id, &rq_create->u.response);\n\tif (hrq->queue_id == 0xFFFF) {\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE) {\n\t\thrq->db_format = bf_get(lpfc_mbx_rq_create_db_format,\n\t\t\t\t\t&rq_create->u.response);\n\t\tif ((hrq->db_format != LPFC_DB_LIST_FORMAT) &&\n\t\t    (hrq->db_format != LPFC_DB_RING_FORMAT)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3262 RQ [%d] doorbell format not \"\n\t\t\t\t\t\"supported: x%x\\n\", hrq->queue_id,\n\t\t\t\t\thrq->db_format);\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tpci_barset = bf_get(lpfc_mbx_rq_create_bar_set,\n\t\t\t\t    &rq_create->u.response);\n\t\tbar_memmap_p = lpfc_dual_chute_pci_bar_map(phba, pci_barset);\n\t\tif (!bar_memmap_p) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3269 RQ[%d] failed to memmap pci \"\n\t\t\t\t\t\"barset:x%x\\n\", hrq->queue_id,\n\t\t\t\t\tpci_barset);\n\t\t\tstatus = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\tdb_offset = rq_create->u.response.doorbell_offset;\n\t\tif ((db_offset != LPFC_ULP0_RQ_DOORBELL) &&\n\t\t    (db_offset != LPFC_ULP1_RQ_DOORBELL)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3270 RQ[%d] doorbell offset not \"\n\t\t\t\t\t\"supported: x%x\\n\", hrq->queue_id,\n\t\t\t\t\tdb_offset);\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\thrq->db_regaddr = bar_memmap_p + db_offset;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3266 RQ[qid:%d]: barset:x%x, offset:x%x, \"\n\t\t\t\t\"format:x%x\\n\", hrq->queue_id, pci_barset,\n\t\t\t\tdb_offset, hrq->db_format);\n\t} else {\n\t\thrq->db_format = LPFC_DB_RING_FORMAT;\n\t\thrq->db_regaddr = phba->sli4_hba.RQDBregaddr;\n\t}\n\thrq->type = LPFC_HRQ;\n\thrq->assoc_qid = cq->queue_id;\n\thrq->subtype = subtype;\n\thrq->host_index = 0;\n\thrq->hba_index = 0;\n\thrq->notify_interval = LPFC_RQ_NOTIFY_INTRVL;\n\n\t \n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t LPFC_MBOX_OPCODE_FCOE_RQ_CREATE,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tbf_set(lpfc_mbox_hdr_version, &shdr->request,\n\t       phba->sli4_hba.pc_sli4_params.rqv);\n\tif (phba->sli4_hba.pc_sli4_params.rqv == LPFC_Q_CREATE_VERSION_1) {\n\t\tbf_set(lpfc_rq_context_rqe_count_1,\n\t\t       &rq_create->u.request.context, hrq->entry_count);\n\t\tif (subtype == LPFC_NVMET)\n\t\t\trq_create->u.request.context.buffer_size =\n\t\t\t\tLPFC_NVMET_DATA_BUF_SIZE;\n\t\telse\n\t\t\trq_create->u.request.context.buffer_size =\n\t\t\t\tLPFC_DATA_BUF_SIZE;\n\t\tbf_set(lpfc_rq_context_rqe_size, &rq_create->u.request.context,\n\t\t       LPFC_RQE_SIZE_8);\n\t\tbf_set(lpfc_rq_context_page_size, &rq_create->u.request.context,\n\t\t       (PAGE_SIZE/SLI4_PAGE_SIZE));\n\t} else {\n\t\tswitch (drq->entry_count) {\n\t\tdefault:\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2536 Unsupported RQ count. (%d)\\n\",\n\t\t\t\t\tdrq->entry_count);\n\t\t\tif (drq->entry_count < 512) {\n\t\t\t\tstatus = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tfallthrough;\t \n\t\tcase 512:\n\t\t\tbf_set(lpfc_rq_context_rqe_count,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_RQ_RING_SIZE_512);\n\t\t\tbreak;\n\t\tcase 1024:\n\t\t\tbf_set(lpfc_rq_context_rqe_count,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_RQ_RING_SIZE_1024);\n\t\t\tbreak;\n\t\tcase 2048:\n\t\t\tbf_set(lpfc_rq_context_rqe_count,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_RQ_RING_SIZE_2048);\n\t\t\tbreak;\n\t\tcase 4096:\n\t\t\tbf_set(lpfc_rq_context_rqe_count,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_RQ_RING_SIZE_4096);\n\t\t\tbreak;\n\t\t}\n\t\tif (subtype == LPFC_NVMET)\n\t\t\tbf_set(lpfc_rq_context_buf_size,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_NVMET_DATA_BUF_SIZE);\n\t\telse\n\t\t\tbf_set(lpfc_rq_context_buf_size,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_DATA_BUF_SIZE);\n\t}\n\tbf_set(lpfc_rq_context_cq_id, &rq_create->u.request.context,\n\t       cq->queue_id);\n\tbf_set(lpfc_mbx_rq_create_num_pages, &rq_create->u.request,\n\t       drq->page_count);\n\tlist_for_each_entry(dmabuf, &drq->page_list, list) {\n\t\trq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\n\t\t\t\t\tputPaddrLow(dmabuf->phys);\n\t\trq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\n\t\t\t\t\tputPaddrHigh(dmabuf->phys);\n\t}\n\tif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE)\n\t\tbf_set(lpfc_mbx_rq_create_dua, &rq_create->u.request, 1);\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\t \n\tshdr = (union lpfc_sli4_cfg_shdr *) &rq_create->header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\tdrq->queue_id = bf_get(lpfc_mbx_rq_create_q_id, &rq_create->u.response);\n\tif (drq->queue_id == 0xFFFF) {\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\tdrq->type = LPFC_DRQ;\n\tdrq->assoc_qid = cq->queue_id;\n\tdrq->subtype = subtype;\n\tdrq->host_index = 0;\n\tdrq->hba_index = 0;\n\tdrq->notify_interval = LPFC_RQ_NOTIFY_INTRVL;\n\n\t \n\tlist_add_tail(&hrq->list, &cq->child_list);\n\tlist_add_tail(&drq->list, &cq->child_list);\n\nout:\n\tmempool_free(mbox, phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nint\nlpfc_mrq_create(struct lpfc_hba *phba, struct lpfc_queue **hrqp,\n\t\tstruct lpfc_queue **drqp, struct lpfc_queue **cqp,\n\t\tuint32_t subtype)\n{\n\tstruct lpfc_queue *hrq, *drq, *cq;\n\tstruct lpfc_mbx_rq_create_v2 *rq_create;\n\tstruct lpfc_dmabuf *dmabuf;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, alloclen, status = 0;\n\tint cnt, idx, numrq, page_idx = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\n\n\tnumrq = phba->cfg_nvmet_mrq;\n\t \n\tif (!hrqp || !drqp || !cqp || !numrq)\n\t\treturn -ENODEV;\n\tif (!phba->sli4_hba.pc_sli4_params.supported)\n\t\thw_page_size = SLI4_PAGE_SIZE;\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\n\tlength = sizeof(struct lpfc_mbx_rq_create_v2);\n\tlength += ((2 * numrq * hrqp[0]->page_count) *\n\t\t   sizeof(struct dma_address));\n\n\talloclen = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t\t    LPFC_MBOX_OPCODE_FCOE_RQ_CREATE, length,\n\t\t\t\t    LPFC_SLI4_MBX_NEMBED);\n\tif (alloclen < length) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3099 Allocated DMA memory size (%d) is \"\n\t\t\t\t\"less than the requested DMA memory size \"\n\t\t\t\t\"(%d)\\n\", alloclen, length);\n\t\tstatus = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\n\n\trq_create = mbox->sge_array->addr[0];\n\tshdr = (union lpfc_sli4_cfg_shdr *)&rq_create->cfg_shdr;\n\n\tbf_set(lpfc_mbox_hdr_version, &shdr->request, LPFC_Q_CREATE_VERSION_2);\n\tcnt = 0;\n\n\tfor (idx = 0; idx < numrq; idx++) {\n\t\thrq = hrqp[idx];\n\t\tdrq = drqp[idx];\n\t\tcq  = cqp[idx];\n\n\t\t \n\t\tif (!hrq || !drq || !cq) {\n\t\t\tstatus = -ENODEV;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (hrq->entry_count != drq->entry_count) {\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (idx == 0) {\n\t\t\tbf_set(lpfc_mbx_rq_create_num_pages,\n\t\t\t       &rq_create->u.request,\n\t\t\t       hrq->page_count);\n\t\t\tbf_set(lpfc_mbx_rq_create_rq_cnt,\n\t\t\t       &rq_create->u.request, (numrq * 2));\n\t\t\tbf_set(lpfc_mbx_rq_create_dnb, &rq_create->u.request,\n\t\t\t       1);\n\t\t\tbf_set(lpfc_rq_context_base_cq,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       cq->queue_id);\n\t\t\tbf_set(lpfc_rq_context_data_size,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_NVMET_DATA_BUF_SIZE);\n\t\t\tbf_set(lpfc_rq_context_hdr_size,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_HDR_BUF_SIZE);\n\t\t\tbf_set(lpfc_rq_context_rqe_count_1,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       hrq->entry_count);\n\t\t\tbf_set(lpfc_rq_context_rqe_size,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       LPFC_RQE_SIZE_8);\n\t\t\tbf_set(lpfc_rq_context_page_size,\n\t\t\t       &rq_create->u.request.context,\n\t\t\t       (PAGE_SIZE/SLI4_PAGE_SIZE));\n\t\t}\n\t\trc = 0;\n\t\tlist_for_each_entry(dmabuf, &hrq->page_list, list) {\n\t\t\tmemset(dmabuf->virt, 0, hw_page_size);\n\t\t\tcnt = page_idx + dmabuf->buffer_tag;\n\t\t\trq_create->u.request.page[cnt].addr_lo =\n\t\t\t\t\tputPaddrLow(dmabuf->phys);\n\t\t\trq_create->u.request.page[cnt].addr_hi =\n\t\t\t\t\tputPaddrHigh(dmabuf->phys);\n\t\t\trc++;\n\t\t}\n\t\tpage_idx += rc;\n\n\t\trc = 0;\n\t\tlist_for_each_entry(dmabuf, &drq->page_list, list) {\n\t\t\tmemset(dmabuf->virt, 0, hw_page_size);\n\t\t\tcnt = page_idx + dmabuf->buffer_tag;\n\t\t\trq_create->u.request.page[cnt].addr_lo =\n\t\t\t\t\tputPaddrLow(dmabuf->phys);\n\t\t\trq_create->u.request.page[cnt].addr_hi =\n\t\t\t\t\tputPaddrHigh(dmabuf->phys);\n\t\t\trc++;\n\t\t}\n\t\tpage_idx += rc;\n\n\t\thrq->db_format = LPFC_DB_RING_FORMAT;\n\t\thrq->db_regaddr = phba->sli4_hba.RQDBregaddr;\n\t\thrq->type = LPFC_HRQ;\n\t\thrq->assoc_qid = cq->queue_id;\n\t\thrq->subtype = subtype;\n\t\thrq->host_index = 0;\n\t\thrq->hba_index = 0;\n\t\thrq->notify_interval = LPFC_RQ_NOTIFY_INTRVL;\n\n\t\tdrq->db_format = LPFC_DB_RING_FORMAT;\n\t\tdrq->db_regaddr = phba->sli4_hba.RQDBregaddr;\n\t\tdrq->type = LPFC_DRQ;\n\t\tdrq->assoc_qid = cq->queue_id;\n\t\tdrq->subtype = subtype;\n\t\tdrq->host_index = 0;\n\t\tdrq->hba_index = 0;\n\t\tdrq->notify_interval = LPFC_RQ_NOTIFY_INTRVL;\n\n\t\tlist_add_tail(&hrq->list, &cq->child_list);\n\t\tlist_add_tail(&drq->list, &cq->child_list);\n\t}\n\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\t \n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3120 RQ_CREATE mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\trc = bf_get(lpfc_mbx_rq_create_q_id, &rq_create->u.response);\n\tif (rc == 0xFFFF) {\n\t\tstatus = -ENXIO;\n\t\tgoto out;\n\t}\n\n\t \n\tfor (idx = 0; idx < numrq; idx++) {\n\t\thrq = hrqp[idx];\n\t\thrq->queue_id = rc + (2 * idx);\n\t\tdrq = drqp[idx];\n\t\tdrq->queue_id = rc + (2 * idx) + 1;\n\t}\n\nout:\n\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\treturn status;\n}\n\n \nint\nlpfc_eq_destroy(struct lpfc_hba *phba, struct lpfc_queue *eq)\n{\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\t \n\tif (!eq)\n\t\treturn -ENODEV;\n\n\tmbox = mempool_alloc(eq->phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_eq_destroy) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_EQ_DESTROY,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tbf_set(lpfc_mbx_eq_destroy_q_id, &mbox->u.mqe.un.eq_destroy.u.request,\n\t       eq->queue_id);\n\tmbox->vport = eq->phba->pport;\n\tmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\n\trc = lpfc_sli_issue_mbox(eq->phba, mbox, MBX_POLL);\n\t \n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&mbox->u.mqe.un.eq_destroy.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2505 EQ_DESTROY mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t}\n\n\t \n\tlist_del_init(&eq->list);\n\tmempool_free(mbox, eq->phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nint\nlpfc_cq_destroy(struct lpfc_hba *phba, struct lpfc_queue *cq)\n{\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\t \n\tif (!cq)\n\t\treturn -ENODEV;\n\tmbox = mempool_alloc(cq->phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_cq_destroy) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_CQ_DESTROY,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tbf_set(lpfc_mbx_cq_destroy_q_id, &mbox->u.mqe.un.cq_destroy.u.request,\n\t       cq->queue_id);\n\tmbox->vport = cq->phba->pport;\n\tmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\trc = lpfc_sli_issue_mbox(cq->phba, mbox, MBX_POLL);\n\t \n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&mbox->u.mqe.un.wq_create.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2506 CQ_DESTROY mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t}\n\t \n\tlist_del_init(&cq->list);\n\tmempool_free(mbox, cq->phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nint\nlpfc_mq_destroy(struct lpfc_hba *phba, struct lpfc_queue *mq)\n{\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\t \n\tif (!mq)\n\t\treturn -ENODEV;\n\tmbox = mempool_alloc(mq->phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_mq_destroy) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_MQ_DESTROY,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tbf_set(lpfc_mbx_mq_destroy_q_id, &mbox->u.mqe.un.mq_destroy.u.request,\n\t       mq->queue_id);\n\tmbox->vport = mq->phba->pport;\n\tmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\trc = lpfc_sli_issue_mbox(mq->phba, mbox, MBX_POLL);\n\t \n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&mbox->u.mqe.un.mq_destroy.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2507 MQ_DESTROY mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t}\n\t \n\tlist_del_init(&mq->list);\n\tmempool_free(mbox, mq->phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nint\nlpfc_wq_destroy(struct lpfc_hba *phba, struct lpfc_queue *wq)\n{\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\t \n\tif (!wq)\n\t\treturn -ENODEV;\n\tmbox = mempool_alloc(wq->phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_wq_destroy) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t LPFC_MBOX_OPCODE_FCOE_WQ_DESTROY,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tbf_set(lpfc_mbx_wq_destroy_q_id, &mbox->u.mqe.un.wq_destroy.u.request,\n\t       wq->queue_id);\n\tmbox->vport = wq->phba->pport;\n\tmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\trc = lpfc_sli_issue_mbox(wq->phba, mbox, MBX_POLL);\n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&mbox->u.mqe.un.wq_destroy.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2508 WQ_DESTROY mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t}\n\t \n\tlist_del_init(&wq->list);\n\tkfree(wq->pring);\n\twq->pring = NULL;\n\tmempool_free(mbox, wq->phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nint\nlpfc_rq_destroy(struct lpfc_hba *phba, struct lpfc_queue *hrq,\n\t\tstruct lpfc_queue *drq)\n{\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, status = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\t \n\tif (!hrq || !drq)\n\t\treturn -ENODEV;\n\tmbox = mempool_alloc(hrq->phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_rq_destroy) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t LPFC_MBOX_OPCODE_FCOE_RQ_DESTROY,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tbf_set(lpfc_mbx_rq_destroy_q_id, &mbox->u.mqe.un.rq_destroy.u.request,\n\t       hrq->queue_id);\n\tmbox->vport = hrq->phba->pport;\n\tmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\trc = lpfc_sli_issue_mbox(hrq->phba, mbox, MBX_POLL);\n\t \n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&mbox->u.mqe.un.rq_destroy.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2509 RQ_DESTROY mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tmempool_free(mbox, hrq->phba->mbox_mem_pool);\n\t\treturn -ENXIO;\n\t}\n\tbf_set(lpfc_mbx_rq_destroy_q_id, &mbox->u.mqe.un.rq_destroy.u.request,\n\t       drq->queue_id);\n\trc = lpfc_sli_issue_mbox(drq->phba, mbox, MBX_POLL);\n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t&mbox->u.mqe.un.rq_destroy.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2510 RQ_DESTROY mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tstatus = -ENXIO;\n\t}\n\tlist_del_init(&hrq->list);\n\tlist_del_init(&drq->list);\n\tmempool_free(mbox, hrq->phba->mbox_mem_pool);\n\treturn status;\n}\n\n \nint\nlpfc_sli4_post_sgl(struct lpfc_hba *phba,\n\t\tdma_addr_t pdma_phys_addr0,\n\t\tdma_addr_t pdma_phys_addr1,\n\t\tuint16_t xritag)\n{\n\tstruct lpfc_mbx_post_sgl_pages *post_sgl_pages;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc;\n\tuint32_t shdr_status, shdr_add_status;\n\tuint32_t mbox_tmo;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\tif (xritag == NO_XRI) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0364 Invalid param:\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\tLPFC_MBOX_OPCODE_FCOE_POST_SGL_PAGES,\n\t\t\tsizeof(struct lpfc_mbx_post_sgl_pages) -\n\t\t\tsizeof(struct lpfc_sli4_cfg_mhdr), LPFC_SLI4_MBX_EMBED);\n\n\tpost_sgl_pages = (struct lpfc_mbx_post_sgl_pages *)\n\t\t\t\t&mbox->u.mqe.un.post_sgl_pages;\n\tbf_set(lpfc_post_sgl_pages_xri, post_sgl_pages, xritag);\n\tbf_set(lpfc_post_sgl_pages_xricnt, post_sgl_pages, 1);\n\n\tpost_sgl_pages->sgl_pg_pairs[0].sgl_pg0_addr_lo\t=\n\t\t\t\tcpu_to_le32(putPaddrLow(pdma_phys_addr0));\n\tpost_sgl_pages->sgl_pg_pairs[0].sgl_pg0_addr_hi =\n\t\t\t\tcpu_to_le32(putPaddrHigh(pdma_phys_addr0));\n\n\tpost_sgl_pages->sgl_pg_pairs[0].sgl_pg1_addr_lo\t=\n\t\t\t\tcpu_to_le32(putPaddrLow(pdma_phys_addr1));\n\tpost_sgl_pages->sgl_pg_pairs[0].sgl_pg1_addr_hi =\n\t\t\t\tcpu_to_le32(putPaddrHigh(pdma_phys_addr1));\n\tif (!phba->sli4_hba.intr_enable)\n\t\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\n\t}\n\t \n\tshdr = (union lpfc_sli4_cfg_shdr *) &post_sgl_pages->header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (!phba->sli4_hba.intr_enable)\n\t\tmempool_free(mbox, phba->mbox_mem_pool);\n\telse if (rc != MBX_TIMEOUT)\n\t\tmempool_free(mbox, phba->mbox_mem_pool);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2511 POST_SGL mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t}\n\treturn 0;\n}\n\n \nstatic uint16_t\nlpfc_sli4_alloc_xri(struct lpfc_hba *phba)\n{\n\tunsigned long xri;\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\txri = find_first_zero_bit(phba->sli4_hba.xri_bmask,\n\t\t\t\t phba->sli4_hba.max_cfg_param.max_xri);\n\tif (xri >= phba->sli4_hba.max_cfg_param.max_xri) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn NO_XRI;\n\t} else {\n\t\tset_bit(xri, phba->sli4_hba.xri_bmask);\n\t\tphba->sli4_hba.max_cfg_param.xri_used++;\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\treturn xri;\n}\n\n \nstatic void\n__lpfc_sli4_free_xri(struct lpfc_hba *phba, int xri)\n{\n\tif (test_and_clear_bit(xri, phba->sli4_hba.xri_bmask)) {\n\t\tphba->sli4_hba.max_cfg_param.xri_used--;\n\t}\n}\n\n \nvoid\nlpfc_sli4_free_xri(struct lpfc_hba *phba, int xri)\n{\n\tspin_lock_irq(&phba->hbalock);\n\t__lpfc_sli4_free_xri(phba, xri);\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n \nuint16_t\nlpfc_sli4_next_xritag(struct lpfc_hba *phba)\n{\n\tuint16_t xri_index;\n\n\txri_index = lpfc_sli4_alloc_xri(phba);\n\tif (xri_index == NO_XRI)\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"2004 Failed to allocate XRI.last XRITAG is %d\"\n\t\t\t\t\" Max XRI is %d, Used XRI is %d\\n\",\n\t\t\t\txri_index,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_xri,\n\t\t\t\tphba->sli4_hba.max_cfg_param.xri_used);\n\treturn xri_index;\n}\n\n \nstatic int\nlpfc_sli4_post_sgl_list(struct lpfc_hba *phba,\n\t\t\t    struct list_head *post_sgl_list,\n\t\t\t    int post_cnt)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL, *sglq_next = NULL;\n\tstruct lpfc_mbx_post_uembed_sgl_page1 *sgl;\n\tstruct sgl_page_pairs *sgl_pg_pairs;\n\tvoid *viraddr;\n\tLPFC_MBOXQ_t *mbox;\n\tuint32_t reqlen, alloclen, pg_pairs;\n\tuint32_t mbox_tmo;\n\tuint16_t xritag_start = 0;\n\tint rc = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\treqlen = post_cnt * sizeof(struct sgl_page_pairs) +\n\t\t sizeof(union lpfc_sli4_cfg_shdr) + sizeof(uint32_t);\n\tif (reqlen > SLI4_PAGE_SIZE) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2559 Block sgl registration required DMA \"\n\t\t\t\t\"size (%d) great than a page\\n\", reqlen);\n\t\treturn -ENOMEM;\n\t}\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\n\t \n\talloclen = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t LPFC_MBOX_OPCODE_FCOE_POST_SGL_PAGES, reqlen,\n\t\t\t LPFC_SLI4_MBX_NEMBED);\n\n\tif (alloclen < reqlen) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0285 Allocated DMA memory size (%d) is \"\n\t\t\t\t\"less than the requested DMA memory \"\n\t\t\t\t\"size (%d)\\n\", alloclen, reqlen);\n\t\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\t\treturn -ENOMEM;\n\t}\n\t \n\tviraddr = mbox->sge_array->addr[0];\n\tsgl = (struct lpfc_mbx_post_uembed_sgl_page1 *)viraddr;\n\tsgl_pg_pairs = &sgl->sgl_pg_pairs;\n\n\tpg_pairs = 0;\n\tlist_for_each_entry_safe(sglq_entry, sglq_next, post_sgl_list, list) {\n\t\t \n\t\tsgl_pg_pairs->sgl_pg0_addr_lo =\n\t\t\t\tcpu_to_le32(putPaddrLow(sglq_entry->phys));\n\t\tsgl_pg_pairs->sgl_pg0_addr_hi =\n\t\t\t\tcpu_to_le32(putPaddrHigh(sglq_entry->phys));\n\t\tsgl_pg_pairs->sgl_pg1_addr_lo =\n\t\t\t\tcpu_to_le32(putPaddrLow(0));\n\t\tsgl_pg_pairs->sgl_pg1_addr_hi =\n\t\t\t\tcpu_to_le32(putPaddrHigh(0));\n\n\t\t \n\t\tif (pg_pairs == 0)\n\t\t\txritag_start = sglq_entry->sli4_xritag;\n\t\tsgl_pg_pairs++;\n\t\tpg_pairs++;\n\t}\n\n\t \n\tbf_set(lpfc_post_sgl_pages_xri, sgl, xritag_start);\n\tbf_set(lpfc_post_sgl_pages_xricnt, sgl, post_cnt);\n\tsgl->word0 = cpu_to_le32(sgl->word0);\n\n\tif (!phba->sli4_hba.intr_enable)\n\t\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\n\t}\n\tshdr = (union lpfc_sli4_cfg_shdr *) &sgl->cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (!phba->sli4_hba.intr_enable)\n\t\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\telse if (rc != MBX_TIMEOUT)\n\t\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2513 POST_SGL_BLOCK mailbox command failed \"\n\t\t\t\t\"status x%x add_status x%x mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\trc = -ENXIO;\n\t}\n\treturn rc;\n}\n\n \nstatic int\nlpfc_sli4_post_io_sgl_block(struct lpfc_hba *phba, struct list_head *nblist,\n\t\t\t    int count)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_mbx_post_uembed_sgl_page1 *sgl;\n\tstruct sgl_page_pairs *sgl_pg_pairs;\n\tvoid *viraddr;\n\tLPFC_MBOXQ_t *mbox;\n\tuint32_t reqlen, alloclen, pg_pairs;\n\tuint32_t mbox_tmo;\n\tuint16_t xritag_start = 0;\n\tint rc = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tdma_addr_t pdma_phys_bpl1;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\t \n\treqlen = count * sizeof(struct sgl_page_pairs) +\n\t\t sizeof(union lpfc_sli4_cfg_shdr) + sizeof(uint32_t);\n\tif (reqlen > SLI4_PAGE_SIZE) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"6118 Block sgl registration required DMA \"\n\t\t\t\t\"size (%d) great than a page\\n\", reqlen);\n\t\treturn -ENOMEM;\n\t}\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6119 Failed to allocate mbox cmd memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\talloclen = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t\t    LPFC_MBOX_OPCODE_FCOE_POST_SGL_PAGES,\n\t\t\t\t    reqlen, LPFC_SLI4_MBX_NEMBED);\n\n\tif (alloclen < reqlen) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6120 Allocated DMA memory size (%d) is \"\n\t\t\t\t\"less than the requested DMA memory \"\n\t\t\t\t\"size (%d)\\n\", alloclen, reqlen);\n\t\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tviraddr = mbox->sge_array->addr[0];\n\n\t \n\tsgl = (struct lpfc_mbx_post_uembed_sgl_page1 *)viraddr;\n\tsgl_pg_pairs = &sgl->sgl_pg_pairs;\n\n\tpg_pairs = 0;\n\tlist_for_each_entry(lpfc_ncmd, nblist, list) {\n\t\t \n\t\tsgl_pg_pairs->sgl_pg0_addr_lo =\n\t\t\tcpu_to_le32(putPaddrLow(lpfc_ncmd->dma_phys_sgl));\n\t\tsgl_pg_pairs->sgl_pg0_addr_hi =\n\t\t\tcpu_to_le32(putPaddrHigh(lpfc_ncmd->dma_phys_sgl));\n\t\tif (phba->cfg_sg_dma_buf_size > SGL_PAGE_SIZE)\n\t\t\tpdma_phys_bpl1 = lpfc_ncmd->dma_phys_sgl +\n\t\t\t\t\t\tSGL_PAGE_SIZE;\n\t\telse\n\t\t\tpdma_phys_bpl1 = 0;\n\t\tsgl_pg_pairs->sgl_pg1_addr_lo =\n\t\t\tcpu_to_le32(putPaddrLow(pdma_phys_bpl1));\n\t\tsgl_pg_pairs->sgl_pg1_addr_hi =\n\t\t\tcpu_to_le32(putPaddrHigh(pdma_phys_bpl1));\n\t\t \n\t\tif (pg_pairs == 0)\n\t\t\txritag_start = lpfc_ncmd->cur_iocbq.sli4_xritag;\n\t\tsgl_pg_pairs++;\n\t\tpg_pairs++;\n\t}\n\tbf_set(lpfc_post_sgl_pages_xri, sgl, xritag_start);\n\tbf_set(lpfc_post_sgl_pages_xricnt, sgl, pg_pairs);\n\t \n\tsgl->word0 = cpu_to_le32(sgl->word0);\n\n\tif (!phba->sli4_hba.intr_enable) {\n\t\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\t} else {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\n\t}\n\tshdr = (union lpfc_sli4_cfg_shdr *)&sgl->cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (!phba->sli4_hba.intr_enable)\n\t\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\telse if (rc != MBX_TIMEOUT)\n\t\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6125 POST_SGL_BLOCK mailbox command failed \"\n\t\t\t\t\"status x%x add_status x%x mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\trc = -ENXIO;\n\t}\n\treturn rc;\n}\n\n \nint\nlpfc_sli4_post_io_sgl_list(struct lpfc_hba *phba,\n\t\t\t   struct list_head *post_nblist, int sb_count)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd, *lpfc_ncmd_next;\n\tint status, sgl_size;\n\tint post_cnt = 0, block_cnt = 0, num_posting = 0, num_posted = 0;\n\tdma_addr_t pdma_phys_sgl1;\n\tint last_xritag = NO_XRI;\n\tint cur_xritag;\n\tLIST_HEAD(prep_nblist);\n\tLIST_HEAD(blck_nblist);\n\tLIST_HEAD(nvme_nblist);\n\n\t \n\tif (sb_count <= 0)\n\t\treturn -EINVAL;\n\n\tsgl_size = phba->cfg_sg_dma_buf_size;\n\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next, post_nblist, list) {\n\t\tlist_del_init(&lpfc_ncmd->list);\n\t\tblock_cnt++;\n\t\tif ((last_xritag != NO_XRI) &&\n\t\t    (lpfc_ncmd->cur_iocbq.sli4_xritag != last_xritag + 1)) {\n\t\t\t \n\t\t\tlist_splice_init(&prep_nblist, &blck_nblist);\n\t\t\tpost_cnt = block_cnt - 1;\n\t\t\t \n\t\t\tlist_add_tail(&lpfc_ncmd->list, &prep_nblist);\n\t\t\tblock_cnt = 1;\n\t\t} else {\n\t\t\t \n\t\t\tlist_add_tail(&lpfc_ncmd->list, &prep_nblist);\n\t\t\t \n\t\t\tif (block_cnt == LPFC_NEMBED_MBOX_SGL_CNT) {\n\t\t\t\tlist_splice_init(&prep_nblist, &blck_nblist);\n\t\t\t\tpost_cnt = block_cnt;\n\t\t\t\tblock_cnt = 0;\n\t\t\t}\n\t\t}\n\t\tnum_posting++;\n\t\tlast_xritag = lpfc_ncmd->cur_iocbq.sli4_xritag;\n\n\t\t \n\t\tif (num_posting == sb_count) {\n\t\t\tif (post_cnt == 0) {\n\t\t\t\t \n\t\t\t\tlist_splice_init(&prep_nblist, &blck_nblist);\n\t\t\t\tpost_cnt = block_cnt;\n\t\t\t} else if (block_cnt == 1) {\n\t\t\t\t \n\t\t\t\tif (sgl_size > SGL_PAGE_SIZE)\n\t\t\t\t\tpdma_phys_sgl1 =\n\t\t\t\t\t\tlpfc_ncmd->dma_phys_sgl +\n\t\t\t\t\t\tSGL_PAGE_SIZE;\n\t\t\t\telse\n\t\t\t\t\tpdma_phys_sgl1 = 0;\n\t\t\t\tcur_xritag = lpfc_ncmd->cur_iocbq.sli4_xritag;\n\t\t\t\tstatus = lpfc_sli4_post_sgl(\n\t\t\t\t\t\tphba, lpfc_ncmd->dma_phys_sgl,\n\t\t\t\t\t\tpdma_phys_sgl1, cur_xritag);\n\t\t\t\tif (status) {\n\t\t\t\t\t \n\t\t\t\t\tlpfc_ncmd->flags |=\n\t\t\t\t\t\tLPFC_SBUF_NOT_POSTED;\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tlpfc_ncmd->flags &=\n\t\t\t\t\t\t~LPFC_SBUF_NOT_POSTED;\n\t\t\t\t\tlpfc_ncmd->status = IOSTAT_SUCCESS;\n\t\t\t\t\tnum_posted++;\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\tlist_add_tail(&lpfc_ncmd->list, &nvme_nblist);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (post_cnt == 0)\n\t\t\tcontinue;\n\n\t\t \n\t\tstatus = lpfc_sli4_post_io_sgl_block(phba, &blck_nblist,\n\t\t\t\t\t\t     post_cnt);\n\n\t\t \n\t\tif (block_cnt == 0)\n\t\t\tlast_xritag = NO_XRI;\n\n\t\t \n\t\tpost_cnt = 0;\n\n\t\t \n\t\twhile (!list_empty(&blck_nblist)) {\n\t\t\tlist_remove_head(&blck_nblist, lpfc_ncmd,\n\t\t\t\t\t struct lpfc_io_buf, list);\n\t\t\tif (status) {\n\t\t\t\t \n\t\t\t\tlpfc_ncmd->flags |= LPFC_SBUF_NOT_POSTED;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tlpfc_ncmd->flags &= ~LPFC_SBUF_NOT_POSTED;\n\t\t\t\tlpfc_ncmd->status = IOSTAT_SUCCESS;\n\t\t\t\tnum_posted++;\n\t\t\t}\n\t\t\tlist_add_tail(&lpfc_ncmd->list, &nvme_nblist);\n\t\t}\n\t}\n\t \n\tlpfc_io_buf_replenish(phba, &nvme_nblist);\n\n\treturn num_posted;\n}\n\n \nstatic int\nlpfc_fc_frame_check(struct lpfc_hba *phba, struct fc_frame_header *fc_hdr)\n{\n\t \n\tstruct fc_vft_header *fc_vft_hdr;\n\tuint32_t *header = (uint32_t *) fc_hdr;\n\n#define FC_RCTL_MDS_DIAGS\t0xF4\n\n\tswitch (fc_hdr->fh_r_ctl) {\n\tcase FC_RCTL_DD_UNCAT:\t\t \n\tcase FC_RCTL_DD_SOL_DATA:\t \n\tcase FC_RCTL_DD_UNSOL_CTL:\t \n\tcase FC_RCTL_DD_SOL_CTL:\t \n\tcase FC_RCTL_DD_UNSOL_DATA:\t \n\tcase FC_RCTL_DD_DATA_DESC:\t \n\tcase FC_RCTL_DD_UNSOL_CMD:\t \n\tcase FC_RCTL_DD_CMD_STATUS:\t \n\tcase FC_RCTL_ELS_REQ:\t \n\tcase FC_RCTL_ELS_REP:\t \n\tcase FC_RCTL_ELS4_REQ:\t \n\tcase FC_RCTL_ELS4_REP:\t \n\tcase FC_RCTL_BA_ABTS: \t \n\tcase FC_RCTL_BA_RMC: \t \n\tcase FC_RCTL_BA_ACC:\t \n\tcase FC_RCTL_BA_RJT:\t \n\tcase FC_RCTL_BA_PRMT:\n\tcase FC_RCTL_ACK_1:\t \n\tcase FC_RCTL_ACK_0:\t \n\tcase FC_RCTL_P_RJT:\t \n\tcase FC_RCTL_F_RJT:\t \n\tcase FC_RCTL_P_BSY:\t \n\tcase FC_RCTL_F_BSY:\t \n\tcase FC_RCTL_F_BSYL:\t \n\tcase FC_RCTL_LCR:\t \n\tcase FC_RCTL_MDS_DIAGS:  \n\tcase FC_RCTL_END:\t \n\t\tbreak;\n\tcase FC_RCTL_VFTH:\t \n\t\tfc_vft_hdr = (struct fc_vft_header *)fc_hdr;\n\t\tfc_hdr = &((struct fc_frame_header *)fc_vft_hdr)[1];\n\t\treturn lpfc_fc_frame_check(phba, fc_hdr);\n\tcase FC_RCTL_BA_NOP:\t \n\tdefault:\n\t\tgoto drop;\n\t}\n\n\tswitch (fc_hdr->fh_type) {\n\tcase FC_TYPE_BLS:\n\tcase FC_TYPE_ELS:\n\tcase FC_TYPE_FCP:\n\tcase FC_TYPE_CT:\n\tcase FC_TYPE_NVME:\n\t\tbreak;\n\tcase FC_TYPE_IP:\n\tcase FC_TYPE_ILS:\n\tdefault:\n\t\tgoto drop;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_ELS,\n\t\t\t\"2538 Received frame rctl:x%x, type:x%x, \"\n\t\t\t\"frame Data:%08x %08x %08x %08x %08x %08x %08x\\n\",\n\t\t\tfc_hdr->fh_r_ctl, fc_hdr->fh_type,\n\t\t\tbe32_to_cpu(header[0]), be32_to_cpu(header[1]),\n\t\t\tbe32_to_cpu(header[2]), be32_to_cpu(header[3]),\n\t\t\tbe32_to_cpu(header[4]), be32_to_cpu(header[5]),\n\t\t\tbe32_to_cpu(header[6]));\n\treturn 0;\ndrop:\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_ELS,\n\t\t\t\"2539 Dropped frame rctl:x%x type:x%x\\n\",\n\t\t\tfc_hdr->fh_r_ctl, fc_hdr->fh_type);\n\treturn 1;\n}\n\n \nstatic uint32_t\nlpfc_fc_hdr_get_vfi(struct fc_frame_header *fc_hdr)\n{\n\tstruct fc_vft_header *fc_vft_hdr = (struct fc_vft_header *)fc_hdr;\n\n\tif (fc_hdr->fh_r_ctl != FC_RCTL_VFTH)\n\t\treturn 0;\n\treturn bf_get(fc_vft_hdr_vf_id, fc_vft_hdr);\n}\n\n \nstatic struct lpfc_vport *\nlpfc_fc_frame_to_vport(struct lpfc_hba *phba, struct fc_frame_header *fc_hdr,\n\t\t       uint16_t fcfi, uint32_t did)\n{\n\tstruct lpfc_vport **vports;\n\tstruct lpfc_vport *vport = NULL;\n\tint i;\n\n\tif (did == Fabric_DID)\n\t\treturn phba->pport;\n\tif ((phba->pport->fc_flag & FC_PT2PT) &&\n\t\t!(phba->link_state == LPFC_HBA_READY))\n\t\treturn phba->pport;\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL) {\n\t\tfor (i = 0; i <= phba->max_vpi && vports[i] != NULL; i++) {\n\t\t\tif (phba->fcf.fcfi == fcfi &&\n\t\t\t    vports[i]->vfi == lpfc_fc_hdr_get_vfi(fc_hdr) &&\n\t\t\t    vports[i]->fc_myDID == did) {\n\t\t\t\tvport = vports[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\treturn vport;\n}\n\n \nstatic void\nlpfc_update_rcv_time_stamp(struct lpfc_vport *vport)\n{\n\tstruct lpfc_dmabuf *h_buf;\n\tstruct hbq_dmabuf *dmabuf = NULL;\n\n\t \n\th_buf = list_get_first(&vport->rcv_buffer_list,\n\t\t\t       struct lpfc_dmabuf, list);\n\tif (!h_buf)\n\t\treturn;\n\tdmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\n\tvport->rcv_buffer_time_stamp = dmabuf->time_stamp;\n}\n\n \nvoid\nlpfc_cleanup_rcv_buffers(struct lpfc_vport *vport)\n{\n\tstruct lpfc_dmabuf *h_buf, *hnext;\n\tstruct lpfc_dmabuf *d_buf, *dnext;\n\tstruct hbq_dmabuf *dmabuf = NULL;\n\n\t \n\tlist_for_each_entry_safe(h_buf, hnext, &vport->rcv_buffer_list, list) {\n\t\tdmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\n\t\tlist_del_init(&dmabuf->hbuf.list);\n\t\tlist_for_each_entry_safe(d_buf, dnext,\n\t\t\t\t\t &dmabuf->dbuf.list, list) {\n\t\t\tlist_del_init(&d_buf->list);\n\t\t\tlpfc_in_buf_free(vport->phba, d_buf);\n\t\t}\n\t\tlpfc_in_buf_free(vport->phba, &dmabuf->dbuf);\n\t}\n}\n\n \nvoid\nlpfc_rcv_seq_check_edtov(struct lpfc_vport *vport)\n{\n\tstruct lpfc_dmabuf *h_buf, *hnext;\n\tstruct lpfc_dmabuf *d_buf, *dnext;\n\tstruct hbq_dmabuf *dmabuf = NULL;\n\tunsigned long timeout;\n\tint abort_count = 0;\n\n\ttimeout = (msecs_to_jiffies(vport->phba->fc_edtov) +\n\t\t   vport->rcv_buffer_time_stamp);\n\tif (list_empty(&vport->rcv_buffer_list) ||\n\t    time_before(jiffies, timeout))\n\t\treturn;\n\t \n\tlist_for_each_entry_safe(h_buf, hnext, &vport->rcv_buffer_list, list) {\n\t\tdmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\n\t\ttimeout = (msecs_to_jiffies(vport->phba->fc_edtov) +\n\t\t\t   dmabuf->time_stamp);\n\t\tif (time_before(jiffies, timeout))\n\t\t\tbreak;\n\t\tabort_count++;\n\t\tlist_del_init(&dmabuf->hbuf.list);\n\t\tlist_for_each_entry_safe(d_buf, dnext,\n\t\t\t\t\t &dmabuf->dbuf.list, list) {\n\t\t\tlist_del_init(&d_buf->list);\n\t\t\tlpfc_in_buf_free(vport->phba, d_buf);\n\t\t}\n\t\tlpfc_in_buf_free(vport->phba, &dmabuf->dbuf);\n\t}\n\tif (abort_count)\n\t\tlpfc_update_rcv_time_stamp(vport);\n}\n\n \nstatic struct hbq_dmabuf *\nlpfc_fc_frame_add(struct lpfc_vport *vport, struct hbq_dmabuf *dmabuf)\n{\n\tstruct fc_frame_header *new_hdr;\n\tstruct fc_frame_header *temp_hdr;\n\tstruct lpfc_dmabuf *d_buf;\n\tstruct lpfc_dmabuf *h_buf;\n\tstruct hbq_dmabuf *seq_dmabuf = NULL;\n\tstruct hbq_dmabuf *temp_dmabuf = NULL;\n\tuint8_t\tfound = 0;\n\n\tINIT_LIST_HEAD(&dmabuf->dbuf.list);\n\tdmabuf->time_stamp = jiffies;\n\tnew_hdr = (struct fc_frame_header *)dmabuf->hbuf.virt;\n\n\t \n\tlist_for_each_entry(h_buf, &vport->rcv_buffer_list, list) {\n\t\ttemp_hdr = (struct fc_frame_header *)h_buf->virt;\n\t\tif ((temp_hdr->fh_seq_id != new_hdr->fh_seq_id) ||\n\t\t    (temp_hdr->fh_ox_id != new_hdr->fh_ox_id) ||\n\t\t    (memcmp(&temp_hdr->fh_s_id, &new_hdr->fh_s_id, 3)))\n\t\t\tcontinue;\n\t\t \n\t\tseq_dmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\n\t\tbreak;\n\t}\n\tif (!seq_dmabuf) {\n\t\t \n\t\tlist_add_tail(&dmabuf->hbuf.list, &vport->rcv_buffer_list);\n\t\tlpfc_update_rcv_time_stamp(vport);\n\t\treturn dmabuf;\n\t}\n\ttemp_hdr = seq_dmabuf->hbuf.virt;\n\tif (be16_to_cpu(new_hdr->fh_seq_cnt) <\n\t\tbe16_to_cpu(temp_hdr->fh_seq_cnt)) {\n\t\tlist_del_init(&seq_dmabuf->hbuf.list);\n\t\tlist_add_tail(&dmabuf->hbuf.list, &vport->rcv_buffer_list);\n\t\tlist_add_tail(&dmabuf->dbuf.list, &seq_dmabuf->dbuf.list);\n\t\tlpfc_update_rcv_time_stamp(vport);\n\t\treturn dmabuf;\n\t}\n\t \n\tlist_move_tail(&seq_dmabuf->hbuf.list, &vport->rcv_buffer_list);\n\tseq_dmabuf->time_stamp = jiffies;\n\tlpfc_update_rcv_time_stamp(vport);\n\tif (list_empty(&seq_dmabuf->dbuf.list)) {\n\t\tlist_add_tail(&dmabuf->dbuf.list, &seq_dmabuf->dbuf.list);\n\t\treturn seq_dmabuf;\n\t}\n\t \n\td_buf = list_entry(seq_dmabuf->dbuf.list.prev, typeof(*d_buf), list);\n\twhile (!found) {\n\t\ttemp_dmabuf = container_of(d_buf, struct hbq_dmabuf, dbuf);\n\t\ttemp_hdr = (struct fc_frame_header *)temp_dmabuf->hbuf.virt;\n\t\t \n\t\tif (be16_to_cpu(new_hdr->fh_seq_cnt) >\n\t\t\tbe16_to_cpu(temp_hdr->fh_seq_cnt)) {\n\t\t\tlist_add(&dmabuf->dbuf.list, &temp_dmabuf->dbuf.list);\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (&d_buf->list == &seq_dmabuf->dbuf.list)\n\t\t\tbreak;\n\t\td_buf = list_entry(d_buf->list.prev, typeof(*d_buf), list);\n\t}\n\n\tif (found)\n\t\treturn seq_dmabuf;\n\treturn NULL;\n}\n\n \nstatic bool\nlpfc_sli4_abort_partial_seq(struct lpfc_vport *vport,\n\t\t\t    struct hbq_dmabuf *dmabuf)\n{\n\tstruct fc_frame_header *new_hdr;\n\tstruct fc_frame_header *temp_hdr;\n\tstruct lpfc_dmabuf *d_buf, *n_buf, *h_buf;\n\tstruct hbq_dmabuf *seq_dmabuf = NULL;\n\n\t \n\tINIT_LIST_HEAD(&dmabuf->dbuf.list);\n\tINIT_LIST_HEAD(&dmabuf->hbuf.list);\n\tnew_hdr = (struct fc_frame_header *)dmabuf->hbuf.virt;\n\tlist_for_each_entry(h_buf, &vport->rcv_buffer_list, list) {\n\t\ttemp_hdr = (struct fc_frame_header *)h_buf->virt;\n\t\tif ((temp_hdr->fh_seq_id != new_hdr->fh_seq_id) ||\n\t\t    (temp_hdr->fh_ox_id != new_hdr->fh_ox_id) ||\n\t\t    (memcmp(&temp_hdr->fh_s_id, &new_hdr->fh_s_id, 3)))\n\t\t\tcontinue;\n\t\t \n\t\tseq_dmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\n\t\tbreak;\n\t}\n\n\t \n\tif (seq_dmabuf) {\n\t\tlist_for_each_entry_safe(d_buf, n_buf,\n\t\t\t\t\t &seq_dmabuf->dbuf.list, list) {\n\t\t\tlist_del_init(&d_buf->list);\n\t\t\tlpfc_in_buf_free(vport->phba, d_buf);\n\t\t}\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nstatic bool\nlpfc_sli4_abort_ulp_seq(struct lpfc_vport *vport, struct hbq_dmabuf *dmabuf)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tint handled;\n\n\t \n\tif (phba->sli_rev < LPFC_SLI_REV4)\n\t\treturn false;\n\n\t \n\thandled = lpfc_ct_handle_unsol_abort(phba, dmabuf);\n\tif (handled)\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic void\nlpfc_sli4_seq_abort_rsp_cmpl(struct lpfc_hba *phba,\n\t\t\t     struct lpfc_iocbq *cmd_iocbq,\n\t\t\t     struct lpfc_iocbq *rsp_iocbq)\n{\n\tif (cmd_iocbq) {\n\t\tlpfc_nlp_put(cmd_iocbq->ndlp);\n\t\tlpfc_sli_release_iocbq(phba, cmd_iocbq);\n\t}\n\n\t \n\tif (rsp_iocbq && rsp_iocbq->iocb.ulpStatus)\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"3154 BLS ABORT RSP failed, data:  x%x/x%x\\n\",\n\t\t\tget_job_ulpstatus(phba, rsp_iocbq),\n\t\t\tget_job_word4(phba, rsp_iocbq));\n}\n\n \nuint16_t\nlpfc_sli4_xri_inrange(struct lpfc_hba *phba,\n\t\t      uint16_t xri)\n{\n\tuint16_t i;\n\n\tfor (i = 0; i < phba->sli4_hba.max_cfg_param.max_xri; i++) {\n\t\tif (xri == phba->sli4_hba.xri_ids[i])\n\t\t\treturn i;\n\t}\n\treturn NO_XRI;\n}\n\n \nvoid\nlpfc_sli4_seq_abort_rsp(struct lpfc_vport *vport,\n\t\t\tstruct fc_frame_header *fc_hdr, bool aborted)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tstruct lpfc_iocbq *ctiocb = NULL;\n\tstruct lpfc_nodelist *ndlp;\n\tuint16_t oxid, rxid, xri, lxri;\n\tuint32_t sid, fctl;\n\tunion lpfc_wqe128 *icmd;\n\tint rc;\n\n\tif (!lpfc_is_link_up(phba))\n\t\treturn;\n\n\tsid = sli4_sid_from_fc_hdr(fc_hdr);\n\toxid = be16_to_cpu(fc_hdr->fh_ox_id);\n\trxid = be16_to_cpu(fc_hdr->fh_rx_id);\n\n\tndlp = lpfc_findnode_did(vport, sid);\n\tif (!ndlp) {\n\t\tndlp = lpfc_nlp_init(vport, sid);\n\t\tif (!ndlp) {\n\t\t\tlpfc_printf_vlog(vport, KERN_WARNING, LOG_ELS,\n\t\t\t\t\t \"1268 Failed to allocate ndlp for \"\n\t\t\t\t\t \"oxid:x%x SID:x%x\\n\", oxid, sid);\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tlpfc_enqueue_node(vport, ndlp);\n\t}\n\n\t \n\tctiocb = lpfc_sli_get_iocbq(phba);\n\tif (!ctiocb)\n\t\treturn;\n\n\ticmd = &ctiocb->wqe;\n\n\t \n\tfctl = sli4_fctl_from_fc_hdr(fc_hdr);\n\n\tctiocb->ndlp = lpfc_nlp_get(ndlp);\n\tif (!ctiocb->ndlp) {\n\t\tlpfc_sli_release_iocbq(phba, ctiocb);\n\t\treturn;\n\t}\n\n\tctiocb->vport = phba->pport;\n\tctiocb->cmd_cmpl = lpfc_sli4_seq_abort_rsp_cmpl;\n\tctiocb->sli4_lxritag = NO_XRI;\n\tctiocb->sli4_xritag = NO_XRI;\n\tctiocb->abort_rctl = FC_RCTL_BA_ACC;\n\n\tif (fctl & FC_FC_EX_CTX)\n\t\t \n\t\txri = oxid;\n\telse\n\t\txri = rxid;\n\tlxri = lpfc_sli4_xri_inrange(phba, xri);\n\tif (lxri != NO_XRI)\n\t\tlpfc_set_rrq_active(phba, ndlp, lxri,\n\t\t\t(xri == oxid) ? rxid : oxid, 0);\n\t \n\tif ((fctl & FC_FC_EX_CTX) &&\n\t    (lxri > lpfc_sli4_get_iocb_cnt(phba))) {\n\t\tctiocb->abort_rctl = FC_RCTL_BA_RJT;\n\t\tbf_set(xmit_bls_rsp64_rjt_vspec, &icmd->xmit_bls_rsp, 0);\n\t\tbf_set(xmit_bls_rsp64_rjt_expc, &icmd->xmit_bls_rsp,\n\t\t       FC_BA_RJT_INV_XID);\n\t\tbf_set(xmit_bls_rsp64_rjt_rsnc, &icmd->xmit_bls_rsp,\n\t\t       FC_BA_RJT_UNABLE);\n\t}\n\n\t \n\tif (aborted == false) {\n\t\tctiocb->abort_rctl = FC_RCTL_BA_RJT;\n\t\tbf_set(xmit_bls_rsp64_rjt_vspec, &icmd->xmit_bls_rsp, 0);\n\t\tbf_set(xmit_bls_rsp64_rjt_expc, &icmd->xmit_bls_rsp,\n\t\t       FC_BA_RJT_INV_XID);\n\t\tbf_set(xmit_bls_rsp64_rjt_rsnc, &icmd->xmit_bls_rsp,\n\t\t       FC_BA_RJT_UNABLE);\n\t}\n\n\tif (fctl & FC_FC_EX_CTX) {\n\t\t \n\t\tctiocb->abort_bls = LPFC_ABTS_UNSOL_RSP;\n\t\tbf_set(xmit_bls_rsp64_rxid, &icmd->xmit_bls_rsp, rxid);\n\t} else {\n\t\t \n\t\tctiocb->abort_bls = LPFC_ABTS_UNSOL_INT;\n\t}\n\n\t \n\tbf_set(xmit_bls_rsp64_oxid, &icmd->xmit_bls_rsp, oxid);\n\tbf_set(xmit_bls_rsp64_oxid, &icmd->xmit_bls_rsp, rxid);\n\n\t \n\tbf_set(wqe_els_did, &icmd->xmit_bls_rsp.wqe_dest,\n\t       ndlp->nlp_DID);\n\tbf_set(xmit_bls_rsp64_temprpi, &icmd->xmit_bls_rsp,\n\t       phba->sli4_hba.rpi_ids[ndlp->nlp_rpi]);\n\tbf_set(wqe_cmnd, &icmd->generic.wqe_com, CMD_XMIT_BLS_RSP64_CX);\n\n\t \n\tlpfc_printf_vlog(vport, KERN_INFO, LOG_ELS,\n\t\t\t \"1200 Send BLS cmd x%x on oxid x%x Data: x%x\\n\",\n\t\t\t ctiocb->abort_rctl, oxid, phba->link_state);\n\n\trc = lpfc_sli_issue_iocb(phba, LPFC_ELS_RING, ctiocb, 0);\n\tif (rc == IOCB_ERROR) {\n\t\tlpfc_printf_vlog(vport, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t \"2925 Failed to issue CT ABTS RSP x%x on \"\n\t\t\t\t \"xri x%x, Data x%x\\n\",\n\t\t\t\t ctiocb->abort_rctl, oxid,\n\t\t\t\t phba->link_state);\n\t\tlpfc_nlp_put(ndlp);\n\t\tctiocb->ndlp = NULL;\n\t\tlpfc_sli_release_iocbq(phba, ctiocb);\n\t}\n}\n\n \nstatic void\nlpfc_sli4_handle_unsol_abort(struct lpfc_vport *vport,\n\t\t\t     struct hbq_dmabuf *dmabuf)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tstruct fc_frame_header fc_hdr;\n\tuint32_t fctl;\n\tbool aborted;\n\n\t \n\tmemcpy(&fc_hdr, dmabuf->hbuf.virt, sizeof(struct fc_frame_header));\n\tfctl = sli4_fctl_from_fc_hdr(&fc_hdr);\n\n\tif (fctl & FC_FC_EX_CTX) {\n\t\t \n\t\taborted = true;\n\t} else {\n\t\t \n\t\taborted = lpfc_sli4_abort_partial_seq(vport, dmabuf);\n\t\tif (aborted == false)\n\t\t\taborted = lpfc_sli4_abort_ulp_seq(vport, dmabuf);\n\t}\n\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n\n\tif (phba->nvmet_support) {\n\t\tlpfc_nvmet_rcv_unsol_abort(vport, &fc_hdr);\n\t\treturn;\n\t}\n\n\t \n\tlpfc_sli4_seq_abort_rsp(vport, &fc_hdr, aborted);\n}\n\n \nstatic int\nlpfc_seq_complete(struct hbq_dmabuf *dmabuf)\n{\n\tstruct fc_frame_header *hdr;\n\tstruct lpfc_dmabuf *d_buf;\n\tstruct hbq_dmabuf *seq_dmabuf;\n\tuint32_t fctl;\n\tint seq_count = 0;\n\n\thdr = (struct fc_frame_header *)dmabuf->hbuf.virt;\n\t \n\tif (hdr->fh_seq_cnt != seq_count)\n\t\treturn 0;\n\tfctl = (hdr->fh_f_ctl[0] << 16 |\n\t\thdr->fh_f_ctl[1] << 8 |\n\t\thdr->fh_f_ctl[2]);\n\t \n\tif (fctl & FC_FC_END_SEQ)\n\t\treturn 1;\n\tlist_for_each_entry(d_buf, &dmabuf->dbuf.list, list) {\n\t\tseq_dmabuf = container_of(d_buf, struct hbq_dmabuf, dbuf);\n\t\thdr = (struct fc_frame_header *)seq_dmabuf->hbuf.virt;\n\t\t \n\t\tif (++seq_count != be16_to_cpu(hdr->fh_seq_cnt))\n\t\t\treturn 0;\n\t\tfctl = (hdr->fh_f_ctl[0] << 16 |\n\t\t\thdr->fh_f_ctl[1] << 8 |\n\t\t\thdr->fh_f_ctl[2]);\n\t\t \n\t\tif (fctl & FC_FC_END_SEQ)\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nstatic struct lpfc_iocbq *\nlpfc_prep_seq(struct lpfc_vport *vport, struct hbq_dmabuf *seq_dmabuf)\n{\n\tstruct hbq_dmabuf *hbq_buf;\n\tstruct lpfc_dmabuf *d_buf, *n_buf;\n\tstruct lpfc_iocbq *first_iocbq, *iocbq;\n\tstruct fc_frame_header *fc_hdr;\n\tuint32_t sid;\n\tuint32_t len, tot_len;\n\n\tfc_hdr = (struct fc_frame_header *)seq_dmabuf->hbuf.virt;\n\t \n\tlist_del_init(&seq_dmabuf->hbuf.list);\n\tlpfc_update_rcv_time_stamp(vport);\n\t \n\tsid = sli4_sid_from_fc_hdr(fc_hdr);\n\ttot_len = 0;\n\t \n\tfirst_iocbq = lpfc_sli_get_iocbq(vport->phba);\n\tif (first_iocbq) {\n\t\t \n\t\tfirst_iocbq->wcqe_cmpl.total_data_placed = 0;\n\t\tbf_set(lpfc_wcqe_c_status, &first_iocbq->wcqe_cmpl,\n\t\t       IOSTAT_SUCCESS);\n\t\tfirst_iocbq->vport = vport;\n\n\t\t \n\t\tif (sli4_type_from_fc_hdr(fc_hdr) == FC_TYPE_ELS) {\n\t\t\tbf_set(els_rsp64_sid, &first_iocbq->wqe.xmit_els_rsp,\n\t\t\t       sli4_did_from_fc_hdr(fc_hdr));\n\t\t}\n\n\t\tbf_set(wqe_ctxt_tag, &first_iocbq->wqe.xmit_els_rsp.wqe_com,\n\t\t       NO_XRI);\n\t\tbf_set(wqe_rcvoxid, &first_iocbq->wqe.xmit_els_rsp.wqe_com,\n\t\t       be16_to_cpu(fc_hdr->fh_ox_id));\n\n\t\t \n\t\ttot_len = bf_get(lpfc_rcqe_length,\n\t\t\t\t &seq_dmabuf->cq_event.cqe.rcqe_cmpl);\n\n\t\tfirst_iocbq->cmd_dmabuf = &seq_dmabuf->dbuf;\n\t\tfirst_iocbq->bpl_dmabuf = NULL;\n\t\t \n\t\tfirst_iocbq->wcqe_cmpl.word3 = 1;\n\n\t\tif (tot_len > LPFC_DATA_BUF_SIZE)\n\t\t\tfirst_iocbq->wqe.gen_req.bde.tus.f.bdeSize =\n\t\t\t\tLPFC_DATA_BUF_SIZE;\n\t\telse\n\t\t\tfirst_iocbq->wqe.gen_req.bde.tus.f.bdeSize = tot_len;\n\n\t\tfirst_iocbq->wcqe_cmpl.total_data_placed = tot_len;\n\t\tbf_set(wqe_els_did, &first_iocbq->wqe.xmit_els_rsp.wqe_dest,\n\t\t       sid);\n\t}\n\tiocbq = first_iocbq;\n\t \n\tlist_for_each_entry_safe(d_buf, n_buf, &seq_dmabuf->dbuf.list, list) {\n\t\tif (!iocbq) {\n\t\t\tlpfc_in_buf_free(vport->phba, d_buf);\n\t\t\tcontinue;\n\t\t}\n\t\tif (!iocbq->bpl_dmabuf) {\n\t\t\tiocbq->bpl_dmabuf = d_buf;\n\t\t\tiocbq->wcqe_cmpl.word3++;\n\t\t\t \n\t\t\thbq_buf = container_of(d_buf, struct hbq_dmabuf, dbuf);\n\t\t\tlen = bf_get(lpfc_rcqe_length,\n\t\t\t\t       &hbq_buf->cq_event.cqe.rcqe_cmpl);\n\t\t\tiocbq->unsol_rcv_len = len;\n\t\t\tiocbq->wcqe_cmpl.total_data_placed += len;\n\t\t\ttot_len += len;\n\t\t} else {\n\t\t\tiocbq = lpfc_sli_get_iocbq(vport->phba);\n\t\t\tif (!iocbq) {\n\t\t\t\tif (first_iocbq) {\n\t\t\t\t\tbf_set(lpfc_wcqe_c_status,\n\t\t\t\t\t       &first_iocbq->wcqe_cmpl,\n\t\t\t\t\t       IOSTAT_SUCCESS);\n\t\t\t\t\tfirst_iocbq->wcqe_cmpl.parameter =\n\t\t\t\t\t\tIOERR_NO_RESOURCES;\n\t\t\t\t}\n\t\t\t\tlpfc_in_buf_free(vport->phba, d_buf);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t \n\t\t\thbq_buf = container_of(d_buf, struct hbq_dmabuf, dbuf);\n\t\t\tlen = bf_get(lpfc_rcqe_length,\n\t\t\t\t       &hbq_buf->cq_event.cqe.rcqe_cmpl);\n\t\t\tiocbq->cmd_dmabuf = d_buf;\n\t\t\tiocbq->bpl_dmabuf = NULL;\n\t\t\tiocbq->wcqe_cmpl.word3 = 1;\n\n\t\t\tif (len > LPFC_DATA_BUF_SIZE)\n\t\t\t\tiocbq->wqe.xmit_els_rsp.bde.tus.f.bdeSize =\n\t\t\t\t\tLPFC_DATA_BUF_SIZE;\n\t\t\telse\n\t\t\t\tiocbq->wqe.xmit_els_rsp.bde.tus.f.bdeSize =\n\t\t\t\t\tlen;\n\n\t\t\ttot_len += len;\n\t\t\tiocbq->wcqe_cmpl.total_data_placed = tot_len;\n\t\t\tbf_set(wqe_els_did, &iocbq->wqe.xmit_els_rsp.wqe_dest,\n\t\t\t       sid);\n\t\t\tlist_add_tail(&iocbq->list, &first_iocbq->list);\n\t\t}\n\t}\n\t \n\tif (!first_iocbq)\n\t\tlpfc_in_buf_free(vport->phba, &seq_dmabuf->dbuf);\n\n\treturn first_iocbq;\n}\n\nstatic void\nlpfc_sli4_send_seq_to_ulp(struct lpfc_vport *vport,\n\t\t\t  struct hbq_dmabuf *seq_dmabuf)\n{\n\tstruct fc_frame_header *fc_hdr;\n\tstruct lpfc_iocbq *iocbq, *curr_iocb, *next_iocb;\n\tstruct lpfc_hba *phba = vport->phba;\n\n\tfc_hdr = (struct fc_frame_header *)seq_dmabuf->hbuf.virt;\n\tiocbq = lpfc_prep_seq(vport, seq_dmabuf);\n\tif (!iocbq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2707 Ring %d handler: Failed to allocate \"\n\t\t\t\t\"iocb Rctl x%x Type x%x received\\n\",\n\t\t\t\tLPFC_ELS_RING,\n\t\t\t\tfc_hdr->fh_r_ctl, fc_hdr->fh_type);\n\t\treturn;\n\t}\n\tif (!lpfc_complete_unsol_iocb(phba,\n\t\t\t\t      phba->sli4_hba.els_wq->pring,\n\t\t\t\t      iocbq, fc_hdr->fh_r_ctl,\n\t\t\t\t      fc_hdr->fh_type)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2540 Ring %d handler: unexpected Rctl \"\n\t\t\t\t\"x%x Type x%x received\\n\",\n\t\t\t\tLPFC_ELS_RING,\n\t\t\t\tfc_hdr->fh_r_ctl, fc_hdr->fh_type);\n\t\tlpfc_in_buf_free(phba, &seq_dmabuf->dbuf);\n\t}\n\n\t \n\tlist_for_each_entry_safe(curr_iocb, next_iocb,\n\t\t\t\t &iocbq->list, list) {\n\t\tlist_del_init(&curr_iocb->list);\n\t\tlpfc_sli_release_iocbq(phba, curr_iocb);\n\t}\n\tlpfc_sli_release_iocbq(phba, iocbq);\n}\n\nstatic void\nlpfc_sli4_mds_loopback_cmpl(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,\n\t\t\t    struct lpfc_iocbq *rspiocb)\n{\n\tstruct lpfc_dmabuf *pcmd = cmdiocb->cmd_dmabuf;\n\n\tif (pcmd && pcmd->virt)\n\t\tdma_pool_free(phba->lpfc_drb_pool, pcmd->virt, pcmd->phys);\n\tkfree(pcmd);\n\tlpfc_sli_release_iocbq(phba, cmdiocb);\n\tlpfc_drain_txq(phba);\n}\n\nstatic void\nlpfc_sli4_handle_mds_loopback(struct lpfc_vport *vport,\n\t\t\t      struct hbq_dmabuf *dmabuf)\n{\n\tstruct fc_frame_header *fc_hdr;\n\tstruct lpfc_hba *phba = vport->phba;\n\tstruct lpfc_iocbq *iocbq = NULL;\n\tunion  lpfc_wqe128 *pwqe;\n\tstruct lpfc_dmabuf *pcmd = NULL;\n\tuint32_t frame_len;\n\tint rc;\n\tunsigned long iflags;\n\n\tfc_hdr = (struct fc_frame_header *)dmabuf->hbuf.virt;\n\tframe_len = bf_get(lpfc_rcqe_length, &dmabuf->cq_event.cqe.rcqe_cmpl);\n\n\t \n\tiocbq = lpfc_sli_get_iocbq(phba);\n\tif (!iocbq) {\n\t\t \n\t\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t\tlist_add_tail(&dmabuf->cq_event.list,\n\t\t\t      &phba->sli4_hba.sp_queue_event);\n\t\tphba->hba_flag |= HBA_SP_QUEUE_EVT;\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\t\tlpfc_worker_wake_up(phba);\n\t\treturn;\n\t}\n\n\t \n\tpcmd = kmalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\n\tif (pcmd)\n\t\tpcmd->virt = dma_pool_alloc(phba->lpfc_drb_pool, GFP_KERNEL,\n\t\t\t\t\t    &pcmd->phys);\n\tif (!pcmd || !pcmd->virt)\n\t\tgoto exit;\n\n\tINIT_LIST_HEAD(&pcmd->list);\n\n\t \n\tmemcpy(pcmd->virt, dmabuf->dbuf.virt, frame_len);\n\n\tiocbq->cmd_dmabuf = pcmd;\n\tiocbq->vport = vport;\n\tiocbq->cmd_flag &= ~LPFC_FIP_ELS_ID_MASK;\n\tiocbq->cmd_flag |= LPFC_USE_FCPWQIDX;\n\tiocbq->num_bdes = 0;\n\n\tpwqe = &iocbq->wqe;\n\t \n\tpwqe->gen_req.bde.addrHigh = putPaddrHigh(pcmd->phys);\n\tpwqe->gen_req.bde.addrLow = putPaddrLow(pcmd->phys);\n\tpwqe->gen_req.bde.tus.f.bdeSize = frame_len;\n\tpwqe->gen_req.bde.tus.f.bdeFlags = BUFF_TYPE_BDE_64;\n\n\tpwqe->send_frame.frame_len = frame_len;\n\tpwqe->send_frame.fc_hdr_wd0 = be32_to_cpu(*((__be32 *)fc_hdr));\n\tpwqe->send_frame.fc_hdr_wd1 = be32_to_cpu(*((__be32 *)fc_hdr + 1));\n\tpwqe->send_frame.fc_hdr_wd2 = be32_to_cpu(*((__be32 *)fc_hdr + 2));\n\tpwqe->send_frame.fc_hdr_wd3 = be32_to_cpu(*((__be32 *)fc_hdr + 3));\n\tpwqe->send_frame.fc_hdr_wd4 = be32_to_cpu(*((__be32 *)fc_hdr + 4));\n\tpwqe->send_frame.fc_hdr_wd5 = be32_to_cpu(*((__be32 *)fc_hdr + 5));\n\n\tpwqe->generic.wqe_com.word7 = 0;\n\tpwqe->generic.wqe_com.word10 = 0;\n\n\tbf_set(wqe_cmnd, &pwqe->generic.wqe_com, CMD_SEND_FRAME);\n\tbf_set(wqe_sof, &pwqe->generic.wqe_com, 0x2E);  \n\tbf_set(wqe_eof, &pwqe->generic.wqe_com, 0x41);  \n\tbf_set(wqe_lenloc, &pwqe->generic.wqe_com, 1);\n\tbf_set(wqe_xbl, &pwqe->generic.wqe_com, 1);\n\tbf_set(wqe_dbde, &pwqe->generic.wqe_com, 1);\n\tbf_set(wqe_xc, &pwqe->generic.wqe_com, 1);\n\tbf_set(wqe_cmd_type, &pwqe->generic.wqe_com, 0xA);\n\tbf_set(wqe_cqid, &pwqe->generic.wqe_com, LPFC_WQE_CQ_ID_DEFAULT);\n\tbf_set(wqe_xri_tag, &pwqe->generic.wqe_com, iocbq->sli4_xritag);\n\tbf_set(wqe_reqtag, &pwqe->generic.wqe_com, iocbq->iotag);\n\tbf_set(wqe_class, &pwqe->generic.wqe_com, CLASS3);\n\tpwqe->generic.wqe_com.abort_tag = iocbq->iotag;\n\n\tiocbq->cmd_cmpl = lpfc_sli4_mds_loopback_cmpl;\n\n\trc = lpfc_sli_issue_iocb(phba, LPFC_ELS_RING, iocbq, 0);\n\tif (rc == IOCB_ERROR)\n\t\tgoto exit;\n\n\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n\treturn;\n\nexit:\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\"2023 Unable to process MDS loopback frame\\n\");\n\tif (pcmd && pcmd->virt)\n\t\tdma_pool_free(phba->lpfc_drb_pool, pcmd->virt, pcmd->phys);\n\tkfree(pcmd);\n\tif (iocbq)\n\t\tlpfc_sli_release_iocbq(phba, iocbq);\n\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n}\n\n \nvoid\nlpfc_sli4_handle_received_buffer(struct lpfc_hba *phba,\n\t\t\t\t struct hbq_dmabuf *dmabuf)\n{\n\tstruct hbq_dmabuf *seq_dmabuf;\n\tstruct fc_frame_header *fc_hdr;\n\tstruct lpfc_vport *vport;\n\tuint32_t fcfi;\n\tuint32_t did;\n\n\t \n\tfc_hdr = (struct fc_frame_header *)dmabuf->hbuf.virt;\n\n\tif (fc_hdr->fh_r_ctl == FC_RCTL_MDS_DIAGS ||\n\t    fc_hdr->fh_r_ctl == FC_RCTL_DD_UNSOL_DATA) {\n\t\tvport = phba->pport;\n\t\t \n\t\tif  (!(phba->pport->load_flag & FC_UNLOADING))\n\t\t\tlpfc_sli4_handle_mds_loopback(vport, dmabuf);\n\t\telse\n\t\t\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n\t\treturn;\n\t}\n\n\t \n\tif (lpfc_fc_frame_check(phba, fc_hdr)) {\n\t\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n\t\treturn;\n\t}\n\n\tif ((bf_get(lpfc_cqe_code,\n\t\t    &dmabuf->cq_event.cqe.rcqe_cmpl) == CQE_CODE_RECEIVE_V1))\n\t\tfcfi = bf_get(lpfc_rcqe_fcf_id_v1,\n\t\t\t      &dmabuf->cq_event.cqe.rcqe_cmpl);\n\telse\n\t\tfcfi = bf_get(lpfc_rcqe_fcf_id,\n\t\t\t      &dmabuf->cq_event.cqe.rcqe_cmpl);\n\n\tif (fc_hdr->fh_r_ctl == 0xF4 && fc_hdr->fh_type == 0xFF) {\n\t\tvport = phba->pport;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"2023 MDS Loopback %d bytes\\n\",\n\t\t\t\tbf_get(lpfc_rcqe_length,\n\t\t\t\t       &dmabuf->cq_event.cqe.rcqe_cmpl));\n\t\t \n\t\tlpfc_sli4_handle_mds_loopback(vport, dmabuf);\n\t\treturn;\n\t}\n\n\t \n\tdid = sli4_did_from_fc_hdr(fc_hdr);\n\n\tvport = lpfc_fc_frame_to_vport(phba, fc_hdr, fcfi, did);\n\tif (!vport) {\n\t\t \n\t\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n\t\treturn;\n\t}\n\n\t \n\tif (!(vport->vpi_state & LPFC_VPI_REGISTERED) &&\n\t\t(did != Fabric_DID)) {\n\t\t \n\t\tif (!(vport->fc_flag & FC_PT2PT) ||\n\t\t\t(phba->link_state == LPFC_HBA_READY)) {\n\t\t\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t \n\tif (fc_hdr->fh_r_ctl == FC_RCTL_BA_ABTS) {\n\t\tlpfc_sli4_handle_unsol_abort(vport, dmabuf);\n\t\treturn;\n\t}\n\n\t \n\tseq_dmabuf = lpfc_fc_frame_add(vport, dmabuf);\n\tif (!seq_dmabuf) {\n\t\t \n\t\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n\t\treturn;\n\t}\n\t \n\tif (!lpfc_seq_complete(seq_dmabuf))\n\t\treturn;\n\n\t \n\tlpfc_sli4_send_seq_to_ulp(vport, seq_dmabuf);\n}\n\n \nint\nlpfc_sli4_post_all_rpi_hdrs(struct lpfc_hba *phba)\n{\n\tstruct lpfc_rpi_hdr *rpi_page;\n\tuint32_t rc = 0;\n\tuint16_t lrpi = 0;\n\n\t \n\tif (!phba->sli4_hba.rpi_hdrs_in_use)\n\t\tgoto exit;\n\tif (phba->sli4_hba.extents_in_use)\n\t\treturn -EIO;\n\n\tlist_for_each_entry(rpi_page, &phba->sli4_hba.lpfc_rpi_hdr_list, list) {\n\t\t \n\t\tif (bf_get(lpfc_rpi_rsrc_rdy, &phba->sli4_hba.sli4_flags) !=\n\t\t    LPFC_RPI_RSRC_RDY)\n\t\t\trpi_page->start_rpi = phba->sli4_hba.rpi_ids[lrpi];\n\n\t\trc = lpfc_sli4_post_rpi_hdr(phba, rpi_page);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2008 Error %d posting all rpi \"\n\t\t\t\t\t\"headers\\n\", rc);\n\t\t\trc = -EIO;\n\t\t\tbreak;\n\t\t}\n\t}\n\n exit:\n\tbf_set(lpfc_rpi_rsrc_rdy, &phba->sli4_hba.sli4_flags,\n\t       LPFC_RPI_RSRC_RDY);\n\treturn rc;\n}\n\n \nint\nlpfc_sli4_post_rpi_hdr(struct lpfc_hba *phba, struct lpfc_rpi_hdr *rpi_page)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct lpfc_mbx_post_hdr_tmpl *hdr_tmpl;\n\tuint32_t rc = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\n\t \n\tif (!phba->sli4_hba.rpi_hdrs_in_use)\n\t\treturn rc;\n\tif (phba->sli4_hba.extents_in_use)\n\t\treturn -EIO;\n\n\t \n\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2001 Unable to allocate memory for issuing \"\n\t\t\t\t\"SLI_CONFIG_SPECIAL mailbox command\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\thdr_tmpl = &mboxq->u.mqe.un.hdr_tmpl;\n\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t LPFC_MBOX_OPCODE_FCOE_POST_HDR_TEMPLATE,\n\t\t\t sizeof(struct lpfc_mbx_post_hdr_tmpl) -\n\t\t\t sizeof(struct lpfc_sli4_cfg_mhdr),\n\t\t\t LPFC_SLI4_MBX_EMBED);\n\n\n\t \n\tbf_set(lpfc_mbx_post_hdr_tmpl_rpi_offset, hdr_tmpl,\n\t       rpi_page->start_rpi);\n\tbf_set(lpfc_mbx_post_hdr_tmpl_page_cnt,\n\t       hdr_tmpl, rpi_page->page_count);\n\n\thdr_tmpl->rpi_paddr_lo = putPaddrLow(rpi_page->dmabuf->phys);\n\thdr_tmpl->rpi_paddr_hi = putPaddrHigh(rpi_page->dmabuf->phys);\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tshdr = (union lpfc_sli4_cfg_shdr *) &hdr_tmpl->header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2514 POST_RPI_HDR mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\trc = -ENXIO;\n\t} else {\n\t\t \n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->sli4_hba.next_rpi = rpi_page->next_rpi;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\treturn rc;\n}\n\n \nint\nlpfc_sli4_alloc_rpi(struct lpfc_hba *phba)\n{\n\tunsigned long rpi;\n\tuint16_t max_rpi, rpi_limit;\n\tuint16_t rpi_remaining, lrpi = 0;\n\tstruct lpfc_rpi_hdr *rpi_hdr;\n\tunsigned long iflag;\n\n\t \n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tmax_rpi = phba->sli4_hba.max_cfg_param.max_rpi;\n\trpi_limit = phba->sli4_hba.next_rpi;\n\n\trpi = find_first_zero_bit(phba->sli4_hba.rpi_bmask, rpi_limit);\n\tif (rpi >= rpi_limit)\n\t\trpi = LPFC_RPI_ALLOC_ERROR;\n\telse {\n\t\tset_bit(rpi, phba->sli4_hba.rpi_bmask);\n\t\tphba->sli4_hba.max_cfg_param.rpi_used++;\n\t\tphba->sli4_hba.rpi_count++;\n\t}\n\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\tLOG_NODE | LOG_DISCOVERY,\n\t\t\t\"0001 Allocated rpi:x%x max:x%x lim:x%x\\n\",\n\t\t\t(int) rpi, max_rpi, rpi_limit);\n\n\t \n\tif ((rpi == LPFC_RPI_ALLOC_ERROR) &&\n\t    (phba->sli4_hba.rpi_count >= max_rpi)) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\treturn rpi;\n\t}\n\n\t \n\tif (!phba->sli4_hba.rpi_hdrs_in_use) {\n\t\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\t\treturn rpi;\n\t}\n\n\t \n\trpi_remaining = phba->sli4_hba.next_rpi - phba->sli4_hba.rpi_count;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\tif (rpi_remaining < LPFC_RPI_LOW_WATER_MARK) {\n\t\trpi_hdr = lpfc_sli4_create_rpi_hdr(phba);\n\t\tif (!rpi_hdr) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2002 Error Could not grow rpi \"\n\t\t\t\t\t\"count\\n\");\n\t\t} else {\n\t\t\tlrpi = rpi_hdr->start_rpi;\n\t\t\trpi_hdr->start_rpi = phba->sli4_hba.rpi_ids[lrpi];\n\t\t\tlpfc_sli4_post_rpi_hdr(phba, rpi_hdr);\n\t\t}\n\t}\n\n\treturn rpi;\n}\n\n \nstatic void\n__lpfc_sli4_free_rpi(struct lpfc_hba *phba, int rpi)\n{\n\t \n\tif (rpi == LPFC_RPI_ALLOC_ERROR)\n\t\treturn;\n\n\tif (test_and_clear_bit(rpi, phba->sli4_hba.rpi_bmask)) {\n\t\tphba->sli4_hba.rpi_count--;\n\t\tphba->sli4_hba.max_cfg_param.rpi_used--;\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\tLOG_NODE | LOG_DISCOVERY,\n\t\t\t\t\"2016 rpi %x not inuse\\n\",\n\t\t\t\trpi);\n\t}\n}\n\n \nvoid\nlpfc_sli4_free_rpi(struct lpfc_hba *phba, int rpi)\n{\n\tspin_lock_irq(&phba->hbalock);\n\t__lpfc_sli4_free_rpi(phba, rpi);\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n \nvoid\nlpfc_sli4_remove_rpis(struct lpfc_hba *phba)\n{\n\tkfree(phba->sli4_hba.rpi_bmask);\n\tkfree(phba->sli4_hba.rpi_ids);\n\tbf_set(lpfc_rpi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\n}\n\n \nint\nlpfc_sli4_resume_rpi(struct lpfc_nodelist *ndlp,\n\tvoid (*cmpl)(struct lpfc_hba *, LPFC_MBOXQ_t *), void *arg)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct lpfc_hba *phba = ndlp->phba;\n\tint rc;\n\n\t \n\tmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\n\t \n\tif (!lpfc_nlp_get(ndlp)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2122 %s: Failed to get nlp ref\\n\",\n\t\t\t\t__func__);\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\n\t \n\tlpfc_resume_rpi(mboxq, ndlp);\n\tif (cmpl) {\n\t\tmboxq->mbox_cmpl = cmpl;\n\t\tmboxq->ctx_buf = arg;\n\t} else\n\t\tmboxq->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\tmboxq->ctx_ndlp = ndlp;\n\tmboxq->vport = ndlp->vport;\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2010 Resume RPI Mailbox failed \"\n\t\t\t\t\"status %d, mbxStatus x%x\\n\", rc,\n\t\t\t\tbf_get(lpfc_mqe_status, &mboxq->u.mqe));\n\t\tlpfc_nlp_put(ndlp);\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\treturn 0;\n}\n\n \nint\nlpfc_sli4_init_vpi(struct lpfc_vport *vport)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tint rc = 0;\n\tint retval = MBX_SUCCESS;\n\tuint32_t mbox_tmo;\n\tstruct lpfc_hba *phba = vport->phba;\n\tmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq)\n\t\treturn -ENOMEM;\n\tlpfc_init_vpi(phba, mboxq, vport->vpi);\n\tmbox_tmo = lpfc_mbox_tmo_val(phba, mboxq);\n\trc = lpfc_sli_issue_mbox_wait(phba, mboxq, mbox_tmo);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_vlog(vport, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2022 INIT VPI Mailbox failed \"\n\t\t\t\t\"status %d, mbxStatus x%x\\n\", rc,\n\t\t\t\tbf_get(lpfc_mqe_status, &mboxq->u.mqe));\n\t\tretval = -EIO;\n\t}\n\tif (rc != MBX_TIMEOUT)\n\t\tmempool_free(mboxq, vport->phba->mbox_mem_pool);\n\n\treturn retval;\n}\n\n \nstatic void\nlpfc_mbx_cmpl_add_fcf_record(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\n{\n\tvoid *virt_addr;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t shdr_status, shdr_add_status;\n\n\tvirt_addr = mboxq->sge_array->addr[0];\n\t \n\tshdr = (union lpfc_sli4_cfg_shdr *) virt_addr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\n\tif ((shdr_status || shdr_add_status) &&\n\t\t(shdr_status != STATUS_FCF_IN_USE))\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2558 ADD_FCF_RECORD mailbox failed with \"\n\t\t\t\"status x%x add_status x%x\\n\",\n\t\t\tshdr_status, shdr_add_status);\n\n\tlpfc_sli4_mbox_cmd_free(phba, mboxq);\n}\n\n \nint\nlpfc_sli4_add_fcf_record(struct lpfc_hba *phba, struct fcf_record *fcf_record)\n{\n\tint rc = 0;\n\tLPFC_MBOXQ_t *mboxq;\n\tuint8_t *bytep;\n\tvoid *virt_addr;\n\tstruct lpfc_mbx_sge sge;\n\tuint32_t alloc_len, req_len;\n\tuint32_t fcfindex;\n\n\tmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2009 Failed to allocate mbox for ADD_FCF cmd\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\treq_len = sizeof(struct fcf_record) + sizeof(union lpfc_sli4_cfg_shdr) +\n\t\t  sizeof(uint32_t);\n\n\t \n\talloc_len = lpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t\t     LPFC_MBOX_OPCODE_FCOE_ADD_FCF,\n\t\t\t\t     req_len, LPFC_SLI4_MBX_NEMBED);\n\tif (alloc_len < req_len) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2523 Allocated DMA memory size (x%x) is \"\n\t\t\t\"less than the requested DMA memory \"\n\t\t\t\"size (x%x)\\n\", alloc_len, req_len);\n\t\tlpfc_sli4_mbox_cmd_free(phba, mboxq);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tlpfc_sli4_mbx_sge_get(mboxq, 0, &sge);\n\tvirt_addr = mboxq->sge_array->addr[0];\n\t \n\tfcfindex = bf_get(lpfc_fcf_record_fcf_index, fcf_record);\n\tbytep = virt_addr + sizeof(union lpfc_sli4_cfg_shdr);\n\tlpfc_sli_pcimem_bcopy(&fcfindex, bytep, sizeof(uint32_t));\n\n\t \n\tbytep += sizeof(uint32_t);\n\tlpfc_sli_pcimem_bcopy(fcf_record, bytep, sizeof(struct fcf_record));\n\tmboxq->vport = phba->pport;\n\tmboxq->mbox_cmpl = lpfc_mbx_cmpl_add_fcf_record;\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2515 ADD_FCF_RECORD mailbox failed with \"\n\t\t\t\"status 0x%x\\n\", rc);\n\t\tlpfc_sli4_mbox_cmd_free(phba, mboxq);\n\t\trc = -EIO;\n\t} else\n\t\trc = 0;\n\n\treturn rc;\n}\n\n \nvoid\nlpfc_sli4_build_dflt_fcf_record(struct lpfc_hba *phba,\n\t\t\t\tstruct fcf_record *fcf_record,\n\t\t\t\tuint16_t fcf_index)\n{\n\tmemset(fcf_record, 0, sizeof(struct fcf_record));\n\tfcf_record->max_rcv_size = LPFC_FCOE_MAX_RCV_SIZE;\n\tfcf_record->fka_adv_period = LPFC_FCOE_FKA_ADV_PER;\n\tfcf_record->fip_priority = LPFC_FCOE_FIP_PRIORITY;\n\tbf_set(lpfc_fcf_record_mac_0, fcf_record, phba->fc_map[0]);\n\tbf_set(lpfc_fcf_record_mac_1, fcf_record, phba->fc_map[1]);\n\tbf_set(lpfc_fcf_record_mac_2, fcf_record, phba->fc_map[2]);\n\tbf_set(lpfc_fcf_record_mac_3, fcf_record, LPFC_FCOE_FCF_MAC3);\n\tbf_set(lpfc_fcf_record_mac_4, fcf_record, LPFC_FCOE_FCF_MAC4);\n\tbf_set(lpfc_fcf_record_mac_5, fcf_record, LPFC_FCOE_FCF_MAC5);\n\tbf_set(lpfc_fcf_record_fc_map_0, fcf_record, phba->fc_map[0]);\n\tbf_set(lpfc_fcf_record_fc_map_1, fcf_record, phba->fc_map[1]);\n\tbf_set(lpfc_fcf_record_fc_map_2, fcf_record, phba->fc_map[2]);\n\tbf_set(lpfc_fcf_record_fcf_valid, fcf_record, 1);\n\tbf_set(lpfc_fcf_record_fcf_avail, fcf_record, 1);\n\tbf_set(lpfc_fcf_record_fcf_index, fcf_record, fcf_index);\n\tbf_set(lpfc_fcf_record_mac_addr_prov, fcf_record,\n\t\tLPFC_FCF_FPMA | LPFC_FCF_SPMA);\n\t \n\tif (phba->valid_vlan) {\n\t\tfcf_record->vlan_bitmap[phba->vlan_id / 8]\n\t\t\t= 1 << (phba->vlan_id % 8);\n\t}\n}\n\n \nint\nlpfc_sli4_fcf_scan_read_fcf_rec(struct lpfc_hba *phba, uint16_t fcf_index)\n{\n\tint rc = 0, error;\n\tLPFC_MBOXQ_t *mboxq;\n\n\tphba->fcoe_eventtag_at_fcf_scan = phba->fcoe_eventtag;\n\tphba->fcoe_cvl_eventtag_attn = phba->fcoe_cvl_eventtag;\n\tmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2000 Failed to allocate mbox for \"\n\t\t\t\t\"READ_FCF cmd\\n\");\n\t\terror = -ENOMEM;\n\t\tgoto fail_fcf_scan;\n\t}\n\t \n\trc = lpfc_sli4_mbx_read_fcf_rec(phba, mboxq, fcf_index);\n\tif (rc) {\n\t\terror = -EINVAL;\n\t\tgoto fail_fcf_scan;\n\t}\n\t \n\tmboxq->vport = phba->pport;\n\tmboxq->mbox_cmpl = lpfc_mbx_cmpl_fcf_scan_read_fcf_rec;\n\n\tspin_lock_irq(&phba->hbalock);\n\tphba->hba_flag |= FCF_TS_INPROG;\n\tspin_unlock_irq(&phba->hbalock);\n\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED)\n\t\terror = -EIO;\n\telse {\n\t\t \n\t\tif (fcf_index == LPFC_FCOE_FCF_GET_FIRST)\n\t\t\tphba->fcf.eligible_fcf_cnt = 0;\n\t\terror = 0;\n\t}\nfail_fcf_scan:\n\tif (error) {\n\t\tif (mboxq)\n\t\t\tlpfc_sli4_mbox_cmd_free(phba, mboxq);\n\t\t \n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->hba_flag &= ~FCF_TS_INPROG;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\treturn error;\n}\n\n \nint\nlpfc_sli4_fcf_rr_read_fcf_rec(struct lpfc_hba *phba, uint16_t fcf_index)\n{\n\tint rc = 0, error;\n\tLPFC_MBOXQ_t *mboxq;\n\n\tmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP | LOG_INIT,\n\t\t\t\t\"2763 Failed to allocate mbox for \"\n\t\t\t\t\"READ_FCF cmd\\n\");\n\t\terror = -ENOMEM;\n\t\tgoto fail_fcf_read;\n\t}\n\t \n\trc = lpfc_sli4_mbx_read_fcf_rec(phba, mboxq, fcf_index);\n\tif (rc) {\n\t\terror = -EINVAL;\n\t\tgoto fail_fcf_read;\n\t}\n\t \n\tmboxq->vport = phba->pport;\n\tmboxq->mbox_cmpl = lpfc_mbx_cmpl_fcf_rr_read_fcf_rec;\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED)\n\t\terror = -EIO;\n\telse\n\t\terror = 0;\n\nfail_fcf_read:\n\tif (error && mboxq)\n\t\tlpfc_sli4_mbox_cmd_free(phba, mboxq);\n\treturn error;\n}\n\n \nint\nlpfc_sli4_read_fcf_rec(struct lpfc_hba *phba, uint16_t fcf_index)\n{\n\tint rc = 0, error;\n\tLPFC_MBOXQ_t *mboxq;\n\n\tmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP | LOG_INIT,\n\t\t\t\t\"2758 Failed to allocate mbox for \"\n\t\t\t\t\"READ_FCF cmd\\n\");\n\t\t\t\terror = -ENOMEM;\n\t\t\t\tgoto fail_fcf_read;\n\t}\n\t \n\trc = lpfc_sli4_mbx_read_fcf_rec(phba, mboxq, fcf_index);\n\tif (rc) {\n\t\terror = -EINVAL;\n\t\tgoto fail_fcf_read;\n\t}\n\t \n\tmboxq->vport = phba->pport;\n\tmboxq->mbox_cmpl = lpfc_mbx_cmpl_read_fcf_rec;\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED)\n\t\terror = -EIO;\n\telse\n\t\terror = 0;\n\nfail_fcf_read:\n\tif (error && mboxq)\n\t\tlpfc_sli4_mbox_cmd_free(phba, mboxq);\n\treturn error;\n}\n\n \nstatic int\nlpfc_check_next_fcf_pri_level(struct lpfc_hba *phba)\n{\n\tuint16_t next_fcf_pri;\n\tuint16_t last_index;\n\tstruct lpfc_fcf_pri *fcf_pri;\n\tint rc;\n\tint ret = 0;\n\n\tlast_index = find_first_bit(phba->fcf.fcf_rr_bmask,\n\t\t\tLPFC_SLI4_FCF_TBL_INDX_MAX);\n\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\n\t\t\t\"3060 Last IDX %d\\n\", last_index);\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tif (list_empty(&phba->fcf.fcf_pri_list) ||\n\t    list_is_singular(&phba->fcf.fcf_pri_list)) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\n\t\t\t\"3061 Last IDX %d\\n\", last_index);\n\t\treturn 0;  \n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\n\tnext_fcf_pri = 0;\n\t \n\tmemset(phba->fcf.fcf_rr_bmask, 0,\n\t\t\tsizeof(*phba->fcf.fcf_rr_bmask));\n\tspin_lock_irq(&phba->hbalock);\n\tlist_for_each_entry(fcf_pri, &phba->fcf.fcf_pri_list, list) {\n\t\tif (fcf_pri->fcf_rec.flag & LPFC_FCF_FLOGI_FAILED)\n\t\t\tcontinue;\n\t\t \n\t\tif (!next_fcf_pri)\n\t\t\tnext_fcf_pri = fcf_pri->fcf_rec.priority;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tif (fcf_pri->fcf_rec.priority == next_fcf_pri) {\n\t\t\trc = lpfc_sli4_fcf_rr_index_set(phba,\n\t\t\t\t\t\tfcf_pri->fcf_rec.fcf_index);\n\t\t\tif (rc)\n\t\t\t\treturn 0;\n\t\t}\n\t\tspin_lock_irq(&phba->hbalock);\n\t}\n\t \n\tif (!next_fcf_pri && !list_empty(&phba->fcf.fcf_pri_list)) {\n\t\tlist_for_each_entry(fcf_pri, &phba->fcf.fcf_pri_list, list) {\n\t\t\tfcf_pri->fcf_rec.flag &= ~LPFC_FCF_FLOGI_FAILED;\n\t\t\t \n\t\t\tif (!next_fcf_pri)\n\t\t\t\tnext_fcf_pri = fcf_pri->fcf_rec.priority;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tif (fcf_pri->fcf_rec.priority == next_fcf_pri) {\n\t\t\t\trc = lpfc_sli4_fcf_rr_index_set(phba,\n\t\t\t\t\t\tfcf_pri->fcf_rec.fcf_index);\n\t\t\t\tif (rc)\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t}\n\t} else\n\t\tret = 1;\n\tspin_unlock_irq(&phba->hbalock);\n\n\treturn ret;\n}\n \nuint16_t\nlpfc_sli4_fcf_rr_next_index_get(struct lpfc_hba *phba)\n{\n\tuint16_t next_fcf_index;\n\ninitial_priority:\n\t \n\tnext_fcf_index = phba->fcf.current_rec.fcf_indx;\n\nnext_priority:\n\t \n\tnext_fcf_index = (next_fcf_index + 1) % LPFC_SLI4_FCF_TBL_INDX_MAX;\n\tnext_fcf_index = find_next_bit(phba->fcf.fcf_rr_bmask,\n\t\t\t\t       LPFC_SLI4_FCF_TBL_INDX_MAX,\n\t\t\t\t       next_fcf_index);\n\n\t \n\tif (next_fcf_index >= LPFC_SLI4_FCF_TBL_INDX_MAX) {\n\t\t \n\t\tnext_fcf_index = find_first_bit(phba->fcf.fcf_rr_bmask,\n\t\t\t\t\t       LPFC_SLI4_FCF_TBL_INDX_MAX);\n\t}\n\n\n\t \n\tif (next_fcf_index >= LPFC_SLI4_FCF_TBL_INDX_MAX ||\n\t\tnext_fcf_index == phba->fcf.current_rec.fcf_indx) {\n\t\t \n\t\tif (lpfc_check_next_fcf_pri_level(phba))\n\t\t\tgoto initial_priority;\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_FIP,\n\t\t\t\t\"2844 No roundrobin failover FCF available\\n\");\n\n\t\treturn LPFC_FCOE_FCF_NEXT_NONE;\n\t}\n\n\tif (next_fcf_index < LPFC_SLI4_FCF_TBL_INDX_MAX &&\n\t\tphba->fcf.fcf_pri[next_fcf_index].fcf_rec.flag &\n\t\tLPFC_FCF_FLOGI_FAILED) {\n\t\tif (list_is_singular(&phba->fcf.fcf_pri_list))\n\t\t\treturn LPFC_FCOE_FCF_NEXT_NONE;\n\n\t\tgoto next_priority;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\n\t\t\t\"2845 Get next roundrobin failover FCF (x%x)\\n\",\n\t\t\tnext_fcf_index);\n\n\treturn next_fcf_index;\n}\n\n \nint\nlpfc_sli4_fcf_rr_index_set(struct lpfc_hba *phba, uint16_t fcf_index)\n{\n\tif (fcf_index >= LPFC_SLI4_FCF_TBL_INDX_MAX) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\n\t\t\t\t\"2610 FCF (x%x) reached driver's book \"\n\t\t\t\t\"keeping dimension:x%x\\n\",\n\t\t\t\tfcf_index, LPFC_SLI4_FCF_TBL_INDX_MAX);\n\t\treturn -EINVAL;\n\t}\n\t \n\tset_bit(fcf_index, phba->fcf.fcf_rr_bmask);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\n\t\t\t\"2790 Set FCF (x%x) to roundrobin FCF failover \"\n\t\t\t\"bmask\\n\", fcf_index);\n\n\treturn 0;\n}\n\n \nvoid\nlpfc_sli4_fcf_rr_index_clear(struct lpfc_hba *phba, uint16_t fcf_index)\n{\n\tstruct lpfc_fcf_pri *fcf_pri, *fcf_pri_next;\n\tif (fcf_index >= LPFC_SLI4_FCF_TBL_INDX_MAX) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\n\t\t\t\t\"2762 FCF (x%x) reached driver's book \"\n\t\t\t\t\"keeping dimension:x%x\\n\",\n\t\t\t\tfcf_index, LPFC_SLI4_FCF_TBL_INDX_MAX);\n\t\treturn;\n\t}\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tlist_for_each_entry_safe(fcf_pri, fcf_pri_next, &phba->fcf.fcf_pri_list,\n\t\t\t\t list) {\n\t\tif (fcf_pri->fcf_rec.fcf_index == fcf_index) {\n\t\t\tlist_del_init(&fcf_pri->list);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\tclear_bit(fcf_index, phba->fcf.fcf_rr_bmask);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\n\t\t\t\"2791 Clear FCF (x%x) from roundrobin failover \"\n\t\t\t\"bmask\\n\", fcf_index);\n}\n\n \nstatic void\nlpfc_mbx_cmpl_redisc_fcf_table(struct lpfc_hba *phba, LPFC_MBOXQ_t *mbox)\n{\n\tstruct lpfc_mbx_redisc_fcf_tbl *redisc_fcf;\n\tuint32_t shdr_status, shdr_add_status;\n\n\tredisc_fcf = &mbox->u.mqe.un.redisc_fcf_tbl;\n\n\tshdr_status = bf_get(lpfc_mbox_hdr_status,\n\t\t\t     &redisc_fcf->header.cfg_shdr.response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status,\n\t\t\t     &redisc_fcf->header.cfg_shdr.response);\n\tif (shdr_status || shdr_add_status) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\n\t\t\t\t\"2746 Requesting for FCF rediscovery failed \"\n\t\t\t\t\"status x%x add_status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status);\n\t\tif (phba->fcf.fcf_flag & FCF_ACVL_DISC) {\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tphba->fcf.fcf_flag &= ~FCF_ACVL_DISC;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t \n\t\t\tlpfc_retry_pport_discovery(phba);\n\t\t} else {\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tphba->fcf.fcf_flag &= ~FCF_DEAD_DISC;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t \n\t\t\tlpfc_sli4_fcf_dead_failthrough(phba);\n\t\t}\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\n\t\t\t\t\"2775 Start FCF rediscover quiescent timer\\n\");\n\t\t \n\t\tlpfc_fcf_redisc_wait_start_timer(phba);\n\t}\n\n\tmempool_free(mbox, phba->mbox_mem_pool);\n}\n\n \nint\nlpfc_sli4_redisc_fcf_table(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mbox;\n\tstruct lpfc_mbx_redisc_fcf_tbl *redisc_fcf;\n\tint rc, length;\n\n\t \n\tlpfc_cancel_all_vport_retry_delay_timer(phba);\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2745 Failed to allocate mbox for \"\n\t\t\t\t\"requesting FCF rediscover.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tlength = (sizeof(struct lpfc_mbx_redisc_fcf_tbl) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\n\t\t\t LPFC_MBOX_OPCODE_FCOE_REDISCOVER_FCF,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\n\tredisc_fcf = &mbox->u.mqe.un.redisc_fcf_tbl;\n\t \n\tbf_set(lpfc_mbx_redisc_fcf_count, redisc_fcf, 0);\n\n\t \n\tmbox->vport = phba->pport;\n\tmbox->mbox_cmpl = lpfc_mbx_cmpl_redisc_fcf_table;\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);\n\n\tif (rc == MBX_NOT_FINISHED) {\n\t\tmempool_free(mbox, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\treturn 0;\n}\n\n \nvoid\nlpfc_sli4_fcf_dead_failthrough(struct lpfc_hba *phba)\n{\n\tuint32_t link_state;\n\n\t \n\tlink_state = phba->link_state;\n\tlpfc_linkdown(phba);\n\tphba->link_state = link_state;\n\n\t \n\tlpfc_unregister_unused_fcf(phba);\n}\n\n \nstatic uint32_t\nlpfc_sli_get_config_region23(struct lpfc_hba *phba, char *rgn23_data)\n{\n\tLPFC_MBOXQ_t *pmb = NULL;\n\tMAILBOX_t *mb;\n\tuint32_t offset = 0;\n\tint rc;\n\n\tif (!rgn23_data)\n\t\treturn 0;\n\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2600 failed to allocate mailbox memory\\n\");\n\t\treturn 0;\n\t}\n\tmb = &pmb->u.mb;\n\n\tdo {\n\t\tlpfc_dump_mem(phba, pmb, offset, DMP_REGION_23);\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"2601 failed to read config \"\n\t\t\t\t\t\"region 23, rc 0x%x Status 0x%x\\n\",\n\t\t\t\t\trc, mb->mbxStatus);\n\t\t\tmb->un.varDmp.word_cnt = 0;\n\t\t}\n\t\t \n\t\tif (mb->un.varDmp.word_cnt == 0)\n\t\t\tbreak;\n\n\t\tif (mb->un.varDmp.word_cnt > DMP_RGN23_SIZE - offset)\n\t\t\tmb->un.varDmp.word_cnt = DMP_RGN23_SIZE - offset;\n\n\t\tlpfc_sli_pcimem_bcopy(((uint8_t *)mb) + DMP_RSP_OFFSET,\n\t\t\t\t       rgn23_data + offset,\n\t\t\t\t       mb->un.varDmp.word_cnt);\n\t\toffset += mb->un.varDmp.word_cnt;\n\t} while (mb->un.varDmp.word_cnt && offset < DMP_RGN23_SIZE);\n\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\treturn offset;\n}\n\n \nstatic uint32_t\nlpfc_sli4_get_config_region23(struct lpfc_hba *phba, char *rgn23_data)\n{\n\tLPFC_MBOXQ_t *mboxq = NULL;\n\tstruct lpfc_dmabuf *mp = NULL;\n\tstruct lpfc_mqe *mqe;\n\tuint32_t data_length = 0;\n\tint rc;\n\n\tif (!rgn23_data)\n\t\treturn 0;\n\n\tmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3105 failed to allocate mailbox memory\\n\");\n\t\treturn 0;\n\t}\n\n\tif (lpfc_sli4_dump_cfg_rg23(phba, mboxq))\n\t\tgoto out;\n\tmqe = &mboxq->u.mqe;\n\tmp = (struct lpfc_dmabuf *)mboxq->ctx_buf;\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tif (rc)\n\t\tgoto out;\n\tdata_length = mqe->un.mb_words[5];\n\tif (data_length == 0)\n\t\tgoto out;\n\tif (data_length > DMP_RGN23_SIZE) {\n\t\tdata_length = 0;\n\t\tgoto out;\n\t}\n\tlpfc_sli_pcimem_bcopy((char *)mp->virt, rgn23_data, data_length);\nout:\n\tlpfc_mbox_rsrc_cleanup(phba, mboxq, MBOX_THD_UNLOCKED);\n\treturn data_length;\n}\n\n \nvoid\nlpfc_sli_read_link_ste(struct lpfc_hba *phba)\n{\n\tuint8_t *rgn23_data = NULL;\n\tuint32_t if_type, data_size, sub_tlv_len, tlv_offset;\n\tuint32_t offset = 0;\n\n\t \n\trgn23_data = kzalloc(DMP_RGN23_SIZE, GFP_KERNEL);\n\tif (!rgn23_data)\n\t\tgoto out;\n\n\tif (phba->sli_rev < LPFC_SLI_REV4)\n\t\tdata_size = lpfc_sli_get_config_region23(phba, rgn23_data);\n\telse {\n\t\tif_type = bf_get(lpfc_sli_intf_if_type,\n\t\t\t\t &phba->sli4_hba.sli_intf);\n\t\tif (if_type == LPFC_SLI_INTF_IF_TYPE_0)\n\t\t\tgoto out;\n\t\tdata_size = lpfc_sli4_get_config_region23(phba, rgn23_data);\n\t}\n\n\tif (!data_size)\n\t\tgoto out;\n\n\t \n\tif (memcmp(&rgn23_data[offset], LPFC_REGION23_SIGNATURE, 4)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2619 Config region 23 has bad signature\\n\");\n\t\t\tgoto out;\n\t}\n\toffset += 4;\n\n\t \n\tif (rgn23_data[offset] != LPFC_REGION23_VERSION) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2620 Config region 23 has bad version\\n\");\n\t\tgoto out;\n\t}\n\toffset += 4;\n\n\t \n\twhile (offset < data_size) {\n\t\tif (rgn23_data[offset] == LPFC_REGION23_LAST_REC)\n\t\t\tbreak;\n\t\t \n\t\tif ((rgn23_data[offset] != DRIVER_SPECIFIC_TYPE) ||\n\t\t    (rgn23_data[offset + 2] != LINUX_DRIVER_ID) ||\n\t\t    (rgn23_data[offset + 3] != 0)) {\n\t\t\toffset += rgn23_data[offset + 1] * 4 + 4;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tsub_tlv_len = rgn23_data[offset + 1] * 4;\n\t\toffset += 4;\n\t\ttlv_offset = 0;\n\n\t\t \n\t\twhile ((offset < data_size) &&\n\t\t\t(tlv_offset < sub_tlv_len)) {\n\t\t\tif (rgn23_data[offset] == LPFC_REGION23_LAST_REC) {\n\t\t\t\toffset += 4;\n\t\t\t\ttlv_offset += 4;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (rgn23_data[offset] != PORT_STE_TYPE) {\n\t\t\t\toffset += rgn23_data[offset + 1] * 4 + 4;\n\t\t\t\ttlv_offset += rgn23_data[offset + 1] * 4 + 4;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (!rgn23_data[offset + 2])\n\t\t\t\tphba->hba_flag |= LINK_DISABLED;\n\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tkfree(rgn23_data);\n\treturn;\n}\n\n \nstatic void\nlpfc_log_fw_write_cmpl(struct lpfc_hba *phba, u32 shdr_status,\n\t\t       u32 shdr_add_status, u32 shdr_add_status_2,\n\t\t       u32 shdr_change_status, u32 shdr_csf)\n{\n\tlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\n\t\t\t\"4198 %s: flash_id x%02x, asic_rev x%02x, \"\n\t\t\t\"status x%02x, add_status x%02x, add_status_2 x%02x, \"\n\t\t\t\"change_status x%02x, csf %01x\\n\", __func__,\n\t\t\tphba->sli4_hba.flash_id, phba->sli4_hba.asic_rev,\n\t\t\tshdr_status, shdr_add_status, shdr_add_status_2,\n\t\t\tshdr_change_status, shdr_csf);\n\n\tif (shdr_add_status == LPFC_ADD_STATUS_INCOMPAT_OBJ) {\n\t\tswitch (shdr_add_status_2) {\n\t\tcase LPFC_ADD_STATUS_2_INCOMPAT_FLASH:\n\t\t\tlpfc_log_msg(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\n\t\t\t\t     \"4199 Firmware write failed: \"\n\t\t\t\t     \"image incompatible with flash x%02x\\n\",\n\t\t\t\t     phba->sli4_hba.flash_id);\n\t\t\tbreak;\n\t\tcase LPFC_ADD_STATUS_2_INCORRECT_ASIC:\n\t\t\tlpfc_log_msg(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\n\t\t\t\t     \"4200 Firmware write failed: \"\n\t\t\t\t     \"image incompatible with ASIC \"\n\t\t\t\t     \"architecture x%02x\\n\",\n\t\t\t\t     phba->sli4_hba.asic_rev);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlpfc_log_msg(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\n\t\t\t\t     \"4210 Firmware write failed: \"\n\t\t\t\t     \"add_status_2 x%02x\\n\",\n\t\t\t\t     shdr_add_status_2);\n\t\t\tbreak;\n\t\t}\n\t} else if (!shdr_status && !shdr_add_status) {\n\t\tif (shdr_change_status == LPFC_CHANGE_STATUS_FW_RESET ||\n\t\t    shdr_change_status == LPFC_CHANGE_STATUS_PORT_MIGRATION) {\n\t\t\tif (shdr_csf)\n\t\t\t\tshdr_change_status =\n\t\t\t\t\t\t   LPFC_CHANGE_STATUS_PCI_RESET;\n\t\t}\n\n\t\tswitch (shdr_change_status) {\n\t\tcase (LPFC_CHANGE_STATUS_PHYS_DEV_RESET):\n\t\t\tlpfc_log_msg(phba, KERN_NOTICE, LOG_MBOX | LOG_SLI,\n\t\t\t\t     \"3198 Firmware write complete: System \"\n\t\t\t\t     \"reboot required to instantiate\\n\");\n\t\t\tbreak;\n\t\tcase (LPFC_CHANGE_STATUS_FW_RESET):\n\t\t\tlpfc_log_msg(phba, KERN_NOTICE, LOG_MBOX | LOG_SLI,\n\t\t\t\t     \"3199 Firmware write complete: \"\n\t\t\t\t     \"Firmware reset required to \"\n\t\t\t\t     \"instantiate\\n\");\n\t\t\tbreak;\n\t\tcase (LPFC_CHANGE_STATUS_PORT_MIGRATION):\n\t\t\tlpfc_log_msg(phba, KERN_NOTICE, LOG_MBOX | LOG_SLI,\n\t\t\t\t     \"3200 Firmware write complete: Port \"\n\t\t\t\t     \"Migration or PCI Reset required to \"\n\t\t\t\t     \"instantiate\\n\");\n\t\t\tbreak;\n\t\tcase (LPFC_CHANGE_STATUS_PCI_RESET):\n\t\t\tlpfc_log_msg(phba, KERN_NOTICE, LOG_MBOX | LOG_SLI,\n\t\t\t\t     \"3201 Firmware write complete: PCI \"\n\t\t\t\t     \"Reset required to instantiate\\n\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nint\nlpfc_wr_object(struct lpfc_hba *phba, struct list_head *dmabuf_list,\n\t       uint32_t size, uint32_t *offset)\n{\n\tstruct lpfc_mbx_wr_object *wr_object;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc = 0, i = 0;\n\tint mbox_status = 0;\n\tuint32_t shdr_status, shdr_add_status, shdr_add_status_2;\n\tuint32_t shdr_change_status = 0, shdr_csf = 0;\n\tuint32_t mbox_tmo;\n\tstruct lpfc_dmabuf *dmabuf;\n\tuint32_t written = 0;\n\tbool check_change_status = false;\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\tLPFC_MBOX_OPCODE_WRITE_OBJECT,\n\t\t\tsizeof(struct lpfc_mbx_wr_object) -\n\t\t\tsizeof(struct lpfc_sli4_cfg_mhdr), LPFC_SLI4_MBX_EMBED);\n\n\twr_object = (struct lpfc_mbx_wr_object *)&mbox->u.mqe.un.wr_object;\n\twr_object->u.request.write_offset = *offset;\n\tsprintf((uint8_t *)wr_object->u.request.object_name, \"/\");\n\twr_object->u.request.object_name[0] =\n\t\tcpu_to_le32(wr_object->u.request.object_name[0]);\n\tbf_set(lpfc_wr_object_eof, &wr_object->u.request, 0);\n\tlist_for_each_entry(dmabuf, dmabuf_list, list) {\n\t\tif (i >= LPFC_MBX_WR_CONFIG_MAX_BDE || written >= size)\n\t\t\tbreak;\n\t\twr_object->u.request.bde[i].addrLow = putPaddrLow(dmabuf->phys);\n\t\twr_object->u.request.bde[i].addrHigh =\n\t\t\tputPaddrHigh(dmabuf->phys);\n\t\tif (written + SLI4_PAGE_SIZE >= size) {\n\t\t\twr_object->u.request.bde[i].tus.f.bdeSize =\n\t\t\t\t(size - written);\n\t\t\twritten += (size - written);\n\t\t\tbf_set(lpfc_wr_object_eof, &wr_object->u.request, 1);\n\t\t\tbf_set(lpfc_wr_object_eas, &wr_object->u.request, 1);\n\t\t\tcheck_change_status = true;\n\t\t} else {\n\t\t\twr_object->u.request.bde[i].tus.f.bdeSize =\n\t\t\t\tSLI4_PAGE_SIZE;\n\t\t\twritten += SLI4_PAGE_SIZE;\n\t\t}\n\t\ti++;\n\t}\n\twr_object->u.request.bde_count = i;\n\tbf_set(lpfc_wr_object_write_length, &wr_object->u.request, written);\n\tif (!phba->sli4_hba.intr_enable)\n\t\tmbox_status = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\n\t\tmbox_status = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\n\t}\n\n\t \n\trc = mbox_status;\n\n\t \n\tshdr_status = bf_get(lpfc_mbox_hdr_status,\n\t\t\t     &wr_object->header.cfg_shdr.response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status,\n\t\t\t\t &wr_object->header.cfg_shdr.response);\n\tshdr_add_status_2 = bf_get(lpfc_mbox_hdr_add_status_2,\n\t\t\t\t   &wr_object->header.cfg_shdr.response);\n\tif (check_change_status) {\n\t\tshdr_change_status = bf_get(lpfc_wr_object_change_status,\n\t\t\t\t\t    &wr_object->u.response);\n\t\tshdr_csf = bf_get(lpfc_wr_object_csf,\n\t\t\t\t  &wr_object->u.response);\n\t}\n\n\tif (shdr_status || shdr_add_status || shdr_add_status_2 || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3025 Write Object mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, add_status_2 x%x, \"\n\t\t\t\t\"mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, shdr_add_status_2,\n\t\t\t\trc);\n\t\trc = -ENXIO;\n\t\t*offset = shdr_add_status;\n\t} else {\n\t\t*offset += wr_object->u.response.actual_write_length;\n\t}\n\n\tif (rc || check_change_status)\n\t\tlpfc_log_fw_write_cmpl(phba, shdr_status, shdr_add_status,\n\t\t\t\t       shdr_add_status_2, shdr_change_status,\n\t\t\t\t       shdr_csf);\n\n\tif (!phba->sli4_hba.intr_enable)\n\t\tmempool_free(mbox, phba->mbox_mem_pool);\n\telse if (mbox_status != MBX_TIMEOUT)\n\t\tmempool_free(mbox, phba->mbox_mem_pool);\n\n\treturn rc;\n}\n\n \nvoid\nlpfc_cleanup_pending_mbox(struct lpfc_vport *vport)\n{\n\tstruct lpfc_hba *phba = vport->phba;\n\tLPFC_MBOXQ_t *mb, *nextmb;\n\tstruct lpfc_nodelist *ndlp;\n\tstruct lpfc_nodelist *act_mbx_ndlp = NULL;\n\tLIST_HEAD(mbox_cmd_list);\n\tuint8_t restart_loop;\n\n\t \n\tspin_lock_irq(&phba->hbalock);\n\tlist_for_each_entry_safe(mb, nextmb, &phba->sli.mboxq, list) {\n\t\tif (mb->vport != vport)\n\t\t\tcontinue;\n\n\t\tif ((mb->u.mb.mbxCommand != MBX_REG_LOGIN64) &&\n\t\t\t(mb->u.mb.mbxCommand != MBX_REG_VPI))\n\t\t\tcontinue;\n\n\t\tlist_move_tail(&mb->list, &mbox_cmd_list);\n\t}\n\t \n\tmb = phba->sli.mbox_active;\n\tif (mb && (mb->vport == vport)) {\n\t\tif ((mb->u.mb.mbxCommand == MBX_REG_LOGIN64) ||\n\t\t\t(mb->u.mb.mbxCommand == MBX_REG_VPI))\n\t\t\tmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\t\tif (mb->u.mb.mbxCommand == MBX_REG_LOGIN64) {\n\t\t\tact_mbx_ndlp = (struct lpfc_nodelist *)mb->ctx_ndlp;\n\n\t\t\t \n\t\t\tact_mbx_ndlp = lpfc_nlp_get(act_mbx_ndlp);\n\n\t\t\t \n\t\t\tmb->mbox_flag |= LPFC_MBX_IMED_UNREG;\n\t\t}\n\t}\n\t \n\tdo {\n\t\trestart_loop = 0;\n\t\tlist_for_each_entry(mb, &phba->sli.mboxq_cmpl, list) {\n\t\t\t \n\t\t\tif ((mb->vport != vport) ||\n\t\t\t\t(mb->mbox_flag & LPFC_MBX_IMED_UNREG))\n\t\t\t\tcontinue;\n\n\t\t\tif ((mb->u.mb.mbxCommand != MBX_REG_LOGIN64) &&\n\t\t\t\t(mb->u.mb.mbxCommand != MBX_REG_VPI))\n\t\t\t\tcontinue;\n\n\t\t\tmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\t\t\tif (mb->u.mb.mbxCommand == MBX_REG_LOGIN64) {\n\t\t\t\tndlp = (struct lpfc_nodelist *)mb->ctx_ndlp;\n\t\t\t\t \n\t\t\t\tmb->mbox_flag |= LPFC_MBX_IMED_UNREG;\n\t\t\t\trestart_loop = 1;\n\t\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t\tspin_lock(&ndlp->lock);\n\t\t\t\tndlp->nlp_flag &= ~NLP_IGNR_REG_CMPL;\n\t\t\t\tspin_unlock(&ndlp->lock);\n\t\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} while (restart_loop);\n\n\tspin_unlock_irq(&phba->hbalock);\n\n\t \n\twhile (!list_empty(&mbox_cmd_list)) {\n\t\tlist_remove_head(&mbox_cmd_list, mb, LPFC_MBOXQ_t, list);\n\t\tif (mb->u.mb.mbxCommand == MBX_REG_LOGIN64) {\n\t\t\tndlp = (struct lpfc_nodelist *)mb->ctx_ndlp;\n\t\t\tmb->ctx_ndlp = NULL;\n\t\t\tif (ndlp) {\n\t\t\t\tspin_lock(&ndlp->lock);\n\t\t\t\tndlp->nlp_flag &= ~NLP_IGNR_REG_CMPL;\n\t\t\t\tspin_unlock(&ndlp->lock);\n\t\t\t\tlpfc_nlp_put(ndlp);\n\t\t\t}\n\t\t}\n\t\tlpfc_mbox_rsrc_cleanup(phba, mb, MBOX_THD_UNLOCKED);\n\t}\n\n\t \n\tif (act_mbx_ndlp) {\n\t\tspin_lock(&act_mbx_ndlp->lock);\n\t\tact_mbx_ndlp->nlp_flag &= ~NLP_IGNR_REG_CMPL;\n\t\tspin_unlock(&act_mbx_ndlp->lock);\n\t\tlpfc_nlp_put(act_mbx_ndlp);\n\t}\n}\n\n \n\nuint32_t\nlpfc_drain_txq(struct lpfc_hba *phba)\n{\n\tLIST_HEAD(completions);\n\tstruct lpfc_sli_ring *pring;\n\tstruct lpfc_iocbq *piocbq = NULL;\n\tunsigned long iflags = 0;\n\tchar *fail_msg = NULL;\n\tuint32_t txq_cnt = 0;\n\tstruct lpfc_queue *wq;\n\tint ret = 0;\n\n\tif (phba->link_flag & LS_MDS_LOOPBACK) {\n\t\t \n\t\twq = phba->sli4_hba.hdwq[0].io_wq;\n\t\tif (unlikely(!wq))\n\t\t\treturn 0;\n\t\tpring = wq->pring;\n\t} else {\n\t\twq = phba->sli4_hba.els_wq;\n\t\tif (unlikely(!wq))\n\t\t\treturn 0;\n\t\tpring = lpfc_phba_elsring(phba);\n\t}\n\n\tif (unlikely(!pring) || list_empty(&pring->txq))\n\t\treturn 0;\n\n\tspin_lock_irqsave(&pring->ring_lock, iflags);\n\tlist_for_each_entry(piocbq, &pring->txq, list) {\n\t\ttxq_cnt++;\n\t}\n\n\tif (txq_cnt > pring->txq_max)\n\t\tpring->txq_max = txq_cnt;\n\n\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\n\twhile (!list_empty(&pring->txq)) {\n\t\tspin_lock_irqsave(&pring->ring_lock, iflags);\n\n\t\tpiocbq = lpfc_sli_ringtx_get(phba, pring);\n\t\tif (!piocbq) {\n\t\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2823 txq empty and txq_cnt is %d\\n \",\n\t\t\t\ttxq_cnt);\n\t\t\tbreak;\n\t\t}\n\t\ttxq_cnt--;\n\n\t\tret = __lpfc_sli_issue_iocb(phba, pring->ringno, piocbq, 0);\n\n\t\tif (ret && ret != IOCB_BUSY) {\n\t\t\tfail_msg = \" - Cannot send IO \";\n\t\t\tpiocbq->cmd_flag &= ~LPFC_DRIVER_ABORTED;\n\t\t}\n\t\tif (fail_msg) {\n\t\t\tpiocbq->cmd_flag |= LPFC_DRIVER_ABORTED;\n\t\t\t \n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2822 IOCB failed %s iotag 0x%x \"\n\t\t\t\t\t\"xri 0x%x %d flg x%x\\n\",\n\t\t\t\t\tfail_msg, piocbq->iotag,\n\t\t\t\t\tpiocbq->sli4_xritag, ret,\n\t\t\t\t\tpiocbq->cmd_flag);\n\t\t\tlist_add_tail(&piocbq->list, &completions);\n\t\t\tfail_msg = NULL;\n\t\t}\n\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\t\tif (txq_cnt == 0 || ret == IOCB_BUSY)\n\t\t\tbreak;\n\t}\n\t \n\tlpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,\n\t\t\t      IOERR_SLI_ABORTED);\n\n\treturn txq_cnt;\n}\n\n \nstatic uint16_t\nlpfc_wqe_bpl2sgl(struct lpfc_hba *phba, struct lpfc_iocbq *pwqeq,\n\t\t struct lpfc_sglq *sglq)\n{\n\tuint16_t xritag = NO_XRI;\n\tstruct ulp_bde64 *bpl = NULL;\n\tstruct ulp_bde64 bde;\n\tstruct sli4_sge *sgl  = NULL;\n\tstruct lpfc_dmabuf *dmabuf;\n\tunion lpfc_wqe128 *wqe;\n\tint numBdes = 0;\n\tint i = 0;\n\tuint32_t offset = 0;  \n\tint inbound = 0;  \n\tuint32_t cmd;\n\n\tif (!pwqeq || !sglq)\n\t\treturn xritag;\n\n\tsgl  = (struct sli4_sge *)sglq->sgl;\n\twqe = &pwqeq->wqe;\n\tpwqeq->iocb.ulpIoTag = pwqeq->iotag;\n\n\tcmd = bf_get(wqe_cmnd, &wqe->generic.wqe_com);\n\tif (cmd == CMD_XMIT_BLS_RSP64_WQE)\n\t\treturn sglq->sli4_xritag;\n\tnumBdes = pwqeq->num_bdes;\n\tif (numBdes) {\n\t\t \n\t\tif (pwqeq->bpl_dmabuf)\n\t\t\tdmabuf = pwqeq->bpl_dmabuf;\n\t\telse\n\t\t\treturn xritag;\n\n\t\tbpl  = (struct ulp_bde64 *)dmabuf->virt;\n\t\tif (!bpl)\n\t\t\treturn xritag;\n\n\t\tfor (i = 0; i < numBdes; i++) {\n\t\t\t \n\t\t\tsgl->addr_hi = bpl->addrHigh;\n\t\t\tsgl->addr_lo = bpl->addrLow;\n\n\t\t\tsgl->word2 = le32_to_cpu(sgl->word2);\n\t\t\tif ((i+1) == numBdes)\n\t\t\t\tbf_set(lpfc_sli4_sge_last, sgl, 1);\n\t\t\telse\n\t\t\t\tbf_set(lpfc_sli4_sge_last, sgl, 0);\n\t\t\t \n\t\t\tbde.tus.w = le32_to_cpu(bpl->tus.w);\n\t\t\tsgl->sge_len = cpu_to_le32(bde.tus.f.bdeSize);\n\t\t\t \n\t\t\tswitch (cmd) {\n\t\t\tcase CMD_GEN_REQUEST64_WQE:\n\t\t\t\t \n\t\t\t\tif (bpl->tus.f.bdeFlags == BUFF_TYPE_BDE_64I)\n\t\t\t\t\tinbound++;\n\t\t\t\t \n\t\t\t\tif (inbound == 1)\n\t\t\t\t\toffset = 0;\n\t\t\t\tbf_set(lpfc_sli4_sge_offset, sgl, offset);\n\t\t\t\tbf_set(lpfc_sli4_sge_type, sgl,\n\t\t\t\t\tLPFC_SGE_TYPE_DATA);\n\t\t\t\toffset += bde.tus.f.bdeSize;\n\t\t\t\tbreak;\n\t\t\tcase CMD_FCP_TRSP64_WQE:\n\t\t\t\tbf_set(lpfc_sli4_sge_offset, sgl, 0);\n\t\t\t\tbf_set(lpfc_sli4_sge_type, sgl,\n\t\t\t\t\tLPFC_SGE_TYPE_DATA);\n\t\t\t\tbreak;\n\t\t\tcase CMD_FCP_TSEND64_WQE:\n\t\t\tcase CMD_FCP_TRECEIVE64_WQE:\n\t\t\t\tbf_set(lpfc_sli4_sge_type, sgl,\n\t\t\t\t\tbpl->tus.f.bdeFlags);\n\t\t\t\tif (i < 3)\n\t\t\t\t\toffset = 0;\n\t\t\t\telse\n\t\t\t\t\toffset += bde.tus.f.bdeSize;\n\t\t\t\tbf_set(lpfc_sli4_sge_offset, sgl, offset);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsgl->word2 = cpu_to_le32(sgl->word2);\n\t\t\tbpl++;\n\t\t\tsgl++;\n\t\t}\n\t} else if (wqe->gen_req.bde.tus.f.bdeFlags == BUFF_TYPE_BDE_64) {\n\t\t \n\t\tsgl->addr_hi = cpu_to_le32(wqe->gen_req.bde.addrHigh);\n\t\tsgl->addr_lo = cpu_to_le32(wqe->gen_req.bde.addrLow);\n\t\tsgl->word2 = le32_to_cpu(sgl->word2);\n\t\tbf_set(lpfc_sli4_sge_last, sgl, 1);\n\t\tsgl->word2 = cpu_to_le32(sgl->word2);\n\t\tsgl->sge_len = cpu_to_le32(wqe->gen_req.bde.tus.f.bdeSize);\n\t}\n\treturn sglq->sli4_xritag;\n}\n\n \nint\nlpfc_sli4_issue_wqe(struct lpfc_hba *phba, struct lpfc_sli4_hdw_queue *qp,\n\t\t    struct lpfc_iocbq *pwqe)\n{\n\tunion lpfc_wqe128 *wqe = &pwqe->wqe;\n\tstruct lpfc_async_xchg_ctx *ctxp;\n\tstruct lpfc_queue *wq;\n\tstruct lpfc_sglq *sglq;\n\tstruct lpfc_sli_ring *pring;\n\tunsigned long iflags;\n\tuint32_t ret = 0;\n\n\t \n\tif (pwqe->cmd_flag & LPFC_IO_NVME_LS) {\n\t\tpring =  phba->sli4_hba.nvmels_wq->pring;\n\t\tlpfc_qp_spin_lock_irqsave(&pring->ring_lock, iflags,\n\t\t\t\t\t  qp, wq_access);\n\t\tsglq = __lpfc_sli_get_els_sglq(phba, pwqe);\n\t\tif (!sglq) {\n\t\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\t\t\treturn WQE_BUSY;\n\t\t}\n\t\tpwqe->sli4_lxritag = sglq->sli4_lxritag;\n\t\tpwqe->sli4_xritag = sglq->sli4_xritag;\n\t\tif (lpfc_wqe_bpl2sgl(phba, pwqe, sglq) == NO_XRI) {\n\t\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\t\t\treturn WQE_ERROR;\n\t\t}\n\t\tbf_set(wqe_xri_tag, &pwqe->wqe.xmit_bls_rsp.wqe_com,\n\t\t       pwqe->sli4_xritag);\n\t\tret = lpfc_sli4_wq_put(phba->sli4_hba.nvmels_wq, wqe);\n\t\tif (ret) {\n\t\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\t\t\treturn ret;\n\t\t}\n\n\t\tlpfc_sli_ringtxcmpl_put(phba, pring, pwqe);\n\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\n\t\tlpfc_sli4_poll_eq(qp->hba_eq);\n\t\treturn 0;\n\t}\n\n\t \n\tif (pwqe->cmd_flag & (LPFC_IO_NVME | LPFC_IO_FCP | LPFC_IO_CMF)) {\n\t\t \n\t\twq = qp->io_wq;\n\t\tpring = wq->pring;\n\n\t\tbf_set(wqe_cqid, &wqe->generic.wqe_com, qp->io_cq_map);\n\n\t\tlpfc_qp_spin_lock_irqsave(&pring->ring_lock, iflags,\n\t\t\t\t\t  qp, wq_access);\n\t\tret = lpfc_sli4_wq_put(wq, wqe);\n\t\tif (ret) {\n\t\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\t\t\treturn ret;\n\t\t}\n\t\tlpfc_sli_ringtxcmpl_put(phba, pring, pwqe);\n\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\n\t\tlpfc_sli4_poll_eq(qp->hba_eq);\n\t\treturn 0;\n\t}\n\n\t \n\tif (pwqe->cmd_flag & LPFC_IO_NVMET) {\n\t\t \n\t\twq = qp->io_wq;\n\t\tpring = wq->pring;\n\n\t\tctxp = pwqe->context_un.axchg;\n\t\tsglq = ctxp->ctxbuf->sglq;\n\t\tif (pwqe->sli4_xritag ==  NO_XRI) {\n\t\t\tpwqe->sli4_lxritag = sglq->sli4_lxritag;\n\t\t\tpwqe->sli4_xritag = sglq->sli4_xritag;\n\t\t}\n\t\tbf_set(wqe_xri_tag, &pwqe->wqe.xmit_bls_rsp.wqe_com,\n\t\t       pwqe->sli4_xritag);\n\t\tbf_set(wqe_cqid, &wqe->generic.wqe_com, qp->io_cq_map);\n\n\t\tlpfc_qp_spin_lock_irqsave(&pring->ring_lock, iflags,\n\t\t\t\t\t  qp, wq_access);\n\t\tret = lpfc_sli4_wq_put(wq, wqe);\n\t\tif (ret) {\n\t\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\t\t\treturn ret;\n\t\t}\n\t\tlpfc_sli_ringtxcmpl_put(phba, pring, pwqe);\n\t\tspin_unlock_irqrestore(&pring->ring_lock, iflags);\n\n\t\tlpfc_sli4_poll_eq(qp->hba_eq);\n\t\treturn 0;\n\t}\n\treturn WQE_ERROR;\n}\n\n \n\nint\nlpfc_sli4_issue_abort_iotag(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,\n\t\t\t    void *cmpl)\n{\n\tstruct lpfc_vport *vport = cmdiocb->vport;\n\tstruct lpfc_iocbq *abtsiocb = NULL;\n\tunion lpfc_wqe128 *abtswqe;\n\tstruct lpfc_io_buf *lpfc_cmd;\n\tint retval = IOCB_ERROR;\n\tu16 xritag = cmdiocb->sli4_xritag;\n\n\t \n\n\tabtsiocb = __lpfc_sli_get_iocbq(phba);\n\tif (!abtsiocb)\n\t\treturn WQE_NORESOURCE;\n\n\t \n\tcmdiocb->cmd_flag |= LPFC_DRIVER_ABORTED;\n\n\tabtswqe = &abtsiocb->wqe;\n\tmemset(abtswqe, 0, sizeof(*abtswqe));\n\n\tif (!lpfc_is_link_up(phba) || (phba->link_flag & LS_EXTERNAL_LOOPBACK))\n\t\tbf_set(abort_cmd_ia, &abtswqe->abort_cmd, 1);\n\tbf_set(abort_cmd_criteria, &abtswqe->abort_cmd, T_XRI_TAG);\n\tabtswqe->abort_cmd.rsrvd5 = 0;\n\tabtswqe->abort_cmd.wqe_com.abort_tag = xritag;\n\tbf_set(wqe_reqtag, &abtswqe->abort_cmd.wqe_com, abtsiocb->iotag);\n\tbf_set(wqe_cmnd, &abtswqe->abort_cmd.wqe_com, CMD_ABORT_XRI_CX);\n\tbf_set(wqe_xri_tag, &abtswqe->generic.wqe_com, 0);\n\tbf_set(wqe_qosd, &abtswqe->abort_cmd.wqe_com, 1);\n\tbf_set(wqe_lenloc, &abtswqe->abort_cmd.wqe_com, LPFC_WQE_LENLOC_NONE);\n\tbf_set(wqe_cmd_type, &abtswqe->abort_cmd.wqe_com, OTHER_COMMAND);\n\n\t \n\tabtsiocb->hba_wqidx = cmdiocb->hba_wqidx;\n\tabtsiocb->cmd_flag |= LPFC_USE_FCPWQIDX;\n\tif (cmdiocb->cmd_flag & LPFC_IO_FCP)\n\t\tabtsiocb->cmd_flag |= LPFC_IO_FCP;\n\tif (cmdiocb->cmd_flag & LPFC_IO_NVME)\n\t\tabtsiocb->cmd_flag |= LPFC_IO_NVME;\n\tif (cmdiocb->cmd_flag & LPFC_IO_FOF)\n\t\tabtsiocb->cmd_flag |= LPFC_IO_FOF;\n\tabtsiocb->vport = vport;\n\tabtsiocb->cmd_cmpl = cmpl;\n\n\tlpfc_cmd = container_of(cmdiocb, struct lpfc_io_buf, cur_iocbq);\n\tretval = lpfc_sli4_issue_wqe(phba, lpfc_cmd->hdwq, abtsiocb);\n\n\tlpfc_printf_vlog(vport, KERN_INFO, LOG_SLI | LOG_NVME_ABTS | LOG_FCP,\n\t\t\t \"0359 Abort xri x%x, original iotag x%x, \"\n\t\t\t \"abort cmd iotag x%x retval x%x\\n\",\n\t\t\t xritag, cmdiocb->iotag, abtsiocb->iotag, retval);\n\n\tif (retval) {\n\t\tcmdiocb->cmd_flag &= ~LPFC_DRIVER_ABORTED;\n\t\t__lpfc_sli_release_iocbq(phba, abtsiocb);\n\t}\n\n\treturn retval;\n}\n\n#ifdef LPFC_MXP_STAT\n \nvoid lpfc_snapshot_mxp(struct lpfc_hba *phba, u32 hwqid)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\tstruct lpfc_pbl_pool *pbl_pool;\n\tu32 txcmplq_cnt;\n\n\tqp = &phba->sli4_hba.hdwq[hwqid];\n\tmultixri_pool = qp->p_multixri_pool;\n\tif (!multixri_pool)\n\t\treturn;\n\n\tif (multixri_pool->stat_snapshot_taken == LPFC_MXP_SNAPSHOT_TAKEN) {\n\t\tpvt_pool = &qp->p_multixri_pool->pvt_pool;\n\t\tpbl_pool = &qp->p_multixri_pool->pbl_pool;\n\t\ttxcmplq_cnt = qp->io_wq->pring->txcmplq_cnt;\n\n\t\tmultixri_pool->stat_pbl_count = pbl_pool->count;\n\t\tmultixri_pool->stat_pvt_count = pvt_pool->count;\n\t\tmultixri_pool->stat_busy_count = txcmplq_cnt;\n\t}\n\n\tmultixri_pool->stat_snapshot_taken++;\n}\n#endif\n\n \nvoid lpfc_adjust_pvt_pool_count(struct lpfc_hba *phba, u32 hwqid)\n{\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tu32 io_req_count;\n\tu32 prev_io_req_count;\n\n\tmultixri_pool = phba->sli4_hba.hdwq[hwqid].p_multixri_pool;\n\tif (!multixri_pool)\n\t\treturn;\n\tio_req_count = multixri_pool->io_req_count;\n\tprev_io_req_count = multixri_pool->prev_io_req_count;\n\n\tif (prev_io_req_count != io_req_count) {\n\t\t \n\t\tmultixri_pool->prev_io_req_count = io_req_count;\n\t} else {\n\t\t \n\t\tlpfc_move_xri_pvt_to_pbl(phba, hwqid);\n\t}\n}\n\n \nvoid lpfc_adjust_high_watermark(struct lpfc_hba *phba, u32 hwqid)\n{\n\tu32 new_watermark;\n\tu32 watermark_max;\n\tu32 watermark_min;\n\tu32 xri_limit;\n\tu32 txcmplq_cnt;\n\tu32 abts_io_bufs;\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\n\tqp = &phba->sli4_hba.hdwq[hwqid];\n\tmultixri_pool = qp->p_multixri_pool;\n\tif (!multixri_pool)\n\t\treturn;\n\txri_limit = multixri_pool->xri_limit;\n\n\twatermark_max = xri_limit;\n\twatermark_min = xri_limit / 2;\n\n\ttxcmplq_cnt = qp->io_wq->pring->txcmplq_cnt;\n\tabts_io_bufs = qp->abts_scsi_io_bufs;\n\tabts_io_bufs += qp->abts_nvme_io_bufs;\n\n\tnew_watermark = txcmplq_cnt + abts_io_bufs;\n\tnew_watermark = min(watermark_max, new_watermark);\n\tnew_watermark = max(watermark_min, new_watermark);\n\tmultixri_pool->pvt_pool.high_watermark = new_watermark;\n\n#ifdef LPFC_MXP_STAT\n\tmultixri_pool->stat_max_hwm = max(multixri_pool->stat_max_hwm,\n\t\t\t\t\t  new_watermark);\n#endif\n}\n\n \nvoid lpfc_move_xri_pvt_to_pbl(struct lpfc_hba *phba, u32 hwqid)\n{\n\tstruct lpfc_pbl_pool *pbl_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tunsigned long iflag;\n\tstruct list_head tmp_list;\n\tu32 tmp_count;\n\n\tqp = &phba->sli4_hba.hdwq[hwqid];\n\tpbl_pool = &qp->p_multixri_pool->pbl_pool;\n\tpvt_pool = &qp->p_multixri_pool->pvt_pool;\n\ttmp_count = 0;\n\n\tlpfc_qp_spin_lock_irqsave(&pbl_pool->lock, iflag, qp, mv_to_pub_pool);\n\tlpfc_qp_spin_lock(&pvt_pool->lock, qp, mv_from_pvt_pool);\n\n\tif (pvt_pool->count > pvt_pool->low_watermark) {\n\t\t \n\n\t\t \n\t\tINIT_LIST_HEAD(&tmp_list);\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &pvt_pool->list, list) {\n\t\t\tlist_move_tail(&lpfc_ncmd->list, &tmp_list);\n\t\t\ttmp_count++;\n\t\t\tif (tmp_count >= pvt_pool->low_watermark)\n\t\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tlist_splice_init(&pvt_pool->list, &pbl_pool->list);\n\n\t\t \n\t\tlist_splice(&tmp_list, &pvt_pool->list);\n\n\t\tpbl_pool->count += (pvt_pool->count - tmp_count);\n\t\tpvt_pool->count = tmp_count;\n\t} else {\n\t\t \n\t\tlist_splice_init(&pvt_pool->list, &pbl_pool->list);\n\t\tpbl_pool->count += pvt_pool->count;\n\t\tpvt_pool->count = 0;\n\t}\n\n\tspin_unlock(&pvt_pool->lock);\n\tspin_unlock_irqrestore(&pbl_pool->lock, iflag);\n}\n\n \nstatic bool\n_lpfc_move_xri_pbl_to_pvt(struct lpfc_hba *phba, struct lpfc_sli4_hdw_queue *qp,\n\t\t\t  struct lpfc_pbl_pool *pbl_pool,\n\t\t\t  struct lpfc_pvt_pool *pvt_pool, u32 count)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tunsigned long iflag;\n\tint ret;\n\n\tret = spin_trylock_irqsave(&pbl_pool->lock, iflag);\n\tif (ret) {\n\t\tif (pbl_pool->count) {\n\t\t\t \n\t\t\tlpfc_qp_spin_lock(&pvt_pool->lock, qp, mv_to_pvt_pool);\n\t\t\tlist_for_each_entry_safe(lpfc_ncmd,\n\t\t\t\t\t\t lpfc_ncmd_next,\n\t\t\t\t\t\t &pbl_pool->list,\n\t\t\t\t\t\t list) {\n\t\t\t\tlist_move_tail(&lpfc_ncmd->list,\n\t\t\t\t\t       &pvt_pool->list);\n\t\t\t\tpvt_pool->count++;\n\t\t\t\tpbl_pool->count--;\n\t\t\t\tcount--;\n\t\t\t\tif (count == 0)\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tspin_unlock(&pvt_pool->lock);\n\t\t\tspin_unlock_irqrestore(&pbl_pool->lock, iflag);\n\t\t\treturn true;\n\t\t}\n\t\tspin_unlock_irqrestore(&pbl_pool->lock, iflag);\n\t}\n\n\treturn false;\n}\n\n \nvoid lpfc_move_xri_pbl_to_pvt(struct lpfc_hba *phba, u32 hwqid, u32 count)\n{\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tstruct lpfc_multixri_pool *next_multixri_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\tstruct lpfc_pbl_pool *pbl_pool;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tu32 next_hwqid;\n\tu32 hwq_count;\n\tint ret;\n\n\tqp = &phba->sli4_hba.hdwq[hwqid];\n\tmultixri_pool = qp->p_multixri_pool;\n\tpvt_pool = &multixri_pool->pvt_pool;\n\tpbl_pool = &multixri_pool->pbl_pool;\n\n\t \n\tret = _lpfc_move_xri_pbl_to_pvt(phba, qp, pbl_pool, pvt_pool, count);\n\tif (ret) {\n#ifdef LPFC_MXP_STAT\n\t\tmultixri_pool->local_pbl_hit_count++;\n#endif\n\t\treturn;\n\t}\n\n\thwq_count = phba->cfg_hdw_queue;\n\n\t \n\tnext_hwqid = multixri_pool->rrb_next_hwqid;\n\n\tdo {\n\t\t \n\t\tnext_hwqid = (next_hwqid + 1) % hwq_count;\n\n\t\tnext_multixri_pool =\n\t\t\tphba->sli4_hba.hdwq[next_hwqid].p_multixri_pool;\n\t\tpbl_pool = &next_multixri_pool->pbl_pool;\n\n\t\t \n\t\tret = _lpfc_move_xri_pbl_to_pvt(\n\t\t\tphba, qp, pbl_pool, pvt_pool, count);\n\n\t\t \n\t} while (!ret && next_hwqid != multixri_pool->rrb_next_hwqid);\n\n\t \n\tmultixri_pool->rrb_next_hwqid = next_hwqid;\n\n\tif (!ret) {\n\t\t \n\t\tmultixri_pool->pbl_empty_count++;\n\t}\n\n#ifdef LPFC_MXP_STAT\n\tif (ret) {\n\t\tif (next_hwqid == hwqid)\n\t\t\tmultixri_pool->local_pbl_hit_count++;\n\t\telse\n\t\t\tmultixri_pool->other_pbl_hit_count++;\n\t}\n#endif\n}\n\n \nvoid lpfc_keep_pvt_pool_above_lowwm(struct lpfc_hba *phba, u32 hwqid)\n{\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\n\tmultixri_pool = phba->sli4_hba.hdwq[hwqid].p_multixri_pool;\n\tpvt_pool = &multixri_pool->pvt_pool;\n\n\tif (pvt_pool->count < pvt_pool->low_watermark)\n\t\tlpfc_move_xri_pbl_to_pvt(phba, hwqid, XRI_BATCH);\n}\n\n \nvoid lpfc_release_io_buf(struct lpfc_hba *phba, struct lpfc_io_buf *lpfc_ncmd,\n\t\t\t struct lpfc_sli4_hdw_queue *qp)\n{\n\tunsigned long iflag;\n\tstruct lpfc_pbl_pool *pbl_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\tstruct lpfc_epd_pool *epd_pool;\n\tu32 txcmplq_cnt;\n\tu32 xri_owned;\n\tu32 xri_limit;\n\tu32 abts_io_bufs;\n\n\t \n\tlpfc_ncmd->nvmeCmd = NULL;\n\tlpfc_ncmd->cur_iocbq.cmd_cmpl = NULL;\n\n\tif (phba->cfg_xpsgl && !phba->nvmet_support &&\n\t    !list_empty(&lpfc_ncmd->dma_sgl_xtra_list))\n\t\tlpfc_put_sgl_per_hdwq(phba, lpfc_ncmd);\n\n\tif (!list_empty(&lpfc_ncmd->dma_cmd_rsp_list))\n\t\tlpfc_put_cmd_rsp_buf_per_hdwq(phba, lpfc_ncmd);\n\n\tif (phba->cfg_xri_rebalancing) {\n\t\tif (lpfc_ncmd->expedite) {\n\t\t\t \n\t\t\tepd_pool = &phba->epd_pool;\n\t\t\tspin_lock_irqsave(&epd_pool->lock, iflag);\n\t\t\tlist_add_tail(&lpfc_ncmd->list, &epd_pool->list);\n\t\t\tepd_pool->count++;\n\t\t\tspin_unlock_irqrestore(&epd_pool->lock, iflag);\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tif (!qp->p_multixri_pool)\n\t\t\treturn;\n\n\t\tpbl_pool = &qp->p_multixri_pool->pbl_pool;\n\t\tpvt_pool = &qp->p_multixri_pool->pvt_pool;\n\n\t\ttxcmplq_cnt = qp->io_wq->pring->txcmplq_cnt;\n\t\tabts_io_bufs = qp->abts_scsi_io_bufs;\n\t\tabts_io_bufs += qp->abts_nvme_io_bufs;\n\n\t\txri_owned = pvt_pool->count + txcmplq_cnt + abts_io_bufs;\n\t\txri_limit = qp->p_multixri_pool->xri_limit;\n\n#ifdef LPFC_MXP_STAT\n\t\tif (xri_owned <= xri_limit)\n\t\t\tqp->p_multixri_pool->below_limit_count++;\n\t\telse\n\t\t\tqp->p_multixri_pool->above_limit_count++;\n#endif\n\n\t\t \n\t\tif ((pvt_pool->count < pvt_pool->low_watermark) ||\n\t\t    (xri_owned < xri_limit &&\n\t\t     pvt_pool->count < pvt_pool->high_watermark)) {\n\t\t\tlpfc_qp_spin_lock_irqsave(&pvt_pool->lock, iflag,\n\t\t\t\t\t\t  qp, free_pvt_pool);\n\t\t\tlist_add_tail(&lpfc_ncmd->list,\n\t\t\t\t      &pvt_pool->list);\n\t\t\tpvt_pool->count++;\n\t\t\tspin_unlock_irqrestore(&pvt_pool->lock, iflag);\n\t\t} else {\n\t\t\tlpfc_qp_spin_lock_irqsave(&pbl_pool->lock, iflag,\n\t\t\t\t\t\t  qp, free_pub_pool);\n\t\t\tlist_add_tail(&lpfc_ncmd->list,\n\t\t\t\t      &pbl_pool->list);\n\t\t\tpbl_pool->count++;\n\t\t\tspin_unlock_irqrestore(&pbl_pool->lock, iflag);\n\t\t}\n\t} else {\n\t\tlpfc_qp_spin_lock_irqsave(&qp->io_buf_list_put_lock, iflag,\n\t\t\t\t\t  qp, free_xri);\n\t\tlist_add_tail(&lpfc_ncmd->list,\n\t\t\t      &qp->lpfc_io_buf_list_put);\n\t\tqp->put_io_bufs++;\n\t\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock,\n\t\t\t\t       iflag);\n\t}\n}\n\n \nstatic struct lpfc_io_buf *\nlpfc_get_io_buf_from_private_pool(struct lpfc_hba *phba,\n\t\t\t\t  struct lpfc_sli4_hdw_queue *qp,\n\t\t\t\t  struct lpfc_pvt_pool *pvt_pool,\n\t\t\t\t  struct lpfc_nodelist *ndlp)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tunsigned long iflag;\n\n\tlpfc_qp_spin_lock_irqsave(&pvt_pool->lock, iflag, qp, alloc_pvt_pool);\n\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t &pvt_pool->list, list) {\n\t\tif (lpfc_test_rrq_active(\n\t\t\tphba, ndlp, lpfc_ncmd->cur_iocbq.sli4_lxritag))\n\t\t\tcontinue;\n\t\tlist_del(&lpfc_ncmd->list);\n\t\tpvt_pool->count--;\n\t\tspin_unlock_irqrestore(&pvt_pool->lock, iflag);\n\t\treturn lpfc_ncmd;\n\t}\n\tspin_unlock_irqrestore(&pvt_pool->lock, iflag);\n\n\treturn NULL;\n}\n\n \nstatic struct lpfc_io_buf *\nlpfc_get_io_buf_from_expedite_pool(struct lpfc_hba *phba)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd = NULL, *iter;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tunsigned long iflag;\n\tstruct lpfc_epd_pool *epd_pool;\n\n\tepd_pool = &phba->epd_pool;\n\n\tspin_lock_irqsave(&epd_pool->lock, iflag);\n\tif (epd_pool->count > 0) {\n\t\tlist_for_each_entry_safe(iter, lpfc_ncmd_next,\n\t\t\t\t\t &epd_pool->list, list) {\n\t\t\tlist_del(&iter->list);\n\t\t\tepd_pool->count--;\n\t\t\tlpfc_ncmd = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&epd_pool->lock, iflag);\n\n\treturn lpfc_ncmd;\n}\n\n \nstatic struct lpfc_io_buf *\nlpfc_get_io_buf_from_multixri_pools(struct lpfc_hba *phba,\n\t\t\t\t    struct lpfc_nodelist *ndlp,\n\t\t\t\t    int hwqid, int expedite)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\n\tqp = &phba->sli4_hba.hdwq[hwqid];\n\tlpfc_ncmd = NULL;\n\tif (!qp) {\n\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\tLOG_SLI | LOG_NVME_ABTS | LOG_FCP,\n\t\t\t\t\"5556 NULL qp for hwqid  x%x\\n\", hwqid);\n\t\treturn lpfc_ncmd;\n\t}\n\tmultixri_pool = qp->p_multixri_pool;\n\tif (!multixri_pool) {\n\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\tLOG_SLI | LOG_NVME_ABTS | LOG_FCP,\n\t\t\t\t\"5557 NULL multixri for hwqid  x%x\\n\", hwqid);\n\t\treturn lpfc_ncmd;\n\t}\n\tpvt_pool = &multixri_pool->pvt_pool;\n\tif (!pvt_pool) {\n\t\tlpfc_printf_log(phba, KERN_INFO,\n\t\t\t\tLOG_SLI | LOG_NVME_ABTS | LOG_FCP,\n\t\t\t\t\"5558 NULL pvt_pool for hwqid  x%x\\n\", hwqid);\n\t\treturn lpfc_ncmd;\n\t}\n\tmultixri_pool->io_req_count++;\n\n\t \n\tif (pvt_pool->count == 0)\n\t\tlpfc_move_xri_pbl_to_pvt(phba, hwqid, XRI_BATCH);\n\n\t \n\tlpfc_ncmd = lpfc_get_io_buf_from_private_pool(phba, qp, pvt_pool, ndlp);\n\n\tif (lpfc_ncmd) {\n\t\tlpfc_ncmd->hdwq = qp;\n\t\tlpfc_ncmd->hdwq_no = hwqid;\n\t} else if (expedite) {\n\t\t \n\t\tlpfc_ncmd = lpfc_get_io_buf_from_expedite_pool(phba);\n\t}\n\n\treturn lpfc_ncmd;\n}\n\nstatic inline struct lpfc_io_buf *\nlpfc_io_buf(struct lpfc_hba *phba, struct lpfc_nodelist *ndlp, int idx)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_cmd, *lpfc_cmd_next;\n\n\tqp = &phba->sli4_hba.hdwq[idx];\n\tlist_for_each_entry_safe(lpfc_cmd, lpfc_cmd_next,\n\t\t\t\t &qp->lpfc_io_buf_list_get, list) {\n\t\tif (lpfc_test_rrq_active(phba, ndlp,\n\t\t\t\t\t lpfc_cmd->cur_iocbq.sli4_lxritag))\n\t\t\tcontinue;\n\n\t\tif (lpfc_cmd->flags & LPFC_SBUF_NOT_POSTED)\n\t\t\tcontinue;\n\n\t\tlist_del_init(&lpfc_cmd->list);\n\t\tqp->get_io_bufs--;\n\t\tlpfc_cmd->hdwq = qp;\n\t\tlpfc_cmd->hdwq_no = idx;\n\t\treturn lpfc_cmd;\n\t}\n\treturn NULL;\n}\n\n \nstruct lpfc_io_buf *lpfc_get_io_buf(struct lpfc_hba *phba,\n\t\t\t\t    struct lpfc_nodelist *ndlp,\n\t\t\t\t    u32 hwqid, int expedite)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tunsigned long iflag;\n\tstruct lpfc_io_buf *lpfc_cmd;\n\n\tqp = &phba->sli4_hba.hdwq[hwqid];\n\tlpfc_cmd = NULL;\n\tif (!qp) {\n\t\tlpfc_printf_log(phba, KERN_WARNING,\n\t\t\t\tLOG_SLI | LOG_NVME_ABTS | LOG_FCP,\n\t\t\t\t\"5555 NULL qp for hwqid  x%x\\n\", hwqid);\n\t\treturn lpfc_cmd;\n\t}\n\n\tif (phba->cfg_xri_rebalancing)\n\t\tlpfc_cmd = lpfc_get_io_buf_from_multixri_pools(\n\t\t\tphba, ndlp, hwqid, expedite);\n\telse {\n\t\tlpfc_qp_spin_lock_irqsave(&qp->io_buf_list_get_lock, iflag,\n\t\t\t\t\t  qp, alloc_xri_get);\n\t\tif (qp->get_io_bufs > LPFC_NVME_EXPEDITE_XRICNT || expedite)\n\t\t\tlpfc_cmd = lpfc_io_buf(phba, ndlp, hwqid);\n\t\tif (!lpfc_cmd) {\n\t\t\tlpfc_qp_spin_lock(&qp->io_buf_list_put_lock,\n\t\t\t\t\t  qp, alloc_xri_put);\n\t\t\tlist_splice(&qp->lpfc_io_buf_list_put,\n\t\t\t\t    &qp->lpfc_io_buf_list_get);\n\t\t\tqp->get_io_bufs += qp->put_io_bufs;\n\t\t\tINIT_LIST_HEAD(&qp->lpfc_io_buf_list_put);\n\t\t\tqp->put_io_bufs = 0;\n\t\t\tspin_unlock(&qp->io_buf_list_put_lock);\n\t\t\tif (qp->get_io_bufs > LPFC_NVME_EXPEDITE_XRICNT ||\n\t\t\t    expedite)\n\t\t\t\tlpfc_cmd = lpfc_io_buf(phba, ndlp, hwqid);\n\t\t}\n\t\tspin_unlock_irqrestore(&qp->io_buf_list_get_lock, iflag);\n\t}\n\n\treturn lpfc_cmd;\n}\n\n \nint\nlpfc_read_object(struct lpfc_hba *phba, char *rdobject, uint32_t *datap,\n\t\t uint32_t datasz)\n{\n\tstruct lpfc_mbx_read_object *read_object;\n\tLPFC_MBOXQ_t *mbox;\n\tint rc, length, eof, j, byte_cnt = 0;\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tstruct lpfc_dmabuf *pcmd;\n\tu32 rd_object_name[LPFC_MBX_OBJECT_NAME_LEN_DW] = {0};\n\n\tmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mbox)\n\t\treturn -ENOMEM;\n\tlength = (sizeof(struct lpfc_mbx_read_object) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_READ_OBJECT,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tread_object = &mbox->u.mqe.un.read_object;\n\tshdr = (union lpfc_sli4_cfg_shdr *)&read_object->header.cfg_shdr;\n\n\tbf_set(lpfc_mbox_hdr_version, &shdr->request, LPFC_Q_CREATE_VERSION_0);\n\tbf_set(lpfc_mbx_rd_object_rlen, &read_object->u.request, datasz);\n\tread_object->u.request.rd_object_offset = 0;\n\tread_object->u.request.rd_object_cnt = 1;\n\n\tmemset((void *)read_object->u.request.rd_object_name, 0,\n\t       LPFC_OBJ_NAME_SZ);\n\tscnprintf((char *)rd_object_name, sizeof(rd_object_name), rdobject);\n\tfor (j = 0; j < strlen(rdobject); j++)\n\t\tread_object->u.request.rd_object_name[j] =\n\t\t\tcpu_to_le32(rd_object_name[j]);\n\n\tpcmd = kmalloc(sizeof(*pcmd), GFP_KERNEL);\n\tif (pcmd)\n\t\tpcmd->virt = lpfc_mbuf_alloc(phba, MEM_PRI, &pcmd->phys);\n\tif (!pcmd || !pcmd->virt) {\n\t\tkfree(pcmd);\n\t\tmempool_free(mbox, phba->mbox_mem_pool);\n\t\treturn -ENOMEM;\n\t}\n\tmemset((void *)pcmd->virt, 0, LPFC_BPL_SIZE);\n\tread_object->u.request.rd_object_hbuf[0].pa_lo =\n\t\tputPaddrLow(pcmd->phys);\n\tread_object->u.request.rd_object_hbuf[0].pa_hi =\n\t\tputPaddrHigh(pcmd->phys);\n\tread_object->u.request.rd_object_hbuf[0].length = LPFC_BPL_SIZE;\n\n\tmbox->vport = phba->pport;\n\tmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\tmbox->ctx_ndlp = NULL;\n\n\trc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\n\tif (shdr_status == STATUS_FAILED &&\n\t    shdr_add_status == ADD_STATUS_INVALID_OBJECT_NAME) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_CGN_MGMT,\n\t\t\t\t\"4674 No port cfg file in FW.\\n\");\n\t\tbyte_cnt = -ENOENT;\n\t} else if (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_CGN_MGMT,\n\t\t\t\t\"2625 READ_OBJECT mailbox failed with \"\n\t\t\t\t\"status x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tbyte_cnt = -ENXIO;\n\t} else {\n\t\t \n\t\tlength = read_object->u.response.rd_object_actual_rlen;\n\t\teof = bf_get(lpfc_mbx_rd_object_eof, &read_object->u.response);\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_CGN_MGMT,\n\t\t\t\t\"2626 READ_OBJECT Success len %d:%d, EOF %d\\n\",\n\t\t\t\tlength, datasz, eof);\n\n\t\t \n\t\tif (!length && eof) {\n\t\t\tbyte_cnt = 0;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tbyte_cnt = length;\n\t\tlpfc_sli_pcimem_bcopy(pcmd->virt, datap, byte_cnt);\n\t}\n\n exit:\n\t \n\tlpfc_mbuf_free(phba, pcmd->virt, pcmd->phys);\n\tkfree(pcmd);\n\tlpfc_sli4_mbox_cmd_free(phba, mbox);\n\treturn byte_cnt;\n}\n\n \nstruct sli4_hybrid_sgl *\nlpfc_get_sgl_per_hdwq(struct lpfc_hba *phba, struct lpfc_io_buf *lpfc_buf)\n{\n\tstruct sli4_hybrid_sgl *list_entry = NULL;\n\tstruct sli4_hybrid_sgl *tmp = NULL;\n\tstruct sli4_hybrid_sgl *allocated_sgl = NULL;\n\tstruct lpfc_sli4_hdw_queue *hdwq = lpfc_buf->hdwq;\n\tstruct list_head *buf_list = &hdwq->sgl_list;\n\tunsigned long iflags;\n\n\tspin_lock_irqsave(&hdwq->hdwq_lock, iflags);\n\n\tif (likely(!list_empty(buf_list))) {\n\t\t \n\t\tlist_for_each_entry_safe(list_entry, tmp,\n\t\t\t\t\t buf_list, list_node) {\n\t\t\tlist_move_tail(&list_entry->list_node,\n\t\t\t\t       &lpfc_buf->dma_sgl_xtra_list);\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\t \n\t\tspin_unlock_irqrestore(&hdwq->hdwq_lock, iflags);\n\t\ttmp = kmalloc_node(sizeof(*tmp), GFP_ATOMIC,\n\t\t\t\t   cpu_to_node(hdwq->io_wq->chann));\n\t\tif (!tmp) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\t\"8353 error kmalloc memory for HDWQ \"\n\t\t\t\t\t\"%d %s\\n\",\n\t\t\t\t\tlpfc_buf->hdwq_no, __func__);\n\t\t\treturn NULL;\n\t\t}\n\n\t\ttmp->dma_sgl = dma_pool_alloc(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t\t      GFP_ATOMIC, &tmp->dma_phys_sgl);\n\t\tif (!tmp->dma_sgl) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\t\"8354 error pool_alloc memory for HDWQ \"\n\t\t\t\t\t\"%d %s\\n\",\n\t\t\t\t\tlpfc_buf->hdwq_no, __func__);\n\t\t\tkfree(tmp);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tspin_lock_irqsave(&hdwq->hdwq_lock, iflags);\n\t\tlist_add_tail(&tmp->list_node, &lpfc_buf->dma_sgl_xtra_list);\n\t}\n\n\tallocated_sgl = list_last_entry(&lpfc_buf->dma_sgl_xtra_list,\n\t\t\t\t\tstruct sli4_hybrid_sgl,\n\t\t\t\t\tlist_node);\n\n\tspin_unlock_irqrestore(&hdwq->hdwq_lock, iflags);\n\n\treturn allocated_sgl;\n}\n\n \nint\nlpfc_put_sgl_per_hdwq(struct lpfc_hba *phba, struct lpfc_io_buf *lpfc_buf)\n{\n\tint rc = 0;\n\tstruct sli4_hybrid_sgl *list_entry = NULL;\n\tstruct sli4_hybrid_sgl *tmp = NULL;\n\tstruct lpfc_sli4_hdw_queue *hdwq = lpfc_buf->hdwq;\n\tstruct list_head *buf_list = &hdwq->sgl_list;\n\tunsigned long iflags;\n\n\tspin_lock_irqsave(&hdwq->hdwq_lock, iflags);\n\n\tif (likely(!list_empty(&lpfc_buf->dma_sgl_xtra_list))) {\n\t\tlist_for_each_entry_safe(list_entry, tmp,\n\t\t\t\t\t &lpfc_buf->dma_sgl_xtra_list,\n\t\t\t\t\t list_node) {\n\t\t\tlist_move_tail(&list_entry->list_node,\n\t\t\t\t       buf_list);\n\t\t}\n\t} else {\n\t\trc = -EINVAL;\n\t}\n\n\tspin_unlock_irqrestore(&hdwq->hdwq_lock, iflags);\n\treturn rc;\n}\n\n \nvoid\nlpfc_free_sgl_per_hdwq(struct lpfc_hba *phba,\n\t\t       struct lpfc_sli4_hdw_queue *hdwq)\n{\n\tstruct list_head *buf_list = &hdwq->sgl_list;\n\tstruct sli4_hybrid_sgl *list_entry = NULL;\n\tstruct sli4_hybrid_sgl *tmp = NULL;\n\tunsigned long iflags;\n\n\tspin_lock_irqsave(&hdwq->hdwq_lock, iflags);\n\n\t \n\tlist_for_each_entry_safe(list_entry, tmp,\n\t\t\t\t buf_list, list_node) {\n\t\tlist_del(&list_entry->list_node);\n\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t      list_entry->dma_sgl,\n\t\t\t      list_entry->dma_phys_sgl);\n\t\tkfree(list_entry);\n\t}\n\n\tspin_unlock_irqrestore(&hdwq->hdwq_lock, iflags);\n}\n\n \nstruct fcp_cmd_rsp_buf *\nlpfc_get_cmd_rsp_buf_per_hdwq(struct lpfc_hba *phba,\n\t\t\t      struct lpfc_io_buf *lpfc_buf)\n{\n\tstruct fcp_cmd_rsp_buf *list_entry = NULL;\n\tstruct fcp_cmd_rsp_buf *tmp = NULL;\n\tstruct fcp_cmd_rsp_buf *allocated_buf = NULL;\n\tstruct lpfc_sli4_hdw_queue *hdwq = lpfc_buf->hdwq;\n\tstruct list_head *buf_list = &hdwq->cmd_rsp_buf_list;\n\tunsigned long iflags;\n\n\tspin_lock_irqsave(&hdwq->hdwq_lock, iflags);\n\n\tif (likely(!list_empty(buf_list))) {\n\t\t \n\t\tlist_for_each_entry_safe(list_entry, tmp,\n\t\t\t\t\t buf_list,\n\t\t\t\t\t list_node) {\n\t\t\tlist_move_tail(&list_entry->list_node,\n\t\t\t\t       &lpfc_buf->dma_cmd_rsp_list);\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\t \n\t\tspin_unlock_irqrestore(&hdwq->hdwq_lock, iflags);\n\t\ttmp = kmalloc_node(sizeof(*tmp), GFP_ATOMIC,\n\t\t\t\t   cpu_to_node(hdwq->io_wq->chann));\n\t\tif (!tmp) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\t\"8355 error kmalloc memory for HDWQ \"\n\t\t\t\t\t\"%d %s\\n\",\n\t\t\t\t\tlpfc_buf->hdwq_no, __func__);\n\t\t\treturn NULL;\n\t\t}\n\n\t\ttmp->fcp_cmnd = dma_pool_zalloc(phba->lpfc_cmd_rsp_buf_pool,\n\t\t\t\t\t\tGFP_ATOMIC,\n\t\t\t\t\t\t&tmp->fcp_cmd_rsp_dma_handle);\n\n\t\tif (!tmp->fcp_cmnd) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\t\"8356 error pool_alloc memory for HDWQ \"\n\t\t\t\t\t\"%d %s\\n\",\n\t\t\t\t\tlpfc_buf->hdwq_no, __func__);\n\t\t\tkfree(tmp);\n\t\t\treturn NULL;\n\t\t}\n\n\t\ttmp->fcp_rsp = (struct fcp_rsp *)((uint8_t *)tmp->fcp_cmnd +\n\t\t\t\tsizeof(struct fcp_cmnd));\n\n\t\tspin_lock_irqsave(&hdwq->hdwq_lock, iflags);\n\t\tlist_add_tail(&tmp->list_node, &lpfc_buf->dma_cmd_rsp_list);\n\t}\n\n\tallocated_buf = list_last_entry(&lpfc_buf->dma_cmd_rsp_list,\n\t\t\t\t\tstruct fcp_cmd_rsp_buf,\n\t\t\t\t\tlist_node);\n\n\tspin_unlock_irqrestore(&hdwq->hdwq_lock, iflags);\n\n\treturn allocated_buf;\n}\n\n \nint\nlpfc_put_cmd_rsp_buf_per_hdwq(struct lpfc_hba *phba,\n\t\t\t      struct lpfc_io_buf *lpfc_buf)\n{\n\tint rc = 0;\n\tstruct fcp_cmd_rsp_buf *list_entry = NULL;\n\tstruct fcp_cmd_rsp_buf *tmp = NULL;\n\tstruct lpfc_sli4_hdw_queue *hdwq = lpfc_buf->hdwq;\n\tstruct list_head *buf_list = &hdwq->cmd_rsp_buf_list;\n\tunsigned long iflags;\n\n\tspin_lock_irqsave(&hdwq->hdwq_lock, iflags);\n\n\tif (likely(!list_empty(&lpfc_buf->dma_cmd_rsp_list))) {\n\t\tlist_for_each_entry_safe(list_entry, tmp,\n\t\t\t\t\t &lpfc_buf->dma_cmd_rsp_list,\n\t\t\t\t\t list_node) {\n\t\t\tlist_move_tail(&list_entry->list_node,\n\t\t\t\t       buf_list);\n\t\t}\n\t} else {\n\t\trc = -EINVAL;\n\t}\n\n\tspin_unlock_irqrestore(&hdwq->hdwq_lock, iflags);\n\treturn rc;\n}\n\n \nvoid\nlpfc_free_cmd_rsp_buf_per_hdwq(struct lpfc_hba *phba,\n\t\t\t       struct lpfc_sli4_hdw_queue *hdwq)\n{\n\tstruct list_head *buf_list = &hdwq->cmd_rsp_buf_list;\n\tstruct fcp_cmd_rsp_buf *list_entry = NULL;\n\tstruct fcp_cmd_rsp_buf *tmp = NULL;\n\tunsigned long iflags;\n\n\tspin_lock_irqsave(&hdwq->hdwq_lock, iflags);\n\n\t \n\tlist_for_each_entry_safe(list_entry, tmp,\n\t\t\t\t buf_list,\n\t\t\t\t list_node) {\n\t\tlist_del(&list_entry->list_node);\n\t\tdma_pool_free(phba->lpfc_cmd_rsp_buf_pool,\n\t\t\t      list_entry->fcp_cmnd,\n\t\t\t      list_entry->fcp_cmd_rsp_dma_handle);\n\t\tkfree(list_entry);\n\t}\n\n\tspin_unlock_irqrestore(&hdwq->hdwq_lock, iflags);\n}\n\n \nvoid\nlpfc_sli_prep_wqe(struct lpfc_hba *phba, struct lpfc_iocbq *job)\n{\n\tu8 cmnd;\n\tu32 *pcmd;\n\tu32 if_type = 0;\n\tu32 fip, abort_tag;\n\tstruct lpfc_nodelist *ndlp = NULL;\n\tunion lpfc_wqe128 *wqe = &job->wqe;\n\tu8 command_type = ELS_COMMAND_NON_FIP;\n\n\tfip = phba->hba_flag & HBA_FIP_SUPPORT;\n\t \n\tif (job->cmd_flag &  LPFC_IO_FCP)\n\t\tcommand_type = FCP_COMMAND;\n\telse if (fip && (job->cmd_flag & LPFC_FIP_ELS_ID_MASK))\n\t\tcommand_type = ELS_COMMAND_FIP;\n\telse\n\t\tcommand_type = ELS_COMMAND_NON_FIP;\n\n\tabort_tag = job->iotag;\n\tcmnd = bf_get(wqe_cmnd, &wqe->els_req.wqe_com);\n\n\tswitch (cmnd) {\n\tcase CMD_ELS_REQUEST64_WQE:\n\t\tndlp = job->ndlp;\n\n\t\tif_type = bf_get(lpfc_sli_intf_if_type,\n\t\t\t\t &phba->sli4_hba.sli_intf);\n\t\tif (if_type >= LPFC_SLI_INTF_IF_TYPE_2) {\n\t\t\tpcmd = (u32 *)job->cmd_dmabuf->virt;\n\t\t\tif (pcmd && (*pcmd == ELS_CMD_FLOGI ||\n\t\t\t\t     *pcmd == ELS_CMD_SCR ||\n\t\t\t\t     *pcmd == ELS_CMD_RDF ||\n\t\t\t\t     *pcmd == ELS_CMD_EDC ||\n\t\t\t\t     *pcmd == ELS_CMD_RSCN_XMT ||\n\t\t\t\t     *pcmd == ELS_CMD_FDISC ||\n\t\t\t\t     *pcmd == ELS_CMD_LOGO ||\n\t\t\t\t     *pcmd == ELS_CMD_QFPA ||\n\t\t\t\t     *pcmd == ELS_CMD_UVEM ||\n\t\t\t\t     *pcmd == ELS_CMD_PLOGI)) {\n\t\t\t\tbf_set(els_req64_sp, &wqe->els_req, 1);\n\t\t\t\tbf_set(els_req64_sid, &wqe->els_req,\n\t\t\t\t       job->vport->fc_myDID);\n\n\t\t\t\tif ((*pcmd == ELS_CMD_FLOGI) &&\n\t\t\t\t    !(phba->fc_topology ==\n\t\t\t\t      LPFC_TOPOLOGY_LOOP))\n\t\t\t\t\tbf_set(els_req64_sid, &wqe->els_req, 0);\n\n\t\t\t\tbf_set(wqe_ct, &wqe->els_req.wqe_com, 1);\n\t\t\t\tbf_set(wqe_ctxt_tag, &wqe->els_req.wqe_com,\n\t\t\t\t       phba->vpi_ids[job->vport->vpi]);\n\t\t\t} else if (pcmd) {\n\t\t\t\tbf_set(wqe_ct, &wqe->els_req.wqe_com, 0);\n\t\t\t\tbf_set(wqe_ctxt_tag, &wqe->els_req.wqe_com,\n\t\t\t\t       phba->sli4_hba.rpi_ids[ndlp->nlp_rpi]);\n\t\t\t}\n\t\t}\n\n\t\tbf_set(wqe_temp_rpi, &wqe->els_req.wqe_com,\n\t\t       phba->sli4_hba.rpi_ids[ndlp->nlp_rpi]);\n\n\t\tbf_set(wqe_dbde, &wqe->els_req.wqe_com, 1);\n\t\tbf_set(wqe_iod, &wqe->els_req.wqe_com, LPFC_WQE_IOD_READ);\n\t\tbf_set(wqe_qosd, &wqe->els_req.wqe_com, 1);\n\t\tbf_set(wqe_lenloc, &wqe->els_req.wqe_com, LPFC_WQE_LENLOC_NONE);\n\t\tbf_set(wqe_ebde_cnt, &wqe->els_req.wqe_com, 0);\n\t\tbreak;\n\tcase CMD_XMIT_ELS_RSP64_WQE:\n\t\tndlp = job->ndlp;\n\n\t\t \n\t\twqe->xmit_els_rsp.word4 = 0;\n\n\t\tif_type = bf_get(lpfc_sli_intf_if_type,\n\t\t\t\t &phba->sli4_hba.sli_intf);\n\t\tif (if_type >= LPFC_SLI_INTF_IF_TYPE_2) {\n\t\t\tif (job->vport->fc_flag & FC_PT2PT) {\n\t\t\t\tbf_set(els_rsp64_sp, &wqe->xmit_els_rsp, 1);\n\t\t\t\tbf_set(els_rsp64_sid, &wqe->xmit_els_rsp,\n\t\t\t\t       job->vport->fc_myDID);\n\t\t\t\tif (job->vport->fc_myDID == Fabric_DID) {\n\t\t\t\t\tbf_set(wqe_els_did,\n\t\t\t\t\t       &wqe->xmit_els_rsp.wqe_dest, 0);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tbf_set(wqe_dbde, &wqe->xmit_els_rsp.wqe_com, 1);\n\t\tbf_set(wqe_iod, &wqe->xmit_els_rsp.wqe_com, LPFC_WQE_IOD_WRITE);\n\t\tbf_set(wqe_qosd, &wqe->xmit_els_rsp.wqe_com, 1);\n\t\tbf_set(wqe_lenloc, &wqe->xmit_els_rsp.wqe_com,\n\t\t       LPFC_WQE_LENLOC_WORD3);\n\t\tbf_set(wqe_ebde_cnt, &wqe->xmit_els_rsp.wqe_com, 0);\n\n\t\tif (phba->fc_topology == LPFC_TOPOLOGY_LOOP) {\n\t\t\tbf_set(els_rsp64_sp, &wqe->xmit_els_rsp, 1);\n\t\t\tbf_set(els_rsp64_sid, &wqe->xmit_els_rsp,\n\t\t\t       job->vport->fc_myDID);\n\t\t\tbf_set(wqe_ct, &wqe->xmit_els_rsp.wqe_com, 1);\n\t\t}\n\n\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\tbf_set(wqe_rsp_temp_rpi, &wqe->xmit_els_rsp,\n\t\t\t       phba->sli4_hba.rpi_ids[ndlp->nlp_rpi]);\n\n\t\t\tif (bf_get(wqe_ct, &wqe->xmit_els_rsp.wqe_com))\n\t\t\t\tbf_set(wqe_ctxt_tag, &wqe->xmit_els_rsp.wqe_com,\n\t\t\t\t       phba->vpi_ids[job->vport->vpi]);\n\t\t}\n\t\tcommand_type = OTHER_COMMAND;\n\t\tbreak;\n\tcase CMD_GEN_REQUEST64_WQE:\n\t\t \n\t\tbf_set(wqe_dbde, &wqe->gen_req.wqe_com, 1);\n\t\tbf_set(wqe_iod, &wqe->gen_req.wqe_com, LPFC_WQE_IOD_READ);\n\t\tbf_set(wqe_qosd, &wqe->gen_req.wqe_com, 1);\n\t\tbf_set(wqe_lenloc, &wqe->gen_req.wqe_com, LPFC_WQE_LENLOC_NONE);\n\t\tbf_set(wqe_ebde_cnt, &wqe->gen_req.wqe_com, 0);\n\t\tcommand_type = OTHER_COMMAND;\n\t\tbreak;\n\tcase CMD_XMIT_SEQUENCE64_WQE:\n\t\tif (phba->link_flag & LS_LOOPBACK_MODE)\n\t\t\tbf_set(wqe_xo, &wqe->xmit_sequence.wge_ctl, 1);\n\n\t\twqe->xmit_sequence.rsvd3 = 0;\n\t\tbf_set(wqe_pu, &wqe->xmit_sequence.wqe_com, 0);\n\t\tbf_set(wqe_dbde, &wqe->xmit_sequence.wqe_com, 1);\n\t\tbf_set(wqe_iod, &wqe->xmit_sequence.wqe_com,\n\t\t       LPFC_WQE_IOD_WRITE);\n\t\tbf_set(wqe_lenloc, &wqe->xmit_sequence.wqe_com,\n\t\t       LPFC_WQE_LENLOC_WORD12);\n\t\tbf_set(wqe_ebde_cnt, &wqe->xmit_sequence.wqe_com, 0);\n\t\tcommand_type = OTHER_COMMAND;\n\t\tbreak;\n\tcase CMD_XMIT_BLS_RSP64_WQE:\n\t\tbf_set(xmit_bls_rsp64_seqcnthi, &wqe->xmit_bls_rsp, 0xffff);\n\t\tbf_set(wqe_xmit_bls_pt, &wqe->xmit_bls_rsp.wqe_dest, 0x1);\n\t\tbf_set(wqe_ct, &wqe->xmit_bls_rsp.wqe_com, 1);\n\t\tbf_set(wqe_ctxt_tag, &wqe->xmit_bls_rsp.wqe_com,\n\t\t       phba->vpi_ids[phba->pport->vpi]);\n\t\tbf_set(wqe_qosd, &wqe->xmit_bls_rsp.wqe_com, 1);\n\t\tbf_set(wqe_lenloc, &wqe->xmit_bls_rsp.wqe_com,\n\t\t       LPFC_WQE_LENLOC_NONE);\n\t\t \n\t\tcommand_type = OTHER_COMMAND;\n\t\tbreak;\n\tcase CMD_FCP_ICMND64_WQE:\t \n\tcase CMD_ABORT_XRI_WQE:\t\t \n\tcase CMD_SEND_FRAME:\t\t \n\t\t \n\t\treturn;\n\tdefault:\n\t\tdump_stack();\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6207 Invalid command 0x%x\\n\",\n\t\t\t\tcmnd);\n\t\tbreak;\n\t}\n\n\twqe->generic.wqe_com.abort_tag = abort_tag;\n\tbf_set(wqe_reqtag, &wqe->generic.wqe_com, job->iotag);\n\tbf_set(wqe_cmd_type, &wqe->generic.wqe_com, command_type);\n\tbf_set(wqe_cqid, &wqe->generic.wqe_com, LPFC_WQE_CQ_ID_DEFAULT);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}