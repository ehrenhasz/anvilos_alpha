{
  "module_name": "ql4_iocb.c",
  "hash_id": "50fa7a2fb52e1c6045f7263ab4c09538cb0a203e3884b1739340ef163f9715dd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/qla4xxx/ql4_iocb.c",
  "human_readable_source": "\n \n\n#include \"ql4_def.h\"\n#include \"ql4_glbl.h\"\n#include \"ql4_dbg.h\"\n#include \"ql4_inline.h\"\n\n#include <scsi/scsi_tcq.h>\n\nstatic int\nqla4xxx_space_in_req_ring(struct scsi_qla_host *ha, uint16_t req_cnt)\n{\n\tuint16_t cnt;\n\n\t \n\tif ((req_cnt + 2) >= ha->req_q_count) {\n\t\tcnt = (uint16_t) ha->isp_ops->rd_shdw_req_q_out(ha);\n\t\tif (ha->request_in < cnt)\n\t\t\tha->req_q_count = cnt - ha->request_in;\n\t\telse\n\t\t\tha->req_q_count = REQUEST_QUEUE_DEPTH -\n\t\t\t\t\t\t(ha->request_in - cnt);\n\t}\n\n\t \n\tif ((req_cnt + 2) < ha->req_q_count)\n\t\treturn 1;\n\telse\n\t\treturn 0;\n}\n\nstatic void qla4xxx_advance_req_ring_ptr(struct scsi_qla_host *ha)\n{\n\t \n\tif (ha->request_in == (REQUEST_QUEUE_DEPTH - 1)) {\n\t\tha->request_in = 0;\n\t\tha->request_ptr = ha->request_ring;\n\t} else {\n\t\tha->request_in++;\n\t\tha->request_ptr++;\n\t}\n}\n\n \nstatic int qla4xxx_get_req_pkt(struct scsi_qla_host *ha,\n\t\t\t       struct queue_entry **queue_entry)\n{\n\tuint16_t req_cnt = 1;\n\n\tif (qla4xxx_space_in_req_ring(ha, req_cnt)) {\n\t\t*queue_entry = ha->request_ptr;\n\t\tmemset(*queue_entry, 0, sizeof(**queue_entry));\n\n\t\tqla4xxx_advance_req_ring_ptr(ha);\n\t\tha->req_q_count -= req_cnt;\n\t\treturn QLA_SUCCESS;\n\t}\n\n\treturn QLA_ERROR;\n}\n\n \nint qla4xxx_send_marker_iocb(struct scsi_qla_host *ha,\n\tstruct ddb_entry *ddb_entry, uint64_t lun, uint16_t mrkr_mod)\n{\n\tstruct qla4_marker_entry *marker_entry;\n\tunsigned long flags = 0;\n\tuint8_t status = QLA_SUCCESS;\n\n\t \n\tspin_lock_irqsave(&ha->hardware_lock, flags);\n\n\t \n\tif (qla4xxx_get_req_pkt(ha, (struct queue_entry **) &marker_entry) !=\n\t    QLA_SUCCESS) {\n\t\tstatus = QLA_ERROR;\n\t\tgoto exit_send_marker;\n\t}\n\n\t \n\tmarker_entry->hdr.entryType = ET_MARKER;\n\tmarker_entry->hdr.entryCount = 1;\n\tmarker_entry->target = cpu_to_le16(ddb_entry->fw_ddb_index);\n\tmarker_entry->modifier = cpu_to_le16(mrkr_mod);\n\tint_to_scsilun(lun, &marker_entry->lun);\n\twmb();\n\n\t \n\tha->isp_ops->queue_iocb(ha);\n\nexit_send_marker:\n\tspin_unlock_irqrestore(&ha->hardware_lock, flags);\n\treturn status;\n}\n\nstatic struct continuation_t1_entry *\nqla4xxx_alloc_cont_entry(struct scsi_qla_host *ha)\n{\n\tstruct continuation_t1_entry *cont_entry;\n\n\tcont_entry = (struct continuation_t1_entry *)ha->request_ptr;\n\n\tqla4xxx_advance_req_ring_ptr(ha);\n\n\t \n\tcont_entry->hdr.entryType = ET_CONTINUE;\n\tcont_entry->hdr.entryCount = 1;\n\tcont_entry->hdr.systemDefined = (uint8_t) cpu_to_le16(ha->request_in);\n\n\treturn cont_entry;\n}\n\nstatic uint16_t qla4xxx_calc_request_entries(uint16_t dsds)\n{\n\tuint16_t iocbs;\n\n\tiocbs = 1;\n\tif (dsds > COMMAND_SEG) {\n\t\tiocbs += (dsds - COMMAND_SEG) / CONTINUE_SEG;\n\t\tif ((dsds - COMMAND_SEG) % CONTINUE_SEG)\n\t\t\tiocbs++;\n\t}\n\treturn iocbs;\n}\n\nstatic void qla4xxx_build_scsi_iocbs(struct srb *srb,\n\t\t\t\t     struct command_t3_entry *cmd_entry,\n\t\t\t\t     uint16_t tot_dsds)\n{\n\tstruct scsi_qla_host *ha;\n\tuint16_t avail_dsds;\n\tstruct data_seg_a64 *cur_dsd;\n\tstruct scsi_cmnd *cmd;\n\tstruct scatterlist *sg;\n\tint i;\n\n\tcmd = srb->cmd;\n\tha = srb->ha;\n\n\tif (!scsi_bufflen(cmd) || cmd->sc_data_direction == DMA_NONE) {\n\t\t \n\t\tcmd_entry->ttlByteCnt = cpu_to_le32(0);\n\t\treturn;\n\t}\n\n\tavail_dsds = COMMAND_SEG;\n\tcur_dsd = (struct data_seg_a64 *) & (cmd_entry->dataseg[0]);\n\n\tscsi_for_each_sg(cmd, sg, tot_dsds, i) {\n\t\tdma_addr_t sle_dma;\n\n\t\t \n\t\tif (avail_dsds == 0) {\n\t\t\tstruct continuation_t1_entry *cont_entry;\n\n\t\t\tcont_entry = qla4xxx_alloc_cont_entry(ha);\n\t\t\tcur_dsd =\n\t\t\t\t(struct data_seg_a64 *)\n\t\t\t\t&cont_entry->dataseg[0];\n\t\t\tavail_dsds = CONTINUE_SEG;\n\t\t}\n\n\t\tsle_dma = sg_dma_address(sg);\n\t\tcur_dsd->base.addrLow = cpu_to_le32(LSDW(sle_dma));\n\t\tcur_dsd->base.addrHigh = cpu_to_le32(MSDW(sle_dma));\n\t\tcur_dsd->count = cpu_to_le32(sg_dma_len(sg));\n\t\tavail_dsds--;\n\n\t\tcur_dsd++;\n\t}\n}\n\nvoid qla4_83xx_queue_iocb(struct scsi_qla_host *ha)\n{\n\twritel(ha->request_in, &ha->qla4_83xx_reg->req_q_in);\n\treadl(&ha->qla4_83xx_reg->req_q_in);\n}\n\nvoid qla4_83xx_complete_iocb(struct scsi_qla_host *ha)\n{\n\twritel(ha->response_out, &ha->qla4_83xx_reg->rsp_q_out);\n\treadl(&ha->qla4_83xx_reg->rsp_q_out);\n}\n\n \nvoid qla4_82xx_queue_iocb(struct scsi_qla_host *ha)\n{\n\tuint32_t dbval = 0;\n\n\tdbval = 0x14 | (ha->func_num << 5);\n\tdbval = dbval | (0 << 8) | (ha->request_in << 16);\n\n\tqla4_82xx_wr_32(ha, ha->nx_db_wr_ptr, ha->request_in);\n}\n\n \nvoid qla4_82xx_complete_iocb(struct scsi_qla_host *ha)\n{\n\twritel(ha->response_out, &ha->qla4_82xx_reg->rsp_q_out);\n\treadl(&ha->qla4_82xx_reg->rsp_q_out);\n}\n\n \nvoid qla4xxx_queue_iocb(struct scsi_qla_host *ha)\n{\n\twritel(ha->request_in, &ha->reg->req_q_in);\n\treadl(&ha->reg->req_q_in);\n}\n\n \nvoid qla4xxx_complete_iocb(struct scsi_qla_host *ha)\n{\n\twritel(ha->response_out, &ha->reg->rsp_q_out);\n\treadl(&ha->reg->rsp_q_out);\n}\n\n \nint qla4xxx_send_command_to_isp(struct scsi_qla_host *ha, struct srb * srb)\n{\n\tstruct scsi_cmnd *cmd = srb->cmd;\n\tstruct ddb_entry *ddb_entry;\n\tstruct command_t3_entry *cmd_entry;\n\tint nseg;\n\tuint16_t tot_dsds;\n\tuint16_t req_cnt;\n\tunsigned long flags;\n\tuint32_t index;\n\n\t \n\tddb_entry = srb->ddb;\n\n\ttot_dsds = 0;\n\n\t \n\tspin_lock_irqsave(&ha->hardware_lock, flags);\n\n\tindex = scsi_cmd_to_rq(cmd)->tag;\n\n\t \n\tif (!test_bit(AF_ONLINE, &ha->flags)) {\n\t\tDEBUG2(printk(\"scsi%ld: %s: Adapter OFFLINE! \"\n\t\t\t      \"Do not issue command.\\n\",\n\t\t\t      ha->host_no, __func__));\n\t\tgoto queuing_error;\n\t}\n\n\t \n\tnseg = scsi_dma_map(cmd);\n\tif (nseg < 0)\n\t\tgoto queuing_error;\n\ttot_dsds = nseg;\n\n\treq_cnt = qla4xxx_calc_request_entries(tot_dsds);\n\tif (!qla4xxx_space_in_req_ring(ha, req_cnt))\n\t\tgoto queuing_error;\n\n\t \n\tif ((ha->iocb_cnt + req_cnt) >= ha->iocb_hiwat)\n\t\tgoto queuing_error;\n\n\t \n\tcmd_entry = (struct command_t3_entry *) ha->request_ptr;\n\tmemset(cmd_entry, 0, sizeof(struct command_t3_entry));\n\tcmd_entry->hdr.entryType = ET_COMMAND;\n\tcmd_entry->handle = cpu_to_le32(index);\n\tcmd_entry->target = cpu_to_le16(ddb_entry->fw_ddb_index);\n\n\tint_to_scsilun(cmd->device->lun, &cmd_entry->lun);\n\tcmd_entry->ttlByteCnt = cpu_to_le32(scsi_bufflen(cmd));\n\tmemcpy(cmd_entry->cdb, cmd->cmnd, cmd->cmd_len);\n\tcmd_entry->dataSegCnt = cpu_to_le16(tot_dsds);\n\tcmd_entry->hdr.entryCount = req_cnt;\n\n\t \n\tcmd_entry->control_flags = CF_NO_DATA;\n\tif (scsi_bufflen(cmd)) {\n\t\tif (cmd->sc_data_direction == DMA_TO_DEVICE)\n\t\t\tcmd_entry->control_flags = CF_WRITE;\n\t\telse if (cmd->sc_data_direction == DMA_FROM_DEVICE)\n\t\t\tcmd_entry->control_flags = CF_READ;\n\n\t\tha->bytes_xfered += scsi_bufflen(cmd);\n\t\tif (ha->bytes_xfered & ~0xFFFFF){\n\t\t\tha->total_mbytes_xferred += ha->bytes_xfered >> 20;\n\t\t\tha->bytes_xfered &= 0xFFFFF;\n\t\t}\n\t}\n\n\t \n\tcmd_entry->control_flags |= CF_SIMPLE_TAG;\n\n\tqla4xxx_advance_req_ring_ptr(ha);\n\tqla4xxx_build_scsi_iocbs(srb, cmd_entry, tot_dsds);\n\twmb();\n\n\tsrb->cmd->host_scribble = (unsigned char *)(unsigned long)index;\n\n\t \n\tsrb->state = SRB_ACTIVE_STATE;\n\tsrb->flags |= SRB_DMA_VALID;\n\n\t \n\tha->iocb_cnt += req_cnt;\n\tsrb->iocb_cnt = req_cnt;\n\tha->req_q_count -= req_cnt;\n\n\tha->isp_ops->queue_iocb(ha);\n\tspin_unlock_irqrestore(&ha->hardware_lock, flags);\n\n\treturn QLA_SUCCESS;\n\nqueuing_error:\n\tif (tot_dsds)\n\t\tscsi_dma_unmap(cmd);\n\n\tspin_unlock_irqrestore(&ha->hardware_lock, flags);\n\n\treturn QLA_ERROR;\n}\n\nint qla4xxx_send_passthru0(struct iscsi_task *task)\n{\n\tstruct passthru0 *passthru_iocb;\n\tstruct iscsi_session *sess = task->conn->session;\n\tstruct ddb_entry *ddb_entry = sess->dd_data;\n\tstruct scsi_qla_host *ha = ddb_entry->ha;\n\tstruct ql4_task_data *task_data = task->dd_data;\n\tuint16_t ctrl_flags = 0;\n\tunsigned long flags;\n\tint ret = QLA_ERROR;\n\n\tspin_lock_irqsave(&ha->hardware_lock, flags);\n\ttask_data->iocb_req_cnt = 1;\n\t \n\tif (!qla4xxx_space_in_req_ring(ha, task_data->iocb_req_cnt))\n\t\tgoto queuing_error;\n\n\tpassthru_iocb = (struct passthru0 *) ha->request_ptr;\n\n\tmemset(passthru_iocb, 0, sizeof(struct passthru0));\n\tpassthru_iocb->hdr.entryType = ET_PASSTHRU0;\n\tpassthru_iocb->hdr.systemDefined = SD_ISCSI_PDU;\n\tpassthru_iocb->hdr.entryCount = task_data->iocb_req_cnt;\n\tpassthru_iocb->handle = task->itt;\n\tpassthru_iocb->target = cpu_to_le16(ddb_entry->fw_ddb_index);\n\tpassthru_iocb->timeout = cpu_to_le16(PT_DEFAULT_TIMEOUT);\n\n\t \n\tif (task_data->req_len) {\n\t\tmemcpy((uint8_t *)task_data->req_buffer +\n\t\t       sizeof(struct iscsi_hdr), task->data, task->data_count);\n\t\tctrl_flags |= PT_FLAG_SEND_BUFFER;\n\t\tpassthru_iocb->out_dsd.base.addrLow =\n\t\t\t\t\tcpu_to_le32(LSDW(task_data->req_dma));\n\t\tpassthru_iocb->out_dsd.base.addrHigh =\n\t\t\t\t\tcpu_to_le32(MSDW(task_data->req_dma));\n\t\tpassthru_iocb->out_dsd.count =\n\t\t\t\t\tcpu_to_le32(task->data_count +\n\t\t\t\t\t\t    sizeof(struct iscsi_hdr));\n\t}\n\tif (task_data->resp_len) {\n\t\tpassthru_iocb->in_dsd.base.addrLow =\n\t\t\t\t\tcpu_to_le32(LSDW(task_data->resp_dma));\n\t\tpassthru_iocb->in_dsd.base.addrHigh =\n\t\t\t\t\tcpu_to_le32(MSDW(task_data->resp_dma));\n\t\tpassthru_iocb->in_dsd.count =\n\t\t\tcpu_to_le32(task_data->resp_len);\n\t}\n\n\tctrl_flags |= (PT_FLAG_ISCSI_PDU | PT_FLAG_WAIT_4_RESPONSE);\n\tpassthru_iocb->control_flags = cpu_to_le16(ctrl_flags);\n\n\t \n\tqla4xxx_advance_req_ring_ptr(ha);\n\twmb();\n\n\t \n\tha->iocb_cnt += task_data->iocb_req_cnt;\n\tha->req_q_count -= task_data->iocb_req_cnt;\n\tha->isp_ops->queue_iocb(ha);\n\tret = QLA_SUCCESS;\n\nqueuing_error:\n\tspin_unlock_irqrestore(&ha->hardware_lock, flags);\n\treturn ret;\n}\n\nstatic struct mrb *qla4xxx_get_new_mrb(struct scsi_qla_host *ha)\n{\n\tstruct mrb *mrb;\n\n\tmrb = kzalloc(sizeof(*mrb), GFP_KERNEL);\n\tif (!mrb)\n\t\treturn mrb;\n\n\tmrb->ha = ha;\n\treturn mrb;\n}\n\nstatic int qla4xxx_send_mbox_iocb(struct scsi_qla_host *ha, struct mrb *mrb,\n\t\t\t\t  uint32_t *in_mbox)\n{\n\tint rval = QLA_SUCCESS;\n\tuint32_t i;\n\tunsigned long flags;\n\tuint32_t index = 0;\n\n\t \n\tspin_lock_irqsave(&ha->hardware_lock, flags);\n\n\t \n\trval = qla4xxx_get_req_pkt(ha, (struct queue_entry **) &(mrb->mbox));\n\tif (rval != QLA_SUCCESS)\n\t\tgoto exit_mbox_iocb;\n\n\tindex = ha->mrb_index;\n\t \n\tfor (i = 0; i < MAX_MRB; i++) {\n\t\tindex++;\n\t\tif (index == MAX_MRB)\n\t\t\tindex = 1;\n\t\tif (ha->active_mrb_array[index] == NULL) {\n\t\t\tha->mrb_index = index;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmrb->iocb_cnt = 1;\n\tha->active_mrb_array[index] = mrb;\n\tmrb->mbox->handle = index;\n\tmrb->mbox->hdr.entryType = ET_MBOX_CMD;\n\tmrb->mbox->hdr.entryCount = mrb->iocb_cnt;\n\tmemcpy(mrb->mbox->in_mbox, in_mbox, 32);\n\tmrb->mbox_cmd = in_mbox[0];\n\twmb();\n\n\tha->iocb_cnt += mrb->iocb_cnt;\n\tha->isp_ops->queue_iocb(ha);\nexit_mbox_iocb:\n\tspin_unlock_irqrestore(&ha->hardware_lock, flags);\n\treturn rval;\n}\n\nint qla4xxx_ping_iocb(struct scsi_qla_host *ha, uint32_t options,\n\t\t      uint32_t payload_size, uint32_t pid, uint8_t *ipaddr)\n{\n\tuint32_t in_mbox[8];\n\tstruct mrb *mrb = NULL;\n\tint rval = QLA_SUCCESS;\n\n\tmemset(in_mbox, 0, sizeof(in_mbox));\n\n\tmrb = qla4xxx_get_new_mrb(ha);\n\tif (!mrb) {\n\t\tDEBUG2(ql4_printk(KERN_WARNING, ha, \"%s: fail to get new mrb\\n\",\n\t\t\t\t  __func__));\n\t\trval = QLA_ERROR;\n\t\tgoto exit_ping;\n\t}\n\n\tin_mbox[0] = MBOX_CMD_PING;\n\tin_mbox[1] = options;\n\tmemcpy(&in_mbox[2], &ipaddr[0], 4);\n\tmemcpy(&in_mbox[3], &ipaddr[4], 4);\n\tmemcpy(&in_mbox[4], &ipaddr[8], 4);\n\tmemcpy(&in_mbox[5], &ipaddr[12], 4);\n\tin_mbox[6] = payload_size;\n\n\tmrb->pid = pid;\n\trval = qla4xxx_send_mbox_iocb(ha, mrb, in_mbox);\n\n\tif (rval != QLA_SUCCESS)\n\t\tgoto exit_ping;\n\n\treturn rval;\nexit_ping:\n\tkfree(mrb);\n\treturn rval;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}