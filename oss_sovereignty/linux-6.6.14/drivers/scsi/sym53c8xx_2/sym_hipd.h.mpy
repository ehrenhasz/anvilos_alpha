{
  "module_name": "sym_hipd.h",
  "hash_id": "f138aa51ceb2dcccc45ab2d0cf978f30775dc4cffcbeb65564741ad07e41733e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/scsi/sym53c8xx_2/sym_hipd.h",
  "human_readable_source": " \n \n\n#include <linux/gfp.h>\n\n#ifndef SYM_HIPD_H\n#define SYM_HIPD_H\n\n \n#if 0\n#define SYM_OPT_HANDLE_DEVICE_QUEUEING\n#define SYM_OPT_LIMIT_COMMAND_REORDERING\n#endif\n\n \n#define DEBUG_ALLOC\t(0x0001)\n#define DEBUG_PHASE\t(0x0002)\n#define DEBUG_POLL\t(0x0004)\n#define DEBUG_QUEUE\t(0x0008)\n#define DEBUG_RESULT\t(0x0010)\n#define DEBUG_SCATTER\t(0x0020)\n#define DEBUG_SCRIPT\t(0x0040)\n#define DEBUG_TINY\t(0x0080)\n#define DEBUG_TIMING\t(0x0100)\n#define DEBUG_NEGO\t(0x0200)\n#define DEBUG_TAGS\t(0x0400)\n#define DEBUG_POINTER\t(0x0800)\n\n#ifndef DEBUG_FLAGS\n#define DEBUG_FLAGS\t(0x0000)\n#endif\n\n#ifndef sym_verbose\n#define sym_verbose\t(np->verbose)\n#endif\n\n \n#ifndef assert\n#define\tassert(expression) { \\\n\tif (!(expression)) { \\\n\t\t(void)panic( \\\n\t\t\t\"assertion \\\"%s\\\" failed: file \\\"%s\\\", line %d\\n\", \\\n\t\t\t#expression, \\\n\t\t\t__FILE__, __LINE__); \\\n\t} \\\n}\n#endif\n\n \n#if\tSYM_CONF_MAX_TAG_ORDER > 8\n#error\t\"more than 256 tags per logical unit not allowed.\"\n#endif\n#define\tSYM_CONF_MAX_TASK\t(1<<SYM_CONF_MAX_TAG_ORDER)\n\n \n#ifndef\tSYM_CONF_MAX_TAG\n#define\tSYM_CONF_MAX_TAG\tSYM_CONF_MAX_TASK\n#endif\n#if\tSYM_CONF_MAX_TAG > SYM_CONF_MAX_TASK\n#undef\tSYM_CONF_MAX_TAG\n#define\tSYM_CONF_MAX_TAG\tSYM_CONF_MAX_TASK\n#endif\n\n \n#define NO_TAG\t(256)\n\n \n#if\tSYM_CONF_MAX_TARGET > 16\n#error\t\"more than 16 targets not allowed.\"\n#endif\n\n \n#if\tSYM_CONF_MAX_LUN > 64\n#error\t\"more than 64 logical units per target not allowed.\"\n#endif\n\n \n#define\tSYM_CONF_MIN_ASYNC (40)\n\n\n \n\n#define SYM_MEM_WARN\t1\t \n\n#define SYM_MEM_PAGE_ORDER 0\t \n#define SYM_MEM_CLUSTER_SHIFT\t(PAGE_SHIFT+SYM_MEM_PAGE_ORDER)\n#define SYM_MEM_FREE_UNUSED\t \n \n#define SYM_MEM_SHIFT\t4\n#define SYM_MEM_CLUSTER_SIZE\t(1UL << SYM_MEM_CLUSTER_SHIFT)\n#define SYM_MEM_CLUSTER_MASK\t(SYM_MEM_CLUSTER_SIZE-1)\n\n \n#ifdef\tSYM_CONF_MAX_START\n#define\tSYM_CONF_MAX_QUEUE (SYM_CONF_MAX_START+2)\n#else\n#define\tSYM_CONF_MAX_QUEUE (7*SYM_CONF_MAX_TASK+2)\n#define\tSYM_CONF_MAX_START (SYM_CONF_MAX_QUEUE-2)\n#endif\n\n#if\tSYM_CONF_MAX_QUEUE > SYM_MEM_CLUSTER_SIZE/8\n#undef\tSYM_CONF_MAX_QUEUE\n#define\tSYM_CONF_MAX_QUEUE (SYM_MEM_CLUSTER_SIZE/8)\n#undef\tSYM_CONF_MAX_START\n#define\tSYM_CONF_MAX_START (SYM_CONF_MAX_QUEUE-2)\n#endif\n\n \n#define MAX_QUEUE\tSYM_CONF_MAX_QUEUE\n\n \n\n#define INB_OFF(np, o)\t\tioread8(np->s.ioaddr + (o))\n#define INW_OFF(np, o)\t\tioread16(np->s.ioaddr + (o))\n#define INL_OFF(np, o)\t\tioread32(np->s.ioaddr + (o))\n\n#define OUTB_OFF(np, o, val)\tiowrite8((val), np->s.ioaddr + (o))\n#define OUTW_OFF(np, o, val)\tiowrite16((val), np->s.ioaddr + (o))\n#define OUTL_OFF(np, o, val)\tiowrite32((val), np->s.ioaddr + (o))\n\n#define INB(np, r)\t\tINB_OFF(np, offsetof(struct sym_reg, r))\n#define INW(np, r)\t\tINW_OFF(np, offsetof(struct sym_reg, r))\n#define INL(np, r)\t\tINL_OFF(np, offsetof(struct sym_reg, r))\n\n#define OUTB(np, r, v)\t\tOUTB_OFF(np, offsetof(struct sym_reg, r), (v))\n#define OUTW(np, r, v)\t\tOUTW_OFF(np, offsetof(struct sym_reg, r), (v))\n#define OUTL(np, r, v)\t\tOUTL_OFF(np, offsetof(struct sym_reg, r), (v))\n\n#define OUTONB(np, r, m)\tOUTB(np, r, INB(np, r) | (m))\n#define OUTOFFB(np, r, m)\tOUTB(np, r, INB(np, r) & ~(m))\n#define OUTONW(np, r, m)\tOUTW(np, r, INW(np, r) | (m))\n#define OUTOFFW(np, r, m)\tOUTW(np, r, INW(np, r) & ~(m))\n#define OUTONL(np, r, m)\tOUTL(np, r, INL(np, r) | (m))\n#define OUTOFFL(np, r, m)\tOUTL(np, r, INL(np, r) & ~(m))\n\n \n#define OUTL_DSP(np, v)\t\t\t\t\\\n\tdo {\t\t\t\t\t\\\n\t\tMEMORY_WRITE_BARRIER();\t\t\\\n\t\tOUTL(np, nc_dsp, (v));\t\t\\\n\t} while (0)\n\n#define OUTONB_STD()\t\t\t\t\\\n\tdo {\t\t\t\t\t\\\n\t\tMEMORY_WRITE_BARRIER();\t\t\\\n\t\tOUTONB(np, nc_dcntl, (STD|NOCOM));\t\\\n\t} while (0)\n\n \n#define HS_IDLE\t\t(0)\n#define HS_BUSY\t\t(1)\n#define HS_NEGOTIATE\t(2)\t \n#define HS_DISCONNECT\t(3)\t \n#define HS_WAIT\t\t(4)\t \n\n#define HS_DONEMASK\t(0x80)\n#define HS_COMPLETE\t(4|HS_DONEMASK)\n#define HS_SEL_TIMEOUT\t(5|HS_DONEMASK)\t \n#define HS_UNEXPECTED\t(6|HS_DONEMASK)\t \n#define HS_COMP_ERR\t(7|HS_DONEMASK)\t \n\n \n#define\tSIR_BAD_SCSI_STATUS\t(1)\n#define\tSIR_SEL_ATN_NO_MSG_OUT\t(2)\n#define\tSIR_MSG_RECEIVED\t(3)\n#define\tSIR_MSG_WEIRD\t\t(4)\n#define\tSIR_NEGO_FAILED\t\t(5)\n#define\tSIR_NEGO_PROTO\t\t(6)\n#define\tSIR_SCRIPT_STOPPED\t(7)\n#define\tSIR_REJECT_TO_SEND\t(8)\n#define\tSIR_SWIDE_OVERRUN\t(9)\n#define\tSIR_SODL_UNDERRUN\t(10)\n#define\tSIR_RESEL_NO_MSG_IN\t(11)\n#define\tSIR_RESEL_NO_IDENTIFY\t(12)\n#define\tSIR_RESEL_BAD_LUN\t(13)\n#define\tSIR_TARGET_SELECTED\t(14)\n#define\tSIR_RESEL_BAD_I_T_L\t(15)\n#define\tSIR_RESEL_BAD_I_T_L_Q\t(16)\n#define\tSIR_ABORT_SENT\t\t(17)\n#define\tSIR_RESEL_ABORTED\t(18)\n#define\tSIR_MSG_OUT_DONE\t(19)\n#define\tSIR_COMPLETE_ERROR\t(20)\n#define\tSIR_DATA_OVERRUN\t(21)\n#define\tSIR_BAD_PHASE\t\t(22)\n#if\tSYM_CONF_DMA_ADDRESSING_MODE == 2\n#define\tSIR_DMAP_DIRTY\t\t(23)\n#define\tSIR_MAX\t\t\t(23)\n#else\n#define\tSIR_MAX\t\t\t(22)\n#endif\n\n \n#define\tXE_EXTRA_DATA\t(1)\t \n#define\tXE_BAD_PHASE\t(1<<1)\t \n#define\tXE_PARITY_ERR\t(1<<2)\t \n#define\tXE_SODL_UNRUN\t(1<<3)\t \n#define\tXE_SWIDE_OVRUN\t(1<<4)\t \n\n \n#define NS_SYNC\t\t(1)\n#define NS_WIDE\t\t(2)\n#define NS_PPR\t\t(3)\n\n \n#define CCB_HASH_SHIFT\t\t8\n#define CCB_HASH_SIZE\t\t(1UL << CCB_HASH_SHIFT)\n#define CCB_HASH_MASK\t\t(CCB_HASH_SIZE-1)\n#if 1\n#define CCB_HASH_CODE(dsa)\t\\\n\t(((dsa) >> (_LGRU16_(sizeof(struct sym_ccb)))) & CCB_HASH_MASK)\n#else\n#define CCB_HASH_CODE(dsa)\t(((dsa) >> 9) & CCB_HASH_MASK)\n#endif\n\n#if\tSYM_CONF_DMA_ADDRESSING_MODE == 2\n \n#define SYM_DMAP_SHIFT\t(4)\n#define SYM_DMAP_SIZE\t(1u<<SYM_DMAP_SHIFT)\n#define SYM_DMAP_MASK\t(SYM_DMAP_SIZE-1)\n#endif\n\n \n#define SYM_DISC_ENABLED\t(1)\n#define SYM_TAGS_ENABLED\t(1<<1)\n#define SYM_SCAN_BOOT_DISABLED\t(1<<2)\n#define SYM_SCAN_LUNS_DISABLED\t(1<<3)\n\n \n#define SYM_AVOID_BUS_RESET\t(1)\n\n \n#define SYM_SNOOP_TIMEOUT (10000000)\n#define BUS_8_BIT\t0\n#define BUS_16_BIT\t1\n\n \nstruct sym_trans {\n\tu8 period;\n\tu8 offset;\n\tunsigned int width:1;\n\tunsigned int iu:1;\n\tunsigned int dt:1;\n\tunsigned int qas:1;\n\tunsigned int check_nego:1;\n\tunsigned int renego:2;\n};\n\n \nstruct sym_tcbh {\n\t \n\tu32\tluntbl_sa;\t \n\tu32\tlun0_sa;\t \n\t \n \tu_char\tuval;\t\t \n \tu_char\tsval;\t\t \n \tu_char\tfiller1;\n \tu_char\twval;\t\t \n};\n\n \nstruct sym_tcb {\n\t \n \tstruct sym_tcbh head;\n\n\t \n\tu32\t*luntbl;\t \n\tint\tnlcb;\t\t \n\n\t \n\tstruct sym_lcb *lun0p;\t\t \n#if SYM_CONF_MAX_LUN > 1\n\tstruct sym_lcb **lunmp;\t\t \n#endif\n\n#ifdef\tSYM_HAVE_STCB\n\t \n\tstruct sym_stcb s;\n#endif\n\n\t \n\tstruct sym_trans tgoal;\n\n\t \n\tstruct sym_trans tprint;\n\n\t \n\tstruct sym_ccb *  nego_cp;\t \n\n\t \n\tu_char\tto_reset;\n\n\t \n\tunsigned char\tusrflags;\n\tunsigned char\tusr_period;\n\tunsigned char\tusr_width;\n\tunsigned short\tusrtags;\n\tstruct scsi_target *starget;\n};\n\n \nstruct sym_lcbh {\n\t \n \tu32\tresel_sa;\n\n\t \n\tu32\titl_task_sa;\n\n\t \n\tu32\titlq_tbl_sa;\n};\n\n \nstruct sym_lcb {\n\t \n \tstruct sym_lcbh head;\n\n\t \n\tu32\t*itlq_tbl;\t \n\n\t \n\tu_short\tbusy_itlq;\t \n\tu_short\tbusy_itl;\t \n\n\t \n\tu_short\tia_tag;\t\t \n\tu_short\tif_tag;\t\t \n\tu_char\t*cb_tags;\t \n\n\t \n#ifdef\tSYM_HAVE_SLCB\n\tstruct sym_slcb s;\n#endif\n\n#ifdef SYM_OPT_HANDLE_DEVICE_QUEUEING\n\t \n\tSYM_QUEHEAD waiting_ccbq;\n\tSYM_QUEHEAD started_ccbq;\n\tint\tnum_sgood;\n\tu_short\tstarted_tags;\n\tu_short\tstarted_no_tag;\n\tu_short\tstarted_max;\n\tu_short\tstarted_limit;\n#endif\n\n#ifdef SYM_OPT_LIMIT_COMMAND_REORDERING\n\t \n\tu_char\t\ttags_si;\t \n\tu_short\t\ttags_sum[2];\t \n\tu_short\t\ttags_since;\t \n#endif\n\n\t \n\tu_char to_clear;\n\n\t \n\tu_char\tuser_flags;\n\tu_char\tcurr_flags;\n};\n\n \nstruct sym_actscr {\n\tu32\tstart;\t\t \n\tu32\trestart;\t \n};\n\n \nstruct sym_pmc {\n\tstruct\tsym_tblmove sg;\t \n\tu32\tret;\t\t \n};\n\n \n#if SYM_CONF_MAX_LUN <= 1\n#define sym_lp(tp, lun) (!lun) ? (tp)->lun0p : NULL\n#else\n#define sym_lp(tp, lun) \\\n\t(!lun) ? (tp)->lun0p : (tp)->lunmp ? (tp)->lunmp[((u8)lun)] : NULL\n#endif\n\n \n\n \n#define  HX_REG\tscr0\n#define  HX_PRT\tnc_scr0\n#define  HS_REG\tscr1\n#define  HS_PRT\tnc_scr1\n#define  SS_REG\tscr2\n#define  SS_PRT\tnc_scr2\n#define  HF_REG\tscr3\n#define  HF_PRT\tnc_scr3\n\n \n#define  host_xflags   phys.head.status[0]\n#define  host_status   phys.head.status[1]\n#define  ssss_status   phys.head.status[2]\n#define  host_flags    phys.head.status[3]\n\n \n#define HF_IN_PM0\t1u\n#define HF_IN_PM1\t(1u<<1)\n#define HF_ACT_PM\t(1u<<2)\n#define HF_DP_SAVED\t(1u<<3)\n#define HF_SENSE\t(1u<<4)\n#define HF_EXT_ERR\t(1u<<5)\n#define HF_DATA_IN\t(1u<<6)\n#ifdef SYM_CONF_IARB_SUPPORT\n#define HF_HINT_IARB\t(1u<<7)\n#endif\n\n \n#if\tSYM_CONF_DMA_ADDRESSING_MODE == 2\n#define\tHX_DMAP_DIRTY\t(1u<<7)\n#endif\n\n \n\nstruct sym_ccbh {\n\t \n \tstruct sym_actscr go;\n\n\t \n\tu32\tsavep;\t\t \n\tu32\tlastp;\t\t \n\n\t \n\tu8\tstatus[4];\n};\n\n \n#if\tSYM_CONF_GENERIC_SUPPORT\n#define sym_set_script_dp(np, cp, dp)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tif (np->features & FE_LDSTR)\t\t\t\\\n\t\t\tcp->phys.head.lastp = cpu_to_scr(dp);\t\\\n\t\telse\t\t\t\t\t\t\\\n\t\t\tnp->ccb_head.lastp = cpu_to_scr(dp);\t\\\n\t} while (0)\n#define sym_get_script_dp(np, cp) \t\t\t\t\\\n\tscr_to_cpu((np->features & FE_LDSTR) ?\t\t\t\\\n\t\tcp->phys.head.lastp : np->ccb_head.lastp)\n#else\n#define sym_set_script_dp(np, cp, dp)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tcp->phys.head.lastp = cpu_to_scr(dp);\t\t\\\n\t} while (0)\n\n#define sym_get_script_dp(np, cp) (cp->phys.head.lastp)\n#endif\n\n \nstruct sym_dsb {\n\t \n \tstruct sym_ccbh head;\n\n\t \n\tstruct sym_pmc pm0;\n\tstruct sym_pmc pm1;\n\n\t \n\tstruct sym_tblsel  select;\n\tstruct sym_tblmove smsg;\n\tstruct sym_tblmove smsg_ext;\n\tstruct sym_tblmove cmd;\n\tstruct sym_tblmove sense;\n\tstruct sym_tblmove wresid;\n\tstruct sym_tblmove data [SYM_CONF_MAX_SG];\n};\n\n \nstruct sym_ccb {\n\t \n\tstruct sym_dsb phys;\n\n\t \n\tstruct scsi_cmnd *cmd;\t \n\tu8\tcdb_buf[16];\t \n#define\tSYM_SNS_BBUF_LEN 32\n\tu8\tsns_bbuf[SYM_SNS_BBUF_LEN];  \n\tint\tdata_len;\t \n\tint\tsegments;\t \n\n\tu8\torder;\t\t \n\tunsigned char odd_byte_adjustment;\t \n\n\tu_char\tnego_status;\t \n\tu_char\txerr_status;\t \n\tu32\textra_bytes;\t \n\n\t \n\tu_char\tscsi_smsg [12];\n\tu_char\tscsi_smsg2[12];\n\n\t \n\tu_char\tsensecmd[6];\t \n\tu_char\tsv_scsi_status;\t \n\tu_char\tsv_xerr_status;\t \n\tint\tsv_resid;\t \n\n\t \n\tu32\tccb_ba;\t\t \n\tu_short\ttag;\t\t \n\t\t\t\t \n\tu_char\ttarget;\n\tu_char\tlun;\n\tstruct sym_ccb *link_ccbh;\t \n\tSYM_QUEHEAD link_ccbq;\t \n\tu32\tstartp;\t\t \n\tu32\tgoalp;\t\t \n\tint\text_sg;\t\t \n\tint\text_ofs;\t \n#ifdef SYM_OPT_HANDLE_DEVICE_QUEUEING\n\tSYM_QUEHEAD link2_ccbq;\t \n\tu_char\tstarted;\t \n#endif\n\tu_char\tto_abort;\t \n#ifdef SYM_OPT_LIMIT_COMMAND_REORDERING\n\tu_char\ttags_si;\t \n#endif\n};\n\n#define CCB_BA(cp,lbl)\tcpu_to_scr(cp->ccb_ba + offsetof(struct sym_ccb, lbl))\n\ntypedef struct device *m_pool_ident_t;\n\n \nstruct sym_hcb {\n\t \n#if\tSYM_CONF_GENERIC_SUPPORT\n\tstruct sym_ccbh\tccb_head;\n\tstruct sym_tcbh\ttcb_head;\n\tstruct sym_lcbh\tlcb_head;\n#endif\n\t \n\tstruct sym_actscr idletask, notask, bad_itl, bad_itlq;\n\tu32 idletask_ba, notask_ba, bad_itl_ba, bad_itlq_ba;\n\n\t \n\tu32\t*badluntbl;\t \n\tu32\tbadlun_sa;\t \n\n\t \n\tu32\thcb_ba;\n\n\t \n\tu32\tscr_ram_seg;\n\n\t \n\tu_char\tsv_scntl0, sv_scntl3, sv_dmode, sv_dcntl, sv_ctest3, sv_ctest4,\n\t\tsv_ctest5, sv_gpcntl, sv_stest2, sv_stest4, sv_scntl4,\n\t\tsv_stest1;\n\n\t \n\tu_char\trv_scntl0, rv_scntl3, rv_dmode, rv_dcntl, rv_ctest3, rv_ctest4, \n\t\trv_ctest5, rv_stest2, rv_ccntl0, rv_ccntl1, rv_scntl4;\n\n\t \n\tstruct sym_tcb\ttarget[SYM_CONF_MAX_TARGET];\n\n\t \n\tu32\t\t*targtbl;\n\tu32\t\ttargtbl_ba;\n\n\t \n\tm_pool_ident_t\tbus_dmat;\n\n\t \n\tstruct sym_shcb s;\n\n\t \n\tu32\t\tmmio_ba;\t \n\tu32\t\tram_ba;\t\t \n\n\t \n\tu_char\t\t*scripta0;\t \n\tu_char\t\t*scriptb0;\n\tu_char\t\t*scriptz0;\n\tu32\t\tscripta_ba;\t \n\tu32\t\tscriptb_ba;\t \n\tu32\t\tscriptz_ba;\n\tu_short\t\tscripta_sz;\t \n\tu_short\t\tscriptb_sz;\n\tu_short\t\tscriptz_sz;\n\n\t \n\tstruct sym_fwa_ba fwa_bas;\t \n\tstruct sym_fwb_ba fwb_bas;\t \n\tstruct sym_fwz_ba fwz_bas;\t \n\tvoid\t\t(*fw_setup)(struct sym_hcb *np, struct sym_fw *fw);\n\tvoid\t\t(*fw_patch)(struct Scsi_Host *);\n\tchar\t\t*fw_name;\n\n\t \n\tu_int\tfeatures;\t \n\tu_char\tmyaddr;\t\t \n\tu_char\tmaxburst;\t \n\tu_char\tmaxwide;\t \n\tu_char\tminsync;\t \n\tu_char\tmaxsync;\t \n\tu_char\tmaxoffs;\t \n\tu_char\tminsync_dt;\t \n\tu_char\tmaxsync_dt;\t \n\tu_char\tmaxoffs_dt;\t \n\tu_char\tmultiplier;\t \n\tu_char\tclock_divn;\t \n\tu32\tclock_khz;\t \n\tu32\tpciclk_khz;\t \n\t \n\tvolatile\t\t \n\tu32\t*squeue;\t \n\tu32\tsqueue_ba;\t \n\tu_short\tsqueueput;\t \n\tu_short\tactccbs;\t \n\n\t \n\tu_short\tdqueueget;\t \n\tvolatile\t\t \n\tu32\t*dqueue;\t \n\tu32\tdqueue_ba;\t \n\n\t \n\tu_char\t\tmsgout[8];\t \n\tu_char\t\tmsgin [8];\t \n\tu32\t\tlastmsg;\t \n\tu32\t\tscratch;\t \n\t\t\t\t\t \n\t \n\tu_char\t\tusrflags;\t \n\tu_char\t\tscsi_mode;\t \n\tu_char\t\tverbose;\t \n\n\t \n\tstruct sym_ccb **ccbh;\t\t\t \n\t\t\t\t\t \n\tSYM_QUEHEAD\tfree_ccbq;\t \n\tSYM_QUEHEAD\tbusy_ccbq;\t \n\n\t \n\tSYM_QUEHEAD\tcomp_ccbq;\n\n#ifdef SYM_OPT_HANDLE_DEVICE_QUEUEING\n\tSYM_QUEHEAD\tdummy_ccbq;\n#endif\n\n\t \n#ifdef SYM_CONF_IARB_SUPPORT\n\tu_short\t\tiarb_max;\t \n\tu_short\t\tiarb_count;\t \n\tstruct sym_ccb *\tlast_cp;\n#endif\n\n\t \n\tu_char\t\tabrt_msg[4];\t \n\tstruct sym_tblmove abrt_tbl;\t \n\tstruct sym_tblsel  abrt_sel;\t \n\tu_char\t\tistat_sem;\t \n\n\t \n#if\tSYM_CONF_DMA_ADDRESSING_MODE != 0\n\tu_char\tuse_dac;\t\t \n#if\tSYM_CONF_DMA_ADDRESSING_MODE == 2\n\tu_char\tdmap_dirty;\t\t \n\tu32\tdmap_bah[SYM_DMAP_SIZE]; \n#endif\n#endif\n};\n\n#if SYM_CONF_DMA_ADDRESSING_MODE == 0\n#define use_dac(np)\t0\n#define set_dac(np)\tdo { } while (0)\n#else\n#define use_dac(np)\t(np)->use_dac\n#define set_dac(np)\t(np)->use_dac = 1\n#endif\n\n#define HCB_BA(np, lbl)\t(np->hcb_ba + offsetof(struct sym_hcb, lbl))\n\n\n \nstruct sym_fw * sym_find_firmware(struct sym_chip *chip);\nvoid sym_fw_bind_script(struct sym_hcb *np, u32 *start, int len);\n\n \nchar *sym_driver_name(void);\nvoid sym_print_xerr(struct scsi_cmnd *cmd, int x_status);\nint sym_reset_scsi_bus(struct sym_hcb *np, int enab_int);\nstruct sym_chip *sym_lookup_chip_table(u_short device_id, u_char revision);\n#ifdef SYM_OPT_HANDLE_DEVICE_QUEUEING\nvoid sym_start_next_ccbs(struct sym_hcb *np, struct sym_lcb *lp, int maxn);\n#else\nvoid sym_put_start_queue(struct sym_hcb *np, struct sym_ccb *cp);\n#endif\nvoid sym_start_up(struct Scsi_Host *, int reason);\nirqreturn_t sym_interrupt(struct Scsi_Host *);\nint sym_clear_tasks(struct sym_hcb *np, int cam_status, int target, int lun, int task);\nstruct sym_ccb *sym_get_ccb(struct sym_hcb *np, struct scsi_cmnd *cmd, u_char tag_order);\nvoid sym_free_ccb(struct sym_hcb *np, struct sym_ccb *cp);\nstruct sym_lcb *sym_alloc_lcb(struct sym_hcb *np, u_char tn, u_char ln);\nint sym_free_lcb(struct sym_hcb *np, u_char tn, u_char ln);\nint sym_queue_scsiio(struct sym_hcb *np, struct scsi_cmnd *csio, struct sym_ccb *cp);\nint sym_abort_scsiio(struct sym_hcb *np, struct scsi_cmnd *ccb, int timed_out);\nint sym_reset_scsi_target(struct sym_hcb *np, int target);\nvoid sym_hcb_free(struct sym_hcb *np);\nint sym_hcb_attach(struct Scsi_Host *shost, struct sym_fw *fw, struct sym_nvram *nvram);\n\n \n\n#if   SYM_CONF_DMA_ADDRESSING_MODE == 0\n#define DMA_DAC_MASK\tDMA_BIT_MASK(32)\n#define sym_build_sge(np, data, badd, len)\t\\\ndo {\t\t\t\t\t\t\\\n\t(data)->addr = cpu_to_scr(badd);\t\\\n\t(data)->size = cpu_to_scr(len);\t\t\\\n} while (0)\n#elif SYM_CONF_DMA_ADDRESSING_MODE == 1\n#define DMA_DAC_MASK\tDMA_BIT_MASK(40)\n#define sym_build_sge(np, data, badd, len)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\t(data)->addr = cpu_to_scr(badd);\t\t\t\t\\\n\t(data)->size = cpu_to_scr((((badd) >> 8) & 0xff000000) + len);\t\\\n} while (0)\n#elif SYM_CONF_DMA_ADDRESSING_MODE == 2\n#define DMA_DAC_MASK\tDMA_BIT_MASK(64)\nint sym_lookup_dmap(struct sym_hcb *np, u32 h, int s);\nstatic inline void\nsym_build_sge(struct sym_hcb *np, struct sym_tblmove *data, u64 badd, int len)\n{\n\tu32 h = (badd>>32);\n\tint s = (h&SYM_DMAP_MASK);\n\n\tif (h != np->dmap_bah[s])\n\t\tgoto bad;\ngood:\n\t(data)->addr = cpu_to_scr(badd);\n\t(data)->size = cpu_to_scr((s<<24) + len);\n\treturn;\nbad:\n\ts = sym_lookup_dmap(np, h, s);\n\tgoto good;\n}\n#else\n#error \"Unsupported DMA addressing mode\"\n#endif\n\n \n\n#define sym_get_mem_cluster()\t\\\n\t(void *) __get_free_pages(GFP_ATOMIC, SYM_MEM_PAGE_ORDER)\n#define sym_free_mem_cluster(p)\t\\\n\tfree_pages((unsigned long)p, SYM_MEM_PAGE_ORDER)\n\n \ntypedef struct sym_m_link {\n\tstruct sym_m_link *next;\n} *m_link_p;\n\n \ntypedef struct sym_m_vtob {\t \n\tstruct sym_m_vtob *next;\n\tvoid *vaddr;\t\t \n\tdma_addr_t baddr;\t \n} *m_vtob_p;\n\n \n#define VTOB_HASH_SHIFT\t\t5\n#define VTOB_HASH_SIZE\t\t(1UL << VTOB_HASH_SHIFT)\n#define VTOB_HASH_MASK\t\t(VTOB_HASH_SIZE-1)\n#define VTOB_HASH_CODE(m)\t\\\n\t((((unsigned long)(m)) >> SYM_MEM_CLUSTER_SHIFT) & VTOB_HASH_MASK)\n\n \ntypedef struct sym_m_pool {\n\tm_pool_ident_t\tdev_dmat;\t \n\tvoid * (*get_mem_cluster)(struct sym_m_pool *);\n#ifdef\tSYM_MEM_FREE_UNUSED\n\tvoid (*free_mem_cluster)(struct sym_m_pool *, void *);\n#endif\n#define M_GET_MEM_CLUSTER()\t\tmp->get_mem_cluster(mp)\n#define M_FREE_MEM_CLUSTER(p)\t\tmp->free_mem_cluster(mp, p)\n\tint nump;\n\tm_vtob_p vtob[VTOB_HASH_SIZE];\n\tstruct sym_m_pool *next;\n\tstruct sym_m_link h[SYM_MEM_CLUSTER_SHIFT - SYM_MEM_SHIFT + 1];\n} *m_pool_p;\n\n \nvoid *__sym_calloc_dma(m_pool_ident_t dev_dmat, int size, char *name);\nvoid __sym_mfree_dma(m_pool_ident_t dev_dmat, void *m, int size, char *name);\ndma_addr_t __vtobus(m_pool_ident_t dev_dmat, void *m);\n\n \n#define _uvptv_(p) ((void *)((u_long)(p)))\n\n#define _sym_calloc_dma(np, l, n)\t__sym_calloc_dma(np->bus_dmat, l, n)\n#define _sym_mfree_dma(np, p, l, n)\t\\\n\t\t\t__sym_mfree_dma(np->bus_dmat, _uvptv_(p), l, n)\n#define sym_calloc_dma(l, n)\t\t_sym_calloc_dma(np, l, n)\n#define sym_mfree_dma(p, l, n)\t\t_sym_mfree_dma(np, p, l, n)\n#define vtobus(p)\t\t\t__vtobus(np->bus_dmat, _uvptv_(p))\n\n \n\n#define sym_m_pool_match(mp_id1, mp_id2)\t(mp_id1 == mp_id2)\n\nstatic inline void *sym_m_get_dma_mem_cluster(m_pool_p mp, m_vtob_p vbp)\n{\n\tvoid *vaddr = NULL;\n\tdma_addr_t baddr = 0;\n\n\tvaddr = dma_alloc_coherent(mp->dev_dmat, SYM_MEM_CLUSTER_SIZE, &baddr,\n\t\t\tGFP_ATOMIC);\n\tif (vaddr) {\n\t\tvbp->vaddr = vaddr;\n\t\tvbp->baddr = baddr;\n\t}\n\treturn vaddr;\n}\n\nstatic inline void sym_m_free_dma_mem_cluster(m_pool_p mp, m_vtob_p vbp)\n{\n\tdma_free_coherent(mp->dev_dmat, SYM_MEM_CLUSTER_SIZE, vbp->vaddr,\n\t\t\tvbp->baddr);\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}