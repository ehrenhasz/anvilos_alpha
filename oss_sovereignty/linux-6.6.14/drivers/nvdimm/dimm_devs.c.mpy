{
  "module_name": "dimm_devs.c",
  "hash_id": "51180172098bdfd662cf0fe783a57d594bb09e4ed3fbda812eebae39d2175144",
  "original_prompt": "Ingested from linux-6.6.14/drivers/nvdimm/dimm_devs.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/moduleparam.h>\n#include <linux/vmalloc.h>\n#include <linux/device.h>\n#include <linux/ndctl.h>\n#include <linux/slab.h>\n#include <linux/io.h>\n#include <linux/fs.h>\n#include <linux/mm.h>\n#include \"nd-core.h\"\n#include \"label.h\"\n#include \"pmem.h\"\n#include \"nd.h\"\n\nstatic DEFINE_IDA(dimm_ida);\n\n \nint nvdimm_check_config_data(struct device *dev)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\tif (!nvdimm->cmd_mask ||\n\t    !test_bit(ND_CMD_GET_CONFIG_DATA, &nvdimm->cmd_mask)) {\n\t\tif (test_bit(NDD_LABELING, &nvdimm->flags))\n\t\t\treturn -ENXIO;\n\t\telse\n\t\t\treturn -ENOTTY;\n\t}\n\n\treturn 0;\n}\n\nstatic int validate_dimm(struct nvdimm_drvdata *ndd)\n{\n\tint rc;\n\n\tif (!ndd)\n\t\treturn -EINVAL;\n\n\trc = nvdimm_check_config_data(ndd->dev);\n\tif (rc)\n\t\tdev_dbg(ndd->dev, \"%ps: %s error: %d\\n\",\n\t\t\t\t__builtin_return_address(0), __func__, rc);\n\treturn rc;\n}\n\n \nint nvdimm_init_nsarea(struct nvdimm_drvdata *ndd)\n{\n\tstruct nd_cmd_get_config_size *cmd = &ndd->nsarea;\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(ndd->dev);\n\tstruct nvdimm_bus_descriptor *nd_desc;\n\tint rc = validate_dimm(ndd);\n\tint cmd_rc = 0;\n\n\tif (rc)\n\t\treturn rc;\n\n\tif (cmd->config_size)\n\t\treturn 0;  \n\n\tmemset(cmd, 0, sizeof(*cmd));\n\tnd_desc = nvdimm_bus->nd_desc;\n\trc = nd_desc->ndctl(nd_desc, to_nvdimm(ndd->dev),\n\t\t\tND_CMD_GET_CONFIG_SIZE, cmd, sizeof(*cmd), &cmd_rc);\n\tif (rc < 0)\n\t\treturn rc;\n\treturn cmd_rc;\n}\n\nint nvdimm_get_config_data(struct nvdimm_drvdata *ndd, void *buf,\n\t\t\t   size_t offset, size_t len)\n{\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(ndd->dev);\n\tstruct nvdimm_bus_descriptor *nd_desc = nvdimm_bus->nd_desc;\n\tint rc = validate_dimm(ndd), cmd_rc = 0;\n\tstruct nd_cmd_get_config_data_hdr *cmd;\n\tsize_t max_cmd_size, buf_offset;\n\n\tif (rc)\n\t\treturn rc;\n\n\tif (offset + len > ndd->nsarea.config_size)\n\t\treturn -ENXIO;\n\n\tmax_cmd_size = min_t(u32, len, ndd->nsarea.max_xfer);\n\tcmd = kvzalloc(max_cmd_size + sizeof(*cmd), GFP_KERNEL);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tfor (buf_offset = 0; len;\n\t     len -= cmd->in_length, buf_offset += cmd->in_length) {\n\t\tsize_t cmd_size;\n\n\t\tcmd->in_offset = offset + buf_offset;\n\t\tcmd->in_length = min(max_cmd_size, len);\n\n\t\tcmd_size = sizeof(*cmd) + cmd->in_length;\n\n\t\trc = nd_desc->ndctl(nd_desc, to_nvdimm(ndd->dev),\n\t\t\t\tND_CMD_GET_CONFIG_DATA, cmd, cmd_size, &cmd_rc);\n\t\tif (rc < 0)\n\t\t\tbreak;\n\t\tif (cmd_rc < 0) {\n\t\t\trc = cmd_rc;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tmemcpy(buf + buf_offset, cmd->out_buf, cmd->in_length);\n\t}\n\tkvfree(cmd);\n\n\treturn rc;\n}\n\nint nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,\n\t\tvoid *buf, size_t len)\n{\n\tsize_t max_cmd_size, buf_offset;\n\tstruct nd_cmd_set_config_hdr *cmd;\n\tint rc = validate_dimm(ndd), cmd_rc = 0;\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(ndd->dev);\n\tstruct nvdimm_bus_descriptor *nd_desc = nvdimm_bus->nd_desc;\n\n\tif (rc)\n\t\treturn rc;\n\n\tif (offset + len > ndd->nsarea.config_size)\n\t\treturn -ENXIO;\n\n\tmax_cmd_size = min_t(u32, len, ndd->nsarea.max_xfer);\n\tcmd = kvzalloc(max_cmd_size + sizeof(*cmd) + sizeof(u32), GFP_KERNEL);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tfor (buf_offset = 0; len; len -= cmd->in_length,\n\t\t\tbuf_offset += cmd->in_length) {\n\t\tsize_t cmd_size;\n\n\t\tcmd->in_offset = offset + buf_offset;\n\t\tcmd->in_length = min(max_cmd_size, len);\n\t\tmemcpy(cmd->in_buf, buf + buf_offset, cmd->in_length);\n\n\t\t \n\t\tcmd_size = sizeof(*cmd) + cmd->in_length + sizeof(u32);\n\n\t\trc = nd_desc->ndctl(nd_desc, to_nvdimm(ndd->dev),\n\t\t\t\tND_CMD_SET_CONFIG_DATA, cmd, cmd_size, &cmd_rc);\n\t\tif (rc < 0)\n\t\t\tbreak;\n\t\tif (cmd_rc < 0) {\n\t\t\trc = cmd_rc;\n\t\t\tbreak;\n\t\t}\n\t}\n\tkvfree(cmd);\n\n\treturn rc;\n}\n\nvoid nvdimm_set_labeling(struct device *dev)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\tset_bit(NDD_LABELING, &nvdimm->flags);\n}\n\nvoid nvdimm_set_locked(struct device *dev)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\tset_bit(NDD_LOCKED, &nvdimm->flags);\n}\n\nvoid nvdimm_clear_locked(struct device *dev)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\tclear_bit(NDD_LOCKED, &nvdimm->flags);\n}\n\nstatic void nvdimm_release(struct device *dev)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\tida_simple_remove(&dimm_ida, nvdimm->id);\n\tkfree(nvdimm);\n}\n\nstruct nvdimm *to_nvdimm(struct device *dev)\n{\n\tstruct nvdimm *nvdimm = container_of(dev, struct nvdimm, dev);\n\n\tWARN_ON(!is_nvdimm(dev));\n\treturn nvdimm;\n}\nEXPORT_SYMBOL_GPL(to_nvdimm);\n\nstruct nvdimm_drvdata *to_ndd(struct nd_mapping *nd_mapping)\n{\n\tstruct nvdimm *nvdimm = nd_mapping->nvdimm;\n\n\tWARN_ON_ONCE(!is_nvdimm_bus_locked(&nvdimm->dev));\n\n\treturn dev_get_drvdata(&nvdimm->dev);\n}\nEXPORT_SYMBOL(to_ndd);\n\nvoid nvdimm_drvdata_release(struct kref *kref)\n{\n\tstruct nvdimm_drvdata *ndd = container_of(kref, typeof(*ndd), kref);\n\tstruct device *dev = ndd->dev;\n\tstruct resource *res, *_r;\n\n\tdev_dbg(dev, \"trace\\n\");\n\tnvdimm_bus_lock(dev);\n\tfor_each_dpa_resource_safe(ndd, res, _r)\n\t\tnvdimm_free_dpa(ndd, res);\n\tnvdimm_bus_unlock(dev);\n\n\tkvfree(ndd->data);\n\tkfree(ndd);\n\tput_device(dev);\n}\n\nvoid get_ndd(struct nvdimm_drvdata *ndd)\n{\n\tkref_get(&ndd->kref);\n}\n\nvoid put_ndd(struct nvdimm_drvdata *ndd)\n{\n\tif (ndd)\n\t\tkref_put(&ndd->kref, nvdimm_drvdata_release);\n}\n\nconst char *nvdimm_name(struct nvdimm *nvdimm)\n{\n\treturn dev_name(&nvdimm->dev);\n}\nEXPORT_SYMBOL_GPL(nvdimm_name);\n\nstruct kobject *nvdimm_kobj(struct nvdimm *nvdimm)\n{\n\treturn &nvdimm->dev.kobj;\n}\nEXPORT_SYMBOL_GPL(nvdimm_kobj);\n\nunsigned long nvdimm_cmd_mask(struct nvdimm *nvdimm)\n{\n\treturn nvdimm->cmd_mask;\n}\nEXPORT_SYMBOL_GPL(nvdimm_cmd_mask);\n\nvoid *nvdimm_provider_data(struct nvdimm *nvdimm)\n{\n\tif (nvdimm)\n\t\treturn nvdimm->provider_data;\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(nvdimm_provider_data);\n\nstatic ssize_t commands_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tint cmd, len = 0;\n\n\tif (!nvdimm->cmd_mask)\n\t\treturn sprintf(buf, \"\\n\");\n\n\tfor_each_set_bit(cmd, &nvdimm->cmd_mask, BITS_PER_LONG)\n\t\tlen += sprintf(buf + len, \"%s \", nvdimm_cmd_name(cmd));\n\tlen += sprintf(buf + len, \"\\n\");\n\treturn len;\n}\nstatic DEVICE_ATTR_RO(commands);\n\nstatic ssize_t flags_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\treturn sprintf(buf, \"%s%s\\n\",\n\t\t\ttest_bit(NDD_LABELING, &nvdimm->flags) ? \"label \" : \"\",\n\t\t\ttest_bit(NDD_LOCKED, &nvdimm->flags) ? \"lock \" : \"\");\n}\nstatic DEVICE_ATTR_RO(flags);\n\nstatic ssize_t state_show(struct device *dev, struct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\t \n\tnvdimm_bus_lock(dev);\n\tnvdimm_bus_unlock(dev);\n\treturn sprintf(buf, \"%s\\n\", atomic_read(&nvdimm->busy)\n\t\t\t? \"active\" : \"idle\");\n}\nstatic DEVICE_ATTR_RO(state);\n\nstatic ssize_t __available_slots_show(struct nvdimm_drvdata *ndd, char *buf)\n{\n\tstruct device *dev;\n\tssize_t rc;\n\tu32 nfree;\n\n\tif (!ndd)\n\t\treturn -ENXIO;\n\n\tdev = ndd->dev;\n\tnvdimm_bus_lock(dev);\n\tnfree = nd_label_nfree(ndd);\n\tif (nfree - 1 > nfree) {\n\t\tdev_WARN_ONCE(dev, 1, \"we ate our last label?\\n\");\n\t\tnfree = 0;\n\t} else\n\t\tnfree--;\n\trc = sprintf(buf, \"%d\\n\", nfree);\n\tnvdimm_bus_unlock(dev);\n\treturn rc;\n}\n\nstatic ssize_t available_slots_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tssize_t rc;\n\n\tdevice_lock(dev);\n\trc = __available_slots_show(dev_get_drvdata(dev), buf);\n\tdevice_unlock(dev);\n\n\treturn rc;\n}\nstatic DEVICE_ATTR_RO(available_slots);\n\nstatic ssize_t security_show(struct device *dev,\n\t\t\t     struct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\t \n\tif (IS_ENABLED(CONFIG_NVDIMM_SECURITY_TEST))\n\t\tnvdimm->sec.flags = nvdimm_security_flags(nvdimm, NVDIMM_USER);\n\n\tif (test_bit(NVDIMM_SECURITY_OVERWRITE, &nvdimm->sec.flags))\n\t\treturn sprintf(buf, \"overwrite\\n\");\n\tif (test_bit(NVDIMM_SECURITY_DISABLED, &nvdimm->sec.flags))\n\t\treturn sprintf(buf, \"disabled\\n\");\n\tif (test_bit(NVDIMM_SECURITY_UNLOCKED, &nvdimm->sec.flags))\n\t\treturn sprintf(buf, \"unlocked\\n\");\n\tif (test_bit(NVDIMM_SECURITY_LOCKED, &nvdimm->sec.flags))\n\t\treturn sprintf(buf, \"locked\\n\");\n\treturn -ENOTTY;\n}\n\nstatic ssize_t frozen_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\treturn sprintf(buf, \"%d\\n\", test_bit(NVDIMM_SECURITY_FROZEN,\n\t\t\t\t&nvdimm->sec.flags));\n}\nstatic DEVICE_ATTR_RO(frozen);\n\nstatic ssize_t security_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t len)\n\n{\n\tssize_t rc;\n\n\t \n\tdevice_lock(dev);\n\tnvdimm_bus_lock(dev);\n\twait_nvdimm_bus_probe_idle(dev);\n\trc = nvdimm_security_store(dev, buf, len);\n\tnvdimm_bus_unlock(dev);\n\tdevice_unlock(dev);\n\n\treturn rc;\n}\nstatic DEVICE_ATTR_RW(security);\n\nstatic struct attribute *nvdimm_attributes[] = {\n\t&dev_attr_state.attr,\n\t&dev_attr_flags.attr,\n\t&dev_attr_commands.attr,\n\t&dev_attr_available_slots.attr,\n\t&dev_attr_security.attr,\n\t&dev_attr_frozen.attr,\n\tNULL,\n};\n\nstatic umode_t nvdimm_visible(struct kobject *kobj, struct attribute *a, int n)\n{\n\tstruct device *dev = container_of(kobj, typeof(*dev), kobj);\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\tif (a != &dev_attr_security.attr && a != &dev_attr_frozen.attr)\n\t\treturn a->mode;\n\tif (!nvdimm->sec.flags)\n\t\treturn 0;\n\n\tif (a == &dev_attr_security.attr) {\n\t\t \n\t\tif (nvdimm->sec.ops->freeze || nvdimm->sec.ops->disable\n\t\t\t\t|| nvdimm->sec.ops->change_key\n\t\t\t\t|| nvdimm->sec.ops->erase\n\t\t\t\t|| nvdimm->sec.ops->overwrite)\n\t\t\treturn a->mode;\n\t\treturn 0444;\n\t}\n\n\tif (nvdimm->sec.ops->freeze)\n\t\treturn a->mode;\n\treturn 0;\n}\n\nstatic const struct attribute_group nvdimm_attribute_group = {\n\t.attrs = nvdimm_attributes,\n\t.is_visible = nvdimm_visible,\n};\n\nstatic ssize_t result_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tenum nvdimm_fwa_result result;\n\n\tif (!nvdimm->fw_ops)\n\t\treturn -EOPNOTSUPP;\n\n\tnvdimm_bus_lock(dev);\n\tresult = nvdimm->fw_ops->activate_result(nvdimm);\n\tnvdimm_bus_unlock(dev);\n\n\tswitch (result) {\n\tcase NVDIMM_FWA_RESULT_NONE:\n\t\treturn sprintf(buf, \"none\\n\");\n\tcase NVDIMM_FWA_RESULT_SUCCESS:\n\t\treturn sprintf(buf, \"success\\n\");\n\tcase NVDIMM_FWA_RESULT_FAIL:\n\t\treturn sprintf(buf, \"fail\\n\");\n\tcase NVDIMM_FWA_RESULT_NOTSTAGED:\n\t\treturn sprintf(buf, \"not_staged\\n\");\n\tcase NVDIMM_FWA_RESULT_NEEDRESET:\n\t\treturn sprintf(buf, \"need_reset\\n\");\n\tdefault:\n\t\treturn -ENXIO;\n\t}\n}\nstatic DEVICE_ATTR_ADMIN_RO(result);\n\nstatic ssize_t activate_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tenum nvdimm_fwa_state state;\n\n\tif (!nvdimm->fw_ops)\n\t\treturn -EOPNOTSUPP;\n\n\tnvdimm_bus_lock(dev);\n\tstate = nvdimm->fw_ops->activate_state(nvdimm);\n\tnvdimm_bus_unlock(dev);\n\n\tswitch (state) {\n\tcase NVDIMM_FWA_IDLE:\n\t\treturn sprintf(buf, \"idle\\n\");\n\tcase NVDIMM_FWA_BUSY:\n\t\treturn sprintf(buf, \"busy\\n\");\n\tcase NVDIMM_FWA_ARMED:\n\t\treturn sprintf(buf, \"armed\\n\");\n\tdefault:\n\t\treturn -ENXIO;\n\t}\n}\n\nstatic ssize_t activate_store(struct device *dev, struct device_attribute *attr,\n\t\tconst char *buf, size_t len)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tenum nvdimm_fwa_trigger arg;\n\tint rc;\n\n\tif (!nvdimm->fw_ops)\n\t\treturn -EOPNOTSUPP;\n\n\tif (sysfs_streq(buf, \"arm\"))\n\t\targ = NVDIMM_FWA_ARM;\n\telse if (sysfs_streq(buf, \"disarm\"))\n\t\targ = NVDIMM_FWA_DISARM;\n\telse\n\t\treturn -EINVAL;\n\n\tnvdimm_bus_lock(dev);\n\trc = nvdimm->fw_ops->arm(nvdimm, arg);\n\tnvdimm_bus_unlock(dev);\n\n\tif (rc < 0)\n\t\treturn rc;\n\treturn len;\n}\nstatic DEVICE_ATTR_ADMIN_RW(activate);\n\nstatic struct attribute *nvdimm_firmware_attributes[] = {\n\t&dev_attr_activate.attr,\n\t&dev_attr_result.attr,\n\tNULL,\n};\n\nstatic umode_t nvdimm_firmware_visible(struct kobject *kobj, struct attribute *a, int n)\n{\n\tstruct device *dev = container_of(kobj, typeof(*dev), kobj);\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);\n\tstruct nvdimm_bus_descriptor *nd_desc = nvdimm_bus->nd_desc;\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tenum nvdimm_fwa_capability cap;\n\n\tif (!nd_desc->fw_ops)\n\t\treturn 0;\n\tif (!nvdimm->fw_ops)\n\t\treturn 0;\n\n\tnvdimm_bus_lock(dev);\n\tcap = nd_desc->fw_ops->capability(nd_desc);\n\tnvdimm_bus_unlock(dev);\n\n\tif (cap < NVDIMM_FWA_CAP_QUIESCE)\n\t\treturn 0;\n\n\treturn a->mode;\n}\n\nstatic const struct attribute_group nvdimm_firmware_attribute_group = {\n\t.name = \"firmware\",\n\t.attrs = nvdimm_firmware_attributes,\n\t.is_visible = nvdimm_firmware_visible,\n};\n\nstatic const struct attribute_group *nvdimm_attribute_groups[] = {\n\t&nd_device_attribute_group,\n\t&nvdimm_attribute_group,\n\t&nvdimm_firmware_attribute_group,\n\tNULL,\n};\n\nstatic const struct device_type nvdimm_device_type = {\n\t.name = \"nvdimm\",\n\t.release = nvdimm_release,\n\t.groups = nvdimm_attribute_groups,\n};\n\nbool is_nvdimm(const struct device *dev)\n{\n\treturn dev->type == &nvdimm_device_type;\n}\n\nstatic struct lock_class_key nvdimm_key;\n\nstruct nvdimm *__nvdimm_create(struct nvdimm_bus *nvdimm_bus,\n\t\tvoid *provider_data, const struct attribute_group **groups,\n\t\tunsigned long flags, unsigned long cmd_mask, int num_flush,\n\t\tstruct resource *flush_wpq, const char *dimm_id,\n\t\tconst struct nvdimm_security_ops *sec_ops,\n\t\tconst struct nvdimm_fw_ops *fw_ops)\n{\n\tstruct nvdimm *nvdimm = kzalloc(sizeof(*nvdimm), GFP_KERNEL);\n\tstruct device *dev;\n\n\tif (!nvdimm)\n\t\treturn NULL;\n\n\tnvdimm->id = ida_simple_get(&dimm_ida, 0, 0, GFP_KERNEL);\n\tif (nvdimm->id < 0) {\n\t\tkfree(nvdimm);\n\t\treturn NULL;\n\t}\n\n\tnvdimm->dimm_id = dimm_id;\n\tnvdimm->provider_data = provider_data;\n\tnvdimm->flags = flags;\n\tnvdimm->cmd_mask = cmd_mask;\n\tnvdimm->num_flush = num_flush;\n\tnvdimm->flush_wpq = flush_wpq;\n\tatomic_set(&nvdimm->busy, 0);\n\tdev = &nvdimm->dev;\n\tdev_set_name(dev, \"nmem%d\", nvdimm->id);\n\tdev->parent = &nvdimm_bus->dev;\n\tdev->type = &nvdimm_device_type;\n\tdev->devt = MKDEV(nvdimm_major, nvdimm->id);\n\tdev->groups = groups;\n\tnvdimm->sec.ops = sec_ops;\n\tnvdimm->fw_ops = fw_ops;\n\tnvdimm->sec.overwrite_tmo = 0;\n\tINIT_DELAYED_WORK(&nvdimm->dwork, nvdimm_security_overwrite_query);\n\t \n\t \n\tnvdimm->sec.flags = nvdimm_security_flags(nvdimm, NVDIMM_USER);\n\tnvdimm->sec.ext_flags = nvdimm_security_flags(nvdimm, NVDIMM_MASTER);\n\tdevice_initialize(dev);\n\tlockdep_set_class(&dev->mutex, &nvdimm_key);\n\tif (test_bit(NDD_REGISTER_SYNC, &flags))\n\t\tnd_device_register_sync(dev);\n\telse\n\t\tnd_device_register(dev);\n\n\treturn nvdimm;\n}\nEXPORT_SYMBOL_GPL(__nvdimm_create);\n\nvoid nvdimm_delete(struct nvdimm *nvdimm)\n{\n\tstruct device *dev = &nvdimm->dev;\n\tbool dev_put = false;\n\n\t \n\tnvdimm_bus_lock(dev);\n\tset_bit(NVDIMM_SECURITY_FROZEN, &nvdimm->sec.flags);\n\tif (test_and_clear_bit(NDD_WORK_PENDING, &nvdimm->flags))\n\t\tdev_put = true;\n\tnvdimm_bus_unlock(dev);\n\tcancel_delayed_work_sync(&nvdimm->dwork);\n\tif (dev_put)\n\t\tput_device(dev);\n\tnd_device_unregister(dev, ND_SYNC);\n}\nEXPORT_SYMBOL_GPL(nvdimm_delete);\n\nstatic void shutdown_security_notify(void *data)\n{\n\tstruct nvdimm *nvdimm = data;\n\n\tsysfs_put(nvdimm->sec.overwrite_state);\n}\n\nint nvdimm_security_setup_events(struct device *dev)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\tif (!nvdimm->sec.flags || !nvdimm->sec.ops\n\t\t\t|| !nvdimm->sec.ops->overwrite)\n\t\treturn 0;\n\tnvdimm->sec.overwrite_state = sysfs_get_dirent(dev->kobj.sd, \"security\");\n\tif (!nvdimm->sec.overwrite_state)\n\t\treturn -ENOMEM;\n\n\treturn devm_add_action_or_reset(dev, shutdown_security_notify, nvdimm);\n}\nEXPORT_SYMBOL_GPL(nvdimm_security_setup_events);\n\nint nvdimm_in_overwrite(struct nvdimm *nvdimm)\n{\n\treturn test_bit(NDD_SECURITY_OVERWRITE, &nvdimm->flags);\n}\nEXPORT_SYMBOL_GPL(nvdimm_in_overwrite);\n\nint nvdimm_security_freeze(struct nvdimm *nvdimm)\n{\n\tint rc;\n\n\tWARN_ON_ONCE(!is_nvdimm_bus_locked(&nvdimm->dev));\n\n\tif (!nvdimm->sec.ops || !nvdimm->sec.ops->freeze)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!nvdimm->sec.flags)\n\t\treturn -EIO;\n\n\tif (test_bit(NDD_SECURITY_OVERWRITE, &nvdimm->flags)) {\n\t\tdev_warn(&nvdimm->dev, \"Overwrite operation in progress.\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\trc = nvdimm->sec.ops->freeze(nvdimm);\n\tnvdimm->sec.flags = nvdimm_security_flags(nvdimm, NVDIMM_USER);\n\n\treturn rc;\n}\n\nstatic unsigned long dpa_align(struct nd_region *nd_region)\n{\n\tstruct device *dev = &nd_region->dev;\n\n\tif (dev_WARN_ONCE(dev, !is_nvdimm_bus_locked(dev),\n\t\t\t\t\"bus lock required for capacity provision\\n\"))\n\t\treturn 0;\n\tif (dev_WARN_ONCE(dev, !nd_region->ndr_mappings || nd_region->align\n\t\t\t\t% nd_region->ndr_mappings,\n\t\t\t\t\"invalid region align %#lx mappings: %d\\n\",\n\t\t\t\tnd_region->align, nd_region->ndr_mappings))\n\t\treturn 0;\n\treturn nd_region->align / nd_region->ndr_mappings;\n}\n\n \nresource_size_t nd_pmem_max_contiguous_dpa(struct nd_region *nd_region,\n\t\t\t\t\t   struct nd_mapping *nd_mapping)\n{\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tstruct nvdimm_bus *nvdimm_bus;\n\tresource_size_t max = 0;\n\tstruct resource *res;\n\tunsigned long align;\n\n\t \n\tif (!ndd)\n\t\treturn 0;\n\n\talign = dpa_align(nd_region);\n\tif (!align)\n\t\treturn 0;\n\n\tnvdimm_bus = walk_to_nvdimm_bus(ndd->dev);\n\tif (__reserve_free_pmem(&nd_region->dev, nd_mapping->nvdimm))\n\t\treturn 0;\n\tfor_each_dpa_resource(ndd, res) {\n\t\tresource_size_t start, end;\n\n\t\tif (strcmp(res->name, \"pmem-reserve\") != 0)\n\t\t\tcontinue;\n\t\t \n\t\tstart = ALIGN(res->start, align);\n\t\tend = ALIGN_DOWN(res->end + 1, align) - 1;\n\t\tif (end < start)\n\t\t\tcontinue;\n\t\tif (end - start + 1 > max)\n\t\t\tmax = end - start + 1;\n\t}\n\trelease_free_pmem(nvdimm_bus, nd_mapping);\n\treturn max;\n}\n\n \nresource_size_t nd_pmem_available_dpa(struct nd_region *nd_region,\n\t\t\t\t      struct nd_mapping *nd_mapping)\n{\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tresource_size_t map_start, map_end, busy = 0;\n\tstruct resource *res;\n\tunsigned long align;\n\n\tif (!ndd)\n\t\treturn 0;\n\n\talign = dpa_align(nd_region);\n\tif (!align)\n\t\treturn 0;\n\n\tmap_start = nd_mapping->start;\n\tmap_end = map_start + nd_mapping->size - 1;\n\tfor_each_dpa_resource(ndd, res) {\n\t\tresource_size_t start, end;\n\n\t\tstart = ALIGN_DOWN(res->start, align);\n\t\tend = ALIGN(res->end + 1, align) - 1;\n\t\tif (start >= map_start && start < map_end) {\n\t\t\tif (end > map_end) {\n\t\t\t\tnd_dbg_dpa(nd_region, ndd, res,\n\t\t\t\t\t   \"misaligned to iset\\n\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tbusy += end - start + 1;\n\t\t} else if (end >= map_start && end <= map_end) {\n\t\t\tbusy += end - start + 1;\n\t\t} else if (map_start > start && map_start < end) {\n\t\t\t \n\t\t\tbusy += nd_mapping->size;\n\t\t}\n\t}\n\n\tif (busy < nd_mapping->size)\n\t\treturn ALIGN_DOWN(nd_mapping->size - busy, align);\n\treturn 0;\n}\n\nvoid nvdimm_free_dpa(struct nvdimm_drvdata *ndd, struct resource *res)\n{\n\tWARN_ON_ONCE(!is_nvdimm_bus_locked(ndd->dev));\n\tkfree(res->name);\n\t__release_region(&ndd->dpa, res->start, resource_size(res));\n}\n\nstruct resource *nvdimm_allocate_dpa(struct nvdimm_drvdata *ndd,\n\t\tstruct nd_label_id *label_id, resource_size_t start,\n\t\tresource_size_t n)\n{\n\tchar *name = kmemdup(label_id, sizeof(*label_id), GFP_KERNEL);\n\tstruct resource *res;\n\n\tif (!name)\n\t\treturn NULL;\n\n\tWARN_ON_ONCE(!is_nvdimm_bus_locked(ndd->dev));\n\tres = __request_region(&ndd->dpa, start, n, name, 0);\n\tif (!res)\n\t\tkfree(name);\n\treturn res;\n}\n\n \nresource_size_t nvdimm_allocated_dpa(struct nvdimm_drvdata *ndd,\n\t\tstruct nd_label_id *label_id)\n{\n\tresource_size_t allocated = 0;\n\tstruct resource *res;\n\n\tfor_each_dpa_resource(ndd, res)\n\t\tif (strcmp(res->name, label_id->id) == 0)\n\t\t\tallocated += resource_size(res);\n\n\treturn allocated;\n}\n\nstatic int count_dimms(struct device *dev, void *c)\n{\n\tint *count = c;\n\n\tif (is_nvdimm(dev))\n\t\t(*count)++;\n\treturn 0;\n}\n\nint nvdimm_bus_check_dimm_count(struct nvdimm_bus *nvdimm_bus, int dimm_count)\n{\n\tint count = 0;\n\t \n\tnd_synchronize();\n\n\tdevice_for_each_child(&nvdimm_bus->dev, &count, count_dimms);\n\tdev_dbg(&nvdimm_bus->dev, \"count: %d\\n\", count);\n\tif (count != dimm_count)\n\t\treturn -ENXIO;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nvdimm_bus_check_dimm_count);\n\nvoid __exit nvdimm_devs_exit(void)\n{\n\tida_destroy(&dimm_ida);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}