{
  "module_name": "namespace_devs.c",
  "hash_id": "4b7adcfaa0b44677184a99c897ccc4c486c974cf96615efaccc0a3474e5bcce3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/nvdimm/namespace_devs.c",
  "human_readable_source": "\n \n#include <linux/kstrtox.h>\n#include <linux/module.h>\n#include <linux/device.h>\n#include <linux/sort.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/nd.h>\n#include \"nd-core.h\"\n#include \"pmem.h\"\n#include \"pfn.h\"\n#include \"nd.h\"\n\nstatic void namespace_io_release(struct device *dev)\n{\n\tstruct nd_namespace_io *nsio = to_nd_namespace_io(dev);\n\n\tkfree(nsio);\n}\n\nstatic void namespace_pmem_release(struct device *dev)\n{\n\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\n\tif (nspm->id >= 0)\n\t\tida_simple_remove(&nd_region->ns_ida, nspm->id);\n\tkfree(nspm->alt_name);\n\tkfree(nspm->uuid);\n\tkfree(nspm);\n}\n\nstatic bool is_namespace_pmem(const struct device *dev);\nstatic bool is_namespace_io(const struct device *dev);\n\nstatic int is_uuid_busy(struct device *dev, void *data)\n{\n\tuuid_t *uuid1 = data, *uuid2 = NULL;\n\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tuuid2 = nspm->uuid;\n\t} else if (is_nd_btt(dev)) {\n\t\tstruct nd_btt *nd_btt = to_nd_btt(dev);\n\n\t\tuuid2 = nd_btt->uuid;\n\t} else if (is_nd_pfn(dev)) {\n\t\tstruct nd_pfn *nd_pfn = to_nd_pfn(dev);\n\n\t\tuuid2 = nd_pfn->uuid;\n\t}\n\n\tif (uuid2 && uuid_equal(uuid1, uuid2))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n\nstatic int is_namespace_uuid_busy(struct device *dev, void *data)\n{\n\tif (is_nd_region(dev))\n\t\treturn device_for_each_child(dev, data, is_uuid_busy);\n\treturn 0;\n}\n\n \nbool nd_is_uuid_unique(struct device *dev, uuid_t *uuid)\n{\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);\n\n\tif (!nvdimm_bus)\n\t\treturn false;\n\tWARN_ON_ONCE(!is_nvdimm_bus_locked(&nvdimm_bus->dev));\n\tif (device_for_each_child(&nvdimm_bus->dev, uuid,\n\t\t\t\tis_namespace_uuid_busy) != 0)\n\t\treturn false;\n\treturn true;\n}\n\nbool pmem_should_map_pages(struct device *dev)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tstruct nd_namespace_common *ndns = to_ndns(dev);\n\tstruct nd_namespace_io *nsio;\n\n\tif (!IS_ENABLED(CONFIG_ZONE_DEVICE))\n\t\treturn false;\n\n\tif (!test_bit(ND_REGION_PAGEMAP, &nd_region->flags))\n\t\treturn false;\n\n\tif (is_nd_pfn(dev) || is_nd_btt(dev))\n\t\treturn false;\n\n\tif (ndns->force_raw)\n\t\treturn false;\n\n\tnsio = to_nd_namespace_io(dev);\n\tif (region_intersects(nsio->res.start, resource_size(&nsio->res),\n\t\t\t\tIORESOURCE_SYSTEM_RAM,\n\t\t\t\tIORES_DESC_NONE) == REGION_MIXED)\n\t\treturn false;\n\n\treturn ARCH_MEMREMAP_PMEM == MEMREMAP_WB;\n}\nEXPORT_SYMBOL(pmem_should_map_pages);\n\nunsigned int pmem_sector_size(struct nd_namespace_common *ndns)\n{\n\tif (is_namespace_pmem(&ndns->dev)) {\n\t\tstruct nd_namespace_pmem *nspm;\n\n\t\tnspm = to_nd_namespace_pmem(&ndns->dev);\n\t\tif (nspm->lbasize == 0 || nspm->lbasize == 512)\n\t\t\t ;\n\t\telse if (nspm->lbasize == 4096)\n\t\t\treturn 4096;\n\t\telse\n\t\t\tdev_WARN(&ndns->dev, \"unsupported sector size: %ld\\n\",\n\t\t\t\t\tnspm->lbasize);\n\t}\n\n\t \n\treturn 512;\n}\nEXPORT_SYMBOL(pmem_sector_size);\n\nconst char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,\n\t\tchar *name)\n{\n\tstruct nd_region *nd_region = to_nd_region(ndns->dev.parent);\n\tconst char *suffix = NULL;\n\n\tif (ndns->claim && is_nd_btt(ndns->claim))\n\t\tsuffix = \"s\";\n\n\tif (is_namespace_pmem(&ndns->dev) || is_namespace_io(&ndns->dev)) {\n\t\tint nsidx = 0;\n\n\t\tif (is_namespace_pmem(&ndns->dev)) {\n\t\t\tstruct nd_namespace_pmem *nspm;\n\n\t\t\tnspm = to_nd_namespace_pmem(&ndns->dev);\n\t\t\tnsidx = nspm->id;\n\t\t}\n\n\t\tif (nsidx)\n\t\t\tsprintf(name, \"pmem%d.%d%s\", nd_region->id, nsidx,\n\t\t\t\t\tsuffix ? suffix : \"\");\n\t\telse\n\t\t\tsprintf(name, \"pmem%d%s\", nd_region->id,\n\t\t\t\t\tsuffix ? suffix : \"\");\n\t} else {\n\t\treturn NULL;\n\t}\n\n\treturn name;\n}\nEXPORT_SYMBOL(nvdimm_namespace_disk_name);\n\nconst uuid_t *nd_dev_to_uuid(struct device *dev)\n{\n\tif (dev && is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\treturn nspm->uuid;\n\t}\n\treturn &uuid_null;\n}\nEXPORT_SYMBOL(nd_dev_to_uuid);\n\nstatic ssize_t nstype_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\n\treturn sprintf(buf, \"%d\\n\", nd_region_to_nstype(nd_region));\n}\nstatic DEVICE_ATTR_RO(nstype);\n\nstatic ssize_t __alt_name_store(struct device *dev, const char *buf,\n\t\tconst size_t len)\n{\n\tchar *input, *pos, *alt_name, **ns_altname;\n\tssize_t rc;\n\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tns_altname = &nspm->alt_name;\n\t} else\n\t\treturn -ENXIO;\n\n\tif (dev->driver || to_ndns(dev)->claim)\n\t\treturn -EBUSY;\n\n\tinput = kstrndup(buf, len, GFP_KERNEL);\n\tif (!input)\n\t\treturn -ENOMEM;\n\n\tpos = strim(input);\n\tif (strlen(pos) + 1 > NSLABEL_NAME_LEN) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\talt_name = kzalloc(NSLABEL_NAME_LEN, GFP_KERNEL);\n\tif (!alt_name) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\tkfree(*ns_altname);\n\t*ns_altname = alt_name;\n\tsprintf(*ns_altname, \"%s\", pos);\n\trc = len;\n\nout:\n\tkfree(input);\n\treturn rc;\n}\n\nstatic int nd_namespace_label_update(struct nd_region *nd_region,\n\t\tstruct device *dev)\n{\n\tdev_WARN_ONCE(dev, dev->driver || to_ndns(dev)->claim,\n\t\t\t\"namespace must be idle during label update\\n\");\n\tif (dev->driver || to_ndns(dev)->claim)\n\t\treturn 0;\n\n\t \n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\t\tresource_size_t size = resource_size(&nspm->nsio.res);\n\n\t\tif (size == 0 && nspm->uuid)\n\t\t\t ;\n\t\telse if (!nspm->uuid)\n\t\t\treturn 0;\n\n\t\treturn nd_pmem_namespace_label_update(nd_region, nspm, size);\n\t} else\n\t\treturn -ENXIO;\n}\n\nstatic ssize_t alt_name_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t len)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tssize_t rc;\n\n\tdevice_lock(dev);\n\tnvdimm_bus_lock(dev);\n\twait_nvdimm_bus_probe_idle(dev);\n\trc = __alt_name_store(dev, buf, len);\n\tif (rc >= 0)\n\t\trc = nd_namespace_label_update(nd_region, dev);\n\tdev_dbg(dev, \"%s(%zd)\\n\", rc < 0 ? \"fail \" : \"\", rc);\n\tnvdimm_bus_unlock(dev);\n\tdevice_unlock(dev);\n\n\treturn rc < 0 ? rc : len;\n}\n\nstatic ssize_t alt_name_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tchar *ns_altname;\n\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tns_altname = nspm->alt_name;\n\t} else\n\t\treturn -ENXIO;\n\n\treturn sprintf(buf, \"%s\\n\", ns_altname ? ns_altname : \"\");\n}\nstatic DEVICE_ATTR_RW(alt_name);\n\nstatic int scan_free(struct nd_region *nd_region,\n\t\tstruct nd_mapping *nd_mapping, struct nd_label_id *label_id,\n\t\tresource_size_t n)\n{\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tint rc = 0;\n\n\twhile (n) {\n\t\tstruct resource *res, *last;\n\n\t\tlast = NULL;\n\t\tfor_each_dpa_resource(ndd, res)\n\t\t\tif (strcmp(res->name, label_id->id) == 0)\n\t\t\t\tlast = res;\n\t\tres = last;\n\t\tif (!res)\n\t\t\treturn 0;\n\n\t\tif (n >= resource_size(res)) {\n\t\t\tn -= resource_size(res);\n\t\t\tnd_dbg_dpa(nd_region, ndd, res, \"delete %d\\n\", rc);\n\t\t\tnvdimm_free_dpa(ndd, res);\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\n\t\trc = adjust_resource(res, res->start, resource_size(res) - n);\n\t\tif (rc == 0)\n\t\t\tres->flags |= DPA_RESOURCE_ADJUSTED;\n\t\tnd_dbg_dpa(nd_region, ndd, res, \"shrink %d\\n\", rc);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}\n\n \nstatic int shrink_dpa_allocation(struct nd_region *nd_region,\n\t\tstruct nd_label_id *label_id, resource_size_t n)\n{\n\tint i;\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tint rc;\n\n\t\trc = scan_free(nd_region, nd_mapping, label_id, n);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic resource_size_t init_dpa_allocation(struct nd_label_id *label_id,\n\t\tstruct nd_region *nd_region, struct nd_mapping *nd_mapping,\n\t\tresource_size_t n)\n{\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tstruct resource *res;\n\tint rc = 0;\n\n\t \n\tres = nvdimm_allocate_dpa(ndd, label_id, nd_mapping->start, n);\n\tif (!res)\n\t\trc = -EBUSY;\n\n\tnd_dbg_dpa(nd_region, ndd, res, \"init %d\\n\", rc);\n\treturn rc ? n : 0;\n}\n\n\n \nstatic void space_valid(struct nd_region *nd_region, struct nvdimm_drvdata *ndd,\n\t\tstruct nd_label_id *label_id, struct resource *prev,\n\t\tstruct resource *next, struct resource *exist,\n\t\tresource_size_t n, struct resource *valid)\n{\n\tbool is_reserve = strcmp(label_id->id, \"pmem-reserve\") == 0;\n\tunsigned long align;\n\n\talign = nd_region->align / nd_region->ndr_mappings;\n\tvalid->start = ALIGN(valid->start, align);\n\tvalid->end = ALIGN_DOWN(valid->end + 1, align) - 1;\n\n\tif (valid->start >= valid->end)\n\t\tgoto invalid;\n\n\tif (is_reserve)\n\t\treturn;\n\n\t \n\tif (resource_size(valid) < n)\n\t\tgoto invalid;\n\n\t \n\tif (!exist)\n\t\treturn;\n\n\t \n\tif (valid->start == exist->end + 1\n\t\t\t|| valid->end == exist->start - 1)\n\t\treturn;\n\n invalid:\n\t \n\tvalid->end = valid->start - 1;\n}\n\nenum alloc_loc {\n\tALLOC_ERR = 0, ALLOC_BEFORE, ALLOC_MID, ALLOC_AFTER,\n};\n\nstatic resource_size_t scan_allocate(struct nd_region *nd_region,\n\t\tstruct nd_mapping *nd_mapping, struct nd_label_id *label_id,\n\t\tresource_size_t n)\n{\n\tresource_size_t mapping_end = nd_mapping->start + nd_mapping->size - 1;\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tstruct resource *res, *exist = NULL, valid;\n\tconst resource_size_t to_allocate = n;\n\tint first;\n\n\tfor_each_dpa_resource(ndd, res)\n\t\tif (strcmp(label_id->id, res->name) == 0)\n\t\t\texist = res;\n\n\tvalid.start = nd_mapping->start;\n\tvalid.end = mapping_end;\n\tvalid.name = \"free space\";\n retry:\n\tfirst = 0;\n\tfor_each_dpa_resource(ndd, res) {\n\t\tstruct resource *next = res->sibling, *new_res = NULL;\n\t\tresource_size_t allocate, available = 0;\n\t\tenum alloc_loc loc = ALLOC_ERR;\n\t\tconst char *action;\n\t\tint rc = 0;\n\n\t\t \n\t\tif (res->start > mapping_end)\n\t\t\tcontinue;\n\t\tif (res->end < nd_mapping->start)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (!first++ && res->start > nd_mapping->start) {\n\t\t\tvalid.start = nd_mapping->start;\n\t\t\tvalid.end = res->start - 1;\n\t\t\tspace_valid(nd_region, ndd, label_id, NULL, next, exist,\n\t\t\t\t\tto_allocate, &valid);\n\t\t\tavailable = resource_size(&valid);\n\t\t\tif (available)\n\t\t\t\tloc = ALLOC_BEFORE;\n\t\t}\n\n\t\t \n\t\tif (!loc && next) {\n\t\t\tvalid.start = res->start + resource_size(res);\n\t\t\tvalid.end = min(mapping_end, next->start - 1);\n\t\t\tspace_valid(nd_region, ndd, label_id, res, next, exist,\n\t\t\t\t\tto_allocate, &valid);\n\t\t\tavailable = resource_size(&valid);\n\t\t\tif (available)\n\t\t\t\tloc = ALLOC_MID;\n\t\t}\n\n\t\t \n\t\tif (!loc && !next) {\n\t\t\tvalid.start = res->start + resource_size(res);\n\t\t\tvalid.end = mapping_end;\n\t\t\tspace_valid(nd_region, ndd, label_id, res, next, exist,\n\t\t\t\t\tto_allocate, &valid);\n\t\t\tavailable = resource_size(&valid);\n\t\t\tif (available)\n\t\t\t\tloc = ALLOC_AFTER;\n\t\t}\n\n\t\tif (!loc || !available)\n\t\t\tcontinue;\n\t\tallocate = min(available, n);\n\t\tswitch (loc) {\n\t\tcase ALLOC_BEFORE:\n\t\t\tif (strcmp(res->name, label_id->id) == 0) {\n\t\t\t\t \n\t\t\t\trc = adjust_resource(res, res->start - allocate,\n\t\t\t\t\t\tresource_size(res) + allocate);\n\t\t\t\taction = \"cur grow up\";\n\t\t\t} else\n\t\t\t\taction = \"allocate\";\n\t\t\tbreak;\n\t\tcase ALLOC_MID:\n\t\t\tif (strcmp(next->name, label_id->id) == 0) {\n\t\t\t\t \n\t\t\t\trc = adjust_resource(next, next->start\n\t\t\t\t\t\t- allocate, resource_size(next)\n\t\t\t\t\t\t+ allocate);\n\t\t\t\tnew_res = next;\n\t\t\t\taction = \"next grow up\";\n\t\t\t} else if (strcmp(res->name, label_id->id) == 0) {\n\t\t\t\taction = \"grow down\";\n\t\t\t} else\n\t\t\t\taction = \"allocate\";\n\t\t\tbreak;\n\t\tcase ALLOC_AFTER:\n\t\t\tif (strcmp(res->name, label_id->id) == 0)\n\t\t\t\taction = \"grow down\";\n\t\t\telse\n\t\t\t\taction = \"allocate\";\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn n;\n\t\t}\n\n\t\tif (strcmp(action, \"allocate\") == 0) {\n\t\t\tnew_res = nvdimm_allocate_dpa(ndd, label_id,\n\t\t\t\t\tvalid.start, allocate);\n\t\t\tif (!new_res)\n\t\t\t\trc = -EBUSY;\n\t\t} else if (strcmp(action, \"grow down\") == 0) {\n\t\t\t \n\t\t\trc = adjust_resource(res, res->start, resource_size(res)\n\t\t\t\t\t+ allocate);\n\t\t\tif (rc == 0)\n\t\t\t\tres->flags |= DPA_RESOURCE_ADJUSTED;\n\t\t}\n\n\t\tif (!new_res)\n\t\t\tnew_res = res;\n\n\t\tnd_dbg_dpa(nd_region, ndd, new_res, \"%s(%d) %d\\n\",\n\t\t\t\taction, loc, rc);\n\n\t\tif (rc)\n\t\t\treturn n;\n\n\t\tn -= allocate;\n\t\tif (n) {\n\t\t\t \n\t\t\tgoto retry;\n\t\t} else\n\t\t\treturn 0;\n\t}\n\n\tif (n == to_allocate)\n\t\treturn init_dpa_allocation(label_id, nd_region, nd_mapping, n);\n\treturn n;\n}\n\nstatic int merge_dpa(struct nd_region *nd_region,\n\t\tstruct nd_mapping *nd_mapping, struct nd_label_id *label_id)\n{\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tstruct resource *res;\n\n\tif (strncmp(\"pmem\", label_id->id, 4) == 0)\n\t\treturn 0;\n retry:\n\tfor_each_dpa_resource(ndd, res) {\n\t\tint rc;\n\t\tstruct resource *next = res->sibling;\n\t\tresource_size_t end = res->start + resource_size(res);\n\n\t\tif (!next || strcmp(res->name, label_id->id) != 0\n\t\t\t\t|| strcmp(next->name, label_id->id) != 0\n\t\t\t\t|| end != next->start)\n\t\t\tcontinue;\n\t\tend += resource_size(next);\n\t\tnvdimm_free_dpa(ndd, next);\n\t\trc = adjust_resource(res, res->start, end - res->start);\n\t\tnd_dbg_dpa(nd_region, ndd, res, \"merge %d\\n\", rc);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tres->flags |= DPA_RESOURCE_ADJUSTED;\n\t\tgoto retry;\n\t}\n\n\treturn 0;\n}\n\nint __reserve_free_pmem(struct device *dev, void *data)\n{\n\tstruct nvdimm *nvdimm = data;\n\tstruct nd_region *nd_region;\n\tstruct nd_label_id label_id;\n\tint i;\n\n\tif (!is_memory(dev))\n\t\treturn 0;\n\n\tnd_region = to_nd_region(dev);\n\tif (nd_region->ndr_mappings == 0)\n\t\treturn 0;\n\n\tmemset(&label_id, 0, sizeof(label_id));\n\tstrcat(label_id.id, \"pmem-reserve\");\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tresource_size_t n, rem = 0;\n\n\t\tif (nd_mapping->nvdimm != nvdimm)\n\t\t\tcontinue;\n\n\t\tn = nd_pmem_available_dpa(nd_region, nd_mapping);\n\t\tif (n == 0)\n\t\t\treturn 0;\n\t\trem = scan_allocate(nd_region, nd_mapping, &label_id, n);\n\t\tdev_WARN_ONCE(&nd_region->dev, rem,\n\t\t\t\t\"pmem reserve underrun: %#llx of %#llx bytes\\n\",\n\t\t\t\t(unsigned long long) n - rem,\n\t\t\t\t(unsigned long long) n);\n\t\treturn rem ? -ENXIO : 0;\n\t}\n\n\treturn 0;\n}\n\nvoid release_free_pmem(struct nvdimm_bus *nvdimm_bus,\n\t\tstruct nd_mapping *nd_mapping)\n{\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tstruct resource *res, *_res;\n\n\tfor_each_dpa_resource_safe(ndd, res, _res)\n\t\tif (strcmp(res->name, \"pmem-reserve\") == 0)\n\t\t\tnvdimm_free_dpa(ndd, res);\n}\n\n \nstatic int grow_dpa_allocation(struct nd_region *nd_region,\n\t\tstruct nd_label_id *label_id, resource_size_t n)\n{\n\tint i;\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tresource_size_t rem = n;\n\t\tint rc;\n\n\t\trem = scan_allocate(nd_region, nd_mapping, label_id, rem);\n\t\tdev_WARN_ONCE(&nd_region->dev, rem,\n\t\t\t\t\"allocation underrun: %#llx of %#llx bytes\\n\",\n\t\t\t\t(unsigned long long) n - rem,\n\t\t\t\t(unsigned long long) n);\n\t\tif (rem)\n\t\t\treturn -ENXIO;\n\n\t\trc = merge_dpa(nd_region, nd_mapping, label_id);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic void nd_namespace_pmem_set_resource(struct nd_region *nd_region,\n\t\tstruct nd_namespace_pmem *nspm, resource_size_t size)\n{\n\tstruct resource *res = &nspm->nsio.res;\n\tresource_size_t offset = 0;\n\n\tif (size && !nspm->uuid) {\n\t\tWARN_ON_ONCE(1);\n\t\tsize = 0;\n\t}\n\n\tif (size && nspm->uuid) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[0];\n\t\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\t\tstruct nd_label_id label_id;\n\t\tstruct resource *res;\n\n\t\tif (!ndd) {\n\t\t\tsize = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\tnd_label_gen_id(&label_id, nspm->uuid, 0);\n\n\t\t \n\t\tfor_each_dpa_resource(ndd, res)\n\t\t\tif (strcmp(res->name, label_id.id) == 0) {\n\t\t\t\toffset = (res->start - nd_mapping->start)\n\t\t\t\t\t* nd_region->ndr_mappings;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\tWARN_ON_ONCE(1);\n\t\tsize = 0;\n\t}\n\n out:\n\tres->start = nd_region->ndr_start + offset;\n\tres->end = res->start + size - 1;\n}\n\nstatic bool uuid_not_set(const uuid_t *uuid, struct device *dev,\n\t\t\t const char *where)\n{\n\tif (!uuid) {\n\t\tdev_dbg(dev, \"%s: uuid not set\\n\", where);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic ssize_t __size_store(struct device *dev, unsigned long long val)\n{\n\tresource_size_t allocated = 0, available = 0;\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tstruct nd_namespace_common *ndns = to_ndns(dev);\n\tstruct nd_mapping *nd_mapping;\n\tstruct nvdimm_drvdata *ndd;\n\tstruct nd_label_id label_id;\n\tu32 flags = 0, remainder;\n\tint rc, i, id = -1;\n\tuuid_t *uuid = NULL;\n\n\tif (dev->driver || ndns->claim)\n\t\treturn -EBUSY;\n\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tuuid = nspm->uuid;\n\t\tid = nspm->id;\n\t}\n\n\t \n\tif (uuid_not_set(uuid, dev, __func__))\n\t\treturn -ENXIO;\n\tif (nd_region->ndr_mappings == 0) {\n\t\tdev_dbg(dev, \"not associated with dimm(s)\\n\");\n\t\treturn -ENXIO;\n\t}\n\n\tdiv_u64_rem(val, nd_region->align, &remainder);\n\tif (remainder) {\n\t\tdev_dbg(dev, \"%llu is not %ldK aligned\\n\", val,\n\t\t\t\tnd_region->align / SZ_1K);\n\t\treturn -EINVAL;\n\t}\n\n\tnd_label_gen_id(&label_id, uuid, flags);\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tnd_mapping = &nd_region->mapping[i];\n\t\tndd = to_ndd(nd_mapping);\n\n\t\t \n\t\tif (!ndd)\n\t\t\treturn -ENXIO;\n\n\t\tallocated += nvdimm_allocated_dpa(ndd, &label_id);\n\t}\n\tavailable = nd_region_allocatable_dpa(nd_region);\n\n\tif (val > available + allocated)\n\t\treturn -ENOSPC;\n\n\tif (val == allocated)\n\t\treturn 0;\n\n\tval = div_u64(val, nd_region->ndr_mappings);\n\tallocated = div_u64(allocated, nd_region->ndr_mappings);\n\tif (val < allocated)\n\t\trc = shrink_dpa_allocation(nd_region, &label_id,\n\t\t\t\tallocated - val);\n\telse\n\t\trc = grow_dpa_allocation(nd_region, &label_id, val - allocated);\n\n\tif (rc)\n\t\treturn rc;\n\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tnd_namespace_pmem_set_resource(nd_region, nspm,\n\t\t\t\tval * nd_region->ndr_mappings);\n\t}\n\n\t \n\tif (val == 0 && id != 0 && nd_region->ns_seed != dev && !ndns->claim)\n\t\tnd_device_unregister(dev, ND_ASYNC);\n\n\treturn rc;\n}\n\nstatic ssize_t size_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t len)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tunsigned long long val;\n\tint rc;\n\n\trc = kstrtoull(buf, 0, &val);\n\tif (rc)\n\t\treturn rc;\n\n\tdevice_lock(dev);\n\tnvdimm_bus_lock(dev);\n\twait_nvdimm_bus_probe_idle(dev);\n\trc = __size_store(dev, val);\n\tif (rc >= 0)\n\t\trc = nd_namespace_label_update(nd_region, dev);\n\n\t \n\tif (rc == 0 && val == 0 && is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tkfree(nspm->uuid);\n\t\tnspm->uuid = NULL;\n\t}\n\n\tdev_dbg(dev, \"%llx %s (%d)\\n\", val, rc < 0 ? \"fail\" : \"success\", rc);\n\n\tnvdimm_bus_unlock(dev);\n\tdevice_unlock(dev);\n\n\treturn rc < 0 ? rc : len;\n}\n\nresource_size_t __nvdimm_namespace_capacity(struct nd_namespace_common *ndns)\n{\n\tstruct device *dev = &ndns->dev;\n\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\treturn resource_size(&nspm->nsio.res);\n\t} else if (is_namespace_io(dev)) {\n\t\tstruct nd_namespace_io *nsio = to_nd_namespace_io(dev);\n\n\t\treturn resource_size(&nsio->res);\n\t} else\n\t\tWARN_ONCE(1, \"unknown namespace type\\n\");\n\treturn 0;\n}\n\nresource_size_t nvdimm_namespace_capacity(struct nd_namespace_common *ndns)\n{\n\tresource_size_t size;\n\n\tnvdimm_bus_lock(&ndns->dev);\n\tsize = __nvdimm_namespace_capacity(ndns);\n\tnvdimm_bus_unlock(&ndns->dev);\n\n\treturn size;\n}\nEXPORT_SYMBOL(nvdimm_namespace_capacity);\n\nbool nvdimm_namespace_locked(struct nd_namespace_common *ndns)\n{\n\tint i;\n\tbool locked = false;\n\tstruct device *dev = &ndns->dev;\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tstruct nvdimm *nvdimm = nd_mapping->nvdimm;\n\n\t\tif (test_bit(NDD_LOCKED, &nvdimm->flags)) {\n\t\t\tdev_dbg(dev, \"%s locked\\n\", nvdimm_name(nvdimm));\n\t\t\tlocked = true;\n\t\t}\n\t}\n\treturn locked;\n}\nEXPORT_SYMBOL(nvdimm_namespace_locked);\n\nstatic ssize_t size_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\treturn sprintf(buf, \"%llu\\n\", (unsigned long long)\n\t\t\tnvdimm_namespace_capacity(to_ndns(dev)));\n}\nstatic DEVICE_ATTR(size, 0444, size_show, size_store);\n\nstatic uuid_t *namespace_to_uuid(struct device *dev)\n{\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\treturn nspm->uuid;\n\t}\n\treturn ERR_PTR(-ENXIO);\n}\n\nstatic ssize_t uuid_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tuuid_t *uuid = namespace_to_uuid(dev);\n\n\tif (IS_ERR(uuid))\n\t\treturn PTR_ERR(uuid);\n\tif (uuid)\n\t\treturn sprintf(buf, \"%pUb\\n\", uuid);\n\treturn sprintf(buf, \"\\n\");\n}\n\n \nstatic int namespace_update_uuid(struct nd_region *nd_region,\n\t\t\t\t struct device *dev, uuid_t *new_uuid,\n\t\t\t\t uuid_t **old_uuid)\n{\n\tstruct nd_label_id old_label_id;\n\tstruct nd_label_id new_label_id;\n\tint i;\n\n\tif (!nd_is_uuid_unique(dev, new_uuid))\n\t\treturn -EINVAL;\n\n\tif (*old_uuid == NULL)\n\t\tgoto out;\n\n\t \n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\n\t\t \n\t\tif (list_empty(&nd_mapping->labels))\n\t\t\treturn -EBUSY;\n\t}\n\n\tnd_label_gen_id(&old_label_id, *old_uuid, 0);\n\tnd_label_gen_id(&new_label_id, new_uuid, 0);\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\t\tstruct nd_label_ent *label_ent;\n\t\tstruct resource *res;\n\n\t\tfor_each_dpa_resource(ndd, res)\n\t\t\tif (strcmp(res->name, old_label_id.id) == 0)\n\t\t\t\tsprintf((void *) res->name, \"%s\",\n\t\t\t\t\t\tnew_label_id.id);\n\n\t\tmutex_lock(&nd_mapping->lock);\n\t\tlist_for_each_entry(label_ent, &nd_mapping->labels, list) {\n\t\t\tstruct nd_namespace_label *nd_label = label_ent->label;\n\t\t\tstruct nd_label_id label_id;\n\t\t\tuuid_t uuid;\n\n\t\t\tif (!nd_label)\n\t\t\t\tcontinue;\n\t\t\tnsl_get_uuid(ndd, nd_label, &uuid);\n\t\t\tnd_label_gen_id(&label_id, &uuid,\n\t\t\t\t\tnsl_get_flags(ndd, nd_label));\n\t\t\tif (strcmp(old_label_id.id, label_id.id) == 0)\n\t\t\t\tset_bit(ND_LABEL_REAP, &label_ent->flags);\n\t\t}\n\t\tmutex_unlock(&nd_mapping->lock);\n\t}\n\tkfree(*old_uuid);\n out:\n\t*old_uuid = new_uuid;\n\treturn 0;\n}\n\nstatic ssize_t uuid_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t len)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tuuid_t *uuid = NULL;\n\tuuid_t **ns_uuid;\n\tssize_t rc = 0;\n\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tns_uuid = &nspm->uuid;\n\t} else\n\t\treturn -ENXIO;\n\n\tdevice_lock(dev);\n\tnvdimm_bus_lock(dev);\n\twait_nvdimm_bus_probe_idle(dev);\n\tif (to_ndns(dev)->claim)\n\t\trc = -EBUSY;\n\tif (rc >= 0)\n\t\trc = nd_uuid_store(dev, &uuid, buf, len);\n\tif (rc >= 0)\n\t\trc = namespace_update_uuid(nd_region, dev, uuid, ns_uuid);\n\tif (rc >= 0)\n\t\trc = nd_namespace_label_update(nd_region, dev);\n\telse\n\t\tkfree(uuid);\n\tdev_dbg(dev, \"result: %zd wrote: %s%s\", rc, buf,\n\t\t\tbuf[len - 1] == '\\n' ? \"\" : \"\\n\");\n\tnvdimm_bus_unlock(dev);\n\tdevice_unlock(dev);\n\n\treturn rc < 0 ? rc : len;\n}\nstatic DEVICE_ATTR_RW(uuid);\n\nstatic ssize_t resource_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct resource *res;\n\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tres = &nspm->nsio.res;\n\t} else if (is_namespace_io(dev)) {\n\t\tstruct nd_namespace_io *nsio = to_nd_namespace_io(dev);\n\n\t\tres = &nsio->res;\n\t} else\n\t\treturn -ENXIO;\n\n\t \n\tif (resource_size(res) == 0)\n\t\treturn -ENXIO;\n\treturn sprintf(buf, \"%#llx\\n\", (unsigned long long) res->start);\n}\nstatic DEVICE_ATTR_ADMIN_RO(resource);\n\nstatic const unsigned long pmem_lbasize_supported[] = { 512, 4096, 0 };\n\nstatic ssize_t sector_size_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\treturn nd_size_select_show(nspm->lbasize,\n\t\t\t\tpmem_lbasize_supported, buf);\n\t}\n\treturn -ENXIO;\n}\n\nstatic ssize_t sector_size_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t len)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tconst unsigned long *supported;\n\tunsigned long *lbasize;\n\tssize_t rc = 0;\n\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tlbasize = &nspm->lbasize;\n\t\tsupported = pmem_lbasize_supported;\n\t} else\n\t\treturn -ENXIO;\n\n\tdevice_lock(dev);\n\tnvdimm_bus_lock(dev);\n\tif (to_ndns(dev)->claim)\n\t\trc = -EBUSY;\n\tif (rc >= 0)\n\t\trc = nd_size_select_store(dev, buf, lbasize, supported);\n\tif (rc >= 0)\n\t\trc = nd_namespace_label_update(nd_region, dev);\n\tdev_dbg(dev, \"result: %zd %s: %s%s\", rc, rc < 0 ? \"tried\" : \"wrote\",\n\t\t\tbuf, buf[len - 1] == '\\n' ? \"\" : \"\\n\");\n\tnvdimm_bus_unlock(dev);\n\tdevice_unlock(dev);\n\n\treturn rc ? rc : len;\n}\nstatic DEVICE_ATTR_RW(sector_size);\n\nstatic ssize_t dpa_extents_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tstruct nd_label_id label_id;\n\tuuid_t *uuid = NULL;\n\tint count = 0, i;\n\tu32 flags = 0;\n\n\tnvdimm_bus_lock(dev);\n\tif (is_namespace_pmem(dev)) {\n\t\tstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\n\n\t\tuuid = nspm->uuid;\n\t\tflags = 0;\n\t}\n\n\tif (!uuid)\n\t\tgoto out;\n\n\tnd_label_gen_id(&label_id, uuid, flags);\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\t\tstruct resource *res;\n\n\t\tfor_each_dpa_resource(ndd, res)\n\t\t\tif (strcmp(res->name, label_id.id) == 0)\n\t\t\t\tcount++;\n\t}\n out:\n\tnvdimm_bus_unlock(dev);\n\n\treturn sprintf(buf, \"%d\\n\", count);\n}\nstatic DEVICE_ATTR_RO(dpa_extents);\n\nstatic int btt_claim_class(struct device *dev)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tint i, loop_bitmask = 0;\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\t\tstruct nd_namespace_index *nsindex;\n\n\t\t \n\t\tif (!ndd) {\n\t\t\tloop_bitmask = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tnsindex = to_namespace_index(ndd, ndd->ns_current);\n\t\tif (nsindex == NULL)\n\t\t\tloop_bitmask |= 1;\n\t\telse {\n\t\t\t \n\t\t\tif (__le16_to_cpu(nsindex->major) == 1\n\t\t\t\t\t&& __le16_to_cpu(nsindex->minor) == 1)\n\t\t\t\tloop_bitmask |= 2;\n\t\t\telse\n\t\t\t\tloop_bitmask |= 4;\n\t\t}\n\t}\n\t \n\tswitch (loop_bitmask) {\n\tcase 0:\n\tcase 2:\n\t\treturn NVDIMM_CCLASS_BTT;\n\tcase 1:\n\tcase 4:\n\t\treturn NVDIMM_CCLASS_BTT2;\n\tdefault:\n\t\treturn -ENXIO;\n\t}\n}\n\nstatic ssize_t holder_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nd_namespace_common *ndns = to_ndns(dev);\n\tssize_t rc;\n\n\tdevice_lock(dev);\n\trc = sprintf(buf, \"%s\\n\", ndns->claim ? dev_name(ndns->claim) : \"\");\n\tdevice_unlock(dev);\n\n\treturn rc;\n}\nstatic DEVICE_ATTR_RO(holder);\n\nstatic int __holder_class_store(struct device *dev, const char *buf)\n{\n\tstruct nd_namespace_common *ndns = to_ndns(dev);\n\n\tif (dev->driver || ndns->claim)\n\t\treturn -EBUSY;\n\n\tif (sysfs_streq(buf, \"btt\")) {\n\t\tint rc = btt_claim_class(dev);\n\n\t\tif (rc < NVDIMM_CCLASS_NONE)\n\t\t\treturn rc;\n\t\tndns->claim_class = rc;\n\t} else if (sysfs_streq(buf, \"pfn\"))\n\t\tndns->claim_class = NVDIMM_CCLASS_PFN;\n\telse if (sysfs_streq(buf, \"dax\"))\n\t\tndns->claim_class = NVDIMM_CCLASS_DAX;\n\telse if (sysfs_streq(buf, \"\"))\n\t\tndns->claim_class = NVDIMM_CCLASS_NONE;\n\telse\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic ssize_t holder_class_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t len)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tint rc;\n\n\tdevice_lock(dev);\n\tnvdimm_bus_lock(dev);\n\twait_nvdimm_bus_probe_idle(dev);\n\trc = __holder_class_store(dev, buf);\n\tif (rc >= 0)\n\t\trc = nd_namespace_label_update(nd_region, dev);\n\tdev_dbg(dev, \"%s(%d)\\n\", rc < 0 ? \"fail \" : \"\", rc);\n\tnvdimm_bus_unlock(dev);\n\tdevice_unlock(dev);\n\n\treturn rc < 0 ? rc : len;\n}\n\nstatic ssize_t holder_class_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nd_namespace_common *ndns = to_ndns(dev);\n\tssize_t rc;\n\n\tdevice_lock(dev);\n\tif (ndns->claim_class == NVDIMM_CCLASS_NONE)\n\t\trc = sprintf(buf, \"\\n\");\n\telse if ((ndns->claim_class == NVDIMM_CCLASS_BTT) ||\n\t\t\t(ndns->claim_class == NVDIMM_CCLASS_BTT2))\n\t\trc = sprintf(buf, \"btt\\n\");\n\telse if (ndns->claim_class == NVDIMM_CCLASS_PFN)\n\t\trc = sprintf(buf, \"pfn\\n\");\n\telse if (ndns->claim_class == NVDIMM_CCLASS_DAX)\n\t\trc = sprintf(buf, \"dax\\n\");\n\telse\n\t\trc = sprintf(buf, \"<unknown>\\n\");\n\tdevice_unlock(dev);\n\n\treturn rc;\n}\nstatic DEVICE_ATTR_RW(holder_class);\n\nstatic ssize_t mode_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nd_namespace_common *ndns = to_ndns(dev);\n\tstruct device *claim;\n\tchar *mode;\n\tssize_t rc;\n\n\tdevice_lock(dev);\n\tclaim = ndns->claim;\n\tif (claim && is_nd_btt(claim))\n\t\tmode = \"safe\";\n\telse if (claim && is_nd_pfn(claim))\n\t\tmode = \"memory\";\n\telse if (claim && is_nd_dax(claim))\n\t\tmode = \"dax\";\n\telse if (!claim && pmem_should_map_pages(dev))\n\t\tmode = \"memory\";\n\telse\n\t\tmode = \"raw\";\n\trc = sprintf(buf, \"%s\\n\", mode);\n\tdevice_unlock(dev);\n\n\treturn rc;\n}\nstatic DEVICE_ATTR_RO(mode);\n\nstatic ssize_t force_raw_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t len)\n{\n\tbool force_raw;\n\tint rc = kstrtobool(buf, &force_raw);\n\n\tif (rc)\n\t\treturn rc;\n\n\tto_ndns(dev)->force_raw = force_raw;\n\treturn len;\n}\n\nstatic ssize_t force_raw_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\treturn sprintf(buf, \"%d\\n\", to_ndns(dev)->force_raw);\n}\nstatic DEVICE_ATTR_RW(force_raw);\n\nstatic struct attribute *nd_namespace_attributes[] = {\n\t&dev_attr_nstype.attr,\n\t&dev_attr_size.attr,\n\t&dev_attr_mode.attr,\n\t&dev_attr_uuid.attr,\n\t&dev_attr_holder.attr,\n\t&dev_attr_resource.attr,\n\t&dev_attr_alt_name.attr,\n\t&dev_attr_force_raw.attr,\n\t&dev_attr_sector_size.attr,\n\t&dev_attr_dpa_extents.attr,\n\t&dev_attr_holder_class.attr,\n\tNULL,\n};\n\nstatic umode_t namespace_visible(struct kobject *kobj,\n\t\tstruct attribute *a, int n)\n{\n\tstruct device *dev = container_of(kobj, struct device, kobj);\n\n\tif (is_namespace_pmem(dev)) {\n\t\tif (a == &dev_attr_size.attr)\n\t\t\treturn 0644;\n\n\t\treturn a->mode;\n\t}\n\n\t \n\tif (a == &dev_attr_nstype.attr || a == &dev_attr_size.attr ||\n\t    a == &dev_attr_holder.attr || a == &dev_attr_holder_class.attr ||\n\t    a == &dev_attr_force_raw.attr || a == &dev_attr_mode.attr ||\n\t    a == &dev_attr_resource.attr)\n\t\treturn a->mode;\n\n\treturn 0;\n}\n\nstatic struct attribute_group nd_namespace_attribute_group = {\n\t.attrs = nd_namespace_attributes,\n\t.is_visible = namespace_visible,\n};\n\nstatic const struct attribute_group *nd_namespace_attribute_groups[] = {\n\t&nd_device_attribute_group,\n\t&nd_namespace_attribute_group,\n\t&nd_numa_attribute_group,\n\tNULL,\n};\n\nstatic const struct device_type namespace_io_device_type = {\n\t.name = \"nd_namespace_io\",\n\t.release = namespace_io_release,\n\t.groups = nd_namespace_attribute_groups,\n};\n\nstatic const struct device_type namespace_pmem_device_type = {\n\t.name = \"nd_namespace_pmem\",\n\t.release = namespace_pmem_release,\n\t.groups = nd_namespace_attribute_groups,\n};\n\nstatic bool is_namespace_pmem(const struct device *dev)\n{\n\treturn dev ? dev->type == &namespace_pmem_device_type : false;\n}\n\nstatic bool is_namespace_io(const struct device *dev)\n{\n\treturn dev ? dev->type == &namespace_io_device_type : false;\n}\n\nstruct nd_namespace_common *nvdimm_namespace_common_probe(struct device *dev)\n{\n\tstruct nd_btt *nd_btt = is_nd_btt(dev) ? to_nd_btt(dev) : NULL;\n\tstruct nd_pfn *nd_pfn = is_nd_pfn(dev) ? to_nd_pfn(dev) : NULL;\n\tstruct nd_dax *nd_dax = is_nd_dax(dev) ? to_nd_dax(dev) : NULL;\n\tstruct nd_namespace_common *ndns = NULL;\n\tresource_size_t size;\n\n\tif (nd_btt || nd_pfn || nd_dax) {\n\t\tif (nd_btt)\n\t\t\tndns = nd_btt->ndns;\n\t\telse if (nd_pfn)\n\t\t\tndns = nd_pfn->ndns;\n\t\telse if (nd_dax)\n\t\t\tndns = nd_dax->nd_pfn.ndns;\n\n\t\tif (!ndns)\n\t\t\treturn ERR_PTR(-ENODEV);\n\n\t\t \n\t\tdevice_lock(&ndns->dev);\n\t\tdevice_unlock(&ndns->dev);\n\t\tif (ndns->dev.driver) {\n\t\t\tdev_dbg(&ndns->dev, \"is active, can't bind %s\\n\",\n\t\t\t\t\tdev_name(dev));\n\t\t\treturn ERR_PTR(-EBUSY);\n\t\t}\n\t\tif (dev_WARN_ONCE(&ndns->dev, ndns->claim != dev,\n\t\t\t\t\t\"host (%s) vs claim (%s) mismatch\\n\",\n\t\t\t\t\tdev_name(dev),\n\t\t\t\t\tdev_name(ndns->claim)))\n\t\t\treturn ERR_PTR(-ENXIO);\n\t} else {\n\t\tndns = to_ndns(dev);\n\t\tif (ndns->claim) {\n\t\t\tdev_dbg(dev, \"claimed by %s, failing probe\\n\",\n\t\t\t\tdev_name(ndns->claim));\n\n\t\t\treturn ERR_PTR(-ENXIO);\n\t\t}\n\t}\n\n\tif (nvdimm_namespace_locked(ndns))\n\t\treturn ERR_PTR(-EACCES);\n\n\tsize = nvdimm_namespace_capacity(ndns);\n\tif (size < ND_MIN_NAMESPACE_SIZE) {\n\t\tdev_dbg(&ndns->dev, \"%pa, too small must be at least %#x\\n\",\n\t\t\t\t&size, ND_MIN_NAMESPACE_SIZE);\n\t\treturn ERR_PTR(-ENODEV);\n\t}\n\n\t \n\tif (pmem_should_map_pages(dev)) {\n\t\tstruct nd_namespace_io *nsio = to_nd_namespace_io(&ndns->dev);\n\t\tstruct resource *res = &nsio->res;\n\n\t\tif (!IS_ALIGNED(res->start | (res->end + 1),\n\t\t\t\t\tmemremap_compat_align())) {\n\t\t\tdev_err(&ndns->dev, \"%pr misaligned, unable to map\\n\", res);\n\t\t\treturn ERR_PTR(-EOPNOTSUPP);\n\t\t}\n\t}\n\n\tif (is_namespace_pmem(&ndns->dev)) {\n\t\tstruct nd_namespace_pmem *nspm;\n\n\t\tnspm = to_nd_namespace_pmem(&ndns->dev);\n\t\tif (uuid_not_set(nspm->uuid, &ndns->dev, __func__))\n\t\t\treturn ERR_PTR(-ENODEV);\n\t}\n\n\treturn ndns;\n}\nEXPORT_SYMBOL(nvdimm_namespace_common_probe);\n\nint devm_namespace_enable(struct device *dev, struct nd_namespace_common *ndns,\n\t\tresource_size_t size)\n{\n\treturn devm_nsio_enable(dev, to_nd_namespace_io(&ndns->dev), size);\n}\nEXPORT_SYMBOL_GPL(devm_namespace_enable);\n\nvoid devm_namespace_disable(struct device *dev, struct nd_namespace_common *ndns)\n{\n\tdevm_nsio_disable(dev, to_nd_namespace_io(&ndns->dev));\n}\nEXPORT_SYMBOL_GPL(devm_namespace_disable);\n\nstatic struct device **create_namespace_io(struct nd_region *nd_region)\n{\n\tstruct nd_namespace_io *nsio;\n\tstruct device *dev, **devs;\n\tstruct resource *res;\n\n\tnsio = kzalloc(sizeof(*nsio), GFP_KERNEL);\n\tif (!nsio)\n\t\treturn NULL;\n\n\tdevs = kcalloc(2, sizeof(struct device *), GFP_KERNEL);\n\tif (!devs) {\n\t\tkfree(nsio);\n\t\treturn NULL;\n\t}\n\n\tdev = &nsio->common.dev;\n\tdev->type = &namespace_io_device_type;\n\tdev->parent = &nd_region->dev;\n\tres = &nsio->res;\n\tres->name = dev_name(&nd_region->dev);\n\tres->flags = IORESOURCE_MEM;\n\tres->start = nd_region->ndr_start;\n\tres->end = res->start + nd_region->ndr_size - 1;\n\n\tdevs[0] = dev;\n\treturn devs;\n}\n\nstatic bool has_uuid_at_pos(struct nd_region *nd_region, const uuid_t *uuid,\n\t\t\t    u64 cookie, u16 pos)\n{\n\tstruct nd_namespace_label *found = NULL;\n\tint i;\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tstruct nd_interleave_set *nd_set = nd_region->nd_set;\n\t\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\t\tstruct nd_label_ent *label_ent;\n\t\tbool found_uuid = false;\n\n\t\tlist_for_each_entry(label_ent, &nd_mapping->labels, list) {\n\t\t\tstruct nd_namespace_label *nd_label = label_ent->label;\n\t\t\tu16 position;\n\n\t\t\tif (!nd_label)\n\t\t\t\tcontinue;\n\t\t\tposition = nsl_get_position(ndd, nd_label);\n\n\t\t\tif (!nsl_validate_isetcookie(ndd, nd_label, cookie))\n\t\t\t\tcontinue;\n\n\t\t\tif (!nsl_uuid_equal(ndd, nd_label, uuid))\n\t\t\t\tcontinue;\n\n\t\t\tif (!nsl_validate_type_guid(ndd, nd_label,\n\t\t\t\t\t\t    &nd_set->type_guid))\n\t\t\t\tcontinue;\n\n\t\t\tif (found_uuid) {\n\t\t\t\tdev_dbg(ndd->dev, \"duplicate entry for uuid\\n\");\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tfound_uuid = true;\n\t\t\tif (!nsl_validate_nlabel(nd_region, ndd, nd_label))\n\t\t\t\tcontinue;\n\t\t\tif (position != pos)\n\t\t\t\tcontinue;\n\t\t\tfound = nd_label;\n\t\t\tbreak;\n\t\t}\n\t\tif (found)\n\t\t\tbreak;\n\t}\n\treturn found != NULL;\n}\n\nstatic int select_pmem_id(struct nd_region *nd_region, const uuid_t *pmem_id)\n{\n\tint i;\n\n\tif (!pmem_id)\n\t\treturn -ENODEV;\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\t\tstruct nd_namespace_label *nd_label = NULL;\n\t\tu64 hw_start, hw_end, pmem_start, pmem_end;\n\t\tstruct nd_label_ent *label_ent;\n\n\t\tlockdep_assert_held(&nd_mapping->lock);\n\t\tlist_for_each_entry(label_ent, &nd_mapping->labels, list) {\n\t\t\tnd_label = label_ent->label;\n\t\t\tif (!nd_label)\n\t\t\t\tcontinue;\n\t\t\tif (nsl_uuid_equal(ndd, nd_label, pmem_id))\n\t\t\t\tbreak;\n\t\t\tnd_label = NULL;\n\t\t}\n\n\t\tif (!nd_label) {\n\t\t\tWARN_ON(1);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\thw_start = nd_mapping->start;\n\t\thw_end = hw_start + nd_mapping->size;\n\t\tpmem_start = nsl_get_dpa(ndd, nd_label);\n\t\tpmem_end = pmem_start + nsl_get_rawsize(ndd, nd_label);\n\t\tif (pmem_start >= hw_start && pmem_start < hw_end\n\t\t\t\t&& pmem_end <= hw_end && pmem_end > hw_start)\n\t\t\t ;\n\t\telse {\n\t\t\tdev_dbg(&nd_region->dev, \"%s invalid label for %pUb\\n\",\n\t\t\t\tdev_name(ndd->dev),\n\t\t\t\tnsl_uuid_raw(ndd, nd_label));\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tlist_move(&label_ent->list, &nd_mapping->labels);\n\t}\n\treturn 0;\n}\n\n \nstatic struct device *create_namespace_pmem(struct nd_region *nd_region,\n\t\t\t\t\t    struct nd_mapping *nd_mapping,\n\t\t\t\t\t    struct nd_namespace_label *nd_label)\n{\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tstruct nd_namespace_index *nsindex =\n\t\tto_namespace_index(ndd, ndd->ns_current);\n\tu64 cookie = nd_region_interleave_set_cookie(nd_region, nsindex);\n\tu64 altcookie = nd_region_interleave_set_altcookie(nd_region);\n\tstruct nd_label_ent *label_ent;\n\tstruct nd_namespace_pmem *nspm;\n\tresource_size_t size = 0;\n\tstruct resource *res;\n\tstruct device *dev;\n\tuuid_t uuid;\n\tint rc = 0;\n\tu16 i;\n\n\tif (cookie == 0) {\n\t\tdev_dbg(&nd_region->dev, \"invalid interleave-set-cookie\\n\");\n\t\treturn ERR_PTR(-ENXIO);\n\t}\n\n\tif (!nsl_validate_isetcookie(ndd, nd_label, cookie)) {\n\t\tdev_dbg(&nd_region->dev, \"invalid cookie in label: %pUb\\n\",\n\t\t\tnsl_uuid_raw(ndd, nd_label));\n\t\tif (!nsl_validate_isetcookie(ndd, nd_label, altcookie))\n\t\t\treturn ERR_PTR(-EAGAIN);\n\n\t\tdev_dbg(&nd_region->dev, \"valid altcookie in label: %pUb\\n\",\n\t\t\tnsl_uuid_raw(ndd, nd_label));\n\t}\n\n\tnspm = kzalloc(sizeof(*nspm), GFP_KERNEL);\n\tif (!nspm)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tnspm->id = -1;\n\tdev = &nspm->nsio.common.dev;\n\tdev->type = &namespace_pmem_device_type;\n\tdev->parent = &nd_region->dev;\n\tres = &nspm->nsio.res;\n\tres->name = dev_name(&nd_region->dev);\n\tres->flags = IORESOURCE_MEM;\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tnsl_get_uuid(ndd, nd_label, &uuid);\n\t\tif (has_uuid_at_pos(nd_region, &uuid, cookie, i))\n\t\t\tcontinue;\n\t\tif (has_uuid_at_pos(nd_region, &uuid, altcookie, i))\n\t\t\tcontinue;\n\t\tbreak;\n\t}\n\n\tif (i < nd_region->ndr_mappings) {\n\t\tstruct nvdimm *nvdimm = nd_region->mapping[i].nvdimm;\n\n\t\t \n\t\tdev_err(&nd_region->dev, \"%s missing label for %pUb\\n\",\n\t\t\tnvdimm_name(nvdimm), nsl_uuid_raw(ndd, nd_label));\n\t\trc = -EINVAL;\n\t\tgoto err;\n\t}\n\n\t \n\tnsl_get_uuid(ndd, nd_label, &uuid);\n\trc = select_pmem_id(nd_region, &uuid);\n\tif (rc)\n\t\tgoto err;\n\n\t \n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_namespace_label *label0;\n\t\tstruct nvdimm_drvdata *ndd;\n\n\t\tnd_mapping = &nd_region->mapping[i];\n\t\tlabel_ent = list_first_entry_or_null(&nd_mapping->labels,\n\t\t\t\ttypeof(*label_ent), list);\n\t\tlabel0 = label_ent ? label_ent->label : NULL;\n\n\t\tif (!label0) {\n\t\t\tWARN_ON(1);\n\t\t\tcontinue;\n\t\t}\n\n\t\tndd = to_ndd(nd_mapping);\n\t\tsize += nsl_get_rawsize(ndd, label0);\n\t\tif (nsl_get_position(ndd, label0) != 0)\n\t\t\tcontinue;\n\t\tWARN_ON(nspm->alt_name || nspm->uuid);\n\t\tnspm->alt_name = kmemdup(nsl_ref_name(ndd, label0),\n\t\t\t\t\t NSLABEL_NAME_LEN, GFP_KERNEL);\n\t\tnsl_get_uuid(ndd, label0, &uuid);\n\t\tnspm->uuid = kmemdup(&uuid, sizeof(uuid_t), GFP_KERNEL);\n\t\tnspm->lbasize = nsl_get_lbasize(ndd, label0);\n\t\tnspm->nsio.common.claim_class =\n\t\t\tnsl_get_claim_class(ndd, label0);\n\t}\n\n\tif (!nspm->alt_name || !nspm->uuid) {\n\t\trc = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tnd_namespace_pmem_set_resource(nd_region, nspm, size);\n\n\treturn dev;\n err:\n\tnamespace_pmem_release(dev);\n\tswitch (rc) {\n\tcase -EINVAL:\n\t\tdev_dbg(&nd_region->dev, \"invalid label(s)\\n\");\n\t\tbreak;\n\tcase -ENODEV:\n\t\tdev_dbg(&nd_region->dev, \"label not found\\n\");\n\t\tbreak;\n\tdefault:\n\t\tdev_dbg(&nd_region->dev, \"unexpected err: %d\\n\", rc);\n\t\tbreak;\n\t}\n\treturn ERR_PTR(rc);\n}\n\nstatic struct device *nd_namespace_pmem_create(struct nd_region *nd_region)\n{\n\tstruct nd_namespace_pmem *nspm;\n\tstruct resource *res;\n\tstruct device *dev;\n\n\tif (!is_memory(&nd_region->dev))\n\t\treturn NULL;\n\n\tnspm = kzalloc(sizeof(*nspm), GFP_KERNEL);\n\tif (!nspm)\n\t\treturn NULL;\n\n\tdev = &nspm->nsio.common.dev;\n\tdev->type = &namespace_pmem_device_type;\n\tdev->parent = &nd_region->dev;\n\tres = &nspm->nsio.res;\n\tres->name = dev_name(&nd_region->dev);\n\tres->flags = IORESOURCE_MEM;\n\n\tnspm->id = ida_simple_get(&nd_region->ns_ida, 0, 0, GFP_KERNEL);\n\tif (nspm->id < 0) {\n\t\tkfree(nspm);\n\t\treturn NULL;\n\t}\n\tdev_set_name(dev, \"namespace%d.%d\", nd_region->id, nspm->id);\n\tnd_namespace_pmem_set_resource(nd_region, nspm, 0);\n\n\treturn dev;\n}\n\nstatic struct lock_class_key nvdimm_namespace_key;\n\nvoid nd_region_create_ns_seed(struct nd_region *nd_region)\n{\n\tWARN_ON(!is_nvdimm_bus_locked(&nd_region->dev));\n\n\tif (nd_region_to_nstype(nd_region) == ND_DEVICE_NAMESPACE_IO)\n\t\treturn;\n\n\tnd_region->ns_seed = nd_namespace_pmem_create(nd_region);\n\n\t \n\tif (!nd_region->ns_seed)\n\t\tdev_err(&nd_region->dev, \"failed to create namespace\\n\");\n\telse {\n\t\tdevice_initialize(nd_region->ns_seed);\n\t\tlockdep_set_class(&nd_region->ns_seed->mutex,\n\t\t\t\t  &nvdimm_namespace_key);\n\t\tnd_device_register(nd_region->ns_seed);\n\t}\n}\n\nvoid nd_region_create_dax_seed(struct nd_region *nd_region)\n{\n\tWARN_ON(!is_nvdimm_bus_locked(&nd_region->dev));\n\tnd_region->dax_seed = nd_dax_create(nd_region);\n\t \n\tif (!nd_region->dax_seed)\n\t\tdev_err(&nd_region->dev, \"failed to create dax namespace\\n\");\n}\n\nvoid nd_region_create_pfn_seed(struct nd_region *nd_region)\n{\n\tWARN_ON(!is_nvdimm_bus_locked(&nd_region->dev));\n\tnd_region->pfn_seed = nd_pfn_create(nd_region);\n\t \n\tif (!nd_region->pfn_seed)\n\t\tdev_err(&nd_region->dev, \"failed to create pfn namespace\\n\");\n}\n\nvoid nd_region_create_btt_seed(struct nd_region *nd_region)\n{\n\tWARN_ON(!is_nvdimm_bus_locked(&nd_region->dev));\n\tnd_region->btt_seed = nd_btt_create(nd_region);\n\t \n\tif (!nd_region->btt_seed)\n\t\tdev_err(&nd_region->dev, \"failed to create btt namespace\\n\");\n}\n\nstatic int add_namespace_resource(struct nd_region *nd_region,\n\t\tstruct nd_namespace_label *nd_label, struct device **devs,\n\t\tint count)\n{\n\tstruct nd_mapping *nd_mapping = &nd_region->mapping[0];\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tint i;\n\n\tfor (i = 0; i < count; i++) {\n\t\tuuid_t *uuid = namespace_to_uuid(devs[i]);\n\n\t\tif (IS_ERR(uuid)) {\n\t\t\tWARN_ON(1);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!nsl_uuid_equal(ndd, nd_label, uuid))\n\t\t\tcontinue;\n\t\tdev_err(&nd_region->dev,\n\t\t\t\"error: conflicting extents for uuid: %pUb\\n\", uuid);\n\t\treturn -ENXIO;\n\t}\n\n\treturn i;\n}\n\nstatic int cmp_dpa(const void *a, const void *b)\n{\n\tconst struct device *dev_a = *(const struct device **) a;\n\tconst struct device *dev_b = *(const struct device **) b;\n\tstruct nd_namespace_pmem *nspm_a, *nspm_b;\n\n\tif (is_namespace_io(dev_a))\n\t\treturn 0;\n\n\tnspm_a = to_nd_namespace_pmem(dev_a);\n\tnspm_b = to_nd_namespace_pmem(dev_b);\n\n\treturn memcmp(&nspm_a->nsio.res.start, &nspm_b->nsio.res.start,\n\t\t\tsizeof(resource_size_t));\n}\n\nstatic struct device **scan_labels(struct nd_region *nd_region)\n{\n\tint i, count = 0;\n\tstruct device *dev, **devs = NULL;\n\tstruct nd_label_ent *label_ent, *e;\n\tstruct nd_mapping *nd_mapping = &nd_region->mapping[0];\n\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\tresource_size_t map_end = nd_mapping->start + nd_mapping->size - 1;\n\n\t \n\tlist_for_each_entry_safe(label_ent, e, &nd_mapping->labels, list) {\n\t\tstruct nd_namespace_label *nd_label = label_ent->label;\n\t\tstruct device **__devs;\n\n\t\tif (!nd_label)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (nsl_get_dpa(ndd, nd_label) < nd_mapping->start ||\n\t\t    nsl_get_dpa(ndd, nd_label) > map_end)\n\t\t\tcontinue;\n\n\t\ti = add_namespace_resource(nd_region, nd_label, devs, count);\n\t\tif (i < 0)\n\t\t\tgoto err;\n\t\tif (i < count)\n\t\t\tcontinue;\n\t\t__devs = kcalloc(count + 2, sizeof(dev), GFP_KERNEL);\n\t\tif (!__devs)\n\t\t\tgoto err;\n\t\tmemcpy(__devs, devs, sizeof(dev) * count);\n\t\tkfree(devs);\n\t\tdevs = __devs;\n\n\t\tdev = create_namespace_pmem(nd_region, nd_mapping, nd_label);\n\t\tif (IS_ERR(dev)) {\n\t\t\tswitch (PTR_ERR(dev)) {\n\t\t\tcase -EAGAIN:\n\t\t\t\t \n\t\t\t\tcontinue;\n\t\t\tcase -ENODEV:\n\t\t\t\t \n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t} else\n\t\t\tdevs[count++] = dev;\n\n\t}\n\n\tdev_dbg(&nd_region->dev, \"discovered %d namespace%s\\n\", count,\n\t\tcount == 1 ? \"\" : \"s\");\n\n\tif (count == 0) {\n\t\tstruct nd_namespace_pmem *nspm;\n\n\t\t \n\t\tnd_mapping_free_labels(nd_mapping);\n\n\t\tdevs = kcalloc(2, sizeof(dev), GFP_KERNEL);\n\t\tif (!devs)\n\t\t\tgoto err;\n\n\t\tnspm = kzalloc(sizeof(*nspm), GFP_KERNEL);\n\t\tif (!nspm)\n\t\t\tgoto err;\n\t\tdev = &nspm->nsio.common.dev;\n\t\tdev->type = &namespace_pmem_device_type;\n\t\tnd_namespace_pmem_set_resource(nd_region, nspm, 0);\n\t\tdev->parent = &nd_region->dev;\n\t\tdevs[count++] = dev;\n\t} else if (is_memory(&nd_region->dev)) {\n\t\t \n\t\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\t\tstruct list_head *l, *e;\n\t\t\tLIST_HEAD(list);\n\t\t\tint j;\n\n\t\t\tnd_mapping = &nd_region->mapping[i];\n\t\t\tif (list_empty(&nd_mapping->labels)) {\n\t\t\t\tWARN_ON(1);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tj = count;\n\t\t\tlist_for_each_safe(l, e, &nd_mapping->labels) {\n\t\t\t\tif (!j--)\n\t\t\t\t\tbreak;\n\t\t\t\tlist_move_tail(l, &list);\n\t\t\t}\n\t\t\tnd_mapping_free_labels(nd_mapping);\n\t\t\tlist_splice_init(&list, &nd_mapping->labels);\n\t\t}\n\t}\n\n\tif (count > 1)\n\t\tsort(devs, count, sizeof(struct device *), cmp_dpa, NULL);\n\n\treturn devs;\n\n err:\n\tif (devs) {\n\t\tfor (i = 0; devs[i]; i++)\n\t\t\tnamespace_pmem_release(devs[i]);\n\t\tkfree(devs);\n\t}\n\treturn NULL;\n}\n\nstatic struct device **create_namespaces(struct nd_region *nd_region)\n{\n\tstruct nd_mapping *nd_mapping;\n\tstruct device **devs;\n\tint i;\n\n\tif (nd_region->ndr_mappings == 0)\n\t\treturn NULL;\n\n\t \n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tnd_mapping = &nd_region->mapping[i];\n\t\tmutex_lock_nested(&nd_mapping->lock, i);\n\t}\n\n\tdevs = scan_labels(nd_region);\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tint reverse = nd_region->ndr_mappings - 1 - i;\n\n\t\tnd_mapping = &nd_region->mapping[reverse];\n\t\tmutex_unlock(&nd_mapping->lock);\n\t}\n\n\treturn devs;\n}\n\nstatic void deactivate_labels(void *region)\n{\n\tstruct nd_region *nd_region = region;\n\tint i;\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tstruct nvdimm_drvdata *ndd = nd_mapping->ndd;\n\t\tstruct nvdimm *nvdimm = nd_mapping->nvdimm;\n\n\t\tmutex_lock(&nd_mapping->lock);\n\t\tnd_mapping_free_labels(nd_mapping);\n\t\tmutex_unlock(&nd_mapping->lock);\n\n\t\tput_ndd(ndd);\n\t\tnd_mapping->ndd = NULL;\n\t\tif (ndd)\n\t\t\tatomic_dec(&nvdimm->busy);\n\t}\n}\n\nstatic int init_active_labels(struct nd_region *nd_region)\n{\n\tint i, rc = 0;\n\n\tfor (i = 0; i < nd_region->ndr_mappings; i++) {\n\t\tstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\n\t\tstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\n\t\tstruct nvdimm *nvdimm = nd_mapping->nvdimm;\n\t\tstruct nd_label_ent *label_ent;\n\t\tint count, j;\n\n\t\t \n\t\tif (!ndd) {\n\t\t\tif (test_bit(NDD_LOCKED, &nvdimm->flags))\n\t\t\t\t ;\n\t\t\telse if (test_bit(NDD_LABELING, &nvdimm->flags))\n\t\t\t\t ;\n\t\t\telse\n\t\t\t\tcontinue;\n\n\t\t\tdev_err(&nd_region->dev, \"%s: is %s, failing probe\\n\",\n\t\t\t\t\tdev_name(&nd_mapping->nvdimm->dev),\n\t\t\t\t\ttest_bit(NDD_LOCKED, &nvdimm->flags)\n\t\t\t\t\t? \"locked\" : \"disabled\");\n\t\t\trc = -ENXIO;\n\t\t\tgoto out;\n\t\t}\n\t\tnd_mapping->ndd = ndd;\n\t\tatomic_inc(&nvdimm->busy);\n\t\tget_ndd(ndd);\n\n\t\tcount = nd_label_active_count(ndd);\n\t\tdev_dbg(ndd->dev, \"count: %d\\n\", count);\n\t\tif (!count)\n\t\t\tcontinue;\n\t\tfor (j = 0; j < count; j++) {\n\t\t\tstruct nd_namespace_label *label;\n\n\t\t\tlabel_ent = kzalloc(sizeof(*label_ent), GFP_KERNEL);\n\t\t\tif (!label_ent)\n\t\t\t\tbreak;\n\t\t\tlabel = nd_label_active(ndd, j);\n\t\t\tlabel_ent->label = label;\n\n\t\t\tmutex_lock(&nd_mapping->lock);\n\t\t\tlist_add_tail(&label_ent->list, &nd_mapping->labels);\n\t\t\tmutex_unlock(&nd_mapping->lock);\n\t\t}\n\n\t\tif (j < count)\n\t\t\tbreak;\n\t}\n\n\tif (i < nd_region->ndr_mappings)\n\t\trc = -ENOMEM;\n\nout:\n\tif (rc) {\n\t\tdeactivate_labels(nd_region);\n\t\treturn rc;\n\t}\n\n\treturn devm_add_action_or_reset(&nd_region->dev, deactivate_labels,\n\t\t\t\t\tnd_region);\n}\n\nint nd_region_register_namespaces(struct nd_region *nd_region, int *err)\n{\n\tstruct device **devs = NULL;\n\tint i, rc = 0, type;\n\n\t*err = 0;\n\tnvdimm_bus_lock(&nd_region->dev);\n\trc = init_active_labels(nd_region);\n\tif (rc) {\n\t\tnvdimm_bus_unlock(&nd_region->dev);\n\t\treturn rc;\n\t}\n\n\ttype = nd_region_to_nstype(nd_region);\n\tswitch (type) {\n\tcase ND_DEVICE_NAMESPACE_IO:\n\t\tdevs = create_namespace_io(nd_region);\n\t\tbreak;\n\tcase ND_DEVICE_NAMESPACE_PMEM:\n\t\tdevs = create_namespaces(nd_region);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\tnvdimm_bus_unlock(&nd_region->dev);\n\n\tif (!devs)\n\t\treturn -ENODEV;\n\n\tfor (i = 0; devs[i]; i++) {\n\t\tstruct device *dev = devs[i];\n\t\tint id;\n\n\t\tif (type == ND_DEVICE_NAMESPACE_PMEM) {\n\t\t\tstruct nd_namespace_pmem *nspm;\n\n\t\t\tnspm = to_nd_namespace_pmem(dev);\n\t\t\tid = ida_simple_get(&nd_region->ns_ida, 0, 0,\n\t\t\t\t\t    GFP_KERNEL);\n\t\t\tnspm->id = id;\n\t\t} else\n\t\t\tid = i;\n\n\t\tif (id < 0)\n\t\t\tbreak;\n\t\tdev_set_name(dev, \"namespace%d.%d\", nd_region->id, id);\n\t\tdevice_initialize(dev);\n\t\tlockdep_set_class(&dev->mutex, &nvdimm_namespace_key);\n\t\tnd_device_register(dev);\n\t}\n\tif (i)\n\t\tnd_region->ns_seed = devs[0];\n\n\tif (devs[i]) {\n\t\tint j;\n\n\t\tfor (j = i; devs[j]; j++) {\n\t\t\tstruct device *dev = devs[j];\n\n\t\t\tdevice_initialize(dev);\n\t\t\tput_device(dev);\n\t\t}\n\t\t*err = j - i;\n\t\t \n\t\tif (*err == 0)\n\t\t\trc = -ENODEV;\n\t}\n\tkfree(devs);\n\n\tif (rc == -ENODEV)\n\t\treturn rc;\n\n\treturn i;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}