{
  "module_name": "bus.c",
  "hash_id": "de55ee4ead89b50fc679ea1555a283b98624875cf1cb2c62565b98da98680970",
  "original_prompt": "Ingested from linux-6.6.14/drivers/nvdimm/bus.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/libnvdimm.h>\n#include <linux/sched/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/uaccess.h>\n#include <linux/module.h>\n#include <linux/blkdev.h>\n#include <linux/fcntl.h>\n#include <linux/async.h>\n#include <linux/ndctl.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/cpu.h>\n#include <linux/fs.h>\n#include <linux/io.h>\n#include <linux/mm.h>\n#include <linux/nd.h>\n#include \"nd-core.h\"\n#include \"nd.h\"\n#include \"pfn.h\"\n\nint nvdimm_major;\nstatic int nvdimm_bus_major;\nstatic struct class *nd_class;\nstatic DEFINE_IDA(nd_ida);\n\nstatic int to_nd_device_type(const struct device *dev)\n{\n\tif (is_nvdimm(dev))\n\t\treturn ND_DEVICE_DIMM;\n\telse if (is_memory(dev))\n\t\treturn ND_DEVICE_REGION_PMEM;\n\telse if (is_nd_dax(dev))\n\t\treturn ND_DEVICE_DAX_PMEM;\n\telse if (is_nd_region(dev->parent))\n\t\treturn nd_region_to_nstype(to_nd_region(dev->parent));\n\n\treturn 0;\n}\n\nstatic int nvdimm_bus_uevent(const struct device *dev, struct kobj_uevent_env *env)\n{\n\treturn add_uevent_var(env, \"MODALIAS=\" ND_DEVICE_MODALIAS_FMT,\n\t\t\tto_nd_device_type(dev));\n}\n\nstatic struct module *to_bus_provider(struct device *dev)\n{\n\t \n\tif (is_nd_region(dev)) {\n\t\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);\n\n\t\treturn nvdimm_bus->nd_desc->module;\n\t}\n\treturn NULL;\n}\n\nstatic void nvdimm_bus_probe_start(struct nvdimm_bus *nvdimm_bus)\n{\n\tnvdimm_bus_lock(&nvdimm_bus->dev);\n\tnvdimm_bus->probe_active++;\n\tnvdimm_bus_unlock(&nvdimm_bus->dev);\n}\n\nstatic void nvdimm_bus_probe_end(struct nvdimm_bus *nvdimm_bus)\n{\n\tnvdimm_bus_lock(&nvdimm_bus->dev);\n\tif (--nvdimm_bus->probe_active == 0)\n\t\twake_up(&nvdimm_bus->wait);\n\tnvdimm_bus_unlock(&nvdimm_bus->dev);\n}\n\nstatic int nvdimm_bus_probe(struct device *dev)\n{\n\tstruct nd_device_driver *nd_drv = to_nd_device_driver(dev->driver);\n\tstruct module *provider = to_bus_provider(dev);\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);\n\tint rc;\n\n\tif (!try_module_get(provider))\n\t\treturn -ENXIO;\n\n\tdev_dbg(&nvdimm_bus->dev, \"START: %s.probe(%s)\\n\",\n\t\t\tdev->driver->name, dev_name(dev));\n\n\tnvdimm_bus_probe_start(nvdimm_bus);\n\trc = nd_drv->probe(dev);\n\tif ((rc == 0 || rc == -EOPNOTSUPP) &&\n\t\t\tdev->parent && is_nd_region(dev->parent))\n\t\tnd_region_advance_seeds(to_nd_region(dev->parent), dev);\n\tnvdimm_bus_probe_end(nvdimm_bus);\n\n\tdev_dbg(&nvdimm_bus->dev, \"END: %s.probe(%s) = %d\\n\", dev->driver->name,\n\t\t\tdev_name(dev), rc);\n\n\tif (rc != 0)\n\t\tmodule_put(provider);\n\treturn rc;\n}\n\nstatic void nvdimm_bus_remove(struct device *dev)\n{\n\tstruct nd_device_driver *nd_drv = to_nd_device_driver(dev->driver);\n\tstruct module *provider = to_bus_provider(dev);\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);\n\n\tif (nd_drv->remove)\n\t\tnd_drv->remove(dev);\n\n\tdev_dbg(&nvdimm_bus->dev, \"%s.remove(%s)\\n\", dev->driver->name,\n\t\t\tdev_name(dev));\n\tmodule_put(provider);\n}\n\nstatic void nvdimm_bus_shutdown(struct device *dev)\n{\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);\n\tstruct nd_device_driver *nd_drv = NULL;\n\n\tif (dev->driver)\n\t\tnd_drv = to_nd_device_driver(dev->driver);\n\n\tif (nd_drv && nd_drv->shutdown) {\n\t\tnd_drv->shutdown(dev);\n\t\tdev_dbg(&nvdimm_bus->dev, \"%s.shutdown(%s)\\n\",\n\t\t\t\tdev->driver->name, dev_name(dev));\n\t}\n}\n\nvoid nd_device_notify(struct device *dev, enum nvdimm_event event)\n{\n\tdevice_lock(dev);\n\tif (dev->driver) {\n\t\tstruct nd_device_driver *nd_drv;\n\n\t\tnd_drv = to_nd_device_driver(dev->driver);\n\t\tif (nd_drv->notify)\n\t\t\tnd_drv->notify(dev, event);\n\t}\n\tdevice_unlock(dev);\n}\nEXPORT_SYMBOL(nd_device_notify);\n\nvoid nvdimm_region_notify(struct nd_region *nd_region, enum nvdimm_event event)\n{\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(&nd_region->dev);\n\n\tif (!nvdimm_bus)\n\t\treturn;\n\n\t \n\tnd_device_notify(&nd_region->dev, event);\n}\nEXPORT_SYMBOL_GPL(nvdimm_region_notify);\n\nstruct clear_badblocks_context {\n\tresource_size_t phys, cleared;\n};\n\nstatic int nvdimm_clear_badblocks_region(struct device *dev, void *data)\n{\n\tstruct clear_badblocks_context *ctx = data;\n\tstruct nd_region *nd_region;\n\tresource_size_t ndr_end;\n\tsector_t sector;\n\n\t \n\tif (!is_memory(dev))\n\t\treturn 0;\n\n\tnd_region = to_nd_region(dev);\n\tndr_end = nd_region->ndr_start + nd_region->ndr_size - 1;\n\n\t \n\tif (ctx->phys < nd_region->ndr_start ||\n\t    (ctx->phys + ctx->cleared - 1) > ndr_end)\n\t\treturn 0;\n\n\tsector = (ctx->phys - nd_region->ndr_start) / 512;\n\tbadblocks_clear(&nd_region->bb, sector, ctx->cleared / 512);\n\n\tif (nd_region->bb_state)\n\t\tsysfs_notify_dirent(nd_region->bb_state);\n\n\treturn 0;\n}\n\nstatic void nvdimm_clear_badblocks_regions(struct nvdimm_bus *nvdimm_bus,\n\t\tphys_addr_t phys, u64 cleared)\n{\n\tstruct clear_badblocks_context ctx = {\n\t\t.phys = phys,\n\t\t.cleared = cleared,\n\t};\n\n\tdevice_for_each_child(&nvdimm_bus->dev, &ctx,\n\t\t\tnvdimm_clear_badblocks_region);\n}\n\nstatic void nvdimm_account_cleared_poison(struct nvdimm_bus *nvdimm_bus,\n\t\tphys_addr_t phys, u64 cleared)\n{\n\tif (cleared > 0)\n\t\tbadrange_forget(&nvdimm_bus->badrange, phys, cleared);\n\n\tif (cleared > 0 && cleared / 512)\n\t\tnvdimm_clear_badblocks_regions(nvdimm_bus, phys, cleared);\n}\n\nlong nvdimm_clear_poison(struct device *dev, phys_addr_t phys,\n\t\tunsigned int len)\n{\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);\n\tstruct nvdimm_bus_descriptor *nd_desc;\n\tstruct nd_cmd_clear_error clear_err;\n\tstruct nd_cmd_ars_cap ars_cap;\n\tu32 clear_err_unit, mask;\n\tunsigned int noio_flag;\n\tint cmd_rc, rc;\n\n\tif (!nvdimm_bus)\n\t\treturn -ENXIO;\n\n\tnd_desc = nvdimm_bus->nd_desc;\n\t \n\tif (!nd_desc->ndctl)\n\t\treturn len;\n\n\tmemset(&ars_cap, 0, sizeof(ars_cap));\n\tars_cap.address = phys;\n\tars_cap.length = len;\n\tnoio_flag = memalloc_noio_save();\n\trc = nd_desc->ndctl(nd_desc, NULL, ND_CMD_ARS_CAP, &ars_cap,\n\t\t\tsizeof(ars_cap), &cmd_rc);\n\tmemalloc_noio_restore(noio_flag);\n\tif (rc < 0)\n\t\treturn rc;\n\tif (cmd_rc < 0)\n\t\treturn cmd_rc;\n\tclear_err_unit = ars_cap.clear_err_unit;\n\tif (!clear_err_unit || !is_power_of_2(clear_err_unit))\n\t\treturn -ENXIO;\n\n\tmask = clear_err_unit - 1;\n\tif ((phys | len) & mask)\n\t\treturn -ENXIO;\n\tmemset(&clear_err, 0, sizeof(clear_err));\n\tclear_err.address = phys;\n\tclear_err.length = len;\n\tnoio_flag = memalloc_noio_save();\n\trc = nd_desc->ndctl(nd_desc, NULL, ND_CMD_CLEAR_ERROR, &clear_err,\n\t\t\tsizeof(clear_err), &cmd_rc);\n\tmemalloc_noio_restore(noio_flag);\n\tif (rc < 0)\n\t\treturn rc;\n\tif (cmd_rc < 0)\n\t\treturn cmd_rc;\n\n\tnvdimm_account_cleared_poison(nvdimm_bus, phys, clear_err.cleared);\n\n\treturn clear_err.cleared;\n}\nEXPORT_SYMBOL_GPL(nvdimm_clear_poison);\n\nstatic int nvdimm_bus_match(struct device *dev, struct device_driver *drv);\n\nstatic struct bus_type nvdimm_bus_type = {\n\t.name = \"nd\",\n\t.uevent = nvdimm_bus_uevent,\n\t.match = nvdimm_bus_match,\n\t.probe = nvdimm_bus_probe,\n\t.remove = nvdimm_bus_remove,\n\t.shutdown = nvdimm_bus_shutdown,\n};\n\nstatic void nvdimm_bus_release(struct device *dev)\n{\n\tstruct nvdimm_bus *nvdimm_bus;\n\n\tnvdimm_bus = container_of(dev, struct nvdimm_bus, dev);\n\tida_simple_remove(&nd_ida, nvdimm_bus->id);\n\tkfree(nvdimm_bus);\n}\n\nstatic const struct device_type nvdimm_bus_dev_type = {\n\t.release = nvdimm_bus_release,\n\t.groups = nvdimm_bus_attribute_groups,\n};\n\nbool is_nvdimm_bus(struct device *dev)\n{\n\treturn dev->type == &nvdimm_bus_dev_type;\n}\n\nstruct nvdimm_bus *walk_to_nvdimm_bus(struct device *nd_dev)\n{\n\tstruct device *dev;\n\n\tfor (dev = nd_dev; dev; dev = dev->parent)\n\t\tif (is_nvdimm_bus(dev))\n\t\t\tbreak;\n\tdev_WARN_ONCE(nd_dev, !dev, \"invalid dev, not on nd bus\\n\");\n\tif (dev)\n\t\treturn to_nvdimm_bus(dev);\n\treturn NULL;\n}\n\nstruct nvdimm_bus *to_nvdimm_bus(struct device *dev)\n{\n\tstruct nvdimm_bus *nvdimm_bus;\n\n\tnvdimm_bus = container_of(dev, struct nvdimm_bus, dev);\n\tWARN_ON(!is_nvdimm_bus(dev));\n\treturn nvdimm_bus;\n}\nEXPORT_SYMBOL_GPL(to_nvdimm_bus);\n\nstruct nvdimm_bus *nvdimm_to_bus(struct nvdimm *nvdimm)\n{\n\treturn to_nvdimm_bus(nvdimm->dev.parent);\n}\nEXPORT_SYMBOL_GPL(nvdimm_to_bus);\n\nstatic struct lock_class_key nvdimm_bus_key;\n\nstruct nvdimm_bus *nvdimm_bus_register(struct device *parent,\n\t\tstruct nvdimm_bus_descriptor *nd_desc)\n{\n\tstruct nvdimm_bus *nvdimm_bus;\n\tint rc;\n\n\tnvdimm_bus = kzalloc(sizeof(*nvdimm_bus), GFP_KERNEL);\n\tif (!nvdimm_bus)\n\t\treturn NULL;\n\tINIT_LIST_HEAD(&nvdimm_bus->list);\n\tINIT_LIST_HEAD(&nvdimm_bus->mapping_list);\n\tinit_waitqueue_head(&nvdimm_bus->wait);\n\tnvdimm_bus->id = ida_simple_get(&nd_ida, 0, 0, GFP_KERNEL);\n\tif (nvdimm_bus->id < 0) {\n\t\tkfree(nvdimm_bus);\n\t\treturn NULL;\n\t}\n\tmutex_init(&nvdimm_bus->reconfig_mutex);\n\tbadrange_init(&nvdimm_bus->badrange);\n\tnvdimm_bus->nd_desc = nd_desc;\n\tnvdimm_bus->dev.parent = parent;\n\tnvdimm_bus->dev.type = &nvdimm_bus_dev_type;\n\tnvdimm_bus->dev.groups = nd_desc->attr_groups;\n\tnvdimm_bus->dev.bus = &nvdimm_bus_type;\n\tnvdimm_bus->dev.of_node = nd_desc->of_node;\n\tdevice_initialize(&nvdimm_bus->dev);\n\tlockdep_set_class(&nvdimm_bus->dev.mutex, &nvdimm_bus_key);\n\tdevice_set_pm_not_required(&nvdimm_bus->dev);\n\trc = dev_set_name(&nvdimm_bus->dev, \"ndbus%d\", nvdimm_bus->id);\n\tif (rc)\n\t\tgoto err;\n\n\trc = device_add(&nvdimm_bus->dev);\n\tif (rc) {\n\t\tdev_dbg(&nvdimm_bus->dev, \"registration failed: %d\\n\", rc);\n\t\tgoto err;\n\t}\n\n\treturn nvdimm_bus;\n err:\n\tput_device(&nvdimm_bus->dev);\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(nvdimm_bus_register);\n\nvoid nvdimm_bus_unregister(struct nvdimm_bus *nvdimm_bus)\n{\n\tif (!nvdimm_bus)\n\t\treturn;\n\tdevice_unregister(&nvdimm_bus->dev);\n}\nEXPORT_SYMBOL_GPL(nvdimm_bus_unregister);\n\nstatic int child_unregister(struct device *dev, void *data)\n{\n\t \n\tif (dev->class)\n\t\treturn 0;\n\n\tif (is_nvdimm(dev))\n\t\tnvdimm_delete(to_nvdimm(dev));\n\telse\n\t\tnd_device_unregister(dev, ND_SYNC);\n\n\treturn 0;\n}\n\nstatic void free_badrange_list(struct list_head *badrange_list)\n{\n\tstruct badrange_entry *bre, *next;\n\n\tlist_for_each_entry_safe(bre, next, badrange_list, list) {\n\t\tlist_del(&bre->list);\n\t\tkfree(bre);\n\t}\n\tlist_del_init(badrange_list);\n}\n\nstatic void nd_bus_remove(struct device *dev)\n{\n\tstruct nvdimm_bus *nvdimm_bus = to_nvdimm_bus(dev);\n\n\tmutex_lock(&nvdimm_bus_list_mutex);\n\tlist_del_init(&nvdimm_bus->list);\n\tmutex_unlock(&nvdimm_bus_list_mutex);\n\n\twait_event(nvdimm_bus->wait,\n\t\t\tatomic_read(&nvdimm_bus->ioctl_active) == 0);\n\n\tnd_synchronize();\n\tdevice_for_each_child(&nvdimm_bus->dev, NULL, child_unregister);\n\n\tspin_lock(&nvdimm_bus->badrange.lock);\n\tfree_badrange_list(&nvdimm_bus->badrange.list);\n\tspin_unlock(&nvdimm_bus->badrange.lock);\n\n\tnvdimm_bus_destroy_ndctl(nvdimm_bus);\n}\n\nstatic int nd_bus_probe(struct device *dev)\n{\n\tstruct nvdimm_bus *nvdimm_bus = to_nvdimm_bus(dev);\n\tint rc;\n\n\trc = nvdimm_bus_create_ndctl(nvdimm_bus);\n\tif (rc)\n\t\treturn rc;\n\n\tmutex_lock(&nvdimm_bus_list_mutex);\n\tlist_add_tail(&nvdimm_bus->list, &nvdimm_bus_list);\n\tmutex_unlock(&nvdimm_bus_list_mutex);\n\n\t \n\tdev_set_drvdata(dev, nvdimm_bus->nd_desc);\n\n\treturn 0;\n}\n\nstatic struct nd_device_driver nd_bus_driver = {\n\t.probe = nd_bus_probe,\n\t.remove = nd_bus_remove,\n\t.drv = {\n\t\t.name = \"nd_bus\",\n\t\t.suppress_bind_attrs = true,\n\t\t.bus = &nvdimm_bus_type,\n\t\t.owner = THIS_MODULE,\n\t\t.mod_name = KBUILD_MODNAME,\n\t},\n};\n\nstatic int nvdimm_bus_match(struct device *dev, struct device_driver *drv)\n{\n\tstruct nd_device_driver *nd_drv = to_nd_device_driver(drv);\n\n\tif (is_nvdimm_bus(dev) && nd_drv == &nd_bus_driver)\n\t\treturn true;\n\n\treturn !!test_bit(to_nd_device_type(dev), &nd_drv->type);\n}\n\nstatic ASYNC_DOMAIN_EXCLUSIVE(nd_async_domain);\n\nvoid nd_synchronize(void)\n{\n\tasync_synchronize_full_domain(&nd_async_domain);\n}\nEXPORT_SYMBOL_GPL(nd_synchronize);\n\nstatic void nd_async_device_register(void *d, async_cookie_t cookie)\n{\n\tstruct device *dev = d;\n\n\tif (device_add(dev) != 0) {\n\t\tdev_err(dev, \"%s: failed\\n\", __func__);\n\t\tput_device(dev);\n\t}\n\tput_device(dev);\n\tif (dev->parent)\n\t\tput_device(dev->parent);\n}\n\nstatic void nd_async_device_unregister(void *d, async_cookie_t cookie)\n{\n\tstruct device *dev = d;\n\n\t \n\tnvdimm_bus_lock(dev);\n\tnvdimm_bus_unlock(dev);\n\n\tdevice_unregister(dev);\n\tput_device(dev);\n}\n\nstatic void __nd_device_register(struct device *dev, bool sync)\n{\n\tif (!dev)\n\t\treturn;\n\n\t \n\tif (is_nd_region(dev))\n\t\tset_dev_node(dev, to_nd_region(dev)->numa_node);\n\n\tdev->bus = &nvdimm_bus_type;\n\tdevice_set_pm_not_required(dev);\n\tif (dev->parent) {\n\t\tget_device(dev->parent);\n\t\tif (dev_to_node(dev) == NUMA_NO_NODE)\n\t\t\tset_dev_node(dev, dev_to_node(dev->parent));\n\t}\n\tget_device(dev);\n\n\tif (sync)\n\t\tnd_async_device_register(dev, 0);\n\telse\n\t\tasync_schedule_dev_domain(nd_async_device_register, dev,\n\t\t\t\t\t  &nd_async_domain);\n}\n\nvoid nd_device_register(struct device *dev)\n{\n\t__nd_device_register(dev, false);\n}\nEXPORT_SYMBOL(nd_device_register);\n\nvoid nd_device_register_sync(struct device *dev)\n{\n\t__nd_device_register(dev, true);\n}\n\nvoid nd_device_unregister(struct device *dev, enum nd_async_mode mode)\n{\n\tbool killed;\n\n\tswitch (mode) {\n\tcase ND_ASYNC:\n\t\t \n\t\tif (!kill_device(dev))\n\t\t\treturn;\n\n\t\tget_device(dev);\n\t\tasync_schedule_domain(nd_async_device_unregister, dev,\n\t\t\t\t&nd_async_domain);\n\t\tbreak;\n\tcase ND_SYNC:\n\t\t \n\t\tdevice_lock(dev);\n\t\tkilled = kill_device(dev);\n\t\tdevice_unlock(dev);\n\n\t\tif (!killed)\n\t\t\treturn;\n\n\t\tnd_synchronize();\n\t\tdevice_unregister(dev);\n\t\tbreak;\n\t}\n}\nEXPORT_SYMBOL(nd_device_unregister);\n\n \nint __nd_driver_register(struct nd_device_driver *nd_drv, struct module *owner,\n\t\tconst char *mod_name)\n{\n\tstruct device_driver *drv = &nd_drv->drv;\n\n\tif (!nd_drv->type) {\n\t\tpr_debug(\"driver type bitmask not set (%ps)\\n\",\n\t\t\t\t__builtin_return_address(0));\n\t\treturn -EINVAL;\n\t}\n\n\tif (!nd_drv->probe) {\n\t\tpr_debug(\"%s ->probe() must be specified\\n\", mod_name);\n\t\treturn -EINVAL;\n\t}\n\n\tdrv->bus = &nvdimm_bus_type;\n\tdrv->owner = owner;\n\tdrv->mod_name = mod_name;\n\n\treturn driver_register(drv);\n}\nEXPORT_SYMBOL(__nd_driver_register);\n\nvoid nvdimm_check_and_set_ro(struct gendisk *disk)\n{\n\tstruct device *dev = disk_to_dev(disk)->parent;\n\tstruct nd_region *nd_region = to_nd_region(dev->parent);\n\tint disk_ro = get_disk_ro(disk);\n\n\t \n\tif (disk_ro == nd_region->ro)\n\t\treturn;\n\n\tdev_info(dev, \"%s read-%s, marking %s read-%s\\n\",\n\t\t dev_name(&nd_region->dev), nd_region->ro ? \"only\" : \"write\",\n\t\t disk->disk_name, nd_region->ro ? \"only\" : \"write\");\n\tset_disk_ro(disk, nd_region->ro);\n}\nEXPORT_SYMBOL(nvdimm_check_and_set_ro);\n\nstatic ssize_t modalias_show(struct device *dev, struct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn sprintf(buf, ND_DEVICE_MODALIAS_FMT \"\\n\",\n\t\t\tto_nd_device_type(dev));\n}\nstatic DEVICE_ATTR_RO(modalias);\n\nstatic ssize_t devtype_show(struct device *dev, struct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn sprintf(buf, \"%s\\n\", dev->type->name);\n}\nstatic DEVICE_ATTR_RO(devtype);\n\nstatic struct attribute *nd_device_attributes[] = {\n\t&dev_attr_modalias.attr,\n\t&dev_attr_devtype.attr,\n\tNULL,\n};\n\n \nconst struct attribute_group nd_device_attribute_group = {\n\t.attrs = nd_device_attributes,\n};\n\nstatic ssize_t numa_node_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\treturn sprintf(buf, \"%d\\n\", dev_to_node(dev));\n}\nstatic DEVICE_ATTR_RO(numa_node);\n\nstatic int nvdimm_dev_to_target_node(struct device *dev)\n{\n\tstruct device *parent = dev->parent;\n\tstruct nd_region *nd_region = NULL;\n\n\tif (is_nd_region(dev))\n\t\tnd_region = to_nd_region(dev);\n\telse if (parent && is_nd_region(parent))\n\t\tnd_region = to_nd_region(parent);\n\n\tif (!nd_region)\n\t\treturn NUMA_NO_NODE;\n\treturn nd_region->target_node;\n}\n\nstatic ssize_t target_node_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\treturn sprintf(buf, \"%d\\n\", nvdimm_dev_to_target_node(dev));\n}\nstatic DEVICE_ATTR_RO(target_node);\n\nstatic struct attribute *nd_numa_attributes[] = {\n\t&dev_attr_numa_node.attr,\n\t&dev_attr_target_node.attr,\n\tNULL,\n};\n\nstatic umode_t nd_numa_attr_visible(struct kobject *kobj, struct attribute *a,\n\t\tint n)\n{\n\tstruct device *dev = container_of(kobj, typeof(*dev), kobj);\n\n\tif (!IS_ENABLED(CONFIG_NUMA))\n\t\treturn 0;\n\n\tif (a == &dev_attr_target_node.attr &&\n\t\t\tnvdimm_dev_to_target_node(dev) == NUMA_NO_NODE)\n\t\treturn 0;\n\n\treturn a->mode;\n}\n\n \nconst struct attribute_group nd_numa_attribute_group = {\n\t.attrs = nd_numa_attributes,\n\t.is_visible = nd_numa_attr_visible,\n};\n\nstatic void ndctl_release(struct device *dev)\n{\n\tkfree(dev);\n}\n\nstatic struct lock_class_key nvdimm_ndctl_key;\n\nint nvdimm_bus_create_ndctl(struct nvdimm_bus *nvdimm_bus)\n{\n\tdev_t devt = MKDEV(nvdimm_bus_major, nvdimm_bus->id);\n\tstruct device *dev;\n\tint rc;\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\tdevice_initialize(dev);\n\tlockdep_set_class(&dev->mutex, &nvdimm_ndctl_key);\n\tdevice_set_pm_not_required(dev);\n\tdev->class = nd_class;\n\tdev->parent = &nvdimm_bus->dev;\n\tdev->devt = devt;\n\tdev->release = ndctl_release;\n\trc = dev_set_name(dev, \"ndctl%d\", nvdimm_bus->id);\n\tif (rc)\n\t\tgoto err;\n\n\trc = device_add(dev);\n\tif (rc) {\n\t\tdev_dbg(&nvdimm_bus->dev, \"failed to register ndctl%d: %d\\n\",\n\t\t\t\tnvdimm_bus->id, rc);\n\t\tgoto err;\n\t}\n\treturn 0;\n\nerr:\n\tput_device(dev);\n\treturn rc;\n}\n\nvoid nvdimm_bus_destroy_ndctl(struct nvdimm_bus *nvdimm_bus)\n{\n\tdevice_destroy(nd_class, MKDEV(nvdimm_bus_major, nvdimm_bus->id));\n}\n\nstatic const struct nd_cmd_desc __nd_cmd_dimm_descs[] = {\n\t[ND_CMD_IMPLEMENTED] = { },\n\t[ND_CMD_SMART] = {\n\t\t.out_num = 2,\n\t\t.out_sizes = { 4, 128, },\n\t},\n\t[ND_CMD_SMART_THRESHOLD] = {\n\t\t.out_num = 2,\n\t\t.out_sizes = { 4, 8, },\n\t},\n\t[ND_CMD_DIMM_FLAGS] = {\n\t\t.out_num = 2,\n\t\t.out_sizes = { 4, 4 },\n\t},\n\t[ND_CMD_GET_CONFIG_SIZE] = {\n\t\t.out_num = 3,\n\t\t.out_sizes = { 4, 4, 4, },\n\t},\n\t[ND_CMD_GET_CONFIG_DATA] = {\n\t\t.in_num = 2,\n\t\t.in_sizes = { 4, 4, },\n\t\t.out_num = 2,\n\t\t.out_sizes = { 4, UINT_MAX, },\n\t},\n\t[ND_CMD_SET_CONFIG_DATA] = {\n\t\t.in_num = 3,\n\t\t.in_sizes = { 4, 4, UINT_MAX, },\n\t\t.out_num = 1,\n\t\t.out_sizes = { 4, },\n\t},\n\t[ND_CMD_VENDOR] = {\n\t\t.in_num = 3,\n\t\t.in_sizes = { 4, 4, UINT_MAX, },\n\t\t.out_num = 3,\n\t\t.out_sizes = { 4, 4, UINT_MAX, },\n\t},\n\t[ND_CMD_CALL] = {\n\t\t.in_num = 2,\n\t\t.in_sizes = { sizeof(struct nd_cmd_pkg), UINT_MAX, },\n\t\t.out_num = 1,\n\t\t.out_sizes = { UINT_MAX, },\n\t},\n};\n\nconst struct nd_cmd_desc *nd_cmd_dimm_desc(int cmd)\n{\n\tif (cmd < ARRAY_SIZE(__nd_cmd_dimm_descs))\n\t\treturn &__nd_cmd_dimm_descs[cmd];\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(nd_cmd_dimm_desc);\n\nstatic const struct nd_cmd_desc __nd_cmd_bus_descs[] = {\n\t[ND_CMD_IMPLEMENTED] = { },\n\t[ND_CMD_ARS_CAP] = {\n\t\t.in_num = 2,\n\t\t.in_sizes = { 8, 8, },\n\t\t.out_num = 4,\n\t\t.out_sizes = { 4, 4, 4, 4, },\n\t},\n\t[ND_CMD_ARS_START] = {\n\t\t.in_num = 5,\n\t\t.in_sizes = { 8, 8, 2, 1, 5, },\n\t\t.out_num = 2,\n\t\t.out_sizes = { 4, 4, },\n\t},\n\t[ND_CMD_ARS_STATUS] = {\n\t\t.out_num = 3,\n\t\t.out_sizes = { 4, 4, UINT_MAX, },\n\t},\n\t[ND_CMD_CLEAR_ERROR] = {\n\t\t.in_num = 2,\n\t\t.in_sizes = { 8, 8, },\n\t\t.out_num = 3,\n\t\t.out_sizes = { 4, 4, 8, },\n\t},\n\t[ND_CMD_CALL] = {\n\t\t.in_num = 2,\n\t\t.in_sizes = { sizeof(struct nd_cmd_pkg), UINT_MAX, },\n\t\t.out_num = 1,\n\t\t.out_sizes = { UINT_MAX, },\n\t},\n};\n\nconst struct nd_cmd_desc *nd_cmd_bus_desc(int cmd)\n{\n\tif (cmd < ARRAY_SIZE(__nd_cmd_bus_descs))\n\t\treturn &__nd_cmd_bus_descs[cmd];\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(nd_cmd_bus_desc);\n\nu32 nd_cmd_in_size(struct nvdimm *nvdimm, int cmd,\n\t\tconst struct nd_cmd_desc *desc, int idx, void *buf)\n{\n\tif (idx >= desc->in_num)\n\t\treturn UINT_MAX;\n\n\tif (desc->in_sizes[idx] < UINT_MAX)\n\t\treturn desc->in_sizes[idx];\n\n\tif (nvdimm && cmd == ND_CMD_SET_CONFIG_DATA && idx == 2) {\n\t\tstruct nd_cmd_set_config_hdr *hdr = buf;\n\n\t\treturn hdr->in_length;\n\t} else if (nvdimm && cmd == ND_CMD_VENDOR && idx == 2) {\n\t\tstruct nd_cmd_vendor_hdr *hdr = buf;\n\n\t\treturn hdr->in_length;\n\t} else if (cmd == ND_CMD_CALL) {\n\t\tstruct nd_cmd_pkg *pkg = buf;\n\n\t\treturn pkg->nd_size_in;\n\t}\n\n\treturn UINT_MAX;\n}\nEXPORT_SYMBOL_GPL(nd_cmd_in_size);\n\nu32 nd_cmd_out_size(struct nvdimm *nvdimm, int cmd,\n\t\tconst struct nd_cmd_desc *desc, int idx, const u32 *in_field,\n\t\tconst u32 *out_field, unsigned long remainder)\n{\n\tif (idx >= desc->out_num)\n\t\treturn UINT_MAX;\n\n\tif (desc->out_sizes[idx] < UINT_MAX)\n\t\treturn desc->out_sizes[idx];\n\n\tif (nvdimm && cmd == ND_CMD_GET_CONFIG_DATA && idx == 1)\n\t\treturn in_field[1];\n\telse if (nvdimm && cmd == ND_CMD_VENDOR && idx == 2)\n\t\treturn out_field[1];\n\telse if (!nvdimm && cmd == ND_CMD_ARS_STATUS && idx == 2) {\n\t\t \n\t\tif (out_field[1] < 4)\n\t\t\treturn 0;\n\t\t \n\t\tif (out_field[1] - 4 == remainder)\n\t\t\treturn remainder;\n\t\treturn out_field[1] - 8;\n\t} else if (cmd == ND_CMD_CALL) {\n\t\tstruct nd_cmd_pkg *pkg = (struct nd_cmd_pkg *) in_field;\n\n\t\treturn pkg->nd_size_out;\n\t}\n\n\n\treturn UINT_MAX;\n}\nEXPORT_SYMBOL_GPL(nd_cmd_out_size);\n\nvoid wait_nvdimm_bus_probe_idle(struct device *dev)\n{\n\tstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);\n\n\tdo {\n\t\tif (nvdimm_bus->probe_active == 0)\n\t\t\tbreak;\n\t\tnvdimm_bus_unlock(dev);\n\t\tdevice_unlock(dev);\n\t\twait_event(nvdimm_bus->wait,\n\t\t\t\tnvdimm_bus->probe_active == 0);\n\t\tdevice_lock(dev);\n\t\tnvdimm_bus_lock(dev);\n\t} while (true);\n}\n\nstatic int nd_pmem_forget_poison_check(struct device *dev, void *data)\n{\n\tstruct nd_cmd_clear_error *clear_err =\n\t\t(struct nd_cmd_clear_error *)data;\n\tstruct nd_btt *nd_btt = is_nd_btt(dev) ? to_nd_btt(dev) : NULL;\n\tstruct nd_pfn *nd_pfn = is_nd_pfn(dev) ? to_nd_pfn(dev) : NULL;\n\tstruct nd_dax *nd_dax = is_nd_dax(dev) ? to_nd_dax(dev) : NULL;\n\tstruct nd_namespace_common *ndns = NULL;\n\tstruct nd_namespace_io *nsio;\n\tresource_size_t offset = 0, end_trunc = 0, start, end, pstart, pend;\n\n\tif (nd_dax || !dev->driver)\n\t\treturn 0;\n\n\tstart = clear_err->address;\n\tend = clear_err->address + clear_err->cleared - 1;\n\n\tif (nd_btt || nd_pfn || nd_dax) {\n\t\tif (nd_btt)\n\t\t\tndns = nd_btt->ndns;\n\t\telse if (nd_pfn)\n\t\t\tndns = nd_pfn->ndns;\n\t\telse if (nd_dax)\n\t\t\tndns = nd_dax->nd_pfn.ndns;\n\n\t\tif (!ndns)\n\t\t\treturn 0;\n\t} else\n\t\tndns = to_ndns(dev);\n\n\tnsio = to_nd_namespace_io(&ndns->dev);\n\tpstart = nsio->res.start + offset;\n\tpend = nsio->res.end - end_trunc;\n\n\tif ((pstart >= start) && (pend <= end))\n\t\treturn -EBUSY;\n\n\treturn 0;\n\n}\n\nstatic int nd_ns_forget_poison_check(struct device *dev, void *data)\n{\n\treturn device_for_each_child(dev, data, nd_pmem_forget_poison_check);\n}\n\n \nstatic int nd_cmd_clear_to_send(struct nvdimm_bus *nvdimm_bus,\n\t\tstruct nvdimm *nvdimm, unsigned int cmd, void *data)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc = nvdimm_bus->nd_desc;\n\n\t \n\tif (nd_desc->clear_to_send) {\n\t\tint rc = nd_desc->clear_to_send(nd_desc, nvdimm, cmd, data);\n\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t \n\tif (!nvdimm && cmd == ND_CMD_CLEAR_ERROR)\n\t\treturn device_for_each_child(&nvdimm_bus->dev, data,\n\t\t\t\tnd_ns_forget_poison_check);\n\n\tif (!nvdimm || cmd != ND_CMD_SET_CONFIG_DATA)\n\t\treturn 0;\n\n\t \n\twait_nvdimm_bus_probe_idle(&nvdimm_bus->dev);\n\tif (atomic_read(&nvdimm->busy))\n\t\treturn -EBUSY;\n\treturn 0;\n}\n\nstatic int __nd_ioctl(struct nvdimm_bus *nvdimm_bus, struct nvdimm *nvdimm,\n\t\tint read_only, unsigned int ioctl_cmd, unsigned long arg)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc = nvdimm_bus->nd_desc;\n\tconst struct nd_cmd_desc *desc = NULL;\n\tunsigned int cmd = _IOC_NR(ioctl_cmd);\n\tstruct device *dev = &nvdimm_bus->dev;\n\tvoid __user *p = (void __user *) arg;\n\tchar *out_env = NULL, *in_env = NULL;\n\tconst char *cmd_name, *dimm_name;\n\tu32 in_len = 0, out_len = 0;\n\tunsigned int func = cmd;\n\tunsigned long cmd_mask;\n\tstruct nd_cmd_pkg pkg;\n\tint rc, i, cmd_rc;\n\tvoid *buf = NULL;\n\tu64 buf_len = 0;\n\n\tif (nvdimm) {\n\t\tdesc = nd_cmd_dimm_desc(cmd);\n\t\tcmd_name = nvdimm_cmd_name(cmd);\n\t\tcmd_mask = nvdimm->cmd_mask;\n\t\tdimm_name = dev_name(&nvdimm->dev);\n\t} else {\n\t\tdesc = nd_cmd_bus_desc(cmd);\n\t\tcmd_name = nvdimm_bus_cmd_name(cmd);\n\t\tcmd_mask = nd_desc->cmd_mask;\n\t\tdimm_name = \"bus\";\n\t}\n\n\t \n\tif (cmd == ND_CMD_CALL) {\n\t\tunsigned long *mask;\n\n\t\tif (copy_from_user(&pkg, p, sizeof(pkg)))\n\t\t\treturn -EFAULT;\n\n\t\tif (nvdimm) {\n\t\t\tif (pkg.nd_family > NVDIMM_FAMILY_MAX)\n\t\t\t\treturn -EINVAL;\n\t\t\tmask = &nd_desc->dimm_family_mask;\n\t\t} else {\n\t\t\tif (pkg.nd_family > NVDIMM_BUS_FAMILY_MAX)\n\t\t\t\treturn -EINVAL;\n\t\t\tmask = &nd_desc->bus_family_mask;\n\t\t}\n\n\t\tif (!test_bit(pkg.nd_family, mask))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (!desc ||\n\t    (desc->out_num + desc->in_num == 0) ||\n\t    cmd > ND_CMD_CALL ||\n\t    !test_bit(cmd, &cmd_mask))\n\t\treturn -ENOTTY;\n\n\t \n\tif (read_only)\n\t\tswitch (cmd) {\n\t\tcase ND_CMD_VENDOR:\n\t\tcase ND_CMD_SET_CONFIG_DATA:\n\t\tcase ND_CMD_ARS_START:\n\t\tcase ND_CMD_CLEAR_ERROR:\n\t\tcase ND_CMD_CALL:\n\t\t\tdev_dbg(dev, \"'%s' command while read-only.\\n\",\n\t\t\t\t\tnvdimm ? nvdimm_cmd_name(cmd)\n\t\t\t\t\t: nvdimm_bus_cmd_name(cmd));\n\t\t\treturn -EPERM;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t \n\tin_env = kzalloc(ND_CMD_MAX_ENVELOPE, GFP_KERNEL);\n\tif (!in_env)\n\t\treturn -ENOMEM;\n\tfor (i = 0; i < desc->in_num; i++) {\n\t\tu32 in_size, copy;\n\n\t\tin_size = nd_cmd_in_size(nvdimm, cmd, desc, i, in_env);\n\t\tif (in_size == UINT_MAX) {\n\t\t\tdev_err(dev, \"%s:%s unknown input size cmd: %s field: %d\\n\",\n\t\t\t\t\t__func__, dimm_name, cmd_name, i);\n\t\t\trc = -ENXIO;\n\t\t\tgoto out;\n\t\t}\n\t\tif (in_len < ND_CMD_MAX_ENVELOPE)\n\t\t\tcopy = min_t(u32, ND_CMD_MAX_ENVELOPE - in_len, in_size);\n\t\telse\n\t\t\tcopy = 0;\n\t\tif (copy && copy_from_user(&in_env[in_len], p + in_len, copy)) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tin_len += in_size;\n\t}\n\n\tif (cmd == ND_CMD_CALL) {\n\t\tfunc = pkg.nd_command;\n\t\tdev_dbg(dev, \"%s, idx: %llu, in: %u, out: %u, len %llu\\n\",\n\t\t\t\tdimm_name, pkg.nd_command,\n\t\t\t\tin_len, out_len, buf_len);\n\t}\n\n\t \n\tout_env = kzalloc(ND_CMD_MAX_ENVELOPE, GFP_KERNEL);\n\tif (!out_env) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < desc->out_num; i++) {\n\t\tu32 out_size = nd_cmd_out_size(nvdimm, cmd, desc, i,\n\t\t\t\t(u32 *) in_env, (u32 *) out_env, 0);\n\t\tu32 copy;\n\n\t\tif (out_size == UINT_MAX) {\n\t\t\tdev_dbg(dev, \"%s unknown output size cmd: %s field: %d\\n\",\n\t\t\t\t\tdimm_name, cmd_name, i);\n\t\t\trc = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tif (out_len < ND_CMD_MAX_ENVELOPE)\n\t\t\tcopy = min_t(u32, ND_CMD_MAX_ENVELOPE - out_len, out_size);\n\t\telse\n\t\t\tcopy = 0;\n\t\tif (copy && copy_from_user(&out_env[out_len],\n\t\t\t\t\tp + in_len + out_len, copy)) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tout_len += out_size;\n\t}\n\n\tbuf_len = (u64) out_len + (u64) in_len;\n\tif (buf_len > ND_IOCTL_MAX_BUFLEN) {\n\t\tdev_dbg(dev, \"%s cmd: %s buf_len: %llu > %d\\n\", dimm_name,\n\t\t\t\tcmd_name, buf_len, ND_IOCTL_MAX_BUFLEN);\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tbuf = vmalloc(buf_len);\n\tif (!buf) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (copy_from_user(buf, p, buf_len)) {\n\t\trc = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tdevice_lock(dev);\n\tnvdimm_bus_lock(dev);\n\trc = nd_cmd_clear_to_send(nvdimm_bus, nvdimm, func, buf);\n\tif (rc)\n\t\tgoto out_unlock;\n\n\trc = nd_desc->ndctl(nd_desc, nvdimm, cmd, buf, buf_len, &cmd_rc);\n\tif (rc < 0)\n\t\tgoto out_unlock;\n\n\tif (!nvdimm && cmd == ND_CMD_CLEAR_ERROR && cmd_rc >= 0) {\n\t\tstruct nd_cmd_clear_error *clear_err = buf;\n\n\t\tnvdimm_account_cleared_poison(nvdimm_bus, clear_err->address,\n\t\t\t\tclear_err->cleared);\n\t}\n\n\tif (copy_to_user(p, buf, buf_len))\n\t\trc = -EFAULT;\n\nout_unlock:\n\tnvdimm_bus_unlock(dev);\n\tdevice_unlock(dev);\nout:\n\tkfree(in_env);\n\tkfree(out_env);\n\tvfree(buf);\n\treturn rc;\n}\n\nenum nd_ioctl_mode {\n\tBUS_IOCTL,\n\tDIMM_IOCTL,\n};\n\nstatic int match_dimm(struct device *dev, void *data)\n{\n\tlong id = (long) data;\n\n\tif (is_nvdimm(dev)) {\n\t\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\t\treturn nvdimm->id == id;\n\t}\n\n\treturn 0;\n}\n\nstatic long nd_ioctl(struct file *file, unsigned int cmd, unsigned long arg,\n\t\tenum nd_ioctl_mode mode)\n\n{\n\tstruct nvdimm_bus *nvdimm_bus, *found = NULL;\n\tlong id = (long) file->private_data;\n\tstruct nvdimm *nvdimm = NULL;\n\tint rc, ro;\n\n\tro = ((file->f_flags & O_ACCMODE) == O_RDONLY);\n\tmutex_lock(&nvdimm_bus_list_mutex);\n\tlist_for_each_entry(nvdimm_bus, &nvdimm_bus_list, list) {\n\t\tif (mode == DIMM_IOCTL) {\n\t\t\tstruct device *dev;\n\n\t\t\tdev = device_find_child(&nvdimm_bus->dev,\n\t\t\t\t\tfile->private_data, match_dimm);\n\t\t\tif (!dev)\n\t\t\t\tcontinue;\n\t\t\tnvdimm = to_nvdimm(dev);\n\t\t\tfound = nvdimm_bus;\n\t\t} else if (nvdimm_bus->id == id) {\n\t\t\tfound = nvdimm_bus;\n\t\t}\n\n\t\tif (found) {\n\t\t\tatomic_inc(&nvdimm_bus->ioctl_active);\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&nvdimm_bus_list_mutex);\n\n\tif (!found)\n\t\treturn -ENXIO;\n\n\tnvdimm_bus = found;\n\trc = __nd_ioctl(nvdimm_bus, nvdimm, ro, cmd, arg);\n\n\tif (nvdimm)\n\t\tput_device(&nvdimm->dev);\n\tif (atomic_dec_and_test(&nvdimm_bus->ioctl_active))\n\t\twake_up(&nvdimm_bus->wait);\n\n\treturn rc;\n}\n\nstatic long bus_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\treturn nd_ioctl(file, cmd, arg, BUS_IOCTL);\n}\n\nstatic long dimm_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\treturn nd_ioctl(file, cmd, arg, DIMM_IOCTL);\n}\n\nstatic int nd_open(struct inode *inode, struct file *file)\n{\n\tlong minor = iminor(inode);\n\n\tfile->private_data = (void *) minor;\n\treturn 0;\n}\n\nstatic const struct file_operations nvdimm_bus_fops = {\n\t.owner = THIS_MODULE,\n\t.open = nd_open,\n\t.unlocked_ioctl = bus_ioctl,\n\t.compat_ioctl = compat_ptr_ioctl,\n\t.llseek = noop_llseek,\n};\n\nstatic const struct file_operations nvdimm_fops = {\n\t.owner = THIS_MODULE,\n\t.open = nd_open,\n\t.unlocked_ioctl = dimm_ioctl,\n\t.compat_ioctl = compat_ptr_ioctl,\n\t.llseek = noop_llseek,\n};\n\nint __init nvdimm_bus_init(void)\n{\n\tint rc;\n\n\trc = bus_register(&nvdimm_bus_type);\n\tif (rc)\n\t\treturn rc;\n\n\trc = register_chrdev(0, \"ndctl\", &nvdimm_bus_fops);\n\tif (rc < 0)\n\t\tgoto err_bus_chrdev;\n\tnvdimm_bus_major = rc;\n\n\trc = register_chrdev(0, \"dimmctl\", &nvdimm_fops);\n\tif (rc < 0)\n\t\tgoto err_dimm_chrdev;\n\tnvdimm_major = rc;\n\n\tnd_class = class_create(\"nd\");\n\tif (IS_ERR(nd_class)) {\n\t\trc = PTR_ERR(nd_class);\n\t\tgoto err_class;\n\t}\n\n\trc = driver_register(&nd_bus_driver.drv);\n\tif (rc)\n\t\tgoto err_nd_bus;\n\n\treturn 0;\n\n err_nd_bus:\n\tclass_destroy(nd_class);\n err_class:\n\tunregister_chrdev(nvdimm_major, \"dimmctl\");\n err_dimm_chrdev:\n\tunregister_chrdev(nvdimm_bus_major, \"ndctl\");\n err_bus_chrdev:\n\tbus_unregister(&nvdimm_bus_type);\n\n\treturn rc;\n}\n\nvoid nvdimm_bus_exit(void)\n{\n\tdriver_unregister(&nd_bus_driver.drv);\n\tclass_destroy(nd_class);\n\tunregister_chrdev(nvdimm_bus_major, \"ndctl\");\n\tunregister_chrdev(nvdimm_major, \"dimmctl\");\n\tbus_unregister(&nvdimm_bus_type);\n\tida_destroy(&nd_ida);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}