{
  "module_name": "badrange.c",
  "hash_id": "f1690d69e5123627f1b1add51b3ea9ea63b5bc3434877143ca9f1578c0e31bc0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/nvdimm/badrange.c",
  "human_readable_source": "\n \n#include <linux/libnvdimm.h>\n#include <linux/badblocks.h>\n#include <linux/export.h>\n#include <linux/module.h>\n#include <linux/blkdev.h>\n#include <linux/device.h>\n#include <linux/ctype.h>\n#include <linux/ndctl.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n#include <linux/io.h>\n#include \"nd-core.h\"\n#include \"nd.h\"\n\nvoid badrange_init(struct badrange *badrange)\n{\n\tINIT_LIST_HEAD(&badrange->list);\n\tspin_lock_init(&badrange->lock);\n}\nEXPORT_SYMBOL_GPL(badrange_init);\n\nstatic void append_badrange_entry(struct badrange *badrange,\n\t\tstruct badrange_entry *bre, u64 addr, u64 length)\n{\n\tlockdep_assert_held(&badrange->lock);\n\tbre->start = addr;\n\tbre->length = length;\n\tlist_add_tail(&bre->list, &badrange->list);\n}\n\nstatic int alloc_and_append_badrange_entry(struct badrange *badrange,\n\t\tu64 addr, u64 length, gfp_t flags)\n{\n\tstruct badrange_entry *bre;\n\n\tbre = kzalloc(sizeof(*bre), flags);\n\tif (!bre)\n\t\treturn -ENOMEM;\n\n\tappend_badrange_entry(badrange, bre, addr, length);\n\treturn 0;\n}\n\nstatic int add_badrange(struct badrange *badrange, u64 addr, u64 length)\n{\n\tstruct badrange_entry *bre, *bre_new;\n\n\tspin_unlock(&badrange->lock);\n\tbre_new = kzalloc(sizeof(*bre_new), GFP_KERNEL);\n\tspin_lock(&badrange->lock);\n\n\tif (list_empty(&badrange->list)) {\n\t\tif (!bre_new)\n\t\t\treturn -ENOMEM;\n\t\tappend_badrange_entry(badrange, bre_new, addr, length);\n\t\treturn 0;\n\t}\n\n\t \n\tlist_for_each_entry(bre, &badrange->list, list)\n\t\tif (bre->start == addr) {\n\t\t\t \n\t\t\tif (bre->length != length)\n\t\t\t\tbre->length = length;\n\t\t\tkfree(bre_new);\n\t\t\treturn 0;\n\t\t}\n\n\t \n\tif (!bre_new)\n\t\treturn -ENOMEM;\n\tappend_badrange_entry(badrange, bre_new, addr, length);\n\n\treturn 0;\n}\n\nint badrange_add(struct badrange *badrange, u64 addr, u64 length)\n{\n\tint rc;\n\n\tspin_lock(&badrange->lock);\n\trc = add_badrange(badrange, addr, length);\n\tspin_unlock(&badrange->lock);\n\n\treturn rc;\n}\nEXPORT_SYMBOL_GPL(badrange_add);\n\nvoid badrange_forget(struct badrange *badrange, phys_addr_t start,\n\t\tunsigned int len)\n{\n\tstruct list_head *badrange_list = &badrange->list;\n\tu64 clr_end = start + len - 1;\n\tstruct badrange_entry *bre, *next;\n\n\tspin_lock(&badrange->lock);\n\n\t \n\n\tlist_for_each_entry_safe(bre, next, badrange_list, list) {\n\t\tu64 bre_end = bre->start + bre->length - 1;\n\n\t\t \n\t\tif (bre_end < start)\n\t\t\tcontinue;\n\t\tif (bre->start >  clr_end)\n\t\t\tcontinue;\n\t\t \n\t\tif ((bre->start >= start) && (bre_end <= clr_end)) {\n\t\t\tlist_del(&bre->list);\n\t\t\tkfree(bre);\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tif ((start <= bre->start) && (clr_end > bre->start)) {\n\t\t\tbre->length -= clr_end - bre->start + 1;\n\t\t\tbre->start = clr_end + 1;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tif ((bre->start < start) && (bre_end <= clr_end)) {\n\t\t\t \n\t\t\tbre->length = start - bre->start;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tif ((bre->start < start) && (bre_end > clr_end)) {\n\t\t\tu64 new_start = clr_end + 1;\n\t\t\tu64 new_len = bre_end - new_start + 1;\n\n\t\t\t \n\t\t\talloc_and_append_badrange_entry(badrange, new_start,\n\t\t\t\t\tnew_len, GFP_NOWAIT);\n\t\t\t \n\t\t\tbre->length = start - bre->start;\n\t\t\tcontinue;\n\t\t}\n\t}\n\tspin_unlock(&badrange->lock);\n}\nEXPORT_SYMBOL_GPL(badrange_forget);\n\nstatic void set_badblock(struct badblocks *bb, sector_t s, int num)\n{\n\tdev_dbg(bb->dev, \"Found a bad range (0x%llx, 0x%llx)\\n\",\n\t\t\t(u64) s * 512, (u64) num * 512);\n\t \n\tif (badblocks_set(bb, s, num, 1))\n\t\tdev_info_once(bb->dev, \"%s: failed for sector %llx\\n\",\n\t\t\t\t__func__, (u64) s);\n}\n\n \nstatic void __add_badblock_range(struct badblocks *bb, u64 ns_offset, u64 len)\n{\n\tconst unsigned int sector_size = 512;\n\tsector_t start_sector, end_sector;\n\tu64 num_sectors;\n\tu32 rem;\n\n\tstart_sector = div_u64(ns_offset, sector_size);\n\tend_sector = div_u64_rem(ns_offset + len, sector_size, &rem);\n\tif (rem)\n\t\tend_sector++;\n\tnum_sectors = end_sector - start_sector;\n\n\tif (unlikely(num_sectors > (u64)INT_MAX)) {\n\t\tu64 remaining = num_sectors;\n\t\tsector_t s = start_sector;\n\n\t\twhile (remaining) {\n\t\t\tint done = min_t(u64, remaining, INT_MAX);\n\n\t\t\tset_badblock(bb, s, done);\n\t\t\tremaining -= done;\n\t\t\ts += done;\n\t\t}\n\t} else\n\t\tset_badblock(bb, start_sector, num_sectors);\n}\n\nstatic void badblocks_populate(struct badrange *badrange,\n\t\tstruct badblocks *bb, const struct range *range)\n{\n\tstruct badrange_entry *bre;\n\n\tif (list_empty(&badrange->list))\n\t\treturn;\n\n\tlist_for_each_entry(bre, &badrange->list, list) {\n\t\tu64 bre_end = bre->start + bre->length - 1;\n\n\t\t \n\t\tif (bre_end < range->start)\n\t\t\tcontinue;\n\t\tif (bre->start > range->end)\n\t\t\tcontinue;\n\t\t \n\t\tif (bre->start >= range->start) {\n\t\t\tu64 start = bre->start;\n\t\t\tu64 len;\n\n\t\t\tif (bre_end <= range->end)\n\t\t\t\tlen = bre->length;\n\t\t\telse\n\t\t\t\tlen = range->start + range_len(range)\n\t\t\t\t\t- bre->start;\n\t\t\t__add_badblock_range(bb, start - range->start, len);\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tif (bre->start < range->start) {\n\t\t\tu64 len;\n\n\t\t\tif (bre_end < range->end)\n\t\t\t\tlen = bre->start + bre->length - range->start;\n\t\t\telse\n\t\t\t\tlen = range_len(range);\n\t\t\t__add_badblock_range(bb, 0, len);\n\t\t}\n\t}\n}\n\n \nvoid nvdimm_badblocks_populate(struct nd_region *nd_region,\n\t\tstruct badblocks *bb, const struct range *range)\n{\n\tstruct nvdimm_bus *nvdimm_bus;\n\n\tif (!is_memory(&nd_region->dev)) {\n\t\tdev_WARN_ONCE(&nd_region->dev, 1,\n\t\t\t\t\"%s only valid for pmem regions\\n\", __func__);\n\t\treturn;\n\t}\n\tnvdimm_bus = walk_to_nvdimm_bus(&nd_region->dev);\n\n\tnvdimm_bus_lock(&nvdimm_bus->dev);\n\tbadblocks_populate(&nvdimm_bus->badrange, bb, range);\n\tnvdimm_bus_unlock(&nvdimm_bus->dev);\n}\nEXPORT_SYMBOL_GPL(nvdimm_badblocks_populate);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}