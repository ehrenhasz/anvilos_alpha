{
  "module_name": "iommu.h",
  "hash_id": "477a44cb6e2c2a248dd4cf44d06001f8a94cb74552f2a4889fe15ba8e8c09bff",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/intel/iommu.h",
  "human_readable_source": " \n \n\n#ifndef _INTEL_IOMMU_H_\n#define _INTEL_IOMMU_H_\n\n#include <linux/types.h>\n#include <linux/iova.h>\n#include <linux/io.h>\n#include <linux/idr.h>\n#include <linux/mmu_notifier.h>\n#include <linux/list.h>\n#include <linux/iommu.h>\n#include <linux/io-64-nonatomic-lo-hi.h>\n#include <linux/dmar.h>\n#include <linux/bitfield.h>\n#include <linux/xarray.h>\n#include <linux/perf_event.h>\n\n#include <asm/cacheflush.h>\n#include <asm/iommu.h>\n\n \n#define VTD_PAGE_SHIFT\t\t(12)\n#define VTD_PAGE_SIZE\t\t(1UL << VTD_PAGE_SHIFT)\n#define VTD_PAGE_MASK\t\t(((u64)-1) << VTD_PAGE_SHIFT)\n#define VTD_PAGE_ALIGN(addr)\t(((addr) + VTD_PAGE_SIZE - 1) & VTD_PAGE_MASK)\n\n#define VTD_STRIDE_SHIFT        (9)\n#define VTD_STRIDE_MASK         (((u64)-1) << VTD_STRIDE_SHIFT)\n\n#define DMA_PTE_READ\t\tBIT_ULL(0)\n#define DMA_PTE_WRITE\t\tBIT_ULL(1)\n#define DMA_PTE_LARGE_PAGE\tBIT_ULL(7)\n#define DMA_PTE_SNP\t\tBIT_ULL(11)\n\n#define DMA_FL_PTE_PRESENT\tBIT_ULL(0)\n#define DMA_FL_PTE_US\t\tBIT_ULL(2)\n#define DMA_FL_PTE_ACCESS\tBIT_ULL(5)\n#define DMA_FL_PTE_DIRTY\tBIT_ULL(6)\n#define DMA_FL_PTE_XD\t\tBIT_ULL(63)\n\n#define ADDR_WIDTH_5LEVEL\t(57)\n#define ADDR_WIDTH_4LEVEL\t(48)\n\n#define CONTEXT_TT_MULTI_LEVEL\t0\n#define CONTEXT_TT_DEV_IOTLB\t1\n#define CONTEXT_TT_PASS_THROUGH 2\n#define CONTEXT_PASIDE\t\tBIT_ULL(3)\n\n \n#define\tDMAR_VER_REG\t0x0\t \n#define\tDMAR_CAP_REG\t0x8\t \n#define\tDMAR_ECAP_REG\t0x10\t \n#define\tDMAR_GCMD_REG\t0x18\t \n#define\tDMAR_GSTS_REG\t0x1c\t \n#define\tDMAR_RTADDR_REG\t0x20\t \n#define\tDMAR_CCMD_REG\t0x28\t \n#define\tDMAR_FSTS_REG\t0x34\t \n#define\tDMAR_FECTL_REG\t0x38\t \n#define\tDMAR_FEDATA_REG\t0x3c\t \n#define\tDMAR_FEADDR_REG\t0x40\t \n#define\tDMAR_FEUADDR_REG 0x44\t \n#define\tDMAR_AFLOG_REG\t0x58\t \n#define\tDMAR_PMEN_REG\t0x64\t \n#define\tDMAR_PLMBASE_REG 0x68\t \n#define\tDMAR_PLMLIMIT_REG 0x6c\t \n#define\tDMAR_PHMBASE_REG 0x70\t \n#define\tDMAR_PHMLIMIT_REG 0x78\t \n#define DMAR_IQH_REG\t0x80\t \n#define DMAR_IQT_REG\t0x88\t \n#define DMAR_IQ_SHIFT\t4\t \n#define DMAR_IQA_REG\t0x90\t \n#define DMAR_ICS_REG\t0x9c\t \n#define DMAR_IQER_REG\t0xb0\t \n#define DMAR_IRTA_REG\t0xb8     \n#define DMAR_PQH_REG\t0xc0\t \n#define DMAR_PQT_REG\t0xc8\t \n#define DMAR_PQA_REG\t0xd0\t \n#define DMAR_PRS_REG\t0xdc\t \n#define DMAR_PECTL_REG\t0xe0\t \n#define\tDMAR_PEDATA_REG\t0xe4\t \n#define\tDMAR_PEADDR_REG\t0xe8\t \n#define\tDMAR_PEUADDR_REG 0xec\t \n#define DMAR_MTRRCAP_REG 0x100\t \n#define DMAR_MTRRDEF_REG 0x108\t \n#define DMAR_MTRR_FIX64K_00000_REG 0x120  \n#define DMAR_MTRR_FIX16K_80000_REG 0x128\n#define DMAR_MTRR_FIX16K_A0000_REG 0x130\n#define DMAR_MTRR_FIX4K_C0000_REG 0x138\n#define DMAR_MTRR_FIX4K_C8000_REG 0x140\n#define DMAR_MTRR_FIX4K_D0000_REG 0x148\n#define DMAR_MTRR_FIX4K_D8000_REG 0x150\n#define DMAR_MTRR_FIX4K_E0000_REG 0x158\n#define DMAR_MTRR_FIX4K_E8000_REG 0x160\n#define DMAR_MTRR_FIX4K_F0000_REG 0x168\n#define DMAR_MTRR_FIX4K_F8000_REG 0x170\n#define DMAR_MTRR_PHYSBASE0_REG 0x180  \n#define DMAR_MTRR_PHYSMASK0_REG 0x188\n#define DMAR_MTRR_PHYSBASE1_REG 0x190\n#define DMAR_MTRR_PHYSMASK1_REG 0x198\n#define DMAR_MTRR_PHYSBASE2_REG 0x1a0\n#define DMAR_MTRR_PHYSMASK2_REG 0x1a8\n#define DMAR_MTRR_PHYSBASE3_REG 0x1b0\n#define DMAR_MTRR_PHYSMASK3_REG 0x1b8\n#define DMAR_MTRR_PHYSBASE4_REG 0x1c0\n#define DMAR_MTRR_PHYSMASK4_REG 0x1c8\n#define DMAR_MTRR_PHYSBASE5_REG 0x1d0\n#define DMAR_MTRR_PHYSMASK5_REG 0x1d8\n#define DMAR_MTRR_PHYSBASE6_REG 0x1e0\n#define DMAR_MTRR_PHYSMASK6_REG 0x1e8\n#define DMAR_MTRR_PHYSBASE7_REG 0x1f0\n#define DMAR_MTRR_PHYSMASK7_REG 0x1f8\n#define DMAR_MTRR_PHYSBASE8_REG 0x200\n#define DMAR_MTRR_PHYSMASK8_REG 0x208\n#define DMAR_MTRR_PHYSBASE9_REG 0x210\n#define DMAR_MTRR_PHYSMASK9_REG 0x218\n#define DMAR_PERFCAP_REG\t0x300\n#define DMAR_PERFCFGOFF_REG\t0x310\n#define DMAR_PERFOVFOFF_REG\t0x318\n#define DMAR_PERFCNTROFF_REG\t0x31c\n#define DMAR_PERFINTRSTS_REG\t0x324\n#define DMAR_PERFINTRCTL_REG\t0x328\n#define DMAR_PERFEVNTCAP_REG\t0x380\n#define DMAR_ECMD_REG\t\t0x400\n#define DMAR_ECEO_REG\t\t0x408\n#define DMAR_ECRSP_REG\t\t0x410\n#define DMAR_ECCAP_REG\t\t0x430\n#define DMAR_VCCAP_REG\t\t0xe30  \n#define DMAR_VCMD_REG\t\t0xe00  \n#define DMAR_VCRSP_REG\t\t0xe10  \n\n#define DMAR_IQER_REG_IQEI(reg)\t\tFIELD_GET(GENMASK_ULL(3, 0), reg)\n#define DMAR_IQER_REG_ITESID(reg)\tFIELD_GET(GENMASK_ULL(47, 32), reg)\n#define DMAR_IQER_REG_ICESID(reg)\tFIELD_GET(GENMASK_ULL(63, 48), reg)\n\n#define OFFSET_STRIDE\t\t(9)\n\n#define dmar_readq(a) readq(a)\n#define dmar_writeq(a,v) writeq(v,a)\n#define dmar_readl(a) readl(a)\n#define dmar_writel(a, v) writel(v, a)\n\n#define DMAR_VER_MAJOR(v)\t\t(((v) & 0xf0) >> 4)\n#define DMAR_VER_MINOR(v)\t\t((v) & 0x0f)\n\n \n#define cap_esrtps(c)\t\t(((c) >> 63) & 1)\n#define cap_esirtps(c)\t\t(((c) >> 62) & 1)\n#define cap_ecmds(c)\t\t(((c) >> 61) & 1)\n#define cap_fl5lp_support(c)\t(((c) >> 60) & 1)\n#define cap_pi_support(c)\t(((c) >> 59) & 1)\n#define cap_fl1gp_support(c)\t(((c) >> 56) & 1)\n#define cap_read_drain(c)\t(((c) >> 55) & 1)\n#define cap_write_drain(c)\t(((c) >> 54) & 1)\n#define cap_max_amask_val(c)\t(((c) >> 48) & 0x3f)\n#define cap_num_fault_regs(c)\t((((c) >> 40) & 0xff) + 1)\n#define cap_pgsel_inv(c)\t(((c) >> 39) & 1)\n\n#define cap_super_page_val(c)\t(((c) >> 34) & 0xf)\n#define cap_super_offset(c)\t(((find_first_bit(&cap_super_page_val(c), 4)) \\\n\t\t\t\t\t* OFFSET_STRIDE) + 21)\n\n#define cap_fault_reg_offset(c)\t((((c) >> 24) & 0x3ff) * 16)\n#define cap_max_fault_reg_offset(c) \\\n\t(cap_fault_reg_offset(c) + cap_num_fault_regs(c) * 16)\n\n#define cap_zlr(c)\t\t(((c) >> 22) & 1)\n#define cap_isoch(c)\t\t(((c) >> 23) & 1)\n#define cap_mgaw(c)\t\t((((c) >> 16) & 0x3f) + 1)\n#define cap_sagaw(c)\t\t(((c) >> 8) & 0x1f)\n#define cap_caching_mode(c)\t(((c) >> 7) & 1)\n#define cap_phmr(c)\t\t(((c) >> 6) & 1)\n#define cap_plmr(c)\t\t(((c) >> 5) & 1)\n#define cap_rwbf(c)\t\t(((c) >> 4) & 1)\n#define cap_afl(c)\t\t(((c) >> 3) & 1)\n#define cap_ndoms(c)\t\t(((unsigned long)1) << (4 + 2 * ((c) & 0x7)))\n \n\n#define ecap_pms(e)\t\t(((e) >> 51) & 0x1)\n#define ecap_rps(e)\t\t(((e) >> 49) & 0x1)\n#define ecap_smpwc(e)\t\t(((e) >> 48) & 0x1)\n#define ecap_flts(e)\t\t(((e) >> 47) & 0x1)\n#define ecap_slts(e)\t\t(((e) >> 46) & 0x1)\n#define ecap_slads(e)\t\t(((e) >> 45) & 0x1)\n#define ecap_smts(e)\t\t(((e) >> 43) & 0x1)\n#define ecap_dit(e)\t\t(((e) >> 41) & 0x1)\n#define ecap_pds(e)\t\t(((e) >> 42) & 0x1)\n#define ecap_pasid(e)\t\t(((e) >> 40) & 0x1)\n#define ecap_pss(e)\t\t(((e) >> 35) & 0x1f)\n#define ecap_eafs(e)\t\t(((e) >> 34) & 0x1)\n#define ecap_nwfs(e)\t\t(((e) >> 33) & 0x1)\n#define ecap_srs(e)\t\t(((e) >> 31) & 0x1)\n#define ecap_ers(e)\t\t(((e) >> 30) & 0x1)\n#define ecap_prs(e)\t\t(((e) >> 29) & 0x1)\n#define ecap_broken_pasid(e)\t(((e) >> 28) & 0x1)\n#define ecap_dis(e)\t\t(((e) >> 27) & 0x1)\n#define ecap_nest(e)\t\t(((e) >> 26) & 0x1)\n#define ecap_mts(e)\t\t(((e) >> 25) & 0x1)\n#define ecap_iotlb_offset(e) \t((((e) >> 8) & 0x3ff) * 16)\n#define ecap_max_iotlb_offset(e) (ecap_iotlb_offset(e) + 16)\n#define ecap_coherent(e)\t((e) & 0x1)\n#define ecap_qis(e)\t\t((e) & 0x2)\n#define ecap_pass_through(e)\t(((e) >> 6) & 0x1)\n#define ecap_eim_support(e)\t(((e) >> 4) & 0x1)\n#define ecap_ir_support(e)\t(((e) >> 3) & 0x1)\n#define ecap_dev_iotlb_support(e)\t(((e) >> 2) & 0x1)\n#define ecap_max_handle_mask(e) (((e) >> 20) & 0xf)\n#define ecap_sc_support(e)\t(((e) >> 7) & 0x1)  \n\n \n#define pcap_num_cntr(p)\t((p) & 0xffff)\n#define pcap_cntr_width(p)\t(((p) >> 16) & 0x7f)\n#define pcap_num_event_group(p)\t(((p) >> 24) & 0x1f)\n#define pcap_filters_mask(p)\t(((p) >> 32) & 0x1f)\n#define pcap_interrupt(p)\t(((p) >> 50) & 0x1)\n \n#define pcap_cntr_stride(p)\t(1ULL << ((((p) >> 52) & 0x7) + 10))\n\n \n#define pecap_es(p)\t\t((p) & 0xfffffff)\n\n \n#define vccap_pasid(v)\t\t(((v) & DMA_VCS_PAS))  \n\n \n#define DMA_TLB_FLUSH_GRANU_OFFSET  60\n#define DMA_TLB_GLOBAL_FLUSH (((u64)1) << 60)\n#define DMA_TLB_DSI_FLUSH (((u64)2) << 60)\n#define DMA_TLB_PSI_FLUSH (((u64)3) << 60)\n#define DMA_TLB_IIRG(type) ((type >> 60) & 3)\n#define DMA_TLB_IAIG(val) (((val) >> 57) & 3)\n#define DMA_TLB_READ_DRAIN (((u64)1) << 49)\n#define DMA_TLB_WRITE_DRAIN (((u64)1) << 48)\n#define DMA_TLB_DID(id)\t(((u64)((id) & 0xffff)) << 32)\n#define DMA_TLB_IVT (((u64)1) << 63)\n#define DMA_TLB_IH_NONLEAF (((u64)1) << 6)\n#define DMA_TLB_MAX_SIZE (0x3f)\n\n \n#define DMA_CCMD_INVL_GRANU_OFFSET  61\n#define DMA_ID_TLB_GLOBAL_FLUSH\t(((u64)1) << 4)\n#define DMA_ID_TLB_DSI_FLUSH\t(((u64)2) << 4)\n#define DMA_ID_TLB_PSI_FLUSH\t(((u64)3) << 4)\n#define DMA_ID_TLB_READ_DRAIN\t(((u64)1) << 7)\n#define DMA_ID_TLB_WRITE_DRAIN\t(((u64)1) << 6)\n#define DMA_ID_TLB_DID(id)\t(((u64)((id & 0xffff) << 16)))\n#define DMA_ID_TLB_IH_NONLEAF\t(((u64)1) << 6)\n#define DMA_ID_TLB_ADDR(addr)\t(addr)\n#define DMA_ID_TLB_ADDR_MASK(mask)\t(mask)\n\n \n#define DMA_PMEN_EPM (((u32)1)<<31)\n#define DMA_PMEN_PRS (((u32)1)<<0)\n\n \n#define DMA_GCMD_TE (((u32)1) << 31)\n#define DMA_GCMD_SRTP (((u32)1) << 30)\n#define DMA_GCMD_SFL (((u32)1) << 29)\n#define DMA_GCMD_EAFL (((u32)1) << 28)\n#define DMA_GCMD_WBF (((u32)1) << 27)\n#define DMA_GCMD_QIE (((u32)1) << 26)\n#define DMA_GCMD_SIRTP (((u32)1) << 24)\n#define DMA_GCMD_IRE (((u32) 1) << 25)\n#define DMA_GCMD_CFI (((u32) 1) << 23)\n\n \n#define DMA_GSTS_TES (((u32)1) << 31)\n#define DMA_GSTS_RTPS (((u32)1) << 30)\n#define DMA_GSTS_FLS (((u32)1) << 29)\n#define DMA_GSTS_AFLS (((u32)1) << 28)\n#define DMA_GSTS_WBFS (((u32)1) << 27)\n#define DMA_GSTS_QIES (((u32)1) << 26)\n#define DMA_GSTS_IRTPS (((u32)1) << 24)\n#define DMA_GSTS_IRES (((u32)1) << 25)\n#define DMA_GSTS_CFIS (((u32)1) << 23)\n\n \n#define DMA_RTADDR_SMT (((u64)1) << 10)\n\n \n#define DMA_CCMD_ICC (((u64)1) << 63)\n#define DMA_CCMD_GLOBAL_INVL (((u64)1) << 61)\n#define DMA_CCMD_DOMAIN_INVL (((u64)2) << 61)\n#define DMA_CCMD_DEVICE_INVL (((u64)3) << 61)\n#define DMA_CCMD_FM(m) (((u64)((m) & 0x3)) << 32)\n#define DMA_CCMD_MASK_NOBIT 0\n#define DMA_CCMD_MASK_1BIT 1\n#define DMA_CCMD_MASK_2BIT 2\n#define DMA_CCMD_MASK_3BIT 3\n#define DMA_CCMD_SID(s) (((u64)((s) & 0xffff)) << 16)\n#define DMA_CCMD_DID(d) ((u64)((d) & 0xffff))\n\n \n#define DMA_MAX_NUM_ECMD\t\t256\n#define DMA_MAX_NUM_ECMDCAP\t\t(DMA_MAX_NUM_ECMD / 64)\n#define DMA_ECMD_REG_STEP\t\t8\n#define DMA_ECMD_ENABLE\t\t\t0xf0\n#define DMA_ECMD_DISABLE\t\t0xf1\n#define DMA_ECMD_FREEZE\t\t\t0xf4\n#define DMA_ECMD_UNFREEZE\t\t0xf5\n#define DMA_ECMD_OA_SHIFT\t\t16\n#define DMA_ECMD_ECRSP_IP\t\t0x1\n#define DMA_ECMD_ECCAP3\t\t\t3\n#define DMA_ECMD_ECCAP3_ECNTS\t\tBIT_ULL(48)\n#define DMA_ECMD_ECCAP3_DCNTS\t\tBIT_ULL(49)\n#define DMA_ECMD_ECCAP3_FCNTS\t\tBIT_ULL(52)\n#define DMA_ECMD_ECCAP3_UFCNTS\t\tBIT_ULL(53)\n#define DMA_ECMD_ECCAP3_ESSENTIAL\t(DMA_ECMD_ECCAP3_ECNTS |\t\\\n\t\t\t\t\t DMA_ECMD_ECCAP3_DCNTS |\t\\\n\t\t\t\t\t DMA_ECMD_ECCAP3_FCNTS |\t\\\n\t\t\t\t\t DMA_ECMD_ECCAP3_UFCNTS)\n\n \n#define DMA_FECTL_IM (((u32)1) << 31)\n\n \n#define DMA_FSTS_PFO (1 << 0)  \n#define DMA_FSTS_PPF (1 << 1)  \n#define DMA_FSTS_IQE (1 << 4)  \n#define DMA_FSTS_ICE (1 << 5)  \n#define DMA_FSTS_ITE (1 << 6)  \n#define DMA_FSTS_PRO (1 << 7)  \n#define dma_fsts_fault_record_index(s) (((s) >> 8) & 0xff)\n\n \n#define DMA_FRCD_F (((u32)1) << 31)\n#define dma_frcd_type(d) ((d >> 30) & 1)\n#define dma_frcd_fault_reason(c) (c & 0xff)\n#define dma_frcd_source_id(c) (c & 0xffff)\n#define dma_frcd_pasid_value(c) (((c) >> 8) & 0xfffff)\n#define dma_frcd_pasid_present(c) (((c) >> 31) & 1)\n \n#define dma_frcd_page_addr(d) (d & (((u64)-1) << PAGE_SHIFT))\n\n \n#define DMA_PRS_PPR\t((u32)1)\n#define DMA_PRS_PRO\t((u32)2)\n\n#define DMA_VCS_PAS\t((u64)1)\n\n \n#define DMA_PERFINTRSTS_PIS\t((u32)1)\n\n#define IOMMU_WAIT_OP(iommu, offset, op, cond, sts)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tcycles_t start_time = get_cycles();\t\t\t\t\\\n\twhile (1) {\t\t\t\t\t\t\t\\\n\t\tsts = op(iommu->reg + offset);\t\t\t\t\\\n\t\tif (cond)\t\t\t\t\t\t\\\n\t\t\tbreak;\t\t\t\t\t\t\\\n\t\tif (DMAR_OPERATION_TIMEOUT < (get_cycles() - start_time))\\\n\t\t\tpanic(\"DMAR hardware is malfunctioning\\n\");\t\\\n\t\tcpu_relax();\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (0)\n\n#define QI_LENGTH\t256\t \n\nenum {\n\tQI_FREE,\n\tQI_IN_USE,\n\tQI_DONE,\n\tQI_ABORT\n};\n\n#define QI_CC_TYPE\t\t0x1\n#define QI_IOTLB_TYPE\t\t0x2\n#define QI_DIOTLB_TYPE\t\t0x3\n#define QI_IEC_TYPE\t\t0x4\n#define QI_IWD_TYPE\t\t0x5\n#define QI_EIOTLB_TYPE\t\t0x6\n#define QI_PC_TYPE\t\t0x7\n#define QI_DEIOTLB_TYPE\t\t0x8\n#define QI_PGRP_RESP_TYPE\t0x9\n#define QI_PSTRM_RESP_TYPE\t0xa\n\n#define QI_IEC_SELECTIVE\t(((u64)1) << 4)\n#define QI_IEC_IIDEX(idx)\t(((u64)(idx & 0xffff) << 32))\n#define QI_IEC_IM(m)\t\t(((u64)(m & 0x1f) << 27))\n\n#define QI_IWD_STATUS_DATA(d)\t(((u64)d) << 32)\n#define QI_IWD_STATUS_WRITE\t(((u64)1) << 5)\n#define QI_IWD_FENCE\t\t(((u64)1) << 6)\n#define QI_IWD_PRQ_DRAIN\t(((u64)1) << 7)\n\n#define QI_IOTLB_DID(did) \t(((u64)did) << 16)\n#define QI_IOTLB_DR(dr) \t(((u64)dr) << 7)\n#define QI_IOTLB_DW(dw) \t(((u64)dw) << 6)\n#define QI_IOTLB_GRAN(gran) \t(((u64)gran) >> (DMA_TLB_FLUSH_GRANU_OFFSET-4))\n#define QI_IOTLB_ADDR(addr)\t(((u64)addr) & VTD_PAGE_MASK)\n#define QI_IOTLB_IH(ih)\t\t(((u64)ih) << 6)\n#define QI_IOTLB_AM(am)\t\t(((u8)am) & 0x3f)\n\n#define QI_CC_FM(fm)\t\t(((u64)fm) << 48)\n#define QI_CC_SID(sid)\t\t(((u64)sid) << 32)\n#define QI_CC_DID(did)\t\t(((u64)did) << 16)\n#define QI_CC_GRAN(gran)\t(((u64)gran) >> (DMA_CCMD_INVL_GRANU_OFFSET-4))\n\n#define QI_DEV_IOTLB_SID(sid)\t((u64)((sid) & 0xffff) << 32)\n#define QI_DEV_IOTLB_QDEP(qdep)\t(((qdep) & 0x1f) << 16)\n#define QI_DEV_IOTLB_ADDR(addr)\t((u64)(addr) & VTD_PAGE_MASK)\n#define QI_DEV_IOTLB_PFSID(pfsid) (((u64)(pfsid & 0xf) << 12) | \\\n\t\t\t\t   ((u64)((pfsid >> 4) & 0xfff) << 52))\n#define QI_DEV_IOTLB_SIZE\t1\n#define QI_DEV_IOTLB_MAX_INVS\t32\n\n#define QI_PC_PASID(pasid)\t(((u64)pasid) << 32)\n#define QI_PC_DID(did)\t\t(((u64)did) << 16)\n#define QI_PC_GRAN(gran)\t(((u64)gran) << 4)\n\n \n#define QI_PC_ALL_PASIDS\t0\n#define QI_PC_PASID_SEL\t\t1\n#define QI_PC_GLOBAL\t\t3\n\n#define QI_EIOTLB_ADDR(addr)\t((u64)(addr) & VTD_PAGE_MASK)\n#define QI_EIOTLB_IH(ih)\t(((u64)ih) << 6)\n#define QI_EIOTLB_AM(am)\t(((u64)am) & 0x3f)\n#define QI_EIOTLB_PASID(pasid) \t(((u64)pasid) << 32)\n#define QI_EIOTLB_DID(did)\t(((u64)did) << 16)\n#define QI_EIOTLB_GRAN(gran) \t(((u64)gran) << 4)\n\n \n#define QI_DEV_IOTLB_GRAN_ALL\t\t1\n#define QI_DEV_IOTLB_GRAN_PASID_SEL\t0\n\n#define QI_DEV_EIOTLB_ADDR(a)\t((u64)(a) & VTD_PAGE_MASK)\n#define QI_DEV_EIOTLB_SIZE\t(((u64)1) << 11)\n#define QI_DEV_EIOTLB_PASID(p)\t((u64)((p) & 0xfffff) << 32)\n#define QI_DEV_EIOTLB_SID(sid)\t((u64)((sid) & 0xffff) << 16)\n#define QI_DEV_EIOTLB_QDEP(qd)\t((u64)((qd) & 0x1f) << 4)\n#define QI_DEV_EIOTLB_PFSID(pfsid) (((u64)(pfsid & 0xf) << 12) | \\\n\t\t\t\t    ((u64)((pfsid >> 4) & 0xfff) << 52))\n#define QI_DEV_EIOTLB_MAX_INVS\t32\n\n \n#define QI_PGRP_PASID_P(p)\t(((u64)(p)) << 4)\n#define QI_PGRP_PDP(p)\t\t(((u64)(p)) << 5)\n#define QI_PGRP_RESP_CODE(res)\t(((u64)(res)) << 12)\n#define QI_PGRP_DID(rid)\t(((u64)(rid)) << 16)\n#define QI_PGRP_PASID(pasid)\t(((u64)(pasid)) << 32)\n\n \n#define QI_PGRP_LPIG(x)\t\t(((u64)(x)) << 2)\n#define QI_PGRP_IDX(idx)\t(((u64)(idx)) << 3)\n\n\n#define QI_RESP_SUCCESS\t\t0x0\n#define QI_RESP_INVALID\t\t0x1\n#define QI_RESP_FAILURE\t\t0xf\n\n#define QI_GRAN_NONG_PASID\t\t2\n#define QI_GRAN_PSI_PASID\t\t3\n\n#define qi_shift(iommu)\t\t(DMAR_IQ_SHIFT + !!ecap_smts((iommu)->ecap))\n\nstruct qi_desc {\n\tu64 qw0;\n\tu64 qw1;\n\tu64 qw2;\n\tu64 qw3;\n};\n\nstruct q_inval {\n\traw_spinlock_t  q_lock;\n\tvoid\t\t*desc;           \n\tint             *desc_status;    \n\tint             free_head;       \n\tint             free_tail;       \n\tint             free_cnt;\n};\n\n \n#define PRQ_ORDER\t4\n#define PRQ_RING_MASK\t((0x1000 << PRQ_ORDER) - 0x20)\n#define PRQ_DEPTH\t((0x1000 << PRQ_ORDER) >> 5)\n\nstruct dmar_pci_notify_info;\n\n#ifdef CONFIG_IRQ_REMAP\n \n#define INTR_REMAP_PAGE_ORDER\t8\n#define INTR_REMAP_TABLE_REG_SIZE\t0xf\n#define INTR_REMAP_TABLE_REG_SIZE_MASK  0xf\n\n#define INTR_REMAP_TABLE_ENTRIES\t65536\n\nstruct irq_domain;\n\nstruct ir_table {\n\tstruct irte *base;\n\tunsigned long *bitmap;\n};\n\nvoid intel_irq_remap_add_device(struct dmar_pci_notify_info *info);\n#else\nstatic inline void\nintel_irq_remap_add_device(struct dmar_pci_notify_info *info) { }\n#endif\n\nstruct iommu_flush {\n\tvoid (*flush_context)(struct intel_iommu *iommu, u16 did, u16 sid,\n\t\t\t      u8 fm, u64 type);\n\tvoid (*flush_iotlb)(struct intel_iommu *iommu, u16 did, u64 addr,\n\t\t\t    unsigned int size_order, u64 type);\n};\n\nenum {\n\tSR_DMAR_FECTL_REG,\n\tSR_DMAR_FEDATA_REG,\n\tSR_DMAR_FEADDR_REG,\n\tSR_DMAR_FEUADDR_REG,\n\tMAX_SR_DMAR_REGS\n};\n\n#define VTD_FLAG_TRANS_PRE_ENABLED\t(1 << 0)\n#define VTD_FLAG_IRQ_REMAP_PRE_ENABLED\t(1 << 1)\n#define VTD_FLAG_SVM_CAPABLE\t\t(1 << 2)\n\n#define sm_supported(iommu)\t(intel_iommu_sm && ecap_smts((iommu)->ecap))\n#define pasid_supported(iommu)\t(sm_supported(iommu) &&\t\t\t\\\n\t\t\t\t ecap_pasid((iommu)->ecap))\n\nstruct pasid_entry;\nstruct pasid_state_entry;\nstruct page_req_dsc;\n\n \nstruct root_entry {\n\tu64     lo;\n\tu64     hi;\n};\n\n \nstruct context_entry {\n\tu64 lo;\n\tu64 hi;\n};\n\nstruct iommu_domain_info {\n\tstruct intel_iommu *iommu;\n\tunsigned int refcnt;\t\t \n\tu16 did;\t\t\t \n};\n\nstruct dmar_domain {\n\tint\tnid;\t\t\t \n\tstruct xarray iommu_array;\t \n\n\tu8 has_iotlb_device: 1;\n\tu8 iommu_coherency: 1;\t\t \n\tu8 force_snooping : 1;\t\t \n\tu8 set_pte_snp:1;\n\tu8 use_first_level:1;\t\t \n\tu8 has_mappings:1;\t\t \n\n\tspinlock_t lock;\t\t \n\tstruct list_head devices;\t \n\tstruct list_head dev_pasids;\t \n\n\tstruct dma_pte\t*pgd;\t\t \n\tint\t\tgaw;\t\t \n\n\t \n\tint\t\tagaw;\n\tint\t\tiommu_superpage; \n\tu64\t\tmax_addr;\t \n\n\tstruct iommu_domain domain;\t \n};\n\n \n#define IOMMU_PMU_IDX_MAX\t\t64\n\nstruct iommu_pmu {\n\tstruct intel_iommu\t*iommu;\n\tu32\t\t\tnum_cntr;\t \n\tu32\t\t\tnum_eg;\t\t \n\tu32\t\t\tcntr_width;\t \n\tu32\t\t\tcntr_stride;\t \n\tu32\t\t\tfilter;\t\t \n\tvoid __iomem\t\t*base;\t\t \n\tvoid __iomem\t\t*cfg_reg;\t \n\tvoid __iomem\t\t*cntr_reg;\t \n\tvoid __iomem\t\t*overflow;\t \n\n\tu64\t\t\t*evcap;\t\t \n\tu32\t\t\t**cntr_evcap;\t \n\n\tstruct pmu\t\tpmu;\n\tDECLARE_BITMAP(used_mask, IOMMU_PMU_IDX_MAX);\n\tstruct perf_event\t*event_list[IOMMU_PMU_IDX_MAX];\n\tunsigned char\t\tirq_name[16];\n\tstruct hlist_node\tcpuhp_node;\n\tint\t\t\tcpu;\n};\n\n#define IOMMU_IRQ_ID_OFFSET_PRQ\t\t(DMAR_UNITS_SUPPORTED)\n#define IOMMU_IRQ_ID_OFFSET_PERF\t(2 * DMAR_UNITS_SUPPORTED)\n\nstruct intel_iommu {\n\tvoid __iomem\t*reg;  \n\tu64 \t\treg_phys;  \n\tu64\t\treg_size;  \n\tu64\t\tcap;\n\tu64\t\tecap;\n\tu64\t\tvccap;\n\tu64\t\tecmdcap[DMA_MAX_NUM_ECMDCAP];\n\tu32\t\tgcmd;  \n\traw_spinlock_t\tregister_lock;  \n\tint\t\tseq_id;\t \n\tint\t\tagaw;  \n\tint\t\tmsagaw;  \n\tunsigned int\tirq, pr_irq, perf_irq;\n\tu16\t\tsegment;      \n\tunsigned char \tname[13];     \n\n#ifdef CONFIG_INTEL_IOMMU\n\tunsigned long \t*domain_ids;  \n\tunsigned long\t*copied_tables;  \n\tspinlock_t\tlock;  \n\tstruct root_entry *root_entry;  \n\n\tstruct iommu_flush flush;\n#endif\n#ifdef CONFIG_INTEL_IOMMU_SVM\n\tstruct page_req_dsc *prq;\n\tunsigned char prq_name[16];     \n\tunsigned long prq_seq_number;\n\tstruct completion prq_complete;\n#endif\n\tstruct iopf_queue *iopf_queue;\n\tunsigned char iopfq_name[16];\n\tstruct q_inval  *qi;             \n\tu32 iommu_state[MAX_SR_DMAR_REGS];  \n\n#ifdef CONFIG_IRQ_REMAP\n\tstruct ir_table *ir_table;\t \n\tstruct irq_domain *ir_domain;\n#endif\n\tstruct iommu_device iommu;   \n\tint\t\tnode;\n\tu32\t\tflags;       \n\n\tstruct dmar_drhd_unit *drhd;\n\tvoid *perf_statistic;\n\n\tstruct iommu_pmu *pmu;\n};\n\n \nstruct device_domain_info {\n\tstruct list_head link;\t \n\tu32 segment;\t\t \n\tu8 bus;\t\t\t \n\tu8 devfn;\t\t \n\tu16 pfsid;\t\t \n\tu8 pasid_supported:3;\n\tu8 pasid_enabled:1;\n\tu8 pri_supported:1;\n\tu8 pri_enabled:1;\n\tu8 ats_supported:1;\n\tu8 ats_enabled:1;\n\tu8 dtlb_extra_inval:1;\t \n\tu8 ats_qdep;\n\tstruct device *dev;  \n\tstruct intel_iommu *iommu;  \n\tstruct dmar_domain *domain;  \n\tstruct pasid_table *pasid_table;  \n};\n\nstruct dev_pasid_info {\n\tstruct list_head link_domain;\t \n\tstruct device *dev;\n\tioasid_t pasid;\n};\n\nstatic inline void __iommu_flush_cache(\n\tstruct intel_iommu *iommu, void *addr, int size)\n{\n\tif (!ecap_coherent(iommu->ecap))\n\t\tclflush_cache_range(addr, size);\n}\n\n \nstatic inline struct dmar_domain *to_dmar_domain(struct iommu_domain *dom)\n{\n\treturn container_of(dom, struct dmar_domain, domain);\n}\n\n \nstatic inline u16\ndomain_id_iommu(struct dmar_domain *domain, struct intel_iommu *iommu)\n{\n\tstruct iommu_domain_info *info =\n\t\t\txa_load(&domain->iommu_array, iommu->seq_id);\n\n\treturn info->did;\n}\n\n \nstruct dma_pte {\n\tu64 val;\n};\n\nstatic inline void dma_clear_pte(struct dma_pte *pte)\n{\n\tpte->val = 0;\n}\n\nstatic inline u64 dma_pte_addr(struct dma_pte *pte)\n{\n#ifdef CONFIG_64BIT\n\treturn pte->val & VTD_PAGE_MASK & (~DMA_FL_PTE_XD);\n#else\n\t \n\treturn  __cmpxchg64(&pte->val, 0ULL, 0ULL) &\n\t\t\tVTD_PAGE_MASK & (~DMA_FL_PTE_XD);\n#endif\n}\n\nstatic inline bool dma_pte_present(struct dma_pte *pte)\n{\n\treturn (pte->val & 3) != 0;\n}\n\nstatic inline bool dma_pte_superpage(struct dma_pte *pte)\n{\n\treturn (pte->val & DMA_PTE_LARGE_PAGE);\n}\n\nstatic inline bool first_pte_in_page(struct dma_pte *pte)\n{\n\treturn IS_ALIGNED((unsigned long)pte, VTD_PAGE_SIZE);\n}\n\nstatic inline int nr_pte_to_next_page(struct dma_pte *pte)\n{\n\treturn first_pte_in_page(pte) ? BIT_ULL(VTD_STRIDE_SHIFT) :\n\t\t(struct dma_pte *)ALIGN((unsigned long)pte, VTD_PAGE_SIZE) - pte;\n}\n\nstatic inline bool context_present(struct context_entry *context)\n{\n\treturn (context->lo & 1);\n}\n\nstruct dmar_drhd_unit *dmar_find_matched_drhd_unit(struct pci_dev *dev);\n\nint dmar_enable_qi(struct intel_iommu *iommu);\nvoid dmar_disable_qi(struct intel_iommu *iommu);\nint dmar_reenable_qi(struct intel_iommu *iommu);\nvoid qi_global_iec(struct intel_iommu *iommu);\n\nvoid qi_flush_context(struct intel_iommu *iommu, u16 did,\n\t\t      u16 sid, u8 fm, u64 type);\nvoid qi_flush_iotlb(struct intel_iommu *iommu, u16 did, u64 addr,\n\t\t    unsigned int size_order, u64 type);\nvoid qi_flush_dev_iotlb(struct intel_iommu *iommu, u16 sid, u16 pfsid,\n\t\t\tu16 qdep, u64 addr, unsigned mask);\n\nvoid qi_flush_piotlb(struct intel_iommu *iommu, u16 did, u32 pasid, u64 addr,\n\t\t     unsigned long npages, bool ih);\n\nvoid qi_flush_dev_iotlb_pasid(struct intel_iommu *iommu, u16 sid, u16 pfsid,\n\t\t\t      u32 pasid, u16 qdep, u64 addr,\n\t\t\t      unsigned int size_order);\nvoid quirk_extra_dev_tlb_flush(struct device_domain_info *info,\n\t\t\t       unsigned long address, unsigned long pages,\n\t\t\t       u32 pasid, u16 qdep);\nvoid qi_flush_pasid_cache(struct intel_iommu *iommu, u16 did, u64 granu,\n\t\t\t  u32 pasid);\n\nint qi_submit_sync(struct intel_iommu *iommu, struct qi_desc *desc,\n\t\t   unsigned int count, unsigned long options);\n \n#define QI_OPT_WAIT_DRAIN\t\tBIT(0)\n\nint dmar_ir_support(void);\n\nvoid *alloc_pgtable_page(int node, gfp_t gfp);\nvoid free_pgtable_page(void *vaddr);\nvoid iommu_flush_write_buffer(struct intel_iommu *iommu);\nstruct intel_iommu *device_to_iommu(struct device *dev, u8 *bus, u8 *devfn);\n\n#ifdef CONFIG_INTEL_IOMMU_SVM\nvoid intel_svm_check(struct intel_iommu *iommu);\nint intel_svm_enable_prq(struct intel_iommu *iommu);\nint intel_svm_finish_prq(struct intel_iommu *iommu);\nint intel_svm_page_response(struct device *dev, struct iommu_fault_event *evt,\n\t\t\t    struct iommu_page_response *msg);\nstruct iommu_domain *intel_svm_domain_alloc(void);\nvoid intel_svm_remove_dev_pasid(struct device *dev, ioasid_t pasid);\nvoid intel_drain_pasid_prq(struct device *dev, u32 pasid);\n\nstruct intel_svm_dev {\n\tstruct list_head list;\n\tstruct rcu_head rcu;\n\tstruct device *dev;\n\tstruct intel_iommu *iommu;\n\tu16 did;\n\tu16 sid, qdep;\n};\n\nstruct intel_svm {\n\tstruct mmu_notifier notifier;\n\tstruct mm_struct *mm;\n\tu32 pasid;\n\tstruct list_head devs;\n};\n#else\nstatic inline void intel_svm_check(struct intel_iommu *iommu) {}\nstatic inline void intel_drain_pasid_prq(struct device *dev, u32 pasid) {}\nstatic inline struct iommu_domain *intel_svm_domain_alloc(void)\n{\n\treturn NULL;\n}\n\nstatic inline void intel_svm_remove_dev_pasid(struct device *dev, ioasid_t pasid)\n{\n}\n#endif\n\n#ifdef CONFIG_INTEL_IOMMU_DEBUGFS\nvoid intel_iommu_debugfs_init(void);\n#else\nstatic inline void intel_iommu_debugfs_init(void) {}\n#endif  \n\nextern const struct attribute_group *intel_iommu_groups[];\nstruct context_entry *iommu_context_addr(struct intel_iommu *iommu, u8 bus,\n\t\t\t\t\t u8 devfn, int alloc);\n\nextern const struct iommu_ops intel_iommu_ops;\n\n#ifdef CONFIG_INTEL_IOMMU\nextern int intel_iommu_sm;\nint iommu_calculate_agaw(struct intel_iommu *iommu);\nint iommu_calculate_max_sagaw(struct intel_iommu *iommu);\nint ecmd_submit_sync(struct intel_iommu *iommu, u8 ecmd, u64 oa, u64 ob);\n\nstatic inline bool ecmd_has_pmu_essential(struct intel_iommu *iommu)\n{\n\treturn (iommu->ecmdcap[DMA_ECMD_ECCAP3] & DMA_ECMD_ECCAP3_ESSENTIAL) ==\n\t\tDMA_ECMD_ECCAP3_ESSENTIAL;\n}\n\nextern int dmar_disabled;\nextern int intel_iommu_enabled;\n#else\nstatic inline int iommu_calculate_agaw(struct intel_iommu *iommu)\n{\n\treturn 0;\n}\nstatic inline int iommu_calculate_max_sagaw(struct intel_iommu *iommu)\n{\n\treturn 0;\n}\n#define dmar_disabled\t(1)\n#define intel_iommu_enabled (0)\n#define intel_iommu_sm (0)\n#endif\n\nstatic inline const char *decode_prq_descriptor(char *str, size_t size,\n\t\tu64 dw0, u64 dw1, u64 dw2, u64 dw3)\n{\n\tchar *buf = str;\n\tint bytes;\n\n\tbytes = snprintf(buf, size,\n\t\t\t \"rid=0x%llx addr=0x%llx %c%c%c%c%c pasid=0x%llx index=0x%llx\",\n\t\t\t FIELD_GET(GENMASK_ULL(31, 16), dw0),\n\t\t\t FIELD_GET(GENMASK_ULL(63, 12), dw1),\n\t\t\t dw1 & BIT_ULL(0) ? 'r' : '-',\n\t\t\t dw1 & BIT_ULL(1) ? 'w' : '-',\n\t\t\t dw0 & BIT_ULL(52) ? 'x' : '-',\n\t\t\t dw0 & BIT_ULL(53) ? 'p' : '-',\n\t\t\t dw1 & BIT_ULL(2) ? 'l' : '-',\n\t\t\t FIELD_GET(GENMASK_ULL(51, 32), dw0),\n\t\t\t FIELD_GET(GENMASK_ULL(11, 3), dw1));\n\n\t \n\tif (dw0 & BIT_ULL(9)) {\n\t\tsize -= bytes;\n\t\tbuf += bytes;\n\t\tsnprintf(buf, size, \" private=0x%llx/0x%llx\\n\", dw2, dw3);\n\t}\n\n\treturn str;\n}\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}