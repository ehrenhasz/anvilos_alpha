{
  "module_name": "pasid.c",
  "hash_id": "a121583c2252b0c61dc32d6fd7d86e6a9077adfaf2464dcfee15eb651ff1170b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/intel/pasid.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\t\"DMAR: \" fmt\n\n#include <linux/bitops.h>\n#include <linux/cpufeature.h>\n#include <linux/dmar.h>\n#include <linux/iommu.h>\n#include <linux/memory.h>\n#include <linux/pci.h>\n#include <linux/pci-ats.h>\n#include <linux/spinlock.h>\n\n#include \"iommu.h\"\n#include \"pasid.h\"\n\n \nu32 intel_pasid_max_id = PASID_MAX;\n\nint vcmd_alloc_pasid(struct intel_iommu *iommu, u32 *pasid)\n{\n\tunsigned long flags;\n\tu8 status_code;\n\tint ret = 0;\n\tu64 res;\n\n\traw_spin_lock_irqsave(&iommu->register_lock, flags);\n\tdmar_writeq(iommu->reg + DMAR_VCMD_REG, VCMD_CMD_ALLOC);\n\tIOMMU_WAIT_OP(iommu, DMAR_VCRSP_REG, dmar_readq,\n\t\t      !(res & VCMD_VRSP_IP), res);\n\traw_spin_unlock_irqrestore(&iommu->register_lock, flags);\n\n\tstatus_code = VCMD_VRSP_SC(res);\n\tswitch (status_code) {\n\tcase VCMD_VRSP_SC_SUCCESS:\n\t\t*pasid = VCMD_VRSP_RESULT_PASID(res);\n\t\tbreak;\n\tcase VCMD_VRSP_SC_NO_PASID_AVAIL:\n\t\tpr_info(\"IOMMU: %s: No PASID available\\n\", iommu->name);\n\t\tret = -ENOSPC;\n\t\tbreak;\n\tdefault:\n\t\tret = -ENODEV;\n\t\tpr_warn(\"IOMMU: %s: Unexpected error code %d\\n\",\n\t\t\tiommu->name, status_code);\n\t}\n\n\treturn ret;\n}\n\nvoid vcmd_free_pasid(struct intel_iommu *iommu, u32 pasid)\n{\n\tunsigned long flags;\n\tu8 status_code;\n\tu64 res;\n\n\traw_spin_lock_irqsave(&iommu->register_lock, flags);\n\tdmar_writeq(iommu->reg + DMAR_VCMD_REG,\n\t\t    VCMD_CMD_OPERAND(pasid) | VCMD_CMD_FREE);\n\tIOMMU_WAIT_OP(iommu, DMAR_VCRSP_REG, dmar_readq,\n\t\t      !(res & VCMD_VRSP_IP), res);\n\traw_spin_unlock_irqrestore(&iommu->register_lock, flags);\n\n\tstatus_code = VCMD_VRSP_SC(res);\n\tswitch (status_code) {\n\tcase VCMD_VRSP_SC_SUCCESS:\n\t\tbreak;\n\tcase VCMD_VRSP_SC_INVALID_PASID:\n\t\tpr_info(\"IOMMU: %s: Invalid PASID\\n\", iommu->name);\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"IOMMU: %s: Unexpected error code %d\\n\",\n\t\t\tiommu->name, status_code);\n\t}\n}\n\n \n\n \nint intel_pasid_alloc_table(struct device *dev)\n{\n\tstruct device_domain_info *info;\n\tstruct pasid_table *pasid_table;\n\tstruct page *pages;\n\tu32 max_pasid = 0;\n\tint order, size;\n\n\tmight_sleep();\n\tinfo = dev_iommu_priv_get(dev);\n\tif (WARN_ON(!info || !dev_is_pci(dev)))\n\t\treturn -ENODEV;\n\tif (WARN_ON(info->pasid_table))\n\t\treturn -EEXIST;\n\n\tpasid_table = kzalloc(sizeof(*pasid_table), GFP_KERNEL);\n\tif (!pasid_table)\n\t\treturn -ENOMEM;\n\n\tif (info->pasid_supported)\n\t\tmax_pasid = min_t(u32, pci_max_pasids(to_pci_dev(dev)),\n\t\t\t\t  intel_pasid_max_id);\n\n\tsize = max_pasid >> (PASID_PDE_SHIFT - 3);\n\torder = size ? get_order(size) : 0;\n\tpages = alloc_pages_node(info->iommu->node,\n\t\t\t\t GFP_KERNEL | __GFP_ZERO, order);\n\tif (!pages) {\n\t\tkfree(pasid_table);\n\t\treturn -ENOMEM;\n\t}\n\n\tpasid_table->table = page_address(pages);\n\tpasid_table->order = order;\n\tpasid_table->max_pasid = 1 << (order + PAGE_SHIFT + 3);\n\tinfo->pasid_table = pasid_table;\n\n\tif (!ecap_coherent(info->iommu->ecap))\n\t\tclflush_cache_range(pasid_table->table, (1 << order) * PAGE_SIZE);\n\n\treturn 0;\n}\n\nvoid intel_pasid_free_table(struct device *dev)\n{\n\tstruct device_domain_info *info;\n\tstruct pasid_table *pasid_table;\n\tstruct pasid_dir_entry *dir;\n\tstruct pasid_entry *table;\n\tint i, max_pde;\n\n\tinfo = dev_iommu_priv_get(dev);\n\tif (!info || !dev_is_pci(dev) || !info->pasid_table)\n\t\treturn;\n\n\tpasid_table = info->pasid_table;\n\tinfo->pasid_table = NULL;\n\n\t \n\tdir = pasid_table->table;\n\tmax_pde = pasid_table->max_pasid >> PASID_PDE_SHIFT;\n\tfor (i = 0; i < max_pde; i++) {\n\t\ttable = get_pasid_table_from_pde(&dir[i]);\n\t\tfree_pgtable_page(table);\n\t}\n\n\tfree_pages((unsigned long)pasid_table->table, pasid_table->order);\n\tkfree(pasid_table);\n}\n\nstruct pasid_table *intel_pasid_get_table(struct device *dev)\n{\n\tstruct device_domain_info *info;\n\n\tinfo = dev_iommu_priv_get(dev);\n\tif (!info)\n\t\treturn NULL;\n\n\treturn info->pasid_table;\n}\n\nstatic int intel_pasid_get_dev_max_id(struct device *dev)\n{\n\tstruct device_domain_info *info;\n\n\tinfo = dev_iommu_priv_get(dev);\n\tif (!info || !info->pasid_table)\n\t\treturn 0;\n\n\treturn info->pasid_table->max_pasid;\n}\n\nstatic struct pasid_entry *intel_pasid_get_entry(struct device *dev, u32 pasid)\n{\n\tstruct device_domain_info *info;\n\tstruct pasid_table *pasid_table;\n\tstruct pasid_dir_entry *dir;\n\tstruct pasid_entry *entries;\n\tint dir_index, index;\n\n\tpasid_table = intel_pasid_get_table(dev);\n\tif (WARN_ON(!pasid_table || pasid >= intel_pasid_get_dev_max_id(dev)))\n\t\treturn NULL;\n\n\tdir = pasid_table->table;\n\tinfo = dev_iommu_priv_get(dev);\n\tdir_index = pasid >> PASID_PDE_SHIFT;\n\tindex = pasid & PASID_PTE_MASK;\n\nretry:\n\tentries = get_pasid_table_from_pde(&dir[dir_index]);\n\tif (!entries) {\n\t\tentries = alloc_pgtable_page(info->iommu->node, GFP_ATOMIC);\n\t\tif (!entries)\n\t\t\treturn NULL;\n\n\t\t \n\t\tif (cmpxchg64(&dir[dir_index].val, 0ULL,\n\t\t\t      (u64)virt_to_phys(entries) | PASID_PTE_PRESENT)) {\n\t\t\tfree_pgtable_page(entries);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (!ecap_coherent(info->iommu->ecap)) {\n\t\t\tclflush_cache_range(entries, VTD_PAGE_SIZE);\n\t\t\tclflush_cache_range(&dir[dir_index].val, sizeof(*dir));\n\t\t}\n\t}\n\n\treturn &entries[index];\n}\n\n \nstatic inline void pasid_clear_entry(struct pasid_entry *pe)\n{\n\tWRITE_ONCE(pe->val[0], 0);\n\tWRITE_ONCE(pe->val[1], 0);\n\tWRITE_ONCE(pe->val[2], 0);\n\tWRITE_ONCE(pe->val[3], 0);\n\tWRITE_ONCE(pe->val[4], 0);\n\tWRITE_ONCE(pe->val[5], 0);\n\tWRITE_ONCE(pe->val[6], 0);\n\tWRITE_ONCE(pe->val[7], 0);\n}\n\nstatic inline void pasid_clear_entry_with_fpd(struct pasid_entry *pe)\n{\n\tWRITE_ONCE(pe->val[0], PASID_PTE_FPD);\n\tWRITE_ONCE(pe->val[1], 0);\n\tWRITE_ONCE(pe->val[2], 0);\n\tWRITE_ONCE(pe->val[3], 0);\n\tWRITE_ONCE(pe->val[4], 0);\n\tWRITE_ONCE(pe->val[5], 0);\n\tWRITE_ONCE(pe->val[6], 0);\n\tWRITE_ONCE(pe->val[7], 0);\n}\n\nstatic void\nintel_pasid_clear_entry(struct device *dev, u32 pasid, bool fault_ignore)\n{\n\tstruct pasid_entry *pe;\n\n\tpe = intel_pasid_get_entry(dev, pasid);\n\tif (WARN_ON(!pe))\n\t\treturn;\n\n\tif (fault_ignore && pasid_pte_is_present(pe))\n\t\tpasid_clear_entry_with_fpd(pe);\n\telse\n\t\tpasid_clear_entry(pe);\n}\n\nstatic inline void pasid_set_bits(u64 *ptr, u64 mask, u64 bits)\n{\n\tu64 old;\n\n\told = READ_ONCE(*ptr);\n\tWRITE_ONCE(*ptr, (old & ~mask) | bits);\n}\n\n \nstatic inline void\npasid_set_domain_id(struct pasid_entry *pe, u64 value)\n{\n\tpasid_set_bits(&pe->val[1], GENMASK_ULL(15, 0), value);\n}\n\n \nstatic inline u16\npasid_get_domain_id(struct pasid_entry *pe)\n{\n\treturn (u16)(READ_ONCE(pe->val[1]) & GENMASK_ULL(15, 0));\n}\n\n \nstatic inline void\npasid_set_slptr(struct pasid_entry *pe, u64 value)\n{\n\tpasid_set_bits(&pe->val[0], VTD_PAGE_MASK, value);\n}\n\n \nstatic inline void\npasid_set_address_width(struct pasid_entry *pe, u64 value)\n{\n\tpasid_set_bits(&pe->val[0], GENMASK_ULL(4, 2), value << 2);\n}\n\n \nstatic inline void\npasid_set_translation_type(struct pasid_entry *pe, u64 value)\n{\n\tpasid_set_bits(&pe->val[0], GENMASK_ULL(8, 6), value << 6);\n}\n\n \nstatic inline void pasid_set_fault_enable(struct pasid_entry *pe)\n{\n\tpasid_set_bits(&pe->val[0], 1 << 1, 0);\n}\n\n \nstatic inline void pasid_set_wpe(struct pasid_entry *pe)\n{\n\tpasid_set_bits(&pe->val[2], 1 << 4, 1 << 4);\n}\n\n \nstatic inline void pasid_set_present(struct pasid_entry *pe)\n{\n\tpasid_set_bits(&pe->val[0], 1 << 0, 1);\n}\n\n \nstatic inline void pasid_set_page_snoop(struct pasid_entry *pe, bool value)\n{\n\tpasid_set_bits(&pe->val[1], 1 << 23, value << 23);\n}\n\n \nstatic inline void pasid_set_nxe(struct pasid_entry *pe)\n{\n\tpasid_set_bits(&pe->val[2], 1 << 5, 1 << 5);\n}\n\n \nstatic inline void\npasid_set_pgsnp(struct pasid_entry *pe)\n{\n\tpasid_set_bits(&pe->val[1], 1ULL << 24, 1ULL << 24);\n}\n\n \nstatic inline void\npasid_set_flptr(struct pasid_entry *pe, u64 value)\n{\n\tpasid_set_bits(&pe->val[2], VTD_PAGE_MASK, value);\n}\n\n \nstatic inline void\npasid_set_flpm(struct pasid_entry *pe, u64 value)\n{\n\tpasid_set_bits(&pe->val[2], GENMASK_ULL(3, 2), value << 2);\n}\n\nstatic void\npasid_cache_invalidation_with_pasid(struct intel_iommu *iommu,\n\t\t\t\t    u16 did, u32 pasid)\n{\n\tstruct qi_desc desc;\n\n\tdesc.qw0 = QI_PC_DID(did) | QI_PC_GRAN(QI_PC_PASID_SEL) |\n\t\tQI_PC_PASID(pasid) | QI_PC_TYPE;\n\tdesc.qw1 = 0;\n\tdesc.qw2 = 0;\n\tdesc.qw3 = 0;\n\n\tqi_submit_sync(iommu, &desc, 1, 0);\n}\n\nstatic void\ndevtlb_invalidation_with_pasid(struct intel_iommu *iommu,\n\t\t\t       struct device *dev, u32 pasid)\n{\n\tstruct device_domain_info *info;\n\tu16 sid, qdep, pfsid;\n\n\tinfo = dev_iommu_priv_get(dev);\n\tif (!info || !info->ats_enabled)\n\t\treturn;\n\n\tsid = info->bus << 8 | info->devfn;\n\tqdep = info->ats_qdep;\n\tpfsid = info->pfsid;\n\n\t \n\tif (pasid == IOMMU_NO_PASID)\n\t\tqi_flush_dev_iotlb(iommu, sid, pfsid, qdep, 0, 64 - VTD_PAGE_SHIFT);\n\telse\n\t\tqi_flush_dev_iotlb_pasid(iommu, sid, pfsid, pasid, qdep, 0, 64 - VTD_PAGE_SHIFT);\n}\n\nvoid intel_pasid_tear_down_entry(struct intel_iommu *iommu, struct device *dev,\n\t\t\t\t u32 pasid, bool fault_ignore)\n{\n\tstruct pasid_entry *pte;\n\tu16 did, pgtt;\n\n\tspin_lock(&iommu->lock);\n\tpte = intel_pasid_get_entry(dev, pasid);\n\tif (WARN_ON(!pte) || !pasid_pte_is_present(pte)) {\n\t\tspin_unlock(&iommu->lock);\n\t\treturn;\n\t}\n\n\tdid = pasid_get_domain_id(pte);\n\tpgtt = pasid_pte_get_pgtt(pte);\n\tintel_pasid_clear_entry(dev, pasid, fault_ignore);\n\tspin_unlock(&iommu->lock);\n\n\tif (!ecap_coherent(iommu->ecap))\n\t\tclflush_cache_range(pte, sizeof(*pte));\n\n\tpasid_cache_invalidation_with_pasid(iommu, did, pasid);\n\n\tif (pgtt == PASID_ENTRY_PGTT_PT || pgtt == PASID_ENTRY_PGTT_FL_ONLY)\n\t\tqi_flush_piotlb(iommu, did, pasid, 0, -1, 0);\n\telse\n\t\tiommu->flush.flush_iotlb(iommu, did, 0, 0, DMA_TLB_DSI_FLUSH);\n\n\t \n\tif (!cap_caching_mode(iommu->cap))\n\t\tdevtlb_invalidation_with_pasid(iommu, dev, pasid);\n}\n\n \nstatic void pasid_flush_caches(struct intel_iommu *iommu,\n\t\t\t\tstruct pasid_entry *pte,\n\t\t\t       u32 pasid, u16 did)\n{\n\tif (!ecap_coherent(iommu->ecap))\n\t\tclflush_cache_range(pte, sizeof(*pte));\n\n\tif (cap_caching_mode(iommu->cap)) {\n\t\tpasid_cache_invalidation_with_pasid(iommu, did, pasid);\n\t\tqi_flush_piotlb(iommu, did, pasid, 0, -1, 0);\n\t} else {\n\t\tiommu_flush_write_buffer(iommu);\n\t}\n}\n\n \nint intel_pasid_setup_first_level(struct intel_iommu *iommu,\n\t\t\t\t  struct device *dev, pgd_t *pgd,\n\t\t\t\t  u32 pasid, u16 did, int flags)\n{\n\tstruct pasid_entry *pte;\n\n\tif (!ecap_flts(iommu->ecap)) {\n\t\tpr_err(\"No first level translation support on %s\\n\",\n\t\t       iommu->name);\n\t\treturn -EINVAL;\n\t}\n\n\tif ((flags & PASID_FLAG_FL5LP) && !cap_fl5lp_support(iommu->cap)) {\n\t\tpr_err(\"No 5-level paging support for first-level on %s\\n\",\n\t\t       iommu->name);\n\t\treturn -EINVAL;\n\t}\n\n\tspin_lock(&iommu->lock);\n\tpte = intel_pasid_get_entry(dev, pasid);\n\tif (!pte) {\n\t\tspin_unlock(&iommu->lock);\n\t\treturn -ENODEV;\n\t}\n\n\tif (pasid_pte_is_present(pte)) {\n\t\tspin_unlock(&iommu->lock);\n\t\treturn -EBUSY;\n\t}\n\n\tpasid_clear_entry(pte);\n\n\t \n\tpasid_set_flptr(pte, (u64)__pa(pgd));\n\n\tif (flags & PASID_FLAG_FL5LP)\n\t\tpasid_set_flpm(pte, 1);\n\n\tif (flags & PASID_FLAG_PAGE_SNOOP)\n\t\tpasid_set_pgsnp(pte);\n\n\tpasid_set_domain_id(pte, did);\n\tpasid_set_address_width(pte, iommu->agaw);\n\tpasid_set_page_snoop(pte, !!ecap_smpwc(iommu->ecap));\n\tpasid_set_nxe(pte);\n\n\t \n\tpasid_set_translation_type(pte, PASID_ENTRY_PGTT_FL_ONLY);\n\tpasid_set_present(pte);\n\tspin_unlock(&iommu->lock);\n\n\tpasid_flush_caches(iommu, pte, pasid, did);\n\n\treturn 0;\n}\n\n \nstatic inline int iommu_skip_agaw(struct dmar_domain *domain,\n\t\t\t\t  struct intel_iommu *iommu,\n\t\t\t\t  struct dma_pte **pgd)\n{\n\tint agaw;\n\n\tfor (agaw = domain->agaw; agaw > iommu->agaw; agaw--) {\n\t\t*pgd = phys_to_virt(dma_pte_addr(*pgd));\n\t\tif (!dma_pte_present(*pgd))\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn agaw;\n}\n\n \nint intel_pasid_setup_second_level(struct intel_iommu *iommu,\n\t\t\t\t   struct dmar_domain *domain,\n\t\t\t\t   struct device *dev, u32 pasid)\n{\n\tstruct pasid_entry *pte;\n\tstruct dma_pte *pgd;\n\tu64 pgd_val;\n\tint agaw;\n\tu16 did;\n\n\t \n\tif (!ecap_slts(iommu->ecap)) {\n\t\tpr_err(\"No second level translation support on %s\\n\",\n\t\t       iommu->name);\n\t\treturn -EINVAL;\n\t}\n\n\tpgd = domain->pgd;\n\tagaw = iommu_skip_agaw(domain, iommu, &pgd);\n\tif (agaw < 0) {\n\t\tdev_err(dev, \"Invalid domain page table\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tpgd_val = virt_to_phys(pgd);\n\tdid = domain_id_iommu(domain, iommu);\n\n\tspin_lock(&iommu->lock);\n\tpte = intel_pasid_get_entry(dev, pasid);\n\tif (!pte) {\n\t\tspin_unlock(&iommu->lock);\n\t\treturn -ENODEV;\n\t}\n\n\tif (pasid_pte_is_present(pte)) {\n\t\tspin_unlock(&iommu->lock);\n\t\treturn -EBUSY;\n\t}\n\n\tpasid_clear_entry(pte);\n\tpasid_set_domain_id(pte, did);\n\tpasid_set_slptr(pte, pgd_val);\n\tpasid_set_address_width(pte, agaw);\n\tpasid_set_translation_type(pte, PASID_ENTRY_PGTT_SL_ONLY);\n\tpasid_set_fault_enable(pte);\n\tpasid_set_page_snoop(pte, !!ecap_smpwc(iommu->ecap));\n\n\tpasid_set_present(pte);\n\tspin_unlock(&iommu->lock);\n\n\tpasid_flush_caches(iommu, pte, pasid, did);\n\n\treturn 0;\n}\n\n \nint intel_pasid_setup_pass_through(struct intel_iommu *iommu,\n\t\t\t\t   struct dmar_domain *domain,\n\t\t\t\t   struct device *dev, u32 pasid)\n{\n\tu16 did = FLPT_DEFAULT_DID;\n\tstruct pasid_entry *pte;\n\n\tspin_lock(&iommu->lock);\n\tpte = intel_pasid_get_entry(dev, pasid);\n\tif (!pte) {\n\t\tspin_unlock(&iommu->lock);\n\t\treturn -ENODEV;\n\t}\n\n\tif (pasid_pte_is_present(pte)) {\n\t\tspin_unlock(&iommu->lock);\n\t\treturn -EBUSY;\n\t}\n\n\tpasid_clear_entry(pte);\n\tpasid_set_domain_id(pte, did);\n\tpasid_set_address_width(pte, iommu->agaw);\n\tpasid_set_translation_type(pte, PASID_ENTRY_PGTT_PT);\n\tpasid_set_fault_enable(pte);\n\tpasid_set_page_snoop(pte, !!ecap_smpwc(iommu->ecap));\n\tpasid_set_present(pte);\n\tspin_unlock(&iommu->lock);\n\n\tpasid_flush_caches(iommu, pte, pasid, did);\n\n\treturn 0;\n}\n\n \nvoid intel_pasid_setup_page_snoop_control(struct intel_iommu *iommu,\n\t\t\t\t\t  struct device *dev, u32 pasid)\n{\n\tstruct pasid_entry *pte;\n\tu16 did;\n\n\tspin_lock(&iommu->lock);\n\tpte = intel_pasid_get_entry(dev, pasid);\n\tif (WARN_ON(!pte || !pasid_pte_is_present(pte))) {\n\t\tspin_unlock(&iommu->lock);\n\t\treturn;\n\t}\n\n\tpasid_set_pgsnp(pte);\n\tdid = pasid_get_domain_id(pte);\n\tspin_unlock(&iommu->lock);\n\n\tif (!ecap_coherent(iommu->ecap))\n\t\tclflush_cache_range(pte, sizeof(*pte));\n\n\t \n\tpasid_cache_invalidation_with_pasid(iommu, did, pasid);\n\tqi_flush_piotlb(iommu, did, pasid, 0, -1, 0);\n\n\t \n\tif (!cap_caching_mode(iommu->cap))\n\t\tdevtlb_invalidation_with_pasid(iommu, dev, pasid);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}