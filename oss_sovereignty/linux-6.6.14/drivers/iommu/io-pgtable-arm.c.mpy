{
  "module_name": "io-pgtable-arm.c",
  "hash_id": "b53ef1f9989de83d3e0d0374f4632a1ad5878781a109a70ad276ca0ad528b53e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/io-pgtable-arm.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\t\"arm-lpae io-pgtable: \" fmt\n\n#include <linux/atomic.h>\n#include <linux/bitops.h>\n#include <linux/io-pgtable.h>\n#include <linux/kernel.h>\n#include <linux/sizes.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/dma-mapping.h>\n\n#include <asm/barrier.h>\n\n#include \"io-pgtable-arm.h\"\n\n#define ARM_LPAE_MAX_ADDR_BITS\t\t52\n#define ARM_LPAE_S2_MAX_CONCAT_PAGES\t16\n#define ARM_LPAE_MAX_LEVELS\t\t4\n\n \n#define io_pgtable_to_data(x)\t\t\t\t\t\t\\\n\tcontainer_of((x), struct arm_lpae_io_pgtable, iop)\n\n#define io_pgtable_ops_to_data(x)\t\t\t\t\t\\\n\tio_pgtable_to_data(io_pgtable_ops_to_pgtable(x))\n\n \n#define ARM_LPAE_LVL_SHIFT(l,d)\t\t\t\t\t\t\\\n\t(((ARM_LPAE_MAX_LEVELS - (l)) * (d)->bits_per_level) +\t\t\\\n\tilog2(sizeof(arm_lpae_iopte)))\n\n#define ARM_LPAE_GRANULE(d)\t\t\t\t\t\t\\\n\t(sizeof(arm_lpae_iopte) << (d)->bits_per_level)\n#define ARM_LPAE_PGD_SIZE(d)\t\t\t\t\t\t\\\n\t(sizeof(arm_lpae_iopte) << (d)->pgd_bits)\n\n#define ARM_LPAE_PTES_PER_TABLE(d)\t\t\t\t\t\\\n\t(ARM_LPAE_GRANULE(d) >> ilog2(sizeof(arm_lpae_iopte)))\n\n \n#define ARM_LPAE_PGD_IDX(l,d)\t\t\t\t\t\t\\\n\t((l) == (d)->start_level ? (d)->pgd_bits - (d)->bits_per_level : 0)\n\n#define ARM_LPAE_LVL_IDX(a,l,d)\t\t\t\t\t\t\\\n\t(((u64)(a) >> ARM_LPAE_LVL_SHIFT(l,d)) &\t\t\t\\\n\t ((1 << ((d)->bits_per_level + ARM_LPAE_PGD_IDX(l,d))) - 1))\n\n \n#define ARM_LPAE_BLOCK_SIZE(l,d)\t(1ULL << ARM_LPAE_LVL_SHIFT(l,d))\n\n \n#define ARM_LPAE_PTE_TYPE_SHIFT\t\t0\n#define ARM_LPAE_PTE_TYPE_MASK\t\t0x3\n\n#define ARM_LPAE_PTE_TYPE_BLOCK\t\t1\n#define ARM_LPAE_PTE_TYPE_TABLE\t\t3\n#define ARM_LPAE_PTE_TYPE_PAGE\t\t3\n\n#define ARM_LPAE_PTE_ADDR_MASK\t\tGENMASK_ULL(47,12)\n\n#define ARM_LPAE_PTE_NSTABLE\t\t(((arm_lpae_iopte)1) << 63)\n#define ARM_LPAE_PTE_XN\t\t\t(((arm_lpae_iopte)3) << 53)\n#define ARM_LPAE_PTE_AF\t\t\t(((arm_lpae_iopte)1) << 10)\n#define ARM_LPAE_PTE_SH_NS\t\t(((arm_lpae_iopte)0) << 8)\n#define ARM_LPAE_PTE_SH_OS\t\t(((arm_lpae_iopte)2) << 8)\n#define ARM_LPAE_PTE_SH_IS\t\t(((arm_lpae_iopte)3) << 8)\n#define ARM_LPAE_PTE_NS\t\t\t(((arm_lpae_iopte)1) << 5)\n#define ARM_LPAE_PTE_VALID\t\t(((arm_lpae_iopte)1) << 0)\n\n#define ARM_LPAE_PTE_ATTR_LO_MASK\t(((arm_lpae_iopte)0x3ff) << 2)\n \n#define ARM_LPAE_PTE_ATTR_HI_MASK\t(((arm_lpae_iopte)6) << 52)\n#define ARM_LPAE_PTE_ATTR_MASK\t\t(ARM_LPAE_PTE_ATTR_LO_MASK |\t\\\n\t\t\t\t\t ARM_LPAE_PTE_ATTR_HI_MASK)\n \n#define ARM_LPAE_PTE_SW_SYNC\t\t(((arm_lpae_iopte)1) << 55)\n\n \n#define ARM_LPAE_PTE_AP_UNPRIV\t\t(((arm_lpae_iopte)1) << 6)\n#define ARM_LPAE_PTE_AP_RDONLY\t\t(((arm_lpae_iopte)2) << 6)\n#define ARM_LPAE_PTE_ATTRINDX_SHIFT\t2\n#define ARM_LPAE_PTE_nG\t\t\t(((arm_lpae_iopte)1) << 11)\n\n \n#define ARM_LPAE_PTE_HAP_FAULT\t\t(((arm_lpae_iopte)0) << 6)\n#define ARM_LPAE_PTE_HAP_READ\t\t(((arm_lpae_iopte)1) << 6)\n#define ARM_LPAE_PTE_HAP_WRITE\t\t(((arm_lpae_iopte)2) << 6)\n#define ARM_LPAE_PTE_MEMATTR_OIWB\t(((arm_lpae_iopte)0xf) << 2)\n#define ARM_LPAE_PTE_MEMATTR_NC\t\t(((arm_lpae_iopte)0x5) << 2)\n#define ARM_LPAE_PTE_MEMATTR_DEV\t(((arm_lpae_iopte)0x1) << 2)\n\n \n#define ARM_LPAE_VTCR_SL0_MASK\t\t0x3\n\n#define ARM_LPAE_TCR_T0SZ_SHIFT\t\t0\n\n#define ARM_LPAE_VTCR_PS_SHIFT\t\t16\n#define ARM_LPAE_VTCR_PS_MASK\t\t0x7\n\n#define ARM_LPAE_MAIR_ATTR_SHIFT(n)\t((n) << 3)\n#define ARM_LPAE_MAIR_ATTR_MASK\t\t0xff\n#define ARM_LPAE_MAIR_ATTR_DEVICE\t0x04\n#define ARM_LPAE_MAIR_ATTR_NC\t\t0x44\n#define ARM_LPAE_MAIR_ATTR_INC_OWBRWA\t0xf4\n#define ARM_LPAE_MAIR_ATTR_WBRWA\t0xff\n#define ARM_LPAE_MAIR_ATTR_IDX_NC\t0\n#define ARM_LPAE_MAIR_ATTR_IDX_CACHE\t1\n#define ARM_LPAE_MAIR_ATTR_IDX_DEV\t2\n#define ARM_LPAE_MAIR_ATTR_IDX_INC_OCACHE\t3\n\n#define ARM_MALI_LPAE_TTBR_ADRMODE_TABLE (3u << 0)\n#define ARM_MALI_LPAE_TTBR_READ_INNER\tBIT(2)\n#define ARM_MALI_LPAE_TTBR_SHARE_OUTER\tBIT(4)\n\n#define ARM_MALI_LPAE_MEMATTR_IMP_DEF\t0x88ULL\n#define ARM_MALI_LPAE_MEMATTR_WRITE_ALLOC 0x8DULL\n\n \n#define iopte_deref(pte,d) __va(iopte_to_paddr(pte, d))\n\n#define iopte_type(pte)\t\t\t\t\t\\\n\t(((pte) >> ARM_LPAE_PTE_TYPE_SHIFT) & ARM_LPAE_PTE_TYPE_MASK)\n\n#define iopte_prot(pte)\t((pte) & ARM_LPAE_PTE_ATTR_MASK)\n\nstruct arm_lpae_io_pgtable {\n\tstruct io_pgtable\tiop;\n\n\tint\t\t\tpgd_bits;\n\tint\t\t\tstart_level;\n\tint\t\t\tbits_per_level;\n\n\tvoid\t\t\t*pgd;\n};\n\ntypedef u64 arm_lpae_iopte;\n\nstatic inline bool iopte_leaf(arm_lpae_iopte pte, int lvl,\n\t\t\t      enum io_pgtable_fmt fmt)\n{\n\tif (lvl == (ARM_LPAE_MAX_LEVELS - 1) && fmt != ARM_MALI_LPAE)\n\t\treturn iopte_type(pte) == ARM_LPAE_PTE_TYPE_PAGE;\n\n\treturn iopte_type(pte) == ARM_LPAE_PTE_TYPE_BLOCK;\n}\n\nstatic arm_lpae_iopte paddr_to_iopte(phys_addr_t paddr,\n\t\t\t\t     struct arm_lpae_io_pgtable *data)\n{\n\tarm_lpae_iopte pte = paddr;\n\n\t \n\treturn (pte | (pte >> (48 - 12))) & ARM_LPAE_PTE_ADDR_MASK;\n}\n\nstatic phys_addr_t iopte_to_paddr(arm_lpae_iopte pte,\n\t\t\t\t  struct arm_lpae_io_pgtable *data)\n{\n\tu64 paddr = pte & ARM_LPAE_PTE_ADDR_MASK;\n\n\tif (ARM_LPAE_GRANULE(data) < SZ_64K)\n\t\treturn paddr;\n\n\t \n\treturn (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);\n}\n\nstatic bool selftest_running = false;\n\nstatic dma_addr_t __arm_lpae_dma_addr(void *pages)\n{\n\treturn (dma_addr_t)virt_to_phys(pages);\n}\n\nstatic void *__arm_lpae_alloc_pages(size_t size, gfp_t gfp,\n\t\t\t\t    struct io_pgtable_cfg *cfg)\n{\n\tstruct device *dev = cfg->iommu_dev;\n\tint order = get_order(size);\n\tstruct page *p;\n\tdma_addr_t dma;\n\tvoid *pages;\n\n\tVM_BUG_ON((gfp & __GFP_HIGHMEM));\n\tp = alloc_pages_node(dev_to_node(dev), gfp | __GFP_ZERO, order);\n\tif (!p)\n\t\treturn NULL;\n\n\tpages = page_address(p);\n\tif (!cfg->coherent_walk) {\n\t\tdma = dma_map_single(dev, pages, size, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(dev, dma))\n\t\t\tgoto out_free;\n\t\t \n\t\tif (dma != virt_to_phys(pages))\n\t\t\tgoto out_unmap;\n\t}\n\n\treturn pages;\n\nout_unmap:\n\tdev_err(dev, \"Cannot accommodate DMA translation for IOMMU page tables\\n\");\n\tdma_unmap_single(dev, dma, size, DMA_TO_DEVICE);\nout_free:\n\t__free_pages(p, order);\n\treturn NULL;\n}\n\nstatic void __arm_lpae_free_pages(void *pages, size_t size,\n\t\t\t\t  struct io_pgtable_cfg *cfg)\n{\n\tif (!cfg->coherent_walk)\n\t\tdma_unmap_single(cfg->iommu_dev, __arm_lpae_dma_addr(pages),\n\t\t\t\t size, DMA_TO_DEVICE);\n\tfree_pages((unsigned long)pages, get_order(size));\n}\n\nstatic void __arm_lpae_sync_pte(arm_lpae_iopte *ptep, int num_entries,\n\t\t\t\tstruct io_pgtable_cfg *cfg)\n{\n\tdma_sync_single_for_device(cfg->iommu_dev, __arm_lpae_dma_addr(ptep),\n\t\t\t\t   sizeof(*ptep) * num_entries, DMA_TO_DEVICE);\n}\n\nstatic void __arm_lpae_clear_pte(arm_lpae_iopte *ptep, struct io_pgtable_cfg *cfg)\n{\n\n\t*ptep = 0;\n\n\tif (!cfg->coherent_walk)\n\t\t__arm_lpae_sync_pte(ptep, 1, cfg);\n}\n\nstatic size_t __arm_lpae_unmap(struct arm_lpae_io_pgtable *data,\n\t\t\t       struct iommu_iotlb_gather *gather,\n\t\t\t       unsigned long iova, size_t size, size_t pgcount,\n\t\t\t       int lvl, arm_lpae_iopte *ptep);\n\nstatic void __arm_lpae_init_pte(struct arm_lpae_io_pgtable *data,\n\t\t\t\tphys_addr_t paddr, arm_lpae_iopte prot,\n\t\t\t\tint lvl, int num_entries, arm_lpae_iopte *ptep)\n{\n\tarm_lpae_iopte pte = prot;\n\tstruct io_pgtable_cfg *cfg = &data->iop.cfg;\n\tsize_t sz = ARM_LPAE_BLOCK_SIZE(lvl, data);\n\tint i;\n\n\tif (data->iop.fmt != ARM_MALI_LPAE && lvl == ARM_LPAE_MAX_LEVELS - 1)\n\t\tpte |= ARM_LPAE_PTE_TYPE_PAGE;\n\telse\n\t\tpte |= ARM_LPAE_PTE_TYPE_BLOCK;\n\n\tfor (i = 0; i < num_entries; i++)\n\t\tptep[i] = pte | paddr_to_iopte(paddr + i * sz, data);\n\n\tif (!cfg->coherent_walk)\n\t\t__arm_lpae_sync_pte(ptep, num_entries, cfg);\n}\n\nstatic int arm_lpae_init_pte(struct arm_lpae_io_pgtable *data,\n\t\t\t     unsigned long iova, phys_addr_t paddr,\n\t\t\t     arm_lpae_iopte prot, int lvl, int num_entries,\n\t\t\t     arm_lpae_iopte *ptep)\n{\n\tint i;\n\n\tfor (i = 0; i < num_entries; i++)\n\t\tif (iopte_leaf(ptep[i], lvl, data->iop.fmt)) {\n\t\t\t \n\t\t\tWARN_ON(!selftest_running);\n\t\t\treturn -EEXIST;\n\t\t} else if (iopte_type(ptep[i]) == ARM_LPAE_PTE_TYPE_TABLE) {\n\t\t\t \n\t\t\tarm_lpae_iopte *tblp;\n\t\t\tsize_t sz = ARM_LPAE_BLOCK_SIZE(lvl, data);\n\n\t\t\ttblp = ptep - ARM_LPAE_LVL_IDX(iova, lvl, data);\n\t\t\tif (__arm_lpae_unmap(data, NULL, iova + i * sz, sz, 1,\n\t\t\t\t\t     lvl, tblp) != sz) {\n\t\t\t\tWARN_ON(1);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t__arm_lpae_init_pte(data, paddr, prot, lvl, num_entries, ptep);\n\treturn 0;\n}\n\nstatic arm_lpae_iopte arm_lpae_install_table(arm_lpae_iopte *table,\n\t\t\t\t\t     arm_lpae_iopte *ptep,\n\t\t\t\t\t     arm_lpae_iopte curr,\n\t\t\t\t\t     struct arm_lpae_io_pgtable *data)\n{\n\tarm_lpae_iopte old, new;\n\tstruct io_pgtable_cfg *cfg = &data->iop.cfg;\n\n\tnew = paddr_to_iopte(__pa(table), data) | ARM_LPAE_PTE_TYPE_TABLE;\n\tif (cfg->quirks & IO_PGTABLE_QUIRK_ARM_NS)\n\t\tnew |= ARM_LPAE_PTE_NSTABLE;\n\n\t \n\tdma_wmb();\n\n\told = cmpxchg64_relaxed(ptep, curr, new);\n\n\tif (cfg->coherent_walk || (old & ARM_LPAE_PTE_SW_SYNC))\n\t\treturn old;\n\n\t \n\t__arm_lpae_sync_pte(ptep, 1, cfg);\n\tif (old == curr)\n\t\tWRITE_ONCE(*ptep, new | ARM_LPAE_PTE_SW_SYNC);\n\n\treturn old;\n}\n\nstatic int __arm_lpae_map(struct arm_lpae_io_pgtable *data, unsigned long iova,\n\t\t\t  phys_addr_t paddr, size_t size, size_t pgcount,\n\t\t\t  arm_lpae_iopte prot, int lvl, arm_lpae_iopte *ptep,\n\t\t\t  gfp_t gfp, size_t *mapped)\n{\n\tarm_lpae_iopte *cptep, pte;\n\tsize_t block_size = ARM_LPAE_BLOCK_SIZE(lvl, data);\n\tsize_t tblsz = ARM_LPAE_GRANULE(data);\n\tstruct io_pgtable_cfg *cfg = &data->iop.cfg;\n\tint ret = 0, num_entries, max_entries, map_idx_start;\n\n\t \n\tmap_idx_start = ARM_LPAE_LVL_IDX(iova, lvl, data);\n\tptep += map_idx_start;\n\n\t \n\tif (size == block_size) {\n\t\tmax_entries = ARM_LPAE_PTES_PER_TABLE(data) - map_idx_start;\n\t\tnum_entries = min_t(int, pgcount, max_entries);\n\t\tret = arm_lpae_init_pte(data, iova, paddr, prot, lvl, num_entries, ptep);\n\t\tif (!ret)\n\t\t\t*mapped += num_entries * size;\n\n\t\treturn ret;\n\t}\n\n\t \n\tif (WARN_ON(lvl >= ARM_LPAE_MAX_LEVELS - 1))\n\t\treturn -EINVAL;\n\n\t \n\tpte = READ_ONCE(*ptep);\n\tif (!pte) {\n\t\tcptep = __arm_lpae_alloc_pages(tblsz, gfp, cfg);\n\t\tif (!cptep)\n\t\t\treturn -ENOMEM;\n\n\t\tpte = arm_lpae_install_table(cptep, ptep, 0, data);\n\t\tif (pte)\n\t\t\t__arm_lpae_free_pages(cptep, tblsz, cfg);\n\t} else if (!cfg->coherent_walk && !(pte & ARM_LPAE_PTE_SW_SYNC)) {\n\t\t__arm_lpae_sync_pte(ptep, 1, cfg);\n\t}\n\n\tif (pte && !iopte_leaf(pte, lvl, data->iop.fmt)) {\n\t\tcptep = iopte_deref(pte, data);\n\t} else if (pte) {\n\t\t \n\t\tWARN_ON(!selftest_running);\n\t\treturn -EEXIST;\n\t}\n\n\t \n\treturn __arm_lpae_map(data, iova, paddr, size, pgcount, prot, lvl + 1,\n\t\t\t      cptep, gfp, mapped);\n}\n\nstatic arm_lpae_iopte arm_lpae_prot_to_pte(struct arm_lpae_io_pgtable *data,\n\t\t\t\t\t   int prot)\n{\n\tarm_lpae_iopte pte;\n\n\tif (data->iop.fmt == ARM_64_LPAE_S1 ||\n\t    data->iop.fmt == ARM_32_LPAE_S1) {\n\t\tpte = ARM_LPAE_PTE_nG;\n\t\tif (!(prot & IOMMU_WRITE) && (prot & IOMMU_READ))\n\t\t\tpte |= ARM_LPAE_PTE_AP_RDONLY;\n\t\tif (!(prot & IOMMU_PRIV))\n\t\t\tpte |= ARM_LPAE_PTE_AP_UNPRIV;\n\t} else {\n\t\tpte = ARM_LPAE_PTE_HAP_FAULT;\n\t\tif (prot & IOMMU_READ)\n\t\t\tpte |= ARM_LPAE_PTE_HAP_READ;\n\t\tif (prot & IOMMU_WRITE)\n\t\t\tpte |= ARM_LPAE_PTE_HAP_WRITE;\n\t}\n\n\t \n\tif (data->iop.fmt == ARM_64_LPAE_S2 ||\n\t    data->iop.fmt == ARM_32_LPAE_S2) {\n\t\tif (prot & IOMMU_MMIO)\n\t\t\tpte |= ARM_LPAE_PTE_MEMATTR_DEV;\n\t\telse if (prot & IOMMU_CACHE)\n\t\t\tpte |= ARM_LPAE_PTE_MEMATTR_OIWB;\n\t\telse\n\t\t\tpte |= ARM_LPAE_PTE_MEMATTR_NC;\n\t} else {\n\t\tif (prot & IOMMU_MMIO)\n\t\t\tpte |= (ARM_LPAE_MAIR_ATTR_IDX_DEV\n\t\t\t\t<< ARM_LPAE_PTE_ATTRINDX_SHIFT);\n\t\telse if (prot & IOMMU_CACHE)\n\t\t\tpte |= (ARM_LPAE_MAIR_ATTR_IDX_CACHE\n\t\t\t\t<< ARM_LPAE_PTE_ATTRINDX_SHIFT);\n\t}\n\n\t \n\tif (prot & IOMMU_CACHE && data->iop.fmt != ARM_MALI_LPAE)\n\t\tpte |= ARM_LPAE_PTE_SH_IS;\n\telse\n\t\tpte |= ARM_LPAE_PTE_SH_OS;\n\n\tif (prot & IOMMU_NOEXEC)\n\t\tpte |= ARM_LPAE_PTE_XN;\n\n\tif (data->iop.cfg.quirks & IO_PGTABLE_QUIRK_ARM_NS)\n\t\tpte |= ARM_LPAE_PTE_NS;\n\n\tif (data->iop.fmt != ARM_MALI_LPAE)\n\t\tpte |= ARM_LPAE_PTE_AF;\n\n\treturn pte;\n}\n\nstatic int arm_lpae_map_pages(struct io_pgtable_ops *ops, unsigned long iova,\n\t\t\t      phys_addr_t paddr, size_t pgsize, size_t pgcount,\n\t\t\t      int iommu_prot, gfp_t gfp, size_t *mapped)\n{\n\tstruct arm_lpae_io_pgtable *data = io_pgtable_ops_to_data(ops);\n\tstruct io_pgtable_cfg *cfg = &data->iop.cfg;\n\tarm_lpae_iopte *ptep = data->pgd;\n\tint ret, lvl = data->start_level;\n\tarm_lpae_iopte prot;\n\tlong iaext = (s64)iova >> cfg->ias;\n\n\tif (WARN_ON(!pgsize || (pgsize & cfg->pgsize_bitmap) != pgsize))\n\t\treturn -EINVAL;\n\n\tif (cfg->quirks & IO_PGTABLE_QUIRK_ARM_TTBR1)\n\t\tiaext = ~iaext;\n\tif (WARN_ON(iaext || paddr >> cfg->oas))\n\t\treturn -ERANGE;\n\n\t \n\tif (!(iommu_prot & (IOMMU_READ | IOMMU_WRITE)))\n\t\treturn 0;\n\n\tprot = arm_lpae_prot_to_pte(data, iommu_prot);\n\tret = __arm_lpae_map(data, iova, paddr, pgsize, pgcount, prot, lvl,\n\t\t\t     ptep, gfp, mapped);\n\t \n\twmb();\n\n\treturn ret;\n}\n\nstatic void __arm_lpae_free_pgtable(struct arm_lpae_io_pgtable *data, int lvl,\n\t\t\t\t    arm_lpae_iopte *ptep)\n{\n\tarm_lpae_iopte *start, *end;\n\tunsigned long table_size;\n\n\tif (lvl == data->start_level)\n\t\ttable_size = ARM_LPAE_PGD_SIZE(data);\n\telse\n\t\ttable_size = ARM_LPAE_GRANULE(data);\n\n\tstart = ptep;\n\n\t \n\tif (lvl == ARM_LPAE_MAX_LEVELS - 1)\n\t\tend = ptep;\n\telse\n\t\tend = (void *)ptep + table_size;\n\n\twhile (ptep != end) {\n\t\tarm_lpae_iopte pte = *ptep++;\n\n\t\tif (!pte || iopte_leaf(pte, lvl, data->iop.fmt))\n\t\t\tcontinue;\n\n\t\t__arm_lpae_free_pgtable(data, lvl + 1, iopte_deref(pte, data));\n\t}\n\n\t__arm_lpae_free_pages(start, table_size, &data->iop.cfg);\n}\n\nstatic void arm_lpae_free_pgtable(struct io_pgtable *iop)\n{\n\tstruct arm_lpae_io_pgtable *data = io_pgtable_to_data(iop);\n\n\t__arm_lpae_free_pgtable(data, data->start_level, data->pgd);\n\tkfree(data);\n}\n\nstatic size_t arm_lpae_split_blk_unmap(struct arm_lpae_io_pgtable *data,\n\t\t\t\t       struct iommu_iotlb_gather *gather,\n\t\t\t\t       unsigned long iova, size_t size,\n\t\t\t\t       arm_lpae_iopte blk_pte, int lvl,\n\t\t\t\t       arm_lpae_iopte *ptep, size_t pgcount)\n{\n\tstruct io_pgtable_cfg *cfg = &data->iop.cfg;\n\tarm_lpae_iopte pte, *tablep;\n\tphys_addr_t blk_paddr;\n\tsize_t tablesz = ARM_LPAE_GRANULE(data);\n\tsize_t split_sz = ARM_LPAE_BLOCK_SIZE(lvl, data);\n\tint ptes_per_table = ARM_LPAE_PTES_PER_TABLE(data);\n\tint i, unmap_idx_start = -1, num_entries = 0, max_entries;\n\n\tif (WARN_ON(lvl == ARM_LPAE_MAX_LEVELS))\n\t\treturn 0;\n\n\ttablep = __arm_lpae_alloc_pages(tablesz, GFP_ATOMIC, cfg);\n\tif (!tablep)\n\t\treturn 0;  \n\n\tif (size == split_sz) {\n\t\tunmap_idx_start = ARM_LPAE_LVL_IDX(iova, lvl, data);\n\t\tmax_entries = ptes_per_table - unmap_idx_start;\n\t\tnum_entries = min_t(int, pgcount, max_entries);\n\t}\n\n\tblk_paddr = iopte_to_paddr(blk_pte, data);\n\tpte = iopte_prot(blk_pte);\n\n\tfor (i = 0; i < ptes_per_table; i++, blk_paddr += split_sz) {\n\t\t \n\t\tif (i >= unmap_idx_start && i < (unmap_idx_start + num_entries))\n\t\t\tcontinue;\n\n\t\t__arm_lpae_init_pte(data, blk_paddr, pte, lvl, 1, &tablep[i]);\n\t}\n\n\tpte = arm_lpae_install_table(tablep, ptep, blk_pte, data);\n\tif (pte != blk_pte) {\n\t\t__arm_lpae_free_pages(tablep, tablesz, cfg);\n\t\t \n\t\tif (iopte_type(pte) != ARM_LPAE_PTE_TYPE_TABLE)\n\t\t\treturn 0;\n\n\t\ttablep = iopte_deref(pte, data);\n\t} else if (unmap_idx_start >= 0) {\n\t\tfor (i = 0; i < num_entries; i++)\n\t\t\tio_pgtable_tlb_add_page(&data->iop, gather, iova + i * size, size);\n\n\t\treturn num_entries * size;\n\t}\n\n\treturn __arm_lpae_unmap(data, gather, iova, size, pgcount, lvl, tablep);\n}\n\nstatic size_t __arm_lpae_unmap(struct arm_lpae_io_pgtable *data,\n\t\t\t       struct iommu_iotlb_gather *gather,\n\t\t\t       unsigned long iova, size_t size, size_t pgcount,\n\t\t\t       int lvl, arm_lpae_iopte *ptep)\n{\n\tarm_lpae_iopte pte;\n\tstruct io_pgtable *iop = &data->iop;\n\tint i = 0, num_entries, max_entries, unmap_idx_start;\n\n\t \n\tif (WARN_ON(lvl == ARM_LPAE_MAX_LEVELS))\n\t\treturn 0;\n\n\tunmap_idx_start = ARM_LPAE_LVL_IDX(iova, lvl, data);\n\tptep += unmap_idx_start;\n\tpte = READ_ONCE(*ptep);\n\tif (WARN_ON(!pte))\n\t\treturn 0;\n\n\t \n\tif (size == ARM_LPAE_BLOCK_SIZE(lvl, data)) {\n\t\tmax_entries = ARM_LPAE_PTES_PER_TABLE(data) - unmap_idx_start;\n\t\tnum_entries = min_t(int, pgcount, max_entries);\n\n\t\twhile (i < num_entries) {\n\t\t\tpte = READ_ONCE(*ptep);\n\t\t\tif (WARN_ON(!pte))\n\t\t\t\tbreak;\n\n\t\t\t__arm_lpae_clear_pte(ptep, &iop->cfg);\n\n\t\t\tif (!iopte_leaf(pte, lvl, iop->fmt)) {\n\t\t\t\t \n\t\t\t\tio_pgtable_tlb_flush_walk(iop, iova + i * size, size,\n\t\t\t\t\t\t\t  ARM_LPAE_GRANULE(data));\n\t\t\t\t__arm_lpae_free_pgtable(data, lvl + 1, iopte_deref(pte, data));\n\t\t\t} else if (!iommu_iotlb_gather_queued(gather)) {\n\t\t\t\tio_pgtable_tlb_add_page(iop, gather, iova + i * size, size);\n\t\t\t}\n\n\t\t\tptep++;\n\t\t\ti++;\n\t\t}\n\n\t\treturn i * size;\n\t} else if (iopte_leaf(pte, lvl, iop->fmt)) {\n\t\t \n\t\treturn arm_lpae_split_blk_unmap(data, gather, iova, size, pte,\n\t\t\t\t\t\tlvl + 1, ptep, pgcount);\n\t}\n\n\t \n\tptep = iopte_deref(pte, data);\n\treturn __arm_lpae_unmap(data, gather, iova, size, pgcount, lvl + 1, ptep);\n}\n\nstatic size_t arm_lpae_unmap_pages(struct io_pgtable_ops *ops, unsigned long iova,\n\t\t\t\t   size_t pgsize, size_t pgcount,\n\t\t\t\t   struct iommu_iotlb_gather *gather)\n{\n\tstruct arm_lpae_io_pgtable *data = io_pgtable_ops_to_data(ops);\n\tstruct io_pgtable_cfg *cfg = &data->iop.cfg;\n\tarm_lpae_iopte *ptep = data->pgd;\n\tlong iaext = (s64)iova >> cfg->ias;\n\n\tif (WARN_ON(!pgsize || (pgsize & cfg->pgsize_bitmap) != pgsize || !pgcount))\n\t\treturn 0;\n\n\tif (cfg->quirks & IO_PGTABLE_QUIRK_ARM_TTBR1)\n\t\tiaext = ~iaext;\n\tif (WARN_ON(iaext))\n\t\treturn 0;\n\n\treturn __arm_lpae_unmap(data, gather, iova, pgsize, pgcount,\n\t\t\t\tdata->start_level, ptep);\n}\n\nstatic phys_addr_t arm_lpae_iova_to_phys(struct io_pgtable_ops *ops,\n\t\t\t\t\t unsigned long iova)\n{\n\tstruct arm_lpae_io_pgtable *data = io_pgtable_ops_to_data(ops);\n\tarm_lpae_iopte pte, *ptep = data->pgd;\n\tint lvl = data->start_level;\n\n\tdo {\n\t\t \n\t\tif (!ptep)\n\t\t\treturn 0;\n\n\t\t \n\t\tptep += ARM_LPAE_LVL_IDX(iova, lvl, data);\n\t\tpte = READ_ONCE(*ptep);\n\n\t\t \n\t\tif (!pte)\n\t\t\treturn 0;\n\n\t\t \n\t\tif (iopte_leaf(pte, lvl, data->iop.fmt))\n\t\t\tgoto found_translation;\n\n\t\t \n\t\tptep = iopte_deref(pte, data);\n\t} while (++lvl < ARM_LPAE_MAX_LEVELS);\n\n\t \n\treturn 0;\n\nfound_translation:\n\tiova &= (ARM_LPAE_BLOCK_SIZE(lvl, data) - 1);\n\treturn iopte_to_paddr(pte, data) | iova;\n}\n\nstatic void arm_lpae_restrict_pgsizes(struct io_pgtable_cfg *cfg)\n{\n\tunsigned long granule, page_sizes;\n\tunsigned int max_addr_bits = 48;\n\n\t \n\tif (cfg->pgsize_bitmap & PAGE_SIZE)\n\t\tgranule = PAGE_SIZE;\n\telse if (cfg->pgsize_bitmap & ~PAGE_MASK)\n\t\tgranule = 1UL << __fls(cfg->pgsize_bitmap & ~PAGE_MASK);\n\telse if (cfg->pgsize_bitmap & PAGE_MASK)\n\t\tgranule = 1UL << __ffs(cfg->pgsize_bitmap & PAGE_MASK);\n\telse\n\t\tgranule = 0;\n\n\tswitch (granule) {\n\tcase SZ_4K:\n\t\tpage_sizes = (SZ_4K | SZ_2M | SZ_1G);\n\t\tbreak;\n\tcase SZ_16K:\n\t\tpage_sizes = (SZ_16K | SZ_32M);\n\t\tbreak;\n\tcase SZ_64K:\n\t\tmax_addr_bits = 52;\n\t\tpage_sizes = (SZ_64K | SZ_512M);\n\t\tif (cfg->oas > 48)\n\t\t\tpage_sizes |= 1ULL << 42;  \n\t\tbreak;\n\tdefault:\n\t\tpage_sizes = 0;\n\t}\n\n\tcfg->pgsize_bitmap &= page_sizes;\n\tcfg->ias = min(cfg->ias, max_addr_bits);\n\tcfg->oas = min(cfg->oas, max_addr_bits);\n}\n\nstatic struct arm_lpae_io_pgtable *\narm_lpae_alloc_pgtable(struct io_pgtable_cfg *cfg)\n{\n\tstruct arm_lpae_io_pgtable *data;\n\tint levels, va_bits, pg_shift;\n\n\tarm_lpae_restrict_pgsizes(cfg);\n\n\tif (!(cfg->pgsize_bitmap & (SZ_4K | SZ_16K | SZ_64K)))\n\t\treturn NULL;\n\n\tif (cfg->ias > ARM_LPAE_MAX_ADDR_BITS)\n\t\treturn NULL;\n\n\tif (cfg->oas > ARM_LPAE_MAX_ADDR_BITS)\n\t\treturn NULL;\n\n\tdata = kmalloc(sizeof(*data), GFP_KERNEL);\n\tif (!data)\n\t\treturn NULL;\n\n\tpg_shift = __ffs(cfg->pgsize_bitmap);\n\tdata->bits_per_level = pg_shift - ilog2(sizeof(arm_lpae_iopte));\n\n\tva_bits = cfg->ias - pg_shift;\n\tlevels = DIV_ROUND_UP(va_bits, data->bits_per_level);\n\tdata->start_level = ARM_LPAE_MAX_LEVELS - levels;\n\n\t \n\tdata->pgd_bits = va_bits - (data->bits_per_level * (levels - 1));\n\n\tdata->iop.ops = (struct io_pgtable_ops) {\n\t\t.map_pages\t= arm_lpae_map_pages,\n\t\t.unmap_pages\t= arm_lpae_unmap_pages,\n\t\t.iova_to_phys\t= arm_lpae_iova_to_phys,\n\t};\n\n\treturn data;\n}\n\nstatic struct io_pgtable *\narm_64_lpae_alloc_pgtable_s1(struct io_pgtable_cfg *cfg, void *cookie)\n{\n\tu64 reg;\n\tstruct arm_lpae_io_pgtable *data;\n\ttypeof(&cfg->arm_lpae_s1_cfg.tcr) tcr = &cfg->arm_lpae_s1_cfg.tcr;\n\tbool tg1;\n\n\tif (cfg->quirks & ~(IO_PGTABLE_QUIRK_ARM_NS |\n\t\t\t    IO_PGTABLE_QUIRK_ARM_TTBR1 |\n\t\t\t    IO_PGTABLE_QUIRK_ARM_OUTER_WBWA))\n\t\treturn NULL;\n\n\tdata = arm_lpae_alloc_pgtable(cfg);\n\tif (!data)\n\t\treturn NULL;\n\n\t \n\tif (cfg->coherent_walk) {\n\t\ttcr->sh = ARM_LPAE_TCR_SH_IS;\n\t\ttcr->irgn = ARM_LPAE_TCR_RGN_WBWA;\n\t\ttcr->orgn = ARM_LPAE_TCR_RGN_WBWA;\n\t\tif (cfg->quirks & IO_PGTABLE_QUIRK_ARM_OUTER_WBWA)\n\t\t\tgoto out_free_data;\n\t} else {\n\t\ttcr->sh = ARM_LPAE_TCR_SH_OS;\n\t\ttcr->irgn = ARM_LPAE_TCR_RGN_NC;\n\t\tif (!(cfg->quirks & IO_PGTABLE_QUIRK_ARM_OUTER_WBWA))\n\t\t\ttcr->orgn = ARM_LPAE_TCR_RGN_NC;\n\t\telse\n\t\t\ttcr->orgn = ARM_LPAE_TCR_RGN_WBWA;\n\t}\n\n\ttg1 = cfg->quirks & IO_PGTABLE_QUIRK_ARM_TTBR1;\n\tswitch (ARM_LPAE_GRANULE(data)) {\n\tcase SZ_4K:\n\t\ttcr->tg = tg1 ? ARM_LPAE_TCR_TG1_4K : ARM_LPAE_TCR_TG0_4K;\n\t\tbreak;\n\tcase SZ_16K:\n\t\ttcr->tg = tg1 ? ARM_LPAE_TCR_TG1_16K : ARM_LPAE_TCR_TG0_16K;\n\t\tbreak;\n\tcase SZ_64K:\n\t\ttcr->tg = tg1 ? ARM_LPAE_TCR_TG1_64K : ARM_LPAE_TCR_TG0_64K;\n\t\tbreak;\n\t}\n\n\tswitch (cfg->oas) {\n\tcase 32:\n\t\ttcr->ips = ARM_LPAE_TCR_PS_32_BIT;\n\t\tbreak;\n\tcase 36:\n\t\ttcr->ips = ARM_LPAE_TCR_PS_36_BIT;\n\t\tbreak;\n\tcase 40:\n\t\ttcr->ips = ARM_LPAE_TCR_PS_40_BIT;\n\t\tbreak;\n\tcase 42:\n\t\ttcr->ips = ARM_LPAE_TCR_PS_42_BIT;\n\t\tbreak;\n\tcase 44:\n\t\ttcr->ips = ARM_LPAE_TCR_PS_44_BIT;\n\t\tbreak;\n\tcase 48:\n\t\ttcr->ips = ARM_LPAE_TCR_PS_48_BIT;\n\t\tbreak;\n\tcase 52:\n\t\ttcr->ips = ARM_LPAE_TCR_PS_52_BIT;\n\t\tbreak;\n\tdefault:\n\t\tgoto out_free_data;\n\t}\n\n\ttcr->tsz = 64ULL - cfg->ias;\n\n\t \n\treg = (ARM_LPAE_MAIR_ATTR_NC\n\t       << ARM_LPAE_MAIR_ATTR_SHIFT(ARM_LPAE_MAIR_ATTR_IDX_NC)) |\n\t      (ARM_LPAE_MAIR_ATTR_WBRWA\n\t       << ARM_LPAE_MAIR_ATTR_SHIFT(ARM_LPAE_MAIR_ATTR_IDX_CACHE)) |\n\t      (ARM_LPAE_MAIR_ATTR_DEVICE\n\t       << ARM_LPAE_MAIR_ATTR_SHIFT(ARM_LPAE_MAIR_ATTR_IDX_DEV)) |\n\t      (ARM_LPAE_MAIR_ATTR_INC_OWBRWA\n\t       << ARM_LPAE_MAIR_ATTR_SHIFT(ARM_LPAE_MAIR_ATTR_IDX_INC_OCACHE));\n\n\tcfg->arm_lpae_s1_cfg.mair = reg;\n\n\t \n\tdata->pgd = __arm_lpae_alloc_pages(ARM_LPAE_PGD_SIZE(data),\n\t\t\t\t\t   GFP_KERNEL, cfg);\n\tif (!data->pgd)\n\t\tgoto out_free_data;\n\n\t \n\twmb();\n\n\t \n\tcfg->arm_lpae_s1_cfg.ttbr = virt_to_phys(data->pgd);\n\treturn &data->iop;\n\nout_free_data:\n\tkfree(data);\n\treturn NULL;\n}\n\nstatic struct io_pgtable *\narm_64_lpae_alloc_pgtable_s2(struct io_pgtable_cfg *cfg, void *cookie)\n{\n\tu64 sl;\n\tstruct arm_lpae_io_pgtable *data;\n\ttypeof(&cfg->arm_lpae_s2_cfg.vtcr) vtcr = &cfg->arm_lpae_s2_cfg.vtcr;\n\n\t \n\tif (cfg->quirks)\n\t\treturn NULL;\n\n\tdata = arm_lpae_alloc_pgtable(cfg);\n\tif (!data)\n\t\treturn NULL;\n\n\t \n\tif (data->start_level == 0) {\n\t\tunsigned long pgd_pages;\n\n\t\tpgd_pages = ARM_LPAE_PGD_SIZE(data) / sizeof(arm_lpae_iopte);\n\t\tif (pgd_pages <= ARM_LPAE_S2_MAX_CONCAT_PAGES) {\n\t\t\tdata->pgd_bits += data->bits_per_level;\n\t\t\tdata->start_level++;\n\t\t}\n\t}\n\n\t \n\tif (cfg->coherent_walk) {\n\t\tvtcr->sh = ARM_LPAE_TCR_SH_IS;\n\t\tvtcr->irgn = ARM_LPAE_TCR_RGN_WBWA;\n\t\tvtcr->orgn = ARM_LPAE_TCR_RGN_WBWA;\n\t} else {\n\t\tvtcr->sh = ARM_LPAE_TCR_SH_OS;\n\t\tvtcr->irgn = ARM_LPAE_TCR_RGN_NC;\n\t\tvtcr->orgn = ARM_LPAE_TCR_RGN_NC;\n\t}\n\n\tsl = data->start_level;\n\n\tswitch (ARM_LPAE_GRANULE(data)) {\n\tcase SZ_4K:\n\t\tvtcr->tg = ARM_LPAE_TCR_TG0_4K;\n\t\tsl++;  \n\t\tbreak;\n\tcase SZ_16K:\n\t\tvtcr->tg = ARM_LPAE_TCR_TG0_16K;\n\t\tbreak;\n\tcase SZ_64K:\n\t\tvtcr->tg = ARM_LPAE_TCR_TG0_64K;\n\t\tbreak;\n\t}\n\n\tswitch (cfg->oas) {\n\tcase 32:\n\t\tvtcr->ps = ARM_LPAE_TCR_PS_32_BIT;\n\t\tbreak;\n\tcase 36:\n\t\tvtcr->ps = ARM_LPAE_TCR_PS_36_BIT;\n\t\tbreak;\n\tcase 40:\n\t\tvtcr->ps = ARM_LPAE_TCR_PS_40_BIT;\n\t\tbreak;\n\tcase 42:\n\t\tvtcr->ps = ARM_LPAE_TCR_PS_42_BIT;\n\t\tbreak;\n\tcase 44:\n\t\tvtcr->ps = ARM_LPAE_TCR_PS_44_BIT;\n\t\tbreak;\n\tcase 48:\n\t\tvtcr->ps = ARM_LPAE_TCR_PS_48_BIT;\n\t\tbreak;\n\tcase 52:\n\t\tvtcr->ps = ARM_LPAE_TCR_PS_52_BIT;\n\t\tbreak;\n\tdefault:\n\t\tgoto out_free_data;\n\t}\n\n\tvtcr->tsz = 64ULL - cfg->ias;\n\tvtcr->sl = ~sl & ARM_LPAE_VTCR_SL0_MASK;\n\n\t \n\tdata->pgd = __arm_lpae_alloc_pages(ARM_LPAE_PGD_SIZE(data),\n\t\t\t\t\t   GFP_KERNEL, cfg);\n\tif (!data->pgd)\n\t\tgoto out_free_data;\n\n\t \n\twmb();\n\n\t \n\tcfg->arm_lpae_s2_cfg.vttbr = virt_to_phys(data->pgd);\n\treturn &data->iop;\n\nout_free_data:\n\tkfree(data);\n\treturn NULL;\n}\n\nstatic struct io_pgtable *\narm_32_lpae_alloc_pgtable_s1(struct io_pgtable_cfg *cfg, void *cookie)\n{\n\tif (cfg->ias > 32 || cfg->oas > 40)\n\t\treturn NULL;\n\n\tcfg->pgsize_bitmap &= (SZ_4K | SZ_2M | SZ_1G);\n\treturn arm_64_lpae_alloc_pgtable_s1(cfg, cookie);\n}\n\nstatic struct io_pgtable *\narm_32_lpae_alloc_pgtable_s2(struct io_pgtable_cfg *cfg, void *cookie)\n{\n\tif (cfg->ias > 40 || cfg->oas > 40)\n\t\treturn NULL;\n\n\tcfg->pgsize_bitmap &= (SZ_4K | SZ_2M | SZ_1G);\n\treturn arm_64_lpae_alloc_pgtable_s2(cfg, cookie);\n}\n\nstatic struct io_pgtable *\narm_mali_lpae_alloc_pgtable(struct io_pgtable_cfg *cfg, void *cookie)\n{\n\tstruct arm_lpae_io_pgtable *data;\n\n\t \n\tif (cfg->quirks)\n\t\treturn NULL;\n\n\tif (cfg->ias > 48 || cfg->oas > 40)\n\t\treturn NULL;\n\n\tcfg->pgsize_bitmap &= (SZ_4K | SZ_2M | SZ_1G);\n\n\tdata = arm_lpae_alloc_pgtable(cfg);\n\tif (!data)\n\t\treturn NULL;\n\n\t \n\tif (data->start_level > 0) {\n\t\tdata->start_level = 0;\n\t\tdata->pgd_bits = 0;\n\t}\n\t \n\tcfg->arm_mali_lpae_cfg.memattr =\n\t\t(ARM_MALI_LPAE_MEMATTR_IMP_DEF\n\t\t << ARM_LPAE_MAIR_ATTR_SHIFT(ARM_LPAE_MAIR_ATTR_IDX_NC)) |\n\t\t(ARM_MALI_LPAE_MEMATTR_WRITE_ALLOC\n\t\t << ARM_LPAE_MAIR_ATTR_SHIFT(ARM_LPAE_MAIR_ATTR_IDX_CACHE)) |\n\t\t(ARM_MALI_LPAE_MEMATTR_IMP_DEF\n\t\t << ARM_LPAE_MAIR_ATTR_SHIFT(ARM_LPAE_MAIR_ATTR_IDX_DEV));\n\n\tdata->pgd = __arm_lpae_alloc_pages(ARM_LPAE_PGD_SIZE(data), GFP_KERNEL,\n\t\t\t\t\t   cfg);\n\tif (!data->pgd)\n\t\tgoto out_free_data;\n\n\t \n\twmb();\n\n\tcfg->arm_mali_lpae_cfg.transtab = virt_to_phys(data->pgd) |\n\t\t\t\t\t  ARM_MALI_LPAE_TTBR_READ_INNER |\n\t\t\t\t\t  ARM_MALI_LPAE_TTBR_ADRMODE_TABLE;\n\tif (cfg->coherent_walk)\n\t\tcfg->arm_mali_lpae_cfg.transtab |= ARM_MALI_LPAE_TTBR_SHARE_OUTER;\n\n\treturn &data->iop;\n\nout_free_data:\n\tkfree(data);\n\treturn NULL;\n}\n\nstruct io_pgtable_init_fns io_pgtable_arm_64_lpae_s1_init_fns = {\n\t.alloc\t= arm_64_lpae_alloc_pgtable_s1,\n\t.free\t= arm_lpae_free_pgtable,\n};\n\nstruct io_pgtable_init_fns io_pgtable_arm_64_lpae_s2_init_fns = {\n\t.alloc\t= arm_64_lpae_alloc_pgtable_s2,\n\t.free\t= arm_lpae_free_pgtable,\n};\n\nstruct io_pgtable_init_fns io_pgtable_arm_32_lpae_s1_init_fns = {\n\t.alloc\t= arm_32_lpae_alloc_pgtable_s1,\n\t.free\t= arm_lpae_free_pgtable,\n};\n\nstruct io_pgtable_init_fns io_pgtable_arm_32_lpae_s2_init_fns = {\n\t.alloc\t= arm_32_lpae_alloc_pgtable_s2,\n\t.free\t= arm_lpae_free_pgtable,\n};\n\nstruct io_pgtable_init_fns io_pgtable_arm_mali_lpae_init_fns = {\n\t.alloc\t= arm_mali_lpae_alloc_pgtable,\n\t.free\t= arm_lpae_free_pgtable,\n};\n\n#ifdef CONFIG_IOMMU_IO_PGTABLE_LPAE_SELFTEST\n\nstatic struct io_pgtable_cfg *cfg_cookie __initdata;\n\nstatic void __init dummy_tlb_flush_all(void *cookie)\n{\n\tWARN_ON(cookie != cfg_cookie);\n}\n\nstatic void __init dummy_tlb_flush(unsigned long iova, size_t size,\n\t\t\t\t   size_t granule, void *cookie)\n{\n\tWARN_ON(cookie != cfg_cookie);\n\tWARN_ON(!(size & cfg_cookie->pgsize_bitmap));\n}\n\nstatic void __init dummy_tlb_add_page(struct iommu_iotlb_gather *gather,\n\t\t\t\t      unsigned long iova, size_t granule,\n\t\t\t\t      void *cookie)\n{\n\tdummy_tlb_flush(iova, granule, granule, cookie);\n}\n\nstatic const struct iommu_flush_ops dummy_tlb_ops __initconst = {\n\t.tlb_flush_all\t= dummy_tlb_flush_all,\n\t.tlb_flush_walk\t= dummy_tlb_flush,\n\t.tlb_add_page\t= dummy_tlb_add_page,\n};\n\nstatic void __init arm_lpae_dump_ops(struct io_pgtable_ops *ops)\n{\n\tstruct arm_lpae_io_pgtable *data = io_pgtable_ops_to_data(ops);\n\tstruct io_pgtable_cfg *cfg = &data->iop.cfg;\n\n\tpr_err(\"cfg: pgsize_bitmap 0x%lx, ias %u-bit\\n\",\n\t\tcfg->pgsize_bitmap, cfg->ias);\n\tpr_err(\"data: %d levels, 0x%zx pgd_size, %u pg_shift, %u bits_per_level, pgd @ %p\\n\",\n\t\tARM_LPAE_MAX_LEVELS - data->start_level, ARM_LPAE_PGD_SIZE(data),\n\t\tilog2(ARM_LPAE_GRANULE(data)), data->bits_per_level, data->pgd);\n}\n\n#define __FAIL(ops, i)\t({\t\t\t\t\t\t\\\n\t\tWARN(1, \"selftest: test failed for fmt idx %d\\n\", (i));\t\\\n\t\tarm_lpae_dump_ops(ops);\t\t\t\t\t\\\n\t\tselftest_running = false;\t\t\t\t\\\n\t\t-EFAULT;\t\t\t\t\t\t\\\n})\n\nstatic int __init arm_lpae_run_tests(struct io_pgtable_cfg *cfg)\n{\n\tstatic const enum io_pgtable_fmt fmts[] __initconst = {\n\t\tARM_64_LPAE_S1,\n\t\tARM_64_LPAE_S2,\n\t};\n\n\tint i, j;\n\tunsigned long iova;\n\tsize_t size, mapped;\n\tstruct io_pgtable_ops *ops;\n\n\tselftest_running = true;\n\n\tfor (i = 0; i < ARRAY_SIZE(fmts); ++i) {\n\t\tcfg_cookie = cfg;\n\t\tops = alloc_io_pgtable_ops(fmts[i], cfg, cfg);\n\t\tif (!ops) {\n\t\t\tpr_err(\"selftest: failed to allocate io pgtable ops\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t \n\t\tif (ops->iova_to_phys(ops, 42))\n\t\t\treturn __FAIL(ops, i);\n\n\t\tif (ops->iova_to_phys(ops, SZ_1G + 42))\n\t\t\treturn __FAIL(ops, i);\n\n\t\tif (ops->iova_to_phys(ops, SZ_2G + 42))\n\t\t\treturn __FAIL(ops, i);\n\n\t\t \n\t\tiova = 0;\n\t\tfor_each_set_bit(j, &cfg->pgsize_bitmap, BITS_PER_LONG) {\n\t\t\tsize = 1UL << j;\n\n\t\t\tif (ops->map_pages(ops, iova, iova, size, 1,\n\t\t\t\t\t   IOMMU_READ | IOMMU_WRITE |\n\t\t\t\t\t   IOMMU_NOEXEC | IOMMU_CACHE,\n\t\t\t\t\t   GFP_KERNEL, &mapped))\n\t\t\t\treturn __FAIL(ops, i);\n\n\t\t\t \n\t\t\tif (!ops->map_pages(ops, iova, iova + size, size, 1,\n\t\t\t\t\t    IOMMU_READ | IOMMU_NOEXEC,\n\t\t\t\t\t    GFP_KERNEL, &mapped))\n\t\t\t\treturn __FAIL(ops, i);\n\n\t\t\tif (ops->iova_to_phys(ops, iova + 42) != (iova + 42))\n\t\t\t\treturn __FAIL(ops, i);\n\n\t\t\tiova += SZ_1G;\n\t\t}\n\n\t\t \n\t\tsize = 1UL << __ffs(cfg->pgsize_bitmap);\n\t\tif (ops->unmap_pages(ops, SZ_1G + size, size, 1, NULL) != size)\n\t\t\treturn __FAIL(ops, i);\n\n\t\t \n\t\tif (ops->map_pages(ops, SZ_1G + size, size, size, 1,\n\t\t\t\t   IOMMU_READ, GFP_KERNEL, &mapped))\n\t\t\treturn __FAIL(ops, i);\n\n\t\tif (ops->iova_to_phys(ops, SZ_1G + size + 42) != (size + 42))\n\t\t\treturn __FAIL(ops, i);\n\n\t\t \n\t\tiova = 0;\n\t\tfor_each_set_bit(j, &cfg->pgsize_bitmap, BITS_PER_LONG) {\n\t\t\tsize = 1UL << j;\n\n\t\t\tif (ops->unmap_pages(ops, iova, size, 1, NULL) != size)\n\t\t\t\treturn __FAIL(ops, i);\n\n\t\t\tif (ops->iova_to_phys(ops, iova + 42))\n\t\t\t\treturn __FAIL(ops, i);\n\n\t\t\t \n\t\t\tif (ops->map_pages(ops, iova, iova, size, 1,\n\t\t\t\t\t   IOMMU_WRITE, GFP_KERNEL, &mapped))\n\t\t\t\treturn __FAIL(ops, i);\n\n\t\t\tif (ops->iova_to_phys(ops, iova + 42) != (iova + 42))\n\t\t\t\treturn __FAIL(ops, i);\n\n\t\t\tiova += SZ_1G;\n\t\t}\n\n\t\tfree_io_pgtable_ops(ops);\n\t}\n\n\tselftest_running = false;\n\treturn 0;\n}\n\nstatic int __init arm_lpae_do_selftests(void)\n{\n\tstatic const unsigned long pgsize[] __initconst = {\n\t\tSZ_4K | SZ_2M | SZ_1G,\n\t\tSZ_16K | SZ_32M,\n\t\tSZ_64K | SZ_512M,\n\t};\n\n\tstatic const unsigned int ias[] __initconst = {\n\t\t32, 36, 40, 42, 44, 48,\n\t};\n\n\tint i, j, pass = 0, fail = 0;\n\tstruct device dev;\n\tstruct io_pgtable_cfg cfg = {\n\t\t.tlb = &dummy_tlb_ops,\n\t\t.oas = 48,\n\t\t.coherent_walk = true,\n\t\t.iommu_dev = &dev,\n\t};\n\n\t \n\tset_dev_node(&dev, NUMA_NO_NODE);\n\n\tfor (i = 0; i < ARRAY_SIZE(pgsize); ++i) {\n\t\tfor (j = 0; j < ARRAY_SIZE(ias); ++j) {\n\t\t\tcfg.pgsize_bitmap = pgsize[i];\n\t\t\tcfg.ias = ias[j];\n\t\t\tpr_info(\"selftest: pgsize_bitmap 0x%08lx, IAS %u\\n\",\n\t\t\t\tpgsize[i], ias[j]);\n\t\t\tif (arm_lpae_run_tests(&cfg))\n\t\t\t\tfail++;\n\t\t\telse\n\t\t\t\tpass++;\n\t\t}\n\t}\n\n\tpr_info(\"selftest: completed with %d PASS %d FAIL\\n\", pass, fail);\n\treturn fail ? -EFAULT : 0;\n}\nsubsys_initcall(arm_lpae_do_selftests);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}