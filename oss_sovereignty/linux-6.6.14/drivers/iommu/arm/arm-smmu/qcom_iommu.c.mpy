{
  "module_name": "qcom_iommu.c",
  "hash_id": "02ab2befe946062fd491bd8cb6f6e0071d8baa06802e7a72401f7215aa0d50fc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/arm/arm-smmu/qcom_iommu.c",
  "human_readable_source": "\n \n\n#include <linux/atomic.h>\n#include <linux/bitfield.h>\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/io-64-nonatomic-hi-lo.h>\n#include <linux/io-pgtable.h>\n#include <linux/iommu.h>\n#include <linux/iopoll.h>\n#include <linux/kconfig.h>\n#include <linux/init.h>\n#include <linux/mutex.h>\n#include <linux/of.h>\n#include <linux/of_platform.h>\n#include <linux/platform_device.h>\n#include <linux/pm.h>\n#include <linux/pm_runtime.h>\n#include <linux/firmware/qcom/qcom_scm.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n\n#include \"arm-smmu.h\"\n\n#define SMMU_INTR_SEL_NS     0x2000\n\nenum qcom_iommu_clk {\n\tCLK_IFACE,\n\tCLK_BUS,\n\tCLK_TBU,\n\tCLK_NUM,\n};\n\nstruct qcom_iommu_ctx;\n\nstruct qcom_iommu_dev {\n\t \n\tstruct iommu_device\t iommu;\n\tstruct device\t\t*dev;\n\tstruct clk_bulk_data clks[CLK_NUM];\n\tvoid __iomem\t\t*local_base;\n\tu32\t\t\t sec_id;\n\tu8\t\t\t max_asid;\n\tstruct qcom_iommu_ctx\t*ctxs[];    \n};\n\nstruct qcom_iommu_ctx {\n\tstruct device\t\t*dev;\n\tvoid __iomem\t\t*base;\n\tbool\t\t\t secure_init;\n\tbool\t\t\t secured_ctx;\n\tu8\t\t\t asid;       \n\tstruct iommu_domain\t*domain;\n};\n\nstruct qcom_iommu_domain {\n\tstruct io_pgtable_ops\t*pgtbl_ops;\n\tspinlock_t\t\t pgtbl_lock;\n\tstruct mutex\t\t init_mutex;  \n\tstruct iommu_domain\t domain;\n\tstruct qcom_iommu_dev\t*iommu;\n\tstruct iommu_fwspec\t*fwspec;\n};\n\nstatic struct qcom_iommu_domain *to_qcom_iommu_domain(struct iommu_domain *dom)\n{\n\treturn container_of(dom, struct qcom_iommu_domain, domain);\n}\n\nstatic const struct iommu_ops qcom_iommu_ops;\n\nstatic struct qcom_iommu_dev * to_iommu(struct device *dev)\n{\n\tstruct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);\n\n\tif (!fwspec || fwspec->ops != &qcom_iommu_ops)\n\t\treturn NULL;\n\n\treturn dev_iommu_priv_get(dev);\n}\n\nstatic struct qcom_iommu_ctx * to_ctx(struct qcom_iommu_domain *d, unsigned asid)\n{\n\tstruct qcom_iommu_dev *qcom_iommu = d->iommu;\n\tif (!qcom_iommu)\n\t\treturn NULL;\n\treturn qcom_iommu->ctxs[asid];\n}\n\nstatic inline void\niommu_writel(struct qcom_iommu_ctx *ctx, unsigned reg, u32 val)\n{\n\twritel_relaxed(val, ctx->base + reg);\n}\n\nstatic inline void\niommu_writeq(struct qcom_iommu_ctx *ctx, unsigned reg, u64 val)\n{\n\twriteq_relaxed(val, ctx->base + reg);\n}\n\nstatic inline u32\niommu_readl(struct qcom_iommu_ctx *ctx, unsigned reg)\n{\n\treturn readl_relaxed(ctx->base + reg);\n}\n\nstatic inline u64\niommu_readq(struct qcom_iommu_ctx *ctx, unsigned reg)\n{\n\treturn readq_relaxed(ctx->base + reg);\n}\n\nstatic void qcom_iommu_tlb_sync(void *cookie)\n{\n\tstruct qcom_iommu_domain *qcom_domain = cookie;\n\tstruct iommu_fwspec *fwspec = qcom_domain->fwspec;\n\tunsigned i;\n\n\tfor (i = 0; i < fwspec->num_ids; i++) {\n\t\tstruct qcom_iommu_ctx *ctx = to_ctx(qcom_domain, fwspec->ids[i]);\n\t\tunsigned int val, ret;\n\n\t\tiommu_writel(ctx, ARM_SMMU_CB_TLBSYNC, 0);\n\n\t\tret = readl_poll_timeout(ctx->base + ARM_SMMU_CB_TLBSTATUS, val,\n\t\t\t\t\t (val & 0x1) == 0, 0, 5000000);\n\t\tif (ret)\n\t\t\tdev_err(ctx->dev, \"timeout waiting for TLB SYNC\\n\");\n\t}\n}\n\nstatic void qcom_iommu_tlb_inv_context(void *cookie)\n{\n\tstruct qcom_iommu_domain *qcom_domain = cookie;\n\tstruct iommu_fwspec *fwspec = qcom_domain->fwspec;\n\tunsigned i;\n\n\tfor (i = 0; i < fwspec->num_ids; i++) {\n\t\tstruct qcom_iommu_ctx *ctx = to_ctx(qcom_domain, fwspec->ids[i]);\n\t\tiommu_writel(ctx, ARM_SMMU_CB_S1_TLBIASID, ctx->asid);\n\t}\n\n\tqcom_iommu_tlb_sync(cookie);\n}\n\nstatic void qcom_iommu_tlb_inv_range_nosync(unsigned long iova, size_t size,\n\t\t\t\t\t    size_t granule, bool leaf, void *cookie)\n{\n\tstruct qcom_iommu_domain *qcom_domain = cookie;\n\tstruct iommu_fwspec *fwspec = qcom_domain->fwspec;\n\tunsigned i, reg;\n\n\treg = leaf ? ARM_SMMU_CB_S1_TLBIVAL : ARM_SMMU_CB_S1_TLBIVA;\n\n\tfor (i = 0; i < fwspec->num_ids; i++) {\n\t\tstruct qcom_iommu_ctx *ctx = to_ctx(qcom_domain, fwspec->ids[i]);\n\t\tsize_t s = size;\n\n\t\tiova = (iova >> 12) << 12;\n\t\tiova |= ctx->asid;\n\t\tdo {\n\t\t\tiommu_writel(ctx, reg, iova);\n\t\t\tiova += granule;\n\t\t} while (s -= granule);\n\t}\n}\n\nstatic void qcom_iommu_tlb_flush_walk(unsigned long iova, size_t size,\n\t\t\t\t      size_t granule, void *cookie)\n{\n\tqcom_iommu_tlb_inv_range_nosync(iova, size, granule, false, cookie);\n\tqcom_iommu_tlb_sync(cookie);\n}\n\nstatic void qcom_iommu_tlb_add_page(struct iommu_iotlb_gather *gather,\n\t\t\t\t    unsigned long iova, size_t granule,\n\t\t\t\t    void *cookie)\n{\n\tqcom_iommu_tlb_inv_range_nosync(iova, granule, granule, true, cookie);\n}\n\nstatic const struct iommu_flush_ops qcom_flush_ops = {\n\t.tlb_flush_all\t= qcom_iommu_tlb_inv_context,\n\t.tlb_flush_walk = qcom_iommu_tlb_flush_walk,\n\t.tlb_add_page\t= qcom_iommu_tlb_add_page,\n};\n\nstatic irqreturn_t qcom_iommu_fault(int irq, void *dev)\n{\n\tstruct qcom_iommu_ctx *ctx = dev;\n\tu32 fsr, fsynr;\n\tu64 iova;\n\n\tfsr = iommu_readl(ctx, ARM_SMMU_CB_FSR);\n\n\tif (!(fsr & ARM_SMMU_FSR_FAULT))\n\t\treturn IRQ_NONE;\n\n\tfsynr = iommu_readl(ctx, ARM_SMMU_CB_FSYNR0);\n\tiova = iommu_readq(ctx, ARM_SMMU_CB_FAR);\n\n\tif (!report_iommu_fault(ctx->domain, ctx->dev, iova, 0)) {\n\t\tdev_err_ratelimited(ctx->dev,\n\t\t\t\t    \"Unhandled context fault: fsr=0x%x, \"\n\t\t\t\t    \"iova=0x%016llx, fsynr=0x%x, cb=%d\\n\",\n\t\t\t\t    fsr, iova, fsynr, ctx->asid);\n\t}\n\n\tiommu_writel(ctx, ARM_SMMU_CB_FSR, fsr);\n\tiommu_writel(ctx, ARM_SMMU_CB_RESUME, ARM_SMMU_RESUME_TERMINATE);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int qcom_iommu_init_domain(struct iommu_domain *domain,\n\t\t\t\t  struct qcom_iommu_dev *qcom_iommu,\n\t\t\t\t  struct device *dev)\n{\n\tstruct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);\n\tstruct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);\n\tstruct io_pgtable_ops *pgtbl_ops;\n\tstruct io_pgtable_cfg pgtbl_cfg;\n\tint i, ret = 0;\n\tu32 reg;\n\n\tmutex_lock(&qcom_domain->init_mutex);\n\tif (qcom_domain->iommu)\n\t\tgoto out_unlock;\n\n\tpgtbl_cfg = (struct io_pgtable_cfg) {\n\t\t.pgsize_bitmap\t= qcom_iommu_ops.pgsize_bitmap,\n\t\t.ias\t\t= 32,\n\t\t.oas\t\t= 40,\n\t\t.tlb\t\t= &qcom_flush_ops,\n\t\t.iommu_dev\t= qcom_iommu->dev,\n\t};\n\n\tqcom_domain->iommu = qcom_iommu;\n\tqcom_domain->fwspec = fwspec;\n\n\tpgtbl_ops = alloc_io_pgtable_ops(ARM_32_LPAE_S1, &pgtbl_cfg, qcom_domain);\n\tif (!pgtbl_ops) {\n\t\tdev_err(qcom_iommu->dev, \"failed to allocate pagetable ops\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_clear_iommu;\n\t}\n\n\t \n\tdomain->pgsize_bitmap = pgtbl_cfg.pgsize_bitmap;\n\tdomain->geometry.aperture_end = (1ULL << pgtbl_cfg.ias) - 1;\n\tdomain->geometry.force_aperture = true;\n\n\tfor (i = 0; i < fwspec->num_ids; i++) {\n\t\tstruct qcom_iommu_ctx *ctx = to_ctx(qcom_domain, fwspec->ids[i]);\n\n\t\tif (!ctx->secure_init) {\n\t\t\tret = qcom_scm_restore_sec_cfg(qcom_iommu->sec_id, ctx->asid);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(qcom_iommu->dev, \"secure init failed: %d\\n\", ret);\n\t\t\t\tgoto out_clear_iommu;\n\t\t\t}\n\t\t\tctx->secure_init = true;\n\t\t}\n\n\t\t \n\t\tif (ctx->secured_ctx) {\n\t\t\tctx->domain = domain;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tiommu_writel(ctx, ARM_SMMU_CB_SCTLR, 0);\n\n\t\t \n\t\tiommu_writel(ctx, ARM_SMMU_CB_FAR, 0);\n\t\tiommu_writel(ctx, ARM_SMMU_CB_FSR, ARM_SMMU_FSR_FAULT);\n\n\t\t \n\t\tiommu_writeq(ctx, ARM_SMMU_CB_TTBR0,\n\t\t\t\tpgtbl_cfg.arm_lpae_s1_cfg.ttbr |\n\t\t\t\tFIELD_PREP(ARM_SMMU_TTBRn_ASID, ctx->asid));\n\t\tiommu_writeq(ctx, ARM_SMMU_CB_TTBR1, 0);\n\n\t\t \n\t\tiommu_writel(ctx, ARM_SMMU_CB_TCR2,\n\t\t\t\tarm_smmu_lpae_tcr2(&pgtbl_cfg));\n\t\tiommu_writel(ctx, ARM_SMMU_CB_TCR,\n\t\t\t     arm_smmu_lpae_tcr(&pgtbl_cfg) | ARM_SMMU_TCR_EAE);\n\n\t\t \n\t\tiommu_writel(ctx, ARM_SMMU_CB_S1_MAIR0,\n\t\t\t\tpgtbl_cfg.arm_lpae_s1_cfg.mair);\n\t\tiommu_writel(ctx, ARM_SMMU_CB_S1_MAIR1,\n\t\t\t\tpgtbl_cfg.arm_lpae_s1_cfg.mair >> 32);\n\n\t\t \n\t\treg = ARM_SMMU_SCTLR_CFIE | ARM_SMMU_SCTLR_CFRE |\n\t\t      ARM_SMMU_SCTLR_AFE | ARM_SMMU_SCTLR_TRE |\n\t\t      ARM_SMMU_SCTLR_M | ARM_SMMU_SCTLR_S1_ASIDPNE |\n\t\t      ARM_SMMU_SCTLR_CFCFG;\n\n\t\tif (IS_ENABLED(CONFIG_CPU_BIG_ENDIAN))\n\t\t\treg |= ARM_SMMU_SCTLR_E;\n\n\t\tiommu_writel(ctx, ARM_SMMU_CB_SCTLR, reg);\n\n\t\tctx->domain = domain;\n\t}\n\n\tmutex_unlock(&qcom_domain->init_mutex);\n\n\t \n\tqcom_domain->pgtbl_ops = pgtbl_ops;\n\n\treturn 0;\n\nout_clear_iommu:\n\tqcom_domain->iommu = NULL;\nout_unlock:\n\tmutex_unlock(&qcom_domain->init_mutex);\n\treturn ret;\n}\n\nstatic struct iommu_domain *qcom_iommu_domain_alloc(unsigned type)\n{\n\tstruct qcom_iommu_domain *qcom_domain;\n\n\tif (type != IOMMU_DOMAIN_UNMANAGED && type != IOMMU_DOMAIN_DMA)\n\t\treturn NULL;\n\t \n\tqcom_domain = kzalloc(sizeof(*qcom_domain), GFP_KERNEL);\n\tif (!qcom_domain)\n\t\treturn NULL;\n\n\tmutex_init(&qcom_domain->init_mutex);\n\tspin_lock_init(&qcom_domain->pgtbl_lock);\n\n\treturn &qcom_domain->domain;\n}\n\nstatic void qcom_iommu_domain_free(struct iommu_domain *domain)\n{\n\tstruct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);\n\n\tif (qcom_domain->iommu) {\n\t\t \n\t\tpm_runtime_get_sync(qcom_domain->iommu->dev);\n\t\tfree_io_pgtable_ops(qcom_domain->pgtbl_ops);\n\t\tpm_runtime_put_sync(qcom_domain->iommu->dev);\n\t}\n\n\tkfree(qcom_domain);\n}\n\nstatic int qcom_iommu_attach_dev(struct iommu_domain *domain, struct device *dev)\n{\n\tstruct qcom_iommu_dev *qcom_iommu = to_iommu(dev);\n\tstruct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);\n\tint ret;\n\n\tif (!qcom_iommu) {\n\t\tdev_err(dev, \"cannot attach to IOMMU, is it on the same bus?\\n\");\n\t\treturn -ENXIO;\n\t}\n\n\t \n\tpm_runtime_get_sync(qcom_iommu->dev);\n\tret = qcom_iommu_init_domain(domain, qcom_iommu, dev);\n\tpm_runtime_put_sync(qcom_iommu->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tif (qcom_domain->iommu != qcom_iommu)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int qcom_iommu_map(struct iommu_domain *domain, unsigned long iova,\n\t\t\t  phys_addr_t paddr, size_t pgsize, size_t pgcount,\n\t\t\t  int prot, gfp_t gfp, size_t *mapped)\n{\n\tint ret;\n\tunsigned long flags;\n\tstruct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);\n\tstruct io_pgtable_ops *ops = qcom_domain->pgtbl_ops;\n\n\tif (!ops)\n\t\treturn -ENODEV;\n\n\tspin_lock_irqsave(&qcom_domain->pgtbl_lock, flags);\n\tret = ops->map_pages(ops, iova, paddr, pgsize, pgcount, prot, GFP_ATOMIC, mapped);\n\tspin_unlock_irqrestore(&qcom_domain->pgtbl_lock, flags);\n\treturn ret;\n}\n\nstatic size_t qcom_iommu_unmap(struct iommu_domain *domain, unsigned long iova,\n\t\t\t       size_t pgsize, size_t pgcount,\n\t\t\t       struct iommu_iotlb_gather *gather)\n{\n\tsize_t ret;\n\tunsigned long flags;\n\tstruct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);\n\tstruct io_pgtable_ops *ops = qcom_domain->pgtbl_ops;\n\n\tif (!ops)\n\t\treturn 0;\n\n\t \n\tpm_runtime_get_sync(qcom_domain->iommu->dev);\n\tspin_lock_irqsave(&qcom_domain->pgtbl_lock, flags);\n\tret = ops->unmap_pages(ops, iova, pgsize, pgcount, gather);\n\tspin_unlock_irqrestore(&qcom_domain->pgtbl_lock, flags);\n\tpm_runtime_put_sync(qcom_domain->iommu->dev);\n\n\treturn ret;\n}\n\nstatic void qcom_iommu_flush_iotlb_all(struct iommu_domain *domain)\n{\n\tstruct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);\n\tstruct io_pgtable *pgtable = container_of(qcom_domain->pgtbl_ops,\n\t\t\t\t\t\t  struct io_pgtable, ops);\n\tif (!qcom_domain->pgtbl_ops)\n\t\treturn;\n\n\tpm_runtime_get_sync(qcom_domain->iommu->dev);\n\tqcom_iommu_tlb_sync(pgtable->cookie);\n\tpm_runtime_put_sync(qcom_domain->iommu->dev);\n}\n\nstatic void qcom_iommu_iotlb_sync(struct iommu_domain *domain,\n\t\t\t\t  struct iommu_iotlb_gather *gather)\n{\n\tqcom_iommu_flush_iotlb_all(domain);\n}\n\nstatic phys_addr_t qcom_iommu_iova_to_phys(struct iommu_domain *domain,\n\t\t\t\t\t   dma_addr_t iova)\n{\n\tphys_addr_t ret;\n\tunsigned long flags;\n\tstruct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);\n\tstruct io_pgtable_ops *ops = qcom_domain->pgtbl_ops;\n\n\tif (!ops)\n\t\treturn 0;\n\n\tspin_lock_irqsave(&qcom_domain->pgtbl_lock, flags);\n\tret = ops->iova_to_phys(ops, iova);\n\tspin_unlock_irqrestore(&qcom_domain->pgtbl_lock, flags);\n\n\treturn ret;\n}\n\nstatic bool qcom_iommu_capable(struct device *dev, enum iommu_cap cap)\n{\n\tswitch (cap) {\n\tcase IOMMU_CAP_CACHE_COHERENCY:\n\t\t \n\t\treturn true;\n\tcase IOMMU_CAP_NOEXEC:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic struct iommu_device *qcom_iommu_probe_device(struct device *dev)\n{\n\tstruct qcom_iommu_dev *qcom_iommu = to_iommu(dev);\n\tstruct device_link *link;\n\n\tif (!qcom_iommu)\n\t\treturn ERR_PTR(-ENODEV);\n\n\t \n\tlink = device_link_add(dev, qcom_iommu->dev, DL_FLAG_PM_RUNTIME);\n\tif (!link) {\n\t\tdev_err(qcom_iommu->dev, \"Unable to create device link between %s and %s\\n\",\n\t\t\tdev_name(qcom_iommu->dev), dev_name(dev));\n\t\treturn ERR_PTR(-ENODEV);\n\t}\n\n\treturn &qcom_iommu->iommu;\n}\n\nstatic int qcom_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)\n{\n\tstruct qcom_iommu_dev *qcom_iommu;\n\tstruct platform_device *iommu_pdev;\n\tunsigned asid = args->args[0];\n\n\tif (args->args_count != 1) {\n\t\tdev_err(dev, \"incorrect number of iommu params found for %s \"\n\t\t\t\"(found %d, expected 1)\\n\",\n\t\t\targs->np->full_name, args->args_count);\n\t\treturn -EINVAL;\n\t}\n\n\tiommu_pdev = of_find_device_by_node(args->np);\n\tif (WARN_ON(!iommu_pdev))\n\t\treturn -EINVAL;\n\n\tqcom_iommu = platform_get_drvdata(iommu_pdev);\n\n\t \n\tif (WARN_ON(asid > qcom_iommu->max_asid) ||\n\t    WARN_ON(qcom_iommu->ctxs[asid] == NULL)) {\n\t\tput_device(&iommu_pdev->dev);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!dev_iommu_priv_get(dev)) {\n\t\tdev_iommu_priv_set(dev, qcom_iommu);\n\t} else {\n\t\t \n\t\tif (WARN_ON(qcom_iommu != dev_iommu_priv_get(dev))) {\n\t\t\tput_device(&iommu_pdev->dev);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn iommu_fwspec_add_ids(dev, &asid, 1);\n}\n\nstatic const struct iommu_ops qcom_iommu_ops = {\n\t.capable\t= qcom_iommu_capable,\n\t.domain_alloc\t= qcom_iommu_domain_alloc,\n\t.probe_device\t= qcom_iommu_probe_device,\n\t.device_group\t= generic_device_group,\n\t.of_xlate\t= qcom_iommu_of_xlate,\n\t.pgsize_bitmap\t= SZ_4K | SZ_64K | SZ_1M | SZ_16M,\n\t.default_domain_ops = &(const struct iommu_domain_ops) {\n\t\t.attach_dev\t= qcom_iommu_attach_dev,\n\t\t.map_pages\t= qcom_iommu_map,\n\t\t.unmap_pages\t= qcom_iommu_unmap,\n\t\t.flush_iotlb_all = qcom_iommu_flush_iotlb_all,\n\t\t.iotlb_sync\t= qcom_iommu_iotlb_sync,\n\t\t.iova_to_phys\t= qcom_iommu_iova_to_phys,\n\t\t.free\t\t= qcom_iommu_domain_free,\n\t}\n};\n\nstatic int qcom_iommu_sec_ptbl_init(struct device *dev)\n{\n\tsize_t psize = 0;\n\tunsigned int spare = 0;\n\tvoid *cpu_addr;\n\tdma_addr_t paddr;\n\tunsigned long attrs;\n\tstatic bool allocated = false;\n\tint ret;\n\n\tif (allocated)\n\t\treturn 0;\n\n\tret = qcom_scm_iommu_secure_ptbl_size(spare, &psize);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to get iommu secure pgtable size (%d)\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tdev_info(dev, \"iommu sec: pgtable size: %zu\\n\", psize);\n\n\tattrs = DMA_ATTR_NO_KERNEL_MAPPING;\n\n\tcpu_addr = dma_alloc_attrs(dev, psize, &paddr, GFP_KERNEL, attrs);\n\tif (!cpu_addr) {\n\t\tdev_err(dev, \"failed to allocate %zu bytes for pgtable\\n\",\n\t\t\tpsize);\n\t\treturn -ENOMEM;\n\t}\n\n\tret = qcom_scm_iommu_secure_ptbl_init(paddr, psize, spare);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to init iommu pgtable (%d)\\n\", ret);\n\t\tgoto free_mem;\n\t}\n\n\tallocated = true;\n\treturn 0;\n\nfree_mem:\n\tdma_free_attrs(dev, psize, cpu_addr, paddr, attrs);\n\treturn ret;\n}\n\nstatic int get_asid(const struct device_node *np)\n{\n\tu32 reg, val;\n\tint asid;\n\n\t \n\tif (of_property_read_u32_index(np, \"reg\", 0, &reg))\n\t\treturn -ENODEV;\n\n\t \n\tif (!of_property_read_u32(np, \"qcom,ctx-asid\", &val))\n\t\tasid = val;\n\telse\n\t\tasid = reg / 0x1000;\n\n\treturn asid;\n}\n\nstatic int qcom_iommu_ctx_probe(struct platform_device *pdev)\n{\n\tstruct qcom_iommu_ctx *ctx;\n\tstruct device *dev = &pdev->dev;\n\tstruct qcom_iommu_dev *qcom_iommu = dev_get_drvdata(dev->parent);\n\tint ret, irq;\n\n\tctx = devm_kzalloc(dev, sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tctx->dev = dev;\n\tplatform_set_drvdata(pdev, ctx);\n\n\tctx->base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(ctx->base))\n\t\treturn PTR_ERR(ctx->base);\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tif (of_device_is_compatible(dev->of_node, \"qcom,msm-iommu-v2-sec\"))\n\t\tctx->secured_ctx = true;\n\n\t \n\tif (!ctx->secured_ctx)\n\t\tiommu_writel(ctx, ARM_SMMU_CB_FSR, iommu_readl(ctx, ARM_SMMU_CB_FSR));\n\n\tret = devm_request_irq(dev, irq,\n\t\t\t       qcom_iommu_fault,\n\t\t\t       IRQF_SHARED,\n\t\t\t       \"qcom-iommu-fault\",\n\t\t\t       ctx);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to request IRQ %u\\n\", irq);\n\t\treturn ret;\n\t}\n\n\tret = get_asid(dev->of_node);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"missing reg property\\n\");\n\t\treturn ret;\n\t}\n\n\tctx->asid = ret;\n\n\tdev_dbg(dev, \"found asid %u\\n\", ctx->asid);\n\n\tqcom_iommu->ctxs[ctx->asid] = ctx;\n\n\treturn 0;\n}\n\nstatic void qcom_iommu_ctx_remove(struct platform_device *pdev)\n{\n\tstruct qcom_iommu_dev *qcom_iommu = dev_get_drvdata(pdev->dev.parent);\n\tstruct qcom_iommu_ctx *ctx = platform_get_drvdata(pdev);\n\n\tplatform_set_drvdata(pdev, NULL);\n\n\tqcom_iommu->ctxs[ctx->asid] = NULL;\n}\n\nstatic const struct of_device_id ctx_of_match[] = {\n\t{ .compatible = \"qcom,msm-iommu-v1-ns\" },\n\t{ .compatible = \"qcom,msm-iommu-v1-sec\" },\n\t{ .compatible = \"qcom,msm-iommu-v2-ns\" },\n\t{ .compatible = \"qcom,msm-iommu-v2-sec\" },\n\t{   }\n};\n\nstatic struct platform_driver qcom_iommu_ctx_driver = {\n\t.driver\t= {\n\t\t.name\t\t= \"qcom-iommu-ctx\",\n\t\t.of_match_table\t= ctx_of_match,\n\t},\n\t.probe\t= qcom_iommu_ctx_probe,\n\t.remove_new = qcom_iommu_ctx_remove,\n};\n\nstatic bool qcom_iommu_has_secure_context(struct qcom_iommu_dev *qcom_iommu)\n{\n\tstruct device_node *child;\n\n\tfor_each_child_of_node(qcom_iommu->dev->of_node, child) {\n\t\tif (of_device_is_compatible(child, \"qcom,msm-iommu-v1-sec\") ||\n\t\t    of_device_is_compatible(child, \"qcom,msm-iommu-v2-sec\")) {\n\t\t\tof_node_put(child);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\nstatic int qcom_iommu_device_probe(struct platform_device *pdev)\n{\n\tstruct device_node *child;\n\tstruct qcom_iommu_dev *qcom_iommu;\n\tstruct device *dev = &pdev->dev;\n\tstruct resource *res;\n\tstruct clk *clk;\n\tint ret, max_asid = 0;\n\n\t \n\tfor_each_child_of_node(dev->of_node, child)\n\t\tmax_asid = max(max_asid, get_asid(child));\n\n\tqcom_iommu = devm_kzalloc(dev, struct_size(qcom_iommu, ctxs, max_asid + 1),\n\t\t\t\t  GFP_KERNEL);\n\tif (!qcom_iommu)\n\t\treturn -ENOMEM;\n\tqcom_iommu->max_asid = max_asid;\n\tqcom_iommu->dev = dev;\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (res) {\n\t\tqcom_iommu->local_base = devm_ioremap_resource(dev, res);\n\t\tif (IS_ERR(qcom_iommu->local_base))\n\t\t\treturn PTR_ERR(qcom_iommu->local_base);\n\t}\n\n\tclk = devm_clk_get(dev, \"iface\");\n\tif (IS_ERR(clk)) {\n\t\tdev_err(dev, \"failed to get iface clock\\n\");\n\t\treturn PTR_ERR(clk);\n\t}\n\tqcom_iommu->clks[CLK_IFACE].clk = clk;\n\n\tclk = devm_clk_get(dev, \"bus\");\n\tif (IS_ERR(clk)) {\n\t\tdev_err(dev, \"failed to get bus clock\\n\");\n\t\treturn PTR_ERR(clk);\n\t}\n\tqcom_iommu->clks[CLK_BUS].clk = clk;\n\n\tclk = devm_clk_get_optional(dev, \"tbu\");\n\tif (IS_ERR(clk)) {\n\t\tdev_err(dev, \"failed to get tbu clock\\n\");\n\t\treturn PTR_ERR(clk);\n\t}\n\tqcom_iommu->clks[CLK_TBU].clk = clk;\n\n\tif (of_property_read_u32(dev->of_node, \"qcom,iommu-secure-id\",\n\t\t\t\t &qcom_iommu->sec_id)) {\n\t\tdev_err(dev, \"missing qcom,iommu-secure-id property\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (qcom_iommu_has_secure_context(qcom_iommu)) {\n\t\tret = qcom_iommu_sec_ptbl_init(dev);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"cannot init secure pg table(%d)\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tplatform_set_drvdata(pdev, qcom_iommu);\n\n\tpm_runtime_enable(dev);\n\n\t \n\tret = devm_of_platform_populate(dev);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to populate iommu contexts\\n\");\n\t\tgoto err_pm_disable;\n\t}\n\n\tret = iommu_device_sysfs_add(&qcom_iommu->iommu, dev, NULL,\n\t\t\t\t     dev_name(dev));\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to register iommu in sysfs\\n\");\n\t\tgoto err_pm_disable;\n\t}\n\n\tret = iommu_device_register(&qcom_iommu->iommu, &qcom_iommu_ops, dev);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to register iommu\\n\");\n\t\tgoto err_pm_disable;\n\t}\n\n\tif (qcom_iommu->local_base) {\n\t\tpm_runtime_get_sync(dev);\n\t\twritel_relaxed(0xffffffff, qcom_iommu->local_base + SMMU_INTR_SEL_NS);\n\t\tpm_runtime_put_sync(dev);\n\t}\n\n\treturn 0;\n\nerr_pm_disable:\n\tpm_runtime_disable(dev);\n\treturn ret;\n}\n\nstatic void qcom_iommu_device_remove(struct platform_device *pdev)\n{\n\tstruct qcom_iommu_dev *qcom_iommu = platform_get_drvdata(pdev);\n\n\tpm_runtime_force_suspend(&pdev->dev);\n\tplatform_set_drvdata(pdev, NULL);\n\tiommu_device_sysfs_remove(&qcom_iommu->iommu);\n\tiommu_device_unregister(&qcom_iommu->iommu);\n}\n\nstatic int __maybe_unused qcom_iommu_resume(struct device *dev)\n{\n\tstruct qcom_iommu_dev *qcom_iommu = dev_get_drvdata(dev);\n\n\treturn clk_bulk_prepare_enable(CLK_NUM, qcom_iommu->clks);\n}\n\nstatic int __maybe_unused qcom_iommu_suspend(struct device *dev)\n{\n\tstruct qcom_iommu_dev *qcom_iommu = dev_get_drvdata(dev);\n\n\tclk_bulk_disable_unprepare(CLK_NUM, qcom_iommu->clks);\n\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops qcom_iommu_pm_ops = {\n\tSET_RUNTIME_PM_OPS(qcom_iommu_suspend, qcom_iommu_resume, NULL)\n\tSET_SYSTEM_SLEEP_PM_OPS(pm_runtime_force_suspend,\n\t\t\t\tpm_runtime_force_resume)\n};\n\nstatic const struct of_device_id qcom_iommu_of_match[] = {\n\t{ .compatible = \"qcom,msm-iommu-v1\" },\n\t{ .compatible = \"qcom,msm-iommu-v2\" },\n\t{   }\n};\n\nstatic struct platform_driver qcom_iommu_driver = {\n\t.driver\t= {\n\t\t.name\t\t= \"qcom-iommu\",\n\t\t.of_match_table\t= qcom_iommu_of_match,\n\t\t.pm\t\t= &qcom_iommu_pm_ops,\n\t},\n\t.probe\t= qcom_iommu_device_probe,\n\t.remove_new = qcom_iommu_device_remove,\n};\n\nstatic int __init qcom_iommu_init(void)\n{\n\tint ret;\n\n\tret = platform_driver_register(&qcom_iommu_ctx_driver);\n\tif (ret)\n\t\treturn ret;\n\n\tret = platform_driver_register(&qcom_iommu_driver);\n\tif (ret)\n\t\tplatform_driver_unregister(&qcom_iommu_ctx_driver);\n\n\treturn ret;\n}\ndevice_initcall(qcom_iommu_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}