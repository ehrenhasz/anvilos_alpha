{
  "module_name": "arm-smmu-qcom.c",
  "hash_id": "90b8b493a38360a08fe6c745fb3ef39869c43fd4dc3255b73d8a8415c74521e9",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/arm/arm-smmu/arm-smmu-qcom.c",
  "human_readable_source": "\n \n\n#include <linux/acpi.h>\n#include <linux/adreno-smmu-priv.h>\n#include <linux/delay.h>\n#include <linux/of_device.h>\n#include <linux/firmware/qcom/qcom_scm.h>\n\n#include \"arm-smmu.h\"\n#include \"arm-smmu-qcom.h\"\n\n#define QCOM_DUMMY_VAL\t-1\n\nstatic struct qcom_smmu *to_qcom_smmu(struct arm_smmu_device *smmu)\n{\n\treturn container_of(smmu, struct qcom_smmu, smmu);\n}\n\nstatic void qcom_smmu_tlb_sync(struct arm_smmu_device *smmu, int page,\n\t\t\t\tint sync, int status)\n{\n\tunsigned int spin_cnt, delay;\n\tu32 reg;\n\n\tarm_smmu_writel(smmu, page, sync, QCOM_DUMMY_VAL);\n\tfor (delay = 1; delay < TLB_LOOP_TIMEOUT; delay *= 2) {\n\t\tfor (spin_cnt = TLB_SPIN_COUNT; spin_cnt > 0; spin_cnt--) {\n\t\t\treg = arm_smmu_readl(smmu, page, status);\n\t\t\tif (!(reg & ARM_SMMU_sTLBGSTATUS_GSACTIVE))\n\t\t\t\treturn;\n\t\t\tcpu_relax();\n\t\t}\n\t\tudelay(delay);\n\t}\n\n\tqcom_smmu_tlb_sync_debug(smmu);\n}\n\nstatic void qcom_adreno_smmu_write_sctlr(struct arm_smmu_device *smmu, int idx,\n\t\tu32 reg)\n{\n\tstruct qcom_smmu *qsmmu = to_qcom_smmu(smmu);\n\n\t \n\treg |= ARM_SMMU_SCTLR_HUPCF;\n\n\tif (qsmmu->stall_enabled & BIT(idx))\n\t\treg |= ARM_SMMU_SCTLR_CFCFG;\n\n\tarm_smmu_cb_write(smmu, idx, ARM_SMMU_CB_SCTLR, reg);\n}\n\nstatic void qcom_adreno_smmu_get_fault_info(const void *cookie,\n\t\tstruct adreno_smmu_fault_info *info)\n{\n\tstruct arm_smmu_domain *smmu_domain = (void *)cookie;\n\tstruct arm_smmu_cfg *cfg = &smmu_domain->cfg;\n\tstruct arm_smmu_device *smmu = smmu_domain->smmu;\n\n\tinfo->fsr = arm_smmu_cb_read(smmu, cfg->cbndx, ARM_SMMU_CB_FSR);\n\tinfo->fsynr0 = arm_smmu_cb_read(smmu, cfg->cbndx, ARM_SMMU_CB_FSYNR0);\n\tinfo->fsynr1 = arm_smmu_cb_read(smmu, cfg->cbndx, ARM_SMMU_CB_FSYNR1);\n\tinfo->far = arm_smmu_cb_readq(smmu, cfg->cbndx, ARM_SMMU_CB_FAR);\n\tinfo->cbfrsynra = arm_smmu_gr1_read(smmu, ARM_SMMU_GR1_CBFRSYNRA(cfg->cbndx));\n\tinfo->ttbr0 = arm_smmu_cb_readq(smmu, cfg->cbndx, ARM_SMMU_CB_TTBR0);\n\tinfo->contextidr = arm_smmu_cb_read(smmu, cfg->cbndx, ARM_SMMU_CB_CONTEXTIDR);\n}\n\nstatic void qcom_adreno_smmu_set_stall(const void *cookie, bool enabled)\n{\n\tstruct arm_smmu_domain *smmu_domain = (void *)cookie;\n\tstruct arm_smmu_cfg *cfg = &smmu_domain->cfg;\n\tstruct qcom_smmu *qsmmu = to_qcom_smmu(smmu_domain->smmu);\n\n\tif (enabled)\n\t\tqsmmu->stall_enabled |= BIT(cfg->cbndx);\n\telse\n\t\tqsmmu->stall_enabled &= ~BIT(cfg->cbndx);\n}\n\nstatic void qcom_adreno_smmu_resume_translation(const void *cookie, bool terminate)\n{\n\tstruct arm_smmu_domain *smmu_domain = (void *)cookie;\n\tstruct arm_smmu_cfg *cfg = &smmu_domain->cfg;\n\tstruct arm_smmu_device *smmu = smmu_domain->smmu;\n\tu32 reg = 0;\n\n\tif (terminate)\n\t\treg |= ARM_SMMU_RESUME_TERMINATE;\n\n\tarm_smmu_cb_write(smmu, cfg->cbndx, ARM_SMMU_CB_RESUME, reg);\n}\n\n#define QCOM_ADRENO_SMMU_GPU_SID 0\n\nstatic bool qcom_adreno_smmu_is_gpu_device(struct device *dev)\n{\n\tstruct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);\n\tint i;\n\n\t \n\tfor (i = 0; i < fwspec->num_ids; i++) {\n\t\tu16 sid = FIELD_GET(ARM_SMMU_SMR_ID, fwspec->ids[i]);\n\n\t\tif (sid == QCOM_ADRENO_SMMU_GPU_SID)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic const struct io_pgtable_cfg *qcom_adreno_smmu_get_ttbr1_cfg(\n\t\tconst void *cookie)\n{\n\tstruct arm_smmu_domain *smmu_domain = (void *)cookie;\n\tstruct io_pgtable *pgtable =\n\t\tio_pgtable_ops_to_pgtable(smmu_domain->pgtbl_ops);\n\treturn &pgtable->cfg;\n}\n\n \n\nstatic int qcom_adreno_smmu_set_ttbr0_cfg(const void *cookie,\n\t\tconst struct io_pgtable_cfg *pgtbl_cfg)\n{\n\tstruct arm_smmu_domain *smmu_domain = (void *)cookie;\n\tstruct io_pgtable *pgtable = io_pgtable_ops_to_pgtable(smmu_domain->pgtbl_ops);\n\tstruct arm_smmu_cfg *cfg = &smmu_domain->cfg;\n\tstruct arm_smmu_cb *cb = &smmu_domain->smmu->cbs[cfg->cbndx];\n\n\t \n\tif (cb->tcr[0] & ARM_SMMU_TCR_EPD1)\n\t\treturn -EINVAL;\n\n\t \n\tif (!pgtbl_cfg) {\n\t\t \n\t\tif ((cb->tcr[0] & ARM_SMMU_TCR_EPD0))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tcb->tcr[0] = arm_smmu_lpae_tcr(&pgtable->cfg);\n\t\tcb->ttbr[0] = FIELD_PREP(ARM_SMMU_TTBRn_ASID, cb->cfg->asid);\n\t} else {\n\t\tu32 tcr = cb->tcr[0];\n\n\t\t \n\t\tif (!(cb->tcr[0] & ARM_SMMU_TCR_EPD0))\n\t\t\treturn -EINVAL;\n\n\t\ttcr |= arm_smmu_lpae_tcr(pgtbl_cfg);\n\t\ttcr &= ~(ARM_SMMU_TCR_EPD0 | ARM_SMMU_TCR_EPD1);\n\n\t\tcb->tcr[0] = tcr;\n\t\tcb->ttbr[0] = pgtbl_cfg->arm_lpae_s1_cfg.ttbr;\n\t\tcb->ttbr[0] |= FIELD_PREP(ARM_SMMU_TTBRn_ASID, cb->cfg->asid);\n\t}\n\n\tarm_smmu_write_context_bank(smmu_domain->smmu, cb->cfg->cbndx);\n\n\treturn 0;\n}\n\nstatic int qcom_adreno_smmu_alloc_context_bank(struct arm_smmu_domain *smmu_domain,\n\t\t\t\t\t       struct arm_smmu_device *smmu,\n\t\t\t\t\t       struct device *dev, int start)\n{\n\tint count;\n\n\t \n\tif (qcom_adreno_smmu_is_gpu_device(dev)) {\n\t\tstart = 0;\n\t\tcount = 1;\n\t} else {\n\t\tstart = 1;\n\t\tcount = smmu->num_context_banks;\n\t}\n\n\treturn __arm_smmu_alloc_bitmap(smmu->context_map, start, count);\n}\n\nstatic bool qcom_adreno_can_do_ttbr1(struct arm_smmu_device *smmu)\n{\n\tconst struct device_node *np = smmu->dev->of_node;\n\n\tif (of_device_is_compatible(np, \"qcom,msm8996-smmu-v2\"))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int qcom_adreno_smmu_init_context(struct arm_smmu_domain *smmu_domain,\n\t\tstruct io_pgtable_cfg *pgtbl_cfg, struct device *dev)\n{\n\tstruct adreno_smmu_priv *priv;\n\n\tsmmu_domain->cfg.flush_walk_prefer_tlbiasid = true;\n\n\t \n\tif (!qcom_adreno_smmu_is_gpu_device(dev))\n\t\treturn 0;\n\n\t \n\tif (qcom_adreno_can_do_ttbr1(smmu_domain->smmu) &&\n\t    (smmu_domain->stage == ARM_SMMU_DOMAIN_S1) &&\n\t    (smmu_domain->cfg.fmt == ARM_SMMU_CTX_FMT_AARCH64))\n\t\tpgtbl_cfg->quirks |= IO_PGTABLE_QUIRK_ARM_TTBR1;\n\n\t \n\n\tpriv = dev_get_drvdata(dev);\n\tpriv->cookie = smmu_domain;\n\tpriv->get_ttbr1_cfg = qcom_adreno_smmu_get_ttbr1_cfg;\n\tpriv->set_ttbr0_cfg = qcom_adreno_smmu_set_ttbr0_cfg;\n\tpriv->get_fault_info = qcom_adreno_smmu_get_fault_info;\n\tpriv->set_stall = qcom_adreno_smmu_set_stall;\n\tpriv->resume_translation = qcom_adreno_smmu_resume_translation;\n\n\treturn 0;\n}\n\nstatic const struct of_device_id qcom_smmu_client_of_match[] __maybe_unused = {\n\t{ .compatible = \"qcom,adreno\" },\n\t{ .compatible = \"qcom,adreno-gmu\" },\n\t{ .compatible = \"qcom,mdp4\" },\n\t{ .compatible = \"qcom,mdss\" },\n\t{ .compatible = \"qcom,sc7180-mdss\" },\n\t{ .compatible = \"qcom,sc7180-mss-pil\" },\n\t{ .compatible = \"qcom,sc7280-mdss\" },\n\t{ .compatible = \"qcom,sc7280-mss-pil\" },\n\t{ .compatible = \"qcom,sc8180x-mdss\" },\n\t{ .compatible = \"qcom,sc8280xp-mdss\" },\n\t{ .compatible = \"qcom,sdm845-mdss\" },\n\t{ .compatible = \"qcom,sdm845-mss-pil\" },\n\t{ .compatible = \"qcom,sm6350-mdss\" },\n\t{ .compatible = \"qcom,sm6375-mdss\" },\n\t{ .compatible = \"qcom,sm8150-mdss\" },\n\t{ .compatible = \"qcom,sm8250-mdss\" },\n\t{ }\n};\n\nstatic int qcom_smmu_init_context(struct arm_smmu_domain *smmu_domain,\n\t\tstruct io_pgtable_cfg *pgtbl_cfg, struct device *dev)\n{\n\tsmmu_domain->cfg.flush_walk_prefer_tlbiasid = true;\n\n\treturn 0;\n}\n\nstatic int qcom_smmu_cfg_probe(struct arm_smmu_device *smmu)\n{\n\tstruct qcom_smmu *qsmmu = to_qcom_smmu(smmu);\n\tunsigned int last_s2cr;\n\tu32 reg;\n\tu32 smr;\n\tint i;\n\n\t \n\tif (smmu->num_mapping_groups > 128) {\n\t\tdev_notice(smmu->dev, \"\\tLimiting the stream matching groups to 128\\n\");\n\t\tsmmu->num_mapping_groups = 128;\n\t}\n\n\tlast_s2cr = ARM_SMMU_GR0_S2CR(smmu->num_mapping_groups - 1);\n\n\t \n\treg = FIELD_PREP(ARM_SMMU_S2CR_TYPE, S2CR_TYPE_BYPASS) |\n\t      FIELD_PREP(ARM_SMMU_S2CR_CBNDX, 0xff) |\n\t      FIELD_PREP(ARM_SMMU_S2CR_PRIVCFG, S2CR_PRIVCFG_DEFAULT);\n\tarm_smmu_gr0_write(smmu, last_s2cr, reg);\n\treg = arm_smmu_gr0_read(smmu, last_s2cr);\n\tif (FIELD_GET(ARM_SMMU_S2CR_TYPE, reg) != S2CR_TYPE_BYPASS) {\n\t\tqsmmu->bypass_quirk = true;\n\t\tqsmmu->bypass_cbndx = smmu->num_context_banks - 1;\n\n\t\tset_bit(qsmmu->bypass_cbndx, smmu->context_map);\n\n\t\tarm_smmu_cb_write(smmu, qsmmu->bypass_cbndx, ARM_SMMU_CB_SCTLR, 0);\n\n\t\treg = FIELD_PREP(ARM_SMMU_CBAR_TYPE, CBAR_TYPE_S1_TRANS_S2_BYPASS);\n\t\tarm_smmu_gr1_write(smmu, ARM_SMMU_GR1_CBAR(qsmmu->bypass_cbndx), reg);\n\t}\n\n\tfor (i = 0; i < smmu->num_mapping_groups; i++) {\n\t\tsmr = arm_smmu_gr0_read(smmu, ARM_SMMU_GR0_SMR(i));\n\n\t\tif (FIELD_GET(ARM_SMMU_SMR_VALID, smr)) {\n\t\t\t \n\t\t\tsmr &= ~ARM_SMMU_SMR_VALID;\n\t\t\tsmmu->smrs[i].id = FIELD_GET(ARM_SMMU_SMR_ID, smr);\n\t\t\tsmmu->smrs[i].mask = FIELD_GET(ARM_SMMU_SMR_MASK, smr);\n\t\t\tsmmu->smrs[i].valid = true;\n\n\t\t\tsmmu->s2crs[i].type = S2CR_TYPE_BYPASS;\n\t\t\tsmmu->s2crs[i].privcfg = S2CR_PRIVCFG_DEFAULT;\n\t\t\tsmmu->s2crs[i].cbndx = 0xff;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void qcom_smmu_write_s2cr(struct arm_smmu_device *smmu, int idx)\n{\n\tstruct arm_smmu_s2cr *s2cr = smmu->s2crs + idx;\n\tstruct qcom_smmu *qsmmu = to_qcom_smmu(smmu);\n\tu32 cbndx = s2cr->cbndx;\n\tu32 type = s2cr->type;\n\tu32 reg;\n\n\tif (qsmmu->bypass_quirk) {\n\t\tif (type == S2CR_TYPE_BYPASS) {\n\t\t\t \n\t\t\ttype = S2CR_TYPE_TRANS;\n\t\t\tcbndx = qsmmu->bypass_cbndx;\n\t\t} else if (type == S2CR_TYPE_FAULT) {\n\t\t\t \n\t\t\ttype = S2CR_TYPE_BYPASS;\n\t\t\tcbndx = 0xff;\n\t\t}\n\t}\n\n\treg = FIELD_PREP(ARM_SMMU_S2CR_TYPE, type) |\n\t      FIELD_PREP(ARM_SMMU_S2CR_CBNDX, cbndx) |\n\t      FIELD_PREP(ARM_SMMU_S2CR_PRIVCFG, s2cr->privcfg);\n\tarm_smmu_gr0_write(smmu, ARM_SMMU_GR0_S2CR(idx), reg);\n}\n\nstatic int qcom_smmu_def_domain_type(struct device *dev)\n{\n\tconst struct of_device_id *match =\n\t\tof_match_device(qcom_smmu_client_of_match, dev);\n\n\treturn match ? IOMMU_DOMAIN_IDENTITY : 0;\n}\n\nstatic int qcom_sdm845_smmu500_reset(struct arm_smmu_device *smmu)\n{\n\tint ret;\n\n\tarm_mmu500_reset(smmu);\n\n\t \n\tret = qcom_scm_qsmmu500_wait_safe_toggle(0);\n\tif (ret)\n\t\tdev_warn(smmu->dev, \"Failed to turn off SAFE logic\\n\");\n\n\treturn ret;\n}\n\nstatic const struct arm_smmu_impl qcom_smmu_v2_impl = {\n\t.init_context = qcom_smmu_init_context,\n\t.cfg_probe = qcom_smmu_cfg_probe,\n\t.def_domain_type = qcom_smmu_def_domain_type,\n\t.write_s2cr = qcom_smmu_write_s2cr,\n\t.tlb_sync = qcom_smmu_tlb_sync,\n};\n\nstatic const struct arm_smmu_impl qcom_smmu_500_impl = {\n\t.init_context = qcom_smmu_init_context,\n\t.cfg_probe = qcom_smmu_cfg_probe,\n\t.def_domain_type = qcom_smmu_def_domain_type,\n\t.reset = arm_mmu500_reset,\n\t.write_s2cr = qcom_smmu_write_s2cr,\n\t.tlb_sync = qcom_smmu_tlb_sync,\n};\n\nstatic const struct arm_smmu_impl sdm845_smmu_500_impl = {\n\t.init_context = qcom_smmu_init_context,\n\t.cfg_probe = qcom_smmu_cfg_probe,\n\t.def_domain_type = qcom_smmu_def_domain_type,\n\t.reset = qcom_sdm845_smmu500_reset,\n\t.write_s2cr = qcom_smmu_write_s2cr,\n\t.tlb_sync = qcom_smmu_tlb_sync,\n};\n\nstatic const struct arm_smmu_impl qcom_adreno_smmu_v2_impl = {\n\t.init_context = qcom_adreno_smmu_init_context,\n\t.def_domain_type = qcom_smmu_def_domain_type,\n\t.alloc_context_bank = qcom_adreno_smmu_alloc_context_bank,\n\t.write_sctlr = qcom_adreno_smmu_write_sctlr,\n\t.tlb_sync = qcom_smmu_tlb_sync,\n};\n\nstatic const struct arm_smmu_impl qcom_adreno_smmu_500_impl = {\n\t.init_context = qcom_adreno_smmu_init_context,\n\t.def_domain_type = qcom_smmu_def_domain_type,\n\t.reset = arm_mmu500_reset,\n\t.alloc_context_bank = qcom_adreno_smmu_alloc_context_bank,\n\t.write_sctlr = qcom_adreno_smmu_write_sctlr,\n\t.tlb_sync = qcom_smmu_tlb_sync,\n};\n\nstatic struct arm_smmu_device *qcom_smmu_create(struct arm_smmu_device *smmu,\n\t\tconst struct qcom_smmu_match_data *data)\n{\n\tconst struct device_node *np = smmu->dev->of_node;\n\tconst struct arm_smmu_impl *impl;\n\tstruct qcom_smmu *qsmmu;\n\n\tif (!data)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (np && of_device_is_compatible(np, \"qcom,adreno-smmu\"))\n\t\timpl = data->adreno_impl;\n\telse\n\t\timpl = data->impl;\n\n\tif (!impl)\n\t\treturn smmu;\n\n\t \n\tif (!qcom_scm_is_available())\n\t\treturn ERR_PTR(-EPROBE_DEFER);\n\n\tqsmmu = devm_krealloc(smmu->dev, smmu, sizeof(*qsmmu), GFP_KERNEL);\n\tif (!qsmmu)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tqsmmu->smmu.impl = impl;\n\tqsmmu->cfg = data->cfg;\n\n\treturn &qsmmu->smmu;\n}\n\n \nstatic const u32 qcom_smmu_impl0_reg_offset[] = {\n\t[QCOM_SMMU_TBU_PWR_STATUS]\t\t= 0x2204,\n\t[QCOM_SMMU_STATS_SYNC_INV_TBU_ACK]\t= 0x25dc,\n\t[QCOM_SMMU_MMU2QSS_AND_SAFE_WAIT_CNTR]\t= 0x2670,\n};\n\nstatic const struct qcom_smmu_config qcom_smmu_impl0_cfg = {\n\t.reg_offset = qcom_smmu_impl0_reg_offset,\n};\n\n \nstatic const struct qcom_smmu_match_data msm8996_smmu_data = {\n\t.impl = NULL,\n\t.adreno_impl = &qcom_adreno_smmu_v2_impl,\n};\n\nstatic const struct qcom_smmu_match_data qcom_smmu_v2_data = {\n\t.impl = &qcom_smmu_v2_impl,\n\t.adreno_impl = &qcom_adreno_smmu_v2_impl,\n};\n\nstatic const struct qcom_smmu_match_data sdm845_smmu_500_data = {\n\t.impl = &sdm845_smmu_500_impl,\n\t \n\t \n};\n\nstatic const struct qcom_smmu_match_data qcom_smmu_500_impl0_data = {\n\t.impl = &qcom_smmu_500_impl,\n\t.adreno_impl = &qcom_adreno_smmu_500_impl,\n\t.cfg = &qcom_smmu_impl0_cfg,\n};\n\n \nstatic const struct of_device_id __maybe_unused qcom_smmu_impl_of_match[] = {\n\t{ .compatible = \"qcom,msm8996-smmu-v2\", .data = &msm8996_smmu_data },\n\t{ .compatible = \"qcom,msm8998-smmu-v2\", .data = &qcom_smmu_v2_data },\n\t{ .compatible = \"qcom,qcm2290-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,qdu1000-smmu-500\", .data = &qcom_smmu_500_impl0_data  },\n\t{ .compatible = \"qcom,sc7180-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sc7180-smmu-v2\", .data = &qcom_smmu_v2_data },\n\t{ .compatible = \"qcom,sc7280-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sc8180x-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sc8280xp-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sdm630-smmu-v2\", .data = &qcom_smmu_v2_data },\n\t{ .compatible = \"qcom,sdm845-smmu-v2\", .data = &qcom_smmu_v2_data },\n\t{ .compatible = \"qcom,sdm845-smmu-500\", .data = &sdm845_smmu_500_data },\n\t{ .compatible = \"qcom,sm6115-smmu-500\", .data = &qcom_smmu_500_impl0_data},\n\t{ .compatible = \"qcom,sm6125-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sm6350-smmu-v2\", .data = &qcom_smmu_v2_data },\n\t{ .compatible = \"qcom,sm6350-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sm6375-smmu-v2\", .data = &qcom_smmu_v2_data },\n\t{ .compatible = \"qcom,sm6375-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sm8150-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sm8250-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sm8350-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,sm8450-smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ .compatible = \"qcom,smmu-500\", .data = &qcom_smmu_500_impl0_data },\n\t{ }\n};\n\n#ifdef CONFIG_ACPI\nstatic struct acpi_platform_list qcom_acpi_platlist[] = {\n\t{ \"LENOVO\", \"CB-01   \", 0x8180, ACPI_SIG_IORT, equal, \"QCOM SMMU\" },\n\t{ \"QCOM  \", \"QCOMEDK2\", 0x8180, ACPI_SIG_IORT, equal, \"QCOM SMMU\" },\n\t{ }\n};\n#endif\n\nstruct arm_smmu_device *qcom_smmu_impl_init(struct arm_smmu_device *smmu)\n{\n\tconst struct device_node *np = smmu->dev->of_node;\n\tconst struct of_device_id *match;\n\n#ifdef CONFIG_ACPI\n\tif (np == NULL) {\n\t\t \n\t\tif (acpi_match_platform_list(qcom_acpi_platlist) >= 0)\n\t\t\treturn qcom_smmu_create(smmu, &qcom_smmu_500_impl0_data);\n\t}\n#endif\n\n\tmatch = of_match_node(qcom_smmu_impl_of_match, np);\n\tif (match)\n\t\treturn qcom_smmu_create(smmu, match->data);\n\n\t \n\tWARN(of_device_is_compatible(np, \"qcom,adreno-smmu\"),\n\t     \"Missing qcom_smmu_impl_of_match entry for: %s\",\n\t     dev_name(smmu->dev));\n\n\treturn smmu;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}