{
  "module_name": "amd_iommu_types.h",
  "hash_id": "1756b52dc8dcd5544321d01119244cb199064f6aba4ebc3cdb4792fdc84d2e3b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/amd/amd_iommu_types.h",
  "human_readable_source": " \n \n\n#ifndef _ASM_X86_AMD_IOMMU_TYPES_H\n#define _ASM_X86_AMD_IOMMU_TYPES_H\n\n#include <linux/types.h>\n#include <linux/mutex.h>\n#include <linux/msi.h>\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/pci.h>\n#include <linux/irqreturn.h>\n#include <linux/io-pgtable.h>\n\n \n#define MAX_IOMMUS\t32\n\n \n#define DEV_TABLE_ENTRY_SIZE\t\t32\n#define ALIAS_TABLE_ENTRY_SIZE\t\t2\n#define RLOOKUP_TABLE_ENTRY_SIZE\t(sizeof(void *))\n\n \n#define MMIO_CAP_HDR_OFFSET\t0x00\n#define MMIO_RANGE_OFFSET\t0x0c\n#define MMIO_MISC_OFFSET\t0x10\n\n \n#define MMIO_RANGE_LD_MASK\t0xff000000\n#define MMIO_RANGE_FD_MASK\t0x00ff0000\n#define MMIO_RANGE_BUS_MASK\t0x0000ff00\n#define MMIO_RANGE_LD_SHIFT\t24\n#define MMIO_RANGE_FD_SHIFT\t16\n#define MMIO_RANGE_BUS_SHIFT\t8\n#define MMIO_GET_LD(x)  (((x) & MMIO_RANGE_LD_MASK) >> MMIO_RANGE_LD_SHIFT)\n#define MMIO_GET_FD(x)  (((x) & MMIO_RANGE_FD_MASK) >> MMIO_RANGE_FD_SHIFT)\n#define MMIO_GET_BUS(x) (((x) & MMIO_RANGE_BUS_MASK) >> MMIO_RANGE_BUS_SHIFT)\n#define MMIO_MSI_NUM(x)\t((x) & 0x1f)\n\n \n#define MMIO_EXCL_ENABLE_MASK 0x01ULL\n#define MMIO_EXCL_ALLOW_MASK  0x02ULL\n\n \n#define MMIO_DEV_TABLE_OFFSET   0x0000\n#define MMIO_CMD_BUF_OFFSET     0x0008\n#define MMIO_EVT_BUF_OFFSET     0x0010\n#define MMIO_CONTROL_OFFSET     0x0018\n#define MMIO_EXCL_BASE_OFFSET   0x0020\n#define MMIO_EXCL_LIMIT_OFFSET  0x0028\n#define MMIO_EXT_FEATURES\t0x0030\n#define MMIO_PPR_LOG_OFFSET\t0x0038\n#define MMIO_GA_LOG_BASE_OFFSET\t0x00e0\n#define MMIO_GA_LOG_TAIL_OFFSET\t0x00e8\n#define MMIO_MSI_ADDR_LO_OFFSET\t0x015C\n#define MMIO_MSI_ADDR_HI_OFFSET\t0x0160\n#define MMIO_MSI_DATA_OFFSET\t0x0164\n#define MMIO_INTCAPXT_EVT_OFFSET\t0x0170\n#define MMIO_INTCAPXT_PPR_OFFSET\t0x0178\n#define MMIO_INTCAPXT_GALOG_OFFSET\t0x0180\n#define MMIO_EXT_FEATURES2\t0x01A0\n#define MMIO_CMD_HEAD_OFFSET\t0x2000\n#define MMIO_CMD_TAIL_OFFSET\t0x2008\n#define MMIO_EVT_HEAD_OFFSET\t0x2010\n#define MMIO_EVT_TAIL_OFFSET\t0x2018\n#define MMIO_STATUS_OFFSET\t0x2020\n#define MMIO_PPR_HEAD_OFFSET\t0x2030\n#define MMIO_PPR_TAIL_OFFSET\t0x2038\n#define MMIO_GA_HEAD_OFFSET\t0x2040\n#define MMIO_GA_TAIL_OFFSET\t0x2048\n#define MMIO_CNTR_CONF_OFFSET\t0x4000\n#define MMIO_CNTR_REG_OFFSET\t0x40000\n#define MMIO_REG_END_OFFSET\t0x80000\n\n\n\n \n#define FEATURE_PREFETCH\tBIT_ULL(0)\n#define FEATURE_PPR\t\tBIT_ULL(1)\n#define FEATURE_X2APIC\t\tBIT_ULL(2)\n#define FEATURE_NX\t\tBIT_ULL(3)\n#define FEATURE_GT\t\tBIT_ULL(4)\n#define FEATURE_IA\t\tBIT_ULL(6)\n#define FEATURE_GA\t\tBIT_ULL(7)\n#define FEATURE_HE\t\tBIT_ULL(8)\n#define FEATURE_PC\t\tBIT_ULL(9)\n#define FEATURE_GATS_SHIFT\t(12)\n#define FEATURE_GATS_MASK\t(3ULL)\n#define FEATURE_GAM_VAPIC\tBIT_ULL(21)\n#define FEATURE_GIOSUP\t\tBIT_ULL(48)\n#define FEATURE_EPHSUP\t\tBIT_ULL(50)\n#define FEATURE_SNP\t\tBIT_ULL(63)\n\n#define FEATURE_PASID_SHIFT\t32\n#define FEATURE_PASID_MASK\t(0x1fULL << FEATURE_PASID_SHIFT)\n\n#define FEATURE_GLXVAL_SHIFT\t14\n#define FEATURE_GLXVAL_MASK\t(0x03ULL << FEATURE_GLXVAL_SHIFT)\n\n \n#define FEATURE_SNPAVICSUP_SHIFT\t5\n#define FEATURE_SNPAVICSUP_MASK\t\t(0x07ULL << FEATURE_SNPAVICSUP_SHIFT)\n#define FEATURE_SNPAVICSUP_GAM(x) \\\n\t((x & FEATURE_SNPAVICSUP_MASK) >> FEATURE_SNPAVICSUP_SHIFT == 0x1)\n\n \n#define PASID_MASK\t\t0x0000ffff\n\n \n#define MMIO_STATUS_EVT_OVERFLOW_MASK\t\tBIT(0)\n#define MMIO_STATUS_EVT_INT_MASK\t\tBIT(1)\n#define MMIO_STATUS_COM_WAIT_INT_MASK\t\tBIT(2)\n#define MMIO_STATUS_EVT_RUN_MASK\t\tBIT(3)\n#define MMIO_STATUS_PPR_OVERFLOW_MASK\t\tBIT(5)\n#define MMIO_STATUS_PPR_INT_MASK\t\tBIT(6)\n#define MMIO_STATUS_PPR_RUN_MASK\t\tBIT(7)\n#define MMIO_STATUS_GALOG_RUN_MASK\t\tBIT(8)\n#define MMIO_STATUS_GALOG_OVERFLOW_MASK\t\tBIT(9)\n#define MMIO_STATUS_GALOG_INT_MASK\t\tBIT(10)\n\n \n#define EVENT_ENTRY_SIZE\t0x10\n#define EVENT_TYPE_SHIFT\t28\n#define EVENT_TYPE_MASK\t\t0xf\n#define EVENT_TYPE_ILL_DEV\t0x1\n#define EVENT_TYPE_IO_FAULT\t0x2\n#define EVENT_TYPE_DEV_TAB_ERR\t0x3\n#define EVENT_TYPE_PAGE_TAB_ERR\t0x4\n#define EVENT_TYPE_ILL_CMD\t0x5\n#define EVENT_TYPE_CMD_HARD_ERR\t0x6\n#define EVENT_TYPE_IOTLB_INV_TO\t0x7\n#define EVENT_TYPE_INV_DEV_REQ\t0x8\n#define EVENT_TYPE_INV_PPR_REQ\t0x9\n#define EVENT_TYPE_RMP_FAULT\t0xd\n#define EVENT_TYPE_RMP_HW_ERR\t0xe\n#define EVENT_DEVID_MASK\t0xffff\n#define EVENT_DEVID_SHIFT\t0\n#define EVENT_DOMID_MASK_LO\t0xffff\n#define EVENT_DOMID_MASK_HI\t0xf0000\n#define EVENT_FLAGS_MASK\t0xfff\n#define EVENT_FLAGS_SHIFT\t0x10\n#define EVENT_FLAG_RW\t\t0x020\n#define EVENT_FLAG_I\t\t0x008\n\n \n#define CONTROL_IOMMU_EN\t0\n#define CONTROL_HT_TUN_EN\t1\n#define CONTROL_EVT_LOG_EN\t2\n#define CONTROL_EVT_INT_EN\t3\n#define CONTROL_COMWAIT_EN\t4\n#define CONTROL_INV_TIMEOUT\t5\n#define CONTROL_PASSPW_EN\t8\n#define CONTROL_RESPASSPW_EN\t9\n#define CONTROL_COHERENT_EN\t10\n#define CONTROL_ISOC_EN\t\t11\n#define CONTROL_CMDBUF_EN\t12\n#define CONTROL_PPRLOG_EN\t13\n#define CONTROL_PPRINT_EN\t14\n#define CONTROL_PPR_EN\t\t15\n#define CONTROL_GT_EN\t\t16\n#define CONTROL_GA_EN\t\t17\n#define CONTROL_GAM_EN\t\t25\n#define CONTROL_GALOG_EN\t28\n#define CONTROL_GAINT_EN\t29\n#define CONTROL_XT_EN\t\t50\n#define CONTROL_INTCAPXT_EN\t51\n#define CONTROL_IRTCACHEDIS\t59\n#define CONTROL_SNPAVIC_EN\t61\n\n#define CTRL_INV_TO_MASK\t(7 << CONTROL_INV_TIMEOUT)\n#define CTRL_INV_TO_NONE\t0\n#define CTRL_INV_TO_1MS\t\t1\n#define CTRL_INV_TO_10MS\t2\n#define CTRL_INV_TO_100MS\t3\n#define CTRL_INV_TO_1S\t\t4\n#define CTRL_INV_TO_10S\t\t5\n#define CTRL_INV_TO_100S\t6\n\n \n#define CMD_COMPL_WAIT          0x01\n#define CMD_INV_DEV_ENTRY       0x02\n#define CMD_INV_IOMMU_PAGES\t0x03\n#define CMD_INV_IOTLB_PAGES\t0x04\n#define CMD_INV_IRT\t\t0x05\n#define CMD_COMPLETE_PPR\t0x07\n#define CMD_INV_ALL\t\t0x08\n\n#define CMD_COMPL_WAIT_STORE_MASK\t0x01\n#define CMD_COMPL_WAIT_INT_MASK\t\t0x02\n#define CMD_INV_IOMMU_PAGES_SIZE_MASK\t0x01\n#define CMD_INV_IOMMU_PAGES_PDE_MASK\t0x02\n#define CMD_INV_IOMMU_PAGES_GN_MASK\t0x04\n\n#define PPR_STATUS_MASK\t\t\t0xf\n#define PPR_STATUS_SHIFT\t\t12\n\n#define CMD_INV_IOMMU_ALL_PAGES_ADDRESS\t0x7fffffffffffffffULL\n\n \n#define DEV_ENTRY_VALID         0x00\n#define DEV_ENTRY_TRANSLATION   0x01\n#define DEV_ENTRY_PPR           0x34\n#define DEV_ENTRY_IR            0x3d\n#define DEV_ENTRY_IW            0x3e\n#define DEV_ENTRY_NO_PAGE_FAULT\t0x62\n#define DEV_ENTRY_EX            0x67\n#define DEV_ENTRY_SYSMGT1       0x68\n#define DEV_ENTRY_SYSMGT2       0x69\n#define DEV_ENTRY_IRQ_TBL_EN\t0x80\n#define DEV_ENTRY_INIT_PASS     0xb8\n#define DEV_ENTRY_EINT_PASS     0xb9\n#define DEV_ENTRY_NMI_PASS      0xba\n#define DEV_ENTRY_LINT0_PASS    0xbe\n#define DEV_ENTRY_LINT1_PASS    0xbf\n#define DEV_ENTRY_MODE_MASK\t0x07\n#define DEV_ENTRY_MODE_SHIFT\t0x09\n\n#define MAX_DEV_TABLE_ENTRIES\t0xffff\n\n \n#define CMD_BUFFER_SIZE    8192\n#define CMD_BUFFER_UNINITIALIZED 1\n#define CMD_BUFFER_ENTRIES 512\n#define MMIO_CMD_SIZE_SHIFT 56\n#define MMIO_CMD_SIZE_512 (0x9ULL << MMIO_CMD_SIZE_SHIFT)\n\n \n#define EVT_BUFFER_SIZE\t\t8192  \n#define EVT_LEN_MASK\t\t(0x9ULL << 56)\n\n \n#define PPR_LOG_ENTRIES\t\t512\n#define PPR_LOG_SIZE_SHIFT\t56\n#define PPR_LOG_SIZE_512\t(0x9ULL << PPR_LOG_SIZE_SHIFT)\n#define PPR_ENTRY_SIZE\t\t16\n#define PPR_LOG_SIZE\t\t(PPR_ENTRY_SIZE * PPR_LOG_ENTRIES)\n\n#define PPR_REQ_TYPE(x)\t\t(((x) >> 60) & 0xfULL)\n#define PPR_FLAGS(x)\t\t(((x) >> 48) & 0xfffULL)\n#define PPR_DEVID(x)\t\t((x) & 0xffffULL)\n#define PPR_TAG(x)\t\t(((x) >> 32) & 0x3ffULL)\n#define PPR_PASID1(x)\t\t(((x) >> 16) & 0xffffULL)\n#define PPR_PASID2(x)\t\t(((x) >> 42) & 0xfULL)\n#define PPR_PASID(x)\t\t((PPR_PASID2(x) << 16) | PPR_PASID1(x))\n\n#define PPR_REQ_FAULT\t\t0x01\n\n \n#define GA_LOG_ENTRIES\t\t512\n#define GA_LOG_SIZE_SHIFT\t56\n#define GA_LOG_SIZE_512\t\t(0x8ULL << GA_LOG_SIZE_SHIFT)\n#define GA_ENTRY_SIZE\t\t8\n#define GA_LOG_SIZE\t\t(GA_ENTRY_SIZE * GA_LOG_ENTRIES)\n\n#define GA_TAG(x)\t\t(u32)(x & 0xffffffffULL)\n#define GA_DEVID(x)\t\t(u16)(((x) >> 32) & 0xffffULL)\n#define GA_REQ_TYPE(x)\t\t(((x) >> 60) & 0xfULL)\n\n#define GA_GUEST_NR\t\t0x1\n\n#define IOMMU_IN_ADDR_BIT_SIZE  52\n#define IOMMU_OUT_ADDR_BIT_SIZE 52\n\n \n#define AMD_IOMMU_PGSIZES\t((~0xFFFUL) & ~(2ULL << 38))\n \n#define AMD_IOMMU_PGSIZES_V2\t(PAGE_SIZE | (1ULL << 21) | (1ULL << 30))\n\n \n#define DTE_IRQ_PHYS_ADDR_MASK\t\tGENMASK_ULL(51, 6)\n#define DTE_IRQ_REMAP_INTCTL_MASK\t(0x3ULL << 60)\n#define DTE_IRQ_REMAP_INTCTL    (2ULL << 60)\n#define DTE_IRQ_REMAP_ENABLE    1ULL\n\n \n#define DTE_INTTAB_ALIGNMENT    128\n#define DTE_INTTABLEN_VALUE     9ULL\n#define DTE_INTTABLEN           (DTE_INTTABLEN_VALUE << 1)\n#define DTE_INTTABLEN_MASK      (0xfULL << 1)\n#define MAX_IRQS_PER_TABLE      (1 << DTE_INTTABLEN_VALUE)\n\n#define PAGE_MODE_NONE    0x00\n#define PAGE_MODE_1_LEVEL 0x01\n#define PAGE_MODE_2_LEVEL 0x02\n#define PAGE_MODE_3_LEVEL 0x03\n#define PAGE_MODE_4_LEVEL 0x04\n#define PAGE_MODE_5_LEVEL 0x05\n#define PAGE_MODE_6_LEVEL 0x06\n#define PAGE_MODE_7_LEVEL 0x07\n\n#define GUEST_PGTABLE_4_LEVEL\t0x00\n#define GUEST_PGTABLE_5_LEVEL\t0x01\n\n#define PM_LEVEL_SHIFT(x)\t(12 + ((x) * 9))\n#define PM_LEVEL_SIZE(x)\t(((x) < 6) ? \\\n\t\t\t\t  ((1ULL << PM_LEVEL_SHIFT((x))) - 1): \\\n\t\t\t\t   (0xffffffffffffffffULL))\n#define PM_LEVEL_INDEX(x, a)\t(((a) >> PM_LEVEL_SHIFT((x))) & 0x1ffULL)\n#define PM_LEVEL_ENC(x)\t\t(((x) << 9) & 0xe00ULL)\n#define PM_LEVEL_PDE(x, a)\t((a) | PM_LEVEL_ENC((x)) | \\\n\t\t\t\t IOMMU_PTE_PR | IOMMU_PTE_IR | IOMMU_PTE_IW)\n#define PM_PTE_LEVEL(pte)\t(((pte) >> 9) & 0x7ULL)\n\n#define PM_MAP_4k\t\t0\n#define PM_ADDR_MASK\t\t0x000ffffffffff000ULL\n#define PM_MAP_MASK(lvl)\t(PM_ADDR_MASK & \\\n\t\t\t\t(~((1ULL << (12 + ((lvl) * 9))) - 1)))\n#define PM_ALIGNED(lvl, addr)\t((PM_MAP_MASK(lvl) & (addr)) == (addr))\n\n \n#define PAGE_SIZE_LEVEL(pagesize) \\\n\t\t((__ffs(pagesize) - 12) / 9)\n \n#define PAGE_SIZE_PTE_COUNT(pagesize) \\\n\t\t(1ULL << ((__ffs(pagesize) - 12) % 9))\n\n \n#define PAGE_SIZE_ALIGN(address, pagesize) \\\n\t\t((address) & ~((pagesize) - 1))\n \n#define PAGE_SIZE_PTE(address, pagesize)\t\t\\\n\t\t(((address) | ((pagesize) - 1)) &\t\\\n\t\t (~(pagesize >> 1)) & PM_ADDR_MASK)\n\n \n#define PTE_PAGE_SIZE(pte) \\\n\t(1ULL << (1 + ffz(((pte) | 0xfffULL))))\n\n \n#define PTE_LEVEL_PAGE_SIZE(level)\t\t\t\\\n\t(1ULL << (12 + (9 * (level))))\n\n \n#define IOMMU_PTE_PR\tBIT_ULL(0)\n#define IOMMU_PTE_U\tBIT_ULL(59)\n#define IOMMU_PTE_FC\tBIT_ULL(60)\n#define IOMMU_PTE_IR\tBIT_ULL(61)\n#define IOMMU_PTE_IW\tBIT_ULL(62)\n\n \n#define DTE_FLAG_V\tBIT_ULL(0)\n#define DTE_FLAG_TV\tBIT_ULL(1)\n#define DTE_FLAG_GIOV\tBIT_ULL(54)\n#define DTE_FLAG_GV\tBIT_ULL(55)\n#define DTE_GLX_SHIFT\t(56)\n#define DTE_GLX_MASK\t(3)\n#define DTE_FLAG_IR\tBIT_ULL(61)\n#define DTE_FLAG_IW\tBIT_ULL(62)\n\n#define DTE_FLAG_IOTLB\tBIT_ULL(32)\n#define DTE_FLAG_MASK\t(0x3ffULL << 32)\n#define DEV_DOMID_MASK\t0xffffULL\n\n#define DTE_GCR3_VAL_A(x)\t(((x) >> 12) & 0x00007ULL)\n#define DTE_GCR3_VAL_B(x)\t(((x) >> 15) & 0x0ffffULL)\n#define DTE_GCR3_VAL_C(x)\t(((x) >> 31) & 0x1fffffULL)\n\n#define DTE_GCR3_INDEX_A\t0\n#define DTE_GCR3_INDEX_B\t1\n#define DTE_GCR3_INDEX_C\t1\n\n#define DTE_GCR3_SHIFT_A\t58\n#define DTE_GCR3_SHIFT_B\t16\n#define DTE_GCR3_SHIFT_C\t43\n\n#define DTE_GPT_LEVEL_SHIFT\t54\n\n#define GCR3_VALID\t\t0x01ULL\n\n#define IOMMU_PAGE_MASK (((1ULL << 52) - 1) & ~0xfffULL)\n#define IOMMU_PTE_PRESENT(pte) ((pte) & IOMMU_PTE_PR)\n#define IOMMU_PTE_PAGE(pte) (iommu_phys_to_virt((pte) & IOMMU_PAGE_MASK))\n#define IOMMU_PTE_MODE(pte) (((pte) >> 9) & 0x07)\n\n#define IOMMU_PROT_MASK 0x03\n#define IOMMU_PROT_IR 0x01\n#define IOMMU_PROT_IW 0x02\n\n#define IOMMU_UNITY_MAP_FLAG_EXCL_RANGE\t(1 << 2)\n\n \n#define IOMMU_CAP_IOTLB   24\n#define IOMMU_CAP_NPCACHE 26\n#define IOMMU_CAP_EFR     27\n\n \n#define IOMMU_IVINFO_OFFSET     36\n#define IOMMU_IVINFO_EFRSUP     BIT(0)\n#define IOMMU_IVINFO_DMA_REMAP  BIT(1)\n\n \n#define IOMMU_FEAT_GASUP_SHIFT\t6\n\n \n#define IOMMU_EFR_XTSUP_SHIFT\t2\n#define IOMMU_EFR_GASUP_SHIFT\t7\n#define IOMMU_EFR_MSICAPMMIOSUP_SHIFT\t46\n\n#define MAX_DOMAIN_ID 65536\n\n \n#define PD_DMA_OPS_MASK\t\tBIT(0)  \n#define PD_DEFAULT_MASK\t\tBIT(1)  \n#define PD_PASSTHROUGH_MASK\tBIT(2)  \n#define PD_IOMMUV2_MASK\t\tBIT(3)  \n#define PD_GIOV_MASK\t\tBIT(4)  \n\nextern bool amd_iommu_dump;\n#define DUMP_printk(format, arg...)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tif (amd_iommu_dump)\t\t\t\t\\\n\t\t\tpr_info(\"AMD-Vi: \" format, ## arg);\t\\\n\t} while(0);\n\n \nextern bool amd_iommu_np_cache;\n \nextern bool amd_iommu_iotlb_sup;\n\nstruct irq_remap_table {\n\traw_spinlock_t lock;\n\tunsigned min_index;\n\tu32 *table;\n};\n\n \nextern bool amd_iommu_irq_remap;\n\nextern const struct iommu_ops amd_iommu_ops;\n\n \nextern bool amdr_ivrs_remap_support;\n\n \nextern struct kmem_cache *amd_iommu_irq_cache;\n\n#define PCI_SBDF_TO_SEGID(sbdf)\t\t(((sbdf) >> 16) & 0xffff)\n#define PCI_SBDF_TO_DEVID(sbdf)\t\t((sbdf) & 0xffff)\n#define PCI_SEG_DEVID_TO_SBDF(seg, devid)\t((((u32)(seg) & 0xffff) << 16) | \\\n\t\t\t\t\t\t ((devid) & 0xffff))\n\n \n#define for_each_pci_segment(pci_seg) \\\n\tlist_for_each_entry((pci_seg), &amd_iommu_pci_seg_list, list)\n#define for_each_pci_segment_safe(pci_seg, next) \\\n\tlist_for_each_entry_safe((pci_seg), (next), &amd_iommu_pci_seg_list, list)\n \n#define for_each_iommu(iommu) \\\n\tlist_for_each_entry((iommu), &amd_iommu_list, list)\n#define for_each_iommu_safe(iommu, next) \\\n\tlist_for_each_entry_safe((iommu), (next), &amd_iommu_list, list)\n\n#define APERTURE_RANGE_SHIFT\t27\t \n#define APERTURE_RANGE_SIZE\t(1ULL << APERTURE_RANGE_SHIFT)\n#define APERTURE_RANGE_PAGES\t(APERTURE_RANGE_SIZE >> PAGE_SHIFT)\n#define APERTURE_MAX_RANGES\t32\t \n#define APERTURE_RANGE_INDEX(a)\t((a) >> APERTURE_RANGE_SHIFT)\n#define APERTURE_PAGE_INDEX(a)\t(((a) >> 21) & 0x3fULL)\n\n \nstruct amd_iommu_fault {\n\tu64 address;     \n\tu32 pasid;       \n\tu32 sbdf;\t \n\tu16 tag;         \n\tu16 flags;       \n\n};\n\n\nstruct amd_iommu;\nstruct iommu_domain;\nstruct irq_domain;\nstruct amd_irte_ops;\n\n#define AMD_IOMMU_FLAG_TRANS_PRE_ENABLED      (1 << 0)\n\n#define io_pgtable_to_data(x) \\\n\tcontainer_of((x), struct amd_io_pgtable, iop)\n\n#define io_pgtable_ops_to_data(x) \\\n\tio_pgtable_to_data(io_pgtable_ops_to_pgtable(x))\n\n#define io_pgtable_ops_to_domain(x) \\\n\tcontainer_of(io_pgtable_ops_to_data(x), \\\n\t\t     struct protection_domain, iop)\n\n#define io_pgtable_cfg_to_data(x) \\\n\tcontainer_of((x), struct amd_io_pgtable, pgtbl_cfg)\n\nstruct amd_io_pgtable {\n\tstruct io_pgtable_cfg\tpgtbl_cfg;\n\tstruct io_pgtable\tiop;\n\tint\t\t\tmode;\n\tu64\t\t\t*root;\n\tatomic64_t\t\tpt_root;\t \n\tu64\t\t\t*pgd;\t\t \n};\n\n \nstruct protection_domain {\n\tstruct list_head dev_list;  \n\tstruct iommu_domain domain;  \n\tstruct amd_io_pgtable iop;\n\tspinlock_t lock;\t \n\tu16 id;\t\t\t \n\tint glx;\t\t \n\tint nid;\t\t \n\tu64 *gcr3_tbl;\t\t \n\tunsigned long flags;\t \n\tunsigned dev_cnt;\t \n\tunsigned dev_iommu[MAX_IOMMUS];  \n};\n\n \nstruct amd_iommu_pci_seg {\n\t \n\tstruct list_head list;\n\n\t \n\tstruct llist_head dev_data_list;\n\n\t \n\tu16 id;\n\n\t \n\tu16 last_bdf;\n\n\t \n\tu32 dev_table_size;\n\n\t \n\tu32 alias_table_size;\n\n\t \n\tu32 rlookup_table_size;\n\n\t \n\tstruct dev_table_entry *dev_table;\n\n\t \n\tstruct amd_iommu **rlookup_table;\n\n\t \n\tstruct irq_remap_table **irq_lookup_table;\n\n\t \n\tstruct dev_table_entry *old_dev_tbl_cpy;\n\n\t \n\tu16 *alias_table;\n\n\t \n\tstruct list_head unity_map;\n};\n\n \nstruct amd_iommu {\n\tstruct list_head list;\n\n\t \n\tint index;\n\n\t \n\traw_spinlock_t lock;\n\n\t \n\tstruct pci_dev *dev;\n\n\t \n\tstruct pci_dev *root_pdev;\n\n\t \n\tu64 mmio_phys;\n\n\t \n\tu64 mmio_phys_end;\n\n\t \n\tu8 __iomem *mmio_base;\n\n\t \n\tu32 cap;\n\n\t \n\tu8 acpi_flags;\n\n\t \n\tu64 features;\n\n\t \n\tu64 features2;\n\n\t \n\tbool is_iommu_v2;\n\n\t \n\tu16 devid;\n\n\t \n\tu16 cap_ptr;\n\n\t \n\tstruct amd_iommu_pci_seg *pci_seg;\n\n\t \n\tu64 exclusion_start;\n\t \n\tu64 exclusion_length;\n\n\t \n\tu8 *cmd_buf;\n\tu32 cmd_buf_head;\n\tu32 cmd_buf_tail;\n\n\t \n\tu8 *evt_buf;\n\n\t \n\tunsigned char evt_irq_name[16];\n\n\t \n\tu8 *ppr_log;\n\n\t \n\tunsigned char ppr_irq_name[16];\n\n\t \n\tu8 *ga_log;\n\n\t \n\tunsigned char ga_irq_name[16];\n\n\t \n\tu8 *ga_log_tail;\n\n\t \n\tbool int_enabled;\n\n\t \n\tbool need_sync;\n\n\t \n\tbool irtcachedis_enabled;\n\n\t \n\tstruct iommu_device iommu;\n\n\t \n\n\t \n\tu32 stored_addr_lo;\n\tu32 stored_addr_hi;\n\n\t \n\tu32 stored_l1[6][0x12];\n\n\t \n\tu32 stored_l2[0x83];\n\n\t \n\tu8 max_banks;\n\tu8 max_counters;\n#ifdef CONFIG_IRQ_REMAP\n\tstruct irq_domain *ir_domain;\n\n\tstruct amd_irte_ops *irte_ops;\n#endif\n\n\tu32 flags;\n\tvolatile u64 *cmd_sem;\n\tatomic64_t cmd_sem_val;\n\n#ifdef CONFIG_AMD_IOMMU_DEBUGFS\n\t \n\tstruct dentry *debugfs;\n#endif\n};\n\nstatic inline struct amd_iommu *dev_to_amd_iommu(struct device *dev)\n{\n\tstruct iommu_device *iommu = dev_to_iommu_device(dev);\n\n\treturn container_of(iommu, struct amd_iommu, iommu);\n}\n\n#define ACPIHID_UID_LEN 256\n#define ACPIHID_HID_LEN 9\n\nstruct acpihid_map_entry {\n\tstruct list_head list;\n\tu8 uid[ACPIHID_UID_LEN];\n\tu8 hid[ACPIHID_HID_LEN];\n\tu32 devid;\n\tu32 root_devid;\n\tbool cmd_line;\n\tstruct iommu_group *group;\n};\n\nstruct devid_map {\n\tstruct list_head list;\n\tu8 id;\n\tu32 devid;\n\tbool cmd_line;\n};\n\n \nstruct iommu_dev_data {\n\t \n\tspinlock_t lock;\n\n\tstruct list_head list;\t\t   \n\tstruct llist_node dev_data_list;   \n\tstruct protection_domain *domain;  \n\tstruct device *dev;\n\tu16 devid;\t\t\t   \n\tbool iommu_v2;\t\t\t   \n\tstruct {\n\t\tbool enabled;\n\t\tint qdep;\n\t} ats;\t\t\t\t   \n\tbool pri_tlp;\t\t\t   \n\tbool use_vapic;\t\t\t   \n\tbool defer_attach;\n\n\tstruct ratelimit_state rs;         \n};\n\n \nextern struct list_head ioapic_map;\nextern struct list_head hpet_map;\nextern struct list_head acpihid_map;\n\n \nextern struct list_head amd_iommu_pci_seg_list;\n\n \nextern struct list_head amd_iommu_list;\n\n \nextern struct amd_iommu *amd_iommus[MAX_IOMMUS];\n\n \nstruct dev_table_entry {\n\tu64 data[4];\n};\n\n \nstruct unity_map_entry {\n\tstruct list_head list;\n\n\t \n\tu16 devid_start;\n\t \n\tu16 devid_end;\n\n\t \n\tu64 address_start;\n\t \n\tu64 address_end;\n\n\t \n\tint prot;\n};\n\n \n\n \nextern unsigned amd_iommu_aperture_order;\n\n \nextern unsigned long *amd_iommu_pd_alloc_bitmap;\n\n \nextern u32 amd_iommu_max_pasid;\n\nextern bool amd_iommu_v2_present;\n\nextern bool amd_iommu_force_isolation;\n\n \nextern int amd_iommu_max_glx_val;\n\n \nvoid iommu_flush_all_caches(struct amd_iommu *iommu);\n\nstatic inline int get_ioapic_devid(int id)\n{\n\tstruct devid_map *entry;\n\n\tlist_for_each_entry(entry, &ioapic_map, list) {\n\t\tif (entry->id == id)\n\t\t\treturn entry->devid;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic inline int get_hpet_devid(int id)\n{\n\tstruct devid_map *entry;\n\n\tlist_for_each_entry(entry, &hpet_map, list) {\n\t\tif (entry->id == id)\n\t\t\treturn entry->devid;\n\t}\n\n\treturn -EINVAL;\n}\n\nenum amd_iommu_intr_mode_type {\n\tAMD_IOMMU_GUEST_IR_LEGACY,\n\n\t \n\tAMD_IOMMU_GUEST_IR_LEGACY_GA,\n\tAMD_IOMMU_GUEST_IR_VAPIC,\n};\n\n#define AMD_IOMMU_GUEST_IR_GA(x)\t(x == AMD_IOMMU_GUEST_IR_VAPIC || \\\n\t\t\t\t\t x == AMD_IOMMU_GUEST_IR_LEGACY_GA)\n\n#define AMD_IOMMU_GUEST_IR_VAPIC(x)\t(x == AMD_IOMMU_GUEST_IR_VAPIC)\n\nunion irte {\n\tu32 val;\n\tstruct {\n\t\tu32 valid\t: 1,\n\t\t    no_fault\t: 1,\n\t\t    int_type\t: 3,\n\t\t    rq_eoi\t: 1,\n\t\t    dm\t\t: 1,\n\t\t    rsvd_1\t: 1,\n\t\t    destination\t: 8,\n\t\t    vector\t: 8,\n\t\t    rsvd_2\t: 8;\n\t} fields;\n};\n\n#define APICID_TO_IRTE_DEST_LO(x)    (x & 0xffffff)\n#define APICID_TO_IRTE_DEST_HI(x)    ((x >> 24) & 0xff)\n\nunion irte_ga_lo {\n\tu64 val;\n\n\t \n\tstruct {\n\t\tu64 valid\t: 1,\n\t\t    no_fault\t: 1,\n\t\t     \n\t\t    int_type\t: 3,\n\t\t    rq_eoi\t: 1,\n\t\t    dm\t\t: 1,\n\t\t     \n\t\t    guest_mode\t: 1,\n\t\t    destination\t: 24,\n\t\t    ga_tag\t: 32;\n\t} fields_remap;\n\n\t \n\tstruct {\n\t\tu64 valid\t: 1,\n\t\t    no_fault\t: 1,\n\t\t     \n\t\t    ga_log_intr\t: 1,\n\t\t    rsvd1\t: 3,\n\t\t    is_run\t: 1,\n\t\t     \n\t\t    guest_mode\t: 1,\n\t\t    destination\t: 24,\n\t\t    ga_tag\t: 32;\n\t} fields_vapic;\n};\n\nunion irte_ga_hi {\n\tu64 val;\n\tstruct {\n\t\tu64 vector\t: 8,\n\t\t    rsvd_1\t: 4,\n\t\t    ga_root_ptr\t: 40,\n\t\t    rsvd_2\t: 4,\n\t\t    destination : 8;\n\t} fields;\n};\n\nstruct irte_ga {\n\tunion {\n\t\tstruct {\n\t\t\tunion irte_ga_lo lo;\n\t\t\tunion irte_ga_hi hi;\n\t\t};\n\t\tu128 irte;\n\t};\n};\n\nstruct irq_2_irte {\n\tu16 devid;  \n\tu16 index;  \n};\n\nstruct amd_ir_data {\n\tu32 cached_ga_tag;\n\tstruct amd_iommu *iommu;\n\tstruct irq_2_irte irq_2_irte;\n\tstruct msi_msg msi_entry;\n\tvoid *entry;     \n\n\t \n\tstruct irq_cfg *cfg;\n\tint ga_vector;\n\tu64 ga_root_ptr;\n\tu32 ga_tag;\n};\n\nstruct amd_irte_ops {\n\tvoid (*prepare)(void *, u32, bool, u8, u32, int);\n\tvoid (*activate)(struct amd_iommu *iommu, void *, u16, u16);\n\tvoid (*deactivate)(struct amd_iommu *iommu, void *, u16, u16);\n\tvoid (*set_affinity)(struct amd_iommu *iommu, void *, u16, u16, u8, u32);\n\tvoid *(*get)(struct irq_remap_table *, int);\n\tvoid (*set_allocated)(struct irq_remap_table *, int);\n\tbool (*is_allocated)(struct irq_remap_table *, int);\n\tvoid (*clear_allocated)(struct irq_remap_table *, int);\n};\n\n#ifdef CONFIG_IRQ_REMAP\nextern struct amd_irte_ops irte_32_ops;\nextern struct amd_irte_ops irte_128_ops;\n#endif\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}