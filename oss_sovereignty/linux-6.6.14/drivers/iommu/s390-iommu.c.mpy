{
  "module_name": "s390-iommu.c",
  "hash_id": "4c7132a8b75a150ee9ecb3741d4972c6d9f79a42ff4671d94888414db15fe2c6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/s390-iommu.c",
  "human_readable_source": "\n \n\n#include <linux/pci.h>\n#include <linux/iommu.h>\n#include <linux/iommu-helper.h>\n#include <linux/sizes.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <asm/pci_dma.h>\n\nstatic const struct iommu_ops s390_iommu_ops;\n\nstruct s390_domain {\n\tstruct iommu_domain\tdomain;\n\tstruct list_head\tdevices;\n\tunsigned long\t\t*dma_table;\n\tspinlock_t\t\tlist_lock;\n\tstruct rcu_head\t\trcu;\n};\n\nstatic struct s390_domain *to_s390_domain(struct iommu_domain *dom)\n{\n\treturn container_of(dom, struct s390_domain, domain);\n}\n\nstatic bool s390_iommu_capable(struct device *dev, enum iommu_cap cap)\n{\n\tswitch (cap) {\n\tcase IOMMU_CAP_CACHE_COHERENCY:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic struct iommu_domain *s390_domain_alloc(unsigned domain_type)\n{\n\tstruct s390_domain *s390_domain;\n\n\tif (domain_type != IOMMU_DOMAIN_UNMANAGED)\n\t\treturn NULL;\n\n\ts390_domain = kzalloc(sizeof(*s390_domain), GFP_KERNEL);\n\tif (!s390_domain)\n\t\treturn NULL;\n\n\ts390_domain->dma_table = dma_alloc_cpu_table(GFP_KERNEL);\n\tif (!s390_domain->dma_table) {\n\t\tkfree(s390_domain);\n\t\treturn NULL;\n\t}\n\ts390_domain->domain.geometry.force_aperture = true;\n\ts390_domain->domain.geometry.aperture_start = 0;\n\ts390_domain->domain.geometry.aperture_end = ZPCI_TABLE_SIZE_RT - 1;\n\n\tspin_lock_init(&s390_domain->list_lock);\n\tINIT_LIST_HEAD_RCU(&s390_domain->devices);\n\n\treturn &s390_domain->domain;\n}\n\nstatic void s390_iommu_rcu_free_domain(struct rcu_head *head)\n{\n\tstruct s390_domain *s390_domain = container_of(head, struct s390_domain, rcu);\n\n\tdma_cleanup_tables(s390_domain->dma_table);\n\tkfree(s390_domain);\n}\n\nstatic void s390_domain_free(struct iommu_domain *domain)\n{\n\tstruct s390_domain *s390_domain = to_s390_domain(domain);\n\n\trcu_read_lock();\n\tWARN_ON(!list_empty(&s390_domain->devices));\n\trcu_read_unlock();\n\n\tcall_rcu(&s390_domain->rcu, s390_iommu_rcu_free_domain);\n}\n\nstatic void __s390_iommu_detach_device(struct zpci_dev *zdev)\n{\n\tstruct s390_domain *s390_domain = zdev->s390_domain;\n\tunsigned long flags;\n\n\tif (!s390_domain)\n\t\treturn;\n\n\tspin_lock_irqsave(&s390_domain->list_lock, flags);\n\tlist_del_rcu(&zdev->iommu_list);\n\tspin_unlock_irqrestore(&s390_domain->list_lock, flags);\n\n\tzpci_unregister_ioat(zdev, 0);\n\tzdev->s390_domain = NULL;\n\tzdev->dma_table = NULL;\n}\n\nstatic int s390_iommu_attach_device(struct iommu_domain *domain,\n\t\t\t\t    struct device *dev)\n{\n\tstruct s390_domain *s390_domain = to_s390_domain(domain);\n\tstruct zpci_dev *zdev = to_zpci_dev(dev);\n\tunsigned long flags;\n\tu8 status;\n\tint cc;\n\n\tif (!zdev)\n\t\treturn -ENODEV;\n\n\tif (WARN_ON(domain->geometry.aperture_start > zdev->end_dma ||\n\t\tdomain->geometry.aperture_end < zdev->start_dma))\n\t\treturn -EINVAL;\n\n\tif (zdev->s390_domain)\n\t\t__s390_iommu_detach_device(zdev);\n\telse if (zdev->dma_table)\n\t\tzpci_dma_exit_device(zdev);\n\n\tcc = zpci_register_ioat(zdev, 0, zdev->start_dma, zdev->end_dma,\n\t\t\t\tvirt_to_phys(s390_domain->dma_table), &status);\n\t \n\tif (cc && status != ZPCI_PCI_ST_FUNC_NOT_AVAIL)\n\t\treturn -EIO;\n\tzdev->dma_table = s390_domain->dma_table;\n\n\tzdev->dma_table = s390_domain->dma_table;\n\tzdev->s390_domain = s390_domain;\n\n\tspin_lock_irqsave(&s390_domain->list_lock, flags);\n\tlist_add_rcu(&zdev->iommu_list, &s390_domain->devices);\n\tspin_unlock_irqrestore(&s390_domain->list_lock, flags);\n\n\treturn 0;\n}\n\nstatic void s390_iommu_set_platform_dma(struct device *dev)\n{\n\tstruct zpci_dev *zdev = to_zpci_dev(dev);\n\n\t__s390_iommu_detach_device(zdev);\n\tzpci_dma_init_device(zdev);\n}\n\nstatic void s390_iommu_get_resv_regions(struct device *dev,\n\t\t\t\t\tstruct list_head *list)\n{\n\tstruct zpci_dev *zdev = to_zpci_dev(dev);\n\tstruct iommu_resv_region *region;\n\n\tif (zdev->start_dma) {\n\t\tregion = iommu_alloc_resv_region(0, zdev->start_dma, 0,\n\t\t\t\t\t\t IOMMU_RESV_RESERVED, GFP_KERNEL);\n\t\tif (!region)\n\t\t\treturn;\n\t\tlist_add_tail(&region->list, list);\n\t}\n\n\tif (zdev->end_dma < ZPCI_TABLE_SIZE_RT - 1) {\n\t\tregion = iommu_alloc_resv_region(zdev->end_dma + 1,\n\t\t\t\t\t\t ZPCI_TABLE_SIZE_RT - zdev->end_dma - 1,\n\t\t\t\t\t\t 0, IOMMU_RESV_RESERVED, GFP_KERNEL);\n\t\tif (!region)\n\t\t\treturn;\n\t\tlist_add_tail(&region->list, list);\n\t}\n}\n\nstatic struct iommu_device *s390_iommu_probe_device(struct device *dev)\n{\n\tstruct zpci_dev *zdev;\n\n\tif (!dev_is_pci(dev))\n\t\treturn ERR_PTR(-ENODEV);\n\n\tzdev = to_zpci_dev(dev);\n\n\tif (zdev->start_dma > zdev->end_dma ||\n\t    zdev->start_dma > ZPCI_TABLE_SIZE_RT - 1)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (zdev->end_dma > ZPCI_TABLE_SIZE_RT - 1)\n\t\tzdev->end_dma = ZPCI_TABLE_SIZE_RT - 1;\n\n\treturn &zdev->iommu_dev;\n}\n\nstatic void s390_iommu_release_device(struct device *dev)\n{\n\tstruct zpci_dev *zdev = to_zpci_dev(dev);\n\n\t \n\tif (zdev)\n\t\t__s390_iommu_detach_device(zdev);\n}\n\nstatic void s390_iommu_flush_iotlb_all(struct iommu_domain *domain)\n{\n\tstruct s390_domain *s390_domain = to_s390_domain(domain);\n\tstruct zpci_dev *zdev;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(zdev, &s390_domain->devices, iommu_list) {\n\t\tzpci_refresh_trans((u64)zdev->fh << 32, zdev->start_dma,\n\t\t\t\t   zdev->end_dma - zdev->start_dma + 1);\n\t}\n\trcu_read_unlock();\n}\n\nstatic void s390_iommu_iotlb_sync(struct iommu_domain *domain,\n\t\t\t\t  struct iommu_iotlb_gather *gather)\n{\n\tstruct s390_domain *s390_domain = to_s390_domain(domain);\n\tsize_t size = gather->end - gather->start + 1;\n\tstruct zpci_dev *zdev;\n\n\t \n\tif (!gather->end)\n\t\treturn;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(zdev, &s390_domain->devices, iommu_list) {\n\t\tzpci_refresh_trans((u64)zdev->fh << 32, gather->start,\n\t\t\t\t   size);\n\t}\n\trcu_read_unlock();\n}\n\nstatic void s390_iommu_iotlb_sync_map(struct iommu_domain *domain,\n\t\t\t\t      unsigned long iova, size_t size)\n{\n\tstruct s390_domain *s390_domain = to_s390_domain(domain);\n\tstruct zpci_dev *zdev;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(zdev, &s390_domain->devices, iommu_list) {\n\t\tif (!zdev->tlb_refresh)\n\t\t\tcontinue;\n\t\tzpci_refresh_trans((u64)zdev->fh << 32,\n\t\t\t\t   iova, size);\n\t}\n\trcu_read_unlock();\n}\n\nstatic int s390_iommu_validate_trans(struct s390_domain *s390_domain,\n\t\t\t\t     phys_addr_t pa, dma_addr_t dma_addr,\n\t\t\t\t     unsigned long nr_pages, int flags,\n\t\t\t\t     gfp_t gfp)\n{\n\tphys_addr_t page_addr = pa & PAGE_MASK;\n\tunsigned long *entry;\n\tunsigned long i;\n\tint rc;\n\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tentry = dma_walk_cpu_trans(s390_domain->dma_table, dma_addr,\n\t\t\t\t\t   gfp);\n\t\tif (unlikely(!entry)) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto undo_cpu_trans;\n\t\t}\n\t\tdma_update_cpu_trans(entry, page_addr, flags);\n\t\tpage_addr += PAGE_SIZE;\n\t\tdma_addr += PAGE_SIZE;\n\t}\n\n\treturn 0;\n\nundo_cpu_trans:\n\twhile (i-- > 0) {\n\t\tdma_addr -= PAGE_SIZE;\n\t\tentry = dma_walk_cpu_trans(s390_domain->dma_table,\n\t\t\t\t\t   dma_addr, gfp);\n\t\tif (!entry)\n\t\t\tbreak;\n\t\tdma_update_cpu_trans(entry, 0, ZPCI_PTE_INVALID);\n\t}\n\n\treturn rc;\n}\n\nstatic int s390_iommu_invalidate_trans(struct s390_domain *s390_domain,\n\t\t\t\t       dma_addr_t dma_addr, unsigned long nr_pages)\n{\n\tunsigned long *entry;\n\tunsigned long i;\n\tint rc = 0;\n\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tentry = dma_walk_cpu_trans(s390_domain->dma_table, dma_addr,\n\t\t\t\t\t   GFP_ATOMIC);\n\t\tif (unlikely(!entry)) {\n\t\t\trc = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tdma_update_cpu_trans(entry, 0, ZPCI_PTE_INVALID);\n\t\tdma_addr += PAGE_SIZE;\n\t}\n\n\treturn rc;\n}\n\nstatic int s390_iommu_map_pages(struct iommu_domain *domain,\n\t\t\t\tunsigned long iova, phys_addr_t paddr,\n\t\t\t\tsize_t pgsize, size_t pgcount,\n\t\t\t\tint prot, gfp_t gfp, size_t *mapped)\n{\n\tstruct s390_domain *s390_domain = to_s390_domain(domain);\n\tsize_t size = pgcount << __ffs(pgsize);\n\tint flags = ZPCI_PTE_VALID, rc = 0;\n\n\tif (pgsize != SZ_4K)\n\t\treturn -EINVAL;\n\n\tif (iova < s390_domain->domain.geometry.aperture_start ||\n\t    (iova + size - 1) > s390_domain->domain.geometry.aperture_end)\n\t\treturn -EINVAL;\n\n\tif (!IS_ALIGNED(iova | paddr, pgsize))\n\t\treturn -EINVAL;\n\n\tif (!(prot & IOMMU_READ))\n\t\treturn -EINVAL;\n\n\tif (!(prot & IOMMU_WRITE))\n\t\tflags |= ZPCI_TABLE_PROTECTED;\n\n\trc = s390_iommu_validate_trans(s390_domain, paddr, iova,\n\t\t\t\t       pgcount, flags, gfp);\n\tif (!rc)\n\t\t*mapped = size;\n\n\treturn rc;\n}\n\nstatic phys_addr_t s390_iommu_iova_to_phys(struct iommu_domain *domain,\n\t\t\t\t\t   dma_addr_t iova)\n{\n\tstruct s390_domain *s390_domain = to_s390_domain(domain);\n\tunsigned long *rto, *sto, *pto;\n\tunsigned long ste, pte, rte;\n\tunsigned int rtx, sx, px;\n\tphys_addr_t phys = 0;\n\n\tif (iova < domain->geometry.aperture_start ||\n\t    iova > domain->geometry.aperture_end)\n\t\treturn 0;\n\n\trtx = calc_rtx(iova);\n\tsx = calc_sx(iova);\n\tpx = calc_px(iova);\n\trto = s390_domain->dma_table;\n\n\trte = READ_ONCE(rto[rtx]);\n\tif (reg_entry_isvalid(rte)) {\n\t\tsto = get_rt_sto(rte);\n\t\tste = READ_ONCE(sto[sx]);\n\t\tif (reg_entry_isvalid(ste)) {\n\t\t\tpto = get_st_pto(ste);\n\t\t\tpte = READ_ONCE(pto[px]);\n\t\t\tif (pt_entry_isvalid(pte))\n\t\t\t\tphys = pte & ZPCI_PTE_ADDR_MASK;\n\t\t}\n\t}\n\n\treturn phys;\n}\n\nstatic size_t s390_iommu_unmap_pages(struct iommu_domain *domain,\n\t\t\t\t     unsigned long iova,\n\t\t\t\t     size_t pgsize, size_t pgcount,\n\t\t\t\t     struct iommu_iotlb_gather *gather)\n{\n\tstruct s390_domain *s390_domain = to_s390_domain(domain);\n\tsize_t size = pgcount << __ffs(pgsize);\n\tint rc;\n\n\tif (WARN_ON(iova < s390_domain->domain.geometry.aperture_start ||\n\t    (iova + size - 1) > s390_domain->domain.geometry.aperture_end))\n\t\treturn 0;\n\n\trc = s390_iommu_invalidate_trans(s390_domain, iova, pgcount);\n\tif (rc)\n\t\treturn 0;\n\n\tiommu_iotlb_gather_add_range(gather, iova, size);\n\n\treturn size;\n}\n\nint zpci_init_iommu(struct zpci_dev *zdev)\n{\n\tint rc = 0;\n\n\trc = iommu_device_sysfs_add(&zdev->iommu_dev, NULL, NULL,\n\t\t\t\t    \"s390-iommu.%08x\", zdev->fid);\n\tif (rc)\n\t\tgoto out_err;\n\n\trc = iommu_device_register(&zdev->iommu_dev, &s390_iommu_ops, NULL);\n\tif (rc)\n\t\tgoto out_sysfs;\n\n\treturn 0;\n\nout_sysfs:\n\tiommu_device_sysfs_remove(&zdev->iommu_dev);\n\nout_err:\n\treturn rc;\n}\n\nvoid zpci_destroy_iommu(struct zpci_dev *zdev)\n{\n\tiommu_device_unregister(&zdev->iommu_dev);\n\tiommu_device_sysfs_remove(&zdev->iommu_dev);\n}\n\nstatic const struct iommu_ops s390_iommu_ops = {\n\t.capable = s390_iommu_capable,\n\t.domain_alloc = s390_domain_alloc,\n\t.probe_device = s390_iommu_probe_device,\n\t.release_device = s390_iommu_release_device,\n\t.device_group = generic_device_group,\n\t.set_platform_dma_ops = s390_iommu_set_platform_dma,\n\t.pgsize_bitmap = SZ_4K,\n\t.get_resv_regions = s390_iommu_get_resv_regions,\n\t.default_domain_ops = &(const struct iommu_domain_ops) {\n\t\t.attach_dev\t= s390_iommu_attach_device,\n\t\t.map_pages\t= s390_iommu_map_pages,\n\t\t.unmap_pages\t= s390_iommu_unmap_pages,\n\t\t.flush_iotlb_all = s390_iommu_flush_iotlb_all,\n\t\t.iotlb_sync      = s390_iommu_iotlb_sync,\n\t\t.iotlb_sync_map  = s390_iommu_iotlb_sync_map,\n\t\t.iova_to_phys\t= s390_iommu_iova_to_phys,\n\t\t.free\t\t= s390_domain_free,\n\t}\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}