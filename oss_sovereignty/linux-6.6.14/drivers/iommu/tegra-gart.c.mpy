{
  "module_name": "tegra-gart.c",
  "hash_id": "4374e4049b539718b020f6f9b73485ab5f127646dda27cc34e0941a9a143b4b3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/tegra-gart.c",
  "human_readable_source": "\n \n\n#define dev_fmt(fmt)\t\"gart: \" fmt\n\n#include <linux/io.h>\n#include <linux/iommu.h>\n#include <linux/moduleparam.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/vmalloc.h>\n\n#include <soc/tegra/mc.h>\n\n#define GART_REG_BASE\t\t0x24\n#define GART_CONFIG\t\t(0x24 - GART_REG_BASE)\n#define GART_ENTRY_ADDR\t\t(0x28 - GART_REG_BASE)\n#define GART_ENTRY_DATA\t\t(0x2c - GART_REG_BASE)\n\n#define GART_ENTRY_PHYS_ADDR_VALID\tBIT(31)\n\n#define GART_PAGE_SHIFT\t\t12\n#define GART_PAGE_SIZE\t\t(1 << GART_PAGE_SHIFT)\n#define GART_PAGE_MASK\t\tGENMASK(30, GART_PAGE_SHIFT)\n\n \n#define GART_IOMMU_PGSIZES\t(GART_PAGE_SIZE)\n\nstruct gart_device {\n\tvoid __iomem\t\t*regs;\n\tu32\t\t\t*savedata;\n\tunsigned long\t\tiovmm_base;\t \n\tunsigned long\t\tiovmm_end;\t \n\tspinlock_t\t\tpte_lock;\t \n\tspinlock_t\t\tdom_lock;\t \n\tunsigned int\t\tactive_devices;\t \n\tstruct iommu_domain\t*active_domain;\t \n\tstruct iommu_device\tiommu;\t\t \n\tstruct device\t\t*dev;\n};\n\nstatic struct gart_device *gart_handle;  \n\nstatic bool gart_debug;\n\n \n#define FLUSH_GART_REGS(gart)\treadl_relaxed((gart)->regs + GART_CONFIG)\n\n#define for_each_gart_pte(gart, iova)\t\t\t\t\t\\\n\tfor (iova = gart->iovmm_base;\t\t\t\t\t\\\n\t     iova < gart->iovmm_end;\t\t\t\t\t\\\n\t     iova += GART_PAGE_SIZE)\n\nstatic inline void gart_set_pte(struct gart_device *gart,\n\t\t\t\tunsigned long iova, unsigned long pte)\n{\n\twritel_relaxed(iova, gart->regs + GART_ENTRY_ADDR);\n\twritel_relaxed(pte, gart->regs + GART_ENTRY_DATA);\n}\n\nstatic inline unsigned long gart_read_pte(struct gart_device *gart,\n\t\t\t\t\t  unsigned long iova)\n{\n\tunsigned long pte;\n\n\twritel_relaxed(iova, gart->regs + GART_ENTRY_ADDR);\n\tpte = readl_relaxed(gart->regs + GART_ENTRY_DATA);\n\n\treturn pte;\n}\n\nstatic void do_gart_setup(struct gart_device *gart, const u32 *data)\n{\n\tunsigned long iova;\n\n\tfor_each_gart_pte(gart, iova)\n\t\tgart_set_pte(gart, iova, data ? *(data++) : 0);\n\n\twritel_relaxed(1, gart->regs + GART_CONFIG);\n\tFLUSH_GART_REGS(gart);\n}\n\nstatic inline bool gart_iova_range_invalid(struct gart_device *gart,\n\t\t\t\t\t   unsigned long iova, size_t bytes)\n{\n\treturn unlikely(iova < gart->iovmm_base || bytes != GART_PAGE_SIZE ||\n\t\t\tiova + bytes > gart->iovmm_end);\n}\n\nstatic inline bool gart_pte_valid(struct gart_device *gart, unsigned long iova)\n{\n\treturn !!(gart_read_pte(gart, iova) & GART_ENTRY_PHYS_ADDR_VALID);\n}\n\nstatic int gart_iommu_attach_dev(struct iommu_domain *domain,\n\t\t\t\t struct device *dev)\n{\n\tstruct gart_device *gart = gart_handle;\n\tint ret = 0;\n\n\tspin_lock(&gart->dom_lock);\n\n\tif (gart->active_domain && gart->active_domain != domain) {\n\t\tret = -EINVAL;\n\t} else if (dev_iommu_priv_get(dev) != domain) {\n\t\tdev_iommu_priv_set(dev, domain);\n\t\tgart->active_domain = domain;\n\t\tgart->active_devices++;\n\t}\n\n\tspin_unlock(&gart->dom_lock);\n\n\treturn ret;\n}\n\nstatic void gart_iommu_set_platform_dma(struct device *dev)\n{\n\tstruct iommu_domain *domain = iommu_get_domain_for_dev(dev);\n\tstruct gart_device *gart = gart_handle;\n\n\tspin_lock(&gart->dom_lock);\n\n\tif (dev_iommu_priv_get(dev) == domain) {\n\t\tdev_iommu_priv_set(dev, NULL);\n\n\t\tif (--gart->active_devices == 0)\n\t\t\tgart->active_domain = NULL;\n\t}\n\n\tspin_unlock(&gart->dom_lock);\n}\n\nstatic struct iommu_domain *gart_iommu_domain_alloc(unsigned type)\n{\n\tstruct iommu_domain *domain;\n\n\tif (type != IOMMU_DOMAIN_UNMANAGED)\n\t\treturn NULL;\n\n\tdomain = kzalloc(sizeof(*domain), GFP_KERNEL);\n\tif (domain) {\n\t\tdomain->geometry.aperture_start = gart_handle->iovmm_base;\n\t\tdomain->geometry.aperture_end = gart_handle->iovmm_end - 1;\n\t\tdomain->geometry.force_aperture = true;\n\t}\n\n\treturn domain;\n}\n\nstatic void gart_iommu_domain_free(struct iommu_domain *domain)\n{\n\tWARN_ON(gart_handle->active_domain == domain);\n\tkfree(domain);\n}\n\nstatic inline int __gart_iommu_map(struct gart_device *gart, unsigned long iova,\n\t\t\t\t   unsigned long pa)\n{\n\tif (unlikely(gart_debug && gart_pte_valid(gart, iova))) {\n\t\tdev_err(gart->dev, \"Page entry is in-use\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tgart_set_pte(gart, iova, GART_ENTRY_PHYS_ADDR_VALID | pa);\n\n\treturn 0;\n}\n\nstatic int gart_iommu_map(struct iommu_domain *domain, unsigned long iova,\n\t\t\t  phys_addr_t pa, size_t bytes, int prot, gfp_t gfp)\n{\n\tstruct gart_device *gart = gart_handle;\n\tint ret;\n\n\tif (gart_iova_range_invalid(gart, iova, bytes))\n\t\treturn -EINVAL;\n\n\tspin_lock(&gart->pte_lock);\n\tret = __gart_iommu_map(gart, iova, (unsigned long)pa);\n\tspin_unlock(&gart->pte_lock);\n\n\treturn ret;\n}\n\nstatic inline int __gart_iommu_unmap(struct gart_device *gart,\n\t\t\t\t     unsigned long iova)\n{\n\tif (unlikely(gart_debug && !gart_pte_valid(gart, iova))) {\n\t\tdev_err(gart->dev, \"Page entry is invalid\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tgart_set_pte(gart, iova, 0);\n\n\treturn 0;\n}\n\nstatic size_t gart_iommu_unmap(struct iommu_domain *domain, unsigned long iova,\n\t\t\t       size_t bytes, struct iommu_iotlb_gather *gather)\n{\n\tstruct gart_device *gart = gart_handle;\n\tint err;\n\n\tif (gart_iova_range_invalid(gart, iova, bytes))\n\t\treturn 0;\n\n\tspin_lock(&gart->pte_lock);\n\terr = __gart_iommu_unmap(gart, iova);\n\tspin_unlock(&gart->pte_lock);\n\n\treturn err ? 0 : bytes;\n}\n\nstatic phys_addr_t gart_iommu_iova_to_phys(struct iommu_domain *domain,\n\t\t\t\t\t   dma_addr_t iova)\n{\n\tstruct gart_device *gart = gart_handle;\n\tunsigned long pte;\n\n\tif (gart_iova_range_invalid(gart, iova, GART_PAGE_SIZE))\n\t\treturn -EINVAL;\n\n\tspin_lock(&gart->pte_lock);\n\tpte = gart_read_pte(gart, iova);\n\tspin_unlock(&gart->pte_lock);\n\n\treturn pte & GART_PAGE_MASK;\n}\n\nstatic struct iommu_device *gart_iommu_probe_device(struct device *dev)\n{\n\tif (!dev_iommu_fwspec_get(dev))\n\t\treturn ERR_PTR(-ENODEV);\n\n\treturn &gart_handle->iommu;\n}\n\nstatic int gart_iommu_of_xlate(struct device *dev,\n\t\t\t       struct of_phandle_args *args)\n{\n\treturn 0;\n}\n\nstatic void gart_iommu_sync_map(struct iommu_domain *domain, unsigned long iova,\n\t\t\t\tsize_t size)\n{\n\tFLUSH_GART_REGS(gart_handle);\n}\n\nstatic void gart_iommu_sync(struct iommu_domain *domain,\n\t\t\t    struct iommu_iotlb_gather *gather)\n{\n\tsize_t length = gather->end - gather->start + 1;\n\n\tgart_iommu_sync_map(domain, gather->start, length);\n}\n\nstatic const struct iommu_ops gart_iommu_ops = {\n\t.domain_alloc\t= gart_iommu_domain_alloc,\n\t.probe_device\t= gart_iommu_probe_device,\n\t.device_group\t= generic_device_group,\n\t.set_platform_dma_ops = gart_iommu_set_platform_dma,\n\t.pgsize_bitmap\t= GART_IOMMU_PGSIZES,\n\t.of_xlate\t= gart_iommu_of_xlate,\n\t.default_domain_ops = &(const struct iommu_domain_ops) {\n\t\t.attach_dev\t= gart_iommu_attach_dev,\n\t\t.map\t\t= gart_iommu_map,\n\t\t.unmap\t\t= gart_iommu_unmap,\n\t\t.iova_to_phys\t= gart_iommu_iova_to_phys,\n\t\t.iotlb_sync_map\t= gart_iommu_sync_map,\n\t\t.iotlb_sync\t= gart_iommu_sync,\n\t\t.free\t\t= gart_iommu_domain_free,\n\t}\n};\n\nint tegra_gart_suspend(struct gart_device *gart)\n{\n\tu32 *data = gart->savedata;\n\tunsigned long iova;\n\n\t \n\twritel_relaxed(0, gart->regs + GART_CONFIG);\n\tFLUSH_GART_REGS(gart);\n\n\tfor_each_gart_pte(gart, iova)\n\t\t*(data++) = gart_read_pte(gart, iova);\n\n\treturn 0;\n}\n\nint tegra_gart_resume(struct gart_device *gart)\n{\n\tdo_gart_setup(gart, gart->savedata);\n\n\treturn 0;\n}\n\nstruct gart_device *tegra_gart_probe(struct device *dev, struct tegra_mc *mc)\n{\n\tstruct gart_device *gart;\n\tstruct resource *res;\n\tint err;\n\n\tBUILD_BUG_ON(PAGE_SHIFT != GART_PAGE_SHIFT);\n\n\t \n\tres = platform_get_resource(to_platform_device(dev), IORESOURCE_MEM, 1);\n\tif (!res) {\n\t\tdev_err(dev, \"Memory aperture resource unavailable\\n\");\n\t\treturn ERR_PTR(-ENXIO);\n\t}\n\n\tgart = kzalloc(sizeof(*gart), GFP_KERNEL);\n\tif (!gart)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tgart_handle = gart;\n\n\tgart->dev = dev;\n\tgart->regs = mc->regs + GART_REG_BASE;\n\tgart->iovmm_base = res->start;\n\tgart->iovmm_end = res->end + 1;\n\tspin_lock_init(&gart->pte_lock);\n\tspin_lock_init(&gart->dom_lock);\n\n\tdo_gart_setup(gart, NULL);\n\n\terr = iommu_device_sysfs_add(&gart->iommu, dev, NULL, \"gart\");\n\tif (err)\n\t\tgoto free_gart;\n\n\terr = iommu_device_register(&gart->iommu, &gart_iommu_ops, dev);\n\tif (err)\n\t\tgoto remove_sysfs;\n\n\tgart->savedata = vmalloc(resource_size(res) / GART_PAGE_SIZE *\n\t\t\t\t sizeof(u32));\n\tif (!gart->savedata) {\n\t\terr = -ENOMEM;\n\t\tgoto unregister_iommu;\n\t}\n\n\treturn gart;\n\nunregister_iommu:\n\tiommu_device_unregister(&gart->iommu);\nremove_sysfs:\n\tiommu_device_sysfs_remove(&gart->iommu);\nfree_gart:\n\tkfree(gart);\n\n\treturn ERR_PTR(err);\n}\n\nmodule_param(gart_debug, bool, 0644);\nMODULE_PARM_DESC(gart_debug, \"Enable GART debugging\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}