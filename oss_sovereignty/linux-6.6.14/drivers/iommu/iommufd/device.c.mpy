{
  "module_name": "device.c",
  "hash_id": "092cfc40bf723dad7fb9f385869b58f94541b9e7f797ecc963fb3b0353bedac4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/iommufd/device.c",
  "human_readable_source": "\n \n#include <linux/iommufd.h>\n#include <linux/slab.h>\n#include <linux/iommu.h>\n#include <uapi/linux/iommufd.h>\n#include \"../iommu-priv.h\"\n\n#include \"io_pagetable.h\"\n#include \"iommufd_private.h\"\n\nstatic bool allow_unsafe_interrupts;\nmodule_param(allow_unsafe_interrupts, bool, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(\n\tallow_unsafe_interrupts,\n\t\"Allow IOMMUFD to bind to devices even if the platform cannot isolate \"\n\t\"the MSI interrupt window. Enabling this is a security weakness.\");\n\nstatic void iommufd_group_release(struct kref *kref)\n{\n\tstruct iommufd_group *igroup =\n\t\tcontainer_of(kref, struct iommufd_group, ref);\n\n\tWARN_ON(igroup->hwpt || !list_empty(&igroup->device_list));\n\n\txa_cmpxchg(&igroup->ictx->groups, iommu_group_id(igroup->group), igroup,\n\t\t   NULL, GFP_KERNEL);\n\tiommu_group_put(igroup->group);\n\tmutex_destroy(&igroup->lock);\n\tkfree(igroup);\n}\n\nstatic void iommufd_put_group(struct iommufd_group *group)\n{\n\tkref_put(&group->ref, iommufd_group_release);\n}\n\nstatic bool iommufd_group_try_get(struct iommufd_group *igroup,\n\t\t\t\t  struct iommu_group *group)\n{\n\tif (!igroup)\n\t\treturn false;\n\t \n\tif (WARN_ON(igroup->group != group))\n\t\treturn false;\n\treturn kref_get_unless_zero(&igroup->ref);\n}\n\n \nstatic struct iommufd_group *iommufd_get_group(struct iommufd_ctx *ictx,\n\t\t\t\t\t       struct device *dev)\n{\n\tstruct iommufd_group *new_igroup;\n\tstruct iommufd_group *cur_igroup;\n\tstruct iommufd_group *igroup;\n\tstruct iommu_group *group;\n\tunsigned int id;\n\n\tgroup = iommu_group_get(dev);\n\tif (!group)\n\t\treturn ERR_PTR(-ENODEV);\n\n\tid = iommu_group_id(group);\n\n\txa_lock(&ictx->groups);\n\tigroup = xa_load(&ictx->groups, id);\n\tif (iommufd_group_try_get(igroup, group)) {\n\t\txa_unlock(&ictx->groups);\n\t\tiommu_group_put(group);\n\t\treturn igroup;\n\t}\n\txa_unlock(&ictx->groups);\n\n\tnew_igroup = kzalloc(sizeof(*new_igroup), GFP_KERNEL);\n\tif (!new_igroup) {\n\t\tiommu_group_put(group);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tkref_init(&new_igroup->ref);\n\tmutex_init(&new_igroup->lock);\n\tINIT_LIST_HEAD(&new_igroup->device_list);\n\tnew_igroup->sw_msi_start = PHYS_ADDR_MAX;\n\t \n\tnew_igroup->group = group;\n\n\t \n\tnew_igroup->ictx = ictx;\n\n\t \n\tcur_igroup = NULL;\n\txa_lock(&ictx->groups);\n\twhile (true) {\n\t\tigroup = __xa_cmpxchg(&ictx->groups, id, cur_igroup, new_igroup,\n\t\t\t\t      GFP_KERNEL);\n\t\tif (xa_is_err(igroup)) {\n\t\t\txa_unlock(&ictx->groups);\n\t\t\tiommufd_put_group(new_igroup);\n\t\t\treturn ERR_PTR(xa_err(igroup));\n\t\t}\n\n\t\t \n\t\tif (cur_igroup == igroup) {\n\t\t\txa_unlock(&ictx->groups);\n\t\t\treturn new_igroup;\n\t\t}\n\n\t\t \n\t\tif (iommufd_group_try_get(igroup, group)) {\n\t\t\txa_unlock(&ictx->groups);\n\t\t\tiommufd_put_group(new_igroup);\n\t\t\treturn igroup;\n\t\t}\n\t\tcur_igroup = igroup;\n\t}\n}\n\nvoid iommufd_device_destroy(struct iommufd_object *obj)\n{\n\tstruct iommufd_device *idev =\n\t\tcontainer_of(obj, struct iommufd_device, obj);\n\n\tiommu_device_release_dma_owner(idev->dev);\n\tiommufd_put_group(idev->igroup);\n\tif (!iommufd_selftest_is_mock_dev(idev->dev))\n\t\tiommufd_ctx_put(idev->ictx);\n}\n\n \nstruct iommufd_device *iommufd_device_bind(struct iommufd_ctx *ictx,\n\t\t\t\t\t   struct device *dev, u32 *id)\n{\n\tstruct iommufd_device *idev;\n\tstruct iommufd_group *igroup;\n\tint rc;\n\n\t \n\tif (!device_iommu_capable(dev, IOMMU_CAP_CACHE_COHERENCY))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tigroup = iommufd_get_group(ictx, dev);\n\tif (IS_ERR(igroup))\n\t\treturn ERR_CAST(igroup);\n\n\t \n\tif (!iommufd_selftest_is_mock_dev(dev) &&\n\t    !iommu_group_has_isolated_msi(igroup->group)) {\n\t\tif (!allow_unsafe_interrupts) {\n\t\t\trc = -EPERM;\n\t\t\tgoto out_group_put;\n\t\t}\n\n\t\tdev_warn(\n\t\t\tdev,\n\t\t\t\"MSI interrupts are not secure, they cannot be isolated by the platform. \"\n\t\t\t\"Check that platform features like interrupt remapping are enabled. \"\n\t\t\t\"Use the \\\"allow_unsafe_interrupts\\\" module parameter to override\\n\");\n\t}\n\n\trc = iommu_device_claim_dma_owner(dev, ictx);\n\tif (rc)\n\t\tgoto out_group_put;\n\n\tidev = iommufd_object_alloc(ictx, idev, IOMMUFD_OBJ_DEVICE);\n\tif (IS_ERR(idev)) {\n\t\trc = PTR_ERR(idev);\n\t\tgoto out_release_owner;\n\t}\n\tidev->ictx = ictx;\n\tif (!iommufd_selftest_is_mock_dev(dev))\n\t\tiommufd_ctx_get(ictx);\n\tidev->dev = dev;\n\tidev->enforce_cache_coherency =\n\t\tdevice_iommu_capable(dev, IOMMU_CAP_ENFORCE_CACHE_COHERENCY);\n\t \n\trefcount_inc(&idev->obj.users);\n\t \n\tidev->igroup = igroup;\n\n\t \n\tiommufd_object_finalize(ictx, &idev->obj);\n\t*id = idev->obj.id;\n\treturn idev;\n\nout_release_owner:\n\tiommu_device_release_dma_owner(dev);\nout_group_put:\n\tiommufd_put_group(igroup);\n\treturn ERR_PTR(rc);\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_device_bind, IOMMUFD);\n\n \nbool iommufd_ctx_has_group(struct iommufd_ctx *ictx, struct iommu_group *group)\n{\n\tstruct iommufd_object *obj;\n\tunsigned long index;\n\n\tif (!ictx || !group)\n\t\treturn false;\n\n\txa_lock(&ictx->objects);\n\txa_for_each(&ictx->objects, index, obj) {\n\t\tif (obj->type == IOMMUFD_OBJ_DEVICE &&\n\t\t    container_of(obj, struct iommufd_device, obj)\n\t\t\t\t    ->igroup->group == group) {\n\t\t\txa_unlock(&ictx->objects);\n\t\t\treturn true;\n\t\t}\n\t}\n\txa_unlock(&ictx->objects);\n\treturn false;\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_ctx_has_group, IOMMUFD);\n\n \nvoid iommufd_device_unbind(struct iommufd_device *idev)\n{\n\tiommufd_object_destroy_user(idev->ictx, &idev->obj);\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_device_unbind, IOMMUFD);\n\nstruct iommufd_ctx *iommufd_device_to_ictx(struct iommufd_device *idev)\n{\n\treturn idev->ictx;\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_device_to_ictx, IOMMUFD);\n\nu32 iommufd_device_to_id(struct iommufd_device *idev)\n{\n\treturn idev->obj.id;\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_device_to_id, IOMMUFD);\n\nstatic int iommufd_group_setup_msi(struct iommufd_group *igroup,\n\t\t\t\t   struct iommufd_hw_pagetable *hwpt)\n{\n\tphys_addr_t sw_msi_start = igroup->sw_msi_start;\n\tint rc;\n\n\t \n\tif (sw_msi_start != PHYS_ADDR_MAX && !hwpt->msi_cookie) {\n\t\trc = iommu_get_msi_cookie(hwpt->domain, sw_msi_start);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\thwpt->msi_cookie = true;\n\t}\n\treturn 0;\n}\n\nint iommufd_hw_pagetable_attach(struct iommufd_hw_pagetable *hwpt,\n\t\t\t\tstruct iommufd_device *idev)\n{\n\tint rc;\n\n\tmutex_lock(&idev->igroup->lock);\n\n\tif (idev->igroup->hwpt != NULL && idev->igroup->hwpt != hwpt) {\n\t\trc = -EINVAL;\n\t\tgoto err_unlock;\n\t}\n\n\t \n\tif (idev->enforce_cache_coherency) {\n\t\trc = iommufd_hw_pagetable_enforce_cc(hwpt);\n\t\tif (rc)\n\t\t\tgoto err_unlock;\n\t}\n\n\trc = iopt_table_enforce_dev_resv_regions(&hwpt->ioas->iopt, idev->dev,\n\t\t\t\t\t\t &idev->igroup->sw_msi_start);\n\tif (rc)\n\t\tgoto err_unlock;\n\n\t \n\tif (list_empty(&idev->igroup->device_list)) {\n\t\trc = iommufd_group_setup_msi(idev->igroup, hwpt);\n\t\tif (rc)\n\t\t\tgoto err_unresv;\n\n\t\trc = iommu_attach_group(hwpt->domain, idev->igroup->group);\n\t\tif (rc)\n\t\t\tgoto err_unresv;\n\t\tidev->igroup->hwpt = hwpt;\n\t}\n\trefcount_inc(&hwpt->obj.users);\n\tlist_add_tail(&idev->group_item, &idev->igroup->device_list);\n\tmutex_unlock(&idev->igroup->lock);\n\treturn 0;\nerr_unresv:\n\tiopt_remove_reserved_iova(&hwpt->ioas->iopt, idev->dev);\nerr_unlock:\n\tmutex_unlock(&idev->igroup->lock);\n\treturn rc;\n}\n\nstruct iommufd_hw_pagetable *\niommufd_hw_pagetable_detach(struct iommufd_device *idev)\n{\n\tstruct iommufd_hw_pagetable *hwpt = idev->igroup->hwpt;\n\n\tmutex_lock(&idev->igroup->lock);\n\tlist_del(&idev->group_item);\n\tif (list_empty(&idev->igroup->device_list)) {\n\t\tiommu_detach_group(hwpt->domain, idev->igroup->group);\n\t\tidev->igroup->hwpt = NULL;\n\t}\n\tiopt_remove_reserved_iova(&hwpt->ioas->iopt, idev->dev);\n\tmutex_unlock(&idev->igroup->lock);\n\n\t \n\treturn hwpt;\n}\n\nstatic struct iommufd_hw_pagetable *\niommufd_device_do_attach(struct iommufd_device *idev,\n\t\t\t struct iommufd_hw_pagetable *hwpt)\n{\n\tint rc;\n\n\trc = iommufd_hw_pagetable_attach(hwpt, idev);\n\tif (rc)\n\t\treturn ERR_PTR(rc);\n\treturn NULL;\n}\n\nstatic struct iommufd_hw_pagetable *\niommufd_device_do_replace(struct iommufd_device *idev,\n\t\t\t  struct iommufd_hw_pagetable *hwpt)\n{\n\tstruct iommufd_group *igroup = idev->igroup;\n\tstruct iommufd_hw_pagetable *old_hwpt;\n\tunsigned int num_devices = 0;\n\tstruct iommufd_device *cur;\n\tint rc;\n\n\tmutex_lock(&idev->igroup->lock);\n\n\tif (igroup->hwpt == NULL) {\n\t\trc = -EINVAL;\n\t\tgoto err_unlock;\n\t}\n\n\tif (hwpt == igroup->hwpt) {\n\t\tmutex_unlock(&idev->igroup->lock);\n\t\treturn NULL;\n\t}\n\n\t \n\tlist_for_each_entry(cur, &igroup->device_list, group_item) {\n\t\tnum_devices++;\n\t\tif (cur->enforce_cache_coherency) {\n\t\t\trc = iommufd_hw_pagetable_enforce_cc(hwpt);\n\t\t\tif (rc)\n\t\t\t\tgoto err_unlock;\n\t\t}\n\t}\n\n\told_hwpt = igroup->hwpt;\n\tif (hwpt->ioas != old_hwpt->ioas) {\n\t\tlist_for_each_entry(cur, &igroup->device_list, group_item) {\n\t\t\trc = iopt_table_enforce_dev_resv_regions(\n\t\t\t\t&hwpt->ioas->iopt, cur->dev, NULL);\n\t\t\tif (rc)\n\t\t\t\tgoto err_unresv;\n\t\t}\n\t}\n\n\trc = iommufd_group_setup_msi(idev->igroup, hwpt);\n\tif (rc)\n\t\tgoto err_unresv;\n\n\trc = iommu_group_replace_domain(igroup->group, hwpt->domain);\n\tif (rc)\n\t\tgoto err_unresv;\n\n\tif (hwpt->ioas != old_hwpt->ioas) {\n\t\tlist_for_each_entry(cur, &igroup->device_list, group_item)\n\t\t\tiopt_remove_reserved_iova(&old_hwpt->ioas->iopt,\n\t\t\t\t\t\t  cur->dev);\n\t}\n\n\tigroup->hwpt = hwpt;\n\n\t \n\trefcount_add(num_devices, &hwpt->obj.users);\n\tif (num_devices > 1)\n\t\tWARN_ON(refcount_sub_and_test(num_devices - 1,\n\t\t\t\t\t      &old_hwpt->obj.users));\n\tmutex_unlock(&idev->igroup->lock);\n\n\t \n\treturn old_hwpt;\nerr_unresv:\n\tlist_for_each_entry(cur, &igroup->device_list, group_item)\n\t\tiopt_remove_reserved_iova(&hwpt->ioas->iopt, cur->dev);\nerr_unlock:\n\tmutex_unlock(&idev->igroup->lock);\n\treturn ERR_PTR(rc);\n}\n\ntypedef struct iommufd_hw_pagetable *(*attach_fn)(\n\tstruct iommufd_device *idev, struct iommufd_hw_pagetable *hwpt);\n\n \nstatic struct iommufd_hw_pagetable *\niommufd_device_auto_get_domain(struct iommufd_device *idev,\n\t\t\t       struct iommufd_ioas *ioas, u32 *pt_id,\n\t\t\t       attach_fn do_attach)\n{\n\t \n\tbool immediate_attach = do_attach == iommufd_device_do_attach;\n\tstruct iommufd_hw_pagetable *destroy_hwpt;\n\tstruct iommufd_hw_pagetable *hwpt;\n\n\t \n\tmutex_lock(&ioas->mutex);\n\tlist_for_each_entry(hwpt, &ioas->hwpt_list, hwpt_item) {\n\t\tif (!hwpt->auto_domain)\n\t\t\tcontinue;\n\n\t\tif (!iommufd_lock_obj(&hwpt->obj))\n\t\t\tcontinue;\n\t\tdestroy_hwpt = (*do_attach)(idev, hwpt);\n\t\tif (IS_ERR(destroy_hwpt)) {\n\t\t\tiommufd_put_object(&hwpt->obj);\n\t\t\t \n\t\t\tif (PTR_ERR(destroy_hwpt) == -EINVAL)\n\t\t\t\tcontinue;\n\t\t\tgoto out_unlock;\n\t\t}\n\t\t*pt_id = hwpt->obj.id;\n\t\tiommufd_put_object(&hwpt->obj);\n\t\tgoto out_unlock;\n\t}\n\n\thwpt = iommufd_hw_pagetable_alloc(idev->ictx, ioas, idev,\n\t\t\t\t\t  immediate_attach);\n\tif (IS_ERR(hwpt)) {\n\t\tdestroy_hwpt = ERR_CAST(hwpt);\n\t\tgoto out_unlock;\n\t}\n\n\tif (!immediate_attach) {\n\t\tdestroy_hwpt = (*do_attach)(idev, hwpt);\n\t\tif (IS_ERR(destroy_hwpt))\n\t\t\tgoto out_abort;\n\t} else {\n\t\tdestroy_hwpt = NULL;\n\t}\n\n\thwpt->auto_domain = true;\n\t*pt_id = hwpt->obj.id;\n\n\tiommufd_object_finalize(idev->ictx, &hwpt->obj);\n\tmutex_unlock(&ioas->mutex);\n\treturn destroy_hwpt;\n\nout_abort:\n\tiommufd_object_abort_and_destroy(idev->ictx, &hwpt->obj);\nout_unlock:\n\tmutex_unlock(&ioas->mutex);\n\treturn destroy_hwpt;\n}\n\nstatic int iommufd_device_change_pt(struct iommufd_device *idev, u32 *pt_id,\n\t\t\t\t    attach_fn do_attach)\n{\n\tstruct iommufd_hw_pagetable *destroy_hwpt;\n\tstruct iommufd_object *pt_obj;\n\n\tpt_obj = iommufd_get_object(idev->ictx, *pt_id, IOMMUFD_OBJ_ANY);\n\tif (IS_ERR(pt_obj))\n\t\treturn PTR_ERR(pt_obj);\n\n\tswitch (pt_obj->type) {\n\tcase IOMMUFD_OBJ_HW_PAGETABLE: {\n\t\tstruct iommufd_hw_pagetable *hwpt =\n\t\t\tcontainer_of(pt_obj, struct iommufd_hw_pagetable, obj);\n\n\t\tdestroy_hwpt = (*do_attach)(idev, hwpt);\n\t\tif (IS_ERR(destroy_hwpt))\n\t\t\tgoto out_put_pt_obj;\n\t\tbreak;\n\t}\n\tcase IOMMUFD_OBJ_IOAS: {\n\t\tstruct iommufd_ioas *ioas =\n\t\t\tcontainer_of(pt_obj, struct iommufd_ioas, obj);\n\n\t\tdestroy_hwpt = iommufd_device_auto_get_domain(idev, ioas, pt_id,\n\t\t\t\t\t\t\t      do_attach);\n\t\tif (IS_ERR(destroy_hwpt))\n\t\t\tgoto out_put_pt_obj;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tdestroy_hwpt = ERR_PTR(-EINVAL);\n\t\tgoto out_put_pt_obj;\n\t}\n\tiommufd_put_object(pt_obj);\n\n\t \n\tif (destroy_hwpt)\n\t\tiommufd_hw_pagetable_put(idev->ictx, destroy_hwpt);\n\treturn 0;\n\nout_put_pt_obj:\n\tiommufd_put_object(pt_obj);\n\treturn PTR_ERR(destroy_hwpt);\n}\n\n \nint iommufd_device_attach(struct iommufd_device *idev, u32 *pt_id)\n{\n\tint rc;\n\n\trc = iommufd_device_change_pt(idev, pt_id, &iommufd_device_do_attach);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\trefcount_inc(&idev->obj.users);\n\treturn 0;\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_device_attach, IOMMUFD);\n\n \nint iommufd_device_replace(struct iommufd_device *idev, u32 *pt_id)\n{\n\treturn iommufd_device_change_pt(idev, pt_id,\n\t\t\t\t\t&iommufd_device_do_replace);\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_device_replace, IOMMUFD);\n\n \nvoid iommufd_device_detach(struct iommufd_device *idev)\n{\n\tstruct iommufd_hw_pagetable *hwpt;\n\n\thwpt = iommufd_hw_pagetable_detach(idev);\n\tiommufd_hw_pagetable_put(idev->ictx, hwpt);\n\trefcount_dec(&idev->obj.users);\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_device_detach, IOMMUFD);\n\n \nstatic int iommufd_access_change_ioas(struct iommufd_access *access,\n\t\t\t\t      struct iommufd_ioas *new_ioas)\n{\n\tu32 iopt_access_list_id = access->iopt_access_list_id;\n\tstruct iommufd_ioas *cur_ioas = access->ioas;\n\tint rc;\n\n\tlockdep_assert_held(&access->ioas_lock);\n\n\t \n\tif (cur_ioas != access->ioas_unpin)\n\t\treturn -EBUSY;\n\n\tif (cur_ioas == new_ioas)\n\t\treturn 0;\n\n\t \n\taccess->ioas = NULL;\n\n\tif (new_ioas) {\n\t\trc = iopt_add_access(&new_ioas->iopt, access);\n\t\tif (rc) {\n\t\t\taccess->ioas = cur_ioas;\n\t\t\treturn rc;\n\t\t}\n\t\trefcount_inc(&new_ioas->obj.users);\n\t}\n\n\tif (cur_ioas) {\n\t\tif (access->ops->unmap) {\n\t\t\tmutex_unlock(&access->ioas_lock);\n\t\t\taccess->ops->unmap(access->data, 0, ULONG_MAX);\n\t\t\tmutex_lock(&access->ioas_lock);\n\t\t}\n\t\tiopt_remove_access(&cur_ioas->iopt, access, iopt_access_list_id);\n\t\trefcount_dec(&cur_ioas->obj.users);\n\t}\n\n\taccess->ioas = new_ioas;\n\taccess->ioas_unpin = new_ioas;\n\n\treturn 0;\n}\n\nstatic int iommufd_access_change_ioas_id(struct iommufd_access *access, u32 id)\n{\n\tstruct iommufd_ioas *ioas = iommufd_get_ioas(access->ictx, id);\n\tint rc;\n\n\tif (IS_ERR(ioas))\n\t\treturn PTR_ERR(ioas);\n\trc = iommufd_access_change_ioas(access, ioas);\n\tiommufd_put_object(&ioas->obj);\n\treturn rc;\n}\n\nvoid iommufd_access_destroy_object(struct iommufd_object *obj)\n{\n\tstruct iommufd_access *access =\n\t\tcontainer_of(obj, struct iommufd_access, obj);\n\n\tmutex_lock(&access->ioas_lock);\n\tif (access->ioas)\n\t\tWARN_ON(iommufd_access_change_ioas(access, NULL));\n\tmutex_unlock(&access->ioas_lock);\n\tiommufd_ctx_put(access->ictx);\n}\n\n \nstruct iommufd_access *\niommufd_access_create(struct iommufd_ctx *ictx,\n\t\t      const struct iommufd_access_ops *ops, void *data, u32 *id)\n{\n\tstruct iommufd_access *access;\n\n\t \n\taccess = iommufd_object_alloc(ictx, access, IOMMUFD_OBJ_ACCESS);\n\tif (IS_ERR(access))\n\t\treturn access;\n\n\taccess->data = data;\n\taccess->ops = ops;\n\n\tif (ops->needs_pin_pages)\n\t\taccess->iova_alignment = PAGE_SIZE;\n\telse\n\t\taccess->iova_alignment = 1;\n\n\t \n\trefcount_inc(&access->obj.users);\n\taccess->ictx = ictx;\n\tiommufd_ctx_get(ictx);\n\tiommufd_object_finalize(ictx, &access->obj);\n\t*id = access->obj.id;\n\tmutex_init(&access->ioas_lock);\n\treturn access;\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_access_create, IOMMUFD);\n\n \nvoid iommufd_access_destroy(struct iommufd_access *access)\n{\n\tiommufd_object_destroy_user(access->ictx, &access->obj);\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_access_destroy, IOMMUFD);\n\nvoid iommufd_access_detach(struct iommufd_access *access)\n{\n\tmutex_lock(&access->ioas_lock);\n\tif (WARN_ON(!access->ioas)) {\n\t\tmutex_unlock(&access->ioas_lock);\n\t\treturn;\n\t}\n\tWARN_ON(iommufd_access_change_ioas(access, NULL));\n\tmutex_unlock(&access->ioas_lock);\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_access_detach, IOMMUFD);\n\nint iommufd_access_attach(struct iommufd_access *access, u32 ioas_id)\n{\n\tint rc;\n\n\tmutex_lock(&access->ioas_lock);\n\tif (WARN_ON(access->ioas)) {\n\t\tmutex_unlock(&access->ioas_lock);\n\t\treturn -EINVAL;\n\t}\n\n\trc = iommufd_access_change_ioas_id(access, ioas_id);\n\tmutex_unlock(&access->ioas_lock);\n\treturn rc;\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_access_attach, IOMMUFD);\n\nint iommufd_access_replace(struct iommufd_access *access, u32 ioas_id)\n{\n\tint rc;\n\n\tmutex_lock(&access->ioas_lock);\n\tif (!access->ioas) {\n\t\tmutex_unlock(&access->ioas_lock);\n\t\treturn -ENOENT;\n\t}\n\trc = iommufd_access_change_ioas_id(access, ioas_id);\n\tmutex_unlock(&access->ioas_lock);\n\treturn rc;\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_access_replace, IOMMUFD);\n\n \nvoid iommufd_access_notify_unmap(struct io_pagetable *iopt, unsigned long iova,\n\t\t\t\t unsigned long length)\n{\n\tstruct iommufd_ioas *ioas =\n\t\tcontainer_of(iopt, struct iommufd_ioas, iopt);\n\tstruct iommufd_access *access;\n\tunsigned long index;\n\n\txa_lock(&ioas->iopt.access_list);\n\txa_for_each(&ioas->iopt.access_list, index, access) {\n\t\tif (!iommufd_lock_obj(&access->obj))\n\t\t\tcontinue;\n\t\txa_unlock(&ioas->iopt.access_list);\n\n\t\taccess->ops->unmap(access->data, iova, length);\n\n\t\tiommufd_put_object(&access->obj);\n\t\txa_lock(&ioas->iopt.access_list);\n\t}\n\txa_unlock(&ioas->iopt.access_list);\n}\n\n \nvoid iommufd_access_unpin_pages(struct iommufd_access *access,\n\t\t\t\tunsigned long iova, unsigned long length)\n{\n\tstruct iopt_area_contig_iter iter;\n\tstruct io_pagetable *iopt;\n\tunsigned long last_iova;\n\tstruct iopt_area *area;\n\n\tif (WARN_ON(!length) ||\n\t    WARN_ON(check_add_overflow(iova, length - 1, &last_iova)))\n\t\treturn;\n\n\tmutex_lock(&access->ioas_lock);\n\t \n\tif (WARN_ON(!access->ioas_unpin)) {\n\t\tmutex_unlock(&access->ioas_lock);\n\t\treturn;\n\t}\n\tiopt = &access->ioas_unpin->iopt;\n\n\tdown_read(&iopt->iova_rwsem);\n\tiopt_for_each_contig_area(&iter, area, iopt, iova, last_iova)\n\t\tiopt_area_remove_access(\n\t\t\tarea, iopt_area_iova_to_index(area, iter.cur_iova),\n\t\t\tiopt_area_iova_to_index(\n\t\t\t\tarea,\n\t\t\t\tmin(last_iova, iopt_area_last_iova(area))));\n\tWARN_ON(!iopt_area_contig_done(&iter));\n\tup_read(&iopt->iova_rwsem);\n\tmutex_unlock(&access->ioas_lock);\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_access_unpin_pages, IOMMUFD);\n\nstatic bool iopt_area_contig_is_aligned(struct iopt_area_contig_iter *iter)\n{\n\tif (iopt_area_start_byte(iter->area, iter->cur_iova) % PAGE_SIZE)\n\t\treturn false;\n\n\tif (!iopt_area_contig_done(iter) &&\n\t    (iopt_area_start_byte(iter->area, iopt_area_last_iova(iter->area)) %\n\t     PAGE_SIZE) != (PAGE_SIZE - 1))\n\t\treturn false;\n\treturn true;\n}\n\nstatic bool check_area_prot(struct iopt_area *area, unsigned int flags)\n{\n\tif (flags & IOMMUFD_ACCESS_RW_WRITE)\n\t\treturn area->iommu_prot & IOMMU_WRITE;\n\treturn area->iommu_prot & IOMMU_READ;\n}\n\n \nint iommufd_access_pin_pages(struct iommufd_access *access, unsigned long iova,\n\t\t\t     unsigned long length, struct page **out_pages,\n\t\t\t     unsigned int flags)\n{\n\tstruct iopt_area_contig_iter iter;\n\tstruct io_pagetable *iopt;\n\tunsigned long last_iova;\n\tstruct iopt_area *area;\n\tint rc;\n\n\t \n\tif (IS_ENABLED(CONFIG_IOMMUFD_TEST) &&\n\t    WARN_ON(access->iova_alignment != PAGE_SIZE || !access->ops->unmap))\n\t\treturn -EINVAL;\n\n\tif (!length)\n\t\treturn -EINVAL;\n\tif (check_add_overflow(iova, length - 1, &last_iova))\n\t\treturn -EOVERFLOW;\n\n\tmutex_lock(&access->ioas_lock);\n\tif (!access->ioas) {\n\t\tmutex_unlock(&access->ioas_lock);\n\t\treturn -ENOENT;\n\t}\n\tiopt = &access->ioas->iopt;\n\n\tdown_read(&iopt->iova_rwsem);\n\tiopt_for_each_contig_area(&iter, area, iopt, iova, last_iova) {\n\t\tunsigned long last = min(last_iova, iopt_area_last_iova(area));\n\t\tunsigned long last_index = iopt_area_iova_to_index(area, last);\n\t\tunsigned long index =\n\t\t\tiopt_area_iova_to_index(area, iter.cur_iova);\n\n\t\tif (area->prevent_access ||\n\t\t    !iopt_area_contig_is_aligned(&iter)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_remove;\n\t\t}\n\n\t\tif (!check_area_prot(area, flags)) {\n\t\t\trc = -EPERM;\n\t\t\tgoto err_remove;\n\t\t}\n\n\t\trc = iopt_area_add_access(area, index, last_index, out_pages,\n\t\t\t\t\t  flags);\n\t\tif (rc)\n\t\t\tgoto err_remove;\n\t\tout_pages += last_index - index + 1;\n\t}\n\tif (!iopt_area_contig_done(&iter)) {\n\t\trc = -ENOENT;\n\t\tgoto err_remove;\n\t}\n\n\tup_read(&iopt->iova_rwsem);\n\tmutex_unlock(&access->ioas_lock);\n\treturn 0;\n\nerr_remove:\n\tif (iova < iter.cur_iova) {\n\t\tlast_iova = iter.cur_iova - 1;\n\t\tiopt_for_each_contig_area(&iter, area, iopt, iova, last_iova)\n\t\t\tiopt_area_remove_access(\n\t\t\t\tarea,\n\t\t\t\tiopt_area_iova_to_index(area, iter.cur_iova),\n\t\t\t\tiopt_area_iova_to_index(\n\t\t\t\t\tarea, min(last_iova,\n\t\t\t\t\t\t  iopt_area_last_iova(area))));\n\t}\n\tup_read(&iopt->iova_rwsem);\n\tmutex_unlock(&access->ioas_lock);\n\treturn rc;\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_access_pin_pages, IOMMUFD);\n\n \nint iommufd_access_rw(struct iommufd_access *access, unsigned long iova,\n\t\t      void *data, size_t length, unsigned int flags)\n{\n\tstruct iopt_area_contig_iter iter;\n\tstruct io_pagetable *iopt;\n\tstruct iopt_area *area;\n\tunsigned long last_iova;\n\tint rc;\n\n\tif (!length)\n\t\treturn -EINVAL;\n\tif (check_add_overflow(iova, length - 1, &last_iova))\n\t\treturn -EOVERFLOW;\n\n\tmutex_lock(&access->ioas_lock);\n\tif (!access->ioas) {\n\t\tmutex_unlock(&access->ioas_lock);\n\t\treturn -ENOENT;\n\t}\n\tiopt = &access->ioas->iopt;\n\n\tdown_read(&iopt->iova_rwsem);\n\tiopt_for_each_contig_area(&iter, area, iopt, iova, last_iova) {\n\t\tunsigned long last = min(last_iova, iopt_area_last_iova(area));\n\t\tunsigned long bytes = (last - iter.cur_iova) + 1;\n\n\t\tif (area->prevent_access) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (!check_area_prot(area, flags)) {\n\t\t\trc = -EPERM;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\trc = iopt_pages_rw_access(\n\t\t\tarea->pages, iopt_area_start_byte(area, iter.cur_iova),\n\t\t\tdata, bytes, flags);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t\tdata += bytes;\n\t}\n\tif (!iopt_area_contig_done(&iter))\n\t\trc = -ENOENT;\nerr_out:\n\tup_read(&iopt->iova_rwsem);\n\tmutex_unlock(&access->ioas_lock);\n\treturn rc;\n}\nEXPORT_SYMBOL_NS_GPL(iommufd_access_rw, IOMMUFD);\n\nint iommufd_get_hw_info(struct iommufd_ucmd *ucmd)\n{\n\tstruct iommu_hw_info *cmd = ucmd->cmd;\n\tvoid __user *user_ptr = u64_to_user_ptr(cmd->data_uptr);\n\tconst struct iommu_ops *ops;\n\tstruct iommufd_device *idev;\n\tunsigned int data_len;\n\tunsigned int copy_len;\n\tvoid *data;\n\tint rc;\n\n\tif (cmd->flags || cmd->__reserved)\n\t\treturn -EOPNOTSUPP;\n\n\tidev = iommufd_get_device(ucmd, cmd->dev_id);\n\tif (IS_ERR(idev))\n\t\treturn PTR_ERR(idev);\n\n\tops = dev_iommu_ops(idev->dev);\n\tif (ops->hw_info) {\n\t\tdata = ops->hw_info(idev->dev, &data_len, &cmd->out_data_type);\n\t\tif (IS_ERR(data)) {\n\t\t\trc = PTR_ERR(data);\n\t\t\tgoto out_put;\n\t\t}\n\n\t\t \n\t\tif (WARN_ON_ONCE(cmd->out_data_type ==\n\t\t\t\t IOMMU_HW_INFO_TYPE_NONE)) {\n\t\t\trc = -ENODEV;\n\t\t\tgoto out_free;\n\t\t}\n\t} else {\n\t\tcmd->out_data_type = IOMMU_HW_INFO_TYPE_NONE;\n\t\tdata_len = 0;\n\t\tdata = NULL;\n\t}\n\n\tcopy_len = min(cmd->data_len, data_len);\n\tif (copy_to_user(user_ptr, data, copy_len)) {\n\t\trc = -EFAULT;\n\t\tgoto out_free;\n\t}\n\n\t \n\tif (copy_len < cmd->data_len) {\n\t\tif (clear_user(user_ptr + copy_len, cmd->data_len - copy_len)) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\n\t \n\tcmd->data_len = data_len;\n\n\trc = iommufd_ucmd_respond(ucmd, sizeof(*cmd));\nout_free:\n\tkfree(data);\nout_put:\n\tiommufd_put_object(&idev->obj);\n\treturn rc;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}