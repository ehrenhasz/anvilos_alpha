{
  "module_name": "mtk_iommu_v1.c",
  "hash_id": "9debf5a48a3f4cf6a2fc44695c092cbddc899f6877a07f35c8a66b29d210332d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/mtk_iommu_v1.c",
  "human_readable_source": "\n \n#include <linux/bug.h>\n#include <linux/clk.h>\n#include <linux/component.h>\n#include <linux/device.h>\n#include <linux/dma-mapping.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/iommu.h>\n#include <linux/iopoll.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/of_platform.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <asm/barrier.h>\n#include <asm/dma-iommu.h>\n#include <dt-bindings/memory/mtk-memory-port.h>\n#include <dt-bindings/memory/mt2701-larb-port.h>\n#include <soc/mediatek/smi.h>\n\n#define REG_MMU_PT_BASE_ADDR\t\t\t0x000\n\n#define F_ALL_INVLD\t\t\t\t0x2\n#define F_MMU_INV_RANGE\t\t\t\t0x1\n#define F_INVLD_EN0\t\t\t\tBIT(0)\n#define F_INVLD_EN1\t\t\t\tBIT(1)\n\n#define F_MMU_FAULT_VA_MSK\t\t\t0xfffff000\n#define MTK_PROTECT_PA_ALIGN\t\t\t128\n\n#define REG_MMU_CTRL_REG\t\t\t0x210\n#define F_MMU_CTRL_COHERENT_EN\t\t\tBIT(8)\n#define REG_MMU_IVRP_PADDR\t\t\t0x214\n#define REG_MMU_INT_CONTROL\t\t\t0x220\n#define F_INT_TRANSLATION_FAULT\t\t\tBIT(0)\n#define F_INT_MAIN_MULTI_HIT_FAULT\t\tBIT(1)\n#define F_INT_INVALID_PA_FAULT\t\t\tBIT(2)\n#define F_INT_ENTRY_REPLACEMENT_FAULT\t\tBIT(3)\n#define F_INT_TABLE_WALK_FAULT\t\t\tBIT(4)\n#define F_INT_TLB_MISS_FAULT\t\t\tBIT(5)\n#define F_INT_PFH_DMA_FIFO_OVERFLOW\t\tBIT(6)\n#define F_INT_MISS_DMA_FIFO_OVERFLOW\t\tBIT(7)\n\n#define F_MMU_TF_PROTECT_SEL(prot)\t\t(((prot) & 0x3) << 5)\n#define F_INT_CLR_BIT\t\t\t\tBIT(12)\n\n#define REG_MMU_FAULT_ST\t\t\t0x224\n#define REG_MMU_FAULT_VA\t\t\t0x228\n#define REG_MMU_INVLD_PA\t\t\t0x22C\n#define REG_MMU_INT_ID\t\t\t\t0x388\n#define REG_MMU_INVALIDATE\t\t\t0x5c0\n#define REG_MMU_INVLD_START_A\t\t\t0x5c4\n#define REG_MMU_INVLD_END_A\t\t\t0x5c8\n\n#define REG_MMU_INV_SEL\t\t\t\t0x5d8\n#define REG_MMU_STANDARD_AXI_MODE\t\t0x5e8\n\n#define REG_MMU_DCM\t\t\t\t0x5f0\n#define F_MMU_DCM_ON\t\t\t\tBIT(1)\n#define REG_MMU_CPE_DONE\t\t\t0x60c\n#define F_DESC_VALID\t\t\t\t0x2\n#define F_DESC_NONSEC\t\t\t\tBIT(3)\n#define MT2701_M4U_TF_LARB(TF)\t\t\t(6 - (((TF) >> 13) & 0x7))\n#define MT2701_M4U_TF_PORT(TF)\t\t\t(((TF) >> 8) & 0xF)\n \n#define MT2701_IOMMU_PAGE_SHIFT\t\t\t12\n#define MT2701_IOMMU_PAGE_SIZE\t\t\t(1UL << MT2701_IOMMU_PAGE_SHIFT)\n#define MT2701_LARB_NR_MAX\t\t\t3\n\n \n#define M2701_IOMMU_PGT_SIZE\t\t\tSZ_4M\n\nstruct mtk_iommu_v1_suspend_reg {\n\tu32\t\t\tstandard_axi_mode;\n\tu32\t\t\tdcm_dis;\n\tu32\t\t\tctrl_reg;\n\tu32\t\t\tint_control0;\n};\n\nstruct mtk_iommu_v1_data {\n\tvoid __iomem\t\t\t*base;\n\tint\t\t\t\tirq;\n\tstruct device\t\t\t*dev;\n\tstruct clk\t\t\t*bclk;\n\tphys_addr_t\t\t\tprotect_base;  \n\tstruct mtk_iommu_v1_domain\t*m4u_dom;\n\n\tstruct iommu_device\t\tiommu;\n\tstruct dma_iommu_mapping\t*mapping;\n\tstruct mtk_smi_larb_iommu\tlarb_imu[MTK_LARB_NR_MAX];\n\n\tstruct mtk_iommu_v1_suspend_reg\treg;\n};\n\nstruct mtk_iommu_v1_domain {\n\tspinlock_t\t\t\tpgtlock;  \n\tstruct iommu_domain\t\tdomain;\n\tu32\t\t\t\t*pgt_va;\n\tdma_addr_t\t\t\tpgt_pa;\n\tstruct mtk_iommu_v1_data\t*data;\n};\n\nstatic int mtk_iommu_v1_bind(struct device *dev)\n{\n\tstruct mtk_iommu_v1_data *data = dev_get_drvdata(dev);\n\n\treturn component_bind_all(dev, &data->larb_imu);\n}\n\nstatic void mtk_iommu_v1_unbind(struct device *dev)\n{\n\tstruct mtk_iommu_v1_data *data = dev_get_drvdata(dev);\n\n\tcomponent_unbind_all(dev, &data->larb_imu);\n}\n\nstatic struct mtk_iommu_v1_domain *to_mtk_domain(struct iommu_domain *dom)\n{\n\treturn container_of(dom, struct mtk_iommu_v1_domain, domain);\n}\n\nstatic const int mt2701_m4u_in_larb[] = {\n\tLARB0_PORT_OFFSET, LARB1_PORT_OFFSET,\n\tLARB2_PORT_OFFSET, LARB3_PORT_OFFSET\n};\n\nstatic inline int mt2701_m4u_to_larb(int id)\n{\n\tint i;\n\n\tfor (i = ARRAY_SIZE(mt2701_m4u_in_larb) - 1; i >= 0; i--)\n\t\tif ((id) >= mt2701_m4u_in_larb[i])\n\t\t\treturn i;\n\n\treturn 0;\n}\n\nstatic inline int mt2701_m4u_to_port(int id)\n{\n\tint larb = mt2701_m4u_to_larb(id);\n\n\treturn id - mt2701_m4u_in_larb[larb];\n}\n\nstatic void mtk_iommu_v1_tlb_flush_all(struct mtk_iommu_v1_data *data)\n{\n\twritel_relaxed(F_INVLD_EN1 | F_INVLD_EN0,\n\t\t\tdata->base + REG_MMU_INV_SEL);\n\twritel_relaxed(F_ALL_INVLD, data->base + REG_MMU_INVALIDATE);\n\twmb();  \n}\n\nstatic void mtk_iommu_v1_tlb_flush_range(struct mtk_iommu_v1_data *data,\n\t\t\t\t\t unsigned long iova, size_t size)\n{\n\tint ret;\n\tu32 tmp;\n\n\twritel_relaxed(F_INVLD_EN1 | F_INVLD_EN0,\n\t\tdata->base + REG_MMU_INV_SEL);\n\twritel_relaxed(iova & F_MMU_FAULT_VA_MSK,\n\t\tdata->base + REG_MMU_INVLD_START_A);\n\twritel_relaxed((iova + size - 1) & F_MMU_FAULT_VA_MSK,\n\t\tdata->base + REG_MMU_INVLD_END_A);\n\twritel_relaxed(F_MMU_INV_RANGE, data->base + REG_MMU_INVALIDATE);\n\n\tret = readl_poll_timeout_atomic(data->base + REG_MMU_CPE_DONE,\n\t\t\t\ttmp, tmp != 0, 10, 100000);\n\tif (ret) {\n\t\tdev_warn(data->dev,\n\t\t\t \"Partial TLB flush timed out, falling back to full flush\\n\");\n\t\tmtk_iommu_v1_tlb_flush_all(data);\n\t}\n\t \n\twritel_relaxed(0, data->base + REG_MMU_CPE_DONE);\n}\n\nstatic irqreturn_t mtk_iommu_v1_isr(int irq, void *dev_id)\n{\n\tstruct mtk_iommu_v1_data *data = dev_id;\n\tstruct mtk_iommu_v1_domain *dom = data->m4u_dom;\n\tu32 int_state, regval, fault_iova, fault_pa;\n\tunsigned int fault_larb, fault_port;\n\n\t \n\tint_state = readl_relaxed(data->base + REG_MMU_FAULT_ST);\n\tfault_iova = readl_relaxed(data->base + REG_MMU_FAULT_VA);\n\n\tfault_iova &= F_MMU_FAULT_VA_MSK;\n\tfault_pa = readl_relaxed(data->base + REG_MMU_INVLD_PA);\n\tregval = readl_relaxed(data->base + REG_MMU_INT_ID);\n\tfault_larb = MT2701_M4U_TF_LARB(regval);\n\tfault_port = MT2701_M4U_TF_PORT(regval);\n\n\t \n\tif (report_iommu_fault(&dom->domain, data->dev, fault_iova,\n\t\t\tIOMMU_FAULT_READ))\n\t\tdev_err_ratelimited(data->dev,\n\t\t\t\"fault type=0x%x iova=0x%x pa=0x%x larb=%d port=%d\\n\",\n\t\t\tint_state, fault_iova, fault_pa,\n\t\t\tfault_larb, fault_port);\n\n\t \n\tregval = readl_relaxed(data->base + REG_MMU_INT_CONTROL);\n\tregval |= F_INT_CLR_BIT;\n\twritel_relaxed(regval, data->base + REG_MMU_INT_CONTROL);\n\n\tmtk_iommu_v1_tlb_flush_all(data);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void mtk_iommu_v1_config(struct mtk_iommu_v1_data *data,\n\t\t\t\tstruct device *dev, bool enable)\n{\n\tstruct mtk_smi_larb_iommu    *larb_mmu;\n\tunsigned int                 larbid, portid;\n\tstruct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);\n\tint i;\n\n\tfor (i = 0; i < fwspec->num_ids; ++i) {\n\t\tlarbid = mt2701_m4u_to_larb(fwspec->ids[i]);\n\t\tportid = mt2701_m4u_to_port(fwspec->ids[i]);\n\t\tlarb_mmu = &data->larb_imu[larbid];\n\n\t\tdev_dbg(dev, \"%s iommu port: %d\\n\",\n\t\t\tenable ? \"enable\" : \"disable\", portid);\n\n\t\tif (enable)\n\t\t\tlarb_mmu->mmu |= MTK_SMI_MMU_EN(portid);\n\t\telse\n\t\t\tlarb_mmu->mmu &= ~MTK_SMI_MMU_EN(portid);\n\t}\n}\n\nstatic int mtk_iommu_v1_domain_finalise(struct mtk_iommu_v1_data *data)\n{\n\tstruct mtk_iommu_v1_domain *dom = data->m4u_dom;\n\n\tspin_lock_init(&dom->pgtlock);\n\n\tdom->pgt_va = dma_alloc_coherent(data->dev, M2701_IOMMU_PGT_SIZE,\n\t\t\t\t\t &dom->pgt_pa, GFP_KERNEL);\n\tif (!dom->pgt_va)\n\t\treturn -ENOMEM;\n\n\twritel(dom->pgt_pa, data->base + REG_MMU_PT_BASE_ADDR);\n\n\tdom->data = data;\n\n\treturn 0;\n}\n\nstatic struct iommu_domain *mtk_iommu_v1_domain_alloc(unsigned type)\n{\n\tstruct mtk_iommu_v1_domain *dom;\n\n\tif (type != IOMMU_DOMAIN_UNMANAGED)\n\t\treturn NULL;\n\n\tdom = kzalloc(sizeof(*dom), GFP_KERNEL);\n\tif (!dom)\n\t\treturn NULL;\n\n\treturn &dom->domain;\n}\n\nstatic void mtk_iommu_v1_domain_free(struct iommu_domain *domain)\n{\n\tstruct mtk_iommu_v1_domain *dom = to_mtk_domain(domain);\n\tstruct mtk_iommu_v1_data *data = dom->data;\n\n\tdma_free_coherent(data->dev, M2701_IOMMU_PGT_SIZE,\n\t\t\tdom->pgt_va, dom->pgt_pa);\n\tkfree(to_mtk_domain(domain));\n}\n\nstatic int mtk_iommu_v1_attach_device(struct iommu_domain *domain, struct device *dev)\n{\n\tstruct mtk_iommu_v1_data *data = dev_iommu_priv_get(dev);\n\tstruct mtk_iommu_v1_domain *dom = to_mtk_domain(domain);\n\tstruct dma_iommu_mapping *mtk_mapping;\n\tint ret;\n\n\t \n\tmtk_mapping = data->mapping;\n\tif (mtk_mapping->domain != domain)\n\t\treturn 0;\n\n\tif (!data->m4u_dom) {\n\t\tdata->m4u_dom = dom;\n\t\tret = mtk_iommu_v1_domain_finalise(data);\n\t\tif (ret) {\n\t\t\tdata->m4u_dom = NULL;\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tmtk_iommu_v1_config(data, dev, true);\n\treturn 0;\n}\n\nstatic void mtk_iommu_v1_set_platform_dma(struct device *dev)\n{\n\tstruct mtk_iommu_v1_data *data = dev_iommu_priv_get(dev);\n\n\tmtk_iommu_v1_config(data, dev, false);\n}\n\nstatic int mtk_iommu_v1_map(struct iommu_domain *domain, unsigned long iova,\n\t\t\t    phys_addr_t paddr, size_t pgsize, size_t pgcount,\n\t\t\t    int prot, gfp_t gfp, size_t *mapped)\n{\n\tstruct mtk_iommu_v1_domain *dom = to_mtk_domain(domain);\n\tunsigned long flags;\n\tunsigned int i;\n\tu32 *pgt_base_iova = dom->pgt_va + (iova  >> MT2701_IOMMU_PAGE_SHIFT);\n\tu32 pabase = (u32)paddr;\n\n\tspin_lock_irqsave(&dom->pgtlock, flags);\n\tfor (i = 0; i < pgcount; i++) {\n\t\tif (pgt_base_iova[i])\n\t\t\tbreak;\n\t\tpgt_base_iova[i] = pabase | F_DESC_VALID | F_DESC_NONSEC;\n\t\tpabase += MT2701_IOMMU_PAGE_SIZE;\n\t}\n\n\tspin_unlock_irqrestore(&dom->pgtlock, flags);\n\n\t*mapped = i * MT2701_IOMMU_PAGE_SIZE;\n\tmtk_iommu_v1_tlb_flush_range(dom->data, iova, *mapped);\n\n\treturn i == pgcount ? 0 : -EEXIST;\n}\n\nstatic size_t mtk_iommu_v1_unmap(struct iommu_domain *domain, unsigned long iova,\n\t\t\t\t size_t pgsize, size_t pgcount,\n\t\t\t\t struct iommu_iotlb_gather *gather)\n{\n\tstruct mtk_iommu_v1_domain *dom = to_mtk_domain(domain);\n\tunsigned long flags;\n\tu32 *pgt_base_iova = dom->pgt_va + (iova  >> MT2701_IOMMU_PAGE_SHIFT);\n\tsize_t size = pgcount * MT2701_IOMMU_PAGE_SIZE;\n\n\tspin_lock_irqsave(&dom->pgtlock, flags);\n\tmemset(pgt_base_iova, 0, pgcount * sizeof(u32));\n\tspin_unlock_irqrestore(&dom->pgtlock, flags);\n\n\tmtk_iommu_v1_tlb_flush_range(dom->data, iova, size);\n\n\treturn size;\n}\n\nstatic phys_addr_t mtk_iommu_v1_iova_to_phys(struct iommu_domain *domain, dma_addr_t iova)\n{\n\tstruct mtk_iommu_v1_domain *dom = to_mtk_domain(domain);\n\tunsigned long flags;\n\tphys_addr_t pa;\n\n\tspin_lock_irqsave(&dom->pgtlock, flags);\n\tpa = *(dom->pgt_va + (iova >> MT2701_IOMMU_PAGE_SHIFT));\n\tpa = pa & (~(MT2701_IOMMU_PAGE_SIZE - 1));\n\tspin_unlock_irqrestore(&dom->pgtlock, flags);\n\n\treturn pa;\n}\n\nstatic const struct iommu_ops mtk_iommu_v1_ops;\n\n \nstatic int mtk_iommu_v1_create_mapping(struct device *dev, struct of_phandle_args *args)\n{\n\tstruct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);\n\tstruct mtk_iommu_v1_data *data;\n\tstruct platform_device *m4updev;\n\tstruct dma_iommu_mapping *mtk_mapping;\n\tint ret;\n\n\tif (args->args_count != 1) {\n\t\tdev_err(dev, \"invalid #iommu-cells(%d) property for IOMMU\\n\",\n\t\t\targs->args_count);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!fwspec) {\n\t\tret = iommu_fwspec_init(dev, &args->np->fwnode, &mtk_iommu_v1_ops);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tfwspec = dev_iommu_fwspec_get(dev);\n\t} else if (dev_iommu_fwspec_get(dev)->ops != &mtk_iommu_v1_ops) {\n\t\treturn -EINVAL;\n\t}\n\n\tif (!dev_iommu_priv_get(dev)) {\n\t\t \n\t\tm4updev = of_find_device_by_node(args->np);\n\t\tif (WARN_ON(!m4updev))\n\t\t\treturn -EINVAL;\n\n\t\tdev_iommu_priv_set(dev, platform_get_drvdata(m4updev));\n\t}\n\n\tret = iommu_fwspec_add_ids(dev, args->args, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tdata = dev_iommu_priv_get(dev);\n\tmtk_mapping = data->mapping;\n\tif (!mtk_mapping) {\n\t\t \n\t\tmtk_mapping = arm_iommu_create_mapping(&platform_bus_type,\n\t\t\t\t\t\t0, 1ULL << 32);\n\t\tif (IS_ERR(mtk_mapping))\n\t\t\treturn PTR_ERR(mtk_mapping);\n\n\t\tdata->mapping = mtk_mapping;\n\t}\n\n\treturn 0;\n}\n\nstatic int mtk_iommu_v1_def_domain_type(struct device *dev)\n{\n\treturn IOMMU_DOMAIN_UNMANAGED;\n}\n\nstatic struct iommu_device *mtk_iommu_v1_probe_device(struct device *dev)\n{\n\tstruct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);\n\tstruct of_phandle_args iommu_spec;\n\tstruct mtk_iommu_v1_data *data;\n\tint err, idx = 0, larbid, larbidx;\n\tstruct device_link *link;\n\tstruct device *larbdev;\n\n\t \n\tif (fwspec) {\n\t\tiommu_fwspec_free(dev);\n\t\tfwspec = dev_iommu_fwspec_get(dev);\n\t}\n\n\twhile (!of_parse_phandle_with_args(dev->of_node, \"iommus\",\n\t\t\t\t\t   \"#iommu-cells\",\n\t\t\t\t\t   idx, &iommu_spec)) {\n\n\t\terr = mtk_iommu_v1_create_mapping(dev, &iommu_spec);\n\t\tof_node_put(iommu_spec.np);\n\t\tif (err)\n\t\t\treturn ERR_PTR(err);\n\n\t\t \n\t\tfwspec = dev_iommu_fwspec_get(dev);\n\t\tidx++;\n\t}\n\n\tif (!fwspec || fwspec->ops != &mtk_iommu_v1_ops)\n\t\treturn ERR_PTR(-ENODEV);  \n\n\tdata = dev_iommu_priv_get(dev);\n\n\t \n\tlarbid = mt2701_m4u_to_larb(fwspec->ids[0]);\n\tif (larbid >= MT2701_LARB_NR_MAX)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tfor (idx = 1; idx < fwspec->num_ids; idx++) {\n\t\tlarbidx = mt2701_m4u_to_larb(fwspec->ids[idx]);\n\t\tif (larbid != larbidx) {\n\t\t\tdev_err(dev, \"Can only use one larb. Fail@larb%d-%d.\\n\",\n\t\t\t\tlarbid, larbidx);\n\t\t\treturn ERR_PTR(-EINVAL);\n\t\t}\n\t}\n\n\tlarbdev = data->larb_imu[larbid].dev;\n\tif (!larbdev)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tlink = device_link_add(dev, larbdev,\n\t\t\t       DL_FLAG_PM_RUNTIME | DL_FLAG_STATELESS);\n\tif (!link)\n\t\tdev_err(dev, \"Unable to link %s\\n\", dev_name(larbdev));\n\n\treturn &data->iommu;\n}\n\nstatic void mtk_iommu_v1_probe_finalize(struct device *dev)\n{\n\tstruct dma_iommu_mapping *mtk_mapping;\n\tstruct mtk_iommu_v1_data *data;\n\tint err;\n\n\tdata        = dev_iommu_priv_get(dev);\n\tmtk_mapping = data->mapping;\n\n\terr = arm_iommu_attach_device(dev, mtk_mapping);\n\tif (err)\n\t\tdev_err(dev, \"Can't create IOMMU mapping - DMA-OPS will not work\\n\");\n}\n\nstatic void mtk_iommu_v1_release_device(struct device *dev)\n{\n\tstruct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);\n\tstruct mtk_iommu_v1_data *data;\n\tstruct device *larbdev;\n\tunsigned int larbid;\n\n\tdata = dev_iommu_priv_get(dev);\n\tlarbid = mt2701_m4u_to_larb(fwspec->ids[0]);\n\tlarbdev = data->larb_imu[larbid].dev;\n\tdevice_link_remove(dev, larbdev);\n}\n\nstatic int mtk_iommu_v1_hw_init(const struct mtk_iommu_v1_data *data)\n{\n\tu32 regval;\n\tint ret;\n\n\tret = clk_prepare_enable(data->bclk);\n\tif (ret) {\n\t\tdev_err(data->dev, \"Failed to enable iommu bclk(%d)\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tregval = F_MMU_CTRL_COHERENT_EN | F_MMU_TF_PROTECT_SEL(2);\n\twritel_relaxed(regval, data->base + REG_MMU_CTRL_REG);\n\n\tregval = F_INT_TRANSLATION_FAULT |\n\t\tF_INT_MAIN_MULTI_HIT_FAULT |\n\t\tF_INT_INVALID_PA_FAULT |\n\t\tF_INT_ENTRY_REPLACEMENT_FAULT |\n\t\tF_INT_TABLE_WALK_FAULT |\n\t\tF_INT_TLB_MISS_FAULT |\n\t\tF_INT_PFH_DMA_FIFO_OVERFLOW |\n\t\tF_INT_MISS_DMA_FIFO_OVERFLOW;\n\twritel_relaxed(regval, data->base + REG_MMU_INT_CONTROL);\n\n\t \n\twritel_relaxed(data->protect_base,\n\t\t\tdata->base + REG_MMU_IVRP_PADDR);\n\n\twritel_relaxed(F_MMU_DCM_ON, data->base + REG_MMU_DCM);\n\n\tif (devm_request_irq(data->dev, data->irq, mtk_iommu_v1_isr, 0,\n\t\t\t     dev_name(data->dev), (void *)data)) {\n\t\twritel_relaxed(0, data->base + REG_MMU_PT_BASE_ADDR);\n\t\tclk_disable_unprepare(data->bclk);\n\t\tdev_err(data->dev, \"Failed @ IRQ-%d Request\\n\", data->irq);\n\t\treturn -ENODEV;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct iommu_ops mtk_iommu_v1_ops = {\n\t.domain_alloc\t= mtk_iommu_v1_domain_alloc,\n\t.probe_device\t= mtk_iommu_v1_probe_device,\n\t.probe_finalize = mtk_iommu_v1_probe_finalize,\n\t.release_device\t= mtk_iommu_v1_release_device,\n\t.def_domain_type = mtk_iommu_v1_def_domain_type,\n\t.device_group\t= generic_device_group,\n\t.pgsize_bitmap\t= MT2701_IOMMU_PAGE_SIZE,\n\t.set_platform_dma_ops = mtk_iommu_v1_set_platform_dma,\n\t.owner          = THIS_MODULE,\n\t.default_domain_ops = &(const struct iommu_domain_ops) {\n\t\t.attach_dev\t= mtk_iommu_v1_attach_device,\n\t\t.map_pages\t= mtk_iommu_v1_map,\n\t\t.unmap_pages\t= mtk_iommu_v1_unmap,\n\t\t.iova_to_phys\t= mtk_iommu_v1_iova_to_phys,\n\t\t.free\t\t= mtk_iommu_v1_domain_free,\n\t}\n};\n\nstatic const struct of_device_id mtk_iommu_v1_of_ids[] = {\n\t{ .compatible = \"mediatek,mt2701-m4u\", },\n\t{}\n};\n\nstatic const struct component_master_ops mtk_iommu_v1_com_ops = {\n\t.bind\t\t= mtk_iommu_v1_bind,\n\t.unbind\t\t= mtk_iommu_v1_unbind,\n};\n\nstatic int mtk_iommu_v1_probe(struct platform_device *pdev)\n{\n\tstruct device\t\t\t*dev = &pdev->dev;\n\tstruct mtk_iommu_v1_data\t*data;\n\tstruct resource\t\t\t*res;\n\tstruct component_match\t\t*match = NULL;\n\tvoid\t\t\t\t*protect;\n\tint\t\t\t\tlarb_nr, ret, i;\n\n\tdata = devm_kzalloc(dev, sizeof(*data), GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tdata->dev = dev;\n\n\t \n\tprotect = devm_kzalloc(dev, MTK_PROTECT_PA_ALIGN * 2,\n\t\t\tGFP_KERNEL | GFP_DMA);\n\tif (!protect)\n\t\treturn -ENOMEM;\n\tdata->protect_base = ALIGN(virt_to_phys(protect), MTK_PROTECT_PA_ALIGN);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tdata->base = devm_ioremap_resource(dev, res);\n\tif (IS_ERR(data->base))\n\t\treturn PTR_ERR(data->base);\n\n\tdata->irq = platform_get_irq(pdev, 0);\n\tif (data->irq < 0)\n\t\treturn data->irq;\n\n\tdata->bclk = devm_clk_get(dev, \"bclk\");\n\tif (IS_ERR(data->bclk))\n\t\treturn PTR_ERR(data->bclk);\n\n\tlarb_nr = of_count_phandle_with_args(dev->of_node,\n\t\t\t\t\t     \"mediatek,larbs\", NULL);\n\tif (larb_nr < 0)\n\t\treturn larb_nr;\n\n\tfor (i = 0; i < larb_nr; i++) {\n\t\tstruct device_node *larbnode;\n\t\tstruct platform_device *plarbdev;\n\n\t\tlarbnode = of_parse_phandle(dev->of_node, \"mediatek,larbs\", i);\n\t\tif (!larbnode)\n\t\t\treturn -EINVAL;\n\n\t\tif (!of_device_is_available(larbnode)) {\n\t\t\tof_node_put(larbnode);\n\t\t\tcontinue;\n\t\t}\n\n\t\tplarbdev = of_find_device_by_node(larbnode);\n\t\tif (!plarbdev) {\n\t\t\tof_node_put(larbnode);\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tif (!plarbdev->dev.driver) {\n\t\t\tof_node_put(larbnode);\n\t\t\treturn -EPROBE_DEFER;\n\t\t}\n\t\tdata->larb_imu[i].dev = &plarbdev->dev;\n\n\t\tcomponent_match_add_release(dev, &match, component_release_of,\n\t\t\t\t\t    component_compare_of, larbnode);\n\t}\n\n\tplatform_set_drvdata(pdev, data);\n\n\tret = mtk_iommu_v1_hw_init(data);\n\tif (ret)\n\t\treturn ret;\n\n\tret = iommu_device_sysfs_add(&data->iommu, &pdev->dev, NULL,\n\t\t\t\t     dev_name(&pdev->dev));\n\tif (ret)\n\t\tgoto out_clk_unprepare;\n\n\tret = iommu_device_register(&data->iommu, &mtk_iommu_v1_ops, dev);\n\tif (ret)\n\t\tgoto out_sysfs_remove;\n\n\tret = component_master_add_with_match(dev, &mtk_iommu_v1_com_ops, match);\n\tif (ret)\n\t\tgoto out_dev_unreg;\n\treturn ret;\n\nout_dev_unreg:\n\tiommu_device_unregister(&data->iommu);\nout_sysfs_remove:\n\tiommu_device_sysfs_remove(&data->iommu);\nout_clk_unprepare:\n\tclk_disable_unprepare(data->bclk);\n\treturn ret;\n}\n\nstatic void mtk_iommu_v1_remove(struct platform_device *pdev)\n{\n\tstruct mtk_iommu_v1_data *data = platform_get_drvdata(pdev);\n\n\tiommu_device_sysfs_remove(&data->iommu);\n\tiommu_device_unregister(&data->iommu);\n\n\tclk_disable_unprepare(data->bclk);\n\tdevm_free_irq(&pdev->dev, data->irq, data);\n\tcomponent_master_del(&pdev->dev, &mtk_iommu_v1_com_ops);\n}\n\nstatic int __maybe_unused mtk_iommu_v1_suspend(struct device *dev)\n{\n\tstruct mtk_iommu_v1_data *data = dev_get_drvdata(dev);\n\tstruct mtk_iommu_v1_suspend_reg *reg = &data->reg;\n\tvoid __iomem *base = data->base;\n\n\treg->standard_axi_mode = readl_relaxed(base +\n\t\t\t\t\t       REG_MMU_STANDARD_AXI_MODE);\n\treg->dcm_dis = readl_relaxed(base + REG_MMU_DCM);\n\treg->ctrl_reg = readl_relaxed(base + REG_MMU_CTRL_REG);\n\treg->int_control0 = readl_relaxed(base + REG_MMU_INT_CONTROL);\n\treturn 0;\n}\n\nstatic int __maybe_unused mtk_iommu_v1_resume(struct device *dev)\n{\n\tstruct mtk_iommu_v1_data *data = dev_get_drvdata(dev);\n\tstruct mtk_iommu_v1_suspend_reg *reg = &data->reg;\n\tvoid __iomem *base = data->base;\n\n\twritel_relaxed(data->m4u_dom->pgt_pa, base + REG_MMU_PT_BASE_ADDR);\n\twritel_relaxed(reg->standard_axi_mode,\n\t\t       base + REG_MMU_STANDARD_AXI_MODE);\n\twritel_relaxed(reg->dcm_dis, base + REG_MMU_DCM);\n\twritel_relaxed(reg->ctrl_reg, base + REG_MMU_CTRL_REG);\n\twritel_relaxed(reg->int_control0, base + REG_MMU_INT_CONTROL);\n\twritel_relaxed(data->protect_base, base + REG_MMU_IVRP_PADDR);\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops mtk_iommu_v1_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(mtk_iommu_v1_suspend, mtk_iommu_v1_resume)\n};\n\nstatic struct platform_driver mtk_iommu_v1_driver = {\n\t.probe\t= mtk_iommu_v1_probe,\n\t.remove_new = mtk_iommu_v1_remove,\n\t.driver\t= {\n\t\t.name = \"mtk-iommu-v1\",\n\t\t.of_match_table = mtk_iommu_v1_of_ids,\n\t\t.pm = &mtk_iommu_v1_pm_ops,\n\t}\n};\nmodule_platform_driver(mtk_iommu_v1_driver);\n\nMODULE_DESCRIPTION(\"IOMMU API for MediaTek M4U v1 implementations\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}