{
  "module_name": "msm_iommu.c",
  "hash_id": "cb78182357adb6a24003e570b92ec2b72f2b3a8ecb70eb0e0b0fbde2e996cb33",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iommu/msm_iommu.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/platform_device.h>\n#include <linux/errno.h>\n#include <linux/io.h>\n#include <linux/io-pgtable.h>\n#include <linux/interrupt.h>\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/iommu.h>\n#include <linux/clk.h>\n#include <linux/err.h>\n\n#include <asm/cacheflush.h>\n#include <linux/sizes.h>\n\n#include \"msm_iommu_hw-8xxx.h\"\n#include \"msm_iommu.h\"\n\n#define MRC(reg, processor, op1, crn, crm, op2)\t\t\t\t\\\n__asm__ __volatile__ (\t\t\t\t\t\t\t\\\n\"   mrc   \"   #processor \",\" #op1 \", %0,\"  #crn \",\" #crm \",\" #op2 \"\\n\"  \\\n: \"=r\" (reg))\n\n \n#define MSM_IOMMU_PGSIZES\t(SZ_4K | SZ_64K | SZ_1M | SZ_16M)\n\nstatic DEFINE_SPINLOCK(msm_iommu_lock);\nstatic LIST_HEAD(qcom_iommu_devices);\nstatic struct iommu_ops msm_iommu_ops;\n\nstruct msm_priv {\n\tstruct list_head list_attached;\n\tstruct iommu_domain domain;\n\tstruct io_pgtable_cfg\tcfg;\n\tstruct io_pgtable_ops\t*iop;\n\tstruct device\t\t*dev;\n\tspinlock_t\t\tpgtlock;  \n};\n\nstatic struct msm_priv *to_msm_priv(struct iommu_domain *dom)\n{\n\treturn container_of(dom, struct msm_priv, domain);\n}\n\nstatic int __enable_clocks(struct msm_iommu_dev *iommu)\n{\n\tint ret;\n\n\tret = clk_enable(iommu->pclk);\n\tif (ret)\n\t\tgoto fail;\n\n\tif (iommu->clk) {\n\t\tret = clk_enable(iommu->clk);\n\t\tif (ret)\n\t\t\tclk_disable(iommu->pclk);\n\t}\nfail:\n\treturn ret;\n}\n\nstatic void __disable_clocks(struct msm_iommu_dev *iommu)\n{\n\tif (iommu->clk)\n\t\tclk_disable(iommu->clk);\n\tclk_disable(iommu->pclk);\n}\n\nstatic void msm_iommu_reset(void __iomem *base, int ncb)\n{\n\tint ctx;\n\n\tSET_RPUE(base, 0);\n\tSET_RPUEIE(base, 0);\n\tSET_ESRRESTORE(base, 0);\n\tSET_TBE(base, 0);\n\tSET_CR(base, 0);\n\tSET_SPDMBE(base, 0);\n\tSET_TESTBUSCR(base, 0);\n\tSET_TLBRSW(base, 0);\n\tSET_GLOBAL_TLBIALL(base, 0);\n\tSET_RPU_ACR(base, 0);\n\tSET_TLBLKCRWE(base, 1);\n\n\tfor (ctx = 0; ctx < ncb; ctx++) {\n\t\tSET_BPRCOSH(base, ctx, 0);\n\t\tSET_BPRCISH(base, ctx, 0);\n\t\tSET_BPRCNSH(base, ctx, 0);\n\t\tSET_BPSHCFG(base, ctx, 0);\n\t\tSET_BPMTCFG(base, ctx, 0);\n\t\tSET_ACTLR(base, ctx, 0);\n\t\tSET_SCTLR(base, ctx, 0);\n\t\tSET_FSRRESTORE(base, ctx, 0);\n\t\tSET_TTBR0(base, ctx, 0);\n\t\tSET_TTBR1(base, ctx, 0);\n\t\tSET_TTBCR(base, ctx, 0);\n\t\tSET_BFBCR(base, ctx, 0);\n\t\tSET_PAR(base, ctx, 0);\n\t\tSET_FAR(base, ctx, 0);\n\t\tSET_CTX_TLBIALL(base, ctx, 0);\n\t\tSET_TLBFLPTER(base, ctx, 0);\n\t\tSET_TLBSLPTER(base, ctx, 0);\n\t\tSET_TLBLKCR(base, ctx, 0);\n\t\tSET_CONTEXTIDR(base, ctx, 0);\n\t}\n}\n\nstatic void __flush_iotlb(void *cookie)\n{\n\tstruct msm_priv *priv = cookie;\n\tstruct msm_iommu_dev *iommu = NULL;\n\tstruct msm_iommu_ctx_dev *master;\n\tint ret = 0;\n\n\tlist_for_each_entry(iommu, &priv->list_attached, dom_node) {\n\t\tret = __enable_clocks(iommu);\n\t\tif (ret)\n\t\t\tgoto fail;\n\n\t\tlist_for_each_entry(master, &iommu->ctx_list, list)\n\t\t\tSET_CTX_TLBIALL(iommu->base, master->num, 0);\n\n\t\t__disable_clocks(iommu);\n\t}\nfail:\n\treturn;\n}\n\nstatic void __flush_iotlb_range(unsigned long iova, size_t size,\n\t\t\t\tsize_t granule, bool leaf, void *cookie)\n{\n\tstruct msm_priv *priv = cookie;\n\tstruct msm_iommu_dev *iommu = NULL;\n\tstruct msm_iommu_ctx_dev *master;\n\tint ret = 0;\n\tint temp_size;\n\n\tlist_for_each_entry(iommu, &priv->list_attached, dom_node) {\n\t\tret = __enable_clocks(iommu);\n\t\tif (ret)\n\t\t\tgoto fail;\n\n\t\tlist_for_each_entry(master, &iommu->ctx_list, list) {\n\t\t\ttemp_size = size;\n\t\t\tdo {\n\t\t\t\tiova &= TLBIVA_VA;\n\t\t\t\tiova |= GET_CONTEXTIDR_ASID(iommu->base,\n\t\t\t\t\t\t\t    master->num);\n\t\t\t\tSET_TLBIVA(iommu->base, master->num, iova);\n\t\t\t\tiova += granule;\n\t\t\t} while (temp_size -= granule);\n\t\t}\n\n\t\t__disable_clocks(iommu);\n\t}\n\nfail:\n\treturn;\n}\n\nstatic void __flush_iotlb_walk(unsigned long iova, size_t size,\n\t\t\t       size_t granule, void *cookie)\n{\n\t__flush_iotlb_range(iova, size, granule, false, cookie);\n}\n\nstatic void __flush_iotlb_page(struct iommu_iotlb_gather *gather,\n\t\t\t       unsigned long iova, size_t granule, void *cookie)\n{\n\t__flush_iotlb_range(iova, granule, granule, true, cookie);\n}\n\nstatic const struct iommu_flush_ops msm_iommu_flush_ops = {\n\t.tlb_flush_all = __flush_iotlb,\n\t.tlb_flush_walk = __flush_iotlb_walk,\n\t.tlb_add_page = __flush_iotlb_page,\n};\n\nstatic int msm_iommu_alloc_ctx(unsigned long *map, int start, int end)\n{\n\tint idx;\n\n\tdo {\n\t\tidx = find_next_zero_bit(map, end, start);\n\t\tif (idx == end)\n\t\t\treturn -ENOSPC;\n\t} while (test_and_set_bit(idx, map));\n\n\treturn idx;\n}\n\nstatic void msm_iommu_free_ctx(unsigned long *map, int idx)\n{\n\tclear_bit(idx, map);\n}\n\nstatic void config_mids(struct msm_iommu_dev *iommu,\n\t\t\tstruct msm_iommu_ctx_dev *master)\n{\n\tint mid, ctx, i;\n\n\tfor (i = 0; i < master->num_mids; i++) {\n\t\tmid = master->mids[i];\n\t\tctx = master->num;\n\n\t\tSET_M2VCBR_N(iommu->base, mid, 0);\n\t\tSET_CBACR_N(iommu->base, ctx, 0);\n\n\t\t \n\t\tSET_VMID(iommu->base, mid, 0);\n\n\t\t \n\t\tSET_CBNDX(iommu->base, mid, ctx);\n\n\t\t \n\t\tSET_CBVMID(iommu->base, ctx, 0);\n\n\t\t \n\t\tSET_CONTEXTIDR_ASID(iommu->base, ctx, ctx);\n\n\t\t \n\t\tSET_NSCFG(iommu->base, mid, 3);\n\t}\n}\n\nstatic void __reset_context(void __iomem *base, int ctx)\n{\n\tSET_BPRCOSH(base, ctx, 0);\n\tSET_BPRCISH(base, ctx, 0);\n\tSET_BPRCNSH(base, ctx, 0);\n\tSET_BPSHCFG(base, ctx, 0);\n\tSET_BPMTCFG(base, ctx, 0);\n\tSET_ACTLR(base, ctx, 0);\n\tSET_SCTLR(base, ctx, 0);\n\tSET_FSRRESTORE(base, ctx, 0);\n\tSET_TTBR0(base, ctx, 0);\n\tSET_TTBR1(base, ctx, 0);\n\tSET_TTBCR(base, ctx, 0);\n\tSET_BFBCR(base, ctx, 0);\n\tSET_PAR(base, ctx, 0);\n\tSET_FAR(base, ctx, 0);\n\tSET_CTX_TLBIALL(base, ctx, 0);\n\tSET_TLBFLPTER(base, ctx, 0);\n\tSET_TLBSLPTER(base, ctx, 0);\n\tSET_TLBLKCR(base, ctx, 0);\n}\n\nstatic void __program_context(void __iomem *base, int ctx,\n\t\t\t      struct msm_priv *priv)\n{\n\t__reset_context(base, ctx);\n\n\t \n\tSET_TRE(base, ctx, 1);\n\tSET_AFE(base, ctx, 1);\n\n\t \n\t \n\tSET_TLBMCFG(base, ctx, 0x3);\n\n\t \n\tSET_V2PCFG(base, ctx, 0x3);\n\n\tSET_TTBCR(base, ctx, priv->cfg.arm_v7s_cfg.tcr);\n\tSET_TTBR0(base, ctx, priv->cfg.arm_v7s_cfg.ttbr);\n\tSET_TTBR1(base, ctx, 0);\n\n\t \n\tSET_PRRR(base, ctx, priv->cfg.arm_v7s_cfg.prrr);\n\tSET_NMRR(base, ctx, priv->cfg.arm_v7s_cfg.nmrr);\n\n\t \n\tSET_CTX_TLBIALL(base, ctx, 0);\n\n\t \n\tSET_IRPTNDX(base, ctx, 0);\n\n\t \n\tSET_CFEIE(base, ctx, 1);\n\n\t \n\tSET_CFCFG(base, ctx, 1);\n\n\t \n\tSET_RCISH(base, ctx, 1);\n\tSET_RCOSH(base, ctx, 1);\n\tSET_RCNSH(base, ctx, 1);\n\n\t \n\tSET_BFBDFE(base, ctx, 1);\n\n\t \n\tSET_M(base, ctx, 1);\n}\n\nstatic struct iommu_domain *msm_iommu_domain_alloc(unsigned type)\n{\n\tstruct msm_priv *priv;\n\n\tif (type != IOMMU_DOMAIN_UNMANAGED)\n\t\treturn NULL;\n\n\tpriv = kzalloc(sizeof(*priv), GFP_KERNEL);\n\tif (!priv)\n\t\tgoto fail_nomem;\n\n\tINIT_LIST_HEAD(&priv->list_attached);\n\n\tpriv->domain.geometry.aperture_start = 0;\n\tpriv->domain.geometry.aperture_end   = (1ULL << 32) - 1;\n\tpriv->domain.geometry.force_aperture = true;\n\n\treturn &priv->domain;\n\nfail_nomem:\n\tkfree(priv);\n\treturn NULL;\n}\n\nstatic void msm_iommu_domain_free(struct iommu_domain *domain)\n{\n\tstruct msm_priv *priv;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&msm_iommu_lock, flags);\n\tpriv = to_msm_priv(domain);\n\tkfree(priv);\n\tspin_unlock_irqrestore(&msm_iommu_lock, flags);\n}\n\nstatic int msm_iommu_domain_config(struct msm_priv *priv)\n{\n\tspin_lock_init(&priv->pgtlock);\n\n\tpriv->cfg = (struct io_pgtable_cfg) {\n\t\t.pgsize_bitmap = msm_iommu_ops.pgsize_bitmap,\n\t\t.ias = 32,\n\t\t.oas = 32,\n\t\t.tlb = &msm_iommu_flush_ops,\n\t\t.iommu_dev = priv->dev,\n\t};\n\n\tpriv->iop = alloc_io_pgtable_ops(ARM_V7S, &priv->cfg, priv);\n\tif (!priv->iop) {\n\t\tdev_err(priv->dev, \"Failed to allocate pgtable\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmsm_iommu_ops.pgsize_bitmap = priv->cfg.pgsize_bitmap;\n\n\treturn 0;\n}\n\n \nstatic struct msm_iommu_dev *find_iommu_for_dev(struct device *dev)\n{\n\tstruct msm_iommu_dev *iommu, *ret = NULL;\n\tstruct msm_iommu_ctx_dev *master;\n\n\tlist_for_each_entry(iommu, &qcom_iommu_devices, dev_node) {\n\t\tmaster = list_first_entry(&iommu->ctx_list,\n\t\t\t\t\t  struct msm_iommu_ctx_dev,\n\t\t\t\t\t  list);\n\t\tif (master->of_node == dev->of_node) {\n\t\t\tret = iommu;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic struct iommu_device *msm_iommu_probe_device(struct device *dev)\n{\n\tstruct msm_iommu_dev *iommu;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&msm_iommu_lock, flags);\n\tiommu = find_iommu_for_dev(dev);\n\tspin_unlock_irqrestore(&msm_iommu_lock, flags);\n\n\tif (!iommu)\n\t\treturn ERR_PTR(-ENODEV);\n\n\treturn &iommu->iommu;\n}\n\nstatic int msm_iommu_attach_dev(struct iommu_domain *domain, struct device *dev)\n{\n\tint ret = 0;\n\tunsigned long flags;\n\tstruct msm_iommu_dev *iommu;\n\tstruct msm_priv *priv = to_msm_priv(domain);\n\tstruct msm_iommu_ctx_dev *master;\n\n\tpriv->dev = dev;\n\tmsm_iommu_domain_config(priv);\n\n\tspin_lock_irqsave(&msm_iommu_lock, flags);\n\tlist_for_each_entry(iommu, &qcom_iommu_devices, dev_node) {\n\t\tmaster = list_first_entry(&iommu->ctx_list,\n\t\t\t\t\t  struct msm_iommu_ctx_dev,\n\t\t\t\t\t  list);\n\t\tif (master->of_node == dev->of_node) {\n\t\t\tret = __enable_clocks(iommu);\n\t\t\tif (ret)\n\t\t\t\tgoto fail;\n\n\t\t\tlist_for_each_entry(master, &iommu->ctx_list, list) {\n\t\t\t\tif (master->num) {\n\t\t\t\t\tdev_err(dev, \"domain already attached\");\n\t\t\t\t\tret = -EEXIST;\n\t\t\t\t\tgoto fail;\n\t\t\t\t}\n\t\t\t\tmaster->num =\n\t\t\t\t\tmsm_iommu_alloc_ctx(iommu->context_map,\n\t\t\t\t\t\t\t    0, iommu->ncb);\n\t\t\t\tif (IS_ERR_VALUE(master->num)) {\n\t\t\t\t\tret = -ENODEV;\n\t\t\t\t\tgoto fail;\n\t\t\t\t}\n\t\t\t\tconfig_mids(iommu, master);\n\t\t\t\t__program_context(iommu->base, master->num,\n\t\t\t\t\t\t  priv);\n\t\t\t}\n\t\t\t__disable_clocks(iommu);\n\t\t\tlist_add(&iommu->dom_node, &priv->list_attached);\n\t\t}\n\t}\n\nfail:\n\tspin_unlock_irqrestore(&msm_iommu_lock, flags);\n\n\treturn ret;\n}\n\nstatic void msm_iommu_set_platform_dma(struct device *dev)\n{\n\tstruct iommu_domain *domain = iommu_get_domain_for_dev(dev);\n\tstruct msm_priv *priv = to_msm_priv(domain);\n\tunsigned long flags;\n\tstruct msm_iommu_dev *iommu;\n\tstruct msm_iommu_ctx_dev *master;\n\tint ret;\n\n\tfree_io_pgtable_ops(priv->iop);\n\n\tspin_lock_irqsave(&msm_iommu_lock, flags);\n\tlist_for_each_entry(iommu, &priv->list_attached, dom_node) {\n\t\tret = __enable_clocks(iommu);\n\t\tif (ret)\n\t\t\tgoto fail;\n\n\t\tlist_for_each_entry(master, &iommu->ctx_list, list) {\n\t\t\tmsm_iommu_free_ctx(iommu->context_map, master->num);\n\t\t\t__reset_context(iommu->base, master->num);\n\t\t}\n\t\t__disable_clocks(iommu);\n\t}\nfail:\n\tspin_unlock_irqrestore(&msm_iommu_lock, flags);\n}\n\nstatic int msm_iommu_map(struct iommu_domain *domain, unsigned long iova,\n\t\t\t phys_addr_t pa, size_t pgsize, size_t pgcount,\n\t\t\t int prot, gfp_t gfp, size_t *mapped)\n{\n\tstruct msm_priv *priv = to_msm_priv(domain);\n\tunsigned long flags;\n\tint ret;\n\n\tspin_lock_irqsave(&priv->pgtlock, flags);\n\tret = priv->iop->map_pages(priv->iop, iova, pa, pgsize, pgcount, prot,\n\t\t\t\t   GFP_ATOMIC, mapped);\n\tspin_unlock_irqrestore(&priv->pgtlock, flags);\n\n\treturn ret;\n}\n\nstatic void msm_iommu_sync_map(struct iommu_domain *domain, unsigned long iova,\n\t\t\t       size_t size)\n{\n\tstruct msm_priv *priv = to_msm_priv(domain);\n\n\t__flush_iotlb_range(iova, size, SZ_4K, false, priv);\n}\n\nstatic size_t msm_iommu_unmap(struct iommu_domain *domain, unsigned long iova,\n\t\t\t      size_t pgsize, size_t pgcount,\n\t\t\t      struct iommu_iotlb_gather *gather)\n{\n\tstruct msm_priv *priv = to_msm_priv(domain);\n\tunsigned long flags;\n\tsize_t ret;\n\n\tspin_lock_irqsave(&priv->pgtlock, flags);\n\tret = priv->iop->unmap_pages(priv->iop, iova, pgsize, pgcount, gather);\n\tspin_unlock_irqrestore(&priv->pgtlock, flags);\n\n\treturn ret;\n}\n\nstatic phys_addr_t msm_iommu_iova_to_phys(struct iommu_domain *domain,\n\t\t\t\t\t  dma_addr_t va)\n{\n\tstruct msm_priv *priv;\n\tstruct msm_iommu_dev *iommu;\n\tstruct msm_iommu_ctx_dev *master;\n\tunsigned int par;\n\tunsigned long flags;\n\tphys_addr_t ret = 0;\n\n\tspin_lock_irqsave(&msm_iommu_lock, flags);\n\n\tpriv = to_msm_priv(domain);\n\tiommu = list_first_entry(&priv->list_attached,\n\t\t\t\t struct msm_iommu_dev, dom_node);\n\n\tif (list_empty(&iommu->ctx_list))\n\t\tgoto fail;\n\n\tmaster = list_first_entry(&iommu->ctx_list,\n\t\t\t\t  struct msm_iommu_ctx_dev, list);\n\tif (!master)\n\t\tgoto fail;\n\n\tret = __enable_clocks(iommu);\n\tif (ret)\n\t\tgoto fail;\n\n\t \n\tSET_CTX_TLBIALL(iommu->base, master->num, 0);\n\tSET_V2PPR(iommu->base, master->num, va & V2Pxx_VA);\n\n\tpar = GET_PAR(iommu->base, master->num);\n\n\t \n\tif (GET_NOFAULT_SS(iommu->base, master->num))\n\t\tret = (par & 0xFF000000) | (va & 0x00FFFFFF);\n\telse\t \n\t\tret = (par & 0xFFFFF000) | (va & 0x00000FFF);\n\n\tif (GET_FAULT(iommu->base, master->num))\n\t\tret = 0;\n\n\t__disable_clocks(iommu);\nfail:\n\tspin_unlock_irqrestore(&msm_iommu_lock, flags);\n\treturn ret;\n}\n\nstatic void print_ctx_regs(void __iomem *base, int ctx)\n{\n\tunsigned int fsr = GET_FSR(base, ctx);\n\tpr_err(\"FAR    = %08x    PAR    = %08x\\n\",\n\t       GET_FAR(base, ctx), GET_PAR(base, ctx));\n\tpr_err(\"FSR    = %08x [%s%s%s%s%s%s%s%s%s%s]\\n\", fsr,\n\t\t\t(fsr & 0x02) ? \"TF \" : \"\",\n\t\t\t(fsr & 0x04) ? \"AFF \" : \"\",\n\t\t\t(fsr & 0x08) ? \"APF \" : \"\",\n\t\t\t(fsr & 0x10) ? \"TLBMF \" : \"\",\n\t\t\t(fsr & 0x20) ? \"HTWDEEF \" : \"\",\n\t\t\t(fsr & 0x40) ? \"HTWSEEF \" : \"\",\n\t\t\t(fsr & 0x80) ? \"MHF \" : \"\",\n\t\t\t(fsr & 0x10000) ? \"SL \" : \"\",\n\t\t\t(fsr & 0x40000000) ? \"SS \" : \"\",\n\t\t\t(fsr & 0x80000000) ? \"MULTI \" : \"\");\n\n\tpr_err(\"FSYNR0 = %08x    FSYNR1 = %08x\\n\",\n\t       GET_FSYNR0(base, ctx), GET_FSYNR1(base, ctx));\n\tpr_err(\"TTBR0  = %08x    TTBR1  = %08x\\n\",\n\t       GET_TTBR0(base, ctx), GET_TTBR1(base, ctx));\n\tpr_err(\"SCTLR  = %08x    ACTLR  = %08x\\n\",\n\t       GET_SCTLR(base, ctx), GET_ACTLR(base, ctx));\n}\n\nstatic int insert_iommu_master(struct device *dev,\n\t\t\t\tstruct msm_iommu_dev **iommu,\n\t\t\t\tstruct of_phandle_args *spec)\n{\n\tstruct msm_iommu_ctx_dev *master = dev_iommu_priv_get(dev);\n\tint sid;\n\n\tif (list_empty(&(*iommu)->ctx_list)) {\n\t\tmaster = kzalloc(sizeof(*master), GFP_ATOMIC);\n\t\tif (!master) {\n\t\t\tdev_err(dev, \"Failed to allocate iommu_master\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tmaster->of_node = dev->of_node;\n\t\tlist_add(&master->list, &(*iommu)->ctx_list);\n\t\tdev_iommu_priv_set(dev, master);\n\t}\n\n\tfor (sid = 0; sid < master->num_mids; sid++)\n\t\tif (master->mids[sid] == spec->args[0]) {\n\t\t\tdev_warn(dev, \"Stream ID 0x%x repeated; ignoring\\n\",\n\t\t\t\t sid);\n\t\t\treturn 0;\n\t\t}\n\n\tmaster->mids[master->num_mids++] = spec->args[0];\n\treturn 0;\n}\n\nstatic int qcom_iommu_of_xlate(struct device *dev,\n\t\t\t       struct of_phandle_args *spec)\n{\n\tstruct msm_iommu_dev *iommu = NULL, *iter;\n\tunsigned long flags;\n\tint ret = 0;\n\n\tspin_lock_irqsave(&msm_iommu_lock, flags);\n\tlist_for_each_entry(iter, &qcom_iommu_devices, dev_node) {\n\t\tif (iter->dev->of_node == spec->np) {\n\t\t\tiommu = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!iommu) {\n\t\tret = -ENODEV;\n\t\tgoto fail;\n\t}\n\n\tret = insert_iommu_master(dev, &iommu, spec);\nfail:\n\tspin_unlock_irqrestore(&msm_iommu_lock, flags);\n\n\treturn ret;\n}\n\nirqreturn_t msm_iommu_fault_handler(int irq, void *dev_id)\n{\n\tstruct msm_iommu_dev *iommu = dev_id;\n\tunsigned int fsr;\n\tint i, ret;\n\n\tspin_lock(&msm_iommu_lock);\n\n\tif (!iommu) {\n\t\tpr_err(\"Invalid device ID in context interrupt handler\\n\");\n\t\tgoto fail;\n\t}\n\n\tpr_err(\"Unexpected IOMMU page fault!\\n\");\n\tpr_err(\"base = %08x\\n\", (unsigned int)iommu->base);\n\n\tret = __enable_clocks(iommu);\n\tif (ret)\n\t\tgoto fail;\n\n\tfor (i = 0; i < iommu->ncb; i++) {\n\t\tfsr = GET_FSR(iommu->base, i);\n\t\tif (fsr) {\n\t\t\tpr_err(\"Fault occurred in context %d.\\n\", i);\n\t\t\tpr_err(\"Interesting registers:\\n\");\n\t\t\tprint_ctx_regs(iommu->base, i);\n\t\t\tSET_FSR(iommu->base, i, 0x4000000F);\n\t\t}\n\t}\n\t__disable_clocks(iommu);\nfail:\n\tspin_unlock(&msm_iommu_lock);\n\treturn 0;\n}\n\nstatic struct iommu_ops msm_iommu_ops = {\n\t.domain_alloc = msm_iommu_domain_alloc,\n\t.probe_device = msm_iommu_probe_device,\n\t.device_group = generic_device_group,\n\t.set_platform_dma_ops = msm_iommu_set_platform_dma,\n\t.pgsize_bitmap = MSM_IOMMU_PGSIZES,\n\t.of_xlate = qcom_iommu_of_xlate,\n\t.default_domain_ops = &(const struct iommu_domain_ops) {\n\t\t.attach_dev\t= msm_iommu_attach_dev,\n\t\t.map_pages\t= msm_iommu_map,\n\t\t.unmap_pages\t= msm_iommu_unmap,\n\t\t \n\t\t.iotlb_sync\t= NULL,\n\t\t.iotlb_sync_map\t= msm_iommu_sync_map,\n\t\t.iova_to_phys\t= msm_iommu_iova_to_phys,\n\t\t.free\t\t= msm_iommu_domain_free,\n\t}\n};\n\nstatic int msm_iommu_probe(struct platform_device *pdev)\n{\n\tstruct resource *r;\n\tresource_size_t ioaddr;\n\tstruct msm_iommu_dev *iommu;\n\tint ret, par, val;\n\n\tiommu = devm_kzalloc(&pdev->dev, sizeof(*iommu), GFP_KERNEL);\n\tif (!iommu)\n\t\treturn -ENODEV;\n\n\tiommu->dev = &pdev->dev;\n\tINIT_LIST_HEAD(&iommu->ctx_list);\n\n\tiommu->pclk = devm_clk_get(iommu->dev, \"smmu_pclk\");\n\tif (IS_ERR(iommu->pclk))\n\t\treturn dev_err_probe(iommu->dev, PTR_ERR(iommu->pclk),\n\t\t\t\t     \"could not get smmu_pclk\\n\");\n\n\tret = clk_prepare(iommu->pclk);\n\tif (ret)\n\t\treturn dev_err_probe(iommu->dev, ret,\n\t\t\t\t     \"could not prepare smmu_pclk\\n\");\n\n\tiommu->clk = devm_clk_get(iommu->dev, \"iommu_clk\");\n\tif (IS_ERR(iommu->clk)) {\n\t\tclk_unprepare(iommu->pclk);\n\t\treturn dev_err_probe(iommu->dev, PTR_ERR(iommu->clk),\n\t\t\t\t     \"could not get iommu_clk\\n\");\n\t}\n\n\tret = clk_prepare(iommu->clk);\n\tif (ret) {\n\t\tclk_unprepare(iommu->pclk);\n\t\treturn dev_err_probe(iommu->dev, ret, \"could not prepare iommu_clk\\n\");\n\t}\n\n\tr = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tiommu->base = devm_ioremap_resource(iommu->dev, r);\n\tif (IS_ERR(iommu->base)) {\n\t\tret = dev_err_probe(iommu->dev, PTR_ERR(iommu->base), \"could not get iommu base\\n\");\n\t\tgoto fail;\n\t}\n\tioaddr = r->start;\n\n\tiommu->irq = platform_get_irq(pdev, 0);\n\tif (iommu->irq < 0) {\n\t\tret = -ENODEV;\n\t\tgoto fail;\n\t}\n\n\tret = of_property_read_u32(iommu->dev->of_node, \"qcom,ncb\", &val);\n\tif (ret) {\n\t\tdev_err(iommu->dev, \"could not get ncb\\n\");\n\t\tgoto fail;\n\t}\n\tiommu->ncb = val;\n\n\tmsm_iommu_reset(iommu->base, iommu->ncb);\n\tSET_M(iommu->base, 0, 1);\n\tSET_PAR(iommu->base, 0, 0);\n\tSET_V2PCFG(iommu->base, 0, 1);\n\tSET_V2PPR(iommu->base, 0, 0);\n\tpar = GET_PAR(iommu->base, 0);\n\tSET_V2PCFG(iommu->base, 0, 0);\n\tSET_M(iommu->base, 0, 0);\n\n\tif (!par) {\n\t\tpr_err(\"Invalid PAR value detected\\n\");\n\t\tret = -ENODEV;\n\t\tgoto fail;\n\t}\n\n\tret = devm_request_threaded_irq(iommu->dev, iommu->irq, NULL,\n\t\t\t\t\tmsm_iommu_fault_handler,\n\t\t\t\t\tIRQF_ONESHOT | IRQF_SHARED,\n\t\t\t\t\t\"msm_iommu_secure_irpt_handler\",\n\t\t\t\t\tiommu);\n\tif (ret) {\n\t\tpr_err(\"Request IRQ %d failed with ret=%d\\n\", iommu->irq, ret);\n\t\tgoto fail;\n\t}\n\n\tlist_add(&iommu->dev_node, &qcom_iommu_devices);\n\n\tret = iommu_device_sysfs_add(&iommu->iommu, iommu->dev, NULL,\n\t\t\t\t     \"msm-smmu.%pa\", &ioaddr);\n\tif (ret) {\n\t\tpr_err(\"Could not add msm-smmu at %pa to sysfs\\n\", &ioaddr);\n\t\tgoto fail;\n\t}\n\n\tret = iommu_device_register(&iommu->iommu, &msm_iommu_ops, &pdev->dev);\n\tif (ret) {\n\t\tpr_err(\"Could not register msm-smmu at %pa\\n\", &ioaddr);\n\t\tgoto fail;\n\t}\n\n\tpr_info(\"device mapped at %p, irq %d with %d ctx banks\\n\",\n\t\tiommu->base, iommu->irq, iommu->ncb);\n\n\treturn ret;\nfail:\n\tclk_unprepare(iommu->clk);\n\tclk_unprepare(iommu->pclk);\n\treturn ret;\n}\n\nstatic const struct of_device_id msm_iommu_dt_match[] = {\n\t{ .compatible = \"qcom,apq8064-iommu\" },\n\t{}\n};\n\nstatic void msm_iommu_remove(struct platform_device *pdev)\n{\n\tstruct msm_iommu_dev *iommu = platform_get_drvdata(pdev);\n\n\tclk_unprepare(iommu->clk);\n\tclk_unprepare(iommu->pclk);\n}\n\nstatic struct platform_driver msm_iommu_driver = {\n\t.driver = {\n\t\t.name\t= \"msm_iommu\",\n\t\t.of_match_table = msm_iommu_dt_match,\n\t},\n\t.probe\t\t= msm_iommu_probe,\n\t.remove_new\t= msm_iommu_remove,\n};\nbuiltin_platform_driver(msm_iommu_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}