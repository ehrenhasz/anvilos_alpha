{
  "module_name": "dm-zoned.h",
  "hash_id": "e7e658936992d3691b6c453192c5cdf6d334121181a56acd8d207b571dce9775",
  "original_prompt": "Ingested from linux-6.6.14/drivers/md/dm-zoned.h",
  "human_readable_source": " \n \n\n#ifndef DM_ZONED_H\n#define DM_ZONED_H\n\n#include <linux/types.h>\n#include <linux/blkdev.h>\n#include <linux/device-mapper.h>\n#include <linux/dm-kcopyd.h>\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/mutex.h>\n#include <linux/workqueue.h>\n#include <linux/rwsem.h>\n#include <linux/rbtree.h>\n#include <linux/radix-tree.h>\n#include <linux/shrinker.h>\n\n \n#define DMZ_BLOCK_SHIFT\t\t12\n#define DMZ_BLOCK_SIZE\t\t(1 << DMZ_BLOCK_SHIFT)\n#define DMZ_BLOCK_MASK\t\t(DMZ_BLOCK_SIZE - 1)\n\n#define DMZ_BLOCK_SHIFT_BITS\t(DMZ_BLOCK_SHIFT + 3)\n#define DMZ_BLOCK_SIZE_BITS\t(1 << DMZ_BLOCK_SHIFT_BITS)\n#define DMZ_BLOCK_MASK_BITS\t(DMZ_BLOCK_SIZE_BITS - 1)\n\n#define DMZ_BLOCK_SECTORS_SHIFT\t(DMZ_BLOCK_SHIFT - SECTOR_SHIFT)\n#define DMZ_BLOCK_SECTORS\t(DMZ_BLOCK_SIZE >> SECTOR_SHIFT)\n#define DMZ_BLOCK_SECTORS_MASK\t(DMZ_BLOCK_SECTORS - 1)\n\n \n#define dmz_blk2sect(b)\t\t((sector_t)(b) << DMZ_BLOCK_SECTORS_SHIFT)\n#define dmz_sect2blk(s)\t\t((sector_t)(s) >> DMZ_BLOCK_SECTORS_SHIFT)\n\n#define dmz_bio_block(bio)\tdmz_sect2blk((bio)->bi_iter.bi_sector)\n#define dmz_bio_blocks(bio)\tdmz_sect2blk(bio_sectors(bio))\n\nstruct dmz_metadata;\nstruct dmz_reclaim;\n\n \nstruct dmz_dev {\n\tstruct block_device\t*bdev;\n\tstruct dmz_metadata\t*metadata;\n\tstruct dmz_reclaim\t*reclaim;\n\n\tuuid_t\t\t\tuuid;\n\n\tsector_t\t\tcapacity;\n\n\tunsigned int\t\tdev_idx;\n\n\tunsigned int\t\tnr_zones;\n\tunsigned int\t\tzone_offset;\n\n\tunsigned int\t\tflags;\n\n\tsector_t\t\tzone_nr_sectors;\n\n\tunsigned int\t\tnr_rnd;\n\tatomic_t\t\tunmap_nr_rnd;\n\tstruct list_head\tunmap_rnd_list;\n\tstruct list_head\tmap_rnd_list;\n\n\tunsigned int\t\tnr_seq;\n\tatomic_t\t\tunmap_nr_seq;\n\tstruct list_head\tunmap_seq_list;\n\tstruct list_head\tmap_seq_list;\n};\n\n#define dmz_bio_chunk(zmd, bio)\t((bio)->bi_iter.bi_sector >> \\\n\t\t\t\t dmz_zone_nr_sectors_shift(zmd))\n#define dmz_chunk_block(zmd, b)\t((b) & (dmz_zone_nr_blocks(zmd) - 1))\n\n \n#define DMZ_BDEV_DYING\t\t(1 << 0)\n#define DMZ_CHECK_BDEV\t\t(2 << 0)\n#define DMZ_BDEV_REGULAR\t(4 << 0)\n\n \nstruct dm_zone {\n\t \n\tstruct list_head\tlink;\n\n\t \n\tstruct dmz_dev\t\t*dev;\n\n\t \n\tunsigned long\t\tflags;\n\n\t \n\tatomic_t\t\trefcount;\n\n\t \n\tunsigned int\t\tid;\n\n\t \n\tunsigned int\t\twp_block;\n\n\t \n\tunsigned int\t\tweight;\n\n\t \n\tunsigned int\t\tchunk;\n\n\t \n\tstruct dm_zone\t\t*bzone;\n};\n\n \nenum {\n\t \n\tDMZ_CACHE,\n\tDMZ_RND,\n\tDMZ_SEQ,\n\n\t \n\tDMZ_OFFLINE,\n\tDMZ_READ_ONLY,\n\n\t \n\tDMZ_META,\n\tDMZ_DATA,\n\tDMZ_BUF,\n\tDMZ_RESERVED,\n\n\t \n\tDMZ_RECLAIM,\n\tDMZ_SEQ_WRITE_ERR,\n\tDMZ_RECLAIM_TERMINATE,\n};\n\n \n#define dmz_is_cache(z)\t\ttest_bit(DMZ_CACHE, &(z)->flags)\n#define dmz_is_rnd(z)\t\ttest_bit(DMZ_RND, &(z)->flags)\n#define dmz_is_seq(z)\t\ttest_bit(DMZ_SEQ, &(z)->flags)\n#define dmz_is_empty(z)\t\t((z)->wp_block == 0)\n#define dmz_is_offline(z)\ttest_bit(DMZ_OFFLINE, &(z)->flags)\n#define dmz_is_readonly(z)\ttest_bit(DMZ_READ_ONLY, &(z)->flags)\n#define dmz_in_reclaim(z)\ttest_bit(DMZ_RECLAIM, &(z)->flags)\n#define dmz_is_reserved(z)\ttest_bit(DMZ_RESERVED, &(z)->flags)\n#define dmz_seq_write_err(z)\ttest_bit(DMZ_SEQ_WRITE_ERR, &(z)->flags)\n#define dmz_reclaim_should_terminate(z) \\\n\t\t\t\ttest_bit(DMZ_RECLAIM_TERMINATE, &(z)->flags)\n\n#define dmz_is_meta(z)\t\ttest_bit(DMZ_META, &(z)->flags)\n#define dmz_is_buf(z)\t\ttest_bit(DMZ_BUF, &(z)->flags)\n#define dmz_is_data(z)\t\ttest_bit(DMZ_DATA, &(z)->flags)\n\n#define dmz_weight(z)\t\t((z)->weight)\n\n \n#define dmz_dev_info(dev, format, args...)\t\\\n\tDMINFO(\"(%pg): \" format, (dev)->bdev, ## args)\n\n#define dmz_dev_err(dev, format, args...)\t\\\n\tDMERR(\"(%pg): \" format, (dev)->bdev, ## args)\n\n#define dmz_dev_warn(dev, format, args...)\t\\\n\tDMWARN(\"(%pg): \" format, (dev)->bdev, ## args)\n\n#define dmz_dev_debug(dev, format, args...)\t\\\n\tDMDEBUG(\"(%pg): \" format, (dev)->bdev, ## args)\n\n \nint dmz_ctr_metadata(struct dmz_dev *dev, int num_dev,\n\t\t     struct dmz_metadata **zmd, const char *devname);\nvoid dmz_dtr_metadata(struct dmz_metadata *zmd);\nint dmz_resume_metadata(struct dmz_metadata *zmd);\n\nvoid dmz_lock_map(struct dmz_metadata *zmd);\nvoid dmz_unlock_map(struct dmz_metadata *zmd);\nvoid dmz_lock_metadata(struct dmz_metadata *zmd);\nvoid dmz_unlock_metadata(struct dmz_metadata *zmd);\nvoid dmz_lock_flush(struct dmz_metadata *zmd);\nvoid dmz_unlock_flush(struct dmz_metadata *zmd);\nint dmz_flush_metadata(struct dmz_metadata *zmd);\nconst char *dmz_metadata_label(struct dmz_metadata *zmd);\n\nsector_t dmz_start_sect(struct dmz_metadata *zmd, struct dm_zone *zone);\nsector_t dmz_start_block(struct dmz_metadata *zmd, struct dm_zone *zone);\nunsigned int dmz_nr_chunks(struct dmz_metadata *zmd);\n\nbool dmz_check_dev(struct dmz_metadata *zmd);\nbool dmz_dev_is_dying(struct dmz_metadata *zmd);\n\n#define DMZ_ALLOC_RND\t\t0x01\n#define DMZ_ALLOC_CACHE\t\t0x02\n#define DMZ_ALLOC_SEQ\t\t0x04\n#define DMZ_ALLOC_RECLAIM\t0x10\n\nstruct dm_zone *dmz_alloc_zone(struct dmz_metadata *zmd,\n\t\t\t       unsigned int dev_idx, unsigned long flags);\nvoid dmz_free_zone(struct dmz_metadata *zmd, struct dm_zone *zone);\n\nvoid dmz_map_zone(struct dmz_metadata *zmd, struct dm_zone *zone,\n\t\t  unsigned int chunk);\nvoid dmz_unmap_zone(struct dmz_metadata *zmd, struct dm_zone *zone);\nunsigned int dmz_nr_zones(struct dmz_metadata *zmd);\nunsigned int dmz_nr_cache_zones(struct dmz_metadata *zmd);\nunsigned int dmz_nr_unmap_cache_zones(struct dmz_metadata *zmd);\nunsigned int dmz_nr_rnd_zones(struct dmz_metadata *zmd, int idx);\nunsigned int dmz_nr_unmap_rnd_zones(struct dmz_metadata *zmd, int idx);\nunsigned int dmz_nr_seq_zones(struct dmz_metadata *zmd, int idx);\nunsigned int dmz_nr_unmap_seq_zones(struct dmz_metadata *zmd, int idx);\nunsigned int dmz_zone_nr_blocks(struct dmz_metadata *zmd);\nunsigned int dmz_zone_nr_blocks_shift(struct dmz_metadata *zmd);\nunsigned int dmz_zone_nr_sectors(struct dmz_metadata *zmd);\nunsigned int dmz_zone_nr_sectors_shift(struct dmz_metadata *zmd);\n\n \nstatic inline void dmz_activate_zone(struct dm_zone *zone)\n{\n\tatomic_inc(&zone->refcount);\n}\n\nint dmz_lock_zone_reclaim(struct dm_zone *zone);\nvoid dmz_unlock_zone_reclaim(struct dm_zone *zone);\nstruct dm_zone *dmz_get_zone_for_reclaim(struct dmz_metadata *zmd,\n\t\t\t\t\t unsigned int dev_idx, bool idle);\n\nstruct dm_zone *dmz_get_chunk_mapping(struct dmz_metadata *zmd,\n\t\t\t\t      unsigned int chunk, enum req_op op);\nvoid dmz_put_chunk_mapping(struct dmz_metadata *zmd, struct dm_zone *zone);\nstruct dm_zone *dmz_get_chunk_buffer(struct dmz_metadata *zmd,\n\t\t\t\t     struct dm_zone *dzone);\n\nint dmz_validate_blocks(struct dmz_metadata *zmd, struct dm_zone *zone,\n\t\t\tsector_t chunk_block, unsigned int nr_blocks);\nint dmz_invalidate_blocks(struct dmz_metadata *zmd, struct dm_zone *zone,\n\t\t\t  sector_t chunk_block, unsigned int nr_blocks);\nint dmz_block_valid(struct dmz_metadata *zmd, struct dm_zone *zone,\n\t\t    sector_t chunk_block);\nint dmz_first_valid_block(struct dmz_metadata *zmd, struct dm_zone *zone,\n\t\t\t  sector_t *chunk_block);\nint dmz_copy_valid_blocks(struct dmz_metadata *zmd, struct dm_zone *from_zone,\n\t\t\t  struct dm_zone *to_zone);\nint dmz_merge_valid_blocks(struct dmz_metadata *zmd, struct dm_zone *from_zone,\n\t\t\t   struct dm_zone *to_zone, sector_t chunk_block);\n\n \nint dmz_ctr_reclaim(struct dmz_metadata *zmd, struct dmz_reclaim **zrc, int idx);\nvoid dmz_dtr_reclaim(struct dmz_reclaim *zrc);\nvoid dmz_suspend_reclaim(struct dmz_reclaim *zrc);\nvoid dmz_resume_reclaim(struct dmz_reclaim *zrc);\nvoid dmz_reclaim_bio_acc(struct dmz_reclaim *zrc);\nvoid dmz_schedule_reclaim(struct dmz_reclaim *zrc);\n\n \nbool dmz_bdev_is_dying(struct dmz_dev *dmz_dev);\nbool dmz_check_bdev(struct dmz_dev *dmz_dev);\n\n \nstatic inline void dmz_deactivate_zone(struct dm_zone *zone)\n{\n\tdmz_reclaim_bio_acc(zone->dev->reclaim);\n\tatomic_dec(&zone->refcount);\n}\n\n \nstatic inline bool dmz_is_active(struct dm_zone *zone)\n{\n\treturn atomic_read(&zone->refcount);\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}