{
  "module_name": "bset.h",
  "hash_id": "8a62e0d8105a3228f5ca09b3819af1976133d22a43ba31c3a8d36a3a2bb96f5f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/md/bcache/bset.h",
  "human_readable_source": " \n#ifndef _BCACHE_BSET_H\n#define _BCACHE_BSET_H\n\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#include \"bcache_ondisk.h\"\n#include \"util.h\"  \n\n \n\nstruct btree_keys;\nstruct btree_iter;\nstruct btree_iter_set;\nstruct bkey_float;\n\n#define MAX_BSETS\t\t4U\n\nstruct bset_tree {\n\t \n\n\t \n\tunsigned int\t\tsize;\n\n\t \n\tunsigned int\t\textra;\n\n\t \n\tstruct bkey\t\tend;\n\tstruct bkey_float\t*tree;\n\n\t \n\tuint8_t\t\t\t*prev;\n\n\t \n\tstruct bset\t\t*data;\n};\n\nstruct btree_keys_ops {\n\tbool\t\t(*sort_cmp)(struct btree_iter_set l,\n\t\t\t\t    struct btree_iter_set r);\n\tstruct bkey\t*(*sort_fixup)(struct btree_iter *iter,\n\t\t\t\t       struct bkey *tmp);\n\tbool\t\t(*insert_fixup)(struct btree_keys *b,\n\t\t\t\t\tstruct bkey *insert,\n\t\t\t\t\tstruct btree_iter *iter,\n\t\t\t\t\tstruct bkey *replace_key);\n\tbool\t\t(*key_invalid)(struct btree_keys *bk,\n\t\t\t\t       const struct bkey *k);\n\tbool\t\t(*key_bad)(struct btree_keys *bk,\n\t\t\t\t   const struct bkey *k);\n\tbool\t\t(*key_merge)(struct btree_keys *bk,\n\t\t\t\t     struct bkey *l, struct bkey *r);\n\tvoid\t\t(*key_to_text)(char *buf,\n\t\t\t\t       size_t size,\n\t\t\t\t       const struct bkey *k);\n\tvoid\t\t(*key_dump)(struct btree_keys *keys,\n\t\t\t\t    const struct bkey *k);\n\n\t \n\tbool\t\tis_extents;\n};\n\nstruct btree_keys {\n\tconst struct btree_keys_ops\t*ops;\n\tuint8_t\t\t\tpage_order;\n\tuint8_t\t\t\tnsets;\n\tunsigned int\t\tlast_set_unwritten:1;\n\tbool\t\t\t*expensive_debug_checks;\n\n\t \n\tstruct bset_tree\tset[MAX_BSETS];\n};\n\nstatic inline struct bset_tree *bset_tree_last(struct btree_keys *b)\n{\n\treturn b->set + b->nsets;\n}\n\nstatic inline bool bset_written(struct btree_keys *b, struct bset_tree *t)\n{\n\treturn t <= b->set + b->nsets - b->last_set_unwritten;\n}\n\nstatic inline bool bkey_written(struct btree_keys *b, struct bkey *k)\n{\n\treturn !b->last_set_unwritten || k < b->set[b->nsets].data->start;\n}\n\nstatic inline unsigned int bset_byte_offset(struct btree_keys *b,\n\t\t\t\t\t    struct bset *i)\n{\n\treturn ((size_t) i) - ((size_t) b->set->data);\n}\n\nstatic inline unsigned int bset_sector_offset(struct btree_keys *b,\n\t\t\t\t\t      struct bset *i)\n{\n\treturn bset_byte_offset(b, i) >> 9;\n}\n\n#define __set_bytes(i, k)\t(sizeof(*(i)) + (k) * sizeof(uint64_t))\n#define set_bytes(i)\t\t__set_bytes(i, i->keys)\n\n#define __set_blocks(i, k, block_bytes)\t\t\t\t\\\n\tDIV_ROUND_UP(__set_bytes(i, k), block_bytes)\n#define set_blocks(i, block_bytes)\t\t\t\t\\\n\t__set_blocks(i, (i)->keys, block_bytes)\n\nstatic inline size_t bch_btree_keys_u64s_remaining(struct btree_keys *b)\n{\n\tstruct bset_tree *t = bset_tree_last(b);\n\n\tBUG_ON((PAGE_SIZE << b->page_order) <\n\t       (bset_byte_offset(b, t->data) + set_bytes(t->data)));\n\n\tif (!b->last_set_unwritten)\n\t\treturn 0;\n\n\treturn ((PAGE_SIZE << b->page_order) -\n\t\t(bset_byte_offset(b, t->data) + set_bytes(t->data))) /\n\t\tsizeof(u64);\n}\n\nstatic inline struct bset *bset_next_set(struct btree_keys *b,\n\t\t\t\t\t unsigned int block_bytes)\n{\n\tstruct bset *i = bset_tree_last(b)->data;\n\n\treturn ((void *) i) + roundup(set_bytes(i), block_bytes);\n}\n\nvoid bch_btree_keys_free(struct btree_keys *b);\nint bch_btree_keys_alloc(struct btree_keys *b, unsigned int page_order,\n\t\t\t gfp_t gfp);\nvoid bch_btree_keys_init(struct btree_keys *b, const struct btree_keys_ops *ops,\n\t\t\t bool *expensive_debug_checks);\n\nvoid bch_bset_init_next(struct btree_keys *b, struct bset *i, uint64_t magic);\nvoid bch_bset_build_written_tree(struct btree_keys *b);\nvoid bch_bset_fix_invalidated_key(struct btree_keys *b, struct bkey *k);\nbool bch_bkey_try_merge(struct btree_keys *b, struct bkey *l, struct bkey *r);\nvoid bch_bset_insert(struct btree_keys *b, struct bkey *where,\n\t\t     struct bkey *insert);\nunsigned int bch_btree_insert_key(struct btree_keys *b, struct bkey *k,\n\t\t\t      struct bkey *replace_key);\n\nenum {\n\tBTREE_INSERT_STATUS_NO_INSERT = 0,\n\tBTREE_INSERT_STATUS_INSERT,\n\tBTREE_INSERT_STATUS_BACK_MERGE,\n\tBTREE_INSERT_STATUS_OVERWROTE,\n\tBTREE_INSERT_STATUS_FRONT_MERGE,\n};\n\n \n\nstruct btree_iter {\n\tsize_t size, used;\n#ifdef CONFIG_BCACHE_DEBUG\n\tstruct btree_keys *b;\n#endif\n\tstruct btree_iter_set {\n\t\tstruct bkey *k, *end;\n\t} data[MAX_BSETS];\n};\n\ntypedef bool (*ptr_filter_fn)(struct btree_keys *b, const struct bkey *k);\n\nstruct bkey *bch_btree_iter_next(struct btree_iter *iter);\nstruct bkey *bch_btree_iter_next_filter(struct btree_iter *iter,\n\t\t\t\t\tstruct btree_keys *b,\n\t\t\t\t\tptr_filter_fn fn);\n\nvoid bch_btree_iter_push(struct btree_iter *iter, struct bkey *k,\n\t\t\t struct bkey *end);\nstruct bkey *bch_btree_iter_init(struct btree_keys *b,\n\t\t\t\t struct btree_iter *iter,\n\t\t\t\t struct bkey *search);\n\nstruct bkey *__bch_bset_search(struct btree_keys *b, struct bset_tree *t,\n\t\t\t       const struct bkey *search);\n\n \nstatic inline struct bkey *bch_bset_search(struct btree_keys *b,\n\t\t\t\t\t   struct bset_tree *t,\n\t\t\t\t\t   const struct bkey *search)\n{\n\treturn search ? __bch_bset_search(b, t, search) : t->data->start;\n}\n\n#define for_each_key_filter(b, k, iter, filter)\t\t\t\t\\\n\tfor (bch_btree_iter_init((b), (iter), NULL);\t\t\t\\\n\t     ((k) = bch_btree_iter_next_filter((iter), (b), filter));)\n\n#define for_each_key(b, k, iter)\t\t\t\t\t\\\n\tfor (bch_btree_iter_init((b), (iter), NULL);\t\t\t\\\n\t     ((k) = bch_btree_iter_next(iter));)\n\n \n\nstruct bset_sort_state {\n\tmempool_t\t\tpool;\n\n\tunsigned int\t\tpage_order;\n\tunsigned int\t\tcrit_factor;\n\n\tstruct time_stats\ttime;\n};\n\nvoid bch_bset_sort_state_free(struct bset_sort_state *state);\nint bch_bset_sort_state_init(struct bset_sort_state *state,\n\t\t\t     unsigned int page_order);\nvoid bch_btree_sort_lazy(struct btree_keys *b, struct bset_sort_state *state);\nvoid bch_btree_sort_into(struct btree_keys *b, struct btree_keys *new,\n\t\t\t struct bset_sort_state *state);\nvoid bch_btree_sort_and_fix_extents(struct btree_keys *b,\n\t\t\t\t    struct btree_iter *iter,\n\t\t\t\t    struct bset_sort_state *state);\nvoid bch_btree_sort_partial(struct btree_keys *b, unsigned int start,\n\t\t\t    struct bset_sort_state *state);\n\nstatic inline void bch_btree_sort(struct btree_keys *b,\n\t\t\t\t  struct bset_sort_state *state)\n{\n\tbch_btree_sort_partial(b, 0, state);\n}\n\nstruct bset_stats {\n\tsize_t sets_written, sets_unwritten;\n\tsize_t bytes_written, bytes_unwritten;\n\tsize_t floats, failed;\n};\n\nvoid bch_btree_keys_stats(struct btree_keys *b, struct bset_stats *state);\n\n \n\n#define bset_bkey_last(i)\tbkey_idx((struct bkey *) (i)->d, \\\n\t\t\t\t\t (unsigned int)(i)->keys)\n\nstatic inline struct bkey *bset_bkey_idx(struct bset *i, unsigned int idx)\n{\n\treturn bkey_idx(i->start, idx);\n}\n\nstatic inline void bkey_init(struct bkey *k)\n{\n\t*k = ZERO_KEY;\n}\n\nstatic __always_inline int64_t bkey_cmp(const struct bkey *l,\n\t\t\t\t\tconst struct bkey *r)\n{\n\treturn unlikely(KEY_INODE(l) != KEY_INODE(r))\n\t\t? (int64_t) KEY_INODE(l) - (int64_t) KEY_INODE(r)\n\t\t: (int64_t) KEY_OFFSET(l) - (int64_t) KEY_OFFSET(r);\n}\n\nvoid bch_bkey_copy_single_ptr(struct bkey *dest, const struct bkey *src,\n\t\t\t      unsigned int i);\nbool __bch_cut_front(const struct bkey *where, struct bkey *k);\nbool __bch_cut_back(const struct bkey *where, struct bkey *k);\n\nstatic inline bool bch_cut_front(const struct bkey *where, struct bkey *k)\n{\n\tBUG_ON(bkey_cmp(where, k) > 0);\n\treturn __bch_cut_front(where, k);\n}\n\nstatic inline bool bch_cut_back(const struct bkey *where, struct bkey *k)\n{\n\tBUG_ON(bkey_cmp(where, &START_KEY(k)) < 0);\n\treturn __bch_cut_back(where, k);\n}\n\n \nstatic inline void preceding_key(struct bkey *k, struct bkey **preceding_key_p)\n{\n\tif (KEY_INODE(k) || KEY_OFFSET(k)) {\n\t\t(**preceding_key_p) = KEY(KEY_INODE(k), KEY_OFFSET(k), 0);\n\t\tif (!(*preceding_key_p)->low)\n\t\t\t(*preceding_key_p)->high--;\n\t\t(*preceding_key_p)->low--;\n\t} else {\n\t\t(*preceding_key_p) = NULL;\n\t}\n}\n\nstatic inline bool bch_ptr_invalid(struct btree_keys *b, const struct bkey *k)\n{\n\treturn b->ops->key_invalid(b, k);\n}\n\nstatic inline bool bch_ptr_bad(struct btree_keys *b, const struct bkey *k)\n{\n\treturn b->ops->key_bad(b, k);\n}\n\nstatic inline void bch_bkey_to_text(struct btree_keys *b, char *buf,\n\t\t\t\t    size_t size, const struct bkey *k)\n{\n\treturn b->ops->key_to_text(buf, size, k);\n}\n\nstatic inline bool bch_bkey_equal_header(const struct bkey *l,\n\t\t\t\t\t const struct bkey *r)\n{\n\treturn (KEY_DIRTY(l) == KEY_DIRTY(r) &&\n\t\tKEY_PTRS(l) == KEY_PTRS(r) &&\n\t\tKEY_CSUM(l) == KEY_CSUM(r));\n}\n\n \n\nstruct keylist {\n\tunion {\n\t\tstruct bkey\t\t*keys;\n\t\tuint64_t\t\t*keys_p;\n\t};\n\tunion {\n\t\tstruct bkey\t\t*top;\n\t\tuint64_t\t\t*top_p;\n\t};\n\n\t \n#define KEYLIST_INLINE\t\t16\n\tuint64_t\t\tinline_keys[KEYLIST_INLINE];\n};\n\nstatic inline void bch_keylist_init(struct keylist *l)\n{\n\tl->top_p = l->keys_p = l->inline_keys;\n}\n\nstatic inline void bch_keylist_init_single(struct keylist *l, struct bkey *k)\n{\n\tl->keys = k;\n\tl->top = bkey_next(k);\n}\n\nstatic inline void bch_keylist_push(struct keylist *l)\n{\n\tl->top = bkey_next(l->top);\n}\n\nstatic inline void bch_keylist_add(struct keylist *l, struct bkey *k)\n{\n\tbkey_copy(l->top, k);\n\tbch_keylist_push(l);\n}\n\nstatic inline bool bch_keylist_empty(struct keylist *l)\n{\n\treturn l->top == l->keys;\n}\n\nstatic inline void bch_keylist_reset(struct keylist *l)\n{\n\tl->top = l->keys;\n}\n\nstatic inline void bch_keylist_free(struct keylist *l)\n{\n\tif (l->keys_p != l->inline_keys)\n\t\tkfree(l->keys_p);\n}\n\nstatic inline size_t bch_keylist_nkeys(struct keylist *l)\n{\n\treturn l->top_p - l->keys_p;\n}\n\nstatic inline size_t bch_keylist_bytes(struct keylist *l)\n{\n\treturn bch_keylist_nkeys(l) * sizeof(uint64_t);\n}\n\nstruct bkey *bch_keylist_pop(struct keylist *l);\nvoid bch_keylist_pop_front(struct keylist *l);\nint __bch_keylist_realloc(struct keylist *l, unsigned int u64s);\n\n \n\n#ifdef CONFIG_BCACHE_DEBUG\n\nint __bch_count_data(struct btree_keys *b);\nvoid __printf(2, 3) __bch_check_keys(struct btree_keys *b,\n\t\t\t\t     const char *fmt,\n\t\t\t\t     ...);\nvoid bch_dump_bset(struct btree_keys *b, struct bset *i, unsigned int set);\nvoid bch_dump_bucket(struct btree_keys *b);\n\n#else\n\nstatic inline int __bch_count_data(struct btree_keys *b) { return -1; }\nstatic inline void __printf(2, 3)\n\t__bch_check_keys(struct btree_keys *b, const char *fmt, ...) {}\nstatic inline void bch_dump_bucket(struct btree_keys *b) {}\nvoid bch_dump_bset(struct btree_keys *b, struct bset *i, unsigned int set);\n\n#endif\n\nstatic inline bool btree_keys_expensive_checks(struct btree_keys *b)\n{\n#ifdef CONFIG_BCACHE_DEBUG\n\treturn *b->expensive_debug_checks;\n#else\n\treturn false;\n#endif\n}\n\nstatic inline int bch_count_data(struct btree_keys *b)\n{\n\treturn btree_keys_expensive_checks(b) ? __bch_count_data(b) : -1;\n}\n\n#define bch_check_keys(b, ...)\t\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (btree_keys_expensive_checks(b))\t\t\t\t\\\n\t\t__bch_check_keys(b, __VA_ARGS__);\t\t\t\\\n} while (0)\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}