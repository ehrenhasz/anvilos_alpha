{
  "module_name": "writeback.h",
  "hash_id": "24e4e9db662eb0fe742c89f014a1b6c7fde64fbfdd1f5f5265fa3d4c716eede2",
  "original_prompt": "Ingested from linux-6.6.14/drivers/md/bcache/writeback.h",
  "human_readable_source": " \n#ifndef _BCACHE_WRITEBACK_H\n#define _BCACHE_WRITEBACK_H\n\n#define CUTOFF_WRITEBACK\t40\n#define CUTOFF_WRITEBACK_SYNC\t70\n\n#define CUTOFF_WRITEBACK_MAX\t\t70\n#define CUTOFF_WRITEBACK_SYNC_MAX\t90\n\n#define MAX_WRITEBACKS_IN_PASS  5\n#define MAX_WRITESIZE_IN_PASS   5000\t \n\n#define WRITEBACK_RATE_UPDATE_SECS_MAX\t\t60\n#define WRITEBACK_RATE_UPDATE_SECS_DEFAULT\t5\n\n#define BCH_AUTO_GC_DIRTY_THRESHOLD\t50\n\n#define BCH_WRITEBACK_FRAGMENT_THRESHOLD_LOW 50\n#define BCH_WRITEBACK_FRAGMENT_THRESHOLD_MID 57\n#define BCH_WRITEBACK_FRAGMENT_THRESHOLD_HIGH 64\n\n#define BCH_DIRTY_INIT_THRD_MAX\t12\n \n#define WRITEBACK_SHARE_SHIFT   14\n\nstruct bch_dirty_init_state;\nstruct dirty_init_thrd_info {\n\tstruct bch_dirty_init_state\t*state;\n\tstruct task_struct\t\t*thread;\n};\n\nstruct bch_dirty_init_state {\n\tstruct cache_set\t\t*c;\n\tstruct bcache_device\t\t*d;\n\tint\t\t\t\ttotal_threads;\n\tint\t\t\t\tkey_idx;\n\tspinlock_t\t\t\tidx_lock;\n\tatomic_t\t\t\tstarted;\n\tatomic_t\t\t\tenough;\n\twait_queue_head_t\t\twait;\n\tstruct dirty_init_thrd_info\tinfos[BCH_DIRTY_INIT_THRD_MAX];\n};\n\nstatic inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)\n{\n\tuint64_t i, ret = 0;\n\n\tfor (i = 0; i < d->nr_stripes; i++)\n\t\tret += atomic_read(d->stripe_sectors_dirty + i);\n\n\treturn ret;\n}\n\nstatic inline int offset_to_stripe(struct bcache_device *d,\n\t\t\t\t\tuint64_t offset)\n{\n\tdo_div(offset, d->stripe_size);\n\n\t \n\tif (unlikely(offset >= d->nr_stripes)) {\n\t\tpr_err(\"Invalid stripe %llu (>= nr_stripes %d).\\n\",\n\t\t\toffset, d->nr_stripes);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\treturn offset;\n}\n\nstatic inline bool bcache_dev_stripe_dirty(struct cached_dev *dc,\n\t\t\t\t\t   uint64_t offset,\n\t\t\t\t\t   unsigned int nr_sectors)\n{\n\tint stripe = offset_to_stripe(&dc->disk, offset);\n\n\tif (stripe < 0)\n\t\treturn false;\n\n\twhile (1) {\n\t\tif (atomic_read(dc->disk.stripe_sectors_dirty + stripe))\n\t\t\treturn true;\n\n\t\tif (nr_sectors <= dc->disk.stripe_size)\n\t\t\treturn false;\n\n\t\tnr_sectors -= dc->disk.stripe_size;\n\t\tstripe++;\n\t}\n}\n\nextern unsigned int bch_cutoff_writeback;\nextern unsigned int bch_cutoff_writeback_sync;\n\nstatic inline bool should_writeback(struct cached_dev *dc, struct bio *bio,\n\t\t\t\t    unsigned int cache_mode, bool would_skip)\n{\n\tunsigned int in_use = dc->disk.c->gc_stats.in_use;\n\n\tif (cache_mode != CACHE_MODE_WRITEBACK ||\n\t    test_bit(BCACHE_DEV_DETACHING, &dc->disk.flags) ||\n\t    in_use > bch_cutoff_writeback_sync)\n\t\treturn false;\n\n\tif (bio_op(bio) == REQ_OP_DISCARD)\n\t\treturn false;\n\n\tif (dc->partial_stripes_expensive &&\n\t    bcache_dev_stripe_dirty(dc, bio->bi_iter.bi_sector,\n\t\t\t\t    bio_sectors(bio)))\n\t\treturn true;\n\n\tif (would_skip)\n\t\treturn false;\n\n\treturn (op_is_sync(bio->bi_opf) ||\n\t\tbio->bi_opf & (REQ_META|REQ_PRIO) ||\n\t\tin_use <= bch_cutoff_writeback);\n}\n\nstatic inline void bch_writeback_queue(struct cached_dev *dc)\n{\n\tif (!IS_ERR_OR_NULL(dc->writeback_thread))\n\t\twake_up_process(dc->writeback_thread);\n}\n\nstatic inline void bch_writeback_add(struct cached_dev *dc)\n{\n\tif (!atomic_read(&dc->has_dirty) &&\n\t    !atomic_xchg(&dc->has_dirty, 1)) {\n\t\tif (BDEV_STATE(&dc->sb) != BDEV_STATE_DIRTY) {\n\t\t\tSET_BDEV_STATE(&dc->sb, BDEV_STATE_DIRTY);\n\t\t\t \n\t\t\tbch_write_bdev_super(dc, NULL);\n\t\t}\n\n\t\tbch_writeback_queue(dc);\n\t}\n}\n\nvoid bcache_dev_sectors_dirty_add(struct cache_set *c, unsigned int inode,\n\t\t\t\t  uint64_t offset, int nr_sectors);\n\nvoid bch_sectors_dirty_init(struct bcache_device *d);\nvoid bch_cached_dev_writeback_init(struct cached_dev *dc);\nint bch_cached_dev_writeback_start(struct cached_dev *dc);\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}