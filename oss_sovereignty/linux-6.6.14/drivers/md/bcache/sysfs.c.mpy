{
  "module_name": "sysfs.c",
  "hash_id": "e151ec917b5c5e90f9021692f9e13c9d475a2a06c8ecd747a8e615bd3fa73f20",
  "original_prompt": "Ingested from linux-6.6.14/drivers/md/bcache/sysfs.c",
  "human_readable_source": "\n \n\n#include \"bcache.h\"\n#include \"sysfs.h\"\n#include \"btree.h\"\n#include \"request.h\"\n#include \"writeback.h\"\n#include \"features.h\"\n\n#include <linux/blkdev.h>\n#include <linux/sort.h>\n#include <linux/sched/clock.h>\n\nextern bool bcache_is_reboot;\n\n \nstatic const char * const bch_cache_modes[] = {\n\t\"writethrough\",\n\t\"writeback\",\n\t\"writearound\",\n\t\"none\",\n\tNULL\n};\n\nstatic const char * const bch_reada_cache_policies[] = {\n\t\"all\",\n\t\"meta-only\",\n\tNULL\n};\n\n \nstatic const char * const bch_stop_on_failure_modes[] = {\n\t\"auto\",\n\t\"always\",\n\tNULL\n};\n\nstatic const char * const cache_replacement_policies[] = {\n\t\"lru\",\n\t\"fifo\",\n\t\"random\",\n\tNULL\n};\n\nstatic const char * const error_actions[] = {\n\t\"unregister\",\n\t\"panic\",\n\tNULL\n};\n\nwrite_attribute(attach);\nwrite_attribute(detach);\nwrite_attribute(unregister);\nwrite_attribute(stop);\nwrite_attribute(clear_stats);\nwrite_attribute(trigger_gc);\nwrite_attribute(prune_cache);\nwrite_attribute(flash_vol_create);\n\nread_attribute(bucket_size);\nread_attribute(block_size);\nread_attribute(nbuckets);\nread_attribute(tree_depth);\nread_attribute(root_usage_percent);\nread_attribute(priority_stats);\nread_attribute(btree_cache_size);\nread_attribute(btree_cache_max_chain);\nread_attribute(cache_available_percent);\nread_attribute(written);\nread_attribute(btree_written);\nread_attribute(metadata_written);\nread_attribute(active_journal_entries);\nread_attribute(backing_dev_name);\nread_attribute(backing_dev_uuid);\n\nsysfs_time_stats_attribute(btree_gc,\tsec, ms);\nsysfs_time_stats_attribute(btree_split, sec, us);\nsysfs_time_stats_attribute(btree_sort,\tms,  us);\nsysfs_time_stats_attribute(btree_read,\tms,  us);\n\nread_attribute(btree_nodes);\nread_attribute(btree_used_percent);\nread_attribute(average_key_size);\nread_attribute(dirty_data);\nread_attribute(bset_tree_stats);\nread_attribute(feature_compat);\nread_attribute(feature_ro_compat);\nread_attribute(feature_incompat);\n\nread_attribute(state);\nread_attribute(cache_read_races);\nread_attribute(reclaim);\nread_attribute(reclaimed_journal_buckets);\nread_attribute(flush_write);\nread_attribute(writeback_keys_done);\nread_attribute(writeback_keys_failed);\nread_attribute(io_errors);\nread_attribute(congested);\nread_attribute(cutoff_writeback);\nread_attribute(cutoff_writeback_sync);\nrw_attribute(congested_read_threshold_us);\nrw_attribute(congested_write_threshold_us);\n\nrw_attribute(sequential_cutoff);\nrw_attribute(data_csum);\nrw_attribute(cache_mode);\nrw_attribute(readahead_cache_policy);\nrw_attribute(stop_when_cache_set_failed);\nrw_attribute(writeback_metadata);\nrw_attribute(writeback_running);\nrw_attribute(writeback_percent);\nrw_attribute(writeback_delay);\nrw_attribute(writeback_rate);\nrw_attribute(writeback_consider_fragment);\n\nrw_attribute(writeback_rate_update_seconds);\nrw_attribute(writeback_rate_i_term_inverse);\nrw_attribute(writeback_rate_p_term_inverse);\nrw_attribute(writeback_rate_fp_term_low);\nrw_attribute(writeback_rate_fp_term_mid);\nrw_attribute(writeback_rate_fp_term_high);\nrw_attribute(writeback_rate_minimum);\nread_attribute(writeback_rate_debug);\n\nread_attribute(stripe_size);\nread_attribute(partial_stripes_expensive);\n\nrw_attribute(synchronous);\nrw_attribute(journal_delay_ms);\nrw_attribute(io_disable);\nrw_attribute(discard);\nrw_attribute(running);\nrw_attribute(label);\nrw_attribute(errors);\nrw_attribute(io_error_limit);\nrw_attribute(io_error_halflife);\nrw_attribute(verify);\nrw_attribute(bypass_torture_test);\nrw_attribute(key_merging_disabled);\nrw_attribute(gc_always_rewrite);\nrw_attribute(expensive_debug_checks);\nrw_attribute(cache_replacement_policy);\nrw_attribute(btree_shrinker_disabled);\nrw_attribute(copy_gc_enabled);\nrw_attribute(idle_max_writeback_rate);\nrw_attribute(gc_after_writeback);\nrw_attribute(size);\n\nstatic ssize_t bch_snprint_string_list(char *buf,\n\t\t\t\t       size_t size,\n\t\t\t\t       const char * const list[],\n\t\t\t\t       size_t selected)\n{\n\tchar *out = buf;\n\tsize_t i;\n\n\tfor (i = 0; list[i]; i++)\n\t\tout += scnprintf(out, buf + size - out,\n\t\t\t\ti == selected ? \"[%s] \" : \"%s \", list[i]);\n\n\tout[-1] = '\\n';\n\treturn out - buf;\n}\n\nSHOW(__bch_cached_dev)\n{\n\tstruct cached_dev *dc = container_of(kobj, struct cached_dev,\n\t\t\t\t\t     disk.kobj);\n\tchar const *states[] = { \"no cache\", \"clean\", \"dirty\", \"inconsistent\" };\n\tint wb = dc->writeback_running;\n\n#define var(stat)\t\t(dc->stat)\n\n\tif (attr == &sysfs_cache_mode)\n\t\treturn bch_snprint_string_list(buf, PAGE_SIZE,\n\t\t\t\t\t       bch_cache_modes,\n\t\t\t\t\t       BDEV_CACHE_MODE(&dc->sb));\n\n\tif (attr == &sysfs_readahead_cache_policy)\n\t\treturn bch_snprint_string_list(buf, PAGE_SIZE,\n\t\t\t\t\t      bch_reada_cache_policies,\n\t\t\t\t\t      dc->cache_readahead_policy);\n\n\tif (attr == &sysfs_stop_when_cache_set_failed)\n\t\treturn bch_snprint_string_list(buf, PAGE_SIZE,\n\t\t\t\t\t       bch_stop_on_failure_modes,\n\t\t\t\t\t       dc->stop_when_cache_set_failed);\n\n\n\tsysfs_printf(data_csum,\t\t\"%i\", dc->disk.data_csum);\n\tvar_printf(verify,\t\t\"%i\");\n\tvar_printf(bypass_torture_test,\t\"%i\");\n\tvar_printf(writeback_metadata,\t\"%i\");\n\tvar_printf(writeback_running,\t\"%i\");\n\tvar_printf(writeback_consider_fragment,\t\"%i\");\n\tvar_print(writeback_delay);\n\tvar_print(writeback_percent);\n\tsysfs_hprint(writeback_rate,\n\t\t     wb ? atomic_long_read(&dc->writeback_rate.rate) << 9 : 0);\n\tsysfs_printf(io_errors,\t\t\"%i\", atomic_read(&dc->io_errors));\n\tsysfs_printf(io_error_limit,\t\"%i\", dc->error_limit);\n\tsysfs_printf(io_disable,\t\"%i\", dc->io_disable);\n\tvar_print(writeback_rate_update_seconds);\n\tvar_print(writeback_rate_i_term_inverse);\n\tvar_print(writeback_rate_p_term_inverse);\n\tvar_print(writeback_rate_fp_term_low);\n\tvar_print(writeback_rate_fp_term_mid);\n\tvar_print(writeback_rate_fp_term_high);\n\tvar_print(writeback_rate_minimum);\n\n\tif (attr == &sysfs_writeback_rate_debug) {\n\t\tchar rate[20];\n\t\tchar dirty[20];\n\t\tchar target[20];\n\t\tchar proportional[20];\n\t\tchar integral[20];\n\t\tchar change[20];\n\t\ts64 next_io;\n\n\t\t \n\t\tbch_hprint(rate,\n\t\t\t   wb ? atomic_long_read(&dc->writeback_rate.rate) << 9\n\t\t\t      : 0);\n\t\tbch_hprint(dirty, bcache_dev_sectors_dirty(&dc->disk) << 9);\n\t\tbch_hprint(target, dc->writeback_rate_target << 9);\n\t\tbch_hprint(proportional,\n\t\t\t   wb ? dc->writeback_rate_proportional << 9 : 0);\n\t\tbch_hprint(integral,\n\t\t\t   wb ? dc->writeback_rate_integral_scaled << 9 : 0);\n\t\tbch_hprint(change, wb ? dc->writeback_rate_change << 9 : 0);\n\t\tnext_io = wb ? div64_s64(dc->writeback_rate.next-local_clock(),\n\t\t\t\t\t NSEC_PER_MSEC) : 0;\n\n\t\treturn sprintf(buf,\n\t\t\t       \"rate:\\t\\t%s/sec\\n\"\n\t\t\t       \"dirty:\\t\\t%s\\n\"\n\t\t\t       \"target:\\t\\t%s\\n\"\n\t\t\t       \"proportional:\\t%s\\n\"\n\t\t\t       \"integral:\\t%s\\n\"\n\t\t\t       \"change:\\t\\t%s/sec\\n\"\n\t\t\t       \"next io:\\t%llims\\n\",\n\t\t\t       rate, dirty, target, proportional,\n\t\t\t       integral, change, next_io);\n\t}\n\n\tsysfs_hprint(dirty_data,\n\t\t     bcache_dev_sectors_dirty(&dc->disk) << 9);\n\n\tsysfs_hprint(stripe_size,\t ((uint64_t)dc->disk.stripe_size) << 9);\n\tvar_printf(partial_stripes_expensive,\t\"%u\");\n\n\tvar_hprint(sequential_cutoff);\n\n\tsysfs_print(running,\t\tatomic_read(&dc->running));\n\tsysfs_print(state,\t\tstates[BDEV_STATE(&dc->sb)]);\n\n\tif (attr == &sysfs_label) {\n\t\tmemcpy(buf, dc->sb.label, SB_LABEL_SIZE);\n\t\tbuf[SB_LABEL_SIZE + 1] = '\\0';\n\t\tstrcat(buf, \"\\n\");\n\t\treturn strlen(buf);\n\t}\n\n\tif (attr == &sysfs_backing_dev_name) {\n\t\tsnprintf(buf, BDEVNAME_SIZE + 1, \"%pg\", dc->bdev);\n\t\tstrcat(buf, \"\\n\");\n\t\treturn strlen(buf);\n\t}\n\n\tif (attr == &sysfs_backing_dev_uuid) {\n\t\t \n\t\tsnprintf(buf, 36+1, \"%pU\", dc->sb.uuid);\n\t\tstrcat(buf, \"\\n\");\n\t\treturn strlen(buf);\n\t}\n\n#undef var\n\treturn 0;\n}\nSHOW_LOCKED(bch_cached_dev)\n\nSTORE(__cached_dev)\n{\n\tstruct cached_dev *dc = container_of(kobj, struct cached_dev,\n\t\t\t\t\t     disk.kobj);\n\tssize_t v;\n\tstruct cache_set *c;\n\tstruct kobj_uevent_env *env;\n\n\t \n\tif (bcache_is_reboot)\n\t\treturn -EBUSY;\n\n#define d_strtoul(var)\t\tsysfs_strtoul(var, dc->var)\n#define d_strtoul_nonzero(var)\tsysfs_strtoul_clamp(var, dc->var, 1, INT_MAX)\n#define d_strtoi_h(var)\t\tsysfs_hatoi(var, dc->var)\n\n\tsysfs_strtoul(data_csum,\tdc->disk.data_csum);\n\td_strtoul(verify);\n\tsysfs_strtoul_bool(bypass_torture_test, dc->bypass_torture_test);\n\tsysfs_strtoul_bool(writeback_metadata, dc->writeback_metadata);\n\tsysfs_strtoul_bool(writeback_running, dc->writeback_running);\n\tsysfs_strtoul_bool(writeback_consider_fragment, dc->writeback_consider_fragment);\n\tsysfs_strtoul_clamp(writeback_delay, dc->writeback_delay, 0, UINT_MAX);\n\n\tsysfs_strtoul_clamp(writeback_percent, dc->writeback_percent,\n\t\t\t    0, bch_cutoff_writeback);\n\n\tif (attr == &sysfs_writeback_rate) {\n\t\tssize_t ret;\n\t\tlong int v = atomic_long_read(&dc->writeback_rate.rate);\n\n\t\tret = strtoul_safe_clamp(buf, v, 1, INT_MAX);\n\n\t\tif (!ret) {\n\t\t\tatomic_long_set(&dc->writeback_rate.rate, v);\n\t\t\tret = size;\n\t\t}\n\n\t\treturn ret;\n\t}\n\n\tsysfs_strtoul_clamp(writeback_rate_update_seconds,\n\t\t\t    dc->writeback_rate_update_seconds,\n\t\t\t    1, WRITEBACK_RATE_UPDATE_SECS_MAX);\n\tsysfs_strtoul_clamp(writeback_rate_i_term_inverse,\n\t\t\t    dc->writeback_rate_i_term_inverse,\n\t\t\t    1, UINT_MAX);\n\tsysfs_strtoul_clamp(writeback_rate_p_term_inverse,\n\t\t\t    dc->writeback_rate_p_term_inverse,\n\t\t\t    1, UINT_MAX);\n\tsysfs_strtoul_clamp(writeback_rate_fp_term_low,\n\t\t\t    dc->writeback_rate_fp_term_low,\n\t\t\t    1, dc->writeback_rate_fp_term_mid - 1);\n\tsysfs_strtoul_clamp(writeback_rate_fp_term_mid,\n\t\t\t    dc->writeback_rate_fp_term_mid,\n\t\t\t    dc->writeback_rate_fp_term_low + 1,\n\t\t\t    dc->writeback_rate_fp_term_high - 1);\n\tsysfs_strtoul_clamp(writeback_rate_fp_term_high,\n\t\t\t    dc->writeback_rate_fp_term_high,\n\t\t\t    dc->writeback_rate_fp_term_mid + 1, UINT_MAX);\n\tsysfs_strtoul_clamp(writeback_rate_minimum,\n\t\t\t    dc->writeback_rate_minimum,\n\t\t\t    1, UINT_MAX);\n\n\tsysfs_strtoul_clamp(io_error_limit, dc->error_limit, 0, INT_MAX);\n\n\tif (attr == &sysfs_io_disable) {\n\t\tint v = strtoul_or_return(buf);\n\n\t\tdc->io_disable = v ? 1 : 0;\n\t}\n\n\tsysfs_strtoul_clamp(sequential_cutoff,\n\t\t\t    dc->sequential_cutoff,\n\t\t\t    0, UINT_MAX);\n\n\tif (attr == &sysfs_clear_stats)\n\t\tbch_cache_accounting_clear(&dc->accounting);\n\n\tif (attr == &sysfs_running &&\n\t    strtoul_or_return(buf)) {\n\t\tv = bch_cached_dev_run(dc);\n\t\tif (v)\n\t\t\treturn v;\n\t}\n\n\tif (attr == &sysfs_cache_mode) {\n\t\tv = __sysfs_match_string(bch_cache_modes, -1, buf);\n\t\tif (v < 0)\n\t\t\treturn v;\n\n\t\tif ((unsigned int) v != BDEV_CACHE_MODE(&dc->sb)) {\n\t\t\tSET_BDEV_CACHE_MODE(&dc->sb, v);\n\t\t\tbch_write_bdev_super(dc, NULL);\n\t\t}\n\t}\n\n\tif (attr == &sysfs_readahead_cache_policy) {\n\t\tv = __sysfs_match_string(bch_reada_cache_policies, -1, buf);\n\t\tif (v < 0)\n\t\t\treturn v;\n\n\t\tif ((unsigned int) v != dc->cache_readahead_policy)\n\t\t\tdc->cache_readahead_policy = v;\n\t}\n\n\tif (attr == &sysfs_stop_when_cache_set_failed) {\n\t\tv = __sysfs_match_string(bch_stop_on_failure_modes, -1, buf);\n\t\tif (v < 0)\n\t\t\treturn v;\n\n\t\tdc->stop_when_cache_set_failed = v;\n\t}\n\n\tif (attr == &sysfs_label) {\n\t\tif (size > SB_LABEL_SIZE)\n\t\t\treturn -EINVAL;\n\t\tmemcpy(dc->sb.label, buf, size);\n\t\tif (size < SB_LABEL_SIZE)\n\t\t\tdc->sb.label[size] = '\\0';\n\t\tif (size && dc->sb.label[size - 1] == '\\n')\n\t\t\tdc->sb.label[size - 1] = '\\0';\n\t\tbch_write_bdev_super(dc, NULL);\n\t\tif (dc->disk.c) {\n\t\t\tmemcpy(dc->disk.c->uuids[dc->disk.id].label,\n\t\t\t       buf, SB_LABEL_SIZE);\n\t\t\tbch_uuid_write(dc->disk.c);\n\t\t}\n\t\tenv = kzalloc(sizeof(struct kobj_uevent_env), GFP_KERNEL);\n\t\tif (!env)\n\t\t\treturn -ENOMEM;\n\t\tadd_uevent_var(env, \"DRIVER=bcache\");\n\t\tadd_uevent_var(env, \"CACHED_UUID=%pU\", dc->sb.uuid);\n\t\tadd_uevent_var(env, \"CACHED_LABEL=%s\", buf);\n\t\tkobject_uevent_env(&disk_to_dev(dc->disk.disk)->kobj,\n\t\t\t\t   KOBJ_CHANGE,\n\t\t\t\t   env->envp);\n\t\tkfree(env);\n\t}\n\n\tif (attr == &sysfs_attach) {\n\t\tuint8_t\t\tset_uuid[16];\n\n\t\tif (bch_parse_uuid(buf, set_uuid) < 16)\n\t\t\treturn -EINVAL;\n\n\t\tv = -ENOENT;\n\t\tlist_for_each_entry(c, &bch_cache_sets, list) {\n\t\t\tv = bch_cached_dev_attach(dc, c, set_uuid);\n\t\t\tif (!v)\n\t\t\t\treturn size;\n\t\t}\n\t\tif (v == -ENOENT)\n\t\t\tpr_err(\"Can't attach %s: cache set not found\\n\", buf);\n\t\treturn v;\n\t}\n\n\tif (attr == &sysfs_detach && dc->disk.c)\n\t\tbch_cached_dev_detach(dc);\n\n\tif (attr == &sysfs_stop)\n\t\tbcache_device_stop(&dc->disk);\n\n\treturn size;\n}\n\nSTORE(bch_cached_dev)\n{\n\tstruct cached_dev *dc = container_of(kobj, struct cached_dev,\n\t\t\t\t\t     disk.kobj);\n\n\t \n\tif (bcache_is_reboot)\n\t\treturn -EBUSY;\n\n\tmutex_lock(&bch_register_lock);\n\tsize = __cached_dev_store(kobj, attr, buf, size);\n\n\tif (attr == &sysfs_writeback_running) {\n\t\t \n\t\tif (IS_ERR_OR_NULL(dc->writeback_thread)) {\n\t\t\t \n\t\t\tif (dc->writeback_running) {\n\t\t\t\tdc->writeback_running = false;\n\t\t\t\tpr_err(\"%s: failed to run non-existent writeback thread\\n\",\n\t\t\t\t\t\tdc->disk.disk->disk_name);\n\t\t\t}\n\t\t} else\n\t\t\t \n\t\t\tbch_writeback_queue(dc);\n\t}\n\n\t \n\tif (attr == &sysfs_writeback_percent)\n\t\tif ((dc->disk.c != NULL) &&\n\t\t    (!test_and_set_bit(BCACHE_DEV_WB_RUNNING, &dc->disk.flags)))\n\t\t\tschedule_delayed_work(&dc->writeback_rate_update,\n\t\t\t\t      dc->writeback_rate_update_seconds * HZ);\n\n\tmutex_unlock(&bch_register_lock);\n\treturn size;\n}\n\nstatic struct attribute *bch_cached_dev_attrs[] = {\n\t&sysfs_attach,\n\t&sysfs_detach,\n\t&sysfs_stop,\n#if 0\n\t&sysfs_data_csum,\n#endif\n\t&sysfs_cache_mode,\n\t&sysfs_readahead_cache_policy,\n\t&sysfs_stop_when_cache_set_failed,\n\t&sysfs_writeback_metadata,\n\t&sysfs_writeback_running,\n\t&sysfs_writeback_delay,\n\t&sysfs_writeback_percent,\n\t&sysfs_writeback_rate,\n\t&sysfs_writeback_consider_fragment,\n\t&sysfs_writeback_rate_update_seconds,\n\t&sysfs_writeback_rate_i_term_inverse,\n\t&sysfs_writeback_rate_p_term_inverse,\n\t&sysfs_writeback_rate_fp_term_low,\n\t&sysfs_writeback_rate_fp_term_mid,\n\t&sysfs_writeback_rate_fp_term_high,\n\t&sysfs_writeback_rate_minimum,\n\t&sysfs_writeback_rate_debug,\n\t&sysfs_io_errors,\n\t&sysfs_io_error_limit,\n\t&sysfs_io_disable,\n\t&sysfs_dirty_data,\n\t&sysfs_stripe_size,\n\t&sysfs_partial_stripes_expensive,\n\t&sysfs_sequential_cutoff,\n\t&sysfs_clear_stats,\n\t&sysfs_running,\n\t&sysfs_state,\n\t&sysfs_label,\n#ifdef CONFIG_BCACHE_DEBUG\n\t&sysfs_verify,\n\t&sysfs_bypass_torture_test,\n#endif\n\t&sysfs_backing_dev_name,\n\t&sysfs_backing_dev_uuid,\n\tNULL\n};\nATTRIBUTE_GROUPS(bch_cached_dev);\nKTYPE(bch_cached_dev);\n\nSHOW(bch_flash_dev)\n{\n\tstruct bcache_device *d = container_of(kobj, struct bcache_device,\n\t\t\t\t\t       kobj);\n\tstruct uuid_entry *u = &d->c->uuids[d->id];\n\n\tsysfs_printf(data_csum,\t\"%i\", d->data_csum);\n\tsysfs_hprint(size,\tu->sectors << 9);\n\n\tif (attr == &sysfs_label) {\n\t\tmemcpy(buf, u->label, SB_LABEL_SIZE);\n\t\tbuf[SB_LABEL_SIZE + 1] = '\\0';\n\t\tstrcat(buf, \"\\n\");\n\t\treturn strlen(buf);\n\t}\n\n\treturn 0;\n}\n\nSTORE(__bch_flash_dev)\n{\n\tstruct bcache_device *d = container_of(kobj, struct bcache_device,\n\t\t\t\t\t       kobj);\n\tstruct uuid_entry *u = &d->c->uuids[d->id];\n\n\t \n\tif (bcache_is_reboot)\n\t\treturn -EBUSY;\n\n\tsysfs_strtoul(data_csum,\td->data_csum);\n\n\tif (attr == &sysfs_size) {\n\t\tuint64_t v;\n\n\t\tstrtoi_h_or_return(buf, v);\n\n\t\tu->sectors = v >> 9;\n\t\tbch_uuid_write(d->c);\n\t\tset_capacity(d->disk, u->sectors);\n\t}\n\n\tif (attr == &sysfs_label) {\n\t\tmemcpy(u->label, buf, SB_LABEL_SIZE);\n\t\tbch_uuid_write(d->c);\n\t}\n\n\tif (attr == &sysfs_unregister) {\n\t\tset_bit(BCACHE_DEV_DETACHING, &d->flags);\n\t\tbcache_device_stop(d);\n\t}\n\n\treturn size;\n}\nSTORE_LOCKED(bch_flash_dev)\n\nstatic struct attribute *bch_flash_dev_attrs[] = {\n\t&sysfs_unregister,\n#if 0\n\t&sysfs_data_csum,\n#endif\n\t&sysfs_label,\n\t&sysfs_size,\n\tNULL\n};\nATTRIBUTE_GROUPS(bch_flash_dev);\nKTYPE(bch_flash_dev);\n\nstruct bset_stats_op {\n\tstruct btree_op op;\n\tsize_t nodes;\n\tstruct bset_stats stats;\n};\n\nstatic int bch_btree_bset_stats(struct btree_op *b_op, struct btree *b)\n{\n\tstruct bset_stats_op *op = container_of(b_op, struct bset_stats_op, op);\n\n\top->nodes++;\n\tbch_btree_keys_stats(&b->keys, &op->stats);\n\n\treturn MAP_CONTINUE;\n}\n\nstatic int bch_bset_print_stats(struct cache_set *c, char *buf)\n{\n\tstruct bset_stats_op op;\n\tint ret;\n\n\tmemset(&op, 0, sizeof(op));\n\tbch_btree_op_init(&op.op, -1);\n\n\tret = bch_btree_map_nodes(&op.op, c, &ZERO_KEY, bch_btree_bset_stats);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn snprintf(buf, PAGE_SIZE,\n\t\t\t\"btree nodes:\t\t%zu\\n\"\n\t\t\t\"written sets:\t\t%zu\\n\"\n\t\t\t\"unwritten sets:\t\t%zu\\n\"\n\t\t\t\"written key bytes:\t%zu\\n\"\n\t\t\t\"unwritten key bytes:\t%zu\\n\"\n\t\t\t\"floats:\t\t\t%zu\\n\"\n\t\t\t\"failed:\t\t\t%zu\\n\",\n\t\t\top.nodes,\n\t\t\top.stats.sets_written, op.stats.sets_unwritten,\n\t\t\top.stats.bytes_written, op.stats.bytes_unwritten,\n\t\t\top.stats.floats, op.stats.failed);\n}\n\nstatic unsigned int bch_root_usage(struct cache_set *c)\n{\n\tunsigned int bytes = 0;\n\tstruct bkey *k;\n\tstruct btree *b;\n\tstruct btree_iter iter;\n\n\tgoto lock_root;\n\n\tdo {\n\t\trw_unlock(false, b);\nlock_root:\n\t\tb = c->root;\n\t\trw_lock(false, b, b->level);\n\t} while (b != c->root);\n\n\tfor_each_key_filter(&b->keys, k, &iter, bch_ptr_bad)\n\t\tbytes += bkey_bytes(k);\n\n\trw_unlock(false, b);\n\n\treturn (bytes * 100) / btree_bytes(c);\n}\n\nstatic size_t bch_cache_size(struct cache_set *c)\n{\n\tsize_t ret = 0;\n\tstruct btree *b;\n\n\tmutex_lock(&c->bucket_lock);\n\tlist_for_each_entry(b, &c->btree_cache, list)\n\t\tret += 1 << (b->keys.page_order + PAGE_SHIFT);\n\n\tmutex_unlock(&c->bucket_lock);\n\treturn ret;\n}\n\nstatic unsigned int bch_cache_max_chain(struct cache_set *c)\n{\n\tunsigned int ret = 0;\n\tstruct hlist_head *h;\n\n\tmutex_lock(&c->bucket_lock);\n\n\tfor (h = c->bucket_hash;\n\t     h < c->bucket_hash + (1 << BUCKET_HASH_BITS);\n\t     h++) {\n\t\tunsigned int i = 0;\n\t\tstruct hlist_node *p;\n\n\t\thlist_for_each(p, h)\n\t\t\ti++;\n\n\t\tret = max(ret, i);\n\t}\n\n\tmutex_unlock(&c->bucket_lock);\n\treturn ret;\n}\n\nstatic unsigned int bch_btree_used(struct cache_set *c)\n{\n\treturn div64_u64(c->gc_stats.key_bytes * 100,\n\t\t\t (c->gc_stats.nodes ?: 1) * btree_bytes(c));\n}\n\nstatic unsigned int bch_average_key_size(struct cache_set *c)\n{\n\treturn c->gc_stats.nkeys\n\t\t? div64_u64(c->gc_stats.data, c->gc_stats.nkeys)\n\t\t: 0;\n}\n\nSHOW(__bch_cache_set)\n{\n\tstruct cache_set *c = container_of(kobj, struct cache_set, kobj);\n\n\tsysfs_print(synchronous,\t\tCACHE_SYNC(&c->cache->sb));\n\tsysfs_print(journal_delay_ms,\t\tc->journal_delay_ms);\n\tsysfs_hprint(bucket_size,\t\tbucket_bytes(c->cache));\n\tsysfs_hprint(block_size,\t\tblock_bytes(c->cache));\n\tsysfs_print(tree_depth,\t\t\tc->root->level);\n\tsysfs_print(root_usage_percent,\t\tbch_root_usage(c));\n\n\tsysfs_hprint(btree_cache_size,\t\tbch_cache_size(c));\n\tsysfs_print(btree_cache_max_chain,\tbch_cache_max_chain(c));\n\tsysfs_print(cache_available_percent,\t100 - c->gc_stats.in_use);\n\n\tsysfs_print_time_stats(&c->btree_gc_time,\tbtree_gc, sec, ms);\n\tsysfs_print_time_stats(&c->btree_split_time,\tbtree_split, sec, us);\n\tsysfs_print_time_stats(&c->sort.time,\t\tbtree_sort, ms, us);\n\tsysfs_print_time_stats(&c->btree_read_time,\tbtree_read, ms, us);\n\n\tsysfs_print(btree_used_percent,\tbch_btree_used(c));\n\tsysfs_print(btree_nodes,\tc->gc_stats.nodes);\n\tsysfs_hprint(average_key_size,\tbch_average_key_size(c));\n\n\tsysfs_print(cache_read_races,\n\t\t    atomic_long_read(&c->cache_read_races));\n\n\tsysfs_print(reclaim,\n\t\t    atomic_long_read(&c->reclaim));\n\n\tsysfs_print(reclaimed_journal_buckets,\n\t\t    atomic_long_read(&c->reclaimed_journal_buckets));\n\n\tsysfs_print(flush_write,\n\t\t    atomic_long_read(&c->flush_write));\n\n\tsysfs_print(writeback_keys_done,\n\t\t    atomic_long_read(&c->writeback_keys_done));\n\tsysfs_print(writeback_keys_failed,\n\t\t    atomic_long_read(&c->writeback_keys_failed));\n\n\tif (attr == &sysfs_errors)\n\t\treturn bch_snprint_string_list(buf, PAGE_SIZE, error_actions,\n\t\t\t\t\t       c->on_error);\n\n\t \n\tsysfs_print(io_error_halflife,\tc->error_decay * 88);\n\tsysfs_print(io_error_limit,\tc->error_limit);\n\n\tsysfs_hprint(congested,\n\t\t     ((uint64_t) bch_get_congested(c)) << 9);\n\tsysfs_print(congested_read_threshold_us,\n\t\t    c->congested_read_threshold_us);\n\tsysfs_print(congested_write_threshold_us,\n\t\t    c->congested_write_threshold_us);\n\n\tsysfs_print(cutoff_writeback, bch_cutoff_writeback);\n\tsysfs_print(cutoff_writeback_sync, bch_cutoff_writeback_sync);\n\n\tsysfs_print(active_journal_entries,\tfifo_used(&c->journal.pin));\n\tsysfs_printf(verify,\t\t\t\"%i\", c->verify);\n\tsysfs_printf(key_merging_disabled,\t\"%i\", c->key_merging_disabled);\n\tsysfs_printf(expensive_debug_checks,\n\t\t     \"%i\", c->expensive_debug_checks);\n\tsysfs_printf(gc_always_rewrite,\t\t\"%i\", c->gc_always_rewrite);\n\tsysfs_printf(btree_shrinker_disabled,\t\"%i\", c->shrinker_disabled);\n\tsysfs_printf(copy_gc_enabled,\t\t\"%i\", c->copy_gc_enabled);\n\tsysfs_printf(idle_max_writeback_rate,\t\"%i\",\n\t\t     c->idle_max_writeback_rate_enabled);\n\tsysfs_printf(gc_after_writeback,\t\"%i\", c->gc_after_writeback);\n\tsysfs_printf(io_disable,\t\t\"%i\",\n\t\t     test_bit(CACHE_SET_IO_DISABLE, &c->flags));\n\n\tif (attr == &sysfs_bset_tree_stats)\n\t\treturn bch_bset_print_stats(c, buf);\n\n\tif (attr == &sysfs_feature_compat)\n\t\treturn bch_print_cache_set_feature_compat(c, buf, PAGE_SIZE);\n\tif (attr == &sysfs_feature_ro_compat)\n\t\treturn bch_print_cache_set_feature_ro_compat(c, buf, PAGE_SIZE);\n\tif (attr == &sysfs_feature_incompat)\n\t\treturn bch_print_cache_set_feature_incompat(c, buf, PAGE_SIZE);\n\n\treturn 0;\n}\nSHOW_LOCKED(bch_cache_set)\n\nSTORE(__bch_cache_set)\n{\n\tstruct cache_set *c = container_of(kobj, struct cache_set, kobj);\n\tssize_t v;\n\n\t \n\tif (bcache_is_reboot)\n\t\treturn -EBUSY;\n\n\tif (attr == &sysfs_unregister)\n\t\tbch_cache_set_unregister(c);\n\n\tif (attr == &sysfs_stop)\n\t\tbch_cache_set_stop(c);\n\n\tif (attr == &sysfs_synchronous) {\n\t\tbool sync = strtoul_or_return(buf);\n\n\t\tif (sync != CACHE_SYNC(&c->cache->sb)) {\n\t\t\tSET_CACHE_SYNC(&c->cache->sb, sync);\n\t\t\tbcache_write_super(c);\n\t\t}\n\t}\n\n\tif (attr == &sysfs_flash_vol_create) {\n\t\tint r;\n\t\tuint64_t v;\n\n\t\tstrtoi_h_or_return(buf, v);\n\n\t\tr = bch_flash_dev_create(c, v);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tif (attr == &sysfs_clear_stats) {\n\t\tatomic_long_set(&c->writeback_keys_done,\t0);\n\t\tatomic_long_set(&c->writeback_keys_failed,\t0);\n\n\t\tmemset(&c->gc_stats, 0, sizeof(struct gc_stat));\n\t\tbch_cache_accounting_clear(&c->accounting);\n\t}\n\n\tif (attr == &sysfs_trigger_gc)\n\t\tforce_wake_up_gc(c);\n\n\tif (attr == &sysfs_prune_cache) {\n\t\tstruct shrink_control sc;\n\n\t\tsc.gfp_mask = GFP_KERNEL;\n\t\tsc.nr_to_scan = strtoul_or_return(buf);\n\t\tc->shrink.scan_objects(&c->shrink, &sc);\n\t}\n\n\tsysfs_strtoul_clamp(congested_read_threshold_us,\n\t\t\t    c->congested_read_threshold_us,\n\t\t\t    0, UINT_MAX);\n\tsysfs_strtoul_clamp(congested_write_threshold_us,\n\t\t\t    c->congested_write_threshold_us,\n\t\t\t    0, UINT_MAX);\n\n\tif (attr == &sysfs_errors) {\n\t\tv = __sysfs_match_string(error_actions, -1, buf);\n\t\tif (v < 0)\n\t\t\treturn v;\n\n\t\tc->on_error = v;\n\t}\n\n\tsysfs_strtoul_clamp(io_error_limit, c->error_limit, 0, UINT_MAX);\n\n\t \n\tif (attr == &sysfs_io_error_halflife) {\n\t\tunsigned long v = 0;\n\t\tssize_t ret;\n\n\t\tret = strtoul_safe_clamp(buf, v, 0, UINT_MAX);\n\t\tif (!ret) {\n\t\t\tc->error_decay = v / 88;\n\t\t\treturn size;\n\t\t}\n\t\treturn ret;\n\t}\n\n\tif (attr == &sysfs_io_disable) {\n\t\tv = strtoul_or_return(buf);\n\t\tif (v) {\n\t\t\tif (test_and_set_bit(CACHE_SET_IO_DISABLE,\n\t\t\t\t\t     &c->flags))\n\t\t\t\tpr_warn(\"CACHE_SET_IO_DISABLE already set\\n\");\n\t\t} else {\n\t\t\tif (!test_and_clear_bit(CACHE_SET_IO_DISABLE,\n\t\t\t\t\t\t&c->flags))\n\t\t\t\tpr_warn(\"CACHE_SET_IO_DISABLE already cleared\\n\");\n\t\t}\n\t}\n\n\tsysfs_strtoul_clamp(journal_delay_ms,\n\t\t\t    c->journal_delay_ms,\n\t\t\t    0, USHRT_MAX);\n\tsysfs_strtoul_bool(verify,\t\tc->verify);\n\tsysfs_strtoul_bool(key_merging_disabled, c->key_merging_disabled);\n\tsysfs_strtoul(expensive_debug_checks,\tc->expensive_debug_checks);\n\tsysfs_strtoul_bool(gc_always_rewrite,\tc->gc_always_rewrite);\n\tsysfs_strtoul_bool(btree_shrinker_disabled, c->shrinker_disabled);\n\tsysfs_strtoul_bool(copy_gc_enabled,\tc->copy_gc_enabled);\n\tsysfs_strtoul_bool(idle_max_writeback_rate,\n\t\t\t   c->idle_max_writeback_rate_enabled);\n\n\t \n\tsysfs_strtoul_clamp(gc_after_writeback, c->gc_after_writeback, 0, 1);\n\n\treturn size;\n}\nSTORE_LOCKED(bch_cache_set)\n\nSHOW(bch_cache_set_internal)\n{\n\tstruct cache_set *c = container_of(kobj, struct cache_set, internal);\n\n\treturn bch_cache_set_show(&c->kobj, attr, buf);\n}\n\nSTORE(bch_cache_set_internal)\n{\n\tstruct cache_set *c = container_of(kobj, struct cache_set, internal);\n\n\t \n\tif (bcache_is_reboot)\n\t\treturn -EBUSY;\n\n\treturn bch_cache_set_store(&c->kobj, attr, buf, size);\n}\n\nstatic void bch_cache_set_internal_release(struct kobject *k)\n{\n}\n\nstatic struct attribute *bch_cache_set_attrs[] = {\n\t&sysfs_unregister,\n\t&sysfs_stop,\n\t&sysfs_synchronous,\n\t&sysfs_journal_delay_ms,\n\t&sysfs_flash_vol_create,\n\n\t&sysfs_bucket_size,\n\t&sysfs_block_size,\n\t&sysfs_tree_depth,\n\t&sysfs_root_usage_percent,\n\t&sysfs_btree_cache_size,\n\t&sysfs_cache_available_percent,\n\n\t&sysfs_average_key_size,\n\n\t&sysfs_errors,\n\t&sysfs_io_error_limit,\n\t&sysfs_io_error_halflife,\n\t&sysfs_congested,\n\t&sysfs_congested_read_threshold_us,\n\t&sysfs_congested_write_threshold_us,\n\t&sysfs_clear_stats,\n\tNULL\n};\nATTRIBUTE_GROUPS(bch_cache_set);\nKTYPE(bch_cache_set);\n\nstatic struct attribute *bch_cache_set_internal_attrs[] = {\n\t&sysfs_active_journal_entries,\n\n\tsysfs_time_stats_attribute_list(btree_gc, sec, ms)\n\tsysfs_time_stats_attribute_list(btree_split, sec, us)\n\tsysfs_time_stats_attribute_list(btree_sort, ms, us)\n\tsysfs_time_stats_attribute_list(btree_read, ms, us)\n\n\t&sysfs_btree_nodes,\n\t&sysfs_btree_used_percent,\n\t&sysfs_btree_cache_max_chain,\n\n\t&sysfs_bset_tree_stats,\n\t&sysfs_cache_read_races,\n\t&sysfs_reclaim,\n\t&sysfs_reclaimed_journal_buckets,\n\t&sysfs_flush_write,\n\t&sysfs_writeback_keys_done,\n\t&sysfs_writeback_keys_failed,\n\n\t&sysfs_trigger_gc,\n\t&sysfs_prune_cache,\n#ifdef CONFIG_BCACHE_DEBUG\n\t&sysfs_verify,\n\t&sysfs_key_merging_disabled,\n\t&sysfs_expensive_debug_checks,\n#endif\n\t&sysfs_gc_always_rewrite,\n\t&sysfs_btree_shrinker_disabled,\n\t&sysfs_copy_gc_enabled,\n\t&sysfs_idle_max_writeback_rate,\n\t&sysfs_gc_after_writeback,\n\t&sysfs_io_disable,\n\t&sysfs_cutoff_writeback,\n\t&sysfs_cutoff_writeback_sync,\n\t&sysfs_feature_compat,\n\t&sysfs_feature_ro_compat,\n\t&sysfs_feature_incompat,\n\tNULL\n};\nATTRIBUTE_GROUPS(bch_cache_set_internal);\nKTYPE(bch_cache_set_internal);\n\nstatic int __bch_cache_cmp(const void *l, const void *r)\n{\n\tcond_resched();\n\treturn *((uint16_t *)r) - *((uint16_t *)l);\n}\n\nSHOW(__bch_cache)\n{\n\tstruct cache *ca = container_of(kobj, struct cache, kobj);\n\n\tsysfs_hprint(bucket_size,\tbucket_bytes(ca));\n\tsysfs_hprint(block_size,\tblock_bytes(ca));\n\tsysfs_print(nbuckets,\t\tca->sb.nbuckets);\n\tsysfs_print(discard,\t\tca->discard);\n\tsysfs_hprint(written, atomic_long_read(&ca->sectors_written) << 9);\n\tsysfs_hprint(btree_written,\n\t\t     atomic_long_read(&ca->btree_sectors_written) << 9);\n\tsysfs_hprint(metadata_written,\n\t\t     (atomic_long_read(&ca->meta_sectors_written) +\n\t\t      atomic_long_read(&ca->btree_sectors_written)) << 9);\n\n\tsysfs_print(io_errors,\n\t\t    atomic_read(&ca->io_errors) >> IO_ERROR_SHIFT);\n\n\tif (attr == &sysfs_cache_replacement_policy)\n\t\treturn bch_snprint_string_list(buf, PAGE_SIZE,\n\t\t\t\t\t       cache_replacement_policies,\n\t\t\t\t\t       CACHE_REPLACEMENT(&ca->sb));\n\n\tif (attr == &sysfs_priority_stats) {\n\t\tstruct bucket *b;\n\t\tsize_t n = ca->sb.nbuckets, i;\n\t\tsize_t unused = 0, available = 0, dirty = 0, meta = 0;\n\t\tuint64_t sum = 0;\n\t\t \n\t\tuint16_t q[31], *p, *cached;\n\t\tssize_t ret;\n\n\t\tcached = p = vmalloc(array_size(sizeof(uint16_t),\n\t\t\t\t\t\tca->sb.nbuckets));\n\t\tif (!p)\n\t\t\treturn -ENOMEM;\n\n\t\tmutex_lock(&ca->set->bucket_lock);\n\t\tfor_each_bucket(b, ca) {\n\t\t\tif (!GC_SECTORS_USED(b))\n\t\t\t\tunused++;\n\t\t\tif (GC_MARK(b) == GC_MARK_RECLAIMABLE)\n\t\t\t\tavailable++;\n\t\t\tif (GC_MARK(b) == GC_MARK_DIRTY)\n\t\t\t\tdirty++;\n\t\t\tif (GC_MARK(b) == GC_MARK_METADATA)\n\t\t\t\tmeta++;\n\t\t}\n\n\t\tfor (i = ca->sb.first_bucket; i < n; i++)\n\t\t\tp[i] = ca->buckets[i].prio;\n\t\tmutex_unlock(&ca->set->bucket_lock);\n\n\t\tsort(p, n, sizeof(uint16_t), __bch_cache_cmp, NULL);\n\n\t\twhile (n &&\n\t\t       !cached[n - 1])\n\t\t\t--n;\n\n\t\twhile (cached < p + n &&\n\t\t       *cached == BTREE_PRIO) {\n\t\t\tcached++;\n\t\t\tn--;\n\t\t}\n\n\t\tfor (i = 0; i < n; i++)\n\t\t\tsum += INITIAL_PRIO - cached[i];\n\n\t\tif (n)\n\t\t\tsum = div64_u64(sum, n);\n\n\t\tfor (i = 0; i < ARRAY_SIZE(q); i++)\n\t\t\tq[i] = INITIAL_PRIO - cached[n * (i + 1) /\n\t\t\t\t(ARRAY_SIZE(q) + 1)];\n\n\t\tvfree(p);\n\n\t\tret = sysfs_emit(buf,\n\t\t\t\t \"Unused:\t\t%zu%%\\n\"\n\t\t\t\t \"Clean:\t\t%zu%%\\n\"\n\t\t\t\t \"Dirty:\t\t%zu%%\\n\"\n\t\t\t\t \"Metadata:\t%zu%%\\n\"\n\t\t\t\t \"Average:\t%llu\\n\"\n\t\t\t\t \"Sectors per Q:\t%zu\\n\"\n\t\t\t\t \"Quantiles:\t[\",\n\t\t\t\t unused * 100 / (size_t) ca->sb.nbuckets,\n\t\t\t\t available * 100 / (size_t) ca->sb.nbuckets,\n\t\t\t\t dirty * 100 / (size_t) ca->sb.nbuckets,\n\t\t\t\t meta * 100 / (size_t) ca->sb.nbuckets, sum,\n\t\t\t\t n * ca->sb.bucket_size / (ARRAY_SIZE(q) + 1));\n\n\t\tfor (i = 0; i < ARRAY_SIZE(q); i++)\n\t\t\tret += sysfs_emit_at(buf, ret, \"%u \", q[i]);\n\t\tret--;\n\n\t\tret += sysfs_emit_at(buf, ret, \"]\\n\");\n\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nSHOW_LOCKED(bch_cache)\n\nSTORE(__bch_cache)\n{\n\tstruct cache *ca = container_of(kobj, struct cache, kobj);\n\tssize_t v;\n\n\t \n\tif (bcache_is_reboot)\n\t\treturn -EBUSY;\n\n\tif (attr == &sysfs_discard) {\n\t\tbool v = strtoul_or_return(buf);\n\n\t\tif (bdev_max_discard_sectors(ca->bdev))\n\t\t\tca->discard = v;\n\n\t\tif (v != CACHE_DISCARD(&ca->sb)) {\n\t\t\tSET_CACHE_DISCARD(&ca->sb, v);\n\t\t\tbcache_write_super(ca->set);\n\t\t}\n\t}\n\n\tif (attr == &sysfs_cache_replacement_policy) {\n\t\tv = __sysfs_match_string(cache_replacement_policies, -1, buf);\n\t\tif (v < 0)\n\t\t\treturn v;\n\n\t\tif ((unsigned int) v != CACHE_REPLACEMENT(&ca->sb)) {\n\t\t\tmutex_lock(&ca->set->bucket_lock);\n\t\t\tSET_CACHE_REPLACEMENT(&ca->sb, v);\n\t\t\tmutex_unlock(&ca->set->bucket_lock);\n\n\t\t\tbcache_write_super(ca->set);\n\t\t}\n\t}\n\n\tif (attr == &sysfs_clear_stats) {\n\t\tatomic_long_set(&ca->sectors_written, 0);\n\t\tatomic_long_set(&ca->btree_sectors_written, 0);\n\t\tatomic_long_set(&ca->meta_sectors_written, 0);\n\t\tatomic_set(&ca->io_count, 0);\n\t\tatomic_set(&ca->io_errors, 0);\n\t}\n\n\treturn size;\n}\nSTORE_LOCKED(bch_cache)\n\nstatic struct attribute *bch_cache_attrs[] = {\n\t&sysfs_bucket_size,\n\t&sysfs_block_size,\n\t&sysfs_nbuckets,\n\t&sysfs_priority_stats,\n\t&sysfs_discard,\n\t&sysfs_written,\n\t&sysfs_btree_written,\n\t&sysfs_metadata_written,\n\t&sysfs_io_errors,\n\t&sysfs_clear_stats,\n\t&sysfs_cache_replacement_policy,\n\tNULL\n};\nATTRIBUTE_GROUPS(bch_cache);\nKTYPE(bch_cache);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}