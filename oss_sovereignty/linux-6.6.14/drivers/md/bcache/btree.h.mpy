{
  "module_name": "btree.h",
  "hash_id": "50d17c7f827dc448fdf2b9aad439bffb1d3440bb9403217e778625796ee2fb2f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/md/bcache/btree.h",
  "human_readable_source": " \n#ifndef _BCACHE_BTREE_H\n#define _BCACHE_BTREE_H\n\n \n\n#include \"bset.h\"\n#include \"debug.h\"\n\nstruct btree_write {\n\tatomic_t\t\t*journal;\n\n\t \n\tint\t\t\tprio_blocked;\n};\n\nstruct btree {\n\t \n\tstruct hlist_node\thash;\n\n\t \n\tBKEY_PADDED(key);\n\n\tunsigned long\t\tseq;\n\tstruct rw_semaphore\tlock;\n\tstruct cache_set\t*c;\n\tstruct btree\t\t*parent;\n\n\tstruct mutex\t\twrite_lock;\n\n\tunsigned long\t\tflags;\n\tuint16_t\t\twritten;\t \n\tuint8_t\t\t\tlevel;\n\n\tstruct btree_keys\tkeys;\n\n\t \n\tstruct closure\t\tio;\n\tstruct semaphore\tio_mutex;\n\n\tstruct list_head\tlist;\n\tstruct delayed_work\twork;\n\n\tstruct btree_write\twrites[2];\n\tstruct bio\t\t*bio;\n};\n\n\n\n\n#define BTREE_FLAG(flag)\t\t\t\t\t\t\\\nstatic inline bool btree_node_ ## flag(struct btree *b)\t\t\t\\\n{\treturn test_bit(BTREE_NODE_ ## flag, &b->flags); }\t\t\\\n\t\t\t\t\t\t\t\t\t\\\nstatic inline void set_btree_node_ ## flag(struct btree *b)\t\t\\\n{\tset_bit(BTREE_NODE_ ## flag, &b->flags); }\n\nenum btree_flags {\n\tBTREE_NODE_io_error,\n\tBTREE_NODE_dirty,\n\tBTREE_NODE_write_idx,\n\tBTREE_NODE_journal_flush,\n};\n\nBTREE_FLAG(io_error);\nBTREE_FLAG(dirty);\nBTREE_FLAG(write_idx);\nBTREE_FLAG(journal_flush);\n\nstatic inline struct btree_write *btree_current_write(struct btree *b)\n{\n\treturn b->writes + btree_node_write_idx(b);\n}\n\nstatic inline struct btree_write *btree_prev_write(struct btree *b)\n{\n\treturn b->writes + (btree_node_write_idx(b) ^ 1);\n}\n\nstatic inline struct bset *btree_bset_first(struct btree *b)\n{\n\treturn b->keys.set->data;\n}\n\nstatic inline struct bset *btree_bset_last(struct btree *b)\n{\n\treturn bset_tree_last(&b->keys)->data;\n}\n\nstatic inline unsigned int bset_block_offset(struct btree *b, struct bset *i)\n{\n\treturn bset_sector_offset(&b->keys, i) >> b->c->block_bits;\n}\n\nstatic inline void set_gc_sectors(struct cache_set *c)\n{\n\tatomic_set(&c->sectors_to_gc, c->cache->sb.bucket_size * c->nbuckets / 16);\n}\n\nvoid bkey_put(struct cache_set *c, struct bkey *k);\n\n \n\n#define for_each_cached_btree(b, c, iter)\t\t\t\t\\\n\tfor (iter = 0;\t\t\t\t\t\t\t\\\n\t     iter < ARRAY_SIZE((c)->bucket_hash);\t\t\t\\\n\t     iter++)\t\t\t\t\t\t\t\\\n\t\thlist_for_each_entry_rcu((b), (c)->bucket_hash + iter, hash)\n\n \n\nstruct btree_op {\n\t \n\twait_queue_entry_t\t\twait;\n\n\t \n\tshort\t\t\tlock;\n\n\tunsigned int\t\tinsert_collision:1;\n};\n\nstruct btree_check_state;\nstruct btree_check_info {\n\tstruct btree_check_state\t*state;\n\tstruct task_struct\t\t*thread;\n\tint\t\t\t\tresult;\n};\n\n#define BCH_BTR_CHKTHREAD_MAX\t12\nstruct btree_check_state {\n\tstruct cache_set\t\t*c;\n\tint\t\t\t\ttotal_threads;\n\tint\t\t\t\tkey_idx;\n\tspinlock_t\t\t\tidx_lock;\n\tatomic_t\t\t\tstarted;\n\tatomic_t\t\t\tenough;\n\twait_queue_head_t\t\twait;\n\tstruct btree_check_info\t\tinfos[BCH_BTR_CHKTHREAD_MAX];\n};\n\nstatic inline void bch_btree_op_init(struct btree_op *op, int write_lock_level)\n{\n\tmemset(op, 0, sizeof(struct btree_op));\n\tinit_wait(&op->wait);\n\top->lock = write_lock_level;\n}\n\nstatic inline void rw_lock(bool w, struct btree *b, int level)\n{\n\tw ? down_write(&b->lock)\n\t  : down_read(&b->lock);\n\tif (w)\n\t\tb->seq++;\n}\n\nstatic inline void rw_unlock(bool w, struct btree *b)\n{\n\tif (w)\n\t\tb->seq++;\n\t(w ? up_write : up_read)(&b->lock);\n}\n\nvoid bch_btree_node_read_done(struct btree *b);\nvoid __bch_btree_node_write(struct btree *b, struct closure *parent);\nvoid bch_btree_node_write(struct btree *b, struct closure *parent);\n\nvoid bch_btree_set_root(struct btree *b);\nstruct btree *__bch_btree_node_alloc(struct cache_set *c, struct btree_op *op,\n\t\t\t\t     int level, bool wait,\n\t\t\t\t     struct btree *parent);\nstruct btree *bch_btree_node_get(struct cache_set *c, struct btree_op *op,\n\t\t\t\t struct bkey *k, int level, bool write,\n\t\t\t\t struct btree *parent);\n\nint bch_btree_insert_check_key(struct btree *b, struct btree_op *op,\n\t\t\t       struct bkey *check_key);\nint bch_btree_insert(struct cache_set *c, struct keylist *keys,\n\t\t     atomic_t *journal_ref, struct bkey *replace_key);\n\nint bch_gc_thread_start(struct cache_set *c);\nvoid bch_initial_gc_finish(struct cache_set *c);\nvoid bch_moving_gc(struct cache_set *c);\nint bch_btree_check(struct cache_set *c);\nvoid bch_initial_mark_key(struct cache_set *c, int level, struct bkey *k);\nvoid bch_cannibalize_unlock(struct cache_set *c);\n\nstatic inline void wake_up_gc(struct cache_set *c)\n{\n\twake_up(&c->gc_wait);\n}\n\nstatic inline void force_wake_up_gc(struct cache_set *c)\n{\n\t \n\tatomic_set(&c->sectors_to_gc, -1);\n\twake_up_gc(c);\n}\n\n \n\n \n#define bcache_btree(fn, key, b, op, ...)\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tint _r, l = (b)->level - 1;\t\t\t\t\t\\\n\tbool _w = l <= (op)->lock;\t\t\t\t\t\\\n\tstruct btree *_child = bch_btree_node_get((b)->c, op, key, l,\t\\\n\t\t\t\t\t\t  _w, b);\t\t\\\n\tif (!IS_ERR(_child)) {\t\t\t\t\t\t\\\n\t\t_r = bch_btree_ ## fn(_child, op, ##__VA_ARGS__);\t\\\n\t\trw_unlock(_w, _child);\t\t\t\t\t\\\n\t} else\t\t\t\t\t\t\t\t\\\n\t\t_r = PTR_ERR(_child);\t\t\t\t\t\\\n\t_r;\t\t\t\t\t\t\t\t\\\n})\n\n \n#define bcache_btree_root(fn, c, op, ...)\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tint _r = -EINTR;\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tstruct btree *_b = (c)->root;\t\t\t\t\\\n\t\tbool _w = insert_lock(op, _b);\t\t\t\t\\\n\t\trw_lock(_w, _b, _b->level);\t\t\t\t\\\n\t\tif (_b == (c)->root &&\t\t\t\t\t\\\n\t\t    _w == insert_lock(op, _b)) {\t\t\t\\\n\t\t\t_r = bch_btree_ ## fn(_b, op, ##__VA_ARGS__);\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t\trw_unlock(_w, _b);\t\t\t\t\t\\\n\t\tbch_cannibalize_unlock(c);                              \\\n\t\tif (_r == -EINTR)                                       \\\n\t\t\tschedule();                                     \\\n\t} while (_r == -EINTR);                                         \\\n\t\t\t\t\t\t\t\t\t\\\n\tfinish_wait(&(c)->btree_cache_wait, &(op)->wait);               \\\n\t_r;                                                             \\\n})\n\n#define MAP_DONE\t0\n#define MAP_CONTINUE\t1\n\n#define MAP_ALL_NODES\t0\n#define MAP_LEAF_NODES\t1\n\n#define MAP_END_KEY\t1\n\ntypedef int (btree_map_nodes_fn)(struct btree_op *b_op, struct btree *b);\nint __bch_btree_map_nodes(struct btree_op *op, struct cache_set *c,\n\t\t\t  struct bkey *from, btree_map_nodes_fn *fn, int flags);\n\nstatic inline int bch_btree_map_nodes(struct btree_op *op, struct cache_set *c,\n\t\t\t\t      struct bkey *from, btree_map_nodes_fn *fn)\n{\n\treturn __bch_btree_map_nodes(op, c, from, fn, MAP_ALL_NODES);\n}\n\nstatic inline int bch_btree_map_leaf_nodes(struct btree_op *op,\n\t\t\t\t\t   struct cache_set *c,\n\t\t\t\t\t   struct bkey *from,\n\t\t\t\t\t   btree_map_nodes_fn *fn)\n{\n\treturn __bch_btree_map_nodes(op, c, from, fn, MAP_LEAF_NODES);\n}\n\ntypedef int (btree_map_keys_fn)(struct btree_op *op, struct btree *b,\n\t\t\t\tstruct bkey *k);\nint bch_btree_map_keys(struct btree_op *op, struct cache_set *c,\n\t\t       struct bkey *from, btree_map_keys_fn *fn, int flags);\nint bch_btree_map_keys_recurse(struct btree *b, struct btree_op *op,\n\t\t\t       struct bkey *from, btree_map_keys_fn *fn,\n\t\t\t       int flags);\n\ntypedef bool (keybuf_pred_fn)(struct keybuf *buf, struct bkey *k);\n\nvoid bch_keybuf_init(struct keybuf *buf);\nvoid bch_refill_keybuf(struct cache_set *c, struct keybuf *buf,\n\t\t       struct bkey *end, keybuf_pred_fn *pred);\nbool bch_keybuf_check_overlapping(struct keybuf *buf, struct bkey *start,\n\t\t\t\t  struct bkey *end);\nvoid bch_keybuf_del(struct keybuf *buf, struct keybuf_key *w);\nstruct keybuf_key *bch_keybuf_next(struct keybuf *buf);\nstruct keybuf_key *bch_keybuf_next_rescan(struct cache_set *c,\n\t\t\t\t\t  struct keybuf *buf,\n\t\t\t\t\t  struct bkey *end,\n\t\t\t\t\t  keybuf_pred_fn *pred);\nvoid bch_update_bucket_in_use(struct cache_set *c, struct gc_stat *stats);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}