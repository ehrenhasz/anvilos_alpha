{
  "module_name": "dm-btree.c",
  "hash_id": "c3554ba2929bf6f5140d547375922cdee0386b1faec1c49b6030f96a7714359d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/md/persistent-data/dm-btree.c",
  "human_readable_source": "\n \n\n#include \"dm-btree-internal.h\"\n#include \"dm-space-map.h\"\n#include \"dm-transaction-manager.h\"\n\n#include <linux/export.h>\n#include <linux/device-mapper.h>\n\n#define DM_MSG_PREFIX \"btree\"\n\n \nstatic void memcpy_disk(void *dest, const void *src, size_t len)\n\t__dm_written_to_disk(src)\n{\n\tmemcpy(dest, src, len);\n\t__dm_unbless_for_disk(src);\n}\n\nstatic void array_insert(void *base, size_t elt_size, unsigned int nr_elts,\n\t\t\t unsigned int index, void *elt)\n\t__dm_written_to_disk(elt)\n{\n\tif (index < nr_elts)\n\t\tmemmove(base + (elt_size * (index + 1)),\n\t\t\tbase + (elt_size * index),\n\t\t\t(nr_elts - index) * elt_size);\n\n\tmemcpy_disk(base + (elt_size * index), elt, elt_size);\n}\n\n \n\n \nstatic int bsearch(struct btree_node *n, uint64_t key, int want_hi)\n{\n\tint lo = -1, hi = le32_to_cpu(n->header.nr_entries);\n\n\twhile (hi - lo > 1) {\n\t\tint mid = lo + ((hi - lo) / 2);\n\t\tuint64_t mid_key = le64_to_cpu(n->keys[mid]);\n\n\t\tif (mid_key == key)\n\t\t\treturn mid;\n\n\t\tif (mid_key < key)\n\t\t\tlo = mid;\n\t\telse\n\t\t\thi = mid;\n\t}\n\n\treturn want_hi ? hi : lo;\n}\n\nint lower_bound(struct btree_node *n, uint64_t key)\n{\n\treturn bsearch(n, key, 0);\n}\n\nstatic int upper_bound(struct btree_node *n, uint64_t key)\n{\n\treturn bsearch(n, key, 1);\n}\n\nvoid inc_children(struct dm_transaction_manager *tm, struct btree_node *n,\n\t\t  struct dm_btree_value_type *vt)\n{\n\tuint32_t nr_entries = le32_to_cpu(n->header.nr_entries);\n\n\tif (le32_to_cpu(n->header.flags) & INTERNAL_NODE)\n\t\tdm_tm_with_runs(tm, value_ptr(n, 0), nr_entries, dm_tm_inc_range);\n\n\telse if (vt->inc)\n\t\tvt->inc(vt->context, value_ptr(n, 0), nr_entries);\n}\n\nstatic int insert_at(size_t value_size, struct btree_node *node, unsigned int index,\n\t\t     uint64_t key, void *value)\n\t__dm_written_to_disk(value)\n{\n\tuint32_t nr_entries = le32_to_cpu(node->header.nr_entries);\n\tuint32_t max_entries = le32_to_cpu(node->header.max_entries);\n\t__le64 key_le = cpu_to_le64(key);\n\n\tif (index > nr_entries ||\n\t    index >= max_entries ||\n\t    nr_entries >= max_entries) {\n\t\tDMERR(\"too many entries in btree node for insert\");\n\t\t__dm_unbless_for_disk(value);\n\t\treturn -ENOMEM;\n\t}\n\n\t__dm_bless_for_disk(&key_le);\n\n\tarray_insert(node->keys, sizeof(*node->keys), nr_entries, index, &key_le);\n\tarray_insert(value_base(node), value_size, nr_entries, index, value);\n\tnode->header.nr_entries = cpu_to_le32(nr_entries + 1);\n\n\treturn 0;\n}\n\n \n\n \nstatic uint32_t calc_max_entries(size_t value_size, size_t block_size)\n{\n\tuint32_t total, n;\n\tsize_t elt_size = sizeof(uint64_t) + value_size;  \n\n\tblock_size -= sizeof(struct node_header);\n\ttotal = block_size / elt_size;\n\tn = total / 3;\t\t \n\n\treturn 3 * n;\n}\n\nint dm_btree_empty(struct dm_btree_info *info, dm_block_t *root)\n{\n\tint r;\n\tstruct dm_block *b;\n\tstruct btree_node *n;\n\tsize_t block_size;\n\tuint32_t max_entries;\n\n\tr = new_block(info, &b);\n\tif (r < 0)\n\t\treturn r;\n\n\tblock_size = dm_bm_block_size(dm_tm_get_bm(info->tm));\n\tmax_entries = calc_max_entries(info->value_type.size, block_size);\n\n\tn = dm_block_data(b);\n\tmemset(n, 0, block_size);\n\tn->header.flags = cpu_to_le32(LEAF_NODE);\n\tn->header.nr_entries = cpu_to_le32(0);\n\tn->header.max_entries = cpu_to_le32(max_entries);\n\tn->header.value_size = cpu_to_le32(info->value_type.size);\n\n\t*root = dm_block_location(b);\n\tunlock_block(info, b);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(dm_btree_empty);\n\n \n\n \n#define MAX_SPINE_DEPTH 64\nstruct frame {\n\tstruct dm_block *b;\n\tstruct btree_node *n;\n\tunsigned int level;\n\tunsigned int nr_children;\n\tunsigned int current_child;\n};\n\nstruct del_stack {\n\tstruct dm_btree_info *info;\n\tstruct dm_transaction_manager *tm;\n\tint top;\n\tstruct frame spine[MAX_SPINE_DEPTH];\n};\n\nstatic int top_frame(struct del_stack *s, struct frame **f)\n{\n\tif (s->top < 0) {\n\t\tDMERR(\"btree deletion stack empty\");\n\t\treturn -EINVAL;\n\t}\n\n\t*f = s->spine + s->top;\n\n\treturn 0;\n}\n\nstatic int unprocessed_frames(struct del_stack *s)\n{\n\treturn s->top >= 0;\n}\n\nstatic void prefetch_children(struct del_stack *s, struct frame *f)\n{\n\tunsigned int i;\n\tstruct dm_block_manager *bm = dm_tm_get_bm(s->tm);\n\n\tfor (i = 0; i < f->nr_children; i++)\n\t\tdm_bm_prefetch(bm, value64(f->n, i));\n}\n\nstatic bool is_internal_level(struct dm_btree_info *info, struct frame *f)\n{\n\treturn f->level < (info->levels - 1);\n}\n\nstatic int push_frame(struct del_stack *s, dm_block_t b, unsigned int level)\n{\n\tint r;\n\tuint32_t ref_count;\n\n\tif (s->top >= MAX_SPINE_DEPTH - 1) {\n\t\tDMERR(\"btree deletion stack out of memory\");\n\t\treturn -ENOMEM;\n\t}\n\n\tr = dm_tm_ref(s->tm, b, &ref_count);\n\tif (r)\n\t\treturn r;\n\n\tif (ref_count > 1)\n\t\t \n\t\tdm_tm_dec(s->tm, b);\n\n\telse {\n\t\tuint32_t flags;\n\t\tstruct frame *f = s->spine + ++s->top;\n\n\t\tr = dm_tm_read_lock(s->tm, b, &btree_node_validator, &f->b);\n\t\tif (r) {\n\t\t\ts->top--;\n\t\t\treturn r;\n\t\t}\n\n\t\tf->n = dm_block_data(f->b);\n\t\tf->level = level;\n\t\tf->nr_children = le32_to_cpu(f->n->header.nr_entries);\n\t\tf->current_child = 0;\n\n\t\tflags = le32_to_cpu(f->n->header.flags);\n\t\tif (flags & INTERNAL_NODE || is_internal_level(s->info, f))\n\t\t\tprefetch_children(s, f);\n\t}\n\n\treturn 0;\n}\n\nstatic void pop_frame(struct del_stack *s)\n{\n\tstruct frame *f = s->spine + s->top--;\n\n\tdm_tm_dec(s->tm, dm_block_location(f->b));\n\tdm_tm_unlock(s->tm, f->b);\n}\n\nstatic void unlock_all_frames(struct del_stack *s)\n{\n\tstruct frame *f;\n\n\twhile (unprocessed_frames(s)) {\n\t\tf = s->spine + s->top--;\n\t\tdm_tm_unlock(s->tm, f->b);\n\t}\n}\n\nint dm_btree_del(struct dm_btree_info *info, dm_block_t root)\n{\n\tint r;\n\tstruct del_stack *s;\n\n\t \n\ts = kmalloc(sizeof(*s), GFP_NOFS);\n\tif (!s)\n\t\treturn -ENOMEM;\n\ts->info = info;\n\ts->tm = info->tm;\n\ts->top = -1;\n\n\tr = push_frame(s, root, 0);\n\tif (r)\n\t\tgoto out;\n\n\twhile (unprocessed_frames(s)) {\n\t\tuint32_t flags;\n\t\tstruct frame *f;\n\t\tdm_block_t b;\n\n\t\tr = top_frame(s, &f);\n\t\tif (r)\n\t\t\tgoto out;\n\n\t\tif (f->current_child >= f->nr_children) {\n\t\t\tpop_frame(s);\n\t\t\tcontinue;\n\t\t}\n\n\t\tflags = le32_to_cpu(f->n->header.flags);\n\t\tif (flags & INTERNAL_NODE) {\n\t\t\tb = value64(f->n, f->current_child);\n\t\t\tf->current_child++;\n\t\t\tr = push_frame(s, b, f->level);\n\t\t\tif (r)\n\t\t\t\tgoto out;\n\n\t\t} else if (is_internal_level(info, f)) {\n\t\t\tb = value64(f->n, f->current_child);\n\t\t\tf->current_child++;\n\t\t\tr = push_frame(s, b, f->level + 1);\n\t\t\tif (r)\n\t\t\t\tgoto out;\n\n\t\t} else {\n\t\t\tif (info->value_type.dec)\n\t\t\t\tinfo->value_type.dec(info->value_type.context,\n\t\t\t\t\t\t     value_ptr(f->n, 0), f->nr_children);\n\t\t\tpop_frame(s);\n\t\t}\n\t}\nout:\n\tif (r) {\n\t\t \n\t\tunlock_all_frames(s);\n\t}\n\tkfree(s);\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(dm_btree_del);\n\n \n\nstatic int btree_lookup_raw(struct ro_spine *s, dm_block_t block, uint64_t key,\n\t\t\t    int (*search_fn)(struct btree_node *, uint64_t),\n\t\t\t    uint64_t *result_key, void *v, size_t value_size)\n{\n\tint i, r;\n\tuint32_t flags, nr_entries;\n\n\tdo {\n\t\tr = ro_step(s, block);\n\t\tif (r < 0)\n\t\t\treturn r;\n\n\t\ti = search_fn(ro_node(s), key);\n\n\t\tflags = le32_to_cpu(ro_node(s)->header.flags);\n\t\tnr_entries = le32_to_cpu(ro_node(s)->header.nr_entries);\n\t\tif (i < 0 || i >= nr_entries)\n\t\t\treturn -ENODATA;\n\n\t\tif (flags & INTERNAL_NODE)\n\t\t\tblock = value64(ro_node(s), i);\n\n\t} while (!(flags & LEAF_NODE));\n\n\t*result_key = le64_to_cpu(ro_node(s)->keys[i]);\n\tif (v)\n\t\tmemcpy(v, value_ptr(ro_node(s), i), value_size);\n\n\treturn 0;\n}\n\nint dm_btree_lookup(struct dm_btree_info *info, dm_block_t root,\n\t\t    uint64_t *keys, void *value_le)\n{\n\tunsigned int level, last_level = info->levels - 1;\n\tint r = -ENODATA;\n\tuint64_t rkey;\n\t__le64 internal_value_le;\n\tstruct ro_spine spine;\n\n\tinit_ro_spine(&spine, info);\n\tfor (level = 0; level < info->levels; level++) {\n\t\tsize_t size;\n\t\tvoid *value_p;\n\n\t\tif (level == last_level) {\n\t\t\tvalue_p = value_le;\n\t\t\tsize = info->value_type.size;\n\n\t\t} else {\n\t\t\tvalue_p = &internal_value_le;\n\t\t\tsize = sizeof(uint64_t);\n\t\t}\n\n\t\tr = btree_lookup_raw(&spine, root, keys[level],\n\t\t\t\t     lower_bound, &rkey,\n\t\t\t\t     value_p, size);\n\n\t\tif (!r) {\n\t\t\tif (rkey != keys[level]) {\n\t\t\t\texit_ro_spine(&spine);\n\t\t\t\treturn -ENODATA;\n\t\t\t}\n\t\t} else {\n\t\t\texit_ro_spine(&spine);\n\t\t\treturn r;\n\t\t}\n\n\t\troot = le64_to_cpu(internal_value_le);\n\t}\n\texit_ro_spine(&spine);\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(dm_btree_lookup);\n\nstatic int dm_btree_lookup_next_single(struct dm_btree_info *info, dm_block_t root,\n\t\t\t\t       uint64_t key, uint64_t *rkey, void *value_le)\n{\n\tint r, i;\n\tuint32_t flags, nr_entries;\n\tstruct dm_block *node;\n\tstruct btree_node *n;\n\n\tr = bn_read_lock(info, root, &node);\n\tif (r)\n\t\treturn r;\n\n\tn = dm_block_data(node);\n\tflags = le32_to_cpu(n->header.flags);\n\tnr_entries = le32_to_cpu(n->header.nr_entries);\n\n\tif (flags & INTERNAL_NODE) {\n\t\ti = lower_bound(n, key);\n\t\tif (i < 0) {\n\t\t\t \n\t\t\ti = 0;\n\t\t}\n\t\tif (i >= nr_entries) {\n\t\t\tr = -ENODATA;\n\t\t\tgoto out;\n\t\t}\n\n\t\tr = dm_btree_lookup_next_single(info, value64(n, i), key, rkey, value_le);\n\t\tif (r == -ENODATA && i < (nr_entries - 1)) {\n\t\t\ti++;\n\t\t\tr = dm_btree_lookup_next_single(info, value64(n, i), key, rkey, value_le);\n\t\t}\n\n\t} else {\n\t\ti = upper_bound(n, key);\n\t\tif (i < 0 || i >= nr_entries) {\n\t\t\tr = -ENODATA;\n\t\t\tgoto out;\n\t\t}\n\n\t\t*rkey = le64_to_cpu(n->keys[i]);\n\t\tmemcpy(value_le, value_ptr(n, i), info->value_type.size);\n\t}\nout:\n\tdm_tm_unlock(info->tm, node);\n\treturn r;\n}\n\nint dm_btree_lookup_next(struct dm_btree_info *info, dm_block_t root,\n\t\t\t uint64_t *keys, uint64_t *rkey, void *value_le)\n{\n\tunsigned int level;\n\tint r = -ENODATA;\n\t__le64 internal_value_le;\n\tstruct ro_spine spine;\n\n\tinit_ro_spine(&spine, info);\n\tfor (level = 0; level < info->levels - 1u; level++) {\n\t\tr = btree_lookup_raw(&spine, root, keys[level],\n\t\t\t\t     lower_bound, rkey,\n\t\t\t\t     &internal_value_le, sizeof(uint64_t));\n\t\tif (r)\n\t\t\tgoto out;\n\n\t\tif (*rkey != keys[level]) {\n\t\t\tr = -ENODATA;\n\t\t\tgoto out;\n\t\t}\n\n\t\troot = le64_to_cpu(internal_value_le);\n\t}\n\n\tr = dm_btree_lookup_next_single(info, root, keys[level], rkey, value_le);\nout:\n\texit_ro_spine(&spine);\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(dm_btree_lookup_next);\n\n \n\n \nstatic void copy_entries(struct btree_node *dest, unsigned int dest_offset,\n\t\t\t struct btree_node *src, unsigned int src_offset,\n\t\t\t unsigned int count)\n{\n\tsize_t value_size = le32_to_cpu(dest->header.value_size);\n\n\tmemcpy(dest->keys + dest_offset, src->keys + src_offset, count * sizeof(uint64_t));\n\tmemcpy(value_ptr(dest, dest_offset), value_ptr(src, src_offset), count * value_size);\n}\n\n \nstatic void move_entries(struct btree_node *dest, unsigned int dest_offset,\n\t\t\t struct btree_node *src, unsigned int src_offset,\n\t\t\t unsigned int count)\n{\n\tsize_t value_size = le32_to_cpu(dest->header.value_size);\n\n\tmemmove(dest->keys + dest_offset, src->keys + src_offset, count * sizeof(uint64_t));\n\tmemmove(value_ptr(dest, dest_offset), value_ptr(src, src_offset), count * value_size);\n}\n\n \nstatic void shift_down(struct btree_node *n, unsigned int count)\n{\n\tmove_entries(n, 0, n, count, le32_to_cpu(n->header.nr_entries) - count);\n}\n\n \nstatic void shift_up(struct btree_node *n, unsigned int count)\n{\n\tmove_entries(n, count, n, 0, le32_to_cpu(n->header.nr_entries));\n}\n\n \nstatic void redistribute2(struct btree_node *left, struct btree_node *right)\n{\n\tunsigned int nr_left = le32_to_cpu(left->header.nr_entries);\n\tunsigned int nr_right = le32_to_cpu(right->header.nr_entries);\n\tunsigned int total = nr_left + nr_right;\n\tunsigned int target_left = total / 2;\n\tunsigned int target_right = total - target_left;\n\n\tif (nr_left < target_left) {\n\t\tunsigned int delta = target_left - nr_left;\n\n\t\tcopy_entries(left, nr_left, right, 0, delta);\n\t\tshift_down(right, delta);\n\t} else if (nr_left > target_left) {\n\t\tunsigned int delta = nr_left - target_left;\n\n\t\tif (nr_right)\n\t\t\tshift_up(right, delta);\n\t\tcopy_entries(right, 0, left, target_left, delta);\n\t}\n\n\tleft->header.nr_entries = cpu_to_le32(target_left);\n\tright->header.nr_entries = cpu_to_le32(target_right);\n}\n\n \nstatic void redistribute3(struct btree_node *left, struct btree_node *center,\n\t\t\t  struct btree_node *right)\n{\n\tunsigned int nr_left = le32_to_cpu(left->header.nr_entries);\n\tunsigned int nr_center = le32_to_cpu(center->header.nr_entries);\n\tunsigned int nr_right = le32_to_cpu(right->header.nr_entries);\n\tunsigned int total, target_left, target_center, target_right;\n\n\tBUG_ON(nr_center);\n\n\ttotal = nr_left + nr_right;\n\ttarget_left = total / 3;\n\ttarget_center = (total - target_left) / 2;\n\ttarget_right = (total - target_left - target_center);\n\n\tif (nr_left < target_left) {\n\t\tunsigned int left_short = target_left - nr_left;\n\n\t\tcopy_entries(left, nr_left, right, 0, left_short);\n\t\tcopy_entries(center, 0, right, left_short, target_center);\n\t\tshift_down(right, nr_right - target_right);\n\n\t} else if (nr_left < (target_left + target_center)) {\n\t\tunsigned int left_to_center = nr_left - target_left;\n\n\t\tcopy_entries(center, 0, left, target_left, left_to_center);\n\t\tcopy_entries(center, left_to_center, right, 0, target_center - left_to_center);\n\t\tshift_down(right, nr_right - target_right);\n\n\t} else {\n\t\tunsigned int right_short = target_right - nr_right;\n\n\t\tshift_up(right, right_short);\n\t\tcopy_entries(right, 0, left, nr_left - right_short, right_short);\n\t\tcopy_entries(center, 0, left, target_left, nr_left - target_left);\n\t}\n\n\tleft->header.nr_entries = cpu_to_le32(target_left);\n\tcenter->header.nr_entries = cpu_to_le32(target_center);\n\tright->header.nr_entries = cpu_to_le32(target_right);\n}\n\n \nstatic int split_one_into_two(struct shadow_spine *s, unsigned int parent_index,\n\t\t\t      struct dm_btree_value_type *vt, uint64_t key)\n{\n\tint r;\n\tstruct dm_block *left, *right, *parent;\n\tstruct btree_node *ln, *rn, *pn;\n\t__le64 location;\n\n\tleft = shadow_current(s);\n\n\tr = new_block(s->info, &right);\n\tif (r < 0)\n\t\treturn r;\n\n\tln = dm_block_data(left);\n\trn = dm_block_data(right);\n\n\trn->header.flags = ln->header.flags;\n\trn->header.nr_entries = cpu_to_le32(0);\n\trn->header.max_entries = ln->header.max_entries;\n\trn->header.value_size = ln->header.value_size;\n\tredistribute2(ln, rn);\n\n\t \n\tparent = shadow_parent(s);\n\tpn = dm_block_data(parent);\n\n\tlocation = cpu_to_le64(dm_block_location(right));\n\t__dm_bless_for_disk(&location);\n\tr = insert_at(sizeof(__le64), pn, parent_index + 1,\n\t\t      le64_to_cpu(rn->keys[0]), &location);\n\tif (r) {\n\t\tunlock_block(s->info, right);\n\t\treturn r;\n\t}\n\n\t \n\tif (key < le64_to_cpu(rn->keys[0])) {\n\t\tunlock_block(s->info, right);\n\t\ts->nodes[1] = left;\n\t} else {\n\t\tunlock_block(s->info, left);\n\t\ts->nodes[1] = right;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int shadow_child(struct dm_btree_info *info, struct dm_btree_value_type *vt,\n\t\t\tstruct btree_node *parent, unsigned int index,\n\t\t\tstruct dm_block **result)\n{\n\tint r, inc;\n\tdm_block_t root;\n\tstruct btree_node *node;\n\n\troot = value64(parent, index);\n\n\tr = dm_tm_shadow_block(info->tm, root, &btree_node_validator,\n\t\t\t       result, &inc);\n\tif (r)\n\t\treturn r;\n\n\tnode = dm_block_data(*result);\n\n\tif (inc)\n\t\tinc_children(info->tm, node, vt);\n\n\t*((__le64 *) value_ptr(parent, index)) =\n\t\tcpu_to_le64(dm_block_location(*result));\n\n\treturn 0;\n}\n\n \nstatic int split_two_into_three(struct shadow_spine *s, unsigned int parent_index,\n\t\t\t\tstruct dm_btree_value_type *vt, uint64_t key)\n{\n\tint r;\n\tunsigned int middle_index;\n\tstruct dm_block *left, *middle, *right, *parent;\n\tstruct btree_node *ln, *rn, *mn, *pn;\n\t__le64 location;\n\n\tparent = shadow_parent(s);\n\tpn = dm_block_data(parent);\n\n\tif (parent_index == 0) {\n\t\tmiddle_index = 1;\n\t\tleft = shadow_current(s);\n\t\tr = shadow_child(s->info, vt, pn, parent_index + 1, &right);\n\t\tif (r)\n\t\t\treturn r;\n\t} else {\n\t\tmiddle_index = parent_index;\n\t\tright = shadow_current(s);\n\t\tr = shadow_child(s->info, vt, pn, parent_index - 1, &left);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tr = new_block(s->info, &middle);\n\tif (r < 0)\n\t\treturn r;\n\n\tln = dm_block_data(left);\n\tmn = dm_block_data(middle);\n\trn = dm_block_data(right);\n\n\tmn->header.nr_entries = cpu_to_le32(0);\n\tmn->header.flags = ln->header.flags;\n\tmn->header.max_entries = ln->header.max_entries;\n\tmn->header.value_size = ln->header.value_size;\n\n\tredistribute3(ln, mn, rn);\n\n\t \n\tpn->keys[middle_index] = rn->keys[0];\n\tlocation = cpu_to_le64(dm_block_location(middle));\n\t__dm_bless_for_disk(&location);\n\tr = insert_at(sizeof(__le64), pn, middle_index,\n\t\t      le64_to_cpu(mn->keys[0]), &location);\n\tif (r) {\n\t\tif (shadow_current(s) != left)\n\t\t\tunlock_block(s->info, left);\n\n\t\tunlock_block(s->info, middle);\n\n\t\tif (shadow_current(s) != right)\n\t\t\tunlock_block(s->info, right);\n\n\t\treturn r;\n\t}\n\n\n\t \n\tif (key < le64_to_cpu(mn->keys[0])) {\n\t\tunlock_block(s->info, middle);\n\t\tunlock_block(s->info, right);\n\t\ts->nodes[1] = left;\n\t} else if (key < le64_to_cpu(rn->keys[0])) {\n\t\tunlock_block(s->info, left);\n\t\tunlock_block(s->info, right);\n\t\ts->nodes[1] = middle;\n\t} else {\n\t\tunlock_block(s->info, left);\n\t\tunlock_block(s->info, middle);\n\t\ts->nodes[1] = right;\n\t}\n\n\treturn 0;\n}\n\n \n\n \nstatic int btree_split_beneath(struct shadow_spine *s, uint64_t key)\n{\n\tint r;\n\tsize_t size;\n\tunsigned int nr_left, nr_right;\n\tstruct dm_block *left, *right, *new_parent;\n\tstruct btree_node *pn, *ln, *rn;\n\t__le64 val;\n\n\tnew_parent = shadow_current(s);\n\n\tpn = dm_block_data(new_parent);\n\tsize = le32_to_cpu(pn->header.flags) & INTERNAL_NODE ?\n\t\tsizeof(__le64) : s->info->value_type.size;\n\n\t \n\tr = new_block(s->info, &left);\n\tif (r < 0)\n\t\treturn r;\n\n\tln = dm_block_data(left);\n\tnr_left = le32_to_cpu(pn->header.nr_entries) / 2;\n\n\tln->header.flags = pn->header.flags;\n\tln->header.nr_entries = cpu_to_le32(nr_left);\n\tln->header.max_entries = pn->header.max_entries;\n\tln->header.value_size = pn->header.value_size;\n\tmemcpy(ln->keys, pn->keys, nr_left * sizeof(pn->keys[0]));\n\tmemcpy(value_ptr(ln, 0), value_ptr(pn, 0), nr_left * size);\n\n\t \n\tr = new_block(s->info, &right);\n\tif (r < 0) {\n\t\tunlock_block(s->info, left);\n\t\treturn r;\n\t}\n\n\trn = dm_block_data(right);\n\tnr_right = le32_to_cpu(pn->header.nr_entries) - nr_left;\n\n\trn->header.flags = pn->header.flags;\n\trn->header.nr_entries = cpu_to_le32(nr_right);\n\trn->header.max_entries = pn->header.max_entries;\n\trn->header.value_size = pn->header.value_size;\n\tmemcpy(rn->keys, pn->keys + nr_left, nr_right * sizeof(pn->keys[0]));\n\tmemcpy(value_ptr(rn, 0), value_ptr(pn, nr_left),\n\t       nr_right * size);\n\n\t \n\tpn->header.flags = cpu_to_le32(INTERNAL_NODE);\n\tpn->header.nr_entries = cpu_to_le32(2);\n\tpn->header.max_entries = cpu_to_le32(\n\t\tcalc_max_entries(sizeof(__le64),\n\t\t\t\t dm_bm_block_size(\n\t\t\t\t\t dm_tm_get_bm(s->info->tm))));\n\tpn->header.value_size = cpu_to_le32(sizeof(__le64));\n\n\tval = cpu_to_le64(dm_block_location(left));\n\t__dm_bless_for_disk(&val);\n\tpn->keys[0] = ln->keys[0];\n\tmemcpy_disk(value_ptr(pn, 0), &val, sizeof(__le64));\n\n\tval = cpu_to_le64(dm_block_location(right));\n\t__dm_bless_for_disk(&val);\n\tpn->keys[1] = rn->keys[0];\n\tmemcpy_disk(value_ptr(pn, 1), &val, sizeof(__le64));\n\n\tunlock_block(s->info, left);\n\tunlock_block(s->info, right);\n\treturn 0;\n}\n\n \n\n \nstatic int rebalance_left(struct shadow_spine *s, struct dm_btree_value_type *vt,\n\t\t\t  unsigned int parent_index, uint64_t key)\n{\n\tint r;\n\tstruct dm_block *sib;\n\tstruct btree_node *left, *right, *parent = dm_block_data(shadow_parent(s));\n\n\tr = shadow_child(s->info, vt, parent, parent_index - 1, &sib);\n\tif (r)\n\t\treturn r;\n\n\tleft = dm_block_data(sib);\n\tright = dm_block_data(shadow_current(s));\n\tredistribute2(left, right);\n\t*key_ptr(parent, parent_index) = right->keys[0];\n\n\tif (key < le64_to_cpu(right->keys[0])) {\n\t\tunlock_block(s->info, s->nodes[1]);\n\t\ts->nodes[1] = sib;\n\t} else {\n\t\tunlock_block(s->info, sib);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int rebalance_right(struct shadow_spine *s, struct dm_btree_value_type *vt,\n\t\t\t   unsigned int parent_index, uint64_t key)\n{\n\tint r;\n\tstruct dm_block *sib;\n\tstruct btree_node *left, *right, *parent = dm_block_data(shadow_parent(s));\n\n\tr = shadow_child(s->info, vt, parent, parent_index + 1, &sib);\n\tif (r)\n\t\treturn r;\n\n\tleft = dm_block_data(shadow_current(s));\n\tright = dm_block_data(sib);\n\tredistribute2(left, right);\n\t*key_ptr(parent, parent_index + 1) = right->keys[0];\n\n\tif (key < le64_to_cpu(right->keys[0])) {\n\t\tunlock_block(s->info, sib);\n\t} else {\n\t\tunlock_block(s->info, s->nodes[1]);\n\t\ts->nodes[1] = sib;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int get_node_free_space(struct dm_btree_info *info, dm_block_t b, unsigned int *space)\n{\n\tint r;\n\tunsigned int nr_entries;\n\tstruct dm_block *block;\n\tstruct btree_node *node;\n\n\tr = bn_read_lock(info, b, &block);\n\tif (r)\n\t\treturn r;\n\n\tnode = dm_block_data(block);\n\tnr_entries = le32_to_cpu(node->header.nr_entries);\n\t*space = le32_to_cpu(node->header.max_entries) - nr_entries;\n\n\tunlock_block(info, block);\n\treturn 0;\n}\n\n \n#define SPACE_THRESHOLD 8\nstatic int rebalance_or_split(struct shadow_spine *s, struct dm_btree_value_type *vt,\n\t\t\t      unsigned int parent_index, uint64_t key)\n{\n\tint r;\n\tstruct btree_node *parent = dm_block_data(shadow_parent(s));\n\tunsigned int nr_parent = le32_to_cpu(parent->header.nr_entries);\n\tunsigned int free_space;\n\tint left_shared = 0, right_shared = 0;\n\n\t \n\tif (parent_index > 0) {\n\t\tdm_block_t left_b = value64(parent, parent_index - 1);\n\n\t\tr = dm_tm_block_is_shared(s->info->tm, left_b, &left_shared);\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tif (!left_shared) {\n\t\t\tr = get_node_free_space(s->info, left_b, &free_space);\n\t\t\tif (r)\n\t\t\t\treturn r;\n\n\t\t\tif (free_space >= SPACE_THRESHOLD)\n\t\t\t\treturn rebalance_left(s, vt, parent_index, key);\n\t\t}\n\t}\n\n\t \n\tif (parent_index < (nr_parent - 1)) {\n\t\tdm_block_t right_b = value64(parent, parent_index + 1);\n\n\t\tr = dm_tm_block_is_shared(s->info->tm, right_b, &right_shared);\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tif (!right_shared) {\n\t\t\tr = get_node_free_space(s->info, right_b, &free_space);\n\t\t\tif (r)\n\t\t\t\treturn r;\n\n\t\t\tif (free_space >= SPACE_THRESHOLD)\n\t\t\t\treturn rebalance_right(s, vt, parent_index, key);\n\t\t}\n\t}\n\n\t \n\tif (left_shared || right_shared || (nr_parent <= 2) ||\n\t    (parent_index == 0) || (parent_index + 1 == nr_parent)) {\n\t\treturn split_one_into_two(s, parent_index, vt, key);\n\t} else {\n\t\treturn split_two_into_three(s, parent_index, vt, key);\n\t}\n}\n\n \nstatic bool contains_key(struct btree_node *node, uint64_t key)\n{\n\tint i = lower_bound(node, key);\n\n\tif (i >= 0 && le64_to_cpu(node->keys[i]) == key)\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic bool has_space_for_insert(struct btree_node *node, uint64_t key)\n{\n\tif (node->header.nr_entries == node->header.max_entries) {\n\t\tif (le32_to_cpu(node->header.flags) & LEAF_NODE) {\n\t\t\t \n\t\t\treturn contains_key(node, key);\n\t\t}\n\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic int btree_insert_raw(struct shadow_spine *s, dm_block_t root,\n\t\t\t    struct dm_btree_value_type *vt,\n\t\t\t    uint64_t key, unsigned int *index)\n{\n\tint r, i = *index, top = 1;\n\tstruct btree_node *node;\n\n\tfor (;;) {\n\t\tr = shadow_step(s, root, vt);\n\t\tif (r < 0)\n\t\t\treturn r;\n\n\t\tnode = dm_block_data(shadow_current(s));\n\n\t\t \n\t\tif (shadow_has_parent(s) && i >= 0) {  \n\t\t\t__le64 location = cpu_to_le64(dm_block_location(shadow_current(s)));\n\n\t\t\t__dm_bless_for_disk(&location);\n\t\t\tmemcpy_disk(value_ptr(dm_block_data(shadow_parent(s)), i),\n\t\t\t\t    &location, sizeof(__le64));\n\t\t}\n\n\t\tnode = dm_block_data(shadow_current(s));\n\n\t\tif (!has_space_for_insert(node, key)) {\n\t\t\tif (top)\n\t\t\t\tr = btree_split_beneath(s, key);\n\t\t\telse\n\t\t\t\tr = rebalance_or_split(s, vt, i, key);\n\n\t\t\tif (r < 0)\n\t\t\t\treturn r;\n\n\t\t\t \n\t\t\tnode = dm_block_data(shadow_current(s));\n\t\t}\n\n\t\ti = lower_bound(node, key);\n\n\t\tif (le32_to_cpu(node->header.flags) & LEAF_NODE)\n\t\t\tbreak;\n\n\t\tif (i < 0) {\n\t\t\t \n\t\t\tnode->keys[0] = cpu_to_le64(key);\n\t\t\ti = 0;\n\t\t}\n\n\t\troot = value64(node, i);\n\t\ttop = 0;\n\t}\n\n\tif (i < 0 || le64_to_cpu(node->keys[i]) != key)\n\t\ti++;\n\n\t*index = i;\n\treturn 0;\n}\n\nstatic int __btree_get_overwrite_leaf(struct shadow_spine *s, dm_block_t root,\n\t\t\t\t      uint64_t key, int *index)\n{\n\tint r, i = -1;\n\tstruct btree_node *node;\n\n\t*index = 0;\n\tfor (;;) {\n\t\tr = shadow_step(s, root, &s->info->value_type);\n\t\tif (r < 0)\n\t\t\treturn r;\n\n\t\tnode = dm_block_data(shadow_current(s));\n\n\t\t \n\t\tif (shadow_has_parent(s) && i >= 0) {\n\t\t\t__le64 location = cpu_to_le64(dm_block_location(shadow_current(s)));\n\n\t\t\t__dm_bless_for_disk(&location);\n\t\t\tmemcpy_disk(value_ptr(dm_block_data(shadow_parent(s)), i),\n\t\t\t\t    &location, sizeof(__le64));\n\t\t}\n\n\t\tnode = dm_block_data(shadow_current(s));\n\t\ti = lower_bound(node, key);\n\n\t\tBUG_ON(i < 0);\n\t\tBUG_ON(i >= le32_to_cpu(node->header.nr_entries));\n\n\t\tif (le32_to_cpu(node->header.flags) & LEAF_NODE) {\n\t\t\tif (key != le64_to_cpu(node->keys[i]))\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\troot = value64(node, i);\n\t}\n\n\t*index = i;\n\treturn 0;\n}\n\nint btree_get_overwrite_leaf(struct dm_btree_info *info, dm_block_t root,\n\t\t\t     uint64_t key, int *index,\n\t\t\t     dm_block_t *new_root, struct dm_block **leaf)\n{\n\tint r;\n\tstruct shadow_spine spine;\n\n\tBUG_ON(info->levels > 1);\n\tinit_shadow_spine(&spine, info);\n\tr = __btree_get_overwrite_leaf(&spine, root, key, index);\n\tif (!r) {\n\t\t*new_root = shadow_root(&spine);\n\t\t*leaf = shadow_current(&spine);\n\n\t\t \n\t\tspine.count--;\n\t}\n\texit_shadow_spine(&spine);\n\n\treturn r;\n}\n\nstatic bool need_insert(struct btree_node *node, uint64_t *keys,\n\t\t\tunsigned int level, unsigned int index)\n{\n\treturn ((index >= le32_to_cpu(node->header.nr_entries)) ||\n\t\t(le64_to_cpu(node->keys[index]) != keys[level]));\n}\n\nstatic int insert(struct dm_btree_info *info, dm_block_t root,\n\t\t  uint64_t *keys, void *value, dm_block_t *new_root,\n\t\t  int *inserted)\n\t\t  __dm_written_to_disk(value)\n{\n\tint r;\n\tunsigned int level, index = -1, last_level = info->levels - 1;\n\tdm_block_t block = root;\n\tstruct shadow_spine spine;\n\tstruct btree_node *n;\n\tstruct dm_btree_value_type le64_type;\n\n\tinit_le64_type(info->tm, &le64_type);\n\tinit_shadow_spine(&spine, info);\n\n\tfor (level = 0; level < (info->levels - 1); level++) {\n\t\tr = btree_insert_raw(&spine, block, &le64_type, keys[level], &index);\n\t\tif (r < 0)\n\t\t\tgoto bad;\n\n\t\tn = dm_block_data(shadow_current(&spine));\n\n\t\tif (need_insert(n, keys, level, index)) {\n\t\t\tdm_block_t new_tree;\n\t\t\t__le64 new_le;\n\n\t\t\tr = dm_btree_empty(info, &new_tree);\n\t\t\tif (r < 0)\n\t\t\t\tgoto bad;\n\n\t\t\tnew_le = cpu_to_le64(new_tree);\n\t\t\t__dm_bless_for_disk(&new_le);\n\n\t\t\tr = insert_at(sizeof(uint64_t), n, index,\n\t\t\t\t      keys[level], &new_le);\n\t\t\tif (r)\n\t\t\t\tgoto bad;\n\t\t}\n\n\t\tif (level < last_level)\n\t\t\tblock = value64(n, index);\n\t}\n\n\tr = btree_insert_raw(&spine, block, &info->value_type,\n\t\t\t     keys[level], &index);\n\tif (r < 0)\n\t\tgoto bad;\n\n\tn = dm_block_data(shadow_current(&spine));\n\n\tif (need_insert(n, keys, level, index)) {\n\t\tif (inserted)\n\t\t\t*inserted = 1;\n\n\t\tr = insert_at(info->value_type.size, n, index,\n\t\t\t      keys[level], value);\n\t\tif (r)\n\t\t\tgoto bad_unblessed;\n\t} else {\n\t\tif (inserted)\n\t\t\t*inserted = 0;\n\n\t\tif (info->value_type.dec &&\n\t\t    (!info->value_type.equal ||\n\t\t     !info->value_type.equal(\n\t\t\t     info->value_type.context,\n\t\t\t     value_ptr(n, index),\n\t\t\t     value))) {\n\t\t\tinfo->value_type.dec(info->value_type.context,\n\t\t\t\t\t     value_ptr(n, index), 1);\n\t\t}\n\t\tmemcpy_disk(value_ptr(n, index),\n\t\t\t    value, info->value_type.size);\n\t}\n\n\t*new_root = shadow_root(&spine);\n\texit_shadow_spine(&spine);\n\n\treturn 0;\n\nbad:\n\t__dm_unbless_for_disk(value);\nbad_unblessed:\n\texit_shadow_spine(&spine);\n\treturn r;\n}\n\nint dm_btree_insert(struct dm_btree_info *info, dm_block_t root,\n\t\t    uint64_t *keys, void *value, dm_block_t *new_root)\n\t__dm_written_to_disk(value)\n{\n\treturn insert(info, root, keys, value, new_root, NULL);\n}\nEXPORT_SYMBOL_GPL(dm_btree_insert);\n\nint dm_btree_insert_notify(struct dm_btree_info *info, dm_block_t root,\n\t\t\t   uint64_t *keys, void *value, dm_block_t *new_root,\n\t\t\t   int *inserted)\n\t__dm_written_to_disk(value)\n{\n\treturn insert(info, root, keys, value, new_root, inserted);\n}\nEXPORT_SYMBOL_GPL(dm_btree_insert_notify);\n\n \n\nstatic int find_key(struct ro_spine *s, dm_block_t block, bool find_highest,\n\t\t    uint64_t *result_key, dm_block_t *next_block)\n{\n\tint i, r;\n\tuint32_t flags;\n\n\tdo {\n\t\tr = ro_step(s, block);\n\t\tif (r < 0)\n\t\t\treturn r;\n\n\t\tflags = le32_to_cpu(ro_node(s)->header.flags);\n\t\ti = le32_to_cpu(ro_node(s)->header.nr_entries);\n\t\tif (!i)\n\t\t\treturn -ENODATA;\n\n\t\ti--;\n\n\t\tif (find_highest)\n\t\t\t*result_key = le64_to_cpu(ro_node(s)->keys[i]);\n\t\telse\n\t\t\t*result_key = le64_to_cpu(ro_node(s)->keys[0]);\n\n\t\tif (next_block || flags & INTERNAL_NODE) {\n\t\t\tif (find_highest)\n\t\t\t\tblock = value64(ro_node(s), i);\n\t\t\telse\n\t\t\t\tblock = value64(ro_node(s), 0);\n\t\t}\n\n\t} while (flags & INTERNAL_NODE);\n\n\tif (next_block)\n\t\t*next_block = block;\n\treturn 0;\n}\n\nstatic int dm_btree_find_key(struct dm_btree_info *info, dm_block_t root,\n\t\t\t     bool find_highest, uint64_t *result_keys)\n{\n\tint r = 0, count = 0, level;\n\tstruct ro_spine spine;\n\n\tinit_ro_spine(&spine, info);\n\tfor (level = 0; level < info->levels; level++) {\n\t\tr = find_key(&spine, root, find_highest, result_keys + level,\n\t\t\t     level == info->levels - 1 ? NULL : &root);\n\t\tif (r == -ENODATA) {\n\t\t\tr = 0;\n\t\t\tbreak;\n\n\t\t} else if (r)\n\t\t\tbreak;\n\n\t\tcount++;\n\t}\n\texit_ro_spine(&spine);\n\n\treturn r ? r : count;\n}\n\nint dm_btree_find_highest_key(struct dm_btree_info *info, dm_block_t root,\n\t\t\t      uint64_t *result_keys)\n{\n\treturn dm_btree_find_key(info, root, true, result_keys);\n}\nEXPORT_SYMBOL_GPL(dm_btree_find_highest_key);\n\nint dm_btree_find_lowest_key(struct dm_btree_info *info, dm_block_t root,\n\t\t\t     uint64_t *result_keys)\n{\n\treturn dm_btree_find_key(info, root, false, result_keys);\n}\nEXPORT_SYMBOL_GPL(dm_btree_find_lowest_key);\n\n \n\n \nstatic int walk_node(struct dm_btree_info *info, dm_block_t block,\n\t\t     int (*fn)(void *context, uint64_t *keys, void *leaf),\n\t\t     void *context)\n{\n\tint r;\n\tunsigned int i, nr;\n\tstruct dm_block *node;\n\tstruct btree_node *n;\n\tuint64_t keys;\n\n\tr = bn_read_lock(info, block, &node);\n\tif (r)\n\t\treturn r;\n\n\tn = dm_block_data(node);\n\n\tnr = le32_to_cpu(n->header.nr_entries);\n\tfor (i = 0; i < nr; i++) {\n\t\tif (le32_to_cpu(n->header.flags) & INTERNAL_NODE) {\n\t\t\tr = walk_node(info, value64(n, i), fn, context);\n\t\t\tif (r)\n\t\t\t\tgoto out;\n\t\t} else {\n\t\t\tkeys = le64_to_cpu(*key_ptr(n, i));\n\t\t\tr = fn(context, &keys, value_ptr(n, i));\n\t\t\tif (r)\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tdm_tm_unlock(info->tm, node);\n\treturn r;\n}\n\nint dm_btree_walk(struct dm_btree_info *info, dm_block_t root,\n\t\t  int (*fn)(void *context, uint64_t *keys, void *leaf),\n\t\t  void *context)\n{\n\tBUG_ON(info->levels > 1);\n\treturn walk_node(info, root, fn, context);\n}\nEXPORT_SYMBOL_GPL(dm_btree_walk);\n\n \n\nstatic void prefetch_values(struct dm_btree_cursor *c)\n{\n\tunsigned int i, nr;\n\t__le64 value_le;\n\tstruct cursor_node *n = c->nodes + c->depth - 1;\n\tstruct btree_node *bn = dm_block_data(n->b);\n\tstruct dm_block_manager *bm = dm_tm_get_bm(c->info->tm);\n\n\tBUG_ON(c->info->value_type.size != sizeof(value_le));\n\n\tnr = le32_to_cpu(bn->header.nr_entries);\n\tfor (i = 0; i < nr; i++) {\n\t\tmemcpy(&value_le, value_ptr(bn, i), sizeof(value_le));\n\t\tdm_bm_prefetch(bm, le64_to_cpu(value_le));\n\t}\n}\n\nstatic bool leaf_node(struct dm_btree_cursor *c)\n{\n\tstruct cursor_node *n = c->nodes + c->depth - 1;\n\tstruct btree_node *bn = dm_block_data(n->b);\n\n\treturn le32_to_cpu(bn->header.flags) & LEAF_NODE;\n}\n\nstatic int push_node(struct dm_btree_cursor *c, dm_block_t b)\n{\n\tint r;\n\tstruct cursor_node *n = c->nodes + c->depth;\n\n\tif (c->depth >= DM_BTREE_CURSOR_MAX_DEPTH - 1) {\n\t\tDMERR(\"couldn't push cursor node, stack depth too high\");\n\t\treturn -EINVAL;\n\t}\n\n\tr = bn_read_lock(c->info, b, &n->b);\n\tif (r)\n\t\treturn r;\n\n\tn->index = 0;\n\tc->depth++;\n\n\tif (c->prefetch_leaves || !leaf_node(c))\n\t\tprefetch_values(c);\n\n\treturn 0;\n}\n\nstatic void pop_node(struct dm_btree_cursor *c)\n{\n\tc->depth--;\n\tunlock_block(c->info, c->nodes[c->depth].b);\n}\n\nstatic int inc_or_backtrack(struct dm_btree_cursor *c)\n{\n\tstruct cursor_node *n;\n\tstruct btree_node *bn;\n\n\tfor (;;) {\n\t\tif (!c->depth)\n\t\t\treturn -ENODATA;\n\n\t\tn = c->nodes + c->depth - 1;\n\t\tbn = dm_block_data(n->b);\n\n\t\tn->index++;\n\t\tif (n->index < le32_to_cpu(bn->header.nr_entries))\n\t\t\tbreak;\n\n\t\tpop_node(c);\n\t}\n\n\treturn 0;\n}\n\nstatic int find_leaf(struct dm_btree_cursor *c)\n{\n\tint r = 0;\n\tstruct cursor_node *n;\n\tstruct btree_node *bn;\n\t__le64 value_le;\n\n\tfor (;;) {\n\t\tn = c->nodes + c->depth - 1;\n\t\tbn = dm_block_data(n->b);\n\n\t\tif (le32_to_cpu(bn->header.flags) & LEAF_NODE)\n\t\t\tbreak;\n\n\t\tmemcpy(&value_le, value_ptr(bn, n->index), sizeof(value_le));\n\t\tr = push_node(c, le64_to_cpu(value_le));\n\t\tif (r) {\n\t\t\tDMERR(\"push_node failed\");\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!r && (le32_to_cpu(bn->header.nr_entries) == 0))\n\t\treturn -ENODATA;\n\n\treturn r;\n}\n\nint dm_btree_cursor_begin(struct dm_btree_info *info, dm_block_t root,\n\t\t\t  bool prefetch_leaves, struct dm_btree_cursor *c)\n{\n\tint r;\n\n\tc->info = info;\n\tc->root = root;\n\tc->depth = 0;\n\tc->prefetch_leaves = prefetch_leaves;\n\n\tr = push_node(c, root);\n\tif (r)\n\t\treturn r;\n\n\treturn find_leaf(c);\n}\nEXPORT_SYMBOL_GPL(dm_btree_cursor_begin);\n\nvoid dm_btree_cursor_end(struct dm_btree_cursor *c)\n{\n\twhile (c->depth)\n\t\tpop_node(c);\n}\nEXPORT_SYMBOL_GPL(dm_btree_cursor_end);\n\nint dm_btree_cursor_next(struct dm_btree_cursor *c)\n{\n\tint r = inc_or_backtrack(c);\n\n\tif (!r) {\n\t\tr = find_leaf(c);\n\t\tif (r)\n\t\t\tDMERR(\"find_leaf failed\");\n\t}\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(dm_btree_cursor_next);\n\nint dm_btree_cursor_skip(struct dm_btree_cursor *c, uint32_t count)\n{\n\tint r = 0;\n\n\twhile (count-- && !r)\n\t\tr = dm_btree_cursor_next(c);\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(dm_btree_cursor_skip);\n\nint dm_btree_cursor_get_value(struct dm_btree_cursor *c, uint64_t *key, void *value_le)\n{\n\tif (c->depth) {\n\t\tstruct cursor_node *n = c->nodes + c->depth - 1;\n\t\tstruct btree_node *bn = dm_block_data(n->b);\n\n\t\tif (le32_to_cpu(bn->header.flags) & INTERNAL_NODE)\n\t\t\treturn -EINVAL;\n\n\t\t*key = le64_to_cpu(*key_ptr(bn, n->index));\n\t\tmemcpy(value_le, value_ptr(bn, n->index), c->info->value_type.size);\n\t\treturn 0;\n\n\t} else\n\t\treturn -ENODATA;\n}\nEXPORT_SYMBOL_GPL(dm_btree_cursor_get_value);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}