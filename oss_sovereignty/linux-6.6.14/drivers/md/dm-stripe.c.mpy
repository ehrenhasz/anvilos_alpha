{
  "module_name": "dm-stripe.c",
  "hash_id": "de4959645d3e9714b3a764bf4adaad41a8ff036018a91c4c26c642b6b33e68ec",
  "original_prompt": "Ingested from linux-6.6.14/drivers/md/dm-stripe.c",
  "human_readable_source": "\n \n\n#include \"dm.h\"\n#include <linux/device-mapper.h>\n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/blkdev.h>\n#include <linux/bio.h>\n#include <linux/dax.h>\n#include <linux/slab.h>\n#include <linux/log2.h>\n\nstatic struct workqueue_struct *dm_stripe_wq;\n\n#define DM_MSG_PREFIX \"striped\"\n#define DM_IO_ERROR_THRESHOLD 15\n\nstruct stripe {\n\tstruct dm_dev *dev;\n\tsector_t physical_start;\n\n\tatomic_t error_count;\n};\n\nstruct stripe_c {\n\tuint32_t stripes;\n\tint stripes_shift;\n\n\t \n\tsector_t stripe_width;\n\n\tuint32_t chunk_size;\n\tint chunk_size_shift;\n\n\t \n\tstruct dm_target *ti;\n\n\t \n\tstruct work_struct trigger_event;\n\n\tstruct stripe stripe[];\n};\n\n \nstatic void trigger_event(struct work_struct *work)\n{\n\tstruct stripe_c *sc = container_of(work, struct stripe_c,\n\t\t\t\t\t   trigger_event);\n\tdm_table_event(sc->ti->table);\n}\n\n \nstatic int get_stripe(struct dm_target *ti, struct stripe_c *sc,\n\t\t      unsigned int stripe, char **argv)\n{\n\tunsigned long long start;\n\tchar dummy;\n\tint ret;\n\n\tif (sscanf(argv[1], \"%llu%c\", &start, &dummy) != 1)\n\t\treturn -EINVAL;\n\n\tret = dm_get_device(ti, argv[0], dm_table_get_mode(ti->table),\n\t\t\t    &sc->stripe[stripe].dev);\n\tif (ret)\n\t\treturn ret;\n\n\tsc->stripe[stripe].physical_start = start;\n\n\treturn 0;\n}\n\n \nstatic int stripe_ctr(struct dm_target *ti, unsigned int argc, char **argv)\n{\n\tstruct stripe_c *sc;\n\tsector_t width, tmp_len;\n\tuint32_t stripes;\n\tuint32_t chunk_size;\n\tint r;\n\tunsigned int i;\n\n\tif (argc < 2) {\n\t\tti->error = \"Not enough arguments\";\n\t\treturn -EINVAL;\n\t}\n\n\tif (kstrtouint(argv[0], 10, &stripes) || !stripes) {\n\t\tti->error = \"Invalid stripe count\";\n\t\treturn -EINVAL;\n\t}\n\n\tif (kstrtouint(argv[1], 10, &chunk_size) || !chunk_size) {\n\t\tti->error = \"Invalid chunk_size\";\n\t\treturn -EINVAL;\n\t}\n\n\twidth = ti->len;\n\tif (sector_div(width, stripes)) {\n\t\tti->error = \"Target length not divisible by number of stripes\";\n\t\treturn -EINVAL;\n\t}\n\n\ttmp_len = width;\n\tif (sector_div(tmp_len, chunk_size)) {\n\t\tti->error = \"Target length not divisible by chunk size\";\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (argc != (2 + 2 * stripes)) {\n\t\tti->error = \"Not enough destinations specified\";\n\t\treturn -EINVAL;\n\t}\n\n\tsc = kmalloc(struct_size(sc, stripe, stripes), GFP_KERNEL);\n\tif (!sc) {\n\t\tti->error = \"Memory allocation for striped context failed\";\n\t\treturn -ENOMEM;\n\t}\n\n\tINIT_WORK(&sc->trigger_event, trigger_event);\n\n\t \n\tsc->ti = ti;\n\tsc->stripes = stripes;\n\tsc->stripe_width = width;\n\n\tif (stripes & (stripes - 1))\n\t\tsc->stripes_shift = -1;\n\telse\n\t\tsc->stripes_shift = __ffs(stripes);\n\n\tr = dm_set_target_max_io_len(ti, chunk_size);\n\tif (r) {\n\t\tkfree(sc);\n\t\treturn r;\n\t}\n\n\tti->num_flush_bios = stripes;\n\tti->num_discard_bios = stripes;\n\tti->num_secure_erase_bios = stripes;\n\tti->num_write_zeroes_bios = stripes;\n\n\tsc->chunk_size = chunk_size;\n\tif (chunk_size & (chunk_size - 1))\n\t\tsc->chunk_size_shift = -1;\n\telse\n\t\tsc->chunk_size_shift = __ffs(chunk_size);\n\n\t \n\tfor (i = 0; i < stripes; i++) {\n\t\targv += 2;\n\n\t\tr = get_stripe(ti, sc, i, argv);\n\t\tif (r < 0) {\n\t\t\tti->error = \"Couldn't parse stripe destination\";\n\t\t\twhile (i--)\n\t\t\t\tdm_put_device(ti, sc->stripe[i].dev);\n\t\t\tkfree(sc);\n\t\t\treturn r;\n\t\t}\n\t\tatomic_set(&(sc->stripe[i].error_count), 0);\n\t}\n\n\tti->private = sc;\n\n\treturn 0;\n}\n\nstatic void stripe_dtr(struct dm_target *ti)\n{\n\tunsigned int i;\n\tstruct stripe_c *sc = ti->private;\n\n\tfor (i = 0; i < sc->stripes; i++)\n\t\tdm_put_device(ti, sc->stripe[i].dev);\n\n\tflush_work(&sc->trigger_event);\n\tkfree(sc);\n}\n\nstatic void stripe_map_sector(struct stripe_c *sc, sector_t sector,\n\t\t\t      uint32_t *stripe, sector_t *result)\n{\n\tsector_t chunk = dm_target_offset(sc->ti, sector);\n\tsector_t chunk_offset;\n\n\tif (sc->chunk_size_shift < 0)\n\t\tchunk_offset = sector_div(chunk, sc->chunk_size);\n\telse {\n\t\tchunk_offset = chunk & (sc->chunk_size - 1);\n\t\tchunk >>= sc->chunk_size_shift;\n\t}\n\n\tif (sc->stripes_shift < 0)\n\t\t*stripe = sector_div(chunk, sc->stripes);\n\telse {\n\t\t*stripe = chunk & (sc->stripes - 1);\n\t\tchunk >>= sc->stripes_shift;\n\t}\n\n\tif (sc->chunk_size_shift < 0)\n\t\tchunk *= sc->chunk_size;\n\telse\n\t\tchunk <<= sc->chunk_size_shift;\n\n\t*result = chunk + chunk_offset;\n}\n\nstatic void stripe_map_range_sector(struct stripe_c *sc, sector_t sector,\n\t\t\t\t    uint32_t target_stripe, sector_t *result)\n{\n\tuint32_t stripe;\n\n\tstripe_map_sector(sc, sector, &stripe, result);\n\tif (stripe == target_stripe)\n\t\treturn;\n\n\t \n\tsector = *result;\n\tif (sc->chunk_size_shift < 0)\n\t\t*result -= sector_div(sector, sc->chunk_size);\n\telse\n\t\t*result = sector & ~(sector_t)(sc->chunk_size - 1);\n\n\tif (target_stripe < stripe)\n\t\t*result += sc->chunk_size;\t\t \n}\n\nstatic int stripe_map_range(struct stripe_c *sc, struct bio *bio,\n\t\t\t    uint32_t target_stripe)\n{\n\tsector_t begin, end;\n\n\tstripe_map_range_sector(sc, bio->bi_iter.bi_sector,\n\t\t\t\ttarget_stripe, &begin);\n\tstripe_map_range_sector(sc, bio_end_sector(bio),\n\t\t\t\ttarget_stripe, &end);\n\tif (begin < end) {\n\t\tbio_set_dev(bio, sc->stripe[target_stripe].dev->bdev);\n\t\tbio->bi_iter.bi_sector = begin +\n\t\t\tsc->stripe[target_stripe].physical_start;\n\t\tbio->bi_iter.bi_size = to_bytes(end - begin);\n\t\treturn DM_MAPIO_REMAPPED;\n\t}\n\n\t \n\tbio_endio(bio);\n\treturn DM_MAPIO_SUBMITTED;\n}\n\nstatic int stripe_map(struct dm_target *ti, struct bio *bio)\n{\n\tstruct stripe_c *sc = ti->private;\n\tuint32_t stripe;\n\tunsigned int target_bio_nr;\n\n\tif (bio->bi_opf & REQ_PREFLUSH) {\n\t\ttarget_bio_nr = dm_bio_get_target_bio_nr(bio);\n\t\tBUG_ON(target_bio_nr >= sc->stripes);\n\t\tbio_set_dev(bio, sc->stripe[target_bio_nr].dev->bdev);\n\t\treturn DM_MAPIO_REMAPPED;\n\t}\n\tif (unlikely(bio_op(bio) == REQ_OP_DISCARD) ||\n\t    unlikely(bio_op(bio) == REQ_OP_SECURE_ERASE) ||\n\t    unlikely(bio_op(bio) == REQ_OP_WRITE_ZEROES)) {\n\t\ttarget_bio_nr = dm_bio_get_target_bio_nr(bio);\n\t\tBUG_ON(target_bio_nr >= sc->stripes);\n\t\treturn stripe_map_range(sc, bio, target_bio_nr);\n\t}\n\n\tstripe_map_sector(sc, bio->bi_iter.bi_sector,\n\t\t\t  &stripe, &bio->bi_iter.bi_sector);\n\n\tbio->bi_iter.bi_sector += sc->stripe[stripe].physical_start;\n\tbio_set_dev(bio, sc->stripe[stripe].dev->bdev);\n\n\treturn DM_MAPIO_REMAPPED;\n}\n\n#if IS_ENABLED(CONFIG_FS_DAX)\nstatic struct dax_device *stripe_dax_pgoff(struct dm_target *ti, pgoff_t *pgoff)\n{\n\tstruct stripe_c *sc = ti->private;\n\tstruct block_device *bdev;\n\tsector_t dev_sector;\n\tuint32_t stripe;\n\n\tstripe_map_sector(sc, *pgoff * PAGE_SECTORS, &stripe, &dev_sector);\n\tdev_sector += sc->stripe[stripe].physical_start;\n\tbdev = sc->stripe[stripe].dev->bdev;\n\n\t*pgoff = (get_start_sect(bdev) + dev_sector) >> PAGE_SECTORS_SHIFT;\n\treturn sc->stripe[stripe].dev->dax_dev;\n}\n\nstatic long stripe_dax_direct_access(struct dm_target *ti, pgoff_t pgoff,\n\t\tlong nr_pages, enum dax_access_mode mode, void **kaddr,\n\t\tpfn_t *pfn)\n{\n\tstruct dax_device *dax_dev = stripe_dax_pgoff(ti, &pgoff);\n\n\treturn dax_direct_access(dax_dev, pgoff, nr_pages, mode, kaddr, pfn);\n}\n\nstatic int stripe_dax_zero_page_range(struct dm_target *ti, pgoff_t pgoff,\n\t\t\t\t      size_t nr_pages)\n{\n\tstruct dax_device *dax_dev = stripe_dax_pgoff(ti, &pgoff);\n\n\treturn dax_zero_page_range(dax_dev, pgoff, nr_pages);\n}\n\nstatic size_t stripe_dax_recovery_write(struct dm_target *ti, pgoff_t pgoff,\n\t\tvoid *addr, size_t bytes, struct iov_iter *i)\n{\n\tstruct dax_device *dax_dev = stripe_dax_pgoff(ti, &pgoff);\n\n\treturn dax_recovery_write(dax_dev, pgoff, addr, bytes, i);\n}\n\n#else\n#define stripe_dax_direct_access NULL\n#define stripe_dax_zero_page_range NULL\n#define stripe_dax_recovery_write NULL\n#endif\n\n \n\nstatic void stripe_status(struct dm_target *ti, status_type_t type,\n\t\t\t  unsigned int status_flags, char *result, unsigned int maxlen)\n{\n\tstruct stripe_c *sc = ti->private;\n\tunsigned int sz = 0;\n\tunsigned int i;\n\n\tswitch (type) {\n\tcase STATUSTYPE_INFO:\n\t\tDMEMIT(\"%d \", sc->stripes);\n\t\tfor (i = 0; i < sc->stripes; i++)\n\t\t\tDMEMIT(\"%s \", sc->stripe[i].dev->name);\n\n\t\tDMEMIT(\"1 \");\n\t\tfor (i = 0; i < sc->stripes; i++)\n\t\t\tDMEMIT(\"%c\", atomic_read(&(sc->stripe[i].error_count)) ?  'D' : 'A');\n\t\tbreak;\n\n\tcase STATUSTYPE_TABLE:\n\t\tDMEMIT(\"%d %llu\", sc->stripes,\n\t\t\t(unsigned long long)sc->chunk_size);\n\t\tfor (i = 0; i < sc->stripes; i++)\n\t\t\tDMEMIT(\" %s %llu\", sc->stripe[i].dev->name,\n\t\t\t    (unsigned long long)sc->stripe[i].physical_start);\n\t\tbreak;\n\n\tcase STATUSTYPE_IMA:\n\t\tDMEMIT_TARGET_NAME_VERSION(ti->type);\n\t\tDMEMIT(\",stripes=%d,chunk_size=%llu\", sc->stripes,\n\t\t       (unsigned long long)sc->chunk_size);\n\n\t\tfor (i = 0; i < sc->stripes; i++) {\n\t\t\tDMEMIT(\",stripe_%d_device_name=%s\", i, sc->stripe[i].dev->name);\n\t\t\tDMEMIT(\",stripe_%d_physical_start=%llu\", i,\n\t\t\t       (unsigned long long)sc->stripe[i].physical_start);\n\t\t\tDMEMIT(\",stripe_%d_status=%c\", i,\n\t\t\t       atomic_read(&(sc->stripe[i].error_count)) ? 'D' : 'A');\n\t\t}\n\t\tDMEMIT(\";\");\n\t\tbreak;\n\t}\n}\n\nstatic int stripe_end_io(struct dm_target *ti, struct bio *bio,\n\t\tblk_status_t *error)\n{\n\tunsigned int i;\n\tchar major_minor[16];\n\tstruct stripe_c *sc = ti->private;\n\n\tif (!*error)\n\t\treturn DM_ENDIO_DONE;  \n\n\tif (bio->bi_opf & REQ_RAHEAD)\n\t\treturn DM_ENDIO_DONE;\n\n\tif (*error == BLK_STS_NOTSUPP)\n\t\treturn DM_ENDIO_DONE;\n\n\tmemset(major_minor, 0, sizeof(major_minor));\n\tsprintf(major_minor, \"%d:%d\", MAJOR(bio_dev(bio)), MINOR(bio_dev(bio)));\n\n\t \n\tfor (i = 0; i < sc->stripes; i++)\n\t\tif (!strcmp(sc->stripe[i].dev->name, major_minor)) {\n\t\t\tatomic_inc(&(sc->stripe[i].error_count));\n\t\t\tif (atomic_read(&(sc->stripe[i].error_count)) <\n\t\t\t    DM_IO_ERROR_THRESHOLD)\n\t\t\t\tqueue_work(dm_stripe_wq, &sc->trigger_event);\n\t\t}\n\n\treturn DM_ENDIO_DONE;\n}\n\nstatic int stripe_iterate_devices(struct dm_target *ti,\n\t\t\t\t  iterate_devices_callout_fn fn, void *data)\n{\n\tstruct stripe_c *sc = ti->private;\n\tint ret = 0;\n\tunsigned int i = 0;\n\n\tdo {\n\t\tret = fn(ti, sc->stripe[i].dev,\n\t\t\t sc->stripe[i].physical_start,\n\t\t\t sc->stripe_width, data);\n\t} while (!ret && ++i < sc->stripes);\n\n\treturn ret;\n}\n\nstatic void stripe_io_hints(struct dm_target *ti,\n\t\t\t    struct queue_limits *limits)\n{\n\tstruct stripe_c *sc = ti->private;\n\tunsigned int chunk_size = sc->chunk_size << SECTOR_SHIFT;\n\n\tblk_limits_io_min(limits, chunk_size);\n\tblk_limits_io_opt(limits, chunk_size * sc->stripes);\n}\n\nstatic struct target_type stripe_target = {\n\t.name   = \"striped\",\n\t.version = {1, 6, 0},\n\t.features = DM_TARGET_PASSES_INTEGRITY | DM_TARGET_NOWAIT,\n\t.module = THIS_MODULE,\n\t.ctr    = stripe_ctr,\n\t.dtr    = stripe_dtr,\n\t.map    = stripe_map,\n\t.end_io = stripe_end_io,\n\t.status = stripe_status,\n\t.iterate_devices = stripe_iterate_devices,\n\t.io_hints = stripe_io_hints,\n\t.direct_access = stripe_dax_direct_access,\n\t.dax_zero_page_range = stripe_dax_zero_page_range,\n\t.dax_recovery_write = stripe_dax_recovery_write,\n};\n\nint __init dm_stripe_init(void)\n{\n\tint r;\n\n\tdm_stripe_wq = alloc_workqueue(\"dm_stripe_wq\", 0, 0);\n\tif (!dm_stripe_wq)\n\t\treturn -ENOMEM;\n\tr = dm_register_target(&stripe_target);\n\tif (r < 0) {\n\t\tdestroy_workqueue(dm_stripe_wq);\n\t\tDMWARN(\"target registration failed\");\n\t}\n\n\treturn r;\n}\n\nvoid dm_stripe_exit(void)\n{\n\tdm_unregister_target(&stripe_target);\n\tdestroy_workqueue(dm_stripe_wq);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}