{
  "module_name": "dm-log-writes.c",
  "hash_id": "6adf9d87ae601a6b86b64e19129fba61151b959512dd03a8ec2e1aace399dd89",
  "original_prompt": "Ingested from linux-6.6.14/drivers/md/dm-log-writes.c",
  "human_readable_source": "\n \n\n#include <linux/device-mapper.h>\n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/blkdev.h>\n#include <linux/bio.h>\n#include <linux/dax.h>\n#include <linux/slab.h>\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n#include <linux/uio.h>\n\n#define DM_MSG_PREFIX \"log-writes\"\n\n \n#define LOG_FLUSH_FLAG\t\t(1 << 0)\n#define LOG_FUA_FLAG\t\t(1 << 1)\n#define LOG_DISCARD_FLAG\t(1 << 2)\n#define LOG_MARK_FLAG\t\t(1 << 3)\n#define LOG_METADATA_FLAG\t(1 << 4)\n\n#define WRITE_LOG_VERSION 1ULL\n#define WRITE_LOG_MAGIC 0x6a736677736872ULL\n#define WRITE_LOG_SUPER_SECTOR 0\n\n \n\n \nstruct log_write_super {\n\t__le64 magic;\n\t__le64 version;\n\t__le64 nr_entries;\n\t__le32 sectorsize;\n};\n\n \nstruct log_write_entry {\n\t__le64 sector;\n\t__le64 nr_sectors;\n\t__le64 flags;\n\t__le64 data_len;\n};\n\nstruct log_writes_c {\n\tstruct dm_dev *dev;\n\tstruct dm_dev *logdev;\n\tu64 logged_entries;\n\tu32 sectorsize;\n\tu32 sectorshift;\n\tatomic_t io_blocks;\n\tatomic_t pending_blocks;\n\tsector_t next_sector;\n\tsector_t end_sector;\n\tbool logging_enabled;\n\tbool device_supports_discard;\n\tspinlock_t blocks_lock;\n\tstruct list_head unflushed_blocks;\n\tstruct list_head logging_blocks;\n\twait_queue_head_t wait;\n\tstruct task_struct *log_kthread;\n\tstruct completion super_done;\n};\n\nstruct pending_block {\n\tint vec_cnt;\n\tu64 flags;\n\tsector_t sector;\n\tsector_t nr_sectors;\n\tchar *data;\n\tu32 datalen;\n\tstruct list_head list;\n\tstruct bio_vec vecs[];\n};\n\nstruct per_bio_data {\n\tstruct pending_block *block;\n};\n\nstatic inline sector_t bio_to_dev_sectors(struct log_writes_c *lc,\n\t\t\t\t\t  sector_t sectors)\n{\n\treturn sectors >> (lc->sectorshift - SECTOR_SHIFT);\n}\n\nstatic inline sector_t dev_to_bio_sectors(struct log_writes_c *lc,\n\t\t\t\t\t  sector_t sectors)\n{\n\treturn sectors << (lc->sectorshift - SECTOR_SHIFT);\n}\n\nstatic void put_pending_block(struct log_writes_c *lc)\n{\n\tif (atomic_dec_and_test(&lc->pending_blocks)) {\n\t\tsmp_mb__after_atomic();\n\t\tif (waitqueue_active(&lc->wait))\n\t\t\twake_up(&lc->wait);\n\t}\n}\n\nstatic void put_io_block(struct log_writes_c *lc)\n{\n\tif (atomic_dec_and_test(&lc->io_blocks)) {\n\t\tsmp_mb__after_atomic();\n\t\tif (waitqueue_active(&lc->wait))\n\t\t\twake_up(&lc->wait);\n\t}\n}\n\nstatic void log_end_io(struct bio *bio)\n{\n\tstruct log_writes_c *lc = bio->bi_private;\n\n\tif (bio->bi_status) {\n\t\tunsigned long flags;\n\n\t\tDMERR(\"Error writing log block, error=%d\", bio->bi_status);\n\t\tspin_lock_irqsave(&lc->blocks_lock, flags);\n\t\tlc->logging_enabled = false;\n\t\tspin_unlock_irqrestore(&lc->blocks_lock, flags);\n\t}\n\n\tbio_free_pages(bio);\n\tput_io_block(lc);\n\tbio_put(bio);\n}\n\nstatic void log_end_super(struct bio *bio)\n{\n\tstruct log_writes_c *lc = bio->bi_private;\n\n\tcomplete(&lc->super_done);\n\tlog_end_io(bio);\n}\n\n \nstatic void free_pending_block(struct log_writes_c *lc,\n\t\t\t       struct pending_block *block)\n{\n\tint i;\n\n\tfor (i = 0; i < block->vec_cnt; i++) {\n\t\tif (block->vecs[i].bv_page)\n\t\t\t__free_page(block->vecs[i].bv_page);\n\t}\n\tkfree(block->data);\n\tkfree(block);\n\tput_pending_block(lc);\n}\n\nstatic int write_metadata(struct log_writes_c *lc, void *entry,\n\t\t\t  size_t entrylen, void *data, size_t datalen,\n\t\t\t  sector_t sector)\n{\n\tstruct bio *bio;\n\tstruct page *page;\n\tvoid *ptr;\n\tsize_t ret;\n\n\tbio = bio_alloc(lc->logdev->bdev, 1, REQ_OP_WRITE, GFP_KERNEL);\n\tbio->bi_iter.bi_size = 0;\n\tbio->bi_iter.bi_sector = sector;\n\tbio->bi_end_io = (sector == WRITE_LOG_SUPER_SECTOR) ?\n\t\t\t  log_end_super : log_end_io;\n\tbio->bi_private = lc;\n\n\tpage = alloc_page(GFP_KERNEL);\n\tif (!page) {\n\t\tDMERR(\"Couldn't alloc log page\");\n\t\tbio_put(bio);\n\t\tgoto error;\n\t}\n\n\tptr = kmap_local_page(page);\n\tmemcpy(ptr, entry, entrylen);\n\tif (datalen)\n\t\tmemcpy(ptr + entrylen, data, datalen);\n\tmemset(ptr + entrylen + datalen, 0,\n\t       lc->sectorsize - entrylen - datalen);\n\tkunmap_local(ptr);\n\n\tret = bio_add_page(bio, page, lc->sectorsize, 0);\n\tif (ret != lc->sectorsize) {\n\t\tDMERR(\"Couldn't add page to the log block\");\n\t\tgoto error_bio;\n\t}\n\tsubmit_bio(bio);\n\treturn 0;\nerror_bio:\n\tbio_put(bio);\n\t__free_page(page);\nerror:\n\tput_io_block(lc);\n\treturn -1;\n}\n\nstatic int write_inline_data(struct log_writes_c *lc, void *entry,\n\t\t\t     size_t entrylen, void *data, size_t datalen,\n\t\t\t     sector_t sector)\n{\n\tint bio_pages, pg_datalen, pg_sectorlen, i;\n\tstruct page *page;\n\tstruct bio *bio;\n\tsize_t ret;\n\tvoid *ptr;\n\n\twhile (datalen) {\n\t\tbio_pages = bio_max_segs(DIV_ROUND_UP(datalen, PAGE_SIZE));\n\n\t\tatomic_inc(&lc->io_blocks);\n\n\t\tbio = bio_alloc(lc->logdev->bdev, bio_pages, REQ_OP_WRITE,\n\t\t\t\tGFP_KERNEL);\n\t\tbio->bi_iter.bi_size = 0;\n\t\tbio->bi_iter.bi_sector = sector;\n\t\tbio->bi_end_io = log_end_io;\n\t\tbio->bi_private = lc;\n\n\t\tfor (i = 0; i < bio_pages; i++) {\n\t\t\tpg_datalen = min_t(int, datalen, PAGE_SIZE);\n\t\t\tpg_sectorlen = ALIGN(pg_datalen, lc->sectorsize);\n\n\t\t\tpage = alloc_page(GFP_KERNEL);\n\t\t\tif (!page) {\n\t\t\t\tDMERR(\"Couldn't alloc inline data page\");\n\t\t\t\tgoto error_bio;\n\t\t\t}\n\n\t\t\tptr = kmap_local_page(page);\n\t\t\tmemcpy(ptr, data, pg_datalen);\n\t\t\tif (pg_sectorlen > pg_datalen)\n\t\t\t\tmemset(ptr + pg_datalen, 0, pg_sectorlen - pg_datalen);\n\t\t\tkunmap_local(ptr);\n\n\t\t\tret = bio_add_page(bio, page, pg_sectorlen, 0);\n\t\t\tif (ret != pg_sectorlen) {\n\t\t\t\tDMERR(\"Couldn't add page of inline data\");\n\t\t\t\t__free_page(page);\n\t\t\t\tgoto error_bio;\n\t\t\t}\n\n\t\t\tdatalen -= pg_datalen;\n\t\t\tdata\t+= pg_datalen;\n\t\t}\n\t\tsubmit_bio(bio);\n\n\t\tsector += bio_pages * PAGE_SECTORS;\n\t}\n\treturn 0;\nerror_bio:\n\tbio_free_pages(bio);\n\tbio_put(bio);\n\tput_io_block(lc);\n\treturn -1;\n}\n\nstatic int log_one_block(struct log_writes_c *lc,\n\t\t\t struct pending_block *block, sector_t sector)\n{\n\tstruct bio *bio;\n\tstruct log_write_entry entry;\n\tsize_t metadatalen, ret;\n\tint i;\n\n\tentry.sector = cpu_to_le64(block->sector);\n\tentry.nr_sectors = cpu_to_le64(block->nr_sectors);\n\tentry.flags = cpu_to_le64(block->flags);\n\tentry.data_len = cpu_to_le64(block->datalen);\n\n\tmetadatalen = (block->flags & LOG_MARK_FLAG) ? block->datalen : 0;\n\tif (write_metadata(lc, &entry, sizeof(entry), block->data,\n\t\t\t   metadatalen, sector)) {\n\t\tfree_pending_block(lc, block);\n\t\treturn -1;\n\t}\n\n\tsector += dev_to_bio_sectors(lc, 1);\n\n\tif (block->datalen && metadatalen == 0) {\n\t\tif (write_inline_data(lc, &entry, sizeof(entry), block->data,\n\t\t\t\t      block->datalen, sector)) {\n\t\t\tfree_pending_block(lc, block);\n\t\t\treturn -1;\n\t\t}\n\t\t \n\t\tgoto out;\n\t}\n\n\tif (!block->vec_cnt)\n\t\tgoto out;\n\n\tatomic_inc(&lc->io_blocks);\n\tbio = bio_alloc(lc->logdev->bdev, bio_max_segs(block->vec_cnt),\n\t\t\tREQ_OP_WRITE, GFP_KERNEL);\n\tbio->bi_iter.bi_size = 0;\n\tbio->bi_iter.bi_sector = sector;\n\tbio->bi_end_io = log_end_io;\n\tbio->bi_private = lc;\n\n\tfor (i = 0; i < block->vec_cnt; i++) {\n\t\t \n\t\tret = bio_add_page(bio, block->vecs[i].bv_page,\n\t\t\t\t   block->vecs[i].bv_len, 0);\n\t\tif (ret != block->vecs[i].bv_len) {\n\t\t\tatomic_inc(&lc->io_blocks);\n\t\t\tsubmit_bio(bio);\n\t\t\tbio = bio_alloc(lc->logdev->bdev,\n\t\t\t\t\tbio_max_segs(block->vec_cnt - i),\n\t\t\t\t\tREQ_OP_WRITE, GFP_KERNEL);\n\t\t\tbio->bi_iter.bi_size = 0;\n\t\t\tbio->bi_iter.bi_sector = sector;\n\t\t\tbio->bi_end_io = log_end_io;\n\t\t\tbio->bi_private = lc;\n\n\t\t\tret = bio_add_page(bio, block->vecs[i].bv_page,\n\t\t\t\t\t   block->vecs[i].bv_len, 0);\n\t\t\tif (ret != block->vecs[i].bv_len) {\n\t\t\t\tDMERR(\"Couldn't add page on new bio?\");\n\t\t\t\tbio_put(bio);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t\tsector += block->vecs[i].bv_len >> SECTOR_SHIFT;\n\t}\n\tsubmit_bio(bio);\nout:\n\tkfree(block->data);\n\tkfree(block);\n\tput_pending_block(lc);\n\treturn 0;\nerror:\n\tfree_pending_block(lc, block);\n\tput_io_block(lc);\n\treturn -1;\n}\n\nstatic int log_super(struct log_writes_c *lc)\n{\n\tstruct log_write_super super;\n\n\tsuper.magic = cpu_to_le64(WRITE_LOG_MAGIC);\n\tsuper.version = cpu_to_le64(WRITE_LOG_VERSION);\n\tsuper.nr_entries = cpu_to_le64(lc->logged_entries);\n\tsuper.sectorsize = cpu_to_le32(lc->sectorsize);\n\n\tif (write_metadata(lc, &super, sizeof(super), NULL, 0,\n\t\t\t   WRITE_LOG_SUPER_SECTOR)) {\n\t\tDMERR(\"Couldn't write super\");\n\t\treturn -1;\n\t}\n\n\t \n\twait_for_completion_io(&lc->super_done);\n\n\treturn 0;\n}\n\nstatic inline sector_t logdev_last_sector(struct log_writes_c *lc)\n{\n\treturn bdev_nr_sectors(lc->logdev->bdev);\n}\n\nstatic int log_writes_kthread(void *arg)\n{\n\tstruct log_writes_c *lc = arg;\n\tsector_t sector = 0;\n\n\twhile (!kthread_should_stop()) {\n\t\tbool super = false;\n\t\tbool logging_enabled;\n\t\tstruct pending_block *block = NULL;\n\t\tint ret;\n\n\t\tspin_lock_irq(&lc->blocks_lock);\n\t\tif (!list_empty(&lc->logging_blocks)) {\n\t\t\tblock = list_first_entry(&lc->logging_blocks,\n\t\t\t\t\t\t struct pending_block, list);\n\t\t\tlist_del_init(&block->list);\n\t\t\tif (!lc->logging_enabled)\n\t\t\t\tgoto next;\n\n\t\t\tsector = lc->next_sector;\n\t\t\tif (!(block->flags & LOG_DISCARD_FLAG))\n\t\t\t\tlc->next_sector += dev_to_bio_sectors(lc, block->nr_sectors);\n\t\t\tlc->next_sector += dev_to_bio_sectors(lc, 1);\n\n\t\t\t \n\t\t\tif (!lc->end_sector)\n\t\t\t\tlc->end_sector = logdev_last_sector(lc);\n\t\t\tif (lc->end_sector &&\n\t\t\t    lc->next_sector >= lc->end_sector) {\n\t\t\t\tDMERR(\"Ran out of space on the logdev\");\n\t\t\t\tlc->logging_enabled = false;\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tlc->logged_entries++;\n\t\t\tatomic_inc(&lc->io_blocks);\n\n\t\t\tsuper = (block->flags & (LOG_FUA_FLAG | LOG_MARK_FLAG));\n\t\t\tif (super)\n\t\t\t\tatomic_inc(&lc->io_blocks);\n\t\t}\nnext:\n\t\tlogging_enabled = lc->logging_enabled;\n\t\tspin_unlock_irq(&lc->blocks_lock);\n\t\tif (block) {\n\t\t\tif (logging_enabled) {\n\t\t\t\tret = log_one_block(lc, block, sector);\n\t\t\t\tif (!ret && super)\n\t\t\t\t\tret = log_super(lc);\n\t\t\t\tif (ret) {\n\t\t\t\t\tspin_lock_irq(&lc->blocks_lock);\n\t\t\t\t\tlc->logging_enabled = false;\n\t\t\t\t\tspin_unlock_irq(&lc->blocks_lock);\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\tfree_pending_block(lc, block);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!try_to_freeze()) {\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\tif (!kthread_should_stop() &&\n\t\t\t    list_empty(&lc->logging_blocks))\n\t\t\t\tschedule();\n\t\t\t__set_current_state(TASK_RUNNING);\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nstatic int log_writes_ctr(struct dm_target *ti, unsigned int argc, char **argv)\n{\n\tstruct log_writes_c *lc;\n\tstruct dm_arg_set as;\n\tconst char *devname, *logdevname;\n\tint ret;\n\n\tas.argc = argc;\n\tas.argv = argv;\n\n\tif (argc < 2) {\n\t\tti->error = \"Invalid argument count\";\n\t\treturn -EINVAL;\n\t}\n\n\tlc = kzalloc(sizeof(struct log_writes_c), GFP_KERNEL);\n\tif (!lc) {\n\t\tti->error = \"Cannot allocate context\";\n\t\treturn -ENOMEM;\n\t}\n\tspin_lock_init(&lc->blocks_lock);\n\tINIT_LIST_HEAD(&lc->unflushed_blocks);\n\tINIT_LIST_HEAD(&lc->logging_blocks);\n\tinit_waitqueue_head(&lc->wait);\n\tinit_completion(&lc->super_done);\n\tatomic_set(&lc->io_blocks, 0);\n\tatomic_set(&lc->pending_blocks, 0);\n\n\tdevname = dm_shift_arg(&as);\n\tret = dm_get_device(ti, devname, dm_table_get_mode(ti->table), &lc->dev);\n\tif (ret) {\n\t\tti->error = \"Device lookup failed\";\n\t\tgoto bad;\n\t}\n\n\tlogdevname = dm_shift_arg(&as);\n\tret = dm_get_device(ti, logdevname, dm_table_get_mode(ti->table),\n\t\t\t    &lc->logdev);\n\tif (ret) {\n\t\tti->error = \"Log device lookup failed\";\n\t\tdm_put_device(ti, lc->dev);\n\t\tgoto bad;\n\t}\n\n\tlc->sectorsize = bdev_logical_block_size(lc->dev->bdev);\n\tlc->sectorshift = ilog2(lc->sectorsize);\n\tlc->log_kthread = kthread_run(log_writes_kthread, lc, \"log-write\");\n\tif (IS_ERR(lc->log_kthread)) {\n\t\tret = PTR_ERR(lc->log_kthread);\n\t\tti->error = \"Couldn't alloc kthread\";\n\t\tdm_put_device(ti, lc->dev);\n\t\tdm_put_device(ti, lc->logdev);\n\t\tgoto bad;\n\t}\n\n\t \n\tlc->next_sector = lc->sectorsize >> SECTOR_SHIFT;\n\tlc->logging_enabled = true;\n\tlc->end_sector = logdev_last_sector(lc);\n\tlc->device_supports_discard = true;\n\n\tti->num_flush_bios = 1;\n\tti->flush_supported = true;\n\tti->num_discard_bios = 1;\n\tti->discards_supported = true;\n\tti->per_io_data_size = sizeof(struct per_bio_data);\n\tti->private = lc;\n\treturn 0;\n\nbad:\n\tkfree(lc);\n\treturn ret;\n}\n\nstatic int log_mark(struct log_writes_c *lc, char *data)\n{\n\tstruct pending_block *block;\n\tsize_t maxsize = lc->sectorsize - sizeof(struct log_write_entry);\n\n\tblock = kzalloc(sizeof(struct pending_block), GFP_KERNEL);\n\tif (!block) {\n\t\tDMERR(\"Error allocating pending block\");\n\t\treturn -ENOMEM;\n\t}\n\n\tblock->data = kstrndup(data, maxsize - 1, GFP_KERNEL);\n\tif (!block->data) {\n\t\tDMERR(\"Error copying mark data\");\n\t\tkfree(block);\n\t\treturn -ENOMEM;\n\t}\n\tatomic_inc(&lc->pending_blocks);\n\tblock->datalen = strlen(block->data);\n\tblock->flags |= LOG_MARK_FLAG;\n\tspin_lock_irq(&lc->blocks_lock);\n\tlist_add_tail(&block->list, &lc->logging_blocks);\n\tspin_unlock_irq(&lc->blocks_lock);\n\twake_up_process(lc->log_kthread);\n\treturn 0;\n}\n\nstatic void log_writes_dtr(struct dm_target *ti)\n{\n\tstruct log_writes_c *lc = ti->private;\n\n\tspin_lock_irq(&lc->blocks_lock);\n\tlist_splice_init(&lc->unflushed_blocks, &lc->logging_blocks);\n\tspin_unlock_irq(&lc->blocks_lock);\n\n\t \n\tlog_mark(lc, \"dm-log-writes-end\");\n\twake_up_process(lc->log_kthread);\n\twait_event(lc->wait, !atomic_read(&lc->io_blocks) &&\n\t\t   !atomic_read(&lc->pending_blocks));\n\tkthread_stop(lc->log_kthread);\n\n\tWARN_ON(!list_empty(&lc->logging_blocks));\n\tWARN_ON(!list_empty(&lc->unflushed_blocks));\n\tdm_put_device(ti, lc->dev);\n\tdm_put_device(ti, lc->logdev);\n\tkfree(lc);\n}\n\nstatic void normal_map_bio(struct dm_target *ti, struct bio *bio)\n{\n\tstruct log_writes_c *lc = ti->private;\n\n\tbio_set_dev(bio, lc->dev->bdev);\n}\n\nstatic int log_writes_map(struct dm_target *ti, struct bio *bio)\n{\n\tstruct log_writes_c *lc = ti->private;\n\tstruct per_bio_data *pb = dm_per_bio_data(bio, sizeof(struct per_bio_data));\n\tstruct pending_block *block;\n\tstruct bvec_iter iter;\n\tstruct bio_vec bv;\n\tsize_t alloc_size;\n\tint i = 0;\n\tbool flush_bio = (bio->bi_opf & REQ_PREFLUSH);\n\tbool fua_bio = (bio->bi_opf & REQ_FUA);\n\tbool discard_bio = (bio_op(bio) == REQ_OP_DISCARD);\n\tbool meta_bio = (bio->bi_opf & REQ_META);\n\n\tpb->block = NULL;\n\n\t \n\tif (!lc->logging_enabled)\n\t\tgoto map_bio;\n\n\t \n\tif (bio_data_dir(bio) == READ)\n\t\tgoto map_bio;\n\n\t \n\tif (!bio_sectors(bio) && !flush_bio)\n\t\tgoto map_bio;\n\n\t \n\tif (discard_bio)\n\t\talloc_size = sizeof(struct pending_block);\n\telse\n\t\talloc_size = struct_size(block, vecs, bio_segments(bio));\n\n\tblock = kzalloc(alloc_size, GFP_NOIO);\n\tif (!block) {\n\t\tDMERR(\"Error allocating pending block\");\n\t\tspin_lock_irq(&lc->blocks_lock);\n\t\tlc->logging_enabled = false;\n\t\tspin_unlock_irq(&lc->blocks_lock);\n\t\treturn DM_MAPIO_KILL;\n\t}\n\tINIT_LIST_HEAD(&block->list);\n\tpb->block = block;\n\tatomic_inc(&lc->pending_blocks);\n\n\tif (flush_bio)\n\t\tblock->flags |= LOG_FLUSH_FLAG;\n\tif (fua_bio)\n\t\tblock->flags |= LOG_FUA_FLAG;\n\tif (discard_bio)\n\t\tblock->flags |= LOG_DISCARD_FLAG;\n\tif (meta_bio)\n\t\tblock->flags |= LOG_METADATA_FLAG;\n\n\tblock->sector = bio_to_dev_sectors(lc, bio->bi_iter.bi_sector);\n\tblock->nr_sectors = bio_to_dev_sectors(lc, bio_sectors(bio));\n\n\t \n\tif (discard_bio) {\n\t\tWARN_ON(flush_bio || fua_bio);\n\t\tif (lc->device_supports_discard)\n\t\t\tgoto map_bio;\n\t\tbio_endio(bio);\n\t\treturn DM_MAPIO_SUBMITTED;\n\t}\n\n\t \n\tif (flush_bio && !bio_sectors(bio)) {\n\t\tspin_lock_irq(&lc->blocks_lock);\n\t\tlist_splice_init(&lc->unflushed_blocks, &block->list);\n\t\tspin_unlock_irq(&lc->blocks_lock);\n\t\tgoto map_bio;\n\t}\n\n\t \n\tbio_for_each_segment(bv, bio, iter) {\n\t\tstruct page *page;\n\t\tvoid *dst;\n\n\t\tpage = alloc_page(GFP_NOIO);\n\t\tif (!page) {\n\t\t\tDMERR(\"Error allocing page\");\n\t\t\tfree_pending_block(lc, block);\n\t\t\tspin_lock_irq(&lc->blocks_lock);\n\t\t\tlc->logging_enabled = false;\n\t\t\tspin_unlock_irq(&lc->blocks_lock);\n\t\t\treturn DM_MAPIO_KILL;\n\t\t}\n\n\t\tdst = kmap_local_page(page);\n\t\tmemcpy_from_bvec(dst, &bv);\n\t\tkunmap_local(dst);\n\t\tblock->vecs[i].bv_page = page;\n\t\tblock->vecs[i].bv_len = bv.bv_len;\n\t\tblock->vec_cnt++;\n\t\ti++;\n\t}\n\n\t \n\tif (flush_bio) {\n\t\tspin_lock_irq(&lc->blocks_lock);\n\t\tlist_splice_init(&lc->unflushed_blocks, &block->list);\n\t\tspin_unlock_irq(&lc->blocks_lock);\n\t}\nmap_bio:\n\tnormal_map_bio(ti, bio);\n\treturn DM_MAPIO_REMAPPED;\n}\n\nstatic int normal_end_io(struct dm_target *ti, struct bio *bio,\n\t\tblk_status_t *error)\n{\n\tstruct log_writes_c *lc = ti->private;\n\tstruct per_bio_data *pb = dm_per_bio_data(bio, sizeof(struct per_bio_data));\n\n\tif (bio_data_dir(bio) == WRITE && pb->block) {\n\t\tstruct pending_block *block = pb->block;\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&lc->blocks_lock, flags);\n\t\tif (block->flags & LOG_FLUSH_FLAG) {\n\t\t\tlist_splice_tail_init(&block->list, &lc->logging_blocks);\n\t\t\tlist_add_tail(&block->list, &lc->logging_blocks);\n\t\t\twake_up_process(lc->log_kthread);\n\t\t} else if (block->flags & LOG_FUA_FLAG) {\n\t\t\tlist_add_tail(&block->list, &lc->logging_blocks);\n\t\t\twake_up_process(lc->log_kthread);\n\t\t} else\n\t\t\tlist_add_tail(&block->list, &lc->unflushed_blocks);\n\t\tspin_unlock_irqrestore(&lc->blocks_lock, flags);\n\t}\n\n\treturn DM_ENDIO_DONE;\n}\n\n \nstatic void log_writes_status(struct dm_target *ti, status_type_t type,\n\t\t\t      unsigned int status_flags, char *result,\n\t\t\t      unsigned int maxlen)\n{\n\tunsigned int sz = 0;\n\tstruct log_writes_c *lc = ti->private;\n\n\tswitch (type) {\n\tcase STATUSTYPE_INFO:\n\t\tDMEMIT(\"%llu %llu\", lc->logged_entries,\n\t\t       (unsigned long long)lc->next_sector - 1);\n\t\tif (!lc->logging_enabled)\n\t\t\tDMEMIT(\" logging_disabled\");\n\t\tbreak;\n\n\tcase STATUSTYPE_TABLE:\n\t\tDMEMIT(\"%s %s\", lc->dev->name, lc->logdev->name);\n\t\tbreak;\n\n\tcase STATUSTYPE_IMA:\n\t\t*result = '\\0';\n\t\tbreak;\n\t}\n}\n\nstatic int log_writes_prepare_ioctl(struct dm_target *ti,\n\t\t\t\t    struct block_device **bdev)\n{\n\tstruct log_writes_c *lc = ti->private;\n\tstruct dm_dev *dev = lc->dev;\n\n\t*bdev = dev->bdev;\n\t \n\tif (ti->len != bdev_nr_sectors(dev->bdev))\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic int log_writes_iterate_devices(struct dm_target *ti,\n\t\t\t\t      iterate_devices_callout_fn fn,\n\t\t\t\t      void *data)\n{\n\tstruct log_writes_c *lc = ti->private;\n\n\treturn fn(ti, lc->dev, 0, ti->len, data);\n}\n\n \nstatic int log_writes_message(struct dm_target *ti, unsigned int argc, char **argv,\n\t\t\t      char *result, unsigned int maxlen)\n{\n\tint r = -EINVAL;\n\tstruct log_writes_c *lc = ti->private;\n\n\tif (argc != 2) {\n\t\tDMWARN(\"Invalid log-writes message arguments, expect 2 arguments, got %d\", argc);\n\t\treturn r;\n\t}\n\n\tif (!strcasecmp(argv[0], \"mark\"))\n\t\tr = log_mark(lc, argv[1]);\n\telse\n\t\tDMWARN(\"Unrecognised log writes target message received: %s\", argv[0]);\n\n\treturn r;\n}\n\nstatic void log_writes_io_hints(struct dm_target *ti, struct queue_limits *limits)\n{\n\tstruct log_writes_c *lc = ti->private;\n\n\tif (!bdev_max_discard_sectors(lc->dev->bdev)) {\n\t\tlc->device_supports_discard = false;\n\t\tlimits->discard_granularity = lc->sectorsize;\n\t\tlimits->max_discard_sectors = (UINT_MAX >> SECTOR_SHIFT);\n\t}\n\tlimits->logical_block_size = bdev_logical_block_size(lc->dev->bdev);\n\tlimits->physical_block_size = bdev_physical_block_size(lc->dev->bdev);\n\tlimits->io_min = limits->physical_block_size;\n\tlimits->dma_alignment = limits->logical_block_size - 1;\n}\n\n#if IS_ENABLED(CONFIG_FS_DAX)\nstatic struct dax_device *log_writes_dax_pgoff(struct dm_target *ti,\n\t\tpgoff_t *pgoff)\n{\n\tstruct log_writes_c *lc = ti->private;\n\n\t*pgoff += (get_start_sect(lc->dev->bdev) >> PAGE_SECTORS_SHIFT);\n\treturn lc->dev->dax_dev;\n}\n\nstatic long log_writes_dax_direct_access(struct dm_target *ti, pgoff_t pgoff,\n\t\tlong nr_pages, enum dax_access_mode mode, void **kaddr,\n\t\tpfn_t *pfn)\n{\n\tstruct dax_device *dax_dev = log_writes_dax_pgoff(ti, &pgoff);\n\n\treturn dax_direct_access(dax_dev, pgoff, nr_pages, mode, kaddr, pfn);\n}\n\nstatic int log_writes_dax_zero_page_range(struct dm_target *ti, pgoff_t pgoff,\n\t\t\t\t\t  size_t nr_pages)\n{\n\tstruct dax_device *dax_dev = log_writes_dax_pgoff(ti, &pgoff);\n\n\treturn dax_zero_page_range(dax_dev, pgoff, nr_pages << PAGE_SHIFT);\n}\n\nstatic size_t log_writes_dax_recovery_write(struct dm_target *ti,\n\t\tpgoff_t pgoff, void *addr, size_t bytes, struct iov_iter *i)\n{\n\tstruct dax_device *dax_dev = log_writes_dax_pgoff(ti, &pgoff);\n\n\treturn dax_recovery_write(dax_dev, pgoff, addr, bytes, i);\n}\n\n#else\n#define log_writes_dax_direct_access NULL\n#define log_writes_dax_zero_page_range NULL\n#define log_writes_dax_recovery_write NULL\n#endif\n\nstatic struct target_type log_writes_target = {\n\t.name   = \"log-writes\",\n\t.version = {1, 1, 0},\n\t.module = THIS_MODULE,\n\t.ctr    = log_writes_ctr,\n\t.dtr    = log_writes_dtr,\n\t.map    = log_writes_map,\n\t.end_io = normal_end_io,\n\t.status = log_writes_status,\n\t.prepare_ioctl = log_writes_prepare_ioctl,\n\t.message = log_writes_message,\n\t.iterate_devices = log_writes_iterate_devices,\n\t.io_hints = log_writes_io_hints,\n\t.direct_access = log_writes_dax_direct_access,\n\t.dax_zero_page_range = log_writes_dax_zero_page_range,\n\t.dax_recovery_write = log_writes_dax_recovery_write,\n};\nmodule_dm(log_writes);\n\nMODULE_DESCRIPTION(DM_NAME \" log writes target\");\nMODULE_AUTHOR(\"Josef Bacik <jbacik@fb.com>\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}