{
  "module_name": "dm-ioctl.c",
  "hash_id": "600d0f283ca07bdeaad8365abf9344e8ed57d2b3801f2faaeb9ff143192cf78b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/md/dm-ioctl.c",
  "human_readable_source": "\n \n\n#include \"dm-core.h\"\n#include \"dm-ima.h\"\n#include <linux/module.h>\n#include <linux/vmalloc.h>\n#include <linux/miscdevice.h>\n#include <linux/sched/mm.h>\n#include <linux/init.h>\n#include <linux/wait.h>\n#include <linux/slab.h>\n#include <linux/rbtree.h>\n#include <linux/dm-ioctl.h>\n#include <linux/hdreg.h>\n#include <linux/compat.h>\n#include <linux/nospec.h>\n\n#include <linux/uaccess.h>\n#include <linux/ima.h>\n\n#define DM_MSG_PREFIX \"ioctl\"\n#define DM_DRIVER_EMAIL \"dm-devel@redhat.com\"\n\nstruct dm_file {\n\t \n\tvolatile unsigned int global_event_nr;\n};\n\n \nstruct hash_cell {\n\tstruct rb_node name_node;\n\tstruct rb_node uuid_node;\n\tbool name_set;\n\tbool uuid_set;\n\n\tchar *name;\n\tchar *uuid;\n\tstruct mapped_device *md;\n\tstruct dm_table *new_map;\n};\n\nstruct vers_iter {\n\tsize_t param_size;\n\tstruct dm_target_versions *vers, *old_vers;\n\tchar *end;\n\tuint32_t flags;\n};\n\n\nstatic struct rb_root name_rb_tree = RB_ROOT;\nstatic struct rb_root uuid_rb_tree = RB_ROOT;\n\nstatic void dm_hash_remove_all(bool keep_open_devices, bool mark_deferred, bool only_deferred);\n\n \nstatic DECLARE_RWSEM(_hash_lock);\n\n \nstatic DEFINE_MUTEX(dm_hash_cells_mutex);\n\nstatic void dm_hash_exit(void)\n{\n\tdm_hash_remove_all(false, false, false);\n}\n\n \nstatic struct hash_cell *__get_name_cell(const char *str)\n{\n\tstruct rb_node *n = name_rb_tree.rb_node;\n\n\twhile (n) {\n\t\tstruct hash_cell *hc = container_of(n, struct hash_cell, name_node);\n\t\tint c;\n\n\t\tc = strcmp(hc->name, str);\n\t\tif (!c) {\n\t\t\tdm_get(hc->md);\n\t\t\treturn hc;\n\t\t}\n\t\tn = c >= 0 ? n->rb_left : n->rb_right;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct hash_cell *__get_uuid_cell(const char *str)\n{\n\tstruct rb_node *n = uuid_rb_tree.rb_node;\n\n\twhile (n) {\n\t\tstruct hash_cell *hc = container_of(n, struct hash_cell, uuid_node);\n\t\tint c;\n\n\t\tc = strcmp(hc->uuid, str);\n\t\tif (!c) {\n\t\t\tdm_get(hc->md);\n\t\t\treturn hc;\n\t\t}\n\t\tn = c >= 0 ? n->rb_left : n->rb_right;\n\t}\n\n\treturn NULL;\n}\n\nstatic void __unlink_name(struct hash_cell *hc)\n{\n\tif (hc->name_set) {\n\t\thc->name_set = false;\n\t\trb_erase(&hc->name_node, &name_rb_tree);\n\t}\n}\n\nstatic void __unlink_uuid(struct hash_cell *hc)\n{\n\tif (hc->uuid_set) {\n\t\thc->uuid_set = false;\n\t\trb_erase(&hc->uuid_node, &uuid_rb_tree);\n\t}\n}\n\nstatic void __link_name(struct hash_cell *new_hc)\n{\n\tstruct rb_node **n, *parent;\n\n\t__unlink_name(new_hc);\n\n\tnew_hc->name_set = true;\n\n\tn = &name_rb_tree.rb_node;\n\tparent = NULL;\n\n\twhile (*n) {\n\t\tstruct hash_cell *hc = container_of(*n, struct hash_cell, name_node);\n\t\tint c;\n\n\t\tc = strcmp(hc->name, new_hc->name);\n\t\tBUG_ON(!c);\n\t\tparent = *n;\n\t\tn = c >= 0 ? &hc->name_node.rb_left : &hc->name_node.rb_right;\n\t}\n\n\trb_link_node(&new_hc->name_node, parent, n);\n\trb_insert_color(&new_hc->name_node, &name_rb_tree);\n}\n\nstatic void __link_uuid(struct hash_cell *new_hc)\n{\n\tstruct rb_node **n, *parent;\n\n\t__unlink_uuid(new_hc);\n\n\tnew_hc->uuid_set = true;\n\n\tn = &uuid_rb_tree.rb_node;\n\tparent = NULL;\n\n\twhile (*n) {\n\t\tstruct hash_cell *hc = container_of(*n, struct hash_cell, uuid_node);\n\t\tint c;\n\n\t\tc = strcmp(hc->uuid, new_hc->uuid);\n\t\tBUG_ON(!c);\n\t\tparent = *n;\n\t\tn = c > 0 ? &hc->uuid_node.rb_left : &hc->uuid_node.rb_right;\n\t}\n\n\trb_link_node(&new_hc->uuid_node, parent, n);\n\trb_insert_color(&new_hc->uuid_node, &uuid_rb_tree);\n}\n\nstatic struct hash_cell *__get_dev_cell(uint64_t dev)\n{\n\tstruct mapped_device *md;\n\tstruct hash_cell *hc;\n\n\tmd = dm_get_md(huge_decode_dev(dev));\n\tif (!md)\n\t\treturn NULL;\n\n\thc = dm_get_mdptr(md);\n\tif (!hc) {\n\t\tdm_put(md);\n\t\treturn NULL;\n\t}\n\n\treturn hc;\n}\n\n \nstatic struct hash_cell *alloc_cell(const char *name, const char *uuid,\n\t\t\t\t    struct mapped_device *md)\n{\n\tstruct hash_cell *hc;\n\n\thc = kmalloc(sizeof(*hc), GFP_KERNEL);\n\tif (!hc)\n\t\treturn NULL;\n\n\thc->name = kstrdup(name, GFP_KERNEL);\n\tif (!hc->name) {\n\t\tkfree(hc);\n\t\treturn NULL;\n\t}\n\n\tif (!uuid)\n\t\thc->uuid = NULL;\n\n\telse {\n\t\thc->uuid = kstrdup(uuid, GFP_KERNEL);\n\t\tif (!hc->uuid) {\n\t\t\tkfree(hc->name);\n\t\t\tkfree(hc);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\thc->name_set = hc->uuid_set = false;\n\thc->md = md;\n\thc->new_map = NULL;\n\treturn hc;\n}\n\nstatic void free_cell(struct hash_cell *hc)\n{\n\tif (hc) {\n\t\tkfree(hc->name);\n\t\tkfree(hc->uuid);\n\t\tkfree(hc);\n\t}\n}\n\n \nstatic int dm_hash_insert(const char *name, const char *uuid, struct mapped_device *md)\n{\n\tstruct hash_cell *cell, *hc;\n\n\t \n\tcell = alloc_cell(name, uuid, md);\n\tif (!cell)\n\t\treturn -ENOMEM;\n\n\t \n\tdown_write(&_hash_lock);\n\thc = __get_name_cell(name);\n\tif (hc) {\n\t\tdm_put(hc->md);\n\t\tgoto bad;\n\t}\n\n\t__link_name(cell);\n\n\tif (uuid) {\n\t\thc = __get_uuid_cell(uuid);\n\t\tif (hc) {\n\t\t\t__unlink_name(cell);\n\t\t\tdm_put(hc->md);\n\t\t\tgoto bad;\n\t\t}\n\t\t__link_uuid(cell);\n\t}\n\tdm_get(md);\n\tmutex_lock(&dm_hash_cells_mutex);\n\tdm_set_mdptr(md, cell);\n\tmutex_unlock(&dm_hash_cells_mutex);\n\tup_write(&_hash_lock);\n\n\treturn 0;\n\n bad:\n\tup_write(&_hash_lock);\n\tfree_cell(cell);\n\treturn -EBUSY;\n}\n\nstatic struct dm_table *__hash_remove(struct hash_cell *hc)\n{\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tlockdep_assert_held(&_hash_lock);\n\n\t \n\t__unlink_name(hc);\n\t__unlink_uuid(hc);\n\tmutex_lock(&dm_hash_cells_mutex);\n\tdm_set_mdptr(hc->md, NULL);\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\ttable = dm_get_live_table(hc->md, &srcu_idx);\n\tif (table)\n\t\tdm_table_event(table);\n\tdm_put_live_table(hc->md, srcu_idx);\n\n\ttable = NULL;\n\tif (hc->new_map)\n\t\ttable = hc->new_map;\n\tdm_put(hc->md);\n\tfree_cell(hc);\n\n\treturn table;\n}\n\nstatic void dm_hash_remove_all(bool keep_open_devices, bool mark_deferred, bool only_deferred)\n{\n\tint dev_skipped;\n\tstruct rb_node *n;\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tstruct dm_table *t;\n\nretry:\n\tdev_skipped = 0;\n\n\tdown_write(&_hash_lock);\n\n\tfor (n = rb_first(&name_rb_tree); n; n = rb_next(n)) {\n\t\thc = container_of(n, struct hash_cell, name_node);\n\t\tmd = hc->md;\n\t\tdm_get(md);\n\n\t\tif (keep_open_devices &&\n\t\t    dm_lock_for_deletion(md, mark_deferred, only_deferred)) {\n\t\t\tdm_put(md);\n\t\t\tdev_skipped++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tt = __hash_remove(hc);\n\n\t\tup_write(&_hash_lock);\n\n\t\tif (t) {\n\t\t\tdm_sync_table(md);\n\t\t\tdm_table_destroy(t);\n\t\t}\n\t\tdm_ima_measure_on_device_remove(md, true);\n\t\tdm_put(md);\n\t\tif (likely(keep_open_devices))\n\t\t\tdm_destroy(md);\n\t\telse\n\t\t\tdm_destroy_immediate(md);\n\n\t\t \n\t\tgoto retry;\n\t}\n\n\tup_write(&_hash_lock);\n\n\tif (dev_skipped)\n\t\tDMWARN(\"remove_all left %d open device(s)\", dev_skipped);\n}\n\n \nstatic void __set_cell_uuid(struct hash_cell *hc, char *new_uuid)\n{\n\tmutex_lock(&dm_hash_cells_mutex);\n\thc->uuid = new_uuid;\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\t__link_uuid(hc);\n}\n\n \nstatic char *__change_cell_name(struct hash_cell *hc, char *new_name)\n{\n\tchar *old_name;\n\n\t \n\t__unlink_name(hc);\n\told_name = hc->name;\n\n\tmutex_lock(&dm_hash_cells_mutex);\n\thc->name = new_name;\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\t__link_name(hc);\n\n\treturn old_name;\n}\n\nstatic struct mapped_device *dm_hash_rename(struct dm_ioctl *param,\n\t\t\t\t\t    const char *new)\n{\n\tchar *new_data, *old_name = NULL;\n\tstruct hash_cell *hc;\n\tstruct dm_table *table;\n\tstruct mapped_device *md;\n\tunsigned int change_uuid = (param->flags & DM_UUID_FLAG) ? 1 : 0;\n\tint srcu_idx;\n\n\t \n\tnew_data = kstrdup(new, GFP_KERNEL);\n\tif (!new_data)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tdown_write(&_hash_lock);\n\n\t \n\tif (change_uuid)\n\t\thc = __get_uuid_cell(new);\n\telse\n\t\thc = __get_name_cell(new);\n\n\tif (hc) {\n\t\tDMERR(\"Unable to change %s on mapped device %s to one that already exists: %s\",\n\t\t      change_uuid ? \"uuid\" : \"name\",\n\t\t      param->name, new);\n\t\tdm_put(hc->md);\n\t\tup_write(&_hash_lock);\n\t\tkfree(new_data);\n\t\treturn ERR_PTR(-EBUSY);\n\t}\n\n\t \n\thc = __get_name_cell(param->name);\n\tif (!hc) {\n\t\tDMERR(\"Unable to rename non-existent device, %s to %s%s\",\n\t\t      param->name, change_uuid ? \"uuid \" : \"\", new);\n\t\tup_write(&_hash_lock);\n\t\tkfree(new_data);\n\t\treturn ERR_PTR(-ENXIO);\n\t}\n\n\t \n\tif (change_uuid && hc->uuid) {\n\t\tDMERR(\"Unable to change uuid of mapped device %s to %s \"\n\t\t      \"because uuid is already set to %s\",\n\t\t      param->name, new, hc->uuid);\n\t\tdm_put(hc->md);\n\t\tup_write(&_hash_lock);\n\t\tkfree(new_data);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (change_uuid)\n\t\t__set_cell_uuid(hc, new_data);\n\telse\n\t\told_name = __change_cell_name(hc, new_data);\n\n\t \n\ttable = dm_get_live_table(hc->md, &srcu_idx);\n\tif (table)\n\t\tdm_table_event(table);\n\tdm_put_live_table(hc->md, srcu_idx);\n\n\tif (!dm_kobject_uevent(hc->md, KOBJ_CHANGE, param->event_nr, false))\n\t\tparam->flags |= DM_UEVENT_GENERATED_FLAG;\n\n\tmd = hc->md;\n\n\tdm_ima_measure_on_device_rename(md);\n\n\tup_write(&_hash_lock);\n\tkfree(old_name);\n\n\treturn md;\n}\n\nvoid dm_deferred_remove(void)\n{\n\tdm_hash_remove_all(true, false, true);\n}\n\n \n \ntypedef int (*ioctl_fn)(struct file *filp, struct dm_ioctl *param, size_t param_size);\n\nstatic int remove_all(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tdm_hash_remove_all(true, !!(param->flags & DM_DEFERRED_REMOVE), false);\n\tparam->data_size = 0;\n\treturn 0;\n}\n\n \n#define ALIGN_MASK 7\nstatic inline size_t align_val(size_t val)\n{\n\treturn (val + ALIGN_MASK) & ~ALIGN_MASK;\n}\nstatic inline void *align_ptr(void *ptr)\n{\n\treturn (void *)align_val((size_t)ptr);\n}\n\n \nstatic void *get_result_buffer(struct dm_ioctl *param, size_t param_size,\n\t\t\t       size_t *len)\n{\n\tparam->data_start = align_ptr(param + 1) - (void *) param;\n\n\tif (param->data_start < param_size)\n\t\t*len = param_size - param->data_start;\n\telse\n\t\t*len = 0;\n\n\treturn ((void *) param) + param->data_start;\n}\n\nstatic bool filter_device(struct hash_cell *hc, const char *pfx_name, const char *pfx_uuid)\n{\n\tconst char *val;\n\tsize_t val_len, pfx_len;\n\n\tval = hc->name;\n\tval_len = strlen(val);\n\tpfx_len = strnlen(pfx_name, DM_NAME_LEN);\n\tif (pfx_len > val_len)\n\t\treturn false;\n\tif (memcmp(val, pfx_name, pfx_len))\n\t\treturn false;\n\n\tval = hc->uuid ? hc->uuid : \"\";\n\tval_len = strlen(val);\n\tpfx_len = strnlen(pfx_uuid, DM_UUID_LEN);\n\tif (pfx_len > val_len)\n\t\treturn false;\n\tif (memcmp(val, pfx_uuid, pfx_len))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int list_devices(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct rb_node *n;\n\tstruct hash_cell *hc;\n\tsize_t len, needed = 0;\n\tstruct gendisk *disk;\n\tstruct dm_name_list *orig_nl, *nl, *old_nl = NULL;\n\tuint32_t *event_nr;\n\n\tdown_write(&_hash_lock);\n\n\t \n\tfor (n = rb_first(&name_rb_tree); n; n = rb_next(n)) {\n\t\thc = container_of(n, struct hash_cell, name_node);\n\t\tif (!filter_device(hc, param->name, param->uuid))\n\t\t\tcontinue;\n\t\tneeded += align_val(offsetof(struct dm_name_list, name) + strlen(hc->name) + 1);\n\t\tneeded += align_val(sizeof(uint32_t) * 2);\n\t\tif (param->flags & DM_UUID_FLAG && hc->uuid)\n\t\t\tneeded += align_val(strlen(hc->uuid) + 1);\n\t}\n\n\t \n\tnl = orig_nl = get_result_buffer(param, param_size, &len);\n\tif (len < needed || len < sizeof(nl->dev)) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\tgoto out;\n\t}\n\tparam->data_size = param->data_start + needed;\n\n\tnl->dev = 0;\t \n\n\t \n\tfor (n = rb_first(&name_rb_tree); n; n = rb_next(n)) {\n\t\tvoid *uuid_ptr;\n\n\t\thc = container_of(n, struct hash_cell, name_node);\n\t\tif (!filter_device(hc, param->name, param->uuid))\n\t\t\tcontinue;\n\t\tif (old_nl)\n\t\t\told_nl->next = (uint32_t) ((void *) nl -\n\t\t\t\t\t\t   (void *) old_nl);\n\t\tdisk = dm_disk(hc->md);\n\t\tnl->dev = huge_encode_dev(disk_devt(disk));\n\t\tnl->next = 0;\n\t\tstrcpy(nl->name, hc->name);\n\n\t\told_nl = nl;\n\t\tevent_nr = align_ptr(nl->name + strlen(hc->name) + 1);\n\t\tevent_nr[0] = dm_get_event_nr(hc->md);\n\t\tevent_nr[1] = 0;\n\t\tuuid_ptr = align_ptr(event_nr + 2);\n\t\tif (param->flags & DM_UUID_FLAG) {\n\t\t\tif (hc->uuid) {\n\t\t\t\tevent_nr[1] |= DM_NAME_LIST_FLAG_HAS_UUID;\n\t\t\t\tstrcpy(uuid_ptr, hc->uuid);\n\t\t\t\tuuid_ptr = align_ptr(uuid_ptr + strlen(hc->uuid) + 1);\n\t\t\t} else {\n\t\t\t\tevent_nr[1] |= DM_NAME_LIST_FLAG_DOESNT_HAVE_UUID;\n\t\t\t}\n\t\t}\n\t\tnl = uuid_ptr;\n\t}\n\t \n\tBUG_ON((char *)nl - (char *)orig_nl != needed);\n\n out:\n\tup_write(&_hash_lock);\n\treturn 0;\n}\n\nstatic void list_version_get_needed(struct target_type *tt, void *needed_param)\n{\n\tsize_t *needed = needed_param;\n\n\t*needed += sizeof(struct dm_target_versions);\n\t*needed += strlen(tt->name) + 1;\n\t*needed += ALIGN_MASK;\n}\n\nstatic void list_version_get_info(struct target_type *tt, void *param)\n{\n\tstruct vers_iter *info = param;\n\n\t \n\tif ((char *)info->vers + sizeof(tt->version) + strlen(tt->name) + 1 > info->end) {\n\t\tinfo->flags = DM_BUFFER_FULL_FLAG;\n\t\treturn;\n\t}\n\n\tif (info->old_vers)\n\t\tinfo->old_vers->next = (uint32_t) ((void *)info->vers - (void *)info->old_vers);\n\n\tinfo->vers->version[0] = tt->version[0];\n\tinfo->vers->version[1] = tt->version[1];\n\tinfo->vers->version[2] = tt->version[2];\n\tinfo->vers->next = 0;\n\tstrcpy(info->vers->name, tt->name);\n\n\tinfo->old_vers = info->vers;\n\tinfo->vers = align_ptr((void *)(info->vers + 1) + strlen(tt->name) + 1);\n}\n\nstatic int __list_versions(struct dm_ioctl *param, size_t param_size, const char *name)\n{\n\tsize_t len, needed = 0;\n\tstruct dm_target_versions *vers;\n\tstruct vers_iter iter_info;\n\tstruct target_type *tt = NULL;\n\n\tif (name) {\n\t\ttt = dm_get_target_type(name);\n\t\tif (!tt)\n\t\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (!tt)\n\t\tdm_target_iterate(list_version_get_needed, &needed);\n\telse\n\t\tlist_version_get_needed(tt, &needed);\n\n\t \n\tvers = get_result_buffer(param, param_size, &len);\n\tif (len < needed) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\tgoto out;\n\t}\n\tparam->data_size = param->data_start + needed;\n\n\titer_info.param_size = param_size;\n\titer_info.old_vers = NULL;\n\titer_info.vers = vers;\n\titer_info.flags = 0;\n\titer_info.end = (char *)vers + needed;\n\n\t \n\tif (!tt)\n\t\tdm_target_iterate(list_version_get_info, &iter_info);\n\telse\n\t\tlist_version_get_info(tt, &iter_info);\n\tparam->flags |= iter_info.flags;\n\n out:\n\tif (tt)\n\t\tdm_put_target_type(tt);\n\treturn 0;\n}\n\nstatic int list_versions(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\treturn __list_versions(param, param_size, NULL);\n}\n\nstatic int get_target_version(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\treturn __list_versions(param, param_size, param->name);\n}\n\nstatic int check_name(const char *name)\n{\n\tif (strchr(name, '/')) {\n\t\tDMERR(\"device name cannot contain '/'\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (strcmp(name, DM_CONTROL_NODE) == 0 ||\n\t    strcmp(name, \".\") == 0 ||\n\t    strcmp(name, \"..\") == 0) {\n\t\tDMERR(\"device name cannot be \\\"%s\\\", \\\".\\\", or \\\"..\\\"\", DM_CONTROL_NODE);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nstatic struct dm_table *dm_get_inactive_table(struct mapped_device *md, int *srcu_idx)\n{\n\tstruct hash_cell *hc;\n\tstruct dm_table *table = NULL;\n\n\t \n\tdm_get_live_table(md, srcu_idx);\n\n\tdown_read(&_hash_lock);\n\thc = dm_get_mdptr(md);\n\tif (!hc) {\n\t\tDMERR(\"device has been removed from the dev hash table.\");\n\t\tgoto out;\n\t}\n\n\ttable = hc->new_map;\n\nout:\n\tup_read(&_hash_lock);\n\n\treturn table;\n}\n\nstatic struct dm_table *dm_get_live_or_inactive_table(struct mapped_device *md,\n\t\t\t\t\t\t      struct dm_ioctl *param,\n\t\t\t\t\t\t      int *srcu_idx)\n{\n\treturn (param->flags & DM_QUERY_INACTIVE_TABLE_FLAG) ?\n\t\tdm_get_inactive_table(md, srcu_idx) : dm_get_live_table(md, srcu_idx);\n}\n\n \nstatic void __dev_status(struct mapped_device *md, struct dm_ioctl *param)\n{\n\tstruct gendisk *disk = dm_disk(md);\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tparam->flags &= ~(DM_SUSPEND_FLAG | DM_READONLY_FLAG |\n\t\t\t  DM_ACTIVE_PRESENT_FLAG | DM_INTERNAL_SUSPEND_FLAG);\n\n\tif (dm_suspended_md(md))\n\t\tparam->flags |= DM_SUSPEND_FLAG;\n\n\tif (dm_suspended_internally_md(md))\n\t\tparam->flags |= DM_INTERNAL_SUSPEND_FLAG;\n\n\tif (dm_test_deferred_remove_flag(md))\n\t\tparam->flags |= DM_DEFERRED_REMOVE;\n\n\tparam->dev = huge_encode_dev(disk_devt(disk));\n\n\t \n\tparam->open_count = dm_open_count(md);\n\n\tparam->event_nr = dm_get_event_nr(md);\n\tparam->target_count = 0;\n\n\ttable = dm_get_live_table(md, &srcu_idx);\n\tif (table) {\n\t\tif (!(param->flags & DM_QUERY_INACTIVE_TABLE_FLAG)) {\n\t\t\tif (get_disk_ro(disk))\n\t\t\t\tparam->flags |= DM_READONLY_FLAG;\n\t\t\tparam->target_count = table->num_targets;\n\t\t}\n\n\t\tparam->flags |= DM_ACTIVE_PRESENT_FLAG;\n\t}\n\tdm_put_live_table(md, srcu_idx);\n\n\tif (param->flags & DM_QUERY_INACTIVE_TABLE_FLAG) {\n\t\tint srcu_idx;\n\n\t\ttable = dm_get_inactive_table(md, &srcu_idx);\n\t\tif (table) {\n\t\t\tif (!(dm_table_get_mode(table) & BLK_OPEN_WRITE))\n\t\t\t\tparam->flags |= DM_READONLY_FLAG;\n\t\t\tparam->target_count = table->num_targets;\n\t\t}\n\t\tdm_put_live_table(md, srcu_idx);\n\t}\n}\n\nstatic int dev_create(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r, m = DM_ANY_MINOR;\n\tstruct mapped_device *md;\n\n\tr = check_name(param->name);\n\tif (r)\n\t\treturn r;\n\n\tif (param->flags & DM_PERSISTENT_DEV_FLAG)\n\t\tm = MINOR(huge_decode_dev(param->dev));\n\n\tr = dm_create(m, &md);\n\tif (r)\n\t\treturn r;\n\n\tr = dm_hash_insert(param->name, *param->uuid ? param->uuid : NULL, md);\n\tif (r) {\n\t\tdm_put(md);\n\t\tdm_destroy(md);\n\t\treturn r;\n\t}\n\n\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\t__dev_status(md, param);\n\n\tdm_put(md);\n\n\treturn 0;\n}\n\n \nstatic struct hash_cell *__find_device_hash_cell(struct dm_ioctl *param)\n{\n\tstruct hash_cell *hc = NULL;\n\n\tif (*param->uuid) {\n\t\tif (*param->name || param->dev) {\n\t\t\tDMERR(\"Invalid ioctl structure: uuid %s, name %s, dev %llx\",\n\t\t\t      param->uuid, param->name, (unsigned long long)param->dev);\n\t\t\treturn NULL;\n\t\t}\n\n\t\thc = __get_uuid_cell(param->uuid);\n\t\tif (!hc)\n\t\t\treturn NULL;\n\t} else if (*param->name) {\n\t\tif (param->dev) {\n\t\t\tDMERR(\"Invalid ioctl structure: name %s, dev %llx\",\n\t\t\t      param->name, (unsigned long long)param->dev);\n\t\t\treturn NULL;\n\t\t}\n\n\t\thc = __get_name_cell(param->name);\n\t\tif (!hc)\n\t\t\treturn NULL;\n\t} else if (param->dev) {\n\t\thc = __get_dev_cell(param->dev);\n\t\tif (!hc)\n\t\t\treturn NULL;\n\t} else\n\t\treturn NULL;\n\n\t \n\tstrscpy(param->name, hc->name, sizeof(param->name));\n\tif (hc->uuid)\n\t\tstrscpy(param->uuid, hc->uuid, sizeof(param->uuid));\n\telse\n\t\tparam->uuid[0] = '\\0';\n\n\tif (hc->new_map)\n\t\tparam->flags |= DM_INACTIVE_PRESENT_FLAG;\n\telse\n\t\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\treturn hc;\n}\n\nstatic struct mapped_device *find_device(struct dm_ioctl *param)\n{\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md = NULL;\n\n\tdown_read(&_hash_lock);\n\thc = __find_device_hash_cell(param);\n\tif (hc)\n\t\tmd = hc->md;\n\tup_read(&_hash_lock);\n\n\treturn md;\n}\n\nstatic int dev_remove(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tint r;\n\tstruct dm_table *t;\n\n\tdown_write(&_hash_lock);\n\thc = __find_device_hash_cell(param);\n\n\tif (!hc) {\n\t\tDMDEBUG_LIMIT(\"device doesn't appear to be in the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\treturn -ENXIO;\n\t}\n\n\tmd = hc->md;\n\n\t \n\tr = dm_lock_for_deletion(md, !!(param->flags & DM_DEFERRED_REMOVE), false);\n\tif (r) {\n\t\tif (r == -EBUSY && param->flags & DM_DEFERRED_REMOVE) {\n\t\t\tup_write(&_hash_lock);\n\t\t\tdm_put(md);\n\t\t\treturn 0;\n\t\t}\n\t\tDMDEBUG_LIMIT(\"unable to remove open device %s\", hc->name);\n\t\tup_write(&_hash_lock);\n\t\tdm_put(md);\n\t\treturn r;\n\t}\n\n\tt = __hash_remove(hc);\n\tup_write(&_hash_lock);\n\n\tif (t) {\n\t\tdm_sync_table(md);\n\t\tdm_table_destroy(t);\n\t}\n\n\tparam->flags &= ~DM_DEFERRED_REMOVE;\n\n\tdm_ima_measure_on_device_remove(md, false);\n\n\tif (!dm_kobject_uevent(md, KOBJ_REMOVE, param->event_nr, false))\n\t\tparam->flags |= DM_UEVENT_GENERATED_FLAG;\n\n\tdm_put(md);\n\tdm_destroy(md);\n\treturn 0;\n}\n\n \nstatic int invalid_str(char *str, void *end)\n{\n\twhile ((void *) str < end)\n\t\tif (!*str++)\n\t\t\treturn 0;\n\n\treturn -EINVAL;\n}\n\nstatic int dev_rename(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r;\n\tchar *new_data = (char *) param + param->data_start;\n\tstruct mapped_device *md;\n\tunsigned int change_uuid = (param->flags & DM_UUID_FLAG) ? 1 : 0;\n\n\tif (new_data < param->data ||\n\t    invalid_str(new_data, (void *) param + param_size) || !*new_data ||\n\t    strlen(new_data) > (change_uuid ? DM_UUID_LEN - 1 : DM_NAME_LEN - 1)) {\n\t\tDMERR(\"Invalid new mapped device name or uuid string supplied.\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!change_uuid) {\n\t\tr = check_name(new_data);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tmd = dm_hash_rename(param, new_data);\n\tif (IS_ERR(md))\n\t\treturn PTR_ERR(md);\n\n\t__dev_status(md, param);\n\tdm_put(md);\n\n\treturn 0;\n}\n\nstatic int dev_set_geometry(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r = -EINVAL, x;\n\tstruct mapped_device *md;\n\tstruct hd_geometry geometry;\n\tunsigned long indata[4];\n\tchar *geostr = (char *) param + param->data_start;\n\tchar dummy;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tif (geostr < param->data ||\n\t    invalid_str(geostr, (void *) param + param_size)) {\n\t\tDMERR(\"Invalid geometry supplied.\");\n\t\tgoto out;\n\t}\n\n\tx = sscanf(geostr, \"%lu %lu %lu %lu%c\", indata,\n\t\t   indata + 1, indata + 2, indata + 3, &dummy);\n\n\tif (x != 4) {\n\t\tDMERR(\"Unable to interpret geometry settings.\");\n\t\tgoto out;\n\t}\n\n\tif (indata[0] > 65535 || indata[1] > 255 || indata[2] > 255) {\n\t\tDMERR(\"Geometry exceeds range limits.\");\n\t\tgoto out;\n\t}\n\n\tgeometry.cylinders = indata[0];\n\tgeometry.heads = indata[1];\n\tgeometry.sectors = indata[2];\n\tgeometry.start = indata[3];\n\n\tr = dm_set_geometry(md, &geometry);\n\n\tparam->data_size = 0;\n\nout:\n\tdm_put(md);\n\treturn r;\n}\n\nstatic int do_suspend(struct dm_ioctl *param)\n{\n\tint r = 0;\n\tunsigned int suspend_flags = DM_SUSPEND_LOCKFS_FLAG;\n\tstruct mapped_device *md;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tif (param->flags & DM_SKIP_LOCKFS_FLAG)\n\t\tsuspend_flags &= ~DM_SUSPEND_LOCKFS_FLAG;\n\tif (param->flags & DM_NOFLUSH_FLAG)\n\t\tsuspend_flags |= DM_SUSPEND_NOFLUSH_FLAG;\n\n\tif (!dm_suspended_md(md)) {\n\t\tr = dm_suspend(md, suspend_flags);\n\t\tif (r)\n\t\t\tgoto out;\n\t}\n\n\t__dev_status(md, param);\n\nout:\n\tdm_put(md);\n\n\treturn r;\n}\n\nstatic int do_resume(struct dm_ioctl *param)\n{\n\tint r = 0;\n\tunsigned int suspend_flags = DM_SUSPEND_LOCKFS_FLAG;\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tstruct dm_table *new_map, *old_map = NULL;\n\tbool need_resize_uevent = false;\n\n\tdown_write(&_hash_lock);\n\n\thc = __find_device_hash_cell(param);\n\tif (!hc) {\n\t\tDMDEBUG_LIMIT(\"device doesn't appear to be in the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\treturn -ENXIO;\n\t}\n\n\tmd = hc->md;\n\n\tnew_map = hc->new_map;\n\thc->new_map = NULL;\n\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\tup_write(&_hash_lock);\n\n\t \n\tif (new_map) {\n\t\tsector_t old_size, new_size;\n\n\t\t \n\t\tif (param->flags & DM_SKIP_LOCKFS_FLAG)\n\t\t\tsuspend_flags &= ~DM_SUSPEND_LOCKFS_FLAG;\n\t\tif (param->flags & DM_NOFLUSH_FLAG)\n\t\t\tsuspend_flags |= DM_SUSPEND_NOFLUSH_FLAG;\n\t\tif (!dm_suspended_md(md))\n\t\t\tdm_suspend(md, suspend_flags);\n\n\t\told_size = dm_get_size(md);\n\t\told_map = dm_swap_table(md, new_map);\n\t\tif (IS_ERR(old_map)) {\n\t\t\tdm_sync_table(md);\n\t\t\tdm_table_destroy(new_map);\n\t\t\tdm_put(md);\n\t\t\treturn PTR_ERR(old_map);\n\t\t}\n\t\tnew_size = dm_get_size(md);\n\t\tif (old_size && new_size && old_size != new_size)\n\t\t\tneed_resize_uevent = true;\n\n\t\tif (dm_table_get_mode(new_map) & BLK_OPEN_WRITE)\n\t\t\tset_disk_ro(dm_disk(md), 0);\n\t\telse\n\t\t\tset_disk_ro(dm_disk(md), 1);\n\t}\n\n\tif (dm_suspended_md(md)) {\n\t\tr = dm_resume(md);\n\t\tif (!r) {\n\t\t\tdm_ima_measure_on_device_resume(md, new_map ? true : false);\n\n\t\t\tif (!dm_kobject_uevent(md, KOBJ_CHANGE, param->event_nr, need_resize_uevent))\n\t\t\t\tparam->flags |= DM_UEVENT_GENERATED_FLAG;\n\t\t}\n\t}\n\n\t \n\tif (old_map)\n\t\tdm_table_destroy(old_map);\n\n\tif (!r)\n\t\t__dev_status(md, param);\n\n\tdm_put(md);\n\treturn r;\n}\n\n \nstatic int dev_suspend(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tif (param->flags & DM_SUSPEND_FLAG)\n\t\treturn do_suspend(param);\n\n\treturn do_resume(param);\n}\n\n \nstatic int dev_status(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct mapped_device *md;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t__dev_status(md, param);\n\tdm_put(md);\n\n\treturn 0;\n}\n\n \nstatic void retrieve_status(struct dm_table *table,\n\t\t\t    struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int i, num_targets;\n\tstruct dm_target_spec *spec;\n\tchar *outbuf, *outptr;\n\tstatus_type_t type;\n\tsize_t remaining, len, used = 0;\n\tunsigned int status_flags = 0;\n\n\toutptr = outbuf = get_result_buffer(param, param_size, &len);\n\n\tif (param->flags & DM_STATUS_TABLE_FLAG)\n\t\ttype = STATUSTYPE_TABLE;\n\telse if (param->flags & DM_IMA_MEASUREMENT_FLAG)\n\t\ttype = STATUSTYPE_IMA;\n\telse\n\t\ttype = STATUSTYPE_INFO;\n\n\t \n\tnum_targets = table->num_targets;\n\tfor (i = 0; i < num_targets; i++) {\n\t\tstruct dm_target *ti = dm_table_get_target(table, i);\n\t\tsize_t l;\n\n\t\tremaining = len - (outptr - outbuf);\n\t\tif (remaining <= sizeof(struct dm_target_spec)) {\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\t\tbreak;\n\t\t}\n\n\t\tspec = (struct dm_target_spec *) outptr;\n\n\t\tspec->status = 0;\n\t\tspec->sector_start = ti->begin;\n\t\tspec->length = ti->len;\n\t\tstrncpy(spec->target_type, ti->type->name,\n\t\t\tsizeof(spec->target_type) - 1);\n\n\t\toutptr += sizeof(struct dm_target_spec);\n\t\tremaining = len - (outptr - outbuf);\n\t\tif (remaining <= 0) {\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (ti->type->status) {\n\t\t\tif (param->flags & DM_NOFLUSH_FLAG)\n\t\t\t\tstatus_flags |= DM_STATUS_NOFLUSH_FLAG;\n\t\t\tti->type->status(ti, type, status_flags, outptr, remaining);\n\t\t} else\n\t\t\toutptr[0] = '\\0';\n\n\t\tl = strlen(outptr) + 1;\n\t\tif (l == remaining) {\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\t\tbreak;\n\t\t}\n\n\t\toutptr += l;\n\t\tused = param->data_start + (outptr - outbuf);\n\n\t\toutptr = align_ptr(outptr);\n\t\tspec->next = outptr - outbuf;\n\t}\n\n\tif (used)\n\t\tparam->data_size = used;\n\n\tparam->target_count = num_targets;\n}\n\n \nstatic int dev_wait(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r = 0;\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t \n\tif (dm_wait_event(md, param->event_nr)) {\n\t\tr = -ERESTARTSYS;\n\t\tgoto out;\n\t}\n\n\t \n\t__dev_status(md, param);\n\n\ttable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\n\tif (table)\n\t\tretrieve_status(table, param, param_size);\n\tdm_put_live_table(md, srcu_idx);\n\nout:\n\tdm_put(md);\n\n\treturn r;\n}\n\n \nstatic int dev_arm_poll(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct dm_file *priv = filp->private_data;\n\n\tpriv->global_event_nr = atomic_read(&dm_global_event_nr);\n\n\treturn 0;\n}\n\nstatic inline blk_mode_t get_mode(struct dm_ioctl *param)\n{\n\tblk_mode_t mode = BLK_OPEN_READ | BLK_OPEN_WRITE;\n\n\tif (param->flags & DM_READONLY_FLAG)\n\t\tmode = BLK_OPEN_READ;\n\n\treturn mode;\n}\n\nstatic int next_target(struct dm_target_spec *last, uint32_t next, const char *end,\n\t\t       struct dm_target_spec **spec, char **target_params)\n{\n\tstatic_assert(__alignof__(struct dm_target_spec) <= 8,\n\t\t\"struct dm_target_spec must not require more than 8-byte alignment\");\n\n\t \n\tsize_t remaining = end - (char *)last;\n\n\t \n\tif (remaining - sizeof(struct dm_target_spec) <= next) {\n\t\tDMERR(\"Target spec extends beyond end of parameters\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (next % __alignof__(struct dm_target_spec)) {\n\t\tDMERR(\"Next dm_target_spec (offset %u) is not %zu-byte aligned\",\n\t\t      next, __alignof__(struct dm_target_spec));\n\t\treturn -EINVAL;\n\t}\n\n\t*spec = (struct dm_target_spec *) ((unsigned char *) last + next);\n\t*target_params = (char *) (*spec + 1);\n\n\treturn 0;\n}\n\nstatic int populate_table(struct dm_table *table,\n\t\t\t  struct dm_ioctl *param, size_t param_size)\n{\n\tint r;\n\tunsigned int i = 0;\n\tstruct dm_target_spec *spec = (struct dm_target_spec *) param;\n\tuint32_t next = param->data_start;\n\tconst char *const end = (const char *) param + param_size;\n\tchar *target_params;\n\tsize_t min_size = sizeof(struct dm_ioctl);\n\n\tif (!param->target_count) {\n\t\tDMERR(\"%s: no targets specified\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < param->target_count; i++) {\n\t\tconst char *nul_terminator;\n\n\t\tif (next < min_size) {\n\t\t\tDMERR(\"%s: next target spec (offset %u) overlaps %s\",\n\t\t\t      __func__, next, i ? \"previous target\" : \"'struct dm_ioctl'\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tr = next_target(spec, next, end, &spec, &target_params);\n\t\tif (r) {\n\t\t\tDMERR(\"unable to find target\");\n\t\t\treturn r;\n\t\t}\n\n\t\tnul_terminator = memchr(target_params, 0, (size_t)(end - target_params));\n\t\tif (nul_terminator == NULL) {\n\t\t\tDMERR(\"%s: target parameters not NUL-terminated\", __func__);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tmin_size = (size_t)(nul_terminator - (const char *)spec) + 1;\n\n\t\tr = dm_table_add_target(table, spec->target_type,\n\t\t\t\t\t(sector_t) spec->sector_start,\n\t\t\t\t\t(sector_t) spec->length,\n\t\t\t\t\ttarget_params);\n\t\tif (r) {\n\t\t\tDMERR(\"error adding target to table\");\n\t\t\treturn r;\n\t\t}\n\n\t\tnext = spec->next;\n\t}\n\n\treturn dm_table_complete(table);\n}\n\nstatic bool is_valid_type(enum dm_queue_mode cur, enum dm_queue_mode new)\n{\n\tif (cur == new ||\n\t    (cur == DM_TYPE_BIO_BASED && new == DM_TYPE_DAX_BIO_BASED))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int table_load(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r;\n\tstruct hash_cell *hc;\n\tstruct dm_table *t, *old_map = NULL;\n\tstruct mapped_device *md;\n\tstruct target_type *immutable_target_type;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tr = dm_table_create(&t, get_mode(param), param->target_count, md);\n\tif (r)\n\t\tgoto err;\n\n\t \n\tdm_lock_md_type(md);\n\tr = populate_table(t, param, param_size);\n\tif (r)\n\t\tgoto err_unlock_md_type;\n\n\tdm_ima_measure_on_table_load(t, STATUSTYPE_IMA);\n\n\timmutable_target_type = dm_get_immutable_target_type(md);\n\tif (immutable_target_type &&\n\t    (immutable_target_type != dm_table_get_immutable_target_type(t)) &&\n\t    !dm_table_get_wildcard_target(t)) {\n\t\tDMERR(\"can't replace immutable target type %s\",\n\t\t      immutable_target_type->name);\n\t\tr = -EINVAL;\n\t\tgoto err_unlock_md_type;\n\t}\n\n\tif (dm_get_md_type(md) == DM_TYPE_NONE) {\n\t\t \n\t\tr = dm_setup_md_queue(md, t);\n\t\tif (r) {\n\t\t\tDMERR(\"unable to set up device queue for new table.\");\n\t\t\tgoto err_unlock_md_type;\n\t\t}\n\t} else if (!is_valid_type(dm_get_md_type(md), dm_table_get_type(t))) {\n\t\tDMERR(\"can't change device type (old=%u vs new=%u) after initial table load.\",\n\t\t      dm_get_md_type(md), dm_table_get_type(t));\n\t\tr = -EINVAL;\n\t\tgoto err_unlock_md_type;\n\t}\n\n\tdm_unlock_md_type(md);\n\n\t \n\tdown_write(&_hash_lock);\n\thc = dm_get_mdptr(md);\n\tif (!hc) {\n\t\tDMERR(\"device has been removed from the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\tr = -ENXIO;\n\t\tgoto err_destroy_table;\n\t}\n\n\tif (hc->new_map)\n\t\told_map = hc->new_map;\n\thc->new_map = t;\n\tup_write(&_hash_lock);\n\n\tparam->flags |= DM_INACTIVE_PRESENT_FLAG;\n\t__dev_status(md, param);\n\n\tif (old_map) {\n\t\tdm_sync_table(md);\n\t\tdm_table_destroy(old_map);\n\t}\n\n\tdm_put(md);\n\n\treturn 0;\n\nerr_unlock_md_type:\n\tdm_unlock_md_type(md);\nerr_destroy_table:\n\tdm_table_destroy(t);\nerr:\n\tdm_put(md);\n\n\treturn r;\n}\n\nstatic int table_clear(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tstruct dm_table *old_map = NULL;\n\tbool has_new_map = false;\n\n\tdown_write(&_hash_lock);\n\n\thc = __find_device_hash_cell(param);\n\tif (!hc) {\n\t\tDMDEBUG_LIMIT(\"device doesn't appear to be in the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\treturn -ENXIO;\n\t}\n\n\tif (hc->new_map) {\n\t\told_map = hc->new_map;\n\t\thc->new_map = NULL;\n\t\thas_new_map = true;\n\t}\n\n\tmd = hc->md;\n\tup_write(&_hash_lock);\n\n\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\t__dev_status(md, param);\n\n\tif (old_map) {\n\t\tdm_sync_table(md);\n\t\tdm_table_destroy(old_map);\n\t}\n\tdm_ima_measure_on_table_clear(md, has_new_map);\n\tdm_put(md);\n\n\treturn 0;\n}\n\n \nstatic void retrieve_deps(struct dm_table *table,\n\t\t\t  struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int count = 0;\n\tstruct list_head *tmp;\n\tsize_t len, needed;\n\tstruct dm_dev_internal *dd;\n\tstruct dm_target_deps *deps;\n\n\tdown_read(&table->devices_lock);\n\n\tdeps = get_result_buffer(param, param_size, &len);\n\n\t \n\tlist_for_each(tmp, dm_table_get_devices(table))\n\t\tcount++;\n\n\t \n\tneeded = struct_size(deps, dev, count);\n\tif (len < needed) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\tgoto out;\n\t}\n\n\t \n\tdeps->count = count;\n\tcount = 0;\n\tlist_for_each_entry(dd, dm_table_get_devices(table), list)\n\t\tdeps->dev[count++] = huge_encode_dev(dd->dm_dev->bdev->bd_dev);\n\n\tparam->data_size = param->data_start + needed;\n\nout:\n\tup_read(&table->devices_lock);\n}\n\nstatic int table_deps(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t__dev_status(md, param);\n\n\ttable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\n\tif (table)\n\t\tretrieve_deps(table, param, param_size);\n\tdm_put_live_table(md, srcu_idx);\n\n\tdm_put(md);\n\n\treturn 0;\n}\n\n \nstatic int table_status(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t__dev_status(md, param);\n\n\ttable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\n\tif (table)\n\t\tretrieve_status(table, param, param_size);\n\tdm_put_live_table(md, srcu_idx);\n\n\tdm_put(md);\n\n\treturn 0;\n}\n\n \nstatic int message_for_md(struct mapped_device *md, unsigned int argc, char **argv,\n\t\t\t  char *result, unsigned int maxlen)\n{\n\tint r;\n\n\tif (**argv != '@')\n\t\treturn 2;  \n\n\tif (!strcasecmp(argv[0], \"@cancel_deferred_remove\")) {\n\t\tif (argc != 1) {\n\t\t\tDMERR(\"Invalid arguments for @cancel_deferred_remove\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn dm_cancel_deferred_remove(md);\n\t}\n\n\tr = dm_stats_message(md, argc, argv, result, maxlen);\n\tif (r < 2)\n\t\treturn r;\n\n\tDMERR(\"Unsupported message sent to DM core: %s\", argv[0]);\n\treturn -EINVAL;\n}\n\n \nstatic int target_message(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r, argc;\n\tchar **argv;\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tstruct dm_target *ti;\n\tstruct dm_target_msg *tmsg = (void *) param + param->data_start;\n\tsize_t maxlen;\n\tchar *result = get_result_buffer(param, param_size, &maxlen);\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tif (tmsg < (struct dm_target_msg *) param->data ||\n\t    invalid_str(tmsg->message, (void *) param + param_size)) {\n\t\tDMERR(\"Invalid target message parameters.\");\n\t\tr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tr = dm_split_args(&argc, &argv, tmsg->message);\n\tif (r) {\n\t\tDMERR(\"Failed to split target message parameters\");\n\t\tgoto out;\n\t}\n\n\tif (!argc) {\n\t\tDMERR(\"Empty message received.\");\n\t\tr = -EINVAL;\n\t\tgoto out_argv;\n\t}\n\n\tr = message_for_md(md, argc, argv, result, maxlen);\n\tif (r <= 1)\n\t\tgoto out_argv;\n\n\ttable = dm_get_live_table(md, &srcu_idx);\n\tif (!table)\n\t\tgoto out_table;\n\n\tif (dm_deleting_md(md)) {\n\t\tr = -ENXIO;\n\t\tgoto out_table;\n\t}\n\n\tti = dm_table_find_target(table, tmsg->sector);\n\tif (!ti) {\n\t\tDMERR(\"Target message sector outside device.\");\n\t\tr = -EINVAL;\n\t} else if (ti->type->message)\n\t\tr = ti->type->message(ti, argc, argv, result, maxlen);\n\telse {\n\t\tDMERR(\"Target type does not support messages\");\n\t\tr = -EINVAL;\n\t}\n\n out_table:\n\tdm_put_live_table(md, srcu_idx);\n out_argv:\n\tkfree(argv);\n out:\n\tif (r >= 0)\n\t\t__dev_status(md, param);\n\n\tif (r == 1) {\n\t\tparam->flags |= DM_DATA_OUT_FLAG;\n\t\tif (dm_message_test_buffer_overflow(result, maxlen))\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\telse\n\t\t\tparam->data_size = param->data_start + strlen(result) + 1;\n\t\tr = 0;\n\t}\n\n\tdm_put(md);\n\treturn r;\n}\n\n \n#define IOCTL_FLAGS_NO_PARAMS\t\t1\n#define IOCTL_FLAGS_ISSUE_GLOBAL_EVENT\t2\n\n \nstatic ioctl_fn lookup_ioctl(unsigned int cmd, int *ioctl_flags)\n{\n\tstatic const struct {\n\t\tint cmd;\n\t\tint flags;\n\t\tioctl_fn fn;\n\t} _ioctls[] = {\n\t\t{DM_VERSION_CMD, 0, NULL},  \n\t\t{DM_REMOVE_ALL_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, remove_all},\n\t\t{DM_LIST_DEVICES_CMD, 0, list_devices},\n\n\t\t{DM_DEV_CREATE_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_create},\n\t\t{DM_DEV_REMOVE_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_remove},\n\t\t{DM_DEV_RENAME_CMD, IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_rename},\n\t\t{DM_DEV_SUSPEND_CMD, IOCTL_FLAGS_NO_PARAMS, dev_suspend},\n\t\t{DM_DEV_STATUS_CMD, IOCTL_FLAGS_NO_PARAMS, dev_status},\n\t\t{DM_DEV_WAIT_CMD, 0, dev_wait},\n\n\t\t{DM_TABLE_LOAD_CMD, 0, table_load},\n\t\t{DM_TABLE_CLEAR_CMD, IOCTL_FLAGS_NO_PARAMS, table_clear},\n\t\t{DM_TABLE_DEPS_CMD, 0, table_deps},\n\t\t{DM_TABLE_STATUS_CMD, 0, table_status},\n\n\t\t{DM_LIST_VERSIONS_CMD, 0, list_versions},\n\n\t\t{DM_TARGET_MSG_CMD, 0, target_message},\n\t\t{DM_DEV_SET_GEOMETRY_CMD, 0, dev_set_geometry},\n\t\t{DM_DEV_ARM_POLL_CMD, IOCTL_FLAGS_NO_PARAMS, dev_arm_poll},\n\t\t{DM_GET_TARGET_VERSION_CMD, 0, get_target_version},\n\t};\n\n\tif (unlikely(cmd >= ARRAY_SIZE(_ioctls)))\n\t\treturn NULL;\n\n\tcmd = array_index_nospec(cmd, ARRAY_SIZE(_ioctls));\n\t*ioctl_flags = _ioctls[cmd].flags;\n\treturn _ioctls[cmd].fn;\n}\n\n \nstatic int check_version(unsigned int cmd, struct dm_ioctl __user *user,\n\t\t\t struct dm_ioctl *kernel_params)\n{\n\tint r = 0;\n\n\t \n\tBUILD_BUG_ON(offsetof(struct dm_ioctl, version) != 0);\n\n\tif (copy_from_user(kernel_params->version, user->version, sizeof(kernel_params->version)))\n\t\treturn -EFAULT;\n\n\tif ((kernel_params->version[0] != DM_VERSION_MAJOR) ||\n\t    (kernel_params->version[1] > DM_VERSION_MINOR)) {\n\t\tDMERR(\"ioctl interface mismatch: kernel(%u.%u.%u), user(%u.%u.%u), cmd(%d)\",\n\t\t      DM_VERSION_MAJOR, DM_VERSION_MINOR,\n\t\t      DM_VERSION_PATCHLEVEL,\n\t\t      kernel_params->version[0],\n\t\t      kernel_params->version[1],\n\t\t      kernel_params->version[2],\n\t\t      cmd);\n\t\tr = -EINVAL;\n\t}\n\n\t \n\tkernel_params->version[0] = DM_VERSION_MAJOR;\n\tkernel_params->version[1] = DM_VERSION_MINOR;\n\tkernel_params->version[2] = DM_VERSION_PATCHLEVEL;\n\tif (copy_to_user(user->version, kernel_params->version, sizeof(kernel_params->version)))\n\t\treturn -EFAULT;\n\n\treturn r;\n}\n\n#define DM_PARAMS_MALLOC\t0x0001\t \n#define DM_WIPE_BUFFER\t\t0x0010\t \n\nstatic void free_params(struct dm_ioctl *param, size_t param_size, int param_flags)\n{\n\tif (param_flags & DM_WIPE_BUFFER)\n\t\tmemset(param, 0, param_size);\n\n\tif (param_flags & DM_PARAMS_MALLOC)\n\t\tkvfree(param);\n}\n\nstatic int copy_params(struct dm_ioctl __user *user, struct dm_ioctl *param_kernel,\n\t\t       int ioctl_flags, struct dm_ioctl **param, int *param_flags)\n{\n\tstruct dm_ioctl *dmi;\n\tint secure_data;\n\tconst size_t minimum_data_size = offsetof(struct dm_ioctl, data);\n\n\t \n\tif (copy_from_user((char *)param_kernel + sizeof(param_kernel->version),\n\t\t\t   (char __user *)user + sizeof(param_kernel->version),\n\t\t\t   minimum_data_size - sizeof(param_kernel->version)))\n\t\treturn -EFAULT;\n\n\tif (param_kernel->data_size < minimum_data_size) {\n\t\tDMERR(\"Invalid data size in the ioctl structure: %u\",\n\t\t      param_kernel->data_size);\n\t\treturn -EINVAL;\n\t}\n\n\tsecure_data = param_kernel->flags & DM_SECURE_DATA_FLAG;\n\n\t*param_flags = secure_data ? DM_WIPE_BUFFER : 0;\n\n\tif (ioctl_flags & IOCTL_FLAGS_NO_PARAMS) {\n\t\tdmi = param_kernel;\n\t\tdmi->data_size = minimum_data_size;\n\t\tgoto data_copied;\n\t}\n\n\t \n\tdmi = NULL;\n\tdmi = kvmalloc(param_kernel->data_size, GFP_NOIO | __GFP_HIGH);\n\n\tif (!dmi) {\n\t\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\t\treturn -EFAULT;\n\t\treturn -ENOMEM;\n\t}\n\n\t*param_flags |= DM_PARAMS_MALLOC;\n\n\t \n\tmemcpy(dmi, param_kernel, minimum_data_size);\n\n\tif (copy_from_user(&dmi->data, (char __user *)user + minimum_data_size,\n\t\t\t   param_kernel->data_size - minimum_data_size))\n\t\tgoto bad;\ndata_copied:\n\t \n\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\tgoto bad;\n\n\t*param = dmi;\n\treturn 0;\n\nbad:\n\tfree_params(dmi, param_kernel->data_size, *param_flags);\n\n\treturn -EFAULT;\n}\n\nstatic int validate_params(uint cmd, struct dm_ioctl *param)\n{\n\t \n\tparam->flags &= ~DM_BUFFER_FULL_FLAG;\n\tparam->flags &= ~DM_UEVENT_GENERATED_FLAG;\n\tparam->flags &= ~DM_SECURE_DATA_FLAG;\n\tparam->flags &= ~DM_DATA_OUT_FLAG;\n\n\t \n\tif (cmd == DM_REMOVE_ALL_CMD ||\n\t    cmd == DM_LIST_DEVICES_CMD ||\n\t    cmd == DM_LIST_VERSIONS_CMD)\n\t\treturn 0;\n\n\tif (cmd == DM_DEV_CREATE_CMD) {\n\t\tif (!*param->name) {\n\t\t\tDMERR(\"name not supplied when creating device\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (*param->uuid && *param->name) {\n\t\tDMERR(\"only supply one of name or uuid, cmd(%u)\", cmd);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tparam->name[DM_NAME_LEN - 1] = '\\0';\n\tparam->uuid[DM_UUID_LEN - 1] = '\\0';\n\n\treturn 0;\n}\n\nstatic int ctl_ioctl(struct file *file, uint command, struct dm_ioctl __user *user)\n{\n\tint r = 0;\n\tint ioctl_flags;\n\tint param_flags;\n\tunsigned int cmd;\n\tstruct dm_ioctl *param;\n\tioctl_fn fn = NULL;\n\tsize_t input_param_size;\n\tstruct dm_ioctl param_kernel;\n\n\t \n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EACCES;\n\n\tif (_IOC_TYPE(command) != DM_IOCTL)\n\t\treturn -ENOTTY;\n\n\tcmd = _IOC_NR(command);\n\n\t \n\tr = check_version(cmd, user, &param_kernel);\n\tif (r)\n\t\treturn r;\n\n\t \n\tif (cmd == DM_VERSION_CMD)\n\t\treturn 0;\n\n\tfn = lookup_ioctl(cmd, &ioctl_flags);\n\tif (!fn) {\n\t\tDMERR(\"dm_ctl_ioctl: unknown command 0x%x\", command);\n\t\treturn -ENOTTY;\n\t}\n\n\t \n\tr = copy_params(user, &param_kernel, ioctl_flags, &param, &param_flags);\n\n\tif (r)\n\t\treturn r;\n\n\tinput_param_size = param->data_size;\n\tr = validate_params(cmd, param);\n\tif (r)\n\t\tgoto out;\n\n\tparam->data_size = offsetof(struct dm_ioctl, data);\n\tr = fn(file, param, input_param_size);\n\n\tif (unlikely(param->flags & DM_BUFFER_FULL_FLAG) &&\n\t    unlikely(ioctl_flags & IOCTL_FLAGS_NO_PARAMS))\n\t\tDMERR(\"ioctl %d tried to output some data but has IOCTL_FLAGS_NO_PARAMS set\", cmd);\n\n\tif (!r && ioctl_flags & IOCTL_FLAGS_ISSUE_GLOBAL_EVENT)\n\t\tdm_issue_global_event();\n\n\t \n\tif (!r && copy_to_user(user, param, param->data_size))\n\t\tr = -EFAULT;\n\nout:\n\tfree_params(param, input_param_size, param_flags);\n\treturn r;\n}\n\nstatic long dm_ctl_ioctl(struct file *file, uint command, ulong u)\n{\n\treturn (long)ctl_ioctl(file, command, (struct dm_ioctl __user *)u);\n}\n\n#ifdef CONFIG_COMPAT\nstatic long dm_compat_ctl_ioctl(struct file *file, uint command, ulong u)\n{\n\treturn (long)dm_ctl_ioctl(file, command, (ulong) compat_ptr(u));\n}\n#else\n#define dm_compat_ctl_ioctl NULL\n#endif\n\nstatic int dm_open(struct inode *inode, struct file *filp)\n{\n\tint r;\n\tstruct dm_file *priv;\n\n\tr = nonseekable_open(inode, filp);\n\tif (unlikely(r))\n\t\treturn r;\n\n\tpriv = filp->private_data = kmalloc(sizeof(struct dm_file), GFP_KERNEL);\n\tif (!priv)\n\t\treturn -ENOMEM;\n\n\tpriv->global_event_nr = atomic_read(&dm_global_event_nr);\n\n\treturn 0;\n}\n\nstatic int dm_release(struct inode *inode, struct file *filp)\n{\n\tkfree(filp->private_data);\n\treturn 0;\n}\n\nstatic __poll_t dm_poll(struct file *filp, poll_table *wait)\n{\n\tstruct dm_file *priv = filp->private_data;\n\t__poll_t mask = 0;\n\n\tpoll_wait(filp, &dm_global_eventq, wait);\n\n\tif ((int)(atomic_read(&dm_global_event_nr) - priv->global_event_nr) > 0)\n\t\tmask |= EPOLLIN;\n\n\treturn mask;\n}\n\nstatic const struct file_operations _ctl_fops = {\n\t.open    = dm_open,\n\t.release = dm_release,\n\t.poll    = dm_poll,\n\t.unlocked_ioctl\t = dm_ctl_ioctl,\n\t.compat_ioctl = dm_compat_ctl_ioctl,\n\t.owner\t = THIS_MODULE,\n\t.llseek  = noop_llseek,\n};\n\nstatic struct miscdevice _dm_misc = {\n\t.minor\t\t= MAPPER_CTRL_MINOR,\n\t.name\t\t= DM_NAME,\n\t.nodename\t= DM_DIR \"/\" DM_CONTROL_NODE,\n\t.fops\t\t= &_ctl_fops\n};\n\nMODULE_ALIAS_MISCDEV(MAPPER_CTRL_MINOR);\nMODULE_ALIAS(\"devname:\" DM_DIR \"/\" DM_CONTROL_NODE);\n\n \nint __init dm_interface_init(void)\n{\n\tint r;\n\n\tr = misc_register(&_dm_misc);\n\tif (r) {\n\t\tDMERR(\"misc_register failed for control device\");\n\t\treturn r;\n\t}\n\n\tDMINFO(\"%d.%d.%d%s initialised: %s\", DM_VERSION_MAJOR,\n\t       DM_VERSION_MINOR, DM_VERSION_PATCHLEVEL, DM_VERSION_EXTRA,\n\t       DM_DRIVER_EMAIL);\n\treturn 0;\n}\n\nvoid dm_interface_exit(void)\n{\n\tmisc_deregister(&_dm_misc);\n\tdm_hash_exit();\n}\n\n \nint dm_copy_name_and_uuid(struct mapped_device *md, char *name, char *uuid)\n{\n\tint r = 0;\n\tstruct hash_cell *hc;\n\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tmutex_lock(&dm_hash_cells_mutex);\n\thc = dm_get_mdptr(md);\n\tif (!hc) {\n\t\tr = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tif (name)\n\t\tstrcpy(name, hc->name);\n\tif (uuid)\n\t\tstrcpy(uuid, hc->uuid ? : \"\");\n\nout:\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(dm_copy_name_and_uuid);\n\n \nint __init dm_early_create(struct dm_ioctl *dmi,\n\t\t\t   struct dm_target_spec **spec_array,\n\t\t\t   char **target_params_array)\n{\n\tint r, m = DM_ANY_MINOR;\n\tstruct dm_table *t, *old_map;\n\tstruct mapped_device *md;\n\tunsigned int i;\n\n\tif (!dmi->target_count)\n\t\treturn -EINVAL;\n\n\tr = check_name(dmi->name);\n\tif (r)\n\t\treturn r;\n\n\tif (dmi->flags & DM_PERSISTENT_DEV_FLAG)\n\t\tm = MINOR(huge_decode_dev(dmi->dev));\n\n\t \n\tr = dm_create(m, &md);\n\tif (r)\n\t\treturn r;\n\n\t \n\tr = dm_hash_insert(dmi->name, *dmi->uuid ? dmi->uuid : NULL, md);\n\tif (r)\n\t\tgoto err_destroy_dm;\n\n\t \n\tr = dm_table_create(&t, get_mode(dmi), dmi->target_count, md);\n\tif (r)\n\t\tgoto err_hash_remove;\n\n\t \n\tfor (i = 0; i < dmi->target_count; i++) {\n\t\tr = dm_table_add_target(t, spec_array[i]->target_type,\n\t\t\t\t\t(sector_t) spec_array[i]->sector_start,\n\t\t\t\t\t(sector_t) spec_array[i]->length,\n\t\t\t\t\ttarget_params_array[i]);\n\t\tif (r) {\n\t\t\tDMERR(\"error adding target to table\");\n\t\t\tgoto err_destroy_table;\n\t\t}\n\t}\n\n\t \n\tr = dm_table_complete(t);\n\tif (r)\n\t\tgoto err_destroy_table;\n\n\t \n\tr = dm_setup_md_queue(md, t);\n\tif (r) {\n\t\tDMERR(\"unable to set up device queue for new table.\");\n\t\tgoto err_destroy_table;\n\t}\n\n\t \n\tdm_suspend(md, 0);\n\told_map = dm_swap_table(md, t);\n\tif (IS_ERR(old_map)) {\n\t\tr = PTR_ERR(old_map);\n\t\tgoto err_destroy_table;\n\t}\n\tset_disk_ro(dm_disk(md), !!(dmi->flags & DM_READONLY_FLAG));\n\n\t \n\tr = dm_resume(md);\n\tif (r)\n\t\tgoto err_destroy_table;\n\n\tDMINFO(\"%s (%s) is ready\", md->disk->disk_name, dmi->name);\n\tdm_put(md);\n\treturn 0;\n\nerr_destroy_table:\n\tdm_table_destroy(t);\nerr_hash_remove:\n\tdown_write(&_hash_lock);\n\t(void) __hash_remove(__get_name_cell(dmi->name));\n\tup_write(&_hash_lock);\n\t \n\tdm_put(md);\nerr_destroy_dm:\n\tdm_put(md);\n\tdm_destroy(md);\n\treturn r;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}