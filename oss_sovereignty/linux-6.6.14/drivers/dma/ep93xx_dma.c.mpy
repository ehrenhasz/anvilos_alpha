{
  "module_name": "ep93xx_dma.c",
  "hash_id": "5167d8517348d706a70e4fe60d90ddf978f1bb38582d5c021de8ec061c92a1bf",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/ep93xx_dma.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/dmaengine.h>\n#include <linux/module.h>\n#include <linux/mod_devicetable.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n\n#include <linux/platform_data/dma-ep93xx.h>\n\n#include \"dmaengine.h\"\n\n \n#define M2P_CONTROL\t\t\t0x0000\n#define M2P_CONTROL_STALLINT\t\tBIT(0)\n#define M2P_CONTROL_NFBINT\t\tBIT(1)\n#define M2P_CONTROL_CH_ERROR_INT\tBIT(3)\n#define M2P_CONTROL_ENABLE\t\tBIT(4)\n#define M2P_CONTROL_ICE\t\t\tBIT(6)\n\n#define M2P_INTERRUPT\t\t\t0x0004\n#define M2P_INTERRUPT_STALL\t\tBIT(0)\n#define M2P_INTERRUPT_NFB\t\tBIT(1)\n#define M2P_INTERRUPT_ERROR\t\tBIT(3)\n\n#define M2P_PPALLOC\t\t\t0x0008\n#define M2P_STATUS\t\t\t0x000c\n\n#define M2P_MAXCNT0\t\t\t0x0020\n#define M2P_BASE0\t\t\t0x0024\n#define M2P_MAXCNT1\t\t\t0x0030\n#define M2P_BASE1\t\t\t0x0034\n\n#define M2P_STATE_IDLE\t\t\t0\n#define M2P_STATE_STALL\t\t\t1\n#define M2P_STATE_ON\t\t\t2\n#define M2P_STATE_NEXT\t\t\t3\n\n \n#define M2M_CONTROL\t\t\t0x0000\n#define M2M_CONTROL_DONEINT\t\tBIT(2)\n#define M2M_CONTROL_ENABLE\t\tBIT(3)\n#define M2M_CONTROL_START\t\tBIT(4)\n#define M2M_CONTROL_DAH\t\t\tBIT(11)\n#define M2M_CONTROL_SAH\t\t\tBIT(12)\n#define M2M_CONTROL_PW_SHIFT\t\t9\n#define M2M_CONTROL_PW_8\t\t(0 << M2M_CONTROL_PW_SHIFT)\n#define M2M_CONTROL_PW_16\t\t(1 << M2M_CONTROL_PW_SHIFT)\n#define M2M_CONTROL_PW_32\t\t(2 << M2M_CONTROL_PW_SHIFT)\n#define M2M_CONTROL_PW_MASK\t\t(3 << M2M_CONTROL_PW_SHIFT)\n#define M2M_CONTROL_TM_SHIFT\t\t13\n#define M2M_CONTROL_TM_TX\t\t(1 << M2M_CONTROL_TM_SHIFT)\n#define M2M_CONTROL_TM_RX\t\t(2 << M2M_CONTROL_TM_SHIFT)\n#define M2M_CONTROL_NFBINT\t\tBIT(21)\n#define M2M_CONTROL_RSS_SHIFT\t\t22\n#define M2M_CONTROL_RSS_SSPRX\t\t(1 << M2M_CONTROL_RSS_SHIFT)\n#define M2M_CONTROL_RSS_SSPTX\t\t(2 << M2M_CONTROL_RSS_SHIFT)\n#define M2M_CONTROL_RSS_IDE\t\t(3 << M2M_CONTROL_RSS_SHIFT)\n#define M2M_CONTROL_NO_HDSK\t\tBIT(24)\n#define M2M_CONTROL_PWSC_SHIFT\t\t25\n\n#define M2M_INTERRUPT\t\t\t0x0004\n#define M2M_INTERRUPT_MASK\t\t6\n\n#define M2M_STATUS\t\t\t0x000c\n#define M2M_STATUS_CTL_SHIFT\t\t1\n#define M2M_STATUS_CTL_IDLE\t\t(0 << M2M_STATUS_CTL_SHIFT)\n#define M2M_STATUS_CTL_STALL\t\t(1 << M2M_STATUS_CTL_SHIFT)\n#define M2M_STATUS_CTL_MEMRD\t\t(2 << M2M_STATUS_CTL_SHIFT)\n#define M2M_STATUS_CTL_MEMWR\t\t(3 << M2M_STATUS_CTL_SHIFT)\n#define M2M_STATUS_CTL_BWCWAIT\t\t(4 << M2M_STATUS_CTL_SHIFT)\n#define M2M_STATUS_CTL_MASK\t\t(7 << M2M_STATUS_CTL_SHIFT)\n#define M2M_STATUS_BUF_SHIFT\t\t4\n#define M2M_STATUS_BUF_NO\t\t(0 << M2M_STATUS_BUF_SHIFT)\n#define M2M_STATUS_BUF_ON\t\t(1 << M2M_STATUS_BUF_SHIFT)\n#define M2M_STATUS_BUF_NEXT\t\t(2 << M2M_STATUS_BUF_SHIFT)\n#define M2M_STATUS_BUF_MASK\t\t(3 << M2M_STATUS_BUF_SHIFT)\n#define M2M_STATUS_DONE\t\t\tBIT(6)\n\n#define M2M_BCR0\t\t\t0x0010\n#define M2M_BCR1\t\t\t0x0014\n#define M2M_SAR_BASE0\t\t\t0x0018\n#define M2M_SAR_BASE1\t\t\t0x001c\n#define M2M_DAR_BASE0\t\t\t0x002c\n#define M2M_DAR_BASE1\t\t\t0x0030\n\n#define DMA_MAX_CHAN_BYTES\t\t0xffff\n#define DMA_MAX_CHAN_DESCRIPTORS\t32\n\nstruct ep93xx_dma_engine;\nstatic int ep93xx_dma_slave_config_write(struct dma_chan *chan,\n\t\t\t\t\t enum dma_transfer_direction dir,\n\t\t\t\t\t struct dma_slave_config *config);\n\n \nstruct ep93xx_dma_desc {\n\tu32\t\t\t\tsrc_addr;\n\tu32\t\t\t\tdst_addr;\n\tsize_t\t\t\t\tsize;\n\tbool\t\t\t\tcomplete;\n\tstruct dma_async_tx_descriptor\ttxd;\n\tstruct list_head\t\ttx_list;\n\tstruct list_head\t\tnode;\n};\n\n \nstruct ep93xx_dma_chan {\n\tstruct dma_chan\t\t\tchan;\n\tconst struct ep93xx_dma_engine\t*edma;\n\tvoid __iomem\t\t\t*regs;\n\tint\t\t\t\tirq;\n\tstruct clk\t\t\t*clk;\n\tstruct tasklet_struct\t\ttasklet;\n\t \n\tspinlock_t\t\t\tlock;\n\tunsigned long\t\t\tflags;\n \n#define EP93XX_DMA_IS_CYCLIC\t\t0\n\n\tint\t\t\t\tbuffer;\n\tstruct list_head\t\tactive;\n\tstruct list_head\t\tqueue;\n\tstruct list_head\t\tfree_list;\n\tu32\t\t\t\truntime_addr;\n\tu32\t\t\t\truntime_ctrl;\n\tstruct dma_slave_config\t\tslave_config;\n};\n\n \nstruct ep93xx_dma_engine {\n\tstruct dma_device\tdma_dev;\n\tbool\t\t\tm2m;\n\tint\t\t\t(*hw_setup)(struct ep93xx_dma_chan *);\n\tvoid\t\t\t(*hw_synchronize)(struct ep93xx_dma_chan *);\n\tvoid\t\t\t(*hw_shutdown)(struct ep93xx_dma_chan *);\n\tvoid\t\t\t(*hw_submit)(struct ep93xx_dma_chan *);\n\tint\t\t\t(*hw_interrupt)(struct ep93xx_dma_chan *);\n#define INTERRUPT_UNKNOWN\t0\n#define INTERRUPT_DONE\t\t1\n#define INTERRUPT_NEXT_BUFFER\t2\n\n\tsize_t\t\t\tnum_channels;\n\tstruct ep93xx_dma_chan\tchannels[];\n};\n\nstatic inline struct device *chan2dev(struct ep93xx_dma_chan *edmac)\n{\n\treturn &edmac->chan.dev->device;\n}\n\nstatic struct ep93xx_dma_chan *to_ep93xx_dma_chan(struct dma_chan *chan)\n{\n\treturn container_of(chan, struct ep93xx_dma_chan, chan);\n}\n\n \nstatic void ep93xx_dma_set_active(struct ep93xx_dma_chan *edmac,\n\t\t\t\t  struct ep93xx_dma_desc *desc)\n{\n\tBUG_ON(!list_empty(&edmac->active));\n\n\tlist_add_tail(&desc->node, &edmac->active);\n\n\t \n\twhile (!list_empty(&desc->tx_list)) {\n\t\tstruct ep93xx_dma_desc *d = list_first_entry(&desc->tx_list,\n\t\t\tstruct ep93xx_dma_desc, node);\n\n\t\t \n\t\td->txd.callback = desc->txd.callback;\n\t\td->txd.callback_param = desc->txd.callback_param;\n\n\t\tlist_move_tail(&d->node, &edmac->active);\n\t}\n}\n\n \nstatic struct ep93xx_dma_desc *\nep93xx_dma_get_active(struct ep93xx_dma_chan *edmac)\n{\n\treturn list_first_entry_or_null(&edmac->active,\n\t\t\t\t\tstruct ep93xx_dma_desc, node);\n}\n\n \nstatic bool ep93xx_dma_advance_active(struct ep93xx_dma_chan *edmac)\n{\n\tstruct ep93xx_dma_desc *desc;\n\n\tlist_rotate_left(&edmac->active);\n\n\tif (test_bit(EP93XX_DMA_IS_CYCLIC, &edmac->flags))\n\t\treturn true;\n\n\tdesc = ep93xx_dma_get_active(edmac);\n\tif (!desc)\n\t\treturn false;\n\n\t \n\treturn !desc->txd.cookie;\n}\n\n \n\nstatic void m2p_set_control(struct ep93xx_dma_chan *edmac, u32 control)\n{\n\twritel(control, edmac->regs + M2P_CONTROL);\n\t \n\treadl(edmac->regs + M2P_CONTROL);\n}\n\nstatic int m2p_hw_setup(struct ep93xx_dma_chan *edmac)\n{\n\tstruct ep93xx_dma_data *data = edmac->chan.private;\n\tu32 control;\n\n\twritel(data->port & 0xf, edmac->regs + M2P_PPALLOC);\n\n\tcontrol = M2P_CONTROL_CH_ERROR_INT | M2P_CONTROL_ICE\n\t\t| M2P_CONTROL_ENABLE;\n\tm2p_set_control(edmac, control);\n\n\tedmac->buffer = 0;\n\n\treturn 0;\n}\n\nstatic inline u32 m2p_channel_state(struct ep93xx_dma_chan *edmac)\n{\n\treturn (readl(edmac->regs + M2P_STATUS) >> 4) & 0x3;\n}\n\nstatic void m2p_hw_synchronize(struct ep93xx_dma_chan *edmac)\n{\n\tunsigned long flags;\n\tu32 control;\n\n\tspin_lock_irqsave(&edmac->lock, flags);\n\tcontrol = readl(edmac->regs + M2P_CONTROL);\n\tcontrol &= ~(M2P_CONTROL_STALLINT | M2P_CONTROL_NFBINT);\n\tm2p_set_control(edmac, control);\n\tspin_unlock_irqrestore(&edmac->lock, flags);\n\n\twhile (m2p_channel_state(edmac) >= M2P_STATE_ON)\n\t\tschedule();\n}\n\nstatic void m2p_hw_shutdown(struct ep93xx_dma_chan *edmac)\n{\n\tm2p_set_control(edmac, 0);\n\n\twhile (m2p_channel_state(edmac) != M2P_STATE_IDLE)\n\t\tdev_warn(chan2dev(edmac), \"M2P: Not yet IDLE\\n\");\n}\n\nstatic void m2p_fill_desc(struct ep93xx_dma_chan *edmac)\n{\n\tstruct ep93xx_dma_desc *desc;\n\tu32 bus_addr;\n\n\tdesc = ep93xx_dma_get_active(edmac);\n\tif (!desc) {\n\t\tdev_warn(chan2dev(edmac), \"M2P: empty descriptor list\\n\");\n\t\treturn;\n\t}\n\n\tif (ep93xx_dma_chan_direction(&edmac->chan) == DMA_MEM_TO_DEV)\n\t\tbus_addr = desc->src_addr;\n\telse\n\t\tbus_addr = desc->dst_addr;\n\n\tif (edmac->buffer == 0) {\n\t\twritel(desc->size, edmac->regs + M2P_MAXCNT0);\n\t\twritel(bus_addr, edmac->regs + M2P_BASE0);\n\t} else {\n\t\twritel(desc->size, edmac->regs + M2P_MAXCNT1);\n\t\twritel(bus_addr, edmac->regs + M2P_BASE1);\n\t}\n\n\tedmac->buffer ^= 1;\n}\n\nstatic void m2p_hw_submit(struct ep93xx_dma_chan *edmac)\n{\n\tu32 control = readl(edmac->regs + M2P_CONTROL);\n\n\tm2p_fill_desc(edmac);\n\tcontrol |= M2P_CONTROL_STALLINT;\n\n\tif (ep93xx_dma_advance_active(edmac)) {\n\t\tm2p_fill_desc(edmac);\n\t\tcontrol |= M2P_CONTROL_NFBINT;\n\t}\n\n\tm2p_set_control(edmac, control);\n}\n\nstatic int m2p_hw_interrupt(struct ep93xx_dma_chan *edmac)\n{\n\tu32 irq_status = readl(edmac->regs + M2P_INTERRUPT);\n\tu32 control;\n\n\tif (irq_status & M2P_INTERRUPT_ERROR) {\n\t\tstruct ep93xx_dma_desc *desc = ep93xx_dma_get_active(edmac);\n\n\t\t \n\t\twritel(1, edmac->regs + M2P_INTERRUPT);\n\n\t\t \n\t\tdev_err(chan2dev(edmac),\n\t\t\t\"DMA transfer failed! Details:\\n\"\n\t\t\t\"\\tcookie\t: %d\\n\"\n\t\t\t\"\\tsrc_addr\t: 0x%08x\\n\"\n\t\t\t\"\\tdst_addr\t: 0x%08x\\n\"\n\t\t\t\"\\tsize\t\t: %zu\\n\",\n\t\t\tdesc->txd.cookie, desc->src_addr, desc->dst_addr,\n\t\t\tdesc->size);\n\t}\n\n\t \n\tif (!(irq_status & (M2P_INTERRUPT_STALL | M2P_INTERRUPT_NFB)))\n\t\treturn INTERRUPT_UNKNOWN;\n\n\tif (ep93xx_dma_advance_active(edmac)) {\n\t\tm2p_fill_desc(edmac);\n\t\treturn INTERRUPT_NEXT_BUFFER;\n\t}\n\n\t \n\tcontrol = readl(edmac->regs + M2P_CONTROL);\n\tcontrol &= ~(M2P_CONTROL_STALLINT | M2P_CONTROL_NFBINT);\n\tm2p_set_control(edmac, control);\n\n\treturn INTERRUPT_DONE;\n}\n\n \n\nstatic int m2m_hw_setup(struct ep93xx_dma_chan *edmac)\n{\n\tconst struct ep93xx_dma_data *data = edmac->chan.private;\n\tu32 control = 0;\n\n\tif (!data) {\n\t\t \n\t\twritel(control, edmac->regs + M2M_CONTROL);\n\t\treturn 0;\n\t}\n\n\tswitch (data->port) {\n\tcase EP93XX_DMA_SSP:\n\t\t \n\t\tcontrol = (5 << M2M_CONTROL_PWSC_SHIFT);\n\t\tcontrol |= M2M_CONTROL_NO_HDSK;\n\n\t\tif (data->direction == DMA_MEM_TO_DEV) {\n\t\t\tcontrol |= M2M_CONTROL_DAH;\n\t\t\tcontrol |= M2M_CONTROL_TM_TX;\n\t\t\tcontrol |= M2M_CONTROL_RSS_SSPTX;\n\t\t} else {\n\t\t\tcontrol |= M2M_CONTROL_SAH;\n\t\t\tcontrol |= M2M_CONTROL_TM_RX;\n\t\t\tcontrol |= M2M_CONTROL_RSS_SSPRX;\n\t\t}\n\t\tbreak;\n\n\tcase EP93XX_DMA_IDE:\n\t\t \n\t\tif (data->direction == DMA_MEM_TO_DEV) {\n\t\t\t \n\t\t\tcontrol = (3 << M2M_CONTROL_PWSC_SHIFT);\n\t\t\tcontrol |= M2M_CONTROL_DAH;\n\t\t\tcontrol |= M2M_CONTROL_TM_TX;\n\t\t} else {\n\t\t\tcontrol = (2 << M2M_CONTROL_PWSC_SHIFT);\n\t\t\tcontrol |= M2M_CONTROL_SAH;\n\t\t\tcontrol |= M2M_CONTROL_TM_RX;\n\t\t}\n\n\t\tcontrol |= M2M_CONTROL_NO_HDSK;\n\t\tcontrol |= M2M_CONTROL_RSS_IDE;\n\t\tcontrol |= M2M_CONTROL_PW_16;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\twritel(control, edmac->regs + M2M_CONTROL);\n\treturn 0;\n}\n\nstatic void m2m_hw_shutdown(struct ep93xx_dma_chan *edmac)\n{\n\t \n\twritel(0, edmac->regs + M2M_CONTROL);\n}\n\nstatic void m2m_fill_desc(struct ep93xx_dma_chan *edmac)\n{\n\tstruct ep93xx_dma_desc *desc;\n\n\tdesc = ep93xx_dma_get_active(edmac);\n\tif (!desc) {\n\t\tdev_warn(chan2dev(edmac), \"M2M: empty descriptor list\\n\");\n\t\treturn;\n\t}\n\n\tif (edmac->buffer == 0) {\n\t\twritel(desc->src_addr, edmac->regs + M2M_SAR_BASE0);\n\t\twritel(desc->dst_addr, edmac->regs + M2M_DAR_BASE0);\n\t\twritel(desc->size, edmac->regs + M2M_BCR0);\n\t} else {\n\t\twritel(desc->src_addr, edmac->regs + M2M_SAR_BASE1);\n\t\twritel(desc->dst_addr, edmac->regs + M2M_DAR_BASE1);\n\t\twritel(desc->size, edmac->regs + M2M_BCR1);\n\t}\n\n\tedmac->buffer ^= 1;\n}\n\nstatic void m2m_hw_submit(struct ep93xx_dma_chan *edmac)\n{\n\tstruct ep93xx_dma_data *data = edmac->chan.private;\n\tu32 control = readl(edmac->regs + M2M_CONTROL);\n\n\t \n\tcontrol &= ~M2M_CONTROL_PW_MASK;\n\tcontrol |= edmac->runtime_ctrl;\n\n\tm2m_fill_desc(edmac);\n\tcontrol |= M2M_CONTROL_DONEINT;\n\n\tif (ep93xx_dma_advance_active(edmac)) {\n\t\tm2m_fill_desc(edmac);\n\t\tcontrol |= M2M_CONTROL_NFBINT;\n\t}\n\n\t \n\tcontrol |= M2M_CONTROL_ENABLE;\n\twritel(control, edmac->regs + M2M_CONTROL);\n\n\tif (!data) {\n\t\t \n\t\tcontrol |= M2M_CONTROL_START;\n\t\twritel(control, edmac->regs + M2M_CONTROL);\n\t}\n}\n\n \nstatic int m2m_hw_interrupt(struct ep93xx_dma_chan *edmac)\n{\n\tu32 status = readl(edmac->regs + M2M_STATUS);\n\tu32 ctl_fsm = status & M2M_STATUS_CTL_MASK;\n\tu32 buf_fsm = status & M2M_STATUS_BUF_MASK;\n\tbool done = status & M2M_STATUS_DONE;\n\tbool last_done;\n\tu32 control;\n\tstruct ep93xx_dma_desc *desc;\n\n\t \n\tif (!(readl(edmac->regs + M2M_INTERRUPT) & M2M_INTERRUPT_MASK))\n\t\treturn INTERRUPT_UNKNOWN;\n\n\tif (done) {\n\t\t \n\t\twritel(0, edmac->regs + M2M_INTERRUPT);\n\t}\n\n\t \n\tdesc = ep93xx_dma_get_active(edmac);\n\tlast_done = !desc || desc->txd.cookie;\n\n\t \n\tif (!last_done &&\n\t    (buf_fsm == M2M_STATUS_BUF_NO ||\n\t     buf_fsm == M2M_STATUS_BUF_ON)) {\n\t\t \n\t\tif (ep93xx_dma_advance_active(edmac)) {\n\t\t\tm2m_fill_desc(edmac);\n\t\t\tif (done && !edmac->chan.private) {\n\t\t\t\t \n\t\t\t\tcontrol = readl(edmac->regs + M2M_CONTROL);\n\t\t\t\tcontrol |= M2M_CONTROL_START;\n\t\t\t\twritel(control, edmac->regs + M2M_CONTROL);\n\t\t\t}\n\t\t\treturn INTERRUPT_NEXT_BUFFER;\n\t\t} else {\n\t\t\tlast_done = true;\n\t\t}\n\t}\n\n\t \n\tif (last_done &&\n\t    buf_fsm == M2M_STATUS_BUF_NO &&\n\t    ctl_fsm == M2M_STATUS_CTL_STALL) {\n\t\t \n\t\tcontrol = readl(edmac->regs + M2M_CONTROL);\n\t\tcontrol &= ~(M2M_CONTROL_DONEINT | M2M_CONTROL_NFBINT\n\t\t\t    | M2M_CONTROL_ENABLE);\n\t\twritel(control, edmac->regs + M2M_CONTROL);\n\t\treturn INTERRUPT_DONE;\n\t}\n\n\t \n\treturn INTERRUPT_NEXT_BUFFER;\n}\n\n \n\nstatic struct ep93xx_dma_desc *\nep93xx_dma_desc_get(struct ep93xx_dma_chan *edmac)\n{\n\tstruct ep93xx_dma_desc *desc, *_desc;\n\tstruct ep93xx_dma_desc *ret = NULL;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&edmac->lock, flags);\n\tlist_for_each_entry_safe(desc, _desc, &edmac->free_list, node) {\n\t\tif (async_tx_test_ack(&desc->txd)) {\n\t\t\tlist_del_init(&desc->node);\n\n\t\t\t \n\t\t\tdesc->src_addr = 0;\n\t\t\tdesc->dst_addr = 0;\n\t\t\tdesc->size = 0;\n\t\t\tdesc->complete = false;\n\t\t\tdesc->txd.cookie = 0;\n\t\t\tdesc->txd.callback = NULL;\n\t\t\tdesc->txd.callback_param = NULL;\n\n\t\t\tret = desc;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&edmac->lock, flags);\n\treturn ret;\n}\n\nstatic void ep93xx_dma_desc_put(struct ep93xx_dma_chan *edmac,\n\t\t\t\tstruct ep93xx_dma_desc *desc)\n{\n\tif (desc) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&edmac->lock, flags);\n\t\tlist_splice_init(&desc->tx_list, &edmac->free_list);\n\t\tlist_add(&desc->node, &edmac->free_list);\n\t\tspin_unlock_irqrestore(&edmac->lock, flags);\n\t}\n}\n\n \nstatic void ep93xx_dma_advance_work(struct ep93xx_dma_chan *edmac)\n{\n\tstruct ep93xx_dma_desc *new;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&edmac->lock, flags);\n\tif (!list_empty(&edmac->active) || list_empty(&edmac->queue)) {\n\t\tspin_unlock_irqrestore(&edmac->lock, flags);\n\t\treturn;\n\t}\n\n\t \n\tnew = list_first_entry(&edmac->queue, struct ep93xx_dma_desc, node);\n\tlist_del_init(&new->node);\n\n\tep93xx_dma_set_active(edmac, new);\n\n\t \n\tedmac->edma->hw_submit(edmac);\n\tspin_unlock_irqrestore(&edmac->lock, flags);\n}\n\nstatic void ep93xx_dma_tasklet(struct tasklet_struct *t)\n{\n\tstruct ep93xx_dma_chan *edmac = from_tasklet(edmac, t, tasklet);\n\tstruct ep93xx_dma_desc *desc, *d;\n\tstruct dmaengine_desc_callback cb;\n\tLIST_HEAD(list);\n\n\tmemset(&cb, 0, sizeof(cb));\n\tspin_lock_irq(&edmac->lock);\n\t \n\tdesc = ep93xx_dma_get_active(edmac);\n\tif (desc) {\n\t\tif (desc->complete) {\n\t\t\t \n\t\t\tif (!test_bit(EP93XX_DMA_IS_CYCLIC, &edmac->flags))\n\t\t\t\tdma_cookie_complete(&desc->txd);\n\t\t\tlist_splice_init(&edmac->active, &list);\n\t\t}\n\t\tdmaengine_desc_get_callback(&desc->txd, &cb);\n\t}\n\tspin_unlock_irq(&edmac->lock);\n\n\t \n\tep93xx_dma_advance_work(edmac);\n\n\t \n\tlist_for_each_entry_safe(desc, d, &list, node) {\n\t\tdma_descriptor_unmap(&desc->txd);\n\t\tep93xx_dma_desc_put(edmac, desc);\n\t}\n\n\tdmaengine_desc_callback_invoke(&cb, NULL);\n}\n\nstatic irqreturn_t ep93xx_dma_interrupt(int irq, void *dev_id)\n{\n\tstruct ep93xx_dma_chan *edmac = dev_id;\n\tstruct ep93xx_dma_desc *desc;\n\tirqreturn_t ret = IRQ_HANDLED;\n\n\tspin_lock(&edmac->lock);\n\n\tdesc = ep93xx_dma_get_active(edmac);\n\tif (!desc) {\n\t\tdev_warn(chan2dev(edmac),\n\t\t\t \"got interrupt while active list is empty\\n\");\n\t\tspin_unlock(&edmac->lock);\n\t\treturn IRQ_NONE;\n\t}\n\n\tswitch (edmac->edma->hw_interrupt(edmac)) {\n\tcase INTERRUPT_DONE:\n\t\tdesc->complete = true;\n\t\ttasklet_schedule(&edmac->tasklet);\n\t\tbreak;\n\n\tcase INTERRUPT_NEXT_BUFFER:\n\t\tif (test_bit(EP93XX_DMA_IS_CYCLIC, &edmac->flags))\n\t\t\ttasklet_schedule(&edmac->tasklet);\n\t\tbreak;\n\n\tdefault:\n\t\tdev_warn(chan2dev(edmac), \"unknown interrupt!\\n\");\n\t\tret = IRQ_NONE;\n\t\tbreak;\n\t}\n\n\tspin_unlock(&edmac->lock);\n\treturn ret;\n}\n\n \nstatic dma_cookie_t ep93xx_dma_tx_submit(struct dma_async_tx_descriptor *tx)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(tx->chan);\n\tstruct ep93xx_dma_desc *desc;\n\tdma_cookie_t cookie;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&edmac->lock, flags);\n\tcookie = dma_cookie_assign(tx);\n\n\tdesc = container_of(tx, struct ep93xx_dma_desc, txd);\n\n\t \n\tif (list_empty(&edmac->active)) {\n\t\tep93xx_dma_set_active(edmac, desc);\n\t\tedmac->edma->hw_submit(edmac);\n\t} else {\n\t\tlist_add_tail(&desc->node, &edmac->queue);\n\t}\n\n\tspin_unlock_irqrestore(&edmac->lock, flags);\n\treturn cookie;\n}\n\n \nstatic int ep93xx_dma_alloc_chan_resources(struct dma_chan *chan)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);\n\tstruct ep93xx_dma_data *data = chan->private;\n\tconst char *name = dma_chan_name(chan);\n\tint ret, i;\n\n\t \n\tif (!edmac->edma->m2m) {\n\t\tif (!data)\n\t\t\treturn -EINVAL;\n\t\tif (data->port < EP93XX_DMA_I2S1 ||\n\t\t    data->port > EP93XX_DMA_IRDA)\n\t\t\treturn -EINVAL;\n\t\tif (data->direction != ep93xx_dma_chan_direction(chan))\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tif (data) {\n\t\t\tswitch (data->port) {\n\t\t\tcase EP93XX_DMA_SSP:\n\t\t\tcase EP93XX_DMA_IDE:\n\t\t\t\tif (!is_slave_direction(data->direction))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (data && data->name)\n\t\tname = data->name;\n\n\tret = clk_prepare_enable(edmac->clk);\n\tif (ret)\n\t\treturn ret;\n\n\tret = request_irq(edmac->irq, ep93xx_dma_interrupt, 0, name, edmac);\n\tif (ret)\n\t\tgoto fail_clk_disable;\n\n\tspin_lock_irq(&edmac->lock);\n\tdma_cookie_init(&edmac->chan);\n\tret = edmac->edma->hw_setup(edmac);\n\tspin_unlock_irq(&edmac->lock);\n\n\tif (ret)\n\t\tgoto fail_free_irq;\n\n\tfor (i = 0; i < DMA_MAX_CHAN_DESCRIPTORS; i++) {\n\t\tstruct ep93xx_dma_desc *desc;\n\n\t\tdesc = kzalloc(sizeof(*desc), GFP_KERNEL);\n\t\tif (!desc) {\n\t\t\tdev_warn(chan2dev(edmac), \"not enough descriptors\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&desc->tx_list);\n\n\t\tdma_async_tx_descriptor_init(&desc->txd, chan);\n\t\tdesc->txd.flags = DMA_CTRL_ACK;\n\t\tdesc->txd.tx_submit = ep93xx_dma_tx_submit;\n\n\t\tep93xx_dma_desc_put(edmac, desc);\n\t}\n\n\treturn i;\n\nfail_free_irq:\n\tfree_irq(edmac->irq, edmac);\nfail_clk_disable:\n\tclk_disable_unprepare(edmac->clk);\n\n\treturn ret;\n}\n\n \nstatic void ep93xx_dma_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);\n\tstruct ep93xx_dma_desc *desc, *d;\n\tunsigned long flags;\n\tLIST_HEAD(list);\n\n\tBUG_ON(!list_empty(&edmac->active));\n\tBUG_ON(!list_empty(&edmac->queue));\n\n\tspin_lock_irqsave(&edmac->lock, flags);\n\tedmac->edma->hw_shutdown(edmac);\n\tedmac->runtime_addr = 0;\n\tedmac->runtime_ctrl = 0;\n\tedmac->buffer = 0;\n\tlist_splice_init(&edmac->free_list, &list);\n\tspin_unlock_irqrestore(&edmac->lock, flags);\n\n\tlist_for_each_entry_safe(desc, d, &list, node)\n\t\tkfree(desc);\n\n\tclk_disable_unprepare(edmac->clk);\n\tfree_irq(edmac->irq, edmac);\n}\n\n \nstatic struct dma_async_tx_descriptor *\nep93xx_dma_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest,\n\t\t\t   dma_addr_t src, size_t len, unsigned long flags)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);\n\tstruct ep93xx_dma_desc *desc, *first;\n\tsize_t bytes, offset;\n\n\tfirst = NULL;\n\tfor (offset = 0; offset < len; offset += bytes) {\n\t\tdesc = ep93xx_dma_desc_get(edmac);\n\t\tif (!desc) {\n\t\t\tdev_warn(chan2dev(edmac), \"couldn't get descriptor\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tbytes = min_t(size_t, len - offset, DMA_MAX_CHAN_BYTES);\n\n\t\tdesc->src_addr = src + offset;\n\t\tdesc->dst_addr = dest + offset;\n\t\tdesc->size = bytes;\n\n\t\tif (!first)\n\t\t\tfirst = desc;\n\t\telse\n\t\t\tlist_add_tail(&desc->node, &first->tx_list);\n\t}\n\n\tfirst->txd.cookie = -EBUSY;\n\tfirst->txd.flags = flags;\n\n\treturn &first->txd;\nfail:\n\tep93xx_dma_desc_put(edmac, first);\n\treturn NULL;\n}\n\n \nstatic struct dma_async_tx_descriptor *\nep93xx_dma_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,\n\t\t\t unsigned int sg_len, enum dma_transfer_direction dir,\n\t\t\t unsigned long flags, void *context)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);\n\tstruct ep93xx_dma_desc *desc, *first;\n\tstruct scatterlist *sg;\n\tint i;\n\n\tif (!edmac->edma->m2m && dir != ep93xx_dma_chan_direction(chan)) {\n\t\tdev_warn(chan2dev(edmac),\n\t\t\t \"channel was configured with different direction\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (test_bit(EP93XX_DMA_IS_CYCLIC, &edmac->flags)) {\n\t\tdev_warn(chan2dev(edmac),\n\t\t\t \"channel is already used for cyclic transfers\\n\");\n\t\treturn NULL;\n\t}\n\n\tep93xx_dma_slave_config_write(chan, dir, &edmac->slave_config);\n\n\tfirst = NULL;\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tsize_t len = sg_dma_len(sg);\n\n\t\tif (len > DMA_MAX_CHAN_BYTES) {\n\t\t\tdev_warn(chan2dev(edmac), \"too big transfer size %zu\\n\",\n\t\t\t\t len);\n\t\t\tgoto fail;\n\t\t}\n\n\t\tdesc = ep93xx_dma_desc_get(edmac);\n\t\tif (!desc) {\n\t\t\tdev_warn(chan2dev(edmac), \"couldn't get descriptor\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (dir == DMA_MEM_TO_DEV) {\n\t\t\tdesc->src_addr = sg_dma_address(sg);\n\t\t\tdesc->dst_addr = edmac->runtime_addr;\n\t\t} else {\n\t\t\tdesc->src_addr = edmac->runtime_addr;\n\t\t\tdesc->dst_addr = sg_dma_address(sg);\n\t\t}\n\t\tdesc->size = len;\n\n\t\tif (!first)\n\t\t\tfirst = desc;\n\t\telse\n\t\t\tlist_add_tail(&desc->node, &first->tx_list);\n\t}\n\n\tfirst->txd.cookie = -EBUSY;\n\tfirst->txd.flags = flags;\n\n\treturn &first->txd;\n\nfail:\n\tep93xx_dma_desc_put(edmac, first);\n\treturn NULL;\n}\n\n \nstatic struct dma_async_tx_descriptor *\nep93xx_dma_prep_dma_cyclic(struct dma_chan *chan, dma_addr_t dma_addr,\n\t\t\t   size_t buf_len, size_t period_len,\n\t\t\t   enum dma_transfer_direction dir, unsigned long flags)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);\n\tstruct ep93xx_dma_desc *desc, *first;\n\tsize_t offset = 0;\n\n\tif (!edmac->edma->m2m && dir != ep93xx_dma_chan_direction(chan)) {\n\t\tdev_warn(chan2dev(edmac),\n\t\t\t \"channel was configured with different direction\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (test_and_set_bit(EP93XX_DMA_IS_CYCLIC, &edmac->flags)) {\n\t\tdev_warn(chan2dev(edmac),\n\t\t\t \"channel is already used for cyclic transfers\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (period_len > DMA_MAX_CHAN_BYTES) {\n\t\tdev_warn(chan2dev(edmac), \"too big period length %zu\\n\",\n\t\t\t period_len);\n\t\treturn NULL;\n\t}\n\n\tep93xx_dma_slave_config_write(chan, dir, &edmac->slave_config);\n\n\t \n\tfirst = NULL;\n\tfor (offset = 0; offset < buf_len; offset += period_len) {\n\t\tdesc = ep93xx_dma_desc_get(edmac);\n\t\tif (!desc) {\n\t\t\tdev_warn(chan2dev(edmac), \"couldn't get descriptor\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (dir == DMA_MEM_TO_DEV) {\n\t\t\tdesc->src_addr = dma_addr + offset;\n\t\t\tdesc->dst_addr = edmac->runtime_addr;\n\t\t} else {\n\t\t\tdesc->src_addr = edmac->runtime_addr;\n\t\t\tdesc->dst_addr = dma_addr + offset;\n\t\t}\n\n\t\tdesc->size = period_len;\n\n\t\tif (!first)\n\t\t\tfirst = desc;\n\t\telse\n\t\t\tlist_add_tail(&desc->node, &first->tx_list);\n\t}\n\n\tfirst->txd.cookie = -EBUSY;\n\n\treturn &first->txd;\n\nfail:\n\tep93xx_dma_desc_put(edmac, first);\n\treturn NULL;\n}\n\n \nstatic void ep93xx_dma_synchronize(struct dma_chan *chan)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);\n\n\tif (edmac->edma->hw_synchronize)\n\t\tedmac->edma->hw_synchronize(edmac);\n}\n\n \nstatic int ep93xx_dma_terminate_all(struct dma_chan *chan)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);\n\tstruct ep93xx_dma_desc *desc, *_d;\n\tunsigned long flags;\n\tLIST_HEAD(list);\n\n\tspin_lock_irqsave(&edmac->lock, flags);\n\t \n\tedmac->edma->hw_shutdown(edmac);\n\tclear_bit(EP93XX_DMA_IS_CYCLIC, &edmac->flags);\n\tlist_splice_init(&edmac->active, &list);\n\tlist_splice_init(&edmac->queue, &list);\n\t \n\tedmac->edma->hw_setup(edmac);\n\tspin_unlock_irqrestore(&edmac->lock, flags);\n\n\tlist_for_each_entry_safe(desc, _d, &list, node)\n\t\tep93xx_dma_desc_put(edmac, desc);\n\n\treturn 0;\n}\n\nstatic int ep93xx_dma_slave_config(struct dma_chan *chan,\n\t\t\t\t   struct dma_slave_config *config)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);\n\n\tmemcpy(&edmac->slave_config, config, sizeof(*config));\n\n\treturn 0;\n}\n\nstatic int ep93xx_dma_slave_config_write(struct dma_chan *chan,\n\t\t\t\t\t enum dma_transfer_direction dir,\n\t\t\t\t\t struct dma_slave_config *config)\n{\n\tstruct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);\n\tenum dma_slave_buswidth width;\n\tunsigned long flags;\n\tu32 addr, ctrl;\n\n\tif (!edmac->edma->m2m)\n\t\treturn -EINVAL;\n\n\tswitch (dir) {\n\tcase DMA_DEV_TO_MEM:\n\t\twidth = config->src_addr_width;\n\t\taddr = config->src_addr;\n\t\tbreak;\n\n\tcase DMA_MEM_TO_DEV:\n\t\twidth = config->dst_addr_width;\n\t\taddr = config->dst_addr;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (width) {\n\tcase DMA_SLAVE_BUSWIDTH_1_BYTE:\n\t\tctrl = 0;\n\t\tbreak;\n\tcase DMA_SLAVE_BUSWIDTH_2_BYTES:\n\t\tctrl = M2M_CONTROL_PW_16;\n\t\tbreak;\n\tcase DMA_SLAVE_BUSWIDTH_4_BYTES:\n\t\tctrl = M2M_CONTROL_PW_32;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tspin_lock_irqsave(&edmac->lock, flags);\n\tedmac->runtime_addr = addr;\n\tedmac->runtime_ctrl = ctrl;\n\tspin_unlock_irqrestore(&edmac->lock, flags);\n\n\treturn 0;\n}\n\n \nstatic enum dma_status ep93xx_dma_tx_status(struct dma_chan *chan,\n\t\t\t\t\t    dma_cookie_t cookie,\n\t\t\t\t\t    struct dma_tx_state *state)\n{\n\treturn dma_cookie_status(chan, cookie, state);\n}\n\n \nstatic void ep93xx_dma_issue_pending(struct dma_chan *chan)\n{\n\tep93xx_dma_advance_work(to_ep93xx_dma_chan(chan));\n}\n\nstatic int __init ep93xx_dma_probe(struct platform_device *pdev)\n{\n\tstruct ep93xx_dma_platform_data *pdata = dev_get_platdata(&pdev->dev);\n\tstruct ep93xx_dma_engine *edma;\n\tstruct dma_device *dma_dev;\n\tint ret, i;\n\n\tedma = kzalloc(struct_size(edma, channels, pdata->num_channels), GFP_KERNEL);\n\tif (!edma)\n\t\treturn -ENOMEM;\n\n\tdma_dev = &edma->dma_dev;\n\tedma->m2m = platform_get_device_id(pdev)->driver_data;\n\tedma->num_channels = pdata->num_channels;\n\n\tINIT_LIST_HEAD(&dma_dev->channels);\n\tfor (i = 0; i < pdata->num_channels; i++) {\n\t\tconst struct ep93xx_dma_chan_data *cdata = &pdata->channels[i];\n\t\tstruct ep93xx_dma_chan *edmac = &edma->channels[i];\n\n\t\tedmac->chan.device = dma_dev;\n\t\tedmac->regs = cdata->base;\n\t\tedmac->irq = cdata->irq;\n\t\tedmac->edma = edma;\n\n\t\tedmac->clk = clk_get(NULL, cdata->name);\n\t\tif (IS_ERR(edmac->clk)) {\n\t\t\tdev_warn(&pdev->dev, \"failed to get clock for %s\\n\",\n\t\t\t\t cdata->name);\n\t\t\tcontinue;\n\t\t}\n\n\t\tspin_lock_init(&edmac->lock);\n\t\tINIT_LIST_HEAD(&edmac->active);\n\t\tINIT_LIST_HEAD(&edmac->queue);\n\t\tINIT_LIST_HEAD(&edmac->free_list);\n\t\ttasklet_setup(&edmac->tasklet, ep93xx_dma_tasklet);\n\n\t\tlist_add_tail(&edmac->chan.device_node,\n\t\t\t      &dma_dev->channels);\n\t}\n\n\tdma_cap_zero(dma_dev->cap_mask);\n\tdma_cap_set(DMA_SLAVE, dma_dev->cap_mask);\n\tdma_cap_set(DMA_CYCLIC, dma_dev->cap_mask);\n\n\tdma_dev->dev = &pdev->dev;\n\tdma_dev->device_alloc_chan_resources = ep93xx_dma_alloc_chan_resources;\n\tdma_dev->device_free_chan_resources = ep93xx_dma_free_chan_resources;\n\tdma_dev->device_prep_slave_sg = ep93xx_dma_prep_slave_sg;\n\tdma_dev->device_prep_dma_cyclic = ep93xx_dma_prep_dma_cyclic;\n\tdma_dev->device_config = ep93xx_dma_slave_config;\n\tdma_dev->device_synchronize = ep93xx_dma_synchronize;\n\tdma_dev->device_terminate_all = ep93xx_dma_terminate_all;\n\tdma_dev->device_issue_pending = ep93xx_dma_issue_pending;\n\tdma_dev->device_tx_status = ep93xx_dma_tx_status;\n\n\tdma_set_max_seg_size(dma_dev->dev, DMA_MAX_CHAN_BYTES);\n\n\tif (edma->m2m) {\n\t\tdma_cap_set(DMA_MEMCPY, dma_dev->cap_mask);\n\t\tdma_dev->device_prep_dma_memcpy = ep93xx_dma_prep_dma_memcpy;\n\n\t\tedma->hw_setup = m2m_hw_setup;\n\t\tedma->hw_shutdown = m2m_hw_shutdown;\n\t\tedma->hw_submit = m2m_hw_submit;\n\t\tedma->hw_interrupt = m2m_hw_interrupt;\n\t} else {\n\t\tdma_cap_set(DMA_PRIVATE, dma_dev->cap_mask);\n\n\t\tedma->hw_synchronize = m2p_hw_synchronize;\n\t\tedma->hw_setup = m2p_hw_setup;\n\t\tedma->hw_shutdown = m2p_hw_shutdown;\n\t\tedma->hw_submit = m2p_hw_submit;\n\t\tedma->hw_interrupt = m2p_hw_interrupt;\n\t}\n\n\tret = dma_async_device_register(dma_dev);\n\tif (unlikely(ret)) {\n\t\tfor (i = 0; i < edma->num_channels; i++) {\n\t\t\tstruct ep93xx_dma_chan *edmac = &edma->channels[i];\n\t\t\tif (!IS_ERR_OR_NULL(edmac->clk))\n\t\t\t\tclk_put(edmac->clk);\n\t\t}\n\t\tkfree(edma);\n\t} else {\n\t\tdev_info(dma_dev->dev, \"EP93xx M2%s DMA ready\\n\",\n\t\t\t edma->m2m ? \"M\" : \"P\");\n\t}\n\n\treturn ret;\n}\n\nstatic const struct platform_device_id ep93xx_dma_driver_ids[] = {\n\t{ \"ep93xx-dma-m2p\", 0 },\n\t{ \"ep93xx-dma-m2m\", 1 },\n\t{ },\n};\n\nstatic struct platform_driver ep93xx_dma_driver = {\n\t.driver\t\t= {\n\t\t.name\t= \"ep93xx-dma\",\n\t},\n\t.id_table\t= ep93xx_dma_driver_ids,\n};\n\nstatic int __init ep93xx_dma_module_init(void)\n{\n\treturn platform_driver_probe(&ep93xx_dma_driver, ep93xx_dma_probe);\n}\nsubsys_initcall(ep93xx_dma_module_init);\n\nMODULE_AUTHOR(\"Mika Westerberg <mika.westerberg@iki.fi>\");\nMODULE_DESCRIPTION(\"EP93xx DMA driver\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}