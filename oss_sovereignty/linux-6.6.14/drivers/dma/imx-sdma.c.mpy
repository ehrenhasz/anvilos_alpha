{
  "module_name": "imx-sdma.c",
  "hash_id": "43753a3cdfb0af13a7befa480c1fd1b08b4d1a643d716f72a0c75bfa8a09e5a0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/imx-sdma.c",
  "human_readable_source": "\n\n\n\n\n\n\n\n\n\n\n\n#include <linux/init.h>\n#include <linux/iopoll.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/bitfield.h>\n#include <linux/bitops.h>\n#include <linux/mm.h>\n#include <linux/interrupt.h>\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/sched.h>\n#include <linux/semaphore.h>\n#include <linux/spinlock.h>\n#include <linux/device.h>\n#include <linux/dma-mapping.h>\n#include <linux/firmware.h>\n#include <linux/slab.h>\n#include <linux/platform_device.h>\n#include <linux/dmaengine.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/of_dma.h>\n#include <linux/workqueue.h>\n\n#include <asm/irq.h>\n#include <linux/dma/imx-dma.h>\n#include <linux/regmap.h>\n#include <linux/mfd/syscon.h>\n#include <linux/mfd/syscon/imx6q-iomuxc-gpr.h>\n\n#include \"dmaengine.h\"\n#include \"virt-dma.h\"\n\n \n#define SDMA_H_C0PTR\t\t0x000\n#define SDMA_H_INTR\t\t0x004\n#define SDMA_H_STATSTOP\t\t0x008\n#define SDMA_H_START\t\t0x00c\n#define SDMA_H_EVTOVR\t\t0x010\n#define SDMA_H_DSPOVR\t\t0x014\n#define SDMA_H_HOSTOVR\t\t0x018\n#define SDMA_H_EVTPEND\t\t0x01c\n#define SDMA_H_DSPENBL\t\t0x020\n#define SDMA_H_RESET\t\t0x024\n#define SDMA_H_EVTERR\t\t0x028\n#define SDMA_H_INTRMSK\t\t0x02c\n#define SDMA_H_PSW\t\t0x030\n#define SDMA_H_EVTERRDBG\t0x034\n#define SDMA_H_CONFIG\t\t0x038\n#define SDMA_ONCE_ENB\t\t0x040\n#define SDMA_ONCE_DATA\t\t0x044\n#define SDMA_ONCE_INSTR\t\t0x048\n#define SDMA_ONCE_STAT\t\t0x04c\n#define SDMA_ONCE_CMD\t\t0x050\n#define SDMA_EVT_MIRROR\t\t0x054\n#define SDMA_ILLINSTADDR\t0x058\n#define SDMA_CHN0ADDR\t\t0x05c\n#define SDMA_ONCE_RTB\t\t0x060\n#define SDMA_XTRIG_CONF1\t0x070\n#define SDMA_XTRIG_CONF2\t0x074\n#define SDMA_CHNENBL0_IMX35\t0x200\n#define SDMA_CHNENBL0_IMX31\t0x080\n#define SDMA_CHNPRI_0\t\t0x100\n#define SDMA_DONE0_CONFIG\t0x1000\n\n \n#define BD_DONE  0x01\n#define BD_WRAP  0x02\n#define BD_CONT  0x04\n#define BD_INTR  0x08\n#define BD_RROR  0x10\n#define BD_LAST  0x20\n#define BD_EXTD  0x80\n\n \n#define DND_END_OF_FRAME  0x80\n#define DND_END_OF_XFER   0x40\n#define DND_DONE          0x20\n#define DND_UNUSED        0x01\n\n \n#define BD_IPCV2_END_OF_FRAME  0x40\n\n#define IPCV2_MAX_NODES        50\n \n#define DATA_ERROR  0x10000000\n\n \n#define C0_ADDR             0x01\n#define C0_LOAD             0x02\n#define C0_DUMP             0x03\n#define C0_SETCTX           0x07\n#define C0_GETCTX           0x03\n#define C0_SETDM            0x01\n#define C0_SETPM            0x04\n#define C0_GETDM            0x02\n#define C0_GETPM            0x08\n \n#define CHANGE_ENDIANNESS   0x80\n\n \n#define SDMA_WATERMARK_LEVEL_LWML\t0xFF\n#define SDMA_WATERMARK_LEVEL_PS\t\tBIT(8)\n#define SDMA_WATERMARK_LEVEL_PA\t\tBIT(9)\n#define SDMA_WATERMARK_LEVEL_SPDIF\tBIT(10)\n#define SDMA_WATERMARK_LEVEL_SP\t\tBIT(11)\n#define SDMA_WATERMARK_LEVEL_DP\t\tBIT(12)\n#define SDMA_WATERMARK_LEVEL_HWML\t(0xFF << 16)\n#define SDMA_WATERMARK_LEVEL_LWE\tBIT(28)\n#define SDMA_WATERMARK_LEVEL_HWE\tBIT(29)\n#define SDMA_WATERMARK_LEVEL_CONT\tBIT(31)\n\n#define SDMA_DMA_BUSWIDTHS\t(BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) | \\\n\t\t\t\t BIT(DMA_SLAVE_BUSWIDTH_2_BYTES) | \\\n\t\t\t\t BIT(DMA_SLAVE_BUSWIDTH_4_BYTES))\n\n#define SDMA_DMA_DIRECTIONS\t(BIT(DMA_DEV_TO_MEM) | \\\n\t\t\t\t BIT(DMA_MEM_TO_DEV) | \\\n\t\t\t\t BIT(DMA_DEV_TO_DEV))\n\n#define SDMA_WATERMARK_LEVEL_N_FIFOS\tGENMASK(15, 12)\n#define SDMA_WATERMARK_LEVEL_OFF_FIFOS  GENMASK(19, 16)\n#define SDMA_WATERMARK_LEVEL_WORDS_PER_FIFO   GENMASK(31, 28)\n#define SDMA_WATERMARK_LEVEL_SW_DONE\tBIT(23)\n\n#define SDMA_DONE0_CONFIG_DONE_SEL\tBIT(7)\n#define SDMA_DONE0_CONFIG_DONE_DIS\tBIT(6)\n\n \nstruct sdma_script_start_addrs {\n\ts32 ap_2_ap_addr;\n\ts32 ap_2_bp_addr;\n\ts32 ap_2_ap_fixed_addr;\n\ts32 bp_2_ap_addr;\n\ts32 loopback_on_dsp_side_addr;\n\ts32 mcu_interrupt_only_addr;\n\ts32 firi_2_per_addr;\n\ts32 firi_2_mcu_addr;\n\ts32 per_2_firi_addr;\n\ts32 mcu_2_firi_addr;\n\ts32 uart_2_per_addr;\n\ts32 uart_2_mcu_addr;\n\ts32 per_2_app_addr;\n\ts32 mcu_2_app_addr;\n\ts32 per_2_per_addr;\n\ts32 uartsh_2_per_addr;\n\ts32 uartsh_2_mcu_addr;\n\ts32 per_2_shp_addr;\n\ts32 mcu_2_shp_addr;\n\ts32 ata_2_mcu_addr;\n\ts32 mcu_2_ata_addr;\n\ts32 app_2_per_addr;\n\ts32 app_2_mcu_addr;\n\ts32 shp_2_per_addr;\n\ts32 shp_2_mcu_addr;\n\ts32 mshc_2_mcu_addr;\n\ts32 mcu_2_mshc_addr;\n\ts32 spdif_2_mcu_addr;\n\ts32 mcu_2_spdif_addr;\n\ts32 asrc_2_mcu_addr;\n\ts32 ext_mem_2_ipu_addr;\n\ts32 descrambler_addr;\n\ts32 dptc_dvfs_addr;\n\ts32 utra_addr;\n\ts32 ram_code_start_addr;\n\t \n\ts32 mcu_2_ssish_addr;\n\ts32 ssish_2_mcu_addr;\n\ts32 hdmi_dma_addr;\n\t \n\ts32 zcanfd_2_mcu_addr;\n\ts32 zqspi_2_mcu_addr;\n\ts32 mcu_2_ecspi_addr;\n\ts32 mcu_2_sai_addr;\n\ts32 sai_2_mcu_addr;\n\ts32 uart_2_mcu_rom_addr;\n\ts32 uartsh_2_mcu_rom_addr;\n\t \n\ts32 mcu_2_zqspi_addr;\n\t \n};\n\n \nstruct sdma_mode_count {\n#define SDMA_BD_MAX_CNT\t0xffff\n\tu32 count   : 16;  \n\tu32 status  :  8;  \n\tu32 command :  8;  \n};\n\n \nstruct sdma_buffer_descriptor {\n\tstruct sdma_mode_count  mode;\n\tu32 buffer_addr;\t \n\tu32 ext_buffer_addr;\t \n} __attribute__ ((packed));\n\n \nstruct sdma_channel_control {\n\tu32 current_bd_ptr;\n\tu32 base_bd_ptr;\n\tu32 unused[2];\n} __attribute__ ((packed));\n\n \nstruct sdma_state_registers {\n\tu32 pc     :14;\n\tu32 unused1: 1;\n\tu32 t      : 1;\n\tu32 rpc    :14;\n\tu32 unused0: 1;\n\tu32 sf     : 1;\n\tu32 spc    :14;\n\tu32 unused2: 1;\n\tu32 df     : 1;\n\tu32 epc    :14;\n\tu32 lm     : 2;\n} __attribute__ ((packed));\n\n \nstruct sdma_context_data {\n\tstruct sdma_state_registers  channel_state;\n\tu32  gReg[8];\n\tu32  mda;\n\tu32  msa;\n\tu32  ms;\n\tu32  md;\n\tu32  pda;\n\tu32  psa;\n\tu32  ps;\n\tu32  pd;\n\tu32  ca;\n\tu32  cs;\n\tu32  dda;\n\tu32  dsa;\n\tu32  ds;\n\tu32  dd;\n\tu32  scratch0;\n\tu32  scratch1;\n\tu32  scratch2;\n\tu32  scratch3;\n\tu32  scratch4;\n\tu32  scratch5;\n\tu32  scratch6;\n\tu32  scratch7;\n} __attribute__ ((packed));\n\n\nstruct sdma_engine;\n\n \nstruct sdma_desc {\n\tstruct virt_dma_desc\tvd;\n\tunsigned int\t\tnum_bd;\n\tdma_addr_t\t\tbd_phys;\n\tunsigned int\t\tbuf_tail;\n\tunsigned int\t\tbuf_ptail;\n\tunsigned int\t\tperiod_len;\n\tunsigned int\t\tchn_real_count;\n\tunsigned int\t\tchn_count;\n\tstruct sdma_channel\t*sdmac;\n\tstruct sdma_buffer_descriptor *bd;\n};\n\n \nstruct sdma_channel {\n\tstruct virt_dma_chan\t\tvc;\n\tstruct sdma_desc\t\t*desc;\n\tstruct sdma_engine\t\t*sdma;\n\tunsigned int\t\t\tchannel;\n\tenum dma_transfer_direction\t\tdirection;\n\tstruct dma_slave_config\t\tslave_config;\n\tenum sdma_peripheral_type\tperipheral_type;\n\tunsigned int\t\t\tevent_id0;\n\tunsigned int\t\t\tevent_id1;\n\tenum dma_slave_buswidth\t\tword_size;\n\tunsigned int\t\t\tpc_from_device, pc_to_device;\n\tunsigned int\t\t\tdevice_to_device;\n\tunsigned int                    pc_to_pc;\n\tunsigned long\t\t\tflags;\n\tdma_addr_t\t\t\tper_address, per_address2;\n\tunsigned long\t\t\tevent_mask[2];\n\tunsigned long\t\t\twatermark_level;\n\tu32\t\t\t\tshp_addr, per_addr;\n\tenum dma_status\t\t\tstatus;\n\tstruct imx_dma_data\t\tdata;\n\tstruct work_struct\t\tterminate_worker;\n\tstruct list_head                terminated;\n\tbool\t\t\t\tis_ram_script;\n\tunsigned int\t\t\tn_fifos_src;\n\tunsigned int\t\t\tn_fifos_dst;\n\tunsigned int\t\t\tstride_fifos_src;\n\tunsigned int\t\t\tstride_fifos_dst;\n\tunsigned int\t\t\twords_per_fifo;\n\tbool\t\t\t\tsw_done;\n};\n\n#define IMX_DMA_SG_LOOP\t\tBIT(0)\n\n#define MAX_DMA_CHANNELS 32\n#define MXC_SDMA_DEFAULT_PRIORITY 1\n#define MXC_SDMA_MIN_PRIORITY 1\n#define MXC_SDMA_MAX_PRIORITY 7\n\n#define SDMA_FIRMWARE_MAGIC 0x414d4453\n\n \nstruct sdma_firmware_header {\n\tu32\tmagic;\n\tu32\tversion_major;\n\tu32\tversion_minor;\n\tu32\tscript_addrs_start;\n\tu32\tnum_script_addrs;\n\tu32\tram_code_start;\n\tu32\tram_code_size;\n};\n\nstruct sdma_driver_data {\n\tint chnenbl0;\n\tint num_events;\n\tstruct sdma_script_start_addrs\t*script_addrs;\n\tbool check_ratio;\n\t \n\tbool ecspi_fixed;\n};\n\nstruct sdma_engine {\n\tstruct device\t\t\t*dev;\n\tstruct sdma_channel\t\tchannel[MAX_DMA_CHANNELS];\n\tstruct sdma_channel_control\t*channel_control;\n\tvoid __iomem\t\t\t*regs;\n\tstruct sdma_context_data\t*context;\n\tdma_addr_t\t\t\tcontext_phys;\n\tstruct dma_device\t\tdma_device;\n\tstruct clk\t\t\t*clk_ipg;\n\tstruct clk\t\t\t*clk_ahb;\n\tspinlock_t\t\t\tchannel_0_lock;\n\tu32\t\t\t\tscript_number;\n\tstruct sdma_script_start_addrs\t*script_addrs;\n\tconst struct sdma_driver_data\t*drvdata;\n\tu32\t\t\t\tspba_start_addr;\n\tu32\t\t\t\tspba_end_addr;\n\tunsigned int\t\t\tirq;\n\tdma_addr_t\t\t\tbd0_phys;\n\tstruct sdma_buffer_descriptor\t*bd0;\n\t \n\tbool\t\t\t\tclk_ratio;\n\tbool                            fw_loaded;\n};\n\nstatic int sdma_config_write(struct dma_chan *chan,\n\t\t       struct dma_slave_config *dmaengine_cfg,\n\t\t       enum dma_transfer_direction direction);\n\nstatic struct sdma_driver_data sdma_imx31 = {\n\t.chnenbl0 = SDMA_CHNENBL0_IMX31,\n\t.num_events = 32,\n};\n\nstatic struct sdma_script_start_addrs sdma_script_imx25 = {\n\t.ap_2_ap_addr = 729,\n\t.uart_2_mcu_addr = 904,\n\t.per_2_app_addr = 1255,\n\t.mcu_2_app_addr = 834,\n\t.uartsh_2_mcu_addr = 1120,\n\t.per_2_shp_addr = 1329,\n\t.mcu_2_shp_addr = 1048,\n\t.ata_2_mcu_addr = 1560,\n\t.mcu_2_ata_addr = 1479,\n\t.app_2_per_addr = 1189,\n\t.app_2_mcu_addr = 770,\n\t.shp_2_per_addr = 1407,\n\t.shp_2_mcu_addr = 979,\n};\n\nstatic struct sdma_driver_data sdma_imx25 = {\n\t.chnenbl0 = SDMA_CHNENBL0_IMX35,\n\t.num_events = 48,\n\t.script_addrs = &sdma_script_imx25,\n};\n\nstatic struct sdma_driver_data sdma_imx35 = {\n\t.chnenbl0 = SDMA_CHNENBL0_IMX35,\n\t.num_events = 48,\n};\n\nstatic struct sdma_script_start_addrs sdma_script_imx51 = {\n\t.ap_2_ap_addr = 642,\n\t.uart_2_mcu_addr = 817,\n\t.mcu_2_app_addr = 747,\n\t.mcu_2_shp_addr = 961,\n\t.ata_2_mcu_addr = 1473,\n\t.mcu_2_ata_addr = 1392,\n\t.app_2_per_addr = 1033,\n\t.app_2_mcu_addr = 683,\n\t.shp_2_per_addr = 1251,\n\t.shp_2_mcu_addr = 892,\n};\n\nstatic struct sdma_driver_data sdma_imx51 = {\n\t.chnenbl0 = SDMA_CHNENBL0_IMX35,\n\t.num_events = 48,\n\t.script_addrs = &sdma_script_imx51,\n};\n\nstatic struct sdma_script_start_addrs sdma_script_imx53 = {\n\t.ap_2_ap_addr = 642,\n\t.app_2_mcu_addr = 683,\n\t.mcu_2_app_addr = 747,\n\t.uart_2_mcu_addr = 817,\n\t.shp_2_mcu_addr = 891,\n\t.mcu_2_shp_addr = 960,\n\t.uartsh_2_mcu_addr = 1032,\n\t.spdif_2_mcu_addr = 1100,\n\t.mcu_2_spdif_addr = 1134,\n\t.firi_2_mcu_addr = 1193,\n\t.mcu_2_firi_addr = 1290,\n};\n\nstatic struct sdma_driver_data sdma_imx53 = {\n\t.chnenbl0 = SDMA_CHNENBL0_IMX35,\n\t.num_events = 48,\n\t.script_addrs = &sdma_script_imx53,\n};\n\nstatic struct sdma_script_start_addrs sdma_script_imx6q = {\n\t.ap_2_ap_addr = 642,\n\t.uart_2_mcu_addr = 817,\n\t.mcu_2_app_addr = 747,\n\t.per_2_per_addr = 6331,\n\t.uartsh_2_mcu_addr = 1032,\n\t.mcu_2_shp_addr = 960,\n\t.app_2_mcu_addr = 683,\n\t.shp_2_mcu_addr = 891,\n\t.spdif_2_mcu_addr = 1100,\n\t.mcu_2_spdif_addr = 1134,\n};\n\nstatic struct sdma_driver_data sdma_imx6q = {\n\t.chnenbl0 = SDMA_CHNENBL0_IMX35,\n\t.num_events = 48,\n\t.script_addrs = &sdma_script_imx6q,\n};\n\nstatic struct sdma_driver_data sdma_imx6ul = {\n\t.chnenbl0 = SDMA_CHNENBL0_IMX35,\n\t.num_events = 48,\n\t.script_addrs = &sdma_script_imx6q,\n\t.ecspi_fixed = true,\n};\n\nstatic struct sdma_script_start_addrs sdma_script_imx7d = {\n\t.ap_2_ap_addr = 644,\n\t.uart_2_mcu_addr = 819,\n\t.mcu_2_app_addr = 749,\n\t.uartsh_2_mcu_addr = 1034,\n\t.mcu_2_shp_addr = 962,\n\t.app_2_mcu_addr = 685,\n\t.shp_2_mcu_addr = 893,\n\t.spdif_2_mcu_addr = 1102,\n\t.mcu_2_spdif_addr = 1136,\n};\n\nstatic struct sdma_driver_data sdma_imx7d = {\n\t.chnenbl0 = SDMA_CHNENBL0_IMX35,\n\t.num_events = 48,\n\t.script_addrs = &sdma_script_imx7d,\n};\n\nstatic struct sdma_driver_data sdma_imx8mq = {\n\t.chnenbl0 = SDMA_CHNENBL0_IMX35,\n\t.num_events = 48,\n\t.script_addrs = &sdma_script_imx7d,\n\t.check_ratio = 1,\n};\n\nstatic const struct of_device_id sdma_dt_ids[] = {\n\t{ .compatible = \"fsl,imx6q-sdma\", .data = &sdma_imx6q, },\n\t{ .compatible = \"fsl,imx53-sdma\", .data = &sdma_imx53, },\n\t{ .compatible = \"fsl,imx51-sdma\", .data = &sdma_imx51, },\n\t{ .compatible = \"fsl,imx35-sdma\", .data = &sdma_imx35, },\n\t{ .compatible = \"fsl,imx31-sdma\", .data = &sdma_imx31, },\n\t{ .compatible = \"fsl,imx25-sdma\", .data = &sdma_imx25, },\n\t{ .compatible = \"fsl,imx7d-sdma\", .data = &sdma_imx7d, },\n\t{ .compatible = \"fsl,imx6ul-sdma\", .data = &sdma_imx6ul, },\n\t{ .compatible = \"fsl,imx8mq-sdma\", .data = &sdma_imx8mq, },\n\t{   }\n};\nMODULE_DEVICE_TABLE(of, sdma_dt_ids);\n\n#define SDMA_H_CONFIG_DSPDMA\tBIT(12)  \n#define SDMA_H_CONFIG_RTD_PINS\tBIT(11)  \n#define SDMA_H_CONFIG_ACR\tBIT(4)   \n#define SDMA_H_CONFIG_CSM\t(3)        \n\nstatic inline u32 chnenbl_ofs(struct sdma_engine *sdma, unsigned int event)\n{\n\tu32 chnenbl0 = sdma->drvdata->chnenbl0;\n\treturn chnenbl0 + event * 4;\n}\n\nstatic int sdma_config_ownership(struct sdma_channel *sdmac,\n\t\tbool event_override, bool mcu_override, bool dsp_override)\n{\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint channel = sdmac->channel;\n\tunsigned long evt, mcu, dsp;\n\n\tif (event_override && mcu_override && dsp_override)\n\t\treturn -EINVAL;\n\n\tevt = readl_relaxed(sdma->regs + SDMA_H_EVTOVR);\n\tmcu = readl_relaxed(sdma->regs + SDMA_H_HOSTOVR);\n\tdsp = readl_relaxed(sdma->regs + SDMA_H_DSPOVR);\n\n\tif (dsp_override)\n\t\t__clear_bit(channel, &dsp);\n\telse\n\t\t__set_bit(channel, &dsp);\n\n\tif (event_override)\n\t\t__clear_bit(channel, &evt);\n\telse\n\t\t__set_bit(channel, &evt);\n\n\tif (mcu_override)\n\t\t__clear_bit(channel, &mcu);\n\telse\n\t\t__set_bit(channel, &mcu);\n\n\twritel_relaxed(evt, sdma->regs + SDMA_H_EVTOVR);\n\twritel_relaxed(mcu, sdma->regs + SDMA_H_HOSTOVR);\n\twritel_relaxed(dsp, sdma->regs + SDMA_H_DSPOVR);\n\n\treturn 0;\n}\n\nstatic int is_sdma_channel_enabled(struct sdma_engine *sdma, int channel)\n{\n\treturn !!(readl(sdma->regs + SDMA_H_STATSTOP) & BIT(channel));\n}\n\nstatic void sdma_enable_channel(struct sdma_engine *sdma, int channel)\n{\n\twritel(BIT(channel), sdma->regs + SDMA_H_START);\n}\n\n \nstatic int sdma_run_channel0(struct sdma_engine *sdma)\n{\n\tint ret;\n\tu32 reg;\n\n\tsdma_enable_channel(sdma, 0);\n\n\tret = readl_relaxed_poll_timeout_atomic(sdma->regs + SDMA_H_STATSTOP,\n\t\t\t\t\t\treg, !(reg & 1), 1, 500);\n\tif (ret)\n\t\tdev_err(sdma->dev, \"Timeout waiting for CH0 ready\\n\");\n\n\t \n\treg = readl(sdma->regs + SDMA_H_CONFIG);\n\tif ((reg & SDMA_H_CONFIG_CSM) == 0) {\n\t\treg |= SDMA_H_CONFIG_CSM;\n\t\twritel_relaxed(reg, sdma->regs + SDMA_H_CONFIG);\n\t}\n\n\treturn ret;\n}\n\nstatic int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,\n\t\tu32 address)\n{\n\tstruct sdma_buffer_descriptor *bd0 = sdma->bd0;\n\tvoid *buf_virt;\n\tdma_addr_t buf_phys;\n\tint ret;\n\tunsigned long flags;\n\n\tbuf_virt = dma_alloc_coherent(sdma->dev, size, &buf_phys, GFP_KERNEL);\n\tif (!buf_virt)\n\t\treturn -ENOMEM;\n\n\tspin_lock_irqsave(&sdma->channel_0_lock, flags);\n\n\tbd0->mode.command = C0_SETPM;\n\tbd0->mode.status = BD_DONE | BD_WRAP | BD_EXTD;\n\tbd0->mode.count = size / 2;\n\tbd0->buffer_addr = buf_phys;\n\tbd0->ext_buffer_addr = address;\n\n\tmemcpy(buf_virt, buf, size);\n\n\tret = sdma_run_channel0(sdma);\n\n\tspin_unlock_irqrestore(&sdma->channel_0_lock, flags);\n\n\tdma_free_coherent(sdma->dev, size, buf_virt, buf_phys);\n\n\treturn ret;\n}\n\nstatic void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event)\n{\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint channel = sdmac->channel;\n\tunsigned long val;\n\tu32 chnenbl = chnenbl_ofs(sdma, event);\n\n\tval = readl_relaxed(sdma->regs + chnenbl);\n\t__set_bit(channel, &val);\n\twritel_relaxed(val, sdma->regs + chnenbl);\n\n\t \n\tif (sdmac->sw_done) {\n\t\tval = readl_relaxed(sdma->regs + SDMA_DONE0_CONFIG);\n\t\tval |= SDMA_DONE0_CONFIG_DONE_SEL;\n\t\tval &= ~SDMA_DONE0_CONFIG_DONE_DIS;\n\t\twritel_relaxed(val, sdma->regs + SDMA_DONE0_CONFIG);\n\t}\n}\n\nstatic void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event)\n{\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint channel = sdmac->channel;\n\tu32 chnenbl = chnenbl_ofs(sdma, event);\n\tunsigned long val;\n\n\tval = readl_relaxed(sdma->regs + chnenbl);\n\t__clear_bit(channel, &val);\n\twritel_relaxed(val, sdma->regs + chnenbl);\n}\n\nstatic struct sdma_desc *to_sdma_desc(struct dma_async_tx_descriptor *t)\n{\n\treturn container_of(t, struct sdma_desc, vd.tx);\n}\n\nstatic void sdma_start_desc(struct sdma_channel *sdmac)\n{\n\tstruct virt_dma_desc *vd = vchan_next_desc(&sdmac->vc);\n\tstruct sdma_desc *desc;\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint channel = sdmac->channel;\n\n\tif (!vd) {\n\t\tsdmac->desc = NULL;\n\t\treturn;\n\t}\n\tsdmac->desc = desc = to_sdma_desc(&vd->tx);\n\n\tlist_del(&vd->node);\n\n\tsdma->channel_control[channel].base_bd_ptr = desc->bd_phys;\n\tsdma->channel_control[channel].current_bd_ptr = desc->bd_phys;\n\tsdma_enable_channel(sdma, sdmac->channel);\n}\n\nstatic void sdma_update_channel_loop(struct sdma_channel *sdmac)\n{\n\tstruct sdma_buffer_descriptor *bd;\n\tint error = 0;\n\tenum dma_status\told_status = sdmac->status;\n\n\t \n\twhile (sdmac->desc) {\n\t\tstruct sdma_desc *desc = sdmac->desc;\n\n\t\tbd = &desc->bd[desc->buf_tail];\n\n\t\tif (bd->mode.status & BD_DONE)\n\t\t\tbreak;\n\n\t\tif (bd->mode.status & BD_RROR) {\n\t\t\tbd->mode.status &= ~BD_RROR;\n\t\t\tsdmac->status = DMA_ERROR;\n\t\t\terror = -EIO;\n\t\t}\n\n\t        \n\n\t\tdesc->chn_real_count = bd->mode.count;\n\t\tbd->mode.count = desc->period_len;\n\t\tdesc->buf_ptail = desc->buf_tail;\n\t\tdesc->buf_tail = (desc->buf_tail + 1) % desc->num_bd;\n\n\t\t \n\t\tspin_unlock(&sdmac->vc.lock);\n\t\tdmaengine_desc_get_callback_invoke(&desc->vd.tx, NULL);\n\t\tspin_lock(&sdmac->vc.lock);\n\n\t\t \n\t\tbd->mode.status |= BD_DONE;\n\n\t\tif (error)\n\t\t\tsdmac->status = old_status;\n\t}\n\n\t \n\tif (sdmac->desc && !is_sdma_channel_enabled(sdmac->sdma, sdmac->channel)) {\n\t\tdev_warn(sdmac->sdma->dev, \"restart cyclic channel %d\\n\", sdmac->channel);\n\t\tsdma_enable_channel(sdmac->sdma, sdmac->channel);\n\t}\n}\n\nstatic void mxc_sdma_handle_channel_normal(struct sdma_channel *data)\n{\n\tstruct sdma_channel *sdmac = (struct sdma_channel *) data;\n\tstruct sdma_buffer_descriptor *bd;\n\tint i, error = 0;\n\n\tsdmac->desc->chn_real_count = 0;\n\t \n\tfor (i = 0; i < sdmac->desc->num_bd; i++) {\n\t\tbd = &sdmac->desc->bd[i];\n\n\t\tif (bd->mode.status & (BD_DONE | BD_RROR))\n\t\t\terror = -EIO;\n\t\tsdmac->desc->chn_real_count += bd->mode.count;\n\t}\n\n\tif (error)\n\t\tsdmac->status = DMA_ERROR;\n\telse\n\t\tsdmac->status = DMA_COMPLETE;\n}\n\nstatic irqreturn_t sdma_int_handler(int irq, void *dev_id)\n{\n\tstruct sdma_engine *sdma = dev_id;\n\tunsigned long stat;\n\n\tstat = readl_relaxed(sdma->regs + SDMA_H_INTR);\n\twritel_relaxed(stat, sdma->regs + SDMA_H_INTR);\n\t \n\tstat &= ~1;\n\n\twhile (stat) {\n\t\tint channel = fls(stat) - 1;\n\t\tstruct sdma_channel *sdmac = &sdma->channel[channel];\n\t\tstruct sdma_desc *desc;\n\n\t\tspin_lock(&sdmac->vc.lock);\n\t\tdesc = sdmac->desc;\n\t\tif (desc) {\n\t\t\tif (sdmac->flags & IMX_DMA_SG_LOOP) {\n\t\t\t\tif (sdmac->peripheral_type != IMX_DMATYPE_HDMI)\n\t\t\t\t\tsdma_update_channel_loop(sdmac);\n\t\t\t\telse\n\t\t\t\t\tvchan_cyclic_callback(&desc->vd);\n\t\t\t} else {\n\t\t\t\tmxc_sdma_handle_channel_normal(sdmac);\n\t\t\t\tvchan_cookie_complete(&desc->vd);\n\t\t\t\tsdma_start_desc(sdmac);\n\t\t\t}\n\t\t}\n\n\t\tspin_unlock(&sdmac->vc.lock);\n\t\t__clear_bit(channel, &stat);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic int sdma_get_pc(struct sdma_channel *sdmac,\n\t\tenum sdma_peripheral_type peripheral_type)\n{\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint per_2_emi = 0, emi_2_per = 0;\n\t \n\tint per_2_per = 0, emi_2_emi = 0;\n\n\tsdmac->pc_from_device = 0;\n\tsdmac->pc_to_device = 0;\n\tsdmac->device_to_device = 0;\n\tsdmac->pc_to_pc = 0;\n\tsdmac->is_ram_script = false;\n\n\tswitch (peripheral_type) {\n\tcase IMX_DMATYPE_MEMORY:\n\t\temi_2_emi = sdma->script_addrs->ap_2_ap_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_DSP:\n\t\temi_2_per = sdma->script_addrs->bp_2_ap_addr;\n\t\tper_2_emi = sdma->script_addrs->ap_2_bp_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_FIRI:\n\t\tper_2_emi = sdma->script_addrs->firi_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_firi_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_UART:\n\t\tper_2_emi = sdma->script_addrs->uart_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_app_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_UART_SP:\n\t\tper_2_emi = sdma->script_addrs->uartsh_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_shp_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_ATA:\n\t\tper_2_emi = sdma->script_addrs->ata_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_ata_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_CSPI:\n\t\tper_2_emi = sdma->script_addrs->app_2_mcu_addr;\n\n\t\t \n\t\tif (sdmac->sdma->drvdata->ecspi_fixed) {\n\t\t\temi_2_per = sdma->script_addrs->mcu_2_app_addr;\n\t\t} else {\n\t\t\temi_2_per = sdma->script_addrs->mcu_2_ecspi_addr;\n\t\t\tsdmac->is_ram_script = true;\n\t\t}\n\n\t\tbreak;\n\tcase IMX_DMATYPE_EXT:\n\tcase IMX_DMATYPE_SSI:\n\tcase IMX_DMATYPE_SAI:\n\t\tper_2_emi = sdma->script_addrs->app_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_app_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_SSI_DUAL:\n\t\tper_2_emi = sdma->script_addrs->ssish_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_ssish_addr;\n\t\tsdmac->is_ram_script = true;\n\t\tbreak;\n\tcase IMX_DMATYPE_SSI_SP:\n\tcase IMX_DMATYPE_MMC:\n\tcase IMX_DMATYPE_SDHC:\n\tcase IMX_DMATYPE_CSPI_SP:\n\tcase IMX_DMATYPE_ESAI:\n\tcase IMX_DMATYPE_MSHC_SP:\n\t\tper_2_emi = sdma->script_addrs->shp_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_shp_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_ASRC:\n\t\tper_2_emi = sdma->script_addrs->asrc_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->asrc_2_mcu_addr;\n\t\tper_2_per = sdma->script_addrs->per_2_per_addr;\n\t\tsdmac->is_ram_script = true;\n\t\tbreak;\n\tcase IMX_DMATYPE_ASRC_SP:\n\t\tper_2_emi = sdma->script_addrs->shp_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_shp_addr;\n\t\tper_2_per = sdma->script_addrs->per_2_per_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_MSHC:\n\t\tper_2_emi = sdma->script_addrs->mshc_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_mshc_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_CCM:\n\t\tper_2_emi = sdma->script_addrs->dptc_dvfs_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_SPDIF:\n\t\tper_2_emi = sdma->script_addrs->spdif_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_spdif_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_IPU_MEMORY:\n\t\temi_2_per = sdma->script_addrs->ext_mem_2_ipu_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_MULTI_SAI:\n\t\tper_2_emi = sdma->script_addrs->sai_2_mcu_addr;\n\t\temi_2_per = sdma->script_addrs->mcu_2_sai_addr;\n\t\tbreak;\n\tcase IMX_DMATYPE_HDMI:\n\t\temi_2_per = sdma->script_addrs->hdmi_dma_addr;\n\t\tsdmac->is_ram_script = true;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(sdma->dev, \"Unsupported transfer type %d\\n\",\n\t\t\tperipheral_type);\n\t\treturn -EINVAL;\n\t}\n\n\tsdmac->pc_from_device = per_2_emi;\n\tsdmac->pc_to_device = emi_2_per;\n\tsdmac->device_to_device = per_2_per;\n\tsdmac->pc_to_pc = emi_2_emi;\n\n\treturn 0;\n}\n\nstatic int sdma_load_context(struct sdma_channel *sdmac)\n{\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint channel = sdmac->channel;\n\tint load_address;\n\tstruct sdma_context_data *context = sdma->context;\n\tstruct sdma_buffer_descriptor *bd0 = sdma->bd0;\n\tint ret;\n\tunsigned long flags;\n\n\tif (sdmac->direction == DMA_DEV_TO_MEM)\n\t\tload_address = sdmac->pc_from_device;\n\telse if (sdmac->direction == DMA_DEV_TO_DEV)\n\t\tload_address = sdmac->device_to_device;\n\telse if (sdmac->direction == DMA_MEM_TO_MEM)\n\t\tload_address = sdmac->pc_to_pc;\n\telse\n\t\tload_address = sdmac->pc_to_device;\n\n\tif (load_address < 0)\n\t\treturn load_address;\n\n\tdev_dbg(sdma->dev, \"load_address = %d\\n\", load_address);\n\tdev_dbg(sdma->dev, \"wml = 0x%08x\\n\", (u32)sdmac->watermark_level);\n\tdev_dbg(sdma->dev, \"shp_addr = 0x%08x\\n\", sdmac->shp_addr);\n\tdev_dbg(sdma->dev, \"per_addr = 0x%08x\\n\", sdmac->per_addr);\n\tdev_dbg(sdma->dev, \"event_mask0 = 0x%08x\\n\", (u32)sdmac->event_mask[0]);\n\tdev_dbg(sdma->dev, \"event_mask1 = 0x%08x\\n\", (u32)sdmac->event_mask[1]);\n\n\tspin_lock_irqsave(&sdma->channel_0_lock, flags);\n\n\tmemset(context, 0, sizeof(*context));\n\tcontext->channel_state.pc = load_address;\n\n\t \n\tif (sdmac->peripheral_type == IMX_DMATYPE_HDMI) {\n\t\tcontext->gReg[4] = sdmac->per_addr;\n\t\tcontext->gReg[6] = sdmac->shp_addr;\n\t} else {\n\t\tcontext->gReg[0] = sdmac->event_mask[1];\n\t\tcontext->gReg[1] = sdmac->event_mask[0];\n\t\tcontext->gReg[2] = sdmac->per_addr;\n\t\tcontext->gReg[6] = sdmac->shp_addr;\n\t\tcontext->gReg[7] = sdmac->watermark_level;\n\t}\n\n\tbd0->mode.command = C0_SETDM;\n\tbd0->mode.status = BD_DONE | BD_WRAP | BD_EXTD;\n\tbd0->mode.count = sizeof(*context) / 4;\n\tbd0->buffer_addr = sdma->context_phys;\n\tbd0->ext_buffer_addr = 2048 + (sizeof(*context) / 4) * channel;\n\tret = sdma_run_channel0(sdma);\n\n\tspin_unlock_irqrestore(&sdma->channel_0_lock, flags);\n\n\treturn ret;\n}\n\nstatic struct sdma_channel *to_sdma_chan(struct dma_chan *chan)\n{\n\treturn container_of(chan, struct sdma_channel, vc.chan);\n}\n\nstatic int sdma_disable_channel(struct dma_chan *chan)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint channel = sdmac->channel;\n\n\twritel_relaxed(BIT(channel), sdma->regs + SDMA_H_STATSTOP);\n\tsdmac->status = DMA_ERROR;\n\n\treturn 0;\n}\nstatic void sdma_channel_terminate_work(struct work_struct *work)\n{\n\tstruct sdma_channel *sdmac = container_of(work, struct sdma_channel,\n\t\t\t\t\t\t  terminate_worker);\n\t \n\tusleep_range(1000, 2000);\n\n\tvchan_dma_desc_free_list(&sdmac->vc, &sdmac->terminated);\n}\n\nstatic int sdma_terminate_all(struct dma_chan *chan)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&sdmac->vc.lock, flags);\n\n\tsdma_disable_channel(chan);\n\n\tif (sdmac->desc) {\n\t\tvchan_terminate_vdesc(&sdmac->desc->vd);\n\t\t \n\t\tvchan_get_all_descriptors(&sdmac->vc, &sdmac->terminated);\n\t\tsdmac->desc = NULL;\n\t\tschedule_work(&sdmac->terminate_worker);\n\t}\n\n\tspin_unlock_irqrestore(&sdmac->vc.lock, flags);\n\n\treturn 0;\n}\n\nstatic void sdma_channel_synchronize(struct dma_chan *chan)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\n\tvchan_synchronize(&sdmac->vc);\n\n\tflush_work(&sdmac->terminate_worker);\n}\n\nstatic void sdma_set_watermarklevel_for_p2p(struct sdma_channel *sdmac)\n{\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\n\tint lwml = sdmac->watermark_level & SDMA_WATERMARK_LEVEL_LWML;\n\tint hwml = (sdmac->watermark_level & SDMA_WATERMARK_LEVEL_HWML) >> 16;\n\n\tset_bit(sdmac->event_id0 % 32, &sdmac->event_mask[1]);\n\tset_bit(sdmac->event_id1 % 32, &sdmac->event_mask[0]);\n\n\tif (sdmac->event_id0 > 31)\n\t\tsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_LWE;\n\n\tif (sdmac->event_id1 > 31)\n\t\tsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_HWE;\n\n\t \n\tif (lwml > hwml) {\n\t\tsdmac->watermark_level &= ~(SDMA_WATERMARK_LEVEL_LWML |\n\t\t\t\t\t\tSDMA_WATERMARK_LEVEL_HWML);\n\t\tsdmac->watermark_level |= hwml;\n\t\tsdmac->watermark_level |= lwml << 16;\n\t\tswap(sdmac->event_mask[0], sdmac->event_mask[1]);\n\t}\n\n\tif (sdmac->per_address2 >= sdma->spba_start_addr &&\n\t\t\tsdmac->per_address2 <= sdma->spba_end_addr)\n\t\tsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_SP;\n\n\tif (sdmac->per_address >= sdma->spba_start_addr &&\n\t\t\tsdmac->per_address <= sdma->spba_end_addr)\n\t\tsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_DP;\n\n\tsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_CONT;\n}\n\nstatic void sdma_set_watermarklevel_for_sais(struct sdma_channel *sdmac)\n{\n\tunsigned int n_fifos;\n\tunsigned int stride_fifos;\n\tunsigned int words_per_fifo;\n\n\tif (sdmac->sw_done)\n\t\tsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_SW_DONE;\n\n\tif (sdmac->direction == DMA_DEV_TO_MEM) {\n\t\tn_fifos = sdmac->n_fifos_src;\n\t\tstride_fifos = sdmac->stride_fifos_src;\n\t} else {\n\t\tn_fifos = sdmac->n_fifos_dst;\n\t\tstride_fifos = sdmac->stride_fifos_dst;\n\t}\n\n\twords_per_fifo = sdmac->words_per_fifo;\n\n\tsdmac->watermark_level |=\n\t\t\tFIELD_PREP(SDMA_WATERMARK_LEVEL_N_FIFOS, n_fifos);\n\tsdmac->watermark_level |=\n\t\t\tFIELD_PREP(SDMA_WATERMARK_LEVEL_OFF_FIFOS, stride_fifos);\n\tif (words_per_fifo)\n\t\tsdmac->watermark_level |=\n\t\t\tFIELD_PREP(SDMA_WATERMARK_LEVEL_WORDS_PER_FIFO, (words_per_fifo - 1));\n}\n\nstatic int sdma_config_channel(struct dma_chan *chan)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tint ret;\n\n\tsdma_disable_channel(chan);\n\n\tsdmac->event_mask[0] = 0;\n\tsdmac->event_mask[1] = 0;\n\tsdmac->shp_addr = 0;\n\tsdmac->per_addr = 0;\n\n\tswitch (sdmac->peripheral_type) {\n\tcase IMX_DMATYPE_DSP:\n\t\tsdma_config_ownership(sdmac, false, true, true);\n\t\tbreak;\n\tcase IMX_DMATYPE_MEMORY:\n\t\tsdma_config_ownership(sdmac, false, true, false);\n\t\tbreak;\n\tdefault:\n\t\tsdma_config_ownership(sdmac, true, true, false);\n\t\tbreak;\n\t}\n\n\tret = sdma_get_pc(sdmac, sdmac->peripheral_type);\n\tif (ret)\n\t\treturn ret;\n\n\tif ((sdmac->peripheral_type != IMX_DMATYPE_MEMORY) &&\n\t\t\t(sdmac->peripheral_type != IMX_DMATYPE_DSP)) {\n\t\t \n\t\tif (sdmac->event_id1) {\n\t\t\tif (sdmac->peripheral_type == IMX_DMATYPE_ASRC_SP ||\n\t\t\t    sdmac->peripheral_type == IMX_DMATYPE_ASRC)\n\t\t\t\tsdma_set_watermarklevel_for_p2p(sdmac);\n\t\t} else {\n\t\t\tif (sdmac->peripheral_type ==\n\t\t\t\t\tIMX_DMATYPE_MULTI_SAI)\n\t\t\t\tsdma_set_watermarklevel_for_sais(sdmac);\n\n\t\t\t__set_bit(sdmac->event_id0, sdmac->event_mask);\n\t\t}\n\n\t\t \n\t\tsdmac->shp_addr = sdmac->per_address;\n\t\tsdmac->per_addr = sdmac->per_address2;\n\t} else {\n\t\tsdmac->watermark_level = 0;  \n\t}\n\n\treturn 0;\n}\n\nstatic int sdma_set_channel_priority(struct sdma_channel *sdmac,\n\t\t\t\t     unsigned int priority)\n{\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint channel = sdmac->channel;\n\n\tif (priority < MXC_SDMA_MIN_PRIORITY\n\t    || priority > MXC_SDMA_MAX_PRIORITY) {\n\t\treturn -EINVAL;\n\t}\n\n\twritel_relaxed(priority, sdma->regs + SDMA_CHNPRI_0 + 4 * channel);\n\n\treturn 0;\n}\n\nstatic int sdma_request_channel0(struct sdma_engine *sdma)\n{\n\tint ret = -EBUSY;\n\n\tsdma->bd0 = dma_alloc_coherent(sdma->dev, PAGE_SIZE, &sdma->bd0_phys,\n\t\t\t\t       GFP_NOWAIT);\n\tif (!sdma->bd0) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tsdma->channel_control[0].base_bd_ptr = sdma->bd0_phys;\n\tsdma->channel_control[0].current_bd_ptr = sdma->bd0_phys;\n\n\tsdma_set_channel_priority(&sdma->channel[0], MXC_SDMA_DEFAULT_PRIORITY);\n\treturn 0;\nout:\n\n\treturn ret;\n}\n\n\nstatic int sdma_alloc_bd(struct sdma_desc *desc)\n{\n\tu32 bd_size = desc->num_bd * sizeof(struct sdma_buffer_descriptor);\n\tint ret = 0;\n\n\tdesc->bd = dma_alloc_coherent(desc->sdmac->sdma->dev, bd_size,\n\t\t\t\t      &desc->bd_phys, GFP_NOWAIT);\n\tif (!desc->bd) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\nout:\n\treturn ret;\n}\n\nstatic void sdma_free_bd(struct sdma_desc *desc)\n{\n\tu32 bd_size = desc->num_bd * sizeof(struct sdma_buffer_descriptor);\n\n\tdma_free_coherent(desc->sdmac->sdma->dev, bd_size, desc->bd,\n\t\t\t  desc->bd_phys);\n}\n\nstatic void sdma_desc_free(struct virt_dma_desc *vd)\n{\n\tstruct sdma_desc *desc = container_of(vd, struct sdma_desc, vd);\n\n\tsdma_free_bd(desc);\n\tkfree(desc);\n}\n\nstatic int sdma_alloc_chan_resources(struct dma_chan *chan)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tstruct imx_dma_data *data = chan->private;\n\tstruct imx_dma_data mem_data;\n\tint prio, ret;\n\n\t \n\tif (!data) {\n\t\tdev_dbg(sdmac->sdma->dev, \"MEMCPY in case?\\n\");\n\t\tmem_data.priority = 2;\n\t\tmem_data.peripheral_type = IMX_DMATYPE_MEMORY;\n\t\tmem_data.dma_request = 0;\n\t\tmem_data.dma_request2 = 0;\n\t\tdata = &mem_data;\n\n\t\tret = sdma_get_pc(sdmac, IMX_DMATYPE_MEMORY);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tswitch (data->priority) {\n\tcase DMA_PRIO_HIGH:\n\t\tprio = 3;\n\t\tbreak;\n\tcase DMA_PRIO_MEDIUM:\n\t\tprio = 2;\n\t\tbreak;\n\tcase DMA_PRIO_LOW:\n\tdefault:\n\t\tprio = 1;\n\t\tbreak;\n\t}\n\n\tsdmac->peripheral_type = data->peripheral_type;\n\tsdmac->event_id0 = data->dma_request;\n\tsdmac->event_id1 = data->dma_request2;\n\n\tret = clk_enable(sdmac->sdma->clk_ipg);\n\tif (ret)\n\t\treturn ret;\n\tret = clk_enable(sdmac->sdma->clk_ahb);\n\tif (ret)\n\t\tgoto disable_clk_ipg;\n\n\tret = sdma_set_channel_priority(sdmac, prio);\n\tif (ret)\n\t\tgoto disable_clk_ahb;\n\n\treturn 0;\n\ndisable_clk_ahb:\n\tclk_disable(sdmac->sdma->clk_ahb);\ndisable_clk_ipg:\n\tclk_disable(sdmac->sdma->clk_ipg);\n\treturn ret;\n}\n\nstatic void sdma_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\n\tsdma_terminate_all(chan);\n\n\tsdma_channel_synchronize(chan);\n\n\tsdma_event_disable(sdmac, sdmac->event_id0);\n\tif (sdmac->event_id1)\n\t\tsdma_event_disable(sdmac, sdmac->event_id1);\n\n\tsdmac->event_id0 = 0;\n\tsdmac->event_id1 = 0;\n\n\tsdma_set_channel_priority(sdmac, 0);\n\n\tclk_disable(sdma->clk_ipg);\n\tclk_disable(sdma->clk_ahb);\n}\n\nstatic struct sdma_desc *sdma_transfer_init(struct sdma_channel *sdmac,\n\t\t\t\tenum dma_transfer_direction direction, u32 bds)\n{\n\tstruct sdma_desc *desc;\n\n\tif (!sdmac->sdma->fw_loaded && sdmac->is_ram_script) {\n\t\tdev_warn_once(sdmac->sdma->dev, \"sdma firmware not ready!\\n\");\n\t\tgoto err_out;\n\t}\n\n\tdesc = kzalloc((sizeof(*desc)), GFP_NOWAIT);\n\tif (!desc)\n\t\tgoto err_out;\n\n\tsdmac->status = DMA_IN_PROGRESS;\n\tsdmac->direction = direction;\n\tsdmac->flags = 0;\n\n\tdesc->chn_count = 0;\n\tdesc->chn_real_count = 0;\n\tdesc->buf_tail = 0;\n\tdesc->buf_ptail = 0;\n\tdesc->sdmac = sdmac;\n\tdesc->num_bd = bds;\n\n\tif (bds && sdma_alloc_bd(desc))\n\t\tgoto err_desc_out;\n\n\t \n\tif (direction == DMA_MEM_TO_MEM)\n\t\tsdma_config_ownership(sdmac, false, true, false);\n\n\tif (sdma_load_context(sdmac))\n\t\tgoto err_bd_out;\n\n\treturn desc;\n\nerr_bd_out:\n\tsdma_free_bd(desc);\nerr_desc_out:\n\tkfree(desc);\nerr_out:\n\treturn NULL;\n}\n\nstatic struct dma_async_tx_descriptor *sdma_prep_memcpy(\n\t\tstruct dma_chan *chan, dma_addr_t dma_dst,\n\t\tdma_addr_t dma_src, size_t len, unsigned long flags)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint channel = sdmac->channel;\n\tsize_t count;\n\tint i = 0, param;\n\tstruct sdma_buffer_descriptor *bd;\n\tstruct sdma_desc *desc;\n\n\tif (!chan || !len)\n\t\treturn NULL;\n\n\tdev_dbg(sdma->dev, \"memcpy: %pad->%pad, len=%zu, channel=%d.\\n\",\n\t\t&dma_src, &dma_dst, len, channel);\n\n\tdesc = sdma_transfer_init(sdmac, DMA_MEM_TO_MEM,\n\t\t\t\t\tlen / SDMA_BD_MAX_CNT + 1);\n\tif (!desc)\n\t\treturn NULL;\n\n\tdo {\n\t\tcount = min_t(size_t, len, SDMA_BD_MAX_CNT);\n\t\tbd = &desc->bd[i];\n\t\tbd->buffer_addr = dma_src;\n\t\tbd->ext_buffer_addr = dma_dst;\n\t\tbd->mode.count = count;\n\t\tdesc->chn_count += count;\n\t\tbd->mode.command = 0;\n\n\t\tdma_src += count;\n\t\tdma_dst += count;\n\t\tlen -= count;\n\t\ti++;\n\n\t\tparam = BD_DONE | BD_EXTD | BD_CONT;\n\t\t \n\t\tif (!len) {\n\t\t\tparam |= BD_INTR;\n\t\t\tparam |= BD_LAST;\n\t\t\tparam &= ~BD_CONT;\n\t\t}\n\n\t\tdev_dbg(sdma->dev, \"entry %d: count: %zd dma: 0x%x %s%s\\n\",\n\t\t\t\ti, count, bd->buffer_addr,\n\t\t\t\tparam & BD_WRAP ? \"wrap\" : \"\",\n\t\t\t\tparam & BD_INTR ? \" intr\" : \"\");\n\n\t\tbd->mode.status = param;\n\t} while (len);\n\n\treturn vchan_tx_prep(&sdmac->vc, &desc->vd, flags);\n}\n\nstatic struct dma_async_tx_descriptor *sdma_prep_slave_sg(\n\t\tstruct dma_chan *chan, struct scatterlist *sgl,\n\t\tunsigned int sg_len, enum dma_transfer_direction direction,\n\t\tunsigned long flags, void *context)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint i, count;\n\tint channel = sdmac->channel;\n\tstruct scatterlist *sg;\n\tstruct sdma_desc *desc;\n\n\tsdma_config_write(chan, &sdmac->slave_config, direction);\n\n\tdesc = sdma_transfer_init(sdmac, direction, sg_len);\n\tif (!desc)\n\t\tgoto err_out;\n\n\tdev_dbg(sdma->dev, \"setting up %d entries for channel %d.\\n\",\n\t\t\tsg_len, channel);\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tstruct sdma_buffer_descriptor *bd = &desc->bd[i];\n\t\tint param;\n\n\t\tbd->buffer_addr = sg->dma_address;\n\n\t\tcount = sg_dma_len(sg);\n\n\t\tif (count > SDMA_BD_MAX_CNT) {\n\t\t\tdev_err(sdma->dev, \"SDMA channel %d: maximum bytes for sg entry exceeded: %d > %d\\n\",\n\t\t\t\t\tchannel, count, SDMA_BD_MAX_CNT);\n\t\t\tgoto err_bd_out;\n\t\t}\n\n\t\tbd->mode.count = count;\n\t\tdesc->chn_count += count;\n\n\t\tif (sdmac->word_size > DMA_SLAVE_BUSWIDTH_4_BYTES)\n\t\t\tgoto err_bd_out;\n\n\t\tswitch (sdmac->word_size) {\n\t\tcase DMA_SLAVE_BUSWIDTH_4_BYTES:\n\t\t\tbd->mode.command = 0;\n\t\t\tif (count & 3 || sg->dma_address & 3)\n\t\t\t\tgoto err_bd_out;\n\t\t\tbreak;\n\t\tcase DMA_SLAVE_BUSWIDTH_2_BYTES:\n\t\t\tbd->mode.command = 2;\n\t\t\tif (count & 1 || sg->dma_address & 1)\n\t\t\t\tgoto err_bd_out;\n\t\t\tbreak;\n\t\tcase DMA_SLAVE_BUSWIDTH_1_BYTE:\n\t\t\tbd->mode.command = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto err_bd_out;\n\t\t}\n\n\t\tparam = BD_DONE | BD_EXTD | BD_CONT;\n\n\t\tif (i + 1 == sg_len) {\n\t\t\tparam |= BD_INTR;\n\t\t\tparam |= BD_LAST;\n\t\t\tparam &= ~BD_CONT;\n\t\t}\n\n\t\tdev_dbg(sdma->dev, \"entry %d: count: %d dma: %#llx %s%s\\n\",\n\t\t\t\ti, count, (u64)sg->dma_address,\n\t\t\t\tparam & BD_WRAP ? \"wrap\" : \"\",\n\t\t\t\tparam & BD_INTR ? \" intr\" : \"\");\n\n\t\tbd->mode.status = param;\n\t}\n\n\treturn vchan_tx_prep(&sdmac->vc, &desc->vd, flags);\nerr_bd_out:\n\tsdma_free_bd(desc);\n\tkfree(desc);\nerr_out:\n\tsdmac->status = DMA_ERROR;\n\treturn NULL;\n}\n\nstatic struct dma_async_tx_descriptor *sdma_prep_dma_cyclic(\n\t\tstruct dma_chan *chan, dma_addr_t dma_addr, size_t buf_len,\n\t\tsize_t period_len, enum dma_transfer_direction direction,\n\t\tunsigned long flags)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\tint num_periods = 0;\n\tint channel = sdmac->channel;\n\tint i = 0, buf = 0;\n\tstruct sdma_desc *desc;\n\n\tdev_dbg(sdma->dev, \"%s channel: %d\\n\", __func__, channel);\n\n\tif (sdmac->peripheral_type != IMX_DMATYPE_HDMI)\n\t\tnum_periods = buf_len / period_len;\n\n\tsdma_config_write(chan, &sdmac->slave_config, direction);\n\n\tdesc = sdma_transfer_init(sdmac, direction, num_periods);\n\tif (!desc)\n\t\tgoto err_out;\n\n\tdesc->period_len = period_len;\n\n\tsdmac->flags |= IMX_DMA_SG_LOOP;\n\n\tif (period_len > SDMA_BD_MAX_CNT) {\n\t\tdev_err(sdma->dev, \"SDMA channel %d: maximum period size exceeded: %zu > %d\\n\",\n\t\t\t\tchannel, period_len, SDMA_BD_MAX_CNT);\n\t\tgoto err_bd_out;\n\t}\n\n\tif (sdmac->peripheral_type == IMX_DMATYPE_HDMI)\n\t\treturn vchan_tx_prep(&sdmac->vc, &desc->vd, flags);\n\n\twhile (buf < buf_len) {\n\t\tstruct sdma_buffer_descriptor *bd = &desc->bd[i];\n\t\tint param;\n\n\t\tbd->buffer_addr = dma_addr;\n\n\t\tbd->mode.count = period_len;\n\n\t\tif (sdmac->word_size > DMA_SLAVE_BUSWIDTH_4_BYTES)\n\t\t\tgoto err_bd_out;\n\t\tif (sdmac->word_size == DMA_SLAVE_BUSWIDTH_4_BYTES)\n\t\t\tbd->mode.command = 0;\n\t\telse\n\t\t\tbd->mode.command = sdmac->word_size;\n\n\t\tparam = BD_DONE | BD_EXTD | BD_CONT | BD_INTR;\n\t\tif (i + 1 == num_periods)\n\t\t\tparam |= BD_WRAP;\n\n\t\tdev_dbg(sdma->dev, \"entry %d: count: %zu dma: %#llx %s%s\\n\",\n\t\t\t\ti, period_len, (u64)dma_addr,\n\t\t\t\tparam & BD_WRAP ? \"wrap\" : \"\",\n\t\t\t\tparam & BD_INTR ? \" intr\" : \"\");\n\n\t\tbd->mode.status = param;\n\n\t\tdma_addr += period_len;\n\t\tbuf += period_len;\n\n\t\ti++;\n\t}\n\n\treturn vchan_tx_prep(&sdmac->vc, &desc->vd, flags);\nerr_bd_out:\n\tsdma_free_bd(desc);\n\tkfree(desc);\nerr_out:\n\tsdmac->status = DMA_ERROR;\n\treturn NULL;\n}\n\nstatic int sdma_config_write(struct dma_chan *chan,\n\t\t       struct dma_slave_config *dmaengine_cfg,\n\t\t       enum dma_transfer_direction direction)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\n\tif (direction == DMA_DEV_TO_MEM) {\n\t\tsdmac->per_address = dmaengine_cfg->src_addr;\n\t\tsdmac->watermark_level = dmaengine_cfg->src_maxburst *\n\t\t\tdmaengine_cfg->src_addr_width;\n\t\tsdmac->word_size = dmaengine_cfg->src_addr_width;\n\t} else if (direction == DMA_DEV_TO_DEV) {\n\t\tsdmac->per_address2 = dmaengine_cfg->src_addr;\n\t\tsdmac->per_address = dmaengine_cfg->dst_addr;\n\t\tsdmac->watermark_level = dmaengine_cfg->src_maxburst &\n\t\t\tSDMA_WATERMARK_LEVEL_LWML;\n\t\tsdmac->watermark_level |= (dmaengine_cfg->dst_maxburst << 16) &\n\t\t\tSDMA_WATERMARK_LEVEL_HWML;\n\t\tsdmac->word_size = dmaengine_cfg->dst_addr_width;\n\t} else if (sdmac->peripheral_type == IMX_DMATYPE_HDMI) {\n\t\tsdmac->per_address = dmaengine_cfg->dst_addr;\n\t\tsdmac->per_address2 = dmaengine_cfg->src_addr;\n\t\tsdmac->watermark_level = 0;\n\t} else {\n\t\tsdmac->per_address = dmaengine_cfg->dst_addr;\n\t\tsdmac->watermark_level = dmaengine_cfg->dst_maxburst *\n\t\t\tdmaengine_cfg->dst_addr_width;\n\t\tsdmac->word_size = dmaengine_cfg->dst_addr_width;\n\t}\n\tsdmac->direction = direction;\n\treturn sdma_config_channel(chan);\n}\n\nstatic int sdma_config(struct dma_chan *chan,\n\t\t       struct dma_slave_config *dmaengine_cfg)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tstruct sdma_engine *sdma = sdmac->sdma;\n\n\tmemcpy(&sdmac->slave_config, dmaengine_cfg, sizeof(*dmaengine_cfg));\n\n\tif (dmaengine_cfg->peripheral_config) {\n\t\tstruct sdma_peripheral_config *sdmacfg = dmaengine_cfg->peripheral_config;\n\t\tif (dmaengine_cfg->peripheral_size != sizeof(struct sdma_peripheral_config)) {\n\t\t\tdev_err(sdma->dev, \"Invalid peripheral size %zu, expected %zu\\n\",\n\t\t\t\tdmaengine_cfg->peripheral_size,\n\t\t\t\tsizeof(struct sdma_peripheral_config));\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tsdmac->n_fifos_src = sdmacfg->n_fifos_src;\n\t\tsdmac->n_fifos_dst = sdmacfg->n_fifos_dst;\n\t\tsdmac->stride_fifos_src = sdmacfg->stride_fifos_src;\n\t\tsdmac->stride_fifos_dst = sdmacfg->stride_fifos_dst;\n\t\tsdmac->words_per_fifo = sdmacfg->words_per_fifo;\n\t\tsdmac->sw_done = sdmacfg->sw_done;\n\t}\n\n\t \n\tif (sdmac->event_id0 >= sdmac->sdma->drvdata->num_events)\n\t\treturn -EINVAL;\n\tsdma_event_enable(sdmac, sdmac->event_id0);\n\n\tif (sdmac->event_id1) {\n\t\tif (sdmac->event_id1 >= sdmac->sdma->drvdata->num_events)\n\t\t\treturn -EINVAL;\n\t\tsdma_event_enable(sdmac, sdmac->event_id1);\n\t}\n\n\treturn 0;\n}\n\nstatic enum dma_status sdma_tx_status(struct dma_chan *chan,\n\t\t\t\t      dma_cookie_t cookie,\n\t\t\t\t      struct dma_tx_state *txstate)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tstruct sdma_desc *desc = NULL;\n\tu32 residue;\n\tstruct virt_dma_desc *vd;\n\tenum dma_status ret;\n\tunsigned long flags;\n\n\tret = dma_cookie_status(chan, cookie, txstate);\n\tif (ret == DMA_COMPLETE || !txstate)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&sdmac->vc.lock, flags);\n\n\tvd = vchan_find_desc(&sdmac->vc, cookie);\n\tif (vd)\n\t\tdesc = to_sdma_desc(&vd->tx);\n\telse if (sdmac->desc && sdmac->desc->vd.tx.cookie == cookie)\n\t\tdesc = sdmac->desc;\n\n\tif (desc) {\n\t\tif (sdmac->flags & IMX_DMA_SG_LOOP)\n\t\t\tresidue = (desc->num_bd - desc->buf_ptail) *\n\t\t\t\tdesc->period_len - desc->chn_real_count;\n\t\telse\n\t\t\tresidue = desc->chn_count - desc->chn_real_count;\n\t} else {\n\t\tresidue = 0;\n\t}\n\n\tspin_unlock_irqrestore(&sdmac->vc.lock, flags);\n\n\tdma_set_tx_state(txstate, chan->completed_cookie, chan->cookie,\n\t\t\t residue);\n\n\treturn sdmac->status;\n}\n\nstatic void sdma_issue_pending(struct dma_chan *chan)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&sdmac->vc.lock, flags);\n\tif (vchan_issue_pending(&sdmac->vc) && !sdmac->desc)\n\t\tsdma_start_desc(sdmac);\n\tspin_unlock_irqrestore(&sdmac->vc.lock, flags);\n}\n\n#define SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V1\t34\n#define SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V2\t38\n#define SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V3\t45\n#define SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V4\t46\n\nstatic void sdma_add_scripts(struct sdma_engine *sdma,\n\t\t\t     const struct sdma_script_start_addrs *addr)\n{\n\ts32 *addr_arr = (u32 *)addr;\n\ts32 *saddr_arr = (u32 *)sdma->script_addrs;\n\tint i;\n\n\t \n\tif (!sdma->script_number)\n\t\tsdma->script_number = SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V1;\n\n\tif (sdma->script_number > sizeof(struct sdma_script_start_addrs)\n\t\t\t\t  / sizeof(s32)) {\n\t\tdev_err(sdma->dev,\n\t\t\t\"SDMA script number %d not match with firmware.\\n\",\n\t\t\tsdma->script_number);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < sdma->script_number; i++)\n\t\tif (addr_arr[i] > 0)\n\t\t\tsaddr_arr[i] = addr_arr[i];\n\n\t \n\tif (sdma->script_number >= SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V3) {\n\t\tif (addr->uart_2_mcu_rom_addr)\n\t\t\tsdma->script_addrs->uart_2_mcu_addr = addr->uart_2_mcu_rom_addr;\n\t\tif (addr->uartsh_2_mcu_rom_addr)\n\t\t\tsdma->script_addrs->uartsh_2_mcu_addr = addr->uartsh_2_mcu_rom_addr;\n\t}\n}\n\nstatic void sdma_load_firmware(const struct firmware *fw, void *context)\n{\n\tstruct sdma_engine *sdma = context;\n\tconst struct sdma_firmware_header *header;\n\tconst struct sdma_script_start_addrs *addr;\n\tunsigned short *ram_code;\n\n\tif (!fw) {\n\t\tdev_info(sdma->dev, \"external firmware not found, using ROM firmware\\n\");\n\t\t \n\t\treturn;\n\t}\n\n\tif (fw->size < sizeof(*header))\n\t\tgoto err_firmware;\n\n\theader = (struct sdma_firmware_header *)fw->data;\n\n\tif (header->magic != SDMA_FIRMWARE_MAGIC)\n\t\tgoto err_firmware;\n\tif (header->ram_code_start + header->ram_code_size > fw->size)\n\t\tgoto err_firmware;\n\tswitch (header->version_major) {\n\tcase 1:\n\t\tsdma->script_number = SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V1;\n\t\tbreak;\n\tcase 2:\n\t\tsdma->script_number = SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V2;\n\t\tbreak;\n\tcase 3:\n\t\tsdma->script_number = SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V3;\n\t\tbreak;\n\tcase 4:\n\t\tsdma->script_number = SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V4;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(sdma->dev, \"unknown firmware version\\n\");\n\t\tgoto err_firmware;\n\t}\n\n\taddr = (void *)header + header->script_addrs_start;\n\tram_code = (void *)header + header->ram_code_start;\n\n\tclk_enable(sdma->clk_ipg);\n\tclk_enable(sdma->clk_ahb);\n\t \n\tsdma_load_script(sdma, ram_code,\n\t\t\t header->ram_code_size,\n\t\t\t addr->ram_code_start_addr);\n\tclk_disable(sdma->clk_ipg);\n\tclk_disable(sdma->clk_ahb);\n\n\tsdma_add_scripts(sdma, addr);\n\n\tsdma->fw_loaded = true;\n\n\tdev_info(sdma->dev, \"loaded firmware %d.%d\\n\",\n\t\t header->version_major,\n\t\t header->version_minor);\n\nerr_firmware:\n\trelease_firmware(fw);\n}\n\n#define EVENT_REMAP_CELLS 3\n\nstatic int sdma_event_remap(struct sdma_engine *sdma)\n{\n\tstruct device_node *np = sdma->dev->of_node;\n\tstruct device_node *gpr_np = of_parse_phandle(np, \"gpr\", 0);\n\tstruct property *event_remap;\n\tstruct regmap *gpr;\n\tchar propname[] = \"fsl,sdma-event-remap\";\n\tu32 reg, val, shift, num_map, i;\n\tint ret = 0;\n\n\tif (IS_ERR(np) || !gpr_np)\n\t\tgoto out;\n\n\tevent_remap = of_find_property(np, propname, NULL);\n\tnum_map = event_remap ? (event_remap->length / sizeof(u32)) : 0;\n\tif (!num_map) {\n\t\tdev_dbg(sdma->dev, \"no event needs to be remapped\\n\");\n\t\tgoto out;\n\t} else if (num_map % EVENT_REMAP_CELLS) {\n\t\tdev_err(sdma->dev, \"the property %s must modulo %d\\n\",\n\t\t\t\tpropname, EVENT_REMAP_CELLS);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tgpr = syscon_node_to_regmap(gpr_np);\n\tif (IS_ERR(gpr)) {\n\t\tdev_err(sdma->dev, \"failed to get gpr regmap\\n\");\n\t\tret = PTR_ERR(gpr);\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < num_map; i += EVENT_REMAP_CELLS) {\n\t\tret = of_property_read_u32_index(np, propname, i, &reg);\n\t\tif (ret) {\n\t\t\tdev_err(sdma->dev, \"failed to read property %s index %d\\n\",\n\t\t\t\t\tpropname, i);\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = of_property_read_u32_index(np, propname, i + 1, &shift);\n\t\tif (ret) {\n\t\t\tdev_err(sdma->dev, \"failed to read property %s index %d\\n\",\n\t\t\t\t\tpropname, i + 1);\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = of_property_read_u32_index(np, propname, i + 2, &val);\n\t\tif (ret) {\n\t\t\tdev_err(sdma->dev, \"failed to read property %s index %d\\n\",\n\t\t\t\t\tpropname, i + 2);\n\t\t\tgoto out;\n\t\t}\n\n\t\tregmap_update_bits(gpr, reg, BIT(shift), val << shift);\n\t}\n\nout:\n\tif (gpr_np)\n\t\tof_node_put(gpr_np);\n\n\treturn ret;\n}\n\nstatic int sdma_get_firmware(struct sdma_engine *sdma,\n\t\tconst char *fw_name)\n{\n\tint ret;\n\n\tret = request_firmware_nowait(THIS_MODULE,\n\t\t\tFW_ACTION_UEVENT, fw_name, sdma->dev,\n\t\t\tGFP_KERNEL, sdma, sdma_load_firmware);\n\n\treturn ret;\n}\n\nstatic int sdma_init(struct sdma_engine *sdma)\n{\n\tint i, ret;\n\tdma_addr_t ccb_phys;\n\n\tret = clk_enable(sdma->clk_ipg);\n\tif (ret)\n\t\treturn ret;\n\tret = clk_enable(sdma->clk_ahb);\n\tif (ret)\n\t\tgoto disable_clk_ipg;\n\n\tif (sdma->drvdata->check_ratio &&\n\t    (clk_get_rate(sdma->clk_ahb) == clk_get_rate(sdma->clk_ipg)))\n\t\tsdma->clk_ratio = 1;\n\n\t \n\twritel_relaxed(0, sdma->regs + SDMA_H_C0PTR);\n\n\tsdma->channel_control = dma_alloc_coherent(sdma->dev,\n\t\t\tMAX_DMA_CHANNELS * sizeof(struct sdma_channel_control) +\n\t\t\tsizeof(struct sdma_context_data),\n\t\t\t&ccb_phys, GFP_KERNEL);\n\n\tif (!sdma->channel_control) {\n\t\tret = -ENOMEM;\n\t\tgoto err_dma_alloc;\n\t}\n\n\tsdma->context = (void *)sdma->channel_control +\n\t\tMAX_DMA_CHANNELS * sizeof(struct sdma_channel_control);\n\tsdma->context_phys = ccb_phys +\n\t\tMAX_DMA_CHANNELS * sizeof(struct sdma_channel_control);\n\n\t \n\tfor (i = 0; i < sdma->drvdata->num_events; i++)\n\t\twritel_relaxed(0, sdma->regs + chnenbl_ofs(sdma, i));\n\n\t \n\tfor (i = 0; i < MAX_DMA_CHANNELS; i++)\n\t\twritel_relaxed(0, sdma->regs + SDMA_CHNPRI_0 + i * 4);\n\n\tret = sdma_request_channel0(sdma);\n\tif (ret)\n\t\tgoto err_dma_alloc;\n\n\tsdma_config_ownership(&sdma->channel[0], false, true, false);\n\n\t \n\twritel_relaxed(0x4050, sdma->regs + SDMA_CHN0ADDR);\n\n\t \n\tif (sdma->clk_ratio)\n\t\twritel_relaxed(SDMA_H_CONFIG_ACR, sdma->regs + SDMA_H_CONFIG);\n\telse\n\t\twritel_relaxed(0, sdma->regs + SDMA_H_CONFIG);\n\n\twritel_relaxed(ccb_phys, sdma->regs + SDMA_H_C0PTR);\n\n\t \n\tsdma_set_channel_priority(&sdma->channel[0], 7);\n\n\tclk_disable(sdma->clk_ipg);\n\tclk_disable(sdma->clk_ahb);\n\n\treturn 0;\n\nerr_dma_alloc:\n\tclk_disable(sdma->clk_ahb);\ndisable_clk_ipg:\n\tclk_disable(sdma->clk_ipg);\n\tdev_err(sdma->dev, \"initialisation failed with %d\\n\", ret);\n\treturn ret;\n}\n\nstatic bool sdma_filter_fn(struct dma_chan *chan, void *fn_param)\n{\n\tstruct sdma_channel *sdmac = to_sdma_chan(chan);\n\tstruct imx_dma_data *data = fn_param;\n\n\tif (!imx_dma_is_general_purpose(chan))\n\t\treturn false;\n\n\tsdmac->data = *data;\n\tchan->private = &sdmac->data;\n\n\treturn true;\n}\n\nstatic struct dma_chan *sdma_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t   struct of_dma *ofdma)\n{\n\tstruct sdma_engine *sdma = ofdma->of_dma_data;\n\tdma_cap_mask_t mask = sdma->dma_device.cap_mask;\n\tstruct imx_dma_data data;\n\n\tif (dma_spec->args_count != 3)\n\t\treturn NULL;\n\n\tdata.dma_request = dma_spec->args[0];\n\tdata.peripheral_type = dma_spec->args[1];\n\tdata.priority = dma_spec->args[2];\n\t \n\tdata.dma_request2 = 0;\n\n\treturn __dma_request_channel(&mask, sdma_filter_fn, &data,\n\t\t\t\t     ofdma->of_node);\n}\n\nstatic int sdma_probe(struct platform_device *pdev)\n{\n\tstruct device_node *np = pdev->dev.of_node;\n\tstruct device_node *spba_bus;\n\tconst char *fw_name;\n\tint ret;\n\tint irq;\n\tstruct resource spba_res;\n\tint i;\n\tstruct sdma_engine *sdma;\n\ts32 *saddr_arr;\n\n\tret = dma_coerce_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (ret)\n\t\treturn ret;\n\n\tsdma = devm_kzalloc(&pdev->dev, sizeof(*sdma), GFP_KERNEL);\n\tif (!sdma)\n\t\treturn -ENOMEM;\n\n\tspin_lock_init(&sdma->channel_0_lock);\n\n\tsdma->dev = &pdev->dev;\n\tsdma->drvdata = of_device_get_match_data(sdma->dev);\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tsdma->regs = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(sdma->regs))\n\t\treturn PTR_ERR(sdma->regs);\n\n\tsdma->clk_ipg = devm_clk_get(&pdev->dev, \"ipg\");\n\tif (IS_ERR(sdma->clk_ipg))\n\t\treturn PTR_ERR(sdma->clk_ipg);\n\n\tsdma->clk_ahb = devm_clk_get(&pdev->dev, \"ahb\");\n\tif (IS_ERR(sdma->clk_ahb))\n\t\treturn PTR_ERR(sdma->clk_ahb);\n\n\tret = clk_prepare(sdma->clk_ipg);\n\tif (ret)\n\t\treturn ret;\n\n\tret = clk_prepare(sdma->clk_ahb);\n\tif (ret)\n\t\tgoto err_clk;\n\n\tret = devm_request_irq(&pdev->dev, irq, sdma_int_handler, 0,\n\t\t\t\tdev_name(&pdev->dev), sdma);\n\tif (ret)\n\t\tgoto err_irq;\n\n\tsdma->irq = irq;\n\n\tsdma->script_addrs = kzalloc(sizeof(*sdma->script_addrs), GFP_KERNEL);\n\tif (!sdma->script_addrs) {\n\t\tret = -ENOMEM;\n\t\tgoto err_irq;\n\t}\n\n\t \n\tsaddr_arr = (s32 *)sdma->script_addrs;\n\tfor (i = 0; i < sizeof(*sdma->script_addrs) / sizeof(s32); i++)\n\t\tsaddr_arr[i] = -EINVAL;\n\n\tdma_cap_set(DMA_SLAVE, sdma->dma_device.cap_mask);\n\tdma_cap_set(DMA_CYCLIC, sdma->dma_device.cap_mask);\n\tdma_cap_set(DMA_MEMCPY, sdma->dma_device.cap_mask);\n\tdma_cap_set(DMA_PRIVATE, sdma->dma_device.cap_mask);\n\n\tINIT_LIST_HEAD(&sdma->dma_device.channels);\n\t \n\tfor (i = 0; i < MAX_DMA_CHANNELS; i++) {\n\t\tstruct sdma_channel *sdmac = &sdma->channel[i];\n\n\t\tsdmac->sdma = sdma;\n\n\t\tsdmac->channel = i;\n\t\tsdmac->vc.desc_free = sdma_desc_free;\n\t\tINIT_LIST_HEAD(&sdmac->terminated);\n\t\tINIT_WORK(&sdmac->terminate_worker,\n\t\t\t\tsdma_channel_terminate_work);\n\t\t \n\t\tif (i)\n\t\t\tvchan_init(&sdmac->vc, &sdma->dma_device);\n\t}\n\n\tret = sdma_init(sdma);\n\tif (ret)\n\t\tgoto err_init;\n\n\tret = sdma_event_remap(sdma);\n\tif (ret)\n\t\tgoto err_init;\n\n\tif (sdma->drvdata->script_addrs)\n\t\tsdma_add_scripts(sdma, sdma->drvdata->script_addrs);\n\n\tsdma->dma_device.dev = &pdev->dev;\n\n\tsdma->dma_device.device_alloc_chan_resources = sdma_alloc_chan_resources;\n\tsdma->dma_device.device_free_chan_resources = sdma_free_chan_resources;\n\tsdma->dma_device.device_tx_status = sdma_tx_status;\n\tsdma->dma_device.device_prep_slave_sg = sdma_prep_slave_sg;\n\tsdma->dma_device.device_prep_dma_cyclic = sdma_prep_dma_cyclic;\n\tsdma->dma_device.device_config = sdma_config;\n\tsdma->dma_device.device_terminate_all = sdma_terminate_all;\n\tsdma->dma_device.device_synchronize = sdma_channel_synchronize;\n\tsdma->dma_device.src_addr_widths = SDMA_DMA_BUSWIDTHS;\n\tsdma->dma_device.dst_addr_widths = SDMA_DMA_BUSWIDTHS;\n\tsdma->dma_device.directions = SDMA_DMA_DIRECTIONS;\n\tsdma->dma_device.residue_granularity = DMA_RESIDUE_GRANULARITY_SEGMENT;\n\tsdma->dma_device.device_prep_dma_memcpy = sdma_prep_memcpy;\n\tsdma->dma_device.device_issue_pending = sdma_issue_pending;\n\tsdma->dma_device.copy_align = 2;\n\tdma_set_max_seg_size(sdma->dma_device.dev, SDMA_BD_MAX_CNT);\n\n\tplatform_set_drvdata(pdev, sdma);\n\n\tret = dma_async_device_register(&sdma->dma_device);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"unable to register\\n\");\n\t\tgoto err_init;\n\t}\n\n\tif (np) {\n\t\tret = of_dma_controller_register(np, sdma_xlate, sdma);\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"failed to register controller\\n\");\n\t\t\tgoto err_register;\n\t\t}\n\n\t\tspba_bus = of_find_compatible_node(NULL, NULL, \"fsl,spba-bus\");\n\t\tret = of_address_to_resource(spba_bus, 0, &spba_res);\n\t\tif (!ret) {\n\t\t\tsdma->spba_start_addr = spba_res.start;\n\t\t\tsdma->spba_end_addr = spba_res.end;\n\t\t}\n\t\tof_node_put(spba_bus);\n\t}\n\n\t \n\tret = of_property_read_string(np, \"fsl,sdma-ram-script-name\",\n\t\t\t\t      &fw_name);\n\tif (ret) {\n\t\tdev_warn(&pdev->dev, \"failed to get firmware name\\n\");\n\t} else {\n\t\tret = sdma_get_firmware(sdma, fw_name);\n\t\tif (ret)\n\t\t\tdev_warn(&pdev->dev, \"failed to get firmware from device tree\\n\");\n\t}\n\n\treturn 0;\n\nerr_register:\n\tdma_async_device_unregister(&sdma->dma_device);\nerr_init:\n\tkfree(sdma->script_addrs);\nerr_irq:\n\tclk_unprepare(sdma->clk_ahb);\nerr_clk:\n\tclk_unprepare(sdma->clk_ipg);\n\treturn ret;\n}\n\nstatic int sdma_remove(struct platform_device *pdev)\n{\n\tstruct sdma_engine *sdma = platform_get_drvdata(pdev);\n\tint i;\n\n\tdevm_free_irq(&pdev->dev, sdma->irq, sdma);\n\tdma_async_device_unregister(&sdma->dma_device);\n\tkfree(sdma->script_addrs);\n\tclk_unprepare(sdma->clk_ahb);\n\tclk_unprepare(sdma->clk_ipg);\n\t \n\tfor (i = 0; i < MAX_DMA_CHANNELS; i++) {\n\t\tstruct sdma_channel *sdmac = &sdma->channel[i];\n\n\t\ttasklet_kill(&sdmac->vc.task);\n\t\tsdma_free_chan_resources(&sdmac->vc.chan);\n\t}\n\n\tplatform_set_drvdata(pdev, NULL);\n\treturn 0;\n}\n\nstatic struct platform_driver sdma_driver = {\n\t.driver\t\t= {\n\t\t.name\t= \"imx-sdma\",\n\t\t.of_match_table = sdma_dt_ids,\n\t},\n\t.remove\t\t= sdma_remove,\n\t.probe\t\t= sdma_probe,\n};\n\nmodule_platform_driver(sdma_driver);\n\nMODULE_AUTHOR(\"Sascha Hauer, Pengutronix <s.hauer@pengutronix.de>\");\nMODULE_DESCRIPTION(\"i.MX SDMA driver\");\n#if IS_ENABLED(CONFIG_SOC_IMX6Q)\nMODULE_FIRMWARE(\"imx/sdma/sdma-imx6q.bin\");\n#endif\n#if IS_ENABLED(CONFIG_SOC_IMX7D) || IS_ENABLED(CONFIG_SOC_IMX8M)\nMODULE_FIRMWARE(\"imx/sdma/sdma-imx7d.bin\");\n#endif\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}