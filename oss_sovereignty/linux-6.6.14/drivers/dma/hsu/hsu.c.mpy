{
  "module_name": "hsu.c",
  "hash_id": "19186f899dd846024cf60f3956df8de16e5b9d8802dcbccc177e6cc57e369c26",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/hsu/hsu.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/bits.h>\n#include <linux/delay.h>\n#include <linux/device.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/percpu-defs.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/spinlock.h>\n\n#include \"hsu.h\"\n\n#define HSU_DMA_BUSWIDTHS\t\t\t\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_UNDEFINED)\t|\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_1_BYTE)\t\t|\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES)\t\t|\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_3_BYTES)\t\t|\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES)\t\t|\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_8_BYTES)\t\t|\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_16_BYTES)\n\nstatic inline void hsu_chan_disable(struct hsu_dma_chan *hsuc)\n{\n\thsu_chan_writel(hsuc, HSU_CH_CR, 0);\n}\n\nstatic inline void hsu_chan_enable(struct hsu_dma_chan *hsuc)\n{\n\tu32 cr = HSU_CH_CR_CHA;\n\n\tif (hsuc->direction == DMA_MEM_TO_DEV)\n\t\tcr &= ~HSU_CH_CR_CHD;\n\telse if (hsuc->direction == DMA_DEV_TO_MEM)\n\t\tcr |= HSU_CH_CR_CHD;\n\n\thsu_chan_writel(hsuc, HSU_CH_CR, cr);\n}\n\nstatic void hsu_dma_chan_start(struct hsu_dma_chan *hsuc)\n{\n\tstruct dma_slave_config *config = &hsuc->config;\n\tstruct hsu_dma_desc *desc = hsuc->desc;\n\tu32 bsr = 0, mtsr = 0;\t \n\tu32 dcr = HSU_CH_DCR_CHSOE | HSU_CH_DCR_CHEI;\n\tunsigned int i, count;\n\n\tif (hsuc->direction == DMA_MEM_TO_DEV) {\n\t\tbsr = config->dst_maxburst;\n\t\tmtsr = config->dst_addr_width;\n\t} else if (hsuc->direction == DMA_DEV_TO_MEM) {\n\t\tbsr = config->src_maxburst;\n\t\tmtsr = config->src_addr_width;\n\t}\n\n\thsu_chan_disable(hsuc);\n\n\thsu_chan_writel(hsuc, HSU_CH_DCR, 0);\n\thsu_chan_writel(hsuc, HSU_CH_BSR, bsr);\n\thsu_chan_writel(hsuc, HSU_CH_MTSR, mtsr);\n\n\t \n\tcount = desc->nents - desc->active;\n\tfor (i = 0; i < count && i < HSU_DMA_CHAN_NR_DESC; i++) {\n\t\thsu_chan_writel(hsuc, HSU_CH_DxSAR(i), desc->sg[i].addr);\n\t\thsu_chan_writel(hsuc, HSU_CH_DxTSR(i), desc->sg[i].len);\n\n\t\t \n\t\tdcr |= HSU_CH_DCR_DESCA(i);\n\t\tdcr |= HSU_CH_DCR_CHTOI(i);\t \n\n\t\tdesc->active++;\n\t}\n\t \n\tdcr |= HSU_CH_DCR_CHSOD(count - 1);\n\tdcr |= HSU_CH_DCR_CHDI(count - 1);\n\n\thsu_chan_writel(hsuc, HSU_CH_DCR, dcr);\n\n\thsu_chan_enable(hsuc);\n}\n\nstatic void hsu_dma_stop_channel(struct hsu_dma_chan *hsuc)\n{\n\thsu_chan_disable(hsuc);\n\thsu_chan_writel(hsuc, HSU_CH_DCR, 0);\n}\n\nstatic void hsu_dma_start_channel(struct hsu_dma_chan *hsuc)\n{\n\thsu_dma_chan_start(hsuc);\n}\n\nstatic void hsu_dma_start_transfer(struct hsu_dma_chan *hsuc)\n{\n\tstruct virt_dma_desc *vdesc;\n\n\t \n\tvdesc = vchan_next_desc(&hsuc->vchan);\n\tif (!vdesc) {\n\t\thsuc->desc = NULL;\n\t\treturn;\n\t}\n\n\tlist_del(&vdesc->node);\n\thsuc->desc = to_hsu_dma_desc(vdesc);\n\n\t \n\thsu_dma_start_channel(hsuc);\n}\n\n \nint hsu_dma_get_status(struct hsu_dma_chip *chip, unsigned short nr,\n\t\t       u32 *status)\n{\n\tstruct hsu_dma_chan *hsuc;\n\tunsigned long flags;\n\tu32 sr;\n\n\t \n\tif (nr >= chip->hsu->nr_channels)\n\t\treturn -EINVAL;\n\n\thsuc = &chip->hsu->chan[nr];\n\n\t \n\tspin_lock_irqsave(&hsuc->vchan.lock, flags);\n\tsr = hsu_chan_readl(hsuc, HSU_CH_SR);\n\tspin_unlock_irqrestore(&hsuc->vchan.lock, flags);\n\n\t \n\tsr &= ~(HSU_CH_SR_DESCE_ANY | HSU_CH_SR_CDESC_ANY);\n\tif (!sr)\n\t\treturn -EIO;\n\n\t \n\tif (sr & HSU_CH_SR_DESCTO_ANY)\n\t\tudelay(2);\n\n\t \n\tsr &= ~HSU_CH_SR_DESCTO_ANY;\n\n\t*status = sr;\n\n\treturn sr ? 0 : 1;\n}\nEXPORT_SYMBOL_GPL(hsu_dma_get_status);\n\n \nint hsu_dma_do_irq(struct hsu_dma_chip *chip, unsigned short nr, u32 status)\n{\n\tstruct dma_chan_percpu *stat;\n\tstruct hsu_dma_chan *hsuc;\n\tstruct hsu_dma_desc *desc;\n\tunsigned long flags;\n\n\t \n\tif (nr >= chip->hsu->nr_channels)\n\t\treturn 0;\n\n\thsuc = &chip->hsu->chan[nr];\n\tstat = this_cpu_ptr(hsuc->vchan.chan.local);\n\n\tspin_lock_irqsave(&hsuc->vchan.lock, flags);\n\tdesc = hsuc->desc;\n\tif (desc) {\n\t\tif (status & HSU_CH_SR_CHE) {\n\t\t\tdesc->status = DMA_ERROR;\n\t\t} else if (desc->active < desc->nents) {\n\t\t\thsu_dma_start_channel(hsuc);\n\t\t} else {\n\t\t\tvchan_cookie_complete(&desc->vdesc);\n\t\t\tdesc->status = DMA_COMPLETE;\n\t\t\tstat->bytes_transferred += desc->length;\n\t\t\thsu_dma_start_transfer(hsuc);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&hsuc->vchan.lock, flags);\n\n\treturn 1;\n}\nEXPORT_SYMBOL_GPL(hsu_dma_do_irq);\n\nstatic struct hsu_dma_desc *hsu_dma_alloc_desc(unsigned int nents)\n{\n\tstruct hsu_dma_desc *desc;\n\n\tdesc = kzalloc(sizeof(*desc), GFP_NOWAIT);\n\tif (!desc)\n\t\treturn NULL;\n\n\tdesc->sg = kcalloc(nents, sizeof(*desc->sg), GFP_NOWAIT);\n\tif (!desc->sg) {\n\t\tkfree(desc);\n\t\treturn NULL;\n\t}\n\n\treturn desc;\n}\n\nstatic void hsu_dma_desc_free(struct virt_dma_desc *vdesc)\n{\n\tstruct hsu_dma_desc *desc = to_hsu_dma_desc(vdesc);\n\n\tkfree(desc->sg);\n\tkfree(desc);\n}\n\nstatic struct dma_async_tx_descriptor *hsu_dma_prep_slave_sg(\n\t\tstruct dma_chan *chan, struct scatterlist *sgl,\n\t\tunsigned int sg_len, enum dma_transfer_direction direction,\n\t\tunsigned long flags, void *context)\n{\n\tstruct hsu_dma_chan *hsuc = to_hsu_dma_chan(chan);\n\tstruct hsu_dma_desc *desc;\n\tstruct scatterlist *sg;\n\tunsigned int i;\n\n\tdesc = hsu_dma_alloc_desc(sg_len);\n\tif (!desc)\n\t\treturn NULL;\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tdesc->sg[i].addr = sg_dma_address(sg);\n\t\tdesc->sg[i].len = sg_dma_len(sg);\n\n\t\tdesc->length += sg_dma_len(sg);\n\t}\n\n\tdesc->nents = sg_len;\n\tdesc->direction = direction;\n\t \n\tdesc->status = DMA_IN_PROGRESS;\n\n\treturn vchan_tx_prep(&hsuc->vchan, &desc->vdesc, flags);\n}\n\nstatic void hsu_dma_issue_pending(struct dma_chan *chan)\n{\n\tstruct hsu_dma_chan *hsuc = to_hsu_dma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&hsuc->vchan.lock, flags);\n\tif (vchan_issue_pending(&hsuc->vchan) && !hsuc->desc)\n\t\thsu_dma_start_transfer(hsuc);\n\tspin_unlock_irqrestore(&hsuc->vchan.lock, flags);\n}\n\nstatic size_t hsu_dma_active_desc_size(struct hsu_dma_chan *hsuc)\n{\n\tstruct hsu_dma_desc *desc = hsuc->desc;\n\tsize_t bytes = 0;\n\tint i;\n\n\tfor (i = desc->active; i < desc->nents; i++)\n\t\tbytes += desc->sg[i].len;\n\n\ti = HSU_DMA_CHAN_NR_DESC - 1;\n\tdo {\n\t\tbytes += hsu_chan_readl(hsuc, HSU_CH_DxTSR(i));\n\t} while (--i >= 0);\n\n\treturn bytes;\n}\n\nstatic enum dma_status hsu_dma_tx_status(struct dma_chan *chan,\n\tdma_cookie_t cookie, struct dma_tx_state *state)\n{\n\tstruct hsu_dma_chan *hsuc = to_hsu_dma_chan(chan);\n\tstruct virt_dma_desc *vdesc;\n\tenum dma_status status;\n\tsize_t bytes;\n\tunsigned long flags;\n\n\tstatus = dma_cookie_status(chan, cookie, state);\n\tif (status == DMA_COMPLETE)\n\t\treturn status;\n\n\tspin_lock_irqsave(&hsuc->vchan.lock, flags);\n\tvdesc = vchan_find_desc(&hsuc->vchan, cookie);\n\tif (hsuc->desc && cookie == hsuc->desc->vdesc.tx.cookie) {\n\t\tbytes = hsu_dma_active_desc_size(hsuc);\n\t\tdma_set_residue(state, bytes);\n\t\tstatus = hsuc->desc->status;\n\t} else if (vdesc) {\n\t\tbytes = to_hsu_dma_desc(vdesc)->length;\n\t\tdma_set_residue(state, bytes);\n\t}\n\tspin_unlock_irqrestore(&hsuc->vchan.lock, flags);\n\n\treturn status;\n}\n\nstatic int hsu_dma_slave_config(struct dma_chan *chan,\n\t\t\t\tstruct dma_slave_config *config)\n{\n\tstruct hsu_dma_chan *hsuc = to_hsu_dma_chan(chan);\n\n\tmemcpy(&hsuc->config, config, sizeof(hsuc->config));\n\n\treturn 0;\n}\n\nstatic int hsu_dma_pause(struct dma_chan *chan)\n{\n\tstruct hsu_dma_chan *hsuc = to_hsu_dma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&hsuc->vchan.lock, flags);\n\tif (hsuc->desc && hsuc->desc->status == DMA_IN_PROGRESS) {\n\t\thsu_chan_disable(hsuc);\n\t\thsuc->desc->status = DMA_PAUSED;\n\t}\n\tspin_unlock_irqrestore(&hsuc->vchan.lock, flags);\n\n\treturn 0;\n}\n\nstatic int hsu_dma_resume(struct dma_chan *chan)\n{\n\tstruct hsu_dma_chan *hsuc = to_hsu_dma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&hsuc->vchan.lock, flags);\n\tif (hsuc->desc && hsuc->desc->status == DMA_PAUSED) {\n\t\thsuc->desc->status = DMA_IN_PROGRESS;\n\t\thsu_chan_enable(hsuc);\n\t}\n\tspin_unlock_irqrestore(&hsuc->vchan.lock, flags);\n\n\treturn 0;\n}\n\nstatic int hsu_dma_terminate_all(struct dma_chan *chan)\n{\n\tstruct hsu_dma_chan *hsuc = to_hsu_dma_chan(chan);\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&hsuc->vchan.lock, flags);\n\n\thsu_dma_stop_channel(hsuc);\n\tif (hsuc->desc) {\n\t\thsu_dma_desc_free(&hsuc->desc->vdesc);\n\t\thsuc->desc = NULL;\n\t}\n\n\tvchan_get_all_descriptors(&hsuc->vchan, &head);\n\tspin_unlock_irqrestore(&hsuc->vchan.lock, flags);\n\tvchan_dma_desc_free_list(&hsuc->vchan, &head);\n\n\treturn 0;\n}\n\nstatic void hsu_dma_free_chan_resources(struct dma_chan *chan)\n{\n\tvchan_free_chan_resources(to_virt_chan(chan));\n}\n\nstatic void hsu_dma_synchronize(struct dma_chan *chan)\n{\n\tstruct hsu_dma_chan *hsuc = to_hsu_dma_chan(chan);\n\n\tvchan_synchronize(&hsuc->vchan);\n}\n\nint hsu_dma_probe(struct hsu_dma_chip *chip)\n{\n\tstruct hsu_dma *hsu;\n\tvoid __iomem *addr = chip->regs + chip->offset;\n\tunsigned short i;\n\tint ret;\n\n\thsu = devm_kzalloc(chip->dev, sizeof(*hsu), GFP_KERNEL);\n\tif (!hsu)\n\t\treturn -ENOMEM;\n\n\tchip->hsu = hsu;\n\n\t \n\thsu->nr_channels = (chip->length - chip->offset) / HSU_DMA_CHAN_LENGTH;\n\n\thsu->chan = devm_kcalloc(chip->dev, hsu->nr_channels,\n\t\t\t\t sizeof(*hsu->chan), GFP_KERNEL);\n\tif (!hsu->chan)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&hsu->dma.channels);\n\tfor (i = 0; i < hsu->nr_channels; i++) {\n\t\tstruct hsu_dma_chan *hsuc = &hsu->chan[i];\n\n\t\thsuc->vchan.desc_free = hsu_dma_desc_free;\n\t\tvchan_init(&hsuc->vchan, &hsu->dma);\n\n\t\thsuc->direction = (i & 0x1) ? DMA_DEV_TO_MEM : DMA_MEM_TO_DEV;\n\t\thsuc->reg = addr + i * HSU_DMA_CHAN_LENGTH;\n\t}\n\n\tdma_cap_set(DMA_SLAVE, hsu->dma.cap_mask);\n\tdma_cap_set(DMA_PRIVATE, hsu->dma.cap_mask);\n\n\thsu->dma.device_free_chan_resources = hsu_dma_free_chan_resources;\n\n\thsu->dma.device_prep_slave_sg = hsu_dma_prep_slave_sg;\n\n\thsu->dma.device_issue_pending = hsu_dma_issue_pending;\n\thsu->dma.device_tx_status = hsu_dma_tx_status;\n\n\thsu->dma.device_config = hsu_dma_slave_config;\n\thsu->dma.device_pause = hsu_dma_pause;\n\thsu->dma.device_resume = hsu_dma_resume;\n\thsu->dma.device_terminate_all = hsu_dma_terminate_all;\n\thsu->dma.device_synchronize = hsu_dma_synchronize;\n\n\thsu->dma.src_addr_widths = HSU_DMA_BUSWIDTHS;\n\thsu->dma.dst_addr_widths = HSU_DMA_BUSWIDTHS;\n\thsu->dma.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\n\thsu->dma.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\n\thsu->dma.dev = chip->dev;\n\n\tdma_set_max_seg_size(hsu->dma.dev, HSU_CH_DxTSR_MASK);\n\n\tret = dma_async_device_register(&hsu->dma);\n\tif (ret)\n\t\treturn ret;\n\n\tdev_info(chip->dev, \"Found HSU DMA, %d channels\\n\", hsu->nr_channels);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(hsu_dma_probe);\n\nint hsu_dma_remove(struct hsu_dma_chip *chip)\n{\n\tstruct hsu_dma *hsu = chip->hsu;\n\tunsigned short i;\n\n\tdma_async_device_unregister(&hsu->dma);\n\n\tfor (i = 0; i < hsu->nr_channels; i++) {\n\t\tstruct hsu_dma_chan *hsuc = &hsu->chan[i];\n\n\t\ttasklet_kill(&hsuc->vchan.task);\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(hsu_dma_remove);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"High Speed UART DMA core driver\");\nMODULE_AUTHOR(\"Andy Shevchenko <andriy.shevchenko@linux.intel.com>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}