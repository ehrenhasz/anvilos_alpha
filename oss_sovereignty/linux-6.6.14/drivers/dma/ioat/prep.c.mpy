{
  "module_name": "prep.c",
  "hash_id": "c36b761f10e41ba7428ad71fc4c2444f9c26dd80ffa50957b96fb6db0be824c3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/ioat/prep.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/gfp.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/prefetch.h>\n#include \"../dmaengine.h\"\n#include \"registers.h\"\n#include \"hw.h\"\n#include \"dma.h\"\n\n#define MAX_SCF\t256\n\n \nstatic const u8 xor_idx_to_desc = 0xe0;\nstatic const u8 xor_idx_to_field[] = { 1, 4, 5, 6, 7, 0, 1, 2 };\nstatic const u8 pq_idx_to_desc = 0xf8;\nstatic const u8 pq16_idx_to_desc[] = { 0, 0, 1, 1, 1, 1, 1, 1, 1,\n\t\t\t\t       2, 2, 2, 2, 2, 2, 2 };\nstatic const u8 pq_idx_to_field[] = { 1, 4, 5, 0, 1, 2, 4, 5 };\nstatic const u8 pq16_idx_to_field[] = { 1, 4, 1, 2, 3, 4, 5, 6, 7,\n\t\t\t\t\t0, 1, 2, 3, 4, 5, 6 };\n\nstatic void xor_set_src(struct ioat_raw_descriptor *descs[2],\n\t\t\tdma_addr_t addr, u32 offset, int idx)\n{\n\tstruct ioat_raw_descriptor *raw = descs[xor_idx_to_desc >> idx & 1];\n\n\traw->field[xor_idx_to_field[idx]] = addr + offset;\n}\n\nstatic dma_addr_t pq_get_src(struct ioat_raw_descriptor *descs[2], int idx)\n{\n\tstruct ioat_raw_descriptor *raw = descs[pq_idx_to_desc >> idx & 1];\n\n\treturn raw->field[pq_idx_to_field[idx]];\n}\n\nstatic dma_addr_t pq16_get_src(struct ioat_raw_descriptor *desc[3], int idx)\n{\n\tstruct ioat_raw_descriptor *raw = desc[pq16_idx_to_desc[idx]];\n\n\treturn raw->field[pq16_idx_to_field[idx]];\n}\n\nstatic void pq_set_src(struct ioat_raw_descriptor *descs[2],\n\t\t       dma_addr_t addr, u32 offset, u8 coef, int idx)\n{\n\tstruct ioat_pq_descriptor *pq = (struct ioat_pq_descriptor *) descs[0];\n\tstruct ioat_raw_descriptor *raw = descs[pq_idx_to_desc >> idx & 1];\n\n\traw->field[pq_idx_to_field[idx]] = addr + offset;\n\tpq->coef[idx] = coef;\n}\n\nstatic void pq16_set_src(struct ioat_raw_descriptor *desc[3],\n\t\t\tdma_addr_t addr, u32 offset, u8 coef, unsigned idx)\n{\n\tstruct ioat_pq_descriptor *pq = (struct ioat_pq_descriptor *)desc[0];\n\tstruct ioat_pq16a_descriptor *pq16 =\n\t\t(struct ioat_pq16a_descriptor *)desc[1];\n\tstruct ioat_raw_descriptor *raw = desc[pq16_idx_to_desc[idx]];\n\n\traw->field[pq16_idx_to_field[idx]] = addr + offset;\n\n\tif (idx < 8)\n\t\tpq->coef[idx] = coef;\n\telse\n\t\tpq16->coef[idx - 8] = coef;\n}\n\nstatic struct ioat_sed_ent *\nioat3_alloc_sed(struct ioatdma_device *ioat_dma, unsigned int hw_pool)\n{\n\tstruct ioat_sed_ent *sed;\n\tgfp_t flags = __GFP_ZERO | GFP_ATOMIC;\n\n\tsed = kmem_cache_alloc(ioat_sed_cache, flags);\n\tif (!sed)\n\t\treturn NULL;\n\n\tsed->hw_pool = hw_pool;\n\tsed->hw = dma_pool_alloc(ioat_dma->sed_hw_pool[hw_pool],\n\t\t\t\t flags, &sed->dma);\n\tif (!sed->hw) {\n\t\tkmem_cache_free(ioat_sed_cache, sed);\n\t\treturn NULL;\n\t}\n\n\treturn sed;\n}\n\nstruct dma_async_tx_descriptor *\nioat_dma_prep_memcpy_lock(struct dma_chan *c, dma_addr_t dma_dest,\n\t\t\t   dma_addr_t dma_src, size_t len, unsigned long flags)\n{\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(c);\n\tstruct ioat_dma_descriptor *hw;\n\tstruct ioat_ring_ent *desc;\n\tdma_addr_t dst = dma_dest;\n\tdma_addr_t src = dma_src;\n\tsize_t total_len = len;\n\tint num_descs, idx, i;\n\n\tif (test_bit(IOAT_CHAN_DOWN, &ioat_chan->state))\n\t\treturn NULL;\n\n\tnum_descs = ioat_xferlen_to_descs(ioat_chan, len);\n\tif (likely(num_descs) &&\n\t    ioat_check_space_lock(ioat_chan, num_descs) == 0)\n\t\tidx = ioat_chan->head;\n\telse\n\t\treturn NULL;\n\ti = 0;\n\tdo {\n\t\tsize_t copy = min_t(size_t, len, 1 << ioat_chan->xfercap_log);\n\n\t\tdesc = ioat_get_ring_ent(ioat_chan, idx + i);\n\t\thw = desc->hw;\n\n\t\thw->size = copy;\n\t\thw->ctl = 0;\n\t\thw->src_addr = src;\n\t\thw->dst_addr = dst;\n\n\t\tlen -= copy;\n\t\tdst += copy;\n\t\tsrc += copy;\n\t\tdump_desc_dbg(ioat_chan, desc);\n\t} while (++i < num_descs);\n\n\tdesc->txd.flags = flags;\n\tdesc->len = total_len;\n\thw->ctl_f.int_en = !!(flags & DMA_PREP_INTERRUPT);\n\thw->ctl_f.fence = !!(flags & DMA_PREP_FENCE);\n\thw->ctl_f.compl_write = 1;\n\tdump_desc_dbg(ioat_chan, desc);\n\t \n\n\treturn &desc->txd;\n}\n\n\nstatic struct dma_async_tx_descriptor *\n__ioat_prep_xor_lock(struct dma_chan *c, enum sum_check_flags *result,\n\t\t      dma_addr_t dest, dma_addr_t *src, unsigned int src_cnt,\n\t\t      size_t len, unsigned long flags)\n{\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(c);\n\tstruct ioat_ring_ent *compl_desc;\n\tstruct ioat_ring_ent *desc;\n\tstruct ioat_ring_ent *ext;\n\tsize_t total_len = len;\n\tstruct ioat_xor_descriptor *xor;\n\tstruct ioat_xor_ext_descriptor *xor_ex = NULL;\n\tstruct ioat_dma_descriptor *hw;\n\tint num_descs, with_ext, idx, i;\n\tu32 offset = 0;\n\tu8 op = result ? IOAT_OP_XOR_VAL : IOAT_OP_XOR;\n\n\tBUG_ON(src_cnt < 2);\n\n\tnum_descs = ioat_xferlen_to_descs(ioat_chan, len);\n\t \n\tif (src_cnt > 5) {\n\t\twith_ext = 1;\n\t\tnum_descs *= 2;\n\t} else\n\t\twith_ext = 0;\n\n\t \n\tif (likely(num_descs) &&\n\t    ioat_check_space_lock(ioat_chan, num_descs+1) == 0)\n\t\tidx = ioat_chan->head;\n\telse\n\t\treturn NULL;\n\ti = 0;\n\tdo {\n\t\tstruct ioat_raw_descriptor *descs[2];\n\t\tsize_t xfer_size = min_t(size_t,\n\t\t\t\t\t len, 1 << ioat_chan->xfercap_log);\n\t\tint s;\n\n\t\tdesc = ioat_get_ring_ent(ioat_chan, idx + i);\n\t\txor = desc->xor;\n\n\t\t \n\t\text = ioat_get_ring_ent(ioat_chan, idx + i + 1);\n\t\txor_ex = ext->xor_ex;\n\n\t\tdescs[0] = (struct ioat_raw_descriptor *) xor;\n\t\tdescs[1] = (struct ioat_raw_descriptor *) xor_ex;\n\t\tfor (s = 0; s < src_cnt; s++)\n\t\t\txor_set_src(descs, src[s], offset, s);\n\t\txor->size = xfer_size;\n\t\txor->dst_addr = dest + offset;\n\t\txor->ctl = 0;\n\t\txor->ctl_f.op = op;\n\t\txor->ctl_f.src_cnt = src_cnt_to_hw(src_cnt);\n\n\t\tlen -= xfer_size;\n\t\toffset += xfer_size;\n\t\tdump_desc_dbg(ioat_chan, desc);\n\t} while ((i += 1 + with_ext) < num_descs);\n\n\t \n\tdesc->txd.flags = flags;\n\tdesc->len = total_len;\n\tif (result)\n\t\tdesc->result = result;\n\txor->ctl_f.fence = !!(flags & DMA_PREP_FENCE);\n\n\t \n\tcompl_desc = ioat_get_ring_ent(ioat_chan, idx + i);\n\tcompl_desc->txd.flags = flags & DMA_PREP_INTERRUPT;\n\thw = compl_desc->hw;\n\thw->ctl = 0;\n\thw->ctl_f.null = 1;\n\thw->ctl_f.int_en = !!(flags & DMA_PREP_INTERRUPT);\n\thw->ctl_f.compl_write = 1;\n\thw->size = NULL_DESC_BUFFER_SIZE;\n\tdump_desc_dbg(ioat_chan, compl_desc);\n\n\t \n\treturn &compl_desc->txd;\n}\n\nstruct dma_async_tx_descriptor *\nioat_prep_xor(struct dma_chan *chan, dma_addr_t dest, dma_addr_t *src,\n\t       unsigned int src_cnt, size_t len, unsigned long flags)\n{\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(chan);\n\n\tif (test_bit(IOAT_CHAN_DOWN, &ioat_chan->state))\n\t\treturn NULL;\n\n\treturn __ioat_prep_xor_lock(chan, NULL, dest, src, src_cnt, len, flags);\n}\n\nstruct dma_async_tx_descriptor *\nioat_prep_xor_val(struct dma_chan *chan, dma_addr_t *src,\n\t\t    unsigned int src_cnt, size_t len,\n\t\t    enum sum_check_flags *result, unsigned long flags)\n{\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(chan);\n\n\tif (test_bit(IOAT_CHAN_DOWN, &ioat_chan->state))\n\t\treturn NULL;\n\n\t \n\t*result = 0;\n\n\treturn __ioat_prep_xor_lock(chan, result, src[0], &src[1],\n\t\t\t\t     src_cnt - 1, len, flags);\n}\n\nstatic void\ndump_pq_desc_dbg(struct ioatdma_chan *ioat_chan, struct ioat_ring_ent *desc,\n\t\t struct ioat_ring_ent *ext)\n{\n\tstruct device *dev = to_dev(ioat_chan);\n\tstruct ioat_pq_descriptor *pq = desc->pq;\n\tstruct ioat_pq_ext_descriptor *pq_ex = ext ? ext->pq_ex : NULL;\n\tstruct ioat_raw_descriptor *descs[] = { (void *) pq, (void *) pq_ex };\n\tint src_cnt = src_cnt_to_sw(pq->ctl_f.src_cnt);\n\tint i;\n\n\tdev_dbg(dev, \"desc[%d]: (%#llx->%#llx) flags: %#x\"\n\t\t\" sz: %#10.8x ctl: %#x (op: %#x int: %d compl: %d pq: '%s%s'\"\n\t\t\" src_cnt: %d)\\n\",\n\t\tdesc_id(desc), (unsigned long long) desc->txd.phys,\n\t\t(unsigned long long) (pq_ex ? pq_ex->next : pq->next),\n\t\tdesc->txd.flags, pq->size, pq->ctl, pq->ctl_f.op,\n\t\tpq->ctl_f.int_en, pq->ctl_f.compl_write,\n\t\tpq->ctl_f.p_disable ? \"\" : \"p\", pq->ctl_f.q_disable ? \"\" : \"q\",\n\t\tpq->ctl_f.src_cnt);\n\tfor (i = 0; i < src_cnt; i++)\n\t\tdev_dbg(dev, \"\\tsrc[%d]: %#llx coef: %#x\\n\", i,\n\t\t\t(unsigned long long) pq_get_src(descs, i), pq->coef[i]);\n\tdev_dbg(dev, \"\\tP: %#llx\\n\", pq->p_addr);\n\tdev_dbg(dev, \"\\tQ: %#llx\\n\", pq->q_addr);\n\tdev_dbg(dev, \"\\tNEXT: %#llx\\n\", pq->next);\n}\n\nstatic void dump_pq16_desc_dbg(struct ioatdma_chan *ioat_chan,\n\t\t\t       struct ioat_ring_ent *desc)\n{\n\tstruct device *dev = to_dev(ioat_chan);\n\tstruct ioat_pq_descriptor *pq = desc->pq;\n\tstruct ioat_raw_descriptor *descs[] = { (void *)pq,\n\t\t\t\t\t\t(void *)pq,\n\t\t\t\t\t\t(void *)pq };\n\tint src_cnt = src16_cnt_to_sw(pq->ctl_f.src_cnt);\n\tint i;\n\n\tif (desc->sed) {\n\t\tdescs[1] = (void *)desc->sed->hw;\n\t\tdescs[2] = (void *)desc->sed->hw + 64;\n\t}\n\n\tdev_dbg(dev, \"desc[%d]: (%#llx->%#llx) flags: %#x\"\n\t\t\" sz: %#x ctl: %#x (op: %#x int: %d compl: %d pq: '%s%s'\"\n\t\t\" src_cnt: %d)\\n\",\n\t\tdesc_id(desc), (unsigned long long) desc->txd.phys,\n\t\t(unsigned long long) pq->next,\n\t\tdesc->txd.flags, pq->size, pq->ctl,\n\t\tpq->ctl_f.op, pq->ctl_f.int_en,\n\t\tpq->ctl_f.compl_write,\n\t\tpq->ctl_f.p_disable ? \"\" : \"p\", pq->ctl_f.q_disable ? \"\" : \"q\",\n\t\tpq->ctl_f.src_cnt);\n\tfor (i = 0; i < src_cnt; i++) {\n\t\tdev_dbg(dev, \"\\tsrc[%d]: %#llx coef: %#x\\n\", i,\n\t\t\t(unsigned long long) pq16_get_src(descs, i),\n\t\t\tpq->coef[i]);\n\t}\n\tdev_dbg(dev, \"\\tP: %#llx\\n\", pq->p_addr);\n\tdev_dbg(dev, \"\\tQ: %#llx\\n\", pq->q_addr);\n}\n\nstatic struct dma_async_tx_descriptor *\n__ioat_prep_pq_lock(struct dma_chan *c, enum sum_check_flags *result,\n\t\t     const dma_addr_t *dst, const dma_addr_t *src,\n\t\t     unsigned int src_cnt, const unsigned char *scf,\n\t\t     size_t len, unsigned long flags)\n{\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(c);\n\tstruct ioatdma_device *ioat_dma = ioat_chan->ioat_dma;\n\tstruct ioat_ring_ent *compl_desc;\n\tstruct ioat_ring_ent *desc;\n\tstruct ioat_ring_ent *ext;\n\tsize_t total_len = len;\n\tstruct ioat_pq_descriptor *pq;\n\tstruct ioat_pq_ext_descriptor *pq_ex = NULL;\n\tstruct ioat_dma_descriptor *hw;\n\tu32 offset = 0;\n\tu8 op = result ? IOAT_OP_PQ_VAL : IOAT_OP_PQ;\n\tint i, s, idx, with_ext, num_descs;\n\tint cb32 = (ioat_dma->version < IOAT_VER_3_3) ? 1 : 0;\n\n\tdev_dbg(to_dev(ioat_chan), \"%s\\n\", __func__);\n\t \n\tBUG_ON(src_cnt + dmaf_continue(flags) < 2);\n\n\tnum_descs = ioat_xferlen_to_descs(ioat_chan, len);\n\t \n\tif (src_cnt + dmaf_p_disabled_continue(flags) > 3 ||\n\t    (dmaf_continue(flags) && !dmaf_p_disabled_continue(flags))) {\n\t\twith_ext = 1;\n\t\tnum_descs *= 2;\n\t} else\n\t\twith_ext = 0;\n\n\t \n\tif (likely(num_descs) &&\n\t    ioat_check_space_lock(ioat_chan, num_descs + cb32) == 0)\n\t\tidx = ioat_chan->head;\n\telse\n\t\treturn NULL;\n\ti = 0;\n\tdo {\n\t\tstruct ioat_raw_descriptor *descs[2];\n\t\tsize_t xfer_size = min_t(size_t, len,\n\t\t\t\t\t 1 << ioat_chan->xfercap_log);\n\n\t\tdesc = ioat_get_ring_ent(ioat_chan, idx + i);\n\t\tpq = desc->pq;\n\n\t\t \n\t\text = ioat_get_ring_ent(ioat_chan, idx + i + with_ext);\n\t\tpq_ex = ext->pq_ex;\n\n\t\tdescs[0] = (struct ioat_raw_descriptor *) pq;\n\t\tdescs[1] = (struct ioat_raw_descriptor *) pq_ex;\n\n\t\tfor (s = 0; s < src_cnt; s++)\n\t\t\tpq_set_src(descs, src[s], offset, scf[s], s);\n\n\t\t \n\t\tif (dmaf_p_disabled_continue(flags))\n\t\t\tpq_set_src(descs, dst[1], offset, 1, s++);\n\t\telse if (dmaf_continue(flags)) {\n\t\t\tpq_set_src(descs, dst[0], offset, 0, s++);\n\t\t\tpq_set_src(descs, dst[1], offset, 1, s++);\n\t\t\tpq_set_src(descs, dst[1], offset, 0, s++);\n\t\t}\n\t\tpq->size = xfer_size;\n\t\tpq->p_addr = dst[0] + offset;\n\t\tpq->q_addr = dst[1] + offset;\n\t\tpq->ctl = 0;\n\t\tpq->ctl_f.op = op;\n\t\t \n\t\tif (ioat_dma->cap & IOAT_CAP_DWBES)\n\t\t\tpq->ctl_f.wb_en = result ? 1 : 0;\n\t\tpq->ctl_f.src_cnt = src_cnt_to_hw(s);\n\t\tpq->ctl_f.p_disable = !!(flags & DMA_PREP_PQ_DISABLE_P);\n\t\tpq->ctl_f.q_disable = !!(flags & DMA_PREP_PQ_DISABLE_Q);\n\n\t\tlen -= xfer_size;\n\t\toffset += xfer_size;\n\t} while ((i += 1 + with_ext) < num_descs);\n\n\t \n\tdesc->txd.flags = flags;\n\tdesc->len = total_len;\n\tif (result)\n\t\tdesc->result = result;\n\tpq->ctl_f.fence = !!(flags & DMA_PREP_FENCE);\n\tdump_pq_desc_dbg(ioat_chan, desc, ext);\n\n\tif (!cb32) {\n\t\tpq->ctl_f.int_en = !!(flags & DMA_PREP_INTERRUPT);\n\t\tpq->ctl_f.compl_write = 1;\n\t\tcompl_desc = desc;\n\t} else {\n\t\t \n\t\tcompl_desc = ioat_get_ring_ent(ioat_chan, idx + i);\n\t\tcompl_desc->txd.flags = flags & DMA_PREP_INTERRUPT;\n\t\thw = compl_desc->hw;\n\t\thw->ctl = 0;\n\t\thw->ctl_f.null = 1;\n\t\thw->ctl_f.int_en = !!(flags & DMA_PREP_INTERRUPT);\n\t\thw->ctl_f.compl_write = 1;\n\t\thw->size = NULL_DESC_BUFFER_SIZE;\n\t\tdump_desc_dbg(ioat_chan, compl_desc);\n\t}\n\n\n\t \n\treturn &compl_desc->txd;\n}\n\nstatic struct dma_async_tx_descriptor *\n__ioat_prep_pq16_lock(struct dma_chan *c, enum sum_check_flags *result,\n\t\t       const dma_addr_t *dst, const dma_addr_t *src,\n\t\t       unsigned int src_cnt, const unsigned char *scf,\n\t\t       size_t len, unsigned long flags)\n{\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(c);\n\tstruct ioatdma_device *ioat_dma = ioat_chan->ioat_dma;\n\tstruct ioat_ring_ent *desc;\n\tsize_t total_len = len;\n\tstruct ioat_pq_descriptor *pq;\n\tu32 offset = 0;\n\tu8 op;\n\tint i, s, idx, num_descs;\n\n\t \n\top = result ? IOAT_OP_PQ_VAL_16S : IOAT_OP_PQ_16S;\n\n\tdev_dbg(to_dev(ioat_chan), \"%s\\n\", __func__);\n\n\tnum_descs = ioat_xferlen_to_descs(ioat_chan, len);\n\n\t \n\tif (num_descs && ioat_check_space_lock(ioat_chan, num_descs) == 0)\n\t\tidx = ioat_chan->head;\n\telse\n\t\treturn NULL;\n\n\ti = 0;\n\n\tdo {\n\t\tstruct ioat_raw_descriptor *descs[4];\n\t\tsize_t xfer_size = min_t(size_t, len,\n\t\t\t\t\t 1 << ioat_chan->xfercap_log);\n\n\t\tdesc = ioat_get_ring_ent(ioat_chan, idx + i);\n\t\tpq = desc->pq;\n\n\t\tdescs[0] = (struct ioat_raw_descriptor *) pq;\n\n\t\tdesc->sed = ioat3_alloc_sed(ioat_dma, (src_cnt-2) >> 3);\n\t\tif (!desc->sed) {\n\t\t\tdev_err(to_dev(ioat_chan),\n\t\t\t\t\"%s: no free sed entries\\n\", __func__);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tpq->sed_addr = desc->sed->dma;\n\t\tdesc->sed->parent = desc;\n\n\t\tdescs[1] = (struct ioat_raw_descriptor *)desc->sed->hw;\n\t\tdescs[2] = (void *)descs[1] + 64;\n\n\t\tfor (s = 0; s < src_cnt; s++)\n\t\t\tpq16_set_src(descs, src[s], offset, scf[s], s);\n\n\t\t \n\t\tif (dmaf_p_disabled_continue(flags))\n\t\t\tpq16_set_src(descs, dst[1], offset, 1, s++);\n\t\telse if (dmaf_continue(flags)) {\n\t\t\tpq16_set_src(descs, dst[0], offset, 0, s++);\n\t\t\tpq16_set_src(descs, dst[1], offset, 1, s++);\n\t\t\tpq16_set_src(descs, dst[1], offset, 0, s++);\n\t\t}\n\n\t\tpq->size = xfer_size;\n\t\tpq->p_addr = dst[0] + offset;\n\t\tpq->q_addr = dst[1] + offset;\n\t\tpq->ctl = 0;\n\t\tpq->ctl_f.op = op;\n\t\tpq->ctl_f.src_cnt = src16_cnt_to_hw(s);\n\t\t \n\t\tif (ioat_dma->cap & IOAT_CAP_DWBES)\n\t\t\tpq->ctl_f.wb_en = result ? 1 : 0;\n\t\tpq->ctl_f.p_disable = !!(flags & DMA_PREP_PQ_DISABLE_P);\n\t\tpq->ctl_f.q_disable = !!(flags & DMA_PREP_PQ_DISABLE_Q);\n\n\t\tlen -= xfer_size;\n\t\toffset += xfer_size;\n\t} while (++i < num_descs);\n\n\t \n\tdesc->txd.flags = flags;\n\tdesc->len = total_len;\n\tif (result)\n\t\tdesc->result = result;\n\tpq->ctl_f.fence = !!(flags & DMA_PREP_FENCE);\n\n\t \n\tpq->ctl_f.int_en = !!(flags & DMA_PREP_INTERRUPT);\n\tpq->ctl_f.compl_write = 1;\n\n\tdump_pq16_desc_dbg(ioat_chan, desc);\n\n\t \n\treturn &desc->txd;\n}\n\nstatic int src_cnt_flags(unsigned int src_cnt, unsigned long flags)\n{\n\tif (dmaf_p_disabled_continue(flags))\n\t\treturn src_cnt + 1;\n\telse if (dmaf_continue(flags))\n\t\treturn src_cnt + 3;\n\telse\n\t\treturn src_cnt;\n}\n\nstruct dma_async_tx_descriptor *\nioat_prep_pq(struct dma_chan *chan, dma_addr_t *dst, dma_addr_t *src,\n\t      unsigned int src_cnt, const unsigned char *scf, size_t len,\n\t      unsigned long flags)\n{\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(chan);\n\n\tif (test_bit(IOAT_CHAN_DOWN, &ioat_chan->state))\n\t\treturn NULL;\n\n\t \n\tif (flags & DMA_PREP_PQ_DISABLE_P)\n\t\tdst[0] = dst[1];\n\tif (flags & DMA_PREP_PQ_DISABLE_Q)\n\t\tdst[1] = dst[0];\n\n\t \n\tif ((flags & DMA_PREP_PQ_DISABLE_P) && src_cnt == 1) {\n\t\tdma_addr_t single_source[2];\n\t\tunsigned char single_source_coef[2];\n\n\t\tBUG_ON(flags & DMA_PREP_PQ_DISABLE_Q);\n\t\tsingle_source[0] = src[0];\n\t\tsingle_source[1] = src[0];\n\t\tsingle_source_coef[0] = scf[0];\n\t\tsingle_source_coef[1] = 0;\n\n\t\treturn src_cnt_flags(src_cnt, flags) > 8 ?\n\t\t\t__ioat_prep_pq16_lock(chan, NULL, dst, single_source,\n\t\t\t\t\t       2, single_source_coef, len,\n\t\t\t\t\t       flags) :\n\t\t\t__ioat_prep_pq_lock(chan, NULL, dst, single_source, 2,\n\t\t\t\t\t     single_source_coef, len, flags);\n\n\t} else {\n\t\treturn src_cnt_flags(src_cnt, flags) > 8 ?\n\t\t\t__ioat_prep_pq16_lock(chan, NULL, dst, src, src_cnt,\n\t\t\t\t\t       scf, len, flags) :\n\t\t\t__ioat_prep_pq_lock(chan, NULL, dst, src, src_cnt,\n\t\t\t\t\t     scf, len, flags);\n\t}\n}\n\nstruct dma_async_tx_descriptor *\nioat_prep_pq_val(struct dma_chan *chan, dma_addr_t *pq, dma_addr_t *src,\n\t\t  unsigned int src_cnt, const unsigned char *scf, size_t len,\n\t\t  enum sum_check_flags *pqres, unsigned long flags)\n{\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(chan);\n\n\tif (test_bit(IOAT_CHAN_DOWN, &ioat_chan->state))\n\t\treturn NULL;\n\n\t \n\tif (flags & DMA_PREP_PQ_DISABLE_P)\n\t\tpq[0] = pq[1];\n\tif (flags & DMA_PREP_PQ_DISABLE_Q)\n\t\tpq[1] = pq[0];\n\n\t \n\t*pqres = 0;\n\n\treturn src_cnt_flags(src_cnt, flags) > 8 ?\n\t\t__ioat_prep_pq16_lock(chan, pqres, pq, src, src_cnt, scf, len,\n\t\t\t\t       flags) :\n\t\t__ioat_prep_pq_lock(chan, pqres, pq, src, src_cnt, scf, len,\n\t\t\t\t     flags);\n}\n\nstruct dma_async_tx_descriptor *\nioat_prep_pqxor(struct dma_chan *chan, dma_addr_t dst, dma_addr_t *src,\n\t\t unsigned int src_cnt, size_t len, unsigned long flags)\n{\n\tunsigned char scf[MAX_SCF];\n\tdma_addr_t pq[2];\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(chan);\n\n\tif (test_bit(IOAT_CHAN_DOWN, &ioat_chan->state))\n\t\treturn NULL;\n\n\tif (src_cnt > MAX_SCF)\n\t\treturn NULL;\n\n\tmemset(scf, 0, src_cnt);\n\tpq[0] = dst;\n\tflags |= DMA_PREP_PQ_DISABLE_Q;\n\tpq[1] = dst;  \n\n\treturn src_cnt_flags(src_cnt, flags) > 8 ?\n\t\t__ioat_prep_pq16_lock(chan, NULL, pq, src, src_cnt, scf, len,\n\t\t\t\t       flags) :\n\t\t__ioat_prep_pq_lock(chan, NULL, pq, src, src_cnt, scf, len,\n\t\t\t\t     flags);\n}\n\nstruct dma_async_tx_descriptor *\nioat_prep_pqxor_val(struct dma_chan *chan, dma_addr_t *src,\n\t\t     unsigned int src_cnt, size_t len,\n\t\t     enum sum_check_flags *result, unsigned long flags)\n{\n\tunsigned char scf[MAX_SCF];\n\tdma_addr_t pq[2];\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(chan);\n\n\tif (test_bit(IOAT_CHAN_DOWN, &ioat_chan->state))\n\t\treturn NULL;\n\n\tif (src_cnt > MAX_SCF)\n\t\treturn NULL;\n\n\t \n\t*result = 0;\n\n\tmemset(scf, 0, src_cnt);\n\tpq[0] = src[0];\n\tflags |= DMA_PREP_PQ_DISABLE_Q;\n\tpq[1] = pq[0];  \n\n\treturn src_cnt_flags(src_cnt, flags) > 8 ?\n\t\t__ioat_prep_pq16_lock(chan, result, pq, &src[1], src_cnt - 1,\n\t\t\t\t       scf, len, flags) :\n\t\t__ioat_prep_pq_lock(chan, result, pq, &src[1], src_cnt - 1,\n\t\t\t\t     scf, len, flags);\n}\n\nstruct dma_async_tx_descriptor *\nioat_prep_interrupt_lock(struct dma_chan *c, unsigned long flags)\n{\n\tstruct ioatdma_chan *ioat_chan = to_ioat_chan(c);\n\tstruct ioat_ring_ent *desc;\n\tstruct ioat_dma_descriptor *hw;\n\n\tif (test_bit(IOAT_CHAN_DOWN, &ioat_chan->state))\n\t\treturn NULL;\n\n\tif (ioat_check_space_lock(ioat_chan, 1) == 0)\n\t\tdesc = ioat_get_ring_ent(ioat_chan, ioat_chan->head);\n\telse\n\t\treturn NULL;\n\n\thw = desc->hw;\n\thw->ctl = 0;\n\thw->ctl_f.null = 1;\n\thw->ctl_f.int_en = 1;\n\thw->ctl_f.fence = !!(flags & DMA_PREP_FENCE);\n\thw->ctl_f.compl_write = 1;\n\thw->size = NULL_DESC_BUFFER_SIZE;\n\thw->src_addr = 0;\n\thw->dst_addr = 0;\n\n\tdesc->txd.flags = flags;\n\tdesc->len = 1;\n\n\tdump_desc_dbg(ioat_chan, desc);\n\n\t \n\treturn &desc->txd;\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}