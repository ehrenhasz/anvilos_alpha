{
  "module_name": "at_xdmac.c",
  "hash_id": "4682ee0802f2ebb1720965a7e3e00f96fcff2e60893c1d9cdd819eddcc2ca012",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/at_xdmac.c",
  "human_readable_source": "\n \n\n#include <asm/barrier.h>\n#include <dt-bindings/dma/at91.h>\n#include <linux/clk.h>\n#include <linux/dmaengine.h>\n#include <linux/dmapool.h>\n#include <linux/interrupt.h>\n#include <linux/irq.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/of_dma.h>\n#include <linux/of_platform.h>\n#include <linux/platform_device.h>\n#include <linux/pm.h>\n#include <linux/pm_runtime.h>\n\n#include \"dmaengine.h\"\n\n \n#define AT_XDMAC_GTYPE\t\t0x00\t \n#define\t\tAT_XDMAC_NB_CH(i)\t(((i) & 0x1F) + 1)\t\t \n#define\t\tAT_XDMAC_FIFO_SZ(i)\t(((i) >> 5) & 0x7FF)\t\t \n#define\t\tAT_XDMAC_NB_REQ(i)\t((((i) >> 16) & 0x3F) + 1)\t \n#define AT_XDMAC_GCFG\t\t0x04\t \n#define\t\tAT_XDMAC_WRHP(i)\t\t(((i) & 0xF) << 4)\n#define\t\tAT_XDMAC_WRMP(i)\t\t(((i) & 0xF) << 8)\n#define\t\tAT_XDMAC_WRLP(i)\t\t(((i) & 0xF) << 12)\n#define\t\tAT_XDMAC_RDHP(i)\t\t(((i) & 0xF) << 16)\n#define\t\tAT_XDMAC_RDMP(i)\t\t(((i) & 0xF) << 20)\n#define\t\tAT_XDMAC_RDLP(i)\t\t(((i) & 0xF) << 24)\n#define\t\tAT_XDMAC_RDSG(i)\t\t(((i) & 0xF) << 28)\n#define AT_XDMAC_GCFG_M2M\t(AT_XDMAC_RDLP(0xF) | AT_XDMAC_WRLP(0xF))\n#define AT_XDMAC_GCFG_P2M\t(AT_XDMAC_RDSG(0x1) | AT_XDMAC_RDHP(0x3) | \\\n\t\t\t\tAT_XDMAC_WRHP(0x5))\n#define AT_XDMAC_GWAC\t\t0x08\t \n#define\t\tAT_XDMAC_PW0(i)\t\t(((i) & 0xF) << 0)\n#define\t\tAT_XDMAC_PW1(i)\t\t(((i) & 0xF) << 4)\n#define\t\tAT_XDMAC_PW2(i)\t\t(((i) & 0xF) << 8)\n#define\t\tAT_XDMAC_PW3(i)\t\t(((i) & 0xF) << 12)\n#define AT_XDMAC_GWAC_M2M\t0\n#define AT_XDMAC_GWAC_P2M\t(AT_XDMAC_PW0(0xF) | AT_XDMAC_PW2(0xF))\n\n#define AT_XDMAC_GIE\t\t0x0C\t \n#define AT_XDMAC_GID\t\t0x10\t \n#define AT_XDMAC_GIM\t\t0x14\t \n#define AT_XDMAC_GIS\t\t0x18\t \n#define AT_XDMAC_GE\t\t0x1C\t \n#define AT_XDMAC_GD\t\t0x20\t \n#define AT_XDMAC_GS\t\t0x24\t \n#define AT_XDMAC_VERSION\t0xFFC\t \n\n \n#define AT_XDMAC_CIE\t\t0x00\t \n#define\t\tAT_XDMAC_CIE_BIE\tBIT(0)\t \n#define\t\tAT_XDMAC_CIE_LIE\tBIT(1)\t \n#define\t\tAT_XDMAC_CIE_DIE\tBIT(2)\t \n#define\t\tAT_XDMAC_CIE_FIE\tBIT(3)\t \n#define\t\tAT_XDMAC_CIE_RBEIE\tBIT(4)\t \n#define\t\tAT_XDMAC_CIE_WBEIE\tBIT(5)\t \n#define\t\tAT_XDMAC_CIE_ROIE\tBIT(6)\t \n#define AT_XDMAC_CID\t\t0x04\t \n#define\t\tAT_XDMAC_CID_BID\tBIT(0)\t \n#define\t\tAT_XDMAC_CID_LID\tBIT(1)\t \n#define\t\tAT_XDMAC_CID_DID\tBIT(2)\t \n#define\t\tAT_XDMAC_CID_FID\tBIT(3)\t \n#define\t\tAT_XDMAC_CID_RBEID\tBIT(4)\t \n#define\t\tAT_XDMAC_CID_WBEID\tBIT(5)\t \n#define\t\tAT_XDMAC_CID_ROID\tBIT(6)\t \n#define AT_XDMAC_CIM\t\t0x08\t \n#define\t\tAT_XDMAC_CIM_BIM\tBIT(0)\t \n#define\t\tAT_XDMAC_CIM_LIM\tBIT(1)\t \n#define\t\tAT_XDMAC_CIM_DIM\tBIT(2)\t \n#define\t\tAT_XDMAC_CIM_FIM\tBIT(3)\t \n#define\t\tAT_XDMAC_CIM_RBEIM\tBIT(4)\t \n#define\t\tAT_XDMAC_CIM_WBEIM\tBIT(5)\t \n#define\t\tAT_XDMAC_CIM_ROIM\tBIT(6)\t \n#define AT_XDMAC_CIS\t\t0x0C\t \n#define\t\tAT_XDMAC_CIS_BIS\tBIT(0)\t \n#define\t\tAT_XDMAC_CIS_LIS\tBIT(1)\t \n#define\t\tAT_XDMAC_CIS_DIS\tBIT(2)\t \n#define\t\tAT_XDMAC_CIS_FIS\tBIT(3)\t \n#define\t\tAT_XDMAC_CIS_RBEIS\tBIT(4)\t \n#define\t\tAT_XDMAC_CIS_WBEIS\tBIT(5)\t \n#define\t\tAT_XDMAC_CIS_ROIS\tBIT(6)\t \n#define AT_XDMAC_CSA\t\t0x10\t \n#define AT_XDMAC_CDA\t\t0x14\t \n#define AT_XDMAC_CNDA\t\t0x18\t \n#define\t\tAT_XDMAC_CNDA_NDAIF(i)\t((i) & 0x1)\t\t\t \n#define\t\tAT_XDMAC_CNDA_NDA(i)\t((i) & 0xfffffffc)\t\t \n#define AT_XDMAC_CNDC\t\t0x1C\t \n#define\t\tAT_XDMAC_CNDC_NDE\t\t(0x1 << 0)\t\t \n#define\t\tAT_XDMAC_CNDC_NDSUP\t\t(0x1 << 1)\t\t \n#define\t\tAT_XDMAC_CNDC_NDDUP\t\t(0x1 << 2)\t\t \n#define\t\tAT_XDMAC_CNDC_NDVIEW_MASK\tGENMASK(28, 27)\n#define\t\tAT_XDMAC_CNDC_NDVIEW_NDV0\t(0x0 << 3)\t\t \n#define\t\tAT_XDMAC_CNDC_NDVIEW_NDV1\t(0x1 << 3)\t\t \n#define\t\tAT_XDMAC_CNDC_NDVIEW_NDV2\t(0x2 << 3)\t\t \n#define\t\tAT_XDMAC_CNDC_NDVIEW_NDV3\t(0x3 << 3)\t\t \n#define AT_XDMAC_CUBC\t\t0x20\t \n#define AT_XDMAC_CBC\t\t0x24\t \n#define AT_XDMAC_CC\t\t0x28\t \n#define\t\tAT_XDMAC_CC_TYPE\t(0x1 << 0)\t \n#define\t\t\tAT_XDMAC_CC_TYPE_MEM_TRAN\t(0x0 << 0)\t \n#define\t\t\tAT_XDMAC_CC_TYPE_PER_TRAN\t(0x1 << 0)\t \n#define\t\tAT_XDMAC_CC_MBSIZE_MASK\t(0x3 << 1)\n#define\t\t\tAT_XDMAC_CC_MBSIZE_SINGLE\t(0x0 << 1)\n#define\t\t\tAT_XDMAC_CC_MBSIZE_FOUR\t\t(0x1 << 1)\n#define\t\t\tAT_XDMAC_CC_MBSIZE_EIGHT\t(0x2 << 1)\n#define\t\t\tAT_XDMAC_CC_MBSIZE_SIXTEEN\t(0x3 << 1)\n#define\t\tAT_XDMAC_CC_DSYNC\t(0x1 << 4)\t \n#define\t\t\tAT_XDMAC_CC_DSYNC_PER2MEM\t(0x0 << 4)\n#define\t\t\tAT_XDMAC_CC_DSYNC_MEM2PER\t(0x1 << 4)\n#define\t\tAT_XDMAC_CC_PROT\t(0x1 << 5)\t \n#define\t\t\tAT_XDMAC_CC_PROT_SEC\t\t(0x0 << 5)\n#define\t\t\tAT_XDMAC_CC_PROT_UNSEC\t\t(0x1 << 5)\n#define\t\tAT_XDMAC_CC_SWREQ\t(0x1 << 6)\t \n#define\t\t\tAT_XDMAC_CC_SWREQ_HWR_CONNECTED\t(0x0 << 6)\n#define\t\t\tAT_XDMAC_CC_SWREQ_SWR_CONNECTED\t(0x1 << 6)\n#define\t\tAT_XDMAC_CC_MEMSET\t(0x1 << 7)\t \n#define\t\t\tAT_XDMAC_CC_MEMSET_NORMAL_MODE\t(0x0 << 7)\n#define\t\t\tAT_XDMAC_CC_MEMSET_HW_MODE\t(0x1 << 7)\n#define\t\tAT_XDMAC_CC_CSIZE(i)\t((0x7 & (i)) << 8)\t \n#define\t\tAT_XDMAC_CC_DWIDTH_OFFSET\t11\n#define\t\tAT_XDMAC_CC_DWIDTH_MASK\t(0x3 << AT_XDMAC_CC_DWIDTH_OFFSET)\n#define\t\tAT_XDMAC_CC_DWIDTH(i)\t((0x3 & (i)) << AT_XDMAC_CC_DWIDTH_OFFSET)\t \n#define\t\t\tAT_XDMAC_CC_DWIDTH_BYTE\t\t0x0\n#define\t\t\tAT_XDMAC_CC_DWIDTH_HALFWORD\t0x1\n#define\t\t\tAT_XDMAC_CC_DWIDTH_WORD\t\t0x2\n#define\t\t\tAT_XDMAC_CC_DWIDTH_DWORD\t0x3\n#define\t\tAT_XDMAC_CC_SIF(i)\t((0x1 & (i)) << 13)\t \n#define\t\tAT_XDMAC_CC_DIF(i)\t((0x1 & (i)) << 14)\t \n#define\t\tAT_XDMAC_CC_SAM_MASK\t(0x3 << 16)\t \n#define\t\t\tAT_XDMAC_CC_SAM_FIXED_AM\t(0x0 << 16)\n#define\t\t\tAT_XDMAC_CC_SAM_INCREMENTED_AM\t(0x1 << 16)\n#define\t\t\tAT_XDMAC_CC_SAM_UBS_AM\t\t(0x2 << 16)\n#define\t\t\tAT_XDMAC_CC_SAM_UBS_DS_AM\t(0x3 << 16)\n#define\t\tAT_XDMAC_CC_DAM_MASK\t(0x3 << 18)\t \n#define\t\t\tAT_XDMAC_CC_DAM_FIXED_AM\t(0x0 << 18)\n#define\t\t\tAT_XDMAC_CC_DAM_INCREMENTED_AM\t(0x1 << 18)\n#define\t\t\tAT_XDMAC_CC_DAM_UBS_AM\t\t(0x2 << 18)\n#define\t\t\tAT_XDMAC_CC_DAM_UBS_DS_AM\t(0x3 << 18)\n#define\t\tAT_XDMAC_CC_INITD\t(0x1 << 21)\t \n#define\t\t\tAT_XDMAC_CC_INITD_TERMINATED\t(0x0 << 21)\n#define\t\t\tAT_XDMAC_CC_INITD_IN_PROGRESS\t(0x1 << 21)\n#define\t\tAT_XDMAC_CC_RDIP\t(0x1 << 22)\t \n#define\t\t\tAT_XDMAC_CC_RDIP_DONE\t\t(0x0 << 22)\n#define\t\t\tAT_XDMAC_CC_RDIP_IN_PROGRESS\t(0x1 << 22)\n#define\t\tAT_XDMAC_CC_WRIP\t(0x1 << 23)\t \n#define\t\t\tAT_XDMAC_CC_WRIP_DONE\t\t(0x0 << 23)\n#define\t\t\tAT_XDMAC_CC_WRIP_IN_PROGRESS\t(0x1 << 23)\n#define\t\tAT_XDMAC_CC_PERID(i)\t((0x7f & (i)) << 24)\t \n#define AT_XDMAC_CDS_MSP\t0x2C\t \n#define AT_XDMAC_CSUS\t\t0x30\t \n#define AT_XDMAC_CDUS\t\t0x34\t \n\n \n#define AT_XDMAC_MBR_UBC_UBLEN_MAX\t0xFFFFFFUL\t \n#define AT_XDMAC_MBR_UBC_NDE\t\t(0x1 << 24)\t \n#define AT_XDMAC_MBR_UBC_NSEN\t\t(0x1 << 25)\t \n#define AT_XDMAC_MBR_UBC_NDEN\t\t(0x1 << 26)\t \n#define AT_XDMAC_MBR_UBC_NDV0\t\t(0x0 << 27)\t \n#define AT_XDMAC_MBR_UBC_NDV1\t\t(0x1 << 27)\t \n#define AT_XDMAC_MBR_UBC_NDV2\t\t(0x2 << 27)\t \n#define AT_XDMAC_MBR_UBC_NDV3\t\t(0x3 << 27)\t \n\n#define AT_XDMAC_MAX_CHAN\t0x20\n#define AT_XDMAC_MAX_CSIZE\t16\t \n#define AT_XDMAC_MAX_DWIDTH\t8\t \n#define AT_XDMAC_RESIDUE_MAX_RETRIES\t5\n\n#define AT_XDMAC_DMA_BUSWIDTHS\\\n\t(BIT(DMA_SLAVE_BUSWIDTH_UNDEFINED) |\\\n\tBIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\\\n\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\\\n\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES) |\\\n\tBIT(DMA_SLAVE_BUSWIDTH_8_BYTES))\n\nenum atc_status {\n\tAT_XDMAC_CHAN_IS_CYCLIC = 0,\n\tAT_XDMAC_CHAN_IS_PAUSED,\n\tAT_XDMAC_CHAN_IS_PAUSED_INTERNAL,\n};\n\nstruct at_xdmac_layout {\n\t \n\tu8\t\t\t\tgrs;\n\t \n\tu8\t\t\t\tgws;\n\t \n\tu8\t\t\t\tgrws;\n\t \n\tu8\t\t\t\tgrwr;\n\t \n\tu8\t\t\t\tgswr;\n\t \n\tu8\t\t\t\tgsws;\n\t \n\tu8\t\t\t\tgswf;\n\t \n\tu8\t\t\t\tchan_cc_reg_base;\n\t \n\tbool\t\t\t\tsdif;\n\t \n\tbool\t\t\t\taxi_config;\n};\n\n \nstruct at_xdmac_chan {\n\tstruct dma_chan\t\t\tchan;\n\tvoid __iomem\t\t\t*ch_regs;\n\tu32\t\t\t\tmask;\t\t \n\tu32\t\t\t\tcfg;\t\t \n\tu8\t\t\t\tperid;\t\t \n\tu8\t\t\t\tperif;\t\t \n\tu8\t\t\t\tmemif;\t\t \n\tu32\t\t\t\tsave_cc;\n\tu32\t\t\t\tsave_cim;\n\tu32\t\t\t\tsave_cnda;\n\tu32\t\t\t\tsave_cndc;\n\tu32\t\t\t\tirq_status;\n\tunsigned long\t\t\tstatus;\n\tstruct tasklet_struct\t\ttasklet;\n\tstruct dma_slave_config\t\tsconfig;\n\n\tspinlock_t\t\t\tlock;\n\n\tstruct list_head\t\txfers_list;\n\tstruct list_head\t\tfree_descs_list;\n};\n\n\n \nstruct at_xdmac {\n\tstruct dma_device\tdma;\n\tvoid __iomem\t\t*regs;\n\tstruct device\t\t*dev;\n\tint\t\t\tirq;\n\tstruct clk\t\t*clk;\n\tu32\t\t\tsave_gim;\n\tu32\t\t\tsave_gs;\n\tstruct dma_pool\t\t*at_xdmac_desc_pool;\n\tconst struct at_xdmac_layout\t*layout;\n\tstruct at_xdmac_chan\tchan[];\n};\n\n\n \n\n \nstruct at_xdmac_lld {\n\tu32 mbr_nda;\t \n\tu32 mbr_ubc;\t \n\tu32 mbr_sa;\t \n\tu32 mbr_da;\t \n\tu32 mbr_cfg;\t \n\tu32 mbr_bc;\t \n\tu32 mbr_ds;\t \n\tu32 mbr_sus;\t \n\tu32 mbr_dus;\t \n};\n\n \nstruct at_xdmac_desc {\n\tstruct at_xdmac_lld\t\tlld;\n\tenum dma_transfer_direction\tdirection;\n\tstruct dma_async_tx_descriptor\ttx_dma_desc;\n\tstruct list_head\t\tdesc_node;\n\t \n\tbool\t\t\t\tactive_xfer;\n\tunsigned int\t\t\txfer_size;\n\tstruct list_head\t\tdescs_list;\n\tstruct list_head\t\txfer_node;\n} __aligned(sizeof(u64));\n\nstatic const struct at_xdmac_layout at_xdmac_sama5d4_layout = {\n\t.grs = 0x28,\n\t.gws = 0x2C,\n\t.grws = 0x30,\n\t.grwr = 0x34,\n\t.gswr = 0x38,\n\t.gsws = 0x3C,\n\t.gswf = 0x40,\n\t.chan_cc_reg_base = 0x50,\n\t.sdif = true,\n\t.axi_config = false,\n};\n\nstatic const struct at_xdmac_layout at_xdmac_sama7g5_layout = {\n\t.grs = 0x30,\n\t.gws = 0x38,\n\t.grws = 0x40,\n\t.grwr = 0x44,\n\t.gswr = 0x48,\n\t.gsws = 0x4C,\n\t.gswf = 0x50,\n\t.chan_cc_reg_base = 0x60,\n\t.sdif = false,\n\t.axi_config = true,\n};\n\nstatic inline void __iomem *at_xdmac_chan_reg_base(struct at_xdmac *atxdmac, unsigned int chan_nb)\n{\n\treturn atxdmac->regs + (atxdmac->layout->chan_cc_reg_base + chan_nb * 0x40);\n}\n\n#define at_xdmac_read(atxdmac, reg) readl_relaxed((atxdmac)->regs + (reg))\n#define at_xdmac_write(atxdmac, reg, value) \\\n\twritel_relaxed((value), (atxdmac)->regs + (reg))\n\n#define at_xdmac_chan_read(atchan, reg) readl_relaxed((atchan)->ch_regs + (reg))\n#define at_xdmac_chan_write(atchan, reg, value) writel_relaxed((value), (atchan)->ch_regs + (reg))\n\nstatic inline struct at_xdmac_chan *to_at_xdmac_chan(struct dma_chan *dchan)\n{\n\treturn container_of(dchan, struct at_xdmac_chan, chan);\n}\n\nstatic struct device *chan2dev(struct dma_chan *chan)\n{\n\treturn &chan->dev->device;\n}\n\nstatic inline struct at_xdmac *to_at_xdmac(struct dma_device *ddev)\n{\n\treturn container_of(ddev, struct at_xdmac, dma);\n}\n\nstatic inline struct at_xdmac_desc *txd_to_at_desc(struct dma_async_tx_descriptor *txd)\n{\n\treturn container_of(txd, struct at_xdmac_desc, tx_dma_desc);\n}\n\nstatic inline int at_xdmac_chan_is_cyclic(struct at_xdmac_chan *atchan)\n{\n\treturn test_bit(AT_XDMAC_CHAN_IS_CYCLIC, &atchan->status);\n}\n\nstatic inline int at_xdmac_chan_is_paused(struct at_xdmac_chan *atchan)\n{\n\treturn test_bit(AT_XDMAC_CHAN_IS_PAUSED, &atchan->status);\n}\n\nstatic inline int at_xdmac_chan_is_paused_internal(struct at_xdmac_chan *atchan)\n{\n\treturn test_bit(AT_XDMAC_CHAN_IS_PAUSED_INTERNAL, &atchan->status);\n}\n\nstatic inline bool at_xdmac_chan_is_peripheral_xfer(u32 cfg)\n{\n\treturn cfg & AT_XDMAC_CC_TYPE_PER_TRAN;\n}\n\nstatic inline u8 at_xdmac_get_dwidth(u32 cfg)\n{\n\treturn (cfg & AT_XDMAC_CC_DWIDTH_MASK) >> AT_XDMAC_CC_DWIDTH_OFFSET;\n};\n\nstatic unsigned int init_nr_desc_per_channel = 64;\nmodule_param(init_nr_desc_per_channel, uint, 0644);\nMODULE_PARM_DESC(init_nr_desc_per_channel,\n\t\t \"initial descriptors per channel (default: 64)\");\n\n\nstatic void at_xdmac_runtime_suspend_descriptors(struct at_xdmac_chan *atchan)\n{\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tstruct at_xdmac_desc\t*desc, *_desc;\n\n\tlist_for_each_entry_safe(desc, _desc, &atchan->xfers_list, xfer_node) {\n\t\tif (!desc->active_xfer)\n\t\t\tcontinue;\n\n\t\tpm_runtime_mark_last_busy(atxdmac->dev);\n\t\tpm_runtime_put_autosuspend(atxdmac->dev);\n\t}\n}\n\nstatic int at_xdmac_runtime_resume_descriptors(struct at_xdmac_chan *atchan)\n{\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tstruct at_xdmac_desc\t*desc, *_desc;\n\tint\t\t\tret;\n\n\tlist_for_each_entry_safe(desc, _desc, &atchan->xfers_list, xfer_node) {\n\t\tif (!desc->active_xfer)\n\t\t\tcontinue;\n\n\t\tret = pm_runtime_resume_and_get(atxdmac->dev);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic bool at_xdmac_chan_is_enabled(struct at_xdmac_chan *atchan)\n{\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tint\t\t\tret;\n\n\tret = pm_runtime_resume_and_get(atxdmac->dev);\n\tif (ret < 0)\n\t\treturn false;\n\n\tret = !!(at_xdmac_chan_read(atchan, AT_XDMAC_GS) & atchan->mask);\n\n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_autosuspend(atxdmac->dev);\n\n\treturn ret;\n}\n\nstatic void at_xdmac_off(struct at_xdmac *atxdmac, bool suspend_descriptors)\n{\n\tstruct dma_chan\t\t*chan, *_chan;\n\tstruct at_xdmac_chan\t*atchan;\n\tint\t\t\tret;\n\n\tret = pm_runtime_resume_and_get(atxdmac->dev);\n\tif (ret < 0)\n\t\treturn;\n\n\tat_xdmac_write(atxdmac, AT_XDMAC_GD, -1L);\n\n\t \n\twhile (at_xdmac_read(atxdmac, AT_XDMAC_GS))\n\t\tcpu_relax();\n\n\tat_xdmac_write(atxdmac, AT_XDMAC_GID, -1L);\n\n\t \n\tif (!list_empty(&atxdmac->dma.channels) && suspend_descriptors) {\n\t\tlist_for_each_entry_safe(chan, _chan, &atxdmac->dma.channels,\n\t\t\t\t\t device_node) {\n\t\t\tatchan = to_at_xdmac_chan(chan);\n\t\t\tat_xdmac_runtime_suspend_descriptors(atchan);\n\t\t}\n\t}\n\n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_autosuspend(atxdmac->dev);\n}\n\n \nstatic void at_xdmac_start_xfer(struct at_xdmac_chan *atchan,\n\t\t\t\tstruct at_xdmac_desc *first)\n{\n\tstruct at_xdmac\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tu32\t\treg;\n\tint\t\tret;\n\n\tret = pm_runtime_resume_and_get(atxdmac->dev);\n\tif (ret < 0)\n\t\treturn;\n\n\tdev_vdbg(chan2dev(&atchan->chan), \"%s: desc 0x%p\\n\", __func__, first);\n\n\t \n\tfirst->active_xfer = true;\n\n\t \n\treg = AT_XDMAC_CNDA_NDA(first->tx_dma_desc.phys);\n\tif (atxdmac->layout->sdif)\n\t\treg |= AT_XDMAC_CNDA_NDAIF(atchan->memif);\n\n\tat_xdmac_chan_write(atchan, AT_XDMAC_CNDA, reg);\n\n\t \n\tif (at_xdmac_chan_is_cyclic(atchan))\n\t\treg = AT_XDMAC_CNDC_NDVIEW_NDV1;\n\telse if ((first->lld.mbr_ubc &\n\t\t  AT_XDMAC_CNDC_NDVIEW_MASK) == AT_XDMAC_MBR_UBC_NDV3)\n\t\treg = AT_XDMAC_CNDC_NDVIEW_NDV3;\n\telse\n\t\treg = AT_XDMAC_CNDC_NDVIEW_NDV2;\n\t \n\tat_xdmac_chan_write(atchan, AT_XDMAC_CC, first->lld.mbr_cfg);\n\n\treg |= AT_XDMAC_CNDC_NDDUP\n\t       | AT_XDMAC_CNDC_NDSUP\n\t       | AT_XDMAC_CNDC_NDE;\n\tat_xdmac_chan_write(atchan, AT_XDMAC_CNDC, reg);\n\n\tdev_vdbg(chan2dev(&atchan->chan),\n\t\t \"%s: CC=0x%08x CNDA=0x%08x, CNDC=0x%08x, CSA=0x%08x, CDA=0x%08x, CUBC=0x%08x\\n\",\n\t\t __func__, at_xdmac_chan_read(atchan, AT_XDMAC_CC),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CNDA),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CNDC),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CSA),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CDA),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CUBC));\n\n\tat_xdmac_chan_write(atchan, AT_XDMAC_CID, 0xffffffff);\n\treg = AT_XDMAC_CIE_RBEIE | AT_XDMAC_CIE_WBEIE;\n\t \n\tif (at_xdmac_chan_is_peripheral_xfer(first->lld.mbr_cfg))\n\t\treg |= AT_XDMAC_CIE_ROIE;\n\n\t \n\tif (at_xdmac_chan_is_cyclic(atchan))\n\t\tat_xdmac_chan_write(atchan, AT_XDMAC_CIE,\n\t\t\t\t    reg | AT_XDMAC_CIE_BIE);\n\telse\n\t\tat_xdmac_chan_write(atchan, AT_XDMAC_CIE,\n\t\t\t\t    reg | AT_XDMAC_CIE_LIE);\n\tat_xdmac_write(atxdmac, AT_XDMAC_GIE, atchan->mask);\n\tdev_vdbg(chan2dev(&atchan->chan),\n\t\t \"%s: enable channel (0x%08x)\\n\", __func__, atchan->mask);\n\twmb();\n\tat_xdmac_write(atxdmac, AT_XDMAC_GE, atchan->mask);\n\n\tdev_vdbg(chan2dev(&atchan->chan),\n\t\t \"%s: CC=0x%08x CNDA=0x%08x, CNDC=0x%08x, CSA=0x%08x, CDA=0x%08x, CUBC=0x%08x\\n\",\n\t\t __func__, at_xdmac_chan_read(atchan, AT_XDMAC_CC),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CNDA),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CNDC),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CSA),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CDA),\n\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CUBC));\n}\n\nstatic dma_cookie_t at_xdmac_tx_submit(struct dma_async_tx_descriptor *tx)\n{\n\tstruct at_xdmac_desc\t*desc = txd_to_at_desc(tx);\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(tx->chan);\n\tdma_cookie_t\t\tcookie;\n\tunsigned long\t\tirqflags;\n\n\tspin_lock_irqsave(&atchan->lock, irqflags);\n\tcookie = dma_cookie_assign(tx);\n\n\tlist_add_tail(&desc->xfer_node, &atchan->xfers_list);\n\tspin_unlock_irqrestore(&atchan->lock, irqflags);\n\n\tdev_vdbg(chan2dev(tx->chan), \"%s: atchan 0x%p, add desc 0x%p to xfers_list\\n\",\n\t\t __func__, atchan, desc);\n\n\treturn cookie;\n}\n\nstatic struct at_xdmac_desc *at_xdmac_alloc_desc(struct dma_chan *chan,\n\t\t\t\t\t\t gfp_t gfp_flags)\n{\n\tstruct at_xdmac_desc\t*desc;\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(chan->device);\n\tdma_addr_t\t\tphys;\n\n\tdesc = dma_pool_zalloc(atxdmac->at_xdmac_desc_pool, gfp_flags, &phys);\n\tif (desc) {\n\t\tINIT_LIST_HEAD(&desc->descs_list);\n\t\tdma_async_tx_descriptor_init(&desc->tx_dma_desc, chan);\n\t\tdesc->tx_dma_desc.tx_submit = at_xdmac_tx_submit;\n\t\tdesc->tx_dma_desc.phys = phys;\n\t}\n\n\treturn desc;\n}\n\nstatic void at_xdmac_init_used_desc(struct at_xdmac_desc *desc)\n{\n\tmemset(&desc->lld, 0, sizeof(desc->lld));\n\tINIT_LIST_HEAD(&desc->descs_list);\n\tdesc->direction = DMA_TRANS_NONE;\n\tdesc->xfer_size = 0;\n\tdesc->active_xfer = false;\n}\n\n \nstatic struct at_xdmac_desc *at_xdmac_get_desc(struct at_xdmac_chan *atchan)\n{\n\tstruct at_xdmac_desc *desc;\n\n\tif (list_empty(&atchan->free_descs_list)) {\n\t\tdesc = at_xdmac_alloc_desc(&atchan->chan, GFP_NOWAIT);\n\t} else {\n\t\tdesc = list_first_entry(&atchan->free_descs_list,\n\t\t\t\t\tstruct at_xdmac_desc, desc_node);\n\t\tlist_del(&desc->desc_node);\n\t\tat_xdmac_init_used_desc(desc);\n\t}\n\n\treturn desc;\n}\n\nstatic void at_xdmac_queue_desc(struct dma_chan *chan,\n\t\t\t\tstruct at_xdmac_desc *prev,\n\t\t\t\tstruct at_xdmac_desc *desc)\n{\n\tif (!prev || !desc)\n\t\treturn;\n\n\tprev->lld.mbr_nda = desc->tx_dma_desc.phys;\n\tprev->lld.mbr_ubc |= AT_XDMAC_MBR_UBC_NDE;\n\n\tdev_dbg(chan2dev(chan),\t\"%s: chain lld: prev=0x%p, mbr_nda=%pad\\n\",\n\t\t__func__, prev, &prev->lld.mbr_nda);\n}\n\nstatic inline void at_xdmac_increment_block_count(struct dma_chan *chan,\n\t\t\t\t\t\t  struct at_xdmac_desc *desc)\n{\n\tif (!desc)\n\t\treturn;\n\n\tdesc->lld.mbr_bc++;\n\n\tdev_dbg(chan2dev(chan),\n\t\t\"%s: incrementing the block count of the desc 0x%p\\n\",\n\t\t__func__, desc);\n}\n\nstatic struct dma_chan *at_xdmac_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t       struct of_dma *of_dma)\n{\n\tstruct at_xdmac\t\t*atxdmac = of_dma->of_dma_data;\n\tstruct at_xdmac_chan\t*atchan;\n\tstruct dma_chan\t\t*chan;\n\tstruct device\t\t*dev = atxdmac->dma.dev;\n\n\tif (dma_spec->args_count != 1) {\n\t\tdev_err(dev, \"dma phandler args: bad number of args\\n\");\n\t\treturn NULL;\n\t}\n\n\tchan = dma_get_any_slave_channel(&atxdmac->dma);\n\tif (!chan) {\n\t\tdev_err(dev, \"can't get a dma channel\\n\");\n\t\treturn NULL;\n\t}\n\n\tatchan = to_at_xdmac_chan(chan);\n\tatchan->memif = AT91_XDMAC_DT_GET_MEM_IF(dma_spec->args[0]);\n\tatchan->perif = AT91_XDMAC_DT_GET_PER_IF(dma_spec->args[0]);\n\tatchan->perid = AT91_XDMAC_DT_GET_PERID(dma_spec->args[0]);\n\tdev_dbg(dev, \"chan dt cfg: memif=%u perif=%u perid=%u\\n\",\n\t\t atchan->memif, atchan->perif, atchan->perid);\n\n\treturn chan;\n}\n\nstatic int at_xdmac_compute_chan_conf(struct dma_chan *chan,\n\t\t\t\t      enum dma_transfer_direction direction)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tint\t\t\tcsize, dwidth;\n\n\tif (direction == DMA_DEV_TO_MEM) {\n\t\tatchan->cfg =\n\t\t\tAT91_XDMAC_DT_PERID(atchan->perid)\n\t\t\t| AT_XDMAC_CC_DAM_INCREMENTED_AM\n\t\t\t| AT_XDMAC_CC_SAM_FIXED_AM\n\t\t\t| AT_XDMAC_CC_SWREQ_HWR_CONNECTED\n\t\t\t| AT_XDMAC_CC_DSYNC_PER2MEM\n\t\t\t| AT_XDMAC_CC_MBSIZE_SIXTEEN\n\t\t\t| AT_XDMAC_CC_TYPE_PER_TRAN;\n\t\tif (atxdmac->layout->sdif)\n\t\t\tatchan->cfg |= AT_XDMAC_CC_DIF(atchan->memif) |\n\t\t\t\t       AT_XDMAC_CC_SIF(atchan->perif);\n\n\t\tcsize = ffs(atchan->sconfig.src_maxburst) - 1;\n\t\tif (csize < 0) {\n\t\t\tdev_err(chan2dev(chan), \"invalid src maxburst value\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tatchan->cfg |= AT_XDMAC_CC_CSIZE(csize);\n\t\tdwidth = ffs(atchan->sconfig.src_addr_width) - 1;\n\t\tif (dwidth < 0) {\n\t\t\tdev_err(chan2dev(chan), \"invalid src addr width value\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tatchan->cfg |= AT_XDMAC_CC_DWIDTH(dwidth);\n\t} else if (direction == DMA_MEM_TO_DEV) {\n\t\tatchan->cfg =\n\t\t\tAT91_XDMAC_DT_PERID(atchan->perid)\n\t\t\t| AT_XDMAC_CC_DAM_FIXED_AM\n\t\t\t| AT_XDMAC_CC_SAM_INCREMENTED_AM\n\t\t\t| AT_XDMAC_CC_SWREQ_HWR_CONNECTED\n\t\t\t| AT_XDMAC_CC_DSYNC_MEM2PER\n\t\t\t| AT_XDMAC_CC_MBSIZE_SIXTEEN\n\t\t\t| AT_XDMAC_CC_TYPE_PER_TRAN;\n\t\tif (atxdmac->layout->sdif)\n\t\t\tatchan->cfg |= AT_XDMAC_CC_DIF(atchan->perif) |\n\t\t\t\t       AT_XDMAC_CC_SIF(atchan->memif);\n\n\t\tcsize = ffs(atchan->sconfig.dst_maxburst) - 1;\n\t\tif (csize < 0) {\n\t\t\tdev_err(chan2dev(chan), \"invalid src maxburst value\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tatchan->cfg |= AT_XDMAC_CC_CSIZE(csize);\n\t\tdwidth = ffs(atchan->sconfig.dst_addr_width) - 1;\n\t\tif (dwidth < 0) {\n\t\t\tdev_err(chan2dev(chan), \"invalid dst addr width value\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tatchan->cfg |= AT_XDMAC_CC_DWIDTH(dwidth);\n\t}\n\n\tdev_dbg(chan2dev(chan),\t\"%s: cfg=0x%08x\\n\", __func__, atchan->cfg);\n\n\treturn 0;\n}\n\n \nstatic int at_xdmac_check_slave_config(struct dma_slave_config *sconfig)\n{\n\tif ((sconfig->src_maxburst > AT_XDMAC_MAX_CSIZE)\n\t    || (sconfig->dst_maxburst > AT_XDMAC_MAX_CSIZE))\n\t\treturn -EINVAL;\n\n\tif ((sconfig->src_addr_width > AT_XDMAC_MAX_DWIDTH)\n\t    || (sconfig->dst_addr_width > AT_XDMAC_MAX_DWIDTH))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int at_xdmac_set_slave_config(struct dma_chan *chan,\n\t\t\t\t      struct dma_slave_config *sconfig)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\n\tif (at_xdmac_check_slave_config(sconfig)) {\n\t\tdev_err(chan2dev(chan), \"invalid slave configuration\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(&atchan->sconfig, sconfig, sizeof(atchan->sconfig));\n\n\treturn 0;\n}\n\nstatic struct dma_async_tx_descriptor *\nat_xdmac_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,\n\t\t       unsigned int sg_len, enum dma_transfer_direction direction,\n\t\t       unsigned long flags, void *context)\n{\n\tstruct at_xdmac_chan\t\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac_desc\t\t*first = NULL, *prev = NULL;\n\tstruct scatterlist\t\t*sg;\n\tint\t\t\t\ti;\n\tunsigned int\t\t\txfer_size = 0;\n\tunsigned long\t\t\tirqflags;\n\tstruct dma_async_tx_descriptor\t*ret = NULL;\n\n\tif (!sgl)\n\t\treturn NULL;\n\n\tif (!is_slave_direction(direction)) {\n\t\tdev_err(chan2dev(chan), \"invalid DMA direction\\n\");\n\t\treturn NULL;\n\t}\n\n\tdev_dbg(chan2dev(chan), \"%s: sg_len=%d, dir=%s, flags=0x%lx\\n\",\n\t\t __func__, sg_len,\n\t\t direction == DMA_MEM_TO_DEV ? \"to device\" : \"from device\",\n\t\t flags);\n\n\t \n\tspin_lock_irqsave(&atchan->lock, irqflags);\n\n\tif (at_xdmac_compute_chan_conf(chan, direction))\n\t\tgoto spin_unlock;\n\n\t \n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tstruct at_xdmac_desc\t*desc = NULL;\n\t\tu32\t\t\tlen, mem, dwidth, fixed_dwidth;\n\n\t\tlen = sg_dma_len(sg);\n\t\tmem = sg_dma_address(sg);\n\t\tif (unlikely(!len)) {\n\t\t\tdev_err(chan2dev(chan), \"sg data length is zero\\n\");\n\t\t\tgoto spin_unlock;\n\t\t}\n\t\tdev_dbg(chan2dev(chan), \"%s: * sg%d len=%u, mem=0x%08x\\n\",\n\t\t\t __func__, i, len, mem);\n\n\t\tdesc = at_xdmac_get_desc(atchan);\n\t\tif (!desc) {\n\t\t\tdev_err(chan2dev(chan), \"can't get descriptor\\n\");\n\t\t\tif (first)\n\t\t\t\tlist_splice_tail_init(&first->descs_list,\n\t\t\t\t\t\t      &atchan->free_descs_list);\n\t\t\tgoto spin_unlock;\n\t\t}\n\n\t\t \n\t\tif (direction == DMA_DEV_TO_MEM) {\n\t\t\tdesc->lld.mbr_sa = atchan->sconfig.src_addr;\n\t\t\tdesc->lld.mbr_da = mem;\n\t\t} else {\n\t\t\tdesc->lld.mbr_sa = mem;\n\t\t\tdesc->lld.mbr_da = atchan->sconfig.dst_addr;\n\t\t}\n\t\tdwidth = at_xdmac_get_dwidth(atchan->cfg);\n\t\tfixed_dwidth = IS_ALIGNED(len, 1 << dwidth)\n\t\t\t       ? dwidth\n\t\t\t       : AT_XDMAC_CC_DWIDTH_BYTE;\n\t\tdesc->lld.mbr_ubc = AT_XDMAC_MBR_UBC_NDV2\t\t\t \n\t\t\t| AT_XDMAC_MBR_UBC_NDEN\t\t\t\t\t \n\t\t\t| AT_XDMAC_MBR_UBC_NSEN\t\t\t\t\t \n\t\t\t| (len >> fixed_dwidth);\t\t\t\t \n\t\tdesc->lld.mbr_cfg = (atchan->cfg & ~AT_XDMAC_CC_DWIDTH_MASK) |\n\t\t\t\t    AT_XDMAC_CC_DWIDTH(fixed_dwidth);\n\t\tdev_dbg(chan2dev(chan),\n\t\t\t \"%s: lld: mbr_sa=%pad, mbr_da=%pad, mbr_ubc=0x%08x\\n\",\n\t\t\t __func__, &desc->lld.mbr_sa, &desc->lld.mbr_da, desc->lld.mbr_ubc);\n\n\t\t \n\t\tif (prev)\n\t\t\tat_xdmac_queue_desc(chan, prev, desc);\n\n\t\tprev = desc;\n\t\tif (!first)\n\t\t\tfirst = desc;\n\n\t\tdev_dbg(chan2dev(chan), \"%s: add desc 0x%p to descs_list 0x%p\\n\",\n\t\t\t __func__, desc, first);\n\t\tlist_add_tail(&desc->desc_node, &first->descs_list);\n\t\txfer_size += len;\n\t}\n\n\n\tfirst->tx_dma_desc.flags = flags;\n\tfirst->xfer_size = xfer_size;\n\tfirst->direction = direction;\n\tret = &first->tx_dma_desc;\n\nspin_unlock:\n\tspin_unlock_irqrestore(&atchan->lock, irqflags);\n\treturn ret;\n}\n\nstatic struct dma_async_tx_descriptor *\nat_xdmac_prep_dma_cyclic(struct dma_chan *chan, dma_addr_t buf_addr,\n\t\t\t size_t buf_len, size_t period_len,\n\t\t\t enum dma_transfer_direction direction,\n\t\t\t unsigned long flags)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac_desc\t*first = NULL, *prev = NULL;\n\tunsigned int\t\tperiods = buf_len / period_len;\n\tint\t\t\ti;\n\tunsigned long\t\tirqflags;\n\n\tdev_dbg(chan2dev(chan), \"%s: buf_addr=%pad, buf_len=%zd, period_len=%zd, dir=%s, flags=0x%lx\\n\",\n\t\t__func__, &buf_addr, buf_len, period_len,\n\t\tdirection == DMA_MEM_TO_DEV ? \"mem2per\" : \"per2mem\", flags);\n\n\tif (!is_slave_direction(direction)) {\n\t\tdev_err(chan2dev(chan), \"invalid DMA direction\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (test_and_set_bit(AT_XDMAC_CHAN_IS_CYCLIC, &atchan->status)) {\n\t\tdev_err(chan2dev(chan), \"channel currently used\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (at_xdmac_compute_chan_conf(chan, direction))\n\t\treturn NULL;\n\n\tfor (i = 0; i < periods; i++) {\n\t\tstruct at_xdmac_desc\t*desc = NULL;\n\n\t\tspin_lock_irqsave(&atchan->lock, irqflags);\n\t\tdesc = at_xdmac_get_desc(atchan);\n\t\tif (!desc) {\n\t\t\tdev_err(chan2dev(chan), \"can't get descriptor\\n\");\n\t\t\tif (first)\n\t\t\t\tlist_splice_tail_init(&first->descs_list,\n\t\t\t\t\t\t      &atchan->free_descs_list);\n\t\t\tspin_unlock_irqrestore(&atchan->lock, irqflags);\n\t\t\treturn NULL;\n\t\t}\n\t\tspin_unlock_irqrestore(&atchan->lock, irqflags);\n\t\tdev_dbg(chan2dev(chan),\n\t\t\t\"%s: desc=0x%p, tx_dma_desc.phys=%pad\\n\",\n\t\t\t__func__, desc, &desc->tx_dma_desc.phys);\n\n\t\tif (direction == DMA_DEV_TO_MEM) {\n\t\t\tdesc->lld.mbr_sa = atchan->sconfig.src_addr;\n\t\t\tdesc->lld.mbr_da = buf_addr + i * period_len;\n\t\t} else {\n\t\t\tdesc->lld.mbr_sa = buf_addr + i * period_len;\n\t\t\tdesc->lld.mbr_da = atchan->sconfig.dst_addr;\n\t\t}\n\t\tdesc->lld.mbr_cfg = atchan->cfg;\n\t\tdesc->lld.mbr_ubc = AT_XDMAC_MBR_UBC_NDV1\n\t\t\t| AT_XDMAC_MBR_UBC_NDEN\n\t\t\t| AT_XDMAC_MBR_UBC_NSEN\n\t\t\t| period_len >> at_xdmac_get_dwidth(desc->lld.mbr_cfg);\n\n\t\tdev_dbg(chan2dev(chan),\n\t\t\t \"%s: lld: mbr_sa=%pad, mbr_da=%pad, mbr_ubc=0x%08x\\n\",\n\t\t\t __func__, &desc->lld.mbr_sa, &desc->lld.mbr_da, desc->lld.mbr_ubc);\n\n\t\t \n\t\tif (prev)\n\t\t\tat_xdmac_queue_desc(chan, prev, desc);\n\n\t\tprev = desc;\n\t\tif (!first)\n\t\t\tfirst = desc;\n\n\t\tdev_dbg(chan2dev(chan), \"%s: add desc 0x%p to descs_list 0x%p\\n\",\n\t\t\t __func__, desc, first);\n\t\tlist_add_tail(&desc->desc_node, &first->descs_list);\n\t}\n\n\tat_xdmac_queue_desc(chan, prev, first);\n\tfirst->tx_dma_desc.flags = flags;\n\tfirst->xfer_size = buf_len;\n\tfirst->direction = direction;\n\n\treturn &first->tx_dma_desc;\n}\n\nstatic inline u32 at_xdmac_align_width(struct dma_chan *chan, dma_addr_t addr)\n{\n\tu32 width;\n\n\t \n\tif (!(addr & 7)) {\n\t\twidth = AT_XDMAC_CC_DWIDTH_DWORD;\n\t\tdev_dbg(chan2dev(chan), \"%s: dwidth: double word\\n\", __func__);\n\t} else if (!(addr & 3)) {\n\t\twidth = AT_XDMAC_CC_DWIDTH_WORD;\n\t\tdev_dbg(chan2dev(chan), \"%s: dwidth: word\\n\", __func__);\n\t} else if (!(addr & 1)) {\n\t\twidth = AT_XDMAC_CC_DWIDTH_HALFWORD;\n\t\tdev_dbg(chan2dev(chan), \"%s: dwidth: half word\\n\", __func__);\n\t} else {\n\t\twidth = AT_XDMAC_CC_DWIDTH_BYTE;\n\t\tdev_dbg(chan2dev(chan), \"%s: dwidth: byte\\n\", __func__);\n\t}\n\n\treturn width;\n}\n\nstatic struct at_xdmac_desc *\nat_xdmac_interleaved_queue_desc(struct dma_chan *chan,\n\t\t\t\tstruct at_xdmac_chan *atchan,\n\t\t\t\tstruct at_xdmac_desc *prev,\n\t\t\t\tdma_addr_t src, dma_addr_t dst,\n\t\t\t\tstruct dma_interleaved_template *xt,\n\t\t\t\tstruct data_chunk *chunk)\n{\n\tstruct at_xdmac_desc\t*desc;\n\tu32\t\t\tdwidth;\n\tunsigned long\t\tflags;\n\tsize_t\t\t\tublen;\n\t \n\tu32\t\t\tchan_cc = AT_XDMAC_CC_PERID(0x7f)\n\t\t\t\t\t| AT_XDMAC_CC_MBSIZE_SIXTEEN\n\t\t\t\t\t| AT_XDMAC_CC_TYPE_MEM_TRAN;\n\n\tdwidth = at_xdmac_align_width(chan, src | dst | chunk->size);\n\tif (chunk->size >= (AT_XDMAC_MBR_UBC_UBLEN_MAX << dwidth)) {\n\t\tdev_dbg(chan2dev(chan),\n\t\t\t\"%s: chunk too big (%zu, max size %lu)...\\n\",\n\t\t\t__func__, chunk->size,\n\t\t\tAT_XDMAC_MBR_UBC_UBLEN_MAX << dwidth);\n\t\treturn NULL;\n\t}\n\n\tif (prev)\n\t\tdev_dbg(chan2dev(chan),\n\t\t\t\"Adding items at the end of desc 0x%p\\n\", prev);\n\n\tif (xt->src_inc) {\n\t\tif (xt->src_sgl)\n\t\t\tchan_cc |=  AT_XDMAC_CC_SAM_UBS_AM;\n\t\telse\n\t\t\tchan_cc |=  AT_XDMAC_CC_SAM_INCREMENTED_AM;\n\t}\n\n\tif (xt->dst_inc) {\n\t\tif (xt->dst_sgl)\n\t\t\tchan_cc |=  AT_XDMAC_CC_DAM_UBS_AM;\n\t\telse\n\t\t\tchan_cc |=  AT_XDMAC_CC_DAM_INCREMENTED_AM;\n\t}\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\tdesc = at_xdmac_get_desc(atchan);\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n\tif (!desc) {\n\t\tdev_err(chan2dev(chan), \"can't get descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\tchan_cc |= AT_XDMAC_CC_DWIDTH(dwidth);\n\n\tublen = chunk->size >> dwidth;\n\n\tdesc->lld.mbr_sa = src;\n\tdesc->lld.mbr_da = dst;\n\tdesc->lld.mbr_sus = dmaengine_get_src_icg(xt, chunk);\n\tdesc->lld.mbr_dus = dmaengine_get_dst_icg(xt, chunk);\n\n\tdesc->lld.mbr_ubc = AT_XDMAC_MBR_UBC_NDV3\n\t\t| AT_XDMAC_MBR_UBC_NDEN\n\t\t| AT_XDMAC_MBR_UBC_NSEN\n\t\t| ublen;\n\tdesc->lld.mbr_cfg = chan_cc;\n\n\tdev_dbg(chan2dev(chan),\n\t\t\"%s: lld: mbr_sa=%pad, mbr_da=%pad, mbr_ubc=0x%08x, mbr_cfg=0x%08x\\n\",\n\t\t__func__, &desc->lld.mbr_sa, &desc->lld.mbr_da,\n\t\tdesc->lld.mbr_ubc, desc->lld.mbr_cfg);\n\n\t \n\tif (prev)\n\t\tat_xdmac_queue_desc(chan, prev, desc);\n\n\treturn desc;\n}\n\nstatic struct dma_async_tx_descriptor *\nat_xdmac_prep_interleaved(struct dma_chan *chan,\n\t\t\t  struct dma_interleaved_template *xt,\n\t\t\t  unsigned long flags)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac_desc\t*prev = NULL, *first = NULL;\n\tdma_addr_t\t\tdst_addr, src_addr;\n\tsize_t\t\t\tsrc_skip = 0, dst_skip = 0, len = 0;\n\tstruct data_chunk\t*chunk;\n\tint\t\t\ti;\n\n\tif (!xt || !xt->numf || (xt->dir != DMA_MEM_TO_MEM))\n\t\treturn NULL;\n\n\t \n\tif ((xt->numf > 1) && (xt->frame_size > 1))\n\t\treturn NULL;\n\n\tdev_dbg(chan2dev(chan), \"%s: src=%pad, dest=%pad, numf=%zu, frame_size=%zu, flags=0x%lx\\n\",\n\t\t__func__, &xt->src_start, &xt->dst_start,\txt->numf,\n\t\txt->frame_size, flags);\n\n\tsrc_addr = xt->src_start;\n\tdst_addr = xt->dst_start;\n\n\tif (xt->numf > 1) {\n\t\tfirst = at_xdmac_interleaved_queue_desc(chan, atchan,\n\t\t\t\t\t\t\tNULL,\n\t\t\t\t\t\t\tsrc_addr, dst_addr,\n\t\t\t\t\t\t\txt, xt->sgl);\n\t\tif (!first)\n\t\t\treturn NULL;\n\n\t\t \n\t\tfor (i = 0; i < xt->numf - 1; i++)\n\t\t\tat_xdmac_increment_block_count(chan, first);\n\n\t\tdev_dbg(chan2dev(chan), \"%s: add desc 0x%p to descs_list 0x%p\\n\",\n\t\t\t__func__, first, first);\n\t\tlist_add_tail(&first->desc_node, &first->descs_list);\n\t} else {\n\t\tfor (i = 0; i < xt->frame_size; i++) {\n\t\t\tsize_t src_icg = 0, dst_icg = 0;\n\t\t\tstruct at_xdmac_desc *desc;\n\n\t\t\tchunk = xt->sgl + i;\n\n\t\t\tdst_icg = dmaengine_get_dst_icg(xt, chunk);\n\t\t\tsrc_icg = dmaengine_get_src_icg(xt, chunk);\n\n\t\t\tsrc_skip = chunk->size + src_icg;\n\t\t\tdst_skip = chunk->size + dst_icg;\n\n\t\t\tdev_dbg(chan2dev(chan),\n\t\t\t\t\"%s: chunk size=%zu, src icg=%zu, dst icg=%zu\\n\",\n\t\t\t\t__func__, chunk->size, src_icg, dst_icg);\n\n\t\t\tdesc = at_xdmac_interleaved_queue_desc(chan, atchan,\n\t\t\t\t\t\t\t       prev,\n\t\t\t\t\t\t\t       src_addr, dst_addr,\n\t\t\t\t\t\t\t       xt, chunk);\n\t\t\tif (!desc) {\n\t\t\t\tif (first)\n\t\t\t\t\tlist_splice_tail_init(&first->descs_list,\n\t\t\t\t\t\t\t      &atchan->free_descs_list);\n\t\t\t\treturn NULL;\n\t\t\t}\n\n\t\t\tif (!first)\n\t\t\t\tfirst = desc;\n\n\t\t\tdev_dbg(chan2dev(chan), \"%s: add desc 0x%p to descs_list 0x%p\\n\",\n\t\t\t\t__func__, desc, first);\n\t\t\tlist_add_tail(&desc->desc_node, &first->descs_list);\n\n\t\t\tif (xt->src_sgl)\n\t\t\t\tsrc_addr += src_skip;\n\n\t\t\tif (xt->dst_sgl)\n\t\t\t\tdst_addr += dst_skip;\n\n\t\t\tlen += chunk->size;\n\t\t\tprev = desc;\n\t\t}\n\t}\n\n\tfirst->tx_dma_desc.cookie = -EBUSY;\n\tfirst->tx_dma_desc.flags = flags;\n\tfirst->xfer_size = len;\n\n\treturn &first->tx_dma_desc;\n}\n\nstatic struct dma_async_tx_descriptor *\nat_xdmac_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest, dma_addr_t src,\n\t\t\t size_t len, unsigned long flags)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac_desc\t*first = NULL, *prev = NULL;\n\tsize_t\t\t\tremaining_size = len, xfer_size = 0, ublen;\n\tdma_addr_t\t\tsrc_addr = src, dst_addr = dest;\n\tu32\t\t\tdwidth;\n\t \n\tu32\t\t\tchan_cc = AT_XDMAC_CC_PERID(0x7f)\n\t\t\t\t\t| AT_XDMAC_CC_DAM_INCREMENTED_AM\n\t\t\t\t\t| AT_XDMAC_CC_SAM_INCREMENTED_AM\n\t\t\t\t\t| AT_XDMAC_CC_MBSIZE_SIXTEEN\n\t\t\t\t\t| AT_XDMAC_CC_TYPE_MEM_TRAN;\n\tunsigned long\t\tirqflags;\n\n\tdev_dbg(chan2dev(chan), \"%s: src=%pad, dest=%pad, len=%zd, flags=0x%lx\\n\",\n\t\t__func__, &src, &dest, len, flags);\n\n\tif (unlikely(!len))\n\t\treturn NULL;\n\n\tdwidth = at_xdmac_align_width(chan, src_addr | dst_addr);\n\n\t \n\twhile (remaining_size) {\n\t\tstruct at_xdmac_desc\t*desc = NULL;\n\n\t\tdev_dbg(chan2dev(chan), \"%s: remaining_size=%zu\\n\", __func__, remaining_size);\n\n\t\tspin_lock_irqsave(&atchan->lock, irqflags);\n\t\tdesc = at_xdmac_get_desc(atchan);\n\t\tspin_unlock_irqrestore(&atchan->lock, irqflags);\n\t\tif (!desc) {\n\t\t\tdev_err(chan2dev(chan), \"can't get descriptor\\n\");\n\t\t\tif (first)\n\t\t\t\tlist_splice_tail_init(&first->descs_list,\n\t\t\t\t\t\t      &atchan->free_descs_list);\n\t\t\treturn NULL;\n\t\t}\n\n\t\t \n\t\tsrc_addr += xfer_size;\n\t\tdst_addr += xfer_size;\n\n\t\tif (remaining_size >= AT_XDMAC_MBR_UBC_UBLEN_MAX << dwidth)\n\t\t\txfer_size = AT_XDMAC_MBR_UBC_UBLEN_MAX << dwidth;\n\t\telse\n\t\t\txfer_size = remaining_size;\n\n\t\tdev_dbg(chan2dev(chan), \"%s: xfer_size=%zu\\n\", __func__, xfer_size);\n\n\t\t \n\t\tdwidth = at_xdmac_align_width(chan,\n\t\t\t\t\t      src_addr | dst_addr | xfer_size);\n\t\tchan_cc &= ~AT_XDMAC_CC_DWIDTH_MASK;\n\t\tchan_cc |= AT_XDMAC_CC_DWIDTH(dwidth);\n\n\t\tublen = xfer_size >> dwidth;\n\t\tremaining_size -= xfer_size;\n\n\t\tdesc->lld.mbr_sa = src_addr;\n\t\tdesc->lld.mbr_da = dst_addr;\n\t\tdesc->lld.mbr_ubc = AT_XDMAC_MBR_UBC_NDV2\n\t\t\t| AT_XDMAC_MBR_UBC_NDEN\n\t\t\t| AT_XDMAC_MBR_UBC_NSEN\n\t\t\t| ublen;\n\t\tdesc->lld.mbr_cfg = chan_cc;\n\n\t\tdev_dbg(chan2dev(chan),\n\t\t\t \"%s: lld: mbr_sa=%pad, mbr_da=%pad, mbr_ubc=0x%08x, mbr_cfg=0x%08x\\n\",\n\t\t\t __func__, &desc->lld.mbr_sa, &desc->lld.mbr_da, desc->lld.mbr_ubc, desc->lld.mbr_cfg);\n\n\t\t \n\t\tif (prev)\n\t\t\tat_xdmac_queue_desc(chan, prev, desc);\n\n\t\tprev = desc;\n\t\tif (!first)\n\t\t\tfirst = desc;\n\n\t\tdev_dbg(chan2dev(chan), \"%s: add desc 0x%p to descs_list 0x%p\\n\",\n\t\t\t __func__, desc, first);\n\t\tlist_add_tail(&desc->desc_node, &first->descs_list);\n\t}\n\n\tfirst->tx_dma_desc.flags = flags;\n\tfirst->xfer_size = len;\n\n\treturn &first->tx_dma_desc;\n}\n\nstatic struct at_xdmac_desc *at_xdmac_memset_create_desc(struct dma_chan *chan,\n\t\t\t\t\t\t\t struct at_xdmac_chan *atchan,\n\t\t\t\t\t\t\t dma_addr_t dst_addr,\n\t\t\t\t\t\t\t size_t len,\n\t\t\t\t\t\t\t int value)\n{\n\tstruct at_xdmac_desc\t*desc;\n\tunsigned long\t\tflags;\n\tsize_t\t\t\tublen;\n\tu32\t\t\tdwidth;\n\tchar\t\t\tpattern;\n\t \n\tu32\t\t\tchan_cc = AT_XDMAC_CC_PERID(0x7f)\n\t\t\t\t\t| AT_XDMAC_CC_DAM_UBS_AM\n\t\t\t\t\t| AT_XDMAC_CC_SAM_INCREMENTED_AM\n\t\t\t\t\t| AT_XDMAC_CC_MBSIZE_SIXTEEN\n\t\t\t\t\t| AT_XDMAC_CC_MEMSET_HW_MODE\n\t\t\t\t\t| AT_XDMAC_CC_TYPE_MEM_TRAN;\n\n\tdwidth = at_xdmac_align_width(chan, dst_addr);\n\n\tif (len >= (AT_XDMAC_MBR_UBC_UBLEN_MAX << dwidth)) {\n\t\tdev_err(chan2dev(chan),\n\t\t\t\"%s: Transfer too large, aborting...\\n\",\n\t\t\t__func__);\n\t\treturn NULL;\n\t}\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\tdesc = at_xdmac_get_desc(atchan);\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n\tif (!desc) {\n\t\tdev_err(chan2dev(chan), \"can't get descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\tchan_cc |= AT_XDMAC_CC_DWIDTH(dwidth);\n\n\t \n\tpattern = (char)value;\n\n\tublen = len >> dwidth;\n\n\tdesc->lld.mbr_da = dst_addr;\n\tdesc->lld.mbr_ds = (pattern << 24) |\n\t\t\t   (pattern << 16) |\n\t\t\t   (pattern << 8) |\n\t\t\t   pattern;\n\tdesc->lld.mbr_ubc = AT_XDMAC_MBR_UBC_NDV3\n\t\t| AT_XDMAC_MBR_UBC_NDEN\n\t\t| AT_XDMAC_MBR_UBC_NSEN\n\t\t| ublen;\n\tdesc->lld.mbr_cfg = chan_cc;\n\n\tdev_dbg(chan2dev(chan),\n\t\t\"%s: lld: mbr_da=%pad, mbr_ds=0x%08x, mbr_ubc=0x%08x, mbr_cfg=0x%08x\\n\",\n\t\t__func__, &desc->lld.mbr_da, desc->lld.mbr_ds, desc->lld.mbr_ubc,\n\t\tdesc->lld.mbr_cfg);\n\n\treturn desc;\n}\n\nstatic struct dma_async_tx_descriptor *\nat_xdmac_prep_dma_memset(struct dma_chan *chan, dma_addr_t dest, int value,\n\t\t\t size_t len, unsigned long flags)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac_desc\t*desc;\n\n\tdev_dbg(chan2dev(chan), \"%s: dest=%pad, len=%zu, pattern=0x%x, flags=0x%lx\\n\",\n\t\t__func__, &dest, len, value, flags);\n\n\tif (unlikely(!len))\n\t\treturn NULL;\n\n\tdesc = at_xdmac_memset_create_desc(chan, atchan, dest, len, value);\n\tlist_add_tail(&desc->desc_node, &desc->descs_list);\n\n\tdesc->tx_dma_desc.cookie = -EBUSY;\n\tdesc->tx_dma_desc.flags = flags;\n\tdesc->xfer_size = len;\n\n\treturn &desc->tx_dma_desc;\n}\n\nstatic struct dma_async_tx_descriptor *\nat_xdmac_prep_dma_memset_sg(struct dma_chan *chan, struct scatterlist *sgl,\n\t\t\t    unsigned int sg_len, int value,\n\t\t\t    unsigned long flags)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac_desc\t*desc, *pdesc = NULL,\n\t\t\t\t*ppdesc = NULL, *first = NULL;\n\tstruct scatterlist\t*sg, *psg = NULL, *ppsg = NULL;\n\tsize_t\t\t\tstride = 0, pstride = 0, len = 0;\n\tint\t\t\ti;\n\n\tif (!sgl)\n\t\treturn NULL;\n\n\tdev_dbg(chan2dev(chan), \"%s: sg_len=%d, value=0x%x, flags=0x%lx\\n\",\n\t\t__func__, sg_len, value, flags);\n\n\t \n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tdev_dbg(chan2dev(chan), \"%s: dest=%pad, len=%d, pattern=0x%x, flags=0x%lx\\n\",\n\t\t\t__func__, &sg_dma_address(sg), sg_dma_len(sg),\n\t\t\tvalue, flags);\n\t\tdesc = at_xdmac_memset_create_desc(chan, atchan,\n\t\t\t\t\t\t   sg_dma_address(sg),\n\t\t\t\t\t\t   sg_dma_len(sg),\n\t\t\t\t\t\t   value);\n\t\tif (!desc && first)\n\t\t\tlist_splice_tail_init(&first->descs_list,\n\t\t\t\t\t      &atchan->free_descs_list);\n\n\t\tif (!first)\n\t\t\tfirst = desc;\n\n\t\t \n\t\tpstride = stride;\n\t\tif (psg)\n\t\t\tstride = sg_dma_address(sg) -\n\t\t\t\t(sg_dma_address(psg) + sg_dma_len(psg));\n\n\t\t \n\t\tif (ppdesc && pdesc) {\n\t\t\tif ((stride == pstride) &&\n\t\t\t    (sg_dma_len(ppsg) == sg_dma_len(psg))) {\n\t\t\t\tdev_dbg(chan2dev(chan),\n\t\t\t\t\t\"%s: desc 0x%p can be merged with desc 0x%p\\n\",\n\t\t\t\t\t__func__, pdesc, ppdesc);\n\n\t\t\t\t \n\t\t\t\tat_xdmac_increment_block_count(chan, ppdesc);\n\t\t\t\tppdesc->lld.mbr_dus = stride;\n\n\t\t\t\t \n\t\t\t\tlist_add_tail(&pdesc->desc_node,\n\t\t\t\t\t      &atchan->free_descs_list);\n\n\t\t\t\t \n\t\t\t\tpdesc = ppdesc;\n\n\t\t\t \n\t\t\t} else if (pstride ||\n\t\t\t\t   sg_dma_address(sg) < sg_dma_address(psg)) {\n\t\t\t\t \n\t\t\t\tat_xdmac_queue_desc(chan, ppdesc, pdesc);\n\n\t\t\t\t \n\t\t\t\tlist_add_tail(&desc->desc_node,\n\t\t\t\t\t      &first->descs_list);\n\t\t\t\tdev_dbg(chan2dev(chan),\n\t\t\t\t\t\"%s: add desc 0x%p to descs_list 0x%p\\n\",\n\t\t\t\t\t__func__, desc, first);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif ((i == (sg_len - 1)) &&\n\t\t    sg_dma_len(psg) == sg_dma_len(sg)) {\n\t\t\tdev_dbg(chan2dev(chan),\n\t\t\t\t\"%s: desc 0x%p can be merged with desc 0x%p\\n\",\n\t\t\t\t__func__, desc, pdesc);\n\n\t\t\t \n\t\t\tat_xdmac_increment_block_count(chan, pdesc);\n\t\t\tpdesc->lld.mbr_dus = stride;\n\n\t\t\t \n\t\t\tlist_add_tail(&desc->desc_node,\n\t\t\t\t      &atchan->free_descs_list);\n\t\t}\n\n\t\t \n\t\tppdesc = pdesc;\n\t\tpdesc = desc;\n\n\t\t \n\t\tppsg = psg;\n\t\tpsg = sg;\n\n\t\tlen += sg_dma_len(sg);\n\t}\n\n\tfirst->tx_dma_desc.cookie = -EBUSY;\n\tfirst->tx_dma_desc.flags = flags;\n\tfirst->xfer_size = len;\n\n\treturn &first->tx_dma_desc;\n}\n\nstatic enum dma_status\nat_xdmac_tx_status(struct dma_chan *chan, dma_cookie_t cookie,\n\t\t   struct dma_tx_state *txstate)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tstruct at_xdmac_desc\t*desc, *_desc, *iter;\n\tstruct list_head\t*descs_list;\n\tenum dma_status\t\tret;\n\tint\t\t\tresidue, retry, pm_status;\n\tu32\t\t\tcur_nda, check_nda, cur_ubc, mask, value;\n\tu8\t\t\tdwidth = 0;\n\tunsigned long\t\tflags;\n\tbool\t\t\tinitd;\n\n\tret = dma_cookie_status(chan, cookie, txstate);\n\tif (ret == DMA_COMPLETE || !txstate)\n\t\treturn ret;\n\n\tpm_status = pm_runtime_resume_and_get(atxdmac->dev);\n\tif (pm_status < 0)\n\t\treturn DMA_ERROR;\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\n\tdesc = list_first_entry(&atchan->xfers_list, struct at_xdmac_desc, xfer_node);\n\n\t \n\tif (!desc->active_xfer) {\n\t\tdma_set_residue(txstate, desc->xfer_size);\n\t\tgoto spin_unlock;\n\t}\n\n\tresidue = desc->xfer_size;\n\t \n\tmask = AT_XDMAC_CC_TYPE | AT_XDMAC_CC_DSYNC;\n\tvalue = AT_XDMAC_CC_TYPE_PER_TRAN | AT_XDMAC_CC_DSYNC_PER2MEM;\n\tif ((desc->lld.mbr_cfg & mask) == value) {\n\t\tat_xdmac_write(atxdmac, atxdmac->layout->gswf, atchan->mask);\n\t\twhile (!(at_xdmac_chan_read(atchan, AT_XDMAC_CIS) & AT_XDMAC_CIS_FIS))\n\t\t\tcpu_relax();\n\t}\n\n\t \n\tfor (retry = 0; retry < AT_XDMAC_RESIDUE_MAX_RETRIES; retry++) {\n\t\tcheck_nda = at_xdmac_chan_read(atchan, AT_XDMAC_CNDA) & 0xfffffffc;\n\t\trmb();\n\t\tcur_ubc = at_xdmac_chan_read(atchan, AT_XDMAC_CUBC);\n\t\trmb();\n\t\tinitd = !!(at_xdmac_chan_read(atchan, AT_XDMAC_CC) & AT_XDMAC_CC_INITD);\n\t\trmb();\n\t\tcur_nda = at_xdmac_chan_read(atchan, AT_XDMAC_CNDA) & 0xfffffffc;\n\t\trmb();\n\n\t\tif ((check_nda == cur_nda) && initd)\n\t\t\tbreak;\n\t}\n\n\tif (unlikely(retry >= AT_XDMAC_RESIDUE_MAX_RETRIES)) {\n\t\tret = DMA_ERROR;\n\t\tgoto spin_unlock;\n\t}\n\n\t \n\tif ((desc->lld.mbr_cfg & mask) == value) {\n\t\tat_xdmac_write(atxdmac, atxdmac->layout->gswf, atchan->mask);\n\t\twhile (!(at_xdmac_chan_read(atchan, AT_XDMAC_CIS) & AT_XDMAC_CIS_FIS))\n\t\t\tcpu_relax();\n\t}\n\n\t \n\tdescs_list = &desc->descs_list;\n\tlist_for_each_entry_safe(iter, _desc, descs_list, desc_node) {\n\t\tdwidth = at_xdmac_get_dwidth(iter->lld.mbr_cfg);\n\t\tresidue -= (iter->lld.mbr_ubc & 0xffffff) << dwidth;\n\t\tif ((iter->lld.mbr_nda & 0xfffffffc) == cur_nda) {\n\t\t\tdesc = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\tresidue += cur_ubc << dwidth;\n\n\tdma_set_residue(txstate, residue);\n\n\tdev_dbg(chan2dev(chan),\n\t\t \"%s: desc=0x%p, tx_dma_desc.phys=%pad, tx_status=%d, cookie=%d, residue=%d\\n\",\n\t\t __func__, desc, &desc->tx_dma_desc.phys, ret, cookie, residue);\n\nspin_unlock:\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_autosuspend(atxdmac->dev);\n\treturn ret;\n}\n\nstatic void at_xdmac_advance_work(struct at_xdmac_chan *atchan)\n{\n\tstruct at_xdmac_desc\t*desc;\n\n\t \n\tif (at_xdmac_chan_is_enabled(atchan) || list_empty(&atchan->xfers_list))\n\t\treturn;\n\n\tdesc = list_first_entry(&atchan->xfers_list, struct at_xdmac_desc,\n\t\t\t\txfer_node);\n\tdev_vdbg(chan2dev(&atchan->chan), \"%s: desc 0x%p\\n\", __func__, desc);\n\tif (!desc->active_xfer)\n\t\tat_xdmac_start_xfer(atchan, desc);\n}\n\nstatic void at_xdmac_handle_cyclic(struct at_xdmac_chan *atchan)\n{\n\tstruct at_xdmac_desc\t\t*desc;\n\tstruct dma_async_tx_descriptor\t*txd;\n\n\tspin_lock_irq(&atchan->lock);\n\tdev_dbg(chan2dev(&atchan->chan), \"%s: status=0x%08x\\n\",\n\t\t__func__, atchan->irq_status);\n\tif (list_empty(&atchan->xfers_list)) {\n\t\tspin_unlock_irq(&atchan->lock);\n\t\treturn;\n\t}\n\tdesc = list_first_entry(&atchan->xfers_list, struct at_xdmac_desc,\n\t\t\t\txfer_node);\n\tspin_unlock_irq(&atchan->lock);\n\ttxd = &desc->tx_dma_desc;\n\tif (txd->flags & DMA_PREP_INTERRUPT)\n\t\tdmaengine_desc_get_callback_invoke(txd, NULL);\n}\n\n \nstatic void at_xdmac_handle_error(struct at_xdmac_chan *atchan)\n{\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tstruct at_xdmac_desc\t*bad_desc;\n\tint\t\t\tret;\n\n\tret = pm_runtime_resume_and_get(atxdmac->dev);\n\tif (ret < 0)\n\t\treturn;\n\n\t \n\tif (atchan->irq_status & AT_XDMAC_CIS_RBEIS)\n\t\tdev_err(chan2dev(&atchan->chan), \"read bus error!!!\");\n\tif (atchan->irq_status & AT_XDMAC_CIS_WBEIS)\n\t\tdev_err(chan2dev(&atchan->chan), \"write bus error!!!\");\n\tif (atchan->irq_status & AT_XDMAC_CIS_ROIS)\n\t\tdev_err(chan2dev(&atchan->chan), \"request overflow error!!!\");\n\n\t \n\tat_xdmac_write(atxdmac, AT_XDMAC_GD, atchan->mask);\n\twhile (at_xdmac_read(atxdmac, AT_XDMAC_GS) & atchan->mask)\n\t\tcpu_relax();\n\n\tbad_desc = list_first_entry(&atchan->xfers_list,\n\t\t\t\t    struct at_xdmac_desc,\n\t\t\t\t    xfer_node);\n\n\t \n\tdev_dbg(chan2dev(&atchan->chan),\n\t\t\"%s: lld: mbr_sa=%pad, mbr_da=%pad, mbr_ubc=0x%08x\\n\",\n\t\t__func__, &bad_desc->lld.mbr_sa, &bad_desc->lld.mbr_da,\n\t\tbad_desc->lld.mbr_ubc);\n\n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_autosuspend(atxdmac->dev);\n\n\t \n}\n\nstatic void at_xdmac_tasklet(struct tasklet_struct *t)\n{\n\tstruct at_xdmac_chan\t*atchan = from_tasklet(atchan, t, tasklet);\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tstruct at_xdmac_desc\t*desc;\n\tstruct dma_async_tx_descriptor *txd;\n\tu32\t\t\terror_mask;\n\n\tif (at_xdmac_chan_is_cyclic(atchan))\n\t\treturn at_xdmac_handle_cyclic(atchan);\n\n\terror_mask = AT_XDMAC_CIS_RBEIS | AT_XDMAC_CIS_WBEIS |\n\t\tAT_XDMAC_CIS_ROIS;\n\n\tspin_lock_irq(&atchan->lock);\n\n\tdev_dbg(chan2dev(&atchan->chan), \"%s: status=0x%08x\\n\",\n\t\t__func__, atchan->irq_status);\n\n\tif (!(atchan->irq_status & AT_XDMAC_CIS_LIS) &&\n\t    !(atchan->irq_status & error_mask)) {\n\t\tspin_unlock_irq(&atchan->lock);\n\t\treturn;\n\t}\n\n\tif (atchan->irq_status & error_mask)\n\t\tat_xdmac_handle_error(atchan);\n\n\tdesc = list_first_entry(&atchan->xfers_list, struct at_xdmac_desc,\n\t\t\t\txfer_node);\n\tdev_vdbg(chan2dev(&atchan->chan), \"%s: desc 0x%p\\n\", __func__, desc);\n\tif (!desc->active_xfer) {\n\t\tdev_err(chan2dev(&atchan->chan), \"Xfer not active: exiting\");\n\t\tspin_unlock_irq(&atchan->lock);\n\t\treturn;\n\t}\n\n\ttxd = &desc->tx_dma_desc;\n\tdma_cookie_complete(txd);\n\t \n\tlist_del(&desc->xfer_node);\n\tspin_unlock_irq(&atchan->lock);\n\n\tif (txd->flags & DMA_PREP_INTERRUPT)\n\t\tdmaengine_desc_get_callback_invoke(txd, NULL);\n\n\tdma_run_dependencies(txd);\n\n\tspin_lock_irq(&atchan->lock);\n\t \n\tlist_splice_tail_init(&desc->descs_list, &atchan->free_descs_list);\n\tat_xdmac_advance_work(atchan);\n\tspin_unlock_irq(&atchan->lock);\n\n\t \n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_autosuspend(atxdmac->dev);\n}\n\nstatic irqreturn_t at_xdmac_interrupt(int irq, void *dev_id)\n{\n\tstruct at_xdmac\t\t*atxdmac = (struct at_xdmac *)dev_id;\n\tstruct at_xdmac_chan\t*atchan;\n\tu32\t\t\timr, status, pending;\n\tu32\t\t\tchan_imr, chan_status;\n\tint\t\t\ti, ret = IRQ_NONE;\n\n\tdo {\n\t\timr = at_xdmac_read(atxdmac, AT_XDMAC_GIM);\n\t\tstatus = at_xdmac_read(atxdmac, AT_XDMAC_GIS);\n\t\tpending = status & imr;\n\n\t\tdev_vdbg(atxdmac->dma.dev,\n\t\t\t \"%s: status=0x%08x, imr=0x%08x, pending=0x%08x\\n\",\n\t\t\t __func__, status, imr, pending);\n\n\t\tif (!pending)\n\t\t\tbreak;\n\n\t\t \n\t\tfor (i = 0; i < atxdmac->dma.chancnt; i++) {\n\t\t\tif (!((1 << i) & pending))\n\t\t\t\tcontinue;\n\n\t\t\tatchan = &atxdmac->chan[i];\n\t\t\tchan_imr = at_xdmac_chan_read(atchan, AT_XDMAC_CIM);\n\t\t\tchan_status = at_xdmac_chan_read(atchan, AT_XDMAC_CIS);\n\t\t\tatchan->irq_status = chan_status & chan_imr;\n\t\t\tdev_vdbg(atxdmac->dma.dev,\n\t\t\t\t \"%s: chan%d: imr=0x%x, status=0x%x\\n\",\n\t\t\t\t __func__, i, chan_imr, chan_status);\n\t\t\tdev_vdbg(chan2dev(&atchan->chan),\n\t\t\t\t \"%s: CC=0x%08x CNDA=0x%08x, CNDC=0x%08x, CSA=0x%08x, CDA=0x%08x, CUBC=0x%08x\\n\",\n\t\t\t\t __func__,\n\t\t\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CC),\n\t\t\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CNDA),\n\t\t\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CNDC),\n\t\t\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CSA),\n\t\t\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CDA),\n\t\t\t\t at_xdmac_chan_read(atchan, AT_XDMAC_CUBC));\n\n\t\t\tif (atchan->irq_status & (AT_XDMAC_CIS_RBEIS | AT_XDMAC_CIS_WBEIS))\n\t\t\t\tat_xdmac_write(atxdmac, AT_XDMAC_GD, atchan->mask);\n\n\t\t\ttasklet_schedule(&atchan->tasklet);\n\t\t\tret = IRQ_HANDLED;\n\t\t}\n\n\t} while (pending);\n\n\treturn ret;\n}\n\nstatic void at_xdmac_issue_pending(struct dma_chan *chan)\n{\n\tstruct at_xdmac_chan *atchan = to_at_xdmac_chan(chan);\n\tunsigned long flags;\n\n\tdev_dbg(chan2dev(&atchan->chan), \"%s\\n\", __func__);\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\tat_xdmac_advance_work(atchan);\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n\n\treturn;\n}\n\nstatic int at_xdmac_device_config(struct dma_chan *chan,\n\t\t\t\t  struct dma_slave_config *config)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tint ret;\n\tunsigned long\t\tflags;\n\n\tdev_dbg(chan2dev(chan), \"%s\\n\", __func__);\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\tret = at_xdmac_set_slave_config(chan, config);\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n\n\treturn ret;\n}\n\nstatic void at_xdmac_device_pause_set(struct at_xdmac *atxdmac,\n\t\t\t\t      struct at_xdmac_chan *atchan)\n{\n\tat_xdmac_write(atxdmac, atxdmac->layout->grws, atchan->mask);\n\twhile (at_xdmac_chan_read(atchan, AT_XDMAC_CC) &\n\t       (AT_XDMAC_CC_WRIP | AT_XDMAC_CC_RDIP))\n\t\tcpu_relax();\n}\n\nstatic void at_xdmac_device_pause_internal(struct at_xdmac_chan *atchan)\n{\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tunsigned long\t\tflags;\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\tset_bit(AT_XDMAC_CHAN_IS_PAUSED_INTERNAL, &atchan->status);\n\tat_xdmac_device_pause_set(atxdmac, atchan);\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n}\n\nstatic int at_xdmac_device_pause(struct dma_chan *chan)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tunsigned long\t\tflags;\n\tint\t\t\tret;\n\n\tdev_dbg(chan2dev(chan), \"%s\\n\", __func__);\n\n\tif (test_and_set_bit(AT_XDMAC_CHAN_IS_PAUSED, &atchan->status))\n\t\treturn 0;\n\n\tret = pm_runtime_resume_and_get(atxdmac->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\n\tat_xdmac_device_pause_set(atxdmac, atchan);\n\t \n\tat_xdmac_runtime_suspend_descriptors(atchan);\n\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n\n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_autosuspend(atxdmac->dev);\n\n\treturn 0;\n}\n\nstatic void at_xdmac_device_resume_internal(struct at_xdmac_chan *atchan)\n{\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tunsigned long\t\tflags;\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\tat_xdmac_write(atxdmac, atxdmac->layout->grwr, atchan->mask);\n\tclear_bit(AT_XDMAC_CHAN_IS_PAUSED_INTERNAL, &atchan->status);\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n}\n\nstatic int at_xdmac_device_resume(struct dma_chan *chan)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tunsigned long\t\tflags;\n\tint\t\t\tret;\n\n\tdev_dbg(chan2dev(chan), \"%s\\n\", __func__);\n\n\tret = pm_runtime_resume_and_get(atxdmac->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\tif (!at_xdmac_chan_is_paused(atchan))\n\t\tgoto unlock;\n\n\t \n\tret = at_xdmac_runtime_resume_descriptors(atchan);\n\tif (ret < 0)\n\t\tgoto unlock;\n\n\tat_xdmac_write(atxdmac, atxdmac->layout->grwr, atchan->mask);\n\tclear_bit(AT_XDMAC_CHAN_IS_PAUSED, &atchan->status);\n\nunlock:\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_autosuspend(atxdmac->dev);\n\n\treturn ret;\n}\n\nstatic int at_xdmac_device_terminate_all(struct dma_chan *chan)\n{\n\tstruct at_xdmac_desc\t*desc, *_desc;\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(atchan->chan.device);\n\tunsigned long\t\tflags;\n\tint\t\t\tret;\n\n\tdev_dbg(chan2dev(chan), \"%s\\n\", __func__);\n\n\tret = pm_runtime_resume_and_get(atxdmac->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&atchan->lock, flags);\n\tat_xdmac_write(atxdmac, AT_XDMAC_GD, atchan->mask);\n\twhile (at_xdmac_read(atxdmac, AT_XDMAC_GS) & atchan->mask)\n\t\tcpu_relax();\n\n\t \n\tlist_for_each_entry_safe(desc, _desc, &atchan->xfers_list, xfer_node) {\n\t\tlist_del(&desc->xfer_node);\n\t\tlist_splice_tail_init(&desc->descs_list,\n\t\t\t\t      &atchan->free_descs_list);\n\t\t \n\t\tif (desc->active_xfer) {\n\t\t\tpm_runtime_put_autosuspend(atxdmac->dev);\n\t\t\tpm_runtime_mark_last_busy(atxdmac->dev);\n\t\t}\n\t}\n\n\tclear_bit(AT_XDMAC_CHAN_IS_PAUSED, &atchan->status);\n\tclear_bit(AT_XDMAC_CHAN_IS_CYCLIC, &atchan->status);\n\tspin_unlock_irqrestore(&atchan->lock, flags);\n\n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_autosuspend(atxdmac->dev);\n\n\treturn 0;\n}\n\nstatic int at_xdmac_alloc_chan_resources(struct dma_chan *chan)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac_desc\t*desc;\n\tint\t\t\ti;\n\n\tif (at_xdmac_chan_is_enabled(atchan)) {\n\t\tdev_err(chan2dev(chan),\n\t\t\t\"can't allocate channel resources (channel enabled)\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (!list_empty(&atchan->free_descs_list)) {\n\t\tdev_err(chan2dev(chan),\n\t\t\t\"can't allocate channel resources (channel not free from a previous use)\\n\");\n\t\treturn -EIO;\n\t}\n\n\tfor (i = 0; i < init_nr_desc_per_channel; i++) {\n\t\tdesc = at_xdmac_alloc_desc(chan, GFP_KERNEL);\n\t\tif (!desc) {\n\t\t\tif (i == 0) {\n\t\t\t\tdev_warn(chan2dev(chan),\n\t\t\t\t\t \"can't allocate any descriptors\\n\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t\tdev_warn(chan2dev(chan),\n\t\t\t\t\"only %d descriptors have been allocated\\n\", i);\n\t\t\tbreak;\n\t\t}\n\t\tlist_add_tail(&desc->desc_node, &atchan->free_descs_list);\n\t}\n\n\tdma_cookie_init(chan);\n\n\tdev_dbg(chan2dev(chan), \"%s: allocated %d descriptors\\n\", __func__, i);\n\n\treturn i;\n}\n\nstatic void at_xdmac_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\tstruct at_xdmac\t\t*atxdmac = to_at_xdmac(chan->device);\n\tstruct at_xdmac_desc\t*desc, *_desc;\n\n\tlist_for_each_entry_safe(desc, _desc, &atchan->free_descs_list, desc_node) {\n\t\tdev_dbg(chan2dev(chan), \"%s: freeing descriptor %p\\n\", __func__, desc);\n\t\tlist_del(&desc->desc_node);\n\t\tdma_pool_free(atxdmac->at_xdmac_desc_pool, desc, desc->tx_dma_desc.phys);\n\t}\n\n\treturn;\n}\n\nstatic void at_xdmac_axi_config(struct platform_device *pdev)\n{\n\tstruct at_xdmac\t*atxdmac = (struct at_xdmac *)platform_get_drvdata(pdev);\n\tbool dev_m2m = false;\n\tu32 dma_requests;\n\n\tif (!atxdmac->layout->axi_config)\n\t\treturn;  \n\n\tif (!of_property_read_u32(pdev->dev.of_node, \"dma-requests\",\n\t\t\t\t  &dma_requests)) {\n\t\tdev_info(&pdev->dev, \"controller in mem2mem mode.\\n\");\n\t\tdev_m2m = true;\n\t}\n\n\tif (dev_m2m) {\n\t\tat_xdmac_write(atxdmac, AT_XDMAC_GCFG, AT_XDMAC_GCFG_M2M);\n\t\tat_xdmac_write(atxdmac, AT_XDMAC_GWAC, AT_XDMAC_GWAC_M2M);\n\t} else {\n\t\tat_xdmac_write(atxdmac, AT_XDMAC_GCFG, AT_XDMAC_GCFG_P2M);\n\t\tat_xdmac_write(atxdmac, AT_XDMAC_GWAC, AT_XDMAC_GWAC_P2M);\n\t}\n}\n\nstatic int __maybe_unused atmel_xdmac_prepare(struct device *dev)\n{\n\tstruct at_xdmac\t\t*atxdmac = dev_get_drvdata(dev);\n\tstruct dma_chan\t\t*chan, *_chan;\n\n\tlist_for_each_entry_safe(chan, _chan, &atxdmac->dma.channels, device_node) {\n\t\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\n\t\t \n\t\tif (at_xdmac_chan_is_enabled(atchan) && !at_xdmac_chan_is_cyclic(atchan))\n\t\t\treturn -EAGAIN;\n\t}\n\treturn 0;\n}\n\nstatic int __maybe_unused atmel_xdmac_suspend(struct device *dev)\n{\n\tstruct at_xdmac\t\t*atxdmac = dev_get_drvdata(dev);\n\tstruct dma_chan\t\t*chan, *_chan;\n\tint\t\t\tret;\n\n\tret = pm_runtime_resume_and_get(atxdmac->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tlist_for_each_entry_safe(chan, _chan, &atxdmac->dma.channels, device_node) {\n\t\tstruct at_xdmac_chan\t*atchan = to_at_xdmac_chan(chan);\n\n\t\tatchan->save_cc = at_xdmac_chan_read(atchan, AT_XDMAC_CC);\n\t\tif (at_xdmac_chan_is_cyclic(atchan)) {\n\t\t\tif (!at_xdmac_chan_is_paused(atchan)) {\n\t\t\t\tdev_warn(chan2dev(chan), \"%s: channel %d not paused\\n\",\n\t\t\t\t\t __func__, chan->chan_id);\n\t\t\t\tat_xdmac_device_pause_internal(atchan);\n\t\t\t\tat_xdmac_runtime_suspend_descriptors(atchan);\n\t\t\t}\n\t\t\tatchan->save_cim = at_xdmac_chan_read(atchan, AT_XDMAC_CIM);\n\t\t\tatchan->save_cnda = at_xdmac_chan_read(atchan, AT_XDMAC_CNDA);\n\t\t\tatchan->save_cndc = at_xdmac_chan_read(atchan, AT_XDMAC_CNDC);\n\t\t}\n\t}\n\tatxdmac->save_gim = at_xdmac_read(atxdmac, AT_XDMAC_GIM);\n\tatxdmac->save_gs = at_xdmac_read(atxdmac, AT_XDMAC_GS);\n\n\tat_xdmac_off(atxdmac, false);\n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_noidle(atxdmac->dev);\n\tclk_disable_unprepare(atxdmac->clk);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused atmel_xdmac_resume(struct device *dev)\n{\n\tstruct at_xdmac\t\t*atxdmac = dev_get_drvdata(dev);\n\tstruct at_xdmac_chan\t*atchan;\n\tstruct dma_chan\t\t*chan, *_chan;\n\tstruct platform_device\t*pdev = container_of(dev, struct platform_device, dev);\n\tint\t\t\ti, ret;\n\n\tret = clk_prepare_enable(atxdmac->clk);\n\tif (ret)\n\t\treturn ret;\n\n\tpm_runtime_get_noresume(atxdmac->dev);\n\n\tat_xdmac_axi_config(pdev);\n\n\t \n\tfor (i = 0; i < atxdmac->dma.chancnt; i++) {\n\t\tatchan = &atxdmac->chan[i];\n\t\twhile (at_xdmac_chan_read(atchan, AT_XDMAC_CIS))\n\t\t\tcpu_relax();\n\t}\n\n\tat_xdmac_write(atxdmac, AT_XDMAC_GIE, atxdmac->save_gim);\n\tlist_for_each_entry_safe(chan, _chan, &atxdmac->dma.channels, device_node) {\n\t\tatchan = to_at_xdmac_chan(chan);\n\n\t\tat_xdmac_chan_write(atchan, AT_XDMAC_CC, atchan->save_cc);\n\t\tif (at_xdmac_chan_is_cyclic(atchan)) {\n\t\t\t \n\t\t\tif (at_xdmac_chan_is_paused_internal(atchan)) {\n\t\t\t\tret = at_xdmac_runtime_resume_descriptors(atchan);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\tat_xdmac_device_resume_internal(atchan);\n\t\t\t}\n\n\t\t\t \n\t\t\telse if (at_xdmac_chan_is_paused(atchan))\n\t\t\t\tat_xdmac_device_pause_set(atxdmac, atchan);\n\n\t\t\tat_xdmac_chan_write(atchan, AT_XDMAC_CNDA, atchan->save_cnda);\n\t\t\tat_xdmac_chan_write(atchan, AT_XDMAC_CNDC, atchan->save_cndc);\n\t\t\tat_xdmac_chan_write(atchan, AT_XDMAC_CIE, atchan->save_cim);\n\t\t\twmb();\n\t\t\tif (atxdmac->save_gs & atchan->mask)\n\t\t\t\tat_xdmac_write(atxdmac, AT_XDMAC_GE, atchan->mask);\n\t\t}\n\t}\n\n\tpm_runtime_mark_last_busy(atxdmac->dev);\n\tpm_runtime_put_autosuspend(atxdmac->dev);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused atmel_xdmac_runtime_suspend(struct device *dev)\n{\n\tstruct at_xdmac *atxdmac = dev_get_drvdata(dev);\n\n\tclk_disable(atxdmac->clk);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused atmel_xdmac_runtime_resume(struct device *dev)\n{\n\tstruct at_xdmac *atxdmac = dev_get_drvdata(dev);\n\n\treturn clk_enable(atxdmac->clk);\n}\n\nstatic int at_xdmac_probe(struct platform_device *pdev)\n{\n\tstruct at_xdmac\t*atxdmac;\n\tint\t\tirq, nr_channels, i, ret;\n\tvoid __iomem\t*base;\n\tu32\t\treg;\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tbase = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(base))\n\t\treturn PTR_ERR(base);\n\n\t \n\treg = readl_relaxed(base + AT_XDMAC_GTYPE);\n\tnr_channels = AT_XDMAC_NB_CH(reg);\n\tif (nr_channels > AT_XDMAC_MAX_CHAN) {\n\t\tdev_err(&pdev->dev, \"invalid number of channels (%u)\\n\",\n\t\t\tnr_channels);\n\t\treturn -EINVAL;\n\t}\n\n\tatxdmac = devm_kzalloc(&pdev->dev,\n\t\t\t       struct_size(atxdmac, chan, nr_channels),\n\t\t\t       GFP_KERNEL);\n\tif (!atxdmac) {\n\t\tdev_err(&pdev->dev, \"can't allocate at_xdmac structure\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tatxdmac->regs = base;\n\tatxdmac->irq = irq;\n\tatxdmac->dev = &pdev->dev;\n\n\tatxdmac->layout = of_device_get_match_data(&pdev->dev);\n\tif (!atxdmac->layout)\n\t\treturn -ENODEV;\n\n\tatxdmac->clk = devm_clk_get(&pdev->dev, \"dma_clk\");\n\tif (IS_ERR(atxdmac->clk)) {\n\t\tdev_err(&pdev->dev, \"can't get dma_clk\\n\");\n\t\treturn PTR_ERR(atxdmac->clk);\n\t}\n\n\t \n\tret = request_irq(atxdmac->irq, at_xdmac_interrupt, 0, \"at_xdmac\", atxdmac);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"can't request irq\\n\");\n\t\treturn ret;\n\t}\n\n\tret = clk_prepare_enable(atxdmac->clk);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"can't prepare or enable clock\\n\");\n\t\tgoto err_free_irq;\n\t}\n\n\tatxdmac->at_xdmac_desc_pool =\n\t\tdmam_pool_create(dev_name(&pdev->dev), &pdev->dev,\n\t\t\t\tsizeof(struct at_xdmac_desc), 4, 0);\n\tif (!atxdmac->at_xdmac_desc_pool) {\n\t\tdev_err(&pdev->dev, \"no memory for descriptors dma pool\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_clk_disable;\n\t}\n\n\tdma_cap_set(DMA_CYCLIC, atxdmac->dma.cap_mask);\n\tdma_cap_set(DMA_INTERLEAVE, atxdmac->dma.cap_mask);\n\tdma_cap_set(DMA_MEMCPY, atxdmac->dma.cap_mask);\n\tdma_cap_set(DMA_MEMSET, atxdmac->dma.cap_mask);\n\tdma_cap_set(DMA_MEMSET_SG, atxdmac->dma.cap_mask);\n\tdma_cap_set(DMA_SLAVE, atxdmac->dma.cap_mask);\n\t \n\tdma_cap_set(DMA_PRIVATE, atxdmac->dma.cap_mask);\n\tatxdmac->dma.dev\t\t\t\t= &pdev->dev;\n\tatxdmac->dma.device_alloc_chan_resources\t= at_xdmac_alloc_chan_resources;\n\tatxdmac->dma.device_free_chan_resources\t\t= at_xdmac_free_chan_resources;\n\tatxdmac->dma.device_tx_status\t\t\t= at_xdmac_tx_status;\n\tatxdmac->dma.device_issue_pending\t\t= at_xdmac_issue_pending;\n\tatxdmac->dma.device_prep_dma_cyclic\t\t= at_xdmac_prep_dma_cyclic;\n\tatxdmac->dma.device_prep_interleaved_dma\t= at_xdmac_prep_interleaved;\n\tatxdmac->dma.device_prep_dma_memcpy\t\t= at_xdmac_prep_dma_memcpy;\n\tatxdmac->dma.device_prep_dma_memset\t\t= at_xdmac_prep_dma_memset;\n\tatxdmac->dma.device_prep_dma_memset_sg\t\t= at_xdmac_prep_dma_memset_sg;\n\tatxdmac->dma.device_prep_slave_sg\t\t= at_xdmac_prep_slave_sg;\n\tatxdmac->dma.device_config\t\t\t= at_xdmac_device_config;\n\tatxdmac->dma.device_pause\t\t\t= at_xdmac_device_pause;\n\tatxdmac->dma.device_resume\t\t\t= at_xdmac_device_resume;\n\tatxdmac->dma.device_terminate_all\t\t= at_xdmac_device_terminate_all;\n\tatxdmac->dma.src_addr_widths = AT_XDMAC_DMA_BUSWIDTHS;\n\tatxdmac->dma.dst_addr_widths = AT_XDMAC_DMA_BUSWIDTHS;\n\tatxdmac->dma.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\n\tatxdmac->dma.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\n\tplatform_set_drvdata(pdev, atxdmac);\n\n\tpm_runtime_set_autosuspend_delay(&pdev->dev, 500);\n\tpm_runtime_use_autosuspend(&pdev->dev);\n\tpm_runtime_set_active(&pdev->dev);\n\tpm_runtime_enable(&pdev->dev);\n\tpm_runtime_get_noresume(&pdev->dev);\n\n\t \n\tINIT_LIST_HEAD(&atxdmac->dma.channels);\n\n\t \n\tat_xdmac_off(atxdmac, true);\n\n\tfor (i = 0; i < nr_channels; i++) {\n\t\tstruct at_xdmac_chan *atchan = &atxdmac->chan[i];\n\n\t\tatchan->chan.device = &atxdmac->dma;\n\t\tlist_add_tail(&atchan->chan.device_node,\n\t\t\t      &atxdmac->dma.channels);\n\n\t\tatchan->ch_regs = at_xdmac_chan_reg_base(atxdmac, i);\n\t\tatchan->mask = 1 << i;\n\n\t\tspin_lock_init(&atchan->lock);\n\t\tINIT_LIST_HEAD(&atchan->xfers_list);\n\t\tINIT_LIST_HEAD(&atchan->free_descs_list);\n\t\ttasklet_setup(&atchan->tasklet, at_xdmac_tasklet);\n\n\t\t \n\t\twhile (at_xdmac_chan_read(atchan, AT_XDMAC_CIS))\n\t\t\tcpu_relax();\n\t}\n\n\tret = dma_async_device_register(&atxdmac->dma);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"fail to register DMA engine device\\n\");\n\t\tgoto err_pm_disable;\n\t}\n\n\tret = of_dma_controller_register(pdev->dev.of_node,\n\t\t\t\t\t at_xdmac_xlate, atxdmac);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"could not register of dma controller\\n\");\n\t\tgoto err_dma_unregister;\n\t}\n\n\tdev_info(&pdev->dev, \"%d channels, mapped at 0x%p\\n\",\n\t\t nr_channels, atxdmac->regs);\n\n\tat_xdmac_axi_config(pdev);\n\n\tpm_runtime_mark_last_busy(&pdev->dev);\n\tpm_runtime_put_autosuspend(&pdev->dev);\n\n\treturn 0;\n\nerr_dma_unregister:\n\tdma_async_device_unregister(&atxdmac->dma);\nerr_pm_disable:\n\tpm_runtime_put_noidle(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\tpm_runtime_set_suspended(&pdev->dev);\n\tpm_runtime_dont_use_autosuspend(&pdev->dev);\nerr_clk_disable:\n\tclk_disable_unprepare(atxdmac->clk);\nerr_free_irq:\n\tfree_irq(atxdmac->irq, atxdmac);\n\treturn ret;\n}\n\nstatic int at_xdmac_remove(struct platform_device *pdev)\n{\n\tstruct at_xdmac\t*atxdmac = (struct at_xdmac *)platform_get_drvdata(pdev);\n\tint\t\ti;\n\n\tat_xdmac_off(atxdmac, true);\n\tof_dma_controller_free(pdev->dev.of_node);\n\tdma_async_device_unregister(&atxdmac->dma);\n\tpm_runtime_disable(atxdmac->dev);\n\tpm_runtime_set_suspended(&pdev->dev);\n\tpm_runtime_dont_use_autosuspend(&pdev->dev);\n\tclk_disable_unprepare(atxdmac->clk);\n\n\tfree_irq(atxdmac->irq, atxdmac);\n\n\tfor (i = 0; i < atxdmac->dma.chancnt; i++) {\n\t\tstruct at_xdmac_chan *atchan = &atxdmac->chan[i];\n\n\t\ttasklet_kill(&atchan->tasklet);\n\t\tat_xdmac_free_chan_resources(&atchan->chan);\n\t}\n\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops __maybe_unused atmel_xdmac_dev_pm_ops = {\n\t.prepare\t= atmel_xdmac_prepare,\n\tSET_LATE_SYSTEM_SLEEP_PM_OPS(atmel_xdmac_suspend, atmel_xdmac_resume)\n\tSET_RUNTIME_PM_OPS(atmel_xdmac_runtime_suspend,\n\t\t\t   atmel_xdmac_runtime_resume, NULL)\n};\n\nstatic const struct of_device_id atmel_xdmac_dt_ids[] = {\n\t{\n\t\t.compatible = \"atmel,sama5d4-dma\",\n\t\t.data = &at_xdmac_sama5d4_layout,\n\t}, {\n\t\t.compatible = \"microchip,sama7g5-dma\",\n\t\t.data = &at_xdmac_sama7g5_layout,\n\t}, {\n\t\t \n\t}\n};\nMODULE_DEVICE_TABLE(of, atmel_xdmac_dt_ids);\n\nstatic struct platform_driver at_xdmac_driver = {\n\t.probe\t\t= at_xdmac_probe,\n\t.remove\t\t= at_xdmac_remove,\n\t.driver = {\n\t\t.name\t\t= \"at_xdmac\",\n\t\t.of_match_table\t= of_match_ptr(atmel_xdmac_dt_ids),\n\t\t.pm\t\t= pm_ptr(&atmel_xdmac_dev_pm_ops),\n\t}\n};\n\nstatic int __init at_xdmac_init(void)\n{\n\treturn platform_driver_register(&at_xdmac_driver);\n}\nsubsys_initcall(at_xdmac_init);\n\nstatic void __exit at_xdmac_exit(void)\n{\n\tplatform_driver_unregister(&at_xdmac_driver);\n}\nmodule_exit(at_xdmac_exit);\n\nMODULE_DESCRIPTION(\"Atmel Extended DMA Controller driver\");\nMODULE_AUTHOR(\"Ludovic Desroches <ludovic.desroches@atmel.com>\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}