{
  "module_name": "tegra20-apb-dma.c",
  "hash_id": "504bc89134063034b658e78f34ce630a88361bf6c7df9913a138cf76f54c9097",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/tegra20-apb-dma.c",
  "human_readable_source": "\n \n\n#include <linux/bitops.h>\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_dma.h>\n#include <linux/platform_device.h>\n#include <linux/pm.h>\n#include <linux/pm_runtime.h>\n#include <linux/reset.h>\n#include <linux/slab.h>\n#include <linux/wait.h>\n\n#include \"dmaengine.h\"\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/tegra_apb_dma.h>\n\n#define TEGRA_APBDMA_GENERAL\t\t\t0x0\n#define TEGRA_APBDMA_GENERAL_ENABLE\t\tBIT(31)\n\n#define TEGRA_APBDMA_CONTROL\t\t\t0x010\n#define TEGRA_APBDMA_IRQ_MASK\t\t\t0x01c\n#define TEGRA_APBDMA_IRQ_MASK_SET\t\t0x020\n\n \n#define TEGRA_APBDMA_CHAN_CSR\t\t\t0x00\n#define TEGRA_APBDMA_CSR_ENB\t\t\tBIT(31)\n#define TEGRA_APBDMA_CSR_IE_EOC\t\t\tBIT(30)\n#define TEGRA_APBDMA_CSR_HOLD\t\t\tBIT(29)\n#define TEGRA_APBDMA_CSR_DIR\t\t\tBIT(28)\n#define TEGRA_APBDMA_CSR_ONCE\t\t\tBIT(27)\n#define TEGRA_APBDMA_CSR_FLOW\t\t\tBIT(21)\n#define TEGRA_APBDMA_CSR_REQ_SEL_SHIFT\t\t16\n#define TEGRA_APBDMA_CSR_REQ_SEL_MASK\t\t0x1F\n#define TEGRA_APBDMA_CSR_WCOUNT_MASK\t\t0xFFFC\n\n \n#define TEGRA_APBDMA_CHAN_STATUS\t\t0x004\n#define TEGRA_APBDMA_STATUS_BUSY\t\tBIT(31)\n#define TEGRA_APBDMA_STATUS_ISE_EOC\t\tBIT(30)\n#define TEGRA_APBDMA_STATUS_HALT\t\tBIT(29)\n#define TEGRA_APBDMA_STATUS_PING_PONG\t\tBIT(28)\n#define TEGRA_APBDMA_STATUS_COUNT_SHIFT\t\t2\n#define TEGRA_APBDMA_STATUS_COUNT_MASK\t\t0xFFFC\n\n#define TEGRA_APBDMA_CHAN_CSRE\t\t\t0x00C\n#define TEGRA_APBDMA_CHAN_CSRE_PAUSE\t\tBIT(31)\n\n \n#define TEGRA_APBDMA_CHAN_AHBPTR\t\t0x010\n\n \n#define TEGRA_APBDMA_CHAN_AHBSEQ\t\t0x14\n#define TEGRA_APBDMA_AHBSEQ_INTR_ENB\t\tBIT(31)\n#define TEGRA_APBDMA_AHBSEQ_BUS_WIDTH_8\t\t(0 << 28)\n#define TEGRA_APBDMA_AHBSEQ_BUS_WIDTH_16\t(1 << 28)\n#define TEGRA_APBDMA_AHBSEQ_BUS_WIDTH_32\t(2 << 28)\n#define TEGRA_APBDMA_AHBSEQ_BUS_WIDTH_64\t(3 << 28)\n#define TEGRA_APBDMA_AHBSEQ_BUS_WIDTH_128\t(4 << 28)\n#define TEGRA_APBDMA_AHBSEQ_DATA_SWAP\t\tBIT(27)\n#define TEGRA_APBDMA_AHBSEQ_BURST_1\t\t(4 << 24)\n#define TEGRA_APBDMA_AHBSEQ_BURST_4\t\t(5 << 24)\n#define TEGRA_APBDMA_AHBSEQ_BURST_8\t\t(6 << 24)\n#define TEGRA_APBDMA_AHBSEQ_DBL_BUF\t\tBIT(19)\n#define TEGRA_APBDMA_AHBSEQ_WRAP_SHIFT\t\t16\n#define TEGRA_APBDMA_AHBSEQ_WRAP_NONE\t\t0\n\n \n#define TEGRA_APBDMA_CHAN_APBPTR\t\t0x018\n\n \n#define TEGRA_APBDMA_CHAN_APBSEQ\t\t0x01c\n#define TEGRA_APBDMA_APBSEQ_BUS_WIDTH_8\t\t(0 << 28)\n#define TEGRA_APBDMA_APBSEQ_BUS_WIDTH_16\t(1 << 28)\n#define TEGRA_APBDMA_APBSEQ_BUS_WIDTH_32\t(2 << 28)\n#define TEGRA_APBDMA_APBSEQ_BUS_WIDTH_64\t(3 << 28)\n#define TEGRA_APBDMA_APBSEQ_BUS_WIDTH_128\t(4 << 28)\n#define TEGRA_APBDMA_APBSEQ_DATA_SWAP\t\tBIT(27)\n#define TEGRA_APBDMA_APBSEQ_WRAP_WORD_1\t\t(1 << 16)\n\n \n#define TEGRA_APBDMA_CHAN_WCOUNT\t\t0x20\n\n#define TEGRA_APBDMA_CHAN_WORD_TRANSFER\t\t0x24\n\n \n#define TEGRA_APBDMA_BURST_COMPLETE_TIME\t20\n\n \n#define TEGRA_APBDMA_CHANNEL_BASE_ADD_OFFSET\t0x1000\n\n#define TEGRA_APBDMA_SLAVE_ID_INVALID\t(TEGRA_APBDMA_CSR_REQ_SEL_MASK + 1)\n\nstruct tegra_dma;\n\n \nstruct tegra_dma_chip_data {\n\tunsigned int nr_channels;\n\tunsigned int channel_reg_size;\n\tunsigned int max_dma_count;\n\tbool support_channel_pause;\n\tbool support_separate_wcount_reg;\n};\n\n \nstruct tegra_dma_channel_regs {\n\tu32 csr;\n\tu32 ahb_ptr;\n\tu32 apb_ptr;\n\tu32 ahb_seq;\n\tu32 apb_seq;\n\tu32 wcount;\n};\n\n \nstruct tegra_dma_sg_req {\n\tstruct tegra_dma_channel_regs\tch_regs;\n\tunsigned int\t\t\treq_len;\n\tbool\t\t\t\tconfigured;\n\tbool\t\t\t\tlast_sg;\n\tstruct list_head\t\tnode;\n\tstruct tegra_dma_desc\t\t*dma_desc;\n\tunsigned int\t\t\twords_xferred;\n};\n\n \nstruct tegra_dma_desc {\n\tstruct dma_async_tx_descriptor\ttxd;\n\tunsigned int\t\t\tbytes_requested;\n\tunsigned int\t\t\tbytes_transferred;\n\tenum dma_status\t\t\tdma_status;\n\tstruct list_head\t\tnode;\n\tstruct list_head\t\ttx_list;\n\tstruct list_head\t\tcb_node;\n\tunsigned int\t\t\tcb_count;\n};\n\nstruct tegra_dma_channel;\n\ntypedef void (*dma_isr_handler)(struct tegra_dma_channel *tdc,\n\t\t\t\tbool to_terminate);\n\n \nstruct tegra_dma_channel {\n\tstruct dma_chan\t\tdma_chan;\n\tchar\t\t\tname[12];\n\tbool\t\t\tconfig_init;\n\tunsigned int\t\tid;\n\tvoid __iomem\t\t*chan_addr;\n\tspinlock_t\t\tlock;\n\tbool\t\t\tbusy;\n\tstruct tegra_dma\t*tdma;\n\tbool\t\t\tcyclic;\n\n\t \n\tstruct list_head\tfree_sg_req;\n\tstruct list_head\tpending_sg_req;\n\tstruct list_head\tfree_dma_desc;\n\tstruct list_head\tcb_desc;\n\n\t \n\tdma_isr_handler\t\tisr_handler;\n\tstruct tasklet_struct\ttasklet;\n\n\t \n\tunsigned int slave_id;\n\tstruct dma_slave_config dma_sconfig;\n\tstruct tegra_dma_channel_regs channel_reg;\n\n\tstruct wait_queue_head wq;\n};\n\n \nstruct tegra_dma {\n\tstruct dma_device\t\tdma_dev;\n\tstruct device\t\t\t*dev;\n\tstruct clk\t\t\t*dma_clk;\n\tstruct reset_control\t\t*rst;\n\tspinlock_t\t\t\tglobal_lock;\n\tvoid __iomem\t\t\t*base_addr;\n\tconst struct tegra_dma_chip_data *chip_data;\n\n\t \n\tu32\t\t\t\tglobal_pause_count;\n\n\t \n\tstruct tegra_dma_channel channels[];\n};\n\nstatic inline void tdma_write(struct tegra_dma *tdma, u32 reg, u32 val)\n{\n\twritel(val, tdma->base_addr + reg);\n}\n\nstatic inline void tdc_write(struct tegra_dma_channel *tdc,\n\t\t\t     u32 reg, u32 val)\n{\n\twritel(val, tdc->chan_addr + reg);\n}\n\nstatic inline u32 tdc_read(struct tegra_dma_channel *tdc, u32 reg)\n{\n\treturn readl(tdc->chan_addr + reg);\n}\n\nstatic inline struct tegra_dma_channel *to_tegra_dma_chan(struct dma_chan *dc)\n{\n\treturn container_of(dc, struct tegra_dma_channel, dma_chan);\n}\n\nstatic inline struct tegra_dma_desc *\ntxd_to_tegra_dma_desc(struct dma_async_tx_descriptor *td)\n{\n\treturn container_of(td, struct tegra_dma_desc, txd);\n}\n\nstatic inline struct device *tdc2dev(struct tegra_dma_channel *tdc)\n{\n\treturn &tdc->dma_chan.dev->device;\n}\n\nstatic dma_cookie_t tegra_dma_tx_submit(struct dma_async_tx_descriptor *tx);\n\n \nstatic struct tegra_dma_desc *tegra_dma_desc_get(struct tegra_dma_channel *tdc)\n{\n\tstruct tegra_dma_desc *dma_desc;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&tdc->lock, flags);\n\n\t \n\tlist_for_each_entry(dma_desc, &tdc->free_dma_desc, node) {\n\t\tif (async_tx_test_ack(&dma_desc->txd) && !dma_desc->cb_count) {\n\t\t\tlist_del(&dma_desc->node);\n\t\t\tspin_unlock_irqrestore(&tdc->lock, flags);\n\t\t\tdma_desc->txd.flags = 0;\n\t\t\treturn dma_desc;\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&tdc->lock, flags);\n\n\t \n\tdma_desc = kzalloc(sizeof(*dma_desc), GFP_NOWAIT);\n\tif (!dma_desc)\n\t\treturn NULL;\n\n\tdma_async_tx_descriptor_init(&dma_desc->txd, &tdc->dma_chan);\n\tdma_desc->txd.tx_submit = tegra_dma_tx_submit;\n\tdma_desc->txd.flags = 0;\n\n\treturn dma_desc;\n}\n\nstatic void tegra_dma_desc_put(struct tegra_dma_channel *tdc,\n\t\t\t       struct tegra_dma_desc *dma_desc)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&tdc->lock, flags);\n\tif (!list_empty(&dma_desc->tx_list))\n\t\tlist_splice_init(&dma_desc->tx_list, &tdc->free_sg_req);\n\tlist_add_tail(&dma_desc->node, &tdc->free_dma_desc);\n\tspin_unlock_irqrestore(&tdc->lock, flags);\n}\n\nstatic struct tegra_dma_sg_req *\ntegra_dma_sg_req_get(struct tegra_dma_channel *tdc)\n{\n\tstruct tegra_dma_sg_req *sg_req;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&tdc->lock, flags);\n\tif (!list_empty(&tdc->free_sg_req)) {\n\t\tsg_req = list_first_entry(&tdc->free_sg_req, typeof(*sg_req),\n\t\t\t\t\t  node);\n\t\tlist_del(&sg_req->node);\n\t\tspin_unlock_irqrestore(&tdc->lock, flags);\n\t\treturn sg_req;\n\t}\n\tspin_unlock_irqrestore(&tdc->lock, flags);\n\n\tsg_req = kzalloc(sizeof(*sg_req), GFP_NOWAIT);\n\n\treturn sg_req;\n}\n\nstatic int tegra_dma_slave_config(struct dma_chan *dc,\n\t\t\t\t  struct dma_slave_config *sconfig)\n{\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(dc);\n\n\tif (!list_empty(&tdc->pending_sg_req)) {\n\t\tdev_err(tdc2dev(tdc), \"Configuration not allowed\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\tmemcpy(&tdc->dma_sconfig, sconfig, sizeof(*sconfig));\n\ttdc->config_init = true;\n\n\treturn 0;\n}\n\nstatic void tegra_dma_global_pause(struct tegra_dma_channel *tdc,\n\t\t\t\t   bool wait_for_burst_complete)\n{\n\tstruct tegra_dma *tdma = tdc->tdma;\n\n\tspin_lock(&tdma->global_lock);\n\n\tif (tdc->tdma->global_pause_count == 0) {\n\t\ttdma_write(tdma, TEGRA_APBDMA_GENERAL, 0);\n\t\tif (wait_for_burst_complete)\n\t\t\tudelay(TEGRA_APBDMA_BURST_COMPLETE_TIME);\n\t}\n\n\ttdc->tdma->global_pause_count++;\n\n\tspin_unlock(&tdma->global_lock);\n}\n\nstatic void tegra_dma_global_resume(struct tegra_dma_channel *tdc)\n{\n\tstruct tegra_dma *tdma = tdc->tdma;\n\n\tspin_lock(&tdma->global_lock);\n\n\tif (WARN_ON(tdc->tdma->global_pause_count == 0))\n\t\tgoto out;\n\n\tif (--tdc->tdma->global_pause_count == 0)\n\t\ttdma_write(tdma, TEGRA_APBDMA_GENERAL,\n\t\t\t   TEGRA_APBDMA_GENERAL_ENABLE);\n\nout:\n\tspin_unlock(&tdma->global_lock);\n}\n\nstatic void tegra_dma_pause(struct tegra_dma_channel *tdc,\n\t\t\t    bool wait_for_burst_complete)\n{\n\tstruct tegra_dma *tdma = tdc->tdma;\n\n\tif (tdma->chip_data->support_channel_pause) {\n\t\ttdc_write(tdc, TEGRA_APBDMA_CHAN_CSRE,\n\t\t\t  TEGRA_APBDMA_CHAN_CSRE_PAUSE);\n\t\tif (wait_for_burst_complete)\n\t\t\tudelay(TEGRA_APBDMA_BURST_COMPLETE_TIME);\n\t} else {\n\t\ttegra_dma_global_pause(tdc, wait_for_burst_complete);\n\t}\n}\n\nstatic void tegra_dma_resume(struct tegra_dma_channel *tdc)\n{\n\tstruct tegra_dma *tdma = tdc->tdma;\n\n\tif (tdma->chip_data->support_channel_pause)\n\t\ttdc_write(tdc, TEGRA_APBDMA_CHAN_CSRE, 0);\n\telse\n\t\ttegra_dma_global_resume(tdc);\n}\n\nstatic void tegra_dma_stop(struct tegra_dma_channel *tdc)\n{\n\tu32 csr, status;\n\n\t \n\tcsr = tdc_read(tdc, TEGRA_APBDMA_CHAN_CSR);\n\tcsr &= ~TEGRA_APBDMA_CSR_IE_EOC;\n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_CSR, csr);\n\n\t \n\tcsr &= ~TEGRA_APBDMA_CSR_ENB;\n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_CSR, csr);\n\n\t \n\tstatus = tdc_read(tdc, TEGRA_APBDMA_CHAN_STATUS);\n\tif (status & TEGRA_APBDMA_STATUS_ISE_EOC) {\n\t\tdev_dbg(tdc2dev(tdc), \"%s():clearing interrupt\\n\", __func__);\n\t\ttdc_write(tdc, TEGRA_APBDMA_CHAN_STATUS, status);\n\t}\n\ttdc->busy = false;\n}\n\nstatic void tegra_dma_start(struct tegra_dma_channel *tdc,\n\t\t\t    struct tegra_dma_sg_req *sg_req)\n{\n\tstruct tegra_dma_channel_regs *ch_regs = &sg_req->ch_regs;\n\n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_CSR, ch_regs->csr);\n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_APBSEQ, ch_regs->apb_seq);\n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_APBPTR, ch_regs->apb_ptr);\n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_AHBSEQ, ch_regs->ahb_seq);\n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_AHBPTR, ch_regs->ahb_ptr);\n\tif (tdc->tdma->chip_data->support_separate_wcount_reg)\n\t\ttdc_write(tdc, TEGRA_APBDMA_CHAN_WCOUNT, ch_regs->wcount);\n\n\t \n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_CSR,\n\t\t  ch_regs->csr | TEGRA_APBDMA_CSR_ENB);\n}\n\nstatic void tegra_dma_configure_for_next(struct tegra_dma_channel *tdc,\n\t\t\t\t\t struct tegra_dma_sg_req *nsg_req)\n{\n\tunsigned long status;\n\n\t \n\ttegra_dma_pause(tdc, false);\n\tstatus = tdc_read(tdc, TEGRA_APBDMA_CHAN_STATUS);\n\n\t \n\tif (status & TEGRA_APBDMA_STATUS_ISE_EOC) {\n\t\tdev_err(tdc2dev(tdc),\n\t\t\t\"Skipping new configuration as interrupt is pending\\n\");\n\t\ttegra_dma_resume(tdc);\n\t\treturn;\n\t}\n\n\t \n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_APBPTR, nsg_req->ch_regs.apb_ptr);\n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_AHBPTR, nsg_req->ch_regs.ahb_ptr);\n\tif (tdc->tdma->chip_data->support_separate_wcount_reg)\n\t\ttdc_write(tdc, TEGRA_APBDMA_CHAN_WCOUNT,\n\t\t\t  nsg_req->ch_regs.wcount);\n\ttdc_write(tdc, TEGRA_APBDMA_CHAN_CSR,\n\t\t  nsg_req->ch_regs.csr | TEGRA_APBDMA_CSR_ENB);\n\tnsg_req->configured = true;\n\tnsg_req->words_xferred = 0;\n\n\ttegra_dma_resume(tdc);\n}\n\nstatic void tdc_start_head_req(struct tegra_dma_channel *tdc)\n{\n\tstruct tegra_dma_sg_req *sg_req;\n\n\tsg_req = list_first_entry(&tdc->pending_sg_req, typeof(*sg_req), node);\n\ttegra_dma_start(tdc, sg_req);\n\tsg_req->configured = true;\n\tsg_req->words_xferred = 0;\n\ttdc->busy = true;\n}\n\nstatic void tdc_configure_next_head_desc(struct tegra_dma_channel *tdc)\n{\n\tstruct tegra_dma_sg_req *hsgreq, *hnsgreq;\n\n\thsgreq = list_first_entry(&tdc->pending_sg_req, typeof(*hsgreq), node);\n\tif (!list_is_last(&hsgreq->node, &tdc->pending_sg_req)) {\n\t\thnsgreq = list_first_entry(&hsgreq->node, typeof(*hnsgreq),\n\t\t\t\t\t   node);\n\t\ttegra_dma_configure_for_next(tdc, hnsgreq);\n\t}\n}\n\nstatic inline unsigned int\nget_current_xferred_count(struct tegra_dma_channel *tdc,\n\t\t\t  struct tegra_dma_sg_req *sg_req,\n\t\t\t  unsigned long status)\n{\n\treturn sg_req->req_len - (status & TEGRA_APBDMA_STATUS_COUNT_MASK) - 4;\n}\n\nstatic void tegra_dma_abort_all(struct tegra_dma_channel *tdc)\n{\n\tstruct tegra_dma_desc *dma_desc;\n\tstruct tegra_dma_sg_req *sgreq;\n\n\twhile (!list_empty(&tdc->pending_sg_req)) {\n\t\tsgreq = list_first_entry(&tdc->pending_sg_req, typeof(*sgreq),\n\t\t\t\t\t node);\n\t\tlist_move_tail(&sgreq->node, &tdc->free_sg_req);\n\t\tif (sgreq->last_sg) {\n\t\t\tdma_desc = sgreq->dma_desc;\n\t\t\tdma_desc->dma_status = DMA_ERROR;\n\t\t\tlist_add_tail(&dma_desc->node, &tdc->free_dma_desc);\n\n\t\t\t \n\t\t\tif (!dma_desc->cb_count)\n\t\t\t\tlist_add_tail(&dma_desc->cb_node,\n\t\t\t\t\t      &tdc->cb_desc);\n\t\t\tdma_desc->cb_count++;\n\t\t}\n\t}\n\ttdc->isr_handler = NULL;\n}\n\nstatic bool handle_continuous_head_request(struct tegra_dma_channel *tdc,\n\t\t\t\t\t   bool to_terminate)\n{\n\tstruct tegra_dma_sg_req *hsgreq;\n\n\t \n\thsgreq = list_first_entry(&tdc->pending_sg_req, typeof(*hsgreq), node);\n\tif (!hsgreq->configured) {\n\t\ttegra_dma_stop(tdc);\n\t\tpm_runtime_put(tdc->tdma->dev);\n\t\tdev_err(tdc2dev(tdc), \"DMA transfer underflow, aborting DMA\\n\");\n\t\ttegra_dma_abort_all(tdc);\n\t\treturn false;\n\t}\n\n\t \n\tif (!to_terminate)\n\t\ttdc_configure_next_head_desc(tdc);\n\n\treturn true;\n}\n\nstatic void handle_once_dma_done(struct tegra_dma_channel *tdc,\n\t\t\t\t bool to_terminate)\n{\n\tstruct tegra_dma_desc *dma_desc;\n\tstruct tegra_dma_sg_req *sgreq;\n\n\ttdc->busy = false;\n\tsgreq = list_first_entry(&tdc->pending_sg_req, typeof(*sgreq), node);\n\tdma_desc = sgreq->dma_desc;\n\tdma_desc->bytes_transferred += sgreq->req_len;\n\n\tlist_del(&sgreq->node);\n\tif (sgreq->last_sg) {\n\t\tdma_desc->dma_status = DMA_COMPLETE;\n\t\tdma_cookie_complete(&dma_desc->txd);\n\t\tif (!dma_desc->cb_count)\n\t\t\tlist_add_tail(&dma_desc->cb_node, &tdc->cb_desc);\n\t\tdma_desc->cb_count++;\n\t\tlist_add_tail(&dma_desc->node, &tdc->free_dma_desc);\n\t}\n\tlist_add_tail(&sgreq->node, &tdc->free_sg_req);\n\n\t \n\tif (to_terminate)\n\t\treturn;\n\n\tif (list_empty(&tdc->pending_sg_req)) {\n\t\tpm_runtime_put(tdc->tdma->dev);\n\t\treturn;\n\t}\n\n\ttdc_start_head_req(tdc);\n}\n\nstatic void handle_cont_sngl_cycle_dma_done(struct tegra_dma_channel *tdc,\n\t\t\t\t\t    bool to_terminate)\n{\n\tstruct tegra_dma_desc *dma_desc;\n\tstruct tegra_dma_sg_req *sgreq;\n\tbool st;\n\n\tsgreq = list_first_entry(&tdc->pending_sg_req, typeof(*sgreq), node);\n\tdma_desc = sgreq->dma_desc;\n\t \n\tdma_desc->bytes_transferred =\n\t\t(dma_desc->bytes_transferred + sgreq->req_len) %\n\t\tdma_desc->bytes_requested;\n\n\t \n\tif (!dma_desc->cb_count)\n\t\tlist_add_tail(&dma_desc->cb_node, &tdc->cb_desc);\n\tdma_desc->cb_count++;\n\n\tsgreq->words_xferred = 0;\n\n\t \n\tif (!list_is_last(&sgreq->node, &tdc->pending_sg_req)) {\n\t\tlist_move_tail(&sgreq->node, &tdc->pending_sg_req);\n\t\tsgreq->configured = false;\n\t\tst = handle_continuous_head_request(tdc, to_terminate);\n\t\tif (!st)\n\t\t\tdma_desc->dma_status = DMA_ERROR;\n\t}\n}\n\nstatic void tegra_dma_tasklet(struct tasklet_struct *t)\n{\n\tstruct tegra_dma_channel *tdc = from_tasklet(tdc, t, tasklet);\n\tstruct dmaengine_desc_callback cb;\n\tstruct tegra_dma_desc *dma_desc;\n\tunsigned int cb_count;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&tdc->lock, flags);\n\twhile (!list_empty(&tdc->cb_desc)) {\n\t\tdma_desc = list_first_entry(&tdc->cb_desc, typeof(*dma_desc),\n\t\t\t\t\t    cb_node);\n\t\tlist_del(&dma_desc->cb_node);\n\t\tdmaengine_desc_get_callback(&dma_desc->txd, &cb);\n\t\tcb_count = dma_desc->cb_count;\n\t\tdma_desc->cb_count = 0;\n\t\ttrace_tegra_dma_complete_cb(&tdc->dma_chan, cb_count,\n\t\t\t\t\t    cb.callback);\n\t\tspin_unlock_irqrestore(&tdc->lock, flags);\n\t\twhile (cb_count--)\n\t\t\tdmaengine_desc_callback_invoke(&cb, NULL);\n\t\tspin_lock_irqsave(&tdc->lock, flags);\n\t}\n\tspin_unlock_irqrestore(&tdc->lock, flags);\n}\n\nstatic irqreturn_t tegra_dma_isr(int irq, void *dev_id)\n{\n\tstruct tegra_dma_channel *tdc = dev_id;\n\tu32 status;\n\n\tspin_lock(&tdc->lock);\n\n\ttrace_tegra_dma_isr(&tdc->dma_chan, irq);\n\tstatus = tdc_read(tdc, TEGRA_APBDMA_CHAN_STATUS);\n\tif (status & TEGRA_APBDMA_STATUS_ISE_EOC) {\n\t\ttdc_write(tdc, TEGRA_APBDMA_CHAN_STATUS, status);\n\t\ttdc->isr_handler(tdc, false);\n\t\ttasklet_schedule(&tdc->tasklet);\n\t\twake_up_all(&tdc->wq);\n\t\tspin_unlock(&tdc->lock);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tspin_unlock(&tdc->lock);\n\tdev_info(tdc2dev(tdc), \"Interrupt already served status 0x%08x\\n\",\n\t\t status);\n\n\treturn IRQ_NONE;\n}\n\nstatic dma_cookie_t tegra_dma_tx_submit(struct dma_async_tx_descriptor *txd)\n{\n\tstruct tegra_dma_desc *dma_desc = txd_to_tegra_dma_desc(txd);\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(txd->chan);\n\tunsigned long flags;\n\tdma_cookie_t cookie;\n\n\tspin_lock_irqsave(&tdc->lock, flags);\n\tdma_desc->dma_status = DMA_IN_PROGRESS;\n\tcookie = dma_cookie_assign(&dma_desc->txd);\n\tlist_splice_tail_init(&dma_desc->tx_list, &tdc->pending_sg_req);\n\tspin_unlock_irqrestore(&tdc->lock, flags);\n\n\treturn cookie;\n}\n\nstatic void tegra_dma_issue_pending(struct dma_chan *dc)\n{\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(dc);\n\tunsigned long flags;\n\tint err;\n\n\tspin_lock_irqsave(&tdc->lock, flags);\n\tif (list_empty(&tdc->pending_sg_req)) {\n\t\tdev_err(tdc2dev(tdc), \"No DMA request\\n\");\n\t\tgoto end;\n\t}\n\tif (!tdc->busy) {\n\t\terr = pm_runtime_resume_and_get(tdc->tdma->dev);\n\t\tif (err < 0) {\n\t\t\tdev_err(tdc2dev(tdc), \"Failed to enable DMA\\n\");\n\t\t\tgoto end;\n\t\t}\n\n\t\ttdc_start_head_req(tdc);\n\n\t\t \n\t\tif (tdc->cyclic) {\n\t\t\t \n\t\t\tudelay(TEGRA_APBDMA_BURST_COMPLETE_TIME);\n\t\t\ttdc_configure_next_head_desc(tdc);\n\t\t}\n\t}\nend:\n\tspin_unlock_irqrestore(&tdc->lock, flags);\n}\n\nstatic int tegra_dma_terminate_all(struct dma_chan *dc)\n{\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(dc);\n\tstruct tegra_dma_desc *dma_desc;\n\tstruct tegra_dma_sg_req *sgreq;\n\tunsigned long flags;\n\tu32 status, wcount;\n\tbool was_busy;\n\n\tspin_lock_irqsave(&tdc->lock, flags);\n\n\tif (!tdc->busy)\n\t\tgoto skip_dma_stop;\n\n\t \n\ttegra_dma_pause(tdc, true);\n\n\tstatus = tdc_read(tdc, TEGRA_APBDMA_CHAN_STATUS);\n\tif (status & TEGRA_APBDMA_STATUS_ISE_EOC) {\n\t\tdev_dbg(tdc2dev(tdc), \"%s():handling isr\\n\", __func__);\n\t\ttdc->isr_handler(tdc, true);\n\t\tstatus = tdc_read(tdc, TEGRA_APBDMA_CHAN_STATUS);\n\t}\n\tif (tdc->tdma->chip_data->support_separate_wcount_reg)\n\t\twcount = tdc_read(tdc, TEGRA_APBDMA_CHAN_WORD_TRANSFER);\n\telse\n\t\twcount = status;\n\n\twas_busy = tdc->busy;\n\ttegra_dma_stop(tdc);\n\n\tif (!list_empty(&tdc->pending_sg_req) && was_busy) {\n\t\tsgreq = list_first_entry(&tdc->pending_sg_req, typeof(*sgreq),\n\t\t\t\t\t node);\n\t\tsgreq->dma_desc->bytes_transferred +=\n\t\t\t\tget_current_xferred_count(tdc, sgreq, wcount);\n\t}\n\ttegra_dma_resume(tdc);\n\n\tpm_runtime_put(tdc->tdma->dev);\n\twake_up_all(&tdc->wq);\n\nskip_dma_stop:\n\ttegra_dma_abort_all(tdc);\n\n\twhile (!list_empty(&tdc->cb_desc)) {\n\t\tdma_desc = list_first_entry(&tdc->cb_desc, typeof(*dma_desc),\n\t\t\t\t\t    cb_node);\n\t\tlist_del(&dma_desc->cb_node);\n\t\tdma_desc->cb_count = 0;\n\t}\n\tspin_unlock_irqrestore(&tdc->lock, flags);\n\n\treturn 0;\n}\n\nstatic bool tegra_dma_eoc_interrupt_deasserted(struct tegra_dma_channel *tdc)\n{\n\tunsigned long flags;\n\tu32 status;\n\n\tspin_lock_irqsave(&tdc->lock, flags);\n\tstatus = tdc_read(tdc, TEGRA_APBDMA_CHAN_STATUS);\n\tspin_unlock_irqrestore(&tdc->lock, flags);\n\n\treturn !(status & TEGRA_APBDMA_STATUS_ISE_EOC);\n}\n\nstatic void tegra_dma_synchronize(struct dma_chan *dc)\n{\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(dc);\n\tint err;\n\n\terr = pm_runtime_resume_and_get(tdc->tdma->dev);\n\tif (err < 0) {\n\t\tdev_err(tdc2dev(tdc), \"Failed to synchronize DMA: %d\\n\", err);\n\t\treturn;\n\t}\n\n\t \n\twait_event(tdc->wq, tegra_dma_eoc_interrupt_deasserted(tdc));\n\n\ttasklet_kill(&tdc->tasklet);\n\n\tpm_runtime_put(tdc->tdma->dev);\n}\n\nstatic unsigned int tegra_dma_sg_bytes_xferred(struct tegra_dma_channel *tdc,\n\t\t\t\t\t       struct tegra_dma_sg_req *sg_req)\n{\n\tu32 status, wcount = 0;\n\n\tif (!list_is_first(&sg_req->node, &tdc->pending_sg_req))\n\t\treturn 0;\n\n\tif (tdc->tdma->chip_data->support_separate_wcount_reg)\n\t\twcount = tdc_read(tdc, TEGRA_APBDMA_CHAN_WORD_TRANSFER);\n\n\tstatus = tdc_read(tdc, TEGRA_APBDMA_CHAN_STATUS);\n\n\tif (!tdc->tdma->chip_data->support_separate_wcount_reg)\n\t\twcount = status;\n\n\tif (status & TEGRA_APBDMA_STATUS_ISE_EOC)\n\t\treturn sg_req->req_len;\n\n\twcount = get_current_xferred_count(tdc, sg_req, wcount);\n\n\tif (!wcount) {\n\t\t \n\t\tif (sg_req->words_xferred)\n\t\t\twcount = sg_req->req_len - 4;\n\n\t} else if (wcount < sg_req->words_xferred) {\n\t\t \n\t\tWARN_ON_ONCE(1);\n\n\t\twcount = sg_req->req_len - 4;\n\t} else {\n\t\tsg_req->words_xferred = wcount;\n\t}\n\n\treturn wcount;\n}\n\nstatic enum dma_status tegra_dma_tx_status(struct dma_chan *dc,\n\t\t\t\t\t   dma_cookie_t cookie,\n\t\t\t\t\t   struct dma_tx_state *txstate)\n{\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(dc);\n\tstruct tegra_dma_desc *dma_desc;\n\tstruct tegra_dma_sg_req *sg_req;\n\tenum dma_status ret;\n\tunsigned long flags;\n\tunsigned int residual;\n\tunsigned int bytes = 0;\n\n\tret = dma_cookie_status(dc, cookie, txstate);\n\tif (ret == DMA_COMPLETE)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&tdc->lock, flags);\n\n\t \n\tlist_for_each_entry(dma_desc, &tdc->free_dma_desc, node) {\n\t\tif (dma_desc->txd.cookie == cookie) {\n\t\t\tret = dma_desc->dma_status;\n\t\t\tgoto found;\n\t\t}\n\t}\n\n\t \n\tlist_for_each_entry(sg_req, &tdc->pending_sg_req, node) {\n\t\tdma_desc = sg_req->dma_desc;\n\t\tif (dma_desc->txd.cookie == cookie) {\n\t\t\tbytes = tegra_dma_sg_bytes_xferred(tdc, sg_req);\n\t\t\tret = dma_desc->dma_status;\n\t\t\tgoto found;\n\t\t}\n\t}\n\n\tdev_dbg(tdc2dev(tdc), \"cookie %d not found\\n\", cookie);\n\tdma_desc = NULL;\n\nfound:\n\tif (dma_desc && txstate) {\n\t\tresidual = dma_desc->bytes_requested -\n\t\t\t   ((dma_desc->bytes_transferred + bytes) %\n\t\t\t    dma_desc->bytes_requested);\n\t\tdma_set_residue(txstate, residual);\n\t}\n\n\ttrace_tegra_dma_tx_status(&tdc->dma_chan, cookie, txstate);\n\tspin_unlock_irqrestore(&tdc->lock, flags);\n\n\treturn ret;\n}\n\nstatic inline unsigned int get_bus_width(struct tegra_dma_channel *tdc,\n\t\t\t\t\t enum dma_slave_buswidth slave_bw)\n{\n\tswitch (slave_bw) {\n\tcase DMA_SLAVE_BUSWIDTH_1_BYTE:\n\t\treturn TEGRA_APBDMA_APBSEQ_BUS_WIDTH_8;\n\tcase DMA_SLAVE_BUSWIDTH_2_BYTES:\n\t\treturn TEGRA_APBDMA_APBSEQ_BUS_WIDTH_16;\n\tcase DMA_SLAVE_BUSWIDTH_4_BYTES:\n\t\treturn TEGRA_APBDMA_APBSEQ_BUS_WIDTH_32;\n\tcase DMA_SLAVE_BUSWIDTH_8_BYTES:\n\t\treturn TEGRA_APBDMA_APBSEQ_BUS_WIDTH_64;\n\tdefault:\n\t\tdev_warn(tdc2dev(tdc),\n\t\t\t \"slave bw is not supported, using 32bits\\n\");\n\t\treturn TEGRA_APBDMA_APBSEQ_BUS_WIDTH_32;\n\t}\n}\n\nstatic inline unsigned int get_burst_size(struct tegra_dma_channel *tdc,\n\t\t\t\t\t  u32 burst_size,\n\t\t\t\t\t  enum dma_slave_buswidth slave_bw,\n\t\t\t\t\t  u32 len)\n{\n\tunsigned int burst_byte, burst_ahb_width;\n\n\t \n\tburst_byte = burst_size * slave_bw;\n\tburst_ahb_width = burst_byte / 4;\n\n\t \n\tif (!burst_ahb_width) {\n\t\tif (len & 0xF)\n\t\t\treturn TEGRA_APBDMA_AHBSEQ_BURST_1;\n\t\telse if ((len >> 4) & 0x1)\n\t\t\treturn TEGRA_APBDMA_AHBSEQ_BURST_4;\n\t\telse\n\t\t\treturn TEGRA_APBDMA_AHBSEQ_BURST_8;\n\t}\n\tif (burst_ahb_width < 4)\n\t\treturn TEGRA_APBDMA_AHBSEQ_BURST_1;\n\telse if (burst_ahb_width < 8)\n\t\treturn TEGRA_APBDMA_AHBSEQ_BURST_4;\n\telse\n\t\treturn TEGRA_APBDMA_AHBSEQ_BURST_8;\n}\n\nstatic int get_transfer_param(struct tegra_dma_channel *tdc,\n\t\t\t      enum dma_transfer_direction direction,\n\t\t\t      u32 *apb_addr,\n\t\t\t      u32 *apb_seq,\n\t\t\t      u32 *csr,\n\t\t\t      unsigned int *burst_size,\n\t\t\t      enum dma_slave_buswidth *slave_bw)\n{\n\tswitch (direction) {\n\tcase DMA_MEM_TO_DEV:\n\t\t*apb_addr = tdc->dma_sconfig.dst_addr;\n\t\t*apb_seq = get_bus_width(tdc, tdc->dma_sconfig.dst_addr_width);\n\t\t*burst_size = tdc->dma_sconfig.dst_maxburst;\n\t\t*slave_bw = tdc->dma_sconfig.dst_addr_width;\n\t\t*csr = TEGRA_APBDMA_CSR_DIR;\n\t\treturn 0;\n\n\tcase DMA_DEV_TO_MEM:\n\t\t*apb_addr = tdc->dma_sconfig.src_addr;\n\t\t*apb_seq = get_bus_width(tdc, tdc->dma_sconfig.src_addr_width);\n\t\t*burst_size = tdc->dma_sconfig.src_maxburst;\n\t\t*slave_bw = tdc->dma_sconfig.src_addr_width;\n\t\t*csr = 0;\n\t\treturn 0;\n\n\tdefault:\n\t\tdev_err(tdc2dev(tdc), \"DMA direction is not supported\\n\");\n\t\tbreak;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic void tegra_dma_prep_wcount(struct tegra_dma_channel *tdc,\n\t\t\t\t  struct tegra_dma_channel_regs *ch_regs,\n\t\t\t\t  u32 len)\n{\n\tu32 len_field = (len - 4) & 0xFFFC;\n\n\tif (tdc->tdma->chip_data->support_separate_wcount_reg)\n\t\tch_regs->wcount = len_field;\n\telse\n\t\tch_regs->csr |= len_field;\n}\n\nstatic struct dma_async_tx_descriptor *\ntegra_dma_prep_slave_sg(struct dma_chan *dc,\n\t\t\tstruct scatterlist *sgl,\n\t\t\tunsigned int sg_len,\n\t\t\tenum dma_transfer_direction direction,\n\t\t\tunsigned long flags,\n\t\t\tvoid *context)\n{\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(dc);\n\tstruct tegra_dma_sg_req *sg_req = NULL;\n\tu32 csr, ahb_seq, apb_ptr, apb_seq;\n\tenum dma_slave_buswidth slave_bw;\n\tstruct tegra_dma_desc *dma_desc;\n\tstruct list_head req_list;\n\tstruct scatterlist *sg;\n\tunsigned int burst_size;\n\tunsigned int i;\n\n\tif (!tdc->config_init) {\n\t\tdev_err(tdc2dev(tdc), \"DMA channel is not configured\\n\");\n\t\treturn NULL;\n\t}\n\tif (sg_len < 1) {\n\t\tdev_err(tdc2dev(tdc), \"Invalid segment length %d\\n\", sg_len);\n\t\treturn NULL;\n\t}\n\n\tif (get_transfer_param(tdc, direction, &apb_ptr, &apb_seq, &csr,\n\t\t\t       &burst_size, &slave_bw) < 0)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&req_list);\n\n\tahb_seq = TEGRA_APBDMA_AHBSEQ_INTR_ENB;\n\tahb_seq |= TEGRA_APBDMA_AHBSEQ_WRAP_NONE <<\n\t\t\t\t\tTEGRA_APBDMA_AHBSEQ_WRAP_SHIFT;\n\tahb_seq |= TEGRA_APBDMA_AHBSEQ_BUS_WIDTH_32;\n\n\tcsr |= TEGRA_APBDMA_CSR_ONCE;\n\n\tif (tdc->slave_id != TEGRA_APBDMA_SLAVE_ID_INVALID) {\n\t\tcsr |= TEGRA_APBDMA_CSR_FLOW;\n\t\tcsr |= tdc->slave_id << TEGRA_APBDMA_CSR_REQ_SEL_SHIFT;\n\t}\n\n\tif (flags & DMA_PREP_INTERRUPT) {\n\t\tcsr |= TEGRA_APBDMA_CSR_IE_EOC;\n\t} else {\n\t\tWARN_ON_ONCE(1);\n\t\treturn NULL;\n\t}\n\n\tapb_seq |= TEGRA_APBDMA_APBSEQ_WRAP_WORD_1;\n\n\tdma_desc = tegra_dma_desc_get(tdc);\n\tif (!dma_desc) {\n\t\tdev_err(tdc2dev(tdc), \"DMA descriptors not available\\n\");\n\t\treturn NULL;\n\t}\n\tINIT_LIST_HEAD(&dma_desc->tx_list);\n\tINIT_LIST_HEAD(&dma_desc->cb_node);\n\tdma_desc->cb_count = 0;\n\tdma_desc->bytes_requested = 0;\n\tdma_desc->bytes_transferred = 0;\n\tdma_desc->dma_status = DMA_IN_PROGRESS;\n\n\t \n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tu32 len, mem;\n\n\t\tmem = sg_dma_address(sg);\n\t\tlen = sg_dma_len(sg);\n\n\t\tif ((len & 3) || (mem & 3) ||\n\t\t    len > tdc->tdma->chip_data->max_dma_count) {\n\t\t\tdev_err(tdc2dev(tdc),\n\t\t\t\t\"DMA length/memory address is not supported\\n\");\n\t\t\ttegra_dma_desc_put(tdc, dma_desc);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tsg_req = tegra_dma_sg_req_get(tdc);\n\t\tif (!sg_req) {\n\t\t\tdev_err(tdc2dev(tdc), \"DMA sg-req not available\\n\");\n\t\t\ttegra_dma_desc_put(tdc, dma_desc);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tahb_seq |= get_burst_size(tdc, burst_size, slave_bw, len);\n\t\tdma_desc->bytes_requested += len;\n\n\t\tsg_req->ch_regs.apb_ptr = apb_ptr;\n\t\tsg_req->ch_regs.ahb_ptr = mem;\n\t\tsg_req->ch_regs.csr = csr;\n\t\ttegra_dma_prep_wcount(tdc, &sg_req->ch_regs, len);\n\t\tsg_req->ch_regs.apb_seq = apb_seq;\n\t\tsg_req->ch_regs.ahb_seq = ahb_seq;\n\t\tsg_req->configured = false;\n\t\tsg_req->last_sg = false;\n\t\tsg_req->dma_desc = dma_desc;\n\t\tsg_req->req_len = len;\n\n\t\tlist_add_tail(&sg_req->node, &dma_desc->tx_list);\n\t}\n\tsg_req->last_sg = true;\n\tif (flags & DMA_CTRL_ACK)\n\t\tdma_desc->txd.flags = DMA_CTRL_ACK;\n\n\t \n\tif (!tdc->isr_handler) {\n\t\ttdc->isr_handler = handle_once_dma_done;\n\t\ttdc->cyclic = false;\n\t} else {\n\t\tif (tdc->cyclic) {\n\t\t\tdev_err(tdc2dev(tdc), \"DMA configured in cyclic mode\\n\");\n\t\t\ttegra_dma_desc_put(tdc, dma_desc);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\treturn &dma_desc->txd;\n}\n\nstatic struct dma_async_tx_descriptor *\ntegra_dma_prep_dma_cyclic(struct dma_chan *dc, dma_addr_t buf_addr,\n\t\t\t  size_t buf_len,\n\t\t\t  size_t period_len,\n\t\t\t  enum dma_transfer_direction direction,\n\t\t\t  unsigned long flags)\n{\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(dc);\n\tstruct tegra_dma_sg_req *sg_req = NULL;\n\tu32 csr, ahb_seq, apb_ptr, apb_seq;\n\tenum dma_slave_buswidth slave_bw;\n\tstruct tegra_dma_desc *dma_desc;\n\tdma_addr_t mem = buf_addr;\n\tunsigned int burst_size;\n\tsize_t len, remain_len;\n\n\tif (!buf_len || !period_len) {\n\t\tdev_err(tdc2dev(tdc), \"Invalid buffer/period len\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!tdc->config_init) {\n\t\tdev_err(tdc2dev(tdc), \"DMA slave is not configured\\n\");\n\t\treturn NULL;\n\t}\n\n\t \n\tif (tdc->busy) {\n\t\tdev_err(tdc2dev(tdc), \"Request not allowed when DMA running\\n\");\n\t\treturn NULL;\n\t}\n\n\t \n\tif (buf_len % period_len) {\n\t\tdev_err(tdc2dev(tdc), \"buf_len is not multiple of period_len\\n\");\n\t\treturn NULL;\n\t}\n\n\tlen = period_len;\n\tif ((len & 3) || (buf_addr & 3) ||\n\t    len > tdc->tdma->chip_data->max_dma_count) {\n\t\tdev_err(tdc2dev(tdc), \"Req len/mem address is not correct\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (get_transfer_param(tdc, direction, &apb_ptr, &apb_seq, &csr,\n\t\t\t       &burst_size, &slave_bw) < 0)\n\t\treturn NULL;\n\n\tahb_seq = TEGRA_APBDMA_AHBSEQ_INTR_ENB;\n\tahb_seq |= TEGRA_APBDMA_AHBSEQ_WRAP_NONE <<\n\t\t\t\t\tTEGRA_APBDMA_AHBSEQ_WRAP_SHIFT;\n\tahb_seq |= TEGRA_APBDMA_AHBSEQ_BUS_WIDTH_32;\n\n\tif (tdc->slave_id != TEGRA_APBDMA_SLAVE_ID_INVALID) {\n\t\tcsr |= TEGRA_APBDMA_CSR_FLOW;\n\t\tcsr |= tdc->slave_id << TEGRA_APBDMA_CSR_REQ_SEL_SHIFT;\n\t}\n\n\tif (flags & DMA_PREP_INTERRUPT) {\n\t\tcsr |= TEGRA_APBDMA_CSR_IE_EOC;\n\t} else {\n\t\tWARN_ON_ONCE(1);\n\t\treturn NULL;\n\t}\n\n\tapb_seq |= TEGRA_APBDMA_APBSEQ_WRAP_WORD_1;\n\n\tdma_desc = tegra_dma_desc_get(tdc);\n\tif (!dma_desc) {\n\t\tdev_err(tdc2dev(tdc), \"not enough descriptors available\\n\");\n\t\treturn NULL;\n\t}\n\n\tINIT_LIST_HEAD(&dma_desc->tx_list);\n\tINIT_LIST_HEAD(&dma_desc->cb_node);\n\tdma_desc->cb_count = 0;\n\n\tdma_desc->bytes_transferred = 0;\n\tdma_desc->bytes_requested = buf_len;\n\tremain_len = buf_len;\n\n\t \n\twhile (remain_len) {\n\t\tsg_req = tegra_dma_sg_req_get(tdc);\n\t\tif (!sg_req) {\n\t\t\tdev_err(tdc2dev(tdc), \"DMA sg-req not available\\n\");\n\t\t\ttegra_dma_desc_put(tdc, dma_desc);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tahb_seq |= get_burst_size(tdc, burst_size, slave_bw, len);\n\t\tsg_req->ch_regs.apb_ptr = apb_ptr;\n\t\tsg_req->ch_regs.ahb_ptr = mem;\n\t\tsg_req->ch_regs.csr = csr;\n\t\ttegra_dma_prep_wcount(tdc, &sg_req->ch_regs, len);\n\t\tsg_req->ch_regs.apb_seq = apb_seq;\n\t\tsg_req->ch_regs.ahb_seq = ahb_seq;\n\t\tsg_req->configured = false;\n\t\tsg_req->last_sg = false;\n\t\tsg_req->dma_desc = dma_desc;\n\t\tsg_req->req_len = len;\n\n\t\tlist_add_tail(&sg_req->node, &dma_desc->tx_list);\n\t\tremain_len -= len;\n\t\tmem += len;\n\t}\n\tsg_req->last_sg = true;\n\tif (flags & DMA_CTRL_ACK)\n\t\tdma_desc->txd.flags = DMA_CTRL_ACK;\n\n\t \n\tif (!tdc->isr_handler) {\n\t\ttdc->isr_handler = handle_cont_sngl_cycle_dma_done;\n\t\ttdc->cyclic = true;\n\t} else {\n\t\tif (!tdc->cyclic) {\n\t\t\tdev_err(tdc2dev(tdc), \"DMA configuration conflict\\n\");\n\t\t\ttegra_dma_desc_put(tdc, dma_desc);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\treturn &dma_desc->txd;\n}\n\nstatic int tegra_dma_alloc_chan_resources(struct dma_chan *dc)\n{\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(dc);\n\n\tdma_cookie_init(&tdc->dma_chan);\n\n\treturn 0;\n}\n\nstatic void tegra_dma_free_chan_resources(struct dma_chan *dc)\n{\n\tstruct tegra_dma_channel *tdc = to_tegra_dma_chan(dc);\n\tstruct tegra_dma_desc *dma_desc;\n\tstruct tegra_dma_sg_req *sg_req;\n\tstruct list_head dma_desc_list;\n\tstruct list_head sg_req_list;\n\n\tINIT_LIST_HEAD(&dma_desc_list);\n\tINIT_LIST_HEAD(&sg_req_list);\n\n\tdev_dbg(tdc2dev(tdc), \"Freeing channel %d\\n\", tdc->id);\n\n\ttegra_dma_terminate_all(dc);\n\ttasklet_kill(&tdc->tasklet);\n\n\tlist_splice_init(&tdc->pending_sg_req, &sg_req_list);\n\tlist_splice_init(&tdc->free_sg_req, &sg_req_list);\n\tlist_splice_init(&tdc->free_dma_desc, &dma_desc_list);\n\tINIT_LIST_HEAD(&tdc->cb_desc);\n\ttdc->config_init = false;\n\ttdc->isr_handler = NULL;\n\n\twhile (!list_empty(&dma_desc_list)) {\n\t\tdma_desc = list_first_entry(&dma_desc_list, typeof(*dma_desc),\n\t\t\t\t\t    node);\n\t\tlist_del(&dma_desc->node);\n\t\tkfree(dma_desc);\n\t}\n\n\twhile (!list_empty(&sg_req_list)) {\n\t\tsg_req = list_first_entry(&sg_req_list, typeof(*sg_req), node);\n\t\tlist_del(&sg_req->node);\n\t\tkfree(sg_req);\n\t}\n\n\ttdc->slave_id = TEGRA_APBDMA_SLAVE_ID_INVALID;\n}\n\nstatic struct dma_chan *tegra_dma_of_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t\t   struct of_dma *ofdma)\n{\n\tstruct tegra_dma *tdma = ofdma->of_dma_data;\n\tstruct tegra_dma_channel *tdc;\n\tstruct dma_chan *chan;\n\n\tif (dma_spec->args[0] > TEGRA_APBDMA_CSR_REQ_SEL_MASK) {\n\t\tdev_err(tdma->dev, \"Invalid slave id: %d\\n\", dma_spec->args[0]);\n\t\treturn NULL;\n\t}\n\n\tchan = dma_get_any_slave_channel(&tdma->dma_dev);\n\tif (!chan)\n\t\treturn NULL;\n\n\ttdc = to_tegra_dma_chan(chan);\n\ttdc->slave_id = dma_spec->args[0];\n\n\treturn chan;\n}\n\n \nstatic const struct tegra_dma_chip_data tegra20_dma_chip_data = {\n\t.nr_channels\t\t= 16,\n\t.channel_reg_size\t= 0x20,\n\t.max_dma_count\t\t= 1024UL * 64,\n\t.support_channel_pause\t= false,\n\t.support_separate_wcount_reg = false,\n};\n\n \nstatic const struct tegra_dma_chip_data tegra30_dma_chip_data = {\n\t.nr_channels\t\t= 32,\n\t.channel_reg_size\t= 0x20,\n\t.max_dma_count\t\t= 1024UL * 64,\n\t.support_channel_pause\t= false,\n\t.support_separate_wcount_reg = false,\n};\n\n \nstatic const struct tegra_dma_chip_data tegra114_dma_chip_data = {\n\t.nr_channels\t\t= 32,\n\t.channel_reg_size\t= 0x20,\n\t.max_dma_count\t\t= 1024UL * 64,\n\t.support_channel_pause\t= true,\n\t.support_separate_wcount_reg = false,\n};\n\n \nstatic const struct tegra_dma_chip_data tegra148_dma_chip_data = {\n\t.nr_channels\t\t= 32,\n\t.channel_reg_size\t= 0x40,\n\t.max_dma_count\t\t= 1024UL * 64,\n\t.support_channel_pause\t= true,\n\t.support_separate_wcount_reg = true,\n};\n\nstatic int tegra_dma_init_hw(struct tegra_dma *tdma)\n{\n\tint err;\n\n\terr = reset_control_assert(tdma->rst);\n\tif (err) {\n\t\tdev_err(tdma->dev, \"failed to assert reset: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = clk_enable(tdma->dma_clk);\n\tif (err) {\n\t\tdev_err(tdma->dev, \"failed to enable clk: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\t \n\tudelay(2);\n\treset_control_deassert(tdma->rst);\n\n\t \n\ttdma_write(tdma, TEGRA_APBDMA_GENERAL, TEGRA_APBDMA_GENERAL_ENABLE);\n\ttdma_write(tdma, TEGRA_APBDMA_CONTROL, 0);\n\ttdma_write(tdma, TEGRA_APBDMA_IRQ_MASK_SET, 0xFFFFFFFF);\n\n\tclk_disable(tdma->dma_clk);\n\n\treturn 0;\n}\n\nstatic int tegra_dma_probe(struct platform_device *pdev)\n{\n\tconst struct tegra_dma_chip_data *cdata;\n\tstruct tegra_dma *tdma;\n\tunsigned int i;\n\tsize_t size;\n\tint ret;\n\n\tcdata = of_device_get_match_data(&pdev->dev);\n\tsize = struct_size(tdma, channels, cdata->nr_channels);\n\n\ttdma = devm_kzalloc(&pdev->dev, size, GFP_KERNEL);\n\tif (!tdma)\n\t\treturn -ENOMEM;\n\n\ttdma->dev = &pdev->dev;\n\ttdma->chip_data = cdata;\n\tplatform_set_drvdata(pdev, tdma);\n\n\ttdma->base_addr = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(tdma->base_addr))\n\t\treturn PTR_ERR(tdma->base_addr);\n\n\ttdma->dma_clk = devm_clk_get(&pdev->dev, NULL);\n\tif (IS_ERR(tdma->dma_clk)) {\n\t\tdev_err(&pdev->dev, \"Error: Missing controller clock\\n\");\n\t\treturn PTR_ERR(tdma->dma_clk);\n\t}\n\n\ttdma->rst = devm_reset_control_get(&pdev->dev, \"dma\");\n\tif (IS_ERR(tdma->rst)) {\n\t\tdev_err(&pdev->dev, \"Error: Missing reset\\n\");\n\t\treturn PTR_ERR(tdma->rst);\n\t}\n\n\tspin_lock_init(&tdma->global_lock);\n\n\tret = clk_prepare(tdma->dma_clk);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tegra_dma_init_hw(tdma);\n\tif (ret)\n\t\tgoto err_clk_unprepare;\n\n\tpm_runtime_irq_safe(&pdev->dev);\n\tpm_runtime_enable(&pdev->dev);\n\n\tINIT_LIST_HEAD(&tdma->dma_dev.channels);\n\tfor (i = 0; i < cdata->nr_channels; i++) {\n\t\tstruct tegra_dma_channel *tdc = &tdma->channels[i];\n\t\tint irq;\n\n\t\ttdc->chan_addr = tdma->base_addr +\n\t\t\t\t TEGRA_APBDMA_CHANNEL_BASE_ADD_OFFSET +\n\t\t\t\t (i * cdata->channel_reg_size);\n\n\t\tirq = platform_get_irq(pdev, i);\n\t\tif (irq < 0) {\n\t\t\tret = irq;\n\t\t\tgoto err_pm_disable;\n\t\t}\n\n\t\tsnprintf(tdc->name, sizeof(tdc->name), \"apbdma.%d\", i);\n\t\tret = devm_request_irq(&pdev->dev, irq, tegra_dma_isr, 0,\n\t\t\t\t       tdc->name, tdc);\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"request_irq failed with err %d channel %d\\n\",\n\t\t\t\tret, i);\n\t\t\tgoto err_pm_disable;\n\t\t}\n\n\t\ttdc->dma_chan.device = &tdma->dma_dev;\n\t\tdma_cookie_init(&tdc->dma_chan);\n\t\tlist_add_tail(&tdc->dma_chan.device_node,\n\t\t\t      &tdma->dma_dev.channels);\n\t\ttdc->tdma = tdma;\n\t\ttdc->id = i;\n\t\ttdc->slave_id = TEGRA_APBDMA_SLAVE_ID_INVALID;\n\n\t\ttasklet_setup(&tdc->tasklet, tegra_dma_tasklet);\n\t\tspin_lock_init(&tdc->lock);\n\t\tinit_waitqueue_head(&tdc->wq);\n\n\t\tINIT_LIST_HEAD(&tdc->pending_sg_req);\n\t\tINIT_LIST_HEAD(&tdc->free_sg_req);\n\t\tINIT_LIST_HEAD(&tdc->free_dma_desc);\n\t\tINIT_LIST_HEAD(&tdc->cb_desc);\n\t}\n\n\tdma_cap_set(DMA_SLAVE, tdma->dma_dev.cap_mask);\n\tdma_cap_set(DMA_PRIVATE, tdma->dma_dev.cap_mask);\n\tdma_cap_set(DMA_CYCLIC, tdma->dma_dev.cap_mask);\n\n\ttdma->global_pause_count = 0;\n\ttdma->dma_dev.dev = &pdev->dev;\n\ttdma->dma_dev.device_alloc_chan_resources =\n\t\t\t\t\ttegra_dma_alloc_chan_resources;\n\ttdma->dma_dev.device_free_chan_resources =\n\t\t\t\t\ttegra_dma_free_chan_resources;\n\ttdma->dma_dev.device_prep_slave_sg = tegra_dma_prep_slave_sg;\n\ttdma->dma_dev.device_prep_dma_cyclic = tegra_dma_prep_dma_cyclic;\n\ttdma->dma_dev.src_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_8_BYTES);\n\ttdma->dma_dev.dst_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_8_BYTES);\n\ttdma->dma_dev.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\n\ttdma->dma_dev.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\ttdma->dma_dev.device_config = tegra_dma_slave_config;\n\ttdma->dma_dev.device_terminate_all = tegra_dma_terminate_all;\n\ttdma->dma_dev.device_synchronize = tegra_dma_synchronize;\n\ttdma->dma_dev.device_tx_status = tegra_dma_tx_status;\n\ttdma->dma_dev.device_issue_pending = tegra_dma_issue_pending;\n\n\tret = dma_async_device_register(&tdma->dma_dev);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Tegra20 APB DMA driver registration failed %d\\n\", ret);\n\t\tgoto err_pm_disable;\n\t}\n\n\tret = of_dma_controller_register(pdev->dev.of_node,\n\t\t\t\t\t tegra_dma_of_xlate, tdma);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Tegra20 APB DMA OF registration failed %d\\n\", ret);\n\t\tgoto err_unregister_dma_dev;\n\t}\n\n\tdev_info(&pdev->dev, \"Tegra20 APB DMA driver registered %u channels\\n\",\n\t\t cdata->nr_channels);\n\n\treturn 0;\n\nerr_unregister_dma_dev:\n\tdma_async_device_unregister(&tdma->dma_dev);\n\nerr_pm_disable:\n\tpm_runtime_disable(&pdev->dev);\n\nerr_clk_unprepare:\n\tclk_unprepare(tdma->dma_clk);\n\n\treturn ret;\n}\n\nstatic int tegra_dma_remove(struct platform_device *pdev)\n{\n\tstruct tegra_dma *tdma = platform_get_drvdata(pdev);\n\n\tof_dma_controller_free(pdev->dev.of_node);\n\tdma_async_device_unregister(&tdma->dma_dev);\n\tpm_runtime_disable(&pdev->dev);\n\tclk_unprepare(tdma->dma_clk);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused tegra_dma_runtime_suspend(struct device *dev)\n{\n\tstruct tegra_dma *tdma = dev_get_drvdata(dev);\n\n\tclk_disable(tdma->dma_clk);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused tegra_dma_runtime_resume(struct device *dev)\n{\n\tstruct tegra_dma *tdma = dev_get_drvdata(dev);\n\n\treturn clk_enable(tdma->dma_clk);\n}\n\nstatic int __maybe_unused tegra_dma_dev_suspend(struct device *dev)\n{\n\tstruct tegra_dma *tdma = dev_get_drvdata(dev);\n\tunsigned long flags;\n\tunsigned int i;\n\tbool busy;\n\n\tfor (i = 0; i < tdma->chip_data->nr_channels; i++) {\n\t\tstruct tegra_dma_channel *tdc = &tdma->channels[i];\n\n\t\ttasklet_kill(&tdc->tasklet);\n\n\t\tspin_lock_irqsave(&tdc->lock, flags);\n\t\tbusy = tdc->busy;\n\t\tspin_unlock_irqrestore(&tdc->lock, flags);\n\n\t\tif (busy) {\n\t\t\tdev_err(tdma->dev, \"channel %u busy\\n\", i);\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\treturn pm_runtime_force_suspend(dev);\n}\n\nstatic int __maybe_unused tegra_dma_dev_resume(struct device *dev)\n{\n\tstruct tegra_dma *tdma = dev_get_drvdata(dev);\n\tint err;\n\n\terr = tegra_dma_init_hw(tdma);\n\tif (err)\n\t\treturn err;\n\n\treturn pm_runtime_force_resume(dev);\n}\n\nstatic const struct dev_pm_ops tegra_dma_dev_pm_ops = {\n\tSET_RUNTIME_PM_OPS(tegra_dma_runtime_suspend, tegra_dma_runtime_resume,\n\t\t\t   NULL)\n\tSET_SYSTEM_SLEEP_PM_OPS(tegra_dma_dev_suspend, tegra_dma_dev_resume)\n};\n\nstatic const struct of_device_id tegra_dma_of_match[] = {\n\t{\n\t\t.compatible = \"nvidia,tegra148-apbdma\",\n\t\t.data = &tegra148_dma_chip_data,\n\t}, {\n\t\t.compatible = \"nvidia,tegra114-apbdma\",\n\t\t.data = &tegra114_dma_chip_data,\n\t}, {\n\t\t.compatible = \"nvidia,tegra30-apbdma\",\n\t\t.data = &tegra30_dma_chip_data,\n\t}, {\n\t\t.compatible = \"nvidia,tegra20-apbdma\",\n\t\t.data = &tegra20_dma_chip_data,\n\t}, {\n\t},\n};\nMODULE_DEVICE_TABLE(of, tegra_dma_of_match);\n\nstatic struct platform_driver tegra_dmac_driver = {\n\t.driver = {\n\t\t.name\t= \"tegra-apbdma\",\n\t\t.pm\t= &tegra_dma_dev_pm_ops,\n\t\t.of_match_table = tegra_dma_of_match,\n\t},\n\t.probe\t\t= tegra_dma_probe,\n\t.remove\t\t= tegra_dma_remove,\n};\n\nmodule_platform_driver(tegra_dmac_driver);\n\nMODULE_DESCRIPTION(\"NVIDIA Tegra APB DMA Controller driver\");\nMODULE_AUTHOR(\"Laxman Dewangan <ldewangan@nvidia.com>\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}