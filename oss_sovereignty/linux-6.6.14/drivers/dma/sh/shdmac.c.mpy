{
  "module_name": "shdmac.c",
  "hash_id": "c956041128c208e7cca8cf8895f69fffd68bda6edd5cc8dddb69470b90c6e163",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/sh/shdmac.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#include <linux/dmaengine.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/kdebug.h>\n#include <linux/module.h>\n#include <linux/notifier.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/rculist.h>\n#include <linux/sh_dma.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n\n#include \"../dmaengine.h\"\n#include \"shdma.h\"\n\n \n#define SAR\t0x00\t \n#define DAR\t0x04\t \n#define TCR\t0x08\t \n#define CHCR\t0x0C\t \n#define DMAOR\t0x40\t \n\n#define TEND\t0x18  \n\n#define SH_DMAE_DRV_NAME \"sh-dma-engine\"\n\n \n#define LOG2_DEFAULT_XFER_SIZE\t2\n#define SH_DMA_SLAVE_NUMBER 256\n#define SH_DMA_TCR_MAX (16 * 1024 * 1024 - 1)\n\n \nstatic DEFINE_SPINLOCK(sh_dmae_lock);\nstatic LIST_HEAD(sh_dmae_devices);\n\n \nstatic void channel_clear(struct sh_dmae_chan *sh_dc)\n{\n\tstruct sh_dmae_device *shdev = to_sh_dev(sh_dc);\n\tconst struct sh_dmae_channel *chan_pdata = shdev->pdata->channel +\n\t\tsh_dc->shdma_chan.id;\n\tu32 val = shdev->pdata->chclr_bitwise ? 1 << chan_pdata->chclr_bit : 0;\n\n\t__raw_writel(val, shdev->chan_reg + chan_pdata->chclr_offset);\n}\n\nstatic void sh_dmae_writel(struct sh_dmae_chan *sh_dc, u32 data, u32 reg)\n{\n\t__raw_writel(data, sh_dc->base + reg);\n}\n\nstatic u32 sh_dmae_readl(struct sh_dmae_chan *sh_dc, u32 reg)\n{\n\treturn __raw_readl(sh_dc->base + reg);\n}\n\nstatic u16 dmaor_read(struct sh_dmae_device *shdev)\n{\n\tvoid __iomem *addr = shdev->chan_reg + DMAOR;\n\n\tif (shdev->pdata->dmaor_is_32bit)\n\t\treturn __raw_readl(addr);\n\telse\n\t\treturn __raw_readw(addr);\n}\n\nstatic void dmaor_write(struct sh_dmae_device *shdev, u16 data)\n{\n\tvoid __iomem *addr = shdev->chan_reg + DMAOR;\n\n\tif (shdev->pdata->dmaor_is_32bit)\n\t\t__raw_writel(data, addr);\n\telse\n\t\t__raw_writew(data, addr);\n}\n\nstatic void chcr_write(struct sh_dmae_chan *sh_dc, u32 data)\n{\n\tstruct sh_dmae_device *shdev = to_sh_dev(sh_dc);\n\n\t__raw_writel(data, sh_dc->base + shdev->chcr_offset);\n}\n\nstatic u32 chcr_read(struct sh_dmae_chan *sh_dc)\n{\n\tstruct sh_dmae_device *shdev = to_sh_dev(sh_dc);\n\n\treturn __raw_readl(sh_dc->base + shdev->chcr_offset);\n}\n\n \nstatic void sh_dmae_ctl_stop(struct sh_dmae_device *shdev)\n{\n\tunsigned short dmaor;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&sh_dmae_lock, flags);\n\n\tdmaor = dmaor_read(shdev);\n\tdmaor_write(shdev, dmaor & ~(DMAOR_NMIF | DMAOR_AE | DMAOR_DME));\n\n\tspin_unlock_irqrestore(&sh_dmae_lock, flags);\n}\n\nstatic int sh_dmae_rst(struct sh_dmae_device *shdev)\n{\n\tunsigned short dmaor;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&sh_dmae_lock, flags);\n\n\tdmaor = dmaor_read(shdev) & ~(DMAOR_NMIF | DMAOR_AE | DMAOR_DME);\n\n\tif (shdev->pdata->chclr_present) {\n\t\tint i;\n\t\tfor (i = 0; i < shdev->pdata->channel_num; i++) {\n\t\t\tstruct sh_dmae_chan *sh_chan = shdev->chan[i];\n\t\t\tif (sh_chan)\n\t\t\t\tchannel_clear(sh_chan);\n\t\t}\n\t}\n\n\tdmaor_write(shdev, dmaor | shdev->pdata->dmaor_init);\n\n\tdmaor = dmaor_read(shdev);\n\n\tspin_unlock_irqrestore(&sh_dmae_lock, flags);\n\n\tif (dmaor & (DMAOR_AE | DMAOR_NMIF)) {\n\t\tdev_warn(shdev->shdma_dev.dma_dev.dev, \"Can't initialize DMAOR.\\n\");\n\t\treturn -EIO;\n\t}\n\tif (shdev->pdata->dmaor_init & ~dmaor)\n\t\tdev_warn(shdev->shdma_dev.dma_dev.dev,\n\t\t\t \"DMAOR=0x%x hasn't latched the initial value 0x%x.\\n\",\n\t\t\t dmaor, shdev->pdata->dmaor_init);\n\treturn 0;\n}\n\nstatic bool dmae_is_busy(struct sh_dmae_chan *sh_chan)\n{\n\tu32 chcr = chcr_read(sh_chan);\n\n\tif ((chcr & (CHCR_DE | CHCR_TE)) == CHCR_DE)\n\t\treturn true;  \n\n\treturn false;  \n}\n\nstatic unsigned int calc_xmit_shift(struct sh_dmae_chan *sh_chan, u32 chcr)\n{\n\tstruct sh_dmae_device *shdev = to_sh_dev(sh_chan);\n\tconst struct sh_dmae_pdata *pdata = shdev->pdata;\n\tint cnt = ((chcr & pdata->ts_low_mask) >> pdata->ts_low_shift) |\n\t\t((chcr & pdata->ts_high_mask) >> pdata->ts_high_shift);\n\n\tif (cnt >= pdata->ts_shift_num)\n\t\tcnt = 0;\n\n\treturn pdata->ts_shift[cnt];\n}\n\nstatic u32 log2size_to_chcr(struct sh_dmae_chan *sh_chan, int l2size)\n{\n\tstruct sh_dmae_device *shdev = to_sh_dev(sh_chan);\n\tconst struct sh_dmae_pdata *pdata = shdev->pdata;\n\tint i;\n\n\tfor (i = 0; i < pdata->ts_shift_num; i++)\n\t\tif (pdata->ts_shift[i] == l2size)\n\t\t\tbreak;\n\n\tif (i == pdata->ts_shift_num)\n\t\ti = 0;\n\n\treturn ((i << pdata->ts_low_shift) & pdata->ts_low_mask) |\n\t\t((i << pdata->ts_high_shift) & pdata->ts_high_mask);\n}\n\nstatic void dmae_set_reg(struct sh_dmae_chan *sh_chan, struct sh_dmae_regs *hw)\n{\n\tsh_dmae_writel(sh_chan, hw->sar, SAR);\n\tsh_dmae_writel(sh_chan, hw->dar, DAR);\n\tsh_dmae_writel(sh_chan, hw->tcr >> sh_chan->xmit_shift, TCR);\n}\n\nstatic void dmae_start(struct sh_dmae_chan *sh_chan)\n{\n\tstruct sh_dmae_device *shdev = to_sh_dev(sh_chan);\n\tu32 chcr = chcr_read(sh_chan);\n\n\tif (shdev->pdata->needs_tend_set)\n\t\tsh_dmae_writel(sh_chan, 0xFFFFFFFF, TEND);\n\n\tchcr |= CHCR_DE | shdev->chcr_ie_bit;\n\tchcr_write(sh_chan, chcr & ~CHCR_TE);\n}\n\nstatic void dmae_init(struct sh_dmae_chan *sh_chan)\n{\n\t \n\tu32 chcr = DM_INC | SM_INC | RS_AUTO | log2size_to_chcr(sh_chan,\n\t\t\t\t\t\t   LOG2_DEFAULT_XFER_SIZE);\n\tsh_chan->xmit_shift = calc_xmit_shift(sh_chan, chcr);\n\tchcr_write(sh_chan, chcr);\n}\n\nstatic int dmae_set_chcr(struct sh_dmae_chan *sh_chan, u32 val)\n{\n\t \n\tif (dmae_is_busy(sh_chan))\n\t\treturn -EBUSY;\n\n\tsh_chan->xmit_shift = calc_xmit_shift(sh_chan, val);\n\tchcr_write(sh_chan, val);\n\n\treturn 0;\n}\n\nstatic int dmae_set_dmars(struct sh_dmae_chan *sh_chan, u16 val)\n{\n\tstruct sh_dmae_device *shdev = to_sh_dev(sh_chan);\n\tconst struct sh_dmae_pdata *pdata = shdev->pdata;\n\tconst struct sh_dmae_channel *chan_pdata = &pdata->channel[sh_chan->shdma_chan.id];\n\tvoid __iomem *addr = shdev->dmars;\n\tunsigned int shift = chan_pdata->dmars_bit;\n\n\tif (dmae_is_busy(sh_chan))\n\t\treturn -EBUSY;\n\n\tif (pdata->no_dmars)\n\t\treturn 0;\n\n\t \n\tif (!addr)\n\t\taddr = shdev->chan_reg;\n\taddr += chan_pdata->dmars;\n\n\t__raw_writew((__raw_readw(addr) & (0xff00 >> shift)) | (val << shift),\n\t\t     addr);\n\n\treturn 0;\n}\n\nstatic void sh_dmae_start_xfer(struct shdma_chan *schan,\n\t\t\t       struct shdma_desc *sdesc)\n{\n\tstruct sh_dmae_chan *sh_chan = container_of(schan, struct sh_dmae_chan,\n\t\t\t\t\t\t    shdma_chan);\n\tstruct sh_dmae_desc *sh_desc = container_of(sdesc,\n\t\t\t\t\tstruct sh_dmae_desc, shdma_desc);\n\tdev_dbg(sh_chan->shdma_chan.dev, \"Queue #%d to %d: %u@%x -> %x\\n\",\n\t\tsdesc->async_tx.cookie, sh_chan->shdma_chan.id,\n\t\tsh_desc->hw.tcr, sh_desc->hw.sar, sh_desc->hw.dar);\n\t \n\tdmae_set_reg(sh_chan, &sh_desc->hw);\n\tdmae_start(sh_chan);\n}\n\nstatic bool sh_dmae_channel_busy(struct shdma_chan *schan)\n{\n\tstruct sh_dmae_chan *sh_chan = container_of(schan, struct sh_dmae_chan,\n\t\t\t\t\t\t    shdma_chan);\n\treturn dmae_is_busy(sh_chan);\n}\n\nstatic void sh_dmae_setup_xfer(struct shdma_chan *schan,\n\t\t\t       int slave_id)\n{\n\tstruct sh_dmae_chan *sh_chan = container_of(schan, struct sh_dmae_chan,\n\t\t\t\t\t\t    shdma_chan);\n\n\tif (slave_id >= 0) {\n\t\tconst struct sh_dmae_slave_config *cfg =\n\t\t\tsh_chan->config;\n\n\t\tdmae_set_dmars(sh_chan, cfg->mid_rid);\n\t\tdmae_set_chcr(sh_chan, cfg->chcr);\n\t} else {\n\t\tdmae_init(sh_chan);\n\t}\n}\n\n \nstatic const struct sh_dmae_slave_config *dmae_find_slave(\n\tstruct sh_dmae_chan *sh_chan, int match)\n{\n\tstruct sh_dmae_device *shdev = to_sh_dev(sh_chan);\n\tconst struct sh_dmae_pdata *pdata = shdev->pdata;\n\tconst struct sh_dmae_slave_config *cfg;\n\tint i;\n\n\tif (!sh_chan->shdma_chan.dev->of_node) {\n\t\tif (match >= SH_DMA_SLAVE_NUMBER)\n\t\t\treturn NULL;\n\n\t\tfor (i = 0, cfg = pdata->slave; i < pdata->slave_num; i++, cfg++)\n\t\t\tif (cfg->slave_id == match)\n\t\t\t\treturn cfg;\n\t} else {\n\t\tfor (i = 0, cfg = pdata->slave; i < pdata->slave_num; i++, cfg++)\n\t\t\tif (cfg->mid_rid == match) {\n\t\t\t\tsh_chan->shdma_chan.slave_id = i;\n\t\t\t\treturn cfg;\n\t\t\t}\n\t}\n\n\treturn NULL;\n}\n\nstatic int sh_dmae_set_slave(struct shdma_chan *schan,\n\t\t\t     int slave_id, dma_addr_t slave_addr, bool try)\n{\n\tstruct sh_dmae_chan *sh_chan = container_of(schan, struct sh_dmae_chan,\n\t\t\t\t\t\t    shdma_chan);\n\tconst struct sh_dmae_slave_config *cfg = dmae_find_slave(sh_chan, slave_id);\n\tif (!cfg)\n\t\treturn -ENXIO;\n\n\tif (!try) {\n\t\tsh_chan->config = cfg;\n\t\tsh_chan->slave_addr = slave_addr ? : cfg->addr;\n\t}\n\n\treturn 0;\n}\n\nstatic void dmae_halt(struct sh_dmae_chan *sh_chan)\n{\n\tstruct sh_dmae_device *shdev = to_sh_dev(sh_chan);\n\tu32 chcr = chcr_read(sh_chan);\n\n\tchcr &= ~(CHCR_DE | CHCR_TE | shdev->chcr_ie_bit);\n\tchcr_write(sh_chan, chcr);\n}\n\nstatic int sh_dmae_desc_setup(struct shdma_chan *schan,\n\t\t\t      struct shdma_desc *sdesc,\n\t\t\t      dma_addr_t src, dma_addr_t dst, size_t *len)\n{\n\tstruct sh_dmae_desc *sh_desc = container_of(sdesc,\n\t\t\t\t\tstruct sh_dmae_desc, shdma_desc);\n\n\tif (*len > schan->max_xfer_len)\n\t\t*len = schan->max_xfer_len;\n\n\tsh_desc->hw.sar = src;\n\tsh_desc->hw.dar = dst;\n\tsh_desc->hw.tcr = *len;\n\n\treturn 0;\n}\n\nstatic void sh_dmae_halt(struct shdma_chan *schan)\n{\n\tstruct sh_dmae_chan *sh_chan = container_of(schan, struct sh_dmae_chan,\n\t\t\t\t\t\t    shdma_chan);\n\tdmae_halt(sh_chan);\n}\n\nstatic bool sh_dmae_chan_irq(struct shdma_chan *schan, int irq)\n{\n\tstruct sh_dmae_chan *sh_chan = container_of(schan, struct sh_dmae_chan,\n\t\t\t\t\t\t    shdma_chan);\n\n\tif (!(chcr_read(sh_chan) & CHCR_TE))\n\t\treturn false;\n\n\t \n\tdmae_halt(sh_chan);\n\n\treturn true;\n}\n\nstatic size_t sh_dmae_get_partial(struct shdma_chan *schan,\n\t\t\t\t  struct shdma_desc *sdesc)\n{\n\tstruct sh_dmae_chan *sh_chan = container_of(schan, struct sh_dmae_chan,\n\t\t\t\t\t\t    shdma_chan);\n\tstruct sh_dmae_desc *sh_desc = container_of(sdesc,\n\t\t\t\t\tstruct sh_dmae_desc, shdma_desc);\n\treturn sh_desc->hw.tcr -\n\t\t(sh_dmae_readl(sh_chan, TCR) << sh_chan->xmit_shift);\n}\n\n \nstatic bool sh_dmae_reset(struct sh_dmae_device *shdev)\n{\n\tbool ret;\n\n\t \n\tsh_dmae_ctl_stop(shdev);\n\n\t \n\tret = shdma_reset(&shdev->shdma_dev);\n\n\tsh_dmae_rst(shdev);\n\n\treturn ret;\n}\n\nstatic irqreturn_t sh_dmae_err(int irq, void *data)\n{\n\tstruct sh_dmae_device *shdev = data;\n\n\tif (!(dmaor_read(shdev) & DMAOR_AE))\n\t\treturn IRQ_NONE;\n\n\tsh_dmae_reset(shdev);\n\treturn IRQ_HANDLED;\n}\n\nstatic bool sh_dmae_desc_completed(struct shdma_chan *schan,\n\t\t\t\t   struct shdma_desc *sdesc)\n{\n\tstruct sh_dmae_chan *sh_chan = container_of(schan,\n\t\t\t\t\tstruct sh_dmae_chan, shdma_chan);\n\tstruct sh_dmae_desc *sh_desc = container_of(sdesc,\n\t\t\t\t\tstruct sh_dmae_desc, shdma_desc);\n\tu32 sar_buf = sh_dmae_readl(sh_chan, SAR);\n\tu32 dar_buf = sh_dmae_readl(sh_chan, DAR);\n\n\treturn\t(sdesc->direction == DMA_DEV_TO_MEM &&\n\t\t (sh_desc->hw.dar + sh_desc->hw.tcr) == dar_buf) ||\n\t\t(sdesc->direction != DMA_DEV_TO_MEM &&\n\t\t (sh_desc->hw.sar + sh_desc->hw.tcr) == sar_buf);\n}\n\nstatic bool sh_dmae_nmi_notify(struct sh_dmae_device *shdev)\n{\n\t \n\tif ((dmaor_read(shdev) & DMAOR_NMIF) == 0)\n\t\treturn false;\n\n\treturn sh_dmae_reset(shdev);\n}\n\nstatic int sh_dmae_nmi_handler(struct notifier_block *self,\n\t\t\t       unsigned long cmd, void *data)\n{\n\tstruct sh_dmae_device *shdev;\n\tint ret = NOTIFY_DONE;\n\tbool triggered;\n\n\t \n\tif (!in_nmi())\n\t\treturn NOTIFY_DONE;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(shdev, &sh_dmae_devices, node) {\n\t\t \n\t\ttriggered = sh_dmae_nmi_notify(shdev);\n\t\tif (triggered == true)\n\t\t\tret = NOTIFY_OK;\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nstatic struct notifier_block sh_dmae_nmi_notifier __read_mostly = {\n\t.notifier_call\t= sh_dmae_nmi_handler,\n\n\t \n\t.priority\t= 1,\n};\n\nstatic int sh_dmae_chan_probe(struct sh_dmae_device *shdev, int id,\n\t\t\t\t\tint irq, unsigned long flags)\n{\n\tconst struct sh_dmae_channel *chan_pdata = &shdev->pdata->channel[id];\n\tstruct shdma_dev *sdev = &shdev->shdma_dev;\n\tstruct platform_device *pdev = to_platform_device(sdev->dma_dev.dev);\n\tstruct sh_dmae_chan *sh_chan;\n\tstruct shdma_chan *schan;\n\tint err;\n\n\tsh_chan = devm_kzalloc(sdev->dma_dev.dev, sizeof(struct sh_dmae_chan),\n\t\t\t       GFP_KERNEL);\n\tif (!sh_chan)\n\t\treturn -ENOMEM;\n\n\tschan = &sh_chan->shdma_chan;\n\tschan->max_xfer_len = SH_DMA_TCR_MAX + 1;\n\n\tshdma_chan_probe(sdev, schan, id);\n\n\tsh_chan->base = shdev->chan_reg + chan_pdata->offset;\n\n\t \n\tif (pdev->id >= 0)\n\t\tsnprintf(sh_chan->dev_id, sizeof(sh_chan->dev_id),\n\t\t\t \"sh-dmae%d.%d\", pdev->id, id);\n\telse\n\t\tsnprintf(sh_chan->dev_id, sizeof(sh_chan->dev_id),\n\t\t\t \"sh-dma%d\", id);\n\n\terr = shdma_request_irq(schan, irq, flags, sh_chan->dev_id);\n\tif (err) {\n\t\tdev_err(sdev->dma_dev.dev,\n\t\t\t\"DMA channel %d request_irq error %d\\n\",\n\t\t\tid, err);\n\t\tgoto err_no_irq;\n\t}\n\n\tshdev->chan[id] = sh_chan;\n\treturn 0;\n\nerr_no_irq:\n\t \n\tshdma_chan_remove(schan);\n\treturn err;\n}\n\nstatic void sh_dmae_chan_remove(struct sh_dmae_device *shdev)\n{\n\tstruct shdma_chan *schan;\n\tint i;\n\n\tshdma_for_each_chan(schan, &shdev->shdma_dev, i) {\n\t\tBUG_ON(!schan);\n\n\t\tshdma_chan_remove(schan);\n\t}\n}\n\n#ifdef CONFIG_PM\nstatic int sh_dmae_runtime_suspend(struct device *dev)\n{\n\tstruct sh_dmae_device *shdev = dev_get_drvdata(dev);\n\n\tsh_dmae_ctl_stop(shdev);\n\treturn 0;\n}\n\nstatic int sh_dmae_runtime_resume(struct device *dev)\n{\n\tstruct sh_dmae_device *shdev = dev_get_drvdata(dev);\n\n\treturn sh_dmae_rst(shdev);\n}\n#endif\n\n#ifdef CONFIG_PM_SLEEP\nstatic int sh_dmae_suspend(struct device *dev)\n{\n\tstruct sh_dmae_device *shdev = dev_get_drvdata(dev);\n\n\tsh_dmae_ctl_stop(shdev);\n\treturn 0;\n}\n\nstatic int sh_dmae_resume(struct device *dev)\n{\n\tstruct sh_dmae_device *shdev = dev_get_drvdata(dev);\n\tint i, ret;\n\n\tret = sh_dmae_rst(shdev);\n\tif (ret < 0)\n\t\tdev_err(dev, \"Failed to reset!\\n\");\n\n\tfor (i = 0; i < shdev->pdata->channel_num; i++) {\n\t\tstruct sh_dmae_chan *sh_chan = shdev->chan[i];\n\n\t\tif (!sh_chan->shdma_chan.desc_num)\n\t\t\tcontinue;\n\n\t\tif (sh_chan->shdma_chan.slave_id >= 0) {\n\t\t\tconst struct sh_dmae_slave_config *cfg = sh_chan->config;\n\t\t\tdmae_set_dmars(sh_chan, cfg->mid_rid);\n\t\t\tdmae_set_chcr(sh_chan, cfg->chcr);\n\t\t} else {\n\t\t\tdmae_init(sh_chan);\n\t\t}\n\t}\n\n\treturn 0;\n}\n#endif\n\nstatic const struct dev_pm_ops sh_dmae_pm = {\n\tSET_SYSTEM_SLEEP_PM_OPS(sh_dmae_suspend, sh_dmae_resume)\n\tSET_RUNTIME_PM_OPS(sh_dmae_runtime_suspend, sh_dmae_runtime_resume,\n\t\t\t   NULL)\n};\n\nstatic dma_addr_t sh_dmae_slave_addr(struct shdma_chan *schan)\n{\n\tstruct sh_dmae_chan *sh_chan = container_of(schan,\n\t\t\t\t\tstruct sh_dmae_chan, shdma_chan);\n\n\t \n\treturn sh_chan->slave_addr;\n}\n\nstatic struct shdma_desc *sh_dmae_embedded_desc(void *buf, int i)\n{\n\treturn &((struct sh_dmae_desc *)buf)[i].shdma_desc;\n}\n\nstatic const struct shdma_ops sh_dmae_shdma_ops = {\n\t.desc_completed = sh_dmae_desc_completed,\n\t.halt_channel = sh_dmae_halt,\n\t.channel_busy = sh_dmae_channel_busy,\n\t.slave_addr = sh_dmae_slave_addr,\n\t.desc_setup = sh_dmae_desc_setup,\n\t.set_slave = sh_dmae_set_slave,\n\t.setup_xfer = sh_dmae_setup_xfer,\n\t.start_xfer = sh_dmae_start_xfer,\n\t.embedded_desc = sh_dmae_embedded_desc,\n\t.chan_irq = sh_dmae_chan_irq,\n\t.get_partial = sh_dmae_get_partial,\n};\n\nstatic int sh_dmae_probe(struct platform_device *pdev)\n{\n\tconst enum dma_slave_buswidth widths =\n\t\tDMA_SLAVE_BUSWIDTH_1_BYTE   | DMA_SLAVE_BUSWIDTH_2_BYTES |\n\t\tDMA_SLAVE_BUSWIDTH_4_BYTES  | DMA_SLAVE_BUSWIDTH_8_BYTES |\n\t\tDMA_SLAVE_BUSWIDTH_16_BYTES | DMA_SLAVE_BUSWIDTH_32_BYTES;\n\tconst struct sh_dmae_pdata *pdata;\n\tunsigned long chan_flag[SH_DMAE_MAX_CHANNELS] = {};\n\tint chan_irq[SH_DMAE_MAX_CHANNELS];\n\tunsigned long irqflags = 0;\n\tint err, errirq, i, irq_cnt = 0, irqres = 0, irq_cap = 0;\n\tstruct sh_dmae_device *shdev;\n\tstruct dma_device *dma_dev;\n\tstruct resource *dmars, *errirq_res, *chanirq_res;\n\n\tif (pdev->dev.of_node)\n\t\tpdata = of_device_get_match_data(&pdev->dev);\n\telse\n\t\tpdata = dev_get_platdata(&pdev->dev);\n\n\t \n\tif (!pdata || !pdata->channel_num)\n\t\treturn -ENODEV;\n\n\t \n\tdmars = platform_get_resource(pdev, IORESOURCE_MEM, 1);\n\t \n\terrirq_res = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\tif (!errirq_res)\n\t\treturn -ENODEV;\n\n\tshdev = devm_kzalloc(&pdev->dev, sizeof(struct sh_dmae_device),\n\t\t\t     GFP_KERNEL);\n\tif (!shdev)\n\t\treturn -ENOMEM;\n\n\tdma_dev = &shdev->shdma_dev.dma_dev;\n\n\tshdev->chan_reg = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(shdev->chan_reg))\n\t\treturn PTR_ERR(shdev->chan_reg);\n\tif (dmars) {\n\t\tshdev->dmars = devm_ioremap_resource(&pdev->dev, dmars);\n\t\tif (IS_ERR(shdev->dmars))\n\t\t\treturn PTR_ERR(shdev->dmars);\n\t}\n\n\tdma_dev->src_addr_widths = widths;\n\tdma_dev->dst_addr_widths = widths;\n\tdma_dev->directions = BIT(DMA_MEM_TO_DEV) | BIT(DMA_DEV_TO_MEM);\n\tdma_dev->residue_granularity = DMA_RESIDUE_GRANULARITY_DESCRIPTOR;\n\n\tif (!pdata->slave_only)\n\t\tdma_cap_set(DMA_MEMCPY, dma_dev->cap_mask);\n\tif (pdata->slave && pdata->slave_num)\n\t\tdma_cap_set(DMA_SLAVE, dma_dev->cap_mask);\n\n\t \n\tdma_dev->copy_align = LOG2_DEFAULT_XFER_SIZE;\n\n\tshdev->shdma_dev.ops = &sh_dmae_shdma_ops;\n\tshdev->shdma_dev.desc_size = sizeof(struct sh_dmae_desc);\n\terr = shdma_init(&pdev->dev, &shdev->shdma_dev,\n\t\t\t      pdata->channel_num);\n\tif (err < 0)\n\t\tgoto eshdma;\n\n\t \n\tshdev->pdata = pdata;\n\n\tif (pdata->chcr_offset)\n\t\tshdev->chcr_offset = pdata->chcr_offset;\n\telse\n\t\tshdev->chcr_offset = CHCR;\n\n\tif (pdata->chcr_ie_bit)\n\t\tshdev->chcr_ie_bit = pdata->chcr_ie_bit;\n\telse\n\t\tshdev->chcr_ie_bit = CHCR_IE;\n\n\tplatform_set_drvdata(pdev, shdev);\n\n\tpm_runtime_enable(&pdev->dev);\n\terr = pm_runtime_get_sync(&pdev->dev);\n\tif (err < 0)\n\t\tdev_err(&pdev->dev, \"%s(): GET = %d\\n\", __func__, err);\n\n\tspin_lock_irq(&sh_dmae_lock);\n\tlist_add_tail_rcu(&shdev->node, &sh_dmae_devices);\n\tspin_unlock_irq(&sh_dmae_lock);\n\n\t \n\terr = sh_dmae_rst(shdev);\n\tif (err)\n\t\tgoto rst_err;\n\n\tif (IS_ENABLED(CONFIG_CPU_SH4) || IS_ENABLED(CONFIG_ARCH_RENESAS)) {\n\t\tchanirq_res = platform_get_resource(pdev, IORESOURCE_IRQ, 1);\n\n\t\tif (!chanirq_res)\n\t\t\tchanirq_res = errirq_res;\n\t\telse\n\t\t\tirqres++;\n\n\t\tif (chanirq_res == errirq_res ||\n\t\t    (errirq_res->flags & IORESOURCE_BITS) == IORESOURCE_IRQ_SHAREABLE)\n\t\t\tirqflags = IRQF_SHARED;\n\n\t\terrirq = errirq_res->start;\n\n\t\terr = devm_request_irq(&pdev->dev, errirq, sh_dmae_err,\n\t\t\t\t       irqflags, \"DMAC Address Error\", shdev);\n\t\tif (err) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"DMA failed requesting irq #%d, error %d\\n\",\n\t\t\t\terrirq, err);\n\t\t\tgoto eirq_err;\n\t\t}\n\t} else {\n\t\tchanirq_res = errirq_res;\n\t}\n\n\tif (chanirq_res->start == chanirq_res->end &&\n\t    !platform_get_resource(pdev, IORESOURCE_IRQ, 1)) {\n\t\t \n\t\tfor (; irq_cnt < pdata->channel_num; irq_cnt++) {\n\t\t\tif (irq_cnt < SH_DMAE_MAX_CHANNELS) {\n\t\t\t\tchan_irq[irq_cnt] = chanirq_res->start;\n\t\t\t\tchan_flag[irq_cnt] = IRQF_SHARED;\n\t\t\t} else {\n\t\t\t\tirq_cap = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tdo {\n\t\t\tfor (i = chanirq_res->start; i <= chanirq_res->end; i++) {\n\t\t\t\tif (irq_cnt >= SH_DMAE_MAX_CHANNELS) {\n\t\t\t\t\tirq_cap = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tif ((errirq_res->flags & IORESOURCE_BITS) ==\n\t\t\t\t    IORESOURCE_IRQ_SHAREABLE)\n\t\t\t\t\tchan_flag[irq_cnt] = IRQF_SHARED;\n\t\t\t\telse\n\t\t\t\t\tchan_flag[irq_cnt] = 0;\n\t\t\t\tdev_dbg(&pdev->dev,\n\t\t\t\t\t\"Found IRQ %d for channel %d\\n\",\n\t\t\t\t\ti, irq_cnt);\n\t\t\t\tchan_irq[irq_cnt++] = i;\n\t\t\t}\n\n\t\t\tif (irq_cnt >= SH_DMAE_MAX_CHANNELS)\n\t\t\t\tbreak;\n\n\t\t\tchanirq_res = platform_get_resource(pdev,\n\t\t\t\t\t\tIORESOURCE_IRQ, ++irqres);\n\t\t} while (irq_cnt < pdata->channel_num && chanirq_res);\n\t}\n\n\t \n\tfor (i = 0; i < irq_cnt; i++) {\n\t\terr = sh_dmae_chan_probe(shdev, i, chan_irq[i], chan_flag[i]);\n\t\tif (err)\n\t\t\tgoto chan_probe_err;\n\t}\n\n\tif (irq_cap)\n\t\tdev_notice(&pdev->dev, \"Attempting to register %d DMA \"\n\t\t\t   \"channels when a maximum of %d are supported.\\n\",\n\t\t\t   pdata->channel_num, SH_DMAE_MAX_CHANNELS);\n\n\tpm_runtime_put(&pdev->dev);\n\n\terr = dma_async_device_register(&shdev->shdma_dev.dma_dev);\n\tif (err < 0)\n\t\tgoto edmadevreg;\n\n\treturn err;\n\nedmadevreg:\n\tpm_runtime_get(&pdev->dev);\n\nchan_probe_err:\n\tsh_dmae_chan_remove(shdev);\n\neirq_err:\nrst_err:\n\tspin_lock_irq(&sh_dmae_lock);\n\tlist_del_rcu(&shdev->node);\n\tspin_unlock_irq(&sh_dmae_lock);\n\n\tpm_runtime_put(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\n\tshdma_cleanup(&shdev->shdma_dev);\neshdma:\n\tsynchronize_rcu();\n\n\treturn err;\n}\n\nstatic int sh_dmae_remove(struct platform_device *pdev)\n{\n\tstruct sh_dmae_device *shdev = platform_get_drvdata(pdev);\n\tstruct dma_device *dma_dev = &shdev->shdma_dev.dma_dev;\n\n\tdma_async_device_unregister(dma_dev);\n\n\tspin_lock_irq(&sh_dmae_lock);\n\tlist_del_rcu(&shdev->node);\n\tspin_unlock_irq(&sh_dmae_lock);\n\n\tpm_runtime_disable(&pdev->dev);\n\n\tsh_dmae_chan_remove(shdev);\n\tshdma_cleanup(&shdev->shdma_dev);\n\n\tsynchronize_rcu();\n\n\treturn 0;\n}\n\nstatic struct platform_driver sh_dmae_driver = {\n\t.driver\t\t= {\n\t\t.pm\t= &sh_dmae_pm,\n\t\t.name\t= SH_DMAE_DRV_NAME,\n\t},\n\t.remove\t\t= sh_dmae_remove,\n};\n\nstatic int __init sh_dmae_init(void)\n{\n\t \n\tint err = register_die_notifier(&sh_dmae_nmi_notifier);\n\tif (err)\n\t\treturn err;\n\n\treturn platform_driver_probe(&sh_dmae_driver, sh_dmae_probe);\n}\nmodule_init(sh_dmae_init);\n\nstatic void __exit sh_dmae_exit(void)\n{\n\tplatform_driver_unregister(&sh_dmae_driver);\n\n\tunregister_die_notifier(&sh_dmae_nmi_notifier);\n}\nmodule_exit(sh_dmae_exit);\n\nMODULE_AUTHOR(\"Nobuhiro Iwamatsu <iwamatsu.nobuhiro@renesas.com>\");\nMODULE_DESCRIPTION(\"Renesas SH DMA Engine driver\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"platform:\" SH_DMAE_DRV_NAME);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}