{
  "module_name": "rz-dmac.c",
  "hash_id": "7e258ecc55485db16bb071a01f07b980578a4217f3627d93d724ef1ab4364d8b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/sh/rz-dmac.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmaengine.h>\n#include <linux/interrupt.h>\n#include <linux/iopoll.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_dma.h>\n#include <linux/of_platform.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/reset.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n\n#include \"../dmaengine.h\"\n#include \"../virt-dma.h\"\n\nenum  rz_dmac_prep_type {\n\tRZ_DMAC_DESC_MEMCPY,\n\tRZ_DMAC_DESC_SLAVE_SG,\n};\n\nstruct rz_lmdesc {\n\tu32 header;\n\tu32 sa;\n\tu32 da;\n\tu32 tb;\n\tu32 chcfg;\n\tu32 chitvl;\n\tu32 chext;\n\tu32 nxla;\n};\n\nstruct rz_dmac_desc {\n\tstruct virt_dma_desc vd;\n\tdma_addr_t src;\n\tdma_addr_t dest;\n\tsize_t len;\n\tstruct list_head node;\n\tenum dma_transfer_direction direction;\n\tenum rz_dmac_prep_type type;\n\t \n\tstruct scatterlist *sg;\n\tunsigned int sgcount;\n};\n\n#define to_rz_dmac_desc(d)\tcontainer_of(d, struct rz_dmac_desc, vd)\n\nstruct rz_dmac_chan {\n\tstruct virt_dma_chan vc;\n\tvoid __iomem *ch_base;\n\tvoid __iomem *ch_cmn_base;\n\tunsigned int index;\n\tint irq;\n\tstruct rz_dmac_desc *desc;\n\tint descs_allocated;\n\n\tdma_addr_t src_per_address;\n\tdma_addr_t dst_per_address;\n\n\tu32 chcfg;\n\tu32 chctrl;\n\tint mid_rid;\n\n\tstruct list_head ld_free;\n\tstruct list_head ld_queue;\n\tstruct list_head ld_active;\n\n\tstruct {\n\t\tstruct rz_lmdesc *base;\n\t\tstruct rz_lmdesc *head;\n\t\tstruct rz_lmdesc *tail;\n\t\tdma_addr_t base_dma;\n\t} lmdesc;\n};\n\n#define to_rz_dmac_chan(c)\tcontainer_of(c, struct rz_dmac_chan, vc.chan)\n\nstruct rz_dmac {\n\tstruct dma_device engine;\n\tstruct device *dev;\n\tstruct reset_control *rstc;\n\tvoid __iomem *base;\n\tvoid __iomem *ext_base;\n\n\tunsigned int n_channels;\n\tstruct rz_dmac_chan *channels;\n\n\tDECLARE_BITMAP(modules, 1024);\n};\n\n#define to_rz_dmac(d)\tcontainer_of(d, struct rz_dmac, engine)\n\n \n\n#define CHSTAT\t\t\t\t0x0024\n#define CHCTRL\t\t\t\t0x0028\n#define CHCFG\t\t\t\t0x002c\n#define NXLA\t\t\t\t0x0038\n\n#define DCTRL\t\t\t\t0x0000\n\n#define EACH_CHANNEL_OFFSET\t\t0x0040\n#define CHANNEL_0_7_OFFSET\t\t0x0000\n#define CHANNEL_0_7_COMMON_BASE\t\t0x0300\n#define CHANNEL_8_15_OFFSET\t\t0x0400\n#define CHANNEL_8_15_COMMON_BASE\t0x0700\n\n#define CHSTAT_ER\t\t\tBIT(4)\n#define CHSTAT_EN\t\t\tBIT(0)\n\n#define CHCTRL_CLRINTMSK\t\tBIT(17)\n#define CHCTRL_CLRSUS\t\t\tBIT(9)\n#define CHCTRL_CLRTC\t\t\tBIT(6)\n#define CHCTRL_CLREND\t\t\tBIT(5)\n#define CHCTRL_CLRRQ\t\t\tBIT(4)\n#define CHCTRL_SWRST\t\t\tBIT(3)\n#define CHCTRL_STG\t\t\tBIT(2)\n#define CHCTRL_CLREN\t\t\tBIT(1)\n#define CHCTRL_SETEN\t\t\tBIT(0)\n#define CHCTRL_DEFAULT\t\t\t(CHCTRL_CLRINTMSK | CHCTRL_CLRSUS | \\\n\t\t\t\t\t CHCTRL_CLRTC |\tCHCTRL_CLREND | \\\n\t\t\t\t\t CHCTRL_CLRRQ | CHCTRL_SWRST | \\\n\t\t\t\t\t CHCTRL_CLREN)\n\n#define CHCFG_DMS\t\t\tBIT(31)\n#define CHCFG_DEM\t\t\tBIT(24)\n#define CHCFG_DAD\t\t\tBIT(21)\n#define CHCFG_SAD\t\t\tBIT(20)\n#define CHCFG_REQD\t\t\tBIT(3)\n#define CHCFG_SEL(bits)\t\t\t((bits) & 0x07)\n#define CHCFG_MEM_COPY\t\t\t(0x80400008)\n#define CHCFG_FILL_DDS_MASK\t\tGENMASK(19, 16)\n#define CHCFG_FILL_SDS_MASK\t\tGENMASK(15, 12)\n#define CHCFG_FILL_TM(a)\t\t(((a) & BIT(5)) << 22)\n#define CHCFG_FILL_AM(a)\t\t(((a) & GENMASK(4, 2)) << 6)\n#define CHCFG_FILL_LVL(a)\t\t(((a) & BIT(1)) << 5)\n#define CHCFG_FILL_HIEN(a)\t\t(((a) & BIT(0)) << 5)\n\n#define MID_RID_MASK\t\t\tGENMASK(9, 0)\n#define CHCFG_MASK\t\t\tGENMASK(15, 10)\n#define CHCFG_DS_INVALID\t\t0xFF\n#define DCTRL_LVINT\t\t\tBIT(1)\n#define DCTRL_PR\t\t\tBIT(0)\n#define DCTRL_DEFAULT\t\t\t(DCTRL_LVINT | DCTRL_PR)\n\n \n#define HEADER_LV\t\t\tBIT(0)\n\n#define RZ_DMAC_MAX_CHAN_DESCRIPTORS\t16\n#define RZ_DMAC_MAX_CHANNELS\t\t16\n#define DMAC_NR_LMDESC\t\t\t64\n\n \n\nstatic void rz_dmac_writel(struct rz_dmac *dmac, unsigned int val,\n\t\t\t   unsigned int offset)\n{\n\twritel(val, dmac->base + offset);\n}\n\nstatic void rz_dmac_ext_writel(struct rz_dmac *dmac, unsigned int val,\n\t\t\t       unsigned int offset)\n{\n\twritel(val, dmac->ext_base + offset);\n}\n\nstatic u32 rz_dmac_ext_readl(struct rz_dmac *dmac, unsigned int offset)\n{\n\treturn readl(dmac->ext_base + offset);\n}\n\nstatic void rz_dmac_ch_writel(struct rz_dmac_chan *channel, unsigned int val,\n\t\t\t      unsigned int offset, int which)\n{\n\tif (which)\n\t\twritel(val, channel->ch_base + offset);\n\telse\n\t\twritel(val, channel->ch_cmn_base + offset);\n}\n\nstatic u32 rz_dmac_ch_readl(struct rz_dmac_chan *channel,\n\t\t\t    unsigned int offset, int which)\n{\n\tif (which)\n\t\treturn readl(channel->ch_base + offset);\n\telse\n\t\treturn readl(channel->ch_cmn_base + offset);\n}\n\n \n\nstatic void rz_lmdesc_setup(struct rz_dmac_chan *channel,\n\t\t\t    struct rz_lmdesc *lmdesc)\n{\n\tu32 nxla;\n\n\tchannel->lmdesc.base = lmdesc;\n\tchannel->lmdesc.head = lmdesc;\n\tchannel->lmdesc.tail = lmdesc;\n\tnxla = channel->lmdesc.base_dma;\n\twhile (lmdesc < (channel->lmdesc.base + (DMAC_NR_LMDESC - 1))) {\n\t\tlmdesc->header = 0;\n\t\tnxla += sizeof(*lmdesc);\n\t\tlmdesc->nxla = nxla;\n\t\tlmdesc++;\n\t}\n\n\tlmdesc->header = 0;\n\tlmdesc->nxla = channel->lmdesc.base_dma;\n}\n\n \n\nstatic void rz_dmac_lmdesc_recycle(struct rz_dmac_chan *channel)\n{\n\tstruct rz_lmdesc *lmdesc = channel->lmdesc.head;\n\n\twhile (!(lmdesc->header & HEADER_LV)) {\n\t\tlmdesc->header = 0;\n\t\tlmdesc++;\n\t\tif (lmdesc >= (channel->lmdesc.base + DMAC_NR_LMDESC))\n\t\t\tlmdesc = channel->lmdesc.base;\n\t}\n\tchannel->lmdesc.head = lmdesc;\n}\n\nstatic void rz_dmac_enable_hw(struct rz_dmac_chan *channel)\n{\n\tstruct dma_chan *chan = &channel->vc.chan;\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tunsigned long flags;\n\tu32 nxla;\n\tu32 chctrl;\n\tu32 chstat;\n\n\tdev_dbg(dmac->dev, \"%s channel %d\\n\", __func__, channel->index);\n\n\tlocal_irq_save(flags);\n\n\trz_dmac_lmdesc_recycle(channel);\n\n\tnxla = channel->lmdesc.base_dma +\n\t\t(sizeof(struct rz_lmdesc) * (channel->lmdesc.head -\n\t\t\t\t\t     channel->lmdesc.base));\n\n\tchstat = rz_dmac_ch_readl(channel, CHSTAT, 1);\n\tif (!(chstat & CHSTAT_EN)) {\n\t\tchctrl = (channel->chctrl | CHCTRL_SETEN);\n\t\trz_dmac_ch_writel(channel, nxla, NXLA, 1);\n\t\trz_dmac_ch_writel(channel, channel->chcfg, CHCFG, 1);\n\t\trz_dmac_ch_writel(channel, CHCTRL_SWRST, CHCTRL, 1);\n\t\trz_dmac_ch_writel(channel, chctrl, CHCTRL, 1);\n\t}\n\n\tlocal_irq_restore(flags);\n}\n\nstatic void rz_dmac_disable_hw(struct rz_dmac_chan *channel)\n{\n\tstruct dma_chan *chan = &channel->vc.chan;\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tunsigned long flags;\n\n\tdev_dbg(dmac->dev, \"%s channel %d\\n\", __func__, channel->index);\n\n\tlocal_irq_save(flags);\n\trz_dmac_ch_writel(channel, CHCTRL_DEFAULT, CHCTRL, 1);\n\tlocal_irq_restore(flags);\n}\n\nstatic void rz_dmac_set_dmars_register(struct rz_dmac *dmac, int nr, u32 dmars)\n{\n\tu32 dmars_offset = (nr / 2) * 4;\n\tu32 shift = (nr % 2) * 16;\n\tu32 dmars32;\n\n\tdmars32 = rz_dmac_ext_readl(dmac, dmars_offset);\n\tdmars32 &= ~(0xffff << shift);\n\tdmars32 |= dmars << shift;\n\n\trz_dmac_ext_writel(dmac, dmars32, dmars_offset);\n}\n\nstatic void rz_dmac_prepare_desc_for_memcpy(struct rz_dmac_chan *channel)\n{\n\tstruct dma_chan *chan = &channel->vc.chan;\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tstruct rz_lmdesc *lmdesc = channel->lmdesc.tail;\n\tstruct rz_dmac_desc *d = channel->desc;\n\tu32 chcfg = CHCFG_MEM_COPY;\n\n\t \n\tlmdesc->sa = d->src;\n\tlmdesc->da = d->dest;\n\tlmdesc->tb = d->len;\n\tlmdesc->chcfg = chcfg;\n\tlmdesc->chitvl = 0;\n\tlmdesc->chext = 0;\n\tlmdesc->header = HEADER_LV;\n\n\trz_dmac_set_dmars_register(dmac, channel->index, 0);\n\n\tchannel->chcfg = chcfg;\n\tchannel->chctrl = CHCTRL_STG | CHCTRL_SETEN;\n}\n\nstatic void rz_dmac_prepare_descs_for_slave_sg(struct rz_dmac_chan *channel)\n{\n\tstruct dma_chan *chan = &channel->vc.chan;\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tstruct rz_dmac_desc *d = channel->desc;\n\tstruct scatterlist *sg, *sgl = d->sg;\n\tstruct rz_lmdesc *lmdesc;\n\tunsigned int i, sg_len = d->sgcount;\n\n\tchannel->chcfg |= CHCFG_SEL(channel->index) | CHCFG_DEM | CHCFG_DMS;\n\n\tif (d->direction == DMA_DEV_TO_MEM) {\n\t\tchannel->chcfg |= CHCFG_SAD;\n\t\tchannel->chcfg &= ~CHCFG_REQD;\n\t} else {\n\t\tchannel->chcfg |= CHCFG_DAD | CHCFG_REQD;\n\t}\n\n\tlmdesc = channel->lmdesc.tail;\n\n\tfor (i = 0, sg = sgl; i < sg_len; i++, sg = sg_next(sg)) {\n\t\tif (d->direction == DMA_DEV_TO_MEM) {\n\t\t\tlmdesc->sa = channel->src_per_address;\n\t\t\tlmdesc->da = sg_dma_address(sg);\n\t\t} else {\n\t\t\tlmdesc->sa = sg_dma_address(sg);\n\t\t\tlmdesc->da = channel->dst_per_address;\n\t\t}\n\n\t\tlmdesc->tb = sg_dma_len(sg);\n\t\tlmdesc->chitvl = 0;\n\t\tlmdesc->chext = 0;\n\t\tif (i == (sg_len - 1)) {\n\t\t\tlmdesc->chcfg = (channel->chcfg & ~CHCFG_DEM);\n\t\t\tlmdesc->header = HEADER_LV;\n\t\t} else {\n\t\t\tlmdesc->chcfg = channel->chcfg;\n\t\t\tlmdesc->header = HEADER_LV;\n\t\t}\n\t\tif (++lmdesc >= (channel->lmdesc.base + DMAC_NR_LMDESC))\n\t\t\tlmdesc = channel->lmdesc.base;\n\t}\n\n\tchannel->lmdesc.tail = lmdesc;\n\n\trz_dmac_set_dmars_register(dmac, channel->index, channel->mid_rid);\n\tchannel->chctrl = CHCTRL_SETEN;\n}\n\nstatic int rz_dmac_xfer_desc(struct rz_dmac_chan *chan)\n{\n\tstruct rz_dmac_desc *d = chan->desc;\n\tstruct virt_dma_desc *vd;\n\n\tvd = vchan_next_desc(&chan->vc);\n\tif (!vd)\n\t\treturn 0;\n\n\tlist_del(&vd->node);\n\n\tswitch (d->type) {\n\tcase RZ_DMAC_DESC_MEMCPY:\n\t\trz_dmac_prepare_desc_for_memcpy(chan);\n\t\tbreak;\n\n\tcase RZ_DMAC_DESC_SLAVE_SG:\n\t\trz_dmac_prepare_descs_for_slave_sg(chan);\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\trz_dmac_enable_hw(chan);\n\n\treturn 0;\n}\n\n \n\nstatic int rz_dmac_alloc_chan_resources(struct dma_chan *chan)\n{\n\tstruct rz_dmac_chan *channel = to_rz_dmac_chan(chan);\n\n\twhile (channel->descs_allocated < RZ_DMAC_MAX_CHAN_DESCRIPTORS) {\n\t\tstruct rz_dmac_desc *desc;\n\n\t\tdesc = kzalloc(sizeof(*desc), GFP_KERNEL);\n\t\tif (!desc)\n\t\t\tbreak;\n\n\t\tlist_add_tail(&desc->node, &channel->ld_free);\n\t\tchannel->descs_allocated++;\n\t}\n\n\tif (!channel->descs_allocated)\n\t\treturn -ENOMEM;\n\n\treturn channel->descs_allocated;\n}\n\nstatic void rz_dmac_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct rz_dmac_chan *channel = to_rz_dmac_chan(chan);\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tstruct rz_lmdesc *lmdesc = channel->lmdesc.base;\n\tstruct rz_dmac_desc *desc, *_desc;\n\tunsigned long flags;\n\tunsigned int i;\n\n\tspin_lock_irqsave(&channel->vc.lock, flags);\n\n\tfor (i = 0; i < DMAC_NR_LMDESC; i++)\n\t\tlmdesc[i].header = 0;\n\n\trz_dmac_disable_hw(channel);\n\tlist_splice_tail_init(&channel->ld_active, &channel->ld_free);\n\tlist_splice_tail_init(&channel->ld_queue, &channel->ld_free);\n\n\tif (channel->mid_rid >= 0) {\n\t\tclear_bit(channel->mid_rid, dmac->modules);\n\t\tchannel->mid_rid = -EINVAL;\n\t}\n\n\tspin_unlock_irqrestore(&channel->vc.lock, flags);\n\n\tlist_for_each_entry_safe(desc, _desc, &channel->ld_free, node) {\n\t\tkfree(desc);\n\t\tchannel->descs_allocated--;\n\t}\n\n\tINIT_LIST_HEAD(&channel->ld_free);\n\tvchan_free_chan_resources(&channel->vc);\n}\n\nstatic struct dma_async_tx_descriptor *\nrz_dmac_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest, dma_addr_t src,\n\t\t\tsize_t len, unsigned long flags)\n{\n\tstruct rz_dmac_chan *channel = to_rz_dmac_chan(chan);\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tstruct rz_dmac_desc *desc;\n\n\tdev_dbg(dmac->dev, \"%s channel: %d src=0x%pad dst=0x%pad len=%zu\\n\",\n\t\t__func__, channel->index, &src, &dest, len);\n\n\tif (list_empty(&channel->ld_free))\n\t\treturn NULL;\n\n\tdesc = list_first_entry(&channel->ld_free, struct rz_dmac_desc, node);\n\n\tdesc->type = RZ_DMAC_DESC_MEMCPY;\n\tdesc->src = src;\n\tdesc->dest = dest;\n\tdesc->len = len;\n\tdesc->direction = DMA_MEM_TO_MEM;\n\n\tlist_move_tail(channel->ld_free.next, &channel->ld_queue);\n\treturn vchan_tx_prep(&channel->vc, &desc->vd, flags);\n}\n\nstatic struct dma_async_tx_descriptor *\nrz_dmac_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,\n\t\t      unsigned int sg_len,\n\t\t      enum dma_transfer_direction direction,\n\t\t      unsigned long flags, void *context)\n{\n\tstruct rz_dmac_chan *channel = to_rz_dmac_chan(chan);\n\tstruct rz_dmac_desc *desc;\n\tstruct scatterlist *sg;\n\tint dma_length = 0;\n\tint i = 0;\n\n\tif (list_empty(&channel->ld_free))\n\t\treturn NULL;\n\n\tdesc = list_first_entry(&channel->ld_free, struct rz_dmac_desc, node);\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tdma_length += sg_dma_len(sg);\n\t}\n\n\tdesc->type = RZ_DMAC_DESC_SLAVE_SG;\n\tdesc->sg = sgl;\n\tdesc->sgcount = sg_len;\n\tdesc->len = dma_length;\n\tdesc->direction = direction;\n\n\tif (direction == DMA_DEV_TO_MEM)\n\t\tdesc->src = channel->src_per_address;\n\telse\n\t\tdesc->dest = channel->dst_per_address;\n\n\tlist_move_tail(channel->ld_free.next, &channel->ld_queue);\n\treturn vchan_tx_prep(&channel->vc, &desc->vd, flags);\n}\n\nstatic int rz_dmac_terminate_all(struct dma_chan *chan)\n{\n\tstruct rz_dmac_chan *channel = to_rz_dmac_chan(chan);\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\trz_dmac_disable_hw(channel);\n\tspin_lock_irqsave(&channel->vc.lock, flags);\n\tlist_splice_tail_init(&channel->ld_active, &channel->ld_free);\n\tlist_splice_tail_init(&channel->ld_queue, &channel->ld_free);\n\tspin_unlock_irqrestore(&channel->vc.lock, flags);\n\tvchan_get_all_descriptors(&channel->vc, &head);\n\tvchan_dma_desc_free_list(&channel->vc, &head);\n\n\treturn 0;\n}\n\nstatic void rz_dmac_issue_pending(struct dma_chan *chan)\n{\n\tstruct rz_dmac_chan *channel = to_rz_dmac_chan(chan);\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tstruct rz_dmac_desc *desc;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&channel->vc.lock, flags);\n\n\tif (!list_empty(&channel->ld_queue)) {\n\t\tdesc = list_first_entry(&channel->ld_queue,\n\t\t\t\t\tstruct rz_dmac_desc, node);\n\t\tchannel->desc = desc;\n\t\tif (vchan_issue_pending(&channel->vc)) {\n\t\t\tif (rz_dmac_xfer_desc(channel) < 0)\n\t\t\t\tdev_warn(dmac->dev, \"ch: %d couldn't issue DMA xfer\\n\",\n\t\t\t\t\t channel->index);\n\t\t\telse\n\t\t\t\tlist_move_tail(channel->ld_queue.next,\n\t\t\t\t\t       &channel->ld_active);\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&channel->vc.lock, flags);\n}\n\nstatic u8 rz_dmac_ds_to_val_mapping(enum dma_slave_buswidth ds)\n{\n\tu8 i;\n\tstatic const enum dma_slave_buswidth ds_lut[] = {\n\t\tDMA_SLAVE_BUSWIDTH_1_BYTE,\n\t\tDMA_SLAVE_BUSWIDTH_2_BYTES,\n\t\tDMA_SLAVE_BUSWIDTH_4_BYTES,\n\t\tDMA_SLAVE_BUSWIDTH_8_BYTES,\n\t\tDMA_SLAVE_BUSWIDTH_16_BYTES,\n\t\tDMA_SLAVE_BUSWIDTH_32_BYTES,\n\t\tDMA_SLAVE_BUSWIDTH_64_BYTES,\n\t\tDMA_SLAVE_BUSWIDTH_128_BYTES,\n\t};\n\n\tfor (i = 0; i < ARRAY_SIZE(ds_lut); i++) {\n\t\tif (ds_lut[i] == ds)\n\t\t\treturn i;\n\t}\n\n\treturn CHCFG_DS_INVALID;\n}\n\nstatic int rz_dmac_config(struct dma_chan *chan,\n\t\t\t  struct dma_slave_config *config)\n{\n\tstruct rz_dmac_chan *channel = to_rz_dmac_chan(chan);\n\tu32 val;\n\n\tchannel->src_per_address = config->src_addr;\n\tchannel->dst_per_address = config->dst_addr;\n\n\tval = rz_dmac_ds_to_val_mapping(config->dst_addr_width);\n\tif (val == CHCFG_DS_INVALID)\n\t\treturn -EINVAL;\n\n\tchannel->chcfg &= ~CHCFG_FILL_DDS_MASK;\n\tchannel->chcfg |= FIELD_PREP(CHCFG_FILL_DDS_MASK, val);\n\n\tval = rz_dmac_ds_to_val_mapping(config->src_addr_width);\n\tif (val == CHCFG_DS_INVALID)\n\t\treturn -EINVAL;\n\n\tchannel->chcfg &= ~CHCFG_FILL_SDS_MASK;\n\tchannel->chcfg |= FIELD_PREP(CHCFG_FILL_SDS_MASK, val);\n\n\treturn 0;\n}\n\nstatic void rz_dmac_virt_desc_free(struct virt_dma_desc *vd)\n{\n\t \n}\n\nstatic void rz_dmac_device_synchronize(struct dma_chan *chan)\n{\n\tstruct rz_dmac_chan *channel = to_rz_dmac_chan(chan);\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tu32 chstat;\n\tint ret;\n\n\tret = read_poll_timeout(rz_dmac_ch_readl, chstat, !(chstat & CHSTAT_EN),\n\t\t\t\t100, 100000, false, channel, CHSTAT, 1);\n\tif (ret < 0)\n\t\tdev_warn(dmac->dev, \"DMA Timeout\");\n\n\trz_dmac_set_dmars_register(dmac, channel->index, 0);\n}\n\n \n\nstatic void rz_dmac_irq_handle_channel(struct rz_dmac_chan *channel)\n{\n\tstruct dma_chan *chan = &channel->vc.chan;\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tu32 chstat, chctrl;\n\n\tchstat = rz_dmac_ch_readl(channel, CHSTAT, 1);\n\tif (chstat & CHSTAT_ER) {\n\t\tdev_err(dmac->dev, \"DMAC err CHSTAT_%d = %08X\\n\",\n\t\t\tchannel->index, chstat);\n\t\trz_dmac_ch_writel(channel, CHCTRL_DEFAULT, CHCTRL, 1);\n\t\tgoto done;\n\t}\n\n\tchctrl = rz_dmac_ch_readl(channel, CHCTRL, 1);\n\trz_dmac_ch_writel(channel, chctrl | CHCTRL_CLREND, CHCTRL, 1);\ndone:\n\treturn;\n}\n\nstatic irqreturn_t rz_dmac_irq_handler(int irq, void *dev_id)\n{\n\tstruct rz_dmac_chan *channel = dev_id;\n\n\tif (channel) {\n\t\trz_dmac_irq_handle_channel(channel);\n\t\treturn IRQ_WAKE_THREAD;\n\t}\n\t \n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t rz_dmac_irq_handler_thread(int irq, void *dev_id)\n{\n\tstruct rz_dmac_chan *channel = dev_id;\n\tstruct rz_dmac_desc *desc = NULL;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&channel->vc.lock, flags);\n\n\tif (list_empty(&channel->ld_active)) {\n\t\t \n\t\tgoto out;\n\t}\n\n\tdesc = list_first_entry(&channel->ld_active, struct rz_dmac_desc, node);\n\tvchan_cookie_complete(&desc->vd);\n\tlist_move_tail(channel->ld_active.next, &channel->ld_free);\n\tif (!list_empty(&channel->ld_queue)) {\n\t\tdesc = list_first_entry(&channel->ld_queue, struct rz_dmac_desc,\n\t\t\t\t\tnode);\n\t\tchannel->desc = desc;\n\t\tif (rz_dmac_xfer_desc(channel) == 0)\n\t\t\tlist_move_tail(channel->ld_queue.next, &channel->ld_active);\n\t}\nout:\n\tspin_unlock_irqrestore(&channel->vc.lock, flags);\n\n\treturn IRQ_HANDLED;\n}\n\n \n\nstatic bool rz_dmac_chan_filter(struct dma_chan *chan, void *arg)\n{\n\tstruct rz_dmac_chan *channel = to_rz_dmac_chan(chan);\n\tstruct rz_dmac *dmac = to_rz_dmac(chan->device);\n\tstruct of_phandle_args *dma_spec = arg;\n\tu32 ch_cfg;\n\n\tchannel->mid_rid = dma_spec->args[0] & MID_RID_MASK;\n\tch_cfg = (dma_spec->args[0] & CHCFG_MASK) >> 10;\n\tchannel->chcfg = CHCFG_FILL_TM(ch_cfg) | CHCFG_FILL_AM(ch_cfg) |\n\t\t\t CHCFG_FILL_LVL(ch_cfg) | CHCFG_FILL_HIEN(ch_cfg);\n\n\treturn !test_and_set_bit(channel->mid_rid, dmac->modules);\n}\n\nstatic struct dma_chan *rz_dmac_of_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t\t struct of_dma *ofdma)\n{\n\tdma_cap_mask_t mask;\n\n\tif (dma_spec->args_count != 1)\n\t\treturn NULL;\n\n\t \n\tdma_cap_zero(mask);\n\tdma_cap_set(DMA_SLAVE, mask);\n\n\treturn dma_request_channel(mask, rz_dmac_chan_filter, dma_spec);\n}\n\n \n\nstatic int rz_dmac_chan_probe(struct rz_dmac *dmac,\n\t\t\t      struct rz_dmac_chan *channel,\n\t\t\t      unsigned int index)\n{\n\tstruct platform_device *pdev = to_platform_device(dmac->dev);\n\tstruct rz_lmdesc *lmdesc;\n\tchar pdev_irqname[5];\n\tchar *irqname;\n\tint ret;\n\n\tchannel->index = index;\n\tchannel->mid_rid = -EINVAL;\n\n\t \n\tsprintf(pdev_irqname, \"ch%u\", index);\n\tchannel->irq = platform_get_irq_byname(pdev, pdev_irqname);\n\tif (channel->irq < 0)\n\t\treturn channel->irq;\n\n\tirqname = devm_kasprintf(dmac->dev, GFP_KERNEL, \"%s:%u\",\n\t\t\t\t dev_name(dmac->dev), index);\n\tif (!irqname)\n\t\treturn -ENOMEM;\n\n\tret = devm_request_threaded_irq(dmac->dev, channel->irq,\n\t\t\t\t\trz_dmac_irq_handler,\n\t\t\t\t\trz_dmac_irq_handler_thread, 0,\n\t\t\t\t\tirqname, channel);\n\tif (ret) {\n\t\tdev_err(dmac->dev, \"failed to request IRQ %u (%d)\\n\",\n\t\t\tchannel->irq, ret);\n\t\treturn ret;\n\t}\n\n\t \n\tif (index < 8) {\n\t\tchannel->ch_base = dmac->base + CHANNEL_0_7_OFFSET +\n\t\t\tEACH_CHANNEL_OFFSET * index;\n\t\tchannel->ch_cmn_base = dmac->base + CHANNEL_0_7_COMMON_BASE;\n\t} else {\n\t\tchannel->ch_base = dmac->base + CHANNEL_8_15_OFFSET +\n\t\t\tEACH_CHANNEL_OFFSET * (index - 8);\n\t\tchannel->ch_cmn_base = dmac->base + CHANNEL_8_15_COMMON_BASE;\n\t}\n\n\t \n\tlmdesc = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t    sizeof(struct rz_lmdesc) * DMAC_NR_LMDESC,\n\t\t\t\t    &channel->lmdesc.base_dma, GFP_KERNEL);\n\tif (!lmdesc) {\n\t\tdev_err(&pdev->dev, \"Can't allocate memory (lmdesc)\\n\");\n\t\treturn -ENOMEM;\n\t}\n\trz_lmdesc_setup(channel, lmdesc);\n\n\t \n\trz_dmac_ch_writel(channel, CHCTRL_DEFAULT, CHCTRL, 1);\n\n\tchannel->vc.desc_free = rz_dmac_virt_desc_free;\n\tvchan_init(&channel->vc, &dmac->engine);\n\tINIT_LIST_HEAD(&channel->ld_queue);\n\tINIT_LIST_HEAD(&channel->ld_free);\n\tINIT_LIST_HEAD(&channel->ld_active);\n\n\treturn 0;\n}\n\nstatic int rz_dmac_parse_of(struct device *dev, struct rz_dmac *dmac)\n{\n\tstruct device_node *np = dev->of_node;\n\tint ret;\n\n\tret = of_property_read_u32(np, \"dma-channels\", &dmac->n_channels);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"unable to read dma-channels property\\n\");\n\t\treturn ret;\n\t}\n\n\tif (!dmac->n_channels || dmac->n_channels > RZ_DMAC_MAX_CHANNELS) {\n\t\tdev_err(dev, \"invalid number of channels %u\\n\", dmac->n_channels);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int rz_dmac_probe(struct platform_device *pdev)\n{\n\tconst char *irqname = \"error\";\n\tstruct dma_device *engine;\n\tstruct rz_dmac *dmac;\n\tint channel_num;\n\tunsigned int i;\n\tint ret;\n\tint irq;\n\n\tdmac = devm_kzalloc(&pdev->dev, sizeof(*dmac), GFP_KERNEL);\n\tif (!dmac)\n\t\treturn -ENOMEM;\n\n\tdmac->dev = &pdev->dev;\n\tplatform_set_drvdata(pdev, dmac);\n\n\tret = rz_dmac_parse_of(&pdev->dev, dmac);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tdmac->channels = devm_kcalloc(&pdev->dev, dmac->n_channels,\n\t\t\t\t      sizeof(*dmac->channels), GFP_KERNEL);\n\tif (!dmac->channels)\n\t\treturn -ENOMEM;\n\n\t \n\tdmac->base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(dmac->base))\n\t\treturn PTR_ERR(dmac->base);\n\n\tdmac->ext_base = devm_platform_ioremap_resource(pdev, 1);\n\tif (IS_ERR(dmac->ext_base))\n\t\treturn PTR_ERR(dmac->ext_base);\n\n\t \n\tirq = platform_get_irq_byname(pdev, irqname);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tret = devm_request_irq(&pdev->dev, irq, rz_dmac_irq_handler, 0,\n\t\t\t       irqname, NULL);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed to request IRQ %u (%d)\\n\",\n\t\t\tirq, ret);\n\t\treturn ret;\n\t}\n\n\t \n\tINIT_LIST_HEAD(&dmac->engine.channels);\n\n\tdmac->rstc = devm_reset_control_array_get_exclusive(&pdev->dev);\n\tif (IS_ERR(dmac->rstc))\n\t\treturn dev_err_probe(&pdev->dev, PTR_ERR(dmac->rstc),\n\t\t\t\t     \"failed to get resets\\n\");\n\n\tpm_runtime_enable(&pdev->dev);\n\tret = pm_runtime_resume_and_get(&pdev->dev);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"pm_runtime_resume_and_get failed\\n\");\n\t\tgoto err_pm_disable;\n\t}\n\n\tret = reset_control_deassert(dmac->rstc);\n\tif (ret)\n\t\tgoto err_pm_runtime_put;\n\n\tfor (i = 0; i < dmac->n_channels; i++) {\n\t\tret = rz_dmac_chan_probe(dmac, &dmac->channels[i], i);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\t}\n\n\t \n\tret = of_dma_controller_register(pdev->dev.of_node, rz_dmac_of_xlate,\n\t\t\t\t\t NULL);\n\tif (ret < 0)\n\t\tgoto err;\n\n\t \n\tengine = &dmac->engine;\n\tdma_cap_set(DMA_SLAVE, engine->cap_mask);\n\tdma_cap_set(DMA_MEMCPY, engine->cap_mask);\n\trz_dmac_writel(dmac, DCTRL_DEFAULT, CHANNEL_0_7_COMMON_BASE + DCTRL);\n\trz_dmac_writel(dmac, DCTRL_DEFAULT, CHANNEL_8_15_COMMON_BASE + DCTRL);\n\n\tengine->dev = &pdev->dev;\n\n\tengine->device_alloc_chan_resources = rz_dmac_alloc_chan_resources;\n\tengine->device_free_chan_resources = rz_dmac_free_chan_resources;\n\tengine->device_tx_status = dma_cookie_status;\n\tengine->device_prep_slave_sg = rz_dmac_prep_slave_sg;\n\tengine->device_prep_dma_memcpy = rz_dmac_prep_dma_memcpy;\n\tengine->device_config = rz_dmac_config;\n\tengine->device_terminate_all = rz_dmac_terminate_all;\n\tengine->device_issue_pending = rz_dmac_issue_pending;\n\tengine->device_synchronize = rz_dmac_device_synchronize;\n\n\tengine->copy_align = DMAENGINE_ALIGN_1_BYTE;\n\tdma_set_max_seg_size(engine->dev, U32_MAX);\n\n\tret = dma_async_device_register(engine);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"unable to register\\n\");\n\t\tgoto dma_register_err;\n\t}\n\treturn 0;\n\ndma_register_err:\n\tof_dma_controller_free(pdev->dev.of_node);\nerr:\n\tchannel_num = i ? i - 1 : 0;\n\tfor (i = 0; i < channel_num; i++) {\n\t\tstruct rz_dmac_chan *channel = &dmac->channels[i];\n\n\t\tdma_free_coherent(&pdev->dev,\n\t\t\t\t  sizeof(struct rz_lmdesc) * DMAC_NR_LMDESC,\n\t\t\t\t  channel->lmdesc.base,\n\t\t\t\t  channel->lmdesc.base_dma);\n\t}\n\n\treset_control_assert(dmac->rstc);\nerr_pm_runtime_put:\n\tpm_runtime_put(&pdev->dev);\nerr_pm_disable:\n\tpm_runtime_disable(&pdev->dev);\n\n\treturn ret;\n}\n\nstatic int rz_dmac_remove(struct platform_device *pdev)\n{\n\tstruct rz_dmac *dmac = platform_get_drvdata(pdev);\n\tunsigned int i;\n\n\tdma_async_device_unregister(&dmac->engine);\n\tof_dma_controller_free(pdev->dev.of_node);\n\tfor (i = 0; i < dmac->n_channels; i++) {\n\t\tstruct rz_dmac_chan *channel = &dmac->channels[i];\n\n\t\tdma_free_coherent(&pdev->dev,\n\t\t\t\t  sizeof(struct rz_lmdesc) * DMAC_NR_LMDESC,\n\t\t\t\t  channel->lmdesc.base,\n\t\t\t\t  channel->lmdesc.base_dma);\n\t}\n\treset_control_assert(dmac->rstc);\n\tpm_runtime_put(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id of_rz_dmac_match[] = {\n\t{ .compatible = \"renesas,rz-dmac\", },\n\t{   }\n};\nMODULE_DEVICE_TABLE(of, of_rz_dmac_match);\n\nstatic struct platform_driver rz_dmac_driver = {\n\t.driver\t\t= {\n\t\t.name\t= \"rz-dmac\",\n\t\t.of_match_table = of_rz_dmac_match,\n\t},\n\t.probe\t\t= rz_dmac_probe,\n\t.remove\t\t= rz_dmac_remove,\n};\n\nmodule_platform_driver(rz_dmac_driver);\n\nMODULE_DESCRIPTION(\"Renesas RZ/G2L DMA Controller Driver\");\nMODULE_AUTHOR(\"Biju Das <biju.das.jz@bp.renesas.com>\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}