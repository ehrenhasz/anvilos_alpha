{
  "module_name": "adma.c",
  "hash_id": "30a9e6579a08ab8ac0e98cc387e3155f8d72d5e984ba3e988127fed11eeaf7bb",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/ppc4xx/adma.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/async_tx.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/spinlock.h>\n#include <linux/interrupt.h>\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/proc_fs.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/platform_device.h>\n#include <asm/dcr.h>\n#include <asm/dcr-regs.h>\n#include \"adma.h\"\n#include \"../dmaengine.h\"\n\nenum ppc_adma_init_code {\n\tPPC_ADMA_INIT_OK = 0,\n\tPPC_ADMA_INIT_MEMRES,\n\tPPC_ADMA_INIT_MEMREG,\n\tPPC_ADMA_INIT_ALLOC,\n\tPPC_ADMA_INIT_COHERENT,\n\tPPC_ADMA_INIT_CHANNEL,\n\tPPC_ADMA_INIT_IRQ1,\n\tPPC_ADMA_INIT_IRQ2,\n\tPPC_ADMA_INIT_REGISTER\n};\n\nstatic char *ppc_adma_errors[] = {\n\t[PPC_ADMA_INIT_OK] = \"ok\",\n\t[PPC_ADMA_INIT_MEMRES] = \"failed to get memory resource\",\n\t[PPC_ADMA_INIT_MEMREG] = \"failed to request memory region\",\n\t[PPC_ADMA_INIT_ALLOC] = \"failed to allocate memory for adev \"\n\t\t\t\t\"structure\",\n\t[PPC_ADMA_INIT_COHERENT] = \"failed to allocate coherent memory for \"\n\t\t\t\t   \"hardware descriptors\",\n\t[PPC_ADMA_INIT_CHANNEL] = \"failed to allocate memory for channel\",\n\t[PPC_ADMA_INIT_IRQ1] = \"failed to request first irq\",\n\t[PPC_ADMA_INIT_IRQ2] = \"failed to request second irq\",\n\t[PPC_ADMA_INIT_REGISTER] = \"failed to register dma async device\",\n};\n\nstatic enum ppc_adma_init_code\nppc440spe_adma_devices[PPC440SPE_ADMA_ENGINES_NUM];\n\nstruct ppc_dma_chan_ref {\n\tstruct dma_chan *chan;\n\tstruct list_head node;\n};\n\n \nstatic struct list_head\nppc440spe_adma_chan_list = LIST_HEAD_INIT(ppc440spe_adma_chan_list);\n\n \nstatic u32 do_xor_refetch;\n\n \nstatic void *ppc440spe_dma_fifo_buf;\n\n \nstatic struct ppc440spe_adma_desc_slot *chan_last_sub[3];\nstatic struct ppc440spe_adma_desc_slot *chan_first_cdb[3];\n\n \nstatic struct ppc440spe_adma_desc_slot *xor_last_linked;\nstatic struct ppc440spe_adma_desc_slot *xor_last_submit;\n\n \nstatic char ppc440spe_qword[16];\n\nstatic atomic_t ppc440spe_adma_err_irq_ref;\nstatic dcr_host_t ppc440spe_mq_dcr_host;\nstatic unsigned int ppc440spe_mq_dcr_len;\n\n \nstatic unsigned long ppc440spe_rxor_state;\n\n \nstatic u32 ppc440spe_r6_enabled;\nstatic struct ppc440spe_adma_chan *ppc440spe_r6_tchan;\nstatic struct completion ppc440spe_r6_test_comp;\n\nstatic int ppc440spe_adma_dma2rxor_prep_src(\n\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\tstruct ppc440spe_rxor *cursor, int index,\n\t\tint src_cnt, u32 addr);\nstatic void ppc440spe_adma_dma2rxor_set_src(\n\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\tint index, dma_addr_t addr);\nstatic void ppc440spe_adma_dma2rxor_set_mult(\n\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\tint index, u8 mult);\n\n#ifdef ADMA_LL_DEBUG\n#define ADMA_LL_DBG(x) ({ if (1) x; 0; })\n#else\n#define ADMA_LL_DBG(x) ({ if (0) x; 0; })\n#endif\n\nstatic void print_cb(struct ppc440spe_adma_chan *chan, void *block)\n{\n\tstruct dma_cdb *cdb;\n\tstruct xor_cb *cb;\n\tint i;\n\n\tswitch (chan->device->id) {\n\tcase 0:\n\tcase 1:\n\t\tcdb = block;\n\n\t\tpr_debug(\"CDB at %p [%d]:\\n\"\n\t\t\t\"\\t attr 0x%02x opc 0x%02x cnt 0x%08x\\n\"\n\t\t\t\"\\t sg1u 0x%08x sg1l 0x%08x\\n\"\n\t\t\t\"\\t sg2u 0x%08x sg2l 0x%08x\\n\"\n\t\t\t\"\\t sg3u 0x%08x sg3l 0x%08x\\n\",\n\t\t\tcdb, chan->device->id,\n\t\t\tcdb->attr, cdb->opc, le32_to_cpu(cdb->cnt),\n\t\t\tle32_to_cpu(cdb->sg1u), le32_to_cpu(cdb->sg1l),\n\t\t\tle32_to_cpu(cdb->sg2u), le32_to_cpu(cdb->sg2l),\n\t\t\tle32_to_cpu(cdb->sg3u), le32_to_cpu(cdb->sg3l)\n\t\t);\n\t\tbreak;\n\tcase 2:\n\t\tcb = block;\n\n\t\tpr_debug(\"CB at %p [%d]:\\n\"\n\t\t\t\"\\t cbc 0x%08x cbbc 0x%08x cbs 0x%08x\\n\"\n\t\t\t\"\\t cbtah 0x%08x cbtal 0x%08x\\n\"\n\t\t\t\"\\t cblah 0x%08x cblal 0x%08x\\n\",\n\t\t\tcb, chan->device->id,\n\t\t\tcb->cbc, cb->cbbc, cb->cbs,\n\t\t\tcb->cbtah, cb->cbtal,\n\t\t\tcb->cblah, cb->cblal);\n\t\tfor (i = 0; i < 16; i++) {\n\t\t\tif (i && !cb->ops[i].h && !cb->ops[i].l)\n\t\t\t\tcontinue;\n\t\t\tpr_debug(\"\\t ops[%2d]: h 0x%08x l 0x%08x\\n\",\n\t\t\t\ti, cb->ops[i].h, cb->ops[i].l);\n\t\t}\n\t\tbreak;\n\t}\n}\n\nstatic void print_cb_list(struct ppc440spe_adma_chan *chan,\n\t\t\t  struct ppc440spe_adma_desc_slot *iter)\n{\n\tfor (; iter; iter = iter->hw_next)\n\t\tprint_cb(chan, iter->hw_desc);\n}\n\nstatic void prep_dma_xor_dbg(int id, dma_addr_t dst, dma_addr_t *src,\n\t\t\t     unsigned int src_cnt)\n{\n\tint i;\n\n\tpr_debug(\"\\n%s(%d):\\nsrc: \", __func__, id);\n\tfor (i = 0; i < src_cnt; i++)\n\t\tpr_debug(\"\\t0x%016llx \", src[i]);\n\tpr_debug(\"dst:\\n\\t0x%016llx\\n\", dst);\n}\n\nstatic void prep_dma_pq_dbg(int id, dma_addr_t *dst, dma_addr_t *src,\n\t\t\t    unsigned int src_cnt)\n{\n\tint i;\n\n\tpr_debug(\"\\n%s(%d):\\nsrc: \", __func__, id);\n\tfor (i = 0; i < src_cnt; i++)\n\t\tpr_debug(\"\\t0x%016llx \", src[i]);\n\tpr_debug(\"dst: \");\n\tfor (i = 0; i < 2; i++)\n\t\tpr_debug(\"\\t0x%016llx \", dst[i]);\n}\n\nstatic void prep_dma_pqzero_sum_dbg(int id, dma_addr_t *src,\n\t\t\t\t    unsigned int src_cnt,\n\t\t\t\t    const unsigned char *scf)\n{\n\tint i;\n\n\tpr_debug(\"\\n%s(%d):\\nsrc(coef): \", __func__, id);\n\tif (scf) {\n\t\tfor (i = 0; i < src_cnt; i++)\n\t\t\tpr_debug(\"\\t0x%016llx(0x%02x) \", src[i], scf[i]);\n\t} else {\n\t\tfor (i = 0; i < src_cnt; i++)\n\t\t\tpr_debug(\"\\t0x%016llx(no) \", src[i]);\n\t}\n\n\tpr_debug(\"dst: \");\n\tfor (i = 0; i < 2; i++)\n\t\tpr_debug(\"\\t0x%016llx \", src[src_cnt + i]);\n}\n\n \n \nstatic void ppc440spe_desc_init_interrupt(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\t\t  struct ppc440spe_adma_chan *chan)\n{\n\tstruct xor_cb *p;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_XOR_ID:\n\t\tp = desc->hw_desc;\n\t\tmemset(desc->hw_desc, 0, sizeof(struct xor_cb));\n\t\t \n\t\tp->cbc = XOR_CBCR_CBCE_BIT;\n\t\tbreak;\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tmemset(desc->hw_desc, 0, sizeof(struct dma_cdb));\n\t\t \n\t\tset_bit(PPC440SPE_DESC_INT, &desc->flags);\n\t\tbreak;\n\tdefault:\n\t\tprintk(KERN_ERR \"Unsupported id %d in %s\\n\", chan->device->id,\n\t\t\t\t__func__);\n\t\tbreak;\n\t}\n}\n\n \nstatic void ppc440spe_desc_init_null_xor(struct ppc440spe_adma_desc_slot *desc)\n{\n\tmemset(desc->hw_desc, 0, sizeof(struct xor_cb));\n\tdesc->hw_next = NULL;\n\tdesc->src_cnt = 0;\n\tdesc->dst_cnt = 1;\n}\n\n \nstatic void ppc440spe_desc_init_xor(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\t\t int src_cnt, unsigned long flags)\n{\n\tstruct xor_cb *hw_desc = desc->hw_desc;\n\n\tmemset(desc->hw_desc, 0, sizeof(struct xor_cb));\n\tdesc->hw_next = NULL;\n\tdesc->src_cnt = src_cnt;\n\tdesc->dst_cnt = 1;\n\n\thw_desc->cbc = XOR_CBCR_TGT_BIT | src_cnt;\n\tif (flags & DMA_PREP_INTERRUPT)\n\t\t \n\t\thw_desc->cbc |= XOR_CBCR_CBCE_BIT;\n}\n\n \nstatic void ppc440spe_desc_init_dma2pq(struct ppc440spe_adma_desc_slot *desc,\n\t\tint dst_cnt, int src_cnt, unsigned long flags)\n{\n\tstruct xor_cb *hw_desc = desc->hw_desc;\n\n\tmemset(desc->hw_desc, 0, sizeof(struct xor_cb));\n\tdesc->hw_next = NULL;\n\tdesc->src_cnt = src_cnt;\n\tdesc->dst_cnt = dst_cnt;\n\tmemset(desc->reverse_flags, 0, sizeof(desc->reverse_flags));\n\tdesc->descs_per_op = 0;\n\n\thw_desc->cbc = XOR_CBCR_TGT_BIT;\n\tif (flags & DMA_PREP_INTERRUPT)\n\t\t \n\t\thw_desc->cbc |= XOR_CBCR_CBCE_BIT;\n}\n\n#define DMA_CTRL_FLAGS_LAST\tDMA_PREP_FENCE\n#define DMA_PREP_ZERO_P\t\t(DMA_CTRL_FLAGS_LAST << 1)\n#define DMA_PREP_ZERO_Q\t\t(DMA_PREP_ZERO_P << 1)\n\n \nstatic void ppc440spe_desc_init_dma01pq(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\tint dst_cnt, int src_cnt, unsigned long flags,\n\t\t\t\tunsigned long op)\n{\n\tstruct dma_cdb *hw_desc;\n\tstruct ppc440spe_adma_desc_slot *iter;\n\tu8 dopc;\n\n\t \n\tset_bits(op, &desc->flags);\n\tdesc->src_cnt = src_cnt;\n\tdesc->dst_cnt = dst_cnt;\n\n\t \n\tdopc = (desc->dst_cnt == DMA_DEST_MAX_NUM) ?\n\t\tDMA_CDB_OPC_MULTICAST : DMA_CDB_OPC_MV_SG1_SG2;\n\n\tlist_for_each_entry(iter, &desc->group_list, chain_node) {\n\t\thw_desc = iter->hw_desc;\n\t\tmemset(iter->hw_desc, 0, sizeof(struct dma_cdb));\n\n\t\tif (likely(!list_is_last(&iter->chain_node,\n\t\t\t\t&desc->group_list))) {\n\t\t\t \n\t\t\titer->hw_next = list_entry(iter->chain_node.next,\n\t\t\t\tstruct ppc440spe_adma_desc_slot, chain_node);\n\t\t\tclear_bit(PPC440SPE_DESC_INT, &iter->flags);\n\t\t} else {\n\t\t\t \n\t\t\titer->hw_next = NULL;\n\t\t\tif (flags & DMA_PREP_INTERRUPT)\n\t\t\t\tset_bit(PPC440SPE_DESC_INT, &iter->flags);\n\t\t\telse\n\t\t\t\tclear_bit(PPC440SPE_DESC_INT, &iter->flags);\n\t\t}\n\t}\n\n\t \n\tif (!test_bit(PPC440SPE_DESC_RXOR, &desc->flags)) {\n\t\t \n\t\titer = list_first_entry(&desc->group_list,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\n\t\tif (test_bit(PPC440SPE_ZERO_P, &desc->flags)) {\n\t\t\thw_desc = iter->hw_desc;\n\t\t\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n\t\t\titer = list_first_entry(&iter->chain_node,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\t\t}\n\n\t\tif (test_bit(PPC440SPE_ZERO_Q, &desc->flags)) {\n\t\t\thw_desc = iter->hw_desc;\n\t\t\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n\t\t\titer = list_first_entry(&iter->chain_node,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\t\t}\n\n\t\tlist_for_each_entry_from(iter, &desc->group_list, chain_node) {\n\t\t\thw_desc = iter->hw_desc;\n\t\t\thw_desc->opc = dopc;\n\t\t}\n\t} else {\n\t\t \n\n\t\t \n\t\titer = list_first_entry(&desc->group_list,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\t\thw_desc = iter->hw_desc;\n\t\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n\n\t\tif (desc->dst_cnt == DMA_DEST_MAX_NUM) {\n\t\t\titer = list_first_entry(&iter->chain_node,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tchain_node);\n\t\t\thw_desc = iter->hw_desc;\n\t\t\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n\t\t}\n\n\t\t \n\t\tif (test_bit(PPC440SPE_DESC_WXOR, &desc->flags)) {\n\t\t\titer = list_first_entry(&iter->chain_node,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tchain_node);\n\t\t\tlist_for_each_entry_from(iter, &desc->group_list,\n\t\t\t\t\t\tchain_node) {\n\t\t\t\thw_desc = iter->hw_desc;\n\t\t\t\thw_desc->opc = dopc;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic void ppc440spe_desc_init_dma01pqzero_sum(\n\t\t\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\t\t\tint dst_cnt, int src_cnt)\n{\n\tstruct dma_cdb *hw_desc;\n\tstruct ppc440spe_adma_desc_slot *iter;\n\tint i = 0;\n\tu8 dopc = (dst_cnt == 2) ? DMA_CDB_OPC_MULTICAST :\n\t\t\t\t   DMA_CDB_OPC_MV_SG1_SG2;\n\t \n\titer = list_first_entry(&desc->group_list,\n\t\t\t\tstruct ppc440spe_adma_desc_slot, chain_node);\n\titer = list_entry(iter->chain_node.next,\n\t\t\t  struct ppc440spe_adma_desc_slot, chain_node);\n\n\tif (dst_cnt > 1) {\n\t\titer = list_entry(iter->chain_node.next,\n\t\t\t\t  struct ppc440spe_adma_desc_slot, chain_node);\n\t}\n\t \n\tlist_for_each_entry_from(iter, &desc->group_list, chain_node) {\n\t\thw_desc = iter->hw_desc;\n\t\tmemset(iter->hw_desc, 0, sizeof(struct dma_cdb));\n\t\titer->src_cnt = 0;\n\t\titer->dst_cnt = 0;\n\n\t\t \n\t\tif (i++ < src_cnt)\n\t\t\t \n\t\t\thw_desc->opc = dopc;\n\t\telse\n\t\t\t \n\t\t\thw_desc->opc = DMA_CDB_OPC_DCHECK128;\n\n\t\tif (likely(!list_is_last(&iter->chain_node,\n\t\t\t\t\t &desc->group_list))) {\n\t\t\t \n\t\t\titer->hw_next = list_entry(iter->chain_node.next,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tchain_node);\n\t\t} else {\n\t\t\t \n\t\t\titer->hw_next = NULL;\n\t\t\t \n\t\t\tset_bit(PPC440SPE_DESC_INT, &iter->flags);\n\t\t}\n\t}\n\tdesc->src_cnt = src_cnt;\n\tdesc->dst_cnt = dst_cnt;\n}\n\n \nstatic void ppc440spe_desc_init_memcpy(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\t\tunsigned long flags)\n{\n\tstruct dma_cdb *hw_desc = desc->hw_desc;\n\n\tmemset(desc->hw_desc, 0, sizeof(struct dma_cdb));\n\tdesc->hw_next = NULL;\n\tdesc->src_cnt = 1;\n\tdesc->dst_cnt = 1;\n\n\tif (flags & DMA_PREP_INTERRUPT)\n\t\tset_bit(PPC440SPE_DESC_INT, &desc->flags);\n\telse\n\t\tclear_bit(PPC440SPE_DESC_INT, &desc->flags);\n\n\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n}\n\n \nstatic void ppc440spe_desc_set_src_addr(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\t\tstruct ppc440spe_adma_chan *chan,\n\t\t\t\t\tint src_idx, dma_addr_t addrh,\n\t\t\t\t\tdma_addr_t addrl)\n{\n\tstruct dma_cdb *dma_hw_desc;\n\tstruct xor_cb *xor_hw_desc;\n\tphys_addr_t addr64, tmplow, tmphi;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tif (!addrh) {\n\t\t\taddr64 = addrl;\n\t\t\ttmphi = (addr64 >> 32);\n\t\t\ttmplow = (addr64 & 0xFFFFFFFF);\n\t\t} else {\n\t\t\ttmphi = addrh;\n\t\t\ttmplow = addrl;\n\t\t}\n\t\tdma_hw_desc = desc->hw_desc;\n\t\tdma_hw_desc->sg1l = cpu_to_le32((u32)tmplow);\n\t\tdma_hw_desc->sg1u |= cpu_to_le32((u32)tmphi);\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\txor_hw_desc = desc->hw_desc;\n\t\txor_hw_desc->ops[src_idx].l = addrl;\n\t\txor_hw_desc->ops[src_idx].h |= addrh;\n\t\tbreak;\n\t}\n}\n\n \nstatic void ppc440spe_desc_set_src_mult(struct ppc440spe_adma_desc_slot *desc,\n\t\t\tstruct ppc440spe_adma_chan *chan, u32 mult_index,\n\t\t\tint sg_index, unsigned char mult_value)\n{\n\tstruct dma_cdb *dma_hw_desc;\n\tu32 *psgu;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tdma_hw_desc = desc->hw_desc;\n\n\t\tswitch (sg_index) {\n\t\t \n\t\tcase DMA_CDB_SG_SRC:\n\t\t\tpsgu = &dma_hw_desc->sg1u;\n\t\t\tbreak;\n\t\t \n\t\tcase DMA_CDB_SG_DST1:\n\t\t\tpsgu = &dma_hw_desc->sg2u;\n\t\t\tbreak;\n\t\tcase DMA_CDB_SG_DST2:\n\t\t\tpsgu = &dma_hw_desc->sg3u;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t}\n\n\t\t*psgu |= cpu_to_le32(mult_value << mult_index);\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n}\n\n \nstatic void ppc440spe_desc_set_dest_addr(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\tstruct ppc440spe_adma_chan *chan,\n\t\t\t\tdma_addr_t addrh, dma_addr_t addrl,\n\t\t\t\tu32 dst_idx)\n{\n\tstruct dma_cdb *dma_hw_desc;\n\tstruct xor_cb *xor_hw_desc;\n\tphys_addr_t addr64, tmphi, tmplow;\n\tu32 *psgu, *psgl;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tif (!addrh) {\n\t\t\taddr64 = addrl;\n\t\t\ttmphi = (addr64 >> 32);\n\t\t\ttmplow = (addr64 & 0xFFFFFFFF);\n\t\t} else {\n\t\t\ttmphi = addrh;\n\t\t\ttmplow = addrl;\n\t\t}\n\t\tdma_hw_desc = desc->hw_desc;\n\n\t\tpsgu = dst_idx ? &dma_hw_desc->sg3u : &dma_hw_desc->sg2u;\n\t\tpsgl = dst_idx ? &dma_hw_desc->sg3l : &dma_hw_desc->sg2l;\n\n\t\t*psgl = cpu_to_le32((u32)tmplow);\n\t\t*psgu |= cpu_to_le32((u32)tmphi);\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\txor_hw_desc = desc->hw_desc;\n\t\txor_hw_desc->cbtal = addrl;\n\t\txor_hw_desc->cbtah |= addrh;\n\t\tbreak;\n\t}\n}\n\n \nstatic void ppc440spe_desc_set_byte_count(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\tstruct ppc440spe_adma_chan *chan,\n\t\t\t\tu32 byte_count)\n{\n\tstruct dma_cdb *dma_hw_desc;\n\tstruct xor_cb *xor_hw_desc;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tdma_hw_desc = desc->hw_desc;\n\t\tdma_hw_desc->cnt = cpu_to_le32(byte_count);\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\txor_hw_desc = desc->hw_desc;\n\t\txor_hw_desc->cbbc = byte_count;\n\t\tbreak;\n\t}\n}\n\n \nstatic inline void ppc440spe_desc_set_rxor_block_size(u32 byte_count)\n{\n\t \n\tdcr_write(ppc440spe_mq_dcr_host, DCRN_MQ0_CF2H, byte_count);\n}\n\n \nstatic void ppc440spe_desc_set_dcheck(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\tstruct ppc440spe_adma_chan *chan, u8 *qword)\n{\n\tstruct dma_cdb *dma_hw_desc;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tdma_hw_desc = desc->hw_desc;\n\t\tiowrite32(qword[0], &dma_hw_desc->sg3l);\n\t\tiowrite32(qword[4], &dma_hw_desc->sg3u);\n\t\tiowrite32(qword[8], &dma_hw_desc->sg2l);\n\t\tiowrite32(qword[12], &dma_hw_desc->sg2u);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n}\n\n \nstatic void ppc440spe_xor_set_link(struct ppc440spe_adma_desc_slot *prev_desc,\n\t\t\t\tstruct ppc440spe_adma_desc_slot *next_desc)\n{\n\tstruct xor_cb *xor_hw_desc = prev_desc->hw_desc;\n\n\tif (unlikely(!next_desc || !(next_desc->phys))) {\n\t\tprintk(KERN_ERR \"%s: next_desc=0x%p; next_desc->phys=0x%llx\\n\",\n\t\t\t__func__, next_desc,\n\t\t\tnext_desc ? next_desc->phys : 0);\n\t\tBUG();\n\t}\n\n\txor_hw_desc->cbs = 0;\n\txor_hw_desc->cblal = next_desc->phys;\n\txor_hw_desc->cblah = 0;\n\txor_hw_desc->cbc |= XOR_CBCR_LNK_BIT;\n}\n\n \nstatic void ppc440spe_desc_set_link(struct ppc440spe_adma_chan *chan,\n\t\t\t\tstruct ppc440spe_adma_desc_slot *prev_desc,\n\t\t\t\tstruct ppc440spe_adma_desc_slot *next_desc)\n{\n\tunsigned long flags;\n\tstruct ppc440spe_adma_desc_slot *tail = next_desc;\n\n\tif (unlikely(!prev_desc || !next_desc ||\n\t\t(prev_desc->hw_next && prev_desc->hw_next != next_desc))) {\n\t\t \n\t\tprintk(KERN_ERR \"%s: prev_desc=0x%p; next_desc=0x%p; \"\n\t\t\t\"prev->hw_next=0x%p\\n\", __func__, prev_desc,\n\t\t\tnext_desc, prev_desc ? prev_desc->hw_next : 0);\n\t\tBUG();\n\t}\n\n\tlocal_irq_save(flags);\n\n\t \n\tprev_desc->hw_next = next_desc;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\t \n\t\twhile (tail->hw_next)\n\t\t\ttail = tail->hw_next;\n\t\txor_last_linked = tail;\n\n\t\tif (prev_desc == xor_last_submit)\n\t\t\t \n\t\t\tbreak;\n\t\tppc440spe_xor_set_link(prev_desc, next_desc);\n\t\tbreak;\n\t}\n\n\tlocal_irq_restore(flags);\n}\n\n \nstatic inline u32 ppc440spe_desc_get_link(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\t\tstruct ppc440spe_adma_chan *chan)\n{\n\tif (!desc->hw_next)\n\t\treturn 0;\n\n\treturn desc->hw_next->phys;\n}\n\n \nstatic inline int ppc440spe_desc_is_aligned(\n\tstruct ppc440spe_adma_desc_slot *desc, int num_slots)\n{\n\treturn (desc->idx & (num_slots - 1)) ? 0 : 1;\n}\n\n \nstatic int ppc440spe_chan_xor_slot_count(size_t len, int src_cnt,\n\t\t\tint *slots_per_op)\n{\n\tint slot_cnt;\n\n\t \n\tslot_cnt = *slots_per_op = (src_cnt + XOR_MAX_OPS - 1)/XOR_MAX_OPS;\n\n\tif (likely(len <= PPC440SPE_ADMA_XOR_MAX_BYTE_COUNT))\n\t\treturn slot_cnt;\n\n\tprintk(KERN_ERR \"%s: len %d > max %d !!\\n\",\n\t\t__func__, len, PPC440SPE_ADMA_XOR_MAX_BYTE_COUNT);\n\tBUG();\n\treturn slot_cnt;\n}\n\n \nstatic int ppc440spe_dma2_pq_slot_count(dma_addr_t *srcs,\n\t\tint src_cnt, size_t len)\n{\n\tsigned long long order = 0;\n\tint state = 0;\n\tint addr_count = 0;\n\tint i;\n\tfor (i = 1; i < src_cnt; i++) {\n\t\tdma_addr_t cur_addr = srcs[i];\n\t\tdma_addr_t old_addr = srcs[i-1];\n\t\tswitch (state) {\n\t\tcase 0:\n\t\t\tif (cur_addr == old_addr + len) {\n\t\t\t\t \n\t\t\t\torder = 1;\n\t\t\t\tstate = 1;\n\t\t\t\tif (i == src_cnt-1)\n\t\t\t\t\taddr_count++;\n\t\t\t} else if (old_addr == cur_addr + len) {\n\t\t\t\t \n\t\t\t\torder = -1;\n\t\t\t\tstate = 1;\n\t\t\t\tif (i == src_cnt-1)\n\t\t\t\t\taddr_count++;\n\t\t\t} else {\n\t\t\t\tstate = 3;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tif (i == src_cnt-2 || (order == -1\n\t\t\t\t&& cur_addr != old_addr - len)) {\n\t\t\t\torder = 0;\n\t\t\t\tstate = 0;\n\t\t\t\taddr_count++;\n\t\t\t} else if (cur_addr == old_addr + len*order) {\n\t\t\t\tstate = 2;\n\t\t\t\tif (i == src_cnt-1)\n\t\t\t\t\taddr_count++;\n\t\t\t} else if (cur_addr == old_addr + 2*len) {\n\t\t\t\tstate = 2;\n\t\t\t\tif (i == src_cnt-1)\n\t\t\t\t\taddr_count++;\n\t\t\t} else if (cur_addr == old_addr + 3*len) {\n\t\t\t\tstate = 2;\n\t\t\t\tif (i == src_cnt-1)\n\t\t\t\t\taddr_count++;\n\t\t\t} else {\n\t\t\t\torder = 0;\n\t\t\t\tstate = 0;\n\t\t\t\taddr_count++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\torder = 0;\n\t\t\tstate = 0;\n\t\t\taddr_count++;\n\t\t\t\tbreak;\n\t\t}\n\t\tif (state == 3)\n\t\t\tbreak;\n\t}\n\tif (src_cnt <= 1 || (state != 1 && state != 2)) {\n\t\tpr_err(\"%s: src_cnt=%d, state=%d, addr_count=%d, order=%lld\\n\",\n\t\t\t__func__, src_cnt, state, addr_count, order);\n\t\tfor (i = 0; i < src_cnt; i++)\n\t\t\tpr_err(\"\\t[%d] 0x%llx \\n\", i, srcs[i]);\n\t\tBUG();\n\t}\n\n\treturn (addr_count + XOR_MAX_OPS - 1) / XOR_MAX_OPS;\n}\n\n\n \n\nstatic u32\nppc440spe_chan_get_current_descriptor(struct ppc440spe_adma_chan *chan);\nstatic void ppc440spe_chan_append(struct ppc440spe_adma_chan *chan);\n\n \nstatic void ppc440spe_adma_device_clear_eot_status(\n\t\t\t\t\tstruct ppc440spe_adma_chan *chan)\n{\n\tstruct dma_regs *dma_reg;\n\tstruct xor_regs *xor_reg;\n\tu8 *p = chan->device->dma_desc_pool_virt;\n\tstruct dma_cdb *cdb;\n\tu32 rv, i;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\t \n\t\tdma_reg = chan->device->dma_reg;\n\t\twhile ((rv = ioread32(&dma_reg->csfpl))) {\n\t\t\ti = rv & DMA_CDB_ADDR_MSK;\n\t\t\tcdb = (struct dma_cdb *)&p[i -\n\t\t\t    (u32)chan->device->dma_desc_pool];\n\n\t\t\t \n\t\t\tcdb->opc = 0;\n\n\t\t\tif (test_bit(PPC440SPE_RXOR_RUN,\n\t\t\t    &ppc440spe_rxor_state)) {\n\t\t\t\t \n\t\t\t\tif (le32_to_cpu(cdb->sg1u) &\n\t\t\t\t    DMA_CUED_XOR_BASE) {\n\t\t\t\t\t \n\t\t\t\t\tclear_bit(PPC440SPE_RXOR_RUN,\n\t\t\t\t\t\t  &ppc440spe_rxor_state);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (rv & DMA_CDB_STATUS_MSK) {\n\t\t\t\t \n\t\t\t\tstruct ppc440spe_adma_desc_slot *iter;\n\t\t\t\tdma_addr_t phys = rv & ~DMA_CDB_MSK;\n\n\t\t\t\t \n\t\t\t\tlist_for_each_entry(iter, &chan->chain,\n\t\t\t\t    chain_node) {\n\t\t\t\t\tif (iter->phys == phys)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\tBUG_ON(&iter->chain_node == &chan->chain);\n\n\t\t\t\tif (iter->xor_check_result) {\n\t\t\t\t\tif (test_bit(PPC440SPE_DESC_PCHECK,\n\t\t\t\t\t\t     &iter->flags)) {\n\t\t\t\t\t\t*iter->xor_check_result |=\n\t\t\t\t\t\t\tSUM_CHECK_P_RESULT;\n\t\t\t\t\t} else\n\t\t\t\t\tif (test_bit(PPC440SPE_DESC_QCHECK,\n\t\t\t\t\t\t     &iter->flags)) {\n\t\t\t\t\t\t*iter->xor_check_result |=\n\t\t\t\t\t\t\tSUM_CHECK_Q_RESULT;\n\t\t\t\t\t} else\n\t\t\t\t\t\tBUG();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\trv = ioread32(&dma_reg->dsts);\n\t\tif (rv) {\n\t\t\tpr_err(\"DMA%d err status: 0x%x\\n\",\n\t\t\t       chan->device->id, rv);\n\t\t\t \n\t\t\tiowrite32(rv, &dma_reg->dsts);\n\t\t}\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\t \n\t\txor_reg = chan->device->xor_reg;\n\t\trv = ioread32be(&xor_reg->sr);\n\t\tiowrite32be(rv, &xor_reg->sr);\n\n\t\tif (rv & (XOR_IE_ICBIE_BIT|XOR_IE_ICIE_BIT|XOR_IE_RPTIE_BIT)) {\n\t\t\tif (rv & XOR_IE_RPTIE_BIT) {\n\t\t\t\t \n\t\t\t\tu32 val = ioread32be(&xor_reg->ccbalr);\n\n\t\t\t\tiowrite32be(val, &xor_reg->cblalr);\n\n\t\t\t\tval = ioread32be(&xor_reg->crsr);\n\t\t\t\tiowrite32be(val | XOR_CRSR_XAE_BIT,\n\t\t\t\t\t    &xor_reg->crsr);\n\t\t\t} else\n\t\t\t\tpr_err(\"XOR ERR 0x%x status\\n\", rv);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (!(ioread32be(&xor_reg->sr) & XOR_SR_XCP_BIT) &&\n\t\t    do_xor_refetch)\n\t\t\tppc440spe_chan_append(chan);\n\t\tbreak;\n\t}\n}\n\n \nstatic int ppc440spe_chan_is_busy(struct ppc440spe_adma_chan *chan)\n{\n\tstruct dma_regs *dma_reg;\n\tstruct xor_regs *xor_reg;\n\tint busy = 0;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tdma_reg = chan->device->dma_reg;\n\t\t \n\t\tif (ioread16(&dma_reg->cpfhp) != ioread16(&dma_reg->cpftp) ||\n\t\t    ioread16(&dma_reg->cpftp) != ioread16(&dma_reg->csftp))\n\t\t\tbusy = 1;\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\t \n\t\txor_reg = chan->device->xor_reg;\n\t\tbusy = (ioread32be(&xor_reg->sr) & XOR_SR_XCP_BIT) ? 1 : 0;\n\t\tbreak;\n\t}\n\n\treturn busy;\n}\n\n \nstatic void ppc440spe_chan_set_first_xor_descriptor(\n\t\t\t\tstruct ppc440spe_adma_chan *chan,\n\t\t\t\tstruct ppc440spe_adma_desc_slot *next_desc)\n{\n\tstruct xor_regs *xor_reg = chan->device->xor_reg;\n\n\tif (ioread32be(&xor_reg->sr) & XOR_SR_XCP_BIT)\n\t\tprintk(KERN_INFO \"%s: Warn: XORcore is running \"\n\t\t\t\"when try to set the first CDB!\\n\",\n\t\t\t__func__);\n\n\txor_last_submit = xor_last_linked = next_desc;\n\n\tiowrite32be(XOR_CRSR_64BA_BIT, &xor_reg->crsr);\n\n\tiowrite32be(next_desc->phys, &xor_reg->cblalr);\n\tiowrite32be(0, &xor_reg->cblahr);\n\tiowrite32be(ioread32be(&xor_reg->cbcr) | XOR_CBCR_LNK_BIT,\n\t\t    &xor_reg->cbcr);\n\n\tchan->hw_chain_inited = 1;\n}\n\n \nstatic void ppc440spe_dma_put_desc(struct ppc440spe_adma_chan *chan,\n\t\tstruct ppc440spe_adma_desc_slot *desc)\n{\n\tu32 pcdb;\n\tstruct dma_regs *dma_reg = chan->device->dma_reg;\n\n\tpcdb = desc->phys;\n\tif (!test_bit(PPC440SPE_DESC_INT, &desc->flags))\n\t\tpcdb |= DMA_CDB_NO_INT;\n\n\tchan_last_sub[chan->device->id] = desc;\n\n\tADMA_LL_DBG(print_cb(chan, desc->hw_desc));\n\n\tiowrite32(pcdb, &dma_reg->cpfpl);\n}\n\n \nstatic void ppc440spe_chan_append(struct ppc440spe_adma_chan *chan)\n{\n\tstruct xor_regs *xor_reg;\n\tstruct ppc440spe_adma_desc_slot *iter;\n\tstruct xor_cb *xcb;\n\tu32 cur_desc;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tcur_desc = ppc440spe_chan_get_current_descriptor(chan);\n\n\t\tif (likely(cur_desc)) {\n\t\t\titer = chan_last_sub[chan->device->id];\n\t\t\tBUG_ON(!iter);\n\t\t} else {\n\t\t\t \n\t\t\titer = chan_first_cdb[chan->device->id];\n\t\t\tBUG_ON(!iter);\n\t\t\tppc440spe_dma_put_desc(chan, iter);\n\t\t\tchan->hw_chain_inited = 1;\n\t\t}\n\n\t\t \n\t\tif (!iter->hw_next)\n\t\t\tbreak;\n\n\t\t \n\t\tlist_for_each_entry_continue(iter, &chan->chain, chain_node) {\n\t\t\tppc440spe_dma_put_desc(chan, iter);\n\t\t\tif (!iter->hw_next)\n\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\t \n\t\tif (!xor_last_submit->hw_next)\n\t\t\tbreak;\n\n\t\txor_reg = chan->device->xor_reg;\n\t\t \n\t\txcb = xor_last_linked->hw_desc;\n\t\txcb->cbc |= XOR_CBCR_CBCE_BIT;\n\n\t\tif (!(ioread32be(&xor_reg->sr) & XOR_SR_XCP_BIT)) {\n\t\t\t \n\t\t\tdo_xor_refetch = 0;\n\t\t\tppc440spe_xor_set_link(xor_last_submit,\n\t\t\t\txor_last_submit->hw_next);\n\n\t\t\tADMA_LL_DBG(print_cb_list(chan,\n\t\t\t\txor_last_submit->hw_next));\n\n\t\t\txor_last_submit = xor_last_linked;\n\t\t\tiowrite32be(ioread32be(&xor_reg->crsr) |\n\t\t\t\t    XOR_CRSR_RCBE_BIT | XOR_CRSR_64BA_BIT,\n\t\t\t\t    &xor_reg->crsr);\n\t\t} else {\n\t\t\t \n\t\t\tdo_xor_refetch = 1;\n\t\t}\n\n\t\tbreak;\n\t}\n\n\tlocal_irq_restore(flags);\n}\n\n \nstatic u32\nppc440spe_chan_get_current_descriptor(struct ppc440spe_adma_chan *chan)\n{\n\tstruct dma_regs *dma_reg;\n\tstruct xor_regs *xor_reg;\n\n\tif (unlikely(!chan->hw_chain_inited))\n\t\t \n\t\treturn 0;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tdma_reg = chan->device->dma_reg;\n\t\treturn ioread32(&dma_reg->acpl) & (~DMA_CDB_MSK);\n\tcase PPC440SPE_XOR_ID:\n\t\txor_reg = chan->device->xor_reg;\n\t\treturn ioread32be(&xor_reg->ccbalr);\n\t}\n\treturn 0;\n}\n\n \nstatic void ppc440spe_chan_run(struct ppc440spe_adma_chan *chan)\n{\n\tstruct xor_regs *xor_reg;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\t \n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\t \n\t\txor_reg = chan->device->xor_reg;\n\n\t\t \n\t\tiowrite32be(XOR_CRSR_64BA_BIT | XOR_CRSR_XAE_BIT,\n\t\t\t    &xor_reg->crsr);\n\t\tbreak;\n\t}\n}\n\n \n\nstatic void ppc440spe_chan_start_null_xor(struct ppc440spe_adma_chan *chan);\nstatic int ppc440spe_adma_alloc_chan_resources(struct dma_chan *chan);\n\nstatic dma_cookie_t\nppc440spe_adma_tx_submit(struct dma_async_tx_descriptor *tx);\n\nstatic void ppc440spe_adma_set_dest(struct ppc440spe_adma_desc_slot *tx,\n\t\t\t\t    dma_addr_t addr, int index);\nstatic void\nppc440spe_adma_memcpy_xor_set_src(struct ppc440spe_adma_desc_slot *tx,\n\t\t\t\t  dma_addr_t addr, int index);\n\nstatic void\nppc440spe_adma_pq_set_dest(struct ppc440spe_adma_desc_slot *tx,\n\t\t\t   dma_addr_t *paddr, unsigned long flags);\nstatic void\nppc440spe_adma_pq_set_src(struct ppc440spe_adma_desc_slot *tx,\n\t\t\t  dma_addr_t addr, int index);\nstatic void\nppc440spe_adma_pq_set_src_mult(struct ppc440spe_adma_desc_slot *tx,\n\t\t\t       unsigned char mult, int index, int dst_pos);\nstatic void\nppc440spe_adma_pqzero_sum_set_dest(struct ppc440spe_adma_desc_slot *tx,\n\t\t\t\t   dma_addr_t paddr, dma_addr_t qaddr);\n\nstatic struct page *ppc440spe_rxor_srcs[32];\n\n \nstatic int ppc440spe_can_rxor(struct page **srcs, int src_cnt, size_t len)\n{\n\tint i, order = 0, state = 0;\n\tint idx = 0;\n\n\tif (unlikely(!(src_cnt > 1)))\n\t\treturn 0;\n\n\tBUG_ON(src_cnt > ARRAY_SIZE(ppc440spe_rxor_srcs));\n\n\t \n\tfor (i = 0; i < src_cnt; i++) {\n\t\tif (!srcs[i])\n\t\t\tcontinue;\n\t\tppc440spe_rxor_srcs[idx++] = srcs[i];\n\t}\n\tsrc_cnt = idx;\n\n\tfor (i = 1; i < src_cnt; i++) {\n\t\tchar *cur_addr = page_address(ppc440spe_rxor_srcs[i]);\n\t\tchar *old_addr = page_address(ppc440spe_rxor_srcs[i - 1]);\n\n\t\tswitch (state) {\n\t\tcase 0:\n\t\t\tif (cur_addr == old_addr + len) {\n\t\t\t\t \n\t\t\t\torder = 1;\n\t\t\t\tstate = 1;\n\t\t\t} else if (old_addr == cur_addr + len) {\n\t\t\t\t \n\t\t\t\torder = -1;\n\t\t\t\tstate = 1;\n\t\t\t} else\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tif ((i == src_cnt - 2) ||\n\t\t\t    (order == -1 && cur_addr != old_addr - len)) {\n\t\t\t\torder = 0;\n\t\t\t\tstate = 0;\n\t\t\t} else if ((cur_addr == old_addr + len * order) ||\n\t\t\t\t   (cur_addr == old_addr + 2 * len) ||\n\t\t\t\t   (cur_addr == old_addr + 3 * len)) {\n\t\t\t\tstate = 2;\n\t\t\t} else {\n\t\t\t\torder = 0;\n\t\t\t\tstate = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\torder = 0;\n\t\t\tstate = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\nout:\n\tif (state == 1 || state == 2)\n\t\treturn 1;\n\n\treturn 0;\n}\n\n \nstatic int ppc440spe_adma_estimate(struct dma_chan *chan,\n\tenum dma_transaction_type cap, struct page **dst_lst, int dst_cnt,\n\tstruct page **src_lst, int src_cnt, size_t src_sz)\n{\n\tint ef = 1;\n\n\tif (cap == DMA_PQ || cap == DMA_PQ_VAL) {\n\t\t \n\t\tif (unlikely(!ppc440spe_r6_enabled))\n\t\t\treturn -1;\n\t}\n\t \n\tif (cap == DMA_PQ && chan->chan_id == PPC440SPE_XOR_ID) {\n\n\t\tif (dst_cnt == 1 && src_cnt == 2 && dst_lst[0] == src_lst[1])\n\t\t\tef = 0;  \n\t\telse if (ppc440spe_can_rxor(src_lst, src_cnt, src_sz))\n\t\t\tef = 3;  \n\t\telse\n\t\t\tef = 0;  \n\t}\n\n\t \n\tif (likely(ef) &&\n\t    !ppc440spe_chan_is_busy(to_ppc440spe_adma_chan(chan)))\n\t\tef++;\n\n\treturn ef;\n}\n\nstruct dma_chan *\nppc440spe_async_tx_find_best_channel(enum dma_transaction_type cap,\n\tstruct page **dst_lst, int dst_cnt, struct page **src_lst,\n\tint src_cnt, size_t src_sz)\n{\n\tstruct dma_chan *best_chan = NULL;\n\tstruct ppc_dma_chan_ref *ref;\n\tint best_rank = -1;\n\n\tif (unlikely(!src_sz))\n\t\treturn NULL;\n\tif (src_sz > PAGE_SIZE) {\n\t\t \n\t\tswitch (cap) {\n\t\tcase DMA_PQ:\n\t\t\tif (src_cnt == 1 && dst_lst[1] == src_lst[0])\n\t\t\t\treturn NULL;\n\t\t\tif (src_cnt == 2 && dst_lst[1] == src_lst[1])\n\t\t\t\treturn NULL;\n\t\t\tbreak;\n\t\tcase DMA_PQ_VAL:\n\t\tcase DMA_XOR_VAL:\n\t\t\treturn NULL;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tlist_for_each_entry(ref, &ppc440spe_adma_chan_list, node) {\n\t\tif (dma_has_cap(cap, ref->chan->device->cap_mask)) {\n\t\t\tint rank;\n\n\t\t\trank = ppc440spe_adma_estimate(ref->chan, cap, dst_lst,\n\t\t\t\t\tdst_cnt, src_lst, src_cnt, src_sz);\n\t\t\tif (rank > best_rank) {\n\t\t\t\tbest_rank = rank;\n\t\t\t\tbest_chan = ref->chan;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn best_chan;\n}\nEXPORT_SYMBOL_GPL(ppc440spe_async_tx_find_best_channel);\n\n \nstatic struct ppc440spe_adma_desc_slot *\nppc440spe_get_group_entry(struct ppc440spe_adma_desc_slot *tdesc, u32 entry_idx)\n{\n\tstruct ppc440spe_adma_desc_slot *iter = tdesc->group_head;\n\tint i = 0;\n\n\tif (entry_idx < 0 || entry_idx >= (tdesc->src_cnt + tdesc->dst_cnt)) {\n\t\tprintk(\"%s: entry_idx %d, src_cnt %d, dst_cnt %d\\n\",\n\t\t\t__func__, entry_idx, tdesc->src_cnt, tdesc->dst_cnt);\n\t\tBUG();\n\t}\n\n\tlist_for_each_entry(iter, &tdesc->group_list, chain_node) {\n\t\tif (i++ == entry_idx)\n\t\t\tbreak;\n\t}\n\treturn iter;\n}\n\n \nstatic void ppc440spe_adma_free_slots(struct ppc440spe_adma_desc_slot *slot,\n\t\t\t\t      struct ppc440spe_adma_chan *chan)\n{\n\tint stride = slot->slots_per_op;\n\n\twhile (stride--) {\n\t\tslot->slots_per_op = 0;\n\t\tslot = list_entry(slot->slot_node.next,\n\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\tslot_node);\n\t}\n}\n\n \nstatic dma_cookie_t ppc440spe_adma_run_tx_complete_actions(\n\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\tstruct ppc440spe_adma_chan *chan,\n\t\tdma_cookie_t cookie)\n{\n\tBUG_ON(desc->async_tx.cookie < 0);\n\tif (desc->async_tx.cookie > 0) {\n\t\tcookie = desc->async_tx.cookie;\n\t\tdesc->async_tx.cookie = 0;\n\n\t\tdma_descriptor_unmap(&desc->async_tx);\n\t\t \n\t\tdmaengine_desc_get_callback_invoke(&desc->async_tx, NULL);\n\t}\n\n\t \n\tdma_run_dependencies(&desc->async_tx);\n\n\treturn cookie;\n}\n\n \nstatic int ppc440spe_adma_clean_slot(struct ppc440spe_adma_desc_slot *desc,\n\t\tstruct ppc440spe_adma_chan *chan)\n{\n\t \n\tif (!async_tx_test_ack(&desc->async_tx))\n\t\treturn 0;\n\n\t \n\tif (list_is_last(&desc->chain_node, &chan->chain) ||\n\t    desc->phys == ppc440spe_chan_get_current_descriptor(chan))\n\t\treturn 1;\n\n\tif (chan->device->id != PPC440SPE_XOR_ID) {\n\t\t \n\t\tstruct dma_cdb *cdb = desc->hw_desc;\n\t\tif (cdb->opc == DMA_CDB_OPC_DCHECK128)\n\t\t\treturn 1;\n\t}\n\n\tdev_dbg(chan->device->common.dev, \"\\tfree slot %llx: %d stride: %d\\n\",\n\t\tdesc->phys, desc->idx, desc->slots_per_op);\n\n\tlist_del(&desc->chain_node);\n\tppc440spe_adma_free_slots(desc, chan);\n\treturn 0;\n}\n\n \nstatic void __ppc440spe_adma_slot_cleanup(struct ppc440spe_adma_chan *chan)\n{\n\tstruct ppc440spe_adma_desc_slot *iter, *_iter, *group_start = NULL;\n\tdma_cookie_t cookie = 0;\n\tu32 current_desc = ppc440spe_chan_get_current_descriptor(chan);\n\tint busy = ppc440spe_chan_is_busy(chan);\n\tint seen_current = 0, slot_cnt = 0, slots_per_op = 0;\n\n\tdev_dbg(chan->device->common.dev, \"ppc440spe adma%d: %s\\n\",\n\t\tchan->device->id, __func__);\n\n\tif (!current_desc) {\n\t\t \n\t\treturn;\n\t}\n\n\t \n\tlist_for_each_entry_safe(iter, _iter, &chan->chain,\n\t\t\t\t\tchain_node) {\n\t\tdev_dbg(chan->device->common.dev, \"\\tcookie: %d slot: %d \"\n\t\t    \"busy: %d this_desc: %#llx next_desc: %#x \"\n\t\t    \"cur: %#x ack: %d\\n\",\n\t\t    iter->async_tx.cookie, iter->idx, busy, iter->phys,\n\t\t    ppc440spe_desc_get_link(iter, chan), current_desc,\n\t\t    async_tx_test_ack(&iter->async_tx));\n\t\tprefetch(_iter);\n\t\tprefetch(&_iter->async_tx);\n\n\t\t \n\t\tif (seen_current)\n\t\t\tbreak;\n\n\t\t \n\t\tif (iter->phys == current_desc) {\n\t\t\tBUG_ON(seen_current++);\n\t\t\tif (busy || ppc440spe_desc_get_link(iter, chan)) {\n\t\t\t\t \n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (!slot_cnt && !slots_per_op) {\n\t\t\tslot_cnt = iter->slot_cnt;\n\t\t\tslots_per_op = iter->slots_per_op;\n\t\t\tif (slot_cnt <= slots_per_op) {\n\t\t\t\tslot_cnt = 0;\n\t\t\t\tslots_per_op = 0;\n\t\t\t}\n\t\t}\n\n\t\tif (slot_cnt) {\n\t\t\tif (!group_start)\n\t\t\t\tgroup_start = iter;\n\t\t\tslot_cnt -= slots_per_op;\n\t\t}\n\n\t\t \n\t\tif (slots_per_op != 0 && slot_cnt == 0) {\n\t\t\tstruct ppc440spe_adma_desc_slot *grp_iter, *_grp_iter;\n\t\t\tint end_of_chain = 0;\n\n\t\t\t \n\t\t\tslot_cnt = group_start->slot_cnt;\n\t\t\tgrp_iter = group_start;\n\t\t\tlist_for_each_entry_safe_from(grp_iter, _grp_iter,\n\t\t\t\t&chan->chain, chain_node) {\n\n\t\t\t\tcookie = ppc440spe_adma_run_tx_complete_actions(\n\t\t\t\t\tgrp_iter, chan, cookie);\n\n\t\t\t\tslot_cnt -= slots_per_op;\n\t\t\t\tend_of_chain = ppc440spe_adma_clean_slot(\n\t\t\t\t    grp_iter, chan);\n\t\t\t\tif (end_of_chain && slot_cnt) {\n\t\t\t\t\t \n\t\t\t\t\tif (cookie > 0)\n\t\t\t\t\t\tchan->common.completed_cookie = cookie;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (slot_cnt == 0 || end_of_chain)\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tBUG_ON(slot_cnt);\n\n\t\t\tslots_per_op = 0;\n\t\t\tgroup_start = NULL;\n\t\t\tif (end_of_chain)\n\t\t\t\tbreak;\n\t\t\telse\n\t\t\t\tcontinue;\n\t\t} else if (slots_per_op)  \n\t\t\tcontinue;\n\n\t\tcookie = ppc440spe_adma_run_tx_complete_actions(iter, chan,\n\t\t    cookie);\n\n\t\tif (ppc440spe_adma_clean_slot(iter, chan))\n\t\t\tbreak;\n\t}\n\n\tBUG_ON(!seen_current);\n\n\tif (cookie > 0) {\n\t\tchan->common.completed_cookie = cookie;\n\t\tpr_debug(\"\\tcompleted cookie %d\\n\", cookie);\n\t}\n\n}\n\n \nstatic void ppc440spe_adma_tasklet(struct tasklet_struct *t)\n{\n\tstruct ppc440spe_adma_chan *chan = from_tasklet(chan, t, irq_tasklet);\n\n\tspin_lock_nested(&chan->lock, SINGLE_DEPTH_NESTING);\n\t__ppc440spe_adma_slot_cleanup(chan);\n\tspin_unlock(&chan->lock);\n}\n\n \nstatic void ppc440spe_adma_slot_cleanup(struct ppc440spe_adma_chan *chan)\n{\n\tspin_lock_bh(&chan->lock);\n\t__ppc440spe_adma_slot_cleanup(chan);\n\tspin_unlock_bh(&chan->lock);\n}\n\n \nstatic struct ppc440spe_adma_desc_slot *ppc440spe_adma_alloc_slots(\n\t\tstruct ppc440spe_adma_chan *chan, int num_slots,\n\t\tint slots_per_op)\n{\n\tstruct ppc440spe_adma_desc_slot *iter = NULL, *_iter;\n\tstruct ppc440spe_adma_desc_slot *alloc_start = NULL;\n\tint slots_found, retry = 0;\n\tLIST_HEAD(chain);\n\n\n\tBUG_ON(!num_slots || !slots_per_op);\n\t \nretry:\n\tslots_found = 0;\n\tif (retry == 0)\n\t\titer = chan->last_used;\n\telse\n\t\titer = list_entry(&chan->all_slots,\n\t\t\t\t  struct ppc440spe_adma_desc_slot,\n\t\t\t\t  slot_node);\n\tlist_for_each_entry_safe_continue(iter, _iter, &chan->all_slots,\n\t    slot_node) {\n\t\tprefetch(_iter);\n\t\tprefetch(&_iter->async_tx);\n\t\tif (iter->slots_per_op) {\n\t\t\tslots_found = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (!slots_found++)\n\t\t\talloc_start = iter;\n\n\t\tif (slots_found == num_slots) {\n\t\t\tstruct ppc440spe_adma_desc_slot *alloc_tail = NULL;\n\t\t\tstruct ppc440spe_adma_desc_slot *last_used = NULL;\n\n\t\t\titer = alloc_start;\n\t\t\twhile (num_slots) {\n\t\t\t\tint i;\n\t\t\t\t \n\t\t\t\tif (num_slots != slots_per_op)\n\t\t\t\t\tasync_tx_ack(&iter->async_tx);\n\n\t\t\t\tlist_add_tail(&iter->chain_node, &chain);\n\t\t\t\talloc_tail = iter;\n\t\t\t\titer->async_tx.cookie = 0;\n\t\t\t\titer->hw_next = NULL;\n\t\t\t\titer->flags = 0;\n\t\t\t\titer->slot_cnt = num_slots;\n\t\t\t\titer->xor_check_result = NULL;\n\t\t\t\tfor (i = 0; i < slots_per_op; i++) {\n\t\t\t\t\titer->slots_per_op = slots_per_op - i;\n\t\t\t\t\tlast_used = iter;\n\t\t\t\t\titer = list_entry(iter->slot_node.next,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tslot_node);\n\t\t\t\t}\n\t\t\t\tnum_slots -= slots_per_op;\n\t\t\t}\n\t\t\talloc_tail->group_head = alloc_start;\n\t\t\talloc_tail->async_tx.cookie = -EBUSY;\n\t\t\tlist_splice(&chain, &alloc_tail->group_list);\n\t\t\tchan->last_used = last_used;\n\t\t\treturn alloc_tail;\n\t\t}\n\t}\n\tif (!retry++)\n\t\tgoto retry;\n\n\t \n\ttasklet_schedule(&chan->irq_tasklet);\n\treturn NULL;\n}\n\n \nstatic int ppc440spe_adma_alloc_chan_resources(struct dma_chan *chan)\n{\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\tstruct ppc440spe_adma_desc_slot *slot = NULL;\n\tchar *hw_desc;\n\tint i, db_sz;\n\tint init;\n\n\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\tinit = ppc440spe_chan->slots_allocated ? 0 : 1;\n\tchan->chan_id = ppc440spe_chan->device->id;\n\n\t \n\ti = ppc440spe_chan->slots_allocated;\n\tif (ppc440spe_chan->device->id != PPC440SPE_XOR_ID)\n\t\tdb_sz = sizeof(struct dma_cdb);\n\telse\n\t\tdb_sz = sizeof(struct xor_cb);\n\n\tfor (; i < (ppc440spe_chan->device->pool_size / db_sz); i++) {\n\t\tslot = kzalloc(sizeof(struct ppc440spe_adma_desc_slot),\n\t\t\t       GFP_KERNEL);\n\t\tif (!slot) {\n\t\t\tprintk(KERN_INFO \"SPE ADMA Channel only initialized\"\n\t\t\t\t\" %d descriptor slots\", i--);\n\t\t\tbreak;\n\t\t}\n\n\t\thw_desc = (char *) ppc440spe_chan->device->dma_desc_pool_virt;\n\t\tslot->hw_desc = (void *) &hw_desc[i * db_sz];\n\t\tdma_async_tx_descriptor_init(&slot->async_tx, chan);\n\t\tslot->async_tx.tx_submit = ppc440spe_adma_tx_submit;\n\t\tINIT_LIST_HEAD(&slot->chain_node);\n\t\tINIT_LIST_HEAD(&slot->slot_node);\n\t\tINIT_LIST_HEAD(&slot->group_list);\n\t\tslot->phys = ppc440spe_chan->device->dma_desc_pool + i * db_sz;\n\t\tslot->idx = i;\n\n\t\tspin_lock_bh(&ppc440spe_chan->lock);\n\t\tppc440spe_chan->slots_allocated++;\n\t\tlist_add_tail(&slot->slot_node, &ppc440spe_chan->all_slots);\n\t\tspin_unlock_bh(&ppc440spe_chan->lock);\n\t}\n\n\tif (i && !ppc440spe_chan->last_used) {\n\t\tppc440spe_chan->last_used =\n\t\t\tlist_entry(ppc440spe_chan->all_slots.next,\n\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\tslot_node);\n\t}\n\n\tdev_dbg(ppc440spe_chan->device->common.dev,\n\t\t\"ppc440spe adma%d: allocated %d descriptor slots\\n\",\n\t\tppc440spe_chan->device->id, i);\n\n\t \n\tif (init) {\n\t\tswitch (ppc440spe_chan->device->id) {\n\t\tcase PPC440SPE_DMA0_ID:\n\t\tcase PPC440SPE_DMA1_ID:\n\t\t\tppc440spe_chan->hw_chain_inited = 0;\n\t\t\t \n\t\t\tif (!ppc440spe_r6_tchan)\n\t\t\t\tppc440spe_r6_tchan = ppc440spe_chan;\n\t\t\tbreak;\n\t\tcase PPC440SPE_XOR_ID:\n\t\t\tppc440spe_chan_start_null_xor(ppc440spe_chan);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t}\n\t\tppc440spe_chan->needs_unmap = 1;\n\t}\n\n\treturn (i > 0) ? i : -ENOMEM;\n}\n\n \nstatic void ppc440spe_rxor_set_region(struct ppc440spe_adma_desc_slot *desc,\n\tu8 xor_arg_no, u32 mask)\n{\n\tstruct xor_cb *xcb = desc->hw_desc;\n\n\txcb->ops[xor_arg_no].h |= mask;\n}\n\n \nstatic void ppc440spe_rxor_set_src(struct ppc440spe_adma_desc_slot *desc,\n\tu8 xor_arg_no, dma_addr_t addr)\n{\n\tstruct xor_cb *xcb = desc->hw_desc;\n\n\txcb->ops[xor_arg_no].h |= DMA_CUED_XOR_BASE;\n\txcb->ops[xor_arg_no].l = addr;\n}\n\n \nstatic void ppc440spe_rxor_set_mult(struct ppc440spe_adma_desc_slot *desc,\n\tu8 xor_arg_no, u8 idx, u8 mult)\n{\n\tstruct xor_cb *xcb = desc->hw_desc;\n\n\txcb->ops[xor_arg_no].h |= mult << (DMA_CUED_MULT1_OFF + idx * 8);\n}\n\n \nstatic void ppc440spe_adma_check_threshold(struct ppc440spe_adma_chan *chan)\n{\n\tdev_dbg(chan->device->common.dev, \"ppc440spe adma%d: pending: %d\\n\",\n\t\tchan->device->id, chan->pending);\n\n\tif (chan->pending >= PPC440SPE_ADMA_THRESHOLD) {\n\t\tchan->pending = 0;\n\t\tppc440spe_chan_append(chan);\n\t}\n}\n\n \nstatic dma_cookie_t ppc440spe_adma_tx_submit(struct dma_async_tx_descriptor *tx)\n{\n\tstruct ppc440spe_adma_desc_slot *sw_desc;\n\tstruct ppc440spe_adma_chan *chan = to_ppc440spe_adma_chan(tx->chan);\n\tstruct ppc440spe_adma_desc_slot *group_start, *old_chain_tail;\n\tint slot_cnt;\n\tint slots_per_op;\n\tdma_cookie_t cookie;\n\n\tsw_desc = tx_to_ppc440spe_adma_slot(tx);\n\n\tgroup_start = sw_desc->group_head;\n\tslot_cnt = group_start->slot_cnt;\n\tslots_per_op = group_start->slots_per_op;\n\n\tspin_lock_bh(&chan->lock);\n\tcookie = dma_cookie_assign(tx);\n\n\tif (unlikely(list_empty(&chan->chain))) {\n\t\t \n\t\tlist_splice_init(&sw_desc->group_list, &chan->chain);\n\t\tchan_first_cdb[chan->device->id] = group_start;\n\t} else {\n\t\t \n\t\told_chain_tail = list_entry(chan->chain.prev,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\t\tlist_splice_init(&sw_desc->group_list,\n\t\t    &old_chain_tail->chain_node);\n\t\t \n\t\tppc440spe_desc_set_link(chan, old_chain_tail, group_start);\n\t}\n\n\t \n\tchan->pending += slot_cnt / slots_per_op;\n\tppc440spe_adma_check_threshold(chan);\n\tspin_unlock_bh(&chan->lock);\n\n\tdev_dbg(chan->device->common.dev,\n\t\t\"ppc440spe adma%d: %s cookie: %d slot: %d tx %p\\n\",\n\t\tchan->device->id, __func__,\n\t\tsw_desc->async_tx.cookie, sw_desc->idx, sw_desc);\n\n\treturn cookie;\n}\n\n \nstatic struct dma_async_tx_descriptor *ppc440spe_adma_prep_dma_interrupt(\n\t\tstruct dma_chan *chan, unsigned long flags)\n{\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\tstruct ppc440spe_adma_desc_slot *sw_desc, *group_start;\n\tint slot_cnt, slots_per_op;\n\n\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\n\tdev_dbg(ppc440spe_chan->device->common.dev,\n\t\t\"ppc440spe adma%d: %s\\n\", ppc440spe_chan->device->id,\n\t\t__func__);\n\n\tspin_lock_bh(&ppc440spe_chan->lock);\n\tslot_cnt = slots_per_op = 1;\n\tsw_desc = ppc440spe_adma_alloc_slots(ppc440spe_chan, slot_cnt,\n\t\t\tslots_per_op);\n\tif (sw_desc) {\n\t\tgroup_start = sw_desc->group_head;\n\t\tppc440spe_desc_init_interrupt(group_start, ppc440spe_chan);\n\t\tgroup_start->unmap_len = 0;\n\t\tsw_desc->async_tx.flags = flags;\n\t}\n\tspin_unlock_bh(&ppc440spe_chan->lock);\n\n\treturn sw_desc ? &sw_desc->async_tx : NULL;\n}\n\n \nstatic struct dma_async_tx_descriptor *ppc440spe_adma_prep_dma_memcpy(\n\t\tstruct dma_chan *chan, dma_addr_t dma_dest,\n\t\tdma_addr_t dma_src, size_t len, unsigned long flags)\n{\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\tstruct ppc440spe_adma_desc_slot *sw_desc, *group_start;\n\tint slot_cnt, slots_per_op;\n\n\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\n\tif (unlikely(!len))\n\t\treturn NULL;\n\n\tBUG_ON(len > PPC440SPE_ADMA_DMA_MAX_BYTE_COUNT);\n\n\tspin_lock_bh(&ppc440spe_chan->lock);\n\n\tdev_dbg(ppc440spe_chan->device->common.dev,\n\t\t\"ppc440spe adma%d: %s len: %u int_en %d\\n\",\n\t\tppc440spe_chan->device->id, __func__, len,\n\t\tflags & DMA_PREP_INTERRUPT ? 1 : 0);\n\tslot_cnt = slots_per_op = 1;\n\tsw_desc = ppc440spe_adma_alloc_slots(ppc440spe_chan, slot_cnt,\n\t\tslots_per_op);\n\tif (sw_desc) {\n\t\tgroup_start = sw_desc->group_head;\n\t\tppc440spe_desc_init_memcpy(group_start, flags);\n\t\tppc440spe_adma_set_dest(group_start, dma_dest, 0);\n\t\tppc440spe_adma_memcpy_xor_set_src(group_start, dma_src, 0);\n\t\tppc440spe_desc_set_byte_count(group_start, ppc440spe_chan, len);\n\t\tsw_desc->unmap_len = len;\n\t\tsw_desc->async_tx.flags = flags;\n\t}\n\tspin_unlock_bh(&ppc440spe_chan->lock);\n\n\treturn sw_desc ? &sw_desc->async_tx : NULL;\n}\n\n \nstatic struct dma_async_tx_descriptor *ppc440spe_adma_prep_dma_xor(\n\t\tstruct dma_chan *chan, dma_addr_t dma_dest,\n\t\tdma_addr_t *dma_src, u32 src_cnt, size_t len,\n\t\tunsigned long flags)\n{\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\tstruct ppc440spe_adma_desc_slot *sw_desc, *group_start;\n\tint slot_cnt, slots_per_op;\n\n\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\n\tADMA_LL_DBG(prep_dma_xor_dbg(ppc440spe_chan->device->id,\n\t\t\t\t     dma_dest, dma_src, src_cnt));\n\tif (unlikely(!len))\n\t\treturn NULL;\n\tBUG_ON(len > PPC440SPE_ADMA_XOR_MAX_BYTE_COUNT);\n\n\tdev_dbg(ppc440spe_chan->device->common.dev,\n\t\t\"ppc440spe adma%d: %s src_cnt: %d len: %u int_en: %d\\n\",\n\t\tppc440spe_chan->device->id, __func__, src_cnt, len,\n\t\tflags & DMA_PREP_INTERRUPT ? 1 : 0);\n\n\tspin_lock_bh(&ppc440spe_chan->lock);\n\tslot_cnt = ppc440spe_chan_xor_slot_count(len, src_cnt, &slots_per_op);\n\tsw_desc = ppc440spe_adma_alloc_slots(ppc440spe_chan, slot_cnt,\n\t\t\tslots_per_op);\n\tif (sw_desc) {\n\t\tgroup_start = sw_desc->group_head;\n\t\tppc440spe_desc_init_xor(group_start, src_cnt, flags);\n\t\tppc440spe_adma_set_dest(group_start, dma_dest, 0);\n\t\twhile (src_cnt--)\n\t\t\tppc440spe_adma_memcpy_xor_set_src(group_start,\n\t\t\t\tdma_src[src_cnt], src_cnt);\n\t\tppc440spe_desc_set_byte_count(group_start, ppc440spe_chan, len);\n\t\tsw_desc->unmap_len = len;\n\t\tsw_desc->async_tx.flags = flags;\n\t}\n\tspin_unlock_bh(&ppc440spe_chan->lock);\n\n\treturn sw_desc ? &sw_desc->async_tx : NULL;\n}\n\nstatic inline void\nppc440spe_desc_set_xor_src_cnt(struct ppc440spe_adma_desc_slot *desc,\n\t\t\t\tint src_cnt);\nstatic void ppc440spe_init_rxor_cursor(struct ppc440spe_rxor *cursor);\n\n \nstatic void ppc440spe_adma_init_dma2rxor_slot(\n\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\tdma_addr_t *src, int src_cnt)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < src_cnt; i++) {\n\t\tppc440spe_adma_dma2rxor_prep_src(desc, &desc->rxor_cursor, i,\n\t\t\t\t\t\t desc->src_cnt, (u32)src[i]);\n\t}\n}\n\n \nstatic struct ppc440spe_adma_desc_slot *ppc440spe_dma01_prep_mult(\n\t\tstruct ppc440spe_adma_chan *ppc440spe_chan,\n\t\tdma_addr_t *dst, int dst_cnt, dma_addr_t *src, int src_cnt,\n\t\tconst unsigned char *scf, size_t len, unsigned long flags)\n{\n\tstruct ppc440spe_adma_desc_slot *sw_desc = NULL;\n\tunsigned long op = 0;\n\tint slot_cnt;\n\n\tset_bit(PPC440SPE_DESC_WXOR, &op);\n\tslot_cnt = 2;\n\n\tspin_lock_bh(&ppc440spe_chan->lock);\n\n\t \n\tsw_desc = ppc440spe_adma_alloc_slots(ppc440spe_chan, slot_cnt, 1);\n\tif (sw_desc) {\n\t\tstruct ppc440spe_adma_chan *chan;\n\t\tstruct ppc440spe_adma_desc_slot *iter;\n\t\tstruct dma_cdb *hw_desc;\n\n\t\tchan = to_ppc440spe_adma_chan(sw_desc->async_tx.chan);\n\t\tset_bits(op, &sw_desc->flags);\n\t\tsw_desc->src_cnt = src_cnt;\n\t\tsw_desc->dst_cnt = dst_cnt;\n\t\t \n\t\titer = list_first_entry(&sw_desc->group_list,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\t\tmemset(iter->hw_desc, 0, sizeof(struct dma_cdb));\n\t\t \n\t\titer->hw_next = list_entry(iter->chain_node.next,\n\t\t\t\t\t   struct ppc440spe_adma_desc_slot,\n\t\t\t\t\t   chain_node);\n\t\tclear_bit(PPC440SPE_DESC_INT, &iter->flags);\n\t\thw_desc = iter->hw_desc;\n\t\thw_desc->opc = DMA_CDB_OPC_MULTICAST;\n\n\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t     DMA_CUED_XOR_BASE, dst[0], 0);\n\t\tppc440spe_desc_set_dest_addr(iter, chan, 0, dst[1], 1);\n\t\tppc440spe_desc_set_src_addr(iter, chan, 0, DMA_CUED_XOR_HB,\n\t\t\t\t\t    src[0]);\n\t\tppc440spe_desc_set_byte_count(iter, ppc440spe_chan, len);\n\t\titer->unmap_len = len;\n\n\t\t \n\t\titer = list_first_entry(&iter->chain_node,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\t\tmemset(iter->hw_desc, 0, sizeof(struct dma_cdb));\n\t\titer->hw_next = NULL;\n\t\tif (flags & DMA_PREP_INTERRUPT)\n\t\t\tset_bit(PPC440SPE_DESC_INT, &iter->flags);\n\t\telse\n\t\t\tclear_bit(PPC440SPE_DESC_INT, &iter->flags);\n\n\t\thw_desc = iter->hw_desc;\n\t\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n\t\tppc440spe_desc_set_src_addr(iter, chan, 0,\n\t\t\t\t\t    DMA_CUED_XOR_HB, dst[1]);\n\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t     DMA_CUED_XOR_BASE, dst[0], 0);\n\n\t\tppc440spe_desc_set_src_mult(iter, chan, DMA_CUED_MULT1_OFF,\n\t\t\t\t\t    DMA_CDB_SG_DST1, scf[0]);\n\t\tppc440spe_desc_set_byte_count(iter, ppc440spe_chan, len);\n\t\titer->unmap_len = len;\n\t\tsw_desc->async_tx.flags = flags;\n\t}\n\n\tspin_unlock_bh(&ppc440spe_chan->lock);\n\n\treturn sw_desc;\n}\n\n \nstatic struct ppc440spe_adma_desc_slot *ppc440spe_dma01_prep_sum_product(\n\t\tstruct ppc440spe_adma_chan *ppc440spe_chan,\n\t\tdma_addr_t *dst, dma_addr_t *src, int src_cnt,\n\t\tconst unsigned char *scf, size_t len, unsigned long flags)\n{\n\tstruct ppc440spe_adma_desc_slot *sw_desc = NULL;\n\tunsigned long op = 0;\n\tint slot_cnt;\n\n\tset_bit(PPC440SPE_DESC_WXOR, &op);\n\tslot_cnt = 3;\n\n\tspin_lock_bh(&ppc440spe_chan->lock);\n\n\t \n\tsw_desc = ppc440spe_adma_alloc_slots(ppc440spe_chan, slot_cnt, 1);\n\tif (sw_desc) {\n\t\tstruct ppc440spe_adma_chan *chan;\n\t\tstruct ppc440spe_adma_desc_slot *iter;\n\t\tstruct dma_cdb *hw_desc;\n\n\t\tchan = to_ppc440spe_adma_chan(sw_desc->async_tx.chan);\n\t\tset_bits(op, &sw_desc->flags);\n\t\tsw_desc->src_cnt = src_cnt;\n\t\tsw_desc->dst_cnt = 1;\n\t\t \n\t\titer = list_first_entry(&sw_desc->group_list,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\t\tmemset(iter->hw_desc, 0, sizeof(struct dma_cdb));\n\t\titer->hw_next = list_entry(iter->chain_node.next,\n\t\t\t\t\t   struct ppc440spe_adma_desc_slot,\n\t\t\t\t\t   chain_node);\n\t\tclear_bit(PPC440SPE_DESC_INT, &iter->flags);\n\t\thw_desc = iter->hw_desc;\n\t\thw_desc->opc = DMA_CDB_OPC_MULTICAST;\n\n\t\tppc440spe_desc_set_dest_addr(iter, chan, DMA_CUED_XOR_BASE,\n\t\t\t\t\t     *dst, 0);\n\t\tppc440spe_desc_set_dest_addr(iter, chan, 0,\n\t\t\t\t\t     ppc440spe_chan->qdest, 1);\n\t\tppc440spe_desc_set_src_addr(iter, chan, 0, DMA_CUED_XOR_HB,\n\t\t\t\t\t    src[1]);\n\t\tppc440spe_desc_set_byte_count(iter, ppc440spe_chan, len);\n\t\titer->unmap_len = len;\n\n\t\t \n\t\titer = list_first_entry(&iter->chain_node,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\t\tmemset(iter->hw_desc, 0, sizeof(struct dma_cdb));\n\t\t \n\t\titer->hw_next = list_entry(iter->chain_node.next,\n\t\t\t\t\t   struct ppc440spe_adma_desc_slot,\n\t\t\t\t\t   chain_node);\n\t\tif (flags & DMA_PREP_INTERRUPT)\n\t\t\tset_bit(PPC440SPE_DESC_INT, &iter->flags);\n\t\telse\n\t\t\tclear_bit(PPC440SPE_DESC_INT, &iter->flags);\n\n\t\thw_desc = iter->hw_desc;\n\t\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n\t\tppc440spe_desc_set_src_addr(iter, chan, 0, DMA_CUED_XOR_HB,\n\t\t\t\t\t    ppc440spe_chan->qdest);\n\t\tppc440spe_desc_set_dest_addr(iter, chan, DMA_CUED_XOR_BASE,\n\t\t\t\t\t     *dst, 0);\n\t\tppc440spe_desc_set_src_mult(iter, chan,\tDMA_CUED_MULT1_OFF,\n\t\t\t\t\t    DMA_CDB_SG_DST1, scf[1]);\n\t\tppc440spe_desc_set_byte_count(iter, ppc440spe_chan, len);\n\t\titer->unmap_len = len;\n\n\t\t \n\t\titer = list_first_entry(&iter->chain_node,\n\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\tchain_node);\n\t\tmemset(iter->hw_desc, 0, sizeof(struct dma_cdb));\n\t\titer->hw_next = NULL;\n\t\tif (flags & DMA_PREP_INTERRUPT)\n\t\t\tset_bit(PPC440SPE_DESC_INT, &iter->flags);\n\t\telse\n\t\t\tclear_bit(PPC440SPE_DESC_INT, &iter->flags);\n\n\t\thw_desc = iter->hw_desc;\n\t\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n\t\tppc440spe_desc_set_src_addr(iter, chan, 0, DMA_CUED_XOR_HB,\n\t\t\t\t\t    src[0]);\n\t\tppc440spe_desc_set_dest_addr(iter, chan, DMA_CUED_XOR_BASE,\n\t\t\t\t\t     *dst, 0);\n\t\tppc440spe_desc_set_src_mult(iter, chan, DMA_CUED_MULT1_OFF,\n\t\t\t\t\t    DMA_CDB_SG_DST1, scf[0]);\n\t\tppc440spe_desc_set_byte_count(iter, ppc440spe_chan, len);\n\t\titer->unmap_len = len;\n\t\tsw_desc->async_tx.flags = flags;\n\t}\n\n\tspin_unlock_bh(&ppc440spe_chan->lock);\n\n\treturn sw_desc;\n}\n\nstatic struct ppc440spe_adma_desc_slot *ppc440spe_dma01_prep_pq(\n\t\tstruct ppc440spe_adma_chan *ppc440spe_chan,\n\t\tdma_addr_t *dst, int dst_cnt, dma_addr_t *src, int src_cnt,\n\t\tconst unsigned char *scf, size_t len, unsigned long flags)\n{\n\tint slot_cnt;\n\tstruct ppc440spe_adma_desc_slot *sw_desc = NULL, *iter;\n\tunsigned long op = 0;\n\tunsigned char mult = 1;\n\n\tpr_debug(\"%s: dst_cnt %d, src_cnt %d, len %d\\n\",\n\t\t __func__, dst_cnt, src_cnt, len);\n\t \n\tset_bit(PPC440SPE_DESC_WXOR, &op);\n\tif (!test_and_set_bit(PPC440SPE_RXOR_RUN, &ppc440spe_rxor_state)) {\n\t\t \n\t\tif (src_cnt > 1 &&\n\t\t    !(len & MQ0_CF2H_RXOR_BS_MASK) &&\n\t\t    (src[0] + len) == src[1]) {\n\t\t\t \n\t\t\tset_bit(PPC440SPE_DESC_RXOR, &op);\n\t\t\tif (src_cnt != 2) {\n\t\t\t\t \n\t\t\t\tif ((src[1] + len) == src[2]) {\n\t\t\t\t\t \n\t\t\t\t\tset_bit(PPC440SPE_DESC_RXOR123,\n\t\t\t\t\t\t&op);\n\t\t\t\t} else if ((src[1] + len * 2) == src[2]) {\n\t\t\t\t\t \n\t\t\t\t\tset_bit(PPC440SPE_DESC_RXOR124, &op);\n\t\t\t\t} else if ((src[1] + len * 3) == src[2]) {\n\t\t\t\t\t \n\t\t\t\t\tset_bit(PPC440SPE_DESC_RXOR125,\n\t\t\t\t\t\t&op);\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tset_bit(PPC440SPE_DESC_RXOR12,\n\t\t\t\t\t\t&op);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tset_bit(PPC440SPE_DESC_RXOR12, &op);\n\t\t\t}\n\t\t}\n\n\t\tif (!test_bit(PPC440SPE_DESC_RXOR, &op)) {\n\t\t\t \n\t\t\tclear_bit(PPC440SPE_RXOR_RUN,\n\t\t\t\t&ppc440spe_rxor_state);\n\t\t} else {\n\t\t\t \n\t\t\tppc440spe_desc_set_rxor_block_size(len);\n\t\t}\n\t}\n\n\t \n\tif (!test_bit(PPC440SPE_DESC_RXOR, &op)) {\n\t\t \n\t\tslot_cnt = src_cnt;\n\n\t\tif (flags & DMA_PREP_ZERO_P) {\n\t\t\tslot_cnt++;\n\t\t\tset_bit(PPC440SPE_ZERO_P, &op);\n\t\t}\n\t\tif (flags & DMA_PREP_ZERO_Q) {\n\t\t\tslot_cnt++;\n\t\t\tset_bit(PPC440SPE_ZERO_Q, &op);\n\t\t}\n\t} else {\n\t\t \n\t\tslot_cnt = dst_cnt;\n\n\t\tif (flags & DMA_PREP_ZERO_P)\n\t\t\tset_bit(PPC440SPE_ZERO_P, &op);\n\t\tif (flags & DMA_PREP_ZERO_Q)\n\t\t\tset_bit(PPC440SPE_ZERO_Q, &op);\n\n\t\tif (test_bit(PPC440SPE_DESC_RXOR12, &op))\n\t\t\tslot_cnt += src_cnt - 2;\n\t\telse\n\t\t\tslot_cnt += src_cnt - 3;\n\n\t\t \n\t\tif (slot_cnt == dst_cnt)\n\t\t\t \n\t\t\tclear_bit(PPC440SPE_DESC_WXOR, &op);\n\t}\n\n\tspin_lock_bh(&ppc440spe_chan->lock);\n\t \n\tsw_desc = ppc440spe_adma_alloc_slots(ppc440spe_chan, slot_cnt, 1);\n\tif (sw_desc) {\n\t\tppc440spe_desc_init_dma01pq(sw_desc, dst_cnt, src_cnt,\n\t\t\t\tflags, op);\n\n\t\t \n\t\tpr_debug(\"%s: set dst descriptor 0, 1: 0x%016llx, 0x%016llx\\n\",\n\t\t\t __func__, dst[0], dst[1]);\n\t\tppc440spe_adma_pq_set_dest(sw_desc, dst, flags);\n\t\twhile (src_cnt--) {\n\t\t\tppc440spe_adma_pq_set_src(sw_desc, src[src_cnt],\n\t\t\t\t\t\t  src_cnt);\n\n\t\t\t \n\t\t\tif (!(flags & DMA_PREP_PQ_DISABLE_Q))\n\t\t\t\tmult = scf[src_cnt];\n\t\t\tppc440spe_adma_pq_set_src_mult(sw_desc,\n\t\t\t\tmult, src_cnt,  dst_cnt - 1);\n\t\t}\n\n\t\t \n\t\tsw_desc->async_tx.flags = flags;\n\t\tlist_for_each_entry(iter, &sw_desc->group_list,\n\t\t\t\tchain_node) {\n\t\t\tppc440spe_desc_set_byte_count(iter,\n\t\t\t\tppc440spe_chan, len);\n\t\t\titer->unmap_len = len;\n\t\t}\n\t}\n\tspin_unlock_bh(&ppc440spe_chan->lock);\n\n\treturn sw_desc;\n}\n\nstatic struct ppc440spe_adma_desc_slot *ppc440spe_dma2_prep_pq(\n\t\tstruct ppc440spe_adma_chan *ppc440spe_chan,\n\t\tdma_addr_t *dst, int dst_cnt, dma_addr_t *src, int src_cnt,\n\t\tconst unsigned char *scf, size_t len, unsigned long flags)\n{\n\tint slot_cnt, descs_per_op;\n\tstruct ppc440spe_adma_desc_slot *sw_desc = NULL, *iter;\n\tunsigned long op = 0;\n\tunsigned char mult = 1;\n\n\tBUG_ON(!dst_cnt);\n\t \n\n\tspin_lock_bh(&ppc440spe_chan->lock);\n\tdescs_per_op = ppc440spe_dma2_pq_slot_count(src, src_cnt, len);\n\tif (descs_per_op < 0) {\n\t\tspin_unlock_bh(&ppc440spe_chan->lock);\n\t\treturn NULL;\n\t}\n\n\t \n\tslot_cnt = descs_per_op * dst_cnt;\n\n\tsw_desc = ppc440spe_adma_alloc_slots(ppc440spe_chan, slot_cnt, 1);\n\tif (sw_desc) {\n\t\top = slot_cnt;\n\t\tsw_desc->async_tx.flags = flags;\n\t\tlist_for_each_entry(iter, &sw_desc->group_list, chain_node) {\n\t\t\tppc440spe_desc_init_dma2pq(iter, dst_cnt, src_cnt,\n\t\t\t\t--op ? 0 : flags);\n\t\t\tppc440spe_desc_set_byte_count(iter, ppc440spe_chan,\n\t\t\t\tlen);\n\t\t\titer->unmap_len = len;\n\n\t\t\tppc440spe_init_rxor_cursor(&(iter->rxor_cursor));\n\t\t\titer->rxor_cursor.len = len;\n\t\t\titer->descs_per_op = descs_per_op;\n\t\t}\n\t\top = 0;\n\t\tlist_for_each_entry(iter, &sw_desc->group_list, chain_node) {\n\t\t\top++;\n\t\t\tif (op % descs_per_op == 0)\n\t\t\t\tppc440spe_adma_init_dma2rxor_slot(iter, src,\n\t\t\t\t\t\t\t\t  src_cnt);\n\t\t\tif (likely(!list_is_last(&iter->chain_node,\n\t\t\t\t\t\t &sw_desc->group_list))) {\n\t\t\t\t \n\t\t\t\titer->hw_next =\n\t\t\t\t\tlist_entry(iter->chain_node.next,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tchain_node);\n\t\t\t\tppc440spe_xor_set_link(iter, iter->hw_next);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\titer->hw_next = NULL;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tsw_desc->dst_cnt = dst_cnt;\n\t\tif (flags & DMA_PREP_ZERO_P)\n\t\t\tset_bit(PPC440SPE_ZERO_P, &sw_desc->flags);\n\t\tif (flags & DMA_PREP_ZERO_Q)\n\t\t\tset_bit(PPC440SPE_ZERO_Q, &sw_desc->flags);\n\n\t\t \n\t\tppc440spe_adma_pq_set_dest(sw_desc, dst, flags);\n\n\t\twhile (src_cnt--) {\n\t\t\t \n\t\t\tppc440spe_adma_pq_set_src(sw_desc, src[src_cnt],\n\t\t\t\t\t\t  src_cnt);\n\t\t\tif (!(flags & DMA_PREP_PQ_DISABLE_Q))\n\t\t\t\tmult = scf[src_cnt];\n\t\t\tppc440spe_adma_pq_set_src_mult(sw_desc,\n\t\t\t\t\tmult, src_cnt, dst_cnt - 1);\n\t\t}\n\t}\n\tspin_unlock_bh(&ppc440spe_chan->lock);\n\tppc440spe_desc_set_rxor_block_size(len);\n\treturn sw_desc;\n}\n\n \nstatic struct dma_async_tx_descriptor *ppc440spe_adma_prep_dma_pq(\n\t\tstruct dma_chan *chan, dma_addr_t *dst, dma_addr_t *src,\n\t\tunsigned int src_cnt, const unsigned char *scf,\n\t\tsize_t len, unsigned long flags)\n{\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\tstruct ppc440spe_adma_desc_slot *sw_desc = NULL;\n\tint dst_cnt = 0;\n\n\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\n\tADMA_LL_DBG(prep_dma_pq_dbg(ppc440spe_chan->device->id,\n\t\t\t\t    dst, src, src_cnt));\n\tBUG_ON(!len);\n\tBUG_ON(len > PPC440SPE_ADMA_XOR_MAX_BYTE_COUNT);\n\tBUG_ON(!src_cnt);\n\n\tif (src_cnt == 1 && dst[1] == src[0]) {\n\t\tdma_addr_t dest[2];\n\n\t\t \n\t\tdest[0] = dst[1];\n\t\t \n\t\tdest[1] = ppc440spe_chan->qdest;\n\t\tsw_desc = ppc440spe_dma01_prep_mult(ppc440spe_chan,\n\t\t\t\tdest, 2, src, src_cnt, scf, len, flags);\n\t\treturn sw_desc ? &sw_desc->async_tx : NULL;\n\t}\n\n\tif (src_cnt == 2 && dst[1] == src[1]) {\n\t\tsw_desc = ppc440spe_dma01_prep_sum_product(ppc440spe_chan,\n\t\t\t\t\t&dst[1], src, 2, scf, len, flags);\n\t\treturn sw_desc ? &sw_desc->async_tx : NULL;\n\t}\n\n\tif (!(flags & DMA_PREP_PQ_DISABLE_P)) {\n\t\tBUG_ON(!dst[0]);\n\t\tdst_cnt++;\n\t\tflags |= DMA_PREP_ZERO_P;\n\t}\n\n\tif (!(flags & DMA_PREP_PQ_DISABLE_Q)) {\n\t\tBUG_ON(!dst[1]);\n\t\tdst_cnt++;\n\t\tflags |= DMA_PREP_ZERO_Q;\n\t}\n\n\tBUG_ON(!dst_cnt);\n\n\tdev_dbg(ppc440spe_chan->device->common.dev,\n\t\t\"ppc440spe adma%d: %s src_cnt: %d len: %u int_en: %d\\n\",\n\t\tppc440spe_chan->device->id, __func__, src_cnt, len,\n\t\tflags & DMA_PREP_INTERRUPT ? 1 : 0);\n\n\tswitch (ppc440spe_chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tsw_desc = ppc440spe_dma01_prep_pq(ppc440spe_chan,\n\t\t\t\tdst, dst_cnt, src, src_cnt, scf,\n\t\t\t\tlen, flags);\n\t\tbreak;\n\n\tcase PPC440SPE_XOR_ID:\n\t\tsw_desc = ppc440spe_dma2_prep_pq(ppc440spe_chan,\n\t\t\t\tdst, dst_cnt, src, src_cnt, scf,\n\t\t\t\tlen, flags);\n\t\tbreak;\n\t}\n\n\treturn sw_desc ? &sw_desc->async_tx : NULL;\n}\n\n \nstatic struct dma_async_tx_descriptor *ppc440spe_adma_prep_dma_pqzero_sum(\n\t\tstruct dma_chan *chan, dma_addr_t *pq, dma_addr_t *src,\n\t\tunsigned int src_cnt, const unsigned char *scf, size_t len,\n\t\tenum sum_check_flags *pqres, unsigned long flags)\n{\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\tstruct ppc440spe_adma_desc_slot *sw_desc, *iter;\n\tdma_addr_t pdest, qdest;\n\tint slot_cnt, slots_per_op, idst, dst_cnt;\n\n\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\n\tif (flags & DMA_PREP_PQ_DISABLE_P)\n\t\tpdest = 0;\n\telse\n\t\tpdest = pq[0];\n\n\tif (flags & DMA_PREP_PQ_DISABLE_Q)\n\t\tqdest = 0;\n\telse\n\t\tqdest = pq[1];\n\n\tADMA_LL_DBG(prep_dma_pqzero_sum_dbg(ppc440spe_chan->device->id,\n\t\t\t\t\t    src, src_cnt, scf));\n\n\t \n\tidst = dst_cnt = (pdest && qdest) ? 2 : 1;\n\n\t \n\tslot_cnt = src_cnt + dst_cnt * 2;\n\tslots_per_op = 1;\n\n\tspin_lock_bh(&ppc440spe_chan->lock);\n\tsw_desc = ppc440spe_adma_alloc_slots(ppc440spe_chan, slot_cnt,\n\t\t\t\t\t     slots_per_op);\n\tif (sw_desc) {\n\t\tppc440spe_desc_init_dma01pqzero_sum(sw_desc, dst_cnt, src_cnt);\n\n\t\t \n\t\tsw_desc->async_tx.flags = flags;\n\t\tlist_for_each_entry(iter, &sw_desc->group_list, chain_node) {\n\t\t\tppc440spe_desc_set_byte_count(iter, ppc440spe_chan,\n\t\t\t\t\t\t      len);\n\t\t\titer->unmap_len = len;\n\t\t}\n\n\t\tif (pdest) {\n\t\t\tstruct dma_cdb *hw_desc;\n\t\t\tstruct ppc440spe_adma_chan *chan;\n\n\t\t\titer = sw_desc->group_head;\n\t\t\tchan = to_ppc440spe_adma_chan(iter->async_tx.chan);\n\t\t\tmemset(iter->hw_desc, 0, sizeof(struct dma_cdb));\n\t\t\titer->hw_next = list_entry(iter->chain_node.next,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tchain_node);\n\t\t\thw_desc = iter->hw_desc;\n\t\t\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n\t\t\titer->src_cnt = 0;\n\t\t\titer->dst_cnt = 0;\n\t\t\tppc440spe_desc_set_dest_addr(iter, chan, 0,\n\t\t\t\t\t\t     ppc440spe_chan->pdest, 0);\n\t\t\tppc440spe_desc_set_src_addr(iter, chan, 0, 0, pdest);\n\t\t\tppc440spe_desc_set_byte_count(iter, ppc440spe_chan,\n\t\t\t\t\t\t      len);\n\t\t\titer->unmap_len = 0;\n\t\t\t \n\t\t\tpdest = ppc440spe_chan->pdest;\n\t\t}\n\t\tif (qdest) {\n\t\t\tstruct dma_cdb *hw_desc;\n\t\t\tstruct ppc440spe_adma_chan *chan;\n\n\t\t\titer = list_first_entry(&sw_desc->group_list,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tchain_node);\n\t\t\tchan = to_ppc440spe_adma_chan(iter->async_tx.chan);\n\n\t\t\tif (pdest) {\n\t\t\t\titer = list_entry(iter->chain_node.next,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tchain_node);\n\t\t\t}\n\n\t\t\tmemset(iter->hw_desc, 0, sizeof(struct dma_cdb));\n\t\t\titer->hw_next = list_entry(iter->chain_node.next,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tchain_node);\n\t\t\thw_desc = iter->hw_desc;\n\t\t\thw_desc->opc = DMA_CDB_OPC_MV_SG1_SG2;\n\t\t\titer->src_cnt = 0;\n\t\t\titer->dst_cnt = 0;\n\t\t\tppc440spe_desc_set_dest_addr(iter, chan, 0,\n\t\t\t\t\t\t     ppc440spe_chan->qdest, 0);\n\t\t\tppc440spe_desc_set_src_addr(iter, chan, 0, 0, qdest);\n\t\t\tppc440spe_desc_set_byte_count(iter, ppc440spe_chan,\n\t\t\t\t\t\t      len);\n\t\t\titer->unmap_len = 0;\n\t\t\t \n\t\t\tqdest = ppc440spe_chan->qdest;\n\t\t}\n\n\t\t \n\t\tppc440spe_adma_pqzero_sum_set_dest(sw_desc, pdest, qdest);\n\n\t\t \n\t\tidst = dst_cnt;\n\t\tlist_for_each_entry_reverse(iter, &sw_desc->group_list,\n\t\t\t\t\t    chain_node) {\n\t\t\t \n\t\t\tif (idst == DMA_DEST_MAX_NUM) {\n\t\t\t\tif (idst == dst_cnt) {\n\t\t\t\t\tset_bit(PPC440SPE_DESC_QCHECK,\n\t\t\t\t\t\t&iter->flags);\n\t\t\t\t} else {\n\t\t\t\t\tset_bit(PPC440SPE_DESC_PCHECK,\n\t\t\t\t\t\t&iter->flags);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (qdest) {\n\t\t\t\t\tset_bit(PPC440SPE_DESC_QCHECK,\n\t\t\t\t\t\t&iter->flags);\n\t\t\t\t} else {\n\t\t\t\t\tset_bit(PPC440SPE_DESC_PCHECK,\n\t\t\t\t\t\t&iter->flags);\n\t\t\t\t}\n\t\t\t}\n\t\t\titer->xor_check_result = pqres;\n\n\t\t\t \n\t\t\t*iter->xor_check_result = 0;\n\t\t\tppc440spe_desc_set_dcheck(iter, ppc440spe_chan,\n\t\t\t\tppc440spe_qword);\n\n\t\t\tif (!(--dst_cnt))\n\t\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tlist_for_each_entry_continue_reverse(iter, &sw_desc->group_list,\n\t\t\t\t\t\t     chain_node) {\n\t\t\tstruct ppc440spe_adma_chan *chan;\n\t\t\tu32 mult_dst;\n\n\t\t\tchan = to_ppc440spe_adma_chan(iter->async_tx.chan);\n\t\t\tppc440spe_desc_set_src_addr(iter, chan, 0,\n\t\t\t\t\t\t    DMA_CUED_XOR_HB,\n\t\t\t\t\t\t    src[src_cnt - 1]);\n\t\t\tif (qdest) {\n\t\t\t\tmult_dst = (dst_cnt - 1) ? DMA_CDB_SG_DST2 :\n\t\t\t\t\t\t\t   DMA_CDB_SG_DST1;\n\t\t\t\tppc440spe_desc_set_src_mult(iter, chan,\n\t\t\t\t\t\t\t    DMA_CUED_MULT1_OFF,\n\t\t\t\t\t\t\t    mult_dst,\n\t\t\t\t\t\t\t    scf[src_cnt - 1]);\n\t\t\t}\n\t\t\tif (!(--src_cnt))\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_bh(&ppc440spe_chan->lock);\n\treturn sw_desc ? &sw_desc->async_tx : NULL;\n}\n\n \nstatic struct dma_async_tx_descriptor *ppc440spe_adma_prep_dma_xor_zero_sum(\n\t\tstruct dma_chan *chan, dma_addr_t *src, unsigned int src_cnt,\n\t\tsize_t len, enum sum_check_flags *result, unsigned long flags)\n{\n\tstruct dma_async_tx_descriptor *tx;\n\tdma_addr_t pq[2];\n\n\t \n\tpq[0] = src[0];\n\tpq[1] = 0;\n\tflags |= DMA_PREP_PQ_DISABLE_Q;\n\n\ttx = ppc440spe_adma_prep_dma_pqzero_sum(chan, pq, &src[1],\n\t\t\t\t\t\tsrc_cnt - 1, 0, len,\n\t\t\t\t\t\tresult, flags);\n\treturn tx;\n}\n\n \nstatic void ppc440spe_adma_set_dest(struct ppc440spe_adma_desc_slot *sw_desc,\n\t\tdma_addr_t addr, int index)\n{\n\tstruct ppc440spe_adma_chan *chan;\n\n\tBUG_ON(index >= sw_desc->dst_cnt);\n\n\tchan = to_ppc440spe_adma_chan(sw_desc->async_tx.chan);\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\t \n\t\tppc440spe_desc_set_dest_addr(sw_desc->group_head,\n\t\t\tchan, 0, addr, index);\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\tsw_desc = ppc440spe_get_group_entry(sw_desc, index);\n\t\tppc440spe_desc_set_dest_addr(sw_desc,\n\t\t\tchan, 0, addr, index);\n\t\tbreak;\n\t}\n}\n\nstatic void ppc440spe_adma_pq_zero_op(struct ppc440spe_adma_desc_slot *iter,\n\t\tstruct ppc440spe_adma_chan *chan, dma_addr_t addr)\n{\n\t \n\tppc440spe_desc_set_dest_addr(iter, chan, DMA_CUED_XOR_BASE, addr, 0);\n\n\t \n\tppc440spe_desc_set_src_addr(iter, chan, 0, DMA_CUED_XOR_HB, addr);\n\n\t \n\tppc440spe_desc_set_src_mult(iter, chan, DMA_CUED_MULT1_OFF,\n\t\t\t\t    DMA_CDB_SG_DST1, 1);\n}\n\n \nstatic void ppc440spe_adma_pq_set_dest(struct ppc440spe_adma_desc_slot *sw_desc,\n\t\tdma_addr_t *addrs, unsigned long flags)\n{\n\tstruct ppc440spe_adma_desc_slot *iter;\n\tstruct ppc440spe_adma_chan *chan;\n\tdma_addr_t paddr, qaddr;\n\tdma_addr_t addr = 0, ppath, qpath;\n\tint index = 0, i;\n\n\tchan = to_ppc440spe_adma_chan(sw_desc->async_tx.chan);\n\n\tif (flags & DMA_PREP_PQ_DISABLE_P)\n\t\tpaddr = 0;\n\telse\n\t\tpaddr = addrs[0];\n\n\tif (flags & DMA_PREP_PQ_DISABLE_Q)\n\t\tqaddr = 0;\n\telse\n\t\tqaddr = addrs[1];\n\n\tif (!paddr || !qaddr)\n\t\taddr = paddr ? paddr : qaddr;\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\t \n\t\tif (!test_bit(PPC440SPE_DESC_RXOR, &sw_desc->flags)) {\n\t\t\t \n\t\t\tif (test_bit(PPC440SPE_ZERO_P, &sw_desc->flags))\n\t\t\t\tindex++;\n\t\t\tif (test_bit(PPC440SPE_ZERO_Q, &sw_desc->flags))\n\t\t\t\tindex++;\n\n\t\t\titer = ppc440spe_get_group_entry(sw_desc, index);\n\t\t\tif (addr) {\n\t\t\t\t \n\t\t\t\tlist_for_each_entry_from(iter,\n\t\t\t\t\t&sw_desc->group_list, chain_node)\n\t\t\t\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t\tDMA_CUED_XOR_BASE, addr, 0);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tlist_for_each_entry_from(iter,\n\t\t\t\t\t&sw_desc->group_list, chain_node) {\n\t\t\t\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t\tDMA_CUED_XOR_BASE, paddr, 0);\n\t\t\t\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t\tDMA_CUED_XOR_BASE, qaddr, 1);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (index) {\n\t\t\t\t \n\t\t\t\tindex = 0;\n\t\t\t\tif (test_bit(PPC440SPE_ZERO_P,\n\t\t\t\t\t\t&sw_desc->flags)) {\n\t\t\t\t\titer = ppc440spe_get_group_entry(\n\t\t\t\t\t\t\tsw_desc, index++);\n\t\t\t\t\tppc440spe_adma_pq_zero_op(iter, chan,\n\t\t\t\t\t\t\tpaddr);\n\t\t\t\t}\n\n\t\t\t\tif (test_bit(PPC440SPE_ZERO_Q,\n\t\t\t\t\t\t&sw_desc->flags)) {\n\t\t\t\t\titer = ppc440spe_get_group_entry(\n\t\t\t\t\t\t\tsw_desc, index++);\n\t\t\t\t\tppc440spe_adma_pq_zero_op(iter, chan,\n\t\t\t\t\t\t\tqaddr);\n\t\t\t\t}\n\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\n\t\t\t \n\t\t\tppath = test_bit(PPC440SPE_ZERO_P, &sw_desc->flags) ?\n\t\t\t\t\tDMA_CUED_XOR_HB :\n\t\t\t\t\tDMA_CUED_XOR_BASE |\n\t\t\t\t\t\t(1 << DMA_CUED_MULT1_OFF);\n\t\t\tqpath = test_bit(PPC440SPE_ZERO_Q, &sw_desc->flags) ?\n\t\t\t\t\tDMA_CUED_XOR_HB :\n\t\t\t\t\tDMA_CUED_XOR_BASE |\n\t\t\t\t\t\t(1 << DMA_CUED_MULT1_OFF);\n\n\t\t\t \n\t\t\titer = ppc440spe_get_group_entry(sw_desc, index++);\n\t\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t\tpaddr ? ppath : qpath,\n\t\t\t\t\t\tpaddr ? paddr : qaddr, 0);\n\t\t\tif (!addr) {\n\t\t\t\t \n\t\t\t\titer = ppc440spe_get_group_entry(sw_desc,\n\t\t\t\t\t\t\t\t index++);\n\t\t\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t\tqpath, qaddr, 0);\n\t\t\t}\n\n\t\t\tif (test_bit(PPC440SPE_DESC_WXOR, &sw_desc->flags)) {\n\t\t\t\t \n\t\t\t\titer = ppc440spe_get_group_entry(sw_desc,\n\t\t\t\t\t\t\t\t index);\n\t\t\t\tif (addr) {\n\t\t\t\t\t \n\t\t\t\t\tlist_for_each_entry_from(iter,\n\t\t\t\t\t    &sw_desc->group_list,\n\t\t\t\t\t    chain_node)\n\t\t\t\t\t\tppc440spe_desc_set_dest_addr(\n\t\t\t\t\t\t\titer, chan,\n\t\t\t\t\t\t\tDMA_CUED_XOR_BASE,\n\t\t\t\t\t\t\taddr, 0);\n\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tlist_for_each_entry_from(iter,\n\t\t\t\t\t    &sw_desc->group_list,\n\t\t\t\t\t    chain_node) {\n\t\t\t\t\t\tppc440spe_desc_set_dest_addr(\n\t\t\t\t\t\t\titer, chan,\n\t\t\t\t\t\t\tDMA_CUED_XOR_BASE,\n\t\t\t\t\t\t\tpaddr, 0);\n\t\t\t\t\t\tppc440spe_desc_set_dest_addr(\n\t\t\t\t\t\t\titer, chan,\n\t\t\t\t\t\t\tDMA_CUED_XOR_BASE,\n\t\t\t\t\t\t\tqaddr, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t}\n\t\tbreak;\n\n\tcase PPC440SPE_XOR_ID:\n\t\t \n\t\tppath = test_bit(PPC440SPE_ZERO_P, &sw_desc->flags) ?\n\t\t\t\tDMA_CUED_XOR_HB :\n\t\t\t\tDMA_CUED_XOR_BASE |\n\t\t\t\t\t(1 << DMA_CUED_MULT1_OFF);\n\n\t\tqpath = test_bit(PPC440SPE_ZERO_Q, &sw_desc->flags) ?\n\t\t\t\tDMA_CUED_XOR_HB :\n\t\t\t\tDMA_CUED_XOR_BASE |\n\t\t\t\t\t(1 << DMA_CUED_MULT1_OFF);\n\n\t\titer = ppc440spe_get_group_entry(sw_desc, 0);\n\t\tfor (i = 0; i < sw_desc->descs_per_op; i++) {\n\t\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\tpaddr ? ppath : qpath,\n\t\t\t\tpaddr ? paddr : qaddr, 0);\n\t\t\titer = list_entry(iter->chain_node.next,\n\t\t\t\t\t  struct ppc440spe_adma_desc_slot,\n\t\t\t\t\t  chain_node);\n\t\t}\n\n\t\tif (!addr) {\n\t\t\t \n\t\t\titer = ppc440spe_get_group_entry(sw_desc,\n\t\t\t\tsw_desc->descs_per_op);\n\t\t\tfor (i = 0; i < sw_desc->descs_per_op; i++) {\n\t\t\t\tppc440spe_desc_set_dest_addr(iter,\n\t\t\t\t\tchan, qpath, qaddr, 0);\n\t\t\t\titer = list_entry(iter->chain_node.next,\n\t\t\t\t\t\tstruct ppc440spe_adma_desc_slot,\n\t\t\t\t\t\tchain_node);\n\t\t\t}\n\t\t}\n\n\t\tbreak;\n\t}\n}\n\n \nstatic void ppc440spe_adma_pqzero_sum_set_dest(\n\t\tstruct ppc440spe_adma_desc_slot *sw_desc,\n\t\tdma_addr_t paddr, dma_addr_t qaddr)\n{\n\tstruct ppc440spe_adma_desc_slot *iter, *end;\n\tstruct ppc440spe_adma_chan *chan;\n\tdma_addr_t addr = 0;\n\tint idx;\n\n\tchan = to_ppc440spe_adma_chan(sw_desc->async_tx.chan);\n\n\t \n\tidx = (paddr && qaddr) ? 2 : 1;\n\t \n\tlist_for_each_entry_reverse(end, &sw_desc->group_list,\n\t\t\t\t    chain_node) {\n\t\tif (!(--idx))\n\t\t\tbreak;\n\t}\n\t \n\tidx = (paddr && qaddr) ? 2 : 1;\n\titer = ppc440spe_get_group_entry(sw_desc, idx);\n\n\tif (paddr && qaddr) {\n\t\t \n\t\tlist_for_each_entry_from(iter, &sw_desc->group_list,\n\t\t\t\t\t chain_node) {\n\t\t\tif (unlikely(iter == end))\n\t\t\t\tbreak;\n\t\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t\tDMA_CUED_XOR_BASE, paddr, 0);\n\t\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t\tDMA_CUED_XOR_BASE, qaddr, 1);\n\t\t}\n\t} else {\n\t\t \n\t\taddr = paddr ? paddr : qaddr;\n\t\tlist_for_each_entry_from(iter, &sw_desc->group_list,\n\t\t\t\t\t chain_node) {\n\t\t\tif (unlikely(iter == end))\n\t\t\t\tbreak;\n\t\t\tppc440spe_desc_set_dest_addr(iter, chan,\n\t\t\t\t\t\tDMA_CUED_XOR_BASE, addr, 0);\n\t\t}\n\t}\n\n\t \n\tppc440spe_desc_set_src_addr(end, chan, 0, 0, addr ? addr : paddr);\n\n\tif (!addr) {\n\t\tend = list_entry(end->chain_node.next,\n\t\t\t\t struct ppc440spe_adma_desc_slot, chain_node);\n\t\tppc440spe_desc_set_src_addr(end, chan, 0, 0, qaddr);\n\t}\n}\n\n \nstatic inline void ppc440spe_desc_set_xor_src_cnt(\n\t\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\t\tint src_cnt)\n{\n\tstruct xor_cb *hw_desc = desc->hw_desc;\n\n\thw_desc->cbc &= ~XOR_CDCR_OAC_MSK;\n\thw_desc->cbc |= src_cnt;\n}\n\n \nstatic void ppc440spe_adma_pq_set_src(struct ppc440spe_adma_desc_slot *sw_desc,\n\t\tdma_addr_t addr, int index)\n{\n\tstruct ppc440spe_adma_chan *chan;\n\tdma_addr_t haddr = 0;\n\tstruct ppc440spe_adma_desc_slot *iter = NULL;\n\n\tchan = to_ppc440spe_adma_chan(sw_desc->async_tx.chan);\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\t \n\t\tif (test_bit(PPC440SPE_DESC_RXOR, &sw_desc->flags)) {\n\t\t\t \n\t\t\tint iskip = test_bit(PPC440SPE_DESC_RXOR12,\n\t\t\t\t&sw_desc->flags) ?  2 : 3;\n\n\t\t\tif (index == 0) {\n\t\t\t\t \n\t\t\t\t \n\t\t\t\tif (test_bit(PPC440SPE_DESC_RXOR12,\n\t\t\t\t\t\t&sw_desc->flags))\n\t\t\t\t\thaddr = DMA_RXOR12 <<\n\t\t\t\t\t\tDMA_CUED_REGION_OFF;\n\t\t\t\telse if (test_bit(PPC440SPE_DESC_RXOR123,\n\t\t\t\t    &sw_desc->flags))\n\t\t\t\t\thaddr = DMA_RXOR123 <<\n\t\t\t\t\t\tDMA_CUED_REGION_OFF;\n\t\t\t\telse if (test_bit(PPC440SPE_DESC_RXOR124,\n\t\t\t\t    &sw_desc->flags))\n\t\t\t\t\thaddr = DMA_RXOR124 <<\n\t\t\t\t\t\tDMA_CUED_REGION_OFF;\n\t\t\t\telse if (test_bit(PPC440SPE_DESC_RXOR125,\n\t\t\t\t    &sw_desc->flags))\n\t\t\t\t\thaddr = DMA_RXOR125 <<\n\t\t\t\t\t\tDMA_CUED_REGION_OFF;\n\t\t\t\telse\n\t\t\t\t\tBUG();\n\t\t\t\thaddr |= DMA_CUED_XOR_BASE;\n\t\t\t\titer = ppc440spe_get_group_entry(sw_desc, 0);\n\t\t\t} else if (index < iskip) {\n\t\t\t\t \n\t\t\t\titer = NULL;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\thaddr = DMA_CUED_XOR_HB;\n\t\t\t\titer = ppc440spe_get_group_entry(sw_desc,\n\t\t\t\t    index - iskip + sw_desc->dst_cnt);\n\t\t\t}\n\t\t} else {\n\t\t\tint znum = 0;\n\n\t\t\t \n\t\t\tif (test_bit(PPC440SPE_ZERO_P, &sw_desc->flags))\n\t\t\t\tznum++;\n\t\t\tif (test_bit(PPC440SPE_ZERO_Q, &sw_desc->flags))\n\t\t\t\tznum++;\n\n\t\t\thaddr = DMA_CUED_XOR_HB;\n\t\t\titer = ppc440spe_get_group_entry(sw_desc,\n\t\t\t\t\tindex + znum);\n\t\t}\n\n\t\tif (likely(iter)) {\n\t\t\tppc440spe_desc_set_src_addr(iter, chan, 0, haddr, addr);\n\n\t\t\tif (!index &&\n\t\t\t    test_bit(PPC440SPE_DESC_RXOR, &sw_desc->flags) &&\n\t\t\t    sw_desc->dst_cnt == 2) {\n\t\t\t\t \n\t\t\t\titer = ppc440spe_get_group_entry(sw_desc, 1);\n\t\t\t\tppc440spe_desc_set_src_addr(iter, chan, 0,\n\t\t\t\t\thaddr, addr);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase PPC440SPE_XOR_ID:\n\t\t \n\t\titer = sw_desc->group_head;\n\t\tif (iter->dst_cnt == 2) {\n\t\t\t \n\t\t\tppc440spe_adma_dma2rxor_set_src(iter, index, addr);\n\n\t\t\t \n\t\t\titer = ppc440spe_get_group_entry(sw_desc,\n\t\t\t\tsw_desc->descs_per_op);\n\t\t}\n\t\tppc440spe_adma_dma2rxor_set_src(iter, index, addr);\n\t\tbreak;\n\t}\n}\n\n \nstatic void ppc440spe_adma_memcpy_xor_set_src(\n\t\tstruct ppc440spe_adma_desc_slot *sw_desc,\n\t\tdma_addr_t addr, int index)\n{\n\tstruct ppc440spe_adma_chan *chan;\n\n\tchan = to_ppc440spe_adma_chan(sw_desc->async_tx.chan);\n\tsw_desc = sw_desc->group_head;\n\n\tif (likely(sw_desc))\n\t\tppc440spe_desc_set_src_addr(sw_desc, chan, index, 0, addr);\n}\n\n \nstatic void ppc440spe_adma_dma2rxor_inc_addr(\n\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\tstruct ppc440spe_rxor *cursor, int index, int src_cnt)\n{\n\tcursor->addr_count++;\n\tif (index == src_cnt - 1) {\n\t\tppc440spe_desc_set_xor_src_cnt(desc, cursor->addr_count);\n\t} else if (cursor->addr_count == XOR_MAX_OPS) {\n\t\tppc440spe_desc_set_xor_src_cnt(desc, cursor->addr_count);\n\t\tcursor->addr_count = 0;\n\t\tcursor->desc_count++;\n\t}\n}\n\n \nstatic int ppc440spe_adma_dma2rxor_prep_src(\n\t\tstruct ppc440spe_adma_desc_slot *hdesc,\n\t\tstruct ppc440spe_rxor *cursor, int index,\n\t\tint src_cnt, u32 addr)\n{\n\tu32 sign;\n\tstruct ppc440spe_adma_desc_slot *desc = hdesc;\n\tint i;\n\n\tfor (i = 0; i < cursor->desc_count; i++) {\n\t\tdesc = list_entry(hdesc->chain_node.next,\n\t\t\t\t  struct ppc440spe_adma_desc_slot,\n\t\t\t\t  chain_node);\n\t}\n\n\tswitch (cursor->state) {\n\tcase 0:\n\t\tif (addr == cursor->addrl + cursor->len) {\n\t\t\t \n\t\t\tcursor->state = 1;\n\t\t\tcursor->xor_count++;\n\t\t\tif (index == src_cnt-1) {\n\t\t\t\tppc440spe_rxor_set_region(desc,\n\t\t\t\t\tcursor->addr_count,\n\t\t\t\t\tDMA_RXOR12 << DMA_CUED_REGION_OFF);\n\t\t\t\tppc440spe_adma_dma2rxor_inc_addr(\n\t\t\t\t\tdesc, cursor, index, src_cnt);\n\t\t\t}\n\t\t} else if (cursor->addrl == addr + cursor->len) {\n\t\t\t \n\t\t\tcursor->state = 1;\n\t\t\tcursor->xor_count++;\n\t\t\tset_bit(cursor->addr_count, &desc->reverse_flags[0]);\n\t\t\tif (index == src_cnt-1) {\n\t\t\t\tppc440spe_rxor_set_region(desc,\n\t\t\t\t\tcursor->addr_count,\n\t\t\t\t\tDMA_RXOR12 << DMA_CUED_REGION_OFF);\n\t\t\t\tppc440spe_adma_dma2rxor_inc_addr(\n\t\t\t\t\tdesc, cursor, index, src_cnt);\n\t\t\t}\n\t\t} else {\n\t\t\tprintk(KERN_ERR \"Cannot build \"\n\t\t\t\t\"DMA2 RXOR command block.\\n\");\n\t\t\tBUG();\n\t\t}\n\t\tbreak;\n\tcase 1:\n\t\tsign = test_bit(cursor->addr_count,\n\t\t\t\tdesc->reverse_flags)\n\t\t\t? -1 : 1;\n\t\tif (index == src_cnt-2 || (sign == -1\n\t\t\t&& addr != cursor->addrl - 2*cursor->len)) {\n\t\t\tcursor->state = 0;\n\t\t\tcursor->xor_count = 1;\n\t\t\tcursor->addrl = addr;\n\t\t\tppc440spe_rxor_set_region(desc,\n\t\t\t\tcursor->addr_count,\n\t\t\t\tDMA_RXOR12 << DMA_CUED_REGION_OFF);\n\t\t\tppc440spe_adma_dma2rxor_inc_addr(\n\t\t\t\tdesc, cursor, index, src_cnt);\n\t\t} else if (addr == cursor->addrl + 2*sign*cursor->len) {\n\t\t\tcursor->state = 2;\n\t\t\tcursor->xor_count = 0;\n\t\t\tppc440spe_rxor_set_region(desc,\n\t\t\t\tcursor->addr_count,\n\t\t\t\tDMA_RXOR123 << DMA_CUED_REGION_OFF);\n\t\t\tif (index == src_cnt-1) {\n\t\t\t\tppc440spe_adma_dma2rxor_inc_addr(\n\t\t\t\t\tdesc, cursor, index, src_cnt);\n\t\t\t}\n\t\t} else if (addr == cursor->addrl + 3*cursor->len) {\n\t\t\tcursor->state = 2;\n\t\t\tcursor->xor_count = 0;\n\t\t\tppc440spe_rxor_set_region(desc,\n\t\t\t\tcursor->addr_count,\n\t\t\t\tDMA_RXOR124 << DMA_CUED_REGION_OFF);\n\t\t\tif (index == src_cnt-1) {\n\t\t\t\tppc440spe_adma_dma2rxor_inc_addr(\n\t\t\t\t\tdesc, cursor, index, src_cnt);\n\t\t\t}\n\t\t} else if (addr == cursor->addrl + 4*cursor->len) {\n\t\t\tcursor->state = 2;\n\t\t\tcursor->xor_count = 0;\n\t\t\tppc440spe_rxor_set_region(desc,\n\t\t\t\tcursor->addr_count,\n\t\t\t\tDMA_RXOR125 << DMA_CUED_REGION_OFF);\n\t\t\tif (index == src_cnt-1) {\n\t\t\t\tppc440spe_adma_dma2rxor_inc_addr(\n\t\t\t\t\tdesc, cursor, index, src_cnt);\n\t\t\t}\n\t\t} else {\n\t\t\tcursor->state = 0;\n\t\t\tcursor->xor_count = 1;\n\t\t\tcursor->addrl = addr;\n\t\t\tppc440spe_rxor_set_region(desc,\n\t\t\t\tcursor->addr_count,\n\t\t\t\tDMA_RXOR12 << DMA_CUED_REGION_OFF);\n\t\t\tppc440spe_adma_dma2rxor_inc_addr(\n\t\t\t\tdesc, cursor, index, src_cnt);\n\t\t}\n\t\tbreak;\n\tcase 2:\n\t\tcursor->state = 0;\n\t\tcursor->addrl = addr;\n\t\tcursor->xor_count++;\n\t\tif (index) {\n\t\t\tppc440spe_adma_dma2rxor_inc_addr(\n\t\t\t\tdesc, cursor, index, src_cnt);\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void ppc440spe_adma_dma2rxor_set_src(\n\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\tint index, dma_addr_t addr)\n{\n\tstruct xor_cb *xcb = desc->hw_desc;\n\tint k = 0, op = 0, lop = 0;\n\n\t \n\twhile (op <= index) {\n\t\tlop = op;\n\t\tif (k == XOR_MAX_OPS) {\n\t\t\tk = 0;\n\t\t\tdesc = list_entry(desc->chain_node.next,\n\t\t\t\tstruct ppc440spe_adma_desc_slot, chain_node);\n\t\t\txcb = desc->hw_desc;\n\n\t\t}\n\t\tif ((xcb->ops[k++].h & (DMA_RXOR12 << DMA_CUED_REGION_OFF)) ==\n\t\t    (DMA_RXOR12 << DMA_CUED_REGION_OFF))\n\t\t\top += 2;\n\t\telse\n\t\t\top += 3;\n\t}\n\n\tBUG_ON(k < 1);\n\n\tif (test_bit(k-1, desc->reverse_flags)) {\n\t\t \n\t\tif (index == op - 1)\n\t\t\tppc440spe_rxor_set_src(desc, k - 1, addr);\n\t} else {\n\t\t \n\t\tif (index == lop)\n\t\t\tppc440spe_rxor_set_src(desc, k - 1, addr);\n\t}\n}\n\n \nstatic void ppc440spe_adma_dma2rxor_set_mult(\n\t\tstruct ppc440spe_adma_desc_slot *desc,\n\t\tint index, u8 mult)\n{\n\tstruct xor_cb *xcb = desc->hw_desc;\n\tint k = 0, op = 0, lop = 0;\n\n\t \n\twhile (op <= index) {\n\t\tlop = op;\n\t\tif (k == XOR_MAX_OPS) {\n\t\t\tk = 0;\n\t\t\tdesc = list_entry(desc->chain_node.next,\n\t\t\t\t\t  struct ppc440spe_adma_desc_slot,\n\t\t\t\t\t  chain_node);\n\t\t\txcb = desc->hw_desc;\n\n\t\t}\n\t\tif ((xcb->ops[k++].h & (DMA_RXOR12 << DMA_CUED_REGION_OFF)) ==\n\t\t    (DMA_RXOR12 << DMA_CUED_REGION_OFF))\n\t\t\top += 2;\n\t\telse\n\t\t\top += 3;\n\t}\n\n\tBUG_ON(k < 1);\n\tif (test_bit(k-1, desc->reverse_flags)) {\n\t\t \n\t\tppc440spe_rxor_set_mult(desc, k - 1, op - index - 1, mult);\n\t} else {\n\t\t \n\t\tppc440spe_rxor_set_mult(desc, k - 1, index - lop, mult);\n\t}\n}\n\n \nstatic void ppc440spe_init_rxor_cursor(struct ppc440spe_rxor *cursor)\n{\n\tmemset(cursor, 0, sizeof(struct ppc440spe_rxor));\n\tcursor->state = 2;\n}\n\n \nstatic void ppc440spe_adma_pq_set_src_mult(\n\t\tstruct ppc440spe_adma_desc_slot *sw_desc,\n\t\tunsigned char mult, int index, int dst_pos)\n{\n\tstruct ppc440spe_adma_chan *chan;\n\tu32 mult_idx, mult_dst;\n\tstruct ppc440spe_adma_desc_slot *iter = NULL, *iter1 = NULL;\n\n\tchan = to_ppc440spe_adma_chan(sw_desc->async_tx.chan);\n\n\tswitch (chan->device->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tif (test_bit(PPC440SPE_DESC_RXOR, &sw_desc->flags)) {\n\t\t\tint region = test_bit(PPC440SPE_DESC_RXOR12,\n\t\t\t\t\t&sw_desc->flags) ? 2 : 3;\n\n\t\t\tif (index < region) {\n\t\t\t\t \n\t\t\t\titer = ppc440spe_get_group_entry(sw_desc,\n\t\t\t\t\tsw_desc->dst_cnt - 1);\n\t\t\t\tif (sw_desc->dst_cnt == 2)\n\t\t\t\t\titer1 = ppc440spe_get_group_entry(\n\t\t\t\t\t\t\tsw_desc, 0);\n\n\t\t\t\tmult_idx = DMA_CUED_MULT1_OFF + (index << 3);\n\t\t\t\tmult_dst = DMA_CDB_SG_SRC;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\titer = ppc440spe_get_group_entry(sw_desc,\n\t\t\t\t\t\t\tindex - region +\n\t\t\t\t\t\t\tsw_desc->dst_cnt);\n\t\t\t\tmult_idx = DMA_CUED_MULT1_OFF;\n\t\t\t\tmult_dst = dst_pos ? DMA_CDB_SG_DST2 :\n\t\t\t\t\t\t     DMA_CDB_SG_DST1;\n\t\t\t}\n\t\t} else {\n\t\t\tint znum = 0;\n\n\t\t\t \n\t\t\tif (test_bit(PPC440SPE_ZERO_P, &sw_desc->flags))\n\t\t\t\tznum++;\n\t\t\tif (test_bit(PPC440SPE_ZERO_Q, &sw_desc->flags))\n\t\t\t\tznum++;\n\n\t\t\titer = ppc440spe_get_group_entry(sw_desc, index + znum);\n\t\t\tmult_idx = DMA_CUED_MULT1_OFF;\n\t\t\tmult_dst = dst_pos ? DMA_CDB_SG_DST2 : DMA_CDB_SG_DST1;\n\t\t}\n\n\t\tif (likely(iter)) {\n\t\t\tppc440spe_desc_set_src_mult(iter, chan,\n\t\t\t\tmult_idx, mult_dst, mult);\n\n\t\t\tif (unlikely(iter1)) {\n\t\t\t\t \n\t\t\t\tppc440spe_desc_set_src_mult(iter1, chan,\n\t\t\t\t\tmult_idx, mult_dst, 1);\n\t\t\t}\n\n\t\t}\n\t\tbreak;\n\n\tcase PPC440SPE_XOR_ID:\n\t\titer = sw_desc->group_head;\n\t\tif (sw_desc->dst_cnt == 2) {\n\t\t\t \n\t\t\tppc440spe_adma_dma2rxor_set_mult(iter, index, 1);\n\n\t\t\t \n\t\t\titer = ppc440spe_get_group_entry(sw_desc,\n\t\t\t       sw_desc->descs_per_op);\n\t\t}\n\t\tppc440spe_adma_dma2rxor_set_mult(iter, index, mult);\n\t\tbreak;\n\t}\n}\n\n \nstatic void ppc440spe_adma_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\tstruct ppc440spe_adma_desc_slot *iter, *_iter;\n\tint in_use_descs = 0;\n\n\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\tppc440spe_adma_slot_cleanup(ppc440spe_chan);\n\n\tspin_lock_bh(&ppc440spe_chan->lock);\n\tlist_for_each_entry_safe(iter, _iter, &ppc440spe_chan->chain,\n\t\t\t\t\tchain_node) {\n\t\tin_use_descs++;\n\t\tlist_del(&iter->chain_node);\n\t}\n\tlist_for_each_entry_safe_reverse(iter, _iter,\n\t\t\t&ppc440spe_chan->all_slots, slot_node) {\n\t\tlist_del(&iter->slot_node);\n\t\tkfree(iter);\n\t\tppc440spe_chan->slots_allocated--;\n\t}\n\tppc440spe_chan->last_used = NULL;\n\n\tdev_dbg(ppc440spe_chan->device->common.dev,\n\t\t\"ppc440spe adma%d %s slots_allocated %d\\n\",\n\t\tppc440spe_chan->device->id,\n\t\t__func__, ppc440spe_chan->slots_allocated);\n\tspin_unlock_bh(&ppc440spe_chan->lock);\n\n\t \n\tif (in_use_descs > 1)\n\t\tprintk(KERN_ERR \"SPE: Freeing %d in use descriptors!\\n\",\n\t\t\tin_use_descs - 1);\n}\n\n \nstatic enum dma_status ppc440spe_adma_tx_status(struct dma_chan *chan,\n\t\t\tdma_cookie_t cookie, struct dma_tx_state *txstate)\n{\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\tenum dma_status ret;\n\n\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\tret = dma_cookie_status(chan, cookie, txstate);\n\tif (ret == DMA_COMPLETE)\n\t\treturn ret;\n\n\tppc440spe_adma_slot_cleanup(ppc440spe_chan);\n\n\treturn dma_cookie_status(chan, cookie, txstate);\n}\n\n \nstatic irqreturn_t ppc440spe_adma_eot_handler(int irq, void *data)\n{\n\tstruct ppc440spe_adma_chan *chan = data;\n\n\tdev_dbg(chan->device->common.dev,\n\t\t\"ppc440spe adma%d: %s\\n\", chan->device->id, __func__);\n\n\ttasklet_schedule(&chan->irq_tasklet);\n\tppc440spe_adma_device_clear_eot_status(chan);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t ppc440spe_adma_err_handler(int irq, void *data)\n{\n\tstruct ppc440spe_adma_chan *chan = data;\n\n\tdev_dbg(chan->device->common.dev,\n\t\t\"ppc440spe adma%d: %s\\n\", chan->device->id, __func__);\n\n\ttasklet_schedule(&chan->irq_tasklet);\n\tppc440spe_adma_device_clear_eot_status(chan);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void ppc440spe_test_callback(void *unused)\n{\n\tcomplete(&ppc440spe_r6_test_comp);\n}\n\n \nstatic void ppc440spe_adma_issue_pending(struct dma_chan *chan)\n{\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\n\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\tdev_dbg(ppc440spe_chan->device->common.dev,\n\t\t\"ppc440spe adma%d: %s %d \\n\", ppc440spe_chan->device->id,\n\t\t__func__, ppc440spe_chan->pending);\n\n\tif (ppc440spe_chan->pending) {\n\t\tppc440spe_chan->pending = 0;\n\t\tppc440spe_chan_append(ppc440spe_chan);\n\t}\n}\n\n \nstatic void ppc440spe_chan_start_null_xor(struct ppc440spe_adma_chan *chan)\n{\n\tstruct ppc440spe_adma_desc_slot *sw_desc, *group_start;\n\tdma_cookie_t cookie;\n\tint slot_cnt, slots_per_op;\n\n\tdev_dbg(chan->device->common.dev,\n\t\t\"ppc440spe adma%d: %s\\n\", chan->device->id, __func__);\n\n\tspin_lock_bh(&chan->lock);\n\tslot_cnt = ppc440spe_chan_xor_slot_count(0, 2, &slots_per_op);\n\tsw_desc = ppc440spe_adma_alloc_slots(chan, slot_cnt, slots_per_op);\n\tif (sw_desc) {\n\t\tgroup_start = sw_desc->group_head;\n\t\tlist_splice_init(&sw_desc->group_list, &chan->chain);\n\t\tasync_tx_ack(&sw_desc->async_tx);\n\t\tppc440spe_desc_init_null_xor(group_start);\n\n\t\tcookie = dma_cookie_assign(&sw_desc->async_tx);\n\n\t\t \n\t\tchan->common.completed_cookie = cookie - 1;\n\n\t\t \n\t\tBUG_ON(ppc440spe_chan_is_busy(chan));\n\n\t\t \n\t\tppc440spe_chan_set_first_xor_descriptor(chan, sw_desc);\n\n\t\t \n\t\tppc440spe_chan_run(chan);\n\t} else\n\t\tprintk(KERN_ERR \"ppc440spe adma%d\"\n\t\t\t\" failed to allocate null descriptor\\n\",\n\t\t\tchan->device->id);\n\tspin_unlock_bh(&chan->lock);\n}\n\n \nstatic int ppc440spe_test_raid6(struct ppc440spe_adma_chan *chan)\n{\n\tstruct ppc440spe_adma_desc_slot *sw_desc, *iter;\n\tstruct page *pg;\n\tchar *a;\n\tdma_addr_t dma_addr, addrs[2];\n\tunsigned long op = 0;\n\tint rval = 0;\n\n\tset_bit(PPC440SPE_DESC_WXOR, &op);\n\n\tpg = alloc_page(GFP_KERNEL);\n\tif (!pg)\n\t\treturn -ENOMEM;\n\n\tspin_lock_bh(&chan->lock);\n\tsw_desc = ppc440spe_adma_alloc_slots(chan, 1, 1);\n\tif (sw_desc) {\n\t\t \n\t\tppc440spe_desc_init_dma01pq(sw_desc, 1, 1, 1, op);\n\t\tlist_for_each_entry(iter, &sw_desc->group_list, chain_node) {\n\t\t\tppc440spe_desc_set_byte_count(iter, chan, PAGE_SIZE);\n\t\t\titer->unmap_len = PAGE_SIZE;\n\t\t}\n\t} else {\n\t\trval = -EFAULT;\n\t\tspin_unlock_bh(&chan->lock);\n\t\tgoto exit;\n\t}\n\tspin_unlock_bh(&chan->lock);\n\n\t \n\tmemset(page_address(pg), 0xFF, PAGE_SIZE);\n\tdma_addr = dma_map_page(chan->device->dev, pg, 0,\n\t\t\t\tPAGE_SIZE, DMA_BIDIRECTIONAL);\n\n\t \n\tppc440spe_adma_pq_set_src(sw_desc, dma_addr, 0);\n\tppc440spe_adma_pq_set_src_mult(sw_desc, 1, 0, 0);\n\taddrs[0] = dma_addr;\n\taddrs[1] = 0;\n\tppc440spe_adma_pq_set_dest(sw_desc, addrs, DMA_PREP_PQ_DISABLE_Q);\n\n\tasync_tx_ack(&sw_desc->async_tx);\n\tsw_desc->async_tx.callback = ppc440spe_test_callback;\n\tsw_desc->async_tx.callback_param = NULL;\n\n\tinit_completion(&ppc440spe_r6_test_comp);\n\n\tppc440spe_adma_tx_submit(&sw_desc->async_tx);\n\tppc440spe_adma_issue_pending(&chan->common);\n\n\twait_for_completion(&ppc440spe_r6_test_comp);\n\n\t \n\ta = page_address(pg);\n\tif ((*(u32 *)a) == 0 && memcmp(a, a+4, PAGE_SIZE-4) == 0) {\n\t\t \n\t\trval = 0;\n\t} else {\n\t\t \n\t\trval = -EINVAL;\n\t}\nexit:\n\t__free_page(pg);\n\treturn rval;\n}\n\nstatic void ppc440spe_adma_init_capabilities(struct ppc440spe_adma_device *adev)\n{\n\tswitch (adev->id) {\n\tcase PPC440SPE_DMA0_ID:\n\tcase PPC440SPE_DMA1_ID:\n\t\tdma_cap_set(DMA_MEMCPY, adev->common.cap_mask);\n\t\tdma_cap_set(DMA_INTERRUPT, adev->common.cap_mask);\n\t\tdma_cap_set(DMA_PQ, adev->common.cap_mask);\n\t\tdma_cap_set(DMA_PQ_VAL, adev->common.cap_mask);\n\t\tdma_cap_set(DMA_XOR_VAL, adev->common.cap_mask);\n\t\tbreak;\n\tcase PPC440SPE_XOR_ID:\n\t\tdma_cap_set(DMA_XOR, adev->common.cap_mask);\n\t\tdma_cap_set(DMA_PQ, adev->common.cap_mask);\n\t\tdma_cap_set(DMA_INTERRUPT, adev->common.cap_mask);\n\t\tadev->common.cap_mask = adev->common.cap_mask;\n\t\tbreak;\n\t}\n\n\t \n\tadev->common.device_alloc_chan_resources =\n\t\t\t\tppc440spe_adma_alloc_chan_resources;\n\tadev->common.device_free_chan_resources =\n\t\t\t\tppc440spe_adma_free_chan_resources;\n\tadev->common.device_tx_status = ppc440spe_adma_tx_status;\n\tadev->common.device_issue_pending = ppc440spe_adma_issue_pending;\n\n\t \n\tif (dma_has_cap(DMA_MEMCPY, adev->common.cap_mask)) {\n\t\tadev->common.device_prep_dma_memcpy =\n\t\t\tppc440spe_adma_prep_dma_memcpy;\n\t}\n\tif (dma_has_cap(DMA_XOR, adev->common.cap_mask)) {\n\t\tadev->common.max_xor = XOR_MAX_OPS;\n\t\tadev->common.device_prep_dma_xor =\n\t\t\tppc440spe_adma_prep_dma_xor;\n\t}\n\tif (dma_has_cap(DMA_PQ, adev->common.cap_mask)) {\n\t\tswitch (adev->id) {\n\t\tcase PPC440SPE_DMA0_ID:\n\t\t\tdma_set_maxpq(&adev->common,\n\t\t\t\tDMA0_FIFO_SIZE / sizeof(struct dma_cdb), 0);\n\t\t\tbreak;\n\t\tcase PPC440SPE_DMA1_ID:\n\t\t\tdma_set_maxpq(&adev->common,\n\t\t\t\tDMA1_FIFO_SIZE / sizeof(struct dma_cdb), 0);\n\t\t\tbreak;\n\t\tcase PPC440SPE_XOR_ID:\n\t\t\tadev->common.max_pq = XOR_MAX_OPS * 3;\n\t\t\tbreak;\n\t\t}\n\t\tadev->common.device_prep_dma_pq =\n\t\t\tppc440spe_adma_prep_dma_pq;\n\t}\n\tif (dma_has_cap(DMA_PQ_VAL, adev->common.cap_mask)) {\n\t\tswitch (adev->id) {\n\t\tcase PPC440SPE_DMA0_ID:\n\t\t\tadev->common.max_pq = DMA0_FIFO_SIZE /\n\t\t\t\t\t\tsizeof(struct dma_cdb);\n\t\t\tbreak;\n\t\tcase PPC440SPE_DMA1_ID:\n\t\t\tadev->common.max_pq = DMA1_FIFO_SIZE /\n\t\t\t\t\t\tsizeof(struct dma_cdb);\n\t\t\tbreak;\n\t\t}\n\t\tadev->common.device_prep_dma_pq_val =\n\t\t\tppc440spe_adma_prep_dma_pqzero_sum;\n\t}\n\tif (dma_has_cap(DMA_XOR_VAL, adev->common.cap_mask)) {\n\t\tswitch (adev->id) {\n\t\tcase PPC440SPE_DMA0_ID:\n\t\t\tadev->common.max_xor = DMA0_FIFO_SIZE /\n\t\t\t\t\t\tsizeof(struct dma_cdb);\n\t\t\tbreak;\n\t\tcase PPC440SPE_DMA1_ID:\n\t\t\tadev->common.max_xor = DMA1_FIFO_SIZE /\n\t\t\t\t\t\tsizeof(struct dma_cdb);\n\t\t\tbreak;\n\t\t}\n\t\tadev->common.device_prep_dma_xor_val =\n\t\t\tppc440spe_adma_prep_dma_xor_zero_sum;\n\t}\n\tif (dma_has_cap(DMA_INTERRUPT, adev->common.cap_mask)) {\n\t\tadev->common.device_prep_dma_interrupt =\n\t\t\tppc440spe_adma_prep_dma_interrupt;\n\t}\n\tpr_info(\"%s: AMCC(R) PPC440SP(E) ADMA Engine: \"\n\t  \"( %s%s%s%s%s%s)\\n\",\n\t  dev_name(adev->dev),\n\t  dma_has_cap(DMA_PQ, adev->common.cap_mask) ? \"pq \" : \"\",\n\t  dma_has_cap(DMA_PQ_VAL, adev->common.cap_mask) ? \"pq_val \" : \"\",\n\t  dma_has_cap(DMA_XOR, adev->common.cap_mask) ? \"xor \" : \"\",\n\t  dma_has_cap(DMA_XOR_VAL, adev->common.cap_mask) ? \"xor_val \" : \"\",\n\t  dma_has_cap(DMA_MEMCPY, adev->common.cap_mask) ? \"memcpy \" : \"\",\n\t  dma_has_cap(DMA_INTERRUPT, adev->common.cap_mask) ? \"intr \" : \"\");\n}\n\nstatic int ppc440spe_adma_setup_irqs(struct ppc440spe_adma_device *adev,\n\t\t\t\t     struct ppc440spe_adma_chan *chan,\n\t\t\t\t     int *initcode)\n{\n\tstruct platform_device *ofdev;\n\tstruct device_node *np;\n\tint ret;\n\n\tofdev = container_of(adev->dev, struct platform_device, dev);\n\tnp = ofdev->dev.of_node;\n\tif (adev->id != PPC440SPE_XOR_ID) {\n\t\tadev->err_irq = irq_of_parse_and_map(np, 1);\n\t\tif (!adev->err_irq) {\n\t\t\tdev_warn(adev->dev, \"no err irq resource?\\n\");\n\t\t\t*initcode = PPC_ADMA_INIT_IRQ2;\n\t\t\tadev->err_irq = -ENXIO;\n\t\t} else\n\t\t\tatomic_inc(&ppc440spe_adma_err_irq_ref);\n\t} else {\n\t\tadev->err_irq = -ENXIO;\n\t}\n\n\tadev->irq = irq_of_parse_and_map(np, 0);\n\tif (!adev->irq) {\n\t\tdev_err(adev->dev, \"no irq resource\\n\");\n\t\t*initcode = PPC_ADMA_INIT_IRQ1;\n\t\tret = -ENXIO;\n\t\tgoto err_irq_map;\n\t}\n\tdev_dbg(adev->dev, \"irq %d, err irq %d\\n\",\n\t\tadev->irq, adev->err_irq);\n\n\tret = request_irq(adev->irq, ppc440spe_adma_eot_handler,\n\t\t\t  0, dev_driver_string(adev->dev), chan);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"can't request irq %d\\n\",\n\t\t\tadev->irq);\n\t\t*initcode = PPC_ADMA_INIT_IRQ1;\n\t\tret = -EIO;\n\t\tgoto err_req1;\n\t}\n\n\t \n\tif (adev->err_irq > 0) {\n\t\t \n\t\tret = request_irq(adev->err_irq,\n\t\t\t\t  ppc440spe_adma_err_handler,\n\t\t\t\t  IRQF_SHARED,\n\t\t\t\t  dev_driver_string(adev->dev),\n\t\t\t\t  chan);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"can't request irq %d\\n\",\n\t\t\t\tadev->err_irq);\n\t\t\t*initcode = PPC_ADMA_INIT_IRQ2;\n\t\t\tret = -EIO;\n\t\t\tgoto err_req2;\n\t\t}\n\t}\n\n\tif (adev->id == PPC440SPE_XOR_ID) {\n\t\t \n\t\tiowrite32be(XOR_IE_CBCIE_BIT | XOR_IE_ICBIE_BIT |\n\t\t\t    XOR_IE_ICIE_BIT | XOR_IE_RPTIE_BIT,\n\t\t\t    &adev->xor_reg->ier);\n\t} else {\n\t\tu32 mask, enable;\n\n\t\tnp = of_find_compatible_node(NULL, NULL, \"ibm,i2o-440spe\");\n\t\tif (!np) {\n\t\t\tpr_err(\"%s: can't find I2O device tree node\\n\",\n\t\t\t\t__func__);\n\t\t\tret = -ENODEV;\n\t\t\tgoto err_req2;\n\t\t}\n\t\tadev->i2o_reg = of_iomap(np, 0);\n\t\tif (!adev->i2o_reg) {\n\t\t\tpr_err(\"%s: failed to map I2O registers\\n\", __func__);\n\t\t\tof_node_put(np);\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_req2;\n\t\t}\n\t\tof_node_put(np);\n\t\t \n\t\tenable = (adev->id == PPC440SPE_DMA0_ID) ?\n\t\t\t ~(I2O_IOPIM_P0SNE | I2O_IOPIM_P0EM) :\n\t\t\t ~(I2O_IOPIM_P1SNE | I2O_IOPIM_P1EM);\n\t\tmask = ioread32(&adev->i2o_reg->iopim) & enable;\n\t\tiowrite32(mask, &adev->i2o_reg->iopim);\n\t}\n\treturn 0;\n\nerr_req2:\n\tfree_irq(adev->irq, chan);\nerr_req1:\n\tirq_dispose_mapping(adev->irq);\nerr_irq_map:\n\tif (adev->err_irq > 0) {\n\t\tif (atomic_dec_and_test(&ppc440spe_adma_err_irq_ref))\n\t\t\tirq_dispose_mapping(adev->err_irq);\n\t}\n\treturn ret;\n}\n\nstatic void ppc440spe_adma_release_irqs(struct ppc440spe_adma_device *adev,\n\t\t\t\t\tstruct ppc440spe_adma_chan *chan)\n{\n\tu32 mask, disable;\n\n\tif (adev->id == PPC440SPE_XOR_ID) {\n\t\t \n\t\tmask = ioread32be(&adev->xor_reg->ier);\n\t\tmask &= ~(XOR_IE_CBCIE_BIT | XOR_IE_ICBIE_BIT |\n\t\t\t  XOR_IE_ICIE_BIT | XOR_IE_RPTIE_BIT);\n\t\tiowrite32be(mask, &adev->xor_reg->ier);\n\t} else {\n\t\t \n\t\tdisable = (adev->id == PPC440SPE_DMA0_ID) ?\n\t\t\t  (I2O_IOPIM_P0SNE | I2O_IOPIM_P0EM) :\n\t\t\t  (I2O_IOPIM_P1SNE | I2O_IOPIM_P1EM);\n\t\tmask = ioread32(&adev->i2o_reg->iopim) | disable;\n\t\tiowrite32(mask, &adev->i2o_reg->iopim);\n\t}\n\tfree_irq(adev->irq, chan);\n\tirq_dispose_mapping(adev->irq);\n\tif (adev->err_irq > 0) {\n\t\tfree_irq(adev->err_irq, chan);\n\t\tif (atomic_dec_and_test(&ppc440spe_adma_err_irq_ref)) {\n\t\t\tirq_dispose_mapping(adev->err_irq);\n\t\t\tiounmap(adev->i2o_reg);\n\t\t}\n\t}\n}\n\n \nstatic int ppc440spe_adma_probe(struct platform_device *ofdev)\n{\n\tstruct device_node *np = ofdev->dev.of_node;\n\tstruct resource res;\n\tstruct ppc440spe_adma_device *adev;\n\tstruct ppc440spe_adma_chan *chan;\n\tstruct ppc_dma_chan_ref *ref, *_ref;\n\tint ret = 0, initcode = PPC_ADMA_INIT_OK;\n\tconst u32 *idx;\n\tint len;\n\tvoid *regs;\n\tu32 id, pool_size;\n\n\tif (of_device_is_compatible(np, \"amcc,xor-accelerator\")) {\n\t\tid = PPC440SPE_XOR_ID;\n\t\t \n\t\tpool_size = PAGE_SIZE << 1;\n\t} else {\n\t\t \n\t\tidx = of_get_property(np, \"cell-index\", &len);\n\t\tif (!idx || (len != sizeof(u32))) {\n\t\t\tdev_err(&ofdev->dev, \"Device node %pOF has missing \"\n\t\t\t\t\"or invalid cell-index property\\n\",\n\t\t\t\tnp);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tid = *idx;\n\t\t \n\t\tpool_size = (id == PPC440SPE_DMA0_ID) ?\n\t\t\t    DMA0_FIFO_SIZE : DMA1_FIFO_SIZE;\n\t\tpool_size <<= 2;\n\t}\n\n\tif (of_address_to_resource(np, 0, &res)) {\n\t\tdev_err(&ofdev->dev, \"failed to get memory resource\\n\");\n\t\tinitcode = PPC_ADMA_INIT_MEMRES;\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tif (!request_mem_region(res.start, resource_size(&res),\n\t\t\t\tdev_driver_string(&ofdev->dev))) {\n\t\tdev_err(&ofdev->dev, \"failed to request memory region %pR\\n\",\n\t\t\t&res);\n\t\tinitcode = PPC_ADMA_INIT_MEMREG;\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\t \n\tadev = kzalloc(sizeof(*adev), GFP_KERNEL);\n\tif (!adev) {\n\t\tinitcode = PPC_ADMA_INIT_ALLOC;\n\t\tret = -ENOMEM;\n\t\tgoto err_adev_alloc;\n\t}\n\n\tadev->id = id;\n\tadev->pool_size = pool_size;\n\t \n\tadev->dma_desc_pool_virt = dma_alloc_coherent(&ofdev->dev,\n\t\t\t\t\tadev->pool_size, &adev->dma_desc_pool,\n\t\t\t\t\tGFP_KERNEL);\n\tif (adev->dma_desc_pool_virt == NULL) {\n\t\tdev_err(&ofdev->dev, \"failed to allocate %d bytes of coherent \"\n\t\t\t\"memory for hardware descriptors\\n\",\n\t\t\tadev->pool_size);\n\t\tinitcode = PPC_ADMA_INIT_COHERENT;\n\t\tret = -ENOMEM;\n\t\tgoto err_dma_alloc;\n\t}\n\tdev_dbg(&ofdev->dev, \"allocated descriptor pool virt 0x%p phys 0x%llx\\n\",\n\t\tadev->dma_desc_pool_virt, (u64)adev->dma_desc_pool);\n\n\tregs = ioremap(res.start, resource_size(&res));\n\tif (!regs) {\n\t\tdev_err(&ofdev->dev, \"failed to ioremap regs!\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_regs_alloc;\n\t}\n\n\tif (adev->id == PPC440SPE_XOR_ID) {\n\t\tadev->xor_reg = regs;\n\t\t \n\t\tiowrite32be(XOR_CRSR_XASR_BIT, &adev->xor_reg->crsr);\n\t\tiowrite32be(XOR_CRSR_64BA_BIT, &adev->xor_reg->crrr);\n\t} else {\n\t\tsize_t fifo_size = (adev->id == PPC440SPE_DMA0_ID) ?\n\t\t\t\t   DMA0_FIFO_SIZE : DMA1_FIFO_SIZE;\n\t\tadev->dma_reg = regs;\n\t\t \n\t\tiowrite32(DMA_FIFO_ENABLE | ((fifo_size >> 3) - 2),\n\t\t\t  &adev->dma_reg->fsiz);\n\t\t \n\t\tiowrite32(DMA_CFG_DXEPR_HP | DMA_CFG_DFMPP_HP | DMA_CFG_FALGN,\n\t\t\t  &adev->dma_reg->cfg);\n\t\t \n\t\tiowrite32(~0, &adev->dma_reg->dsts);\n\t}\n\n\tadev->dev = &ofdev->dev;\n\tadev->common.dev = &ofdev->dev;\n\tINIT_LIST_HEAD(&adev->common.channels);\n\tplatform_set_drvdata(ofdev, adev);\n\n\t \n\tchan = kzalloc(sizeof(*chan), GFP_KERNEL);\n\tif (!chan) {\n\t\tinitcode = PPC_ADMA_INIT_CHANNEL;\n\t\tret = -ENOMEM;\n\t\tgoto err_chan_alloc;\n\t}\n\n\tspin_lock_init(&chan->lock);\n\tINIT_LIST_HEAD(&chan->chain);\n\tINIT_LIST_HEAD(&chan->all_slots);\n\tchan->device = adev;\n\tchan->common.device = &adev->common;\n\tdma_cookie_init(&chan->common);\n\tlist_add_tail(&chan->common.device_node, &adev->common.channels);\n\ttasklet_setup(&chan->irq_tasklet, ppc440spe_adma_tasklet);\n\n\t \n\tif (adev->id != PPC440SPE_XOR_ID) {\n\t\tchan->pdest_page = alloc_page(GFP_KERNEL);\n\t\tchan->qdest_page = alloc_page(GFP_KERNEL);\n\t\tif (!chan->pdest_page ||\n\t\t    !chan->qdest_page) {\n\t\t\tif (chan->pdest_page)\n\t\t\t\t__free_page(chan->pdest_page);\n\t\t\tif (chan->qdest_page)\n\t\t\t\t__free_page(chan->qdest_page);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_page_alloc;\n\t\t}\n\t\tchan->pdest = dma_map_page(&ofdev->dev, chan->pdest_page, 0,\n\t\t\t\t\t   PAGE_SIZE, DMA_BIDIRECTIONAL);\n\t\tchan->qdest = dma_map_page(&ofdev->dev, chan->qdest_page, 0,\n\t\t\t\t\t   PAGE_SIZE, DMA_BIDIRECTIONAL);\n\t}\n\n\tref = kmalloc(sizeof(*ref), GFP_KERNEL);\n\tif (ref) {\n\t\tref->chan = &chan->common;\n\t\tINIT_LIST_HEAD(&ref->node);\n\t\tlist_add_tail(&ref->node, &ppc440spe_adma_chan_list);\n\t} else {\n\t\tdev_err(&ofdev->dev, \"failed to allocate channel reference!\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_ref_alloc;\n\t}\n\n\tret = ppc440spe_adma_setup_irqs(adev, chan, &initcode);\n\tif (ret)\n\t\tgoto err_irq;\n\n\tppc440spe_adma_init_capabilities(adev);\n\n\tret = dma_async_device_register(&adev->common);\n\tif (ret) {\n\t\tinitcode = PPC_ADMA_INIT_REGISTER;\n\t\tdev_err(&ofdev->dev, \"failed to register dma device\\n\");\n\t\tgoto err_dev_reg;\n\t}\n\n\tgoto out;\n\nerr_dev_reg:\n\tppc440spe_adma_release_irqs(adev, chan);\nerr_irq:\n\tlist_for_each_entry_safe(ref, _ref, &ppc440spe_adma_chan_list, node) {\n\t\tif (chan == to_ppc440spe_adma_chan(ref->chan)) {\n\t\t\tlist_del(&ref->node);\n\t\t\tkfree(ref);\n\t\t}\n\t}\nerr_ref_alloc:\n\tif (adev->id != PPC440SPE_XOR_ID) {\n\t\tdma_unmap_page(&ofdev->dev, chan->pdest,\n\t\t\t       PAGE_SIZE, DMA_BIDIRECTIONAL);\n\t\tdma_unmap_page(&ofdev->dev, chan->qdest,\n\t\t\t       PAGE_SIZE, DMA_BIDIRECTIONAL);\n\t\t__free_page(chan->pdest_page);\n\t\t__free_page(chan->qdest_page);\n\t}\nerr_page_alloc:\n\tkfree(chan);\nerr_chan_alloc:\n\tif (adev->id == PPC440SPE_XOR_ID)\n\t\tiounmap(adev->xor_reg);\n\telse\n\t\tiounmap(adev->dma_reg);\nerr_regs_alloc:\n\tdma_free_coherent(adev->dev, adev->pool_size,\n\t\t\t  adev->dma_desc_pool_virt,\n\t\t\t  adev->dma_desc_pool);\nerr_dma_alloc:\n\tkfree(adev);\nerr_adev_alloc:\n\trelease_mem_region(res.start, resource_size(&res));\nout:\n\tif (id < PPC440SPE_ADMA_ENGINES_NUM)\n\t\tppc440spe_adma_devices[id] = initcode;\n\n\treturn ret;\n}\n\n \nstatic int ppc440spe_adma_remove(struct platform_device *ofdev)\n{\n\tstruct ppc440spe_adma_device *adev = platform_get_drvdata(ofdev);\n\tstruct device_node *np = ofdev->dev.of_node;\n\tstruct resource res;\n\tstruct dma_chan *chan, *_chan;\n\tstruct ppc_dma_chan_ref *ref, *_ref;\n\tstruct ppc440spe_adma_chan *ppc440spe_chan;\n\n\tif (adev->id < PPC440SPE_ADMA_ENGINES_NUM)\n\t\tppc440spe_adma_devices[adev->id] = -1;\n\n\tdma_async_device_unregister(&adev->common);\n\n\tlist_for_each_entry_safe(chan, _chan, &adev->common.channels,\n\t\t\t\t device_node) {\n\t\tppc440spe_chan = to_ppc440spe_adma_chan(chan);\n\t\tppc440spe_adma_release_irqs(adev, ppc440spe_chan);\n\t\ttasklet_kill(&ppc440spe_chan->irq_tasklet);\n\t\tif (adev->id != PPC440SPE_XOR_ID) {\n\t\t\tdma_unmap_page(&ofdev->dev, ppc440spe_chan->pdest,\n\t\t\t\t\tPAGE_SIZE, DMA_BIDIRECTIONAL);\n\t\t\tdma_unmap_page(&ofdev->dev, ppc440spe_chan->qdest,\n\t\t\t\t\tPAGE_SIZE, DMA_BIDIRECTIONAL);\n\t\t\t__free_page(ppc440spe_chan->pdest_page);\n\t\t\t__free_page(ppc440spe_chan->qdest_page);\n\t\t}\n\t\tlist_for_each_entry_safe(ref, _ref, &ppc440spe_adma_chan_list,\n\t\t\t\t\t node) {\n\t\t\tif (ppc440spe_chan ==\n\t\t\t    to_ppc440spe_adma_chan(ref->chan)) {\n\t\t\t\tlist_del(&ref->node);\n\t\t\t\tkfree(ref);\n\t\t\t}\n\t\t}\n\t\tlist_del(&chan->device_node);\n\t\tkfree(ppc440spe_chan);\n\t}\n\n\tdma_free_coherent(adev->dev, adev->pool_size,\n\t\t\t  adev->dma_desc_pool_virt, adev->dma_desc_pool);\n\tif (adev->id == PPC440SPE_XOR_ID)\n\t\tiounmap(adev->xor_reg);\n\telse\n\t\tiounmap(adev->dma_reg);\n\tof_address_to_resource(np, 0, &res);\n\trelease_mem_region(res.start, resource_size(&res));\n\tkfree(adev);\n\treturn 0;\n}\n\n \n\nstatic ssize_t devices_show(struct device_driver *dev, char *buf)\n{\n\tssize_t size = 0;\n\tint i;\n\n\tfor (i = 0; i < PPC440SPE_ADMA_ENGINES_NUM; i++) {\n\t\tif (ppc440spe_adma_devices[i] == -1)\n\t\t\tcontinue;\n\t\tsize += sysfs_emit_at(buf, size, \"PPC440SP(E)-ADMA.%d: %s\\n\",\n\t\t\t\t     i, ppc_adma_errors[ppc440spe_adma_devices[i]]);\n\t}\n\treturn size;\n}\nstatic DRIVER_ATTR_RO(devices);\n\nstatic ssize_t enable_show(struct device_driver *dev, char *buf)\n{\n\treturn sysfs_emit(buf, \"PPC440SP(e) RAID-6 capabilities are %sABLED.\\n\",\n\t\t\t  ppc440spe_r6_enabled ? \"EN\" : \"DIS\");\n}\n\nstatic ssize_t enable_store(struct device_driver *dev, const char *buf,\n\t\t\t    size_t count)\n{\n\tunsigned long val;\n\tint err;\n\n\tif (!count || count > 11)\n\t\treturn -EINVAL;\n\n\tif (!ppc440spe_r6_tchan)\n\t\treturn -EFAULT;\n\n\t \n\terr = kstrtoul(buf, 16, &val);\n\tif (err)\n\t\treturn err;\n\n\tdcr_write(ppc440spe_mq_dcr_host, DCRN_MQ0_XORBA, val);\n\tisync();\n\n\t \n\tif (ppc440spe_test_raid6(ppc440spe_r6_tchan) == 0) {\n\t\tpr_info(\"PPC440SP(e) RAID-6 has been activated \"\n\t\t\t\"successfully\\n\");\n\t\tppc440spe_r6_enabled = 1;\n\t} else {\n\t\tpr_info(\"PPC440SP(e) RAID-6 hasn't been activated!\"\n\t\t\t\" Error key ?\\n\");\n\t\tppc440spe_r6_enabled = 0;\n\t}\n\treturn count;\n}\nstatic DRIVER_ATTR_RW(enable);\n\nstatic ssize_t poly_show(struct device_driver *dev, char *buf)\n{\n\tssize_t size = 0;\n\tu32 reg;\n\n#ifdef CONFIG_440SP\n\t \n\treg = 0x4d;\n#else\n\treg = dcr_read(ppc440spe_mq_dcr_host, DCRN_MQ0_CFBHL);\n\treg >>= MQ0_CFBHL_POLY;\n\treg &= 0xFF;\n#endif\n\n\tsize = sysfs_emit(buf, \"PPC440SP(e) RAID-6 driver \"\n\t\t\t\"uses 0x1%02x polynomial.\\n\", reg);\n\treturn size;\n}\n\nstatic ssize_t poly_store(struct device_driver *dev, const char *buf,\n\t\t\t  size_t count)\n{\n\tunsigned long reg, val;\n\tint err;\n#ifdef CONFIG_440SP\n\t \n\treturn -EINVAL;\n#endif\n\n\tif (!count || count > 6)\n\t\treturn -EINVAL;\n\n\t \n\terr = kstrtoul(buf, 16, &val);\n\tif (err)\n\t\treturn err;\n\n\tif (val & ~0x1FF)\n\t\treturn -EINVAL;\n\n\tval &= 0xFF;\n\treg = dcr_read(ppc440spe_mq_dcr_host, DCRN_MQ0_CFBHL);\n\treg &= ~(0xFF << MQ0_CFBHL_POLY);\n\treg |= val << MQ0_CFBHL_POLY;\n\tdcr_write(ppc440spe_mq_dcr_host, DCRN_MQ0_CFBHL, reg);\n\n\treturn count;\n}\nstatic DRIVER_ATTR_RW(poly);\n\n \nstatic int ppc440spe_configure_raid_devices(void)\n{\n\tstruct device_node *np;\n\tstruct resource i2o_res;\n\tstruct i2o_regs __iomem *i2o_reg;\n\tdcr_host_t i2o_dcr_host;\n\tunsigned int dcr_base, dcr_len;\n\tint i, ret;\n\n\tnp = of_find_compatible_node(NULL, NULL, \"ibm,i2o-440spe\");\n\tif (!np) {\n\t\tpr_err(\"%s: can't find I2O device tree node\\n\",\n\t\t\t__func__);\n\t\treturn -ENODEV;\n\t}\n\n\tif (of_address_to_resource(np, 0, &i2o_res)) {\n\t\tof_node_put(np);\n\t\treturn -EINVAL;\n\t}\n\n\ti2o_reg = of_iomap(np, 0);\n\tif (!i2o_reg) {\n\t\tpr_err(\"%s: failed to map I2O registers\\n\", __func__);\n\t\tof_node_put(np);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tdcr_base = dcr_resource_start(np, 0);\n\tdcr_len = dcr_resource_len(np, 0);\n\tif (!dcr_base && !dcr_len) {\n\t\tpr_err(\"%pOF: can't get DCR registers base/len!\\n\", np);\n\t\tof_node_put(np);\n\t\tiounmap(i2o_reg);\n\t\treturn -ENODEV;\n\t}\n\n\ti2o_dcr_host = dcr_map(np, dcr_base, dcr_len);\n\tif (!DCR_MAP_OK(i2o_dcr_host)) {\n\t\tpr_err(\"%pOF: failed to map DCRs!\\n\", np);\n\t\tof_node_put(np);\n\t\tiounmap(i2o_reg);\n\t\treturn -ENODEV;\n\t}\n\tof_node_put(np);\n\n\t \n\tppc440spe_dma_fifo_buf = kmalloc((DMA0_FIFO_SIZE + DMA1_FIFO_SIZE) << 1,\n\t\t\t\t\t GFP_KERNEL);\n\tif (!ppc440spe_dma_fifo_buf) {\n\t\tpr_err(\"%s: DMA FIFO buffer allocation failed.\\n\", __func__);\n\t\tiounmap(i2o_reg);\n\t\tdcr_unmap(i2o_dcr_host, dcr_len);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\t \n\tmtdcri(SDR0, DCRN_SDR0_SRST, DCRN_SDR0_SRST_I2ODMA);\n\tmtdcri(SDR0, DCRN_SDR0_SRST, 0);\n\n\t \n\tdcr_write(i2o_dcr_host, DCRN_I2O0_IBAH, (u32)(i2o_res.start >> 32));\n\tdcr_write(i2o_dcr_host, DCRN_I2O0_IBAL, (u32)(i2o_res.start) |\n\t\t\t\t\t\tI2O_REG_ENABLE);\n\tdcr_unmap(i2o_dcr_host, dcr_len);\n\n\t \n\tiowrite32(0, &i2o_reg->ifbah);\n\tiowrite32(((u32)__pa(ppc440spe_dma_fifo_buf)), &i2o_reg->ifbal);\n\n\t \n\tiowrite32(0, &i2o_reg->ifsiz);\n\tiounmap(i2o_reg);\n\n\t \n\tnp = of_find_compatible_node(NULL, NULL, \"ibm,mq-440spe\");\n\tif (!np) {\n\t\tpr_err(\"%s: can't find MQ device tree node\\n\",\n\t\t\t__func__);\n\t\tret = -ENODEV;\n\t\tgoto out_free;\n\t}\n\n\t \n\tdcr_base = dcr_resource_start(np, 0);\n\tdcr_len = dcr_resource_len(np, 0);\n\tif (!dcr_base && !dcr_len) {\n\t\tpr_err(\"%pOF: can't get DCR registers base/len!\\n\", np);\n\t\tret = -ENODEV;\n\t\tgoto out_mq;\n\t}\n\n\tppc440spe_mq_dcr_host = dcr_map(np, dcr_base, dcr_len);\n\tif (!DCR_MAP_OK(ppc440spe_mq_dcr_host)) {\n\t\tpr_err(\"%pOF: failed to map DCRs!\\n\", np);\n\t\tret = -ENODEV;\n\t\tgoto out_mq;\n\t}\n\tof_node_put(np);\n\tppc440spe_mq_dcr_len = dcr_len;\n\n\t \n\tdcr_write(ppc440spe_mq_dcr_host, DCRN_MQ0_BAUH, DMA_CUED_XOR_HB);\n\n\t \n\tdcr_write(ppc440spe_mq_dcr_host, DCRN_MQ0_CFBHL,\n\t\t  (1 << MQ0_CFBHL_TPLM) | (1 << MQ0_CFBHL_HBCL) |\n\t\t  (PPC440SPE_DEFAULT_POLY << MQ0_CFBHL_POLY));\n\n\tatomic_set(&ppc440spe_adma_err_irq_ref, 0);\n\tfor (i = 0; i < PPC440SPE_ADMA_ENGINES_NUM; i++)\n\t\tppc440spe_adma_devices[i] = -1;\n\n\treturn 0;\n\nout_mq:\n\tof_node_put(np);\nout_free:\n\tkfree(ppc440spe_dma_fifo_buf);\n\treturn ret;\n}\n\nstatic const struct of_device_id ppc440spe_adma_of_match[] = {\n\t{ .compatible\t= \"ibm,dma-440spe\", },\n\t{ .compatible\t= \"amcc,xor-accelerator\", },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, ppc440spe_adma_of_match);\n\nstatic struct platform_driver ppc440spe_adma_driver = {\n\t.probe = ppc440spe_adma_probe,\n\t.remove = ppc440spe_adma_remove,\n\t.driver = {\n\t\t.name = \"PPC440SP(E)-ADMA\",\n\t\t.of_match_table = ppc440spe_adma_of_match,\n\t},\n};\n\nstatic __init int ppc440spe_adma_init(void)\n{\n\tint ret;\n\n\tret = ppc440spe_configure_raid_devices();\n\tif (ret)\n\t\treturn ret;\n\n\tret = platform_driver_register(&ppc440spe_adma_driver);\n\tif (ret) {\n\t\tpr_err(\"%s: failed to register platform driver\\n\",\n\t\t\t__func__);\n\t\tgoto out_reg;\n\t}\n\n\t \n\tret = driver_create_file(&ppc440spe_adma_driver.driver,\n\t\t\t\t &driver_attr_devices);\n\tif (ret)\n\t\tgoto out_dev;\n\n\t \n\tret = driver_create_file(&ppc440spe_adma_driver.driver,\n\t\t\t\t &driver_attr_enable);\n\tif (ret)\n\t\tgoto out_en;\n\n\t \n\tret = driver_create_file(&ppc440spe_adma_driver.driver,\n\t\t\t\t &driver_attr_poly);\n\tif (!ret)\n\t\treturn ret;\n\n\tdriver_remove_file(&ppc440spe_adma_driver.driver,\n\t\t\t   &driver_attr_enable);\nout_en:\n\tdriver_remove_file(&ppc440spe_adma_driver.driver,\n\t\t\t   &driver_attr_devices);\nout_dev:\n\t \n\tpr_err(\"%s: failed to create RAID-6 driver interface\\n\",\n\t\t__func__);\n\tplatform_driver_unregister(&ppc440spe_adma_driver);\nout_reg:\n\tdcr_unmap(ppc440spe_mq_dcr_host, ppc440spe_mq_dcr_len);\n\tkfree(ppc440spe_dma_fifo_buf);\n\treturn ret;\n}\n\nstatic void __exit ppc440spe_adma_exit(void)\n{\n\tdriver_remove_file(&ppc440spe_adma_driver.driver,\n\t\t\t   &driver_attr_poly);\n\tdriver_remove_file(&ppc440spe_adma_driver.driver,\n\t\t\t   &driver_attr_enable);\n\tdriver_remove_file(&ppc440spe_adma_driver.driver,\n\t\t\t   &driver_attr_devices);\n\tplatform_driver_unregister(&ppc440spe_adma_driver);\n\tdcr_unmap(ppc440spe_mq_dcr_host, ppc440spe_mq_dcr_len);\n\tkfree(ppc440spe_dma_fifo_buf);\n}\n\narch_initcall(ppc440spe_adma_init);\nmodule_exit(ppc440spe_adma_exit);\n\nMODULE_AUTHOR(\"Yuri Tikhonov <yur@emcraft.com>\");\nMODULE_DESCRIPTION(\"PPC440SPE ADMA Engine Driver\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}