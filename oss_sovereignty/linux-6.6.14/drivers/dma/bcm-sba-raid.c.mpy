{
  "module_name": "bcm-sba-raid.c",
  "hash_id": "b7873c5796299a3f69d369a631561b78e3d08e70ffd08cabd2e0984ac354eae5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/bcm-sba-raid.c",
  "human_readable_source": "\n\n\n \n\n#include <linux/bitops.h>\n#include <linux/debugfs.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmaengine.h>\n#include <linux/list.h>\n#include <linux/mailbox_client.h>\n#include <linux/mailbox/brcm-message.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_platform.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n#include <linux/raid/pq.h>\n\n#include \"dmaengine.h\"\n\n \n\n#define SBA_TYPE_SHIFT\t\t\t\t\t48\n#define SBA_TYPE_MASK\t\t\t\t\tGENMASK(1, 0)\n#define SBA_TYPE_A\t\t\t\t\t0x0\n#define SBA_TYPE_B\t\t\t\t\t0x2\n#define SBA_TYPE_C\t\t\t\t\t0x3\n#define SBA_USER_DEF_SHIFT\t\t\t\t32\n#define SBA_USER_DEF_MASK\t\t\t\tGENMASK(15, 0)\n#define SBA_R_MDATA_SHIFT\t\t\t\t24\n#define SBA_R_MDATA_MASK\t\t\t\tGENMASK(7, 0)\n#define SBA_C_MDATA_MS_SHIFT\t\t\t\t18\n#define SBA_C_MDATA_MS_MASK\t\t\t\tGENMASK(1, 0)\n#define SBA_INT_SHIFT\t\t\t\t\t17\n#define SBA_INT_MASK\t\t\t\t\tBIT(0)\n#define SBA_RESP_SHIFT\t\t\t\t\t16\n#define SBA_RESP_MASK\t\t\t\t\tBIT(0)\n#define SBA_C_MDATA_SHIFT\t\t\t\t8\n#define SBA_C_MDATA_MASK\t\t\t\tGENMASK(7, 0)\n#define SBA_C_MDATA_BNUMx_SHIFT(__bnum)\t\t\t(2 * (__bnum))\n#define SBA_C_MDATA_BNUMx_MASK\t\t\t\tGENMASK(1, 0)\n#define SBA_C_MDATA_DNUM_SHIFT\t\t\t\t5\n#define SBA_C_MDATA_DNUM_MASK\t\t\t\tGENMASK(4, 0)\n#define SBA_C_MDATA_LS(__v)\t\t\t\t((__v) & 0xff)\n#define SBA_C_MDATA_MS(__v)\t\t\t\t(((__v) >> 8) & 0x3)\n#define SBA_CMD_SHIFT\t\t\t\t\t0\n#define SBA_CMD_MASK\t\t\t\t\tGENMASK(3, 0)\n#define SBA_CMD_ZERO_BUFFER\t\t\t\t0x4\n#define SBA_CMD_ZERO_ALL_BUFFERS\t\t\t0x8\n#define SBA_CMD_LOAD_BUFFER\t\t\t\t0x9\n#define SBA_CMD_XOR\t\t\t\t\t0xa\n#define SBA_CMD_GALOIS_XOR\t\t\t\t0xb\n#define SBA_CMD_WRITE_BUFFER\t\t\t\t0xc\n#define SBA_CMD_GALOIS\t\t\t\t\t0xe\n\n#define SBA_MAX_REQ_PER_MBOX_CHANNEL\t\t\t8192\n#define SBA_MAX_MSG_SEND_PER_MBOX_CHANNEL\t\t8\n\n \n#define to_sba_request(tx)\t\t\\\n\tcontainer_of(tx, struct sba_request, tx)\n#define to_sba_device(dchan)\t\t\\\n\tcontainer_of(dchan, struct sba_device, dma_chan)\n\n \n\nenum sba_request_flags {\n\tSBA_REQUEST_STATE_FREE\t\t= 0x001,\n\tSBA_REQUEST_STATE_ALLOCED\t= 0x002,\n\tSBA_REQUEST_STATE_PENDING\t= 0x004,\n\tSBA_REQUEST_STATE_ACTIVE\t= 0x008,\n\tSBA_REQUEST_STATE_ABORTED\t= 0x010,\n\tSBA_REQUEST_STATE_MASK\t\t= 0x0ff,\n\tSBA_REQUEST_FENCE\t\t= 0x100,\n};\n\nstruct sba_request {\n\t \n\tstruct list_head node;\n\tstruct sba_device *sba;\n\tu32 flags;\n\t \n\tstruct sba_request *first;\n\tstruct list_head next;\n\tatomic_t next_pending_count;\n\t \n\tstruct brcm_message msg;\n\tstruct dma_async_tx_descriptor tx;\n\t \n\tstruct brcm_sba_command cmds[];\n};\n\nenum sba_version {\n\tSBA_VER_1 = 0,\n\tSBA_VER_2\n};\n\nstruct sba_device {\n\t \n\tstruct device *dev;\n\t \n\tenum sba_version ver;\n\t \n\tu32 max_req;\n\tu32 hw_buf_size;\n\tu32 hw_resp_size;\n\tu32 max_pq_coefs;\n\tu32 max_pq_srcs;\n\tu32 max_cmd_per_req;\n\tu32 max_xor_srcs;\n\tu32 max_resp_pool_size;\n\tu32 max_cmds_pool_size;\n\t \n\tstruct mbox_client client;\n\tstruct mbox_chan *mchan;\n\tstruct device *mbox_dev;\n\t \n\tstruct dma_device dma_dev;\n\tstruct dma_chan dma_chan;\n\t \n\tvoid *resp_base;\n\tdma_addr_t resp_dma_base;\n\tvoid *cmds_base;\n\tdma_addr_t cmds_dma_base;\n\tspinlock_t reqs_lock;\n\tbool reqs_fence;\n\tstruct list_head reqs_alloc_list;\n\tstruct list_head reqs_pending_list;\n\tstruct list_head reqs_active_list;\n\tstruct list_head reqs_aborted_list;\n\tstruct list_head reqs_free_list;\n\t \n\tstruct dentry *root;\n};\n\n \n\nstatic inline u64 __pure sba_cmd_enc(u64 cmd, u32 val, u32 shift, u32 mask)\n{\n\tcmd &= ~((u64)mask << shift);\n\tcmd |= ((u64)(val & mask) << shift);\n\treturn cmd;\n}\n\nstatic inline u32 __pure sba_cmd_load_c_mdata(u32 b0)\n{\n\treturn b0 & SBA_C_MDATA_BNUMx_MASK;\n}\n\nstatic inline u32 __pure sba_cmd_write_c_mdata(u32 b0)\n{\n\treturn b0 & SBA_C_MDATA_BNUMx_MASK;\n}\n\nstatic inline u32 __pure sba_cmd_xor_c_mdata(u32 b1, u32 b0)\n{\n\treturn (b0 & SBA_C_MDATA_BNUMx_MASK) |\n\t       ((b1 & SBA_C_MDATA_BNUMx_MASK) << SBA_C_MDATA_BNUMx_SHIFT(1));\n}\n\nstatic inline u32 __pure sba_cmd_pq_c_mdata(u32 d, u32 b1, u32 b0)\n{\n\treturn (b0 & SBA_C_MDATA_BNUMx_MASK) |\n\t       ((b1 & SBA_C_MDATA_BNUMx_MASK) << SBA_C_MDATA_BNUMx_SHIFT(1)) |\n\t       ((d & SBA_C_MDATA_DNUM_MASK) << SBA_C_MDATA_DNUM_SHIFT);\n}\n\n \n\nstatic struct sba_request *sba_alloc_request(struct sba_device *sba)\n{\n\tbool found = false;\n\tunsigned long flags;\n\tstruct sba_request *req = NULL;\n\n\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\tlist_for_each_entry(req, &sba->reqs_free_list, node) {\n\t\tif (async_tx_test_ack(&req->tx)) {\n\t\t\tlist_move_tail(&req->node, &sba->reqs_alloc_list);\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n\n\tif (!found) {\n\t\t \n\t\tmbox_client_peek_data(sba->mchan);\n\t\treturn NULL;\n\t}\n\n\treq->flags = SBA_REQUEST_STATE_ALLOCED;\n\treq->first = req;\n\tINIT_LIST_HEAD(&req->next);\n\tatomic_set(&req->next_pending_count, 1);\n\n\tdma_async_tx_descriptor_init(&req->tx, &sba->dma_chan);\n\tasync_tx_ack(&req->tx);\n\n\treturn req;\n}\n\n \nstatic void _sba_pending_request(struct sba_device *sba,\n\t\t\t\t struct sba_request *req)\n{\n\tlockdep_assert_held(&sba->reqs_lock);\n\treq->flags &= ~SBA_REQUEST_STATE_MASK;\n\treq->flags |= SBA_REQUEST_STATE_PENDING;\n\tlist_move_tail(&req->node, &sba->reqs_pending_list);\n\tif (list_empty(&sba->reqs_active_list))\n\t\tsba->reqs_fence = false;\n}\n\n \nstatic bool _sba_active_request(struct sba_device *sba,\n\t\t\t\tstruct sba_request *req)\n{\n\tlockdep_assert_held(&sba->reqs_lock);\n\tif (list_empty(&sba->reqs_active_list))\n\t\tsba->reqs_fence = false;\n\tif (sba->reqs_fence)\n\t\treturn false;\n\treq->flags &= ~SBA_REQUEST_STATE_MASK;\n\treq->flags |= SBA_REQUEST_STATE_ACTIVE;\n\tlist_move_tail(&req->node, &sba->reqs_active_list);\n\tif (req->flags & SBA_REQUEST_FENCE)\n\t\tsba->reqs_fence = true;\n\treturn true;\n}\n\n \nstatic void _sba_abort_request(struct sba_device *sba,\n\t\t\t       struct sba_request *req)\n{\n\tlockdep_assert_held(&sba->reqs_lock);\n\treq->flags &= ~SBA_REQUEST_STATE_MASK;\n\treq->flags |= SBA_REQUEST_STATE_ABORTED;\n\tlist_move_tail(&req->node, &sba->reqs_aborted_list);\n\tif (list_empty(&sba->reqs_active_list))\n\t\tsba->reqs_fence = false;\n}\n\n \nstatic void _sba_free_request(struct sba_device *sba,\n\t\t\t      struct sba_request *req)\n{\n\tlockdep_assert_held(&sba->reqs_lock);\n\treq->flags &= ~SBA_REQUEST_STATE_MASK;\n\treq->flags |= SBA_REQUEST_STATE_FREE;\n\tlist_move_tail(&req->node, &sba->reqs_free_list);\n\tif (list_empty(&sba->reqs_active_list))\n\t\tsba->reqs_fence = false;\n}\n\nstatic void sba_free_chained_requests(struct sba_request *req)\n{\n\tunsigned long flags;\n\tstruct sba_request *nreq;\n\tstruct sba_device *sba = req->sba;\n\n\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\n\t_sba_free_request(sba, req);\n\tlist_for_each_entry(nreq, &req->next, next)\n\t\t_sba_free_request(sba, nreq);\n\n\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n}\n\nstatic void sba_chain_request(struct sba_request *first,\n\t\t\t      struct sba_request *req)\n{\n\tunsigned long flags;\n\tstruct sba_device *sba = req->sba;\n\n\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\n\tlist_add_tail(&req->next, &first->next);\n\treq->first = first;\n\tatomic_inc(&first->next_pending_count);\n\n\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n}\n\nstatic void sba_cleanup_nonpending_requests(struct sba_device *sba)\n{\n\tunsigned long flags;\n\tstruct sba_request *req, *req1;\n\n\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\n\t \n\tlist_for_each_entry_safe(req, req1, &sba->reqs_alloc_list, node)\n\t\t_sba_free_request(sba, req);\n\n\t \n\tlist_for_each_entry_safe(req, req1, &sba->reqs_active_list, node)\n\t\t_sba_abort_request(sba, req);\n\n\t \n\n\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n}\n\nstatic void sba_cleanup_pending_requests(struct sba_device *sba)\n{\n\tunsigned long flags;\n\tstruct sba_request *req, *req1;\n\n\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\n\t \n\tlist_for_each_entry_safe(req, req1, &sba->reqs_pending_list, node)\n\t\t_sba_free_request(sba, req);\n\n\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n}\n\nstatic int sba_send_mbox_request(struct sba_device *sba,\n\t\t\t\t struct sba_request *req)\n{\n\tint ret = 0;\n\n\t \n\treq->msg.error = 0;\n\tret = mbox_send_message(sba->mchan, &req->msg);\n\tif (ret < 0) {\n\t\tdev_err(sba->dev, \"send message failed with error %d\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tret = req->msg.error;\n\tif (ret < 0) {\n\t\tdev_err(sba->dev, \"message error %d\", ret);\n\t}\n\n\t \n\tmbox_client_txdone(sba->mchan, ret);\n\n\treturn ret;\n}\n\n \nstatic void _sba_process_pending_requests(struct sba_device *sba)\n{\n\tint ret;\n\tu32 count;\n\tstruct sba_request *req;\n\n\t \n\tcount = SBA_MAX_MSG_SEND_PER_MBOX_CHANNEL;\n\twhile (!list_empty(&sba->reqs_pending_list) && count) {\n\t\t \n\t\treq = list_first_entry(&sba->reqs_pending_list,\n\t\t\t\t       struct sba_request, node);\n\n\t\t \n\t\tif (!_sba_active_request(sba, req))\n\t\t\tbreak;\n\n\t\t \n\t\tret = sba_send_mbox_request(sba, req);\n\t\tif (ret < 0) {\n\t\t\t_sba_pending_request(sba, req);\n\t\t\tbreak;\n\t\t}\n\n\t\tcount--;\n\t}\n}\n\nstatic void sba_process_received_request(struct sba_device *sba,\n\t\t\t\t\t struct sba_request *req)\n{\n\tunsigned long flags;\n\tstruct dma_async_tx_descriptor *tx;\n\tstruct sba_request *nreq, *first = req->first;\n\n\t \n\tif (!atomic_dec_return(&first->next_pending_count)) {\n\t\ttx = &first->tx;\n\n\t\tWARN_ON(tx->cookie < 0);\n\t\tif (tx->cookie > 0) {\n\t\t\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\t\t\tdma_cookie_complete(tx);\n\t\t\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n\t\t\tdmaengine_desc_get_callback_invoke(tx, NULL);\n\t\t\tdma_descriptor_unmap(tx);\n\t\t\ttx->callback = NULL;\n\t\t\ttx->callback_result = NULL;\n\t\t}\n\n\t\tdma_run_dependencies(tx);\n\n\t\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\n\t\t \n\t\tlist_for_each_entry(nreq, &first->next, next)\n\t\t\t_sba_free_request(sba, nreq);\n\t\tINIT_LIST_HEAD(&first->next);\n\n\t\t \n\t\t_sba_free_request(sba, first);\n\n\t\t \n\t\t_sba_process_pending_requests(sba);\n\n\t\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n\t}\n}\n\nstatic void sba_write_stats_in_seqfile(struct sba_device *sba,\n\t\t\t\t       struct seq_file *file)\n{\n\tunsigned long flags;\n\tstruct sba_request *req;\n\tu32 free_count = 0, alloced_count = 0;\n\tu32 pending_count = 0, active_count = 0, aborted_count = 0;\n\n\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\n\tlist_for_each_entry(req, &sba->reqs_free_list, node)\n\t\tif (async_tx_test_ack(&req->tx))\n\t\t\tfree_count++;\n\n\tlist_for_each_entry(req, &sba->reqs_alloc_list, node)\n\t\talloced_count++;\n\n\tlist_for_each_entry(req, &sba->reqs_pending_list, node)\n\t\tpending_count++;\n\n\tlist_for_each_entry(req, &sba->reqs_active_list, node)\n\t\tactive_count++;\n\n\tlist_for_each_entry(req, &sba->reqs_aborted_list, node)\n\t\taborted_count++;\n\n\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n\n\tseq_printf(file, \"maximum requests   = %d\\n\", sba->max_req);\n\tseq_printf(file, \"free requests      = %d\\n\", free_count);\n\tseq_printf(file, \"alloced requests   = %d\\n\", alloced_count);\n\tseq_printf(file, \"pending requests   = %d\\n\", pending_count);\n\tseq_printf(file, \"active requests    = %d\\n\", active_count);\n\tseq_printf(file, \"aborted requests   = %d\\n\", aborted_count);\n}\n\n \n\nstatic void sba_free_chan_resources(struct dma_chan *dchan)\n{\n\t \n\tsba_cleanup_nonpending_requests(to_sba_device(dchan));\n}\n\nstatic int sba_device_terminate_all(struct dma_chan *dchan)\n{\n\t \n\tsba_cleanup_pending_requests(to_sba_device(dchan));\n\n\treturn 0;\n}\n\nstatic void sba_issue_pending(struct dma_chan *dchan)\n{\n\tunsigned long flags;\n\tstruct sba_device *sba = to_sba_device(dchan);\n\n\t \n\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\t_sba_process_pending_requests(sba);\n\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n}\n\nstatic dma_cookie_t sba_tx_submit(struct dma_async_tx_descriptor *tx)\n{\n\tunsigned long flags;\n\tdma_cookie_t cookie;\n\tstruct sba_device *sba;\n\tstruct sba_request *req, *nreq;\n\n\tif (unlikely(!tx))\n\t\treturn -EINVAL;\n\n\tsba = to_sba_device(tx->chan);\n\treq = to_sba_request(tx);\n\n\t \n\tspin_lock_irqsave(&sba->reqs_lock, flags);\n\tcookie = dma_cookie_assign(tx);\n\t_sba_pending_request(sba, req);\n\tlist_for_each_entry(nreq, &req->next, next)\n\t\t_sba_pending_request(sba, nreq);\n\tspin_unlock_irqrestore(&sba->reqs_lock, flags);\n\n\treturn cookie;\n}\n\nstatic enum dma_status sba_tx_status(struct dma_chan *dchan,\n\t\t\t\t     dma_cookie_t cookie,\n\t\t\t\t     struct dma_tx_state *txstate)\n{\n\tenum dma_status ret;\n\tstruct sba_device *sba = to_sba_device(dchan);\n\n\tret = dma_cookie_status(dchan, cookie, txstate);\n\tif (ret == DMA_COMPLETE)\n\t\treturn ret;\n\n\tmbox_client_peek_data(sba->mchan);\n\n\treturn dma_cookie_status(dchan, cookie, txstate);\n}\n\nstatic void sba_fillup_interrupt_msg(struct sba_request *req,\n\t\t\t\t     struct brcm_sba_command *cmds,\n\t\t\t\t     struct brcm_message *msg)\n{\n\tu64 cmd;\n\tu32 c_mdata;\n\tdma_addr_t resp_dma = req->tx.phys;\n\tstruct brcm_sba_command *cmdsp = cmds;\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, req->sba->hw_resp_size,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tc_mdata = sba_cmd_load_c_mdata(0);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_LOAD_BUFFER,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\tcmdsp->data = resp_dma;\n\tcmdsp->data_len = req->sba->hw_resp_size;\n\tcmdsp++;\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, req->sba->hw_resp_size,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tcmd = sba_cmd_enc(cmd, 0x1,\n\t\t\t  SBA_RESP_SHIFT, SBA_RESP_MASK);\n\tc_mdata = sba_cmd_write_c_mdata(0);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_WRITE_BUFFER,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\tif (req->sba->hw_resp_size) {\n\t\tcmdsp->flags |= BRCM_SBA_CMD_HAS_RESP;\n\t\tcmdsp->resp = resp_dma;\n\t\tcmdsp->resp_len = req->sba->hw_resp_size;\n\t}\n\tcmdsp->flags |= BRCM_SBA_CMD_HAS_OUTPUT;\n\tcmdsp->data = resp_dma;\n\tcmdsp->data_len = req->sba->hw_resp_size;\n\tcmdsp++;\n\n\t \n\tmsg->type = BRCM_MESSAGE_SBA;\n\tmsg->sba.cmds = cmds;\n\tmsg->sba.cmds_count = cmdsp - cmds;\n\tmsg->ctx = req;\n\tmsg->error = 0;\n}\n\nstatic struct dma_async_tx_descriptor *\nsba_prep_dma_interrupt(struct dma_chan *dchan, unsigned long flags)\n{\n\tstruct sba_request *req = NULL;\n\tstruct sba_device *sba = to_sba_device(dchan);\n\n\t \n\treq = sba_alloc_request(sba);\n\tif (!req)\n\t\treturn NULL;\n\n\t \n\treq->flags |= SBA_REQUEST_FENCE;\n\n\t \n\tsba_fillup_interrupt_msg(req, req->cmds, &req->msg);\n\n\t \n\treq->tx.flags = flags;\n\treq->tx.cookie = -EBUSY;\n\n\treturn &req->tx;\n}\n\nstatic void sba_fillup_memcpy_msg(struct sba_request *req,\n\t\t\t\t  struct brcm_sba_command *cmds,\n\t\t\t\t  struct brcm_message *msg,\n\t\t\t\t  dma_addr_t msg_offset, size_t msg_len,\n\t\t\t\t  dma_addr_t dst, dma_addr_t src)\n{\n\tu64 cmd;\n\tu32 c_mdata;\n\tdma_addr_t resp_dma = req->tx.phys;\n\tstruct brcm_sba_command *cmdsp = cmds;\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tc_mdata = sba_cmd_load_c_mdata(0);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_LOAD_BUFFER,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\tcmdsp->data = src + msg_offset;\n\tcmdsp->data_len = msg_len;\n\tcmdsp++;\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tcmd = sba_cmd_enc(cmd, 0x1,\n\t\t\t  SBA_RESP_SHIFT, SBA_RESP_MASK);\n\tc_mdata = sba_cmd_write_c_mdata(0);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_WRITE_BUFFER,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\tif (req->sba->hw_resp_size) {\n\t\tcmdsp->flags |= BRCM_SBA_CMD_HAS_RESP;\n\t\tcmdsp->resp = resp_dma;\n\t\tcmdsp->resp_len = req->sba->hw_resp_size;\n\t}\n\tcmdsp->flags |= BRCM_SBA_CMD_HAS_OUTPUT;\n\tcmdsp->data = dst + msg_offset;\n\tcmdsp->data_len = msg_len;\n\tcmdsp++;\n\n\t \n\tmsg->type = BRCM_MESSAGE_SBA;\n\tmsg->sba.cmds = cmds;\n\tmsg->sba.cmds_count = cmdsp - cmds;\n\tmsg->ctx = req;\n\tmsg->error = 0;\n}\n\nstatic struct sba_request *\nsba_prep_dma_memcpy_req(struct sba_device *sba,\n\t\t\tdma_addr_t off, dma_addr_t dst, dma_addr_t src,\n\t\t\tsize_t len, unsigned long flags)\n{\n\tstruct sba_request *req = NULL;\n\n\t \n\treq = sba_alloc_request(sba);\n\tif (!req)\n\t\treturn NULL;\n\tif (flags & DMA_PREP_FENCE)\n\t\treq->flags |= SBA_REQUEST_FENCE;\n\n\t \n\tsba_fillup_memcpy_msg(req, req->cmds, &req->msg,\n\t\t\t      off, len, dst, src);\n\n\t \n\treq->tx.flags = flags;\n\treq->tx.cookie = -EBUSY;\n\n\treturn req;\n}\n\nstatic struct dma_async_tx_descriptor *\nsba_prep_dma_memcpy(struct dma_chan *dchan, dma_addr_t dst, dma_addr_t src,\n\t\t    size_t len, unsigned long flags)\n{\n\tsize_t req_len;\n\tdma_addr_t off = 0;\n\tstruct sba_device *sba = to_sba_device(dchan);\n\tstruct sba_request *first = NULL, *req;\n\n\t \n\twhile (len) {\n\t\treq_len = (len < sba->hw_buf_size) ? len : sba->hw_buf_size;\n\n\t\treq = sba_prep_dma_memcpy_req(sba, off, dst, src,\n\t\t\t\t\t      req_len, flags);\n\t\tif (!req) {\n\t\t\tif (first)\n\t\t\t\tsba_free_chained_requests(first);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (first)\n\t\t\tsba_chain_request(first, req);\n\t\telse\n\t\t\tfirst = req;\n\n\t\toff += req_len;\n\t\tlen -= req_len;\n\t}\n\n\treturn (first) ? &first->tx : NULL;\n}\n\nstatic void sba_fillup_xor_msg(struct sba_request *req,\n\t\t\t\tstruct brcm_sba_command *cmds,\n\t\t\t\tstruct brcm_message *msg,\n\t\t\t\tdma_addr_t msg_offset, size_t msg_len,\n\t\t\t\tdma_addr_t dst, dma_addr_t *src, u32 src_cnt)\n{\n\tu64 cmd;\n\tu32 c_mdata;\n\tunsigned int i;\n\tdma_addr_t resp_dma = req->tx.phys;\n\tstruct brcm_sba_command *cmdsp = cmds;\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tc_mdata = sba_cmd_load_c_mdata(0);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_LOAD_BUFFER,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\tcmdsp->data = src[0] + msg_offset;\n\tcmdsp->data_len = msg_len;\n\tcmdsp++;\n\n\t \n\tfor (i = 1; i < src_cnt; i++) {\n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tc_mdata = sba_cmd_xor_c_mdata(0, 0);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_XOR,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\t\tcmdsp->data = src[i] + msg_offset;\n\t\tcmdsp->data_len = msg_len;\n\t\tcmdsp++;\n\t}\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tcmd = sba_cmd_enc(cmd, 0x1,\n\t\t\t  SBA_RESP_SHIFT, SBA_RESP_MASK);\n\tc_mdata = sba_cmd_write_c_mdata(0);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_WRITE_BUFFER,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\tif (req->sba->hw_resp_size) {\n\t\tcmdsp->flags |= BRCM_SBA_CMD_HAS_RESP;\n\t\tcmdsp->resp = resp_dma;\n\t\tcmdsp->resp_len = req->sba->hw_resp_size;\n\t}\n\tcmdsp->flags |= BRCM_SBA_CMD_HAS_OUTPUT;\n\tcmdsp->data = dst + msg_offset;\n\tcmdsp->data_len = msg_len;\n\tcmdsp++;\n\n\t \n\tmsg->type = BRCM_MESSAGE_SBA;\n\tmsg->sba.cmds = cmds;\n\tmsg->sba.cmds_count = cmdsp - cmds;\n\tmsg->ctx = req;\n\tmsg->error = 0;\n}\n\nstatic struct sba_request *\nsba_prep_dma_xor_req(struct sba_device *sba,\n\t\t     dma_addr_t off, dma_addr_t dst, dma_addr_t *src,\n\t\t     u32 src_cnt, size_t len, unsigned long flags)\n{\n\tstruct sba_request *req = NULL;\n\n\t \n\treq = sba_alloc_request(sba);\n\tif (!req)\n\t\treturn NULL;\n\tif (flags & DMA_PREP_FENCE)\n\t\treq->flags |= SBA_REQUEST_FENCE;\n\n\t \n\tsba_fillup_xor_msg(req, req->cmds, &req->msg,\n\t\t\t   off, len, dst, src, src_cnt);\n\n\t \n\treq->tx.flags = flags;\n\treq->tx.cookie = -EBUSY;\n\n\treturn req;\n}\n\nstatic struct dma_async_tx_descriptor *\nsba_prep_dma_xor(struct dma_chan *dchan, dma_addr_t dst, dma_addr_t *src,\n\t\t u32 src_cnt, size_t len, unsigned long flags)\n{\n\tsize_t req_len;\n\tdma_addr_t off = 0;\n\tstruct sba_device *sba = to_sba_device(dchan);\n\tstruct sba_request *first = NULL, *req;\n\n\t \n\tif (unlikely(src_cnt > sba->max_xor_srcs))\n\t\treturn NULL;\n\n\t \n\twhile (len) {\n\t\treq_len = (len < sba->hw_buf_size) ? len : sba->hw_buf_size;\n\n\t\treq = sba_prep_dma_xor_req(sba, off, dst, src, src_cnt,\n\t\t\t\t\t   req_len, flags);\n\t\tif (!req) {\n\t\t\tif (first)\n\t\t\t\tsba_free_chained_requests(first);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (first)\n\t\t\tsba_chain_request(first, req);\n\t\telse\n\t\t\tfirst = req;\n\n\t\toff += req_len;\n\t\tlen -= req_len;\n\t}\n\n\treturn (first) ? &first->tx : NULL;\n}\n\nstatic void sba_fillup_pq_msg(struct sba_request *req,\n\t\t\t\tbool pq_continue,\n\t\t\t\tstruct brcm_sba_command *cmds,\n\t\t\t\tstruct brcm_message *msg,\n\t\t\t\tdma_addr_t msg_offset, size_t msg_len,\n\t\t\t\tdma_addr_t *dst_p, dma_addr_t *dst_q,\n\t\t\t\tconst u8 *scf, dma_addr_t *src, u32 src_cnt)\n{\n\tu64 cmd;\n\tu32 c_mdata;\n\tunsigned int i;\n\tdma_addr_t resp_dma = req->tx.phys;\n\tstruct brcm_sba_command *cmdsp = cmds;\n\n\tif (pq_continue) {\n\t\t \n\t\tif (dst_p) {\n\t\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t\tSBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\tSBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\t\tc_mdata = sba_cmd_load_c_mdata(0);\n\t\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\tSBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_LOAD_BUFFER,\n\t\t\t\tSBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\t\tcmdsp->cmd = cmd;\n\t\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\t\t\tcmdsp->data = *dst_p + msg_offset;\n\t\t\tcmdsp->data_len = msg_len;\n\t\t\tcmdsp++;\n\t\t}\n\n\t\t \n\t\tif (dst_q) {\n\t\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t\tSBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\tSBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\t\tc_mdata = sba_cmd_load_c_mdata(1);\n\t\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\tSBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_LOAD_BUFFER,\n\t\t\t\tSBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\t\tcmdsp->cmd = cmd;\n\t\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\t\t\tcmdsp->data = *dst_q + msg_offset;\n\t\t\tcmdsp->data_len = msg_len;\n\t\t\tcmdsp++;\n\t\t}\n\t} else {\n\t\t \n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_ZERO_ALL_BUFFERS,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\t\tcmdsp++;\n\t}\n\n\t \n\tfor (i = 0; i < src_cnt; i++) {\n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tc_mdata = sba_cmd_pq_c_mdata(raid6_gflog[scf[i]], 1, 0);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_MS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_MS_SHIFT, SBA_C_MDATA_MS_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_GALOIS_XOR,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\t\tcmdsp->data = src[i] + msg_offset;\n\t\tcmdsp->data_len = msg_len;\n\t\tcmdsp++;\n\t}\n\n\t \n\tif (dst_p) {\n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tcmd = sba_cmd_enc(cmd, 0x1,\n\t\t\t\t  SBA_RESP_SHIFT, SBA_RESP_MASK);\n\t\tc_mdata = sba_cmd_write_c_mdata(0);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_WRITE_BUFFER,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\t\tif (req->sba->hw_resp_size) {\n\t\t\tcmdsp->flags |= BRCM_SBA_CMD_HAS_RESP;\n\t\t\tcmdsp->resp = resp_dma;\n\t\t\tcmdsp->resp_len = req->sba->hw_resp_size;\n\t\t}\n\t\tcmdsp->flags |= BRCM_SBA_CMD_HAS_OUTPUT;\n\t\tcmdsp->data = *dst_p + msg_offset;\n\t\tcmdsp->data_len = msg_len;\n\t\tcmdsp++;\n\t}\n\n\t \n\tif (dst_q) {\n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tcmd = sba_cmd_enc(cmd, 0x1,\n\t\t\t\t  SBA_RESP_SHIFT, SBA_RESP_MASK);\n\t\tc_mdata = sba_cmd_write_c_mdata(1);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_WRITE_BUFFER,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\t\tif (req->sba->hw_resp_size) {\n\t\t\tcmdsp->flags |= BRCM_SBA_CMD_HAS_RESP;\n\t\t\tcmdsp->resp = resp_dma;\n\t\t\tcmdsp->resp_len = req->sba->hw_resp_size;\n\t\t}\n\t\tcmdsp->flags |= BRCM_SBA_CMD_HAS_OUTPUT;\n\t\tcmdsp->data = *dst_q + msg_offset;\n\t\tcmdsp->data_len = msg_len;\n\t\tcmdsp++;\n\t}\n\n\t \n\tmsg->type = BRCM_MESSAGE_SBA;\n\tmsg->sba.cmds = cmds;\n\tmsg->sba.cmds_count = cmdsp - cmds;\n\tmsg->ctx = req;\n\tmsg->error = 0;\n}\n\nstatic struct sba_request *\nsba_prep_dma_pq_req(struct sba_device *sba, dma_addr_t off,\n\t\t    dma_addr_t *dst_p, dma_addr_t *dst_q, dma_addr_t *src,\n\t\t    u32 src_cnt, const u8 *scf, size_t len, unsigned long flags)\n{\n\tstruct sba_request *req = NULL;\n\n\t \n\treq = sba_alloc_request(sba);\n\tif (!req)\n\t\treturn NULL;\n\tif (flags & DMA_PREP_FENCE)\n\t\treq->flags |= SBA_REQUEST_FENCE;\n\n\t \n\tsba_fillup_pq_msg(req, dmaf_continue(flags),\n\t\t\t  req->cmds, &req->msg,\n\t\t\t  off, len, dst_p, dst_q, scf, src, src_cnt);\n\n\t \n\treq->tx.flags = flags;\n\treq->tx.cookie = -EBUSY;\n\n\treturn req;\n}\n\nstatic void sba_fillup_pq_single_msg(struct sba_request *req,\n\t\t\t\tbool pq_continue,\n\t\t\t\tstruct brcm_sba_command *cmds,\n\t\t\t\tstruct brcm_message *msg,\n\t\t\t\tdma_addr_t msg_offset, size_t msg_len,\n\t\t\t\tdma_addr_t *dst_p, dma_addr_t *dst_q,\n\t\t\t\tdma_addr_t src, u8 scf)\n{\n\tu64 cmd;\n\tu32 c_mdata;\n\tu8 pos, dpos = raid6_gflog[scf];\n\tdma_addr_t resp_dma = req->tx.phys;\n\tstruct brcm_sba_command *cmdsp = cmds;\n\n\tif (!dst_p)\n\t\tgoto skip_p;\n\n\tif (pq_continue) {\n\t\t \n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tc_mdata = sba_cmd_load_c_mdata(0);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_LOAD_BUFFER,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\t\tcmdsp->data = *dst_p + msg_offset;\n\t\tcmdsp->data_len = msg_len;\n\t\tcmdsp++;\n\n\t\t \n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tc_mdata = sba_cmd_xor_c_mdata(0, 0);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_XOR,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\t\tcmdsp->data = src + msg_offset;\n\t\tcmdsp->data_len = msg_len;\n\t\tcmdsp++;\n\t} else {\n\t\t \n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tc_mdata = sba_cmd_load_c_mdata(0);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_LOAD_BUFFER,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\t\tcmdsp->data = src + msg_offset;\n\t\tcmdsp->data_len = msg_len;\n\t\tcmdsp++;\n\t}\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tcmd = sba_cmd_enc(cmd, 0x1,\n\t\t\t  SBA_RESP_SHIFT, SBA_RESP_MASK);\n\tc_mdata = sba_cmd_write_c_mdata(0);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_WRITE_BUFFER,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\tif (req->sba->hw_resp_size) {\n\t\tcmdsp->flags |= BRCM_SBA_CMD_HAS_RESP;\n\t\tcmdsp->resp = resp_dma;\n\t\tcmdsp->resp_len = req->sba->hw_resp_size;\n\t}\n\tcmdsp->flags |= BRCM_SBA_CMD_HAS_OUTPUT;\n\tcmdsp->data = *dst_p + msg_offset;\n\tcmdsp->data_len = msg_len;\n\tcmdsp++;\n\nskip_p:\n\tif (!dst_q)\n\t\tgoto skip_q;\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_ZERO_ALL_BUFFERS,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\tcmdsp++;\n\n\tif (dpos == 255)\n\t\tgoto skip_q_computation;\n\tpos = (dpos < req->sba->max_pq_coefs) ?\n\t\tdpos : (req->sba->max_pq_coefs - 1);\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tc_mdata = sba_cmd_pq_c_mdata(pos, 0, 0);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_MS(c_mdata),\n\t\t\t  SBA_C_MDATA_MS_SHIFT, SBA_C_MDATA_MS_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_GALOIS,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\tcmdsp->data = src + msg_offset;\n\tcmdsp->data_len = msg_len;\n\tcmdsp++;\n\n\tdpos -= pos;\n\n\t \n\twhile (dpos) {\n\t\tpos = (dpos < req->sba->max_pq_coefs) ?\n\t\t\tdpos : (req->sba->max_pq_coefs - 1);\n\n\t\t \n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tc_mdata = sba_cmd_pq_c_mdata(pos, 0, 1);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_MS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_MS_SHIFT, SBA_C_MDATA_MS_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_GALOIS,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\t\tcmdsp++;\n\n\t\tdpos -= pos;\n\t}\n\nskip_q_computation:\n\tif (pq_continue) {\n\t\t \n\t\tcmd = sba_cmd_enc(0x0, SBA_TYPE_B,\n\t\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\t\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\t\tc_mdata = sba_cmd_xor_c_mdata(0, 0);\n\t\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\t\tcmd = sba_cmd_enc(cmd, SBA_CMD_XOR,\n\t\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\t\tcmdsp->cmd = cmd;\n\t\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\t\tcmdsp->flags = BRCM_SBA_CMD_TYPE_B;\n\t\tcmdsp->data = *dst_q + msg_offset;\n\t\tcmdsp->data_len = msg_len;\n\t\tcmdsp++;\n\t}\n\n\t \n\tcmd = sba_cmd_enc(0x0, SBA_TYPE_A,\n\t\t\t  SBA_TYPE_SHIFT, SBA_TYPE_MASK);\n\tcmd = sba_cmd_enc(cmd, msg_len,\n\t\t\t  SBA_USER_DEF_SHIFT, SBA_USER_DEF_MASK);\n\tcmd = sba_cmd_enc(cmd, 0x1,\n\t\t\t  SBA_RESP_SHIFT, SBA_RESP_MASK);\n\tc_mdata = sba_cmd_write_c_mdata(0);\n\tcmd = sba_cmd_enc(cmd, SBA_C_MDATA_LS(c_mdata),\n\t\t\t  SBA_C_MDATA_SHIFT, SBA_C_MDATA_MASK);\n\tcmd = sba_cmd_enc(cmd, SBA_CMD_WRITE_BUFFER,\n\t\t\t  SBA_CMD_SHIFT, SBA_CMD_MASK);\n\tcmdsp->cmd = cmd;\n\t*cmdsp->cmd_dma = cpu_to_le64(cmd);\n\tcmdsp->flags = BRCM_SBA_CMD_TYPE_A;\n\tif (req->sba->hw_resp_size) {\n\t\tcmdsp->flags |= BRCM_SBA_CMD_HAS_RESP;\n\t\tcmdsp->resp = resp_dma;\n\t\tcmdsp->resp_len = req->sba->hw_resp_size;\n\t}\n\tcmdsp->flags |= BRCM_SBA_CMD_HAS_OUTPUT;\n\tcmdsp->data = *dst_q + msg_offset;\n\tcmdsp->data_len = msg_len;\n\tcmdsp++;\n\nskip_q:\n\t \n\tmsg->type = BRCM_MESSAGE_SBA;\n\tmsg->sba.cmds = cmds;\n\tmsg->sba.cmds_count = cmdsp - cmds;\n\tmsg->ctx = req;\n\tmsg->error = 0;\n}\n\nstatic struct sba_request *\nsba_prep_dma_pq_single_req(struct sba_device *sba, dma_addr_t off,\n\t\t\t   dma_addr_t *dst_p, dma_addr_t *dst_q,\n\t\t\t   dma_addr_t src, u8 scf, size_t len,\n\t\t\t   unsigned long flags)\n{\n\tstruct sba_request *req = NULL;\n\n\t \n\treq = sba_alloc_request(sba);\n\tif (!req)\n\t\treturn NULL;\n\tif (flags & DMA_PREP_FENCE)\n\t\treq->flags |= SBA_REQUEST_FENCE;\n\n\t \n\tsba_fillup_pq_single_msg(req,  dmaf_continue(flags),\n\t\t\t\t req->cmds, &req->msg, off, len,\n\t\t\t\t dst_p, dst_q, src, scf);\n\n\t \n\treq->tx.flags = flags;\n\treq->tx.cookie = -EBUSY;\n\n\treturn req;\n}\n\nstatic struct dma_async_tx_descriptor *\nsba_prep_dma_pq(struct dma_chan *dchan, dma_addr_t *dst, dma_addr_t *src,\n\t\tu32 src_cnt, const u8 *scf, size_t len, unsigned long flags)\n{\n\tu32 i, dst_q_index;\n\tsize_t req_len;\n\tbool slow = false;\n\tdma_addr_t off = 0;\n\tdma_addr_t *dst_p = NULL, *dst_q = NULL;\n\tstruct sba_device *sba = to_sba_device(dchan);\n\tstruct sba_request *first = NULL, *req;\n\n\t \n\tif (unlikely(src_cnt > sba->max_pq_srcs))\n\t\treturn NULL;\n\tfor (i = 0; i < src_cnt; i++)\n\t\tif (sba->max_pq_coefs <= raid6_gflog[scf[i]])\n\t\t\tslow = true;\n\n\t \n\tif (!(flags & DMA_PREP_PQ_DISABLE_P))\n\t\tdst_p = &dst[0];\n\tif (!(flags & DMA_PREP_PQ_DISABLE_Q))\n\t\tdst_q = &dst[1];\n\n\t \n\twhile (len) {\n\t\treq_len = (len < sba->hw_buf_size) ? len : sba->hw_buf_size;\n\n\t\tif (slow) {\n\t\t\tdst_q_index = src_cnt;\n\n\t\t\tif (dst_q) {\n\t\t\t\tfor (i = 0; i < src_cnt; i++) {\n\t\t\t\t\tif (*dst_q == src[i]) {\n\t\t\t\t\t\tdst_q_index = i;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (dst_q_index < src_cnt) {\n\t\t\t\ti = dst_q_index;\n\t\t\t\treq = sba_prep_dma_pq_single_req(sba,\n\t\t\t\t\toff, dst_p, dst_q, src[i], scf[i],\n\t\t\t\t\treq_len, flags | DMA_PREP_FENCE);\n\t\t\t\tif (!req)\n\t\t\t\t\tgoto fail;\n\n\t\t\t\tif (first)\n\t\t\t\t\tsba_chain_request(first, req);\n\t\t\t\telse\n\t\t\t\t\tfirst = req;\n\n\t\t\t\tflags |= DMA_PREP_CONTINUE;\n\t\t\t}\n\n\t\t\tfor (i = 0; i < src_cnt; i++) {\n\t\t\t\tif (dst_q_index == i)\n\t\t\t\t\tcontinue;\n\n\t\t\t\treq = sba_prep_dma_pq_single_req(sba,\n\t\t\t\t\toff, dst_p, dst_q, src[i], scf[i],\n\t\t\t\t\treq_len, flags | DMA_PREP_FENCE);\n\t\t\t\tif (!req)\n\t\t\t\t\tgoto fail;\n\n\t\t\t\tif (first)\n\t\t\t\t\tsba_chain_request(first, req);\n\t\t\t\telse\n\t\t\t\t\tfirst = req;\n\n\t\t\t\tflags |= DMA_PREP_CONTINUE;\n\t\t\t}\n\t\t} else {\n\t\t\treq = sba_prep_dma_pq_req(sba, off,\n\t\t\t\t\t\t  dst_p, dst_q, src, src_cnt,\n\t\t\t\t\t\t  scf, req_len, flags);\n\t\t\tif (!req)\n\t\t\t\tgoto fail;\n\n\t\t\tif (first)\n\t\t\t\tsba_chain_request(first, req);\n\t\t\telse\n\t\t\t\tfirst = req;\n\t\t}\n\n\t\toff += req_len;\n\t\tlen -= req_len;\n\t}\n\n\treturn (first) ? &first->tx : NULL;\n\nfail:\n\tif (first)\n\t\tsba_free_chained_requests(first);\n\treturn NULL;\n}\n\n \n\nstatic void sba_receive_message(struct mbox_client *cl, void *msg)\n{\n\tstruct brcm_message *m = msg;\n\tstruct sba_request *req = m->ctx;\n\tstruct sba_device *sba = req->sba;\n\n\t \n\tif (m->error < 0)\n\t\tdev_err(sba->dev, \"%s got message with error %d\",\n\t\t\tdma_chan_name(&sba->dma_chan), m->error);\n\n\t \n\tsba_process_received_request(sba, req);\n}\n\n \n\nstatic int sba_debugfs_stats_show(struct seq_file *file, void *offset)\n{\n\tstruct sba_device *sba = dev_get_drvdata(file->private);\n\n\t \n\tsba_write_stats_in_seqfile(sba, file);\n\n\treturn 0;\n}\n\n \n\nstatic int sba_prealloc_channel_resources(struct sba_device *sba)\n{\n\tint i, j, ret = 0;\n\tstruct sba_request *req = NULL;\n\n\tsba->resp_base = dma_alloc_coherent(sba->mbox_dev,\n\t\t\t\t\t    sba->max_resp_pool_size,\n\t\t\t\t\t    &sba->resp_dma_base, GFP_KERNEL);\n\tif (!sba->resp_base)\n\t\treturn -ENOMEM;\n\n\tsba->cmds_base = dma_alloc_coherent(sba->mbox_dev,\n\t\t\t\t\t    sba->max_cmds_pool_size,\n\t\t\t\t\t    &sba->cmds_dma_base, GFP_KERNEL);\n\tif (!sba->cmds_base) {\n\t\tret = -ENOMEM;\n\t\tgoto fail_free_resp_pool;\n\t}\n\n\tspin_lock_init(&sba->reqs_lock);\n\tsba->reqs_fence = false;\n\tINIT_LIST_HEAD(&sba->reqs_alloc_list);\n\tINIT_LIST_HEAD(&sba->reqs_pending_list);\n\tINIT_LIST_HEAD(&sba->reqs_active_list);\n\tINIT_LIST_HEAD(&sba->reqs_aborted_list);\n\tINIT_LIST_HEAD(&sba->reqs_free_list);\n\n\tfor (i = 0; i < sba->max_req; i++) {\n\t\treq = devm_kzalloc(sba->dev,\n\t\t\t\t   struct_size(req, cmds, sba->max_cmd_per_req),\n\t\t\t\t   GFP_KERNEL);\n\t\tif (!req) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail_free_cmds_pool;\n\t\t}\n\t\tINIT_LIST_HEAD(&req->node);\n\t\treq->sba = sba;\n\t\treq->flags = SBA_REQUEST_STATE_FREE;\n\t\tINIT_LIST_HEAD(&req->next);\n\t\tatomic_set(&req->next_pending_count, 0);\n\t\tfor (j = 0; j < sba->max_cmd_per_req; j++) {\n\t\t\treq->cmds[j].cmd = 0;\n\t\t\treq->cmds[j].cmd_dma = sba->cmds_base +\n\t\t\t\t(i * sba->max_cmd_per_req + j) * sizeof(u64);\n\t\t\treq->cmds[j].cmd_dma_addr = sba->cmds_dma_base +\n\t\t\t\t(i * sba->max_cmd_per_req + j) * sizeof(u64);\n\t\t\treq->cmds[j].flags = 0;\n\t\t}\n\t\tmemset(&req->msg, 0, sizeof(req->msg));\n\t\tdma_async_tx_descriptor_init(&req->tx, &sba->dma_chan);\n\t\tasync_tx_ack(&req->tx);\n\t\treq->tx.tx_submit = sba_tx_submit;\n\t\treq->tx.phys = sba->resp_dma_base + i * sba->hw_resp_size;\n\t\tlist_add_tail(&req->node, &sba->reqs_free_list);\n\t}\n\n\treturn 0;\n\nfail_free_cmds_pool:\n\tdma_free_coherent(sba->mbox_dev,\n\t\t\t  sba->max_cmds_pool_size,\n\t\t\t  sba->cmds_base, sba->cmds_dma_base);\nfail_free_resp_pool:\n\tdma_free_coherent(sba->mbox_dev,\n\t\t\t  sba->max_resp_pool_size,\n\t\t\t  sba->resp_base, sba->resp_dma_base);\n\treturn ret;\n}\n\nstatic void sba_freeup_channel_resources(struct sba_device *sba)\n{\n\tdmaengine_terminate_all(&sba->dma_chan);\n\tdma_free_coherent(sba->mbox_dev, sba->max_cmds_pool_size,\n\t\t\t  sba->cmds_base, sba->cmds_dma_base);\n\tdma_free_coherent(sba->mbox_dev, sba->max_resp_pool_size,\n\t\t\t  sba->resp_base, sba->resp_dma_base);\n\tsba->resp_base = NULL;\n\tsba->resp_dma_base = 0;\n}\n\nstatic int sba_async_register(struct sba_device *sba)\n{\n\tint ret;\n\tstruct dma_device *dma_dev = &sba->dma_dev;\n\n\t \n\tsba->dma_chan.device = dma_dev;\n\tdma_cookie_init(&sba->dma_chan);\n\n\t \n\tdma_cap_zero(dma_dev->cap_mask);\n\tdma_cap_set(DMA_INTERRUPT, dma_dev->cap_mask);\n\tdma_cap_set(DMA_MEMCPY, dma_dev->cap_mask);\n\tdma_cap_set(DMA_XOR, dma_dev->cap_mask);\n\tdma_cap_set(DMA_PQ, dma_dev->cap_mask);\n\n\t \n\tdma_dev->dev = sba->mbox_dev;\n\n\t \n\tdma_dev->device_free_chan_resources = sba_free_chan_resources;\n\tdma_dev->device_terminate_all = sba_device_terminate_all;\n\tdma_dev->device_issue_pending = sba_issue_pending;\n\tdma_dev->device_tx_status = sba_tx_status;\n\n\t \n\tif (dma_has_cap(DMA_INTERRUPT, dma_dev->cap_mask))\n\t\tdma_dev->device_prep_dma_interrupt = sba_prep_dma_interrupt;\n\n\t \n\tif (dma_has_cap(DMA_MEMCPY, dma_dev->cap_mask))\n\t\tdma_dev->device_prep_dma_memcpy = sba_prep_dma_memcpy;\n\n\t \n\tif (dma_has_cap(DMA_XOR, dma_dev->cap_mask)) {\n\t\tdma_dev->device_prep_dma_xor = sba_prep_dma_xor;\n\t\tdma_dev->max_xor = sba->max_xor_srcs;\n\t}\n\n\t \n\tif (dma_has_cap(DMA_PQ, dma_dev->cap_mask)) {\n\t\tdma_dev->device_prep_dma_pq = sba_prep_dma_pq;\n\t\tdma_set_maxpq(dma_dev, sba->max_pq_srcs, 0);\n\t}\n\n\t \n\tINIT_LIST_HEAD(&dma_dev->channels);\n\tlist_add_tail(&sba->dma_chan.device_node, &dma_dev->channels);\n\n\t \n\tret = dma_async_device_register(dma_dev);\n\tif (ret) {\n\t\tdev_err(sba->dev, \"async device register error %d\", ret);\n\t\treturn ret;\n\t}\n\n\tdev_info(sba->dev, \"%s capabilities: %s%s%s%s\\n\",\n\tdma_chan_name(&sba->dma_chan),\n\tdma_has_cap(DMA_INTERRUPT, dma_dev->cap_mask) ? \"interrupt \" : \"\",\n\tdma_has_cap(DMA_MEMCPY, dma_dev->cap_mask) ? \"memcpy \" : \"\",\n\tdma_has_cap(DMA_XOR, dma_dev->cap_mask) ? \"xor \" : \"\",\n\tdma_has_cap(DMA_PQ, dma_dev->cap_mask) ? \"pq \" : \"\");\n\n\treturn 0;\n}\n\nstatic int sba_probe(struct platform_device *pdev)\n{\n\tint ret = 0;\n\tstruct sba_device *sba;\n\tstruct platform_device *mbox_pdev;\n\tstruct of_phandle_args args;\n\n\t \n\tsba = devm_kzalloc(&pdev->dev, sizeof(*sba), GFP_KERNEL);\n\tif (!sba)\n\t\treturn -ENOMEM;\n\n\tsba->dev = &pdev->dev;\n\tplatform_set_drvdata(pdev, sba);\n\n\t \n\tret = of_count_phandle_with_args(pdev->dev.of_node,\n\t\t\t\t\t \"mboxes\", \"#mbox-cells\");\n\tif (ret <= 0)\n\t\treturn -ENODEV;\n\n\t \n\tif (of_device_is_compatible(sba->dev->of_node, \"brcm,iproc-sba\"))\n\t\tsba->ver = SBA_VER_1;\n\telse if (of_device_is_compatible(sba->dev->of_node,\n\t\t\t\t\t \"brcm,iproc-sba-v2\"))\n\t\tsba->ver = SBA_VER_2;\n\telse\n\t\treturn -ENODEV;\n\n\t \n\tswitch (sba->ver) {\n\tcase SBA_VER_1:\n\t\tsba->hw_buf_size = 4096;\n\t\tsba->hw_resp_size = 8;\n\t\tsba->max_pq_coefs = 6;\n\t\tsba->max_pq_srcs = 6;\n\t\tbreak;\n\tcase SBA_VER_2:\n\t\tsba->hw_buf_size = 4096;\n\t\tsba->hw_resp_size = 8;\n\t\tsba->max_pq_coefs = 30;\n\t\t \n\t\tsba->max_pq_srcs = 12;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\tsba->max_req = SBA_MAX_REQ_PER_MBOX_CHANNEL;\n\tsba->max_cmd_per_req = sba->max_pq_srcs + 3;\n\tsba->max_xor_srcs = sba->max_cmd_per_req - 1;\n\tsba->max_resp_pool_size = sba->max_req * sba->hw_resp_size;\n\tsba->max_cmds_pool_size = sba->max_req *\n\t\t\t\t  sba->max_cmd_per_req * sizeof(u64);\n\n\t \n\tsba->client.dev\t\t\t= &pdev->dev;\n\tsba->client.rx_callback\t\t= sba_receive_message;\n\tsba->client.tx_block\t\t= false;\n\tsba->client.knows_txdone\t= true;\n\tsba->client.tx_tout\t\t= 0;\n\n\t \n\tsba->mchan = mbox_request_channel(&sba->client, 0);\n\tif (IS_ERR(sba->mchan)) {\n\t\tret = PTR_ERR(sba->mchan);\n\t\tgoto fail_free_mchan;\n\t}\n\n\t \n\tret = of_parse_phandle_with_args(pdev->dev.of_node,\n\t\t\t\t\t \"mboxes\", \"#mbox-cells\", 0, &args);\n\tif (ret)\n\t\tgoto fail_free_mchan;\n\tmbox_pdev = of_find_device_by_node(args.np);\n\tof_node_put(args.np);\n\tif (!mbox_pdev) {\n\t\tret = -ENODEV;\n\t\tgoto fail_free_mchan;\n\t}\n\tsba->mbox_dev = &mbox_pdev->dev;\n\n\t \n\tret = sba_prealloc_channel_resources(sba);\n\tif (ret)\n\t\tgoto fail_free_mchan;\n\n\t \n\tif (!debugfs_initialized())\n\t\tgoto skip_debugfs;\n\n\t \n\tsba->root = debugfs_create_dir(dev_name(sba->dev), NULL);\n\n\t \n\tdebugfs_create_devm_seqfile(sba->dev, \"stats\", sba->root,\n\t\t\t\t    sba_debugfs_stats_show);\n\nskip_debugfs:\n\n\t \n\tret = sba_async_register(sba);\n\tif (ret)\n\t\tgoto fail_free_resources;\n\n\t \n\tdev_info(sba->dev, \"%s using SBAv%d mailbox channel from %s\",\n\t\t dma_chan_name(&sba->dma_chan), sba->ver+1,\n\t\t dev_name(sba->mbox_dev));\n\n\treturn 0;\n\nfail_free_resources:\n\tdebugfs_remove_recursive(sba->root);\n\tsba_freeup_channel_resources(sba);\nfail_free_mchan:\n\tmbox_free_channel(sba->mchan);\n\treturn ret;\n}\n\nstatic int sba_remove(struct platform_device *pdev)\n{\n\tstruct sba_device *sba = platform_get_drvdata(pdev);\n\n\tdma_async_device_unregister(&sba->dma_dev);\n\n\tdebugfs_remove_recursive(sba->root);\n\n\tsba_freeup_channel_resources(sba);\n\n\tmbox_free_channel(sba->mchan);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id sba_of_match[] = {\n\t{ .compatible = \"brcm,iproc-sba\", },\n\t{ .compatible = \"brcm,iproc-sba-v2\", },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, sba_of_match);\n\nstatic struct platform_driver sba_driver = {\n\t.probe = sba_probe,\n\t.remove = sba_remove,\n\t.driver = {\n\t\t.name = \"bcm-sba-raid\",\n\t\t.of_match_table = sba_of_match,\n\t},\n};\nmodule_platform_driver(sba_driver);\n\nMODULE_DESCRIPTION(\"Broadcom SBA RAID driver\");\nMODULE_AUTHOR(\"Anup Patel <anup.patel@broadcom.com>\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}