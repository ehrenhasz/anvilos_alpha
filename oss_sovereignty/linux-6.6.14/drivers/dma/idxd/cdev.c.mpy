{
  "module_name": "cdev.c",
  "hash_id": "2d439875c0bf2a15fe8f66562153015c0078a19dae9339801dedc2587cba6026",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/idxd/cdev.c",
  "human_readable_source": "\n \n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/device.h>\n#include <linux/sched/task.h>\n#include <linux/io-64-nonatomic-lo-hi.h>\n#include <linux/cdev.h>\n#include <linux/fs.h>\n#include <linux/poll.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <uapi/linux/idxd.h>\n#include <linux/xarray.h>\n#include \"registers.h\"\n#include \"idxd.h\"\n\nstruct idxd_cdev_context {\n\tconst char *name;\n\tdev_t devt;\n\tstruct ida minor_ida;\n};\n\n \nstatic DEFINE_IDA(file_ida);\nstatic DEFINE_MUTEX(ida_lock);\n\n \nstatic struct idxd_cdev_context ictx[IDXD_TYPE_MAX] = {\n\t{ .name = \"dsa\" },\n\t{ .name = \"iax\" }\n};\n\nstruct idxd_user_context {\n\tstruct idxd_wq *wq;\n\tstruct task_struct *task;\n\tunsigned int pasid;\n\tstruct mm_struct *mm;\n\tunsigned int flags;\n\tstruct iommu_sva *sva;\n\tstruct idxd_dev idxd_dev;\n\tu64 counters[COUNTER_MAX];\n\tint id;\n\tpid_t pid;\n};\n\nstatic void idxd_cdev_evl_drain_pasid(struct idxd_wq *wq, u32 pasid);\nstatic void idxd_xa_pasid_remove(struct idxd_user_context *ctx);\n\nstatic inline struct idxd_user_context *dev_to_uctx(struct device *dev)\n{\n\tstruct idxd_dev *idxd_dev = confdev_to_idxd_dev(dev);\n\n\treturn container_of(idxd_dev, struct idxd_user_context, idxd_dev);\n}\n\nstatic ssize_t cr_faults_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct idxd_user_context *ctx = dev_to_uctx(dev);\n\n\treturn sysfs_emit(buf, \"%llu\\n\", ctx->counters[COUNTER_FAULTS]);\n}\nstatic DEVICE_ATTR_RO(cr_faults);\n\nstatic ssize_t cr_fault_failures_show(struct device *dev,\n\t\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct idxd_user_context *ctx = dev_to_uctx(dev);\n\n\treturn sysfs_emit(buf, \"%llu\\n\", ctx->counters[COUNTER_FAULT_FAILS]);\n}\nstatic DEVICE_ATTR_RO(cr_fault_failures);\n\nstatic ssize_t pid_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct idxd_user_context *ctx = dev_to_uctx(dev);\n\n\treturn sysfs_emit(buf, \"%u\\n\", ctx->pid);\n}\nstatic DEVICE_ATTR_RO(pid);\n\nstatic struct attribute *cdev_file_attributes[] = {\n\t&dev_attr_cr_faults.attr,\n\t&dev_attr_cr_fault_failures.attr,\n\t&dev_attr_pid.attr,\n\tNULL\n};\n\nstatic umode_t cdev_file_attr_visible(struct kobject *kobj, struct attribute *a, int n)\n{\n\tstruct device *dev = container_of(kobj, typeof(*dev), kobj);\n\tstruct idxd_user_context *ctx = dev_to_uctx(dev);\n\tstruct idxd_wq *wq = ctx->wq;\n\n\tif (!wq_pasid_enabled(wq))\n\t\treturn 0;\n\n\treturn a->mode;\n}\n\nstatic const struct attribute_group cdev_file_attribute_group = {\n\t.attrs = cdev_file_attributes,\n\t.is_visible = cdev_file_attr_visible,\n};\n\nstatic const struct attribute_group *cdev_file_attribute_groups[] = {\n\t&cdev_file_attribute_group,\n\tNULL\n};\n\nstatic void idxd_file_dev_release(struct device *dev)\n{\n\tstruct idxd_user_context *ctx = dev_to_uctx(dev);\n\tstruct idxd_wq *wq = ctx->wq;\n\tstruct idxd_device *idxd = wq->idxd;\n\tint rc;\n\n\tmutex_lock(&ida_lock);\n\tida_free(&file_ida, ctx->id);\n\tmutex_unlock(&ida_lock);\n\n\t \n\tif (wq_shared(wq)) {\n\t\tidxd_device_drain_pasid(idxd, ctx->pasid);\n\t} else {\n\t\tif (device_user_pasid_enabled(idxd)) {\n\t\t\t \n\t\t\trc = idxd_wq_disable_pasid(wq);\n\t\t\tif (rc < 0)\n\t\t\t\tdev_err(dev, \"wq disable pasid failed.\\n\");\n\t\t} else {\n\t\t\tidxd_wq_drain(wq);\n\t\t}\n\t}\n\n\tif (ctx->sva) {\n\t\tidxd_cdev_evl_drain_pasid(wq, ctx->pasid);\n\t\tiommu_sva_unbind_device(ctx->sva);\n\t\tidxd_xa_pasid_remove(ctx);\n\t}\n\tkfree(ctx);\n\tmutex_lock(&wq->wq_lock);\n\tidxd_wq_put(wq);\n\tmutex_unlock(&wq->wq_lock);\n}\n\nstatic struct device_type idxd_cdev_file_type = {\n\t.name = \"idxd_file\",\n\t.release = idxd_file_dev_release,\n\t.groups = cdev_file_attribute_groups,\n};\n\nstatic void idxd_cdev_dev_release(struct device *dev)\n{\n\tstruct idxd_cdev *idxd_cdev = dev_to_cdev(dev);\n\tstruct idxd_cdev_context *cdev_ctx;\n\tstruct idxd_wq *wq = idxd_cdev->wq;\n\n\tcdev_ctx = &ictx[wq->idxd->data->type];\n\tida_simple_remove(&cdev_ctx->minor_ida, idxd_cdev->minor);\n\tkfree(idxd_cdev);\n}\n\nstatic struct device_type idxd_cdev_device_type = {\n\t.name = \"idxd_cdev\",\n\t.release = idxd_cdev_dev_release,\n};\n\nstatic inline struct idxd_cdev *inode_idxd_cdev(struct inode *inode)\n{\n\tstruct cdev *cdev = inode->i_cdev;\n\n\treturn container_of(cdev, struct idxd_cdev, cdev);\n}\n\nstatic inline struct idxd_wq *inode_wq(struct inode *inode)\n{\n\tstruct idxd_cdev *idxd_cdev = inode_idxd_cdev(inode);\n\n\treturn idxd_cdev->wq;\n}\n\nstatic void idxd_xa_pasid_remove(struct idxd_user_context *ctx)\n{\n\tstruct idxd_wq *wq = ctx->wq;\n\tvoid *ptr;\n\n\tmutex_lock(&wq->uc_lock);\n\tptr = xa_cmpxchg(&wq->upasid_xa, ctx->pasid, ctx, NULL, GFP_KERNEL);\n\tif (ptr != (void *)ctx)\n\t\tdev_warn(&wq->idxd->pdev->dev, \"xarray cmpxchg failed for pasid %u\\n\",\n\t\t\t ctx->pasid);\n\tmutex_unlock(&wq->uc_lock);\n}\n\nvoid idxd_user_counter_increment(struct idxd_wq *wq, u32 pasid, int index)\n{\n\tstruct idxd_user_context *ctx;\n\n\tif (index >= COUNTER_MAX)\n\t\treturn;\n\n\tmutex_lock(&wq->uc_lock);\n\tctx = xa_load(&wq->upasid_xa, pasid);\n\tif (!ctx) {\n\t\tmutex_unlock(&wq->uc_lock);\n\t\treturn;\n\t}\n\tctx->counters[index]++;\n\tmutex_unlock(&wq->uc_lock);\n}\n\nstatic int idxd_cdev_open(struct inode *inode, struct file *filp)\n{\n\tstruct idxd_user_context *ctx;\n\tstruct idxd_device *idxd;\n\tstruct idxd_wq *wq;\n\tstruct device *dev, *fdev;\n\tint rc = 0;\n\tstruct iommu_sva *sva;\n\tunsigned int pasid;\n\tstruct idxd_cdev *idxd_cdev;\n\n\twq = inode_wq(inode);\n\tidxd = wq->idxd;\n\tdev = &idxd->pdev->dev;\n\n\tdev_dbg(dev, \"%s called: %d\\n\", __func__, idxd_wq_refcount(wq));\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&wq->wq_lock);\n\n\tif (idxd_wq_refcount(wq) > 0 && wq_dedicated(wq)) {\n\t\trc = -EBUSY;\n\t\tgoto failed;\n\t}\n\n\tctx->wq = wq;\n\tfilp->private_data = ctx;\n\tctx->pid = current->pid;\n\n\tif (device_user_pasid_enabled(idxd)) {\n\t\tsva = iommu_sva_bind_device(dev, current->mm);\n\t\tif (IS_ERR(sva)) {\n\t\t\trc = PTR_ERR(sva);\n\t\t\tdev_err(dev, \"pasid allocation failed: %d\\n\", rc);\n\t\t\tgoto failed;\n\t\t}\n\n\t\tpasid = iommu_sva_get_pasid(sva);\n\t\tif (pasid == IOMMU_PASID_INVALID) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto failed_get_pasid;\n\t\t}\n\n\t\tctx->sva = sva;\n\t\tctx->pasid = pasid;\n\t\tctx->mm = current->mm;\n\n\t\tmutex_lock(&wq->uc_lock);\n\t\trc = xa_insert(&wq->upasid_xa, pasid, ctx, GFP_KERNEL);\n\t\tmutex_unlock(&wq->uc_lock);\n\t\tif (rc < 0)\n\t\t\tdev_warn(dev, \"PASID entry already exist in xarray.\\n\");\n\n\t\tif (wq_dedicated(wq)) {\n\t\t\trc = idxd_wq_set_pasid(wq, pasid);\n\t\t\tif (rc < 0) {\n\t\t\t\tdev_err(dev, \"wq set pasid failed: %d\\n\", rc);\n\t\t\t\tgoto failed_set_pasid;\n\t\t\t}\n\t\t}\n\t}\n\n\tidxd_cdev = wq->idxd_cdev;\n\tmutex_lock(&ida_lock);\n\tctx->id = ida_alloc(&file_ida, GFP_KERNEL);\n\tmutex_unlock(&ida_lock);\n\tif (ctx->id < 0) {\n\t\tdev_warn(dev, \"ida alloc failure\\n\");\n\t\tgoto failed_ida;\n\t}\n\tctx->idxd_dev.type  = IDXD_DEV_CDEV_FILE;\n\tfdev = user_ctx_dev(ctx);\n\tdevice_initialize(fdev);\n\tfdev->parent = cdev_dev(idxd_cdev);\n\tfdev->bus = &dsa_bus_type;\n\tfdev->type = &idxd_cdev_file_type;\n\n\trc = dev_set_name(fdev, \"file%d\", ctx->id);\n\tif (rc < 0) {\n\t\tdev_warn(dev, \"set name failure\\n\");\n\t\tgoto failed_dev_name;\n\t}\n\n\trc = device_add(fdev);\n\tif (rc < 0) {\n\t\tdev_warn(dev, \"file device add failure\\n\");\n\t\tgoto failed_dev_add;\n\t}\n\n\tidxd_wq_get(wq);\n\tmutex_unlock(&wq->wq_lock);\n\treturn 0;\n\nfailed_dev_add:\nfailed_dev_name:\n\tput_device(fdev);\nfailed_ida:\nfailed_set_pasid:\n\tif (device_user_pasid_enabled(idxd))\n\t\tidxd_xa_pasid_remove(ctx);\nfailed_get_pasid:\n\tif (device_user_pasid_enabled(idxd))\n\t\tiommu_sva_unbind_device(sva);\nfailed:\n\tmutex_unlock(&wq->wq_lock);\n\tkfree(ctx);\n\treturn rc;\n}\n\nstatic void idxd_cdev_evl_drain_pasid(struct idxd_wq *wq, u32 pasid)\n{\n\tstruct idxd_device *idxd = wq->idxd;\n\tstruct idxd_evl *evl = idxd->evl;\n\tunion evl_status_reg status;\n\tu16 h, t, size;\n\tint ent_size = evl_ent_size(idxd);\n\tstruct __evl_entry *entry_head;\n\n\tif (!evl)\n\t\treturn;\n\n\tspin_lock(&evl->lock);\n\tstatus.bits = ioread64(idxd->reg_base + IDXD_EVLSTATUS_OFFSET);\n\tt = status.tail;\n\th = evl->head;\n\tsize = evl->size;\n\n\twhile (h != t) {\n\t\tentry_head = (struct __evl_entry *)(evl->log + (h * ent_size));\n\t\tif (entry_head->pasid == pasid && entry_head->wq_idx == wq->id)\n\t\t\tset_bit(h, evl->bmap);\n\t\th = (h + 1) % size;\n\t}\n\tspin_unlock(&evl->lock);\n\n\tdrain_workqueue(wq->wq);\n}\n\nstatic int idxd_cdev_release(struct inode *node, struct file *filep)\n{\n\tstruct idxd_user_context *ctx = filep->private_data;\n\tstruct idxd_wq *wq = ctx->wq;\n\tstruct idxd_device *idxd = wq->idxd;\n\tstruct device *dev = &idxd->pdev->dev;\n\n\tdev_dbg(dev, \"%s called\\n\", __func__);\n\tfilep->private_data = NULL;\n\n\tdevice_unregister(user_ctx_dev(ctx));\n\n\treturn 0;\n}\n\nstatic int check_vma(struct idxd_wq *wq, struct vm_area_struct *vma,\n\t\t     const char *func)\n{\n\tstruct device *dev = &wq->idxd->pdev->dev;\n\n\tif ((vma->vm_end - vma->vm_start) > PAGE_SIZE) {\n\t\tdev_info_ratelimited(dev,\n\t\t\t\t     \"%s: %s: mapping too large: %lu\\n\",\n\t\t\t\t     current->comm, func,\n\t\t\t\t     vma->vm_end - vma->vm_start);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int idxd_cdev_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\tstruct idxd_user_context *ctx = filp->private_data;\n\tstruct idxd_wq *wq = ctx->wq;\n\tstruct idxd_device *idxd = wq->idxd;\n\tstruct pci_dev *pdev = idxd->pdev;\n\tphys_addr_t base = pci_resource_start(pdev, IDXD_WQ_BAR);\n\tunsigned long pfn;\n\tint rc;\n\n\tdev_dbg(&pdev->dev, \"%s called\\n\", __func__);\n\trc = check_vma(wq, vma, __func__);\n\tif (rc < 0)\n\t\treturn rc;\n\n\tvm_flags_set(vma, VM_DONTCOPY);\n\tpfn = (base + idxd_get_wq_portal_full_offset(wq->id,\n\t\t\t\tIDXD_PORTAL_LIMITED)) >> PAGE_SHIFT;\n\tvma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);\n\tvma->vm_private_data = ctx;\n\n\treturn io_remap_pfn_range(vma, vma->vm_start, pfn, PAGE_SIZE,\n\t\t\tvma->vm_page_prot);\n}\n\nstatic __poll_t idxd_cdev_poll(struct file *filp,\n\t\t\t       struct poll_table_struct *wait)\n{\n\tstruct idxd_user_context *ctx = filp->private_data;\n\tstruct idxd_wq *wq = ctx->wq;\n\tstruct idxd_device *idxd = wq->idxd;\n\t__poll_t out = 0;\n\n\tpoll_wait(filp, &wq->err_queue, wait);\n\tspin_lock(&idxd->dev_lock);\n\tif (idxd->sw_err.valid)\n\t\tout = EPOLLIN | EPOLLRDNORM;\n\tspin_unlock(&idxd->dev_lock);\n\n\treturn out;\n}\n\nstatic const struct file_operations idxd_cdev_fops = {\n\t.owner = THIS_MODULE,\n\t.open = idxd_cdev_open,\n\t.release = idxd_cdev_release,\n\t.mmap = idxd_cdev_mmap,\n\t.poll = idxd_cdev_poll,\n};\n\nint idxd_cdev_get_major(struct idxd_device *idxd)\n{\n\treturn MAJOR(ictx[idxd->data->type].devt);\n}\n\nint idxd_wq_add_cdev(struct idxd_wq *wq)\n{\n\tstruct idxd_device *idxd = wq->idxd;\n\tstruct idxd_cdev *idxd_cdev;\n\tstruct cdev *cdev;\n\tstruct device *dev;\n\tstruct idxd_cdev_context *cdev_ctx;\n\tint rc, minor;\n\n\tidxd_cdev = kzalloc(sizeof(*idxd_cdev), GFP_KERNEL);\n\tif (!idxd_cdev)\n\t\treturn -ENOMEM;\n\n\tidxd_cdev->idxd_dev.type = IDXD_DEV_CDEV;\n\tidxd_cdev->wq = wq;\n\tcdev = &idxd_cdev->cdev;\n\tdev = cdev_dev(idxd_cdev);\n\tcdev_ctx = &ictx[wq->idxd->data->type];\n\tminor = ida_simple_get(&cdev_ctx->minor_ida, 0, MINORMASK, GFP_KERNEL);\n\tif (minor < 0) {\n\t\tkfree(idxd_cdev);\n\t\treturn minor;\n\t}\n\tidxd_cdev->minor = minor;\n\n\tdevice_initialize(dev);\n\tdev->parent = wq_confdev(wq);\n\tdev->bus = &dsa_bus_type;\n\tdev->type = &idxd_cdev_device_type;\n\tdev->devt = MKDEV(MAJOR(cdev_ctx->devt), minor);\n\n\trc = dev_set_name(dev, \"%s/wq%u.%u\", idxd->data->name_prefix, idxd->id, wq->id);\n\tif (rc < 0)\n\t\tgoto err;\n\n\twq->idxd_cdev = idxd_cdev;\n\tcdev_init(cdev, &idxd_cdev_fops);\n\trc = cdev_device_add(cdev, dev);\n\tif (rc) {\n\t\tdev_dbg(&wq->idxd->pdev->dev, \"cdev_add failed: %d\\n\", rc);\n\t\tgoto err;\n\t}\n\n\treturn 0;\n\n err:\n\tput_device(dev);\n\twq->idxd_cdev = NULL;\n\treturn rc;\n}\n\nvoid idxd_wq_del_cdev(struct idxd_wq *wq)\n{\n\tstruct idxd_cdev *idxd_cdev;\n\n\tidxd_cdev = wq->idxd_cdev;\n\tida_destroy(&file_ida);\n\twq->idxd_cdev = NULL;\n\tcdev_device_del(&idxd_cdev->cdev, cdev_dev(idxd_cdev));\n\tput_device(cdev_dev(idxd_cdev));\n}\n\nstatic int idxd_user_drv_probe(struct idxd_dev *idxd_dev)\n{\n\tstruct idxd_wq *wq = idxd_dev_to_wq(idxd_dev);\n\tstruct idxd_device *idxd = wq->idxd;\n\tint rc;\n\n\tif (idxd->state != IDXD_DEV_ENABLED)\n\t\treturn -ENXIO;\n\n\t \n\tif (!device_user_pasid_enabled(idxd)) {\n\t\tidxd->cmd_status = IDXD_SCMD_WQ_USER_NO_IOMMU;\n\t\tdev_dbg(&idxd->pdev->dev,\n\t\t\t\"User type WQ cannot be enabled without SVA.\\n\");\n\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tmutex_lock(&wq->wq_lock);\n\n\twq->wq = create_workqueue(dev_name(wq_confdev(wq)));\n\tif (!wq->wq) {\n\t\trc = -ENOMEM;\n\t\tgoto wq_err;\n\t}\n\n\twq->type = IDXD_WQT_USER;\n\trc = drv_enable_wq(wq);\n\tif (rc < 0)\n\t\tgoto err;\n\n\trc = idxd_wq_add_cdev(wq);\n\tif (rc < 0) {\n\t\tidxd->cmd_status = IDXD_SCMD_CDEV_ERR;\n\t\tgoto err_cdev;\n\t}\n\n\tidxd->cmd_status = 0;\n\tmutex_unlock(&wq->wq_lock);\n\treturn 0;\n\nerr_cdev:\n\tdrv_disable_wq(wq);\nerr:\n\tdestroy_workqueue(wq->wq);\n\twq->type = IDXD_WQT_NONE;\nwq_err:\n\tmutex_unlock(&wq->wq_lock);\n\treturn rc;\n}\n\nstatic void idxd_user_drv_remove(struct idxd_dev *idxd_dev)\n{\n\tstruct idxd_wq *wq = idxd_dev_to_wq(idxd_dev);\n\n\tmutex_lock(&wq->wq_lock);\n\tidxd_wq_del_cdev(wq);\n\tdrv_disable_wq(wq);\n\twq->type = IDXD_WQT_NONE;\n\tdestroy_workqueue(wq->wq);\n\twq->wq = NULL;\n\tmutex_unlock(&wq->wq_lock);\n}\n\nstatic enum idxd_dev_type dev_types[] = {\n\tIDXD_DEV_WQ,\n\tIDXD_DEV_NONE,\n};\n\nstruct idxd_device_driver idxd_user_drv = {\n\t.probe = idxd_user_drv_probe,\n\t.remove = idxd_user_drv_remove,\n\t.name = \"user\",\n\t.type = dev_types,\n};\nEXPORT_SYMBOL_GPL(idxd_user_drv);\n\nint idxd_cdev_register(void)\n{\n\tint rc, i;\n\n\tfor (i = 0; i < IDXD_TYPE_MAX; i++) {\n\t\tida_init(&ictx[i].minor_ida);\n\t\trc = alloc_chrdev_region(&ictx[i].devt, 0, MINORMASK,\n\t\t\t\t\t ictx[i].name);\n\t\tif (rc)\n\t\t\tgoto err_free_chrdev_region;\n\t}\n\n\treturn 0;\n\nerr_free_chrdev_region:\n\tfor (i--; i >= 0; i--)\n\t\tunregister_chrdev_region(ictx[i].devt, MINORMASK);\n\n\treturn rc;\n}\n\nvoid idxd_cdev_remove(void)\n{\n\tint i;\n\n\tfor (i = 0; i < IDXD_TYPE_MAX; i++) {\n\t\tunregister_chrdev_region(ictx[i].devt, MINORMASK);\n\t\tida_destroy(&ictx[i].minor_ida);\n\t}\n}\n\n \nint idxd_copy_cr(struct idxd_wq *wq, ioasid_t pasid, unsigned long addr,\n\t\t void *cr, int len)\n{\n\tstruct device *dev = &wq->idxd->pdev->dev;\n\tint left = len, status_size = 1;\n\tstruct idxd_user_context *ctx;\n\tstruct mm_struct *mm;\n\n\tmutex_lock(&wq->uc_lock);\n\n\tctx = xa_load(&wq->upasid_xa, pasid);\n\tif (!ctx) {\n\t\tdev_warn(dev, \"No user context\\n\");\n\t\tgoto out;\n\t}\n\n\tmm = ctx->mm;\n\t \n\tkthread_use_mm(mm);\n\tleft = copy_to_user((void __user *)addr + status_size, cr + status_size,\n\t\t\t    len - status_size);\n\t \n\tif (!left) {\n\t\tu8 status;\n\n\t\t \n\t\twmb();\n\t\tstatus = *(u8 *)cr;\n\t\tif (put_user(status, (u8 __user *)addr))\n\t\t\tleft += status_size;\n\t} else {\n\t\tleft += status_size;\n\t}\n\tkthread_unuse_mm(mm);\n\nout:\n\tmutex_unlock(&wq->uc_lock);\n\n\treturn len - left;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}