{
  "module_name": "dma-axi-dmac.c",
  "hash_id": "ac4da260475848e923eb342584b6e5e8db7b6a4f07e7a91dfae573f19240063b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/dma-axi-dmac.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/clk.h>\n#include <linux/device.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmaengine.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_dma.h>\n#include <linux/of_address.h>\n#include <linux/platform_device.h>\n#include <linux/regmap.h>\n#include <linux/slab.h>\n#include <linux/fpga/adi-axi-common.h>\n\n#include <dt-bindings/dma/axi-dmac.h>\n\n#include \"dmaengine.h\"\n#include \"virt-dma.h\"\n\n \n\n#define AXI_DMAC_REG_INTERFACE_DESC\t0x10\n#define   AXI_DMAC_DMA_SRC_TYPE_MSK\tGENMASK(13, 12)\n#define   AXI_DMAC_DMA_SRC_TYPE_GET(x)\tFIELD_GET(AXI_DMAC_DMA_SRC_TYPE_MSK, x)\n#define   AXI_DMAC_DMA_SRC_WIDTH_MSK\tGENMASK(11, 8)\n#define   AXI_DMAC_DMA_SRC_WIDTH_GET(x)\tFIELD_GET(AXI_DMAC_DMA_SRC_WIDTH_MSK, x)\n#define   AXI_DMAC_DMA_DST_TYPE_MSK\tGENMASK(5, 4)\n#define   AXI_DMAC_DMA_DST_TYPE_GET(x)\tFIELD_GET(AXI_DMAC_DMA_DST_TYPE_MSK, x)\n#define   AXI_DMAC_DMA_DST_WIDTH_MSK\tGENMASK(3, 0)\n#define   AXI_DMAC_DMA_DST_WIDTH_GET(x)\tFIELD_GET(AXI_DMAC_DMA_DST_WIDTH_MSK, x)\n#define AXI_DMAC_REG_COHERENCY_DESC\t0x14\n#define   AXI_DMAC_DST_COHERENT_MSK\tBIT(0)\n#define   AXI_DMAC_DST_COHERENT_GET(x)\tFIELD_GET(AXI_DMAC_DST_COHERENT_MSK, x)\n\n#define AXI_DMAC_REG_IRQ_MASK\t\t0x80\n#define AXI_DMAC_REG_IRQ_PENDING\t0x84\n#define AXI_DMAC_REG_IRQ_SOURCE\t\t0x88\n\n#define AXI_DMAC_REG_CTRL\t\t0x400\n#define AXI_DMAC_REG_TRANSFER_ID\t0x404\n#define AXI_DMAC_REG_START_TRANSFER\t0x408\n#define AXI_DMAC_REG_FLAGS\t\t0x40c\n#define AXI_DMAC_REG_DEST_ADDRESS\t0x410\n#define AXI_DMAC_REG_SRC_ADDRESS\t0x414\n#define AXI_DMAC_REG_X_LENGTH\t\t0x418\n#define AXI_DMAC_REG_Y_LENGTH\t\t0x41c\n#define AXI_DMAC_REG_DEST_STRIDE\t0x420\n#define AXI_DMAC_REG_SRC_STRIDE\t\t0x424\n#define AXI_DMAC_REG_TRANSFER_DONE\t0x428\n#define AXI_DMAC_REG_ACTIVE_TRANSFER_ID 0x42c\n#define AXI_DMAC_REG_STATUS\t\t0x430\n#define AXI_DMAC_REG_CURRENT_SRC_ADDR\t0x434\n#define AXI_DMAC_REG_CURRENT_DEST_ADDR\t0x438\n#define AXI_DMAC_REG_PARTIAL_XFER_LEN\t0x44c\n#define AXI_DMAC_REG_PARTIAL_XFER_ID\t0x450\n\n#define AXI_DMAC_CTRL_ENABLE\t\tBIT(0)\n#define AXI_DMAC_CTRL_PAUSE\t\tBIT(1)\n\n#define AXI_DMAC_IRQ_SOT\t\tBIT(0)\n#define AXI_DMAC_IRQ_EOT\t\tBIT(1)\n\n#define AXI_DMAC_FLAG_CYCLIC\t\tBIT(0)\n#define AXI_DMAC_FLAG_LAST\t\tBIT(1)\n#define AXI_DMAC_FLAG_PARTIAL_REPORT\tBIT(2)\n\n#define AXI_DMAC_FLAG_PARTIAL_XFER_DONE BIT(31)\n\n \n#define AXI_DMAC_SG_UNUSED 32U\n\nstruct axi_dmac_sg {\n\tdma_addr_t src_addr;\n\tdma_addr_t dest_addr;\n\tunsigned int x_len;\n\tunsigned int y_len;\n\tunsigned int dest_stride;\n\tunsigned int src_stride;\n\tunsigned int id;\n\tunsigned int partial_len;\n\tbool schedule_when_free;\n};\n\nstruct axi_dmac_desc {\n\tstruct virt_dma_desc vdesc;\n\tbool cyclic;\n\tbool have_partial_xfer;\n\n\tunsigned int num_submitted;\n\tunsigned int num_completed;\n\tunsigned int num_sgs;\n\tstruct axi_dmac_sg sg[];\n};\n\nstruct axi_dmac_chan {\n\tstruct virt_dma_chan vchan;\n\n\tstruct axi_dmac_desc *next_desc;\n\tstruct list_head active_descs;\n\tenum dma_transfer_direction direction;\n\n\tunsigned int src_width;\n\tunsigned int dest_width;\n\tunsigned int src_type;\n\tunsigned int dest_type;\n\n\tunsigned int max_length;\n\tunsigned int address_align_mask;\n\tunsigned int length_align_mask;\n\n\tbool hw_partial_xfer;\n\tbool hw_cyclic;\n\tbool hw_2d;\n};\n\nstruct axi_dmac {\n\tvoid __iomem *base;\n\tint irq;\n\n\tstruct clk *clk;\n\n\tstruct dma_device dma_dev;\n\tstruct axi_dmac_chan chan;\n};\n\nstatic struct axi_dmac *chan_to_axi_dmac(struct axi_dmac_chan *chan)\n{\n\treturn container_of(chan->vchan.chan.device, struct axi_dmac,\n\t\tdma_dev);\n}\n\nstatic struct axi_dmac_chan *to_axi_dmac_chan(struct dma_chan *c)\n{\n\treturn container_of(c, struct axi_dmac_chan, vchan.chan);\n}\n\nstatic struct axi_dmac_desc *to_axi_dmac_desc(struct virt_dma_desc *vdesc)\n{\n\treturn container_of(vdesc, struct axi_dmac_desc, vdesc);\n}\n\nstatic void axi_dmac_write(struct axi_dmac *axi_dmac, unsigned int reg,\n\tunsigned int val)\n{\n\twritel(val, axi_dmac->base + reg);\n}\n\nstatic int axi_dmac_read(struct axi_dmac *axi_dmac, unsigned int reg)\n{\n\treturn readl(axi_dmac->base + reg);\n}\n\nstatic int axi_dmac_src_is_mem(struct axi_dmac_chan *chan)\n{\n\treturn chan->src_type == AXI_DMAC_BUS_TYPE_AXI_MM;\n}\n\nstatic int axi_dmac_dest_is_mem(struct axi_dmac_chan *chan)\n{\n\treturn chan->dest_type == AXI_DMAC_BUS_TYPE_AXI_MM;\n}\n\nstatic bool axi_dmac_check_len(struct axi_dmac_chan *chan, unsigned int len)\n{\n\tif (len == 0)\n\t\treturn false;\n\tif ((len & chan->length_align_mask) != 0)  \n\t\treturn false;\n\treturn true;\n}\n\nstatic bool axi_dmac_check_addr(struct axi_dmac_chan *chan, dma_addr_t addr)\n{\n\tif ((addr & chan->address_align_mask) != 0)  \n\t\treturn false;\n\treturn true;\n}\n\nstatic void axi_dmac_start_transfer(struct axi_dmac_chan *chan)\n{\n\tstruct axi_dmac *dmac = chan_to_axi_dmac(chan);\n\tstruct virt_dma_desc *vdesc;\n\tstruct axi_dmac_desc *desc;\n\tstruct axi_dmac_sg *sg;\n\tunsigned int flags = 0;\n\tunsigned int val;\n\n\tval = axi_dmac_read(dmac, AXI_DMAC_REG_START_TRANSFER);\n\tif (val)  \n\t\treturn;\n\n\tdesc = chan->next_desc;\n\n\tif (!desc) {\n\t\tvdesc = vchan_next_desc(&chan->vchan);\n\t\tif (!vdesc)\n\t\t\treturn;\n\t\tlist_move_tail(&vdesc->node, &chan->active_descs);\n\t\tdesc = to_axi_dmac_desc(vdesc);\n\t}\n\tsg = &desc->sg[desc->num_submitted];\n\n\t \n\tif (sg->id != AXI_DMAC_SG_UNUSED) {\n\t\tsg->schedule_when_free = true;\n\t\treturn;\n\t}\n\n\tdesc->num_submitted++;\n\tif (desc->num_submitted == desc->num_sgs ||\n\t    desc->have_partial_xfer) {\n\t\tif (desc->cyclic)\n\t\t\tdesc->num_submitted = 0;  \n\t\telse\n\t\t\tchan->next_desc = NULL;\n\t\tflags |= AXI_DMAC_FLAG_LAST;\n\t} else {\n\t\tchan->next_desc = desc;\n\t}\n\n\tsg->id = axi_dmac_read(dmac, AXI_DMAC_REG_TRANSFER_ID);\n\n\tif (axi_dmac_dest_is_mem(chan)) {\n\t\taxi_dmac_write(dmac, AXI_DMAC_REG_DEST_ADDRESS, sg->dest_addr);\n\t\taxi_dmac_write(dmac, AXI_DMAC_REG_DEST_STRIDE, sg->dest_stride);\n\t}\n\n\tif (axi_dmac_src_is_mem(chan)) {\n\t\taxi_dmac_write(dmac, AXI_DMAC_REG_SRC_ADDRESS, sg->src_addr);\n\t\taxi_dmac_write(dmac, AXI_DMAC_REG_SRC_STRIDE, sg->src_stride);\n\t}\n\n\t \n\tif (chan->hw_cyclic && desc->cyclic && !desc->vdesc.tx.callback &&\n\t\tdesc->num_sgs == 1)\n\t\tflags |= AXI_DMAC_FLAG_CYCLIC;\n\n\tif (chan->hw_partial_xfer)\n\t\tflags |= AXI_DMAC_FLAG_PARTIAL_REPORT;\n\n\taxi_dmac_write(dmac, AXI_DMAC_REG_X_LENGTH, sg->x_len - 1);\n\taxi_dmac_write(dmac, AXI_DMAC_REG_Y_LENGTH, sg->y_len - 1);\n\taxi_dmac_write(dmac, AXI_DMAC_REG_FLAGS, flags);\n\taxi_dmac_write(dmac, AXI_DMAC_REG_START_TRANSFER, 1);\n}\n\nstatic struct axi_dmac_desc *axi_dmac_active_desc(struct axi_dmac_chan *chan)\n{\n\treturn list_first_entry_or_null(&chan->active_descs,\n\t\tstruct axi_dmac_desc, vdesc.node);\n}\n\nstatic inline unsigned int axi_dmac_total_sg_bytes(struct axi_dmac_chan *chan,\n\tstruct axi_dmac_sg *sg)\n{\n\tif (chan->hw_2d)\n\t\treturn sg->x_len * sg->y_len;\n\telse\n\t\treturn sg->x_len;\n}\n\nstatic void axi_dmac_dequeue_partial_xfers(struct axi_dmac_chan *chan)\n{\n\tstruct axi_dmac *dmac = chan_to_axi_dmac(chan);\n\tstruct axi_dmac_desc *desc;\n\tstruct axi_dmac_sg *sg;\n\tu32 xfer_done, len, id, i;\n\tbool found_sg;\n\n\tdo {\n\t\tlen = axi_dmac_read(dmac, AXI_DMAC_REG_PARTIAL_XFER_LEN);\n\t\tid  = axi_dmac_read(dmac, AXI_DMAC_REG_PARTIAL_XFER_ID);\n\n\t\tfound_sg = false;\n\t\tlist_for_each_entry(desc, &chan->active_descs, vdesc.node) {\n\t\t\tfor (i = 0; i < desc->num_sgs; i++) {\n\t\t\t\tsg = &desc->sg[i];\n\t\t\t\tif (sg->id == AXI_DMAC_SG_UNUSED)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (sg->id == id) {\n\t\t\t\t\tdesc->have_partial_xfer = true;\n\t\t\t\t\tsg->partial_len = len;\n\t\t\t\t\tfound_sg = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (found_sg)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (found_sg) {\n\t\t\tdev_dbg(dmac->dma_dev.dev,\n\t\t\t\t\"Found partial segment id=%u, len=%u\\n\",\n\t\t\t\tid, len);\n\t\t} else {\n\t\t\tdev_warn(dmac->dma_dev.dev,\n\t\t\t\t \"Not found partial segment id=%u, len=%u\\n\",\n\t\t\t\t id, len);\n\t\t}\n\n\t\t \n\t\txfer_done = axi_dmac_read(dmac, AXI_DMAC_REG_TRANSFER_DONE);\n\t\txfer_done = !(xfer_done & AXI_DMAC_FLAG_PARTIAL_XFER_DONE);\n\n\t} while (!xfer_done);\n}\n\nstatic void axi_dmac_compute_residue(struct axi_dmac_chan *chan,\n\tstruct axi_dmac_desc *active)\n{\n\tstruct dmaengine_result *rslt = &active->vdesc.tx_result;\n\tunsigned int start = active->num_completed - 1;\n\tstruct axi_dmac_sg *sg;\n\tunsigned int i, total;\n\n\trslt->result = DMA_TRANS_NOERROR;\n\trslt->residue = 0;\n\n\t \n\tfor (i = start; i < active->num_sgs; i++) {\n\t\tsg = &active->sg[i];\n\t\ttotal = axi_dmac_total_sg_bytes(chan, sg);\n\t\trslt->residue += (total - sg->partial_len);\n\t}\n}\n\nstatic bool axi_dmac_transfer_done(struct axi_dmac_chan *chan,\n\tunsigned int completed_transfers)\n{\n\tstruct axi_dmac_desc *active;\n\tstruct axi_dmac_sg *sg;\n\tbool start_next = false;\n\n\tactive = axi_dmac_active_desc(chan);\n\tif (!active)\n\t\treturn false;\n\n\tif (chan->hw_partial_xfer &&\n\t    (completed_transfers & AXI_DMAC_FLAG_PARTIAL_XFER_DONE))\n\t\taxi_dmac_dequeue_partial_xfers(chan);\n\n\tdo {\n\t\tsg = &active->sg[active->num_completed];\n\t\tif (sg->id == AXI_DMAC_SG_UNUSED)  \n\t\t\tbreak;\n\t\tif (!(BIT(sg->id) & completed_transfers))\n\t\t\tbreak;\n\t\tactive->num_completed++;\n\t\tsg->id = AXI_DMAC_SG_UNUSED;\n\t\tif (sg->schedule_when_free) {\n\t\t\tsg->schedule_when_free = false;\n\t\t\tstart_next = true;\n\t\t}\n\n\t\tif (sg->partial_len)\n\t\t\taxi_dmac_compute_residue(chan, active);\n\n\t\tif (active->cyclic)\n\t\t\tvchan_cyclic_callback(&active->vdesc);\n\n\t\tif (active->num_completed == active->num_sgs ||\n\t\t    sg->partial_len) {\n\t\t\tif (active->cyclic) {\n\t\t\t\tactive->num_completed = 0;  \n\t\t\t} else {\n\t\t\t\tlist_del(&active->vdesc.node);\n\t\t\t\tvchan_cookie_complete(&active->vdesc);\n\t\t\t\tactive = axi_dmac_active_desc(chan);\n\t\t\t}\n\t\t}\n\t} while (active);\n\n\treturn start_next;\n}\n\nstatic irqreturn_t axi_dmac_interrupt_handler(int irq, void *devid)\n{\n\tstruct axi_dmac *dmac = devid;\n\tunsigned int pending;\n\tbool start_next = false;\n\n\tpending = axi_dmac_read(dmac, AXI_DMAC_REG_IRQ_PENDING);\n\tif (!pending)\n\t\treturn IRQ_NONE;\n\n\taxi_dmac_write(dmac, AXI_DMAC_REG_IRQ_PENDING, pending);\n\n\tspin_lock(&dmac->chan.vchan.lock);\n\t \n\tif (pending & AXI_DMAC_IRQ_EOT) {\n\t\tunsigned int completed;\n\n\t\tcompleted = axi_dmac_read(dmac, AXI_DMAC_REG_TRANSFER_DONE);\n\t\tstart_next = axi_dmac_transfer_done(&dmac->chan, completed);\n\t}\n\t \n\tif ((pending & AXI_DMAC_IRQ_SOT) || start_next)\n\t\taxi_dmac_start_transfer(&dmac->chan);\n\tspin_unlock(&dmac->chan.vchan.lock);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int axi_dmac_terminate_all(struct dma_chan *c)\n{\n\tstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\n\tstruct axi_dmac *dmac = chan_to_axi_dmac(chan);\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\taxi_dmac_write(dmac, AXI_DMAC_REG_CTRL, 0);\n\tchan->next_desc = NULL;\n\tvchan_get_all_descriptors(&chan->vchan, &head);\n\tlist_splice_tail_init(&chan->active_descs, &head);\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\n\tvchan_dma_desc_free_list(&chan->vchan, &head);\n\n\treturn 0;\n}\n\nstatic void axi_dmac_synchronize(struct dma_chan *c)\n{\n\tstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\n\n\tvchan_synchronize(&chan->vchan);\n}\n\nstatic void axi_dmac_issue_pending(struct dma_chan *c)\n{\n\tstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\n\tstruct axi_dmac *dmac = chan_to_axi_dmac(chan);\n\tunsigned long flags;\n\n\taxi_dmac_write(dmac, AXI_DMAC_REG_CTRL, AXI_DMAC_CTRL_ENABLE);\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\tif (vchan_issue_pending(&chan->vchan))\n\t\taxi_dmac_start_transfer(chan);\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n}\n\nstatic struct axi_dmac_desc *axi_dmac_alloc_desc(unsigned int num_sgs)\n{\n\tstruct axi_dmac_desc *desc;\n\tunsigned int i;\n\n\tdesc = kzalloc(struct_size(desc, sg, num_sgs), GFP_NOWAIT);\n\tif (!desc)\n\t\treturn NULL;\n\n\tfor (i = 0; i < num_sgs; i++)\n\t\tdesc->sg[i].id = AXI_DMAC_SG_UNUSED;\n\n\tdesc->num_sgs = num_sgs;\n\n\treturn desc;\n}\n\nstatic struct axi_dmac_sg *axi_dmac_fill_linear_sg(struct axi_dmac_chan *chan,\n\tenum dma_transfer_direction direction, dma_addr_t addr,\n\tunsigned int num_periods, unsigned int period_len,\n\tstruct axi_dmac_sg *sg)\n{\n\tunsigned int num_segments, i;\n\tunsigned int segment_size;\n\tunsigned int len;\n\n\t \n\tnum_segments = DIV_ROUND_UP(period_len, chan->max_length);\n\tsegment_size = DIV_ROUND_UP(period_len, num_segments);\n\t \n\tsegment_size = ((segment_size - 1) | chan->length_align_mask) + 1;\n\n\tfor (i = 0; i < num_periods; i++) {\n\t\tlen = period_len;\n\n\t\twhile (len > segment_size) {\n\t\t\tif (direction == DMA_DEV_TO_MEM)\n\t\t\t\tsg->dest_addr = addr;\n\t\t\telse\n\t\t\t\tsg->src_addr = addr;\n\t\t\tsg->x_len = segment_size;\n\t\t\tsg->y_len = 1;\n\t\t\tsg++;\n\t\t\taddr += segment_size;\n\t\t\tlen -= segment_size;\n\t\t}\n\n\t\tif (direction == DMA_DEV_TO_MEM)\n\t\t\tsg->dest_addr = addr;\n\t\telse\n\t\t\tsg->src_addr = addr;\n\t\tsg->x_len = len;\n\t\tsg->y_len = 1;\n\t\tsg++;\n\t\taddr += len;\n\t}\n\n\treturn sg;\n}\n\nstatic struct dma_async_tx_descriptor *axi_dmac_prep_slave_sg(\n\tstruct dma_chan *c, struct scatterlist *sgl,\n\tunsigned int sg_len, enum dma_transfer_direction direction,\n\tunsigned long flags, void *context)\n{\n\tstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\n\tstruct axi_dmac_desc *desc;\n\tstruct axi_dmac_sg *dsg;\n\tstruct scatterlist *sg;\n\tunsigned int num_sgs;\n\tunsigned int i;\n\n\tif (direction != chan->direction)\n\t\treturn NULL;\n\n\tnum_sgs = 0;\n\tfor_each_sg(sgl, sg, sg_len, i)\n\t\tnum_sgs += DIV_ROUND_UP(sg_dma_len(sg), chan->max_length);\n\n\tdesc = axi_dmac_alloc_desc(num_sgs);\n\tif (!desc)\n\t\treturn NULL;\n\n\tdsg = desc->sg;\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tif (!axi_dmac_check_addr(chan, sg_dma_address(sg)) ||\n\t\t    !axi_dmac_check_len(chan, sg_dma_len(sg))) {\n\t\t\tkfree(desc);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tdsg = axi_dmac_fill_linear_sg(chan, direction, sg_dma_address(sg), 1,\n\t\t\tsg_dma_len(sg), dsg);\n\t}\n\n\tdesc->cyclic = false;\n\n\treturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n}\n\nstatic struct dma_async_tx_descriptor *axi_dmac_prep_dma_cyclic(\n\tstruct dma_chan *c, dma_addr_t buf_addr, size_t buf_len,\n\tsize_t period_len, enum dma_transfer_direction direction,\n\tunsigned long flags)\n{\n\tstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\n\tstruct axi_dmac_desc *desc;\n\tunsigned int num_periods, num_segments;\n\n\tif (direction != chan->direction)\n\t\treturn NULL;\n\n\tif (!axi_dmac_check_len(chan, buf_len) ||\n\t    !axi_dmac_check_addr(chan, buf_addr))\n\t\treturn NULL;\n\n\tif (period_len == 0 || buf_len % period_len)\n\t\treturn NULL;\n\n\tnum_periods = buf_len / period_len;\n\tnum_segments = DIV_ROUND_UP(period_len, chan->max_length);\n\n\tdesc = axi_dmac_alloc_desc(num_periods * num_segments);\n\tif (!desc)\n\t\treturn NULL;\n\n\taxi_dmac_fill_linear_sg(chan, direction, buf_addr, num_periods,\n\t\tperiod_len, desc->sg);\n\n\tdesc->cyclic = true;\n\n\treturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n}\n\nstatic struct dma_async_tx_descriptor *axi_dmac_prep_interleaved(\n\tstruct dma_chan *c, struct dma_interleaved_template *xt,\n\tunsigned long flags)\n{\n\tstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\n\tstruct axi_dmac_desc *desc;\n\tsize_t dst_icg, src_icg;\n\n\tif (xt->frame_size != 1)\n\t\treturn NULL;\n\n\tif (xt->dir != chan->direction)\n\t\treturn NULL;\n\n\tif (axi_dmac_src_is_mem(chan)) {\n\t\tif (!xt->src_inc || !axi_dmac_check_addr(chan, xt->src_start))\n\t\t\treturn NULL;\n\t}\n\n\tif (axi_dmac_dest_is_mem(chan)) {\n\t\tif (!xt->dst_inc || !axi_dmac_check_addr(chan, xt->dst_start))\n\t\t\treturn NULL;\n\t}\n\n\tdst_icg = dmaengine_get_dst_icg(xt, &xt->sgl[0]);\n\tsrc_icg = dmaengine_get_src_icg(xt, &xt->sgl[0]);\n\n\tif (chan->hw_2d) {\n\t\tif (!axi_dmac_check_len(chan, xt->sgl[0].size) ||\n\t\t    xt->numf == 0)\n\t\t\treturn NULL;\n\t\tif (xt->sgl[0].size + dst_icg > chan->max_length ||\n\t\t    xt->sgl[0].size + src_icg > chan->max_length)\n\t\t\treturn NULL;\n\t} else {\n\t\tif (dst_icg != 0 || src_icg != 0)\n\t\t\treturn NULL;\n\t\tif (chan->max_length / xt->sgl[0].size < xt->numf)\n\t\t\treturn NULL;\n\t\tif (!axi_dmac_check_len(chan, xt->sgl[0].size * xt->numf))\n\t\t\treturn NULL;\n\t}\n\n\tdesc = axi_dmac_alloc_desc(1);\n\tif (!desc)\n\t\treturn NULL;\n\n\tif (axi_dmac_src_is_mem(chan)) {\n\t\tdesc->sg[0].src_addr = xt->src_start;\n\t\tdesc->sg[0].src_stride = xt->sgl[0].size + src_icg;\n\t}\n\n\tif (axi_dmac_dest_is_mem(chan)) {\n\t\tdesc->sg[0].dest_addr = xt->dst_start;\n\t\tdesc->sg[0].dest_stride = xt->sgl[0].size + dst_icg;\n\t}\n\n\tif (chan->hw_2d) {\n\t\tdesc->sg[0].x_len = xt->sgl[0].size;\n\t\tdesc->sg[0].y_len = xt->numf;\n\t} else {\n\t\tdesc->sg[0].x_len = xt->sgl[0].size * xt->numf;\n\t\tdesc->sg[0].y_len = 1;\n\t}\n\n\tif (flags & DMA_CYCLIC)\n\t\tdesc->cyclic = true;\n\n\treturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n}\n\nstatic void axi_dmac_free_chan_resources(struct dma_chan *c)\n{\n\tvchan_free_chan_resources(to_virt_chan(c));\n}\n\nstatic void axi_dmac_desc_free(struct virt_dma_desc *vdesc)\n{\n\tkfree(container_of(vdesc, struct axi_dmac_desc, vdesc));\n}\n\nstatic bool axi_dmac_regmap_rdwr(struct device *dev, unsigned int reg)\n{\n\tswitch (reg) {\n\tcase AXI_DMAC_REG_IRQ_MASK:\n\tcase AXI_DMAC_REG_IRQ_SOURCE:\n\tcase AXI_DMAC_REG_IRQ_PENDING:\n\tcase AXI_DMAC_REG_CTRL:\n\tcase AXI_DMAC_REG_TRANSFER_ID:\n\tcase AXI_DMAC_REG_START_TRANSFER:\n\tcase AXI_DMAC_REG_FLAGS:\n\tcase AXI_DMAC_REG_DEST_ADDRESS:\n\tcase AXI_DMAC_REG_SRC_ADDRESS:\n\tcase AXI_DMAC_REG_X_LENGTH:\n\tcase AXI_DMAC_REG_Y_LENGTH:\n\tcase AXI_DMAC_REG_DEST_STRIDE:\n\tcase AXI_DMAC_REG_SRC_STRIDE:\n\tcase AXI_DMAC_REG_TRANSFER_DONE:\n\tcase AXI_DMAC_REG_ACTIVE_TRANSFER_ID:\n\tcase AXI_DMAC_REG_STATUS:\n\tcase AXI_DMAC_REG_CURRENT_SRC_ADDR:\n\tcase AXI_DMAC_REG_CURRENT_DEST_ADDR:\n\tcase AXI_DMAC_REG_PARTIAL_XFER_LEN:\n\tcase AXI_DMAC_REG_PARTIAL_XFER_ID:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic const struct regmap_config axi_dmac_regmap_config = {\n\t.reg_bits = 32,\n\t.val_bits = 32,\n\t.reg_stride = 4,\n\t.max_register = AXI_DMAC_REG_PARTIAL_XFER_ID,\n\t.readable_reg = axi_dmac_regmap_rdwr,\n\t.writeable_reg = axi_dmac_regmap_rdwr,\n};\n\nstatic void axi_dmac_adjust_chan_params(struct axi_dmac_chan *chan)\n{\n\tchan->address_align_mask = max(chan->dest_width, chan->src_width) - 1;\n\n\tif (axi_dmac_dest_is_mem(chan) && axi_dmac_src_is_mem(chan))\n\t\tchan->direction = DMA_MEM_TO_MEM;\n\telse if (!axi_dmac_dest_is_mem(chan) && axi_dmac_src_is_mem(chan))\n\t\tchan->direction = DMA_MEM_TO_DEV;\n\telse if (axi_dmac_dest_is_mem(chan) && !axi_dmac_src_is_mem(chan))\n\t\tchan->direction = DMA_DEV_TO_MEM;\n\telse\n\t\tchan->direction = DMA_DEV_TO_DEV;\n}\n\n \nstatic int axi_dmac_parse_chan_dt(struct device_node *of_chan,\n\tstruct axi_dmac_chan *chan)\n{\n\tu32 val;\n\tint ret;\n\n\tret = of_property_read_u32(of_chan, \"reg\", &val);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (val != 0)\n\t\treturn -EINVAL;\n\n\tret = of_property_read_u32(of_chan, \"adi,source-bus-type\", &val);\n\tif (ret)\n\t\treturn ret;\n\tif (val > AXI_DMAC_BUS_TYPE_FIFO)\n\t\treturn -EINVAL;\n\tchan->src_type = val;\n\n\tret = of_property_read_u32(of_chan, \"adi,destination-bus-type\", &val);\n\tif (ret)\n\t\treturn ret;\n\tif (val > AXI_DMAC_BUS_TYPE_FIFO)\n\t\treturn -EINVAL;\n\tchan->dest_type = val;\n\n\tret = of_property_read_u32(of_chan, \"adi,source-bus-width\", &val);\n\tif (ret)\n\t\treturn ret;\n\tchan->src_width = val / 8;\n\n\tret = of_property_read_u32(of_chan, \"adi,destination-bus-width\", &val);\n\tif (ret)\n\t\treturn ret;\n\tchan->dest_width = val / 8;\n\n\taxi_dmac_adjust_chan_params(chan);\n\n\treturn 0;\n}\n\nstatic int axi_dmac_parse_dt(struct device *dev, struct axi_dmac *dmac)\n{\n\tstruct device_node *of_channels, *of_chan;\n\tint ret;\n\n\tof_channels = of_get_child_by_name(dev->of_node, \"adi,channels\");\n\tif (of_channels == NULL)\n\t\treturn -ENODEV;\n\n\tfor_each_child_of_node(of_channels, of_chan) {\n\t\tret = axi_dmac_parse_chan_dt(of_chan, &dmac->chan);\n\t\tif (ret) {\n\t\t\tof_node_put(of_chan);\n\t\t\tof_node_put(of_channels);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tof_node_put(of_channels);\n\n\treturn 0;\n}\n\nstatic int axi_dmac_read_chan_config(struct device *dev, struct axi_dmac *dmac)\n{\n\tstruct axi_dmac_chan *chan = &dmac->chan;\n\tunsigned int val, desc;\n\n\tdesc = axi_dmac_read(dmac, AXI_DMAC_REG_INTERFACE_DESC);\n\tif (desc == 0) {\n\t\tdev_err(dev, \"DMA interface register reads zero\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tval = AXI_DMAC_DMA_SRC_TYPE_GET(desc);\n\tif (val > AXI_DMAC_BUS_TYPE_FIFO) {\n\t\tdev_err(dev, \"Invalid source bus type read: %d\\n\", val);\n\t\treturn -EINVAL;\n\t}\n\tchan->src_type = val;\n\n\tval = AXI_DMAC_DMA_DST_TYPE_GET(desc);\n\tif (val > AXI_DMAC_BUS_TYPE_FIFO) {\n\t\tdev_err(dev, \"Invalid destination bus type read: %d\\n\", val);\n\t\treturn -EINVAL;\n\t}\n\tchan->dest_type = val;\n\n\tval = AXI_DMAC_DMA_SRC_WIDTH_GET(desc);\n\tif (val == 0) {\n\t\tdev_err(dev, \"Source bus width is zero\\n\");\n\t\treturn -EINVAL;\n\t}\n\t \n\tchan->src_width = 1 << val;\n\n\tval = AXI_DMAC_DMA_DST_WIDTH_GET(desc);\n\tif (val == 0) {\n\t\tdev_err(dev, \"Destination bus width is zero\\n\");\n\t\treturn -EINVAL;\n\t}\n\tchan->dest_width = 1 << val;\n\n\taxi_dmac_adjust_chan_params(chan);\n\n\treturn 0;\n}\n\nstatic int axi_dmac_detect_caps(struct axi_dmac *dmac, unsigned int version)\n{\n\tstruct axi_dmac_chan *chan = &dmac->chan;\n\n\taxi_dmac_write(dmac, AXI_DMAC_REG_FLAGS, AXI_DMAC_FLAG_CYCLIC);\n\tif (axi_dmac_read(dmac, AXI_DMAC_REG_FLAGS) == AXI_DMAC_FLAG_CYCLIC)\n\t\tchan->hw_cyclic = true;\n\n\taxi_dmac_write(dmac, AXI_DMAC_REG_Y_LENGTH, 1);\n\tif (axi_dmac_read(dmac, AXI_DMAC_REG_Y_LENGTH) == 1)\n\t\tchan->hw_2d = true;\n\n\taxi_dmac_write(dmac, AXI_DMAC_REG_X_LENGTH, 0xffffffff);\n\tchan->max_length = axi_dmac_read(dmac, AXI_DMAC_REG_X_LENGTH);\n\tif (chan->max_length != UINT_MAX)\n\t\tchan->max_length++;\n\n\taxi_dmac_write(dmac, AXI_DMAC_REG_DEST_ADDRESS, 0xffffffff);\n\tif (axi_dmac_read(dmac, AXI_DMAC_REG_DEST_ADDRESS) == 0 &&\n\t    chan->dest_type == AXI_DMAC_BUS_TYPE_AXI_MM) {\n\t\tdev_err(dmac->dma_dev.dev,\n\t\t\t\"Destination memory-mapped interface not supported.\");\n\t\treturn -ENODEV;\n\t}\n\n\taxi_dmac_write(dmac, AXI_DMAC_REG_SRC_ADDRESS, 0xffffffff);\n\tif (axi_dmac_read(dmac, AXI_DMAC_REG_SRC_ADDRESS) == 0 &&\n\t    chan->src_type == AXI_DMAC_BUS_TYPE_AXI_MM) {\n\t\tdev_err(dmac->dma_dev.dev,\n\t\t\t\"Source memory-mapped interface not supported.\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (version >= ADI_AXI_PCORE_VER(4, 2, 'a'))\n\t\tchan->hw_partial_xfer = true;\n\n\tif (version >= ADI_AXI_PCORE_VER(4, 1, 'a')) {\n\t\taxi_dmac_write(dmac, AXI_DMAC_REG_X_LENGTH, 0x00);\n\t\tchan->length_align_mask =\n\t\t\taxi_dmac_read(dmac, AXI_DMAC_REG_X_LENGTH);\n\t} else {\n\t\tchan->length_align_mask = chan->address_align_mask;\n\t}\n\n\treturn 0;\n}\n\nstatic int axi_dmac_probe(struct platform_device *pdev)\n{\n\tstruct dma_device *dma_dev;\n\tstruct axi_dmac *dmac;\n\tstruct regmap *regmap;\n\tunsigned int version;\n\tint ret;\n\n\tdmac = devm_kzalloc(&pdev->dev, sizeof(*dmac), GFP_KERNEL);\n\tif (!dmac)\n\t\treturn -ENOMEM;\n\n\tdmac->irq = platform_get_irq(pdev, 0);\n\tif (dmac->irq < 0)\n\t\treturn dmac->irq;\n\tif (dmac->irq == 0)\n\t\treturn -EINVAL;\n\n\tdmac->base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(dmac->base))\n\t\treturn PTR_ERR(dmac->base);\n\n\tdmac->clk = devm_clk_get(&pdev->dev, NULL);\n\tif (IS_ERR(dmac->clk))\n\t\treturn PTR_ERR(dmac->clk);\n\n\tret = clk_prepare_enable(dmac->clk);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tversion = axi_dmac_read(dmac, ADI_AXI_REG_VERSION);\n\n\tif (version >= ADI_AXI_PCORE_VER(4, 3, 'a'))\n\t\tret = axi_dmac_read_chan_config(&pdev->dev, dmac);\n\telse\n\t\tret = axi_dmac_parse_dt(&pdev->dev, dmac);\n\n\tif (ret < 0)\n\t\tgoto err_clk_disable;\n\n\tINIT_LIST_HEAD(&dmac->chan.active_descs);\n\n\tdma_set_max_seg_size(&pdev->dev, UINT_MAX);\n\n\tdma_dev = &dmac->dma_dev;\n\tdma_cap_set(DMA_SLAVE, dma_dev->cap_mask);\n\tdma_cap_set(DMA_CYCLIC, dma_dev->cap_mask);\n\tdma_cap_set(DMA_INTERLEAVE, dma_dev->cap_mask);\n\tdma_dev->device_free_chan_resources = axi_dmac_free_chan_resources;\n\tdma_dev->device_tx_status = dma_cookie_status;\n\tdma_dev->device_issue_pending = axi_dmac_issue_pending;\n\tdma_dev->device_prep_slave_sg = axi_dmac_prep_slave_sg;\n\tdma_dev->device_prep_dma_cyclic = axi_dmac_prep_dma_cyclic;\n\tdma_dev->device_prep_interleaved_dma = axi_dmac_prep_interleaved;\n\tdma_dev->device_terminate_all = axi_dmac_terminate_all;\n\tdma_dev->device_synchronize = axi_dmac_synchronize;\n\tdma_dev->dev = &pdev->dev;\n\tdma_dev->src_addr_widths = BIT(dmac->chan.src_width);\n\tdma_dev->dst_addr_widths = BIT(dmac->chan.dest_width);\n\tdma_dev->directions = BIT(dmac->chan.direction);\n\tdma_dev->residue_granularity = DMA_RESIDUE_GRANULARITY_DESCRIPTOR;\n\tINIT_LIST_HEAD(&dma_dev->channels);\n\n\tdmac->chan.vchan.desc_free = axi_dmac_desc_free;\n\tvchan_init(&dmac->chan.vchan, dma_dev);\n\n\tret = axi_dmac_detect_caps(dmac, version);\n\tif (ret)\n\t\tgoto err_clk_disable;\n\n\tdma_dev->copy_align = (dmac->chan.address_align_mask + 1);\n\n\taxi_dmac_write(dmac, AXI_DMAC_REG_IRQ_MASK, 0x00);\n\n\tif (of_dma_is_coherent(pdev->dev.of_node)) {\n\t\tret = axi_dmac_read(dmac, AXI_DMAC_REG_COHERENCY_DESC);\n\n\t\tif (version < ADI_AXI_PCORE_VER(4, 4, 'a') ||\n\t\t    !AXI_DMAC_DST_COHERENT_GET(ret)) {\n\t\t\tdev_err(dmac->dma_dev.dev,\n\t\t\t\t\"Coherent DMA not supported in hardware\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_clk_disable;\n\t\t}\n\t}\n\n\tret = dma_async_device_register(dma_dev);\n\tif (ret)\n\t\tgoto err_clk_disable;\n\n\tret = of_dma_controller_register(pdev->dev.of_node,\n\t\tof_dma_xlate_by_chan_id, dma_dev);\n\tif (ret)\n\t\tgoto err_unregister_device;\n\n\tret = request_irq(dmac->irq, axi_dmac_interrupt_handler, IRQF_SHARED,\n\t\tdev_name(&pdev->dev), dmac);\n\tif (ret)\n\t\tgoto err_unregister_of;\n\n\tplatform_set_drvdata(pdev, dmac);\n\n\tregmap = devm_regmap_init_mmio(&pdev->dev, dmac->base,\n\t\t &axi_dmac_regmap_config);\n\tif (IS_ERR(regmap)) {\n\t\tret = PTR_ERR(regmap);\n\t\tgoto err_free_irq;\n\t}\n\n\treturn 0;\n\nerr_free_irq:\n\tfree_irq(dmac->irq, dmac);\nerr_unregister_of:\n\tof_dma_controller_free(pdev->dev.of_node);\nerr_unregister_device:\n\tdma_async_device_unregister(&dmac->dma_dev);\nerr_clk_disable:\n\tclk_disable_unprepare(dmac->clk);\n\n\treturn ret;\n}\n\nstatic int axi_dmac_remove(struct platform_device *pdev)\n{\n\tstruct axi_dmac *dmac = platform_get_drvdata(pdev);\n\n\tof_dma_controller_free(pdev->dev.of_node);\n\tfree_irq(dmac->irq, dmac);\n\ttasklet_kill(&dmac->chan.vchan.task);\n\tdma_async_device_unregister(&dmac->dma_dev);\n\tclk_disable_unprepare(dmac->clk);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id axi_dmac_of_match_table[] = {\n\t{ .compatible = \"adi,axi-dmac-1.00.a\" },\n\t{ },\n};\nMODULE_DEVICE_TABLE(of, axi_dmac_of_match_table);\n\nstatic struct platform_driver axi_dmac_driver = {\n\t.driver = {\n\t\t.name = \"dma-axi-dmac\",\n\t\t.of_match_table = axi_dmac_of_match_table,\n\t},\n\t.probe = axi_dmac_probe,\n\t.remove = axi_dmac_remove,\n};\nmodule_platform_driver(axi_dmac_driver);\n\nMODULE_AUTHOR(\"Lars-Peter Clausen <lars@metafoo.de>\");\nMODULE_DESCRIPTION(\"DMA controller driver for the AXI-DMAC controller\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}