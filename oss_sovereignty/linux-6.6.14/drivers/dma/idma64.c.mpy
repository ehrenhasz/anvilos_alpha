{
  "module_name": "idma64.c",
  "hash_id": "f897d865dab5882fe54b94886cb29dc1fadc38f9e128cdd46530ea65bdb174bc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/idma64.c",
  "human_readable_source": "\n \n\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmapool.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n\n#include <linux/dma/idma64.h>\n\n#include \"idma64.h\"\n\n \n#define IDMA64_NR_CHAN\t\t2\n\n \n\nstatic struct device *chan2dev(struct dma_chan *chan)\n{\n\treturn &chan->dev->device;\n}\n\n \n\nstatic void idma64_off(struct idma64 *idma64)\n{\n\tunsigned short count = 100;\n\n\tdma_writel(idma64, CFG, 0);\n\n\tchannel_clear_bit(idma64, MASK(XFER), idma64->all_chan_mask);\n\tchannel_clear_bit(idma64, MASK(BLOCK), idma64->all_chan_mask);\n\tchannel_clear_bit(idma64, MASK(SRC_TRAN), idma64->all_chan_mask);\n\tchannel_clear_bit(idma64, MASK(DST_TRAN), idma64->all_chan_mask);\n\tchannel_clear_bit(idma64, MASK(ERROR), idma64->all_chan_mask);\n\n\tdo {\n\t\tcpu_relax();\n\t} while (dma_readl(idma64, CFG) & IDMA64_CFG_DMA_EN && --count);\n}\n\nstatic void idma64_on(struct idma64 *idma64)\n{\n\tdma_writel(idma64, CFG, IDMA64_CFG_DMA_EN);\n}\n\n \n\nstatic void idma64_chan_init(struct idma64 *idma64, struct idma64_chan *idma64c)\n{\n\tu32 cfghi = IDMA64C_CFGH_SRC_PER(1) | IDMA64C_CFGH_DST_PER(0);\n\tu32 cfglo = 0;\n\n\t \n\tcfglo |= IDMA64C_CFGL_DST_BURST_ALIGN | IDMA64C_CFGL_SRC_BURST_ALIGN;\n\n\tchannel_writel(idma64c, CFG_LO, cfglo);\n\tchannel_writel(idma64c, CFG_HI, cfghi);\n\n\t \n\tchannel_set_bit(idma64, MASK(XFER), idma64c->mask);\n\tchannel_set_bit(idma64, MASK(ERROR), idma64c->mask);\n\n\t \n\tidma64_on(idma64);\n}\n\nstatic void idma64_chan_stop(struct idma64 *idma64, struct idma64_chan *idma64c)\n{\n\tchannel_clear_bit(idma64, CH_EN, idma64c->mask);\n}\n\nstatic void idma64_chan_start(struct idma64 *idma64, struct idma64_chan *idma64c)\n{\n\tstruct idma64_desc *desc = idma64c->desc;\n\tstruct idma64_hw_desc *hw = &desc->hw[0];\n\n\tchannel_writeq(idma64c, SAR, 0);\n\tchannel_writeq(idma64c, DAR, 0);\n\n\tchannel_writel(idma64c, CTL_HI, IDMA64C_CTLH_BLOCK_TS(~0UL));\n\tchannel_writel(idma64c, CTL_LO, IDMA64C_CTLL_LLP_S_EN | IDMA64C_CTLL_LLP_D_EN);\n\n\tchannel_writeq(idma64c, LLP, hw->llp);\n\n\tchannel_set_bit(idma64, CH_EN, idma64c->mask);\n}\n\nstatic void idma64_stop_transfer(struct idma64_chan *idma64c)\n{\n\tstruct idma64 *idma64 = to_idma64(idma64c->vchan.chan.device);\n\n\tidma64_chan_stop(idma64, idma64c);\n}\n\nstatic void idma64_start_transfer(struct idma64_chan *idma64c)\n{\n\tstruct idma64 *idma64 = to_idma64(idma64c->vchan.chan.device);\n\tstruct virt_dma_desc *vdesc;\n\n\t \n\tvdesc = vchan_next_desc(&idma64c->vchan);\n\tif (!vdesc) {\n\t\tidma64c->desc = NULL;\n\t\treturn;\n\t}\n\n\tlist_del(&vdesc->node);\n\tidma64c->desc = to_idma64_desc(vdesc);\n\n\t \n\tidma64_chan_init(idma64, idma64c);\n\n\t \n\tidma64_chan_start(idma64, idma64c);\n}\n\n \n\nstatic void idma64_chan_irq(struct idma64 *idma64, unsigned short c,\n\t\tu32 status_err, u32 status_xfer)\n{\n\tstruct idma64_chan *idma64c = &idma64->chan[c];\n\tstruct dma_chan_percpu *stat;\n\tstruct idma64_desc *desc;\n\n\tstat = this_cpu_ptr(idma64c->vchan.chan.local);\n\n\tspin_lock(&idma64c->vchan.lock);\n\tdesc = idma64c->desc;\n\tif (desc) {\n\t\tif (status_err & (1 << c)) {\n\t\t\tdma_writel(idma64, CLEAR(ERROR), idma64c->mask);\n\t\t\tdesc->status = DMA_ERROR;\n\t\t} else if (status_xfer & (1 << c)) {\n\t\t\tdma_writel(idma64, CLEAR(XFER), idma64c->mask);\n\t\t\tdesc->status = DMA_COMPLETE;\n\t\t\tvchan_cookie_complete(&desc->vdesc);\n\t\t\tstat->bytes_transferred += desc->length;\n\t\t\tidma64_start_transfer(idma64c);\n\t\t}\n\n\t\t \n\t\tif (idma64c->desc == NULL || desc->status == DMA_ERROR)\n\t\t\tidma64_stop_transfer(idma64c);\n\t}\n\tspin_unlock(&idma64c->vchan.lock);\n}\n\nstatic irqreturn_t idma64_irq(int irq, void *dev)\n{\n\tstruct idma64 *idma64 = dev;\n\tu32 status = dma_readl(idma64, STATUS_INT);\n\tu32 status_xfer;\n\tu32 status_err;\n\tunsigned short i;\n\n\tdev_vdbg(idma64->dma.dev, \"%s: status=%#x\\n\", __func__, status);\n\n\t \n\tif (!status)\n\t\treturn IRQ_NONE;\n\n\tstatus_xfer = dma_readl(idma64, RAW(XFER));\n\tstatus_err = dma_readl(idma64, RAW(ERROR));\n\n\tfor (i = 0; i < idma64->dma.chancnt; i++)\n\t\tidma64_chan_irq(idma64, i, status_err, status_xfer);\n\n\treturn IRQ_HANDLED;\n}\n\n \n\nstatic struct idma64_desc *idma64_alloc_desc(unsigned int ndesc)\n{\n\tstruct idma64_desc *desc;\n\n\tdesc = kzalloc(sizeof(*desc), GFP_NOWAIT);\n\tif (!desc)\n\t\treturn NULL;\n\n\tdesc->hw = kcalloc(ndesc, sizeof(*desc->hw), GFP_NOWAIT);\n\tif (!desc->hw) {\n\t\tkfree(desc);\n\t\treturn NULL;\n\t}\n\n\treturn desc;\n}\n\nstatic void idma64_desc_free(struct idma64_chan *idma64c,\n\t\tstruct idma64_desc *desc)\n{\n\tstruct idma64_hw_desc *hw;\n\n\tif (desc->ndesc) {\n\t\tunsigned int i = desc->ndesc;\n\n\t\tdo {\n\t\t\thw = &desc->hw[--i];\n\t\t\tdma_pool_free(idma64c->pool, hw->lli, hw->llp);\n\t\t} while (i);\n\t}\n\n\tkfree(desc->hw);\n\tkfree(desc);\n}\n\nstatic void idma64_vdesc_free(struct virt_dma_desc *vdesc)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(vdesc->tx.chan);\n\n\tidma64_desc_free(idma64c, to_idma64_desc(vdesc));\n}\n\nstatic void idma64_hw_desc_fill(struct idma64_hw_desc *hw,\n\t\tstruct dma_slave_config *config,\n\t\tenum dma_transfer_direction direction, u64 llp)\n{\n\tstruct idma64_lli *lli = hw->lli;\n\tu64 sar, dar;\n\tu32 ctlhi = IDMA64C_CTLH_BLOCK_TS(hw->len);\n\tu32 ctllo = IDMA64C_CTLL_LLP_S_EN | IDMA64C_CTLL_LLP_D_EN;\n\tu32 src_width, dst_width;\n\n\tif (direction == DMA_MEM_TO_DEV) {\n\t\tsar = hw->phys;\n\t\tdar = config->dst_addr;\n\t\tctllo |= IDMA64C_CTLL_DST_FIX | IDMA64C_CTLL_SRC_INC |\n\t\t\t IDMA64C_CTLL_FC_M2P;\n\t\tsrc_width = __ffs(sar | hw->len | 4);\n\t\tdst_width = __ffs(config->dst_addr_width);\n\t} else {\t \n\t\tsar = config->src_addr;\n\t\tdar = hw->phys;\n\t\tctllo |= IDMA64C_CTLL_DST_INC | IDMA64C_CTLL_SRC_FIX |\n\t\t\t IDMA64C_CTLL_FC_P2M;\n\t\tsrc_width = __ffs(config->src_addr_width);\n\t\tdst_width = __ffs(dar | hw->len | 4);\n\t}\n\n\tlli->sar = sar;\n\tlli->dar = dar;\n\n\tlli->ctlhi = ctlhi;\n\tlli->ctllo = ctllo |\n\t\t     IDMA64C_CTLL_SRC_MSIZE(config->src_maxburst) |\n\t\t     IDMA64C_CTLL_DST_MSIZE(config->dst_maxburst) |\n\t\t     IDMA64C_CTLL_DST_WIDTH(dst_width) |\n\t\t     IDMA64C_CTLL_SRC_WIDTH(src_width);\n\n\tlli->llp = llp;\n}\n\nstatic void idma64_desc_fill(struct idma64_chan *idma64c,\n\t\tstruct idma64_desc *desc)\n{\n\tstruct dma_slave_config *config = &idma64c->config;\n\tunsigned int i = desc->ndesc;\n\tstruct idma64_hw_desc *hw = &desc->hw[i - 1];\n\tstruct idma64_lli *lli = hw->lli;\n\tu64 llp = 0;\n\n\t \n\tdo {\n\t\thw = &desc->hw[--i];\n\t\tidma64_hw_desc_fill(hw, config, desc->direction, llp);\n\t\tllp = hw->llp;\n\t\tdesc->length += hw->len;\n\t} while (i);\n\n\t \n\tlli->ctllo |= IDMA64C_CTLL_INT_EN;\n\n\t \n\tlli->ctllo &= ~(IDMA64C_CTLL_LLP_S_EN | IDMA64C_CTLL_LLP_D_EN);\n}\n\nstatic struct dma_async_tx_descriptor *idma64_prep_slave_sg(\n\t\tstruct dma_chan *chan, struct scatterlist *sgl,\n\t\tunsigned int sg_len, enum dma_transfer_direction direction,\n\t\tunsigned long flags, void *context)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\tstruct idma64_desc *desc;\n\tstruct scatterlist *sg;\n\tunsigned int i;\n\n\tdesc = idma64_alloc_desc(sg_len);\n\tif (!desc)\n\t\treturn NULL;\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tstruct idma64_hw_desc *hw = &desc->hw[i];\n\n\t\t \n\t\thw->lli = dma_pool_alloc(idma64c->pool, GFP_NOWAIT, &hw->llp);\n\t\tif (!hw->lli) {\n\t\t\tdesc->ndesc = i;\n\t\t\tidma64_desc_free(idma64c, desc);\n\t\t\treturn NULL;\n\t\t}\n\n\t\thw->phys = sg_dma_address(sg);\n\t\thw->len = sg_dma_len(sg);\n\t}\n\n\tdesc->ndesc = sg_len;\n\tdesc->direction = direction;\n\tdesc->status = DMA_IN_PROGRESS;\n\n\tidma64_desc_fill(idma64c, desc);\n\treturn vchan_tx_prep(&idma64c->vchan, &desc->vdesc, flags);\n}\n\nstatic void idma64_issue_pending(struct dma_chan *chan)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&idma64c->vchan.lock, flags);\n\tif (vchan_issue_pending(&idma64c->vchan) && !idma64c->desc)\n\t\tidma64_start_transfer(idma64c);\n\tspin_unlock_irqrestore(&idma64c->vchan.lock, flags);\n}\n\nstatic size_t idma64_active_desc_size(struct idma64_chan *idma64c)\n{\n\tstruct idma64_desc *desc = idma64c->desc;\n\tstruct idma64_hw_desc *hw;\n\tsize_t bytes = desc->length;\n\tu64 llp = channel_readq(idma64c, LLP);\n\tu32 ctlhi = channel_readl(idma64c, CTL_HI);\n\tunsigned int i = 0;\n\n\tdo {\n\t\thw = &desc->hw[i];\n\t\tif (hw->llp == llp)\n\t\t\tbreak;\n\t\tbytes -= hw->len;\n\t} while (++i < desc->ndesc);\n\n\tif (!i)\n\t\treturn bytes;\n\n\t \n\tbytes += desc->hw[--i].len;\n\n\treturn bytes - IDMA64C_CTLH_BLOCK_TS(ctlhi);\n}\n\nstatic enum dma_status idma64_tx_status(struct dma_chan *chan,\n\t\tdma_cookie_t cookie, struct dma_tx_state *state)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\tstruct virt_dma_desc *vdesc;\n\tenum dma_status status;\n\tsize_t bytes;\n\tunsigned long flags;\n\n\tstatus = dma_cookie_status(chan, cookie, state);\n\tif (status == DMA_COMPLETE)\n\t\treturn status;\n\n\tspin_lock_irqsave(&idma64c->vchan.lock, flags);\n\tvdesc = vchan_find_desc(&idma64c->vchan, cookie);\n\tif (idma64c->desc && cookie == idma64c->desc->vdesc.tx.cookie) {\n\t\tbytes = idma64_active_desc_size(idma64c);\n\t\tdma_set_residue(state, bytes);\n\t\tstatus = idma64c->desc->status;\n\t} else if (vdesc) {\n\t\tbytes = to_idma64_desc(vdesc)->length;\n\t\tdma_set_residue(state, bytes);\n\t}\n\tspin_unlock_irqrestore(&idma64c->vchan.lock, flags);\n\n\treturn status;\n}\n\nstatic void convert_burst(u32 *maxburst)\n{\n\tif (*maxburst)\n\t\t*maxburst = __fls(*maxburst);\n\telse\n\t\t*maxburst = 0;\n}\n\nstatic int idma64_slave_config(struct dma_chan *chan,\n\t\tstruct dma_slave_config *config)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\n\tmemcpy(&idma64c->config, config, sizeof(idma64c->config));\n\n\tconvert_burst(&idma64c->config.src_maxburst);\n\tconvert_burst(&idma64c->config.dst_maxburst);\n\n\treturn 0;\n}\n\nstatic void idma64_chan_deactivate(struct idma64_chan *idma64c, bool drain)\n{\n\tunsigned short count = 100;\n\tu32 cfglo;\n\n\tcfglo = channel_readl(idma64c, CFG_LO);\n\tif (drain)\n\t\tcfglo |= IDMA64C_CFGL_CH_DRAIN;\n\telse\n\t\tcfglo &= ~IDMA64C_CFGL_CH_DRAIN;\n\n\tchannel_writel(idma64c, CFG_LO, cfglo | IDMA64C_CFGL_CH_SUSP);\n\tdo {\n\t\tudelay(1);\n\t\tcfglo = channel_readl(idma64c, CFG_LO);\n\t} while (!(cfglo & IDMA64C_CFGL_FIFO_EMPTY) && --count);\n}\n\nstatic void idma64_chan_activate(struct idma64_chan *idma64c)\n{\n\tu32 cfglo;\n\n\tcfglo = channel_readl(idma64c, CFG_LO);\n\tchannel_writel(idma64c, CFG_LO, cfglo & ~IDMA64C_CFGL_CH_SUSP);\n}\n\nstatic int idma64_pause(struct dma_chan *chan)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&idma64c->vchan.lock, flags);\n\tif (idma64c->desc && idma64c->desc->status == DMA_IN_PROGRESS) {\n\t\tidma64_chan_deactivate(idma64c, false);\n\t\tidma64c->desc->status = DMA_PAUSED;\n\t}\n\tspin_unlock_irqrestore(&idma64c->vchan.lock, flags);\n\n\treturn 0;\n}\n\nstatic int idma64_resume(struct dma_chan *chan)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&idma64c->vchan.lock, flags);\n\tif (idma64c->desc && idma64c->desc->status == DMA_PAUSED) {\n\t\tidma64c->desc->status = DMA_IN_PROGRESS;\n\t\tidma64_chan_activate(idma64c);\n\t}\n\tspin_unlock_irqrestore(&idma64c->vchan.lock, flags);\n\n\treturn 0;\n}\n\nstatic int idma64_terminate_all(struct dma_chan *chan)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&idma64c->vchan.lock, flags);\n\tidma64_chan_deactivate(idma64c, true);\n\tidma64_stop_transfer(idma64c);\n\tif (idma64c->desc) {\n\t\tidma64_vdesc_free(&idma64c->desc->vdesc);\n\t\tidma64c->desc = NULL;\n\t}\n\tvchan_get_all_descriptors(&idma64c->vchan, &head);\n\tspin_unlock_irqrestore(&idma64c->vchan.lock, flags);\n\n\tvchan_dma_desc_free_list(&idma64c->vchan, &head);\n\treturn 0;\n}\n\nstatic void idma64_synchronize(struct dma_chan *chan)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\n\tvchan_synchronize(&idma64c->vchan);\n}\n\nstatic int idma64_alloc_chan_resources(struct dma_chan *chan)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\n\t \n\tidma64c->pool = dma_pool_create(dev_name(chan2dev(chan)),\n\t\t\t\t\tchan->device->dev,\n\t\t\t\t\tsizeof(struct idma64_lli), 8, 0);\n\tif (!idma64c->pool) {\n\t\tdev_err(chan2dev(chan), \"No memory for descriptors\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic void idma64_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct idma64_chan *idma64c = to_idma64_chan(chan);\n\n\tvchan_free_chan_resources(to_virt_chan(chan));\n\tdma_pool_destroy(idma64c->pool);\n\tidma64c->pool = NULL;\n}\n\n \n\n#define IDMA64_BUSWIDTHS\t\t\t\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_1_BYTE)\t\t|\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES)\t\t|\t\\\n\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES)\n\nstatic int idma64_probe(struct idma64_chip *chip)\n{\n\tstruct idma64 *idma64;\n\tunsigned short nr_chan = IDMA64_NR_CHAN;\n\tunsigned short i;\n\tint ret;\n\n\tidma64 = devm_kzalloc(chip->dev, sizeof(*idma64), GFP_KERNEL);\n\tif (!idma64)\n\t\treturn -ENOMEM;\n\n\tidma64->regs = chip->regs;\n\tchip->idma64 = idma64;\n\n\tidma64->chan = devm_kcalloc(chip->dev, nr_chan, sizeof(*idma64->chan),\n\t\t\t\t    GFP_KERNEL);\n\tif (!idma64->chan)\n\t\treturn -ENOMEM;\n\n\tidma64->all_chan_mask = (1 << nr_chan) - 1;\n\n\t \n\tidma64_off(idma64);\n\n\tret = devm_request_irq(chip->dev, chip->irq, idma64_irq, IRQF_SHARED,\n\t\t\t       dev_name(chip->dev), idma64);\n\tif (ret)\n\t\treturn ret;\n\n\tINIT_LIST_HEAD(&idma64->dma.channels);\n\tfor (i = 0; i < nr_chan; i++) {\n\t\tstruct idma64_chan *idma64c = &idma64->chan[i];\n\n\t\tidma64c->vchan.desc_free = idma64_vdesc_free;\n\t\tvchan_init(&idma64c->vchan, &idma64->dma);\n\n\t\tidma64c->regs = idma64->regs + i * IDMA64_CH_LENGTH;\n\t\tidma64c->mask = BIT(i);\n\t}\n\n\tdma_cap_set(DMA_SLAVE, idma64->dma.cap_mask);\n\tdma_cap_set(DMA_PRIVATE, idma64->dma.cap_mask);\n\n\tidma64->dma.device_alloc_chan_resources = idma64_alloc_chan_resources;\n\tidma64->dma.device_free_chan_resources = idma64_free_chan_resources;\n\n\tidma64->dma.device_prep_slave_sg = idma64_prep_slave_sg;\n\n\tidma64->dma.device_issue_pending = idma64_issue_pending;\n\tidma64->dma.device_tx_status = idma64_tx_status;\n\n\tidma64->dma.device_config = idma64_slave_config;\n\tidma64->dma.device_pause = idma64_pause;\n\tidma64->dma.device_resume = idma64_resume;\n\tidma64->dma.device_terminate_all = idma64_terminate_all;\n\tidma64->dma.device_synchronize = idma64_synchronize;\n\n\tidma64->dma.src_addr_widths = IDMA64_BUSWIDTHS;\n\tidma64->dma.dst_addr_widths = IDMA64_BUSWIDTHS;\n\tidma64->dma.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\n\tidma64->dma.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\n\tidma64->dma.dev = chip->sysdev;\n\n\tdma_set_max_seg_size(idma64->dma.dev, IDMA64C_CTLH_BLOCK_TS_MASK);\n\n\tret = dma_async_device_register(&idma64->dma);\n\tif (ret)\n\t\treturn ret;\n\n\tdev_info(chip->dev, \"Found Intel integrated DMA 64-bit\\n\");\n\treturn 0;\n}\n\nstatic void idma64_remove(struct idma64_chip *chip)\n{\n\tstruct idma64 *idma64 = chip->idma64;\n\tunsigned short i;\n\n\tdma_async_device_unregister(&idma64->dma);\n\n\t \n\tdevm_free_irq(chip->dev, chip->irq, idma64);\n\n\tfor (i = 0; i < idma64->dma.chancnt; i++) {\n\t\tstruct idma64_chan *idma64c = &idma64->chan[i];\n\n\t\ttasklet_kill(&idma64c->vchan.task);\n\t}\n}\n\n \n\nstatic int idma64_platform_probe(struct platform_device *pdev)\n{\n\tstruct idma64_chip *chip;\n\tstruct device *dev = &pdev->dev;\n\tstruct device *sysdev = dev->parent;\n\tint ret;\n\n\tchip = devm_kzalloc(dev, sizeof(*chip), GFP_KERNEL);\n\tif (!chip)\n\t\treturn -ENOMEM;\n\n\tchip->irq = platform_get_irq(pdev, 0);\n\tif (chip->irq < 0)\n\t\treturn chip->irq;\n\n\tchip->regs = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(chip->regs))\n\t\treturn PTR_ERR(chip->regs);\n\n\tret = dma_coerce_mask_and_coherent(sysdev, DMA_BIT_MASK(64));\n\tif (ret)\n\t\treturn ret;\n\n\tchip->dev = dev;\n\tchip->sysdev = sysdev;\n\n\tret = idma64_probe(chip);\n\tif (ret)\n\t\treturn ret;\n\n\tplatform_set_drvdata(pdev, chip);\n\treturn 0;\n}\n\nstatic int idma64_platform_remove(struct platform_device *pdev)\n{\n\tstruct idma64_chip *chip = platform_get_drvdata(pdev);\n\n\tidma64_remove(chip);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused idma64_pm_suspend(struct device *dev)\n{\n\tstruct idma64_chip *chip = dev_get_drvdata(dev);\n\n\tidma64_off(chip->idma64);\n\treturn 0;\n}\n\nstatic int __maybe_unused idma64_pm_resume(struct device *dev)\n{\n\tstruct idma64_chip *chip = dev_get_drvdata(dev);\n\n\tidma64_on(chip->idma64);\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops idma64_dev_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(idma64_pm_suspend, idma64_pm_resume)\n};\n\nstatic struct platform_driver idma64_platform_driver = {\n\t.probe\t\t= idma64_platform_probe,\n\t.remove\t\t= idma64_platform_remove,\n\t.driver = {\n\t\t.name\t= LPSS_IDMA64_DRIVER_NAME,\n\t\t.pm\t= &idma64_dev_pm_ops,\n\t},\n};\n\nmodule_platform_driver(idma64_platform_driver);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"iDMA64 core driver\");\nMODULE_AUTHOR(\"Andy Shevchenko <andriy.shevchenko@linux.intel.com>\");\nMODULE_ALIAS(\"platform:\" LPSS_IDMA64_DRIVER_NAME);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}