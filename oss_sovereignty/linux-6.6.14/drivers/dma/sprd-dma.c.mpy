{
  "module_name": "sprd-dma.c",
  "hash_id": "c984fb8992898c10e407826fbc14c97993b9d0c9de6dd836a8f931082d197d03",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/sprd-dma.c",
  "human_readable_source": " \n\n#include <linux/clk.h>\n#include <linux/dma-mapping.h>\n#include <linux/dma/sprd-dma.h>\n#include <linux/errno.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_dma.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/slab.h>\n\n#include \"virt-dma.h\"\n\n#define SPRD_DMA_CHN_REG_OFFSET\t\t0x1000\n#define SPRD_DMA_CHN_REG_LENGTH\t\t0x40\n#define SPRD_DMA_MEMCPY_MIN_SIZE\t64\n\n \n#define SPRD_DMA_GLB_PAUSE\t\t0x0\n#define SPRD_DMA_GLB_FRAG_WAIT\t\t0x4\n#define SPRD_DMA_GLB_REQ_PEND0_EN\t0x8\n#define SPRD_DMA_GLB_REQ_PEND1_EN\t0xc\n#define SPRD_DMA_GLB_INT_RAW_STS\t0x10\n#define SPRD_DMA_GLB_INT_MSK_STS\t0x14\n#define SPRD_DMA_GLB_REQ_STS\t\t0x18\n#define SPRD_DMA_GLB_CHN_EN_STS\t\t0x1c\n#define SPRD_DMA_GLB_DEBUG_STS\t\t0x20\n#define SPRD_DMA_GLB_ARB_SEL_STS\t0x24\n#define SPRD_DMA_GLB_2STAGE_GRP1\t0x28\n#define SPRD_DMA_GLB_2STAGE_GRP2\t0x2c\n#define SPRD_DMA_GLB_REQ_UID(uid)\t(0x4 * ((uid) - 1))\n#define SPRD_DMA_GLB_REQ_UID_OFFSET\t0x2000\n\n \n#define SPRD_DMA_CHN_PAUSE\t\t0x0\n#define SPRD_DMA_CHN_REQ\t\t0x4\n#define SPRD_DMA_CHN_CFG\t\t0x8\n#define SPRD_DMA_CHN_INTC\t\t0xc\n#define SPRD_DMA_CHN_SRC_ADDR\t\t0x10\n#define SPRD_DMA_CHN_DES_ADDR\t\t0x14\n#define SPRD_DMA_CHN_FRG_LEN\t\t0x18\n#define SPRD_DMA_CHN_BLK_LEN\t\t0x1c\n#define SPRD_DMA_CHN_TRSC_LEN\t\t0x20\n#define SPRD_DMA_CHN_TRSF_STEP\t\t0x24\n#define SPRD_DMA_CHN_WARP_PTR\t\t0x28\n#define SPRD_DMA_CHN_WARP_TO\t\t0x2c\n#define SPRD_DMA_CHN_LLIST_PTR\t\t0x30\n#define SPRD_DMA_CHN_FRAG_STEP\t\t0x34\n#define SPRD_DMA_CHN_SRC_BLK_STEP\t0x38\n#define SPRD_DMA_CHN_DES_BLK_STEP\t0x3c\n\n \n#define SPRD_DMA_GLB_2STAGE_EN\t\tBIT(24)\n#define SPRD_DMA_GLB_CHN_INT_MASK\tGENMASK(23, 20)\n#define SPRD_DMA_GLB_DEST_INT\t\tBIT(22)\n#define SPRD_DMA_GLB_SRC_INT\t\tBIT(20)\n#define SPRD_DMA_GLB_LIST_DONE_TRG\tBIT(19)\n#define SPRD_DMA_GLB_TRANS_DONE_TRG\tBIT(18)\n#define SPRD_DMA_GLB_BLOCK_DONE_TRG\tBIT(17)\n#define SPRD_DMA_GLB_FRAG_DONE_TRG\tBIT(16)\n#define SPRD_DMA_GLB_TRG_OFFSET\t\t16\n#define SPRD_DMA_GLB_DEST_CHN_MASK\tGENMASK(13, 8)\n#define SPRD_DMA_GLB_DEST_CHN_OFFSET\t8\n#define SPRD_DMA_GLB_SRC_CHN_MASK\tGENMASK(5, 0)\n\n \n#define SPRD_DMA_INT_MASK\t\tGENMASK(4, 0)\n#define SPRD_DMA_INT_CLR_OFFSET\t\t24\n#define SPRD_DMA_FRAG_INT_EN\t\tBIT(0)\n#define SPRD_DMA_BLK_INT_EN\t\tBIT(1)\n#define SPRD_DMA_TRANS_INT_EN\t\tBIT(2)\n#define SPRD_DMA_LIST_INT_EN\t\tBIT(3)\n#define SPRD_DMA_CFG_ERR_INT_EN\t\tBIT(4)\n\n \n#define SPRD_DMA_CHN_EN\t\t\tBIT(0)\n#define SPRD_DMA_LINKLIST_EN\t\tBIT(4)\n#define SPRD_DMA_WAIT_BDONE_OFFSET\t24\n#define SPRD_DMA_DONOT_WAIT_BDONE\t1\n\n \n#define SPRD_DMA_REQ_EN\t\t\tBIT(0)\n\n \n#define SPRD_DMA_PAUSE_EN\t\tBIT(0)\n#define SPRD_DMA_PAUSE_STS\t\tBIT(2)\n#define SPRD_DMA_PAUSE_CNT\t\t0x2000\n\n \n#define SPRD_DMA_HIGH_ADDR_MASK\t\tGENMASK(31, 28)\n#define SPRD_DMA_LOW_ADDR_MASK\t\tGENMASK(31, 0)\n#define SPRD_DMA_WRAP_ADDR_MASK\t\tGENMASK(27, 0)\n#define SPRD_DMA_HIGH_ADDR_OFFSET\t4\n\n \n#define SPRD_DMA_FRAG_INT_STS\t\tBIT(16)\n#define SPRD_DMA_BLK_INT_STS\t\tBIT(17)\n#define SPRD_DMA_TRSC_INT_STS\t\tBIT(18)\n#define SPRD_DMA_LIST_INT_STS\t\tBIT(19)\n#define SPRD_DMA_CFGERR_INT_STS\t\tBIT(20)\n#define SPRD_DMA_CHN_INT_STS\t\t\t\t\t\\\n\t(SPRD_DMA_FRAG_INT_STS | SPRD_DMA_BLK_INT_STS |\t\t\\\n\t SPRD_DMA_TRSC_INT_STS | SPRD_DMA_LIST_INT_STS |\t\\\n\t SPRD_DMA_CFGERR_INT_STS)\n\n \n#define SPRD_DMA_SRC_DATAWIDTH_OFFSET\t30\n#define SPRD_DMA_DES_DATAWIDTH_OFFSET\t28\n#define SPRD_DMA_SWT_MODE_OFFSET\t26\n#define SPRD_DMA_REQ_MODE_OFFSET\t24\n#define SPRD_DMA_REQ_MODE_MASK\t\tGENMASK(1, 0)\n#define SPRD_DMA_WRAP_SEL_DEST\t\tBIT(23)\n#define SPRD_DMA_WRAP_EN\t\tBIT(22)\n#define SPRD_DMA_FIX_SEL_OFFSET\t\t21\n#define SPRD_DMA_FIX_EN_OFFSET\t\t20\n#define SPRD_DMA_LLIST_END\t\tBIT(19)\n#define SPRD_DMA_FRG_LEN_MASK\t\tGENMASK(16, 0)\n\n \n#define SPRD_DMA_BLK_LEN_MASK\t\tGENMASK(16, 0)\n\n \n#define SPRD_DMA_TRSC_LEN_MASK\t\tGENMASK(27, 0)\n\n \n#define SPRD_DMA_DEST_TRSF_STEP_OFFSET\t16\n#define SPRD_DMA_SRC_TRSF_STEP_OFFSET\t0\n#define SPRD_DMA_TRSF_STEP_MASK\t\tGENMASK(15, 0)\n\n \n#define SPRD_DMA_LLIST_HIGH_MASK\tGENMASK(31, 28)\n#define SPRD_DMA_LLIST_HIGH_SHIFT\t28\n\n \n#define SPRD_DMA_CHN_MODE_MASK\t\tGENMASK(7, 0)\n#define SPRD_DMA_TRG_MODE_MASK\t\tGENMASK(7, 0)\n#define SPRD_DMA_INT_TYPE_MASK\t\tGENMASK(7, 0)\n\n \n#define SPRD_DMA_NONE_STEP\t\t0\n#define SPRD_DMA_BYTE_STEP\t\t1\n#define SPRD_DMA_SHORT_STEP\t\t2\n#define SPRD_DMA_WORD_STEP\t\t4\n#define SPRD_DMA_DWORD_STEP\t\t8\n\n#define SPRD_DMA_SOFTWARE_UID\t\t0\n\n \nenum sprd_dma_datawidth {\n\tSPRD_DMA_DATAWIDTH_1_BYTE,\n\tSPRD_DMA_DATAWIDTH_2_BYTES,\n\tSPRD_DMA_DATAWIDTH_4_BYTES,\n\tSPRD_DMA_DATAWIDTH_8_BYTES,\n};\n\n \nstruct sprd_dma_chn_hw {\n\tu32 pause;\n\tu32 req;\n\tu32 cfg;\n\tu32 intc;\n\tu32 src_addr;\n\tu32 des_addr;\n\tu32 frg_len;\n\tu32 blk_len;\n\tu32 trsc_len;\n\tu32 trsf_step;\n\tu32 wrap_ptr;\n\tu32 wrap_to;\n\tu32 llist_ptr;\n\tu32 frg_step;\n\tu32 src_blk_step;\n\tu32 des_blk_step;\n};\n\n \nstruct sprd_dma_desc {\n\tstruct virt_dma_desc\tvd;\n\tstruct sprd_dma_chn_hw\tchn_hw;\n\tenum dma_transfer_direction dir;\n};\n\n \nstruct sprd_dma_chn {\n\tstruct virt_dma_chan\tvc;\n\tvoid __iomem\t\t*chn_base;\n\tstruct sprd_dma_linklist\tlinklist;\n\tstruct dma_slave_config\tslave_cfg;\n\tu32\t\t\tchn_num;\n\tu32\t\t\tdev_id;\n\tenum sprd_dma_chn_mode\tchn_mode;\n\tenum sprd_dma_trg_mode\ttrg_mode;\n\tenum sprd_dma_int_type\tint_type;\n\tstruct sprd_dma_desc\t*cur_desc;\n};\n\n \nstruct sprd_dma_dev {\n\tstruct dma_device\tdma_dev;\n\tvoid __iomem\t\t*glb_base;\n\tstruct clk\t\t*clk;\n\tstruct clk\t\t*ashb_clk;\n\tint\t\t\tirq;\n\tu32\t\t\ttotal_chns;\n\tstruct sprd_dma_chn\tchannels[];\n};\n\nstatic void sprd_dma_free_desc(struct virt_dma_desc *vd);\nstatic bool sprd_dma_filter_fn(struct dma_chan *chan, void *param);\nstatic struct of_dma_filter_info sprd_dma_info = {\n\t.filter_fn = sprd_dma_filter_fn,\n};\n\nstatic inline struct sprd_dma_chn *to_sprd_dma_chan(struct dma_chan *c)\n{\n\treturn container_of(c, struct sprd_dma_chn, vc.chan);\n}\n\nstatic inline struct sprd_dma_dev *to_sprd_dma_dev(struct dma_chan *c)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(c);\n\n\treturn container_of(schan, struct sprd_dma_dev, channels[c->chan_id]);\n}\n\nstatic inline struct sprd_dma_desc *to_sprd_dma_desc(struct virt_dma_desc *vd)\n{\n\treturn container_of(vd, struct sprd_dma_desc, vd);\n}\n\nstatic void sprd_dma_glb_update(struct sprd_dma_dev *sdev, u32 reg,\n\t\t\t\tu32 mask, u32 val)\n{\n\tu32 orig = readl(sdev->glb_base + reg);\n\tu32 tmp;\n\n\ttmp = (orig & ~mask) | val;\n\twritel(tmp, sdev->glb_base + reg);\n}\n\nstatic void sprd_dma_chn_update(struct sprd_dma_chn *schan, u32 reg,\n\t\t\t\tu32 mask, u32 val)\n{\n\tu32 orig = readl(schan->chn_base + reg);\n\tu32 tmp;\n\n\ttmp = (orig & ~mask) | val;\n\twritel(tmp, schan->chn_base + reg);\n}\n\nstatic int sprd_dma_enable(struct sprd_dma_dev *sdev)\n{\n\tint ret;\n\n\tret = clk_prepare_enable(sdev->clk);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (!IS_ERR(sdev->ashb_clk))\n\t\tret = clk_prepare_enable(sdev->ashb_clk);\n\n\treturn ret;\n}\n\nstatic void sprd_dma_disable(struct sprd_dma_dev *sdev)\n{\n\tclk_disable_unprepare(sdev->clk);\n\n\t \n\tif (!IS_ERR(sdev->ashb_clk))\n\t\tclk_disable_unprepare(sdev->ashb_clk);\n}\n\nstatic void sprd_dma_set_uid(struct sprd_dma_chn *schan)\n{\n\tstruct sprd_dma_dev *sdev = to_sprd_dma_dev(&schan->vc.chan);\n\tu32 dev_id = schan->dev_id;\n\n\tif (dev_id != SPRD_DMA_SOFTWARE_UID) {\n\t\tu32 uid_offset = SPRD_DMA_GLB_REQ_UID_OFFSET +\n\t\t\t\t SPRD_DMA_GLB_REQ_UID(dev_id);\n\n\t\twritel(schan->chn_num + 1, sdev->glb_base + uid_offset);\n\t}\n}\n\nstatic void sprd_dma_unset_uid(struct sprd_dma_chn *schan)\n{\n\tstruct sprd_dma_dev *sdev = to_sprd_dma_dev(&schan->vc.chan);\n\tu32 dev_id = schan->dev_id;\n\n\tif (dev_id != SPRD_DMA_SOFTWARE_UID) {\n\t\tu32 uid_offset = SPRD_DMA_GLB_REQ_UID_OFFSET +\n\t\t\t\t SPRD_DMA_GLB_REQ_UID(dev_id);\n\n\t\twritel(0, sdev->glb_base + uid_offset);\n\t}\n}\n\nstatic void sprd_dma_clear_int(struct sprd_dma_chn *schan)\n{\n\tsprd_dma_chn_update(schan, SPRD_DMA_CHN_INTC,\n\t\t\t    SPRD_DMA_INT_MASK << SPRD_DMA_INT_CLR_OFFSET,\n\t\t\t    SPRD_DMA_INT_MASK << SPRD_DMA_INT_CLR_OFFSET);\n}\n\nstatic void sprd_dma_enable_chn(struct sprd_dma_chn *schan)\n{\n\tsprd_dma_chn_update(schan, SPRD_DMA_CHN_CFG, SPRD_DMA_CHN_EN,\n\t\t\t    SPRD_DMA_CHN_EN);\n}\n\nstatic void sprd_dma_disable_chn(struct sprd_dma_chn *schan)\n{\n\tsprd_dma_chn_update(schan, SPRD_DMA_CHN_CFG, SPRD_DMA_CHN_EN, 0);\n}\n\nstatic void sprd_dma_soft_request(struct sprd_dma_chn *schan)\n{\n\tsprd_dma_chn_update(schan, SPRD_DMA_CHN_REQ, SPRD_DMA_REQ_EN,\n\t\t\t    SPRD_DMA_REQ_EN);\n}\n\nstatic void sprd_dma_pause_resume(struct sprd_dma_chn *schan, bool enable)\n{\n\tstruct sprd_dma_dev *sdev = to_sprd_dma_dev(&schan->vc.chan);\n\tu32 pause, timeout = SPRD_DMA_PAUSE_CNT;\n\n\tif (enable) {\n\t\tsprd_dma_chn_update(schan, SPRD_DMA_CHN_PAUSE,\n\t\t\t\t    SPRD_DMA_PAUSE_EN, SPRD_DMA_PAUSE_EN);\n\n\t\tdo {\n\t\t\tpause = readl(schan->chn_base + SPRD_DMA_CHN_PAUSE);\n\t\t\tif (pause & SPRD_DMA_PAUSE_STS)\n\t\t\t\tbreak;\n\n\t\t\tcpu_relax();\n\t\t} while (--timeout > 0);\n\n\t\tif (!timeout)\n\t\t\tdev_warn(sdev->dma_dev.dev,\n\t\t\t\t \"pause dma controller timeout\\n\");\n\t} else {\n\t\tsprd_dma_chn_update(schan, SPRD_DMA_CHN_PAUSE,\n\t\t\t\t    SPRD_DMA_PAUSE_EN, 0);\n\t}\n}\n\nstatic void sprd_dma_stop_and_disable(struct sprd_dma_chn *schan)\n{\n\tu32 cfg = readl(schan->chn_base + SPRD_DMA_CHN_CFG);\n\n\tif (!(cfg & SPRD_DMA_CHN_EN))\n\t\treturn;\n\n\tsprd_dma_pause_resume(schan, true);\n\tsprd_dma_disable_chn(schan);\n}\n\nstatic unsigned long sprd_dma_get_src_addr(struct sprd_dma_chn *schan)\n{\n\tunsigned long addr, addr_high;\n\n\taddr = readl(schan->chn_base + SPRD_DMA_CHN_SRC_ADDR);\n\taddr_high = readl(schan->chn_base + SPRD_DMA_CHN_WARP_PTR) &\n\t\t    SPRD_DMA_HIGH_ADDR_MASK;\n\n\treturn addr | (addr_high << SPRD_DMA_HIGH_ADDR_OFFSET);\n}\n\nstatic unsigned long sprd_dma_get_dst_addr(struct sprd_dma_chn *schan)\n{\n\tunsigned long addr, addr_high;\n\n\taddr = readl(schan->chn_base + SPRD_DMA_CHN_DES_ADDR);\n\taddr_high = readl(schan->chn_base + SPRD_DMA_CHN_WARP_TO) &\n\t\t    SPRD_DMA_HIGH_ADDR_MASK;\n\n\treturn addr | (addr_high << SPRD_DMA_HIGH_ADDR_OFFSET);\n}\n\nstatic enum sprd_dma_int_type sprd_dma_get_int_type(struct sprd_dma_chn *schan)\n{\n\tstruct sprd_dma_dev *sdev = to_sprd_dma_dev(&schan->vc.chan);\n\tu32 intc_sts = readl(schan->chn_base + SPRD_DMA_CHN_INTC) &\n\t\t       SPRD_DMA_CHN_INT_STS;\n\n\tswitch (intc_sts) {\n\tcase SPRD_DMA_CFGERR_INT_STS:\n\t\treturn SPRD_DMA_CFGERR_INT;\n\n\tcase SPRD_DMA_LIST_INT_STS:\n\t\treturn SPRD_DMA_LIST_INT;\n\n\tcase SPRD_DMA_TRSC_INT_STS:\n\t\treturn SPRD_DMA_TRANS_INT;\n\n\tcase SPRD_DMA_BLK_INT_STS:\n\t\treturn SPRD_DMA_BLK_INT;\n\n\tcase SPRD_DMA_FRAG_INT_STS:\n\t\treturn SPRD_DMA_FRAG_INT;\n\n\tdefault:\n\t\tdev_warn(sdev->dma_dev.dev, \"incorrect dma interrupt type\\n\");\n\t\treturn SPRD_DMA_NO_INT;\n\t}\n}\n\nstatic enum sprd_dma_req_mode sprd_dma_get_req_type(struct sprd_dma_chn *schan)\n{\n\tu32 frag_reg = readl(schan->chn_base + SPRD_DMA_CHN_FRG_LEN);\n\n\treturn (frag_reg >> SPRD_DMA_REQ_MODE_OFFSET) & SPRD_DMA_REQ_MODE_MASK;\n}\n\nstatic int sprd_dma_set_2stage_config(struct sprd_dma_chn *schan)\n{\n\tstruct sprd_dma_dev *sdev = to_sprd_dma_dev(&schan->vc.chan);\n\tu32 val, chn = schan->chn_num + 1;\n\n\tswitch (schan->chn_mode) {\n\tcase SPRD_DMA_SRC_CHN0:\n\t\tval = chn & SPRD_DMA_GLB_SRC_CHN_MASK;\n\t\tval |= BIT(schan->trg_mode - 1) << SPRD_DMA_GLB_TRG_OFFSET;\n\t\tval |= SPRD_DMA_GLB_2STAGE_EN;\n\t\tif (schan->int_type != SPRD_DMA_NO_INT)\n\t\t\tval |= SPRD_DMA_GLB_SRC_INT;\n\n\t\tsprd_dma_glb_update(sdev, SPRD_DMA_GLB_2STAGE_GRP1, val, val);\n\t\tbreak;\n\n\tcase SPRD_DMA_SRC_CHN1:\n\t\tval = chn & SPRD_DMA_GLB_SRC_CHN_MASK;\n\t\tval |= BIT(schan->trg_mode - 1) << SPRD_DMA_GLB_TRG_OFFSET;\n\t\tval |= SPRD_DMA_GLB_2STAGE_EN;\n\t\tif (schan->int_type != SPRD_DMA_NO_INT)\n\t\t\tval |= SPRD_DMA_GLB_SRC_INT;\n\n\t\tsprd_dma_glb_update(sdev, SPRD_DMA_GLB_2STAGE_GRP2, val, val);\n\t\tbreak;\n\n\tcase SPRD_DMA_DST_CHN0:\n\t\tval = (chn << SPRD_DMA_GLB_DEST_CHN_OFFSET) &\n\t\t\tSPRD_DMA_GLB_DEST_CHN_MASK;\n\t\tval |= SPRD_DMA_GLB_2STAGE_EN;\n\t\tif (schan->int_type != SPRD_DMA_NO_INT)\n\t\t\tval |= SPRD_DMA_GLB_DEST_INT;\n\n\t\tsprd_dma_glb_update(sdev, SPRD_DMA_GLB_2STAGE_GRP1, val, val);\n\t\tbreak;\n\n\tcase SPRD_DMA_DST_CHN1:\n\t\tval = (chn << SPRD_DMA_GLB_DEST_CHN_OFFSET) &\n\t\t\tSPRD_DMA_GLB_DEST_CHN_MASK;\n\t\tval |= SPRD_DMA_GLB_2STAGE_EN;\n\t\tif (schan->int_type != SPRD_DMA_NO_INT)\n\t\t\tval |= SPRD_DMA_GLB_DEST_INT;\n\n\t\tsprd_dma_glb_update(sdev, SPRD_DMA_GLB_2STAGE_GRP2, val, val);\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(sdev->dma_dev.dev, \"invalid channel mode setting %d\\n\",\n\t\t\tschan->chn_mode);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void sprd_dma_set_pending(struct sprd_dma_chn *schan, bool enable)\n{\n\tstruct sprd_dma_dev *sdev = to_sprd_dma_dev(&schan->vc.chan);\n\tu32 reg, val, req_id;\n\n\tif (schan->dev_id == SPRD_DMA_SOFTWARE_UID)\n\t\treturn;\n\n\t \n\treq_id = schan->dev_id - 1;\n\n\tif (req_id < 32) {\n\t\treg = SPRD_DMA_GLB_REQ_PEND0_EN;\n\t\tval = BIT(req_id);\n\t} else {\n\t\treg = SPRD_DMA_GLB_REQ_PEND1_EN;\n\t\tval = BIT(req_id - 32);\n\t}\n\n\tsprd_dma_glb_update(sdev, reg, val, enable ? val : 0);\n}\n\nstatic void sprd_dma_set_chn_config(struct sprd_dma_chn *schan,\n\t\t\t\t    struct sprd_dma_desc *sdesc)\n{\n\tstruct sprd_dma_chn_hw *cfg = &sdesc->chn_hw;\n\n\twritel(cfg->pause, schan->chn_base + SPRD_DMA_CHN_PAUSE);\n\twritel(cfg->cfg, schan->chn_base + SPRD_DMA_CHN_CFG);\n\twritel(cfg->intc, schan->chn_base + SPRD_DMA_CHN_INTC);\n\twritel(cfg->src_addr, schan->chn_base + SPRD_DMA_CHN_SRC_ADDR);\n\twritel(cfg->des_addr, schan->chn_base + SPRD_DMA_CHN_DES_ADDR);\n\twritel(cfg->frg_len, schan->chn_base + SPRD_DMA_CHN_FRG_LEN);\n\twritel(cfg->blk_len, schan->chn_base + SPRD_DMA_CHN_BLK_LEN);\n\twritel(cfg->trsc_len, schan->chn_base + SPRD_DMA_CHN_TRSC_LEN);\n\twritel(cfg->trsf_step, schan->chn_base + SPRD_DMA_CHN_TRSF_STEP);\n\twritel(cfg->wrap_ptr, schan->chn_base + SPRD_DMA_CHN_WARP_PTR);\n\twritel(cfg->wrap_to, schan->chn_base + SPRD_DMA_CHN_WARP_TO);\n\twritel(cfg->llist_ptr, schan->chn_base + SPRD_DMA_CHN_LLIST_PTR);\n\twritel(cfg->frg_step, schan->chn_base + SPRD_DMA_CHN_FRAG_STEP);\n\twritel(cfg->src_blk_step, schan->chn_base + SPRD_DMA_CHN_SRC_BLK_STEP);\n\twritel(cfg->des_blk_step, schan->chn_base + SPRD_DMA_CHN_DES_BLK_STEP);\n\twritel(cfg->req, schan->chn_base + SPRD_DMA_CHN_REQ);\n}\n\nstatic void sprd_dma_start(struct sprd_dma_chn *schan)\n{\n\tstruct virt_dma_desc *vd = vchan_next_desc(&schan->vc);\n\n\tif (!vd)\n\t\treturn;\n\n\tlist_del(&vd->node);\n\tschan->cur_desc = to_sprd_dma_desc(vd);\n\n\t \n\tif (schan->chn_mode && sprd_dma_set_2stage_config(schan))\n\t\treturn;\n\n\t \n\tsprd_dma_set_chn_config(schan, schan->cur_desc);\n\tsprd_dma_set_uid(schan);\n\tsprd_dma_set_pending(schan, true);\n\tsprd_dma_enable_chn(schan);\n\n\tif (schan->dev_id == SPRD_DMA_SOFTWARE_UID &&\n\t    schan->chn_mode != SPRD_DMA_DST_CHN0 &&\n\t    schan->chn_mode != SPRD_DMA_DST_CHN1)\n\t\tsprd_dma_soft_request(schan);\n}\n\nstatic void sprd_dma_stop(struct sprd_dma_chn *schan)\n{\n\tsprd_dma_stop_and_disable(schan);\n\tsprd_dma_set_pending(schan, false);\n\tsprd_dma_unset_uid(schan);\n\tsprd_dma_clear_int(schan);\n\tschan->cur_desc = NULL;\n}\n\nstatic bool sprd_dma_check_trans_done(struct sprd_dma_desc *sdesc,\n\t\t\t\t      enum sprd_dma_int_type int_type,\n\t\t\t\t      enum sprd_dma_req_mode req_mode)\n{\n\tif (int_type == SPRD_DMA_NO_INT)\n\t\treturn false;\n\n\tif (int_type >= req_mode + 1)\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\nstatic irqreturn_t dma_irq_handle(int irq, void *dev_id)\n{\n\tstruct sprd_dma_dev *sdev = (struct sprd_dma_dev *)dev_id;\n\tu32 irq_status = readl(sdev->glb_base + SPRD_DMA_GLB_INT_MSK_STS);\n\tstruct sprd_dma_chn *schan;\n\tstruct sprd_dma_desc *sdesc;\n\tenum sprd_dma_req_mode req_type;\n\tenum sprd_dma_int_type int_type;\n\tbool trans_done = false, cyclic = false;\n\tu32 i;\n\n\twhile (irq_status) {\n\t\ti = __ffs(irq_status);\n\t\tirq_status &= (irq_status - 1);\n\t\tschan = &sdev->channels[i];\n\n\t\tspin_lock(&schan->vc.lock);\n\n\t\tsdesc = schan->cur_desc;\n\t\tif (!sdesc) {\n\t\t\tspin_unlock(&schan->vc.lock);\n\t\t\treturn IRQ_HANDLED;\n\t\t}\n\n\t\tint_type = sprd_dma_get_int_type(schan);\n\t\treq_type = sprd_dma_get_req_type(schan);\n\t\tsprd_dma_clear_int(schan);\n\n\t\t \n\t\tcyclic = schan->linklist.phy_addr ? true : false;\n\t\tif (cyclic == true) {\n\t\t\tvchan_cyclic_callback(&sdesc->vd);\n\t\t} else {\n\t\t\t \n\t\t\ttrans_done = sprd_dma_check_trans_done(sdesc, int_type,\n\t\t\t\t\t\t\t       req_type);\n\t\t\tif (trans_done == true) {\n\t\t\t\tvchan_cookie_complete(&sdesc->vd);\n\t\t\t\tschan->cur_desc = NULL;\n\t\t\t\tsprd_dma_start(schan);\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&schan->vc.lock);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int sprd_dma_alloc_chan_resources(struct dma_chan *chan)\n{\n\treturn pm_runtime_get_sync(chan->device->dev);\n}\n\nstatic void sprd_dma_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tstruct virt_dma_desc *cur_vd = NULL;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&schan->vc.lock, flags);\n\tif (schan->cur_desc)\n\t\tcur_vd = &schan->cur_desc->vd;\n\n\tsprd_dma_stop(schan);\n\tspin_unlock_irqrestore(&schan->vc.lock, flags);\n\n\tif (cur_vd)\n\t\tsprd_dma_free_desc(cur_vd);\n\n\tvchan_free_chan_resources(&schan->vc);\n\tpm_runtime_put(chan->device->dev);\n}\n\nstatic enum dma_status sprd_dma_tx_status(struct dma_chan *chan,\n\t\t\t\t\t  dma_cookie_t cookie,\n\t\t\t\t\t  struct dma_tx_state *txstate)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tstruct virt_dma_desc *vd;\n\tunsigned long flags;\n\tenum dma_status ret;\n\tu32 pos;\n\n\tret = dma_cookie_status(chan, cookie, txstate);\n\tif (ret == DMA_COMPLETE || !txstate)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&schan->vc.lock, flags);\n\tvd = vchan_find_desc(&schan->vc, cookie);\n\tif (vd) {\n\t\tstruct sprd_dma_desc *sdesc = to_sprd_dma_desc(vd);\n\t\tstruct sprd_dma_chn_hw *hw = &sdesc->chn_hw;\n\n\t\tif (hw->trsc_len > 0)\n\t\t\tpos = hw->trsc_len;\n\t\telse if (hw->blk_len > 0)\n\t\t\tpos = hw->blk_len;\n\t\telse if (hw->frg_len > 0)\n\t\t\tpos = hw->frg_len;\n\t\telse\n\t\t\tpos = 0;\n\t} else if (schan->cur_desc && schan->cur_desc->vd.tx.cookie == cookie) {\n\t\tstruct sprd_dma_desc *sdesc = schan->cur_desc;\n\n\t\tif (sdesc->dir == DMA_DEV_TO_MEM)\n\t\t\tpos = sprd_dma_get_dst_addr(schan);\n\t\telse\n\t\t\tpos = sprd_dma_get_src_addr(schan);\n\t} else {\n\t\tpos = 0;\n\t}\n\tspin_unlock_irqrestore(&schan->vc.lock, flags);\n\n\tdma_set_residue(txstate, pos);\n\treturn ret;\n}\n\nstatic void sprd_dma_issue_pending(struct dma_chan *chan)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&schan->vc.lock, flags);\n\tif (vchan_issue_pending(&schan->vc) && !schan->cur_desc)\n\t\tsprd_dma_start(schan);\n\tspin_unlock_irqrestore(&schan->vc.lock, flags);\n}\n\nstatic int sprd_dma_get_datawidth(enum dma_slave_buswidth buswidth)\n{\n\tswitch (buswidth) {\n\tcase DMA_SLAVE_BUSWIDTH_1_BYTE:\n\tcase DMA_SLAVE_BUSWIDTH_2_BYTES:\n\tcase DMA_SLAVE_BUSWIDTH_4_BYTES:\n\tcase DMA_SLAVE_BUSWIDTH_8_BYTES:\n\t\treturn ffs(buswidth) - 1;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic int sprd_dma_get_step(enum dma_slave_buswidth buswidth)\n{\n\tswitch (buswidth) {\n\tcase DMA_SLAVE_BUSWIDTH_1_BYTE:\n\tcase DMA_SLAVE_BUSWIDTH_2_BYTES:\n\tcase DMA_SLAVE_BUSWIDTH_4_BYTES:\n\tcase DMA_SLAVE_BUSWIDTH_8_BYTES:\n\t\treturn buswidth;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic int sprd_dma_fill_desc(struct dma_chan *chan,\n\t\t\t      struct sprd_dma_chn_hw *hw,\n\t\t\t      unsigned int sglen, int sg_index,\n\t\t\t      dma_addr_t src, dma_addr_t dst, u32 len,\n\t\t\t      enum dma_transfer_direction dir,\n\t\t\t      unsigned long flags,\n\t\t\t      struct dma_slave_config *slave_cfg)\n{\n\tstruct sprd_dma_dev *sdev = to_sprd_dma_dev(chan);\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tenum sprd_dma_chn_mode chn_mode = schan->chn_mode;\n\tu32 req_mode = (flags >> SPRD_DMA_REQ_SHIFT) & SPRD_DMA_REQ_MODE_MASK;\n\tu32 int_mode = flags & SPRD_DMA_INT_MASK;\n\tint src_datawidth, dst_datawidth, src_step, dst_step;\n\tu32 temp, fix_mode = 0, fix_en = 0;\n\tphys_addr_t llist_ptr;\n\n\tif (dir == DMA_MEM_TO_DEV) {\n\t\tsrc_step = sprd_dma_get_step(slave_cfg->src_addr_width);\n\t\tif (src_step < 0) {\n\t\t\tdev_err(sdev->dma_dev.dev, \"invalid source step\\n\");\n\t\t\treturn src_step;\n\t\t}\n\n\t\t \n\t\tif (chn_mode == SPRD_DMA_DST_CHN0 ||\n\t\t    chn_mode == SPRD_DMA_DST_CHN1)\n\t\t\tdst_step = src_step;\n\t\telse\n\t\t\tdst_step = SPRD_DMA_NONE_STEP;\n\t} else {\n\t\tdst_step = sprd_dma_get_step(slave_cfg->dst_addr_width);\n\t\tif (dst_step < 0) {\n\t\t\tdev_err(sdev->dma_dev.dev, \"invalid destination step\\n\");\n\t\t\treturn dst_step;\n\t\t}\n\t\tsrc_step = SPRD_DMA_NONE_STEP;\n\t}\n\n\tsrc_datawidth = sprd_dma_get_datawidth(slave_cfg->src_addr_width);\n\tif (src_datawidth < 0) {\n\t\tdev_err(sdev->dma_dev.dev, \"invalid source datawidth\\n\");\n\t\treturn src_datawidth;\n\t}\n\n\tdst_datawidth = sprd_dma_get_datawidth(slave_cfg->dst_addr_width);\n\tif (dst_datawidth < 0) {\n\t\tdev_err(sdev->dma_dev.dev, \"invalid destination datawidth\\n\");\n\t\treturn dst_datawidth;\n\t}\n\n\thw->cfg = SPRD_DMA_DONOT_WAIT_BDONE << SPRD_DMA_WAIT_BDONE_OFFSET;\n\n\t \n\thw->wrap_ptr = (src >> SPRD_DMA_HIGH_ADDR_OFFSET) & SPRD_DMA_HIGH_ADDR_MASK;\n\thw->wrap_to = (dst >> SPRD_DMA_HIGH_ADDR_OFFSET) & SPRD_DMA_HIGH_ADDR_MASK;\n\thw->src_addr = src & SPRD_DMA_LOW_ADDR_MASK;\n\thw->des_addr = dst & SPRD_DMA_LOW_ADDR_MASK;\n\n\t \n\tif ((src_step != 0 && dst_step != 0) || (src_step | dst_step) == 0) {\n\t\tfix_en = 0;\n\t} else {\n\t\tfix_en = 1;\n\t\tif (src_step)\n\t\t\tfix_mode = 1;\n\t\telse\n\t\t\tfix_mode = 0;\n\t}\n\n\thw->intc = int_mode | SPRD_DMA_CFG_ERR_INT_EN;\n\n\ttemp = src_datawidth << SPRD_DMA_SRC_DATAWIDTH_OFFSET;\n\ttemp |= dst_datawidth << SPRD_DMA_DES_DATAWIDTH_OFFSET;\n\ttemp |= req_mode << SPRD_DMA_REQ_MODE_OFFSET;\n\ttemp |= fix_mode << SPRD_DMA_FIX_SEL_OFFSET;\n\ttemp |= fix_en << SPRD_DMA_FIX_EN_OFFSET;\n\ttemp |= schan->linklist.wrap_addr ?\n\t\tSPRD_DMA_WRAP_EN | SPRD_DMA_WRAP_SEL_DEST : 0;\n\ttemp |= slave_cfg->src_maxburst & SPRD_DMA_FRG_LEN_MASK;\n\thw->frg_len = temp;\n\n\thw->blk_len = slave_cfg->src_maxburst & SPRD_DMA_BLK_LEN_MASK;\n\thw->trsc_len = len & SPRD_DMA_TRSC_LEN_MASK;\n\n\ttemp = (dst_step & SPRD_DMA_TRSF_STEP_MASK) << SPRD_DMA_DEST_TRSF_STEP_OFFSET;\n\ttemp |= (src_step & SPRD_DMA_TRSF_STEP_MASK) << SPRD_DMA_SRC_TRSF_STEP_OFFSET;\n\thw->trsf_step = temp;\n\n\t \n\tif (schan->linklist.phy_addr) {\n\t\thw->cfg |= SPRD_DMA_LINKLIST_EN;\n\n\t\t \n\t\ttemp = sglen ? (sg_index + 1) % sglen : 0;\n\n\t\t \n\t\ttemp = temp * sizeof(*hw) + SPRD_DMA_CHN_SRC_ADDR;\n\t\t \n\t\tllist_ptr = schan->linklist.phy_addr + temp;\n\t\thw->llist_ptr = lower_32_bits(llist_ptr);\n\t\thw->src_blk_step = (upper_32_bits(llist_ptr) << SPRD_DMA_LLIST_HIGH_SHIFT) &\n\t\t\tSPRD_DMA_LLIST_HIGH_MASK;\n\n\t\tif (schan->linklist.wrap_addr) {\n\t\t\thw->wrap_ptr |= schan->linklist.wrap_addr &\n\t\t\t\tSPRD_DMA_WRAP_ADDR_MASK;\n\t\t\thw->wrap_to |= dst & SPRD_DMA_WRAP_ADDR_MASK;\n\t\t}\n\t} else {\n\t\thw->llist_ptr = 0;\n\t\thw->src_blk_step = 0;\n\t}\n\n\thw->frg_step = 0;\n\thw->des_blk_step = 0;\n\treturn 0;\n}\n\nstatic int sprd_dma_fill_linklist_desc(struct dma_chan *chan,\n\t\t\t\t       unsigned int sglen, int sg_index,\n\t\t\t\t       dma_addr_t src, dma_addr_t dst, u32 len,\n\t\t\t\t       enum dma_transfer_direction dir,\n\t\t\t\t       unsigned long flags,\n\t\t\t\t       struct dma_slave_config *slave_cfg)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tstruct sprd_dma_chn_hw *hw;\n\n\tif (!schan->linklist.virt_addr)\n\t\treturn -EINVAL;\n\n\thw = (struct sprd_dma_chn_hw *)(schan->linklist.virt_addr +\n\t\t\t\t\tsg_index * sizeof(*hw));\n\n\treturn sprd_dma_fill_desc(chan, hw, sglen, sg_index, src, dst, len,\n\t\t\t\t  dir, flags, slave_cfg);\n}\n\nstatic struct dma_async_tx_descriptor *\nsprd_dma_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest, dma_addr_t src,\n\t\t\t size_t len, unsigned long flags)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tstruct sprd_dma_desc *sdesc;\n\tstruct sprd_dma_chn_hw *hw;\n\tenum sprd_dma_datawidth datawidth;\n\tu32 step, temp;\n\n\tsdesc = kzalloc(sizeof(*sdesc), GFP_NOWAIT);\n\tif (!sdesc)\n\t\treturn NULL;\n\n\thw = &sdesc->chn_hw;\n\n\thw->cfg = SPRD_DMA_DONOT_WAIT_BDONE << SPRD_DMA_WAIT_BDONE_OFFSET;\n\thw->intc = SPRD_DMA_TRANS_INT | SPRD_DMA_CFG_ERR_INT_EN;\n\thw->src_addr = src & SPRD_DMA_LOW_ADDR_MASK;\n\thw->des_addr = dest & SPRD_DMA_LOW_ADDR_MASK;\n\thw->wrap_ptr = (src >> SPRD_DMA_HIGH_ADDR_OFFSET) &\n\t\tSPRD_DMA_HIGH_ADDR_MASK;\n\thw->wrap_to = (dest >> SPRD_DMA_HIGH_ADDR_OFFSET) &\n\t\tSPRD_DMA_HIGH_ADDR_MASK;\n\n\tif (IS_ALIGNED(len, 8)) {\n\t\tdatawidth = SPRD_DMA_DATAWIDTH_8_BYTES;\n\t\tstep = SPRD_DMA_DWORD_STEP;\n\t} else if (IS_ALIGNED(len, 4)) {\n\t\tdatawidth = SPRD_DMA_DATAWIDTH_4_BYTES;\n\t\tstep = SPRD_DMA_WORD_STEP;\n\t} else if (IS_ALIGNED(len, 2)) {\n\t\tdatawidth = SPRD_DMA_DATAWIDTH_2_BYTES;\n\t\tstep = SPRD_DMA_SHORT_STEP;\n\t} else {\n\t\tdatawidth = SPRD_DMA_DATAWIDTH_1_BYTE;\n\t\tstep = SPRD_DMA_BYTE_STEP;\n\t}\n\n\ttemp = datawidth << SPRD_DMA_SRC_DATAWIDTH_OFFSET;\n\ttemp |= datawidth << SPRD_DMA_DES_DATAWIDTH_OFFSET;\n\ttemp |= SPRD_DMA_TRANS_REQ << SPRD_DMA_REQ_MODE_OFFSET;\n\ttemp |= len & SPRD_DMA_FRG_LEN_MASK;\n\thw->frg_len = temp;\n\n\thw->blk_len = len & SPRD_DMA_BLK_LEN_MASK;\n\thw->trsc_len = len & SPRD_DMA_TRSC_LEN_MASK;\n\n\ttemp = (step & SPRD_DMA_TRSF_STEP_MASK) << SPRD_DMA_DEST_TRSF_STEP_OFFSET;\n\ttemp |= (step & SPRD_DMA_TRSF_STEP_MASK) << SPRD_DMA_SRC_TRSF_STEP_OFFSET;\n\thw->trsf_step = temp;\n\n\treturn vchan_tx_prep(&schan->vc, &sdesc->vd, flags);\n}\n\nstatic struct dma_async_tx_descriptor *\nsprd_dma_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,\n\t\t       unsigned int sglen, enum dma_transfer_direction dir,\n\t\t       unsigned long flags, void *context)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tstruct dma_slave_config *slave_cfg = &schan->slave_cfg;\n\tdma_addr_t src = 0, dst = 0;\n\tdma_addr_t start_src = 0, start_dst = 0;\n\tstruct sprd_dma_desc *sdesc;\n\tstruct scatterlist *sg;\n\tu32 len = 0;\n\tint ret, i;\n\n\tif (!is_slave_direction(dir))\n\t\treturn NULL;\n\n\tif (context) {\n\t\tstruct sprd_dma_linklist *ll_cfg =\n\t\t\t(struct sprd_dma_linklist *)context;\n\n\t\tschan->linklist.phy_addr = ll_cfg->phy_addr;\n\t\tschan->linklist.virt_addr = ll_cfg->virt_addr;\n\t\tschan->linklist.wrap_addr = ll_cfg->wrap_addr;\n\t} else {\n\t\tschan->linklist.phy_addr = 0;\n\t\tschan->linklist.virt_addr = 0;\n\t\tschan->linklist.wrap_addr = 0;\n\t}\n\n\t \n\tschan->chn_mode =\n\t\t(flags >> SPRD_DMA_CHN_MODE_SHIFT) & SPRD_DMA_CHN_MODE_MASK;\n\tschan->trg_mode =\n\t\t(flags >> SPRD_DMA_TRG_MODE_SHIFT) & SPRD_DMA_TRG_MODE_MASK;\n\tschan->int_type = flags & SPRD_DMA_INT_TYPE_MASK;\n\n\tsdesc = kzalloc(sizeof(*sdesc), GFP_NOWAIT);\n\tif (!sdesc)\n\t\treturn NULL;\n\n\tsdesc->dir = dir;\n\n\tfor_each_sg(sgl, sg, sglen, i) {\n\t\tlen = sg_dma_len(sg);\n\n\t\tif (dir == DMA_MEM_TO_DEV) {\n\t\t\tsrc = sg_dma_address(sg);\n\t\t\tdst = slave_cfg->dst_addr;\n\t\t} else {\n\t\t\tsrc = slave_cfg->src_addr;\n\t\t\tdst = sg_dma_address(sg);\n\t\t}\n\n\t\tif (!i) {\n\t\t\tstart_src = src;\n\t\t\tstart_dst = dst;\n\t\t}\n\n\t\t \n\t\tif (sglen < 2)\n\t\t\tbreak;\n\n\t\tret = sprd_dma_fill_linklist_desc(chan, sglen, i, src, dst, len,\n\t\t\t\t\t\t  dir, flags, slave_cfg);\n\t\tif (ret) {\n\t\t\tkfree(sdesc);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tret = sprd_dma_fill_desc(chan, &sdesc->chn_hw, 0, 0, start_src,\n\t\t\t\t start_dst, len, dir, flags, slave_cfg);\n\tif (ret) {\n\t\tkfree(sdesc);\n\t\treturn NULL;\n\t}\n\n\treturn vchan_tx_prep(&schan->vc, &sdesc->vd, flags);\n}\n\nstatic int sprd_dma_slave_config(struct dma_chan *chan,\n\t\t\t\t struct dma_slave_config *config)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tstruct dma_slave_config *slave_cfg = &schan->slave_cfg;\n\n\tmemcpy(slave_cfg, config, sizeof(*config));\n\treturn 0;\n}\n\nstatic int sprd_dma_pause(struct dma_chan *chan)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&schan->vc.lock, flags);\n\tsprd_dma_pause_resume(schan, true);\n\tspin_unlock_irqrestore(&schan->vc.lock, flags);\n\n\treturn 0;\n}\n\nstatic int sprd_dma_resume(struct dma_chan *chan)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&schan->vc.lock, flags);\n\tsprd_dma_pause_resume(schan, false);\n\tspin_unlock_irqrestore(&schan->vc.lock, flags);\n\n\treturn 0;\n}\n\nstatic int sprd_dma_terminate_all(struct dma_chan *chan)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tstruct virt_dma_desc *cur_vd = NULL;\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&schan->vc.lock, flags);\n\tif (schan->cur_desc)\n\t\tcur_vd = &schan->cur_desc->vd;\n\n\tsprd_dma_stop(schan);\n\n\tvchan_get_all_descriptors(&schan->vc, &head);\n\tspin_unlock_irqrestore(&schan->vc.lock, flags);\n\n\tif (cur_vd)\n\t\tsprd_dma_free_desc(cur_vd);\n\n\tvchan_dma_desc_free_list(&schan->vc, &head);\n\treturn 0;\n}\n\nstatic void sprd_dma_free_desc(struct virt_dma_desc *vd)\n{\n\tstruct sprd_dma_desc *sdesc = to_sprd_dma_desc(vd);\n\n\tkfree(sdesc);\n}\n\nstatic bool sprd_dma_filter_fn(struct dma_chan *chan, void *param)\n{\n\tstruct sprd_dma_chn *schan = to_sprd_dma_chan(chan);\n\tu32 slave_id = *(u32 *)param;\n\n\tschan->dev_id = slave_id;\n\treturn true;\n}\n\nstatic int sprd_dma_probe(struct platform_device *pdev)\n{\n\tstruct device_node *np = pdev->dev.of_node;\n\tstruct sprd_dma_dev *sdev;\n\tstruct sprd_dma_chn *dma_chn;\n\tu32 chn_count;\n\tint ret, i;\n\n\t \n\tret = device_property_read_u32(&pdev->dev, \"dma-channels\", &chn_count);\n\tif (ret)\n\t\tret = device_property_read_u32(&pdev->dev, \"#dma-channels\",\n\t\t\t\t\t       &chn_count);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"get dma channels count failed\\n\");\n\t\treturn ret;\n\t}\n\n\tsdev = devm_kzalloc(&pdev->dev,\n\t\t\t    struct_size(sdev, channels, chn_count),\n\t\t\t    GFP_KERNEL);\n\tif (!sdev)\n\t\treturn -ENOMEM;\n\n\tsdev->clk = devm_clk_get(&pdev->dev, \"enable\");\n\tif (IS_ERR(sdev->clk)) {\n\t\tdev_err(&pdev->dev, \"get enable clock failed\\n\");\n\t\treturn PTR_ERR(sdev->clk);\n\t}\n\n\t \n\tsdev->ashb_clk = devm_clk_get(&pdev->dev, \"ashb_eb\");\n\tif (IS_ERR(sdev->ashb_clk))\n\t\tdev_warn(&pdev->dev, \"no optional ashb eb clock\\n\");\n\n\t \n\tsdev->irq = platform_get_irq(pdev, 0);\n\tif (sdev->irq > 0) {\n\t\tret = devm_request_irq(&pdev->dev, sdev->irq, dma_irq_handle,\n\t\t\t\t       0, \"sprd_dma\", (void *)sdev);\n\t\tif (ret < 0) {\n\t\t\tdev_err(&pdev->dev, \"request dma irq failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t} else {\n\t\tdev_warn(&pdev->dev, \"no interrupts for the dma controller\\n\");\n\t}\n\n\tsdev->glb_base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(sdev->glb_base))\n\t\treturn PTR_ERR(sdev->glb_base);\n\n\tdma_cap_set(DMA_MEMCPY, sdev->dma_dev.cap_mask);\n\tsdev->total_chns = chn_count;\n\tINIT_LIST_HEAD(&sdev->dma_dev.channels);\n\tINIT_LIST_HEAD(&sdev->dma_dev.global_node);\n\tsdev->dma_dev.dev = &pdev->dev;\n\tsdev->dma_dev.device_alloc_chan_resources = sprd_dma_alloc_chan_resources;\n\tsdev->dma_dev.device_free_chan_resources = sprd_dma_free_chan_resources;\n\tsdev->dma_dev.device_tx_status = sprd_dma_tx_status;\n\tsdev->dma_dev.device_issue_pending = sprd_dma_issue_pending;\n\tsdev->dma_dev.device_prep_dma_memcpy = sprd_dma_prep_dma_memcpy;\n\tsdev->dma_dev.device_prep_slave_sg = sprd_dma_prep_slave_sg;\n\tsdev->dma_dev.device_config = sprd_dma_slave_config;\n\tsdev->dma_dev.device_pause = sprd_dma_pause;\n\tsdev->dma_dev.device_resume = sprd_dma_resume;\n\tsdev->dma_dev.device_terminate_all = sprd_dma_terminate_all;\n\n\tfor (i = 0; i < chn_count; i++) {\n\t\tdma_chn = &sdev->channels[i];\n\t\tdma_chn->chn_num = i;\n\t\tdma_chn->cur_desc = NULL;\n\t\t \n\t\tdma_chn->chn_base = sdev->glb_base + SPRD_DMA_CHN_REG_OFFSET +\n\t\t\t\t    SPRD_DMA_CHN_REG_LENGTH * i;\n\n\t\tdma_chn->vc.desc_free = sprd_dma_free_desc;\n\t\tvchan_init(&dma_chn->vc, &sdev->dma_dev);\n\t}\n\n\tplatform_set_drvdata(pdev, sdev);\n\tret = sprd_dma_enable(sdev);\n\tif (ret)\n\t\treturn ret;\n\n\tpm_runtime_set_active(&pdev->dev);\n\tpm_runtime_enable(&pdev->dev);\n\n\tret = pm_runtime_get_sync(&pdev->dev);\n\tif (ret < 0)\n\t\tgoto err_rpm;\n\n\tret = dma_async_device_register(&sdev->dma_dev);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"register dma device failed:%d\\n\", ret);\n\t\tgoto err_register;\n\t}\n\n\tsprd_dma_info.dma_cap = sdev->dma_dev.cap_mask;\n\tret = of_dma_controller_register(np, of_dma_simple_xlate,\n\t\t\t\t\t &sprd_dma_info);\n\tif (ret)\n\t\tgoto err_of_register;\n\n\tpm_runtime_put(&pdev->dev);\n\treturn 0;\n\nerr_of_register:\n\tdma_async_device_unregister(&sdev->dma_dev);\nerr_register:\n\tpm_runtime_put_noidle(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\nerr_rpm:\n\tsprd_dma_disable(sdev);\n\treturn ret;\n}\n\nstatic int sprd_dma_remove(struct platform_device *pdev)\n{\n\tstruct sprd_dma_dev *sdev = platform_get_drvdata(pdev);\n\tstruct sprd_dma_chn *c, *cn;\n\n\tpm_runtime_get_sync(&pdev->dev);\n\n\t \n\tif (sdev->irq > 0)\n\t\tdevm_free_irq(&pdev->dev, sdev->irq, sdev);\n\n\tlist_for_each_entry_safe(c, cn, &sdev->dma_dev.channels,\n\t\t\t\t vc.chan.device_node) {\n\t\tlist_del(&c->vc.chan.device_node);\n\t\ttasklet_kill(&c->vc.task);\n\t}\n\n\tof_dma_controller_free(pdev->dev.of_node);\n\tdma_async_device_unregister(&sdev->dma_dev);\n\tsprd_dma_disable(sdev);\n\n\tpm_runtime_put_noidle(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\treturn 0;\n}\n\nstatic const struct of_device_id sprd_dma_match[] = {\n\t{ .compatible = \"sprd,sc9860-dma\", },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, sprd_dma_match);\n\nstatic int __maybe_unused sprd_dma_runtime_suspend(struct device *dev)\n{\n\tstruct sprd_dma_dev *sdev = dev_get_drvdata(dev);\n\n\tsprd_dma_disable(sdev);\n\treturn 0;\n}\n\nstatic int __maybe_unused sprd_dma_runtime_resume(struct device *dev)\n{\n\tstruct sprd_dma_dev *sdev = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = sprd_dma_enable(sdev);\n\tif (ret)\n\t\tdev_err(sdev->dma_dev.dev, \"enable dma failed\\n\");\n\n\treturn ret;\n}\n\nstatic const struct dev_pm_ops sprd_dma_pm_ops = {\n\tSET_RUNTIME_PM_OPS(sprd_dma_runtime_suspend,\n\t\t\t   sprd_dma_runtime_resume,\n\t\t\t   NULL)\n};\n\nstatic struct platform_driver sprd_dma_driver = {\n\t.probe = sprd_dma_probe,\n\t.remove = sprd_dma_remove,\n\t.driver = {\n\t\t.name = \"sprd-dma\",\n\t\t.of_match_table = sprd_dma_match,\n\t\t.pm = &sprd_dma_pm_ops,\n\t},\n};\nmodule_platform_driver(sprd_dma_driver);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"DMA driver for Spreadtrum\");\nMODULE_AUTHOR(\"Baolin Wang <baolin.wang@spreadtrum.com>\");\nMODULE_AUTHOR(\"Eric Long <eric.long@spreadtrum.com>\");\nMODULE_ALIAS(\"platform:sprd-dma\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}