{
  "module_name": "uniphier-xdmac.c",
  "hash_id": "48e8466b04e73e2ba30b39d8adf1d49b41f52f40b3c6eccda9aa823bf81c57a5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/uniphier-xdmac.c",
  "human_readable_source": "\n \n\n#include <linux/bitops.h>\n#include <linux/bitfield.h>\n#include <linux/iopoll.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_dma.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n\n#include \"dmaengine.h\"\n#include \"virt-dma.h\"\n\n#define XDMAC_CH_WIDTH\t\t0x100\n\n#define XDMAC_TFA\t\t0x08\n#define XDMAC_TFA_MCNT_MASK\tGENMASK(23, 16)\n#define XDMAC_TFA_MASK\t\tGENMASK(5, 0)\n#define XDMAC_SADM\t\t0x10\n#define XDMAC_SADM_STW_MASK\tGENMASK(25, 24)\n#define XDMAC_SADM_SAM\t\tBIT(4)\n#define XDMAC_SADM_SAM_FIXED\tXDMAC_SADM_SAM\n#define XDMAC_SADM_SAM_INC\t0\n#define XDMAC_DADM\t\t0x14\n#define XDMAC_DADM_DTW_MASK\tXDMAC_SADM_STW_MASK\n#define XDMAC_DADM_DAM\t\tXDMAC_SADM_SAM\n#define XDMAC_DADM_DAM_FIXED\tXDMAC_SADM_SAM_FIXED\n#define XDMAC_DADM_DAM_INC\tXDMAC_SADM_SAM_INC\n#define XDMAC_EXSAD\t\t0x18\n#define XDMAC_EXDAD\t\t0x1c\n#define XDMAC_SAD\t\t0x20\n#define XDMAC_DAD\t\t0x24\n#define XDMAC_ITS\t\t0x28\n#define XDMAC_ITS_MASK\t\tGENMASK(25, 0)\n#define XDMAC_TNUM\t\t0x2c\n#define XDMAC_TNUM_MASK\t\tGENMASK(15, 0)\n#define XDMAC_TSS\t\t0x30\n#define XDMAC_TSS_REQ\t\tBIT(0)\n#define XDMAC_IEN\t\t0x34\n#define XDMAC_IEN_ERRIEN\tBIT(1)\n#define XDMAC_IEN_ENDIEN\tBIT(0)\n#define XDMAC_STAT\t\t0x40\n#define XDMAC_STAT_TENF\t\tBIT(0)\n#define XDMAC_IR\t\t0x44\n#define XDMAC_IR_ERRF\t\tBIT(1)\n#define XDMAC_IR_ENDF\t\tBIT(0)\n#define XDMAC_ID\t\t0x48\n#define XDMAC_ID_ERRIDF\t\tBIT(1)\n#define XDMAC_ID_ENDIDF\t\tBIT(0)\n\n#define XDMAC_MAX_CHANS\t\t16\n#define XDMAC_INTERVAL_CLKS\t20\n#define XDMAC_MAX_WORDS\t\tXDMAC_TNUM_MASK\n\n \n#define XDMAC_MAX_WORD_SIZE\t(XDMAC_ITS_MASK & ~GENMASK(3, 0))\n\n#define UNIPHIER_XDMAC_BUSWIDTHS \\\n\t(BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) | \\\n\t BIT(DMA_SLAVE_BUSWIDTH_2_BYTES) | \\\n\t BIT(DMA_SLAVE_BUSWIDTH_4_BYTES) | \\\n\t BIT(DMA_SLAVE_BUSWIDTH_8_BYTES))\n\nstruct uniphier_xdmac_desc_node {\n\tdma_addr_t src;\n\tdma_addr_t dst;\n\tu32 burst_size;\n\tu32 nr_burst;\n};\n\nstruct uniphier_xdmac_desc {\n\tstruct virt_dma_desc vd;\n\n\tunsigned int nr_node;\n\tunsigned int cur_node;\n\tenum dma_transfer_direction dir;\n\tstruct uniphier_xdmac_desc_node nodes[];\n};\n\nstruct uniphier_xdmac_chan {\n\tstruct virt_dma_chan vc;\n\tstruct uniphier_xdmac_device *xdev;\n\tstruct uniphier_xdmac_desc *xd;\n\tvoid __iomem *reg_ch_base;\n\tstruct dma_slave_config\tsconfig;\n\tint id;\n\tunsigned int req_factor;\n};\n\nstruct uniphier_xdmac_device {\n\tstruct dma_device ddev;\n\tvoid __iomem *reg_base;\n\tint nr_chans;\n\tstruct uniphier_xdmac_chan channels[];\n};\n\nstatic struct uniphier_xdmac_chan *\nto_uniphier_xdmac_chan(struct virt_dma_chan *vc)\n{\n\treturn container_of(vc, struct uniphier_xdmac_chan, vc);\n}\n\nstatic struct uniphier_xdmac_desc *\nto_uniphier_xdmac_desc(struct virt_dma_desc *vd)\n{\n\treturn container_of(vd, struct uniphier_xdmac_desc, vd);\n}\n\n \nstatic struct uniphier_xdmac_desc *\nuniphier_xdmac_next_desc(struct uniphier_xdmac_chan *xc)\n{\n\tstruct virt_dma_desc *vd;\n\n\tvd = vchan_next_desc(&xc->vc);\n\tif (!vd)\n\t\treturn NULL;\n\n\tlist_del(&vd->node);\n\n\treturn to_uniphier_xdmac_desc(vd);\n}\n\n \nstatic void uniphier_xdmac_chan_start(struct uniphier_xdmac_chan *xc,\n\t\t\t\t      struct uniphier_xdmac_desc *xd)\n{\n\tu32 src_mode, src_width;\n\tu32 dst_mode, dst_width;\n\tdma_addr_t src_addr, dst_addr;\n\tu32 val, its, tnum;\n\tenum dma_slave_buswidth buswidth;\n\n\tsrc_addr = xd->nodes[xd->cur_node].src;\n\tdst_addr = xd->nodes[xd->cur_node].dst;\n\tits      = xd->nodes[xd->cur_node].burst_size;\n\ttnum     = xd->nodes[xd->cur_node].nr_burst;\n\n\t \n\tif (xd->dir == DMA_DEV_TO_MEM) {\n\t\tsrc_mode = XDMAC_SADM_SAM_FIXED;\n\t\tbuswidth = xc->sconfig.src_addr_width;\n\t} else {\n\t\tsrc_mode = XDMAC_SADM_SAM_INC;\n\t\tbuswidth = DMA_SLAVE_BUSWIDTH_8_BYTES;\n\t}\n\tsrc_width = FIELD_PREP(XDMAC_SADM_STW_MASK, __ffs(buswidth));\n\n\tif (xd->dir == DMA_MEM_TO_DEV) {\n\t\tdst_mode = XDMAC_DADM_DAM_FIXED;\n\t\tbuswidth = xc->sconfig.dst_addr_width;\n\t} else {\n\t\tdst_mode = XDMAC_DADM_DAM_INC;\n\t\tbuswidth = DMA_SLAVE_BUSWIDTH_8_BYTES;\n\t}\n\tdst_width = FIELD_PREP(XDMAC_DADM_DTW_MASK, __ffs(buswidth));\n\n\t \n\tval = FIELD_PREP(XDMAC_TFA_MCNT_MASK, XDMAC_INTERVAL_CLKS);\n\tval |= FIELD_PREP(XDMAC_TFA_MASK, xc->req_factor);\n\twritel(val, xc->reg_ch_base + XDMAC_TFA);\n\n\t \n\twritel(lower_32_bits(src_addr), xc->reg_ch_base + XDMAC_SAD);\n\twritel(upper_32_bits(src_addr), xc->reg_ch_base + XDMAC_EXSAD);\n\n\twritel(lower_32_bits(dst_addr), xc->reg_ch_base + XDMAC_DAD);\n\twritel(upper_32_bits(dst_addr), xc->reg_ch_base + XDMAC_EXDAD);\n\n\tsrc_mode |= src_width;\n\tdst_mode |= dst_width;\n\twritel(src_mode, xc->reg_ch_base + XDMAC_SADM);\n\twritel(dst_mode, xc->reg_ch_base + XDMAC_DADM);\n\n\twritel(its, xc->reg_ch_base + XDMAC_ITS);\n\twritel(tnum, xc->reg_ch_base + XDMAC_TNUM);\n\n\t \n\twritel(XDMAC_IEN_ENDIEN | XDMAC_IEN_ERRIEN,\n\t       xc->reg_ch_base + XDMAC_IEN);\n\n\t \n\tval = readl(xc->reg_ch_base + XDMAC_TSS);\n\tval |= XDMAC_TSS_REQ;\n\twritel(val, xc->reg_ch_base + XDMAC_TSS);\n}\n\n \nstatic int uniphier_xdmac_chan_stop(struct uniphier_xdmac_chan *xc)\n{\n\tu32 val;\n\n\t \n\tval = readl(xc->reg_ch_base + XDMAC_IEN);\n\tval &= ~(XDMAC_IEN_ENDIEN | XDMAC_IEN_ERRIEN);\n\twritel(val, xc->reg_ch_base + XDMAC_IEN);\n\n\t \n\tval = readl(xc->reg_ch_base + XDMAC_TSS);\n\tval &= ~XDMAC_TSS_REQ;\n\twritel(0, xc->reg_ch_base + XDMAC_TSS);\n\n\t \n\treturn readl_poll_timeout_atomic(xc->reg_ch_base + XDMAC_STAT, val,\n\t\t\t\t\t !(val & XDMAC_STAT_TENF), 100, 1000);\n}\n\n \nstatic void uniphier_xdmac_start(struct uniphier_xdmac_chan *xc)\n{\n\tstruct uniphier_xdmac_desc *xd;\n\n\txd = uniphier_xdmac_next_desc(xc);\n\tif (xd)\n\t\tuniphier_xdmac_chan_start(xc, xd);\n\n\t \n\txc->xd = xd;\n}\n\nstatic void uniphier_xdmac_chan_irq(struct uniphier_xdmac_chan *xc)\n{\n\tu32 stat;\n\tint ret;\n\n\tspin_lock(&xc->vc.lock);\n\n\tstat = readl(xc->reg_ch_base + XDMAC_ID);\n\n\tif (stat & XDMAC_ID_ERRIDF) {\n\t\tret = uniphier_xdmac_chan_stop(xc);\n\t\tif (ret)\n\t\t\tdev_err(xc->xdev->ddev.dev,\n\t\t\t\t\"DMA transfer error with aborting issue\\n\");\n\t\telse\n\t\t\tdev_err(xc->xdev->ddev.dev,\n\t\t\t\t\"DMA transfer error\\n\");\n\n\t} else if ((stat & XDMAC_ID_ENDIDF) && xc->xd) {\n\t\txc->xd->cur_node++;\n\t\tif (xc->xd->cur_node >= xc->xd->nr_node) {\n\t\t\tvchan_cookie_complete(&xc->xd->vd);\n\t\t\tuniphier_xdmac_start(xc);\n\t\t} else {\n\t\t\tuniphier_xdmac_chan_start(xc, xc->xd);\n\t\t}\n\t}\n\n\t \n\twritel(stat, xc->reg_ch_base + XDMAC_IR);\n\n\tspin_unlock(&xc->vc.lock);\n}\n\nstatic irqreturn_t uniphier_xdmac_irq_handler(int irq, void *dev_id)\n{\n\tstruct uniphier_xdmac_device *xdev = dev_id;\n\tint i;\n\n\tfor (i = 0; i < xdev->nr_chans; i++)\n\t\tuniphier_xdmac_chan_irq(&xdev->channels[i]);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void uniphier_xdmac_free_chan_resources(struct dma_chan *chan)\n{\n\tvchan_free_chan_resources(to_virt_chan(chan));\n}\n\nstatic struct dma_async_tx_descriptor *\nuniphier_xdmac_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dst,\n\t\t\t       dma_addr_t src, size_t len, unsigned long flags)\n{\n\tstruct virt_dma_chan *vc = to_virt_chan(chan);\n\tstruct uniphier_xdmac_desc *xd;\n\tunsigned int nr;\n\tsize_t burst_size, tlen;\n\tint i;\n\n\tif (len > XDMAC_MAX_WORD_SIZE * XDMAC_MAX_WORDS)\n\t\treturn NULL;\n\n\tnr = 1 + len / XDMAC_MAX_WORD_SIZE;\n\n\txd = kzalloc(struct_size(xd, nodes, nr), GFP_NOWAIT);\n\tif (!xd)\n\t\treturn NULL;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tburst_size = min_t(size_t, len, XDMAC_MAX_WORD_SIZE);\n\t\txd->nodes[i].src = src;\n\t\txd->nodes[i].dst = dst;\n\t\txd->nodes[i].burst_size = burst_size;\n\t\txd->nodes[i].nr_burst = len / burst_size;\n\t\ttlen = rounddown(len, burst_size);\n\t\tsrc += tlen;\n\t\tdst += tlen;\n\t\tlen -= tlen;\n\t}\n\n\txd->dir = DMA_MEM_TO_MEM;\n\txd->nr_node = nr;\n\txd->cur_node = 0;\n\n\treturn vchan_tx_prep(vc, &xd->vd, flags);\n}\n\nstatic struct dma_async_tx_descriptor *\nuniphier_xdmac_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,\n\t\t\t     unsigned int sg_len,\n\t\t\t     enum dma_transfer_direction direction,\n\t\t\t     unsigned long flags, void *context)\n{\n\tstruct virt_dma_chan *vc = to_virt_chan(chan);\n\tstruct uniphier_xdmac_chan *xc = to_uniphier_xdmac_chan(vc);\n\tstruct uniphier_xdmac_desc *xd;\n\tstruct scatterlist *sg;\n\tenum dma_slave_buswidth buswidth;\n\tu32 maxburst;\n\tint i;\n\n\tif (!is_slave_direction(direction))\n\t\treturn NULL;\n\n\tif (direction == DMA_DEV_TO_MEM) {\n\t\tbuswidth = xc->sconfig.src_addr_width;\n\t\tmaxburst = xc->sconfig.src_maxburst;\n\t} else {\n\t\tbuswidth = xc->sconfig.dst_addr_width;\n\t\tmaxburst = xc->sconfig.dst_maxburst;\n\t}\n\n\tif (!maxburst)\n\t\tmaxburst = 1;\n\tif (maxburst > xc->xdev->ddev.max_burst) {\n\t\tdev_err(xc->xdev->ddev.dev,\n\t\t\t\"Exceed maximum number of burst words\\n\");\n\t\treturn NULL;\n\t}\n\n\txd = kzalloc(struct_size(xd, nodes, sg_len), GFP_NOWAIT);\n\tif (!xd)\n\t\treturn NULL;\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\txd->nodes[i].src = (direction == DMA_DEV_TO_MEM)\n\t\t\t? xc->sconfig.src_addr : sg_dma_address(sg);\n\t\txd->nodes[i].dst = (direction == DMA_MEM_TO_DEV)\n\t\t\t? xc->sconfig.dst_addr : sg_dma_address(sg);\n\t\txd->nodes[i].burst_size = maxburst * buswidth;\n\t\txd->nodes[i].nr_burst =\n\t\t\tsg_dma_len(sg) / xd->nodes[i].burst_size;\n\n\t\t \n\t\tif (sg_dma_len(sg) % xd->nodes[i].burst_size) {\n\t\t\tdev_err(xc->xdev->ddev.dev,\n\t\t\t\t\"Unaligned transfer size: %d\", sg_dma_len(sg));\n\t\t\tkfree(xd);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (xd->nodes[i].nr_burst > XDMAC_MAX_WORDS) {\n\t\t\tdev_err(xc->xdev->ddev.dev,\n\t\t\t\t\"Exceed maximum transfer size\");\n\t\t\tkfree(xd);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\txd->dir = direction;\n\txd->nr_node = sg_len;\n\txd->cur_node = 0;\n\n\treturn vchan_tx_prep(vc, &xd->vd, flags);\n}\n\nstatic int uniphier_xdmac_slave_config(struct dma_chan *chan,\n\t\t\t\t       struct dma_slave_config *config)\n{\n\tstruct virt_dma_chan *vc = to_virt_chan(chan);\n\tstruct uniphier_xdmac_chan *xc = to_uniphier_xdmac_chan(vc);\n\n\tmemcpy(&xc->sconfig, config, sizeof(*config));\n\n\treturn 0;\n}\n\nstatic int uniphier_xdmac_terminate_all(struct dma_chan *chan)\n{\n\tstruct virt_dma_chan *vc = to_virt_chan(chan);\n\tstruct uniphier_xdmac_chan *xc = to_uniphier_xdmac_chan(vc);\n\tunsigned long flags;\n\tint ret = 0;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&vc->lock, flags);\n\n\tif (xc->xd) {\n\t\tvchan_terminate_vdesc(&xc->xd->vd);\n\t\txc->xd = NULL;\n\t\tret = uniphier_xdmac_chan_stop(xc);\n\t}\n\n\tvchan_get_all_descriptors(vc, &head);\n\n\tspin_unlock_irqrestore(&vc->lock, flags);\n\n\tvchan_dma_desc_free_list(vc, &head);\n\n\treturn ret;\n}\n\nstatic void uniphier_xdmac_synchronize(struct dma_chan *chan)\n{\n\tvchan_synchronize(to_virt_chan(chan));\n}\n\nstatic void uniphier_xdmac_issue_pending(struct dma_chan *chan)\n{\n\tstruct virt_dma_chan *vc = to_virt_chan(chan);\n\tstruct uniphier_xdmac_chan *xc = to_uniphier_xdmac_chan(vc);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&vc->lock, flags);\n\n\tif (vchan_issue_pending(vc) && !xc->xd)\n\t\tuniphier_xdmac_start(xc);\n\n\tspin_unlock_irqrestore(&vc->lock, flags);\n}\n\nstatic void uniphier_xdmac_desc_free(struct virt_dma_desc *vd)\n{\n\tkfree(to_uniphier_xdmac_desc(vd));\n}\n\nstatic void uniphier_xdmac_chan_init(struct uniphier_xdmac_device *xdev,\n\t\t\t\t     int ch)\n{\n\tstruct uniphier_xdmac_chan *xc = &xdev->channels[ch];\n\n\txc->xdev = xdev;\n\txc->reg_ch_base = xdev->reg_base + XDMAC_CH_WIDTH * ch;\n\txc->vc.desc_free = uniphier_xdmac_desc_free;\n\n\tvchan_init(&xc->vc, &xdev->ddev);\n}\n\nstatic struct dma_chan *of_dma_uniphier_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t\t      struct of_dma *ofdma)\n{\n\tstruct uniphier_xdmac_device *xdev = ofdma->of_dma_data;\n\tint chan_id = dma_spec->args[0];\n\n\tif (chan_id >= xdev->nr_chans)\n\t\treturn NULL;\n\n\txdev->channels[chan_id].id = chan_id;\n\txdev->channels[chan_id].req_factor = dma_spec->args[1];\n\n\treturn dma_get_slave_channel(&xdev->channels[chan_id].vc.chan);\n}\n\nstatic int uniphier_xdmac_probe(struct platform_device *pdev)\n{\n\tstruct uniphier_xdmac_device *xdev;\n\tstruct device *dev = &pdev->dev;\n\tstruct dma_device *ddev;\n\tint irq;\n\tint nr_chans;\n\tint i, ret;\n\n\tif (of_property_read_u32(dev->of_node, \"dma-channels\", &nr_chans))\n\t\treturn -EINVAL;\n\tif (nr_chans > XDMAC_MAX_CHANS)\n\t\tnr_chans = XDMAC_MAX_CHANS;\n\n\txdev = devm_kzalloc(dev, struct_size(xdev, channels, nr_chans),\n\t\t\t    GFP_KERNEL);\n\tif (!xdev)\n\t\treturn -ENOMEM;\n\n\txdev->nr_chans = nr_chans;\n\txdev->reg_base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(xdev->reg_base))\n\t\treturn PTR_ERR(xdev->reg_base);\n\n\tddev = &xdev->ddev;\n\tddev->dev = dev;\n\tdma_cap_zero(ddev->cap_mask);\n\tdma_cap_set(DMA_MEMCPY, ddev->cap_mask);\n\tdma_cap_set(DMA_SLAVE, ddev->cap_mask);\n\tddev->src_addr_widths = UNIPHIER_XDMAC_BUSWIDTHS;\n\tddev->dst_addr_widths = UNIPHIER_XDMAC_BUSWIDTHS;\n\tddev->directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV) |\n\t\t\t   BIT(DMA_MEM_TO_MEM);\n\tddev->residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\tddev->max_burst = XDMAC_MAX_WORDS;\n\tddev->device_free_chan_resources = uniphier_xdmac_free_chan_resources;\n\tddev->device_prep_dma_memcpy = uniphier_xdmac_prep_dma_memcpy;\n\tddev->device_prep_slave_sg = uniphier_xdmac_prep_slave_sg;\n\tddev->device_config = uniphier_xdmac_slave_config;\n\tddev->device_terminate_all = uniphier_xdmac_terminate_all;\n\tddev->device_synchronize = uniphier_xdmac_synchronize;\n\tddev->device_tx_status = dma_cookie_status;\n\tddev->device_issue_pending = uniphier_xdmac_issue_pending;\n\tINIT_LIST_HEAD(&ddev->channels);\n\n\tfor (i = 0; i < nr_chans; i++)\n\t\tuniphier_xdmac_chan_init(xdev, i);\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tret = devm_request_irq(dev, irq, uniphier_xdmac_irq_handler,\n\t\t\t       IRQF_SHARED, \"xdmac\", xdev);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to request IRQ\\n\");\n\t\treturn ret;\n\t}\n\n\tret = dma_async_device_register(ddev);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to register XDMA device\\n\");\n\t\treturn ret;\n\t}\n\n\tret = of_dma_controller_register(dev->of_node,\n\t\t\t\t\t of_dma_uniphier_xlate, xdev);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to register XDMA controller\\n\");\n\t\tgoto out_unregister_dmac;\n\t}\n\n\tplatform_set_drvdata(pdev, xdev);\n\n\tdev_info(&pdev->dev, \"UniPhier XDMAC driver (%d channels)\\n\",\n\t\t nr_chans);\n\n\treturn 0;\n\nout_unregister_dmac:\n\tdma_async_device_unregister(ddev);\n\n\treturn ret;\n}\n\nstatic int uniphier_xdmac_remove(struct platform_device *pdev)\n{\n\tstruct uniphier_xdmac_device *xdev = platform_get_drvdata(pdev);\n\tstruct dma_device *ddev = &xdev->ddev;\n\tstruct dma_chan *chan;\n\tint ret;\n\n\t \n\tlist_for_each_entry(chan, &ddev->channels, device_node) {\n\t\tret = dmaengine_terminate_sync(chan);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tuniphier_xdmac_free_chan_resources(chan);\n\t}\n\n\tof_dma_controller_free(pdev->dev.of_node);\n\tdma_async_device_unregister(ddev);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id uniphier_xdmac_match[] = {\n\t{ .compatible = \"socionext,uniphier-xdmac\" },\n\t{   }\n};\nMODULE_DEVICE_TABLE(of, uniphier_xdmac_match);\n\nstatic struct platform_driver uniphier_xdmac_driver = {\n\t.probe = uniphier_xdmac_probe,\n\t.remove = uniphier_xdmac_remove,\n\t.driver = {\n\t\t.name = \"uniphier-xdmac\",\n\t\t.of_match_table = uniphier_xdmac_match,\n\t},\n};\nmodule_platform_driver(uniphier_xdmac_driver);\n\nMODULE_AUTHOR(\"Kunihiko Hayashi <hayashi.kunihiko@socionext.com>\");\nMODULE_DESCRIPTION(\"UniPhier external DMA controller driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}