{
  "module_name": "edma.c",
  "hash_id": "a6af5ab5f32b2783bd4a5873d016bee39aa771e97a2edee5b7279f7847b4c80f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/ti/edma.c",
  "human_readable_source": "\n \n\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/bitmap.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/of.h>\n#include <linux/of_dma.h>\n#include <linux/of_irq.h>\n#include <linux/of_address.h>\n#include <linux/pm_runtime.h>\n\n#include <linux/platform_data/edma.h>\n\n#include \"../dmaengine.h\"\n#include \"../virt-dma.h\"\n\n \n#define PARM_OPT\t\t0x00\n#define PARM_SRC\t\t0x04\n#define PARM_A_B_CNT\t\t0x08\n#define PARM_DST\t\t0x0c\n#define PARM_SRC_DST_BIDX\t0x10\n#define PARM_LINK_BCNTRLD\t0x14\n#define PARM_SRC_DST_CIDX\t0x18\n#define PARM_CCNT\t\t0x1c\n\n#define PARM_SIZE\t\t0x20\n\n \n#define SH_ER\t\t\t0x00\t \n#define SH_ECR\t\t\t0x08\t \n#define SH_ESR\t\t\t0x10\t \n#define SH_CER\t\t\t0x18\t \n#define SH_EER\t\t\t0x20\t \n#define SH_EECR\t\t\t0x28\t \n#define SH_EESR\t\t\t0x30\t \n#define SH_SER\t\t\t0x38\t \n#define SH_SECR\t\t\t0x40\t \n#define SH_IER\t\t\t0x50\t \n#define SH_IECR\t\t\t0x58\t \n#define SH_IESR\t\t\t0x60\t \n#define SH_IPR\t\t\t0x68\t \n#define SH_ICR\t\t\t0x70\t \n#define SH_IEVAL\t\t0x78\n#define SH_QER\t\t\t0x80\n#define SH_QEER\t\t\t0x84\n#define SH_QEECR\t\t0x88\n#define SH_QEESR\t\t0x8c\n#define SH_QSER\t\t\t0x90\n#define SH_QSECR\t\t0x94\n#define SH_SIZE\t\t\t0x200\n\n \n#define EDMA_REV\t\t0x0000\n#define EDMA_CCCFG\t\t0x0004\n#define EDMA_QCHMAP\t\t0x0200\t \n#define EDMA_DMAQNUM\t\t0x0240\t \n#define EDMA_QDMAQNUM\t\t0x0260\n#define EDMA_QUETCMAP\t\t0x0280\n#define EDMA_QUEPRI\t\t0x0284\n#define EDMA_EMR\t\t0x0300\t \n#define EDMA_EMCR\t\t0x0308\t \n#define EDMA_QEMR\t\t0x0310\n#define EDMA_QEMCR\t\t0x0314\n#define EDMA_CCERR\t\t0x0318\n#define EDMA_CCERRCLR\t\t0x031c\n#define EDMA_EEVAL\t\t0x0320\n#define EDMA_DRAE\t\t0x0340\t \n#define EDMA_QRAE\t\t0x0380\t \n#define EDMA_QUEEVTENTRY\t0x0400\t \n#define EDMA_QSTAT\t\t0x0600\t \n#define EDMA_QWMTHRA\t\t0x0620\n#define EDMA_QWMTHRB\t\t0x0624\n#define EDMA_CCSTAT\t\t0x0640\n\n#define EDMA_M\t\t\t0x1000\t \n#define EDMA_ECR\t\t0x1008\n#define EDMA_ECRH\t\t0x100C\n#define EDMA_SHADOW0\t\t0x2000\t \n#define EDMA_PARM\t\t0x4000\t \n\n#define PARM_OFFSET(param_no)\t(EDMA_PARM + ((param_no) << 5))\n\n#define EDMA_DCHMAP\t\t0x0100   \n\n \n#define GET_NUM_DMACH(x)\t(x & 0x7)  \n#define GET_NUM_QDMACH(x)\t((x & 0x70) >> 4)  \n#define GET_NUM_PAENTRY(x)\t((x & 0x7000) >> 12)  \n#define GET_NUM_EVQUE(x)\t((x & 0x70000) >> 16)  \n#define GET_NUM_REGN(x)\t\t((x & 0x300000) >> 20)  \n#define CHMAP_EXIST\t\tBIT(24)\n\n \n#define EDMA_CCSTAT_ACTV\tBIT(4)\n\n \n#define MAX_NR_SG\t\t20\n#define EDMA_MAX_SLOTS\t\tMAX_NR_SG\n#define EDMA_DESCRIPTORS\t16\n\n#define EDMA_CHANNEL_ANY\t\t-1\t \n#define EDMA_SLOT_ANY\t\t\t-1\t \n#define EDMA_CONT_PARAMS_ANY\t\t 1001\n#define EDMA_CONT_PARAMS_FIXED_EXACT\t 1002\n#define EDMA_CONT_PARAMS_FIXED_NOT_EXACT 1003\n\n \n#define EDMA_REG_ARRAY_INDEX(channel)\t((channel) >> 5)\n#define EDMA_CHANNEL_BIT(channel)\t(BIT((channel) & 0x1f))\n\n \nstruct edmacc_param {\n\tu32 opt;\n\tu32 src;\n\tu32 a_b_cnt;\n\tu32 dst;\n\tu32 src_dst_bidx;\n\tu32 link_bcntrld;\n\tu32 src_dst_cidx;\n\tu32 ccnt;\n} __packed;\n\n \n#define SAM\t\tBIT(0)\n#define DAM\t\tBIT(1)\n#define SYNCDIM\t\tBIT(2)\n#define STATIC\t\tBIT(3)\n#define EDMA_FWID\t(0x07 << 8)\n#define TCCMODE\t\tBIT(11)\n#define EDMA_TCC(t)\t((t) << 12)\n#define TCINTEN\t\tBIT(20)\n#define ITCINTEN\tBIT(21)\n#define TCCHEN\t\tBIT(22)\n#define ITCCHEN\t\tBIT(23)\n\nstruct edma_pset {\n\tu32\t\t\t\tlen;\n\tdma_addr_t\t\t\taddr;\n\tstruct edmacc_param\t\tparam;\n};\n\nstruct edma_desc {\n\tstruct virt_dma_desc\t\tvdesc;\n\tstruct list_head\t\tnode;\n\tenum dma_transfer_direction\tdirection;\n\tint\t\t\t\tcyclic;\n\tbool\t\t\t\tpolled;\n\tint\t\t\t\tabsync;\n\tint\t\t\t\tpset_nr;\n\tstruct edma_chan\t\t*echan;\n\tint\t\t\t\tprocessed;\n\n\t \n\tint\t\t\t\tprocessed_stat;\n\tu32\t\t\t\tsg_len;\n\tu32\t\t\t\tresidue;\n\tu32\t\t\t\tresidue_stat;\n\n\tstruct edma_pset\t\tpset[];\n};\n\nstruct edma_cc;\n\nstruct edma_tc {\n\tstruct device_node\t\t*node;\n\tu16\t\t\t\tid;\n};\n\nstruct edma_chan {\n\tstruct virt_dma_chan\t\tvchan;\n\tstruct list_head\t\tnode;\n\tstruct edma_desc\t\t*edesc;\n\tstruct edma_cc\t\t\t*ecc;\n\tstruct edma_tc\t\t\t*tc;\n\tint\t\t\t\tch_num;\n\tbool\t\t\t\talloced;\n\tbool\t\t\t\thw_triggered;\n\tint\t\t\t\tslot[EDMA_MAX_SLOTS];\n\tint\t\t\t\tmissed;\n\tstruct dma_slave_config\t\tcfg;\n};\n\nstruct edma_cc {\n\tstruct device\t\t\t*dev;\n\tstruct edma_soc_info\t\t*info;\n\tvoid __iomem\t\t\t*base;\n\tint\t\t\t\tid;\n\tbool\t\t\t\tlegacy_mode;\n\n\t \n\tunsigned\t\t\tnum_channels;\n\tunsigned\t\t\tnum_qchannels;\n\tunsigned\t\t\tnum_region;\n\tunsigned\t\t\tnum_slots;\n\tunsigned\t\t\tnum_tc;\n\tbool\t\t\t\tchmap_exist;\n\tenum dma_event_q\t\tdefault_queue;\n\n\tunsigned int\t\t\tccint;\n\tunsigned int\t\t\tccerrint;\n\n\t \n\tunsigned long *slot_inuse;\n\n\t \n\tunsigned long *channels_mask;\n\n\tstruct dma_device\t\tdma_slave;\n\tstruct dma_device\t\t*dma_memcpy;\n\tstruct edma_chan\t\t*slave_chans;\n\tstruct edma_tc\t\t\t*tc_list;\n\tint\t\t\t\tdummy_slot;\n};\n\n \nstatic const struct edmacc_param dummy_paramset = {\n\t.link_bcntrld = 0xffff,\n\t.ccnt = 1,\n};\n\n#define EDMA_BINDING_LEGACY\t0\n#define EDMA_BINDING_TPCC\t1\nstatic const u32 edma_binding_type[] = {\n\t[EDMA_BINDING_LEGACY] = EDMA_BINDING_LEGACY,\n\t[EDMA_BINDING_TPCC] = EDMA_BINDING_TPCC,\n};\n\nstatic const struct of_device_id edma_of_ids[] = {\n\t{\n\t\t.compatible = \"ti,edma3\",\n\t\t.data = &edma_binding_type[EDMA_BINDING_LEGACY],\n\t},\n\t{\n\t\t.compatible = \"ti,edma3-tpcc\",\n\t\t.data = &edma_binding_type[EDMA_BINDING_TPCC],\n\t},\n\t{}\n};\nMODULE_DEVICE_TABLE(of, edma_of_ids);\n\nstatic const struct of_device_id edma_tptc_of_ids[] = {\n\t{ .compatible = \"ti,edma3-tptc\", },\n\t{}\n};\nMODULE_DEVICE_TABLE(of, edma_tptc_of_ids);\n\nstatic inline unsigned int edma_read(struct edma_cc *ecc, int offset)\n{\n\treturn (unsigned int)__raw_readl(ecc->base + offset);\n}\n\nstatic inline void edma_write(struct edma_cc *ecc, int offset, int val)\n{\n\t__raw_writel(val, ecc->base + offset);\n}\n\nstatic inline void edma_modify(struct edma_cc *ecc, int offset, unsigned and,\n\t\t\t       unsigned or)\n{\n\tunsigned val = edma_read(ecc, offset);\n\n\tval &= and;\n\tval |= or;\n\tedma_write(ecc, offset, val);\n}\n\nstatic inline void edma_or(struct edma_cc *ecc, int offset, unsigned or)\n{\n\tunsigned val = edma_read(ecc, offset);\n\n\tval |= or;\n\tedma_write(ecc, offset, val);\n}\n\nstatic inline unsigned int edma_read_array(struct edma_cc *ecc, int offset,\n\t\t\t\t\t   int i)\n{\n\treturn edma_read(ecc, offset + (i << 2));\n}\n\nstatic inline void edma_write_array(struct edma_cc *ecc, int offset, int i,\n\t\t\t\t    unsigned val)\n{\n\tedma_write(ecc, offset + (i << 2), val);\n}\n\nstatic inline void edma_modify_array(struct edma_cc *ecc, int offset, int i,\n\t\t\t\t     unsigned and, unsigned or)\n{\n\tedma_modify(ecc, offset + (i << 2), and, or);\n}\n\nstatic inline void edma_or_array2(struct edma_cc *ecc, int offset, int i, int j,\n\t\t\t\t  unsigned or)\n{\n\tedma_or(ecc, offset + ((i * 2 + j) << 2), or);\n}\n\nstatic inline void edma_write_array2(struct edma_cc *ecc, int offset, int i,\n\t\t\t\t     int j, unsigned val)\n{\n\tedma_write(ecc, offset + ((i * 2 + j) << 2), val);\n}\n\nstatic inline unsigned int edma_shadow0_read_array(struct edma_cc *ecc,\n\t\t\t\t\t\t   int offset, int i)\n{\n\treturn edma_read(ecc, EDMA_SHADOW0 + offset + (i << 2));\n}\n\nstatic inline void edma_shadow0_write(struct edma_cc *ecc, int offset,\n\t\t\t\t      unsigned val)\n{\n\tedma_write(ecc, EDMA_SHADOW0 + offset, val);\n}\n\nstatic inline void edma_shadow0_write_array(struct edma_cc *ecc, int offset,\n\t\t\t\t\t    int i, unsigned val)\n{\n\tedma_write(ecc, EDMA_SHADOW0 + offset + (i << 2), val);\n}\n\nstatic inline void edma_param_modify(struct edma_cc *ecc, int offset,\n\t\t\t\t     int param_no, unsigned and, unsigned or)\n{\n\tedma_modify(ecc, EDMA_PARM + offset + (param_no << 5), and, or);\n}\n\nstatic void edma_assign_priority_to_queue(struct edma_cc *ecc, int queue_no,\n\t\t\t\t\t  int priority)\n{\n\tint bit = queue_no * 4;\n\n\tedma_modify(ecc, EDMA_QUEPRI, ~(0x7 << bit), ((priority & 0x7) << bit));\n}\n\nstatic void edma_set_chmap(struct edma_chan *echan, int slot)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\n\tif (ecc->chmap_exist) {\n\t\tslot = EDMA_CHAN_SLOT(slot);\n\t\tedma_write_array(ecc, EDMA_DCHMAP, channel, (slot << 5));\n\t}\n}\n\nstatic void edma_setup_interrupt(struct edma_chan *echan, bool enable)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\tint idx = EDMA_REG_ARRAY_INDEX(channel);\n\tint ch_bit = EDMA_CHANNEL_BIT(channel);\n\n\tif (enable) {\n\t\tedma_shadow0_write_array(ecc, SH_ICR, idx, ch_bit);\n\t\tedma_shadow0_write_array(ecc, SH_IESR, idx, ch_bit);\n\t} else {\n\t\tedma_shadow0_write_array(ecc, SH_IECR, idx, ch_bit);\n\t}\n}\n\n \nstatic void edma_write_slot(struct edma_cc *ecc, unsigned slot,\n\t\t\t    const struct edmacc_param *param)\n{\n\tslot = EDMA_CHAN_SLOT(slot);\n\tif (slot >= ecc->num_slots)\n\t\treturn;\n\tmemcpy_toio(ecc->base + PARM_OFFSET(slot), param, PARM_SIZE);\n}\n\nstatic int edma_read_slot(struct edma_cc *ecc, unsigned slot,\n\t\t\t   struct edmacc_param *param)\n{\n\tslot = EDMA_CHAN_SLOT(slot);\n\tif (slot >= ecc->num_slots)\n\t\treturn -EINVAL;\n\tmemcpy_fromio(param, ecc->base + PARM_OFFSET(slot), PARM_SIZE);\n\n\treturn 0;\n}\n\n \nstatic int edma_alloc_slot(struct edma_cc *ecc, int slot)\n{\n\tif (slot >= 0) {\n\t\tslot = EDMA_CHAN_SLOT(slot);\n\t\t \n\t\tif (ecc->chmap_exist && slot < ecc->num_channels)\n\t\t\tslot = EDMA_SLOT_ANY;\n\t}\n\n\tif (slot < 0) {\n\t\tif (ecc->chmap_exist)\n\t\t\tslot = 0;\n\t\telse\n\t\t\tslot = ecc->num_channels;\n\t\tfor (;;) {\n\t\t\tslot = find_next_zero_bit(ecc->slot_inuse,\n\t\t\t\t\t\t  ecc->num_slots,\n\t\t\t\t\t\t  slot);\n\t\t\tif (slot == ecc->num_slots)\n\t\t\t\treturn -ENOMEM;\n\t\t\tif (!test_and_set_bit(slot, ecc->slot_inuse))\n\t\t\t\tbreak;\n\t\t}\n\t} else if (slot >= ecc->num_slots) {\n\t\treturn -EINVAL;\n\t} else if (test_and_set_bit(slot, ecc->slot_inuse)) {\n\t\treturn -EBUSY;\n\t}\n\n\tedma_write_slot(ecc, slot, &dummy_paramset);\n\n\treturn EDMA_CTLR_CHAN(ecc->id, slot);\n}\n\nstatic void edma_free_slot(struct edma_cc *ecc, unsigned slot)\n{\n\tslot = EDMA_CHAN_SLOT(slot);\n\tif (slot >= ecc->num_slots)\n\t\treturn;\n\n\tedma_write_slot(ecc, slot, &dummy_paramset);\n\tclear_bit(slot, ecc->slot_inuse);\n}\n\n \nstatic void edma_link(struct edma_cc *ecc, unsigned from, unsigned to)\n{\n\tif (unlikely(EDMA_CTLR(from) != EDMA_CTLR(to)))\n\t\tdev_warn(ecc->dev, \"Ignoring eDMA instance for linking\\n\");\n\n\tfrom = EDMA_CHAN_SLOT(from);\n\tto = EDMA_CHAN_SLOT(to);\n\tif (from >= ecc->num_slots || to >= ecc->num_slots)\n\t\treturn;\n\n\tedma_param_modify(ecc, PARM_LINK_BCNTRLD, from, 0xffff0000,\n\t\t\t  PARM_OFFSET(to));\n}\n\n \nstatic dma_addr_t edma_get_position(struct edma_cc *ecc, unsigned slot,\n\t\t\t\t    bool dst)\n{\n\tu32 offs;\n\n\tslot = EDMA_CHAN_SLOT(slot);\n\toffs = PARM_OFFSET(slot);\n\toffs += dst ? PARM_DST : PARM_SRC;\n\n\treturn edma_read(ecc, offs);\n}\n\n \nstatic void edma_start(struct edma_chan *echan)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\tint idx = EDMA_REG_ARRAY_INDEX(channel);\n\tint ch_bit = EDMA_CHANNEL_BIT(channel);\n\n\tif (!echan->hw_triggered) {\n\t\t \n\t\tdev_dbg(ecc->dev, \"ESR%d %08x\\n\", idx,\n\t\t\tedma_shadow0_read_array(ecc, SH_ESR, idx));\n\t\tedma_shadow0_write_array(ecc, SH_ESR, idx, ch_bit);\n\t} else {\n\t\t \n\t\tdev_dbg(ecc->dev, \"ER%d %08x\\n\", idx,\n\t\t\tedma_shadow0_read_array(ecc, SH_ER, idx));\n\t\t \n\t\tedma_write_array(ecc, EDMA_ECR, idx, ch_bit);\n\t\tedma_write_array(ecc, EDMA_EMCR, idx, ch_bit);\n\t\t \n\t\tedma_shadow0_write_array(ecc, SH_SECR, idx, ch_bit);\n\t\tedma_shadow0_write_array(ecc, SH_EESR, idx, ch_bit);\n\t\tdev_dbg(ecc->dev, \"EER%d %08x\\n\", idx,\n\t\t\tedma_shadow0_read_array(ecc, SH_EER, idx));\n\t}\n}\n\nstatic void edma_stop(struct edma_chan *echan)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\tint idx = EDMA_REG_ARRAY_INDEX(channel);\n\tint ch_bit = EDMA_CHANNEL_BIT(channel);\n\n\tedma_shadow0_write_array(ecc, SH_EECR, idx, ch_bit);\n\tedma_shadow0_write_array(ecc, SH_ECR, idx, ch_bit);\n\tedma_shadow0_write_array(ecc, SH_SECR, idx, ch_bit);\n\tedma_write_array(ecc, EDMA_EMCR, idx, ch_bit);\n\n\t \n\tedma_shadow0_write_array(ecc, SH_ICR, idx, ch_bit);\n\n\tdev_dbg(ecc->dev, \"EER%d %08x\\n\", idx,\n\t\tedma_shadow0_read_array(ecc, SH_EER, idx));\n\n\t \n}\n\n \nstatic void edma_pause(struct edma_chan *echan)\n{\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\n\tedma_shadow0_write_array(echan->ecc, SH_EECR,\n\t\t\t\t EDMA_REG_ARRAY_INDEX(channel),\n\t\t\t\t EDMA_CHANNEL_BIT(channel));\n}\n\n \nstatic void edma_resume(struct edma_chan *echan)\n{\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\n\tedma_shadow0_write_array(echan->ecc, SH_EESR,\n\t\t\t\t EDMA_REG_ARRAY_INDEX(channel),\n\t\t\t\t EDMA_CHANNEL_BIT(channel));\n}\n\nstatic void edma_trigger_channel(struct edma_chan *echan)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\tint idx = EDMA_REG_ARRAY_INDEX(channel);\n\tint ch_bit = EDMA_CHANNEL_BIT(channel);\n\n\tedma_shadow0_write_array(ecc, SH_ESR, idx, ch_bit);\n\n\tdev_dbg(ecc->dev, \"ESR%d %08x\\n\", idx,\n\t\tedma_shadow0_read_array(ecc, SH_ESR, idx));\n}\n\nstatic void edma_clean_channel(struct edma_chan *echan)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\tint idx = EDMA_REG_ARRAY_INDEX(channel);\n\tint ch_bit = EDMA_CHANNEL_BIT(channel);\n\n\tdev_dbg(ecc->dev, \"EMR%d %08x\\n\", idx,\n\t\tedma_read_array(ecc, EDMA_EMR, idx));\n\tedma_shadow0_write_array(ecc, SH_ECR, idx, ch_bit);\n\t \n\tedma_write_array(ecc, EDMA_EMCR, idx, ch_bit);\n\t \n\tedma_shadow0_write_array(ecc, SH_SECR, idx, ch_bit);\n\tedma_write(ecc, EDMA_CCERRCLR, BIT(16) | BIT(1) | BIT(0));\n}\n\n \nstatic void edma_assign_channel_eventq(struct edma_chan *echan,\n\t\t\t\t       enum dma_event_q eventq_no)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\tint bit = (channel & 0x7) * 4;\n\n\t \n\tif (eventq_no == EVENTQ_DEFAULT)\n\t\teventq_no = ecc->default_queue;\n\tif (eventq_no >= ecc->num_tc)\n\t\treturn;\n\n\teventq_no &= 7;\n\tedma_modify_array(ecc, EDMA_DMAQNUM, (channel >> 3), ~(0x7 << bit),\n\t\t\t  eventq_no << bit);\n}\n\nstatic int edma_alloc_channel(struct edma_chan *echan,\n\t\t\t      enum dma_event_q eventq_no)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\n\tif (!test_bit(echan->ch_num, ecc->channels_mask)) {\n\t\tdev_err(ecc->dev, \"Channel%d is reserved, can not be used!\\n\",\n\t\t\techan->ch_num);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tedma_or_array2(ecc, EDMA_DRAE, 0, EDMA_REG_ARRAY_INDEX(channel),\n\t\t       EDMA_CHANNEL_BIT(channel));\n\n\t \n\tedma_stop(echan);\n\n\tedma_setup_interrupt(echan, true);\n\n\tedma_assign_channel_eventq(echan, eventq_no);\n\n\treturn 0;\n}\n\nstatic void edma_free_channel(struct edma_chan *echan)\n{\n\t \n\tedma_stop(echan);\n\t \n\tedma_setup_interrupt(echan, false);\n}\n\nstatic inline struct edma_chan *to_edma_chan(struct dma_chan *c)\n{\n\treturn container_of(c, struct edma_chan, vchan.chan);\n}\n\nstatic inline struct edma_desc *to_edma_desc(struct dma_async_tx_descriptor *tx)\n{\n\treturn container_of(tx, struct edma_desc, vdesc.tx);\n}\n\nstatic void edma_desc_free(struct virt_dma_desc *vdesc)\n{\n\tkfree(container_of(vdesc, struct edma_desc, vdesc));\n}\n\n \nstatic void edma_execute(struct edma_chan *echan)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tstruct virt_dma_desc *vdesc;\n\tstruct edma_desc *edesc;\n\tstruct device *dev = echan->vchan.chan.device->dev;\n\tint i, j, left, nslots;\n\n\tif (!echan->edesc) {\n\t\t \n\t\tvdesc = vchan_next_desc(&echan->vchan);\n\t\tif (!vdesc)\n\t\t\treturn;\n\t\tlist_del(&vdesc->node);\n\t\techan->edesc = to_edma_desc(&vdesc->tx);\n\t}\n\n\tedesc = echan->edesc;\n\n\t \n\tleft = edesc->pset_nr - edesc->processed;\n\tnslots = min(MAX_NR_SG, left);\n\tedesc->sg_len = 0;\n\n\t \n\tfor (i = 0; i < nslots; i++) {\n\t\tj = i + edesc->processed;\n\t\tedma_write_slot(ecc, echan->slot[i], &edesc->pset[j].param);\n\t\tedesc->sg_len += edesc->pset[j].len;\n\t\tdev_vdbg(dev,\n\t\t\t \"\\n pset[%d]:\\n\"\n\t\t\t \"  chnum\\t%d\\n\"\n\t\t\t \"  slot\\t%d\\n\"\n\t\t\t \"  opt\\t%08x\\n\"\n\t\t\t \"  src\\t%08x\\n\"\n\t\t\t \"  dst\\t%08x\\n\"\n\t\t\t \"  abcnt\\t%08x\\n\"\n\t\t\t \"  ccnt\\t%08x\\n\"\n\t\t\t \"  bidx\\t%08x\\n\"\n\t\t\t \"  cidx\\t%08x\\n\"\n\t\t\t \"  lkrld\\t%08x\\n\",\n\t\t\t j, echan->ch_num, echan->slot[i],\n\t\t\t edesc->pset[j].param.opt,\n\t\t\t edesc->pset[j].param.src,\n\t\t\t edesc->pset[j].param.dst,\n\t\t\t edesc->pset[j].param.a_b_cnt,\n\t\t\t edesc->pset[j].param.ccnt,\n\t\t\t edesc->pset[j].param.src_dst_bidx,\n\t\t\t edesc->pset[j].param.src_dst_cidx,\n\t\t\t edesc->pset[j].param.link_bcntrld);\n\t\t \n\t\tif (i != (nslots - 1))\n\t\t\tedma_link(ecc, echan->slot[i], echan->slot[i + 1]);\n\t}\n\n\tedesc->processed += nslots;\n\n\t \n\tif (edesc->processed == edesc->pset_nr) {\n\t\tif (edesc->cyclic)\n\t\t\tedma_link(ecc, echan->slot[nslots - 1], echan->slot[1]);\n\t\telse\n\t\t\tedma_link(ecc, echan->slot[nslots - 1],\n\t\t\t\t  echan->ecc->dummy_slot);\n\t}\n\n\tif (echan->missed) {\n\t\t \n\t\tdev_dbg(dev, \"missed event on channel %d\\n\", echan->ch_num);\n\t\tedma_clean_channel(echan);\n\t\tedma_stop(echan);\n\t\tedma_start(echan);\n\t\tedma_trigger_channel(echan);\n\t\techan->missed = 0;\n\t} else if (edesc->processed <= MAX_NR_SG) {\n\t\tdev_dbg(dev, \"first transfer starting on channel %d\\n\",\n\t\t\techan->ch_num);\n\t\tedma_start(echan);\n\t} else {\n\t\tdev_dbg(dev, \"chan: %d: completed %d elements, resuming\\n\",\n\t\t\techan->ch_num, edesc->processed);\n\t\tedma_resume(echan);\n\t}\n}\n\nstatic int edma_terminate_all(struct dma_chan *chan)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&echan->vchan.lock, flags);\n\n\t \n\tif (echan->edesc) {\n\t\tedma_stop(echan);\n\t\t \n\t\tif (!echan->tc && echan->edesc->cyclic)\n\t\t\tedma_assign_channel_eventq(echan, EVENTQ_DEFAULT);\n\n\t\tvchan_terminate_vdesc(&echan->edesc->vdesc);\n\t\techan->edesc = NULL;\n\t}\n\n\tvchan_get_all_descriptors(&echan->vchan, &head);\n\tspin_unlock_irqrestore(&echan->vchan.lock, flags);\n\tvchan_dma_desc_free_list(&echan->vchan, &head);\n\n\treturn 0;\n}\n\nstatic void edma_synchronize(struct dma_chan *chan)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\n\tvchan_synchronize(&echan->vchan);\n}\n\nstatic int edma_slave_config(struct dma_chan *chan,\n\tstruct dma_slave_config *cfg)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\n\tif (cfg->src_addr_width == DMA_SLAVE_BUSWIDTH_8_BYTES ||\n\t    cfg->dst_addr_width == DMA_SLAVE_BUSWIDTH_8_BYTES)\n\t\treturn -EINVAL;\n\n\tif (cfg->src_maxburst > chan->device->max_burst ||\n\t    cfg->dst_maxburst > chan->device->max_burst)\n\t\treturn -EINVAL;\n\n\tmemcpy(&echan->cfg, cfg, sizeof(echan->cfg));\n\n\treturn 0;\n}\n\nstatic int edma_dma_pause(struct dma_chan *chan)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\n\tif (!echan->edesc)\n\t\treturn -EINVAL;\n\n\tedma_pause(echan);\n\treturn 0;\n}\n\nstatic int edma_dma_resume(struct dma_chan *chan)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\n\tedma_resume(echan);\n\treturn 0;\n}\n\n \nstatic int edma_config_pset(struct dma_chan *chan, struct edma_pset *epset,\n\t\t\t    dma_addr_t src_addr, dma_addr_t dst_addr, u32 burst,\n\t\t\t    unsigned int acnt, unsigned int dma_length,\n\t\t\t    enum dma_transfer_direction direction)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tstruct device *dev = chan->device->dev;\n\tstruct edmacc_param *param = &epset->param;\n\tint bcnt, ccnt, cidx;\n\tint src_bidx, dst_bidx, src_cidx, dst_cidx;\n\tint absync;\n\n\t \n\tif (!burst)\n\t\tburst = 1;\n\t \n\tif (burst == 1) {\n\t\t \n\t\tabsync = false;\n\t\tccnt = dma_length / acnt / (SZ_64K - 1);\n\t\tbcnt = dma_length / acnt - ccnt * (SZ_64K - 1);\n\t\t \n\t\tif (bcnt)\n\t\t\tccnt++;\n\t\telse\n\t\t\tbcnt = SZ_64K - 1;\n\t\tcidx = acnt;\n\t} else {\n\t\t \n\t\tabsync = true;\n\t\tbcnt = burst;\n\t\tccnt = dma_length / (acnt * bcnt);\n\t\tif (ccnt > (SZ_64K - 1)) {\n\t\t\tdev_err(dev, \"Exceeded max SG segment size\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tcidx = acnt * bcnt;\n\t}\n\n\tepset->len = dma_length;\n\n\tif (direction == DMA_MEM_TO_DEV) {\n\t\tsrc_bidx = acnt;\n\t\tsrc_cidx = cidx;\n\t\tdst_bidx = 0;\n\t\tdst_cidx = 0;\n\t\tepset->addr = src_addr;\n\t} else if (direction == DMA_DEV_TO_MEM)  {\n\t\tsrc_bidx = 0;\n\t\tsrc_cidx = 0;\n\t\tdst_bidx = acnt;\n\t\tdst_cidx = cidx;\n\t\tepset->addr = dst_addr;\n\t} else if (direction == DMA_MEM_TO_MEM)  {\n\t\tsrc_bidx = acnt;\n\t\tsrc_cidx = cidx;\n\t\tdst_bidx = acnt;\n\t\tdst_cidx = cidx;\n\t\tepset->addr = src_addr;\n\t} else {\n\t\tdev_err(dev, \"%s: direction not implemented yet\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tparam->opt = EDMA_TCC(EDMA_CHAN_SLOT(echan->ch_num));\n\t \n\tif (absync)\n\t\tparam->opt |= SYNCDIM;\n\n\tparam->src = src_addr;\n\tparam->dst = dst_addr;\n\n\tparam->src_dst_bidx = (dst_bidx << 16) | src_bidx;\n\tparam->src_dst_cidx = (dst_cidx << 16) | src_cidx;\n\n\tparam->a_b_cnt = bcnt << 16 | acnt;\n\tparam->ccnt = ccnt;\n\t \n\tparam->link_bcntrld = 0xffffffff;\n\treturn absync;\n}\n\nstatic struct dma_async_tx_descriptor *edma_prep_slave_sg(\n\tstruct dma_chan *chan, struct scatterlist *sgl,\n\tunsigned int sg_len, enum dma_transfer_direction direction,\n\tunsigned long tx_flags, void *context)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tstruct device *dev = chan->device->dev;\n\tstruct edma_desc *edesc;\n\tdma_addr_t src_addr = 0, dst_addr = 0;\n\tenum dma_slave_buswidth dev_width;\n\tu32 burst;\n\tstruct scatterlist *sg;\n\tint i, nslots, ret;\n\n\tif (unlikely(!echan || !sgl || !sg_len))\n\t\treturn NULL;\n\n\tif (direction == DMA_DEV_TO_MEM) {\n\t\tsrc_addr = echan->cfg.src_addr;\n\t\tdev_width = echan->cfg.src_addr_width;\n\t\tburst = echan->cfg.src_maxburst;\n\t} else if (direction == DMA_MEM_TO_DEV) {\n\t\tdst_addr = echan->cfg.dst_addr;\n\t\tdev_width = echan->cfg.dst_addr_width;\n\t\tburst = echan->cfg.dst_maxburst;\n\t} else {\n\t\tdev_err(dev, \"%s: bad direction: %d\\n\", __func__, direction);\n\t\treturn NULL;\n\t}\n\n\tif (dev_width == DMA_SLAVE_BUSWIDTH_UNDEFINED) {\n\t\tdev_err(dev, \"%s: Undefined slave buswidth\\n\", __func__);\n\t\treturn NULL;\n\t}\n\n\tedesc = kzalloc(struct_size(edesc, pset, sg_len), GFP_ATOMIC);\n\tif (!edesc)\n\t\treturn NULL;\n\n\tedesc->pset_nr = sg_len;\n\tedesc->residue = 0;\n\tedesc->direction = direction;\n\tedesc->echan = echan;\n\n\t \n\tnslots = min_t(unsigned, MAX_NR_SG, sg_len);\n\n\tfor (i = 0; i < nslots; i++) {\n\t\tif (echan->slot[i] < 0) {\n\t\t\techan->slot[i] =\n\t\t\t\tedma_alloc_slot(echan->ecc, EDMA_SLOT_ANY);\n\t\t\tif (echan->slot[i] < 0) {\n\t\t\t\tkfree(edesc);\n\t\t\t\tdev_err(dev, \"%s: Failed to allocate slot\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\t \n\t\tif (direction == DMA_DEV_TO_MEM)\n\t\t\tdst_addr = sg_dma_address(sg);\n\t\telse\n\t\t\tsrc_addr = sg_dma_address(sg);\n\n\t\tret = edma_config_pset(chan, &edesc->pset[i], src_addr,\n\t\t\t\t       dst_addr, burst, dev_width,\n\t\t\t\t       sg_dma_len(sg), direction);\n\t\tif (ret < 0) {\n\t\t\tkfree(edesc);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tedesc->absync = ret;\n\t\tedesc->residue += sg_dma_len(sg);\n\n\t\tif (i == sg_len - 1)\n\t\t\t \n\t\t\tedesc->pset[i].param.opt |= TCINTEN;\n\t\telse if (!((i+1) % MAX_NR_SG))\n\t\t\t \n\t\t\tedesc->pset[i].param.opt |= (TCINTEN | TCCMODE);\n\t}\n\tedesc->residue_stat = edesc->residue;\n\n\treturn vchan_tx_prep(&echan->vchan, &edesc->vdesc, tx_flags);\n}\n\nstatic struct dma_async_tx_descriptor *edma_prep_dma_memcpy(\n\tstruct dma_chan *chan, dma_addr_t dest, dma_addr_t src,\n\tsize_t len, unsigned long tx_flags)\n{\n\tint ret, nslots;\n\tstruct edma_desc *edesc;\n\tstruct device *dev = chan->device->dev;\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tunsigned int width, pset_len, array_size;\n\n\tif (unlikely(!echan || !len))\n\t\treturn NULL;\n\n\t \n\tswitch (__ffs((src | dest | len))) {\n\tcase 0:\n\t\tarray_size = SZ_32K - 1;\n\t\tbreak;\n\tcase 1:\n\t\tarray_size = SZ_32K - 2;\n\t\tbreak;\n\tdefault:\n\t\tarray_size = SZ_32K - 4;\n\t\tbreak;\n\t}\n\n\tif (len < SZ_64K) {\n\t\t \n\t\twidth = len;\n\t\tpset_len = len;\n\t\tnslots = 1;\n\t} else {\n\t\t \n\t\twidth = array_size;\n\t\tpset_len = rounddown(len, width);\n\t\t \n\t\tif (unlikely(pset_len == len))\n\t\t\tnslots = 1;\n\t\telse\n\t\t\tnslots = 2;\n\t}\n\n\tedesc = kzalloc(struct_size(edesc, pset, nslots), GFP_ATOMIC);\n\tif (!edesc)\n\t\treturn NULL;\n\n\tedesc->pset_nr = nslots;\n\tedesc->residue = edesc->residue_stat = len;\n\tedesc->direction = DMA_MEM_TO_MEM;\n\tedesc->echan = echan;\n\n\tret = edma_config_pset(chan, &edesc->pset[0], src, dest, 1,\n\t\t\t       width, pset_len, DMA_MEM_TO_MEM);\n\tif (ret < 0) {\n\t\tkfree(edesc);\n\t\treturn NULL;\n\t}\n\n\tedesc->absync = ret;\n\n\tedesc->pset[0].param.opt |= ITCCHEN;\n\tif (nslots == 1) {\n\t\t \n\t\tif (tx_flags & DMA_PREP_INTERRUPT)\n\t\t\tedesc->pset[0].param.opt |= TCINTEN;\n\t} else {\n\t\t \n\t\tedesc->pset[0].param.opt |= TCCHEN;\n\n\t\tif (echan->slot[1] < 0) {\n\t\t\techan->slot[1] = edma_alloc_slot(echan->ecc,\n\t\t\t\t\t\t\t EDMA_SLOT_ANY);\n\t\t\tif (echan->slot[1] < 0) {\n\t\t\t\tkfree(edesc);\n\t\t\t\tdev_err(dev, \"%s: Failed to allocate slot\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t}\n\t\tdest += pset_len;\n\t\tsrc += pset_len;\n\t\tpset_len = width = len % array_size;\n\n\t\tret = edma_config_pset(chan, &edesc->pset[1], src, dest, 1,\n\t\t\t\t       width, pset_len, DMA_MEM_TO_MEM);\n\t\tif (ret < 0) {\n\t\t\tkfree(edesc);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tedesc->pset[1].param.opt |= ITCCHEN;\n\t\t \n\t\tif (tx_flags & DMA_PREP_INTERRUPT)\n\t\t\tedesc->pset[1].param.opt |= TCINTEN;\n\t}\n\n\tif (!(tx_flags & DMA_PREP_INTERRUPT))\n\t\tedesc->polled = true;\n\n\treturn vchan_tx_prep(&echan->vchan, &edesc->vdesc, tx_flags);\n}\n\nstatic struct dma_async_tx_descriptor *\nedma_prep_dma_interleaved(struct dma_chan *chan,\n\t\t\t  struct dma_interleaved_template *xt,\n\t\t\t  unsigned long tx_flags)\n{\n\tstruct device *dev = chan->device->dev;\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tstruct edmacc_param *param;\n\tstruct edma_desc *edesc;\n\tsize_t src_icg, dst_icg;\n\tint src_bidx, dst_bidx;\n\n\t \n\tif (is_slave_direction(xt->dir))\n\t\treturn NULL;\n\n\tif (xt->frame_size != 1 || xt->numf == 0)\n\t\treturn NULL;\n\n\tif (xt->sgl[0].size > SZ_64K || xt->numf > SZ_64K)\n\t\treturn NULL;\n\n\tsrc_icg = dmaengine_get_src_icg(xt, &xt->sgl[0]);\n\tif (src_icg) {\n\t\tsrc_bidx = src_icg + xt->sgl[0].size;\n\t} else if (xt->src_inc) {\n\t\tsrc_bidx = xt->sgl[0].size;\n\t} else {\n\t\tdev_err(dev, \"%s: SRC constant addressing is not supported\\n\",\n\t\t\t__func__);\n\t\treturn NULL;\n\t}\n\n\tdst_icg = dmaengine_get_dst_icg(xt, &xt->sgl[0]);\n\tif (dst_icg) {\n\t\tdst_bidx = dst_icg + xt->sgl[0].size;\n\t} else if (xt->dst_inc) {\n\t\tdst_bidx = xt->sgl[0].size;\n\t} else {\n\t\tdev_err(dev, \"%s: DST constant addressing is not supported\\n\",\n\t\t\t__func__);\n\t\treturn NULL;\n\t}\n\n\tif (src_bidx > SZ_64K || dst_bidx > SZ_64K)\n\t\treturn NULL;\n\n\tedesc = kzalloc(struct_size(edesc, pset, 1), GFP_ATOMIC);\n\tif (!edesc)\n\t\treturn NULL;\n\n\tedesc->direction = DMA_MEM_TO_MEM;\n\tedesc->echan = echan;\n\tedesc->pset_nr = 1;\n\n\tparam = &edesc->pset[0].param;\n\n\tparam->src = xt->src_start;\n\tparam->dst = xt->dst_start;\n\tparam->a_b_cnt = xt->numf << 16 | xt->sgl[0].size;\n\tparam->ccnt = 1;\n\tparam->src_dst_bidx = (dst_bidx << 16) | src_bidx;\n\tparam->src_dst_cidx = 0;\n\n\tparam->opt = EDMA_TCC(EDMA_CHAN_SLOT(echan->ch_num));\n\tparam->opt |= ITCCHEN;\n\t \n\tif (tx_flags & DMA_PREP_INTERRUPT)\n\t\tparam->opt |= TCINTEN;\n\telse\n\t\tedesc->polled = true;\n\n\treturn vchan_tx_prep(&echan->vchan, &edesc->vdesc, tx_flags);\n}\n\nstatic struct dma_async_tx_descriptor *edma_prep_dma_cyclic(\n\tstruct dma_chan *chan, dma_addr_t buf_addr, size_t buf_len,\n\tsize_t period_len, enum dma_transfer_direction direction,\n\tunsigned long tx_flags)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tstruct device *dev = chan->device->dev;\n\tstruct edma_desc *edesc;\n\tdma_addr_t src_addr, dst_addr;\n\tenum dma_slave_buswidth dev_width;\n\tbool use_intermediate = false;\n\tu32 burst;\n\tint i, ret, nslots;\n\n\tif (unlikely(!echan || !buf_len || !period_len))\n\t\treturn NULL;\n\n\tif (direction == DMA_DEV_TO_MEM) {\n\t\tsrc_addr = echan->cfg.src_addr;\n\t\tdst_addr = buf_addr;\n\t\tdev_width = echan->cfg.src_addr_width;\n\t\tburst = echan->cfg.src_maxburst;\n\t} else if (direction == DMA_MEM_TO_DEV) {\n\t\tsrc_addr = buf_addr;\n\t\tdst_addr = echan->cfg.dst_addr;\n\t\tdev_width = echan->cfg.dst_addr_width;\n\t\tburst = echan->cfg.dst_maxburst;\n\t} else {\n\t\tdev_err(dev, \"%s: bad direction: %d\\n\", __func__, direction);\n\t\treturn NULL;\n\t}\n\n\tif (dev_width == DMA_SLAVE_BUSWIDTH_UNDEFINED) {\n\t\tdev_err(dev, \"%s: Undefined slave buswidth\\n\", __func__);\n\t\treturn NULL;\n\t}\n\n\tif (unlikely(buf_len % period_len)) {\n\t\tdev_err(dev, \"Period should be multiple of Buffer length\\n\");\n\t\treturn NULL;\n\t}\n\n\tnslots = (buf_len / period_len) + 1;\n\n\t \n\tif (nslots > MAX_NR_SG) {\n\t\t \n\t\tif (burst == period_len) {\n\t\t\tperiod_len = buf_len;\n\t\t\tnslots = 2;\n\t\t\tuse_intermediate = true;\n\t\t} else {\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tedesc = kzalloc(struct_size(edesc, pset, nslots), GFP_ATOMIC);\n\tif (!edesc)\n\t\treturn NULL;\n\n\tedesc->cyclic = 1;\n\tedesc->pset_nr = nslots;\n\tedesc->residue = edesc->residue_stat = buf_len;\n\tedesc->direction = direction;\n\tedesc->echan = echan;\n\n\tdev_dbg(dev, \"%s: channel=%d nslots=%d period_len=%zu buf_len=%zu\\n\",\n\t\t__func__, echan->ch_num, nslots, period_len, buf_len);\n\n\tfor (i = 0; i < nslots; i++) {\n\t\t \n\t\tif (echan->slot[i] < 0) {\n\t\t\techan->slot[i] =\n\t\t\t\tedma_alloc_slot(echan->ecc, EDMA_SLOT_ANY);\n\t\t\tif (echan->slot[i] < 0) {\n\t\t\t\tkfree(edesc);\n\t\t\t\tdev_err(dev, \"%s: Failed to allocate slot\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t}\n\n\t\tif (i == nslots - 1) {\n\t\t\tmemcpy(&edesc->pset[i], &edesc->pset[0],\n\t\t\t       sizeof(edesc->pset[0]));\n\t\t\tbreak;\n\t\t}\n\n\t\tret = edma_config_pset(chan, &edesc->pset[i], src_addr,\n\t\t\t\t       dst_addr, burst, dev_width, period_len,\n\t\t\t\t       direction);\n\t\tif (ret < 0) {\n\t\t\tkfree(edesc);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (direction == DMA_DEV_TO_MEM)\n\t\t\tdst_addr += period_len;\n\t\telse\n\t\t\tsrc_addr += period_len;\n\n\t\tdev_vdbg(dev, \"%s: Configure period %d of buf:\\n\", __func__, i);\n\t\tdev_vdbg(dev,\n\t\t\t\"\\n pset[%d]:\\n\"\n\t\t\t\"  chnum\\t%d\\n\"\n\t\t\t\"  slot\\t%d\\n\"\n\t\t\t\"  opt\\t%08x\\n\"\n\t\t\t\"  src\\t%08x\\n\"\n\t\t\t\"  dst\\t%08x\\n\"\n\t\t\t\"  abcnt\\t%08x\\n\"\n\t\t\t\"  ccnt\\t%08x\\n\"\n\t\t\t\"  bidx\\t%08x\\n\"\n\t\t\t\"  cidx\\t%08x\\n\"\n\t\t\t\"  lkrld\\t%08x\\n\",\n\t\t\ti, echan->ch_num, echan->slot[i],\n\t\t\tedesc->pset[i].param.opt,\n\t\t\tedesc->pset[i].param.src,\n\t\t\tedesc->pset[i].param.dst,\n\t\t\tedesc->pset[i].param.a_b_cnt,\n\t\t\tedesc->pset[i].param.ccnt,\n\t\t\tedesc->pset[i].param.src_dst_bidx,\n\t\t\tedesc->pset[i].param.src_dst_cidx,\n\t\t\tedesc->pset[i].param.link_bcntrld);\n\n\t\tedesc->absync = ret;\n\n\t\t \n\t\tif (tx_flags & DMA_PREP_INTERRUPT) {\n\t\t\tedesc->pset[i].param.opt |= TCINTEN;\n\n\t\t\t \n\t\t\tif (use_intermediate)\n\t\t\t\tedesc->pset[i].param.opt |= ITCINTEN;\n\t\t}\n\t}\n\n\t \n\tif (!echan->tc)\n\t\tedma_assign_channel_eventq(echan, EVENTQ_0);\n\n\treturn vchan_tx_prep(&echan->vchan, &edesc->vdesc, tx_flags);\n}\n\nstatic void edma_completion_handler(struct edma_chan *echan)\n{\n\tstruct device *dev = echan->vchan.chan.device->dev;\n\tstruct edma_desc *edesc;\n\n\tspin_lock(&echan->vchan.lock);\n\tedesc = echan->edesc;\n\tif (edesc) {\n\t\tif (edesc->cyclic) {\n\t\t\tvchan_cyclic_callback(&edesc->vdesc);\n\t\t\tspin_unlock(&echan->vchan.lock);\n\t\t\treturn;\n\t\t} else if (edesc->processed == edesc->pset_nr) {\n\t\t\tedesc->residue = 0;\n\t\t\tedma_stop(echan);\n\t\t\tvchan_cookie_complete(&edesc->vdesc);\n\t\t\techan->edesc = NULL;\n\n\t\t\tdev_dbg(dev, \"Transfer completed on channel %d\\n\",\n\t\t\t\techan->ch_num);\n\t\t} else {\n\t\t\tdev_dbg(dev, \"Sub transfer completed on channel %d\\n\",\n\t\t\t\techan->ch_num);\n\n\t\t\tedma_pause(echan);\n\n\t\t\t \n\t\t\tedesc->residue -= edesc->sg_len;\n\t\t\tedesc->residue_stat = edesc->residue;\n\t\t\tedesc->processed_stat = edesc->processed;\n\t\t}\n\t\tedma_execute(echan);\n\t}\n\n\tspin_unlock(&echan->vchan.lock);\n}\n\n \nstatic irqreturn_t dma_irq_handler(int irq, void *data)\n{\n\tstruct edma_cc *ecc = data;\n\tint ctlr;\n\tu32 sh_ier;\n\tu32 sh_ipr;\n\tu32 bank;\n\n\tctlr = ecc->id;\n\tif (ctlr < 0)\n\t\treturn IRQ_NONE;\n\n\tdev_vdbg(ecc->dev, \"dma_irq_handler\\n\");\n\n\tsh_ipr = edma_shadow0_read_array(ecc, SH_IPR, 0);\n\tif (!sh_ipr) {\n\t\tsh_ipr = edma_shadow0_read_array(ecc, SH_IPR, 1);\n\t\tif (!sh_ipr)\n\t\t\treturn IRQ_NONE;\n\t\tsh_ier = edma_shadow0_read_array(ecc, SH_IER, 1);\n\t\tbank = 1;\n\t} else {\n\t\tsh_ier = edma_shadow0_read_array(ecc, SH_IER, 0);\n\t\tbank = 0;\n\t}\n\n\tdo {\n\t\tu32 slot;\n\t\tu32 channel;\n\n\t\tslot = __ffs(sh_ipr);\n\t\tsh_ipr &= ~(BIT(slot));\n\n\t\tif (sh_ier & BIT(slot)) {\n\t\t\tchannel = (bank << 5) | slot;\n\t\t\t \n\t\t\tedma_shadow0_write_array(ecc, SH_ICR, bank, BIT(slot));\n\t\t\tedma_completion_handler(&ecc->slave_chans[channel]);\n\t\t}\n\t} while (sh_ipr);\n\n\tedma_shadow0_write(ecc, SH_IEVAL, 1);\n\treturn IRQ_HANDLED;\n}\n\nstatic void edma_error_handler(struct edma_chan *echan)\n{\n\tstruct edma_cc *ecc = echan->ecc;\n\tstruct device *dev = echan->vchan.chan.device->dev;\n\tstruct edmacc_param p;\n\tint err;\n\n\tif (!echan->edesc)\n\t\treturn;\n\n\tspin_lock(&echan->vchan.lock);\n\n\terr = edma_read_slot(ecc, echan->slot[0], &p);\n\n\t \n\tif (err || (p.a_b_cnt == 0 && p.ccnt == 0)) {\n\t\tdev_dbg(dev, \"Error on null slot, setting miss\\n\");\n\t\techan->missed = 1;\n\t} else {\n\t\t \n\t\tdev_dbg(dev, \"Missed event, TRIGGERING\\n\");\n\t\tedma_clean_channel(echan);\n\t\tedma_stop(echan);\n\t\tedma_start(echan);\n\t\tedma_trigger_channel(echan);\n\t}\n\tspin_unlock(&echan->vchan.lock);\n}\n\nstatic inline bool edma_error_pending(struct edma_cc *ecc)\n{\n\tif (edma_read_array(ecc, EDMA_EMR, 0) ||\n\t    edma_read_array(ecc, EDMA_EMR, 1) ||\n\t    edma_read(ecc, EDMA_QEMR) || edma_read(ecc, EDMA_CCERR))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic irqreturn_t dma_ccerr_handler(int irq, void *data)\n{\n\tstruct edma_cc *ecc = data;\n\tint i, j;\n\tint ctlr;\n\tunsigned int cnt = 0;\n\tunsigned int val;\n\n\tctlr = ecc->id;\n\tif (ctlr < 0)\n\t\treturn IRQ_NONE;\n\n\tdev_vdbg(ecc->dev, \"dma_ccerr_handler\\n\");\n\n\tif (!edma_error_pending(ecc)) {\n\t\t \n\t\tdev_err(ecc->dev, \"%s: Error interrupt without error event!\\n\",\n\t\t\t__func__);\n\t\tedma_write(ecc, EDMA_EEVAL, 1);\n\t\treturn IRQ_NONE;\n\t}\n\n\twhile (1) {\n\t\t \n\t\tfor (j = 0; j < 2; j++) {\n\t\t\tunsigned long emr;\n\n\t\t\tval = edma_read_array(ecc, EDMA_EMR, j);\n\t\t\tif (!val)\n\t\t\t\tcontinue;\n\n\t\t\tdev_dbg(ecc->dev, \"EMR%d 0x%08x\\n\", j, val);\n\t\t\temr = val;\n\t\t\tfor_each_set_bit(i, &emr, 32) {\n\t\t\t\tint k = (j << 5) + i;\n\n\t\t\t\t \n\t\t\t\tedma_write_array(ecc, EDMA_EMCR, j, BIT(i));\n\t\t\t\t \n\t\t\t\tedma_shadow0_write_array(ecc, SH_SECR, j,\n\t\t\t\t\t\t\t BIT(i));\n\t\t\t\tedma_error_handler(&ecc->slave_chans[k]);\n\t\t\t}\n\t\t}\n\n\t\tval = edma_read(ecc, EDMA_QEMR);\n\t\tif (val) {\n\t\t\tdev_dbg(ecc->dev, \"QEMR 0x%02x\\n\", val);\n\t\t\t \n\t\t\tedma_write(ecc, EDMA_QEMCR, val);\n\t\t\tedma_shadow0_write(ecc, SH_QSECR, val);\n\t\t}\n\n\t\tval = edma_read(ecc, EDMA_CCERR);\n\t\tif (val) {\n\t\t\tdev_warn(ecc->dev, \"CCERR 0x%08x\\n\", val);\n\t\t\t \n\t\t\tedma_write(ecc, EDMA_CCERRCLR, val);\n\t\t}\n\n\t\tif (!edma_error_pending(ecc))\n\t\t\tbreak;\n\t\tcnt++;\n\t\tif (cnt > 10)\n\t\t\tbreak;\n\t}\n\tedma_write(ecc, EDMA_EEVAL, 1);\n\treturn IRQ_HANDLED;\n}\n\n \nstatic int edma_alloc_chan_resources(struct dma_chan *chan)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tstruct edma_cc *ecc = echan->ecc;\n\tstruct device *dev = ecc->dev;\n\tenum dma_event_q eventq_no = EVENTQ_DEFAULT;\n\tint ret;\n\n\tif (echan->tc) {\n\t\teventq_no = echan->tc->id;\n\t} else if (ecc->tc_list) {\n\t\t \n\t\techan->tc = &ecc->tc_list[ecc->info->default_queue];\n\t\teventq_no = echan->tc->id;\n\t}\n\n\tret = edma_alloc_channel(echan, eventq_no);\n\tif (ret)\n\t\treturn ret;\n\n\techan->slot[0] = edma_alloc_slot(ecc, echan->ch_num);\n\tif (echan->slot[0] < 0) {\n\t\tdev_err(dev, \"Entry slot allocation failed for channel %u\\n\",\n\t\t\tEDMA_CHAN_SLOT(echan->ch_num));\n\t\tret = echan->slot[0];\n\t\tgoto err_slot;\n\t}\n\n\t \n\tedma_set_chmap(echan, echan->slot[0]);\n\techan->alloced = true;\n\n\tdev_dbg(dev, \"Got eDMA channel %d for virt channel %d (%s trigger)\\n\",\n\t\tEDMA_CHAN_SLOT(echan->ch_num), chan->chan_id,\n\t\techan->hw_triggered ? \"HW\" : \"SW\");\n\n\treturn 0;\n\nerr_slot:\n\tedma_free_channel(echan);\n\treturn ret;\n}\n\n \nstatic void edma_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tstruct device *dev = echan->ecc->dev;\n\tint i;\n\n\t \n\tedma_stop(echan);\n\n\tvchan_free_chan_resources(&echan->vchan);\n\n\t \n\tfor (i = 0; i < EDMA_MAX_SLOTS; i++) {\n\t\tif (echan->slot[i] >= 0) {\n\t\t\tedma_free_slot(echan->ecc, echan->slot[i]);\n\t\t\techan->slot[i] = -1;\n\t\t}\n\t}\n\n\t \n\tedma_set_chmap(echan, echan->ecc->dummy_slot);\n\n\t \n\tif (echan->alloced) {\n\t\tedma_free_channel(echan);\n\t\techan->alloced = false;\n\t}\n\n\techan->tc = NULL;\n\techan->hw_triggered = false;\n\n\tdev_dbg(dev, \"Free eDMA channel %d for virt channel %d\\n\",\n\t\tEDMA_CHAN_SLOT(echan->ch_num), chan->chan_id);\n}\n\n \nstatic void edma_issue_pending(struct dma_chan *chan)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&echan->vchan.lock, flags);\n\tif (vchan_issue_pending(&echan->vchan) && !echan->edesc)\n\t\tedma_execute(echan);\n\tspin_unlock_irqrestore(&echan->vchan.lock, flags);\n}\n\n \n#define EDMA_MAX_TR_WAIT_LOOPS 1000\n\nstatic u32 edma_residue(struct edma_desc *edesc)\n{\n\tbool dst = edesc->direction == DMA_DEV_TO_MEM;\n\tint loop_count = EDMA_MAX_TR_WAIT_LOOPS;\n\tstruct edma_chan *echan = edesc->echan;\n\tstruct edma_pset *pset = edesc->pset;\n\tdma_addr_t done, pos, pos_old;\n\tint channel = EDMA_CHAN_SLOT(echan->ch_num);\n\tint idx = EDMA_REG_ARRAY_INDEX(channel);\n\tint ch_bit = EDMA_CHANNEL_BIT(channel);\n\tint event_reg;\n\tint i;\n\n\t \n\tpos = edma_get_position(echan->ecc, echan->slot[0], dst);\n\n\t \n\tif (is_slave_direction(edesc->direction))\n\t\tevent_reg = SH_ER;\n\telse\n\t\tevent_reg = SH_ESR;\n\n\tpos_old = pos;\n\twhile (edma_shadow0_read_array(echan->ecc, event_reg, idx) & ch_bit) {\n\t\tpos = edma_get_position(echan->ecc, echan->slot[0], dst);\n\t\tif (pos != pos_old)\n\t\t\tbreak;\n\n\t\tif (!--loop_count) {\n\t\t\tdev_dbg_ratelimited(echan->vchan.chan.device->dev,\n\t\t\t\t\"%s: timeout waiting for PaRAM update\\n\",\n\t\t\t\t__func__);\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\n\t \n\tif (edesc->cyclic) {\n\t\tdone = pos - pset->addr;\n\t\tedesc->residue_stat = edesc->residue - done;\n\t\treturn edesc->residue_stat;\n\t}\n\n\t \n\tif (!pos)\n\t\treturn 0;\n\t \n\tpset += edesc->processed_stat;\n\n\tfor (i = edesc->processed_stat; i < edesc->processed; i++, pset++) {\n\t\t \n\t\tif (pos >= pset->addr && pos < pset->addr + pset->len)\n\t\t\treturn edesc->residue_stat - (pos - pset->addr);\n\n\t\t \n\t\tedesc->processed_stat++;\n\t\tedesc->residue_stat -= pset->len;\n\t}\n\treturn edesc->residue_stat;\n}\n\n \nstatic enum dma_status edma_tx_status(struct dma_chan *chan,\n\t\t\t\t      dma_cookie_t cookie,\n\t\t\t\t      struct dma_tx_state *txstate)\n{\n\tstruct edma_chan *echan = to_edma_chan(chan);\n\tstruct dma_tx_state txstate_tmp;\n\tenum dma_status ret;\n\tunsigned long flags;\n\n\tret = dma_cookie_status(chan, cookie, txstate);\n\n\tif (ret == DMA_COMPLETE)\n\t\treturn ret;\n\n\t \n\tif (!txstate)\n\t\ttxstate = &txstate_tmp;\n\n\tspin_lock_irqsave(&echan->vchan.lock, flags);\n\tif (echan->edesc && echan->edesc->vdesc.tx.cookie == cookie) {\n\t\ttxstate->residue = edma_residue(echan->edesc);\n\t} else {\n\t\tstruct virt_dma_desc *vdesc = vchan_find_desc(&echan->vchan,\n\t\t\t\t\t\t\t      cookie);\n\n\t\tif (vdesc)\n\t\t\ttxstate->residue = to_edma_desc(&vdesc->tx)->residue;\n\t\telse\n\t\t\ttxstate->residue = 0;\n\t}\n\n\t \n\tif (ret != DMA_COMPLETE && !txstate->residue &&\n\t    echan->edesc && echan->edesc->polled &&\n\t    echan->edesc->vdesc.tx.cookie == cookie) {\n\t\tedma_stop(echan);\n\t\tvchan_cookie_complete(&echan->edesc->vdesc);\n\t\techan->edesc = NULL;\n\t\tedma_execute(echan);\n\t\tret = DMA_COMPLETE;\n\t}\n\n\tspin_unlock_irqrestore(&echan->vchan.lock, flags);\n\n\treturn ret;\n}\n\nstatic bool edma_is_memcpy_channel(int ch_num, s32 *memcpy_channels)\n{\n\tif (!memcpy_channels)\n\t\treturn false;\n\twhile (*memcpy_channels != -1) {\n\t\tif (*memcpy_channels == ch_num)\n\t\t\treturn true;\n\t\tmemcpy_channels++;\n\t}\n\treturn false;\n}\n\n#define EDMA_DMA_BUSWIDTHS\t(BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) | \\\n\t\t\t\t BIT(DMA_SLAVE_BUSWIDTH_2_BYTES) | \\\n\t\t\t\t BIT(DMA_SLAVE_BUSWIDTH_3_BYTES) | \\\n\t\t\t\t BIT(DMA_SLAVE_BUSWIDTH_4_BYTES))\n\nstatic void edma_dma_init(struct edma_cc *ecc, bool legacy_mode)\n{\n\tstruct dma_device *s_ddev = &ecc->dma_slave;\n\tstruct dma_device *m_ddev = NULL;\n\ts32 *memcpy_channels = ecc->info->memcpy_channels;\n\tint i, j;\n\n\tdma_cap_zero(s_ddev->cap_mask);\n\tdma_cap_set(DMA_SLAVE, s_ddev->cap_mask);\n\tdma_cap_set(DMA_CYCLIC, s_ddev->cap_mask);\n\tif (ecc->legacy_mode && !memcpy_channels) {\n\t\tdev_warn(ecc->dev,\n\t\t\t \"Legacy memcpy is enabled, things might not work\\n\");\n\n\t\tdma_cap_set(DMA_MEMCPY, s_ddev->cap_mask);\n\t\tdma_cap_set(DMA_INTERLEAVE, s_ddev->cap_mask);\n\t\ts_ddev->device_prep_dma_memcpy = edma_prep_dma_memcpy;\n\t\ts_ddev->device_prep_interleaved_dma = edma_prep_dma_interleaved;\n\t\ts_ddev->directions = BIT(DMA_MEM_TO_MEM);\n\t}\n\n\ts_ddev->device_prep_slave_sg = edma_prep_slave_sg;\n\ts_ddev->device_prep_dma_cyclic = edma_prep_dma_cyclic;\n\ts_ddev->device_alloc_chan_resources = edma_alloc_chan_resources;\n\ts_ddev->device_free_chan_resources = edma_free_chan_resources;\n\ts_ddev->device_issue_pending = edma_issue_pending;\n\ts_ddev->device_tx_status = edma_tx_status;\n\ts_ddev->device_config = edma_slave_config;\n\ts_ddev->device_pause = edma_dma_pause;\n\ts_ddev->device_resume = edma_dma_resume;\n\ts_ddev->device_terminate_all = edma_terminate_all;\n\ts_ddev->device_synchronize = edma_synchronize;\n\n\ts_ddev->src_addr_widths = EDMA_DMA_BUSWIDTHS;\n\ts_ddev->dst_addr_widths = EDMA_DMA_BUSWIDTHS;\n\ts_ddev->directions |= (BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV));\n\ts_ddev->residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\ts_ddev->max_burst = SZ_32K - 1;  \n\n\ts_ddev->dev = ecc->dev;\n\tINIT_LIST_HEAD(&s_ddev->channels);\n\n\tif (memcpy_channels) {\n\t\tm_ddev = devm_kzalloc(ecc->dev, sizeof(*m_ddev), GFP_KERNEL);\n\t\tif (!m_ddev) {\n\t\t\tdev_warn(ecc->dev, \"memcpy is disabled due to OoM\\n\");\n\t\t\tmemcpy_channels = NULL;\n\t\t\tgoto ch_setup;\n\t\t}\n\t\tecc->dma_memcpy = m_ddev;\n\n\t\tdma_cap_zero(m_ddev->cap_mask);\n\t\tdma_cap_set(DMA_MEMCPY, m_ddev->cap_mask);\n\t\tdma_cap_set(DMA_INTERLEAVE, m_ddev->cap_mask);\n\n\t\tm_ddev->device_prep_dma_memcpy = edma_prep_dma_memcpy;\n\t\tm_ddev->device_prep_interleaved_dma = edma_prep_dma_interleaved;\n\t\tm_ddev->device_alloc_chan_resources = edma_alloc_chan_resources;\n\t\tm_ddev->device_free_chan_resources = edma_free_chan_resources;\n\t\tm_ddev->device_issue_pending = edma_issue_pending;\n\t\tm_ddev->device_tx_status = edma_tx_status;\n\t\tm_ddev->device_config = edma_slave_config;\n\t\tm_ddev->device_pause = edma_dma_pause;\n\t\tm_ddev->device_resume = edma_dma_resume;\n\t\tm_ddev->device_terminate_all = edma_terminate_all;\n\t\tm_ddev->device_synchronize = edma_synchronize;\n\n\t\tm_ddev->src_addr_widths = EDMA_DMA_BUSWIDTHS;\n\t\tm_ddev->dst_addr_widths = EDMA_DMA_BUSWIDTHS;\n\t\tm_ddev->directions = BIT(DMA_MEM_TO_MEM);\n\t\tm_ddev->residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\n\t\tm_ddev->dev = ecc->dev;\n\t\tINIT_LIST_HEAD(&m_ddev->channels);\n\t} else if (!ecc->legacy_mode) {\n\t\tdev_info(ecc->dev, \"memcpy is disabled\\n\");\n\t}\n\nch_setup:\n\tfor (i = 0; i < ecc->num_channels; i++) {\n\t\tstruct edma_chan *echan = &ecc->slave_chans[i];\n\t\techan->ch_num = EDMA_CTLR_CHAN(ecc->id, i);\n\t\techan->ecc = ecc;\n\t\techan->vchan.desc_free = edma_desc_free;\n\n\t\tif (m_ddev && edma_is_memcpy_channel(i, memcpy_channels))\n\t\t\tvchan_init(&echan->vchan, m_ddev);\n\t\telse\n\t\t\tvchan_init(&echan->vchan, s_ddev);\n\n\t\tINIT_LIST_HEAD(&echan->node);\n\t\tfor (j = 0; j < EDMA_MAX_SLOTS; j++)\n\t\t\techan->slot[j] = -1;\n\t}\n}\n\nstatic int edma_setup_from_hw(struct device *dev, struct edma_soc_info *pdata,\n\t\t\t      struct edma_cc *ecc)\n{\n\tint i;\n\tu32 value, cccfg;\n\ts8 (*queue_priority_map)[2];\n\n\t \n\tcccfg = edma_read(ecc, EDMA_CCCFG);\n\n\tvalue = GET_NUM_REGN(cccfg);\n\tecc->num_region = BIT(value);\n\n\tvalue = GET_NUM_DMACH(cccfg);\n\tecc->num_channels = BIT(value + 1);\n\n\tvalue = GET_NUM_QDMACH(cccfg);\n\tecc->num_qchannels = value * 2;\n\n\tvalue = GET_NUM_PAENTRY(cccfg);\n\tecc->num_slots = BIT(value + 4);\n\n\tvalue = GET_NUM_EVQUE(cccfg);\n\tecc->num_tc = value + 1;\n\n\tecc->chmap_exist = (cccfg & CHMAP_EXIST) ? true : false;\n\n\tdev_dbg(dev, \"eDMA3 CC HW configuration (cccfg: 0x%08x):\\n\", cccfg);\n\tdev_dbg(dev, \"num_region: %u\\n\", ecc->num_region);\n\tdev_dbg(dev, \"num_channels: %u\\n\", ecc->num_channels);\n\tdev_dbg(dev, \"num_qchannels: %u\\n\", ecc->num_qchannels);\n\tdev_dbg(dev, \"num_slots: %u\\n\", ecc->num_slots);\n\tdev_dbg(dev, \"num_tc: %u\\n\", ecc->num_tc);\n\tdev_dbg(dev, \"chmap_exist: %s\\n\", ecc->chmap_exist ? \"yes\" : \"no\");\n\n\t \n\tif (pdata->queue_priority_mapping)\n\t\treturn 0;\n\n\t \n\tqueue_priority_map = devm_kcalloc(dev, ecc->num_tc + 1, sizeof(s8),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!queue_priority_map)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < ecc->num_tc; i++) {\n\t\tqueue_priority_map[i][0] = i;\n\t\tqueue_priority_map[i][1] = i;\n\t}\n\tqueue_priority_map[i][0] = -1;\n\tqueue_priority_map[i][1] = -1;\n\n\tpdata->queue_priority_mapping = queue_priority_map;\n\t \n\tpdata->default_queue = i - 1;\n\n\treturn 0;\n}\n\n#if IS_ENABLED(CONFIG_OF)\nstatic int edma_xbar_event_map(struct device *dev, struct edma_soc_info *pdata,\n\t\t\t       size_t sz)\n{\n\tconst char pname[] = \"ti,edma-xbar-event-map\";\n\tstruct resource res;\n\tvoid __iomem *xbar;\n\ts16 (*xbar_chans)[2];\n\tsize_t nelm = sz / sizeof(s16);\n\tu32 shift, offset, mux;\n\tint ret, i;\n\n\txbar_chans = devm_kcalloc(dev, nelm + 2, sizeof(s16), GFP_KERNEL);\n\tif (!xbar_chans)\n\t\treturn -ENOMEM;\n\n\tret = of_address_to_resource(dev->of_node, 1, &res);\n\tif (ret)\n\t\treturn -ENOMEM;\n\n\txbar = devm_ioremap(dev, res.start, resource_size(&res));\n\tif (!xbar)\n\t\treturn -ENOMEM;\n\n\tret = of_property_read_u16_array(dev->of_node, pname, (u16 *)xbar_chans,\n\t\t\t\t\t nelm);\n\tif (ret)\n\t\treturn -EIO;\n\n\t \n\tnelm >>= 1;\n\txbar_chans[nelm][0] = -1;\n\txbar_chans[nelm][1] = -1;\n\n\tfor (i = 0; i < nelm; i++) {\n\t\tshift = (xbar_chans[i][1] & 0x03) << 3;\n\t\toffset = xbar_chans[i][1] & 0xfffffffc;\n\t\tmux = readl(xbar + offset);\n\t\tmux &= ~(0xff << shift);\n\t\tmux |= xbar_chans[i][0] << shift;\n\t\twritel(mux, (xbar + offset));\n\t}\n\n\tpdata->xbar_chans = (const s16 (*)[2]) xbar_chans;\n\treturn 0;\n}\n\nstatic struct edma_soc_info *edma_setup_info_from_dt(struct device *dev,\n\t\t\t\t\t\t     bool legacy_mode)\n{\n\tstruct edma_soc_info *info;\n\tstruct property *prop;\n\tint sz, ret;\n\n\tinfo = devm_kzalloc(dev, sizeof(struct edma_soc_info), GFP_KERNEL);\n\tif (!info)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (legacy_mode) {\n\t\tprop = of_find_property(dev->of_node, \"ti,edma-xbar-event-map\",\n\t\t\t\t\t&sz);\n\t\tif (prop) {\n\t\t\tret = edma_xbar_event_map(dev, info, sz);\n\t\t\tif (ret)\n\t\t\t\treturn ERR_PTR(ret);\n\t\t}\n\t\treturn info;\n\t}\n\n\t \n\tprop = of_find_property(dev->of_node, \"ti,edma-memcpy-channels\", &sz);\n\tif (prop) {\n\t\tconst char pname[] = \"ti,edma-memcpy-channels\";\n\t\tsize_t nelm = sz / sizeof(s32);\n\t\ts32 *memcpy_ch;\n\n\t\tmemcpy_ch = devm_kcalloc(dev, nelm + 1, sizeof(s32),\n\t\t\t\t\t GFP_KERNEL);\n\t\tif (!memcpy_ch)\n\t\t\treturn ERR_PTR(-ENOMEM);\n\n\t\tret = of_property_read_u32_array(dev->of_node, pname,\n\t\t\t\t\t\t (u32 *)memcpy_ch, nelm);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\n\t\tmemcpy_ch[nelm] = -1;\n\t\tinfo->memcpy_channels = memcpy_ch;\n\t}\n\n\tprop = of_find_property(dev->of_node, \"ti,edma-reserved-slot-ranges\",\n\t\t\t\t&sz);\n\tif (prop) {\n\t\tconst char pname[] = \"ti,edma-reserved-slot-ranges\";\n\t\tu32 (*tmp)[2];\n\t\ts16 (*rsv_slots)[2];\n\t\tsize_t nelm = sz / sizeof(*tmp);\n\t\tstruct edma_rsv_info *rsv_info;\n\t\tint i;\n\n\t\tif (!nelm)\n\t\t\treturn info;\n\n\t\ttmp = kcalloc(nelm, sizeof(*tmp), GFP_KERNEL);\n\t\tif (!tmp)\n\t\t\treturn ERR_PTR(-ENOMEM);\n\n\t\trsv_info = devm_kzalloc(dev, sizeof(*rsv_info), GFP_KERNEL);\n\t\tif (!rsv_info) {\n\t\t\tkfree(tmp);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\n\t\trsv_slots = devm_kcalloc(dev, nelm + 1, sizeof(*rsv_slots),\n\t\t\t\t\t GFP_KERNEL);\n\t\tif (!rsv_slots) {\n\t\t\tkfree(tmp);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\n\t\tret = of_property_read_u32_array(dev->of_node, pname,\n\t\t\t\t\t\t (u32 *)tmp, nelm * 2);\n\t\tif (ret) {\n\t\t\tkfree(tmp);\n\t\t\treturn ERR_PTR(ret);\n\t\t}\n\n\t\tfor (i = 0; i < nelm; i++) {\n\t\t\trsv_slots[i][0] = tmp[i][0];\n\t\t\trsv_slots[i][1] = tmp[i][1];\n\t\t}\n\t\trsv_slots[nelm][0] = -1;\n\t\trsv_slots[nelm][1] = -1;\n\n\t\tinfo->rsv = rsv_info;\n\t\tinfo->rsv->rsv_slots = (const s16 (*)[2])rsv_slots;\n\n\t\tkfree(tmp);\n\t}\n\n\treturn info;\n}\n\nstatic struct dma_chan *of_edma_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t      struct of_dma *ofdma)\n{\n\tstruct edma_cc *ecc = ofdma->of_dma_data;\n\tstruct dma_chan *chan = NULL;\n\tstruct edma_chan *echan;\n\tint i;\n\n\tif (!ecc || dma_spec->args_count < 1)\n\t\treturn NULL;\n\n\tfor (i = 0; i < ecc->num_channels; i++) {\n\t\techan = &ecc->slave_chans[i];\n\t\tif (echan->ch_num == dma_spec->args[0]) {\n\t\t\tchan = &echan->vchan.chan;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!chan)\n\t\treturn NULL;\n\n\tif (echan->ecc->legacy_mode && dma_spec->args_count == 1)\n\t\tgoto out;\n\n\tif (!echan->ecc->legacy_mode && dma_spec->args_count == 2 &&\n\t    dma_spec->args[1] < echan->ecc->num_tc) {\n\t\techan->tc = &echan->ecc->tc_list[dma_spec->args[1]];\n\t\tgoto out;\n\t}\n\n\treturn NULL;\nout:\n\t \n\techan->hw_triggered = true;\n\treturn dma_get_slave_channel(chan);\n}\n#else\nstatic struct edma_soc_info *edma_setup_info_from_dt(struct device *dev,\n\t\t\t\t\t\t     bool legacy_mode)\n{\n\treturn ERR_PTR(-EINVAL);\n}\n\nstatic struct dma_chan *of_edma_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t      struct of_dma *ofdma)\n{\n\treturn NULL;\n}\n#endif\n\nstatic bool edma_filter_fn(struct dma_chan *chan, void *param);\n\nstatic int edma_probe(struct platform_device *pdev)\n{\n\tstruct edma_soc_info\t*info = pdev->dev.platform_data;\n\ts8\t\t\t(*queue_priority_mapping)[2];\n\tconst s16\t\t(*reserved)[2];\n\tint\t\t\ti, irq;\n\tchar\t\t\t*irq_name;\n\tstruct resource\t\t*mem;\n\tstruct device_node\t*node = pdev->dev.of_node;\n\tstruct device\t\t*dev = &pdev->dev;\n\tstruct edma_cc\t\t*ecc;\n\tbool\t\t\tlegacy_mode = true;\n\tint ret;\n\n\tif (node) {\n\t\tconst struct of_device_id *match;\n\n\t\tmatch = of_match_node(edma_of_ids, node);\n\t\tif (match && (*(u32 *)match->data) == EDMA_BINDING_TPCC)\n\t\t\tlegacy_mode = false;\n\n\t\tinfo = edma_setup_info_from_dt(dev, legacy_mode);\n\t\tif (IS_ERR(info)) {\n\t\t\tdev_err(dev, \"failed to get DT data\\n\");\n\t\t\treturn PTR_ERR(info);\n\t\t}\n\t}\n\n\tif (!info)\n\t\treturn -ENODEV;\n\n\tret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(32));\n\tif (ret)\n\t\treturn ret;\n\n\tecc = devm_kzalloc(dev, sizeof(*ecc), GFP_KERNEL);\n\tif (!ecc)\n\t\treturn -ENOMEM;\n\n\tecc->dev = dev;\n\tecc->id = pdev->id;\n\tecc->legacy_mode = legacy_mode;\n\t \n\tif (ecc->id < 0)\n\t\tecc->id = 0;\n\n\tmem = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"edma3_cc\");\n\tif (!mem) {\n\t\tdev_dbg(dev, \"mem resource not found, using index 0\\n\");\n\t\tmem = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\t\tif (!mem) {\n\t\t\tdev_err(dev, \"no mem resource?\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\tecc->base = devm_ioremap_resource(dev, mem);\n\tif (IS_ERR(ecc->base))\n\t\treturn PTR_ERR(ecc->base);\n\n\tplatform_set_drvdata(pdev, ecc);\n\n\tpm_runtime_enable(dev);\n\tret = pm_runtime_get_sync(dev);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"pm_runtime_get_sync() failed\\n\");\n\t\tpm_runtime_disable(dev);\n\t\treturn ret;\n\t}\n\n\t \n\tret = edma_setup_from_hw(dev, info, ecc);\n\tif (ret)\n\t\tgoto err_disable_pm;\n\n\t \n\tecc->slave_chans = devm_kcalloc(dev, ecc->num_channels,\n\t\t\t\t\tsizeof(*ecc->slave_chans), GFP_KERNEL);\n\n\tecc->slot_inuse = devm_kcalloc(dev, BITS_TO_LONGS(ecc->num_slots),\n\t\t\t\t       sizeof(unsigned long), GFP_KERNEL);\n\n\tecc->channels_mask = devm_kcalloc(dev,\n\t\t\t\t\t   BITS_TO_LONGS(ecc->num_channels),\n\t\t\t\t\t   sizeof(unsigned long), GFP_KERNEL);\n\tif (!ecc->slave_chans || !ecc->slot_inuse || !ecc->channels_mask) {\n\t\tret = -ENOMEM;\n\t\tgoto err_disable_pm;\n\t}\n\n\t \n\tbitmap_fill(ecc->channels_mask, ecc->num_channels);\n\n\tecc->default_queue = info->default_queue;\n\n\tif (info->rsv) {\n\t\t \n\t\treserved = info->rsv->rsv_slots;\n\t\tif (reserved) {\n\t\t\tfor (i = 0; reserved[i][0] != -1; i++)\n\t\t\t\tbitmap_set(ecc->slot_inuse, reserved[i][0],\n\t\t\t\t\t   reserved[i][1]);\n\t\t}\n\n\t\t \n\t\treserved = info->rsv->rsv_chans;\n\t\tif (reserved) {\n\t\t\tfor (i = 0; reserved[i][0] != -1; i++)\n\t\t\t\tbitmap_clear(ecc->channels_mask, reserved[i][0],\n\t\t\t\t\t     reserved[i][1]);\n\t\t}\n\t}\n\n\tfor (i = 0; i < ecc->num_slots; i++) {\n\t\t \n\t\tif (!test_bit(i, ecc->slot_inuse))\n\t\t\tedma_write_slot(ecc, i, &dummy_paramset);\n\t}\n\n\tirq = platform_get_irq_byname(pdev, \"edma3_ccint\");\n\tif (irq < 0 && node)\n\t\tirq = irq_of_parse_and_map(node, 0);\n\n\tif (irq > 0) {\n\t\tirq_name = devm_kasprintf(dev, GFP_KERNEL, \"%s_ccint\",\n\t\t\t\t\t  dev_name(dev));\n\t\tret = devm_request_irq(dev, irq, dma_irq_handler, 0, irq_name,\n\t\t\t\t       ecc);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"CCINT (%d) failed --> %d\\n\", irq, ret);\n\t\t\tgoto err_disable_pm;\n\t\t}\n\t\tecc->ccint = irq;\n\t}\n\n\tirq = platform_get_irq_byname(pdev, \"edma3_ccerrint\");\n\tif (irq < 0 && node)\n\t\tirq = irq_of_parse_and_map(node, 2);\n\n\tif (irq > 0) {\n\t\tirq_name = devm_kasprintf(dev, GFP_KERNEL, \"%s_ccerrint\",\n\t\t\t\t\t  dev_name(dev));\n\t\tret = devm_request_irq(dev, irq, dma_ccerr_handler, 0, irq_name,\n\t\t\t\t       ecc);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"CCERRINT (%d) failed --> %d\\n\", irq, ret);\n\t\t\tgoto err_disable_pm;\n\t\t}\n\t\tecc->ccerrint = irq;\n\t}\n\n\tecc->dummy_slot = edma_alloc_slot(ecc, EDMA_SLOT_ANY);\n\tif (ecc->dummy_slot < 0) {\n\t\tdev_err(dev, \"Can't allocate PaRAM dummy slot\\n\");\n\t\tret = ecc->dummy_slot;\n\t\tgoto err_disable_pm;\n\t}\n\n\tqueue_priority_mapping = info->queue_priority_mapping;\n\n\tif (!ecc->legacy_mode) {\n\t\tint lowest_priority = 0;\n\t\tunsigned int array_max;\n\t\tstruct of_phandle_args tc_args;\n\n\t\tecc->tc_list = devm_kcalloc(dev, ecc->num_tc,\n\t\t\t\t\t    sizeof(*ecc->tc_list), GFP_KERNEL);\n\t\tif (!ecc->tc_list) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_reg1;\n\t\t}\n\n\t\tfor (i = 0;; i++) {\n\t\t\tret = of_parse_phandle_with_fixed_args(node, \"ti,tptcs\",\n\t\t\t\t\t\t\t       1, i, &tc_args);\n\t\t\tif (ret || i == ecc->num_tc)\n\t\t\t\tbreak;\n\n\t\t\tecc->tc_list[i].node = tc_args.np;\n\t\t\tecc->tc_list[i].id = i;\n\t\t\tqueue_priority_mapping[i][1] = tc_args.args[0];\n\t\t\tif (queue_priority_mapping[i][1] > lowest_priority) {\n\t\t\t\tlowest_priority = queue_priority_mapping[i][1];\n\t\t\t\tinfo->default_queue = i;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tarray_max = DIV_ROUND_UP(ecc->num_channels, BITS_PER_TYPE(u32));\n\t\tret = of_property_read_variable_u32_array(node,\n\t\t\t\t\t\t\"dma-channel-mask\",\n\t\t\t\t\t\t(u32 *)ecc->channels_mask,\n\t\t\t\t\t\t1, array_max);\n\t\tif (ret > 0 && ret != array_max)\n\t\t\tdev_warn(dev, \"dma-channel-mask is not complete.\\n\");\n\t\telse if (ret == -EOVERFLOW || ret == -ENODATA)\n\t\t\tdev_warn(dev,\n\t\t\t\t \"dma-channel-mask is out of range or empty\\n\");\n\t}\n\n\t \n\tfor (i = 0; queue_priority_mapping[i][0] != -1; i++)\n\t\tedma_assign_priority_to_queue(ecc, queue_priority_mapping[i][0],\n\t\t\t\t\t      queue_priority_mapping[i][1]);\n\n\tedma_write_array2(ecc, EDMA_DRAE, 0, 0, 0x0);\n\tedma_write_array2(ecc, EDMA_DRAE, 0, 1, 0x0);\n\tedma_write_array(ecc, EDMA_QRAE, 0, 0x0);\n\n\tecc->info = info;\n\n\t \n\tedma_dma_init(ecc, legacy_mode);\n\n\tfor (i = 0; i < ecc->num_channels; i++) {\n\t\t \n\t\tif (!test_bit(i, ecc->channels_mask))\n\t\t\tcontinue;\n\n\t\t \n\t\tedma_assign_channel_eventq(&ecc->slave_chans[i],\n\t\t\t\t\t   info->default_queue);\n\t\t \n\t\tedma_set_chmap(&ecc->slave_chans[i], ecc->dummy_slot);\n\t}\n\n\tecc->dma_slave.filter.map = info->slave_map;\n\tecc->dma_slave.filter.mapcnt = info->slavecnt;\n\tecc->dma_slave.filter.fn = edma_filter_fn;\n\n\tret = dma_async_device_register(&ecc->dma_slave);\n\tif (ret) {\n\t\tdev_err(dev, \"slave ddev registration failed (%d)\\n\", ret);\n\t\tgoto err_reg1;\n\t}\n\n\tif (ecc->dma_memcpy) {\n\t\tret = dma_async_device_register(ecc->dma_memcpy);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"memcpy ddev registration failed (%d)\\n\",\n\t\t\t\tret);\n\t\t\tdma_async_device_unregister(&ecc->dma_slave);\n\t\t\tgoto err_reg1;\n\t\t}\n\t}\n\n\tif (node)\n\t\tof_dma_controller_register(node, of_edma_xlate, ecc);\n\n\tdev_info(dev, \"TI EDMA DMA engine driver\\n\");\n\n\treturn 0;\n\nerr_reg1:\n\tedma_free_slot(ecc, ecc->dummy_slot);\nerr_disable_pm:\n\tpm_runtime_put_sync(dev);\n\tpm_runtime_disable(dev);\n\treturn ret;\n}\n\nstatic void edma_cleanupp_vchan(struct dma_device *dmadev)\n{\n\tstruct edma_chan *echan, *_echan;\n\n\tlist_for_each_entry_safe(echan, _echan,\n\t\t\t&dmadev->channels, vchan.chan.device_node) {\n\t\tlist_del(&echan->vchan.chan.device_node);\n\t\ttasklet_kill(&echan->vchan.task);\n\t}\n}\n\nstatic int edma_remove(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct edma_cc *ecc = dev_get_drvdata(dev);\n\n\tdevm_free_irq(dev, ecc->ccint, ecc);\n\tdevm_free_irq(dev, ecc->ccerrint, ecc);\n\n\tedma_cleanupp_vchan(&ecc->dma_slave);\n\n\tif (dev->of_node)\n\t\tof_dma_controller_free(dev->of_node);\n\tdma_async_device_unregister(&ecc->dma_slave);\n\tif (ecc->dma_memcpy)\n\t\tdma_async_device_unregister(ecc->dma_memcpy);\n\tedma_free_slot(ecc, ecc->dummy_slot);\n\tpm_runtime_put_sync(dev);\n\tpm_runtime_disable(dev);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int edma_pm_suspend(struct device *dev)\n{\n\tstruct edma_cc *ecc = dev_get_drvdata(dev);\n\tstruct edma_chan *echan = ecc->slave_chans;\n\tint i;\n\n\tfor (i = 0; i < ecc->num_channels; i++) {\n\t\tif (echan[i].alloced)\n\t\t\tedma_setup_interrupt(&echan[i], false);\n\t}\n\n\treturn 0;\n}\n\nstatic int edma_pm_resume(struct device *dev)\n{\n\tstruct edma_cc *ecc = dev_get_drvdata(dev);\n\tstruct edma_chan *echan = ecc->slave_chans;\n\tint i;\n\ts8 (*queue_priority_mapping)[2];\n\n\t \n\tedma_write_slot(ecc, ecc->dummy_slot, &dummy_paramset);\n\n\tqueue_priority_mapping = ecc->info->queue_priority_mapping;\n\n\t \n\tfor (i = 0; queue_priority_mapping[i][0] != -1; i++)\n\t\tedma_assign_priority_to_queue(ecc, queue_priority_mapping[i][0],\n\t\t\t\t\t      queue_priority_mapping[i][1]);\n\n\tfor (i = 0; i < ecc->num_channels; i++) {\n\t\tif (echan[i].alloced) {\n\t\t\t \n\t\t\tedma_or_array2(ecc, EDMA_DRAE, 0,\n\t\t\t\t       EDMA_REG_ARRAY_INDEX(i),\n\t\t\t\t       EDMA_CHANNEL_BIT(i));\n\n\t\t\tedma_setup_interrupt(&echan[i], true);\n\n\t\t\t \n\t\t\tedma_set_chmap(&echan[i], echan[i].slot[0]);\n\t\t}\n\t}\n\n\treturn 0;\n}\n#endif\n\nstatic const struct dev_pm_ops edma_pm_ops = {\n\tSET_LATE_SYSTEM_SLEEP_PM_OPS(edma_pm_suspend, edma_pm_resume)\n};\n\nstatic struct platform_driver edma_driver = {\n\t.probe\t\t= edma_probe,\n\t.remove\t\t= edma_remove,\n\t.driver = {\n\t\t.name\t= \"edma\",\n\t\t.pm\t= &edma_pm_ops,\n\t\t.of_match_table = edma_of_ids,\n\t},\n};\n\nstatic int edma_tptc_probe(struct platform_device *pdev)\n{\n\tpm_runtime_enable(&pdev->dev);\n\treturn pm_runtime_get_sync(&pdev->dev);\n}\n\nstatic struct platform_driver edma_tptc_driver = {\n\t.probe\t\t= edma_tptc_probe,\n\t.driver = {\n\t\t.name\t= \"edma3-tptc\",\n\t\t.of_match_table = edma_tptc_of_ids,\n\t},\n};\n\nstatic bool edma_filter_fn(struct dma_chan *chan, void *param)\n{\n\tbool match = false;\n\n\tif (chan->device->dev->driver == &edma_driver.driver) {\n\t\tstruct edma_chan *echan = to_edma_chan(chan);\n\t\tunsigned ch_req = *(unsigned *)param;\n\t\tif (ch_req == echan->ch_num) {\n\t\t\t \n\t\t\techan->hw_triggered = true;\n\t\t\tmatch = true;\n\t\t}\n\t}\n\treturn match;\n}\n\nstatic int edma_init(void)\n{\n\tint ret;\n\n\tret = platform_driver_register(&edma_tptc_driver);\n\tif (ret)\n\t\treturn ret;\n\n\treturn platform_driver_register(&edma_driver);\n}\nsubsys_initcall(edma_init);\n\nstatic void __exit edma_exit(void)\n{\n\tplatform_driver_unregister(&edma_driver);\n\tplatform_driver_unregister(&edma_tptc_driver);\n}\nmodule_exit(edma_exit);\n\nMODULE_AUTHOR(\"Matt Porter <matt.porter@linaro.org>\");\nMODULE_DESCRIPTION(\"TI EDMA DMA engine driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}