{
  "module_name": "hidma_ll.c",
  "hash_id": "9fdd594f188f2b40eddf81802338fe25f46d975883f442be31ad1ded10ddb7ce",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/qcom/hidma_ll.c",
  "human_readable_source": "\n \n\n#include <linux/dmaengine.h>\n#include <linux/slab.h>\n#include <linux/interrupt.h>\n#include <linux/mm.h>\n#include <linux/highmem.h>\n#include <linux/dma-mapping.h>\n#include <linux/delay.h>\n#include <linux/atomic.h>\n#include <linux/iopoll.h>\n#include <linux/kfifo.h>\n#include <linux/bitops.h>\n\n#include \"hidma.h\"\n\n#define HIDMA_EVRE_SIZE\t\t\t16\t \n\n#define HIDMA_TRCA_CTRLSTS_REG\t\t\t0x000\n#define HIDMA_TRCA_RING_LOW_REG\t\t0x008\n#define HIDMA_TRCA_RING_HIGH_REG\t\t0x00C\n#define HIDMA_TRCA_RING_LEN_REG\t\t0x010\n#define HIDMA_TRCA_DOORBELL_REG\t\t0x400\n\n#define HIDMA_EVCA_CTRLSTS_REG\t\t\t0x000\n#define HIDMA_EVCA_INTCTRL_REG\t\t\t0x004\n#define HIDMA_EVCA_RING_LOW_REG\t\t0x008\n#define HIDMA_EVCA_RING_HIGH_REG\t\t0x00C\n#define HIDMA_EVCA_RING_LEN_REG\t\t0x010\n#define HIDMA_EVCA_WRITE_PTR_REG\t\t0x020\n#define HIDMA_EVCA_DOORBELL_REG\t\t0x400\n\n#define HIDMA_EVCA_IRQ_STAT_REG\t\t0x100\n#define HIDMA_EVCA_IRQ_CLR_REG\t\t\t0x108\n#define HIDMA_EVCA_IRQ_EN_REG\t\t\t0x110\n\n#define HIDMA_EVRE_CFG_IDX\t\t\t0\n\n#define HIDMA_EVRE_ERRINFO_BIT_POS\t\t24\n#define HIDMA_EVRE_CODE_BIT_POS\t\t28\n\n#define HIDMA_EVRE_ERRINFO_MASK\t\tGENMASK(3, 0)\n#define HIDMA_EVRE_CODE_MASK\t\t\tGENMASK(3, 0)\n\n#define HIDMA_CH_CONTROL_MASK\t\t\tGENMASK(7, 0)\n#define HIDMA_CH_STATE_MASK\t\t\tGENMASK(7, 0)\n#define HIDMA_CH_STATE_BIT_POS\t\t\t0x8\n\n#define HIDMA_IRQ_EV_CH_EOB_IRQ_BIT_POS\t0\n#define HIDMA_IRQ_EV_CH_WR_RESP_BIT_POS\t1\n#define HIDMA_IRQ_TR_CH_TRE_RD_RSP_ER_BIT_POS\t9\n#define HIDMA_IRQ_TR_CH_DATA_RD_ER_BIT_POS\t10\n#define HIDMA_IRQ_TR_CH_DATA_WR_ER_BIT_POS\t11\n#define HIDMA_IRQ_TR_CH_INVALID_TRE_BIT_POS\t14\n\n#define ENABLE_IRQS (BIT(HIDMA_IRQ_EV_CH_EOB_IRQ_BIT_POS)\t| \\\n\t\t     BIT(HIDMA_IRQ_EV_CH_WR_RESP_BIT_POS)\t| \\\n\t\t     BIT(HIDMA_IRQ_TR_CH_TRE_RD_RSP_ER_BIT_POS)\t| \\\n\t\t     BIT(HIDMA_IRQ_TR_CH_DATA_RD_ER_BIT_POS)\t| \\\n\t\t     BIT(HIDMA_IRQ_TR_CH_DATA_WR_ER_BIT_POS)\t| \\\n\t\t     BIT(HIDMA_IRQ_TR_CH_INVALID_TRE_BIT_POS))\n\n#define HIDMA_INCREMENT_ITERATOR(iter, size, ring_size)\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\titer += size;\t\t\t\t\t\t\\\n\tif (iter >= ring_size)\t\t\t\t\t\\\n\t\titer -= ring_size;\t\t\t\t\\\n} while (0)\n\n#define HIDMA_CH_STATE(val)\t\\\n\t((val >> HIDMA_CH_STATE_BIT_POS) & HIDMA_CH_STATE_MASK)\n\n#define HIDMA_ERR_INT_MASK\t\t\t\t\\\n\t(BIT(HIDMA_IRQ_TR_CH_INVALID_TRE_BIT_POS)   |\t\\\n\t BIT(HIDMA_IRQ_TR_CH_TRE_RD_RSP_ER_BIT_POS) |\t\\\n\t BIT(HIDMA_IRQ_EV_CH_WR_RESP_BIT_POS)\t    |\t\\\n\t BIT(HIDMA_IRQ_TR_CH_DATA_RD_ER_BIT_POS)    |\t\\\n\t BIT(HIDMA_IRQ_TR_CH_DATA_WR_ER_BIT_POS))\n\nenum ch_command {\n\tHIDMA_CH_DISABLE = 0,\n\tHIDMA_CH_ENABLE = 1,\n\tHIDMA_CH_SUSPEND = 2,\n\tHIDMA_CH_RESET = 9,\n};\n\nenum ch_state {\n\tHIDMA_CH_DISABLED = 0,\n\tHIDMA_CH_ENABLED = 1,\n\tHIDMA_CH_RUNNING = 2,\n\tHIDMA_CH_SUSPENDED = 3,\n\tHIDMA_CH_STOPPED = 4,\n};\n\nenum err_code {\n\tHIDMA_EVRE_STATUS_COMPLETE = 1,\n\tHIDMA_EVRE_STATUS_ERROR = 4,\n};\n\nstatic int hidma_is_chan_enabled(int state)\n{\n\tswitch (state) {\n\tcase HIDMA_CH_ENABLED:\n\tcase HIDMA_CH_RUNNING:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nvoid hidma_ll_free(struct hidma_lldev *lldev, u32 tre_ch)\n{\n\tstruct hidma_tre *tre;\n\n\tif (tre_ch >= lldev->nr_tres) {\n\t\tdev_err(lldev->dev, \"invalid TRE number in free:%d\", tre_ch);\n\t\treturn;\n\t}\n\n\ttre = &lldev->trepool[tre_ch];\n\tif (atomic_read(&tre->allocated) != true) {\n\t\tdev_err(lldev->dev, \"trying to free an unused TRE:%d\", tre_ch);\n\t\treturn;\n\t}\n\n\tatomic_set(&tre->allocated, 0);\n}\n\nint hidma_ll_request(struct hidma_lldev *lldev, u32 sig, const char *dev_name,\n\t\t     void (*callback)(void *data), void *data, u32 *tre_ch)\n{\n\tunsigned int i;\n\tstruct hidma_tre *tre;\n\tu32 *tre_local;\n\n\tif (!tre_ch || !lldev)\n\t\treturn -EINVAL;\n\n\t \n\tfor (i = 0; i < lldev->nr_tres - 1; i++) {\n\t\tif (atomic_add_unless(&lldev->trepool[i].allocated, 1, 1))\n\t\t\tbreak;\n\t}\n\n\tif (i == (lldev->nr_tres - 1))\n\t\treturn -ENOMEM;\n\n\ttre = &lldev->trepool[i];\n\ttre->dma_sig = sig;\n\ttre->dev_name = dev_name;\n\ttre->callback = callback;\n\ttre->data = data;\n\ttre->idx = i;\n\ttre->status = 0;\n\ttre->queued = 0;\n\ttre->err_code = 0;\n\ttre->err_info = 0;\n\ttre->lldev = lldev;\n\ttre_local = &tre->tre_local[0];\n\ttre_local[HIDMA_TRE_CFG_IDX] = (lldev->chidx & 0xFF) << 8;\n\ttre_local[HIDMA_TRE_CFG_IDX] |= BIT(16);\t \n\t*tre_ch = i;\n\tif (callback)\n\t\tcallback(data);\n\treturn 0;\n}\n\n \nstatic void hidma_ll_tre_complete(struct tasklet_struct *t)\n{\n\tstruct hidma_lldev *lldev = from_tasklet(lldev, t, task);\n\tstruct hidma_tre *tre;\n\n\twhile (kfifo_out(&lldev->handoff_fifo, &tre, 1)) {\n\t\t \n\t\tif (tre->callback)\n\t\t\ttre->callback(tre->data);\n\t}\n}\n\nstatic int hidma_post_completed(struct hidma_lldev *lldev, u8 err_info,\n\t\t\t\tu8 err_code)\n{\n\tstruct hidma_tre *tre;\n\tunsigned long flags;\n\tu32 tre_iterator;\n\n\tspin_lock_irqsave(&lldev->lock, flags);\n\n\ttre_iterator = lldev->tre_processed_off;\n\ttre = lldev->pending_tre_list[tre_iterator / HIDMA_TRE_SIZE];\n\tif (!tre) {\n\t\tspin_unlock_irqrestore(&lldev->lock, flags);\n\t\tdev_warn(lldev->dev, \"tre_index [%d] and tre out of sync\\n\",\n\t\t\t tre_iterator / HIDMA_TRE_SIZE);\n\t\treturn -EINVAL;\n\t}\n\tlldev->pending_tre_list[tre->tre_index] = NULL;\n\n\t \n\tif (atomic_dec_return(&lldev->pending_tre_count) < 0) {\n\t\tdev_warn(lldev->dev, \"tre count mismatch on completion\");\n\t\tatomic_set(&lldev->pending_tre_count, 0);\n\t}\n\n\tHIDMA_INCREMENT_ITERATOR(tre_iterator, HIDMA_TRE_SIZE,\n\t\t\t\t lldev->tre_ring_size);\n\tlldev->tre_processed_off = tre_iterator;\n\tspin_unlock_irqrestore(&lldev->lock, flags);\n\n\ttre->err_info = err_info;\n\ttre->err_code = err_code;\n\ttre->queued = 0;\n\n\tkfifo_put(&lldev->handoff_fifo, tre);\n\ttasklet_schedule(&lldev->task);\n\n\treturn 0;\n}\n\n \nstatic int hidma_handle_tre_completion(struct hidma_lldev *lldev)\n{\n\tu32 evre_ring_size = lldev->evre_ring_size;\n\tu32 err_info, err_code, evre_write_off;\n\tu32 evre_iterator;\n\tu32 num_completed = 0;\n\n\tevre_write_off = readl_relaxed(lldev->evca + HIDMA_EVCA_WRITE_PTR_REG);\n\tevre_iterator = lldev->evre_processed_off;\n\n\tif ((evre_write_off > evre_ring_size) ||\n\t    (evre_write_off % HIDMA_EVRE_SIZE)) {\n\t\tdev_err(lldev->dev, \"HW reports invalid EVRE write offset\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\twhile ((evre_iterator != evre_write_off)) {\n\t\tu32 *current_evre = lldev->evre_ring + evre_iterator;\n\t\tu32 cfg;\n\n\t\tcfg = current_evre[HIDMA_EVRE_CFG_IDX];\n\t\terr_info = cfg >> HIDMA_EVRE_ERRINFO_BIT_POS;\n\t\terr_info &= HIDMA_EVRE_ERRINFO_MASK;\n\t\terr_code =\n\t\t    (cfg >> HIDMA_EVRE_CODE_BIT_POS) & HIDMA_EVRE_CODE_MASK;\n\n\t\tif (hidma_post_completed(lldev, err_info, err_code))\n\t\t\tbreak;\n\n\t\tHIDMA_INCREMENT_ITERATOR(evre_iterator, HIDMA_EVRE_SIZE,\n\t\t\t\t\t evre_ring_size);\n\n\t\t \n\t\tevre_write_off =\n\t\t    readl_relaxed(lldev->evca + HIDMA_EVCA_WRITE_PTR_REG);\n\t\tnum_completed++;\n\n\t\t \n\t\tif (!hidma_ll_isenabled(lldev))\n\t\t\tbreak;\n\t}\n\n\tif (num_completed) {\n\t\tu32 evre_read_off = (lldev->evre_processed_off +\n\t\t\t\t     HIDMA_EVRE_SIZE * num_completed);\n\t\tevre_read_off = evre_read_off % evre_ring_size;\n\t\twritel(evre_read_off, lldev->evca + HIDMA_EVCA_DOORBELL_REG);\n\n\t\t \n\t\tlldev->evre_processed_off = evre_read_off;\n\t}\n\n\treturn num_completed;\n}\n\nvoid hidma_cleanup_pending_tre(struct hidma_lldev *lldev, u8 err_info,\n\t\t\t       u8 err_code)\n{\n\twhile (atomic_read(&lldev->pending_tre_count)) {\n\t\tif (hidma_post_completed(lldev, err_info, err_code))\n\t\t\tbreak;\n\t}\n}\n\nstatic int hidma_ll_reset(struct hidma_lldev *lldev)\n{\n\tu32 val;\n\tint ret;\n\n\tval = readl(lldev->trca + HIDMA_TRCA_CTRLSTS_REG);\n\tval &= ~(HIDMA_CH_CONTROL_MASK << 16);\n\tval |= HIDMA_CH_RESET << 16;\n\twritel(val, lldev->trca + HIDMA_TRCA_CTRLSTS_REG);\n\n\t \n\tret = readl_poll_timeout(lldev->trca + HIDMA_TRCA_CTRLSTS_REG, val,\n\t\t\t\t HIDMA_CH_STATE(val) == HIDMA_CH_DISABLED,\n\t\t\t\t 1000, 10000);\n\tif (ret) {\n\t\tdev_err(lldev->dev, \"transfer channel did not reset\\n\");\n\t\treturn ret;\n\t}\n\n\tval = readl(lldev->evca + HIDMA_EVCA_CTRLSTS_REG);\n\tval &= ~(HIDMA_CH_CONTROL_MASK << 16);\n\tval |= HIDMA_CH_RESET << 16;\n\twritel(val, lldev->evca + HIDMA_EVCA_CTRLSTS_REG);\n\n\t \n\tret = readl_poll_timeout(lldev->evca + HIDMA_EVCA_CTRLSTS_REG, val,\n\t\t\t\t HIDMA_CH_STATE(val) == HIDMA_CH_DISABLED,\n\t\t\t\t 1000, 10000);\n\tif (ret)\n\t\treturn ret;\n\n\tlldev->trch_state = HIDMA_CH_DISABLED;\n\tlldev->evch_state = HIDMA_CH_DISABLED;\n\treturn 0;\n}\n\n \nstatic void hidma_ll_int_handler_internal(struct hidma_lldev *lldev, int cause)\n{\n\tunsigned long irqflags;\n\n\tif (cause & HIDMA_ERR_INT_MASK) {\n\t\tdev_err(lldev->dev, \"error 0x%x, disabling...\\n\",\n\t\t\t\tcause);\n\n\t\t \n\t\twritel(cause, lldev->evca + HIDMA_EVCA_IRQ_CLR_REG);\n\n\t\t \n\t\thidma_ll_disable(lldev);\n\n\t\t \n\t\thidma_cleanup_pending_tre(lldev, 0xFF,\n\t\t\t\t\t  HIDMA_EVRE_STATUS_ERROR);\n\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&lldev->lock, irqflags);\n\twritel_relaxed(cause, lldev->evca + HIDMA_EVCA_IRQ_CLR_REG);\n\tspin_unlock_irqrestore(&lldev->lock, irqflags);\n\n\t \n\thidma_handle_tre_completion(lldev);\n}\n\nirqreturn_t hidma_ll_inthandler(int chirq, void *arg)\n{\n\tstruct hidma_lldev *lldev = arg;\n\tu32 status;\n\tu32 enable;\n\tu32 cause;\n\n\tstatus = readl_relaxed(lldev->evca + HIDMA_EVCA_IRQ_STAT_REG);\n\tenable = readl_relaxed(lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n\tcause = status & enable;\n\n\twhile (cause) {\n\t\thidma_ll_int_handler_internal(lldev, cause);\n\n\t\t \n\t\tstatus = readl_relaxed(lldev->evca + HIDMA_EVCA_IRQ_STAT_REG);\n\t\tenable = readl_relaxed(lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n\t\tcause = status & enable;\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nirqreturn_t hidma_ll_inthandler_msi(int chirq, void *arg, int cause)\n{\n\tstruct hidma_lldev *lldev = arg;\n\n\thidma_ll_int_handler_internal(lldev, cause);\n\treturn IRQ_HANDLED;\n}\n\nint hidma_ll_enable(struct hidma_lldev *lldev)\n{\n\tu32 val;\n\tint ret;\n\n\tval = readl(lldev->evca + HIDMA_EVCA_CTRLSTS_REG);\n\tval &= ~(HIDMA_CH_CONTROL_MASK << 16);\n\tval |= HIDMA_CH_ENABLE << 16;\n\twritel(val, lldev->evca + HIDMA_EVCA_CTRLSTS_REG);\n\n\tret = readl_poll_timeout(lldev->evca + HIDMA_EVCA_CTRLSTS_REG, val,\n\t\t\t\t hidma_is_chan_enabled(HIDMA_CH_STATE(val)),\n\t\t\t\t 1000, 10000);\n\tif (ret) {\n\t\tdev_err(lldev->dev, \"event channel did not get enabled\\n\");\n\t\treturn ret;\n\t}\n\n\tval = readl(lldev->trca + HIDMA_TRCA_CTRLSTS_REG);\n\tval &= ~(HIDMA_CH_CONTROL_MASK << 16);\n\tval |= HIDMA_CH_ENABLE << 16;\n\twritel(val, lldev->trca + HIDMA_TRCA_CTRLSTS_REG);\n\n\tret = readl_poll_timeout(lldev->trca + HIDMA_TRCA_CTRLSTS_REG, val,\n\t\t\t\t hidma_is_chan_enabled(HIDMA_CH_STATE(val)),\n\t\t\t\t 1000, 10000);\n\tif (ret) {\n\t\tdev_err(lldev->dev, \"transfer channel did not get enabled\\n\");\n\t\treturn ret;\n\t}\n\n\tlldev->trch_state = HIDMA_CH_ENABLED;\n\tlldev->evch_state = HIDMA_CH_ENABLED;\n\n\t \n\twritel(ENABLE_IRQS, lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n\n\treturn 0;\n}\n\nvoid hidma_ll_start(struct hidma_lldev *lldev)\n{\n\tunsigned long irqflags;\n\n\tspin_lock_irqsave(&lldev->lock, irqflags);\n\twritel(lldev->tre_write_offset, lldev->trca + HIDMA_TRCA_DOORBELL_REG);\n\tspin_unlock_irqrestore(&lldev->lock, irqflags);\n}\n\nbool hidma_ll_isenabled(struct hidma_lldev *lldev)\n{\n\tu32 val;\n\n\tval = readl(lldev->trca + HIDMA_TRCA_CTRLSTS_REG);\n\tlldev->trch_state = HIDMA_CH_STATE(val);\n\tval = readl(lldev->evca + HIDMA_EVCA_CTRLSTS_REG);\n\tlldev->evch_state = HIDMA_CH_STATE(val);\n\n\t \n\tif (hidma_is_chan_enabled(lldev->trch_state) &&\n\t    hidma_is_chan_enabled(lldev->evch_state))\n\t\treturn true;\n\n\treturn false;\n}\n\nvoid hidma_ll_queue_request(struct hidma_lldev *lldev, u32 tre_ch)\n{\n\tstruct hidma_tre *tre;\n\tunsigned long flags;\n\n\ttre = &lldev->trepool[tre_ch];\n\n\t \n\tspin_lock_irqsave(&lldev->lock, flags);\n\ttre->tre_index = lldev->tre_write_offset / HIDMA_TRE_SIZE;\n\tlldev->pending_tre_list[tre->tre_index] = tre;\n\tmemcpy(lldev->tre_ring + lldev->tre_write_offset,\n\t\t\t&tre->tre_local[0], HIDMA_TRE_SIZE);\n\ttre->err_code = 0;\n\ttre->err_info = 0;\n\ttre->queued = 1;\n\tatomic_inc(&lldev->pending_tre_count);\n\tlldev->tre_write_offset = (lldev->tre_write_offset + HIDMA_TRE_SIZE)\n\t\t\t\t\t% lldev->tre_ring_size;\n\tspin_unlock_irqrestore(&lldev->lock, flags);\n}\n\n \nint hidma_ll_disable(struct hidma_lldev *lldev)\n{\n\tu32 val;\n\tint ret;\n\n\t \n\tif (!hidma_ll_isenabled(lldev))\n\t\treturn 0;\n\n\tval = readl(lldev->trca + HIDMA_TRCA_CTRLSTS_REG);\n\tval &= ~(HIDMA_CH_CONTROL_MASK << 16);\n\tval |= HIDMA_CH_SUSPEND << 16;\n\twritel(val, lldev->trca + HIDMA_TRCA_CTRLSTS_REG);\n\n\t \n\tret = readl_poll_timeout(lldev->trca + HIDMA_TRCA_CTRLSTS_REG, val,\n\t\t\t\t HIDMA_CH_STATE(val) == HIDMA_CH_SUSPENDED,\n\t\t\t\t 1000, 10000);\n\tif (ret)\n\t\treturn ret;\n\n\tval = readl(lldev->evca + HIDMA_EVCA_CTRLSTS_REG);\n\tval &= ~(HIDMA_CH_CONTROL_MASK << 16);\n\tval |= HIDMA_CH_SUSPEND << 16;\n\twritel(val, lldev->evca + HIDMA_EVCA_CTRLSTS_REG);\n\n\t \n\tret = readl_poll_timeout(lldev->evca + HIDMA_EVCA_CTRLSTS_REG, val,\n\t\t\t\t HIDMA_CH_STATE(val) == HIDMA_CH_SUSPENDED,\n\t\t\t\t 1000, 10000);\n\tif (ret)\n\t\treturn ret;\n\n\tlldev->trch_state = HIDMA_CH_SUSPENDED;\n\tlldev->evch_state = HIDMA_CH_SUSPENDED;\n\n\t \n\twritel(0, lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n\treturn 0;\n}\n\nvoid hidma_ll_set_transfer_params(struct hidma_lldev *lldev, u32 tre_ch,\n\t\t\t\t  dma_addr_t src, dma_addr_t dest, u32 len,\n\t\t\t\t  u32 flags, u32 txntype)\n{\n\tstruct hidma_tre *tre;\n\tu32 *tre_local;\n\n\tif (tre_ch >= lldev->nr_tres) {\n\t\tdev_err(lldev->dev, \"invalid TRE number in transfer params:%d\",\n\t\t\ttre_ch);\n\t\treturn;\n\t}\n\n\ttre = &lldev->trepool[tre_ch];\n\tif (atomic_read(&tre->allocated) != true) {\n\t\tdev_err(lldev->dev, \"trying to set params on an unused TRE:%d\",\n\t\t\ttre_ch);\n\t\treturn;\n\t}\n\n\ttre_local = &tre->tre_local[0];\n\ttre_local[HIDMA_TRE_CFG_IDX] &= ~GENMASK(7, 0);\n\ttre_local[HIDMA_TRE_CFG_IDX] |= txntype;\n\ttre_local[HIDMA_TRE_LEN_IDX] = len;\n\ttre_local[HIDMA_TRE_SRC_LOW_IDX] = lower_32_bits(src);\n\ttre_local[HIDMA_TRE_SRC_HI_IDX] = upper_32_bits(src);\n\ttre_local[HIDMA_TRE_DEST_LOW_IDX] = lower_32_bits(dest);\n\ttre_local[HIDMA_TRE_DEST_HI_IDX] = upper_32_bits(dest);\n\ttre->int_flags = flags;\n}\n\n \nint hidma_ll_setup(struct hidma_lldev *lldev)\n{\n\tint rc;\n\tu64 addr;\n\tu32 val;\n\tu32 nr_tres = lldev->nr_tres;\n\n\tatomic_set(&lldev->pending_tre_count, 0);\n\tlldev->tre_processed_off = 0;\n\tlldev->evre_processed_off = 0;\n\tlldev->tre_write_offset = 0;\n\n\t \n\twritel(0, lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n\n\t \n\tval = readl(lldev->evca + HIDMA_EVCA_IRQ_STAT_REG);\n\twritel(val, lldev->evca + HIDMA_EVCA_IRQ_CLR_REG);\n\n\trc = hidma_ll_reset(lldev);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tval = readl(lldev->evca + HIDMA_EVCA_IRQ_STAT_REG);\n\twritel(val, lldev->evca + HIDMA_EVCA_IRQ_CLR_REG);\n\n\t \n\twritel(0, lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n\n\taddr = lldev->tre_dma;\n\twritel(lower_32_bits(addr), lldev->trca + HIDMA_TRCA_RING_LOW_REG);\n\twritel(upper_32_bits(addr), lldev->trca + HIDMA_TRCA_RING_HIGH_REG);\n\twritel(lldev->tre_ring_size, lldev->trca + HIDMA_TRCA_RING_LEN_REG);\n\n\taddr = lldev->evre_dma;\n\twritel(lower_32_bits(addr), lldev->evca + HIDMA_EVCA_RING_LOW_REG);\n\twritel(upper_32_bits(addr), lldev->evca + HIDMA_EVCA_RING_HIGH_REG);\n\twritel(HIDMA_EVRE_SIZE * nr_tres,\n\t\t\tlldev->evca + HIDMA_EVCA_RING_LEN_REG);\n\n\t \n\thidma_ll_setup_irq(lldev, lldev->msi_support);\n\n\trc = hidma_ll_enable(lldev);\n\tif (rc)\n\t\treturn rc;\n\n\treturn rc;\n}\n\nvoid hidma_ll_setup_irq(struct hidma_lldev *lldev, bool msi)\n{\n\tu32 val;\n\n\tlldev->msi_support = msi;\n\n\t \n\twritel(0, lldev->evca + HIDMA_EVCA_IRQ_CLR_REG);\n\twritel(0, lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n\n\t \n\tval = readl(lldev->evca + HIDMA_EVCA_INTCTRL_REG);\n\tval &= ~0xF;\n\tif (!lldev->msi_support)\n\t\tval = val | 0x1;\n\twritel(val, lldev->evca + HIDMA_EVCA_INTCTRL_REG);\n\n\t \n\twritel(ENABLE_IRQS, lldev->evca + HIDMA_EVCA_IRQ_CLR_REG);\n\twritel(ENABLE_IRQS, lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n}\n\nstruct hidma_lldev *hidma_ll_init(struct device *dev, u32 nr_tres,\n\t\t\t\t  void __iomem *trca, void __iomem *evca,\n\t\t\t\t  u8 chidx)\n{\n\tu32 required_bytes;\n\tstruct hidma_lldev *lldev;\n\tint rc;\n\tsize_t sz;\n\n\tif (!trca || !evca || !dev || !nr_tres)\n\t\treturn NULL;\n\n\t \n\tif (nr_tres < 4)\n\t\treturn NULL;\n\n\t \n\tnr_tres += 1;\n\n\tlldev = devm_kzalloc(dev, sizeof(struct hidma_lldev), GFP_KERNEL);\n\tif (!lldev)\n\t\treturn NULL;\n\n\tlldev->evca = evca;\n\tlldev->trca = trca;\n\tlldev->dev = dev;\n\tsz = sizeof(struct hidma_tre);\n\tlldev->trepool = devm_kcalloc(lldev->dev, nr_tres, sz, GFP_KERNEL);\n\tif (!lldev->trepool)\n\t\treturn NULL;\n\n\trequired_bytes = sizeof(lldev->pending_tre_list[0]);\n\tlldev->pending_tre_list = devm_kcalloc(dev, nr_tres, required_bytes,\n\t\t\t\t\t       GFP_KERNEL);\n\tif (!lldev->pending_tre_list)\n\t\treturn NULL;\n\n\tsz = (HIDMA_TRE_SIZE + 1) * nr_tres;\n\tlldev->tre_ring = dmam_alloc_coherent(dev, sz, &lldev->tre_dma,\n\t\t\t\t\t      GFP_KERNEL);\n\tif (!lldev->tre_ring)\n\t\treturn NULL;\n\n\tlldev->tre_ring_size = HIDMA_TRE_SIZE * nr_tres;\n\tlldev->nr_tres = nr_tres;\n\n\t \n\tif (!IS_ALIGNED(lldev->tre_dma, HIDMA_TRE_SIZE)) {\n\t\tu8 tre_ring_shift;\n\n\t\ttre_ring_shift = lldev->tre_dma % HIDMA_TRE_SIZE;\n\t\ttre_ring_shift = HIDMA_TRE_SIZE - tre_ring_shift;\n\t\tlldev->tre_dma += tre_ring_shift;\n\t\tlldev->tre_ring += tre_ring_shift;\n\t}\n\n\tsz = (HIDMA_EVRE_SIZE + 1) * nr_tres;\n\tlldev->evre_ring = dmam_alloc_coherent(dev, sz, &lldev->evre_dma,\n\t\t\t\t\t       GFP_KERNEL);\n\tif (!lldev->evre_ring)\n\t\treturn NULL;\n\n\tlldev->evre_ring_size = HIDMA_EVRE_SIZE * nr_tres;\n\n\t \n\tif (!IS_ALIGNED(lldev->evre_dma, HIDMA_EVRE_SIZE)) {\n\t\tu8 evre_ring_shift;\n\n\t\tevre_ring_shift = lldev->evre_dma % HIDMA_EVRE_SIZE;\n\t\tevre_ring_shift = HIDMA_EVRE_SIZE - evre_ring_shift;\n\t\tlldev->evre_dma += evre_ring_shift;\n\t\tlldev->evre_ring += evre_ring_shift;\n\t}\n\tlldev->nr_tres = nr_tres;\n\tlldev->chidx = chidx;\n\n\tsz = nr_tres * sizeof(struct hidma_tre *);\n\trc = kfifo_alloc(&lldev->handoff_fifo, sz, GFP_KERNEL);\n\tif (rc)\n\t\treturn NULL;\n\n\trc = hidma_ll_setup(lldev);\n\tif (rc)\n\t\treturn NULL;\n\n\tspin_lock_init(&lldev->lock);\n\ttasklet_setup(&lldev->task, hidma_ll_tre_complete);\n\tlldev->initialized = 1;\n\twritel(ENABLE_IRQS, lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n\treturn lldev;\n}\n\nint hidma_ll_uninit(struct hidma_lldev *lldev)\n{\n\tu32 required_bytes;\n\tint rc = 0;\n\tu32 val;\n\n\tif (!lldev)\n\t\treturn -ENODEV;\n\n\tif (!lldev->initialized)\n\t\treturn 0;\n\n\tlldev->initialized = 0;\n\n\trequired_bytes = sizeof(struct hidma_tre) * lldev->nr_tres;\n\ttasklet_kill(&lldev->task);\n\tmemset(lldev->trepool, 0, required_bytes);\n\tlldev->trepool = NULL;\n\tatomic_set(&lldev->pending_tre_count, 0);\n\tlldev->tre_write_offset = 0;\n\n\trc = hidma_ll_reset(lldev);\n\n\t \n\tval = readl(lldev->evca + HIDMA_EVCA_IRQ_STAT_REG);\n\twritel(val, lldev->evca + HIDMA_EVCA_IRQ_CLR_REG);\n\twritel(0, lldev->evca + HIDMA_EVCA_IRQ_EN_REG);\n\treturn rc;\n}\n\nenum dma_status hidma_ll_status(struct hidma_lldev *lldev, u32 tre_ch)\n{\n\tenum dma_status ret = DMA_ERROR;\n\tstruct hidma_tre *tre;\n\tunsigned long flags;\n\tu8 err_code;\n\n\tspin_lock_irqsave(&lldev->lock, flags);\n\n\ttre = &lldev->trepool[tre_ch];\n\terr_code = tre->err_code;\n\n\tif (err_code & HIDMA_EVRE_STATUS_COMPLETE)\n\t\tret = DMA_COMPLETE;\n\telse if (err_code & HIDMA_EVRE_STATUS_ERROR)\n\t\tret = DMA_ERROR;\n\telse\n\t\tret = DMA_IN_PROGRESS;\n\tspin_unlock_irqrestore(&lldev->lock, flags);\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}