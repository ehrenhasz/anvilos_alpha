{
  "module_name": "qcom_adm.c",
  "hash_id": "a147418d3c215292b621e8fa6c3b41159fc41f953bd1a8272cc23ca005f6fc4c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/qcom/qcom_adm.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/device.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/dma/qcom_adm.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/of_dma.h>\n#include <linux/platform_device.h>\n#include <linux/reset.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n\n#include \"../dmaengine.h\"\n#include \"../virt-dma.h\"\n\n \n#define ADM_CHAN_MULTI\t\t\t0x4\n#define ADM_CI_MULTI\t\t\t0x4\n#define ADM_CRCI_MULTI\t\t\t0x4\n#define ADM_EE_MULTI\t\t\t0x800\n#define ADM_CHAN_OFFS(chan)\t\t(ADM_CHAN_MULTI * (chan))\n#define ADM_EE_OFFS(ee)\t\t\t(ADM_EE_MULTI * (ee))\n#define ADM_CHAN_EE_OFFS(chan, ee)\t(ADM_CHAN_OFFS(chan) + ADM_EE_OFFS(ee))\n#define ADM_CHAN_OFFS(chan)\t\t(ADM_CHAN_MULTI * (chan))\n#define ADM_CI_OFFS(ci)\t\t\t(ADM_CHAN_OFF(ci))\n#define ADM_CH_CMD_PTR(chan, ee)\t(ADM_CHAN_EE_OFFS(chan, ee))\n#define ADM_CH_RSLT(chan, ee)\t\t(0x40 + ADM_CHAN_EE_OFFS(chan, ee))\n#define ADM_CH_FLUSH_STATE0(chan, ee)\t(0x80 + ADM_CHAN_EE_OFFS(chan, ee))\n#define ADM_CH_STATUS_SD(chan, ee)\t(0x200 + ADM_CHAN_EE_OFFS(chan, ee))\n#define ADM_CH_CONF(chan)\t\t(0x240 + ADM_CHAN_OFFS(chan))\n#define ADM_CH_RSLT_CONF(chan, ee)\t(0x300 + ADM_CHAN_EE_OFFS(chan, ee))\n#define ADM_SEC_DOMAIN_IRQ_STATUS(ee)\t(0x380 + ADM_EE_OFFS(ee))\n#define ADM_CI_CONF(ci)\t\t\t(0x390 + (ci) * ADM_CI_MULTI)\n#define ADM_GP_CTL\t\t\t0x3d8\n#define ADM_CRCI_CTL(crci, ee)\t\t(0x400 + (crci) * ADM_CRCI_MULTI + \\\n\t\t\t\t\t\tADM_EE_OFFS(ee))\n\n \n#define ADM_CH_STATUS_VALID\t\tBIT(1)\n\n \n#define ADM_CH_RSLT_VALID\t\tBIT(31)\n#define ADM_CH_RSLT_ERR\t\t\tBIT(3)\n#define ADM_CH_RSLT_FLUSH\t\tBIT(2)\n#define ADM_CH_RSLT_TPD\t\t\tBIT(1)\n\n \n#define ADM_CH_CONF_SHADOW_EN\t\tBIT(12)\n#define ADM_CH_CONF_MPU_DISABLE\t\tBIT(11)\n#define ADM_CH_CONF_PERM_MPU_CONF\tBIT(9)\n#define ADM_CH_CONF_FORCE_RSLT_EN\tBIT(7)\n#define ADM_CH_CONF_SEC_DOMAIN(ee)\t((((ee) & 0x3) << 4) | (((ee) & 0x4) << 11))\n\n \n#define ADM_CH_RSLT_CONF_FLUSH_EN\tBIT(1)\n#define ADM_CH_RSLT_CONF_IRQ_EN\t\tBIT(0)\n\n \n#define ADM_CRCI_CTL_MUX_SEL\t\tBIT(18)\n#define ADM_CRCI_CTL_RST\t\tBIT(17)\n\n \n#define ADM_CI_RANGE_END(x)\t\t((x) << 24)\n#define ADM_CI_RANGE_START(x)\t\t((x) << 16)\n#define ADM_CI_BURST_4_WORDS\t\tBIT(2)\n#define ADM_CI_BURST_8_WORDS\t\tBIT(3)\n\n \n#define ADM_GP_CTL_LP_EN\t\tBIT(12)\n#define ADM_GP_CTL_LP_CNT(x)\t\t((x) << 8)\n\n \n#define ADM_CPLE_LP\t\t\tBIT(31)\n#define ADM_CPLE_CMD_PTR_LIST\t\tBIT(29)\n\n \n#define ADM_CMD_LC\t\t\tBIT(31)\n#define ADM_CMD_DST_CRCI(n)\t\t(((n) & 0xf) << 7)\n#define ADM_CMD_SRC_CRCI(n)\t\t(((n) & 0xf) << 3)\n\n#define ADM_CMD_TYPE_SINGLE\t\t0x0\n#define ADM_CMD_TYPE_BOX\t\t0x3\n\n#define ADM_CRCI_MUX_SEL\t\tBIT(4)\n#define ADM_DESC_ALIGN\t\t\t8\n#define ADM_MAX_XFER\t\t\t(SZ_64K - 1)\n#define ADM_MAX_ROWS\t\t\t(SZ_64K - 1)\n#define ADM_MAX_CHANNELS\t\t16\n\nstruct adm_desc_hw_box {\n\tu32 cmd;\n\tu32 src_addr;\n\tu32 dst_addr;\n\tu32 row_len;\n\tu32 num_rows;\n\tu32 row_offset;\n};\n\nstruct adm_desc_hw_single {\n\tu32 cmd;\n\tu32 src_addr;\n\tu32 dst_addr;\n\tu32 len;\n};\n\nstruct adm_async_desc {\n\tstruct virt_dma_desc vd;\n\tstruct adm_device *adev;\n\n\tsize_t length;\n\tenum dma_transfer_direction dir;\n\tdma_addr_t dma_addr;\n\tsize_t dma_len;\n\n\tvoid *cpl;\n\tdma_addr_t cp_addr;\n\tu32 crci;\n\tu32 mux;\n\tu32 blk_size;\n};\n\nstruct adm_chan {\n\tstruct virt_dma_chan vc;\n\tstruct adm_device *adev;\n\n\t \n\tu32 id;\t\t\t \n\n\tstruct adm_async_desc *curr_txd;\n\tstruct dma_slave_config slave;\n\tu32 crci;\n\tu32 mux;\n\tstruct list_head node;\n\n\tint error;\n\tint initialized;\n};\n\nstatic inline struct adm_chan *to_adm_chan(struct dma_chan *common)\n{\n\treturn container_of(common, struct adm_chan, vc.chan);\n}\n\nstruct adm_device {\n\tvoid __iomem *regs;\n\tstruct device *dev;\n\tstruct dma_device common;\n\tstruct device_dma_parameters dma_parms;\n\tstruct adm_chan *channels;\n\n\tu32 ee;\n\n\tstruct clk *core_clk;\n\tstruct clk *iface_clk;\n\n\tstruct reset_control *clk_reset;\n\tstruct reset_control *c0_reset;\n\tstruct reset_control *c1_reset;\n\tstruct reset_control *c2_reset;\n\tint irq;\n};\n\n \nstatic void adm_free_chan(struct dma_chan *chan)\n{\n\t \n\tvchan_free_chan_resources(to_virt_chan(chan));\n}\n\n \nstatic int adm_get_blksize(unsigned int burst)\n{\n\tint ret;\n\n\tswitch (burst) {\n\tcase 16:\n\tcase 32:\n\tcase 64:\n\tcase 128:\n\t\tret = ffs(burst >> 4) - 1;\n\t\tbreak;\n\tcase 192:\n\t\tret = 4;\n\t\tbreak;\n\tcase 256:\n\t\tret = 5;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n \nstatic void *adm_process_fc_descriptors(struct adm_chan *achan, void *desc,\n\t\t\t\t\tstruct scatterlist *sg, u32 crci,\n\t\t\t\t\tu32 burst,\n\t\t\t\t\tenum dma_transfer_direction direction)\n{\n\tstruct adm_desc_hw_box *box_desc = NULL;\n\tstruct adm_desc_hw_single *single_desc;\n\tu32 remainder = sg_dma_len(sg);\n\tu32 rows, row_offset, crci_cmd;\n\tu32 mem_addr = sg_dma_address(sg);\n\tu32 *incr_addr = &mem_addr;\n\tu32 *src, *dst;\n\n\tif (direction == DMA_DEV_TO_MEM) {\n\t\tcrci_cmd = ADM_CMD_SRC_CRCI(crci);\n\t\trow_offset = burst;\n\t\tsrc = &achan->slave.src_addr;\n\t\tdst = &mem_addr;\n\t} else {\n\t\tcrci_cmd = ADM_CMD_DST_CRCI(crci);\n\t\trow_offset = burst << 16;\n\t\tsrc = &mem_addr;\n\t\tdst = &achan->slave.dst_addr;\n\t}\n\n\twhile (remainder >= burst) {\n\t\tbox_desc = desc;\n\t\tbox_desc->cmd = ADM_CMD_TYPE_BOX | crci_cmd;\n\t\tbox_desc->row_offset = row_offset;\n\t\tbox_desc->src_addr = *src;\n\t\tbox_desc->dst_addr = *dst;\n\n\t\trows = remainder / burst;\n\t\trows = min_t(u32, rows, ADM_MAX_ROWS);\n\t\tbox_desc->num_rows = rows << 16 | rows;\n\t\tbox_desc->row_len = burst << 16 | burst;\n\n\t\t*incr_addr += burst * rows;\n\t\tremainder -= burst * rows;\n\t\tdesc += sizeof(*box_desc);\n\t}\n\n\t \n\tif (remainder) {\n\t\tsingle_desc = desc;\n\t\tsingle_desc->cmd = ADM_CMD_TYPE_SINGLE | crci_cmd;\n\t\tsingle_desc->len = remainder;\n\t\tsingle_desc->src_addr = *src;\n\t\tsingle_desc->dst_addr = *dst;\n\t\tdesc += sizeof(*single_desc);\n\n\t\tif (sg_is_last(sg))\n\t\t\tsingle_desc->cmd |= ADM_CMD_LC;\n\t} else {\n\t\tif (box_desc && sg_is_last(sg))\n\t\t\tbox_desc->cmd |= ADM_CMD_LC;\n\t}\n\n\treturn desc;\n}\n\n \nstatic void *adm_process_non_fc_descriptors(struct adm_chan *achan, void *desc,\n\t\t\t\t\t    struct scatterlist *sg,\n\t\t\t\t\t    enum dma_transfer_direction direction)\n{\n\tstruct adm_desc_hw_single *single_desc;\n\tu32 remainder = sg_dma_len(sg);\n\tu32 mem_addr = sg_dma_address(sg);\n\tu32 *incr_addr = &mem_addr;\n\tu32 *src, *dst;\n\n\tif (direction == DMA_DEV_TO_MEM) {\n\t\tsrc = &achan->slave.src_addr;\n\t\tdst = &mem_addr;\n\t} else {\n\t\tsrc = &mem_addr;\n\t\tdst = &achan->slave.dst_addr;\n\t}\n\n\tdo {\n\t\tsingle_desc = desc;\n\t\tsingle_desc->cmd = ADM_CMD_TYPE_SINGLE;\n\t\tsingle_desc->src_addr = *src;\n\t\tsingle_desc->dst_addr = *dst;\n\t\tsingle_desc->len = (remainder > ADM_MAX_XFER) ?\n\t\t\t\tADM_MAX_XFER : remainder;\n\n\t\tremainder -= single_desc->len;\n\t\t*incr_addr += single_desc->len;\n\t\tdesc += sizeof(*single_desc);\n\t} while (remainder);\n\n\t \n\tif (sg_is_last(sg))\n\t\tsingle_desc->cmd |= ADM_CMD_LC;\n\n\treturn desc;\n}\n\n \nstatic struct dma_async_tx_descriptor *adm_prep_slave_sg(struct dma_chan *chan,\n\t\t\t\t\t\t\t struct scatterlist *sgl,\n\t\t\t\t\t\t\t unsigned int sg_len,\n\t\t\t\t\t\t\t enum dma_transfer_direction direction,\n\t\t\t\t\t\t\t unsigned long flags,\n\t\t\t\t\t\t\t void *context)\n{\n\tstruct adm_chan *achan = to_adm_chan(chan);\n\tstruct adm_device *adev = achan->adev;\n\tstruct adm_async_desc *async_desc;\n\tstruct scatterlist *sg;\n\tdma_addr_t cple_addr;\n\tu32 i, burst;\n\tu32 single_count = 0, box_count = 0, crci = 0;\n\tvoid *desc;\n\tu32 *cple;\n\tint blk_size = 0;\n\n\tif (!is_slave_direction(direction)) {\n\t\tdev_err(adev->dev, \"invalid dma direction\\n\");\n\t\treturn NULL;\n\t}\n\n\t \n\tburst = (direction == DMA_MEM_TO_DEV) ?\n\t\tachan->slave.dst_maxburst :\n\t\tachan->slave.src_maxburst;\n\n\t \n\tif (achan->slave.device_fc) {\n\t\tblk_size = adm_get_blksize(burst);\n\t\tif (blk_size < 0) {\n\t\t\tdev_err(adev->dev, \"invalid burst value: %d\\n\",\n\t\t\t\tburst);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tcrci = achan->crci & 0xf;\n\t\tif (!crci || achan->crci > 0x1f) {\n\t\t\tdev_err(adev->dev, \"invalid crci value\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t \n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tif (achan->slave.device_fc) {\n\t\t\tbox_count += DIV_ROUND_UP(sg_dma_len(sg) / burst,\n\t\t\t\t\t\t  ADM_MAX_ROWS);\n\t\t\tif (sg_dma_len(sg) % burst)\n\t\t\t\tsingle_count++;\n\t\t} else {\n\t\t\tsingle_count += DIV_ROUND_UP(sg_dma_len(sg),\n\t\t\t\t\t\t     ADM_MAX_XFER);\n\t\t}\n\t}\n\n\tasync_desc = kzalloc(sizeof(*async_desc), GFP_NOWAIT);\n\tif (!async_desc) {\n\t\tdev_err(adev->dev, \"not enough memory for async_desc struct\\n\");\n\t\treturn NULL;\n\t}\n\n\tasync_desc->mux = achan->mux ? ADM_CRCI_CTL_MUX_SEL : 0;\n\tasync_desc->crci = crci;\n\tasync_desc->blk_size = blk_size;\n\tasync_desc->dma_len = single_count * sizeof(struct adm_desc_hw_single) +\n\t\t\t\tbox_count * sizeof(struct adm_desc_hw_box) +\n\t\t\t\tsizeof(*cple) + 2 * ADM_DESC_ALIGN;\n\n\tasync_desc->cpl = kzalloc(async_desc->dma_len, GFP_NOWAIT);\n\tif (!async_desc->cpl) {\n\t\tdev_err(adev->dev, \"not enough memory for cpl struct\\n\");\n\t\tgoto free;\n\t}\n\n\tasync_desc->adev = adev;\n\n\t \n\tcple = PTR_ALIGN(async_desc->cpl, ADM_DESC_ALIGN);\n\tdesc = PTR_ALIGN(cple + 1, ADM_DESC_ALIGN);\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tasync_desc->length += sg_dma_len(sg);\n\n\t\tif (achan->slave.device_fc)\n\t\t\tdesc = adm_process_fc_descriptors(achan, desc, sg, crci,\n\t\t\t\t\t\t\t  burst, direction);\n\t\telse\n\t\t\tdesc = adm_process_non_fc_descriptors(achan, desc, sg,\n\t\t\t\t\t\t\t      direction);\n\t}\n\n\tasync_desc->dma_addr = dma_map_single(adev->dev, async_desc->cpl,\n\t\t\t\t\t      async_desc->dma_len,\n\t\t\t\t\t      DMA_TO_DEVICE);\n\tif (dma_mapping_error(adev->dev, async_desc->dma_addr)) {\n\t\tdev_err(adev->dev, \"dma mapping error for cpl\\n\");\n\t\tgoto free;\n\t}\n\n\tcple_addr = async_desc->dma_addr + ((void *)cple - async_desc->cpl);\n\n\t \n\tdma_sync_single_for_cpu(adev->dev, cple_addr, sizeof(*cple),\n\t\t\t\tDMA_TO_DEVICE);\n\t*cple = ADM_CPLE_LP;\n\t*cple |= (async_desc->dma_addr + ADM_DESC_ALIGN) >> 3;\n\tdma_sync_single_for_device(adev->dev, cple_addr, sizeof(*cple),\n\t\t\t\t   DMA_TO_DEVICE);\n\n\treturn vchan_tx_prep(&achan->vc, &async_desc->vd, flags);\n\nfree:\n\tkfree(async_desc);\n\treturn NULL;\n}\n\n \nstatic int adm_terminate_all(struct dma_chan *chan)\n{\n\tstruct adm_chan *achan = to_adm_chan(chan);\n\tstruct adm_device *adev = achan->adev;\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&achan->vc.lock, flags);\n\tvchan_get_all_descriptors(&achan->vc, &head);\n\n\t \n\twritel_relaxed(0x0,\n\t\t       adev->regs + ADM_CH_FLUSH_STATE0(achan->id, adev->ee));\n\n\tspin_unlock_irqrestore(&achan->vc.lock, flags);\n\n\tvchan_dma_desc_free_list(&achan->vc, &head);\n\n\treturn 0;\n}\n\nstatic int adm_slave_config(struct dma_chan *chan, struct dma_slave_config *cfg)\n{\n\tstruct adm_chan *achan = to_adm_chan(chan);\n\tstruct qcom_adm_peripheral_config *config = cfg->peripheral_config;\n\tunsigned long flag;\n\n\tspin_lock_irqsave(&achan->vc.lock, flag);\n\tmemcpy(&achan->slave, cfg, sizeof(struct dma_slave_config));\n\tif (cfg->peripheral_size == sizeof(*config))\n\t\tachan->crci = config->crci;\n\tspin_unlock_irqrestore(&achan->vc.lock, flag);\n\n\treturn 0;\n}\n\n \nstatic void adm_start_dma(struct adm_chan *achan)\n{\n\tstruct virt_dma_desc *vd = vchan_next_desc(&achan->vc);\n\tstruct adm_device *adev = achan->adev;\n\tstruct adm_async_desc *async_desc;\n\n\tlockdep_assert_held(&achan->vc.lock);\n\n\tif (!vd)\n\t\treturn;\n\n\tlist_del(&vd->node);\n\n\t \n\tasync_desc = container_of(vd, struct adm_async_desc, vd);\n\tachan->curr_txd = async_desc;\n\n\t \n\tachan->error = 0;\n\n\tif (!achan->initialized) {\n\t\t \n\t\twritel(ADM_CH_CONF_SHADOW_EN |\n\t\t       ADM_CH_CONF_PERM_MPU_CONF |\n\t\t       ADM_CH_CONF_MPU_DISABLE |\n\t\t       ADM_CH_CONF_SEC_DOMAIN(adev->ee),\n\t\t       adev->regs + ADM_CH_CONF(achan->id));\n\n\t\twritel(ADM_CH_RSLT_CONF_IRQ_EN | ADM_CH_RSLT_CONF_FLUSH_EN,\n\t\t       adev->regs + ADM_CH_RSLT_CONF(achan->id, adev->ee));\n\n\t\tachan->initialized = 1;\n\t}\n\n\t \n\tif (async_desc->crci) {\n\t\twritel(async_desc->mux | async_desc->blk_size,\n\t\t       adev->regs + ADM_CRCI_CTL(async_desc->crci, adev->ee));\n\t}\n\n\t \n\twmb();\n\n\t \n\twritel(ALIGN(async_desc->dma_addr, ADM_DESC_ALIGN) >> 3,\n\t       adev->regs + ADM_CH_CMD_PTR(achan->id, adev->ee));\n}\n\n \nstatic irqreturn_t adm_dma_irq(int irq, void *data)\n{\n\tstruct adm_device *adev = data;\n\tu32 srcs, i;\n\tstruct adm_async_desc *async_desc;\n\tunsigned long flags;\n\n\tsrcs = readl_relaxed(adev->regs +\n\t\t\tADM_SEC_DOMAIN_IRQ_STATUS(adev->ee));\n\n\tfor (i = 0; i < ADM_MAX_CHANNELS; i++) {\n\t\tstruct adm_chan *achan = &adev->channels[i];\n\t\tu32 status, result;\n\n\t\tif (srcs & BIT(i)) {\n\t\t\tstatus = readl_relaxed(adev->regs +\n\t\t\t\t\t       ADM_CH_STATUS_SD(i, adev->ee));\n\n\t\t\t \n\t\t\tif (!(status & ADM_CH_STATUS_VALID))\n\t\t\t\tcontinue;\n\n\t\t\tresult = readl_relaxed(adev->regs +\n\t\t\t\tADM_CH_RSLT(i, adev->ee));\n\n\t\t\t \n\t\t\tif (!(result & ADM_CH_RSLT_VALID))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (result & (ADM_CH_RSLT_ERR | ADM_CH_RSLT_FLUSH))\n\t\t\t\tachan->error = 1;\n\n\t\t\tspin_lock_irqsave(&achan->vc.lock, flags);\n\t\t\tasync_desc = achan->curr_txd;\n\n\t\t\tachan->curr_txd = NULL;\n\n\t\t\tif (async_desc) {\n\t\t\t\tvchan_cookie_complete(&async_desc->vd);\n\n\t\t\t\t \n\t\t\t\tadm_start_dma(achan);\n\t\t\t}\n\n\t\t\tspin_unlock_irqrestore(&achan->vc.lock, flags);\n\t\t}\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic enum dma_status adm_tx_status(struct dma_chan *chan, dma_cookie_t cookie,\n\t\t\t\t     struct dma_tx_state *txstate)\n{\n\tstruct adm_chan *achan = to_adm_chan(chan);\n\tstruct virt_dma_desc *vd;\n\tenum dma_status ret;\n\tunsigned long flags;\n\tsize_t residue = 0;\n\n\tret = dma_cookie_status(chan, cookie, txstate);\n\tif (ret == DMA_COMPLETE || !txstate)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&achan->vc.lock, flags);\n\n\tvd = vchan_find_desc(&achan->vc, cookie);\n\tif (vd)\n\t\tresidue = container_of(vd, struct adm_async_desc, vd)->length;\n\n\tspin_unlock_irqrestore(&achan->vc.lock, flags);\n\n\t \n\tdma_set_residue(txstate, residue);\n\n\tif (achan->error)\n\t\treturn DMA_ERROR;\n\n\treturn ret;\n}\n\n \nstatic void adm_issue_pending(struct dma_chan *chan)\n{\n\tstruct adm_chan *achan = to_adm_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&achan->vc.lock, flags);\n\n\tif (vchan_issue_pending(&achan->vc) && !achan->curr_txd)\n\t\tadm_start_dma(achan);\n\tspin_unlock_irqrestore(&achan->vc.lock, flags);\n}\n\n \nstatic void adm_dma_free_desc(struct virt_dma_desc *vd)\n{\n\tstruct adm_async_desc *async_desc = container_of(vd,\n\t\t\tstruct adm_async_desc, vd);\n\n\tdma_unmap_single(async_desc->adev->dev, async_desc->dma_addr,\n\t\t\t async_desc->dma_len, DMA_TO_DEVICE);\n\tkfree(async_desc->cpl);\n\tkfree(async_desc);\n}\n\nstatic void adm_channel_init(struct adm_device *adev, struct adm_chan *achan,\n\t\t\t     u32 index)\n{\n\tachan->id = index;\n\tachan->adev = adev;\n\n\tvchan_init(&achan->vc, &adev->common);\n\tachan->vc.desc_free = adm_dma_free_desc;\n}\n\n \nstatic struct dma_chan *adm_dma_xlate(struct of_phandle_args *dma_spec,\n\t\t\t       struct of_dma *ofdma)\n{\n\tstruct dma_device *dev = ofdma->of_dma_data;\n\tstruct dma_chan *chan, *candidate = NULL;\n\tstruct adm_chan *achan;\n\n\tif (!dev || dma_spec->args_count > 2)\n\t\treturn NULL;\n\n\tlist_for_each_entry(chan, &dev->channels, device_node)\n\t\tif (chan->chan_id == dma_spec->args[0]) {\n\t\t\tcandidate = chan;\n\t\t\tbreak;\n\t\t}\n\n\tif (!candidate)\n\t\treturn NULL;\n\n\tachan = to_adm_chan(candidate);\n\tif (dma_spec->args_count == 2)\n\t\tachan->crci = dma_spec->args[1];\n\telse\n\t\tachan->crci = 0;\n\n\treturn dma_get_slave_channel(candidate);\n}\n\nstatic int adm_dma_probe(struct platform_device *pdev)\n{\n\tstruct adm_device *adev;\n\tint ret;\n\tu32 i;\n\n\tadev = devm_kzalloc(&pdev->dev, sizeof(*adev), GFP_KERNEL);\n\tif (!adev)\n\t\treturn -ENOMEM;\n\n\tadev->dev = &pdev->dev;\n\n\tadev->regs = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(adev->regs))\n\t\treturn PTR_ERR(adev->regs);\n\n\tadev->irq = platform_get_irq(pdev, 0);\n\tif (adev->irq < 0)\n\t\treturn adev->irq;\n\n\tret = of_property_read_u32(pdev->dev.of_node, \"qcom,ee\", &adev->ee);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Execution environment unspecified\\n\");\n\t\treturn ret;\n\t}\n\n\tadev->core_clk = devm_clk_get(adev->dev, \"core\");\n\tif (IS_ERR(adev->core_clk))\n\t\treturn PTR_ERR(adev->core_clk);\n\n\tadev->iface_clk = devm_clk_get(adev->dev, \"iface\");\n\tif (IS_ERR(adev->iface_clk))\n\t\treturn PTR_ERR(adev->iface_clk);\n\n\tadev->clk_reset = devm_reset_control_get_exclusive(&pdev->dev, \"clk\");\n\tif (IS_ERR(adev->clk_reset)) {\n\t\tdev_err(adev->dev, \"failed to get ADM0 reset\\n\");\n\t\treturn PTR_ERR(adev->clk_reset);\n\t}\n\n\tadev->c0_reset = devm_reset_control_get_exclusive(&pdev->dev, \"c0\");\n\tif (IS_ERR(adev->c0_reset)) {\n\t\tdev_err(adev->dev, \"failed to get ADM0 C0 reset\\n\");\n\t\treturn PTR_ERR(adev->c0_reset);\n\t}\n\n\tadev->c1_reset = devm_reset_control_get_exclusive(&pdev->dev, \"c1\");\n\tif (IS_ERR(adev->c1_reset)) {\n\t\tdev_err(adev->dev, \"failed to get ADM0 C1 reset\\n\");\n\t\treturn PTR_ERR(adev->c1_reset);\n\t}\n\n\tadev->c2_reset = devm_reset_control_get_exclusive(&pdev->dev, \"c2\");\n\tif (IS_ERR(adev->c2_reset)) {\n\t\tdev_err(adev->dev, \"failed to get ADM0 C2 reset\\n\");\n\t\treturn PTR_ERR(adev->c2_reset);\n\t}\n\n\tret = clk_prepare_enable(adev->core_clk);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"failed to prepare/enable core clock\\n\");\n\t\treturn ret;\n\t}\n\n\tret = clk_prepare_enable(adev->iface_clk);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"failed to prepare/enable iface clock\\n\");\n\t\tgoto err_disable_core_clk;\n\t}\n\n\treset_control_assert(adev->clk_reset);\n\treset_control_assert(adev->c0_reset);\n\treset_control_assert(adev->c1_reset);\n\treset_control_assert(adev->c2_reset);\n\n\tudelay(2);\n\n\treset_control_deassert(adev->clk_reset);\n\treset_control_deassert(adev->c0_reset);\n\treset_control_deassert(adev->c1_reset);\n\treset_control_deassert(adev->c2_reset);\n\n\tadev->channels = devm_kcalloc(adev->dev, ADM_MAX_CHANNELS,\n\t\t\t\t      sizeof(*adev->channels), GFP_KERNEL);\n\n\tif (!adev->channels) {\n\t\tret = -ENOMEM;\n\t\tgoto err_disable_clks;\n\t}\n\n\t \n\tINIT_LIST_HEAD(&adev->common.channels);\n\n\tfor (i = 0; i < ADM_MAX_CHANNELS; i++)\n\t\tadm_channel_init(adev, &adev->channels[i], i);\n\n\t \n\tfor (i = 0; i < 16; i++)\n\t\twritel(ADM_CRCI_CTL_RST, adev->regs +\n\t\t\tADM_CRCI_CTL(i, adev->ee));\n\n\t \n\twritel(ADM_CI_RANGE_START(0x40) | ADM_CI_RANGE_END(0xb0) |\n\t       ADM_CI_BURST_8_WORDS, adev->regs + ADM_CI_CONF(0));\n\twritel(ADM_CI_RANGE_START(0x2a) | ADM_CI_RANGE_END(0x2c) |\n\t       ADM_CI_BURST_8_WORDS, adev->regs + ADM_CI_CONF(1));\n\twritel(ADM_CI_RANGE_START(0x12) | ADM_CI_RANGE_END(0x28) |\n\t       ADM_CI_BURST_8_WORDS, adev->regs + ADM_CI_CONF(2));\n\twritel(ADM_GP_CTL_LP_EN | ADM_GP_CTL_LP_CNT(0xf),\n\t       adev->regs + ADM_GP_CTL);\n\n\tret = devm_request_irq(adev->dev, adev->irq, adm_dma_irq,\n\t\t\t       0, \"adm_dma\", adev);\n\tif (ret)\n\t\tgoto err_disable_clks;\n\n\tplatform_set_drvdata(pdev, adev);\n\n\tadev->common.dev = adev->dev;\n\tadev->common.dev->dma_parms = &adev->dma_parms;\n\n\t \n\tdma_cap_zero(adev->common.cap_mask);\n\tdma_cap_set(DMA_SLAVE, adev->common.cap_mask);\n\tdma_cap_set(DMA_PRIVATE, adev->common.cap_mask);\n\n\t \n\tadev->common.directions = BIT(DMA_DEV_TO_MEM | DMA_MEM_TO_DEV);\n\tadev->common.residue_granularity = DMA_RESIDUE_GRANULARITY_DESCRIPTOR;\n\tadev->common.src_addr_widths = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\tadev->common.dst_addr_widths = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\tadev->common.device_free_chan_resources = adm_free_chan;\n\tadev->common.device_prep_slave_sg = adm_prep_slave_sg;\n\tadev->common.device_issue_pending = adm_issue_pending;\n\tadev->common.device_tx_status = adm_tx_status;\n\tadev->common.device_terminate_all = adm_terminate_all;\n\tadev->common.device_config = adm_slave_config;\n\n\tret = dma_async_device_register(&adev->common);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"failed to register dma async device\\n\");\n\t\tgoto err_disable_clks;\n\t}\n\n\tret = of_dma_controller_register(pdev->dev.of_node, adm_dma_xlate,\n\t\t\t\t\t &adev->common);\n\tif (ret)\n\t\tgoto err_unregister_dma;\n\n\treturn 0;\n\nerr_unregister_dma:\n\tdma_async_device_unregister(&adev->common);\nerr_disable_clks:\n\tclk_disable_unprepare(adev->iface_clk);\nerr_disable_core_clk:\n\tclk_disable_unprepare(adev->core_clk);\n\n\treturn ret;\n}\n\nstatic int adm_dma_remove(struct platform_device *pdev)\n{\n\tstruct adm_device *adev = platform_get_drvdata(pdev);\n\tstruct adm_chan *achan;\n\tu32 i;\n\n\tof_dma_controller_free(pdev->dev.of_node);\n\tdma_async_device_unregister(&adev->common);\n\n\tfor (i = 0; i < ADM_MAX_CHANNELS; i++) {\n\t\tachan = &adev->channels[i];\n\n\t\t \n\t\twritel(0, adev->regs + ADM_CH_RSLT_CONF(achan->id, adev->ee));\n\n\t\ttasklet_kill(&adev->channels[i].vc.task);\n\t\tadm_terminate_all(&adev->channels[i].vc.chan);\n\t}\n\n\tdevm_free_irq(adev->dev, adev->irq, adev);\n\n\tclk_disable_unprepare(adev->core_clk);\n\tclk_disable_unprepare(adev->iface_clk);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id adm_of_match[] = {\n\t{ .compatible = \"qcom,adm\", },\n\t{}\n};\nMODULE_DEVICE_TABLE(of, adm_of_match);\n\nstatic struct platform_driver adm_dma_driver = {\n\t.probe = adm_dma_probe,\n\t.remove = adm_dma_remove,\n\t.driver = {\n\t\t.name = \"adm-dma-engine\",\n\t\t.of_match_table = adm_of_match,\n\t},\n};\n\nmodule_platform_driver(adm_dma_driver);\n\nMODULE_AUTHOR(\"Andy Gross <agross@codeaurora.org>\");\nMODULE_DESCRIPTION(\"QCOM ADM DMA engine driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}