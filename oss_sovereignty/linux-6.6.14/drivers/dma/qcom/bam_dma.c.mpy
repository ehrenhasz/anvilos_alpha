{
  "module_name": "bam_dma.c",
  "hash_id": "f104b55b921cd2347205a25109774d5c00b118c94081e9a239c0ef05c82a2692",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/qcom/bam_dma.c",
  "human_readable_source": "\n \n \n\n#include <linux/kernel.h>\n#include <linux/io.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/dma-mapping.h>\n#include <linux/scatterlist.h>\n#include <linux/device.h>\n#include <linux/platform_device.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/of_dma.h>\n#include <linux/circ_buf.h>\n#include <linux/clk.h>\n#include <linux/dmaengine.h>\n#include <linux/pm_runtime.h>\n\n#include \"../dmaengine.h\"\n#include \"../virt-dma.h\"\n\nstruct bam_desc_hw {\n\t__le32 addr;\t\t \n\t__le16 size;\t\t \n\t__le16 flags;\n};\n\n#define BAM_DMA_AUTOSUSPEND_DELAY 100\n\n#define DESC_FLAG_INT BIT(15)\n#define DESC_FLAG_EOT BIT(14)\n#define DESC_FLAG_EOB BIT(13)\n#define DESC_FLAG_NWD BIT(12)\n#define DESC_FLAG_CMD BIT(11)\n\nstruct bam_async_desc {\n\tstruct virt_dma_desc vd;\n\n\tu32 num_desc;\n\tu32 xfer_len;\n\n\t \n\tu16 flags;\n\n\tstruct bam_desc_hw *curr_desc;\n\n\t \n\tstruct list_head desc_node;\n\tenum dma_transfer_direction dir;\n\tsize_t length;\n\tstruct bam_desc_hw desc[];\n};\n\nenum bam_reg {\n\tBAM_CTRL,\n\tBAM_REVISION,\n\tBAM_NUM_PIPES,\n\tBAM_DESC_CNT_TRSHLD,\n\tBAM_IRQ_SRCS,\n\tBAM_IRQ_SRCS_MSK,\n\tBAM_IRQ_SRCS_UNMASKED,\n\tBAM_IRQ_STTS,\n\tBAM_IRQ_CLR,\n\tBAM_IRQ_EN,\n\tBAM_CNFG_BITS,\n\tBAM_IRQ_SRCS_EE,\n\tBAM_IRQ_SRCS_MSK_EE,\n\tBAM_P_CTRL,\n\tBAM_P_RST,\n\tBAM_P_HALT,\n\tBAM_P_IRQ_STTS,\n\tBAM_P_IRQ_CLR,\n\tBAM_P_IRQ_EN,\n\tBAM_P_EVNT_DEST_ADDR,\n\tBAM_P_EVNT_REG,\n\tBAM_P_SW_OFSTS,\n\tBAM_P_DATA_FIFO_ADDR,\n\tBAM_P_DESC_FIFO_ADDR,\n\tBAM_P_EVNT_GEN_TRSHLD,\n\tBAM_P_FIFO_SIZES,\n};\n\nstruct reg_offset_data {\n\tu32 base_offset;\n\tunsigned int pipe_mult, evnt_mult, ee_mult;\n};\n\nstatic const struct reg_offset_data bam_v1_3_reg_info[] = {\n\t[BAM_CTRL]\t\t= { 0x0F80, 0x00, 0x00, 0x00 },\n\t[BAM_REVISION]\t\t= { 0x0F84, 0x00, 0x00, 0x00 },\n\t[BAM_NUM_PIPES]\t\t= { 0x0FBC, 0x00, 0x00, 0x00 },\n\t[BAM_DESC_CNT_TRSHLD]\t= { 0x0F88, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS]\t\t= { 0x0F8C, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS_MSK]\t= { 0x0F90, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS_UNMASKED]\t= { 0x0FB0, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_STTS]\t\t= { 0x0F94, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_CLR]\t\t= { 0x0F98, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_EN]\t\t= { 0x0F9C, 0x00, 0x00, 0x00 },\n\t[BAM_CNFG_BITS]\t\t= { 0x0FFC, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS_EE]\t= { 0x1800, 0x00, 0x00, 0x80 },\n\t[BAM_IRQ_SRCS_MSK_EE]\t= { 0x1804, 0x00, 0x00, 0x80 },\n\t[BAM_P_CTRL]\t\t= { 0x0000, 0x80, 0x00, 0x00 },\n\t[BAM_P_RST]\t\t= { 0x0004, 0x80, 0x00, 0x00 },\n\t[BAM_P_HALT]\t\t= { 0x0008, 0x80, 0x00, 0x00 },\n\t[BAM_P_IRQ_STTS]\t= { 0x0010, 0x80, 0x00, 0x00 },\n\t[BAM_P_IRQ_CLR]\t\t= { 0x0014, 0x80, 0x00, 0x00 },\n\t[BAM_P_IRQ_EN]\t\t= { 0x0018, 0x80, 0x00, 0x00 },\n\t[BAM_P_EVNT_DEST_ADDR]\t= { 0x102C, 0x00, 0x40, 0x00 },\n\t[BAM_P_EVNT_REG]\t= { 0x1018, 0x00, 0x40, 0x00 },\n\t[BAM_P_SW_OFSTS]\t= { 0x1000, 0x00, 0x40, 0x00 },\n\t[BAM_P_DATA_FIFO_ADDR]\t= { 0x1024, 0x00, 0x40, 0x00 },\n\t[BAM_P_DESC_FIFO_ADDR]\t= { 0x101C, 0x00, 0x40, 0x00 },\n\t[BAM_P_EVNT_GEN_TRSHLD]\t= { 0x1028, 0x00, 0x40, 0x00 },\n\t[BAM_P_FIFO_SIZES]\t= { 0x1020, 0x00, 0x40, 0x00 },\n};\n\nstatic const struct reg_offset_data bam_v1_4_reg_info[] = {\n\t[BAM_CTRL]\t\t= { 0x0000, 0x00, 0x00, 0x00 },\n\t[BAM_REVISION]\t\t= { 0x0004, 0x00, 0x00, 0x00 },\n\t[BAM_NUM_PIPES]\t\t= { 0x003C, 0x00, 0x00, 0x00 },\n\t[BAM_DESC_CNT_TRSHLD]\t= { 0x0008, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS]\t\t= { 0x000C, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS_MSK]\t= { 0x0010, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS_UNMASKED]\t= { 0x0030, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_STTS]\t\t= { 0x0014, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_CLR]\t\t= { 0x0018, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_EN]\t\t= { 0x001C, 0x00, 0x00, 0x00 },\n\t[BAM_CNFG_BITS]\t\t= { 0x007C, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS_EE]\t= { 0x0800, 0x00, 0x00, 0x80 },\n\t[BAM_IRQ_SRCS_MSK_EE]\t= { 0x0804, 0x00, 0x00, 0x80 },\n\t[BAM_P_CTRL]\t\t= { 0x1000, 0x1000, 0x00, 0x00 },\n\t[BAM_P_RST]\t\t= { 0x1004, 0x1000, 0x00, 0x00 },\n\t[BAM_P_HALT]\t\t= { 0x1008, 0x1000, 0x00, 0x00 },\n\t[BAM_P_IRQ_STTS]\t= { 0x1010, 0x1000, 0x00, 0x00 },\n\t[BAM_P_IRQ_CLR]\t\t= { 0x1014, 0x1000, 0x00, 0x00 },\n\t[BAM_P_IRQ_EN]\t\t= { 0x1018, 0x1000, 0x00, 0x00 },\n\t[BAM_P_EVNT_DEST_ADDR]\t= { 0x182C, 0x00, 0x1000, 0x00 },\n\t[BAM_P_EVNT_REG]\t= { 0x1818, 0x00, 0x1000, 0x00 },\n\t[BAM_P_SW_OFSTS]\t= { 0x1800, 0x00, 0x1000, 0x00 },\n\t[BAM_P_DATA_FIFO_ADDR]\t= { 0x1824, 0x00, 0x1000, 0x00 },\n\t[BAM_P_DESC_FIFO_ADDR]\t= { 0x181C, 0x00, 0x1000, 0x00 },\n\t[BAM_P_EVNT_GEN_TRSHLD]\t= { 0x1828, 0x00, 0x1000, 0x00 },\n\t[BAM_P_FIFO_SIZES]\t= { 0x1820, 0x00, 0x1000, 0x00 },\n};\n\nstatic const struct reg_offset_data bam_v1_7_reg_info[] = {\n\t[BAM_CTRL]\t\t= { 0x00000, 0x00, 0x00, 0x00 },\n\t[BAM_REVISION]\t\t= { 0x01000, 0x00, 0x00, 0x00 },\n\t[BAM_NUM_PIPES]\t\t= { 0x01008, 0x00, 0x00, 0x00 },\n\t[BAM_DESC_CNT_TRSHLD]\t= { 0x00008, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS]\t\t= { 0x03010, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS_MSK]\t= { 0x03014, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS_UNMASKED]\t= { 0x03018, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_STTS]\t\t= { 0x00014, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_CLR]\t\t= { 0x00018, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_EN]\t\t= { 0x0001C, 0x00, 0x00, 0x00 },\n\t[BAM_CNFG_BITS]\t\t= { 0x0007C, 0x00, 0x00, 0x00 },\n\t[BAM_IRQ_SRCS_EE]\t= { 0x03000, 0x00, 0x00, 0x1000 },\n\t[BAM_IRQ_SRCS_MSK_EE]\t= { 0x03004, 0x00, 0x00, 0x1000 },\n\t[BAM_P_CTRL]\t\t= { 0x13000, 0x1000, 0x00, 0x00 },\n\t[BAM_P_RST]\t\t= { 0x13004, 0x1000, 0x00, 0x00 },\n\t[BAM_P_HALT]\t\t= { 0x13008, 0x1000, 0x00, 0x00 },\n\t[BAM_P_IRQ_STTS]\t= { 0x13010, 0x1000, 0x00, 0x00 },\n\t[BAM_P_IRQ_CLR]\t\t= { 0x13014, 0x1000, 0x00, 0x00 },\n\t[BAM_P_IRQ_EN]\t\t= { 0x13018, 0x1000, 0x00, 0x00 },\n\t[BAM_P_EVNT_DEST_ADDR]\t= { 0x1382C, 0x00, 0x1000, 0x00 },\n\t[BAM_P_EVNT_REG]\t= { 0x13818, 0x00, 0x1000, 0x00 },\n\t[BAM_P_SW_OFSTS]\t= { 0x13800, 0x00, 0x1000, 0x00 },\n\t[BAM_P_DATA_FIFO_ADDR]\t= { 0x13824, 0x00, 0x1000, 0x00 },\n\t[BAM_P_DESC_FIFO_ADDR]\t= { 0x1381C, 0x00, 0x1000, 0x00 },\n\t[BAM_P_EVNT_GEN_TRSHLD]\t= { 0x13828, 0x00, 0x1000, 0x00 },\n\t[BAM_P_FIFO_SIZES]\t= { 0x13820, 0x00, 0x1000, 0x00 },\n};\n\n \n#define BAM_SW_RST\t\t\tBIT(0)\n#define BAM_EN\t\t\t\tBIT(1)\n#define BAM_EN_ACCUM\t\t\tBIT(4)\n#define BAM_TESTBUS_SEL_SHIFT\t\t5\n#define BAM_TESTBUS_SEL_MASK\t\t0x3F\n#define BAM_DESC_CACHE_SEL_SHIFT\t13\n#define BAM_DESC_CACHE_SEL_MASK\t\t0x3\n#define BAM_CACHED_DESC_STORE\t\tBIT(15)\n#define IBC_DISABLE\t\t\tBIT(16)\n\n \n#define REVISION_SHIFT\t\t0\n#define REVISION_MASK\t\t0xFF\n#define NUM_EES_SHIFT\t\t8\n#define NUM_EES_MASK\t\t0xF\n#define CE_BUFFER_SIZE\t\tBIT(13)\n#define AXI_ACTIVE\t\tBIT(14)\n#define USE_VMIDMT\t\tBIT(15)\n#define SECURED\t\t\tBIT(16)\n#define BAM_HAS_NO_BYPASS\tBIT(17)\n#define HIGH_FREQUENCY_BAM\tBIT(18)\n#define INACTIV_TMRS_EXST\tBIT(19)\n#define NUM_INACTIV_TMRS\tBIT(20)\n#define DESC_CACHE_DEPTH_SHIFT\t21\n#define DESC_CACHE_DEPTH_1\t(0 << DESC_CACHE_DEPTH_SHIFT)\n#define DESC_CACHE_DEPTH_2\t(1 << DESC_CACHE_DEPTH_SHIFT)\n#define DESC_CACHE_DEPTH_3\t(2 << DESC_CACHE_DEPTH_SHIFT)\n#define DESC_CACHE_DEPTH_4\t(3 << DESC_CACHE_DEPTH_SHIFT)\n#define CMD_DESC_EN\t\tBIT(23)\n#define INACTIV_TMR_BASE_SHIFT\t24\n#define INACTIV_TMR_BASE_MASK\t0xFF\n\n \n#define BAM_NUM_PIPES_SHIFT\t\t0\n#define BAM_NUM_PIPES_MASK\t\t0xFF\n#define PERIPH_NON_PIPE_GRP_SHIFT\t16\n#define PERIPH_NON_PIP_GRP_MASK\t\t0xFF\n#define BAM_NON_PIPE_GRP_SHIFT\t\t24\n#define BAM_NON_PIPE_GRP_MASK\t\t0xFF\n\n \n#define BAM_PIPE_CNFG\t\tBIT(2)\n#define BAM_FULL_PIPE\t\tBIT(11)\n#define BAM_NO_EXT_P_RST\tBIT(12)\n#define BAM_IBC_DISABLE\t\tBIT(13)\n#define BAM_SB_CLK_REQ\t\tBIT(14)\n#define BAM_PSM_CSW_REQ\t\tBIT(15)\n#define BAM_PSM_P_RES\t\tBIT(16)\n#define BAM_AU_P_RES\t\tBIT(17)\n#define BAM_SI_P_RES\t\tBIT(18)\n#define BAM_WB_P_RES\t\tBIT(19)\n#define BAM_WB_BLK_CSW\t\tBIT(20)\n#define BAM_WB_CSW_ACK_IDL\tBIT(21)\n#define BAM_WB_RETR_SVPNT\tBIT(22)\n#define BAM_WB_DSC_AVL_P_RST\tBIT(23)\n#define BAM_REG_P_EN\t\tBIT(24)\n#define BAM_PSM_P_HD_DATA\tBIT(25)\n#define BAM_AU_ACCUMED\t\tBIT(26)\n#define BAM_CMD_ENABLE\t\tBIT(27)\n\n#define BAM_CNFG_BITS_DEFAULT\t(BAM_PIPE_CNFG |\t\\\n\t\t\t\t BAM_NO_EXT_P_RST |\t\\\n\t\t\t\t BAM_IBC_DISABLE |\t\\\n\t\t\t\t BAM_SB_CLK_REQ |\t\\\n\t\t\t\t BAM_PSM_CSW_REQ |\t\\\n\t\t\t\t BAM_PSM_P_RES |\t\\\n\t\t\t\t BAM_AU_P_RES |\t\t\\\n\t\t\t\t BAM_SI_P_RES |\t\t\\\n\t\t\t\t BAM_WB_P_RES |\t\t\\\n\t\t\t\t BAM_WB_BLK_CSW |\t\\\n\t\t\t\t BAM_WB_CSW_ACK_IDL |\t\\\n\t\t\t\t BAM_WB_RETR_SVPNT |\t\\\n\t\t\t\t BAM_WB_DSC_AVL_P_RST |\t\\\n\t\t\t\t BAM_REG_P_EN |\t\t\\\n\t\t\t\t BAM_PSM_P_HD_DATA |\t\\\n\t\t\t\t BAM_AU_ACCUMED |\t\\\n\t\t\t\t BAM_CMD_ENABLE)\n\n \n#define P_EN\t\t\tBIT(1)\n#define P_DIRECTION\t\tBIT(3)\n#define P_SYS_STRM\t\tBIT(4)\n#define P_SYS_MODE\t\tBIT(5)\n#define P_AUTO_EOB\t\tBIT(6)\n#define P_AUTO_EOB_SEL_SHIFT\t7\n#define P_AUTO_EOB_SEL_512\t(0 << P_AUTO_EOB_SEL_SHIFT)\n#define P_AUTO_EOB_SEL_256\t(1 << P_AUTO_EOB_SEL_SHIFT)\n#define P_AUTO_EOB_SEL_128\t(2 << P_AUTO_EOB_SEL_SHIFT)\n#define P_AUTO_EOB_SEL_64\t(3 << P_AUTO_EOB_SEL_SHIFT)\n#define P_PREFETCH_LIMIT_SHIFT\t9\n#define P_PREFETCH_LIMIT_32\t(0 << P_PREFETCH_LIMIT_SHIFT)\n#define P_PREFETCH_LIMIT_16\t(1 << P_PREFETCH_LIMIT_SHIFT)\n#define P_PREFETCH_LIMIT_4\t(2 << P_PREFETCH_LIMIT_SHIFT)\n#define P_WRITE_NWD\t\tBIT(11)\n#define P_LOCK_GROUP_SHIFT\t16\n#define P_LOCK_GROUP_MASK\t0x1F\n\n \n#define CNT_TRSHLD\t\t0xffff\n#define DEFAULT_CNT_THRSHLD\t0x4\n\n \n#define BAM_IRQ\t\t\tBIT(31)\n#define P_IRQ\t\t\t0x7fffffff\n\n \n#define BAM_IRQ_MSK\t\tBAM_IRQ\n#define P_IRQ_MSK\t\tP_IRQ\n\n \n#define BAM_TIMER_IRQ\t\tBIT(4)\n#define BAM_EMPTY_IRQ\t\tBIT(3)\n#define BAM_ERROR_IRQ\t\tBIT(2)\n#define BAM_HRESP_ERR_IRQ\tBIT(1)\n\n \n#define BAM_TIMER_CLR\t\tBIT(4)\n#define BAM_EMPTY_CLR\t\tBIT(3)\n#define BAM_ERROR_CLR\t\tBIT(2)\n#define BAM_HRESP_ERR_CLR\tBIT(1)\n\n \n#define BAM_TIMER_EN\t\tBIT(4)\n#define BAM_EMPTY_EN\t\tBIT(3)\n#define BAM_ERROR_EN\t\tBIT(2)\n#define BAM_HRESP_ERR_EN\tBIT(1)\n\n \n#define P_PRCSD_DESC_EN\t\tBIT(0)\n#define P_TIMER_EN\t\tBIT(1)\n#define P_WAKE_EN\t\tBIT(2)\n#define P_OUT_OF_DESC_EN\tBIT(3)\n#define P_ERR_EN\t\tBIT(4)\n#define P_TRNSFR_END_EN\t\tBIT(5)\n#define P_DEFAULT_IRQS_EN\t(P_PRCSD_DESC_EN | P_ERR_EN | P_TRNSFR_END_EN)\n\n \n#define P_SW_OFSTS_MASK\t\t0xffff\n\n#define BAM_DESC_FIFO_SIZE\tSZ_32K\n#define MAX_DESCRIPTORS (BAM_DESC_FIFO_SIZE / sizeof(struct bam_desc_hw) - 1)\n#define BAM_FIFO_SIZE\t(SZ_32K - 8)\n#define IS_BUSY(chan)\t(CIRC_SPACE(bchan->tail, bchan->head,\\\n\t\t\t MAX_DESCRIPTORS + 1) == 0)\n\nstruct bam_chan {\n\tstruct virt_dma_chan vc;\n\n\tstruct bam_device *bdev;\n\n\t \n\tu32 id;\n\n\t \n\tstruct dma_slave_config slave;\n\n\t \n\tstruct bam_desc_hw *fifo_virt;\n\tdma_addr_t fifo_phys;\n\n\t \n\tunsigned short head;\t\t \n\tunsigned short tail;\t\t \n\n\tunsigned int initialized;\t \n\tunsigned int paused;\t\t \n\tunsigned int reconfigure;\t \n\t \n\tstruct list_head desc_list;\n\n\tstruct list_head node;\n};\n\nstatic inline struct bam_chan *to_bam_chan(struct dma_chan *common)\n{\n\treturn container_of(common, struct bam_chan, vc.chan);\n}\n\nstruct bam_device {\n\tvoid __iomem *regs;\n\tstruct device *dev;\n\tstruct dma_device common;\n\tstruct bam_chan *channels;\n\tu32 num_channels;\n\tu32 num_ees;\n\n\t \n\tu32 ee;\n\tbool controlled_remotely;\n\tbool powered_remotely;\n\tu32 active_channels;\n\n\tconst struct reg_offset_data *layout;\n\n\tstruct clk *bamclk;\n\tint irq;\n\n\t \n\tstruct tasklet_struct task;\n};\n\n \nstatic inline void __iomem *bam_addr(struct bam_device *bdev, u32 pipe,\n\t\tenum bam_reg reg)\n{\n\tconst struct reg_offset_data r = bdev->layout[reg];\n\n\treturn bdev->regs + r.base_offset +\n\t\tr.pipe_mult * pipe +\n\t\tr.evnt_mult * pipe +\n\t\tr.ee_mult * bdev->ee;\n}\n\n \nstatic void bam_reset(struct bam_device *bdev)\n{\n\tu32 val;\n\n\t \n\t \n\tval = readl_relaxed(bam_addr(bdev, 0, BAM_CTRL));\n\tval |= BAM_SW_RST;\n\twritel_relaxed(val, bam_addr(bdev, 0, BAM_CTRL));\n\tval &= ~BAM_SW_RST;\n\twritel_relaxed(val, bam_addr(bdev, 0, BAM_CTRL));\n\n\t \n\twmb();\n\n\t \n\tval |= BAM_EN;\n\twritel_relaxed(val, bam_addr(bdev, 0, BAM_CTRL));\n\n\t \n\twritel_relaxed(DEFAULT_CNT_THRSHLD,\n\t\t\tbam_addr(bdev, 0, BAM_DESC_CNT_TRSHLD));\n\n\t \n\twritel_relaxed(BAM_CNFG_BITS_DEFAULT, bam_addr(bdev, 0, BAM_CNFG_BITS));\n\n\t \n\twritel_relaxed(BAM_ERROR_EN | BAM_HRESP_ERR_EN,\n\t\t\tbam_addr(bdev, 0, BAM_IRQ_EN));\n\n\t \n\twritel_relaxed(BAM_IRQ_MSK, bam_addr(bdev, 0, BAM_IRQ_SRCS_MSK_EE));\n}\n\n \nstatic void bam_reset_channel(struct bam_chan *bchan)\n{\n\tstruct bam_device *bdev = bchan->bdev;\n\n\tlockdep_assert_held(&bchan->vc.lock);\n\n\t \n\twritel_relaxed(1, bam_addr(bdev, bchan->id, BAM_P_RST));\n\twritel_relaxed(0, bam_addr(bdev, bchan->id, BAM_P_RST));\n\n\t \n\twmb();\n\n\t \n\tbchan->initialized = 0;\n}\n\n \nstatic void bam_chan_init_hw(struct bam_chan *bchan,\n\tenum dma_transfer_direction dir)\n{\n\tstruct bam_device *bdev = bchan->bdev;\n\tu32 val;\n\n\t \n\tbam_reset_channel(bchan);\n\n\t \n\twritel_relaxed(ALIGN(bchan->fifo_phys, sizeof(struct bam_desc_hw)),\n\t\t\tbam_addr(bdev, bchan->id, BAM_P_DESC_FIFO_ADDR));\n\twritel_relaxed(BAM_FIFO_SIZE,\n\t\t\tbam_addr(bdev, bchan->id, BAM_P_FIFO_SIZES));\n\n\t \n\twritel_relaxed(P_DEFAULT_IRQS_EN,\n\t\t\tbam_addr(bdev, bchan->id, BAM_P_IRQ_EN));\n\n\t \n\tval = readl_relaxed(bam_addr(bdev, 0, BAM_IRQ_SRCS_MSK_EE));\n\tval |= BIT(bchan->id);\n\twritel_relaxed(val, bam_addr(bdev, 0, BAM_IRQ_SRCS_MSK_EE));\n\n\t \n\twmb();\n\n\t \n\tval = P_EN | P_SYS_MODE;\n\tif (dir == DMA_DEV_TO_MEM)\n\t\tval |= P_DIRECTION;\n\n\twritel_relaxed(val, bam_addr(bdev, bchan->id, BAM_P_CTRL));\n\n\tbchan->initialized = 1;\n\n\t \n\tbchan->head = 0;\n\tbchan->tail = 0;\n}\n\n \nstatic int bam_alloc_chan(struct dma_chan *chan)\n{\n\tstruct bam_chan *bchan = to_bam_chan(chan);\n\tstruct bam_device *bdev = bchan->bdev;\n\n\tif (bchan->fifo_virt)\n\t\treturn 0;\n\n\t \n\tbchan->fifo_virt = dma_alloc_wc(bdev->dev, BAM_DESC_FIFO_SIZE,\n\t\t\t\t\t&bchan->fifo_phys, GFP_KERNEL);\n\n\tif (!bchan->fifo_virt) {\n\t\tdev_err(bdev->dev, \"Failed to allocate desc fifo\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (bdev->active_channels++ == 0 && bdev->powered_remotely)\n\t\tbam_reset(bdev);\n\n\treturn 0;\n}\n\n \nstatic void bam_free_chan(struct dma_chan *chan)\n{\n\tstruct bam_chan *bchan = to_bam_chan(chan);\n\tstruct bam_device *bdev = bchan->bdev;\n\tu32 val;\n\tunsigned long flags;\n\tint ret;\n\n\tret = pm_runtime_get_sync(bdev->dev);\n\tif (ret < 0)\n\t\treturn;\n\n\tvchan_free_chan_resources(to_virt_chan(chan));\n\n\tif (!list_empty(&bchan->desc_list)) {\n\t\tdev_err(bchan->bdev->dev, \"Cannot free busy channel\\n\");\n\t\tgoto err;\n\t}\n\n\tspin_lock_irqsave(&bchan->vc.lock, flags);\n\tbam_reset_channel(bchan);\n\tspin_unlock_irqrestore(&bchan->vc.lock, flags);\n\n\tdma_free_wc(bdev->dev, BAM_DESC_FIFO_SIZE, bchan->fifo_virt,\n\t\t    bchan->fifo_phys);\n\tbchan->fifo_virt = NULL;\n\n\t \n\tval = readl_relaxed(bam_addr(bdev, 0, BAM_IRQ_SRCS_MSK_EE));\n\tval &= ~BIT(bchan->id);\n\twritel_relaxed(val, bam_addr(bdev, 0, BAM_IRQ_SRCS_MSK_EE));\n\n\t \n\twritel_relaxed(0, bam_addr(bdev, bchan->id, BAM_P_IRQ_EN));\n\n\tif (--bdev->active_channels == 0 && bdev->powered_remotely) {\n\t\t \n\t\tval = readl_relaxed(bam_addr(bdev, 0, BAM_CTRL));\n\t\tval |= BAM_SW_RST;\n\t\twritel_relaxed(val, bam_addr(bdev, 0, BAM_CTRL));\n\t}\n\nerr:\n\tpm_runtime_mark_last_busy(bdev->dev);\n\tpm_runtime_put_autosuspend(bdev->dev);\n}\n\n \nstatic int bam_slave_config(struct dma_chan *chan,\n\t\t\t    struct dma_slave_config *cfg)\n{\n\tstruct bam_chan *bchan = to_bam_chan(chan);\n\tunsigned long flag;\n\n\tspin_lock_irqsave(&bchan->vc.lock, flag);\n\tmemcpy(&bchan->slave, cfg, sizeof(*cfg));\n\tbchan->reconfigure = 1;\n\tspin_unlock_irqrestore(&bchan->vc.lock, flag);\n\n\treturn 0;\n}\n\n \nstatic struct dma_async_tx_descriptor *bam_prep_slave_sg(struct dma_chan *chan,\n\tstruct scatterlist *sgl, unsigned int sg_len,\n\tenum dma_transfer_direction direction, unsigned long flags,\n\tvoid *context)\n{\n\tstruct bam_chan *bchan = to_bam_chan(chan);\n\tstruct bam_device *bdev = bchan->bdev;\n\tstruct bam_async_desc *async_desc;\n\tstruct scatterlist *sg;\n\tu32 i;\n\tstruct bam_desc_hw *desc;\n\tunsigned int num_alloc = 0;\n\n\n\tif (!is_slave_direction(direction)) {\n\t\tdev_err(bdev->dev, \"invalid dma direction\\n\");\n\t\treturn NULL;\n\t}\n\n\t \n\tfor_each_sg(sgl, sg, sg_len, i)\n\t\tnum_alloc += DIV_ROUND_UP(sg_dma_len(sg), BAM_FIFO_SIZE);\n\n\t \n\tasync_desc = kzalloc(struct_size(async_desc, desc, num_alloc),\n\t\t\t     GFP_NOWAIT);\n\n\tif (!async_desc)\n\t\treturn NULL;\n\n\tif (flags & DMA_PREP_FENCE)\n\t\tasync_desc->flags |= DESC_FLAG_NWD;\n\n\tif (flags & DMA_PREP_INTERRUPT)\n\t\tasync_desc->flags |= DESC_FLAG_EOT;\n\n\tasync_desc->num_desc = num_alloc;\n\tasync_desc->curr_desc = async_desc->desc;\n\tasync_desc->dir = direction;\n\n\t \n\tdesc = async_desc->desc;\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tunsigned int remainder = sg_dma_len(sg);\n\t\tunsigned int curr_offset = 0;\n\n\t\tdo {\n\t\t\tif (flags & DMA_PREP_CMD)\n\t\t\t\tdesc->flags |= cpu_to_le16(DESC_FLAG_CMD);\n\n\t\t\tdesc->addr = cpu_to_le32(sg_dma_address(sg) +\n\t\t\t\t\t\t curr_offset);\n\n\t\t\tif (remainder > BAM_FIFO_SIZE) {\n\t\t\t\tdesc->size = cpu_to_le16(BAM_FIFO_SIZE);\n\t\t\t\tremainder -= BAM_FIFO_SIZE;\n\t\t\t\tcurr_offset += BAM_FIFO_SIZE;\n\t\t\t} else {\n\t\t\t\tdesc->size = cpu_to_le16(remainder);\n\t\t\t\tremainder = 0;\n\t\t\t}\n\n\t\t\tasync_desc->length += le16_to_cpu(desc->size);\n\t\t\tdesc++;\n\t\t} while (remainder > 0);\n\t}\n\n\treturn vchan_tx_prep(&bchan->vc, &async_desc->vd, flags);\n}\n\n \nstatic int bam_dma_terminate_all(struct dma_chan *chan)\n{\n\tstruct bam_chan *bchan = to_bam_chan(chan);\n\tstruct bam_async_desc *async_desc, *tmp;\n\tunsigned long flag;\n\tLIST_HEAD(head);\n\n\t \n\tspin_lock_irqsave(&bchan->vc.lock, flag);\n\t \n\tif (!list_empty(&bchan->desc_list)) {\n\t\tasync_desc = list_first_entry(&bchan->desc_list,\n\t\t\t\t\t      struct bam_async_desc, desc_node);\n\t\tbam_chan_init_hw(bchan, async_desc->dir);\n\t}\n\n\tlist_for_each_entry_safe(async_desc, tmp,\n\t\t\t\t &bchan->desc_list, desc_node) {\n\t\tlist_add(&async_desc->vd.node, &bchan->vc.desc_issued);\n\t\tlist_del(&async_desc->desc_node);\n\t}\n\n\tvchan_get_all_descriptors(&bchan->vc, &head);\n\tspin_unlock_irqrestore(&bchan->vc.lock, flag);\n\n\tvchan_dma_desc_free_list(&bchan->vc, &head);\n\n\treturn 0;\n}\n\n \nstatic int bam_pause(struct dma_chan *chan)\n{\n\tstruct bam_chan *bchan = to_bam_chan(chan);\n\tstruct bam_device *bdev = bchan->bdev;\n\tunsigned long flag;\n\tint ret;\n\n\tret = pm_runtime_get_sync(bdev->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&bchan->vc.lock, flag);\n\twritel_relaxed(1, bam_addr(bdev, bchan->id, BAM_P_HALT));\n\tbchan->paused = 1;\n\tspin_unlock_irqrestore(&bchan->vc.lock, flag);\n\tpm_runtime_mark_last_busy(bdev->dev);\n\tpm_runtime_put_autosuspend(bdev->dev);\n\n\treturn 0;\n}\n\n \nstatic int bam_resume(struct dma_chan *chan)\n{\n\tstruct bam_chan *bchan = to_bam_chan(chan);\n\tstruct bam_device *bdev = bchan->bdev;\n\tunsigned long flag;\n\tint ret;\n\n\tret = pm_runtime_get_sync(bdev->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&bchan->vc.lock, flag);\n\twritel_relaxed(0, bam_addr(bdev, bchan->id, BAM_P_HALT));\n\tbchan->paused = 0;\n\tspin_unlock_irqrestore(&bchan->vc.lock, flag);\n\tpm_runtime_mark_last_busy(bdev->dev);\n\tpm_runtime_put_autosuspend(bdev->dev);\n\n\treturn 0;\n}\n\n \nstatic u32 process_channel_irqs(struct bam_device *bdev)\n{\n\tu32 i, srcs, pipe_stts, offset, avail;\n\tunsigned long flags;\n\tstruct bam_async_desc *async_desc, *tmp;\n\n\tsrcs = readl_relaxed(bam_addr(bdev, 0, BAM_IRQ_SRCS_EE));\n\n\t \n\tif (!(srcs & P_IRQ))\n\t\treturn srcs;\n\n\tfor (i = 0; i < bdev->num_channels; i++) {\n\t\tstruct bam_chan *bchan = &bdev->channels[i];\n\n\t\tif (!(srcs & BIT(i)))\n\t\t\tcontinue;\n\n\t\t \n\t\tpipe_stts = readl_relaxed(bam_addr(bdev, i, BAM_P_IRQ_STTS));\n\n\t\twritel_relaxed(pipe_stts, bam_addr(bdev, i, BAM_P_IRQ_CLR));\n\n\t\tspin_lock_irqsave(&bchan->vc.lock, flags);\n\n\t\toffset = readl_relaxed(bam_addr(bdev, i, BAM_P_SW_OFSTS)) &\n\t\t\t\t       P_SW_OFSTS_MASK;\n\t\toffset /= sizeof(struct bam_desc_hw);\n\n\t\t \n\t\tavail = CIRC_CNT(offset, bchan->head, MAX_DESCRIPTORS + 1);\n\n\t\tif (offset < bchan->head)\n\t\t\tavail--;\n\n\t\tlist_for_each_entry_safe(async_desc, tmp,\n\t\t\t\t\t &bchan->desc_list, desc_node) {\n\t\t\t \n\t\t\tif (avail < async_desc->xfer_len)\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\tbchan->head += async_desc->xfer_len;\n\t\t\tbchan->head %= MAX_DESCRIPTORS;\n\n\t\t\tasync_desc->num_desc -= async_desc->xfer_len;\n\t\t\tasync_desc->curr_desc += async_desc->xfer_len;\n\t\t\tavail -= async_desc->xfer_len;\n\n\t\t\t \n\t\t\tif (!async_desc->num_desc) {\n\t\t\t\tvchan_cookie_complete(&async_desc->vd);\n\t\t\t} else {\n\t\t\t\tlist_add(&async_desc->vd.node,\n\t\t\t\t\t &bchan->vc.desc_issued);\n\t\t\t}\n\t\t\tlist_del(&async_desc->desc_node);\n\t\t}\n\n\t\tspin_unlock_irqrestore(&bchan->vc.lock, flags);\n\t}\n\n\treturn srcs;\n}\n\n \nstatic irqreturn_t bam_dma_irq(int irq, void *data)\n{\n\tstruct bam_device *bdev = data;\n\tu32 clr_mask = 0, srcs = 0;\n\tint ret;\n\n\tsrcs |= process_channel_irqs(bdev);\n\n\t \n\tif (srcs & P_IRQ)\n\t\ttasklet_schedule(&bdev->task);\n\n\tret = pm_runtime_get_sync(bdev->dev);\n\tif (ret < 0)\n\t\treturn IRQ_NONE;\n\n\tif (srcs & BAM_IRQ) {\n\t\tclr_mask = readl_relaxed(bam_addr(bdev, 0, BAM_IRQ_STTS));\n\n\t\t \n\t\tmb();\n\n\t\twritel_relaxed(clr_mask, bam_addr(bdev, 0, BAM_IRQ_CLR));\n\t}\n\n\tpm_runtime_mark_last_busy(bdev->dev);\n\tpm_runtime_put_autosuspend(bdev->dev);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic enum dma_status bam_tx_status(struct dma_chan *chan, dma_cookie_t cookie,\n\t\tstruct dma_tx_state *txstate)\n{\n\tstruct bam_chan *bchan = to_bam_chan(chan);\n\tstruct bam_async_desc *async_desc;\n\tstruct virt_dma_desc *vd;\n\tint ret;\n\tsize_t residue = 0;\n\tunsigned int i;\n\tunsigned long flags;\n\n\tret = dma_cookie_status(chan, cookie, txstate);\n\tif (ret == DMA_COMPLETE)\n\t\treturn ret;\n\n\tif (!txstate)\n\t\treturn bchan->paused ? DMA_PAUSED : ret;\n\n\tspin_lock_irqsave(&bchan->vc.lock, flags);\n\tvd = vchan_find_desc(&bchan->vc, cookie);\n\tif (vd) {\n\t\tresidue = container_of(vd, struct bam_async_desc, vd)->length;\n\t} else {\n\t\tlist_for_each_entry(async_desc, &bchan->desc_list, desc_node) {\n\t\t\tif (async_desc->vd.tx.cookie != cookie)\n\t\t\t\tcontinue;\n\n\t\t\tfor (i = 0; i < async_desc->num_desc; i++)\n\t\t\t\tresidue += le16_to_cpu(\n\t\t\t\t\t\tasync_desc->curr_desc[i].size);\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&bchan->vc.lock, flags);\n\n\tdma_set_residue(txstate, residue);\n\n\tif (ret == DMA_IN_PROGRESS && bchan->paused)\n\t\tret = DMA_PAUSED;\n\n\treturn ret;\n}\n\n \nstatic void bam_apply_new_config(struct bam_chan *bchan,\n\tenum dma_transfer_direction dir)\n{\n\tstruct bam_device *bdev = bchan->bdev;\n\tu32 maxburst;\n\n\tif (!bdev->controlled_remotely) {\n\t\tif (dir == DMA_DEV_TO_MEM)\n\t\t\tmaxburst = bchan->slave.src_maxburst;\n\t\telse\n\t\t\tmaxburst = bchan->slave.dst_maxburst;\n\n\t\twritel_relaxed(maxburst,\n\t\t\t       bam_addr(bdev, 0, BAM_DESC_CNT_TRSHLD));\n\t}\n\n\tbchan->reconfigure = 0;\n}\n\n \nstatic void bam_start_dma(struct bam_chan *bchan)\n{\n\tstruct virt_dma_desc *vd = vchan_next_desc(&bchan->vc);\n\tstruct bam_device *bdev = bchan->bdev;\n\tstruct bam_async_desc *async_desc = NULL;\n\tstruct bam_desc_hw *desc;\n\tstruct bam_desc_hw *fifo = PTR_ALIGN(bchan->fifo_virt,\n\t\t\t\t\tsizeof(struct bam_desc_hw));\n\tint ret;\n\tunsigned int avail;\n\tstruct dmaengine_desc_callback cb;\n\n\tlockdep_assert_held(&bchan->vc.lock);\n\n\tif (!vd)\n\t\treturn;\n\n\tret = pm_runtime_get_sync(bdev->dev);\n\tif (ret < 0)\n\t\treturn;\n\n\twhile (vd && !IS_BUSY(bchan)) {\n\t\tlist_del(&vd->node);\n\n\t\tasync_desc = container_of(vd, struct bam_async_desc, vd);\n\n\t\t \n\t\tif (!bchan->initialized)\n\t\t\tbam_chan_init_hw(bchan, async_desc->dir);\n\n\t\t \n\t\tif (bchan->reconfigure)\n\t\t\tbam_apply_new_config(bchan, async_desc->dir);\n\n\t\tdesc = async_desc->curr_desc;\n\t\tavail = CIRC_SPACE(bchan->tail, bchan->head,\n\t\t\t\t   MAX_DESCRIPTORS + 1);\n\n\t\tif (async_desc->num_desc > avail)\n\t\t\tasync_desc->xfer_len = avail;\n\t\telse\n\t\t\tasync_desc->xfer_len = async_desc->num_desc;\n\n\t\t \n\t\tif (async_desc->num_desc == async_desc->xfer_len)\n\t\t\tdesc[async_desc->xfer_len - 1].flags |=\n\t\t\t\t\t\tcpu_to_le16(async_desc->flags);\n\n\t\tvd = vchan_next_desc(&bchan->vc);\n\n\t\tdmaengine_desc_get_callback(&async_desc->vd.tx, &cb);\n\n\t\t \n\t\tif (((avail <= async_desc->xfer_len) || !vd ||\n\t\t     dmaengine_desc_callback_valid(&cb)) &&\n\t\t    !(async_desc->flags & DESC_FLAG_EOT))\n\t\t\tdesc[async_desc->xfer_len - 1].flags |=\n\t\t\t\tcpu_to_le16(DESC_FLAG_INT);\n\n\t\tif (bchan->tail + async_desc->xfer_len > MAX_DESCRIPTORS) {\n\t\t\tu32 partial = MAX_DESCRIPTORS - bchan->tail;\n\n\t\t\tmemcpy(&fifo[bchan->tail], desc,\n\t\t\t       partial * sizeof(struct bam_desc_hw));\n\t\t\tmemcpy(fifo, &desc[partial],\n\t\t\t       (async_desc->xfer_len - partial) *\n\t\t\t\tsizeof(struct bam_desc_hw));\n\t\t} else {\n\t\t\tmemcpy(&fifo[bchan->tail], desc,\n\t\t\t       async_desc->xfer_len *\n\t\t\t       sizeof(struct bam_desc_hw));\n\t\t}\n\n\t\tbchan->tail += async_desc->xfer_len;\n\t\tbchan->tail %= MAX_DESCRIPTORS;\n\t\tlist_add_tail(&async_desc->desc_node, &bchan->desc_list);\n\t}\n\n\t \n\twmb();\n\twritel_relaxed(bchan->tail * sizeof(struct bam_desc_hw),\n\t\t\tbam_addr(bdev, bchan->id, BAM_P_EVNT_REG));\n\n\tpm_runtime_mark_last_busy(bdev->dev);\n\tpm_runtime_put_autosuspend(bdev->dev);\n}\n\n \nstatic void dma_tasklet(struct tasklet_struct *t)\n{\n\tstruct bam_device *bdev = from_tasklet(bdev, t, task);\n\tstruct bam_chan *bchan;\n\tunsigned long flags;\n\tunsigned int i;\n\n\t \n\tfor (i = 0; i < bdev->num_channels; i++) {\n\t\tbchan = &bdev->channels[i];\n\t\tspin_lock_irqsave(&bchan->vc.lock, flags);\n\n\t\tif (!list_empty(&bchan->vc.desc_issued) && !IS_BUSY(bchan))\n\t\t\tbam_start_dma(bchan);\n\t\tspin_unlock_irqrestore(&bchan->vc.lock, flags);\n\t}\n\n}\n\n \nstatic void bam_issue_pending(struct dma_chan *chan)\n{\n\tstruct bam_chan *bchan = to_bam_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&bchan->vc.lock, flags);\n\n\t \n\tif (vchan_issue_pending(&bchan->vc) && !IS_BUSY(bchan))\n\t\tbam_start_dma(bchan);\n\n\tspin_unlock_irqrestore(&bchan->vc.lock, flags);\n}\n\n \nstatic void bam_dma_free_desc(struct virt_dma_desc *vd)\n{\n\tstruct bam_async_desc *async_desc = container_of(vd,\n\t\t\tstruct bam_async_desc, vd);\n\n\tkfree(async_desc);\n}\n\nstatic struct dma_chan *bam_dma_xlate(struct of_phandle_args *dma_spec,\n\t\tstruct of_dma *of)\n{\n\tstruct bam_device *bdev = container_of(of->of_dma_data,\n\t\t\t\t\tstruct bam_device, common);\n\tunsigned int request;\n\n\tif (dma_spec->args_count != 1)\n\t\treturn NULL;\n\n\trequest = dma_spec->args[0];\n\tif (request >= bdev->num_channels)\n\t\treturn NULL;\n\n\treturn dma_get_slave_channel(&(bdev->channels[request].vc.chan));\n}\n\n \nstatic int bam_init(struct bam_device *bdev)\n{\n\tu32 val;\n\n\t \n\tif (!bdev->num_ees) {\n\t\tval = readl_relaxed(bam_addr(bdev, 0, BAM_REVISION));\n\t\tbdev->num_ees = (val >> NUM_EES_SHIFT) & NUM_EES_MASK;\n\t}\n\n\t \n\tif (bdev->ee >= bdev->num_ees)\n\t\treturn -EINVAL;\n\n\tif (!bdev->num_channels) {\n\t\tval = readl_relaxed(bam_addr(bdev, 0, BAM_NUM_PIPES));\n\t\tbdev->num_channels = val & BAM_NUM_PIPES_MASK;\n\t}\n\n\t \n\tif (!bdev->controlled_remotely && !bdev->powered_remotely)\n\t\tbam_reset(bdev);\n\n\treturn 0;\n}\n\nstatic void bam_channel_init(struct bam_device *bdev, struct bam_chan *bchan,\n\tu32 index)\n{\n\tbchan->id = index;\n\tbchan->bdev = bdev;\n\n\tvchan_init(&bchan->vc, &bdev->common);\n\tbchan->vc.desc_free = bam_dma_free_desc;\n\tINIT_LIST_HEAD(&bchan->desc_list);\n}\n\nstatic const struct of_device_id bam_of_match[] = {\n\t{ .compatible = \"qcom,bam-v1.3.0\", .data = &bam_v1_3_reg_info },\n\t{ .compatible = \"qcom,bam-v1.4.0\", .data = &bam_v1_4_reg_info },\n\t{ .compatible = \"qcom,bam-v1.7.0\", .data = &bam_v1_7_reg_info },\n\t{}\n};\n\nMODULE_DEVICE_TABLE(of, bam_of_match);\n\nstatic int bam_dma_probe(struct platform_device *pdev)\n{\n\tstruct bam_device *bdev;\n\tconst struct of_device_id *match;\n\tint ret, i;\n\n\tbdev = devm_kzalloc(&pdev->dev, sizeof(*bdev), GFP_KERNEL);\n\tif (!bdev)\n\t\treturn -ENOMEM;\n\n\tbdev->dev = &pdev->dev;\n\n\tmatch = of_match_node(bam_of_match, pdev->dev.of_node);\n\tif (!match) {\n\t\tdev_err(&pdev->dev, \"Unsupported BAM module\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tbdev->layout = match->data;\n\n\tbdev->regs = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(bdev->regs))\n\t\treturn PTR_ERR(bdev->regs);\n\n\tbdev->irq = platform_get_irq(pdev, 0);\n\tif (bdev->irq < 0)\n\t\treturn bdev->irq;\n\n\tret = of_property_read_u32(pdev->dev.of_node, \"qcom,ee\", &bdev->ee);\n\tif (ret) {\n\t\tdev_err(bdev->dev, \"Execution environment unspecified\\n\");\n\t\treturn ret;\n\t}\n\n\tbdev->controlled_remotely = of_property_read_bool(pdev->dev.of_node,\n\t\t\t\t\t\t\"qcom,controlled-remotely\");\n\tbdev->powered_remotely = of_property_read_bool(pdev->dev.of_node,\n\t\t\t\t\t\t\"qcom,powered-remotely\");\n\n\tif (bdev->controlled_remotely || bdev->powered_remotely)\n\t\tbdev->bamclk = devm_clk_get_optional(bdev->dev, \"bam_clk\");\n\telse\n\t\tbdev->bamclk = devm_clk_get(bdev->dev, \"bam_clk\");\n\n\tif (IS_ERR(bdev->bamclk))\n\t\treturn PTR_ERR(bdev->bamclk);\n\n\tif (!bdev->bamclk) {\n\t\tret = of_property_read_u32(pdev->dev.of_node, \"num-channels\",\n\t\t\t\t\t   &bdev->num_channels);\n\t\tif (ret)\n\t\t\tdev_err(bdev->dev, \"num-channels unspecified in dt\\n\");\n\n\t\tret = of_property_read_u32(pdev->dev.of_node, \"qcom,num-ees\",\n\t\t\t\t\t   &bdev->num_ees);\n\t\tif (ret)\n\t\t\tdev_err(bdev->dev, \"num-ees unspecified in dt\\n\");\n\t}\n\n\tret = clk_prepare_enable(bdev->bamclk);\n\tif (ret) {\n\t\tdev_err(bdev->dev, \"failed to prepare/enable clock\\n\");\n\t\treturn ret;\n\t}\n\n\tret = bam_init(bdev);\n\tif (ret)\n\t\tgoto err_disable_clk;\n\n\ttasklet_setup(&bdev->task, dma_tasklet);\n\n\tbdev->channels = devm_kcalloc(bdev->dev, bdev->num_channels,\n\t\t\t\tsizeof(*bdev->channels), GFP_KERNEL);\n\n\tif (!bdev->channels) {\n\t\tret = -ENOMEM;\n\t\tgoto err_tasklet_kill;\n\t}\n\n\t \n\tINIT_LIST_HEAD(&bdev->common.channels);\n\n\tfor (i = 0; i < bdev->num_channels; i++)\n\t\tbam_channel_init(bdev, &bdev->channels[i], i);\n\n\tret = devm_request_irq(bdev->dev, bdev->irq, bam_dma_irq,\n\t\t\tIRQF_TRIGGER_HIGH, \"bam_dma\", bdev);\n\tif (ret)\n\t\tgoto err_bam_channel_exit;\n\n\t \n\tbdev->common.dev = bdev->dev;\n\tret = dma_set_max_seg_size(bdev->common.dev, BAM_FIFO_SIZE);\n\tif (ret) {\n\t\tdev_err(bdev->dev, \"cannot set maximum segment size\\n\");\n\t\tgoto err_bam_channel_exit;\n\t}\n\n\tplatform_set_drvdata(pdev, bdev);\n\n\t \n\tdma_cap_zero(bdev->common.cap_mask);\n\tdma_cap_set(DMA_SLAVE, bdev->common.cap_mask);\n\n\t \n\tbdev->common.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\n\tbdev->common.residue_granularity = DMA_RESIDUE_GRANULARITY_SEGMENT;\n\tbdev->common.src_addr_widths = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\tbdev->common.dst_addr_widths = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\tbdev->common.device_alloc_chan_resources = bam_alloc_chan;\n\tbdev->common.device_free_chan_resources = bam_free_chan;\n\tbdev->common.device_prep_slave_sg = bam_prep_slave_sg;\n\tbdev->common.device_config = bam_slave_config;\n\tbdev->common.device_pause = bam_pause;\n\tbdev->common.device_resume = bam_resume;\n\tbdev->common.device_terminate_all = bam_dma_terminate_all;\n\tbdev->common.device_issue_pending = bam_issue_pending;\n\tbdev->common.device_tx_status = bam_tx_status;\n\tbdev->common.dev = bdev->dev;\n\n\tret = dma_async_device_register(&bdev->common);\n\tif (ret) {\n\t\tdev_err(bdev->dev, \"failed to register dma async device\\n\");\n\t\tgoto err_bam_channel_exit;\n\t}\n\n\tret = of_dma_controller_register(pdev->dev.of_node, bam_dma_xlate,\n\t\t\t\t\t&bdev->common);\n\tif (ret)\n\t\tgoto err_unregister_dma;\n\n\tpm_runtime_irq_safe(&pdev->dev);\n\tpm_runtime_set_autosuspend_delay(&pdev->dev, BAM_DMA_AUTOSUSPEND_DELAY);\n\tpm_runtime_use_autosuspend(&pdev->dev);\n\tpm_runtime_mark_last_busy(&pdev->dev);\n\tpm_runtime_set_active(&pdev->dev);\n\tpm_runtime_enable(&pdev->dev);\n\n\treturn 0;\n\nerr_unregister_dma:\n\tdma_async_device_unregister(&bdev->common);\nerr_bam_channel_exit:\n\tfor (i = 0; i < bdev->num_channels; i++)\n\t\ttasklet_kill(&bdev->channels[i].vc.task);\nerr_tasklet_kill:\n\ttasklet_kill(&bdev->task);\nerr_disable_clk:\n\tclk_disable_unprepare(bdev->bamclk);\n\n\treturn ret;\n}\n\nstatic int bam_dma_remove(struct platform_device *pdev)\n{\n\tstruct bam_device *bdev = platform_get_drvdata(pdev);\n\tu32 i;\n\n\tpm_runtime_force_suspend(&pdev->dev);\n\n\tof_dma_controller_free(pdev->dev.of_node);\n\tdma_async_device_unregister(&bdev->common);\n\n\t \n\twritel_relaxed(0, bam_addr(bdev, 0,  BAM_IRQ_SRCS_MSK_EE));\n\n\tdevm_free_irq(bdev->dev, bdev->irq, bdev);\n\n\tfor (i = 0; i < bdev->num_channels; i++) {\n\t\tbam_dma_terminate_all(&bdev->channels[i].vc.chan);\n\t\ttasklet_kill(&bdev->channels[i].vc.task);\n\n\t\tif (!bdev->channels[i].fifo_virt)\n\t\t\tcontinue;\n\n\t\tdma_free_wc(bdev->dev, BAM_DESC_FIFO_SIZE,\n\t\t\t    bdev->channels[i].fifo_virt,\n\t\t\t    bdev->channels[i].fifo_phys);\n\t}\n\n\ttasklet_kill(&bdev->task);\n\n\tclk_disable_unprepare(bdev->bamclk);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused bam_dma_runtime_suspend(struct device *dev)\n{\n\tstruct bam_device *bdev = dev_get_drvdata(dev);\n\n\tclk_disable(bdev->bamclk);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused bam_dma_runtime_resume(struct device *dev)\n{\n\tstruct bam_device *bdev = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = clk_enable(bdev->bamclk);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"clk_enable failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int __maybe_unused bam_dma_suspend(struct device *dev)\n{\n\tstruct bam_device *bdev = dev_get_drvdata(dev);\n\n\tpm_runtime_force_suspend(dev);\n\tclk_unprepare(bdev->bamclk);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused bam_dma_resume(struct device *dev)\n{\n\tstruct bam_device *bdev = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = clk_prepare(bdev->bamclk);\n\tif (ret)\n\t\treturn ret;\n\n\tpm_runtime_force_resume(dev);\n\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops bam_dma_pm_ops = {\n\tSET_LATE_SYSTEM_SLEEP_PM_OPS(bam_dma_suspend, bam_dma_resume)\n\tSET_RUNTIME_PM_OPS(bam_dma_runtime_suspend, bam_dma_runtime_resume,\n\t\t\t\tNULL)\n};\n\nstatic struct platform_driver bam_dma_driver = {\n\t.probe = bam_dma_probe,\n\t.remove = bam_dma_remove,\n\t.driver = {\n\t\t.name = \"bam-dma-engine\",\n\t\t.pm = &bam_dma_pm_ops,\n\t\t.of_match_table = bam_of_match,\n\t},\n};\n\nmodule_platform_driver(bam_dma_driver);\n\nMODULE_AUTHOR(\"Andy Gross <agross@codeaurora.org>\");\nMODULE_DESCRIPTION(\"QCOM BAM DMA engine driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}