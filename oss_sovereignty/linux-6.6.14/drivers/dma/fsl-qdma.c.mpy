{
  "module_name": "fsl-qdma.c",
  "hash_id": "61459e9ecc060759952b423555489a26fdcffce85a23e906905c1cd3c588b435",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/fsl-qdma.c",
  "human_readable_source": "\n\n\n\n \n\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/of.h>\n#include <linux/of_dma.h>\n#include <linux/dma-mapping.h>\n#include <linux/platform_device.h>\n\n#include \"virt-dma.h\"\n#include \"fsldma.h\"\n\n \n#define FSL_QDMA_DMR\t\t\t0x0\n#define FSL_QDMA_DSR\t\t\t0x4\n#define FSL_QDMA_DEIER\t\t\t0xe00\n#define FSL_QDMA_DEDR\t\t\t0xe04\n#define FSL_QDMA_DECFDW0R\t\t0xe10\n#define FSL_QDMA_DECFDW1R\t\t0xe14\n#define FSL_QDMA_DECFDW2R\t\t0xe18\n#define FSL_QDMA_DECFDW3R\t\t0xe1c\n#define FSL_QDMA_DECFQIDR\t\t0xe30\n#define FSL_QDMA_DECBR\t\t\t0xe34\n\n#define FSL_QDMA_BCQMR(x)\t\t(0xc0 + 0x100 * (x))\n#define FSL_QDMA_BCQSR(x)\t\t(0xc4 + 0x100 * (x))\n#define FSL_QDMA_BCQEDPA_SADDR(x)\t(0xc8 + 0x100 * (x))\n#define FSL_QDMA_BCQDPA_SADDR(x)\t(0xcc + 0x100 * (x))\n#define FSL_QDMA_BCQEEPA_SADDR(x)\t(0xd0 + 0x100 * (x))\n#define FSL_QDMA_BCQEPA_SADDR(x)\t(0xd4 + 0x100 * (x))\n#define FSL_QDMA_BCQIER(x)\t\t(0xe0 + 0x100 * (x))\n#define FSL_QDMA_BCQIDR(x)\t\t(0xe4 + 0x100 * (x))\n\n#define FSL_QDMA_SQDPAR\t\t\t0x80c\n#define FSL_QDMA_SQEPAR\t\t\t0x814\n#define FSL_QDMA_BSQMR\t\t\t0x800\n#define FSL_QDMA_BSQSR\t\t\t0x804\n#define FSL_QDMA_BSQICR\t\t\t0x828\n#define FSL_QDMA_CQMR\t\t\t0xa00\n#define FSL_QDMA_CQDSCR1\t\t0xa08\n#define FSL_QDMA_CQDSCR2                0xa0c\n#define FSL_QDMA_CQIER\t\t\t0xa10\n#define FSL_QDMA_CQEDR\t\t\t0xa14\n#define FSL_QDMA_SQCCMR\t\t\t0xa20\n\n \n#define FSL_QDMA_CQIDR_SQT\t\tBIT(15)\n#define QDMA_CCDF_FORMAT\t\tBIT(29)\n#define QDMA_CCDF_SER\t\t\tBIT(30)\n#define QDMA_SG_FIN\t\t\tBIT(30)\n#define QDMA_SG_LEN_MASK\t\tGENMASK(29, 0)\n#define QDMA_CCDF_MASK\t\t\tGENMASK(28, 20)\n\n#define FSL_QDMA_DEDR_CLEAR\t\tGENMASK(31, 0)\n#define FSL_QDMA_BCQIDR_CLEAR\t\tGENMASK(31, 0)\n#define FSL_QDMA_DEIER_CLEAR\t\tGENMASK(31, 0)\n\n#define FSL_QDMA_BCQIER_CQTIE\t\tBIT(15)\n#define FSL_QDMA_BCQIER_CQPEIE\t\tBIT(23)\n#define FSL_QDMA_BSQICR_ICEN\t\tBIT(31)\n\n#define FSL_QDMA_BSQICR_ICST(x)\t\t((x) << 16)\n#define FSL_QDMA_CQIER_MEIE\t\tBIT(31)\n#define FSL_QDMA_CQIER_TEIE\t\tBIT(0)\n#define FSL_QDMA_SQCCMR_ENTER_WM\tBIT(21)\n\n#define FSL_QDMA_BCQMR_EN\t\tBIT(31)\n#define FSL_QDMA_BCQMR_EI\t\tBIT(30)\n#define FSL_QDMA_BCQMR_CD_THLD(x)\t((x) << 20)\n#define FSL_QDMA_BCQMR_CQ_SIZE(x)\t((x) << 16)\n\n#define FSL_QDMA_BCQSR_QF\t\tBIT(16)\n#define FSL_QDMA_BCQSR_XOFF\t\tBIT(0)\n\n#define FSL_QDMA_BSQMR_EN\t\tBIT(31)\n#define FSL_QDMA_BSQMR_DI\t\tBIT(30)\n#define FSL_QDMA_BSQMR_CQ_SIZE(x)\t((x) << 16)\n\n#define FSL_QDMA_BSQSR_QE\t\tBIT(17)\n\n#define FSL_QDMA_DMR_DQD\t\tBIT(30)\n#define FSL_QDMA_DSR_DB\t\tBIT(31)\n\n \n#define FSL_QDMA_QUEUE_MAX\t\t8\n#define FSL_QDMA_COMMAND_BUFFER_SIZE\t64\n#define FSL_QDMA_DESCRIPTOR_BUFFER_SIZE 32\n#define FSL_QDMA_CIRCULAR_DESC_SIZE_MIN\t64\n#define FSL_QDMA_CIRCULAR_DESC_SIZE_MAX\t16384\n#define FSL_QDMA_QUEUE_NUM_MAX\t\t8\n\n \n#define FSL_QDMA_CMD_RWTTYPE\t\t0x4\n#define FSL_QDMA_CMD_LWC                0x2\n#define FSL_QDMA_CMD_RWTTYPE_OFFSET\t28\n#define FSL_QDMA_CMD_NS_OFFSET\t\t27\n#define FSL_QDMA_CMD_DQOS_OFFSET\t24\n#define FSL_QDMA_CMD_WTHROTL_OFFSET\t20\n#define FSL_QDMA_CMD_DSEN_OFFSET\t19\n#define FSL_QDMA_CMD_LWC_OFFSET\t\t16\n\n \n#define QDMA_CCDF_STATUS_RTE\t\tBIT(5)\n#define QDMA_CCDF_STATUS_WTE\t\tBIT(4)\n#define QDMA_CCDF_STATUS_CDE\t\tBIT(2)\n#define QDMA_CCDF_STATUS_SDE\t\tBIT(1)\n#define QDMA_CCDF_STATUS_DDE\t\tBIT(0)\n#define QDMA_CCDF_STATUS_MASK\t\t(QDMA_CCDF_STATUS_RTE | \\\n\t\t\t\t\tQDMA_CCDF_STATUS_WTE | \\\n\t\t\t\t\tQDMA_CCDF_STATUS_CDE | \\\n\t\t\t\t\tQDMA_CCDF_STATUS_SDE | \\\n\t\t\t\t\tQDMA_CCDF_STATUS_DDE)\n\n \n#define QDMA_CCDF_OFFSET\t\t20\n#define QDMA_SDDF_CMD(x)\t\t(((u64)(x)) << 32)\n\n \n#define FSL_QDMA_HALT_COUNT\t\t1500\n#define FSL_QDMA_MAX_SIZE\t\t16385\n#define\tFSL_QDMA_COMP_TIMEOUT\t\t1000\n#define FSL_COMMAND_QUEUE_OVERFLLOW\t10\n\n#define FSL_QDMA_BLOCK_BASE_OFFSET(fsl_qdma_engine, x)\t\t\t\\\n\t(((fsl_qdma_engine)->block_offset) * (x))\n\n \nstruct fsl_qdma_format {\n\t__le32 status;\n\t__le32 cfg;\n\tunion {\n\t\tstruct {\n\t\t\t__le32 addr_lo;\n\t\t\tu8 addr_hi;\n\t\t\tu8 __reserved1[2];\n\t\t\tu8 cfg8b_w1;\n\t\t} __packed;\n\t\t__le64 data;\n\t};\n} __packed;\n\n \nstruct fsl_pre_status {\n\tu64 addr;\n\tu8 queue;\n};\n\nstatic DEFINE_PER_CPU(struct fsl_pre_status, pre);\n\nstruct fsl_qdma_chan {\n\tstruct virt_dma_chan\t\tvchan;\n\tstruct virt_dma_desc\t\tvdesc;\n\tenum dma_status\t\t\tstatus;\n\tstruct fsl_qdma_engine\t\t*qdma;\n\tstruct fsl_qdma_queue\t\t*queue;\n};\n\nstruct fsl_qdma_queue {\n\tstruct fsl_qdma_format\t*virt_head;\n\tstruct fsl_qdma_format\t*virt_tail;\n\tstruct list_head\tcomp_used;\n\tstruct list_head\tcomp_free;\n\tstruct dma_pool\t\t*comp_pool;\n\tstruct dma_pool\t\t*desc_pool;\n\tspinlock_t\t\tqueue_lock;\n\tdma_addr_t\t\tbus_addr;\n\tu32                     n_cq;\n\tu32\t\t\tid;\n\tstruct fsl_qdma_format\t*cq;\n\tvoid __iomem\t\t*block_base;\n};\n\nstruct fsl_qdma_comp {\n\tdma_addr_t              bus_addr;\n\tdma_addr_t              desc_bus_addr;\n\tstruct fsl_qdma_format\t*virt_addr;\n\tstruct fsl_qdma_format\t*desc_virt_addr;\n\tstruct fsl_qdma_chan\t*qchan;\n\tstruct virt_dma_desc    vdesc;\n\tstruct list_head\tlist;\n};\n\nstruct fsl_qdma_engine {\n\tstruct dma_device\tdma_dev;\n\tvoid __iomem\t\t*ctrl_base;\n\tvoid __iomem            *status_base;\n\tvoid __iomem\t\t*block_base;\n\tu32\t\t\tn_chans;\n\tu32\t\t\tn_queues;\n\tstruct mutex            fsl_qdma_mutex;\n\tint\t\t\terror_irq;\n\tint\t\t\t*queue_irq;\n\tu32\t\t\tfeature;\n\tstruct fsl_qdma_queue\t*queue;\n\tstruct fsl_qdma_queue\t**status;\n\tstruct fsl_qdma_chan\t*chans;\n\tint\t\t\tblock_number;\n\tint\t\t\tblock_offset;\n\tint\t\t\tirq_base;\n\tint\t\t\tdesc_allocated;\n\n};\n\nstatic inline u64\nqdma_ccdf_addr_get64(const struct fsl_qdma_format *ccdf)\n{\n\treturn le64_to_cpu(ccdf->data) & (U64_MAX >> 24);\n}\n\nstatic inline void\nqdma_desc_addr_set64(struct fsl_qdma_format *ccdf, u64 addr)\n{\n\tccdf->addr_hi = upper_32_bits(addr);\n\tccdf->addr_lo = cpu_to_le32(lower_32_bits(addr));\n}\n\nstatic inline u8\nqdma_ccdf_get_queue(const struct fsl_qdma_format *ccdf)\n{\n\treturn ccdf->cfg8b_w1 & U8_MAX;\n}\n\nstatic inline int\nqdma_ccdf_get_offset(const struct fsl_qdma_format *ccdf)\n{\n\treturn (le32_to_cpu(ccdf->cfg) & QDMA_CCDF_MASK) >> QDMA_CCDF_OFFSET;\n}\n\nstatic inline void\nqdma_ccdf_set_format(struct fsl_qdma_format *ccdf, int offset)\n{\n\tccdf->cfg = cpu_to_le32(QDMA_CCDF_FORMAT |\n\t\t\t\t(offset << QDMA_CCDF_OFFSET));\n}\n\nstatic inline int\nqdma_ccdf_get_status(const struct fsl_qdma_format *ccdf)\n{\n\treturn (le32_to_cpu(ccdf->status) & QDMA_CCDF_STATUS_MASK);\n}\n\nstatic inline void\nqdma_ccdf_set_ser(struct fsl_qdma_format *ccdf, int status)\n{\n\tccdf->status = cpu_to_le32(QDMA_CCDF_SER | status);\n}\n\nstatic inline void qdma_csgf_set_len(struct fsl_qdma_format *csgf, int len)\n{\n\tcsgf->cfg = cpu_to_le32(len & QDMA_SG_LEN_MASK);\n}\n\nstatic inline void qdma_csgf_set_f(struct fsl_qdma_format *csgf, int len)\n{\n\tcsgf->cfg = cpu_to_le32(QDMA_SG_FIN | (len & QDMA_SG_LEN_MASK));\n}\n\nstatic u32 qdma_readl(struct fsl_qdma_engine *qdma, void __iomem *addr)\n{\n\treturn FSL_DMA_IN(qdma, addr, 32);\n}\n\nstatic void qdma_writel(struct fsl_qdma_engine *qdma, u32 val,\n\t\t\tvoid __iomem *addr)\n{\n\tFSL_DMA_OUT(qdma, addr, val, 32);\n}\n\nstatic struct fsl_qdma_chan *to_fsl_qdma_chan(struct dma_chan *chan)\n{\n\treturn container_of(chan, struct fsl_qdma_chan, vchan.chan);\n}\n\nstatic struct fsl_qdma_comp *to_fsl_qdma_comp(struct virt_dma_desc *vd)\n{\n\treturn container_of(vd, struct fsl_qdma_comp, vdesc);\n}\n\nstatic void fsl_qdma_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct fsl_qdma_chan *fsl_chan = to_fsl_qdma_chan(chan);\n\tstruct fsl_qdma_queue *fsl_queue = fsl_chan->queue;\n\tstruct fsl_qdma_engine *fsl_qdma = fsl_chan->qdma;\n\tstruct fsl_qdma_comp *comp_temp, *_comp_temp;\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&fsl_chan->vchan.lock, flags);\n\tvchan_get_all_descriptors(&fsl_chan->vchan, &head);\n\tspin_unlock_irqrestore(&fsl_chan->vchan.lock, flags);\n\n\tvchan_dma_desc_free_list(&fsl_chan->vchan, &head);\n\n\tif (!fsl_queue->comp_pool && !fsl_queue->desc_pool)\n\t\treturn;\n\n\tlist_for_each_entry_safe(comp_temp, _comp_temp,\n\t\t\t\t &fsl_queue->comp_used,\tlist) {\n\t\tdma_pool_free(fsl_queue->comp_pool,\n\t\t\t      comp_temp->virt_addr,\n\t\t\t      comp_temp->bus_addr);\n\t\tdma_pool_free(fsl_queue->desc_pool,\n\t\t\t      comp_temp->desc_virt_addr,\n\t\t\t      comp_temp->desc_bus_addr);\n\t\tlist_del(&comp_temp->list);\n\t\tkfree(comp_temp);\n\t}\n\n\tlist_for_each_entry_safe(comp_temp, _comp_temp,\n\t\t\t\t &fsl_queue->comp_free, list) {\n\t\tdma_pool_free(fsl_queue->comp_pool,\n\t\t\t      comp_temp->virt_addr,\n\t\t\t      comp_temp->bus_addr);\n\t\tdma_pool_free(fsl_queue->desc_pool,\n\t\t\t      comp_temp->desc_virt_addr,\n\t\t\t      comp_temp->desc_bus_addr);\n\t\tlist_del(&comp_temp->list);\n\t\tkfree(comp_temp);\n\t}\n\n\tdma_pool_destroy(fsl_queue->comp_pool);\n\tdma_pool_destroy(fsl_queue->desc_pool);\n\n\tfsl_qdma->desc_allocated--;\n\tfsl_queue->comp_pool = NULL;\n\tfsl_queue->desc_pool = NULL;\n}\n\nstatic void fsl_qdma_comp_fill_memcpy(struct fsl_qdma_comp *fsl_comp,\n\t\t\t\t      dma_addr_t dst, dma_addr_t src, u32 len)\n{\n\tu32 cmd;\n\tstruct fsl_qdma_format *sdf, *ddf;\n\tstruct fsl_qdma_format *ccdf, *csgf_desc, *csgf_src, *csgf_dest;\n\n\tccdf = fsl_comp->virt_addr;\n\tcsgf_desc = fsl_comp->virt_addr + 1;\n\tcsgf_src = fsl_comp->virt_addr + 2;\n\tcsgf_dest = fsl_comp->virt_addr + 3;\n\tsdf = fsl_comp->desc_virt_addr;\n\tddf = fsl_comp->desc_virt_addr + 1;\n\n\tmemset(fsl_comp->virt_addr, 0, FSL_QDMA_COMMAND_BUFFER_SIZE);\n\tmemset(fsl_comp->desc_virt_addr, 0, FSL_QDMA_DESCRIPTOR_BUFFER_SIZE);\n\t \n\tqdma_desc_addr_set64(ccdf, fsl_comp->bus_addr + 16);\n\tqdma_ccdf_set_format(ccdf, qdma_ccdf_get_offset(ccdf));\n\tqdma_ccdf_set_ser(ccdf, qdma_ccdf_get_status(ccdf));\n\t \n\t \n\tqdma_desc_addr_set64(csgf_desc, fsl_comp->desc_bus_addr);\n\t \n\tqdma_csgf_set_len(csgf_desc, 32);\n\tqdma_desc_addr_set64(csgf_src, src);\n\tqdma_csgf_set_len(csgf_src, len);\n\tqdma_desc_addr_set64(csgf_dest, dst);\n\tqdma_csgf_set_len(csgf_dest, len);\n\t \n\tqdma_csgf_set_f(csgf_dest, len);\n\t \n\tcmd = cpu_to_le32(FSL_QDMA_CMD_RWTTYPE <<\n\t\t\t  FSL_QDMA_CMD_RWTTYPE_OFFSET);\n\tsdf->data = QDMA_SDDF_CMD(cmd);\n\n\tcmd = cpu_to_le32(FSL_QDMA_CMD_RWTTYPE <<\n\t\t\t  FSL_QDMA_CMD_RWTTYPE_OFFSET);\n\tcmd |= cpu_to_le32(FSL_QDMA_CMD_LWC << FSL_QDMA_CMD_LWC_OFFSET);\n\tddf->data = QDMA_SDDF_CMD(cmd);\n}\n\n \nstatic int fsl_qdma_pre_request_enqueue_desc(struct fsl_qdma_queue *queue)\n{\n\tint i;\n\tstruct fsl_qdma_comp *comp_temp, *_comp_temp;\n\n\tfor (i = 0; i < queue->n_cq + FSL_COMMAND_QUEUE_OVERFLLOW; i++) {\n\t\tcomp_temp = kzalloc(sizeof(*comp_temp), GFP_KERNEL);\n\t\tif (!comp_temp)\n\t\t\tgoto err_alloc;\n\t\tcomp_temp->virt_addr =\n\t\t\tdma_pool_alloc(queue->comp_pool, GFP_KERNEL,\n\t\t\t\t       &comp_temp->bus_addr);\n\t\tif (!comp_temp->virt_addr)\n\t\t\tgoto err_dma_alloc;\n\n\t\tcomp_temp->desc_virt_addr =\n\t\t\tdma_pool_alloc(queue->desc_pool, GFP_KERNEL,\n\t\t\t\t       &comp_temp->desc_bus_addr);\n\t\tif (!comp_temp->desc_virt_addr)\n\t\t\tgoto err_desc_dma_alloc;\n\n\t\tlist_add_tail(&comp_temp->list, &queue->comp_free);\n\t}\n\n\treturn 0;\n\nerr_desc_dma_alloc:\n\tdma_pool_free(queue->comp_pool, comp_temp->virt_addr,\n\t\t      comp_temp->bus_addr);\n\nerr_dma_alloc:\n\tkfree(comp_temp);\n\nerr_alloc:\n\tlist_for_each_entry_safe(comp_temp, _comp_temp,\n\t\t\t\t &queue->comp_free, list) {\n\t\tif (comp_temp->virt_addr)\n\t\t\tdma_pool_free(queue->comp_pool,\n\t\t\t\t      comp_temp->virt_addr,\n\t\t\t\t      comp_temp->bus_addr);\n\t\tif (comp_temp->desc_virt_addr)\n\t\t\tdma_pool_free(queue->desc_pool,\n\t\t\t\t      comp_temp->desc_virt_addr,\n\t\t\t\t      comp_temp->desc_bus_addr);\n\n\t\tlist_del(&comp_temp->list);\n\t\tkfree(comp_temp);\n\t}\n\n\treturn -ENOMEM;\n}\n\n \nstatic struct fsl_qdma_comp\n*fsl_qdma_request_enqueue_desc(struct fsl_qdma_chan *fsl_chan)\n{\n\tunsigned long flags;\n\tstruct fsl_qdma_comp *comp_temp;\n\tint timeout = FSL_QDMA_COMP_TIMEOUT;\n\tstruct fsl_qdma_queue *queue = fsl_chan->queue;\n\n\twhile (timeout--) {\n\t\tspin_lock_irqsave(&queue->queue_lock, flags);\n\t\tif (!list_empty(&queue->comp_free)) {\n\t\t\tcomp_temp = list_first_entry(&queue->comp_free,\n\t\t\t\t\t\t     struct fsl_qdma_comp,\n\t\t\t\t\t\t     list);\n\t\t\tlist_del(&comp_temp->list);\n\n\t\t\tspin_unlock_irqrestore(&queue->queue_lock, flags);\n\t\t\tcomp_temp->qchan = fsl_chan;\n\t\t\treturn comp_temp;\n\t\t}\n\t\tspin_unlock_irqrestore(&queue->queue_lock, flags);\n\t\tudelay(1);\n\t}\n\n\treturn NULL;\n}\n\nstatic struct fsl_qdma_queue\n*fsl_qdma_alloc_queue_resources(struct platform_device *pdev,\n\t\t\t\tstruct fsl_qdma_engine *fsl_qdma)\n{\n\tint ret, len, i, j;\n\tint queue_num, block_number;\n\tunsigned int queue_size[FSL_QDMA_QUEUE_MAX];\n\tstruct fsl_qdma_queue *queue_head, *queue_temp;\n\n\tqueue_num = fsl_qdma->n_queues;\n\tblock_number = fsl_qdma->block_number;\n\n\tif (queue_num > FSL_QDMA_QUEUE_MAX)\n\t\tqueue_num = FSL_QDMA_QUEUE_MAX;\n\tlen = sizeof(*queue_head) * queue_num * block_number;\n\tqueue_head = devm_kzalloc(&pdev->dev, len, GFP_KERNEL);\n\tif (!queue_head)\n\t\treturn NULL;\n\n\tret = device_property_read_u32_array(&pdev->dev, \"queue-sizes\",\n\t\t\t\t\t     queue_size, queue_num);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Can't get queue-sizes.\\n\");\n\t\treturn NULL;\n\t}\n\tfor (j = 0; j < block_number; j++) {\n\t\tfor (i = 0; i < queue_num; i++) {\n\t\t\tif (queue_size[i] > FSL_QDMA_CIRCULAR_DESC_SIZE_MAX ||\n\t\t\t    queue_size[i] < FSL_QDMA_CIRCULAR_DESC_SIZE_MIN) {\n\t\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\t\"Get wrong queue-sizes.\\n\");\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\tqueue_temp = queue_head + i + (j * queue_num);\n\n\t\t\tqueue_temp->cq =\n\t\t\tdma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t   sizeof(struct fsl_qdma_format) *\n\t\t\t\t\t   queue_size[i],\n\t\t\t\t\t   &queue_temp->bus_addr,\n\t\t\t\t\t   GFP_KERNEL);\n\t\t\tif (!queue_temp->cq)\n\t\t\t\treturn NULL;\n\t\t\tqueue_temp->block_base = fsl_qdma->block_base +\n\t\t\t\tFSL_QDMA_BLOCK_BASE_OFFSET(fsl_qdma, j);\n\t\t\tqueue_temp->n_cq = queue_size[i];\n\t\t\tqueue_temp->id = i;\n\t\t\tqueue_temp->virt_head = queue_temp->cq;\n\t\t\tqueue_temp->virt_tail = queue_temp->cq;\n\t\t\t \n\t\t\tINIT_LIST_HEAD(&queue_temp->comp_used);\n\t\t\tspin_lock_init(&queue_temp->queue_lock);\n\t\t}\n\t}\n\treturn queue_head;\n}\n\nstatic struct fsl_qdma_queue\n*fsl_qdma_prep_status_queue(struct platform_device *pdev)\n{\n\tint ret;\n\tunsigned int status_size;\n\tstruct fsl_qdma_queue *status_head;\n\tstruct device_node *np = pdev->dev.of_node;\n\n\tret = of_property_read_u32(np, \"status-sizes\", &status_size);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Can't get status-sizes.\\n\");\n\t\treturn NULL;\n\t}\n\tif (status_size > FSL_QDMA_CIRCULAR_DESC_SIZE_MAX ||\n\t    status_size < FSL_QDMA_CIRCULAR_DESC_SIZE_MIN) {\n\t\tdev_err(&pdev->dev, \"Get wrong status_size.\\n\");\n\t\treturn NULL;\n\t}\n\tstatus_head = devm_kzalloc(&pdev->dev,\n\t\t\t\t   sizeof(*status_head), GFP_KERNEL);\n\tif (!status_head)\n\t\treturn NULL;\n\n\t \n\tstatus_head->cq = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t     sizeof(struct fsl_qdma_format) *\n\t\t\t\t\t     status_size,\n\t\t\t\t\t     &status_head->bus_addr,\n\t\t\t\t\t     GFP_KERNEL);\n\tif (!status_head->cq) {\n\t\tdevm_kfree(&pdev->dev, status_head);\n\t\treturn NULL;\n\t}\n\tstatus_head->n_cq = status_size;\n\tstatus_head->virt_head = status_head->cq;\n\tstatus_head->virt_tail = status_head->cq;\n\tstatus_head->comp_pool = NULL;\n\n\treturn status_head;\n}\n\nstatic int fsl_qdma_halt(struct fsl_qdma_engine *fsl_qdma)\n{\n\tu32 reg;\n\tint i, j, count = FSL_QDMA_HALT_COUNT;\n\tvoid __iomem *block, *ctrl = fsl_qdma->ctrl_base;\n\n\t \n\treg = qdma_readl(fsl_qdma, ctrl + FSL_QDMA_DMR);\n\treg |= FSL_QDMA_DMR_DQD;\n\tqdma_writel(fsl_qdma, reg, ctrl + FSL_QDMA_DMR);\n\tfor (j = 0; j < fsl_qdma->block_number; j++) {\n\t\tblock = fsl_qdma->block_base +\n\t\t\tFSL_QDMA_BLOCK_BASE_OFFSET(fsl_qdma, j);\n\t\tfor (i = 0; i < FSL_QDMA_QUEUE_NUM_MAX; i++)\n\t\t\tqdma_writel(fsl_qdma, 0, block + FSL_QDMA_BCQMR(i));\n\t}\n\twhile (1) {\n\t\treg = qdma_readl(fsl_qdma, ctrl + FSL_QDMA_DSR);\n\t\tif (!(reg & FSL_QDMA_DSR_DB))\n\t\t\tbreak;\n\t\tif (count-- < 0)\n\t\t\treturn -EBUSY;\n\t\tudelay(100);\n\t}\n\n\tfor (j = 0; j < fsl_qdma->block_number; j++) {\n\t\tblock = fsl_qdma->block_base +\n\t\t\tFSL_QDMA_BLOCK_BASE_OFFSET(fsl_qdma, j);\n\n\t\t \n\t\tqdma_writel(fsl_qdma, 0, block + FSL_QDMA_BSQMR);\n\n\t\t \n\t\tqdma_writel(fsl_qdma, FSL_QDMA_BCQIDR_CLEAR,\n\t\t\t    block + FSL_QDMA_BCQIDR(0));\n\t}\n\n\treturn 0;\n}\n\nstatic int\nfsl_qdma_queue_transfer_complete(struct fsl_qdma_engine *fsl_qdma,\n\t\t\t\t void *block,\n\t\t\t\t int id)\n{\n\tbool duplicate;\n\tu32 reg, i, count;\n\tu8 completion_status;\n\tstruct fsl_qdma_queue *temp_queue;\n\tstruct fsl_qdma_format *status_addr;\n\tstruct fsl_qdma_comp *fsl_comp = NULL;\n\tstruct fsl_qdma_queue *fsl_queue = fsl_qdma->queue;\n\tstruct fsl_qdma_queue *fsl_status = fsl_qdma->status[id];\n\n\tcount = FSL_QDMA_MAX_SIZE;\n\n\twhile (count--) {\n\t\tduplicate = 0;\n\t\treg = qdma_readl(fsl_qdma, block + FSL_QDMA_BSQSR);\n\t\tif (reg & FSL_QDMA_BSQSR_QE)\n\t\t\treturn 0;\n\n\t\tstatus_addr = fsl_status->virt_head;\n\n\t\tif (qdma_ccdf_get_queue(status_addr) ==\n\t\t   __this_cpu_read(pre.queue) &&\n\t\t\tqdma_ccdf_addr_get64(status_addr) ==\n\t\t\t__this_cpu_read(pre.addr))\n\t\t\tduplicate = 1;\n\t\ti = qdma_ccdf_get_queue(status_addr) +\n\t\t\tid * fsl_qdma->n_queues;\n\t\t__this_cpu_write(pre.addr, qdma_ccdf_addr_get64(status_addr));\n\t\t__this_cpu_write(pre.queue, qdma_ccdf_get_queue(status_addr));\n\t\ttemp_queue = fsl_queue + i;\n\n\t\tspin_lock(&temp_queue->queue_lock);\n\t\tif (list_empty(&temp_queue->comp_used)) {\n\t\t\tif (!duplicate) {\n\t\t\t\tspin_unlock(&temp_queue->queue_lock);\n\t\t\t\treturn -EAGAIN;\n\t\t\t}\n\t\t} else {\n\t\t\tfsl_comp = list_first_entry(&temp_queue->comp_used,\n\t\t\t\t\t\t    struct fsl_qdma_comp, list);\n\t\t\tif (fsl_comp->bus_addr + 16 !=\n\t\t\t\t__this_cpu_read(pre.addr)) {\n\t\t\t\tif (!duplicate) {\n\t\t\t\t\tspin_unlock(&temp_queue->queue_lock);\n\t\t\t\t\treturn -EAGAIN;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (duplicate) {\n\t\t\treg = qdma_readl(fsl_qdma, block + FSL_QDMA_BSQMR);\n\t\t\treg |= FSL_QDMA_BSQMR_DI;\n\t\t\tqdma_desc_addr_set64(status_addr, 0x0);\n\t\t\tfsl_status->virt_head++;\n\t\t\tif (fsl_status->virt_head == fsl_status->cq\n\t\t\t\t\t\t   + fsl_status->n_cq)\n\t\t\t\tfsl_status->virt_head = fsl_status->cq;\n\t\t\tqdma_writel(fsl_qdma, reg, block + FSL_QDMA_BSQMR);\n\t\t\tspin_unlock(&temp_queue->queue_lock);\n\t\t\tcontinue;\n\t\t}\n\t\tlist_del(&fsl_comp->list);\n\n\t\tcompletion_status = qdma_ccdf_get_status(status_addr);\n\n\t\treg = qdma_readl(fsl_qdma, block + FSL_QDMA_BSQMR);\n\t\treg |= FSL_QDMA_BSQMR_DI;\n\t\tqdma_desc_addr_set64(status_addr, 0x0);\n\t\tfsl_status->virt_head++;\n\t\tif (fsl_status->virt_head == fsl_status->cq + fsl_status->n_cq)\n\t\t\tfsl_status->virt_head = fsl_status->cq;\n\t\tqdma_writel(fsl_qdma, reg, block + FSL_QDMA_BSQMR);\n\t\tspin_unlock(&temp_queue->queue_lock);\n\n\t\t \n\t\tif (completion_status) {\n\t\t\t \n\t\t\tif (completion_status & QDMA_CCDF_STATUS_WTE) {\n\t\t\t\t \n\t\t\t\tfsl_comp->vdesc.tx_result.result =\n\t\t\t\t\tDMA_TRANS_WRITE_FAILED;\n\t\t\t} else if (completion_status & QDMA_CCDF_STATUS_RTE) {\n\t\t\t\t \n\t\t\t\tfsl_comp->vdesc.tx_result.result =\n\t\t\t\t\tDMA_TRANS_READ_FAILED;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tfsl_comp->vdesc.tx_result.result =\n\t\t\t\t\tDMA_TRANS_ABORTED;\n\t\t\t\tdev_err(fsl_qdma->dma_dev.dev,\n\t\t\t\t\t\"DMA status descriptor error %x\\n\",\n\t\t\t\t\tcompletion_status);\n\t\t\t}\n\t\t}\n\n\t\tspin_lock(&fsl_comp->qchan->vchan.lock);\n\t\tvchan_cookie_complete(&fsl_comp->vdesc);\n\t\tfsl_comp->qchan->status = DMA_COMPLETE;\n\t\tspin_unlock(&fsl_comp->qchan->vchan.lock);\n\t}\n\n\treturn 0;\n}\n\nstatic irqreturn_t fsl_qdma_error_handler(int irq, void *dev_id)\n{\n\tunsigned int intr;\n\tstruct fsl_qdma_engine *fsl_qdma = dev_id;\n\tvoid __iomem *status = fsl_qdma->status_base;\n\tunsigned int decfdw0r;\n\tunsigned int decfdw1r;\n\tunsigned int decfdw2r;\n\tunsigned int decfdw3r;\n\n\tintr = qdma_readl(fsl_qdma, status + FSL_QDMA_DEDR);\n\n\tif (intr) {\n\t\tdecfdw0r = qdma_readl(fsl_qdma, status + FSL_QDMA_DECFDW0R);\n\t\tdecfdw1r = qdma_readl(fsl_qdma, status + FSL_QDMA_DECFDW1R);\n\t\tdecfdw2r = qdma_readl(fsl_qdma, status + FSL_QDMA_DECFDW2R);\n\t\tdecfdw3r = qdma_readl(fsl_qdma, status + FSL_QDMA_DECFDW3R);\n\t\tdev_err(fsl_qdma->dma_dev.dev,\n\t\t\t\"DMA transaction error! (%x: %x-%x-%x-%x)\\n\",\n\t\t\tintr, decfdw0r, decfdw1r, decfdw2r, decfdw3r);\n\t}\n\n\tqdma_writel(fsl_qdma, FSL_QDMA_DEDR_CLEAR, status + FSL_QDMA_DEDR);\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t fsl_qdma_queue_handler(int irq, void *dev_id)\n{\n\tint id;\n\tunsigned int intr, reg;\n\tstruct fsl_qdma_engine *fsl_qdma = dev_id;\n\tvoid __iomem *block, *ctrl = fsl_qdma->ctrl_base;\n\n\tid = irq - fsl_qdma->irq_base;\n\tif (id < 0 && id > fsl_qdma->block_number) {\n\t\tdev_err(fsl_qdma->dma_dev.dev,\n\t\t\t\"irq %d is wrong irq_base is %d\\n\",\n\t\t\tirq, fsl_qdma->irq_base);\n\t}\n\n\tblock = fsl_qdma->block_base +\n\t\tFSL_QDMA_BLOCK_BASE_OFFSET(fsl_qdma, id);\n\n\tintr = qdma_readl(fsl_qdma, block + FSL_QDMA_BCQIDR(0));\n\n\tif ((intr & FSL_QDMA_CQIDR_SQT) != 0)\n\t\tintr = fsl_qdma_queue_transfer_complete(fsl_qdma, block, id);\n\n\tif (intr != 0) {\n\t\treg = qdma_readl(fsl_qdma, ctrl + FSL_QDMA_DMR);\n\t\treg |= FSL_QDMA_DMR_DQD;\n\t\tqdma_writel(fsl_qdma, reg, ctrl + FSL_QDMA_DMR);\n\t\tqdma_writel(fsl_qdma, 0, block + FSL_QDMA_BCQIER(0));\n\t\tdev_err(fsl_qdma->dma_dev.dev, \"QDMA: status err!\\n\");\n\t}\n\n\t \n\tqdma_writel(fsl_qdma, FSL_QDMA_BCQIDR_CLEAR,\n\t\t    block + FSL_QDMA_BCQIDR(0));\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int\nfsl_qdma_irq_init(struct platform_device *pdev,\n\t\t  struct fsl_qdma_engine *fsl_qdma)\n{\n\tint i;\n\tint cpu;\n\tint ret;\n\tchar irq_name[20];\n\n\tfsl_qdma->error_irq =\n\t\tplatform_get_irq_byname(pdev, \"qdma-error\");\n\tif (fsl_qdma->error_irq < 0)\n\t\treturn fsl_qdma->error_irq;\n\n\tret = devm_request_irq(&pdev->dev, fsl_qdma->error_irq,\n\t\t\t       fsl_qdma_error_handler, 0,\n\t\t\t       \"qDMA error\", fsl_qdma);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Can't register qDMA controller IRQ.\\n\");\n\t\treturn  ret;\n\t}\n\n\tfor (i = 0; i < fsl_qdma->block_number; i++) {\n\t\tsprintf(irq_name, \"qdma-queue%d\", i);\n\t\tfsl_qdma->queue_irq[i] =\n\t\t\t\tplatform_get_irq_byname(pdev, irq_name);\n\n\t\tif (fsl_qdma->queue_irq[i] < 0)\n\t\t\treturn fsl_qdma->queue_irq[i];\n\n\t\tret = devm_request_irq(&pdev->dev,\n\t\t\t\t       fsl_qdma->queue_irq[i],\n\t\t\t\t       fsl_qdma_queue_handler,\n\t\t\t\t       0,\n\t\t\t\t       \"qDMA queue\",\n\t\t\t\t       fsl_qdma);\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Can't register qDMA queue IRQ.\\n\");\n\t\t\treturn  ret;\n\t\t}\n\n\t\tcpu = i % num_online_cpus();\n\t\tret = irq_set_affinity_hint(fsl_qdma->queue_irq[i],\n\t\t\t\t\t    get_cpu_mask(cpu));\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Can't set cpu %d affinity to IRQ %d.\\n\",\n\t\t\t\tcpu,\n\t\t\t\tfsl_qdma->queue_irq[i]);\n\t\t\treturn  ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void fsl_qdma_irq_exit(struct platform_device *pdev,\n\t\t\t      struct fsl_qdma_engine *fsl_qdma)\n{\n\tint i;\n\n\tdevm_free_irq(&pdev->dev, fsl_qdma->error_irq, fsl_qdma);\n\tfor (i = 0; i < fsl_qdma->block_number; i++)\n\t\tdevm_free_irq(&pdev->dev, fsl_qdma->queue_irq[i], fsl_qdma);\n}\n\nstatic int fsl_qdma_reg_init(struct fsl_qdma_engine *fsl_qdma)\n{\n\tu32 reg;\n\tint i, j, ret;\n\tstruct fsl_qdma_queue *temp;\n\tvoid __iomem *status = fsl_qdma->status_base;\n\tvoid __iomem *block, *ctrl = fsl_qdma->ctrl_base;\n\tstruct fsl_qdma_queue *fsl_queue = fsl_qdma->queue;\n\n\t \n\tret = fsl_qdma_halt(fsl_qdma);\n\tif (ret) {\n\t\tdev_err(fsl_qdma->dma_dev.dev, \"DMA halt failed!\");\n\t\treturn ret;\n\t}\n\n\tfor (i = 0; i < fsl_qdma->block_number; i++) {\n\t\t \n\n\t\tblock = fsl_qdma->block_base +\n\t\t\tFSL_QDMA_BLOCK_BASE_OFFSET(fsl_qdma, i);\n\t\tqdma_writel(fsl_qdma, FSL_QDMA_BCQIDR_CLEAR,\n\t\t\t    block + FSL_QDMA_BCQIDR(0));\n\t}\n\n\tfor (j = 0; j < fsl_qdma->block_number; j++) {\n\t\tblock = fsl_qdma->block_base +\n\t\t\tFSL_QDMA_BLOCK_BASE_OFFSET(fsl_qdma, j);\n\t\tfor (i = 0; i < fsl_qdma->n_queues; i++) {\n\t\t\ttemp = fsl_queue + i + (j * fsl_qdma->n_queues);\n\t\t\t \n\n\t\t\tqdma_writel(fsl_qdma, temp->bus_addr,\n\t\t\t\t    block + FSL_QDMA_BCQDPA_SADDR(i));\n\t\t\tqdma_writel(fsl_qdma, temp->bus_addr,\n\t\t\t\t    block + FSL_QDMA_BCQEPA_SADDR(i));\n\n\t\t\t \n\t\t\treg = FSL_QDMA_BCQMR_EN;\n\t\t\treg |= FSL_QDMA_BCQMR_CD_THLD(ilog2(temp->n_cq) - 4);\n\t\t\treg |= FSL_QDMA_BCQMR_CQ_SIZE(ilog2(temp->n_cq) - 6);\n\t\t\tqdma_writel(fsl_qdma, reg, block + FSL_QDMA_BCQMR(i));\n\t\t}\n\n\t\t \n\n\t\tqdma_writel(fsl_qdma, FSL_QDMA_SQCCMR_ENTER_WM,\n\t\t\t    block + FSL_QDMA_SQCCMR);\n\n\t\t \n\n\t\tqdma_writel(fsl_qdma, fsl_qdma->status[j]->bus_addr,\n\t\t\t    block + FSL_QDMA_SQEPAR);\n\t\tqdma_writel(fsl_qdma, fsl_qdma->status[j]->bus_addr,\n\t\t\t    block + FSL_QDMA_SQDPAR);\n\t\t \n\t\tqdma_writel(fsl_qdma, FSL_QDMA_BCQIER_CQTIE,\n\t\t\t    block + FSL_QDMA_BCQIER(0));\n\t\tqdma_writel(fsl_qdma, FSL_QDMA_BSQICR_ICEN |\n\t\t\t\t   FSL_QDMA_BSQICR_ICST(5) | 0x8000,\n\t\t\t\t   block + FSL_QDMA_BSQICR);\n\t\tqdma_writel(fsl_qdma, FSL_QDMA_CQIER_MEIE |\n\t\t\t\t   FSL_QDMA_CQIER_TEIE,\n\t\t\t\t   block + FSL_QDMA_CQIER);\n\n\t\t \n\t\treg = FSL_QDMA_BSQMR_EN;\n\t\treg |= FSL_QDMA_BSQMR_CQ_SIZE(ilog2\n\t\t\t(fsl_qdma->status[j]->n_cq) - 6);\n\n\t\tqdma_writel(fsl_qdma, reg, block + FSL_QDMA_BSQMR);\n\t\treg = qdma_readl(fsl_qdma, block + FSL_QDMA_BSQMR);\n\t}\n\n\t \n\tqdma_writel(fsl_qdma, FSL_QDMA_DEDR_CLEAR, status + FSL_QDMA_DEDR);\n\tqdma_writel(fsl_qdma, FSL_QDMA_DEIER_CLEAR, status + FSL_QDMA_DEIER);\n\n\treg = qdma_readl(fsl_qdma, ctrl + FSL_QDMA_DMR);\n\treg &= ~FSL_QDMA_DMR_DQD;\n\tqdma_writel(fsl_qdma, reg, ctrl + FSL_QDMA_DMR);\n\n\treturn 0;\n}\n\nstatic struct dma_async_tx_descriptor *\nfsl_qdma_prep_memcpy(struct dma_chan *chan, dma_addr_t dst,\n\t\t     dma_addr_t src, size_t len, unsigned long flags)\n{\n\tstruct fsl_qdma_comp *fsl_comp;\n\tstruct fsl_qdma_chan *fsl_chan = to_fsl_qdma_chan(chan);\n\n\tfsl_comp = fsl_qdma_request_enqueue_desc(fsl_chan);\n\n\tif (!fsl_comp)\n\t\treturn NULL;\n\n\tfsl_qdma_comp_fill_memcpy(fsl_comp, dst, src, len);\n\n\treturn vchan_tx_prep(&fsl_chan->vchan, &fsl_comp->vdesc, flags);\n}\n\nstatic void fsl_qdma_enqueue_desc(struct fsl_qdma_chan *fsl_chan)\n{\n\tu32 reg;\n\tstruct virt_dma_desc *vdesc;\n\tstruct fsl_qdma_comp *fsl_comp;\n\tstruct fsl_qdma_queue *fsl_queue = fsl_chan->queue;\n\tvoid __iomem *block = fsl_queue->block_base;\n\n\treg = qdma_readl(fsl_chan->qdma, block + FSL_QDMA_BCQSR(fsl_queue->id));\n\tif (reg & (FSL_QDMA_BCQSR_QF | FSL_QDMA_BCQSR_XOFF))\n\t\treturn;\n\tvdesc = vchan_next_desc(&fsl_chan->vchan);\n\tif (!vdesc)\n\t\treturn;\n\tlist_del(&vdesc->node);\n\tfsl_comp = to_fsl_qdma_comp(vdesc);\n\n\tmemcpy(fsl_queue->virt_head++,\n\t       fsl_comp->virt_addr, sizeof(struct fsl_qdma_format));\n\tif (fsl_queue->virt_head == fsl_queue->cq + fsl_queue->n_cq)\n\t\tfsl_queue->virt_head = fsl_queue->cq;\n\n\tlist_add_tail(&fsl_comp->list, &fsl_queue->comp_used);\n\tbarrier();\n\treg = qdma_readl(fsl_chan->qdma, block + FSL_QDMA_BCQMR(fsl_queue->id));\n\treg |= FSL_QDMA_BCQMR_EI;\n\tqdma_writel(fsl_chan->qdma, reg, block + FSL_QDMA_BCQMR(fsl_queue->id));\n\tfsl_chan->status = DMA_IN_PROGRESS;\n}\n\nstatic void fsl_qdma_free_desc(struct virt_dma_desc *vdesc)\n{\n\tunsigned long flags;\n\tstruct fsl_qdma_comp *fsl_comp;\n\tstruct fsl_qdma_queue *fsl_queue;\n\n\tfsl_comp = to_fsl_qdma_comp(vdesc);\n\tfsl_queue = fsl_comp->qchan->queue;\n\n\tspin_lock_irqsave(&fsl_queue->queue_lock, flags);\n\tlist_add_tail(&fsl_comp->list, &fsl_queue->comp_free);\n\tspin_unlock_irqrestore(&fsl_queue->queue_lock, flags);\n}\n\nstatic void fsl_qdma_issue_pending(struct dma_chan *chan)\n{\n\tunsigned long flags;\n\tstruct fsl_qdma_chan *fsl_chan = to_fsl_qdma_chan(chan);\n\tstruct fsl_qdma_queue *fsl_queue = fsl_chan->queue;\n\n\tspin_lock_irqsave(&fsl_queue->queue_lock, flags);\n\tspin_lock(&fsl_chan->vchan.lock);\n\tif (vchan_issue_pending(&fsl_chan->vchan))\n\t\tfsl_qdma_enqueue_desc(fsl_chan);\n\tspin_unlock(&fsl_chan->vchan.lock);\n\tspin_unlock_irqrestore(&fsl_queue->queue_lock, flags);\n}\n\nstatic void fsl_qdma_synchronize(struct dma_chan *chan)\n{\n\tstruct fsl_qdma_chan *fsl_chan = to_fsl_qdma_chan(chan);\n\n\tvchan_synchronize(&fsl_chan->vchan);\n}\n\nstatic int fsl_qdma_terminate_all(struct dma_chan *chan)\n{\n\tLIST_HEAD(head);\n\tunsigned long flags;\n\tstruct fsl_qdma_chan *fsl_chan = to_fsl_qdma_chan(chan);\n\n\tspin_lock_irqsave(&fsl_chan->vchan.lock, flags);\n\tvchan_get_all_descriptors(&fsl_chan->vchan, &head);\n\tspin_unlock_irqrestore(&fsl_chan->vchan.lock, flags);\n\tvchan_dma_desc_free_list(&fsl_chan->vchan, &head);\n\treturn 0;\n}\n\nstatic int fsl_qdma_alloc_chan_resources(struct dma_chan *chan)\n{\n\tint ret;\n\tstruct fsl_qdma_chan *fsl_chan = to_fsl_qdma_chan(chan);\n\tstruct fsl_qdma_engine *fsl_qdma = fsl_chan->qdma;\n\tstruct fsl_qdma_queue *fsl_queue = fsl_chan->queue;\n\n\tif (fsl_queue->comp_pool && fsl_queue->desc_pool)\n\t\treturn fsl_qdma->desc_allocated;\n\n\tINIT_LIST_HEAD(&fsl_queue->comp_free);\n\n\t \n\tfsl_queue->comp_pool =\n\tdma_pool_create(\"comp_pool\",\n\t\t\tchan->device->dev,\n\t\t\tFSL_QDMA_COMMAND_BUFFER_SIZE,\n\t\t\t64, 0);\n\tif (!fsl_queue->comp_pool)\n\t\treturn -ENOMEM;\n\n\t \n\tfsl_queue->desc_pool =\n\tdma_pool_create(\"desc_pool\",\n\t\t\tchan->device->dev,\n\t\t\tFSL_QDMA_DESCRIPTOR_BUFFER_SIZE,\n\t\t\t32, 0);\n\tif (!fsl_queue->desc_pool)\n\t\tgoto err_desc_pool;\n\n\tret = fsl_qdma_pre_request_enqueue_desc(fsl_queue);\n\tif (ret) {\n\t\tdev_err(chan->device->dev,\n\t\t\t\"failed to alloc dma buffer for S/G descriptor\\n\");\n\t\tgoto err_mem;\n\t}\n\n\tfsl_qdma->desc_allocated++;\n\treturn fsl_qdma->desc_allocated;\n\nerr_mem:\n\tdma_pool_destroy(fsl_queue->desc_pool);\nerr_desc_pool:\n\tdma_pool_destroy(fsl_queue->comp_pool);\n\treturn -ENOMEM;\n}\n\nstatic int fsl_qdma_probe(struct platform_device *pdev)\n{\n\tint ret, i;\n\tint blk_num, blk_off;\n\tu32 len, chans, queues;\n\tstruct fsl_qdma_chan *fsl_chan;\n\tstruct fsl_qdma_engine *fsl_qdma;\n\tstruct device_node *np = pdev->dev.of_node;\n\n\tret = of_property_read_u32(np, \"dma-channels\", &chans);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Can't get dma-channels.\\n\");\n\t\treturn ret;\n\t}\n\n\tret = of_property_read_u32(np, \"block-offset\", &blk_off);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Can't get block-offset.\\n\");\n\t\treturn ret;\n\t}\n\n\tret = of_property_read_u32(np, \"block-number\", &blk_num);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Can't get block-number.\\n\");\n\t\treturn ret;\n\t}\n\n\tblk_num = min_t(int, blk_num, num_online_cpus());\n\n\tlen = sizeof(*fsl_qdma);\n\tfsl_qdma = devm_kzalloc(&pdev->dev, len, GFP_KERNEL);\n\tif (!fsl_qdma)\n\t\treturn -ENOMEM;\n\n\tlen = sizeof(*fsl_chan) * chans;\n\tfsl_qdma->chans = devm_kzalloc(&pdev->dev, len, GFP_KERNEL);\n\tif (!fsl_qdma->chans)\n\t\treturn -ENOMEM;\n\n\tlen = sizeof(struct fsl_qdma_queue *) * blk_num;\n\tfsl_qdma->status = devm_kzalloc(&pdev->dev, len, GFP_KERNEL);\n\tif (!fsl_qdma->status)\n\t\treturn -ENOMEM;\n\n\tlen = sizeof(int) * blk_num;\n\tfsl_qdma->queue_irq = devm_kzalloc(&pdev->dev, len, GFP_KERNEL);\n\tif (!fsl_qdma->queue_irq)\n\t\treturn -ENOMEM;\n\n\tret = of_property_read_u32(np, \"fsl,dma-queues\", &queues);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Can't get queues.\\n\");\n\t\treturn ret;\n\t}\n\n\tfsl_qdma->desc_allocated = 0;\n\tfsl_qdma->n_chans = chans;\n\tfsl_qdma->n_queues = queues;\n\tfsl_qdma->block_number = blk_num;\n\tfsl_qdma->block_offset = blk_off;\n\n\tmutex_init(&fsl_qdma->fsl_qdma_mutex);\n\n\tfor (i = 0; i < fsl_qdma->block_number; i++) {\n\t\tfsl_qdma->status[i] = fsl_qdma_prep_status_queue(pdev);\n\t\tif (!fsl_qdma->status[i])\n\t\t\treturn -ENOMEM;\n\t}\n\tfsl_qdma->ctrl_base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(fsl_qdma->ctrl_base))\n\t\treturn PTR_ERR(fsl_qdma->ctrl_base);\n\n\tfsl_qdma->status_base = devm_platform_ioremap_resource(pdev, 1);\n\tif (IS_ERR(fsl_qdma->status_base))\n\t\treturn PTR_ERR(fsl_qdma->status_base);\n\n\tfsl_qdma->block_base = devm_platform_ioremap_resource(pdev, 2);\n\tif (IS_ERR(fsl_qdma->block_base))\n\t\treturn PTR_ERR(fsl_qdma->block_base);\n\tfsl_qdma->queue = fsl_qdma_alloc_queue_resources(pdev, fsl_qdma);\n\tif (!fsl_qdma->queue)\n\t\treturn -ENOMEM;\n\n\tret = fsl_qdma_irq_init(pdev, fsl_qdma);\n\tif (ret)\n\t\treturn ret;\n\n\tfsl_qdma->irq_base = platform_get_irq_byname(pdev, \"qdma-queue0\");\n\tif (fsl_qdma->irq_base < 0)\n\t\treturn fsl_qdma->irq_base;\n\n\tfsl_qdma->feature = of_property_read_bool(np, \"big-endian\");\n\tINIT_LIST_HEAD(&fsl_qdma->dma_dev.channels);\n\n\tfor (i = 0; i < fsl_qdma->n_chans; i++) {\n\t\tstruct fsl_qdma_chan *fsl_chan = &fsl_qdma->chans[i];\n\n\t\tfsl_chan->qdma = fsl_qdma;\n\t\tfsl_chan->queue = fsl_qdma->queue + i % (fsl_qdma->n_queues *\n\t\t\t\t\t\t\tfsl_qdma->block_number);\n\t\tfsl_chan->vchan.desc_free = fsl_qdma_free_desc;\n\t\tvchan_init(&fsl_chan->vchan, &fsl_qdma->dma_dev);\n\t}\n\n\tdma_cap_set(DMA_MEMCPY, fsl_qdma->dma_dev.cap_mask);\n\n\tfsl_qdma->dma_dev.dev = &pdev->dev;\n\tfsl_qdma->dma_dev.device_free_chan_resources =\n\t\tfsl_qdma_free_chan_resources;\n\tfsl_qdma->dma_dev.device_alloc_chan_resources =\n\t\tfsl_qdma_alloc_chan_resources;\n\tfsl_qdma->dma_dev.device_tx_status = dma_cookie_status;\n\tfsl_qdma->dma_dev.device_prep_dma_memcpy = fsl_qdma_prep_memcpy;\n\tfsl_qdma->dma_dev.device_issue_pending = fsl_qdma_issue_pending;\n\tfsl_qdma->dma_dev.device_synchronize = fsl_qdma_synchronize;\n\tfsl_qdma->dma_dev.device_terminate_all = fsl_qdma_terminate_all;\n\n\tret = dma_set_mask(&pdev->dev, DMA_BIT_MASK(40));\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"dma_set_mask failure.\\n\");\n\t\treturn ret;\n\t}\n\n\tplatform_set_drvdata(pdev, fsl_qdma);\n\n\tret = dma_async_device_register(&fsl_qdma->dma_dev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Can't register NXP Layerscape qDMA engine.\\n\");\n\t\treturn ret;\n\t}\n\n\tret = fsl_qdma_reg_init(fsl_qdma);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Can't Initialize the qDMA engine.\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void fsl_qdma_cleanup_vchan(struct dma_device *dmadev)\n{\n\tstruct fsl_qdma_chan *chan, *_chan;\n\n\tlist_for_each_entry_safe(chan, _chan,\n\t\t\t\t &dmadev->channels, vchan.chan.device_node) {\n\t\tlist_del(&chan->vchan.chan.device_node);\n\t\ttasklet_kill(&chan->vchan.task);\n\t}\n}\n\nstatic int fsl_qdma_remove(struct platform_device *pdev)\n{\n\tint i;\n\tstruct fsl_qdma_queue *status;\n\tstruct device_node *np = pdev->dev.of_node;\n\tstruct fsl_qdma_engine *fsl_qdma = platform_get_drvdata(pdev);\n\n\tfsl_qdma_irq_exit(pdev, fsl_qdma);\n\tfsl_qdma_cleanup_vchan(&fsl_qdma->dma_dev);\n\tof_dma_controller_free(np);\n\tdma_async_device_unregister(&fsl_qdma->dma_dev);\n\n\tfor (i = 0; i < fsl_qdma->block_number; i++) {\n\t\tstatus = fsl_qdma->status[i];\n\t\tdma_free_coherent(&pdev->dev, sizeof(struct fsl_qdma_format) *\n\t\t\t\tstatus->n_cq, status->cq, status->bus_addr);\n\t}\n\treturn 0;\n}\n\nstatic const struct of_device_id fsl_qdma_dt_ids[] = {\n\t{ .compatible = \"fsl,ls1021a-qdma\", },\n\t{   }\n};\nMODULE_DEVICE_TABLE(of, fsl_qdma_dt_ids);\n\nstatic struct platform_driver fsl_qdma_driver = {\n\t.driver\t\t= {\n\t\t.name\t= \"fsl-qdma\",\n\t\t.of_match_table = fsl_qdma_dt_ids,\n\t},\n\t.probe          = fsl_qdma_probe,\n\t.remove\t\t= fsl_qdma_remove,\n};\n\nmodule_platform_driver(fsl_qdma_driver);\n\nMODULE_ALIAS(\"platform:fsl-qdma\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"NXP Layerscape qDMA engine driver\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}