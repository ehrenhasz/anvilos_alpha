{
  "module_name": "stm32-mdma.c",
  "hash_id": "01c0a7f1f6919a62ec1dd7ae3d53d2cea47966bde5eb90597aedece7c6e4ce2a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/stm32-mdma.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmapool.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/iopoll.h>\n#include <linux/jiffies.h>\n#include <linux/list.h>\n#include <linux/log2.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_dma.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/reset.h>\n#include <linux/slab.h>\n\n#include \"virt-dma.h\"\n\n#define STM32_MDMA_GISR0\t\t0x0000  \n\n \n#define STM32_MDMA_CISR(x)\t\t(0x40 + 0x40 * (x))  \n#define STM32_MDMA_CISR_CRQA\t\tBIT(16)\n#define STM32_MDMA_CISR_TCIF\t\tBIT(4)\n#define STM32_MDMA_CISR_BTIF\t\tBIT(3)\n#define STM32_MDMA_CISR_BRTIF\t\tBIT(2)\n#define STM32_MDMA_CISR_CTCIF\t\tBIT(1)\n#define STM32_MDMA_CISR_TEIF\t\tBIT(0)\n\n \n#define STM32_MDMA_CIFCR(x)\t\t(0x44 + 0x40 * (x))\n#define STM32_MDMA_CIFCR_CLTCIF\t\tBIT(4)\n#define STM32_MDMA_CIFCR_CBTIF\t\tBIT(3)\n#define STM32_MDMA_CIFCR_CBRTIF\t\tBIT(2)\n#define STM32_MDMA_CIFCR_CCTCIF\t\tBIT(1)\n#define STM32_MDMA_CIFCR_CTEIF\t\tBIT(0)\n#define STM32_MDMA_CIFCR_CLEAR_ALL\t(STM32_MDMA_CIFCR_CLTCIF \\\n\t\t\t\t\t| STM32_MDMA_CIFCR_CBTIF \\\n\t\t\t\t\t| STM32_MDMA_CIFCR_CBRTIF \\\n\t\t\t\t\t| STM32_MDMA_CIFCR_CCTCIF \\\n\t\t\t\t\t| STM32_MDMA_CIFCR_CTEIF)\n\n \n#define STM32_MDMA_CESR(x)\t\t(0x48 + 0x40 * (x))\n#define STM32_MDMA_CESR_BSE\t\tBIT(11)\n#define STM32_MDMA_CESR_ASR\t\tBIT(10)\n#define STM32_MDMA_CESR_TEMD\t\tBIT(9)\n#define STM32_MDMA_CESR_TELD\t\tBIT(8)\n#define STM32_MDMA_CESR_TED\t\tBIT(7)\n#define STM32_MDMA_CESR_TEA_MASK\tGENMASK(6, 0)\n\n \n#define STM32_MDMA_CCR(x)\t\t(0x4C + 0x40 * (x))\n#define STM32_MDMA_CCR_SWRQ\t\tBIT(16)\n#define STM32_MDMA_CCR_WEX\t\tBIT(14)\n#define STM32_MDMA_CCR_HEX\t\tBIT(13)\n#define STM32_MDMA_CCR_BEX\t\tBIT(12)\n#define STM32_MDMA_CCR_SM\t\tBIT(8)\n#define STM32_MDMA_CCR_PL_MASK\t\tGENMASK(7, 6)\n#define STM32_MDMA_CCR_PL(n)\t\tFIELD_PREP(STM32_MDMA_CCR_PL_MASK, (n))\n#define STM32_MDMA_CCR_TCIE\t\tBIT(5)\n#define STM32_MDMA_CCR_BTIE\t\tBIT(4)\n#define STM32_MDMA_CCR_BRTIE\t\tBIT(3)\n#define STM32_MDMA_CCR_CTCIE\t\tBIT(2)\n#define STM32_MDMA_CCR_TEIE\t\tBIT(1)\n#define STM32_MDMA_CCR_EN\t\tBIT(0)\n#define STM32_MDMA_CCR_IRQ_MASK\t\t(STM32_MDMA_CCR_TCIE \\\n\t\t\t\t\t| STM32_MDMA_CCR_BTIE \\\n\t\t\t\t\t| STM32_MDMA_CCR_BRTIE \\\n\t\t\t\t\t| STM32_MDMA_CCR_CTCIE \\\n\t\t\t\t\t| STM32_MDMA_CCR_TEIE)\n\n \n#define STM32_MDMA_CTCR(x)\t\t(0x50 + 0x40 * (x))\n#define STM32_MDMA_CTCR_BWM\t\tBIT(31)\n#define STM32_MDMA_CTCR_SWRM\t\tBIT(30)\n#define STM32_MDMA_CTCR_TRGM_MSK\tGENMASK(29, 28)\n#define STM32_MDMA_CTCR_TRGM(n)\t\tFIELD_PREP(STM32_MDMA_CTCR_TRGM_MSK, (n))\n#define STM32_MDMA_CTCR_TRGM_GET(n)\tFIELD_GET(STM32_MDMA_CTCR_TRGM_MSK, (n))\n#define STM32_MDMA_CTCR_PAM_MASK\tGENMASK(27, 26)\n#define STM32_MDMA_CTCR_PAM(n)\t\tFIELD_PREP(STM32_MDMA_CTCR_PAM_MASK, (n))\n#define STM32_MDMA_CTCR_PKE\t\tBIT(25)\n#define STM32_MDMA_CTCR_TLEN_MSK\tGENMASK(24, 18)\n#define STM32_MDMA_CTCR_TLEN(n)\t\tFIELD_PREP(STM32_MDMA_CTCR_TLEN_MSK, (n))\n#define STM32_MDMA_CTCR_TLEN_GET(n)\tFIELD_GET(STM32_MDMA_CTCR_TLEN_MSK, (n))\n#define STM32_MDMA_CTCR_LEN2_MSK\tGENMASK(25, 18)\n#define STM32_MDMA_CTCR_LEN2(n)\t\tFIELD_PREP(STM32_MDMA_CTCR_LEN2_MSK, (n))\n#define STM32_MDMA_CTCR_LEN2_GET(n)\tFIELD_GET(STM32_MDMA_CTCR_LEN2_MSK, (n))\n#define STM32_MDMA_CTCR_DBURST_MASK\tGENMASK(17, 15)\n#define STM32_MDMA_CTCR_DBURST(n)\tFIELD_PREP(STM32_MDMA_CTCR_DBURST_MASK, (n))\n#define STM32_MDMA_CTCR_SBURST_MASK\tGENMASK(14, 12)\n#define STM32_MDMA_CTCR_SBURST(n)\tFIELD_PREP(STM32_MDMA_CTCR_SBURST_MASK, (n))\n#define STM32_MDMA_CTCR_DINCOS_MASK\tGENMASK(11, 10)\n#define STM32_MDMA_CTCR_DINCOS(n)\tFIELD_PREP(STM32_MDMA_CTCR_DINCOS_MASK, (n))\n#define STM32_MDMA_CTCR_SINCOS_MASK\tGENMASK(9, 8)\n#define STM32_MDMA_CTCR_SINCOS(n)\tFIELD_PREP(STM32_MDMA_CTCR_SINCOS_MASK, (n))\n#define STM32_MDMA_CTCR_DSIZE_MASK\tGENMASK(7, 6)\n#define STM32_MDMA_CTCR_DSIZE(n)\tFIELD_PREP(STM32_MDMA_CTCR_DSIZE_MASK, (n))\n#define STM32_MDMA_CTCR_SSIZE_MASK\tGENMASK(5, 4)\n#define STM32_MDMA_CTCR_SSIZE(n)\tFIELD_PREP(STM32_MDMA_CTCR_SSIZE_MASK, (n))\n#define STM32_MDMA_CTCR_DINC_MASK\tGENMASK(3, 2)\n#define STM32_MDMA_CTCR_DINC(n)\t\tFIELD_PREP(STM32_MDMA_CTCR_DINC_MASK, (n))\n#define STM32_MDMA_CTCR_SINC_MASK\tGENMASK(1, 0)\n#define STM32_MDMA_CTCR_SINC(n)\t\tFIELD_PREP(STM32_MDMA_CTCR_SINC_MASK, (n))\n#define STM32_MDMA_CTCR_CFG_MASK\t(STM32_MDMA_CTCR_SINC_MASK \\\n\t\t\t\t\t| STM32_MDMA_CTCR_DINC_MASK \\\n\t\t\t\t\t| STM32_MDMA_CTCR_SINCOS_MASK \\\n\t\t\t\t\t| STM32_MDMA_CTCR_DINCOS_MASK \\\n\t\t\t\t\t| STM32_MDMA_CTCR_LEN2_MSK \\\n\t\t\t\t\t| STM32_MDMA_CTCR_TRGM_MSK)\n\n \n#define STM32_MDMA_CBNDTR(x)\t\t(0x54 + 0x40 * (x))\n#define STM32_MDMA_CBNDTR_BRC_MK\tGENMASK(31, 20)\n#define STM32_MDMA_CBNDTR_BRC(n)\tFIELD_PREP(STM32_MDMA_CBNDTR_BRC_MK, (n))\n#define STM32_MDMA_CBNDTR_BRC_GET(n)\tFIELD_GET(STM32_MDMA_CBNDTR_BRC_MK, (n))\n\n#define STM32_MDMA_CBNDTR_BRDUM\t\tBIT(19)\n#define STM32_MDMA_CBNDTR_BRSUM\t\tBIT(18)\n#define STM32_MDMA_CBNDTR_BNDT_MASK\tGENMASK(16, 0)\n#define STM32_MDMA_CBNDTR_BNDT(n)\tFIELD_PREP(STM32_MDMA_CBNDTR_BNDT_MASK, (n))\n\n \n#define STM32_MDMA_CSAR(x)\t\t(0x58 + 0x40 * (x))\n\n \n#define STM32_MDMA_CDAR(x)\t\t(0x5C + 0x40 * (x))\n\n \n#define STM32_MDMA_CBRUR(x)\t\t(0x60 + 0x40 * (x))\n#define STM32_MDMA_CBRUR_DUV_MASK\tGENMASK(31, 16)\n#define STM32_MDMA_CBRUR_DUV(n)\t\tFIELD_PREP(STM32_MDMA_CBRUR_DUV_MASK, (n))\n#define STM32_MDMA_CBRUR_SUV_MASK\tGENMASK(15, 0)\n#define STM32_MDMA_CBRUR_SUV(n)\t\tFIELD_PREP(STM32_MDMA_CBRUR_SUV_MASK, (n))\n\n \n#define STM32_MDMA_CLAR(x)\t\t(0x64 + 0x40 * (x))\n\n \n#define STM32_MDMA_CTBR(x)\t\t(0x68 + 0x40 * (x))\n#define STM32_MDMA_CTBR_DBUS\t\tBIT(17)\n#define STM32_MDMA_CTBR_SBUS\t\tBIT(16)\n#define STM32_MDMA_CTBR_TSEL_MASK\tGENMASK(5, 0)\n#define STM32_MDMA_CTBR_TSEL(n)\t\tFIELD_PREP(STM32_MDMA_CTBR_TSEL_MASK, (n))\n\n \n#define STM32_MDMA_CMAR(x)\t\t(0x70 + 0x40 * (x))\n\n \n#define STM32_MDMA_CMDR(x)\t\t(0x74 + 0x40 * (x))\n\n#define STM32_MDMA_MAX_BUF_LEN\t\t128\n#define STM32_MDMA_MAX_BLOCK_LEN\t65536\n#define STM32_MDMA_MAX_CHANNELS\t\t32\n#define STM32_MDMA_MAX_REQUESTS\t\t256\n#define STM32_MDMA_MAX_BURST\t\t128\n#define STM32_MDMA_VERY_HIGH_PRIORITY\t0x3\n\nenum stm32_mdma_trigger_mode {\n\tSTM32_MDMA_BUFFER,\n\tSTM32_MDMA_BLOCK,\n\tSTM32_MDMA_BLOCK_REP,\n\tSTM32_MDMA_LINKED_LIST,\n};\n\nenum stm32_mdma_width {\n\tSTM32_MDMA_BYTE,\n\tSTM32_MDMA_HALF_WORD,\n\tSTM32_MDMA_WORD,\n\tSTM32_MDMA_DOUBLE_WORD,\n};\n\nenum stm32_mdma_inc_mode {\n\tSTM32_MDMA_FIXED = 0,\n\tSTM32_MDMA_INC = 2,\n\tSTM32_MDMA_DEC = 3,\n};\n\nstruct stm32_mdma_chan_config {\n\tu32 request;\n\tu32 priority_level;\n\tu32 transfer_config;\n\tu32 mask_addr;\n\tu32 mask_data;\n\tbool m2m_hw;  \n};\n\nstruct stm32_mdma_hwdesc {\n\tu32 ctcr;\n\tu32 cbndtr;\n\tu32 csar;\n\tu32 cdar;\n\tu32 cbrur;\n\tu32 clar;\n\tu32 ctbr;\n\tu32 dummy;\n\tu32 cmar;\n\tu32 cmdr;\n} __aligned(64);\n\nstruct stm32_mdma_desc_node {\n\tstruct stm32_mdma_hwdesc *hwdesc;\n\tdma_addr_t hwdesc_phys;\n};\n\nstruct stm32_mdma_desc {\n\tstruct virt_dma_desc vdesc;\n\tu32 ccr;\n\tbool cyclic;\n\tu32 count;\n\tstruct stm32_mdma_desc_node node[];\n};\n\nstruct stm32_mdma_dma_config {\n\tu32 request;\t \n\tu32 cmar;\t \n\tu32 cmdr;\t \n};\n\nstruct stm32_mdma_chan {\n\tstruct virt_dma_chan vchan;\n\tstruct dma_pool *desc_pool;\n\tu32 id;\n\tstruct stm32_mdma_desc *desc;\n\tu32 curr_hwdesc;\n\tstruct dma_slave_config dma_config;\n\tstruct stm32_mdma_chan_config chan_config;\n\tbool busy;\n\tu32 mem_burst;\n\tu32 mem_width;\n};\n\nstruct stm32_mdma_device {\n\tstruct dma_device ddev;\n\tvoid __iomem *base;\n\tstruct clk *clk;\n\tint irq;\n\tu32 nr_channels;\n\tu32 nr_requests;\n\tu32 nr_ahb_addr_masks;\n\tu32 chan_reserved;\n\tstruct stm32_mdma_chan chan[STM32_MDMA_MAX_CHANNELS];\n\tu32 ahb_addr_masks[];\n};\n\nstatic struct stm32_mdma_device *stm32_mdma_get_dev(\n\tstruct stm32_mdma_chan *chan)\n{\n\treturn container_of(chan->vchan.chan.device, struct stm32_mdma_device,\n\t\t\t    ddev);\n}\n\nstatic struct stm32_mdma_chan *to_stm32_mdma_chan(struct dma_chan *c)\n{\n\treturn container_of(c, struct stm32_mdma_chan, vchan.chan);\n}\n\nstatic struct stm32_mdma_desc *to_stm32_mdma_desc(struct virt_dma_desc *vdesc)\n{\n\treturn container_of(vdesc, struct stm32_mdma_desc, vdesc);\n}\n\nstatic struct device *chan2dev(struct stm32_mdma_chan *chan)\n{\n\treturn &chan->vchan.chan.dev->device;\n}\n\nstatic struct device *mdma2dev(struct stm32_mdma_device *mdma_dev)\n{\n\treturn mdma_dev->ddev.dev;\n}\n\nstatic u32 stm32_mdma_read(struct stm32_mdma_device *dmadev, u32 reg)\n{\n\treturn readl_relaxed(dmadev->base + reg);\n}\n\nstatic void stm32_mdma_write(struct stm32_mdma_device *dmadev, u32 reg, u32 val)\n{\n\twritel_relaxed(val, dmadev->base + reg);\n}\n\nstatic void stm32_mdma_set_bits(struct stm32_mdma_device *dmadev, u32 reg,\n\t\t\t\tu32 mask)\n{\n\tvoid __iomem *addr = dmadev->base + reg;\n\n\twritel_relaxed(readl_relaxed(addr) | mask, addr);\n}\n\nstatic void stm32_mdma_clr_bits(struct stm32_mdma_device *dmadev, u32 reg,\n\t\t\t\tu32 mask)\n{\n\tvoid __iomem *addr = dmadev->base + reg;\n\n\twritel_relaxed(readl_relaxed(addr) & ~mask, addr);\n}\n\nstatic struct stm32_mdma_desc *stm32_mdma_alloc_desc(\n\t\tstruct stm32_mdma_chan *chan, u32 count)\n{\n\tstruct stm32_mdma_desc *desc;\n\tint i;\n\n\tdesc = kzalloc(struct_size(desc, node, count), GFP_NOWAIT);\n\tif (!desc)\n\t\treturn NULL;\n\n\tfor (i = 0; i < count; i++) {\n\t\tdesc->node[i].hwdesc =\n\t\t\tdma_pool_alloc(chan->desc_pool, GFP_NOWAIT,\n\t\t\t\t       &desc->node[i].hwdesc_phys);\n\t\tif (!desc->node[i].hwdesc)\n\t\t\tgoto err;\n\t}\n\n\tdesc->count = count;\n\n\treturn desc;\n\nerr:\n\tdev_err(chan2dev(chan), \"Failed to allocate descriptor\\n\");\n\twhile (--i >= 0)\n\t\tdma_pool_free(chan->desc_pool, desc->node[i].hwdesc,\n\t\t\t      desc->node[i].hwdesc_phys);\n\tkfree(desc);\n\treturn NULL;\n}\n\nstatic void stm32_mdma_desc_free(struct virt_dma_desc *vdesc)\n{\n\tstruct stm32_mdma_desc *desc = to_stm32_mdma_desc(vdesc);\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(vdesc->tx.chan);\n\tint i;\n\n\tfor (i = 0; i < desc->count; i++)\n\t\tdma_pool_free(chan->desc_pool, desc->node[i].hwdesc,\n\t\t\t      desc->node[i].hwdesc_phys);\n\tkfree(desc);\n}\n\nstatic int stm32_mdma_get_width(struct stm32_mdma_chan *chan,\n\t\t\t\tenum dma_slave_buswidth width)\n{\n\tswitch (width) {\n\tcase DMA_SLAVE_BUSWIDTH_1_BYTE:\n\tcase DMA_SLAVE_BUSWIDTH_2_BYTES:\n\tcase DMA_SLAVE_BUSWIDTH_4_BYTES:\n\tcase DMA_SLAVE_BUSWIDTH_8_BYTES:\n\t\treturn ffs(width) - 1;\n\tdefault:\n\t\tdev_err(chan2dev(chan), \"Dma bus width %i not supported\\n\",\n\t\t\twidth);\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic enum dma_slave_buswidth stm32_mdma_get_max_width(dma_addr_t addr,\n\t\t\t\t\t\t\tu32 buf_len, u32 tlen)\n{\n\tenum dma_slave_buswidth max_width = DMA_SLAVE_BUSWIDTH_8_BYTES;\n\n\tfor (max_width = DMA_SLAVE_BUSWIDTH_8_BYTES;\n\t     max_width > DMA_SLAVE_BUSWIDTH_1_BYTE;\n\t     max_width >>= 1) {\n\t\t \n\t\tif ((((buf_len | addr) & (max_width - 1)) == 0) &&\n\t\t    tlen >= max_width)\n\t\t\tbreak;\n\t}\n\n\treturn max_width;\n}\n\nstatic u32 stm32_mdma_get_best_burst(u32 buf_len, u32 tlen, u32 max_burst,\n\t\t\t\t     enum dma_slave_buswidth width)\n{\n\tu32 best_burst;\n\n\tbest_burst = min((u32)1 << __ffs(tlen | buf_len),\n\t\t\t max_burst * width) / width;\n\n\treturn (best_burst > 0) ? best_burst : 1;\n}\n\nstatic int stm32_mdma_disable_chan(struct stm32_mdma_chan *chan)\n{\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tu32 ccr, cisr, id, reg;\n\tint ret;\n\n\tid = chan->id;\n\treg = STM32_MDMA_CCR(id);\n\n\t \n\tstm32_mdma_clr_bits(dmadev, reg, STM32_MDMA_CCR_IRQ_MASK);\n\n\tccr = stm32_mdma_read(dmadev, reg);\n\tif (ccr & STM32_MDMA_CCR_EN) {\n\t\tstm32_mdma_clr_bits(dmadev, reg, STM32_MDMA_CCR_EN);\n\n\t\t \n\t\tret = readl_relaxed_poll_timeout_atomic(\n\t\t\t\tdmadev->base + STM32_MDMA_CISR(id), cisr,\n\t\t\t\t(cisr & STM32_MDMA_CISR_CTCIF), 10, 1000);\n\t\tif (ret) {\n\t\t\tdev_err(chan2dev(chan), \"%s: timeout!\\n\", __func__);\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void stm32_mdma_stop(struct stm32_mdma_chan *chan)\n{\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tu32 status;\n\tint ret;\n\n\t \n\tret = stm32_mdma_disable_chan(chan);\n\tif (ret < 0)\n\t\treturn;\n\n\t \n\tstatus = stm32_mdma_read(dmadev, STM32_MDMA_CISR(chan->id));\n\tif (status) {\n\t\tdev_dbg(chan2dev(chan), \"%s(): clearing interrupt: 0x%08x\\n\",\n\t\t\t__func__, status);\n\t\tstm32_mdma_set_bits(dmadev, STM32_MDMA_CIFCR(chan->id), status);\n\t}\n\n\tchan->busy = false;\n}\n\nstatic void stm32_mdma_set_bus(struct stm32_mdma_device *dmadev, u32 *ctbr,\n\t\t\t       u32 ctbr_mask, u32 src_addr)\n{\n\tu32 mask;\n\tint i;\n\n\t \n\t*ctbr &= ~ctbr_mask;\n\tmask = src_addr & 0xF0000000;\n\tfor (i = 0; i < dmadev->nr_ahb_addr_masks; i++) {\n\t\tif (mask == dmadev->ahb_addr_masks[i]) {\n\t\t\t*ctbr |= ctbr_mask;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic int stm32_mdma_set_xfer_param(struct stm32_mdma_chan *chan,\n\t\t\t\t     enum dma_transfer_direction direction,\n\t\t\t\t     u32 *mdma_ccr, u32 *mdma_ctcr,\n\t\t\t\t     u32 *mdma_ctbr, dma_addr_t addr,\n\t\t\t\t     u32 buf_len)\n{\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tstruct stm32_mdma_chan_config *chan_config = &chan->chan_config;\n\tenum dma_slave_buswidth src_addr_width, dst_addr_width;\n\tphys_addr_t src_addr, dst_addr;\n\tint src_bus_width, dst_bus_width;\n\tu32 src_maxburst, dst_maxburst, src_best_burst, dst_best_burst;\n\tu32 ccr, ctcr, ctbr, tlen;\n\n\tsrc_addr_width = chan->dma_config.src_addr_width;\n\tdst_addr_width = chan->dma_config.dst_addr_width;\n\tsrc_maxburst = chan->dma_config.src_maxburst;\n\tdst_maxburst = chan->dma_config.dst_maxburst;\n\n\tccr = stm32_mdma_read(dmadev, STM32_MDMA_CCR(chan->id)) & ~STM32_MDMA_CCR_EN;\n\tctcr = stm32_mdma_read(dmadev, STM32_MDMA_CTCR(chan->id));\n\tctbr = stm32_mdma_read(dmadev, STM32_MDMA_CTBR(chan->id));\n\n\t \n\tctcr &= ~STM32_MDMA_CTCR_SWRM;\n\n\t \n\tctcr &= ~STM32_MDMA_CTCR_CFG_MASK;\n\tctcr |= chan_config->transfer_config & STM32_MDMA_CTCR_CFG_MASK;\n\n\t \n\ttlen = STM32_MDMA_CTCR_LEN2_GET(ctcr);\n\tctcr &= ~STM32_MDMA_CTCR_LEN2_MSK;\n\tctcr |= STM32_MDMA_CTCR_TLEN((tlen - 1));\n\n\t \n\tctcr &= ~STM32_MDMA_CTCR_PKE;\n\n\t \n\tif (src_maxburst * src_addr_width > STM32_MDMA_MAX_BURST ||\n\t    dst_maxburst * dst_addr_width > STM32_MDMA_MAX_BURST) {\n\t\tdev_err(chan2dev(chan),\n\t\t\t\"burst size * bus width higher than %d bytes\\n\",\n\t\t\tSTM32_MDMA_MAX_BURST);\n\t\treturn -EINVAL;\n\t}\n\n\tif ((!is_power_of_2(src_maxburst) && src_maxburst > 0) ||\n\t    (!is_power_of_2(dst_maxburst) && dst_maxburst > 0)) {\n\t\tdev_err(chan2dev(chan), \"burst size must be a power of 2\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tccr &= ~(STM32_MDMA_CCR_SWRQ | STM32_MDMA_CCR_WEX | STM32_MDMA_CCR_HEX |\n\t\t STM32_MDMA_CCR_BEX | STM32_MDMA_CCR_PL_MASK);\n\tccr |= STM32_MDMA_CCR_PL(chan_config->priority_level);\n\n\t \n\tctbr &= ~STM32_MDMA_CTBR_TSEL_MASK;\n\tctbr |= STM32_MDMA_CTBR_TSEL(chan_config->request);\n\n\tswitch (direction) {\n\tcase DMA_MEM_TO_DEV:\n\t\tdst_addr = chan->dma_config.dst_addr;\n\n\t\t \n\t\tif (chan_config->m2m_hw)\n\t\t\tdst_addr_width = stm32_mdma_get_max_width(dst_addr, buf_len,\n\t\t\t\t\t\t\t\t  STM32_MDMA_MAX_BUF_LEN);\n\t\tdst_bus_width = stm32_mdma_get_width(chan, dst_addr_width);\n\t\tif (dst_bus_width < 0)\n\t\t\treturn dst_bus_width;\n\t\tctcr &= ~STM32_MDMA_CTCR_DSIZE_MASK;\n\t\tctcr |= STM32_MDMA_CTCR_DSIZE(dst_bus_width);\n\t\tif (chan_config->m2m_hw) {\n\t\t\tctcr &= ~STM32_MDMA_CTCR_DINCOS_MASK;\n\t\t\tctcr |= STM32_MDMA_CTCR_DINCOS(dst_bus_width);\n\t\t}\n\n\t\t \n\t\tif (chan_config->m2m_hw)\n\t\t\tdst_maxburst = STM32_MDMA_MAX_BUF_LEN / dst_addr_width;\n\n\t\tdst_best_burst = stm32_mdma_get_best_burst(buf_len, tlen,\n\t\t\t\t\t\t\t   dst_maxburst,\n\t\t\t\t\t\t\t   dst_addr_width);\n\t\tchan->mem_burst = dst_best_burst;\n\t\tctcr &= ~STM32_MDMA_CTCR_DBURST_MASK;\n\t\tctcr |= STM32_MDMA_CTCR_DBURST((ilog2(dst_best_burst)));\n\n\t\t \n\t\tsrc_addr_width = stm32_mdma_get_max_width(addr, buf_len, tlen);\n\t\tchan->mem_width = src_addr_width;\n\t\tsrc_bus_width = stm32_mdma_get_width(chan, src_addr_width);\n\t\tif (src_bus_width < 0)\n\t\t\treturn src_bus_width;\n\t\tctcr &= ~STM32_MDMA_CTCR_SSIZE_MASK |\n\t\t\tSTM32_MDMA_CTCR_SINCOS_MASK;\n\t\tctcr |= STM32_MDMA_CTCR_SSIZE(src_bus_width) |\n\t\t\tSTM32_MDMA_CTCR_SINCOS(src_bus_width);\n\n\t\t \n\t\tsrc_maxburst = STM32_MDMA_MAX_BUF_LEN / src_addr_width;\n\t\tsrc_best_burst = stm32_mdma_get_best_burst(buf_len, tlen,\n\t\t\t\t\t\t\t   src_maxburst,\n\t\t\t\t\t\t\t   src_addr_width);\n\t\tchan->mem_burst = src_best_burst;\n\t\tctcr &= ~STM32_MDMA_CTCR_SBURST_MASK;\n\t\tctcr |= STM32_MDMA_CTCR_SBURST((ilog2(src_best_burst)));\n\n\t\t \n\t\tstm32_mdma_set_bus(dmadev, &ctbr, STM32_MDMA_CTBR_DBUS,\n\t\t\t\t   dst_addr);\n\n\t\tif (dst_bus_width != src_bus_width)\n\t\t\tctcr |= STM32_MDMA_CTCR_PKE;\n\n\t\t \n\t\tstm32_mdma_write(dmadev, STM32_MDMA_CDAR(chan->id), dst_addr);\n\t\tbreak;\n\n\tcase DMA_DEV_TO_MEM:\n\t\tsrc_addr = chan->dma_config.src_addr;\n\n\t\t \n\t\tif (chan_config->m2m_hw)\n\t\t\tsrc_addr_width = stm32_mdma_get_max_width(src_addr, buf_len,\n\t\t\t\t\t\t\t\t  STM32_MDMA_MAX_BUF_LEN);\n\n\t\tsrc_bus_width = stm32_mdma_get_width(chan, src_addr_width);\n\t\tif (src_bus_width < 0)\n\t\t\treturn src_bus_width;\n\t\tctcr &= ~STM32_MDMA_CTCR_SSIZE_MASK;\n\t\tctcr |= STM32_MDMA_CTCR_SSIZE(src_bus_width);\n\t\tif (chan_config->m2m_hw) {\n\t\t\tctcr &= ~STM32_MDMA_CTCR_SINCOS_MASK;\n\t\t\tctcr |= STM32_MDMA_CTCR_SINCOS(src_bus_width);\n\t\t}\n\n\t\t \n\t\tif (chan_config->m2m_hw)\n\t\t\tsrc_maxburst = STM32_MDMA_MAX_BUF_LEN / src_addr_width;\n\n\t\tsrc_best_burst = stm32_mdma_get_best_burst(buf_len, tlen,\n\t\t\t\t\t\t\t   src_maxburst,\n\t\t\t\t\t\t\t   src_addr_width);\n\t\tctcr &= ~STM32_MDMA_CTCR_SBURST_MASK;\n\t\tctcr |= STM32_MDMA_CTCR_SBURST((ilog2(src_best_burst)));\n\n\t\t \n\t\tdst_addr_width = stm32_mdma_get_max_width(addr, buf_len, tlen);\n\t\tchan->mem_width = dst_addr_width;\n\t\tdst_bus_width = stm32_mdma_get_width(chan, dst_addr_width);\n\t\tif (dst_bus_width < 0)\n\t\t\treturn dst_bus_width;\n\t\tctcr &= ~(STM32_MDMA_CTCR_DSIZE_MASK |\n\t\t\tSTM32_MDMA_CTCR_DINCOS_MASK);\n\t\tctcr |= STM32_MDMA_CTCR_DSIZE(dst_bus_width) |\n\t\t\tSTM32_MDMA_CTCR_DINCOS(dst_bus_width);\n\n\t\t \n\t\tdst_maxburst = STM32_MDMA_MAX_BUF_LEN / dst_addr_width;\n\t\tdst_best_burst = stm32_mdma_get_best_burst(buf_len, tlen,\n\t\t\t\t\t\t\t   dst_maxburst,\n\t\t\t\t\t\t\t   dst_addr_width);\n\t\tctcr &= ~STM32_MDMA_CTCR_DBURST_MASK;\n\t\tctcr |= STM32_MDMA_CTCR_DBURST((ilog2(dst_best_burst)));\n\n\t\t \n\t\tstm32_mdma_set_bus(dmadev, &ctbr, STM32_MDMA_CTBR_SBUS,\n\t\t\t\t   src_addr);\n\n\t\tif (dst_bus_width != src_bus_width)\n\t\t\tctcr |= STM32_MDMA_CTCR_PKE;\n\n\t\t \n\t\tstm32_mdma_write(dmadev, STM32_MDMA_CSAR(chan->id), src_addr);\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(chan2dev(chan), \"Dma direction is not supported\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t*mdma_ccr = ccr;\n\t*mdma_ctcr = ctcr;\n\t*mdma_ctbr = ctbr;\n\n\treturn 0;\n}\n\nstatic void stm32_mdma_dump_hwdesc(struct stm32_mdma_chan *chan,\n\t\t\t\t   struct stm32_mdma_desc_node *node)\n{\n\tdev_dbg(chan2dev(chan), \"hwdesc:  %pad\\n\", &node->hwdesc_phys);\n\tdev_dbg(chan2dev(chan), \"CTCR:    0x%08x\\n\", node->hwdesc->ctcr);\n\tdev_dbg(chan2dev(chan), \"CBNDTR:  0x%08x\\n\", node->hwdesc->cbndtr);\n\tdev_dbg(chan2dev(chan), \"CSAR:    0x%08x\\n\", node->hwdesc->csar);\n\tdev_dbg(chan2dev(chan), \"CDAR:    0x%08x\\n\", node->hwdesc->cdar);\n\tdev_dbg(chan2dev(chan), \"CBRUR:   0x%08x\\n\", node->hwdesc->cbrur);\n\tdev_dbg(chan2dev(chan), \"CLAR:    0x%08x\\n\", node->hwdesc->clar);\n\tdev_dbg(chan2dev(chan), \"CTBR:    0x%08x\\n\", node->hwdesc->ctbr);\n\tdev_dbg(chan2dev(chan), \"CMAR:    0x%08x\\n\", node->hwdesc->cmar);\n\tdev_dbg(chan2dev(chan), \"CMDR:    0x%08x\\n\\n\", node->hwdesc->cmdr);\n}\n\nstatic void stm32_mdma_setup_hwdesc(struct stm32_mdma_chan *chan,\n\t\t\t\t    struct stm32_mdma_desc *desc,\n\t\t\t\t    enum dma_transfer_direction dir, u32 count,\n\t\t\t\t    dma_addr_t src_addr, dma_addr_t dst_addr,\n\t\t\t\t    u32 len, u32 ctcr, u32 ctbr, bool is_last,\n\t\t\t\t    bool is_first, bool is_cyclic)\n{\n\tstruct stm32_mdma_chan_config *config = &chan->chan_config;\n\tstruct stm32_mdma_hwdesc *hwdesc;\n\tu32 next = count + 1;\n\n\thwdesc = desc->node[count].hwdesc;\n\thwdesc->ctcr = ctcr;\n\thwdesc->cbndtr &= ~(STM32_MDMA_CBNDTR_BRC_MK |\n\t\t\tSTM32_MDMA_CBNDTR_BRDUM |\n\t\t\tSTM32_MDMA_CBNDTR_BRSUM |\n\t\t\tSTM32_MDMA_CBNDTR_BNDT_MASK);\n\thwdesc->cbndtr |= STM32_MDMA_CBNDTR_BNDT(len);\n\thwdesc->csar = src_addr;\n\thwdesc->cdar = dst_addr;\n\thwdesc->cbrur = 0;\n\thwdesc->ctbr = ctbr;\n\thwdesc->cmar = config->mask_addr;\n\thwdesc->cmdr = config->mask_data;\n\n\tif (is_last) {\n\t\tif (is_cyclic)\n\t\t\thwdesc->clar = desc->node[0].hwdesc_phys;\n\t\telse\n\t\t\thwdesc->clar = 0;\n\t} else {\n\t\thwdesc->clar = desc->node[next].hwdesc_phys;\n\t}\n\n\tstm32_mdma_dump_hwdesc(chan, &desc->node[count]);\n}\n\nstatic int stm32_mdma_setup_xfer(struct stm32_mdma_chan *chan,\n\t\t\t\t struct stm32_mdma_desc *desc,\n\t\t\t\t struct scatterlist *sgl, u32 sg_len,\n\t\t\t\t enum dma_transfer_direction direction)\n{\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tstruct dma_slave_config *dma_config = &chan->dma_config;\n\tstruct stm32_mdma_chan_config *chan_config = &chan->chan_config;\n\tstruct scatterlist *sg;\n\tdma_addr_t src_addr, dst_addr;\n\tu32 m2m_hw_period, ccr, ctcr, ctbr;\n\tint i, ret = 0;\n\n\tif (chan_config->m2m_hw)\n\t\tm2m_hw_period = sg_dma_len(sgl);\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tif (sg_dma_len(sg) > STM32_MDMA_MAX_BLOCK_LEN) {\n\t\t\tdev_err(chan2dev(chan), \"Invalid block len\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (direction == DMA_MEM_TO_DEV) {\n\t\t\tsrc_addr = sg_dma_address(sg);\n\t\t\tdst_addr = dma_config->dst_addr;\n\t\t\tif (chan_config->m2m_hw && (i & 1))\n\t\t\t\tdst_addr += m2m_hw_period;\n\t\t\tret = stm32_mdma_set_xfer_param(chan, direction, &ccr,\n\t\t\t\t\t\t\t&ctcr, &ctbr, src_addr,\n\t\t\t\t\t\t\tsg_dma_len(sg));\n\t\t\tstm32_mdma_set_bus(dmadev, &ctbr, STM32_MDMA_CTBR_SBUS,\n\t\t\t\t\t   src_addr);\n\t\t} else {\n\t\t\tsrc_addr = dma_config->src_addr;\n\t\t\tif (chan_config->m2m_hw && (i & 1))\n\t\t\t\tsrc_addr += m2m_hw_period;\n\t\t\tdst_addr = sg_dma_address(sg);\n\t\t\tret = stm32_mdma_set_xfer_param(chan, direction, &ccr,\n\t\t\t\t\t\t\t&ctcr, &ctbr, dst_addr,\n\t\t\t\t\t\t\tsg_dma_len(sg));\n\t\t\tstm32_mdma_set_bus(dmadev, &ctbr, STM32_MDMA_CTBR_DBUS,\n\t\t\t\t\t   dst_addr);\n\t\t}\n\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tstm32_mdma_setup_hwdesc(chan, desc, direction, i, src_addr,\n\t\t\t\t\tdst_addr, sg_dma_len(sg), ctcr, ctbr,\n\t\t\t\t\ti == sg_len - 1, i == 0, false);\n\t}\n\n\t \n\tccr &= ~STM32_MDMA_CCR_IRQ_MASK;\n\tccr |= STM32_MDMA_CCR_TEIE | STM32_MDMA_CCR_CTCIE;\n\tdesc->ccr = ccr;\n\n\treturn 0;\n}\n\nstatic struct dma_async_tx_descriptor *\nstm32_mdma_prep_slave_sg(struct dma_chan *c, struct scatterlist *sgl,\n\t\t\t u32 sg_len, enum dma_transfer_direction direction,\n\t\t\t unsigned long flags, void *context)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tstruct stm32_mdma_chan_config *chan_config = &chan->chan_config;\n\tstruct stm32_mdma_desc *desc;\n\tint i, ret;\n\n\t \n\tif (chan->desc && chan->desc->cyclic) {\n\t\tdev_err(chan2dev(chan),\n\t\t\t\"Request not allowed when dma in cyclic mode\\n\");\n\t\treturn NULL;\n\t}\n\n\tdesc = stm32_mdma_alloc_desc(chan, sg_len);\n\tif (!desc)\n\t\treturn NULL;\n\n\tret = stm32_mdma_setup_xfer(chan, desc, sgl, sg_len, direction);\n\tif (ret < 0)\n\t\tgoto xfer_setup_err;\n\n\t \n\tif (chan_config->m2m_hw && direction == DMA_MEM_TO_DEV) {\n\t\tstruct stm32_mdma_hwdesc *hwdesc;\n\n\t\tfor (i = 0; i < sg_len; i++) {\n\t\t\thwdesc = desc->node[i].hwdesc;\n\t\t\thwdesc->cmar = 0;\n\t\t\thwdesc->cmdr = 0;\n\t\t}\n\t}\n\n\tdesc->cyclic = false;\n\n\treturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n\nxfer_setup_err:\n\tfor (i = 0; i < desc->count; i++)\n\t\tdma_pool_free(chan->desc_pool, desc->node[i].hwdesc,\n\t\t\t      desc->node[i].hwdesc_phys);\n\tkfree(desc);\n\treturn NULL;\n}\n\nstatic struct dma_async_tx_descriptor *\nstm32_mdma_prep_dma_cyclic(struct dma_chan *c, dma_addr_t buf_addr,\n\t\t\t   size_t buf_len, size_t period_len,\n\t\t\t   enum dma_transfer_direction direction,\n\t\t\t   unsigned long flags)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tstruct dma_slave_config *dma_config = &chan->dma_config;\n\tstruct stm32_mdma_chan_config *chan_config = &chan->chan_config;\n\tstruct stm32_mdma_desc *desc;\n\tdma_addr_t src_addr, dst_addr;\n\tu32 ccr, ctcr, ctbr, count;\n\tint i, ret;\n\n\t \n\tif (chan->desc && chan->desc->cyclic) {\n\t\tdev_err(chan2dev(chan),\n\t\t\t\"Request not allowed when dma in cyclic mode\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!buf_len || !period_len || period_len > STM32_MDMA_MAX_BLOCK_LEN) {\n\t\tdev_err(chan2dev(chan), \"Invalid buffer/period len\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (buf_len % period_len) {\n\t\tdev_err(chan2dev(chan), \"buf_len not multiple of period_len\\n\");\n\t\treturn NULL;\n\t}\n\n\tcount = buf_len / period_len;\n\n\tdesc = stm32_mdma_alloc_desc(chan, count);\n\tif (!desc)\n\t\treturn NULL;\n\n\t \n\tif (direction == DMA_MEM_TO_DEV) {\n\t\tsrc_addr = buf_addr;\n\t\tret = stm32_mdma_set_xfer_param(chan, direction, &ccr, &ctcr,\n\t\t\t\t\t\t&ctbr, src_addr, period_len);\n\t\tstm32_mdma_set_bus(dmadev, &ctbr, STM32_MDMA_CTBR_SBUS,\n\t\t\t\t   src_addr);\n\t} else {\n\t\tdst_addr = buf_addr;\n\t\tret = stm32_mdma_set_xfer_param(chan, direction, &ccr, &ctcr,\n\t\t\t\t\t\t&ctbr, dst_addr, period_len);\n\t\tstm32_mdma_set_bus(dmadev, &ctbr, STM32_MDMA_CTBR_DBUS,\n\t\t\t\t   dst_addr);\n\t}\n\n\tif (ret < 0)\n\t\tgoto xfer_setup_err;\n\n\t \n\tccr &= ~STM32_MDMA_CCR_IRQ_MASK;\n\tccr |= STM32_MDMA_CCR_TEIE | STM32_MDMA_CCR_CTCIE | STM32_MDMA_CCR_BTIE;\n\tdesc->ccr = ccr;\n\n\t \n\tfor (i = 0; i < count; i++) {\n\t\tif (direction == DMA_MEM_TO_DEV) {\n\t\t\tsrc_addr = buf_addr + i * period_len;\n\t\t\tdst_addr = dma_config->dst_addr;\n\t\t\tif (chan_config->m2m_hw && (i & 1))\n\t\t\t\tdst_addr += period_len;\n\t\t} else {\n\t\t\tsrc_addr = dma_config->src_addr;\n\t\t\tif (chan_config->m2m_hw && (i & 1))\n\t\t\t\tsrc_addr += period_len;\n\t\t\tdst_addr = buf_addr + i * period_len;\n\t\t}\n\n\t\tstm32_mdma_setup_hwdesc(chan, desc, direction, i, src_addr,\n\t\t\t\t\tdst_addr, period_len, ctcr, ctbr,\n\t\t\t\t\ti == count - 1, i == 0, true);\n\t}\n\n\tdesc->cyclic = true;\n\n\treturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n\nxfer_setup_err:\n\tfor (i = 0; i < desc->count; i++)\n\t\tdma_pool_free(chan->desc_pool, desc->node[i].hwdesc,\n\t\t\t      desc->node[i].hwdesc_phys);\n\tkfree(desc);\n\treturn NULL;\n}\n\nstatic struct dma_async_tx_descriptor *\nstm32_mdma_prep_dma_memcpy(struct dma_chan *c, dma_addr_t dest, dma_addr_t src,\n\t\t\t   size_t len, unsigned long flags)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tenum dma_slave_buswidth max_width;\n\tstruct stm32_mdma_desc *desc;\n\tstruct stm32_mdma_hwdesc *hwdesc;\n\tu32 ccr, ctcr, ctbr, cbndtr, count, max_burst, mdma_burst;\n\tu32 best_burst, tlen;\n\tsize_t xfer_count, offset;\n\tint src_bus_width, dst_bus_width;\n\tint i;\n\n\t \n\tif (chan->desc && chan->desc->cyclic) {\n\t\tdev_err(chan2dev(chan),\n\t\t\t\"Request not allowed when dma in cyclic mode\\n\");\n\t\treturn NULL;\n\t}\n\n\tcount = DIV_ROUND_UP(len, STM32_MDMA_MAX_BLOCK_LEN);\n\tdesc = stm32_mdma_alloc_desc(chan, count);\n\tif (!desc)\n\t\treturn NULL;\n\n\tccr = stm32_mdma_read(dmadev, STM32_MDMA_CCR(chan->id)) & ~STM32_MDMA_CCR_EN;\n\tctcr = stm32_mdma_read(dmadev, STM32_MDMA_CTCR(chan->id));\n\tctbr = stm32_mdma_read(dmadev, STM32_MDMA_CTBR(chan->id));\n\tcbndtr = stm32_mdma_read(dmadev, STM32_MDMA_CBNDTR(chan->id));\n\n\t \n\tccr &= ~(STM32_MDMA_CCR_WEX | STM32_MDMA_CCR_HEX |\n\t\t STM32_MDMA_CCR_BEX | STM32_MDMA_CCR_PL_MASK |\n\t\t STM32_MDMA_CCR_IRQ_MASK);\n\tccr |= STM32_MDMA_CCR_TEIE;\n\n\t \n\tctcr &= ~(STM32_MDMA_CTCR_BWM | STM32_MDMA_CTCR_TRGM_MSK |\n\t\t  STM32_MDMA_CTCR_PAM_MASK | STM32_MDMA_CTCR_PKE |\n\t\t  STM32_MDMA_CTCR_TLEN_MSK | STM32_MDMA_CTCR_DBURST_MASK |\n\t\t  STM32_MDMA_CTCR_SBURST_MASK | STM32_MDMA_CTCR_DINCOS_MASK |\n\t\t  STM32_MDMA_CTCR_SINCOS_MASK | STM32_MDMA_CTCR_DSIZE_MASK |\n\t\t  STM32_MDMA_CTCR_SSIZE_MASK | STM32_MDMA_CTCR_DINC_MASK |\n\t\t  STM32_MDMA_CTCR_SINC_MASK);\n\tctcr |= STM32_MDMA_CTCR_SWRM | STM32_MDMA_CTCR_SINC(STM32_MDMA_INC) |\n\t\tSTM32_MDMA_CTCR_DINC(STM32_MDMA_INC);\n\n\t \n\tctbr &= ~STM32_MDMA_CTBR_TSEL_MASK;\n\n\t \n\tstm32_mdma_set_bus(dmadev, &ctbr, STM32_MDMA_CTBR_SBUS, src);\n\tstm32_mdma_set_bus(dmadev, &ctbr, STM32_MDMA_CTBR_DBUS, dest);\n\n\t \n\tcbndtr &= ~(STM32_MDMA_CBNDTR_BRC_MK | STM32_MDMA_CBNDTR_BRDUM |\n\t\t\tSTM32_MDMA_CBNDTR_BRSUM | STM32_MDMA_CBNDTR_BNDT_MASK);\n\n\tif (len <= STM32_MDMA_MAX_BLOCK_LEN) {\n\t\tcbndtr |= STM32_MDMA_CBNDTR_BNDT(len);\n\t\tif (len <= STM32_MDMA_MAX_BUF_LEN) {\n\t\t\t \n\t\t\tccr |= STM32_MDMA_CCR_TCIE | STM32_MDMA_CCR_CTCIE;\n\t\t\tctcr |= STM32_MDMA_CTCR_TRGM(STM32_MDMA_BUFFER);\n\t\t} else {\n\t\t\t \n\t\t\tccr |= STM32_MDMA_CCR_BTIE | STM32_MDMA_CCR_CTCIE;\n\t\t\tctcr |= STM32_MDMA_CTCR_TRGM(STM32_MDMA_BLOCK);\n\t\t}\n\n\t\ttlen = STM32_MDMA_MAX_BUF_LEN;\n\t\tctcr |= STM32_MDMA_CTCR_TLEN((tlen - 1));\n\n\t\t \n\t\tmax_width = stm32_mdma_get_max_width(src, len, tlen);\n\t\tsrc_bus_width = stm32_mdma_get_width(chan, max_width);\n\n\t\tmax_burst = tlen / max_width;\n\t\tbest_burst = stm32_mdma_get_best_burst(len, tlen, max_burst,\n\t\t\t\t\t\t       max_width);\n\t\tmdma_burst = ilog2(best_burst);\n\n\t\tctcr |= STM32_MDMA_CTCR_SBURST(mdma_burst) |\n\t\t\tSTM32_MDMA_CTCR_SSIZE(src_bus_width) |\n\t\t\tSTM32_MDMA_CTCR_SINCOS(src_bus_width);\n\n\t\t \n\t\tmax_width = stm32_mdma_get_max_width(dest, len, tlen);\n\t\tdst_bus_width = stm32_mdma_get_width(chan, max_width);\n\n\t\tmax_burst = tlen / max_width;\n\t\tbest_burst = stm32_mdma_get_best_burst(len, tlen, max_burst,\n\t\t\t\t\t\t       max_width);\n\t\tmdma_burst = ilog2(best_burst);\n\n\t\tctcr |= STM32_MDMA_CTCR_DBURST(mdma_burst) |\n\t\t\tSTM32_MDMA_CTCR_DSIZE(dst_bus_width) |\n\t\t\tSTM32_MDMA_CTCR_DINCOS(dst_bus_width);\n\n\t\tif (dst_bus_width != src_bus_width)\n\t\t\tctcr |= STM32_MDMA_CTCR_PKE;\n\n\t\t \n\t\thwdesc = desc->node[0].hwdesc;\n\t\thwdesc->ctcr = ctcr;\n\t\thwdesc->cbndtr = cbndtr;\n\t\thwdesc->csar = src;\n\t\thwdesc->cdar = dest;\n\t\thwdesc->cbrur = 0;\n\t\thwdesc->clar = 0;\n\t\thwdesc->ctbr = ctbr;\n\t\thwdesc->cmar = 0;\n\t\thwdesc->cmdr = 0;\n\n\t\tstm32_mdma_dump_hwdesc(chan, &desc->node[0]);\n\t} else {\n\t\t \n\t\tctcr |= STM32_MDMA_CTCR_TRGM(STM32_MDMA_LINKED_LIST) |\n\t\t\tSTM32_MDMA_CTCR_TLEN((STM32_MDMA_MAX_BUF_LEN - 1));\n\t\tccr |= STM32_MDMA_CCR_BTIE | STM32_MDMA_CCR_CTCIE;\n\t\ttlen = STM32_MDMA_MAX_BUF_LEN;\n\n\t\tfor (i = 0, offset = 0; offset < len;\n\t\t     i++, offset += xfer_count) {\n\t\t\txfer_count = min_t(size_t, len - offset,\n\t\t\t\t\t   STM32_MDMA_MAX_BLOCK_LEN);\n\n\t\t\t \n\t\t\tmax_width = stm32_mdma_get_max_width(src, len, tlen);\n\t\t\tsrc_bus_width = stm32_mdma_get_width(chan, max_width);\n\n\t\t\tmax_burst = tlen / max_width;\n\t\t\tbest_burst = stm32_mdma_get_best_burst(len, tlen,\n\t\t\t\t\t\t\t       max_burst,\n\t\t\t\t\t\t\t       max_width);\n\t\t\tmdma_burst = ilog2(best_burst);\n\n\t\t\tctcr |= STM32_MDMA_CTCR_SBURST(mdma_burst) |\n\t\t\t\tSTM32_MDMA_CTCR_SSIZE(src_bus_width) |\n\t\t\t\tSTM32_MDMA_CTCR_SINCOS(src_bus_width);\n\n\t\t\t \n\t\t\tmax_width = stm32_mdma_get_max_width(dest, len, tlen);\n\t\t\tdst_bus_width = stm32_mdma_get_width(chan, max_width);\n\n\t\t\tmax_burst = tlen / max_width;\n\t\t\tbest_burst = stm32_mdma_get_best_burst(len, tlen,\n\t\t\t\t\t\t\t       max_burst,\n\t\t\t\t\t\t\t       max_width);\n\t\t\tmdma_burst = ilog2(best_burst);\n\n\t\t\tctcr |= STM32_MDMA_CTCR_DBURST(mdma_burst) |\n\t\t\t\tSTM32_MDMA_CTCR_DSIZE(dst_bus_width) |\n\t\t\t\tSTM32_MDMA_CTCR_DINCOS(dst_bus_width);\n\n\t\t\tif (dst_bus_width != src_bus_width)\n\t\t\t\tctcr |= STM32_MDMA_CTCR_PKE;\n\n\t\t\t \n\t\t\tstm32_mdma_setup_hwdesc(chan, desc, DMA_MEM_TO_MEM, i,\n\t\t\t\t\t\tsrc + offset, dest + offset,\n\t\t\t\t\t\txfer_count, ctcr, ctbr,\n\t\t\t\t\t\ti == count - 1, i == 0, false);\n\t\t}\n\t}\n\n\tdesc->ccr = ccr;\n\n\tdesc->cyclic = false;\n\n\treturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n}\n\nstatic void stm32_mdma_dump_reg(struct stm32_mdma_chan *chan)\n{\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\n\tdev_dbg(chan2dev(chan), \"CCR:     0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CCR(chan->id)));\n\tdev_dbg(chan2dev(chan), \"CTCR:    0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CTCR(chan->id)));\n\tdev_dbg(chan2dev(chan), \"CBNDTR:  0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CBNDTR(chan->id)));\n\tdev_dbg(chan2dev(chan), \"CSAR:    0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CSAR(chan->id)));\n\tdev_dbg(chan2dev(chan), \"CDAR:    0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CDAR(chan->id)));\n\tdev_dbg(chan2dev(chan), \"CBRUR:   0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CBRUR(chan->id)));\n\tdev_dbg(chan2dev(chan), \"CLAR:    0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CLAR(chan->id)));\n\tdev_dbg(chan2dev(chan), \"CTBR:    0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CTBR(chan->id)));\n\tdev_dbg(chan2dev(chan), \"CMAR:    0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CMAR(chan->id)));\n\tdev_dbg(chan2dev(chan), \"CMDR:    0x%08x\\n\",\n\t\tstm32_mdma_read(dmadev, STM32_MDMA_CMDR(chan->id)));\n}\n\nstatic void stm32_mdma_start_transfer(struct stm32_mdma_chan *chan)\n{\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tstruct virt_dma_desc *vdesc;\n\tstruct stm32_mdma_hwdesc *hwdesc;\n\tu32 id = chan->id;\n\tu32 status, reg;\n\n\tvdesc = vchan_next_desc(&chan->vchan);\n\tif (!vdesc) {\n\t\tchan->desc = NULL;\n\t\treturn;\n\t}\n\n\tlist_del(&vdesc->node);\n\n\tchan->desc = to_stm32_mdma_desc(vdesc);\n\thwdesc = chan->desc->node[0].hwdesc;\n\tchan->curr_hwdesc = 0;\n\n\tstm32_mdma_write(dmadev, STM32_MDMA_CCR(id), chan->desc->ccr);\n\tstm32_mdma_write(dmadev, STM32_MDMA_CTCR(id), hwdesc->ctcr);\n\tstm32_mdma_write(dmadev, STM32_MDMA_CBNDTR(id), hwdesc->cbndtr);\n\tstm32_mdma_write(dmadev, STM32_MDMA_CSAR(id), hwdesc->csar);\n\tstm32_mdma_write(dmadev, STM32_MDMA_CDAR(id), hwdesc->cdar);\n\tstm32_mdma_write(dmadev, STM32_MDMA_CBRUR(id), hwdesc->cbrur);\n\tstm32_mdma_write(dmadev, STM32_MDMA_CLAR(id), hwdesc->clar);\n\tstm32_mdma_write(dmadev, STM32_MDMA_CTBR(id), hwdesc->ctbr);\n\tstm32_mdma_write(dmadev, STM32_MDMA_CMAR(id), hwdesc->cmar);\n\tstm32_mdma_write(dmadev, STM32_MDMA_CMDR(id), hwdesc->cmdr);\n\n\t \n\tstatus = stm32_mdma_read(dmadev, STM32_MDMA_CISR(id));\n\tif (status)\n\t\tstm32_mdma_set_bits(dmadev, STM32_MDMA_CIFCR(id), status);\n\n\tstm32_mdma_dump_reg(chan);\n\n\t \n\tstm32_mdma_set_bits(dmadev, STM32_MDMA_CCR(id), STM32_MDMA_CCR_EN);\n\n\t \n\tif (hwdesc->ctcr & STM32_MDMA_CTCR_SWRM) {\n\t\treg = STM32_MDMA_CCR(id);\n\t\tstm32_mdma_set_bits(dmadev, reg, STM32_MDMA_CCR_SWRQ);\n\t}\n\n\tchan->busy = true;\n\n\tdev_dbg(chan2dev(chan), \"vchan %pK: started\\n\", &chan->vchan);\n}\n\nstatic void stm32_mdma_issue_pending(struct dma_chan *c)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\n\tif (!vchan_issue_pending(&chan->vchan))\n\t\tgoto end;\n\n\tdev_dbg(chan2dev(chan), \"vchan %pK: issued\\n\", &chan->vchan);\n\n\tif (!chan->desc && !chan->busy)\n\t\tstm32_mdma_start_transfer(chan);\n\nend:\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n}\n\nstatic int stm32_mdma_pause(struct dma_chan *c)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tunsigned long flags;\n\tint ret;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\tret = stm32_mdma_disable_chan(chan);\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\n\tif (!ret)\n\t\tdev_dbg(chan2dev(chan), \"vchan %pK: pause\\n\", &chan->vchan);\n\n\treturn ret;\n}\n\nstatic int stm32_mdma_resume(struct dma_chan *c)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tstruct stm32_mdma_hwdesc *hwdesc;\n\tunsigned long flags;\n\tu32 status, reg;\n\n\t \n\tif (!chan->desc || (stm32_mdma_read(dmadev, STM32_MDMA_CCR(chan->id)) & STM32_MDMA_CCR_EN))\n\t\treturn -EPERM;\n\n\thwdesc = chan->desc->node[chan->curr_hwdesc].hwdesc;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\n\t \n\tstm32_mdma_write(dmadev, STM32_MDMA_CCR(chan->id), chan->desc->ccr);\n\n\t \n\tstatus = stm32_mdma_read(dmadev, STM32_MDMA_CISR(chan->id));\n\tif (status)\n\t\tstm32_mdma_set_bits(dmadev, STM32_MDMA_CIFCR(chan->id), status);\n\n\tstm32_mdma_dump_reg(chan);\n\n\t \n\treg = STM32_MDMA_CCR(chan->id);\n\tstm32_mdma_set_bits(dmadev, reg, STM32_MDMA_CCR_EN);\n\n\t \n\tif (hwdesc->ctcr & STM32_MDMA_CTCR_SWRM)\n\t\tstm32_mdma_set_bits(dmadev, reg, STM32_MDMA_CCR_SWRQ);\n\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\n\tdev_dbg(chan2dev(chan), \"vchan %pK: resume\\n\", &chan->vchan);\n\n\treturn 0;\n}\n\nstatic int stm32_mdma_terminate_all(struct dma_chan *c)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\tif (chan->desc) {\n\t\tvchan_terminate_vdesc(&chan->desc->vdesc);\n\t\tif (chan->busy)\n\t\t\tstm32_mdma_stop(chan);\n\t\tchan->desc = NULL;\n\t}\n\tvchan_get_all_descriptors(&chan->vchan, &head);\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\n\tvchan_dma_desc_free_list(&chan->vchan, &head);\n\n\treturn 0;\n}\n\nstatic void stm32_mdma_synchronize(struct dma_chan *c)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\n\tvchan_synchronize(&chan->vchan);\n}\n\nstatic int stm32_mdma_slave_config(struct dma_chan *c,\n\t\t\t\t   struct dma_slave_config *config)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\n\tmemcpy(&chan->dma_config, config, sizeof(*config));\n\n\t \n\tif (config->peripheral_size) {\n\t\tstruct stm32_mdma_dma_config *mdma_config;\n\n\t\tmdma_config = (struct stm32_mdma_dma_config *)chan->dma_config.peripheral_config;\n\t\tchan->chan_config.request = mdma_config->request;\n\t\tchan->chan_config.mask_addr = mdma_config->cmar;\n\t\tchan->chan_config.mask_data = mdma_config->cmdr;\n\t\tchan->chan_config.m2m_hw = true;\n\t}\n\n\treturn 0;\n}\n\nstatic size_t stm32_mdma_desc_residue(struct stm32_mdma_chan *chan,\n\t\t\t\t      struct stm32_mdma_desc *desc,\n\t\t\t\t      u32 curr_hwdesc,\n\t\t\t\t      struct dma_tx_state *state)\n{\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tstruct stm32_mdma_hwdesc *hwdesc;\n\tu32 cisr, clar, cbndtr, residue, modulo, burst_size;\n\tint i;\n\n\tcisr = stm32_mdma_read(dmadev, STM32_MDMA_CISR(chan->id));\n\n\tresidue = 0;\n\t \n\tclar = stm32_mdma_read(dmadev, STM32_MDMA_CLAR(chan->id));\n\tfor (i = desc->count - 1; i >= 0; i--) {\n\t\thwdesc = desc->node[i].hwdesc;\n\n\t\tif (hwdesc->clar == clar)\n\t\t\tbreak; \n\n\t\t \n\t\tresidue += STM32_MDMA_CBNDTR_BNDT(hwdesc->cbndtr);\n\t}\n\tcbndtr = stm32_mdma_read(dmadev, STM32_MDMA_CBNDTR(chan->id));\n\tresidue += cbndtr & STM32_MDMA_CBNDTR_BNDT_MASK;\n\n\tstate->in_flight_bytes = 0;\n\tif (chan->chan_config.m2m_hw && (cisr & STM32_MDMA_CISR_CRQA))\n\t\tstate->in_flight_bytes = cbndtr & STM32_MDMA_CBNDTR_BNDT_MASK;\n\n\tif (!chan->mem_burst)\n\t\treturn residue;\n\n\tburst_size = chan->mem_burst * chan->mem_width;\n\tmodulo = residue % burst_size;\n\tif (modulo)\n\t\tresidue = residue - modulo + burst_size;\n\n\treturn residue;\n}\n\nstatic enum dma_status stm32_mdma_tx_status(struct dma_chan *c,\n\t\t\t\t\t    dma_cookie_t cookie,\n\t\t\t\t\t    struct dma_tx_state *state)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tstruct virt_dma_desc *vdesc;\n\tenum dma_status status;\n\tunsigned long flags;\n\tu32 residue = 0;\n\n\tstatus = dma_cookie_status(c, cookie, state);\n\tif ((status == DMA_COMPLETE) || (!state))\n\t\treturn status;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\n\tvdesc = vchan_find_desc(&chan->vchan, cookie);\n\tif (chan->desc && cookie == chan->desc->vdesc.tx.cookie)\n\t\tresidue = stm32_mdma_desc_residue(chan, chan->desc, chan->curr_hwdesc, state);\n\telse if (vdesc)\n\t\tresidue = stm32_mdma_desc_residue(chan, to_stm32_mdma_desc(vdesc), 0, state);\n\n\tdma_set_residue(state, residue);\n\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\n\treturn status;\n}\n\nstatic void stm32_mdma_xfer_end(struct stm32_mdma_chan *chan)\n{\n\tvchan_cookie_complete(&chan->desc->vdesc);\n\tchan->desc = NULL;\n\tchan->busy = false;\n\n\t \n\tstm32_mdma_start_transfer(chan);\n}\n\nstatic irqreturn_t stm32_mdma_irq_handler(int irq, void *devid)\n{\n\tstruct stm32_mdma_device *dmadev = devid;\n\tstruct stm32_mdma_chan *chan;\n\tu32 reg, id, ccr, ien, status;\n\n\t \n\tstatus = readl_relaxed(dmadev->base + STM32_MDMA_GISR0);\n\tif (!status) {\n\t\tdev_dbg(mdma2dev(dmadev), \"spurious it\\n\");\n\t\treturn IRQ_NONE;\n\t}\n\tid = __ffs(status);\n\tchan = &dmadev->chan[id];\n\n\t \n\tspin_lock(&chan->vchan.lock);\n\tstatus = stm32_mdma_read(dmadev, STM32_MDMA_CISR(id));\n\t \n\tstatus &= ~STM32_MDMA_CISR_CRQA;\n\tccr = stm32_mdma_read(dmadev, STM32_MDMA_CCR(id));\n\tien = (ccr & STM32_MDMA_CCR_IRQ_MASK) >> 1;\n\n\tif (!(status & ien)) {\n\t\tspin_unlock(&chan->vchan.lock);\n\t\tif (chan->busy)\n\t\t\tdev_warn(chan2dev(chan),\n\t\t\t\t \"spurious it (status=0x%04x, ien=0x%04x)\\n\", status, ien);\n\t\telse\n\t\t\tdev_dbg(chan2dev(chan),\n\t\t\t\t\"spurious it (status=0x%04x, ien=0x%04x)\\n\", status, ien);\n\t\treturn IRQ_NONE;\n\t}\n\n\treg = STM32_MDMA_CIFCR(id);\n\n\tif (status & STM32_MDMA_CISR_TEIF) {\n\t\tdev_err(chan2dev(chan), \"Transfer Err: stat=0x%08x\\n\",\n\t\t\treadl_relaxed(dmadev->base + STM32_MDMA_CESR(id)));\n\t\tstm32_mdma_set_bits(dmadev, reg, STM32_MDMA_CIFCR_CTEIF);\n\t\tstatus &= ~STM32_MDMA_CISR_TEIF;\n\t}\n\n\tif (status & STM32_MDMA_CISR_CTCIF) {\n\t\tstm32_mdma_set_bits(dmadev, reg, STM32_MDMA_CIFCR_CCTCIF);\n\t\tstatus &= ~STM32_MDMA_CISR_CTCIF;\n\t\tstm32_mdma_xfer_end(chan);\n\t}\n\n\tif (status & STM32_MDMA_CISR_BRTIF) {\n\t\tstm32_mdma_set_bits(dmadev, reg, STM32_MDMA_CIFCR_CBRTIF);\n\t\tstatus &= ~STM32_MDMA_CISR_BRTIF;\n\t}\n\n\tif (status & STM32_MDMA_CISR_BTIF) {\n\t\tstm32_mdma_set_bits(dmadev, reg, STM32_MDMA_CIFCR_CBTIF);\n\t\tstatus &= ~STM32_MDMA_CISR_BTIF;\n\t\tchan->curr_hwdesc++;\n\t\tif (chan->desc && chan->desc->cyclic) {\n\t\t\tif (chan->curr_hwdesc == chan->desc->count)\n\t\t\t\tchan->curr_hwdesc = 0;\n\t\t\tvchan_cyclic_callback(&chan->desc->vdesc);\n\t\t}\n\t}\n\n\tif (status & STM32_MDMA_CISR_TCIF) {\n\t\tstm32_mdma_set_bits(dmadev, reg, STM32_MDMA_CIFCR_CLTCIF);\n\t\tstatus &= ~STM32_MDMA_CISR_TCIF;\n\t}\n\n\tif (status) {\n\t\tstm32_mdma_set_bits(dmadev, reg, status);\n\t\tdev_err(chan2dev(chan), \"DMA error: status=0x%08x\\n\", status);\n\t\tif (!(ccr & STM32_MDMA_CCR_EN))\n\t\t\tdev_err(chan2dev(chan), \"chan disabled by HW\\n\");\n\t}\n\n\tspin_unlock(&chan->vchan.lock);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int stm32_mdma_alloc_chan_resources(struct dma_chan *c)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tint ret;\n\n\tchan->desc_pool = dmam_pool_create(dev_name(&c->dev->device),\n\t\t\t\t\t   c->device->dev,\n\t\t\t\t\t   sizeof(struct stm32_mdma_hwdesc),\n\t\t\t\t\t  __alignof__(struct stm32_mdma_hwdesc),\n\t\t\t\t\t   0);\n\tif (!chan->desc_pool) {\n\t\tdev_err(chan2dev(chan), \"failed to allocate descriptor pool\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tret = pm_runtime_resume_and_get(dmadev->ddev.dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = stm32_mdma_disable_chan(chan);\n\tif (ret < 0)\n\t\tpm_runtime_put(dmadev->ddev.dev);\n\n\treturn ret;\n}\n\nstatic void stm32_mdma_free_chan_resources(struct dma_chan *c)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\tunsigned long flags;\n\n\tdev_dbg(chan2dev(chan), \"Freeing channel %d\\n\", chan->id);\n\n\tif (chan->busy) {\n\t\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\t\tstm32_mdma_stop(chan);\n\t\tchan->desc = NULL;\n\t\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\t}\n\n\tpm_runtime_put(dmadev->ddev.dev);\n\tvchan_free_chan_resources(to_virt_chan(c));\n\tdmam_pool_destroy(chan->desc_pool);\n\tchan->desc_pool = NULL;\n}\n\nstatic bool stm32_mdma_filter_fn(struct dma_chan *c, void *fn_param)\n{\n\tstruct stm32_mdma_chan *chan = to_stm32_mdma_chan(c);\n\tstruct stm32_mdma_device *dmadev = stm32_mdma_get_dev(chan);\n\n\t \n\tif (dmadev->chan_reserved & BIT(chan->id))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic struct dma_chan *stm32_mdma_of_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t\t    struct of_dma *ofdma)\n{\n\tstruct stm32_mdma_device *dmadev = ofdma->of_dma_data;\n\tdma_cap_mask_t mask = dmadev->ddev.cap_mask;\n\tstruct stm32_mdma_chan *chan;\n\tstruct dma_chan *c;\n\tstruct stm32_mdma_chan_config config;\n\n\tif (dma_spec->args_count < 5) {\n\t\tdev_err(mdma2dev(dmadev), \"Bad number of args\\n\");\n\t\treturn NULL;\n\t}\n\n\tmemset(&config, 0, sizeof(config));\n\tconfig.request = dma_spec->args[0];\n\tconfig.priority_level = dma_spec->args[1];\n\tconfig.transfer_config = dma_spec->args[2];\n\tconfig.mask_addr = dma_spec->args[3];\n\tconfig.mask_data = dma_spec->args[4];\n\n\tif (config.request >= dmadev->nr_requests) {\n\t\tdev_err(mdma2dev(dmadev), \"Bad request line\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (config.priority_level > STM32_MDMA_VERY_HIGH_PRIORITY) {\n\t\tdev_err(mdma2dev(dmadev), \"Priority level not supported\\n\");\n\t\treturn NULL;\n\t}\n\n\tc = __dma_request_channel(&mask, stm32_mdma_filter_fn, &config, ofdma->of_node);\n\tif (!c) {\n\t\tdev_err(mdma2dev(dmadev), \"No more channels available\\n\");\n\t\treturn NULL;\n\t}\n\n\tchan = to_stm32_mdma_chan(c);\n\tchan->chan_config = config;\n\n\treturn c;\n}\n\nstatic const struct of_device_id stm32_mdma_of_match[] = {\n\t{ .compatible = \"st,stm32h7-mdma\", },\n\t{   },\n};\nMODULE_DEVICE_TABLE(of, stm32_mdma_of_match);\n\nstatic int stm32_mdma_probe(struct platform_device *pdev)\n{\n\tstruct stm32_mdma_chan *chan;\n\tstruct stm32_mdma_device *dmadev;\n\tstruct dma_device *dd;\n\tstruct device_node *of_node;\n\tstruct reset_control *rst;\n\tu32 nr_channels, nr_requests;\n\tint i, count, ret;\n\n\tof_node = pdev->dev.of_node;\n\tif (!of_node)\n\t\treturn -ENODEV;\n\n\tret = device_property_read_u32(&pdev->dev, \"dma-channels\",\n\t\t\t\t       &nr_channels);\n\tif (ret) {\n\t\tnr_channels = STM32_MDMA_MAX_CHANNELS;\n\t\tdev_warn(&pdev->dev, \"MDMA defaulting on %i channels\\n\",\n\t\t\t nr_channels);\n\t}\n\n\tret = device_property_read_u32(&pdev->dev, \"dma-requests\",\n\t\t\t\t       &nr_requests);\n\tif (ret) {\n\t\tnr_requests = STM32_MDMA_MAX_REQUESTS;\n\t\tdev_warn(&pdev->dev, \"MDMA defaulting on %i request lines\\n\",\n\t\t\t nr_requests);\n\t}\n\n\tcount = device_property_count_u32(&pdev->dev, \"st,ahb-addr-masks\");\n\tif (count < 0)\n\t\tcount = 0;\n\n\tdmadev = devm_kzalloc(&pdev->dev,\n\t\t\t      struct_size(dmadev, ahb_addr_masks, count),\n\t\t\t      GFP_KERNEL);\n\tif (!dmadev)\n\t\treturn -ENOMEM;\n\n\tdmadev->nr_channels = nr_channels;\n\tdmadev->nr_requests = nr_requests;\n\tdevice_property_read_u32_array(&pdev->dev, \"st,ahb-addr-masks\",\n\t\t\t\t       dmadev->ahb_addr_masks,\n\t\t\t\t       count);\n\tdmadev->nr_ahb_addr_masks = count;\n\n\tdmadev->base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(dmadev->base))\n\t\treturn PTR_ERR(dmadev->base);\n\n\tdmadev->clk = devm_clk_get(&pdev->dev, NULL);\n\tif (IS_ERR(dmadev->clk))\n\t\treturn dev_err_probe(&pdev->dev, PTR_ERR(dmadev->clk),\n\t\t\t\t     \"Missing clock controller\\n\");\n\n\tret = clk_prepare_enable(dmadev->clk);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"clk_prep_enable error: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\trst = devm_reset_control_get(&pdev->dev, NULL);\n\tif (IS_ERR(rst)) {\n\t\tret = PTR_ERR(rst);\n\t\tif (ret == -EPROBE_DEFER)\n\t\t\tgoto err_clk;\n\t} else {\n\t\treset_control_assert(rst);\n\t\tudelay(2);\n\t\treset_control_deassert(rst);\n\t}\n\n\tdd = &dmadev->ddev;\n\tdma_cap_set(DMA_SLAVE, dd->cap_mask);\n\tdma_cap_set(DMA_PRIVATE, dd->cap_mask);\n\tdma_cap_set(DMA_CYCLIC, dd->cap_mask);\n\tdma_cap_set(DMA_MEMCPY, dd->cap_mask);\n\tdd->device_alloc_chan_resources = stm32_mdma_alloc_chan_resources;\n\tdd->device_free_chan_resources = stm32_mdma_free_chan_resources;\n\tdd->device_tx_status = stm32_mdma_tx_status;\n\tdd->device_issue_pending = stm32_mdma_issue_pending;\n\tdd->device_prep_slave_sg = stm32_mdma_prep_slave_sg;\n\tdd->device_prep_dma_cyclic = stm32_mdma_prep_dma_cyclic;\n\tdd->device_prep_dma_memcpy = stm32_mdma_prep_dma_memcpy;\n\tdd->device_config = stm32_mdma_slave_config;\n\tdd->device_pause = stm32_mdma_pause;\n\tdd->device_resume = stm32_mdma_resume;\n\tdd->device_terminate_all = stm32_mdma_terminate_all;\n\tdd->device_synchronize = stm32_mdma_synchronize;\n\tdd->descriptor_reuse = true;\n\n\tdd->src_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_8_BYTES);\n\tdd->dst_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_8_BYTES);\n\tdd->directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV) |\n\t\tBIT(DMA_MEM_TO_MEM);\n\tdd->residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\tdd->max_burst = STM32_MDMA_MAX_BURST;\n\tdd->dev = &pdev->dev;\n\tINIT_LIST_HEAD(&dd->channels);\n\n\tfor (i = 0; i < dmadev->nr_channels; i++) {\n\t\tchan = &dmadev->chan[i];\n\t\tchan->id = i;\n\n\t\tif (stm32_mdma_read(dmadev, STM32_MDMA_CCR(i)) & STM32_MDMA_CCR_SM)\n\t\t\tdmadev->chan_reserved |= BIT(i);\n\n\t\tchan->vchan.desc_free = stm32_mdma_desc_free;\n\t\tvchan_init(&chan->vchan, dd);\n\t}\n\n\tdmadev->irq = platform_get_irq(pdev, 0);\n\tif (dmadev->irq < 0) {\n\t\tret = dmadev->irq;\n\t\tgoto err_clk;\n\t}\n\n\tret = devm_request_irq(&pdev->dev, dmadev->irq, stm32_mdma_irq_handler,\n\t\t\t       0, dev_name(&pdev->dev), dmadev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed to request IRQ\\n\");\n\t\tgoto err_clk;\n\t}\n\n\tret = dmaenginem_async_device_register(dd);\n\tif (ret)\n\t\tgoto err_clk;\n\n\tret = of_dma_controller_register(of_node, stm32_mdma_of_xlate, dmadev);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"STM32 MDMA DMA OF registration failed %d\\n\", ret);\n\t\tgoto err_clk;\n\t}\n\n\tplatform_set_drvdata(pdev, dmadev);\n\tpm_runtime_set_active(&pdev->dev);\n\tpm_runtime_enable(&pdev->dev);\n\tpm_runtime_get_noresume(&pdev->dev);\n\tpm_runtime_put(&pdev->dev);\n\n\tdev_info(&pdev->dev, \"STM32 MDMA driver registered\\n\");\n\n\treturn 0;\n\nerr_clk:\n\tclk_disable_unprepare(dmadev->clk);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_PM\nstatic int stm32_mdma_runtime_suspend(struct device *dev)\n{\n\tstruct stm32_mdma_device *dmadev = dev_get_drvdata(dev);\n\n\tclk_disable_unprepare(dmadev->clk);\n\n\treturn 0;\n}\n\nstatic int stm32_mdma_runtime_resume(struct device *dev)\n{\n\tstruct stm32_mdma_device *dmadev = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = clk_prepare_enable(dmadev->clk);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to prepare_enable clock\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n#endif\n\n#ifdef CONFIG_PM_SLEEP\nstatic int stm32_mdma_pm_suspend(struct device *dev)\n{\n\tstruct stm32_mdma_device *dmadev = dev_get_drvdata(dev);\n\tu32 ccr, id;\n\tint ret;\n\n\tret = pm_runtime_resume_and_get(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tfor (id = 0; id < dmadev->nr_channels; id++) {\n\t\tccr = stm32_mdma_read(dmadev, STM32_MDMA_CCR(id));\n\t\tif (ccr & STM32_MDMA_CCR_EN) {\n\t\t\tdev_warn(dev, \"Suspend is prevented by Chan %i\\n\", id);\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\tpm_runtime_put_sync(dev);\n\n\tpm_runtime_force_suspend(dev);\n\n\treturn 0;\n}\n\nstatic int stm32_mdma_pm_resume(struct device *dev)\n{\n\treturn pm_runtime_force_resume(dev);\n}\n#endif\n\nstatic const struct dev_pm_ops stm32_mdma_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(stm32_mdma_pm_suspend, stm32_mdma_pm_resume)\n\tSET_RUNTIME_PM_OPS(stm32_mdma_runtime_suspend,\n\t\t\t   stm32_mdma_runtime_resume, NULL)\n};\n\nstatic struct platform_driver stm32_mdma_driver = {\n\t.probe = stm32_mdma_probe,\n\t.driver = {\n\t\t.name = \"stm32-mdma\",\n\t\t.of_match_table = stm32_mdma_of_match,\n\t\t.pm = &stm32_mdma_pm_ops,\n\t},\n};\n\nstatic int __init stm32_mdma_init(void)\n{\n\treturn platform_driver_register(&stm32_mdma_driver);\n}\n\nsubsys_initcall(stm32_mdma_init);\n\nMODULE_DESCRIPTION(\"Driver for STM32 MDMA controller\");\nMODULE_AUTHOR(\"M'boumba Cedric Madianga <cedric.madianga@gmail.com>\");\nMODULE_AUTHOR(\"Pierre-Yves Mordret <pierre-yves.mordret@st.com>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}