{
  "module_name": "sa11x0-dma.c",
  "hash_id": "3be633804b452508e69dd68ac7b9ef6240c5dd7400dfe31b59872de3d8088316",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/sa11x0-dma.c",
  "human_readable_source": "\n \n#include <linux/sched.h>\n#include <linux/device.h>\n#include <linux/dmaengine.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n\n#include \"virt-dma.h\"\n\n#define NR_PHY_CHAN\t6\n#define DMA_ALIGN\t3\n#define DMA_MAX_SIZE\t0x1fff\n#define DMA_CHUNK_SIZE\t0x1000\n\n#define DMA_DDAR\t0x00\n#define DMA_DCSR_S\t0x04\n#define DMA_DCSR_C\t0x08\n#define DMA_DCSR_R\t0x0c\n#define DMA_DBSA\t0x10\n#define DMA_DBTA\t0x14\n#define DMA_DBSB\t0x18\n#define DMA_DBTB\t0x1c\n#define DMA_SIZE\t0x20\n\n#define DCSR_RUN\t(1 << 0)\n#define DCSR_IE\t\t(1 << 1)\n#define DCSR_ERROR\t(1 << 2)\n#define DCSR_DONEA\t(1 << 3)\n#define DCSR_STRTA\t(1 << 4)\n#define DCSR_DONEB\t(1 << 5)\n#define DCSR_STRTB\t(1 << 6)\n#define DCSR_BIU\t(1 << 7)\n\n#define DDAR_RW\t\t(1 << 0)\t \n#define DDAR_E\t\t(1 << 1)\t \n#define DDAR_BS\t\t(1 << 2)\t \n#define DDAR_DW\t\t(1 << 3)\t \n#define DDAR_Ser0UDCTr\t(0x0 << 4)\n#define DDAR_Ser0UDCRc\t(0x1 << 4)\n#define DDAR_Ser1SDLCTr\t(0x2 << 4)\n#define DDAR_Ser1SDLCRc\t(0x3 << 4)\n#define DDAR_Ser1UARTTr\t(0x4 << 4)\n#define DDAR_Ser1UARTRc\t(0x5 << 4)\n#define DDAR_Ser2ICPTr\t(0x6 << 4)\n#define DDAR_Ser2ICPRc\t(0x7 << 4)\n#define DDAR_Ser3UARTTr\t(0x8 << 4)\n#define DDAR_Ser3UARTRc\t(0x9 << 4)\n#define DDAR_Ser4MCP0Tr\t(0xa << 4)\n#define DDAR_Ser4MCP0Rc\t(0xb << 4)\n#define DDAR_Ser4MCP1Tr\t(0xc << 4)\n#define DDAR_Ser4MCP1Rc\t(0xd << 4)\n#define DDAR_Ser4SSPTr\t(0xe << 4)\n#define DDAR_Ser4SSPRc\t(0xf << 4)\n\nstruct sa11x0_dma_sg {\n\tu32\t\t\taddr;\n\tu32\t\t\tlen;\n};\n\nstruct sa11x0_dma_desc {\n\tstruct virt_dma_desc\tvd;\n\n\tu32\t\t\tddar;\n\tsize_t\t\t\tsize;\n\tunsigned\t\tperiod;\n\tbool\t\t\tcyclic;\n\n\tunsigned\t\tsglen;\n\tstruct sa11x0_dma_sg\tsg[];\n};\n\nstruct sa11x0_dma_phy;\n\nstruct sa11x0_dma_chan {\n\tstruct virt_dma_chan\tvc;\n\n\t \n\tstruct sa11x0_dma_phy\t*phy;\n\tenum dma_status\t\tstatus;\n\n\t \n\tstruct list_head\tnode;\n\n\tu32\t\t\tddar;\n\tconst char\t\t*name;\n};\n\nstruct sa11x0_dma_phy {\n\tvoid __iomem\t\t*base;\n\tstruct sa11x0_dma_dev\t*dev;\n\tunsigned\t\tnum;\n\n\tstruct sa11x0_dma_chan\t*vchan;\n\n\t \n\tunsigned\t\tsg_load;\n\tstruct sa11x0_dma_desc\t*txd_load;\n\tunsigned\t\tsg_done;\n\tstruct sa11x0_dma_desc\t*txd_done;\n\tu32\t\t\tdbs[2];\n\tu32\t\t\tdbt[2];\n\tu32\t\t\tdcsr;\n};\n\nstruct sa11x0_dma_dev {\n\tstruct dma_device\tslave;\n\tvoid __iomem\t\t*base;\n\tspinlock_t\t\tlock;\n\tstruct tasklet_struct\ttask;\n\tstruct list_head\tchan_pending;\n\tstruct sa11x0_dma_phy\tphy[NR_PHY_CHAN];\n};\n\nstatic struct sa11x0_dma_chan *to_sa11x0_dma_chan(struct dma_chan *chan)\n{\n\treturn container_of(chan, struct sa11x0_dma_chan, vc.chan);\n}\n\nstatic struct sa11x0_dma_dev *to_sa11x0_dma(struct dma_device *dmadev)\n{\n\treturn container_of(dmadev, struct sa11x0_dma_dev, slave);\n}\n\nstatic struct sa11x0_dma_desc *sa11x0_dma_next_desc(struct sa11x0_dma_chan *c)\n{\n\tstruct virt_dma_desc *vd = vchan_next_desc(&c->vc);\n\n\treturn vd ? container_of(vd, struct sa11x0_dma_desc, vd) : NULL;\n}\n\nstatic void sa11x0_dma_free_desc(struct virt_dma_desc *vd)\n{\n\tkfree(container_of(vd, struct sa11x0_dma_desc, vd));\n}\n\nstatic void sa11x0_dma_start_desc(struct sa11x0_dma_phy *p, struct sa11x0_dma_desc *txd)\n{\n\tlist_del(&txd->vd.node);\n\tp->txd_load = txd;\n\tp->sg_load = 0;\n\n\tdev_vdbg(p->dev->slave.dev, \"pchan %u: txd %p[%x]: starting: DDAR:%x\\n\",\n\t\tp->num, &txd->vd, txd->vd.tx.cookie, txd->ddar);\n}\n\nstatic void noinline sa11x0_dma_start_sg(struct sa11x0_dma_phy *p,\n\tstruct sa11x0_dma_chan *c)\n{\n\tstruct sa11x0_dma_desc *txd = p->txd_load;\n\tstruct sa11x0_dma_sg *sg;\n\tvoid __iomem *base = p->base;\n\tunsigned dbsx, dbtx;\n\tu32 dcsr;\n\n\tif (!txd)\n\t\treturn;\n\n\tdcsr = readl_relaxed(base + DMA_DCSR_R);\n\n\t \n\tif ((dcsr & (DCSR_STRTA | DCSR_STRTB)) == (DCSR_STRTA | DCSR_STRTB))\n\t\treturn;\n\n\tif (p->sg_load == txd->sglen) {\n\t\tif (!txd->cyclic) {\n\t\t\tstruct sa11x0_dma_desc *txn = sa11x0_dma_next_desc(c);\n\n\t\t\t \n\t\t\tif (txn && txn->ddar == txd->ddar) {\n\t\t\t\ttxd = txn;\n\t\t\t\tsa11x0_dma_start_desc(p, txn);\n\t\t\t} else {\n\t\t\t\tp->txd_load = NULL;\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tp->sg_load = 0;\n\t\t}\n\t}\n\n\tsg = &txd->sg[p->sg_load++];\n\n\t \n\tif (((dcsr & (DCSR_BIU | DCSR_STRTB)) == (DCSR_BIU | DCSR_STRTB)) ||\n\t    ((dcsr & (DCSR_BIU | DCSR_STRTA)) == 0)) {\n\t\tdbsx = DMA_DBSA;\n\t\tdbtx = DMA_DBTA;\n\t\tdcsr = DCSR_STRTA | DCSR_IE | DCSR_RUN;\n\t} else {\n\t\tdbsx = DMA_DBSB;\n\t\tdbtx = DMA_DBTB;\n\t\tdcsr = DCSR_STRTB | DCSR_IE | DCSR_RUN;\n\t}\n\n\twritel_relaxed(sg->addr, base + dbsx);\n\twritel_relaxed(sg->len, base + dbtx);\n\twritel(dcsr, base + DMA_DCSR_S);\n\n\tdev_dbg(p->dev->slave.dev, \"pchan %u: load: DCSR:%02x DBS%c:%08x DBT%c:%08x\\n\",\n\t\tp->num, dcsr,\n\t\t'A' + (dbsx == DMA_DBSB), sg->addr,\n\t\t'A' + (dbtx == DMA_DBTB), sg->len);\n}\n\nstatic void noinline sa11x0_dma_complete(struct sa11x0_dma_phy *p,\n\tstruct sa11x0_dma_chan *c)\n{\n\tstruct sa11x0_dma_desc *txd = p->txd_done;\n\n\tif (++p->sg_done == txd->sglen) {\n\t\tif (!txd->cyclic) {\n\t\t\tvchan_cookie_complete(&txd->vd);\n\n\t\t\tp->sg_done = 0;\n\t\t\tp->txd_done = p->txd_load;\n\n\t\t\tif (!p->txd_done)\n\t\t\t\ttasklet_schedule(&p->dev->task);\n\t\t} else {\n\t\t\tif ((p->sg_done % txd->period) == 0)\n\t\t\t\tvchan_cyclic_callback(&txd->vd);\n\n\t\t\t \n\t\t\tp->sg_done = 0;\n\t\t}\n\t}\n\n\tsa11x0_dma_start_sg(p, c);\n}\n\nstatic irqreturn_t sa11x0_dma_irq(int irq, void *dev_id)\n{\n\tstruct sa11x0_dma_phy *p = dev_id;\n\tstruct sa11x0_dma_dev *d = p->dev;\n\tstruct sa11x0_dma_chan *c;\n\tu32 dcsr;\n\n\tdcsr = readl_relaxed(p->base + DMA_DCSR_R);\n\tif (!(dcsr & (DCSR_ERROR | DCSR_DONEA | DCSR_DONEB)))\n\t\treturn IRQ_NONE;\n\n\t \n\twritel_relaxed(dcsr & (DCSR_ERROR | DCSR_DONEA | DCSR_DONEB),\n\t\tp->base + DMA_DCSR_C);\n\n\tdev_dbg(d->slave.dev, \"pchan %u: irq: DCSR:%02x\\n\", p->num, dcsr);\n\n\tif (dcsr & DCSR_ERROR) {\n\t\tdev_err(d->slave.dev, \"pchan %u: error. DCSR:%02x DDAR:%08x DBSA:%08x DBTA:%08x DBSB:%08x DBTB:%08x\\n\",\n\t\t\tp->num, dcsr,\n\t\t\treadl_relaxed(p->base + DMA_DDAR),\n\t\t\treadl_relaxed(p->base + DMA_DBSA),\n\t\t\treadl_relaxed(p->base + DMA_DBTA),\n\t\t\treadl_relaxed(p->base + DMA_DBSB),\n\t\t\treadl_relaxed(p->base + DMA_DBTB));\n\t}\n\n\tc = p->vchan;\n\tif (c) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&c->vc.lock, flags);\n\t\t \n\t\tif (c->phy == p) {\n\t\t\tif (dcsr & DCSR_DONEA)\n\t\t\t\tsa11x0_dma_complete(p, c);\n\t\t\tif (dcsr & DCSR_DONEB)\n\t\t\t\tsa11x0_dma_complete(p, c);\n\t\t}\n\t\tspin_unlock_irqrestore(&c->vc.lock, flags);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void sa11x0_dma_start_txd(struct sa11x0_dma_chan *c)\n{\n\tstruct sa11x0_dma_desc *txd = sa11x0_dma_next_desc(c);\n\n\t \n\tif (txd) {\n\t\tstruct sa11x0_dma_phy *p = c->phy;\n\n\t\tsa11x0_dma_start_desc(p, txd);\n\t\tp->txd_done = txd;\n\t\tp->sg_done = 0;\n\n\t\t \n\t\tWARN_ON(readl_relaxed(p->base + DMA_DCSR_R) &\n\t\t\t\t      (DCSR_STRTA | DCSR_STRTB));\n\n\t\t \n\t\twritel_relaxed(DCSR_RUN | DCSR_STRTA | DCSR_STRTB,\n\t\t\t       p->base + DMA_DCSR_C);\n\t\twritel_relaxed(txd->ddar, p->base + DMA_DDAR);\n\n\t\t \n\t\tsa11x0_dma_start_sg(p, c);\n\t\tsa11x0_dma_start_sg(p, c);\n\t}\n}\n\nstatic void sa11x0_dma_tasklet(struct tasklet_struct *t)\n{\n\tstruct sa11x0_dma_dev *d = from_tasklet(d, t, task);\n\tstruct sa11x0_dma_phy *p;\n\tstruct sa11x0_dma_chan *c;\n\tunsigned pch, pch_alloc = 0;\n\n\tdev_dbg(d->slave.dev, \"tasklet enter\\n\");\n\n\tlist_for_each_entry(c, &d->slave.channels, vc.chan.device_node) {\n\t\tspin_lock_irq(&c->vc.lock);\n\t\tp = c->phy;\n\t\tif (p && !p->txd_done) {\n\t\t\tsa11x0_dma_start_txd(c);\n\t\t\tif (!p->txd_done) {\n\t\t\t\t \n\t\t\t\tdev_dbg(d->slave.dev, \"pchan %u: free\\n\", p->num);\n\n\t\t\t\t \n\t\t\t\tc->phy = NULL;\n\t\t\t\tp->vchan = NULL;\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irq(&c->vc.lock);\n\t}\n\n\tspin_lock_irq(&d->lock);\n\tfor (pch = 0; pch < NR_PHY_CHAN; pch++) {\n\t\tp = &d->phy[pch];\n\n\t\tif (p->vchan == NULL && !list_empty(&d->chan_pending)) {\n\t\t\tc = list_first_entry(&d->chan_pending,\n\t\t\t\tstruct sa11x0_dma_chan, node);\n\t\t\tlist_del_init(&c->node);\n\n\t\t\tpch_alloc |= 1 << pch;\n\n\t\t\t \n\t\t\tp->vchan = c;\n\n\t\t\tdev_dbg(d->slave.dev, \"pchan %u: alloc vchan %p\\n\", pch, &c->vc);\n\t\t}\n\t}\n\tspin_unlock_irq(&d->lock);\n\n\tfor (pch = 0; pch < NR_PHY_CHAN; pch++) {\n\t\tif (pch_alloc & (1 << pch)) {\n\t\t\tp = &d->phy[pch];\n\t\t\tc = p->vchan;\n\n\t\t\tspin_lock_irq(&c->vc.lock);\n\t\t\tc->phy = p;\n\n\t\t\tsa11x0_dma_start_txd(c);\n\t\t\tspin_unlock_irq(&c->vc.lock);\n\t\t}\n\t}\n\n\tdev_dbg(d->slave.dev, \"tasklet exit\\n\");\n}\n\n\nstatic void sa11x0_dma_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tstruct sa11x0_dma_dev *d = to_sa11x0_dma(chan->device);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&d->lock, flags);\n\tlist_del_init(&c->node);\n\tspin_unlock_irqrestore(&d->lock, flags);\n\n\tvchan_free_chan_resources(&c->vc);\n}\n\nstatic dma_addr_t sa11x0_dma_pos(struct sa11x0_dma_phy *p)\n{\n\tunsigned reg;\n\tu32 dcsr;\n\n\tdcsr = readl_relaxed(p->base + DMA_DCSR_R);\n\n\tif ((dcsr & (DCSR_BIU | DCSR_STRTA)) == DCSR_STRTA ||\n\t    (dcsr & (DCSR_BIU | DCSR_STRTB)) == DCSR_BIU)\n\t\treg = DMA_DBSA;\n\telse\n\t\treg = DMA_DBSB;\n\n\treturn readl_relaxed(p->base + reg);\n}\n\nstatic enum dma_status sa11x0_dma_tx_status(struct dma_chan *chan,\n\tdma_cookie_t cookie, struct dma_tx_state *state)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tstruct sa11x0_dma_dev *d = to_sa11x0_dma(chan->device);\n\tstruct sa11x0_dma_phy *p;\n\tstruct virt_dma_desc *vd;\n\tunsigned long flags;\n\tenum dma_status ret;\n\n\tret = dma_cookie_status(&c->vc.chan, cookie, state);\n\tif (ret == DMA_COMPLETE)\n\t\treturn ret;\n\n\tif (!state)\n\t\treturn c->status;\n\n\tspin_lock_irqsave(&c->vc.lock, flags);\n\tp = c->phy;\n\n\t \n\tvd = vchan_find_desc(&c->vc, cookie);\n\tif (vd) {\n\t\tstate->residue = container_of(vd, struct sa11x0_dma_desc, vd)->size;\n\t} else if (!p) {\n\t\tstate->residue = 0;\n\t} else {\n\t\tstruct sa11x0_dma_desc *txd;\n\t\tsize_t bytes = 0;\n\n\t\tif (p->txd_done && p->txd_done->vd.tx.cookie == cookie)\n\t\t\ttxd = p->txd_done;\n\t\telse if (p->txd_load && p->txd_load->vd.tx.cookie == cookie)\n\t\t\ttxd = p->txd_load;\n\t\telse\n\t\t\ttxd = NULL;\n\n\t\tret = c->status;\n\t\tif (txd) {\n\t\t\tdma_addr_t addr = sa11x0_dma_pos(p);\n\t\t\tunsigned i;\n\n\t\t\tdev_vdbg(d->slave.dev, \"tx_status: addr:%pad\\n\", &addr);\n\n\t\t\tfor (i = 0; i < txd->sglen; i++) {\n\t\t\t\tdev_vdbg(d->slave.dev, \"tx_status: [%u] %x+%x\\n\",\n\t\t\t\t\ti, txd->sg[i].addr, txd->sg[i].len);\n\t\t\t\tif (addr >= txd->sg[i].addr &&\n\t\t\t\t    addr < txd->sg[i].addr + txd->sg[i].len) {\n\t\t\t\t\tunsigned len;\n\n\t\t\t\t\tlen = txd->sg[i].len -\n\t\t\t\t\t\t(addr - txd->sg[i].addr);\n\t\t\t\t\tdev_vdbg(d->slave.dev, \"tx_status: [%u] +%x\\n\",\n\t\t\t\t\t\ti, len);\n\t\t\t\t\tbytes += len;\n\t\t\t\t\ti++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor (; i < txd->sglen; i++) {\n\t\t\t\tdev_vdbg(d->slave.dev, \"tx_status: [%u] %x+%x ++\\n\",\n\t\t\t\t\ti, txd->sg[i].addr, txd->sg[i].len);\n\t\t\t\tbytes += txd->sg[i].len;\n\t\t\t}\n\t\t}\n\t\tstate->residue = bytes;\n\t}\n\tspin_unlock_irqrestore(&c->vc.lock, flags);\n\n\tdev_vdbg(d->slave.dev, \"tx_status: bytes 0x%x\\n\", state->residue);\n\n\treturn ret;\n}\n\n \nstatic void sa11x0_dma_issue_pending(struct dma_chan *chan)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tstruct sa11x0_dma_dev *d = to_sa11x0_dma(chan->device);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&c->vc.lock, flags);\n\tif (vchan_issue_pending(&c->vc)) {\n\t\tif (!c->phy) {\n\t\t\tspin_lock(&d->lock);\n\t\t\tif (list_empty(&c->node)) {\n\t\t\t\tlist_add_tail(&c->node, &d->chan_pending);\n\t\t\t\ttasklet_schedule(&d->task);\n\t\t\t\tdev_dbg(d->slave.dev, \"vchan %p: issued\\n\", &c->vc);\n\t\t\t}\n\t\t\tspin_unlock(&d->lock);\n\t\t}\n\t} else\n\t\tdev_dbg(d->slave.dev, \"vchan %p: nothing to issue\\n\", &c->vc);\n\tspin_unlock_irqrestore(&c->vc.lock, flags);\n}\n\nstatic struct dma_async_tx_descriptor *sa11x0_dma_prep_slave_sg(\n\tstruct dma_chan *chan, struct scatterlist *sg, unsigned int sglen,\n\tenum dma_transfer_direction dir, unsigned long flags, void *context)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tstruct sa11x0_dma_desc *txd;\n\tstruct scatterlist *sgent;\n\tunsigned i, j = sglen;\n\tsize_t size = 0;\n\n\t \n\tif (dir != (c->ddar & DDAR_RW ? DMA_DEV_TO_MEM : DMA_MEM_TO_DEV)) {\n\t\tdev_err(chan->device->dev, \"vchan %p: bad DMA direction: DDAR:%08x dir:%u\\n\",\n\t\t\t&c->vc, c->ddar, dir);\n\t\treturn NULL;\n\t}\n\n\t \n\tif (sglen == 0)\n\t\treturn NULL;\n\n\tfor_each_sg(sg, sgent, sglen, i) {\n\t\tdma_addr_t addr = sg_dma_address(sgent);\n\t\tunsigned int len = sg_dma_len(sgent);\n\n\t\tif (len > DMA_MAX_SIZE)\n\t\t\tj += DIV_ROUND_UP(len, DMA_MAX_SIZE & ~DMA_ALIGN) - 1;\n\t\tif (addr & DMA_ALIGN) {\n\t\t\tdev_dbg(chan->device->dev, \"vchan %p: bad buffer alignment: %pad\\n\",\n\t\t\t\t&c->vc, &addr);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\ttxd = kzalloc(struct_size(txd, sg, j), GFP_ATOMIC);\n\tif (!txd) {\n\t\tdev_dbg(chan->device->dev, \"vchan %p: kzalloc failed\\n\", &c->vc);\n\t\treturn NULL;\n\t}\n\n\tj = 0;\n\tfor_each_sg(sg, sgent, sglen, i) {\n\t\tdma_addr_t addr = sg_dma_address(sgent);\n\t\tunsigned len = sg_dma_len(sgent);\n\n\t\tsize += len;\n\n\t\tdo {\n\t\t\tunsigned tlen = len;\n\n\t\t\t \n\t\t\tif (tlen > DMA_MAX_SIZE) {\n\t\t\t\tunsigned mult = DIV_ROUND_UP(tlen,\n\t\t\t\t\tDMA_MAX_SIZE & ~DMA_ALIGN);\n\n\t\t\t\ttlen = (tlen / mult) & ~DMA_ALIGN;\n\t\t\t}\n\n\t\t\ttxd->sg[j].addr = addr;\n\t\t\ttxd->sg[j].len = tlen;\n\n\t\t\taddr += tlen;\n\t\t\tlen -= tlen;\n\t\t\tj++;\n\t\t} while (len);\n\t}\n\n\ttxd->ddar = c->ddar;\n\ttxd->size = size;\n\ttxd->sglen = j;\n\n\tdev_dbg(chan->device->dev, \"vchan %p: txd %p: size %zu nr %u\\n\",\n\t\t&c->vc, &txd->vd, txd->size, txd->sglen);\n\n\treturn vchan_tx_prep(&c->vc, &txd->vd, flags);\n}\n\nstatic struct dma_async_tx_descriptor *sa11x0_dma_prep_dma_cyclic(\n\tstruct dma_chan *chan, dma_addr_t addr, size_t size, size_t period,\n\tenum dma_transfer_direction dir, unsigned long flags)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tstruct sa11x0_dma_desc *txd;\n\tunsigned i, j, k, sglen, sgperiod;\n\n\t \n\tif (dir != (c->ddar & DDAR_RW ? DMA_DEV_TO_MEM : DMA_MEM_TO_DEV)) {\n\t\tdev_err(chan->device->dev, \"vchan %p: bad DMA direction: DDAR:%08x dir:%u\\n\",\n\t\t\t&c->vc, c->ddar, dir);\n\t\treturn NULL;\n\t}\n\n\tsgperiod = DIV_ROUND_UP(period, DMA_MAX_SIZE & ~DMA_ALIGN);\n\tsglen = size * sgperiod / period;\n\n\t \n\tif (sglen == 0)\n\t\treturn NULL;\n\n\ttxd = kzalloc(struct_size(txd, sg, sglen), GFP_ATOMIC);\n\tif (!txd) {\n\t\tdev_dbg(chan->device->dev, \"vchan %p: kzalloc failed\\n\", &c->vc);\n\t\treturn NULL;\n\t}\n\n\tfor (i = k = 0; i < size / period; i++) {\n\t\tsize_t tlen, len = period;\n\n\t\tfor (j = 0; j < sgperiod; j++, k++) {\n\t\t\ttlen = len;\n\n\t\t\tif (tlen > DMA_MAX_SIZE) {\n\t\t\t\tunsigned mult = DIV_ROUND_UP(tlen, DMA_MAX_SIZE & ~DMA_ALIGN);\n\t\t\t\ttlen = (tlen / mult) & ~DMA_ALIGN;\n\t\t\t}\n\n\t\t\ttxd->sg[k].addr = addr;\n\t\t\ttxd->sg[k].len = tlen;\n\t\t\taddr += tlen;\n\t\t\tlen -= tlen;\n\t\t}\n\n\t\tWARN_ON(len != 0);\n\t}\n\n\tWARN_ON(k != sglen);\n\n\ttxd->ddar = c->ddar;\n\ttxd->size = size;\n\ttxd->sglen = sglen;\n\ttxd->cyclic = 1;\n\ttxd->period = sgperiod;\n\n\treturn vchan_tx_prep(&c->vc, &txd->vd, DMA_PREP_INTERRUPT | DMA_CTRL_ACK);\n}\n\nstatic int sa11x0_dma_device_config(struct dma_chan *chan,\n\t\t\t\t    struct dma_slave_config *cfg)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tu32 ddar = c->ddar & ((0xf << 4) | DDAR_RW);\n\tdma_addr_t addr;\n\tenum dma_slave_buswidth width;\n\tu32 maxburst;\n\n\tif (ddar & DDAR_RW) {\n\t\taddr = cfg->src_addr;\n\t\twidth = cfg->src_addr_width;\n\t\tmaxburst = cfg->src_maxburst;\n\t} else {\n\t\taddr = cfg->dst_addr;\n\t\twidth = cfg->dst_addr_width;\n\t\tmaxburst = cfg->dst_maxburst;\n\t}\n\n\tif ((width != DMA_SLAVE_BUSWIDTH_1_BYTE &&\n\t     width != DMA_SLAVE_BUSWIDTH_2_BYTES) ||\n\t    (maxburst != 4 && maxburst != 8))\n\t\treturn -EINVAL;\n\n\tif (width == DMA_SLAVE_BUSWIDTH_2_BYTES)\n\t\tddar |= DDAR_DW;\n\tif (maxburst == 8)\n\t\tddar |= DDAR_BS;\n\n\tdev_dbg(c->vc.chan.device->dev, \"vchan %p: dma_slave_config addr %pad width %u burst %u\\n\",\n\t\t&c->vc, &addr, width, maxburst);\n\n\tc->ddar = ddar | (addr & 0xf0000000) | (addr & 0x003ffffc) << 6;\n\n\treturn 0;\n}\n\nstatic int sa11x0_dma_device_pause(struct dma_chan *chan)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tstruct sa11x0_dma_dev *d = to_sa11x0_dma(chan->device);\n\tstruct sa11x0_dma_phy *p;\n\tunsigned long flags;\n\n\tdev_dbg(d->slave.dev, \"vchan %p: pause\\n\", &c->vc);\n\tspin_lock_irqsave(&c->vc.lock, flags);\n\tif (c->status == DMA_IN_PROGRESS) {\n\t\tc->status = DMA_PAUSED;\n\n\t\tp = c->phy;\n\t\tif (p) {\n\t\t\twritel(DCSR_RUN | DCSR_IE, p->base + DMA_DCSR_C);\n\t\t} else {\n\t\t\tspin_lock(&d->lock);\n\t\t\tlist_del_init(&c->node);\n\t\t\tspin_unlock(&d->lock);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&c->vc.lock, flags);\n\n\treturn 0;\n}\n\nstatic int sa11x0_dma_device_resume(struct dma_chan *chan)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tstruct sa11x0_dma_dev *d = to_sa11x0_dma(chan->device);\n\tstruct sa11x0_dma_phy *p;\n\tunsigned long flags;\n\n\tdev_dbg(d->slave.dev, \"vchan %p: resume\\n\", &c->vc);\n\tspin_lock_irqsave(&c->vc.lock, flags);\n\tif (c->status == DMA_PAUSED) {\n\t\tc->status = DMA_IN_PROGRESS;\n\n\t\tp = c->phy;\n\t\tif (p) {\n\t\t\twritel(DCSR_RUN | DCSR_IE, p->base + DMA_DCSR_S);\n\t\t} else if (!list_empty(&c->vc.desc_issued)) {\n\t\t\tspin_lock(&d->lock);\n\t\t\tlist_add_tail(&c->node, &d->chan_pending);\n\t\t\tspin_unlock(&d->lock);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&c->vc.lock, flags);\n\n\treturn 0;\n}\n\nstatic int sa11x0_dma_device_terminate_all(struct dma_chan *chan)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tstruct sa11x0_dma_dev *d = to_sa11x0_dma(chan->device);\n\tstruct sa11x0_dma_phy *p;\n\tLIST_HEAD(head);\n\tunsigned long flags;\n\n\tdev_dbg(d->slave.dev, \"vchan %p: terminate all\\n\", &c->vc);\n\t \n\tspin_lock_irqsave(&c->vc.lock, flags);\n\tvchan_get_all_descriptors(&c->vc, &head);\n\n\tp = c->phy;\n\tif (p) {\n\t\tdev_dbg(d->slave.dev, \"pchan %u: terminating\\n\", p->num);\n\t\t \n\t\twritel(DCSR_RUN | DCSR_IE |\n\t\t       DCSR_STRTA | DCSR_DONEA |\n\t\t       DCSR_STRTB | DCSR_DONEB,\n\t\t       p->base + DMA_DCSR_C);\n\n\t\tif (p->txd_load) {\n\t\t\tif (p->txd_load != p->txd_done)\n\t\t\t\tlist_add_tail(&p->txd_load->vd.node, &head);\n\t\t\tp->txd_load = NULL;\n\t\t}\n\t\tif (p->txd_done) {\n\t\t\tlist_add_tail(&p->txd_done->vd.node, &head);\n\t\t\tp->txd_done = NULL;\n\t\t}\n\t\tc->phy = NULL;\n\t\tspin_lock(&d->lock);\n\t\tp->vchan = NULL;\n\t\tspin_unlock(&d->lock);\n\t\ttasklet_schedule(&d->task);\n\t}\n\tspin_unlock_irqrestore(&c->vc.lock, flags);\n\tvchan_dma_desc_free_list(&c->vc, &head);\n\n\treturn 0;\n}\n\nstruct sa11x0_dma_channel_desc {\n\tu32 ddar;\n\tconst char *name;\n};\n\n#define CD(d1, d2) { .ddar = DDAR_##d1 | d2, .name = #d1 }\nstatic const struct sa11x0_dma_channel_desc chan_desc[] = {\n\tCD(Ser0UDCTr, 0),\n\tCD(Ser0UDCRc, DDAR_RW),\n\tCD(Ser1SDLCTr, 0),\n\tCD(Ser1SDLCRc, DDAR_RW),\n\tCD(Ser1UARTTr, 0),\n\tCD(Ser1UARTRc, DDAR_RW),\n\tCD(Ser2ICPTr, 0),\n\tCD(Ser2ICPRc, DDAR_RW),\n\tCD(Ser3UARTTr, 0),\n\tCD(Ser3UARTRc, DDAR_RW),\n\tCD(Ser4MCP0Tr, 0),\n\tCD(Ser4MCP0Rc, DDAR_RW),\n\tCD(Ser4MCP1Tr, 0),\n\tCD(Ser4MCP1Rc, DDAR_RW),\n\tCD(Ser4SSPTr, 0),\n\tCD(Ser4SSPRc, DDAR_RW),\n};\n\nstatic const struct dma_slave_map sa11x0_dma_map[] = {\n\t{ \"sa11x0-ir\", \"tx\", \"Ser2ICPTr\" },\n\t{ \"sa11x0-ir\", \"rx\", \"Ser2ICPRc\" },\n\t{ \"sa11x0-ssp\", \"tx\", \"Ser4SSPTr\" },\n\t{ \"sa11x0-ssp\", \"rx\", \"Ser4SSPRc\" },\n};\n\nstatic bool sa11x0_dma_filter_fn(struct dma_chan *chan, void *param)\n{\n\tstruct sa11x0_dma_chan *c = to_sa11x0_dma_chan(chan);\n\tconst char *p = param;\n\n\treturn !strcmp(c->name, p);\n}\n\nstatic int sa11x0_dma_init_dmadev(struct dma_device *dmadev,\n\tstruct device *dev)\n{\n\tunsigned i;\n\n\tINIT_LIST_HEAD(&dmadev->channels);\n\tdmadev->dev = dev;\n\tdmadev->device_free_chan_resources = sa11x0_dma_free_chan_resources;\n\tdmadev->device_config = sa11x0_dma_device_config;\n\tdmadev->device_pause = sa11x0_dma_device_pause;\n\tdmadev->device_resume = sa11x0_dma_device_resume;\n\tdmadev->device_terminate_all = sa11x0_dma_device_terminate_all;\n\tdmadev->device_tx_status = sa11x0_dma_tx_status;\n\tdmadev->device_issue_pending = sa11x0_dma_issue_pending;\n\n\tfor (i = 0; i < ARRAY_SIZE(chan_desc); i++) {\n\t\tstruct sa11x0_dma_chan *c;\n\n\t\tc = kzalloc(sizeof(*c), GFP_KERNEL);\n\t\tif (!c) {\n\t\t\tdev_err(dev, \"no memory for channel %u\\n\", i);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tc->status = DMA_IN_PROGRESS;\n\t\tc->ddar = chan_desc[i].ddar;\n\t\tc->name = chan_desc[i].name;\n\t\tINIT_LIST_HEAD(&c->node);\n\n\t\tc->vc.desc_free = sa11x0_dma_free_desc;\n\t\tvchan_init(&c->vc, dmadev);\n\t}\n\n\treturn dma_async_device_register(dmadev);\n}\n\nstatic int sa11x0_dma_request_irq(struct platform_device *pdev, int nr,\n\tvoid *data)\n{\n\tint irq = platform_get_irq(pdev, nr);\n\n\tif (irq <= 0)\n\t\treturn -ENXIO;\n\n\treturn request_irq(irq, sa11x0_dma_irq, 0, dev_name(&pdev->dev), data);\n}\n\nstatic void sa11x0_dma_free_irq(struct platform_device *pdev, int nr,\n\tvoid *data)\n{\n\tint irq = platform_get_irq(pdev, nr);\n\tif (irq > 0)\n\t\tfree_irq(irq, data);\n}\n\nstatic void sa11x0_dma_free_channels(struct dma_device *dmadev)\n{\n\tstruct sa11x0_dma_chan *c, *cn;\n\n\tlist_for_each_entry_safe(c, cn, &dmadev->channels, vc.chan.device_node) {\n\t\tlist_del(&c->vc.chan.device_node);\n\t\ttasklet_kill(&c->vc.task);\n\t\tkfree(c);\n\t}\n}\n\nstatic int sa11x0_dma_probe(struct platform_device *pdev)\n{\n\tstruct sa11x0_dma_dev *d;\n\tstruct resource *res;\n\tunsigned i;\n\tint ret;\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!res)\n\t\treturn -ENXIO;\n\n\td = kzalloc(sizeof(*d), GFP_KERNEL);\n\tif (!d) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc;\n\t}\n\n\tspin_lock_init(&d->lock);\n\tINIT_LIST_HEAD(&d->chan_pending);\n\n\td->slave.filter.fn = sa11x0_dma_filter_fn;\n\td->slave.filter.mapcnt = ARRAY_SIZE(sa11x0_dma_map);\n\td->slave.filter.map = sa11x0_dma_map;\n\n\td->base = ioremap(res->start, resource_size(res));\n\tif (!d->base) {\n\t\tret = -ENOMEM;\n\t\tgoto err_ioremap;\n\t}\n\n\ttasklet_setup(&d->task, sa11x0_dma_tasklet);\n\n\tfor (i = 0; i < NR_PHY_CHAN; i++) {\n\t\tstruct sa11x0_dma_phy *p = &d->phy[i];\n\n\t\tp->dev = d;\n\t\tp->num = i;\n\t\tp->base = d->base + i * DMA_SIZE;\n\t\twritel_relaxed(DCSR_RUN | DCSR_IE | DCSR_ERROR |\n\t\t\tDCSR_DONEA | DCSR_STRTA | DCSR_DONEB | DCSR_STRTB,\n\t\t\tp->base + DMA_DCSR_C);\n\t\twritel_relaxed(0, p->base + DMA_DDAR);\n\n\t\tret = sa11x0_dma_request_irq(pdev, i, p);\n\t\tif (ret) {\n\t\t\twhile (i) {\n\t\t\t\ti--;\n\t\t\t\tsa11x0_dma_free_irq(pdev, i, &d->phy[i]);\n\t\t\t}\n\t\t\tgoto err_irq;\n\t\t}\n\t}\n\n\tdma_cap_set(DMA_SLAVE, d->slave.cap_mask);\n\tdma_cap_set(DMA_CYCLIC, d->slave.cap_mask);\n\td->slave.device_prep_slave_sg = sa11x0_dma_prep_slave_sg;\n\td->slave.device_prep_dma_cyclic = sa11x0_dma_prep_dma_cyclic;\n\td->slave.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\n\td->slave.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\td->slave.src_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\n\t\t\t\t   BIT(DMA_SLAVE_BUSWIDTH_2_BYTES);\n\td->slave.dst_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\n\t\t\t\t   BIT(DMA_SLAVE_BUSWIDTH_2_BYTES);\n\tret = sa11x0_dma_init_dmadev(&d->slave, &pdev->dev);\n\tif (ret) {\n\t\tdev_warn(d->slave.dev, \"failed to register slave async device: %d\\n\",\n\t\t\tret);\n\t\tgoto err_slave_reg;\n\t}\n\n\tplatform_set_drvdata(pdev, d);\n\treturn 0;\n\n err_slave_reg:\n\tsa11x0_dma_free_channels(&d->slave);\n\tfor (i = 0; i < NR_PHY_CHAN; i++)\n\t\tsa11x0_dma_free_irq(pdev, i, &d->phy[i]);\n err_irq:\n\ttasklet_kill(&d->task);\n\tiounmap(d->base);\n err_ioremap:\n\tkfree(d);\n err_alloc:\n\treturn ret;\n}\n\nstatic int sa11x0_dma_remove(struct platform_device *pdev)\n{\n\tstruct sa11x0_dma_dev *d = platform_get_drvdata(pdev);\n\tunsigned pch;\n\n\tdma_async_device_unregister(&d->slave);\n\n\tsa11x0_dma_free_channels(&d->slave);\n\tfor (pch = 0; pch < NR_PHY_CHAN; pch++)\n\t\tsa11x0_dma_free_irq(pdev, pch, &d->phy[pch]);\n\ttasklet_kill(&d->task);\n\tiounmap(d->base);\n\tkfree(d);\n\n\treturn 0;\n}\n\nstatic __maybe_unused int sa11x0_dma_suspend(struct device *dev)\n{\n\tstruct sa11x0_dma_dev *d = dev_get_drvdata(dev);\n\tunsigned pch;\n\n\tfor (pch = 0; pch < NR_PHY_CHAN; pch++) {\n\t\tstruct sa11x0_dma_phy *p = &d->phy[pch];\n\t\tu32 dcsr, saved_dcsr;\n\n\t\tdcsr = saved_dcsr = readl_relaxed(p->base + DMA_DCSR_R);\n\t\tif (dcsr & DCSR_RUN) {\n\t\t\twritel(DCSR_RUN | DCSR_IE, p->base + DMA_DCSR_C);\n\t\t\tdcsr = readl_relaxed(p->base + DMA_DCSR_R);\n\t\t}\n\n\t\tsaved_dcsr &= DCSR_RUN | DCSR_IE;\n\t\tif (dcsr & DCSR_BIU) {\n\t\t\tp->dbs[0] = readl_relaxed(p->base + DMA_DBSB);\n\t\t\tp->dbt[0] = readl_relaxed(p->base + DMA_DBTB);\n\t\t\tp->dbs[1] = readl_relaxed(p->base + DMA_DBSA);\n\t\t\tp->dbt[1] = readl_relaxed(p->base + DMA_DBTA);\n\t\t\tsaved_dcsr |= (dcsr & DCSR_STRTA ? DCSR_STRTB : 0) |\n\t\t\t\t      (dcsr & DCSR_STRTB ? DCSR_STRTA : 0);\n\t\t} else {\n\t\t\tp->dbs[0] = readl_relaxed(p->base + DMA_DBSA);\n\t\t\tp->dbt[0] = readl_relaxed(p->base + DMA_DBTA);\n\t\t\tp->dbs[1] = readl_relaxed(p->base + DMA_DBSB);\n\t\t\tp->dbt[1] = readl_relaxed(p->base + DMA_DBTB);\n\t\t\tsaved_dcsr |= dcsr & (DCSR_STRTA | DCSR_STRTB);\n\t\t}\n\t\tp->dcsr = saved_dcsr;\n\n\t\twritel(DCSR_STRTA | DCSR_STRTB, p->base + DMA_DCSR_C);\n\t}\n\n\treturn 0;\n}\n\nstatic __maybe_unused int sa11x0_dma_resume(struct device *dev)\n{\n\tstruct sa11x0_dma_dev *d = dev_get_drvdata(dev);\n\tunsigned pch;\n\n\tfor (pch = 0; pch < NR_PHY_CHAN; pch++) {\n\t\tstruct sa11x0_dma_phy *p = &d->phy[pch];\n\t\tstruct sa11x0_dma_desc *txd = NULL;\n\t\tu32 dcsr = readl_relaxed(p->base + DMA_DCSR_R);\n\n\t\tWARN_ON(dcsr & (DCSR_BIU | DCSR_STRTA | DCSR_STRTB | DCSR_RUN));\n\n\t\tif (p->txd_done)\n\t\t\ttxd = p->txd_done;\n\t\telse if (p->txd_load)\n\t\t\ttxd = p->txd_load;\n\n\t\tif (!txd)\n\t\t\tcontinue;\n\n\t\twritel_relaxed(txd->ddar, p->base + DMA_DDAR);\n\n\t\twritel_relaxed(p->dbs[0], p->base + DMA_DBSA);\n\t\twritel_relaxed(p->dbt[0], p->base + DMA_DBTA);\n\t\twritel_relaxed(p->dbs[1], p->base + DMA_DBSB);\n\t\twritel_relaxed(p->dbt[1], p->base + DMA_DBTB);\n\t\twritel_relaxed(p->dcsr, p->base + DMA_DCSR_S);\n\t}\n\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops sa11x0_dma_pm_ops = {\n\tSET_NOIRQ_SYSTEM_SLEEP_PM_OPS(sa11x0_dma_suspend, sa11x0_dma_resume)\n};\n\nstatic struct platform_driver sa11x0_dma_driver = {\n\t.driver = {\n\t\t.name\t= \"sa11x0-dma\",\n\t\t.pm\t= &sa11x0_dma_pm_ops,\n\t},\n\t.probe\t\t= sa11x0_dma_probe,\n\t.remove\t\t= sa11x0_dma_remove,\n};\n\nstatic int __init sa11x0_dma_init(void)\n{\n\treturn platform_driver_register(&sa11x0_dma_driver);\n}\nsubsys_initcall(sa11x0_dma_init);\n\nstatic void __exit sa11x0_dma_exit(void)\n{\n\tplatform_driver_unregister(&sa11x0_dma_driver);\n}\nmodule_exit(sa11x0_dma_exit);\n\nMODULE_AUTHOR(\"Russell King\");\nMODULE_DESCRIPTION(\"SA-11x0 DMA driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS(\"platform:sa11x0-dma\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}