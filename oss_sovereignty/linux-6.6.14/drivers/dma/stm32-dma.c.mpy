{
  "module_name": "stm32-dma.c",
  "hash_id": "44de06922aa43acc43823c2bf4bfc1feba3f6d9ce9da6c2d90409362cfd744e0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/stm32-dma.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/iopoll.h>\n#include <linux/jiffies.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_device.h>\n#include <linux/of_dma.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/reset.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n\n#include \"virt-dma.h\"\n\n#define STM32_DMA_LISR\t\t\t0x0000  \n#define STM32_DMA_HISR\t\t\t0x0004  \n#define STM32_DMA_ISR(n)\t\t(((n) & 4) ? STM32_DMA_HISR : STM32_DMA_LISR)\n#define STM32_DMA_LIFCR\t\t\t0x0008  \n#define STM32_DMA_HIFCR\t\t\t0x000c  \n#define STM32_DMA_IFCR(n)\t\t(((n) & 4) ? STM32_DMA_HIFCR : STM32_DMA_LIFCR)\n#define STM32_DMA_TCI\t\t\tBIT(5)  \n#define STM32_DMA_HTI\t\t\tBIT(4)  \n#define STM32_DMA_TEI\t\t\tBIT(3)  \n#define STM32_DMA_DMEI\t\t\tBIT(2)  \n#define STM32_DMA_FEI\t\t\tBIT(0)  \n#define STM32_DMA_MASKI\t\t\t(STM32_DMA_TCI \\\n\t\t\t\t\t | STM32_DMA_TEI \\\n\t\t\t\t\t | STM32_DMA_DMEI \\\n\t\t\t\t\t | STM32_DMA_FEI)\n \n#define STM32_DMA_FLAGS_SHIFT(n)\t({ typeof(n) (_n) = (n); \\\n\t\t\t\t\t   (((_n) & 2) << 3) | (((_n) & 1) * 6); })\n\n \n#define STM32_DMA_SCR(x)\t\t(0x0010 + 0x18 * (x))  \n#define STM32_DMA_SCR_REQ_MASK\t\tGENMASK(27, 25)\n#define STM32_DMA_SCR_MBURST_MASK\tGENMASK(24, 23)\n#define STM32_DMA_SCR_PBURST_MASK\tGENMASK(22, 21)\n#define STM32_DMA_SCR_PL_MASK\t\tGENMASK(17, 16)\n#define STM32_DMA_SCR_MSIZE_MASK\tGENMASK(14, 13)\n#define STM32_DMA_SCR_PSIZE_MASK\tGENMASK(12, 11)\n#define STM32_DMA_SCR_DIR_MASK\t\tGENMASK(7, 6)\n#define STM32_DMA_SCR_TRBUFF\t\tBIT(20)  \n#define STM32_DMA_SCR_CT\t\tBIT(19)  \n#define STM32_DMA_SCR_DBM\t\tBIT(18)  \n#define STM32_DMA_SCR_PINCOS\t\tBIT(15)  \n#define STM32_DMA_SCR_MINC\t\tBIT(10)  \n#define STM32_DMA_SCR_PINC\t\tBIT(9)  \n#define STM32_DMA_SCR_CIRC\t\tBIT(8)  \n#define STM32_DMA_SCR_PFCTRL\t\tBIT(5)  \n#define STM32_DMA_SCR_TCIE\t\tBIT(4)  \n#define STM32_DMA_SCR_TEIE\t\tBIT(2)  \n#define STM32_DMA_SCR_DMEIE\t\tBIT(1)  \n#define STM32_DMA_SCR_EN\t\tBIT(0)  \n#define STM32_DMA_SCR_CFG_MASK\t\t(STM32_DMA_SCR_PINC \\\n\t\t\t\t\t| STM32_DMA_SCR_MINC \\\n\t\t\t\t\t| STM32_DMA_SCR_PINCOS \\\n\t\t\t\t\t| STM32_DMA_SCR_PL_MASK)\n#define STM32_DMA_SCR_IRQ_MASK\t\t(STM32_DMA_SCR_TCIE \\\n\t\t\t\t\t| STM32_DMA_SCR_TEIE \\\n\t\t\t\t\t| STM32_DMA_SCR_DMEIE)\n\n \n#define STM32_DMA_SNDTR(x)\t\t(0x0014 + 0x18 * (x))\n\n \n#define STM32_DMA_SPAR(x)\t\t(0x0018 + 0x18 * (x))\n\n \n#define STM32_DMA_SM0AR(x)\t\t(0x001c + 0x18 * (x))\n\n \n#define STM32_DMA_SM1AR(x)\t\t(0x0020 + 0x18 * (x))\n\n \n#define STM32_DMA_SFCR(x)\t\t(0x0024 + 0x18 * (x))\n#define STM32_DMA_SFCR_FTH_MASK\t\tGENMASK(1, 0)\n#define STM32_DMA_SFCR_FEIE\t\tBIT(7)  \n#define STM32_DMA_SFCR_DMDIS\t\tBIT(2)  \n#define STM32_DMA_SFCR_MASK\t\t(STM32_DMA_SFCR_FEIE \\\n\t\t\t\t\t| STM32_DMA_SFCR_DMDIS)\n\n \n#define STM32_DMA_DEV_TO_MEM\t\t0x00\n#define\tSTM32_DMA_MEM_TO_DEV\t\t0x01\n#define\tSTM32_DMA_MEM_TO_MEM\t\t0x02\n\n \n#define STM32_DMA_PRIORITY_LOW\t\t0x00\n#define STM32_DMA_PRIORITY_MEDIUM\t0x01\n#define STM32_DMA_PRIORITY_HIGH\t\t0x02\n#define STM32_DMA_PRIORITY_VERY_HIGH\t0x03\n\n \n#define STM32_DMA_FIFO_THRESHOLD_1QUARTERFULL\t\t0x00\n#define STM32_DMA_FIFO_THRESHOLD_HALFFULL\t\t0x01\n#define STM32_DMA_FIFO_THRESHOLD_3QUARTERSFULL\t\t0x02\n#define STM32_DMA_FIFO_THRESHOLD_FULL\t\t\t0x03\n#define STM32_DMA_FIFO_THRESHOLD_NONE\t\t\t0x04\n\n#define STM32_DMA_MAX_DATA_ITEMS\t0xffff\n \n#define STM32_DMA_ALIGNED_MAX_DATA_ITEMS\t\\\n\tALIGN_DOWN(STM32_DMA_MAX_DATA_ITEMS, 16)\n#define STM32_DMA_MAX_CHANNELS\t\t0x08\n#define STM32_DMA_MAX_REQUEST_ID\t0x08\n#define STM32_DMA_MAX_DATA_PARAM\t0x03\n#define STM32_DMA_FIFO_SIZE\t\t16\t \n#define STM32_DMA_MIN_BURST\t\t4\n#define STM32_DMA_MAX_BURST\t\t16\n\n \n#define STM32_DMA_THRESHOLD_FTR_MASK\tGENMASK(1, 0)\n#define STM32_DMA_DIRECT_MODE_MASK\tBIT(2)\n#define STM32_DMA_ALT_ACK_MODE_MASK\tBIT(4)\n#define STM32_DMA_MDMA_STREAM_ID_MASK\tGENMASK(19, 16)\n\nenum stm32_dma_width {\n\tSTM32_DMA_BYTE,\n\tSTM32_DMA_HALF_WORD,\n\tSTM32_DMA_WORD,\n};\n\nenum stm32_dma_burst_size {\n\tSTM32_DMA_BURST_SINGLE,\n\tSTM32_DMA_BURST_INCR4,\n\tSTM32_DMA_BURST_INCR8,\n\tSTM32_DMA_BURST_INCR16,\n};\n\n \nstruct stm32_dma_cfg {\n\tu32 channel_id;\n\tu32 request_line;\n\tu32 stream_config;\n\tu32 features;\n};\n\nstruct stm32_dma_chan_reg {\n\tu32 dma_lisr;\n\tu32 dma_hisr;\n\tu32 dma_lifcr;\n\tu32 dma_hifcr;\n\tu32 dma_scr;\n\tu32 dma_sndtr;\n\tu32 dma_spar;\n\tu32 dma_sm0ar;\n\tu32 dma_sm1ar;\n\tu32 dma_sfcr;\n};\n\nstruct stm32_dma_sg_req {\n\tu32 len;\n\tstruct stm32_dma_chan_reg chan_reg;\n};\n\nstruct stm32_dma_desc {\n\tstruct virt_dma_desc vdesc;\n\tbool cyclic;\n\tu32 num_sgs;\n\tstruct stm32_dma_sg_req sg_req[];\n};\n\n \nstruct stm32_dma_mdma_config {\n\tu32 stream_id;\n\tu32 ifcr;\n\tu32 tcf;\n};\n\nstruct stm32_dma_chan {\n\tstruct virt_dma_chan vchan;\n\tbool config_init;\n\tbool busy;\n\tu32 id;\n\tu32 irq;\n\tstruct stm32_dma_desc *desc;\n\tu32 next_sg;\n\tstruct dma_slave_config\tdma_sconfig;\n\tstruct stm32_dma_chan_reg chan_reg;\n\tu32 threshold;\n\tu32 mem_burst;\n\tu32 mem_width;\n\tenum dma_status status;\n\tbool trig_mdma;\n\tstruct stm32_dma_mdma_config mdma_config;\n};\n\nstruct stm32_dma_device {\n\tstruct dma_device ddev;\n\tvoid __iomem *base;\n\tstruct clk *clk;\n\tbool mem2mem;\n\tstruct stm32_dma_chan chan[STM32_DMA_MAX_CHANNELS];\n};\n\nstatic struct stm32_dma_device *stm32_dma_get_dev(struct stm32_dma_chan *chan)\n{\n\treturn container_of(chan->vchan.chan.device, struct stm32_dma_device,\n\t\t\t    ddev);\n}\n\nstatic struct stm32_dma_chan *to_stm32_dma_chan(struct dma_chan *c)\n{\n\treturn container_of(c, struct stm32_dma_chan, vchan.chan);\n}\n\nstatic struct stm32_dma_desc *to_stm32_dma_desc(struct virt_dma_desc *vdesc)\n{\n\treturn container_of(vdesc, struct stm32_dma_desc, vdesc);\n}\n\nstatic struct device *chan2dev(struct stm32_dma_chan *chan)\n{\n\treturn &chan->vchan.chan.dev->device;\n}\n\nstatic u32 stm32_dma_read(struct stm32_dma_device *dmadev, u32 reg)\n{\n\treturn readl_relaxed(dmadev->base + reg);\n}\n\nstatic void stm32_dma_write(struct stm32_dma_device *dmadev, u32 reg, u32 val)\n{\n\twritel_relaxed(val, dmadev->base + reg);\n}\n\nstatic int stm32_dma_get_width(struct stm32_dma_chan *chan,\n\t\t\t       enum dma_slave_buswidth width)\n{\n\tswitch (width) {\n\tcase DMA_SLAVE_BUSWIDTH_1_BYTE:\n\t\treturn STM32_DMA_BYTE;\n\tcase DMA_SLAVE_BUSWIDTH_2_BYTES:\n\t\treturn STM32_DMA_HALF_WORD;\n\tcase DMA_SLAVE_BUSWIDTH_4_BYTES:\n\t\treturn STM32_DMA_WORD;\n\tdefault:\n\t\tdev_err(chan2dev(chan), \"Dma bus width not supported\\n\");\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic enum dma_slave_buswidth stm32_dma_get_max_width(u32 buf_len,\n\t\t\t\t\t\t       dma_addr_t buf_addr,\n\t\t\t\t\t\t       u32 threshold)\n{\n\tenum dma_slave_buswidth max_width;\n\n\tif (threshold == STM32_DMA_FIFO_THRESHOLD_FULL)\n\t\tmax_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\telse\n\t\tmax_width = DMA_SLAVE_BUSWIDTH_2_BYTES;\n\n\twhile ((buf_len < max_width  || buf_len % max_width) &&\n\t       max_width > DMA_SLAVE_BUSWIDTH_1_BYTE)\n\t\tmax_width = max_width >> 1;\n\n\tif (buf_addr & (max_width - 1))\n\t\tmax_width = DMA_SLAVE_BUSWIDTH_1_BYTE;\n\n\treturn max_width;\n}\n\nstatic bool stm32_dma_fifo_threshold_is_allowed(u32 burst, u32 threshold,\n\t\t\t\t\t\tenum dma_slave_buswidth width)\n{\n\tu32 remaining;\n\n\tif (threshold == STM32_DMA_FIFO_THRESHOLD_NONE)\n\t\treturn false;\n\n\tif (width != DMA_SLAVE_BUSWIDTH_UNDEFINED) {\n\t\tif (burst != 0) {\n\t\t\t \n\t\t\tremaining = ((STM32_DMA_FIFO_SIZE / width) *\n\t\t\t\t     (threshold + 1) / 4) % burst;\n\n\t\t\tif (remaining == 0)\n\t\t\t\treturn true;\n\t\t} else {\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\nstatic bool stm32_dma_is_burst_possible(u32 buf_len, u32 threshold)\n{\n\t \n\tif (threshold == STM32_DMA_FIFO_THRESHOLD_NONE)\n\t\treturn false;\n\n\t \n\treturn ((buf_len % ((threshold + 1) * 4)) == 0);\n}\n\nstatic u32 stm32_dma_get_best_burst(u32 buf_len, u32 max_burst, u32 threshold,\n\t\t\t\t    enum dma_slave_buswidth width)\n{\n\tu32 best_burst = max_burst;\n\n\tif (best_burst == 1 || !stm32_dma_is_burst_possible(buf_len, threshold))\n\t\treturn 0;\n\n\twhile ((buf_len < best_burst * width && best_burst > 1) ||\n\t       !stm32_dma_fifo_threshold_is_allowed(best_burst, threshold,\n\t\t\t\t\t\t    width)) {\n\t\tif (best_burst > STM32_DMA_MIN_BURST)\n\t\t\tbest_burst = best_burst >> 1;\n\t\telse\n\t\t\tbest_burst = 0;\n\t}\n\n\treturn best_burst;\n}\n\nstatic int stm32_dma_get_burst(struct stm32_dma_chan *chan, u32 maxburst)\n{\n\tswitch (maxburst) {\n\tcase 0:\n\tcase 1:\n\t\treturn STM32_DMA_BURST_SINGLE;\n\tcase 4:\n\t\treturn STM32_DMA_BURST_INCR4;\n\tcase 8:\n\t\treturn STM32_DMA_BURST_INCR8;\n\tcase 16:\n\t\treturn STM32_DMA_BURST_INCR16;\n\tdefault:\n\t\tdev_err(chan2dev(chan), \"Dma burst size not supported\\n\");\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic void stm32_dma_set_fifo_config(struct stm32_dma_chan *chan,\n\t\t\t\t      u32 src_burst, u32 dst_burst)\n{\n\tchan->chan_reg.dma_sfcr &= ~STM32_DMA_SFCR_MASK;\n\tchan->chan_reg.dma_scr &= ~STM32_DMA_SCR_DMEIE;\n\n\tif (!src_burst && !dst_burst) {\n\t\t \n\t\tchan->chan_reg.dma_scr |= STM32_DMA_SCR_DMEIE;\n\t} else {\n\t\t \n\t\tchan->chan_reg.dma_sfcr |= STM32_DMA_SFCR_MASK;\n\t}\n}\n\nstatic int stm32_dma_slave_config(struct dma_chan *c,\n\t\t\t\t  struct dma_slave_config *config)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\n\tmemcpy(&chan->dma_sconfig, config, sizeof(*config));\n\n\t \n\tif (config->peripheral_size) {\n\t\tconfig->peripheral_config = &chan->mdma_config;\n\t\tconfig->peripheral_size = sizeof(chan->mdma_config);\n\t\tchan->trig_mdma = true;\n\t}\n\n\tchan->config_init = true;\n\n\treturn 0;\n}\n\nstatic u32 stm32_dma_irq_status(struct stm32_dma_chan *chan)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tu32 flags, dma_isr;\n\n\t \n\n\tdma_isr = stm32_dma_read(dmadev, STM32_DMA_ISR(chan->id));\n\tflags = dma_isr >> STM32_DMA_FLAGS_SHIFT(chan->id);\n\n\treturn flags & STM32_DMA_MASKI;\n}\n\nstatic void stm32_dma_irq_clear(struct stm32_dma_chan *chan, u32 flags)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tu32 dma_ifcr;\n\n\t \n\tflags &= STM32_DMA_MASKI;\n\tdma_ifcr = flags << STM32_DMA_FLAGS_SHIFT(chan->id);\n\n\tstm32_dma_write(dmadev, STM32_DMA_IFCR(chan->id), dma_ifcr);\n}\n\nstatic int stm32_dma_disable_chan(struct stm32_dma_chan *chan)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tu32 dma_scr, id, reg;\n\n\tid = chan->id;\n\treg = STM32_DMA_SCR(id);\n\tdma_scr = stm32_dma_read(dmadev, reg);\n\n\tif (dma_scr & STM32_DMA_SCR_EN) {\n\t\tdma_scr &= ~STM32_DMA_SCR_EN;\n\t\tstm32_dma_write(dmadev, reg, dma_scr);\n\n\t\treturn readl_relaxed_poll_timeout_atomic(dmadev->base + reg,\n\t\t\t\t\tdma_scr, !(dma_scr & STM32_DMA_SCR_EN),\n\t\t\t\t\t10, 1000000);\n\t}\n\n\treturn 0;\n}\n\nstatic void stm32_dma_stop(struct stm32_dma_chan *chan)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tu32 dma_scr, dma_sfcr, status;\n\tint ret;\n\n\t \n\tdma_scr = stm32_dma_read(dmadev, STM32_DMA_SCR(chan->id));\n\tdma_scr &= ~STM32_DMA_SCR_IRQ_MASK;\n\tstm32_dma_write(dmadev, STM32_DMA_SCR(chan->id), dma_scr);\n\tdma_sfcr = stm32_dma_read(dmadev, STM32_DMA_SFCR(chan->id));\n\tdma_sfcr &= ~STM32_DMA_SFCR_FEIE;\n\tstm32_dma_write(dmadev, STM32_DMA_SFCR(chan->id), dma_sfcr);\n\n\t \n\tret = stm32_dma_disable_chan(chan);\n\tif (ret < 0)\n\t\treturn;\n\n\t \n\tstatus = stm32_dma_irq_status(chan);\n\tif (status) {\n\t\tdev_dbg(chan2dev(chan), \"%s(): clearing interrupt: 0x%08x\\n\",\n\t\t\t__func__, status);\n\t\tstm32_dma_irq_clear(chan, status);\n\t}\n\n\tchan->busy = false;\n\tchan->status = DMA_COMPLETE;\n}\n\nstatic int stm32_dma_terminate_all(struct dma_chan *c)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\n\tif (chan->desc) {\n\t\tdma_cookie_complete(&chan->desc->vdesc.tx);\n\t\tvchan_terminate_vdesc(&chan->desc->vdesc);\n\t\tif (chan->busy)\n\t\t\tstm32_dma_stop(chan);\n\t\tchan->desc = NULL;\n\t}\n\n\tvchan_get_all_descriptors(&chan->vchan, &head);\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\tvchan_dma_desc_free_list(&chan->vchan, &head);\n\n\treturn 0;\n}\n\nstatic void stm32_dma_synchronize(struct dma_chan *c)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\n\tvchan_synchronize(&chan->vchan);\n}\n\nstatic void stm32_dma_dump_reg(struct stm32_dma_chan *chan)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tu32 scr = stm32_dma_read(dmadev, STM32_DMA_SCR(chan->id));\n\tu32 ndtr = stm32_dma_read(dmadev, STM32_DMA_SNDTR(chan->id));\n\tu32 spar = stm32_dma_read(dmadev, STM32_DMA_SPAR(chan->id));\n\tu32 sm0ar = stm32_dma_read(dmadev, STM32_DMA_SM0AR(chan->id));\n\tu32 sm1ar = stm32_dma_read(dmadev, STM32_DMA_SM1AR(chan->id));\n\tu32 sfcr = stm32_dma_read(dmadev, STM32_DMA_SFCR(chan->id));\n\n\tdev_dbg(chan2dev(chan), \"SCR:   0x%08x\\n\", scr);\n\tdev_dbg(chan2dev(chan), \"NDTR:  0x%08x\\n\", ndtr);\n\tdev_dbg(chan2dev(chan), \"SPAR:  0x%08x\\n\", spar);\n\tdev_dbg(chan2dev(chan), \"SM0AR: 0x%08x\\n\", sm0ar);\n\tdev_dbg(chan2dev(chan), \"SM1AR: 0x%08x\\n\", sm1ar);\n\tdev_dbg(chan2dev(chan), \"SFCR:  0x%08x\\n\", sfcr);\n}\n\nstatic void stm32_dma_sg_inc(struct stm32_dma_chan *chan)\n{\n\tchan->next_sg++;\n\tif (chan->desc->cyclic && (chan->next_sg == chan->desc->num_sgs))\n\t\tchan->next_sg = 0;\n}\n\nstatic void stm32_dma_configure_next_sg(struct stm32_dma_chan *chan);\n\nstatic void stm32_dma_start_transfer(struct stm32_dma_chan *chan)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tstruct virt_dma_desc *vdesc;\n\tstruct stm32_dma_sg_req *sg_req;\n\tstruct stm32_dma_chan_reg *reg;\n\tu32 status;\n\tint ret;\n\n\tret = stm32_dma_disable_chan(chan);\n\tif (ret < 0)\n\t\treturn;\n\n\tif (!chan->desc) {\n\t\tvdesc = vchan_next_desc(&chan->vchan);\n\t\tif (!vdesc)\n\t\t\treturn;\n\n\t\tlist_del(&vdesc->node);\n\n\t\tchan->desc = to_stm32_dma_desc(vdesc);\n\t\tchan->next_sg = 0;\n\t}\n\n\tif (chan->next_sg == chan->desc->num_sgs)\n\t\tchan->next_sg = 0;\n\n\tsg_req = &chan->desc->sg_req[chan->next_sg];\n\treg = &sg_req->chan_reg;\n\n\t \n\tif (chan->trig_mdma && chan->dma_sconfig.direction != DMA_MEM_TO_DEV)\n\t\treg->dma_scr &= ~STM32_DMA_SCR_TCIE;\n\n\treg->dma_scr &= ~STM32_DMA_SCR_EN;\n\tstm32_dma_write(dmadev, STM32_DMA_SCR(chan->id), reg->dma_scr);\n\tstm32_dma_write(dmadev, STM32_DMA_SPAR(chan->id), reg->dma_spar);\n\tstm32_dma_write(dmadev, STM32_DMA_SM0AR(chan->id), reg->dma_sm0ar);\n\tstm32_dma_write(dmadev, STM32_DMA_SFCR(chan->id), reg->dma_sfcr);\n\tstm32_dma_write(dmadev, STM32_DMA_SM1AR(chan->id), reg->dma_sm1ar);\n\tstm32_dma_write(dmadev, STM32_DMA_SNDTR(chan->id), reg->dma_sndtr);\n\n\tstm32_dma_sg_inc(chan);\n\n\t \n\tstatus = stm32_dma_irq_status(chan);\n\tif (status)\n\t\tstm32_dma_irq_clear(chan, status);\n\n\tif (chan->desc->cyclic)\n\t\tstm32_dma_configure_next_sg(chan);\n\n\tstm32_dma_dump_reg(chan);\n\n\t \n\tchan->busy = true;\n\tchan->status = DMA_IN_PROGRESS;\n\treg->dma_scr |= STM32_DMA_SCR_EN;\n\tstm32_dma_write(dmadev, STM32_DMA_SCR(chan->id), reg->dma_scr);\n\n\tdev_dbg(chan2dev(chan), \"vchan %pK: started\\n\", &chan->vchan);\n}\n\nstatic void stm32_dma_configure_next_sg(struct stm32_dma_chan *chan)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tstruct stm32_dma_sg_req *sg_req;\n\tu32 dma_scr, dma_sm0ar, dma_sm1ar, id;\n\n\tid = chan->id;\n\tdma_scr = stm32_dma_read(dmadev, STM32_DMA_SCR(id));\n\n\tsg_req = &chan->desc->sg_req[chan->next_sg];\n\n\tif (dma_scr & STM32_DMA_SCR_CT) {\n\t\tdma_sm0ar = sg_req->chan_reg.dma_sm0ar;\n\t\tstm32_dma_write(dmadev, STM32_DMA_SM0AR(id), dma_sm0ar);\n\t\tdev_dbg(chan2dev(chan), \"CT=1 <=> SM0AR: 0x%08x\\n\",\n\t\t\tstm32_dma_read(dmadev, STM32_DMA_SM0AR(id)));\n\t} else {\n\t\tdma_sm1ar = sg_req->chan_reg.dma_sm1ar;\n\t\tstm32_dma_write(dmadev, STM32_DMA_SM1AR(id), dma_sm1ar);\n\t\tdev_dbg(chan2dev(chan), \"CT=0 <=> SM1AR: 0x%08x\\n\",\n\t\t\tstm32_dma_read(dmadev, STM32_DMA_SM1AR(id)));\n\t}\n}\n\nstatic void stm32_dma_handle_chan_paused(struct stm32_dma_chan *chan)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tu32 dma_scr;\n\n\t \n\tdma_scr = stm32_dma_read(dmadev, STM32_DMA_SCR(chan->id));\n\t \n\tif (chan->desc && chan->desc->cyclic) {\n\t\tif (chan->desc->num_sgs == 1)\n\t\t\tdma_scr |= STM32_DMA_SCR_CIRC;\n\t\telse\n\t\t\tdma_scr |= STM32_DMA_SCR_DBM;\n\t}\n\tchan->chan_reg.dma_scr = dma_scr;\n\n\t \n\tif (chan->desc && chan->desc->cyclic) {\n\t\tdma_scr &= ~(STM32_DMA_SCR_DBM | STM32_DMA_SCR_CIRC);\n\t\tstm32_dma_write(dmadev, STM32_DMA_SCR(chan->id), dma_scr);\n\t}\n\n\tchan->chan_reg.dma_sndtr = stm32_dma_read(dmadev, STM32_DMA_SNDTR(chan->id));\n\n\tchan->status = DMA_PAUSED;\n\n\tdev_dbg(chan2dev(chan), \"vchan %pK: paused\\n\", &chan->vchan);\n}\n\nstatic void stm32_dma_post_resume_reconfigure(struct stm32_dma_chan *chan)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tstruct stm32_dma_sg_req *sg_req;\n\tu32 dma_scr, status, id;\n\n\tid = chan->id;\n\tdma_scr = stm32_dma_read(dmadev, STM32_DMA_SCR(id));\n\n\t \n\tstatus = stm32_dma_irq_status(chan);\n\tif (status)\n\t\tstm32_dma_irq_clear(chan, status);\n\n\tif (!chan->next_sg)\n\t\tsg_req = &chan->desc->sg_req[chan->desc->num_sgs - 1];\n\telse\n\t\tsg_req = &chan->desc->sg_req[chan->next_sg - 1];\n\n\t \n\tstm32_dma_write(dmadev, STM32_DMA_SNDTR(chan->id), sg_req->chan_reg.dma_sndtr);\n\n\t \n\tstm32_dma_write(dmadev, STM32_DMA_SPAR(id), sg_req->chan_reg.dma_spar);\n\n\t \n\tstm32_dma_write(dmadev, STM32_DMA_SM0AR(id), sg_req->chan_reg.dma_sm0ar);\n\tstm32_dma_write(dmadev, STM32_DMA_SM1AR(id), sg_req->chan_reg.dma_sm1ar);\n\n\t \n\tif (chan->chan_reg.dma_scr & STM32_DMA_SCR_DBM) {\n\t\tdma_scr |= STM32_DMA_SCR_DBM;\n\t\t \n\t\tif (chan->chan_reg.dma_scr & STM32_DMA_SCR_CT)\n\t\t\tdma_scr &= ~STM32_DMA_SCR_CT;\n\t\telse\n\t\t\tdma_scr |= STM32_DMA_SCR_CT;\n\t} else if (chan->chan_reg.dma_scr & STM32_DMA_SCR_CIRC) {\n\t\tdma_scr |= STM32_DMA_SCR_CIRC;\n\t}\n\tstm32_dma_write(dmadev, STM32_DMA_SCR(chan->id), dma_scr);\n\n\tstm32_dma_configure_next_sg(chan);\n\n\tstm32_dma_dump_reg(chan);\n\n\tdma_scr |= STM32_DMA_SCR_EN;\n\tstm32_dma_write(dmadev, STM32_DMA_SCR(chan->id), dma_scr);\n\n\tdev_dbg(chan2dev(chan), \"vchan %pK: reconfigured after pause/resume\\n\", &chan->vchan);\n}\n\nstatic void stm32_dma_handle_chan_done(struct stm32_dma_chan *chan, u32 scr)\n{\n\tif (!chan->desc)\n\t\treturn;\n\n\tif (chan->desc->cyclic) {\n\t\tvchan_cyclic_callback(&chan->desc->vdesc);\n\t\tif (chan->trig_mdma)\n\t\t\treturn;\n\t\tstm32_dma_sg_inc(chan);\n\t\t \n\t\tif (!(scr & (STM32_DMA_SCR_CIRC | STM32_DMA_SCR_DBM)))\n\t\t\tstm32_dma_post_resume_reconfigure(chan);\n\t\telse if (scr & STM32_DMA_SCR_DBM)\n\t\t\tstm32_dma_configure_next_sg(chan);\n\t} else {\n\t\tchan->busy = false;\n\t\tchan->status = DMA_COMPLETE;\n\t\tif (chan->next_sg == chan->desc->num_sgs) {\n\t\t\tvchan_cookie_complete(&chan->desc->vdesc);\n\t\t\tchan->desc = NULL;\n\t\t}\n\t\tstm32_dma_start_transfer(chan);\n\t}\n}\n\nstatic irqreturn_t stm32_dma_chan_irq(int irq, void *devid)\n{\n\tstruct stm32_dma_chan *chan = devid;\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tu32 status, scr, sfcr;\n\n\tspin_lock(&chan->vchan.lock);\n\n\tstatus = stm32_dma_irq_status(chan);\n\tscr = stm32_dma_read(dmadev, STM32_DMA_SCR(chan->id));\n\tsfcr = stm32_dma_read(dmadev, STM32_DMA_SFCR(chan->id));\n\n\tif (status & STM32_DMA_FEI) {\n\t\tstm32_dma_irq_clear(chan, STM32_DMA_FEI);\n\t\tstatus &= ~STM32_DMA_FEI;\n\t\tif (sfcr & STM32_DMA_SFCR_FEIE) {\n\t\t\tif (!(scr & STM32_DMA_SCR_EN) &&\n\t\t\t    !(status & STM32_DMA_TCI))\n\t\t\t\tdev_err(chan2dev(chan), \"FIFO Error\\n\");\n\t\t\telse\n\t\t\t\tdev_dbg(chan2dev(chan), \"FIFO over/underrun\\n\");\n\t\t}\n\t}\n\tif (status & STM32_DMA_DMEI) {\n\t\tstm32_dma_irq_clear(chan, STM32_DMA_DMEI);\n\t\tstatus &= ~STM32_DMA_DMEI;\n\t\tif (sfcr & STM32_DMA_SCR_DMEIE)\n\t\t\tdev_dbg(chan2dev(chan), \"Direct mode overrun\\n\");\n\t}\n\n\tif (status & STM32_DMA_TCI) {\n\t\tstm32_dma_irq_clear(chan, STM32_DMA_TCI);\n\t\tif (scr & STM32_DMA_SCR_TCIE) {\n\t\t\tif (chan->status != DMA_PAUSED)\n\t\t\t\tstm32_dma_handle_chan_done(chan, scr);\n\t\t}\n\t\tstatus &= ~STM32_DMA_TCI;\n\t}\n\n\tif (status & STM32_DMA_HTI) {\n\t\tstm32_dma_irq_clear(chan, STM32_DMA_HTI);\n\t\tstatus &= ~STM32_DMA_HTI;\n\t}\n\n\tif (status) {\n\t\tstm32_dma_irq_clear(chan, status);\n\t\tdev_err(chan2dev(chan), \"DMA error: status=0x%08x\\n\", status);\n\t\tif (!(scr & STM32_DMA_SCR_EN))\n\t\t\tdev_err(chan2dev(chan), \"chan disabled by HW\\n\");\n\t}\n\n\tspin_unlock(&chan->vchan.lock);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void stm32_dma_issue_pending(struct dma_chan *c)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\tif (vchan_issue_pending(&chan->vchan) && !chan->desc && !chan->busy) {\n\t\tdev_dbg(chan2dev(chan), \"vchan %pK: issued\\n\", &chan->vchan);\n\t\tstm32_dma_start_transfer(chan);\n\n\t}\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n}\n\nstatic int stm32_dma_pause(struct dma_chan *c)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tunsigned long flags;\n\tint ret;\n\n\tif (chan->status != DMA_IN_PROGRESS)\n\t\treturn -EPERM;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\n\tret = stm32_dma_disable_chan(chan);\n\tif (!ret)\n\t\tstm32_dma_handle_chan_paused(chan);\n\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\n\treturn ret;\n}\n\nstatic int stm32_dma_resume(struct dma_chan *c)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tstruct stm32_dma_chan_reg chan_reg = chan->chan_reg;\n\tu32 id = chan->id, scr, ndtr, offset, spar, sm0ar, sm1ar;\n\tstruct stm32_dma_sg_req *sg_req;\n\tunsigned long flags;\n\n\tif (chan->status != DMA_PAUSED)\n\t\treturn -EPERM;\n\n\tscr = stm32_dma_read(dmadev, STM32_DMA_SCR(id));\n\tif (WARN_ON(scr & STM32_DMA_SCR_EN))\n\t\treturn -EPERM;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\n\t \n\tif (!chan->next_sg)\n\t\tsg_req = &chan->desc->sg_req[chan->desc->num_sgs - 1];\n\telse\n\t\tsg_req = &chan->desc->sg_req[chan->next_sg - 1];\n\n\tndtr = sg_req->chan_reg.dma_sndtr;\n\toffset = (ndtr - chan_reg.dma_sndtr);\n\toffset <<= FIELD_GET(STM32_DMA_SCR_PSIZE_MASK, chan_reg.dma_scr);\n\tspar = sg_req->chan_reg.dma_spar;\n\tsm0ar = sg_req->chan_reg.dma_sm0ar;\n\tsm1ar = sg_req->chan_reg.dma_sm1ar;\n\n\t \n\tif (chan_reg.dma_scr & STM32_DMA_SCR_PINC)\n\t\tstm32_dma_write(dmadev, STM32_DMA_SPAR(id), spar + offset);\n\telse\n\t\tstm32_dma_write(dmadev, STM32_DMA_SPAR(id), spar);\n\n\tif (!(chan_reg.dma_scr & STM32_DMA_SCR_MINC))\n\t\toffset = 0;\n\n\t \n\tif ((chan_reg.dma_scr & STM32_DMA_SCR_DBM) && (chan_reg.dma_scr & STM32_DMA_SCR_CT))\n\t\tstm32_dma_write(dmadev, STM32_DMA_SM1AR(id), sm1ar + offset);\n\telse\n\t\tstm32_dma_write(dmadev, STM32_DMA_SM0AR(id), sm0ar + offset);\n\n\t \n\tstm32_dma_write(dmadev, STM32_DMA_SNDTR(id), chan_reg.dma_sndtr);\n\n\t \n\tif (chan_reg.dma_scr & (STM32_DMA_SCR_CIRC | STM32_DMA_SCR_DBM))\n\t\tchan_reg.dma_scr &= ~(STM32_DMA_SCR_CIRC | STM32_DMA_SCR_DBM);\n\n\tif (chan_reg.dma_scr & STM32_DMA_SCR_DBM)\n\t\tstm32_dma_configure_next_sg(chan);\n\n\tstm32_dma_dump_reg(chan);\n\n\t \n\tchan->status = DMA_IN_PROGRESS;\n\tchan_reg.dma_scr |= STM32_DMA_SCR_EN;\n\tstm32_dma_write(dmadev, STM32_DMA_SCR(id), chan_reg.dma_scr);\n\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\n\tdev_dbg(chan2dev(chan), \"vchan %pK: resumed\\n\", &chan->vchan);\n\n\treturn 0;\n}\n\nstatic int stm32_dma_set_xfer_param(struct stm32_dma_chan *chan,\n\t\t\t\t    enum dma_transfer_direction direction,\n\t\t\t\t    enum dma_slave_buswidth *buswidth,\n\t\t\t\t    u32 buf_len, dma_addr_t buf_addr)\n{\n\tenum dma_slave_buswidth src_addr_width, dst_addr_width;\n\tint src_bus_width, dst_bus_width;\n\tint src_burst_size, dst_burst_size;\n\tu32 src_maxburst, dst_maxburst, src_best_burst, dst_best_burst;\n\tu32 dma_scr, fifoth;\n\n\tsrc_addr_width = chan->dma_sconfig.src_addr_width;\n\tdst_addr_width = chan->dma_sconfig.dst_addr_width;\n\tsrc_maxburst = chan->dma_sconfig.src_maxburst;\n\tdst_maxburst = chan->dma_sconfig.dst_maxburst;\n\tfifoth = chan->threshold;\n\n\tswitch (direction) {\n\tcase DMA_MEM_TO_DEV:\n\t\t \n\t\tdst_bus_width = stm32_dma_get_width(chan, dst_addr_width);\n\t\tif (dst_bus_width < 0)\n\t\t\treturn dst_bus_width;\n\n\t\t \n\t\tdst_best_burst = stm32_dma_get_best_burst(buf_len,\n\t\t\t\t\t\t\t  dst_maxburst,\n\t\t\t\t\t\t\t  fifoth,\n\t\t\t\t\t\t\t  dst_addr_width);\n\n\t\tdst_burst_size = stm32_dma_get_burst(chan, dst_best_burst);\n\t\tif (dst_burst_size < 0)\n\t\t\treturn dst_burst_size;\n\n\t\t \n\t\tsrc_addr_width = stm32_dma_get_max_width(buf_len, buf_addr,\n\t\t\t\t\t\t\t fifoth);\n\t\tchan->mem_width = src_addr_width;\n\t\tsrc_bus_width = stm32_dma_get_width(chan, src_addr_width);\n\t\tif (src_bus_width < 0)\n\t\t\treturn src_bus_width;\n\n\t\t \n\t\tif (buf_addr & (buf_len - 1))\n\t\t\tsrc_maxburst = 1;\n\t\telse\n\t\t\tsrc_maxburst = STM32_DMA_MAX_BURST;\n\t\tsrc_best_burst = stm32_dma_get_best_burst(buf_len,\n\t\t\t\t\t\t\t  src_maxburst,\n\t\t\t\t\t\t\t  fifoth,\n\t\t\t\t\t\t\t  src_addr_width);\n\t\tsrc_burst_size = stm32_dma_get_burst(chan, src_best_burst);\n\t\tif (src_burst_size < 0)\n\t\t\treturn src_burst_size;\n\n\t\tdma_scr = FIELD_PREP(STM32_DMA_SCR_DIR_MASK, STM32_DMA_MEM_TO_DEV) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_PSIZE_MASK, dst_bus_width) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_MSIZE_MASK, src_bus_width) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_PBURST_MASK, dst_burst_size) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_MBURST_MASK, src_burst_size);\n\n\t\t \n\t\tchan->chan_reg.dma_sfcr &= ~STM32_DMA_SFCR_FTH_MASK;\n\t\tif (fifoth != STM32_DMA_FIFO_THRESHOLD_NONE)\n\t\t\tchan->chan_reg.dma_sfcr |= FIELD_PREP(STM32_DMA_SFCR_FTH_MASK, fifoth);\n\n\t\t \n\t\tchan->chan_reg.dma_spar = chan->dma_sconfig.dst_addr;\n\t\t*buswidth = dst_addr_width;\n\t\tbreak;\n\n\tcase DMA_DEV_TO_MEM:\n\t\t \n\t\tsrc_bus_width = stm32_dma_get_width(chan, src_addr_width);\n\t\tif (src_bus_width < 0)\n\t\t\treturn src_bus_width;\n\n\t\t \n\t\tsrc_best_burst = stm32_dma_get_best_burst(buf_len,\n\t\t\t\t\t\t\t  src_maxburst,\n\t\t\t\t\t\t\t  fifoth,\n\t\t\t\t\t\t\t  src_addr_width);\n\t\tchan->mem_burst = src_best_burst;\n\t\tsrc_burst_size = stm32_dma_get_burst(chan, src_best_burst);\n\t\tif (src_burst_size < 0)\n\t\t\treturn src_burst_size;\n\n\t\t \n\t\tdst_addr_width = stm32_dma_get_max_width(buf_len, buf_addr,\n\t\t\t\t\t\t\t fifoth);\n\t\tchan->mem_width = dst_addr_width;\n\t\tdst_bus_width = stm32_dma_get_width(chan, dst_addr_width);\n\t\tif (dst_bus_width < 0)\n\t\t\treturn dst_bus_width;\n\n\t\t \n\t\tif (buf_addr & (buf_len - 1))\n\t\t\tdst_maxburst = 1;\n\t\telse\n\t\t\tdst_maxburst = STM32_DMA_MAX_BURST;\n\t\tdst_best_burst = stm32_dma_get_best_burst(buf_len,\n\t\t\t\t\t\t\t  dst_maxburst,\n\t\t\t\t\t\t\t  fifoth,\n\t\t\t\t\t\t\t  dst_addr_width);\n\t\tchan->mem_burst = dst_best_burst;\n\t\tdst_burst_size = stm32_dma_get_burst(chan, dst_best_burst);\n\t\tif (dst_burst_size < 0)\n\t\t\treturn dst_burst_size;\n\n\t\tdma_scr = FIELD_PREP(STM32_DMA_SCR_DIR_MASK, STM32_DMA_DEV_TO_MEM) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_PSIZE_MASK, src_bus_width) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_MSIZE_MASK, dst_bus_width) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_PBURST_MASK, src_burst_size) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_MBURST_MASK, dst_burst_size);\n\n\t\t \n\t\tchan->chan_reg.dma_sfcr &= ~STM32_DMA_SFCR_FTH_MASK;\n\t\tif (fifoth != STM32_DMA_FIFO_THRESHOLD_NONE)\n\t\t\tchan->chan_reg.dma_sfcr |= FIELD_PREP(STM32_DMA_SFCR_FTH_MASK, fifoth);\n\n\t\t \n\t\tchan->chan_reg.dma_spar = chan->dma_sconfig.src_addr;\n\t\t*buswidth = chan->dma_sconfig.src_addr_width;\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(chan2dev(chan), \"Dma direction is not supported\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tstm32_dma_set_fifo_config(chan, src_best_burst, dst_best_burst);\n\n\t \n\tchan->chan_reg.dma_scr &= ~(STM32_DMA_SCR_DIR_MASK |\n\t\t\tSTM32_DMA_SCR_PSIZE_MASK | STM32_DMA_SCR_MSIZE_MASK |\n\t\t\tSTM32_DMA_SCR_PBURST_MASK | STM32_DMA_SCR_MBURST_MASK);\n\tchan->chan_reg.dma_scr |= dma_scr;\n\n\treturn 0;\n}\n\nstatic void stm32_dma_clear_reg(struct stm32_dma_chan_reg *regs)\n{\n\tmemset(regs, 0, sizeof(struct stm32_dma_chan_reg));\n}\n\nstatic struct dma_async_tx_descriptor *stm32_dma_prep_slave_sg(\n\tstruct dma_chan *c, struct scatterlist *sgl,\n\tu32 sg_len, enum dma_transfer_direction direction,\n\tunsigned long flags, void *context)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tstruct stm32_dma_desc *desc;\n\tstruct scatterlist *sg;\n\tenum dma_slave_buswidth buswidth;\n\tu32 nb_data_items;\n\tint i, ret;\n\n\tif (!chan->config_init) {\n\t\tdev_err(chan2dev(chan), \"dma channel is not configured\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (sg_len < 1) {\n\t\tdev_err(chan2dev(chan), \"Invalid segment length %d\\n\", sg_len);\n\t\treturn NULL;\n\t}\n\n\tdesc = kzalloc(struct_size(desc, sg_req, sg_len), GFP_NOWAIT);\n\tif (!desc)\n\t\treturn NULL;\n\n\t \n\tif (chan->dma_sconfig.device_fc)\n\t\tchan->chan_reg.dma_scr |= STM32_DMA_SCR_PFCTRL;\n\telse\n\t\tchan->chan_reg.dma_scr &= ~STM32_DMA_SCR_PFCTRL;\n\n\t \n\tif (chan->trig_mdma && sg_len > 1) {\n\t\tchan->chan_reg.dma_scr |= STM32_DMA_SCR_DBM;\n\t\tchan->chan_reg.dma_scr &= ~STM32_DMA_SCR_CT;\n\t}\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tret = stm32_dma_set_xfer_param(chan, direction, &buswidth,\n\t\t\t\t\t       sg_dma_len(sg),\n\t\t\t\t\t       sg_dma_address(sg));\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\n\t\tdesc->sg_req[i].len = sg_dma_len(sg);\n\n\t\tnb_data_items = desc->sg_req[i].len / buswidth;\n\t\tif (nb_data_items > STM32_DMA_ALIGNED_MAX_DATA_ITEMS) {\n\t\t\tdev_err(chan2dev(chan), \"nb items not supported\\n\");\n\t\t\tgoto err;\n\t\t}\n\n\t\tstm32_dma_clear_reg(&desc->sg_req[i].chan_reg);\n\t\tdesc->sg_req[i].chan_reg.dma_scr = chan->chan_reg.dma_scr;\n\t\tdesc->sg_req[i].chan_reg.dma_sfcr = chan->chan_reg.dma_sfcr;\n\t\tdesc->sg_req[i].chan_reg.dma_spar = chan->chan_reg.dma_spar;\n\t\tdesc->sg_req[i].chan_reg.dma_sm0ar = sg_dma_address(sg);\n\t\tdesc->sg_req[i].chan_reg.dma_sm1ar = sg_dma_address(sg);\n\t\tif (chan->trig_mdma)\n\t\t\tdesc->sg_req[i].chan_reg.dma_sm1ar += sg_dma_len(sg);\n\t\tdesc->sg_req[i].chan_reg.dma_sndtr = nb_data_items;\n\t}\n\n\tdesc->num_sgs = sg_len;\n\tdesc->cyclic = false;\n\n\treturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n\nerr:\n\tkfree(desc);\n\treturn NULL;\n}\n\nstatic struct dma_async_tx_descriptor *stm32_dma_prep_dma_cyclic(\n\tstruct dma_chan *c, dma_addr_t buf_addr, size_t buf_len,\n\tsize_t period_len, enum dma_transfer_direction direction,\n\tunsigned long flags)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tstruct stm32_dma_desc *desc;\n\tenum dma_slave_buswidth buswidth;\n\tu32 num_periods, nb_data_items;\n\tint i, ret;\n\n\tif (!buf_len || !period_len) {\n\t\tdev_err(chan2dev(chan), \"Invalid buffer/period len\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!chan->config_init) {\n\t\tdev_err(chan2dev(chan), \"dma channel is not configured\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (buf_len % period_len) {\n\t\tdev_err(chan2dev(chan), \"buf_len not multiple of period_len\\n\");\n\t\treturn NULL;\n\t}\n\n\t \n\tif (chan->busy) {\n\t\tdev_err(chan2dev(chan), \"Request not allowed when dma busy\\n\");\n\t\treturn NULL;\n\t}\n\n\tret = stm32_dma_set_xfer_param(chan, direction, &buswidth, period_len,\n\t\t\t\t       buf_addr);\n\tif (ret < 0)\n\t\treturn NULL;\n\n\tnb_data_items = period_len / buswidth;\n\tif (nb_data_items > STM32_DMA_ALIGNED_MAX_DATA_ITEMS) {\n\t\tdev_err(chan2dev(chan), \"number of items not supported\\n\");\n\t\treturn NULL;\n\t}\n\n\t \n\tif (buf_len == period_len) {\n\t\tchan->chan_reg.dma_scr |= STM32_DMA_SCR_CIRC;\n\t} else {\n\t\tchan->chan_reg.dma_scr |= STM32_DMA_SCR_DBM;\n\t\tchan->chan_reg.dma_scr &= ~STM32_DMA_SCR_CT;\n\t}\n\n\t \n\tchan->chan_reg.dma_scr &= ~STM32_DMA_SCR_PFCTRL;\n\n\tnum_periods = buf_len / period_len;\n\n\tdesc = kzalloc(struct_size(desc, sg_req, num_periods), GFP_NOWAIT);\n\tif (!desc)\n\t\treturn NULL;\n\n\tfor (i = 0; i < num_periods; i++) {\n\t\tdesc->sg_req[i].len = period_len;\n\n\t\tstm32_dma_clear_reg(&desc->sg_req[i].chan_reg);\n\t\tdesc->sg_req[i].chan_reg.dma_scr = chan->chan_reg.dma_scr;\n\t\tdesc->sg_req[i].chan_reg.dma_sfcr = chan->chan_reg.dma_sfcr;\n\t\tdesc->sg_req[i].chan_reg.dma_spar = chan->chan_reg.dma_spar;\n\t\tdesc->sg_req[i].chan_reg.dma_sm0ar = buf_addr;\n\t\tdesc->sg_req[i].chan_reg.dma_sm1ar = buf_addr;\n\t\tif (chan->trig_mdma)\n\t\t\tdesc->sg_req[i].chan_reg.dma_sm1ar += period_len;\n\t\tdesc->sg_req[i].chan_reg.dma_sndtr = nb_data_items;\n\t\tif (!chan->trig_mdma)\n\t\t\tbuf_addr += period_len;\n\t}\n\n\tdesc->num_sgs = num_periods;\n\tdesc->cyclic = true;\n\n\treturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n}\n\nstatic struct dma_async_tx_descriptor *stm32_dma_prep_dma_memcpy(\n\tstruct dma_chan *c, dma_addr_t dest,\n\tdma_addr_t src, size_t len, unsigned long flags)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tenum dma_slave_buswidth max_width;\n\tstruct stm32_dma_desc *desc;\n\tsize_t xfer_count, offset;\n\tu32 num_sgs, best_burst, threshold;\n\tint dma_burst, i;\n\n\tnum_sgs = DIV_ROUND_UP(len, STM32_DMA_ALIGNED_MAX_DATA_ITEMS);\n\tdesc = kzalloc(struct_size(desc, sg_req, num_sgs), GFP_NOWAIT);\n\tif (!desc)\n\t\treturn NULL;\n\n\tthreshold = chan->threshold;\n\n\tfor (offset = 0, i = 0; offset < len; offset += xfer_count, i++) {\n\t\txfer_count = min_t(size_t, len - offset,\n\t\t\t\t   STM32_DMA_ALIGNED_MAX_DATA_ITEMS);\n\n\t\t \n\t\tmax_width = DMA_SLAVE_BUSWIDTH_1_BYTE;\n\t\tbest_burst = stm32_dma_get_best_burst(len, STM32_DMA_MAX_BURST,\n\t\t\t\t\t\t      threshold, max_width);\n\t\tdma_burst = stm32_dma_get_burst(chan, best_burst);\n\t\tif (dma_burst < 0) {\n\t\t\tkfree(desc);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tstm32_dma_clear_reg(&desc->sg_req[i].chan_reg);\n\t\tdesc->sg_req[i].chan_reg.dma_scr =\n\t\t\tFIELD_PREP(STM32_DMA_SCR_DIR_MASK, STM32_DMA_MEM_TO_MEM) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_PBURST_MASK, dma_burst) |\n\t\t\tFIELD_PREP(STM32_DMA_SCR_MBURST_MASK, dma_burst) |\n\t\t\tSTM32_DMA_SCR_MINC |\n\t\t\tSTM32_DMA_SCR_PINC |\n\t\t\tSTM32_DMA_SCR_TCIE |\n\t\t\tSTM32_DMA_SCR_TEIE;\n\t\tdesc->sg_req[i].chan_reg.dma_sfcr |= STM32_DMA_SFCR_MASK;\n\t\tdesc->sg_req[i].chan_reg.dma_sfcr |= FIELD_PREP(STM32_DMA_SFCR_FTH_MASK, threshold);\n\t\tdesc->sg_req[i].chan_reg.dma_spar = src + offset;\n\t\tdesc->sg_req[i].chan_reg.dma_sm0ar = dest + offset;\n\t\tdesc->sg_req[i].chan_reg.dma_sndtr = xfer_count;\n\t\tdesc->sg_req[i].len = xfer_count;\n\t}\n\n\tdesc->num_sgs = num_sgs;\n\tdesc->cyclic = false;\n\n\treturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n}\n\nstatic u32 stm32_dma_get_remaining_bytes(struct stm32_dma_chan *chan)\n{\n\tu32 dma_scr, width, ndtr;\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\n\tdma_scr = stm32_dma_read(dmadev, STM32_DMA_SCR(chan->id));\n\twidth = FIELD_GET(STM32_DMA_SCR_PSIZE_MASK, dma_scr);\n\tndtr = stm32_dma_read(dmadev, STM32_DMA_SNDTR(chan->id));\n\n\treturn ndtr << width;\n}\n\n \nstatic bool stm32_dma_is_current_sg(struct stm32_dma_chan *chan)\n{\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tstruct stm32_dma_sg_req *sg_req;\n\tu32 dma_scr, dma_smar, id, period_len;\n\n\tid = chan->id;\n\tdma_scr = stm32_dma_read(dmadev, STM32_DMA_SCR(id));\n\n\t \n\tif (!(dma_scr & STM32_DMA_SCR_DBM))\n\t\treturn true;\n\n\tsg_req = &chan->desc->sg_req[chan->next_sg];\n\tperiod_len = sg_req->len;\n\n\t \n\tif (dma_scr & STM32_DMA_SCR_CT) {\n\t\tdma_smar = stm32_dma_read(dmadev, STM32_DMA_SM0AR(id));\n\t\t \n\t\treturn (dma_smar >= sg_req->chan_reg.dma_sm0ar &&\n\t\t\tdma_smar < sg_req->chan_reg.dma_sm0ar + period_len);\n\t}\n\n\tdma_smar = stm32_dma_read(dmadev, STM32_DMA_SM1AR(id));\n\t \n\treturn (dma_smar >= sg_req->chan_reg.dma_sm1ar &&\n\t\tdma_smar < sg_req->chan_reg.dma_sm1ar + period_len);\n}\n\nstatic size_t stm32_dma_desc_residue(struct stm32_dma_chan *chan,\n\t\t\t\t     struct stm32_dma_desc *desc,\n\t\t\t\t     u32 next_sg)\n{\n\tu32 modulo, burst_size;\n\tu32 residue;\n\tu32 n_sg = next_sg;\n\tstruct stm32_dma_sg_req *sg_req = &chan->desc->sg_req[chan->next_sg];\n\tint i;\n\n\t \n\n\tresidue = stm32_dma_get_remaining_bytes(chan);\n\n\tif ((chan->desc->cyclic || chan->trig_mdma) && !stm32_dma_is_current_sg(chan)) {\n\t\tn_sg++;\n\t\tif (n_sg == chan->desc->num_sgs)\n\t\t\tn_sg = 0;\n\t\tif (!chan->trig_mdma)\n\t\t\tresidue = sg_req->len;\n\t}\n\n\t \n\tif ((!chan->desc->cyclic && !chan->trig_mdma) || n_sg != 0)\n\t\tfor (i = n_sg; i < desc->num_sgs; i++)\n\t\t\tresidue += desc->sg_req[i].len;\n\n\tif (!chan->mem_burst)\n\t\treturn residue;\n\n\tburst_size = chan->mem_burst * chan->mem_width;\n\tmodulo = residue % burst_size;\n\tif (modulo)\n\t\tresidue = residue - modulo + burst_size;\n\n\treturn residue;\n}\n\nstatic enum dma_status stm32_dma_tx_status(struct dma_chan *c,\n\t\t\t\t\t   dma_cookie_t cookie,\n\t\t\t\t\t   struct dma_tx_state *state)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tstruct virt_dma_desc *vdesc;\n\tenum dma_status status;\n\tunsigned long flags;\n\tu32 residue = 0;\n\n\tstatus = dma_cookie_status(c, cookie, state);\n\tif (status == DMA_COMPLETE)\n\t\treturn status;\n\n\tstatus = chan->status;\n\n\tif (!state)\n\t\treturn status;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\tvdesc = vchan_find_desc(&chan->vchan, cookie);\n\tif (chan->desc && cookie == chan->desc->vdesc.tx.cookie)\n\t\tresidue = stm32_dma_desc_residue(chan, chan->desc,\n\t\t\t\t\t\t chan->next_sg);\n\telse if (vdesc)\n\t\tresidue = stm32_dma_desc_residue(chan,\n\t\t\t\t\t\t to_stm32_dma_desc(vdesc), 0);\n\tdma_set_residue(state, residue);\n\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\n\treturn status;\n}\n\nstatic int stm32_dma_alloc_chan_resources(struct dma_chan *c)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tint ret;\n\n\tchan->config_init = false;\n\n\tret = pm_runtime_resume_and_get(dmadev->ddev.dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = stm32_dma_disable_chan(chan);\n\tif (ret < 0)\n\t\tpm_runtime_put(dmadev->ddev.dev);\n\n\treturn ret;\n}\n\nstatic void stm32_dma_free_chan_resources(struct dma_chan *c)\n{\n\tstruct stm32_dma_chan *chan = to_stm32_dma_chan(c);\n\tstruct stm32_dma_device *dmadev = stm32_dma_get_dev(chan);\n\tunsigned long flags;\n\n\tdev_dbg(chan2dev(chan), \"Freeing channel %d\\n\", chan->id);\n\n\tif (chan->busy) {\n\t\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\t\tstm32_dma_stop(chan);\n\t\tchan->desc = NULL;\n\t\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\t}\n\n\tpm_runtime_put(dmadev->ddev.dev);\n\n\tvchan_free_chan_resources(to_virt_chan(c));\n\tstm32_dma_clear_reg(&chan->chan_reg);\n\tchan->threshold = 0;\n}\n\nstatic void stm32_dma_desc_free(struct virt_dma_desc *vdesc)\n{\n\tkfree(container_of(vdesc, struct stm32_dma_desc, vdesc));\n}\n\nstatic void stm32_dma_set_config(struct stm32_dma_chan *chan,\n\t\t\t\t struct stm32_dma_cfg *cfg)\n{\n\tstm32_dma_clear_reg(&chan->chan_reg);\n\n\tchan->chan_reg.dma_scr = cfg->stream_config & STM32_DMA_SCR_CFG_MASK;\n\tchan->chan_reg.dma_scr |= FIELD_PREP(STM32_DMA_SCR_REQ_MASK, cfg->request_line);\n\n\t \n\tchan->chan_reg.dma_scr |= STM32_DMA_SCR_TEIE | STM32_DMA_SCR_TCIE;\n\n\tchan->threshold = FIELD_GET(STM32_DMA_THRESHOLD_FTR_MASK, cfg->features);\n\tif (FIELD_GET(STM32_DMA_DIRECT_MODE_MASK, cfg->features))\n\t\tchan->threshold = STM32_DMA_FIFO_THRESHOLD_NONE;\n\tif (FIELD_GET(STM32_DMA_ALT_ACK_MODE_MASK, cfg->features))\n\t\tchan->chan_reg.dma_scr |= STM32_DMA_SCR_TRBUFF;\n\tchan->mdma_config.stream_id = FIELD_GET(STM32_DMA_MDMA_STREAM_ID_MASK, cfg->features);\n}\n\nstatic struct dma_chan *stm32_dma_of_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t\t   struct of_dma *ofdma)\n{\n\tstruct stm32_dma_device *dmadev = ofdma->of_dma_data;\n\tstruct device *dev = dmadev->ddev.dev;\n\tstruct stm32_dma_cfg cfg;\n\tstruct stm32_dma_chan *chan;\n\tstruct dma_chan *c;\n\n\tif (dma_spec->args_count < 4) {\n\t\tdev_err(dev, \"Bad number of cells\\n\");\n\t\treturn NULL;\n\t}\n\n\tcfg.channel_id = dma_spec->args[0];\n\tcfg.request_line = dma_spec->args[1];\n\tcfg.stream_config = dma_spec->args[2];\n\tcfg.features = dma_spec->args[3];\n\n\tif (cfg.channel_id >= STM32_DMA_MAX_CHANNELS ||\n\t    cfg.request_line >= STM32_DMA_MAX_REQUEST_ID) {\n\t\tdev_err(dev, \"Bad channel and/or request id\\n\");\n\t\treturn NULL;\n\t}\n\n\tchan = &dmadev->chan[cfg.channel_id];\n\n\tc = dma_get_slave_channel(&chan->vchan.chan);\n\tif (!c) {\n\t\tdev_err(dev, \"No more channels available\\n\");\n\t\treturn NULL;\n\t}\n\n\tstm32_dma_set_config(chan, &cfg);\n\n\treturn c;\n}\n\nstatic const struct of_device_id stm32_dma_of_match[] = {\n\t{ .compatible = \"st,stm32-dma\", },\n\t{   },\n};\nMODULE_DEVICE_TABLE(of, stm32_dma_of_match);\n\nstatic int stm32_dma_probe(struct platform_device *pdev)\n{\n\tstruct stm32_dma_chan *chan;\n\tstruct stm32_dma_device *dmadev;\n\tstruct dma_device *dd;\n\tconst struct of_device_id *match;\n\tstruct resource *res;\n\tstruct reset_control *rst;\n\tint i, ret;\n\n\tmatch = of_match_device(stm32_dma_of_match, &pdev->dev);\n\tif (!match) {\n\t\tdev_err(&pdev->dev, \"Error: No device match found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tdmadev = devm_kzalloc(&pdev->dev, sizeof(*dmadev), GFP_KERNEL);\n\tif (!dmadev)\n\t\treturn -ENOMEM;\n\n\tdd = &dmadev->ddev;\n\n\tdmadev->base = devm_platform_get_and_ioremap_resource(pdev, 0, &res);\n\tif (IS_ERR(dmadev->base))\n\t\treturn PTR_ERR(dmadev->base);\n\n\tdmadev->clk = devm_clk_get(&pdev->dev, NULL);\n\tif (IS_ERR(dmadev->clk))\n\t\treturn dev_err_probe(&pdev->dev, PTR_ERR(dmadev->clk), \"Can't get clock\\n\");\n\n\tret = clk_prepare_enable(dmadev->clk);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"clk_prep_enable error: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tdmadev->mem2mem = of_property_read_bool(pdev->dev.of_node,\n\t\t\t\t\t\t\"st,mem2mem\");\n\n\trst = devm_reset_control_get(&pdev->dev, NULL);\n\tif (IS_ERR(rst)) {\n\t\tret = PTR_ERR(rst);\n\t\tif (ret == -EPROBE_DEFER)\n\t\t\tgoto clk_free;\n\t} else {\n\t\treset_control_assert(rst);\n\t\tudelay(2);\n\t\treset_control_deassert(rst);\n\t}\n\n\tdma_set_max_seg_size(&pdev->dev, STM32_DMA_ALIGNED_MAX_DATA_ITEMS);\n\n\tdma_cap_set(DMA_SLAVE, dd->cap_mask);\n\tdma_cap_set(DMA_PRIVATE, dd->cap_mask);\n\tdma_cap_set(DMA_CYCLIC, dd->cap_mask);\n\tdd->device_alloc_chan_resources = stm32_dma_alloc_chan_resources;\n\tdd->device_free_chan_resources = stm32_dma_free_chan_resources;\n\tdd->device_tx_status = stm32_dma_tx_status;\n\tdd->device_issue_pending = stm32_dma_issue_pending;\n\tdd->device_prep_slave_sg = stm32_dma_prep_slave_sg;\n\tdd->device_prep_dma_cyclic = stm32_dma_prep_dma_cyclic;\n\tdd->device_config = stm32_dma_slave_config;\n\tdd->device_pause = stm32_dma_pause;\n\tdd->device_resume = stm32_dma_resume;\n\tdd->device_terminate_all = stm32_dma_terminate_all;\n\tdd->device_synchronize = stm32_dma_synchronize;\n\tdd->src_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\n\tdd->dst_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\n\t\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\n\tdd->directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\n\tdd->residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\tdd->copy_align = DMAENGINE_ALIGN_32_BYTES;\n\tdd->max_burst = STM32_DMA_MAX_BURST;\n\tdd->max_sg_burst = STM32_DMA_ALIGNED_MAX_DATA_ITEMS;\n\tdd->descriptor_reuse = true;\n\tdd->dev = &pdev->dev;\n\tINIT_LIST_HEAD(&dd->channels);\n\n\tif (dmadev->mem2mem) {\n\t\tdma_cap_set(DMA_MEMCPY, dd->cap_mask);\n\t\tdd->device_prep_dma_memcpy = stm32_dma_prep_dma_memcpy;\n\t\tdd->directions |= BIT(DMA_MEM_TO_MEM);\n\t}\n\n\tfor (i = 0; i < STM32_DMA_MAX_CHANNELS; i++) {\n\t\tchan = &dmadev->chan[i];\n\t\tchan->id = i;\n\t\tchan->vchan.desc_free = stm32_dma_desc_free;\n\t\tvchan_init(&chan->vchan, dd);\n\n\t\tchan->mdma_config.ifcr = res->start;\n\t\tchan->mdma_config.ifcr += STM32_DMA_IFCR(chan->id);\n\n\t\tchan->mdma_config.tcf = STM32_DMA_TCI;\n\t\tchan->mdma_config.tcf <<= STM32_DMA_FLAGS_SHIFT(chan->id);\n\t}\n\n\tret = dma_async_device_register(dd);\n\tif (ret)\n\t\tgoto clk_free;\n\n\tfor (i = 0; i < STM32_DMA_MAX_CHANNELS; i++) {\n\t\tchan = &dmadev->chan[i];\n\t\tret = platform_get_irq(pdev, i);\n\t\tif (ret < 0)\n\t\t\tgoto err_unregister;\n\t\tchan->irq = ret;\n\n\t\tret = devm_request_irq(&pdev->dev, chan->irq,\n\t\t\t\t       stm32_dma_chan_irq, 0,\n\t\t\t\t       dev_name(chan2dev(chan)), chan);\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"request_irq failed with err %d channel %d\\n\",\n\t\t\t\tret, i);\n\t\t\tgoto err_unregister;\n\t\t}\n\t}\n\n\tret = of_dma_controller_register(pdev->dev.of_node,\n\t\t\t\t\t stm32_dma_of_xlate, dmadev);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"STM32 DMA DMA OF registration failed %d\\n\", ret);\n\t\tgoto err_unregister;\n\t}\n\n\tplatform_set_drvdata(pdev, dmadev);\n\n\tpm_runtime_set_active(&pdev->dev);\n\tpm_runtime_enable(&pdev->dev);\n\tpm_runtime_get_noresume(&pdev->dev);\n\tpm_runtime_put(&pdev->dev);\n\n\tdev_info(&pdev->dev, \"STM32 DMA driver registered\\n\");\n\n\treturn 0;\n\nerr_unregister:\n\tdma_async_device_unregister(dd);\nclk_free:\n\tclk_disable_unprepare(dmadev->clk);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_PM\nstatic int stm32_dma_runtime_suspend(struct device *dev)\n{\n\tstruct stm32_dma_device *dmadev = dev_get_drvdata(dev);\n\n\tclk_disable_unprepare(dmadev->clk);\n\n\treturn 0;\n}\n\nstatic int stm32_dma_runtime_resume(struct device *dev)\n{\n\tstruct stm32_dma_device *dmadev = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = clk_prepare_enable(dmadev->clk);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to prepare_enable clock\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n#endif\n\n#ifdef CONFIG_PM_SLEEP\nstatic int stm32_dma_pm_suspend(struct device *dev)\n{\n\tstruct stm32_dma_device *dmadev = dev_get_drvdata(dev);\n\tint id, ret, scr;\n\n\tret = pm_runtime_resume_and_get(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tfor (id = 0; id < STM32_DMA_MAX_CHANNELS; id++) {\n\t\tscr = stm32_dma_read(dmadev, STM32_DMA_SCR(id));\n\t\tif (scr & STM32_DMA_SCR_EN) {\n\t\t\tdev_warn(dev, \"Suspend is prevented by Chan %i\\n\", id);\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\tpm_runtime_put_sync(dev);\n\n\tpm_runtime_force_suspend(dev);\n\n\treturn 0;\n}\n\nstatic int stm32_dma_pm_resume(struct device *dev)\n{\n\treturn pm_runtime_force_resume(dev);\n}\n#endif\n\nstatic const struct dev_pm_ops stm32_dma_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(stm32_dma_pm_suspend, stm32_dma_pm_resume)\n\tSET_RUNTIME_PM_OPS(stm32_dma_runtime_suspend,\n\t\t\t   stm32_dma_runtime_resume, NULL)\n};\n\nstatic struct platform_driver stm32_dma_driver = {\n\t.driver = {\n\t\t.name = \"stm32-dma\",\n\t\t.of_match_table = stm32_dma_of_match,\n\t\t.pm = &stm32_dma_pm_ops,\n\t},\n\t.probe = stm32_dma_probe,\n};\n\nstatic int __init stm32_dma_init(void)\n{\n\treturn platform_driver_register(&stm32_dma_driver);\n}\nsubsys_initcall(stm32_dma_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}