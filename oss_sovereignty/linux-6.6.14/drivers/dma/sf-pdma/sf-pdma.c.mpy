{
  "module_name": "sf-pdma.c",
  "hash_id": "81619ad107c9d0175121ab172616633307b859fa02f6916e670761b3ab139507",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/sf-pdma/sf-pdma.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include <linux/device.h>\n#include <linux/kernel.h>\n#include <linux/platform_device.h>\n#include <linux/mod_devicetable.h>\n#include <linux/dma-mapping.h>\n#include <linux/of.h>\n#include <linux/slab.h>\n\n#include \"sf-pdma.h\"\n\n#ifndef readq\nstatic inline unsigned long long readq(void __iomem *addr)\n{\n\treturn readl(addr) | (((unsigned long long)readl(addr + 4)) << 32LL);\n}\n#endif\n\n#ifndef writeq\nstatic inline void writeq(unsigned long long v, void __iomem *addr)\n{\n\twritel(lower_32_bits(v), addr);\n\twritel(upper_32_bits(v), addr + 4);\n}\n#endif\n\nstatic inline struct sf_pdma_chan *to_sf_pdma_chan(struct dma_chan *dchan)\n{\n\treturn container_of(dchan, struct sf_pdma_chan, vchan.chan);\n}\n\nstatic inline struct sf_pdma_desc *to_sf_pdma_desc(struct virt_dma_desc *vd)\n{\n\treturn container_of(vd, struct sf_pdma_desc, vdesc);\n}\n\nstatic struct sf_pdma_desc *sf_pdma_alloc_desc(struct sf_pdma_chan *chan)\n{\n\tstruct sf_pdma_desc *desc;\n\n\tdesc = kzalloc(sizeof(*desc), GFP_NOWAIT);\n\tif (!desc)\n\t\treturn NULL;\n\n\tdesc->chan = chan;\n\n\treturn desc;\n}\n\nstatic void sf_pdma_fill_desc(struct sf_pdma_desc *desc,\n\t\t\t      u64 dst, u64 src, u64 size)\n{\n\tdesc->xfer_type = PDMA_FULL_SPEED;\n\tdesc->xfer_size = size;\n\tdesc->dst_addr = dst;\n\tdesc->src_addr = src;\n}\n\nstatic void sf_pdma_disclaim_chan(struct sf_pdma_chan *chan)\n{\n\tstruct pdma_regs *regs = &chan->regs;\n\n\twritel(PDMA_CLEAR_CTRL, regs->ctrl);\n}\n\nstatic struct dma_async_tx_descriptor *\nsf_pdma_prep_dma_memcpy(struct dma_chan *dchan,\tdma_addr_t dest, dma_addr_t src,\n\t\t\tsize_t len, unsigned long flags)\n{\n\tstruct sf_pdma_chan *chan = to_sf_pdma_chan(dchan);\n\tstruct sf_pdma_desc *desc;\n\tunsigned long iflags;\n\n\tif (chan && (!len || !dest || !src)) {\n\t\tdev_err(chan->pdma->dma_dev.dev,\n\t\t\t\"Please check dma len, dest, src!\\n\");\n\t\treturn NULL;\n\t}\n\n\tdesc = sf_pdma_alloc_desc(chan);\n\tif (!desc)\n\t\treturn NULL;\n\n\tdesc->dirn = DMA_MEM_TO_MEM;\n\tdesc->async_tx = vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\n\n\tspin_lock_irqsave(&chan->vchan.lock, iflags);\n\tsf_pdma_fill_desc(desc, dest, src, len);\n\tspin_unlock_irqrestore(&chan->vchan.lock, iflags);\n\n\treturn desc->async_tx;\n}\n\nstatic int sf_pdma_slave_config(struct dma_chan *dchan,\n\t\t\t\tstruct dma_slave_config *cfg)\n{\n\tstruct sf_pdma_chan *chan = to_sf_pdma_chan(dchan);\n\n\tmemcpy(&chan->cfg, cfg, sizeof(*cfg));\n\n\treturn 0;\n}\n\nstatic int sf_pdma_alloc_chan_resources(struct dma_chan *dchan)\n{\n\tstruct sf_pdma_chan *chan = to_sf_pdma_chan(dchan);\n\tstruct pdma_regs *regs = &chan->regs;\n\n\tdma_cookie_init(dchan);\n\twritel(PDMA_CLAIM_MASK, regs->ctrl);\n\n\treturn 0;\n}\n\nstatic void sf_pdma_disable_request(struct sf_pdma_chan *chan)\n{\n\tstruct pdma_regs *regs = &chan->regs;\n\n\twritel(readl(regs->ctrl) & ~PDMA_RUN_MASK, regs->ctrl);\n}\n\nstatic void sf_pdma_free_chan_resources(struct dma_chan *dchan)\n{\n\tstruct sf_pdma_chan *chan = to_sf_pdma_chan(dchan);\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\tsf_pdma_disable_request(chan);\n\tkfree(chan->desc);\n\tchan->desc = NULL;\n\tvchan_get_all_descriptors(&chan->vchan, &head);\n\tsf_pdma_disclaim_chan(chan);\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\tvchan_dma_desc_free_list(&chan->vchan, &head);\n}\n\nstatic size_t sf_pdma_desc_residue(struct sf_pdma_chan *chan,\n\t\t\t\t   dma_cookie_t cookie)\n{\n\tstruct virt_dma_desc *vd = NULL;\n\tstruct pdma_regs *regs = &chan->regs;\n\tunsigned long flags;\n\tu64 residue = 0;\n\tstruct sf_pdma_desc *desc;\n\tstruct dma_async_tx_descriptor *tx = NULL;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\n\tlist_for_each_entry(vd, &chan->vchan.desc_submitted, node)\n\t\tif (vd->tx.cookie == cookie)\n\t\t\ttx = &vd->tx;\n\n\tif (!tx)\n\t\tgoto out;\n\n\tif (cookie == tx->chan->completed_cookie)\n\t\tgoto out;\n\n\tif (cookie == tx->cookie) {\n\t\tresidue = readq(regs->residue);\n\t} else {\n\t\tvd = vchan_find_desc(&chan->vchan, cookie);\n\t\tif (!vd)\n\t\t\tgoto out;\n\n\t\tdesc = to_sf_pdma_desc(vd);\n\t\tresidue = desc->xfer_size;\n\t}\n\nout:\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\treturn residue;\n}\n\nstatic enum dma_status\nsf_pdma_tx_status(struct dma_chan *dchan,\n\t\t  dma_cookie_t cookie,\n\t\t  struct dma_tx_state *txstate)\n{\n\tstruct sf_pdma_chan *chan = to_sf_pdma_chan(dchan);\n\tenum dma_status status;\n\n\tstatus = dma_cookie_status(dchan, cookie, txstate);\n\n\tif (txstate && status != DMA_ERROR)\n\t\tdma_set_residue(txstate, sf_pdma_desc_residue(chan, cookie));\n\n\treturn status;\n}\n\nstatic int sf_pdma_terminate_all(struct dma_chan *dchan)\n{\n\tstruct sf_pdma_chan *chan = to_sf_pdma_chan(dchan);\n\tunsigned long flags;\n\tLIST_HEAD(head);\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\tsf_pdma_disable_request(chan);\n\tkfree(chan->desc);\n\tchan->desc = NULL;\n\tchan->xfer_err = false;\n\tvchan_get_all_descriptors(&chan->vchan, &head);\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n\tvchan_dma_desc_free_list(&chan->vchan, &head);\n\n\treturn 0;\n}\n\nstatic void sf_pdma_enable_request(struct sf_pdma_chan *chan)\n{\n\tstruct pdma_regs *regs = &chan->regs;\n\tu32 v;\n\n\tv = PDMA_CLAIM_MASK |\n\t\tPDMA_ENABLE_DONE_INT_MASK |\n\t\tPDMA_ENABLE_ERR_INT_MASK |\n\t\tPDMA_RUN_MASK;\n\n\twritel(v, regs->ctrl);\n}\n\nstatic struct sf_pdma_desc *sf_pdma_get_first_pending_desc(struct sf_pdma_chan *chan)\n{\n\tstruct virt_dma_chan *vchan = &chan->vchan;\n\tstruct virt_dma_desc *vdesc;\n\n\tif (list_empty(&vchan->desc_issued))\n\t\treturn NULL;\n\n\tvdesc = list_first_entry(&vchan->desc_issued, struct virt_dma_desc, node);\n\n\treturn container_of(vdesc, struct sf_pdma_desc, vdesc);\n}\n\nstatic void sf_pdma_xfer_desc(struct sf_pdma_chan *chan)\n{\n\tstruct sf_pdma_desc *desc = chan->desc;\n\tstruct pdma_regs *regs = &chan->regs;\n\n\tif (!desc) {\n\t\tdev_err(chan->pdma->dma_dev.dev, \"NULL desc.\\n\");\n\t\treturn;\n\t}\n\n\twritel(desc->xfer_type, regs->xfer_type);\n\twriteq(desc->xfer_size, regs->xfer_size);\n\twriteq(desc->dst_addr, regs->dst_addr);\n\twriteq(desc->src_addr, regs->src_addr);\n\n\tchan->desc = desc;\n\tchan->status = DMA_IN_PROGRESS;\n\tsf_pdma_enable_request(chan);\n}\n\nstatic void sf_pdma_issue_pending(struct dma_chan *dchan)\n{\n\tstruct sf_pdma_chan *chan = to_sf_pdma_chan(dchan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\n\tif (!chan->desc && vchan_issue_pending(&chan->vchan)) {\n\t\t \n\t\tchan->desc = sf_pdma_get_first_pending_desc(chan);\n\t\tsf_pdma_xfer_desc(chan);\n\t}\n\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n}\n\nstatic void sf_pdma_free_desc(struct virt_dma_desc *vdesc)\n{\n\tstruct sf_pdma_desc *desc;\n\n\tdesc = to_sf_pdma_desc(vdesc);\n\tkfree(desc);\n}\n\nstatic void sf_pdma_donebh_tasklet(struct tasklet_struct *t)\n{\n\tstruct sf_pdma_chan *chan = from_tasklet(chan, t, done_tasklet);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (chan->xfer_err) {\n\t\tchan->retries = MAX_RETRY;\n\t\tchan->status = DMA_COMPLETE;\n\t\tchan->xfer_err = false;\n\t}\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\n\tspin_lock_irqsave(&chan->vchan.lock, flags);\n\tlist_del(&chan->desc->vdesc.node);\n\tvchan_cookie_complete(&chan->desc->vdesc);\n\n\tchan->desc = sf_pdma_get_first_pending_desc(chan);\n\tif (chan->desc)\n\t\tsf_pdma_xfer_desc(chan);\n\n\tspin_unlock_irqrestore(&chan->vchan.lock, flags);\n}\n\nstatic void sf_pdma_errbh_tasklet(struct tasklet_struct *t)\n{\n\tstruct sf_pdma_chan *chan = from_tasklet(chan, t, err_tasklet);\n\tstruct sf_pdma_desc *desc = chan->desc;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (chan->retries <= 0) {\n\t\t \n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\tdmaengine_desc_get_callback_invoke(desc->async_tx, NULL);\n\t} else {\n\t\t \n\t\tchan->retries--;\n\t\tchan->xfer_err = true;\n\t\tchan->status = DMA_ERROR;\n\n\t\tsf_pdma_enable_request(chan);\n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t}\n}\n\nstatic irqreturn_t sf_pdma_done_isr(int irq, void *dev_id)\n{\n\tstruct sf_pdma_chan *chan = dev_id;\n\tstruct pdma_regs *regs = &chan->regs;\n\tu64 residue;\n\n\tspin_lock(&chan->vchan.lock);\n\twritel((readl(regs->ctrl)) & ~PDMA_DONE_STATUS_MASK, regs->ctrl);\n\tresidue = readq(regs->residue);\n\n\tif (!residue) {\n\t\ttasklet_hi_schedule(&chan->done_tasklet);\n\t} else {\n\t\t \n\t\tstruct sf_pdma_desc *desc = chan->desc;\n\n\t\tdesc->src_addr += desc->xfer_size - residue;\n\t\tdesc->dst_addr += desc->xfer_size - residue;\n\t\tdesc->xfer_size = residue;\n\n\t\tsf_pdma_xfer_desc(chan);\n\t}\n\n\tspin_unlock(&chan->vchan.lock);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t sf_pdma_err_isr(int irq, void *dev_id)\n{\n\tstruct sf_pdma_chan *chan = dev_id;\n\tstruct pdma_regs *regs = &chan->regs;\n\n\tspin_lock(&chan->lock);\n\twritel((readl(regs->ctrl)) & ~PDMA_ERR_STATUS_MASK, regs->ctrl);\n\tspin_unlock(&chan->lock);\n\n\ttasklet_schedule(&chan->err_tasklet);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic int sf_pdma_irq_init(struct platform_device *pdev, struct sf_pdma *pdma)\n{\n\tint irq, r, i;\n\tstruct sf_pdma_chan *chan;\n\n\tfor (i = 0; i < pdma->n_chans; i++) {\n\t\tchan = &pdma->chans[i];\n\n\t\tirq = platform_get_irq(pdev, i * 2);\n\t\tif (irq < 0)\n\t\t\treturn -EINVAL;\n\n\t\tr = devm_request_irq(&pdev->dev, irq, sf_pdma_done_isr, 0,\n\t\t\t\t     dev_name(&pdev->dev), (void *)chan);\n\t\tif (r) {\n\t\t\tdev_err(&pdev->dev, \"Fail to attach done ISR: %d\\n\", r);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tchan->txirq = irq;\n\n\t\tirq = platform_get_irq(pdev, (i * 2) + 1);\n\t\tif (irq < 0)\n\t\t\treturn -EINVAL;\n\n\t\tr = devm_request_irq(&pdev->dev, irq, sf_pdma_err_isr, 0,\n\t\t\t\t     dev_name(&pdev->dev), (void *)chan);\n\t\tif (r) {\n\t\t\tdev_err(&pdev->dev, \"Fail to attach err ISR: %d\\n\", r);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tchan->errirq = irq;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void sf_pdma_setup_chans(struct sf_pdma *pdma)\n{\n\tint i;\n\tstruct sf_pdma_chan *chan;\n\n\tINIT_LIST_HEAD(&pdma->dma_dev.channels);\n\n\tfor (i = 0; i < pdma->n_chans; i++) {\n\t\tchan = &pdma->chans[i];\n\n\t\tchan->regs.ctrl =\n\t\t\tSF_PDMA_REG_BASE(i) + PDMA_CTRL;\n\t\tchan->regs.xfer_type =\n\t\t\tSF_PDMA_REG_BASE(i) + PDMA_XFER_TYPE;\n\t\tchan->regs.xfer_size =\n\t\t\tSF_PDMA_REG_BASE(i) + PDMA_XFER_SIZE;\n\t\tchan->regs.dst_addr =\n\t\t\tSF_PDMA_REG_BASE(i) + PDMA_DST_ADDR;\n\t\tchan->regs.src_addr =\n\t\t\tSF_PDMA_REG_BASE(i) + PDMA_SRC_ADDR;\n\t\tchan->regs.act_type =\n\t\t\tSF_PDMA_REG_BASE(i) + PDMA_ACT_TYPE;\n\t\tchan->regs.residue =\n\t\t\tSF_PDMA_REG_BASE(i) + PDMA_REMAINING_BYTE;\n\t\tchan->regs.cur_dst_addr =\n\t\t\tSF_PDMA_REG_BASE(i) + PDMA_CUR_DST_ADDR;\n\t\tchan->regs.cur_src_addr =\n\t\t\tSF_PDMA_REG_BASE(i) + PDMA_CUR_SRC_ADDR;\n\n\t\tchan->pdma = pdma;\n\t\tchan->pm_state = RUNNING;\n\t\tchan->slave_id = i;\n\t\tchan->xfer_err = false;\n\t\tspin_lock_init(&chan->lock);\n\n\t\tchan->vchan.desc_free = sf_pdma_free_desc;\n\t\tvchan_init(&chan->vchan, &pdma->dma_dev);\n\n\t\twritel(PDMA_CLEAR_CTRL, chan->regs.ctrl);\n\n\t\ttasklet_setup(&chan->done_tasklet, sf_pdma_donebh_tasklet);\n\t\ttasklet_setup(&chan->err_tasklet, sf_pdma_errbh_tasklet);\n\t}\n}\n\nstatic int sf_pdma_probe(struct platform_device *pdev)\n{\n\tstruct sf_pdma *pdma;\n\tint ret, n_chans;\n\tconst enum dma_slave_buswidth widths =\n\t\tDMA_SLAVE_BUSWIDTH_1_BYTE | DMA_SLAVE_BUSWIDTH_2_BYTES |\n\t\tDMA_SLAVE_BUSWIDTH_4_BYTES | DMA_SLAVE_BUSWIDTH_8_BYTES |\n\t\tDMA_SLAVE_BUSWIDTH_16_BYTES | DMA_SLAVE_BUSWIDTH_32_BYTES |\n\t\tDMA_SLAVE_BUSWIDTH_64_BYTES;\n\n\tret = of_property_read_u32(pdev->dev.of_node, \"dma-channels\", &n_chans);\n\tif (ret) {\n\t\t \n\t\tdev_dbg(&pdev->dev, \"set number of channels to default value: 4\\n\");\n\t\tn_chans = PDMA_MAX_NR_CH;\n\t} else if (n_chans > PDMA_MAX_NR_CH) {\n\t\tdev_err(&pdev->dev, \"the number of channels exceeds the maximum\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tpdma = devm_kzalloc(&pdev->dev, struct_size(pdma, chans, n_chans),\n\t\t\t    GFP_KERNEL);\n\tif (!pdma)\n\t\treturn -ENOMEM;\n\n\tpdma->n_chans = n_chans;\n\n\tpdma->membase = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(pdma->membase))\n\t\treturn PTR_ERR(pdma->membase);\n\n\tret = sf_pdma_irq_init(pdev, pdma);\n\tif (ret)\n\t\treturn ret;\n\n\tsf_pdma_setup_chans(pdma);\n\n\tpdma->dma_dev.dev = &pdev->dev;\n\n\t \n\tdma_cap_set(DMA_MEMCPY, pdma->dma_dev.cap_mask);\n\tpdma->dma_dev.copy_align = 2;\n\tpdma->dma_dev.src_addr_widths = widths;\n\tpdma->dma_dev.dst_addr_widths = widths;\n\tpdma->dma_dev.directions = BIT(DMA_MEM_TO_MEM);\n\tpdma->dma_dev.residue_granularity = DMA_RESIDUE_GRANULARITY_DESCRIPTOR;\n\tpdma->dma_dev.descriptor_reuse = true;\n\n\t \n\tpdma->dma_dev.device_alloc_chan_resources =\n\t\tsf_pdma_alloc_chan_resources;\n\tpdma->dma_dev.device_free_chan_resources =\n\t\tsf_pdma_free_chan_resources;\n\tpdma->dma_dev.device_tx_status = sf_pdma_tx_status;\n\tpdma->dma_dev.device_prep_dma_memcpy = sf_pdma_prep_dma_memcpy;\n\tpdma->dma_dev.device_config = sf_pdma_slave_config;\n\tpdma->dma_dev.device_terminate_all = sf_pdma_terminate_all;\n\tpdma->dma_dev.device_issue_pending = sf_pdma_issue_pending;\n\n\tplatform_set_drvdata(pdev, pdma);\n\n\tret = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (ret)\n\t\tdev_warn(&pdev->dev,\n\t\t\t \"Failed to set DMA mask. Fall back to default.\\n\");\n\n\tret = dma_async_device_register(&pdma->dma_dev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Can't register SiFive Platform DMA. (%d)\\n\", ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int sf_pdma_remove(struct platform_device *pdev)\n{\n\tstruct sf_pdma *pdma = platform_get_drvdata(pdev);\n\tstruct sf_pdma_chan *ch;\n\tint i;\n\n\tfor (i = 0; i < pdma->n_chans; i++) {\n\t\tch = &pdma->chans[i];\n\n\t\tdevm_free_irq(&pdev->dev, ch->txirq, ch);\n\t\tdevm_free_irq(&pdev->dev, ch->errirq, ch);\n\t\tlist_del(&ch->vchan.chan.device_node);\n\t\ttasklet_kill(&ch->vchan.task);\n\t\ttasklet_kill(&ch->done_tasklet);\n\t\ttasklet_kill(&ch->err_tasklet);\n\t}\n\n\tdma_async_device_unregister(&pdma->dma_dev);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id sf_pdma_dt_ids[] = {\n\t{ .compatible = \"sifive,fu540-c000-pdma\" },\n\t{ .compatible = \"sifive,pdma0\" },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, sf_pdma_dt_ids);\n\nstatic struct platform_driver sf_pdma_driver = {\n\t.probe\t\t= sf_pdma_probe,\n\t.remove\t\t= sf_pdma_remove,\n\t.driver\t\t= {\n\t\t.name\t= \"sf-pdma\",\n\t\t.of_match_table = sf_pdma_dt_ids,\n\t},\n};\n\nstatic int __init sf_pdma_init(void)\n{\n\treturn platform_driver_register(&sf_pdma_driver);\n}\n\nstatic void __exit sf_pdma_exit(void)\n{\n\tplatform_driver_unregister(&sf_pdma_driver);\n}\n\n \nsubsys_initcall(sf_pdma_init);\nmodule_exit(sf_pdma_exit);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"SiFive Platform DMA driver\");\nMODULE_AUTHOR(\"Green Wan <green.wan@sifive.com>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}