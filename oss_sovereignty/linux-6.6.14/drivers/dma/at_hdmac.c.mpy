{
  "module_name": "at_hdmac.c",
  "hash_id": "31b124118877b79d97e3c0da865cf00c61114896065d037f862dc0a15c27eb88",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma/at_hdmac.c",
  "human_readable_source": "\n \n\n#include <dt-bindings/dma/at91.h>\n#include <linux/bitfield.h>\n#include <linux/clk.h>\n#include <linux/dmaengine.h>\n#include <linux/dmapool.h>\n#include <linux/dma-mapping.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/overflow.h>\n#include <linux/of_platform.h>\n#include <linux/of_dma.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n\n#include \"dmaengine.h\"\n#include \"virt-dma.h\"\n\n \n\n#define\tAT_DMA_MAX_NR_CHANNELS\t8\n\n \n#define AT_DMA_GCFG\t\t0x00\n#define AT_DMA_IF_BIGEND(i)\tBIT((i))\t \n#define AT_DMA_ARB_CFG\t\tBIT(4)\t\t \n\n \n#define AT_DMA_EN\t\t0x04\n#define AT_DMA_ENABLE\t\tBIT(0)\n\n \n#define AT_DMA_SREQ\t\t0x08\n#define AT_DMA_SSREQ(x)\t\tBIT((x) << 1)\t\t \n#define AT_DMA_DSREQ(x)\t\tBIT(1 + ((x) << 1))\t \n\n \n#define AT_DMA_CREQ\t\t0x0c\n#define AT_DMA_SCREQ(x)\t\tBIT((x) << 1)\t\t \n#define AT_DMA_DCREQ(x)\t\tBIT(1 + ((x) << 1))\t \n\n \n#define AT_DMA_LAST\t\t0x10\n#define AT_DMA_SLAST(x)\t\tBIT((x) << 1)\t\t \n#define AT_DMA_DLAST(x)\t\tBIT(1 + ((x) << 1))\t \n\n \n#define AT_DMA_SYNC\t\t0x14\n#define AT_DMA_SYR(h)\t\tBIT((h))\t\t \n\n \n#define AT_DMA_EBCIER\t\t0x18\t\t\t \n#define AT_DMA_EBCIDR\t\t0x1c\t\t\t \n#define AT_DMA_EBCIMR\t\t0x20\t\t\t \n#define AT_DMA_EBCISR\t\t0x24\t\t\t \n#define AT_DMA_CBTC_OFFSET\t8\n#define AT_DMA_ERR_OFFSET\t16\n#define AT_DMA_BTC(x)\t\tBIT((x))\n#define AT_DMA_CBTC(x)\t\tBIT(AT_DMA_CBTC_OFFSET + (x))\n#define AT_DMA_ERR(x)\t\tBIT(AT_DMA_ERR_OFFSET + (x))\n\n \n#define AT_DMA_CHER\t\t0x28\n#define AT_DMA_ENA(x)\t\tBIT((x))\n#define AT_DMA_SUSP(x)\t\tBIT(8 + (x))\n#define AT_DMA_KEEP(x)\t\tBIT(24 + (x))\n\n \n#define AT_DMA_CHDR\t\t0x2c\n#define AT_DMA_DIS(x)\t\tBIT(x)\n#define AT_DMA_RES(x)\t\tBIT(8 + (x))\n\n \n#define AT_DMA_CHSR\t\t0x30\n#define AT_DMA_EMPT(x)\t\tBIT(16 + (x))\n#define AT_DMA_STAL(x)\t\tBIT(24 + (x))\n\n \n#define AT_DMA_CH_REGS_BASE\t0x3c\n#define ch_regs(x)\t\t(AT_DMA_CH_REGS_BASE + (x) * 0x28)  \n\n \n#define ATC_SADDR_OFFSET\t0x00\t \n#define ATC_DADDR_OFFSET\t0x04\t \n#define ATC_DSCR_OFFSET\t\t0x08\t \n#define ATC_CTRLA_OFFSET\t0x0c\t \n#define ATC_CTRLB_OFFSET\t0x10\t \n#define ATC_CFG_OFFSET\t\t0x14\t \n#define ATC_SPIP_OFFSET\t\t0x18\t \n#define ATC_DPIP_OFFSET\t\t0x1c\t \n\n\n \n\n \n#define ATC_DSCR_IF\t\tGENMASK(1, 0)\t \n\n \n#define ATC_BTSIZE_MAX\t\tGENMASK(15, 0)\t \n#define ATC_BTSIZE\t\tGENMASK(15, 0)\t \n#define ATC_SCSIZE\t\tGENMASK(18, 16)\t \n#define ATC_DCSIZE\t\tGENMASK(22, 20)\t \n#define ATC_SRC_WIDTH\t\tGENMASK(25, 24)\t \n#define ATC_DST_WIDTH\t\tGENMASK(29, 28)\t \n#define ATC_DONE\t\tBIT(31)\t \n\n \n#define ATC_SIF\t\t\tGENMASK(1, 0)\t \n#define ATC_DIF\t\t\tGENMASK(5, 4)\t \n#define AT_DMA_MEM_IF\t\t0x0\t\t \n#define AT_DMA_PER_IF\t\t0x1\t\t \n#define ATC_SRC_PIP\t\tBIT(8)\t\t \n#define ATC_DST_PIP\t\tBIT(12)\t\t \n#define ATC_SRC_DSCR_DIS\tBIT(16)\t\t \n#define ATC_DST_DSCR_DIS\tBIT(20)\t\t \n#define ATC_FC\t\t\tGENMASK(23, 21)\t \n#define ATC_FC_MEM2MEM\t\t0x0\t\t \n#define ATC_FC_MEM2PER\t\t0x1\t\t \n#define ATC_FC_PER2MEM\t\t0x2\t\t \n#define ATC_FC_PER2PER\t\t0x3\t\t \n#define ATC_FC_PER2MEM_PER\t0x4\t\t \n#define ATC_FC_MEM2PER_PER\t0x5\t\t \n#define ATC_FC_PER2PER_SRCPER\t0x6\t\t \n#define ATC_FC_PER2PER_DSTPER\t0x7\t\t \n#define ATC_SRC_ADDR_MODE\tGENMASK(25, 24)\n#define ATC_SRC_ADDR_MODE_INCR\t0x0\t\t \n#define ATC_SRC_ADDR_MODE_DECR\t0x1\t\t \n#define ATC_SRC_ADDR_MODE_FIXED\t0x2\t\t \n#define ATC_DST_ADDR_MODE\tGENMASK(29, 28)\n#define ATC_DST_ADDR_MODE_INCR\t0x0\t\t \n#define ATC_DST_ADDR_MODE_DECR\t0x1\t\t \n#define ATC_DST_ADDR_MODE_FIXED\t0x2\t\t \n#define ATC_IEN\t\t\tBIT(30)\t\t \n#define ATC_AUTO\t\tBIT(31)\t\t \n\n \n#define ATC_SRC_PER\t\tGENMASK(3, 0)\t \n#define ATC_DST_PER\t\tGENMASK(7, 4)\t \n#define ATC_SRC_REP\t\tBIT(8)\t\t \n#define ATC_SRC_H2SEL\t\tBIT(9)\t\t \n#define ATC_SRC_PER_MSB\t\tGENMASK(11, 10)\t \n#define ATC_DST_REP\t\tBIT(12)\t\t \n#define ATC_DST_H2SEL\t\tBIT(13)\t\t \n#define ATC_DST_PER_MSB\t\tGENMASK(15, 14)\t \n#define ATC_SOD\t\t\tBIT(16)\t\t \n#define ATC_LOCK_IF\t\tBIT(20)\t\t \n#define ATC_LOCK_B\t\tBIT(21)\t\t \n#define ATC_LOCK_IF_L\t\tBIT(22)\t\t \n#define ATC_AHB_PROT\t\tGENMASK(26, 24)\t \n#define ATC_FIFOCFG\t\tGENMASK(29, 28)\t \n#define ATC_FIFOCFG_LARGESTBURST\t0x0\n#define ATC_FIFOCFG_HALFFIFO\t\t0x1\n#define ATC_FIFOCFG_ENOUGHSPACE\t\t0x2\n\n \n#define ATC_SPIP_HOLE\t\tGENMASK(15, 0)\n#define ATC_SPIP_BOUNDARY\tGENMASK(25, 16)\n\n \n#define ATC_DPIP_HOLE\t\tGENMASK(15, 0)\n#define ATC_DPIP_BOUNDARY\tGENMASK(25, 16)\n\n#define ATC_PER_MSB\t\tGENMASK(5, 4)\t \n#define ATC_SRC_PER_ID(id)\t\t\t\t\t       \\\n\t({ typeof(id) _id = (id);\t\t\t\t       \\\n\t   FIELD_PREP(ATC_SRC_PER_MSB, FIELD_GET(ATC_PER_MSB, _id)) |  \\\n\t   FIELD_PREP(ATC_SRC_PER, _id); })\n#define ATC_DST_PER_ID(id)\t\t\t\t\t       \\\n\t({ typeof(id) _id = (id);\t\t\t\t       \\\n\t   FIELD_PREP(ATC_DST_PER_MSB, FIELD_GET(ATC_PER_MSB, _id)) |  \\\n\t   FIELD_PREP(ATC_DST_PER, _id); })\n\n\n\n \n\n \nstruct at_lli {\n\t \n\tu32 saddr;\n\tu32 daddr;\n\t \n\tu32 ctrla;\n\t \n\tu32 ctrlb;\n\tu32 dscr;\t \n};\n\n \nstruct atdma_sg {\n\tunsigned int len;\n\tstruct at_lli *lli;\n\tdma_addr_t lli_phys;\n};\n\n \nstruct at_desc {\n\tstruct\t\t\t\tvirt_dma_desc vd;\n\tstruct\t\t\t\tat_dma_chan *atchan;\n\tsize_t\t\t\t\ttotal_len;\n\tunsigned int\t\t\tsglen;\n\t \n\tsize_t\t\t\t\tboundary;\n\tsize_t\t\t\t\tdst_hole;\n\tsize_t\t\t\t\tsrc_hole;\n\n\t \n\tbool\t\t\t\tmemset_buffer;\n\tdma_addr_t\t\t\tmemset_paddr;\n\tint\t\t\t\t*memset_vaddr;\n\tstruct atdma_sg\t\t\tsg[];\n};\n\n \n\n \nenum atc_status {\n\tATC_IS_PAUSED = 1,\n\tATC_IS_CYCLIC = 24,\n};\n\n \nstruct at_dma_chan {\n\tstruct virt_dma_chan\tvc;\n\tstruct at_dma\t\t*atdma;\n\tvoid __iomem\t\t*ch_regs;\n\tu8\t\t\tmask;\n\tu8\t\t\tper_if;\n\tu8\t\t\tmem_if;\n\tunsigned long\t\tstatus;\n\tu32\t\t\tsave_cfg;\n\tu32\t\t\tsave_dscr;\n\tstruct dma_slave_config\tdma_sconfig;\n\tbool\t\t\tcyclic;\n\tstruct at_desc\t\t*desc;\n};\n\n#define\tchannel_readl(atchan, name) \\\n\t__raw_readl((atchan)->ch_regs + ATC_##name##_OFFSET)\n\n#define\tchannel_writel(atchan, name, val) \\\n\t__raw_writel((val), (atchan)->ch_regs + ATC_##name##_OFFSET)\n\n \nstatic inline void convert_burst(u32 *maxburst)\n{\n\tif (*maxburst > 1)\n\t\t*maxburst = fls(*maxburst) - 2;\n\telse\n\t\t*maxburst = 0;\n}\n\n \nstatic inline u8 convert_buswidth(enum dma_slave_buswidth addr_width)\n{\n\tswitch (addr_width) {\n\tcase DMA_SLAVE_BUSWIDTH_2_BYTES:\n\t\treturn 1;\n\tcase DMA_SLAVE_BUSWIDTH_4_BYTES:\n\t\treturn 2;\n\tdefault:\n\t\t \n\t\treturn 0;\n\t}\n}\n\n \n\n \nstruct at_dma {\n\tstruct dma_device\tdma_device;\n\tvoid __iomem\t\t*regs;\n\tstruct clk\t\t*clk;\n\tu32\t\t\tsave_imr;\n\n\tu8\t\t\tall_chan_mask;\n\n\tstruct dma_pool\t\t*lli_pool;\n\tstruct dma_pool\t\t*memset_pool;\n\t \n\tstruct at_dma_chan\tchan[];\n};\n\n#define\tdma_readl(atdma, name) \\\n\t__raw_readl((atdma)->regs + AT_DMA_##name)\n#define\tdma_writel(atdma, name, val) \\\n\t__raw_writel((val), (atdma)->regs + AT_DMA_##name)\n\nstatic inline struct at_desc *to_atdma_desc(struct dma_async_tx_descriptor *t)\n{\n\treturn container_of(t, struct at_desc, vd.tx);\n}\n\nstatic inline struct at_dma_chan *to_at_dma_chan(struct dma_chan *chan)\n{\n\treturn container_of(chan, struct at_dma_chan, vc.chan);\n}\n\nstatic inline struct at_dma *to_at_dma(struct dma_device *ddev)\n{\n\treturn container_of(ddev, struct at_dma, dma_device);\n}\n\n\n \n\nstatic struct device *chan2dev(struct dma_chan *chan)\n{\n\treturn &chan->dev->device;\n}\n\n#if defined(VERBOSE_DEBUG)\nstatic void vdbg_dump_regs(struct at_dma_chan *atchan)\n{\n\tstruct at_dma\t*atdma = to_at_dma(atchan->vc.chan.device);\n\n\tdev_err(chan2dev(&atchan->vc.chan),\n\t\t\"  channel %d : imr = 0x%x, chsr = 0x%x\\n\",\n\t\tatchan->vc.chan.chan_id,\n\t\tdma_readl(atdma, EBCIMR),\n\t\tdma_readl(atdma, CHSR));\n\n\tdev_err(chan2dev(&atchan->vc.chan),\n\t\t\"  channel: s0x%x d0x%x ctrl0x%x:0x%x cfg0x%x l0x%x\\n\",\n\t\tchannel_readl(atchan, SADDR),\n\t\tchannel_readl(atchan, DADDR),\n\t\tchannel_readl(atchan, CTRLA),\n\t\tchannel_readl(atchan, CTRLB),\n\t\tchannel_readl(atchan, CFG),\n\t\tchannel_readl(atchan, DSCR));\n}\n#else\nstatic void vdbg_dump_regs(struct at_dma_chan *atchan) {}\n#endif\n\nstatic void atc_dump_lli(struct at_dma_chan *atchan, struct at_lli *lli)\n{\n\tdev_crit(chan2dev(&atchan->vc.chan),\n\t\t \"desc: s%pad d%pad ctrl0x%x:0x%x l%pad\\n\",\n\t\t &lli->saddr, &lli->daddr,\n\t\t lli->ctrla, lli->ctrlb, &lli->dscr);\n}\n\n\nstatic void atc_setup_irq(struct at_dma *atdma, int chan_id, int on)\n{\n\tu32 ebci;\n\n\t \n\tebci =    AT_DMA_BTC(chan_id)\n\t\t| AT_DMA_ERR(chan_id);\n\tif (on)\n\t\tdma_writel(atdma, EBCIER, ebci);\n\telse\n\t\tdma_writel(atdma, EBCIDR, ebci);\n}\n\nstatic void atc_enable_chan_irq(struct at_dma *atdma, int chan_id)\n{\n\tatc_setup_irq(atdma, chan_id, 1);\n}\n\nstatic void atc_disable_chan_irq(struct at_dma *atdma, int chan_id)\n{\n\tatc_setup_irq(atdma, chan_id, 0);\n}\n\n\n \nstatic inline int atc_chan_is_enabled(struct at_dma_chan *atchan)\n{\n\tstruct at_dma *atdma = to_at_dma(atchan->vc.chan.device);\n\n\treturn !!(dma_readl(atdma, CHSR) & atchan->mask);\n}\n\n \nstatic inline int atc_chan_is_paused(struct at_dma_chan *atchan)\n{\n\treturn test_bit(ATC_IS_PAUSED, &atchan->status);\n}\n\n \nstatic inline int atc_chan_is_cyclic(struct at_dma_chan *atchan)\n{\n\treturn test_bit(ATC_IS_CYCLIC, &atchan->status);\n}\n\n \nstatic void set_lli_eol(struct at_desc *desc, unsigned int i)\n{\n\tu32 ctrlb = desc->sg[i].lli->ctrlb;\n\n\tctrlb &= ~ATC_IEN;\n\tctrlb |= ATC_SRC_DSCR_DIS | ATC_DST_DSCR_DIS;\n\n\tdesc->sg[i].lli->ctrlb = ctrlb;\n\tdesc->sg[i].lli->dscr = 0;\n}\n\n#define\tATC_DEFAULT_CFG\t\tFIELD_PREP(ATC_FIFOCFG, ATC_FIFOCFG_HALFFIFO)\n#define\tATC_DEFAULT_CTRLB\t(FIELD_PREP(ATC_SIF, AT_DMA_MEM_IF) | \\\n\t\t\t\t FIELD_PREP(ATC_DIF, AT_DMA_MEM_IF))\n#define ATC_DMA_BUSWIDTHS\\\n\t(BIT(DMA_SLAVE_BUSWIDTH_UNDEFINED) |\\\n\tBIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\\\n\tBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\\\n\tBIT(DMA_SLAVE_BUSWIDTH_4_BYTES))\n\n#define ATC_MAX_DSCR_TRIALS\t10\n\n \nstatic unsigned int init_nr_desc_per_channel = 64;\nmodule_param(init_nr_desc_per_channel, uint, 0644);\nMODULE_PARM_DESC(init_nr_desc_per_channel,\n\t\t \"initial descriptors per channel (default: 64)\");\n\n \nstruct at_dma_platform_data {\n\tunsigned int\tnr_channels;\n\tdma_cap_mask_t  cap_mask;\n};\n\n \nstruct at_dma_slave {\n\tstruct device\t\t*dma_dev;\n\tu32\t\t\tcfg;\n};\n\nstatic inline unsigned int atc_get_xfer_width(dma_addr_t src, dma_addr_t dst,\n\t\t\t\t\t\tsize_t len)\n{\n\tunsigned int width;\n\n\tif (!((src | dst  | len) & 3))\n\t\twidth = 2;\n\telse if (!((src | dst | len) & 1))\n\t\twidth = 1;\n\telse\n\t\twidth = 0;\n\n\treturn width;\n}\n\nstatic void atdma_lli_chain(struct at_desc *desc, unsigned int i)\n{\n\tstruct atdma_sg *atdma_sg = &desc->sg[i];\n\n\tif (i)\n\t\tdesc->sg[i - 1].lli->dscr = atdma_sg->lli_phys;\n}\n\n \nstatic void atc_dostart(struct at_dma_chan *atchan)\n{\n\tstruct virt_dma_desc *vd = vchan_next_desc(&atchan->vc);\n\tstruct at_desc *desc;\n\n\tif (!vd) {\n\t\tatchan->desc = NULL;\n\t\treturn;\n\t}\n\n\tvdbg_dump_regs(atchan);\n\n\tlist_del(&vd->node);\n\tatchan->desc = desc = to_atdma_desc(&vd->tx);\n\n\tchannel_writel(atchan, SADDR, 0);\n\tchannel_writel(atchan, DADDR, 0);\n\tchannel_writel(atchan, CTRLA, 0);\n\tchannel_writel(atchan, CTRLB, 0);\n\tchannel_writel(atchan, DSCR, desc->sg[0].lli_phys);\n\tchannel_writel(atchan, SPIP,\n\t\t       FIELD_PREP(ATC_SPIP_HOLE, desc->src_hole) |\n\t\t       FIELD_PREP(ATC_SPIP_BOUNDARY, desc->boundary));\n\tchannel_writel(atchan, DPIP,\n\t\t       FIELD_PREP(ATC_DPIP_HOLE, desc->dst_hole) |\n\t\t       FIELD_PREP(ATC_DPIP_BOUNDARY, desc->boundary));\n\n\t \n\twmb();\n\tdma_writel(atchan->atdma, CHER, atchan->mask);\n\n\tvdbg_dump_regs(atchan);\n}\n\nstatic void atdma_desc_free(struct virt_dma_desc *vd)\n{\n\tstruct at_dma *atdma = to_at_dma(vd->tx.chan->device);\n\tstruct at_desc *desc = to_atdma_desc(&vd->tx);\n\tunsigned int i;\n\n\tfor (i = 0; i < desc->sglen; i++) {\n\t\tif (desc->sg[i].lli)\n\t\t\tdma_pool_free(atdma->lli_pool, desc->sg[i].lli,\n\t\t\t\t      desc->sg[i].lli_phys);\n\t}\n\n\t \n\tif (desc->memset_buffer) {\n\t\tdma_pool_free(atdma->memset_pool, desc->memset_vaddr,\n\t\t\t      desc->memset_paddr);\n\t\tdesc->memset_buffer = false;\n\t}\n\n\tkfree(desc);\n}\n\n \nstatic inline u32 atc_calc_bytes_left(u32 current_len, u32 ctrla)\n{\n\tu32 btsize = FIELD_GET(ATC_BTSIZE, ctrla);\n\tu32 src_width = FIELD_GET(ATC_SRC_WIDTH, ctrla);\n\n\t \n\treturn current_len - (btsize << src_width);\n}\n\n \nstatic int atc_get_llis_residue(struct at_dma_chan *atchan,\n\t\t\t\tstruct at_desc *desc, u32 *residue)\n{\n\tu32 len, ctrla, dscr;\n\tunsigned int i;\n\n\tlen = desc->total_len;\n\tdscr = channel_readl(atchan, DSCR);\n\trmb();  \n\tctrla = channel_readl(atchan, CTRLA);\n\tfor (i = 0; i < ATC_MAX_DSCR_TRIALS; ++i) {\n\t\tu32 new_dscr;\n\n\t\trmb();  \n\t\tnew_dscr = channel_readl(atchan, DSCR);\n\n\t\t \n\t\tif (likely(new_dscr == dscr))\n\t\t\tbreak;\n\n\t\t \n\t\tdscr = new_dscr;\n\t\trmb();  \n\t\tctrla = channel_readl(atchan, CTRLA);\n\t}\n\tif (unlikely(i == ATC_MAX_DSCR_TRIALS))\n\t\treturn -ETIMEDOUT;\n\n\t \n\tif (desc->sg[0].lli->dscr == dscr) {\n\t\t*residue = atc_calc_bytes_left(len, ctrla);\n\t\treturn 0;\n\t}\n\tlen -= desc->sg[0].len;\n\n\tfor (i = 1; i < desc->sglen; i++) {\n\t\tif (desc->sg[i].lli && desc->sg[i].lli->dscr == dscr)\n\t\t\tbreak;\n\t\tlen -= desc->sg[i].len;\n\t}\n\n\t \n\t*residue = atc_calc_bytes_left(len, ctrla);\n\treturn 0;\n\n}\n\n \nstatic int atc_get_residue(struct dma_chan *chan, dma_cookie_t cookie,\n\t\t\t   u32 *residue)\n{\n\tstruct at_dma_chan *atchan = to_at_dma_chan(chan);\n\tstruct virt_dma_desc *vd;\n\tstruct at_desc *desc = NULL;\n\tu32 len, ctrla;\n\n\tvd = vchan_find_desc(&atchan->vc, cookie);\n\tif (vd)\n\t\tdesc = to_atdma_desc(&vd->tx);\n\telse if (atchan->desc && atchan->desc->vd.tx.cookie == cookie)\n\t\tdesc = atchan->desc;\n\n\tif (!desc)\n\t\treturn -EINVAL;\n\n\tif (desc->sg[0].lli->dscr)\n\t\t \n\t\treturn atc_get_llis_residue(atchan, desc, residue);\n\n\t \n\tlen = desc->total_len;\n\tctrla = channel_readl(atchan, CTRLA);\n\t*residue = atc_calc_bytes_left(len, ctrla);\n\treturn 0;\n}\n\n \nstatic void atc_handle_error(struct at_dma_chan *atchan, unsigned int i)\n{\n\tstruct at_desc *desc = atchan->desc;\n\n\t \n\tdma_writel(atchan->atdma, CHDR, AT_DMA_RES(i) | atchan->mask);\n\n\t \n\tdev_crit(chan2dev(&atchan->vc.chan), \"Bad descriptor submitted for DMA!\\n\");\n\tdev_crit(chan2dev(&atchan->vc.chan), \"cookie: %d\\n\",\n\t\t desc->vd.tx.cookie);\n\tfor (i = 0; i < desc->sglen; i++)\n\t\tatc_dump_lli(atchan, desc->sg[i].lli);\n}\n\nstatic void atdma_handle_chan_done(struct at_dma_chan *atchan, u32 pending,\n\t\t\t\t   unsigned int i)\n{\n\tstruct at_desc *desc;\n\n\tspin_lock(&atchan->vc.lock);\n\tdesc = atchan->desc;\n\n\tif (desc) {\n\t\tif (pending & AT_DMA_ERR(i)) {\n\t\t\tatc_handle_error(atchan, i);\n\t\t\t \n\t\t}\n\n\t\tif (atc_chan_is_cyclic(atchan)) {\n\t\t\tvchan_cyclic_callback(&desc->vd);\n\t\t} else {\n\t\t\tvchan_cookie_complete(&desc->vd);\n\t\t\tatchan->desc = NULL;\n\t\t\tif (!(atc_chan_is_enabled(atchan)))\n\t\t\t\tatc_dostart(atchan);\n\t\t}\n\t}\n\tspin_unlock(&atchan->vc.lock);\n}\n\nstatic irqreturn_t at_dma_interrupt(int irq, void *dev_id)\n{\n\tstruct at_dma\t\t*atdma = dev_id;\n\tstruct at_dma_chan\t*atchan;\n\tint\t\t\ti;\n\tu32\t\t\tstatus, pending, imr;\n\tint\t\t\tret = IRQ_NONE;\n\n\tdo {\n\t\timr = dma_readl(atdma, EBCIMR);\n\t\tstatus = dma_readl(atdma, EBCISR);\n\t\tpending = status & imr;\n\n\t\tif (!pending)\n\t\t\tbreak;\n\n\t\tdev_vdbg(atdma->dma_device.dev,\n\t\t\t\"interrupt: status = 0x%08x, 0x%08x, 0x%08x\\n\",\n\t\t\t status, imr, pending);\n\n\t\tfor (i = 0; i < atdma->dma_device.chancnt; i++) {\n\t\t\tatchan = &atdma->chan[i];\n\t\t\tif (!(pending & (AT_DMA_BTC(i) | AT_DMA_ERR(i))))\n\t\t\t\tcontinue;\n\t\t\tatdma_handle_chan_done(atchan, pending, i);\n\t\t\tret = IRQ_HANDLED;\n\t\t}\n\n\t} while (pending);\n\n\treturn ret;\n}\n\n \n \nstatic struct dma_async_tx_descriptor *\natc_prep_dma_interleaved(struct dma_chan *chan,\n\t\t\t struct dma_interleaved_template *xt,\n\t\t\t unsigned long flags)\n{\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct data_chunk\t*first;\n\tstruct atdma_sg\t\t*atdma_sg;\n\tstruct at_desc\t\t*desc;\n\tstruct at_lli\t\t*lli;\n\tsize_t\t\t\txfer_count;\n\tunsigned int\t\tdwidth;\n\tu32\t\t\tctrla;\n\tu32\t\t\tctrlb;\n\tsize_t\t\t\tlen = 0;\n\tint\t\t\ti;\n\n\tif (unlikely(!xt || xt->numf != 1 || !xt->frame_size))\n\t\treturn NULL;\n\n\tfirst = xt->sgl;\n\n\tdev_info(chan2dev(chan),\n\t\t \"%s: src=%pad, dest=%pad, numf=%d, frame_size=%d, flags=0x%lx\\n\",\n\t\t__func__, &xt->src_start, &xt->dst_start, xt->numf,\n\t\txt->frame_size, flags);\n\n\t \n\tfor (i = 0; i < xt->frame_size; i++) {\n\t\tstruct data_chunk *chunk = xt->sgl + i;\n\n\t\tif ((chunk->size != xt->sgl->size) ||\n\t\t    (dmaengine_get_dst_icg(xt, chunk) != dmaengine_get_dst_icg(xt, first)) ||\n\t\t    (dmaengine_get_src_icg(xt, chunk) != dmaengine_get_src_icg(xt, first))) {\n\t\t\tdev_err(chan2dev(chan),\n\t\t\t\t\"%s: the controller can transfer only identical chunks\\n\",\n\t\t\t\t__func__);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tlen += chunk->size;\n\t}\n\n\tdwidth = atc_get_xfer_width(xt->src_start, xt->dst_start, len);\n\n\txfer_count = len >> dwidth;\n\tif (xfer_count > ATC_BTSIZE_MAX) {\n\t\tdev_err(chan2dev(chan), \"%s: buffer is too big\\n\", __func__);\n\t\treturn NULL;\n\t}\n\n\tctrla = FIELD_PREP(ATC_SRC_WIDTH, dwidth) |\n\t\tFIELD_PREP(ATC_DST_WIDTH, dwidth);\n\n\tctrlb = ATC_DEFAULT_CTRLB | ATC_IEN |\n\t\tFIELD_PREP(ATC_SRC_ADDR_MODE, ATC_SRC_ADDR_MODE_INCR) |\n\t\tFIELD_PREP(ATC_DST_ADDR_MODE, ATC_DST_ADDR_MODE_INCR) |\n\t\tATC_SRC_PIP | ATC_DST_PIP |\n\t\tFIELD_PREP(ATC_FC, ATC_FC_MEM2MEM);\n\n\tdesc = kzalloc(struct_size(desc, sg, 1), GFP_ATOMIC);\n\tif (!desc)\n\t\treturn NULL;\n\tdesc->sglen = 1;\n\n\tatdma_sg = desc->sg;\n\tatdma_sg->lli = dma_pool_alloc(atdma->lli_pool, GFP_NOWAIT,\n\t\t\t\t       &atdma_sg->lli_phys);\n\tif (!atdma_sg->lli) {\n\t\tkfree(desc);\n\t\treturn NULL;\n\t}\n\tlli = atdma_sg->lli;\n\n\tlli->saddr = xt->src_start;\n\tlli->daddr = xt->dst_start;\n\tlli->ctrla = ctrla | xfer_count;\n\tlli->ctrlb = ctrlb;\n\n\tdesc->boundary = first->size >> dwidth;\n\tdesc->dst_hole = (dmaengine_get_dst_icg(xt, first) >> dwidth) + 1;\n\tdesc->src_hole = (dmaengine_get_src_icg(xt, first) >> dwidth) + 1;\n\n\tatdma_sg->len = len;\n\tdesc->total_len = len;\n\n\tset_lli_eol(desc, 0);\n\treturn vchan_tx_prep(&atchan->vc, &desc->vd, flags);\n}\n\n \nstatic struct dma_async_tx_descriptor *\natc_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest, dma_addr_t src,\n\t\tsize_t len, unsigned long flags)\n{\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct at_desc\t\t*desc = NULL;\n\tsize_t\t\t\txfer_count;\n\tsize_t\t\t\toffset;\n\tsize_t\t\t\tsg_len;\n\tunsigned int\t\tsrc_width;\n\tunsigned int\t\tdst_width;\n\tunsigned int\t\ti;\n\tu32\t\t\tctrla;\n\tu32\t\t\tctrlb;\n\n\tdev_dbg(chan2dev(chan), \"prep_dma_memcpy: d%pad s%pad l0x%zx f0x%lx\\n\",\n\t\t&dest, &src, len, flags);\n\n\tif (unlikely(!len)) {\n\t\tdev_err(chan2dev(chan), \"prep_dma_memcpy: length is zero!\\n\");\n\t\treturn NULL;\n\t}\n\n\tsg_len = DIV_ROUND_UP(len, ATC_BTSIZE_MAX);\n\tdesc = kzalloc(struct_size(desc, sg, sg_len), GFP_ATOMIC);\n\tif (!desc)\n\t\treturn NULL;\n\tdesc->sglen = sg_len;\n\n\tctrlb = ATC_DEFAULT_CTRLB | ATC_IEN |\n\t\tFIELD_PREP(ATC_SRC_ADDR_MODE, ATC_SRC_ADDR_MODE_INCR) |\n\t\tFIELD_PREP(ATC_DST_ADDR_MODE, ATC_DST_ADDR_MODE_INCR) |\n\t\tFIELD_PREP(ATC_FC, ATC_FC_MEM2MEM);\n\n\t \n\tsrc_width = dst_width = atc_get_xfer_width(src, dest, len);\n\n\tctrla = FIELD_PREP(ATC_SRC_WIDTH, src_width) |\n\t\tFIELD_PREP(ATC_DST_WIDTH, dst_width);\n\n\tfor (offset = 0, i = 0; offset < len;\n\t     offset += xfer_count << src_width, i++) {\n\t\tstruct atdma_sg *atdma_sg = &desc->sg[i];\n\t\tstruct at_lli *lli;\n\n\t\tatdma_sg->lli = dma_pool_alloc(atdma->lli_pool, GFP_NOWAIT,\n\t\t\t\t\t       &atdma_sg->lli_phys);\n\t\tif (!atdma_sg->lli)\n\t\t\tgoto err_desc_get;\n\t\tlli = atdma_sg->lli;\n\n\t\txfer_count = min_t(size_t, (len - offset) >> src_width,\n\t\t\t\t   ATC_BTSIZE_MAX);\n\n\t\tlli->saddr = src + offset;\n\t\tlli->daddr = dest + offset;\n\t\tlli->ctrla = ctrla | xfer_count;\n\t\tlli->ctrlb = ctrlb;\n\n\t\tdesc->sg[i].len = xfer_count << src_width;\n\n\t\tatdma_lli_chain(desc, i);\n\t}\n\n\tdesc->total_len = len;\n\n\t \n\tset_lli_eol(desc, i - 1);\n\n\treturn vchan_tx_prep(&atchan->vc, &desc->vd, flags);\n\nerr_desc_get:\n\tatdma_desc_free(&desc->vd);\n\treturn NULL;\n}\n\nstatic int atdma_create_memset_lli(struct dma_chan *chan,\n\t\t\t\t   struct atdma_sg *atdma_sg,\n\t\t\t\t   dma_addr_t psrc, dma_addr_t pdst, size_t len)\n{\n\tstruct at_dma *atdma = to_at_dma(chan->device);\n\tstruct at_lli *lli;\n\tsize_t xfer_count;\n\tu32 ctrla = FIELD_PREP(ATC_SRC_WIDTH, 2) | FIELD_PREP(ATC_DST_WIDTH, 2);\n\tu32 ctrlb = ATC_DEFAULT_CTRLB | ATC_IEN |\n\t\t    FIELD_PREP(ATC_SRC_ADDR_MODE, ATC_SRC_ADDR_MODE_FIXED) |\n\t\t    FIELD_PREP(ATC_DST_ADDR_MODE, ATC_DST_ADDR_MODE_INCR) |\n\t\t    FIELD_PREP(ATC_FC, ATC_FC_MEM2MEM);\n\n\txfer_count = len >> 2;\n\tif (xfer_count > ATC_BTSIZE_MAX) {\n\t\tdev_err(chan2dev(chan), \"%s: buffer is too big\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tatdma_sg->lli = dma_pool_alloc(atdma->lli_pool, GFP_NOWAIT,\n\t\t\t\t       &atdma_sg->lli_phys);\n\tif (!atdma_sg->lli)\n\t\treturn -ENOMEM;\n\tlli = atdma_sg->lli;\n\n\tlli->saddr = psrc;\n\tlli->daddr = pdst;\n\tlli->ctrla = ctrla | xfer_count;\n\tlli->ctrlb = ctrlb;\n\n\tatdma_sg->len = len;\n\n\treturn 0;\n}\n\n \nstatic struct dma_async_tx_descriptor *\natc_prep_dma_memset(struct dma_chan *chan, dma_addr_t dest, int value,\n\t\t    size_t len, unsigned long flags)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tstruct at_desc\t\t*desc;\n\tvoid __iomem\t\t*vaddr;\n\tdma_addr_t\t\tpaddr;\n\tchar\t\t\tfill_pattern;\n\tint\t\t\tret;\n\n\tdev_vdbg(chan2dev(chan), \"%s: d%pad v0x%x l0x%zx f0x%lx\\n\", __func__,\n\t\t&dest, value, len, flags);\n\n\tif (unlikely(!len)) {\n\t\tdev_dbg(chan2dev(chan), \"%s: length is zero!\\n\", __func__);\n\t\treturn NULL;\n\t}\n\n\tif (!is_dma_fill_aligned(chan->device, dest, 0, len)) {\n\t\tdev_dbg(chan2dev(chan), \"%s: buffer is not aligned\\n\",\n\t\t\t__func__);\n\t\treturn NULL;\n\t}\n\n\tvaddr = dma_pool_alloc(atdma->memset_pool, GFP_NOWAIT, &paddr);\n\tif (!vaddr) {\n\t\tdev_err(chan2dev(chan), \"%s: couldn't allocate buffer\\n\",\n\t\t\t__func__);\n\t\treturn NULL;\n\t}\n\n\t \n\tfill_pattern = (char)value;\n\n\t*(u32*)vaddr = (fill_pattern << 24) |\n\t\t       (fill_pattern << 16) |\n\t\t       (fill_pattern << 8) |\n\t\t       fill_pattern;\n\n\tdesc = kzalloc(struct_size(desc, sg, 1), GFP_ATOMIC);\n\tif (!desc)\n\t\tgoto err_free_buffer;\n\tdesc->sglen = 1;\n\n\tret = atdma_create_memset_lli(chan, desc->sg, paddr, dest, len);\n\tif (ret)\n\t\tgoto err_free_desc;\n\n\tdesc->memset_paddr = paddr;\n\tdesc->memset_vaddr = vaddr;\n\tdesc->memset_buffer = true;\n\n\tdesc->total_len = len;\n\n\t \n\tset_lli_eol(desc, 0);\n\n\treturn vchan_tx_prep(&atchan->vc, &desc->vd, flags);\n\nerr_free_desc:\n\tkfree(desc);\nerr_free_buffer:\n\tdma_pool_free(atdma->memset_pool, vaddr, paddr);\n\treturn NULL;\n}\n\nstatic struct dma_async_tx_descriptor *\natc_prep_dma_memset_sg(struct dma_chan *chan,\n\t\t       struct scatterlist *sgl,\n\t\t       unsigned int sg_len, int value,\n\t\t       unsigned long flags)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tstruct at_desc\t\t*desc;\n\tstruct scatterlist\t*sg;\n\tvoid __iomem\t\t*vaddr;\n\tdma_addr_t\t\tpaddr;\n\tsize_t\t\t\ttotal_len = 0;\n\tint\t\t\ti;\n\tint\t\t\tret;\n\n\tdev_vdbg(chan2dev(chan), \"%s: v0x%x l0x%zx f0x%lx\\n\", __func__,\n\t\t value, sg_len, flags);\n\n\tif (unlikely(!sgl || !sg_len)) {\n\t\tdev_dbg(chan2dev(chan), \"%s: scatterlist is empty!\\n\",\n\t\t\t__func__);\n\t\treturn NULL;\n\t}\n\n\tvaddr = dma_pool_alloc(atdma->memset_pool, GFP_NOWAIT, &paddr);\n\tif (!vaddr) {\n\t\tdev_err(chan2dev(chan), \"%s: couldn't allocate buffer\\n\",\n\t\t\t__func__);\n\t\treturn NULL;\n\t}\n\t*(u32*)vaddr = value;\n\n\tdesc = kzalloc(struct_size(desc, sg, sg_len), GFP_ATOMIC);\n\tif (!desc)\n\t\tgoto err_free_dma_buf;\n\tdesc->sglen = sg_len;\n\n\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\tdma_addr_t dest = sg_dma_address(sg);\n\t\tsize_t len = sg_dma_len(sg);\n\n\t\tdev_vdbg(chan2dev(chan), \"%s: d%pad, l0x%zx\\n\",\n\t\t\t __func__, &dest, len);\n\n\t\tif (!is_dma_fill_aligned(chan->device, dest, 0, len)) {\n\t\t\tdev_err(chan2dev(chan), \"%s: buffer is not aligned\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto err_free_desc;\n\t\t}\n\n\t\tret = atdma_create_memset_lli(chan, &desc->sg[i], paddr, dest,\n\t\t\t\t\t      len);\n\t\tif (ret)\n\t\t\tgoto err_free_desc;\n\n\t\tatdma_lli_chain(desc, i);\n\t\ttotal_len += len;\n\t}\n\n\tdesc->memset_paddr = paddr;\n\tdesc->memset_vaddr = vaddr;\n\tdesc->memset_buffer = true;\n\n\tdesc->total_len = total_len;\n\n\t \n\tset_lli_eol(desc, i - 1);\n\n\treturn vchan_tx_prep(&atchan->vc, &desc->vd, flags);\n\nerr_free_desc:\n\tatdma_desc_free(&desc->vd);\nerr_free_dma_buf:\n\tdma_pool_free(atdma->memset_pool, vaddr, paddr);\n\treturn NULL;\n}\n\n \nstatic struct dma_async_tx_descriptor *\natc_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,\n\t\tunsigned int sg_len, enum dma_transfer_direction direction,\n\t\tunsigned long flags, void *context)\n{\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct at_dma_slave\t*atslave = chan->private;\n\tstruct dma_slave_config\t*sconfig = &atchan->dma_sconfig;\n\tstruct at_desc\t\t*desc;\n\tu32\t\t\tctrla;\n\tu32\t\t\tctrlb;\n\tdma_addr_t\t\treg;\n\tunsigned int\t\treg_width;\n\tunsigned int\t\tmem_width;\n\tunsigned int\t\ti;\n\tstruct scatterlist\t*sg;\n\tsize_t\t\t\ttotal_len = 0;\n\n\tdev_vdbg(chan2dev(chan), \"prep_slave_sg (%d): %s f0x%lx\\n\",\n\t\t\tsg_len,\n\t\t\tdirection == DMA_MEM_TO_DEV ? \"TO DEVICE\" : \"FROM DEVICE\",\n\t\t\tflags);\n\n\tif (unlikely(!atslave || !sg_len)) {\n\t\tdev_dbg(chan2dev(chan), \"prep_slave_sg: sg length is zero!\\n\");\n\t\treturn NULL;\n\t}\n\n\tdesc = kzalloc(struct_size(desc, sg, sg_len), GFP_ATOMIC);\n\tif (!desc)\n\t\treturn NULL;\n\tdesc->sglen = sg_len;\n\n\tctrla = FIELD_PREP(ATC_SCSIZE, sconfig->src_maxburst) |\n\t\tFIELD_PREP(ATC_DCSIZE, sconfig->dst_maxburst);\n\tctrlb = ATC_IEN;\n\n\tswitch (direction) {\n\tcase DMA_MEM_TO_DEV:\n\t\treg_width = convert_buswidth(sconfig->dst_addr_width);\n\t\tctrla |= FIELD_PREP(ATC_DST_WIDTH, reg_width);\n\t\tctrlb |= FIELD_PREP(ATC_DST_ADDR_MODE,\n\t\t\t\t    ATC_DST_ADDR_MODE_FIXED) |\n\t\t\t FIELD_PREP(ATC_SRC_ADDR_MODE, ATC_SRC_ADDR_MODE_INCR) |\n\t\t\t FIELD_PREP(ATC_FC, ATC_FC_MEM2PER) |\n\t\t\t FIELD_PREP(ATC_SIF, atchan->mem_if) |\n\t\t\t FIELD_PREP(ATC_DIF, atchan->per_if);\n\t\treg = sconfig->dst_addr;\n\t\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\t\tstruct atdma_sg *atdma_sg = &desc->sg[i];\n\t\t\tstruct at_lli *lli;\n\t\t\tu32\t\tlen;\n\t\t\tu32\t\tmem;\n\n\t\t\tatdma_sg->lli = dma_pool_alloc(atdma->lli_pool,\n\t\t\t\t\t\t       GFP_NOWAIT,\n\t\t\t\t\t\t       &atdma_sg->lli_phys);\n\t\t\tif (!atdma_sg->lli)\n\t\t\t\tgoto err_desc_get;\n\t\t\tlli = atdma_sg->lli;\n\n\t\t\tmem = sg_dma_address(sg);\n\t\t\tlen = sg_dma_len(sg);\n\t\t\tif (unlikely(!len)) {\n\t\t\t\tdev_dbg(chan2dev(chan),\n\t\t\t\t\t\"prep_slave_sg: sg(%d) data length is zero\\n\", i);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tmem_width = 2;\n\t\t\tif (unlikely(mem & 3 || len & 3))\n\t\t\t\tmem_width = 0;\n\n\t\t\tlli->saddr = mem;\n\t\t\tlli->daddr = reg;\n\t\t\tlli->ctrla = ctrla |\n\t\t\t\t     FIELD_PREP(ATC_SRC_WIDTH, mem_width) |\n\t\t\t\t     len >> mem_width;\n\t\t\tlli->ctrlb = ctrlb;\n\n\t\t\tatdma_sg->len = len;\n\t\t\ttotal_len += len;\n\n\t\t\tdesc->sg[i].len = len;\n\t\t\tatdma_lli_chain(desc, i);\n\t\t}\n\t\tbreak;\n\tcase DMA_DEV_TO_MEM:\n\t\treg_width = convert_buswidth(sconfig->src_addr_width);\n\t\tctrla |= FIELD_PREP(ATC_SRC_WIDTH, reg_width);\n\t\tctrlb |= FIELD_PREP(ATC_DST_ADDR_MODE, ATC_DST_ADDR_MODE_INCR) |\n\t\t\t FIELD_PREP(ATC_SRC_ADDR_MODE,\n\t\t\t\t    ATC_SRC_ADDR_MODE_FIXED) |\n\t\t\t FIELD_PREP(ATC_FC, ATC_FC_PER2MEM) |\n\t\t\t FIELD_PREP(ATC_SIF, atchan->per_if) |\n\t\t\t FIELD_PREP(ATC_DIF, atchan->mem_if);\n\n\t\treg = sconfig->src_addr;\n\t\tfor_each_sg(sgl, sg, sg_len, i) {\n\t\t\tstruct atdma_sg *atdma_sg = &desc->sg[i];\n\t\t\tstruct at_lli *lli;\n\t\t\tu32\t\tlen;\n\t\t\tu32\t\tmem;\n\n\t\t\tatdma_sg->lli = dma_pool_alloc(atdma->lli_pool,\n\t\t\t\t\t\t       GFP_NOWAIT,\n\t\t\t\t\t\t       &atdma_sg->lli_phys);\n\t\t\tif (!atdma_sg->lli)\n\t\t\t\tgoto err_desc_get;\n\t\t\tlli = atdma_sg->lli;\n\n\t\t\tmem = sg_dma_address(sg);\n\t\t\tlen = sg_dma_len(sg);\n\t\t\tif (unlikely(!len)) {\n\t\t\t\tdev_dbg(chan2dev(chan),\n\t\t\t\t\t\"prep_slave_sg: sg(%d) data length is zero\\n\", i);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tmem_width = 2;\n\t\t\tif (unlikely(mem & 3 || len & 3))\n\t\t\t\tmem_width = 0;\n\n\t\t\tlli->saddr = reg;\n\t\t\tlli->daddr = mem;\n\t\t\tlli->ctrla = ctrla |\n\t\t\t\t     FIELD_PREP(ATC_DST_WIDTH, mem_width) |\n\t\t\t\t     len >> reg_width;\n\t\t\tlli->ctrlb = ctrlb;\n\n\t\t\tdesc->sg[i].len = len;\n\t\t\ttotal_len += len;\n\n\t\t\tatdma_lli_chain(desc, i);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\treturn NULL;\n\t}\n\n\t \n\tset_lli_eol(desc, i - 1);\n\n\tdesc->total_len = total_len;\n\n\treturn vchan_tx_prep(&atchan->vc, &desc->vd, flags);\n\nerr_desc_get:\n\tdev_err(chan2dev(chan), \"not enough descriptors available\\n\");\nerr:\n\tatdma_desc_free(&desc->vd);\n\treturn NULL;\n}\n\n \nstatic int\natc_dma_cyclic_check_values(unsigned int reg_width, dma_addr_t buf_addr,\n\t\tsize_t period_len)\n{\n\tif (period_len > (ATC_BTSIZE_MAX << reg_width))\n\t\tgoto err_out;\n\tif (unlikely(period_len & ((1 << reg_width) - 1)))\n\t\tgoto err_out;\n\tif (unlikely(buf_addr & ((1 << reg_width) - 1)))\n\t\tgoto err_out;\n\n\treturn 0;\n\nerr_out:\n\treturn -EINVAL;\n}\n\n \nstatic int\natc_dma_cyclic_fill_desc(struct dma_chan *chan, struct at_desc *desc,\n\t\tunsigned int i, dma_addr_t buf_addr,\n\t\tunsigned int reg_width, size_t period_len,\n\t\tenum dma_transfer_direction direction)\n{\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct dma_slave_config\t*sconfig = &atchan->dma_sconfig;\n\tstruct atdma_sg\t\t*atdma_sg = &desc->sg[i];\n\tstruct at_lli\t\t*lli;\n\n\tatdma_sg->lli = dma_pool_alloc(atdma->lli_pool, GFP_ATOMIC,\n\t\t\t\t       &atdma_sg->lli_phys);\n\tif (!atdma_sg->lli)\n\t\treturn -ENOMEM;\n\tlli = atdma_sg->lli;\n\n\tswitch (direction) {\n\tcase DMA_MEM_TO_DEV:\n\t\tlli->saddr = buf_addr + (period_len * i);\n\t\tlli->daddr = sconfig->dst_addr;\n\t\tlli->ctrlb = FIELD_PREP(ATC_DST_ADDR_MODE,\n\t\t\t\t\tATC_DST_ADDR_MODE_FIXED) |\n\t\t\t     FIELD_PREP(ATC_SRC_ADDR_MODE,\n\t\t\t\t\tATC_SRC_ADDR_MODE_INCR) |\n\t\t\t     FIELD_PREP(ATC_FC, ATC_FC_MEM2PER) |\n\t\t\t     FIELD_PREP(ATC_SIF, atchan->mem_if) |\n\t\t\t     FIELD_PREP(ATC_DIF, atchan->per_if);\n\n\t\tbreak;\n\n\tcase DMA_DEV_TO_MEM:\n\t\tlli->saddr = sconfig->src_addr;\n\t\tlli->daddr = buf_addr + (period_len * i);\n\t\tlli->ctrlb = FIELD_PREP(ATC_DST_ADDR_MODE,\n\t\t\t\t\tATC_DST_ADDR_MODE_INCR) |\n\t\t\t     FIELD_PREP(ATC_SRC_ADDR_MODE,\n\t\t\t\t\tATC_SRC_ADDR_MODE_FIXED) |\n\t\t\t     FIELD_PREP(ATC_FC, ATC_FC_PER2MEM) |\n\t\t\t     FIELD_PREP(ATC_SIF, atchan->per_if) |\n\t\t\t     FIELD_PREP(ATC_DIF, atchan->mem_if);\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tlli->ctrla = FIELD_PREP(ATC_SCSIZE, sconfig->src_maxburst) |\n\t\t     FIELD_PREP(ATC_DCSIZE, sconfig->dst_maxburst) |\n\t\t     FIELD_PREP(ATC_DST_WIDTH, reg_width) |\n\t\t     FIELD_PREP(ATC_SRC_WIDTH, reg_width) |\n\t\t     period_len >> reg_width;\n\tdesc->sg[i].len = period_len;\n\n\treturn 0;\n}\n\n \nstatic struct dma_async_tx_descriptor *\natc_prep_dma_cyclic(struct dma_chan *chan, dma_addr_t buf_addr, size_t buf_len,\n\t\tsize_t period_len, enum dma_transfer_direction direction,\n\t\tunsigned long flags)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct at_dma_slave\t*atslave = chan->private;\n\tstruct dma_slave_config\t*sconfig = &atchan->dma_sconfig;\n\tstruct at_desc\t\t*desc;\n\tunsigned long\t\twas_cyclic;\n\tunsigned int\t\treg_width;\n\tunsigned int\t\tperiods = buf_len / period_len;\n\tunsigned int\t\ti;\n\n\tdev_vdbg(chan2dev(chan), \"prep_dma_cyclic: %s buf@%pad - %d (%d/%d)\\n\",\n\t\t\tdirection == DMA_MEM_TO_DEV ? \"TO DEVICE\" : \"FROM DEVICE\",\n\t\t\t&buf_addr,\n\t\t\tperiods, buf_len, period_len);\n\n\tif (unlikely(!atslave || !buf_len || !period_len)) {\n\t\tdev_dbg(chan2dev(chan), \"prep_dma_cyclic: length is zero!\\n\");\n\t\treturn NULL;\n\t}\n\n\twas_cyclic = test_and_set_bit(ATC_IS_CYCLIC, &atchan->status);\n\tif (was_cyclic) {\n\t\tdev_dbg(chan2dev(chan), \"prep_dma_cyclic: channel in use!\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (unlikely(!is_slave_direction(direction)))\n\t\tgoto err_out;\n\n\tif (direction == DMA_MEM_TO_DEV)\n\t\treg_width = convert_buswidth(sconfig->dst_addr_width);\n\telse\n\t\treg_width = convert_buswidth(sconfig->src_addr_width);\n\n\t \n\tif (atc_dma_cyclic_check_values(reg_width, buf_addr, period_len))\n\t\tgoto err_out;\n\n\tdesc = kzalloc(struct_size(desc, sg, periods), GFP_ATOMIC);\n\tif (!desc)\n\t\tgoto err_out;\n\tdesc->sglen = periods;\n\n\t \n\tfor (i = 0; i < periods; i++) {\n\t\tif (atc_dma_cyclic_fill_desc(chan, desc, i, buf_addr,\n\t\t\t\t\t     reg_width, period_len, direction))\n\t\t\tgoto err_fill_desc;\n\t\tatdma_lli_chain(desc, i);\n\t}\n\tdesc->total_len = buf_len;\n\t \n\tdesc->sg[i - 1].lli->dscr = desc->sg[0].lli_phys;\n\n\treturn vchan_tx_prep(&atchan->vc, &desc->vd, flags);\n\nerr_fill_desc:\n\tatdma_desc_free(&desc->vd);\nerr_out:\n\tclear_bit(ATC_IS_CYCLIC, &atchan->status);\n\treturn NULL;\n}\n\nstatic int atc_config(struct dma_chan *chan,\n\t\t      struct dma_slave_config *sconfig)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\n\tdev_vdbg(chan2dev(chan), \"%s\\n\", __func__);\n\n\t \n\tif (!chan->private)\n\t\treturn -EINVAL;\n\n\tmemcpy(&atchan->dma_sconfig, sconfig, sizeof(*sconfig));\n\n\tconvert_burst(&atchan->dma_sconfig.src_maxburst);\n\tconvert_burst(&atchan->dma_sconfig.dst_maxburst);\n\n\treturn 0;\n}\n\nstatic int atc_pause(struct dma_chan *chan)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tint\t\t\tchan_id = atchan->vc.chan.chan_id;\n\tunsigned long\t\tflags;\n\n\tdev_vdbg(chan2dev(chan), \"%s\\n\", __func__);\n\n\tspin_lock_irqsave(&atchan->vc.lock, flags);\n\n\tdma_writel(atdma, CHER, AT_DMA_SUSP(chan_id));\n\tset_bit(ATC_IS_PAUSED, &atchan->status);\n\n\tspin_unlock_irqrestore(&atchan->vc.lock, flags);\n\n\treturn 0;\n}\n\nstatic int atc_resume(struct dma_chan *chan)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tint\t\t\tchan_id = atchan->vc.chan.chan_id;\n\tunsigned long\t\tflags;\n\n\tdev_vdbg(chan2dev(chan), \"%s\\n\", __func__);\n\n\tif (!atc_chan_is_paused(atchan))\n\t\treturn 0;\n\n\tspin_lock_irqsave(&atchan->vc.lock, flags);\n\n\tdma_writel(atdma, CHDR, AT_DMA_RES(chan_id));\n\tclear_bit(ATC_IS_PAUSED, &atchan->status);\n\n\tspin_unlock_irqrestore(&atchan->vc.lock, flags);\n\n\treturn 0;\n}\n\nstatic int atc_terminate_all(struct dma_chan *chan)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tint\t\t\tchan_id = atchan->vc.chan.chan_id;\n\tunsigned long\t\tflags;\n\n\tLIST_HEAD(list);\n\n\tdev_vdbg(chan2dev(chan), \"%s\\n\", __func__);\n\n\t \n\tspin_lock_irqsave(&atchan->vc.lock, flags);\n\n\t \n\tdma_writel(atdma, CHDR, AT_DMA_RES(chan_id) | atchan->mask);\n\n\t \n\twhile (dma_readl(atdma, CHSR) & atchan->mask)\n\t\tcpu_relax();\n\n\tif (atchan->desc) {\n\t\tvchan_terminate_vdesc(&atchan->desc->vd);\n\t\tatchan->desc = NULL;\n\t}\n\n\tvchan_get_all_descriptors(&atchan->vc, &list);\n\n\tclear_bit(ATC_IS_PAUSED, &atchan->status);\n\t \n\tclear_bit(ATC_IS_CYCLIC, &atchan->status);\n\n\tspin_unlock_irqrestore(&atchan->vc.lock, flags);\n\n\tvchan_dma_desc_free_list(&atchan->vc, &list);\n\n\treturn 0;\n}\n\n \nstatic enum dma_status\natc_tx_status(struct dma_chan *chan,\n\t\tdma_cookie_t cookie,\n\t\tstruct dma_tx_state *txstate)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tunsigned long\t\tflags;\n\tenum dma_status\t\tdma_status;\n\tu32 residue;\n\tint ret;\n\n\tdma_status = dma_cookie_status(chan, cookie, txstate);\n\tif (dma_status == DMA_COMPLETE || !txstate)\n\t\treturn dma_status;\n\n\tspin_lock_irqsave(&atchan->vc.lock, flags);\n\t \n\tret = atc_get_residue(chan, cookie, &residue);\n\tspin_unlock_irqrestore(&atchan->vc.lock, flags);\n\n\tif (unlikely(ret < 0)) {\n\t\tdev_vdbg(chan2dev(chan), \"get residual bytes error\\n\");\n\t\treturn DMA_ERROR;\n\t} else {\n\t\tdma_set_residue(txstate, residue);\n\t}\n\n\tdev_vdbg(chan2dev(chan), \"tx_status %d: cookie = %d residue = %u\\n\",\n\t\t dma_status, cookie, residue);\n\n\treturn dma_status;\n}\n\nstatic void atc_issue_pending(struct dma_chan *chan)\n{\n\tstruct at_dma_chan *atchan = to_at_dma_chan(chan);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&atchan->vc.lock, flags);\n\tif (vchan_issue_pending(&atchan->vc) && !atchan->desc) {\n\t\tif (!(atc_chan_is_enabled(atchan)))\n\t\t\tatc_dostart(atchan);\n\t}\n\tspin_unlock_irqrestore(&atchan->vc.lock, flags);\n}\n\n \nstatic int atc_alloc_chan_resources(struct dma_chan *chan)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\tstruct at_dma\t\t*atdma = to_at_dma(chan->device);\n\tstruct at_dma_slave\t*atslave;\n\tu32\t\t\tcfg;\n\n\tdev_vdbg(chan2dev(chan), \"alloc_chan_resources\\n\");\n\n\t \n\tif (atc_chan_is_enabled(atchan)) {\n\t\tdev_dbg(chan2dev(chan), \"DMA channel not idle ?\\n\");\n\t\treturn -EIO;\n\t}\n\n\tcfg = ATC_DEFAULT_CFG;\n\n\tatslave = chan->private;\n\tif (atslave) {\n\t\t \n\t\tBUG_ON(!atslave->dma_dev || atslave->dma_dev != atdma->dma_device.dev);\n\n\t\t \n\t\tif (atslave->cfg)\n\t\t\tcfg = atslave->cfg;\n\t}\n\n\t \n\tchannel_writel(atchan, CFG, cfg);\n\n\treturn 0;\n}\n\n \nstatic void atc_free_chan_resources(struct dma_chan *chan)\n{\n\tstruct at_dma_chan\t*atchan = to_at_dma_chan(chan);\n\n\tBUG_ON(atc_chan_is_enabled(atchan));\n\n\tvchan_free_chan_resources(to_virt_chan(chan));\n\tatchan->status = 0;\n\n\t \n\tkfree(chan->private);\n\tchan->private = NULL;\n\n\tdev_vdbg(chan2dev(chan), \"free_chan_resources: done\\n\");\n}\n\n#ifdef CONFIG_OF\nstatic bool at_dma_filter(struct dma_chan *chan, void *slave)\n{\n\tstruct at_dma_slave *atslave = slave;\n\n\tif (atslave->dma_dev == chan->device->dev) {\n\t\tchan->private = atslave;\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}\n\nstatic struct dma_chan *at_dma_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t     struct of_dma *of_dma)\n{\n\tstruct dma_chan *chan;\n\tstruct at_dma_chan *atchan;\n\tstruct at_dma_slave *atslave;\n\tdma_cap_mask_t mask;\n\tunsigned int per_id;\n\tstruct platform_device *dmac_pdev;\n\n\tif (dma_spec->args_count != 2)\n\t\treturn NULL;\n\n\tdmac_pdev = of_find_device_by_node(dma_spec->np);\n\tif (!dmac_pdev)\n\t\treturn NULL;\n\n\tdma_cap_zero(mask);\n\tdma_cap_set(DMA_SLAVE, mask);\n\n\tatslave = kmalloc(sizeof(*atslave), GFP_KERNEL);\n\tif (!atslave) {\n\t\tput_device(&dmac_pdev->dev);\n\t\treturn NULL;\n\t}\n\n\tatslave->cfg = ATC_DST_H2SEL | ATC_SRC_H2SEL;\n\t \n\tper_id = dma_spec->args[1] & AT91_DMA_CFG_PER_ID_MASK;\n\tatslave->cfg |= ATC_DST_PER_ID(per_id) |  ATC_SRC_PER_ID(per_id);\n\t \n\tswitch (dma_spec->args[1] & AT91_DMA_CFG_FIFOCFG_MASK) {\n\tcase AT91_DMA_CFG_FIFOCFG_ALAP:\n\t\tatslave->cfg |= FIELD_PREP(ATC_FIFOCFG,\n\t\t\t\t\t   ATC_FIFOCFG_LARGESTBURST);\n\t\tbreak;\n\tcase AT91_DMA_CFG_FIFOCFG_ASAP:\n\t\tatslave->cfg |= FIELD_PREP(ATC_FIFOCFG,\n\t\t\t\t\t   ATC_FIFOCFG_ENOUGHSPACE);\n\t\tbreak;\n\tcase AT91_DMA_CFG_FIFOCFG_HALF:\n\tdefault:\n\t\tatslave->cfg |= FIELD_PREP(ATC_FIFOCFG, ATC_FIFOCFG_HALFFIFO);\n\t}\n\tatslave->dma_dev = &dmac_pdev->dev;\n\n\tchan = dma_request_channel(mask, at_dma_filter, atslave);\n\tif (!chan) {\n\t\tput_device(&dmac_pdev->dev);\n\t\tkfree(atslave);\n\t\treturn NULL;\n\t}\n\n\tatchan = to_at_dma_chan(chan);\n\tatchan->per_if = dma_spec->args[0] & 0xff;\n\tatchan->mem_if = (dma_spec->args[0] >> 16) & 0xff;\n\n\treturn chan;\n}\n#else\nstatic struct dma_chan *at_dma_xlate(struct of_phandle_args *dma_spec,\n\t\t\t\t     struct of_dma *of_dma)\n{\n\treturn NULL;\n}\n#endif\n\n \n\n \nstatic struct at_dma_platform_data at91sam9rl_config = {\n\t.nr_channels = 2,\n};\nstatic struct at_dma_platform_data at91sam9g45_config = {\n\t.nr_channels = 8,\n};\n\n#if defined(CONFIG_OF)\nstatic const struct of_device_id atmel_dma_dt_ids[] = {\n\t{\n\t\t.compatible = \"atmel,at91sam9rl-dma\",\n\t\t.data = &at91sam9rl_config,\n\t}, {\n\t\t.compatible = \"atmel,at91sam9g45-dma\",\n\t\t.data = &at91sam9g45_config,\n\t}, {\n\t\t \n\t}\n};\n\nMODULE_DEVICE_TABLE(of, atmel_dma_dt_ids);\n#endif\n\nstatic const struct platform_device_id atdma_devtypes[] = {\n\t{\n\t\t.name = \"at91sam9rl_dma\",\n\t\t.driver_data = (unsigned long) &at91sam9rl_config,\n\t}, {\n\t\t.name = \"at91sam9g45_dma\",\n\t\t.driver_data = (unsigned long) &at91sam9g45_config,\n\t}, {\n\t\t \n\t}\n};\n\nstatic inline const struct at_dma_platform_data * __init at_dma_get_driver_data(\n\t\t\t\t\t\tstruct platform_device *pdev)\n{\n\tif (pdev->dev.of_node) {\n\t\tconst struct of_device_id *match;\n\t\tmatch = of_match_node(atmel_dma_dt_ids, pdev->dev.of_node);\n\t\tif (match == NULL)\n\t\t\treturn NULL;\n\t\treturn match->data;\n\t}\n\treturn (struct at_dma_platform_data *)\n\t\t\tplatform_get_device_id(pdev)->driver_data;\n}\n\n \nstatic void at_dma_off(struct at_dma *atdma)\n{\n\tdma_writel(atdma, EN, 0);\n\n\t \n\tdma_writel(atdma, EBCIDR, -1L);\n\n\t \n\twhile (dma_readl(atdma, CHSR) & atdma->all_chan_mask)\n\t\tcpu_relax();\n}\n\nstatic int __init at_dma_probe(struct platform_device *pdev)\n{\n\tstruct at_dma\t\t*atdma;\n\tint\t\t\tirq;\n\tint\t\t\terr;\n\tint\t\t\ti;\n\tconst struct at_dma_platform_data *plat_dat;\n\n\t \n\tdma_cap_set(DMA_MEMCPY, at91sam9rl_config.cap_mask);\n\tdma_cap_set(DMA_INTERLEAVE, at91sam9g45_config.cap_mask);\n\tdma_cap_set(DMA_MEMCPY, at91sam9g45_config.cap_mask);\n\tdma_cap_set(DMA_MEMSET, at91sam9g45_config.cap_mask);\n\tdma_cap_set(DMA_MEMSET_SG, at91sam9g45_config.cap_mask);\n\tdma_cap_set(DMA_PRIVATE, at91sam9g45_config.cap_mask);\n\tdma_cap_set(DMA_SLAVE, at91sam9g45_config.cap_mask);\n\n\t \n\tplat_dat = at_dma_get_driver_data(pdev);\n\tif (!plat_dat)\n\t\treturn -ENODEV;\n\n\tatdma = devm_kzalloc(&pdev->dev,\n\t\t\t     struct_size(atdma, chan, plat_dat->nr_channels),\n\t\t\t     GFP_KERNEL);\n\tif (!atdma)\n\t\treturn -ENOMEM;\n\n\tatdma->regs = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(atdma->regs))\n\t\treturn PTR_ERR(atdma->regs);\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\t \n\tatdma->dma_device.cap_mask = plat_dat->cap_mask;\n\tatdma->all_chan_mask = (1 << plat_dat->nr_channels) - 1;\n\n\tatdma->clk = devm_clk_get(&pdev->dev, \"dma_clk\");\n\tif (IS_ERR(atdma->clk))\n\t\treturn PTR_ERR(atdma->clk);\n\n\terr = clk_prepare_enable(atdma->clk);\n\tif (err)\n\t\treturn err;\n\n\t \n\tat_dma_off(atdma);\n\n\terr = request_irq(irq, at_dma_interrupt, 0, \"at_hdmac\", atdma);\n\tif (err)\n\t\tgoto err_irq;\n\n\tplatform_set_drvdata(pdev, atdma);\n\n\t \n\tatdma->lli_pool = dma_pool_create(\"at_hdmac_lli_pool\",\n\t\t\t\t\t  &pdev->dev, sizeof(struct at_lli),\n\t\t\t\t\t  4  , 0);\n\tif (!atdma->lli_pool) {\n\t\tdev_err(&pdev->dev, \"Unable to allocate DMA LLI descriptor pool\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_desc_pool_create;\n\t}\n\n\t \n\tatdma->memset_pool = dma_pool_create(\"at_hdmac_memset_pool\",\n\t\t\t\t\t     &pdev->dev, sizeof(int), 4, 0);\n\tif (!atdma->memset_pool) {\n\t\tdev_err(&pdev->dev, \"No memory for memset dma pool\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_memset_pool_create;\n\t}\n\n\t \n\twhile (dma_readl(atdma, EBCISR))\n\t\tcpu_relax();\n\n\t \n\tINIT_LIST_HEAD(&atdma->dma_device.channels);\n\tfor (i = 0; i < plat_dat->nr_channels; i++) {\n\t\tstruct at_dma_chan\t*atchan = &atdma->chan[i];\n\n\t\tatchan->mem_if = AT_DMA_MEM_IF;\n\t\tatchan->per_if = AT_DMA_PER_IF;\n\n\t\tatchan->ch_regs = atdma->regs + ch_regs(i);\n\t\tatchan->mask = 1 << i;\n\n\t\tatchan->atdma = atdma;\n\t\tatchan->vc.desc_free = atdma_desc_free;\n\t\tvchan_init(&atchan->vc, &atdma->dma_device);\n\t\tatc_enable_chan_irq(atdma, i);\n\t}\n\n\t \n\tatdma->dma_device.device_alloc_chan_resources = atc_alloc_chan_resources;\n\tatdma->dma_device.device_free_chan_resources = atc_free_chan_resources;\n\tatdma->dma_device.device_tx_status = atc_tx_status;\n\tatdma->dma_device.device_issue_pending = atc_issue_pending;\n\tatdma->dma_device.dev = &pdev->dev;\n\n\t \n\tif (dma_has_cap(DMA_INTERLEAVE, atdma->dma_device.cap_mask))\n\t\tatdma->dma_device.device_prep_interleaved_dma = atc_prep_dma_interleaved;\n\n\tif (dma_has_cap(DMA_MEMCPY, atdma->dma_device.cap_mask))\n\t\tatdma->dma_device.device_prep_dma_memcpy = atc_prep_dma_memcpy;\n\n\tif (dma_has_cap(DMA_MEMSET, atdma->dma_device.cap_mask)) {\n\t\tatdma->dma_device.device_prep_dma_memset = atc_prep_dma_memset;\n\t\tatdma->dma_device.device_prep_dma_memset_sg = atc_prep_dma_memset_sg;\n\t\tatdma->dma_device.fill_align = DMAENGINE_ALIGN_4_BYTES;\n\t}\n\n\tif (dma_has_cap(DMA_SLAVE, atdma->dma_device.cap_mask)) {\n\t\tatdma->dma_device.device_prep_slave_sg = atc_prep_slave_sg;\n\t\t \n\t\tdma_cap_set(DMA_CYCLIC, atdma->dma_device.cap_mask);\n\t\tatdma->dma_device.device_prep_dma_cyclic = atc_prep_dma_cyclic;\n\t\tatdma->dma_device.device_config = atc_config;\n\t\tatdma->dma_device.device_pause = atc_pause;\n\t\tatdma->dma_device.device_resume = atc_resume;\n\t\tatdma->dma_device.device_terminate_all = atc_terminate_all;\n\t\tatdma->dma_device.src_addr_widths = ATC_DMA_BUSWIDTHS;\n\t\tatdma->dma_device.dst_addr_widths = ATC_DMA_BUSWIDTHS;\n\t\tatdma->dma_device.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\n\t\tatdma->dma_device.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\n\t}\n\n\tdma_writel(atdma, EN, AT_DMA_ENABLE);\n\n\tdev_info(&pdev->dev, \"Atmel AHB DMA Controller ( %s%s%s), %d channels\\n\",\n\t  dma_has_cap(DMA_MEMCPY, atdma->dma_device.cap_mask) ? \"cpy \" : \"\",\n\t  dma_has_cap(DMA_MEMSET, atdma->dma_device.cap_mask) ? \"set \" : \"\",\n\t  dma_has_cap(DMA_SLAVE, atdma->dma_device.cap_mask)  ? \"slave \" : \"\",\n\t  plat_dat->nr_channels);\n\n\terr = dma_async_device_register(&atdma->dma_device);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Unable to register: %d.\\n\", err);\n\t\tgoto err_dma_async_device_register;\n\t}\n\n\t \n\tif (pdev->dev.of_node) {\n\t\terr = of_dma_controller_register(pdev->dev.of_node,\n\t\t\t\t\t\t at_dma_xlate, atdma);\n\t\tif (err) {\n\t\t\tdev_err(&pdev->dev, \"could not register of_dma_controller\\n\");\n\t\t\tgoto err_of_dma_controller_register;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_of_dma_controller_register:\n\tdma_async_device_unregister(&atdma->dma_device);\nerr_dma_async_device_register:\n\tdma_pool_destroy(atdma->memset_pool);\nerr_memset_pool_create:\n\tdma_pool_destroy(atdma->lli_pool);\nerr_desc_pool_create:\n\tfree_irq(platform_get_irq(pdev, 0), atdma);\nerr_irq:\n\tclk_disable_unprepare(atdma->clk);\n\treturn err;\n}\n\nstatic int at_dma_remove(struct platform_device *pdev)\n{\n\tstruct at_dma\t\t*atdma = platform_get_drvdata(pdev);\n\tstruct dma_chan\t\t*chan, *_chan;\n\n\tat_dma_off(atdma);\n\tif (pdev->dev.of_node)\n\t\tof_dma_controller_free(pdev->dev.of_node);\n\tdma_async_device_unregister(&atdma->dma_device);\n\n\tdma_pool_destroy(atdma->memset_pool);\n\tdma_pool_destroy(atdma->lli_pool);\n\tfree_irq(platform_get_irq(pdev, 0), atdma);\n\n\tlist_for_each_entry_safe(chan, _chan, &atdma->dma_device.channels,\n\t\t\tdevice_node) {\n\t\t \n\t\tatc_disable_chan_irq(atdma, chan->chan_id);\n\t\tlist_del(&chan->device_node);\n\t}\n\n\tclk_disable_unprepare(atdma->clk);\n\n\treturn 0;\n}\n\nstatic void at_dma_shutdown(struct platform_device *pdev)\n{\n\tstruct at_dma\t*atdma = platform_get_drvdata(pdev);\n\n\tat_dma_off(platform_get_drvdata(pdev));\n\tclk_disable_unprepare(atdma->clk);\n}\n\nstatic int at_dma_prepare(struct device *dev)\n{\n\tstruct at_dma *atdma = dev_get_drvdata(dev);\n\tstruct dma_chan *chan, *_chan;\n\n\tlist_for_each_entry_safe(chan, _chan, &atdma->dma_device.channels,\n\t\t\tdevice_node) {\n\t\tstruct at_dma_chan *atchan = to_at_dma_chan(chan);\n\t\t \n\t\tif (atc_chan_is_enabled(atchan) && !atc_chan_is_cyclic(atchan))\n\t\t\treturn -EAGAIN;\n\t}\n\treturn 0;\n}\n\nstatic void atc_suspend_cyclic(struct at_dma_chan *atchan)\n{\n\tstruct dma_chan\t*chan = &atchan->vc.chan;\n\n\t \n\tif (!atc_chan_is_paused(atchan)) {\n\t\tdev_warn(chan2dev(chan),\n\t\t\"cyclic channel not paused, should be done by channel user\\n\");\n\t\tatc_pause(chan);\n\t}\n\n\t \n\t \n\tatchan->save_dscr = channel_readl(atchan, DSCR);\n\n\tvdbg_dump_regs(atchan);\n}\n\nstatic int at_dma_suspend_noirq(struct device *dev)\n{\n\tstruct at_dma *atdma = dev_get_drvdata(dev);\n\tstruct dma_chan *chan, *_chan;\n\n\t \n\tlist_for_each_entry_safe(chan, _chan, &atdma->dma_device.channels,\n\t\t\tdevice_node) {\n\t\tstruct at_dma_chan *atchan = to_at_dma_chan(chan);\n\n\t\tif (atc_chan_is_cyclic(atchan))\n\t\t\tatc_suspend_cyclic(atchan);\n\t\tatchan->save_cfg = channel_readl(atchan, CFG);\n\t}\n\tatdma->save_imr = dma_readl(atdma, EBCIMR);\n\n\t \n\tat_dma_off(atdma);\n\tclk_disable_unprepare(atdma->clk);\n\treturn 0;\n}\n\nstatic void atc_resume_cyclic(struct at_dma_chan *atchan)\n{\n\tstruct at_dma\t*atdma = to_at_dma(atchan->vc.chan.device);\n\n\t \n\tchannel_writel(atchan, SADDR, 0);\n\tchannel_writel(atchan, DADDR, 0);\n\tchannel_writel(atchan, CTRLA, 0);\n\tchannel_writel(atchan, CTRLB, 0);\n\tchannel_writel(atchan, DSCR, atchan->save_dscr);\n\tdma_writel(atdma, CHER, atchan->mask);\n\n\t \n\n\tvdbg_dump_regs(atchan);\n}\n\nstatic int at_dma_resume_noirq(struct device *dev)\n{\n\tstruct at_dma *atdma = dev_get_drvdata(dev);\n\tstruct dma_chan *chan, *_chan;\n\n\t \n\tclk_prepare_enable(atdma->clk);\n\tdma_writel(atdma, EN, AT_DMA_ENABLE);\n\n\t \n\twhile (dma_readl(atdma, EBCISR))\n\t\tcpu_relax();\n\n\t \n\tdma_writel(atdma, EBCIER, atdma->save_imr);\n\tlist_for_each_entry_safe(chan, _chan, &atdma->dma_device.channels,\n\t\t\tdevice_node) {\n\t\tstruct at_dma_chan *atchan = to_at_dma_chan(chan);\n\n\t\tchannel_writel(atchan, CFG, atchan->save_cfg);\n\t\tif (atc_chan_is_cyclic(atchan))\n\t\t\tatc_resume_cyclic(atchan);\n\t}\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops __maybe_unused at_dma_dev_pm_ops = {\n\t.prepare = at_dma_prepare,\n\t.suspend_noirq = at_dma_suspend_noirq,\n\t.resume_noirq = at_dma_resume_noirq,\n};\n\nstatic struct platform_driver at_dma_driver = {\n\t.remove\t\t= at_dma_remove,\n\t.shutdown\t= at_dma_shutdown,\n\t.id_table\t= atdma_devtypes,\n\t.driver = {\n\t\t.name\t= \"at_hdmac\",\n\t\t.pm\t= pm_ptr(&at_dma_dev_pm_ops),\n\t\t.of_match_table\t= of_match_ptr(atmel_dma_dt_ids),\n\t},\n};\n\nstatic int __init at_dma_init(void)\n{\n\treturn platform_driver_probe(&at_dma_driver, at_dma_probe);\n}\nsubsys_initcall(at_dma_init);\n\nstatic void __exit at_dma_exit(void)\n{\n\tplatform_driver_unregister(&at_dma_driver);\n}\nmodule_exit(at_dma_exit);\n\nMODULE_DESCRIPTION(\"Atmel AHB DMA Controller driver\");\nMODULE_AUTHOR(\"Nicolas Ferre <nicolas.ferre@atmel.com>\");\nMODULE_AUTHOR(\"Tudor Ambarus <tudor.ambarus@microchip.com>\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"platform:at_hdmac\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}