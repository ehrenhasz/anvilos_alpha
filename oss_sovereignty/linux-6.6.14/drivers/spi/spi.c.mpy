{
  "module_name": "spi.c",
  "hash_id": "f4181e0d1e65d0ad6b56d8e8d02a9f2e269fd819998c83559c39e4d81f74e7ff",
  "original_prompt": "Ingested from linux-6.6.14/drivers/spi/spi.c",
  "human_readable_source": "\n\n\n\n\n\n#include <linux/acpi.h>\n#include <linux/cache.h>\n#include <linux/clk/clk-conf.h>\n#include <linux/delay.h>\n#include <linux/device.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/export.h>\n#include <linux/gpio/consumer.h>\n#include <linux/highmem.h>\n#include <linux/idr.h>\n#include <linux/init.h>\n#include <linux/ioport.h>\n#include <linux/kernel.h>\n#include <linux/kthread.h>\n#include <linux/mod_devicetable.h>\n#include <linux/mutex.h>\n#include <linux/of_device.h>\n#include <linux/of_irq.h>\n#include <linux/percpu.h>\n#include <linux/platform_data/x86/apple.h>\n#include <linux/pm_domain.h>\n#include <linux/pm_runtime.h>\n#include <linux/property.h>\n#include <linux/ptp_clock_kernel.h>\n#include <linux/sched/rt.h>\n#include <linux/slab.h>\n#include <linux/spi/spi.h>\n#include <linux/spi/spi-mem.h>\n#include <uapi/linux/sched/types.h>\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/spi.h>\nEXPORT_TRACEPOINT_SYMBOL(spi_transfer_start);\nEXPORT_TRACEPOINT_SYMBOL(spi_transfer_stop);\n\n#include \"internals.h\"\n\nstatic DEFINE_IDR(spi_master_idr);\n\nstatic void spidev_release(struct device *dev)\n{\n\tstruct spi_device\t*spi = to_spi_device(dev);\n\n\tspi_controller_put(spi->controller);\n\tkfree(spi->driver_override);\n\tfree_percpu(spi->pcpu_statistics);\n\tkfree(spi);\n}\n\nstatic ssize_t\nmodalias_show(struct device *dev, struct device_attribute *a, char *buf)\n{\n\tconst struct spi_device\t*spi = to_spi_device(dev);\n\tint len;\n\n\tlen = acpi_device_modalias(dev, buf, PAGE_SIZE - 1);\n\tif (len != -ENODEV)\n\t\treturn len;\n\n\treturn sysfs_emit(buf, \"%s%s\\n\", SPI_MODULE_PREFIX, spi->modalias);\n}\nstatic DEVICE_ATTR_RO(modalias);\n\nstatic ssize_t driver_override_store(struct device *dev,\n\t\t\t\t     struct device_attribute *a,\n\t\t\t\t     const char *buf, size_t count)\n{\n\tstruct spi_device *spi = to_spi_device(dev);\n\tint ret;\n\n\tret = driver_set_override(dev, &spi->driver_override, buf, count);\n\tif (ret)\n\t\treturn ret;\n\n\treturn count;\n}\n\nstatic ssize_t driver_override_show(struct device *dev,\n\t\t\t\t    struct device_attribute *a, char *buf)\n{\n\tconst struct spi_device *spi = to_spi_device(dev);\n\tssize_t len;\n\n\tdevice_lock(dev);\n\tlen = sysfs_emit(buf, \"%s\\n\", spi->driver_override ? : \"\");\n\tdevice_unlock(dev);\n\treturn len;\n}\nstatic DEVICE_ATTR_RW(driver_override);\n\nstatic struct spi_statistics __percpu *spi_alloc_pcpu_stats(struct device *dev)\n{\n\tstruct spi_statistics __percpu *pcpu_stats;\n\n\tif (dev)\n\t\tpcpu_stats = devm_alloc_percpu(dev, struct spi_statistics);\n\telse\n\t\tpcpu_stats = alloc_percpu_gfp(struct spi_statistics, GFP_KERNEL);\n\n\tif (pcpu_stats) {\n\t\tint cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tstruct spi_statistics *stat;\n\n\t\t\tstat = per_cpu_ptr(pcpu_stats, cpu);\n\t\t\tu64_stats_init(&stat->syncp);\n\t\t}\n\t}\n\treturn pcpu_stats;\n}\n\nstatic ssize_t spi_emit_pcpu_stats(struct spi_statistics __percpu *stat,\n\t\t\t\t   char *buf, size_t offset)\n{\n\tu64 val = 0;\n\tint i;\n\n\tfor_each_possible_cpu(i) {\n\t\tconst struct spi_statistics *pcpu_stats;\n\t\tu64_stats_t *field;\n\t\tunsigned int start;\n\t\tu64 inc;\n\n\t\tpcpu_stats = per_cpu_ptr(stat, i);\n\t\tfield = (void *)pcpu_stats + offset;\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&pcpu_stats->syncp);\n\t\t\tinc = u64_stats_read(field);\n\t\t} while (u64_stats_fetch_retry(&pcpu_stats->syncp, start));\n\t\tval += inc;\n\t}\n\treturn sysfs_emit(buf, \"%llu\\n\", val);\n}\n\n#define SPI_STATISTICS_ATTRS(field, file)\t\t\t\t\\\nstatic ssize_t spi_controller_##field##_show(struct device *dev,\t\\\n\t\t\t\t\t     struct device_attribute *attr, \\\n\t\t\t\t\t     char *buf)\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tstruct spi_controller *ctlr = container_of(dev,\t\t\t\\\n\t\t\t\t\t struct spi_controller, dev);\t\\\n\treturn spi_statistics_##field##_show(ctlr->pcpu_statistics, buf); \\\n}\t\t\t\t\t\t\t\t\t\\\nstatic struct device_attribute dev_attr_spi_controller_##field = {\t\\\n\t.attr = { .name = file, .mode = 0444 },\t\t\t\t\\\n\t.show = spi_controller_##field##_show,\t\t\t\t\\\n};\t\t\t\t\t\t\t\t\t\\\nstatic ssize_t spi_device_##field##_show(struct device *dev,\t\t\\\n\t\t\t\t\t struct device_attribute *attr,\t\\\n\t\t\t\t\tchar *buf)\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tstruct spi_device *spi = to_spi_device(dev);\t\t\t\\\n\treturn spi_statistics_##field##_show(spi->pcpu_statistics, buf); \\\n}\t\t\t\t\t\t\t\t\t\\\nstatic struct device_attribute dev_attr_spi_device_##field = {\t\t\\\n\t.attr = { .name = file, .mode = 0444 },\t\t\t\t\\\n\t.show = spi_device_##field##_show,\t\t\t\t\\\n}\n\n#define SPI_STATISTICS_SHOW_NAME(name, file, field)\t\t\t\\\nstatic ssize_t spi_statistics_##name##_show(struct spi_statistics __percpu *stat, \\\n\t\t\t\t\t    char *buf)\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\treturn spi_emit_pcpu_stats(stat, buf,\t\t\t\t\\\n\t\t\toffsetof(struct spi_statistics, field));\t\\\n}\t\t\t\t\t\t\t\t\t\\\nSPI_STATISTICS_ATTRS(name, file)\n\n#define SPI_STATISTICS_SHOW(field)\t\t\t\t\t\\\n\tSPI_STATISTICS_SHOW_NAME(field, __stringify(field),\t\t\\\n\t\t\t\t field)\n\nSPI_STATISTICS_SHOW(messages);\nSPI_STATISTICS_SHOW(transfers);\nSPI_STATISTICS_SHOW(errors);\nSPI_STATISTICS_SHOW(timedout);\n\nSPI_STATISTICS_SHOW(spi_sync);\nSPI_STATISTICS_SHOW(spi_sync_immediate);\nSPI_STATISTICS_SHOW(spi_async);\n\nSPI_STATISTICS_SHOW(bytes);\nSPI_STATISTICS_SHOW(bytes_rx);\nSPI_STATISTICS_SHOW(bytes_tx);\n\n#define SPI_STATISTICS_TRANSFER_BYTES_HISTO(index, number)\t\t\\\n\tSPI_STATISTICS_SHOW_NAME(transfer_bytes_histo##index,\t\t\\\n\t\t\t\t \"transfer_bytes_histo_\" number,\t\\\n\t\t\t\t transfer_bytes_histo[index])\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(0,  \"0-1\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(1,  \"2-3\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(2,  \"4-7\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(3,  \"8-15\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(4,  \"16-31\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(5,  \"32-63\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(6,  \"64-127\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(7,  \"128-255\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(8,  \"256-511\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(9,  \"512-1023\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(10, \"1024-2047\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(11, \"2048-4095\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(12, \"4096-8191\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(13, \"8192-16383\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(14, \"16384-32767\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(15, \"32768-65535\");\nSPI_STATISTICS_TRANSFER_BYTES_HISTO(16, \"65536+\");\n\nSPI_STATISTICS_SHOW(transfers_split_maxsize);\n\nstatic struct attribute *spi_dev_attrs[] = {\n\t&dev_attr_modalias.attr,\n\t&dev_attr_driver_override.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group spi_dev_group = {\n\t.attrs  = spi_dev_attrs,\n};\n\nstatic struct attribute *spi_device_statistics_attrs[] = {\n\t&dev_attr_spi_device_messages.attr,\n\t&dev_attr_spi_device_transfers.attr,\n\t&dev_attr_spi_device_errors.attr,\n\t&dev_attr_spi_device_timedout.attr,\n\t&dev_attr_spi_device_spi_sync.attr,\n\t&dev_attr_spi_device_spi_sync_immediate.attr,\n\t&dev_attr_spi_device_spi_async.attr,\n\t&dev_attr_spi_device_bytes.attr,\n\t&dev_attr_spi_device_bytes_rx.attr,\n\t&dev_attr_spi_device_bytes_tx.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo0.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo1.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo2.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo3.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo4.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo5.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo6.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo7.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo8.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo9.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo10.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo11.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo12.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo13.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo14.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo15.attr,\n\t&dev_attr_spi_device_transfer_bytes_histo16.attr,\n\t&dev_attr_spi_device_transfers_split_maxsize.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group spi_device_statistics_group = {\n\t.name  = \"statistics\",\n\t.attrs  = spi_device_statistics_attrs,\n};\n\nstatic const struct attribute_group *spi_dev_groups[] = {\n\t&spi_dev_group,\n\t&spi_device_statistics_group,\n\tNULL,\n};\n\nstatic struct attribute *spi_controller_statistics_attrs[] = {\n\t&dev_attr_spi_controller_messages.attr,\n\t&dev_attr_spi_controller_transfers.attr,\n\t&dev_attr_spi_controller_errors.attr,\n\t&dev_attr_spi_controller_timedout.attr,\n\t&dev_attr_spi_controller_spi_sync.attr,\n\t&dev_attr_spi_controller_spi_sync_immediate.attr,\n\t&dev_attr_spi_controller_spi_async.attr,\n\t&dev_attr_spi_controller_bytes.attr,\n\t&dev_attr_spi_controller_bytes_rx.attr,\n\t&dev_attr_spi_controller_bytes_tx.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo0.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo1.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo2.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo3.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo4.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo5.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo6.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo7.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo8.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo9.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo10.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo11.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo12.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo13.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo14.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo15.attr,\n\t&dev_attr_spi_controller_transfer_bytes_histo16.attr,\n\t&dev_attr_spi_controller_transfers_split_maxsize.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group spi_controller_statistics_group = {\n\t.name  = \"statistics\",\n\t.attrs  = spi_controller_statistics_attrs,\n};\n\nstatic const struct attribute_group *spi_master_groups[] = {\n\t&spi_controller_statistics_group,\n\tNULL,\n};\n\nstatic void spi_statistics_add_transfer_stats(struct spi_statistics __percpu *pcpu_stats,\n\t\t\t\t\t      struct spi_transfer *xfer,\n\t\t\t\t\t      struct spi_controller *ctlr)\n{\n\tint l2len = min(fls(xfer->len), SPI_STATISTICS_HISTO_SIZE) - 1;\n\tstruct spi_statistics *stats;\n\n\tif (l2len < 0)\n\t\tl2len = 0;\n\n\tget_cpu();\n\tstats = this_cpu_ptr(pcpu_stats);\n\tu64_stats_update_begin(&stats->syncp);\n\n\tu64_stats_inc(&stats->transfers);\n\tu64_stats_inc(&stats->transfer_bytes_histo[l2len]);\n\n\tu64_stats_add(&stats->bytes, xfer->len);\n\tif ((xfer->tx_buf) &&\n\t    (xfer->tx_buf != ctlr->dummy_tx))\n\t\tu64_stats_add(&stats->bytes_tx, xfer->len);\n\tif ((xfer->rx_buf) &&\n\t    (xfer->rx_buf != ctlr->dummy_rx))\n\t\tu64_stats_add(&stats->bytes_rx, xfer->len);\n\n\tu64_stats_update_end(&stats->syncp);\n\tput_cpu();\n}\n\n \nstatic const struct spi_device_id *spi_match_id(const struct spi_device_id *id, const char *name)\n{\n\twhile (id->name[0]) {\n\t\tif (!strcmp(name, id->name))\n\t\t\treturn id;\n\t\tid++;\n\t}\n\treturn NULL;\n}\n\nconst struct spi_device_id *spi_get_device_id(const struct spi_device *sdev)\n{\n\tconst struct spi_driver *sdrv = to_spi_driver(sdev->dev.driver);\n\n\treturn spi_match_id(sdrv->id_table, sdev->modalias);\n}\nEXPORT_SYMBOL_GPL(spi_get_device_id);\n\nconst void *spi_get_device_match_data(const struct spi_device *sdev)\n{\n\tconst void *match;\n\n\tmatch = device_get_match_data(&sdev->dev);\n\tif (match)\n\t\treturn match;\n\n\treturn (const void *)spi_get_device_id(sdev)->driver_data;\n}\nEXPORT_SYMBOL_GPL(spi_get_device_match_data);\n\nstatic int spi_match_device(struct device *dev, struct device_driver *drv)\n{\n\tconst struct spi_device\t*spi = to_spi_device(dev);\n\tconst struct spi_driver\t*sdrv = to_spi_driver(drv);\n\n\t \n\tif (spi->driver_override)\n\t\treturn strcmp(spi->driver_override, drv->name) == 0;\n\n\t \n\tif (of_driver_match_device(dev, drv))\n\t\treturn 1;\n\n\t \n\tif (acpi_driver_match_device(dev, drv))\n\t\treturn 1;\n\n\tif (sdrv->id_table)\n\t\treturn !!spi_match_id(sdrv->id_table, spi->modalias);\n\n\treturn strcmp(spi->modalias, drv->name) == 0;\n}\n\nstatic int spi_uevent(const struct device *dev, struct kobj_uevent_env *env)\n{\n\tconst struct spi_device\t\t*spi = to_spi_device(dev);\n\tint rc;\n\n\trc = acpi_device_uevent_modalias(dev, env);\n\tif (rc != -ENODEV)\n\t\treturn rc;\n\n\treturn add_uevent_var(env, \"MODALIAS=%s%s\", SPI_MODULE_PREFIX, spi->modalias);\n}\n\nstatic int spi_probe(struct device *dev)\n{\n\tconst struct spi_driver\t\t*sdrv = to_spi_driver(dev->driver);\n\tstruct spi_device\t\t*spi = to_spi_device(dev);\n\tint ret;\n\n\tret = of_clk_set_defaults(dev->of_node, false);\n\tif (ret)\n\t\treturn ret;\n\n\tif (dev->of_node) {\n\t\tspi->irq = of_irq_get(dev->of_node, 0);\n\t\tif (spi->irq == -EPROBE_DEFER)\n\t\t\treturn -EPROBE_DEFER;\n\t\tif (spi->irq < 0)\n\t\t\tspi->irq = 0;\n\t}\n\n\tret = dev_pm_domain_attach(dev, true);\n\tif (ret)\n\t\treturn ret;\n\n\tif (sdrv->probe) {\n\t\tret = sdrv->probe(spi);\n\t\tif (ret)\n\t\t\tdev_pm_domain_detach(dev, true);\n\t}\n\n\treturn ret;\n}\n\nstatic void spi_remove(struct device *dev)\n{\n\tconst struct spi_driver\t\t*sdrv = to_spi_driver(dev->driver);\n\n\tif (sdrv->remove)\n\t\tsdrv->remove(to_spi_device(dev));\n\n\tdev_pm_domain_detach(dev, true);\n}\n\nstatic void spi_shutdown(struct device *dev)\n{\n\tif (dev->driver) {\n\t\tconst struct spi_driver\t*sdrv = to_spi_driver(dev->driver);\n\n\t\tif (sdrv->shutdown)\n\t\t\tsdrv->shutdown(to_spi_device(dev));\n\t}\n}\n\nstruct bus_type spi_bus_type = {\n\t.name\t\t= \"spi\",\n\t.dev_groups\t= spi_dev_groups,\n\t.match\t\t= spi_match_device,\n\t.uevent\t\t= spi_uevent,\n\t.probe\t\t= spi_probe,\n\t.remove\t\t= spi_remove,\n\t.shutdown\t= spi_shutdown,\n};\nEXPORT_SYMBOL_GPL(spi_bus_type);\n\n \nint __spi_register_driver(struct module *owner, struct spi_driver *sdrv)\n{\n\tsdrv->driver.owner = owner;\n\tsdrv->driver.bus = &spi_bus_type;\n\n\t \n\tif (sdrv->driver.of_match_table) {\n\t\tconst struct of_device_id *of_id;\n\n\t\tfor (of_id = sdrv->driver.of_match_table; of_id->compatible[0];\n\t\t     of_id++) {\n\t\t\tconst char *of_name;\n\n\t\t\t \n\t\t\tof_name = strnchr(of_id->compatible,\n\t\t\t\t\t  sizeof(of_id->compatible), ',');\n\t\t\tif (of_name)\n\t\t\t\tof_name++;\n\t\t\telse\n\t\t\t\tof_name = of_id->compatible;\n\n\t\t\tif (sdrv->id_table) {\n\t\t\t\tconst struct spi_device_id *spi_id;\n\n\t\t\t\tspi_id = spi_match_id(sdrv->id_table, of_name);\n\t\t\t\tif (spi_id)\n\t\t\t\t\tcontinue;\n\t\t\t} else {\n\t\t\t\tif (strcmp(sdrv->driver.name, of_name) == 0)\n\t\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tpr_warn(\"SPI driver %s has no spi_device_id for %s\\n\",\n\t\t\t\tsdrv->driver.name, of_id->compatible);\n\t\t}\n\t}\n\n\treturn driver_register(&sdrv->driver);\n}\nEXPORT_SYMBOL_GPL(__spi_register_driver);\n\n \n\n \n\nstruct boardinfo {\n\tstruct list_head\tlist;\n\tstruct spi_board_info\tboard_info;\n};\n\nstatic LIST_HEAD(board_list);\nstatic LIST_HEAD(spi_controller_list);\n\n \nstatic DEFINE_MUTEX(board_lock);\n\n \nstruct spi_device *spi_alloc_device(struct spi_controller *ctlr)\n{\n\tstruct spi_device\t*spi;\n\n\tif (!spi_controller_get(ctlr))\n\t\treturn NULL;\n\n\tspi = kzalloc(sizeof(*spi), GFP_KERNEL);\n\tif (!spi) {\n\t\tspi_controller_put(ctlr);\n\t\treturn NULL;\n\t}\n\n\tspi->pcpu_statistics = spi_alloc_pcpu_stats(NULL);\n\tif (!spi->pcpu_statistics) {\n\t\tkfree(spi);\n\t\tspi_controller_put(ctlr);\n\t\treturn NULL;\n\t}\n\n\tspi->master = spi->controller = ctlr;\n\tspi->dev.parent = &ctlr->dev;\n\tspi->dev.bus = &spi_bus_type;\n\tspi->dev.release = spidev_release;\n\tspi->mode = ctlr->buswidth_override_bits;\n\n\tdevice_initialize(&spi->dev);\n\treturn spi;\n}\nEXPORT_SYMBOL_GPL(spi_alloc_device);\n\nstatic void spi_dev_set_name(struct spi_device *spi)\n{\n\tstruct acpi_device *adev = ACPI_COMPANION(&spi->dev);\n\n\tif (adev) {\n\t\tdev_set_name(&spi->dev, \"spi-%s\", acpi_dev_name(adev));\n\t\treturn;\n\t}\n\n\tdev_set_name(&spi->dev, \"%s.%u\", dev_name(&spi->controller->dev),\n\t\t     spi_get_chipselect(spi, 0));\n}\n\nstatic int spi_dev_check(struct device *dev, void *data)\n{\n\tstruct spi_device *spi = to_spi_device(dev);\n\tstruct spi_device *new_spi = data;\n\n\tif (spi->controller == new_spi->controller &&\n\t    spi_get_chipselect(spi, 0) == spi_get_chipselect(new_spi, 0))\n\t\treturn -EBUSY;\n\treturn 0;\n}\n\nstatic void spi_cleanup(struct spi_device *spi)\n{\n\tif (spi->controller->cleanup)\n\t\tspi->controller->cleanup(spi);\n}\n\nstatic int __spi_add_device(struct spi_device *spi)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\tstruct device *dev = ctlr->dev.parent;\n\tint status;\n\n\t \n\tif (spi_get_chipselect(spi, 0) >= ctlr->num_chipselect) {\n\t\tdev_err(dev, \"cs%d >= max %d\\n\", spi_get_chipselect(spi, 0),\n\t\t\tctlr->num_chipselect);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tspi_dev_set_name(spi);\n\n\t \n\tstatus = bus_for_each_dev(&spi_bus_type, NULL, spi, spi_dev_check);\n\tif (status) {\n\t\tdev_err(dev, \"chipselect %d already in use\\n\",\n\t\t\t\tspi_get_chipselect(spi, 0));\n\t\treturn status;\n\t}\n\n\t \n\tif (IS_ENABLED(CONFIG_SPI_DYNAMIC) &&\n\t    !device_is_registered(&ctlr->dev)) {\n\t\treturn -ENODEV;\n\t}\n\n\tif (ctlr->cs_gpiods)\n\t\tspi_set_csgpiod(spi, 0, ctlr->cs_gpiods[spi_get_chipselect(spi, 0)]);\n\n\t \n\tstatus = spi_setup(spi);\n\tif (status < 0) {\n\t\tdev_err(dev, \"can't setup %s, status %d\\n\",\n\t\t\t\tdev_name(&spi->dev), status);\n\t\treturn status;\n\t}\n\n\t \n\tstatus = device_add(&spi->dev);\n\tif (status < 0) {\n\t\tdev_err(dev, \"can't add %s, status %d\\n\",\n\t\t\t\tdev_name(&spi->dev), status);\n\t\tspi_cleanup(spi);\n\t} else {\n\t\tdev_dbg(dev, \"registered child %s\\n\", dev_name(&spi->dev));\n\t}\n\n\treturn status;\n}\n\n \nint spi_add_device(struct spi_device *spi)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\tint status;\n\n\tmutex_lock(&ctlr->add_lock);\n\tstatus = __spi_add_device(spi);\n\tmutex_unlock(&ctlr->add_lock);\n\treturn status;\n}\nEXPORT_SYMBOL_GPL(spi_add_device);\n\n \nstruct spi_device *spi_new_device(struct spi_controller *ctlr,\n\t\t\t\t  struct spi_board_info *chip)\n{\n\tstruct spi_device\t*proxy;\n\tint\t\t\tstatus;\n\n\t \n\n\tproxy = spi_alloc_device(ctlr);\n\tif (!proxy)\n\t\treturn NULL;\n\n\tWARN_ON(strlen(chip->modalias) >= sizeof(proxy->modalias));\n\n\tspi_set_chipselect(proxy, 0, chip->chip_select);\n\tproxy->max_speed_hz = chip->max_speed_hz;\n\tproxy->mode = chip->mode;\n\tproxy->irq = chip->irq;\n\tstrscpy(proxy->modalias, chip->modalias, sizeof(proxy->modalias));\n\tproxy->dev.platform_data = (void *) chip->platform_data;\n\tproxy->controller_data = chip->controller_data;\n\tproxy->controller_state = NULL;\n\n\tif (chip->swnode) {\n\t\tstatus = device_add_software_node(&proxy->dev, chip->swnode);\n\t\tif (status) {\n\t\t\tdev_err(&ctlr->dev, \"failed to add software node to '%s': %d\\n\",\n\t\t\t\tchip->modalias, status);\n\t\t\tgoto err_dev_put;\n\t\t}\n\t}\n\n\tstatus = spi_add_device(proxy);\n\tif (status < 0)\n\t\tgoto err_dev_put;\n\n\treturn proxy;\n\nerr_dev_put:\n\tdevice_remove_software_node(&proxy->dev);\n\tspi_dev_put(proxy);\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(spi_new_device);\n\n \nvoid spi_unregister_device(struct spi_device *spi)\n{\n\tif (!spi)\n\t\treturn;\n\n\tif (spi->dev.of_node) {\n\t\tof_node_clear_flag(spi->dev.of_node, OF_POPULATED);\n\t\tof_node_put(spi->dev.of_node);\n\t}\n\tif (ACPI_COMPANION(&spi->dev))\n\t\tacpi_device_clear_enumerated(ACPI_COMPANION(&spi->dev));\n\tdevice_remove_software_node(&spi->dev);\n\tdevice_del(&spi->dev);\n\tspi_cleanup(spi);\n\tput_device(&spi->dev);\n}\nEXPORT_SYMBOL_GPL(spi_unregister_device);\n\nstatic void spi_match_controller_to_boardinfo(struct spi_controller *ctlr,\n\t\t\t\t\t      struct spi_board_info *bi)\n{\n\tstruct spi_device *dev;\n\n\tif (ctlr->bus_num != bi->bus_num)\n\t\treturn;\n\n\tdev = spi_new_device(ctlr, bi);\n\tif (!dev)\n\t\tdev_err(ctlr->dev.parent, \"can't create new device for %s\\n\",\n\t\t\tbi->modalias);\n}\n\n \nint spi_register_board_info(struct spi_board_info const *info, unsigned n)\n{\n\tstruct boardinfo *bi;\n\tint i;\n\n\tif (!n)\n\t\treturn 0;\n\n\tbi = kcalloc(n, sizeof(*bi), GFP_KERNEL);\n\tif (!bi)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < n; i++, bi++, info++) {\n\t\tstruct spi_controller *ctlr;\n\n\t\tmemcpy(&bi->board_info, info, sizeof(*info));\n\n\t\tmutex_lock(&board_lock);\n\t\tlist_add_tail(&bi->list, &board_list);\n\t\tlist_for_each_entry(ctlr, &spi_controller_list, list)\n\t\t\tspi_match_controller_to_boardinfo(ctlr,\n\t\t\t\t\t\t\t  &bi->board_info);\n\t\tmutex_unlock(&board_lock);\n\t}\n\n\treturn 0;\n}\n\n \n\n \n\n \nstatic void *spi_res_alloc(struct spi_device *spi, spi_res_release_t release,\n\t\t\t   size_t size, gfp_t gfp)\n{\n\tstruct spi_res *sres;\n\n\tsres = kzalloc(sizeof(*sres) + size, gfp);\n\tif (!sres)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&sres->entry);\n\tsres->release = release;\n\n\treturn sres->data;\n}\n\n \nstatic void spi_res_free(void *res)\n{\n\tstruct spi_res *sres = container_of(res, struct spi_res, data);\n\n\tif (!res)\n\t\treturn;\n\n\tWARN_ON(!list_empty(&sres->entry));\n\tkfree(sres);\n}\n\n \nstatic void spi_res_add(struct spi_message *message, void *res)\n{\n\tstruct spi_res *sres = container_of(res, struct spi_res, data);\n\n\tWARN_ON(!list_empty(&sres->entry));\n\tlist_add_tail(&sres->entry, &message->resources);\n}\n\n \nstatic void spi_res_release(struct spi_controller *ctlr, struct spi_message *message)\n{\n\tstruct spi_res *res, *tmp;\n\n\tlist_for_each_entry_safe_reverse(res, tmp, &message->resources, entry) {\n\t\tif (res->release)\n\t\t\tres->release(ctlr, message, res->data);\n\n\t\tlist_del(&res->entry);\n\n\t\tkfree(res);\n\t}\n}\n\n \n\nstatic void spi_set_cs(struct spi_device *spi, bool enable, bool force)\n{\n\tbool activate = enable;\n\n\t \n\tif (!force && ((enable && spi->controller->last_cs == spi_get_chipselect(spi, 0)) ||\n\t\t       (!enable && spi->controller->last_cs != spi_get_chipselect(spi, 0))) &&\n\t    (spi->controller->last_cs_mode_high == (spi->mode & SPI_CS_HIGH)))\n\t\treturn;\n\n\ttrace_spi_set_cs(spi, activate);\n\n\tspi->controller->last_cs = enable ? spi_get_chipselect(spi, 0) : -1;\n\tspi->controller->last_cs_mode_high = spi->mode & SPI_CS_HIGH;\n\n\tif ((spi_get_csgpiod(spi, 0) || !spi->controller->set_cs_timing) && !activate)\n\t\tspi_delay_exec(&spi->cs_hold, NULL);\n\n\tif (spi->mode & SPI_CS_HIGH)\n\t\tenable = !enable;\n\n\tif (spi_get_csgpiod(spi, 0)) {\n\t\tif (!(spi->mode & SPI_NO_CS)) {\n\t\t\t \n\t\t\tif (has_acpi_companion(&spi->dev))\n\t\t\t\tgpiod_set_value_cansleep(spi_get_csgpiod(spi, 0), !enable);\n\t\t\telse\n\t\t\t\t \n\t\t\t\tgpiod_set_value_cansleep(spi_get_csgpiod(spi, 0), activate);\n\t\t}\n\t\t \n\t\tif ((spi->controller->flags & SPI_CONTROLLER_GPIO_SS) &&\n\t\t    spi->controller->set_cs)\n\t\t\tspi->controller->set_cs(spi, !enable);\n\t} else if (spi->controller->set_cs) {\n\t\tspi->controller->set_cs(spi, !enable);\n\t}\n\n\tif (spi_get_csgpiod(spi, 0) || !spi->controller->set_cs_timing) {\n\t\tif (activate)\n\t\t\tspi_delay_exec(&spi->cs_setup, NULL);\n\t\telse\n\t\t\tspi_delay_exec(&spi->cs_inactive, NULL);\n\t}\n}\n\n#ifdef CONFIG_HAS_DMA\nstatic int spi_map_buf_attrs(struct spi_controller *ctlr, struct device *dev,\n\t\t\t     struct sg_table *sgt, void *buf, size_t len,\n\t\t\t     enum dma_data_direction dir, unsigned long attrs)\n{\n\tconst bool vmalloced_buf = is_vmalloc_addr(buf);\n\tunsigned int max_seg_size = dma_get_max_seg_size(dev);\n#ifdef CONFIG_HIGHMEM\n\tconst bool kmap_buf = ((unsigned long)buf >= PKMAP_BASE &&\n\t\t\t\t(unsigned long)buf < (PKMAP_BASE +\n\t\t\t\t\t(LAST_PKMAP * PAGE_SIZE)));\n#else\n\tconst bool kmap_buf = false;\n#endif\n\tint desc_len;\n\tint sgs;\n\tstruct page *vm_page;\n\tstruct scatterlist *sg;\n\tvoid *sg_buf;\n\tsize_t min;\n\tint i, ret;\n\n\tif (vmalloced_buf || kmap_buf) {\n\t\tdesc_len = min_t(unsigned long, max_seg_size, PAGE_SIZE);\n\t\tsgs = DIV_ROUND_UP(len + offset_in_page(buf), desc_len);\n\t} else if (virt_addr_valid(buf)) {\n\t\tdesc_len = min_t(size_t, max_seg_size, ctlr->max_dma_len);\n\t\tsgs = DIV_ROUND_UP(len, desc_len);\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\tret = sg_alloc_table(sgt, sgs, GFP_KERNEL);\n\tif (ret != 0)\n\t\treturn ret;\n\n\tsg = &sgt->sgl[0];\n\tfor (i = 0; i < sgs; i++) {\n\n\t\tif (vmalloced_buf || kmap_buf) {\n\t\t\t \n\t\t\tmin = min_t(size_t, desc_len,\n\t\t\t\t    min_t(size_t, len,\n\t\t\t\t\t  PAGE_SIZE - offset_in_page(buf)));\n\t\t\tif (vmalloced_buf)\n\t\t\t\tvm_page = vmalloc_to_page(buf);\n\t\t\telse\n\t\t\t\tvm_page = kmap_to_page(buf);\n\t\t\tif (!vm_page) {\n\t\t\t\tsg_free_table(sgt);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tsg_set_page(sg, vm_page,\n\t\t\t\t    min, offset_in_page(buf));\n\t\t} else {\n\t\t\tmin = min_t(size_t, len, desc_len);\n\t\t\tsg_buf = buf;\n\t\t\tsg_set_buf(sg, sg_buf, min);\n\t\t}\n\n\t\tbuf += min;\n\t\tlen -= min;\n\t\tsg = sg_next(sg);\n\t}\n\n\tret = dma_map_sgtable(dev, sgt, dir, attrs);\n\tif (ret < 0) {\n\t\tsg_free_table(sgt);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint spi_map_buf(struct spi_controller *ctlr, struct device *dev,\n\t\tstruct sg_table *sgt, void *buf, size_t len,\n\t\tenum dma_data_direction dir)\n{\n\treturn spi_map_buf_attrs(ctlr, dev, sgt, buf, len, dir, 0);\n}\n\nstatic void spi_unmap_buf_attrs(struct spi_controller *ctlr,\n\t\t\t\tstruct device *dev, struct sg_table *sgt,\n\t\t\t\tenum dma_data_direction dir,\n\t\t\t\tunsigned long attrs)\n{\n\tif (sgt->orig_nents) {\n\t\tdma_unmap_sgtable(dev, sgt, dir, attrs);\n\t\tsg_free_table(sgt);\n\t\tsgt->orig_nents = 0;\n\t\tsgt->nents = 0;\n\t}\n}\n\nvoid spi_unmap_buf(struct spi_controller *ctlr, struct device *dev,\n\t\t   struct sg_table *sgt, enum dma_data_direction dir)\n{\n\tspi_unmap_buf_attrs(ctlr, dev, sgt, dir, 0);\n}\n\nstatic int __spi_map_msg(struct spi_controller *ctlr, struct spi_message *msg)\n{\n\tstruct device *tx_dev, *rx_dev;\n\tstruct spi_transfer *xfer;\n\tint ret;\n\n\tif (!ctlr->can_dma)\n\t\treturn 0;\n\n\tif (ctlr->dma_tx)\n\t\ttx_dev = ctlr->dma_tx->device->dev;\n\telse if (ctlr->dma_map_dev)\n\t\ttx_dev = ctlr->dma_map_dev;\n\telse\n\t\ttx_dev = ctlr->dev.parent;\n\n\tif (ctlr->dma_rx)\n\t\trx_dev = ctlr->dma_rx->device->dev;\n\telse if (ctlr->dma_map_dev)\n\t\trx_dev = ctlr->dma_map_dev;\n\telse\n\t\trx_dev = ctlr->dev.parent;\n\n\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\t \n\t\tunsigned long attrs = DMA_ATTR_SKIP_CPU_SYNC;\n\n\t\tif (!ctlr->can_dma(ctlr, msg->spi, xfer))\n\t\t\tcontinue;\n\n\t\tif (xfer->tx_buf != NULL) {\n\t\t\tret = spi_map_buf_attrs(ctlr, tx_dev, &xfer->tx_sg,\n\t\t\t\t\t\t(void *)xfer->tx_buf,\n\t\t\t\t\t\txfer->len, DMA_TO_DEVICE,\n\t\t\t\t\t\tattrs);\n\t\t\tif (ret != 0)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tif (xfer->rx_buf != NULL) {\n\t\t\tret = spi_map_buf_attrs(ctlr, rx_dev, &xfer->rx_sg,\n\t\t\t\t\t\txfer->rx_buf, xfer->len,\n\t\t\t\t\t\tDMA_FROM_DEVICE, attrs);\n\t\t\tif (ret != 0) {\n\t\t\t\tspi_unmap_buf_attrs(ctlr, tx_dev,\n\t\t\t\t\t\t&xfer->tx_sg, DMA_TO_DEVICE,\n\t\t\t\t\t\tattrs);\n\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\tctlr->cur_rx_dma_dev = rx_dev;\n\tctlr->cur_tx_dma_dev = tx_dev;\n\tctlr->cur_msg_mapped = true;\n\n\treturn 0;\n}\n\nstatic int __spi_unmap_msg(struct spi_controller *ctlr, struct spi_message *msg)\n{\n\tstruct device *rx_dev = ctlr->cur_rx_dma_dev;\n\tstruct device *tx_dev = ctlr->cur_tx_dma_dev;\n\tstruct spi_transfer *xfer;\n\n\tif (!ctlr->cur_msg_mapped || !ctlr->can_dma)\n\t\treturn 0;\n\n\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\t \n\t\tunsigned long attrs = DMA_ATTR_SKIP_CPU_SYNC;\n\n\t\tif (!ctlr->can_dma(ctlr, msg->spi, xfer))\n\t\t\tcontinue;\n\n\t\tspi_unmap_buf_attrs(ctlr, rx_dev, &xfer->rx_sg,\n\t\t\t\t    DMA_FROM_DEVICE, attrs);\n\t\tspi_unmap_buf_attrs(ctlr, tx_dev, &xfer->tx_sg,\n\t\t\t\t    DMA_TO_DEVICE, attrs);\n\t}\n\n\tctlr->cur_msg_mapped = false;\n\n\treturn 0;\n}\n\nstatic void spi_dma_sync_for_device(struct spi_controller *ctlr,\n\t\t\t\t    struct spi_transfer *xfer)\n{\n\tstruct device *rx_dev = ctlr->cur_rx_dma_dev;\n\tstruct device *tx_dev = ctlr->cur_tx_dma_dev;\n\n\tif (!ctlr->cur_msg_mapped)\n\t\treturn;\n\n\tif (xfer->tx_sg.orig_nents)\n\t\tdma_sync_sgtable_for_device(tx_dev, &xfer->tx_sg, DMA_TO_DEVICE);\n\tif (xfer->rx_sg.orig_nents)\n\t\tdma_sync_sgtable_for_device(rx_dev, &xfer->rx_sg, DMA_FROM_DEVICE);\n}\n\nstatic void spi_dma_sync_for_cpu(struct spi_controller *ctlr,\n\t\t\t\t struct spi_transfer *xfer)\n{\n\tstruct device *rx_dev = ctlr->cur_rx_dma_dev;\n\tstruct device *tx_dev = ctlr->cur_tx_dma_dev;\n\n\tif (!ctlr->cur_msg_mapped)\n\t\treturn;\n\n\tif (xfer->rx_sg.orig_nents)\n\t\tdma_sync_sgtable_for_cpu(rx_dev, &xfer->rx_sg, DMA_FROM_DEVICE);\n\tif (xfer->tx_sg.orig_nents)\n\t\tdma_sync_sgtable_for_cpu(tx_dev, &xfer->tx_sg, DMA_TO_DEVICE);\n}\n#else  \nstatic inline int __spi_map_msg(struct spi_controller *ctlr,\n\t\t\t\tstruct spi_message *msg)\n{\n\treturn 0;\n}\n\nstatic inline int __spi_unmap_msg(struct spi_controller *ctlr,\n\t\t\t\t  struct spi_message *msg)\n{\n\treturn 0;\n}\n\nstatic void spi_dma_sync_for_device(struct spi_controller *ctrl,\n\t\t\t\t    struct spi_transfer *xfer)\n{\n}\n\nstatic void spi_dma_sync_for_cpu(struct spi_controller *ctrl,\n\t\t\t\t struct spi_transfer *xfer)\n{\n}\n#endif  \n\nstatic inline int spi_unmap_msg(struct spi_controller *ctlr,\n\t\t\t\tstruct spi_message *msg)\n{\n\tstruct spi_transfer *xfer;\n\n\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\t \n\t\tif (xfer->tx_buf == ctlr->dummy_tx)\n\t\t\txfer->tx_buf = NULL;\n\t\tif (xfer->rx_buf == ctlr->dummy_rx)\n\t\t\txfer->rx_buf = NULL;\n\t}\n\n\treturn __spi_unmap_msg(ctlr, msg);\n}\n\nstatic int spi_map_msg(struct spi_controller *ctlr, struct spi_message *msg)\n{\n\tstruct spi_transfer *xfer;\n\tvoid *tmp;\n\tunsigned int max_tx, max_rx;\n\n\tif ((ctlr->flags & (SPI_CONTROLLER_MUST_RX | SPI_CONTROLLER_MUST_TX))\n\t\t&& !(msg->spi->mode & SPI_3WIRE)) {\n\t\tmax_tx = 0;\n\t\tmax_rx = 0;\n\n\t\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\t\tif ((ctlr->flags & SPI_CONTROLLER_MUST_TX) &&\n\t\t\t    !xfer->tx_buf)\n\t\t\t\tmax_tx = max(xfer->len, max_tx);\n\t\t\tif ((ctlr->flags & SPI_CONTROLLER_MUST_RX) &&\n\t\t\t    !xfer->rx_buf)\n\t\t\t\tmax_rx = max(xfer->len, max_rx);\n\t\t}\n\n\t\tif (max_tx) {\n\t\t\ttmp = krealloc(ctlr->dummy_tx, max_tx,\n\t\t\t\t       GFP_KERNEL | GFP_DMA | __GFP_ZERO);\n\t\t\tif (!tmp)\n\t\t\t\treturn -ENOMEM;\n\t\t\tctlr->dummy_tx = tmp;\n\t\t}\n\n\t\tif (max_rx) {\n\t\t\ttmp = krealloc(ctlr->dummy_rx, max_rx,\n\t\t\t\t       GFP_KERNEL | GFP_DMA);\n\t\t\tif (!tmp)\n\t\t\t\treturn -ENOMEM;\n\t\t\tctlr->dummy_rx = tmp;\n\t\t}\n\n\t\tif (max_tx || max_rx) {\n\t\t\tlist_for_each_entry(xfer, &msg->transfers,\n\t\t\t\t\t    transfer_list) {\n\t\t\t\tif (!xfer->len)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (!xfer->tx_buf)\n\t\t\t\t\txfer->tx_buf = ctlr->dummy_tx;\n\t\t\t\tif (!xfer->rx_buf)\n\t\t\t\t\txfer->rx_buf = ctlr->dummy_rx;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn __spi_map_msg(ctlr, msg);\n}\n\nstatic int spi_transfer_wait(struct spi_controller *ctlr,\n\t\t\t     struct spi_message *msg,\n\t\t\t     struct spi_transfer *xfer)\n{\n\tstruct spi_statistics __percpu *statm = ctlr->pcpu_statistics;\n\tstruct spi_statistics __percpu *stats = msg->spi->pcpu_statistics;\n\tu32 speed_hz = xfer->speed_hz;\n\tunsigned long long ms;\n\n\tif (spi_controller_is_slave(ctlr)) {\n\t\tif (wait_for_completion_interruptible(&ctlr->xfer_completion)) {\n\t\t\tdev_dbg(&msg->spi->dev, \"SPI transfer interrupted\\n\");\n\t\t\treturn -EINTR;\n\t\t}\n\t} else {\n\t\tif (!speed_hz)\n\t\t\tspeed_hz = 100000;\n\n\t\t \n\t\tms = 8LL * MSEC_PER_SEC * xfer->len;\n\t\tdo_div(ms, speed_hz);\n\n\t\t \n\t\tms += ms + 200;\n\t\tif (ms > UINT_MAX)\n\t\t\tms = UINT_MAX;\n\n\t\tms = wait_for_completion_timeout(&ctlr->xfer_completion,\n\t\t\t\t\t\t msecs_to_jiffies(ms));\n\n\t\tif (ms == 0) {\n\t\t\tSPI_STATISTICS_INCREMENT_FIELD(statm, timedout);\n\t\t\tSPI_STATISTICS_INCREMENT_FIELD(stats, timedout);\n\t\t\tdev_err(&msg->spi->dev,\n\t\t\t\t\"SPI transfer timed out\\n\");\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void _spi_transfer_delay_ns(u32 ns)\n{\n\tif (!ns)\n\t\treturn;\n\tif (ns <= NSEC_PER_USEC) {\n\t\tndelay(ns);\n\t} else {\n\t\tu32 us = DIV_ROUND_UP(ns, NSEC_PER_USEC);\n\n\t\tif (us <= 10)\n\t\t\tudelay(us);\n\t\telse\n\t\t\tusleep_range(us, us + DIV_ROUND_UP(us, 10));\n\t}\n}\n\nint spi_delay_to_ns(struct spi_delay *_delay, struct spi_transfer *xfer)\n{\n\tu32 delay = _delay->value;\n\tu32 unit = _delay->unit;\n\tu32 hz;\n\n\tif (!delay)\n\t\treturn 0;\n\n\tswitch (unit) {\n\tcase SPI_DELAY_UNIT_USECS:\n\t\tdelay *= NSEC_PER_USEC;\n\t\tbreak;\n\tcase SPI_DELAY_UNIT_NSECS:\n\t\t \n\t\tbreak;\n\tcase SPI_DELAY_UNIT_SCK:\n\t\t \n\t\tif (!xfer)\n\t\t\treturn -EINVAL;\n\t\t \n\t\thz = xfer->effective_speed_hz ?: xfer->speed_hz / 2;\n\t\tif (!hz)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tdelay *= DIV_ROUND_UP(NSEC_PER_SEC, hz);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn delay;\n}\nEXPORT_SYMBOL_GPL(spi_delay_to_ns);\n\nint spi_delay_exec(struct spi_delay *_delay, struct spi_transfer *xfer)\n{\n\tint delay;\n\n\tmight_sleep();\n\n\tif (!_delay)\n\t\treturn -EINVAL;\n\n\tdelay = spi_delay_to_ns(_delay, xfer);\n\tif (delay < 0)\n\t\treturn delay;\n\n\t_spi_transfer_delay_ns(delay);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(spi_delay_exec);\n\nstatic void _spi_transfer_cs_change_delay(struct spi_message *msg,\n\t\t\t\t\t  struct spi_transfer *xfer)\n{\n\tu32 default_delay_ns = 10 * NSEC_PER_USEC;\n\tu32 delay = xfer->cs_change_delay.value;\n\tu32 unit = xfer->cs_change_delay.unit;\n\tint ret;\n\n\t \n\tif (!delay) {\n\t\tif (unit == SPI_DELAY_UNIT_USECS)\n\t\t\t_spi_transfer_delay_ns(default_delay_ns);\n\t\treturn;\n\t}\n\n\tret = spi_delay_exec(&xfer->cs_change_delay, xfer);\n\tif (ret) {\n\t\tdev_err_once(&msg->spi->dev,\n\t\t\t     \"Use of unsupported delay unit %i, using default of %luus\\n\",\n\t\t\t     unit, default_delay_ns / NSEC_PER_USEC);\n\t\t_spi_transfer_delay_ns(default_delay_ns);\n\t}\n}\n\nvoid spi_transfer_cs_change_delay_exec(struct spi_message *msg,\n\t\t\t\t\t\t  struct spi_transfer *xfer)\n{\n\t_spi_transfer_cs_change_delay(msg, xfer);\n}\nEXPORT_SYMBOL_GPL(spi_transfer_cs_change_delay_exec);\n\n \nstatic int spi_transfer_one_message(struct spi_controller *ctlr,\n\t\t\t\t    struct spi_message *msg)\n{\n\tstruct spi_transfer *xfer;\n\tbool keep_cs = false;\n\tint ret = 0;\n\tstruct spi_statistics __percpu *statm = ctlr->pcpu_statistics;\n\tstruct spi_statistics __percpu *stats = msg->spi->pcpu_statistics;\n\n\txfer = list_first_entry(&msg->transfers, struct spi_transfer, transfer_list);\n\tspi_set_cs(msg->spi, !xfer->cs_off, false);\n\n\tSPI_STATISTICS_INCREMENT_FIELD(statm, messages);\n\tSPI_STATISTICS_INCREMENT_FIELD(stats, messages);\n\n\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\ttrace_spi_transfer_start(msg, xfer);\n\n\t\tspi_statistics_add_transfer_stats(statm, xfer, ctlr);\n\t\tspi_statistics_add_transfer_stats(stats, xfer, ctlr);\n\n\t\tif (!ctlr->ptp_sts_supported) {\n\t\t\txfer->ptp_sts_word_pre = 0;\n\t\t\tptp_read_system_prets(xfer->ptp_sts);\n\t\t}\n\n\t\tif ((xfer->tx_buf || xfer->rx_buf) && xfer->len) {\n\t\t\treinit_completion(&ctlr->xfer_completion);\n\nfallback_pio:\n\t\t\tspi_dma_sync_for_device(ctlr, xfer);\n\t\t\tret = ctlr->transfer_one(ctlr, msg->spi, xfer);\n\t\t\tif (ret < 0) {\n\t\t\t\tspi_dma_sync_for_cpu(ctlr, xfer);\n\n\t\t\t\tif (ctlr->cur_msg_mapped &&\n\t\t\t\t   (xfer->error & SPI_TRANS_FAIL_NO_START)) {\n\t\t\t\t\t__spi_unmap_msg(ctlr, msg);\n\t\t\t\t\tctlr->fallback = true;\n\t\t\t\t\txfer->error &= ~SPI_TRANS_FAIL_NO_START;\n\t\t\t\t\tgoto fallback_pio;\n\t\t\t\t}\n\n\t\t\t\tSPI_STATISTICS_INCREMENT_FIELD(statm,\n\t\t\t\t\t\t\t       errors);\n\t\t\t\tSPI_STATISTICS_INCREMENT_FIELD(stats,\n\t\t\t\t\t\t\t       errors);\n\t\t\t\tdev_err(&msg->spi->dev,\n\t\t\t\t\t\"SPI transfer failed: %d\\n\", ret);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tif (ret > 0) {\n\t\t\t\tret = spi_transfer_wait(ctlr, msg, xfer);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\tmsg->status = ret;\n\t\t\t}\n\n\t\t\tspi_dma_sync_for_cpu(ctlr, xfer);\n\t\t} else {\n\t\t\tif (xfer->len)\n\t\t\t\tdev_err(&msg->spi->dev,\n\t\t\t\t\t\"Bufferless transfer has length %u\\n\",\n\t\t\t\t\txfer->len);\n\t\t}\n\n\t\tif (!ctlr->ptp_sts_supported) {\n\t\t\tptp_read_system_postts(xfer->ptp_sts);\n\t\t\txfer->ptp_sts_word_post = xfer->len;\n\t\t}\n\n\t\ttrace_spi_transfer_stop(msg, xfer);\n\n\t\tif (msg->status != -EINPROGRESS)\n\t\t\tgoto out;\n\n\t\tspi_transfer_delay_exec(xfer);\n\n\t\tif (xfer->cs_change) {\n\t\t\tif (list_is_last(&xfer->transfer_list,\n\t\t\t\t\t &msg->transfers)) {\n\t\t\t\tkeep_cs = true;\n\t\t\t} else {\n\t\t\t\tif (!xfer->cs_off)\n\t\t\t\t\tspi_set_cs(msg->spi, false, false);\n\t\t\t\t_spi_transfer_cs_change_delay(msg, xfer);\n\t\t\t\tif (!list_next_entry(xfer, transfer_list)->cs_off)\n\t\t\t\t\tspi_set_cs(msg->spi, true, false);\n\t\t\t}\n\t\t} else if (!list_is_last(&xfer->transfer_list, &msg->transfers) &&\n\t\t\t   xfer->cs_off != list_next_entry(xfer, transfer_list)->cs_off) {\n\t\t\tspi_set_cs(msg->spi, xfer->cs_off, false);\n\t\t}\n\n\t\tmsg->actual_length += xfer->len;\n\t}\n\nout:\n\tif (ret != 0 || !keep_cs)\n\t\tspi_set_cs(msg->spi, false, false);\n\n\tif (msg->status == -EINPROGRESS)\n\t\tmsg->status = ret;\n\n\tif (msg->status && ctlr->handle_err)\n\t\tctlr->handle_err(ctlr, msg);\n\n\tspi_finalize_current_message(ctlr);\n\n\treturn ret;\n}\n\n \nvoid spi_finalize_current_transfer(struct spi_controller *ctlr)\n{\n\tcomplete(&ctlr->xfer_completion);\n}\nEXPORT_SYMBOL_GPL(spi_finalize_current_transfer);\n\nstatic void spi_idle_runtime_pm(struct spi_controller *ctlr)\n{\n\tif (ctlr->auto_runtime_pm) {\n\t\tpm_runtime_mark_last_busy(ctlr->dev.parent);\n\t\tpm_runtime_put_autosuspend(ctlr->dev.parent);\n\t}\n}\n\nstatic int __spi_pump_transfer_message(struct spi_controller *ctlr,\n\t\tstruct spi_message *msg, bool was_busy)\n{\n\tstruct spi_transfer *xfer;\n\tint ret;\n\n\tif (!was_busy && ctlr->auto_runtime_pm) {\n\t\tret = pm_runtime_get_sync(ctlr->dev.parent);\n\t\tif (ret < 0) {\n\t\t\tpm_runtime_put_noidle(ctlr->dev.parent);\n\t\t\tdev_err(&ctlr->dev, \"Failed to power device: %d\\n\",\n\t\t\t\tret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (!was_busy)\n\t\ttrace_spi_controller_busy(ctlr);\n\n\tif (!was_busy && ctlr->prepare_transfer_hardware) {\n\t\tret = ctlr->prepare_transfer_hardware(ctlr);\n\t\tif (ret) {\n\t\t\tdev_err(&ctlr->dev,\n\t\t\t\t\"failed to prepare transfer hardware: %d\\n\",\n\t\t\t\tret);\n\n\t\t\tif (ctlr->auto_runtime_pm)\n\t\t\t\tpm_runtime_put(ctlr->dev.parent);\n\n\t\t\tmsg->status = ret;\n\t\t\tspi_finalize_current_message(ctlr);\n\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\ttrace_spi_message_start(msg);\n\n\tret = spi_split_transfers_maxsize(ctlr, msg,\n\t\t\t\t\t  spi_max_transfer_size(msg->spi),\n\t\t\t\t\t  GFP_KERNEL | GFP_DMA);\n\tif (ret) {\n\t\tmsg->status = ret;\n\t\tspi_finalize_current_message(ctlr);\n\t\treturn ret;\n\t}\n\n\tif (ctlr->prepare_message) {\n\t\tret = ctlr->prepare_message(ctlr, msg);\n\t\tif (ret) {\n\t\t\tdev_err(&ctlr->dev, \"failed to prepare message: %d\\n\",\n\t\t\t\tret);\n\t\t\tmsg->status = ret;\n\t\t\tspi_finalize_current_message(ctlr);\n\t\t\treturn ret;\n\t\t}\n\t\tmsg->prepared = true;\n\t}\n\n\tret = spi_map_msg(ctlr, msg);\n\tif (ret) {\n\t\tmsg->status = ret;\n\t\tspi_finalize_current_message(ctlr);\n\t\treturn ret;\n\t}\n\n\tif (!ctlr->ptp_sts_supported && !ctlr->transfer_one) {\n\t\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\t\txfer->ptp_sts_word_pre = 0;\n\t\t\tptp_read_system_prets(xfer->ptp_sts);\n\t\t}\n\t}\n\n\t \n\tWRITE_ONCE(ctlr->cur_msg_incomplete, true);\n\tWRITE_ONCE(ctlr->cur_msg_need_completion, false);\n\treinit_completion(&ctlr->cur_msg_completion);\n\tsmp_wmb();  \n\n\tret = ctlr->transfer_one_message(ctlr, msg);\n\tif (ret) {\n\t\tdev_err(&ctlr->dev,\n\t\t\t\"failed to transfer one message from queue\\n\");\n\t\treturn ret;\n\t}\n\n\tWRITE_ONCE(ctlr->cur_msg_need_completion, true);\n\tsmp_mb();  \n\tif (READ_ONCE(ctlr->cur_msg_incomplete))\n\t\twait_for_completion(&ctlr->cur_msg_completion);\n\n\treturn 0;\n}\n\n \nstatic void __spi_pump_messages(struct spi_controller *ctlr, bool in_kthread)\n{\n\tstruct spi_message *msg;\n\tbool was_busy = false;\n\tunsigned long flags;\n\tint ret;\n\n\t \n\tmutex_lock(&ctlr->io_mutex);\n\n\t \n\tspin_lock_irqsave(&ctlr->queue_lock, flags);\n\n\t \n\tif (ctlr->cur_msg)\n\t\tgoto out_unlock;\n\n\t \n\tif (list_empty(&ctlr->queue) || !ctlr->running) {\n\t\tif (!ctlr->busy)\n\t\t\tgoto out_unlock;\n\n\t\t \n\t\tif (!in_kthread) {\n\t\t\tif (!ctlr->dummy_rx && !ctlr->dummy_tx &&\n\t\t\t    !ctlr->unprepare_transfer_hardware) {\n\t\t\t\tspi_idle_runtime_pm(ctlr);\n\t\t\t\tctlr->busy = false;\n\t\t\t\tctlr->queue_empty = true;\n\t\t\t\ttrace_spi_controller_idle(ctlr);\n\t\t\t} else {\n\t\t\t\tkthread_queue_work(ctlr->kworker,\n\t\t\t\t\t\t   &ctlr->pump_messages);\n\t\t\t}\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tctlr->busy = false;\n\t\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\n\t\tkfree(ctlr->dummy_rx);\n\t\tctlr->dummy_rx = NULL;\n\t\tkfree(ctlr->dummy_tx);\n\t\tctlr->dummy_tx = NULL;\n\t\tif (ctlr->unprepare_transfer_hardware &&\n\t\t    ctlr->unprepare_transfer_hardware(ctlr))\n\t\t\tdev_err(&ctlr->dev,\n\t\t\t\t\"failed to unprepare transfer hardware\\n\");\n\t\tspi_idle_runtime_pm(ctlr);\n\t\ttrace_spi_controller_idle(ctlr);\n\n\t\tspin_lock_irqsave(&ctlr->queue_lock, flags);\n\t\tctlr->queue_empty = true;\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tmsg = list_first_entry(&ctlr->queue, struct spi_message, queue);\n\tctlr->cur_msg = msg;\n\n\tlist_del_init(&msg->queue);\n\tif (ctlr->busy)\n\t\twas_busy = true;\n\telse\n\t\tctlr->busy = true;\n\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\n\tret = __spi_pump_transfer_message(ctlr, msg, was_busy);\n\tkthread_queue_work(ctlr->kworker, &ctlr->pump_messages);\n\n\tctlr->cur_msg = NULL;\n\tctlr->fallback = false;\n\n\tmutex_unlock(&ctlr->io_mutex);\n\n\t \n\tif (!ret)\n\t\tcond_resched();\n\treturn;\n\nout_unlock:\n\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\tmutex_unlock(&ctlr->io_mutex);\n}\n\n \nstatic void spi_pump_messages(struct kthread_work *work)\n{\n\tstruct spi_controller *ctlr =\n\t\tcontainer_of(work, struct spi_controller, pump_messages);\n\n\t__spi_pump_messages(ctlr, true);\n}\n\n \nvoid spi_take_timestamp_pre(struct spi_controller *ctlr,\n\t\t\t    struct spi_transfer *xfer,\n\t\t\t    size_t progress, bool irqs_off)\n{\n\tif (!xfer->ptp_sts)\n\t\treturn;\n\n\tif (xfer->timestamped)\n\t\treturn;\n\n\tif (progress > xfer->ptp_sts_word_pre)\n\t\treturn;\n\n\t \n\txfer->ptp_sts_word_pre = progress;\n\n\tif (irqs_off) {\n\t\tlocal_irq_save(ctlr->irq_flags);\n\t\tpreempt_disable();\n\t}\n\n\tptp_read_system_prets(xfer->ptp_sts);\n}\nEXPORT_SYMBOL_GPL(spi_take_timestamp_pre);\n\n \nvoid spi_take_timestamp_post(struct spi_controller *ctlr,\n\t\t\t     struct spi_transfer *xfer,\n\t\t\t     size_t progress, bool irqs_off)\n{\n\tif (!xfer->ptp_sts)\n\t\treturn;\n\n\tif (xfer->timestamped)\n\t\treturn;\n\n\tif (progress < xfer->ptp_sts_word_post)\n\t\treturn;\n\n\tptp_read_system_postts(xfer->ptp_sts);\n\n\tif (irqs_off) {\n\t\tlocal_irq_restore(ctlr->irq_flags);\n\t\tpreempt_enable();\n\t}\n\n\t \n\txfer->ptp_sts_word_post = progress;\n\n\txfer->timestamped = 1;\n}\nEXPORT_SYMBOL_GPL(spi_take_timestamp_post);\n\n \nstatic void spi_set_thread_rt(struct spi_controller *ctlr)\n{\n\tdev_info(&ctlr->dev,\n\t\t\"will run message pump with realtime priority\\n\");\n\tsched_set_fifo(ctlr->kworker->task);\n}\n\nstatic int spi_init_queue(struct spi_controller *ctlr)\n{\n\tctlr->running = false;\n\tctlr->busy = false;\n\tctlr->queue_empty = true;\n\n\tctlr->kworker = kthread_create_worker(0, dev_name(&ctlr->dev));\n\tif (IS_ERR(ctlr->kworker)) {\n\t\tdev_err(&ctlr->dev, \"failed to create message pump kworker\\n\");\n\t\treturn PTR_ERR(ctlr->kworker);\n\t}\n\n\tkthread_init_work(&ctlr->pump_messages, spi_pump_messages);\n\n\t \n\tif (ctlr->rt)\n\t\tspi_set_thread_rt(ctlr);\n\n\treturn 0;\n}\n\n \nstruct spi_message *spi_get_next_queued_message(struct spi_controller *ctlr)\n{\n\tstruct spi_message *next;\n\tunsigned long flags;\n\n\t \n\tspin_lock_irqsave(&ctlr->queue_lock, flags);\n\tnext = list_first_entry_or_null(&ctlr->queue, struct spi_message,\n\t\t\t\t\tqueue);\n\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\n\treturn next;\n}\nEXPORT_SYMBOL_GPL(spi_get_next_queued_message);\n\n \nvoid spi_finalize_current_message(struct spi_controller *ctlr)\n{\n\tstruct spi_transfer *xfer;\n\tstruct spi_message *mesg;\n\tint ret;\n\n\tmesg = ctlr->cur_msg;\n\n\tif (!ctlr->ptp_sts_supported && !ctlr->transfer_one) {\n\t\tlist_for_each_entry(xfer, &mesg->transfers, transfer_list) {\n\t\t\tptp_read_system_postts(xfer->ptp_sts);\n\t\t\txfer->ptp_sts_word_post = xfer->len;\n\t\t}\n\t}\n\n\tif (unlikely(ctlr->ptp_sts_supported))\n\t\tlist_for_each_entry(xfer, &mesg->transfers, transfer_list)\n\t\t\tWARN_ON_ONCE(xfer->ptp_sts && !xfer->timestamped);\n\n\tspi_unmap_msg(ctlr, mesg);\n\n\t \n\tspi_res_release(ctlr, mesg);\n\n\tif (mesg->prepared && ctlr->unprepare_message) {\n\t\tret = ctlr->unprepare_message(ctlr, mesg);\n\t\tif (ret) {\n\t\t\tdev_err(&ctlr->dev, \"failed to unprepare message: %d\\n\",\n\t\t\t\tret);\n\t\t}\n\t}\n\n\tmesg->prepared = false;\n\n\tWRITE_ONCE(ctlr->cur_msg_incomplete, false);\n\tsmp_mb();  \n\tif (READ_ONCE(ctlr->cur_msg_need_completion))\n\t\tcomplete(&ctlr->cur_msg_completion);\n\n\ttrace_spi_message_done(mesg);\n\n\tmesg->state = NULL;\n\tif (mesg->complete)\n\t\tmesg->complete(mesg->context);\n}\nEXPORT_SYMBOL_GPL(spi_finalize_current_message);\n\nstatic int spi_start_queue(struct spi_controller *ctlr)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ctlr->queue_lock, flags);\n\n\tif (ctlr->running || ctlr->busy) {\n\t\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\t\treturn -EBUSY;\n\t}\n\n\tctlr->running = true;\n\tctlr->cur_msg = NULL;\n\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\n\tkthread_queue_work(ctlr->kworker, &ctlr->pump_messages);\n\n\treturn 0;\n}\n\nstatic int spi_stop_queue(struct spi_controller *ctlr)\n{\n\tunsigned long flags;\n\tunsigned limit = 500;\n\tint ret = 0;\n\n\tspin_lock_irqsave(&ctlr->queue_lock, flags);\n\n\t \n\twhile ((!list_empty(&ctlr->queue) || ctlr->busy) && limit--) {\n\t\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\t\tusleep_range(10000, 11000);\n\t\tspin_lock_irqsave(&ctlr->queue_lock, flags);\n\t}\n\n\tif (!list_empty(&ctlr->queue) || ctlr->busy)\n\t\tret = -EBUSY;\n\telse\n\t\tctlr->running = false;\n\n\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\n\tif (ret) {\n\t\tdev_warn(&ctlr->dev, \"could not stop message queue\\n\");\n\t\treturn ret;\n\t}\n\treturn ret;\n}\n\nstatic int spi_destroy_queue(struct spi_controller *ctlr)\n{\n\tint ret;\n\n\tret = spi_stop_queue(ctlr);\n\n\t \n\tif (ret) {\n\t\tdev_err(&ctlr->dev, \"problem destroying queue\\n\");\n\t\treturn ret;\n\t}\n\n\tkthread_destroy_worker(ctlr->kworker);\n\n\treturn 0;\n}\n\nstatic int __spi_queued_transfer(struct spi_device *spi,\n\t\t\t\t struct spi_message *msg,\n\t\t\t\t bool need_pump)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ctlr->queue_lock, flags);\n\n\tif (!ctlr->running) {\n\t\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\t\treturn -ESHUTDOWN;\n\t}\n\tmsg->actual_length = 0;\n\tmsg->status = -EINPROGRESS;\n\n\tlist_add_tail(&msg->queue, &ctlr->queue);\n\tctlr->queue_empty = false;\n\tif (!ctlr->busy && need_pump)\n\t\tkthread_queue_work(ctlr->kworker, &ctlr->pump_messages);\n\n\tspin_unlock_irqrestore(&ctlr->queue_lock, flags);\n\treturn 0;\n}\n\n \nstatic int spi_queued_transfer(struct spi_device *spi, struct spi_message *msg)\n{\n\treturn __spi_queued_transfer(spi, msg, true);\n}\n\nstatic int spi_controller_initialize_queue(struct spi_controller *ctlr)\n{\n\tint ret;\n\n\tctlr->transfer = spi_queued_transfer;\n\tif (!ctlr->transfer_one_message)\n\t\tctlr->transfer_one_message = spi_transfer_one_message;\n\n\t \n\tret = spi_init_queue(ctlr);\n\tif (ret) {\n\t\tdev_err(&ctlr->dev, \"problem initializing queue\\n\");\n\t\tgoto err_init_queue;\n\t}\n\tctlr->queued = true;\n\tret = spi_start_queue(ctlr);\n\tif (ret) {\n\t\tdev_err(&ctlr->dev, \"problem starting queue\\n\");\n\t\tgoto err_start_queue;\n\t}\n\n\treturn 0;\n\nerr_start_queue:\n\tspi_destroy_queue(ctlr);\nerr_init_queue:\n\treturn ret;\n}\n\n \nvoid spi_flush_queue(struct spi_controller *ctlr)\n{\n\tif (ctlr->transfer == spi_queued_transfer)\n\t\t__spi_pump_messages(ctlr, false);\n}\n\n \n\n#if defined(CONFIG_OF)\nstatic void of_spi_parse_dt_cs_delay(struct device_node *nc,\n\t\t\t\t     struct spi_delay *delay, const char *prop)\n{\n\tu32 value;\n\n\tif (!of_property_read_u32(nc, prop, &value)) {\n\t\tif (value > U16_MAX) {\n\t\t\tdelay->value = DIV_ROUND_UP(value, 1000);\n\t\t\tdelay->unit = SPI_DELAY_UNIT_USECS;\n\t\t} else {\n\t\t\tdelay->value = value;\n\t\t\tdelay->unit = SPI_DELAY_UNIT_NSECS;\n\t\t}\n\t}\n}\n\nstatic int of_spi_parse_dt(struct spi_controller *ctlr, struct spi_device *spi,\n\t\t\t   struct device_node *nc)\n{\n\tu32 value;\n\tint rc;\n\n\t \n\tif (of_property_read_bool(nc, \"spi-cpha\"))\n\t\tspi->mode |= SPI_CPHA;\n\tif (of_property_read_bool(nc, \"spi-cpol\"))\n\t\tspi->mode |= SPI_CPOL;\n\tif (of_property_read_bool(nc, \"spi-3wire\"))\n\t\tspi->mode |= SPI_3WIRE;\n\tif (of_property_read_bool(nc, \"spi-lsb-first\"))\n\t\tspi->mode |= SPI_LSB_FIRST;\n\tif (of_property_read_bool(nc, \"spi-cs-high\"))\n\t\tspi->mode |= SPI_CS_HIGH;\n\n\t \n\tif (!of_property_read_u32(nc, \"spi-tx-bus-width\", &value)) {\n\t\tswitch (value) {\n\t\tcase 0:\n\t\t\tspi->mode |= SPI_NO_TX;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tspi->mode |= SPI_TX_DUAL;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tspi->mode |= SPI_TX_QUAD;\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tspi->mode |= SPI_TX_OCTAL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_warn(&ctlr->dev,\n\t\t\t\t\"spi-tx-bus-width %d not supported\\n\",\n\t\t\t\tvalue);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!of_property_read_u32(nc, \"spi-rx-bus-width\", &value)) {\n\t\tswitch (value) {\n\t\tcase 0:\n\t\t\tspi->mode |= SPI_NO_RX;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tspi->mode |= SPI_RX_DUAL;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tspi->mode |= SPI_RX_QUAD;\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tspi->mode |= SPI_RX_OCTAL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_warn(&ctlr->dev,\n\t\t\t\t\"spi-rx-bus-width %d not supported\\n\",\n\t\t\t\tvalue);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (spi_controller_is_slave(ctlr)) {\n\t\tif (!of_node_name_eq(nc, \"slave\")) {\n\t\t\tdev_err(&ctlr->dev, \"%pOF is not called 'slave'\\n\",\n\t\t\t\tnc);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn 0;\n\t}\n\n\t \n\trc = of_property_read_u32(nc, \"reg\", &value);\n\tif (rc) {\n\t\tdev_err(&ctlr->dev, \"%pOF has no valid 'reg' property (%d)\\n\",\n\t\t\tnc, rc);\n\t\treturn rc;\n\t}\n\tspi_set_chipselect(spi, 0, value);\n\n\t \n\tif (!of_property_read_u32(nc, \"spi-max-frequency\", &value))\n\t\tspi->max_speed_hz = value;\n\n\t \n\tof_spi_parse_dt_cs_delay(nc, &spi->cs_setup, \"spi-cs-setup-delay-ns\");\n\tof_spi_parse_dt_cs_delay(nc, &spi->cs_hold, \"spi-cs-hold-delay-ns\");\n\tof_spi_parse_dt_cs_delay(nc, &spi->cs_inactive, \"spi-cs-inactive-delay-ns\");\n\n\treturn 0;\n}\n\nstatic struct spi_device *\nof_register_spi_device(struct spi_controller *ctlr, struct device_node *nc)\n{\n\tstruct spi_device *spi;\n\tint rc;\n\n\t \n\tspi = spi_alloc_device(ctlr);\n\tif (!spi) {\n\t\tdev_err(&ctlr->dev, \"spi_device alloc error for %pOF\\n\", nc);\n\t\trc = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\t \n\trc = of_alias_from_compatible(nc, spi->modalias,\n\t\t\t\t      sizeof(spi->modalias));\n\tif (rc < 0) {\n\t\tdev_err(&ctlr->dev, \"cannot find modalias for %pOF\\n\", nc);\n\t\tgoto err_out;\n\t}\n\n\trc = of_spi_parse_dt(ctlr, spi, nc);\n\tif (rc)\n\t\tgoto err_out;\n\n\t \n\tof_node_get(nc);\n\n\tdevice_set_node(&spi->dev, of_fwnode_handle(nc));\n\n\t \n\trc = spi_add_device(spi);\n\tif (rc) {\n\t\tdev_err(&ctlr->dev, \"spi_device register error %pOF\\n\", nc);\n\t\tgoto err_of_node_put;\n\t}\n\n\treturn spi;\n\nerr_of_node_put:\n\tof_node_put(nc);\nerr_out:\n\tspi_dev_put(spi);\n\treturn ERR_PTR(rc);\n}\n\n \nstatic void of_register_spi_devices(struct spi_controller *ctlr)\n{\n\tstruct spi_device *spi;\n\tstruct device_node *nc;\n\n\tfor_each_available_child_of_node(ctlr->dev.of_node, nc) {\n\t\tif (of_node_test_and_set_flag(nc, OF_POPULATED))\n\t\t\tcontinue;\n\t\tspi = of_register_spi_device(ctlr, nc);\n\t\tif (IS_ERR(spi)) {\n\t\t\tdev_warn(&ctlr->dev,\n\t\t\t\t \"Failed to create SPI device for %pOF\\n\", nc);\n\t\t\tof_node_clear_flag(nc, OF_POPULATED);\n\t\t}\n\t}\n}\n#else\nstatic void of_register_spi_devices(struct spi_controller *ctlr) { }\n#endif\n\n \nstruct spi_device *spi_new_ancillary_device(struct spi_device *spi,\n\t\t\t\t\t     u8 chip_select)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\tstruct spi_device *ancillary;\n\tint rc = 0;\n\n\t \n\tancillary = spi_alloc_device(ctlr);\n\tif (!ancillary) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\tstrscpy(ancillary->modalias, \"dummy\", sizeof(ancillary->modalias));\n\n\t \n\tspi_set_chipselect(ancillary, 0, chip_select);\n\n\t \n\tancillary->max_speed_hz = spi->max_speed_hz;\n\tancillary->mode = spi->mode;\n\n\tWARN_ON(!mutex_is_locked(&ctlr->add_lock));\n\n\t \n\trc = __spi_add_device(ancillary);\n\tif (rc) {\n\t\tdev_err(&spi->dev, \"failed to register ancillary device\\n\");\n\t\tgoto err_out;\n\t}\n\n\treturn ancillary;\n\nerr_out:\n\tspi_dev_put(ancillary);\n\treturn ERR_PTR(rc);\n}\nEXPORT_SYMBOL_GPL(spi_new_ancillary_device);\n\n#ifdef CONFIG_ACPI\nstruct acpi_spi_lookup {\n\tstruct spi_controller \t*ctlr;\n\tu32\t\t\tmax_speed_hz;\n\tu32\t\t\tmode;\n\tint\t\t\tirq;\n\tu8\t\t\tbits_per_word;\n\tu8\t\t\tchip_select;\n\tint\t\t\tn;\n\tint\t\t\tindex;\n};\n\nstatic int acpi_spi_count(struct acpi_resource *ares, void *data)\n{\n\tstruct acpi_resource_spi_serialbus *sb;\n\tint *count = data;\n\n\tif (ares->type != ACPI_RESOURCE_TYPE_SERIAL_BUS)\n\t\treturn 1;\n\n\tsb = &ares->data.spi_serial_bus;\n\tif (sb->type != ACPI_RESOURCE_SERIAL_TYPE_SPI)\n\t\treturn 1;\n\n\t*count = *count + 1;\n\n\treturn 1;\n}\n\n \nint acpi_spi_count_resources(struct acpi_device *adev)\n{\n\tLIST_HEAD(r);\n\tint count = 0;\n\tint ret;\n\n\tret = acpi_dev_get_resources(adev, &r, acpi_spi_count, &count);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tacpi_dev_free_resource_list(&r);\n\n\treturn count;\n}\nEXPORT_SYMBOL_GPL(acpi_spi_count_resources);\n\nstatic void acpi_spi_parse_apple_properties(struct acpi_device *dev,\n\t\t\t\t\t    struct acpi_spi_lookup *lookup)\n{\n\tconst union acpi_object *obj;\n\n\tif (!x86_apple_machine)\n\t\treturn;\n\n\tif (!acpi_dev_get_property(dev, \"spiSclkPeriod\", ACPI_TYPE_BUFFER, &obj)\n\t    && obj->buffer.length >= 4)\n\t\tlookup->max_speed_hz  = NSEC_PER_SEC / *(u32 *)obj->buffer.pointer;\n\n\tif (!acpi_dev_get_property(dev, \"spiWordSize\", ACPI_TYPE_BUFFER, &obj)\n\t    && obj->buffer.length == 8)\n\t\tlookup->bits_per_word = *(u64 *)obj->buffer.pointer;\n\n\tif (!acpi_dev_get_property(dev, \"spiBitOrder\", ACPI_TYPE_BUFFER, &obj)\n\t    && obj->buffer.length == 8 && !*(u64 *)obj->buffer.pointer)\n\t\tlookup->mode |= SPI_LSB_FIRST;\n\n\tif (!acpi_dev_get_property(dev, \"spiSPO\", ACPI_TYPE_BUFFER, &obj)\n\t    && obj->buffer.length == 8 &&  *(u64 *)obj->buffer.pointer)\n\t\tlookup->mode |= SPI_CPOL;\n\n\tif (!acpi_dev_get_property(dev, \"spiSPH\", ACPI_TYPE_BUFFER, &obj)\n\t    && obj->buffer.length == 8 &&  *(u64 *)obj->buffer.pointer)\n\t\tlookup->mode |= SPI_CPHA;\n}\n\nstatic struct spi_controller *acpi_spi_find_controller_by_adev(struct acpi_device *adev);\n\nstatic int acpi_spi_add_resource(struct acpi_resource *ares, void *data)\n{\n\tstruct acpi_spi_lookup *lookup = data;\n\tstruct spi_controller *ctlr = lookup->ctlr;\n\n\tif (ares->type == ACPI_RESOURCE_TYPE_SERIAL_BUS) {\n\t\tstruct acpi_resource_spi_serialbus *sb;\n\t\tacpi_handle parent_handle;\n\t\tacpi_status status;\n\n\t\tsb = &ares->data.spi_serial_bus;\n\t\tif (sb->type == ACPI_RESOURCE_SERIAL_TYPE_SPI) {\n\n\t\t\tif (lookup->index != -1 && lookup->n++ != lookup->index)\n\t\t\t\treturn 1;\n\n\t\t\tstatus = acpi_get_handle(NULL,\n\t\t\t\t\t\t sb->resource_source.string_ptr,\n\t\t\t\t\t\t &parent_handle);\n\n\t\t\tif (ACPI_FAILURE(status))\n\t\t\t\treturn -ENODEV;\n\n\t\t\tif (ctlr) {\n\t\t\t\tif (ACPI_HANDLE(ctlr->dev.parent) != parent_handle)\n\t\t\t\t\treturn -ENODEV;\n\t\t\t} else {\n\t\t\t\tstruct acpi_device *adev;\n\n\t\t\t\tadev = acpi_fetch_acpi_dev(parent_handle);\n\t\t\t\tif (!adev)\n\t\t\t\t\treturn -ENODEV;\n\n\t\t\t\tctlr = acpi_spi_find_controller_by_adev(adev);\n\t\t\t\tif (!ctlr)\n\t\t\t\t\treturn -EPROBE_DEFER;\n\n\t\t\t\tlookup->ctlr = ctlr;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (ctlr->fw_translate_cs) {\n\t\t\t\tint cs = ctlr->fw_translate_cs(ctlr,\n\t\t\t\t\t\tsb->device_selection);\n\t\t\t\tif (cs < 0)\n\t\t\t\t\treturn cs;\n\t\t\t\tlookup->chip_select = cs;\n\t\t\t} else {\n\t\t\t\tlookup->chip_select = sb->device_selection;\n\t\t\t}\n\n\t\t\tlookup->max_speed_hz = sb->connection_speed;\n\t\t\tlookup->bits_per_word = sb->data_bit_length;\n\n\t\t\tif (sb->clock_phase == ACPI_SPI_SECOND_PHASE)\n\t\t\t\tlookup->mode |= SPI_CPHA;\n\t\t\tif (sb->clock_polarity == ACPI_SPI_START_HIGH)\n\t\t\t\tlookup->mode |= SPI_CPOL;\n\t\t\tif (sb->device_polarity == ACPI_SPI_ACTIVE_HIGH)\n\t\t\t\tlookup->mode |= SPI_CS_HIGH;\n\t\t}\n\t} else if (lookup->irq < 0) {\n\t\tstruct resource r;\n\n\t\tif (acpi_dev_resource_interrupt(ares, 0, &r))\n\t\t\tlookup->irq = r.start;\n\t}\n\n\t \n\treturn 1;\n}\n\n \nstruct spi_device *acpi_spi_device_alloc(struct spi_controller *ctlr,\n\t\t\t\t\t struct acpi_device *adev,\n\t\t\t\t\t int index)\n{\n\tacpi_handle parent_handle = NULL;\n\tstruct list_head resource_list;\n\tstruct acpi_spi_lookup lookup = {};\n\tstruct spi_device *spi;\n\tint ret;\n\n\tif (!ctlr && index == -1)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tlookup.ctlr\t\t= ctlr;\n\tlookup.irq\t\t= -1;\n\tlookup.index\t\t= index;\n\tlookup.n\t\t= 0;\n\n\tINIT_LIST_HEAD(&resource_list);\n\tret = acpi_dev_get_resources(adev, &resource_list,\n\t\t\t\t     acpi_spi_add_resource, &lookup);\n\tacpi_dev_free_resource_list(&resource_list);\n\n\tif (ret < 0)\n\t\t \n\t\treturn ERR_PTR(ret);\n\n\tif (!lookup.max_speed_hz &&\n\t    ACPI_SUCCESS(acpi_get_parent(adev->handle, &parent_handle)) &&\n\t    ACPI_HANDLE(lookup.ctlr->dev.parent) == parent_handle) {\n\t\t \n\t\tacpi_spi_parse_apple_properties(adev, &lookup);\n\t}\n\n\tif (!lookup.max_speed_hz)\n\t\treturn ERR_PTR(-ENODEV);\n\n\tspi = spi_alloc_device(lookup.ctlr);\n\tif (!spi) {\n\t\tdev_err(&lookup.ctlr->dev, \"failed to allocate SPI device for %s\\n\",\n\t\t\tdev_name(&adev->dev));\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tACPI_COMPANION_SET(&spi->dev, adev);\n\tspi->max_speed_hz\t= lookup.max_speed_hz;\n\tspi->mode\t\t|= lookup.mode;\n\tspi->irq\t\t= lookup.irq;\n\tspi->bits_per_word\t= lookup.bits_per_word;\n\tspi_set_chipselect(spi, 0, lookup.chip_select);\n\n\treturn spi;\n}\nEXPORT_SYMBOL_GPL(acpi_spi_device_alloc);\n\nstatic acpi_status acpi_register_spi_device(struct spi_controller *ctlr,\n\t\t\t\t\t    struct acpi_device *adev)\n{\n\tstruct spi_device *spi;\n\n\tif (acpi_bus_get_status(adev) || !adev->status.present ||\n\t    acpi_device_enumerated(adev))\n\t\treturn AE_OK;\n\n\tspi = acpi_spi_device_alloc(ctlr, adev, -1);\n\tif (IS_ERR(spi)) {\n\t\tif (PTR_ERR(spi) == -ENOMEM)\n\t\t\treturn AE_NO_MEMORY;\n\t\telse\n\t\t\treturn AE_OK;\n\t}\n\n\tacpi_set_modalias(adev, acpi_device_hid(adev), spi->modalias,\n\t\t\t  sizeof(spi->modalias));\n\n\tif (spi->irq < 0)\n\t\tspi->irq = acpi_dev_gpio_irq_get(adev, 0);\n\n\tacpi_device_set_enumerated(adev);\n\n\tadev->power.flags.ignore_parent = true;\n\tif (spi_add_device(spi)) {\n\t\tadev->power.flags.ignore_parent = false;\n\t\tdev_err(&ctlr->dev, \"failed to add SPI device %s from ACPI\\n\",\n\t\t\tdev_name(&adev->dev));\n\t\tspi_dev_put(spi);\n\t}\n\n\treturn AE_OK;\n}\n\nstatic acpi_status acpi_spi_add_device(acpi_handle handle, u32 level,\n\t\t\t\t       void *data, void **return_value)\n{\n\tstruct acpi_device *adev = acpi_fetch_acpi_dev(handle);\n\tstruct spi_controller *ctlr = data;\n\n\tif (!adev)\n\t\treturn AE_OK;\n\n\treturn acpi_register_spi_device(ctlr, adev);\n}\n\n#define SPI_ACPI_ENUMERATE_MAX_DEPTH\t\t32\n\nstatic void acpi_register_spi_devices(struct spi_controller *ctlr)\n{\n\tacpi_status status;\n\tacpi_handle handle;\n\n\thandle = ACPI_HANDLE(ctlr->dev.parent);\n\tif (!handle)\n\t\treturn;\n\n\tstatus = acpi_walk_namespace(ACPI_TYPE_DEVICE, ACPI_ROOT_OBJECT,\n\t\t\t\t     SPI_ACPI_ENUMERATE_MAX_DEPTH,\n\t\t\t\t     acpi_spi_add_device, NULL, ctlr, NULL);\n\tif (ACPI_FAILURE(status))\n\t\tdev_warn(&ctlr->dev, \"failed to enumerate SPI slaves\\n\");\n}\n#else\nstatic inline void acpi_register_spi_devices(struct spi_controller *ctlr) {}\n#endif  \n\nstatic void spi_controller_release(struct device *dev)\n{\n\tstruct spi_controller *ctlr;\n\n\tctlr = container_of(dev, struct spi_controller, dev);\n\tkfree(ctlr);\n}\n\nstatic struct class spi_master_class = {\n\t.name\t\t= \"spi_master\",\n\t.dev_release\t= spi_controller_release,\n\t.dev_groups\t= spi_master_groups,\n};\n\n#ifdef CONFIG_SPI_SLAVE\n \nint spi_slave_abort(struct spi_device *spi)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\n\tif (spi_controller_is_slave(ctlr) && ctlr->slave_abort)\n\t\treturn ctlr->slave_abort(ctlr);\n\n\treturn -ENOTSUPP;\n}\nEXPORT_SYMBOL_GPL(spi_slave_abort);\n\nint spi_target_abort(struct spi_device *spi)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\n\tif (spi_controller_is_target(ctlr) && ctlr->target_abort)\n\t\treturn ctlr->target_abort(ctlr);\n\n\treturn -ENOTSUPP;\n}\nEXPORT_SYMBOL_GPL(spi_target_abort);\n\nstatic ssize_t slave_show(struct device *dev, struct device_attribute *attr,\n\t\t\t  char *buf)\n{\n\tstruct spi_controller *ctlr = container_of(dev, struct spi_controller,\n\t\t\t\t\t\t   dev);\n\tstruct device *child;\n\n\tchild = device_find_any_child(&ctlr->dev);\n\treturn sysfs_emit(buf, \"%s\\n\", child ? to_spi_device(child)->modalias : NULL);\n}\n\nstatic ssize_t slave_store(struct device *dev, struct device_attribute *attr,\n\t\t\t   const char *buf, size_t count)\n{\n\tstruct spi_controller *ctlr = container_of(dev, struct spi_controller,\n\t\t\t\t\t\t   dev);\n\tstruct spi_device *spi;\n\tstruct device *child;\n\tchar name[32];\n\tint rc;\n\n\trc = sscanf(buf, \"%31s\", name);\n\tif (rc != 1 || !name[0])\n\t\treturn -EINVAL;\n\n\tchild = device_find_any_child(&ctlr->dev);\n\tif (child) {\n\t\t \n\t\tdevice_unregister(child);\n\t\tput_device(child);\n\t}\n\n\tif (strcmp(name, \"(null)\")) {\n\t\t \n\t\tspi = spi_alloc_device(ctlr);\n\t\tif (!spi)\n\t\t\treturn -ENOMEM;\n\n\t\tstrscpy(spi->modalias, name, sizeof(spi->modalias));\n\n\t\trc = spi_add_device(spi);\n\t\tif (rc) {\n\t\t\tspi_dev_put(spi);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\treturn count;\n}\n\nstatic DEVICE_ATTR_RW(slave);\n\nstatic struct attribute *spi_slave_attrs[] = {\n\t&dev_attr_slave.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group spi_slave_group = {\n\t.attrs = spi_slave_attrs,\n};\n\nstatic const struct attribute_group *spi_slave_groups[] = {\n\t&spi_controller_statistics_group,\n\t&spi_slave_group,\n\tNULL,\n};\n\nstatic struct class spi_slave_class = {\n\t.name\t\t= \"spi_slave\",\n\t.dev_release\t= spi_controller_release,\n\t.dev_groups\t= spi_slave_groups,\n};\n#else\nextern struct class spi_slave_class;\t \n#endif\n\n \nstruct spi_controller *__spi_alloc_controller(struct device *dev,\n\t\t\t\t\t      unsigned int size, bool slave)\n{\n\tstruct spi_controller\t*ctlr;\n\tsize_t ctlr_size = ALIGN(sizeof(*ctlr), dma_get_cache_alignment());\n\n\tif (!dev)\n\t\treturn NULL;\n\n\tctlr = kzalloc(size + ctlr_size, GFP_KERNEL);\n\tif (!ctlr)\n\t\treturn NULL;\n\n\tdevice_initialize(&ctlr->dev);\n\tINIT_LIST_HEAD(&ctlr->queue);\n\tspin_lock_init(&ctlr->queue_lock);\n\tspin_lock_init(&ctlr->bus_lock_spinlock);\n\tmutex_init(&ctlr->bus_lock_mutex);\n\tmutex_init(&ctlr->io_mutex);\n\tmutex_init(&ctlr->add_lock);\n\tctlr->bus_num = -1;\n\tctlr->num_chipselect = 1;\n\tctlr->slave = slave;\n\tif (IS_ENABLED(CONFIG_SPI_SLAVE) && slave)\n\t\tctlr->dev.class = &spi_slave_class;\n\telse\n\t\tctlr->dev.class = &spi_master_class;\n\tctlr->dev.parent = dev;\n\tpm_suspend_ignore_children(&ctlr->dev, true);\n\tspi_controller_set_devdata(ctlr, (void *)ctlr + ctlr_size);\n\n\treturn ctlr;\n}\nEXPORT_SYMBOL_GPL(__spi_alloc_controller);\n\nstatic void devm_spi_release_controller(struct device *dev, void *ctlr)\n{\n\tspi_controller_put(*(struct spi_controller **)ctlr);\n}\n\n \nstruct spi_controller *__devm_spi_alloc_controller(struct device *dev,\n\t\t\t\t\t\t   unsigned int size,\n\t\t\t\t\t\t   bool slave)\n{\n\tstruct spi_controller **ptr, *ctlr;\n\n\tptr = devres_alloc(devm_spi_release_controller, sizeof(*ptr),\n\t\t\t   GFP_KERNEL);\n\tif (!ptr)\n\t\treturn NULL;\n\n\tctlr = __spi_alloc_controller(dev, size, slave);\n\tif (ctlr) {\n\t\tctlr->devm_allocated = true;\n\t\t*ptr = ctlr;\n\t\tdevres_add(dev, ptr);\n\t} else {\n\t\tdevres_free(ptr);\n\t}\n\n\treturn ctlr;\n}\nEXPORT_SYMBOL_GPL(__devm_spi_alloc_controller);\n\n \nstatic int spi_get_gpio_descs(struct spi_controller *ctlr)\n{\n\tint nb, i;\n\tstruct gpio_desc **cs;\n\tstruct device *dev = &ctlr->dev;\n\tunsigned long native_cs_mask = 0;\n\tunsigned int num_cs_gpios = 0;\n\n\tnb = gpiod_count(dev, \"cs\");\n\tif (nb < 0) {\n\t\t \n\t\tif (nb == -ENOENT)\n\t\t\treturn 0;\n\t\treturn nb;\n\t}\n\n\tctlr->num_chipselect = max_t(int, nb, ctlr->num_chipselect);\n\n\tcs = devm_kcalloc(dev, ctlr->num_chipselect, sizeof(*cs),\n\t\t\t  GFP_KERNEL);\n\tif (!cs)\n\t\treturn -ENOMEM;\n\tctlr->cs_gpiods = cs;\n\n\tfor (i = 0; i < nb; i++) {\n\t\t \n\t\tcs[i] = devm_gpiod_get_index_optional(dev, \"cs\", i,\n\t\t\t\t\t\t      GPIOD_OUT_LOW);\n\t\tif (IS_ERR(cs[i]))\n\t\t\treturn PTR_ERR(cs[i]);\n\n\t\tif (cs[i]) {\n\t\t\t \n\t\t\tchar *gpioname;\n\n\t\t\tgpioname = devm_kasprintf(dev, GFP_KERNEL, \"%s CS%d\",\n\t\t\t\t\t\t  dev_name(dev), i);\n\t\t\tif (!gpioname)\n\t\t\t\treturn -ENOMEM;\n\t\t\tgpiod_set_consumer_name(cs[i], gpioname);\n\t\t\tnum_cs_gpios++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (ctlr->max_native_cs && i >= ctlr->max_native_cs) {\n\t\t\tdev_err(dev, \"Invalid native chip select %d\\n\", i);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tnative_cs_mask |= BIT(i);\n\t}\n\n\tctlr->unused_native_cs = ffs(~native_cs_mask) - 1;\n\n\tif ((ctlr->flags & SPI_CONTROLLER_GPIO_SS) && num_cs_gpios &&\n\t    ctlr->max_native_cs && ctlr->unused_native_cs >= ctlr->max_native_cs) {\n\t\tdev_err(dev, \"No unused native chip select available\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int spi_controller_check_ops(struct spi_controller *ctlr)\n{\n\t \n\tif (!ctlr->mem_ops || !ctlr->mem_ops->exec_op) {\n\t\tif (!ctlr->transfer && !ctlr->transfer_one &&\n\t\t   !ctlr->transfer_one_message) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic int spi_controller_id_alloc(struct spi_controller *ctlr, int start, int end)\n{\n\tint id;\n\n\tmutex_lock(&board_lock);\n\tid = idr_alloc(&spi_master_idr, ctlr, start, end, GFP_KERNEL);\n\tmutex_unlock(&board_lock);\n\tif (WARN(id < 0, \"couldn't get idr\"))\n\t\treturn id == -ENOSPC ? -EBUSY : id;\n\tctlr->bus_num = id;\n\treturn 0;\n}\n\n \nint spi_register_controller(struct spi_controller *ctlr)\n{\n\tstruct device\t\t*dev = ctlr->dev.parent;\n\tstruct boardinfo\t*bi;\n\tint\t\t\tfirst_dynamic;\n\tint\t\t\tstatus;\n\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\t \n\tstatus = spi_controller_check_ops(ctlr);\n\tif (status)\n\t\treturn status;\n\n\tif (ctlr->bus_num < 0)\n\t\tctlr->bus_num = of_alias_get_id(ctlr->dev.of_node, \"spi\");\n\tif (ctlr->bus_num >= 0) {\n\t\t \n\t\tstatus = spi_controller_id_alloc(ctlr, ctlr->bus_num, ctlr->bus_num + 1);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\tif (ctlr->bus_num < 0) {\n\t\tfirst_dynamic = of_alias_get_highest_id(\"spi\");\n\t\tif (first_dynamic < 0)\n\t\t\tfirst_dynamic = 0;\n\t\telse\n\t\t\tfirst_dynamic++;\n\n\t\tstatus = spi_controller_id_alloc(ctlr, first_dynamic, 0);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\tctlr->bus_lock_flag = 0;\n\tinit_completion(&ctlr->xfer_completion);\n\tinit_completion(&ctlr->cur_msg_completion);\n\tif (!ctlr->max_dma_len)\n\t\tctlr->max_dma_len = INT_MAX;\n\n\t \n\tdev_set_name(&ctlr->dev, \"spi%u\", ctlr->bus_num);\n\n\tif (!spi_controller_is_slave(ctlr) && ctlr->use_gpio_descriptors) {\n\t\tstatus = spi_get_gpio_descs(ctlr);\n\t\tif (status)\n\t\t\tgoto free_bus_id;\n\t\t \n\t\tctlr->mode_bits |= SPI_CS_HIGH;\n\t}\n\n\t \n\tif (!ctlr->num_chipselect) {\n\t\tstatus = -EINVAL;\n\t\tgoto free_bus_id;\n\t}\n\n\t \n\tctlr->last_cs = -1;\n\n\tstatus = device_add(&ctlr->dev);\n\tif (status < 0)\n\t\tgoto free_bus_id;\n\tdev_dbg(dev, \"registered %s %s\\n\",\n\t\t\tspi_controller_is_slave(ctlr) ? \"slave\" : \"master\",\n\t\t\tdev_name(&ctlr->dev));\n\n\t \n\tif (ctlr->transfer) {\n\t\tdev_info(dev, \"controller is unqueued, this is deprecated\\n\");\n\t} else if (ctlr->transfer_one || ctlr->transfer_one_message) {\n\t\tstatus = spi_controller_initialize_queue(ctlr);\n\t\tif (status) {\n\t\t\tdevice_del(&ctlr->dev);\n\t\t\tgoto free_bus_id;\n\t\t}\n\t}\n\t \n\tctlr->pcpu_statistics = spi_alloc_pcpu_stats(dev);\n\tif (!ctlr->pcpu_statistics) {\n\t\tdev_err(dev, \"Error allocating per-cpu statistics\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto destroy_queue;\n\t}\n\n\tmutex_lock(&board_lock);\n\tlist_add_tail(&ctlr->list, &spi_controller_list);\n\tlist_for_each_entry(bi, &board_list, list)\n\t\tspi_match_controller_to_boardinfo(ctlr, &bi->board_info);\n\tmutex_unlock(&board_lock);\n\n\t \n\tof_register_spi_devices(ctlr);\n\tacpi_register_spi_devices(ctlr);\n\treturn status;\n\ndestroy_queue:\n\tspi_destroy_queue(ctlr);\nfree_bus_id:\n\tmutex_lock(&board_lock);\n\tidr_remove(&spi_master_idr, ctlr->bus_num);\n\tmutex_unlock(&board_lock);\n\treturn status;\n}\nEXPORT_SYMBOL_GPL(spi_register_controller);\n\nstatic void devm_spi_unregister(struct device *dev, void *res)\n{\n\tspi_unregister_controller(*(struct spi_controller **)res);\n}\n\n \nint devm_spi_register_controller(struct device *dev,\n\t\t\t\t struct spi_controller *ctlr)\n{\n\tstruct spi_controller **ptr;\n\tint ret;\n\n\tptr = devres_alloc(devm_spi_unregister, sizeof(*ptr), GFP_KERNEL);\n\tif (!ptr)\n\t\treturn -ENOMEM;\n\n\tret = spi_register_controller(ctlr);\n\tif (!ret) {\n\t\t*ptr = ctlr;\n\t\tdevres_add(dev, ptr);\n\t} else {\n\t\tdevres_free(ptr);\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(devm_spi_register_controller);\n\nstatic int __unregister(struct device *dev, void *null)\n{\n\tspi_unregister_device(to_spi_device(dev));\n\treturn 0;\n}\n\n \nvoid spi_unregister_controller(struct spi_controller *ctlr)\n{\n\tstruct spi_controller *found;\n\tint id = ctlr->bus_num;\n\n\t \n\tif (IS_ENABLED(CONFIG_SPI_DYNAMIC))\n\t\tmutex_lock(&ctlr->add_lock);\n\n\tdevice_for_each_child(&ctlr->dev, NULL, __unregister);\n\n\t \n\tmutex_lock(&board_lock);\n\tfound = idr_find(&spi_master_idr, id);\n\tmutex_unlock(&board_lock);\n\tif (ctlr->queued) {\n\t\tif (spi_destroy_queue(ctlr))\n\t\t\tdev_err(&ctlr->dev, \"queue remove failed\\n\");\n\t}\n\tmutex_lock(&board_lock);\n\tlist_del(&ctlr->list);\n\tmutex_unlock(&board_lock);\n\n\tdevice_del(&ctlr->dev);\n\n\t \n\tmutex_lock(&board_lock);\n\tif (found == ctlr)\n\t\tidr_remove(&spi_master_idr, id);\n\tmutex_unlock(&board_lock);\n\n\tif (IS_ENABLED(CONFIG_SPI_DYNAMIC))\n\t\tmutex_unlock(&ctlr->add_lock);\n\n\t \n\tif (!ctlr->devm_allocated)\n\t\tput_device(&ctlr->dev);\n}\nEXPORT_SYMBOL_GPL(spi_unregister_controller);\n\nstatic inline int __spi_check_suspended(const struct spi_controller *ctlr)\n{\n\treturn ctlr->flags & SPI_CONTROLLER_SUSPENDED ? -ESHUTDOWN : 0;\n}\n\nstatic inline void __spi_mark_suspended(struct spi_controller *ctlr)\n{\n\tmutex_lock(&ctlr->bus_lock_mutex);\n\tctlr->flags |= SPI_CONTROLLER_SUSPENDED;\n\tmutex_unlock(&ctlr->bus_lock_mutex);\n}\n\nstatic inline void __spi_mark_resumed(struct spi_controller *ctlr)\n{\n\tmutex_lock(&ctlr->bus_lock_mutex);\n\tctlr->flags &= ~SPI_CONTROLLER_SUSPENDED;\n\tmutex_unlock(&ctlr->bus_lock_mutex);\n}\n\nint spi_controller_suspend(struct spi_controller *ctlr)\n{\n\tint ret = 0;\n\n\t \n\tif (ctlr->queued) {\n\t\tret = spi_stop_queue(ctlr);\n\t\tif (ret)\n\t\t\tdev_err(&ctlr->dev, \"queue stop failed\\n\");\n\t}\n\n\t__spi_mark_suspended(ctlr);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(spi_controller_suspend);\n\nint spi_controller_resume(struct spi_controller *ctlr)\n{\n\tint ret = 0;\n\n\t__spi_mark_resumed(ctlr);\n\n\tif (ctlr->queued) {\n\t\tret = spi_start_queue(ctlr);\n\t\tif (ret)\n\t\t\tdev_err(&ctlr->dev, \"queue restart failed\\n\");\n\t}\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(spi_controller_resume);\n\n \n\n \n\nstatic void __spi_replace_transfers_release(struct spi_controller *ctlr,\n\t\t\t\t\t    struct spi_message *msg,\n\t\t\t\t\t    void *res)\n{\n\tstruct spi_replaced_transfers *rxfer = res;\n\tsize_t i;\n\n\t \n\tif (rxfer->release)\n\t\trxfer->release(ctlr, msg, res);\n\n\t \n\tlist_splice(&rxfer->replaced_transfers, rxfer->replaced_after);\n\n\t \n\tfor (i = 0; i < rxfer->inserted; i++)\n\t\tlist_del(&rxfer->inserted_transfers[i].transfer_list);\n}\n\n \nstatic struct spi_replaced_transfers *spi_replace_transfers(\n\tstruct spi_message *msg,\n\tstruct spi_transfer *xfer_first,\n\tsize_t remove,\n\tsize_t insert,\n\tspi_replaced_release_t release,\n\tsize_t extradatasize,\n\tgfp_t gfp)\n{\n\tstruct spi_replaced_transfers *rxfer;\n\tstruct spi_transfer *xfer;\n\tsize_t i;\n\n\t \n\trxfer = spi_res_alloc(msg->spi, __spi_replace_transfers_release,\n\t\t\t      struct_size(rxfer, inserted_transfers, insert)\n\t\t\t      + extradatasize,\n\t\t\t      gfp);\n\tif (!rxfer)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t \n\trxfer->release = release;\n\n\t \n\tif (extradatasize)\n\t\trxfer->extradata =\n\t\t\t&rxfer->inserted_transfers[insert];\n\n\t \n\tINIT_LIST_HEAD(&rxfer->replaced_transfers);\n\n\t \n\trxfer->replaced_after = xfer_first->transfer_list.prev;\n\n\t \n\tfor (i = 0; i < remove; i++) {\n\t\t \n\t\tif (rxfer->replaced_after->next == &msg->transfers) {\n\t\t\tdev_err(&msg->spi->dev,\n\t\t\t\t\"requested to remove more spi_transfers than are available\\n\");\n\t\t\t \n\t\t\tlist_splice(&rxfer->replaced_transfers,\n\t\t\t\t    rxfer->replaced_after);\n\n\t\t\t \n\t\t\tspi_res_free(rxfer);\n\n\t\t\t \n\t\t\treturn ERR_PTR(-EINVAL);\n\t\t}\n\n\t\t \n\t\tlist_move_tail(rxfer->replaced_after->next,\n\t\t\t       &rxfer->replaced_transfers);\n\t}\n\n\t \n\tfor (i = 0; i < insert; i++) {\n\t\t \n\t\txfer = &rxfer->inserted_transfers[insert - 1 - i];\n\n\t\t \n\t\tmemcpy(xfer, xfer_first, sizeof(*xfer));\n\n\t\t \n\t\tlist_add(&xfer->transfer_list, rxfer->replaced_after);\n\n\t\t \n\t\tif (i) {\n\t\t\txfer->cs_change = false;\n\t\t\txfer->delay.value = 0;\n\t\t}\n\t}\n\n\t \n\trxfer->inserted = insert;\n\n\t \n\tspi_res_add(msg, rxfer);\n\n\treturn rxfer;\n}\n\nstatic int __spi_split_transfer_maxsize(struct spi_controller *ctlr,\n\t\t\t\t\tstruct spi_message *msg,\n\t\t\t\t\tstruct spi_transfer **xferp,\n\t\t\t\t\tsize_t maxsize,\n\t\t\t\t\tgfp_t gfp)\n{\n\tstruct spi_transfer *xfer = *xferp, *xfers;\n\tstruct spi_replaced_transfers *srt;\n\tsize_t offset;\n\tsize_t count, i;\n\n\t \n\tcount = DIV_ROUND_UP(xfer->len, maxsize);\n\n\t \n\tsrt = spi_replace_transfers(msg, xfer, 1, count, NULL, 0, gfp);\n\tif (IS_ERR(srt))\n\t\treturn PTR_ERR(srt);\n\txfers = srt->inserted_transfers;\n\n\t \n\n\t \n\txfers[0].len = min_t(size_t, maxsize, xfer[0].len);\n\n\t \n\tfor (i = 1, offset = maxsize; i < count; offset += maxsize, i++) {\n\t\t \n\t\tif (xfers[i].rx_buf)\n\t\t\txfers[i].rx_buf += offset;\n\t\tif (xfers[i].rx_dma)\n\t\t\txfers[i].rx_dma += offset;\n\t\tif (xfers[i].tx_buf)\n\t\t\txfers[i].tx_buf += offset;\n\t\tif (xfers[i].tx_dma)\n\t\t\txfers[i].tx_dma += offset;\n\n\t\t \n\t\txfers[i].len = min(maxsize, xfers[i].len - offset);\n\t}\n\n\t \n\t*xferp = &xfers[count - 1];\n\n\t \n\tSPI_STATISTICS_INCREMENT_FIELD(ctlr->pcpu_statistics,\n\t\t\t\t       transfers_split_maxsize);\n\tSPI_STATISTICS_INCREMENT_FIELD(msg->spi->pcpu_statistics,\n\t\t\t\t       transfers_split_maxsize);\n\n\treturn 0;\n}\n\n \nint spi_split_transfers_maxsize(struct spi_controller *ctlr,\n\t\t\t\tstruct spi_message *msg,\n\t\t\t\tsize_t maxsize,\n\t\t\t\tgfp_t gfp)\n{\n\tstruct spi_transfer *xfer;\n\tint ret;\n\n\t \n\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\tif (xfer->len > maxsize) {\n\t\t\tret = __spi_split_transfer_maxsize(ctlr, msg, &xfer,\n\t\t\t\t\t\t\t   maxsize, gfp);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(spi_split_transfers_maxsize);\n\n\n \nint spi_split_transfers_maxwords(struct spi_controller *ctlr,\n\t\t\t\t struct spi_message *msg,\n\t\t\t\t size_t maxwords,\n\t\t\t\t gfp_t gfp)\n{\n\tstruct spi_transfer *xfer;\n\n\t \n\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\tsize_t maxsize;\n\t\tint ret;\n\n\t\tmaxsize = maxwords * roundup_pow_of_two(BITS_TO_BYTES(xfer->bits_per_word));\n\t\tif (xfer->len > maxsize) {\n\t\t\tret = __spi_split_transfer_maxsize(ctlr, msg, &xfer,\n\t\t\t\t\t\t\t   maxsize, gfp);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(spi_split_transfers_maxwords);\n\n \n\n \n\nstatic int __spi_validate_bits_per_word(struct spi_controller *ctlr,\n\t\t\t\t\tu8 bits_per_word)\n{\n\tif (ctlr->bits_per_word_mask) {\n\t\t \n\t\tif (bits_per_word > 32)\n\t\t\treturn -EINVAL;\n\t\tif (!(ctlr->bits_per_word_mask & SPI_BPW_MASK(bits_per_word)))\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int spi_set_cs_timing(struct spi_device *spi)\n{\n\tstruct device *parent = spi->controller->dev.parent;\n\tint status = 0;\n\n\tif (spi->controller->set_cs_timing && !spi_get_csgpiod(spi, 0)) {\n\t\tif (spi->controller->auto_runtime_pm) {\n\t\t\tstatus = pm_runtime_get_sync(parent);\n\t\t\tif (status < 0) {\n\t\t\t\tpm_runtime_put_noidle(parent);\n\t\t\t\tdev_err(&spi->controller->dev, \"Failed to power device: %d\\n\",\n\t\t\t\t\tstatus);\n\t\t\t\treturn status;\n\t\t\t}\n\n\t\t\tstatus = spi->controller->set_cs_timing(spi);\n\t\t\tpm_runtime_mark_last_busy(parent);\n\t\t\tpm_runtime_put_autosuspend(parent);\n\t\t} else {\n\t\t\tstatus = spi->controller->set_cs_timing(spi);\n\t\t}\n\t}\n\treturn status;\n}\n\n \nint spi_setup(struct spi_device *spi)\n{\n\tunsigned\tbad_bits, ugly_bits;\n\tint\t\tstatus = 0;\n\n\t \n\tif ((hweight_long(spi->mode &\n\t\t(SPI_TX_DUAL | SPI_TX_QUAD | SPI_NO_TX)) > 1) ||\n\t    (hweight_long(spi->mode &\n\t\t(SPI_RX_DUAL | SPI_RX_QUAD | SPI_NO_RX)) > 1)) {\n\t\tdev_err(&spi->dev,\n\t\t\"setup: can not select any two of dual, quad and no-rx/tx at the same time\\n\");\n\t\treturn -EINVAL;\n\t}\n\t \n\tif ((spi->mode & SPI_3WIRE) && (spi->mode &\n\t\t(SPI_TX_DUAL | SPI_TX_QUAD | SPI_TX_OCTAL |\n\t\t SPI_RX_DUAL | SPI_RX_QUAD | SPI_RX_OCTAL)))\n\t\treturn -EINVAL;\n\t \n\tbad_bits = spi->mode & ~(spi->controller->mode_bits | SPI_CS_WORD |\n\t\t\t\t SPI_NO_TX | SPI_NO_RX);\n\tugly_bits = bad_bits &\n\t\t    (SPI_TX_DUAL | SPI_TX_QUAD | SPI_TX_OCTAL |\n\t\t     SPI_RX_DUAL | SPI_RX_QUAD | SPI_RX_OCTAL);\n\tif (ugly_bits) {\n\t\tdev_warn(&spi->dev,\n\t\t\t \"setup: ignoring unsupported mode bits %x\\n\",\n\t\t\t ugly_bits);\n\t\tspi->mode &= ~ugly_bits;\n\t\tbad_bits &= ~ugly_bits;\n\t}\n\tif (bad_bits) {\n\t\tdev_err(&spi->dev, \"setup: unsupported mode bits %x\\n\",\n\t\t\tbad_bits);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!spi->bits_per_word) {\n\t\tspi->bits_per_word = 8;\n\t} else {\n\t\t \n\t\tstatus = __spi_validate_bits_per_word(spi->controller,\n\t\t\t\t\t\t      spi->bits_per_word);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\n\tif (spi->controller->max_speed_hz &&\n\t    (!spi->max_speed_hz ||\n\t     spi->max_speed_hz > spi->controller->max_speed_hz))\n\t\tspi->max_speed_hz = spi->controller->max_speed_hz;\n\n\tmutex_lock(&spi->controller->io_mutex);\n\n\tif (spi->controller->setup) {\n\t\tstatus = spi->controller->setup(spi);\n\t\tif (status) {\n\t\t\tmutex_unlock(&spi->controller->io_mutex);\n\t\t\tdev_err(&spi->controller->dev, \"Failed to setup device: %d\\n\",\n\t\t\t\tstatus);\n\t\t\treturn status;\n\t\t}\n\t}\n\n\tstatus = spi_set_cs_timing(spi);\n\tif (status) {\n\t\tmutex_unlock(&spi->controller->io_mutex);\n\t\treturn status;\n\t}\n\n\tif (spi->controller->auto_runtime_pm && spi->controller->set_cs) {\n\t\tstatus = pm_runtime_resume_and_get(spi->controller->dev.parent);\n\t\tif (status < 0) {\n\t\t\tmutex_unlock(&spi->controller->io_mutex);\n\t\t\tdev_err(&spi->controller->dev, \"Failed to power device: %d\\n\",\n\t\t\t\tstatus);\n\t\t\treturn status;\n\t\t}\n\n\t\t \n\t\tstatus = 0;\n\n\t\tspi_set_cs(spi, false, true);\n\t\tpm_runtime_mark_last_busy(spi->controller->dev.parent);\n\t\tpm_runtime_put_autosuspend(spi->controller->dev.parent);\n\t} else {\n\t\tspi_set_cs(spi, false, true);\n\t}\n\n\tmutex_unlock(&spi->controller->io_mutex);\n\n\tif (spi->rt && !spi->controller->rt) {\n\t\tspi->controller->rt = true;\n\t\tspi_set_thread_rt(spi->controller);\n\t}\n\n\ttrace_spi_setup(spi, status);\n\n\tdev_dbg(&spi->dev, \"setup mode %lu, %s%s%s%s%u bits/w, %u Hz max --> %d\\n\",\n\t\t\tspi->mode & SPI_MODE_X_MASK,\n\t\t\t(spi->mode & SPI_CS_HIGH) ? \"cs_high, \" : \"\",\n\t\t\t(spi->mode & SPI_LSB_FIRST) ? \"lsb, \" : \"\",\n\t\t\t(spi->mode & SPI_3WIRE) ? \"3wire, \" : \"\",\n\t\t\t(spi->mode & SPI_LOOP) ? \"loopback, \" : \"\",\n\t\t\tspi->bits_per_word, spi->max_speed_hz,\n\t\t\tstatus);\n\n\treturn status;\n}\nEXPORT_SYMBOL_GPL(spi_setup);\n\nstatic int _spi_xfer_word_delay_update(struct spi_transfer *xfer,\n\t\t\t\t       struct spi_device *spi)\n{\n\tint delay1, delay2;\n\n\tdelay1 = spi_delay_to_ns(&xfer->word_delay, xfer);\n\tif (delay1 < 0)\n\t\treturn delay1;\n\n\tdelay2 = spi_delay_to_ns(&spi->word_delay, xfer);\n\tif (delay2 < 0)\n\t\treturn delay2;\n\n\tif (delay1 < delay2)\n\t\tmemcpy(&xfer->word_delay, &spi->word_delay,\n\t\t       sizeof(xfer->word_delay));\n\n\treturn 0;\n}\n\nstatic int __spi_validate(struct spi_device *spi, struct spi_message *message)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\tstruct spi_transfer *xfer;\n\tint w_size;\n\n\tif (list_empty(&message->transfers))\n\t\treturn -EINVAL;\n\n\t \n\tif ((spi->mode & SPI_CS_WORD) && (!(ctlr->mode_bits & SPI_CS_WORD) ||\n\t\t\t\t\t  spi_get_csgpiod(spi, 0))) {\n\t\tsize_t maxsize = BITS_TO_BYTES(spi->bits_per_word);\n\t\tint ret;\n\n\t\t \n\t\tmessage->spi = spi;\n\n\t\tret = spi_split_transfers_maxsize(ctlr, message, maxsize,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tlist_for_each_entry(xfer, &message->transfers, transfer_list) {\n\t\t\t \n\t\t\tif (list_is_last(&xfer->transfer_list, &message->transfers))\n\t\t\t\tbreak;\n\t\t\txfer->cs_change = 1;\n\t\t}\n\t}\n\n\t \n\tif ((ctlr->flags & SPI_CONTROLLER_HALF_DUPLEX) ||\n\t    (spi->mode & SPI_3WIRE)) {\n\t\tunsigned flags = ctlr->flags;\n\n\t\tlist_for_each_entry(xfer, &message->transfers, transfer_list) {\n\t\t\tif (xfer->rx_buf && xfer->tx_buf)\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((flags & SPI_CONTROLLER_NO_TX) && xfer->tx_buf)\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((flags & SPI_CONTROLLER_NO_RX) && xfer->rx_buf)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t \n\tmessage->frame_length = 0;\n\tlist_for_each_entry(xfer, &message->transfers, transfer_list) {\n\t\txfer->effective_speed_hz = 0;\n\t\tmessage->frame_length += xfer->len;\n\t\tif (!xfer->bits_per_word)\n\t\t\txfer->bits_per_word = spi->bits_per_word;\n\n\t\tif (!xfer->speed_hz)\n\t\t\txfer->speed_hz = spi->max_speed_hz;\n\n\t\tif (ctlr->max_speed_hz && xfer->speed_hz > ctlr->max_speed_hz)\n\t\t\txfer->speed_hz = ctlr->max_speed_hz;\n\n\t\tif (__spi_validate_bits_per_word(ctlr, xfer->bits_per_word))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (xfer->bits_per_word <= 8)\n\t\t\tw_size = 1;\n\t\telse if (xfer->bits_per_word <= 16)\n\t\t\tw_size = 2;\n\t\telse\n\t\t\tw_size = 4;\n\n\t\t \n\t\tif (xfer->len % w_size)\n\t\t\treturn -EINVAL;\n\n\t\tif (xfer->speed_hz && ctlr->min_speed_hz &&\n\t\t    xfer->speed_hz < ctlr->min_speed_hz)\n\t\t\treturn -EINVAL;\n\n\t\tif (xfer->tx_buf && !xfer->tx_nbits)\n\t\t\txfer->tx_nbits = SPI_NBITS_SINGLE;\n\t\tif (xfer->rx_buf && !xfer->rx_nbits)\n\t\t\txfer->rx_nbits = SPI_NBITS_SINGLE;\n\t\t \n\t\tif (xfer->tx_buf) {\n\t\t\tif (spi->mode & SPI_NO_TX)\n\t\t\t\treturn -EINVAL;\n\t\t\tif (xfer->tx_nbits != SPI_NBITS_SINGLE &&\n\t\t\t\txfer->tx_nbits != SPI_NBITS_DUAL &&\n\t\t\t\txfer->tx_nbits != SPI_NBITS_QUAD)\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((xfer->tx_nbits == SPI_NBITS_DUAL) &&\n\t\t\t\t!(spi->mode & (SPI_TX_DUAL | SPI_TX_QUAD)))\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((xfer->tx_nbits == SPI_NBITS_QUAD) &&\n\t\t\t\t!(spi->mode & SPI_TX_QUAD))\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\t \n\t\tif (xfer->rx_buf) {\n\t\t\tif (spi->mode & SPI_NO_RX)\n\t\t\t\treturn -EINVAL;\n\t\t\tif (xfer->rx_nbits != SPI_NBITS_SINGLE &&\n\t\t\t\txfer->rx_nbits != SPI_NBITS_DUAL &&\n\t\t\t\txfer->rx_nbits != SPI_NBITS_QUAD)\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((xfer->rx_nbits == SPI_NBITS_DUAL) &&\n\t\t\t\t!(spi->mode & (SPI_RX_DUAL | SPI_RX_QUAD)))\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((xfer->rx_nbits == SPI_NBITS_QUAD) &&\n\t\t\t\t!(spi->mode & SPI_RX_QUAD))\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (_spi_xfer_word_delay_update(xfer, spi))\n\t\t\treturn -EINVAL;\n\t}\n\n\tmessage->status = -EINPROGRESS;\n\n\treturn 0;\n}\n\nstatic int __spi_async(struct spi_device *spi, struct spi_message *message)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\tstruct spi_transfer *xfer;\n\n\t \n\tif (!ctlr->transfer)\n\t\treturn -ENOTSUPP;\n\n\tmessage->spi = spi;\n\n\tSPI_STATISTICS_INCREMENT_FIELD(ctlr->pcpu_statistics, spi_async);\n\tSPI_STATISTICS_INCREMENT_FIELD(spi->pcpu_statistics, spi_async);\n\n\ttrace_spi_message_submit(message);\n\n\tif (!ctlr->ptp_sts_supported) {\n\t\tlist_for_each_entry(xfer, &message->transfers, transfer_list) {\n\t\t\txfer->ptp_sts_word_pre = 0;\n\t\t\tptp_read_system_prets(xfer->ptp_sts);\n\t\t}\n\t}\n\n\treturn ctlr->transfer(spi, message);\n}\n\n \nint spi_async(struct spi_device *spi, struct spi_message *message)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\tint ret;\n\tunsigned long flags;\n\n\tret = __spi_validate(spi, message);\n\tif (ret != 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&ctlr->bus_lock_spinlock, flags);\n\n\tif (ctlr->bus_lock_flag)\n\t\tret = -EBUSY;\n\telse\n\t\tret = __spi_async(spi, message);\n\n\tspin_unlock_irqrestore(&ctlr->bus_lock_spinlock, flags);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(spi_async);\n\n \nstatic int spi_async_locked(struct spi_device *spi, struct spi_message *message)\n{\n\tstruct spi_controller *ctlr = spi->controller;\n\tint ret;\n\tunsigned long flags;\n\n\tret = __spi_validate(spi, message);\n\tif (ret != 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&ctlr->bus_lock_spinlock, flags);\n\n\tret = __spi_async(spi, message);\n\n\tspin_unlock_irqrestore(&ctlr->bus_lock_spinlock, flags);\n\n\treturn ret;\n\n}\n\nstatic void __spi_transfer_message_noqueue(struct spi_controller *ctlr, struct spi_message *msg)\n{\n\tbool was_busy;\n\tint ret;\n\n\tmutex_lock(&ctlr->io_mutex);\n\n\twas_busy = ctlr->busy;\n\n\tctlr->cur_msg = msg;\n\tret = __spi_pump_transfer_message(ctlr, msg, was_busy);\n\tif (ret)\n\t\tdev_err(&ctlr->dev, \"noqueue transfer failed\\n\");\n\tctlr->cur_msg = NULL;\n\tctlr->fallback = false;\n\n\tif (!was_busy) {\n\t\tkfree(ctlr->dummy_rx);\n\t\tctlr->dummy_rx = NULL;\n\t\tkfree(ctlr->dummy_tx);\n\t\tctlr->dummy_tx = NULL;\n\t\tif (ctlr->unprepare_transfer_hardware &&\n\t\t    ctlr->unprepare_transfer_hardware(ctlr))\n\t\t\tdev_err(&ctlr->dev,\n\t\t\t\t\"failed to unprepare transfer hardware\\n\");\n\t\tspi_idle_runtime_pm(ctlr);\n\t}\n\n\tmutex_unlock(&ctlr->io_mutex);\n}\n\n \n\n \n\nstatic void spi_complete(void *arg)\n{\n\tcomplete(arg);\n}\n\nstatic int __spi_sync(struct spi_device *spi, struct spi_message *message)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tint status;\n\tstruct spi_controller *ctlr = spi->controller;\n\n\tif (__spi_check_suspended(ctlr)) {\n\t\tdev_warn_once(&spi->dev, \"Attempted to sync while suspend\\n\");\n\t\treturn -ESHUTDOWN;\n\t}\n\n\tstatus = __spi_validate(spi, message);\n\tif (status != 0)\n\t\treturn status;\n\n\tmessage->spi = spi;\n\n\tSPI_STATISTICS_INCREMENT_FIELD(ctlr->pcpu_statistics, spi_sync);\n\tSPI_STATISTICS_INCREMENT_FIELD(spi->pcpu_statistics, spi_sync);\n\n\t \n\tif (READ_ONCE(ctlr->queue_empty) && !ctlr->must_async) {\n\t\tmessage->actual_length = 0;\n\t\tmessage->status = -EINPROGRESS;\n\n\t\ttrace_spi_message_submit(message);\n\n\t\tSPI_STATISTICS_INCREMENT_FIELD(ctlr->pcpu_statistics, spi_sync_immediate);\n\t\tSPI_STATISTICS_INCREMENT_FIELD(spi->pcpu_statistics, spi_sync_immediate);\n\n\t\t__spi_transfer_message_noqueue(ctlr, message);\n\n\t\treturn message->status;\n\t}\n\n\t \n\tmessage->complete = spi_complete;\n\tmessage->context = &done;\n\tstatus = spi_async_locked(spi, message);\n\tif (status == 0) {\n\t\twait_for_completion(&done);\n\t\tstatus = message->status;\n\t}\n\tmessage->context = NULL;\n\n\treturn status;\n}\n\n \nint spi_sync(struct spi_device *spi, struct spi_message *message)\n{\n\tint ret;\n\n\tmutex_lock(&spi->controller->bus_lock_mutex);\n\tret = __spi_sync(spi, message);\n\tmutex_unlock(&spi->controller->bus_lock_mutex);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(spi_sync);\n\n \nint spi_sync_locked(struct spi_device *spi, struct spi_message *message)\n{\n\treturn __spi_sync(spi, message);\n}\nEXPORT_SYMBOL_GPL(spi_sync_locked);\n\n \nint spi_bus_lock(struct spi_controller *ctlr)\n{\n\tunsigned long flags;\n\n\tmutex_lock(&ctlr->bus_lock_mutex);\n\n\tspin_lock_irqsave(&ctlr->bus_lock_spinlock, flags);\n\tctlr->bus_lock_flag = 1;\n\tspin_unlock_irqrestore(&ctlr->bus_lock_spinlock, flags);\n\n\t \n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(spi_bus_lock);\n\n \nint spi_bus_unlock(struct spi_controller *ctlr)\n{\n\tctlr->bus_lock_flag = 0;\n\n\tmutex_unlock(&ctlr->bus_lock_mutex);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(spi_bus_unlock);\n\n \n#define\tSPI_BUFSIZ\tmax(32, SMP_CACHE_BYTES)\n\nstatic u8\t*buf;\n\n \nint spi_write_then_read(struct spi_device *spi,\n\t\tconst void *txbuf, unsigned n_tx,\n\t\tvoid *rxbuf, unsigned n_rx)\n{\n\tstatic DEFINE_MUTEX(lock);\n\n\tint\t\t\tstatus;\n\tstruct spi_message\tmessage;\n\tstruct spi_transfer\tx[2];\n\tu8\t\t\t*local_buf;\n\n\t \n\tif ((n_tx + n_rx) > SPI_BUFSIZ || !mutex_trylock(&lock)) {\n\t\tlocal_buf = kmalloc(max((unsigned)SPI_BUFSIZ, n_tx + n_rx),\n\t\t\t\t    GFP_KERNEL | GFP_DMA);\n\t\tif (!local_buf)\n\t\t\treturn -ENOMEM;\n\t} else {\n\t\tlocal_buf = buf;\n\t}\n\n\tspi_message_init(&message);\n\tmemset(x, 0, sizeof(x));\n\tif (n_tx) {\n\t\tx[0].len = n_tx;\n\t\tspi_message_add_tail(&x[0], &message);\n\t}\n\tif (n_rx) {\n\t\tx[1].len = n_rx;\n\t\tspi_message_add_tail(&x[1], &message);\n\t}\n\n\tmemcpy(local_buf, txbuf, n_tx);\n\tx[0].tx_buf = local_buf;\n\tx[1].rx_buf = local_buf + n_tx;\n\n\t \n\tstatus = spi_sync(spi, &message);\n\tif (status == 0)\n\t\tmemcpy(rxbuf, x[1].rx_buf, n_rx);\n\n\tif (x[0].tx_buf == buf)\n\t\tmutex_unlock(&lock);\n\telse\n\t\tkfree(local_buf);\n\n\treturn status;\n}\nEXPORT_SYMBOL_GPL(spi_write_then_read);\n\n \n\n#if IS_ENABLED(CONFIG_OF_DYNAMIC)\n \nstatic struct spi_device *of_find_spi_device_by_node(struct device_node *node)\n{\n\tstruct device *dev = bus_find_device_by_of_node(&spi_bus_type, node);\n\n\treturn dev ? to_spi_device(dev) : NULL;\n}\n\n \nstatic struct spi_controller *of_find_spi_controller_by_node(struct device_node *node)\n{\n\tstruct device *dev;\n\n\tdev = class_find_device_by_of_node(&spi_master_class, node);\n\tif (!dev && IS_ENABLED(CONFIG_SPI_SLAVE))\n\t\tdev = class_find_device_by_of_node(&spi_slave_class, node);\n\tif (!dev)\n\t\treturn NULL;\n\n\t \n\treturn container_of(dev, struct spi_controller, dev);\n}\n\nstatic int of_spi_notify(struct notifier_block *nb, unsigned long action,\n\t\t\t void *arg)\n{\n\tstruct of_reconfig_data *rd = arg;\n\tstruct spi_controller *ctlr;\n\tstruct spi_device *spi;\n\n\tswitch (of_reconfig_get_state_change(action, arg)) {\n\tcase OF_RECONFIG_CHANGE_ADD:\n\t\tctlr = of_find_spi_controller_by_node(rd->dn->parent);\n\t\tif (ctlr == NULL)\n\t\t\treturn NOTIFY_OK;\t \n\n\t\tif (of_node_test_and_set_flag(rd->dn, OF_POPULATED)) {\n\t\t\tput_device(&ctlr->dev);\n\t\t\treturn NOTIFY_OK;\n\t\t}\n\n\t\t \n\t\trd->dn->fwnode.flags &= ~FWNODE_FLAG_NOT_DEVICE;\n\t\tspi = of_register_spi_device(ctlr, rd->dn);\n\t\tput_device(&ctlr->dev);\n\n\t\tif (IS_ERR(spi)) {\n\t\t\tpr_err(\"%s: failed to create for '%pOF'\\n\",\n\t\t\t\t\t__func__, rd->dn);\n\t\t\tof_node_clear_flag(rd->dn, OF_POPULATED);\n\t\t\treturn notifier_from_errno(PTR_ERR(spi));\n\t\t}\n\t\tbreak;\n\n\tcase OF_RECONFIG_CHANGE_REMOVE:\n\t\t \n\t\tif (!of_node_check_flag(rd->dn, OF_POPULATED))\n\t\t\treturn NOTIFY_OK;\n\n\t\t \n\t\tspi = of_find_spi_device_by_node(rd->dn);\n\t\tif (spi == NULL)\n\t\t\treturn NOTIFY_OK;\t \n\n\t\t \n\t\tspi_unregister_device(spi);\n\n\t\t \n\t\tput_device(&spi->dev);\n\t\tbreak;\n\t}\n\n\treturn NOTIFY_OK;\n}\n\nstatic struct notifier_block spi_of_notifier = {\n\t.notifier_call = of_spi_notify,\n};\n#else  \nextern struct notifier_block spi_of_notifier;\n#endif  \n\n#if IS_ENABLED(CONFIG_ACPI)\nstatic int spi_acpi_controller_match(struct device *dev, const void *data)\n{\n\treturn ACPI_COMPANION(dev->parent) == data;\n}\n\nstatic struct spi_controller *acpi_spi_find_controller_by_adev(struct acpi_device *adev)\n{\n\tstruct device *dev;\n\n\tdev = class_find_device(&spi_master_class, NULL, adev,\n\t\t\t\tspi_acpi_controller_match);\n\tif (!dev && IS_ENABLED(CONFIG_SPI_SLAVE))\n\t\tdev = class_find_device(&spi_slave_class, NULL, adev,\n\t\t\t\t\tspi_acpi_controller_match);\n\tif (!dev)\n\t\treturn NULL;\n\n\treturn container_of(dev, struct spi_controller, dev);\n}\n\nstatic struct spi_device *acpi_spi_find_device_by_adev(struct acpi_device *adev)\n{\n\tstruct device *dev;\n\n\tdev = bus_find_device_by_acpi_dev(&spi_bus_type, adev);\n\treturn to_spi_device(dev);\n}\n\nstatic int acpi_spi_notify(struct notifier_block *nb, unsigned long value,\n\t\t\t   void *arg)\n{\n\tstruct acpi_device *adev = arg;\n\tstruct spi_controller *ctlr;\n\tstruct spi_device *spi;\n\n\tswitch (value) {\n\tcase ACPI_RECONFIG_DEVICE_ADD:\n\t\tctlr = acpi_spi_find_controller_by_adev(acpi_dev_parent(adev));\n\t\tif (!ctlr)\n\t\t\tbreak;\n\n\t\tacpi_register_spi_device(ctlr, adev);\n\t\tput_device(&ctlr->dev);\n\t\tbreak;\n\tcase ACPI_RECONFIG_DEVICE_REMOVE:\n\t\tif (!acpi_device_enumerated(adev))\n\t\t\tbreak;\n\n\t\tspi = acpi_spi_find_device_by_adev(adev);\n\t\tif (!spi)\n\t\t\tbreak;\n\n\t\tspi_unregister_device(spi);\n\t\tput_device(&spi->dev);\n\t\tbreak;\n\t}\n\n\treturn NOTIFY_OK;\n}\n\nstatic struct notifier_block spi_acpi_notifier = {\n\t.notifier_call = acpi_spi_notify,\n};\n#else\nextern struct notifier_block spi_acpi_notifier;\n#endif\n\nstatic int __init spi_init(void)\n{\n\tint\tstatus;\n\n\tbuf = kmalloc(SPI_BUFSIZ, GFP_KERNEL);\n\tif (!buf) {\n\t\tstatus = -ENOMEM;\n\t\tgoto err0;\n\t}\n\n\tstatus = bus_register(&spi_bus_type);\n\tif (status < 0)\n\t\tgoto err1;\n\n\tstatus = class_register(&spi_master_class);\n\tif (status < 0)\n\t\tgoto err2;\n\n\tif (IS_ENABLED(CONFIG_SPI_SLAVE)) {\n\t\tstatus = class_register(&spi_slave_class);\n\t\tif (status < 0)\n\t\t\tgoto err3;\n\t}\n\n\tif (IS_ENABLED(CONFIG_OF_DYNAMIC))\n\t\tWARN_ON(of_reconfig_notifier_register(&spi_of_notifier));\n\tif (IS_ENABLED(CONFIG_ACPI))\n\t\tWARN_ON(acpi_reconfig_notifier_register(&spi_acpi_notifier));\n\n\treturn 0;\n\nerr3:\n\tclass_unregister(&spi_master_class);\nerr2:\n\tbus_unregister(&spi_bus_type);\nerr1:\n\tkfree(buf);\n\tbuf = NULL;\nerr0:\n\treturn status;\n}\n\n \npostcore_initcall(spi_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}