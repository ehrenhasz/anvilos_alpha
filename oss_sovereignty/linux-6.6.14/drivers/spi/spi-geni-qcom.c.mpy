{
  "module_name": "spi-geni-qcom.c",
  "hash_id": "93a453bafcfe8ed0c80e72e41aafac8acb602125d14acf7a6320c00f68f316ad",
  "original_prompt": "Ingested from linux-6.6.14/drivers/spi/spi-geni-qcom.c",
  "human_readable_source": "\n\n\n#include <linux/clk.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/dma/qcom-gpi-dma.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/log2.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/pm_opp.h>\n#include <linux/pm_runtime.h>\n#include <linux/property.h>\n#include <linux/soc/qcom/geni-se.h>\n#include <linux/spi/spi.h>\n#include <linux/spinlock.h>\n\n \n#define SE_SPI_CPHA\t\t0x224\n#define CPHA\t\t\tBIT(0)\n\n#define SE_SPI_LOOPBACK\t\t0x22c\n#define LOOPBACK_ENABLE\t\t0x1\n#define NORMAL_MODE\t\t0x0\n#define LOOPBACK_MSK\t\tGENMASK(1, 0)\n\n#define SE_SPI_CPOL\t\t0x230\n#define CPOL\t\t\tBIT(2)\n\n#define SE_SPI_DEMUX_OUTPUT_INV\t0x24c\n#define CS_DEMUX_OUTPUT_INV_MSK\tGENMASK(3, 0)\n\n#define SE_SPI_DEMUX_SEL\t0x250\n#define CS_DEMUX_OUTPUT_SEL\tGENMASK(3, 0)\n\n#define SE_SPI_TRANS_CFG\t0x25c\n#define CS_TOGGLE\t\tBIT(1)\n\n#define SE_SPI_WORD_LEN\t\t0x268\n#define WORD_LEN_MSK\t\tGENMASK(9, 0)\n#define MIN_WORD_LEN\t\t4\n\n#define SE_SPI_TX_TRANS_LEN\t0x26c\n#define SE_SPI_RX_TRANS_LEN\t0x270\n#define TRANS_LEN_MSK\t\tGENMASK(23, 0)\n\n#define SE_SPI_PRE_POST_CMD_DLY\t0x274\n\n#define SE_SPI_DELAY_COUNTERS\t0x278\n#define SPI_INTER_WORDS_DELAY_MSK\tGENMASK(9, 0)\n#define SPI_CS_CLK_DELAY_MSK\t\tGENMASK(19, 10)\n#define SPI_CS_CLK_DELAY_SHFT\t\t10\n\n#define SE_SPI_SLAVE_EN\t\t\t\t(0x2BC)\n#define SPI_SLAVE_EN\t\t\t\tBIT(0)\n\n \n#define SPI_TX_ONLY\t\t1\n#define SPI_RX_ONLY\t\t2\n#define SPI_TX_RX\t\t7\n#define SPI_CS_ASSERT\t\t8\n#define SPI_CS_DEASSERT\t\t9\n#define SPI_SCK_ONLY\t\t10\n \n#define SPI_PRE_CMD_DELAY\tBIT(0)\n#define TIMESTAMP_BEFORE\tBIT(1)\n#define FRAGMENTATION\t\tBIT(2)\n#define TIMESTAMP_AFTER\t\tBIT(3)\n#define POST_CMD_DELAY\t\tBIT(4)\n\n#define GSI_LOOPBACK_EN\t\tBIT(0)\n#define GSI_CS_TOGGLE\t\tBIT(3)\n#define GSI_CPHA\t\tBIT(4)\n#define GSI_CPOL\t\tBIT(5)\n\nstruct spi_geni_master {\n\tstruct geni_se se;\n\tstruct device *dev;\n\tu32 tx_fifo_depth;\n\tu32 fifo_width_bits;\n\tu32 tx_wm;\n\tu32 last_mode;\n\tunsigned long cur_speed_hz;\n\tunsigned long cur_sclk_hz;\n\tunsigned int cur_bits_per_word;\n\tunsigned int tx_rem_bytes;\n\tunsigned int rx_rem_bytes;\n\tconst struct spi_transfer *cur_xfer;\n\tstruct completion cs_done;\n\tstruct completion cancel_done;\n\tstruct completion abort_done;\n\tstruct completion tx_reset_done;\n\tstruct completion rx_reset_done;\n\tunsigned int oversampling;\n\tspinlock_t lock;\n\tint irq;\n\tbool cs_flag;\n\tbool abort_failed;\n\tstruct dma_chan *tx;\n\tstruct dma_chan *rx;\n\tint cur_xfer_mode;\n};\n\nstatic void spi_slv_setup(struct spi_geni_master *mas)\n{\n\tstruct geni_se *se = &mas->se;\n\n\twritel(SPI_SLAVE_EN, se->base + SE_SPI_SLAVE_EN);\n\twritel(GENI_IO_MUX_0_EN, se->base + GENI_OUTPUT_CTRL);\n\twritel(START_TRIGGER, se->base + SE_GENI_CFG_SEQ_START);\n\tdev_dbg(mas->dev, \"spi slave setup done\\n\");\n}\n\nstatic int get_spi_clk_cfg(unsigned int speed_hz,\n\t\t\tstruct spi_geni_master *mas,\n\t\t\tunsigned int *clk_idx,\n\t\t\tunsigned int *clk_div)\n{\n\tunsigned long sclk_freq;\n\tunsigned int actual_hz;\n\tint ret;\n\n\tret = geni_se_clk_freq_match(&mas->se,\n\t\t\t\tspeed_hz * mas->oversampling,\n\t\t\t\tclk_idx, &sclk_freq, false);\n\tif (ret) {\n\t\tdev_err(mas->dev, \"Failed(%d) to find src clk for %dHz\\n\",\n\t\t\t\t\t\t\tret, speed_hz);\n\t\treturn ret;\n\t}\n\n\t*clk_div = DIV_ROUND_UP(sclk_freq, mas->oversampling * speed_hz);\n\tactual_hz = sclk_freq / (mas->oversampling * *clk_div);\n\n\tdev_dbg(mas->dev, \"req %u=>%u sclk %lu, idx %d, div %d\\n\", speed_hz,\n\t\t\t\tactual_hz, sclk_freq, *clk_idx, *clk_div);\n\tret = dev_pm_opp_set_rate(mas->dev, sclk_freq);\n\tif (ret)\n\t\tdev_err(mas->dev, \"dev_pm_opp_set_rate failed %d\\n\", ret);\n\telse\n\t\tmas->cur_sclk_hz = sclk_freq;\n\n\treturn ret;\n}\n\nstatic void handle_se_timeout(struct spi_master *spi,\n\t\t\t\tstruct spi_message *msg)\n{\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\tunsigned long time_left;\n\tstruct geni_se *se = &mas->se;\n\tconst struct spi_transfer *xfer;\n\n\tspin_lock_irq(&mas->lock);\n\tif (mas->cur_xfer_mode == GENI_SE_FIFO)\n\t\twritel(0, se->base + SE_GENI_TX_WATERMARK_REG);\n\n\txfer = mas->cur_xfer;\n\tmas->cur_xfer = NULL;\n\n\tif (spi->slave) {\n\t\t \n\t\tspin_unlock_irq(&mas->lock);\n\t\tgoto unmap_if_dma;\n\t}\n\n\treinit_completion(&mas->cancel_done);\n\tgeni_se_cancel_m_cmd(se);\n\tspin_unlock_irq(&mas->lock);\n\n\ttime_left = wait_for_completion_timeout(&mas->cancel_done, HZ);\n\tif (time_left)\n\t\tgoto unmap_if_dma;\n\n\tspin_lock_irq(&mas->lock);\n\treinit_completion(&mas->abort_done);\n\tgeni_se_abort_m_cmd(se);\n\tspin_unlock_irq(&mas->lock);\n\n\ttime_left = wait_for_completion_timeout(&mas->abort_done, HZ);\n\tif (!time_left) {\n\t\tdev_err(mas->dev, \"Failed to cancel/abort m_cmd\\n\");\n\n\t\t \n\t\tmas->abort_failed = true;\n\t}\n\nunmap_if_dma:\n\tif (mas->cur_xfer_mode == GENI_SE_DMA) {\n\t\tif (xfer) {\n\t\t\tif (xfer->tx_buf) {\n\t\t\t\tspin_lock_irq(&mas->lock);\n\t\t\t\treinit_completion(&mas->tx_reset_done);\n\t\t\t\twritel(1, se->base + SE_DMA_TX_FSM_RST);\n\t\t\t\tspin_unlock_irq(&mas->lock);\n\t\t\t\ttime_left = wait_for_completion_timeout(&mas->tx_reset_done, HZ);\n\t\t\t\tif (!time_left)\n\t\t\t\t\tdev_err(mas->dev, \"DMA TX RESET failed\\n\");\n\t\t\t}\n\t\t\tif (xfer->rx_buf) {\n\t\t\t\tspin_lock_irq(&mas->lock);\n\t\t\t\treinit_completion(&mas->rx_reset_done);\n\t\t\t\twritel(1, se->base + SE_DMA_RX_FSM_RST);\n\t\t\t\tspin_unlock_irq(&mas->lock);\n\t\t\t\ttime_left = wait_for_completion_timeout(&mas->rx_reset_done, HZ);\n\t\t\t\tif (!time_left)\n\t\t\t\t\tdev_err(mas->dev, \"DMA RX RESET failed\\n\");\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tdev_warn(mas->dev, \"Cancel/Abort on completed SPI transfer\\n\");\n\t\t}\n\t}\n}\n\nstatic void handle_gpi_timeout(struct spi_master *spi, struct spi_message *msg)\n{\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\n\tdmaengine_terminate_sync(mas->tx);\n\tdmaengine_terminate_sync(mas->rx);\n}\n\nstatic void spi_geni_handle_err(struct spi_master *spi, struct spi_message *msg)\n{\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\n\tswitch (mas->cur_xfer_mode) {\n\tcase GENI_SE_FIFO:\n\tcase GENI_SE_DMA:\n\t\thandle_se_timeout(spi, msg);\n\t\tbreak;\n\tcase GENI_GPI_DMA:\n\t\thandle_gpi_timeout(spi, msg);\n\t\tbreak;\n\tdefault:\n\t\tdev_err(mas->dev, \"Abort on Mode:%d not supported\", mas->cur_xfer_mode);\n\t}\n}\n\nstatic bool spi_geni_is_abort_still_pending(struct spi_geni_master *mas)\n{\n\tstruct geni_se *se = &mas->se;\n\tu32 m_irq, m_irq_en;\n\n\tif (!mas->abort_failed)\n\t\treturn false;\n\n\t \n\tspin_lock_irq(&mas->lock);\n\tm_irq = readl(se->base + SE_GENI_M_IRQ_STATUS);\n\tm_irq_en = readl(se->base + SE_GENI_M_IRQ_EN);\n\tspin_unlock_irq(&mas->lock);\n\n\tif (m_irq & m_irq_en) {\n\t\tdev_err(mas->dev, \"Interrupts pending after abort: %#010x\\n\",\n\t\t\tm_irq & m_irq_en);\n\t\treturn true;\n\t}\n\n\t \n\tmas->abort_failed = false;\n\n\treturn false;\n}\n\nstatic void spi_geni_set_cs(struct spi_device *slv, bool set_flag)\n{\n\tstruct spi_geni_master *mas = spi_master_get_devdata(slv->master);\n\tstruct spi_master *spi = dev_get_drvdata(mas->dev);\n\tstruct geni_se *se = &mas->se;\n\tunsigned long time_left;\n\n\tif (!(slv->mode & SPI_CS_HIGH))\n\t\tset_flag = !set_flag;\n\n\tif (set_flag == mas->cs_flag)\n\t\treturn;\n\n\tpm_runtime_get_sync(mas->dev);\n\n\tif (spi_geni_is_abort_still_pending(mas)) {\n\t\tdev_err(mas->dev, \"Can't set chip select\\n\");\n\t\tgoto exit;\n\t}\n\n\tspin_lock_irq(&mas->lock);\n\tif (mas->cur_xfer) {\n\t\tdev_err(mas->dev, \"Can't set CS when prev xfer running\\n\");\n\t\tspin_unlock_irq(&mas->lock);\n\t\tgoto exit;\n\t}\n\n\tmas->cs_flag = set_flag;\n\t \n\tmas->cur_xfer_mode = GENI_SE_FIFO;\n\tgeni_se_select_mode(se, mas->cur_xfer_mode);\n\n\treinit_completion(&mas->cs_done);\n\tif (set_flag)\n\t\tgeni_se_setup_m_cmd(se, SPI_CS_ASSERT, 0);\n\telse\n\t\tgeni_se_setup_m_cmd(se, SPI_CS_DEASSERT, 0);\n\tspin_unlock_irq(&mas->lock);\n\n\ttime_left = wait_for_completion_timeout(&mas->cs_done, HZ);\n\tif (!time_left) {\n\t\tdev_warn(mas->dev, \"Timeout setting chip select\\n\");\n\t\thandle_se_timeout(spi, NULL);\n\t}\n\nexit:\n\tpm_runtime_put(mas->dev);\n}\n\nstatic void spi_setup_word_len(struct spi_geni_master *mas, u16 mode,\n\t\t\t\t\tunsigned int bits_per_word)\n{\n\tunsigned int pack_words;\n\tbool msb_first = (mode & SPI_LSB_FIRST) ? false : true;\n\tstruct geni_se *se = &mas->se;\n\tu32 word_len;\n\n\t \n\tif (!(mas->fifo_width_bits % bits_per_word))\n\t\tpack_words = mas->fifo_width_bits / bits_per_word;\n\telse\n\t\tpack_words = 1;\n\tgeni_se_config_packing(&mas->se, bits_per_word, pack_words, msb_first,\n\t\t\t\t\t\t\t\ttrue, true);\n\tword_len = (bits_per_word - MIN_WORD_LEN) & WORD_LEN_MSK;\n\twritel(word_len, se->base + SE_SPI_WORD_LEN);\n}\n\nstatic int geni_spi_set_clock_and_bw(struct spi_geni_master *mas,\n\t\t\t\t\tunsigned long clk_hz)\n{\n\tu32 clk_sel, m_clk_cfg, idx, div;\n\tstruct geni_se *se = &mas->se;\n\tint ret;\n\n\tif (clk_hz == mas->cur_speed_hz)\n\t\treturn 0;\n\n\tret = get_spi_clk_cfg(clk_hz, mas, &idx, &div);\n\tif (ret) {\n\t\tdev_err(mas->dev, \"Err setting clk to %lu: %d\\n\", clk_hz, ret);\n\t\treturn ret;\n\t}\n\n\t \n\tmas->cur_speed_hz = clk_hz;\n\n\tclk_sel = idx & CLK_SEL_MSK;\n\tm_clk_cfg = (div << CLK_DIV_SHFT) | SER_CLK_EN;\n\twritel(clk_sel, se->base + SE_GENI_CLK_SEL);\n\twritel(m_clk_cfg, se->base + GENI_SER_M_CLK_CFG);\n\n\t \n\tse->icc_paths[CPU_TO_GENI].avg_bw = Bps_to_icc(mas->cur_speed_hz);\n\tret = geni_icc_set_bw(se);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int setup_fifo_params(struct spi_device *spi_slv,\n\t\t\t\t\tstruct spi_master *spi)\n{\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\tstruct geni_se *se = &mas->se;\n\tu32 loopback_cfg = 0, cpol = 0, cpha = 0, demux_output_inv = 0;\n\tu32 demux_sel;\n\n\tif (mas->last_mode != spi_slv->mode) {\n\t\tif (spi_slv->mode & SPI_LOOP)\n\t\t\tloopback_cfg = LOOPBACK_ENABLE;\n\n\t\tif (spi_slv->mode & SPI_CPOL)\n\t\t\tcpol = CPOL;\n\n\t\tif (spi_slv->mode & SPI_CPHA)\n\t\t\tcpha = CPHA;\n\n\t\tif (spi_slv->mode & SPI_CS_HIGH)\n\t\t\tdemux_output_inv = BIT(spi_get_chipselect(spi_slv, 0));\n\n\t\tdemux_sel = spi_get_chipselect(spi_slv, 0);\n\t\tmas->cur_bits_per_word = spi_slv->bits_per_word;\n\n\t\tspi_setup_word_len(mas, spi_slv->mode, spi_slv->bits_per_word);\n\t\twritel(loopback_cfg, se->base + SE_SPI_LOOPBACK);\n\t\twritel(demux_sel, se->base + SE_SPI_DEMUX_SEL);\n\t\twritel(cpha, se->base + SE_SPI_CPHA);\n\t\twritel(cpol, se->base + SE_SPI_CPOL);\n\t\twritel(demux_output_inv, se->base + SE_SPI_DEMUX_OUTPUT_INV);\n\n\t\tmas->last_mode = spi_slv->mode;\n\t}\n\n\treturn geni_spi_set_clock_and_bw(mas, spi_slv->max_speed_hz);\n}\n\nstatic void\nspi_gsi_callback_result(void *cb, const struct dmaengine_result *result)\n{\n\tstruct spi_master *spi = cb;\n\n\tspi->cur_msg->status = -EIO;\n\tif (result->result != DMA_TRANS_NOERROR) {\n\t\tdev_err(&spi->dev, \"DMA txn failed: %d\\n\", result->result);\n\t\tspi_finalize_current_transfer(spi);\n\t\treturn;\n\t}\n\n\tif (!result->residue) {\n\t\tspi->cur_msg->status = 0;\n\t\tdev_dbg(&spi->dev, \"DMA txn completed\\n\");\n\t} else {\n\t\tdev_err(&spi->dev, \"DMA xfer has pending: %d\\n\", result->residue);\n\t}\n\n\tspi_finalize_current_transfer(spi);\n}\n\nstatic int setup_gsi_xfer(struct spi_transfer *xfer, struct spi_geni_master *mas,\n\t\t\t  struct spi_device *spi_slv, struct spi_master *spi)\n{\n\tunsigned long flags = DMA_PREP_INTERRUPT | DMA_CTRL_ACK;\n\tstruct dma_slave_config config = {};\n\tstruct gpi_spi_config peripheral = {};\n\tstruct dma_async_tx_descriptor *tx_desc, *rx_desc;\n\tint ret;\n\n\tconfig.peripheral_config = &peripheral;\n\tconfig.peripheral_size = sizeof(peripheral);\n\tperipheral.set_config = true;\n\n\tif (xfer->bits_per_word != mas->cur_bits_per_word ||\n\t    xfer->speed_hz != mas->cur_speed_hz) {\n\t\tmas->cur_bits_per_word = xfer->bits_per_word;\n\t\tmas->cur_speed_hz = xfer->speed_hz;\n\t}\n\n\tif (xfer->tx_buf && xfer->rx_buf) {\n\t\tperipheral.cmd = SPI_DUPLEX;\n\t} else if (xfer->tx_buf) {\n\t\tperipheral.cmd = SPI_TX;\n\t\tperipheral.rx_len = 0;\n\t} else if (xfer->rx_buf) {\n\t\tperipheral.cmd = SPI_RX;\n\t\tif (!(mas->cur_bits_per_word % MIN_WORD_LEN)) {\n\t\t\tperipheral.rx_len = ((xfer->len << 3) / mas->cur_bits_per_word);\n\t\t} else {\n\t\t\tint bytes_per_word = (mas->cur_bits_per_word / BITS_PER_BYTE) + 1;\n\n\t\t\tperipheral.rx_len = (xfer->len / bytes_per_word);\n\t\t}\n\t}\n\n\tperipheral.loopback_en = !!(spi_slv->mode & SPI_LOOP);\n\tperipheral.clock_pol_high = !!(spi_slv->mode & SPI_CPOL);\n\tperipheral.data_pol_high = !!(spi_slv->mode & SPI_CPHA);\n\tperipheral.cs = spi_get_chipselect(spi_slv, 0);\n\tperipheral.pack_en = true;\n\tperipheral.word_len = xfer->bits_per_word - MIN_WORD_LEN;\n\n\tret = get_spi_clk_cfg(mas->cur_speed_hz, mas,\n\t\t\t      &peripheral.clk_src, &peripheral.clk_div);\n\tif (ret) {\n\t\tdev_err(mas->dev, \"Err in get_spi_clk_cfg() :%d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (!xfer->cs_change) {\n\t\tif (!list_is_last(&xfer->transfer_list, &spi->cur_msg->transfers))\n\t\t\tperipheral.fragmentation = FRAGMENTATION;\n\t}\n\n\tif (peripheral.cmd & SPI_RX) {\n\t\tdmaengine_slave_config(mas->rx, &config);\n\t\trx_desc = dmaengine_prep_slave_sg(mas->rx, xfer->rx_sg.sgl, xfer->rx_sg.nents,\n\t\t\t\t\t\t  DMA_DEV_TO_MEM, flags);\n\t\tif (!rx_desc) {\n\t\t\tdev_err(mas->dev, \"Err setting up rx desc\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\n\t \n\tdmaengine_slave_config(mas->tx, &config);\n\ttx_desc = dmaengine_prep_slave_sg(mas->tx, xfer->tx_sg.sgl, xfer->tx_sg.nents,\n\t\t\t\t\t  DMA_MEM_TO_DEV, flags);\n\tif (!tx_desc) {\n\t\tdev_err(mas->dev, \"Err setting up tx desc\\n\");\n\t\treturn -EIO;\n\t}\n\n\ttx_desc->callback_result = spi_gsi_callback_result;\n\ttx_desc->callback_param = spi;\n\n\tif (peripheral.cmd & SPI_RX)\n\t\tdmaengine_submit(rx_desc);\n\tdmaengine_submit(tx_desc);\n\n\tif (peripheral.cmd & SPI_RX)\n\t\tdma_async_issue_pending(mas->rx);\n\n\tdma_async_issue_pending(mas->tx);\n\treturn 1;\n}\n\nstatic u32 get_xfer_len_in_words(struct spi_transfer *xfer,\n\t\t\t\tstruct spi_geni_master *mas)\n{\n\tu32 len;\n\n\tif (!(mas->cur_bits_per_word % MIN_WORD_LEN))\n\t\tlen = xfer->len * BITS_PER_BYTE / mas->cur_bits_per_word;\n\telse\n\t\tlen = xfer->len / (mas->cur_bits_per_word / BITS_PER_BYTE + 1);\n\tlen &= TRANS_LEN_MSK;\n\n\treturn len;\n}\n\nstatic bool geni_can_dma(struct spi_controller *ctlr,\n\t\t\t struct spi_device *slv, struct spi_transfer *xfer)\n{\n\tstruct spi_geni_master *mas = spi_master_get_devdata(slv->master);\n\tu32 len, fifo_size;\n\n\tif (mas->cur_xfer_mode == GENI_GPI_DMA)\n\t\treturn true;\n\n\t \n\tif (ctlr->slave)\n\t\treturn true;\n\n\tlen = get_xfer_len_in_words(xfer, mas);\n\tfifo_size = mas->tx_fifo_depth * mas->fifo_width_bits / mas->cur_bits_per_word;\n\n\tif (len > fifo_size)\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\nstatic int spi_geni_prepare_message(struct spi_master *spi,\n\t\t\t\t\tstruct spi_message *spi_msg)\n{\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\tint ret;\n\n\tswitch (mas->cur_xfer_mode) {\n\tcase GENI_SE_FIFO:\n\tcase GENI_SE_DMA:\n\t\tif (spi_geni_is_abort_still_pending(mas))\n\t\t\treturn -EBUSY;\n\t\tret = setup_fifo_params(spi_msg->spi, spi);\n\t\tif (ret)\n\t\t\tdev_err(mas->dev, \"Couldn't select mode %d\\n\", ret);\n\t\treturn ret;\n\n\tcase GENI_GPI_DMA:\n\t\t \n\t\treturn 0;\n\t}\n\n\tdev_err(mas->dev, \"Mode not supported %d\", mas->cur_xfer_mode);\n\treturn -EINVAL;\n}\n\nstatic int spi_geni_grab_gpi_chan(struct spi_geni_master *mas)\n{\n\tint ret;\n\n\tmas->tx = dma_request_chan(mas->dev, \"tx\");\n\tif (IS_ERR(mas->tx)) {\n\t\tret = dev_err_probe(mas->dev, PTR_ERR(mas->tx),\n\t\t\t\t    \"Failed to get tx DMA ch\\n\");\n\t\tgoto err_tx;\n\t}\n\n\tmas->rx = dma_request_chan(mas->dev, \"rx\");\n\tif (IS_ERR(mas->rx)) {\n\t\tret = dev_err_probe(mas->dev, PTR_ERR(mas->rx),\n\t\t\t\t    \"Failed to get rx DMA ch\\n\");\n\t\tgoto err_rx;\n\t}\n\n\treturn 0;\n\nerr_rx:\n\tmas->rx = NULL;\n\tdma_release_channel(mas->tx);\nerr_tx:\n\tmas->tx = NULL;\n\treturn ret;\n}\n\nstatic void spi_geni_release_dma_chan(struct spi_geni_master *mas)\n{\n\tif (mas->rx) {\n\t\tdma_release_channel(mas->rx);\n\t\tmas->rx = NULL;\n\t}\n\n\tif (mas->tx) {\n\t\tdma_release_channel(mas->tx);\n\t\tmas->tx = NULL;\n\t}\n}\n\nstatic int spi_geni_init(struct spi_geni_master *mas)\n{\n\tstruct spi_master *spi = dev_get_drvdata(mas->dev);\n\tstruct geni_se *se = &mas->se;\n\tunsigned int proto, major, minor, ver;\n\tu32 spi_tx_cfg, fifo_disable;\n\tint ret = -ENXIO;\n\n\tpm_runtime_get_sync(mas->dev);\n\n\tproto = geni_se_read_proto(se);\n\n\tif (spi->slave) {\n\t\tif (proto != GENI_SE_SPI_SLAVE) {\n\t\t\tdev_err(mas->dev, \"Invalid proto %d\\n\", proto);\n\t\t\tgoto out_pm;\n\t\t}\n\t\tspi_slv_setup(mas);\n\t} else if (proto != GENI_SE_SPI) {\n\t\tdev_err(mas->dev, \"Invalid proto %d\\n\", proto);\n\t\tgoto out_pm;\n\t}\n\tmas->tx_fifo_depth = geni_se_get_tx_fifo_depth(se);\n\n\t \n\tmas->fifo_width_bits = geni_se_get_tx_fifo_width(se);\n\n\t \n\tgeni_se_init(se, mas->tx_fifo_depth - 3, mas->tx_fifo_depth - 2);\n\t \n\tmas->tx_wm = 1;\n\tver = geni_se_get_qup_hw_version(se);\n\tmajor = GENI_SE_VERSION_MAJOR(ver);\n\tminor = GENI_SE_VERSION_MINOR(ver);\n\n\tif (major == 1 && minor == 0)\n\t\tmas->oversampling = 2;\n\telse\n\t\tmas->oversampling = 1;\n\n\tfifo_disable = readl(se->base + GENI_IF_DISABLE_RO) & FIFO_IF_DISABLE;\n\tswitch (fifo_disable) {\n\tcase 1:\n\t\tret = spi_geni_grab_gpi_chan(mas);\n\t\tif (!ret) {  \n\t\t\tmas->cur_xfer_mode = GENI_GPI_DMA;\n\t\t\tgeni_se_select_mode(se, GENI_GPI_DMA);\n\t\t\tdev_dbg(mas->dev, \"Using GPI DMA mode for SPI\\n\");\n\t\t\tbreak;\n\t\t} else if (ret == -EPROBE_DEFER) {\n\t\t\tgoto out_pm;\n\t\t}\n\t\t \n\t\tdev_warn(mas->dev, \"FIFO mode disabled, but couldn't get DMA, fall back to FIFO mode\\n\");\n\t\tfallthrough;\n\n\tcase 0:\n\t\tmas->cur_xfer_mode = GENI_SE_FIFO;\n\t\tgeni_se_select_mode(se, GENI_SE_FIFO);\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n\t \n\tif (!spi->slave) {\n\t\tspi_tx_cfg = readl(se->base + SE_SPI_TRANS_CFG);\n\t\tspi_tx_cfg &= ~CS_TOGGLE;\n\t\twritel(spi_tx_cfg, se->base + SE_SPI_TRANS_CFG);\n\t}\n\nout_pm:\n\tpm_runtime_put(mas->dev);\n\treturn ret;\n}\n\nstatic unsigned int geni_byte_per_fifo_word(struct spi_geni_master *mas)\n{\n\t \n\tif (mas->fifo_width_bits % mas->cur_bits_per_word)\n\t\treturn roundup_pow_of_two(DIV_ROUND_UP(mas->cur_bits_per_word,\n\t\t\t\t\t\t       BITS_PER_BYTE));\n\n\treturn mas->fifo_width_bits / BITS_PER_BYTE;\n}\n\nstatic bool geni_spi_handle_tx(struct spi_geni_master *mas)\n{\n\tstruct geni_se *se = &mas->se;\n\tunsigned int max_bytes;\n\tconst u8 *tx_buf;\n\tunsigned int bytes_per_fifo_word = geni_byte_per_fifo_word(mas);\n\tunsigned int i = 0;\n\n\t \n\tif (!mas->cur_xfer) {\n\t\twritel(0, se->base + SE_GENI_TX_WATERMARK_REG);\n\t\treturn false;\n\t}\n\n\tmax_bytes = (mas->tx_fifo_depth - mas->tx_wm) * bytes_per_fifo_word;\n\tif (mas->tx_rem_bytes < max_bytes)\n\t\tmax_bytes = mas->tx_rem_bytes;\n\n\ttx_buf = mas->cur_xfer->tx_buf + mas->cur_xfer->len - mas->tx_rem_bytes;\n\twhile (i < max_bytes) {\n\t\tunsigned int j;\n\t\tunsigned int bytes_to_write;\n\t\tu32 fifo_word = 0;\n\t\tu8 *fifo_byte = (u8 *)&fifo_word;\n\n\t\tbytes_to_write = min(bytes_per_fifo_word, max_bytes - i);\n\t\tfor (j = 0; j < bytes_to_write; j++)\n\t\t\tfifo_byte[j] = tx_buf[i++];\n\t\tiowrite32_rep(se->base + SE_GENI_TX_FIFOn, &fifo_word, 1);\n\t}\n\tmas->tx_rem_bytes -= max_bytes;\n\tif (!mas->tx_rem_bytes) {\n\t\twritel(0, se->base + SE_GENI_TX_WATERMARK_REG);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic void geni_spi_handle_rx(struct spi_geni_master *mas)\n{\n\tstruct geni_se *se = &mas->se;\n\tu32 rx_fifo_status;\n\tunsigned int rx_bytes;\n\tunsigned int rx_last_byte_valid;\n\tu8 *rx_buf;\n\tunsigned int bytes_per_fifo_word = geni_byte_per_fifo_word(mas);\n\tunsigned int i = 0;\n\n\trx_fifo_status = readl(se->base + SE_GENI_RX_FIFO_STATUS);\n\trx_bytes = (rx_fifo_status & RX_FIFO_WC_MSK) * bytes_per_fifo_word;\n\tif (rx_fifo_status & RX_LAST) {\n\t\trx_last_byte_valid = rx_fifo_status & RX_LAST_BYTE_VALID_MSK;\n\t\trx_last_byte_valid >>= RX_LAST_BYTE_VALID_SHFT;\n\t\tif (rx_last_byte_valid && rx_last_byte_valid < 4)\n\t\t\trx_bytes -= bytes_per_fifo_word - rx_last_byte_valid;\n\t}\n\n\t \n\tif (!mas->cur_xfer) {\n\t\tfor (i = 0; i < DIV_ROUND_UP(rx_bytes, bytes_per_fifo_word); i++)\n\t\t\treadl(se->base + SE_GENI_RX_FIFOn);\n\t\treturn;\n\t}\n\n\tif (mas->rx_rem_bytes < rx_bytes)\n\t\trx_bytes = mas->rx_rem_bytes;\n\n\trx_buf = mas->cur_xfer->rx_buf + mas->cur_xfer->len - mas->rx_rem_bytes;\n\twhile (i < rx_bytes) {\n\t\tu32 fifo_word = 0;\n\t\tu8 *fifo_byte = (u8 *)&fifo_word;\n\t\tunsigned int bytes_to_read;\n\t\tunsigned int j;\n\n\t\tbytes_to_read = min(bytes_per_fifo_word, rx_bytes - i);\n\t\tioread32_rep(se->base + SE_GENI_RX_FIFOn, &fifo_word, 1);\n\t\tfor (j = 0; j < bytes_to_read; j++)\n\t\t\trx_buf[i++] = fifo_byte[j];\n\t}\n\tmas->rx_rem_bytes -= rx_bytes;\n}\n\nstatic int setup_se_xfer(struct spi_transfer *xfer,\n\t\t\t\tstruct spi_geni_master *mas,\n\t\t\t\tu16 mode, struct spi_master *spi)\n{\n\tu32 m_cmd = 0;\n\tu32 len;\n\tstruct geni_se *se = &mas->se;\n\tint ret;\n\n\t \n\tspin_lock_irq(&mas->lock);\n\tspin_unlock_irq(&mas->lock);\n\n\tif (xfer->bits_per_word != mas->cur_bits_per_word) {\n\t\tspi_setup_word_len(mas, mode, xfer->bits_per_word);\n\t\tmas->cur_bits_per_word = xfer->bits_per_word;\n\t}\n\n\t \n\tret = geni_spi_set_clock_and_bw(mas, xfer->speed_hz);\n\tif (ret)\n\t\treturn ret;\n\n\tmas->tx_rem_bytes = 0;\n\tmas->rx_rem_bytes = 0;\n\n\tlen = get_xfer_len_in_words(xfer, mas);\n\n\tmas->cur_xfer = xfer;\n\tif (xfer->tx_buf) {\n\t\tm_cmd |= SPI_TX_ONLY;\n\t\tmas->tx_rem_bytes = xfer->len;\n\t\twritel(len, se->base + SE_SPI_TX_TRANS_LEN);\n\t}\n\n\tif (xfer->rx_buf) {\n\t\tm_cmd |= SPI_RX_ONLY;\n\t\twritel(len, se->base + SE_SPI_RX_TRANS_LEN);\n\t\tmas->rx_rem_bytes = xfer->len;\n\t}\n\n\t \n\tif (!xfer->tx_sg.nents && !xfer->rx_sg.nents)\n\t\tmas->cur_xfer_mode = GENI_SE_FIFO;\n\telse if (xfer->tx_sg.nents > 1 || xfer->rx_sg.nents > 1) {\n\t\tdev_warn_once(mas->dev, \"Doing FIFO, cannot handle tx_nents-%d, rx_nents-%d\\n\",\n\t\t\txfer->tx_sg.nents, xfer->rx_sg.nents);\n\t\tmas->cur_xfer_mode = GENI_SE_FIFO;\n\t} else\n\t\tmas->cur_xfer_mode = GENI_SE_DMA;\n\tgeni_se_select_mode(se, mas->cur_xfer_mode);\n\n\t \n\tspin_lock_irq(&mas->lock);\n\tgeni_se_setup_m_cmd(se, m_cmd, FRAGMENTATION);\n\n\tif (mas->cur_xfer_mode == GENI_SE_DMA) {\n\t\tif (m_cmd & SPI_RX_ONLY)\n\t\t\tgeni_se_rx_init_dma(se, sg_dma_address(xfer->rx_sg.sgl),\n\t\t\t\tsg_dma_len(xfer->rx_sg.sgl));\n\t\tif (m_cmd & SPI_TX_ONLY)\n\t\t\tgeni_se_tx_init_dma(se, sg_dma_address(xfer->tx_sg.sgl),\n\t\t\t\tsg_dma_len(xfer->tx_sg.sgl));\n\t} else if (m_cmd & SPI_TX_ONLY) {\n\t\tif (geni_spi_handle_tx(mas))\n\t\t\twritel(mas->tx_wm, se->base + SE_GENI_TX_WATERMARK_REG);\n\t}\n\n\tspin_unlock_irq(&mas->lock);\n\treturn ret;\n}\n\nstatic int spi_geni_transfer_one(struct spi_master *spi,\n\t\t\t\tstruct spi_device *slv,\n\t\t\t\tstruct spi_transfer *xfer)\n{\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\tint ret;\n\n\tif (spi_geni_is_abort_still_pending(mas))\n\t\treturn -EBUSY;\n\n\t \n\tif (!xfer->len)\n\t\treturn 0;\n\n\tif (mas->cur_xfer_mode == GENI_SE_FIFO || mas->cur_xfer_mode == GENI_SE_DMA) {\n\t\tret = setup_se_xfer(xfer, mas, slv->mode, spi);\n\t\t \n\t\tif (!ret)\n\t\t\tret = 1;\n\t\treturn ret;\n\t}\n\treturn setup_gsi_xfer(xfer, mas, slv, spi);\n}\n\nstatic irqreturn_t geni_spi_isr(int irq, void *data)\n{\n\tstruct spi_master *spi = data;\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\tstruct geni_se *se = &mas->se;\n\tu32 m_irq;\n\n\tm_irq = readl(se->base + SE_GENI_M_IRQ_STATUS);\n\tif (!m_irq)\n\t\treturn IRQ_NONE;\n\n\tif (m_irq & (M_CMD_OVERRUN_EN | M_ILLEGAL_CMD_EN | M_CMD_FAILURE_EN |\n\t\t     M_RX_FIFO_RD_ERR_EN | M_RX_FIFO_WR_ERR_EN |\n\t\t     M_TX_FIFO_RD_ERR_EN | M_TX_FIFO_WR_ERR_EN))\n\t\tdev_warn(mas->dev, \"Unexpected IRQ err status %#010x\\n\", m_irq);\n\n\tspin_lock(&mas->lock);\n\n\tif (mas->cur_xfer_mode == GENI_SE_FIFO) {\n\t\tif ((m_irq & M_RX_FIFO_WATERMARK_EN) || (m_irq & M_RX_FIFO_LAST_EN))\n\t\t\tgeni_spi_handle_rx(mas);\n\n\t\tif (m_irq & M_TX_FIFO_WATERMARK_EN)\n\t\t\tgeni_spi_handle_tx(mas);\n\n\t\tif (m_irq & M_CMD_DONE_EN) {\n\t\t\tif (mas->cur_xfer) {\n\t\t\t\tspi_finalize_current_transfer(spi);\n\t\t\t\tmas->cur_xfer = NULL;\n\t\t\t\t \n\t\t\t\tif (mas->tx_rem_bytes) {\n\t\t\t\t\twritel(0, se->base + SE_GENI_TX_WATERMARK_REG);\n\t\t\t\t\tdev_err(mas->dev, \"Premature done. tx_rem = %d bpw%d\\n\",\n\t\t\t\t\t\tmas->tx_rem_bytes, mas->cur_bits_per_word);\n\t\t\t\t}\n\t\t\t\tif (mas->rx_rem_bytes)\n\t\t\t\t\tdev_err(mas->dev, \"Premature done. rx_rem = %d bpw%d\\n\",\n\t\t\t\t\t\tmas->rx_rem_bytes, mas->cur_bits_per_word);\n\t\t\t} else {\n\t\t\t\tcomplete(&mas->cs_done);\n\t\t\t}\n\t\t}\n\t} else if (mas->cur_xfer_mode == GENI_SE_DMA) {\n\t\tconst struct spi_transfer *xfer = mas->cur_xfer;\n\t\tu32 dma_tx_status = readl_relaxed(se->base + SE_DMA_TX_IRQ_STAT);\n\t\tu32 dma_rx_status = readl_relaxed(se->base + SE_DMA_RX_IRQ_STAT);\n\n\t\tif (dma_tx_status)\n\t\t\twritel(dma_tx_status, se->base + SE_DMA_TX_IRQ_CLR);\n\t\tif (dma_rx_status)\n\t\t\twritel(dma_rx_status, se->base + SE_DMA_RX_IRQ_CLR);\n\t\tif (dma_tx_status & TX_DMA_DONE)\n\t\t\tmas->tx_rem_bytes = 0;\n\t\tif (dma_rx_status & RX_DMA_DONE)\n\t\t\tmas->rx_rem_bytes = 0;\n\t\tif (dma_tx_status & TX_RESET_DONE)\n\t\t\tcomplete(&mas->tx_reset_done);\n\t\tif (dma_rx_status & RX_RESET_DONE)\n\t\t\tcomplete(&mas->rx_reset_done);\n\t\tif (!mas->tx_rem_bytes && !mas->rx_rem_bytes && xfer) {\n\t\t\tspi_finalize_current_transfer(spi);\n\t\t\tmas->cur_xfer = NULL;\n\t\t}\n\t}\n\n\tif (m_irq & M_CMD_CANCEL_EN)\n\t\tcomplete(&mas->cancel_done);\n\tif (m_irq & M_CMD_ABORT_EN)\n\t\tcomplete(&mas->abort_done);\n\n\t \n\twritel(m_irq, se->base + SE_GENI_M_IRQ_CLEAR);\n\n\tspin_unlock(&mas->lock);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int spi_geni_probe(struct platform_device *pdev)\n{\n\tint ret, irq;\n\tstruct spi_master *spi;\n\tstruct spi_geni_master *mas;\n\tvoid __iomem *base;\n\tstruct clk *clk;\n\tstruct device *dev = &pdev->dev;\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));\n\tif (ret)\n\t\treturn dev_err_probe(dev, ret, \"could not set DMA mask\\n\");\n\n\tbase = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(base))\n\t\treturn PTR_ERR(base);\n\n\tclk = devm_clk_get(dev, \"se\");\n\tif (IS_ERR(clk))\n\t\treturn PTR_ERR(clk);\n\n\tspi = devm_spi_alloc_master(dev, sizeof(*mas));\n\tif (!spi)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, spi);\n\tmas = spi_master_get_devdata(spi);\n\tmas->irq = irq;\n\tmas->dev = dev;\n\tmas->se.dev = dev;\n\tmas->se.wrapper = dev_get_drvdata(dev->parent);\n\tmas->se.base = base;\n\tmas->se.clk = clk;\n\n\tret = devm_pm_opp_set_clkname(&pdev->dev, \"se\");\n\tif (ret)\n\t\treturn ret;\n\t \n\tret = devm_pm_opp_of_add_table(&pdev->dev);\n\tif (ret && ret != -ENODEV) {\n\t\tdev_err(&pdev->dev, \"invalid OPP table in device tree\\n\");\n\t\treturn ret;\n\t}\n\n\tspi->bus_num = -1;\n\tspi->dev.of_node = dev->of_node;\n\tspi->mode_bits = SPI_CPOL | SPI_CPHA | SPI_LOOP | SPI_CS_HIGH;\n\tspi->bits_per_word_mask = SPI_BPW_RANGE_MASK(4, 32);\n\tspi->num_chipselect = 4;\n\tspi->max_speed_hz = 50000000;\n\tspi->max_dma_len = 0xffff0;  \n\tspi->prepare_message = spi_geni_prepare_message;\n\tspi->transfer_one = spi_geni_transfer_one;\n\tspi->can_dma = geni_can_dma;\n\tspi->dma_map_dev = dev->parent;\n\tspi->auto_runtime_pm = true;\n\tspi->handle_err = spi_geni_handle_err;\n\tspi->use_gpio_descriptors = true;\n\n\tinit_completion(&mas->cs_done);\n\tinit_completion(&mas->cancel_done);\n\tinit_completion(&mas->abort_done);\n\tinit_completion(&mas->tx_reset_done);\n\tinit_completion(&mas->rx_reset_done);\n\tspin_lock_init(&mas->lock);\n\tpm_runtime_use_autosuspend(&pdev->dev);\n\tpm_runtime_set_autosuspend_delay(&pdev->dev, 250);\n\tpm_runtime_enable(dev);\n\n\tif (device_property_read_bool(&pdev->dev, \"spi-slave\"))\n\t\tspi->slave = true;\n\n\tret = geni_icc_get(&mas->se, NULL);\n\tif (ret)\n\t\tgoto spi_geni_probe_runtime_disable;\n\t \n\tmas->se.icc_paths[GENI_TO_CORE].avg_bw = Bps_to_icc(CORE_2X_50_MHZ);\n\tmas->se.icc_paths[CPU_TO_GENI].avg_bw = GENI_DEFAULT_BW;\n\n\tret = geni_icc_set_bw(&mas->se);\n\tif (ret)\n\t\tgoto spi_geni_probe_runtime_disable;\n\n\tret = spi_geni_init(mas);\n\tif (ret)\n\t\tgoto spi_geni_probe_runtime_disable;\n\n\t \n\tif (!spi->slave && mas->cur_xfer_mode == GENI_SE_FIFO)\n\t\tspi->set_cs = spi_geni_set_cs;\n\n\t \n\tif (mas->cur_xfer_mode == GENI_GPI_DMA)\n\t\tspi->flags = SPI_CONTROLLER_MUST_TX;\n\n\tret = request_irq(mas->irq, geni_spi_isr, 0, dev_name(dev), spi);\n\tif (ret)\n\t\tgoto spi_geni_release_dma;\n\n\tret = spi_register_master(spi);\n\tif (ret)\n\t\tgoto spi_geni_probe_free_irq;\n\n\treturn 0;\nspi_geni_probe_free_irq:\n\tfree_irq(mas->irq, spi);\nspi_geni_release_dma:\n\tspi_geni_release_dma_chan(mas);\nspi_geni_probe_runtime_disable:\n\tpm_runtime_disable(dev);\n\treturn ret;\n}\n\nstatic void spi_geni_remove(struct platform_device *pdev)\n{\n\tstruct spi_master *spi = platform_get_drvdata(pdev);\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\n\t \n\tspi_unregister_master(spi);\n\n\tspi_geni_release_dma_chan(mas);\n\n\tfree_irq(mas->irq, spi);\n\tpm_runtime_disable(&pdev->dev);\n}\n\nstatic int __maybe_unused spi_geni_runtime_suspend(struct device *dev)\n{\n\tstruct spi_master *spi = dev_get_drvdata(dev);\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\tint ret;\n\n\t \n\tdev_pm_opp_set_rate(dev, 0);\n\n\tret = geni_se_resources_off(&mas->se);\n\tif (ret)\n\t\treturn ret;\n\n\treturn geni_icc_disable(&mas->se);\n}\n\nstatic int __maybe_unused spi_geni_runtime_resume(struct device *dev)\n{\n\tstruct spi_master *spi = dev_get_drvdata(dev);\n\tstruct spi_geni_master *mas = spi_master_get_devdata(spi);\n\tint ret;\n\n\tret = geni_icc_enable(&mas->se);\n\tif (ret)\n\t\treturn ret;\n\n\tret = geni_se_resources_on(&mas->se);\n\tif (ret)\n\t\treturn ret;\n\n\treturn dev_pm_opp_set_rate(mas->dev, mas->cur_sclk_hz);\n}\n\nstatic int __maybe_unused spi_geni_suspend(struct device *dev)\n{\n\tstruct spi_master *spi = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = spi_master_suspend(spi);\n\tif (ret)\n\t\treturn ret;\n\n\tret = pm_runtime_force_suspend(dev);\n\tif (ret)\n\t\tspi_master_resume(spi);\n\n\treturn ret;\n}\n\nstatic int __maybe_unused spi_geni_resume(struct device *dev)\n{\n\tstruct spi_master *spi = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = pm_runtime_force_resume(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = spi_master_resume(spi);\n\tif (ret)\n\t\tpm_runtime_force_suspend(dev);\n\n\treturn ret;\n}\n\nstatic const struct dev_pm_ops spi_geni_pm_ops = {\n\tSET_RUNTIME_PM_OPS(spi_geni_runtime_suspend,\n\t\t\t\t\tspi_geni_runtime_resume, NULL)\n\tSET_SYSTEM_SLEEP_PM_OPS(spi_geni_suspend, spi_geni_resume)\n};\n\nstatic const struct of_device_id spi_geni_dt_match[] = {\n\t{ .compatible = \"qcom,geni-spi\" },\n\t{}\n};\nMODULE_DEVICE_TABLE(of, spi_geni_dt_match);\n\nstatic struct platform_driver spi_geni_driver = {\n\t.probe  = spi_geni_probe,\n\t.remove_new = spi_geni_remove,\n\t.driver = {\n\t\t.name = \"geni_spi\",\n\t\t.pm = &spi_geni_pm_ops,\n\t\t.of_match_table = spi_geni_dt_match,\n\t},\n};\nmodule_platform_driver(spi_geni_driver);\n\nMODULE_DESCRIPTION(\"SPI driver for GENI based QUP cores\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}