{
  "module_name": "spi-mtk-snfi.c",
  "hash_id": "2ffb67d218181203a1b4b7edfe86953ecf638f89b115dfe96407ba4d9cf2ba51",
  "original_prompt": "Ingested from linux-6.6.14/drivers/spi/spi-mtk-snfi.c",
  "human_readable_source": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/device.h>\n#include <linux/mutex.h>\n#include <linux/clk.h>\n#include <linux/interrupt.h>\n#include <linux/dma-mapping.h>\n#include <linux/iopoll.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/mtd/nand-ecc-mtk.h>\n#include <linux/spi/spi.h>\n#include <linux/spi/spi-mem.h>\n#include <linux/mtd/nand.h>\n\n\n#define NFI_CNFG 0x000\n#define CNFG_OP_MODE_S 12\n#define CNFG_OP_MODE_CUST 6\n#define CNFG_OP_MODE_PROGRAM 3\n#define CNFG_AUTO_FMT_EN BIT(9)\n#define CNFG_HW_ECC_EN BIT(8)\n#define CNFG_DMA_BURST_EN BIT(2)\n#define CNFG_READ_MODE BIT(1)\n#define CNFG_DMA_MODE BIT(0)\n\n#define NFI_PAGEFMT 0x0004\n#define NFI_SPARE_SIZE_LS_S 16\n#define NFI_FDM_ECC_NUM_S 12\n#define NFI_FDM_NUM_S 8\n#define NFI_SPARE_SIZE_S 4\n#define NFI_SEC_SEL_512 BIT(2)\n#define NFI_PAGE_SIZE_S 0\n#define NFI_PAGE_SIZE_512_2K 0\n#define NFI_PAGE_SIZE_2K_4K 1\n#define NFI_PAGE_SIZE_4K_8K 2\n#define NFI_PAGE_SIZE_8K_16K 3\n\n#define NFI_CON 0x008\n#define CON_SEC_NUM_S 12\n#define CON_BWR BIT(9)\n#define CON_BRD BIT(8)\n#define CON_NFI_RST BIT(1)\n#define CON_FIFO_FLUSH BIT(0)\n\n#define NFI_INTR_EN 0x010\n#define NFI_INTR_STA 0x014\n#define NFI_IRQ_INTR_EN BIT(31)\n#define NFI_IRQ_CUS_READ BIT(8)\n#define NFI_IRQ_CUS_PG BIT(7)\n\n#define NFI_CMD 0x020\n#define NFI_CMD_DUMMY_READ 0x00\n#define NFI_CMD_DUMMY_WRITE 0x80\n\n#define NFI_STRDATA 0x040\n#define STR_DATA BIT(0)\n\n#define NFI_STA 0x060\n#define NFI_NAND_FSM_7622 GENMASK(28, 24)\n#define NFI_NAND_FSM_7986 GENMASK(29, 23)\n#define NFI_FSM GENMASK(19, 16)\n#define READ_EMPTY BIT(12)\n\n#define NFI_FIFOSTA 0x064\n#define FIFO_WR_REMAIN_S 8\n#define FIFO_RD_REMAIN_S 0\n\n#define NFI_ADDRCNTR 0x070\n#define SEC_CNTR GENMASK(16, 12)\n#define SEC_CNTR_S 12\n#define NFI_SEC_CNTR(val) (((val)&SEC_CNTR) >> SEC_CNTR_S)\n\n#define NFI_STRADDR 0x080\n\n#define NFI_BYTELEN 0x084\n#define BUS_SEC_CNTR(val) (((val)&SEC_CNTR) >> SEC_CNTR_S)\n\n#define NFI_FDM0L 0x0a0\n#define NFI_FDM0M 0x0a4\n#define NFI_FDML(n) (NFI_FDM0L + (n)*8)\n#define NFI_FDMM(n) (NFI_FDM0M + (n)*8)\n\n#define NFI_DEBUG_CON1 0x220\n#define WBUF_EN BIT(2)\n\n#define NFI_MASTERSTA 0x224\n#define MAS_ADDR GENMASK(11, 9)\n#define MAS_RD GENMASK(8, 6)\n#define MAS_WR GENMASK(5, 3)\n#define MAS_RDDLY GENMASK(2, 0)\n#define NFI_MASTERSTA_MASK_7622 (MAS_ADDR | MAS_RD | MAS_WR | MAS_RDDLY)\n#define NFI_MASTERSTA_MASK_7986 3\n\n\n#define SNF_MAC_CTL 0x500\n#define MAC_XIO_SEL BIT(4)\n#define SF_MAC_EN BIT(3)\n#define SF_TRIG BIT(2)\n#define WIP_READY BIT(1)\n#define WIP BIT(0)\n\n#define SNF_MAC_OUTL 0x504\n#define SNF_MAC_INL 0x508\n\n#define SNF_RD_CTL2 0x510\n#define DATA_READ_DUMMY_S 8\n#define DATA_READ_MAX_DUMMY 0xf\n#define DATA_READ_CMD_S 0\n\n#define SNF_RD_CTL3 0x514\n\n#define SNF_PG_CTL1 0x524\n#define PG_LOAD_CMD_S 8\n\n#define SNF_PG_CTL2 0x528\n\n#define SNF_MISC_CTL 0x538\n#define SW_RST BIT(28)\n#define FIFO_RD_LTC_S 25\n#define PG_LOAD_X4_EN BIT(20)\n#define DATA_READ_MODE_S 16\n#define DATA_READ_MODE GENMASK(18, 16)\n#define DATA_READ_MODE_X1 0\n#define DATA_READ_MODE_X2 1\n#define DATA_READ_MODE_X4 2\n#define DATA_READ_MODE_DUAL 5\n#define DATA_READ_MODE_QUAD 6\n#define DATA_READ_LATCH_LAT GENMASK(9, 8)\n#define DATA_READ_LATCH_LAT_S 8\n#define PG_LOAD_CUSTOM_EN BIT(7)\n#define DATARD_CUSTOM_EN BIT(6)\n#define CS_DESELECT_CYC_S 0\n\n#define SNF_MISC_CTL2 0x53c\n#define PROGRAM_LOAD_BYTE_NUM_S 16\n#define READ_DATA_BYTE_NUM_S 11\n\n#define SNF_DLY_CTL3 0x548\n#define SFCK_SAM_DLY_S 0\n#define SFCK_SAM_DLY GENMASK(5, 0)\n#define SFCK_SAM_DLY_TOTAL 9\n#define SFCK_SAM_DLY_RANGE 47\n\n#define SNF_STA_CTL1 0x550\n#define CUS_PG_DONE BIT(28)\n#define CUS_READ_DONE BIT(27)\n#define SPI_STATE_S 0\n#define SPI_STATE GENMASK(3, 0)\n\n#define SNF_CFG 0x55c\n#define SPI_MODE BIT(0)\n\n#define SNF_GPRAM 0x800\n#define SNF_GPRAM_SIZE 0xa0\n\n#define SNFI_POLL_INTERVAL 1000000\n\nstatic const u8 mt7622_spare_sizes[] = { 16, 26, 27, 28 };\n\nstatic const u8 mt7986_spare_sizes[] = {\n\t16, 26, 27, 28, 32, 36, 40, 44, 48, 49, 50, 51, 52, 62, 61, 63, 64, 67,\n\t74\n};\n\nstruct mtk_snand_caps {\n\tu16 sector_size;\n\tu16 max_sectors;\n\tu16 fdm_size;\n\tu16 fdm_ecc_size;\n\tu16 fifo_size;\n\n\tbool bbm_swap;\n\tbool empty_page_check;\n\tu32 mastersta_mask;\n\tu32 nandfsm_mask;\n\n\tconst u8 *spare_sizes;\n\tu32 num_spare_size;\n};\n\nstatic const struct mtk_snand_caps mt7622_snand_caps = {\n\t.sector_size = 512,\n\t.max_sectors = 8,\n\t.fdm_size = 8,\n\t.fdm_ecc_size = 1,\n\t.fifo_size = 32,\n\t.bbm_swap = false,\n\t.empty_page_check = false,\n\t.mastersta_mask = NFI_MASTERSTA_MASK_7622,\n\t.nandfsm_mask = NFI_NAND_FSM_7622,\n\t.spare_sizes = mt7622_spare_sizes,\n\t.num_spare_size = ARRAY_SIZE(mt7622_spare_sizes)\n};\n\nstatic const struct mtk_snand_caps mt7629_snand_caps = {\n\t.sector_size = 512,\n\t.max_sectors = 8,\n\t.fdm_size = 8,\n\t.fdm_ecc_size = 1,\n\t.fifo_size = 32,\n\t.bbm_swap = true,\n\t.empty_page_check = false,\n\t.mastersta_mask = NFI_MASTERSTA_MASK_7622,\n\t.nandfsm_mask = NFI_NAND_FSM_7622,\n\t.spare_sizes = mt7622_spare_sizes,\n\t.num_spare_size = ARRAY_SIZE(mt7622_spare_sizes)\n};\n\nstatic const struct mtk_snand_caps mt7986_snand_caps = {\n\t.sector_size = 1024,\n\t.max_sectors = 8,\n\t.fdm_size = 8,\n\t.fdm_ecc_size = 1,\n\t.fifo_size = 64,\n\t.bbm_swap = true,\n\t.empty_page_check = true,\n\t.mastersta_mask = NFI_MASTERSTA_MASK_7986,\n\t.nandfsm_mask = NFI_NAND_FSM_7986,\n\t.spare_sizes = mt7986_spare_sizes,\n\t.num_spare_size = ARRAY_SIZE(mt7986_spare_sizes)\n};\n\nstruct mtk_snand_conf {\n\tsize_t page_size;\n\tsize_t oob_size;\n\tu8 nsectors;\n\tu8 spare_size;\n};\n\nstruct mtk_snand {\n\tstruct spi_controller *ctlr;\n\tstruct device *dev;\n\tstruct clk *nfi_clk;\n\tstruct clk *pad_clk;\n\tstruct clk *nfi_hclk;\n\tvoid __iomem *nfi_base;\n\tint irq;\n\tstruct completion op_done;\n\tconst struct mtk_snand_caps *caps;\n\tstruct mtk_ecc_config *ecc_cfg;\n\tstruct mtk_ecc *ecc;\n\tstruct mtk_snand_conf nfi_cfg;\n\tstruct mtk_ecc_stats ecc_stats;\n\tstruct nand_ecc_engine ecc_eng;\n\tbool autofmt;\n\tu8 *buf;\n\tsize_t buf_len;\n};\n\nstatic struct mtk_snand *nand_to_mtk_snand(struct nand_device *nand)\n{\n\tstruct nand_ecc_engine *eng = nand->ecc.engine;\n\n\treturn container_of(eng, struct mtk_snand, ecc_eng);\n}\n\nstatic inline int snand_prepare_bouncebuf(struct mtk_snand *snf, size_t size)\n{\n\tif (snf->buf_len >= size)\n\t\treturn 0;\n\tkfree(snf->buf);\n\tsnf->buf = kmalloc(size, GFP_KERNEL);\n\tif (!snf->buf)\n\t\treturn -ENOMEM;\n\tsnf->buf_len = size;\n\tmemset(snf->buf, 0xff, snf->buf_len);\n\treturn 0;\n}\n\nstatic inline u32 nfi_read32(struct mtk_snand *snf, u32 reg)\n{\n\treturn readl(snf->nfi_base + reg);\n}\n\nstatic inline void nfi_write32(struct mtk_snand *snf, u32 reg, u32 val)\n{\n\twritel(val, snf->nfi_base + reg);\n}\n\nstatic inline void nfi_write16(struct mtk_snand *snf, u32 reg, u16 val)\n{\n\twritew(val, snf->nfi_base + reg);\n}\n\nstatic inline void nfi_rmw32(struct mtk_snand *snf, u32 reg, u32 clr, u32 set)\n{\n\tu32 val;\n\n\tval = readl(snf->nfi_base + reg);\n\tval &= ~clr;\n\tval |= set;\n\twritel(val, snf->nfi_base + reg);\n}\n\nstatic void nfi_read_data(struct mtk_snand *snf, u32 reg, u8 *data, u32 len)\n{\n\tu32 i, val = 0, es = sizeof(u32);\n\n\tfor (i = reg; i < reg + len; i++) {\n\t\tif (i == reg || i % es == 0)\n\t\t\tval = nfi_read32(snf, i & ~(es - 1));\n\n\t\t*data++ = (u8)(val >> (8 * (i % es)));\n\t}\n}\n\nstatic int mtk_nfi_reset(struct mtk_snand *snf)\n{\n\tu32 val, fifo_mask;\n\tint ret;\n\n\tnfi_write32(snf, NFI_CON, CON_FIFO_FLUSH | CON_NFI_RST);\n\n\tret = readw_poll_timeout(snf->nfi_base + NFI_MASTERSTA, val,\n\t\t\t\t !(val & snf->caps->mastersta_mask), 0,\n\t\t\t\t SNFI_POLL_INTERVAL);\n\tif (ret) {\n\t\tdev_err(snf->dev, \"NFI master is still busy after reset\\n\");\n\t\treturn ret;\n\t}\n\n\tret = readl_poll_timeout(snf->nfi_base + NFI_STA, val,\n\t\t\t\t !(val & (NFI_FSM | snf->caps->nandfsm_mask)), 0,\n\t\t\t\t SNFI_POLL_INTERVAL);\n\tif (ret) {\n\t\tdev_err(snf->dev, \"Failed to reset NFI\\n\");\n\t\treturn ret;\n\t}\n\n\tfifo_mask = ((snf->caps->fifo_size - 1) << FIFO_RD_REMAIN_S) |\n\t\t    ((snf->caps->fifo_size - 1) << FIFO_WR_REMAIN_S);\n\tret = readw_poll_timeout(snf->nfi_base + NFI_FIFOSTA, val,\n\t\t\t\t !(val & fifo_mask), 0, SNFI_POLL_INTERVAL);\n\tif (ret) {\n\t\tdev_err(snf->dev, \"NFI FIFOs are not empty\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int mtk_snand_mac_reset(struct mtk_snand *snf)\n{\n\tint ret;\n\tu32 val;\n\n\tnfi_rmw32(snf, SNF_MISC_CTL, 0, SW_RST);\n\n\tret = readl_poll_timeout(snf->nfi_base + SNF_STA_CTL1, val,\n\t\t\t\t !(val & SPI_STATE), 0, SNFI_POLL_INTERVAL);\n\tif (ret)\n\t\tdev_err(snf->dev, \"Failed to reset SNFI MAC\\n\");\n\n\tnfi_write32(snf, SNF_MISC_CTL,\n\t\t    (2 << FIFO_RD_LTC_S) | (10 << CS_DESELECT_CYC_S));\n\n\treturn ret;\n}\n\nstatic int mtk_snand_mac_trigger(struct mtk_snand *snf, u32 outlen, u32 inlen)\n{\n\tint ret;\n\tu32 val;\n\n\tnfi_write32(snf, SNF_MAC_CTL, SF_MAC_EN);\n\tnfi_write32(snf, SNF_MAC_OUTL, outlen);\n\tnfi_write32(snf, SNF_MAC_INL, inlen);\n\n\tnfi_write32(snf, SNF_MAC_CTL, SF_MAC_EN | SF_TRIG);\n\n\tret = readl_poll_timeout(snf->nfi_base + SNF_MAC_CTL, val,\n\t\t\t\t val & WIP_READY, 0, SNFI_POLL_INTERVAL);\n\tif (ret) {\n\t\tdev_err(snf->dev, \"Timed out waiting for WIP_READY\\n\");\n\t\tgoto cleanup;\n\t}\n\n\tret = readl_poll_timeout(snf->nfi_base + SNF_MAC_CTL, val, !(val & WIP),\n\t\t\t\t 0, SNFI_POLL_INTERVAL);\n\tif (ret)\n\t\tdev_err(snf->dev, \"Timed out waiting for WIP cleared\\n\");\n\ncleanup:\n\tnfi_write32(snf, SNF_MAC_CTL, 0);\n\n\treturn ret;\n}\n\nstatic int mtk_snand_mac_io(struct mtk_snand *snf, const struct spi_mem_op *op)\n{\n\tu32 rx_len = 0;\n\tu32 reg_offs = 0;\n\tu32 val = 0;\n\tconst u8 *tx_buf = NULL;\n\tu8 *rx_buf = NULL;\n\tint i, ret;\n\tu8 b;\n\n\tif (op->data.dir == SPI_MEM_DATA_IN) {\n\t\trx_len = op->data.nbytes;\n\t\trx_buf = op->data.buf.in;\n\t} else {\n\t\ttx_buf = op->data.buf.out;\n\t}\n\n\tmtk_snand_mac_reset(snf);\n\n\tfor (i = 0; i < op->cmd.nbytes; i++, reg_offs++) {\n\t\tb = (op->cmd.opcode >> ((op->cmd.nbytes - i - 1) * 8)) & 0xff;\n\t\tval |= b << (8 * (reg_offs % 4));\n\t\tif (reg_offs % 4 == 3) {\n\t\t\tnfi_write32(snf, SNF_GPRAM + reg_offs - 3, val);\n\t\t\tval = 0;\n\t\t}\n\t}\n\n\tfor (i = 0; i < op->addr.nbytes; i++, reg_offs++) {\n\t\tb = (op->addr.val >> ((op->addr.nbytes - i - 1) * 8)) & 0xff;\n\t\tval |= b << (8 * (reg_offs % 4));\n\t\tif (reg_offs % 4 == 3) {\n\t\t\tnfi_write32(snf, SNF_GPRAM + reg_offs - 3, val);\n\t\t\tval = 0;\n\t\t}\n\t}\n\n\tfor (i = 0; i < op->dummy.nbytes; i++, reg_offs++) {\n\t\tif (reg_offs % 4 == 3) {\n\t\t\tnfi_write32(snf, SNF_GPRAM + reg_offs - 3, val);\n\t\t\tval = 0;\n\t\t}\n\t}\n\n\tif (op->data.dir == SPI_MEM_DATA_OUT) {\n\t\tfor (i = 0; i < op->data.nbytes; i++, reg_offs++) {\n\t\t\tval |= tx_buf[i] << (8 * (reg_offs % 4));\n\t\t\tif (reg_offs % 4 == 3) {\n\t\t\t\tnfi_write32(snf, SNF_GPRAM + reg_offs - 3, val);\n\t\t\t\tval = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (reg_offs % 4)\n\t\tnfi_write32(snf, SNF_GPRAM + (reg_offs & ~3), val);\n\n\tfor (i = 0; i < reg_offs; i += 4)\n\t\tdev_dbg(snf->dev, \"%d: %08X\", i,\n\t\t\tnfi_read32(snf, SNF_GPRAM + i));\n\n\tdev_dbg(snf->dev, \"SNF TX: %u RX: %u\", reg_offs, rx_len);\n\n\tret = mtk_snand_mac_trigger(snf, reg_offs, rx_len);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!rx_len)\n\t\treturn 0;\n\n\tnfi_read_data(snf, SNF_GPRAM + reg_offs, rx_buf, rx_len);\n\treturn 0;\n}\n\nstatic int mtk_snand_setup_pagefmt(struct mtk_snand *snf, u32 page_size,\n\t\t\t\t   u32 oob_size)\n{\n\tint spare_idx = -1;\n\tu32 spare_size, spare_size_shift, pagesize_idx;\n\tu32 sector_size_512;\n\tu8 nsectors;\n\tint i;\n\n\t\n\tif (snf->nfi_cfg.page_size == page_size &&\n\t    snf->nfi_cfg.oob_size == oob_size)\n\t\treturn 0;\n\n\tnsectors = page_size / snf->caps->sector_size;\n\tif (nsectors > snf->caps->max_sectors) {\n\t\tdev_err(snf->dev, \"too many sectors required.\\n\");\n\t\tgoto err;\n\t}\n\n\tif (snf->caps->sector_size == 512) {\n\t\tsector_size_512 = NFI_SEC_SEL_512;\n\t\tspare_size_shift = NFI_SPARE_SIZE_S;\n\t} else {\n\t\tsector_size_512 = 0;\n\t\tspare_size_shift = NFI_SPARE_SIZE_LS_S;\n\t}\n\n\tswitch (page_size) {\n\tcase SZ_512:\n\t\tpagesize_idx = NFI_PAGE_SIZE_512_2K;\n\t\tbreak;\n\tcase SZ_2K:\n\t\tif (snf->caps->sector_size == 512)\n\t\t\tpagesize_idx = NFI_PAGE_SIZE_2K_4K;\n\t\telse\n\t\t\tpagesize_idx = NFI_PAGE_SIZE_512_2K;\n\t\tbreak;\n\tcase SZ_4K:\n\t\tif (snf->caps->sector_size == 512)\n\t\t\tpagesize_idx = NFI_PAGE_SIZE_4K_8K;\n\t\telse\n\t\t\tpagesize_idx = NFI_PAGE_SIZE_2K_4K;\n\t\tbreak;\n\tcase SZ_8K:\n\t\tif (snf->caps->sector_size == 512)\n\t\t\tpagesize_idx = NFI_PAGE_SIZE_8K_16K;\n\t\telse\n\t\t\tpagesize_idx = NFI_PAGE_SIZE_4K_8K;\n\t\tbreak;\n\tcase SZ_16K:\n\t\tpagesize_idx = NFI_PAGE_SIZE_8K_16K;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(snf->dev, \"unsupported page size.\\n\");\n\t\tgoto err;\n\t}\n\n\tspare_size = oob_size / nsectors;\n\t\n\t\n\tif (snf->caps->sector_size == 1024)\n\t\tspare_size /= 2;\n\n\tfor (i = snf->caps->num_spare_size - 1; i >= 0; i--) {\n\t\tif (snf->caps->spare_sizes[i] <= spare_size) {\n\t\t\tspare_size = snf->caps->spare_sizes[i];\n\t\t\tif (snf->caps->sector_size == 1024)\n\t\t\t\tspare_size *= 2;\n\t\t\tspare_idx = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (spare_idx < 0) {\n\t\tdev_err(snf->dev, \"unsupported spare size: %u\\n\", spare_size);\n\t\tgoto err;\n\t}\n\n\tnfi_write32(snf, NFI_PAGEFMT,\n\t\t    (snf->caps->fdm_ecc_size << NFI_FDM_ECC_NUM_S) |\n\t\t\t    (snf->caps->fdm_size << NFI_FDM_NUM_S) |\n\t\t\t    (spare_idx << spare_size_shift) |\n\t\t\t    (pagesize_idx << NFI_PAGE_SIZE_S) |\n\t\t\t    sector_size_512);\n\n\tsnf->nfi_cfg.page_size = page_size;\n\tsnf->nfi_cfg.oob_size = oob_size;\n\tsnf->nfi_cfg.nsectors = nsectors;\n\tsnf->nfi_cfg.spare_size = spare_size;\n\n\tdev_dbg(snf->dev, \"page format: (%u + %u) * %u\\n\",\n\t\tsnf->caps->sector_size, spare_size, nsectors);\n\treturn snand_prepare_bouncebuf(snf, page_size + oob_size);\nerr:\n\tdev_err(snf->dev, \"page size %u + %u is not supported\\n\", page_size,\n\t\toob_size);\n\treturn -EOPNOTSUPP;\n}\n\nstatic int mtk_snand_ooblayout_ecc(struct mtd_info *mtd, int section,\n\t\t\t\t   struct mtd_oob_region *oobecc)\n{\n\t\n\treturn -ERANGE;\n}\n\nstatic int mtk_snand_ooblayout_free(struct mtd_info *mtd, int section,\n\t\t\t\t    struct mtd_oob_region *oobfree)\n{\n\tstruct nand_device *nand = mtd_to_nanddev(mtd);\n\tstruct mtk_snand *ms = nand_to_mtk_snand(nand);\n\n\tif (section >= ms->nfi_cfg.nsectors)\n\t\treturn -ERANGE;\n\n\toobfree->length = ms->caps->fdm_size - 1;\n\toobfree->offset = section * ms->caps->fdm_size + 1;\n\treturn 0;\n}\n\nstatic const struct mtd_ooblayout_ops mtk_snand_ooblayout = {\n\t.ecc = mtk_snand_ooblayout_ecc,\n\t.free = mtk_snand_ooblayout_free,\n};\n\nstatic int mtk_snand_ecc_init_ctx(struct nand_device *nand)\n{\n\tstruct mtk_snand *snf = nand_to_mtk_snand(nand);\n\tstruct nand_ecc_props *conf = &nand->ecc.ctx.conf;\n\tstruct nand_ecc_props *reqs = &nand->ecc.requirements;\n\tstruct nand_ecc_props *user = &nand->ecc.user_conf;\n\tstruct mtd_info *mtd = nanddev_to_mtd(nand);\n\tint step_size = 0, strength = 0, desired_correction = 0, steps;\n\tbool ecc_user = false;\n\tint ret;\n\tu32 parity_bits, max_ecc_bytes;\n\tstruct mtk_ecc_config *ecc_cfg;\n\n\tret = mtk_snand_setup_pagefmt(snf, nand->memorg.pagesize,\n\t\t\t\t      nand->memorg.oobsize);\n\tif (ret)\n\t\treturn ret;\n\n\tecc_cfg = kzalloc(sizeof(*ecc_cfg), GFP_KERNEL);\n\tif (!ecc_cfg)\n\t\treturn -ENOMEM;\n\n\tnand->ecc.ctx.priv = ecc_cfg;\n\n\tif (user->step_size && user->strength) {\n\t\tstep_size = user->step_size;\n\t\tstrength = user->strength;\n\t\tecc_user = true;\n\t} else if (reqs->step_size && reqs->strength) {\n\t\tstep_size = reqs->step_size;\n\t\tstrength = reqs->strength;\n\t}\n\n\tif (step_size && strength) {\n\t\tsteps = mtd->writesize / step_size;\n\t\tdesired_correction = steps * strength;\n\t\tstrength = desired_correction / snf->nfi_cfg.nsectors;\n\t}\n\n\tecc_cfg->mode = ECC_NFI_MODE;\n\tecc_cfg->sectors = snf->nfi_cfg.nsectors;\n\tecc_cfg->len = snf->caps->sector_size + snf->caps->fdm_ecc_size;\n\n\t\n\tparity_bits = mtk_ecc_get_parity_bits(snf->ecc);\n\tmax_ecc_bytes = snf->nfi_cfg.spare_size - snf->caps->fdm_size;\n\tecc_cfg->strength = max_ecc_bytes * 8 / parity_bits;\n\tmtk_ecc_adjust_strength(snf->ecc, &ecc_cfg->strength);\n\n\t\n\t\n\t\n\tif (ecc_user && strength) {\n\t\tu32 s_next = ecc_cfg->strength - 1;\n\n\t\twhile (1) {\n\t\t\tmtk_ecc_adjust_strength(snf->ecc, &s_next);\n\t\t\tif (s_next >= ecc_cfg->strength)\n\t\t\t\tbreak;\n\t\t\tif (s_next < strength)\n\t\t\t\tbreak;\n\t\t\ts_next = ecc_cfg->strength - 1;\n\t\t}\n\t}\n\n\tmtd_set_ooblayout(mtd, &mtk_snand_ooblayout);\n\n\tconf->step_size = snf->caps->sector_size;\n\tconf->strength = ecc_cfg->strength;\n\n\tif (ecc_cfg->strength < strength)\n\t\tdev_warn(snf->dev, \"unable to fulfill ECC of %u bits.\\n\",\n\t\t\t strength);\n\tdev_info(snf->dev, \"ECC strength: %u bits per %u bytes\\n\",\n\t\t ecc_cfg->strength, snf->caps->sector_size);\n\n\treturn 0;\n}\n\nstatic void mtk_snand_ecc_cleanup_ctx(struct nand_device *nand)\n{\n\tstruct mtk_ecc_config *ecc_cfg = nand_to_ecc_ctx(nand);\n\n\tkfree(ecc_cfg);\n}\n\nstatic int mtk_snand_ecc_prepare_io_req(struct nand_device *nand,\n\t\t\t\t\tstruct nand_page_io_req *req)\n{\n\tstruct mtk_snand *snf = nand_to_mtk_snand(nand);\n\tstruct mtk_ecc_config *ecc_cfg = nand_to_ecc_ctx(nand);\n\tint ret;\n\n\tret = mtk_snand_setup_pagefmt(snf, nand->memorg.pagesize,\n\t\t\t\t      nand->memorg.oobsize);\n\tif (ret)\n\t\treturn ret;\n\tsnf->autofmt = true;\n\tsnf->ecc_cfg = ecc_cfg;\n\treturn 0;\n}\n\nstatic int mtk_snand_ecc_finish_io_req(struct nand_device *nand,\n\t\t\t\t       struct nand_page_io_req *req)\n{\n\tstruct mtk_snand *snf = nand_to_mtk_snand(nand);\n\tstruct mtd_info *mtd = nanddev_to_mtd(nand);\n\n\tsnf->ecc_cfg = NULL;\n\tsnf->autofmt = false;\n\tif ((req->mode == MTD_OPS_RAW) || (req->type != NAND_PAGE_READ))\n\t\treturn 0;\n\n\tif (snf->ecc_stats.failed)\n\t\tmtd->ecc_stats.failed += snf->ecc_stats.failed;\n\tmtd->ecc_stats.corrected += snf->ecc_stats.corrected;\n\treturn snf->ecc_stats.failed ? -EBADMSG : snf->ecc_stats.bitflips;\n}\n\nstatic struct nand_ecc_engine_ops mtk_snfi_ecc_engine_ops = {\n\t.init_ctx = mtk_snand_ecc_init_ctx,\n\t.cleanup_ctx = mtk_snand_ecc_cleanup_ctx,\n\t.prepare_io_req = mtk_snand_ecc_prepare_io_req,\n\t.finish_io_req = mtk_snand_ecc_finish_io_req,\n};\n\nstatic void mtk_snand_read_fdm(struct mtk_snand *snf, u8 *buf)\n{\n\tu32 vall, valm;\n\tu8 *oobptr = buf;\n\tint i, j;\n\n\tfor (i = 0; i < snf->nfi_cfg.nsectors; i++) {\n\t\tvall = nfi_read32(snf, NFI_FDML(i));\n\t\tvalm = nfi_read32(snf, NFI_FDMM(i));\n\n\t\tfor (j = 0; j < snf->caps->fdm_size; j++)\n\t\t\toobptr[j] = (j >= 4 ? valm : vall) >> ((j % 4) * 8);\n\n\t\toobptr += snf->caps->fdm_size;\n\t}\n}\n\nstatic void mtk_snand_write_fdm(struct mtk_snand *snf, const u8 *buf)\n{\n\tu32 fdm_size = snf->caps->fdm_size;\n\tconst u8 *oobptr = buf;\n\tu32 vall, valm;\n\tint i, j;\n\n\tfor (i = 0; i < snf->nfi_cfg.nsectors; i++) {\n\t\tvall = 0;\n\t\tvalm = 0;\n\n\t\tfor (j = 0; j < 8; j++) {\n\t\t\tif (j < 4)\n\t\t\t\tvall |= (j < fdm_size ? oobptr[j] : 0xff)\n\t\t\t\t\t<< (j * 8);\n\t\t\telse\n\t\t\t\tvalm |= (j < fdm_size ? oobptr[j] : 0xff)\n\t\t\t\t\t<< ((j - 4) * 8);\n\t\t}\n\n\t\tnfi_write32(snf, NFI_FDML(i), vall);\n\t\tnfi_write32(snf, NFI_FDMM(i), valm);\n\n\t\toobptr += fdm_size;\n\t}\n}\n\nstatic void mtk_snand_bm_swap(struct mtk_snand *snf, u8 *buf)\n{\n\tu32 buf_bbm_pos, fdm_bbm_pos;\n\n\tif (!snf->caps->bbm_swap || snf->nfi_cfg.nsectors == 1)\n\t\treturn;\n\n\t\n\t\n\tbuf_bbm_pos = snf->nfi_cfg.page_size -\n\t\t      (snf->nfi_cfg.nsectors - 1) * snf->nfi_cfg.spare_size;\n\tfdm_bbm_pos = snf->nfi_cfg.page_size +\n\t\t      (snf->nfi_cfg.nsectors - 1) * snf->caps->fdm_size;\n\n\tswap(snf->buf[fdm_bbm_pos], buf[buf_bbm_pos]);\n}\n\nstatic void mtk_snand_fdm_bm_swap(struct mtk_snand *snf)\n{\n\tu32 fdm_bbm_pos1, fdm_bbm_pos2;\n\n\tif (!snf->caps->bbm_swap || snf->nfi_cfg.nsectors == 1)\n\t\treturn;\n\n\t\n\tfdm_bbm_pos1 = snf->nfi_cfg.page_size;\n\tfdm_bbm_pos2 = snf->nfi_cfg.page_size +\n\t\t       (snf->nfi_cfg.nsectors - 1) * snf->caps->fdm_size;\n\tswap(snf->buf[fdm_bbm_pos1], snf->buf[fdm_bbm_pos2]);\n}\n\nstatic int mtk_snand_read_page_cache(struct mtk_snand *snf,\n\t\t\t\t     const struct spi_mem_op *op)\n{\n\tu8 *buf = snf->buf;\n\tu8 *buf_fdm = buf + snf->nfi_cfg.page_size;\n\t\n\tu32 op_addr = op->addr.val;\n\t\n\tu32 rd_offset = 0;\n\tu32 dummy_clk = (op->dummy.nbytes * BITS_PER_BYTE / op->dummy.buswidth);\n\tu32 op_mode = 0;\n\tu32 dma_len = snf->buf_len;\n\tint ret = 0;\n\tu32 rd_mode, rd_bytes, val;\n\tdma_addr_t buf_dma;\n\n\tif (snf->autofmt) {\n\t\tu32 last_bit;\n\t\tu32 mask;\n\n\t\tdma_len = snf->nfi_cfg.page_size;\n\t\top_mode = CNFG_AUTO_FMT_EN;\n\t\tif (op->data.ecc)\n\t\t\top_mode |= CNFG_HW_ECC_EN;\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tlast_bit = fls(snf->nfi_cfg.page_size + snf->nfi_cfg.oob_size);\n\t\tmask = (1 << last_bit) - 1;\n\t\trd_offset = op_addr & mask;\n\t\top_addr &= ~mask;\n\n\t\t\n\t\tif (rd_offset == 0 && op->data.nbytes >= snf->nfi_cfg.page_size)\n\t\t\tbuf = op->data.buf.in;\n\t}\n\tmtk_snand_mac_reset(snf);\n\tmtk_nfi_reset(snf);\n\n\t\n\tnfi_write32(snf, SNF_RD_CTL2,\n\t\t    (dummy_clk << DATA_READ_DUMMY_S) |\n\t\t\t    (op->cmd.opcode << DATA_READ_CMD_S));\n\n\t\n\tnfi_write32(snf, SNF_RD_CTL3, op_addr);\n\n\t\n\tif (op->data.buswidth == 4)\n\t\trd_mode = op->addr.buswidth == 4 ? DATA_READ_MODE_QUAD :\n\t\t\t\t\t\t   DATA_READ_MODE_X4;\n\telse if (op->data.buswidth == 2)\n\t\trd_mode = op->addr.buswidth == 2 ? DATA_READ_MODE_DUAL :\n\t\t\t\t\t\t   DATA_READ_MODE_X2;\n\telse\n\t\trd_mode = DATA_READ_MODE_X1;\n\trd_mode <<= DATA_READ_MODE_S;\n\tnfi_rmw32(snf, SNF_MISC_CTL, DATA_READ_MODE,\n\t\t  rd_mode | DATARD_CUSTOM_EN);\n\n\t\n\trd_bytes = (snf->nfi_cfg.spare_size + snf->caps->sector_size) *\n\t\t   snf->nfi_cfg.nsectors;\n\tnfi_write32(snf, SNF_MISC_CTL2,\n\t\t    (rd_bytes << PROGRAM_LOAD_BYTE_NUM_S) | rd_bytes);\n\n\t\n\tnfi_write16(snf, NFI_CNFG,\n\t\t    (CNFG_OP_MODE_CUST << CNFG_OP_MODE_S) | CNFG_DMA_BURST_EN |\n\t\t\t    CNFG_READ_MODE | CNFG_DMA_MODE | op_mode);\n\n\tnfi_write32(snf, NFI_CON, (snf->nfi_cfg.nsectors << CON_SEC_NUM_S));\n\n\tbuf_dma = dma_map_single(snf->dev, buf, dma_len, DMA_FROM_DEVICE);\n\tret = dma_mapping_error(snf->dev, buf_dma);\n\tif (ret) {\n\t\tdev_err(snf->dev, \"DMA mapping failed.\\n\");\n\t\tgoto cleanup;\n\t}\n\tnfi_write32(snf, NFI_STRADDR, buf_dma);\n\tif (op->data.ecc) {\n\t\tsnf->ecc_cfg->op = ECC_DECODE;\n\t\tret = mtk_ecc_enable(snf->ecc, snf->ecc_cfg);\n\t\tif (ret)\n\t\t\tgoto cleanup_dma;\n\t}\n\t\n\tnfi_write32(snf, NFI_INTR_EN, NFI_IRQ_INTR_EN | NFI_IRQ_CUS_READ);\n\treinit_completion(&snf->op_done);\n\n\t\n\tnfi_write16(snf, NFI_CMD, NFI_CMD_DUMMY_READ);\n\n\t\n\tnfi_rmw32(snf, NFI_CON, 0, CON_BRD);\n\tnfi_write16(snf, NFI_STRDATA, STR_DATA);\n\n\tif (!wait_for_completion_timeout(\n\t\t    &snf->op_done, usecs_to_jiffies(SNFI_POLL_INTERVAL))) {\n\t\tdev_err(snf->dev, \"DMA timed out for reading from cache.\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto cleanup;\n\t}\n\n\t\n\tret = readl_poll_timeout(snf->nfi_base + NFI_BYTELEN, val,\n\t\t\t\t BUS_SEC_CNTR(val) >= snf->nfi_cfg.nsectors, 0,\n\t\t\t\t SNFI_POLL_INTERVAL);\n\tif (ret) {\n\t\tdev_err(snf->dev, \"Timed out waiting for BUS_SEC_CNTR\\n\");\n\t\tgoto cleanup2;\n\t}\n\n\t\n\tret = readl_poll_timeout(snf->nfi_base + NFI_MASTERSTA, val,\n\t\t\t\t !(val & snf->caps->mastersta_mask), 0,\n\t\t\t\t SNFI_POLL_INTERVAL);\n\tif (ret) {\n\t\tdev_err(snf->dev, \"Timed out waiting for bus becoming idle\\n\");\n\t\tgoto cleanup2;\n\t}\n\n\tif (op->data.ecc) {\n\t\tret = mtk_ecc_wait_done(snf->ecc, ECC_DECODE);\n\t\tif (ret) {\n\t\t\tdev_err(snf->dev, \"wait ecc done timeout\\n\");\n\t\t\tgoto cleanup2;\n\t\t}\n\t\t\n\t\tmtk_ecc_get_stats(snf->ecc, &snf->ecc_stats,\n\t\t\t\t  snf->nfi_cfg.nsectors);\n\t}\n\n\tdma_unmap_single(snf->dev, buf_dma, dma_len, DMA_FROM_DEVICE);\n\n\tif (snf->autofmt) {\n\t\tmtk_snand_read_fdm(snf, buf_fdm);\n\t\tif (snf->caps->bbm_swap) {\n\t\t\tmtk_snand_bm_swap(snf, buf);\n\t\t\tmtk_snand_fdm_bm_swap(snf);\n\t\t}\n\t}\n\n\t\n\tif (nfi_read32(snf, NFI_STA) & READ_EMPTY) {\n\t\tmemset(op->data.buf.in, 0xff, op->data.nbytes);\n\t\tsnf->ecc_stats.bitflips = 0;\n\t\tsnf->ecc_stats.failed = 0;\n\t\tsnf->ecc_stats.corrected = 0;\n\t} else {\n\t\tif (buf == op->data.buf.in) {\n\t\t\tu32 cap_len = snf->buf_len - snf->nfi_cfg.page_size;\n\t\t\tu32 req_left = op->data.nbytes - snf->nfi_cfg.page_size;\n\n\t\t\tif (req_left)\n\t\t\t\tmemcpy(op->data.buf.in + snf->nfi_cfg.page_size,\n\t\t\t\t       buf_fdm,\n\t\t\t\t       cap_len < req_left ? cap_len : req_left);\n\t\t} else if (rd_offset < snf->buf_len) {\n\t\t\tu32 cap_len = snf->buf_len - rd_offset;\n\n\t\t\tif (op->data.nbytes < cap_len)\n\t\t\t\tcap_len = op->data.nbytes;\n\t\t\tmemcpy(op->data.buf.in, snf->buf + rd_offset, cap_len);\n\t\t}\n\t}\ncleanup2:\n\tif (op->data.ecc)\n\t\tmtk_ecc_disable(snf->ecc);\ncleanup_dma:\n\t\n\t\n\tif (ret)\n\t\tdma_unmap_single(snf->dev, buf_dma, dma_len, DMA_FROM_DEVICE);\ncleanup:\n\t\n\tnfi_write32(snf, NFI_CON, 0);\n\tnfi_write16(snf, NFI_CNFG, 0);\n\n\t\n\tnfi_rmw32(snf, SNF_STA_CTL1, 0, CUS_READ_DONE);\n\tnfi_write32(snf, SNF_STA_CTL1, 0);\n\n\t\n\tnfi_read32(snf, NFI_INTR_STA);\n\tnfi_write32(snf, NFI_INTR_EN, 0);\n\n\tnfi_rmw32(snf, SNF_MISC_CTL, DATARD_CUSTOM_EN, 0);\n\treturn ret;\n}\n\nstatic int mtk_snand_write_page_cache(struct mtk_snand *snf,\n\t\t\t\t      const struct spi_mem_op *op)\n{\n\t\n\tu32 op_addr = op->addr.val;\n\t\n\tu32 wr_offset = 0;\n\tu32 op_mode = 0;\n\tint ret = 0;\n\tu32 wr_mode = 0;\n\tu32 dma_len = snf->buf_len;\n\tu32 wr_bytes, val;\n\tsize_t cap_len;\n\tdma_addr_t buf_dma;\n\n\tif (snf->autofmt) {\n\t\tu32 last_bit;\n\t\tu32 mask;\n\n\t\tdma_len = snf->nfi_cfg.page_size;\n\t\top_mode = CNFG_AUTO_FMT_EN;\n\t\tif (op->data.ecc)\n\t\t\top_mode |= CNFG_HW_ECC_EN;\n\n\t\tlast_bit = fls(snf->nfi_cfg.page_size + snf->nfi_cfg.oob_size);\n\t\tmask = (1 << last_bit) - 1;\n\t\twr_offset = op_addr & mask;\n\t\top_addr &= ~mask;\n\t}\n\tmtk_snand_mac_reset(snf);\n\tmtk_nfi_reset(snf);\n\n\tif (wr_offset)\n\t\tmemset(snf->buf, 0xff, wr_offset);\n\n\tcap_len = snf->buf_len - wr_offset;\n\tif (op->data.nbytes < cap_len)\n\t\tcap_len = op->data.nbytes;\n\tmemcpy(snf->buf + wr_offset, op->data.buf.out, cap_len);\n\tif (snf->autofmt) {\n\t\tif (snf->caps->bbm_swap) {\n\t\t\tmtk_snand_fdm_bm_swap(snf);\n\t\t\tmtk_snand_bm_swap(snf, snf->buf);\n\t\t}\n\t\tmtk_snand_write_fdm(snf, snf->buf + snf->nfi_cfg.page_size);\n\t}\n\n\t\n\tnfi_write32(snf, SNF_PG_CTL1, (op->cmd.opcode << PG_LOAD_CMD_S));\n\n\t\n\tnfi_write32(snf, SNF_PG_CTL2, op_addr);\n\n\t\n\tif (op->data.buswidth == 4)\n\t\twr_mode = PG_LOAD_X4_EN;\n\n\tnfi_rmw32(snf, SNF_MISC_CTL, PG_LOAD_X4_EN,\n\t\t  wr_mode | PG_LOAD_CUSTOM_EN);\n\n\t\n\twr_bytes = (snf->nfi_cfg.spare_size + snf->caps->sector_size) *\n\t\t   snf->nfi_cfg.nsectors;\n\tnfi_write32(snf, SNF_MISC_CTL2,\n\t\t    (wr_bytes << PROGRAM_LOAD_BYTE_NUM_S) | wr_bytes);\n\n\t\n\tnfi_write16(snf, NFI_CNFG,\n\t\t    (CNFG_OP_MODE_PROGRAM << CNFG_OP_MODE_S) |\n\t\t\t    CNFG_DMA_BURST_EN | CNFG_DMA_MODE | op_mode);\n\n\tnfi_write32(snf, NFI_CON, (snf->nfi_cfg.nsectors << CON_SEC_NUM_S));\n\tbuf_dma = dma_map_single(snf->dev, snf->buf, dma_len, DMA_TO_DEVICE);\n\tret = dma_mapping_error(snf->dev, buf_dma);\n\tif (ret) {\n\t\tdev_err(snf->dev, \"DMA mapping failed.\\n\");\n\t\tgoto cleanup;\n\t}\n\tnfi_write32(snf, NFI_STRADDR, buf_dma);\n\tif (op->data.ecc) {\n\t\tsnf->ecc_cfg->op = ECC_ENCODE;\n\t\tret = mtk_ecc_enable(snf->ecc, snf->ecc_cfg);\n\t\tif (ret)\n\t\t\tgoto cleanup_dma;\n\t}\n\t\n\tnfi_write32(snf, NFI_INTR_EN, NFI_IRQ_INTR_EN | NFI_IRQ_CUS_PG);\n\treinit_completion(&snf->op_done);\n\t;\n\n\t\n\tnfi_write16(snf, NFI_CMD, NFI_CMD_DUMMY_WRITE);\n\n\t\n\tnfi_rmw32(snf, NFI_CON, 0, CON_BWR);\n\tnfi_write16(snf, NFI_STRDATA, STR_DATA);\n\n\tif (!wait_for_completion_timeout(\n\t\t    &snf->op_done, usecs_to_jiffies(SNFI_POLL_INTERVAL))) {\n\t\tdev_err(snf->dev, \"DMA timed out for program load.\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto cleanup_ecc;\n\t}\n\n\t\n\tret = readl_poll_timeout(snf->nfi_base + NFI_ADDRCNTR, val,\n\t\t\t\t NFI_SEC_CNTR(val) >= snf->nfi_cfg.nsectors, 0,\n\t\t\t\t SNFI_POLL_INTERVAL);\n\tif (ret)\n\t\tdev_err(snf->dev, \"Timed out waiting for NFI_SEC_CNTR\\n\");\n\ncleanup_ecc:\n\tif (op->data.ecc)\n\t\tmtk_ecc_disable(snf->ecc);\ncleanup_dma:\n\tdma_unmap_single(snf->dev, buf_dma, dma_len, DMA_TO_DEVICE);\ncleanup:\n\t\n\tnfi_write32(snf, NFI_CON, 0);\n\tnfi_write16(snf, NFI_CNFG, 0);\n\n\t\n\tnfi_rmw32(snf, SNF_STA_CTL1, 0, CUS_PG_DONE);\n\tnfi_write32(snf, SNF_STA_CTL1, 0);\n\n\t\n\tnfi_read32(snf, NFI_INTR_STA);\n\tnfi_write32(snf, NFI_INTR_EN, 0);\n\n\tnfi_rmw32(snf, SNF_MISC_CTL, PG_LOAD_CUSTOM_EN, 0);\n\n\treturn ret;\n}\n\n \nstatic bool mtk_snand_is_page_ops(const struct spi_mem_op *op)\n{\n\tif (op->addr.nbytes != 2)\n\t\treturn false;\n\n\tif (op->addr.buswidth != 1 && op->addr.buswidth != 2 &&\n\t    op->addr.buswidth != 4)\n\t\treturn false;\n\n\t\n\tif (op->data.dir == SPI_MEM_DATA_IN) {\n\t\t\n\t\tif (op->dummy.nbytes * BITS_PER_BYTE / op->dummy.buswidth >\n\t\t    DATA_READ_MAX_DUMMY)\n\t\t\treturn false;\n\t\t\n\t\tif ((op->addr.buswidth == 4 || op->addr.buswidth == 1) &&\n\t\t    op->data.buswidth == 4)\n\t\t\treturn true;\n\n\t\t\n\t\tif ((op->addr.buswidth == 2 || op->addr.buswidth == 1) &&\n\t\t    op->data.buswidth == 2)\n\t\t\treturn true;\n\n\t\t\n\t\tif (op->addr.buswidth == 1 && op->data.buswidth == 1)\n\t\t\treturn true;\n\t} else if (op->data.dir == SPI_MEM_DATA_OUT) {\n\t\t\n\t\tif (op->dummy.nbytes)\n\t\t\treturn false;\n\t\t\n\t\tif (op->addr.buswidth == 1 && op->data.buswidth == 4)\n\t\t\treturn true;\n\t\t\n\t\tif (op->addr.buswidth == 1 && op->data.buswidth == 1)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic bool mtk_snand_supports_op(struct spi_mem *mem,\n\t\t\t\t  const struct spi_mem_op *op)\n{\n\tif (!spi_mem_default_supports_op(mem, op))\n\t\treturn false;\n\tif (op->cmd.nbytes != 1 || op->cmd.buswidth != 1)\n\t\treturn false;\n\tif (mtk_snand_is_page_ops(op))\n\t\treturn true;\n\treturn ((op->addr.nbytes == 0 || op->addr.buswidth == 1) &&\n\t\t(op->dummy.nbytes == 0 || op->dummy.buswidth == 1) &&\n\t\t(op->data.nbytes == 0 || op->data.buswidth == 1));\n}\n\nstatic int mtk_snand_adjust_op_size(struct spi_mem *mem, struct spi_mem_op *op)\n{\n\tstruct mtk_snand *ms = spi_controller_get_devdata(mem->spi->master);\n\t\n\t\n\t\n\t\n\tif (mtk_snand_is_page_ops(op)) {\n\t\tsize_t l;\n\t\t\n\t\tif (ms->autofmt)\n\t\t\treturn 0;\n\t\tl = ms->caps->sector_size + ms->nfi_cfg.spare_size;\n\t\tl *= ms->nfi_cfg.nsectors;\n\t\tif (op->data.nbytes > l)\n\t\t\top->data.nbytes = l;\n\t} else {\n\t\tsize_t hl = op->cmd.nbytes + op->addr.nbytes + op->dummy.nbytes;\n\n\t\tif (hl >= SNF_GPRAM_SIZE)\n\t\t\treturn -EOPNOTSUPP;\n\t\tif (op->data.nbytes > SNF_GPRAM_SIZE - hl)\n\t\t\top->data.nbytes = SNF_GPRAM_SIZE - hl;\n\t}\n\treturn 0;\n}\n\nstatic int mtk_snand_exec_op(struct spi_mem *mem, const struct spi_mem_op *op)\n{\n\tstruct mtk_snand *ms = spi_controller_get_devdata(mem->spi->master);\n\n\tdev_dbg(ms->dev, \"OP %02x ADDR %08llX@%d:%u DATA %d:%u\", op->cmd.opcode,\n\t\top->addr.val, op->addr.buswidth, op->addr.nbytes,\n\t\top->data.buswidth, op->data.nbytes);\n\tif (mtk_snand_is_page_ops(op)) {\n\t\tif (op->data.dir == SPI_MEM_DATA_IN)\n\t\t\treturn mtk_snand_read_page_cache(ms, op);\n\t\telse\n\t\t\treturn mtk_snand_write_page_cache(ms, op);\n\t} else {\n\t\treturn mtk_snand_mac_io(ms, op);\n\t}\n}\n\nstatic const struct spi_controller_mem_ops mtk_snand_mem_ops = {\n\t.adjust_op_size = mtk_snand_adjust_op_size,\n\t.supports_op = mtk_snand_supports_op,\n\t.exec_op = mtk_snand_exec_op,\n};\n\nstatic const struct spi_controller_mem_caps mtk_snand_mem_caps = {\n\t.ecc = true,\n};\n\nstatic irqreturn_t mtk_snand_irq(int irq, void *id)\n{\n\tstruct mtk_snand *snf = id;\n\tu32 sta, ien;\n\n\tsta = nfi_read32(snf, NFI_INTR_STA);\n\tien = nfi_read32(snf, NFI_INTR_EN);\n\n\tif (!(sta & ien))\n\t\treturn IRQ_NONE;\n\n\tnfi_write32(snf, NFI_INTR_EN, 0);\n\tcomplete(&snf->op_done);\n\treturn IRQ_HANDLED;\n}\n\nstatic const struct of_device_id mtk_snand_ids[] = {\n\t{ .compatible = \"mediatek,mt7622-snand\", .data = &mt7622_snand_caps },\n\t{ .compatible = \"mediatek,mt7629-snand\", .data = &mt7629_snand_caps },\n\t{ .compatible = \"mediatek,mt7986-snand\", .data = &mt7986_snand_caps },\n\t{},\n};\n\nMODULE_DEVICE_TABLE(of, mtk_snand_ids);\n\nstatic int mtk_snand_enable_clk(struct mtk_snand *ms)\n{\n\tint ret;\n\n\tret = clk_prepare_enable(ms->nfi_clk);\n\tif (ret) {\n\t\tdev_err(ms->dev, \"unable to enable nfi clk\\n\");\n\t\treturn ret;\n\t}\n\tret = clk_prepare_enable(ms->pad_clk);\n\tif (ret) {\n\t\tdev_err(ms->dev, \"unable to enable pad clk\\n\");\n\t\tgoto err1;\n\t}\n\tret = clk_prepare_enable(ms->nfi_hclk);\n\tif (ret) {\n\t\tdev_err(ms->dev, \"unable to enable nfi hclk\\n\");\n\t\tgoto err2;\n\t}\n\n\treturn 0;\n\nerr2:\n\tclk_disable_unprepare(ms->pad_clk);\nerr1:\n\tclk_disable_unprepare(ms->nfi_clk);\n\treturn ret;\n}\n\nstatic void mtk_snand_disable_clk(struct mtk_snand *ms)\n{\n\tclk_disable_unprepare(ms->nfi_hclk);\n\tclk_disable_unprepare(ms->pad_clk);\n\tclk_disable_unprepare(ms->nfi_clk);\n}\n\nstatic int mtk_snand_probe(struct platform_device *pdev)\n{\n\tstruct device_node *np = pdev->dev.of_node;\n\tconst struct of_device_id *dev_id;\n\tstruct spi_controller *ctlr;\n\tstruct mtk_snand *ms;\n\tunsigned long spi_freq;\n\tu32 val = 0;\n\tint ret;\n\n\tdev_id = of_match_node(mtk_snand_ids, np);\n\tif (!dev_id)\n\t\treturn -EINVAL;\n\n\tctlr = devm_spi_alloc_master(&pdev->dev, sizeof(*ms));\n\tif (!ctlr)\n\t\treturn -ENOMEM;\n\tplatform_set_drvdata(pdev, ctlr);\n\n\tms = spi_controller_get_devdata(ctlr);\n\n\tms->ctlr = ctlr;\n\tms->caps = dev_id->data;\n\n\tms->ecc = of_mtk_ecc_get(np);\n\tif (IS_ERR(ms->ecc))\n\t\treturn PTR_ERR(ms->ecc);\n\telse if (!ms->ecc)\n\t\treturn -ENODEV;\n\n\tms->nfi_base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(ms->nfi_base)) {\n\t\tret = PTR_ERR(ms->nfi_base);\n\t\tgoto release_ecc;\n\t}\n\n\tms->dev = &pdev->dev;\n\n\tms->nfi_clk = devm_clk_get(&pdev->dev, \"nfi_clk\");\n\tif (IS_ERR(ms->nfi_clk)) {\n\t\tret = PTR_ERR(ms->nfi_clk);\n\t\tdev_err(&pdev->dev, \"unable to get nfi_clk, err = %d\\n\", ret);\n\t\tgoto release_ecc;\n\t}\n\n\tms->pad_clk = devm_clk_get(&pdev->dev, \"pad_clk\");\n\tif (IS_ERR(ms->pad_clk)) {\n\t\tret = PTR_ERR(ms->pad_clk);\n\t\tdev_err(&pdev->dev, \"unable to get pad_clk, err = %d\\n\", ret);\n\t\tgoto release_ecc;\n\t}\n\n\tms->nfi_hclk = devm_clk_get_optional(&pdev->dev, \"nfi_hclk\");\n\tif (IS_ERR(ms->nfi_hclk)) {\n\t\tret = PTR_ERR(ms->nfi_hclk);\n\t\tdev_err(&pdev->dev, \"unable to get nfi_hclk, err = %d\\n\", ret);\n\t\tgoto release_ecc;\n\t}\n\n\tret = mtk_snand_enable_clk(ms);\n\tif (ret)\n\t\tgoto release_ecc;\n\n\tinit_completion(&ms->op_done);\n\n\tms->irq = platform_get_irq(pdev, 0);\n\tif (ms->irq < 0) {\n\t\tret = ms->irq;\n\t\tgoto disable_clk;\n\t}\n\tret = devm_request_irq(ms->dev, ms->irq, mtk_snand_irq, 0x0,\n\t\t\t       \"mtk-snand\", ms);\n\tif (ret) {\n\t\tdev_err(ms->dev, \"failed to request snfi irq\\n\");\n\t\tgoto disable_clk;\n\t}\n\n\tret = dma_set_mask(ms->dev, DMA_BIT_MASK(32));\n\tif (ret) {\n\t\tdev_err(ms->dev, \"failed to set dma mask\\n\");\n\t\tgoto disable_clk;\n\t}\n\n\t\n\tnfi_write32(ms, SNF_CFG, SPI_MODE);\n\n\tret = of_property_read_u32(np, \"rx-sample-delay-ns\", &val);\n\tif (!ret)\n\t\tnfi_rmw32(ms, SNF_DLY_CTL3, SFCK_SAM_DLY,\n\t\t\t  val * SFCK_SAM_DLY_RANGE / SFCK_SAM_DLY_TOTAL);\n\n\tret = of_property_read_u32(np, \"mediatek,rx-latch-latency-ns\", &val);\n\tif (!ret) {\n\t\tspi_freq = clk_get_rate(ms->pad_clk);\n\t\tval = DIV_ROUND_CLOSEST(val, NSEC_PER_SEC / spi_freq);\n\t\tnfi_rmw32(ms, SNF_MISC_CTL, DATA_READ_LATCH_LAT,\n\t\t\t  val << DATA_READ_LATCH_LAT_S);\n\t}\n\n\t\n\t\n\tret = mtk_snand_setup_pagefmt(ms, SZ_2K, SZ_64);\n\tif (ret) {\n\t\tdev_err(ms->dev, \"failed to set initial page format\\n\");\n\t\tgoto disable_clk;\n\t}\n\n\t\n\tms->ecc_eng.dev = &pdev->dev;\n\tms->ecc_eng.integration = NAND_ECC_ENGINE_INTEGRATION_PIPELINED;\n\tms->ecc_eng.ops = &mtk_snfi_ecc_engine_ops;\n\tms->ecc_eng.priv = ms;\n\n\tret = nand_ecc_register_on_host_hw_engine(&ms->ecc_eng);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed to register ecc engine.\\n\");\n\t\tgoto disable_clk;\n\t}\n\n\tctlr->num_chipselect = 1;\n\tctlr->mem_ops = &mtk_snand_mem_ops;\n\tctlr->mem_caps = &mtk_snand_mem_caps;\n\tctlr->bits_per_word_mask = SPI_BPW_MASK(8);\n\tctlr->mode_bits = SPI_RX_DUAL | SPI_RX_QUAD | SPI_TX_DUAL | SPI_TX_QUAD;\n\tctlr->dev.of_node = pdev->dev.of_node;\n\tret = spi_register_controller(ctlr);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"spi_register_controller failed.\\n\");\n\t\tgoto disable_clk;\n\t}\n\n\treturn 0;\ndisable_clk:\n\tmtk_snand_disable_clk(ms);\nrelease_ecc:\n\tmtk_ecc_release(ms->ecc);\n\treturn ret;\n}\n\nstatic void mtk_snand_remove(struct platform_device *pdev)\n{\n\tstruct spi_controller *ctlr = platform_get_drvdata(pdev);\n\tstruct mtk_snand *ms = spi_controller_get_devdata(ctlr);\n\n\tspi_unregister_controller(ctlr);\n\tmtk_snand_disable_clk(ms);\n\tmtk_ecc_release(ms->ecc);\n\tkfree(ms->buf);\n}\n\nstatic struct platform_driver mtk_snand_driver = {\n\t.probe = mtk_snand_probe,\n\t.remove_new = mtk_snand_remove,\n\t.driver = {\n\t\t.name = \"mtk-snand\",\n\t\t.of_match_table = mtk_snand_ids,\n\t},\n};\n\nmodule_platform_driver(mtk_snand_driver);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Chuanhong Guo <gch981213@gmail.com>\");\nMODULE_DESCRIPTION(\"MeidaTek SPI-NAND Flash Controller Driver\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}