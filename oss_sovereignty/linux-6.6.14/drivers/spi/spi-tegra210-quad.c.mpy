{
  "module_name": "spi-tegra210-quad.c",
  "hash_id": "47be9b23c7fa9bbdcac587782f8e1f884197ccb1a3ad172f3b9954217a29277a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/spi/spi-tegra210-quad.c",
  "human_readable_source": "\n\n\n\n#include <linux/clk.h>\n#include <linux/completion.h>\n#include <linux/delay.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmapool.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/iopoll.h>\n#include <linux/kernel.h>\n#include <linux/kthread.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/of.h>\n#include <linux/reset.h>\n#include <linux/spi/spi.h>\n#include <linux/acpi.h>\n#include <linux/property.h>\n\n#define QSPI_COMMAND1\t\t\t\t0x000\n#define QSPI_BIT_LENGTH(x)\t\t\t(((x) & 0x1f) << 0)\n#define QSPI_PACKED\t\t\t\tBIT(5)\n#define QSPI_INTERFACE_WIDTH_MASK\t\t(0x03 << 7)\n#define QSPI_INTERFACE_WIDTH(x)\t\t\t(((x) & 0x03) << 7)\n#define QSPI_INTERFACE_WIDTH_SINGLE\t\tQSPI_INTERFACE_WIDTH(0)\n#define QSPI_INTERFACE_WIDTH_DUAL\t\tQSPI_INTERFACE_WIDTH(1)\n#define QSPI_INTERFACE_WIDTH_QUAD\t\tQSPI_INTERFACE_WIDTH(2)\n#define QSPI_SDR_DDR_SEL\t\t\tBIT(9)\n#define QSPI_TX_EN\t\t\t\tBIT(11)\n#define QSPI_RX_EN\t\t\t\tBIT(12)\n#define QSPI_CS_SW_VAL\t\t\t\tBIT(20)\n#define QSPI_CS_SW_HW\t\t\t\tBIT(21)\n\n#define QSPI_CS_POL_INACTIVE(n)\t\t\t(1 << (22 + (n)))\n#define QSPI_CS_POL_INACTIVE_MASK\t\t(0xF << 22)\n#define QSPI_CS_SEL_0\t\t\t\t(0 << 26)\n#define QSPI_CS_SEL_1\t\t\t\t(1 << 26)\n#define QSPI_CS_SEL_2\t\t\t\t(2 << 26)\n#define QSPI_CS_SEL_3\t\t\t\t(3 << 26)\n#define QSPI_CS_SEL_MASK\t\t\t(3 << 26)\n#define QSPI_CS_SEL(x)\t\t\t\t(((x) & 0x3) << 26)\n\n#define QSPI_CONTROL_MODE_0\t\t\t(0 << 28)\n#define QSPI_CONTROL_MODE_3\t\t\t(3 << 28)\n#define QSPI_CONTROL_MODE_MASK\t\t\t(3 << 28)\n#define QSPI_M_S\t\t\t\tBIT(30)\n#define QSPI_PIO\t\t\t\tBIT(31)\n\n#define QSPI_COMMAND2\t\t\t\t0x004\n#define QSPI_TX_TAP_DELAY(x)\t\t\t(((x) & 0x3f) << 10)\n#define QSPI_RX_TAP_DELAY(x)\t\t\t(((x) & 0xff) << 0)\n\n#define QSPI_CS_TIMING1\t\t\t\t0x008\n#define QSPI_SETUP_HOLD(setup, hold)\t\t(((setup) << 4) | (hold))\n\n#define QSPI_CS_TIMING2\t\t\t\t0x00c\n#define CYCLES_BETWEEN_PACKETS_0(x)\t\t(((x) & 0x1f) << 0)\n#define CS_ACTIVE_BETWEEN_PACKETS_0\t\tBIT(5)\n\n#define QSPI_TRANS_STATUS\t\t\t0x010\n#define QSPI_BLK_CNT(val)\t\t\t(((val) >> 0) & 0xffff)\n#define QSPI_RDY\t\t\t\tBIT(30)\n\n#define QSPI_FIFO_STATUS\t\t\t0x014\n#define QSPI_RX_FIFO_EMPTY\t\t\tBIT(0)\n#define QSPI_RX_FIFO_FULL\t\t\tBIT(1)\n#define QSPI_TX_FIFO_EMPTY\t\t\tBIT(2)\n#define QSPI_TX_FIFO_FULL\t\t\tBIT(3)\n#define QSPI_RX_FIFO_UNF\t\t\tBIT(4)\n#define QSPI_RX_FIFO_OVF\t\t\tBIT(5)\n#define QSPI_TX_FIFO_UNF\t\t\tBIT(6)\n#define QSPI_TX_FIFO_OVF\t\t\tBIT(7)\n#define QSPI_ERR\t\t\t\tBIT(8)\n#define QSPI_TX_FIFO_FLUSH\t\t\tBIT(14)\n#define QSPI_RX_FIFO_FLUSH\t\t\tBIT(15)\n#define QSPI_TX_FIFO_EMPTY_COUNT(val)\t\t(((val) >> 16) & 0x7f)\n#define QSPI_RX_FIFO_FULL_COUNT(val)\t\t(((val) >> 23) & 0x7f)\n\n#define QSPI_FIFO_ERROR\t\t\t\t(QSPI_RX_FIFO_UNF | \\\n\t\t\t\t\t\t QSPI_RX_FIFO_OVF | \\\n\t\t\t\t\t\t QSPI_TX_FIFO_UNF | \\\n\t\t\t\t\t\t QSPI_TX_FIFO_OVF)\n#define QSPI_FIFO_EMPTY\t\t\t\t(QSPI_RX_FIFO_EMPTY | \\\n\t\t\t\t\t\t QSPI_TX_FIFO_EMPTY)\n\n#define QSPI_TX_DATA\t\t\t\t0x018\n#define QSPI_RX_DATA\t\t\t\t0x01c\n\n#define QSPI_DMA_CTL\t\t\t\t0x020\n#define QSPI_TX_TRIG(n)\t\t\t\t(((n) & 0x3) << 15)\n#define QSPI_TX_TRIG_1\t\t\t\tQSPI_TX_TRIG(0)\n#define QSPI_TX_TRIG_4\t\t\t\tQSPI_TX_TRIG(1)\n#define QSPI_TX_TRIG_8\t\t\t\tQSPI_TX_TRIG(2)\n#define QSPI_TX_TRIG_16\t\t\t\tQSPI_TX_TRIG(3)\n\n#define QSPI_RX_TRIG(n)\t\t\t\t(((n) & 0x3) << 19)\n#define QSPI_RX_TRIG_1\t\t\t\tQSPI_RX_TRIG(0)\n#define QSPI_RX_TRIG_4\t\t\t\tQSPI_RX_TRIG(1)\n#define QSPI_RX_TRIG_8\t\t\t\tQSPI_RX_TRIG(2)\n#define QSPI_RX_TRIG_16\t\t\t\tQSPI_RX_TRIG(3)\n\n#define QSPI_DMA_EN\t\t\t\tBIT(31)\n\n#define QSPI_DMA_BLK\t\t\t\t0x024\n#define QSPI_DMA_BLK_SET(x)\t\t\t(((x) & 0xffff) << 0)\n\n#define QSPI_TX_FIFO\t\t\t\t0x108\n#define QSPI_RX_FIFO\t\t\t\t0x188\n\n#define QSPI_FIFO_DEPTH\t\t\t\t64\n\n#define QSPI_INTR_MASK\t\t\t\t0x18c\n#define QSPI_INTR_RX_FIFO_UNF_MASK\t\tBIT(25)\n#define QSPI_INTR_RX_FIFO_OVF_MASK\t\tBIT(26)\n#define QSPI_INTR_TX_FIFO_UNF_MASK\t\tBIT(27)\n#define QSPI_INTR_TX_FIFO_OVF_MASK\t\tBIT(28)\n#define QSPI_INTR_RDY_MASK\t\t\tBIT(29)\n#define QSPI_INTR_RX_TX_FIFO_ERR\t\t(QSPI_INTR_RX_FIFO_UNF_MASK | \\\n\t\t\t\t\t\t QSPI_INTR_RX_FIFO_OVF_MASK | \\\n\t\t\t\t\t\t QSPI_INTR_TX_FIFO_UNF_MASK | \\\n\t\t\t\t\t\t QSPI_INTR_TX_FIFO_OVF_MASK)\n\n#define QSPI_MISC_REG                           0x194\n#define QSPI_NUM_DUMMY_CYCLE(x)\t\t\t(((x) & 0xff) << 0)\n#define QSPI_DUMMY_CYCLES_MAX\t\t\t0xff\n\n#define QSPI_CMB_SEQ_CMD\t\t\t0x19c\n#define QSPI_COMMAND_VALUE_SET(X)\t\t(((x) & 0xFF) << 0)\n\n#define QSPI_CMB_SEQ_CMD_CFG\t\t\t0x1a0\n#define QSPI_COMMAND_X1_X2_X4(x)\t\t(((x) & 0x3) << 13)\n#define QSPI_COMMAND_X1_X2_X4_MASK\t\t(0x03 << 13)\n#define QSPI_COMMAND_SDR_DDR\t\t\tBIT(12)\n#define QSPI_COMMAND_SIZE_SET(x)\t\t(((x) & 0xFF) << 0)\n\n#define QSPI_GLOBAL_CONFIG\t\t\t0X1a4\n#define QSPI_CMB_SEQ_EN\t\t\t\tBIT(0)\n#define QSPI_TPM_WAIT_POLL_EN\t\t\tBIT(1)\n\n#define QSPI_CMB_SEQ_ADDR\t\t\t0x1a8\n#define QSPI_ADDRESS_VALUE_SET(X)\t\t(((x) & 0xFFFF) << 0)\n\n#define QSPI_CMB_SEQ_ADDR_CFG\t\t\t0x1ac\n#define QSPI_ADDRESS_X1_X2_X4(x)\t\t(((x) & 0x3) << 13)\n#define QSPI_ADDRESS_X1_X2_X4_MASK\t\t(0x03 << 13)\n#define QSPI_ADDRESS_SDR_DDR\t\t\tBIT(12)\n#define QSPI_ADDRESS_SIZE_SET(x)\t\t(((x) & 0xFF) << 0)\n\n#define DATA_DIR_TX\t\t\t\tBIT(0)\n#define DATA_DIR_RX\t\t\t\tBIT(1)\n\n#define QSPI_DMA_TIMEOUT\t\t\t(msecs_to_jiffies(1000))\n#define DEFAULT_QSPI_DMA_BUF_LEN\t\t(64 * 1024)\n#define CMD_TRANSFER\t\t\t\t0\n#define ADDR_TRANSFER\t\t\t\t1\n#define DATA_TRANSFER\t\t\t\t2\n\nstruct tegra_qspi_soc_data {\n\tbool has_dma;\n\tbool cmb_xfer_capable;\n\tbool supports_tpm;\n\tunsigned int cs_count;\n};\n\nstruct tegra_qspi_client_data {\n\tint tx_clk_tap_delay;\n\tint rx_clk_tap_delay;\n};\n\nstruct tegra_qspi {\n\tstruct device\t\t\t\t*dev;\n\tstruct spi_master\t\t\t*master;\n\t \n\tspinlock_t\t\t\t\tlock;\n\n\tstruct clk\t\t\t\t*clk;\n\tvoid __iomem\t\t\t\t*base;\n\tphys_addr_t\t\t\t\tphys;\n\tunsigned int\t\t\t\tirq;\n\n\tu32\t\t\t\t\tcur_speed;\n\tunsigned int\t\t\t\tcur_pos;\n\tunsigned int\t\t\t\twords_per_32bit;\n\tunsigned int\t\t\t\tbytes_per_word;\n\tunsigned int\t\t\t\tcurr_dma_words;\n\tunsigned int\t\t\t\tcur_direction;\n\n\tunsigned int\t\t\t\tcur_rx_pos;\n\tunsigned int\t\t\t\tcur_tx_pos;\n\n\tunsigned int\t\t\t\tdma_buf_size;\n\tunsigned int\t\t\t\tmax_buf_size;\n\tbool\t\t\t\t\tis_curr_dma_xfer;\n\n\tstruct completion\t\t\trx_dma_complete;\n\tstruct completion\t\t\ttx_dma_complete;\n\n\tu32\t\t\t\t\ttx_status;\n\tu32\t\t\t\t\trx_status;\n\tu32\t\t\t\t\tstatus_reg;\n\tbool\t\t\t\t\tis_packed;\n\tbool\t\t\t\t\tuse_dma;\n\n\tu32\t\t\t\t\tcommand1_reg;\n\tu32\t\t\t\t\tdma_control_reg;\n\tu32\t\t\t\t\tdef_command1_reg;\n\tu32\t\t\t\t\tdef_command2_reg;\n\tu32\t\t\t\t\tspi_cs_timing1;\n\tu32\t\t\t\t\tspi_cs_timing2;\n\tu8\t\t\t\t\tdummy_cycles;\n\n\tstruct completion\t\t\txfer_completion;\n\tstruct spi_transfer\t\t\t*curr_xfer;\n\n\tstruct dma_chan\t\t\t\t*rx_dma_chan;\n\tu32\t\t\t\t\t*rx_dma_buf;\n\tdma_addr_t\t\t\t\trx_dma_phys;\n\tstruct dma_async_tx_descriptor\t\t*rx_dma_desc;\n\n\tstruct dma_chan\t\t\t\t*tx_dma_chan;\n\tu32\t\t\t\t\t*tx_dma_buf;\n\tdma_addr_t\t\t\t\ttx_dma_phys;\n\tstruct dma_async_tx_descriptor\t\t*tx_dma_desc;\n\tconst struct tegra_qspi_soc_data\t*soc_data;\n};\n\nstatic inline u32 tegra_qspi_readl(struct tegra_qspi *tqspi, unsigned long offset)\n{\n\treturn readl(tqspi->base + offset);\n}\n\nstatic inline void tegra_qspi_writel(struct tegra_qspi *tqspi, u32 value, unsigned long offset)\n{\n\twritel(value, tqspi->base + offset);\n\n\t \n\tif (offset != QSPI_TX_FIFO)\n\t\treadl(tqspi->base + QSPI_COMMAND1);\n}\n\nstatic void tegra_qspi_mask_clear_irq(struct tegra_qspi *tqspi)\n{\n\tu32 value;\n\n\t \n\tvalue = tegra_qspi_readl(tqspi, QSPI_TRANS_STATUS);\n\ttegra_qspi_writel(tqspi, value, QSPI_TRANS_STATUS);\n\n\tvalue = tegra_qspi_readl(tqspi, QSPI_INTR_MASK);\n\tif (!(value & QSPI_INTR_RDY_MASK)) {\n\t\tvalue |= (QSPI_INTR_RDY_MASK | QSPI_INTR_RX_TX_FIFO_ERR);\n\t\ttegra_qspi_writel(tqspi, value, QSPI_INTR_MASK);\n\t}\n\n\t \n\tvalue = tegra_qspi_readl(tqspi, QSPI_FIFO_STATUS);\n\tif (value & QSPI_ERR)\n\t\ttegra_qspi_writel(tqspi, QSPI_ERR | QSPI_FIFO_ERROR, QSPI_FIFO_STATUS);\n}\n\nstatic unsigned int\ntegra_qspi_calculate_curr_xfer_param(struct tegra_qspi *tqspi, struct spi_transfer *t)\n{\n\tunsigned int max_word, max_len, total_fifo_words;\n\tunsigned int remain_len = t->len - tqspi->cur_pos;\n\tunsigned int bits_per_word = t->bits_per_word;\n\n\ttqspi->bytes_per_word = DIV_ROUND_UP(bits_per_word, 8);\n\n\t \n\n\tif ((bits_per_word == 8 || bits_per_word == 16 ||\n\t     bits_per_word == 32) && t->len > 3) {\n\t\ttqspi->is_packed = true;\n\t\ttqspi->words_per_32bit = 32 / bits_per_word;\n\t} else {\n\t\ttqspi->is_packed = false;\n\t\ttqspi->words_per_32bit = 1;\n\t}\n\n\tif (tqspi->is_packed) {\n\t\tmax_len = min(remain_len, tqspi->max_buf_size);\n\t\ttqspi->curr_dma_words = max_len / tqspi->bytes_per_word;\n\t\ttotal_fifo_words = (max_len + 3) / 4;\n\t} else {\n\t\tmax_word = (remain_len - 1) / tqspi->bytes_per_word + 1;\n\t\tmax_word = min(max_word, tqspi->max_buf_size / 4);\n\t\ttqspi->curr_dma_words = max_word;\n\t\ttotal_fifo_words = max_word;\n\t}\n\n\treturn total_fifo_words;\n}\n\nstatic unsigned int\ntegra_qspi_fill_tx_fifo_from_client_txbuf(struct tegra_qspi *tqspi, struct spi_transfer *t)\n{\n\tunsigned int written_words, fifo_words_left, count;\n\tunsigned int len, tx_empty_count, max_n_32bit, i;\n\tu8 *tx_buf = (u8 *)t->tx_buf + tqspi->cur_tx_pos;\n\tu32 fifo_status;\n\n\tfifo_status = tegra_qspi_readl(tqspi, QSPI_FIFO_STATUS);\n\ttx_empty_count = QSPI_TX_FIFO_EMPTY_COUNT(fifo_status);\n\n\tif (tqspi->is_packed) {\n\t\tfifo_words_left = tx_empty_count * tqspi->words_per_32bit;\n\t\twritten_words = min(fifo_words_left, tqspi->curr_dma_words);\n\t\tlen = written_words * tqspi->bytes_per_word;\n\t\tmax_n_32bit = DIV_ROUND_UP(len, 4);\n\t\tfor (count = 0; count < max_n_32bit; count++) {\n\t\t\tu32 x = 0;\n\n\t\t\tfor (i = 0; (i < 4) && len; i++, len--)\n\t\t\t\tx |= (u32)(*tx_buf++) << (i * 8);\n\t\t\ttegra_qspi_writel(tqspi, x, QSPI_TX_FIFO);\n\t\t}\n\n\t\ttqspi->cur_tx_pos += written_words * tqspi->bytes_per_word;\n\t} else {\n\t\tunsigned int write_bytes;\n\t\tu8 bytes_per_word = tqspi->bytes_per_word;\n\n\t\tmax_n_32bit = min(tqspi->curr_dma_words, tx_empty_count);\n\t\twritten_words = max_n_32bit;\n\t\tlen = written_words * tqspi->bytes_per_word;\n\t\tif (len > t->len - tqspi->cur_pos)\n\t\t\tlen = t->len - tqspi->cur_pos;\n\t\twrite_bytes = len;\n\t\tfor (count = 0; count < max_n_32bit; count++) {\n\t\t\tu32 x = 0;\n\n\t\t\tfor (i = 0; len && (i < bytes_per_word); i++, len--)\n\t\t\t\tx |= (u32)(*tx_buf++) << (i * 8);\n\t\t\ttegra_qspi_writel(tqspi, x, QSPI_TX_FIFO);\n\t\t}\n\n\t\ttqspi->cur_tx_pos += write_bytes;\n\t}\n\n\treturn written_words;\n}\n\nstatic unsigned int\ntegra_qspi_read_rx_fifo_to_client_rxbuf(struct tegra_qspi *tqspi, struct spi_transfer *t)\n{\n\tu8 *rx_buf = (u8 *)t->rx_buf + tqspi->cur_rx_pos;\n\tunsigned int len, rx_full_count, count, i;\n\tunsigned int read_words = 0;\n\tu32 fifo_status, x;\n\n\tfifo_status = tegra_qspi_readl(tqspi, QSPI_FIFO_STATUS);\n\trx_full_count = QSPI_RX_FIFO_FULL_COUNT(fifo_status);\n\tif (tqspi->is_packed) {\n\t\tlen = tqspi->curr_dma_words * tqspi->bytes_per_word;\n\t\tfor (count = 0; count < rx_full_count; count++) {\n\t\t\tx = tegra_qspi_readl(tqspi, QSPI_RX_FIFO);\n\n\t\t\tfor (i = 0; len && (i < 4); i++, len--)\n\t\t\t\t*rx_buf++ = (x >> i * 8) & 0xff;\n\t\t}\n\n\t\tread_words += tqspi->curr_dma_words;\n\t\ttqspi->cur_rx_pos += tqspi->curr_dma_words * tqspi->bytes_per_word;\n\t} else {\n\t\tu32 rx_mask = ((u32)1 << t->bits_per_word) - 1;\n\t\tu8 bytes_per_word = tqspi->bytes_per_word;\n\t\tunsigned int read_bytes;\n\n\t\tlen = rx_full_count * bytes_per_word;\n\t\tif (len > t->len - tqspi->cur_pos)\n\t\t\tlen = t->len - tqspi->cur_pos;\n\t\tread_bytes = len;\n\t\tfor (count = 0; count < rx_full_count; count++) {\n\t\t\tx = tegra_qspi_readl(tqspi, QSPI_RX_FIFO) & rx_mask;\n\n\t\t\tfor (i = 0; len && (i < bytes_per_word); i++, len--)\n\t\t\t\t*rx_buf++ = (x >> (i * 8)) & 0xff;\n\t\t}\n\n\t\tread_words += rx_full_count;\n\t\ttqspi->cur_rx_pos += read_bytes;\n\t}\n\n\treturn read_words;\n}\n\nstatic void\ntegra_qspi_copy_client_txbuf_to_qspi_txbuf(struct tegra_qspi *tqspi, struct spi_transfer *t)\n{\n\tdma_sync_single_for_cpu(tqspi->dev, tqspi->tx_dma_phys,\n\t\t\t\ttqspi->dma_buf_size, DMA_TO_DEVICE);\n\n\t \n\tif (tqspi->is_packed) {\n\t\ttqspi->cur_tx_pos += tqspi->curr_dma_words * tqspi->bytes_per_word;\n\t} else {\n\t\tu8 *tx_buf = (u8 *)t->tx_buf + tqspi->cur_tx_pos;\n\t\tunsigned int i, count, consume, write_bytes;\n\n\t\t \n\t\tconsume = tqspi->curr_dma_words * tqspi->bytes_per_word;\n\t\tif (consume > t->len - tqspi->cur_pos)\n\t\t\tconsume = t->len - tqspi->cur_pos;\n\t\twrite_bytes = consume;\n\t\tfor (count = 0; count < tqspi->curr_dma_words; count++) {\n\t\t\tu32 x = 0;\n\n\t\t\tfor (i = 0; consume && (i < tqspi->bytes_per_word); i++, consume--)\n\t\t\t\tx |= (u32)(*tx_buf++) << (i * 8);\n\t\t\ttqspi->tx_dma_buf[count] = x;\n\t\t}\n\n\t\ttqspi->cur_tx_pos += write_bytes;\n\t}\n\n\tdma_sync_single_for_device(tqspi->dev, tqspi->tx_dma_phys,\n\t\t\t\t   tqspi->dma_buf_size, DMA_TO_DEVICE);\n}\n\nstatic void\ntegra_qspi_copy_qspi_rxbuf_to_client_rxbuf(struct tegra_qspi *tqspi, struct spi_transfer *t)\n{\n\tdma_sync_single_for_cpu(tqspi->dev, tqspi->rx_dma_phys,\n\t\t\t\ttqspi->dma_buf_size, DMA_FROM_DEVICE);\n\n\tif (tqspi->is_packed) {\n\t\ttqspi->cur_rx_pos += tqspi->curr_dma_words * tqspi->bytes_per_word;\n\t} else {\n\t\tunsigned char *rx_buf = t->rx_buf + tqspi->cur_rx_pos;\n\t\tu32 rx_mask = ((u32)1 << t->bits_per_word) - 1;\n\t\tunsigned int i, count, consume, read_bytes;\n\n\t\t \n\t\tconsume = tqspi->curr_dma_words * tqspi->bytes_per_word;\n\t\tif (consume > t->len - tqspi->cur_pos)\n\t\t\tconsume = t->len - tqspi->cur_pos;\n\t\tread_bytes = consume;\n\t\tfor (count = 0; count < tqspi->curr_dma_words; count++) {\n\t\t\tu32 x = tqspi->rx_dma_buf[count] & rx_mask;\n\n\t\t\tfor (i = 0; consume && (i < tqspi->bytes_per_word); i++, consume--)\n\t\t\t\t*rx_buf++ = (x >> (i * 8)) & 0xff;\n\t\t}\n\n\t\ttqspi->cur_rx_pos += read_bytes;\n\t}\n\n\tdma_sync_single_for_device(tqspi->dev, tqspi->rx_dma_phys,\n\t\t\t\t   tqspi->dma_buf_size, DMA_FROM_DEVICE);\n}\n\nstatic void tegra_qspi_dma_complete(void *args)\n{\n\tstruct completion *dma_complete = args;\n\n\tcomplete(dma_complete);\n}\n\nstatic int tegra_qspi_start_tx_dma(struct tegra_qspi *tqspi, struct spi_transfer *t, int len)\n{\n\tdma_addr_t tx_dma_phys;\n\n\treinit_completion(&tqspi->tx_dma_complete);\n\n\tif (tqspi->is_packed)\n\t\ttx_dma_phys = t->tx_dma;\n\telse\n\t\ttx_dma_phys = tqspi->tx_dma_phys;\n\n\ttqspi->tx_dma_desc = dmaengine_prep_slave_single(tqspi->tx_dma_chan, tx_dma_phys,\n\t\t\t\t\t\t\t len, DMA_MEM_TO_DEV,\n\t\t\t\t\t\t\t DMA_PREP_INTERRUPT |  DMA_CTRL_ACK);\n\n\tif (!tqspi->tx_dma_desc) {\n\t\tdev_err(tqspi->dev, \"Unable to get TX descriptor\\n\");\n\t\treturn -EIO;\n\t}\n\n\ttqspi->tx_dma_desc->callback = tegra_qspi_dma_complete;\n\ttqspi->tx_dma_desc->callback_param = &tqspi->tx_dma_complete;\n\tdmaengine_submit(tqspi->tx_dma_desc);\n\tdma_async_issue_pending(tqspi->tx_dma_chan);\n\n\treturn 0;\n}\n\nstatic int tegra_qspi_start_rx_dma(struct tegra_qspi *tqspi, struct spi_transfer *t, int len)\n{\n\tdma_addr_t rx_dma_phys;\n\n\treinit_completion(&tqspi->rx_dma_complete);\n\n\tif (tqspi->is_packed)\n\t\trx_dma_phys = t->rx_dma;\n\telse\n\t\trx_dma_phys = tqspi->rx_dma_phys;\n\n\ttqspi->rx_dma_desc = dmaengine_prep_slave_single(tqspi->rx_dma_chan, rx_dma_phys,\n\t\t\t\t\t\t\t len, DMA_DEV_TO_MEM,\n\t\t\t\t\t\t\t DMA_PREP_INTERRUPT |  DMA_CTRL_ACK);\n\n\tif (!tqspi->rx_dma_desc) {\n\t\tdev_err(tqspi->dev, \"Unable to get RX descriptor\\n\");\n\t\treturn -EIO;\n\t}\n\n\ttqspi->rx_dma_desc->callback = tegra_qspi_dma_complete;\n\ttqspi->rx_dma_desc->callback_param = &tqspi->rx_dma_complete;\n\tdmaengine_submit(tqspi->rx_dma_desc);\n\tdma_async_issue_pending(tqspi->rx_dma_chan);\n\n\treturn 0;\n}\n\nstatic int tegra_qspi_flush_fifos(struct tegra_qspi *tqspi, bool atomic)\n{\n\tvoid __iomem *addr = tqspi->base + QSPI_FIFO_STATUS;\n\tu32 val;\n\n\tval = tegra_qspi_readl(tqspi, QSPI_FIFO_STATUS);\n\tif ((val & QSPI_FIFO_EMPTY) == QSPI_FIFO_EMPTY)\n\t\treturn 0;\n\n\tval |= QSPI_RX_FIFO_FLUSH | QSPI_TX_FIFO_FLUSH;\n\ttegra_qspi_writel(tqspi, val, QSPI_FIFO_STATUS);\n\n\tif (!atomic)\n\t\treturn readl_relaxed_poll_timeout(addr, val,\n\t\t\t\t\t\t  (val & QSPI_FIFO_EMPTY) == QSPI_FIFO_EMPTY,\n\t\t\t\t\t\t  1000, 1000000);\n\n\treturn readl_relaxed_poll_timeout_atomic(addr, val,\n\t\t\t\t\t\t (val & QSPI_FIFO_EMPTY) == QSPI_FIFO_EMPTY,\n\t\t\t\t\t\t 1000, 1000000);\n}\n\nstatic void tegra_qspi_unmask_irq(struct tegra_qspi *tqspi)\n{\n\tu32 intr_mask;\n\n\tintr_mask = tegra_qspi_readl(tqspi, QSPI_INTR_MASK);\n\tintr_mask &= ~(QSPI_INTR_RDY_MASK | QSPI_INTR_RX_TX_FIFO_ERR);\n\ttegra_qspi_writel(tqspi, intr_mask, QSPI_INTR_MASK);\n}\n\nstatic int tegra_qspi_dma_map_xfer(struct tegra_qspi *tqspi, struct spi_transfer *t)\n{\n\tu8 *tx_buf = (u8 *)t->tx_buf + tqspi->cur_tx_pos;\n\tu8 *rx_buf = (u8 *)t->rx_buf + tqspi->cur_rx_pos;\n\tunsigned int len;\n\n\tlen = DIV_ROUND_UP(tqspi->curr_dma_words * tqspi->bytes_per_word, 4) * 4;\n\n\tif (t->tx_buf) {\n\t\tt->tx_dma = dma_map_single(tqspi->dev, (void *)tx_buf, len, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(tqspi->dev, t->tx_dma))\n\t\t\treturn -ENOMEM;\n\t}\n\n\tif (t->rx_buf) {\n\t\tt->rx_dma = dma_map_single(tqspi->dev, (void *)rx_buf, len, DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(tqspi->dev, t->rx_dma)) {\n\t\t\tdma_unmap_single(tqspi->dev, t->tx_dma, len, DMA_TO_DEVICE);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void tegra_qspi_dma_unmap_xfer(struct tegra_qspi *tqspi, struct spi_transfer *t)\n{\n\tunsigned int len;\n\n\tlen = DIV_ROUND_UP(tqspi->curr_dma_words * tqspi->bytes_per_word, 4) * 4;\n\n\tdma_unmap_single(tqspi->dev, t->tx_dma, len, DMA_TO_DEVICE);\n\tdma_unmap_single(tqspi->dev, t->rx_dma, len, DMA_FROM_DEVICE);\n}\n\nstatic int tegra_qspi_start_dma_based_transfer(struct tegra_qspi *tqspi, struct spi_transfer *t)\n{\n\tstruct dma_slave_config dma_sconfig = { 0 };\n\tunsigned int len;\n\tu8 dma_burst;\n\tint ret = 0;\n\tu32 val;\n\n\tif (tqspi->is_packed) {\n\t\tret = tegra_qspi_dma_map_xfer(tqspi, t);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tval = QSPI_DMA_BLK_SET(tqspi->curr_dma_words - 1);\n\ttegra_qspi_writel(tqspi, val, QSPI_DMA_BLK);\n\n\ttegra_qspi_unmask_irq(tqspi);\n\n\tif (tqspi->is_packed)\n\t\tlen = DIV_ROUND_UP(tqspi->curr_dma_words * tqspi->bytes_per_word, 4) * 4;\n\telse\n\t\tlen = tqspi->curr_dma_words * 4;\n\n\t \n\tval = 0;\n\tif (len & 0xf) {\n\t\tval |= QSPI_TX_TRIG_1 | QSPI_RX_TRIG_1;\n\t\tdma_burst = 1;\n\t} else if (((len) >> 4) & 0x1) {\n\t\tval |= QSPI_TX_TRIG_4 | QSPI_RX_TRIG_4;\n\t\tdma_burst = 4;\n\t} else {\n\t\tval |= QSPI_TX_TRIG_8 | QSPI_RX_TRIG_8;\n\t\tdma_burst = 8;\n\t}\n\n\ttegra_qspi_writel(tqspi, val, QSPI_DMA_CTL);\n\ttqspi->dma_control_reg = val;\n\n\tdma_sconfig.device_fc = true;\n\tif (tqspi->cur_direction & DATA_DIR_TX) {\n\t\tdma_sconfig.dst_addr = tqspi->phys + QSPI_TX_FIFO;\n\t\tdma_sconfig.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\t\tdma_sconfig.dst_maxburst = dma_burst;\n\t\tret = dmaengine_slave_config(tqspi->tx_dma_chan, &dma_sconfig);\n\t\tif (ret < 0) {\n\t\t\tdev_err(tqspi->dev, \"failed DMA slave config: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\ttegra_qspi_copy_client_txbuf_to_qspi_txbuf(tqspi, t);\n\t\tret = tegra_qspi_start_tx_dma(tqspi, t, len);\n\t\tif (ret < 0) {\n\t\t\tdev_err(tqspi->dev, \"failed to starting TX DMA: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (tqspi->cur_direction & DATA_DIR_RX) {\n\t\tdma_sconfig.src_addr = tqspi->phys + QSPI_RX_FIFO;\n\t\tdma_sconfig.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\t\tdma_sconfig.src_maxburst = dma_burst;\n\t\tret = dmaengine_slave_config(tqspi->rx_dma_chan, &dma_sconfig);\n\t\tif (ret < 0) {\n\t\t\tdev_err(tqspi->dev, \"failed DMA slave config: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tdma_sync_single_for_device(tqspi->dev, tqspi->rx_dma_phys,\n\t\t\t\t\t   tqspi->dma_buf_size,\n\t\t\t\t\t   DMA_FROM_DEVICE);\n\n\t\tret = tegra_qspi_start_rx_dma(tqspi, t, len);\n\t\tif (ret < 0) {\n\t\t\tdev_err(tqspi->dev, \"failed to start RX DMA: %d\\n\", ret);\n\t\t\tif (tqspi->cur_direction & DATA_DIR_TX)\n\t\t\t\tdmaengine_terminate_all(tqspi->tx_dma_chan);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\ttegra_qspi_writel(tqspi, tqspi->command1_reg, QSPI_COMMAND1);\n\n\ttqspi->is_curr_dma_xfer = true;\n\ttqspi->dma_control_reg = val;\n\tval |= QSPI_DMA_EN;\n\ttegra_qspi_writel(tqspi, val, QSPI_DMA_CTL);\n\n\treturn ret;\n}\n\nstatic int tegra_qspi_start_cpu_based_transfer(struct tegra_qspi *qspi, struct spi_transfer *t)\n{\n\tu32 val;\n\tunsigned int cur_words;\n\n\tif (qspi->cur_direction & DATA_DIR_TX)\n\t\tcur_words = tegra_qspi_fill_tx_fifo_from_client_txbuf(qspi, t);\n\telse\n\t\tcur_words = qspi->curr_dma_words;\n\n\tval = QSPI_DMA_BLK_SET(cur_words - 1);\n\ttegra_qspi_writel(qspi, val, QSPI_DMA_BLK);\n\n\ttegra_qspi_unmask_irq(qspi);\n\n\tqspi->is_curr_dma_xfer = false;\n\tval = qspi->command1_reg;\n\tval |= QSPI_PIO;\n\ttegra_qspi_writel(qspi, val, QSPI_COMMAND1);\n\n\treturn 0;\n}\n\nstatic void tegra_qspi_deinit_dma(struct tegra_qspi *tqspi)\n{\n\tif (!tqspi->soc_data->has_dma)\n\t\treturn;\n\n\tif (tqspi->tx_dma_buf) {\n\t\tdma_free_coherent(tqspi->dev, tqspi->dma_buf_size,\n\t\t\t\t  tqspi->tx_dma_buf, tqspi->tx_dma_phys);\n\t\ttqspi->tx_dma_buf = NULL;\n\t}\n\n\tif (tqspi->tx_dma_chan) {\n\t\tdma_release_channel(tqspi->tx_dma_chan);\n\t\ttqspi->tx_dma_chan = NULL;\n\t}\n\n\tif (tqspi->rx_dma_buf) {\n\t\tdma_free_coherent(tqspi->dev, tqspi->dma_buf_size,\n\t\t\t\t  tqspi->rx_dma_buf, tqspi->rx_dma_phys);\n\t\ttqspi->rx_dma_buf = NULL;\n\t}\n\n\tif (tqspi->rx_dma_chan) {\n\t\tdma_release_channel(tqspi->rx_dma_chan);\n\t\ttqspi->rx_dma_chan = NULL;\n\t}\n}\n\nstatic int tegra_qspi_init_dma(struct tegra_qspi *tqspi)\n{\n\tstruct dma_chan *dma_chan;\n\tdma_addr_t dma_phys;\n\tu32 *dma_buf;\n\tint err;\n\n\tif (!tqspi->soc_data->has_dma)\n\t\treturn 0;\n\n\tdma_chan = dma_request_chan(tqspi->dev, \"rx\");\n\tif (IS_ERR(dma_chan)) {\n\t\terr = PTR_ERR(dma_chan);\n\t\tgoto err_out;\n\t}\n\n\ttqspi->rx_dma_chan = dma_chan;\n\n\tdma_buf = dma_alloc_coherent(tqspi->dev, tqspi->dma_buf_size, &dma_phys, GFP_KERNEL);\n\tif (!dma_buf) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\ttqspi->rx_dma_buf = dma_buf;\n\ttqspi->rx_dma_phys = dma_phys;\n\n\tdma_chan = dma_request_chan(tqspi->dev, \"tx\");\n\tif (IS_ERR(dma_chan)) {\n\t\terr = PTR_ERR(dma_chan);\n\t\tgoto err_out;\n\t}\n\n\ttqspi->tx_dma_chan = dma_chan;\n\n\tdma_buf = dma_alloc_coherent(tqspi->dev, tqspi->dma_buf_size, &dma_phys, GFP_KERNEL);\n\tif (!dma_buf) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\ttqspi->tx_dma_buf = dma_buf;\n\ttqspi->tx_dma_phys = dma_phys;\n\ttqspi->use_dma = true;\n\n\treturn 0;\n\nerr_out:\n\ttegra_qspi_deinit_dma(tqspi);\n\n\tif (err != -EPROBE_DEFER) {\n\t\tdev_err(tqspi->dev, \"cannot use DMA: %d\\n\", err);\n\t\tdev_err(tqspi->dev, \"falling back to PIO\\n\");\n\t\treturn 0;\n\t}\n\n\treturn err;\n}\n\nstatic u32 tegra_qspi_setup_transfer_one(struct spi_device *spi, struct spi_transfer *t,\n\t\t\t\t\t bool is_first_of_msg)\n{\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(spi->master);\n\tstruct tegra_qspi_client_data *cdata = spi->controller_data;\n\tu32 command1, command2, speed = t->speed_hz;\n\tu8 bits_per_word = t->bits_per_word;\n\tu32 tx_tap = 0, rx_tap = 0;\n\tint req_mode;\n\n\tif (!has_acpi_companion(tqspi->dev) && speed != tqspi->cur_speed) {\n\t\tclk_set_rate(tqspi->clk, speed);\n\t\ttqspi->cur_speed = speed;\n\t}\n\n\ttqspi->cur_pos = 0;\n\ttqspi->cur_rx_pos = 0;\n\ttqspi->cur_tx_pos = 0;\n\ttqspi->curr_xfer = t;\n\n\tif (is_first_of_msg) {\n\t\ttegra_qspi_mask_clear_irq(tqspi);\n\n\t\tcommand1 = tqspi->def_command1_reg;\n\t\tcommand1 |= QSPI_CS_SEL(spi_get_chipselect(spi, 0));\n\t\tcommand1 |= QSPI_BIT_LENGTH(bits_per_word - 1);\n\n\t\tcommand1 &= ~QSPI_CONTROL_MODE_MASK;\n\t\treq_mode = spi->mode & 0x3;\n\t\tif (req_mode == SPI_MODE_3)\n\t\t\tcommand1 |= QSPI_CONTROL_MODE_3;\n\t\telse\n\t\t\tcommand1 |= QSPI_CONTROL_MODE_0;\n\n\t\tif (spi->mode & SPI_CS_HIGH)\n\t\t\tcommand1 |= QSPI_CS_SW_VAL;\n\t\telse\n\t\t\tcommand1 &= ~QSPI_CS_SW_VAL;\n\t\ttegra_qspi_writel(tqspi, command1, QSPI_COMMAND1);\n\n\t\tif (cdata && cdata->tx_clk_tap_delay)\n\t\t\ttx_tap = cdata->tx_clk_tap_delay;\n\n\t\tif (cdata && cdata->rx_clk_tap_delay)\n\t\t\trx_tap = cdata->rx_clk_tap_delay;\n\n\t\tcommand2 = QSPI_TX_TAP_DELAY(tx_tap) | QSPI_RX_TAP_DELAY(rx_tap);\n\t\tif (command2 != tqspi->def_command2_reg)\n\t\t\ttegra_qspi_writel(tqspi, command2, QSPI_COMMAND2);\n\n\t} else {\n\t\tcommand1 = tqspi->command1_reg;\n\t\tcommand1 &= ~QSPI_BIT_LENGTH(~0);\n\t\tcommand1 |= QSPI_BIT_LENGTH(bits_per_word - 1);\n\t}\n\n\tcommand1 &= ~QSPI_SDR_DDR_SEL;\n\n\treturn command1;\n}\n\nstatic int tegra_qspi_start_transfer_one(struct spi_device *spi,\n\t\t\t\t\t struct spi_transfer *t, u32 command1)\n{\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(spi->master);\n\tunsigned int total_fifo_words;\n\tu8 bus_width = 0;\n\tint ret;\n\n\ttotal_fifo_words = tegra_qspi_calculate_curr_xfer_param(tqspi, t);\n\n\tcommand1 &= ~QSPI_PACKED;\n\tif (tqspi->is_packed)\n\t\tcommand1 |= QSPI_PACKED;\n\ttegra_qspi_writel(tqspi, command1, QSPI_COMMAND1);\n\n\ttqspi->cur_direction = 0;\n\n\tcommand1 &= ~(QSPI_TX_EN | QSPI_RX_EN);\n\tif (t->rx_buf) {\n\t\tcommand1 |= QSPI_RX_EN;\n\t\ttqspi->cur_direction |= DATA_DIR_RX;\n\t\tbus_width = t->rx_nbits;\n\t}\n\n\tif (t->tx_buf) {\n\t\tcommand1 |= QSPI_TX_EN;\n\t\ttqspi->cur_direction |= DATA_DIR_TX;\n\t\tbus_width = t->tx_nbits;\n\t}\n\n\tcommand1 &= ~QSPI_INTERFACE_WIDTH_MASK;\n\n\tif (bus_width == SPI_NBITS_QUAD)\n\t\tcommand1 |= QSPI_INTERFACE_WIDTH_QUAD;\n\telse if (bus_width == SPI_NBITS_DUAL)\n\t\tcommand1 |= QSPI_INTERFACE_WIDTH_DUAL;\n\telse\n\t\tcommand1 |= QSPI_INTERFACE_WIDTH_SINGLE;\n\n\ttqspi->command1_reg = command1;\n\n\ttegra_qspi_writel(tqspi, QSPI_NUM_DUMMY_CYCLE(tqspi->dummy_cycles), QSPI_MISC_REG);\n\n\tret = tegra_qspi_flush_fifos(tqspi, false);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (tqspi->use_dma && total_fifo_words > QSPI_FIFO_DEPTH)\n\t\tret = tegra_qspi_start_dma_based_transfer(tqspi, t);\n\telse\n\t\tret = tegra_qspi_start_cpu_based_transfer(tqspi, t);\n\n\treturn ret;\n}\n\nstatic struct tegra_qspi_client_data *tegra_qspi_parse_cdata_dt(struct spi_device *spi)\n{\n\tstruct tegra_qspi_client_data *cdata;\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(spi->master);\n\n\tcdata = devm_kzalloc(tqspi->dev, sizeof(*cdata), GFP_KERNEL);\n\tif (!cdata)\n\t\treturn NULL;\n\n\tdevice_property_read_u32(&spi->dev, \"nvidia,tx-clk-tap-delay\",\n\t\t\t\t &cdata->tx_clk_tap_delay);\n\tdevice_property_read_u32(&spi->dev, \"nvidia,rx-clk-tap-delay\",\n\t\t\t\t &cdata->rx_clk_tap_delay);\n\n\treturn cdata;\n}\n\nstatic int tegra_qspi_setup(struct spi_device *spi)\n{\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(spi->master);\n\tstruct tegra_qspi_client_data *cdata = spi->controller_data;\n\tunsigned long flags;\n\tu32 val;\n\tint ret;\n\n\tret = pm_runtime_resume_and_get(tqspi->dev);\n\tif (ret < 0) {\n\t\tdev_err(tqspi->dev, \"failed to get runtime PM: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (!cdata) {\n\t\tcdata = tegra_qspi_parse_cdata_dt(spi);\n\t\tspi->controller_data = cdata;\n\t}\n\tspin_lock_irqsave(&tqspi->lock, flags);\n\n\t \n\tval = tqspi->def_command1_reg;\n\tval |= QSPI_CS_SEL(spi_get_chipselect(spi, 0));\n\tif (spi->mode & SPI_CS_HIGH)\n\t\tval &= ~QSPI_CS_POL_INACTIVE(spi_get_chipselect(spi, 0));\n\telse\n\t\tval |= QSPI_CS_POL_INACTIVE(spi_get_chipselect(spi, 0));\n\n\ttqspi->def_command1_reg = val;\n\ttegra_qspi_writel(tqspi, tqspi->def_command1_reg, QSPI_COMMAND1);\n\n\tspin_unlock_irqrestore(&tqspi->lock, flags);\n\n\tpm_runtime_put(tqspi->dev);\n\n\treturn 0;\n}\n\nstatic void tegra_qspi_dump_regs(struct tegra_qspi *tqspi)\n{\n\tdev_dbg(tqspi->dev, \"============ QSPI REGISTER DUMP ============\\n\");\n\tdev_dbg(tqspi->dev, \"Command1:    0x%08x | Command2:    0x%08x\\n\",\n\t\ttegra_qspi_readl(tqspi, QSPI_COMMAND1),\n\t\ttegra_qspi_readl(tqspi, QSPI_COMMAND2));\n\tdev_dbg(tqspi->dev, \"DMA_CTL:     0x%08x | DMA_BLK:     0x%08x\\n\",\n\t\ttegra_qspi_readl(tqspi, QSPI_DMA_CTL),\n\t\ttegra_qspi_readl(tqspi, QSPI_DMA_BLK));\n\tdev_dbg(tqspi->dev, \"INTR_MASK:  0x%08x | MISC: 0x%08x\\n\",\n\t\ttegra_qspi_readl(tqspi, QSPI_INTR_MASK),\n\t\ttegra_qspi_readl(tqspi, QSPI_MISC_REG));\n\tdev_dbg(tqspi->dev, \"TRANS_STAT:  0x%08x | FIFO_STATUS: 0x%08x\\n\",\n\t\ttegra_qspi_readl(tqspi, QSPI_TRANS_STATUS),\n\t\ttegra_qspi_readl(tqspi, QSPI_FIFO_STATUS));\n}\n\nstatic void tegra_qspi_handle_error(struct tegra_qspi *tqspi)\n{\n\tdev_err(tqspi->dev, \"error in transfer, fifo status 0x%08x\\n\", tqspi->status_reg);\n\ttegra_qspi_dump_regs(tqspi);\n\ttegra_qspi_flush_fifos(tqspi, true);\n\tif (device_reset(tqspi->dev) < 0)\n\t\tdev_warn_once(tqspi->dev, \"device reset failed\\n\");\n}\n\nstatic void tegra_qspi_transfer_end(struct spi_device *spi)\n{\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(spi->master);\n\tint cs_val = (spi->mode & SPI_CS_HIGH) ? 0 : 1;\n\n\tif (cs_val)\n\t\ttqspi->command1_reg |= QSPI_CS_SW_VAL;\n\telse\n\t\ttqspi->command1_reg &= ~QSPI_CS_SW_VAL;\n\ttegra_qspi_writel(tqspi, tqspi->command1_reg, QSPI_COMMAND1);\n\ttegra_qspi_writel(tqspi, tqspi->def_command1_reg, QSPI_COMMAND1);\n}\n\nstatic u32 tegra_qspi_cmd_config(bool is_ddr, u8 bus_width, u8 len)\n{\n\tu32 cmd_config = 0;\n\n\t \n\tif (is_ddr)\n\t\tcmd_config |= QSPI_COMMAND_SDR_DDR;\n\telse\n\t\tcmd_config &= ~QSPI_COMMAND_SDR_DDR;\n\n\tcmd_config |= QSPI_COMMAND_X1_X2_X4(bus_width);\n\tcmd_config |= QSPI_COMMAND_SIZE_SET((len * 8) - 1);\n\n\treturn cmd_config;\n}\n\nstatic u32 tegra_qspi_addr_config(bool is_ddr, u8 bus_width, u8 len)\n{\n\tu32 addr_config = 0;\n\n\t \n\tis_ddr = 0; \n\tbus_width = 0; \n\n\tif (is_ddr)\n\t\taddr_config |= QSPI_ADDRESS_SDR_DDR;\n\telse\n\t\taddr_config &= ~QSPI_ADDRESS_SDR_DDR;\n\n\taddr_config |= QSPI_ADDRESS_X1_X2_X4(bus_width);\n\taddr_config |= QSPI_ADDRESS_SIZE_SET((len * 8) - 1);\n\n\treturn addr_config;\n}\n\nstatic int tegra_qspi_combined_seq_xfer(struct tegra_qspi *tqspi,\n\t\t\t\t\tstruct spi_message *msg)\n{\n\tbool is_first_msg = true;\n\tstruct spi_transfer *xfer;\n\tstruct spi_device *spi = msg->spi;\n\tu8 transfer_phase = 0;\n\tu32 cmd1 = 0, dma_ctl = 0;\n\tint ret = 0;\n\tu32 address_value = 0;\n\tu32 cmd_config = 0, addr_config = 0;\n\tu8 cmd_value = 0, val = 0;\n\n\t \n\tval = tegra_qspi_readl(tqspi, QSPI_GLOBAL_CONFIG);\n\tif (spi->mode & SPI_TPM_HW_FLOW) {\n\t\tif (tqspi->soc_data->supports_tpm)\n\t\t\tval |= QSPI_TPM_WAIT_POLL_EN;\n\t\telse\n\t\t\treturn -EIO;\n\t}\n\tval |= QSPI_CMB_SEQ_EN;\n\ttegra_qspi_writel(tqspi, val, QSPI_GLOBAL_CONFIG);\n\t \n\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\tswitch (transfer_phase) {\n\t\tcase CMD_TRANSFER:\n\t\t\t \n\t\t\tcmd_config = tegra_qspi_cmd_config(false, 0,\n\t\t\t\t\t\t\t   xfer->len);\n\t\t\tcmd_value = *((const u8 *)(xfer->tx_buf));\n\t\t\tbreak;\n\t\tcase ADDR_TRANSFER:\n\t\t\t \n\t\t\taddr_config = tegra_qspi_addr_config(false, 0,\n\t\t\t\t\t\t\t     xfer->len);\n\t\t\taddress_value = *((const u32 *)(xfer->tx_buf));\n\t\t\tbreak;\n\t\tcase DATA_TRANSFER:\n\t\t\t \n\t\t\ttegra_qspi_writel(tqspi, cmd_value, QSPI_CMB_SEQ_CMD);\n\t\t\ttegra_qspi_writel(tqspi, address_value,\n\t\t\t\t\t  QSPI_CMB_SEQ_ADDR);\n\t\t\t \n\t\t\ttegra_qspi_writel(tqspi, cmd_config,\n\t\t\t\t\t  QSPI_CMB_SEQ_CMD_CFG);\n\t\t\ttegra_qspi_writel(tqspi, addr_config,\n\t\t\t\t\t  QSPI_CMB_SEQ_ADDR_CFG);\n\n\t\t\treinit_completion(&tqspi->xfer_completion);\n\t\t\tcmd1 = tegra_qspi_setup_transfer_one(spi, xfer,\n\t\t\t\t\t\t\t     is_first_msg);\n\t\t\tret = tegra_qspi_start_transfer_one(spi, xfer,\n\t\t\t\t\t\t\t    cmd1);\n\n\t\t\tif (ret < 0) {\n\t\t\t\tdev_err(tqspi->dev, \"Failed to start transfer-one: %d\\n\",\n\t\t\t\t\tret);\n\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tis_first_msg = false;\n\t\t\tret = wait_for_completion_timeout\n\t\t\t\t\t(&tqspi->xfer_completion,\n\t\t\t\t\tQSPI_DMA_TIMEOUT);\n\n\t\t\tif (WARN_ON(ret == 0)) {\n\t\t\t\tdev_err(tqspi->dev, \"QSPI Transfer failed with timeout: %d\\n\",\n\t\t\t\t\tret);\n\t\t\t\tif (tqspi->is_curr_dma_xfer &&\n\t\t\t\t    (tqspi->cur_direction & DATA_DIR_TX))\n\t\t\t\t\tdmaengine_terminate_all\n\t\t\t\t\t\t(tqspi->tx_dma_chan);\n\n\t\t\t\tif (tqspi->is_curr_dma_xfer &&\n\t\t\t\t    (tqspi->cur_direction & DATA_DIR_RX))\n\t\t\t\t\tdmaengine_terminate_all\n\t\t\t\t\t\t(tqspi->rx_dma_chan);\n\n\t\t\t\t \n\t\t\t\tif (!tqspi->is_curr_dma_xfer) {\n\t\t\t\t\tcmd1 = tegra_qspi_readl\n\t\t\t\t\t\t\t(tqspi,\n\t\t\t\t\t\t\t QSPI_COMMAND1);\n\t\t\t\t\tcmd1 &= ~QSPI_PIO;\n\t\t\t\t\ttegra_qspi_writel\n\t\t\t\t\t\t\t(tqspi, cmd1,\n\t\t\t\t\t\t\t QSPI_COMMAND1);\n\t\t\t\t} else {\n\t\t\t\t\tdma_ctl = tegra_qspi_readl\n\t\t\t\t\t\t\t(tqspi,\n\t\t\t\t\t\t\t QSPI_DMA_CTL);\n\t\t\t\t\tdma_ctl &= ~QSPI_DMA_EN;\n\t\t\t\t\ttegra_qspi_writel(tqspi, dma_ctl,\n\t\t\t\t\t\t\t  QSPI_DMA_CTL);\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tif (device_reset(tqspi->dev) < 0)\n\t\t\t\t\tdev_warn_once(tqspi->dev,\n\t\t\t\t\t\t      \"device reset failed\\n\");\n\t\t\t\tret = -EIO;\n\t\t\t\tgoto exit;\n\t\t\t}\n\n\t\t\tif (tqspi->tx_status ||  tqspi->rx_status) {\n\t\t\t\tdev_err(tqspi->dev, \"QSPI Transfer failed\\n\");\n\t\t\t\ttqspi->tx_status = 0;\n\t\t\t\ttqspi->rx_status = 0;\n\t\t\t\tret = -EIO;\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t\tif (!xfer->cs_change) {\n\t\t\t\ttegra_qspi_transfer_end(spi);\n\t\t\t\tspi_transfer_delay_exec(xfer);\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tgoto exit;\n\t\t}\n\t\tmsg->actual_length += xfer->len;\n\t\ttransfer_phase++;\n\t}\n\tret = 0;\n\nexit:\n\tmsg->status = ret;\n\tif (ret < 0) {\n\t\ttegra_qspi_transfer_end(spi);\n\t\tspi_transfer_delay_exec(xfer);\n\t}\n\n\treturn ret;\n}\n\nstatic int tegra_qspi_non_combined_seq_xfer(struct tegra_qspi *tqspi,\n\t\t\t\t\t    struct spi_message *msg)\n{\n\tstruct spi_device *spi = msg->spi;\n\tstruct spi_transfer *transfer;\n\tbool is_first_msg = true;\n\tint ret = 0, val = 0;\n\n\tmsg->status = 0;\n\tmsg->actual_length = 0;\n\ttqspi->tx_status = 0;\n\ttqspi->rx_status = 0;\n\n\t \n\tval = tegra_qspi_readl(tqspi, QSPI_GLOBAL_CONFIG);\n\tval &= ~QSPI_CMB_SEQ_EN;\n\tif (tqspi->soc_data->supports_tpm)\n\t\tval &= ~QSPI_TPM_WAIT_POLL_EN;\n\ttegra_qspi_writel(tqspi, val, QSPI_GLOBAL_CONFIG);\n\tlist_for_each_entry(transfer, &msg->transfers, transfer_list) {\n\t\tstruct spi_transfer *xfer = transfer;\n\t\tu8 dummy_bytes = 0;\n\t\tu32 cmd1;\n\n\t\ttqspi->dummy_cycles = 0;\n\t\t \n\t\tif (!list_is_last(&xfer->transfer_list, &msg->transfers)) {\n\t\t\tstruct spi_transfer *next_xfer;\n\n\t\t\tnext_xfer = list_next_entry(xfer, transfer_list);\n\t\t\tif (next_xfer->dummy_data) {\n\t\t\t\tu32 dummy_cycles = next_xfer->len * 8 / next_xfer->tx_nbits;\n\n\t\t\t\tif (dummy_cycles <= QSPI_DUMMY_CYCLES_MAX) {\n\t\t\t\t\ttqspi->dummy_cycles = dummy_cycles;\n\t\t\t\t\tdummy_bytes = next_xfer->len;\n\t\t\t\t\ttransfer = next_xfer;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treinit_completion(&tqspi->xfer_completion);\n\n\t\tcmd1 = tegra_qspi_setup_transfer_one(spi, xfer, is_first_msg);\n\n\t\tret = tegra_qspi_start_transfer_one(spi, xfer, cmd1);\n\t\tif (ret < 0) {\n\t\t\tdev_err(tqspi->dev, \"failed to start transfer: %d\\n\", ret);\n\t\t\tgoto complete_xfer;\n\t\t}\n\n\t\tret = wait_for_completion_timeout(&tqspi->xfer_completion,\n\t\t\t\t\t\t  QSPI_DMA_TIMEOUT);\n\t\tif (WARN_ON(ret == 0)) {\n\t\t\tdev_err(tqspi->dev, \"transfer timeout\\n\");\n\t\t\tif (tqspi->is_curr_dma_xfer && (tqspi->cur_direction & DATA_DIR_TX))\n\t\t\t\tdmaengine_terminate_all(tqspi->tx_dma_chan);\n\t\t\tif (tqspi->is_curr_dma_xfer && (tqspi->cur_direction & DATA_DIR_RX))\n\t\t\t\tdmaengine_terminate_all(tqspi->rx_dma_chan);\n\t\t\ttegra_qspi_handle_error(tqspi);\n\t\t\tret = -EIO;\n\t\t\tgoto complete_xfer;\n\t\t}\n\n\t\tif (tqspi->tx_status ||  tqspi->rx_status) {\n\t\t\ttegra_qspi_handle_error(tqspi);\n\t\t\tret = -EIO;\n\t\t\tgoto complete_xfer;\n\t\t}\n\n\t\tmsg->actual_length += xfer->len + dummy_bytes;\n\ncomplete_xfer:\n\t\tif (ret < 0) {\n\t\t\ttegra_qspi_transfer_end(spi);\n\t\t\tspi_transfer_delay_exec(xfer);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (list_is_last(&xfer->transfer_list, &msg->transfers)) {\n\t\t\t \n\t\t\tif (!xfer->cs_change) {\n\t\t\t\ttegra_qspi_transfer_end(spi);\n\t\t\t\tspi_transfer_delay_exec(xfer);\n\t\t\t}\n\t\t} else if (xfer->cs_change) {\n\t\t\t  \n\t\t\ttegra_qspi_transfer_end(spi);\n\t\t\tspi_transfer_delay_exec(xfer);\n\t\t}\n\t}\n\n\tret = 0;\nexit:\n\tmsg->status = ret;\n\n\treturn ret;\n}\n\nstatic bool tegra_qspi_validate_cmb_seq(struct tegra_qspi *tqspi,\n\t\t\t\t\tstruct spi_message *msg)\n{\n\tint transfer_count = 0;\n\tstruct spi_transfer *xfer;\n\n\tlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\n\t\ttransfer_count++;\n\t}\n\tif (!tqspi->soc_data->cmb_xfer_capable || transfer_count != 3)\n\t\treturn false;\n\txfer = list_first_entry(&msg->transfers, typeof(*xfer),\n\t\t\t\ttransfer_list);\n\tif (xfer->len > 2)\n\t\treturn false;\n\txfer = list_next_entry(xfer, transfer_list);\n\tif (xfer->len > 4 || xfer->len < 3)\n\t\treturn false;\n\txfer = list_next_entry(xfer, transfer_list);\n\tif (!tqspi->soc_data->has_dma && xfer->len > (QSPI_FIFO_DEPTH << 2))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int tegra_qspi_transfer_one_message(struct spi_master *master,\n\t\t\t\t\t   struct spi_message *msg)\n{\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(master);\n\tint ret;\n\n\tif (tegra_qspi_validate_cmb_seq(tqspi, msg))\n\t\tret = tegra_qspi_combined_seq_xfer(tqspi, msg);\n\telse\n\t\tret = tegra_qspi_non_combined_seq_xfer(tqspi, msg);\n\n\tspi_finalize_current_message(master);\n\n\treturn ret;\n}\n\nstatic irqreturn_t handle_cpu_based_xfer(struct tegra_qspi *tqspi)\n{\n\tstruct spi_transfer *t = tqspi->curr_xfer;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&tqspi->lock, flags);\n\n\tif (tqspi->tx_status ||  tqspi->rx_status) {\n\t\ttegra_qspi_handle_error(tqspi);\n\t\tcomplete(&tqspi->xfer_completion);\n\t\tgoto exit;\n\t}\n\n\tif (tqspi->cur_direction & DATA_DIR_RX)\n\t\ttegra_qspi_read_rx_fifo_to_client_rxbuf(tqspi, t);\n\n\tif (tqspi->cur_direction & DATA_DIR_TX)\n\t\ttqspi->cur_pos = tqspi->cur_tx_pos;\n\telse\n\t\ttqspi->cur_pos = tqspi->cur_rx_pos;\n\n\tif (tqspi->cur_pos == t->len) {\n\t\tcomplete(&tqspi->xfer_completion);\n\t\tgoto exit;\n\t}\n\n\ttegra_qspi_calculate_curr_xfer_param(tqspi, t);\n\ttegra_qspi_start_cpu_based_transfer(tqspi, t);\nexit:\n\tspin_unlock_irqrestore(&tqspi->lock, flags);\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t handle_dma_based_xfer(struct tegra_qspi *tqspi)\n{\n\tstruct spi_transfer *t = tqspi->curr_xfer;\n\tunsigned int total_fifo_words;\n\tunsigned long flags;\n\tlong wait_status;\n\tint err = 0;\n\n\tif (tqspi->cur_direction & DATA_DIR_TX) {\n\t\tif (tqspi->tx_status) {\n\t\t\tdmaengine_terminate_all(tqspi->tx_dma_chan);\n\t\t\terr += 1;\n\t\t} else {\n\t\t\twait_status = wait_for_completion_interruptible_timeout(\n\t\t\t\t&tqspi->tx_dma_complete, QSPI_DMA_TIMEOUT);\n\t\t\tif (wait_status <= 0) {\n\t\t\t\tdmaengine_terminate_all(tqspi->tx_dma_chan);\n\t\t\t\tdev_err(tqspi->dev, \"failed TX DMA transfer\\n\");\n\t\t\t\terr += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (tqspi->cur_direction & DATA_DIR_RX) {\n\t\tif (tqspi->rx_status) {\n\t\t\tdmaengine_terminate_all(tqspi->rx_dma_chan);\n\t\t\terr += 2;\n\t\t} else {\n\t\t\twait_status = wait_for_completion_interruptible_timeout(\n\t\t\t\t&tqspi->rx_dma_complete, QSPI_DMA_TIMEOUT);\n\t\t\tif (wait_status <= 0) {\n\t\t\t\tdmaengine_terminate_all(tqspi->rx_dma_chan);\n\t\t\t\tdev_err(tqspi->dev, \"failed RX DMA transfer\\n\");\n\t\t\t\terr += 2;\n\t\t\t}\n\t\t}\n\t}\n\n\tspin_lock_irqsave(&tqspi->lock, flags);\n\n\tif (err) {\n\t\ttegra_qspi_dma_unmap_xfer(tqspi, t);\n\t\ttegra_qspi_handle_error(tqspi);\n\t\tcomplete(&tqspi->xfer_completion);\n\t\tgoto exit;\n\t}\n\n\tif (tqspi->cur_direction & DATA_DIR_RX)\n\t\ttegra_qspi_copy_qspi_rxbuf_to_client_rxbuf(tqspi, t);\n\n\tif (tqspi->cur_direction & DATA_DIR_TX)\n\t\ttqspi->cur_pos = tqspi->cur_tx_pos;\n\telse\n\t\ttqspi->cur_pos = tqspi->cur_rx_pos;\n\n\tif (tqspi->cur_pos == t->len) {\n\t\ttegra_qspi_dma_unmap_xfer(tqspi, t);\n\t\tcomplete(&tqspi->xfer_completion);\n\t\tgoto exit;\n\t}\n\n\ttegra_qspi_dma_unmap_xfer(tqspi, t);\n\n\t \n\ttotal_fifo_words = tegra_qspi_calculate_curr_xfer_param(tqspi, t);\n\tif (total_fifo_words > QSPI_FIFO_DEPTH)\n\t\terr = tegra_qspi_start_dma_based_transfer(tqspi, t);\n\telse\n\t\terr = tegra_qspi_start_cpu_based_transfer(tqspi, t);\n\nexit:\n\tspin_unlock_irqrestore(&tqspi->lock, flags);\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t tegra_qspi_isr_thread(int irq, void *context_data)\n{\n\tstruct tegra_qspi *tqspi = context_data;\n\n\ttqspi->status_reg = tegra_qspi_readl(tqspi, QSPI_FIFO_STATUS);\n\n\tif (tqspi->cur_direction & DATA_DIR_TX)\n\t\ttqspi->tx_status = tqspi->status_reg & (QSPI_TX_FIFO_UNF | QSPI_TX_FIFO_OVF);\n\n\tif (tqspi->cur_direction & DATA_DIR_RX)\n\t\ttqspi->rx_status = tqspi->status_reg & (QSPI_RX_FIFO_OVF | QSPI_RX_FIFO_UNF);\n\n\ttegra_qspi_mask_clear_irq(tqspi);\n\n\tif (!tqspi->is_curr_dma_xfer)\n\t\treturn handle_cpu_based_xfer(tqspi);\n\n\treturn handle_dma_based_xfer(tqspi);\n}\n\nstatic struct tegra_qspi_soc_data tegra210_qspi_soc_data = {\n\t.has_dma = true,\n\t.cmb_xfer_capable = false,\n\t.supports_tpm = false,\n\t.cs_count = 1,\n};\n\nstatic struct tegra_qspi_soc_data tegra186_qspi_soc_data = {\n\t.has_dma = true,\n\t.cmb_xfer_capable = true,\n\t.supports_tpm = false,\n\t.cs_count = 1,\n};\n\nstatic struct tegra_qspi_soc_data tegra234_qspi_soc_data = {\n\t.has_dma = false,\n\t.cmb_xfer_capable = true,\n\t.supports_tpm = true,\n\t.cs_count = 1,\n};\n\nstatic struct tegra_qspi_soc_data tegra241_qspi_soc_data = {\n\t.has_dma = false,\n\t.cmb_xfer_capable = true,\n\t.supports_tpm = true,\n\t.cs_count = 4,\n};\n\nstatic const struct of_device_id tegra_qspi_of_match[] = {\n\t{\n\t\t.compatible = \"nvidia,tegra210-qspi\",\n\t\t.data\t    = &tegra210_qspi_soc_data,\n\t}, {\n\t\t.compatible = \"nvidia,tegra186-qspi\",\n\t\t.data\t    = &tegra186_qspi_soc_data,\n\t}, {\n\t\t.compatible = \"nvidia,tegra194-qspi\",\n\t\t.data\t    = &tegra186_qspi_soc_data,\n\t}, {\n\t\t.compatible = \"nvidia,tegra234-qspi\",\n\t\t.data\t    = &tegra234_qspi_soc_data,\n\t}, {\n\t\t.compatible = \"nvidia,tegra241-qspi\",\n\t\t.data\t    = &tegra241_qspi_soc_data,\n\t},\n\t{}\n};\n\nMODULE_DEVICE_TABLE(of, tegra_qspi_of_match);\n\n#ifdef CONFIG_ACPI\nstatic const struct acpi_device_id tegra_qspi_acpi_match[] = {\n\t{\n\t\t.id = \"NVDA1213\",\n\t\t.driver_data = (kernel_ulong_t)&tegra210_qspi_soc_data,\n\t}, {\n\t\t.id = \"NVDA1313\",\n\t\t.driver_data = (kernel_ulong_t)&tegra186_qspi_soc_data,\n\t}, {\n\t\t.id = \"NVDA1413\",\n\t\t.driver_data = (kernel_ulong_t)&tegra234_qspi_soc_data,\n\t}, {\n\t\t.id = \"NVDA1513\",\n\t\t.driver_data = (kernel_ulong_t)&tegra241_qspi_soc_data,\n\t},\n\t{}\n};\n\nMODULE_DEVICE_TABLE(acpi, tegra_qspi_acpi_match);\n#endif\n\nstatic int tegra_qspi_probe(struct platform_device *pdev)\n{\n\tstruct spi_master\t*master;\n\tstruct tegra_qspi\t*tqspi;\n\tstruct resource\t\t*r;\n\tint ret, qspi_irq;\n\tint bus_num;\n\n\tmaster = devm_spi_alloc_master(&pdev->dev, sizeof(*tqspi));\n\tif (!master)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, master);\n\ttqspi = spi_master_get_devdata(master);\n\n\tmaster->mode_bits = SPI_MODE_0 | SPI_MODE_3 | SPI_CS_HIGH |\n\t\t\t    SPI_TX_DUAL | SPI_RX_DUAL | SPI_TX_QUAD | SPI_RX_QUAD;\n\tmaster->bits_per_word_mask = SPI_BPW_MASK(32) | SPI_BPW_MASK(16) | SPI_BPW_MASK(8);\n\tmaster->flags = SPI_CONTROLLER_HALF_DUPLEX;\n\tmaster->setup = tegra_qspi_setup;\n\tmaster->transfer_one_message = tegra_qspi_transfer_one_message;\n\tmaster->num_chipselect = 1;\n\tmaster->auto_runtime_pm = true;\n\n\tbus_num = of_alias_get_id(pdev->dev.of_node, \"spi\");\n\tif (bus_num >= 0)\n\t\tmaster->bus_num = bus_num;\n\n\ttqspi->master = master;\n\ttqspi->dev = &pdev->dev;\n\tspin_lock_init(&tqspi->lock);\n\n\ttqspi->soc_data = device_get_match_data(&pdev->dev);\n\tmaster->num_chipselect = tqspi->soc_data->cs_count;\n\ttqspi->base = devm_platform_get_and_ioremap_resource(pdev, 0, &r);\n\tif (IS_ERR(tqspi->base))\n\t\treturn PTR_ERR(tqspi->base);\n\n\ttqspi->phys = r->start;\n\tqspi_irq = platform_get_irq(pdev, 0);\n\tif (qspi_irq < 0)\n\t\treturn qspi_irq;\n\ttqspi->irq = qspi_irq;\n\n\tif (!has_acpi_companion(tqspi->dev)) {\n\t\ttqspi->clk = devm_clk_get(&pdev->dev, \"qspi\");\n\t\tif (IS_ERR(tqspi->clk)) {\n\t\t\tret = PTR_ERR(tqspi->clk);\n\t\t\tdev_err(&pdev->dev, \"failed to get clock: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t}\n\n\ttqspi->max_buf_size = QSPI_FIFO_DEPTH << 2;\n\ttqspi->dma_buf_size = DEFAULT_QSPI_DMA_BUF_LEN;\n\n\tret = tegra_qspi_init_dma(tqspi);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (tqspi->use_dma)\n\t\ttqspi->max_buf_size = tqspi->dma_buf_size;\n\n\tinit_completion(&tqspi->tx_dma_complete);\n\tinit_completion(&tqspi->rx_dma_complete);\n\tinit_completion(&tqspi->xfer_completion);\n\n\tpm_runtime_enable(&pdev->dev);\n\tret = pm_runtime_resume_and_get(&pdev->dev);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"failed to get runtime PM: %d\\n\", ret);\n\t\tgoto exit_pm_disable;\n\t}\n\n\tif (device_reset(tqspi->dev) < 0)\n\t\tdev_warn_once(tqspi->dev, \"device reset failed\\n\");\n\n\ttqspi->def_command1_reg = QSPI_M_S | QSPI_CS_SW_HW |  QSPI_CS_SW_VAL;\n\ttegra_qspi_writel(tqspi, tqspi->def_command1_reg, QSPI_COMMAND1);\n\ttqspi->spi_cs_timing1 = tegra_qspi_readl(tqspi, QSPI_CS_TIMING1);\n\ttqspi->spi_cs_timing2 = tegra_qspi_readl(tqspi, QSPI_CS_TIMING2);\n\ttqspi->def_command2_reg = tegra_qspi_readl(tqspi, QSPI_COMMAND2);\n\n\tpm_runtime_put(&pdev->dev);\n\n\tret = request_threaded_irq(tqspi->irq, NULL,\n\t\t\t\t   tegra_qspi_isr_thread, IRQF_ONESHOT,\n\t\t\t\t   dev_name(&pdev->dev), tqspi);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"failed to request IRQ#%u: %d\\n\", tqspi->irq, ret);\n\t\tgoto exit_pm_disable;\n\t}\n\n\tmaster->dev.of_node = pdev->dev.of_node;\n\tret = spi_register_master(master);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"failed to register master: %d\\n\", ret);\n\t\tgoto exit_free_irq;\n\t}\n\n\treturn 0;\n\nexit_free_irq:\n\tfree_irq(qspi_irq, tqspi);\nexit_pm_disable:\n\tpm_runtime_force_suspend(&pdev->dev);\n\ttegra_qspi_deinit_dma(tqspi);\n\treturn ret;\n}\n\nstatic void tegra_qspi_remove(struct platform_device *pdev)\n{\n\tstruct spi_master *master = platform_get_drvdata(pdev);\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(master);\n\n\tspi_unregister_master(master);\n\tfree_irq(tqspi->irq, tqspi);\n\tpm_runtime_force_suspend(&pdev->dev);\n\ttegra_qspi_deinit_dma(tqspi);\n}\n\nstatic int __maybe_unused tegra_qspi_suspend(struct device *dev)\n{\n\tstruct spi_master *master = dev_get_drvdata(dev);\n\n\treturn spi_master_suspend(master);\n}\n\nstatic int __maybe_unused tegra_qspi_resume(struct device *dev)\n{\n\tstruct spi_master *master = dev_get_drvdata(dev);\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(master);\n\tint ret;\n\n\tret = pm_runtime_resume_and_get(dev);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"failed to get runtime PM: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\ttegra_qspi_writel(tqspi, tqspi->command1_reg, QSPI_COMMAND1);\n\ttegra_qspi_writel(tqspi, tqspi->def_command2_reg, QSPI_COMMAND2);\n\tpm_runtime_put(dev);\n\n\treturn spi_master_resume(master);\n}\n\nstatic int __maybe_unused tegra_qspi_runtime_suspend(struct device *dev)\n{\n\tstruct spi_master *master = dev_get_drvdata(dev);\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(master);\n\n\t \n\tif (has_acpi_companion(tqspi->dev))\n\t\treturn 0;\n\t \n\ttegra_qspi_readl(tqspi, QSPI_COMMAND1);\n\n\tclk_disable_unprepare(tqspi->clk);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused tegra_qspi_runtime_resume(struct device *dev)\n{\n\tstruct spi_master *master = dev_get_drvdata(dev);\n\tstruct tegra_qspi *tqspi = spi_master_get_devdata(master);\n\tint ret;\n\n\t \n\tif (has_acpi_companion(tqspi->dev))\n\t\treturn 0;\n\tret = clk_prepare_enable(tqspi->clk);\n\tif (ret < 0)\n\t\tdev_err(tqspi->dev, \"failed to enable clock: %d\\n\", ret);\n\n\treturn ret;\n}\n\nstatic const struct dev_pm_ops tegra_qspi_pm_ops = {\n\tSET_RUNTIME_PM_OPS(tegra_qspi_runtime_suspend, tegra_qspi_runtime_resume, NULL)\n\tSET_SYSTEM_SLEEP_PM_OPS(tegra_qspi_suspend, tegra_qspi_resume)\n};\n\nstatic struct platform_driver tegra_qspi_driver = {\n\t.driver = {\n\t\t.name\t\t= \"tegra-qspi\",\n\t\t.pm\t\t= &tegra_qspi_pm_ops,\n\t\t.of_match_table\t= tegra_qspi_of_match,\n\t\t.acpi_match_table = ACPI_PTR(tegra_qspi_acpi_match),\n\t},\n\t.probe =\ttegra_qspi_probe,\n\t.remove_new =\ttegra_qspi_remove,\n};\nmodule_platform_driver(tegra_qspi_driver);\n\nMODULE_ALIAS(\"platform:qspi-tegra\");\nMODULE_DESCRIPTION(\"NVIDIA Tegra QSPI Controller Driver\");\nMODULE_AUTHOR(\"Sowjanya Komatineni <skomatineni@nvidia.com>\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}