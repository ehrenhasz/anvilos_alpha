{
  "module_name": "spi-qcom-qspi.c",
  "hash_id": "cd1828f5739f1b9d958b57f01f3f18dd1260314284cbec30458eaaf0283359eb",
  "original_prompt": "Ingested from linux-6.6.14/drivers/spi/spi-qcom-qspi.c",
  "human_readable_source": "\n\n\n#include <linux/clk.h>\n#include <linux/dmapool.h>\n#include <linux/dma-mapping.h>\n#include <linux/interconnect.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/pinctrl/consumer.h>\n#include <linux/pm_runtime.h>\n#include <linux/pm_opp.h>\n#include <linux/spi/spi.h>\n#include <linux/spi/spi-mem.h>\n\n\n#define QSPI_NUM_CS\t\t2\n#define QSPI_BYTES_PER_WORD\t4\n\n#define MSTR_CONFIG\t\t0x0000\n#define FULL_CYCLE_MODE\t\tBIT(3)\n#define FB_CLK_EN\t\tBIT(4)\n#define PIN_HOLDN\t\tBIT(6)\n#define PIN_WPN\t\t\tBIT(7)\n#define DMA_ENABLE\t\tBIT(8)\n#define BIG_ENDIAN_MODE\t\tBIT(9)\n#define SPI_MODE_MSK\t\t0xc00\n#define SPI_MODE_SHFT\t\t10\n#define CHIP_SELECT_NUM\t\tBIT(12)\n#define SBL_EN\t\t\tBIT(13)\n#define LPA_BASE_MSK\t\t0x3c000\n#define LPA_BASE_SHFT\t\t14\n#define TX_DATA_DELAY_MSK\t0xc0000\n#define TX_DATA_DELAY_SHFT\t18\n#define TX_CLK_DELAY_MSK\t0x300000\n#define TX_CLK_DELAY_SHFT\t20\n#define TX_CS_N_DELAY_MSK\t0xc00000\n#define TX_CS_N_DELAY_SHFT\t22\n#define TX_DATA_OE_DELAY_MSK\t0x3000000\n#define TX_DATA_OE_DELAY_SHFT\t24\n\n#define AHB_MASTER_CFG\t\t\t\t0x0004\n#define HMEM_TYPE_START_MID_TRANS_MSK\t\t0x7\n#define HMEM_TYPE_START_MID_TRANS_SHFT\t\t0\n#define HMEM_TYPE_LAST_TRANS_MSK\t\t0x38\n#define HMEM_TYPE_LAST_TRANS_SHFT\t\t3\n#define USE_HMEMTYPE_LAST_ON_DESC_OR_CHAIN_MSK\t0xc0\n#define USE_HMEMTYPE_LAST_ON_DESC_OR_CHAIN_SHFT\t6\n#define HMEMTYPE_READ_TRANS_MSK\t\t\t0x700\n#define HMEMTYPE_READ_TRANS_SHFT\t\t8\n#define HSHARED\t\t\t\t\tBIT(11)\n#define HINNERSHARED\t\t\t\tBIT(12)\n\n#define MSTR_INT_EN\t\t0x000C\n#define MSTR_INT_STATUS\t\t0x0010\n#define RESP_FIFO_UNDERRUN\tBIT(0)\n#define RESP_FIFO_NOT_EMPTY\tBIT(1)\n#define RESP_FIFO_RDY\t\tBIT(2)\n#define HRESP_FROM_NOC_ERR\tBIT(3)\n#define WR_FIFO_EMPTY\t\tBIT(9)\n#define WR_FIFO_FULL\t\tBIT(10)\n#define WR_FIFO_OVERRUN\t\tBIT(11)\n#define TRANSACTION_DONE\tBIT(16)\n#define DMA_CHAIN_DONE\t\tBIT(31)\n#define QSPI_ERR_IRQS\t\t(RESP_FIFO_UNDERRUN | HRESP_FROM_NOC_ERR | \\\n\t\t\t\t WR_FIFO_OVERRUN)\n#define QSPI_ALL_IRQS\t\t(QSPI_ERR_IRQS | RESP_FIFO_RDY | \\\n\t\t\t\t WR_FIFO_EMPTY | WR_FIFO_FULL | \\\n\t\t\t\t TRANSACTION_DONE | DMA_CHAIN_DONE)\n\n#define PIO_XFER_CTRL\t\t0x0014\n#define REQUEST_COUNT_MSK\t0xffff\n\n#define PIO_XFER_CFG\t\t0x0018\n#define TRANSFER_DIRECTION\tBIT(0)\n#define MULTI_IO_MODE_MSK\t0xe\n#define MULTI_IO_MODE_SHFT\t1\n#define TRANSFER_FRAGMENT\tBIT(8)\n#define SDR_1BIT\t\t1\n#define SDR_2BIT\t\t2\n#define SDR_4BIT\t\t3\n#define DDR_1BIT\t\t5\n#define DDR_2BIT\t\t6\n#define DDR_4BIT\t\t7\n#define DMA_DESC_SINGLE_SPI\t1\n#define DMA_DESC_DUAL_SPI\t2\n#define DMA_DESC_QUAD_SPI\t3\n\n#define PIO_XFER_STATUS\t\t0x001c\n#define WR_FIFO_BYTES_MSK\t0xffff0000\n#define WR_FIFO_BYTES_SHFT\t16\n\n#define PIO_DATAOUT_1B\t\t0x0020\n#define PIO_DATAOUT_4B\t\t0x0024\n\n#define RD_FIFO_CFG\t\t0x0028\n#define CONTINUOUS_MODE\t\tBIT(0)\n\n#define RD_FIFO_STATUS\t0x002c\n#define FIFO_EMPTY\tBIT(11)\n#define WR_CNTS_MSK\t0x7f0\n#define WR_CNTS_SHFT\t4\n#define RDY_64BYTE\tBIT(3)\n#define RDY_32BYTE\tBIT(2)\n#define RDY_16BYTE\tBIT(1)\n#define FIFO_RDY\tBIT(0)\n\n#define RD_FIFO_RESET\t\t0x0030\n#define RESET_FIFO\t\tBIT(0)\n\n#define NEXT_DMA_DESC_ADDR\t0x0040\n#define CURRENT_DMA_DESC_ADDR\t0x0044\n#define CURRENT_MEM_ADDR\t0x0048\n\n#define CUR_MEM_ADDR\t\t0x0048\n#define HW_VERSION\t\t0x004c\n#define RD_FIFO\t\t\t0x0050\n#define SAMPLING_CLK_CFG\t0x0090\n#define SAMPLING_CLK_STATUS\t0x0094\n\n#define QSPI_ALIGN_REQ\t32\n\nenum qspi_dir {\n\tQSPI_READ,\n\tQSPI_WRITE,\n};\n\nstruct qspi_cmd_desc {\n\tu32 data_address;\n\tu32 next_descriptor;\n\tu32 direction:1;\n\tu32 multi_io_mode:3;\n\tu32 reserved1:4;\n\tu32 fragment:1;\n\tu32 reserved2:7;\n\tu32 length:16;\n};\n\nstruct qspi_xfer {\n\tunion {\n\t\tconst void *tx_buf;\n\t\tvoid *rx_buf;\n\t};\n\tunsigned int rem_bytes;\n\tunsigned int buswidth;\n\tenum qspi_dir dir;\n\tbool is_last;\n};\n\nenum qspi_clocks {\n\tQSPI_CLK_CORE,\n\tQSPI_CLK_IFACE,\n\tQSPI_NUM_CLKS\n};\n\n \n#define QSPI_MAX_SG 5\n\nstruct qcom_qspi {\n\tvoid __iomem *base;\n\tstruct device *dev;\n\tstruct clk_bulk_data *clks;\n\tstruct qspi_xfer xfer;\n\tstruct dma_pool *dma_cmd_pool;\n\tdma_addr_t dma_cmd_desc[QSPI_MAX_SG];\n\tvoid *virt_cmd_desc[QSPI_MAX_SG];\n\tunsigned int n_cmd_desc;\n\tstruct icc_path *icc_path_cpu_to_qspi;\n\tunsigned long last_speed;\n\t \n\tspinlock_t lock;\n};\n\nstatic u32 qspi_buswidth_to_iomode(struct qcom_qspi *ctrl,\n\t\t\t\t   unsigned int buswidth)\n{\n\tswitch (buswidth) {\n\tcase 1:\n\t\treturn SDR_1BIT;\n\tcase 2:\n\t\treturn SDR_2BIT;\n\tcase 4:\n\t\treturn SDR_4BIT;\n\tdefault:\n\t\tdev_warn_once(ctrl->dev,\n\t\t\t\t\"Unexpected bus width: %u\\n\", buswidth);\n\t\treturn SDR_1BIT;\n\t}\n}\n\nstatic void qcom_qspi_pio_xfer_cfg(struct qcom_qspi *ctrl)\n{\n\tu32 pio_xfer_cfg;\n\tu32 iomode;\n\tconst struct qspi_xfer *xfer;\n\n\txfer = &ctrl->xfer;\n\tpio_xfer_cfg = readl(ctrl->base + PIO_XFER_CFG);\n\tpio_xfer_cfg &= ~TRANSFER_DIRECTION;\n\tpio_xfer_cfg |= xfer->dir;\n\tif (xfer->is_last)\n\t\tpio_xfer_cfg &= ~TRANSFER_FRAGMENT;\n\telse\n\t\tpio_xfer_cfg |= TRANSFER_FRAGMENT;\n\tpio_xfer_cfg &= ~MULTI_IO_MODE_MSK;\n\tiomode = qspi_buswidth_to_iomode(ctrl, xfer->buswidth);\n\tpio_xfer_cfg |= iomode << MULTI_IO_MODE_SHFT;\n\n\twritel(pio_xfer_cfg, ctrl->base + PIO_XFER_CFG);\n}\n\nstatic void qcom_qspi_pio_xfer_ctrl(struct qcom_qspi *ctrl)\n{\n\tu32 pio_xfer_ctrl;\n\n\tpio_xfer_ctrl = readl(ctrl->base + PIO_XFER_CTRL);\n\tpio_xfer_ctrl &= ~REQUEST_COUNT_MSK;\n\tpio_xfer_ctrl |= ctrl->xfer.rem_bytes;\n\twritel(pio_xfer_ctrl, ctrl->base + PIO_XFER_CTRL);\n}\n\nstatic void qcom_qspi_pio_xfer(struct qcom_qspi *ctrl)\n{\n\tu32 ints;\n\n\tqcom_qspi_pio_xfer_cfg(ctrl);\n\n\t \n\twritel(QSPI_ALL_IRQS, ctrl->base + MSTR_INT_STATUS);\n\n\t \n\tif (ctrl->xfer.dir == QSPI_WRITE)\n\t\tints = QSPI_ERR_IRQS | WR_FIFO_EMPTY;\n\telse\n\t\tints = QSPI_ERR_IRQS | RESP_FIFO_RDY;\n\twritel(ints, ctrl->base + MSTR_INT_EN);\n\n\t \n\tqcom_qspi_pio_xfer_ctrl(ctrl);\n}\n\nstatic void qcom_qspi_handle_err(struct spi_controller *host,\n\t\t\t\t struct spi_message *msg)\n{\n\tu32 int_status;\n\tstruct qcom_qspi *ctrl = spi_controller_get_devdata(host);\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&ctrl->lock, flags);\n\twritel(0, ctrl->base + MSTR_INT_EN);\n\tint_status = readl(ctrl->base + MSTR_INT_STATUS);\n\twritel(int_status, ctrl->base + MSTR_INT_STATUS);\n\tctrl->xfer.rem_bytes = 0;\n\n\t \n\tfor (i = 0; i < ctrl->n_cmd_desc; i++)\n\t\tdma_pool_free(ctrl->dma_cmd_pool, ctrl->virt_cmd_desc[i],\n\t\t\t\t  ctrl->dma_cmd_desc[i]);\n\tctrl->n_cmd_desc = 0;\n\tspin_unlock_irqrestore(&ctrl->lock, flags);\n}\n\nstatic int qcom_qspi_set_speed(struct qcom_qspi *ctrl, unsigned long speed_hz)\n{\n\tint ret;\n\tunsigned int avg_bw_cpu;\n\n\tif (speed_hz == ctrl->last_speed)\n\t\treturn 0;\n\n\t \n\tret = dev_pm_opp_set_rate(ctrl->dev, speed_hz * 4);\n\tif (ret) {\n\t\tdev_err(ctrl->dev, \"Failed to set core clk %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tavg_bw_cpu = Bps_to_icc(speed_hz);\n\tret = icc_set_bw(ctrl->icc_path_cpu_to_qspi, avg_bw_cpu, avg_bw_cpu);\n\tif (ret) {\n\t\tdev_err(ctrl->dev, \"%s: ICC BW voting failed for cpu: %d\\n\",\n\t\t\t__func__, ret);\n\t\treturn ret;\n\t}\n\n\tctrl->last_speed = speed_hz;\n\n\treturn 0;\n}\n\nstatic int qcom_qspi_alloc_desc(struct qcom_qspi *ctrl, dma_addr_t dma_ptr,\n\t\t\tuint32_t n_bytes)\n{\n\tstruct qspi_cmd_desc *virt_cmd_desc, *prev;\n\tdma_addr_t dma_cmd_desc;\n\n\t \n\tvirt_cmd_desc = dma_pool_alloc(ctrl->dma_cmd_pool, GFP_ATOMIC | __GFP_ZERO, &dma_cmd_desc);\n\tif (!virt_cmd_desc) {\n\t\tdev_warn_once(ctrl->dev, \"Couldn't find memory for descriptor\\n\");\n\t\treturn -EAGAIN;\n\t}\n\n\tctrl->virt_cmd_desc[ctrl->n_cmd_desc] = virt_cmd_desc;\n\tctrl->dma_cmd_desc[ctrl->n_cmd_desc] = dma_cmd_desc;\n\tctrl->n_cmd_desc++;\n\n\t \n\tvirt_cmd_desc->data_address = dma_ptr;\n\tvirt_cmd_desc->direction = ctrl->xfer.dir;\n\tvirt_cmd_desc->multi_io_mode = qspi_buswidth_to_iomode(ctrl, ctrl->xfer.buswidth);\n\tvirt_cmd_desc->fragment = !ctrl->xfer.is_last;\n\tvirt_cmd_desc->length = n_bytes;\n\n\t \n\tif (ctrl->n_cmd_desc >= 2) {\n\t\tprev = (ctrl->virt_cmd_desc)[ctrl->n_cmd_desc - 2];\n\t\tprev->next_descriptor = dma_cmd_desc;\n\t\tprev->fragment = 1;\n\t}\n\n\treturn 0;\n}\n\nstatic int qcom_qspi_setup_dma_desc(struct qcom_qspi *ctrl,\n\t\t\t\tstruct spi_transfer *xfer)\n{\n\tint ret;\n\tstruct sg_table *sgt;\n\tdma_addr_t dma_ptr_sg;\n\tunsigned int dma_len_sg;\n\tint i;\n\n\tif (ctrl->n_cmd_desc) {\n\t\tdev_err(ctrl->dev, \"Remnant dma buffers n_cmd_desc-%d\\n\", ctrl->n_cmd_desc);\n\t\treturn -EIO;\n\t}\n\n\tsgt = (ctrl->xfer.dir == QSPI_READ) ? &xfer->rx_sg : &xfer->tx_sg;\n\tif (!sgt->nents || sgt->nents > QSPI_MAX_SG) {\n\t\tdev_warn_once(ctrl->dev, \"Cannot handle %d entries in scatter list\\n\", sgt->nents);\n\t\treturn -EAGAIN;\n\t}\n\n\tfor (i = 0; i < sgt->nents; i++) {\n\t\tdma_ptr_sg = sg_dma_address(sgt->sgl + i);\n\t\tdma_len_sg = sg_dma_len(sgt->sgl + i);\n\t\tif (!IS_ALIGNED(dma_ptr_sg, QSPI_ALIGN_REQ)) {\n\t\t\tdev_warn_once(ctrl->dev, \"dma_address not aligned to %d\\n\", QSPI_ALIGN_REQ);\n\t\t\treturn -EAGAIN;\n\t\t}\n\t\t \n\t\tif (ctrl->xfer.dir == QSPI_READ && (dma_len_sg & 0x03)) {\n\t\t\tdev_warn_once(ctrl->dev, \"fallback to PIO for read of size %#010x\\n\",\n\t\t\t\t      dma_len_sg);\n\t\t\treturn -EAGAIN;\n\t\t}\n\t}\n\n\tfor (i = 0; i < sgt->nents; i++) {\n\t\tdma_ptr_sg = sg_dma_address(sgt->sgl + i);\n\t\tdma_len_sg = sg_dma_len(sgt->sgl + i);\n\n\t\tret = qcom_qspi_alloc_desc(ctrl, dma_ptr_sg, dma_len_sg);\n\t\tif (ret)\n\t\t\tgoto cleanup;\n\t}\n\treturn 0;\n\ncleanup:\n\tfor (i = 0; i < ctrl->n_cmd_desc; i++)\n\t\tdma_pool_free(ctrl->dma_cmd_pool, ctrl->virt_cmd_desc[i],\n\t\t\t\t  ctrl->dma_cmd_desc[i]);\n\tctrl->n_cmd_desc = 0;\n\treturn ret;\n}\n\nstatic void qcom_qspi_dma_xfer(struct qcom_qspi *ctrl)\n{\n\t \n\twritel(DMA_CHAIN_DONE, ctrl->base + MSTR_INT_EN);\n\n\t \n\twritel((u32)((ctrl->dma_cmd_desc)[0]), ctrl->base + NEXT_DMA_DESC_ADDR);\n}\n\n \n#define QSPI_MAX_BYTES_FIFO 64\n\nstatic bool qcom_qspi_can_dma(struct spi_controller *ctlr,\n\t\t\t struct spi_device *slv, struct spi_transfer *xfer)\n{\n\treturn xfer->len > QSPI_MAX_BYTES_FIFO;\n}\n\nstatic int qcom_qspi_transfer_one(struct spi_controller *host,\n\t\t\t\t  struct spi_device *slv,\n\t\t\t\t  struct spi_transfer *xfer)\n{\n\tstruct qcom_qspi *ctrl = spi_controller_get_devdata(host);\n\tint ret;\n\tunsigned long speed_hz;\n\tunsigned long flags;\n\tu32 mstr_cfg;\n\n\tspeed_hz = slv->max_speed_hz;\n\tif (xfer->speed_hz)\n\t\tspeed_hz = xfer->speed_hz;\n\n\tret = qcom_qspi_set_speed(ctrl, speed_hz);\n\tif (ret)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&ctrl->lock, flags);\n\tmstr_cfg = readl(ctrl->base + MSTR_CONFIG);\n\n\t \n\tif (xfer->rx_buf) {\n\t\tctrl->xfer.dir = QSPI_READ;\n\t\tctrl->xfer.buswidth = xfer->rx_nbits;\n\t\tctrl->xfer.rx_buf = xfer->rx_buf;\n\t} else {\n\t\tctrl->xfer.dir = QSPI_WRITE;\n\t\tctrl->xfer.buswidth = xfer->tx_nbits;\n\t\tctrl->xfer.tx_buf = xfer->tx_buf;\n\t}\n\tctrl->xfer.is_last = list_is_last(&xfer->transfer_list,\n\t\t\t\t\t  &host->cur_msg->transfers);\n\tctrl->xfer.rem_bytes = xfer->len;\n\n\tif (xfer->rx_sg.nents || xfer->tx_sg.nents) {\n\t\t \n\t\tif (!(mstr_cfg & DMA_ENABLE)) {\n\t\t\tmstr_cfg |= DMA_ENABLE;\n\t\t\twritel(mstr_cfg, ctrl->base + MSTR_CONFIG);\n\t\t}\n\n\t\tret = qcom_qspi_setup_dma_desc(ctrl, xfer);\n\t\tif (ret != -EAGAIN) {\n\t\t\tif (!ret) {\n\t\t\t\tdma_wmb();\n\t\t\t\tqcom_qspi_dma_xfer(ctrl);\n\t\t\t}\n\t\t\tgoto exit;\n\t\t}\n\t\tdev_warn_once(ctrl->dev, \"DMA failure, falling back to PIO\\n\");\n\t\tret = 0;  \n\t}\n\n\tif (mstr_cfg & DMA_ENABLE) {\n\t\tmstr_cfg &= ~DMA_ENABLE;\n\t\twritel(mstr_cfg, ctrl->base + MSTR_CONFIG);\n\t}\n\tqcom_qspi_pio_xfer(ctrl);\n\nexit:\n\tspin_unlock_irqrestore(&ctrl->lock, flags);\n\n\tif (ret)\n\t\treturn ret;\n\n\t \n\treturn 1;\n}\n\nstatic int qcom_qspi_prepare_message(struct spi_controller *host,\n\t\t\t\t     struct spi_message *message)\n{\n\tu32 mstr_cfg;\n\tstruct qcom_qspi *ctrl;\n\tint tx_data_oe_delay = 1;\n\tint tx_data_delay = 1;\n\tunsigned long flags;\n\n\tctrl = spi_controller_get_devdata(host);\n\tspin_lock_irqsave(&ctrl->lock, flags);\n\n\tmstr_cfg = readl(ctrl->base + MSTR_CONFIG);\n\tmstr_cfg &= ~CHIP_SELECT_NUM;\n\tif (spi_get_chipselect(message->spi, 0))\n\t\tmstr_cfg |= CHIP_SELECT_NUM;\n\n\tmstr_cfg |= FB_CLK_EN | PIN_WPN | PIN_HOLDN | SBL_EN | FULL_CYCLE_MODE;\n\tmstr_cfg &= ~(SPI_MODE_MSK | TX_DATA_OE_DELAY_MSK | TX_DATA_DELAY_MSK);\n\tmstr_cfg |= message->spi->mode << SPI_MODE_SHFT;\n\tmstr_cfg |= tx_data_oe_delay << TX_DATA_OE_DELAY_SHFT;\n\tmstr_cfg |= tx_data_delay << TX_DATA_DELAY_SHFT;\n\tmstr_cfg &= ~DMA_ENABLE;\n\n\twritel(mstr_cfg, ctrl->base + MSTR_CONFIG);\n\tspin_unlock_irqrestore(&ctrl->lock, flags);\n\n\treturn 0;\n}\n\nstatic int qcom_qspi_alloc_dma(struct qcom_qspi *ctrl)\n{\n\tctrl->dma_cmd_pool = dmam_pool_create(\"qspi cmd desc pool\",\n\t\tctrl->dev, sizeof(struct qspi_cmd_desc), 0, 0);\n\tif (!ctrl->dma_cmd_pool)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic irqreturn_t pio_read(struct qcom_qspi *ctrl)\n{\n\tu32 rd_fifo_status;\n\tu32 rd_fifo;\n\tunsigned int wr_cnts;\n\tunsigned int bytes_to_read;\n\tunsigned int words_to_read;\n\tu32 *word_buf;\n\tu8 *byte_buf;\n\tint i;\n\n\trd_fifo_status = readl(ctrl->base + RD_FIFO_STATUS);\n\n\tif (!(rd_fifo_status & FIFO_RDY)) {\n\t\tdev_dbg(ctrl->dev, \"Spurious IRQ %#x\\n\", rd_fifo_status);\n\t\treturn IRQ_NONE;\n\t}\n\n\twr_cnts = (rd_fifo_status & WR_CNTS_MSK) >> WR_CNTS_SHFT;\n\twr_cnts = min(wr_cnts, ctrl->xfer.rem_bytes);\n\n\twords_to_read = wr_cnts / QSPI_BYTES_PER_WORD;\n\tbytes_to_read = wr_cnts % QSPI_BYTES_PER_WORD;\n\n\tif (words_to_read) {\n\t\tword_buf = ctrl->xfer.rx_buf;\n\t\tctrl->xfer.rem_bytes -= words_to_read * QSPI_BYTES_PER_WORD;\n\t\tioread32_rep(ctrl->base + RD_FIFO, word_buf, words_to_read);\n\t\tctrl->xfer.rx_buf = word_buf + words_to_read;\n\t}\n\n\tif (bytes_to_read) {\n\t\tbyte_buf = ctrl->xfer.rx_buf;\n\t\trd_fifo = readl(ctrl->base + RD_FIFO);\n\t\tctrl->xfer.rem_bytes -= bytes_to_read;\n\t\tfor (i = 0; i < bytes_to_read; i++)\n\t\t\t*byte_buf++ = rd_fifo >> (i * BITS_PER_BYTE);\n\t\tctrl->xfer.rx_buf = byte_buf;\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t pio_write(struct qcom_qspi *ctrl)\n{\n\tconst void *xfer_buf = ctrl->xfer.tx_buf;\n\tconst int *word_buf;\n\tconst char *byte_buf;\n\tunsigned int wr_fifo_bytes;\n\tunsigned int wr_fifo_words;\n\tunsigned int wr_size;\n\tunsigned int rem_words;\n\n\twr_fifo_bytes = readl(ctrl->base + PIO_XFER_STATUS);\n\twr_fifo_bytes >>= WR_FIFO_BYTES_SHFT;\n\n\tif (ctrl->xfer.rem_bytes < QSPI_BYTES_PER_WORD) {\n\t\t \n\t\twr_size = min(wr_fifo_bytes, ctrl->xfer.rem_bytes);\n\t\tctrl->xfer.rem_bytes -= wr_size;\n\n\t\tbyte_buf = xfer_buf;\n\t\twhile (wr_size--)\n\t\t\twritel(*byte_buf++,\n\t\t\t       ctrl->base + PIO_DATAOUT_1B);\n\t\tctrl->xfer.tx_buf = byte_buf;\n\t} else {\n\t\t \n\t\trem_words = ctrl->xfer.rem_bytes / QSPI_BYTES_PER_WORD;\n\t\twr_fifo_words = wr_fifo_bytes / QSPI_BYTES_PER_WORD;\n\n\t\twr_size = min(rem_words, wr_fifo_words);\n\t\tctrl->xfer.rem_bytes -= wr_size * QSPI_BYTES_PER_WORD;\n\n\t\tword_buf = xfer_buf;\n\t\tiowrite32_rep(ctrl->base + PIO_DATAOUT_4B, word_buf, wr_size);\n\t\tctrl->xfer.tx_buf = word_buf + wr_size;\n\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t qcom_qspi_irq(int irq, void *dev_id)\n{\n\tu32 int_status;\n\tstruct qcom_qspi *ctrl = dev_id;\n\tirqreturn_t ret = IRQ_NONE;\n\n\tspin_lock(&ctrl->lock);\n\n\tint_status = readl(ctrl->base + MSTR_INT_STATUS);\n\twritel(int_status, ctrl->base + MSTR_INT_STATUS);\n\n\t \n\tint_status &= readl(ctrl->base + MSTR_INT_EN);\n\n\t \n\tif (ctrl->xfer.dir == QSPI_WRITE) {\n\t\tif (int_status & WR_FIFO_EMPTY)\n\t\t\tret = pio_write(ctrl);\n\t} else {\n\t\tif (int_status & RESP_FIFO_RDY)\n\t\t\tret = pio_read(ctrl);\n\t}\n\n\tif (int_status & QSPI_ERR_IRQS) {\n\t\tif (int_status & RESP_FIFO_UNDERRUN)\n\t\t\tdev_err(ctrl->dev, \"IRQ error: FIFO underrun\\n\");\n\t\tif (int_status & WR_FIFO_OVERRUN)\n\t\t\tdev_err(ctrl->dev, \"IRQ error: FIFO overrun\\n\");\n\t\tif (int_status & HRESP_FROM_NOC_ERR)\n\t\t\tdev_err(ctrl->dev, \"IRQ error: NOC response error\\n\");\n\t\tret = IRQ_HANDLED;\n\t}\n\n\tif (!ctrl->xfer.rem_bytes) {\n\t\twritel(0, ctrl->base + MSTR_INT_EN);\n\t\tspi_finalize_current_transfer(dev_get_drvdata(ctrl->dev));\n\t}\n\n\t \n\tif (int_status & DMA_CHAIN_DONE) {\n\t\tint i;\n\n\t\twritel(0, ctrl->base + MSTR_INT_EN);\n\t\tctrl->xfer.rem_bytes = 0;\n\n\t\tfor (i = 0; i < ctrl->n_cmd_desc; i++)\n\t\t\tdma_pool_free(ctrl->dma_cmd_pool, ctrl->virt_cmd_desc[i],\n\t\t\t\t\t  ctrl->dma_cmd_desc[i]);\n\t\tctrl->n_cmd_desc = 0;\n\n\t\tret = IRQ_HANDLED;\n\t\tspi_finalize_current_transfer(dev_get_drvdata(ctrl->dev));\n\t}\n\n\tspin_unlock(&ctrl->lock);\n\treturn ret;\n}\n\nstatic int qcom_qspi_adjust_op_size(struct spi_mem *mem, struct spi_mem_op *op)\n{\n\t \n\tif (op->data.nbytes <= QSPI_MAX_BYTES_FIFO)\n\t\treturn 0;\n\n\t \n\tif (op->data.dir == SPI_MEM_DATA_IN && (op->data.nbytes & 0x3))\n\t\top->data.nbytes &= ~0x3;\n\n\treturn 0;\n}\n\nstatic const struct spi_controller_mem_ops qcom_qspi_mem_ops = {\n\t.adjust_op_size = qcom_qspi_adjust_op_size,\n};\n\nstatic int qcom_qspi_probe(struct platform_device *pdev)\n{\n\tint ret;\n\tstruct device *dev;\n\tstruct spi_controller *host;\n\tstruct qcom_qspi *ctrl;\n\n\tdev = &pdev->dev;\n\n\thost = devm_spi_alloc_host(dev, sizeof(*ctrl));\n\tif (!host)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, host);\n\n\tctrl = spi_controller_get_devdata(host);\n\n\tspin_lock_init(&ctrl->lock);\n\tctrl->dev = dev;\n\tctrl->base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(ctrl->base))\n\t\treturn PTR_ERR(ctrl->base);\n\n\tctrl->clks = devm_kcalloc(dev, QSPI_NUM_CLKS,\n\t\t\t\t  sizeof(*ctrl->clks), GFP_KERNEL);\n\tif (!ctrl->clks)\n\t\treturn -ENOMEM;\n\n\tctrl->clks[QSPI_CLK_CORE].id = \"core\";\n\tctrl->clks[QSPI_CLK_IFACE].id = \"iface\";\n\tret = devm_clk_bulk_get(dev, QSPI_NUM_CLKS, ctrl->clks);\n\tif (ret)\n\t\treturn ret;\n\n\tctrl->icc_path_cpu_to_qspi = devm_of_icc_get(dev, \"qspi-config\");\n\tif (IS_ERR(ctrl->icc_path_cpu_to_qspi))\n\t\treturn dev_err_probe(dev, PTR_ERR(ctrl->icc_path_cpu_to_qspi),\n\t\t\t\t     \"Failed to get cpu path\\n\");\n\n\t \n\tret = icc_set_bw(ctrl->icc_path_cpu_to_qspi, Bps_to_icc(1000),\n\t\t\t\tBps_to_icc(1000));\n\tif (ret) {\n\t\tdev_err(ctrl->dev, \"%s: ICC BW voting failed for cpu: %d\\n\",\n\t\t\t\t__func__, ret);\n\t\treturn ret;\n\t}\n\n\tret = icc_disable(ctrl->icc_path_cpu_to_qspi);\n\tif (ret) {\n\t\tdev_err(ctrl->dev, \"%s: ICC disable failed for cpu: %d\\n\",\n\t\t\t\t__func__, ret);\n\t\treturn ret;\n\t}\n\n\tret = platform_get_irq(pdev, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = devm_request_irq(dev, ret, qcom_qspi_irq, 0, dev_name(dev), ctrl);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to request irq %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(32));\n\tif (ret)\n\t\treturn dev_err_probe(dev, ret, \"could not set DMA mask\\n\");\n\n\thost->max_speed_hz = 300000000;\n\thost->max_dma_len = 65536;  \n\thost->dma_alignment = QSPI_ALIGN_REQ;\n\thost->num_chipselect = QSPI_NUM_CS;\n\thost->bus_num = -1;\n\thost->dev.of_node = pdev->dev.of_node;\n\thost->mode_bits = SPI_MODE_0 |\n\t\t\t  SPI_TX_DUAL | SPI_RX_DUAL |\n\t\t\t  SPI_TX_QUAD | SPI_RX_QUAD;\n\thost->flags = SPI_CONTROLLER_HALF_DUPLEX;\n\thost->prepare_message = qcom_qspi_prepare_message;\n\thost->transfer_one = qcom_qspi_transfer_one;\n\thost->handle_err = qcom_qspi_handle_err;\n\tif (of_property_read_bool(pdev->dev.of_node, \"iommus\"))\n\t\thost->can_dma = qcom_qspi_can_dma;\n\thost->auto_runtime_pm = true;\n\thost->mem_ops = &qcom_qspi_mem_ops;\n\n\tret = devm_pm_opp_set_clkname(&pdev->dev, \"core\");\n\tif (ret)\n\t\treturn ret;\n\t \n\tret = devm_pm_opp_of_add_table(&pdev->dev);\n\tif (ret && ret != -ENODEV) {\n\t\tdev_err(&pdev->dev, \"invalid OPP table in device tree\\n\");\n\t\treturn ret;\n\t}\n\n\tret = qcom_qspi_alloc_dma(ctrl);\n\tif (ret)\n\t\treturn ret;\n\n\tpm_runtime_use_autosuspend(dev);\n\tpm_runtime_set_autosuspend_delay(dev, 250);\n\tpm_runtime_enable(dev);\n\n\tret = spi_register_controller(host);\n\tif (!ret)\n\t\treturn 0;\n\n\tpm_runtime_disable(dev);\n\n\treturn ret;\n}\n\nstatic void qcom_qspi_remove(struct platform_device *pdev)\n{\n\tstruct spi_controller *host = platform_get_drvdata(pdev);\n\n\t \n\tspi_unregister_controller(host);\n\n\tpm_runtime_disable(&pdev->dev);\n}\n\nstatic int __maybe_unused qcom_qspi_runtime_suspend(struct device *dev)\n{\n\tstruct spi_controller *host = dev_get_drvdata(dev);\n\tstruct qcom_qspi *ctrl = spi_controller_get_devdata(host);\n\tint ret;\n\n\t \n\tdev_pm_opp_set_rate(dev, 0);\n\tclk_bulk_disable_unprepare(QSPI_NUM_CLKS, ctrl->clks);\n\n\tret = icc_disable(ctrl->icc_path_cpu_to_qspi);\n\tif (ret) {\n\t\tdev_err_ratelimited(ctrl->dev, \"%s: ICC disable failed for cpu: %d\\n\",\n\t\t\t__func__, ret);\n\t\treturn ret;\n\t}\n\n\tpinctrl_pm_select_sleep_state(dev);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused qcom_qspi_runtime_resume(struct device *dev)\n{\n\tstruct spi_controller *host = dev_get_drvdata(dev);\n\tstruct qcom_qspi *ctrl = spi_controller_get_devdata(host);\n\tint ret;\n\n\tpinctrl_pm_select_default_state(dev);\n\n\tret = icc_enable(ctrl->icc_path_cpu_to_qspi);\n\tif (ret) {\n\t\tdev_err_ratelimited(ctrl->dev, \"%s: ICC enable failed for cpu: %d\\n\",\n\t\t\t__func__, ret);\n\t\treturn ret;\n\t}\n\n\tret = clk_bulk_prepare_enable(QSPI_NUM_CLKS, ctrl->clks);\n\tif (ret)\n\t\treturn ret;\n\n\treturn dev_pm_opp_set_rate(dev, ctrl->last_speed * 4);\n}\n\nstatic int __maybe_unused qcom_qspi_suspend(struct device *dev)\n{\n\tstruct spi_controller *host = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = spi_controller_suspend(host);\n\tif (ret)\n\t\treturn ret;\n\n\tret = pm_runtime_force_suspend(dev);\n\tif (ret)\n\t\tspi_controller_resume(host);\n\n\treturn ret;\n}\n\nstatic int __maybe_unused qcom_qspi_resume(struct device *dev)\n{\n\tstruct spi_controller *host = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = pm_runtime_force_resume(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = spi_controller_resume(host);\n\tif (ret)\n\t\tpm_runtime_force_suspend(dev);\n\n\treturn ret;\n}\n\nstatic const struct dev_pm_ops qcom_qspi_dev_pm_ops = {\n\tSET_RUNTIME_PM_OPS(qcom_qspi_runtime_suspend,\n\t\t\t   qcom_qspi_runtime_resume, NULL)\n\tSET_SYSTEM_SLEEP_PM_OPS(qcom_qspi_suspend, qcom_qspi_resume)\n};\n\nstatic const struct of_device_id qcom_qspi_dt_match[] = {\n\t{ .compatible = \"qcom,qspi-v1\", },\n\t{ }\n};\nMODULE_DEVICE_TABLE(of, qcom_qspi_dt_match);\n\nstatic struct platform_driver qcom_qspi_driver = {\n\t.driver = {\n\t\t.name\t\t= \"qcom_qspi\",\n\t\t.pm\t\t= &qcom_qspi_dev_pm_ops,\n\t\t.of_match_table = qcom_qspi_dt_match,\n\t},\n\t.probe = qcom_qspi_probe,\n\t.remove_new = qcom_qspi_remove,\n};\nmodule_platform_driver(qcom_qspi_driver);\n\nMODULE_DESCRIPTION(\"SPI driver for QSPI cores\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}