{
  "module_name": "spi-mt65xx.c",
  "hash_id": "dbd07b406118a3c63e17fbfb40209a43bd1fcfee9226c065fc5efc1a40d50abd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/spi/spi-mt65xx.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/device.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/ioport.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/gpio/consumer.h>\n#include <linux/platform_device.h>\n#include <linux/platform_data/spi-mt65xx.h>\n#include <linux/pm_runtime.h>\n#include <linux/spi/spi.h>\n#include <linux/spi/spi-mem.h>\n#include <linux/dma-mapping.h>\n\n#define SPI_CFG0_REG\t\t\t0x0000\n#define SPI_CFG1_REG\t\t\t0x0004\n#define SPI_TX_SRC_REG\t\t\t0x0008\n#define SPI_RX_DST_REG\t\t\t0x000c\n#define SPI_TX_DATA_REG\t\t\t0x0010\n#define SPI_RX_DATA_REG\t\t\t0x0014\n#define SPI_CMD_REG\t\t\t0x0018\n#define SPI_STATUS0_REG\t\t\t0x001c\n#define SPI_PAD_SEL_REG\t\t\t0x0024\n#define SPI_CFG2_REG\t\t\t0x0028\n#define SPI_TX_SRC_REG_64\t\t0x002c\n#define SPI_RX_DST_REG_64\t\t0x0030\n#define SPI_CFG3_IPM_REG\t\t0x0040\n\n#define SPI_CFG0_SCK_HIGH_OFFSET\t0\n#define SPI_CFG0_SCK_LOW_OFFSET\t\t8\n#define SPI_CFG0_CS_HOLD_OFFSET\t\t16\n#define SPI_CFG0_CS_SETUP_OFFSET\t24\n#define SPI_ADJUST_CFG0_CS_HOLD_OFFSET\t0\n#define SPI_ADJUST_CFG0_CS_SETUP_OFFSET\t16\n\n#define SPI_CFG1_CS_IDLE_OFFSET\t\t0\n#define SPI_CFG1_PACKET_LOOP_OFFSET\t8\n#define SPI_CFG1_PACKET_LENGTH_OFFSET\t16\n#define SPI_CFG1_GET_TICK_DLY_OFFSET\t29\n#define SPI_CFG1_GET_TICK_DLY_OFFSET_V1\t30\n\n#define SPI_CFG1_GET_TICK_DLY_MASK\t0xe0000000\n#define SPI_CFG1_GET_TICK_DLY_MASK_V1\t0xc0000000\n\n#define SPI_CFG1_CS_IDLE_MASK\t\t0xff\n#define SPI_CFG1_PACKET_LOOP_MASK\t0xff00\n#define SPI_CFG1_PACKET_LENGTH_MASK\t0x3ff0000\n#define SPI_CFG1_IPM_PACKET_LENGTH_MASK\tGENMASK(31, 16)\n#define SPI_CFG2_SCK_HIGH_OFFSET\t0\n#define SPI_CFG2_SCK_LOW_OFFSET\t\t16\n\n#define SPI_CMD_ACT\t\t\tBIT(0)\n#define SPI_CMD_RESUME\t\t\tBIT(1)\n#define SPI_CMD_RST\t\t\tBIT(2)\n#define SPI_CMD_PAUSE_EN\t\tBIT(4)\n#define SPI_CMD_DEASSERT\t\tBIT(5)\n#define SPI_CMD_SAMPLE_SEL\t\tBIT(6)\n#define SPI_CMD_CS_POL\t\t\tBIT(7)\n#define SPI_CMD_CPHA\t\t\tBIT(8)\n#define SPI_CMD_CPOL\t\t\tBIT(9)\n#define SPI_CMD_RX_DMA\t\t\tBIT(10)\n#define SPI_CMD_TX_DMA\t\t\tBIT(11)\n#define SPI_CMD_TXMSBF\t\t\tBIT(12)\n#define SPI_CMD_RXMSBF\t\t\tBIT(13)\n#define SPI_CMD_RX_ENDIAN\t\tBIT(14)\n#define SPI_CMD_TX_ENDIAN\t\tBIT(15)\n#define SPI_CMD_FINISH_IE\t\tBIT(16)\n#define SPI_CMD_PAUSE_IE\t\tBIT(17)\n#define SPI_CMD_IPM_NONIDLE_MODE\tBIT(19)\n#define SPI_CMD_IPM_SPIM_LOOP\t\tBIT(21)\n#define SPI_CMD_IPM_GET_TICKDLY_OFFSET\t22\n\n#define SPI_CMD_IPM_GET_TICKDLY_MASK\tGENMASK(24, 22)\n\n#define PIN_MODE_CFG(x)\t((x) / 2)\n\n#define SPI_CFG3_IPM_HALF_DUPLEX_DIR\tBIT(2)\n#define SPI_CFG3_IPM_HALF_DUPLEX_EN\tBIT(3)\n#define SPI_CFG3_IPM_XMODE_EN\t\tBIT(4)\n#define SPI_CFG3_IPM_NODATA_FLAG\tBIT(5)\n#define SPI_CFG3_IPM_CMD_BYTELEN_OFFSET\t8\n#define SPI_CFG3_IPM_ADDR_BYTELEN_OFFSET 12\n\n#define SPI_CFG3_IPM_CMD_PIN_MODE_MASK\tGENMASK(1, 0)\n#define SPI_CFG3_IPM_CMD_BYTELEN_MASK\tGENMASK(11, 8)\n#define SPI_CFG3_IPM_ADDR_BYTELEN_MASK\tGENMASK(15, 12)\n\n#define MT8173_SPI_MAX_PAD_SEL\t\t3\n\n#define MTK_SPI_PAUSE_INT_STATUS\t0x2\n\n#define MTK_SPI_MAX_FIFO_SIZE\t\t32U\n#define MTK_SPI_PACKET_SIZE\t\t1024\n#define MTK_SPI_IPM_PACKET_SIZE\t\tSZ_64K\n#define MTK_SPI_IPM_PACKET_LOOP\t\tSZ_256\n\n#define MTK_SPI_IDLE\t\t\t0\n#define MTK_SPI_PAUSED\t\t\t1\n\n#define MTK_SPI_32BITS_MASK\t\t(0xffffffff)\n\n#define DMA_ADDR_EXT_BITS\t\t(36)\n#define DMA_ADDR_DEF_BITS\t\t(32)\n\n \nstruct mtk_spi_compatible {\n\tbool need_pad_sel;\n\tbool must_tx;\n\tbool enhance_timing;\n\tbool dma_ext;\n\tbool no_need_unprepare;\n\tbool ipm_design;\n};\n\n \nstruct mtk_spi {\n\tvoid __iomem *base;\n\tu32 state;\n\tint pad_num;\n\tu32 *pad_sel;\n\tstruct clk *parent_clk, *sel_clk, *spi_clk, *spi_hclk;\n\tstruct spi_transfer *cur_transfer;\n\tu32 xfer_len;\n\tu32 num_xfered;\n\tstruct scatterlist *tx_sgl, *rx_sgl;\n\tu32 tx_sgl_len, rx_sgl_len;\n\tconst struct mtk_spi_compatible *dev_comp;\n\tu32 spi_clk_hz;\n\tstruct completion spimem_done;\n\tbool use_spimem;\n\tstruct device *dev;\n\tdma_addr_t tx_dma;\n\tdma_addr_t rx_dma;\n};\n\nstatic const struct mtk_spi_compatible mtk_common_compat;\n\nstatic const struct mtk_spi_compatible mt2712_compat = {\n\t.must_tx = true,\n};\n\nstatic const struct mtk_spi_compatible mtk_ipm_compat = {\n\t.enhance_timing = true,\n\t.dma_ext = true,\n\t.ipm_design = true,\n};\n\nstatic const struct mtk_spi_compatible mt6765_compat = {\n\t.need_pad_sel = true,\n\t.must_tx = true,\n\t.enhance_timing = true,\n\t.dma_ext = true,\n};\n\nstatic const struct mtk_spi_compatible mt7622_compat = {\n\t.must_tx = true,\n\t.enhance_timing = true,\n};\n\nstatic const struct mtk_spi_compatible mt8173_compat = {\n\t.need_pad_sel = true,\n\t.must_tx = true,\n};\n\nstatic const struct mtk_spi_compatible mt8183_compat = {\n\t.need_pad_sel = true,\n\t.must_tx = true,\n\t.enhance_timing = true,\n};\n\nstatic const struct mtk_spi_compatible mt6893_compat = {\n\t.need_pad_sel = true,\n\t.must_tx = true,\n\t.enhance_timing = true,\n\t.dma_ext = true,\n\t.no_need_unprepare = true,\n};\n\n \nstatic const struct mtk_chip_config mtk_default_chip_info = {\n\t.sample_sel = 0,\n\t.tick_delay = 0,\n};\n\nstatic const struct of_device_id mtk_spi_of_match[] = {\n\t{ .compatible = \"mediatek,spi-ipm\",\n\t\t.data = (void *)&mtk_ipm_compat,\n\t},\n\t{ .compatible = \"mediatek,mt2701-spi\",\n\t\t.data = (void *)&mtk_common_compat,\n\t},\n\t{ .compatible = \"mediatek,mt2712-spi\",\n\t\t.data = (void *)&mt2712_compat,\n\t},\n\t{ .compatible = \"mediatek,mt6589-spi\",\n\t\t.data = (void *)&mtk_common_compat,\n\t},\n\t{ .compatible = \"mediatek,mt6765-spi\",\n\t\t.data = (void *)&mt6765_compat,\n\t},\n\t{ .compatible = \"mediatek,mt7622-spi\",\n\t\t.data = (void *)&mt7622_compat,\n\t},\n\t{ .compatible = \"mediatek,mt7629-spi\",\n\t\t.data = (void *)&mt7622_compat,\n\t},\n\t{ .compatible = \"mediatek,mt8135-spi\",\n\t\t.data = (void *)&mtk_common_compat,\n\t},\n\t{ .compatible = \"mediatek,mt8173-spi\",\n\t\t.data = (void *)&mt8173_compat,\n\t},\n\t{ .compatible = \"mediatek,mt8183-spi\",\n\t\t.data = (void *)&mt8183_compat,\n\t},\n\t{ .compatible = \"mediatek,mt8192-spi\",\n\t\t.data = (void *)&mt6765_compat,\n\t},\n\t{ .compatible = \"mediatek,mt6893-spi\",\n\t\t.data = (void *)&mt6893_compat,\n\t},\n\t{}\n};\nMODULE_DEVICE_TABLE(of, mtk_spi_of_match);\n\nstatic void mtk_spi_reset(struct mtk_spi *mdata)\n{\n\tu32 reg_val;\n\n\t \n\treg_val = readl(mdata->base + SPI_CMD_REG);\n\treg_val |= SPI_CMD_RST;\n\twritel(reg_val, mdata->base + SPI_CMD_REG);\n\n\treg_val = readl(mdata->base + SPI_CMD_REG);\n\treg_val &= ~SPI_CMD_RST;\n\twritel(reg_val, mdata->base + SPI_CMD_REG);\n}\n\nstatic int mtk_spi_set_hw_cs_timing(struct spi_device *spi)\n{\n\tstruct mtk_spi *mdata = spi_master_get_devdata(spi->master);\n\tstruct spi_delay *cs_setup = &spi->cs_setup;\n\tstruct spi_delay *cs_hold = &spi->cs_hold;\n\tstruct spi_delay *cs_inactive = &spi->cs_inactive;\n\tu32 setup, hold, inactive;\n\tu32 reg_val;\n\tint delay;\n\n\tdelay = spi_delay_to_ns(cs_setup, NULL);\n\tif (delay < 0)\n\t\treturn delay;\n\tsetup = (delay * DIV_ROUND_UP(mdata->spi_clk_hz, 1000000)) / 1000;\n\n\tdelay = spi_delay_to_ns(cs_hold, NULL);\n\tif (delay < 0)\n\t\treturn delay;\n\thold = (delay * DIV_ROUND_UP(mdata->spi_clk_hz, 1000000)) / 1000;\n\n\tdelay = spi_delay_to_ns(cs_inactive, NULL);\n\tif (delay < 0)\n\t\treturn delay;\n\tinactive = (delay * DIV_ROUND_UP(mdata->spi_clk_hz, 1000000)) / 1000;\n\n\tif (hold || setup) {\n\t\treg_val = readl(mdata->base + SPI_CFG0_REG);\n\t\tif (mdata->dev_comp->enhance_timing) {\n\t\t\tif (hold) {\n\t\t\t\thold = min_t(u32, hold, 0x10000);\n\t\t\t\treg_val &= ~(0xffff << SPI_ADJUST_CFG0_CS_HOLD_OFFSET);\n\t\t\t\treg_val |= (((hold - 1) & 0xffff)\n\t\t\t\t\t<< SPI_ADJUST_CFG0_CS_HOLD_OFFSET);\n\t\t\t}\n\t\t\tif (setup) {\n\t\t\t\tsetup = min_t(u32, setup, 0x10000);\n\t\t\t\treg_val &= ~(0xffff << SPI_ADJUST_CFG0_CS_SETUP_OFFSET);\n\t\t\t\treg_val |= (((setup - 1) & 0xffff)\n\t\t\t\t\t<< SPI_ADJUST_CFG0_CS_SETUP_OFFSET);\n\t\t\t}\n\t\t} else {\n\t\t\tif (hold) {\n\t\t\t\thold = min_t(u32, hold, 0x100);\n\t\t\t\treg_val &= ~(0xff << SPI_CFG0_CS_HOLD_OFFSET);\n\t\t\t\treg_val |= (((hold - 1) & 0xff) << SPI_CFG0_CS_HOLD_OFFSET);\n\t\t\t}\n\t\t\tif (setup) {\n\t\t\t\tsetup = min_t(u32, setup, 0x100);\n\t\t\t\treg_val &= ~(0xff << SPI_CFG0_CS_SETUP_OFFSET);\n\t\t\t\treg_val |= (((setup - 1) & 0xff)\n\t\t\t\t\t<< SPI_CFG0_CS_SETUP_OFFSET);\n\t\t\t}\n\t\t}\n\t\twritel(reg_val, mdata->base + SPI_CFG0_REG);\n\t}\n\n\tif (inactive) {\n\t\tinactive = min_t(u32, inactive, 0x100);\n\t\treg_val = readl(mdata->base + SPI_CFG1_REG);\n\t\treg_val &= ~SPI_CFG1_CS_IDLE_MASK;\n\t\treg_val |= (((inactive - 1) & 0xff) << SPI_CFG1_CS_IDLE_OFFSET);\n\t\twritel(reg_val, mdata->base + SPI_CFG1_REG);\n\t}\n\n\treturn 0;\n}\n\nstatic int mtk_spi_hw_init(struct spi_master *master,\n\t\t\t   struct spi_device *spi)\n{\n\tu16 cpha, cpol;\n\tu32 reg_val;\n\tstruct mtk_chip_config *chip_config = spi->controller_data;\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tcpha = spi->mode & SPI_CPHA ? 1 : 0;\n\tcpol = spi->mode & SPI_CPOL ? 1 : 0;\n\n\treg_val = readl(mdata->base + SPI_CMD_REG);\n\tif (mdata->dev_comp->ipm_design) {\n\t\t \n\t\treg_val |= SPI_CMD_IPM_NONIDLE_MODE;\n\t\tif (spi->mode & SPI_LOOP)\n\t\t\treg_val |= SPI_CMD_IPM_SPIM_LOOP;\n\t\telse\n\t\t\treg_val &= ~SPI_CMD_IPM_SPIM_LOOP;\n\t}\n\n\tif (cpha)\n\t\treg_val |= SPI_CMD_CPHA;\n\telse\n\t\treg_val &= ~SPI_CMD_CPHA;\n\tif (cpol)\n\t\treg_val |= SPI_CMD_CPOL;\n\telse\n\t\treg_val &= ~SPI_CMD_CPOL;\n\n\t \n\tif (spi->mode & SPI_LSB_FIRST) {\n\t\treg_val &= ~SPI_CMD_TXMSBF;\n\t\treg_val &= ~SPI_CMD_RXMSBF;\n\t} else {\n\t\treg_val |= SPI_CMD_TXMSBF;\n\t\treg_val |= SPI_CMD_RXMSBF;\n\t}\n\n\t \n#ifdef __LITTLE_ENDIAN\n\treg_val &= ~SPI_CMD_TX_ENDIAN;\n\treg_val &= ~SPI_CMD_RX_ENDIAN;\n#else\n\treg_val |= SPI_CMD_TX_ENDIAN;\n\treg_val |= SPI_CMD_RX_ENDIAN;\n#endif\n\n\tif (mdata->dev_comp->enhance_timing) {\n\t\t \n\t\tif (spi->mode & SPI_CS_HIGH)\n\t\t\treg_val |= SPI_CMD_CS_POL;\n\t\telse\n\t\t\treg_val &= ~SPI_CMD_CS_POL;\n\n\t\tif (chip_config->sample_sel)\n\t\t\treg_val |= SPI_CMD_SAMPLE_SEL;\n\t\telse\n\t\t\treg_val &= ~SPI_CMD_SAMPLE_SEL;\n\t}\n\n\t \n\treg_val |= SPI_CMD_FINISH_IE | SPI_CMD_PAUSE_IE;\n\n\t \n\treg_val &= ~(SPI_CMD_TX_DMA | SPI_CMD_RX_DMA);\n\n\t \n\treg_val &= ~SPI_CMD_DEASSERT;\n\n\twritel(reg_val, mdata->base + SPI_CMD_REG);\n\n\t \n\tif (mdata->dev_comp->need_pad_sel)\n\t\twritel(mdata->pad_sel[spi_get_chipselect(spi, 0)],\n\t\t       mdata->base + SPI_PAD_SEL_REG);\n\n\t \n\tif (mdata->dev_comp->enhance_timing) {\n\t\tif (mdata->dev_comp->ipm_design) {\n\t\t\treg_val = readl(mdata->base + SPI_CMD_REG);\n\t\t\treg_val &= ~SPI_CMD_IPM_GET_TICKDLY_MASK;\n\t\t\treg_val |= ((chip_config->tick_delay & 0x7)\n\t\t\t\t    << SPI_CMD_IPM_GET_TICKDLY_OFFSET);\n\t\t\twritel(reg_val, mdata->base + SPI_CMD_REG);\n\t\t} else {\n\t\t\treg_val = readl(mdata->base + SPI_CFG1_REG);\n\t\t\treg_val &= ~SPI_CFG1_GET_TICK_DLY_MASK;\n\t\t\treg_val |= ((chip_config->tick_delay & 0x7)\n\t\t\t\t    << SPI_CFG1_GET_TICK_DLY_OFFSET);\n\t\t\twritel(reg_val, mdata->base + SPI_CFG1_REG);\n\t\t}\n\t} else {\n\t\treg_val = readl(mdata->base + SPI_CFG1_REG);\n\t\treg_val &= ~SPI_CFG1_GET_TICK_DLY_MASK_V1;\n\t\treg_val |= ((chip_config->tick_delay & 0x3)\n\t\t\t    << SPI_CFG1_GET_TICK_DLY_OFFSET_V1);\n\t\twritel(reg_val, mdata->base + SPI_CFG1_REG);\n\t}\n\n\t \n\tmtk_spi_set_hw_cs_timing(spi);\n\treturn 0;\n}\n\nstatic int mtk_spi_prepare_message(struct spi_master *master,\n\t\t\t\t   struct spi_message *msg)\n{\n\treturn mtk_spi_hw_init(master, msg->spi);\n}\n\nstatic void mtk_spi_set_cs(struct spi_device *spi, bool enable)\n{\n\tu32 reg_val;\n\tstruct mtk_spi *mdata = spi_master_get_devdata(spi->master);\n\n\tif (spi->mode & SPI_CS_HIGH)\n\t\tenable = !enable;\n\n\treg_val = readl(mdata->base + SPI_CMD_REG);\n\tif (!enable) {\n\t\treg_val |= SPI_CMD_PAUSE_EN;\n\t\twritel(reg_val, mdata->base + SPI_CMD_REG);\n\t} else {\n\t\treg_val &= ~SPI_CMD_PAUSE_EN;\n\t\twritel(reg_val, mdata->base + SPI_CMD_REG);\n\t\tmdata->state = MTK_SPI_IDLE;\n\t\tmtk_spi_reset(mdata);\n\t}\n}\n\nstatic void mtk_spi_prepare_transfer(struct spi_master *master,\n\t\t\t\t     u32 speed_hz)\n{\n\tu32 div, sck_time, reg_val;\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tif (speed_hz < mdata->spi_clk_hz / 2)\n\t\tdiv = DIV_ROUND_UP(mdata->spi_clk_hz, speed_hz);\n\telse\n\t\tdiv = 1;\n\n\tsck_time = (div + 1) / 2;\n\n\tif (mdata->dev_comp->enhance_timing) {\n\t\treg_val = readl(mdata->base + SPI_CFG2_REG);\n\t\treg_val &= ~(0xffff << SPI_CFG2_SCK_HIGH_OFFSET);\n\t\treg_val |= (((sck_time - 1) & 0xffff)\n\t\t\t   << SPI_CFG2_SCK_HIGH_OFFSET);\n\t\treg_val &= ~(0xffff << SPI_CFG2_SCK_LOW_OFFSET);\n\t\treg_val |= (((sck_time - 1) & 0xffff)\n\t\t\t   << SPI_CFG2_SCK_LOW_OFFSET);\n\t\twritel(reg_val, mdata->base + SPI_CFG2_REG);\n\t} else {\n\t\treg_val = readl(mdata->base + SPI_CFG0_REG);\n\t\treg_val &= ~(0xff << SPI_CFG0_SCK_HIGH_OFFSET);\n\t\treg_val |= (((sck_time - 1) & 0xff)\n\t\t\t   << SPI_CFG0_SCK_HIGH_OFFSET);\n\t\treg_val &= ~(0xff << SPI_CFG0_SCK_LOW_OFFSET);\n\t\treg_val |= (((sck_time - 1) & 0xff) << SPI_CFG0_SCK_LOW_OFFSET);\n\t\twritel(reg_val, mdata->base + SPI_CFG0_REG);\n\t}\n}\n\nstatic void mtk_spi_setup_packet(struct spi_master *master)\n{\n\tu32 packet_size, packet_loop, reg_val;\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tif (mdata->dev_comp->ipm_design)\n\t\tpacket_size = min_t(u32,\n\t\t\t\t    mdata->xfer_len,\n\t\t\t\t    MTK_SPI_IPM_PACKET_SIZE);\n\telse\n\t\tpacket_size = min_t(u32,\n\t\t\t\t    mdata->xfer_len,\n\t\t\t\t    MTK_SPI_PACKET_SIZE);\n\n\tpacket_loop = mdata->xfer_len / packet_size;\n\n\treg_val = readl(mdata->base + SPI_CFG1_REG);\n\tif (mdata->dev_comp->ipm_design)\n\t\treg_val &= ~SPI_CFG1_IPM_PACKET_LENGTH_MASK;\n\telse\n\t\treg_val &= ~SPI_CFG1_PACKET_LENGTH_MASK;\n\treg_val |= (packet_size - 1) << SPI_CFG1_PACKET_LENGTH_OFFSET;\n\treg_val &= ~SPI_CFG1_PACKET_LOOP_MASK;\n\treg_val |= (packet_loop - 1) << SPI_CFG1_PACKET_LOOP_OFFSET;\n\twritel(reg_val, mdata->base + SPI_CFG1_REG);\n}\n\nstatic void mtk_spi_enable_transfer(struct spi_master *master)\n{\n\tu32 cmd;\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tcmd = readl(mdata->base + SPI_CMD_REG);\n\tif (mdata->state == MTK_SPI_IDLE)\n\t\tcmd |= SPI_CMD_ACT;\n\telse\n\t\tcmd |= SPI_CMD_RESUME;\n\twritel(cmd, mdata->base + SPI_CMD_REG);\n}\n\nstatic int mtk_spi_get_mult_delta(struct mtk_spi *mdata, u32 xfer_len)\n{\n\tu32 mult_delta = 0;\n\n\tif (mdata->dev_comp->ipm_design) {\n\t\tif (xfer_len > MTK_SPI_IPM_PACKET_SIZE)\n\t\t\tmult_delta = xfer_len % MTK_SPI_IPM_PACKET_SIZE;\n\t} else {\n\t\tif (xfer_len > MTK_SPI_PACKET_SIZE)\n\t\t\tmult_delta = xfer_len % MTK_SPI_PACKET_SIZE;\n\t}\n\n\treturn mult_delta;\n}\n\nstatic void mtk_spi_update_mdata_len(struct spi_master *master)\n{\n\tint mult_delta;\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tif (mdata->tx_sgl_len && mdata->rx_sgl_len) {\n\t\tif (mdata->tx_sgl_len > mdata->rx_sgl_len) {\n\t\t\tmult_delta = mtk_spi_get_mult_delta(mdata, mdata->rx_sgl_len);\n\t\t\tmdata->xfer_len = mdata->rx_sgl_len - mult_delta;\n\t\t\tmdata->rx_sgl_len = mult_delta;\n\t\t\tmdata->tx_sgl_len -= mdata->xfer_len;\n\t\t} else {\n\t\t\tmult_delta = mtk_spi_get_mult_delta(mdata, mdata->tx_sgl_len);\n\t\t\tmdata->xfer_len = mdata->tx_sgl_len - mult_delta;\n\t\t\tmdata->tx_sgl_len = mult_delta;\n\t\t\tmdata->rx_sgl_len -= mdata->xfer_len;\n\t\t}\n\t} else if (mdata->tx_sgl_len) {\n\t\tmult_delta = mtk_spi_get_mult_delta(mdata, mdata->tx_sgl_len);\n\t\tmdata->xfer_len = mdata->tx_sgl_len - mult_delta;\n\t\tmdata->tx_sgl_len = mult_delta;\n\t} else if (mdata->rx_sgl_len) {\n\t\tmult_delta = mtk_spi_get_mult_delta(mdata, mdata->rx_sgl_len);\n\t\tmdata->xfer_len = mdata->rx_sgl_len - mult_delta;\n\t\tmdata->rx_sgl_len = mult_delta;\n\t}\n}\n\nstatic void mtk_spi_setup_dma_addr(struct spi_master *master,\n\t\t\t\t   struct spi_transfer *xfer)\n{\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tif (mdata->tx_sgl) {\n\t\twritel((u32)(xfer->tx_dma & MTK_SPI_32BITS_MASK),\n\t\t       mdata->base + SPI_TX_SRC_REG);\n#ifdef CONFIG_ARCH_DMA_ADDR_T_64BIT\n\t\tif (mdata->dev_comp->dma_ext)\n\t\t\twritel((u32)(xfer->tx_dma >> 32),\n\t\t\t       mdata->base + SPI_TX_SRC_REG_64);\n#endif\n\t}\n\n\tif (mdata->rx_sgl) {\n\t\twritel((u32)(xfer->rx_dma & MTK_SPI_32BITS_MASK),\n\t\t       mdata->base + SPI_RX_DST_REG);\n#ifdef CONFIG_ARCH_DMA_ADDR_T_64BIT\n\t\tif (mdata->dev_comp->dma_ext)\n\t\t\twritel((u32)(xfer->rx_dma >> 32),\n\t\t\t       mdata->base + SPI_RX_DST_REG_64);\n#endif\n\t}\n}\n\nstatic int mtk_spi_fifo_transfer(struct spi_master *master,\n\t\t\t\t struct spi_device *spi,\n\t\t\t\t struct spi_transfer *xfer)\n{\n\tint cnt, remainder;\n\tu32 reg_val;\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tmdata->cur_transfer = xfer;\n\tmdata->xfer_len = min(MTK_SPI_MAX_FIFO_SIZE, xfer->len);\n\tmdata->num_xfered = 0;\n\tmtk_spi_prepare_transfer(master, xfer->speed_hz);\n\tmtk_spi_setup_packet(master);\n\n\tif (xfer->tx_buf) {\n\t\tcnt = xfer->len / 4;\n\t\tiowrite32_rep(mdata->base + SPI_TX_DATA_REG, xfer->tx_buf, cnt);\n\t\tremainder = xfer->len % 4;\n\t\tif (remainder > 0) {\n\t\t\treg_val = 0;\n\t\t\tmemcpy(&reg_val, xfer->tx_buf + (cnt * 4), remainder);\n\t\t\twritel(reg_val, mdata->base + SPI_TX_DATA_REG);\n\t\t}\n\t}\n\n\tmtk_spi_enable_transfer(master);\n\n\treturn 1;\n}\n\nstatic int mtk_spi_dma_transfer(struct spi_master *master,\n\t\t\t\tstruct spi_device *spi,\n\t\t\t\tstruct spi_transfer *xfer)\n{\n\tint cmd;\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tmdata->tx_sgl = NULL;\n\tmdata->rx_sgl = NULL;\n\tmdata->tx_sgl_len = 0;\n\tmdata->rx_sgl_len = 0;\n\tmdata->cur_transfer = xfer;\n\tmdata->num_xfered = 0;\n\n\tmtk_spi_prepare_transfer(master, xfer->speed_hz);\n\n\tcmd = readl(mdata->base + SPI_CMD_REG);\n\tif (xfer->tx_buf)\n\t\tcmd |= SPI_CMD_TX_DMA;\n\tif (xfer->rx_buf)\n\t\tcmd |= SPI_CMD_RX_DMA;\n\twritel(cmd, mdata->base + SPI_CMD_REG);\n\n\tif (xfer->tx_buf)\n\t\tmdata->tx_sgl = xfer->tx_sg.sgl;\n\tif (xfer->rx_buf)\n\t\tmdata->rx_sgl = xfer->rx_sg.sgl;\n\n\tif (mdata->tx_sgl) {\n\t\txfer->tx_dma = sg_dma_address(mdata->tx_sgl);\n\t\tmdata->tx_sgl_len = sg_dma_len(mdata->tx_sgl);\n\t}\n\tif (mdata->rx_sgl) {\n\t\txfer->rx_dma = sg_dma_address(mdata->rx_sgl);\n\t\tmdata->rx_sgl_len = sg_dma_len(mdata->rx_sgl);\n\t}\n\n\tmtk_spi_update_mdata_len(master);\n\tmtk_spi_setup_packet(master);\n\tmtk_spi_setup_dma_addr(master, xfer);\n\tmtk_spi_enable_transfer(master);\n\n\treturn 1;\n}\n\nstatic int mtk_spi_transfer_one(struct spi_master *master,\n\t\t\t\tstruct spi_device *spi,\n\t\t\t\tstruct spi_transfer *xfer)\n{\n\tstruct mtk_spi *mdata = spi_master_get_devdata(spi->master);\n\tu32 reg_val = 0;\n\n\t \n\tif (mdata->dev_comp->ipm_design) {\n\t\tif (!xfer->tx_buf || !xfer->rx_buf) {\n\t\t\treg_val |= SPI_CFG3_IPM_HALF_DUPLEX_EN;\n\t\t\tif (xfer->rx_buf)\n\t\t\t\treg_val |= SPI_CFG3_IPM_HALF_DUPLEX_DIR;\n\t\t}\n\t\twritel(reg_val, mdata->base + SPI_CFG3_IPM_REG);\n\t}\n\n\tif (master->can_dma(master, spi, xfer))\n\t\treturn mtk_spi_dma_transfer(master, spi, xfer);\n\telse\n\t\treturn mtk_spi_fifo_transfer(master, spi, xfer);\n}\n\nstatic bool mtk_spi_can_dma(struct spi_master *master,\n\t\t\t    struct spi_device *spi,\n\t\t\t    struct spi_transfer *xfer)\n{\n\t \n\treturn (xfer->len > MTK_SPI_MAX_FIFO_SIZE &&\n\t\t(unsigned long)xfer->tx_buf % 4 == 0 &&\n\t\t(unsigned long)xfer->rx_buf % 4 == 0);\n}\n\nstatic int mtk_spi_setup(struct spi_device *spi)\n{\n\tstruct mtk_spi *mdata = spi_master_get_devdata(spi->master);\n\n\tif (!spi->controller_data)\n\t\tspi->controller_data = (void *)&mtk_default_chip_info;\n\n\tif (mdata->dev_comp->need_pad_sel && spi_get_csgpiod(spi, 0))\n\t\t \n\t\tgpiod_direction_output(spi_get_csgpiod(spi, 0), 0);\n\n\treturn 0;\n}\n\nstatic irqreturn_t mtk_spi_interrupt(int irq, void *dev_id)\n{\n\tu32 cmd, reg_val, cnt, remainder, len;\n\tstruct spi_master *master = dev_id;\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\tstruct spi_transfer *trans = mdata->cur_transfer;\n\n\treg_val = readl(mdata->base + SPI_STATUS0_REG);\n\tif (reg_val & MTK_SPI_PAUSE_INT_STATUS)\n\t\tmdata->state = MTK_SPI_PAUSED;\n\telse\n\t\tmdata->state = MTK_SPI_IDLE;\n\n\t \n\tif (mdata->use_spimem) {\n\t\tcomplete(&mdata->spimem_done);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tif (!master->can_dma(master, NULL, trans)) {\n\t\tif (trans->rx_buf) {\n\t\t\tcnt = mdata->xfer_len / 4;\n\t\t\tioread32_rep(mdata->base + SPI_RX_DATA_REG,\n\t\t\t\t     trans->rx_buf + mdata->num_xfered, cnt);\n\t\t\tremainder = mdata->xfer_len % 4;\n\t\t\tif (remainder > 0) {\n\t\t\t\treg_val = readl(mdata->base + SPI_RX_DATA_REG);\n\t\t\t\tmemcpy(trans->rx_buf +\n\t\t\t\t\tmdata->num_xfered +\n\t\t\t\t\t(cnt * 4),\n\t\t\t\t\t&reg_val,\n\t\t\t\t\tremainder);\n\t\t\t}\n\t\t}\n\n\t\tmdata->num_xfered += mdata->xfer_len;\n\t\tif (mdata->num_xfered == trans->len) {\n\t\t\tspi_finalize_current_transfer(master);\n\t\t\treturn IRQ_HANDLED;\n\t\t}\n\n\t\tlen = trans->len - mdata->num_xfered;\n\t\tmdata->xfer_len = min(MTK_SPI_MAX_FIFO_SIZE, len);\n\t\tmtk_spi_setup_packet(master);\n\n\t\tcnt = mdata->xfer_len / 4;\n\t\tiowrite32_rep(mdata->base + SPI_TX_DATA_REG,\n\t\t\t\ttrans->tx_buf + mdata->num_xfered, cnt);\n\n\t\tremainder = mdata->xfer_len % 4;\n\t\tif (remainder > 0) {\n\t\t\treg_val = 0;\n\t\t\tmemcpy(&reg_val,\n\t\t\t\ttrans->tx_buf + (cnt * 4) + mdata->num_xfered,\n\t\t\t\tremainder);\n\t\t\twritel(reg_val, mdata->base + SPI_TX_DATA_REG);\n\t\t}\n\n\t\tmtk_spi_enable_transfer(master);\n\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tif (mdata->tx_sgl)\n\t\ttrans->tx_dma += mdata->xfer_len;\n\tif (mdata->rx_sgl)\n\t\ttrans->rx_dma += mdata->xfer_len;\n\n\tif (mdata->tx_sgl && (mdata->tx_sgl_len == 0)) {\n\t\tmdata->tx_sgl = sg_next(mdata->tx_sgl);\n\t\tif (mdata->tx_sgl) {\n\t\t\ttrans->tx_dma = sg_dma_address(mdata->tx_sgl);\n\t\t\tmdata->tx_sgl_len = sg_dma_len(mdata->tx_sgl);\n\t\t}\n\t}\n\tif (mdata->rx_sgl && (mdata->rx_sgl_len == 0)) {\n\t\tmdata->rx_sgl = sg_next(mdata->rx_sgl);\n\t\tif (mdata->rx_sgl) {\n\t\t\ttrans->rx_dma = sg_dma_address(mdata->rx_sgl);\n\t\t\tmdata->rx_sgl_len = sg_dma_len(mdata->rx_sgl);\n\t\t}\n\t}\n\n\tif (!mdata->tx_sgl && !mdata->rx_sgl) {\n\t\t \n\t\tcmd = readl(mdata->base + SPI_CMD_REG);\n\t\tcmd &= ~SPI_CMD_TX_DMA;\n\t\tcmd &= ~SPI_CMD_RX_DMA;\n\t\twritel(cmd, mdata->base + SPI_CMD_REG);\n\n\t\tspi_finalize_current_transfer(master);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tmtk_spi_update_mdata_len(master);\n\tmtk_spi_setup_packet(master);\n\tmtk_spi_setup_dma_addr(master, trans);\n\tmtk_spi_enable_transfer(master);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int mtk_spi_mem_adjust_op_size(struct spi_mem *mem,\n\t\t\t\t      struct spi_mem_op *op)\n{\n\tint opcode_len;\n\n\tif (op->data.dir != SPI_MEM_NO_DATA) {\n\t\topcode_len = 1 + op->addr.nbytes + op->dummy.nbytes;\n\t\tif (opcode_len + op->data.nbytes > MTK_SPI_IPM_PACKET_SIZE) {\n\t\t\top->data.nbytes = MTK_SPI_IPM_PACKET_SIZE - opcode_len;\n\t\t\t \n\t\t\top->data.nbytes -= op->data.nbytes % 4;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic bool mtk_spi_mem_supports_op(struct spi_mem *mem,\n\t\t\t\t    const struct spi_mem_op *op)\n{\n\tif (!spi_mem_default_supports_op(mem, op))\n\t\treturn false;\n\n\tif (op->addr.nbytes && op->dummy.nbytes &&\n\t    op->addr.buswidth != op->dummy.buswidth)\n\t\treturn false;\n\n\tif (op->addr.nbytes + op->dummy.nbytes > 16)\n\t\treturn false;\n\n\tif (op->data.nbytes > MTK_SPI_IPM_PACKET_SIZE) {\n\t\tif (op->data.nbytes / MTK_SPI_IPM_PACKET_SIZE >\n\t\t    MTK_SPI_IPM_PACKET_LOOP ||\n\t\t    op->data.nbytes % MTK_SPI_IPM_PACKET_SIZE != 0)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void mtk_spi_mem_setup_dma_xfer(struct spi_master *master,\n\t\t\t\t       const struct spi_mem_op *op)\n{\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\twritel((u32)(mdata->tx_dma & MTK_SPI_32BITS_MASK),\n\t       mdata->base + SPI_TX_SRC_REG);\n#ifdef CONFIG_ARCH_DMA_ADDR_T_64BIT\n\tif (mdata->dev_comp->dma_ext)\n\t\twritel((u32)(mdata->tx_dma >> 32),\n\t\t       mdata->base + SPI_TX_SRC_REG_64);\n#endif\n\n\tif (op->data.dir == SPI_MEM_DATA_IN) {\n\t\twritel((u32)(mdata->rx_dma & MTK_SPI_32BITS_MASK),\n\t\t       mdata->base + SPI_RX_DST_REG);\n#ifdef CONFIG_ARCH_DMA_ADDR_T_64BIT\n\t\tif (mdata->dev_comp->dma_ext)\n\t\t\twritel((u32)(mdata->rx_dma >> 32),\n\t\t\t       mdata->base + SPI_RX_DST_REG_64);\n#endif\n\t}\n}\n\nstatic int mtk_spi_transfer_wait(struct spi_mem *mem,\n\t\t\t\t const struct spi_mem_op *op)\n{\n\tstruct mtk_spi *mdata = spi_master_get_devdata(mem->spi->master);\n\t \n\tu64 ms = 8000LL;\n\n\tif (op->data.dir == SPI_MEM_NO_DATA)\n\t\tms *= 32;  \n\telse\n\t\tms *= op->data.nbytes;\n\tms = div_u64(ms, mem->spi->max_speed_hz);\n\tms += ms + 1000;  \n\n\tif (ms > UINT_MAX)\n\t\tms = UINT_MAX;\n\n\tif (!wait_for_completion_timeout(&mdata->spimem_done,\n\t\t\t\t\t msecs_to_jiffies(ms))) {\n\t\tdev_err(mdata->dev, \"spi-mem transfer timeout\\n\");\n\t\treturn -ETIMEDOUT;\n\t}\n\n\treturn 0;\n}\n\nstatic int mtk_spi_mem_exec_op(struct spi_mem *mem,\n\t\t\t       const struct spi_mem_op *op)\n{\n\tstruct mtk_spi *mdata = spi_master_get_devdata(mem->spi->master);\n\tu32 reg_val, nio, tx_size;\n\tchar *tx_tmp_buf, *rx_tmp_buf;\n\tint ret = 0;\n\n\tmdata->use_spimem = true;\n\treinit_completion(&mdata->spimem_done);\n\n\tmtk_spi_reset(mdata);\n\tmtk_spi_hw_init(mem->spi->master, mem->spi);\n\tmtk_spi_prepare_transfer(mem->spi->master, mem->spi->max_speed_hz);\n\n\treg_val = readl(mdata->base + SPI_CFG3_IPM_REG);\n\t \n\treg_val &= ~SPI_CFG3_IPM_CMD_BYTELEN_MASK;\n\treg_val |= 1 << SPI_CFG3_IPM_CMD_BYTELEN_OFFSET;\n\n\t \n\treg_val &= ~SPI_CFG3_IPM_ADDR_BYTELEN_MASK;\n\tif (op->addr.nbytes || op->dummy.nbytes)\n\t\treg_val |= (op->addr.nbytes + op->dummy.nbytes) <<\n\t\t\t    SPI_CFG3_IPM_ADDR_BYTELEN_OFFSET;\n\n\t \n\tif (op->data.dir == SPI_MEM_NO_DATA) {\n\t\treg_val |= SPI_CFG3_IPM_NODATA_FLAG;\n\t\twritel(0, mdata->base + SPI_CFG1_REG);\n\t} else {\n\t\treg_val &= ~SPI_CFG3_IPM_NODATA_FLAG;\n\t\tmdata->xfer_len = op->data.nbytes;\n\t\tmtk_spi_setup_packet(mem->spi->master);\n\t}\n\n\tif (op->addr.nbytes || op->dummy.nbytes) {\n\t\tif (op->addr.buswidth == 1 || op->dummy.buswidth == 1)\n\t\t\treg_val |= SPI_CFG3_IPM_XMODE_EN;\n\t\telse\n\t\t\treg_val &= ~SPI_CFG3_IPM_XMODE_EN;\n\t}\n\n\tif (op->addr.buswidth == 2 ||\n\t    op->dummy.buswidth == 2 ||\n\t    op->data.buswidth == 2)\n\t\tnio = 2;\n\telse if (op->addr.buswidth == 4 ||\n\t\t op->dummy.buswidth == 4 ||\n\t\t op->data.buswidth == 4)\n\t\tnio = 4;\n\telse\n\t\tnio = 1;\n\n\treg_val &= ~SPI_CFG3_IPM_CMD_PIN_MODE_MASK;\n\treg_val |= PIN_MODE_CFG(nio);\n\n\treg_val |= SPI_CFG3_IPM_HALF_DUPLEX_EN;\n\tif (op->data.dir == SPI_MEM_DATA_IN)\n\t\treg_val |= SPI_CFG3_IPM_HALF_DUPLEX_DIR;\n\telse\n\t\treg_val &= ~SPI_CFG3_IPM_HALF_DUPLEX_DIR;\n\twritel(reg_val, mdata->base + SPI_CFG3_IPM_REG);\n\n\ttx_size = 1 + op->addr.nbytes + op->dummy.nbytes;\n\tif (op->data.dir == SPI_MEM_DATA_OUT)\n\t\ttx_size += op->data.nbytes;\n\n\ttx_size = max_t(u32, tx_size, 32);\n\n\ttx_tmp_buf = kzalloc(tx_size, GFP_KERNEL | GFP_DMA);\n\tif (!tx_tmp_buf) {\n\t\tmdata->use_spimem = false;\n\t\treturn -ENOMEM;\n\t}\n\n\ttx_tmp_buf[0] = op->cmd.opcode;\n\n\tif (op->addr.nbytes) {\n\t\tint i;\n\n\t\tfor (i = 0; i < op->addr.nbytes; i++)\n\t\t\ttx_tmp_buf[i + 1] = op->addr.val >>\n\t\t\t\t\t(8 * (op->addr.nbytes - i - 1));\n\t}\n\n\tif (op->dummy.nbytes)\n\t\tmemset(tx_tmp_buf + op->addr.nbytes + 1,\n\t\t       0xff,\n\t\t       op->dummy.nbytes);\n\n\tif (op->data.nbytes && op->data.dir == SPI_MEM_DATA_OUT)\n\t\tmemcpy(tx_tmp_buf + op->dummy.nbytes + op->addr.nbytes + 1,\n\t\t       op->data.buf.out,\n\t\t       op->data.nbytes);\n\n\tmdata->tx_dma = dma_map_single(mdata->dev, tx_tmp_buf,\n\t\t\t\t       tx_size, DMA_TO_DEVICE);\n\tif (dma_mapping_error(mdata->dev, mdata->tx_dma)) {\n\t\tret = -ENOMEM;\n\t\tgoto err_exit;\n\t}\n\n\tif (op->data.dir == SPI_MEM_DATA_IN) {\n\t\tif (!IS_ALIGNED((size_t)op->data.buf.in, 4)) {\n\t\t\trx_tmp_buf = kzalloc(op->data.nbytes,\n\t\t\t\t\t     GFP_KERNEL | GFP_DMA);\n\t\t\tif (!rx_tmp_buf) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto unmap_tx_dma;\n\t\t\t}\n\t\t} else {\n\t\t\trx_tmp_buf = op->data.buf.in;\n\t\t}\n\n\t\tmdata->rx_dma = dma_map_single(mdata->dev,\n\t\t\t\t\t       rx_tmp_buf,\n\t\t\t\t\t       op->data.nbytes,\n\t\t\t\t\t       DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(mdata->dev, mdata->rx_dma)) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto kfree_rx_tmp_buf;\n\t\t}\n\t}\n\n\treg_val = readl(mdata->base + SPI_CMD_REG);\n\treg_val |= SPI_CMD_TX_DMA;\n\tif (op->data.dir == SPI_MEM_DATA_IN)\n\t\treg_val |= SPI_CMD_RX_DMA;\n\twritel(reg_val, mdata->base + SPI_CMD_REG);\n\n\tmtk_spi_mem_setup_dma_xfer(mem->spi->master, op);\n\n\tmtk_spi_enable_transfer(mem->spi->master);\n\n\t \n\tret = mtk_spi_transfer_wait(mem, op);\n\tif (ret)\n\t\tgoto unmap_rx_dma;\n\n\t \n\treg_val = readl(mdata->base + SPI_CMD_REG);\n\treg_val &= ~SPI_CMD_TX_DMA;\n\tif (op->data.dir == SPI_MEM_DATA_IN)\n\t\treg_val &= ~SPI_CMD_RX_DMA;\n\twritel(reg_val, mdata->base + SPI_CMD_REG);\n\nunmap_rx_dma:\n\tif (op->data.dir == SPI_MEM_DATA_IN) {\n\t\tdma_unmap_single(mdata->dev, mdata->rx_dma,\n\t\t\t\t op->data.nbytes, DMA_FROM_DEVICE);\n\t\tif (!IS_ALIGNED((size_t)op->data.buf.in, 4))\n\t\t\tmemcpy(op->data.buf.in, rx_tmp_buf, op->data.nbytes);\n\t}\nkfree_rx_tmp_buf:\n\tif (op->data.dir == SPI_MEM_DATA_IN &&\n\t    !IS_ALIGNED((size_t)op->data.buf.in, 4))\n\t\tkfree(rx_tmp_buf);\nunmap_tx_dma:\n\tdma_unmap_single(mdata->dev, mdata->tx_dma,\n\t\t\t tx_size, DMA_TO_DEVICE);\nerr_exit:\n\tkfree(tx_tmp_buf);\n\tmdata->use_spimem = false;\n\n\treturn ret;\n}\n\nstatic const struct spi_controller_mem_ops mtk_spi_mem_ops = {\n\t.adjust_op_size = mtk_spi_mem_adjust_op_size,\n\t.supports_op = mtk_spi_mem_supports_op,\n\t.exec_op = mtk_spi_mem_exec_op,\n};\n\nstatic int mtk_spi_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct spi_master *master;\n\tstruct mtk_spi *mdata;\n\tint i, irq, ret, addr_bits;\n\n\tmaster = devm_spi_alloc_master(dev, sizeof(*mdata));\n\tif (!master)\n\t\treturn dev_err_probe(dev, -ENOMEM, \"failed to alloc spi master\\n\");\n\n\tmaster->auto_runtime_pm = true;\n\tmaster->dev.of_node = dev->of_node;\n\tmaster->mode_bits = SPI_CPOL | SPI_CPHA | SPI_LSB_FIRST;\n\n\tmaster->set_cs = mtk_spi_set_cs;\n\tmaster->prepare_message = mtk_spi_prepare_message;\n\tmaster->transfer_one = mtk_spi_transfer_one;\n\tmaster->can_dma = mtk_spi_can_dma;\n\tmaster->setup = mtk_spi_setup;\n\tmaster->set_cs_timing = mtk_spi_set_hw_cs_timing;\n\tmaster->use_gpio_descriptors = true;\n\n\tmdata = spi_master_get_devdata(master);\n\tmdata->dev_comp = device_get_match_data(dev);\n\n\tif (mdata->dev_comp->enhance_timing)\n\t\tmaster->mode_bits |= SPI_CS_HIGH;\n\n\tif (mdata->dev_comp->must_tx)\n\t\tmaster->flags = SPI_CONTROLLER_MUST_TX;\n\tif (mdata->dev_comp->ipm_design)\n\t\tmaster->mode_bits |= SPI_LOOP | SPI_RX_DUAL | SPI_TX_DUAL |\n\t\t\t\t     SPI_RX_QUAD | SPI_TX_QUAD;\n\n\tif (mdata->dev_comp->ipm_design) {\n\t\tmdata->dev = dev;\n\t\tmaster->mem_ops = &mtk_spi_mem_ops;\n\t\tinit_completion(&mdata->spimem_done);\n\t}\n\n\tif (mdata->dev_comp->need_pad_sel) {\n\t\tmdata->pad_num = of_property_count_u32_elems(dev->of_node,\n\t\t\t\"mediatek,pad-select\");\n\t\tif (mdata->pad_num < 0)\n\t\t\treturn dev_err_probe(dev, -EINVAL,\n\t\t\t\t\"No 'mediatek,pad-select' property\\n\");\n\n\t\tmdata->pad_sel = devm_kmalloc_array(dev, mdata->pad_num,\n\t\t\t\t\t\t    sizeof(u32), GFP_KERNEL);\n\t\tif (!mdata->pad_sel)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < mdata->pad_num; i++) {\n\t\t\tof_property_read_u32_index(dev->of_node,\n\t\t\t\t\t\t   \"mediatek,pad-select\",\n\t\t\t\t\t\t   i, &mdata->pad_sel[i]);\n\t\t\tif (mdata->pad_sel[i] > MT8173_SPI_MAX_PAD_SEL)\n\t\t\t\treturn dev_err_probe(dev, -EINVAL,\n\t\t\t\t\t\t     \"wrong pad-sel[%d]: %u\\n\",\n\t\t\t\t\t\t     i, mdata->pad_sel[i]);\n\t\t}\n\t}\n\n\tplatform_set_drvdata(pdev, master);\n\tmdata->base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(mdata->base))\n\t\treturn PTR_ERR(mdata->base);\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tif (!dev->dma_mask)\n\t\tdev->dma_mask = &dev->coherent_dma_mask;\n\n\tif (mdata->dev_comp->ipm_design)\n\t\tdma_set_max_seg_size(dev, SZ_16M);\n\telse\n\t\tdma_set_max_seg_size(dev, SZ_256K);\n\n\tmdata->parent_clk = devm_clk_get(dev, \"parent-clk\");\n\tif (IS_ERR(mdata->parent_clk))\n\t\treturn dev_err_probe(dev, PTR_ERR(mdata->parent_clk),\n\t\t\t\t     \"failed to get parent-clk\\n\");\n\n\tmdata->sel_clk = devm_clk_get(dev, \"sel-clk\");\n\tif (IS_ERR(mdata->sel_clk))\n\t\treturn dev_err_probe(dev, PTR_ERR(mdata->sel_clk), \"failed to get sel-clk\\n\");\n\n\tmdata->spi_clk = devm_clk_get(dev, \"spi-clk\");\n\tif (IS_ERR(mdata->spi_clk))\n\t\treturn dev_err_probe(dev, PTR_ERR(mdata->spi_clk), \"failed to get spi-clk\\n\");\n\n\tmdata->spi_hclk = devm_clk_get_optional(dev, \"hclk\");\n\tif (IS_ERR(mdata->spi_hclk))\n\t\treturn dev_err_probe(dev, PTR_ERR(mdata->spi_hclk), \"failed to get hclk\\n\");\n\n\tret = clk_set_parent(mdata->sel_clk, mdata->parent_clk);\n\tif (ret < 0)\n\t\treturn dev_err_probe(dev, ret, \"failed to clk_set_parent\\n\");\n\n\tret = clk_prepare_enable(mdata->spi_hclk);\n\tif (ret < 0)\n\t\treturn dev_err_probe(dev, ret, \"failed to enable hclk\\n\");\n\n\tret = clk_prepare_enable(mdata->spi_clk);\n\tif (ret < 0) {\n\t\tclk_disable_unprepare(mdata->spi_hclk);\n\t\treturn dev_err_probe(dev, ret, \"failed to enable spi_clk\\n\");\n\t}\n\n\tmdata->spi_clk_hz = clk_get_rate(mdata->spi_clk);\n\n\tif (mdata->dev_comp->no_need_unprepare) {\n\t\tclk_disable(mdata->spi_clk);\n\t\tclk_disable(mdata->spi_hclk);\n\t} else {\n\t\tclk_disable_unprepare(mdata->spi_clk);\n\t\tclk_disable_unprepare(mdata->spi_hclk);\n\t}\n\n\tif (mdata->dev_comp->need_pad_sel) {\n\t\tif (mdata->pad_num != master->num_chipselect)\n\t\t\treturn dev_err_probe(dev, -EINVAL,\n\t\t\t\t\"pad_num does not match num_chipselect(%d != %d)\\n\",\n\t\t\t\tmdata->pad_num, master->num_chipselect);\n\n\t\tif (!master->cs_gpiods && master->num_chipselect > 1)\n\t\t\treturn dev_err_probe(dev, -EINVAL,\n\t\t\t\t\"cs_gpios not specified and num_chipselect > 1\\n\");\n\t}\n\n\tif (mdata->dev_comp->dma_ext)\n\t\taddr_bits = DMA_ADDR_EXT_BITS;\n\telse\n\t\taddr_bits = DMA_ADDR_DEF_BITS;\n\tret = dma_set_mask(dev, DMA_BIT_MASK(addr_bits));\n\tif (ret)\n\t\tdev_notice(dev, \"SPI dma_set_mask(%d) failed, ret:%d\\n\",\n\t\t\t   addr_bits, ret);\n\n\tret = devm_request_irq(dev, irq, mtk_spi_interrupt,\n\t\t\t       IRQF_TRIGGER_NONE, dev_name(dev), master);\n\tif (ret)\n\t\treturn dev_err_probe(dev, ret, \"failed to register irq\\n\");\n\n\tpm_runtime_enable(dev);\n\n\tret = devm_spi_register_master(dev, master);\n\tif (ret) {\n\t\tpm_runtime_disable(dev);\n\t\treturn dev_err_probe(dev, ret, \"failed to register master\\n\");\n\t}\n\n\treturn 0;\n}\n\nstatic void mtk_spi_remove(struct platform_device *pdev)\n{\n\tstruct spi_master *master = platform_get_drvdata(pdev);\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\tint ret;\n\n\tif (mdata->use_spimem && !completion_done(&mdata->spimem_done))\n\t\tcomplete(&mdata->spimem_done);\n\n\tret = pm_runtime_get_sync(&pdev->dev);\n\tif (ret < 0) {\n\t\tdev_warn(&pdev->dev, \"Failed to resume hardware (%pe)\\n\", ERR_PTR(ret));\n\t} else {\n\t\t \n\t\tmtk_spi_reset(mdata);\n\n\t\tif (mdata->dev_comp->no_need_unprepare) {\n\t\t\tclk_unprepare(mdata->spi_clk);\n\t\t\tclk_unprepare(mdata->spi_hclk);\n\t\t}\n\t}\n\n\tpm_runtime_put_noidle(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int mtk_spi_suspend(struct device *dev)\n{\n\tint ret;\n\tstruct spi_master *master = dev_get_drvdata(dev);\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tret = spi_master_suspend(master);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!pm_runtime_suspended(dev)) {\n\t\tclk_disable_unprepare(mdata->spi_clk);\n\t\tclk_disable_unprepare(mdata->spi_hclk);\n\t}\n\n\treturn 0;\n}\n\nstatic int mtk_spi_resume(struct device *dev)\n{\n\tint ret;\n\tstruct spi_master *master = dev_get_drvdata(dev);\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tif (!pm_runtime_suspended(dev)) {\n\t\tret = clk_prepare_enable(mdata->spi_clk);\n\t\tif (ret < 0) {\n\t\t\tdev_err(dev, \"failed to enable spi_clk (%d)\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = clk_prepare_enable(mdata->spi_hclk);\n\t\tif (ret < 0) {\n\t\t\tdev_err(dev, \"failed to enable spi_hclk (%d)\\n\", ret);\n\t\t\tclk_disable_unprepare(mdata->spi_clk);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = spi_master_resume(master);\n\tif (ret < 0) {\n\t\tclk_disable_unprepare(mdata->spi_clk);\n\t\tclk_disable_unprepare(mdata->spi_hclk);\n\t}\n\n\treturn ret;\n}\n#endif  \n\n#ifdef CONFIG_PM\nstatic int mtk_spi_runtime_suspend(struct device *dev)\n{\n\tstruct spi_master *master = dev_get_drvdata(dev);\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\n\tif (mdata->dev_comp->no_need_unprepare) {\n\t\tclk_disable(mdata->spi_clk);\n\t\tclk_disable(mdata->spi_hclk);\n\t} else {\n\t\tclk_disable_unprepare(mdata->spi_clk);\n\t\tclk_disable_unprepare(mdata->spi_hclk);\n\t}\n\n\treturn 0;\n}\n\nstatic int mtk_spi_runtime_resume(struct device *dev)\n{\n\tstruct spi_master *master = dev_get_drvdata(dev);\n\tstruct mtk_spi *mdata = spi_master_get_devdata(master);\n\tint ret;\n\n\tif (mdata->dev_comp->no_need_unprepare) {\n\t\tret = clk_enable(mdata->spi_clk);\n\t\tif (ret < 0) {\n\t\t\tdev_err(dev, \"failed to enable spi_clk (%d)\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t\tret = clk_enable(mdata->spi_hclk);\n\t\tif (ret < 0) {\n\t\t\tdev_err(dev, \"failed to enable spi_hclk (%d)\\n\", ret);\n\t\t\tclk_disable(mdata->spi_clk);\n\t\t\treturn ret;\n\t\t}\n\t} else {\n\t\tret = clk_prepare_enable(mdata->spi_clk);\n\t\tif (ret < 0) {\n\t\t\tdev_err(dev, \"failed to prepare_enable spi_clk (%d)\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = clk_prepare_enable(mdata->spi_hclk);\n\t\tif (ret < 0) {\n\t\t\tdev_err(dev, \"failed to prepare_enable spi_hclk (%d)\\n\", ret);\n\t\t\tclk_disable_unprepare(mdata->spi_clk);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n#endif  \n\nstatic const struct dev_pm_ops mtk_spi_pm = {\n\tSET_SYSTEM_SLEEP_PM_OPS(mtk_spi_suspend, mtk_spi_resume)\n\tSET_RUNTIME_PM_OPS(mtk_spi_runtime_suspend,\n\t\t\t   mtk_spi_runtime_resume, NULL)\n};\n\nstatic struct platform_driver mtk_spi_driver = {\n\t.driver = {\n\t\t.name = \"mtk-spi\",\n\t\t.pm\t= &mtk_spi_pm,\n\t\t.of_match_table = mtk_spi_of_match,\n\t},\n\t.probe = mtk_spi_probe,\n\t.remove_new = mtk_spi_remove,\n};\n\nmodule_platform_driver(mtk_spi_driver);\n\nMODULE_DESCRIPTION(\"MTK SPI Controller driver\");\nMODULE_AUTHOR(\"Leilk Liu <leilk.liu@mediatek.com>\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS(\"platform:mtk-spi\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}