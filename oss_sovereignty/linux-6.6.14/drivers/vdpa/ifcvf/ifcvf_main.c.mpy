{
  "module_name": "ifcvf_main.c",
  "hash_id": "6ae5b41cad73569a15b47360ddf241aad2c5c5a056677148d7aae77bb5b5e7c5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/vdpa/ifcvf/ifcvf_main.c",
  "human_readable_source": "\n \n\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/sysfs.h>\n#include \"ifcvf_base.h\"\n\n#define DRIVER_AUTHOR   \"Intel Corporation\"\n#define IFCVF_DRIVER_NAME       \"ifcvf\"\n\nstatic irqreturn_t ifcvf_config_changed(int irq, void *arg)\n{\n\tstruct ifcvf_hw *vf = arg;\n\n\tif (vf->config_cb.callback)\n\t\treturn vf->config_cb.callback(vf->config_cb.private);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t ifcvf_vq_intr_handler(int irq, void *arg)\n{\n\tstruct vring_info *vring = arg;\n\n\tif (vring->cb.callback)\n\t\treturn vring->cb.callback(vring->cb.private);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t ifcvf_vqs_reused_intr_handler(int irq, void *arg)\n{\n\tstruct ifcvf_hw *vf = arg;\n\tstruct vring_info *vring;\n\tint i;\n\n\tfor (i = 0; i < vf->nr_vring; i++) {\n\t\tvring = &vf->vring[i];\n\t\tif (vring->cb.callback)\n\t\t\tvring->cb.callback(vring->cb.private);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t ifcvf_dev_intr_handler(int irq, void *arg)\n{\n\tstruct ifcvf_hw *vf = arg;\n\tu8 isr;\n\n\tisr = vp_ioread8(vf->isr);\n\tif (isr & VIRTIO_PCI_ISR_CONFIG)\n\t\tifcvf_config_changed(irq, arg);\n\n\treturn ifcvf_vqs_reused_intr_handler(irq, arg);\n}\n\nstatic void ifcvf_free_irq_vectors(void *data)\n{\n\tpci_free_irq_vectors(data);\n}\n\nstatic void ifcvf_free_per_vq_irq(struct ifcvf_hw *vf)\n{\n\tstruct pci_dev *pdev = vf->pdev;\n\tint i;\n\n\tfor (i = 0; i < vf->nr_vring; i++) {\n\t\tif (vf->vring[i].irq != -EINVAL) {\n\t\t\tdevm_free_irq(&pdev->dev, vf->vring[i].irq, &vf->vring[i]);\n\t\t\tvf->vring[i].irq = -EINVAL;\n\t\t}\n\t}\n}\n\nstatic void ifcvf_free_vqs_reused_irq(struct ifcvf_hw *vf)\n{\n\tstruct pci_dev *pdev = vf->pdev;\n\n\tif (vf->vqs_reused_irq != -EINVAL) {\n\t\tdevm_free_irq(&pdev->dev, vf->vqs_reused_irq, vf);\n\t\tvf->vqs_reused_irq = -EINVAL;\n\t}\n\n}\n\nstatic void ifcvf_free_vq_irq(struct ifcvf_hw *vf)\n{\n\tif (vf->msix_vector_status == MSIX_VECTOR_PER_VQ_AND_CONFIG)\n\t\tifcvf_free_per_vq_irq(vf);\n\telse\n\t\tifcvf_free_vqs_reused_irq(vf);\n}\n\nstatic void ifcvf_free_config_irq(struct ifcvf_hw *vf)\n{\n\tstruct pci_dev *pdev = vf->pdev;\n\n\tif (vf->config_irq == -EINVAL)\n\t\treturn;\n\n\t \n\tif (vf->msix_vector_status != MSIX_VECTOR_DEV_SHARED) {\n\t\tdevm_free_irq(&pdev->dev, vf->config_irq, vf);\n\t\tvf->config_irq = -EINVAL;\n\t}\n}\n\nstatic void ifcvf_free_irq(struct ifcvf_hw *vf)\n{\n\tstruct pci_dev *pdev = vf->pdev;\n\n\tifcvf_free_vq_irq(vf);\n\tifcvf_free_config_irq(vf);\n\tifcvf_free_irq_vectors(pdev);\n\tvf->num_msix_vectors = 0;\n}\n\n \nstatic int ifcvf_alloc_vectors(struct ifcvf_hw *vf)\n{\n\tstruct pci_dev *pdev = vf->pdev;\n\tint max_intr, ret;\n\n\t \n\tmax_intr = vf->nr_vring + 1;\n\tret = pci_alloc_irq_vectors(pdev, 1, max_intr, PCI_IRQ_MSIX | PCI_IRQ_AFFINITY);\n\n\tif (ret < 0) {\n\t\tIFCVF_ERR(pdev, \"Failed to alloc IRQ vectors\\n\");\n\t\treturn ret;\n\t}\n\n\tif (ret < max_intr)\n\t\tIFCVF_INFO(pdev,\n\t\t\t   \"Requested %u vectors, however only %u allocated, lower performance\\n\",\n\t\t\t   max_intr, ret);\n\n\treturn ret;\n}\n\nstatic int ifcvf_request_per_vq_irq(struct ifcvf_hw *vf)\n{\n\tstruct pci_dev *pdev = vf->pdev;\n\tint i, vector, ret, irq;\n\n\tvf->vqs_reused_irq = -EINVAL;\n\tfor (i = 0; i < vf->nr_vring; i++) {\n\t\tsnprintf(vf->vring[i].msix_name, 256, \"ifcvf[%s]-%d\\n\", pci_name(pdev), i);\n\t\tvector = i;\n\t\tirq = pci_irq_vector(pdev, vector);\n\t\tret = devm_request_irq(&pdev->dev, irq,\n\t\t\t\t       ifcvf_vq_intr_handler, 0,\n\t\t\t\t       vf->vring[i].msix_name,\n\t\t\t\t       &vf->vring[i]);\n\t\tif (ret) {\n\t\t\tIFCVF_ERR(pdev, \"Failed to request irq for vq %d\\n\", i);\n\t\t\tgoto err;\n\t\t}\n\n\t\tvf->vring[i].irq = irq;\n\t\tret = ifcvf_set_vq_vector(vf, i, vector);\n\t\tif (ret == VIRTIO_MSI_NO_VECTOR) {\n\t\t\tIFCVF_ERR(pdev, \"No msix vector for vq %u\\n\", i);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\treturn 0;\nerr:\n\tifcvf_free_irq(vf);\n\n\treturn -EFAULT;\n}\n\nstatic int ifcvf_request_vqs_reused_irq(struct ifcvf_hw *vf)\n{\n\tstruct pci_dev *pdev = vf->pdev;\n\tint i, vector, ret, irq;\n\n\tvector = 0;\n\tsnprintf(vf->vring[0].msix_name, 256, \"ifcvf[%s]-vqs-reused-irq\\n\", pci_name(pdev));\n\tirq = pci_irq_vector(pdev, vector);\n\tret = devm_request_irq(&pdev->dev, irq,\n\t\t\t       ifcvf_vqs_reused_intr_handler, 0,\n\t\t\t       vf->vring[0].msix_name, vf);\n\tif (ret) {\n\t\tIFCVF_ERR(pdev, \"Failed to request reused irq for the device\\n\");\n\t\tgoto err;\n\t}\n\n\tvf->vqs_reused_irq = irq;\n\tfor (i = 0; i < vf->nr_vring; i++) {\n\t\tvf->vring[i].irq = -EINVAL;\n\t\tret = ifcvf_set_vq_vector(vf, i, vector);\n\t\tif (ret == VIRTIO_MSI_NO_VECTOR) {\n\t\t\tIFCVF_ERR(pdev, \"No msix vector for vq %u\\n\", i);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\treturn 0;\nerr:\n\tifcvf_free_irq(vf);\n\n\treturn -EFAULT;\n}\n\nstatic int ifcvf_request_dev_irq(struct ifcvf_hw *vf)\n{\n\tstruct pci_dev *pdev = vf->pdev;\n\tint i, vector, ret, irq;\n\n\tvector = 0;\n\tsnprintf(vf->vring[0].msix_name, 256, \"ifcvf[%s]-dev-irq\\n\", pci_name(pdev));\n\tirq = pci_irq_vector(pdev, vector);\n\tret = devm_request_irq(&pdev->dev, irq,\n\t\t\t       ifcvf_dev_intr_handler, 0,\n\t\t\t       vf->vring[0].msix_name, vf);\n\tif (ret) {\n\t\tIFCVF_ERR(pdev, \"Failed to request irq for the device\\n\");\n\t\tgoto err;\n\t}\n\n\tvf->vqs_reused_irq = irq;\n\tfor (i = 0; i < vf->nr_vring; i++) {\n\t\tvf->vring[i].irq = -EINVAL;\n\t\tret = ifcvf_set_vq_vector(vf, i, vector);\n\t\tif (ret == VIRTIO_MSI_NO_VECTOR) {\n\t\t\tIFCVF_ERR(pdev, \"No msix vector for vq %u\\n\", i);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tvf->config_irq = irq;\n\tret = ifcvf_set_config_vector(vf, vector);\n\tif (ret == VIRTIO_MSI_NO_VECTOR) {\n\t\tIFCVF_ERR(pdev, \"No msix vector for device config\\n\");\n\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tifcvf_free_irq(vf);\n\n\treturn -EFAULT;\n\n}\n\nstatic int ifcvf_request_vq_irq(struct ifcvf_hw *vf)\n{\n\tint ret;\n\n\tif (vf->msix_vector_status == MSIX_VECTOR_PER_VQ_AND_CONFIG)\n\t\tret = ifcvf_request_per_vq_irq(vf);\n\telse\n\t\tret = ifcvf_request_vqs_reused_irq(vf);\n\n\treturn ret;\n}\n\nstatic int ifcvf_request_config_irq(struct ifcvf_hw *vf)\n{\n\tstruct pci_dev *pdev = vf->pdev;\n\tint config_vector, ret;\n\n\tif (vf->msix_vector_status == MSIX_VECTOR_PER_VQ_AND_CONFIG)\n\t\tconfig_vector = vf->nr_vring;\n\telse if (vf->msix_vector_status ==  MSIX_VECTOR_SHARED_VQ_AND_CONFIG)\n\t\t \n\t\tconfig_vector = 1;\n\telse if (vf->msix_vector_status == MSIX_VECTOR_DEV_SHARED)\n\t\t \n\t\treturn 0;\n\telse\n\t\treturn -EINVAL;\n\n\tsnprintf(vf->config_msix_name, 256, \"ifcvf[%s]-config\\n\",\n\t\t pci_name(pdev));\n\tvf->config_irq = pci_irq_vector(pdev, config_vector);\n\tret = devm_request_irq(&pdev->dev, vf->config_irq,\n\t\t\t       ifcvf_config_changed, 0,\n\t\t\t       vf->config_msix_name, vf);\n\tif (ret) {\n\t\tIFCVF_ERR(pdev, \"Failed to request config irq\\n\");\n\t\tgoto err;\n\t}\n\n\tret = ifcvf_set_config_vector(vf, config_vector);\n\tif (ret == VIRTIO_MSI_NO_VECTOR) {\n\t\tIFCVF_ERR(pdev, \"No msix vector for device config\\n\");\n\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tifcvf_free_irq(vf);\n\n\treturn -EFAULT;\n}\n\nstatic int ifcvf_request_irq(struct ifcvf_hw *vf)\n{\n\tint nvectors, ret, max_intr;\n\n\tnvectors = ifcvf_alloc_vectors(vf);\n\tif (nvectors <= 0)\n\t\treturn -EFAULT;\n\n\tvf->msix_vector_status = MSIX_VECTOR_PER_VQ_AND_CONFIG;\n\tmax_intr = vf->nr_vring + 1;\n\tif (nvectors < max_intr)\n\t\tvf->msix_vector_status = MSIX_VECTOR_SHARED_VQ_AND_CONFIG;\n\n\tif (nvectors == 1) {\n\t\tvf->msix_vector_status = MSIX_VECTOR_DEV_SHARED;\n\t\tret = ifcvf_request_dev_irq(vf);\n\n\t\treturn ret;\n\t}\n\n\tret = ifcvf_request_vq_irq(vf);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ifcvf_request_config_irq(vf);\n\n\tif (ret)\n\t\treturn ret;\n\n\tvf->num_msix_vectors = nvectors;\n\n\treturn 0;\n}\n\nstatic struct ifcvf_adapter *vdpa_to_adapter(struct vdpa_device *vdpa_dev)\n{\n\treturn container_of(vdpa_dev, struct ifcvf_adapter, vdpa);\n}\n\nstatic struct ifcvf_hw *vdpa_to_vf(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_adapter *adapter = vdpa_to_adapter(vdpa_dev);\n\n\treturn adapter->vf;\n}\n\nstatic u64 ifcvf_vdpa_get_device_features(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_adapter *adapter = vdpa_to_adapter(vdpa_dev);\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\tstruct pci_dev *pdev = adapter->pdev;\n\tu32 type = vf->dev_type;\n\tu64 features;\n\n\tif (type == VIRTIO_ID_NET || type == VIRTIO_ID_BLOCK)\n\t\tfeatures = ifcvf_get_dev_features(vf);\n\telse {\n\t\tfeatures = 0;\n\t\tIFCVF_ERR(pdev, \"VIRTIO ID %u not supported\\n\", vf->dev_type);\n\t}\n\n\treturn features;\n}\n\nstatic int ifcvf_vdpa_set_driver_features(struct vdpa_device *vdpa_dev, u64 features)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\tint ret;\n\n\tret = ifcvf_verify_min_features(vf, features);\n\tif (ret)\n\t\treturn ret;\n\n\tifcvf_set_driver_features(vf, features);\n\n\treturn 0;\n}\n\nstatic u64 ifcvf_vdpa_get_driver_features(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\tu64 features;\n\n\tfeatures = ifcvf_get_driver_features(vf);\n\n\treturn features;\n}\n\nstatic u8 ifcvf_vdpa_get_status(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\treturn ifcvf_get_status(vf);\n}\n\nstatic void ifcvf_vdpa_set_status(struct vdpa_device *vdpa_dev, u8 status)\n{\n\tstruct ifcvf_hw *vf;\n\tu8 status_old;\n\tint ret;\n\n\tvf  = vdpa_to_vf(vdpa_dev);\n\tstatus_old = ifcvf_get_status(vf);\n\n\tif (status_old == status)\n\t\treturn;\n\n\tif ((status & VIRTIO_CONFIG_S_DRIVER_OK) &&\n\t    !(status_old & VIRTIO_CONFIG_S_DRIVER_OK)) {\n\t\tret = ifcvf_request_irq(vf);\n\t\tif (ret) {\n\t\t\tIFCVF_ERR(vf->pdev, \"failed to request irq with error %d\\n\", ret);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tifcvf_set_status(vf, status);\n}\n\nstatic int ifcvf_vdpa_reset(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\tu8 status = ifcvf_get_status(vf);\n\n\tifcvf_stop(vf);\n\n\tif (status & VIRTIO_CONFIG_S_DRIVER_OK)\n\t\tifcvf_free_irq(vf);\n\n\tifcvf_reset(vf);\n\n\treturn 0;\n}\n\nstatic u16 ifcvf_vdpa_get_vq_num_max(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\treturn ifcvf_get_max_vq_size(vf);\n}\n\nstatic int ifcvf_vdpa_get_vq_state(struct vdpa_device *vdpa_dev, u16 qid,\n\t\t\t\t   struct vdpa_vq_state *state)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\tstate->split.avail_index = ifcvf_get_vq_state(vf, qid);\n\treturn 0;\n}\n\nstatic int ifcvf_vdpa_set_vq_state(struct vdpa_device *vdpa_dev, u16 qid,\n\t\t\t\t   const struct vdpa_vq_state *state)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\treturn ifcvf_set_vq_state(vf, qid, state->split.avail_index);\n}\n\nstatic void ifcvf_vdpa_set_vq_cb(struct vdpa_device *vdpa_dev, u16 qid,\n\t\t\t\t struct vdpa_callback *cb)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\tvf->vring[qid].cb = *cb;\n}\n\nstatic void ifcvf_vdpa_set_vq_ready(struct vdpa_device *vdpa_dev,\n\t\t\t\t    u16 qid, bool ready)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\tifcvf_set_vq_ready(vf, qid, ready);\n}\n\nstatic bool ifcvf_vdpa_get_vq_ready(struct vdpa_device *vdpa_dev, u16 qid)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\treturn ifcvf_get_vq_ready(vf, qid);\n}\n\nstatic void ifcvf_vdpa_set_vq_num(struct vdpa_device *vdpa_dev, u16 qid,\n\t\t\t\t  u32 num)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\tifcvf_set_vq_num(vf, qid, num);\n}\n\nstatic int ifcvf_vdpa_set_vq_address(struct vdpa_device *vdpa_dev, u16 qid,\n\t\t\t\t     u64 desc_area, u64 driver_area,\n\t\t\t\t     u64 device_area)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\treturn ifcvf_set_vq_address(vf, qid, desc_area, driver_area, device_area);\n}\n\nstatic void ifcvf_vdpa_kick_vq(struct vdpa_device *vdpa_dev, u16 qid)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\tifcvf_notify_queue(vf, qid);\n}\n\nstatic u32 ifcvf_vdpa_get_generation(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\treturn vp_ioread8(&vf->common_cfg->config_generation);\n}\n\nstatic u32 ifcvf_vdpa_get_device_id(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\treturn vf->dev_type;\n}\n\nstatic u32 ifcvf_vdpa_get_vendor_id(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_adapter *adapter = vdpa_to_adapter(vdpa_dev);\n\tstruct pci_dev *pdev = adapter->pdev;\n\n\treturn pdev->subsystem_vendor;\n}\n\nstatic u32 ifcvf_vdpa_get_vq_align(struct vdpa_device *vdpa_dev)\n{\n\treturn IFCVF_QUEUE_ALIGNMENT;\n}\n\nstatic size_t ifcvf_vdpa_get_config_size(struct vdpa_device *vdpa_dev)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\treturn  vf->config_size;\n}\n\nstatic u32 ifcvf_vdpa_get_vq_group(struct vdpa_device *vdpa, u16 idx)\n{\n\treturn 0;\n}\n\nstatic void ifcvf_vdpa_get_config(struct vdpa_device *vdpa_dev,\n\t\t\t\t  unsigned int offset,\n\t\t\t\t  void *buf, unsigned int len)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\tifcvf_read_dev_config(vf, offset, buf, len);\n}\n\nstatic void ifcvf_vdpa_set_config(struct vdpa_device *vdpa_dev,\n\t\t\t\t  unsigned int offset, const void *buf,\n\t\t\t\t  unsigned int len)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\tifcvf_write_dev_config(vf, offset, buf, len);\n}\n\nstatic void ifcvf_vdpa_set_config_cb(struct vdpa_device *vdpa_dev,\n\t\t\t\t     struct vdpa_callback *cb)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\tvf->config_cb.callback = cb->callback;\n\tvf->config_cb.private = cb->private;\n}\n\nstatic int ifcvf_vdpa_get_vq_irq(struct vdpa_device *vdpa_dev,\n\t\t\t\t u16 qid)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\n\tif (vf->vqs_reused_irq < 0)\n\t\treturn vf->vring[qid].irq;\n\telse\n\t\treturn -EINVAL;\n}\n\nstatic struct vdpa_notification_area ifcvf_get_vq_notification(struct vdpa_device *vdpa_dev,\n\t\t\t\t\t\t\t       u16 idx)\n{\n\tstruct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);\n\tstruct vdpa_notification_area area;\n\n\tarea.addr = vf->vring[idx].notify_pa;\n\tif (!vf->notify_off_multiplier)\n\t\tarea.size = PAGE_SIZE;\n\telse\n\t\tarea.size = vf->notify_off_multiplier;\n\n\treturn area;\n}\n\n \nstatic const struct vdpa_config_ops ifc_vdpa_ops = {\n\t.get_device_features = ifcvf_vdpa_get_device_features,\n\t.set_driver_features = ifcvf_vdpa_set_driver_features,\n\t.get_driver_features = ifcvf_vdpa_get_driver_features,\n\t.get_status\t= ifcvf_vdpa_get_status,\n\t.set_status\t= ifcvf_vdpa_set_status,\n\t.reset\t\t= ifcvf_vdpa_reset,\n\t.get_vq_num_max\t= ifcvf_vdpa_get_vq_num_max,\n\t.get_vq_state\t= ifcvf_vdpa_get_vq_state,\n\t.set_vq_state\t= ifcvf_vdpa_set_vq_state,\n\t.set_vq_cb\t= ifcvf_vdpa_set_vq_cb,\n\t.set_vq_ready\t= ifcvf_vdpa_set_vq_ready,\n\t.get_vq_ready\t= ifcvf_vdpa_get_vq_ready,\n\t.set_vq_num\t= ifcvf_vdpa_set_vq_num,\n\t.set_vq_address\t= ifcvf_vdpa_set_vq_address,\n\t.get_vq_irq\t= ifcvf_vdpa_get_vq_irq,\n\t.kick_vq\t= ifcvf_vdpa_kick_vq,\n\t.get_generation\t= ifcvf_vdpa_get_generation,\n\t.get_device_id\t= ifcvf_vdpa_get_device_id,\n\t.get_vendor_id\t= ifcvf_vdpa_get_vendor_id,\n\t.get_vq_align\t= ifcvf_vdpa_get_vq_align,\n\t.get_vq_group\t= ifcvf_vdpa_get_vq_group,\n\t.get_config_size\t= ifcvf_vdpa_get_config_size,\n\t.get_config\t= ifcvf_vdpa_get_config,\n\t.set_config\t= ifcvf_vdpa_set_config,\n\t.set_config_cb  = ifcvf_vdpa_set_config_cb,\n\t.get_vq_notification = ifcvf_get_vq_notification,\n};\n\nstatic struct virtio_device_id id_table_net[] = {\n\t{VIRTIO_ID_NET, VIRTIO_DEV_ANY_ID},\n\t{0},\n};\n\nstatic struct virtio_device_id id_table_blk[] = {\n\t{VIRTIO_ID_BLOCK, VIRTIO_DEV_ANY_ID},\n\t{0},\n};\n\nstatic u32 get_dev_type(struct pci_dev *pdev)\n{\n\tu32 dev_type;\n\n\t \n\n\tif (pdev->device < 0x1040)\n\t\tdev_type =  pdev->subsystem_device;\n\telse\n\t\tdev_type =  pdev->device - 0x1040;\n\n\treturn dev_type;\n}\n\nstatic int ifcvf_vdpa_dev_add(struct vdpa_mgmt_dev *mdev, const char *name,\n\t\t\t      const struct vdpa_dev_set_config *config)\n{\n\tstruct ifcvf_vdpa_mgmt_dev *ifcvf_mgmt_dev;\n\tstruct ifcvf_adapter *adapter;\n\tstruct vdpa_device *vdpa_dev;\n\tstruct pci_dev *pdev;\n\tstruct ifcvf_hw *vf;\n\tu64 device_features;\n\tint ret;\n\n\tifcvf_mgmt_dev = container_of(mdev, struct ifcvf_vdpa_mgmt_dev, mdev);\n\tvf = &ifcvf_mgmt_dev->vf;\n\tpdev = vf->pdev;\n\tadapter = vdpa_alloc_device(struct ifcvf_adapter, vdpa,\n\t\t\t\t    &pdev->dev, &ifc_vdpa_ops, 1, 1, NULL, false);\n\tif (IS_ERR(adapter)) {\n\t\tIFCVF_ERR(pdev, \"Failed to allocate vDPA structure\");\n\t\treturn PTR_ERR(adapter);\n\t}\n\n\tifcvf_mgmt_dev->adapter = adapter;\n\tadapter->pdev = pdev;\n\tadapter->vdpa.dma_dev = &pdev->dev;\n\tadapter->vdpa.mdev = mdev;\n\tadapter->vf = vf;\n\tvdpa_dev = &adapter->vdpa;\n\n\tdevice_features = vf->hw_features;\n\tif (config->mask & BIT_ULL(VDPA_ATTR_DEV_FEATURES)) {\n\t\tif (config->device_features & ~device_features) {\n\t\t\tIFCVF_ERR(pdev, \"The provisioned features 0x%llx are not supported by this device with features 0x%llx\\n\",\n\t\t\t\t  config->device_features, device_features);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tdevice_features &= config->device_features;\n\t}\n\tvf->dev_features = device_features;\n\n\tif (name)\n\t\tret = dev_set_name(&vdpa_dev->dev, \"%s\", name);\n\telse\n\t\tret = dev_set_name(&vdpa_dev->dev, \"vdpa%u\", vdpa_dev->index);\n\n\tret = _vdpa_register_device(&adapter->vdpa, vf->nr_vring);\n\tif (ret) {\n\t\tput_device(&adapter->vdpa.dev);\n\t\tIFCVF_ERR(pdev, \"Failed to register to vDPA bus\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void ifcvf_vdpa_dev_del(struct vdpa_mgmt_dev *mdev, struct vdpa_device *dev)\n{\n\tstruct ifcvf_vdpa_mgmt_dev *ifcvf_mgmt_dev;\n\n\tifcvf_mgmt_dev = container_of(mdev, struct ifcvf_vdpa_mgmt_dev, mdev);\n\t_vdpa_unregister_device(dev);\n\tifcvf_mgmt_dev->adapter = NULL;\n}\n\nstatic const struct vdpa_mgmtdev_ops ifcvf_vdpa_mgmt_dev_ops = {\n\t.dev_add = ifcvf_vdpa_dev_add,\n\t.dev_del = ifcvf_vdpa_dev_del\n};\n\nstatic int ifcvf_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tstruct ifcvf_vdpa_mgmt_dev *ifcvf_mgmt_dev;\n\tstruct device *dev = &pdev->dev;\n\tstruct ifcvf_hw *vf;\n\tu32 dev_type;\n\tint ret, i;\n\n\tret = pcim_enable_device(pdev);\n\tif (ret) {\n\t\tIFCVF_ERR(pdev, \"Failed to enable device\\n\");\n\t\treturn ret;\n\t}\n\tret = pcim_iomap_regions(pdev, BIT(0) | BIT(2) | BIT(4),\n\t\t\t\t IFCVF_DRIVER_NAME);\n\tif (ret) {\n\t\tIFCVF_ERR(pdev, \"Failed to request MMIO region\\n\");\n\t\treturn ret;\n\t}\n\n\tret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));\n\tif (ret) {\n\t\tIFCVF_ERR(pdev, \"No usable DMA configuration\\n\");\n\t\treturn ret;\n\t}\n\n\tret = devm_add_action_or_reset(dev, ifcvf_free_irq_vectors, pdev);\n\tif (ret) {\n\t\tIFCVF_ERR(pdev,\n\t\t\t  \"Failed for adding devres for freeing irq vectors\\n\");\n\t\treturn ret;\n\t}\n\n\tpci_set_master(pdev);\n\tifcvf_mgmt_dev = kzalloc(sizeof(struct ifcvf_vdpa_mgmt_dev), GFP_KERNEL);\n\tif (!ifcvf_mgmt_dev) {\n\t\tIFCVF_ERR(pdev, \"Failed to alloc memory for the vDPA management device\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tvf = &ifcvf_mgmt_dev->vf;\n\tvf->dev_type = get_dev_type(pdev);\n\tvf->base = pcim_iomap_table(pdev);\n\tvf->pdev = pdev;\n\n\tret = ifcvf_init_hw(vf, pdev);\n\tif (ret) {\n\t\tIFCVF_ERR(pdev, \"Failed to init IFCVF hw\\n\");\n\t\tgoto err;\n\t}\n\n\tfor (i = 0; i < vf->nr_vring; i++)\n\t\tvf->vring[i].irq = -EINVAL;\n\n\tvf->hw_features = ifcvf_get_hw_features(vf);\n\tvf->config_size = ifcvf_get_config_size(vf);\n\n\tdev_type = get_dev_type(pdev);\n\tswitch (dev_type) {\n\tcase VIRTIO_ID_NET:\n\t\tifcvf_mgmt_dev->mdev.id_table = id_table_net;\n\t\tbreak;\n\tcase VIRTIO_ID_BLOCK:\n\t\tifcvf_mgmt_dev->mdev.id_table = id_table_blk;\n\t\tbreak;\n\tdefault:\n\t\tIFCVF_ERR(pdev, \"VIRTIO ID %u not supported\\n\", dev_type);\n\t\tret = -EOPNOTSUPP;\n\t\tgoto err;\n\t}\n\n\tifcvf_mgmt_dev->mdev.ops = &ifcvf_vdpa_mgmt_dev_ops;\n\tifcvf_mgmt_dev->mdev.device = dev;\n\tifcvf_mgmt_dev->mdev.max_supported_vqs = vf->nr_vring;\n\tifcvf_mgmt_dev->mdev.supported_features = vf->hw_features;\n\tifcvf_mgmt_dev->mdev.config_attr_mask = (1 << VDPA_ATTR_DEV_FEATURES);\n\n\tret = vdpa_mgmtdev_register(&ifcvf_mgmt_dev->mdev);\n\tif (ret) {\n\t\tIFCVF_ERR(pdev,\n\t\t\t  \"Failed to initialize the management interfaces\\n\");\n\t\tgoto err;\n\t}\n\n\tpci_set_drvdata(pdev, ifcvf_mgmt_dev);\n\n\treturn 0;\n\nerr:\n\tkfree(ifcvf_mgmt_dev->vf.vring);\n\tkfree(ifcvf_mgmt_dev);\n\treturn ret;\n}\n\nstatic void ifcvf_remove(struct pci_dev *pdev)\n{\n\tstruct ifcvf_vdpa_mgmt_dev *ifcvf_mgmt_dev;\n\n\tifcvf_mgmt_dev = pci_get_drvdata(pdev);\n\tvdpa_mgmtdev_unregister(&ifcvf_mgmt_dev->mdev);\n\tkfree(ifcvf_mgmt_dev->vf.vring);\n\tkfree(ifcvf_mgmt_dev);\n}\n\nstatic struct pci_device_id ifcvf_pci_ids[] = {\n\t \n\t{ PCI_DEVICE_SUB(PCI_VENDOR_ID_REDHAT_QUMRANET,\n\t\t\t N3000_DEVICE_ID,\n\t\t\t PCI_VENDOR_ID_INTEL,\n\t\t\t N3000_SUBSYS_DEVICE_ID) },\n\t \n\t{ PCI_DEVICE_SUB(PCI_VENDOR_ID_REDHAT_QUMRANET,\n\t\t\t VIRTIO_TRANS_ID_NET,\n\t\t\t PCI_VENDOR_ID_INTEL,\n\t\t\t VIRTIO_ID_NET) },\n\t \n\t{ PCI_DEVICE_SUB(PCI_VENDOR_ID_REDHAT_QUMRANET,\n\t\t\t VIRTIO_TRANS_ID_BLOCK,\n\t\t\t PCI_VENDOR_ID_INTEL,\n\t\t\t VIRTIO_ID_BLOCK) },\n\n\t{ 0 },\n};\nMODULE_DEVICE_TABLE(pci, ifcvf_pci_ids);\n\nstatic struct pci_driver ifcvf_driver = {\n\t.name     = IFCVF_DRIVER_NAME,\n\t.id_table = ifcvf_pci_ids,\n\t.probe    = ifcvf_probe,\n\t.remove   = ifcvf_remove,\n};\n\nmodule_pci_driver(ifcvf_driver);\n\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}