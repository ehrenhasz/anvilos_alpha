{
  "module_name": "vdpa_sim_blk.c",
  "hash_id": "ac9cd93ed2fbf2dfbd6912b99b8485bb2fbf9792b0e4e7bf1132355368d99e8b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/vdpa/vdpa_sim/vdpa_sim_blk.c",
  "human_readable_source": "\n \n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/device.h>\n#include <linux/kernel.h>\n#include <linux/blkdev.h>\n#include <linux/vringh.h>\n#include <linux/vdpa.h>\n#include <uapi/linux/virtio_blk.h>\n\n#include \"vdpa_sim.h\"\n\n#define DRV_VERSION  \"0.1\"\n#define DRV_AUTHOR   \"Max Gurtovoy <mgurtovoy@nvidia.com>\"\n#define DRV_DESC     \"vDPA Device Simulator for block device\"\n#define DRV_LICENSE  \"GPL v2\"\n\n#define VDPASIM_BLK_FEATURES\t(VDPASIM_FEATURES | \\\n\t\t\t\t (1ULL << VIRTIO_BLK_F_FLUSH)    | \\\n\t\t\t\t (1ULL << VIRTIO_BLK_F_SIZE_MAX) | \\\n\t\t\t\t (1ULL << VIRTIO_BLK_F_SEG_MAX)  | \\\n\t\t\t\t (1ULL << VIRTIO_BLK_F_BLK_SIZE) | \\\n\t\t\t\t (1ULL << VIRTIO_BLK_F_TOPOLOGY) | \\\n\t\t\t\t (1ULL << VIRTIO_BLK_F_MQ)       | \\\n\t\t\t\t (1ULL << VIRTIO_BLK_F_DISCARD)  | \\\n\t\t\t\t (1ULL << VIRTIO_BLK_F_WRITE_ZEROES))\n\n#define VDPASIM_BLK_CAPACITY\t0x40000\n#define VDPASIM_BLK_SIZE_MAX\t0x1000\n#define VDPASIM_BLK_SEG_MAX\t32\n#define VDPASIM_BLK_DWZ_MAX_SECTORS UINT_MAX\n\n \n#define VDPASIM_BLK_VQ_NUM\t1\n#define VDPASIM_BLK_AS_NUM\t1\n#define VDPASIM_BLK_GROUP_NUM\t1\n\nstruct vdpasim_blk {\n\tstruct vdpasim vdpasim;\n\tvoid *buffer;\n\tbool shared_backend;\n};\n\nstatic struct vdpasim_blk *sim_to_blk(struct vdpasim *vdpasim)\n{\n\treturn container_of(vdpasim, struct vdpasim_blk, vdpasim);\n}\n\nstatic char vdpasim_blk_id[VIRTIO_BLK_ID_BYTES] = \"vdpa_blk_sim\";\n\nstatic bool shared_backend;\nmodule_param(shared_backend, bool, 0444);\nMODULE_PARM_DESC(shared_backend, \"Enable the shared backend between virtio-blk devices\");\n\nstatic void *shared_buffer;\n \nstatic DEFINE_MUTEX(shared_buffer_mutex);\n\nstatic void vdpasim_blk_buffer_lock(struct vdpasim_blk *blk)\n{\n\tif (blk->shared_backend)\n\t\tmutex_lock(&shared_buffer_mutex);\n}\n\nstatic void vdpasim_blk_buffer_unlock(struct vdpasim_blk *blk)\n{\n\tif (blk->shared_backend)\n\t\tmutex_unlock(&shared_buffer_mutex);\n}\n\nstatic bool vdpasim_blk_check_range(struct vdpasim *vdpasim, u64 start_sector,\n\t\t\t\t    u64 num_sectors, u64 max_sectors)\n{\n\tif (start_sector > VDPASIM_BLK_CAPACITY) {\n\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\"starting sector exceeds the capacity - start: 0x%llx capacity: 0x%x\\n\",\n\t\t\tstart_sector, VDPASIM_BLK_CAPACITY);\n\t}\n\n\tif (num_sectors > max_sectors) {\n\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\"number of sectors exceeds the max allowed in a request - num: 0x%llx max: 0x%llx\\n\",\n\t\t\tnum_sectors, max_sectors);\n\t\treturn false;\n\t}\n\n\tif (num_sectors > VDPASIM_BLK_CAPACITY - start_sector) {\n\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\"request exceeds the capacity - start: 0x%llx num: 0x%llx capacity: 0x%x\\n\",\n\t\t\tstart_sector, num_sectors, VDPASIM_BLK_CAPACITY);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic bool vdpasim_blk_handle_req(struct vdpasim *vdpasim,\n\t\t\t\t   struct vdpasim_virtqueue *vq)\n{\n\tstruct vdpasim_blk *blk = sim_to_blk(vdpasim);\n\tsize_t pushed = 0, to_pull, to_push;\n\tstruct virtio_blk_outhdr hdr;\n\tbool handled = false;\n\tssize_t bytes;\n\tloff_t offset;\n\tu64 sector;\n\tu8 status;\n\tu32 type;\n\tint ret;\n\n\tret = vringh_getdesc_iotlb(&vq->vring, &vq->out_iov, &vq->in_iov,\n\t\t\t\t   &vq->head, GFP_ATOMIC);\n\tif (ret != 1)\n\t\treturn false;\n\n\tif (vq->out_iov.used < 1 || vq->in_iov.used < 1) {\n\t\tdev_dbg(&vdpasim->vdpa.dev, \"missing headers - out_iov: %u in_iov %u\\n\",\n\t\t\tvq->out_iov.used, vq->in_iov.used);\n\t\tgoto err;\n\t}\n\n\tif (vq->in_iov.iov[vq->in_iov.used - 1].iov_len < 1) {\n\t\tdev_dbg(&vdpasim->vdpa.dev, \"request in header too short\\n\");\n\t\tgoto err;\n\t}\n\n\t \n\tto_push = vringh_kiov_length(&vq->in_iov) - 1;\n\n\tto_pull = vringh_kiov_length(&vq->out_iov);\n\n\tbytes = vringh_iov_pull_iotlb(&vq->vring, &vq->out_iov, &hdr,\n\t\t\t\t      sizeof(hdr));\n\tif (bytes != sizeof(hdr)) {\n\t\tdev_dbg(&vdpasim->vdpa.dev, \"request out header too short\\n\");\n\t\tgoto err;\n\t}\n\n\tto_pull -= bytes;\n\n\ttype = vdpasim32_to_cpu(vdpasim, hdr.type);\n\tsector = vdpasim64_to_cpu(vdpasim, hdr.sector);\n\toffset = sector << SECTOR_SHIFT;\n\tstatus = VIRTIO_BLK_S_OK;\n\n\tif (type != VIRTIO_BLK_T_IN && type != VIRTIO_BLK_T_OUT &&\n\t    sector != 0) {\n\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\"sector must be 0 for %u request - sector: 0x%llx\\n\",\n\t\t\ttype, sector);\n\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\tgoto err_status;\n\t}\n\n\tswitch (type) {\n\tcase VIRTIO_BLK_T_IN:\n\t\tif (!vdpasim_blk_check_range(vdpasim, sector,\n\t\t\t\t\t     to_push >> SECTOR_SHIFT,\n\t\t\t\t\t     VDPASIM_BLK_SIZE_MAX * VDPASIM_BLK_SEG_MAX)) {\n\t\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\t\tbreak;\n\t\t}\n\n\t\tvdpasim_blk_buffer_lock(blk);\n\t\tbytes = vringh_iov_push_iotlb(&vq->vring, &vq->in_iov,\n\t\t\t\t\t      blk->buffer + offset, to_push);\n\t\tvdpasim_blk_buffer_unlock(blk);\n\t\tif (bytes < 0) {\n\t\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\t\"vringh_iov_push_iotlb() error: %zd offset: 0x%llx len: 0x%zx\\n\",\n\t\t\t\tbytes, offset, to_push);\n\t\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\t\tbreak;\n\t\t}\n\n\t\tpushed += bytes;\n\t\tbreak;\n\n\tcase VIRTIO_BLK_T_OUT:\n\t\tif (!vdpasim_blk_check_range(vdpasim, sector,\n\t\t\t\t\t     to_pull >> SECTOR_SHIFT,\n\t\t\t\t\t     VDPASIM_BLK_SIZE_MAX * VDPASIM_BLK_SEG_MAX)) {\n\t\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\t\tbreak;\n\t\t}\n\n\t\tvdpasim_blk_buffer_lock(blk);\n\t\tbytes = vringh_iov_pull_iotlb(&vq->vring, &vq->out_iov,\n\t\t\t\t\t      blk->buffer + offset, to_pull);\n\t\tvdpasim_blk_buffer_unlock(blk);\n\t\tif (bytes < 0) {\n\t\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\t\"vringh_iov_pull_iotlb() error: %zd offset: 0x%llx len: 0x%zx\\n\",\n\t\t\t\tbytes, offset, to_pull);\n\t\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tcase VIRTIO_BLK_T_GET_ID:\n\t\tbytes = vringh_iov_push_iotlb(&vq->vring, &vq->in_iov,\n\t\t\t\t\t      vdpasim_blk_id,\n\t\t\t\t\t      VIRTIO_BLK_ID_BYTES);\n\t\tif (bytes < 0) {\n\t\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\t\"vringh_iov_push_iotlb() error: %zd\\n\", bytes);\n\t\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\t\tbreak;\n\t\t}\n\n\t\tpushed += bytes;\n\t\tbreak;\n\n\tcase VIRTIO_BLK_T_FLUSH:\n\t\t \n\t\tbreak;\n\n\tcase VIRTIO_BLK_T_DISCARD:\n\tcase VIRTIO_BLK_T_WRITE_ZEROES: {\n\t\tstruct virtio_blk_discard_write_zeroes range;\n\t\tu32 num_sectors, flags;\n\n\t\tif (to_pull != sizeof(range)) {\n\t\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\t\"discard/write_zeroes header len: 0x%zx [expected: 0x%zx]\\n\",\n\t\t\t\tto_pull, sizeof(range));\n\t\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\t\tbreak;\n\t\t}\n\n\t\tbytes = vringh_iov_pull_iotlb(&vq->vring, &vq->out_iov, &range,\n\t\t\t\t\t      to_pull);\n\t\tif (bytes < 0) {\n\t\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\t\"vringh_iov_pull_iotlb() error: %zd offset: 0x%llx len: 0x%zx\\n\",\n\t\t\t\tbytes, offset, to_pull);\n\t\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\t\tbreak;\n\t\t}\n\n\t\tsector = le64_to_cpu(range.sector);\n\t\toffset = sector << SECTOR_SHIFT;\n\t\tnum_sectors = le32_to_cpu(range.num_sectors);\n\t\tflags = le32_to_cpu(range.flags);\n\n\t\tif (type == VIRTIO_BLK_T_DISCARD && flags != 0) {\n\t\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\t\"discard unexpected flags set - flags: 0x%x\\n\",\n\t\t\t\tflags);\n\t\t\tstatus = VIRTIO_BLK_S_UNSUPP;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (type == VIRTIO_BLK_T_WRITE_ZEROES &&\n\t\t    flags & ~VIRTIO_BLK_WRITE_ZEROES_FLAG_UNMAP) {\n\t\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\t\"write_zeroes unexpected flags set - flags: 0x%x\\n\",\n\t\t\t\tflags);\n\t\t\tstatus = VIRTIO_BLK_S_UNSUPP;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!vdpasim_blk_check_range(vdpasim, sector, num_sectors,\n\t\t\t\t\t     VDPASIM_BLK_DWZ_MAX_SECTORS)) {\n\t\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (type == VIRTIO_BLK_T_WRITE_ZEROES) {\n\t\t\tvdpasim_blk_buffer_lock(blk);\n\t\t\tmemset(blk->buffer + offset, 0,\n\t\t\t       num_sectors << SECTOR_SHIFT);\n\t\t\tvdpasim_blk_buffer_unlock(blk);\n\t\t}\n\n\t\tbreak;\n\t}\n\tdefault:\n\t\tdev_dbg(&vdpasim->vdpa.dev,\n\t\t\t\"Unsupported request type %d\\n\", type);\n\t\tstatus = VIRTIO_BLK_S_IOERR;\n\t\tbreak;\n\t}\n\nerr_status:\n\t \n\tif (to_push - pushed > 0)\n\t\tvringh_kiov_advance(&vq->in_iov, to_push - pushed);\n\n\t \n\tbytes = vringh_iov_push_iotlb(&vq->vring, &vq->in_iov, &status, 1);\n\tif (bytes != 1)\n\t\tgoto err;\n\n\tpushed += bytes;\n\n\t \n\tsmp_wmb();\n\n\thandled = true;\n\nerr:\n\tvringh_complete_iotlb(&vq->vring, vq->head, pushed);\n\n\treturn handled;\n}\n\nstatic void vdpasim_blk_work(struct vdpasim *vdpasim)\n{\n\tbool reschedule = false;\n\tint i;\n\n\tmutex_lock(&vdpasim->mutex);\n\n\tif (!(vdpasim->status & VIRTIO_CONFIG_S_DRIVER_OK))\n\t\tgoto out;\n\n\tif (!vdpasim->running)\n\t\tgoto out;\n\n\tfor (i = 0; i < VDPASIM_BLK_VQ_NUM; i++) {\n\t\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[i];\n\t\tint reqs = 0;\n\n\t\tif (!vq->ready)\n\t\t\tcontinue;\n\n\t\twhile (vdpasim_blk_handle_req(vdpasim, vq)) {\n\t\t\t \n\t\t\tsmp_wmb();\n\n\t\t\tlocal_bh_disable();\n\t\t\tif (vringh_need_notify_iotlb(&vq->vring) > 0)\n\t\t\t\tvringh_notify(&vq->vring);\n\t\t\tlocal_bh_enable();\n\n\t\t\tif (++reqs > 4) {\n\t\t\t\treschedule = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\nout:\n\tmutex_unlock(&vdpasim->mutex);\n\n\tif (reschedule)\n\t\tvdpasim_schedule_work(vdpasim);\n}\n\nstatic void vdpasim_blk_get_config(struct vdpasim *vdpasim, void *config)\n{\n\tstruct virtio_blk_config *blk_config = config;\n\n\tmemset(config, 0, sizeof(struct virtio_blk_config));\n\n\tblk_config->capacity = cpu_to_vdpasim64(vdpasim, VDPASIM_BLK_CAPACITY);\n\tblk_config->size_max = cpu_to_vdpasim32(vdpasim, VDPASIM_BLK_SIZE_MAX);\n\tblk_config->seg_max = cpu_to_vdpasim32(vdpasim, VDPASIM_BLK_SEG_MAX);\n\tblk_config->num_queues = cpu_to_vdpasim16(vdpasim, VDPASIM_BLK_VQ_NUM);\n\tblk_config->min_io_size = cpu_to_vdpasim16(vdpasim, 1);\n\tblk_config->opt_io_size = cpu_to_vdpasim32(vdpasim, 1);\n\tblk_config->blk_size = cpu_to_vdpasim32(vdpasim, SECTOR_SIZE);\n\t \n\tblk_config->discard_sector_alignment =\n\t\tcpu_to_vdpasim32(vdpasim, SECTOR_SIZE);\n\tblk_config->max_discard_sectors =\n\t\tcpu_to_vdpasim32(vdpasim, VDPASIM_BLK_DWZ_MAX_SECTORS);\n\tblk_config->max_discard_seg = cpu_to_vdpasim32(vdpasim, 1);\n\t \n\tblk_config->max_write_zeroes_sectors =\n\t\tcpu_to_vdpasim32(vdpasim, VDPASIM_BLK_DWZ_MAX_SECTORS);\n\tblk_config->max_write_zeroes_seg = cpu_to_vdpasim32(vdpasim, 1);\n\n}\n\nstatic void vdpasim_blk_free(struct vdpasim *vdpasim)\n{\n\tstruct vdpasim_blk *blk = sim_to_blk(vdpasim);\n\n\tif (!blk->shared_backend)\n\t\tkvfree(blk->buffer);\n}\n\nstatic void vdpasim_blk_mgmtdev_release(struct device *dev)\n{\n}\n\nstatic struct device vdpasim_blk_mgmtdev = {\n\t.init_name = \"vdpasim_blk\",\n\t.release = vdpasim_blk_mgmtdev_release,\n};\n\nstatic int vdpasim_blk_dev_add(struct vdpa_mgmt_dev *mdev, const char *name,\n\t\t\t       const struct vdpa_dev_set_config *config)\n{\n\tstruct vdpasim_dev_attr dev_attr = {};\n\tstruct vdpasim_blk *blk;\n\tstruct vdpasim *simdev;\n\tint ret;\n\n\tdev_attr.mgmt_dev = mdev;\n\tdev_attr.name = name;\n\tdev_attr.id = VIRTIO_ID_BLOCK;\n\tdev_attr.supported_features = VDPASIM_BLK_FEATURES;\n\tdev_attr.nvqs = VDPASIM_BLK_VQ_NUM;\n\tdev_attr.ngroups = VDPASIM_BLK_GROUP_NUM;\n\tdev_attr.nas = VDPASIM_BLK_AS_NUM;\n\tdev_attr.alloc_size = sizeof(struct vdpasim_blk);\n\tdev_attr.config_size = sizeof(struct virtio_blk_config);\n\tdev_attr.get_config = vdpasim_blk_get_config;\n\tdev_attr.work_fn = vdpasim_blk_work;\n\tdev_attr.free = vdpasim_blk_free;\n\n\tsimdev = vdpasim_create(&dev_attr, config);\n\tif (IS_ERR(simdev))\n\t\treturn PTR_ERR(simdev);\n\n\tblk = sim_to_blk(simdev);\n\tblk->shared_backend = shared_backend;\n\n\tif (blk->shared_backend) {\n\t\tblk->buffer = shared_buffer;\n\t} else {\n\t\tblk->buffer = kvzalloc(VDPASIM_BLK_CAPACITY << SECTOR_SHIFT,\n\t\t\t\t       GFP_KERNEL);\n\t\tif (!blk->buffer) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto put_dev;\n\t\t}\n\t}\n\n\tret = _vdpa_register_device(&simdev->vdpa, VDPASIM_BLK_VQ_NUM);\n\tif (ret)\n\t\tgoto put_dev;\n\n\treturn 0;\n\nput_dev:\n\tput_device(&simdev->vdpa.dev);\n\treturn ret;\n}\n\nstatic void vdpasim_blk_dev_del(struct vdpa_mgmt_dev *mdev,\n\t\t\t\tstruct vdpa_device *dev)\n{\n\tstruct vdpasim *simdev = container_of(dev, struct vdpasim, vdpa);\n\n\t_vdpa_unregister_device(&simdev->vdpa);\n}\n\nstatic const struct vdpa_mgmtdev_ops vdpasim_blk_mgmtdev_ops = {\n\t.dev_add = vdpasim_blk_dev_add,\n\t.dev_del = vdpasim_blk_dev_del\n};\n\nstatic struct virtio_device_id id_table[] = {\n\t{ VIRTIO_ID_BLOCK, VIRTIO_DEV_ANY_ID },\n\t{ 0 },\n};\n\nstatic struct vdpa_mgmt_dev mgmt_dev = {\n\t.device = &vdpasim_blk_mgmtdev,\n\t.id_table = id_table,\n\t.ops = &vdpasim_blk_mgmtdev_ops,\n};\n\nstatic int __init vdpasim_blk_init(void)\n{\n\tint ret;\n\n\tret = device_register(&vdpasim_blk_mgmtdev);\n\tif (ret) {\n\t\tput_device(&vdpasim_blk_mgmtdev);\n\t\treturn ret;\n\t}\n\n\tret = vdpa_mgmtdev_register(&mgmt_dev);\n\tif (ret)\n\t\tgoto parent_err;\n\n\tif (shared_backend) {\n\t\tshared_buffer = kvzalloc(VDPASIM_BLK_CAPACITY << SECTOR_SHIFT,\n\t\t\t\t\t GFP_KERNEL);\n\t\tif (!shared_buffer) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto mgmt_dev_err;\n\t\t}\n\t}\n\n\treturn 0;\nmgmt_dev_err:\n\tvdpa_mgmtdev_unregister(&mgmt_dev);\nparent_err:\n\tdevice_unregister(&vdpasim_blk_mgmtdev);\n\treturn ret;\n}\n\nstatic void __exit vdpasim_blk_exit(void)\n{\n\tkvfree(shared_buffer);\n\tvdpa_mgmtdev_unregister(&mgmt_dev);\n\tdevice_unregister(&vdpasim_blk_mgmtdev);\n}\n\nmodule_init(vdpasim_blk_init)\nmodule_exit(vdpasim_blk_exit)\n\nMODULE_VERSION(DRV_VERSION);\nMODULE_LICENSE(DRV_LICENSE);\nMODULE_AUTHOR(DRV_AUTHOR);\nMODULE_DESCRIPTION(DRV_DESC);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}