{
  "module_name": "vdpa_sim.c",
  "hash_id": "497a8922bba6002ab80dd723f4e1c6b268aa02e389ae52ec0563bae93aa7c46b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/vdpa/vdpa_sim/vdpa_sim.c",
  "human_readable_source": "\n \n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/device.h>\n#include <linux/kernel.h>\n#include <linux/kthread.h>\n#include <linux/slab.h>\n#include <linux/dma-map-ops.h>\n#include <linux/vringh.h>\n#include <linux/vdpa.h>\n#include <linux/vhost_iotlb.h>\n#include <uapi/linux/vdpa.h>\n#include <uapi/linux/vhost_types.h>\n\n#include \"vdpa_sim.h\"\n\n#define DRV_VERSION  \"0.1\"\n#define DRV_AUTHOR   \"Jason Wang <jasowang@redhat.com>\"\n#define DRV_DESC     \"vDPA Device Simulator core\"\n#define DRV_LICENSE  \"GPL v2\"\n\nstatic int batch_mapping = 1;\nmodule_param(batch_mapping, int, 0444);\nMODULE_PARM_DESC(batch_mapping, \"Batched mapping 1 -Enable; 0 - Disable\");\n\nstatic int max_iotlb_entries = 2048;\nmodule_param(max_iotlb_entries, int, 0444);\nMODULE_PARM_DESC(max_iotlb_entries,\n\t\t \"Maximum number of iotlb entries for each address space. 0 means unlimited. (default: 2048)\");\n\nstatic bool use_va = true;\nmodule_param(use_va, bool, 0444);\nMODULE_PARM_DESC(use_va, \"Enable/disable the device's ability to use VA\");\n\n#define VDPASIM_QUEUE_ALIGN PAGE_SIZE\n#define VDPASIM_QUEUE_MAX 256\n#define VDPASIM_VENDOR_ID 0\n\nstruct vdpasim_mm_work {\n\tstruct kthread_work work;\n\tstruct vdpasim *vdpasim;\n\tstruct mm_struct *mm_to_bind;\n\tint ret;\n};\n\nstatic void vdpasim_mm_work_fn(struct kthread_work *work)\n{\n\tstruct vdpasim_mm_work *mm_work =\n\t\tcontainer_of(work, struct vdpasim_mm_work, work);\n\tstruct vdpasim *vdpasim = mm_work->vdpasim;\n\n\tmm_work->ret = 0;\n\n\t\n\tvdpasim->mm_bound = mm_work->mm_to_bind;\n}\n\nstatic void vdpasim_worker_change_mm_sync(struct vdpasim *vdpasim,\n\t\t\t\t\t  struct vdpasim_mm_work *mm_work)\n{\n\tstruct kthread_work *work = &mm_work->work;\n\n\tkthread_init_work(work, vdpasim_mm_work_fn);\n\tkthread_queue_work(vdpasim->worker, work);\n\n\tkthread_flush_work(work);\n}\n\nstatic struct vdpasim *vdpa_to_sim(struct vdpa_device *vdpa)\n{\n\treturn container_of(vdpa, struct vdpasim, vdpa);\n}\n\nstatic void vdpasim_vq_notify(struct vringh *vring)\n{\n\tstruct vdpasim_virtqueue *vq =\n\t\tcontainer_of(vring, struct vdpasim_virtqueue, vring);\n\n\tif (!vq->cb)\n\t\treturn;\n\n\tvq->cb(vq->private);\n}\n\nstatic void vdpasim_queue_ready(struct vdpasim *vdpasim, unsigned int idx)\n{\n\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[idx];\n\tuint16_t last_avail_idx = vq->vring.last_avail_idx;\n\tstruct vring_desc *desc = (struct vring_desc *)\n\t\t\t\t  (uintptr_t)vq->desc_addr;\n\tstruct vring_avail *avail = (struct vring_avail *)\n\t\t\t\t    (uintptr_t)vq->driver_addr;\n\tstruct vring_used *used = (struct vring_used *)\n\t\t\t\t  (uintptr_t)vq->device_addr;\n\n\tif (use_va && vdpasim->mm_bound) {\n\t\tvringh_init_iotlb_va(&vq->vring, vdpasim->features, vq->num,\n\t\t\t\t     true, desc, avail, used);\n\t} else {\n\t\tvringh_init_iotlb(&vq->vring, vdpasim->features, vq->num,\n\t\t\t\t  true, desc, avail, used);\n\t}\n\n\tvq->vring.last_avail_idx = last_avail_idx;\n\n\t \n\tvq->vring.last_used_idx = last_avail_idx;\n\tvq->vring.notify = vdpasim_vq_notify;\n}\n\nstatic void vdpasim_vq_reset(struct vdpasim *vdpasim,\n\t\t\t     struct vdpasim_virtqueue *vq)\n{\n\tvq->ready = false;\n\tvq->desc_addr = 0;\n\tvq->driver_addr = 0;\n\tvq->device_addr = 0;\n\tvq->cb = NULL;\n\tvq->private = NULL;\n\tvringh_init_iotlb(&vq->vring, vdpasim->dev_attr.supported_features,\n\t\t\t  VDPASIM_QUEUE_MAX, false, NULL, NULL, NULL);\n\n\tvq->vring.notify = NULL;\n}\n\nstatic void vdpasim_do_reset(struct vdpasim *vdpasim)\n{\n\tint i;\n\n\tspin_lock(&vdpasim->iommu_lock);\n\n\tfor (i = 0; i < vdpasim->dev_attr.nvqs; i++) {\n\t\tvdpasim_vq_reset(vdpasim, &vdpasim->vqs[i]);\n\t\tvringh_set_iotlb(&vdpasim->vqs[i].vring, &vdpasim->iommu[0],\n\t\t\t\t &vdpasim->iommu_lock);\n\t}\n\n\tfor (i = 0; i < vdpasim->dev_attr.nas; i++) {\n\t\tvhost_iotlb_reset(&vdpasim->iommu[i]);\n\t\tvhost_iotlb_add_range(&vdpasim->iommu[i], 0, ULONG_MAX,\n\t\t\t\t      0, VHOST_MAP_RW);\n\t\tvdpasim->iommu_pt[i] = true;\n\t}\n\n\tvdpasim->running = true;\n\tspin_unlock(&vdpasim->iommu_lock);\n\n\tvdpasim->features = 0;\n\tvdpasim->status = 0;\n\t++vdpasim->generation;\n}\n\nstatic const struct vdpa_config_ops vdpasim_config_ops;\nstatic const struct vdpa_config_ops vdpasim_batch_config_ops;\n\nstatic void vdpasim_work_fn(struct kthread_work *work)\n{\n\tstruct vdpasim *vdpasim = container_of(work, struct vdpasim, work);\n\tstruct mm_struct *mm = vdpasim->mm_bound;\n\n\tif (use_va && mm) {\n\t\tif (!mmget_not_zero(mm))\n\t\t\treturn;\n\t\tkthread_use_mm(mm);\n\t}\n\n\tvdpasim->dev_attr.work_fn(vdpasim);\n\n\tif (use_va && mm) {\n\t\tkthread_unuse_mm(mm);\n\t\tmmput(mm);\n\t}\n}\n\nstruct vdpasim *vdpasim_create(struct vdpasim_dev_attr *dev_attr,\n\t\t\t       const struct vdpa_dev_set_config *config)\n{\n\tconst struct vdpa_config_ops *ops;\n\tstruct vdpa_device *vdpa;\n\tstruct vdpasim *vdpasim;\n\tstruct device *dev;\n\tint i, ret = -ENOMEM;\n\n\tif (!dev_attr->alloc_size)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (config->mask & BIT_ULL(VDPA_ATTR_DEV_FEATURES)) {\n\t\tif (config->device_features &\n\t\t    ~dev_attr->supported_features)\n\t\t\treturn ERR_PTR(-EINVAL);\n\t\tdev_attr->supported_features =\n\t\t\tconfig->device_features;\n\t}\n\n\tif (batch_mapping)\n\t\tops = &vdpasim_batch_config_ops;\n\telse\n\t\tops = &vdpasim_config_ops;\n\n\tvdpa = __vdpa_alloc_device(NULL, ops,\n\t\t\t\t   dev_attr->ngroups, dev_attr->nas,\n\t\t\t\t   dev_attr->alloc_size,\n\t\t\t\t   dev_attr->name, use_va);\n\tif (IS_ERR(vdpa)) {\n\t\tret = PTR_ERR(vdpa);\n\t\tgoto err_alloc;\n\t}\n\n\tvdpasim = vdpa_to_sim(vdpa);\n\tvdpasim->dev_attr = *dev_attr;\n\tdev = &vdpasim->vdpa.dev;\n\n\tkthread_init_work(&vdpasim->work, vdpasim_work_fn);\n\tvdpasim->worker = kthread_create_worker(0, \"vDPA sim worker: %s\",\n\t\t\t\t\t\tdev_attr->name);\n\tif (IS_ERR(vdpasim->worker))\n\t\tgoto err_iommu;\n\n\tmutex_init(&vdpasim->mutex);\n\tspin_lock_init(&vdpasim->iommu_lock);\n\n\tdev->dma_mask = &dev->coherent_dma_mask;\n\tif (dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64)))\n\t\tgoto err_iommu;\n\tvdpasim->vdpa.mdev = dev_attr->mgmt_dev;\n\n\tvdpasim->config = kzalloc(dev_attr->config_size, GFP_KERNEL);\n\tif (!vdpasim->config)\n\t\tgoto err_iommu;\n\n\tvdpasim->vqs = kcalloc(dev_attr->nvqs, sizeof(struct vdpasim_virtqueue),\n\t\t\t       GFP_KERNEL);\n\tif (!vdpasim->vqs)\n\t\tgoto err_iommu;\n\n\tvdpasim->iommu = kmalloc_array(vdpasim->dev_attr.nas,\n\t\t\t\t       sizeof(*vdpasim->iommu), GFP_KERNEL);\n\tif (!vdpasim->iommu)\n\t\tgoto err_iommu;\n\n\tvdpasim->iommu_pt = kmalloc_array(vdpasim->dev_attr.nas,\n\t\t\t\t\t  sizeof(*vdpasim->iommu_pt), GFP_KERNEL);\n\tif (!vdpasim->iommu_pt)\n\t\tgoto err_iommu;\n\n\tfor (i = 0; i < vdpasim->dev_attr.nas; i++)\n\t\tvhost_iotlb_init(&vdpasim->iommu[i], max_iotlb_entries, 0);\n\n\tfor (i = 0; i < dev_attr->nvqs; i++)\n\t\tvringh_set_iotlb(&vdpasim->vqs[i].vring, &vdpasim->iommu[0],\n\t\t\t\t &vdpasim->iommu_lock);\n\n\tvdpasim->vdpa.dma_dev = dev;\n\n\treturn vdpasim;\n\nerr_iommu:\n\tput_device(dev);\nerr_alloc:\n\treturn ERR_PTR(ret);\n}\nEXPORT_SYMBOL_GPL(vdpasim_create);\n\nvoid vdpasim_schedule_work(struct vdpasim *vdpasim)\n{\n\tkthread_queue_work(vdpasim->worker, &vdpasim->work);\n}\nEXPORT_SYMBOL_GPL(vdpasim_schedule_work);\n\nstatic int vdpasim_set_vq_address(struct vdpa_device *vdpa, u16 idx,\n\t\t\t\t  u64 desc_area, u64 driver_area,\n\t\t\t\t  u64 device_area)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[idx];\n\n\tvq->desc_addr = desc_area;\n\tvq->driver_addr = driver_area;\n\tvq->device_addr = device_area;\n\n\treturn 0;\n}\n\nstatic void vdpasim_set_vq_num(struct vdpa_device *vdpa, u16 idx, u32 num)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[idx];\n\n\tvq->num = num;\n}\n\nstatic void vdpasim_kick_vq(struct vdpa_device *vdpa, u16 idx)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[idx];\n\n\tif (!vdpasim->running &&\n\t    (vdpasim->status & VIRTIO_CONFIG_S_DRIVER_OK)) {\n\t\tvdpasim->pending_kick = true;\n\t\treturn;\n\t}\n\n\tif (vq->ready)\n\t\tvdpasim_schedule_work(vdpasim);\n}\n\nstatic void vdpasim_set_vq_cb(struct vdpa_device *vdpa, u16 idx,\n\t\t\t      struct vdpa_callback *cb)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[idx];\n\n\tvq->cb = cb->callback;\n\tvq->private = cb->private;\n}\n\nstatic void vdpasim_set_vq_ready(struct vdpa_device *vdpa, u16 idx, bool ready)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[idx];\n\tbool old_ready;\n\n\tmutex_lock(&vdpasim->mutex);\n\told_ready = vq->ready;\n\tvq->ready = ready;\n\tif (vq->ready && !old_ready) {\n\t\tvdpasim_queue_ready(vdpasim, idx);\n\t}\n\tmutex_unlock(&vdpasim->mutex);\n}\n\nstatic bool vdpasim_get_vq_ready(struct vdpa_device *vdpa, u16 idx)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[idx];\n\n\treturn vq->ready;\n}\n\nstatic int vdpasim_set_vq_state(struct vdpa_device *vdpa, u16 idx,\n\t\t\t\tconst struct vdpa_vq_state *state)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[idx];\n\tstruct vringh *vrh = &vq->vring;\n\n\tmutex_lock(&vdpasim->mutex);\n\tvrh->last_avail_idx = state->split.avail_index;\n\tmutex_unlock(&vdpasim->mutex);\n\n\treturn 0;\n}\n\nstatic int vdpasim_get_vq_state(struct vdpa_device *vdpa, u16 idx,\n\t\t\t\tstruct vdpa_vq_state *state)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_virtqueue *vq = &vdpasim->vqs[idx];\n\tstruct vringh *vrh = &vq->vring;\n\n\tstate->split.avail_index = vrh->last_avail_idx;\n\treturn 0;\n}\n\nstatic int vdpasim_get_vq_stats(struct vdpa_device *vdpa, u16 idx,\n\t\t\t\tstruct sk_buff *msg,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\tif (vdpasim->dev_attr.get_stats)\n\t\treturn vdpasim->dev_attr.get_stats(vdpasim, idx,\n\t\t\t\t\t\t   msg, extack);\n\treturn -EOPNOTSUPP;\n}\n\nstatic u32 vdpasim_get_vq_align(struct vdpa_device *vdpa)\n{\n\treturn VDPASIM_QUEUE_ALIGN;\n}\n\nstatic u32 vdpasim_get_vq_group(struct vdpa_device *vdpa, u16 idx)\n{\n\t \n\tif (idx == 2)\n\t\treturn 1;\n\telse\n\t\treturn 0;\n}\n\nstatic u64 vdpasim_get_device_features(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\treturn vdpasim->dev_attr.supported_features;\n}\n\nstatic u64 vdpasim_get_backend_features(const struct vdpa_device *vdpa)\n{\n\treturn BIT_ULL(VHOST_BACKEND_F_ENABLE_AFTER_DRIVER_OK);\n}\n\nstatic int vdpasim_set_driver_features(struct vdpa_device *vdpa, u64 features)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\t \n\tif (!(features & (1ULL << VIRTIO_F_ACCESS_PLATFORM)))\n\t\treturn -EINVAL;\n\n\tvdpasim->features = features & vdpasim->dev_attr.supported_features;\n\n\treturn 0;\n}\n\nstatic u64 vdpasim_get_driver_features(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\treturn vdpasim->features;\n}\n\nstatic void vdpasim_set_config_cb(struct vdpa_device *vdpa,\n\t\t\t\t  struct vdpa_callback *cb)\n{\n\t \n}\n\nstatic u16 vdpasim_get_vq_num_max(struct vdpa_device *vdpa)\n{\n\treturn VDPASIM_QUEUE_MAX;\n}\n\nstatic u32 vdpasim_get_device_id(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\treturn vdpasim->dev_attr.id;\n}\n\nstatic u32 vdpasim_get_vendor_id(struct vdpa_device *vdpa)\n{\n\treturn VDPASIM_VENDOR_ID;\n}\n\nstatic u8 vdpasim_get_status(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tu8 status;\n\n\tmutex_lock(&vdpasim->mutex);\n\tstatus = vdpasim->status;\n\tmutex_unlock(&vdpasim->mutex);\n\n\treturn status;\n}\n\nstatic void vdpasim_set_status(struct vdpa_device *vdpa, u8 status)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\tmutex_lock(&vdpasim->mutex);\n\tvdpasim->status = status;\n\tmutex_unlock(&vdpasim->mutex);\n}\n\nstatic int vdpasim_reset(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\tmutex_lock(&vdpasim->mutex);\n\tvdpasim->status = 0;\n\tvdpasim_do_reset(vdpasim);\n\tmutex_unlock(&vdpasim->mutex);\n\n\treturn 0;\n}\n\nstatic int vdpasim_suspend(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\tmutex_lock(&vdpasim->mutex);\n\tvdpasim->running = false;\n\tmutex_unlock(&vdpasim->mutex);\n\n\treturn 0;\n}\n\nstatic int vdpasim_resume(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tint i;\n\n\tmutex_lock(&vdpasim->mutex);\n\tvdpasim->running = true;\n\n\tif (vdpasim->pending_kick) {\n\t\t \n\t\tfor (i = 0; i < vdpasim->dev_attr.nvqs; ++i)\n\t\t\tvdpasim_kick_vq(vdpa, i);\n\n\t\tvdpasim->pending_kick = false;\n\t}\n\n\tmutex_unlock(&vdpasim->mutex);\n\n\treturn 0;\n}\n\nstatic size_t vdpasim_get_config_size(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\treturn vdpasim->dev_attr.config_size;\n}\n\nstatic void vdpasim_get_config(struct vdpa_device *vdpa, unsigned int offset,\n\t\t\t     void *buf, unsigned int len)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\tif (offset + len > vdpasim->dev_attr.config_size)\n\t\treturn;\n\n\tif (vdpasim->dev_attr.get_config)\n\t\tvdpasim->dev_attr.get_config(vdpasim, vdpasim->config);\n\n\tmemcpy(buf, vdpasim->config + offset, len);\n}\n\nstatic void vdpasim_set_config(struct vdpa_device *vdpa, unsigned int offset,\n\t\t\t     const void *buf, unsigned int len)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\tif (offset + len > vdpasim->dev_attr.config_size)\n\t\treturn;\n\n\tmemcpy(vdpasim->config + offset, buf, len);\n\n\tif (vdpasim->dev_attr.set_config)\n\t\tvdpasim->dev_attr.set_config(vdpasim, vdpasim->config);\n}\n\nstatic u32 vdpasim_get_generation(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\treturn vdpasim->generation;\n}\n\nstatic struct vdpa_iova_range vdpasim_get_iova_range(struct vdpa_device *vdpa)\n{\n\tstruct vdpa_iova_range range = {\n\t\t.first = 0ULL,\n\t\t.last = ULLONG_MAX,\n\t};\n\n\treturn range;\n}\n\nstatic int vdpasim_set_group_asid(struct vdpa_device *vdpa, unsigned int group,\n\t\t\t\t  unsigned int asid)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vhost_iotlb *iommu;\n\tint i;\n\n\tif (group > vdpasim->dev_attr.ngroups)\n\t\treturn -EINVAL;\n\n\tif (asid >= vdpasim->dev_attr.nas)\n\t\treturn -EINVAL;\n\n\tiommu = &vdpasim->iommu[asid];\n\n\tmutex_lock(&vdpasim->mutex);\n\n\tfor (i = 0; i < vdpasim->dev_attr.nvqs; i++)\n\t\tif (vdpasim_get_vq_group(vdpa, i) == group)\n\t\t\tvringh_set_iotlb(&vdpasim->vqs[i].vring, iommu,\n\t\t\t\t\t &vdpasim->iommu_lock);\n\n\tmutex_unlock(&vdpasim->mutex);\n\n\treturn 0;\n}\n\nstatic int vdpasim_set_map(struct vdpa_device *vdpa, unsigned int asid,\n\t\t\t   struct vhost_iotlb *iotlb)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vhost_iotlb_map *map;\n\tstruct vhost_iotlb *iommu;\n\tu64 start = 0ULL, last = 0ULL - 1;\n\tint ret;\n\n\tif (asid >= vdpasim->dev_attr.nas)\n\t\treturn -EINVAL;\n\n\tspin_lock(&vdpasim->iommu_lock);\n\n\tiommu = &vdpasim->iommu[asid];\n\tvhost_iotlb_reset(iommu);\n\tvdpasim->iommu_pt[asid] = false;\n\n\tfor (map = vhost_iotlb_itree_first(iotlb, start, last); map;\n\t     map = vhost_iotlb_itree_next(map, start, last)) {\n\t\tret = vhost_iotlb_add_range(iommu, map->start,\n\t\t\t\t\t    map->last, map->addr, map->perm);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\tspin_unlock(&vdpasim->iommu_lock);\n\treturn 0;\n\nerr:\n\tvhost_iotlb_reset(iommu);\n\tspin_unlock(&vdpasim->iommu_lock);\n\treturn ret;\n}\n\nstatic int vdpasim_bind_mm(struct vdpa_device *vdpa, struct mm_struct *mm)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_mm_work mm_work;\n\n\tmm_work.vdpasim = vdpasim;\n\tmm_work.mm_to_bind = mm;\n\n\tvdpasim_worker_change_mm_sync(vdpasim, &mm_work);\n\n\treturn mm_work.ret;\n}\n\nstatic void vdpasim_unbind_mm(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tstruct vdpasim_mm_work mm_work;\n\n\tmm_work.vdpasim = vdpasim;\n\tmm_work.mm_to_bind = NULL;\n\n\tvdpasim_worker_change_mm_sync(vdpasim, &mm_work);\n}\n\nstatic int vdpasim_dma_map(struct vdpa_device *vdpa, unsigned int asid,\n\t\t\t   u64 iova, u64 size,\n\t\t\t   u64 pa, u32 perm, void *opaque)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tint ret;\n\n\tif (asid >= vdpasim->dev_attr.nas)\n\t\treturn -EINVAL;\n\n\tspin_lock(&vdpasim->iommu_lock);\n\tif (vdpasim->iommu_pt[asid]) {\n\t\tvhost_iotlb_reset(&vdpasim->iommu[asid]);\n\t\tvdpasim->iommu_pt[asid] = false;\n\t}\n\tret = vhost_iotlb_add_range_ctx(&vdpasim->iommu[asid], iova,\n\t\t\t\t\tiova + size - 1, pa, perm, opaque);\n\tspin_unlock(&vdpasim->iommu_lock);\n\n\treturn ret;\n}\n\nstatic int vdpasim_dma_unmap(struct vdpa_device *vdpa, unsigned int asid,\n\t\t\t     u64 iova, u64 size)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\n\tif (asid >= vdpasim->dev_attr.nas)\n\t\treturn -EINVAL;\n\n\tif (vdpasim->iommu_pt[asid]) {\n\t\tvhost_iotlb_reset(&vdpasim->iommu[asid]);\n\t\tvdpasim->iommu_pt[asid] = false;\n\t}\n\n\tspin_lock(&vdpasim->iommu_lock);\n\tvhost_iotlb_del_range(&vdpasim->iommu[asid], iova, iova + size - 1);\n\tspin_unlock(&vdpasim->iommu_lock);\n\n\treturn 0;\n}\n\nstatic void vdpasim_free(struct vdpa_device *vdpa)\n{\n\tstruct vdpasim *vdpasim = vdpa_to_sim(vdpa);\n\tint i;\n\n\tkthread_cancel_work_sync(&vdpasim->work);\n\tkthread_destroy_worker(vdpasim->worker);\n\n\tfor (i = 0; i < vdpasim->dev_attr.nvqs; i++) {\n\t\tvringh_kiov_cleanup(&vdpasim->vqs[i].out_iov);\n\t\tvringh_kiov_cleanup(&vdpasim->vqs[i].in_iov);\n\t}\n\n\tvdpasim->dev_attr.free(vdpasim);\n\n\tfor (i = 0; i < vdpasim->dev_attr.nas; i++)\n\t\tvhost_iotlb_reset(&vdpasim->iommu[i]);\n\tkfree(vdpasim->iommu);\n\tkfree(vdpasim->iommu_pt);\n\tkfree(vdpasim->vqs);\n\tkfree(vdpasim->config);\n}\n\nstatic const struct vdpa_config_ops vdpasim_config_ops = {\n\t.set_vq_address         = vdpasim_set_vq_address,\n\t.set_vq_num             = vdpasim_set_vq_num,\n\t.kick_vq                = vdpasim_kick_vq,\n\t.set_vq_cb              = vdpasim_set_vq_cb,\n\t.set_vq_ready           = vdpasim_set_vq_ready,\n\t.get_vq_ready           = vdpasim_get_vq_ready,\n\t.set_vq_state           = vdpasim_set_vq_state,\n\t.get_vendor_vq_stats    = vdpasim_get_vq_stats,\n\t.get_vq_state           = vdpasim_get_vq_state,\n\t.get_vq_align           = vdpasim_get_vq_align,\n\t.get_vq_group           = vdpasim_get_vq_group,\n\t.get_device_features    = vdpasim_get_device_features,\n\t.get_backend_features   = vdpasim_get_backend_features,\n\t.set_driver_features    = vdpasim_set_driver_features,\n\t.get_driver_features    = vdpasim_get_driver_features,\n\t.set_config_cb          = vdpasim_set_config_cb,\n\t.get_vq_num_max         = vdpasim_get_vq_num_max,\n\t.get_device_id          = vdpasim_get_device_id,\n\t.get_vendor_id          = vdpasim_get_vendor_id,\n\t.get_status             = vdpasim_get_status,\n\t.set_status             = vdpasim_set_status,\n\t.reset\t\t\t= vdpasim_reset,\n\t.suspend\t\t= vdpasim_suspend,\n\t.resume\t\t\t= vdpasim_resume,\n\t.get_config_size        = vdpasim_get_config_size,\n\t.get_config             = vdpasim_get_config,\n\t.set_config             = vdpasim_set_config,\n\t.get_generation         = vdpasim_get_generation,\n\t.get_iova_range         = vdpasim_get_iova_range,\n\t.set_group_asid         = vdpasim_set_group_asid,\n\t.dma_map                = vdpasim_dma_map,\n\t.dma_unmap              = vdpasim_dma_unmap,\n\t.bind_mm\t\t= vdpasim_bind_mm,\n\t.unbind_mm\t\t= vdpasim_unbind_mm,\n\t.free                   = vdpasim_free,\n};\n\nstatic const struct vdpa_config_ops vdpasim_batch_config_ops = {\n\t.set_vq_address         = vdpasim_set_vq_address,\n\t.set_vq_num             = vdpasim_set_vq_num,\n\t.kick_vq                = vdpasim_kick_vq,\n\t.set_vq_cb              = vdpasim_set_vq_cb,\n\t.set_vq_ready           = vdpasim_set_vq_ready,\n\t.get_vq_ready           = vdpasim_get_vq_ready,\n\t.set_vq_state           = vdpasim_set_vq_state,\n\t.get_vendor_vq_stats    = vdpasim_get_vq_stats,\n\t.get_vq_state           = vdpasim_get_vq_state,\n\t.get_vq_align           = vdpasim_get_vq_align,\n\t.get_vq_group           = vdpasim_get_vq_group,\n\t.get_device_features    = vdpasim_get_device_features,\n\t.get_backend_features   = vdpasim_get_backend_features,\n\t.set_driver_features    = vdpasim_set_driver_features,\n\t.get_driver_features    = vdpasim_get_driver_features,\n\t.set_config_cb          = vdpasim_set_config_cb,\n\t.get_vq_num_max         = vdpasim_get_vq_num_max,\n\t.get_device_id          = vdpasim_get_device_id,\n\t.get_vendor_id          = vdpasim_get_vendor_id,\n\t.get_status             = vdpasim_get_status,\n\t.set_status             = vdpasim_set_status,\n\t.reset\t\t\t= vdpasim_reset,\n\t.suspend\t\t= vdpasim_suspend,\n\t.resume\t\t\t= vdpasim_resume,\n\t.get_config_size        = vdpasim_get_config_size,\n\t.get_config             = vdpasim_get_config,\n\t.set_config             = vdpasim_set_config,\n\t.get_generation         = vdpasim_get_generation,\n\t.get_iova_range         = vdpasim_get_iova_range,\n\t.set_group_asid         = vdpasim_set_group_asid,\n\t.set_map                = vdpasim_set_map,\n\t.bind_mm\t\t= vdpasim_bind_mm,\n\t.unbind_mm\t\t= vdpasim_unbind_mm,\n\t.free                   = vdpasim_free,\n};\n\nMODULE_VERSION(DRV_VERSION);\nMODULE_LICENSE(DRV_LICENSE);\nMODULE_AUTHOR(DRV_AUTHOR);\nMODULE_DESCRIPTION(DRV_DESC);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}