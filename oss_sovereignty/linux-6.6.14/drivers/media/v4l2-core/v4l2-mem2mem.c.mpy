{
  "module_name": "v4l2-mem2mem.c",
  "hash_id": "61a1b78ba0ec7ee0ec344086dad7310ecb68aaad7482e9a3bfaac499ed69bcfc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/v4l2-core/v4l2-mem2mem.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n\n#include <media/media-device.h>\n#include <media/videobuf2-v4l2.h>\n#include <media/v4l2-mem2mem.h>\n#include <media/v4l2-dev.h>\n#include <media/v4l2-device.h>\n#include <media/v4l2-fh.h>\n#include <media/v4l2-event.h>\n\nMODULE_DESCRIPTION(\"Mem to mem device framework for vb2\");\nMODULE_AUTHOR(\"Pawel Osciak, <pawel@osciak.com>\");\nMODULE_LICENSE(\"GPL\");\n\nstatic bool debug;\nmodule_param(debug, bool, 0644);\n\n#define dprintk(fmt, arg...)\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (debug)\t\t\t\t\t\t\\\n\t\t\tprintk(KERN_DEBUG \"%s: \" fmt, __func__, ## arg);\\\n\t} while (0)\n\n\n \n#define TRANS_QUEUED\t\t(1 << 0)\n \n#define TRANS_RUNNING\t\t(1 << 1)\n \n#define TRANS_ABORT\t\t(1 << 2)\n\n\n \n#define QUEUE_PAUSED\t\t(1 << 0)\n\n\n \n#define DST_QUEUE_OFF_BASE\t(1 << 30)\n\nenum v4l2_m2m_entity_type {\n\tMEM2MEM_ENT_TYPE_SOURCE,\n\tMEM2MEM_ENT_TYPE_SINK,\n\tMEM2MEM_ENT_TYPE_PROC\n};\n\nstatic const char * const m2m_entity_name[] = {\n\t\"source\",\n\t\"sink\",\n\t\"proc\"\n};\n\n \nstruct v4l2_m2m_dev {\n\tstruct v4l2_m2m_ctx\t*curr_ctx;\n#ifdef CONFIG_MEDIA_CONTROLLER\n\tstruct media_entity\t*source;\n\tstruct media_pad\tsource_pad;\n\tstruct media_entity\tsink;\n\tstruct media_pad\tsink_pad;\n\tstruct media_entity\tproc;\n\tstruct media_pad\tproc_pads[2];\n\tstruct media_intf_devnode *intf_devnode;\n#endif\n\n\tstruct list_head\tjob_queue;\n\tspinlock_t\t\tjob_spinlock;\n\tstruct work_struct\tjob_work;\n\tunsigned long\t\tjob_queue_flags;\n\n\tconst struct v4l2_m2m_ops *m2m_ops;\n};\n\nstatic struct v4l2_m2m_queue_ctx *get_queue_ctx(struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t\t\t\tenum v4l2_buf_type type)\n{\n\tif (V4L2_TYPE_IS_OUTPUT(type))\n\t\treturn &m2m_ctx->out_q_ctx;\n\telse\n\t\treturn &m2m_ctx->cap_q_ctx;\n}\n\nstruct vb2_queue *v4l2_m2m_get_vq(struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t\t       enum v4l2_buf_type type)\n{\n\tstruct v4l2_m2m_queue_ctx *q_ctx;\n\n\tq_ctx = get_queue_ctx(m2m_ctx, type);\n\tif (!q_ctx)\n\t\treturn NULL;\n\n\treturn &q_ctx->q;\n}\nEXPORT_SYMBOL(v4l2_m2m_get_vq);\n\nstruct vb2_v4l2_buffer *v4l2_m2m_next_buf(struct v4l2_m2m_queue_ctx *q_ctx)\n{\n\tstruct v4l2_m2m_buffer *b;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&q_ctx->rdy_spinlock, flags);\n\n\tif (list_empty(&q_ctx->rdy_queue)) {\n\t\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n\t\treturn NULL;\n\t}\n\n\tb = list_first_entry(&q_ctx->rdy_queue, struct v4l2_m2m_buffer, list);\n\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n\treturn &b->vb;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_next_buf);\n\nstruct vb2_v4l2_buffer *v4l2_m2m_last_buf(struct v4l2_m2m_queue_ctx *q_ctx)\n{\n\tstruct v4l2_m2m_buffer *b;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&q_ctx->rdy_spinlock, flags);\n\n\tif (list_empty(&q_ctx->rdy_queue)) {\n\t\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n\t\treturn NULL;\n\t}\n\n\tb = list_last_entry(&q_ctx->rdy_queue, struct v4l2_m2m_buffer, list);\n\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n\treturn &b->vb;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_last_buf);\n\nstruct vb2_v4l2_buffer *v4l2_m2m_buf_remove(struct v4l2_m2m_queue_ctx *q_ctx)\n{\n\tstruct v4l2_m2m_buffer *b;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&q_ctx->rdy_spinlock, flags);\n\tif (list_empty(&q_ctx->rdy_queue)) {\n\t\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n\t\treturn NULL;\n\t}\n\tb = list_first_entry(&q_ctx->rdy_queue, struct v4l2_m2m_buffer, list);\n\tlist_del(&b->list);\n\tq_ctx->num_rdy--;\n\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n\n\treturn &b->vb;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_buf_remove);\n\nvoid v4l2_m2m_buf_remove_by_buf(struct v4l2_m2m_queue_ctx *q_ctx,\n\t\t\t\tstruct vb2_v4l2_buffer *vbuf)\n{\n\tstruct v4l2_m2m_buffer *b;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&q_ctx->rdy_spinlock, flags);\n\tb = container_of(vbuf, struct v4l2_m2m_buffer, vb);\n\tlist_del(&b->list);\n\tq_ctx->num_rdy--;\n\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_buf_remove_by_buf);\n\nstruct vb2_v4l2_buffer *\nv4l2_m2m_buf_remove_by_idx(struct v4l2_m2m_queue_ctx *q_ctx, unsigned int idx)\n\n{\n\tstruct v4l2_m2m_buffer *b, *tmp;\n\tstruct vb2_v4l2_buffer *ret = NULL;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&q_ctx->rdy_spinlock, flags);\n\tlist_for_each_entry_safe(b, tmp, &q_ctx->rdy_queue, list) {\n\t\tif (b->vb.vb2_buf.index == idx) {\n\t\t\tlist_del(&b->list);\n\t\t\tq_ctx->num_rdy--;\n\t\t\tret = &b->vb;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_buf_remove_by_idx);\n\n \n\nvoid *v4l2_m2m_get_curr_priv(struct v4l2_m2m_dev *m2m_dev)\n{\n\tunsigned long flags;\n\tvoid *ret = NULL;\n\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags);\n\tif (m2m_dev->curr_ctx)\n\t\tret = m2m_dev->curr_ctx->priv;\n\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(v4l2_m2m_get_curr_priv);\n\n \nstatic void v4l2_m2m_try_run(struct v4l2_m2m_dev *m2m_dev)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags);\n\tif (NULL != m2m_dev->curr_ctx) {\n\t\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\t\tdprintk(\"Another instance is running, won't run now\\n\");\n\t\treturn;\n\t}\n\n\tif (list_empty(&m2m_dev->job_queue)) {\n\t\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\t\tdprintk(\"No job pending\\n\");\n\t\treturn;\n\t}\n\n\tif (m2m_dev->job_queue_flags & QUEUE_PAUSED) {\n\t\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\t\tdprintk(\"Running new jobs is paused\\n\");\n\t\treturn;\n\t}\n\n\tm2m_dev->curr_ctx = list_first_entry(&m2m_dev->job_queue,\n\t\t\t\t   struct v4l2_m2m_ctx, queue);\n\tm2m_dev->curr_ctx->job_flags |= TRANS_RUNNING;\n\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\n\tdprintk(\"Running job on m2m_ctx: %p\\n\", m2m_dev->curr_ctx);\n\tm2m_dev->m2m_ops->device_run(m2m_dev->curr_ctx->priv);\n}\n\n \nstatic void __v4l2_m2m_try_queue(struct v4l2_m2m_dev *m2m_dev,\n\t\t\t\t struct v4l2_m2m_ctx *m2m_ctx)\n{\n\tunsigned long flags_job;\n\tstruct vb2_v4l2_buffer *dst, *src;\n\n\tdprintk(\"Trying to schedule a job for m2m_ctx: %p\\n\", m2m_ctx);\n\n\tif (!m2m_ctx->out_q_ctx.q.streaming\n\t    || !m2m_ctx->cap_q_ctx.q.streaming) {\n\t\tdprintk(\"Streaming needs to be on for both queues\\n\");\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags_job);\n\n\t \n\tif (m2m_ctx->job_flags & TRANS_ABORT) {\n\t\tdprintk(\"Aborted context\\n\");\n\t\tgoto job_unlock;\n\t}\n\n\tif (m2m_ctx->job_flags & TRANS_QUEUED) {\n\t\tdprintk(\"On job queue already\\n\");\n\t\tgoto job_unlock;\n\t}\n\n\tsrc = v4l2_m2m_next_src_buf(m2m_ctx);\n\tdst = v4l2_m2m_next_dst_buf(m2m_ctx);\n\tif (!src && !m2m_ctx->out_q_ctx.buffered) {\n\t\tdprintk(\"No input buffers available\\n\");\n\t\tgoto job_unlock;\n\t}\n\tif (!dst && !m2m_ctx->cap_q_ctx.buffered) {\n\t\tdprintk(\"No output buffers available\\n\");\n\t\tgoto job_unlock;\n\t}\n\n\tm2m_ctx->new_frame = true;\n\n\tif (src && dst && dst->is_held &&\n\t    dst->vb2_buf.copied_timestamp &&\n\t    dst->vb2_buf.timestamp != src->vb2_buf.timestamp) {\n\t\tdprintk(\"Timestamp mismatch, returning held capture buffer\\n\");\n\t\tdst->is_held = false;\n\t\tv4l2_m2m_dst_buf_remove(m2m_ctx);\n\t\tv4l2_m2m_buf_done(dst, VB2_BUF_STATE_DONE);\n\t\tdst = v4l2_m2m_next_dst_buf(m2m_ctx);\n\n\t\tif (!dst && !m2m_ctx->cap_q_ctx.buffered) {\n\t\t\tdprintk(\"No output buffers available after returning held buffer\\n\");\n\t\t\tgoto job_unlock;\n\t\t}\n\t}\n\n\tif (src && dst && (m2m_ctx->out_q_ctx.q.subsystem_flags &\n\t\t\t   VB2_V4L2_FL_SUPPORTS_M2M_HOLD_CAPTURE_BUF))\n\t\tm2m_ctx->new_frame = !dst->vb2_buf.copied_timestamp ||\n\t\t\tdst->vb2_buf.timestamp != src->vb2_buf.timestamp;\n\n\tif (m2m_ctx->has_stopped) {\n\t\tdprintk(\"Device has stopped\\n\");\n\t\tgoto job_unlock;\n\t}\n\n\tif (m2m_dev->m2m_ops->job_ready\n\t\t&& (!m2m_dev->m2m_ops->job_ready(m2m_ctx->priv))) {\n\t\tdprintk(\"Driver not ready\\n\");\n\t\tgoto job_unlock;\n\t}\n\n\tlist_add_tail(&m2m_ctx->queue, &m2m_dev->job_queue);\n\tm2m_ctx->job_flags |= TRANS_QUEUED;\n\njob_unlock:\n\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags_job);\n}\n\n \nvoid v4l2_m2m_try_schedule(struct v4l2_m2m_ctx *m2m_ctx)\n{\n\tstruct v4l2_m2m_dev *m2m_dev = m2m_ctx->m2m_dev;\n\n\t__v4l2_m2m_try_queue(m2m_dev, m2m_ctx);\n\tv4l2_m2m_try_run(m2m_dev);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_try_schedule);\n\n \nstatic void v4l2_m2m_device_run_work(struct work_struct *work)\n{\n\tstruct v4l2_m2m_dev *m2m_dev =\n\t\tcontainer_of(work, struct v4l2_m2m_dev, job_work);\n\n\tv4l2_m2m_try_run(m2m_dev);\n}\n\n \nstatic void v4l2_m2m_cancel_job(struct v4l2_m2m_ctx *m2m_ctx)\n{\n\tstruct v4l2_m2m_dev *m2m_dev;\n\tunsigned long flags;\n\n\tm2m_dev = m2m_ctx->m2m_dev;\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags);\n\n\tm2m_ctx->job_flags |= TRANS_ABORT;\n\tif (m2m_ctx->job_flags & TRANS_RUNNING) {\n\t\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\t\tif (m2m_dev->m2m_ops->job_abort)\n\t\t\tm2m_dev->m2m_ops->job_abort(m2m_ctx->priv);\n\t\tdprintk(\"m2m_ctx %p running, will wait to complete\\n\", m2m_ctx);\n\t\twait_event(m2m_ctx->finished,\n\t\t\t\t!(m2m_ctx->job_flags & TRANS_RUNNING));\n\t} else if (m2m_ctx->job_flags & TRANS_QUEUED) {\n\t\tlist_del(&m2m_ctx->queue);\n\t\tm2m_ctx->job_flags &= ~(TRANS_QUEUED | TRANS_RUNNING);\n\t\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\t\tdprintk(\"m2m_ctx: %p had been on queue and was removed\\n\",\n\t\t\tm2m_ctx);\n\t} else {\n\t\t \n\t\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\t}\n}\n\n \nstatic void v4l2_m2m_schedule_next_job(struct v4l2_m2m_dev *m2m_dev,\n\t\t\t\t       struct v4l2_m2m_ctx *m2m_ctx)\n{\n\t \n\t__v4l2_m2m_try_queue(m2m_dev, m2m_ctx);\n\n\t \n\tschedule_work(&m2m_dev->job_work);\n}\n\n \nstatic bool _v4l2_m2m_job_finish(struct v4l2_m2m_dev *m2m_dev,\n\t\t\t\t struct v4l2_m2m_ctx *m2m_ctx)\n{\n\tif (!m2m_dev->curr_ctx || m2m_dev->curr_ctx != m2m_ctx) {\n\t\tdprintk(\"Called by an instance not currently running\\n\");\n\t\treturn false;\n\t}\n\n\tlist_del(&m2m_dev->curr_ctx->queue);\n\tm2m_dev->curr_ctx->job_flags &= ~(TRANS_QUEUED | TRANS_RUNNING);\n\twake_up(&m2m_dev->curr_ctx->finished);\n\tm2m_dev->curr_ctx = NULL;\n\treturn true;\n}\n\nvoid v4l2_m2m_job_finish(struct v4l2_m2m_dev *m2m_dev,\n\t\t\t struct v4l2_m2m_ctx *m2m_ctx)\n{\n\tunsigned long flags;\n\tbool schedule_next;\n\n\t \n\tWARN_ON(m2m_ctx->out_q_ctx.q.subsystem_flags &\n\t\tVB2_V4L2_FL_SUPPORTS_M2M_HOLD_CAPTURE_BUF);\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags);\n\tschedule_next = _v4l2_m2m_job_finish(m2m_dev, m2m_ctx);\n\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\n\tif (schedule_next)\n\t\tv4l2_m2m_schedule_next_job(m2m_dev, m2m_ctx);\n}\nEXPORT_SYMBOL(v4l2_m2m_job_finish);\n\nvoid v4l2_m2m_buf_done_and_job_finish(struct v4l2_m2m_dev *m2m_dev,\n\t\t\t\t      struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t\t      enum vb2_buffer_state state)\n{\n\tstruct vb2_v4l2_buffer *src_buf, *dst_buf;\n\tbool schedule_next = false;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags);\n\tsrc_buf = v4l2_m2m_src_buf_remove(m2m_ctx);\n\tdst_buf = v4l2_m2m_next_dst_buf(m2m_ctx);\n\n\tif (WARN_ON(!src_buf || !dst_buf))\n\t\tgoto unlock;\n\tdst_buf->is_held = src_buf->flags & V4L2_BUF_FLAG_M2M_HOLD_CAPTURE_BUF;\n\tif (!dst_buf->is_held) {\n\t\tv4l2_m2m_dst_buf_remove(m2m_ctx);\n\t\tv4l2_m2m_buf_done(dst_buf, state);\n\t}\n\t \n\tv4l2_m2m_buf_done(src_buf, state);\n\tschedule_next = _v4l2_m2m_job_finish(m2m_dev, m2m_ctx);\nunlock:\n\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\n\tif (schedule_next)\n\t\tv4l2_m2m_schedule_next_job(m2m_dev, m2m_ctx);\n}\nEXPORT_SYMBOL(v4l2_m2m_buf_done_and_job_finish);\n\nvoid v4l2_m2m_suspend(struct v4l2_m2m_dev *m2m_dev)\n{\n\tunsigned long flags;\n\tstruct v4l2_m2m_ctx *curr_ctx;\n\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags);\n\tm2m_dev->job_queue_flags |= QUEUE_PAUSED;\n\tcurr_ctx = m2m_dev->curr_ctx;\n\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\n\tif (curr_ctx)\n\t\twait_event(curr_ctx->finished,\n\t\t\t   !(curr_ctx->job_flags & TRANS_RUNNING));\n}\nEXPORT_SYMBOL(v4l2_m2m_suspend);\n\nvoid v4l2_m2m_resume(struct v4l2_m2m_dev *m2m_dev)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags);\n\tm2m_dev->job_queue_flags &= ~QUEUE_PAUSED;\n\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\n\tv4l2_m2m_try_run(m2m_dev);\n}\nEXPORT_SYMBOL(v4l2_m2m_resume);\n\nint v4l2_m2m_reqbufs(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t     struct v4l2_requestbuffers *reqbufs)\n{\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, reqbufs->type);\n\tret = vb2_reqbufs(vq, reqbufs);\n\t \n\tif (ret == 0)\n\t\tvq->owner = reqbufs->count ? file->private_data : NULL;\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_reqbufs);\n\nstatic void v4l2_m2m_adjust_mem_offset(struct vb2_queue *vq,\n\t\t\t\t       struct v4l2_buffer *buf)\n{\n\t \n\tif (buf->memory == V4L2_MEMORY_MMAP && V4L2_TYPE_IS_CAPTURE(vq->type)) {\n\t\tif (V4L2_TYPE_IS_MULTIPLANAR(vq->type)) {\n\t\t\tunsigned int i;\n\n\t\t\tfor (i = 0; i < buf->length; ++i)\n\t\t\t\tbuf->m.planes[i].m.mem_offset\n\t\t\t\t\t+= DST_QUEUE_OFF_BASE;\n\t\t} else {\n\t\t\tbuf->m.offset += DST_QUEUE_OFF_BASE;\n\t\t}\n\t}\n}\n\nint v4l2_m2m_querybuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t      struct v4l2_buffer *buf)\n{\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tret = vb2_querybuf(vq, buf);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tv4l2_m2m_adjust_mem_offset(vq, buf);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_querybuf);\n\n \nvoid v4l2_m2m_last_buffer_done(struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t       struct vb2_v4l2_buffer *vbuf)\n{\n\tvbuf->flags |= V4L2_BUF_FLAG_LAST;\n\tvb2_buffer_done(&vbuf->vb2_buf, VB2_BUF_STATE_DONE);\n\n\tv4l2_m2m_mark_stopped(m2m_ctx);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_last_buffer_done);\n\n \nstatic int v4l2_update_last_buf_state(struct v4l2_m2m_ctx *m2m_ctx)\n{\n\tstruct vb2_v4l2_buffer *next_dst_buf;\n\n\tif (m2m_ctx->is_draining)\n\t\treturn -EBUSY;\n\n\tif (m2m_ctx->has_stopped)\n\t\treturn 0;\n\n\tm2m_ctx->last_src_buf = v4l2_m2m_last_src_buf(m2m_ctx);\n\tm2m_ctx->is_draining = true;\n\n\t \n\tif (m2m_ctx->last_src_buf)\n\t\treturn 0;\n\n\t \n\tnext_dst_buf = v4l2_m2m_dst_buf_remove(m2m_ctx);\n\tif (!next_dst_buf) {\n\t\t \n\t\tm2m_ctx->next_buf_last = true;\n\t\treturn 0;\n\t}\n\n\tv4l2_m2m_last_buffer_done(m2m_ctx, next_dst_buf);\n\n\treturn 0;\n}\n\n \nvoid v4l2_m2m_update_start_streaming_state(struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t\t\t   struct vb2_queue *q)\n{\n\t \n\tif (V4L2_TYPE_IS_OUTPUT(q->type))\n\t\tm2m_ctx->last_src_buf = NULL;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_update_start_streaming_state);\n\n \nvoid v4l2_m2m_update_stop_streaming_state(struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t\t\t  struct vb2_queue *q)\n{\n\tif (V4L2_TYPE_IS_OUTPUT(q->type)) {\n\t\t \n\t\tif (m2m_ctx->is_draining) {\n\t\t\tstruct vb2_v4l2_buffer *next_dst_buf;\n\n\t\t\tm2m_ctx->last_src_buf = NULL;\n\t\t\tnext_dst_buf = v4l2_m2m_dst_buf_remove(m2m_ctx);\n\t\t\tif (!next_dst_buf)\n\t\t\t\tm2m_ctx->next_buf_last = true;\n\t\t\telse\n\t\t\t\tv4l2_m2m_last_buffer_done(m2m_ctx,\n\t\t\t\t\t\t\t  next_dst_buf);\n\t\t}\n\t} else {\n\t\tv4l2_m2m_clear_state(m2m_ctx);\n\t}\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_update_stop_streaming_state);\n\nstatic void v4l2_m2m_force_last_buf_done(struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t\t\t struct vb2_queue *q)\n{\n\tstruct vb2_buffer *vb;\n\tstruct vb2_v4l2_buffer *vbuf;\n\tunsigned int i;\n\n\tif (WARN_ON(q->is_output))\n\t\treturn;\n\tif (list_empty(&q->queued_list))\n\t\treturn;\n\n\tvb = list_first_entry(&q->queued_list, struct vb2_buffer, queued_entry);\n\tfor (i = 0; i < vb->num_planes; i++)\n\t\tvb2_set_plane_payload(vb, i, 0);\n\n\t \n\tvb->state = VB2_BUF_STATE_ACTIVE;\n\tatomic_inc(&q->owned_by_drv_count);\n\n\tvbuf = to_vb2_v4l2_buffer(vb);\n\tvbuf->field = V4L2_FIELD_NONE;\n\n\tv4l2_m2m_last_buffer_done(m2m_ctx, vbuf);\n}\n\nint v4l2_m2m_qbuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t  struct v4l2_buffer *buf)\n{\n\tstruct video_device *vdev = video_devdata(file);\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tif (V4L2_TYPE_IS_CAPTURE(vq->type) &&\n\t    (buf->flags & V4L2_BUF_FLAG_REQUEST_FD)) {\n\t\tdprintk(\"%s: requests cannot be used with capture buffers\\n\",\n\t\t\t__func__);\n\t\treturn -EPERM;\n\t}\n\n\tret = vb2_qbuf(vq, vdev->v4l2_dev->mdev, buf);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tv4l2_m2m_adjust_mem_offset(vq, buf);\n\n\t \n\tif (V4L2_TYPE_IS_CAPTURE(vq->type) &&\n\t    vb2_is_streaming(vq) && !vb2_start_streaming_called(vq) &&\n\t   (v4l2_m2m_has_stopped(m2m_ctx) || v4l2_m2m_dst_buf_is_last(m2m_ctx)))\n\t\tv4l2_m2m_force_last_buf_done(m2m_ctx, vq);\n\telse if (!(buf->flags & V4L2_BUF_FLAG_IN_REQUEST))\n\t\tv4l2_m2m_try_schedule(m2m_ctx);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_qbuf);\n\nint v4l2_m2m_dqbuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t   struct v4l2_buffer *buf)\n{\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tret = vb2_dqbuf(vq, buf, file->f_flags & O_NONBLOCK);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tv4l2_m2m_adjust_mem_offset(vq, buf);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_dqbuf);\n\nint v4l2_m2m_prepare_buf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t struct v4l2_buffer *buf)\n{\n\tstruct video_device *vdev = video_devdata(file);\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tret = vb2_prepare_buf(vq, vdev->v4l2_dev->mdev, buf);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tv4l2_m2m_adjust_mem_offset(vq, buf);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_prepare_buf);\n\nint v4l2_m2m_create_bufs(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t struct v4l2_create_buffers *create)\n{\n\tstruct vb2_queue *vq;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, create->format.type);\n\treturn vb2_create_bufs(vq, create);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_create_bufs);\n\nint v4l2_m2m_expbuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t  struct v4l2_exportbuffer *eb)\n{\n\tstruct vb2_queue *vq;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, eb->type);\n\treturn vb2_expbuf(vq, eb);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_expbuf);\n\nint v4l2_m2m_streamon(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t      enum v4l2_buf_type type)\n{\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, type);\n\tret = vb2_streamon(vq, type);\n\tif (!ret)\n\t\tv4l2_m2m_try_schedule(m2m_ctx);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_streamon);\n\nint v4l2_m2m_streamoff(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t       enum v4l2_buf_type type)\n{\n\tstruct v4l2_m2m_dev *m2m_dev;\n\tstruct v4l2_m2m_queue_ctx *q_ctx;\n\tunsigned long flags_job, flags;\n\tint ret;\n\n\t \n\tv4l2_m2m_cancel_job(m2m_ctx);\n\n\tq_ctx = get_queue_ctx(m2m_ctx, type);\n\tret = vb2_streamoff(&q_ctx->q, type);\n\tif (ret)\n\t\treturn ret;\n\n\tm2m_dev = m2m_ctx->m2m_dev;\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags_job);\n\t \n\tif (m2m_ctx->job_flags & TRANS_QUEUED)\n\t\tlist_del(&m2m_ctx->queue);\n\tm2m_ctx->job_flags = 0;\n\n\tspin_lock_irqsave(&q_ctx->rdy_spinlock, flags);\n\t \n\tINIT_LIST_HEAD(&q_ctx->rdy_queue);\n\tq_ctx->num_rdy = 0;\n\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n\n\tif (m2m_dev->curr_ctx == m2m_ctx) {\n\t\tm2m_dev->curr_ctx = NULL;\n\t\twake_up(&m2m_ctx->finished);\n\t}\n\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags_job);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_streamoff);\n\nstatic __poll_t v4l2_m2m_poll_for_data(struct file *file,\n\t\t\t\t       struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t\t       struct poll_table_struct *wait)\n{\n\tstruct vb2_queue *src_q, *dst_q;\n\t__poll_t rc = 0;\n\tunsigned long flags;\n\n\tsrc_q = v4l2_m2m_get_src_vq(m2m_ctx);\n\tdst_q = v4l2_m2m_get_dst_vq(m2m_ctx);\n\n\t \n\tif ((!vb2_is_streaming(src_q) || src_q->error ||\n\t     list_empty(&src_q->queued_list)) &&\n\t    (!vb2_is_streaming(dst_q) || dst_q->error ||\n\t     (list_empty(&dst_q->queued_list) && !dst_q->last_buffer_dequeued)))\n\t\treturn EPOLLERR;\n\n\tspin_lock_irqsave(&src_q->done_lock, flags);\n\tif (!list_empty(&src_q->done_list))\n\t\trc |= EPOLLOUT | EPOLLWRNORM;\n\tspin_unlock_irqrestore(&src_q->done_lock, flags);\n\n\tspin_lock_irqsave(&dst_q->done_lock, flags);\n\t \n\tif (!list_empty(&dst_q->done_list) || dst_q->last_buffer_dequeued)\n\t\trc |= EPOLLIN | EPOLLRDNORM;\n\tspin_unlock_irqrestore(&dst_q->done_lock, flags);\n\n\treturn rc;\n}\n\n__poll_t v4l2_m2m_poll(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t       struct poll_table_struct *wait)\n{\n\tstruct video_device *vfd = video_devdata(file);\n\tstruct vb2_queue *src_q = v4l2_m2m_get_src_vq(m2m_ctx);\n\tstruct vb2_queue *dst_q = v4l2_m2m_get_dst_vq(m2m_ctx);\n\t__poll_t req_events = poll_requested_events(wait);\n\t__poll_t rc = 0;\n\n\t \n\tpoll_wait(file, &src_q->done_wq, wait);\n\tpoll_wait(file, &dst_q->done_wq, wait);\n\n\tif (req_events & (EPOLLOUT | EPOLLWRNORM | EPOLLIN | EPOLLRDNORM))\n\t\trc = v4l2_m2m_poll_for_data(file, m2m_ctx, wait);\n\n\tif (test_bit(V4L2_FL_USES_V4L2_FH, &vfd->flags)) {\n\t\tstruct v4l2_fh *fh = file->private_data;\n\n\t\tpoll_wait(file, &fh->wait, wait);\n\t\tif (v4l2_event_pending(fh))\n\t\t\trc |= EPOLLPRI;\n\t}\n\n\treturn rc;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_poll);\n\nint v4l2_m2m_mmap(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t struct vm_area_struct *vma)\n{\n\tunsigned long offset = vma->vm_pgoff << PAGE_SHIFT;\n\tstruct vb2_queue *vq;\n\n\tif (offset < DST_QUEUE_OFF_BASE) {\n\t\tvq = v4l2_m2m_get_src_vq(m2m_ctx);\n\t} else {\n\t\tvq = v4l2_m2m_get_dst_vq(m2m_ctx);\n\t\tvma->vm_pgoff -= (DST_QUEUE_OFF_BASE >> PAGE_SHIFT);\n\t}\n\n\treturn vb2_mmap(vq, vma);\n}\nEXPORT_SYMBOL(v4l2_m2m_mmap);\n\n#ifndef CONFIG_MMU\nunsigned long v4l2_m2m_get_unmapped_area(struct file *file, unsigned long addr,\n\t\t\t\t\t unsigned long len, unsigned long pgoff,\n\t\t\t\t\t unsigned long flags)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\tunsigned long offset = pgoff << PAGE_SHIFT;\n\tstruct vb2_queue *vq;\n\n\tif (offset < DST_QUEUE_OFF_BASE) {\n\t\tvq = v4l2_m2m_get_src_vq(fh->m2m_ctx);\n\t} else {\n\t\tvq = v4l2_m2m_get_dst_vq(fh->m2m_ctx);\n\t\tpgoff -= (DST_QUEUE_OFF_BASE >> PAGE_SHIFT);\n\t}\n\n\treturn vb2_get_unmapped_area(vq, addr, len, pgoff, flags);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_get_unmapped_area);\n#endif\n\n#if defined(CONFIG_MEDIA_CONTROLLER)\nvoid v4l2_m2m_unregister_media_controller(struct v4l2_m2m_dev *m2m_dev)\n{\n\tmedia_remove_intf_links(&m2m_dev->intf_devnode->intf);\n\tmedia_devnode_remove(m2m_dev->intf_devnode);\n\n\tmedia_entity_remove_links(m2m_dev->source);\n\tmedia_entity_remove_links(&m2m_dev->sink);\n\tmedia_entity_remove_links(&m2m_dev->proc);\n\tmedia_device_unregister_entity(m2m_dev->source);\n\tmedia_device_unregister_entity(&m2m_dev->sink);\n\tmedia_device_unregister_entity(&m2m_dev->proc);\n\tkfree(m2m_dev->source->name);\n\tkfree(m2m_dev->sink.name);\n\tkfree(m2m_dev->proc.name);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_unregister_media_controller);\n\nstatic int v4l2_m2m_register_entity(struct media_device *mdev,\n\tstruct v4l2_m2m_dev *m2m_dev, enum v4l2_m2m_entity_type type,\n\tstruct video_device *vdev, int function)\n{\n\tstruct media_entity *entity;\n\tstruct media_pad *pads;\n\tchar *name;\n\tunsigned int len;\n\tint num_pads;\n\tint ret;\n\n\tswitch (type) {\n\tcase MEM2MEM_ENT_TYPE_SOURCE:\n\t\tentity = m2m_dev->source;\n\t\tpads = &m2m_dev->source_pad;\n\t\tpads[0].flags = MEDIA_PAD_FL_SOURCE;\n\t\tnum_pads = 1;\n\t\tbreak;\n\tcase MEM2MEM_ENT_TYPE_SINK:\n\t\tentity = &m2m_dev->sink;\n\t\tpads = &m2m_dev->sink_pad;\n\t\tpads[0].flags = MEDIA_PAD_FL_SINK;\n\t\tnum_pads = 1;\n\t\tbreak;\n\tcase MEM2MEM_ENT_TYPE_PROC:\n\t\tentity = &m2m_dev->proc;\n\t\tpads = m2m_dev->proc_pads;\n\t\tpads[0].flags = MEDIA_PAD_FL_SINK;\n\t\tpads[1].flags = MEDIA_PAD_FL_SOURCE;\n\t\tnum_pads = 2;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tentity->obj_type = MEDIA_ENTITY_TYPE_BASE;\n\tif (type != MEM2MEM_ENT_TYPE_PROC) {\n\t\tentity->info.dev.major = VIDEO_MAJOR;\n\t\tentity->info.dev.minor = vdev->minor;\n\t}\n\tlen = strlen(vdev->name) + 2 + strlen(m2m_entity_name[type]);\n\tname = kmalloc(len, GFP_KERNEL);\n\tif (!name)\n\t\treturn -ENOMEM;\n\tsnprintf(name, len, \"%s-%s\", vdev->name, m2m_entity_name[type]);\n\tentity->name = name;\n\tentity->function = function;\n\n\tret = media_entity_pads_init(entity, num_pads, pads);\n\tif (ret)\n\t\treturn ret;\n\tret = media_device_register_entity(mdev, entity);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nint v4l2_m2m_register_media_controller(struct v4l2_m2m_dev *m2m_dev,\n\t\tstruct video_device *vdev, int function)\n{\n\tstruct media_device *mdev = vdev->v4l2_dev->mdev;\n\tstruct media_link *link;\n\tint ret;\n\n\tif (!mdev)\n\t\treturn 0;\n\n\t \n\n\t \n\tm2m_dev->source = &vdev->entity;\n\tret = v4l2_m2m_register_entity(mdev, m2m_dev,\n\t\t\tMEM2MEM_ENT_TYPE_SOURCE, vdev, MEDIA_ENT_F_IO_V4L);\n\tif (ret)\n\t\treturn ret;\n\tret = v4l2_m2m_register_entity(mdev, m2m_dev,\n\t\t\tMEM2MEM_ENT_TYPE_PROC, vdev, function);\n\tif (ret)\n\t\tgoto err_rel_entity0;\n\tret = v4l2_m2m_register_entity(mdev, m2m_dev,\n\t\t\tMEM2MEM_ENT_TYPE_SINK, vdev, MEDIA_ENT_F_IO_V4L);\n\tif (ret)\n\t\tgoto err_rel_entity1;\n\n\t \n\tret = media_create_pad_link(m2m_dev->source, 0, &m2m_dev->proc, 0,\n\t\t\tMEDIA_LNK_FL_IMMUTABLE | MEDIA_LNK_FL_ENABLED);\n\tif (ret)\n\t\tgoto err_rel_entity2;\n\n\tret = media_create_pad_link(&m2m_dev->proc, 1, &m2m_dev->sink, 0,\n\t\t\tMEDIA_LNK_FL_IMMUTABLE | MEDIA_LNK_FL_ENABLED);\n\tif (ret)\n\t\tgoto err_rm_links0;\n\n\t \n\tm2m_dev->intf_devnode = media_devnode_create(mdev,\n\t\t\tMEDIA_INTF_T_V4L_VIDEO, 0,\n\t\t\tVIDEO_MAJOR, vdev->minor);\n\tif (!m2m_dev->intf_devnode) {\n\t\tret = -ENOMEM;\n\t\tgoto err_rm_links1;\n\t}\n\n\t \n\tlink = media_create_intf_link(m2m_dev->source,\n\t\t\t&m2m_dev->intf_devnode->intf,\n\t\t\tMEDIA_LNK_FL_IMMUTABLE | MEDIA_LNK_FL_ENABLED);\n\tif (!link) {\n\t\tret = -ENOMEM;\n\t\tgoto err_rm_devnode;\n\t}\n\n\tlink = media_create_intf_link(&m2m_dev->sink,\n\t\t\t&m2m_dev->intf_devnode->intf,\n\t\t\tMEDIA_LNK_FL_IMMUTABLE | MEDIA_LNK_FL_ENABLED);\n\tif (!link) {\n\t\tret = -ENOMEM;\n\t\tgoto err_rm_intf_link;\n\t}\n\treturn 0;\n\nerr_rm_intf_link:\n\tmedia_remove_intf_links(&m2m_dev->intf_devnode->intf);\nerr_rm_devnode:\n\tmedia_devnode_remove(m2m_dev->intf_devnode);\nerr_rm_links1:\n\tmedia_entity_remove_links(&m2m_dev->sink);\nerr_rm_links0:\n\tmedia_entity_remove_links(&m2m_dev->proc);\n\tmedia_entity_remove_links(m2m_dev->source);\nerr_rel_entity2:\n\tmedia_device_unregister_entity(&m2m_dev->proc);\n\tkfree(m2m_dev->proc.name);\nerr_rel_entity1:\n\tmedia_device_unregister_entity(&m2m_dev->sink);\n\tkfree(m2m_dev->sink.name);\nerr_rel_entity0:\n\tmedia_device_unregister_entity(m2m_dev->source);\n\tkfree(m2m_dev->source->name);\n\treturn ret;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_register_media_controller);\n#endif\n\nstruct v4l2_m2m_dev *v4l2_m2m_init(const struct v4l2_m2m_ops *m2m_ops)\n{\n\tstruct v4l2_m2m_dev *m2m_dev;\n\n\tif (!m2m_ops || WARN_ON(!m2m_ops->device_run))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tm2m_dev = kzalloc(sizeof *m2m_dev, GFP_KERNEL);\n\tif (!m2m_dev)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tm2m_dev->curr_ctx = NULL;\n\tm2m_dev->m2m_ops = m2m_ops;\n\tINIT_LIST_HEAD(&m2m_dev->job_queue);\n\tspin_lock_init(&m2m_dev->job_spinlock);\n\tINIT_WORK(&m2m_dev->job_work, v4l2_m2m_device_run_work);\n\n\treturn m2m_dev;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_init);\n\nvoid v4l2_m2m_release(struct v4l2_m2m_dev *m2m_dev)\n{\n\tkfree(m2m_dev);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_release);\n\nstruct v4l2_m2m_ctx *v4l2_m2m_ctx_init(struct v4l2_m2m_dev *m2m_dev,\n\t\tvoid *drv_priv,\n\t\tint (*queue_init)(void *priv, struct vb2_queue *src_vq, struct vb2_queue *dst_vq))\n{\n\tstruct v4l2_m2m_ctx *m2m_ctx;\n\tstruct v4l2_m2m_queue_ctx *out_q_ctx, *cap_q_ctx;\n\tint ret;\n\n\tm2m_ctx = kzalloc(sizeof *m2m_ctx, GFP_KERNEL);\n\tif (!m2m_ctx)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tm2m_ctx->priv = drv_priv;\n\tm2m_ctx->m2m_dev = m2m_dev;\n\tinit_waitqueue_head(&m2m_ctx->finished);\n\n\tout_q_ctx = &m2m_ctx->out_q_ctx;\n\tcap_q_ctx = &m2m_ctx->cap_q_ctx;\n\n\tINIT_LIST_HEAD(&out_q_ctx->rdy_queue);\n\tINIT_LIST_HEAD(&cap_q_ctx->rdy_queue);\n\tspin_lock_init(&out_q_ctx->rdy_spinlock);\n\tspin_lock_init(&cap_q_ctx->rdy_spinlock);\n\n\tINIT_LIST_HEAD(&m2m_ctx->queue);\n\n\tret = queue_init(drv_priv, &out_q_ctx->q, &cap_q_ctx->q);\n\n\tif (ret)\n\t\tgoto err;\n\t \n\tif (WARN_ON(out_q_ctx->q.lock != cap_q_ctx->q.lock)) {\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\tm2m_ctx->q_lock = out_q_ctx->q.lock;\n\n\treturn m2m_ctx;\nerr:\n\tkfree(m2m_ctx);\n\treturn ERR_PTR(ret);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ctx_init);\n\nvoid v4l2_m2m_ctx_release(struct v4l2_m2m_ctx *m2m_ctx)\n{\n\t \n\tv4l2_m2m_cancel_job(m2m_ctx);\n\n\tvb2_queue_release(&m2m_ctx->cap_q_ctx.q);\n\tvb2_queue_release(&m2m_ctx->out_q_ctx.q);\n\n\tkfree(m2m_ctx);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ctx_release);\n\nvoid v4l2_m2m_buf_queue(struct v4l2_m2m_ctx *m2m_ctx,\n\t\tstruct vb2_v4l2_buffer *vbuf)\n{\n\tstruct v4l2_m2m_buffer *b = container_of(vbuf,\n\t\t\t\tstruct v4l2_m2m_buffer, vb);\n\tstruct v4l2_m2m_queue_ctx *q_ctx;\n\tunsigned long flags;\n\n\tq_ctx = get_queue_ctx(m2m_ctx, vbuf->vb2_buf.vb2_queue->type);\n\tif (!q_ctx)\n\t\treturn;\n\n\tspin_lock_irqsave(&q_ctx->rdy_spinlock, flags);\n\tlist_add_tail(&b->list, &q_ctx->rdy_queue);\n\tq_ctx->num_rdy++;\n\tspin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_buf_queue);\n\nvoid v4l2_m2m_buf_copy_metadata(const struct vb2_v4l2_buffer *out_vb,\n\t\t\t\tstruct vb2_v4l2_buffer *cap_vb,\n\t\t\t\tbool copy_frame_flags)\n{\n\tu32 mask = V4L2_BUF_FLAG_TIMECODE | V4L2_BUF_FLAG_TSTAMP_SRC_MASK;\n\n\tif (copy_frame_flags)\n\t\tmask |= V4L2_BUF_FLAG_KEYFRAME | V4L2_BUF_FLAG_PFRAME |\n\t\t\tV4L2_BUF_FLAG_BFRAME;\n\n\tcap_vb->vb2_buf.timestamp = out_vb->vb2_buf.timestamp;\n\n\tif (out_vb->flags & V4L2_BUF_FLAG_TIMECODE)\n\t\tcap_vb->timecode = out_vb->timecode;\n\tcap_vb->field = out_vb->field;\n\tcap_vb->flags &= ~mask;\n\tcap_vb->flags |= out_vb->flags & mask;\n\tcap_vb->vb2_buf.copied_timestamp = 1;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_buf_copy_metadata);\n\nvoid v4l2_m2m_request_queue(struct media_request *req)\n{\n\tstruct media_request_object *obj, *obj_safe;\n\tstruct v4l2_m2m_ctx *m2m_ctx = NULL;\n\n\t \n\tlist_for_each_entry_safe(obj, obj_safe, &req->objects, list) {\n\t\tstruct v4l2_m2m_ctx *m2m_ctx_obj;\n\t\tstruct vb2_buffer *vb;\n\n\t\tif (!obj->ops->queue)\n\t\t\tcontinue;\n\n\t\tif (vb2_request_object_is_buffer(obj)) {\n\t\t\t \n\t\t\tvb = container_of(obj, struct vb2_buffer, req_obj);\n\t\t\tWARN_ON(!V4L2_TYPE_IS_OUTPUT(vb->vb2_queue->type));\n\t\t\tm2m_ctx_obj = container_of(vb->vb2_queue,\n\t\t\t\t\t\t   struct v4l2_m2m_ctx,\n\t\t\t\t\t\t   out_q_ctx.q);\n\t\t\tWARN_ON(m2m_ctx && m2m_ctx_obj != m2m_ctx);\n\t\t\tm2m_ctx = m2m_ctx_obj;\n\t\t}\n\n\t\t \n\t\tobj->ops->queue(obj);\n\t}\n\n\tWARN_ON(!m2m_ctx);\n\n\tif (m2m_ctx)\n\t\tv4l2_m2m_try_schedule(m2m_ctx);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_request_queue);\n\n \n\nint v4l2_m2m_ioctl_reqbufs(struct file *file, void *priv,\n\t\t\t\tstruct v4l2_requestbuffers *rb)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_reqbufs(file, fh->m2m_ctx, rb);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_reqbufs);\n\nint v4l2_m2m_ioctl_create_bufs(struct file *file, void *priv,\n\t\t\t\tstruct v4l2_create_buffers *create)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_create_bufs(file, fh->m2m_ctx, create);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_create_bufs);\n\nint v4l2_m2m_ioctl_querybuf(struct file *file, void *priv,\n\t\t\t\tstruct v4l2_buffer *buf)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_querybuf(file, fh->m2m_ctx, buf);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_querybuf);\n\nint v4l2_m2m_ioctl_qbuf(struct file *file, void *priv,\n\t\t\t\tstruct v4l2_buffer *buf)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_qbuf(file, fh->m2m_ctx, buf);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_qbuf);\n\nint v4l2_m2m_ioctl_dqbuf(struct file *file, void *priv,\n\t\t\t\tstruct v4l2_buffer *buf)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_dqbuf(file, fh->m2m_ctx, buf);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_dqbuf);\n\nint v4l2_m2m_ioctl_prepare_buf(struct file *file, void *priv,\n\t\t\t       struct v4l2_buffer *buf)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_prepare_buf(file, fh->m2m_ctx, buf);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_prepare_buf);\n\nint v4l2_m2m_ioctl_expbuf(struct file *file, void *priv,\n\t\t\t\tstruct v4l2_exportbuffer *eb)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_expbuf(file, fh->m2m_ctx, eb);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_expbuf);\n\nint v4l2_m2m_ioctl_streamon(struct file *file, void *priv,\n\t\t\t\tenum v4l2_buf_type type)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_streamon(file, fh->m2m_ctx, type);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_streamon);\n\nint v4l2_m2m_ioctl_streamoff(struct file *file, void *priv,\n\t\t\t\tenum v4l2_buf_type type)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_streamoff(file, fh->m2m_ctx, type);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_streamoff);\n\nint v4l2_m2m_ioctl_try_encoder_cmd(struct file *file, void *fh,\n\t\t\t\t   struct v4l2_encoder_cmd *ec)\n{\n\tif (ec->cmd != V4L2_ENC_CMD_STOP && ec->cmd != V4L2_ENC_CMD_START)\n\t\treturn -EINVAL;\n\n\tec->flags = 0;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_try_encoder_cmd);\n\nint v4l2_m2m_ioctl_try_decoder_cmd(struct file *file, void *fh,\n\t\t\t\t   struct v4l2_decoder_cmd *dc)\n{\n\tif (dc->cmd != V4L2_DEC_CMD_STOP && dc->cmd != V4L2_DEC_CMD_START)\n\t\treturn -EINVAL;\n\n\tdc->flags = 0;\n\n\tif (dc->cmd == V4L2_DEC_CMD_STOP) {\n\t\tdc->stop.pts = 0;\n\t} else if (dc->cmd == V4L2_DEC_CMD_START) {\n\t\tdc->start.speed = 0;\n\t\tdc->start.format = V4L2_DEC_START_FMT_NONE;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_try_decoder_cmd);\n\n \nint v4l2_m2m_encoder_cmd(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t struct v4l2_encoder_cmd *ec)\n{\n\tif (ec->cmd != V4L2_ENC_CMD_STOP && ec->cmd != V4L2_ENC_CMD_START)\n\t\treturn -EINVAL;\n\n\tif (ec->cmd == V4L2_ENC_CMD_STOP)\n\t\treturn v4l2_update_last_buf_state(m2m_ctx);\n\n\tif (m2m_ctx->is_draining)\n\t\treturn -EBUSY;\n\n\tif (m2m_ctx->has_stopped)\n\t\tm2m_ctx->has_stopped = false;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_encoder_cmd);\n\n \nint v4l2_m2m_decoder_cmd(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t struct v4l2_decoder_cmd *dc)\n{\n\tif (dc->cmd != V4L2_DEC_CMD_STOP && dc->cmd != V4L2_DEC_CMD_START)\n\t\treturn -EINVAL;\n\n\tif (dc->cmd == V4L2_DEC_CMD_STOP)\n\t\treturn v4l2_update_last_buf_state(m2m_ctx);\n\n\tif (m2m_ctx->is_draining)\n\t\treturn -EBUSY;\n\n\tif (m2m_ctx->has_stopped)\n\t\tm2m_ctx->has_stopped = false;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_decoder_cmd);\n\nint v4l2_m2m_ioctl_encoder_cmd(struct file *file, void *priv,\n\t\t\t       struct v4l2_encoder_cmd *ec)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_encoder_cmd(file, fh->m2m_ctx, ec);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_encoder_cmd);\n\nint v4l2_m2m_ioctl_decoder_cmd(struct file *file, void *priv,\n\t\t\t       struct v4l2_decoder_cmd *dc)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_decoder_cmd(file, fh->m2m_ctx, dc);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_decoder_cmd);\n\nint v4l2_m2m_ioctl_stateless_try_decoder_cmd(struct file *file, void *fh,\n\t\t\t\t\t     struct v4l2_decoder_cmd *dc)\n{\n\tif (dc->cmd != V4L2_DEC_CMD_FLUSH)\n\t\treturn -EINVAL;\n\n\tdc->flags = 0;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_stateless_try_decoder_cmd);\n\nint v4l2_m2m_ioctl_stateless_decoder_cmd(struct file *file, void *priv,\n\t\t\t\t\t struct v4l2_decoder_cmd *dc)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\tstruct vb2_v4l2_buffer *out_vb, *cap_vb;\n\tstruct v4l2_m2m_dev *m2m_dev = fh->m2m_ctx->m2m_dev;\n\tunsigned long flags;\n\tint ret;\n\n\tret = v4l2_m2m_ioctl_stateless_try_decoder_cmd(file, priv, dc);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&m2m_dev->job_spinlock, flags);\n\tout_vb = v4l2_m2m_last_src_buf(fh->m2m_ctx);\n\tcap_vb = v4l2_m2m_last_dst_buf(fh->m2m_ctx);\n\n\t \n\tif (out_vb) {\n\t\tout_vb->flags &= ~V4L2_BUF_FLAG_M2M_HOLD_CAPTURE_BUF;\n\t} else if (cap_vb && cap_vb->is_held) {\n\t\t \n\t\tcap_vb->is_held = false;\n\t\tv4l2_m2m_dst_buf_remove(fh->m2m_ctx);\n\t\tv4l2_m2m_buf_done(cap_vb, VB2_BUF_STATE_DONE);\n\t}\n\tspin_unlock_irqrestore(&m2m_dev->job_spinlock, flags);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_ioctl_stateless_decoder_cmd);\n\n \n\nint v4l2_m2m_fop_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\n\treturn v4l2_m2m_mmap(file, fh->m2m_ctx, vma);\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_fop_mmap);\n\n__poll_t v4l2_m2m_fop_poll(struct file *file, poll_table *wait)\n{\n\tstruct v4l2_fh *fh = file->private_data;\n\tstruct v4l2_m2m_ctx *m2m_ctx = fh->m2m_ctx;\n\t__poll_t ret;\n\n\tif (m2m_ctx->q_lock)\n\t\tmutex_lock(m2m_ctx->q_lock);\n\n\tret = v4l2_m2m_poll(file, m2m_ctx, wait);\n\n\tif (m2m_ctx->q_lock)\n\t\tmutex_unlock(m2m_ctx->q_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(v4l2_m2m_fop_poll);\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}