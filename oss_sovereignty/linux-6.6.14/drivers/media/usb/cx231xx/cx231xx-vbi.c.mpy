{
  "module_name": "cx231xx-vbi.c",
  "hash_id": "572edf6158d18bee8f9212f9a61e02bdc2485b16d1cef9e52e585f6ba7729cf6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/usb/cx231xx/cx231xx-vbi.c",
  "human_readable_source": "\n \n\n#include \"cx231xx.h\"\n#include <linux/init.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/bitmap.h>\n#include <linux/i2c.h>\n#include <linux/mm.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n\n#include <media/v4l2-common.h>\n#include <media/v4l2-ioctl.h>\n#include <media/drv-intf/msp3400.h>\n#include <media/tuner.h>\n\n#include \"cx231xx-vbi.h\"\n\nstatic inline void print_err_status(struct cx231xx *dev, int packet, int status)\n{\n\tchar *errmsg = \"Unknown\";\n\n\tswitch (status) {\n\tcase -ENOENT:\n\t\terrmsg = \"unlinked synchronously\";\n\t\tbreak;\n\tcase -ECONNRESET:\n\t\terrmsg = \"unlinked asynchronously\";\n\t\tbreak;\n\tcase -ENOSR:\n\t\terrmsg = \"Buffer error (overrun)\";\n\t\tbreak;\n\tcase -EPIPE:\n\t\terrmsg = \"Stalled (device not responding)\";\n\t\tbreak;\n\tcase -EOVERFLOW:\n\t\terrmsg = \"Babble (bad cable?)\";\n\t\tbreak;\n\tcase -EPROTO:\n\t\terrmsg = \"Bit-stuff error (bad cable?)\";\n\t\tbreak;\n\tcase -EILSEQ:\n\t\terrmsg = \"CRC/Timeout (could be anything)\";\n\t\tbreak;\n\tcase -ETIME:\n\t\terrmsg = \"Device does not respond\";\n\t\tbreak;\n\t}\n\tif (packet < 0) {\n\t\tdev_err(dev->dev,\n\t\t\t\"URB status %d [%s].\\n\", status, errmsg);\n\t} else {\n\t\tdev_err(dev->dev,\n\t\t\t\"URB packet %d, status %d [%s].\\n\",\n\t\t\tpacket, status, errmsg);\n\t}\n}\n\n \nstatic inline int cx231xx_isoc_vbi_copy(struct cx231xx *dev, struct urb *urb)\n{\n\tstruct cx231xx_dmaqueue *dma_q = urb->context;\n\tint rc = 1;\n\tunsigned char *p_buffer;\n\tu32 bytes_parsed = 0, buffer_size = 0;\n\tu8 sav_eav = 0;\n\n\tif (!dev)\n\t\treturn 0;\n\n\tif (dev->state & DEV_DISCONNECTED)\n\t\treturn 0;\n\n\tif (urb->status < 0) {\n\t\tprint_err_status(dev, -1, urb->status);\n\t\tif (urb->status == -ENOENT)\n\t\t\treturn 0;\n\t}\n\n\t \n\tp_buffer = urb->transfer_buffer;\n\tbuffer_size = urb->actual_length;\n\n\tif (buffer_size > 0) {\n\t\tbytes_parsed = 0;\n\n\t\tif (dma_q->is_partial_line) {\n\t\t\t \n\t\t\tsav_eav = dma_q->last_sav;\n\t\t} else {\n\t\t\t \n\n\t\t\tsav_eav = cx231xx_find_boundary_SAV_EAV(p_buffer,\n\t\t\t\t\t\t\t  dma_q->partial_buf,\n\t\t\t\t\t\t\t  &bytes_parsed);\n\t\t}\n\n\t\tsav_eav &= 0xF0;\n\t\t \n\t\tif (sav_eav) {\n\t\t\tbytes_parsed += cx231xx_get_vbi_line(dev, dma_q,\n\t\t\t\tsav_eav,\t\t        \n\t\t\t\tp_buffer + bytes_parsed,        \n\t\t\t\tbuffer_size - bytes_parsed);    \n\t\t}\n\n\t\t \n\t\tdma_q->is_partial_line = 0;\n\n\t\twhile (bytes_parsed < buffer_size) {\n\t\t\tu32 bytes_used = 0;\n\n\t\t\tsav_eav = cx231xx_find_next_SAV_EAV(\n\t\t\t\tp_buffer + bytes_parsed,\t \n\t\t\t\tbuffer_size - bytes_parsed,  \n\t\t\t\t&bytes_used);\t \n\n\t\t\tbytes_parsed += bytes_used;\n\n\t\t\tsav_eav &= 0xF0;\n\t\t\tif (sav_eav && (bytes_parsed < buffer_size)) {\n\t\t\t\tbytes_parsed += cx231xx_get_vbi_line(dev,\n\t\t\t\t\tdma_q, sav_eav,\t \n\t\t\t\t\tp_buffer+bytes_parsed,  \n\t\t\t\t\tbuffer_size-bytes_parsed); \n\t\t\t}\n\t\t}\n\n\t\t \n\t\tmemcpy(dma_q->partial_buf, p_buffer + buffer_size - 4, 4);\n\t\tbytes_parsed = 0;\n\t}\n\n\treturn rc;\n}\n\n \n\nstatic int vbi_queue_setup(struct vb2_queue *vq,\n\t\t\t   unsigned int *nbuffers, unsigned int *nplanes,\n\t\t\t   unsigned int sizes[], struct device *alloc_devs[])\n{\n\tstruct cx231xx *dev = vb2_get_drv_priv(vq);\n\tu32 height = 0;\n\n\theight = ((dev->norm & V4L2_STD_625_50) ?\n\t\t  PAL_VBI_LINES : NTSC_VBI_LINES);\n\n\t*nplanes = 1;\n\tsizes[0] = (dev->width * height * 2 * 2);\n\treturn 0;\n}\n\n \nstatic int vbi_buf_prepare(struct vb2_buffer *vb)\n{\n\tstruct cx231xx *dev = vb2_get_drv_priv(vb->vb2_queue);\n\tu32 height = 0;\n\tu32 size;\n\n\theight = ((dev->norm & V4L2_STD_625_50) ?\n\t\t  PAL_VBI_LINES : NTSC_VBI_LINES);\n\tsize = ((dev->width << 1) * height * 2);\n\n\tif (vb2_plane_size(vb, 0) < size)\n\t\treturn -EINVAL;\n\tvb2_set_plane_payload(vb, 0, size);\n\treturn 0;\n}\n\nstatic void vbi_buf_queue(struct vb2_buffer *vb)\n{\n\tstruct cx231xx *dev = vb2_get_drv_priv(vb->vb2_queue);\n\tstruct cx231xx_buffer *buf =\n\t    container_of(vb, struct cx231xx_buffer, vb.vb2_buf);\n\tstruct cx231xx_dmaqueue *vidq = &dev->vbi_mode.vidq;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->vbi_mode.slock, flags);\n\tlist_add_tail(&buf->list, &vidq->active);\n\tspin_unlock_irqrestore(&dev->vbi_mode.slock, flags);\n}\n\nstatic void return_all_buffers(struct cx231xx *dev,\n\t\t\t       enum vb2_buffer_state state)\n{\n\tstruct cx231xx_dmaqueue *vidq = &dev->vbi_mode.vidq;\n\tstruct cx231xx_buffer *buf, *node;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->vbi_mode.slock, flags);\n\tdev->vbi_mode.bulk_ctl.buf = NULL;\n\tlist_for_each_entry_safe(buf, node, &vidq->active, list) {\n\t\tlist_del(&buf->list);\n\t\tvb2_buffer_done(&buf->vb.vb2_buf, state);\n\t}\n\tspin_unlock_irqrestore(&dev->vbi_mode.slock, flags);\n}\n\nstatic int vbi_start_streaming(struct vb2_queue *vq, unsigned int count)\n{\n\tstruct cx231xx *dev = vb2_get_drv_priv(vq);\n\tstruct cx231xx_dmaqueue *vidq = &dev->vbi_mode.vidq;\n\tint ret;\n\n\tvidq->sequence = 0;\n\tret = cx231xx_init_vbi_isoc(dev, CX231XX_NUM_VBI_PACKETS,\n\t\t\t\t    CX231XX_NUM_VBI_BUFS,\n\t\t\t\t    dev->vbi_mode.alt_max_pkt_size[0],\n\t\t\t\t    cx231xx_isoc_vbi_copy);\n\tif (ret)\n\t\treturn_all_buffers(dev, VB2_BUF_STATE_QUEUED);\n\treturn ret;\n}\n\nstatic void vbi_stop_streaming(struct vb2_queue *vq)\n{\n\tstruct cx231xx *dev = vb2_get_drv_priv(vq);\n\n\treturn_all_buffers(dev, VB2_BUF_STATE_ERROR);\n}\n\nstruct vb2_ops cx231xx_vbi_qops = {\n\t.queue_setup = vbi_queue_setup,\n\t.buf_prepare = vbi_buf_prepare,\n\t.buf_queue = vbi_buf_queue,\n\t.start_streaming = vbi_start_streaming,\n\t.stop_streaming = vbi_stop_streaming,\n\t.wait_prepare = vb2_ops_wait_prepare,\n\t.wait_finish = vb2_ops_wait_finish,\n};\n\n \n\n \nstatic void cx231xx_irq_vbi_callback(struct urb *urb)\n{\n\tstruct cx231xx_dmaqueue *dma_q = urb->context;\n\tstruct cx231xx_video_mode *vmode =\n\t    container_of(dma_q, struct cx231xx_video_mode, vidq);\n\tstruct cx231xx *dev = container_of(vmode, struct cx231xx, vbi_mode);\n\tunsigned long flags;\n\n\tswitch (urb->status) {\n\tcase 0:\t\t \n\tcase -ETIMEDOUT:\t \n\t\tbreak;\n\tcase -ECONNRESET:\t \n\tcase -ENOENT:\n\tcase -ESHUTDOWN:\n\t\treturn;\n\tdefault:\t\t \n\t\tdev_err(dev->dev,\n\t\t\t\"urb completion error %d.\\n\", urb->status);\n\t\tbreak;\n\t}\n\n\t \n\tspin_lock_irqsave(&dev->vbi_mode.slock, flags);\n\tdev->vbi_mode.bulk_ctl.bulk_copy(dev, urb);\n\tspin_unlock_irqrestore(&dev->vbi_mode.slock, flags);\n\n\t \n\turb->status = 0;\n\n\turb->status = usb_submit_urb(urb, GFP_ATOMIC);\n\tif (urb->status) {\n\t\tdev_err(dev->dev, \"urb resubmit failed (error=%i)\\n\",\n\t\t\turb->status);\n\t}\n}\n\n \nvoid cx231xx_uninit_vbi_isoc(struct cx231xx *dev)\n{\n\tstruct urb *urb;\n\tint i;\n\n\tdev_dbg(dev->dev, \"called cx231xx_uninit_vbi_isoc\\n\");\n\n\tdev->vbi_mode.bulk_ctl.nfields = -1;\n\tfor (i = 0; i < dev->vbi_mode.bulk_ctl.num_bufs; i++) {\n\t\turb = dev->vbi_mode.bulk_ctl.urb[i];\n\t\tif (urb) {\n\t\t\tif (!irqs_disabled())\n\t\t\t\tusb_kill_urb(urb);\n\t\t\telse\n\t\t\t\tusb_unlink_urb(urb);\n\n\t\t\tif (dev->vbi_mode.bulk_ctl.transfer_buffer[i]) {\n\n\t\t\t\tkfree(dev->vbi_mode.bulk_ctl.\n\t\t\t\t      transfer_buffer[i]);\n\t\t\t\tdev->vbi_mode.bulk_ctl.transfer_buffer[i] =\n\t\t\t\t    NULL;\n\t\t\t}\n\t\t\tusb_free_urb(urb);\n\t\t\tdev->vbi_mode.bulk_ctl.urb[i] = NULL;\n\t\t}\n\t\tdev->vbi_mode.bulk_ctl.transfer_buffer[i] = NULL;\n\t}\n\n\tkfree(dev->vbi_mode.bulk_ctl.urb);\n\tkfree(dev->vbi_mode.bulk_ctl.transfer_buffer);\n\n\tdev->vbi_mode.bulk_ctl.urb = NULL;\n\tdev->vbi_mode.bulk_ctl.transfer_buffer = NULL;\n\tdev->vbi_mode.bulk_ctl.num_bufs = 0;\n\n\tcx231xx_capture_start(dev, 0, Vbi);\n}\nEXPORT_SYMBOL_GPL(cx231xx_uninit_vbi_isoc);\n\n \nint cx231xx_init_vbi_isoc(struct cx231xx *dev, int max_packets,\n\t\t\t  int num_bufs, int max_pkt_size,\n\t\t\t  int (*bulk_copy) (struct cx231xx *dev,\n\t\t\t\t\t    struct urb *urb))\n{\n\tstruct cx231xx_dmaqueue *dma_q = &dev->vbi_mode.vidq;\n\tint i;\n\tint sb_size, pipe;\n\tstruct urb *urb;\n\tint rc;\n\n\tdev_dbg(dev->dev, \"called cx231xx_vbi_isoc\\n\");\n\n\t \n\tcx231xx_uninit_vbi_isoc(dev);\n\n\t \n\tusb_clear_halt(dev->udev,\n\t\t       usb_rcvbulkpipe(dev->udev,\n\t\t\t\t       dev->vbi_mode.end_point_addr));\n\n\tdev->vbi_mode.bulk_ctl.bulk_copy = bulk_copy;\n\tdev->vbi_mode.bulk_ctl.num_bufs = num_bufs;\n\tdma_q->pos = 0;\n\tdma_q->is_partial_line = 0;\n\tdma_q->last_sav = 0;\n\tdma_q->current_field = -1;\n\tdma_q->bytes_left_in_line = dev->width << 1;\n\tdma_q->lines_per_field = ((dev->norm & V4L2_STD_625_50) ?\n\t\t\t\t  PAL_VBI_LINES : NTSC_VBI_LINES);\n\tdma_q->lines_completed = 0;\n\tfor (i = 0; i < 8; i++)\n\t\tdma_q->partial_buf[i] = 0;\n\n\tdev->vbi_mode.bulk_ctl.urb = kcalloc(num_bufs, sizeof(void *),\n\t\t\t\t\t     GFP_KERNEL);\n\tif (!dev->vbi_mode.bulk_ctl.urb) {\n\t\tdev_err(dev->dev,\n\t\t\t\"cannot alloc memory for usb buffers\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tdev->vbi_mode.bulk_ctl.transfer_buffer =\n\t    kcalloc(num_bufs, sizeof(void *), GFP_KERNEL);\n\tif (!dev->vbi_mode.bulk_ctl.transfer_buffer) {\n\t\tdev_err(dev->dev,\n\t\t\t\"cannot allocate memory for usbtransfer\\n\");\n\t\tkfree(dev->vbi_mode.bulk_ctl.urb);\n\t\treturn -ENOMEM;\n\t}\n\n\tdev->vbi_mode.bulk_ctl.max_pkt_size = max_pkt_size;\n\tdev->vbi_mode.bulk_ctl.buf = NULL;\n\n\tsb_size = max_packets * dev->vbi_mode.bulk_ctl.max_pkt_size;\n\n\t \n\tfor (i = 0; i < dev->vbi_mode.bulk_ctl.num_bufs; i++) {\n\n\t\turb = usb_alloc_urb(0, GFP_KERNEL);\n\t\tif (!urb) {\n\t\t\tcx231xx_uninit_vbi_isoc(dev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tdev->vbi_mode.bulk_ctl.urb[i] = urb;\n\t\turb->transfer_flags = 0;\n\n\t\tdev->vbi_mode.bulk_ctl.transfer_buffer[i] =\n\t\t    kzalloc(sb_size, GFP_KERNEL);\n\t\tif (!dev->vbi_mode.bulk_ctl.transfer_buffer[i]) {\n\t\t\tdev_err(dev->dev,\n\t\t\t\t\"unable to allocate %i bytes for transfer buffer %i\\n\",\n\t\t\t\tsb_size, i);\n\t\t\tcx231xx_uninit_vbi_isoc(dev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tpipe = usb_rcvbulkpipe(dev->udev, dev->vbi_mode.end_point_addr);\n\t\tusb_fill_bulk_urb(urb, dev->udev, pipe,\n\t\t\t\t  dev->vbi_mode.bulk_ctl.transfer_buffer[i],\n\t\t\t\t  sb_size, cx231xx_irq_vbi_callback, dma_q);\n\t}\n\n\tinit_waitqueue_head(&dma_q->wq);\n\n\t \n\tfor (i = 0; i < dev->vbi_mode.bulk_ctl.num_bufs; i++) {\n\t\trc = usb_submit_urb(dev->vbi_mode.bulk_ctl.urb[i], GFP_ATOMIC);\n\t\tif (rc) {\n\t\t\tdev_err(dev->dev,\n\t\t\t\t\"submit of urb %i failed (error=%i)\\n\", i, rc);\n\t\t\tcx231xx_uninit_vbi_isoc(dev);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\tcx231xx_capture_start(dev, 1, Vbi);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(cx231xx_init_vbi_isoc);\n\nu32 cx231xx_get_vbi_line(struct cx231xx *dev, struct cx231xx_dmaqueue *dma_q,\n\t\t\t u8 sav_eav, u8 *p_buffer, u32 buffer_size)\n{\n\tu32 bytes_copied = 0;\n\tint current_field = -1;\n\n\tswitch (sav_eav) {\n\n\tcase SAV_VBI_FIELD1:\n\t\tcurrent_field = 1;\n\t\tbreak;\n\n\tcase SAV_VBI_FIELD2:\n\t\tcurrent_field = 2;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (current_field < 0)\n\t\treturn bytes_copied;\n\n\tdma_q->last_sav = sav_eav;\n\n\tbytes_copied =\n\t    cx231xx_copy_vbi_line(dev, dma_q, p_buffer, buffer_size,\n\t\t\t\t  current_field);\n\n\treturn bytes_copied;\n}\n\n \nstatic inline void vbi_buffer_filled(struct cx231xx *dev,\n\t\t\t\t     struct cx231xx_dmaqueue *dma_q,\n\t\t\t\t     struct cx231xx_buffer *buf)\n{\n\t \n\t \n\n\tbuf->vb.sequence = dma_q->sequence++;\n\tbuf->vb.vb2_buf.timestamp = ktime_get_ns();\n\n\tdev->vbi_mode.bulk_ctl.buf = NULL;\n\n\tlist_del(&buf->list);\n\tvb2_buffer_done(&buf->vb.vb2_buf, VB2_BUF_STATE_DONE);\n}\n\nu32 cx231xx_copy_vbi_line(struct cx231xx *dev, struct cx231xx_dmaqueue *dma_q,\n\t\t\t  u8 *p_line, u32 length, int field_number)\n{\n\tu32 bytes_to_copy;\n\tstruct cx231xx_buffer *buf;\n\tu32 _line_size = dev->width * 2;\n\n\tif (dma_q->current_field == -1) {\n\t\t \n\t\tcx231xx_reset_vbi_buffer(dev, dma_q);\n\t}\n\n\tif (dma_q->current_field != field_number)\n\t\tdma_q->lines_completed = 0;\n\n\t \n\tbuf = dev->vbi_mode.bulk_ctl.buf;\n\n\t \n\tdma_q->current_field = field_number;\n\n\tbytes_to_copy = dma_q->bytes_left_in_line;\n\tif (bytes_to_copy > length)\n\t\tbytes_to_copy = length;\n\n\tif (dma_q->lines_completed >= dma_q->lines_per_field) {\n\t\tdma_q->bytes_left_in_line -= bytes_to_copy;\n\t\tdma_q->is_partial_line =\n\t\t    (dma_q->bytes_left_in_line == 0) ? 0 : 1;\n\t\treturn 0;\n\t}\n\n\tdma_q->is_partial_line = 1;\n\n\t \n\tif (!buf) {\n\t\tdma_q->bytes_left_in_line -= bytes_to_copy;\n\t\tdma_q->is_partial_line =\n\t\t    (dma_q->bytes_left_in_line == 0) ? 0 : 1;\n\t\treturn bytes_to_copy;\n\t}\n\n\t \n\tcx231xx_do_vbi_copy(dev, dma_q, p_line, bytes_to_copy);\n\n\tdma_q->pos += bytes_to_copy;\n\tdma_q->bytes_left_in_line -= bytes_to_copy;\n\n\tif (dma_q->bytes_left_in_line == 0) {\n\n\t\tdma_q->bytes_left_in_line = _line_size;\n\t\tdma_q->lines_completed++;\n\t\tdma_q->is_partial_line = 0;\n\n\t\tif (cx231xx_is_vbi_buffer_done(dev, dma_q) && buf) {\n\n\t\t\tvbi_buffer_filled(dev, dma_q, buf);\n\n\t\t\tdma_q->pos = 0;\n\t\t\tdma_q->lines_completed = 0;\n\t\t\tcx231xx_reset_vbi_buffer(dev, dma_q);\n\t\t}\n\t}\n\n\treturn bytes_to_copy;\n}\n\n \nstatic inline void get_next_vbi_buf(struct cx231xx_dmaqueue *dma_q,\n\t\t\t\t    struct cx231xx_buffer **buf)\n{\n\tstruct cx231xx_video_mode *vmode =\n\t    container_of(dma_q, struct cx231xx_video_mode, vidq);\n\tstruct cx231xx *dev = container_of(vmode, struct cx231xx, vbi_mode);\n\tchar *outp;\n\n\tif (list_empty(&dma_q->active)) {\n\t\tdev_err(dev->dev, \"No active queue to serve\\n\");\n\t\tdev->vbi_mode.bulk_ctl.buf = NULL;\n\t\t*buf = NULL;\n\t\treturn;\n\t}\n\n\t \n\t*buf = list_entry(dma_q->active.next, struct cx231xx_buffer, list);\n\n\t \n\toutp = vb2_plane_vaddr(&(*buf)->vb.vb2_buf, 0);\n\tmemset(outp, 0, vb2_plane_size(&(*buf)->vb.vb2_buf, 0));\n\n\tdev->vbi_mode.bulk_ctl.buf = *buf;\n\n\treturn;\n}\n\nvoid cx231xx_reset_vbi_buffer(struct cx231xx *dev,\n\t\t\t      struct cx231xx_dmaqueue *dma_q)\n{\n\tstruct cx231xx_buffer *buf;\n\n\tbuf = dev->vbi_mode.bulk_ctl.buf;\n\n\tif (buf == NULL) {\n\t\t \n\t\tget_next_vbi_buf(dma_q, &buf);\n\n\t\tdma_q->pos = 0;\n\t\tdma_q->current_field = -1;\n\t}\n\n\tdma_q->bytes_left_in_line = dev->width << 1;\n\tdma_q->lines_completed = 0;\n}\n\nint cx231xx_do_vbi_copy(struct cx231xx *dev, struct cx231xx_dmaqueue *dma_q,\n\t\t\tu8 *p_buffer, u32 bytes_to_copy)\n{\n\tu8 *p_out_buffer = NULL;\n\tu32 current_line_bytes_copied = 0;\n\tstruct cx231xx_buffer *buf;\n\tu32 _line_size = dev->width << 1;\n\tvoid *startwrite;\n\tint offset, lencopy;\n\n\tbuf = dev->vbi_mode.bulk_ctl.buf;\n\n\tif (buf == NULL)\n\t\treturn -EINVAL;\n\n\tp_out_buffer = vb2_plane_vaddr(&buf->vb.vb2_buf, 0);\n\n\tif (dma_q->bytes_left_in_line != _line_size) {\n\t\tcurrent_line_bytes_copied =\n\t\t    _line_size - dma_q->bytes_left_in_line;\n\t}\n\n\toffset = (dma_q->lines_completed * _line_size) +\n\t\t current_line_bytes_copied;\n\n\tif (dma_q->current_field == 2) {\n\t\t \n\t\toffset += (dev->width * 2 * dma_q->lines_per_field);\n\t}\n\n\t \n\tstartwrite = p_out_buffer + offset;\n\n\tlencopy = dma_q->bytes_left_in_line > bytes_to_copy ?\n\t\t  bytes_to_copy : dma_q->bytes_left_in_line;\n\n\tmemcpy(startwrite, p_buffer, lencopy);\n\n\treturn 0;\n}\n\nu8 cx231xx_is_vbi_buffer_done(struct cx231xx *dev,\n\t\t\t      struct cx231xx_dmaqueue *dma_q)\n{\n\tu32 height = 0;\n\n\theight = ((dev->norm & V4L2_STD_625_50) ?\n\t\t  PAL_VBI_LINES : NTSC_VBI_LINES);\n\tif (dma_q->lines_completed == height && dma_q->current_field == 2)\n\t\treturn 1;\n\telse\n\t\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}