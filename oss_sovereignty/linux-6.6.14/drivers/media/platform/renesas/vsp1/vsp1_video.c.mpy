{
  "module_name": "vsp1_video.c",
  "hash_id": "da05d2b5975cadeb1602d1bbc94599bfc6e6cd1c521cc1108253b9236883307e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/platform/renesas/vsp1/vsp1_video.c",
  "human_readable_source": "\n \n\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n#include <linux/v4l2-mediabus.h>\n#include <linux/videodev2.h>\n#include <linux/wait.h>\n\n#include <media/media-entity.h>\n#include <media/v4l2-dev.h>\n#include <media/v4l2-fh.h>\n#include <media/v4l2-ioctl.h>\n#include <media/v4l2-subdev.h>\n#include <media/videobuf2-v4l2.h>\n#include <media/videobuf2-dma-contig.h>\n\n#include \"vsp1.h\"\n#include \"vsp1_brx.h\"\n#include \"vsp1_dl.h\"\n#include \"vsp1_entity.h\"\n#include \"vsp1_hgo.h\"\n#include \"vsp1_hgt.h\"\n#include \"vsp1_pipe.h\"\n#include \"vsp1_rwpf.h\"\n#include \"vsp1_uds.h\"\n#include \"vsp1_video.h\"\n\n#define VSP1_VIDEO_DEF_FORMAT\t\tV4L2_PIX_FMT_YUYV\n#define VSP1_VIDEO_DEF_WIDTH\t\t1024\n#define VSP1_VIDEO_DEF_HEIGHT\t\t768\n\n#define VSP1_VIDEO_MAX_WIDTH\t\t8190U\n#define VSP1_VIDEO_MAX_HEIGHT\t\t8190U\n\n \n\nstatic struct v4l2_subdev *\nvsp1_video_remote_subdev(struct media_pad *local, u32 *pad)\n{\n\tstruct media_pad *remote;\n\n\tremote = media_pad_remote_pad_first(local);\n\tif (!remote || !is_media_entity_v4l2_subdev(remote->entity))\n\t\treturn NULL;\n\n\tif (pad)\n\t\t*pad = remote->index;\n\n\treturn media_entity_to_v4l2_subdev(remote->entity);\n}\n\nstatic int vsp1_video_verify_format(struct vsp1_video *video)\n{\n\tstruct v4l2_subdev_format fmt = {\n\t\t.which = V4L2_SUBDEV_FORMAT_ACTIVE,\n\t};\n\tstruct v4l2_subdev *subdev;\n\tint ret;\n\n\tsubdev = vsp1_video_remote_subdev(&video->pad, &fmt.pad);\n\tif (subdev == NULL)\n\t\treturn -EINVAL;\n\n\tret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &fmt);\n\tif (ret < 0)\n\t\treturn ret == -ENOIOCTLCMD ? -EINVAL : ret;\n\n\tif (video->rwpf->fmtinfo->mbus != fmt.format.code ||\n\t    video->rwpf->format.height != fmt.format.height ||\n\t    video->rwpf->format.width != fmt.format.width)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int __vsp1_video_try_format(struct vsp1_video *video,\n\t\t\t\t   struct v4l2_pix_format_mplane *pix,\n\t\t\t\t   const struct vsp1_format_info **fmtinfo)\n{\n\tstatic const u32 xrgb_formats[][2] = {\n\t\t{ V4L2_PIX_FMT_RGB444, V4L2_PIX_FMT_XRGB444 },\n\t\t{ V4L2_PIX_FMT_RGB555, V4L2_PIX_FMT_XRGB555 },\n\t\t{ V4L2_PIX_FMT_BGR32, V4L2_PIX_FMT_XBGR32 },\n\t\t{ V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_XRGB32 },\n\t};\n\n\tconst struct vsp1_format_info *info;\n\tunsigned int width = pix->width;\n\tunsigned int height = pix->height;\n\tunsigned int i;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(xrgb_formats); ++i) {\n\t\tif (xrgb_formats[i][0] == pix->pixelformat) {\n\t\t\tpix->pixelformat = xrgb_formats[i][1];\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tinfo = vsp1_get_format_info(video->vsp1, pix->pixelformat);\n\tif (info == NULL)\n\t\tinfo = vsp1_get_format_info(video->vsp1, VSP1_VIDEO_DEF_FORMAT);\n\n\tpix->pixelformat = info->fourcc;\n\tpix->colorspace = V4L2_COLORSPACE_SRGB;\n\tpix->field = V4L2_FIELD_NONE;\n\n\tif (info->fourcc == V4L2_PIX_FMT_HSV24 ||\n\t    info->fourcc == V4L2_PIX_FMT_HSV32)\n\t\tpix->hsv_enc = V4L2_HSV_ENC_256;\n\n\tmemset(pix->reserved, 0, sizeof(pix->reserved));\n\n\t \n\twidth = round_down(width, info->hsub);\n\theight = round_down(height, info->vsub);\n\n\t \n\tpix->width = clamp(width, info->hsub, VSP1_VIDEO_MAX_WIDTH);\n\tpix->height = clamp(height, info->vsub, VSP1_VIDEO_MAX_HEIGHT);\n\n\t \n\tfor (i = 0; i < min(info->planes, 2U); ++i) {\n\t\tunsigned int hsub = i > 0 ? info->hsub : 1;\n\t\tunsigned int vsub = i > 0 ? info->vsub : 1;\n\t\tunsigned int align = 128;\n\t\tunsigned int bpl;\n\n\t\tbpl = clamp_t(unsigned int, pix->plane_fmt[i].bytesperline,\n\t\t\t      pix->width / hsub * info->bpp[i] / 8,\n\t\t\t      round_down(65535U, align));\n\n\t\tpix->plane_fmt[i].bytesperline = round_up(bpl, align);\n\t\tpix->plane_fmt[i].sizeimage = pix->plane_fmt[i].bytesperline\n\t\t\t\t\t    * pix->height / vsub;\n\t}\n\n\tif (info->planes == 3) {\n\t\t \n\t\tpix->plane_fmt[2].bytesperline = pix->plane_fmt[1].bytesperline;\n\t\tpix->plane_fmt[2].sizeimage = pix->plane_fmt[1].sizeimage;\n\t}\n\n\tpix->num_planes = info->planes;\n\n\tif (fmtinfo)\n\t\t*fmtinfo = info;\n\n\treturn 0;\n}\n\n \n\n \nstatic void vsp1_video_calculate_partition(struct vsp1_pipeline *pipe,\n\t\t\t\t\t   struct vsp1_partition *partition,\n\t\t\t\t\t   unsigned int div_size,\n\t\t\t\t\t   unsigned int index)\n{\n\tconst struct v4l2_mbus_framefmt *format;\n\tstruct vsp1_partition_window window;\n\tunsigned int modulus;\n\n\t \n\tformat = vsp1_entity_get_pad_format(&pipe->output->entity,\n\t\t\t\t\t    pipe->output->entity.config,\n\t\t\t\t\t    RWPF_PAD_SINK);\n\n\t \n\tif (pipe->partitions <= 1) {\n\t\twindow.left = 0;\n\t\twindow.width = format->width;\n\n\t\tvsp1_pipeline_propagate_partition(pipe, partition, index,\n\t\t\t\t\t\t  &window);\n\t\treturn;\n\t}\n\n\t \n\twindow.left = index * div_size;\n\twindow.width = div_size;\n\n\tmodulus = format->width % div_size;\n\n\t \n\tif (modulus) {\n\t\t \n\t\tunsigned int partitions = pipe->partitions - 1;\n\n\t\tif (modulus < div_size / 2) {\n\t\t\tif (index == partitions - 1) {\n\t\t\t\t \n\t\t\t\twindow.width = div_size / 2;\n\t\t\t} else if (index == partitions) {\n\t\t\t\t \n\t\t\t\twindow.width = (div_size / 2) + modulus;\n\t\t\t\twindow.left -= div_size / 2;\n\t\t\t}\n\t\t} else if (index == partitions) {\n\t\t\twindow.width = modulus;\n\t\t}\n\t}\n\n\tvsp1_pipeline_propagate_partition(pipe, partition, index, &window);\n}\n\nstatic int vsp1_video_pipeline_setup_partitions(struct vsp1_pipeline *pipe)\n{\n\tstruct vsp1_device *vsp1 = pipe->output->entity.vsp1;\n\tconst struct v4l2_mbus_framefmt *format;\n\tstruct vsp1_entity *entity;\n\tunsigned int div_size;\n\tunsigned int i;\n\n\t \n\tformat = vsp1_entity_get_pad_format(&pipe->output->entity,\n\t\t\t\t\t    pipe->output->entity.config,\n\t\t\t\t\t    RWPF_PAD_SINK);\n\tdiv_size = format->width;\n\n\t \n\tif (vsp1->info->gen >= 3) {\n\t\tlist_for_each_entry(entity, &pipe->entities, list_pipe) {\n\t\t\tunsigned int entity_max;\n\n\t\t\tif (!entity->ops->max_width)\n\t\t\t\tcontinue;\n\n\t\t\tentity_max = entity->ops->max_width(entity, pipe);\n\t\t\tif (entity_max)\n\t\t\t\tdiv_size = min(div_size, entity_max);\n\t\t}\n\t}\n\n\tpipe->partitions = DIV_ROUND_UP(format->width, div_size);\n\tpipe->part_table = kcalloc(pipe->partitions, sizeof(*pipe->part_table),\n\t\t\t\t   GFP_KERNEL);\n\tif (!pipe->part_table)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < pipe->partitions; ++i)\n\t\tvsp1_video_calculate_partition(pipe, &pipe->part_table[i],\n\t\t\t\t\t       div_size, i);\n\n\treturn 0;\n}\n\n \n\n \nstatic struct vsp1_vb2_buffer *\nvsp1_video_complete_buffer(struct vsp1_video *video)\n{\n\tstruct vsp1_pipeline *pipe = video->rwpf->entity.pipe;\n\tstruct vsp1_vb2_buffer *next = NULL;\n\tstruct vsp1_vb2_buffer *done;\n\tunsigned long flags;\n\tunsigned int i;\n\n\tspin_lock_irqsave(&video->irqlock, flags);\n\n\tif (list_empty(&video->irqqueue)) {\n\t\tspin_unlock_irqrestore(&video->irqlock, flags);\n\t\treturn NULL;\n\t}\n\n\tdone = list_first_entry(&video->irqqueue,\n\t\t\t\tstruct vsp1_vb2_buffer, queue);\n\n\tlist_del(&done->queue);\n\n\tif (!list_empty(&video->irqqueue))\n\t\tnext = list_first_entry(&video->irqqueue,\n\t\t\t\t\tstruct vsp1_vb2_buffer, queue);\n\n\tspin_unlock_irqrestore(&video->irqlock, flags);\n\n\tdone->buf.sequence = pipe->sequence;\n\tdone->buf.vb2_buf.timestamp = ktime_get_ns();\n\tfor (i = 0; i < done->buf.vb2_buf.num_planes; ++i)\n\t\tvb2_set_plane_payload(&done->buf.vb2_buf, i,\n\t\t\t\t      vb2_plane_size(&done->buf.vb2_buf, i));\n\tvb2_buffer_done(&done->buf.vb2_buf, VB2_BUF_STATE_DONE);\n\n\treturn next;\n}\n\nstatic void vsp1_video_frame_end(struct vsp1_pipeline *pipe,\n\t\t\t\t struct vsp1_rwpf *rwpf)\n{\n\tstruct vsp1_video *video = rwpf->video;\n\tstruct vsp1_vb2_buffer *buf;\n\n\tbuf = vsp1_video_complete_buffer(video);\n\tif (buf == NULL)\n\t\treturn;\n\n\tvideo->rwpf->mem = buf->mem;\n\tpipe->buffers_ready |= 1 << video->pipe_index;\n}\n\nstatic void vsp1_video_pipeline_run_partition(struct vsp1_pipeline *pipe,\n\t\t\t\t\t      struct vsp1_dl_list *dl,\n\t\t\t\t\t      unsigned int partition)\n{\n\tstruct vsp1_dl_body *dlb = vsp1_dl_list_get_body0(dl);\n\tstruct vsp1_entity *entity;\n\n\tpipe->partition = &pipe->part_table[partition];\n\n\tlist_for_each_entry(entity, &pipe->entities, list_pipe)\n\t\tvsp1_entity_configure_partition(entity, pipe, dl, dlb);\n}\n\nstatic void vsp1_video_pipeline_run(struct vsp1_pipeline *pipe)\n{\n\tstruct vsp1_device *vsp1 = pipe->output->entity.vsp1;\n\tstruct vsp1_entity *entity;\n\tstruct vsp1_dl_body *dlb;\n\tstruct vsp1_dl_list *dl;\n\tunsigned int partition;\n\n\tdl = vsp1_dl_list_get(pipe->output->dlm);\n\n\t \n\tif (!pipe->configured)\n\t\tvsp1_dl_list_add_body(dl, pipe->stream_config);\n\n\tdlb = vsp1_dl_list_get_body0(dl);\n\n\tlist_for_each_entry(entity, &pipe->entities, list_pipe)\n\t\tvsp1_entity_configure_frame(entity, pipe, dl, dlb);\n\n\t \n\tvsp1_video_pipeline_run_partition(pipe, dl, 0);\n\n\t \n\tfor (partition = 1; partition < pipe->partitions; ++partition) {\n\t\tstruct vsp1_dl_list *dl_next;\n\n\t\tdl_next = vsp1_dl_list_get(pipe->output->dlm);\n\n\t\t \n\t\tif (!dl_next) {\n\t\t\tdev_err(vsp1->dev, \"Failed to obtain a dl list. Frame will be incomplete\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tvsp1_video_pipeline_run_partition(pipe, dl_next, partition);\n\t\tvsp1_dl_list_add_chain(dl, dl_next);\n\t}\n\n\t \n\tvsp1_dl_list_commit(dl, 0);\n\tpipe->configured = true;\n\n\tvsp1_pipeline_run(pipe);\n}\n\nstatic void vsp1_video_pipeline_frame_end(struct vsp1_pipeline *pipe,\n\t\t\t\t\t  unsigned int completion)\n{\n\tstruct vsp1_device *vsp1 = pipe->output->entity.vsp1;\n\tenum vsp1_pipeline_state state;\n\tunsigned long flags;\n\tunsigned int i;\n\n\t \n\tWARN_ON_ONCE(!(completion & VSP1_DL_FRAME_END_COMPLETED));\n\n\tspin_lock_irqsave(&pipe->irqlock, flags);\n\n\t \n\tfor (i = 0; i < vsp1->info->rpf_count; ++i) {\n\t\tif (!pipe->inputs[i])\n\t\t\tcontinue;\n\n\t\tvsp1_video_frame_end(pipe, pipe->inputs[i]);\n\t}\n\n\tvsp1_video_frame_end(pipe, pipe->output);\n\n\tstate = pipe->state;\n\tpipe->state = VSP1_PIPELINE_STOPPED;\n\n\t \n\tif (state == VSP1_PIPELINE_STOPPING)\n\t\twake_up(&pipe->wq);\n\telse if (vsp1_pipeline_ready(pipe))\n\t\tvsp1_video_pipeline_run(pipe);\n\n\tspin_unlock_irqrestore(&pipe->irqlock, flags);\n}\n\nstatic int vsp1_video_pipeline_build_branch(struct vsp1_pipeline *pipe,\n\t\t\t\t\t    struct vsp1_rwpf *input,\n\t\t\t\t\t    struct vsp1_rwpf *output)\n{\n\tstruct media_entity_enum ent_enum;\n\tstruct vsp1_entity *entity;\n\tstruct media_pad *pad;\n\tstruct vsp1_brx *brx = NULL;\n\tint ret;\n\n\tret = media_entity_enum_init(&ent_enum, &input->entity.vsp1->media_dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\n\tpad = vsp1_entity_remote_pad(&input->entity.pads[RWPF_PAD_SOURCE]);\n\n\twhile (1) {\n\t\tif (pad == NULL) {\n\t\t\tret = -EPIPE;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tif (!is_media_entity_v4l2_subdev(pad->entity)) {\n\t\t\tret = -EPIPE;\n\t\t\tgoto out;\n\t\t}\n\n\t\tentity = to_vsp1_entity(\n\t\t\tmedia_entity_to_v4l2_subdev(pad->entity));\n\n\t\t \n\t\tif (entity->type == VSP1_ENTITY_BRU ||\n\t\t    entity->type == VSP1_ENTITY_BRS) {\n\t\t\t \n\t\t\tif (brx) {\n\t\t\t\tret = -EPIPE;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tbrx = to_brx(&entity->subdev);\n\t\t\tbrx->inputs[pad->index].rpf = input;\n\t\t\tinput->brx_input = pad->index;\n\t\t}\n\n\t\t \n\t\tif (entity->type == VSP1_ENTITY_WPF)\n\t\t\tbreak;\n\n\t\t \n\t\tif (media_entity_enum_test_and_set(&ent_enum,\n\t\t\t\t\t\t   &entity->subdev.entity)) {\n\t\t\tret = -EPIPE;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tif (entity->type == VSP1_ENTITY_UDS) {\n\t\t\tif (pipe->uds) {\n\t\t\t\tret = -EPIPE;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tpipe->uds = entity;\n\t\t\tpipe->uds_input = brx ? &brx->entity : &input->entity;\n\t\t}\n\n\t\t \n\t\tpad = &entity->pads[entity->source_pad];\n\t\tpad = vsp1_entity_remote_pad(pad);\n\t}\n\n\t \n\tif (entity != &output->entity)\n\t\tret = -EPIPE;\n\nout:\n\tmedia_entity_enum_cleanup(&ent_enum);\n\n\treturn ret;\n}\n\nstatic int vsp1_video_pipeline_build(struct vsp1_pipeline *pipe,\n\t\t\t\t     struct vsp1_video *video)\n{\n\tstruct media_graph graph;\n\tstruct media_entity *entity = &video->video.entity;\n\tstruct media_device *mdev = entity->graph_obj.mdev;\n\tunsigned int i;\n\tint ret;\n\n\t \n\tret = media_graph_walk_init(&graph, mdev);\n\tif (ret)\n\t\treturn ret;\n\n\tmedia_graph_walk_start(&graph, entity);\n\n\twhile ((entity = media_graph_walk_next(&graph))) {\n\t\tstruct v4l2_subdev *subdev;\n\t\tstruct vsp1_rwpf *rwpf;\n\t\tstruct vsp1_entity *e;\n\n\t\tif (!is_media_entity_v4l2_subdev(entity))\n\t\t\tcontinue;\n\n\t\tsubdev = media_entity_to_v4l2_subdev(entity);\n\t\te = to_vsp1_entity(subdev);\n\t\tlist_add_tail(&e->list_pipe, &pipe->entities);\n\t\te->pipe = pipe;\n\n\t\tswitch (e->type) {\n\t\tcase VSP1_ENTITY_RPF:\n\t\t\trwpf = to_rwpf(subdev);\n\t\t\tpipe->inputs[rwpf->entity.index] = rwpf;\n\t\t\trwpf->video->pipe_index = ++pipe->num_inputs;\n\t\t\tbreak;\n\n\t\tcase VSP1_ENTITY_WPF:\n\t\t\trwpf = to_rwpf(subdev);\n\t\t\tpipe->output = rwpf;\n\t\t\trwpf->video->pipe_index = 0;\n\t\t\tbreak;\n\n\t\tcase VSP1_ENTITY_LIF:\n\t\t\tpipe->lif = e;\n\t\t\tbreak;\n\n\t\tcase VSP1_ENTITY_BRU:\n\t\tcase VSP1_ENTITY_BRS:\n\t\t\tpipe->brx = e;\n\t\t\tbreak;\n\n\t\tcase VSP1_ENTITY_HGO:\n\t\t\tpipe->hgo = e;\n\t\t\tbreak;\n\n\t\tcase VSP1_ENTITY_HGT:\n\t\t\tpipe->hgt = e;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmedia_graph_walk_cleanup(&graph);\n\n\t \n\tif (pipe->num_inputs == 0 || !pipe->output)\n\t\treturn -EPIPE;\n\n\t \n\tfor (i = 0; i < video->vsp1->info->rpf_count; ++i) {\n\t\tif (!pipe->inputs[i])\n\t\t\tcontinue;\n\n\t\tret = vsp1_video_pipeline_build_branch(pipe, pipe->inputs[i],\n\t\t\t\t\t\t       pipe->output);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int vsp1_video_pipeline_init(struct vsp1_pipeline *pipe,\n\t\t\t\t    struct vsp1_video *video)\n{\n\tvsp1_pipeline_init(pipe);\n\n\tpipe->frame_end = vsp1_video_pipeline_frame_end;\n\n\treturn vsp1_video_pipeline_build(pipe, video);\n}\n\nstatic struct vsp1_pipeline *vsp1_video_pipeline_get(struct vsp1_video *video)\n{\n\tstruct vsp1_pipeline *pipe;\n\tint ret;\n\n\t \n\tif (!video->rwpf->entity.pipe) {\n\t\tpipe = kzalloc(sizeof(*pipe), GFP_KERNEL);\n\t\tif (!pipe)\n\t\t\treturn ERR_PTR(-ENOMEM);\n\n\t\tret = vsp1_video_pipeline_init(pipe, video);\n\t\tif (ret < 0) {\n\t\t\tvsp1_pipeline_reset(pipe);\n\t\t\tkfree(pipe);\n\t\t\treturn ERR_PTR(ret);\n\t\t}\n\t} else {\n\t\tpipe = video->rwpf->entity.pipe;\n\t\tkref_get(&pipe->kref);\n\t}\n\n\treturn pipe;\n}\n\nstatic void vsp1_video_pipeline_release(struct kref *kref)\n{\n\tstruct vsp1_pipeline *pipe = container_of(kref, typeof(*pipe), kref);\n\n\tvsp1_pipeline_reset(pipe);\n\tkfree(pipe);\n}\n\nstatic void vsp1_video_pipeline_put(struct vsp1_pipeline *pipe)\n{\n\tstruct media_device *mdev = &pipe->output->entity.vsp1->media_dev;\n\n\tmutex_lock(&mdev->graph_mutex);\n\tkref_put(&pipe->kref, vsp1_video_pipeline_release);\n\tmutex_unlock(&mdev->graph_mutex);\n}\n\n \n\nstatic int\nvsp1_video_queue_setup(struct vb2_queue *vq,\n\t\t       unsigned int *nbuffers, unsigned int *nplanes,\n\t\t       unsigned int sizes[], struct device *alloc_devs[])\n{\n\tstruct vsp1_video *video = vb2_get_drv_priv(vq);\n\tconst struct v4l2_pix_format_mplane *format = &video->rwpf->format;\n\tunsigned int i;\n\n\tif (*nplanes) {\n\t\tif (*nplanes != format->num_planes)\n\t\t\treturn -EINVAL;\n\n\t\tfor (i = 0; i < *nplanes; i++)\n\t\t\tif (sizes[i] < format->plane_fmt[i].sizeimage)\n\t\t\t\treturn -EINVAL;\n\t\treturn 0;\n\t}\n\n\t*nplanes = format->num_planes;\n\n\tfor (i = 0; i < format->num_planes; ++i)\n\t\tsizes[i] = format->plane_fmt[i].sizeimage;\n\n\treturn 0;\n}\n\nstatic int vsp1_video_buffer_prepare(struct vb2_buffer *vb)\n{\n\tstruct vb2_v4l2_buffer *vbuf = to_vb2_v4l2_buffer(vb);\n\tstruct vsp1_video *video = vb2_get_drv_priv(vb->vb2_queue);\n\tstruct vsp1_vb2_buffer *buf = to_vsp1_vb2_buffer(vbuf);\n\tconst struct v4l2_pix_format_mplane *format = &video->rwpf->format;\n\tunsigned int i;\n\n\tif (vb->num_planes < format->num_planes)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < vb->num_planes; ++i) {\n\t\tbuf->mem.addr[i] = vb2_dma_contig_plane_dma_addr(vb, i);\n\n\t\tif (vb2_plane_size(vb, i) < format->plane_fmt[i].sizeimage)\n\t\t\treturn -EINVAL;\n\t}\n\n\tfor ( ; i < 3; ++i)\n\t\tbuf->mem.addr[i] = 0;\n\n\treturn 0;\n}\n\nstatic void vsp1_video_buffer_queue(struct vb2_buffer *vb)\n{\n\tstruct vb2_v4l2_buffer *vbuf = to_vb2_v4l2_buffer(vb);\n\tstruct vsp1_video *video = vb2_get_drv_priv(vb->vb2_queue);\n\tstruct vsp1_pipeline *pipe = video->rwpf->entity.pipe;\n\tstruct vsp1_vb2_buffer *buf = to_vsp1_vb2_buffer(vbuf);\n\tunsigned long flags;\n\tbool empty;\n\n\tspin_lock_irqsave(&video->irqlock, flags);\n\tempty = list_empty(&video->irqqueue);\n\tlist_add_tail(&buf->queue, &video->irqqueue);\n\tspin_unlock_irqrestore(&video->irqlock, flags);\n\n\tif (!empty)\n\t\treturn;\n\n\tspin_lock_irqsave(&pipe->irqlock, flags);\n\n\tvideo->rwpf->mem = buf->mem;\n\tpipe->buffers_ready |= 1 << video->pipe_index;\n\n\tif (vb2_start_streaming_called(&video->queue) &&\n\t    vsp1_pipeline_ready(pipe))\n\t\tvsp1_video_pipeline_run(pipe);\n\n\tspin_unlock_irqrestore(&pipe->irqlock, flags);\n}\n\nstatic int vsp1_video_setup_pipeline(struct vsp1_pipeline *pipe)\n{\n\tstruct vsp1_entity *entity;\n\tint ret;\n\n\t \n\tret = vsp1_video_pipeline_setup_partitions(pipe);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (pipe->uds) {\n\t\tstruct vsp1_uds *uds = to_uds(&pipe->uds->subdev);\n\n\t\t \n\t\tif (pipe->uds_input->type == VSP1_ENTITY_BRU ||\n\t\t    pipe->uds_input->type == VSP1_ENTITY_BRS) {\n\t\t\tuds->scale_alpha = false;\n\t\t} else {\n\t\t\tstruct vsp1_rwpf *rpf =\n\t\t\t\tto_rwpf(&pipe->uds_input->subdev);\n\n\t\t\tuds->scale_alpha = rpf->fmtinfo->alpha;\n\t\t}\n\t}\n\n\t \n\tpipe->stream_config = vsp1_dlm_dl_body_get(pipe->output->dlm);\n\tif (!pipe->stream_config)\n\t\treturn -ENOMEM;\n\n\tlist_for_each_entry(entity, &pipe->entities, list_pipe) {\n\t\tvsp1_entity_route_setup(entity, pipe, pipe->stream_config);\n\t\tvsp1_entity_configure_stream(entity, pipe, NULL,\n\t\t\t\t\t     pipe->stream_config);\n\t}\n\n\treturn 0;\n}\n\nstatic void vsp1_video_release_buffers(struct vsp1_video *video)\n{\n\tstruct vsp1_vb2_buffer *buffer;\n\tunsigned long flags;\n\n\t \n\tspin_lock_irqsave(&video->irqlock, flags);\n\tlist_for_each_entry(buffer, &video->irqqueue, queue)\n\t\tvb2_buffer_done(&buffer->buf.vb2_buf, VB2_BUF_STATE_ERROR);\n\tINIT_LIST_HEAD(&video->irqqueue);\n\tspin_unlock_irqrestore(&video->irqlock, flags);\n}\n\nstatic void vsp1_video_cleanup_pipeline(struct vsp1_pipeline *pipe)\n{\n\tlockdep_assert_held(&pipe->lock);\n\n\t \n\tvsp1_dl_body_put(pipe->stream_config);\n\tpipe->stream_config = NULL;\n\tpipe->configured = false;\n\n\t \n\tkfree(pipe->part_table);\n\tpipe->part_table = NULL;\n}\n\nstatic int vsp1_video_start_streaming(struct vb2_queue *vq, unsigned int count)\n{\n\tstruct vsp1_video *video = vb2_get_drv_priv(vq);\n\tstruct vsp1_pipeline *pipe = video->rwpf->entity.pipe;\n\tbool start_pipeline = false;\n\tunsigned long flags;\n\tint ret;\n\n\tmutex_lock(&pipe->lock);\n\tif (pipe->stream_count == pipe->num_inputs) {\n\t\tret = vsp1_video_setup_pipeline(pipe);\n\t\tif (ret < 0) {\n\t\t\tvsp1_video_release_buffers(video);\n\t\t\tvsp1_video_cleanup_pipeline(pipe);\n\t\t\tmutex_unlock(&pipe->lock);\n\t\t\treturn ret;\n\t\t}\n\n\t\tstart_pipeline = true;\n\t}\n\n\tpipe->stream_count++;\n\tmutex_unlock(&pipe->lock);\n\n\t \n\tif (!start_pipeline)\n\t\treturn 0;\n\n\tspin_lock_irqsave(&pipe->irqlock, flags);\n\tif (vsp1_pipeline_ready(pipe))\n\t\tvsp1_video_pipeline_run(pipe);\n\tspin_unlock_irqrestore(&pipe->irqlock, flags);\n\n\treturn 0;\n}\n\nstatic void vsp1_video_stop_streaming(struct vb2_queue *vq)\n{\n\tstruct vsp1_video *video = vb2_get_drv_priv(vq);\n\tstruct vsp1_pipeline *pipe = video->rwpf->entity.pipe;\n\tunsigned long flags;\n\tint ret;\n\n\t \n\tspin_lock_irqsave(&video->irqlock, flags);\n\tpipe->buffers_ready &= ~(1 << video->pipe_index);\n\tspin_unlock_irqrestore(&video->irqlock, flags);\n\n\tmutex_lock(&pipe->lock);\n\tif (--pipe->stream_count == pipe->num_inputs) {\n\t\t \n\t\tret = vsp1_pipeline_stop(pipe);\n\t\tif (ret == -ETIMEDOUT)\n\t\t\tdev_err(video->vsp1->dev, \"pipeline stop timeout\\n\");\n\n\t\tvsp1_video_cleanup_pipeline(pipe);\n\t}\n\tmutex_unlock(&pipe->lock);\n\n\tvideo_device_pipeline_stop(&video->video);\n\tvsp1_video_release_buffers(video);\n\tvsp1_video_pipeline_put(pipe);\n}\n\nstatic const struct vb2_ops vsp1_video_queue_qops = {\n\t.queue_setup = vsp1_video_queue_setup,\n\t.buf_prepare = vsp1_video_buffer_prepare,\n\t.buf_queue = vsp1_video_buffer_queue,\n\t.wait_prepare = vb2_ops_wait_prepare,\n\t.wait_finish = vb2_ops_wait_finish,\n\t.start_streaming = vsp1_video_start_streaming,\n\t.stop_streaming = vsp1_video_stop_streaming,\n};\n\n \n\nstatic int\nvsp1_video_querycap(struct file *file, void *fh, struct v4l2_capability *cap)\n{\n\tstruct v4l2_fh *vfh = file->private_data;\n\tstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\n\n\tcap->capabilities = V4L2_CAP_DEVICE_CAPS | V4L2_CAP_STREAMING\n\t\t\t  | V4L2_CAP_VIDEO_CAPTURE_MPLANE\n\t\t\t  | V4L2_CAP_VIDEO_OUTPUT_MPLANE;\n\n\n\tstrscpy(cap->driver, \"vsp1\", sizeof(cap->driver));\n\tstrscpy(cap->card, video->video.name, sizeof(cap->card));\n\n\treturn 0;\n}\n\nstatic int\nvsp1_video_get_format(struct file *file, void *fh, struct v4l2_format *format)\n{\n\tstruct v4l2_fh *vfh = file->private_data;\n\tstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\n\n\tif (format->type != video->queue.type)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&video->lock);\n\tformat->fmt.pix_mp = video->rwpf->format;\n\tmutex_unlock(&video->lock);\n\n\treturn 0;\n}\n\nstatic int\nvsp1_video_try_format(struct file *file, void *fh, struct v4l2_format *format)\n{\n\tstruct v4l2_fh *vfh = file->private_data;\n\tstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\n\n\tif (format->type != video->queue.type)\n\t\treturn -EINVAL;\n\n\treturn __vsp1_video_try_format(video, &format->fmt.pix_mp, NULL);\n}\n\nstatic int\nvsp1_video_set_format(struct file *file, void *fh, struct v4l2_format *format)\n{\n\tstruct v4l2_fh *vfh = file->private_data;\n\tstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\n\tconst struct vsp1_format_info *info;\n\tint ret;\n\n\tif (format->type != video->queue.type)\n\t\treturn -EINVAL;\n\n\tret = __vsp1_video_try_format(video, &format->fmt.pix_mp, &info);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&video->lock);\n\n\tif (vb2_is_busy(&video->queue)) {\n\t\tret = -EBUSY;\n\t\tgoto done;\n\t}\n\n\tvideo->rwpf->format = format->fmt.pix_mp;\n\tvideo->rwpf->fmtinfo = info;\n\ndone:\n\tmutex_unlock(&video->lock);\n\treturn ret;\n}\n\nstatic int\nvsp1_video_streamon(struct file *file, void *fh, enum v4l2_buf_type type)\n{\n\tstruct v4l2_fh *vfh = file->private_data;\n\tstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\n\tstruct media_device *mdev = &video->vsp1->media_dev;\n\tstruct vsp1_pipeline *pipe;\n\tint ret;\n\n\tif (vb2_queue_is_busy(&video->queue, file))\n\t\treturn -EBUSY;\n\n\t \n\tmutex_lock(&mdev->graph_mutex);\n\n\tpipe = vsp1_video_pipeline_get(video);\n\tif (IS_ERR(pipe)) {\n\t\tmutex_unlock(&mdev->graph_mutex);\n\t\treturn PTR_ERR(pipe);\n\t}\n\n\tret = __video_device_pipeline_start(&video->video, &pipe->pipe);\n\tif (ret < 0) {\n\t\tmutex_unlock(&mdev->graph_mutex);\n\t\tgoto err_pipe;\n\t}\n\n\tmutex_unlock(&mdev->graph_mutex);\n\n\t \n\tret = vsp1_video_verify_format(video);\n\tif (ret < 0)\n\t\tgoto err_stop;\n\n\t \n\tret = vb2_streamon(&video->queue, type);\n\tif (ret < 0)\n\t\tgoto err_stop;\n\n\treturn 0;\n\nerr_stop:\n\tvideo_device_pipeline_stop(&video->video);\nerr_pipe:\n\tvsp1_video_pipeline_put(pipe);\n\treturn ret;\n}\n\nstatic const struct v4l2_ioctl_ops vsp1_video_ioctl_ops = {\n\t.vidioc_querycap\t\t= vsp1_video_querycap,\n\t.vidioc_g_fmt_vid_cap_mplane\t= vsp1_video_get_format,\n\t.vidioc_s_fmt_vid_cap_mplane\t= vsp1_video_set_format,\n\t.vidioc_try_fmt_vid_cap_mplane\t= vsp1_video_try_format,\n\t.vidioc_g_fmt_vid_out_mplane\t= vsp1_video_get_format,\n\t.vidioc_s_fmt_vid_out_mplane\t= vsp1_video_set_format,\n\t.vidioc_try_fmt_vid_out_mplane\t= vsp1_video_try_format,\n\t.vidioc_reqbufs\t\t\t= vb2_ioctl_reqbufs,\n\t.vidioc_querybuf\t\t= vb2_ioctl_querybuf,\n\t.vidioc_qbuf\t\t\t= vb2_ioctl_qbuf,\n\t.vidioc_dqbuf\t\t\t= vb2_ioctl_dqbuf,\n\t.vidioc_expbuf\t\t\t= vb2_ioctl_expbuf,\n\t.vidioc_create_bufs\t\t= vb2_ioctl_create_bufs,\n\t.vidioc_prepare_buf\t\t= vb2_ioctl_prepare_buf,\n\t.vidioc_streamon\t\t= vsp1_video_streamon,\n\t.vidioc_streamoff\t\t= vb2_ioctl_streamoff,\n};\n\n \n\nstatic int vsp1_video_open(struct file *file)\n{\n\tstruct vsp1_video *video = video_drvdata(file);\n\tstruct v4l2_fh *vfh;\n\tint ret = 0;\n\n\tvfh = kzalloc(sizeof(*vfh), GFP_KERNEL);\n\tif (vfh == NULL)\n\t\treturn -ENOMEM;\n\n\tv4l2_fh_init(vfh, &video->video);\n\tv4l2_fh_add(vfh);\n\n\tfile->private_data = vfh;\n\n\tret = vsp1_device_get(video->vsp1);\n\tif (ret < 0) {\n\t\tv4l2_fh_del(vfh);\n\t\tv4l2_fh_exit(vfh);\n\t\tkfree(vfh);\n\t}\n\n\treturn ret;\n}\n\nstatic int vsp1_video_release(struct file *file)\n{\n\tstruct vsp1_video *video = video_drvdata(file);\n\n\tvb2_fop_release(file);\n\n\tvsp1_device_put(video->vsp1);\n\n\treturn 0;\n}\n\nstatic const struct v4l2_file_operations vsp1_video_fops = {\n\t.owner = THIS_MODULE,\n\t.unlocked_ioctl = video_ioctl2,\n\t.open = vsp1_video_open,\n\t.release = vsp1_video_release,\n\t.poll = vb2_fop_poll,\n\t.mmap = vb2_fop_mmap,\n};\n\n \n\nvoid vsp1_video_suspend(struct vsp1_device *vsp1)\n{\n\tunsigned long flags;\n\tunsigned int i;\n\tint ret;\n\n\t \n\tfor (i = 0; i < vsp1->info->wpf_count; ++i) {\n\t\tstruct vsp1_rwpf *wpf = vsp1->wpf[i];\n\t\tstruct vsp1_pipeline *pipe;\n\n\t\tif (wpf == NULL)\n\t\t\tcontinue;\n\n\t\tpipe = wpf->entity.pipe;\n\t\tif (pipe == NULL)\n\t\t\tcontinue;\n\n\t\tspin_lock_irqsave(&pipe->irqlock, flags);\n\t\tif (pipe->state == VSP1_PIPELINE_RUNNING)\n\t\t\tpipe->state = VSP1_PIPELINE_STOPPING;\n\t\tspin_unlock_irqrestore(&pipe->irqlock, flags);\n\t}\n\n\tfor (i = 0; i < vsp1->info->wpf_count; ++i) {\n\t\tstruct vsp1_rwpf *wpf = vsp1->wpf[i];\n\t\tstruct vsp1_pipeline *pipe;\n\n\t\tif (wpf == NULL)\n\t\t\tcontinue;\n\n\t\tpipe = wpf->entity.pipe;\n\t\tif (pipe == NULL)\n\t\t\tcontinue;\n\n\t\tret = wait_event_timeout(pipe->wq, vsp1_pipeline_stopped(pipe),\n\t\t\t\t\t msecs_to_jiffies(500));\n\t\tif (ret == 0)\n\t\t\tdev_warn(vsp1->dev, \"pipeline %u stop timeout\\n\",\n\t\t\t\t wpf->entity.index);\n\t}\n}\n\nvoid vsp1_video_resume(struct vsp1_device *vsp1)\n{\n\tunsigned long flags;\n\tunsigned int i;\n\n\t \n\tfor (i = 0; i < vsp1->info->wpf_count; ++i) {\n\t\tstruct vsp1_rwpf *wpf = vsp1->wpf[i];\n\t\tstruct vsp1_pipeline *pipe;\n\n\t\tif (wpf == NULL)\n\t\t\tcontinue;\n\n\t\tpipe = wpf->entity.pipe;\n\t\tif (pipe == NULL)\n\t\t\tcontinue;\n\n\t\t \n\t\tpipe->configured = false;\n\n\t\tspin_lock_irqsave(&pipe->irqlock, flags);\n\t\tif (vsp1_pipeline_ready(pipe))\n\t\t\tvsp1_video_pipeline_run(pipe);\n\t\tspin_unlock_irqrestore(&pipe->irqlock, flags);\n\t}\n}\n\n \n\nstruct vsp1_video *vsp1_video_create(struct vsp1_device *vsp1,\n\t\t\t\t     struct vsp1_rwpf *rwpf)\n{\n\tstruct vsp1_video *video;\n\tconst char *direction;\n\tint ret;\n\n\tvideo = devm_kzalloc(vsp1->dev, sizeof(*video), GFP_KERNEL);\n\tif (!video)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\trwpf->video = video;\n\n\tvideo->vsp1 = vsp1;\n\tvideo->rwpf = rwpf;\n\n\tif (rwpf->entity.type == VSP1_ENTITY_RPF) {\n\t\tdirection = \"input\";\n\t\tvideo->type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;\n\t\tvideo->pad.flags = MEDIA_PAD_FL_SOURCE;\n\t\tvideo->video.vfl_dir = VFL_DIR_TX;\n\t\tvideo->video.device_caps = V4L2_CAP_VIDEO_OUTPUT_MPLANE |\n\t\t\t\t\t   V4L2_CAP_STREAMING;\n\t} else {\n\t\tdirection = \"output\";\n\t\tvideo->type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;\n\t\tvideo->pad.flags = MEDIA_PAD_FL_SINK;\n\t\tvideo->video.vfl_dir = VFL_DIR_RX;\n\t\tvideo->video.device_caps = V4L2_CAP_VIDEO_CAPTURE_MPLANE |\n\t\t\t\t\t   V4L2_CAP_STREAMING;\n\t}\n\n\tmutex_init(&video->lock);\n\tspin_lock_init(&video->irqlock);\n\tINIT_LIST_HEAD(&video->irqqueue);\n\n\t \n\tret = media_entity_pads_init(&video->video.entity, 1, &video->pad);\n\tif (ret < 0)\n\t\treturn ERR_PTR(ret);\n\n\t \n\trwpf->format.pixelformat = VSP1_VIDEO_DEF_FORMAT;\n\trwpf->format.width = VSP1_VIDEO_DEF_WIDTH;\n\trwpf->format.height = VSP1_VIDEO_DEF_HEIGHT;\n\t__vsp1_video_try_format(video, &rwpf->format, &rwpf->fmtinfo);\n\n\t \n\tvideo->video.v4l2_dev = &video->vsp1->v4l2_dev;\n\tvideo->video.fops = &vsp1_video_fops;\n\tsnprintf(video->video.name, sizeof(video->video.name), \"%s %s\",\n\t\t rwpf->entity.subdev.name, direction);\n\tvideo->video.vfl_type = VFL_TYPE_VIDEO;\n\tvideo->video.release = video_device_release_empty;\n\tvideo->video.ioctl_ops = &vsp1_video_ioctl_ops;\n\n\tvideo_set_drvdata(&video->video, video);\n\n\tvideo->queue.type = video->type;\n\tvideo->queue.io_modes = VB2_MMAP | VB2_USERPTR | VB2_DMABUF;\n\tvideo->queue.lock = &video->lock;\n\tvideo->queue.drv_priv = video;\n\tvideo->queue.buf_struct_size = sizeof(struct vsp1_vb2_buffer);\n\tvideo->queue.ops = &vsp1_video_queue_qops;\n\tvideo->queue.mem_ops = &vb2_dma_contig_memops;\n\tvideo->queue.timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_COPY;\n\tvideo->queue.dev = video->vsp1->bus_master;\n\tret = vb2_queue_init(&video->queue);\n\tif (ret < 0) {\n\t\tdev_err(video->vsp1->dev, \"failed to initialize vb2 queue\\n\");\n\t\tgoto error;\n\t}\n\n\t \n\tvideo->video.queue = &video->queue;\n\tret = video_register_device(&video->video, VFL_TYPE_VIDEO, -1);\n\tif (ret < 0) {\n\t\tdev_err(video->vsp1->dev, \"failed to register video device\\n\");\n\t\tgoto error;\n\t}\n\n\treturn video;\n\nerror:\n\tvsp1_video_cleanup(video);\n\treturn ERR_PTR(ret);\n}\n\nvoid vsp1_video_cleanup(struct vsp1_video *video)\n{\n\tif (video_is_registered(&video->video))\n\t\tvideo_unregister_device(&video->video);\n\n\tmedia_entity_cleanup(&video->video.entity);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}