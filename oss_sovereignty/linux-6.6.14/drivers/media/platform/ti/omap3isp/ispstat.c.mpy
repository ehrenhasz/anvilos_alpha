{
  "module_name": "ispstat.c",
  "hash_id": "0244dec716b91675daeb85175e7b44aee0dd028d846d8e33eee3f0aa4056c2ba",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/platform/ti/omap3isp/ispstat.c",
  "human_readable_source": "\n \n\n#include <linux/dma-mapping.h>\n#include <linux/slab.h>\n#include <linux/timekeeping.h>\n#include <linux/uaccess.h>\n\n#include \"isp.h\"\n\n#define ISP_STAT_USES_DMAENGINE(stat)\t((stat)->dma_ch != NULL)\n\n \n#define MAGIC_SIZE\t\t16\n#define MAGIC_NUM\t\t0x55\n\n \n#define AF_EXTRA_DATA\t\tOMAP3ISP_AF_PAXEL_SIZE\n\n \n#define NUM_H3A_RECOVER_BUFS\t10\n\n \n#define IS_H3A_AF(stat)\t\t((stat) == &(stat)->isp->isp_af)\n#define IS_H3A_AEWB(stat)\t((stat) == &(stat)->isp->isp_aewb)\n#define IS_H3A(stat)\t\t(IS_H3A_AF(stat) || IS_H3A_AEWB(stat))\n\nstatic void __isp_stat_buf_sync_magic(struct ispstat *stat,\n\t\t\t\t      struct ispstat_buffer *buf,\n\t\t\t\t      u32 buf_size, enum dma_data_direction dir,\n\t\t\t\t      void (*dma_sync)(struct device *,\n\t\t\t\t\tdma_addr_t, unsigned long, size_t,\n\t\t\t\t\tenum dma_data_direction))\n{\n\t \n\tdma_sync(stat->isp->dev, buf->dma_addr, 0, MAGIC_SIZE, dir);\n\tdma_sync(stat->isp->dev, buf->dma_addr + (buf_size & PAGE_MASK),\n\t\t buf_size & ~PAGE_MASK, MAGIC_SIZE, dir);\n}\n\nstatic void isp_stat_buf_sync_magic_for_device(struct ispstat *stat,\n\t\t\t\t\t       struct ispstat_buffer *buf,\n\t\t\t\t\t       u32 buf_size,\n\t\t\t\t\t       enum dma_data_direction dir)\n{\n\tif (ISP_STAT_USES_DMAENGINE(stat))\n\t\treturn;\n\n\t__isp_stat_buf_sync_magic(stat, buf, buf_size, dir,\n\t\t\t\t  dma_sync_single_range_for_device);\n}\n\nstatic void isp_stat_buf_sync_magic_for_cpu(struct ispstat *stat,\n\t\t\t\t\t    struct ispstat_buffer *buf,\n\t\t\t\t\t    u32 buf_size,\n\t\t\t\t\t    enum dma_data_direction dir)\n{\n\tif (ISP_STAT_USES_DMAENGINE(stat))\n\t\treturn;\n\n\t__isp_stat_buf_sync_magic(stat, buf, buf_size, dir,\n\t\t\t\t  dma_sync_single_range_for_cpu);\n}\n\nstatic int isp_stat_buf_check_magic(struct ispstat *stat,\n\t\t\t\t    struct ispstat_buffer *buf)\n{\n\tconst u32 buf_size = IS_H3A_AF(stat) ?\n\t\t\t     buf->buf_size + AF_EXTRA_DATA : buf->buf_size;\n\tu8 *w;\n\tu8 *end;\n\tint ret = -EINVAL;\n\n\tisp_stat_buf_sync_magic_for_cpu(stat, buf, buf_size, DMA_FROM_DEVICE);\n\n\t \n\tfor (w = buf->virt_addr, end = w + MAGIC_SIZE; w < end; w++)\n\t\tif (likely(*w != MAGIC_NUM))\n\t\t\tret = 0;\n\n\tif (ret) {\n\t\tdev_dbg(stat->isp->dev,\n\t\t\t\"%s: beginning magic check does not match.\\n\",\n\t\t\tstat->subdev.name);\n\t\treturn ret;\n\t}\n\n\t \n\tfor (w = buf->virt_addr + buf_size, end = w + MAGIC_SIZE;\n\t     w < end; w++) {\n\t\tif (unlikely(*w != MAGIC_NUM)) {\n\t\t\tdev_dbg(stat->isp->dev,\n\t\t\t\t\"%s: ending magic check does not match.\\n\",\n\t\t\t\tstat->subdev.name);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tisp_stat_buf_sync_magic_for_device(stat, buf, buf_size,\n\t\t\t\t\t   DMA_FROM_DEVICE);\n\n\treturn 0;\n}\n\nstatic void isp_stat_buf_insert_magic(struct ispstat *stat,\n\t\t\t\t      struct ispstat_buffer *buf)\n{\n\tconst u32 buf_size = IS_H3A_AF(stat) ?\n\t\t\t     stat->buf_size + AF_EXTRA_DATA : stat->buf_size;\n\n\tisp_stat_buf_sync_magic_for_cpu(stat, buf, buf_size, DMA_FROM_DEVICE);\n\n\t \n\tmemset(buf->virt_addr, MAGIC_NUM, MAGIC_SIZE);\n\tmemset(buf->virt_addr + buf_size, MAGIC_NUM, MAGIC_SIZE);\n\n\tisp_stat_buf_sync_magic_for_device(stat, buf, buf_size,\n\t\t\t\t\t   DMA_BIDIRECTIONAL);\n}\n\nstatic void isp_stat_buf_sync_for_device(struct ispstat *stat,\n\t\t\t\t\t struct ispstat_buffer *buf)\n{\n\tif (ISP_STAT_USES_DMAENGINE(stat))\n\t\treturn;\n\n\tdma_sync_sg_for_device(stat->isp->dev, buf->sgt.sgl,\n\t\t\t       buf->sgt.nents, DMA_FROM_DEVICE);\n}\n\nstatic void isp_stat_buf_sync_for_cpu(struct ispstat *stat,\n\t\t\t\t      struct ispstat_buffer *buf)\n{\n\tif (ISP_STAT_USES_DMAENGINE(stat))\n\t\treturn;\n\n\tdma_sync_sg_for_cpu(stat->isp->dev, buf->sgt.sgl,\n\t\t\t    buf->sgt.nents, DMA_FROM_DEVICE);\n}\n\nstatic void isp_stat_buf_clear(struct ispstat *stat)\n{\n\tint i;\n\n\tfor (i = 0; i < STAT_MAX_BUFS; i++)\n\t\tstat->buf[i].empty = 1;\n}\n\nstatic struct ispstat_buffer *\n__isp_stat_buf_find(struct ispstat *stat, int look_empty)\n{\n\tstruct ispstat_buffer *found = NULL;\n\tint i;\n\n\tfor (i = 0; i < STAT_MAX_BUFS; i++) {\n\t\tstruct ispstat_buffer *curr = &stat->buf[i];\n\n\t\t \n\t\tif (curr == stat->locked_buf || curr == stat->active_buf)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (!look_empty && curr->empty)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (curr->empty) {\n\t\t\tfound = curr;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (!found ||\n\t\t    (s32)curr->frame_number - (s32)found->frame_number < 0)\n\t\t\tfound = curr;\n\t}\n\n\treturn found;\n}\n\nstatic inline struct ispstat_buffer *\nisp_stat_buf_find_oldest(struct ispstat *stat)\n{\n\treturn __isp_stat_buf_find(stat, 0);\n}\n\nstatic inline struct ispstat_buffer *\nisp_stat_buf_find_oldest_or_empty(struct ispstat *stat)\n{\n\treturn __isp_stat_buf_find(stat, 1);\n}\n\nstatic int isp_stat_buf_queue(struct ispstat *stat)\n{\n\tif (!stat->active_buf)\n\t\treturn STAT_NO_BUF;\n\n\tktime_get_ts64(&stat->active_buf->ts);\n\n\tstat->active_buf->buf_size = stat->buf_size;\n\tif (isp_stat_buf_check_magic(stat, stat->active_buf)) {\n\t\tdev_dbg(stat->isp->dev, \"%s: data wasn't properly written.\\n\",\n\t\t\tstat->subdev.name);\n\t\treturn STAT_NO_BUF;\n\t}\n\tstat->active_buf->config_counter = stat->config_counter;\n\tstat->active_buf->frame_number = stat->frame_number;\n\tstat->active_buf->empty = 0;\n\tstat->active_buf = NULL;\n\n\treturn STAT_BUF_DONE;\n}\n\n \nstatic void isp_stat_buf_next(struct ispstat *stat)\n{\n\tif (unlikely(stat->active_buf))\n\t\t \n\t\tdev_dbg(stat->isp->dev,\n\t\t\t\"%s: new buffer requested without queuing active one.\\n\",\n\t\t\tstat->subdev.name);\n\telse\n\t\tstat->active_buf = isp_stat_buf_find_oldest_or_empty(stat);\n}\n\nstatic void isp_stat_buf_release(struct ispstat *stat)\n{\n\tunsigned long flags;\n\n\tisp_stat_buf_sync_for_device(stat, stat->locked_buf);\n\tspin_lock_irqsave(&stat->isp->stat_lock, flags);\n\tstat->locked_buf = NULL;\n\tspin_unlock_irqrestore(&stat->isp->stat_lock, flags);\n}\n\n \nstatic struct ispstat_buffer *isp_stat_buf_get(struct ispstat *stat,\n\t\t\t\t\t       struct omap3isp_stat_data *data)\n{\n\tint rval = 0;\n\tunsigned long flags;\n\tstruct ispstat_buffer *buf;\n\n\tspin_lock_irqsave(&stat->isp->stat_lock, flags);\n\n\twhile (1) {\n\t\tbuf = isp_stat_buf_find_oldest(stat);\n\t\tif (!buf) {\n\t\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, flags);\n\t\t\tdev_dbg(stat->isp->dev, \"%s: cannot find a buffer.\\n\",\n\t\t\t\tstat->subdev.name);\n\t\t\treturn ERR_PTR(-EBUSY);\n\t\t}\n\t\tif (isp_stat_buf_check_magic(stat, buf)) {\n\t\t\tdev_dbg(stat->isp->dev,\n\t\t\t\t\"%s: current buffer has corrupted data\\n.\",\n\t\t\t\tstat->subdev.name);\n\t\t\t \n\t\t\tbuf->empty = 1;\n\t\t} else {\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\t}\n\n\tstat->locked_buf = buf;\n\n\tspin_unlock_irqrestore(&stat->isp->stat_lock, flags);\n\n\tif (buf->buf_size > data->buf_size) {\n\t\tdev_warn(stat->isp->dev,\n\t\t\t \"%s: userspace's buffer size is not enough.\\n\",\n\t\t\t stat->subdev.name);\n\t\tisp_stat_buf_release(stat);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tisp_stat_buf_sync_for_cpu(stat, buf);\n\n\trval = copy_to_user(data->buf,\n\t\t\t    buf->virt_addr,\n\t\t\t    buf->buf_size);\n\n\tif (rval) {\n\t\tdev_info(stat->isp->dev,\n\t\t\t \"%s: failed copying %d bytes of stat data\\n\",\n\t\t\t stat->subdev.name, rval);\n\t\tbuf = ERR_PTR(-EFAULT);\n\t\tisp_stat_buf_release(stat);\n\t}\n\n\treturn buf;\n}\n\nstatic void isp_stat_bufs_free(struct ispstat *stat)\n{\n\tstruct device *dev = ISP_STAT_USES_DMAENGINE(stat)\n\t\t\t   ? NULL : stat->isp->dev;\n\tunsigned int i;\n\n\tfor (i = 0; i < STAT_MAX_BUFS; i++) {\n\t\tstruct ispstat_buffer *buf = &stat->buf[i];\n\n\t\tif (!buf->virt_addr)\n\t\t\tcontinue;\n\n\t\tsg_free_table(&buf->sgt);\n\n\t\tdma_free_coherent(dev, stat->buf_alloc_size, buf->virt_addr,\n\t\t\t\t  buf->dma_addr);\n\n\t\tbuf->dma_addr = 0;\n\t\tbuf->virt_addr = NULL;\n\t\tbuf->empty = 1;\n\t}\n\n\tdev_dbg(stat->isp->dev, \"%s: all buffers were freed.\\n\",\n\t\tstat->subdev.name);\n\n\tstat->buf_alloc_size = 0;\n\tstat->active_buf = NULL;\n}\n\nstatic int isp_stat_bufs_alloc_one(struct device *dev,\n\t\t\t\t   struct ispstat_buffer *buf,\n\t\t\t\t   unsigned int size)\n{\n\tint ret;\n\n\tbuf->virt_addr = dma_alloc_coherent(dev, size, &buf->dma_addr,\n\t\t\t\t\t    GFP_KERNEL);\n\tif (!buf->virt_addr)\n\t\treturn -ENOMEM;\n\n\tret = dma_get_sgtable(dev, &buf->sgt, buf->virt_addr, buf->dma_addr,\n\t\t\t      size);\n\tif (ret < 0) {\n\t\tdma_free_coherent(dev, size, buf->virt_addr, buf->dma_addr);\n\t\tbuf->virt_addr = NULL;\n\t\tbuf->dma_addr = 0;\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int isp_stat_bufs_alloc(struct ispstat *stat, u32 size)\n{\n\tstruct device *dev = ISP_STAT_USES_DMAENGINE(stat)\n\t\t\t   ? NULL : stat->isp->dev;\n\tunsigned long flags;\n\tunsigned int i;\n\n\tspin_lock_irqsave(&stat->isp->stat_lock, flags);\n\n\tBUG_ON(stat->locked_buf != NULL);\n\n\t \n\tif (stat->buf_alloc_size >= size) {\n\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, flags);\n\t\treturn 0;\n\t}\n\n\tif (stat->state != ISPSTAT_DISABLED || stat->buf_processing) {\n\t\tdev_info(stat->isp->dev,\n\t\t\t \"%s: trying to allocate memory when busy\\n\",\n\t\t\t stat->subdev.name);\n\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, flags);\n\t\treturn -EBUSY;\n\t}\n\n\tspin_unlock_irqrestore(&stat->isp->stat_lock, flags);\n\n\tisp_stat_bufs_free(stat);\n\n\tstat->buf_alloc_size = size;\n\n\tfor (i = 0; i < STAT_MAX_BUFS; i++) {\n\t\tstruct ispstat_buffer *buf = &stat->buf[i];\n\t\tint ret;\n\n\t\tret = isp_stat_bufs_alloc_one(dev, buf, size);\n\t\tif (ret < 0) {\n\t\t\tdev_err(stat->isp->dev,\n\t\t\t\t\"%s: Failed to allocate DMA buffer %u\\n\",\n\t\t\t\tstat->subdev.name, i);\n\t\t\tisp_stat_bufs_free(stat);\n\t\t\treturn ret;\n\t\t}\n\n\t\tbuf->empty = 1;\n\n\t\tdev_dbg(stat->isp->dev,\n\t\t\t\"%s: buffer[%u] allocated. dma=%pad virt=%p\",\n\t\t\tstat->subdev.name, i, &buf->dma_addr, buf->virt_addr);\n\t}\n\n\treturn 0;\n}\n\nstatic void isp_stat_queue_event(struct ispstat *stat, int err)\n{\n\tstruct video_device *vdev = stat->subdev.devnode;\n\tstruct v4l2_event event;\n\tstruct omap3isp_stat_event_status *status = (void *)event.u.data;\n\n\tmemset(&event, 0, sizeof(event));\n\tif (!err) {\n\t\tstatus->frame_number = stat->frame_number;\n\t\tstatus->config_counter = stat->config_counter;\n\t} else {\n\t\tstatus->buf_err = 1;\n\t}\n\tevent.type = stat->event_type;\n\tv4l2_event_queue(vdev, &event);\n}\n\n\n \nint omap3isp_stat_request_statistics(struct ispstat *stat,\n\t\t\t\t     struct omap3isp_stat_data *data)\n{\n\tstruct ispstat_buffer *buf;\n\n\tif (stat->state != ISPSTAT_ENABLED) {\n\t\tdev_dbg(stat->isp->dev, \"%s: engine not enabled.\\n\",\n\t\t\tstat->subdev.name);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_lock(&stat->ioctl_lock);\n\tbuf = isp_stat_buf_get(stat, data);\n\tif (IS_ERR(buf)) {\n\t\tmutex_unlock(&stat->ioctl_lock);\n\t\treturn PTR_ERR(buf);\n\t}\n\n\tdata->ts.tv_sec = buf->ts.tv_sec;\n\tdata->ts.tv_usec = buf->ts.tv_nsec / NSEC_PER_USEC;\n\tdata->config_counter = buf->config_counter;\n\tdata->frame_number = buf->frame_number;\n\tdata->buf_size = buf->buf_size;\n\n\tbuf->empty = 1;\n\tisp_stat_buf_release(stat);\n\tmutex_unlock(&stat->ioctl_lock);\n\n\treturn 0;\n}\n\nint omap3isp_stat_request_statistics_time32(struct ispstat *stat,\n\t\t\t\t\tstruct omap3isp_stat_data_time32 *data)\n{\n\tstruct omap3isp_stat_data data64 = { };\n\tint ret;\n\n\tret = omap3isp_stat_request_statistics(stat, &data64);\n\tif (ret)\n\t\treturn ret;\n\n\tdata->ts.tv_sec = data64.ts.tv_sec;\n\tdata->ts.tv_usec = data64.ts.tv_usec;\n\tdata->buf = (uintptr_t)data64.buf;\n\tmemcpy(&data->frame, &data64.frame, sizeof(data->frame));\n\n\treturn 0;\n}\n\n \nint omap3isp_stat_config(struct ispstat *stat, void *new_conf)\n{\n\tint ret;\n\tunsigned long irqflags;\n\tstruct ispstat_generic_config *user_cfg = new_conf;\n\tu32 buf_size = user_cfg->buf_size;\n\n\tmutex_lock(&stat->ioctl_lock);\n\n\tdev_dbg(stat->isp->dev,\n\t\t\"%s: configuring module with buffer size=0x%08lx\\n\",\n\t\tstat->subdev.name, (unsigned long)buf_size);\n\n\tret = stat->ops->validate_params(stat, new_conf);\n\tif (ret) {\n\t\tmutex_unlock(&stat->ioctl_lock);\n\t\tdev_dbg(stat->isp->dev, \"%s: configuration values are invalid.\\n\",\n\t\t\tstat->subdev.name);\n\t\treturn ret;\n\t}\n\n\tif (buf_size != user_cfg->buf_size)\n\t\tdev_dbg(stat->isp->dev,\n\t\t\t\"%s: driver has corrected buffer size request to 0x%08lx\\n\",\n\t\t\tstat->subdev.name,\n\t\t\t(unsigned long)user_cfg->buf_size);\n\n\t \n\tif (IS_H3A(stat)) {\n\t\tbuf_size = user_cfg->buf_size * 2 + MAGIC_SIZE;\n\t\tif (IS_H3A_AF(stat))\n\t\t\t \n\t\t\tbuf_size += AF_EXTRA_DATA * (NUM_H3A_RECOVER_BUFS + 2);\n\t\tif (stat->recover_priv) {\n\t\t\tstruct ispstat_generic_config *recover_cfg =\n\t\t\t\tstat->recover_priv;\n\t\t\tbuf_size += recover_cfg->buf_size *\n\t\t\t\t    NUM_H3A_RECOVER_BUFS;\n\t\t}\n\t\tbuf_size = PAGE_ALIGN(buf_size);\n\t} else {  \n\t\tbuf_size = PAGE_ALIGN(user_cfg->buf_size + MAGIC_SIZE);\n\t}\n\n\tret = isp_stat_bufs_alloc(stat, buf_size);\n\tif (ret) {\n\t\tmutex_unlock(&stat->ioctl_lock);\n\t\treturn ret;\n\t}\n\n\tspin_lock_irqsave(&stat->isp->stat_lock, irqflags);\n\tstat->ops->set_params(stat, new_conf);\n\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\n\t \n\tuser_cfg->config_counter = stat->config_counter + stat->inc_config;\n\n\t \n\tstat->configured = 1;\n\tdev_dbg(stat->isp->dev,\n\t\t\"%s: module has been successfully configured.\\n\",\n\t\tstat->subdev.name);\n\n\tmutex_unlock(&stat->ioctl_lock);\n\n\treturn 0;\n}\n\n \nstatic int isp_stat_buf_process(struct ispstat *stat, int buf_state)\n{\n\tint ret = STAT_NO_BUF;\n\n\tif (!atomic_add_unless(&stat->buf_err, -1, 0) &&\n\t    buf_state == STAT_BUF_DONE && stat->state == ISPSTAT_ENABLED) {\n\t\tret = isp_stat_buf_queue(stat);\n\t\tisp_stat_buf_next(stat);\n\t}\n\n\treturn ret;\n}\n\nint omap3isp_stat_pcr_busy(struct ispstat *stat)\n{\n\treturn stat->ops->busy(stat);\n}\n\nint omap3isp_stat_busy(struct ispstat *stat)\n{\n\treturn omap3isp_stat_pcr_busy(stat) | stat->buf_processing |\n\t\t(stat->state != ISPSTAT_DISABLED);\n}\n\n \nstatic void isp_stat_pcr_enable(struct ispstat *stat, u8 pcr_enable)\n{\n\tif ((stat->state != ISPSTAT_ENABLING &&\n\t     stat->state != ISPSTAT_ENABLED) && pcr_enable)\n\t\t \n\t\treturn;\n\n\tstat->ops->enable(stat, pcr_enable);\n\tif (stat->state == ISPSTAT_DISABLING && !pcr_enable)\n\t\tstat->state = ISPSTAT_DISABLED;\n\telse if (stat->state == ISPSTAT_ENABLING && pcr_enable)\n\t\tstat->state = ISPSTAT_ENABLED;\n}\n\nvoid omap3isp_stat_suspend(struct ispstat *stat)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&stat->isp->stat_lock, flags);\n\n\tif (stat->state != ISPSTAT_DISABLED)\n\t\tstat->ops->enable(stat, 0);\n\tif (stat->state == ISPSTAT_ENABLED)\n\t\tstat->state = ISPSTAT_SUSPENDED;\n\n\tspin_unlock_irqrestore(&stat->isp->stat_lock, flags);\n}\n\nvoid omap3isp_stat_resume(struct ispstat *stat)\n{\n\t \n\tif (stat->state == ISPSTAT_SUSPENDED)\n\t\tstat->state = ISPSTAT_ENABLING;\n}\n\nstatic void isp_stat_try_enable(struct ispstat *stat)\n{\n\tunsigned long irqflags;\n\n\tif (stat->priv == NULL)\n\t\t \n\t\treturn;\n\n\tspin_lock_irqsave(&stat->isp->stat_lock, irqflags);\n\tif (stat->state == ISPSTAT_ENABLING && !stat->buf_processing &&\n\t    stat->buf_alloc_size) {\n\t\t \n\t\tstat->update = 1;\n\t\tisp_stat_buf_next(stat);\n\t\tstat->ops->setup_regs(stat, stat->priv);\n\t\tisp_stat_buf_insert_magic(stat, stat->active_buf);\n\n\t\t \n\t\tif (!IS_H3A(stat))\n\t\t\tatomic_set(&stat->buf_err, 0);\n\n\t\tisp_stat_pcr_enable(stat, 1);\n\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\t\tdev_dbg(stat->isp->dev, \"%s: module is enabled.\\n\",\n\t\t\tstat->subdev.name);\n\t} else {\n\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\t}\n}\n\nvoid omap3isp_stat_isr_frame_sync(struct ispstat *stat)\n{\n\tisp_stat_try_enable(stat);\n}\n\nvoid omap3isp_stat_sbl_overflow(struct ispstat *stat)\n{\n\tunsigned long irqflags;\n\n\tspin_lock_irqsave(&stat->isp->stat_lock, irqflags);\n\t \n\tatomic_set(&stat->buf_err, 2);\n\n\t \n\tif (stat->recover_priv)\n\t\tstat->sbl_ovl_recover = 1;\n\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n}\n\n \nint omap3isp_stat_enable(struct ispstat *stat, u8 enable)\n{\n\tunsigned long irqflags;\n\n\tdev_dbg(stat->isp->dev, \"%s: user wants to %s module.\\n\",\n\t\tstat->subdev.name, enable ? \"enable\" : \"disable\");\n\n\t \n\tmutex_lock(&stat->ioctl_lock);\n\n\tspin_lock_irqsave(&stat->isp->stat_lock, irqflags);\n\n\tif (!stat->configured && enable) {\n\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\t\tmutex_unlock(&stat->ioctl_lock);\n\t\tdev_dbg(stat->isp->dev,\n\t\t\t\"%s: cannot enable module as it's never been successfully configured so far.\\n\",\n\t\t\tstat->subdev.name);\n\t\treturn -EINVAL;\n\t}\n\n\tif (enable) {\n\t\tif (stat->state == ISPSTAT_DISABLING)\n\t\t\t \n\t\t\tstat->state = ISPSTAT_ENABLED;\n\t\telse if (stat->state == ISPSTAT_DISABLED)\n\t\t\t \n\t\t\tstat->state = ISPSTAT_ENABLING;\n\t} else {\n\t\tif (stat->state == ISPSTAT_ENABLING) {\n\t\t\t \n\t\t\tstat->state = ISPSTAT_DISABLED;\n\t\t} else if (stat->state == ISPSTAT_ENABLED) {\n\t\t\t \n\t\t\tstat->state = ISPSTAT_DISABLING;\n\t\t\tisp_stat_buf_clear(stat);\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\tmutex_unlock(&stat->ioctl_lock);\n\n\treturn 0;\n}\n\nint omap3isp_stat_s_stream(struct v4l2_subdev *subdev, int enable)\n{\n\tstruct ispstat *stat = v4l2_get_subdevdata(subdev);\n\n\tif (enable) {\n\t\t \n\t\tisp_stat_try_enable(stat);\n\t} else {\n\t\tunsigned long flags;\n\t\t \n\t\tomap3isp_stat_enable(stat, 0);\n\t\tspin_lock_irqsave(&stat->isp->stat_lock, flags);\n\t\tstat->ops->enable(stat, 0);\n\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, flags);\n\n\t\t \n\t\tif (!omap3isp_stat_pcr_busy(stat))\n\t\t\tomap3isp_stat_isr(stat);\n\n\t\tdev_dbg(stat->isp->dev, \"%s: module is being disabled\\n\",\n\t\t\tstat->subdev.name);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void __stat_isr(struct ispstat *stat, int from_dma)\n{\n\tint ret = STAT_BUF_DONE;\n\tint buf_processing;\n\tunsigned long irqflags;\n\tstruct isp_pipeline *pipe;\n\n\t \n\tspin_lock_irqsave(&stat->isp->stat_lock, irqflags);\n\tif (stat->state == ISPSTAT_DISABLED) {\n\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\t\treturn;\n\t}\n\tbuf_processing = stat->buf_processing;\n\tstat->buf_processing = 1;\n\tstat->ops->enable(stat, 0);\n\n\tif (buf_processing && !from_dma) {\n\t\tif (stat->state == ISPSTAT_ENABLED) {\n\t\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\t\t\tdev_err(stat->isp->dev,\n\t\t\t\t\"%s: interrupt occurred when module was still processing a buffer.\\n\",\n\t\t\t\tstat->subdev.name);\n\t\t\tret = STAT_NO_BUF;\n\t\t\tgoto out;\n\t\t} else {\n\t\t\t \n\t\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\t\t\treturn;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\n\t \n\tif (!omap3isp_stat_pcr_busy(stat)) {\n\t\tif (!from_dma && stat->ops->buf_process)\n\t\t\t \n\t\t\tret = stat->ops->buf_process(stat);\n\t\tif (ret == STAT_BUF_WAITING_DMA)\n\t\t\t \n\t\t\treturn;\n\n\t\tspin_lock_irqsave(&stat->isp->stat_lock, irqflags);\n\n\t\t \n\t\tif (stat->state == ISPSTAT_DISABLING) {\n\t\t\tstat->state = ISPSTAT_DISABLED;\n\t\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\t\t\tstat->buf_processing = 0;\n\t\t\treturn;\n\t\t}\n\t\tpipe = to_isp_pipeline(&stat->subdev.entity);\n\t\tstat->frame_number = atomic_read(&pipe->frame_number);\n\n\t\t \n\t\tret = isp_stat_buf_process(stat, ret);\n\n\t\tif (likely(!stat->sbl_ovl_recover)) {\n\t\t\tstat->ops->setup_regs(stat, stat->priv);\n\t\t} else {\n\t\t\t \n\t\t\tstat->update = 1;\n\t\t\tstat->ops->setup_regs(stat, stat->recover_priv);\n\t\t\tstat->sbl_ovl_recover = 0;\n\n\t\t\t \n\t\t\tstat->update = 1;\n\t\t}\n\n\t\tisp_stat_buf_insert_magic(stat, stat->active_buf);\n\n\t\t \n\t\tisp_stat_pcr_enable(stat, 1);\n\t\tspin_unlock_irqrestore(&stat->isp->stat_lock, irqflags);\n\t} else {\n\t\t \n\n\t\tif (stat->ops->buf_process)\n\t\t\t \n\t\t\tatomic_set(&stat->buf_err, 1);\n\n\t\tret = STAT_NO_BUF;\n\t\tdev_dbg(stat->isp->dev,\n\t\t\t\"%s: cannot process buffer, device is busy.\\n\",\n\t\t\tstat->subdev.name);\n\t}\n\nout:\n\tstat->buf_processing = 0;\n\tisp_stat_queue_event(stat, ret != STAT_BUF_DONE);\n}\n\nvoid omap3isp_stat_isr(struct ispstat *stat)\n{\n\t__stat_isr(stat, 0);\n}\n\nvoid omap3isp_stat_dma_isr(struct ispstat *stat)\n{\n\t__stat_isr(stat, 1);\n}\n\nint omap3isp_stat_subscribe_event(struct v4l2_subdev *subdev,\n\t\t\t\t  struct v4l2_fh *fh,\n\t\t\t\t  struct v4l2_event_subscription *sub)\n{\n\tstruct ispstat *stat = v4l2_get_subdevdata(subdev);\n\n\tif (sub->type != stat->event_type)\n\t\treturn -EINVAL;\n\n\treturn v4l2_event_subscribe(fh, sub, STAT_NEVENTS, NULL);\n}\n\nint omap3isp_stat_unsubscribe_event(struct v4l2_subdev *subdev,\n\t\t\t\t    struct v4l2_fh *fh,\n\t\t\t\t    struct v4l2_event_subscription *sub)\n{\n\treturn v4l2_event_unsubscribe(fh, sub);\n}\n\nvoid omap3isp_stat_unregister_entities(struct ispstat *stat)\n{\n\tv4l2_device_unregister_subdev(&stat->subdev);\n}\n\nint omap3isp_stat_register_entities(struct ispstat *stat,\n\t\t\t\t    struct v4l2_device *vdev)\n{\n\tstat->subdev.dev = vdev->mdev->dev;\n\n\treturn v4l2_device_register_subdev(vdev, &stat->subdev);\n}\n\nstatic int isp_stat_init_entities(struct ispstat *stat, const char *name,\n\t\t\t\t  const struct v4l2_subdev_ops *sd_ops)\n{\n\tstruct v4l2_subdev *subdev = &stat->subdev;\n\tstruct media_entity *me = &subdev->entity;\n\n\tv4l2_subdev_init(subdev, sd_ops);\n\tsnprintf(subdev->name, V4L2_SUBDEV_NAME_SIZE, \"OMAP3 ISP %s\", name);\n\tsubdev->grp_id = BIT(16);\t \n\tsubdev->flags |= V4L2_SUBDEV_FL_HAS_EVENTS | V4L2_SUBDEV_FL_HAS_DEVNODE;\n\tv4l2_set_subdevdata(subdev, stat);\n\n\tstat->pad.flags = MEDIA_PAD_FL_SINK | MEDIA_PAD_FL_MUST_CONNECT;\n\tme->ops = NULL;\n\n\treturn media_entity_pads_init(me, 1, &stat->pad);\n}\n\nint omap3isp_stat_init(struct ispstat *stat, const char *name,\n\t\t       const struct v4l2_subdev_ops *sd_ops)\n{\n\tint ret;\n\n\tstat->buf = kcalloc(STAT_MAX_BUFS, sizeof(*stat->buf), GFP_KERNEL);\n\tif (!stat->buf)\n\t\treturn -ENOMEM;\n\n\tisp_stat_buf_clear(stat);\n\tmutex_init(&stat->ioctl_lock);\n\tatomic_set(&stat->buf_err, 0);\n\n\tret = isp_stat_init_entities(stat, name, sd_ops);\n\tif (ret < 0) {\n\t\tmutex_destroy(&stat->ioctl_lock);\n\t\tkfree(stat->buf);\n\t}\n\n\treturn ret;\n}\n\nvoid omap3isp_stat_cleanup(struct ispstat *stat)\n{\n\tmedia_entity_cleanup(&stat->subdev.entity);\n\tmutex_destroy(&stat->ioctl_lock);\n\tisp_stat_bufs_free(stat);\n\tkfree(stat->buf);\n\tkfree(stat->priv);\n\tkfree(stat->recover_priv);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}