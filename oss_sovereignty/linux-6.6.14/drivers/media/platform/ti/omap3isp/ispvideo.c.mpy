{
  "module_name": "ispvideo.c",
  "hash_id": "b84a1b624c63ea9f2a7551aba0000c3d589d3e47a93032e3baeeda671421d512",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/platform/ti/omap3isp/ispvideo.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/pagemap.h>\n#include <linux/scatterlist.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n\n#include <media/v4l2-dev.h>\n#include <media/v4l2-ioctl.h>\n#include <media/v4l2-mc.h>\n#include <media/videobuf2-dma-contig.h>\n\n#include \"ispvideo.h\"\n#include \"isp.h\"\n\n\n \n\n \nstatic struct isp_format_info formats[] = {\n\t{ MEDIA_BUS_FMT_Y8_1X8, MEDIA_BUS_FMT_Y8_1X8,\n\t  MEDIA_BUS_FMT_Y8_1X8, MEDIA_BUS_FMT_Y8_1X8,\n\t  V4L2_PIX_FMT_GREY, 8, 1, },\n\t{ MEDIA_BUS_FMT_Y10_1X10, MEDIA_BUS_FMT_Y10_1X10,\n\t  MEDIA_BUS_FMT_Y10_1X10, MEDIA_BUS_FMT_Y8_1X8,\n\t  V4L2_PIX_FMT_Y10, 10, 2, },\n\t{ MEDIA_BUS_FMT_Y12_1X12, MEDIA_BUS_FMT_Y10_1X10,\n\t  MEDIA_BUS_FMT_Y12_1X12, MEDIA_BUS_FMT_Y8_1X8,\n\t  V4L2_PIX_FMT_Y12, 12, 2, },\n\t{ MEDIA_BUS_FMT_SBGGR8_1X8, MEDIA_BUS_FMT_SBGGR8_1X8,\n\t  MEDIA_BUS_FMT_SBGGR8_1X8, MEDIA_BUS_FMT_SBGGR8_1X8,\n\t  V4L2_PIX_FMT_SBGGR8, 8, 1, },\n\t{ MEDIA_BUS_FMT_SGBRG8_1X8, MEDIA_BUS_FMT_SGBRG8_1X8,\n\t  MEDIA_BUS_FMT_SGBRG8_1X8, MEDIA_BUS_FMT_SGBRG8_1X8,\n\t  V4L2_PIX_FMT_SGBRG8, 8, 1, },\n\t{ MEDIA_BUS_FMT_SGRBG8_1X8, MEDIA_BUS_FMT_SGRBG8_1X8,\n\t  MEDIA_BUS_FMT_SGRBG8_1X8, MEDIA_BUS_FMT_SGRBG8_1X8,\n\t  V4L2_PIX_FMT_SGRBG8, 8, 1, },\n\t{ MEDIA_BUS_FMT_SRGGB8_1X8, MEDIA_BUS_FMT_SRGGB8_1X8,\n\t  MEDIA_BUS_FMT_SRGGB8_1X8, MEDIA_BUS_FMT_SRGGB8_1X8,\n\t  V4L2_PIX_FMT_SRGGB8, 8, 1, },\n\t{ MEDIA_BUS_FMT_SBGGR10_DPCM8_1X8, MEDIA_BUS_FMT_SBGGR10_DPCM8_1X8,\n\t  MEDIA_BUS_FMT_SBGGR10_1X10, 0,\n\t  V4L2_PIX_FMT_SBGGR10DPCM8, 8, 1, },\n\t{ MEDIA_BUS_FMT_SGBRG10_DPCM8_1X8, MEDIA_BUS_FMT_SGBRG10_DPCM8_1X8,\n\t  MEDIA_BUS_FMT_SGBRG10_1X10, 0,\n\t  V4L2_PIX_FMT_SGBRG10DPCM8, 8, 1, },\n\t{ MEDIA_BUS_FMT_SGRBG10_DPCM8_1X8, MEDIA_BUS_FMT_SGRBG10_DPCM8_1X8,\n\t  MEDIA_BUS_FMT_SGRBG10_1X10, 0,\n\t  V4L2_PIX_FMT_SGRBG10DPCM8, 8, 1, },\n\t{ MEDIA_BUS_FMT_SRGGB10_DPCM8_1X8, MEDIA_BUS_FMT_SRGGB10_DPCM8_1X8,\n\t  MEDIA_BUS_FMT_SRGGB10_1X10, 0,\n\t  V4L2_PIX_FMT_SRGGB10DPCM8, 8, 1, },\n\t{ MEDIA_BUS_FMT_SBGGR10_1X10, MEDIA_BUS_FMT_SBGGR10_1X10,\n\t  MEDIA_BUS_FMT_SBGGR10_1X10, MEDIA_BUS_FMT_SBGGR8_1X8,\n\t  V4L2_PIX_FMT_SBGGR10, 10, 2, },\n\t{ MEDIA_BUS_FMT_SGBRG10_1X10, MEDIA_BUS_FMT_SGBRG10_1X10,\n\t  MEDIA_BUS_FMT_SGBRG10_1X10, MEDIA_BUS_FMT_SGBRG8_1X8,\n\t  V4L2_PIX_FMT_SGBRG10, 10, 2, },\n\t{ MEDIA_BUS_FMT_SGRBG10_1X10, MEDIA_BUS_FMT_SGRBG10_1X10,\n\t  MEDIA_BUS_FMT_SGRBG10_1X10, MEDIA_BUS_FMT_SGRBG8_1X8,\n\t  V4L2_PIX_FMT_SGRBG10, 10, 2, },\n\t{ MEDIA_BUS_FMT_SRGGB10_1X10, MEDIA_BUS_FMT_SRGGB10_1X10,\n\t  MEDIA_BUS_FMT_SRGGB10_1X10, MEDIA_BUS_FMT_SRGGB8_1X8,\n\t  V4L2_PIX_FMT_SRGGB10, 10, 2, },\n\t{ MEDIA_BUS_FMT_SBGGR12_1X12, MEDIA_BUS_FMT_SBGGR10_1X10,\n\t  MEDIA_BUS_FMT_SBGGR12_1X12, MEDIA_BUS_FMT_SBGGR8_1X8,\n\t  V4L2_PIX_FMT_SBGGR12, 12, 2, },\n\t{ MEDIA_BUS_FMT_SGBRG12_1X12, MEDIA_BUS_FMT_SGBRG10_1X10,\n\t  MEDIA_BUS_FMT_SGBRG12_1X12, MEDIA_BUS_FMT_SGBRG8_1X8,\n\t  V4L2_PIX_FMT_SGBRG12, 12, 2, },\n\t{ MEDIA_BUS_FMT_SGRBG12_1X12, MEDIA_BUS_FMT_SGRBG10_1X10,\n\t  MEDIA_BUS_FMT_SGRBG12_1X12, MEDIA_BUS_FMT_SGRBG8_1X8,\n\t  V4L2_PIX_FMT_SGRBG12, 12, 2, },\n\t{ MEDIA_BUS_FMT_SRGGB12_1X12, MEDIA_BUS_FMT_SRGGB10_1X10,\n\t  MEDIA_BUS_FMT_SRGGB12_1X12, MEDIA_BUS_FMT_SRGGB8_1X8,\n\t  V4L2_PIX_FMT_SRGGB12, 12, 2, },\n\t{ MEDIA_BUS_FMT_UYVY8_1X16, MEDIA_BUS_FMT_UYVY8_1X16,\n\t  MEDIA_BUS_FMT_UYVY8_1X16, 0,\n\t  V4L2_PIX_FMT_UYVY, 16, 2, },\n\t{ MEDIA_BUS_FMT_YUYV8_1X16, MEDIA_BUS_FMT_YUYV8_1X16,\n\t  MEDIA_BUS_FMT_YUYV8_1X16, 0,\n\t  V4L2_PIX_FMT_YUYV, 16, 2, },\n\t{ MEDIA_BUS_FMT_UYVY8_2X8, MEDIA_BUS_FMT_UYVY8_2X8,\n\t  MEDIA_BUS_FMT_UYVY8_2X8, 0,\n\t  V4L2_PIX_FMT_UYVY, 8, 2, },\n\t{ MEDIA_BUS_FMT_YUYV8_2X8, MEDIA_BUS_FMT_YUYV8_2X8,\n\t  MEDIA_BUS_FMT_YUYV8_2X8, 0,\n\t  V4L2_PIX_FMT_YUYV, 8, 2, },\n\t \n\t{ 0, }\n};\n\nconst struct isp_format_info *omap3isp_video_format_info(u32 code)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < ARRAY_SIZE(formats); ++i) {\n\t\tif (formats[i].code == code)\n\t\t\treturn &formats[i];\n\t}\n\n\treturn NULL;\n}\n\n \nstatic unsigned int isp_video_mbus_to_pix(const struct isp_video *video,\n\t\t\t\t\t  const struct v4l2_mbus_framefmt *mbus,\n\t\t\t\t\t  struct v4l2_pix_format *pix)\n{\n\tunsigned int bpl = pix->bytesperline;\n\tunsigned int min_bpl;\n\tunsigned int i;\n\n\tmemset(pix, 0, sizeof(*pix));\n\tpix->width = mbus->width;\n\tpix->height = mbus->height;\n\n\tfor (i = 0; i < ARRAY_SIZE(formats); ++i) {\n\t\tif (formats[i].code == mbus->code)\n\t\t\tbreak;\n\t}\n\n\tif (WARN_ON(i == ARRAY_SIZE(formats)))\n\t\treturn 0;\n\n\tmin_bpl = pix->width * formats[i].bpp;\n\n\t \n\tif (video->bpl_max)\n\t\tbpl = clamp(bpl, min_bpl, video->bpl_max);\n\telse\n\t\tbpl = min_bpl;\n\n\tif (!video->bpl_zero_padding || bpl != min_bpl)\n\t\tbpl = ALIGN(bpl, video->bpl_alignment);\n\n\tpix->pixelformat = formats[i].pixelformat;\n\tpix->bytesperline = bpl;\n\tpix->sizeimage = pix->bytesperline * pix->height;\n\tpix->colorspace = mbus->colorspace;\n\tpix->field = mbus->field;\n\n\treturn bpl - min_bpl;\n}\n\nstatic void isp_video_pix_to_mbus(const struct v4l2_pix_format *pix,\n\t\t\t\t  struct v4l2_mbus_framefmt *mbus)\n{\n\tunsigned int i;\n\n\tmemset(mbus, 0, sizeof(*mbus));\n\tmbus->width = pix->width;\n\tmbus->height = pix->height;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(formats) - 1; ++i) {\n\t\tif (formats[i].pixelformat == pix->pixelformat)\n\t\t\tbreak;\n\t}\n\n\tmbus->code = formats[i].code;\n\tmbus->colorspace = pix->colorspace;\n\tmbus->field = pix->field;\n}\n\nstatic struct v4l2_subdev *\nisp_video_remote_subdev(struct isp_video *video, u32 *pad)\n{\n\tstruct media_pad *remote;\n\n\tremote = media_pad_remote_pad_first(&video->pad);\n\n\tif (!remote || !is_media_entity_v4l2_subdev(remote->entity))\n\t\treturn NULL;\n\n\tif (pad)\n\t\t*pad = remote->index;\n\n\treturn media_entity_to_v4l2_subdev(remote->entity);\n}\n\n \nstatic int isp_video_get_graph_data(struct isp_video *video,\n\t\t\t\t    struct isp_pipeline *pipe)\n{\n\tstruct media_pipeline_entity_iter iter;\n\tstruct media_entity *entity;\n\tstruct isp_video *far_end = NULL;\n\tint ret;\n\n\tret = media_pipeline_entity_iter_init(&pipe->pipe, &iter);\n\tif (ret)\n\t\treturn ret;\n\n\tmedia_pipeline_for_each_entity(&pipe->pipe, &iter, entity) {\n\t\tstruct isp_video *__video;\n\n\t\tmedia_entity_enum_set(&pipe->ent_enum, entity);\n\n\t\tif (far_end != NULL)\n\t\t\tcontinue;\n\n\t\tif (entity == &video->video.entity)\n\t\t\tcontinue;\n\n\t\tif (!is_media_entity_v4l2_video_device(entity))\n\t\t\tcontinue;\n\n\t\t__video = to_isp_video(media_entity_to_video_device(entity));\n\t\tif (__video->type != video->type)\n\t\t\tfar_end = __video;\n\t}\n\n\tmedia_pipeline_entity_iter_cleanup(&iter);\n\n\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE) {\n\t\tpipe->input = far_end;\n\t\tpipe->output = video;\n\t} else {\n\t\tif (far_end == NULL)\n\t\t\treturn -EPIPE;\n\n\t\tpipe->input = video;\n\t\tpipe->output = far_end;\n\t}\n\n\treturn 0;\n}\n\nstatic int\n__isp_video_get_format(struct isp_video *video, struct v4l2_format *format)\n{\n\tstruct v4l2_subdev_format fmt = {\n\t\t.which = V4L2_SUBDEV_FORMAT_ACTIVE,\n\t};\n\tstruct v4l2_subdev *subdev;\n\tu32 pad;\n\tint ret;\n\n\tsubdev = isp_video_remote_subdev(video, &pad);\n\tif (subdev == NULL)\n\t\treturn -EINVAL;\n\n\tfmt.pad = pad;\n\n\tmutex_lock(&video->mutex);\n\tret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &fmt);\n\tmutex_unlock(&video->mutex);\n\n\tif (ret)\n\t\treturn ret;\n\n\tformat->type = video->type;\n\treturn isp_video_mbus_to_pix(video, &fmt.format, &format->fmt.pix);\n}\n\nstatic int\nisp_video_check_format(struct isp_video *video, struct isp_video_fh *vfh)\n{\n\tstruct v4l2_format format;\n\tint ret;\n\n\tmemcpy(&format, &vfh->format, sizeof(format));\n\tret = __isp_video_get_format(video, &format);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (vfh->format.fmt.pix.pixelformat != format.fmt.pix.pixelformat ||\n\t    vfh->format.fmt.pix.height != format.fmt.pix.height ||\n\t    vfh->format.fmt.pix.width != format.fmt.pix.width ||\n\t    vfh->format.fmt.pix.bytesperline != format.fmt.pix.bytesperline ||\n\t    vfh->format.fmt.pix.sizeimage != format.fmt.pix.sizeimage ||\n\t    vfh->format.fmt.pix.field != format.fmt.pix.field)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\n \n\nstatic int isp_video_queue_setup(struct vb2_queue *queue,\n\t\t\t\t unsigned int *count, unsigned int *num_planes,\n\t\t\t\t unsigned int sizes[], struct device *alloc_devs[])\n{\n\tstruct isp_video_fh *vfh = vb2_get_drv_priv(queue);\n\tstruct isp_video *video = vfh->video;\n\n\t*num_planes = 1;\n\n\tsizes[0] = vfh->format.fmt.pix.sizeimage;\n\tif (sizes[0] == 0)\n\t\treturn -EINVAL;\n\n\t*count = min(*count, video->capture_mem / PAGE_ALIGN(sizes[0]));\n\n\treturn 0;\n}\n\nstatic int isp_video_buffer_prepare(struct vb2_buffer *buf)\n{\n\tstruct vb2_v4l2_buffer *vbuf = to_vb2_v4l2_buffer(buf);\n\tstruct isp_video_fh *vfh = vb2_get_drv_priv(buf->vb2_queue);\n\tstruct isp_buffer *buffer = to_isp_buffer(vbuf);\n\tstruct isp_video *video = vfh->video;\n\tdma_addr_t addr;\n\n\t \n\tif (unlikely(video->error))\n\t\treturn -EIO;\n\n\taddr = vb2_dma_contig_plane_dma_addr(buf, 0);\n\tif (!IS_ALIGNED(addr, 32)) {\n\t\tdev_dbg(video->isp->dev,\n\t\t\t\"Buffer address must be aligned to 32 bytes boundary.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tvb2_set_plane_payload(&buffer->vb.vb2_buf, 0,\n\t\t\t      vfh->format.fmt.pix.sizeimage);\n\tbuffer->dma = addr;\n\n\treturn 0;\n}\n\n \nstatic void isp_video_buffer_queue(struct vb2_buffer *buf)\n{\n\tstruct vb2_v4l2_buffer *vbuf = to_vb2_v4l2_buffer(buf);\n\tstruct isp_video_fh *vfh = vb2_get_drv_priv(buf->vb2_queue);\n\tstruct isp_buffer *buffer = to_isp_buffer(vbuf);\n\tstruct isp_video *video = vfh->video;\n\tstruct isp_pipeline *pipe = to_isp_pipeline(&video->video.entity);\n\tenum isp_pipeline_state state;\n\tunsigned long flags;\n\tunsigned int empty;\n\tunsigned int start;\n\n\tspin_lock_irqsave(&video->irqlock, flags);\n\n\tif (unlikely(video->error)) {\n\t\tvb2_buffer_done(&buffer->vb.vb2_buf, VB2_BUF_STATE_ERROR);\n\t\tspin_unlock_irqrestore(&video->irqlock, flags);\n\t\treturn;\n\t}\n\n\tempty = list_empty(&video->dmaqueue);\n\tlist_add_tail(&buffer->irqlist, &video->dmaqueue);\n\n\tspin_unlock_irqrestore(&video->irqlock, flags);\n\n\tif (empty) {\n\t\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\t\tstate = ISP_PIPELINE_QUEUE_OUTPUT;\n\t\telse\n\t\t\tstate = ISP_PIPELINE_QUEUE_INPUT;\n\n\t\tspin_lock_irqsave(&pipe->lock, flags);\n\t\tpipe->state |= state;\n\t\tvideo->ops->queue(video, buffer);\n\t\tvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_QUEUED;\n\n\t\tstart = isp_pipeline_ready(pipe);\n\t\tif (start)\n\t\t\tpipe->state |= ISP_PIPELINE_STREAM;\n\t\tspin_unlock_irqrestore(&pipe->lock, flags);\n\n\t\tif (start)\n\t\t\tomap3isp_pipeline_set_stream(pipe,\n\t\t\t\t\t\tISP_PIPELINE_STREAM_SINGLESHOT);\n\t}\n}\n\n \nstatic void omap3isp_video_return_buffers(struct isp_video *video,\n\t\t\t\t\t  enum vb2_buffer_state state)\n{\n\twhile (!list_empty(&video->dmaqueue)) {\n\t\tstruct isp_buffer *buf;\n\n\t\tbuf = list_first_entry(&video->dmaqueue,\n\t\t\t\t       struct isp_buffer, irqlist);\n\t\tlist_del(&buf->irqlist);\n\t\tvb2_buffer_done(&buf->vb.vb2_buf, state);\n\t}\n}\n\nstatic int isp_video_start_streaming(struct vb2_queue *queue,\n\t\t\t\t     unsigned int count)\n{\n\tstruct isp_video_fh *vfh = vb2_get_drv_priv(queue);\n\tstruct isp_video *video = vfh->video;\n\tstruct isp_pipeline *pipe = to_isp_pipeline(&video->video.entity);\n\tunsigned long flags;\n\tint ret;\n\n\t \n\tif (pipe->input)\n\t\treturn 0;\n\n\tret = omap3isp_pipeline_set_stream(pipe,\n\t\t\t\t\t   ISP_PIPELINE_STREAM_CONTINUOUS);\n\tif (ret < 0) {\n\t\tspin_lock_irqsave(&video->irqlock, flags);\n\t\tomap3isp_video_return_buffers(video, VB2_BUF_STATE_QUEUED);\n\t\tspin_unlock_irqrestore(&video->irqlock, flags);\n\t\treturn ret;\n\t}\n\n\tspin_lock_irqsave(&video->irqlock, flags);\n\tif (list_empty(&video->dmaqueue))\n\t\tvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_UNDERRUN;\n\tspin_unlock_irqrestore(&video->irqlock, flags);\n\n\treturn 0;\n}\n\nstatic const struct vb2_ops isp_video_queue_ops = {\n\t.queue_setup = isp_video_queue_setup,\n\t.buf_prepare = isp_video_buffer_prepare,\n\t.buf_queue = isp_video_buffer_queue,\n\t.start_streaming = isp_video_start_streaming,\n};\n\n \nstruct isp_buffer *omap3isp_video_buffer_next(struct isp_video *video)\n{\n\tstruct isp_pipeline *pipe = to_isp_pipeline(&video->video.entity);\n\tenum vb2_buffer_state vb_state;\n\tstruct isp_buffer *buf;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&video->irqlock, flags);\n\tif (WARN_ON(list_empty(&video->dmaqueue))) {\n\t\tspin_unlock_irqrestore(&video->irqlock, flags);\n\t\treturn NULL;\n\t}\n\n\tbuf = list_first_entry(&video->dmaqueue, struct isp_buffer,\n\t\t\t       irqlist);\n\tlist_del(&buf->irqlist);\n\tspin_unlock_irqrestore(&video->irqlock, flags);\n\n\tbuf->vb.vb2_buf.timestamp = ktime_get_ns();\n\n\t \n\tif (video == pipe->output && !pipe->do_propagation)\n\t\tbuf->vb.sequence =\n\t\t\tatomic_inc_return(&pipe->frame_number);\n\telse\n\t\tbuf->vb.sequence = atomic_read(&pipe->frame_number);\n\n\tif (pipe->field != V4L2_FIELD_NONE)\n\t\tbuf->vb.sequence /= 2;\n\n\tbuf->vb.field = pipe->field;\n\n\t \n\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE && pipe->error) {\n\t\tvb_state = VB2_BUF_STATE_ERROR;\n\t\tpipe->error = false;\n\t} else {\n\t\tvb_state = VB2_BUF_STATE_DONE;\n\t}\n\n\tvb2_buffer_done(&buf->vb.vb2_buf, vb_state);\n\n\tspin_lock_irqsave(&video->irqlock, flags);\n\n\tif (list_empty(&video->dmaqueue)) {\n\t\tenum isp_pipeline_state state;\n\n\t\tspin_unlock_irqrestore(&video->irqlock, flags);\n\n\t\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\t\tstate = ISP_PIPELINE_QUEUE_OUTPUT\n\t\t\t      | ISP_PIPELINE_STREAM;\n\t\telse\n\t\t\tstate = ISP_PIPELINE_QUEUE_INPUT\n\t\t\t      | ISP_PIPELINE_STREAM;\n\n\t\tspin_lock_irqsave(&pipe->lock, flags);\n\t\tpipe->state &= ~state;\n\t\tif (video->pipe.stream_state == ISP_PIPELINE_STREAM_CONTINUOUS)\n\t\t\tvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_UNDERRUN;\n\t\tspin_unlock_irqrestore(&pipe->lock, flags);\n\t\treturn NULL;\n\t}\n\n\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE && pipe->input != NULL) {\n\t\tspin_lock(&pipe->lock);\n\t\tpipe->state &= ~ISP_PIPELINE_STREAM;\n\t\tspin_unlock(&pipe->lock);\n\t}\n\n\tbuf = list_first_entry(&video->dmaqueue, struct isp_buffer,\n\t\t\t       irqlist);\n\n\tspin_unlock_irqrestore(&video->irqlock, flags);\n\n\treturn buf;\n}\n\n \nvoid omap3isp_video_cancel_stream(struct isp_video *video)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&video->irqlock, flags);\n\tomap3isp_video_return_buffers(video, VB2_BUF_STATE_ERROR);\n\tvideo->error = true;\n\tspin_unlock_irqrestore(&video->irqlock, flags);\n}\n\n \nvoid omap3isp_video_resume(struct isp_video *video, int continuous)\n{\n\tstruct isp_buffer *buf = NULL;\n\n\tif (continuous && video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE) {\n\t\tmutex_lock(&video->queue_lock);\n\t\tvb2_discard_done(video->queue);\n\t\tmutex_unlock(&video->queue_lock);\n\t}\n\n\tif (!list_empty(&video->dmaqueue)) {\n\t\tbuf = list_first_entry(&video->dmaqueue,\n\t\t\t\t       struct isp_buffer, irqlist);\n\t\tvideo->ops->queue(video, buf);\n\t\tvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_QUEUED;\n\t} else {\n\t\tif (continuous)\n\t\t\tvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_UNDERRUN;\n\t}\n}\n\n \n\nstatic int\nisp_video_querycap(struct file *file, void *fh, struct v4l2_capability *cap)\n{\n\tstruct isp_video *video = video_drvdata(file);\n\n\tstrscpy(cap->driver, ISP_VIDEO_DRIVER_NAME, sizeof(cap->driver));\n\tstrscpy(cap->card, video->video.name, sizeof(cap->card));\n\tstrscpy(cap->bus_info, \"media\", sizeof(cap->bus_info));\n\n\tcap->capabilities = V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_VIDEO_OUTPUT\n\t\t| V4L2_CAP_STREAMING | V4L2_CAP_DEVICE_CAPS;\n\n\n\treturn 0;\n}\n\nstatic int\nisp_video_get_format(struct file *file, void *fh, struct v4l2_format *format)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\n\tif (format->type != video->type)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&video->mutex);\n\t*format = vfh->format;\n\tmutex_unlock(&video->mutex);\n\n\treturn 0;\n}\n\nstatic int\nisp_video_set_format(struct file *file, void *fh, struct v4l2_format *format)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\tstruct v4l2_mbus_framefmt fmt;\n\n\tif (format->type != video->type)\n\t\treturn -EINVAL;\n\n\t \n\tswitch (format->fmt.pix.field) {\n\tcase V4L2_FIELD_NONE:\n\t\t \n\t\tbreak;\n\tcase V4L2_FIELD_ALTERNATE:\n\t\t \n\t\tif (video->type == V4L2_BUF_TYPE_VIDEO_OUTPUT)\n\t\t\tformat->fmt.pix.field = V4L2_FIELD_NONE;\n\t\tbreak;\n\tcase V4L2_FIELD_INTERLACED:\n\t\t \n\t\tformat->fmt.pix.field = V4L2_FIELD_INTERLACED_TB;\n\t\tfallthrough;\n\tcase V4L2_FIELD_INTERLACED_TB:\n\tcase V4L2_FIELD_INTERLACED_BT:\n\t\t \n\t\tif (video != &video->isp->isp_ccdc.video_out)\n\t\t\tformat->fmt.pix.field = V4L2_FIELD_NONE;\n\t\tbreak;\n\tcase V4L2_FIELD_TOP:\n\tcase V4L2_FIELD_BOTTOM:\n\tcase V4L2_FIELD_SEQ_TB:\n\tcase V4L2_FIELD_SEQ_BT:\n\tdefault:\n\t\t \n\t\tformat->fmt.pix.field = V4L2_FIELD_NONE;\n\t\tbreak;\n\t}\n\n\t \n\tisp_video_pix_to_mbus(&format->fmt.pix, &fmt);\n\tisp_video_mbus_to_pix(video, &fmt, &format->fmt.pix);\n\n\tmutex_lock(&video->mutex);\n\tvfh->format = *format;\n\tmutex_unlock(&video->mutex);\n\n\treturn 0;\n}\n\nstatic int\nisp_video_try_format(struct file *file, void *fh, struct v4l2_format *format)\n{\n\tstruct isp_video *video = video_drvdata(file);\n\tstruct v4l2_subdev_format fmt = {\n\t\t.which = V4L2_SUBDEV_FORMAT_ACTIVE,\n\t};\n\tstruct v4l2_subdev *subdev;\n\tu32 pad;\n\tint ret;\n\n\tif (format->type != video->type)\n\t\treturn -EINVAL;\n\n\tsubdev = isp_video_remote_subdev(video, &pad);\n\tif (subdev == NULL)\n\t\treturn -EINVAL;\n\n\tisp_video_pix_to_mbus(&format->fmt.pix, &fmt.format);\n\n\tfmt.pad = pad;\n\tret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &fmt);\n\tif (ret)\n\t\treturn ret == -ENOIOCTLCMD ? -ENOTTY : ret;\n\n\tisp_video_mbus_to_pix(video, &fmt.format, &format->fmt.pix);\n\treturn 0;\n}\n\nstatic int\nisp_video_get_selection(struct file *file, void *fh, struct v4l2_selection *sel)\n{\n\tstruct isp_video *video = video_drvdata(file);\n\tstruct v4l2_subdev_format format = {\n\t\t.which = V4L2_SUBDEV_FORMAT_ACTIVE,\n\t};\n\tstruct v4l2_subdev *subdev;\n\tstruct v4l2_subdev_selection sdsel = {\n\t\t.which = V4L2_SUBDEV_FORMAT_ACTIVE,\n\t\t.target = sel->target,\n\t};\n\tu32 pad;\n\tint ret;\n\n\tswitch (sel->target) {\n\tcase V4L2_SEL_TGT_CROP:\n\tcase V4L2_SEL_TGT_CROP_BOUNDS:\n\tcase V4L2_SEL_TGT_CROP_DEFAULT:\n\t\tif (video->type == V4L2_BUF_TYPE_VIDEO_OUTPUT)\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tcase V4L2_SEL_TGT_COMPOSE:\n\tcase V4L2_SEL_TGT_COMPOSE_BOUNDS:\n\tcase V4L2_SEL_TGT_COMPOSE_DEFAULT:\n\t\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\tsubdev = isp_video_remote_subdev(video, &pad);\n\tif (subdev == NULL)\n\t\treturn -EINVAL;\n\n\t \n\tsdsel.pad = pad;\n\tret = v4l2_subdev_call(subdev, pad, get_selection, NULL, &sdsel);\n\tif (!ret)\n\t\tsel->r = sdsel.r;\n\tif (ret != -ENOIOCTLCMD)\n\t\treturn ret;\n\n\tformat.pad = pad;\n\tret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &format);\n\tif (ret < 0)\n\t\treturn ret == -ENOIOCTLCMD ? -ENOTTY : ret;\n\n\tsel->r.left = 0;\n\tsel->r.top = 0;\n\tsel->r.width = format.format.width;\n\tsel->r.height = format.format.height;\n\n\treturn 0;\n}\n\nstatic int\nisp_video_set_selection(struct file *file, void *fh, struct v4l2_selection *sel)\n{\n\tstruct isp_video *video = video_drvdata(file);\n\tstruct v4l2_subdev *subdev;\n\tstruct v4l2_subdev_selection sdsel = {\n\t\t.which = V4L2_SUBDEV_FORMAT_ACTIVE,\n\t\t.target = sel->target,\n\t\t.flags = sel->flags,\n\t\t.r = sel->r,\n\t};\n\tu32 pad;\n\tint ret;\n\n\tswitch (sel->target) {\n\tcase V4L2_SEL_TGT_CROP:\n\t\tif (video->type == V4L2_BUF_TYPE_VIDEO_OUTPUT)\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tcase V4L2_SEL_TGT_COMPOSE:\n\t\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\tsubdev = isp_video_remote_subdev(video, &pad);\n\tif (subdev == NULL)\n\t\treturn -EINVAL;\n\n\tsdsel.pad = pad;\n\tmutex_lock(&video->mutex);\n\tret = v4l2_subdev_call(subdev, pad, set_selection, NULL, &sdsel);\n\tmutex_unlock(&video->mutex);\n\tif (!ret)\n\t\tsel->r = sdsel.r;\n\n\treturn ret == -ENOIOCTLCMD ? -ENOTTY : ret;\n}\n\nstatic int\nisp_video_get_param(struct file *file, void *fh, struct v4l2_streamparm *a)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\n\tif (video->type != V4L2_BUF_TYPE_VIDEO_OUTPUT ||\n\t    video->type != a->type)\n\t\treturn -EINVAL;\n\n\tmemset(a, 0, sizeof(*a));\n\ta->type = V4L2_BUF_TYPE_VIDEO_OUTPUT;\n\ta->parm.output.capability = V4L2_CAP_TIMEPERFRAME;\n\ta->parm.output.timeperframe = vfh->timeperframe;\n\n\treturn 0;\n}\n\nstatic int\nisp_video_set_param(struct file *file, void *fh, struct v4l2_streamparm *a)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\n\tif (video->type != V4L2_BUF_TYPE_VIDEO_OUTPUT ||\n\t    video->type != a->type)\n\t\treturn -EINVAL;\n\n\tif (a->parm.output.timeperframe.denominator == 0)\n\t\ta->parm.output.timeperframe.denominator = 1;\n\n\tvfh->timeperframe = a->parm.output.timeperframe;\n\n\treturn 0;\n}\n\nstatic int\nisp_video_reqbufs(struct file *file, void *fh, struct v4l2_requestbuffers *rb)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\tint ret;\n\n\tmutex_lock(&video->queue_lock);\n\tret = vb2_reqbufs(&vfh->queue, rb);\n\tmutex_unlock(&video->queue_lock);\n\n\treturn ret;\n}\n\nstatic int\nisp_video_querybuf(struct file *file, void *fh, struct v4l2_buffer *b)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\tint ret;\n\n\tmutex_lock(&video->queue_lock);\n\tret = vb2_querybuf(&vfh->queue, b);\n\tmutex_unlock(&video->queue_lock);\n\n\treturn ret;\n}\n\nstatic int\nisp_video_qbuf(struct file *file, void *fh, struct v4l2_buffer *b)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\tint ret;\n\n\tmutex_lock(&video->queue_lock);\n\tret = vb2_qbuf(&vfh->queue, video->video.v4l2_dev->mdev, b);\n\tmutex_unlock(&video->queue_lock);\n\n\treturn ret;\n}\n\nstatic int\nisp_video_dqbuf(struct file *file, void *fh, struct v4l2_buffer *b)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\tint ret;\n\n\tmutex_lock(&video->queue_lock);\n\tret = vb2_dqbuf(&vfh->queue, b, file->f_flags & O_NONBLOCK);\n\tmutex_unlock(&video->queue_lock);\n\n\treturn ret;\n}\n\nstatic int isp_video_check_external_subdevs(struct isp_video *video,\n\t\t\t\t\t    struct isp_pipeline *pipe)\n{\n\tstruct isp_device *isp = video->isp;\n\tstruct media_entity *ents[] = {\n\t\t&isp->isp_csi2a.subdev.entity,\n\t\t&isp->isp_csi2c.subdev.entity,\n\t\t&isp->isp_ccp2.subdev.entity,\n\t\t&isp->isp_ccdc.subdev.entity\n\t};\n\tstruct media_pad *source_pad;\n\tstruct media_entity *source = NULL;\n\tstruct media_entity *sink;\n\tstruct v4l2_subdev_format fmt = {\n\t\t.which = V4L2_SUBDEV_FORMAT_ACTIVE,\n\t};\n\tstruct v4l2_ext_controls ctrls;\n\tstruct v4l2_ext_control ctrl;\n\tunsigned int i;\n\tint ret;\n\n\t \n\tif (pipe->input != NULL)\n\t\treturn 0;\n\n\tfor (i = 0; i < ARRAY_SIZE(ents); i++) {\n\t\t \n\t\tif (!media_entity_enum_test(&pipe->ent_enum, ents[i]))\n\t\t\tcontinue;\n\n\t\t \n\t\tsource_pad = media_pad_remote_pad_first(&ents[i]->pads[0]);\n\t\tif (source_pad == NULL)\n\t\t\tcontinue;\n\n\t\tsource = source_pad->entity;\n\t\tsink = ents[i];\n\t\tbreak;\n\t}\n\n\tif (!source) {\n\t\tdev_warn(isp->dev, \"can't find source, failing now\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!is_media_entity_v4l2_subdev(source))\n\t\treturn 0;\n\n\tpipe->external = media_entity_to_v4l2_subdev(source);\n\n\tfmt.pad = source_pad->index;\n\tret = v4l2_subdev_call(media_entity_to_v4l2_subdev(sink),\n\t\t\t       pad, get_fmt, NULL, &fmt);\n\tif (unlikely(ret < 0)) {\n\t\tdev_warn(isp->dev, \"get_fmt returned null!\\n\");\n\t\treturn ret;\n\t}\n\n\tpipe->external_width =\n\t\tomap3isp_video_format_info(fmt.format.code)->width;\n\n\tmemset(&ctrls, 0, sizeof(ctrls));\n\tmemset(&ctrl, 0, sizeof(ctrl));\n\n\tctrl.id = V4L2_CID_PIXEL_RATE;\n\n\tctrls.count = 1;\n\tctrls.controls = &ctrl;\n\tret = v4l2_g_ext_ctrls(pipe->external->ctrl_handler, &video->video,\n\t\t\t       NULL, &ctrls);\n\tif (ret < 0) {\n\t\tdev_warn(isp->dev, \"no pixel rate control in subdev %s\\n\",\n\t\t\t pipe->external->name);\n\t\treturn ret;\n\t}\n\n\tpipe->external_rate = ctrl.value64;\n\n\tif (media_entity_enum_test(&pipe->ent_enum,\n\t\t\t\t   &isp->isp_ccdc.subdev.entity)) {\n\t\tunsigned int rate = UINT_MAX;\n\t\t \n\t\tomap3isp_ccdc_max_rate(&isp->isp_ccdc, &rate);\n\t\tif (pipe->external_rate > rate)\n\t\t\treturn -ENOSPC;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nisp_video_streamon(struct file *file, void *fh, enum v4l2_buf_type type)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\tenum isp_pipeline_state state;\n\tstruct isp_pipeline *pipe;\n\tunsigned long flags;\n\tint ret;\n\n\tif (type != video->type)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&video->stream_lock);\n\n\t \n\tpipe = to_isp_pipeline(&video->video.entity) ? : &video->pipe;\n\n\tret = media_entity_enum_init(&pipe->ent_enum, &video->isp->media_dev);\n\tif (ret)\n\t\tgoto err_enum_init;\n\n\t \n\tpipe->l3_ick = clk_get_rate(video->isp->clock[ISP_CLK_L3_ICK]);\n\tpipe->max_rate = pipe->l3_ick;\n\n\tret = video_device_pipeline_start(&video->video, &pipe->pipe);\n\tif (ret < 0)\n\t\tgoto err_pipeline_start;\n\n\t \n\tret = isp_video_check_format(video, vfh);\n\tif (ret < 0)\n\t\tgoto err_check_format;\n\n\tvideo->bpl_padding = ret;\n\tvideo->bpl_value = vfh->format.fmt.pix.bytesperline;\n\n\tret = isp_video_get_graph_data(video, pipe);\n\tif (ret < 0)\n\t\tgoto err_check_format;\n\n\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\tstate = ISP_PIPELINE_STREAM_OUTPUT | ISP_PIPELINE_IDLE_OUTPUT;\n\telse\n\t\tstate = ISP_PIPELINE_STREAM_INPUT | ISP_PIPELINE_IDLE_INPUT;\n\n\tret = isp_video_check_external_subdevs(video, pipe);\n\tif (ret < 0)\n\t\tgoto err_check_format;\n\n\tpipe->error = false;\n\n\tspin_lock_irqsave(&pipe->lock, flags);\n\tpipe->state &= ~ISP_PIPELINE_STREAM;\n\tpipe->state |= state;\n\tspin_unlock_irqrestore(&pipe->lock, flags);\n\n\t \n\tif (video->type == V4L2_BUF_TYPE_VIDEO_OUTPUT)\n\t\tpipe->max_timeperframe = vfh->timeperframe;\n\n\tvideo->queue = &vfh->queue;\n\tINIT_LIST_HEAD(&video->dmaqueue);\n\tatomic_set(&pipe->frame_number, -1);\n\tpipe->field = vfh->format.fmt.pix.field;\n\n\tmutex_lock(&video->queue_lock);\n\tret = vb2_streamon(&vfh->queue, type);\n\tmutex_unlock(&video->queue_lock);\n\tif (ret < 0)\n\t\tgoto err_check_format;\n\n\tmutex_unlock(&video->stream_lock);\n\n\treturn 0;\n\nerr_check_format:\n\tvideo_device_pipeline_stop(&video->video);\nerr_pipeline_start:\n\t \n\t \n\tINIT_LIST_HEAD(&video->dmaqueue);\n\tvideo->queue = NULL;\n\n\tmedia_entity_enum_cleanup(&pipe->ent_enum);\n\nerr_enum_init:\n\tmutex_unlock(&video->stream_lock);\n\n\treturn ret;\n}\n\nstatic int\nisp_video_streamoff(struct file *file, void *fh, enum v4l2_buf_type type)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(fh);\n\tstruct isp_video *video = video_drvdata(file);\n\tstruct isp_pipeline *pipe = to_isp_pipeline(&video->video.entity);\n\tenum isp_pipeline_state state;\n\tunsigned int streaming;\n\tunsigned long flags;\n\n\tif (type != video->type)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&video->stream_lock);\n\n\t \n\tmutex_lock(&video->queue_lock);\n\tstreaming = vb2_is_streaming(&vfh->queue);\n\tmutex_unlock(&video->queue_lock);\n\n\tif (!streaming)\n\t\tgoto done;\n\n\t \n\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\tstate = ISP_PIPELINE_STREAM_OUTPUT\n\t\t      | ISP_PIPELINE_QUEUE_OUTPUT;\n\telse\n\t\tstate = ISP_PIPELINE_STREAM_INPUT\n\t\t      | ISP_PIPELINE_QUEUE_INPUT;\n\n\tspin_lock_irqsave(&pipe->lock, flags);\n\tpipe->state &= ~state;\n\tspin_unlock_irqrestore(&pipe->lock, flags);\n\n\t \n\tomap3isp_pipeline_set_stream(pipe, ISP_PIPELINE_STREAM_STOPPED);\n\tomap3isp_video_cancel_stream(video);\n\n\tmutex_lock(&video->queue_lock);\n\tvb2_streamoff(&vfh->queue, type);\n\tmutex_unlock(&video->queue_lock);\n\tvideo->queue = NULL;\n\tvideo->error = false;\n\n\t \n\tvideo_device_pipeline_stop(&video->video);\n\n\tmedia_entity_enum_cleanup(&pipe->ent_enum);\n\ndone:\n\tmutex_unlock(&video->stream_lock);\n\treturn 0;\n}\n\nstatic int\nisp_video_enum_input(struct file *file, void *fh, struct v4l2_input *input)\n{\n\tif (input->index > 0)\n\t\treturn -EINVAL;\n\n\tstrscpy(input->name, \"camera\", sizeof(input->name));\n\tinput->type = V4L2_INPUT_TYPE_CAMERA;\n\n\treturn 0;\n}\n\nstatic int\nisp_video_g_input(struct file *file, void *fh, unsigned int *input)\n{\n\t*input = 0;\n\n\treturn 0;\n}\n\nstatic int\nisp_video_s_input(struct file *file, void *fh, unsigned int input)\n{\n\treturn input == 0 ? 0 : -EINVAL;\n}\n\nstatic const struct v4l2_ioctl_ops isp_video_ioctl_ops = {\n\t.vidioc_querycap\t\t= isp_video_querycap,\n\t.vidioc_g_fmt_vid_cap\t\t= isp_video_get_format,\n\t.vidioc_s_fmt_vid_cap\t\t= isp_video_set_format,\n\t.vidioc_try_fmt_vid_cap\t\t= isp_video_try_format,\n\t.vidioc_g_fmt_vid_out\t\t= isp_video_get_format,\n\t.vidioc_s_fmt_vid_out\t\t= isp_video_set_format,\n\t.vidioc_try_fmt_vid_out\t\t= isp_video_try_format,\n\t.vidioc_g_selection\t\t= isp_video_get_selection,\n\t.vidioc_s_selection\t\t= isp_video_set_selection,\n\t.vidioc_g_parm\t\t\t= isp_video_get_param,\n\t.vidioc_s_parm\t\t\t= isp_video_set_param,\n\t.vidioc_reqbufs\t\t\t= isp_video_reqbufs,\n\t.vidioc_querybuf\t\t= isp_video_querybuf,\n\t.vidioc_qbuf\t\t\t= isp_video_qbuf,\n\t.vidioc_dqbuf\t\t\t= isp_video_dqbuf,\n\t.vidioc_streamon\t\t= isp_video_streamon,\n\t.vidioc_streamoff\t\t= isp_video_streamoff,\n\t.vidioc_enum_input\t\t= isp_video_enum_input,\n\t.vidioc_g_input\t\t\t= isp_video_g_input,\n\t.vidioc_s_input\t\t\t= isp_video_s_input,\n};\n\n \n\nstatic int isp_video_open(struct file *file)\n{\n\tstruct isp_video *video = video_drvdata(file);\n\tstruct isp_video_fh *handle;\n\tstruct vb2_queue *queue;\n\tint ret = 0;\n\n\thandle = kzalloc(sizeof(*handle), GFP_KERNEL);\n\tif (handle == NULL)\n\t\treturn -ENOMEM;\n\n\tv4l2_fh_init(&handle->vfh, &video->video);\n\tv4l2_fh_add(&handle->vfh);\n\n\t \n\tif (omap3isp_get(video->isp) == NULL) {\n\t\tret = -EBUSY;\n\t\tgoto done;\n\t}\n\n\tret = v4l2_pipeline_pm_get(&video->video.entity);\n\tif (ret < 0) {\n\t\tomap3isp_put(video->isp);\n\t\tgoto done;\n\t}\n\n\tqueue = &handle->queue;\n\tqueue->type = video->type;\n\tqueue->io_modes = VB2_MMAP | VB2_USERPTR;\n\tqueue->drv_priv = handle;\n\tqueue->ops = &isp_video_queue_ops;\n\tqueue->mem_ops = &vb2_dma_contig_memops;\n\tqueue->buf_struct_size = sizeof(struct isp_buffer);\n\tqueue->timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;\n\tqueue->dev = video->isp->dev;\n\n\tret = vb2_queue_init(&handle->queue);\n\tif (ret < 0) {\n\t\tomap3isp_put(video->isp);\n\t\tgoto done;\n\t}\n\n\tmemset(&handle->format, 0, sizeof(handle->format));\n\thandle->format.type = video->type;\n\thandle->timeperframe.denominator = 1;\n\n\thandle->video = video;\n\tfile->private_data = &handle->vfh;\n\ndone:\n\tif (ret < 0) {\n\t\tv4l2_fh_del(&handle->vfh);\n\t\tv4l2_fh_exit(&handle->vfh);\n\t\tkfree(handle);\n\t}\n\n\treturn ret;\n}\n\nstatic int isp_video_release(struct file *file)\n{\n\tstruct isp_video *video = video_drvdata(file);\n\tstruct v4l2_fh *vfh = file->private_data;\n\tstruct isp_video_fh *handle = to_isp_video_fh(vfh);\n\n\t \n\tisp_video_streamoff(file, vfh, video->type);\n\n\tmutex_lock(&video->queue_lock);\n\tvb2_queue_release(&handle->queue);\n\tmutex_unlock(&video->queue_lock);\n\n\tv4l2_pipeline_pm_put(&video->video.entity);\n\n\t \n\tv4l2_fh_del(vfh);\n\tv4l2_fh_exit(vfh);\n\tkfree(handle);\n\tfile->private_data = NULL;\n\n\tomap3isp_put(video->isp);\n\n\treturn 0;\n}\n\nstatic __poll_t isp_video_poll(struct file *file, poll_table *wait)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(file->private_data);\n\tstruct isp_video *video = video_drvdata(file);\n\t__poll_t ret;\n\n\tmutex_lock(&video->queue_lock);\n\tret = vb2_poll(&vfh->queue, file, wait);\n\tmutex_unlock(&video->queue_lock);\n\n\treturn ret;\n}\n\nstatic int isp_video_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct isp_video_fh *vfh = to_isp_video_fh(file->private_data);\n\n\treturn vb2_mmap(&vfh->queue, vma);\n}\n\nstatic const struct v4l2_file_operations isp_video_fops = {\n\t.owner = THIS_MODULE,\n\t.unlocked_ioctl = video_ioctl2,\n\t.open = isp_video_open,\n\t.release = isp_video_release,\n\t.poll = isp_video_poll,\n\t.mmap = isp_video_mmap,\n};\n\n \n\nstatic const struct isp_video_operations isp_video_dummy_ops = {\n};\n\nint omap3isp_video_init(struct isp_video *video, const char *name)\n{\n\tconst char *direction;\n\tint ret;\n\n\tswitch (video->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n\t\tdirection = \"output\";\n\t\tvideo->pad.flags = MEDIA_PAD_FL_SINK\n\t\t\t\t   | MEDIA_PAD_FL_MUST_CONNECT;\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n\t\tdirection = \"input\";\n\t\tvideo->pad.flags = MEDIA_PAD_FL_SOURCE\n\t\t\t\t   | MEDIA_PAD_FL_MUST_CONNECT;\n\t\tvideo->video.vfl_dir = VFL_DIR_TX;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tret = media_entity_pads_init(&video->video.entity, 1, &video->pad);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_init(&video->mutex);\n\tatomic_set(&video->active, 0);\n\n\tspin_lock_init(&video->pipe.lock);\n\tmutex_init(&video->stream_lock);\n\tmutex_init(&video->queue_lock);\n\tspin_lock_init(&video->irqlock);\n\n\t \n\tif (video->ops == NULL)\n\t\tvideo->ops = &isp_video_dummy_ops;\n\n\tvideo->video.fops = &isp_video_fops;\n\tsnprintf(video->video.name, sizeof(video->video.name),\n\t\t \"OMAP3 ISP %s %s\", name, direction);\n\tvideo->video.vfl_type = VFL_TYPE_VIDEO;\n\tvideo->video.release = video_device_release_empty;\n\tvideo->video.ioctl_ops = &isp_video_ioctl_ops;\n\tif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\tvideo->video.device_caps = V4L2_CAP_VIDEO_CAPTURE\n\t\t\t\t\t | V4L2_CAP_STREAMING;\n\telse\n\t\tvideo->video.device_caps = V4L2_CAP_VIDEO_OUTPUT\n\t\t\t\t\t | V4L2_CAP_STREAMING;\n\n\tvideo->pipe.stream_state = ISP_PIPELINE_STREAM_STOPPED;\n\n\tvideo_set_drvdata(&video->video, video);\n\n\treturn 0;\n}\n\nvoid omap3isp_video_cleanup(struct isp_video *video)\n{\n\tmedia_entity_cleanup(&video->video.entity);\n\tmutex_destroy(&video->queue_lock);\n\tmutex_destroy(&video->stream_lock);\n\tmutex_destroy(&video->mutex);\n}\n\nint omap3isp_video_register(struct isp_video *video, struct v4l2_device *vdev)\n{\n\tint ret;\n\n\tvideo->video.v4l2_dev = vdev;\n\n\tret = video_register_device(&video->video, VFL_TYPE_VIDEO, -1);\n\tif (ret < 0)\n\t\tdev_err(video->isp->dev,\n\t\t\t\"%s: could not register video device (%d)\\n\",\n\t\t\t__func__, ret);\n\n\treturn ret;\n}\n\nvoid omap3isp_video_unregister(struct isp_video *video)\n{\n\tvideo_unregister_device(&video->video);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}