{
  "module_name": "vdec_msg_queue.c",
  "hash_id": "47df2dd768491610c562031e8c274595bed403ecdf693deae0403ce7a35f879b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/platform/mediatek/vcodec/decoder/vdec_msg_queue.c",
  "human_readable_source": "\n \n\n#include <linux/freezer.h>\n#include <linux/interrupt.h>\n#include <linux/kthread.h>\n\n#include \"mtk_vcodec_dec_drv.h\"\n#include \"mtk_vcodec_dec_pm.h\"\n#include \"vdec_msg_queue.h\"\n\n#define VDEC_MSG_QUEUE_TIMEOUT_MS 1500\n\n \n#define VDEC_LAT_SLICE_HEADER_SZ    (640 * SZ_1K)\n\n \n#define VDEC_ERR_MAP_SZ_AVC         (17 * SZ_1K)\n\n#define VDEC_RD_MV_BUFFER_SZ        (((SZ_4K * 2304 >> 4) + SZ_1K) << 1)\n#define VDEC_LAT_TILE_SZ            (64 * V4L2_AV1_MAX_TILE_COUNT)\n\n \nstatic int vde_msg_queue_get_trans_size(int width, int height)\n{\n\tif (width > 1920 || height > 1088)\n\t\treturn 30 * SZ_1M;\n\telse\n\t\treturn 6 * SZ_1M;\n}\n\nvoid vdec_msg_queue_init_ctx(struct vdec_msg_queue_ctx *ctx, int hardware_index)\n{\n\tinit_waitqueue_head(&ctx->ready_to_use);\n\tINIT_LIST_HEAD(&ctx->ready_queue);\n\tspin_lock_init(&ctx->ready_lock);\n\tctx->ready_num = 0;\n\tctx->hardware_index = hardware_index;\n}\n\nstatic struct list_head *vdec_get_buf_list(int hardware_index, struct vdec_lat_buf *buf)\n{\n\tswitch (hardware_index) {\n\tcase MTK_VDEC_CORE:\n\t\treturn &buf->core_list;\n\tcase MTK_VDEC_LAT0:\n\t\treturn &buf->lat_list;\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic void vdec_msg_queue_inc(struct vdec_msg_queue *msg_queue, int hardware_index)\n{\n\tif (hardware_index == MTK_VDEC_CORE)\n\t\tatomic_inc(&msg_queue->core_list_cnt);\n\telse\n\t\tatomic_inc(&msg_queue->lat_list_cnt);\n}\n\nstatic void vdec_msg_queue_dec(struct vdec_msg_queue *msg_queue, int hardware_index)\n{\n\tif (hardware_index == MTK_VDEC_CORE)\n\t\tatomic_dec(&msg_queue->core_list_cnt);\n\telse\n\t\tatomic_dec(&msg_queue->lat_list_cnt);\n}\n\nint vdec_msg_queue_qbuf(struct vdec_msg_queue_ctx *msg_ctx, struct vdec_lat_buf *buf)\n{\n\tstruct list_head *head;\n\n\thead = vdec_get_buf_list(msg_ctx->hardware_index, buf);\n\tif (!head) {\n\t\tmtk_v4l2_vdec_err(buf->ctx, \"fail to qbuf: %d\", msg_ctx->hardware_index);\n\t\treturn -EINVAL;\n\t}\n\n\tspin_lock(&msg_ctx->ready_lock);\n\tlist_add_tail(head, &msg_ctx->ready_queue);\n\tmsg_ctx->ready_num++;\n\n\tvdec_msg_queue_inc(&buf->ctx->msg_queue, msg_ctx->hardware_index);\n\tif (msg_ctx->hardware_index != MTK_VDEC_CORE) {\n\t\twake_up_all(&msg_ctx->ready_to_use);\n\t} else {\n\t\tif (!(buf->ctx->msg_queue.status & CONTEXT_LIST_QUEUED)) {\n\t\t\tqueue_work(buf->ctx->dev->core_workqueue, &buf->ctx->msg_queue.core_work);\n\t\t\tbuf->ctx->msg_queue.status |= CONTEXT_LIST_QUEUED;\n\t\t}\n\t}\n\n\tmtk_v4l2_vdec_dbg(3, buf->ctx, \"enqueue buf type: %d addr: 0x%p num: %d\",\n\t\t\t  msg_ctx->hardware_index, buf, msg_ctx->ready_num);\n\tspin_unlock(&msg_ctx->ready_lock);\n\n\treturn 0;\n}\n\nstatic bool vdec_msg_queue_wait_event(struct vdec_msg_queue_ctx *msg_ctx)\n{\n\tint ret;\n\n\tret = wait_event_timeout(msg_ctx->ready_to_use,\n\t\t\t\t !list_empty(&msg_ctx->ready_queue),\n\t\t\t\t msecs_to_jiffies(VDEC_MSG_QUEUE_TIMEOUT_MS));\n\tif (!ret)\n\t\treturn false;\n\n\treturn true;\n}\n\nstruct vdec_lat_buf *vdec_msg_queue_dqbuf(struct vdec_msg_queue_ctx *msg_ctx)\n{\n\tstruct vdec_lat_buf *buf;\n\tstruct list_head *head;\n\tint ret;\n\n\tspin_lock(&msg_ctx->ready_lock);\n\tif (list_empty(&msg_ctx->ready_queue)) {\n\t\tspin_unlock(&msg_ctx->ready_lock);\n\n\t\tif (msg_ctx->hardware_index == MTK_VDEC_CORE)\n\t\t\treturn NULL;\n\n\t\tret = vdec_msg_queue_wait_event(msg_ctx);\n\t\tif (!ret)\n\t\t\treturn NULL;\n\t\tspin_lock(&msg_ctx->ready_lock);\n\t}\n\n\tif (msg_ctx->hardware_index == MTK_VDEC_CORE)\n\t\tbuf = list_first_entry(&msg_ctx->ready_queue,\n\t\t\t\t       struct vdec_lat_buf, core_list);\n\telse\n\t\tbuf = list_first_entry(&msg_ctx->ready_queue,\n\t\t\t\t       struct vdec_lat_buf, lat_list);\n\n\thead = vdec_get_buf_list(msg_ctx->hardware_index, buf);\n\tif (!head) {\n\t\tspin_unlock(&msg_ctx->ready_lock);\n\t\tmtk_v4l2_vdec_err(buf->ctx, \"fail to dqbuf: %d\", msg_ctx->hardware_index);\n\t\treturn NULL;\n\t}\n\tlist_del(head);\n\tvdec_msg_queue_dec(&buf->ctx->msg_queue, msg_ctx->hardware_index);\n\n\tmsg_ctx->ready_num--;\n\tmtk_v4l2_vdec_dbg(3, buf->ctx, \"dqueue buf type:%d addr: 0x%p num: %d\",\n\t\t\t  msg_ctx->hardware_index, buf, msg_ctx->ready_num);\n\tspin_unlock(&msg_ctx->ready_lock);\n\n\treturn buf;\n}\n\nvoid vdec_msg_queue_update_ube_rptr(struct vdec_msg_queue *msg_queue, uint64_t ube_rptr)\n{\n\tspin_lock(&msg_queue->lat_ctx.ready_lock);\n\tmsg_queue->wdma_rptr_addr = ube_rptr;\n\tmtk_v4l2_vdec_dbg(3, msg_queue->ctx, \"update ube rprt (0x%llx)\", ube_rptr);\n\tspin_unlock(&msg_queue->lat_ctx.ready_lock);\n}\n\nvoid vdec_msg_queue_update_ube_wptr(struct vdec_msg_queue *msg_queue, uint64_t ube_wptr)\n{\n\tspin_lock(&msg_queue->lat_ctx.ready_lock);\n\tmsg_queue->wdma_wptr_addr = ube_wptr;\n\tmtk_v4l2_vdec_dbg(3, msg_queue->ctx, \"update ube wprt: (0x%llx 0x%llx) offset: 0x%llx\",\n\t\t\t  msg_queue->wdma_rptr_addr, msg_queue->wdma_wptr_addr,\n\t\t\t  ube_wptr);\n\tspin_unlock(&msg_queue->lat_ctx.ready_lock);\n}\n\nbool vdec_msg_queue_wait_lat_buf_full(struct vdec_msg_queue *msg_queue)\n{\n\tif (atomic_read(&msg_queue->lat_list_cnt) == NUM_BUFFER_COUNT) {\n\t\tmtk_v4l2_vdec_dbg(3, msg_queue->ctx, \"wait buf full: (%d %d) ready:%d status:%d\",\n\t\t\t\t  atomic_read(&msg_queue->lat_list_cnt),\n\t\t\t\t  atomic_read(&msg_queue->core_list_cnt),\n\t\t\t\t  msg_queue->lat_ctx.ready_num, msg_queue->status);\n\t\treturn true;\n\t}\n\n\tmsg_queue->flush_done = false;\n\tvdec_msg_queue_qbuf(&msg_queue->core_ctx, &msg_queue->empty_lat_buf);\n\twait_event(msg_queue->core_dec_done, msg_queue->flush_done);\n\n\tmtk_v4l2_vdec_dbg(3, msg_queue->ctx, \"flush done => ready_num:%d status:%d list(%d %d)\",\n\t\t\t  msg_queue->lat_ctx.ready_num, msg_queue->status,\n\t\t\t  atomic_read(&msg_queue->lat_list_cnt),\n\t\t\t  atomic_read(&msg_queue->core_list_cnt));\n\n\treturn false;\n}\n\nvoid vdec_msg_queue_deinit(struct vdec_msg_queue *msg_queue,\n\t\t\t   struct mtk_vcodec_dec_ctx *ctx)\n{\n\tstruct vdec_lat_buf *lat_buf;\n\tstruct mtk_vcodec_mem *mem;\n\tint i;\n\n\tmem = &msg_queue->wdma_addr;\n\tif (mem->va)\n\t\tmtk_vcodec_mem_free(ctx, mem);\n\tfor (i = 0; i < NUM_BUFFER_COUNT; i++) {\n\t\tlat_buf = &msg_queue->lat_buf[i];\n\n\t\tmem = &lat_buf->wdma_err_addr;\n\t\tif (mem->va)\n\t\t\tmtk_vcodec_mem_free(ctx, mem);\n\n\t\tmem = &lat_buf->slice_bc_addr;\n\t\tif (mem->va)\n\t\t\tmtk_vcodec_mem_free(ctx, mem);\n\n\t\tmem = &lat_buf->rd_mv_addr;\n\t\tif (mem->va)\n\t\t\tmtk_vcodec_mem_free(ctx, mem);\n\n\t\tmem = &lat_buf->tile_addr;\n\t\tif (mem->va)\n\t\t\tmtk_vcodec_mem_free(ctx, mem);\n\n\t\tkfree(lat_buf->private_data);\n\t\tlat_buf->private_data = NULL;\n\t}\n\n\tif (msg_queue->wdma_addr.size)\n\t\tcancel_work_sync(&msg_queue->core_work);\n}\n\nstatic void vdec_msg_queue_core_work(struct work_struct *work)\n{\n\tstruct vdec_msg_queue *msg_queue =\n\t\tcontainer_of(work, struct vdec_msg_queue, core_work);\n\tstruct mtk_vcodec_dec_ctx *ctx =\n\t\tcontainer_of(msg_queue, struct mtk_vcodec_dec_ctx, msg_queue);\n\tstruct mtk_vcodec_dec_dev *dev = ctx->dev;\n\tstruct vdec_lat_buf *lat_buf;\n\n\tspin_lock(&msg_queue->core_ctx.ready_lock);\n\tctx->msg_queue.status &= ~CONTEXT_LIST_QUEUED;\n\tspin_unlock(&msg_queue->core_ctx.ready_lock);\n\n\tlat_buf = vdec_msg_queue_dqbuf(&msg_queue->core_ctx);\n\tif (!lat_buf)\n\t\treturn;\n\n\tif (lat_buf->is_last_frame) {\n\t\tctx->msg_queue.status = CONTEXT_LIST_DEC_DONE;\n\t\tmsg_queue->flush_done = true;\n\t\twake_up(&ctx->msg_queue.core_dec_done);\n\n\t\treturn;\n\t}\n\n\tctx = lat_buf->ctx;\n\tmtk_vcodec_dec_enable_hardware(ctx, MTK_VDEC_CORE);\n\tmtk_vcodec_set_curr_ctx(dev, ctx, MTK_VDEC_CORE);\n\n\tlat_buf->core_decode(lat_buf);\n\n\tmtk_vcodec_set_curr_ctx(dev, NULL, MTK_VDEC_CORE);\n\tmtk_vcodec_dec_disable_hardware(ctx, MTK_VDEC_CORE);\n\tvdec_msg_queue_qbuf(&ctx->msg_queue.lat_ctx, lat_buf);\n\n\tif (!(ctx->msg_queue.status & CONTEXT_LIST_QUEUED) &&\n\t    atomic_read(&msg_queue->core_list_cnt)) {\n\t\tspin_lock(&msg_queue->core_ctx.ready_lock);\n\t\tctx->msg_queue.status |= CONTEXT_LIST_QUEUED;\n\t\tspin_unlock(&msg_queue->core_ctx.ready_lock);\n\t\tqueue_work(ctx->dev->core_workqueue, &msg_queue->core_work);\n\t}\n}\n\nint vdec_msg_queue_init(struct vdec_msg_queue *msg_queue,\n\t\t\tstruct mtk_vcodec_dec_ctx *ctx, core_decode_cb_t core_decode,\n\t\t\tint private_size)\n{\n\tstruct vdec_lat_buf *lat_buf;\n\tint i, err;\n\n\t \n\tif (msg_queue->wdma_addr.size)\n\t\treturn 0;\n\n\tvdec_msg_queue_init_ctx(&msg_queue->lat_ctx, MTK_VDEC_LAT0);\n\tvdec_msg_queue_init_ctx(&msg_queue->core_ctx, MTK_VDEC_CORE);\n\tINIT_WORK(&msg_queue->core_work, vdec_msg_queue_core_work);\n\n\tatomic_set(&msg_queue->lat_list_cnt, 0);\n\tatomic_set(&msg_queue->core_list_cnt, 0);\n\tinit_waitqueue_head(&msg_queue->core_dec_done);\n\tmsg_queue->status = CONTEXT_LIST_EMPTY;\n\n\tmsg_queue->wdma_addr.size =\n\t\tvde_msg_queue_get_trans_size(ctx->picinfo.buf_w,\n\t\t\t\t\t     ctx->picinfo.buf_h);\n\terr = mtk_vcodec_mem_alloc(ctx, &msg_queue->wdma_addr);\n\tif (err) {\n\t\tmtk_v4l2_vdec_err(ctx, \"failed to allocate wdma_addr buf\");\n\t\tmsg_queue->wdma_addr.size = 0;\n\t\treturn -ENOMEM;\n\t}\n\tmsg_queue->wdma_rptr_addr = msg_queue->wdma_addr.dma_addr;\n\tmsg_queue->wdma_wptr_addr = msg_queue->wdma_addr.dma_addr;\n\n\tmsg_queue->empty_lat_buf.ctx = ctx;\n\tmsg_queue->empty_lat_buf.core_decode = NULL;\n\tmsg_queue->empty_lat_buf.is_last_frame = true;\n\n\tmsg_queue->ctx = ctx;\n\tfor (i = 0; i < NUM_BUFFER_COUNT; i++) {\n\t\tlat_buf = &msg_queue->lat_buf[i];\n\n\t\tlat_buf->wdma_err_addr.size = VDEC_ERR_MAP_SZ_AVC;\n\t\terr = mtk_vcodec_mem_alloc(ctx, &lat_buf->wdma_err_addr);\n\t\tif (err) {\n\t\t\tmtk_v4l2_vdec_err(ctx, \"failed to allocate wdma_err_addr buf[%d]\", i);\n\t\t\tgoto mem_alloc_err;\n\t\t}\n\n\t\tlat_buf->slice_bc_addr.size = VDEC_LAT_SLICE_HEADER_SZ;\n\t\terr = mtk_vcodec_mem_alloc(ctx, &lat_buf->slice_bc_addr);\n\t\tif (err) {\n\t\t\tmtk_v4l2_vdec_err(ctx, \"failed to allocate wdma_addr buf[%d]\", i);\n\t\t\tgoto mem_alloc_err;\n\t\t}\n\n\t\tif (ctx->current_codec == V4L2_PIX_FMT_AV1_FRAME) {\n\t\t\tlat_buf->rd_mv_addr.size = VDEC_RD_MV_BUFFER_SZ;\n\t\t\terr = mtk_vcodec_mem_alloc(ctx, &lat_buf->rd_mv_addr);\n\t\t\tif (err) {\n\t\t\t\tmtk_v4l2_vdec_err(ctx, \"failed to allocate rd_mv_addr buf[%d]\", i);\n\t\t\t\tgoto mem_alloc_err;\n\t\t\t}\n\n\t\t\tlat_buf->tile_addr.size = VDEC_LAT_TILE_SZ;\n\t\t\terr = mtk_vcodec_mem_alloc(ctx, &lat_buf->tile_addr);\n\t\t\tif (err) {\n\t\t\t\tmtk_v4l2_vdec_err(ctx, \"failed to allocate tile_addr buf[%d]\", i);\n\t\t\t\tgoto mem_alloc_err;\n\t\t\t}\n\t\t}\n\n\t\tlat_buf->private_data = kzalloc(private_size, GFP_KERNEL);\n\t\tif (!lat_buf->private_data) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto mem_alloc_err;\n\t\t}\n\n\t\tlat_buf->ctx = ctx;\n\t\tlat_buf->core_decode = core_decode;\n\t\tlat_buf->is_last_frame = false;\n\t\terr = vdec_msg_queue_qbuf(&msg_queue->lat_ctx, lat_buf);\n\t\tif (err) {\n\t\t\tmtk_v4l2_vdec_err(ctx, \"failed to qbuf buf[%d]\", i);\n\t\t\tgoto mem_alloc_err;\n\t\t}\n\t}\n\treturn 0;\n\nmem_alloc_err:\n\tvdec_msg_queue_deinit(msg_queue, ctx);\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}