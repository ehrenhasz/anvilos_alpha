{
  "module_name": "vpu_cmds.c",
  "hash_id": "c6d758147ca9412edd30cef608672a5a32851bd91bb25c307d09179d56d6607b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/platform/amphion/vpu_cmds.c",
  "human_readable_source": "\n \n\n#include <linux/init.h>\n#include <linux/interconnect.h>\n#include <linux/ioctl.h>\n#include <linux/list.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/delay.h>\n#include <linux/vmalloc.h>\n#include \"vpu.h\"\n#include \"vpu_defs.h\"\n#include \"vpu_cmds.h\"\n#include \"vpu_rpc.h\"\n#include \"vpu_mbox.h\"\n\nstruct vpu_cmd_request {\n\tu32 request;\n\tu32 response;\n\tu32 handled;\n};\n\nstruct vpu_cmd_t {\n\tstruct list_head list;\n\tu32 id;\n\tstruct vpu_cmd_request *request;\n\tstruct vpu_rpc_event *pkt;\n\tunsigned long key;\n};\n\nstatic struct vpu_cmd_request vpu_cmd_requests[] = {\n\t{\n\t\t.request = VPU_CMD_ID_CONFIGURE_CODEC,\n\t\t.response = VPU_MSG_ID_MEM_REQUEST,\n\t\t.handled = 1,\n\t},\n\t{\n\t\t.request = VPU_CMD_ID_START,\n\t\t.response = VPU_MSG_ID_START_DONE,\n\t\t.handled = 0,\n\t},\n\t{\n\t\t.request = VPU_CMD_ID_STOP,\n\t\t.response = VPU_MSG_ID_STOP_DONE,\n\t\t.handled = 0,\n\t},\n\t{\n\t\t.request = VPU_CMD_ID_ABORT,\n\t\t.response = VPU_MSG_ID_ABORT_DONE,\n\t\t.handled = 0,\n\t},\n\t{\n\t\t.request = VPU_CMD_ID_RST_BUF,\n\t\t.response = VPU_MSG_ID_BUF_RST,\n\t\t.handled = 1,\n\t},\n};\n\nstatic int vpu_cmd_send(struct vpu_core *core, struct vpu_rpc_event *pkt)\n{\n\tint ret = 0;\n\n\tret = vpu_iface_send_cmd(core, pkt);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tmb();\n\tvpu_mbox_send_type(core, COMMAND);\n\n\treturn ret;\n}\n\nstatic struct vpu_cmd_t *vpu_alloc_cmd(struct vpu_inst *inst, u32 id, void *data)\n{\n\tstruct vpu_cmd_t *cmd;\n\tint i;\n\tint ret;\n\n\tcmd = vzalloc(sizeof(*cmd));\n\tif (!cmd)\n\t\treturn NULL;\n\n\tcmd->pkt = vzalloc(sizeof(*cmd->pkt));\n\tif (!cmd->pkt) {\n\t\tvfree(cmd);\n\t\treturn NULL;\n\t}\n\n\tcmd->id = id;\n\tret = vpu_iface_pack_cmd(inst->core, cmd->pkt, inst->id, id, data);\n\tif (ret) {\n\t\tdev_err(inst->dev, \"iface pack cmd %s fail\\n\", vpu_id_name(id));\n\t\tvfree(cmd->pkt);\n\t\tvfree(cmd);\n\t\treturn NULL;\n\t}\n\tfor (i = 0; i < ARRAY_SIZE(vpu_cmd_requests); i++) {\n\t\tif (vpu_cmd_requests[i].request == id) {\n\t\t\tcmd->request = &vpu_cmd_requests[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn cmd;\n}\n\nstatic void vpu_free_cmd(struct vpu_cmd_t *cmd)\n{\n\tif (!cmd)\n\t\treturn;\n\tvfree(cmd->pkt);\n\tvfree(cmd);\n}\n\nstatic int vpu_session_process_cmd(struct vpu_inst *inst, struct vpu_cmd_t *cmd)\n{\n\tint ret;\n\n\tdev_dbg(inst->dev, \"[%d]send cmd %s\\n\", inst->id, vpu_id_name(cmd->id));\n\tvpu_iface_pre_send_cmd(inst);\n\tret = vpu_cmd_send(inst->core, cmd->pkt);\n\tif (!ret) {\n\t\tvpu_iface_post_send_cmd(inst);\n\t\tvpu_inst_record_flow(inst, cmd->id);\n\t} else {\n\t\tdev_err(inst->dev, \"[%d] iface send cmd %s fail\\n\", inst->id, vpu_id_name(cmd->id));\n\t}\n\n\treturn ret;\n}\n\nstatic void vpu_process_cmd_request(struct vpu_inst *inst)\n{\n\tstruct vpu_cmd_t *cmd;\n\tstruct vpu_cmd_t *tmp;\n\n\tif (!inst || inst->pending)\n\t\treturn;\n\n\tlist_for_each_entry_safe(cmd, tmp, &inst->cmd_q, list) {\n\t\tlist_del_init(&cmd->list);\n\t\tif (vpu_session_process_cmd(inst, cmd))\n\t\t\tdev_err(inst->dev, \"[%d] process cmd %s fail\\n\",\n\t\t\t\tinst->id, vpu_id_name(cmd->id));\n\t\tif (cmd->request) {\n\t\t\tinst->pending = (void *)cmd;\n\t\t\tbreak;\n\t\t}\n\t\tvpu_free_cmd(cmd);\n\t}\n}\n\nstatic int vpu_request_cmd(struct vpu_inst *inst, u32 id, void *data,\n\t\t\t   unsigned long *key, int *sync)\n{\n\tstruct vpu_core *core;\n\tstruct vpu_cmd_t *cmd;\n\n\tif (!inst || !inst->core)\n\t\treturn -EINVAL;\n\n\tcore = inst->core;\n\tcmd = vpu_alloc_cmd(inst, id, data);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&core->cmd_lock);\n\tcmd->key = core->cmd_seq++;\n\tif (key)\n\t\t*key = cmd->key;\n\tif (sync)\n\t\t*sync = cmd->request ? true : false;\n\tlist_add_tail(&cmd->list, &inst->cmd_q);\n\tvpu_process_cmd_request(inst);\n\tmutex_unlock(&core->cmd_lock);\n\n\treturn 0;\n}\n\nstatic void vpu_clear_pending(struct vpu_inst *inst)\n{\n\tif (!inst || !inst->pending)\n\t\treturn;\n\n\tvpu_free_cmd(inst->pending);\n\twake_up_all(&inst->core->ack_wq);\n\tinst->pending = NULL;\n}\n\nstatic bool vpu_check_response(struct vpu_cmd_t *cmd, u32 response, u32 handled)\n{\n\tstruct vpu_cmd_request *request;\n\n\tif (!cmd || !cmd->request)\n\t\treturn false;\n\n\trequest = cmd->request;\n\tif (request->response != response)\n\t\treturn false;\n\tif (request->handled != handled)\n\t\treturn false;\n\n\treturn true;\n}\n\nint vpu_response_cmd(struct vpu_inst *inst, u32 response, u32 handled)\n{\n\tstruct vpu_core *core;\n\n\tif (!inst || !inst->core)\n\t\treturn -EINVAL;\n\n\tcore = inst->core;\n\tmutex_lock(&core->cmd_lock);\n\tif (vpu_check_response(inst->pending, response, handled))\n\t\tvpu_clear_pending(inst);\n\n\tvpu_process_cmd_request(inst);\n\tmutex_unlock(&core->cmd_lock);\n\n\treturn 0;\n}\n\nvoid vpu_clear_request(struct vpu_inst *inst)\n{\n\tstruct vpu_cmd_t *cmd;\n\tstruct vpu_cmd_t *tmp;\n\n\tmutex_lock(&inst->core->cmd_lock);\n\tif (inst->pending)\n\t\tvpu_clear_pending(inst);\n\n\tlist_for_each_entry_safe(cmd, tmp, &inst->cmd_q, list) {\n\t\tlist_del_init(&cmd->list);\n\t\tvpu_free_cmd(cmd);\n\t}\n\tmutex_unlock(&inst->core->cmd_lock);\n}\n\nstatic bool check_is_responsed(struct vpu_inst *inst, unsigned long key)\n{\n\tstruct vpu_core *core = inst->core;\n\tstruct vpu_cmd_t *cmd;\n\tbool flag = true;\n\n\tmutex_lock(&core->cmd_lock);\n\tcmd = inst->pending;\n\tif (cmd && key == cmd->key) {\n\t\tflag = false;\n\t\tgoto exit;\n\t}\n\tlist_for_each_entry(cmd, &inst->cmd_q, list) {\n\t\tif (key == cmd->key) {\n\t\t\tflag = false;\n\t\t\tbreak;\n\t\t}\n\t}\nexit:\n\tmutex_unlock(&core->cmd_lock);\n\n\treturn flag;\n}\n\nstatic int sync_session_response(struct vpu_inst *inst, unsigned long key, long timeout, int try)\n{\n\tstruct vpu_core *core;\n\n\tif (!inst || !inst->core)\n\t\treturn -EINVAL;\n\n\tcore = inst->core;\n\n\tcall_void_vop(inst, wait_prepare);\n\twait_event_timeout(core->ack_wq, check_is_responsed(inst, key), timeout);\n\tcall_void_vop(inst, wait_finish);\n\n\tif (!check_is_responsed(inst, key)) {\n\t\tif (try)\n\t\t\treturn -EINVAL;\n\t\tdev_err(inst->dev, \"[%d] sync session timeout\\n\", inst->id);\n\t\tset_bit(inst->id, &core->hang_mask);\n\t\tmutex_lock(&inst->core->cmd_lock);\n\t\tvpu_clear_pending(inst);\n\t\tmutex_unlock(&inst->core->cmd_lock);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void vpu_core_keep_active(struct vpu_core *core)\n{\n\tstruct vpu_rpc_event pkt;\n\n\tmemset(&pkt, 0, sizeof(pkt));\n\tvpu_iface_pack_cmd(core, &pkt, 0, VPU_CMD_ID_NOOP, NULL);\n\n\tdev_dbg(core->dev, \"try to wake up\\n\");\n\tmutex_lock(&core->cmd_lock);\n\tif (vpu_cmd_send(core, &pkt))\n\t\tdev_err(core->dev, \"fail to keep active\\n\");\n\tmutex_unlock(&core->cmd_lock);\n}\n\nstatic int vpu_session_send_cmd(struct vpu_inst *inst, u32 id, void *data)\n{\n\tunsigned long key;\n\tint sync = false;\n\tint ret;\n\n\tif (inst->id < 0)\n\t\treturn -EINVAL;\n\n\tret = vpu_request_cmd(inst, id, data, &key, &sync);\n\tif (ret)\n\t\tgoto exit;\n\n\t \n\tif (sync && (id == VPU_CMD_ID_CONFIGURE_CODEC || id == VPU_CMD_ID_START)) {\n\t\tif (sync_session_response(inst, key, VPU_TIMEOUT_WAKEUP, 1))\n\t\t\tvpu_core_keep_active(inst->core);\n\t\telse\n\t\t\tgoto exit;\n\t}\n\n\tif (sync)\n\t\tret = sync_session_response(inst, key, VPU_TIMEOUT, 0);\n\nexit:\n\tif (ret)\n\t\tdev_err(inst->dev, \"[%d] send cmd %s fail\\n\", inst->id, vpu_id_name(id));\n\n\treturn ret;\n}\n\nint vpu_session_configure_codec(struct vpu_inst *inst)\n{\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_CONFIGURE_CODEC, NULL);\n}\n\nint vpu_session_start(struct vpu_inst *inst)\n{\n\tvpu_trace(inst->dev, \"[%d]\\n\", inst->id);\n\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_START, NULL);\n}\n\nint vpu_session_stop(struct vpu_inst *inst)\n{\n\tint ret;\n\n\tvpu_trace(inst->dev, \"[%d]\\n\", inst->id);\n\n\tret = vpu_session_send_cmd(inst, VPU_CMD_ID_STOP, NULL);\n\t \n\tusleep_range(3000, 5000);\n\treturn ret;\n}\n\nint vpu_session_encode_frame(struct vpu_inst *inst, s64 timestamp)\n{\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_FRAME_ENCODE, &timestamp);\n}\n\nint vpu_session_alloc_fs(struct vpu_inst *inst, struct vpu_fs_info *fs)\n{\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_FS_ALLOC, fs);\n}\n\nint vpu_session_release_fs(struct vpu_inst *inst, struct vpu_fs_info *fs)\n{\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_FS_RELEASE, fs);\n}\n\nint vpu_session_abort(struct vpu_inst *inst)\n{\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_ABORT, NULL);\n}\n\nint vpu_session_rst_buf(struct vpu_inst *inst)\n{\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_RST_BUF, NULL);\n}\n\nint vpu_session_fill_timestamp(struct vpu_inst *inst, struct vpu_ts_info *info)\n{\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_TIMESTAMP, info);\n}\n\nint vpu_session_update_parameters(struct vpu_inst *inst, void *arg)\n{\n\tif (inst->type & VPU_CORE_TYPE_DEC)\n\t\tvpu_iface_set_decode_params(inst, arg, 1);\n\telse\n\t\tvpu_iface_set_encode_params(inst, arg, 1);\n\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_UPDATE_PARAMETER, arg);\n}\n\nint vpu_session_debug(struct vpu_inst *inst)\n{\n\treturn vpu_session_send_cmd(inst, VPU_CMD_ID_DEBUG, NULL);\n}\n\nint vpu_core_snapshot(struct vpu_core *core)\n{\n\tstruct vpu_inst *inst;\n\tint ret;\n\n\tif (!core || list_empty(&core->instances))\n\t\treturn 0;\n\n\tinst = list_first_entry(&core->instances, struct vpu_inst, list);\n\n\treinit_completion(&core->cmp);\n\tret = vpu_session_send_cmd(inst, VPU_CMD_ID_SNAPSHOT, NULL);\n\tif (ret)\n\t\treturn ret;\n\tret = wait_for_completion_timeout(&core->cmp, VPU_TIMEOUT);\n\tif (!ret) {\n\t\tdev_err(core->dev, \"snapshot timeout\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nint vpu_core_sw_reset(struct vpu_core *core)\n{\n\tstruct vpu_rpc_event pkt;\n\tint ret;\n\n\tmemset(&pkt, 0, sizeof(pkt));\n\tvpu_iface_pack_cmd(core, &pkt, 0, VPU_CMD_ID_FIRM_RESET, NULL);\n\n\treinit_completion(&core->cmp);\n\tmutex_lock(&core->cmd_lock);\n\tret = vpu_cmd_send(core, &pkt);\n\tmutex_unlock(&core->cmd_lock);\n\tif (ret)\n\t\treturn ret;\n\tret = wait_for_completion_timeout(&core->cmp, VPU_TIMEOUT);\n\tif (!ret) {\n\t\tdev_err(core->dev, \"sw reset timeout\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}