{
  "module_name": "vivid-vid-cap.c",
  "hash_id": "1c057badf733c2851746a6654b3c0ee0b5bd8cb1530c31cf0052dacb52317866",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/test-drivers/vivid/vivid-vid-cap.c",
  "human_readable_source": "\n \n\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/sched.h>\n#include <linux/vmalloc.h>\n#include <linux/videodev2.h>\n#include <linux/v4l2-dv-timings.h>\n#include <media/v4l2-common.h>\n#include <media/v4l2-event.h>\n#include <media/v4l2-dv-timings.h>\n#include <media/v4l2-rect.h>\n\n#include \"vivid-core.h\"\n#include \"vivid-vid-common.h\"\n#include \"vivid-kthread-cap.h\"\n#include \"vivid-vid-cap.h\"\n\n \nstatic const struct v4l2_frmsize_discrete webcam_sizes[] = {\n\t{  320, 180 },\n\t{  640, 360 },\n\t{  640, 480 },\n\t{ 1280, 720 },\n\t{ 1920, 1080 },\n\t{ 3840, 2160 },\n};\n\n \nstatic const struct v4l2_fract webcam_intervals[] = {\n\t{  1, 1 },\n\t{  1, 2 },\n\t{  1, 4 },\n\t{  1, 5 },\n\t{  1, 10 },\n\t{  2, 25 },\n\t{  1, 15 },  \n\t{  1, 25 },\n\t{  1, 30 },  \n\t{  1, 40 },\n\t{  1, 50 },\n\t{  1, 60 },  \n\t{  1, 120 },\n};\n\n \n#define IVAL_COUNT_720P 12  \n#define IVAL_COUNT_1080P 9  \n#define IVAL_COUNT_2160P 7  \n\nstatic inline unsigned int webcam_ival_count(const struct vivid_dev *dev,\n\t\t\t\t\t     unsigned int frmsize_idx)\n{\n\tif (webcam_sizes[frmsize_idx].height >= 2160)\n\t\treturn IVAL_COUNT_2160P;\n\n\tif (webcam_sizes[frmsize_idx].height >= 1080)\n\t\treturn IVAL_COUNT_1080P;\n\n\tif (webcam_sizes[frmsize_idx].height >= 720)\n\t\treturn IVAL_COUNT_720P;\n\n\t \n\treturn ARRAY_SIZE(webcam_intervals);\n}\n\nstatic int vid_cap_queue_setup(struct vb2_queue *vq,\n\t\t       unsigned *nbuffers, unsigned *nplanes,\n\t\t       unsigned sizes[], struct device *alloc_devs[])\n{\n\tstruct vivid_dev *dev = vb2_get_drv_priv(vq);\n\tunsigned buffers = tpg_g_buffers(&dev->tpg);\n\tunsigned h = dev->fmt_cap_rect.height;\n\tunsigned p;\n\n\tif (dev->field_cap == V4L2_FIELD_ALTERNATE) {\n\t\t \n\t\tif (vb2_fileio_is_active(vq))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (dev->queue_setup_error) {\n\t\t \n\t\tdev->queue_setup_error = false;\n\t\treturn -EINVAL;\n\t}\n\tif (*nplanes) {\n\t\t \n\t\tif (*nplanes != buffers)\n\t\t\treturn -EINVAL;\n\t\tfor (p = 0; p < buffers; p++) {\n\t\t\tif (sizes[p] < tpg_g_line_width(&dev->tpg, p) * h +\n\t\t\t\t\t\tdev->fmt_cap->data_offset[p])\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tfor (p = 0; p < buffers; p++)\n\t\t\tsizes[p] = (tpg_g_line_width(&dev->tpg, p) * h) /\n\t\t\t\t\tdev->fmt_cap->vdownsampling[p] +\n\t\t\t\t\tdev->fmt_cap->data_offset[p];\n\t}\n\n\tif (vq->num_buffers + *nbuffers < 2)\n\t\t*nbuffers = 2 - vq->num_buffers;\n\n\t*nplanes = buffers;\n\n\tdprintk(dev, 1, \"%s: count=%d\\n\", __func__, *nbuffers);\n\tfor (p = 0; p < buffers; p++)\n\t\tdprintk(dev, 1, \"%s: size[%u]=%u\\n\", __func__, p, sizes[p]);\n\n\treturn 0;\n}\n\nstatic int vid_cap_buf_prepare(struct vb2_buffer *vb)\n{\n\tstruct vivid_dev *dev = vb2_get_drv_priv(vb->vb2_queue);\n\tunsigned long size;\n\tunsigned buffers = tpg_g_buffers(&dev->tpg);\n\tunsigned p;\n\n\tdprintk(dev, 1, \"%s\\n\", __func__);\n\n\tif (WARN_ON(NULL == dev->fmt_cap))\n\t\treturn -EINVAL;\n\n\tif (dev->buf_prepare_error) {\n\t\t \n\t\tdev->buf_prepare_error = false;\n\t\treturn -EINVAL;\n\t}\n\tfor (p = 0; p < buffers; p++) {\n\t\tsize = (tpg_g_line_width(&dev->tpg, p) *\n\t\t\tdev->fmt_cap_rect.height) /\n\t\t\tdev->fmt_cap->vdownsampling[p] +\n\t\t\tdev->fmt_cap->data_offset[p];\n\n\t\tif (vb2_plane_size(vb, p) < size) {\n\t\t\tdprintk(dev, 1, \"%s data will not fit into plane %u (%lu < %lu)\\n\",\n\t\t\t\t\t__func__, p, vb2_plane_size(vb, p), size);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tvb2_set_plane_payload(vb, p, size);\n\t\tvb->planes[p].data_offset = dev->fmt_cap->data_offset[p];\n\t}\n\n\treturn 0;\n}\n\nstatic void vid_cap_buf_finish(struct vb2_buffer *vb)\n{\n\tstruct vb2_v4l2_buffer *vbuf = to_vb2_v4l2_buffer(vb);\n\tstruct vivid_dev *dev = vb2_get_drv_priv(vb->vb2_queue);\n\tstruct v4l2_timecode *tc = &vbuf->timecode;\n\tunsigned fps = 25;\n\tunsigned seq = vbuf->sequence;\n\n\tif (!vivid_is_sdtv_cap(dev))\n\t\treturn;\n\n\t \n\tvbuf->flags |= V4L2_BUF_FLAG_TIMECODE;\n\tif (dev->std_cap[dev->input] & V4L2_STD_525_60)\n\t\tfps = 30;\n\ttc->type = (fps == 30) ? V4L2_TC_TYPE_30FPS : V4L2_TC_TYPE_25FPS;\n\ttc->flags = 0;\n\ttc->frames = seq % fps;\n\ttc->seconds = (seq / fps) % 60;\n\ttc->minutes = (seq / (60 * fps)) % 60;\n\ttc->hours = (seq / (60 * 60 * fps)) % 24;\n}\n\nstatic void vid_cap_buf_queue(struct vb2_buffer *vb)\n{\n\tstruct vb2_v4l2_buffer *vbuf = to_vb2_v4l2_buffer(vb);\n\tstruct vivid_dev *dev = vb2_get_drv_priv(vb->vb2_queue);\n\tstruct vivid_buffer *buf = container_of(vbuf, struct vivid_buffer, vb);\n\n\tdprintk(dev, 1, \"%s\\n\", __func__);\n\n\tspin_lock(&dev->slock);\n\tlist_add_tail(&buf->list, &dev->vid_cap_active);\n\tspin_unlock(&dev->slock);\n}\n\nstatic int vid_cap_start_streaming(struct vb2_queue *vq, unsigned count)\n{\n\tstruct vivid_dev *dev = vb2_get_drv_priv(vq);\n\tunsigned i;\n\tint err;\n\n\tif (vb2_is_streaming(&dev->vb_vid_out_q))\n\t\tdev->can_loop_video = vivid_vid_can_loop(dev);\n\n\tdev->vid_cap_seq_count = 0;\n\tdprintk(dev, 1, \"%s\\n\", __func__);\n\tfor (i = 0; i < VIDEO_MAX_FRAME; i++)\n\t\tdev->must_blank[i] = tpg_g_perc_fill(&dev->tpg) < 100;\n\tif (dev->start_streaming_error) {\n\t\tdev->start_streaming_error = false;\n\t\terr = -EINVAL;\n\t} else {\n\t\terr = vivid_start_generating_vid_cap(dev, &dev->vid_cap_streaming);\n\t}\n\tif (err) {\n\t\tstruct vivid_buffer *buf, *tmp;\n\n\t\tlist_for_each_entry_safe(buf, tmp, &dev->vid_cap_active, list) {\n\t\t\tlist_del(&buf->list);\n\t\t\tvb2_buffer_done(&buf->vb.vb2_buf,\n\t\t\t\t\tVB2_BUF_STATE_QUEUED);\n\t\t}\n\t}\n\treturn err;\n}\n\n \nstatic void vid_cap_stop_streaming(struct vb2_queue *vq)\n{\n\tstruct vivid_dev *dev = vb2_get_drv_priv(vq);\n\n\tdprintk(dev, 1, \"%s\\n\", __func__);\n\tvivid_stop_generating_vid_cap(dev, &dev->vid_cap_streaming);\n\tdev->can_loop_video = false;\n}\n\nstatic void vid_cap_buf_request_complete(struct vb2_buffer *vb)\n{\n\tstruct vivid_dev *dev = vb2_get_drv_priv(vb->vb2_queue);\n\n\tv4l2_ctrl_request_complete(vb->req_obj.req, &dev->ctrl_hdl_vid_cap);\n}\n\nconst struct vb2_ops vivid_vid_cap_qops = {\n\t.queue_setup\t\t= vid_cap_queue_setup,\n\t.buf_prepare\t\t= vid_cap_buf_prepare,\n\t.buf_finish\t\t= vid_cap_buf_finish,\n\t.buf_queue\t\t= vid_cap_buf_queue,\n\t.start_streaming\t= vid_cap_start_streaming,\n\t.stop_streaming\t\t= vid_cap_stop_streaming,\n\t.buf_request_complete\t= vid_cap_buf_request_complete,\n\t.wait_prepare\t\t= vb2_ops_wait_prepare,\n\t.wait_finish\t\t= vb2_ops_wait_finish,\n};\n\n \nvoid vivid_update_quality(struct vivid_dev *dev)\n{\n\tunsigned freq_modulus;\n\n\tif (dev->loop_video && (vivid_is_svid_cap(dev) || vivid_is_hdmi_cap(dev))) {\n\t\t \n\t\ttpg_s_quality(&dev->tpg, TPG_QUAL_NOISE, 0);\n\t\treturn;\n\t}\n\tif (vivid_is_hdmi_cap(dev) &&\n\t    VIVID_INVALID_SIGNAL(dev->dv_timings_signal_mode[dev->input])) {\n\t\ttpg_s_quality(&dev->tpg, TPG_QUAL_NOISE, 0);\n\t\treturn;\n\t}\n\tif (vivid_is_sdtv_cap(dev) &&\n\t    VIVID_INVALID_SIGNAL(dev->std_signal_mode[dev->input])) {\n\t\ttpg_s_quality(&dev->tpg, TPG_QUAL_NOISE, 0);\n\t\treturn;\n\t}\n\tif (!vivid_is_tv_cap(dev)) {\n\t\ttpg_s_quality(&dev->tpg, TPG_QUAL_COLOR, 0);\n\t\treturn;\n\t}\n\n\t \n\tfreq_modulus = (dev->tv_freq - 676  ) % (6 * 16);\n\tif (freq_modulus > 2 * 16) {\n\t\ttpg_s_quality(&dev->tpg, TPG_QUAL_NOISE,\n\t\t\tnext_pseudo_random32(dev->tv_freq ^ 0x55) & 0x3f);\n\t\treturn;\n\t}\n\tif (freq_modulus < 12   || freq_modulus > 20  )\n\t\ttpg_s_quality(&dev->tpg, TPG_QUAL_GRAY, 0);\n\telse\n\t\ttpg_s_quality(&dev->tpg, TPG_QUAL_COLOR, 0);\n}\n\n \nstatic enum tpg_quality vivid_get_quality(struct vivid_dev *dev, s32 *afc)\n{\n\tunsigned freq_modulus;\n\n\tif (afc)\n\t\t*afc = 0;\n\tif (tpg_g_quality(&dev->tpg) == TPG_QUAL_COLOR ||\n\t    tpg_g_quality(&dev->tpg) == TPG_QUAL_NOISE)\n\t\treturn tpg_g_quality(&dev->tpg);\n\n\t \n\tfreq_modulus = (dev->tv_freq - 676  ) % (6 * 16);\n\tif (afc)\n\t\t*afc = freq_modulus - 1 * 16;\n\treturn TPG_QUAL_GRAY;\n}\n\nenum tpg_video_aspect vivid_get_video_aspect(const struct vivid_dev *dev)\n{\n\tif (vivid_is_sdtv_cap(dev))\n\t\treturn dev->std_aspect_ratio[dev->input];\n\n\tif (vivid_is_hdmi_cap(dev))\n\t\treturn dev->dv_timings_aspect_ratio[dev->input];\n\n\treturn TPG_VIDEO_ASPECT_IMAGE;\n}\n\nstatic enum tpg_pixel_aspect vivid_get_pixel_aspect(const struct vivid_dev *dev)\n{\n\tif (vivid_is_sdtv_cap(dev))\n\t\treturn (dev->std_cap[dev->input] & V4L2_STD_525_60) ?\n\t\t\tTPG_PIXEL_ASPECT_NTSC : TPG_PIXEL_ASPECT_PAL;\n\n\tif (vivid_is_hdmi_cap(dev) &&\n\t    dev->src_rect.width == 720 && dev->src_rect.height <= 576)\n\t\treturn dev->src_rect.height == 480 ?\n\t\t\tTPG_PIXEL_ASPECT_NTSC : TPG_PIXEL_ASPECT_PAL;\n\n\treturn TPG_PIXEL_ASPECT_SQUARE;\n}\n\n \nvoid vivid_update_format_cap(struct vivid_dev *dev, bool keep_controls)\n{\n\tstruct v4l2_bt_timings *bt = &dev->dv_timings_cap[dev->input].bt;\n\tu32 dims[V4L2_CTRL_MAX_DIMS] = {};\n\tunsigned size;\n\tu64 pixelclock;\n\n\tswitch (dev->input_type[dev->input]) {\n\tcase WEBCAM:\n\tdefault:\n\t\tdev->src_rect.width = webcam_sizes[dev->webcam_size_idx].width;\n\t\tdev->src_rect.height = webcam_sizes[dev->webcam_size_idx].height;\n\t\tdev->timeperframe_vid_cap = webcam_intervals[dev->webcam_ival_idx];\n\t\tdev->field_cap = V4L2_FIELD_NONE;\n\t\ttpg_s_rgb_range(&dev->tpg, V4L2_DV_RGB_RANGE_AUTO);\n\t\tbreak;\n\tcase TV:\n\tcase SVID:\n\t\tdev->field_cap = dev->tv_field_cap;\n\t\tdev->src_rect.width = 720;\n\t\tif (dev->std_cap[dev->input] & V4L2_STD_525_60) {\n\t\t\tdev->src_rect.height = 480;\n\t\t\tdev->timeperframe_vid_cap = (struct v4l2_fract) { 1001, 30000 };\n\t\t\tdev->service_set_cap = V4L2_SLICED_CAPTION_525;\n\t\t} else {\n\t\t\tdev->src_rect.height = 576;\n\t\t\tdev->timeperframe_vid_cap = (struct v4l2_fract) { 1000, 25000 };\n\t\t\tdev->service_set_cap = V4L2_SLICED_WSS_625 | V4L2_SLICED_TELETEXT_B;\n\t\t}\n\t\ttpg_s_rgb_range(&dev->tpg, V4L2_DV_RGB_RANGE_AUTO);\n\t\tbreak;\n\tcase HDMI:\n\t\tdev->src_rect.width = bt->width;\n\t\tdev->src_rect.height = bt->height;\n\t\tsize = V4L2_DV_BT_FRAME_WIDTH(bt) * V4L2_DV_BT_FRAME_HEIGHT(bt);\n\t\tif (dev->reduced_fps && can_reduce_fps(bt)) {\n\t\t\tpixelclock = div_u64(bt->pixelclock * 1000, 1001);\n\t\t\tbt->flags |= V4L2_DV_FL_REDUCED_FPS;\n\t\t} else {\n\t\t\tpixelclock = bt->pixelclock;\n\t\t\tbt->flags &= ~V4L2_DV_FL_REDUCED_FPS;\n\t\t}\n\t\tdev->timeperframe_vid_cap = (struct v4l2_fract) {\n\t\t\tsize / 100, (u32)pixelclock / 100\n\t\t};\n\t\tif (bt->interlaced)\n\t\t\tdev->field_cap = V4L2_FIELD_ALTERNATE;\n\t\telse\n\t\t\tdev->field_cap = V4L2_FIELD_NONE;\n\n\t\t \n\t\tif (keep_controls || !dev->colorspace)\n\t\t\tbreak;\n\t\tif (bt->flags & V4L2_DV_FL_IS_CE_VIDEO) {\n\t\t\tif (bt->width == 720 && bt->height <= 576)\n\t\t\t\tv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_170M);\n\t\t\telse\n\t\t\t\tv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_709);\n\t\t\tv4l2_ctrl_s_ctrl(dev->real_rgb_range_cap, 1);\n\t\t} else {\n\t\t\tv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_SRGB);\n\t\t\tv4l2_ctrl_s_ctrl(dev->real_rgb_range_cap, 0);\n\t\t}\n\t\ttpg_s_rgb_range(&dev->tpg, v4l2_ctrl_g_ctrl(dev->rgb_range_cap));\n\t\tbreak;\n\t}\n\tvivid_update_quality(dev);\n\ttpg_reset_source(&dev->tpg, dev->src_rect.width, dev->src_rect.height, dev->field_cap);\n\tdev->crop_cap = dev->src_rect;\n\tdev->crop_bounds_cap = dev->src_rect;\n\tdev->compose_cap = dev->crop_cap;\n\tif (V4L2_FIELD_HAS_T_OR_B(dev->field_cap))\n\t\tdev->compose_cap.height /= 2;\n\tdev->fmt_cap_rect = dev->compose_cap;\n\ttpg_s_video_aspect(&dev->tpg, vivid_get_video_aspect(dev));\n\ttpg_s_pixel_aspect(&dev->tpg, vivid_get_pixel_aspect(dev));\n\ttpg_update_mv_step(&dev->tpg);\n\n\t \n\tif (keep_controls)\n\t\treturn;\n\n\tdims[0] = roundup(dev->src_rect.width, PIXEL_ARRAY_DIV);\n\tdims[1] = roundup(dev->src_rect.height, PIXEL_ARRAY_DIV);\n\tv4l2_ctrl_modify_dimensions(dev->pixel_array, dims);\n}\n\n \nstatic enum v4l2_field vivid_field_cap(struct vivid_dev *dev, enum v4l2_field field)\n{\n\tif (vivid_is_sdtv_cap(dev)) {\n\t\tswitch (field) {\n\t\tcase V4L2_FIELD_INTERLACED_TB:\n\t\tcase V4L2_FIELD_INTERLACED_BT:\n\t\tcase V4L2_FIELD_SEQ_TB:\n\t\tcase V4L2_FIELD_SEQ_BT:\n\t\tcase V4L2_FIELD_TOP:\n\t\tcase V4L2_FIELD_BOTTOM:\n\t\tcase V4L2_FIELD_ALTERNATE:\n\t\t\treturn field;\n\t\tcase V4L2_FIELD_INTERLACED:\n\t\tdefault:\n\t\t\treturn V4L2_FIELD_INTERLACED;\n\t\t}\n\t}\n\tif (vivid_is_hdmi_cap(dev))\n\t\treturn dev->dv_timings_cap[dev->input].bt.interlaced ?\n\t\t\tV4L2_FIELD_ALTERNATE : V4L2_FIELD_NONE;\n\treturn V4L2_FIELD_NONE;\n}\n\nstatic unsigned vivid_colorspace_cap(struct vivid_dev *dev)\n{\n\tif (!dev->loop_video || vivid_is_webcam(dev) || vivid_is_tv_cap(dev))\n\t\treturn tpg_g_colorspace(&dev->tpg);\n\treturn dev->colorspace_out;\n}\n\nstatic unsigned vivid_xfer_func_cap(struct vivid_dev *dev)\n{\n\tif (!dev->loop_video || vivid_is_webcam(dev) || vivid_is_tv_cap(dev))\n\t\treturn tpg_g_xfer_func(&dev->tpg);\n\treturn dev->xfer_func_out;\n}\n\nstatic unsigned vivid_ycbcr_enc_cap(struct vivid_dev *dev)\n{\n\tif (!dev->loop_video || vivid_is_webcam(dev) || vivid_is_tv_cap(dev))\n\t\treturn tpg_g_ycbcr_enc(&dev->tpg);\n\treturn dev->ycbcr_enc_out;\n}\n\nstatic unsigned int vivid_hsv_enc_cap(struct vivid_dev *dev)\n{\n\tif (!dev->loop_video || vivid_is_webcam(dev) || vivid_is_tv_cap(dev))\n\t\treturn tpg_g_hsv_enc(&dev->tpg);\n\treturn dev->hsv_enc_out;\n}\n\nstatic unsigned vivid_quantization_cap(struct vivid_dev *dev)\n{\n\tif (!dev->loop_video || vivid_is_webcam(dev) || vivid_is_tv_cap(dev))\n\t\treturn tpg_g_quantization(&dev->tpg);\n\treturn dev->quantization_out;\n}\n\nint vivid_g_fmt_vid_cap(struct file *file, void *priv,\n\t\t\t\t\tstruct v4l2_format *f)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tstruct v4l2_pix_format_mplane *mp = &f->fmt.pix_mp;\n\tunsigned p;\n\n\tmp->width        = dev->fmt_cap_rect.width;\n\tmp->height       = dev->fmt_cap_rect.height;\n\tmp->field        = dev->field_cap;\n\tmp->pixelformat  = dev->fmt_cap->fourcc;\n\tmp->colorspace   = vivid_colorspace_cap(dev);\n\tmp->xfer_func    = vivid_xfer_func_cap(dev);\n\tif (dev->fmt_cap->color_enc == TGP_COLOR_ENC_HSV)\n\t\tmp->hsv_enc    = vivid_hsv_enc_cap(dev);\n\telse\n\t\tmp->ycbcr_enc    = vivid_ycbcr_enc_cap(dev);\n\tmp->quantization = vivid_quantization_cap(dev);\n\tmp->num_planes = dev->fmt_cap->buffers;\n\tfor (p = 0; p < mp->num_planes; p++) {\n\t\tmp->plane_fmt[p].bytesperline = tpg_g_bytesperline(&dev->tpg, p);\n\t\tmp->plane_fmt[p].sizeimage =\n\t\t\t(tpg_g_line_width(&dev->tpg, p) * mp->height) /\n\t\t\tdev->fmt_cap->vdownsampling[p] +\n\t\t\tdev->fmt_cap->data_offset[p];\n\t}\n\treturn 0;\n}\n\nint vivid_try_fmt_vid_cap(struct file *file, void *priv,\n\t\t\tstruct v4l2_format *f)\n{\n\tstruct v4l2_pix_format_mplane *mp = &f->fmt.pix_mp;\n\tstruct v4l2_plane_pix_format *pfmt = mp->plane_fmt;\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tconst struct vivid_fmt *fmt;\n\tunsigned bytesperline, max_bpl;\n\tunsigned factor = 1;\n\tunsigned w, h;\n\tunsigned p;\n\tbool user_set_csc = !!(mp->flags & V4L2_PIX_FMT_FLAG_SET_CSC);\n\n\tfmt = vivid_get_format(dev, mp->pixelformat);\n\tif (!fmt) {\n\t\tdprintk(dev, 1, \"Fourcc format (0x%08x) unknown.\\n\",\n\t\t\tmp->pixelformat);\n\t\tmp->pixelformat = V4L2_PIX_FMT_YUYV;\n\t\tfmt = vivid_get_format(dev, mp->pixelformat);\n\t}\n\n\tmp->field = vivid_field_cap(dev, mp->field);\n\tif (vivid_is_webcam(dev)) {\n\t\tconst struct v4l2_frmsize_discrete *sz =\n\t\t\tv4l2_find_nearest_size(webcam_sizes,\n\t\t\t\t\t       ARRAY_SIZE(webcam_sizes), width,\n\t\t\t\t\t       height, mp->width, mp->height);\n\n\t\tw = sz->width;\n\t\th = sz->height;\n\t} else if (vivid_is_sdtv_cap(dev)) {\n\t\tw = 720;\n\t\th = (dev->std_cap[dev->input] & V4L2_STD_525_60) ? 480 : 576;\n\t} else {\n\t\tw = dev->src_rect.width;\n\t\th = dev->src_rect.height;\n\t}\n\tif (V4L2_FIELD_HAS_T_OR_B(mp->field))\n\t\tfactor = 2;\n\tif (vivid_is_webcam(dev) ||\n\t    (!dev->has_scaler_cap && !dev->has_crop_cap && !dev->has_compose_cap)) {\n\t\tmp->width = w;\n\t\tmp->height = h / factor;\n\t} else {\n\t\tstruct v4l2_rect r = { 0, 0, mp->width, mp->height * factor };\n\n\t\tv4l2_rect_set_min_size(&r, &vivid_min_rect);\n\t\tv4l2_rect_set_max_size(&r, &vivid_max_rect);\n\t\tif (dev->has_scaler_cap && !dev->has_compose_cap) {\n\t\t\tstruct v4l2_rect max_r = { 0, 0, MAX_ZOOM * w, MAX_ZOOM * h };\n\n\t\t\tv4l2_rect_set_max_size(&r, &max_r);\n\t\t} else if (!dev->has_scaler_cap && dev->has_crop_cap && !dev->has_compose_cap) {\n\t\t\tv4l2_rect_set_max_size(&r, &dev->src_rect);\n\t\t} else if (!dev->has_scaler_cap && !dev->has_crop_cap) {\n\t\t\tv4l2_rect_set_min_size(&r, &dev->src_rect);\n\t\t}\n\t\tmp->width = r.width;\n\t\tmp->height = r.height / factor;\n\t}\n\n\t \n\n\tmp->num_planes = fmt->buffers;\n\tfor (p = 0; p < fmt->buffers; p++) {\n\t\t \n\t\tbytesperline = (mp->width * fmt->bit_depth[p]) >> 3;\n\t\t \n\t\tmax_bpl = (MAX_ZOOM * MAX_WIDTH * fmt->bit_depth[p]) >> 3;\n\n\t\tif (pfmt[p].bytesperline > max_bpl)\n\t\t\tpfmt[p].bytesperline = max_bpl;\n\t\tif (pfmt[p].bytesperline < bytesperline)\n\t\t\tpfmt[p].bytesperline = bytesperline;\n\n\t\tpfmt[p].sizeimage = (pfmt[p].bytesperline * mp->height) /\n\t\t\t\tfmt->vdownsampling[p] + fmt->data_offset[p];\n\n\t\tmemset(pfmt[p].reserved, 0, sizeof(pfmt[p].reserved));\n\t}\n\tfor (p = fmt->buffers; p < fmt->planes; p++)\n\t\tpfmt[0].sizeimage += (pfmt[0].bytesperline * mp->height *\n\t\t\t(fmt->bit_depth[p] / fmt->vdownsampling[p])) /\n\t\t\t(fmt->bit_depth[0] / fmt->vdownsampling[0]);\n\n\tif (!user_set_csc || !v4l2_is_colorspace_valid(mp->colorspace))\n\t\tmp->colorspace = vivid_colorspace_cap(dev);\n\n\tif (!user_set_csc || !v4l2_is_xfer_func_valid(mp->xfer_func))\n\t\tmp->xfer_func = vivid_xfer_func_cap(dev);\n\n\tif (fmt->color_enc == TGP_COLOR_ENC_HSV) {\n\t\tif (!user_set_csc || !v4l2_is_hsv_enc_valid(mp->hsv_enc))\n\t\t\tmp->hsv_enc = vivid_hsv_enc_cap(dev);\n\t} else if (fmt->color_enc == TGP_COLOR_ENC_YCBCR) {\n\t\tif (!user_set_csc || !v4l2_is_ycbcr_enc_valid(mp->ycbcr_enc))\n\t\t\tmp->ycbcr_enc = vivid_ycbcr_enc_cap(dev);\n\t} else {\n\t\tmp->ycbcr_enc = vivid_ycbcr_enc_cap(dev);\n\t}\n\n\tif (fmt->color_enc == TGP_COLOR_ENC_YCBCR ||\n\t    fmt->color_enc == TGP_COLOR_ENC_RGB) {\n\t\tif (!user_set_csc || !v4l2_is_quant_valid(mp->quantization))\n\t\t\tmp->quantization = vivid_quantization_cap(dev);\n\t} else {\n\t\tmp->quantization = vivid_quantization_cap(dev);\n\t}\n\n\tmemset(mp->reserved, 0, sizeof(mp->reserved));\n\treturn 0;\n}\n\nint vivid_s_fmt_vid_cap(struct file *file, void *priv,\n\t\t\t\t\tstruct v4l2_format *f)\n{\n\tstruct v4l2_pix_format_mplane *mp = &f->fmt.pix_mp;\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tstruct v4l2_rect *crop = &dev->crop_cap;\n\tstruct v4l2_rect *compose = &dev->compose_cap;\n\tstruct vb2_queue *q = &dev->vb_vid_cap_q;\n\tint ret = vivid_try_fmt_vid_cap(file, priv, f);\n\tunsigned factor = 1;\n\tunsigned p;\n\tunsigned i;\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (vb2_is_busy(q)) {\n\t\tdprintk(dev, 1, \"%s device busy\\n\", __func__);\n\t\treturn -EBUSY;\n\t}\n\n\tdev->fmt_cap = vivid_get_format(dev, mp->pixelformat);\n\tif (V4L2_FIELD_HAS_T_OR_B(mp->field))\n\t\tfactor = 2;\n\n\t \n\n\tif (!vivid_is_webcam(dev) &&\n\t    (dev->has_scaler_cap || dev->has_crop_cap || dev->has_compose_cap)) {\n\t\tstruct v4l2_rect r = { 0, 0, mp->width, mp->height };\n\n\t\tif (dev->has_scaler_cap) {\n\t\t\tif (dev->has_compose_cap)\n\t\t\t\tv4l2_rect_map_inside(compose, &r);\n\t\t\telse\n\t\t\t\t*compose = r;\n\t\t\tif (dev->has_crop_cap && !dev->has_compose_cap) {\n\t\t\t\tstruct v4l2_rect min_r = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\tr.width / MAX_ZOOM,\n\t\t\t\t\tfactor * r.height / MAX_ZOOM\n\t\t\t\t};\n\t\t\t\tstruct v4l2_rect max_r = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\tr.width * MAX_ZOOM,\n\t\t\t\t\tfactor * r.height * MAX_ZOOM\n\t\t\t\t};\n\n\t\t\t\tv4l2_rect_set_min_size(crop, &min_r);\n\t\t\t\tv4l2_rect_set_max_size(crop, &max_r);\n\t\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\t} else if (dev->has_crop_cap) {\n\t\t\t\tstruct v4l2_rect min_r = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\tcompose->width / MAX_ZOOM,\n\t\t\t\t\tfactor * compose->height / MAX_ZOOM\n\t\t\t\t};\n\t\t\t\tstruct v4l2_rect max_r = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\tcompose->width * MAX_ZOOM,\n\t\t\t\t\tfactor * compose->height * MAX_ZOOM\n\t\t\t\t};\n\n\t\t\t\tv4l2_rect_set_min_size(crop, &min_r);\n\t\t\t\tv4l2_rect_set_max_size(crop, &max_r);\n\t\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\t}\n\t\t} else if (dev->has_crop_cap && !dev->has_compose_cap) {\n\t\t\tr.height *= factor;\n\t\t\tv4l2_rect_set_size_to(crop, &r);\n\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\tr = *crop;\n\t\t\tr.height /= factor;\n\t\t\tv4l2_rect_set_size_to(compose, &r);\n\t\t} else if (!dev->has_crop_cap) {\n\t\t\tv4l2_rect_map_inside(compose, &r);\n\t\t} else {\n\t\t\tr.height *= factor;\n\t\t\tv4l2_rect_set_max_size(crop, &r);\n\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\tcompose->top *= factor;\n\t\t\tcompose->height *= factor;\n\t\t\tv4l2_rect_set_size_to(compose, crop);\n\t\t\tv4l2_rect_map_inside(compose, &r);\n\t\t\tcompose->top /= factor;\n\t\t\tcompose->height /= factor;\n\t\t}\n\t} else if (vivid_is_webcam(dev)) {\n\t\tunsigned int ival_sz = webcam_ival_count(dev, dev->webcam_size_idx);\n\n\t\t \n\t\tfor (i = 0; i < ARRAY_SIZE(webcam_sizes); i++)\n\t\t\tif (webcam_sizes[i].width == mp->width &&\n\t\t\t\t\twebcam_sizes[i].height == mp->height)\n\t\t\t\tbreak;\n\t\tdev->webcam_size_idx = i;\n\t\tif (dev->webcam_ival_idx >= ival_sz)\n\t\t\tdev->webcam_ival_idx = ival_sz - 1;\n\t\tvivid_update_format_cap(dev, false);\n\t} else {\n\t\tstruct v4l2_rect r = { 0, 0, mp->width, mp->height };\n\n\t\tv4l2_rect_set_size_to(compose, &r);\n\t\tr.height *= factor;\n\t\tv4l2_rect_set_size_to(crop, &r);\n\t}\n\n\tdev->fmt_cap_rect.width = mp->width;\n\tdev->fmt_cap_rect.height = mp->height;\n\ttpg_s_buf_height(&dev->tpg, mp->height);\n\ttpg_s_fourcc(&dev->tpg, dev->fmt_cap->fourcc);\n\tfor (p = 0; p < tpg_g_buffers(&dev->tpg); p++)\n\t\ttpg_s_bytesperline(&dev->tpg, p, mp->plane_fmt[p].bytesperline);\n\tdev->field_cap = mp->field;\n\tif (dev->field_cap == V4L2_FIELD_ALTERNATE)\n\t\ttpg_s_field(&dev->tpg, V4L2_FIELD_TOP, true);\n\telse\n\t\ttpg_s_field(&dev->tpg, dev->field_cap, false);\n\ttpg_s_crop_compose(&dev->tpg, &dev->crop_cap, &dev->compose_cap);\n\tif (vivid_is_sdtv_cap(dev))\n\t\tdev->tv_field_cap = mp->field;\n\ttpg_update_mv_step(&dev->tpg);\n\tdev->tpg.colorspace = mp->colorspace;\n\tdev->tpg.xfer_func = mp->xfer_func;\n\tif (dev->fmt_cap->color_enc == TGP_COLOR_ENC_YCBCR)\n\t\tdev->tpg.ycbcr_enc = mp->ycbcr_enc;\n\telse\n\t\tdev->tpg.hsv_enc = mp->hsv_enc;\n\tdev->tpg.quantization = mp->quantization;\n\n\treturn 0;\n}\n\nint vidioc_g_fmt_vid_cap_mplane(struct file *file, void *priv,\n\t\t\t\t\tstruct v4l2_format *f)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (!dev->multiplanar)\n\t\treturn -ENOTTY;\n\treturn vivid_g_fmt_vid_cap(file, priv, f);\n}\n\nint vidioc_try_fmt_vid_cap_mplane(struct file *file, void *priv,\n\t\t\tstruct v4l2_format *f)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (!dev->multiplanar)\n\t\treturn -ENOTTY;\n\treturn vivid_try_fmt_vid_cap(file, priv, f);\n}\n\nint vidioc_s_fmt_vid_cap_mplane(struct file *file, void *priv,\n\t\t\tstruct v4l2_format *f)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (!dev->multiplanar)\n\t\treturn -ENOTTY;\n\treturn vivid_s_fmt_vid_cap(file, priv, f);\n}\n\nint vidioc_g_fmt_vid_cap(struct file *file, void *priv,\n\t\t\t\t\tstruct v4l2_format *f)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (dev->multiplanar)\n\t\treturn -ENOTTY;\n\treturn fmt_sp2mp_func(file, priv, f, vivid_g_fmt_vid_cap);\n}\n\nint vidioc_try_fmt_vid_cap(struct file *file, void *priv,\n\t\t\tstruct v4l2_format *f)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (dev->multiplanar)\n\t\treturn -ENOTTY;\n\treturn fmt_sp2mp_func(file, priv, f, vivid_try_fmt_vid_cap);\n}\n\nint vidioc_s_fmt_vid_cap(struct file *file, void *priv,\n\t\t\tstruct v4l2_format *f)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (dev->multiplanar)\n\t\treturn -ENOTTY;\n\treturn fmt_sp2mp_func(file, priv, f, vivid_s_fmt_vid_cap);\n}\n\nint vivid_vid_cap_g_selection(struct file *file, void *priv,\n\t\t\t      struct v4l2_selection *sel)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (!dev->has_crop_cap && !dev->has_compose_cap)\n\t\treturn -ENOTTY;\n\tif (sel->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\treturn -EINVAL;\n\tif (vivid_is_webcam(dev))\n\t\treturn -ENODATA;\n\n\tsel->r.left = sel->r.top = 0;\n\tswitch (sel->target) {\n\tcase V4L2_SEL_TGT_CROP:\n\t\tif (!dev->has_crop_cap)\n\t\t\treturn -EINVAL;\n\t\tsel->r = dev->crop_cap;\n\t\tbreak;\n\tcase V4L2_SEL_TGT_CROP_DEFAULT:\n\tcase V4L2_SEL_TGT_CROP_BOUNDS:\n\t\tif (!dev->has_crop_cap)\n\t\t\treturn -EINVAL;\n\t\tsel->r = dev->src_rect;\n\t\tbreak;\n\tcase V4L2_SEL_TGT_COMPOSE_BOUNDS:\n\t\tif (!dev->has_compose_cap)\n\t\t\treturn -EINVAL;\n\t\tsel->r = vivid_max_rect;\n\t\tbreak;\n\tcase V4L2_SEL_TGT_COMPOSE:\n\t\tif (!dev->has_compose_cap)\n\t\t\treturn -EINVAL;\n\t\tsel->r = dev->compose_cap;\n\t\tbreak;\n\tcase V4L2_SEL_TGT_COMPOSE_DEFAULT:\n\t\tif (!dev->has_compose_cap)\n\t\t\treturn -EINVAL;\n\t\tsel->r = dev->fmt_cap_rect;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nint vivid_vid_cap_s_selection(struct file *file, void *fh, struct v4l2_selection *s)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tstruct v4l2_rect *crop = &dev->crop_cap;\n\tstruct v4l2_rect *compose = &dev->compose_cap;\n\tunsigned factor = V4L2_FIELD_HAS_T_OR_B(dev->field_cap) ? 2 : 1;\n\tint ret;\n\n\tif (!dev->has_crop_cap && !dev->has_compose_cap)\n\t\treturn -ENOTTY;\n\tif (s->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\treturn -EINVAL;\n\tif (vivid_is_webcam(dev))\n\t\treturn -ENODATA;\n\n\tswitch (s->target) {\n\tcase V4L2_SEL_TGT_CROP:\n\t\tif (!dev->has_crop_cap)\n\t\t\treturn -EINVAL;\n\t\tret = vivid_vid_adjust_sel(s->flags, &s->r);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tv4l2_rect_set_min_size(&s->r, &vivid_min_rect);\n\t\tv4l2_rect_set_max_size(&s->r, &dev->src_rect);\n\t\tv4l2_rect_map_inside(&s->r, &dev->crop_bounds_cap);\n\t\ts->r.top /= factor;\n\t\ts->r.height /= factor;\n\t\tif (dev->has_scaler_cap) {\n\t\t\tstruct v4l2_rect fmt = dev->fmt_cap_rect;\n\t\t\tstruct v4l2_rect max_rect = {\n\t\t\t\t0, 0,\n\t\t\t\ts->r.width * MAX_ZOOM,\n\t\t\t\ts->r.height * MAX_ZOOM\n\t\t\t};\n\t\t\tstruct v4l2_rect min_rect = {\n\t\t\t\t0, 0,\n\t\t\t\ts->r.width / MAX_ZOOM,\n\t\t\t\ts->r.height / MAX_ZOOM\n\t\t\t};\n\n\t\t\tv4l2_rect_set_min_size(&fmt, &min_rect);\n\t\t\tif (!dev->has_compose_cap)\n\t\t\t\tv4l2_rect_set_max_size(&fmt, &max_rect);\n\t\t\tif (!v4l2_rect_same_size(&dev->fmt_cap_rect, &fmt) &&\n\t\t\t    vb2_is_busy(&dev->vb_vid_cap_q))\n\t\t\t\treturn -EBUSY;\n\t\t\tif (dev->has_compose_cap) {\n\t\t\t\tv4l2_rect_set_min_size(compose, &min_rect);\n\t\t\t\tv4l2_rect_set_max_size(compose, &max_rect);\n\t\t\t\tv4l2_rect_map_inside(compose, &fmt);\n\t\t\t}\n\t\t\tdev->fmt_cap_rect = fmt;\n\t\t\ttpg_s_buf_height(&dev->tpg, fmt.height);\n\t\t} else if (dev->has_compose_cap) {\n\t\t\tstruct v4l2_rect fmt = dev->fmt_cap_rect;\n\n\t\t\tv4l2_rect_set_min_size(&fmt, &s->r);\n\t\t\tif (!v4l2_rect_same_size(&dev->fmt_cap_rect, &fmt) &&\n\t\t\t    vb2_is_busy(&dev->vb_vid_cap_q))\n\t\t\t\treturn -EBUSY;\n\t\t\tdev->fmt_cap_rect = fmt;\n\t\t\ttpg_s_buf_height(&dev->tpg, fmt.height);\n\t\t\tv4l2_rect_set_size_to(compose, &s->r);\n\t\t\tv4l2_rect_map_inside(compose, &dev->fmt_cap_rect);\n\t\t} else {\n\t\t\tif (!v4l2_rect_same_size(&s->r, &dev->fmt_cap_rect) &&\n\t\t\t    vb2_is_busy(&dev->vb_vid_cap_q))\n\t\t\t\treturn -EBUSY;\n\t\t\tv4l2_rect_set_size_to(&dev->fmt_cap_rect, &s->r);\n\t\t\tv4l2_rect_set_size_to(compose, &s->r);\n\t\t\tv4l2_rect_map_inside(compose, &dev->fmt_cap_rect);\n\t\t\ttpg_s_buf_height(&dev->tpg, dev->fmt_cap_rect.height);\n\t\t}\n\t\ts->r.top *= factor;\n\t\ts->r.height *= factor;\n\t\t*crop = s->r;\n\t\tbreak;\n\tcase V4L2_SEL_TGT_COMPOSE:\n\t\tif (!dev->has_compose_cap)\n\t\t\treturn -EINVAL;\n\t\tret = vivid_vid_adjust_sel(s->flags, &s->r);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tv4l2_rect_set_min_size(&s->r, &vivid_min_rect);\n\t\tv4l2_rect_set_max_size(&s->r, &dev->fmt_cap_rect);\n\t\tif (dev->has_scaler_cap) {\n\t\t\tstruct v4l2_rect max_rect = {\n\t\t\t\t0, 0,\n\t\t\t\tdev->src_rect.width * MAX_ZOOM,\n\t\t\t\t(dev->src_rect.height / factor) * MAX_ZOOM\n\t\t\t};\n\n\t\t\tv4l2_rect_set_max_size(&s->r, &max_rect);\n\t\t\tif (dev->has_crop_cap) {\n\t\t\t\tstruct v4l2_rect min_rect = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\ts->r.width / MAX_ZOOM,\n\t\t\t\t\t(s->r.height * factor) / MAX_ZOOM\n\t\t\t\t};\n\t\t\t\tstruct v4l2_rect max_rect = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\ts->r.width * MAX_ZOOM,\n\t\t\t\t\t(s->r.height * factor) * MAX_ZOOM\n\t\t\t\t};\n\n\t\t\t\tv4l2_rect_set_min_size(crop, &min_rect);\n\t\t\t\tv4l2_rect_set_max_size(crop, &max_rect);\n\t\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\t}\n\t\t} else if (dev->has_crop_cap) {\n\t\t\ts->r.top *= factor;\n\t\t\ts->r.height *= factor;\n\t\t\tv4l2_rect_set_max_size(&s->r, &dev->src_rect);\n\t\t\tv4l2_rect_set_size_to(crop, &s->r);\n\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\ts->r.top /= factor;\n\t\t\ts->r.height /= factor;\n\t\t} else {\n\t\t\tv4l2_rect_set_size_to(&s->r, &dev->src_rect);\n\t\t\ts->r.height /= factor;\n\t\t}\n\t\tv4l2_rect_map_inside(&s->r, &dev->fmt_cap_rect);\n\t\t*compose = s->r;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\ttpg_s_crop_compose(&dev->tpg, crop, compose);\n\treturn 0;\n}\n\nint vivid_vid_cap_g_pixelaspect(struct file *file, void *priv,\n\t\t\t\tint type, struct v4l2_fract *f)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\treturn -EINVAL;\n\n\tswitch (vivid_get_pixel_aspect(dev)) {\n\tcase TPG_PIXEL_ASPECT_NTSC:\n\t\tf->numerator = 11;\n\t\tf->denominator = 10;\n\t\tbreak;\n\tcase TPG_PIXEL_ASPECT_PAL:\n\t\tf->numerator = 54;\n\t\tf->denominator = 59;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic const struct v4l2_audio vivid_audio_inputs[] = {\n\t{ 0, \"TV\", V4L2_AUDCAP_STEREO },\n\t{ 1, \"Line-In\", V4L2_AUDCAP_STEREO },\n};\n\nint vidioc_enum_input(struct file *file, void *priv,\n\t\t\t\tstruct v4l2_input *inp)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (inp->index >= dev->num_inputs)\n\t\treturn -EINVAL;\n\n\tinp->type = V4L2_INPUT_TYPE_CAMERA;\n\tswitch (dev->input_type[inp->index]) {\n\tcase WEBCAM:\n\t\tsnprintf(inp->name, sizeof(inp->name), \"Webcam %u\",\n\t\t\t\tdev->input_name_counter[inp->index]);\n\t\tinp->capabilities = 0;\n\t\tbreak;\n\tcase TV:\n\t\tsnprintf(inp->name, sizeof(inp->name), \"TV %u\",\n\t\t\t\tdev->input_name_counter[inp->index]);\n\t\tinp->type = V4L2_INPUT_TYPE_TUNER;\n\t\tinp->std = V4L2_STD_ALL;\n\t\tif (dev->has_audio_inputs)\n\t\t\tinp->audioset = (1 << ARRAY_SIZE(vivid_audio_inputs)) - 1;\n\t\tinp->capabilities = V4L2_IN_CAP_STD;\n\t\tbreak;\n\tcase SVID:\n\t\tsnprintf(inp->name, sizeof(inp->name), \"S-Video %u\",\n\t\t\t\tdev->input_name_counter[inp->index]);\n\t\tinp->std = V4L2_STD_ALL;\n\t\tif (dev->has_audio_inputs)\n\t\t\tinp->audioset = (1 << ARRAY_SIZE(vivid_audio_inputs)) - 1;\n\t\tinp->capabilities = V4L2_IN_CAP_STD;\n\t\tbreak;\n\tcase HDMI:\n\t\tsnprintf(inp->name, sizeof(inp->name), \"HDMI %u\",\n\t\t\t\tdev->input_name_counter[inp->index]);\n\t\tinp->capabilities = V4L2_IN_CAP_DV_TIMINGS;\n\t\tif (dev->edid_blocks == 0 ||\n\t\t    dev->dv_timings_signal_mode[dev->input] == NO_SIGNAL)\n\t\t\tinp->status |= V4L2_IN_ST_NO_SIGNAL;\n\t\telse if (dev->dv_timings_signal_mode[dev->input] == NO_LOCK ||\n\t\t\t dev->dv_timings_signal_mode[dev->input] == OUT_OF_RANGE)\n\t\t\tinp->status |= V4L2_IN_ST_NO_H_LOCK;\n\t\tbreak;\n\t}\n\tif (dev->sensor_hflip)\n\t\tinp->status |= V4L2_IN_ST_HFLIP;\n\tif (dev->sensor_vflip)\n\t\tinp->status |= V4L2_IN_ST_VFLIP;\n\tif (dev->input == inp->index && vivid_is_sdtv_cap(dev)) {\n\t\tif (dev->std_signal_mode[dev->input] == NO_SIGNAL) {\n\t\t\tinp->status |= V4L2_IN_ST_NO_SIGNAL;\n\t\t} else if (dev->std_signal_mode[dev->input] == NO_LOCK) {\n\t\t\tinp->status |= V4L2_IN_ST_NO_H_LOCK;\n\t\t} else if (vivid_is_tv_cap(dev)) {\n\t\t\tswitch (tpg_g_quality(&dev->tpg)) {\n\t\t\tcase TPG_QUAL_GRAY:\n\t\t\t\tinp->status |= V4L2_IN_ST_COLOR_KILL;\n\t\t\t\tbreak;\n\t\t\tcase TPG_QUAL_NOISE:\n\t\t\t\tinp->status |= V4L2_IN_ST_NO_H_LOCK;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nint vidioc_g_input(struct file *file, void *priv, unsigned *i)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\t*i = dev->input;\n\treturn 0;\n}\n\nint vidioc_s_input(struct file *file, void *priv, unsigned i)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tstruct v4l2_bt_timings *bt = &dev->dv_timings_cap[dev->input].bt;\n\tunsigned brightness;\n\n\tif (i >= dev->num_inputs)\n\t\treturn -EINVAL;\n\n\tif (i == dev->input)\n\t\treturn 0;\n\n\tif (vb2_is_busy(&dev->vb_vid_cap_q) ||\n\t    vb2_is_busy(&dev->vb_vbi_cap_q) ||\n\t    vb2_is_busy(&dev->vb_meta_cap_q))\n\t\treturn -EBUSY;\n\n\tdev->input = i;\n\tdev->vid_cap_dev.tvnorms = 0;\n\tif (dev->input_type[i] == TV || dev->input_type[i] == SVID) {\n\t\tdev->tv_audio_input = (dev->input_type[i] == TV) ? 0 : 1;\n\t\tdev->vid_cap_dev.tvnorms = V4L2_STD_ALL;\n\t}\n\tdev->vbi_cap_dev.tvnorms = dev->vid_cap_dev.tvnorms;\n\tdev->meta_cap_dev.tvnorms = dev->vid_cap_dev.tvnorms;\n\tvivid_update_format_cap(dev, false);\n\n\tif (dev->colorspace) {\n\t\tswitch (dev->input_type[i]) {\n\t\tcase WEBCAM:\n\t\t\tv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_SRGB);\n\t\t\tbreak;\n\t\tcase TV:\n\t\tcase SVID:\n\t\t\tv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_170M);\n\t\t\tbreak;\n\t\tcase HDMI:\n\t\t\tif (bt->flags & V4L2_DV_FL_IS_CE_VIDEO) {\n\t\t\t\tif (dev->src_rect.width == 720 && dev->src_rect.height <= 576)\n\t\t\t\t\tv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_170M);\n\t\t\t\telse\n\t\t\t\t\tv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_709);\n\t\t\t} else {\n\t\t\t\tv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_SRGB);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tbrightness = 128 * i + dev->input_brightness[i];\n\tv4l2_ctrl_modify_range(dev->brightness,\n\t\t\t128 * i, 255 + 128 * i, 1, 128 + 128 * i);\n\tv4l2_ctrl_s_ctrl(dev->brightness, brightness);\n\n\t \n\tv4l2_ctrl_activate(dev->ctrl_dv_timings_signal_mode,\n\t\t\t   vivid_is_hdmi_cap(dev));\n\tv4l2_ctrl_activate(dev->ctrl_dv_timings, vivid_is_hdmi_cap(dev) &&\n\t\t\t   dev->dv_timings_signal_mode[dev->input] ==\n\t\t\t   SELECTED_DV_TIMINGS);\n\tv4l2_ctrl_activate(dev->ctrl_std_signal_mode, vivid_is_sdtv_cap(dev));\n\tv4l2_ctrl_activate(dev->ctrl_standard, vivid_is_sdtv_cap(dev) &&\n\t\t\t   dev->std_signal_mode[dev->input]);\n\n\tif (vivid_is_hdmi_cap(dev)) {\n\t\tv4l2_ctrl_s_ctrl(dev->ctrl_dv_timings_signal_mode,\n\t\t\t\t dev->dv_timings_signal_mode[dev->input]);\n\t\tv4l2_ctrl_s_ctrl(dev->ctrl_dv_timings,\n\t\t\t\t dev->query_dv_timings[dev->input]);\n\t} else if (vivid_is_sdtv_cap(dev)) {\n\t\tv4l2_ctrl_s_ctrl(dev->ctrl_std_signal_mode,\n\t\t\t\t dev->std_signal_mode[dev->input]);\n\t\tv4l2_ctrl_s_ctrl(dev->ctrl_standard,\n\t\t\t\t dev->std_signal_mode[dev->input]);\n\t}\n\n\treturn 0;\n}\n\nint vidioc_enumaudio(struct file *file, void *fh, struct v4l2_audio *vin)\n{\n\tif (vin->index >= ARRAY_SIZE(vivid_audio_inputs))\n\t\treturn -EINVAL;\n\t*vin = vivid_audio_inputs[vin->index];\n\treturn 0;\n}\n\nint vidioc_g_audio(struct file *file, void *fh, struct v4l2_audio *vin)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (!vivid_is_sdtv_cap(dev))\n\t\treturn -EINVAL;\n\t*vin = vivid_audio_inputs[dev->tv_audio_input];\n\treturn 0;\n}\n\nint vidioc_s_audio(struct file *file, void *fh, const struct v4l2_audio *vin)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (!vivid_is_sdtv_cap(dev))\n\t\treturn -EINVAL;\n\tif (vin->index >= ARRAY_SIZE(vivid_audio_inputs))\n\t\treturn -EINVAL;\n\tdev->tv_audio_input = vin->index;\n\treturn 0;\n}\n\nint vivid_video_g_frequency(struct file *file, void *fh, struct v4l2_frequency *vf)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (vf->tuner != 0)\n\t\treturn -EINVAL;\n\tvf->frequency = dev->tv_freq;\n\treturn 0;\n}\n\nint vivid_video_s_frequency(struct file *file, void *fh, const struct v4l2_frequency *vf)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (vf->tuner != 0)\n\t\treturn -EINVAL;\n\tdev->tv_freq = clamp_t(unsigned, vf->frequency, MIN_TV_FREQ, MAX_TV_FREQ);\n\tif (vivid_is_tv_cap(dev))\n\t\tvivid_update_quality(dev);\n\treturn 0;\n}\n\nint vivid_video_s_tuner(struct file *file, void *fh, const struct v4l2_tuner *vt)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (vt->index != 0)\n\t\treturn -EINVAL;\n\tif (vt->audmode > V4L2_TUNER_MODE_LANG1_LANG2)\n\t\treturn -EINVAL;\n\tdev->tv_audmode = vt->audmode;\n\treturn 0;\n}\n\nint vivid_video_g_tuner(struct file *file, void *fh, struct v4l2_tuner *vt)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tenum tpg_quality qual;\n\n\tif (vt->index != 0)\n\t\treturn -EINVAL;\n\n\tvt->capability = V4L2_TUNER_CAP_NORM | V4L2_TUNER_CAP_STEREO |\n\t\t\t V4L2_TUNER_CAP_LANG1 | V4L2_TUNER_CAP_LANG2;\n\tvt->audmode = dev->tv_audmode;\n\tvt->rangelow = MIN_TV_FREQ;\n\tvt->rangehigh = MAX_TV_FREQ;\n\tqual = vivid_get_quality(dev, &vt->afc);\n\tif (qual == TPG_QUAL_COLOR)\n\t\tvt->signal = 0xffff;\n\telse if (qual == TPG_QUAL_GRAY)\n\t\tvt->signal = 0x8000;\n\telse\n\t\tvt->signal = 0;\n\tif (qual == TPG_QUAL_NOISE) {\n\t\tvt->rxsubchans = 0;\n\t} else if (qual == TPG_QUAL_GRAY) {\n\t\tvt->rxsubchans = V4L2_TUNER_SUB_MONO;\n\t} else {\n\t\tunsigned int channel_nr = dev->tv_freq / (6 * 16);\n\t\tunsigned int options =\n\t\t\t(dev->std_cap[dev->input] & V4L2_STD_NTSC_M) ? 4 : 3;\n\n\t\tswitch (channel_nr % options) {\n\t\tcase 0:\n\t\t\tvt->rxsubchans = V4L2_TUNER_SUB_MONO;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tvt->rxsubchans = V4L2_TUNER_SUB_STEREO;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tif (dev->std_cap[dev->input] & V4L2_STD_NTSC_M)\n\t\t\t\tvt->rxsubchans = V4L2_TUNER_SUB_MONO | V4L2_TUNER_SUB_SAP;\n\t\t\telse\n\t\t\t\tvt->rxsubchans = V4L2_TUNER_SUB_LANG1 | V4L2_TUNER_SUB_LANG2;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tvt->rxsubchans = V4L2_TUNER_SUB_STEREO | V4L2_TUNER_SUB_SAP;\n\t\t\tbreak;\n\t\t}\n\t}\n\tstrscpy(vt->name, \"TV Tuner\", sizeof(vt->name));\n\treturn 0;\n}\n\n \nconst v4l2_std_id vivid_standard[] = {\n\tV4L2_STD_NTSC_M,\n\tV4L2_STD_NTSC_M_JP,\n\tV4L2_STD_NTSC_M_KR,\n\tV4L2_STD_NTSC_443,\n\tV4L2_STD_PAL_BG | V4L2_STD_PAL_H,\n\tV4L2_STD_PAL_I,\n\tV4L2_STD_PAL_DK,\n\tV4L2_STD_PAL_M,\n\tV4L2_STD_PAL_N,\n\tV4L2_STD_PAL_Nc,\n\tV4L2_STD_PAL_60,\n\tV4L2_STD_SECAM_B | V4L2_STD_SECAM_G | V4L2_STD_SECAM_H,\n\tV4L2_STD_SECAM_DK,\n\tV4L2_STD_SECAM_L,\n\tV4L2_STD_SECAM_LC,\n\tV4L2_STD_UNKNOWN\n};\n\n \nconst char * const vivid_ctrl_standard_strings[] = {\n\t\"NTSC-M\",\n\t\"NTSC-M-JP\",\n\t\"NTSC-M-KR\",\n\t\"NTSC-443\",\n\t\"PAL-BGH\",\n\t\"PAL-I\",\n\t\"PAL-DK\",\n\t\"PAL-M\",\n\t\"PAL-N\",\n\t\"PAL-Nc\",\n\t\"PAL-60\",\n\t\"SECAM-BGH\",\n\t\"SECAM-DK\",\n\t\"SECAM-L\",\n\t\"SECAM-Lc\",\n\tNULL,\n};\n\nint vidioc_querystd(struct file *file, void *priv, v4l2_std_id *id)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tunsigned int last = dev->query_std_last[dev->input];\n\n\tif (!vivid_is_sdtv_cap(dev))\n\t\treturn -ENODATA;\n\tif (dev->std_signal_mode[dev->input] == NO_SIGNAL ||\n\t    dev->std_signal_mode[dev->input] == NO_LOCK) {\n\t\t*id = V4L2_STD_UNKNOWN;\n\t\treturn 0;\n\t}\n\tif (vivid_is_tv_cap(dev) && tpg_g_quality(&dev->tpg) == TPG_QUAL_NOISE) {\n\t\t*id = V4L2_STD_UNKNOWN;\n\t} else if (dev->std_signal_mode[dev->input] == CURRENT_STD) {\n\t\t*id = dev->std_cap[dev->input];\n\t} else if (dev->std_signal_mode[dev->input] == SELECTED_STD) {\n\t\t*id = dev->query_std[dev->input];\n\t} else {\n\t\t*id = vivid_standard[last];\n\t\tdev->query_std_last[dev->input] =\n\t\t\t(last + 1) % ARRAY_SIZE(vivid_standard);\n\t}\n\n\treturn 0;\n}\n\nint vivid_vid_cap_s_std(struct file *file, void *priv, v4l2_std_id id)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (!vivid_is_sdtv_cap(dev))\n\t\treturn -ENODATA;\n\tif (dev->std_cap[dev->input] == id)\n\t\treturn 0;\n\tif (vb2_is_busy(&dev->vb_vid_cap_q) || vb2_is_busy(&dev->vb_vbi_cap_q))\n\t\treturn -EBUSY;\n\tdev->std_cap[dev->input] = id;\n\tvivid_update_format_cap(dev, false);\n\treturn 0;\n}\n\nstatic void find_aspect_ratio(u32 width, u32 height,\n\t\t\t       u32 *num, u32 *denom)\n{\n\tif (!(height % 3) && ((height * 4 / 3) == width)) {\n\t\t*num = 4;\n\t\t*denom = 3;\n\t} else if (!(height % 9) && ((height * 16 / 9) == width)) {\n\t\t*num = 16;\n\t\t*denom = 9;\n\t} else if (!(height % 10) && ((height * 16 / 10) == width)) {\n\t\t*num = 16;\n\t\t*denom = 10;\n\t} else if (!(height % 4) && ((height * 5 / 4) == width)) {\n\t\t*num = 5;\n\t\t*denom = 4;\n\t} else if (!(height % 9) && ((height * 15 / 9) == width)) {\n\t\t*num = 15;\n\t\t*denom = 9;\n\t} else {  \n\t\t*num = 16;\n\t\t*denom = 9;\n\t}\n}\n\nstatic bool valid_cvt_gtf_timings(struct v4l2_dv_timings *timings)\n{\n\tstruct v4l2_bt_timings *bt = &timings->bt;\n\tu32 total_h_pixel;\n\tu32 total_v_lines;\n\tu32 h_freq;\n\n\tif (!v4l2_valid_dv_timings(timings, &vivid_dv_timings_cap,\n\t\t\t\tNULL, NULL))\n\t\treturn false;\n\n\ttotal_h_pixel = V4L2_DV_BT_FRAME_WIDTH(bt);\n\ttotal_v_lines = V4L2_DV_BT_FRAME_HEIGHT(bt);\n\n\th_freq = (u32)bt->pixelclock / total_h_pixel;\n\n\tif (bt->standards == 0 || (bt->standards & V4L2_DV_BT_STD_CVT)) {\n\t\tif (v4l2_detect_cvt(total_v_lines, h_freq, bt->vsync, bt->width,\n\t\t\t\t    bt->polarities, bt->interlaced, timings))\n\t\t\treturn true;\n\t}\n\n\tif (bt->standards == 0 || (bt->standards & V4L2_DV_BT_STD_GTF)) {\n\t\tstruct v4l2_fract aspect_ratio;\n\n\t\tfind_aspect_ratio(bt->width, bt->height,\n\t\t\t\t  &aspect_ratio.numerator,\n\t\t\t\t  &aspect_ratio.denominator);\n\t\tif (v4l2_detect_gtf(total_v_lines, h_freq, bt->vsync,\n\t\t\t\t    bt->polarities, bt->interlaced,\n\t\t\t\t    aspect_ratio, timings))\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nint vivid_vid_cap_s_dv_timings(struct file *file, void *_fh,\n\t\t\t\t    struct v4l2_dv_timings *timings)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (!vivid_is_hdmi_cap(dev))\n\t\treturn -ENODATA;\n\tif (!v4l2_find_dv_timings_cap(timings, &vivid_dv_timings_cap,\n\t\t\t\t      0, NULL, NULL) &&\n\t    !valid_cvt_gtf_timings(timings))\n\t\treturn -EINVAL;\n\n\tif (v4l2_match_dv_timings(timings, &dev->dv_timings_cap[dev->input],\n\t\t\t\t  0, false))\n\t\treturn 0;\n\tif (vb2_is_busy(&dev->vb_vid_cap_q))\n\t\treturn -EBUSY;\n\n\tdev->dv_timings_cap[dev->input] = *timings;\n\tvivid_update_format_cap(dev, false);\n\treturn 0;\n}\n\nint vidioc_query_dv_timings(struct file *file, void *_fh,\n\t\t\t\t    struct v4l2_dv_timings *timings)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tunsigned int input = dev->input;\n\tunsigned int last = dev->query_dv_timings_last[input];\n\n\tif (!vivid_is_hdmi_cap(dev))\n\t\treturn -ENODATA;\n\tif (dev->dv_timings_signal_mode[input] == NO_SIGNAL ||\n\t    dev->edid_blocks == 0)\n\t\treturn -ENOLINK;\n\tif (dev->dv_timings_signal_mode[input] == NO_LOCK)\n\t\treturn -ENOLCK;\n\tif (dev->dv_timings_signal_mode[input] == OUT_OF_RANGE) {\n\t\ttimings->bt.pixelclock = vivid_dv_timings_cap.bt.max_pixelclock * 2;\n\t\treturn -ERANGE;\n\t}\n\tif (dev->dv_timings_signal_mode[input] == CURRENT_DV_TIMINGS) {\n\t\t*timings = dev->dv_timings_cap[input];\n\t} else if (dev->dv_timings_signal_mode[input] ==\n\t\t   SELECTED_DV_TIMINGS) {\n\t\t*timings =\n\t\t\tv4l2_dv_timings_presets[dev->query_dv_timings[input]];\n\t} else {\n\t\t*timings =\n\t\t\tv4l2_dv_timings_presets[last];\n\t\tdev->query_dv_timings_last[input] =\n\t\t\t(last + 1) % dev->query_dv_timings_size;\n\t}\n\treturn 0;\n}\n\nint vidioc_s_edid(struct file *file, void *_fh,\n\t\t\t struct v4l2_edid *edid)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tu16 phys_addr;\n\tu32 display_present = 0;\n\tunsigned int i, j;\n\tint ret;\n\n\tmemset(edid->reserved, 0, sizeof(edid->reserved));\n\tif (edid->pad >= dev->num_inputs)\n\t\treturn -EINVAL;\n\tif (dev->input_type[edid->pad] != HDMI || edid->start_block)\n\t\treturn -EINVAL;\n\tif (edid->blocks == 0) {\n\t\tdev->edid_blocks = 0;\n\t\tv4l2_ctrl_s_ctrl(dev->ctrl_tx_edid_present, 0);\n\t\tv4l2_ctrl_s_ctrl(dev->ctrl_tx_hotplug, 0);\n\t\tphys_addr = CEC_PHYS_ADDR_INVALID;\n\t\tgoto set_phys_addr;\n\t}\n\tif (edid->blocks > dev->edid_max_blocks) {\n\t\tedid->blocks = dev->edid_max_blocks;\n\t\treturn -E2BIG;\n\t}\n\tphys_addr = cec_get_edid_phys_addr(edid->edid, edid->blocks * 128, NULL);\n\tret = v4l2_phys_addr_validate(phys_addr, &phys_addr, NULL);\n\tif (ret)\n\t\treturn ret;\n\n\tif (vb2_is_busy(&dev->vb_vid_cap_q))\n\t\treturn -EBUSY;\n\n\tdev->edid_blocks = edid->blocks;\n\tmemcpy(dev->edid, edid->edid, edid->blocks * 128);\n\n\tfor (i = 0, j = 0; i < dev->num_outputs; i++)\n\t\tif (dev->output_type[i] == HDMI)\n\t\t\tdisplay_present |=\n\t\t\t\tdev->display_present[i] << j++;\n\n\tv4l2_ctrl_s_ctrl(dev->ctrl_tx_edid_present, display_present);\n\tv4l2_ctrl_s_ctrl(dev->ctrl_tx_hotplug, display_present);\n\nset_phys_addr:\n\t \n\tcec_s_phys_addr(dev->cec_rx_adap, phys_addr, false);\n\n\tfor (i = 0; i < MAX_OUTPUTS && dev->cec_tx_adap[i]; i++)\n\t\tcec_s_phys_addr(dev->cec_tx_adap[i],\n\t\t\t\tdev->display_present[i] ?\n\t\t\t\tv4l2_phys_addr_for_input(phys_addr, i + 1) :\n\t\t\t\tCEC_PHYS_ADDR_INVALID,\n\t\t\t\tfalse);\n\treturn 0;\n}\n\nint vidioc_enum_framesizes(struct file *file, void *fh,\n\t\t\t\t\t struct v4l2_frmsizeenum *fsize)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (!vivid_is_webcam(dev) && !dev->has_scaler_cap)\n\t\treturn -EINVAL;\n\tif (vivid_get_format(dev, fsize->pixel_format) == NULL)\n\t\treturn -EINVAL;\n\tif (vivid_is_webcam(dev)) {\n\t\tif (fsize->index >= ARRAY_SIZE(webcam_sizes))\n\t\t\treturn -EINVAL;\n\t\tfsize->type = V4L2_FRMSIZE_TYPE_DISCRETE;\n\t\tfsize->discrete = webcam_sizes[fsize->index];\n\t\treturn 0;\n\t}\n\tif (fsize->index)\n\t\treturn -EINVAL;\n\tfsize->type = V4L2_FRMSIZE_TYPE_STEPWISE;\n\tfsize->stepwise.min_width = MIN_WIDTH;\n\tfsize->stepwise.max_width = MAX_WIDTH * MAX_ZOOM;\n\tfsize->stepwise.step_width = 2;\n\tfsize->stepwise.min_height = MIN_HEIGHT;\n\tfsize->stepwise.max_height = MAX_HEIGHT * MAX_ZOOM;\n\tfsize->stepwise.step_height = 2;\n\treturn 0;\n}\n\n \nint vidioc_enum_frameintervals(struct file *file, void *priv,\n\t\t\t\t\t     struct v4l2_frmivalenum *fival)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tconst struct vivid_fmt *fmt;\n\tint i;\n\n\tfmt = vivid_get_format(dev, fival->pixel_format);\n\tif (!fmt)\n\t\treturn -EINVAL;\n\n\tif (!vivid_is_webcam(dev)) {\n\t\tif (fival->index)\n\t\t\treturn -EINVAL;\n\t\tif (fival->width < MIN_WIDTH || fival->width > MAX_WIDTH * MAX_ZOOM)\n\t\t\treturn -EINVAL;\n\t\tif (fival->height < MIN_HEIGHT || fival->height > MAX_HEIGHT * MAX_ZOOM)\n\t\t\treturn -EINVAL;\n\t\tfival->type = V4L2_FRMIVAL_TYPE_DISCRETE;\n\t\tfival->discrete = dev->timeperframe_vid_cap;\n\t\treturn 0;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(webcam_sizes); i++)\n\t\tif (fival->width == webcam_sizes[i].width &&\n\t\t    fival->height == webcam_sizes[i].height)\n\t\t\tbreak;\n\tif (i == ARRAY_SIZE(webcam_sizes))\n\t\treturn -EINVAL;\n\tif (fival->index >= webcam_ival_count(dev, i))\n\t\treturn -EINVAL;\n\tfival->type = V4L2_FRMIVAL_TYPE_DISCRETE;\n\tfival->discrete = webcam_intervals[fival->index];\n\treturn 0;\n}\n\nint vivid_vid_cap_g_parm(struct file *file, void *priv,\n\t\t\t  struct v4l2_streamparm *parm)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\n\tif (parm->type != (dev->multiplanar ?\n\t\t\t   V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE :\n\t\t\t   V4L2_BUF_TYPE_VIDEO_CAPTURE))\n\t\treturn -EINVAL;\n\n\tparm->parm.capture.capability   = V4L2_CAP_TIMEPERFRAME;\n\tparm->parm.capture.timeperframe = dev->timeperframe_vid_cap;\n\tparm->parm.capture.readbuffers  = 1;\n\treturn 0;\n}\n\nint vivid_vid_cap_s_parm(struct file *file, void *priv,\n\t\t\t  struct v4l2_streamparm *parm)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tunsigned int ival_sz = webcam_ival_count(dev, dev->webcam_size_idx);\n\tstruct v4l2_fract tpf;\n\tunsigned i;\n\n\tif (parm->type != (dev->multiplanar ?\n\t\t\t   V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE :\n\t\t\t   V4L2_BUF_TYPE_VIDEO_CAPTURE))\n\t\treturn -EINVAL;\n\tif (!vivid_is_webcam(dev))\n\t\treturn vivid_vid_cap_g_parm(file, priv, parm);\n\n\ttpf = parm->parm.capture.timeperframe;\n\n\tif (tpf.denominator == 0)\n\t\ttpf = webcam_intervals[ival_sz - 1];\n\tfor (i = 0; i < ival_sz; i++)\n\t\tif (V4L2_FRACT_COMPARE(tpf, >=, webcam_intervals[i]))\n\t\t\tbreak;\n\tif (i == ival_sz)\n\t\ti = ival_sz - 1;\n\tdev->webcam_ival_idx = i;\n\ttpf = webcam_intervals[dev->webcam_ival_idx];\n\n\t \n\tdev->cap_seq_resync = true;\n\tdev->timeperframe_vid_cap = tpf;\n\tparm->parm.capture.capability   = V4L2_CAP_TIMEPERFRAME;\n\tparm->parm.capture.timeperframe = tpf;\n\tparm->parm.capture.readbuffers  = 1;\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}