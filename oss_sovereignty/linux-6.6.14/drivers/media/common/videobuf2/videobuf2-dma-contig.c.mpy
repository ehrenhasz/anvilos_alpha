{
  "module_name": "videobuf2-dma-contig.c",
  "hash_id": "240ead869d492982f0db2223294cb39a7096beb637556b464e75ef812e313b9f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/common/videobuf2/videobuf2-dma-contig.c",
  "human_readable_source": " \n\n#include <linux/dma-buf.h>\n#include <linux/module.h>\n#include <linux/refcount.h>\n#include <linux/scatterlist.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/dma-mapping.h>\n#include <linux/highmem.h>\n\n#include <media/videobuf2-v4l2.h>\n#include <media/videobuf2-dma-contig.h>\n#include <media/videobuf2-memops.h>\n\nstruct vb2_dc_buf {\n\tstruct device\t\t\t*dev;\n\tvoid\t\t\t\t*vaddr;\n\tunsigned long\t\t\tsize;\n\tvoid\t\t\t\t*cookie;\n\tdma_addr_t\t\t\tdma_addr;\n\tunsigned long\t\t\tattrs;\n\tenum dma_data_direction\t\tdma_dir;\n\tstruct sg_table\t\t\t*dma_sgt;\n\tstruct frame_vector\t\t*vec;\n\n\t \n\tstruct vb2_vmarea_handler\thandler;\n\trefcount_t\t\t\trefcount;\n\tstruct sg_table\t\t\t*sgt_base;\n\n\t \n\tstruct dma_buf_attachment\t*db_attach;\n\n\tstruct vb2_buffer\t\t*vb;\n\tbool\t\t\t\tnon_coherent_mem;\n};\n\n \n \n \n\nstatic unsigned long vb2_dc_get_contiguous_size(struct sg_table *sgt)\n{\n\tstruct scatterlist *s;\n\tdma_addr_t expected = sg_dma_address(sgt->sgl);\n\tunsigned int i;\n\tunsigned long size = 0;\n\n\tfor_each_sgtable_dma_sg(sgt, s, i) {\n\t\tif (sg_dma_address(s) != expected)\n\t\t\tbreak;\n\t\texpected += sg_dma_len(s);\n\t\tsize += sg_dma_len(s);\n\t}\n\treturn size;\n}\n\n \n \n \n\nstatic void *vb2_dc_cookie(struct vb2_buffer *vb, void *buf_priv)\n{\n\tstruct vb2_dc_buf *buf = buf_priv;\n\n\treturn &buf->dma_addr;\n}\n\n \nstatic void *vb2_dc_vaddr(struct vb2_buffer *vb, void *buf_priv)\n{\n\tstruct vb2_dc_buf *buf = buf_priv;\n\n\tif (buf->vaddr)\n\t\treturn buf->vaddr;\n\n\tif (buf->db_attach) {\n\t\tstruct iosys_map map;\n\n\t\tif (!dma_buf_vmap_unlocked(buf->db_attach->dmabuf, &map))\n\t\t\tbuf->vaddr = map.vaddr;\n\n\t\treturn buf->vaddr;\n\t}\n\n\tif (buf->non_coherent_mem)\n\t\tbuf->vaddr = dma_vmap_noncontiguous(buf->dev, buf->size,\n\t\t\t\t\t\t    buf->dma_sgt);\n\treturn buf->vaddr;\n}\n\nstatic unsigned int vb2_dc_num_users(void *buf_priv)\n{\n\tstruct vb2_dc_buf *buf = buf_priv;\n\n\treturn refcount_read(&buf->refcount);\n}\n\nstatic void vb2_dc_prepare(void *buf_priv)\n{\n\tstruct vb2_dc_buf *buf = buf_priv;\n\tstruct sg_table *sgt = buf->dma_sgt;\n\n\t \n\tif (buf->vb->skip_cache_sync_on_prepare)\n\t\treturn;\n\n\tif (!buf->non_coherent_mem)\n\t\treturn;\n\n\t \n\tif (buf->vaddr)\n\t\tflush_kernel_vmap_range(buf->vaddr, buf->size);\n\n\t \n\tdma_sync_sgtable_for_device(buf->dev, sgt, buf->dma_dir);\n}\n\nstatic void vb2_dc_finish(void *buf_priv)\n{\n\tstruct vb2_dc_buf *buf = buf_priv;\n\tstruct sg_table *sgt = buf->dma_sgt;\n\n\t \n\tif (buf->vb->skip_cache_sync_on_finish)\n\t\treturn;\n\n\tif (!buf->non_coherent_mem)\n\t\treturn;\n\n\t \n\tif (buf->vaddr)\n\t\tinvalidate_kernel_vmap_range(buf->vaddr, buf->size);\n\n\t \n\tdma_sync_sgtable_for_cpu(buf->dev, sgt, buf->dma_dir);\n}\n\n \n \n \n\nstatic void vb2_dc_put(void *buf_priv)\n{\n\tstruct vb2_dc_buf *buf = buf_priv;\n\n\tif (!refcount_dec_and_test(&buf->refcount))\n\t\treturn;\n\n\tif (buf->non_coherent_mem) {\n\t\tif (buf->vaddr)\n\t\t\tdma_vunmap_noncontiguous(buf->dev, buf->vaddr);\n\t\tdma_free_noncontiguous(buf->dev, buf->size,\n\t\t\t\t       buf->dma_sgt, buf->dma_dir);\n\t} else {\n\t\tif (buf->sgt_base) {\n\t\t\tsg_free_table(buf->sgt_base);\n\t\t\tkfree(buf->sgt_base);\n\t\t}\n\t\tdma_free_attrs(buf->dev, buf->size, buf->cookie,\n\t\t\t       buf->dma_addr, buf->attrs);\n\t}\n\tput_device(buf->dev);\n\tkfree(buf);\n}\n\nstatic int vb2_dc_alloc_coherent(struct vb2_dc_buf *buf)\n{\n\tstruct vb2_queue *q = buf->vb->vb2_queue;\n\n\tbuf->cookie = dma_alloc_attrs(buf->dev,\n\t\t\t\t      buf->size,\n\t\t\t\t      &buf->dma_addr,\n\t\t\t\t      GFP_KERNEL | q->gfp_flags,\n\t\t\t\t      buf->attrs);\n\tif (!buf->cookie)\n\t\treturn -ENOMEM;\n\n\tif (q->dma_attrs & DMA_ATTR_NO_KERNEL_MAPPING)\n\t\treturn 0;\n\n\tbuf->vaddr = buf->cookie;\n\treturn 0;\n}\n\nstatic int vb2_dc_alloc_non_coherent(struct vb2_dc_buf *buf)\n{\n\tstruct vb2_queue *q = buf->vb->vb2_queue;\n\n\tbuf->dma_sgt = dma_alloc_noncontiguous(buf->dev,\n\t\t\t\t\t       buf->size,\n\t\t\t\t\t       buf->dma_dir,\n\t\t\t\t\t       GFP_KERNEL | q->gfp_flags,\n\t\t\t\t\t       buf->attrs);\n\tif (!buf->dma_sgt)\n\t\treturn -ENOMEM;\n\n\tbuf->dma_addr = sg_dma_address(buf->dma_sgt->sgl);\n\n\t \n\treturn 0;\n}\n\nstatic void *vb2_dc_alloc(struct vb2_buffer *vb,\n\t\t\t  struct device *dev,\n\t\t\t  unsigned long size)\n{\n\tstruct vb2_dc_buf *buf;\n\tint ret;\n\n\tif (WARN_ON(!dev))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tbuf = kzalloc(sizeof *buf, GFP_KERNEL);\n\tif (!buf)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbuf->attrs = vb->vb2_queue->dma_attrs;\n\tbuf->dma_dir = vb->vb2_queue->dma_dir;\n\tbuf->vb = vb;\n\tbuf->non_coherent_mem = vb->vb2_queue->non_coherent_mem;\n\n\tbuf->size = size;\n\t \n\tbuf->dev = get_device(dev);\n\n\tif (buf->non_coherent_mem)\n\t\tret = vb2_dc_alloc_non_coherent(buf);\n\telse\n\t\tret = vb2_dc_alloc_coherent(buf);\n\n\tif (ret) {\n\t\tdev_err(dev, \"dma alloc of size %lu failed\\n\", size);\n\t\tkfree(buf);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tbuf->handler.refcount = &buf->refcount;\n\tbuf->handler.put = vb2_dc_put;\n\tbuf->handler.arg = buf;\n\n\trefcount_set(&buf->refcount, 1);\n\n\treturn buf;\n}\n\nstatic int vb2_dc_mmap(void *buf_priv, struct vm_area_struct *vma)\n{\n\tstruct vb2_dc_buf *buf = buf_priv;\n\tint ret;\n\n\tif (!buf) {\n\t\tprintk(KERN_ERR \"No buffer to map\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (buf->non_coherent_mem)\n\t\tret = dma_mmap_noncontiguous(buf->dev, vma, buf->size,\n\t\t\t\t\t     buf->dma_sgt);\n\telse\n\t\tret = dma_mmap_attrs(buf->dev, vma, buf->cookie, buf->dma_addr,\n\t\t\t\t     buf->size, buf->attrs);\n\tif (ret) {\n\t\tpr_err(\"Remapping memory failed, error: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tvm_flags_set(vma, VM_DONTEXPAND | VM_DONTDUMP);\n\tvma->vm_private_data\t= &buf->handler;\n\tvma->vm_ops\t\t= &vb2_common_vm_ops;\n\n\tvma->vm_ops->open(vma);\n\n\tpr_debug(\"%s: mapped dma addr 0x%08lx at 0x%08lx, size %lu\\n\",\n\t\t __func__, (unsigned long)buf->dma_addr, vma->vm_start,\n\t\t buf->size);\n\n\treturn 0;\n}\n\n \n \n \n\nstruct vb2_dc_attachment {\n\tstruct sg_table sgt;\n\tenum dma_data_direction dma_dir;\n};\n\nstatic int vb2_dc_dmabuf_ops_attach(struct dma_buf *dbuf,\n\tstruct dma_buf_attachment *dbuf_attach)\n{\n\tstruct vb2_dc_attachment *attach;\n\tunsigned int i;\n\tstruct scatterlist *rd, *wr;\n\tstruct sg_table *sgt;\n\tstruct vb2_dc_buf *buf = dbuf->priv;\n\tint ret;\n\n\tattach = kzalloc(sizeof(*attach), GFP_KERNEL);\n\tif (!attach)\n\t\treturn -ENOMEM;\n\n\tsgt = &attach->sgt;\n\t \n\tret = sg_alloc_table(sgt, buf->sgt_base->orig_nents, GFP_KERNEL);\n\tif (ret) {\n\t\tkfree(attach);\n\t\treturn -ENOMEM;\n\t}\n\n\trd = buf->sgt_base->sgl;\n\twr = sgt->sgl;\n\tfor (i = 0; i < sgt->orig_nents; ++i) {\n\t\tsg_set_page(wr, sg_page(rd), rd->length, rd->offset);\n\t\trd = sg_next(rd);\n\t\twr = sg_next(wr);\n\t}\n\n\tattach->dma_dir = DMA_NONE;\n\tdbuf_attach->priv = attach;\n\n\treturn 0;\n}\n\nstatic void vb2_dc_dmabuf_ops_detach(struct dma_buf *dbuf,\n\tstruct dma_buf_attachment *db_attach)\n{\n\tstruct vb2_dc_attachment *attach = db_attach->priv;\n\tstruct sg_table *sgt;\n\n\tif (!attach)\n\t\treturn;\n\n\tsgt = &attach->sgt;\n\n\t \n\tif (attach->dma_dir != DMA_NONE)\n\t\t \n\t\tdma_unmap_sgtable(db_attach->dev, sgt, attach->dma_dir,\n\t\t\t\t  DMA_ATTR_SKIP_CPU_SYNC);\n\tsg_free_table(sgt);\n\tkfree(attach);\n\tdb_attach->priv = NULL;\n}\n\nstatic struct sg_table *vb2_dc_dmabuf_ops_map(\n\tstruct dma_buf_attachment *db_attach, enum dma_data_direction dma_dir)\n{\n\tstruct vb2_dc_attachment *attach = db_attach->priv;\n\tstruct sg_table *sgt;\n\n\tsgt = &attach->sgt;\n\t \n\tif (attach->dma_dir == dma_dir)\n\t\treturn sgt;\n\n\t \n\tif (attach->dma_dir != DMA_NONE) {\n\t\tdma_unmap_sgtable(db_attach->dev, sgt, attach->dma_dir,\n\t\t\t\t  DMA_ATTR_SKIP_CPU_SYNC);\n\t\tattach->dma_dir = DMA_NONE;\n\t}\n\n\t \n\tif (dma_map_sgtable(db_attach->dev, sgt, dma_dir,\n\t\t\t    DMA_ATTR_SKIP_CPU_SYNC)) {\n\t\tpr_err(\"failed to map scatterlist\\n\");\n\t\treturn ERR_PTR(-EIO);\n\t}\n\n\tattach->dma_dir = dma_dir;\n\n\treturn sgt;\n}\n\nstatic void vb2_dc_dmabuf_ops_unmap(struct dma_buf_attachment *db_attach,\n\tstruct sg_table *sgt, enum dma_data_direction dma_dir)\n{\n\t \n}\n\nstatic void vb2_dc_dmabuf_ops_release(struct dma_buf *dbuf)\n{\n\t \n\tvb2_dc_put(dbuf->priv);\n}\n\nstatic int\nvb2_dc_dmabuf_ops_begin_cpu_access(struct dma_buf *dbuf,\n\t\t\t\t   enum dma_data_direction direction)\n{\n\treturn 0;\n}\n\nstatic int\nvb2_dc_dmabuf_ops_end_cpu_access(struct dma_buf *dbuf,\n\t\t\t\t enum dma_data_direction direction)\n{\n\treturn 0;\n}\n\nstatic int vb2_dc_dmabuf_ops_vmap(struct dma_buf *dbuf, struct iosys_map *map)\n{\n\tstruct vb2_dc_buf *buf;\n\tvoid *vaddr;\n\n\tbuf = dbuf->priv;\n\tvaddr = vb2_dc_vaddr(buf->vb, buf);\n\tif (!vaddr)\n\t\treturn -EINVAL;\n\n\tiosys_map_set_vaddr(map, vaddr);\n\n\treturn 0;\n}\n\nstatic int vb2_dc_dmabuf_ops_mmap(struct dma_buf *dbuf,\n\tstruct vm_area_struct *vma)\n{\n\treturn vb2_dc_mmap(dbuf->priv, vma);\n}\n\nstatic const struct dma_buf_ops vb2_dc_dmabuf_ops = {\n\t.attach = vb2_dc_dmabuf_ops_attach,\n\t.detach = vb2_dc_dmabuf_ops_detach,\n\t.map_dma_buf = vb2_dc_dmabuf_ops_map,\n\t.unmap_dma_buf = vb2_dc_dmabuf_ops_unmap,\n\t.begin_cpu_access = vb2_dc_dmabuf_ops_begin_cpu_access,\n\t.end_cpu_access = vb2_dc_dmabuf_ops_end_cpu_access,\n\t.vmap = vb2_dc_dmabuf_ops_vmap,\n\t.mmap = vb2_dc_dmabuf_ops_mmap,\n\t.release = vb2_dc_dmabuf_ops_release,\n};\n\nstatic struct sg_table *vb2_dc_get_base_sgt(struct vb2_dc_buf *buf)\n{\n\tint ret;\n\tstruct sg_table *sgt;\n\n\tif (buf->non_coherent_mem)\n\t\treturn buf->dma_sgt;\n\n\tsgt = kmalloc(sizeof(*sgt), GFP_KERNEL);\n\tif (!sgt) {\n\t\tdev_err(buf->dev, \"failed to alloc sg table\\n\");\n\t\treturn NULL;\n\t}\n\n\tret = dma_get_sgtable_attrs(buf->dev, sgt, buf->cookie, buf->dma_addr,\n\t\tbuf->size, buf->attrs);\n\tif (ret < 0) {\n\t\tdev_err(buf->dev, \"failed to get scatterlist from DMA API\\n\");\n\t\tkfree(sgt);\n\t\treturn NULL;\n\t}\n\n\treturn sgt;\n}\n\nstatic struct dma_buf *vb2_dc_get_dmabuf(struct vb2_buffer *vb,\n\t\t\t\t\t void *buf_priv,\n\t\t\t\t\t unsigned long flags)\n{\n\tstruct vb2_dc_buf *buf = buf_priv;\n\tstruct dma_buf *dbuf;\n\tDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\n\n\texp_info.ops = &vb2_dc_dmabuf_ops;\n\texp_info.size = buf->size;\n\texp_info.flags = flags;\n\texp_info.priv = buf;\n\n\tif (!buf->sgt_base)\n\t\tbuf->sgt_base = vb2_dc_get_base_sgt(buf);\n\n\tif (WARN_ON(!buf->sgt_base))\n\t\treturn NULL;\n\n\tdbuf = dma_buf_export(&exp_info);\n\tif (IS_ERR(dbuf))\n\t\treturn NULL;\n\n\t \n\trefcount_inc(&buf->refcount);\n\n\treturn dbuf;\n}\n\n \n \n \n\nstatic void vb2_dc_put_userptr(void *buf_priv)\n{\n\tstruct vb2_dc_buf *buf = buf_priv;\n\tstruct sg_table *sgt = buf->dma_sgt;\n\tint i;\n\tstruct page **pages;\n\n\tif (sgt) {\n\t\t \n\t\tdma_unmap_sgtable(buf->dev, sgt, buf->dma_dir,\n\t\t\t\t  DMA_ATTR_SKIP_CPU_SYNC);\n\t\tpages = frame_vector_pages(buf->vec);\n\t\t \n\t\tBUG_ON(IS_ERR(pages));\n\t\tif (buf->dma_dir == DMA_FROM_DEVICE ||\n\t\t    buf->dma_dir == DMA_BIDIRECTIONAL)\n\t\t\tfor (i = 0; i < frame_vector_count(buf->vec); i++)\n\t\t\t\tset_page_dirty_lock(pages[i]);\n\t\tsg_free_table(sgt);\n\t\tkfree(sgt);\n\t} else {\n\t\tdma_unmap_resource(buf->dev, buf->dma_addr, buf->size,\n\t\t\t\t   buf->dma_dir, 0);\n\t}\n\tvb2_destroy_framevec(buf->vec);\n\tkfree(buf);\n}\n\nstatic void *vb2_dc_get_userptr(struct vb2_buffer *vb, struct device *dev,\n\t\t\t\tunsigned long vaddr, unsigned long size)\n{\n\tstruct vb2_dc_buf *buf;\n\tstruct frame_vector *vec;\n\tunsigned int offset;\n\tint n_pages, i;\n\tint ret = 0;\n\tstruct sg_table *sgt;\n\tunsigned long contig_size;\n\tunsigned long dma_align = dma_get_cache_alignment();\n\n\t \n\tif (!IS_ALIGNED(vaddr | size, dma_align)) {\n\t\tpr_debug(\"user data must be aligned to %lu bytes\\n\", dma_align);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!size) {\n\t\tpr_debug(\"size is zero\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (WARN_ON(!dev))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tbuf = kzalloc(sizeof *buf, GFP_KERNEL);\n\tif (!buf)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbuf->dev = dev;\n\tbuf->dma_dir = vb->vb2_queue->dma_dir;\n\tbuf->vb = vb;\n\n\toffset = lower_32_bits(offset_in_page(vaddr));\n\tvec = vb2_create_framevec(vaddr, size, buf->dma_dir == DMA_FROM_DEVICE ||\n\t\t\t\t\t       buf->dma_dir == DMA_BIDIRECTIONAL);\n\tif (IS_ERR(vec)) {\n\t\tret = PTR_ERR(vec);\n\t\tgoto fail_buf;\n\t}\n\tbuf->vec = vec;\n\tn_pages = frame_vector_count(vec);\n\tret = frame_vector_to_pages(vec);\n\tif (ret < 0) {\n\t\tunsigned long *nums = frame_vector_pfns(vec);\n\n\t\t \n\t\tfor (i = 1; i < n_pages; i++)\n\t\t\tif (nums[i-1] + 1 != nums[i])\n\t\t\t\tgoto fail_pfnvec;\n\t\tbuf->dma_addr = dma_map_resource(buf->dev,\n\t\t\t\t__pfn_to_phys(nums[0]), size, buf->dma_dir, 0);\n\t\tif (dma_mapping_error(buf->dev, buf->dma_addr)) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail_pfnvec;\n\t\t}\n\t\tgoto out;\n\t}\n\n\tsgt = kzalloc(sizeof(*sgt), GFP_KERNEL);\n\tif (!sgt) {\n\t\tpr_err(\"failed to allocate sg table\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto fail_pfnvec;\n\t}\n\n\tret = sg_alloc_table_from_pages(sgt, frame_vector_pages(vec), n_pages,\n\t\toffset, size, GFP_KERNEL);\n\tif (ret) {\n\t\tpr_err(\"failed to initialize sg table\\n\");\n\t\tgoto fail_sgt;\n\t}\n\n\t \n\tif (dma_map_sgtable(buf->dev, sgt, buf->dma_dir,\n\t\t\t    DMA_ATTR_SKIP_CPU_SYNC)) {\n\t\tpr_err(\"failed to map scatterlist\\n\");\n\t\tret = -EIO;\n\t\tgoto fail_sgt_init;\n\t}\n\n\tcontig_size = vb2_dc_get_contiguous_size(sgt);\n\tif (contig_size < size) {\n\t\tpr_err(\"contiguous mapping is too small %lu/%lu\\n\",\n\t\t\tcontig_size, size);\n\t\tret = -EFAULT;\n\t\tgoto fail_map_sg;\n\t}\n\n\tbuf->dma_addr = sg_dma_address(sgt->sgl);\n\tbuf->dma_sgt = sgt;\n\tbuf->non_coherent_mem = 1;\n\nout:\n\tbuf->size = size;\n\n\treturn buf;\n\nfail_map_sg:\n\tdma_unmap_sgtable(buf->dev, sgt, buf->dma_dir, DMA_ATTR_SKIP_CPU_SYNC);\n\nfail_sgt_init:\n\tsg_free_table(sgt);\n\nfail_sgt:\n\tkfree(sgt);\n\nfail_pfnvec:\n\tvb2_destroy_framevec(vec);\n\nfail_buf:\n\tkfree(buf);\n\n\treturn ERR_PTR(ret);\n}\n\n \n \n \n\nstatic int vb2_dc_map_dmabuf(void *mem_priv)\n{\n\tstruct vb2_dc_buf *buf = mem_priv;\n\tstruct sg_table *sgt;\n\tunsigned long contig_size;\n\n\tif (WARN_ON(!buf->db_attach)) {\n\t\tpr_err(\"trying to pin a non attached buffer\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (WARN_ON(buf->dma_sgt)) {\n\t\tpr_err(\"dmabuf buffer is already pinned\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tsgt = dma_buf_map_attachment_unlocked(buf->db_attach, buf->dma_dir);\n\tif (IS_ERR(sgt)) {\n\t\tpr_err(\"Error getting dmabuf scatterlist\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tcontig_size = vb2_dc_get_contiguous_size(sgt);\n\tif (contig_size < buf->size) {\n\t\tpr_err(\"contiguous chunk is too small %lu/%lu\\n\",\n\t\t       contig_size, buf->size);\n\t\tdma_buf_unmap_attachment_unlocked(buf->db_attach, sgt,\n\t\t\t\t\t\t  buf->dma_dir);\n\t\treturn -EFAULT;\n\t}\n\n\tbuf->dma_addr = sg_dma_address(sgt->sgl);\n\tbuf->dma_sgt = sgt;\n\tbuf->vaddr = NULL;\n\n\treturn 0;\n}\n\nstatic void vb2_dc_unmap_dmabuf(void *mem_priv)\n{\n\tstruct vb2_dc_buf *buf = mem_priv;\n\tstruct sg_table *sgt = buf->dma_sgt;\n\tstruct iosys_map map = IOSYS_MAP_INIT_VADDR(buf->vaddr);\n\n\tif (WARN_ON(!buf->db_attach)) {\n\t\tpr_err(\"trying to unpin a not attached buffer\\n\");\n\t\treturn;\n\t}\n\n\tif (WARN_ON(!sgt)) {\n\t\tpr_err(\"dmabuf buffer is already unpinned\\n\");\n\t\treturn;\n\t}\n\n\tif (buf->vaddr) {\n\t\tdma_buf_vunmap_unlocked(buf->db_attach->dmabuf, &map);\n\t\tbuf->vaddr = NULL;\n\t}\n\tdma_buf_unmap_attachment_unlocked(buf->db_attach, sgt, buf->dma_dir);\n\n\tbuf->dma_addr = 0;\n\tbuf->dma_sgt = NULL;\n}\n\nstatic void vb2_dc_detach_dmabuf(void *mem_priv)\n{\n\tstruct vb2_dc_buf *buf = mem_priv;\n\n\t \n\tif (WARN_ON(buf->dma_addr))\n\t\tvb2_dc_unmap_dmabuf(buf);\n\n\t \n\tdma_buf_detach(buf->db_attach->dmabuf, buf->db_attach);\n\tkfree(buf);\n}\n\nstatic void *vb2_dc_attach_dmabuf(struct vb2_buffer *vb, struct device *dev,\n\t\t\t\t  struct dma_buf *dbuf, unsigned long size)\n{\n\tstruct vb2_dc_buf *buf;\n\tstruct dma_buf_attachment *dba;\n\n\tif (dbuf->size < size)\n\t\treturn ERR_PTR(-EFAULT);\n\n\tif (WARN_ON(!dev))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tbuf = kzalloc(sizeof(*buf), GFP_KERNEL);\n\tif (!buf)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbuf->dev = dev;\n\tbuf->vb = vb;\n\n\t \n\tdba = dma_buf_attach(dbuf, buf->dev);\n\tif (IS_ERR(dba)) {\n\t\tpr_err(\"failed to attach dmabuf\\n\");\n\t\tkfree(buf);\n\t\treturn dba;\n\t}\n\n\tbuf->dma_dir = vb->vb2_queue->dma_dir;\n\tbuf->size = size;\n\tbuf->db_attach = dba;\n\n\treturn buf;\n}\n\n \n \n \n\nconst struct vb2_mem_ops vb2_dma_contig_memops = {\n\t.alloc\t\t= vb2_dc_alloc,\n\t.put\t\t= vb2_dc_put,\n\t.get_dmabuf\t= vb2_dc_get_dmabuf,\n\t.cookie\t\t= vb2_dc_cookie,\n\t.vaddr\t\t= vb2_dc_vaddr,\n\t.mmap\t\t= vb2_dc_mmap,\n\t.get_userptr\t= vb2_dc_get_userptr,\n\t.put_userptr\t= vb2_dc_put_userptr,\n\t.prepare\t= vb2_dc_prepare,\n\t.finish\t\t= vb2_dc_finish,\n\t.map_dmabuf\t= vb2_dc_map_dmabuf,\n\t.unmap_dmabuf\t= vb2_dc_unmap_dmabuf,\n\t.attach_dmabuf\t= vb2_dc_attach_dmabuf,\n\t.detach_dmabuf\t= vb2_dc_detach_dmabuf,\n\t.num_users\t= vb2_dc_num_users,\n};\nEXPORT_SYMBOL_GPL(vb2_dma_contig_memops);\n\n \nint vb2_dma_contig_set_max_seg_size(struct device *dev, unsigned int size)\n{\n\tif (!dev->dma_parms) {\n\t\tdev_err(dev, \"Failed to set max_seg_size: dma_parms is NULL\\n\");\n\t\treturn -ENODEV;\n\t}\n\tif (dma_get_max_seg_size(dev) < size)\n\t\treturn dma_set_max_seg_size(dev, size);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(vb2_dma_contig_set_max_seg_size);\n\nMODULE_DESCRIPTION(\"DMA-contig memory handling routines for videobuf2\");\nMODULE_AUTHOR(\"Pawel Osciak <pawel@osciak.com>\");\nMODULE_LICENSE(\"GPL\");\nMODULE_IMPORT_NS(DMA_BUF);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}