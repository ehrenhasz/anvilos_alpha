{
  "module_name": "cx18-queue.c",
  "hash_id": "cc1877ee00f9cc145470b78b559a0a95f06302b2c175c6ab3ae25a1967ca3bed",
  "original_prompt": "Ingested from linux-6.6.14/drivers/media/pci/cx18/cx18-queue.c",
  "human_readable_source": "\n \n\n#include \"cx18-driver.h\"\n#include \"cx18-queue.h\"\n#include \"cx18-streams.h\"\n#include \"cx18-scb.h\"\n#include \"cx18-io.h\"\n\nvoid cx18_buf_swap(struct cx18_buffer *buf)\n{\n\tint i;\n\n\tfor (i = 0; i < buf->bytesused; i += 4)\n\t\tswab32s((u32 *)(buf->buf + i));\n}\n\nvoid _cx18_mdl_swap(struct cx18_mdl *mdl)\n{\n\tstruct cx18_buffer *buf;\n\n\tlist_for_each_entry(buf, &mdl->buf_list, list) {\n\t\tif (buf->bytesused == 0)\n\t\t\tbreak;\n\t\tcx18_buf_swap(buf);\n\t}\n}\n\nvoid cx18_queue_init(struct cx18_queue *q)\n{\n\tINIT_LIST_HEAD(&q->list);\n\tatomic_set(&q->depth, 0);\n\tq->bytesused = 0;\n}\n\nstruct cx18_queue *_cx18_enqueue(struct cx18_stream *s, struct cx18_mdl *mdl,\n\t\t\t\t struct cx18_queue *q, int to_front)\n{\n\t \n\tif (q != &s->q_full) {\n\t\tmdl->bytesused = 0;\n\t\tmdl->readpos = 0;\n\t\tmdl->m_flags = 0;\n\t\tmdl->skipped = 0;\n\t\tmdl->curr_buf = NULL;\n\t}\n\n\t \n\tif (q == &s->q_busy &&\n\t    atomic_read(&q->depth) >= CX18_MAX_FW_MDLS_PER_STREAM)\n\t\tq = &s->q_free;\n\n\tspin_lock(&q->lock);\n\n\tif (to_front)\n\t\tlist_add(&mdl->list, &q->list);  \n\telse\n\t\tlist_add_tail(&mdl->list, &q->list);  \n\tq->bytesused += mdl->bytesused - mdl->readpos;\n\tatomic_inc(&q->depth);\n\n\tspin_unlock(&q->lock);\n\treturn q;\n}\n\nstruct cx18_mdl *cx18_dequeue(struct cx18_stream *s, struct cx18_queue *q)\n{\n\tstruct cx18_mdl *mdl = NULL;\n\n\tspin_lock(&q->lock);\n\tif (!list_empty(&q->list)) {\n\t\tmdl = list_first_entry(&q->list, struct cx18_mdl, list);\n\t\tlist_del_init(&mdl->list);\n\t\tq->bytesused -= mdl->bytesused - mdl->readpos;\n\t\tmdl->skipped = 0;\n\t\tatomic_dec(&q->depth);\n\t}\n\tspin_unlock(&q->lock);\n\treturn mdl;\n}\n\nstatic void _cx18_mdl_update_bufs_for_cpu(struct cx18_stream *s,\n\t\t\t\t\t  struct cx18_mdl *mdl)\n{\n\tstruct cx18_buffer *buf;\n\tu32 buf_size = s->buf_size;\n\tu32 bytesused = mdl->bytesused;\n\n\tlist_for_each_entry(buf, &mdl->buf_list, list) {\n\t\tbuf->readpos = 0;\n\t\tif (bytesused >= buf_size) {\n\t\t\tbuf->bytesused = buf_size;\n\t\t\tbytesused -= buf_size;\n\t\t} else {\n\t\t\tbuf->bytesused = bytesused;\n\t\t\tbytesused = 0;\n\t\t}\n\t\tcx18_buf_sync_for_cpu(s, buf);\n\t}\n}\n\nstatic inline void cx18_mdl_update_bufs_for_cpu(struct cx18_stream *s,\n\t\t\t\t\t\tstruct cx18_mdl *mdl)\n{\n\tstruct cx18_buffer *buf;\n\n\tif (list_is_singular(&mdl->buf_list)) {\n\t\tbuf = list_first_entry(&mdl->buf_list, struct cx18_buffer,\n\t\t\t\t       list);\n\t\tbuf->bytesused = mdl->bytesused;\n\t\tbuf->readpos = 0;\n\t\tcx18_buf_sync_for_cpu(s, buf);\n\t} else {\n\t\t_cx18_mdl_update_bufs_for_cpu(s, mdl);\n\t}\n}\n\nstruct cx18_mdl *cx18_queue_get_mdl(struct cx18_stream *s, u32 id,\n\tu32 bytesused)\n{\n\tstruct cx18 *cx = s->cx;\n\tstruct cx18_mdl *mdl;\n\tstruct cx18_mdl *tmp;\n\tstruct cx18_mdl *ret = NULL;\n\tLIST_HEAD(sweep_up);\n\n\t \n\tspin_lock(&s->q_busy.lock);\n\tlist_for_each_entry_safe(mdl, tmp, &s->q_busy.list, list) {\n\t\t \n\t\tif (mdl->id != id) {\n\t\t\tmdl->skipped++;\n\t\t\tif (mdl->skipped >= atomic_read(&s->q_busy.depth)-1) {\n\t\t\t\t \n\t\t\t\tCX18_WARN(\"Skipped %s, MDL %d, %d times - it must have dropped out of rotation\\n\",\n\t\t\t\t\t  s->name, mdl->id,\n\t\t\t\t\t  mdl->skipped);\n\t\t\t\t \n\t\t\t\tlist_move_tail(&mdl->list, &sweep_up);\n\t\t\t\tatomic_dec(&s->q_busy.depth);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tlist_del_init(&mdl->list);\n\t\tatomic_dec(&s->q_busy.depth);\n\t\tret = mdl;\n\t\tbreak;\n\t}\n\tspin_unlock(&s->q_busy.lock);\n\n\t \n\tif (ret != NULL) {\n\t\tret->bytesused = bytesused;\n\t\tret->skipped = 0;\n\t\t \n\t\tcx18_mdl_update_bufs_for_cpu(s, ret);\n\t\tif (s->type != CX18_ENC_STREAM_TYPE_TS)\n\t\t\tset_bit(CX18_F_M_NEED_SWAP, &ret->m_flags);\n\t}\n\n\t \n\tlist_for_each_entry_safe(mdl, tmp, &sweep_up, list) {\n\t\tlist_del_init(&mdl->list);\n\t\tcx18_enqueue(s, mdl, &s->q_free);\n\t}\n\treturn ret;\n}\n\n \nstatic void cx18_queue_flush(struct cx18_stream *s,\n\t\t\t     struct cx18_queue *q_src, struct cx18_queue *q_dst)\n{\n\tstruct cx18_mdl *mdl;\n\n\t \n\tif (q_src == q_dst || q_dst == &s->q_full || q_dst == &s->q_busy)\n\t\treturn;\n\n\tspin_lock(&q_src->lock);\n\tspin_lock(&q_dst->lock);\n\twhile (!list_empty(&q_src->list)) {\n\t\tmdl = list_first_entry(&q_src->list, struct cx18_mdl, list);\n\t\tlist_move_tail(&mdl->list, &q_dst->list);\n\t\tmdl->bytesused = 0;\n\t\tmdl->readpos = 0;\n\t\tmdl->m_flags = 0;\n\t\tmdl->skipped = 0;\n\t\tmdl->curr_buf = NULL;\n\t\tatomic_inc(&q_dst->depth);\n\t}\n\tcx18_queue_init(q_src);\n\tspin_unlock(&q_src->lock);\n\tspin_unlock(&q_dst->lock);\n}\n\nvoid cx18_flush_queues(struct cx18_stream *s)\n{\n\tcx18_queue_flush(s, &s->q_busy, &s->q_free);\n\tcx18_queue_flush(s, &s->q_full, &s->q_free);\n}\n\n \nvoid cx18_unload_queues(struct cx18_stream *s)\n{\n\tstruct cx18_queue *q_idle = &s->q_idle;\n\tstruct cx18_mdl *mdl;\n\tstruct cx18_buffer *buf;\n\n\t \n\tcx18_queue_flush(s, &s->q_busy, q_idle);\n\tcx18_queue_flush(s, &s->q_full, q_idle);\n\tcx18_queue_flush(s, &s->q_free, q_idle);\n\n\t \n\tspin_lock(&q_idle->lock);\n\tlist_for_each_entry(mdl, &q_idle->list, list) {\n\t\twhile (!list_empty(&mdl->buf_list)) {\n\t\t\tbuf = list_first_entry(&mdl->buf_list,\n\t\t\t\t\t       struct cx18_buffer, list);\n\t\t\tlist_move_tail(&buf->list, &s->buf_pool);\n\t\t\tbuf->bytesused = 0;\n\t\t\tbuf->readpos = 0;\n\t\t}\n\t\tmdl->id = s->mdl_base_idx;  \n\t\t \n\t}\n\tspin_unlock(&q_idle->lock);\n}\n\n \nvoid cx18_load_queues(struct cx18_stream *s)\n{\n\tstruct cx18 *cx = s->cx;\n\tstruct cx18_mdl *mdl;\n\tstruct cx18_buffer *buf;\n\tint mdl_id;\n\tint i;\n\tu32 partial_buf_size;\n\n\t \n\tmdl_id = s->mdl_base_idx;\n\tfor (mdl = cx18_dequeue(s, &s->q_idle), i = s->bufs_per_mdl;\n\t     mdl != NULL && i == s->bufs_per_mdl;\n\t     mdl = cx18_dequeue(s, &s->q_idle)) {\n\n\t\tmdl->id = mdl_id;\n\n\t\tfor (i = 0; i < s->bufs_per_mdl; i++) {\n\t\t\tif (list_empty(&s->buf_pool))\n\t\t\t\tbreak;\n\n\t\t\tbuf = list_first_entry(&s->buf_pool, struct cx18_buffer,\n\t\t\t\t\t       list);\n\t\t\tlist_move_tail(&buf->list, &mdl->buf_list);\n\n\t\t\t \n\t\t\tcx18_writel(cx, buf->dma_handle,\n\t\t\t\t    &cx->scb->cpu_mdl[mdl_id + i].paddr);\n\t\t\tcx18_writel(cx, s->buf_size,\n\t\t\t\t    &cx->scb->cpu_mdl[mdl_id + i].length);\n\t\t}\n\n\t\tif (i == s->bufs_per_mdl) {\n\t\t\t \n\t\t\tpartial_buf_size = s->mdl_size % s->buf_size;\n\t\t\tif (partial_buf_size) {\n\t\t\t\tcx18_writel(cx, partial_buf_size,\n\t\t\t\t      &cx->scb->cpu_mdl[mdl_id + i - 1].length);\n\t\t\t}\n\t\t\tcx18_enqueue(s, mdl, &s->q_free);\n\t\t} else {\n\t\t\t \n\t\t\tcx18_push(s, mdl, &s->q_idle);\n\t\t}\n\t\tmdl_id += i;\n\t}\n}\n\nvoid _cx18_mdl_sync_for_device(struct cx18_stream *s, struct cx18_mdl *mdl)\n{\n\tint dma = s->dma;\n\tu32 buf_size = s->buf_size;\n\tstruct pci_dev *pci_dev = s->cx->pci_dev;\n\tstruct cx18_buffer *buf;\n\n\tlist_for_each_entry(buf, &mdl->buf_list, list)\n\t\tdma_sync_single_for_device(&pci_dev->dev, buf->dma_handle,\n\t\t\t\t\t   buf_size, dma);\n}\n\nint cx18_stream_alloc(struct cx18_stream *s)\n{\n\tstruct cx18 *cx = s->cx;\n\tint i;\n\n\tif (s->buffers == 0)\n\t\treturn 0;\n\n\tCX18_DEBUG_INFO(\"Allocate %s stream: %d x %d buffers (%d.%02d kB total)\\n\",\n\t\ts->name, s->buffers, s->buf_size,\n\t\ts->buffers * s->buf_size / 1024,\n\t\t(s->buffers * s->buf_size * 100 / 1024) % 100);\n\n\tif (((char __iomem *)&cx->scb->cpu_mdl[cx->free_mdl_idx + s->buffers] -\n\t\t\t\t(char __iomem *)cx->scb) > SCB_RESERVED_SIZE) {\n\t\tunsigned bufsz = (((char __iomem *)cx->scb) + SCB_RESERVED_SIZE -\n\t\t\t\t\t((char __iomem *)cx->scb->cpu_mdl));\n\n\t\tCX18_ERR(\"Too many buffers, cannot fit in SCB area\\n\");\n\t\tCX18_ERR(\"Max buffers = %zu\\n\",\n\t\t\tbufsz / sizeof(struct cx18_mdl_ent));\n\t\treturn -ENOMEM;\n\t}\n\n\ts->mdl_base_idx = cx->free_mdl_idx;\n\n\t \n\tfor (i = 0; i < s->buffers; i++) {\n\t\tstruct cx18_mdl *mdl;\n\t\tstruct cx18_buffer *buf;\n\n\t\t \n\t\tmdl = kzalloc(sizeof(struct cx18_mdl), GFP_KERNEL|__GFP_NOWARN);\n\t\tif (mdl == NULL)\n\t\t\tbreak;\n\n\t\tbuf = kzalloc(sizeof(struct cx18_buffer),\n\t\t\t\tGFP_KERNEL|__GFP_NOWARN);\n\t\tif (buf == NULL) {\n\t\t\tkfree(mdl);\n\t\t\tbreak;\n\t\t}\n\n\t\tbuf->buf = kmalloc(s->buf_size, GFP_KERNEL|__GFP_NOWARN);\n\t\tif (buf->buf == NULL) {\n\t\t\tkfree(mdl);\n\t\t\tkfree(buf);\n\t\t\tbreak;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&mdl->list);\n\t\tINIT_LIST_HEAD(&mdl->buf_list);\n\t\tmdl->id = s->mdl_base_idx;  \n\t\tcx18_enqueue(s, mdl, &s->q_idle);\n\n\t\tINIT_LIST_HEAD(&buf->list);\n\t\tbuf->dma_handle = dma_map_single(&s->cx->pci_dev->dev,\n\t\t\t\t\t\t buf->buf, s->buf_size,\n\t\t\t\t\t\t s->dma);\n\t\tcx18_buf_sync_for_cpu(s, buf);\n\t\tlist_add_tail(&buf->list, &s->buf_pool);\n\t}\n\tif (i == s->buffers) {\n\t\tcx->free_mdl_idx += s->buffers;\n\t\treturn 0;\n\t}\n\tCX18_ERR(\"Couldn't allocate buffers for %s stream\\n\", s->name);\n\tcx18_stream_free(s);\n\treturn -ENOMEM;\n}\n\nvoid cx18_stream_free(struct cx18_stream *s)\n{\n\tstruct cx18_mdl *mdl;\n\tstruct cx18_buffer *buf;\n\tstruct cx18 *cx = s->cx;\n\n\tCX18_DEBUG_INFO(\"Deallocating buffers for %s stream\\n\", s->name);\n\n\t \n\tcx18_unload_queues(s);\n\n\t \n\twhile ((mdl = cx18_dequeue(s, &s->q_idle)))\n\t\tkfree(mdl);\n\n\t \n\twhile (!list_empty(&s->buf_pool)) {\n\t\tbuf = list_first_entry(&s->buf_pool, struct cx18_buffer, list);\n\t\tlist_del_init(&buf->list);\n\n\t\tdma_unmap_single(&s->cx->pci_dev->dev, buf->dma_handle,\n\t\t\t\t s->buf_size, s->dma);\n\t\tkfree(buf->buf);\n\t\tkfree(buf);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}