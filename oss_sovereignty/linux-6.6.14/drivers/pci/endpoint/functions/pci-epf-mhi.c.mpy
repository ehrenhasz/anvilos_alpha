{
  "module_name": "pci-epf-mhi.c",
  "hash_id": "79cd23a3908d690f69fb1f67ebfb0ab0f08de64096e572472f7757d837ebe14e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/endpoint/functions/pci-epf-mhi.c",
  "human_readable_source": "\n \n\n#include <linux/dmaengine.h>\n#include <linux/mhi_ep.h>\n#include <linux/module.h>\n#include <linux/of_dma.h>\n#include <linux/platform_device.h>\n#include <linux/pci-epc.h>\n#include <linux/pci-epf.h>\n\n#define MHI_VERSION_1_0 0x01000000\n\n#define to_epf_mhi(cntrl) container_of(cntrl, struct pci_epf_mhi, cntrl)\n\n \n#define MHI_EPF_USE_DMA BIT(0)\n\nstruct pci_epf_mhi_ep_info {\n\tconst struct mhi_ep_cntrl_config *config;\n\tstruct pci_epf_header *epf_header;\n\tenum pci_barno bar_num;\n\tu32 epf_flags;\n\tu32 msi_count;\n\tu32 mru;\n\tu32 flags;\n};\n\n#define MHI_EP_CHANNEL_CONFIG(ch_num, ch_name, direction)\t\\\n\t{\t\t\t\t\t\t\t\\\n\t\t.num = ch_num,\t\t\t\t\t\\\n\t\t.name = ch_name,\t\t\t\t\\\n\t\t.dir = direction,\t\t\t\t\\\n\t}\n\n#define MHI_EP_CHANNEL_CONFIG_UL(ch_num, ch_name)\t\t\\\n\tMHI_EP_CHANNEL_CONFIG(ch_num, ch_name, DMA_TO_DEVICE)\n\n#define MHI_EP_CHANNEL_CONFIG_DL(ch_num, ch_name)\t\t\\\n\tMHI_EP_CHANNEL_CONFIG(ch_num, ch_name, DMA_FROM_DEVICE)\n\nstatic const struct mhi_ep_channel_config mhi_v1_channels[] = {\n\tMHI_EP_CHANNEL_CONFIG_UL(0, \"LOOPBACK\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(1, \"LOOPBACK\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(2, \"SAHARA\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(3, \"SAHARA\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(4, \"DIAG\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(5, \"DIAG\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(6, \"SSR\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(7, \"SSR\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(8, \"QDSS\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(9, \"QDSS\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(10, \"EFS\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(11, \"EFS\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(12, \"MBIM\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(13, \"MBIM\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(14, \"QMI\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(15, \"QMI\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(16, \"QMI\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(17, \"QMI\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(18, \"IP-CTRL-1\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(19, \"IP-CTRL-1\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(20, \"IPCR\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(21, \"IPCR\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(32, \"DUN\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(33, \"DUN\"),\n\tMHI_EP_CHANNEL_CONFIG_UL(46, \"IP_SW0\"),\n\tMHI_EP_CHANNEL_CONFIG_DL(47, \"IP_SW0\"),\n};\n\nstatic const struct mhi_ep_cntrl_config mhi_v1_config = {\n\t.max_channels = 128,\n\t.num_channels = ARRAY_SIZE(mhi_v1_channels),\n\t.ch_cfg = mhi_v1_channels,\n\t.mhi_version = MHI_VERSION_1_0,\n};\n\nstatic struct pci_epf_header sdx55_header = {\n\t.vendorid = PCI_VENDOR_ID_QCOM,\n\t.deviceid = 0x0306,\n\t.baseclass_code = PCI_BASE_CLASS_COMMUNICATION,\n\t.subclass_code = PCI_CLASS_COMMUNICATION_MODEM & 0xff,\n\t.interrupt_pin\t= PCI_INTERRUPT_INTA,\n};\n\nstatic const struct pci_epf_mhi_ep_info sdx55_info = {\n\t.config = &mhi_v1_config,\n\t.epf_header = &sdx55_header,\n\t.bar_num = BAR_0,\n\t.epf_flags = PCI_BASE_ADDRESS_MEM_TYPE_32,\n\t.msi_count = 32,\n\t.mru = 0x8000,\n};\n\nstatic struct pci_epf_header sm8450_header = {\n\t.vendorid = PCI_VENDOR_ID_QCOM,\n\t.deviceid = 0x0306,\n\t.baseclass_code = PCI_CLASS_OTHERS,\n\t.interrupt_pin = PCI_INTERRUPT_INTA,\n};\n\nstatic const struct pci_epf_mhi_ep_info sm8450_info = {\n\t.config = &mhi_v1_config,\n\t.epf_header = &sm8450_header,\n\t.bar_num = BAR_0,\n\t.epf_flags = PCI_BASE_ADDRESS_MEM_TYPE_32,\n\t.msi_count = 32,\n\t.mru = 0x8000,\n\t.flags = MHI_EPF_USE_DMA,\n};\n\nstruct pci_epf_mhi {\n\tconst struct pci_epc_features *epc_features;\n\tconst struct pci_epf_mhi_ep_info *info;\n\tstruct mhi_ep_cntrl mhi_cntrl;\n\tstruct pci_epf *epf;\n\tstruct mutex lock;\n\tvoid __iomem *mmio;\n\tresource_size_t mmio_phys;\n\tstruct dma_chan *dma_chan_tx;\n\tstruct dma_chan *dma_chan_rx;\n\tu32 mmio_size;\n\tint irq;\n};\n\nstatic size_t get_align_offset(struct pci_epf_mhi *epf_mhi, u64 addr)\n{\n\treturn addr & (epf_mhi->epc_features->align -1);\n}\n\nstatic int __pci_epf_mhi_alloc_map(struct mhi_ep_cntrl *mhi_cntrl, u64 pci_addr,\n\t\t\t\t phys_addr_t *paddr, void __iomem **vaddr,\n\t\t\t\t size_t offset, size_t size)\n{\n\tstruct pci_epf_mhi *epf_mhi = to_epf_mhi(mhi_cntrl);\n\tstruct pci_epf *epf = epf_mhi->epf;\n\tstruct pci_epc *epc = epf->epc;\n\tint ret;\n\n\t*vaddr = pci_epc_mem_alloc_addr(epc, paddr, size + offset);\n\tif (!*vaddr)\n\t\treturn -ENOMEM;\n\n\tret = pci_epc_map_addr(epc, epf->func_no, epf->vfunc_no, *paddr,\n\t\t\t       pci_addr - offset, size + offset);\n\tif (ret) {\n\t\tpci_epc_mem_free_addr(epc, *paddr, *vaddr, size + offset);\n\t\treturn ret;\n\t}\n\n\t*paddr = *paddr + offset;\n\t*vaddr = *vaddr + offset;\n\n\treturn 0;\n}\n\nstatic int pci_epf_mhi_alloc_map(struct mhi_ep_cntrl *mhi_cntrl, u64 pci_addr,\n\t\t\t\t phys_addr_t *paddr, void __iomem **vaddr,\n\t\t\t\t size_t size)\n{\n\tstruct pci_epf_mhi *epf_mhi = to_epf_mhi(mhi_cntrl);\n\tsize_t offset = get_align_offset(epf_mhi, pci_addr);\n\n\treturn __pci_epf_mhi_alloc_map(mhi_cntrl, pci_addr, paddr, vaddr,\n\t\t\t\t      offset, size);\n}\n\nstatic void __pci_epf_mhi_unmap_free(struct mhi_ep_cntrl *mhi_cntrl,\n\t\t\t\t     u64 pci_addr, phys_addr_t paddr,\n\t\t\t\t     void __iomem *vaddr, size_t offset,\n\t\t\t\t     size_t size)\n{\n\tstruct pci_epf_mhi *epf_mhi = to_epf_mhi(mhi_cntrl);\n\tstruct pci_epf *epf = epf_mhi->epf;\n\tstruct pci_epc *epc = epf->epc;\n\n\tpci_epc_unmap_addr(epc, epf->func_no, epf->vfunc_no, paddr - offset);\n\tpci_epc_mem_free_addr(epc, paddr - offset, vaddr - offset,\n\t\t\t      size + offset);\n}\n\nstatic void pci_epf_mhi_unmap_free(struct mhi_ep_cntrl *mhi_cntrl, u64 pci_addr,\n\t\t\t\t   phys_addr_t paddr, void __iomem *vaddr,\n\t\t\t\t   size_t size)\n{\n\tstruct pci_epf_mhi *epf_mhi = to_epf_mhi(mhi_cntrl);\n\tsize_t offset = get_align_offset(epf_mhi, pci_addr);\n\n\t__pci_epf_mhi_unmap_free(mhi_cntrl, pci_addr, paddr, vaddr, offset,\n\t\t\t\t size);\n}\n\nstatic void pci_epf_mhi_raise_irq(struct mhi_ep_cntrl *mhi_cntrl, u32 vector)\n{\n\tstruct pci_epf_mhi *epf_mhi = to_epf_mhi(mhi_cntrl);\n\tstruct pci_epf *epf = epf_mhi->epf;\n\tstruct pci_epc *epc = epf->epc;\n\n\t \n\tpci_epc_raise_irq(epc, epf->func_no, epf->vfunc_no, PCI_EPC_IRQ_MSI,\n\t\t\t  vector + 1);\n}\n\nstatic int pci_epf_mhi_iatu_read(struct mhi_ep_cntrl *mhi_cntrl,\n\t\t\t\t struct mhi_ep_buf_info *buf_info)\n{\n\tstruct pci_epf_mhi *epf_mhi = to_epf_mhi(mhi_cntrl);\n\tsize_t offset = get_align_offset(epf_mhi, buf_info->host_addr);\n\tvoid __iomem *tre_buf;\n\tphys_addr_t tre_phys;\n\tint ret;\n\n\tmutex_lock(&epf_mhi->lock);\n\n\tret = __pci_epf_mhi_alloc_map(mhi_cntrl, buf_info->host_addr, &tre_phys,\n\t\t\t\t      &tre_buf, offset, buf_info->size);\n\tif (ret) {\n\t\tmutex_unlock(&epf_mhi->lock);\n\t\treturn ret;\n\t}\n\n\tmemcpy_fromio(buf_info->dev_addr, tre_buf, buf_info->size);\n\n\t__pci_epf_mhi_unmap_free(mhi_cntrl, buf_info->host_addr, tre_phys,\n\t\t\t\t tre_buf, offset, buf_info->size);\n\n\tmutex_unlock(&epf_mhi->lock);\n\n\treturn 0;\n}\n\nstatic int pci_epf_mhi_iatu_write(struct mhi_ep_cntrl *mhi_cntrl,\n\t\t\t\t  struct mhi_ep_buf_info *buf_info)\n{\n\tstruct pci_epf_mhi *epf_mhi = to_epf_mhi(mhi_cntrl);\n\tsize_t offset = get_align_offset(epf_mhi, buf_info->host_addr);\n\tvoid __iomem *tre_buf;\n\tphys_addr_t tre_phys;\n\tint ret;\n\n\tmutex_lock(&epf_mhi->lock);\n\n\tret = __pci_epf_mhi_alloc_map(mhi_cntrl, buf_info->host_addr, &tre_phys,\n\t\t\t\t      &tre_buf, offset, buf_info->size);\n\tif (ret) {\n\t\tmutex_unlock(&epf_mhi->lock);\n\t\treturn ret;\n\t}\n\n\tmemcpy_toio(tre_buf, buf_info->dev_addr, buf_info->size);\n\n\t__pci_epf_mhi_unmap_free(mhi_cntrl, buf_info->host_addr, tre_phys,\n\t\t\t\t tre_buf, offset, buf_info->size);\n\n\tmutex_unlock(&epf_mhi->lock);\n\n\treturn 0;\n}\n\nstatic void pci_epf_mhi_dma_callback(void *param)\n{\n\tcomplete(param);\n}\n\nstatic int pci_epf_mhi_edma_read(struct mhi_ep_cntrl *mhi_cntrl,\n\t\t\t\t struct mhi_ep_buf_info *buf_info)\n{\n\tstruct pci_epf_mhi *epf_mhi = to_epf_mhi(mhi_cntrl);\n\tstruct device *dma_dev = epf_mhi->epf->epc->dev.parent;\n\tstruct dma_chan *chan = epf_mhi->dma_chan_rx;\n\tstruct device *dev = &epf_mhi->epf->dev;\n\tDECLARE_COMPLETION_ONSTACK(complete);\n\tstruct dma_async_tx_descriptor *desc;\n\tstruct dma_slave_config config = {};\n\tdma_cookie_t cookie;\n\tdma_addr_t dst_addr;\n\tint ret;\n\n\tif (buf_info->size < SZ_4K)\n\t\treturn pci_epf_mhi_iatu_read(mhi_cntrl, buf_info);\n\n\tmutex_lock(&epf_mhi->lock);\n\n\tconfig.direction = DMA_DEV_TO_MEM;\n\tconfig.src_addr = buf_info->host_addr;\n\n\tret = dmaengine_slave_config(chan, &config);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to configure DMA channel\\n\");\n\t\tgoto err_unlock;\n\t}\n\n\tdst_addr = dma_map_single(dma_dev, buf_info->dev_addr, buf_info->size,\n\t\t\t\t  DMA_FROM_DEVICE);\n\tret = dma_mapping_error(dma_dev, dst_addr);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to map remote memory\\n\");\n\t\tgoto err_unlock;\n\t}\n\n\tdesc = dmaengine_prep_slave_single(chan, dst_addr, buf_info->size,\n\t\t\t\t\t   DMA_DEV_TO_MEM,\n\t\t\t\t\t   DMA_CTRL_ACK | DMA_PREP_INTERRUPT);\n\tif (!desc) {\n\t\tdev_err(dev, \"Failed to prepare DMA\\n\");\n\t\tret = -EIO;\n\t\tgoto err_unmap;\n\t}\n\n\tdesc->callback = pci_epf_mhi_dma_callback;\n\tdesc->callback_param = &complete;\n\n\tcookie = dmaengine_submit(desc);\n\tret = dma_submit_error(cookie);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to do DMA submit\\n\");\n\t\tgoto err_unmap;\n\t}\n\n\tdma_async_issue_pending(chan);\n\tret = wait_for_completion_timeout(&complete, msecs_to_jiffies(1000));\n\tif (!ret) {\n\t\tdev_err(dev, \"DMA transfer timeout\\n\");\n\t\tdmaengine_terminate_sync(chan);\n\t\tret = -ETIMEDOUT;\n\t}\n\nerr_unmap:\n\tdma_unmap_single(dma_dev, dst_addr, buf_info->size, DMA_FROM_DEVICE);\nerr_unlock:\n\tmutex_unlock(&epf_mhi->lock);\n\n\treturn ret;\n}\n\nstatic int pci_epf_mhi_edma_write(struct mhi_ep_cntrl *mhi_cntrl,\n\t\t\t\t  struct mhi_ep_buf_info *buf_info)\n{\n\tstruct pci_epf_mhi *epf_mhi = to_epf_mhi(mhi_cntrl);\n\tstruct device *dma_dev = epf_mhi->epf->epc->dev.parent;\n\tstruct dma_chan *chan = epf_mhi->dma_chan_tx;\n\tstruct device *dev = &epf_mhi->epf->dev;\n\tDECLARE_COMPLETION_ONSTACK(complete);\n\tstruct dma_async_tx_descriptor *desc;\n\tstruct dma_slave_config config = {};\n\tdma_cookie_t cookie;\n\tdma_addr_t src_addr;\n\tint ret;\n\n\tif (buf_info->size < SZ_4K)\n\t\treturn pci_epf_mhi_iatu_write(mhi_cntrl, buf_info);\n\n\tmutex_lock(&epf_mhi->lock);\n\n\tconfig.direction = DMA_MEM_TO_DEV;\n\tconfig.dst_addr = buf_info->host_addr;\n\n\tret = dmaengine_slave_config(chan, &config);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to configure DMA channel\\n\");\n\t\tgoto err_unlock;\n\t}\n\n\tsrc_addr = dma_map_single(dma_dev, buf_info->dev_addr, buf_info->size,\n\t\t\t\t  DMA_TO_DEVICE);\n\tret = dma_mapping_error(dma_dev, src_addr);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to map remote memory\\n\");\n\t\tgoto err_unlock;\n\t}\n\n\tdesc = dmaengine_prep_slave_single(chan, src_addr, buf_info->size,\n\t\t\t\t\t   DMA_MEM_TO_DEV,\n\t\t\t\t\t   DMA_CTRL_ACK | DMA_PREP_INTERRUPT);\n\tif (!desc) {\n\t\tdev_err(dev, \"Failed to prepare DMA\\n\");\n\t\tret = -EIO;\n\t\tgoto err_unmap;\n\t}\n\n\tdesc->callback = pci_epf_mhi_dma_callback;\n\tdesc->callback_param = &complete;\n\n\tcookie = dmaengine_submit(desc);\n\tret = dma_submit_error(cookie);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to do DMA submit\\n\");\n\t\tgoto err_unmap;\n\t}\n\n\tdma_async_issue_pending(chan);\n\tret = wait_for_completion_timeout(&complete, msecs_to_jiffies(1000));\n\tif (!ret) {\n\t\tdev_err(dev, \"DMA transfer timeout\\n\");\n\t\tdmaengine_terminate_sync(chan);\n\t\tret = -ETIMEDOUT;\n\t}\n\nerr_unmap:\n\tdma_unmap_single(dma_dev, src_addr, buf_info->size, DMA_TO_DEVICE);\nerr_unlock:\n\tmutex_unlock(&epf_mhi->lock);\n\n\treturn ret;\n}\n\nstruct epf_dma_filter {\n\tstruct device *dev;\n\tu32 dma_mask;\n};\n\nstatic bool pci_epf_mhi_filter(struct dma_chan *chan, void *node)\n{\n\tstruct epf_dma_filter *filter = node;\n\tstruct dma_slave_caps caps;\n\n\tmemset(&caps, 0, sizeof(caps));\n\tdma_get_slave_caps(chan, &caps);\n\n\treturn chan->device->dev == filter->dev && filter->dma_mask &\n\t\t\t\t\tcaps.directions;\n}\n\nstatic int pci_epf_mhi_dma_init(struct pci_epf_mhi *epf_mhi)\n{\n\tstruct device *dma_dev = epf_mhi->epf->epc->dev.parent;\n\tstruct device *dev = &epf_mhi->epf->dev;\n\tstruct epf_dma_filter filter;\n\tdma_cap_mask_t mask;\n\n\tdma_cap_zero(mask);\n\tdma_cap_set(DMA_SLAVE, mask);\n\n\tfilter.dev = dma_dev;\n\tfilter.dma_mask = BIT(DMA_MEM_TO_DEV);\n\tepf_mhi->dma_chan_tx = dma_request_channel(mask, pci_epf_mhi_filter,\n\t\t\t\t\t\t   &filter);\n\tif (IS_ERR_OR_NULL(epf_mhi->dma_chan_tx)) {\n\t\tdev_err(dev, \"Failed to request tx channel\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tfilter.dma_mask = BIT(DMA_DEV_TO_MEM);\n\tepf_mhi->dma_chan_rx = dma_request_channel(mask, pci_epf_mhi_filter,\n\t\t\t\t\t\t   &filter);\n\tif (IS_ERR_OR_NULL(epf_mhi->dma_chan_rx)) {\n\t\tdev_err(dev, \"Failed to request rx channel\\n\");\n\t\tdma_release_channel(epf_mhi->dma_chan_tx);\n\t\tepf_mhi->dma_chan_tx = NULL;\n\t\treturn -ENODEV;\n\t}\n\n\treturn 0;\n}\n\nstatic void pci_epf_mhi_dma_deinit(struct pci_epf_mhi *epf_mhi)\n{\n\tdma_release_channel(epf_mhi->dma_chan_tx);\n\tdma_release_channel(epf_mhi->dma_chan_rx);\n\tepf_mhi->dma_chan_tx = NULL;\n\tepf_mhi->dma_chan_rx = NULL;\n}\n\nstatic int pci_epf_mhi_core_init(struct pci_epf *epf)\n{\n\tstruct pci_epf_mhi *epf_mhi = epf_get_drvdata(epf);\n\tconst struct pci_epf_mhi_ep_info *info = epf_mhi->info;\n\tstruct pci_epf_bar *epf_bar = &epf->bar[info->bar_num];\n\tstruct pci_epc *epc = epf->epc;\n\tstruct device *dev = &epf->dev;\n\tint ret;\n\n\tepf_bar->phys_addr = epf_mhi->mmio_phys;\n\tepf_bar->size = epf_mhi->mmio_size;\n\tepf_bar->barno = info->bar_num;\n\tepf_bar->flags = info->epf_flags;\n\tret = pci_epc_set_bar(epc, epf->func_no, epf->vfunc_no, epf_bar);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to set BAR: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = pci_epc_set_msi(epc, epf->func_no, epf->vfunc_no,\n\t\t\t      order_base_2(info->msi_count));\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to set MSI configuration: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = pci_epc_write_header(epc, epf->func_no, epf->vfunc_no,\n\t\t\t\t   epf->header);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to set Configuration header: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tepf_mhi->epc_features = pci_epc_get_features(epc, epf->func_no, epf->vfunc_no);\n\tif (!epf_mhi->epc_features)\n\t\treturn -ENODATA;\n\n\treturn 0;\n}\n\nstatic int pci_epf_mhi_link_up(struct pci_epf *epf)\n{\n\tstruct pci_epf_mhi *epf_mhi = epf_get_drvdata(epf);\n\tconst struct pci_epf_mhi_ep_info *info = epf_mhi->info;\n\tstruct mhi_ep_cntrl *mhi_cntrl = &epf_mhi->mhi_cntrl;\n\tstruct pci_epc *epc = epf->epc;\n\tstruct device *dev = &epf->dev;\n\tint ret;\n\n\tif (info->flags & MHI_EPF_USE_DMA) {\n\t\tret = pci_epf_mhi_dma_init(epf_mhi);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"Failed to initialize DMA: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tmhi_cntrl->mmio = epf_mhi->mmio;\n\tmhi_cntrl->irq = epf_mhi->irq;\n\tmhi_cntrl->mru = info->mru;\n\n\t \n\tmhi_cntrl->cntrl_dev = epc->dev.parent;\n\tmhi_cntrl->raise_irq = pci_epf_mhi_raise_irq;\n\tmhi_cntrl->alloc_map = pci_epf_mhi_alloc_map;\n\tmhi_cntrl->unmap_free = pci_epf_mhi_unmap_free;\n\tif (info->flags & MHI_EPF_USE_DMA) {\n\t\tmhi_cntrl->read_from_host = pci_epf_mhi_edma_read;\n\t\tmhi_cntrl->write_to_host = pci_epf_mhi_edma_write;\n\t} else {\n\t\tmhi_cntrl->read_from_host = pci_epf_mhi_iatu_read;\n\t\tmhi_cntrl->write_to_host = pci_epf_mhi_iatu_write;\n\t}\n\n\t \n\tret = mhi_ep_register_controller(mhi_cntrl, info->config);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to register MHI EP controller: %d\\n\", ret);\n\t\tif (info->flags & MHI_EPF_USE_DMA)\n\t\t\tpci_epf_mhi_dma_deinit(epf_mhi);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int pci_epf_mhi_link_down(struct pci_epf *epf)\n{\n\tstruct pci_epf_mhi *epf_mhi = epf_get_drvdata(epf);\n\tconst struct pci_epf_mhi_ep_info *info = epf_mhi->info;\n\tstruct mhi_ep_cntrl *mhi_cntrl = &epf_mhi->mhi_cntrl;\n\n\tif (mhi_cntrl->mhi_dev) {\n\t\tmhi_ep_power_down(mhi_cntrl);\n\t\tif (info->flags & MHI_EPF_USE_DMA)\n\t\t\tpci_epf_mhi_dma_deinit(epf_mhi);\n\t\tmhi_ep_unregister_controller(mhi_cntrl);\n\t}\n\n\treturn 0;\n}\n\nstatic int pci_epf_mhi_bme(struct pci_epf *epf)\n{\n\tstruct pci_epf_mhi *epf_mhi = epf_get_drvdata(epf);\n\tconst struct pci_epf_mhi_ep_info *info = epf_mhi->info;\n\tstruct mhi_ep_cntrl *mhi_cntrl = &epf_mhi->mhi_cntrl;\n\tstruct device *dev = &epf->dev;\n\tint ret;\n\n\t \n\tif (!mhi_cntrl->enabled && mhi_cntrl->mhi_dev) {\n\t\tret = mhi_ep_power_up(mhi_cntrl);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"Failed to power up MHI EP: %d\\n\", ret);\n\t\t\tif (info->flags & MHI_EPF_USE_DMA)\n\t\t\t\tpci_epf_mhi_dma_deinit(epf_mhi);\n\t\t\tmhi_ep_unregister_controller(mhi_cntrl);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int pci_epf_mhi_bind(struct pci_epf *epf)\n{\n\tstruct pci_epf_mhi *epf_mhi = epf_get_drvdata(epf);\n\tstruct pci_epc *epc = epf->epc;\n\tstruct platform_device *pdev = to_platform_device(epc->dev.parent);\n\tstruct resource *res;\n\tint ret;\n\n\t \n\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"mmio\");\n\tepf_mhi->mmio_phys = res->start;\n\tepf_mhi->mmio_size = resource_size(res);\n\n\tepf_mhi->mmio = ioremap(epf_mhi->mmio_phys, epf_mhi->mmio_size);\n\tif (!epf_mhi->mmio)\n\t\treturn -ENOMEM;\n\n\tret = platform_get_irq_byname(pdev, \"doorbell\");\n\tif (ret < 0) {\n\t\tiounmap(epf_mhi->mmio);\n\t\treturn ret;\n\t}\n\n\tepf_mhi->irq = ret;\n\n\treturn 0;\n}\n\nstatic void pci_epf_mhi_unbind(struct pci_epf *epf)\n{\n\tstruct pci_epf_mhi *epf_mhi = epf_get_drvdata(epf);\n\tconst struct pci_epf_mhi_ep_info *info = epf_mhi->info;\n\tstruct pci_epf_bar *epf_bar = &epf->bar[info->bar_num];\n\tstruct mhi_ep_cntrl *mhi_cntrl = &epf_mhi->mhi_cntrl;\n\tstruct pci_epc *epc = epf->epc;\n\n\t \n\tif (mhi_cntrl->mhi_dev) {\n\t\tmhi_ep_power_down(mhi_cntrl);\n\t\tif (info->flags & MHI_EPF_USE_DMA)\n\t\t\tpci_epf_mhi_dma_deinit(epf_mhi);\n\t\tmhi_ep_unregister_controller(mhi_cntrl);\n\t}\n\n\tiounmap(epf_mhi->mmio);\n\tpci_epc_clear_bar(epc, epf->func_no, epf->vfunc_no, epf_bar);\n}\n\nstatic struct pci_epc_event_ops pci_epf_mhi_event_ops = {\n\t.core_init = pci_epf_mhi_core_init,\n\t.link_up = pci_epf_mhi_link_up,\n\t.link_down = pci_epf_mhi_link_down,\n\t.bme = pci_epf_mhi_bme,\n};\n\nstatic int pci_epf_mhi_probe(struct pci_epf *epf,\n\t\t\t     const struct pci_epf_device_id *id)\n{\n\tstruct pci_epf_mhi_ep_info *info =\n\t\t\t(struct pci_epf_mhi_ep_info *)id->driver_data;\n\tstruct pci_epf_mhi *epf_mhi;\n\tstruct device *dev = &epf->dev;\n\n\tepf_mhi = devm_kzalloc(dev, sizeof(*epf_mhi), GFP_KERNEL);\n\tif (!epf_mhi)\n\t\treturn -ENOMEM;\n\n\tepf->header = info->epf_header;\n\tepf_mhi->info = info;\n\tepf_mhi->epf = epf;\n\n\tepf->event_ops = &pci_epf_mhi_event_ops;\n\n\tmutex_init(&epf_mhi->lock);\n\n\tepf_set_drvdata(epf, epf_mhi);\n\n\treturn 0;\n}\n\nstatic const struct pci_epf_device_id pci_epf_mhi_ids[] = {\n\t{ .name = \"sdx55\", .driver_data = (kernel_ulong_t)&sdx55_info },\n\t{ .name = \"sm8450\", .driver_data = (kernel_ulong_t)&sm8450_info },\n\t{},\n};\n\nstatic struct pci_epf_ops pci_epf_mhi_ops = {\n\t.unbind\t= pci_epf_mhi_unbind,\n\t.bind\t= pci_epf_mhi_bind,\n};\n\nstatic struct pci_epf_driver pci_epf_mhi_driver = {\n\t.driver.name\t= \"pci_epf_mhi\",\n\t.probe\t\t= pci_epf_mhi_probe,\n\t.id_table\t= pci_epf_mhi_ids,\n\t.ops\t\t= &pci_epf_mhi_ops,\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic int __init pci_epf_mhi_init(void)\n{\n\treturn pci_epf_register_driver(&pci_epf_mhi_driver);\n}\nmodule_init(pci_epf_mhi_init);\n\nstatic void __exit pci_epf_mhi_exit(void)\n{\n\tpci_epf_unregister_driver(&pci_epf_mhi_driver);\n}\nmodule_exit(pci_epf_mhi_exit);\n\nMODULE_DESCRIPTION(\"PCI EPF driver for MHI Endpoint devices\");\nMODULE_AUTHOR(\"Manivannan Sadhasivam <manivannan.sadhasivam@linaro.org>\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}