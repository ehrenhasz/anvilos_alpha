{
  "module_name": "pci-tegra.c",
  "hash_id": "a0d22ef3d238199549d11068b809888574f094dc133ee1175d0baac7a902bb83",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/controller/pci-tegra.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/debugfs.h>\n#include <linux/delay.h>\n#include <linux/export.h>\n#include <linux/gpio/consumer.h>\n#include <linux/interrupt.h>\n#include <linux/iopoll.h>\n#include <linux/irq.h>\n#include <linux/irqchip/chained_irq.h>\n#include <linux/irqdomain.h>\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/msi.h>\n#include <linux/of_address.h>\n#include <linux/of_pci.h>\n#include <linux/of_platform.h>\n#include <linux/pci.h>\n#include <linux/phy/phy.h>\n#include <linux/pinctrl/consumer.h>\n#include <linux/platform_device.h>\n#include <linux/reset.h>\n#include <linux/sizes.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/regulator/consumer.h>\n\n#include <soc/tegra/cpuidle.h>\n#include <soc/tegra/pmc.h>\n\n#include \"../pci.h\"\n\n#define INT_PCI_MSI_NR (8 * 32)\n\n \n\n#define AFI_AXI_BAR0_SZ\t0x00\n#define AFI_AXI_BAR1_SZ\t0x04\n#define AFI_AXI_BAR2_SZ\t0x08\n#define AFI_AXI_BAR3_SZ\t0x0c\n#define AFI_AXI_BAR4_SZ\t0x10\n#define AFI_AXI_BAR5_SZ\t0x14\n\n#define AFI_AXI_BAR0_START\t0x18\n#define AFI_AXI_BAR1_START\t0x1c\n#define AFI_AXI_BAR2_START\t0x20\n#define AFI_AXI_BAR3_START\t0x24\n#define AFI_AXI_BAR4_START\t0x28\n#define AFI_AXI_BAR5_START\t0x2c\n\n#define AFI_FPCI_BAR0\t0x30\n#define AFI_FPCI_BAR1\t0x34\n#define AFI_FPCI_BAR2\t0x38\n#define AFI_FPCI_BAR3\t0x3c\n#define AFI_FPCI_BAR4\t0x40\n#define AFI_FPCI_BAR5\t0x44\n\n#define AFI_CACHE_BAR0_SZ\t0x48\n#define AFI_CACHE_BAR0_ST\t0x4c\n#define AFI_CACHE_BAR1_SZ\t0x50\n#define AFI_CACHE_BAR1_ST\t0x54\n\n#define AFI_MSI_BAR_SZ\t\t0x60\n#define AFI_MSI_FPCI_BAR_ST\t0x64\n#define AFI_MSI_AXI_BAR_ST\t0x68\n\n#define AFI_MSI_VEC(x)\t\t(0x6c + ((x) * 4))\n#define AFI_MSI_EN_VEC(x)\t(0x8c + ((x) * 4))\n\n#define AFI_CONFIGURATION\t\t0xac\n#define  AFI_CONFIGURATION_EN_FPCI\t\t(1 << 0)\n#define  AFI_CONFIGURATION_CLKEN_OVERRIDE\t(1 << 31)\n\n#define AFI_FPCI_ERROR_MASKS\t0xb0\n\n#define AFI_INTR_MASK\t\t0xb4\n#define  AFI_INTR_MASK_INT_MASK\t(1 << 0)\n#define  AFI_INTR_MASK_MSI_MASK\t(1 << 8)\n\n#define AFI_INTR_CODE\t\t\t0xb8\n#define  AFI_INTR_CODE_MASK\t\t0xf\n#define  AFI_INTR_INI_SLAVE_ERROR\t1\n#define  AFI_INTR_INI_DECODE_ERROR\t2\n#define  AFI_INTR_TARGET_ABORT\t\t3\n#define  AFI_INTR_MASTER_ABORT\t\t4\n#define  AFI_INTR_INVALID_WRITE\t\t5\n#define  AFI_INTR_LEGACY\t\t6\n#define  AFI_INTR_FPCI_DECODE_ERROR\t7\n#define  AFI_INTR_AXI_DECODE_ERROR\t8\n#define  AFI_INTR_FPCI_TIMEOUT\t\t9\n#define  AFI_INTR_PE_PRSNT_SENSE\t10\n#define  AFI_INTR_PE_CLKREQ_SENSE\t11\n#define  AFI_INTR_CLKCLAMP_SENSE\t12\n#define  AFI_INTR_RDY4PD_SENSE\t\t13\n#define  AFI_INTR_P2P_ERROR\t\t14\n\n#define AFI_INTR_SIGNATURE\t0xbc\n#define AFI_UPPER_FPCI_ADDRESS\t0xc0\n#define AFI_SM_INTR_ENABLE\t0xc4\n#define  AFI_SM_INTR_INTA_ASSERT\t(1 << 0)\n#define  AFI_SM_INTR_INTB_ASSERT\t(1 << 1)\n#define  AFI_SM_INTR_INTC_ASSERT\t(1 << 2)\n#define  AFI_SM_INTR_INTD_ASSERT\t(1 << 3)\n#define  AFI_SM_INTR_INTA_DEASSERT\t(1 << 4)\n#define  AFI_SM_INTR_INTB_DEASSERT\t(1 << 5)\n#define  AFI_SM_INTR_INTC_DEASSERT\t(1 << 6)\n#define  AFI_SM_INTR_INTD_DEASSERT\t(1 << 7)\n\n#define AFI_AFI_INTR_ENABLE\t\t0xc8\n#define  AFI_INTR_EN_INI_SLVERR\t\t(1 << 0)\n#define  AFI_INTR_EN_INI_DECERR\t\t(1 << 1)\n#define  AFI_INTR_EN_TGT_SLVERR\t\t(1 << 2)\n#define  AFI_INTR_EN_TGT_DECERR\t\t(1 << 3)\n#define  AFI_INTR_EN_TGT_WRERR\t\t(1 << 4)\n#define  AFI_INTR_EN_DFPCI_DECERR\t(1 << 5)\n#define  AFI_INTR_EN_AXI_DECERR\t\t(1 << 6)\n#define  AFI_INTR_EN_FPCI_TIMEOUT\t(1 << 7)\n#define  AFI_INTR_EN_PRSNT_SENSE\t(1 << 8)\n\n#define AFI_PCIE_PME\t\t0xf0\n\n#define AFI_PCIE_CONFIG\t\t\t\t\t0x0f8\n#define  AFI_PCIE_CONFIG_PCIE_DISABLE(x)\t\t(1 << ((x) + 1))\n#define  AFI_PCIE_CONFIG_PCIE_DISABLE_ALL\t\t0xe\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_MASK\t(0xf << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_SINGLE\t(0x0 << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_420\t(0x0 << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_X2_X1\t(0x0 << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_401\t(0x0 << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_DUAL\t(0x1 << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_222\t(0x1 << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_X4_X1\t(0x1 << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_211\t(0x1 << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_411\t(0x2 << 20)\n#define  AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_111\t(0x2 << 20)\n#define  AFI_PCIE_CONFIG_PCIE_CLKREQ_GPIO(x)\t\t(1 << ((x) + 29))\n#define  AFI_PCIE_CONFIG_PCIE_CLKREQ_GPIO_ALL\t\t(0x7 << 29)\n\n#define AFI_FUSE\t\t\t0x104\n#define  AFI_FUSE_PCIE_T0_GEN2_DIS\t(1 << 2)\n\n#define AFI_PEX0_CTRL\t\t\t0x110\n#define AFI_PEX1_CTRL\t\t\t0x118\n#define  AFI_PEX_CTRL_RST\t\t(1 << 0)\n#define  AFI_PEX_CTRL_CLKREQ_EN\t\t(1 << 1)\n#define  AFI_PEX_CTRL_REFCLK_EN\t\t(1 << 3)\n#define  AFI_PEX_CTRL_OVERRIDE_EN\t(1 << 4)\n\n#define AFI_PLLE_CONTROL\t\t0x160\n#define  AFI_PLLE_CONTROL_BYPASS_PADS2PLLE_CONTROL (1 << 9)\n#define  AFI_PLLE_CONTROL_PADS2PLLE_CONTROL_EN (1 << 1)\n\n#define AFI_PEXBIAS_CTRL_0\t\t0x168\n\n#define RP_ECTL_2_R1\t0x00000e84\n#define  RP_ECTL_2_R1_RX_CTLE_1C_MASK\t\t0xffff\n\n#define RP_ECTL_4_R1\t0x00000e8c\n#define  RP_ECTL_4_R1_RX_CDR_CTRL_1C_MASK\t(0xffff << 16)\n#define  RP_ECTL_4_R1_RX_CDR_CTRL_1C_SHIFT\t16\n\n#define RP_ECTL_5_R1\t0x00000e90\n#define  RP_ECTL_5_R1_RX_EQ_CTRL_L_1C_MASK\t0xffffffff\n\n#define RP_ECTL_6_R1\t0x00000e94\n#define  RP_ECTL_6_R1_RX_EQ_CTRL_H_1C_MASK\t0xffffffff\n\n#define RP_ECTL_2_R2\t0x00000ea4\n#define  RP_ECTL_2_R2_RX_CTLE_1C_MASK\t0xffff\n\n#define RP_ECTL_4_R2\t0x00000eac\n#define  RP_ECTL_4_R2_RX_CDR_CTRL_1C_MASK\t(0xffff << 16)\n#define  RP_ECTL_4_R2_RX_CDR_CTRL_1C_SHIFT\t16\n\n#define RP_ECTL_5_R2\t0x00000eb0\n#define  RP_ECTL_5_R2_RX_EQ_CTRL_L_1C_MASK\t0xffffffff\n\n#define RP_ECTL_6_R2\t0x00000eb4\n#define  RP_ECTL_6_R2_RX_EQ_CTRL_H_1C_MASK\t0xffffffff\n\n#define RP_VEND_XP\t0x00000f00\n#define  RP_VEND_XP_DL_UP\t\t\t(1 << 30)\n#define  RP_VEND_XP_OPPORTUNISTIC_ACK\t\t(1 << 27)\n#define  RP_VEND_XP_OPPORTUNISTIC_UPDATEFC\t(1 << 28)\n#define  RP_VEND_XP_UPDATE_FC_THRESHOLD_MASK\t(0xff << 18)\n\n#define RP_VEND_CTL0\t0x00000f44\n#define  RP_VEND_CTL0_DSK_RST_PULSE_WIDTH_MASK\t(0xf << 12)\n#define  RP_VEND_CTL0_DSK_RST_PULSE_WIDTH\t(0x9 << 12)\n\n#define RP_VEND_CTL1\t0x00000f48\n#define  RP_VEND_CTL1_ERPT\t(1 << 13)\n\n#define RP_VEND_XP_BIST\t0x00000f4c\n#define  RP_VEND_XP_BIST_GOTO_L1_L2_AFTER_DLLP_DONE\t(1 << 28)\n\n#define RP_VEND_CTL2 0x00000fa8\n#define  RP_VEND_CTL2_PCA_ENABLE (1 << 7)\n\n#define RP_PRIV_MISC\t0x00000fe0\n#define  RP_PRIV_MISC_PRSNT_MAP_EP_PRSNT\t\t(0xe << 0)\n#define  RP_PRIV_MISC_PRSNT_MAP_EP_ABSNT\t\t(0xf << 0)\n#define  RP_PRIV_MISC_CTLR_CLK_CLAMP_THRESHOLD_MASK\t(0x7f << 16)\n#define  RP_PRIV_MISC_CTLR_CLK_CLAMP_THRESHOLD\t\t(0xf << 16)\n#define  RP_PRIV_MISC_CTLR_CLK_CLAMP_ENABLE\t\t(1 << 23)\n#define  RP_PRIV_MISC_TMS_CLK_CLAMP_THRESHOLD_MASK\t(0x7f << 24)\n#define  RP_PRIV_MISC_TMS_CLK_CLAMP_THRESHOLD\t\t(0xf << 24)\n#define  RP_PRIV_MISC_TMS_CLK_CLAMP_ENABLE\t\t(1 << 31)\n\n#define RP_LINK_CONTROL_STATUS\t\t\t0x00000090\n#define  RP_LINK_CONTROL_STATUS_DL_LINK_ACTIVE\t0x20000000\n#define  RP_LINK_CONTROL_STATUS_LINKSTAT_MASK\t0x3fff0000\n\n#define RP_LINK_CONTROL_STATUS_2\t\t0x000000b0\n\n#define PADS_CTL_SEL\t\t0x0000009c\n\n#define PADS_CTL\t\t0x000000a0\n#define  PADS_CTL_IDDQ_1L\t(1 << 0)\n#define  PADS_CTL_TX_DATA_EN_1L\t(1 << 6)\n#define  PADS_CTL_RX_DATA_EN_1L\t(1 << 10)\n\n#define PADS_PLL_CTL_TEGRA20\t\t\t0x000000b8\n#define PADS_PLL_CTL_TEGRA30\t\t\t0x000000b4\n#define  PADS_PLL_CTL_RST_B4SM\t\t\t(1 << 1)\n#define  PADS_PLL_CTL_LOCKDET\t\t\t(1 << 8)\n#define  PADS_PLL_CTL_REFCLK_MASK\t\t(0x3 << 16)\n#define  PADS_PLL_CTL_REFCLK_INTERNAL_CML\t(0 << 16)\n#define  PADS_PLL_CTL_REFCLK_INTERNAL_CMOS\t(1 << 16)\n#define  PADS_PLL_CTL_REFCLK_EXTERNAL\t\t(2 << 16)\n#define  PADS_PLL_CTL_TXCLKREF_MASK\t\t(0x1 << 20)\n#define  PADS_PLL_CTL_TXCLKREF_DIV10\t\t(0 << 20)\n#define  PADS_PLL_CTL_TXCLKREF_DIV5\t\t(1 << 20)\n#define  PADS_PLL_CTL_TXCLKREF_BUF_EN\t\t(1 << 22)\n\n#define PADS_REFCLK_CFG0\t\t\t0x000000c8\n#define PADS_REFCLK_CFG1\t\t\t0x000000cc\n#define PADS_REFCLK_BIAS\t\t\t0x000000d0\n\n \n#define PADS_REFCLK_CFG_TERM_SHIFT\t\t2   \n#define PADS_REFCLK_CFG_E_TERM_SHIFT\t\t7\n#define PADS_REFCLK_CFG_PREDI_SHIFT\t\t8   \n#define PADS_REFCLK_CFG_DRVI_SHIFT\t\t12  \n\n#define PME_ACK_TIMEOUT 10000\n#define LINK_RETRAIN_TIMEOUT 100000  \n\nstruct tegra_msi {\n\tDECLARE_BITMAP(used, INT_PCI_MSI_NR);\n\tstruct irq_domain *domain;\n\tstruct mutex map_lock;\n\tspinlock_t mask_lock;\n\tvoid *virt;\n\tdma_addr_t phys;\n\tint irq;\n};\n\n \nstruct tegra_pcie_port_soc {\n\tstruct {\n\t\tu8 turnoff_bit;\n\t\tu8 ack_bit;\n\t} pme;\n};\n\nstruct tegra_pcie_soc {\n\tunsigned int num_ports;\n\tconst struct tegra_pcie_port_soc *ports;\n\tunsigned int msi_base_shift;\n\tunsigned long afi_pex2_ctrl;\n\tu32 pads_pll_ctl;\n\tu32 tx_ref_sel;\n\tu32 pads_refclk_cfg0;\n\tu32 pads_refclk_cfg1;\n\tu32 update_fc_threshold;\n\tbool has_pex_clkreq_en;\n\tbool has_pex_bias_ctrl;\n\tbool has_intr_prsnt_sense;\n\tbool has_cml_clk;\n\tbool has_gen2;\n\tbool force_pca_enable;\n\tbool program_uphy;\n\tbool update_clamp_threshold;\n\tbool program_deskew_time;\n\tbool update_fc_timer;\n\tbool has_cache_bars;\n\tstruct {\n\t\tstruct {\n\t\t\tu32 rp_ectl_2_r1;\n\t\t\tu32 rp_ectl_4_r1;\n\t\t\tu32 rp_ectl_5_r1;\n\t\t\tu32 rp_ectl_6_r1;\n\t\t\tu32 rp_ectl_2_r2;\n\t\t\tu32 rp_ectl_4_r2;\n\t\t\tu32 rp_ectl_5_r2;\n\t\t\tu32 rp_ectl_6_r2;\n\t\t} regs;\n\t\tbool enable;\n\t} ectl;\n};\n\nstruct tegra_pcie {\n\tstruct device *dev;\n\n\tvoid __iomem *pads;\n\tvoid __iomem *afi;\n\tvoid __iomem *cfg;\n\tint irq;\n\n\tstruct resource cs;\n\n\tstruct clk *pex_clk;\n\tstruct clk *afi_clk;\n\tstruct clk *pll_e;\n\tstruct clk *cml_clk;\n\n\tstruct reset_control *pex_rst;\n\tstruct reset_control *afi_rst;\n\tstruct reset_control *pcie_xrst;\n\n\tbool legacy_phy;\n\tstruct phy *phy;\n\n\tstruct tegra_msi msi;\n\n\tstruct list_head ports;\n\tu32 xbar_config;\n\n\tstruct regulator_bulk_data *supplies;\n\tunsigned int num_supplies;\n\n\tconst struct tegra_pcie_soc *soc;\n\tstruct dentry *debugfs;\n};\n\nstatic inline struct tegra_pcie *msi_to_pcie(struct tegra_msi *msi)\n{\n\treturn container_of(msi, struct tegra_pcie, msi);\n}\n\nstruct tegra_pcie_port {\n\tstruct tegra_pcie *pcie;\n\tstruct device_node *np;\n\tstruct list_head list;\n\tstruct resource regs;\n\tvoid __iomem *base;\n\tunsigned int index;\n\tunsigned int lanes;\n\n\tstruct phy **phys;\n\n\tstruct gpio_desc *reset_gpio;\n};\n\nstatic inline void afi_writel(struct tegra_pcie *pcie, u32 value,\n\t\t\t      unsigned long offset)\n{\n\twritel(value, pcie->afi + offset);\n}\n\nstatic inline u32 afi_readl(struct tegra_pcie *pcie, unsigned long offset)\n{\n\treturn readl(pcie->afi + offset);\n}\n\nstatic inline void pads_writel(struct tegra_pcie *pcie, u32 value,\n\t\t\t       unsigned long offset)\n{\n\twritel(value, pcie->pads + offset);\n}\n\nstatic inline u32 pads_readl(struct tegra_pcie *pcie, unsigned long offset)\n{\n\treturn readl(pcie->pads + offset);\n}\n\n \nstatic unsigned int tegra_pcie_conf_offset(u8 bus, unsigned int devfn,\n\t\t\t\t\t   unsigned int where)\n{\n\treturn ((where & 0xf00) << 16) | (bus << 16) | (PCI_SLOT(devfn) << 11) |\n\t       (PCI_FUNC(devfn) << 8) | (where & 0xff);\n}\n\nstatic void __iomem *tegra_pcie_map_bus(struct pci_bus *bus,\n\t\t\t\t\tunsigned int devfn,\n\t\t\t\t\tint where)\n{\n\tstruct tegra_pcie *pcie = bus->sysdata;\n\tvoid __iomem *addr = NULL;\n\n\tif (bus->number == 0) {\n\t\tunsigned int slot = PCI_SLOT(devfn);\n\t\tstruct tegra_pcie_port *port;\n\n\t\tlist_for_each_entry(port, &pcie->ports, list) {\n\t\t\tif (port->index + 1 == slot) {\n\t\t\t\taddr = port->base + (where & ~3);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tunsigned int offset;\n\t\tu32 base;\n\n\t\toffset = tegra_pcie_conf_offset(bus->number, devfn, where);\n\n\t\t \n\t\tbase = 0xfe100000 + ((offset & ~(SZ_4K - 1)) >> 8);\n\t\tafi_writel(pcie, base, AFI_FPCI_BAR0);\n\n\t\t \n\t\taddr = pcie->cfg + (offset & (SZ_4K - 1));\n\t}\n\n\treturn addr;\n}\n\nstatic int tegra_pcie_config_read(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\t  int where, int size, u32 *value)\n{\n\tif (bus->number == 0)\n\t\treturn pci_generic_config_read32(bus, devfn, where, size,\n\t\t\t\t\t\t value);\n\n\treturn pci_generic_config_read(bus, devfn, where, size, value);\n}\n\nstatic int tegra_pcie_config_write(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\t   int where, int size, u32 value)\n{\n\tif (bus->number == 0)\n\t\treturn pci_generic_config_write32(bus, devfn, where, size,\n\t\t\t\t\t\t  value);\n\n\treturn pci_generic_config_write(bus, devfn, where, size, value);\n}\n\nstatic struct pci_ops tegra_pcie_ops = {\n\t.map_bus = tegra_pcie_map_bus,\n\t.read = tegra_pcie_config_read,\n\t.write = tegra_pcie_config_write,\n};\n\nstatic unsigned long tegra_pcie_port_get_pex_ctrl(struct tegra_pcie_port *port)\n{\n\tconst struct tegra_pcie_soc *soc = port->pcie->soc;\n\tunsigned long ret = 0;\n\n\tswitch (port->index) {\n\tcase 0:\n\t\tret = AFI_PEX0_CTRL;\n\t\tbreak;\n\n\tcase 1:\n\t\tret = AFI_PEX1_CTRL;\n\t\tbreak;\n\n\tcase 2:\n\t\tret = soc->afi_pex2_ctrl;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic void tegra_pcie_port_reset(struct tegra_pcie_port *port)\n{\n\tunsigned long ctrl = tegra_pcie_port_get_pex_ctrl(port);\n\tunsigned long value;\n\n\t \n\tif (port->reset_gpio) {\n\t\tgpiod_set_value(port->reset_gpio, 1);\n\t} else {\n\t\tvalue = afi_readl(port->pcie, ctrl);\n\t\tvalue &= ~AFI_PEX_CTRL_RST;\n\t\tafi_writel(port->pcie, value, ctrl);\n\t}\n\n\tusleep_range(1000, 2000);\n\n\tif (port->reset_gpio) {\n\t\tgpiod_set_value(port->reset_gpio, 0);\n\t} else {\n\t\tvalue = afi_readl(port->pcie, ctrl);\n\t\tvalue |= AFI_PEX_CTRL_RST;\n\t\tafi_writel(port->pcie, value, ctrl);\n\t}\n}\n\nstatic void tegra_pcie_enable_rp_features(struct tegra_pcie_port *port)\n{\n\tconst struct tegra_pcie_soc *soc = port->pcie->soc;\n\tu32 value;\n\n\t \n\tvalue = readl(port->base + RP_VEND_CTL1);\n\tvalue |= RP_VEND_CTL1_ERPT;\n\twritel(value, port->base + RP_VEND_CTL1);\n\n\t \n\tvalue = readl(port->base + RP_VEND_XP);\n\tvalue |= RP_VEND_XP_OPPORTUNISTIC_ACK;\n\tvalue |= RP_VEND_XP_OPPORTUNISTIC_UPDATEFC;\n\twritel(value, port->base + RP_VEND_XP);\n\n\t \n\tvalue = readl(port->base + RP_VEND_XP_BIST);\n\tvalue |= RP_VEND_XP_BIST_GOTO_L1_L2_AFTER_DLLP_DONE;\n\twritel(value, port->base + RP_VEND_XP_BIST);\n\n\tvalue = readl(port->base + RP_PRIV_MISC);\n\tvalue |= RP_PRIV_MISC_CTLR_CLK_CLAMP_ENABLE;\n\tvalue |= RP_PRIV_MISC_TMS_CLK_CLAMP_ENABLE;\n\n\tif (soc->update_clamp_threshold) {\n\t\tvalue &= ~(RP_PRIV_MISC_CTLR_CLK_CLAMP_THRESHOLD_MASK |\n\t\t\t\tRP_PRIV_MISC_TMS_CLK_CLAMP_THRESHOLD_MASK);\n\t\tvalue |= RP_PRIV_MISC_CTLR_CLK_CLAMP_THRESHOLD |\n\t\t\tRP_PRIV_MISC_TMS_CLK_CLAMP_THRESHOLD;\n\t}\n\n\twritel(value, port->base + RP_PRIV_MISC);\n}\n\nstatic void tegra_pcie_program_ectl_settings(struct tegra_pcie_port *port)\n{\n\tconst struct tegra_pcie_soc *soc = port->pcie->soc;\n\tu32 value;\n\n\tvalue = readl(port->base + RP_ECTL_2_R1);\n\tvalue &= ~RP_ECTL_2_R1_RX_CTLE_1C_MASK;\n\tvalue |= soc->ectl.regs.rp_ectl_2_r1;\n\twritel(value, port->base + RP_ECTL_2_R1);\n\n\tvalue = readl(port->base + RP_ECTL_4_R1);\n\tvalue &= ~RP_ECTL_4_R1_RX_CDR_CTRL_1C_MASK;\n\tvalue |= soc->ectl.regs.rp_ectl_4_r1 <<\n\t\t\t\tRP_ECTL_4_R1_RX_CDR_CTRL_1C_SHIFT;\n\twritel(value, port->base + RP_ECTL_4_R1);\n\n\tvalue = readl(port->base + RP_ECTL_5_R1);\n\tvalue &= ~RP_ECTL_5_R1_RX_EQ_CTRL_L_1C_MASK;\n\tvalue |= soc->ectl.regs.rp_ectl_5_r1;\n\twritel(value, port->base + RP_ECTL_5_R1);\n\n\tvalue = readl(port->base + RP_ECTL_6_R1);\n\tvalue &= ~RP_ECTL_6_R1_RX_EQ_CTRL_H_1C_MASK;\n\tvalue |= soc->ectl.regs.rp_ectl_6_r1;\n\twritel(value, port->base + RP_ECTL_6_R1);\n\n\tvalue = readl(port->base + RP_ECTL_2_R2);\n\tvalue &= ~RP_ECTL_2_R2_RX_CTLE_1C_MASK;\n\tvalue |= soc->ectl.regs.rp_ectl_2_r2;\n\twritel(value, port->base + RP_ECTL_2_R2);\n\n\tvalue = readl(port->base + RP_ECTL_4_R2);\n\tvalue &= ~RP_ECTL_4_R2_RX_CDR_CTRL_1C_MASK;\n\tvalue |= soc->ectl.regs.rp_ectl_4_r2 <<\n\t\t\t\tRP_ECTL_4_R2_RX_CDR_CTRL_1C_SHIFT;\n\twritel(value, port->base + RP_ECTL_4_R2);\n\n\tvalue = readl(port->base + RP_ECTL_5_R2);\n\tvalue &= ~RP_ECTL_5_R2_RX_EQ_CTRL_L_1C_MASK;\n\tvalue |= soc->ectl.regs.rp_ectl_5_r2;\n\twritel(value, port->base + RP_ECTL_5_R2);\n\n\tvalue = readl(port->base + RP_ECTL_6_R2);\n\tvalue &= ~RP_ECTL_6_R2_RX_EQ_CTRL_H_1C_MASK;\n\tvalue |= soc->ectl.regs.rp_ectl_6_r2;\n\twritel(value, port->base + RP_ECTL_6_R2);\n}\n\nstatic void tegra_pcie_apply_sw_fixup(struct tegra_pcie_port *port)\n{\n\tconst struct tegra_pcie_soc *soc = port->pcie->soc;\n\tu32 value;\n\n\t \n\tif (soc->program_deskew_time) {\n\t\tvalue = readl(port->base + RP_VEND_CTL0);\n\t\tvalue &= ~RP_VEND_CTL0_DSK_RST_PULSE_WIDTH_MASK;\n\t\tvalue |= RP_VEND_CTL0_DSK_RST_PULSE_WIDTH;\n\t\twritel(value, port->base + RP_VEND_CTL0);\n\t}\n\n\tif (soc->update_fc_timer) {\n\t\tvalue = readl(port->base + RP_VEND_XP);\n\t\tvalue &= ~RP_VEND_XP_UPDATE_FC_THRESHOLD_MASK;\n\t\tvalue |= soc->update_fc_threshold;\n\t\twritel(value, port->base + RP_VEND_XP);\n\t}\n\n\t \n\tvalue = readl(port->base + RP_LINK_CONTROL_STATUS_2);\n\tvalue &= ~PCI_EXP_LNKSTA_CLS;\n\tvalue |= PCI_EXP_LNKSTA_CLS_2_5GB;\n\twritel(value, port->base + RP_LINK_CONTROL_STATUS_2);\n}\n\nstatic void tegra_pcie_port_enable(struct tegra_pcie_port *port)\n{\n\tunsigned long ctrl = tegra_pcie_port_get_pex_ctrl(port);\n\tconst struct tegra_pcie_soc *soc = port->pcie->soc;\n\tunsigned long value;\n\n\t \n\tvalue = afi_readl(port->pcie, ctrl);\n\tvalue |= AFI_PEX_CTRL_REFCLK_EN;\n\n\tif (soc->has_pex_clkreq_en)\n\t\tvalue |= AFI_PEX_CTRL_CLKREQ_EN;\n\n\tvalue |= AFI_PEX_CTRL_OVERRIDE_EN;\n\n\tafi_writel(port->pcie, value, ctrl);\n\n\ttegra_pcie_port_reset(port);\n\n\tif (soc->force_pca_enable) {\n\t\tvalue = readl(port->base + RP_VEND_CTL2);\n\t\tvalue |= RP_VEND_CTL2_PCA_ENABLE;\n\t\twritel(value, port->base + RP_VEND_CTL2);\n\t}\n\n\ttegra_pcie_enable_rp_features(port);\n\n\tif (soc->ectl.enable)\n\t\ttegra_pcie_program_ectl_settings(port);\n\n\ttegra_pcie_apply_sw_fixup(port);\n}\n\nstatic void tegra_pcie_port_disable(struct tegra_pcie_port *port)\n{\n\tunsigned long ctrl = tegra_pcie_port_get_pex_ctrl(port);\n\tconst struct tegra_pcie_soc *soc = port->pcie->soc;\n\tunsigned long value;\n\n\t \n\tvalue = afi_readl(port->pcie, ctrl);\n\tvalue &= ~AFI_PEX_CTRL_RST;\n\tafi_writel(port->pcie, value, ctrl);\n\n\t \n\tvalue = afi_readl(port->pcie, ctrl);\n\n\tif (soc->has_pex_clkreq_en)\n\t\tvalue &= ~AFI_PEX_CTRL_CLKREQ_EN;\n\n\tvalue &= ~AFI_PEX_CTRL_REFCLK_EN;\n\tafi_writel(port->pcie, value, ctrl);\n\n\t \n\tvalue = afi_readl(port->pcie, AFI_PCIE_CONFIG);\n\tvalue |= AFI_PCIE_CONFIG_PCIE_DISABLE(port->index);\n\tvalue |= AFI_PCIE_CONFIG_PCIE_CLKREQ_GPIO(port->index);\n\tafi_writel(port->pcie, value, AFI_PCIE_CONFIG);\n}\n\nstatic void tegra_pcie_port_free(struct tegra_pcie_port *port)\n{\n\tstruct tegra_pcie *pcie = port->pcie;\n\tstruct device *dev = pcie->dev;\n\n\tdevm_iounmap(dev, port->base);\n\tdevm_release_mem_region(dev, port->regs.start,\n\t\t\t\tresource_size(&port->regs));\n\tlist_del(&port->list);\n\tdevm_kfree(dev, port);\n}\n\n \nstatic void tegra_pcie_fixup_class(struct pci_dev *dev)\n{\n\tdev->class = PCI_CLASS_BRIDGE_PCI_NORMAL;\n}\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_NVIDIA, 0x0bf0, tegra_pcie_fixup_class);\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_NVIDIA, 0x0bf1, tegra_pcie_fixup_class);\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_NVIDIA, 0x0e1c, tegra_pcie_fixup_class);\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_NVIDIA, 0x0e1d, tegra_pcie_fixup_class);\n\n \nstatic void tegra_pcie_relax_enable(struct pci_dev *dev)\n{\n\tpcie_capability_set_word(dev, PCI_EXP_DEVCTL, PCI_EXP_DEVCTL_RELAX_EN);\n}\nDECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_NVIDIA, 0x0bf0, tegra_pcie_relax_enable);\nDECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_NVIDIA, 0x0bf1, tegra_pcie_relax_enable);\nDECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_NVIDIA, 0x0e1c, tegra_pcie_relax_enable);\nDECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_NVIDIA, 0x0e1d, tegra_pcie_relax_enable);\n\nstatic int tegra_pcie_map_irq(const struct pci_dev *pdev, u8 slot, u8 pin)\n{\n\tstruct tegra_pcie *pcie = pdev->bus->sysdata;\n\tint irq;\n\n\ttegra_cpuidle_pcie_irqs_in_use();\n\n\tirq = of_irq_parse_and_map_pci(pdev, slot, pin);\n\tif (!irq)\n\t\tirq = pcie->irq;\n\n\treturn irq;\n}\n\nstatic irqreturn_t tegra_pcie_isr(int irq, void *arg)\n{\n\tstatic const char * const err_msg[] = {\n\t\t\"Unknown\",\n\t\t\"AXI slave error\",\n\t\t\"AXI decode error\",\n\t\t\"Target abort\",\n\t\t\"Master abort\",\n\t\t\"Invalid write\",\n\t\t\"Legacy interrupt\",\n\t\t\"Response decoding error\",\n\t\t\"AXI response decoding error\",\n\t\t\"Transaction timeout\",\n\t\t\"Slot present pin change\",\n\t\t\"Slot clock request change\",\n\t\t\"TMS clock ramp change\",\n\t\t\"TMS ready for power down\",\n\t\t\"Peer2Peer error\",\n\t};\n\tstruct tegra_pcie *pcie = arg;\n\tstruct device *dev = pcie->dev;\n\tu32 code, signature;\n\n\tcode = afi_readl(pcie, AFI_INTR_CODE) & AFI_INTR_CODE_MASK;\n\tsignature = afi_readl(pcie, AFI_INTR_SIGNATURE);\n\tafi_writel(pcie, 0, AFI_INTR_CODE);\n\n\tif (code == AFI_INTR_LEGACY)\n\t\treturn IRQ_NONE;\n\n\tif (code >= ARRAY_SIZE(err_msg))\n\t\tcode = 0;\n\n\t \n\tif (code == AFI_INTR_MASTER_ABORT || code == AFI_INTR_PE_PRSNT_SENSE)\n\t\tdev_dbg(dev, \"%s, signature: %08x\\n\", err_msg[code], signature);\n\telse\n\t\tdev_err(dev, \"%s, signature: %08x\\n\", err_msg[code], signature);\n\n\tif (code == AFI_INTR_TARGET_ABORT || code == AFI_INTR_MASTER_ABORT ||\n\t    code == AFI_INTR_FPCI_DECODE_ERROR) {\n\t\tu32 fpci = afi_readl(pcie, AFI_UPPER_FPCI_ADDRESS) & 0xff;\n\t\tu64 address = (u64)fpci << 32 | (signature & 0xfffffffc);\n\n\t\tif (code == AFI_INTR_MASTER_ABORT)\n\t\t\tdev_dbg(dev, \"  FPCI address: %10llx\\n\", address);\n\t\telse\n\t\t\tdev_err(dev, \"  FPCI address: %10llx\\n\", address);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void tegra_pcie_setup_translations(struct tegra_pcie *pcie)\n{\n\tu32 size;\n\tstruct resource_entry *entry;\n\tstruct pci_host_bridge *bridge = pci_host_bridge_from_priv(pcie);\n\n\t \n\tsize = resource_size(&pcie->cs);\n\tafi_writel(pcie, pcie->cs.start, AFI_AXI_BAR0_START);\n\tafi_writel(pcie, size >> 12, AFI_AXI_BAR0_SZ);\n\n\tresource_list_for_each_entry(entry, &bridge->windows) {\n\t\tu32 fpci_bar, axi_address;\n\t\tstruct resource *res = entry->res;\n\n\t\tsize = resource_size(res);\n\n\t\tswitch (resource_type(res)) {\n\t\tcase IORESOURCE_IO:\n\t\t\t \n\t\t\tfpci_bar = 0xfdfc0000;\n\t\t\taxi_address = pci_pio_to_address(res->start);\n\t\t\tafi_writel(pcie, axi_address, AFI_AXI_BAR1_START);\n\t\t\tafi_writel(pcie, size >> 12, AFI_AXI_BAR1_SZ);\n\t\t\tafi_writel(pcie, fpci_bar, AFI_FPCI_BAR1);\n\t\t\tbreak;\n\t\tcase IORESOURCE_MEM:\n\t\t\tfpci_bar = (((res->start >> 12) & 0x0fffffff) << 4) | 0x1;\n\t\t\taxi_address = res->start;\n\n\t\t\tif (res->flags & IORESOURCE_PREFETCH) {\n\t\t\t\t \n\t\t\t\tafi_writel(pcie, axi_address, AFI_AXI_BAR2_START);\n\t\t\t\tafi_writel(pcie, size >> 12, AFI_AXI_BAR2_SZ);\n\t\t\t\tafi_writel(pcie, fpci_bar, AFI_FPCI_BAR2);\n\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tafi_writel(pcie, axi_address, AFI_AXI_BAR3_START);\n\t\t\t\tafi_writel(pcie, size >> 12, AFI_AXI_BAR3_SZ);\n\t\t\t\tafi_writel(pcie, fpci_bar, AFI_FPCI_BAR3);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tafi_writel(pcie, 0, AFI_AXI_BAR4_START);\n\tafi_writel(pcie, 0, AFI_AXI_BAR4_SZ);\n\tafi_writel(pcie, 0, AFI_FPCI_BAR4);\n\n\tafi_writel(pcie, 0, AFI_AXI_BAR5_START);\n\tafi_writel(pcie, 0, AFI_AXI_BAR5_SZ);\n\tafi_writel(pcie, 0, AFI_FPCI_BAR5);\n\n\tif (pcie->soc->has_cache_bars) {\n\t\t \n\t\tafi_writel(pcie, 0, AFI_CACHE_BAR0_ST);\n\t\tafi_writel(pcie, 0, AFI_CACHE_BAR0_SZ);\n\t\tafi_writel(pcie, 0, AFI_CACHE_BAR1_ST);\n\t\tafi_writel(pcie, 0, AFI_CACHE_BAR1_SZ);\n\t}\n\n\t \n\tafi_writel(pcie, 0, AFI_MSI_FPCI_BAR_ST);\n\tafi_writel(pcie, 0, AFI_MSI_BAR_SZ);\n\tafi_writel(pcie, 0, AFI_MSI_AXI_BAR_ST);\n\tafi_writel(pcie, 0, AFI_MSI_BAR_SZ);\n}\n\nstatic int tegra_pcie_pll_wait(struct tegra_pcie *pcie, unsigned long timeout)\n{\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tu32 value;\n\n\ttimeout = jiffies + msecs_to_jiffies(timeout);\n\n\twhile (time_before(jiffies, timeout)) {\n\t\tvalue = pads_readl(pcie, soc->pads_pll_ctl);\n\t\tif (value & PADS_PLL_CTL_LOCKDET)\n\t\t\treturn 0;\n\t}\n\n\treturn -ETIMEDOUT;\n}\n\nstatic int tegra_pcie_phy_enable(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tu32 value;\n\tint err;\n\n\t \n\tpads_writel(pcie, 0x0, PADS_CTL_SEL);\n\n\t \n\tvalue = pads_readl(pcie, PADS_CTL);\n\tvalue |= PADS_CTL_IDDQ_1L;\n\tpads_writel(pcie, value, PADS_CTL);\n\n\t \n\tvalue = pads_readl(pcie, soc->pads_pll_ctl);\n\tvalue &= ~(PADS_PLL_CTL_REFCLK_MASK | PADS_PLL_CTL_TXCLKREF_MASK);\n\tvalue |= PADS_PLL_CTL_REFCLK_INTERNAL_CML | soc->tx_ref_sel;\n\tpads_writel(pcie, value, soc->pads_pll_ctl);\n\n\t \n\tvalue = pads_readl(pcie, soc->pads_pll_ctl);\n\tvalue &= ~PADS_PLL_CTL_RST_B4SM;\n\tpads_writel(pcie, value, soc->pads_pll_ctl);\n\n\tusleep_range(20, 100);\n\n\t \n\tvalue = pads_readl(pcie, soc->pads_pll_ctl);\n\tvalue |= PADS_PLL_CTL_RST_B4SM;\n\tpads_writel(pcie, value, soc->pads_pll_ctl);\n\n\t \n\terr = tegra_pcie_pll_wait(pcie, 500);\n\tif (err < 0) {\n\t\tdev_err(dev, \"PLL failed to lock: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\t \n\tvalue = pads_readl(pcie, PADS_CTL);\n\tvalue &= ~PADS_CTL_IDDQ_1L;\n\tpads_writel(pcie, value, PADS_CTL);\n\n\t \n\tvalue = pads_readl(pcie, PADS_CTL);\n\tvalue |= PADS_CTL_TX_DATA_EN_1L | PADS_CTL_RX_DATA_EN_1L;\n\tpads_writel(pcie, value, PADS_CTL);\n\n\treturn 0;\n}\n\nstatic int tegra_pcie_phy_disable(struct tegra_pcie *pcie)\n{\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tu32 value;\n\n\t \n\tvalue = pads_readl(pcie, PADS_CTL);\n\tvalue &= ~(PADS_CTL_TX_DATA_EN_1L | PADS_CTL_RX_DATA_EN_1L);\n\tpads_writel(pcie, value, PADS_CTL);\n\n\t \n\tvalue = pads_readl(pcie, PADS_CTL);\n\tvalue |= PADS_CTL_IDDQ_1L;\n\tpads_writel(pcie, value, PADS_CTL);\n\n\t \n\tvalue = pads_readl(pcie, soc->pads_pll_ctl);\n\tvalue &= ~PADS_PLL_CTL_RST_B4SM;\n\tpads_writel(pcie, value, soc->pads_pll_ctl);\n\n\tusleep_range(20, 100);\n\n\treturn 0;\n}\n\nstatic int tegra_pcie_port_phy_power_on(struct tegra_pcie_port *port)\n{\n\tstruct device *dev = port->pcie->dev;\n\tunsigned int i;\n\tint err;\n\n\tfor (i = 0; i < port->lanes; i++) {\n\t\terr = phy_power_on(port->phys[i]);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev, \"failed to power on PHY#%u: %d\\n\", i, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int tegra_pcie_port_phy_power_off(struct tegra_pcie_port *port)\n{\n\tstruct device *dev = port->pcie->dev;\n\tunsigned int i;\n\tint err;\n\n\tfor (i = 0; i < port->lanes; i++) {\n\t\terr = phy_power_off(port->phys[i]);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev, \"failed to power off PHY#%u: %d\\n\", i,\n\t\t\t\terr);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int tegra_pcie_phy_power_on(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct tegra_pcie_port *port;\n\tint err;\n\n\tif (pcie->legacy_phy) {\n\t\tif (pcie->phy)\n\t\t\terr = phy_power_on(pcie->phy);\n\t\telse\n\t\t\terr = tegra_pcie_phy_enable(pcie);\n\n\t\tif (err < 0)\n\t\t\tdev_err(dev, \"failed to power on PHY: %d\\n\", err);\n\n\t\treturn err;\n\t}\n\n\tlist_for_each_entry(port, &pcie->ports, list) {\n\t\terr = tegra_pcie_port_phy_power_on(port);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev,\n\t\t\t\t\"failed to power on PCIe port %u PHY: %d\\n\",\n\t\t\t\tport->index, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int tegra_pcie_phy_power_off(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct tegra_pcie_port *port;\n\tint err;\n\n\tif (pcie->legacy_phy) {\n\t\tif (pcie->phy)\n\t\t\terr = phy_power_off(pcie->phy);\n\t\telse\n\t\t\terr = tegra_pcie_phy_disable(pcie);\n\n\t\tif (err < 0)\n\t\t\tdev_err(dev, \"failed to power off PHY: %d\\n\", err);\n\n\t\treturn err;\n\t}\n\n\tlist_for_each_entry(port, &pcie->ports, list) {\n\t\terr = tegra_pcie_port_phy_power_off(port);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev,\n\t\t\t\t\"failed to power off PCIe port %u PHY: %d\\n\",\n\t\t\t\tport->index, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void tegra_pcie_enable_controller(struct tegra_pcie *pcie)\n{\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tstruct tegra_pcie_port *port;\n\tunsigned long value;\n\n\t \n\tif (pcie->phy) {\n\t\tvalue = afi_readl(pcie, AFI_PLLE_CONTROL);\n\t\tvalue &= ~AFI_PLLE_CONTROL_BYPASS_PADS2PLLE_CONTROL;\n\t\tvalue |= AFI_PLLE_CONTROL_PADS2PLLE_CONTROL_EN;\n\t\tafi_writel(pcie, value, AFI_PLLE_CONTROL);\n\t}\n\n\t \n\tif (soc->has_pex_bias_ctrl)\n\t\tafi_writel(pcie, 0, AFI_PEXBIAS_CTRL_0);\n\n\t \n\tvalue = afi_readl(pcie, AFI_PCIE_CONFIG);\n\tvalue &= ~AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_MASK;\n\tvalue |= AFI_PCIE_CONFIG_PCIE_DISABLE_ALL | pcie->xbar_config;\n\tvalue |= AFI_PCIE_CONFIG_PCIE_CLKREQ_GPIO_ALL;\n\n\tlist_for_each_entry(port, &pcie->ports, list) {\n\t\tvalue &= ~AFI_PCIE_CONFIG_PCIE_DISABLE(port->index);\n\t\tvalue &= ~AFI_PCIE_CONFIG_PCIE_CLKREQ_GPIO(port->index);\n\t}\n\n\tafi_writel(pcie, value, AFI_PCIE_CONFIG);\n\n\tif (soc->has_gen2) {\n\t\tvalue = afi_readl(pcie, AFI_FUSE);\n\t\tvalue &= ~AFI_FUSE_PCIE_T0_GEN2_DIS;\n\t\tafi_writel(pcie, value, AFI_FUSE);\n\t} else {\n\t\tvalue = afi_readl(pcie, AFI_FUSE);\n\t\tvalue |= AFI_FUSE_PCIE_T0_GEN2_DIS;\n\t\tafi_writel(pcie, value, AFI_FUSE);\n\t}\n\n\t \n\tvalue = afi_readl(pcie, AFI_CONFIGURATION);\n\tvalue |= AFI_CONFIGURATION_EN_FPCI;\n\tvalue |= AFI_CONFIGURATION_CLKEN_OVERRIDE;\n\tafi_writel(pcie, value, AFI_CONFIGURATION);\n\n\tvalue = AFI_INTR_EN_INI_SLVERR | AFI_INTR_EN_INI_DECERR |\n\t\tAFI_INTR_EN_TGT_SLVERR | AFI_INTR_EN_TGT_DECERR |\n\t\tAFI_INTR_EN_TGT_WRERR | AFI_INTR_EN_DFPCI_DECERR;\n\n\tif (soc->has_intr_prsnt_sense)\n\t\tvalue |= AFI_INTR_EN_PRSNT_SENSE;\n\n\tafi_writel(pcie, value, AFI_AFI_INTR_ENABLE);\n\tafi_writel(pcie, 0xffffffff, AFI_SM_INTR_ENABLE);\n\n\t \n\tafi_writel(pcie, AFI_INTR_MASK_INT_MASK, AFI_INTR_MASK);\n\n\t \n\tafi_writel(pcie, 0, AFI_FPCI_ERROR_MASKS);\n}\n\nstatic void tegra_pcie_power_off(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tint err;\n\n\treset_control_assert(pcie->afi_rst);\n\n\tclk_disable_unprepare(pcie->pll_e);\n\tif (soc->has_cml_clk)\n\t\tclk_disable_unprepare(pcie->cml_clk);\n\tclk_disable_unprepare(pcie->afi_clk);\n\n\tif (!dev->pm_domain)\n\t\ttegra_powergate_power_off(TEGRA_POWERGATE_PCIE);\n\n\terr = regulator_bulk_disable(pcie->num_supplies, pcie->supplies);\n\tif (err < 0)\n\t\tdev_warn(dev, \"failed to disable regulators: %d\\n\", err);\n}\n\nstatic int tegra_pcie_power_on(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tint err;\n\n\treset_control_assert(pcie->pcie_xrst);\n\treset_control_assert(pcie->afi_rst);\n\treset_control_assert(pcie->pex_rst);\n\n\tif (!dev->pm_domain)\n\t\ttegra_powergate_power_off(TEGRA_POWERGATE_PCIE);\n\n\t \n\terr = regulator_bulk_enable(pcie->num_supplies, pcie->supplies);\n\tif (err < 0)\n\t\tdev_err(dev, \"failed to enable regulators: %d\\n\", err);\n\n\tif (!dev->pm_domain) {\n\t\terr = tegra_powergate_power_on(TEGRA_POWERGATE_PCIE);\n\t\tif (err) {\n\t\t\tdev_err(dev, \"failed to power ungate: %d\\n\", err);\n\t\t\tgoto regulator_disable;\n\t\t}\n\t\terr = tegra_powergate_remove_clamping(TEGRA_POWERGATE_PCIE);\n\t\tif (err) {\n\t\t\tdev_err(dev, \"failed to remove clamp: %d\\n\", err);\n\t\t\tgoto powergate;\n\t\t}\n\t}\n\n\terr = clk_prepare_enable(pcie->afi_clk);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to enable AFI clock: %d\\n\", err);\n\t\tgoto powergate;\n\t}\n\n\tif (soc->has_cml_clk) {\n\t\terr = clk_prepare_enable(pcie->cml_clk);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev, \"failed to enable CML clock: %d\\n\", err);\n\t\t\tgoto disable_afi_clk;\n\t\t}\n\t}\n\n\terr = clk_prepare_enable(pcie->pll_e);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to enable PLLE clock: %d\\n\", err);\n\t\tgoto disable_cml_clk;\n\t}\n\n\treset_control_deassert(pcie->afi_rst);\n\n\treturn 0;\n\ndisable_cml_clk:\n\tif (soc->has_cml_clk)\n\t\tclk_disable_unprepare(pcie->cml_clk);\ndisable_afi_clk:\n\tclk_disable_unprepare(pcie->afi_clk);\npowergate:\n\tif (!dev->pm_domain)\n\t\ttegra_powergate_power_off(TEGRA_POWERGATE_PCIE);\nregulator_disable:\n\tregulator_bulk_disable(pcie->num_supplies, pcie->supplies);\n\n\treturn err;\n}\n\nstatic void tegra_pcie_apply_pad_settings(struct tegra_pcie *pcie)\n{\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\n\t \n\tpads_writel(pcie, soc->pads_refclk_cfg0, PADS_REFCLK_CFG0);\n\n\tif (soc->num_ports > 2)\n\t\tpads_writel(pcie, soc->pads_refclk_cfg1, PADS_REFCLK_CFG1);\n}\n\nstatic int tegra_pcie_clocks_get(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\n\tpcie->pex_clk = devm_clk_get(dev, \"pex\");\n\tif (IS_ERR(pcie->pex_clk))\n\t\treturn PTR_ERR(pcie->pex_clk);\n\n\tpcie->afi_clk = devm_clk_get(dev, \"afi\");\n\tif (IS_ERR(pcie->afi_clk))\n\t\treturn PTR_ERR(pcie->afi_clk);\n\n\tpcie->pll_e = devm_clk_get(dev, \"pll_e\");\n\tif (IS_ERR(pcie->pll_e))\n\t\treturn PTR_ERR(pcie->pll_e);\n\n\tif (soc->has_cml_clk) {\n\t\tpcie->cml_clk = devm_clk_get(dev, \"cml\");\n\t\tif (IS_ERR(pcie->cml_clk))\n\t\t\treturn PTR_ERR(pcie->cml_clk);\n\t}\n\n\treturn 0;\n}\n\nstatic int tegra_pcie_resets_get(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\n\tpcie->pex_rst = devm_reset_control_get_exclusive(dev, \"pex\");\n\tif (IS_ERR(pcie->pex_rst))\n\t\treturn PTR_ERR(pcie->pex_rst);\n\n\tpcie->afi_rst = devm_reset_control_get_exclusive(dev, \"afi\");\n\tif (IS_ERR(pcie->afi_rst))\n\t\treturn PTR_ERR(pcie->afi_rst);\n\n\tpcie->pcie_xrst = devm_reset_control_get_exclusive(dev, \"pcie_x\");\n\tif (IS_ERR(pcie->pcie_xrst))\n\t\treturn PTR_ERR(pcie->pcie_xrst);\n\n\treturn 0;\n}\n\nstatic int tegra_pcie_phys_get_legacy(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tint err;\n\n\tpcie->phy = devm_phy_optional_get(dev, \"pcie\");\n\tif (IS_ERR(pcie->phy)) {\n\t\terr = PTR_ERR(pcie->phy);\n\t\tdev_err(dev, \"failed to get PHY: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = phy_init(pcie->phy);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to initialize PHY: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tpcie->legacy_phy = true;\n\n\treturn 0;\n}\n\nstatic struct phy *devm_of_phy_optional_get_index(struct device *dev,\n\t\t\t\t\t\t  struct device_node *np,\n\t\t\t\t\t\t  const char *consumer,\n\t\t\t\t\t\t  unsigned int index)\n{\n\tstruct phy *phy;\n\tchar *name;\n\n\tname = kasprintf(GFP_KERNEL, \"%s-%u\", consumer, index);\n\tif (!name)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tphy = devm_of_phy_optional_get(dev, np, name);\n\tkfree(name);\n\n\treturn phy;\n}\n\nstatic int tegra_pcie_port_get_phys(struct tegra_pcie_port *port)\n{\n\tstruct device *dev = port->pcie->dev;\n\tstruct phy *phy;\n\tunsigned int i;\n\tint err;\n\n\tport->phys = devm_kcalloc(dev, sizeof(phy), port->lanes, GFP_KERNEL);\n\tif (!port->phys)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < port->lanes; i++) {\n\t\tphy = devm_of_phy_optional_get_index(dev, port->np, \"pcie\", i);\n\t\tif (IS_ERR(phy)) {\n\t\t\tdev_err(dev, \"failed to get PHY#%u: %ld\\n\", i,\n\t\t\t\tPTR_ERR(phy));\n\t\t\treturn PTR_ERR(phy);\n\t\t}\n\n\t\terr = phy_init(phy);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev, \"failed to initialize PHY#%u: %d\\n\", i,\n\t\t\t\terr);\n\t\t\treturn err;\n\t\t}\n\n\t\tport->phys[i] = phy;\n\t}\n\n\treturn 0;\n}\n\nstatic int tegra_pcie_phys_get(struct tegra_pcie *pcie)\n{\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tstruct device_node *np = pcie->dev->of_node;\n\tstruct tegra_pcie_port *port;\n\tint err;\n\n\tif (!soc->has_gen2 || of_property_present(np, \"phys\"))\n\t\treturn tegra_pcie_phys_get_legacy(pcie);\n\n\tlist_for_each_entry(port, &pcie->ports, list) {\n\t\terr = tegra_pcie_port_get_phys(port);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic void tegra_pcie_phys_put(struct tegra_pcie *pcie)\n{\n\tstruct tegra_pcie_port *port;\n\tstruct device *dev = pcie->dev;\n\tint err, i;\n\n\tif (pcie->legacy_phy) {\n\t\terr = phy_exit(pcie->phy);\n\t\tif (err < 0)\n\t\t\tdev_err(dev, \"failed to teardown PHY: %d\\n\", err);\n\t\treturn;\n\t}\n\n\tlist_for_each_entry(port, &pcie->ports, list) {\n\t\tfor (i = 0; i < port->lanes; i++) {\n\t\t\terr = phy_exit(port->phys[i]);\n\t\t\tif (err < 0)\n\t\t\t\tdev_err(dev, \"failed to teardown PHY#%u: %d\\n\",\n\t\t\t\t\ti, err);\n\t\t}\n\t}\n}\n\nstatic int tegra_pcie_get_resources(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct resource *res;\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tint err;\n\n\terr = tegra_pcie_clocks_get(pcie);\n\tif (err) {\n\t\tdev_err(dev, \"failed to get clocks: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = tegra_pcie_resets_get(pcie);\n\tif (err) {\n\t\tdev_err(dev, \"failed to get resets: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tif (soc->program_uphy) {\n\t\terr = tegra_pcie_phys_get(pcie);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev, \"failed to get PHYs: %d\\n\", err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tpcie->pads = devm_platform_ioremap_resource_byname(pdev, \"pads\");\n\tif (IS_ERR(pcie->pads)) {\n\t\terr = PTR_ERR(pcie->pads);\n\t\tgoto phys_put;\n\t}\n\n\tpcie->afi = devm_platform_ioremap_resource_byname(pdev, \"afi\");\n\tif (IS_ERR(pcie->afi)) {\n\t\terr = PTR_ERR(pcie->afi);\n\t\tgoto phys_put;\n\t}\n\n\t \n\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"cs\");\n\tif (!res) {\n\t\terr = -EADDRNOTAVAIL;\n\t\tgoto phys_put;\n\t}\n\n\tpcie->cs = *res;\n\n\t \n\tpcie->cs.end = pcie->cs.start + SZ_4K - 1;\n\n\tpcie->cfg = devm_ioremap_resource(dev, &pcie->cs);\n\tif (IS_ERR(pcie->cfg)) {\n\t\terr = PTR_ERR(pcie->cfg);\n\t\tgoto phys_put;\n\t}\n\n\t \n\terr = platform_get_irq_byname(pdev, \"intr\");\n\tif (err < 0)\n\t\tgoto phys_put;\n\n\tpcie->irq = err;\n\n\terr = request_irq(pcie->irq, tegra_pcie_isr, IRQF_SHARED, \"PCIE\", pcie);\n\tif (err) {\n\t\tdev_err(dev, \"failed to register IRQ: %d\\n\", err);\n\t\tgoto phys_put;\n\t}\n\n\treturn 0;\n\nphys_put:\n\tif (soc->program_uphy)\n\t\ttegra_pcie_phys_put(pcie);\n\n\treturn err;\n}\n\nstatic int tegra_pcie_put_resources(struct tegra_pcie *pcie)\n{\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\n\tif (pcie->irq > 0)\n\t\tfree_irq(pcie->irq, pcie);\n\n\tif (soc->program_uphy)\n\t\ttegra_pcie_phys_put(pcie);\n\n\treturn 0;\n}\n\nstatic void tegra_pcie_pme_turnoff(struct tegra_pcie_port *port)\n{\n\tstruct tegra_pcie *pcie = port->pcie;\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tint err;\n\tu32 val;\n\tu8 ack_bit;\n\n\tval = afi_readl(pcie, AFI_PCIE_PME);\n\tval |= (0x1 << soc->ports[port->index].pme.turnoff_bit);\n\tafi_writel(pcie, val, AFI_PCIE_PME);\n\n\tack_bit = soc->ports[port->index].pme.ack_bit;\n\terr = readl_poll_timeout(pcie->afi + AFI_PCIE_PME, val,\n\t\t\t\t val & (0x1 << ack_bit), 1, PME_ACK_TIMEOUT);\n\tif (err)\n\t\tdev_err(pcie->dev, \"PME Ack is not received on port: %d\\n\",\n\t\t\tport->index);\n\n\tusleep_range(10000, 11000);\n\n\tval = afi_readl(pcie, AFI_PCIE_PME);\n\tval &= ~(0x1 << soc->ports[port->index].pme.turnoff_bit);\n\tafi_writel(pcie, val, AFI_PCIE_PME);\n}\n\nstatic void tegra_pcie_msi_irq(struct irq_desc *desc)\n{\n\tstruct tegra_pcie *pcie = irq_desc_get_handler_data(desc);\n\tstruct irq_chip *chip = irq_desc_get_chip(desc);\n\tstruct tegra_msi *msi = &pcie->msi;\n\tstruct device *dev = pcie->dev;\n\tunsigned int i;\n\n\tchained_irq_enter(chip, desc);\n\n\tfor (i = 0; i < 8; i++) {\n\t\tunsigned long reg = afi_readl(pcie, AFI_MSI_VEC(i));\n\n\t\twhile (reg) {\n\t\t\tunsigned int offset = find_first_bit(&reg, 32);\n\t\t\tunsigned int index = i * 32 + offset;\n\t\t\tint ret;\n\n\t\t\tret = generic_handle_domain_irq(msi->domain->parent, index);\n\t\t\tif (ret) {\n\t\t\t\t \n\t\t\t\tdev_info(dev, \"unexpected MSI\\n\");\n\t\t\t\tafi_writel(pcie, BIT(index % 32), AFI_MSI_VEC(index));\n\t\t\t}\n\n\t\t\t \n\t\t\treg = afi_readl(pcie, AFI_MSI_VEC(i));\n\t\t}\n\t}\n\n\tchained_irq_exit(chip, desc);\n}\n\nstatic void tegra_msi_top_irq_ack(struct irq_data *d)\n{\n\tirq_chip_ack_parent(d);\n}\n\nstatic void tegra_msi_top_irq_mask(struct irq_data *d)\n{\n\tpci_msi_mask_irq(d);\n\tirq_chip_mask_parent(d);\n}\n\nstatic void tegra_msi_top_irq_unmask(struct irq_data *d)\n{\n\tpci_msi_unmask_irq(d);\n\tirq_chip_unmask_parent(d);\n}\n\nstatic struct irq_chip tegra_msi_top_chip = {\n\t.name\t\t= \"Tegra PCIe MSI\",\n\t.irq_ack\t= tegra_msi_top_irq_ack,\n\t.irq_mask\t= tegra_msi_top_irq_mask,\n\t.irq_unmask\t= tegra_msi_top_irq_unmask,\n};\n\nstatic void tegra_msi_irq_ack(struct irq_data *d)\n{\n\tstruct tegra_msi *msi = irq_data_get_irq_chip_data(d);\n\tstruct tegra_pcie *pcie = msi_to_pcie(msi);\n\tunsigned int index = d->hwirq / 32;\n\n\t \n\tafi_writel(pcie, BIT(d->hwirq % 32), AFI_MSI_VEC(index));\n}\n\nstatic void tegra_msi_irq_mask(struct irq_data *d)\n{\n\tstruct tegra_msi *msi = irq_data_get_irq_chip_data(d);\n\tstruct tegra_pcie *pcie = msi_to_pcie(msi);\n\tunsigned int index = d->hwirq / 32;\n\tunsigned long flags;\n\tu32 value;\n\n\tspin_lock_irqsave(&msi->mask_lock, flags);\n\tvalue = afi_readl(pcie, AFI_MSI_EN_VEC(index));\n\tvalue &= ~BIT(d->hwirq % 32);\n\tafi_writel(pcie, value, AFI_MSI_EN_VEC(index));\n\tspin_unlock_irqrestore(&msi->mask_lock, flags);\n}\n\nstatic void tegra_msi_irq_unmask(struct irq_data *d)\n{\n\tstruct tegra_msi *msi = irq_data_get_irq_chip_data(d);\n\tstruct tegra_pcie *pcie = msi_to_pcie(msi);\n\tunsigned int index = d->hwirq / 32;\n\tunsigned long flags;\n\tu32 value;\n\n\tspin_lock_irqsave(&msi->mask_lock, flags);\n\tvalue = afi_readl(pcie, AFI_MSI_EN_VEC(index));\n\tvalue |= BIT(d->hwirq % 32);\n\tafi_writel(pcie, value, AFI_MSI_EN_VEC(index));\n\tspin_unlock_irqrestore(&msi->mask_lock, flags);\n}\n\nstatic int tegra_msi_set_affinity(struct irq_data *d, const struct cpumask *mask, bool force)\n{\n\treturn -EINVAL;\n}\n\nstatic void tegra_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)\n{\n\tstruct tegra_msi *msi = irq_data_get_irq_chip_data(data);\n\n\tmsg->address_lo = lower_32_bits(msi->phys);\n\tmsg->address_hi = upper_32_bits(msi->phys);\n\tmsg->data = data->hwirq;\n}\n\nstatic struct irq_chip tegra_msi_bottom_chip = {\n\t.name\t\t\t= \"Tegra MSI\",\n\t.irq_ack\t\t= tegra_msi_irq_ack,\n\t.irq_mask\t\t= tegra_msi_irq_mask,\n\t.irq_unmask\t\t= tegra_msi_irq_unmask,\n\t.irq_set_affinity \t= tegra_msi_set_affinity,\n\t.irq_compose_msi_msg\t= tegra_compose_msi_msg,\n};\n\nstatic int tegra_msi_domain_alloc(struct irq_domain *domain, unsigned int virq,\n\t\t\t\t  unsigned int nr_irqs, void *args)\n{\n\tstruct tegra_msi *msi = domain->host_data;\n\tunsigned int i;\n\tint hwirq;\n\n\tmutex_lock(&msi->map_lock);\n\n\thwirq = bitmap_find_free_region(msi->used, INT_PCI_MSI_NR, order_base_2(nr_irqs));\n\n\tmutex_unlock(&msi->map_lock);\n\n\tif (hwirq < 0)\n\t\treturn -ENOSPC;\n\n\tfor (i = 0; i < nr_irqs; i++)\n\t\tirq_domain_set_info(domain, virq + i, hwirq + i,\n\t\t\t\t    &tegra_msi_bottom_chip, domain->host_data,\n\t\t\t\t    handle_edge_irq, NULL, NULL);\n\n\ttegra_cpuidle_pcie_irqs_in_use();\n\n\treturn 0;\n}\n\nstatic void tegra_msi_domain_free(struct irq_domain *domain, unsigned int virq,\n\t\t\t\t  unsigned int nr_irqs)\n{\n\tstruct irq_data *d = irq_domain_get_irq_data(domain, virq);\n\tstruct tegra_msi *msi = domain->host_data;\n\n\tmutex_lock(&msi->map_lock);\n\n\tbitmap_release_region(msi->used, d->hwirq, order_base_2(nr_irqs));\n\n\tmutex_unlock(&msi->map_lock);\n}\n\nstatic const struct irq_domain_ops tegra_msi_domain_ops = {\n\t.alloc = tegra_msi_domain_alloc,\n\t.free = tegra_msi_domain_free,\n};\n\nstatic struct msi_domain_info tegra_msi_info = {\n\t.flags\t= (MSI_FLAG_USE_DEF_DOM_OPS | MSI_FLAG_USE_DEF_CHIP_OPS |\n\t\t   MSI_FLAG_PCI_MSIX),\n\t.chip\t= &tegra_msi_top_chip,\n};\n\nstatic int tegra_allocate_domains(struct tegra_msi *msi)\n{\n\tstruct tegra_pcie *pcie = msi_to_pcie(msi);\n\tstruct fwnode_handle *fwnode = dev_fwnode(pcie->dev);\n\tstruct irq_domain *parent;\n\n\tparent = irq_domain_create_linear(fwnode, INT_PCI_MSI_NR,\n\t\t\t\t\t  &tegra_msi_domain_ops, msi);\n\tif (!parent) {\n\t\tdev_err(pcie->dev, \"failed to create IRQ domain\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tirq_domain_update_bus_token(parent, DOMAIN_BUS_NEXUS);\n\n\tmsi->domain = pci_msi_create_irq_domain(fwnode, &tegra_msi_info, parent);\n\tif (!msi->domain) {\n\t\tdev_err(pcie->dev, \"failed to create MSI domain\\n\");\n\t\tirq_domain_remove(parent);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic void tegra_free_domains(struct tegra_msi *msi)\n{\n\tstruct irq_domain *parent = msi->domain->parent;\n\n\tirq_domain_remove(msi->domain);\n\tirq_domain_remove(parent);\n}\n\nstatic int tegra_pcie_msi_setup(struct tegra_pcie *pcie)\n{\n\tstruct platform_device *pdev = to_platform_device(pcie->dev);\n\tstruct tegra_msi *msi = &pcie->msi;\n\tstruct device *dev = pcie->dev;\n\tint err;\n\n\tmutex_init(&msi->map_lock);\n\tspin_lock_init(&msi->mask_lock);\n\n\tif (IS_ENABLED(CONFIG_PCI_MSI)) {\n\t\terr = tegra_allocate_domains(msi);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = platform_get_irq_byname(pdev, \"msi\");\n\tif (err < 0)\n\t\tgoto free_irq_domain;\n\n\tmsi->irq = err;\n\n\tirq_set_chained_handler_and_data(msi->irq, tegra_pcie_msi_irq, pcie);\n\n\t \n\terr = dma_set_coherent_mask(dev, DMA_BIT_MASK(32));\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to set DMA coherent mask: %d\\n\", err);\n\t\tgoto free_irq;\n\t}\n\n\tmsi->virt = dma_alloc_attrs(dev, PAGE_SIZE, &msi->phys, GFP_KERNEL,\n\t\t\t\t    DMA_ATTR_NO_KERNEL_MAPPING);\n\tif (!msi->virt) {\n\t\tdev_err(dev, \"failed to allocate DMA memory for MSI\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto free_irq;\n\t}\n\n\treturn 0;\n\nfree_irq:\n\tirq_set_chained_handler_and_data(msi->irq, NULL, NULL);\nfree_irq_domain:\n\tif (IS_ENABLED(CONFIG_PCI_MSI))\n\t\ttegra_free_domains(msi);\n\n\treturn err;\n}\n\nstatic void tegra_pcie_enable_msi(struct tegra_pcie *pcie)\n{\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tstruct tegra_msi *msi = &pcie->msi;\n\tu32 reg, msi_state[INT_PCI_MSI_NR / 32];\n\tint i;\n\n\tafi_writel(pcie, msi->phys >> soc->msi_base_shift, AFI_MSI_FPCI_BAR_ST);\n\tafi_writel(pcie, msi->phys, AFI_MSI_AXI_BAR_ST);\n\t \n\tafi_writel(pcie, 1, AFI_MSI_BAR_SZ);\n\n\t \n\tbitmap_to_arr32(msi_state, msi->used, INT_PCI_MSI_NR);\n\tfor (i = 0; i < ARRAY_SIZE(msi_state); i++)\n\t\tafi_writel(pcie, msi_state[i], AFI_MSI_EN_VEC(i));\n\n\t \n\treg = afi_readl(pcie, AFI_INTR_MASK);\n\treg |= AFI_INTR_MASK_MSI_MASK;\n\tafi_writel(pcie, reg, AFI_INTR_MASK);\n}\n\nstatic void tegra_pcie_msi_teardown(struct tegra_pcie *pcie)\n{\n\tstruct tegra_msi *msi = &pcie->msi;\n\tunsigned int i, irq;\n\n\tdma_free_attrs(pcie->dev, PAGE_SIZE, msi->virt, msi->phys,\n\t\t       DMA_ATTR_NO_KERNEL_MAPPING);\n\n\tfor (i = 0; i < INT_PCI_MSI_NR; i++) {\n\t\tirq = irq_find_mapping(msi->domain, i);\n\t\tif (irq > 0)\n\t\t\tirq_domain_free_irqs(irq, 1);\n\t}\n\n\tirq_set_chained_handler_and_data(msi->irq, NULL, NULL);\n\n\tif (IS_ENABLED(CONFIG_PCI_MSI))\n\t\ttegra_free_domains(msi);\n}\n\nstatic int tegra_pcie_disable_msi(struct tegra_pcie *pcie)\n{\n\tu32 value;\n\n\t \n\tvalue = afi_readl(pcie, AFI_INTR_MASK);\n\tvalue &= ~AFI_INTR_MASK_MSI_MASK;\n\tafi_writel(pcie, value, AFI_INTR_MASK);\n\n\treturn 0;\n}\n\nstatic void tegra_pcie_disable_interrupts(struct tegra_pcie *pcie)\n{\n\tu32 value;\n\n\tvalue = afi_readl(pcie, AFI_INTR_MASK);\n\tvalue &= ~AFI_INTR_MASK_INT_MASK;\n\tafi_writel(pcie, value, AFI_INTR_MASK);\n}\n\nstatic int tegra_pcie_get_xbar_config(struct tegra_pcie *pcie, u32 lanes,\n\t\t\t\t      u32 *xbar)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct device_node *np = dev->of_node;\n\n\tif (of_device_is_compatible(np, \"nvidia,tegra186-pcie\")) {\n\t\tswitch (lanes) {\n\t\tcase 0x010004:\n\t\t\tdev_info(dev, \"4x1, 1x1 configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_401;\n\t\t\treturn 0;\n\n\t\tcase 0x010102:\n\t\t\tdev_info(dev, \"2x1, 1X1, 1x1 configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_211;\n\t\t\treturn 0;\n\n\t\tcase 0x010101:\n\t\t\tdev_info(dev, \"1x1, 1x1, 1x1 configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_111;\n\t\t\treturn 0;\n\n\t\tdefault:\n\t\t\tdev_info(dev, \"wrong configuration updated in DT, \"\n\t\t\t\t \"switching to default 2x1, 1x1, 1x1 \"\n\t\t\t\t \"configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_211;\n\t\t\treturn 0;\n\t\t}\n\t} else if (of_device_is_compatible(np, \"nvidia,tegra124-pcie\") ||\n\t\t   of_device_is_compatible(np, \"nvidia,tegra210-pcie\")) {\n\t\tswitch (lanes) {\n\t\tcase 0x0000104:\n\t\t\tdev_info(dev, \"4x1, 1x1 configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_X4_X1;\n\t\t\treturn 0;\n\n\t\tcase 0x0000102:\n\t\t\tdev_info(dev, \"2x1, 1x1 configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_X2_X1;\n\t\t\treturn 0;\n\t\t}\n\t} else if (of_device_is_compatible(np, \"nvidia,tegra30-pcie\")) {\n\t\tswitch (lanes) {\n\t\tcase 0x00000204:\n\t\t\tdev_info(dev, \"4x1, 2x1 configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_420;\n\t\t\treturn 0;\n\n\t\tcase 0x00020202:\n\t\t\tdev_info(dev, \"2x3 configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_222;\n\t\t\treturn 0;\n\n\t\tcase 0x00010104:\n\t\t\tdev_info(dev, \"4x1, 1x2 configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_411;\n\t\t\treturn 0;\n\t\t}\n\t} else if (of_device_is_compatible(np, \"nvidia,tegra20-pcie\")) {\n\t\tswitch (lanes) {\n\t\tcase 0x00000004:\n\t\t\tdev_info(dev, \"single-mode configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_SINGLE;\n\t\t\treturn 0;\n\n\t\tcase 0x00000202:\n\t\t\tdev_info(dev, \"dual-mode configuration\\n\");\n\t\t\t*xbar = AFI_PCIE_CONFIG_SM2TMS0_XBAR_CONFIG_DUAL;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn -EINVAL;\n}\n\n \nstatic bool of_regulator_bulk_available(struct device_node *np,\n\t\t\t\t\tstruct regulator_bulk_data *supplies,\n\t\t\t\t\tunsigned int num_supplies)\n{\n\tchar property[32];\n\tunsigned int i;\n\n\tfor (i = 0; i < num_supplies; i++) {\n\t\tsnprintf(property, 32, \"%s-supply\", supplies[i].supply);\n\n\t\tif (!of_property_present(np, property))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic int tegra_pcie_get_legacy_regulators(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct device_node *np = dev->of_node;\n\n\tif (of_device_is_compatible(np, \"nvidia,tegra30-pcie\"))\n\t\tpcie->num_supplies = 3;\n\telse if (of_device_is_compatible(np, \"nvidia,tegra20-pcie\"))\n\t\tpcie->num_supplies = 2;\n\n\tif (pcie->num_supplies == 0) {\n\t\tdev_err(dev, \"device %pOF not supported in legacy mode\\n\", np);\n\t\treturn -ENODEV;\n\t}\n\n\tpcie->supplies = devm_kcalloc(dev, pcie->num_supplies,\n\t\t\t\t      sizeof(*pcie->supplies),\n\t\t\t\t      GFP_KERNEL);\n\tif (!pcie->supplies)\n\t\treturn -ENOMEM;\n\n\tpcie->supplies[0].supply = \"pex-clk\";\n\tpcie->supplies[1].supply = \"vdd\";\n\n\tif (pcie->num_supplies > 2)\n\t\tpcie->supplies[2].supply = \"avdd\";\n\n\treturn devm_regulator_bulk_get(dev, pcie->num_supplies, pcie->supplies);\n}\n\n \nstatic int tegra_pcie_get_regulators(struct tegra_pcie *pcie, u32 lane_mask)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct device_node *np = dev->of_node;\n\tunsigned int i = 0;\n\n\tif (of_device_is_compatible(np, \"nvidia,tegra186-pcie\")) {\n\t\tpcie->num_supplies = 4;\n\n\t\tpcie->supplies = devm_kcalloc(pcie->dev, pcie->num_supplies,\n\t\t\t\t\t      sizeof(*pcie->supplies),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!pcie->supplies)\n\t\t\treturn -ENOMEM;\n\n\t\tpcie->supplies[i++].supply = \"dvdd-pex\";\n\t\tpcie->supplies[i++].supply = \"hvdd-pex-pll\";\n\t\tpcie->supplies[i++].supply = \"hvdd-pex\";\n\t\tpcie->supplies[i++].supply = \"vddio-pexctl-aud\";\n\t} else if (of_device_is_compatible(np, \"nvidia,tegra210-pcie\")) {\n\t\tpcie->num_supplies = 3;\n\n\t\tpcie->supplies = devm_kcalloc(pcie->dev, pcie->num_supplies,\n\t\t\t\t\t      sizeof(*pcie->supplies),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!pcie->supplies)\n\t\t\treturn -ENOMEM;\n\n\t\tpcie->supplies[i++].supply = \"hvddio-pex\";\n\t\tpcie->supplies[i++].supply = \"dvddio-pex\";\n\t\tpcie->supplies[i++].supply = \"vddio-pex-ctl\";\n\t} else if (of_device_is_compatible(np, \"nvidia,tegra124-pcie\")) {\n\t\tpcie->num_supplies = 4;\n\n\t\tpcie->supplies = devm_kcalloc(dev, pcie->num_supplies,\n\t\t\t\t\t      sizeof(*pcie->supplies),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!pcie->supplies)\n\t\t\treturn -ENOMEM;\n\n\t\tpcie->supplies[i++].supply = \"avddio-pex\";\n\t\tpcie->supplies[i++].supply = \"dvddio-pex\";\n\t\tpcie->supplies[i++].supply = \"hvdd-pex\";\n\t\tpcie->supplies[i++].supply = \"vddio-pex-ctl\";\n\t} else if (of_device_is_compatible(np, \"nvidia,tegra30-pcie\")) {\n\t\tbool need_pexa = false, need_pexb = false;\n\n\t\t \n\t\tif (lane_mask & 0x0f)\n\t\t\tneed_pexa = true;\n\n\t\t \n\t\tif (lane_mask & 0x30)\n\t\t\tneed_pexb = true;\n\n\t\tpcie->num_supplies = 4 + (need_pexa ? 2 : 0) +\n\t\t\t\t\t (need_pexb ? 2 : 0);\n\n\t\tpcie->supplies = devm_kcalloc(dev, pcie->num_supplies,\n\t\t\t\t\t      sizeof(*pcie->supplies),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!pcie->supplies)\n\t\t\treturn -ENOMEM;\n\n\t\tpcie->supplies[i++].supply = \"avdd-pex-pll\";\n\t\tpcie->supplies[i++].supply = \"hvdd-pex\";\n\t\tpcie->supplies[i++].supply = \"vddio-pex-ctl\";\n\t\tpcie->supplies[i++].supply = \"avdd-plle\";\n\n\t\tif (need_pexa) {\n\t\t\tpcie->supplies[i++].supply = \"avdd-pexa\";\n\t\t\tpcie->supplies[i++].supply = \"vdd-pexa\";\n\t\t}\n\n\t\tif (need_pexb) {\n\t\t\tpcie->supplies[i++].supply = \"avdd-pexb\";\n\t\t\tpcie->supplies[i++].supply = \"vdd-pexb\";\n\t\t}\n\t} else if (of_device_is_compatible(np, \"nvidia,tegra20-pcie\")) {\n\t\tpcie->num_supplies = 5;\n\n\t\tpcie->supplies = devm_kcalloc(dev, pcie->num_supplies,\n\t\t\t\t\t      sizeof(*pcie->supplies),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!pcie->supplies)\n\t\t\treturn -ENOMEM;\n\n\t\tpcie->supplies[0].supply = \"avdd-pex\";\n\t\tpcie->supplies[1].supply = \"vdd-pex\";\n\t\tpcie->supplies[2].supply = \"avdd-pex-pll\";\n\t\tpcie->supplies[3].supply = \"avdd-plle\";\n\t\tpcie->supplies[4].supply = \"vddio-pex-clk\";\n\t}\n\n\tif (of_regulator_bulk_available(dev->of_node, pcie->supplies,\n\t\t\t\t\tpcie->num_supplies))\n\t\treturn devm_regulator_bulk_get(dev, pcie->num_supplies,\n\t\t\t\t\t       pcie->supplies);\n\n\t \n\tdev_info(dev, \"using legacy DT binding for power supplies\\n\");\n\n\tdevm_kfree(dev, pcie->supplies);\n\tpcie->num_supplies = 0;\n\n\treturn tegra_pcie_get_legacy_regulators(pcie);\n}\n\nstatic int tegra_pcie_parse_dt(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct device_node *np = dev->of_node, *port;\n\tconst struct tegra_pcie_soc *soc = pcie->soc;\n\tu32 lanes = 0, mask = 0;\n\tunsigned int lane = 0;\n\tint err;\n\n\t \n\tfor_each_child_of_node(np, port) {\n\t\tstruct tegra_pcie_port *rp;\n\t\tunsigned int index;\n\t\tu32 value;\n\t\tchar *label;\n\n\t\terr = of_pci_get_devfn(port);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev, \"failed to parse address: %d\\n\", err);\n\t\t\tgoto err_node_put;\n\t\t}\n\n\t\tindex = PCI_SLOT(err);\n\n\t\tif (index < 1 || index > soc->num_ports) {\n\t\t\tdev_err(dev, \"invalid port number: %d\\n\", index);\n\t\t\terr = -EINVAL;\n\t\t\tgoto err_node_put;\n\t\t}\n\n\t\tindex--;\n\n\t\terr = of_property_read_u32(port, \"nvidia,num-lanes\", &value);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev, \"failed to parse # of lanes: %d\\n\",\n\t\t\t\terr);\n\t\t\tgoto err_node_put;\n\t\t}\n\n\t\tif (value > 16) {\n\t\t\tdev_err(dev, \"invalid # of lanes: %u\\n\", value);\n\t\t\terr = -EINVAL;\n\t\t\tgoto err_node_put;\n\t\t}\n\n\t\tlanes |= value << (index << 3);\n\n\t\tif (!of_device_is_available(port)) {\n\t\t\tlane += value;\n\t\t\tcontinue;\n\t\t}\n\n\t\tmask |= ((1 << value) - 1) << lane;\n\t\tlane += value;\n\n\t\trp = devm_kzalloc(dev, sizeof(*rp), GFP_KERNEL);\n\t\tif (!rp) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_node_put;\n\t\t}\n\n\t\terr = of_address_to_resource(port, 0, &rp->regs);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev, \"failed to parse address: %d\\n\", err);\n\t\t\tgoto err_node_put;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&rp->list);\n\t\trp->index = index;\n\t\trp->lanes = value;\n\t\trp->pcie = pcie;\n\t\trp->np = port;\n\n\t\trp->base = devm_pci_remap_cfg_resource(dev, &rp->regs);\n\t\tif (IS_ERR(rp->base)) {\n\t\t\terr = PTR_ERR(rp->base);\n\t\t\tgoto err_node_put;\n\t\t}\n\n\t\tlabel = devm_kasprintf(dev, GFP_KERNEL, \"pex-reset-%u\", index);\n\t\tif (!label) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_node_put;\n\t\t}\n\n\t\t \n\t\trp->reset_gpio = devm_fwnode_gpiod_get(dev,\n\t\t\t\t\t\t       of_fwnode_handle(port),\n\t\t\t\t\t\t       \"reset\",\n\t\t\t\t\t\t       GPIOD_OUT_LOW,\n\t\t\t\t\t\t       label);\n\t\tif (IS_ERR(rp->reset_gpio)) {\n\t\t\tif (PTR_ERR(rp->reset_gpio) == -ENOENT) {\n\t\t\t\trp->reset_gpio = NULL;\n\t\t\t} else {\n\t\t\t\tdev_err(dev, \"failed to get reset GPIO: %ld\\n\",\n\t\t\t\t\tPTR_ERR(rp->reset_gpio));\n\t\t\t\terr = PTR_ERR(rp->reset_gpio);\n\t\t\t\tgoto err_node_put;\n\t\t\t}\n\t\t}\n\n\t\tlist_add_tail(&rp->list, &pcie->ports);\n\t}\n\n\terr = tegra_pcie_get_xbar_config(pcie, lanes, &pcie->xbar_config);\n\tif (err < 0) {\n\t\tdev_err(dev, \"invalid lane configuration\\n\");\n\t\treturn err;\n\t}\n\n\terr = tegra_pcie_get_regulators(pcie, mask);\n\tif (err < 0)\n\t\treturn err;\n\n\treturn 0;\n\nerr_node_put:\n\tof_node_put(port);\n\treturn err;\n}\n\n \n#define TEGRA_PCIE_LINKUP_TIMEOUT\t200\t \nstatic bool tegra_pcie_port_check_link(struct tegra_pcie_port *port)\n{\n\tstruct device *dev = port->pcie->dev;\n\tunsigned int retries = 3;\n\tunsigned long value;\n\n\t \n\tvalue = readl(port->base + RP_PRIV_MISC);\n\tvalue &= ~RP_PRIV_MISC_PRSNT_MAP_EP_ABSNT;\n\tvalue |= RP_PRIV_MISC_PRSNT_MAP_EP_PRSNT;\n\twritel(value, port->base + RP_PRIV_MISC);\n\n\tdo {\n\t\tunsigned int timeout = TEGRA_PCIE_LINKUP_TIMEOUT;\n\n\t\tdo {\n\t\t\tvalue = readl(port->base + RP_VEND_XP);\n\n\t\t\tif (value & RP_VEND_XP_DL_UP)\n\t\t\t\tbreak;\n\n\t\t\tusleep_range(1000, 2000);\n\t\t} while (--timeout);\n\n\t\tif (!timeout) {\n\t\t\tdev_dbg(dev, \"link %u down, retrying\\n\", port->index);\n\t\t\tgoto retry;\n\t\t}\n\n\t\ttimeout = TEGRA_PCIE_LINKUP_TIMEOUT;\n\n\t\tdo {\n\t\t\tvalue = readl(port->base + RP_LINK_CONTROL_STATUS);\n\n\t\t\tif (value & RP_LINK_CONTROL_STATUS_DL_LINK_ACTIVE)\n\t\t\t\treturn true;\n\n\t\t\tusleep_range(1000, 2000);\n\t\t} while (--timeout);\n\nretry:\n\t\ttegra_pcie_port_reset(port);\n\t} while (--retries);\n\n\treturn false;\n}\n\nstatic void tegra_pcie_change_link_speed(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct tegra_pcie_port *port;\n\tktime_t deadline;\n\tu32 value;\n\n\tlist_for_each_entry(port, &pcie->ports, list) {\n\t\t \n\t\tvalue = readl(port->base + RP_LINK_CONTROL_STATUS_2);\n\t\tvalue &= ~PCI_EXP_LNKSTA_CLS;\n\t\tvalue |= PCI_EXP_LNKSTA_CLS_5_0GB;\n\t\twritel(value, port->base + RP_LINK_CONTROL_STATUS_2);\n\n\t\t \n\t\tdeadline = ktime_add_us(ktime_get(), LINK_RETRAIN_TIMEOUT);\n\n\t\twhile (ktime_before(ktime_get(), deadline)) {\n\t\t\tvalue = readl(port->base + RP_LINK_CONTROL_STATUS);\n\t\t\tif ((value & PCI_EXP_LNKSTA_LT) == 0)\n\t\t\t\tbreak;\n\n\t\t\tusleep_range(2000, 3000);\n\t\t}\n\n\t\tif (value & PCI_EXP_LNKSTA_LT)\n\t\t\tdev_warn(dev, \"PCIe port %u link is in recovery\\n\",\n\t\t\t\t port->index);\n\n\t\t \n\t\tvalue = readl(port->base + RP_LINK_CONTROL_STATUS);\n\t\tvalue |= PCI_EXP_LNKCTL_RL;\n\t\twritel(value, port->base + RP_LINK_CONTROL_STATUS);\n\n\t\tdeadline = ktime_add_us(ktime_get(), LINK_RETRAIN_TIMEOUT);\n\n\t\twhile (ktime_before(ktime_get(), deadline)) {\n\t\t\tvalue = readl(port->base + RP_LINK_CONTROL_STATUS);\n\t\t\tif ((value & PCI_EXP_LNKSTA_LT) == 0)\n\t\t\t\tbreak;\n\n\t\t\tusleep_range(2000, 3000);\n\t\t}\n\n\t\tif (value & PCI_EXP_LNKSTA_LT)\n\t\t\tdev_err(dev, \"failed to retrain link of port %u\\n\",\n\t\t\t\tport->index);\n\t}\n}\n\nstatic void tegra_pcie_enable_ports(struct tegra_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct tegra_pcie_port *port, *tmp;\n\n\tlist_for_each_entry_safe(port, tmp, &pcie->ports, list) {\n\t\tdev_info(dev, \"probing port %u, using %u lanes\\n\",\n\t\t\t port->index, port->lanes);\n\n\t\ttegra_pcie_port_enable(port);\n\t}\n\n\t \n\treset_control_deassert(pcie->pcie_xrst);\n\n\tlist_for_each_entry_safe(port, tmp, &pcie->ports, list) {\n\t\tif (tegra_pcie_port_check_link(port))\n\t\t\tcontinue;\n\n\t\tdev_info(dev, \"link %u down, ignoring\\n\", port->index);\n\n\t\ttegra_pcie_port_disable(port);\n\t\ttegra_pcie_port_free(port);\n\t}\n\n\tif (pcie->soc->has_gen2)\n\t\ttegra_pcie_change_link_speed(pcie);\n}\n\nstatic void tegra_pcie_disable_ports(struct tegra_pcie *pcie)\n{\n\tstruct tegra_pcie_port *port, *tmp;\n\n\treset_control_assert(pcie->pcie_xrst);\n\n\tlist_for_each_entry_safe(port, tmp, &pcie->ports, list)\n\t\ttegra_pcie_port_disable(port);\n}\n\nstatic const struct tegra_pcie_port_soc tegra20_pcie_ports[] = {\n\t{ .pme.turnoff_bit = 0, .pme.ack_bit =  5 },\n\t{ .pme.turnoff_bit = 8, .pme.ack_bit = 10 },\n};\n\nstatic const struct tegra_pcie_soc tegra20_pcie = {\n\t.num_ports = 2,\n\t.ports = tegra20_pcie_ports,\n\t.msi_base_shift = 0,\n\t.pads_pll_ctl = PADS_PLL_CTL_TEGRA20,\n\t.tx_ref_sel = PADS_PLL_CTL_TXCLKREF_DIV10,\n\t.pads_refclk_cfg0 = 0xfa5cfa5c,\n\t.has_pex_clkreq_en = false,\n\t.has_pex_bias_ctrl = false,\n\t.has_intr_prsnt_sense = false,\n\t.has_cml_clk = false,\n\t.has_gen2 = false,\n\t.force_pca_enable = false,\n\t.program_uphy = true,\n\t.update_clamp_threshold = false,\n\t.program_deskew_time = false,\n\t.update_fc_timer = false,\n\t.has_cache_bars = true,\n\t.ectl.enable = false,\n};\n\nstatic const struct tegra_pcie_port_soc tegra30_pcie_ports[] = {\n\t{ .pme.turnoff_bit =  0, .pme.ack_bit =  5 },\n\t{ .pme.turnoff_bit =  8, .pme.ack_bit = 10 },\n\t{ .pme.turnoff_bit = 16, .pme.ack_bit = 18 },\n};\n\nstatic const struct tegra_pcie_soc tegra30_pcie = {\n\t.num_ports = 3,\n\t.ports = tegra30_pcie_ports,\n\t.msi_base_shift = 8,\n\t.afi_pex2_ctrl = 0x128,\n\t.pads_pll_ctl = PADS_PLL_CTL_TEGRA30,\n\t.tx_ref_sel = PADS_PLL_CTL_TXCLKREF_BUF_EN,\n\t.pads_refclk_cfg0 = 0xfa5cfa5c,\n\t.pads_refclk_cfg1 = 0xfa5cfa5c,\n\t.has_pex_clkreq_en = true,\n\t.has_pex_bias_ctrl = true,\n\t.has_intr_prsnt_sense = true,\n\t.has_cml_clk = true,\n\t.has_gen2 = false,\n\t.force_pca_enable = false,\n\t.program_uphy = true,\n\t.update_clamp_threshold = false,\n\t.program_deskew_time = false,\n\t.update_fc_timer = false,\n\t.has_cache_bars = false,\n\t.ectl.enable = false,\n};\n\nstatic const struct tegra_pcie_soc tegra124_pcie = {\n\t.num_ports = 2,\n\t.ports = tegra20_pcie_ports,\n\t.msi_base_shift = 8,\n\t.pads_pll_ctl = PADS_PLL_CTL_TEGRA30,\n\t.tx_ref_sel = PADS_PLL_CTL_TXCLKREF_BUF_EN,\n\t.pads_refclk_cfg0 = 0x44ac44ac,\n\t.has_pex_clkreq_en = true,\n\t.has_pex_bias_ctrl = true,\n\t.has_intr_prsnt_sense = true,\n\t.has_cml_clk = true,\n\t.has_gen2 = true,\n\t.force_pca_enable = false,\n\t.program_uphy = true,\n\t.update_clamp_threshold = true,\n\t.program_deskew_time = false,\n\t.update_fc_timer = false,\n\t.has_cache_bars = false,\n\t.ectl.enable = false,\n};\n\nstatic const struct tegra_pcie_soc tegra210_pcie = {\n\t.num_ports = 2,\n\t.ports = tegra20_pcie_ports,\n\t.msi_base_shift = 8,\n\t.pads_pll_ctl = PADS_PLL_CTL_TEGRA30,\n\t.tx_ref_sel = PADS_PLL_CTL_TXCLKREF_BUF_EN,\n\t.pads_refclk_cfg0 = 0x90b890b8,\n\t \n\t.update_fc_threshold = 0x01800000,\n\t.has_pex_clkreq_en = true,\n\t.has_pex_bias_ctrl = true,\n\t.has_intr_prsnt_sense = true,\n\t.has_cml_clk = true,\n\t.has_gen2 = true,\n\t.force_pca_enable = true,\n\t.program_uphy = true,\n\t.update_clamp_threshold = true,\n\t.program_deskew_time = true,\n\t.update_fc_timer = true,\n\t.has_cache_bars = false,\n\t.ectl = {\n\t\t.regs = {\n\t\t\t.rp_ectl_2_r1 = 0x0000000f,\n\t\t\t.rp_ectl_4_r1 = 0x00000067,\n\t\t\t.rp_ectl_5_r1 = 0x55010000,\n\t\t\t.rp_ectl_6_r1 = 0x00000001,\n\t\t\t.rp_ectl_2_r2 = 0x0000008f,\n\t\t\t.rp_ectl_4_r2 = 0x000000c7,\n\t\t\t.rp_ectl_5_r2 = 0x55010000,\n\t\t\t.rp_ectl_6_r2 = 0x00000001,\n\t\t},\n\t\t.enable = true,\n\t},\n};\n\nstatic const struct tegra_pcie_port_soc tegra186_pcie_ports[] = {\n\t{ .pme.turnoff_bit =  0, .pme.ack_bit =  5 },\n\t{ .pme.turnoff_bit =  8, .pme.ack_bit = 10 },\n\t{ .pme.turnoff_bit = 12, .pme.ack_bit = 14 },\n};\n\nstatic const struct tegra_pcie_soc tegra186_pcie = {\n\t.num_ports = 3,\n\t.ports = tegra186_pcie_ports,\n\t.msi_base_shift = 8,\n\t.afi_pex2_ctrl = 0x19c,\n\t.pads_pll_ctl = PADS_PLL_CTL_TEGRA30,\n\t.tx_ref_sel = PADS_PLL_CTL_TXCLKREF_BUF_EN,\n\t.pads_refclk_cfg0 = 0x80b880b8,\n\t.pads_refclk_cfg1 = 0x000480b8,\n\t.has_pex_clkreq_en = true,\n\t.has_pex_bias_ctrl = true,\n\t.has_intr_prsnt_sense = true,\n\t.has_cml_clk = false,\n\t.has_gen2 = true,\n\t.force_pca_enable = false,\n\t.program_uphy = false,\n\t.update_clamp_threshold = false,\n\t.program_deskew_time = false,\n\t.update_fc_timer = false,\n\t.has_cache_bars = false,\n\t.ectl.enable = false,\n};\n\nstatic const struct of_device_id tegra_pcie_of_match[] = {\n\t{ .compatible = \"nvidia,tegra186-pcie\", .data = &tegra186_pcie },\n\t{ .compatible = \"nvidia,tegra210-pcie\", .data = &tegra210_pcie },\n\t{ .compatible = \"nvidia,tegra124-pcie\", .data = &tegra124_pcie },\n\t{ .compatible = \"nvidia,tegra30-pcie\", .data = &tegra30_pcie },\n\t{ .compatible = \"nvidia,tegra20-pcie\", .data = &tegra20_pcie },\n\t{ },\n};\nMODULE_DEVICE_TABLE(of, tegra_pcie_of_match);\n\nstatic void *tegra_pcie_ports_seq_start(struct seq_file *s, loff_t *pos)\n{\n\tstruct tegra_pcie *pcie = s->private;\n\n\tif (list_empty(&pcie->ports))\n\t\treturn NULL;\n\n\tseq_puts(s, \"Index  Status\\n\");\n\n\treturn seq_list_start(&pcie->ports, *pos);\n}\n\nstatic void *tegra_pcie_ports_seq_next(struct seq_file *s, void *v, loff_t *pos)\n{\n\tstruct tegra_pcie *pcie = s->private;\n\n\treturn seq_list_next(v, &pcie->ports, pos);\n}\n\nstatic void tegra_pcie_ports_seq_stop(struct seq_file *s, void *v)\n{\n}\n\nstatic int tegra_pcie_ports_seq_show(struct seq_file *s, void *v)\n{\n\tbool up = false, active = false;\n\tstruct tegra_pcie_port *port;\n\tunsigned int value;\n\n\tport = list_entry(v, struct tegra_pcie_port, list);\n\n\tvalue = readl(port->base + RP_VEND_XP);\n\n\tif (value & RP_VEND_XP_DL_UP)\n\t\tup = true;\n\n\tvalue = readl(port->base + RP_LINK_CONTROL_STATUS);\n\n\tif (value & RP_LINK_CONTROL_STATUS_DL_LINK_ACTIVE)\n\t\tactive = true;\n\n\tseq_printf(s, \"%2u     \", port->index);\n\n\tif (up)\n\t\tseq_puts(s, \"up\");\n\n\tif (active) {\n\t\tif (up)\n\t\t\tseq_puts(s, \", \");\n\n\t\tseq_puts(s, \"active\");\n\t}\n\n\tseq_puts(s, \"\\n\");\n\treturn 0;\n}\n\nstatic const struct seq_operations tegra_pcie_ports_sops = {\n\t.start = tegra_pcie_ports_seq_start,\n\t.next = tegra_pcie_ports_seq_next,\n\t.stop = tegra_pcie_ports_seq_stop,\n\t.show = tegra_pcie_ports_seq_show,\n};\n\nDEFINE_SEQ_ATTRIBUTE(tegra_pcie_ports);\n\nstatic void tegra_pcie_debugfs_exit(struct tegra_pcie *pcie)\n{\n\tdebugfs_remove_recursive(pcie->debugfs);\n\tpcie->debugfs = NULL;\n}\n\nstatic void tegra_pcie_debugfs_init(struct tegra_pcie *pcie)\n{\n\tpcie->debugfs = debugfs_create_dir(\"pcie\", NULL);\n\n\tdebugfs_create_file(\"ports\", S_IFREG | S_IRUGO, pcie->debugfs, pcie,\n\t\t\t    &tegra_pcie_ports_fops);\n}\n\nstatic int tegra_pcie_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct pci_host_bridge *host;\n\tstruct tegra_pcie *pcie;\n\tint err;\n\n\thost = devm_pci_alloc_host_bridge(dev, sizeof(*pcie));\n\tif (!host)\n\t\treturn -ENOMEM;\n\n\tpcie = pci_host_bridge_priv(host);\n\thost->sysdata = pcie;\n\tplatform_set_drvdata(pdev, pcie);\n\n\tpcie->soc = of_device_get_match_data(dev);\n\tINIT_LIST_HEAD(&pcie->ports);\n\tpcie->dev = dev;\n\n\terr = tegra_pcie_parse_dt(pcie);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = tegra_pcie_get_resources(pcie);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to request resources: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = tegra_pcie_msi_setup(pcie);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to enable MSI support: %d\\n\", err);\n\t\tgoto put_resources;\n\t}\n\n\tpm_runtime_enable(pcie->dev);\n\terr = pm_runtime_get_sync(pcie->dev);\n\tif (err < 0) {\n\t\tdev_err(dev, \"fail to enable pcie controller: %d\\n\", err);\n\t\tgoto pm_runtime_put;\n\t}\n\n\thost->ops = &tegra_pcie_ops;\n\thost->map_irq = tegra_pcie_map_irq;\n\n\terr = pci_host_probe(host);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to register host: %d\\n\", err);\n\t\tgoto pm_runtime_put;\n\t}\n\n\tif (IS_ENABLED(CONFIG_DEBUG_FS))\n\t\ttegra_pcie_debugfs_init(pcie);\n\n\treturn 0;\n\npm_runtime_put:\n\tpm_runtime_put_sync(pcie->dev);\n\tpm_runtime_disable(pcie->dev);\n\ttegra_pcie_msi_teardown(pcie);\nput_resources:\n\ttegra_pcie_put_resources(pcie);\n\treturn err;\n}\n\nstatic void tegra_pcie_remove(struct platform_device *pdev)\n{\n\tstruct tegra_pcie *pcie = platform_get_drvdata(pdev);\n\tstruct pci_host_bridge *host = pci_host_bridge_from_priv(pcie);\n\tstruct tegra_pcie_port *port, *tmp;\n\n\tif (IS_ENABLED(CONFIG_DEBUG_FS))\n\t\ttegra_pcie_debugfs_exit(pcie);\n\n\tpci_stop_root_bus(host->bus);\n\tpci_remove_root_bus(host->bus);\n\tpm_runtime_put_sync(pcie->dev);\n\tpm_runtime_disable(pcie->dev);\n\n\tif (IS_ENABLED(CONFIG_PCI_MSI))\n\t\ttegra_pcie_msi_teardown(pcie);\n\n\ttegra_pcie_put_resources(pcie);\n\n\tlist_for_each_entry_safe(port, tmp, &pcie->ports, list)\n\t\ttegra_pcie_port_free(port);\n}\n\nstatic int tegra_pcie_pm_suspend(struct device *dev)\n{\n\tstruct tegra_pcie *pcie = dev_get_drvdata(dev);\n\tstruct tegra_pcie_port *port;\n\tint err;\n\n\tlist_for_each_entry(port, &pcie->ports, list)\n\t\ttegra_pcie_pme_turnoff(port);\n\n\ttegra_pcie_disable_ports(pcie);\n\n\t \n\ttegra_pcie_disable_interrupts(pcie);\n\n\tif (pcie->soc->program_uphy) {\n\t\terr = tegra_pcie_phy_power_off(pcie);\n\t\tif (err < 0)\n\t\t\tdev_err(dev, \"failed to power off PHY(s): %d\\n\", err);\n\t}\n\n\treset_control_assert(pcie->pex_rst);\n\tclk_disable_unprepare(pcie->pex_clk);\n\n\tif (IS_ENABLED(CONFIG_PCI_MSI))\n\t\ttegra_pcie_disable_msi(pcie);\n\n\tpinctrl_pm_select_idle_state(dev);\n\ttegra_pcie_power_off(pcie);\n\n\treturn 0;\n}\n\nstatic int tegra_pcie_pm_resume(struct device *dev)\n{\n\tstruct tegra_pcie *pcie = dev_get_drvdata(dev);\n\tint err;\n\n\terr = tegra_pcie_power_on(pcie);\n\tif (err) {\n\t\tdev_err(dev, \"tegra pcie power on fail: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = pinctrl_pm_select_default_state(dev);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to disable PCIe IO DPD: %d\\n\", err);\n\t\tgoto poweroff;\n\t}\n\n\ttegra_pcie_enable_controller(pcie);\n\ttegra_pcie_setup_translations(pcie);\n\n\tif (IS_ENABLED(CONFIG_PCI_MSI))\n\t\ttegra_pcie_enable_msi(pcie);\n\n\terr = clk_prepare_enable(pcie->pex_clk);\n\tif (err) {\n\t\tdev_err(dev, \"failed to enable PEX clock: %d\\n\", err);\n\t\tgoto pex_dpd_enable;\n\t}\n\n\treset_control_deassert(pcie->pex_rst);\n\n\tif (pcie->soc->program_uphy) {\n\t\terr = tegra_pcie_phy_power_on(pcie);\n\t\tif (err < 0) {\n\t\t\tdev_err(dev, \"failed to power on PHY(s): %d\\n\", err);\n\t\t\tgoto disable_pex_clk;\n\t\t}\n\t}\n\n\ttegra_pcie_apply_pad_settings(pcie);\n\ttegra_pcie_enable_ports(pcie);\n\n\treturn 0;\n\ndisable_pex_clk:\n\treset_control_assert(pcie->pex_rst);\n\tclk_disable_unprepare(pcie->pex_clk);\npex_dpd_enable:\n\tpinctrl_pm_select_idle_state(dev);\npoweroff:\n\ttegra_pcie_power_off(pcie);\n\n\treturn err;\n}\n\nstatic const struct dev_pm_ops tegra_pcie_pm_ops = {\n\tRUNTIME_PM_OPS(tegra_pcie_pm_suspend, tegra_pcie_pm_resume, NULL)\n\tNOIRQ_SYSTEM_SLEEP_PM_OPS(tegra_pcie_pm_suspend, tegra_pcie_pm_resume)\n};\n\nstatic struct platform_driver tegra_pcie_driver = {\n\t.driver = {\n\t\t.name = \"tegra-pcie\",\n\t\t.of_match_table = tegra_pcie_of_match,\n\t\t.suppress_bind_attrs = true,\n\t\t.pm = &tegra_pcie_pm_ops,\n\t},\n\t.probe = tegra_pcie_probe,\n\t.remove_new = tegra_pcie_remove,\n};\nmodule_platform_driver(tegra_pcie_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}