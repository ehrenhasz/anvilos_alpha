{
  "module_name": "pci-hyperv.c",
  "hash_id": "bce64f5633fd327e7d15fde4e2780574baf31eca0f7289516aa159831619161f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/controller/pci-hyperv.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/pci-ecam.h>\n#include <linux/delay.h>\n#include <linux/semaphore.h>\n#include <linux/irq.h>\n#include <linux/msi.h>\n#include <linux/hyperv.h>\n#include <linux/refcount.h>\n#include <linux/irqdomain.h>\n#include <linux/acpi.h>\n#include <asm/mshyperv.h>\n\n \n\n#define PCI_MAKE_VERSION(major, minor) ((u32)(((major) << 16) | (minor)))\n#define PCI_MAJOR_VERSION(version) ((u32)(version) >> 16)\n#define PCI_MINOR_VERSION(version) ((u32)(version) & 0xff)\n\nenum pci_protocol_version_t {\n\tPCI_PROTOCOL_VERSION_1_1 = PCI_MAKE_VERSION(1, 1),\t \n\tPCI_PROTOCOL_VERSION_1_2 = PCI_MAKE_VERSION(1, 2),\t \n\tPCI_PROTOCOL_VERSION_1_3 = PCI_MAKE_VERSION(1, 3),\t \n\tPCI_PROTOCOL_VERSION_1_4 = PCI_MAKE_VERSION(1, 4),\t \n};\n\n#define CPU_AFFINITY_ALL\t-1ULL\n\n \nstatic enum pci_protocol_version_t pci_protocol_versions[] = {\n\tPCI_PROTOCOL_VERSION_1_4,\n\tPCI_PROTOCOL_VERSION_1_3,\n\tPCI_PROTOCOL_VERSION_1_2,\n\tPCI_PROTOCOL_VERSION_1_1,\n};\n\n#define PCI_CONFIG_MMIO_LENGTH\t0x2000\n#define CFG_PAGE_OFFSET 0x1000\n#define CFG_PAGE_SIZE (PCI_CONFIG_MMIO_LENGTH - CFG_PAGE_OFFSET)\n\n#define MAX_SUPPORTED_MSI_MESSAGES 0x400\n\n#define STATUS_REVISION_MISMATCH 0xC0000059\n\n \n#define SLOT_NAME_SIZE 11\n\n \n#define HV_PCI_RQSTOR_SIZE 64\n\n \n\nenum pci_message_type {\n\t \n\tPCI_MESSAGE_BASE                = 0x42490000,\n\tPCI_BUS_RELATIONS               = PCI_MESSAGE_BASE + 0,\n\tPCI_QUERY_BUS_RELATIONS         = PCI_MESSAGE_BASE + 1,\n\tPCI_POWER_STATE_CHANGE          = PCI_MESSAGE_BASE + 4,\n\tPCI_QUERY_RESOURCE_REQUIREMENTS = PCI_MESSAGE_BASE + 5,\n\tPCI_QUERY_RESOURCE_RESOURCES    = PCI_MESSAGE_BASE + 6,\n\tPCI_BUS_D0ENTRY                 = PCI_MESSAGE_BASE + 7,\n\tPCI_BUS_D0EXIT                  = PCI_MESSAGE_BASE + 8,\n\tPCI_READ_BLOCK                  = PCI_MESSAGE_BASE + 9,\n\tPCI_WRITE_BLOCK                 = PCI_MESSAGE_BASE + 0xA,\n\tPCI_EJECT                       = PCI_MESSAGE_BASE + 0xB,\n\tPCI_QUERY_STOP                  = PCI_MESSAGE_BASE + 0xC,\n\tPCI_REENABLE                    = PCI_MESSAGE_BASE + 0xD,\n\tPCI_QUERY_STOP_FAILED           = PCI_MESSAGE_BASE + 0xE,\n\tPCI_EJECTION_COMPLETE           = PCI_MESSAGE_BASE + 0xF,\n\tPCI_RESOURCES_ASSIGNED          = PCI_MESSAGE_BASE + 0x10,\n\tPCI_RESOURCES_RELEASED          = PCI_MESSAGE_BASE + 0x11,\n\tPCI_INVALIDATE_BLOCK            = PCI_MESSAGE_BASE + 0x12,\n\tPCI_QUERY_PROTOCOL_VERSION      = PCI_MESSAGE_BASE + 0x13,\n\tPCI_CREATE_INTERRUPT_MESSAGE    = PCI_MESSAGE_BASE + 0x14,\n\tPCI_DELETE_INTERRUPT_MESSAGE    = PCI_MESSAGE_BASE + 0x15,\n\tPCI_RESOURCES_ASSIGNED2\t\t= PCI_MESSAGE_BASE + 0x16,\n\tPCI_CREATE_INTERRUPT_MESSAGE2\t= PCI_MESSAGE_BASE + 0x17,\n\tPCI_DELETE_INTERRUPT_MESSAGE2\t= PCI_MESSAGE_BASE + 0x18,  \n\tPCI_BUS_RELATIONS2\t\t= PCI_MESSAGE_BASE + 0x19,\n\tPCI_RESOURCES_ASSIGNED3         = PCI_MESSAGE_BASE + 0x1A,\n\tPCI_CREATE_INTERRUPT_MESSAGE3   = PCI_MESSAGE_BASE + 0x1B,\n\tPCI_MESSAGE_MAXIMUM\n};\n\n \n\nunion pci_version {\n\tstruct {\n\t\tu16 minor_version;\n\t\tu16 major_version;\n\t} parts;\n\tu32 version;\n} __packed;\n\n \nunion win_slot_encoding {\n\tstruct {\n\t\tu32\tdev:5;\n\t\tu32\tfunc:3;\n\t\tu32\treserved:24;\n\t} bits;\n\tu32 slot;\n} __packed;\n\n \nstruct pci_function_description {\n\tu16\tv_id;\t \n\tu16\td_id;\t \n\tu8\trev;\n\tu8\tprog_intf;\n\tu8\tsubclass;\n\tu8\tbase_class;\n\tu32\tsubsystem_id;\n\tunion win_slot_encoding win_slot;\n\tu32\tser;\t \n} __packed;\n\nenum pci_device_description_flags {\n\tHV_PCI_DEVICE_FLAG_NONE\t\t\t= 0x0,\n\tHV_PCI_DEVICE_FLAG_NUMA_AFFINITY\t= 0x1,\n};\n\nstruct pci_function_description2 {\n\tu16\tv_id;\t \n\tu16\td_id;\t \n\tu8\trev;\n\tu8\tprog_intf;\n\tu8\tsubclass;\n\tu8\tbase_class;\n\tu32\tsubsystem_id;\n\tunion\twin_slot_encoding win_slot;\n\tu32\tser;\t \n\tu32\tflags;\n\tu16\tvirtual_numa_node;\n\tu16\treserved;\n} __packed;\n\n \nstruct hv_msi_desc {\n\tu8\tvector;\n\tu8\tdelivery_mode;\n\tu16\tvector_count;\n\tu32\treserved;\n\tu64\tcpu_mask;\n} __packed;\n\n \nstruct hv_msi_desc2 {\n\tu8\tvector;\n\tu8\tdelivery_mode;\n\tu16\tvector_count;\n\tu16\tprocessor_count;\n\tu16\tprocessor_array[32];\n} __packed;\n\n \nstruct hv_msi_desc3 {\n\tu32\tvector;\n\tu8\tdelivery_mode;\n\tu8\treserved;\n\tu16\tvector_count;\n\tu16\tprocessor_count;\n\tu16\tprocessor_array[32];\n} __packed;\n\n \nstruct tran_int_desc {\n\tu16\treserved;\n\tu16\tvector_count;\n\tu32\tdata;\n\tu64\taddress;\n} __packed;\n\n \n\nstruct pci_message {\n\tu32 type;\n} __packed;\n\nstruct pci_child_message {\n\tstruct pci_message message_type;\n\tunion win_slot_encoding wslot;\n} __packed;\n\nstruct pci_incoming_message {\n\tstruct vmpacket_descriptor hdr;\n\tstruct pci_message message_type;\n} __packed;\n\nstruct pci_response {\n\tstruct vmpacket_descriptor hdr;\n\ts32 status;\t\t\t \n} __packed;\n\nstruct pci_packet {\n\tvoid (*completion_func)(void *context, struct pci_response *resp,\n\t\t\t\tint resp_packet_size);\n\tvoid *compl_ctxt;\n\n\tstruct pci_message message[];\n};\n\n \n\n \n\nstruct pci_version_request {\n\tstruct pci_message message_type;\n\tu32 protocol_version;\n} __packed;\n\n \n\nstruct pci_bus_d0_entry {\n\tstruct pci_message message_type;\n\tu32 reserved;\n\tu64 mmio_base;\n} __packed;\n\nstruct pci_bus_relations {\n\tstruct pci_incoming_message incoming;\n\tu32 device_count;\n\tstruct pci_function_description func[];\n} __packed;\n\nstruct pci_bus_relations2 {\n\tstruct pci_incoming_message incoming;\n\tu32 device_count;\n\tstruct pci_function_description2 func[];\n} __packed;\n\nstruct pci_q_res_req_response {\n\tstruct vmpacket_descriptor hdr;\n\ts32 status;\t\t\t \n\tu32 probed_bar[PCI_STD_NUM_BARS];\n} __packed;\n\nstruct pci_set_power {\n\tstruct pci_message message_type;\n\tunion win_slot_encoding wslot;\n\tu32 power_state;\t\t \n\tu32 reserved;\n} __packed;\n\nstruct pci_set_power_response {\n\tstruct vmpacket_descriptor hdr;\n\ts32 status;\t\t\t \n\tunion win_slot_encoding wslot;\n\tu32 resultant_state;\t\t \n\tu32 reserved;\n} __packed;\n\nstruct pci_resources_assigned {\n\tstruct pci_message message_type;\n\tunion win_slot_encoding wslot;\n\tu8 memory_range[0x14][6];\t \n\tu32 msi_descriptors;\n\tu32 reserved[4];\n} __packed;\n\nstruct pci_resources_assigned2 {\n\tstruct pci_message message_type;\n\tunion win_slot_encoding wslot;\n\tu8 memory_range[0x14][6];\t \n\tu32 msi_descriptor_count;\n\tu8 reserved[70];\n} __packed;\n\nstruct pci_create_interrupt {\n\tstruct pci_message message_type;\n\tunion win_slot_encoding wslot;\n\tstruct hv_msi_desc int_desc;\n} __packed;\n\nstruct pci_create_int_response {\n\tstruct pci_response response;\n\tu32 reserved;\n\tstruct tran_int_desc int_desc;\n} __packed;\n\nstruct pci_create_interrupt2 {\n\tstruct pci_message message_type;\n\tunion win_slot_encoding wslot;\n\tstruct hv_msi_desc2 int_desc;\n} __packed;\n\nstruct pci_create_interrupt3 {\n\tstruct pci_message message_type;\n\tunion win_slot_encoding wslot;\n\tstruct hv_msi_desc3 int_desc;\n} __packed;\n\nstruct pci_delete_interrupt {\n\tstruct pci_message message_type;\n\tunion win_slot_encoding wslot;\n\tstruct tran_int_desc int_desc;\n} __packed;\n\n \nstruct pci_read_block {\n\tstruct pci_message message_type;\n\tu32 block_id;\n\tunion win_slot_encoding wslot;\n\tu32 bytes_requested;\n} __packed;\n\nstruct pci_read_block_response {\n\tstruct vmpacket_descriptor hdr;\n\tu32 status;\n\tu8 bytes[HV_CONFIG_BLOCK_SIZE_MAX];\n} __packed;\n\n \nstruct pci_write_block {\n\tstruct pci_message message_type;\n\tu32 block_id;\n\tunion win_slot_encoding wslot;\n\tu32 byte_count;\n\tu8 bytes[HV_CONFIG_BLOCK_SIZE_MAX];\n} __packed;\n\nstruct pci_dev_inval_block {\n\tstruct pci_incoming_message incoming;\n\tunion win_slot_encoding wslot;\n\tu64 block_mask;\n} __packed;\n\nstruct pci_dev_incoming {\n\tstruct pci_incoming_message incoming;\n\tunion win_slot_encoding wslot;\n} __packed;\n\nstruct pci_eject_response {\n\tstruct pci_message message_type;\n\tunion win_slot_encoding wslot;\n\tu32 status;\n} __packed;\n\nstatic int pci_ring_size = (4 * PAGE_SIZE);\n\n \n\nenum hv_pcibus_state {\n\thv_pcibus_init = 0,\n\thv_pcibus_probed,\n\thv_pcibus_installed,\n\thv_pcibus_removing,\n\thv_pcibus_maximum\n};\n\nstruct hv_pcibus_device {\n#ifdef CONFIG_X86\n\tstruct pci_sysdata sysdata;\n#elif defined(CONFIG_ARM64)\n\tstruct pci_config_window sysdata;\n#endif\n\tstruct pci_host_bridge *bridge;\n\tstruct fwnode_handle *fwnode;\n\t \n\tenum pci_protocol_version_t protocol_version;\n\n\tstruct mutex state_lock;\n\tenum hv_pcibus_state state;\n\n\tstruct hv_device *hdev;\n\tresource_size_t low_mmio_space;\n\tresource_size_t high_mmio_space;\n\tstruct resource *mem_config;\n\tstruct resource *low_mmio_res;\n\tstruct resource *high_mmio_res;\n\tstruct completion *survey_event;\n\tstruct pci_bus *pci_bus;\n\tspinlock_t config_lock;\t \n\tspinlock_t device_list_lock;\t \n\tvoid __iomem *cfg_addr;\n\n\tstruct list_head children;\n\tstruct list_head dr_list;\n\n\tstruct msi_domain_info msi_info;\n\tstruct irq_domain *irq_domain;\n\n\tstruct workqueue_struct *wq;\n\n\t \n\tint wslot_res_allocated;\n\tbool use_calls;  \n};\n\n \nstruct hv_dr_work {\n\tstruct work_struct wrk;\n\tstruct hv_pcibus_device *bus;\n};\n\nstruct hv_pcidev_description {\n\tu16\tv_id;\t \n\tu16\td_id;\t \n\tu8\trev;\n\tu8\tprog_intf;\n\tu8\tsubclass;\n\tu8\tbase_class;\n\tu32\tsubsystem_id;\n\tunion\twin_slot_encoding win_slot;\n\tu32\tser;\t \n\tu32\tflags;\n\tu16\tvirtual_numa_node;\n};\n\nstruct hv_dr_state {\n\tstruct list_head list_entry;\n\tu32 device_count;\n\tstruct hv_pcidev_description func[];\n};\n\nstruct hv_pci_dev {\n\t \n\tstruct list_head list_entry;\n\trefcount_t refs;\n\tstruct pci_slot *pci_slot;\n\tstruct hv_pcidev_description desc;\n\tbool reported_missing;\n\tstruct hv_pcibus_device *hbus;\n\tstruct work_struct wrk;\n\n\tvoid (*block_invalidate)(void *context, u64 block_mask);\n\tvoid *invalidate_context;\n\n\t \n\tu32 probed_bar[PCI_STD_NUM_BARS];\n};\n\nstruct hv_pci_compl {\n\tstruct completion host_event;\n\ts32 completion_status;\n};\n\nstatic void hv_pci_onchannelcallback(void *context);\n\n#ifdef CONFIG_X86\n#define DELIVERY_MODE\tAPIC_DELIVERY_MODE_FIXED\n#define FLOW_HANDLER\thandle_edge_irq\n#define FLOW_NAME\t\"edge\"\n\nstatic int hv_pci_irqchip_init(void)\n{\n\treturn 0;\n}\n\nstatic struct irq_domain *hv_pci_get_root_domain(void)\n{\n\treturn x86_vector_domain;\n}\n\nstatic unsigned int hv_msi_get_int_vector(struct irq_data *data)\n{\n\tstruct irq_cfg *cfg = irqd_cfg(data);\n\n\treturn cfg->vector;\n}\n\n#define hv_msi_prepare\t\tpci_msi_prepare\n\n \nstatic void hv_arch_irq_unmask(struct irq_data *data)\n{\n\tstruct msi_desc *msi_desc = irq_data_get_msi_desc(data);\n\tstruct hv_retarget_device_interrupt *params;\n\tstruct tran_int_desc *int_desc;\n\tstruct hv_pcibus_device *hbus;\n\tconst struct cpumask *dest;\n\tcpumask_var_t tmp;\n\tstruct pci_bus *pbus;\n\tstruct pci_dev *pdev;\n\tunsigned long flags;\n\tu32 var_size = 0;\n\tint cpu, nr_bank;\n\tu64 res;\n\n\tdest = irq_data_get_effective_affinity_mask(data);\n\tpdev = msi_desc_to_pci_dev(msi_desc);\n\tpbus = pdev->bus;\n\thbus = container_of(pbus->sysdata, struct hv_pcibus_device, sysdata);\n\tint_desc = data->chip_data;\n\tif (!int_desc) {\n\t\tdev_warn(&hbus->hdev->device, \"%s() can not unmask irq %u\\n\",\n\t\t\t __func__, data->irq);\n\t\treturn;\n\t}\n\n\tlocal_irq_save(flags);\n\n\tparams = *this_cpu_ptr(hyperv_pcpu_input_arg);\n\tmemset(params, 0, sizeof(*params));\n\tparams->partition_id = HV_PARTITION_ID_SELF;\n\tparams->int_entry.source = HV_INTERRUPT_SOURCE_MSI;\n\tparams->int_entry.msi_entry.address.as_uint32 = int_desc->address & 0xffffffff;\n\tparams->int_entry.msi_entry.data.as_uint32 = int_desc->data;\n\tparams->device_id = (hbus->hdev->dev_instance.b[5] << 24) |\n\t\t\t   (hbus->hdev->dev_instance.b[4] << 16) |\n\t\t\t   (hbus->hdev->dev_instance.b[7] << 8) |\n\t\t\t   (hbus->hdev->dev_instance.b[6] & 0xf8) |\n\t\t\t   PCI_FUNC(pdev->devfn);\n\tparams->int_target.vector = hv_msi_get_int_vector(data);\n\n\t \n\n\tif (hbus->protocol_version >= PCI_PROTOCOL_VERSION_1_2) {\n\t\t \n\t\tparams->int_target.flags |=\n\t\t\tHV_DEVICE_INTERRUPT_TARGET_PROCESSOR_SET;\n\n\t\tif (!alloc_cpumask_var(&tmp, GFP_ATOMIC)) {\n\t\t\tres = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tcpumask_and(tmp, dest, cpu_online_mask);\n\t\tnr_bank = cpumask_to_vpset(&params->int_target.vp_set, tmp);\n\t\tfree_cpumask_var(tmp);\n\n\t\tif (nr_bank <= 0) {\n\t\t\tres = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tvar_size = 1 + nr_bank;\n\t} else {\n\t\tfor_each_cpu_and(cpu, dest, cpu_online_mask) {\n\t\t\tparams->int_target.vp_mask |=\n\t\t\t\t(1ULL << hv_cpu_number_to_vp_number(cpu));\n\t\t}\n\t}\n\n\tres = hv_do_hypercall(HVCALL_RETARGET_INTERRUPT | (var_size << 17),\n\t\t\t      params, NULL);\n\nout:\n\tlocal_irq_restore(flags);\n\n\t \n\tif (!hv_result_success(res) && hbus->state != hv_pcibus_removing)\n\t\tdev_err(&hbus->hdev->device,\n\t\t\t\"%s() failed: %#llx\", __func__, res);\n}\n#elif defined(CONFIG_ARM64)\n \n#define HV_PCI_MSI_SPI_START\t64\n#define HV_PCI_MSI_SPI_NR\t(1020 - HV_PCI_MSI_SPI_START)\n#define DELIVERY_MODE\t\t0\n#define FLOW_HANDLER\t\tNULL\n#define FLOW_NAME\t\tNULL\n#define hv_msi_prepare\t\tNULL\n\nstruct hv_pci_chip_data {\n\tDECLARE_BITMAP(spi_map, HV_PCI_MSI_SPI_NR);\n\tstruct mutex\tmap_lock;\n};\n\n \nstatic struct irq_domain *hv_msi_gic_irq_domain;\n\n \nstatic struct irq_chip hv_arm64_msi_irq_chip = {\n\t.name = \"MSI\",\n\t.irq_set_affinity = irq_chip_set_affinity_parent,\n\t.irq_eoi = irq_chip_eoi_parent,\n\t.irq_mask = irq_chip_mask_parent,\n\t.irq_unmask = irq_chip_unmask_parent\n};\n\nstatic unsigned int hv_msi_get_int_vector(struct irq_data *irqd)\n{\n\treturn irqd->parent_data->hwirq;\n}\n\n \nstatic void hv_pci_vec_irq_free(struct irq_domain *domain,\n\t\t\t\tunsigned int virq,\n\t\t\t\tunsigned int nr_bm_irqs,\n\t\t\t\tunsigned int nr_dom_irqs)\n{\n\tstruct hv_pci_chip_data *chip_data = domain->host_data;\n\tstruct irq_data *d = irq_domain_get_irq_data(domain, virq);\n\tint first = d->hwirq - HV_PCI_MSI_SPI_START;\n\tint i;\n\n\tmutex_lock(&chip_data->map_lock);\n\tbitmap_release_region(chip_data->spi_map,\n\t\t\t      first,\n\t\t\t      get_count_order(nr_bm_irqs));\n\tmutex_unlock(&chip_data->map_lock);\n\tfor (i = 0; i < nr_dom_irqs; i++) {\n\t\tif (i)\n\t\t\td = irq_domain_get_irq_data(domain, virq + i);\n\t\tirq_domain_reset_irq_data(d);\n\t}\n\n\tirq_domain_free_irqs_parent(domain, virq, nr_dom_irqs);\n}\n\nstatic void hv_pci_vec_irq_domain_free(struct irq_domain *domain,\n\t\t\t\t       unsigned int virq,\n\t\t\t\t       unsigned int nr_irqs)\n{\n\thv_pci_vec_irq_free(domain, virq, nr_irqs, nr_irqs);\n}\n\nstatic int hv_pci_vec_alloc_device_irq(struct irq_domain *domain,\n\t\t\t\t       unsigned int nr_irqs,\n\t\t\t\t       irq_hw_number_t *hwirq)\n{\n\tstruct hv_pci_chip_data *chip_data = domain->host_data;\n\tint index;\n\n\t \n\tmutex_lock(&chip_data->map_lock);\n\tindex = bitmap_find_free_region(chip_data->spi_map,\n\t\t\t\t\tHV_PCI_MSI_SPI_NR,\n\t\t\t\t\tget_count_order(nr_irqs));\n\tmutex_unlock(&chip_data->map_lock);\n\tif (index < 0)\n\t\treturn -ENOSPC;\n\n\t*hwirq = index + HV_PCI_MSI_SPI_START;\n\n\treturn 0;\n}\n\nstatic int hv_pci_vec_irq_gic_domain_alloc(struct irq_domain *domain,\n\t\t\t\t\t   unsigned int virq,\n\t\t\t\t\t   irq_hw_number_t hwirq)\n{\n\tstruct irq_fwspec fwspec;\n\tstruct irq_data *d;\n\tint ret;\n\n\tfwspec.fwnode = domain->parent->fwnode;\n\tfwspec.param_count = 2;\n\tfwspec.param[0] = hwirq;\n\tfwspec.param[1] = IRQ_TYPE_EDGE_RISING;\n\n\tret = irq_domain_alloc_irqs_parent(domain, virq, 1, &fwspec);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\td = irq_domain_get_irq_data(domain->parent, virq);\n\n\treturn d->chip->irq_set_type(d, IRQ_TYPE_EDGE_RISING);\n}\n\nstatic int hv_pci_vec_irq_domain_alloc(struct irq_domain *domain,\n\t\t\t\t       unsigned int virq, unsigned int nr_irqs,\n\t\t\t\t       void *args)\n{\n\tirq_hw_number_t hwirq;\n\tunsigned int i;\n\tint ret;\n\n\tret = hv_pci_vec_alloc_device_irq(domain, nr_irqs, &hwirq);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < nr_irqs; i++) {\n\t\tret = hv_pci_vec_irq_gic_domain_alloc(domain, virq + i,\n\t\t\t\t\t\t      hwirq + i);\n\t\tif (ret) {\n\t\t\thv_pci_vec_irq_free(domain, virq, nr_irqs, i);\n\t\t\treturn ret;\n\t\t}\n\n\t\tirq_domain_set_hwirq_and_chip(domain, virq + i,\n\t\t\t\t\t      hwirq + i,\n\t\t\t\t\t      &hv_arm64_msi_irq_chip,\n\t\t\t\t\t      domain->host_data);\n\t\tpr_debug(\"pID:%d vID:%u\\n\", (int)(hwirq + i), virq + i);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int hv_pci_vec_irq_domain_activate(struct irq_domain *domain,\n\t\t\t\t\t  struct irq_data *irqd, bool reserve)\n{\n\tint cpu = cpumask_first(cpu_present_mask);\n\n\tirq_data_update_effective_affinity(irqd, cpumask_of(cpu));\n\n\treturn 0;\n}\n\nstatic const struct irq_domain_ops hv_pci_domain_ops = {\n\t.alloc\t= hv_pci_vec_irq_domain_alloc,\n\t.free\t= hv_pci_vec_irq_domain_free,\n\t.activate = hv_pci_vec_irq_domain_activate,\n};\n\nstatic int hv_pci_irqchip_init(void)\n{\n\tstatic struct hv_pci_chip_data *chip_data;\n\tstruct fwnode_handle *fn = NULL;\n\tint ret = -ENOMEM;\n\n\tchip_data = kzalloc(sizeof(*chip_data), GFP_KERNEL);\n\tif (!chip_data)\n\t\treturn ret;\n\n\tmutex_init(&chip_data->map_lock);\n\tfn = irq_domain_alloc_named_fwnode(\"hv_vpci_arm64\");\n\tif (!fn)\n\t\tgoto free_chip;\n\n\t \n\thv_msi_gic_irq_domain = acpi_irq_create_hierarchy(0, HV_PCI_MSI_SPI_NR,\n\t\t\t\t\t\t\t  fn, &hv_pci_domain_ops,\n\t\t\t\t\t\t\t  chip_data);\n\n\tif (!hv_msi_gic_irq_domain) {\n\t\tpr_err(\"Failed to create Hyper-V arm64 vPCI MSI IRQ domain\\n\");\n\t\tgoto free_chip;\n\t}\n\n\treturn 0;\n\nfree_chip:\n\tkfree(chip_data);\n\tif (fn)\n\t\tirq_domain_free_fwnode(fn);\n\n\treturn ret;\n}\n\nstatic struct irq_domain *hv_pci_get_root_domain(void)\n{\n\treturn hv_msi_gic_irq_domain;\n}\n\n \nstatic void hv_arch_irq_unmask(struct irq_data *data) { }\n#endif  \n\n \nstatic void hv_pci_generic_compl(void *context, struct pci_response *resp,\n\t\t\t\t int resp_packet_size)\n{\n\tstruct hv_pci_compl *comp_pkt = context;\n\n\tcomp_pkt->completion_status = resp->status;\n\tcomplete(&comp_pkt->host_event);\n}\n\nstatic struct hv_pci_dev *get_pcichild_wslot(struct hv_pcibus_device *hbus,\n\t\t\t\t\t\tu32 wslot);\n\nstatic void get_pcichild(struct hv_pci_dev *hpdev)\n{\n\trefcount_inc(&hpdev->refs);\n}\n\nstatic void put_pcichild(struct hv_pci_dev *hpdev)\n{\n\tif (refcount_dec_and_test(&hpdev->refs))\n\t\tkfree(hpdev);\n}\n\n \nstatic int wait_for_response(struct hv_device *hdev,\n\t\t\t     struct completion *comp)\n{\n\twhile (true) {\n\t\tif (hdev->channel->rescind) {\n\t\t\tdev_warn_once(&hdev->device, \"The device is gone.\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tif (wait_for_completion_timeout(comp, HZ / 10))\n\t\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n \nstatic u32 devfn_to_wslot(int devfn)\n{\n\tunion win_slot_encoding wslot;\n\n\twslot.slot = 0;\n\twslot.bits.dev = PCI_SLOT(devfn);\n\twslot.bits.func = PCI_FUNC(devfn);\n\n\treturn wslot.slot;\n}\n\n \nstatic int wslot_to_devfn(u32 wslot)\n{\n\tunion win_slot_encoding slot_no;\n\n\tslot_no.slot = wslot;\n\treturn PCI_DEVFN(slot_no.bits.dev, slot_no.bits.func);\n}\n\nstatic void hv_pci_read_mmio(struct device *dev, phys_addr_t gpa, int size, u32 *val)\n{\n\tstruct hv_mmio_read_input *in;\n\tstruct hv_mmio_read_output *out;\n\tu64 ret;\n\n\t \n\tin = *this_cpu_ptr(hyperv_pcpu_input_arg);\n\tout = *this_cpu_ptr(hyperv_pcpu_input_arg) + sizeof(*in);\n\tin->gpa = gpa;\n\tin->size = size;\n\n\tret = hv_do_hypercall(HVCALL_MMIO_READ, in, out);\n\tif (hv_result_success(ret)) {\n\t\tswitch (size) {\n\t\tcase 1:\n\t\t\t*val = *(u8 *)(out->data);\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\t*val = *(u16 *)(out->data);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t*val = *(u32 *)(out->data);\n\t\t\tbreak;\n\t\t}\n\t} else\n\t\tdev_err(dev, \"MMIO read hypercall error %llx addr %llx size %d\\n\",\n\t\t\t\tret, gpa, size);\n}\n\nstatic void hv_pci_write_mmio(struct device *dev, phys_addr_t gpa, int size, u32 val)\n{\n\tstruct hv_mmio_write_input *in;\n\tu64 ret;\n\n\t \n\tin = *this_cpu_ptr(hyperv_pcpu_input_arg);\n\tin->gpa = gpa;\n\tin->size = size;\n\tswitch (size) {\n\tcase 1:\n\t\t*(u8 *)(in->data) = val;\n\t\tbreak;\n\tcase 2:\n\t\t*(u16 *)(in->data) = val;\n\t\tbreak;\n\tdefault:\n\t\t*(u32 *)(in->data) = val;\n\t\tbreak;\n\t}\n\n\tret = hv_do_hypercall(HVCALL_MMIO_WRITE, in, NULL);\n\tif (!hv_result_success(ret))\n\t\tdev_err(dev, \"MMIO write hypercall error %llx addr %llx size %d\\n\",\n\t\t\t\tret, gpa, size);\n}\n\n \n\n \nstatic void _hv_pcifront_read_config(struct hv_pci_dev *hpdev, int where,\n\t\t\t\t     int size, u32 *val)\n{\n\tstruct hv_pcibus_device *hbus = hpdev->hbus;\n\tstruct device *dev = &hbus->hdev->device;\n\tint offset = where + CFG_PAGE_OFFSET;\n\tunsigned long flags;\n\n\t \n\tif (where + size <= PCI_COMMAND) {\n\t\tmemcpy(val, ((u8 *)&hpdev->desc.v_id) + where, size);\n\t} else if (where >= PCI_CLASS_REVISION && where + size <=\n\t\t   PCI_CACHE_LINE_SIZE) {\n\t\tmemcpy(val, ((u8 *)&hpdev->desc.rev) + where -\n\t\t       PCI_CLASS_REVISION, size);\n\t} else if (where >= PCI_SUBSYSTEM_VENDOR_ID && where + size <=\n\t\t   PCI_ROM_ADDRESS) {\n\t\tmemcpy(val, (u8 *)&hpdev->desc.subsystem_id + where -\n\t\t       PCI_SUBSYSTEM_VENDOR_ID, size);\n\t} else if (where >= PCI_ROM_ADDRESS && where + size <=\n\t\t   PCI_CAPABILITY_LIST) {\n\t\t \n\t\t*val = 0;\n\t} else if (where >= PCI_INTERRUPT_LINE && where + size <=\n\t\t   PCI_INTERRUPT_PIN) {\n\t\t \n\t\t*val = 0;\n\t} else if (where + size <= CFG_PAGE_SIZE) {\n\n\t\tspin_lock_irqsave(&hbus->config_lock, flags);\n\t\tif (hbus->use_calls) {\n\t\t\tphys_addr_t addr = hbus->mem_config->start + offset;\n\n\t\t\thv_pci_write_mmio(dev, hbus->mem_config->start, 4,\n\t\t\t\t\t\thpdev->desc.win_slot.slot);\n\t\t\thv_pci_read_mmio(dev, addr, size, val);\n\t\t} else {\n\t\t\tvoid __iomem *addr = hbus->cfg_addr + offset;\n\n\t\t\t \n\t\t\twritel(hpdev->desc.win_slot.slot, hbus->cfg_addr);\n\t\t\t \n\t\t\tmb();\n\t\t\t \n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\t*val = readb(addr);\n\t\t\t\tbreak;\n\t\t\tcase 2:\n\t\t\t\t*val = readw(addr);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t*val = readl(addr);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t \n\t\t\tmb();\n\t\t}\n\t\tspin_unlock_irqrestore(&hbus->config_lock, flags);\n\t} else {\n\t\tdev_err(dev, \"Attempt to read beyond a function's config space.\\n\");\n\t}\n}\n\nstatic u16 hv_pcifront_get_vendor_id(struct hv_pci_dev *hpdev)\n{\n\tstruct hv_pcibus_device *hbus = hpdev->hbus;\n\tstruct device *dev = &hbus->hdev->device;\n\tu32 val;\n\tu16 ret;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&hbus->config_lock, flags);\n\n\tif (hbus->use_calls) {\n\t\tphys_addr_t addr = hbus->mem_config->start +\n\t\t\t\t\t CFG_PAGE_OFFSET + PCI_VENDOR_ID;\n\n\t\thv_pci_write_mmio(dev, hbus->mem_config->start, 4,\n\t\t\t\t\thpdev->desc.win_slot.slot);\n\t\thv_pci_read_mmio(dev, addr, 2, &val);\n\t\tret = val;   \n\t} else {\n\t\tvoid __iomem *addr = hbus->cfg_addr + CFG_PAGE_OFFSET +\n\t\t\t\t\t     PCI_VENDOR_ID;\n\t\t \n\t\twritel(hpdev->desc.win_slot.slot, hbus->cfg_addr);\n\t\t \n\t\tmb();\n\t\t \n\t\tret = readw(addr);\n\t\t \n\t}\n\n\tspin_unlock_irqrestore(&hbus->config_lock, flags);\n\n\treturn ret;\n}\n\n \nstatic void _hv_pcifront_write_config(struct hv_pci_dev *hpdev, int where,\n\t\t\t\t      int size, u32 val)\n{\n\tstruct hv_pcibus_device *hbus = hpdev->hbus;\n\tstruct device *dev = &hbus->hdev->device;\n\tint offset = where + CFG_PAGE_OFFSET;\n\tunsigned long flags;\n\n\tif (where >= PCI_SUBSYSTEM_VENDOR_ID &&\n\t    where + size <= PCI_CAPABILITY_LIST) {\n\t\t \n\t} else if (where >= PCI_COMMAND && where + size <= CFG_PAGE_SIZE) {\n\t\tspin_lock_irqsave(&hbus->config_lock, flags);\n\n\t\tif (hbus->use_calls) {\n\t\t\tphys_addr_t addr = hbus->mem_config->start + offset;\n\n\t\t\thv_pci_write_mmio(dev, hbus->mem_config->start, 4,\n\t\t\t\t\t\thpdev->desc.win_slot.slot);\n\t\t\thv_pci_write_mmio(dev, addr, size, val);\n\t\t} else {\n\t\t\tvoid __iomem *addr = hbus->cfg_addr + offset;\n\n\t\t\t \n\t\t\twritel(hpdev->desc.win_slot.slot, hbus->cfg_addr);\n\t\t\t \n\t\t\twmb();\n\t\t\t \n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\twriteb(val, addr);\n\t\t\t\tbreak;\n\t\t\tcase 2:\n\t\t\t\twritew(val, addr);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\twritel(val, addr);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t \n\t\t\tmb();\n\t\t}\n\t\tspin_unlock_irqrestore(&hbus->config_lock, flags);\n\t} else {\n\t\tdev_err(dev, \"Attempt to write beyond a function's config space.\\n\");\n\t}\n}\n\n \nstatic int hv_pcifront_read_config(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\t   int where, int size, u32 *val)\n{\n\tstruct hv_pcibus_device *hbus =\n\t\tcontainer_of(bus->sysdata, struct hv_pcibus_device, sysdata);\n\tstruct hv_pci_dev *hpdev;\n\n\thpdev = get_pcichild_wslot(hbus, devfn_to_wslot(devfn));\n\tif (!hpdev)\n\t\treturn PCIBIOS_DEVICE_NOT_FOUND;\n\n\t_hv_pcifront_read_config(hpdev, where, size, val);\n\n\tput_pcichild(hpdev);\n\treturn PCIBIOS_SUCCESSFUL;\n}\n\n \nstatic int hv_pcifront_write_config(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\t    int where, int size, u32 val)\n{\n\tstruct hv_pcibus_device *hbus =\n\t    container_of(bus->sysdata, struct hv_pcibus_device, sysdata);\n\tstruct hv_pci_dev *hpdev;\n\n\thpdev = get_pcichild_wslot(hbus, devfn_to_wslot(devfn));\n\tif (!hpdev)\n\t\treturn PCIBIOS_DEVICE_NOT_FOUND;\n\n\t_hv_pcifront_write_config(hpdev, where, size, val);\n\n\tput_pcichild(hpdev);\n\treturn PCIBIOS_SUCCESSFUL;\n}\n\n \nstatic struct pci_ops hv_pcifront_ops = {\n\t.read  = hv_pcifront_read_config,\n\t.write = hv_pcifront_write_config,\n};\n\n \n\nstruct hv_read_config_compl {\n\tstruct hv_pci_compl comp_pkt;\n\tvoid *buf;\n\tunsigned int len;\n\tunsigned int bytes_returned;\n};\n\n \nstatic void hv_pci_read_config_compl(void *context, struct pci_response *resp,\n\t\t\t\t     int resp_packet_size)\n{\n\tstruct hv_read_config_compl *comp = context;\n\tstruct pci_read_block_response *read_resp =\n\t\t(struct pci_read_block_response *)resp;\n\tunsigned int data_len, hdr_len;\n\n\thdr_len = offsetof(struct pci_read_block_response, bytes);\n\tif (resp_packet_size < hdr_len) {\n\t\tcomp->comp_pkt.completion_status = -1;\n\t\tgoto out;\n\t}\n\n\tdata_len = resp_packet_size - hdr_len;\n\tif (data_len > 0 && read_resp->status == 0) {\n\t\tcomp->bytes_returned = min(comp->len, data_len);\n\t\tmemcpy(comp->buf, read_resp->bytes, comp->bytes_returned);\n\t} else {\n\t\tcomp->bytes_returned = 0;\n\t}\n\n\tcomp->comp_pkt.completion_status = read_resp->status;\nout:\n\tcomplete(&comp->comp_pkt.host_event);\n}\n\n \nstatic int hv_read_config_block(struct pci_dev *pdev, void *buf,\n\t\t\t\tunsigned int len, unsigned int block_id,\n\t\t\t\tunsigned int *bytes_returned)\n{\n\tstruct hv_pcibus_device *hbus =\n\t\tcontainer_of(pdev->bus->sysdata, struct hv_pcibus_device,\n\t\t\t     sysdata);\n\tstruct {\n\t\tstruct pci_packet pkt;\n\t\tchar buf[sizeof(struct pci_read_block)];\n\t} pkt;\n\tstruct hv_read_config_compl comp_pkt;\n\tstruct pci_read_block *read_blk;\n\tint ret;\n\n\tif (len == 0 || len > HV_CONFIG_BLOCK_SIZE_MAX)\n\t\treturn -EINVAL;\n\n\tinit_completion(&comp_pkt.comp_pkt.host_event);\n\tcomp_pkt.buf = buf;\n\tcomp_pkt.len = len;\n\n\tmemset(&pkt, 0, sizeof(pkt));\n\tpkt.pkt.completion_func = hv_pci_read_config_compl;\n\tpkt.pkt.compl_ctxt = &comp_pkt;\n\tread_blk = (struct pci_read_block *)&pkt.pkt.message;\n\tread_blk->message_type.type = PCI_READ_BLOCK;\n\tread_blk->wslot.slot = devfn_to_wslot(pdev->devfn);\n\tread_blk->block_id = block_id;\n\tread_blk->bytes_requested = len;\n\n\tret = vmbus_sendpacket(hbus->hdev->channel, read_blk,\n\t\t\t       sizeof(*read_blk), (unsigned long)&pkt.pkt,\n\t\t\t       VM_PKT_DATA_INBAND,\n\t\t\t       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);\n\tif (ret)\n\t\treturn ret;\n\n\tret = wait_for_response(hbus->hdev, &comp_pkt.comp_pkt.host_event);\n\tif (ret)\n\t\treturn ret;\n\n\tif (comp_pkt.comp_pkt.completion_status != 0 ||\n\t    comp_pkt.bytes_returned == 0) {\n\t\tdev_err(&hbus->hdev->device,\n\t\t\t\"Read Config Block failed: 0x%x, bytes_returned=%d\\n\",\n\t\t\tcomp_pkt.comp_pkt.completion_status,\n\t\t\tcomp_pkt.bytes_returned);\n\t\treturn -EIO;\n\t}\n\n\t*bytes_returned = comp_pkt.bytes_returned;\n\treturn 0;\n}\n\n \nstatic void hv_pci_write_config_compl(void *context, struct pci_response *resp,\n\t\t\t\t      int resp_packet_size)\n{\n\tstruct hv_pci_compl *comp_pkt = context;\n\n\tcomp_pkt->completion_status = resp->status;\n\tcomplete(&comp_pkt->host_event);\n}\n\n \nstatic int hv_write_config_block(struct pci_dev *pdev, void *buf,\n\t\t\t\tunsigned int len, unsigned int block_id)\n{\n\tstruct hv_pcibus_device *hbus =\n\t\tcontainer_of(pdev->bus->sysdata, struct hv_pcibus_device,\n\t\t\t     sysdata);\n\tstruct {\n\t\tstruct pci_packet pkt;\n\t\tchar buf[sizeof(struct pci_write_block)];\n\t\tu32 reserved;\n\t} pkt;\n\tstruct hv_pci_compl comp_pkt;\n\tstruct pci_write_block *write_blk;\n\tu32 pkt_size;\n\tint ret;\n\n\tif (len == 0 || len > HV_CONFIG_BLOCK_SIZE_MAX)\n\t\treturn -EINVAL;\n\n\tinit_completion(&comp_pkt.host_event);\n\n\tmemset(&pkt, 0, sizeof(pkt));\n\tpkt.pkt.completion_func = hv_pci_write_config_compl;\n\tpkt.pkt.compl_ctxt = &comp_pkt;\n\twrite_blk = (struct pci_write_block *)&pkt.pkt.message;\n\twrite_blk->message_type.type = PCI_WRITE_BLOCK;\n\twrite_blk->wslot.slot = devfn_to_wslot(pdev->devfn);\n\twrite_blk->block_id = block_id;\n\twrite_blk->byte_count = len;\n\tmemcpy(write_blk->bytes, buf, len);\n\tpkt_size = offsetof(struct pci_write_block, bytes) + len;\n\t \n\tpkt_size += sizeof(pkt.reserved);\n\n\tret = vmbus_sendpacket(hbus->hdev->channel, write_blk, pkt_size,\n\t\t\t       (unsigned long)&pkt.pkt, VM_PKT_DATA_INBAND,\n\t\t\t       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);\n\tif (ret)\n\t\treturn ret;\n\n\tret = wait_for_response(hbus->hdev, &comp_pkt.host_event);\n\tif (ret)\n\t\treturn ret;\n\n\tif (comp_pkt.completion_status != 0) {\n\t\tdev_err(&hbus->hdev->device,\n\t\t\t\"Write Config Block failed: 0x%x\\n\",\n\t\t\tcomp_pkt.completion_status);\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int hv_register_block_invalidate(struct pci_dev *pdev, void *context,\n\t\t\t\t\tvoid (*block_invalidate)(void *context,\n\t\t\t\t\t\t\t\t u64 block_mask))\n{\n\tstruct hv_pcibus_device *hbus =\n\t\tcontainer_of(pdev->bus->sysdata, struct hv_pcibus_device,\n\t\t\t     sysdata);\n\tstruct hv_pci_dev *hpdev;\n\n\thpdev = get_pcichild_wslot(hbus, devfn_to_wslot(pdev->devfn));\n\tif (!hpdev)\n\t\treturn -ENODEV;\n\n\thpdev->block_invalidate = block_invalidate;\n\thpdev->invalidate_context = context;\n\n\tput_pcichild(hpdev);\n\treturn 0;\n\n}\n\n \nstatic void hv_int_desc_free(struct hv_pci_dev *hpdev,\n\t\t\t     struct tran_int_desc *int_desc)\n{\n\tstruct pci_delete_interrupt *int_pkt;\n\tstruct {\n\t\tstruct pci_packet pkt;\n\t\tu8 buffer[sizeof(struct pci_delete_interrupt)];\n\t} ctxt;\n\n\tif (!int_desc->vector_count) {\n\t\tkfree(int_desc);\n\t\treturn;\n\t}\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tint_pkt = (struct pci_delete_interrupt *)&ctxt.pkt.message;\n\tint_pkt->message_type.type =\n\t\tPCI_DELETE_INTERRUPT_MESSAGE;\n\tint_pkt->wslot.slot = hpdev->desc.win_slot.slot;\n\tint_pkt->int_desc = *int_desc;\n\tvmbus_sendpacket(hpdev->hbus->hdev->channel, int_pkt, sizeof(*int_pkt),\n\t\t\t 0, VM_PKT_DATA_INBAND, 0);\n\tkfree(int_desc);\n}\n\n \nstatic void hv_msi_free(struct irq_domain *domain, struct msi_domain_info *info,\n\t\t\tunsigned int irq)\n{\n\tstruct hv_pcibus_device *hbus;\n\tstruct hv_pci_dev *hpdev;\n\tstruct pci_dev *pdev;\n\tstruct tran_int_desc *int_desc;\n\tstruct irq_data *irq_data = irq_domain_get_irq_data(domain, irq);\n\tstruct msi_desc *msi = irq_data_get_msi_desc(irq_data);\n\n\tpdev = msi_desc_to_pci_dev(msi);\n\thbus = info->data;\n\tint_desc = irq_data_get_irq_chip_data(irq_data);\n\tif (!int_desc)\n\t\treturn;\n\n\tirq_data->chip_data = NULL;\n\thpdev = get_pcichild_wslot(hbus, devfn_to_wslot(pdev->devfn));\n\tif (!hpdev) {\n\t\tkfree(int_desc);\n\t\treturn;\n\t}\n\n\thv_int_desc_free(hpdev, int_desc);\n\tput_pcichild(hpdev);\n}\n\nstatic void hv_irq_mask(struct irq_data *data)\n{\n\tpci_msi_mask_irq(data);\n\tif (data->parent_data->chip->irq_mask)\n\t\tirq_chip_mask_parent(data);\n}\n\nstatic void hv_irq_unmask(struct irq_data *data)\n{\n\thv_arch_irq_unmask(data);\n\n\tif (data->parent_data->chip->irq_unmask)\n\t\tirq_chip_unmask_parent(data);\n\tpci_msi_unmask_irq(data);\n}\n\nstruct compose_comp_ctxt {\n\tstruct hv_pci_compl comp_pkt;\n\tstruct tran_int_desc int_desc;\n};\n\nstatic void hv_pci_compose_compl(void *context, struct pci_response *resp,\n\t\t\t\t int resp_packet_size)\n{\n\tstruct compose_comp_ctxt *comp_pkt = context;\n\tstruct pci_create_int_response *int_resp =\n\t\t(struct pci_create_int_response *)resp;\n\n\tif (resp_packet_size < sizeof(*int_resp)) {\n\t\tcomp_pkt->comp_pkt.completion_status = -1;\n\t\tgoto out;\n\t}\n\tcomp_pkt->comp_pkt.completion_status = resp->status;\n\tcomp_pkt->int_desc = int_resp->int_desc;\nout:\n\tcomplete(&comp_pkt->comp_pkt.host_event);\n}\n\nstatic u32 hv_compose_msi_req_v1(\n\tstruct pci_create_interrupt *int_pkt,\n\tu32 slot, u8 vector, u16 vector_count)\n{\n\tint_pkt->message_type.type = PCI_CREATE_INTERRUPT_MESSAGE;\n\tint_pkt->wslot.slot = slot;\n\tint_pkt->int_desc.vector = vector;\n\tint_pkt->int_desc.vector_count = vector_count;\n\tint_pkt->int_desc.delivery_mode = DELIVERY_MODE;\n\n\t \n\tint_pkt->int_desc.cpu_mask = CPU_AFFINITY_ALL;\n\n\treturn sizeof(*int_pkt);\n}\n\n \n\n \nstatic int hv_compose_msi_req_get_cpu(const struct cpumask *affinity)\n{\n\treturn cpumask_first_and(affinity, cpu_online_mask);\n}\n\n \nstatic int hv_compose_multi_msi_req_get_cpu(void)\n{\n\tstatic DEFINE_SPINLOCK(multi_msi_cpu_lock);\n\n\t \n\tstatic int cpu_next = -1;\n\n\tunsigned long flags;\n\tint cpu;\n\n\tspin_lock_irqsave(&multi_msi_cpu_lock, flags);\n\n\tcpu_next = cpumask_next_wrap(cpu_next, cpu_online_mask, nr_cpu_ids,\n\t\t\t\t     false);\n\tcpu = cpu_next;\n\n\tspin_unlock_irqrestore(&multi_msi_cpu_lock, flags);\n\n\treturn cpu;\n}\n\nstatic u32 hv_compose_msi_req_v2(\n\tstruct pci_create_interrupt2 *int_pkt, int cpu,\n\tu32 slot, u8 vector, u16 vector_count)\n{\n\tint_pkt->message_type.type = PCI_CREATE_INTERRUPT_MESSAGE2;\n\tint_pkt->wslot.slot = slot;\n\tint_pkt->int_desc.vector = vector;\n\tint_pkt->int_desc.vector_count = vector_count;\n\tint_pkt->int_desc.delivery_mode = DELIVERY_MODE;\n\tint_pkt->int_desc.processor_array[0] =\n\t\thv_cpu_number_to_vp_number(cpu);\n\tint_pkt->int_desc.processor_count = 1;\n\n\treturn sizeof(*int_pkt);\n}\n\nstatic u32 hv_compose_msi_req_v3(\n\tstruct pci_create_interrupt3 *int_pkt, int cpu,\n\tu32 slot, u32 vector, u16 vector_count)\n{\n\tint_pkt->message_type.type = PCI_CREATE_INTERRUPT_MESSAGE3;\n\tint_pkt->wslot.slot = slot;\n\tint_pkt->int_desc.vector = vector;\n\tint_pkt->int_desc.reserved = 0;\n\tint_pkt->int_desc.vector_count = vector_count;\n\tint_pkt->int_desc.delivery_mode = DELIVERY_MODE;\n\tint_pkt->int_desc.processor_array[0] =\n\t\thv_cpu_number_to_vp_number(cpu);\n\tint_pkt->int_desc.processor_count = 1;\n\n\treturn sizeof(*int_pkt);\n}\n\n \nstatic void hv_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)\n{\n\tstruct hv_pcibus_device *hbus;\n\tstruct vmbus_channel *channel;\n\tstruct hv_pci_dev *hpdev;\n\tstruct pci_bus *pbus;\n\tstruct pci_dev *pdev;\n\tconst struct cpumask *dest;\n\tstruct compose_comp_ctxt comp;\n\tstruct tran_int_desc *int_desc;\n\tstruct msi_desc *msi_desc;\n\t \n\tu16 vector_count;\n\tu32 vector;\n\tstruct {\n\t\tstruct pci_packet pci_pkt;\n\t\tunion {\n\t\t\tstruct pci_create_interrupt v1;\n\t\t\tstruct pci_create_interrupt2 v2;\n\t\t\tstruct pci_create_interrupt3 v3;\n\t\t} int_pkts;\n\t} __packed ctxt;\n\tbool multi_msi;\n\tu64 trans_id;\n\tu32 size;\n\tint ret;\n\tint cpu;\n\n\tmsi_desc  = irq_data_get_msi_desc(data);\n\tmulti_msi = !msi_desc->pci.msi_attrib.is_msix &&\n\t\t    msi_desc->nvec_used > 1;\n\n\t \n\tif (data->chip_data && multi_msi) {\n\t\tint_desc = data->chip_data;\n\t\tmsg->address_hi = int_desc->address >> 32;\n\t\tmsg->address_lo = int_desc->address & 0xffffffff;\n\t\tmsg->data = int_desc->data;\n\t\treturn;\n\t}\n\n\tpdev = msi_desc_to_pci_dev(msi_desc);\n\tdest = irq_data_get_effective_affinity_mask(data);\n\tpbus = pdev->bus;\n\thbus = container_of(pbus->sysdata, struct hv_pcibus_device, sysdata);\n\tchannel = hbus->hdev->channel;\n\thpdev = get_pcichild_wslot(hbus, devfn_to_wslot(pdev->devfn));\n\tif (!hpdev)\n\t\tgoto return_null_message;\n\n\t \n\tif (data->chip_data && !multi_msi) {\n\t\tint_desc = data->chip_data;\n\t\tdata->chip_data = NULL;\n\t\thv_int_desc_free(hpdev, int_desc);\n\t}\n\n\tint_desc = kzalloc(sizeof(*int_desc), GFP_ATOMIC);\n\tif (!int_desc)\n\t\tgoto drop_reference;\n\n\tif (multi_msi) {\n\t\t \n\t\tif (msi_desc->irq != data->irq) {\n\t\t\tdata->chip_data = int_desc;\n\t\t\tint_desc->address = msi_desc->msg.address_lo |\n\t\t\t\t\t    (u64)msi_desc->msg.address_hi << 32;\n\t\t\tint_desc->data = msi_desc->msg.data +\n\t\t\t\t\t (data->irq - msi_desc->irq);\n\t\t\tmsg->address_hi = msi_desc->msg.address_hi;\n\t\t\tmsg->address_lo = msi_desc->msg.address_lo;\n\t\t\tmsg->data = int_desc->data;\n\t\t\tput_pcichild(hpdev);\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tvector = 32;\n\t\tvector_count = msi_desc->nvec_used;\n\t\tcpu = hv_compose_multi_msi_req_get_cpu();\n\t} else {\n\t\tvector = hv_msi_get_int_vector(data);\n\t\tvector_count = 1;\n\t\tcpu = hv_compose_msi_req_get_cpu(dest);\n\t}\n\n\t \n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tinit_completion(&comp.comp_pkt.host_event);\n\tctxt.pci_pkt.completion_func = hv_pci_compose_compl;\n\tctxt.pci_pkt.compl_ctxt = &comp;\n\n\tswitch (hbus->protocol_version) {\n\tcase PCI_PROTOCOL_VERSION_1_1:\n\t\tsize = hv_compose_msi_req_v1(&ctxt.int_pkts.v1,\n\t\t\t\t\thpdev->desc.win_slot.slot,\n\t\t\t\t\t(u8)vector,\n\t\t\t\t\tvector_count);\n\t\tbreak;\n\n\tcase PCI_PROTOCOL_VERSION_1_2:\n\tcase PCI_PROTOCOL_VERSION_1_3:\n\t\tsize = hv_compose_msi_req_v2(&ctxt.int_pkts.v2,\n\t\t\t\t\tcpu,\n\t\t\t\t\thpdev->desc.win_slot.slot,\n\t\t\t\t\t(u8)vector,\n\t\t\t\t\tvector_count);\n\t\tbreak;\n\n\tcase PCI_PROTOCOL_VERSION_1_4:\n\t\tsize = hv_compose_msi_req_v3(&ctxt.int_pkts.v3,\n\t\t\t\t\tcpu,\n\t\t\t\t\thpdev->desc.win_slot.slot,\n\t\t\t\t\tvector,\n\t\t\t\t\tvector_count);\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\tdev_err(&hbus->hdev->device,\n\t\t\t\"Unexpected vPCI protocol, update driver.\");\n\t\tgoto free_int_desc;\n\t}\n\n\tret = vmbus_sendpacket_getid(hpdev->hbus->hdev->channel, &ctxt.int_pkts,\n\t\t\t\t     size, (unsigned long)&ctxt.pci_pkt,\n\t\t\t\t     &trans_id, VM_PKT_DATA_INBAND,\n\t\t\t\t     VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);\n\tif (ret) {\n\t\tdev_err(&hbus->hdev->device,\n\t\t\t\"Sending request for interrupt failed: 0x%x\",\n\t\t\tcomp.comp_pkt.completion_status);\n\t\tgoto free_int_desc;\n\t}\n\n\t \n\ttasklet_disable_in_atomic(&channel->callback_event);\n\n\t \n\twhile (!try_wait_for_completion(&comp.comp_pkt.host_event)) {\n\t\tunsigned long flags;\n\n\t\t \n\t\tif (hv_pcifront_get_vendor_id(hpdev) == 0xFFFF) {\n\t\t\tdev_err_once(&hbus->hdev->device,\n\t\t\t\t     \"the device has gone\\n\");\n\t\t\tgoto enable_tasklet;\n\t\t}\n\n\t\t \n\t\tspin_lock_irqsave(&channel->sched_lock, flags);\n\t\tif (unlikely(channel->onchannel_callback == NULL)) {\n\t\t\tspin_unlock_irqrestore(&channel->sched_lock, flags);\n\t\t\tgoto enable_tasklet;\n\t\t}\n\t\thv_pci_onchannelcallback(hbus);\n\t\tspin_unlock_irqrestore(&channel->sched_lock, flags);\n\n\t\tudelay(100);\n\t}\n\n\ttasklet_enable(&channel->callback_event);\n\n\tif (comp.comp_pkt.completion_status < 0) {\n\t\tdev_err(&hbus->hdev->device,\n\t\t\t\"Request for interrupt failed: 0x%x\",\n\t\t\tcomp.comp_pkt.completion_status);\n\t\tgoto free_int_desc;\n\t}\n\n\t \n\t*int_desc = comp.int_desc;\n\tdata->chip_data = int_desc;\n\n\t \n\tmsg->address_hi = comp.int_desc.address >> 32;\n\tmsg->address_lo = comp.int_desc.address & 0xffffffff;\n\tmsg->data = comp.int_desc.data;\n\n\tput_pcichild(hpdev);\n\treturn;\n\nenable_tasklet:\n\ttasklet_enable(&channel->callback_event);\n\t \n\tvmbus_request_addr_match(channel, trans_id, (unsigned long)&ctxt.pci_pkt);\nfree_int_desc:\n\tkfree(int_desc);\ndrop_reference:\n\tput_pcichild(hpdev);\nreturn_null_message:\n\tmsg->address_hi = 0;\n\tmsg->address_lo = 0;\n\tmsg->data = 0;\n}\n\n \nstatic struct irq_chip hv_msi_irq_chip = {\n\t.name\t\t\t= \"Hyper-V PCIe MSI\",\n\t.irq_compose_msi_msg\t= hv_compose_msi_msg,\n\t.irq_set_affinity\t= irq_chip_set_affinity_parent,\n#ifdef CONFIG_X86\n\t.irq_ack\t\t= irq_chip_ack_parent,\n#elif defined(CONFIG_ARM64)\n\t.irq_eoi\t\t= irq_chip_eoi_parent,\n#endif\n\t.irq_mask\t\t= hv_irq_mask,\n\t.irq_unmask\t\t= hv_irq_unmask,\n};\n\nstatic struct msi_domain_ops hv_msi_ops = {\n\t.msi_prepare\t= hv_msi_prepare,\n\t.msi_free\t= hv_msi_free,\n};\n\n \nstatic int hv_pcie_init_irq_domain(struct hv_pcibus_device *hbus)\n{\n\thbus->msi_info.chip = &hv_msi_irq_chip;\n\thbus->msi_info.ops = &hv_msi_ops;\n\thbus->msi_info.flags = (MSI_FLAG_USE_DEF_DOM_OPS |\n\t\tMSI_FLAG_USE_DEF_CHIP_OPS | MSI_FLAG_MULTI_PCI_MSI |\n\t\tMSI_FLAG_PCI_MSIX);\n\thbus->msi_info.handler = FLOW_HANDLER;\n\thbus->msi_info.handler_name = FLOW_NAME;\n\thbus->msi_info.data = hbus;\n\thbus->irq_domain = pci_msi_create_irq_domain(hbus->fwnode,\n\t\t\t\t\t\t     &hbus->msi_info,\n\t\t\t\t\t\t     hv_pci_get_root_domain());\n\tif (!hbus->irq_domain) {\n\t\tdev_err(&hbus->hdev->device,\n\t\t\t\"Failed to build an MSI IRQ domain\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tdev_set_msi_domain(&hbus->bridge->dev, hbus->irq_domain);\n\n\treturn 0;\n}\n\n \nstatic u64 get_bar_size(u64 bar_val)\n{\n\treturn round_up((1 + ~(bar_val & PCI_BASE_ADDRESS_MEM_MASK)),\n\t\t\tPAGE_SIZE);\n}\n\n \nstatic void survey_child_resources(struct hv_pcibus_device *hbus)\n{\n\tstruct hv_pci_dev *hpdev;\n\tresource_size_t bar_size = 0;\n\tunsigned long flags;\n\tstruct completion *event;\n\tu64 bar_val;\n\tint i;\n\n\t \n\tevent = xchg(&hbus->survey_event, NULL);\n\tif (!event)\n\t\treturn;\n\n\t \n\tif (hbus->low_mmio_space || hbus->high_mmio_space) {\n\t\tcomplete(event);\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\n\t \n\tlist_for_each_entry(hpdev, &hbus->children, list_entry) {\n\t\tfor (i = 0; i < PCI_STD_NUM_BARS; i++) {\n\t\t\tif (hpdev->probed_bar[i] & PCI_BASE_ADDRESS_SPACE_IO)\n\t\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\t\"There's an I/O BAR in this list!\\n\");\n\n\t\t\tif (hpdev->probed_bar[i] != 0) {\n\t\t\t\t \n\n\t\t\t\tbar_val = hpdev->probed_bar[i];\n\t\t\t\tif (bar_val & PCI_BASE_ADDRESS_MEM_TYPE_64)\n\t\t\t\t\tbar_val |=\n\t\t\t\t\t((u64)hpdev->probed_bar[++i] << 32);\n\t\t\t\telse\n\t\t\t\t\tbar_val |= 0xffffffff00000000ULL;\n\n\t\t\t\tbar_size = get_bar_size(bar_val);\n\n\t\t\t\tif (bar_val & PCI_BASE_ADDRESS_MEM_TYPE_64)\n\t\t\t\t\thbus->high_mmio_space += bar_size;\n\t\t\t\telse\n\t\t\t\t\thbus->low_mmio_space += bar_size;\n\t\t\t}\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\tcomplete(event);\n}\n\n \nstatic void prepopulate_bars(struct hv_pcibus_device *hbus)\n{\n\tresource_size_t high_size = 0;\n\tresource_size_t low_size = 0;\n\tresource_size_t high_base = 0;\n\tresource_size_t low_base = 0;\n\tresource_size_t bar_size;\n\tstruct hv_pci_dev *hpdev;\n\tunsigned long flags;\n\tu64 bar_val;\n\tu32 command;\n\tbool high;\n\tint i;\n\n\tif (hbus->low_mmio_space) {\n\t\tlow_size = 1ULL << (63 - __builtin_clzll(hbus->low_mmio_space));\n\t\tlow_base = hbus->low_mmio_res->start;\n\t}\n\n\tif (hbus->high_mmio_space) {\n\t\thigh_size = 1ULL <<\n\t\t\t(63 - __builtin_clzll(hbus->high_mmio_space));\n\t\thigh_base = hbus->high_mmio_res->start;\n\t}\n\n\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\n\t \n\tlist_for_each_entry(hpdev, &hbus->children, list_entry) {\n\t\t_hv_pcifront_read_config(hpdev, PCI_COMMAND, 2, &command);\n\t\tcommand &= ~PCI_COMMAND_MEMORY;\n\t\t_hv_pcifront_write_config(hpdev, PCI_COMMAND, 2, command);\n\t}\n\n\t \n\tdo {\n\t\tlist_for_each_entry(hpdev, &hbus->children, list_entry) {\n\t\t\tfor (i = 0; i < PCI_STD_NUM_BARS; i++) {\n\t\t\t\tbar_val = hpdev->probed_bar[i];\n\t\t\t\tif (bar_val == 0)\n\t\t\t\t\tcontinue;\n\t\t\t\thigh = bar_val & PCI_BASE_ADDRESS_MEM_TYPE_64;\n\t\t\t\tif (high) {\n\t\t\t\t\tbar_val |=\n\t\t\t\t\t\t((u64)hpdev->probed_bar[i + 1]\n\t\t\t\t\t\t << 32);\n\t\t\t\t} else {\n\t\t\t\t\tbar_val |= 0xffffffffULL << 32;\n\t\t\t\t}\n\t\t\t\tbar_size = get_bar_size(bar_val);\n\t\t\t\tif (high) {\n\t\t\t\t\tif (high_size != bar_size) {\n\t\t\t\t\t\ti++;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\t_hv_pcifront_write_config(hpdev,\n\t\t\t\t\t\tPCI_BASE_ADDRESS_0 + (4 * i),\n\t\t\t\t\t\t4,\n\t\t\t\t\t\t(u32)(high_base & 0xffffff00));\n\t\t\t\t\ti++;\n\t\t\t\t\t_hv_pcifront_write_config(hpdev,\n\t\t\t\t\t\tPCI_BASE_ADDRESS_0 + (4 * i),\n\t\t\t\t\t\t4, (u32)(high_base >> 32));\n\t\t\t\t\thigh_base += bar_size;\n\t\t\t\t} else {\n\t\t\t\t\tif (low_size != bar_size)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t_hv_pcifront_write_config(hpdev,\n\t\t\t\t\t\tPCI_BASE_ADDRESS_0 + (4 * i),\n\t\t\t\t\t\t4,\n\t\t\t\t\t\t(u32)(low_base & 0xffffff00));\n\t\t\t\t\tlow_base += bar_size;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (high_size <= 1 && low_size <= 1) {\n\t\t\t\t \n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\thigh_size >>= 1;\n\t\tlow_size >>= 1;\n\t}  while (high_size || low_size);\n\n\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n}\n\n \nstatic void hv_pci_assign_slots(struct hv_pcibus_device *hbus)\n{\n\tstruct hv_pci_dev *hpdev;\n\tchar name[SLOT_NAME_SIZE];\n\tint slot_nr;\n\n\tlist_for_each_entry(hpdev, &hbus->children, list_entry) {\n\t\tif (hpdev->pci_slot)\n\t\t\tcontinue;\n\n\t\tslot_nr = PCI_SLOT(wslot_to_devfn(hpdev->desc.win_slot.slot));\n\t\tsnprintf(name, SLOT_NAME_SIZE, \"%u\", hpdev->desc.ser);\n\t\thpdev->pci_slot = pci_create_slot(hbus->bridge->bus, slot_nr,\n\t\t\t\t\t  name, NULL);\n\t\tif (IS_ERR(hpdev->pci_slot)) {\n\t\t\tpr_warn(\"pci_create slot %s failed\\n\", name);\n\t\t\thpdev->pci_slot = NULL;\n\t\t}\n\t}\n}\n\n \nstatic void hv_pci_remove_slots(struct hv_pcibus_device *hbus)\n{\n\tstruct hv_pci_dev *hpdev;\n\n\tlist_for_each_entry(hpdev, &hbus->children, list_entry) {\n\t\tif (!hpdev->pci_slot)\n\t\t\tcontinue;\n\t\tpci_destroy_slot(hpdev->pci_slot);\n\t\thpdev->pci_slot = NULL;\n\t}\n}\n\n \nstatic void hv_pci_assign_numa_node(struct hv_pcibus_device *hbus)\n{\n\tstruct pci_dev *dev;\n\tstruct pci_bus *bus = hbus->bridge->bus;\n\tstruct hv_pci_dev *hv_dev;\n\n\tlist_for_each_entry(dev, &bus->devices, bus_list) {\n\t\thv_dev = get_pcichild_wslot(hbus, devfn_to_wslot(dev->devfn));\n\t\tif (!hv_dev)\n\t\t\tcontinue;\n\n\t\tif (hv_dev->desc.flags & HV_PCI_DEVICE_FLAG_NUMA_AFFINITY &&\n\t\t    hv_dev->desc.virtual_numa_node < num_possible_nodes())\n\t\t\t \n\t\t\tset_dev_node(&dev->dev,\n\t\t\t\t     numa_map_to_online_node(\n\t\t\t\t\t     hv_dev->desc.virtual_numa_node));\n\n\t\tput_pcichild(hv_dev);\n\t}\n}\n\n \nstatic int create_root_hv_pci_bus(struct hv_pcibus_device *hbus)\n{\n\tint error;\n\tstruct pci_host_bridge *bridge = hbus->bridge;\n\n\tbridge->dev.parent = &hbus->hdev->device;\n\tbridge->sysdata = &hbus->sysdata;\n\tbridge->ops = &hv_pcifront_ops;\n\n\terror = pci_scan_root_bus_bridge(bridge);\n\tif (error)\n\t\treturn error;\n\n\tpci_lock_rescan_remove();\n\thv_pci_assign_numa_node(hbus);\n\tpci_bus_assign_resources(bridge->bus);\n\thv_pci_assign_slots(hbus);\n\tpci_bus_add_devices(bridge->bus);\n\tpci_unlock_rescan_remove();\n\thbus->state = hv_pcibus_installed;\n\treturn 0;\n}\n\nstruct q_res_req_compl {\n\tstruct completion host_event;\n\tstruct hv_pci_dev *hpdev;\n};\n\n \nstatic void q_resource_requirements(void *context, struct pci_response *resp,\n\t\t\t\t    int resp_packet_size)\n{\n\tstruct q_res_req_compl *completion = context;\n\tstruct pci_q_res_req_response *q_res_req =\n\t\t(struct pci_q_res_req_response *)resp;\n\ts32 status;\n\tint i;\n\n\tstatus = (resp_packet_size < sizeof(*q_res_req)) ? -1 : resp->status;\n\tif (status < 0) {\n\t\tdev_err(&completion->hpdev->hbus->hdev->device,\n\t\t\t\"query resource requirements failed: %x\\n\",\n\t\t\tstatus);\n\t} else {\n\t\tfor (i = 0; i < PCI_STD_NUM_BARS; i++) {\n\t\t\tcompletion->hpdev->probed_bar[i] =\n\t\t\t\tq_res_req->probed_bar[i];\n\t\t}\n\t}\n\n\tcomplete(&completion->host_event);\n}\n\n \nstatic struct hv_pci_dev *new_pcichild_device(struct hv_pcibus_device *hbus,\n\t\tstruct hv_pcidev_description *desc)\n{\n\tstruct hv_pci_dev *hpdev;\n\tstruct pci_child_message *res_req;\n\tstruct q_res_req_compl comp_pkt;\n\tstruct {\n\t\tstruct pci_packet init_packet;\n\t\tu8 buffer[sizeof(struct pci_child_message)];\n\t} pkt;\n\tunsigned long flags;\n\tint ret;\n\n\thpdev = kzalloc(sizeof(*hpdev), GFP_KERNEL);\n\tif (!hpdev)\n\t\treturn NULL;\n\n\thpdev->hbus = hbus;\n\n\tmemset(&pkt, 0, sizeof(pkt));\n\tinit_completion(&comp_pkt.host_event);\n\tcomp_pkt.hpdev = hpdev;\n\tpkt.init_packet.compl_ctxt = &comp_pkt;\n\tpkt.init_packet.completion_func = q_resource_requirements;\n\tres_req = (struct pci_child_message *)&pkt.init_packet.message;\n\tres_req->message_type.type = PCI_QUERY_RESOURCE_REQUIREMENTS;\n\tres_req->wslot.slot = desc->win_slot.slot;\n\n\tret = vmbus_sendpacket(hbus->hdev->channel, res_req,\n\t\t\t       sizeof(struct pci_child_message),\n\t\t\t       (unsigned long)&pkt.init_packet,\n\t\t\t       VM_PKT_DATA_INBAND,\n\t\t\t       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);\n\tif (ret)\n\t\tgoto error;\n\n\tif (wait_for_response(hbus->hdev, &comp_pkt.host_event))\n\t\tgoto error;\n\n\thpdev->desc = *desc;\n\trefcount_set(&hpdev->refs, 1);\n\tget_pcichild(hpdev);\n\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\n\tlist_add_tail(&hpdev->list_entry, &hbus->children);\n\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\treturn hpdev;\n\nerror:\n\tkfree(hpdev);\n\treturn NULL;\n}\n\n \nstatic struct hv_pci_dev *get_pcichild_wslot(struct hv_pcibus_device *hbus,\n\t\t\t\t\t     u32 wslot)\n{\n\tunsigned long flags;\n\tstruct hv_pci_dev *iter, *hpdev = NULL;\n\n\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\tlist_for_each_entry(iter, &hbus->children, list_entry) {\n\t\tif (iter->desc.win_slot.slot == wslot) {\n\t\t\thpdev = iter;\n\t\t\tget_pcichild(hpdev);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\n\treturn hpdev;\n}\n\n \nstatic void pci_devices_present_work(struct work_struct *work)\n{\n\tu32 child_no;\n\tbool found;\n\tstruct hv_pcidev_description *new_desc;\n\tstruct hv_pci_dev *hpdev;\n\tstruct hv_pcibus_device *hbus;\n\tstruct list_head removed;\n\tstruct hv_dr_work *dr_wrk;\n\tstruct hv_dr_state *dr = NULL;\n\tunsigned long flags;\n\n\tdr_wrk = container_of(work, struct hv_dr_work, wrk);\n\thbus = dr_wrk->bus;\n\tkfree(dr_wrk);\n\n\tINIT_LIST_HEAD(&removed);\n\n\t \n\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\twhile (!list_empty(&hbus->dr_list)) {\n\t\tdr = list_first_entry(&hbus->dr_list, struct hv_dr_state,\n\t\t\t\t      list_entry);\n\t\tlist_del(&dr->list_entry);\n\n\t\t \n\t\tif (!list_empty(&hbus->dr_list)) {\n\t\t\tkfree(dr);\n\t\t\tcontinue;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\n\tif (!dr)\n\t\treturn;\n\n\tmutex_lock(&hbus->state_lock);\n\n\t \n\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\tlist_for_each_entry(hpdev, &hbus->children, list_entry) {\n\t\thpdev->reported_missing = true;\n\t}\n\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\n\t \n\tfor (child_no = 0; child_no < dr->device_count; child_no++) {\n\t\tfound = false;\n\t\tnew_desc = &dr->func[child_no];\n\n\t\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\t\tlist_for_each_entry(hpdev, &hbus->children, list_entry) {\n\t\t\tif ((hpdev->desc.win_slot.slot == new_desc->win_slot.slot) &&\n\t\t\t    (hpdev->desc.v_id == new_desc->v_id) &&\n\t\t\t    (hpdev->desc.d_id == new_desc->d_id) &&\n\t\t\t    (hpdev->desc.ser == new_desc->ser)) {\n\t\t\t\thpdev->reported_missing = false;\n\t\t\t\tfound = true;\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\n\t\tif (!found) {\n\t\t\thpdev = new_pcichild_device(hbus, new_desc);\n\t\t\tif (!hpdev)\n\t\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\t\"couldn't record a child device.\\n\");\n\t\t}\n\t}\n\n\t \n\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\tdo {\n\t\tfound = false;\n\t\tlist_for_each_entry(hpdev, &hbus->children, list_entry) {\n\t\t\tif (hpdev->reported_missing) {\n\t\t\t\tfound = true;\n\t\t\t\tput_pcichild(hpdev);\n\t\t\t\tlist_move_tail(&hpdev->list_entry, &removed);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} while (found);\n\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\n\t \n\twhile (!list_empty(&removed)) {\n\t\thpdev = list_first_entry(&removed, struct hv_pci_dev,\n\t\t\t\t\t list_entry);\n\t\tlist_del(&hpdev->list_entry);\n\n\t\tif (hpdev->pci_slot)\n\t\t\tpci_destroy_slot(hpdev->pci_slot);\n\n\t\tput_pcichild(hpdev);\n\t}\n\n\tswitch (hbus->state) {\n\tcase hv_pcibus_installed:\n\t\t \n\t\tpci_lock_rescan_remove();\n\t\tpci_scan_child_bus(hbus->bridge->bus);\n\t\thv_pci_assign_numa_node(hbus);\n\t\thv_pci_assign_slots(hbus);\n\t\tpci_unlock_rescan_remove();\n\t\tbreak;\n\n\tcase hv_pcibus_init:\n\tcase hv_pcibus_probed:\n\t\tsurvey_child_resources(hbus);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tmutex_unlock(&hbus->state_lock);\n\n\tkfree(dr);\n}\n\n \nstatic int hv_pci_start_relations_work(struct hv_pcibus_device *hbus,\n\t\t\t\t       struct hv_dr_state *dr)\n{\n\tstruct hv_dr_work *dr_wrk;\n\tunsigned long flags;\n\tbool pending_dr;\n\n\tif (hbus->state == hv_pcibus_removing) {\n\t\tdev_info(&hbus->hdev->device,\n\t\t\t \"PCI VMBus BUS_RELATIONS: ignored\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\tdr_wrk = kzalloc(sizeof(*dr_wrk), GFP_NOWAIT);\n\tif (!dr_wrk)\n\t\treturn -ENOMEM;\n\n\tINIT_WORK(&dr_wrk->wrk, pci_devices_present_work);\n\tdr_wrk->bus = hbus;\n\n\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\t \n\tpending_dr = !list_empty(&hbus->dr_list);\n\tlist_add_tail(&dr->list_entry, &hbus->dr_list);\n\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\n\tif (pending_dr)\n\t\tkfree(dr_wrk);\n\telse\n\t\tqueue_work(hbus->wq, &dr_wrk->wrk);\n\n\treturn 0;\n}\n\n \nstatic void hv_pci_devices_present(struct hv_pcibus_device *hbus,\n\t\t\t\t   struct pci_bus_relations *relations)\n{\n\tstruct hv_dr_state *dr;\n\tint i;\n\n\tdr = kzalloc(struct_size(dr, func, relations->device_count),\n\t\t     GFP_NOWAIT);\n\tif (!dr)\n\t\treturn;\n\n\tdr->device_count = relations->device_count;\n\tfor (i = 0; i < dr->device_count; i++) {\n\t\tdr->func[i].v_id = relations->func[i].v_id;\n\t\tdr->func[i].d_id = relations->func[i].d_id;\n\t\tdr->func[i].rev = relations->func[i].rev;\n\t\tdr->func[i].prog_intf = relations->func[i].prog_intf;\n\t\tdr->func[i].subclass = relations->func[i].subclass;\n\t\tdr->func[i].base_class = relations->func[i].base_class;\n\t\tdr->func[i].subsystem_id = relations->func[i].subsystem_id;\n\t\tdr->func[i].win_slot = relations->func[i].win_slot;\n\t\tdr->func[i].ser = relations->func[i].ser;\n\t}\n\n\tif (hv_pci_start_relations_work(hbus, dr))\n\t\tkfree(dr);\n}\n\n \nstatic void hv_pci_devices_present2(struct hv_pcibus_device *hbus,\n\t\t\t\t    struct pci_bus_relations2 *relations)\n{\n\tstruct hv_dr_state *dr;\n\tint i;\n\n\tdr = kzalloc(struct_size(dr, func, relations->device_count),\n\t\t     GFP_NOWAIT);\n\tif (!dr)\n\t\treturn;\n\n\tdr->device_count = relations->device_count;\n\tfor (i = 0; i < dr->device_count; i++) {\n\t\tdr->func[i].v_id = relations->func[i].v_id;\n\t\tdr->func[i].d_id = relations->func[i].d_id;\n\t\tdr->func[i].rev = relations->func[i].rev;\n\t\tdr->func[i].prog_intf = relations->func[i].prog_intf;\n\t\tdr->func[i].subclass = relations->func[i].subclass;\n\t\tdr->func[i].base_class = relations->func[i].base_class;\n\t\tdr->func[i].subsystem_id = relations->func[i].subsystem_id;\n\t\tdr->func[i].win_slot = relations->func[i].win_slot;\n\t\tdr->func[i].ser = relations->func[i].ser;\n\t\tdr->func[i].flags = relations->func[i].flags;\n\t\tdr->func[i].virtual_numa_node =\n\t\t\trelations->func[i].virtual_numa_node;\n\t}\n\n\tif (hv_pci_start_relations_work(hbus, dr))\n\t\tkfree(dr);\n}\n\n \nstatic void hv_eject_device_work(struct work_struct *work)\n{\n\tstruct pci_eject_response *ejct_pkt;\n\tstruct hv_pcibus_device *hbus;\n\tstruct hv_pci_dev *hpdev;\n\tstruct pci_dev *pdev;\n\tunsigned long flags;\n\tint wslot;\n\tstruct {\n\t\tstruct pci_packet pkt;\n\t\tu8 buffer[sizeof(struct pci_eject_response)];\n\t} ctxt;\n\n\thpdev = container_of(work, struct hv_pci_dev, wrk);\n\thbus = hpdev->hbus;\n\n\tmutex_lock(&hbus->state_lock);\n\n\t \n\twslot = wslot_to_devfn(hpdev->desc.win_slot.slot);\n\tpdev = pci_get_domain_bus_and_slot(hbus->bridge->domain_nr, 0, wslot);\n\tif (pdev) {\n\t\tpci_lock_rescan_remove();\n\t\tpci_stop_and_remove_bus_device(pdev);\n\t\tpci_dev_put(pdev);\n\t\tpci_unlock_rescan_remove();\n\t}\n\n\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\tlist_del(&hpdev->list_entry);\n\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\n\tif (hpdev->pci_slot)\n\t\tpci_destroy_slot(hpdev->pci_slot);\n\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tejct_pkt = (struct pci_eject_response *)&ctxt.pkt.message;\n\tejct_pkt->message_type.type = PCI_EJECTION_COMPLETE;\n\tejct_pkt->wslot.slot = hpdev->desc.win_slot.slot;\n\tvmbus_sendpacket(hbus->hdev->channel, ejct_pkt,\n\t\t\t sizeof(*ejct_pkt), 0,\n\t\t\t VM_PKT_DATA_INBAND, 0);\n\n\t \n\tput_pcichild(hpdev);\n\t \n\tput_pcichild(hpdev);\n\tput_pcichild(hpdev);\n\t \n\n\tmutex_unlock(&hbus->state_lock);\n}\n\n \nstatic void hv_pci_eject_device(struct hv_pci_dev *hpdev)\n{\n\tstruct hv_pcibus_device *hbus = hpdev->hbus;\n\tstruct hv_device *hdev = hbus->hdev;\n\n\tif (hbus->state == hv_pcibus_removing) {\n\t\tdev_info(&hdev->device, \"PCI VMBus EJECT: ignored\\n\");\n\t\treturn;\n\t}\n\n\tget_pcichild(hpdev);\n\tINIT_WORK(&hpdev->wrk, hv_eject_device_work);\n\tqueue_work(hbus->wq, &hpdev->wrk);\n}\n\n \nstatic void hv_pci_onchannelcallback(void *context)\n{\n\tconst int packet_size = 0x100;\n\tint ret;\n\tstruct hv_pcibus_device *hbus = context;\n\tstruct vmbus_channel *chan = hbus->hdev->channel;\n\tu32 bytes_recvd;\n\tu64 req_id, req_addr;\n\tstruct vmpacket_descriptor *desc;\n\tunsigned char *buffer;\n\tint bufferlen = packet_size;\n\tstruct pci_packet *comp_packet;\n\tstruct pci_response *response;\n\tstruct pci_incoming_message *new_message;\n\tstruct pci_bus_relations *bus_rel;\n\tstruct pci_bus_relations2 *bus_rel2;\n\tstruct pci_dev_inval_block *inval;\n\tstruct pci_dev_incoming *dev_message;\n\tstruct hv_pci_dev *hpdev;\n\tunsigned long flags;\n\n\tbuffer = kmalloc(bufferlen, GFP_ATOMIC);\n\tif (!buffer)\n\t\treturn;\n\n\twhile (1) {\n\t\tret = vmbus_recvpacket_raw(chan, buffer, bufferlen,\n\t\t\t\t\t   &bytes_recvd, &req_id);\n\n\t\tif (ret == -ENOBUFS) {\n\t\t\tkfree(buffer);\n\t\t\t \n\t\t\tbufferlen = bytes_recvd;\n\t\t\tbuffer = kmalloc(bytes_recvd, GFP_ATOMIC);\n\t\t\tif (!buffer)\n\t\t\t\treturn;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (ret || !bytes_recvd)\n\t\t\tbreak;\n\n\t\t \n\t\tif (bytes_recvd <= sizeof(struct pci_response))\n\t\t\tcontinue;\n\t\tdesc = (struct vmpacket_descriptor *)buffer;\n\n\t\tswitch (desc->type) {\n\t\tcase VM_PKT_COMP:\n\n\t\t\tlock_requestor(chan, flags);\n\t\t\treq_addr = __vmbus_request_addr_match(chan, req_id,\n\t\t\t\t\t\t\t      VMBUS_RQST_ADDR_ANY);\n\t\t\tif (req_addr == VMBUS_RQST_ERROR) {\n\t\t\t\tunlock_requestor(chan, flags);\n\t\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\t\"Invalid transaction ID %llx\\n\",\n\t\t\t\t\treq_id);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcomp_packet = (struct pci_packet *)req_addr;\n\t\t\tresponse = (struct pci_response *)buffer;\n\t\t\t \n\t\t\tcomp_packet->completion_func(comp_packet->compl_ctxt,\n\t\t\t\t\t\t     response,\n\t\t\t\t\t\t     bytes_recvd);\n\t\t\tunlock_requestor(chan, flags);\n\t\t\tbreak;\n\n\t\tcase VM_PKT_DATA_INBAND:\n\n\t\t\tnew_message = (struct pci_incoming_message *)buffer;\n\t\t\tswitch (new_message->message_type.type) {\n\t\t\tcase PCI_BUS_RELATIONS:\n\n\t\t\t\tbus_rel = (struct pci_bus_relations *)buffer;\n\t\t\t\tif (bytes_recvd < sizeof(*bus_rel) ||\n\t\t\t\t    bytes_recvd <\n\t\t\t\t\tstruct_size(bus_rel, func,\n\t\t\t\t\t\t    bus_rel->device_count)) {\n\t\t\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\t\t\"bus relations too small\\n\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\thv_pci_devices_present(hbus, bus_rel);\n\t\t\t\tbreak;\n\n\t\t\tcase PCI_BUS_RELATIONS2:\n\n\t\t\t\tbus_rel2 = (struct pci_bus_relations2 *)buffer;\n\t\t\t\tif (bytes_recvd < sizeof(*bus_rel2) ||\n\t\t\t\t    bytes_recvd <\n\t\t\t\t\tstruct_size(bus_rel2, func,\n\t\t\t\t\t\t    bus_rel2->device_count)) {\n\t\t\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\t\t\"bus relations v2 too small\\n\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\thv_pci_devices_present2(hbus, bus_rel2);\n\t\t\t\tbreak;\n\n\t\t\tcase PCI_EJECT:\n\n\t\t\t\tdev_message = (struct pci_dev_incoming *)buffer;\n\t\t\t\tif (bytes_recvd < sizeof(*dev_message)) {\n\t\t\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\t\t\"eject message too small\\n\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\thpdev = get_pcichild_wslot(hbus,\n\t\t\t\t\t\t      dev_message->wslot.slot);\n\t\t\t\tif (hpdev) {\n\t\t\t\t\thv_pci_eject_device(hpdev);\n\t\t\t\t\tput_pcichild(hpdev);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase PCI_INVALIDATE_BLOCK:\n\n\t\t\t\tinval = (struct pci_dev_inval_block *)buffer;\n\t\t\t\tif (bytes_recvd < sizeof(*inval)) {\n\t\t\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\t\t\"invalidate message too small\\n\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\thpdev = get_pcichild_wslot(hbus,\n\t\t\t\t\t\t\t   inval->wslot.slot);\n\t\t\t\tif (hpdev) {\n\t\t\t\t\tif (hpdev->block_invalidate) {\n\t\t\t\t\t\thpdev->block_invalidate(\n\t\t\t\t\t\t    hpdev->invalidate_context,\n\t\t\t\t\t\t    inval->block_mask);\n\t\t\t\t\t}\n\t\t\t\t\tput_pcichild(hpdev);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tdev_warn(&hbus->hdev->device,\n\t\t\t\t\t\"Unimplemented protocol message %x\\n\",\n\t\t\t\t\tnew_message->message_type.type);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\"unhandled packet type %d, tid %llx len %d\\n\",\n\t\t\t\tdesc->type, req_id, bytes_recvd);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tkfree(buffer);\n}\n\n \nstatic int hv_pci_protocol_negotiation(struct hv_device *hdev,\n\t\t\t\t       enum pci_protocol_version_t version[],\n\t\t\t\t       int num_version)\n{\n\tstruct hv_pcibus_device *hbus = hv_get_drvdata(hdev);\n\tstruct pci_version_request *version_req;\n\tstruct hv_pci_compl comp_pkt;\n\tstruct pci_packet *pkt;\n\tint ret;\n\tint i;\n\n\t \n\tpkt = kzalloc(sizeof(*pkt) + sizeof(*version_req), GFP_KERNEL);\n\tif (!pkt)\n\t\treturn -ENOMEM;\n\n\tinit_completion(&comp_pkt.host_event);\n\tpkt->completion_func = hv_pci_generic_compl;\n\tpkt->compl_ctxt = &comp_pkt;\n\tversion_req = (struct pci_version_request *)&pkt->message;\n\tversion_req->message_type.type = PCI_QUERY_PROTOCOL_VERSION;\n\n\tfor (i = 0; i < num_version; i++) {\n\t\tversion_req->protocol_version = version[i];\n\t\tret = vmbus_sendpacket(hdev->channel, version_req,\n\t\t\t\tsizeof(struct pci_version_request),\n\t\t\t\t(unsigned long)pkt, VM_PKT_DATA_INBAND,\n\t\t\t\tVMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);\n\t\tif (!ret)\n\t\t\tret = wait_for_response(hdev, &comp_pkt.host_event);\n\n\t\tif (ret) {\n\t\t\tdev_err(&hdev->device,\n\t\t\t\t\"PCI Pass-through VSP failed to request version: %d\",\n\t\t\t\tret);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (comp_pkt.completion_status >= 0) {\n\t\t\thbus->protocol_version = version[i];\n\t\t\tdev_info(&hdev->device,\n\t\t\t\t\"PCI VMBus probing: Using version %#x\\n\",\n\t\t\t\thbus->protocol_version);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (comp_pkt.completion_status != STATUS_REVISION_MISMATCH) {\n\t\t\tdev_err(&hdev->device,\n\t\t\t\t\"PCI Pass-through VSP failed version request: %#x\",\n\t\t\t\tcomp_pkt.completion_status);\n\t\t\tret = -EPROTO;\n\t\t\tgoto exit;\n\t\t}\n\n\t\treinit_completion(&comp_pkt.host_event);\n\t}\n\n\tdev_err(&hdev->device,\n\t\t\"PCI pass-through VSP failed to find supported version\");\n\tret = -EPROTO;\n\nexit:\n\tkfree(pkt);\n\treturn ret;\n}\n\n \nstatic void hv_pci_free_bridge_windows(struct hv_pcibus_device *hbus)\n{\n\t \n\n\tif (hbus->low_mmio_space && hbus->low_mmio_res) {\n\t\thbus->low_mmio_res->flags |= IORESOURCE_BUSY;\n\t\tvmbus_free_mmio(hbus->low_mmio_res->start,\n\t\t\t\tresource_size(hbus->low_mmio_res));\n\t}\n\n\tif (hbus->high_mmio_space && hbus->high_mmio_res) {\n\t\thbus->high_mmio_res->flags |= IORESOURCE_BUSY;\n\t\tvmbus_free_mmio(hbus->high_mmio_res->start,\n\t\t\t\tresource_size(hbus->high_mmio_res));\n\t}\n}\n\n \nstatic int hv_pci_allocate_bridge_windows(struct hv_pcibus_device *hbus)\n{\n\tresource_size_t align;\n\tint ret;\n\n\tif (hbus->low_mmio_space) {\n\t\talign = 1ULL << (63 - __builtin_clzll(hbus->low_mmio_space));\n\t\tret = vmbus_allocate_mmio(&hbus->low_mmio_res, hbus->hdev, 0,\n\t\t\t\t\t  (u64)(u32)0xffffffff,\n\t\t\t\t\t  hbus->low_mmio_space,\n\t\t\t\t\t  align, false);\n\t\tif (ret) {\n\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\"Need %#llx of low MMIO space. Consider reconfiguring the VM.\\n\",\n\t\t\t\thbus->low_mmio_space);\n\t\t\treturn ret;\n\t\t}\n\n\t\t \n\t\thbus->low_mmio_res->flags |= IORESOURCE_WINDOW;\n\t\thbus->low_mmio_res->flags &= ~IORESOURCE_BUSY;\n\t\tpci_add_resource(&hbus->bridge->windows, hbus->low_mmio_res);\n\t}\n\n\tif (hbus->high_mmio_space) {\n\t\talign = 1ULL << (63 - __builtin_clzll(hbus->high_mmio_space));\n\t\tret = vmbus_allocate_mmio(&hbus->high_mmio_res, hbus->hdev,\n\t\t\t\t\t  0x100000000, -1,\n\t\t\t\t\t  hbus->high_mmio_space, align,\n\t\t\t\t\t  false);\n\t\tif (ret) {\n\t\t\tdev_err(&hbus->hdev->device,\n\t\t\t\t\"Need %#llx of high MMIO space. Consider reconfiguring the VM.\\n\",\n\t\t\t\thbus->high_mmio_space);\n\t\t\tgoto release_low_mmio;\n\t\t}\n\n\t\t \n\t\thbus->high_mmio_res->flags |= IORESOURCE_WINDOW;\n\t\thbus->high_mmio_res->flags &= ~IORESOURCE_BUSY;\n\t\tpci_add_resource(&hbus->bridge->windows, hbus->high_mmio_res);\n\t}\n\n\treturn 0;\n\nrelease_low_mmio:\n\tif (hbus->low_mmio_res) {\n\t\tvmbus_free_mmio(hbus->low_mmio_res->start,\n\t\t\t\tresource_size(hbus->low_mmio_res));\n\t}\n\n\treturn ret;\n}\n\n \nstatic int hv_allocate_config_window(struct hv_pcibus_device *hbus)\n{\n\tint ret;\n\n\t \n\tret = vmbus_allocate_mmio(&hbus->mem_config, hbus->hdev, 0, -1,\n\t\t\t\t  PCI_CONFIG_MMIO_LENGTH, 0x1000, false);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\n\thbus->mem_config->flags |= IORESOURCE_BUSY;\n\n\treturn 0;\n}\n\nstatic void hv_free_config_window(struct hv_pcibus_device *hbus)\n{\n\tvmbus_free_mmio(hbus->mem_config->start, PCI_CONFIG_MMIO_LENGTH);\n}\n\nstatic int hv_pci_bus_exit(struct hv_device *hdev, bool keep_devs);\n\n \nstatic int hv_pci_enter_d0(struct hv_device *hdev)\n{\n\tstruct hv_pcibus_device *hbus = hv_get_drvdata(hdev);\n\tstruct pci_bus_d0_entry *d0_entry;\n\tstruct hv_pci_compl comp_pkt;\n\tstruct pci_packet *pkt;\n\tbool retry = true;\n\tint ret;\n\nenter_d0_retry:\n\t \n\tpkt = kzalloc(sizeof(*pkt) + sizeof(*d0_entry), GFP_KERNEL);\n\tif (!pkt)\n\t\treturn -ENOMEM;\n\n\tinit_completion(&comp_pkt.host_event);\n\tpkt->completion_func = hv_pci_generic_compl;\n\tpkt->compl_ctxt = &comp_pkt;\n\td0_entry = (struct pci_bus_d0_entry *)&pkt->message;\n\td0_entry->message_type.type = PCI_BUS_D0ENTRY;\n\td0_entry->mmio_base = hbus->mem_config->start;\n\n\tret = vmbus_sendpacket(hdev->channel, d0_entry, sizeof(*d0_entry),\n\t\t\t       (unsigned long)pkt, VM_PKT_DATA_INBAND,\n\t\t\t       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);\n\tif (!ret)\n\t\tret = wait_for_response(hdev, &comp_pkt.host_event);\n\n\tif (ret)\n\t\tgoto exit;\n\n\t \n\tif (comp_pkt.completion_status < 0 && retry) {\n\t\tretry = false;\n\n\t\tdev_err(&hdev->device, \"Retrying D0 Entry\\n\");\n\n\t\t \n\t\thbus->wslot_res_allocated = 255;\n\n\t\tret = hv_pci_bus_exit(hdev, true);\n\n\t\tif (ret == 0) {\n\t\t\tkfree(pkt);\n\t\t\tgoto enter_d0_retry;\n\t\t}\n\t\tdev_err(&hdev->device,\n\t\t\t\"Retrying D0 failed with ret %d\\n\", ret);\n\t}\n\n\tif (comp_pkt.completion_status < 0) {\n\t\tdev_err(&hdev->device,\n\t\t\t\"PCI Pass-through VSP failed D0 Entry with status %x\\n\",\n\t\t\tcomp_pkt.completion_status);\n\t\tret = -EPROTO;\n\t\tgoto exit;\n\t}\n\n\tret = 0;\n\nexit:\n\tkfree(pkt);\n\treturn ret;\n}\n\n \nstatic int hv_pci_query_relations(struct hv_device *hdev)\n{\n\tstruct hv_pcibus_device *hbus = hv_get_drvdata(hdev);\n\tstruct pci_message message;\n\tstruct completion comp;\n\tint ret;\n\n\t \n\tinit_completion(&comp);\n\tif (cmpxchg(&hbus->survey_event, NULL, &comp))\n\t\treturn -ENOTEMPTY;\n\n\tmemset(&message, 0, sizeof(message));\n\tmessage.type = PCI_QUERY_BUS_RELATIONS;\n\n\tret = vmbus_sendpacket(hdev->channel, &message, sizeof(message),\n\t\t\t       0, VM_PKT_DATA_INBAND, 0);\n\tif (!ret)\n\t\tret = wait_for_response(hdev, &comp);\n\n\t \n\tflush_workqueue(hbus->wq);\n\n\treturn ret;\n}\n\n \nstatic int hv_send_resources_allocated(struct hv_device *hdev)\n{\n\tstruct hv_pcibus_device *hbus = hv_get_drvdata(hdev);\n\tstruct pci_resources_assigned *res_assigned;\n\tstruct pci_resources_assigned2 *res_assigned2;\n\tstruct hv_pci_compl comp_pkt;\n\tstruct hv_pci_dev *hpdev;\n\tstruct pci_packet *pkt;\n\tsize_t size_res;\n\tint wslot;\n\tint ret;\n\n\tsize_res = (hbus->protocol_version < PCI_PROTOCOL_VERSION_1_2)\n\t\t\t? sizeof(*res_assigned) : sizeof(*res_assigned2);\n\n\tpkt = kmalloc(sizeof(*pkt) + size_res, GFP_KERNEL);\n\tif (!pkt)\n\t\treturn -ENOMEM;\n\n\tret = 0;\n\n\tfor (wslot = 0; wslot < 256; wslot++) {\n\t\thpdev = get_pcichild_wslot(hbus, wslot);\n\t\tif (!hpdev)\n\t\t\tcontinue;\n\n\t\tmemset(pkt, 0, sizeof(*pkt) + size_res);\n\t\tinit_completion(&comp_pkt.host_event);\n\t\tpkt->completion_func = hv_pci_generic_compl;\n\t\tpkt->compl_ctxt = &comp_pkt;\n\n\t\tif (hbus->protocol_version < PCI_PROTOCOL_VERSION_1_2) {\n\t\t\tres_assigned =\n\t\t\t\t(struct pci_resources_assigned *)&pkt->message;\n\t\t\tres_assigned->message_type.type =\n\t\t\t\tPCI_RESOURCES_ASSIGNED;\n\t\t\tres_assigned->wslot.slot = hpdev->desc.win_slot.slot;\n\t\t} else {\n\t\t\tres_assigned2 =\n\t\t\t\t(struct pci_resources_assigned2 *)&pkt->message;\n\t\t\tres_assigned2->message_type.type =\n\t\t\t\tPCI_RESOURCES_ASSIGNED2;\n\t\t\tres_assigned2->wslot.slot = hpdev->desc.win_slot.slot;\n\t\t}\n\t\tput_pcichild(hpdev);\n\n\t\tret = vmbus_sendpacket(hdev->channel, &pkt->message,\n\t\t\t\tsize_res, (unsigned long)pkt,\n\t\t\t\tVM_PKT_DATA_INBAND,\n\t\t\t\tVMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);\n\t\tif (!ret)\n\t\t\tret = wait_for_response(hdev, &comp_pkt.host_event);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (comp_pkt.completion_status < 0) {\n\t\t\tret = -EPROTO;\n\t\t\tdev_err(&hdev->device,\n\t\t\t\t\"resource allocated returned 0x%x\",\n\t\t\t\tcomp_pkt.completion_status);\n\t\t\tbreak;\n\t\t}\n\n\t\thbus->wslot_res_allocated = wslot;\n\t}\n\n\tkfree(pkt);\n\treturn ret;\n}\n\n \nstatic int hv_send_resources_released(struct hv_device *hdev)\n{\n\tstruct hv_pcibus_device *hbus = hv_get_drvdata(hdev);\n\tstruct pci_child_message pkt;\n\tstruct hv_pci_dev *hpdev;\n\tint wslot;\n\tint ret;\n\n\tfor (wslot = hbus->wslot_res_allocated; wslot >= 0; wslot--) {\n\t\thpdev = get_pcichild_wslot(hbus, wslot);\n\t\tif (!hpdev)\n\t\t\tcontinue;\n\n\t\tmemset(&pkt, 0, sizeof(pkt));\n\t\tpkt.message_type.type = PCI_RESOURCES_RELEASED;\n\t\tpkt.wslot.slot = hpdev->desc.win_slot.slot;\n\n\t\tput_pcichild(hpdev);\n\n\t\tret = vmbus_sendpacket(hdev->channel, &pkt, sizeof(pkt), 0,\n\t\t\t\t       VM_PKT_DATA_INBAND, 0);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\thbus->wslot_res_allocated = wslot - 1;\n\t}\n\n\thbus->wslot_res_allocated = -1;\n\n\treturn 0;\n}\n\n#define HVPCI_DOM_MAP_SIZE (64 * 1024)\nstatic DECLARE_BITMAP(hvpci_dom_map, HVPCI_DOM_MAP_SIZE);\n\n \n#define HVPCI_DOM_INVALID 0\n\n \nstatic u16 hv_get_dom_num(u16 dom)\n{\n\tunsigned int i;\n\n\tif (test_and_set_bit(dom, hvpci_dom_map) == 0)\n\t\treturn dom;\n\n\tfor_each_clear_bit(i, hvpci_dom_map, HVPCI_DOM_MAP_SIZE) {\n\t\tif (test_and_set_bit(i, hvpci_dom_map) == 0)\n\t\t\treturn i;\n\t}\n\n\treturn HVPCI_DOM_INVALID;\n}\n\n \nstatic void hv_put_dom_num(u16 dom)\n{\n\tclear_bit(dom, hvpci_dom_map);\n}\n\n \nstatic int hv_pci_probe(struct hv_device *hdev,\n\t\t\tconst struct hv_vmbus_device_id *dev_id)\n{\n\tstruct pci_host_bridge *bridge;\n\tstruct hv_pcibus_device *hbus;\n\tu16 dom_req, dom;\n\tchar *name;\n\tint ret;\n\n\tbridge = devm_pci_alloc_host_bridge(&hdev->device, 0);\n\tif (!bridge)\n\t\treturn -ENOMEM;\n\n\thbus = kzalloc(sizeof(*hbus), GFP_KERNEL);\n\tif (!hbus)\n\t\treturn -ENOMEM;\n\n\thbus->bridge = bridge;\n\tmutex_init(&hbus->state_lock);\n\thbus->state = hv_pcibus_init;\n\thbus->wslot_res_allocated = -1;\n\n\t \n\tdom_req = hdev->dev_instance.b[5] << 8 | hdev->dev_instance.b[4];\n\tdom = hv_get_dom_num(dom_req);\n\n\tif (dom == HVPCI_DOM_INVALID) {\n\t\tdev_err(&hdev->device,\n\t\t\t\"Unable to use dom# 0x%x or other numbers\", dom_req);\n\t\tret = -EINVAL;\n\t\tgoto free_bus;\n\t}\n\n\tif (dom != dom_req)\n\t\tdev_info(&hdev->device,\n\t\t\t \"PCI dom# 0x%x has collision, using 0x%x\",\n\t\t\t dom_req, dom);\n\n\thbus->bridge->domain_nr = dom;\n#ifdef CONFIG_X86\n\thbus->sysdata.domain = dom;\n\thbus->use_calls = !!(ms_hyperv.hints & HV_X64_USE_MMIO_HYPERCALLS);\n#elif defined(CONFIG_ARM64)\n\t \n\thbus->sysdata.parent = hdev->device.parent;\n\thbus->use_calls = false;\n#endif\n\n\thbus->hdev = hdev;\n\tINIT_LIST_HEAD(&hbus->children);\n\tINIT_LIST_HEAD(&hbus->dr_list);\n\tspin_lock_init(&hbus->config_lock);\n\tspin_lock_init(&hbus->device_list_lock);\n\thbus->wq = alloc_ordered_workqueue(\"hv_pci_%x\", 0,\n\t\t\t\t\t   hbus->bridge->domain_nr);\n\tif (!hbus->wq) {\n\t\tret = -ENOMEM;\n\t\tgoto free_dom;\n\t}\n\n\thdev->channel->next_request_id_callback = vmbus_next_request_id;\n\thdev->channel->request_addr_callback = vmbus_request_addr;\n\thdev->channel->rqstor_size = HV_PCI_RQSTOR_SIZE;\n\n\tret = vmbus_open(hdev->channel, pci_ring_size, pci_ring_size, NULL, 0,\n\t\t\t hv_pci_onchannelcallback, hbus);\n\tif (ret)\n\t\tgoto destroy_wq;\n\n\thv_set_drvdata(hdev, hbus);\n\n\tret = hv_pci_protocol_negotiation(hdev, pci_protocol_versions,\n\t\t\t\t\t  ARRAY_SIZE(pci_protocol_versions));\n\tif (ret)\n\t\tgoto close;\n\n\tret = hv_allocate_config_window(hbus);\n\tif (ret)\n\t\tgoto close;\n\n\thbus->cfg_addr = ioremap(hbus->mem_config->start,\n\t\t\t\t PCI_CONFIG_MMIO_LENGTH);\n\tif (!hbus->cfg_addr) {\n\t\tdev_err(&hdev->device,\n\t\t\t\"Unable to map a virtual address for config space\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_config;\n\t}\n\n\tname = kasprintf(GFP_KERNEL, \"%pUL\", &hdev->dev_instance);\n\tif (!name) {\n\t\tret = -ENOMEM;\n\t\tgoto unmap;\n\t}\n\n\thbus->fwnode = irq_domain_alloc_named_fwnode(name);\n\tkfree(name);\n\tif (!hbus->fwnode) {\n\t\tret = -ENOMEM;\n\t\tgoto unmap;\n\t}\n\n\tret = hv_pcie_init_irq_domain(hbus);\n\tif (ret)\n\t\tgoto free_fwnode;\n\n\tret = hv_pci_query_relations(hdev);\n\tif (ret)\n\t\tgoto free_irq_domain;\n\n\tmutex_lock(&hbus->state_lock);\n\n\tret = hv_pci_enter_d0(hdev);\n\tif (ret)\n\t\tgoto release_state_lock;\n\n\tret = hv_pci_allocate_bridge_windows(hbus);\n\tif (ret)\n\t\tgoto exit_d0;\n\n\tret = hv_send_resources_allocated(hdev);\n\tif (ret)\n\t\tgoto free_windows;\n\n\tprepopulate_bars(hbus);\n\n\thbus->state = hv_pcibus_probed;\n\n\tret = create_root_hv_pci_bus(hbus);\n\tif (ret)\n\t\tgoto free_windows;\n\n\tmutex_unlock(&hbus->state_lock);\n\treturn 0;\n\nfree_windows:\n\thv_pci_free_bridge_windows(hbus);\nexit_d0:\n\t(void) hv_pci_bus_exit(hdev, true);\nrelease_state_lock:\n\tmutex_unlock(&hbus->state_lock);\nfree_irq_domain:\n\tirq_domain_remove(hbus->irq_domain);\nfree_fwnode:\n\tirq_domain_free_fwnode(hbus->fwnode);\nunmap:\n\tiounmap(hbus->cfg_addr);\nfree_config:\n\thv_free_config_window(hbus);\nclose:\n\tvmbus_close(hdev->channel);\ndestroy_wq:\n\tdestroy_workqueue(hbus->wq);\nfree_dom:\n\thv_put_dom_num(hbus->bridge->domain_nr);\nfree_bus:\n\tkfree(hbus);\n\treturn ret;\n}\n\nstatic int hv_pci_bus_exit(struct hv_device *hdev, bool keep_devs)\n{\n\tstruct hv_pcibus_device *hbus = hv_get_drvdata(hdev);\n\tstruct vmbus_channel *chan = hdev->channel;\n\tstruct {\n\t\tstruct pci_packet teardown_packet;\n\t\tu8 buffer[sizeof(struct pci_message)];\n\t} pkt;\n\tstruct hv_pci_compl comp_pkt;\n\tstruct hv_pci_dev *hpdev, *tmp;\n\tunsigned long flags;\n\tu64 trans_id;\n\tint ret;\n\n\t \n\tif (chan->rescind)\n\t\treturn 0;\n\n\tif (!keep_devs) {\n\t\tstruct list_head removed;\n\n\t\t \n\t\tINIT_LIST_HEAD(&removed);\n\t\tspin_lock_irqsave(&hbus->device_list_lock, flags);\n\t\tlist_for_each_entry_safe(hpdev, tmp, &hbus->children, list_entry)\n\t\t\tlist_move_tail(&hpdev->list_entry, &removed);\n\t\tspin_unlock_irqrestore(&hbus->device_list_lock, flags);\n\n\t\t \n\t\tlist_for_each_entry_safe(hpdev, tmp, &removed, list_entry) {\n\t\t\tlist_del(&hpdev->list_entry);\n\t\t\tif (hpdev->pci_slot)\n\t\t\t\tpci_destroy_slot(hpdev->pci_slot);\n\t\t\t \n\t\t\tput_pcichild(hpdev);\n\t\t\tput_pcichild(hpdev);\n\t\t}\n\t}\n\n\tret = hv_send_resources_released(hdev);\n\tif (ret) {\n\t\tdev_err(&hdev->device,\n\t\t\t\"Couldn't send resources released packet(s)\\n\");\n\t\treturn ret;\n\t}\n\n\tmemset(&pkt.teardown_packet, 0, sizeof(pkt.teardown_packet));\n\tinit_completion(&comp_pkt.host_event);\n\tpkt.teardown_packet.completion_func = hv_pci_generic_compl;\n\tpkt.teardown_packet.compl_ctxt = &comp_pkt;\n\tpkt.teardown_packet.message[0].type = PCI_BUS_D0EXIT;\n\n\tret = vmbus_sendpacket_getid(chan, &pkt.teardown_packet.message,\n\t\t\t\t     sizeof(struct pci_message),\n\t\t\t\t     (unsigned long)&pkt.teardown_packet,\n\t\t\t\t     &trans_id, VM_PKT_DATA_INBAND,\n\t\t\t\t     VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);\n\tif (ret)\n\t\treturn ret;\n\n\tif (wait_for_completion_timeout(&comp_pkt.host_event, 10 * HZ) == 0) {\n\t\t \n\t\tvmbus_request_addr_match(chan, trans_id,\n\t\t\t\t\t (unsigned long)&pkt.teardown_packet);\n\t\treturn -ETIMEDOUT;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void hv_pci_remove(struct hv_device *hdev)\n{\n\tstruct hv_pcibus_device *hbus;\n\n\thbus = hv_get_drvdata(hdev);\n\tif (hbus->state == hv_pcibus_installed) {\n\t\ttasklet_disable(&hdev->channel->callback_event);\n\t\thbus->state = hv_pcibus_removing;\n\t\ttasklet_enable(&hdev->channel->callback_event);\n\t\tdestroy_workqueue(hbus->wq);\n\t\thbus->wq = NULL;\n\t\t \n\n\t\t \n\t\tpci_lock_rescan_remove();\n\t\tpci_stop_root_bus(hbus->bridge->bus);\n\t\thv_pci_remove_slots(hbus);\n\t\tpci_remove_root_bus(hbus->bridge->bus);\n\t\tpci_unlock_rescan_remove();\n\t}\n\n\thv_pci_bus_exit(hdev, false);\n\n\tvmbus_close(hdev->channel);\n\n\tiounmap(hbus->cfg_addr);\n\thv_free_config_window(hbus);\n\thv_pci_free_bridge_windows(hbus);\n\tirq_domain_remove(hbus->irq_domain);\n\tirq_domain_free_fwnode(hbus->fwnode);\n\n\thv_put_dom_num(hbus->bridge->domain_nr);\n\n\tkfree(hbus);\n}\n\nstatic int hv_pci_suspend(struct hv_device *hdev)\n{\n\tstruct hv_pcibus_device *hbus = hv_get_drvdata(hdev);\n\tenum hv_pcibus_state old_state;\n\tint ret;\n\n\t \n\ttasklet_disable(&hdev->channel->callback_event);\n\n\t \n\told_state = hbus->state;\n\tif (hbus->state == hv_pcibus_installed)\n\t\thbus->state = hv_pcibus_removing;\n\n\ttasklet_enable(&hdev->channel->callback_event);\n\n\tif (old_state != hv_pcibus_installed)\n\t\treturn -EINVAL;\n\n\tflush_workqueue(hbus->wq);\n\n\tret = hv_pci_bus_exit(hdev, true);\n\tif (ret)\n\t\treturn ret;\n\n\tvmbus_close(hdev->channel);\n\n\treturn 0;\n}\n\nstatic int hv_pci_restore_msi_msg(struct pci_dev *pdev, void *arg)\n{\n\tstruct irq_data *irq_data;\n\tstruct msi_desc *entry;\n\tint ret = 0;\n\n\tif (!pdev->msi_enabled && !pdev->msix_enabled)\n\t\treturn 0;\n\n\tmsi_lock_descs(&pdev->dev);\n\tmsi_for_each_desc(entry, &pdev->dev, MSI_DESC_ASSOCIATED) {\n\t\tirq_data = irq_get_irq_data(entry->irq);\n\t\tif (WARN_ON_ONCE(!irq_data)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\thv_compose_msi_msg(irq_data, &entry->msg);\n\t}\n\tmsi_unlock_descs(&pdev->dev);\n\n\treturn ret;\n}\n\n \nstatic void hv_pci_restore_msi_state(struct hv_pcibus_device *hbus)\n{\n\tpci_walk_bus(hbus->bridge->bus, hv_pci_restore_msi_msg, NULL);\n}\n\nstatic int hv_pci_resume(struct hv_device *hdev)\n{\n\tstruct hv_pcibus_device *hbus = hv_get_drvdata(hdev);\n\tenum pci_protocol_version_t version[1];\n\tint ret;\n\n\thbus->state = hv_pcibus_init;\n\n\thdev->channel->next_request_id_callback = vmbus_next_request_id;\n\thdev->channel->request_addr_callback = vmbus_request_addr;\n\thdev->channel->rqstor_size = HV_PCI_RQSTOR_SIZE;\n\n\tret = vmbus_open(hdev->channel, pci_ring_size, pci_ring_size, NULL, 0,\n\t\t\t hv_pci_onchannelcallback, hbus);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tversion[0] = hbus->protocol_version;\n\tret = hv_pci_protocol_negotiation(hdev, version, 1);\n\tif (ret)\n\t\tgoto out;\n\n\tret = hv_pci_query_relations(hdev);\n\tif (ret)\n\t\tgoto out;\n\n\tmutex_lock(&hbus->state_lock);\n\n\tret = hv_pci_enter_d0(hdev);\n\tif (ret)\n\t\tgoto release_state_lock;\n\n\tret = hv_send_resources_allocated(hdev);\n\tif (ret)\n\t\tgoto release_state_lock;\n\n\tprepopulate_bars(hbus);\n\n\thv_pci_restore_msi_state(hbus);\n\n\thbus->state = hv_pcibus_installed;\n\tmutex_unlock(&hbus->state_lock);\n\treturn 0;\n\nrelease_state_lock:\n\tmutex_unlock(&hbus->state_lock);\nout:\n\tvmbus_close(hdev->channel);\n\treturn ret;\n}\n\nstatic const struct hv_vmbus_device_id hv_pci_id_table[] = {\n\t \n\t \n\t{ HV_PCIE_GUID, },\n\t{ },\n};\n\nMODULE_DEVICE_TABLE(vmbus, hv_pci_id_table);\n\nstatic struct hv_driver hv_pci_drv = {\n\t.name\t\t= \"hv_pci\",\n\t.id_table\t= hv_pci_id_table,\n\t.probe\t\t= hv_pci_probe,\n\t.remove\t\t= hv_pci_remove,\n\t.suspend\t= hv_pci_suspend,\n\t.resume\t\t= hv_pci_resume,\n};\n\nstatic void __exit exit_hv_pci_drv(void)\n{\n\tvmbus_driver_unregister(&hv_pci_drv);\n\n\thvpci_block_ops.read_block = NULL;\n\thvpci_block_ops.write_block = NULL;\n\thvpci_block_ops.reg_blk_invalidate = NULL;\n}\n\nstatic int __init init_hv_pci_drv(void)\n{\n\tint ret;\n\n\tif (!hv_is_hyperv_initialized())\n\t\treturn -ENODEV;\n\n\tret = hv_pci_irqchip_init();\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tset_bit(HVPCI_DOM_INVALID, hvpci_dom_map);\n\n\t \n\thvpci_block_ops.read_block = hv_read_config_block;\n\thvpci_block_ops.write_block = hv_write_config_block;\n\thvpci_block_ops.reg_blk_invalidate = hv_register_block_invalidate;\n\n\treturn vmbus_driver_register(&hv_pci_drv);\n}\n\nmodule_init(init_hv_pci_drv);\nmodule_exit(exit_hv_pci_drv);\n\nMODULE_DESCRIPTION(\"Hyper-V PCI\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}