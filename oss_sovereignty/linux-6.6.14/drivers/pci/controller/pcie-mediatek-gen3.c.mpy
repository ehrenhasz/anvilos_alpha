{
  "module_name": "pcie-mediatek-gen3.c",
  "hash_id": "e40c52cc90fcbb27045059406c8c4819f9ff3d71a433a29a6b54cc4c15771c79",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/controller/pcie-mediatek-gen3.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/iopoll.h>\n#include <linux/irq.h>\n#include <linux/irqchip/chained_irq.h>\n#include <linux/irqdomain.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/msi.h>\n#include <linux/pci.h>\n#include <linux/phy/phy.h>\n#include <linux/platform_device.h>\n#include <linux/pm_domain.h>\n#include <linux/pm_runtime.h>\n#include <linux/reset.h>\n\n#include \"../pci.h\"\n\n#define PCIE_SETTING_REG\t\t0x80\n#define PCIE_PCI_IDS_1\t\t\t0x9c\n#define PCI_CLASS(class)\t\t(class << 8)\n#define PCIE_RC_MODE\t\t\tBIT(0)\n\n#define PCIE_CFGNUM_REG\t\t\t0x140\n#define PCIE_CFG_DEVFN(devfn)\t\t((devfn) & GENMASK(7, 0))\n#define PCIE_CFG_BUS(bus)\t\t(((bus) << 8) & GENMASK(15, 8))\n#define PCIE_CFG_BYTE_EN(bytes)\t\t(((bytes) << 16) & GENMASK(19, 16))\n#define PCIE_CFG_FORCE_BYTE_EN\t\tBIT(20)\n#define PCIE_CFG_OFFSET_ADDR\t\t0x1000\n#define PCIE_CFG_HEADER(bus, devfn) \\\n\t(PCIE_CFG_BUS(bus) | PCIE_CFG_DEVFN(devfn))\n\n#define PCIE_RST_CTRL_REG\t\t0x148\n#define PCIE_MAC_RSTB\t\t\tBIT(0)\n#define PCIE_PHY_RSTB\t\t\tBIT(1)\n#define PCIE_BRG_RSTB\t\t\tBIT(2)\n#define PCIE_PE_RSTB\t\t\tBIT(3)\n\n#define PCIE_LTSSM_STATUS_REG\t\t0x150\n#define PCIE_LTSSM_STATE_MASK\t\tGENMASK(28, 24)\n#define PCIE_LTSSM_STATE(val)\t\t((val & PCIE_LTSSM_STATE_MASK) >> 24)\n#define PCIE_LTSSM_STATE_L2_IDLE\t0x14\n\n#define PCIE_LINK_STATUS_REG\t\t0x154\n#define PCIE_PORT_LINKUP\t\tBIT(8)\n\n#define PCIE_MSI_SET_NUM\t\t8\n#define PCIE_MSI_IRQS_PER_SET\t\t32\n#define PCIE_MSI_IRQS_NUM \\\n\t(PCIE_MSI_IRQS_PER_SET * PCIE_MSI_SET_NUM)\n\n#define PCIE_INT_ENABLE_REG\t\t0x180\n#define PCIE_MSI_ENABLE\t\t\tGENMASK(PCIE_MSI_SET_NUM + 8 - 1, 8)\n#define PCIE_MSI_SHIFT\t\t\t8\n#define PCIE_INTX_SHIFT\t\t\t24\n#define PCIE_INTX_ENABLE \\\n\tGENMASK(PCIE_INTX_SHIFT + PCI_NUM_INTX - 1, PCIE_INTX_SHIFT)\n\n#define PCIE_INT_STATUS_REG\t\t0x184\n#define PCIE_MSI_SET_ENABLE_REG\t\t0x190\n#define PCIE_MSI_SET_ENABLE\t\tGENMASK(PCIE_MSI_SET_NUM - 1, 0)\n\n#define PCIE_MSI_SET_BASE_REG\t\t0xc00\n#define PCIE_MSI_SET_OFFSET\t\t0x10\n#define PCIE_MSI_SET_STATUS_OFFSET\t0x04\n#define PCIE_MSI_SET_ENABLE_OFFSET\t0x08\n\n#define PCIE_MSI_SET_ADDR_HI_BASE\t0xc80\n#define PCIE_MSI_SET_ADDR_HI_OFFSET\t0x04\n\n#define PCIE_ICMD_PM_REG\t\t0x198\n#define PCIE_TURN_OFF_LINK\t\tBIT(4)\n\n#define PCIE_MISC_CTRL_REG\t\t0x348\n#define PCIE_DISABLE_DVFSRC_VLT_REQ\tBIT(1)\n\n#define PCIE_TRANS_TABLE_BASE_REG\t0x800\n#define PCIE_ATR_SRC_ADDR_MSB_OFFSET\t0x4\n#define PCIE_ATR_TRSL_ADDR_LSB_OFFSET\t0x8\n#define PCIE_ATR_TRSL_ADDR_MSB_OFFSET\t0xc\n#define PCIE_ATR_TRSL_PARAM_OFFSET\t0x10\n#define PCIE_ATR_TLB_SET_OFFSET\t\t0x20\n\n#define PCIE_MAX_TRANS_TABLES\t\t8\n#define PCIE_ATR_EN\t\t\tBIT(0)\n#define PCIE_ATR_SIZE(size) \\\n\t(((((size) - 1) << 1) & GENMASK(6, 1)) | PCIE_ATR_EN)\n#define PCIE_ATR_ID(id)\t\t\t((id) & GENMASK(3, 0))\n#define PCIE_ATR_TYPE_MEM\t\tPCIE_ATR_ID(0)\n#define PCIE_ATR_TYPE_IO\t\tPCIE_ATR_ID(1)\n#define PCIE_ATR_TLP_TYPE(type)\t\t(((type) << 16) & GENMASK(18, 16))\n#define PCIE_ATR_TLP_TYPE_MEM\t\tPCIE_ATR_TLP_TYPE(0)\n#define PCIE_ATR_TLP_TYPE_IO\t\tPCIE_ATR_TLP_TYPE(2)\n\n \nstruct mtk_msi_set {\n\tvoid __iomem *base;\n\tphys_addr_t msg_addr;\n\tu32 saved_irq_state;\n};\n\n \nstruct mtk_gen3_pcie {\n\tstruct device *dev;\n\tvoid __iomem *base;\n\tphys_addr_t reg_base;\n\tstruct reset_control *mac_reset;\n\tstruct reset_control *phy_reset;\n\tstruct phy *phy;\n\tstruct clk_bulk_data *clks;\n\tint num_clks;\n\n\tint irq;\n\tu32 saved_irq_state;\n\traw_spinlock_t irq_lock;\n\tstruct irq_domain *intx_domain;\n\tstruct irq_domain *msi_domain;\n\tstruct irq_domain *msi_bottom_domain;\n\tstruct mtk_msi_set msi_sets[PCIE_MSI_SET_NUM];\n\tstruct mutex lock;\n\tDECLARE_BITMAP(msi_irq_in_use, PCIE_MSI_IRQS_NUM);\n};\n\n \nstatic const char *const ltssm_str[] = {\n\t\"detect.quiet\",\t\t\t \n\t\"detect.active\",\t\t \n\t\"polling.active\",\t\t \n\t\"polling.compliance\",\t\t \n\t\"polling.configuration\",\t \n\t\"config.linkwidthstart\",\t \n\t\"config.linkwidthaccept\",\t \n\t\"config.lanenumwait\",\t\t \n\t\"config.lanenumaccept\",\t\t \n\t\"config.complete\",\t\t \n\t\"config.idle\",\t\t\t \n\t\"recovery.receiverlock\",\t \n\t\"recovery.equalization\",\t \n\t\"recovery.speed\",\t\t \n\t\"recovery.receiverconfig\",\t \n\t\"recovery.idle\",\t\t \n\t\"L0\",\t\t\t\t \n\t\"L0s\",\t\t\t\t \n\t\"L1.entry\",\t\t\t \n\t\"L1.idle\",\t\t\t \n\t\"L2.idle\",\t\t\t \n\t\"L2.transmitwake\",\t\t \n\t\"disable\",\t\t\t \n\t\"loopback.entry\",\t\t \n\t\"loopback.active\",\t\t \n\t\"loopback.exit\",\t\t \n\t\"hotreset\",\t\t\t \n};\n\n \nstatic void mtk_pcie_config_tlp_header(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\t\tint where, int size)\n{\n\tstruct mtk_gen3_pcie *pcie = bus->sysdata;\n\tint bytes;\n\tu32 val;\n\n\tbytes = (GENMASK(size - 1, 0) & 0xf) << (where & 0x3);\n\n\tval = PCIE_CFG_FORCE_BYTE_EN | PCIE_CFG_BYTE_EN(bytes) |\n\t      PCIE_CFG_HEADER(bus->number, devfn);\n\n\twritel_relaxed(val, pcie->base + PCIE_CFGNUM_REG);\n}\n\nstatic void __iomem *mtk_pcie_map_bus(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\t      int where)\n{\n\tstruct mtk_gen3_pcie *pcie = bus->sysdata;\n\n\treturn pcie->base + PCIE_CFG_OFFSET_ADDR + where;\n}\n\nstatic int mtk_pcie_config_read(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\tint where, int size, u32 *val)\n{\n\tmtk_pcie_config_tlp_header(bus, devfn, where, size);\n\n\treturn pci_generic_config_read32(bus, devfn, where, size, val);\n}\n\nstatic int mtk_pcie_config_write(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\t int where, int size, u32 val)\n{\n\tmtk_pcie_config_tlp_header(bus, devfn, where, size);\n\n\tif (size <= 2)\n\t\tval <<= (where & 0x3) * 8;\n\n\treturn pci_generic_config_write32(bus, devfn, where, 4, val);\n}\n\nstatic struct pci_ops mtk_pcie_ops = {\n\t.map_bus = mtk_pcie_map_bus,\n\t.read  = mtk_pcie_config_read,\n\t.write = mtk_pcie_config_write,\n};\n\nstatic int mtk_pcie_set_trans_table(struct mtk_gen3_pcie *pcie,\n\t\t\t\t    resource_size_t cpu_addr,\n\t\t\t\t    resource_size_t pci_addr,\n\t\t\t\t    resource_size_t size,\n\t\t\t\t    unsigned long type, int *num)\n{\n\tresource_size_t remaining = size;\n\tresource_size_t table_size;\n\tresource_size_t addr_align;\n\tconst char *range_type;\n\tvoid __iomem *table;\n\tu32 val;\n\n\twhile (remaining && (*num < PCIE_MAX_TRANS_TABLES)) {\n\t\t \n\t\ttable_size = BIT(fls(remaining) - 1);\n\n\t\tif (cpu_addr > 0) {\n\t\t\taddr_align = BIT(ffs(cpu_addr) - 1);\n\t\t\ttable_size = min(table_size, addr_align);\n\t\t}\n\n\t\t \n\t\tif (table_size < 0x1000) {\n\t\t\tdev_err(pcie->dev, \"illegal table size %#llx\\n\",\n\t\t\t\t(unsigned long long)table_size);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\ttable = pcie->base + PCIE_TRANS_TABLE_BASE_REG + *num * PCIE_ATR_TLB_SET_OFFSET;\n\t\twritel_relaxed(lower_32_bits(cpu_addr) | PCIE_ATR_SIZE(fls(table_size) - 1), table);\n\t\twritel_relaxed(upper_32_bits(cpu_addr), table + PCIE_ATR_SRC_ADDR_MSB_OFFSET);\n\t\twritel_relaxed(lower_32_bits(pci_addr), table + PCIE_ATR_TRSL_ADDR_LSB_OFFSET);\n\t\twritel_relaxed(upper_32_bits(pci_addr), table + PCIE_ATR_TRSL_ADDR_MSB_OFFSET);\n\n\t\tif (type == IORESOURCE_IO) {\n\t\t\tval = PCIE_ATR_TYPE_IO | PCIE_ATR_TLP_TYPE_IO;\n\t\t\trange_type = \"IO\";\n\t\t} else {\n\t\t\tval = PCIE_ATR_TYPE_MEM | PCIE_ATR_TLP_TYPE_MEM;\n\t\t\trange_type = \"MEM\";\n\t\t}\n\n\t\twritel_relaxed(val, table + PCIE_ATR_TRSL_PARAM_OFFSET);\n\n\t\tdev_dbg(pcie->dev, \"set %s trans window[%d]: cpu_addr = %#llx, pci_addr = %#llx, size = %#llx\\n\",\n\t\t\trange_type, *num, (unsigned long long)cpu_addr,\n\t\t\t(unsigned long long)pci_addr, (unsigned long long)table_size);\n\n\t\tcpu_addr += table_size;\n\t\tpci_addr += table_size;\n\t\tremaining -= table_size;\n\t\t(*num)++;\n\t}\n\n\tif (remaining)\n\t\tdev_warn(pcie->dev, \"not enough translate table for addr: %#llx, limited to [%d]\\n\",\n\t\t\t (unsigned long long)cpu_addr, PCIE_MAX_TRANS_TABLES);\n\n\treturn 0;\n}\n\nstatic void mtk_pcie_enable_msi(struct mtk_gen3_pcie *pcie)\n{\n\tint i;\n\tu32 val;\n\n\tfor (i = 0; i < PCIE_MSI_SET_NUM; i++) {\n\t\tstruct mtk_msi_set *msi_set = &pcie->msi_sets[i];\n\n\t\tmsi_set->base = pcie->base + PCIE_MSI_SET_BASE_REG +\n\t\t\t\ti * PCIE_MSI_SET_OFFSET;\n\t\tmsi_set->msg_addr = pcie->reg_base + PCIE_MSI_SET_BASE_REG +\n\t\t\t\t    i * PCIE_MSI_SET_OFFSET;\n\n\t\t \n\t\twritel_relaxed(lower_32_bits(msi_set->msg_addr), msi_set->base);\n\t\twritel_relaxed(upper_32_bits(msi_set->msg_addr),\n\t\t\t       pcie->base + PCIE_MSI_SET_ADDR_HI_BASE +\n\t\t\t       i * PCIE_MSI_SET_ADDR_HI_OFFSET);\n\t}\n\n\tval = readl_relaxed(pcie->base + PCIE_MSI_SET_ENABLE_REG);\n\tval |= PCIE_MSI_SET_ENABLE;\n\twritel_relaxed(val, pcie->base + PCIE_MSI_SET_ENABLE_REG);\n\n\tval = readl_relaxed(pcie->base + PCIE_INT_ENABLE_REG);\n\tval |= PCIE_MSI_ENABLE;\n\twritel_relaxed(val, pcie->base + PCIE_INT_ENABLE_REG);\n}\n\nstatic int mtk_pcie_startup_port(struct mtk_gen3_pcie *pcie)\n{\n\tstruct resource_entry *entry;\n\tstruct pci_host_bridge *host = pci_host_bridge_from_priv(pcie);\n\tunsigned int table_index = 0;\n\tint err;\n\tu32 val;\n\n\t \n\tval = readl_relaxed(pcie->base + PCIE_SETTING_REG);\n\tval |= PCIE_RC_MODE;\n\twritel_relaxed(val, pcie->base + PCIE_SETTING_REG);\n\n\t \n\tval = readl_relaxed(pcie->base + PCIE_PCI_IDS_1);\n\tval &= ~GENMASK(31, 8);\n\tval |= PCI_CLASS(PCI_CLASS_BRIDGE_PCI_NORMAL);\n\twritel_relaxed(val, pcie->base + PCIE_PCI_IDS_1);\n\n\t \n\tval = readl_relaxed(pcie->base + PCIE_INT_ENABLE_REG);\n\tval &= ~PCIE_INTX_ENABLE;\n\twritel_relaxed(val, pcie->base + PCIE_INT_ENABLE_REG);\n\n\t \n\tval = readl_relaxed(pcie->base + PCIE_MISC_CTRL_REG);\n\tval |= PCIE_DISABLE_DVFSRC_VLT_REQ;\n\twritel_relaxed(val, pcie->base + PCIE_MISC_CTRL_REG);\n\n\t \n\tval = readl_relaxed(pcie->base + PCIE_RST_CTRL_REG);\n\tval |= PCIE_MAC_RSTB | PCIE_PHY_RSTB | PCIE_BRG_RSTB | PCIE_PE_RSTB;\n\twritel_relaxed(val, pcie->base + PCIE_RST_CTRL_REG);\n\n\t \n\tmsleep(100);\n\n\t \n\tval &= ~(PCIE_MAC_RSTB | PCIE_PHY_RSTB | PCIE_BRG_RSTB | PCIE_PE_RSTB);\n\twritel_relaxed(val, pcie->base + PCIE_RST_CTRL_REG);\n\n\t \n\terr = readl_poll_timeout(pcie->base + PCIE_LINK_STATUS_REG, val,\n\t\t\t\t !!(val & PCIE_PORT_LINKUP), 20,\n\t\t\t\t PCI_PM_D3COLD_WAIT * USEC_PER_MSEC);\n\tif (err) {\n\t\tconst char *ltssm_state;\n\t\tint ltssm_index;\n\n\t\tval = readl_relaxed(pcie->base + PCIE_LTSSM_STATUS_REG);\n\t\tltssm_index = PCIE_LTSSM_STATE(val);\n\t\tltssm_state = ltssm_index >= ARRAY_SIZE(ltssm_str) ?\n\t\t\t      \"Unknown state\" : ltssm_str[ltssm_index];\n\t\tdev_err(pcie->dev,\n\t\t\t\"PCIe link down, current LTSSM state: %s (%#x)\\n\",\n\t\t\tltssm_state, val);\n\t\treturn err;\n\t}\n\n\tmtk_pcie_enable_msi(pcie);\n\n\t \n\tresource_list_for_each_entry(entry, &host->windows) {\n\t\tstruct resource *res = entry->res;\n\t\tunsigned long type = resource_type(res);\n\t\tresource_size_t cpu_addr;\n\t\tresource_size_t pci_addr;\n\t\tresource_size_t size;\n\n\t\tif (type == IORESOURCE_IO)\n\t\t\tcpu_addr = pci_pio_to_address(res->start);\n\t\telse if (type == IORESOURCE_MEM)\n\t\t\tcpu_addr = res->start;\n\t\telse\n\t\t\tcontinue;\n\n\t\tpci_addr = res->start - entry->offset;\n\t\tsize = resource_size(res);\n\t\terr = mtk_pcie_set_trans_table(pcie, cpu_addr, pci_addr, size,\n\t\t\t\t\t       type, &table_index);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int mtk_pcie_set_affinity(struct irq_data *data,\n\t\t\t\t const struct cpumask *mask, bool force)\n{\n\treturn -EINVAL;\n}\n\nstatic void mtk_pcie_msi_irq_mask(struct irq_data *data)\n{\n\tpci_msi_mask_irq(data);\n\tirq_chip_mask_parent(data);\n}\n\nstatic void mtk_pcie_msi_irq_unmask(struct irq_data *data)\n{\n\tpci_msi_unmask_irq(data);\n\tirq_chip_unmask_parent(data);\n}\n\nstatic struct irq_chip mtk_msi_irq_chip = {\n\t.irq_ack = irq_chip_ack_parent,\n\t.irq_mask = mtk_pcie_msi_irq_mask,\n\t.irq_unmask = mtk_pcie_msi_irq_unmask,\n\t.name = \"MSI\",\n};\n\nstatic struct msi_domain_info mtk_msi_domain_info = {\n\t.flags\t= (MSI_FLAG_USE_DEF_DOM_OPS | MSI_FLAG_USE_DEF_CHIP_OPS |\n\t\t   MSI_FLAG_PCI_MSIX | MSI_FLAG_MULTI_PCI_MSI),\n\t.chip\t= &mtk_msi_irq_chip,\n};\n\nstatic void mtk_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)\n{\n\tstruct mtk_msi_set *msi_set = irq_data_get_irq_chip_data(data);\n\tstruct mtk_gen3_pcie *pcie = data->domain->host_data;\n\tunsigned long hwirq;\n\n\thwirq =\tdata->hwirq % PCIE_MSI_IRQS_PER_SET;\n\n\tmsg->address_hi = upper_32_bits(msi_set->msg_addr);\n\tmsg->address_lo = lower_32_bits(msi_set->msg_addr);\n\tmsg->data = hwirq;\n\tdev_dbg(pcie->dev, \"msi#%#lx address_hi %#x address_lo %#x data %d\\n\",\n\t\thwirq, msg->address_hi, msg->address_lo, msg->data);\n}\n\nstatic void mtk_msi_bottom_irq_ack(struct irq_data *data)\n{\n\tstruct mtk_msi_set *msi_set = irq_data_get_irq_chip_data(data);\n\tunsigned long hwirq;\n\n\thwirq =\tdata->hwirq % PCIE_MSI_IRQS_PER_SET;\n\n\twritel_relaxed(BIT(hwirq), msi_set->base + PCIE_MSI_SET_STATUS_OFFSET);\n}\n\nstatic void mtk_msi_bottom_irq_mask(struct irq_data *data)\n{\n\tstruct mtk_msi_set *msi_set = irq_data_get_irq_chip_data(data);\n\tstruct mtk_gen3_pcie *pcie = data->domain->host_data;\n\tunsigned long hwirq, flags;\n\tu32 val;\n\n\thwirq =\tdata->hwirq % PCIE_MSI_IRQS_PER_SET;\n\n\traw_spin_lock_irqsave(&pcie->irq_lock, flags);\n\tval = readl_relaxed(msi_set->base + PCIE_MSI_SET_ENABLE_OFFSET);\n\tval &= ~BIT(hwirq);\n\twritel_relaxed(val, msi_set->base + PCIE_MSI_SET_ENABLE_OFFSET);\n\traw_spin_unlock_irqrestore(&pcie->irq_lock, flags);\n}\n\nstatic void mtk_msi_bottom_irq_unmask(struct irq_data *data)\n{\n\tstruct mtk_msi_set *msi_set = irq_data_get_irq_chip_data(data);\n\tstruct mtk_gen3_pcie *pcie = data->domain->host_data;\n\tunsigned long hwirq, flags;\n\tu32 val;\n\n\thwirq =\tdata->hwirq % PCIE_MSI_IRQS_PER_SET;\n\n\traw_spin_lock_irqsave(&pcie->irq_lock, flags);\n\tval = readl_relaxed(msi_set->base + PCIE_MSI_SET_ENABLE_OFFSET);\n\tval |= BIT(hwirq);\n\twritel_relaxed(val, msi_set->base + PCIE_MSI_SET_ENABLE_OFFSET);\n\traw_spin_unlock_irqrestore(&pcie->irq_lock, flags);\n}\n\nstatic struct irq_chip mtk_msi_bottom_irq_chip = {\n\t.irq_ack\t\t= mtk_msi_bottom_irq_ack,\n\t.irq_mask\t\t= mtk_msi_bottom_irq_mask,\n\t.irq_unmask\t\t= mtk_msi_bottom_irq_unmask,\n\t.irq_compose_msi_msg\t= mtk_compose_msi_msg,\n\t.irq_set_affinity\t= mtk_pcie_set_affinity,\n\t.name\t\t\t= \"MSI\",\n};\n\nstatic int mtk_msi_bottom_domain_alloc(struct irq_domain *domain,\n\t\t\t\t       unsigned int virq, unsigned int nr_irqs,\n\t\t\t\t       void *arg)\n{\n\tstruct mtk_gen3_pcie *pcie = domain->host_data;\n\tstruct mtk_msi_set *msi_set;\n\tint i, hwirq, set_idx;\n\n\tmutex_lock(&pcie->lock);\n\n\thwirq = bitmap_find_free_region(pcie->msi_irq_in_use, PCIE_MSI_IRQS_NUM,\n\t\t\t\t\torder_base_2(nr_irqs));\n\n\tmutex_unlock(&pcie->lock);\n\n\tif (hwirq < 0)\n\t\treturn -ENOSPC;\n\n\tset_idx = hwirq / PCIE_MSI_IRQS_PER_SET;\n\tmsi_set = &pcie->msi_sets[set_idx];\n\n\tfor (i = 0; i < nr_irqs; i++)\n\t\tirq_domain_set_info(domain, virq + i, hwirq + i,\n\t\t\t\t    &mtk_msi_bottom_irq_chip, msi_set,\n\t\t\t\t    handle_edge_irq, NULL, NULL);\n\n\treturn 0;\n}\n\nstatic void mtk_msi_bottom_domain_free(struct irq_domain *domain,\n\t\t\t\t       unsigned int virq, unsigned int nr_irqs)\n{\n\tstruct mtk_gen3_pcie *pcie = domain->host_data;\n\tstruct irq_data *data = irq_domain_get_irq_data(domain, virq);\n\n\tmutex_lock(&pcie->lock);\n\n\tbitmap_release_region(pcie->msi_irq_in_use, data->hwirq,\n\t\t\t      order_base_2(nr_irqs));\n\n\tmutex_unlock(&pcie->lock);\n\n\tirq_domain_free_irqs_common(domain, virq, nr_irqs);\n}\n\nstatic const struct irq_domain_ops mtk_msi_bottom_domain_ops = {\n\t.alloc = mtk_msi_bottom_domain_alloc,\n\t.free = mtk_msi_bottom_domain_free,\n};\n\nstatic void mtk_intx_mask(struct irq_data *data)\n{\n\tstruct mtk_gen3_pcie *pcie = irq_data_get_irq_chip_data(data);\n\tunsigned long flags;\n\tu32 val;\n\n\traw_spin_lock_irqsave(&pcie->irq_lock, flags);\n\tval = readl_relaxed(pcie->base + PCIE_INT_ENABLE_REG);\n\tval &= ~BIT(data->hwirq + PCIE_INTX_SHIFT);\n\twritel_relaxed(val, pcie->base + PCIE_INT_ENABLE_REG);\n\traw_spin_unlock_irqrestore(&pcie->irq_lock, flags);\n}\n\nstatic void mtk_intx_unmask(struct irq_data *data)\n{\n\tstruct mtk_gen3_pcie *pcie = irq_data_get_irq_chip_data(data);\n\tunsigned long flags;\n\tu32 val;\n\n\traw_spin_lock_irqsave(&pcie->irq_lock, flags);\n\tval = readl_relaxed(pcie->base + PCIE_INT_ENABLE_REG);\n\tval |= BIT(data->hwirq + PCIE_INTX_SHIFT);\n\twritel_relaxed(val, pcie->base + PCIE_INT_ENABLE_REG);\n\traw_spin_unlock_irqrestore(&pcie->irq_lock, flags);\n}\n\n \nstatic void mtk_intx_eoi(struct irq_data *data)\n{\n\tstruct mtk_gen3_pcie *pcie = irq_data_get_irq_chip_data(data);\n\tunsigned long hwirq;\n\n\thwirq = data->hwirq + PCIE_INTX_SHIFT;\n\twritel_relaxed(BIT(hwirq), pcie->base + PCIE_INT_STATUS_REG);\n}\n\nstatic struct irq_chip mtk_intx_irq_chip = {\n\t.irq_mask\t\t= mtk_intx_mask,\n\t.irq_unmask\t\t= mtk_intx_unmask,\n\t.irq_eoi\t\t= mtk_intx_eoi,\n\t.irq_set_affinity\t= mtk_pcie_set_affinity,\n\t.name\t\t\t= \"INTx\",\n};\n\nstatic int mtk_pcie_intx_map(struct irq_domain *domain, unsigned int irq,\n\t\t\t     irq_hw_number_t hwirq)\n{\n\tirq_set_chip_data(irq, domain->host_data);\n\tirq_set_chip_and_handler_name(irq, &mtk_intx_irq_chip,\n\t\t\t\t      handle_fasteoi_irq, \"INTx\");\n\treturn 0;\n}\n\nstatic const struct irq_domain_ops intx_domain_ops = {\n\t.map = mtk_pcie_intx_map,\n};\n\nstatic int mtk_pcie_init_irq_domains(struct mtk_gen3_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct device_node *intc_node, *node = dev->of_node;\n\tint ret;\n\n\traw_spin_lock_init(&pcie->irq_lock);\n\n\t \n\tintc_node = of_get_child_by_name(node, \"interrupt-controller\");\n\tif (!intc_node) {\n\t\tdev_err(dev, \"missing interrupt-controller node\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tpcie->intx_domain = irq_domain_add_linear(intc_node, PCI_NUM_INTX,\n\t\t\t\t\t\t  &intx_domain_ops, pcie);\n\tif (!pcie->intx_domain) {\n\t\tdev_err(dev, \"failed to create INTx IRQ domain\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_put_node;\n\t}\n\n\t \n\tmutex_init(&pcie->lock);\n\n\tpcie->msi_bottom_domain = irq_domain_add_linear(node, PCIE_MSI_IRQS_NUM,\n\t\t\t\t  &mtk_msi_bottom_domain_ops, pcie);\n\tif (!pcie->msi_bottom_domain) {\n\t\tdev_err(dev, \"failed to create MSI bottom domain\\n\");\n\t\tret = -ENODEV;\n\t\tgoto err_msi_bottom_domain;\n\t}\n\n\tpcie->msi_domain = pci_msi_create_irq_domain(dev->fwnode,\n\t\t\t\t\t\t     &mtk_msi_domain_info,\n\t\t\t\t\t\t     pcie->msi_bottom_domain);\n\tif (!pcie->msi_domain) {\n\t\tdev_err(dev, \"failed to create MSI domain\\n\");\n\t\tret = -ENODEV;\n\t\tgoto err_msi_domain;\n\t}\n\n\tof_node_put(intc_node);\n\treturn 0;\n\nerr_msi_domain:\n\tirq_domain_remove(pcie->msi_bottom_domain);\nerr_msi_bottom_domain:\n\tirq_domain_remove(pcie->intx_domain);\nout_put_node:\n\tof_node_put(intc_node);\n\treturn ret;\n}\n\nstatic void mtk_pcie_irq_teardown(struct mtk_gen3_pcie *pcie)\n{\n\tirq_set_chained_handler_and_data(pcie->irq, NULL, NULL);\n\n\tif (pcie->intx_domain)\n\t\tirq_domain_remove(pcie->intx_domain);\n\n\tif (pcie->msi_domain)\n\t\tirq_domain_remove(pcie->msi_domain);\n\n\tif (pcie->msi_bottom_domain)\n\t\tirq_domain_remove(pcie->msi_bottom_domain);\n\n\tirq_dispose_mapping(pcie->irq);\n}\n\nstatic void mtk_pcie_msi_handler(struct mtk_gen3_pcie *pcie, int set_idx)\n{\n\tstruct mtk_msi_set *msi_set = &pcie->msi_sets[set_idx];\n\tunsigned long msi_enable, msi_status;\n\tirq_hw_number_t bit, hwirq;\n\n\tmsi_enable = readl_relaxed(msi_set->base + PCIE_MSI_SET_ENABLE_OFFSET);\n\n\tdo {\n\t\tmsi_status = readl_relaxed(msi_set->base +\n\t\t\t\t\t   PCIE_MSI_SET_STATUS_OFFSET);\n\t\tmsi_status &= msi_enable;\n\t\tif (!msi_status)\n\t\t\tbreak;\n\n\t\tfor_each_set_bit(bit, &msi_status, PCIE_MSI_IRQS_PER_SET) {\n\t\t\thwirq = bit + set_idx * PCIE_MSI_IRQS_PER_SET;\n\t\t\tgeneric_handle_domain_irq(pcie->msi_bottom_domain, hwirq);\n\t\t}\n\t} while (true);\n}\n\nstatic void mtk_pcie_irq_handler(struct irq_desc *desc)\n{\n\tstruct mtk_gen3_pcie *pcie = irq_desc_get_handler_data(desc);\n\tstruct irq_chip *irqchip = irq_desc_get_chip(desc);\n\tunsigned long status;\n\tirq_hw_number_t irq_bit = PCIE_INTX_SHIFT;\n\n\tchained_irq_enter(irqchip, desc);\n\n\tstatus = readl_relaxed(pcie->base + PCIE_INT_STATUS_REG);\n\tfor_each_set_bit_from(irq_bit, &status, PCI_NUM_INTX +\n\t\t\t      PCIE_INTX_SHIFT)\n\t\tgeneric_handle_domain_irq(pcie->intx_domain,\n\t\t\t\t\t  irq_bit - PCIE_INTX_SHIFT);\n\n\tirq_bit = PCIE_MSI_SHIFT;\n\tfor_each_set_bit_from(irq_bit, &status, PCIE_MSI_SET_NUM +\n\t\t\t      PCIE_MSI_SHIFT) {\n\t\tmtk_pcie_msi_handler(pcie, irq_bit - PCIE_MSI_SHIFT);\n\n\t\twritel_relaxed(BIT(irq_bit), pcie->base + PCIE_INT_STATUS_REG);\n\t}\n\n\tchained_irq_exit(irqchip, desc);\n}\n\nstatic int mtk_pcie_setup_irq(struct mtk_gen3_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tint err;\n\n\terr = mtk_pcie_init_irq_domains(pcie);\n\tif (err)\n\t\treturn err;\n\n\tpcie->irq = platform_get_irq(pdev, 0);\n\tif (pcie->irq < 0)\n\t\treturn pcie->irq;\n\n\tirq_set_chained_handler_and_data(pcie->irq, mtk_pcie_irq_handler, pcie);\n\n\treturn 0;\n}\n\nstatic int mtk_pcie_parse_port(struct mtk_gen3_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct resource *regs;\n\tint ret;\n\n\tregs = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"pcie-mac\");\n\tif (!regs)\n\t\treturn -EINVAL;\n\tpcie->base = devm_ioremap_resource(dev, regs);\n\tif (IS_ERR(pcie->base)) {\n\t\tdev_err(dev, \"failed to map register base\\n\");\n\t\treturn PTR_ERR(pcie->base);\n\t}\n\n\tpcie->reg_base = regs->start;\n\n\tpcie->phy_reset = devm_reset_control_get_optional_exclusive(dev, \"phy\");\n\tif (IS_ERR(pcie->phy_reset)) {\n\t\tret = PTR_ERR(pcie->phy_reset);\n\t\tif (ret != -EPROBE_DEFER)\n\t\t\tdev_err(dev, \"failed to get PHY reset\\n\");\n\n\t\treturn ret;\n\t}\n\n\tpcie->mac_reset = devm_reset_control_get_optional_exclusive(dev, \"mac\");\n\tif (IS_ERR(pcie->mac_reset)) {\n\t\tret = PTR_ERR(pcie->mac_reset);\n\t\tif (ret != -EPROBE_DEFER)\n\t\t\tdev_err(dev, \"failed to get MAC reset\\n\");\n\n\t\treturn ret;\n\t}\n\n\tpcie->phy = devm_phy_optional_get(dev, \"pcie-phy\");\n\tif (IS_ERR(pcie->phy)) {\n\t\tret = PTR_ERR(pcie->phy);\n\t\tif (ret != -EPROBE_DEFER)\n\t\t\tdev_err(dev, \"failed to get PHY\\n\");\n\n\t\treturn ret;\n\t}\n\n\tpcie->num_clks = devm_clk_bulk_get_all(dev, &pcie->clks);\n\tif (pcie->num_clks < 0) {\n\t\tdev_err(dev, \"failed to get clocks\\n\");\n\t\treturn pcie->num_clks;\n\t}\n\n\treturn 0;\n}\n\nstatic int mtk_pcie_power_up(struct mtk_gen3_pcie *pcie)\n{\n\tstruct device *dev = pcie->dev;\n\tint err;\n\n\t \n\treset_control_deassert(pcie->phy_reset);\n\n\terr = phy_init(pcie->phy);\n\tif (err) {\n\t\tdev_err(dev, \"failed to initialize PHY\\n\");\n\t\tgoto err_phy_init;\n\t}\n\n\terr = phy_power_on(pcie->phy);\n\tif (err) {\n\t\tdev_err(dev, \"failed to power on PHY\\n\");\n\t\tgoto err_phy_on;\n\t}\n\n\t \n\treset_control_deassert(pcie->mac_reset);\n\n\tpm_runtime_enable(dev);\n\tpm_runtime_get_sync(dev);\n\n\terr = clk_bulk_prepare_enable(pcie->num_clks, pcie->clks);\n\tif (err) {\n\t\tdev_err(dev, \"failed to enable clocks\\n\");\n\t\tgoto err_clk_init;\n\t}\n\n\treturn 0;\n\nerr_clk_init:\n\tpm_runtime_put_sync(dev);\n\tpm_runtime_disable(dev);\n\treset_control_assert(pcie->mac_reset);\n\tphy_power_off(pcie->phy);\nerr_phy_on:\n\tphy_exit(pcie->phy);\nerr_phy_init:\n\treset_control_assert(pcie->phy_reset);\n\n\treturn err;\n}\n\nstatic void mtk_pcie_power_down(struct mtk_gen3_pcie *pcie)\n{\n\tclk_bulk_disable_unprepare(pcie->num_clks, pcie->clks);\n\n\tpm_runtime_put_sync(pcie->dev);\n\tpm_runtime_disable(pcie->dev);\n\treset_control_assert(pcie->mac_reset);\n\n\tphy_power_off(pcie->phy);\n\tphy_exit(pcie->phy);\n\treset_control_assert(pcie->phy_reset);\n}\n\nstatic int mtk_pcie_setup(struct mtk_gen3_pcie *pcie)\n{\n\tint err;\n\n\terr = mtk_pcie_parse_port(pcie);\n\tif (err)\n\t\treturn err;\n\n\t \n\treset_control_assert(pcie->phy_reset);\n\treset_control_assert(pcie->mac_reset);\n\tusleep_range(10, 20);\n\n\t \n\terr = mtk_pcie_power_up(pcie);\n\tif (err)\n\t\treturn err;\n\n\t \n\terr = mtk_pcie_startup_port(pcie);\n\tif (err)\n\t\tgoto err_setup;\n\n\terr = mtk_pcie_setup_irq(pcie);\n\tif (err)\n\t\tgoto err_setup;\n\n\treturn 0;\n\nerr_setup:\n\tmtk_pcie_power_down(pcie);\n\n\treturn err;\n}\n\nstatic int mtk_pcie_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct mtk_gen3_pcie *pcie;\n\tstruct pci_host_bridge *host;\n\tint err;\n\n\thost = devm_pci_alloc_host_bridge(dev, sizeof(*pcie));\n\tif (!host)\n\t\treturn -ENOMEM;\n\n\tpcie = pci_host_bridge_priv(host);\n\n\tpcie->dev = dev;\n\tplatform_set_drvdata(pdev, pcie);\n\n\terr = mtk_pcie_setup(pcie);\n\tif (err)\n\t\treturn err;\n\n\thost->ops = &mtk_pcie_ops;\n\thost->sysdata = pcie;\n\n\terr = pci_host_probe(host);\n\tif (err) {\n\t\tmtk_pcie_irq_teardown(pcie);\n\t\tmtk_pcie_power_down(pcie);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic void mtk_pcie_remove(struct platform_device *pdev)\n{\n\tstruct mtk_gen3_pcie *pcie = platform_get_drvdata(pdev);\n\tstruct pci_host_bridge *host = pci_host_bridge_from_priv(pcie);\n\n\tpci_lock_rescan_remove();\n\tpci_stop_root_bus(host->bus);\n\tpci_remove_root_bus(host->bus);\n\tpci_unlock_rescan_remove();\n\n\tmtk_pcie_irq_teardown(pcie);\n\tmtk_pcie_power_down(pcie);\n}\n\nstatic void mtk_pcie_irq_save(struct mtk_gen3_pcie *pcie)\n{\n\tint i;\n\n\traw_spin_lock(&pcie->irq_lock);\n\n\tpcie->saved_irq_state = readl_relaxed(pcie->base + PCIE_INT_ENABLE_REG);\n\n\tfor (i = 0; i < PCIE_MSI_SET_NUM; i++) {\n\t\tstruct mtk_msi_set *msi_set = &pcie->msi_sets[i];\n\n\t\tmsi_set->saved_irq_state = readl_relaxed(msi_set->base +\n\t\t\t\t\t   PCIE_MSI_SET_ENABLE_OFFSET);\n\t}\n\n\traw_spin_unlock(&pcie->irq_lock);\n}\n\nstatic void mtk_pcie_irq_restore(struct mtk_gen3_pcie *pcie)\n{\n\tint i;\n\n\traw_spin_lock(&pcie->irq_lock);\n\n\twritel_relaxed(pcie->saved_irq_state, pcie->base + PCIE_INT_ENABLE_REG);\n\n\tfor (i = 0; i < PCIE_MSI_SET_NUM; i++) {\n\t\tstruct mtk_msi_set *msi_set = &pcie->msi_sets[i];\n\n\t\twritel_relaxed(msi_set->saved_irq_state,\n\t\t\t       msi_set->base + PCIE_MSI_SET_ENABLE_OFFSET);\n\t}\n\n\traw_spin_unlock(&pcie->irq_lock);\n}\n\nstatic int mtk_pcie_turn_off_link(struct mtk_gen3_pcie *pcie)\n{\n\tu32 val;\n\n\tval = readl_relaxed(pcie->base + PCIE_ICMD_PM_REG);\n\tval |= PCIE_TURN_OFF_LINK;\n\twritel_relaxed(val, pcie->base + PCIE_ICMD_PM_REG);\n\n\t \n\treturn readl_poll_timeout(pcie->base + PCIE_LTSSM_STATUS_REG, val,\n\t\t\t\t  (PCIE_LTSSM_STATE(val) ==\n\t\t\t\t   PCIE_LTSSM_STATE_L2_IDLE), 20,\n\t\t\t\t   50 * USEC_PER_MSEC);\n}\n\nstatic int mtk_pcie_suspend_noirq(struct device *dev)\n{\n\tstruct mtk_gen3_pcie *pcie = dev_get_drvdata(dev);\n\tint err;\n\tu32 val;\n\n\t \n\terr = mtk_pcie_turn_off_link(pcie);\n\tif (err) {\n\t\tdev_err(pcie->dev, \"cannot enter L2 state\\n\");\n\t\treturn err;\n\t}\n\n\t \n\tval = readl_relaxed(pcie->base + PCIE_RST_CTRL_REG);\n\tval |= PCIE_PE_RSTB;\n\twritel_relaxed(val, pcie->base + PCIE_RST_CTRL_REG);\n\n\tdev_dbg(pcie->dev, \"entered L2 states successfully\");\n\n\tmtk_pcie_irq_save(pcie);\n\tmtk_pcie_power_down(pcie);\n\n\treturn 0;\n}\n\nstatic int mtk_pcie_resume_noirq(struct device *dev)\n{\n\tstruct mtk_gen3_pcie *pcie = dev_get_drvdata(dev);\n\tint err;\n\n\terr = mtk_pcie_power_up(pcie);\n\tif (err)\n\t\treturn err;\n\n\terr = mtk_pcie_startup_port(pcie);\n\tif (err) {\n\t\tmtk_pcie_power_down(pcie);\n\t\treturn err;\n\t}\n\n\tmtk_pcie_irq_restore(pcie);\n\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops mtk_pcie_pm_ops = {\n\tNOIRQ_SYSTEM_SLEEP_PM_OPS(mtk_pcie_suspend_noirq,\n\t\t\t\t  mtk_pcie_resume_noirq)\n};\n\nstatic const struct of_device_id mtk_pcie_of_match[] = {\n\t{ .compatible = \"mediatek,mt8192-pcie\" },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, mtk_pcie_of_match);\n\nstatic struct platform_driver mtk_pcie_driver = {\n\t.probe = mtk_pcie_probe,\n\t.remove_new = mtk_pcie_remove,\n\t.driver = {\n\t\t.name = \"mtk-pcie-gen3\",\n\t\t.of_match_table = mtk_pcie_of_match,\n\t\t.pm = &mtk_pcie_pm_ops,\n\t},\n};\n\nmodule_platform_driver(mtk_pcie_driver);\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}