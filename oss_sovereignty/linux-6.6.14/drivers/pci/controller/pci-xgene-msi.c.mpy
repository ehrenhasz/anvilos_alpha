{
  "module_name": "pci-xgene-msi.c",
  "hash_id": "8fe7a77f7f9b3324ac87a09027a507ad534737f2bbf9fb6c42e6b43d905f4bcc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/controller/pci-xgene-msi.c",
  "human_readable_source": "\n \n#include <linux/cpu.h>\n#include <linux/interrupt.h>\n#include <linux/irqdomain.h>\n#include <linux/module.h>\n#include <linux/msi.h>\n#include <linux/irqchip/chained_irq.h>\n#include <linux/pci.h>\n#include <linux/platform_device.h>\n#include <linux/of_pci.h>\n\n#define MSI_IR0\t\t\t0x000000\n#define MSI_INT0\t\t0x800000\n#define IDX_PER_GROUP\t\t8\n#define IRQS_PER_IDX\t\t16\n#define NR_HW_IRQS\t\t16\n#define NR_MSI_VEC\t\t(IDX_PER_GROUP * IRQS_PER_IDX * NR_HW_IRQS)\n\nstruct xgene_msi_group {\n\tstruct xgene_msi\t*msi;\n\tint\t\t\tgic_irq;\n\tu32\t\t\tmsi_grp;\n};\n\nstruct xgene_msi {\n\tstruct device_node\t*node;\n\tstruct irq_domain\t*inner_domain;\n\tstruct irq_domain\t*msi_domain;\n\tu64\t\t\tmsi_addr;\n\tvoid __iomem\t\t*msi_regs;\n\tunsigned long\t\t*bitmap;\n\tstruct mutex\t\tbitmap_lock;\n\tstruct xgene_msi_group\t*msi_groups;\n\tint\t\t\tnum_cpus;\n};\n\n \nstatic struct xgene_msi xgene_msi_ctrl;\n\nstatic struct irq_chip xgene_msi_top_irq_chip = {\n\t.name\t\t= \"X-Gene1 MSI\",\n\t.irq_enable\t= pci_msi_unmask_irq,\n\t.irq_disable\t= pci_msi_mask_irq,\n\t.irq_mask\t= pci_msi_mask_irq,\n\t.irq_unmask\t= pci_msi_unmask_irq,\n};\n\nstatic struct  msi_domain_info xgene_msi_domain_info = {\n\t.flags\t= (MSI_FLAG_USE_DEF_DOM_OPS | MSI_FLAG_USE_DEF_CHIP_OPS |\n\t\t  MSI_FLAG_PCI_MSIX),\n\t.chip\t= &xgene_msi_top_irq_chip,\n};\n\n \n\n \nstatic u32 xgene_msi_ir_read(struct xgene_msi *msi,\n\t\t\t\t    u32 msi_grp, u32 msir_idx)\n{\n\treturn readl_relaxed(msi->msi_regs + MSI_IR0 +\n\t\t\t      (msi_grp << 19) + (msir_idx << 16));\n}\n\n \nstatic u32 xgene_msi_int_read(struct xgene_msi *msi, u32 msi_grp)\n{\n\treturn readl_relaxed(msi->msi_regs + MSI_INT0 + (msi_grp << 16));\n}\n\n \nstatic u32 hwirq_to_reg_set(unsigned long hwirq)\n{\n\treturn (hwirq / (NR_HW_IRQS * IRQS_PER_IDX));\n}\n\nstatic u32 hwirq_to_group(unsigned long hwirq)\n{\n\treturn (hwirq % NR_HW_IRQS);\n}\n\nstatic u32 hwirq_to_msi_data(unsigned long hwirq)\n{\n\treturn ((hwirq / NR_HW_IRQS) % IRQS_PER_IDX);\n}\n\nstatic void xgene_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)\n{\n\tstruct xgene_msi *msi = irq_data_get_irq_chip_data(data);\n\tu32 reg_set = hwirq_to_reg_set(data->hwirq);\n\tu32 group = hwirq_to_group(data->hwirq);\n\tu64 target_addr = msi->msi_addr + (((8 * group) + reg_set) << 16);\n\n\tmsg->address_hi = upper_32_bits(target_addr);\n\tmsg->address_lo = lower_32_bits(target_addr);\n\tmsg->data = hwirq_to_msi_data(data->hwirq);\n}\n\n \nstatic int hwirq_to_cpu(unsigned long hwirq)\n{\n\treturn (hwirq % xgene_msi_ctrl.num_cpus);\n}\n\nstatic unsigned long hwirq_to_canonical_hwirq(unsigned long hwirq)\n{\n\treturn (hwirq - hwirq_to_cpu(hwirq));\n}\n\nstatic int xgene_msi_set_affinity(struct irq_data *irqdata,\n\t\t\t\t  const struct cpumask *mask, bool force)\n{\n\tint target_cpu = cpumask_first(mask);\n\tint curr_cpu;\n\n\tcurr_cpu = hwirq_to_cpu(irqdata->hwirq);\n\tif (curr_cpu == target_cpu)\n\t\treturn IRQ_SET_MASK_OK_DONE;\n\n\t \n\tirqdata->hwirq = hwirq_to_canonical_hwirq(irqdata->hwirq) + target_cpu;\n\n\treturn IRQ_SET_MASK_OK;\n}\n\nstatic struct irq_chip xgene_msi_bottom_irq_chip = {\n\t.name\t\t\t= \"MSI\",\n\t.irq_set_affinity       = xgene_msi_set_affinity,\n\t.irq_compose_msi_msg\t= xgene_compose_msi_msg,\n};\n\nstatic int xgene_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,\n\t\t\t\t  unsigned int nr_irqs, void *args)\n{\n\tstruct xgene_msi *msi = domain->host_data;\n\tint msi_irq;\n\n\tmutex_lock(&msi->bitmap_lock);\n\n\tmsi_irq = bitmap_find_next_zero_area(msi->bitmap, NR_MSI_VEC, 0,\n\t\t\t\t\t     msi->num_cpus, 0);\n\tif (msi_irq < NR_MSI_VEC)\n\t\tbitmap_set(msi->bitmap, msi_irq, msi->num_cpus);\n\telse\n\t\tmsi_irq = -ENOSPC;\n\n\tmutex_unlock(&msi->bitmap_lock);\n\n\tif (msi_irq < 0)\n\t\treturn msi_irq;\n\n\tirq_domain_set_info(domain, virq, msi_irq,\n\t\t\t    &xgene_msi_bottom_irq_chip, domain->host_data,\n\t\t\t    handle_simple_irq, NULL, NULL);\n\n\treturn 0;\n}\n\nstatic void xgene_irq_domain_free(struct irq_domain *domain,\n\t\t\t\t  unsigned int virq, unsigned int nr_irqs)\n{\n\tstruct irq_data *d = irq_domain_get_irq_data(domain, virq);\n\tstruct xgene_msi *msi = irq_data_get_irq_chip_data(d);\n\tu32 hwirq;\n\n\tmutex_lock(&msi->bitmap_lock);\n\n\thwirq = hwirq_to_canonical_hwirq(d->hwirq);\n\tbitmap_clear(msi->bitmap, hwirq, msi->num_cpus);\n\n\tmutex_unlock(&msi->bitmap_lock);\n\n\tirq_domain_free_irqs_parent(domain, virq, nr_irqs);\n}\n\nstatic const struct irq_domain_ops msi_domain_ops = {\n\t.alloc  = xgene_irq_domain_alloc,\n\t.free   = xgene_irq_domain_free,\n};\n\nstatic int xgene_allocate_domains(struct xgene_msi *msi)\n{\n\tmsi->inner_domain = irq_domain_add_linear(NULL, NR_MSI_VEC,\n\t\t\t\t\t\t  &msi_domain_ops, msi);\n\tif (!msi->inner_domain)\n\t\treturn -ENOMEM;\n\n\tmsi->msi_domain = pci_msi_create_irq_domain(of_node_to_fwnode(msi->node),\n\t\t\t\t\t\t    &xgene_msi_domain_info,\n\t\t\t\t\t\t    msi->inner_domain);\n\n\tif (!msi->msi_domain) {\n\t\tirq_domain_remove(msi->inner_domain);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic void xgene_free_domains(struct xgene_msi *msi)\n{\n\tif (msi->msi_domain)\n\t\tirq_domain_remove(msi->msi_domain);\n\tif (msi->inner_domain)\n\t\tirq_domain_remove(msi->inner_domain);\n}\n\nstatic int xgene_msi_init_allocator(struct xgene_msi *xgene_msi)\n{\n\txgene_msi->bitmap = bitmap_zalloc(NR_MSI_VEC, GFP_KERNEL);\n\tif (!xgene_msi->bitmap)\n\t\treturn -ENOMEM;\n\n\tmutex_init(&xgene_msi->bitmap_lock);\n\n\txgene_msi->msi_groups = kcalloc(NR_HW_IRQS,\n\t\t\t\t\tsizeof(struct xgene_msi_group),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!xgene_msi->msi_groups)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void xgene_msi_isr(struct irq_desc *desc)\n{\n\tstruct irq_chip *chip = irq_desc_get_chip(desc);\n\tstruct xgene_msi_group *msi_groups;\n\tstruct xgene_msi *xgene_msi;\n\tint msir_index, msir_val, hw_irq, ret;\n\tu32 intr_index, grp_select, msi_grp;\n\n\tchained_irq_enter(chip, desc);\n\n\tmsi_groups = irq_desc_get_handler_data(desc);\n\txgene_msi = msi_groups->msi;\n\tmsi_grp = msi_groups->msi_grp;\n\n\t \n\tgrp_select = xgene_msi_int_read(xgene_msi, msi_grp);\n\twhile (grp_select) {\n\t\tmsir_index = ffs(grp_select) - 1;\n\t\t \n\t\tmsir_val = xgene_msi_ir_read(xgene_msi, msi_grp, msir_index);\n\t\twhile (msir_val) {\n\t\t\tintr_index = ffs(msir_val) - 1;\n\t\t\t \n\t\t\thw_irq = (((msir_index * IRQS_PER_IDX) + intr_index) *\n\t\t\t\t NR_HW_IRQS) + msi_grp;\n\t\t\t \n\t\t\thw_irq = hwirq_to_canonical_hwirq(hw_irq);\n\t\t\tret = generic_handle_domain_irq(xgene_msi->inner_domain, hw_irq);\n\t\t\tWARN_ON_ONCE(ret);\n\t\t\tmsir_val &= ~(1 << intr_index);\n\t\t}\n\t\tgrp_select &= ~(1 << msir_index);\n\n\t\tif (!grp_select) {\n\t\t\t \n\t\t\tgrp_select = xgene_msi_int_read(xgene_msi, msi_grp);\n\t\t}\n\t}\n\n\tchained_irq_exit(chip, desc);\n}\n\nstatic enum cpuhp_state pci_xgene_online;\n\nstatic void xgene_msi_remove(struct platform_device *pdev)\n{\n\tstruct xgene_msi *msi = platform_get_drvdata(pdev);\n\n\tif (pci_xgene_online)\n\t\tcpuhp_remove_state(pci_xgene_online);\n\tcpuhp_remove_state(CPUHP_PCI_XGENE_DEAD);\n\n\tkfree(msi->msi_groups);\n\n\tbitmap_free(msi->bitmap);\n\tmsi->bitmap = NULL;\n\n\txgene_free_domains(msi);\n}\n\nstatic int xgene_msi_hwirq_alloc(unsigned int cpu)\n{\n\tstruct xgene_msi *msi = &xgene_msi_ctrl;\n\tstruct xgene_msi_group *msi_group;\n\tcpumask_var_t mask;\n\tint i;\n\tint err;\n\n\tfor (i = cpu; i < NR_HW_IRQS; i += msi->num_cpus) {\n\t\tmsi_group = &msi->msi_groups[i];\n\t\tif (!msi_group->gic_irq)\n\t\t\tcontinue;\n\n\t\tirq_set_chained_handler_and_data(msi_group->gic_irq,\n\t\t\txgene_msi_isr, msi_group);\n\n\t\t \n\t\tif (alloc_cpumask_var(&mask, GFP_KERNEL)) {\n\t\t\tcpumask_clear(mask);\n\t\t\tcpumask_set_cpu(cpu, mask);\n\t\t\terr = irq_set_affinity(msi_group->gic_irq, mask);\n\t\t\tif (err)\n\t\t\t\tpr_err(\"failed to set affinity for GIC IRQ\");\n\t\t\tfree_cpumask_var(mask);\n\t\t} else {\n\t\t\tpr_err(\"failed to alloc CPU mask for affinity\\n\");\n\t\t\terr = -EINVAL;\n\t\t}\n\n\t\tif (err) {\n\t\t\tirq_set_chained_handler_and_data(msi_group->gic_irq,\n\t\t\t\t\t\t\t NULL, NULL);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int xgene_msi_hwirq_free(unsigned int cpu)\n{\n\tstruct xgene_msi *msi = &xgene_msi_ctrl;\n\tstruct xgene_msi_group *msi_group;\n\tint i;\n\n\tfor (i = cpu; i < NR_HW_IRQS; i += msi->num_cpus) {\n\t\tmsi_group = &msi->msi_groups[i];\n\t\tif (!msi_group->gic_irq)\n\t\t\tcontinue;\n\n\t\tirq_set_chained_handler_and_data(msi_group->gic_irq, NULL,\n\t\t\t\t\t\t NULL);\n\t}\n\treturn 0;\n}\n\nstatic const struct of_device_id xgene_msi_match_table[] = {\n\t{.compatible = \"apm,xgene1-msi\"},\n\t{},\n};\n\nstatic int xgene_msi_probe(struct platform_device *pdev)\n{\n\tstruct resource *res;\n\tint rc, irq_index;\n\tstruct xgene_msi *xgene_msi;\n\tint virt_msir;\n\tu32 msi_val, msi_idx;\n\n\txgene_msi = &xgene_msi_ctrl;\n\n\tplatform_set_drvdata(pdev, xgene_msi);\n\n\txgene_msi->msi_regs = devm_platform_get_and_ioremap_resource(pdev, 0, &res);\n\tif (IS_ERR(xgene_msi->msi_regs)) {\n\t\trc = PTR_ERR(xgene_msi->msi_regs);\n\t\tgoto error;\n\t}\n\txgene_msi->msi_addr = res->start;\n\txgene_msi->node = pdev->dev.of_node;\n\txgene_msi->num_cpus = num_possible_cpus();\n\n\trc = xgene_msi_init_allocator(xgene_msi);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Error allocating MSI bitmap\\n\");\n\t\tgoto error;\n\t}\n\n\trc = xgene_allocate_domains(xgene_msi);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Failed to allocate MSI domain\\n\");\n\t\tgoto error;\n\t}\n\n\tfor (irq_index = 0; irq_index < NR_HW_IRQS; irq_index++) {\n\t\tvirt_msir = platform_get_irq(pdev, irq_index);\n\t\tif (virt_msir < 0) {\n\t\t\trc = virt_msir;\n\t\t\tgoto error;\n\t\t}\n\t\txgene_msi->msi_groups[irq_index].gic_irq = virt_msir;\n\t\txgene_msi->msi_groups[irq_index].msi_grp = irq_index;\n\t\txgene_msi->msi_groups[irq_index].msi = xgene_msi;\n\t}\n\n\t \n\tfor (irq_index = 0; irq_index < NR_HW_IRQS; irq_index++) {\n\t\tfor (msi_idx = 0; msi_idx < IDX_PER_GROUP; msi_idx++)\n\t\t\txgene_msi_ir_read(xgene_msi, irq_index, msi_idx);\n\n\t\t \n\t\tmsi_val = xgene_msi_int_read(xgene_msi, irq_index);\n\t\tif (msi_val) {\n\t\t\tdev_err(&pdev->dev, \"Failed to clear spurious IRQ\\n\");\n\t\t\trc = -EINVAL;\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\trc = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, \"pci/xgene:online\",\n\t\t\t       xgene_msi_hwirq_alloc, NULL);\n\tif (rc < 0)\n\t\tgoto err_cpuhp;\n\tpci_xgene_online = rc;\n\trc = cpuhp_setup_state(CPUHP_PCI_XGENE_DEAD, \"pci/xgene:dead\", NULL,\n\t\t\t       xgene_msi_hwirq_free);\n\tif (rc)\n\t\tgoto err_cpuhp;\n\n\tdev_info(&pdev->dev, \"APM X-Gene PCIe MSI driver loaded\\n\");\n\n\treturn 0;\n\nerr_cpuhp:\n\tdev_err(&pdev->dev, \"failed to add CPU MSI notifier\\n\");\nerror:\n\txgene_msi_remove(pdev);\n\treturn rc;\n}\n\nstatic struct platform_driver xgene_msi_driver = {\n\t.driver = {\n\t\t.name = \"xgene-msi\",\n\t\t.of_match_table = xgene_msi_match_table,\n\t},\n\t.probe = xgene_msi_probe,\n\t.remove_new = xgene_msi_remove,\n};\n\nstatic int __init xgene_pcie_msi_init(void)\n{\n\treturn platform_driver_register(&xgene_msi_driver);\n}\nsubsys_initcall(xgene_pcie_msi_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}