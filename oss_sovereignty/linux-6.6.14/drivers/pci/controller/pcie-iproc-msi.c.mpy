{
  "module_name": "pcie-iproc-msi.c",
  "hash_id": "1a015abd81b5a60dc90eef13a5c3948297ffd89ce86ccba2e515ed6052e6207a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/controller/pcie-iproc-msi.c",
  "human_readable_source": "\n \n\n#include <linux/interrupt.h>\n#include <linux/irqchip/chained_irq.h>\n#include <linux/irqdomain.h>\n#include <linux/msi.h>\n#include <linux/of_irq.h>\n#include <linux/of_pci.h>\n#include <linux/pci.h>\n\n#include \"pcie-iproc.h\"\n\n#define IPROC_MSI_INTR_EN_SHIFT        11\n#define IPROC_MSI_INTR_EN              BIT(IPROC_MSI_INTR_EN_SHIFT)\n#define IPROC_MSI_INT_N_EVENT_SHIFT    1\n#define IPROC_MSI_INT_N_EVENT          BIT(IPROC_MSI_INT_N_EVENT_SHIFT)\n#define IPROC_MSI_EQ_EN_SHIFT          0\n#define IPROC_MSI_EQ_EN                BIT(IPROC_MSI_EQ_EN_SHIFT)\n\n#define IPROC_MSI_EQ_MASK              0x3f\n\n \n#define NR_HW_IRQS                     6\n\n \n#define EQ_LEN                         64\n\n \n#define EQ_MEM_REGION_SIZE             SZ_4K\n\n \n#define MSI_MEM_REGION_SIZE            SZ_4K\n\nenum iproc_msi_reg {\n\tIPROC_MSI_EQ_PAGE = 0,\n\tIPROC_MSI_EQ_PAGE_UPPER,\n\tIPROC_MSI_PAGE,\n\tIPROC_MSI_PAGE_UPPER,\n\tIPROC_MSI_CTRL,\n\tIPROC_MSI_EQ_HEAD,\n\tIPROC_MSI_EQ_TAIL,\n\tIPROC_MSI_INTS_EN,\n\tIPROC_MSI_REG_SIZE,\n};\n\nstruct iproc_msi;\n\n \nstruct iproc_msi_grp {\n\tstruct iproc_msi *msi;\n\tint gic_irq;\n\tunsigned int eq;\n};\n\n \nstruct iproc_msi {\n\tstruct iproc_pcie *pcie;\n\tconst u16 (*reg_offsets)[IPROC_MSI_REG_SIZE];\n\tstruct iproc_msi_grp *grps;\n\tint nr_irqs;\n\tint nr_cpus;\n\tbool has_inten_reg;\n\tunsigned long *bitmap;\n\tstruct mutex bitmap_lock;\n\tunsigned int nr_msi_vecs;\n\tstruct irq_domain *inner_domain;\n\tstruct irq_domain *msi_domain;\n\tunsigned int nr_eq_region;\n\tunsigned int nr_msi_region;\n\tvoid *eq_cpu;\n\tdma_addr_t eq_dma;\n\tphys_addr_t msi_addr;\n};\n\nstatic const u16 iproc_msi_reg_paxb[NR_HW_IRQS][IPROC_MSI_REG_SIZE] = {\n\t{ 0x200, 0x2c0, 0x204, 0x2c4, 0x210, 0x250, 0x254, 0x208 },\n\t{ 0x200, 0x2c0, 0x204, 0x2c4, 0x214, 0x258, 0x25c, 0x208 },\n\t{ 0x200, 0x2c0, 0x204, 0x2c4, 0x218, 0x260, 0x264, 0x208 },\n\t{ 0x200, 0x2c0, 0x204, 0x2c4, 0x21c, 0x268, 0x26c, 0x208 },\n\t{ 0x200, 0x2c0, 0x204, 0x2c4, 0x220, 0x270, 0x274, 0x208 },\n\t{ 0x200, 0x2c0, 0x204, 0x2c4, 0x224, 0x278, 0x27c, 0x208 },\n};\n\nstatic const u16 iproc_msi_reg_paxc[NR_HW_IRQS][IPROC_MSI_REG_SIZE] = {\n\t{ 0xc00, 0xc04, 0xc08, 0xc0c, 0xc40, 0xc50, 0xc60 },\n\t{ 0xc10, 0xc14, 0xc18, 0xc1c, 0xc44, 0xc54, 0xc64 },\n\t{ 0xc20, 0xc24, 0xc28, 0xc2c, 0xc48, 0xc58, 0xc68 },\n\t{ 0xc30, 0xc34, 0xc38, 0xc3c, 0xc4c, 0xc5c, 0xc6c },\n};\n\nstatic inline u32 iproc_msi_read_reg(struct iproc_msi *msi,\n\t\t\t\t     enum iproc_msi_reg reg,\n\t\t\t\t     unsigned int eq)\n{\n\tstruct iproc_pcie *pcie = msi->pcie;\n\n\treturn readl_relaxed(pcie->base + msi->reg_offsets[eq][reg]);\n}\n\nstatic inline void iproc_msi_write_reg(struct iproc_msi *msi,\n\t\t\t\t       enum iproc_msi_reg reg,\n\t\t\t\t       int eq, u32 val)\n{\n\tstruct iproc_pcie *pcie = msi->pcie;\n\n\twritel_relaxed(val, pcie->base + msi->reg_offsets[eq][reg]);\n}\n\nstatic inline u32 hwirq_to_group(struct iproc_msi *msi, unsigned long hwirq)\n{\n\treturn (hwirq % msi->nr_irqs);\n}\n\nstatic inline unsigned int iproc_msi_addr_offset(struct iproc_msi *msi,\n\t\t\t\t\t\t unsigned long hwirq)\n{\n\tif (msi->nr_msi_region > 1)\n\t\treturn hwirq_to_group(msi, hwirq) * MSI_MEM_REGION_SIZE;\n\telse\n\t\treturn hwirq_to_group(msi, hwirq) * sizeof(u32);\n}\n\nstatic inline unsigned int iproc_msi_eq_offset(struct iproc_msi *msi, u32 eq)\n{\n\tif (msi->nr_eq_region > 1)\n\t\treturn eq * EQ_MEM_REGION_SIZE;\n\telse\n\t\treturn eq * EQ_LEN * sizeof(u32);\n}\n\nstatic struct irq_chip iproc_msi_irq_chip = {\n\t.name = \"iProc-MSI\",\n};\n\nstatic struct msi_domain_info iproc_msi_domain_info = {\n\t.flags = MSI_FLAG_USE_DEF_DOM_OPS | MSI_FLAG_USE_DEF_CHIP_OPS |\n\t\tMSI_FLAG_PCI_MSIX,\n\t.chip = &iproc_msi_irq_chip,\n};\n\n \nstatic inline int hwirq_to_cpu(struct iproc_msi *msi, unsigned long hwirq)\n{\n\treturn (hwirq % msi->nr_cpus);\n}\n\nstatic inline unsigned long hwirq_to_canonical_hwirq(struct iproc_msi *msi,\n\t\t\t\t\t\t     unsigned long hwirq)\n{\n\treturn (hwirq - hwirq_to_cpu(msi, hwirq));\n}\n\nstatic int iproc_msi_irq_set_affinity(struct irq_data *data,\n\t\t\t\t      const struct cpumask *mask, bool force)\n{\n\tstruct iproc_msi *msi = irq_data_get_irq_chip_data(data);\n\tint target_cpu = cpumask_first(mask);\n\tint curr_cpu;\n\tint ret;\n\n\tcurr_cpu = hwirq_to_cpu(msi, data->hwirq);\n\tif (curr_cpu == target_cpu)\n\t\tret = IRQ_SET_MASK_OK_DONE;\n\telse {\n\t\t \n\t\tdata->hwirq = hwirq_to_canonical_hwirq(msi, data->hwirq) + target_cpu;\n\t\tret = IRQ_SET_MASK_OK;\n\t}\n\n\tirq_data_update_effective_affinity(data, cpumask_of(target_cpu));\n\n\treturn ret;\n}\n\nstatic void iproc_msi_irq_compose_msi_msg(struct irq_data *data,\n\t\t\t\t\t  struct msi_msg *msg)\n{\n\tstruct iproc_msi *msi = irq_data_get_irq_chip_data(data);\n\tdma_addr_t addr;\n\n\taddr = msi->msi_addr + iproc_msi_addr_offset(msi, data->hwirq);\n\tmsg->address_lo = lower_32_bits(addr);\n\tmsg->address_hi = upper_32_bits(addr);\n\tmsg->data = data->hwirq << 5;\n}\n\nstatic struct irq_chip iproc_msi_bottom_irq_chip = {\n\t.name = \"MSI\",\n\t.irq_set_affinity = iproc_msi_irq_set_affinity,\n\t.irq_compose_msi_msg = iproc_msi_irq_compose_msi_msg,\n};\n\nstatic int iproc_msi_irq_domain_alloc(struct irq_domain *domain,\n\t\t\t\t      unsigned int virq, unsigned int nr_irqs,\n\t\t\t\t      void *args)\n{\n\tstruct iproc_msi *msi = domain->host_data;\n\tint hwirq, i;\n\n\tif (msi->nr_cpus > 1 && nr_irqs > 1)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&msi->bitmap_lock);\n\n\t \n\thwirq = bitmap_find_free_region(msi->bitmap, msi->nr_msi_vecs,\n\t\t\t\t\torder_base_2(msi->nr_cpus * nr_irqs));\n\n\tmutex_unlock(&msi->bitmap_lock);\n\n\tif (hwirq < 0)\n\t\treturn -ENOSPC;\n\n\tfor (i = 0; i < nr_irqs; i++) {\n\t\tirq_domain_set_info(domain, virq + i, hwirq + i,\n\t\t\t\t    &iproc_msi_bottom_irq_chip,\n\t\t\t\t    domain->host_data, handle_simple_irq,\n\t\t\t\t    NULL, NULL);\n\t}\n\n\treturn 0;\n}\n\nstatic void iproc_msi_irq_domain_free(struct irq_domain *domain,\n\t\t\t\t      unsigned int virq, unsigned int nr_irqs)\n{\n\tstruct irq_data *data = irq_domain_get_irq_data(domain, virq);\n\tstruct iproc_msi *msi = irq_data_get_irq_chip_data(data);\n\tunsigned int hwirq;\n\n\tmutex_lock(&msi->bitmap_lock);\n\n\thwirq = hwirq_to_canonical_hwirq(msi, data->hwirq);\n\tbitmap_release_region(msi->bitmap, hwirq,\n\t\t\t      order_base_2(msi->nr_cpus * nr_irqs));\n\n\tmutex_unlock(&msi->bitmap_lock);\n\n\tirq_domain_free_irqs_parent(domain, virq, nr_irqs);\n}\n\nstatic const struct irq_domain_ops msi_domain_ops = {\n\t.alloc = iproc_msi_irq_domain_alloc,\n\t.free = iproc_msi_irq_domain_free,\n};\n\nstatic inline u32 decode_msi_hwirq(struct iproc_msi *msi, u32 eq, u32 head)\n{\n\tu32 __iomem *msg;\n\tu32 hwirq;\n\tunsigned int offs;\n\n\toffs = iproc_msi_eq_offset(msi, eq) + head * sizeof(u32);\n\tmsg = (u32 __iomem *)(msi->eq_cpu + offs);\n\thwirq = readl(msg);\n\thwirq = (hwirq >> 5) + (hwirq & 0x1f);\n\n\t \n\treturn hwirq_to_canonical_hwirq(msi, hwirq);\n}\n\nstatic void iproc_msi_handler(struct irq_desc *desc)\n{\n\tstruct irq_chip *chip = irq_desc_get_chip(desc);\n\tstruct iproc_msi_grp *grp;\n\tstruct iproc_msi *msi;\n\tu32 eq, head, tail, nr_events;\n\tunsigned long hwirq;\n\n\tchained_irq_enter(chip, desc);\n\n\tgrp = irq_desc_get_handler_data(desc);\n\tmsi = grp->msi;\n\teq = grp->eq;\n\n\t \n\thead = iproc_msi_read_reg(msi, IPROC_MSI_EQ_HEAD,\n\t\t\t\t  eq) & IPROC_MSI_EQ_MASK;\n\tdo {\n\t\ttail = iproc_msi_read_reg(msi, IPROC_MSI_EQ_TAIL,\n\t\t\t\t\t  eq) & IPROC_MSI_EQ_MASK;\n\n\t\t \n\t\tnr_events = (tail < head) ?\n\t\t\t(EQ_LEN - (head - tail)) : (tail - head);\n\t\tif (!nr_events)\n\t\t\tbreak;\n\n\t\t \n\t\twhile (nr_events--) {\n\t\t\thwirq = decode_msi_hwirq(msi, eq, head);\n\t\t\tgeneric_handle_domain_irq(msi->inner_domain, hwirq);\n\n\t\t\thead++;\n\t\t\thead %= EQ_LEN;\n\t\t}\n\n\t\t \n\t\tiproc_msi_write_reg(msi, IPROC_MSI_EQ_HEAD, eq, head);\n\n\t\t \n\t} while (true);\n\n\tchained_irq_exit(chip, desc);\n}\n\nstatic void iproc_msi_enable(struct iproc_msi *msi)\n{\n\tint i, eq;\n\tu32 val;\n\n\t \n\tfor (i = 0; i < msi->nr_eq_region; i++) {\n\t\tdma_addr_t addr = msi->eq_dma + (i * EQ_MEM_REGION_SIZE);\n\n\t\tiproc_msi_write_reg(msi, IPROC_MSI_EQ_PAGE, i,\n\t\t\t\t    lower_32_bits(addr));\n\t\tiproc_msi_write_reg(msi, IPROC_MSI_EQ_PAGE_UPPER, i,\n\t\t\t\t    upper_32_bits(addr));\n\t}\n\n\t \n\tfor (i = 0; i < msi->nr_msi_region; i++) {\n\t\tphys_addr_t addr = msi->msi_addr + (i * MSI_MEM_REGION_SIZE);\n\n\t\tiproc_msi_write_reg(msi, IPROC_MSI_PAGE, i,\n\t\t\t\t    lower_32_bits(addr));\n\t\tiproc_msi_write_reg(msi, IPROC_MSI_PAGE_UPPER, i,\n\t\t\t\t    upper_32_bits(addr));\n\t}\n\n\tfor (eq = 0; eq < msi->nr_irqs; eq++) {\n\t\t \n\t\tval = IPROC_MSI_INTR_EN | IPROC_MSI_INT_N_EVENT |\n\t\t\tIPROC_MSI_EQ_EN;\n\t\tiproc_msi_write_reg(msi, IPROC_MSI_CTRL, eq, val);\n\n\t\t \n\t\tif (msi->has_inten_reg) {\n\t\t\tval = iproc_msi_read_reg(msi, IPROC_MSI_INTS_EN, eq);\n\t\t\tval |= BIT(eq);\n\t\t\tiproc_msi_write_reg(msi, IPROC_MSI_INTS_EN, eq, val);\n\t\t}\n\t}\n}\n\nstatic void iproc_msi_disable(struct iproc_msi *msi)\n{\n\tu32 eq, val;\n\n\tfor (eq = 0; eq < msi->nr_irqs; eq++) {\n\t\tif (msi->has_inten_reg) {\n\t\t\tval = iproc_msi_read_reg(msi, IPROC_MSI_INTS_EN, eq);\n\t\t\tval &= ~BIT(eq);\n\t\t\tiproc_msi_write_reg(msi, IPROC_MSI_INTS_EN, eq, val);\n\t\t}\n\n\t\tval = iproc_msi_read_reg(msi, IPROC_MSI_CTRL, eq);\n\t\tval &= ~(IPROC_MSI_INTR_EN | IPROC_MSI_INT_N_EVENT |\n\t\t\t IPROC_MSI_EQ_EN);\n\t\tiproc_msi_write_reg(msi, IPROC_MSI_CTRL, eq, val);\n\t}\n}\n\nstatic int iproc_msi_alloc_domains(struct device_node *node,\n\t\t\t\t   struct iproc_msi *msi)\n{\n\tmsi->inner_domain = irq_domain_add_linear(NULL, msi->nr_msi_vecs,\n\t\t\t\t\t\t  &msi_domain_ops, msi);\n\tif (!msi->inner_domain)\n\t\treturn -ENOMEM;\n\n\tmsi->msi_domain = pci_msi_create_irq_domain(of_node_to_fwnode(node),\n\t\t\t\t\t\t    &iproc_msi_domain_info,\n\t\t\t\t\t\t    msi->inner_domain);\n\tif (!msi->msi_domain) {\n\t\tirq_domain_remove(msi->inner_domain);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic void iproc_msi_free_domains(struct iproc_msi *msi)\n{\n\tif (msi->msi_domain)\n\t\tirq_domain_remove(msi->msi_domain);\n\n\tif (msi->inner_domain)\n\t\tirq_domain_remove(msi->inner_domain);\n}\n\nstatic void iproc_msi_irq_free(struct iproc_msi *msi, unsigned int cpu)\n{\n\tint i;\n\n\tfor (i = cpu; i < msi->nr_irqs; i += msi->nr_cpus) {\n\t\tirq_set_chained_handler_and_data(msi->grps[i].gic_irq,\n\t\t\t\t\t\t NULL, NULL);\n\t}\n}\n\nstatic int iproc_msi_irq_setup(struct iproc_msi *msi, unsigned int cpu)\n{\n\tint i, ret;\n\tcpumask_var_t mask;\n\tstruct iproc_pcie *pcie = msi->pcie;\n\n\tfor (i = cpu; i < msi->nr_irqs; i += msi->nr_cpus) {\n\t\tirq_set_chained_handler_and_data(msi->grps[i].gic_irq,\n\t\t\t\t\t\t iproc_msi_handler,\n\t\t\t\t\t\t &msi->grps[i]);\n\t\t \n\t\tif (alloc_cpumask_var(&mask, GFP_KERNEL)) {\n\t\t\tcpumask_clear(mask);\n\t\t\tcpumask_set_cpu(cpu, mask);\n\t\t\tret = irq_set_affinity(msi->grps[i].gic_irq, mask);\n\t\t\tif (ret)\n\t\t\t\tdev_err(pcie->dev,\n\t\t\t\t\t\"failed to set affinity for IRQ%d\\n\",\n\t\t\t\t\tmsi->grps[i].gic_irq);\n\t\t\tfree_cpumask_var(mask);\n\t\t} else {\n\t\t\tdev_err(pcie->dev, \"failed to alloc CPU mask\\n\");\n\t\t\tret = -EINVAL;\n\t\t}\n\n\t\tif (ret) {\n\t\t\t \n\t\t\tiproc_msi_irq_free(msi, cpu);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint iproc_msi_init(struct iproc_pcie *pcie, struct device_node *node)\n{\n\tstruct iproc_msi *msi;\n\tint i, ret;\n\tunsigned int cpu;\n\n\tif (!of_device_is_compatible(node, \"brcm,iproc-msi\"))\n\t\treturn -ENODEV;\n\n\tif (!of_property_read_bool(node, \"msi-controller\"))\n\t\treturn -ENODEV;\n\n\tif (pcie->msi)\n\t\treturn -EBUSY;\n\n\tmsi = devm_kzalloc(pcie->dev, sizeof(*msi), GFP_KERNEL);\n\tif (!msi)\n\t\treturn -ENOMEM;\n\n\tmsi->pcie = pcie;\n\tpcie->msi = msi;\n\tmsi->msi_addr = pcie->base_addr;\n\tmutex_init(&msi->bitmap_lock);\n\tmsi->nr_cpus = num_possible_cpus();\n\n\tif (msi->nr_cpus == 1)\n\t\tiproc_msi_domain_info.flags |=  MSI_FLAG_MULTI_PCI_MSI;\n\n\tmsi->nr_irqs = of_irq_count(node);\n\tif (!msi->nr_irqs) {\n\t\tdev_err(pcie->dev, \"found no MSI GIC interrupt\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (msi->nr_irqs > NR_HW_IRQS) {\n\t\tdev_warn(pcie->dev, \"too many MSI GIC interrupts defined %d\\n\",\n\t\t\t msi->nr_irqs);\n\t\tmsi->nr_irqs = NR_HW_IRQS;\n\t}\n\n\tif (msi->nr_irqs < msi->nr_cpus) {\n\t\tdev_err(pcie->dev,\n\t\t\t\"not enough GIC interrupts for MSI affinity\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (msi->nr_irqs % msi->nr_cpus != 0) {\n\t\tmsi->nr_irqs -= msi->nr_irqs % msi->nr_cpus;\n\t\tdev_warn(pcie->dev, \"Reducing number of interrupts to %d\\n\",\n\t\t\t msi->nr_irqs);\n\t}\n\n\tswitch (pcie->type) {\n\tcase IPROC_PCIE_PAXB_BCMA:\n\tcase IPROC_PCIE_PAXB:\n\t\tmsi->reg_offsets = iproc_msi_reg_paxb;\n\t\tmsi->nr_eq_region = 1;\n\t\tmsi->nr_msi_region = 1;\n\t\tbreak;\n\tcase IPROC_PCIE_PAXC:\n\t\tmsi->reg_offsets = iproc_msi_reg_paxc;\n\t\tmsi->nr_eq_region = msi->nr_irqs;\n\t\tmsi->nr_msi_region = msi->nr_irqs;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(pcie->dev, \"incompatible iProc PCIe interface\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmsi->has_inten_reg = of_property_read_bool(node, \"brcm,pcie-msi-inten\");\n\n\tmsi->nr_msi_vecs = msi->nr_irqs * EQ_LEN;\n\tmsi->bitmap = devm_bitmap_zalloc(pcie->dev, msi->nr_msi_vecs,\n\t\t\t\t\t GFP_KERNEL);\n\tif (!msi->bitmap)\n\t\treturn -ENOMEM;\n\n\tmsi->grps = devm_kcalloc(pcie->dev, msi->nr_irqs, sizeof(*msi->grps),\n\t\t\t\t GFP_KERNEL);\n\tif (!msi->grps)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < msi->nr_irqs; i++) {\n\t\tunsigned int irq = irq_of_parse_and_map(node, i);\n\n\t\tif (!irq) {\n\t\t\tdev_err(pcie->dev, \"unable to parse/map interrupt\\n\");\n\t\t\tret = -ENODEV;\n\t\t\tgoto free_irqs;\n\t\t}\n\t\tmsi->grps[i].gic_irq = irq;\n\t\tmsi->grps[i].msi = msi;\n\t\tmsi->grps[i].eq = i;\n\t}\n\n\t \n\tmsi->eq_cpu = dma_alloc_coherent(pcie->dev,\n\t\t\t\t\t msi->nr_eq_region * EQ_MEM_REGION_SIZE,\n\t\t\t\t\t &msi->eq_dma, GFP_KERNEL);\n\tif (!msi->eq_cpu) {\n\t\tret = -ENOMEM;\n\t\tgoto free_irqs;\n\t}\n\n\tret = iproc_msi_alloc_domains(node, msi);\n\tif (ret) {\n\t\tdev_err(pcie->dev, \"failed to create MSI domains\\n\");\n\t\tgoto free_eq_dma;\n\t}\n\n\tfor_each_online_cpu(cpu) {\n\t\tret = iproc_msi_irq_setup(msi, cpu);\n\t\tif (ret)\n\t\t\tgoto free_msi_irq;\n\t}\n\n\tiproc_msi_enable(msi);\n\n\treturn 0;\n\nfree_msi_irq:\n\tfor_each_online_cpu(cpu)\n\t\tiproc_msi_irq_free(msi, cpu);\n\tiproc_msi_free_domains(msi);\n\nfree_eq_dma:\n\tdma_free_coherent(pcie->dev, msi->nr_eq_region * EQ_MEM_REGION_SIZE,\n\t\t\t  msi->eq_cpu, msi->eq_dma);\n\nfree_irqs:\n\tfor (i = 0; i < msi->nr_irqs; i++) {\n\t\tif (msi->grps[i].gic_irq)\n\t\t\tirq_dispose_mapping(msi->grps[i].gic_irq);\n\t}\n\tpcie->msi = NULL;\n\treturn ret;\n}\nEXPORT_SYMBOL(iproc_msi_init);\n\nvoid iproc_msi_exit(struct iproc_pcie *pcie)\n{\n\tstruct iproc_msi *msi = pcie->msi;\n\tunsigned int i, cpu;\n\n\tif (!msi)\n\t\treturn;\n\n\tiproc_msi_disable(msi);\n\n\tfor_each_online_cpu(cpu)\n\t\tiproc_msi_irq_free(msi, cpu);\n\n\tiproc_msi_free_domains(msi);\n\n\tdma_free_coherent(pcie->dev, msi->nr_eq_region * EQ_MEM_REGION_SIZE,\n\t\t\t  msi->eq_cpu, msi->eq_dma);\n\n\tfor (i = 0; i < msi->nr_irqs; i++) {\n\t\tif (msi->grps[i].gic_irq)\n\t\t\tirq_dispose_mapping(msi->grps[i].gic_irq);\n\t}\n}\nEXPORT_SYMBOL(iproc_msi_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}