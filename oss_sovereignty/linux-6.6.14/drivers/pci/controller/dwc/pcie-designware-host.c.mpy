{
  "module_name": "pcie-designware-host.c",
  "hash_id": "d7987ff6e5e5ad9b4ae0a85532df21763c2c146bb2c78e0a6418968b1b2eb236",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/controller/dwc/pcie-designware-host.c",
  "human_readable_source": "\n \n\n#include <linux/iopoll.h>\n#include <linux/irqchip/chained_irq.h>\n#include <linux/irqdomain.h>\n#include <linux/msi.h>\n#include <linux/of_address.h>\n#include <linux/of_pci.h>\n#include <linux/pci_regs.h>\n#include <linux/platform_device.h>\n\n#include \"../../pci.h\"\n#include \"pcie-designware.h\"\n\nstatic struct pci_ops dw_pcie_ops;\nstatic struct pci_ops dw_child_pcie_ops;\n\nstatic void dw_msi_ack_irq(struct irq_data *d)\n{\n\tirq_chip_ack_parent(d);\n}\n\nstatic void dw_msi_mask_irq(struct irq_data *d)\n{\n\tpci_msi_mask_irq(d);\n\tirq_chip_mask_parent(d);\n}\n\nstatic void dw_msi_unmask_irq(struct irq_data *d)\n{\n\tpci_msi_unmask_irq(d);\n\tirq_chip_unmask_parent(d);\n}\n\nstatic struct irq_chip dw_pcie_msi_irq_chip = {\n\t.name = \"PCI-MSI\",\n\t.irq_ack = dw_msi_ack_irq,\n\t.irq_mask = dw_msi_mask_irq,\n\t.irq_unmask = dw_msi_unmask_irq,\n};\n\nstatic struct msi_domain_info dw_pcie_msi_domain_info = {\n\t.flags\t= (MSI_FLAG_USE_DEF_DOM_OPS | MSI_FLAG_USE_DEF_CHIP_OPS |\n\t\t   MSI_FLAG_PCI_MSIX | MSI_FLAG_MULTI_PCI_MSI),\n\t.chip\t= &dw_pcie_msi_irq_chip,\n};\n\n \nirqreturn_t dw_handle_msi_irq(struct dw_pcie_rp *pp)\n{\n\tint i, pos;\n\tunsigned long val;\n\tu32 status, num_ctrls;\n\tirqreturn_t ret = IRQ_NONE;\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\n\tnum_ctrls = pp->num_vectors / MAX_MSI_IRQS_PER_CTRL;\n\n\tfor (i = 0; i < num_ctrls; i++) {\n\t\tstatus = dw_pcie_readl_dbi(pci, PCIE_MSI_INTR0_STATUS +\n\t\t\t\t\t   (i * MSI_REG_CTRL_BLOCK_SIZE));\n\t\tif (!status)\n\t\t\tcontinue;\n\n\t\tret = IRQ_HANDLED;\n\t\tval = status;\n\t\tpos = 0;\n\t\twhile ((pos = find_next_bit(&val, MAX_MSI_IRQS_PER_CTRL,\n\t\t\t\t\t    pos)) != MAX_MSI_IRQS_PER_CTRL) {\n\t\t\tgeneric_handle_domain_irq(pp->irq_domain,\n\t\t\t\t\t\t  (i * MAX_MSI_IRQS_PER_CTRL) +\n\t\t\t\t\t\t  pos);\n\t\t\tpos++;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n \nstatic void dw_chained_msi_isr(struct irq_desc *desc)\n{\n\tstruct irq_chip *chip = irq_desc_get_chip(desc);\n\tstruct dw_pcie_rp *pp;\n\n\tchained_irq_enter(chip, desc);\n\n\tpp = irq_desc_get_handler_data(desc);\n\tdw_handle_msi_irq(pp);\n\n\tchained_irq_exit(chip, desc);\n}\n\nstatic void dw_pci_setup_msi_msg(struct irq_data *d, struct msi_msg *msg)\n{\n\tstruct dw_pcie_rp *pp = irq_data_get_irq_chip_data(d);\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tu64 msi_target;\n\n\tmsi_target = (u64)pp->msi_data;\n\n\tmsg->address_lo = lower_32_bits(msi_target);\n\tmsg->address_hi = upper_32_bits(msi_target);\n\n\tmsg->data = d->hwirq;\n\n\tdev_dbg(pci->dev, \"msi#%d address_hi %#x address_lo %#x\\n\",\n\t\t(int)d->hwirq, msg->address_hi, msg->address_lo);\n}\n\nstatic int dw_pci_msi_set_affinity(struct irq_data *d,\n\t\t\t\t   const struct cpumask *mask, bool force)\n{\n\treturn -EINVAL;\n}\n\nstatic void dw_pci_bottom_mask(struct irq_data *d)\n{\n\tstruct dw_pcie_rp *pp = irq_data_get_irq_chip_data(d);\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tunsigned int res, bit, ctrl;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&pp->lock, flags);\n\n\tctrl = d->hwirq / MAX_MSI_IRQS_PER_CTRL;\n\tres = ctrl * MSI_REG_CTRL_BLOCK_SIZE;\n\tbit = d->hwirq % MAX_MSI_IRQS_PER_CTRL;\n\n\tpp->irq_mask[ctrl] |= BIT(bit);\n\tdw_pcie_writel_dbi(pci, PCIE_MSI_INTR0_MASK + res, pp->irq_mask[ctrl]);\n\n\traw_spin_unlock_irqrestore(&pp->lock, flags);\n}\n\nstatic void dw_pci_bottom_unmask(struct irq_data *d)\n{\n\tstruct dw_pcie_rp *pp = irq_data_get_irq_chip_data(d);\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tunsigned int res, bit, ctrl;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&pp->lock, flags);\n\n\tctrl = d->hwirq / MAX_MSI_IRQS_PER_CTRL;\n\tres = ctrl * MSI_REG_CTRL_BLOCK_SIZE;\n\tbit = d->hwirq % MAX_MSI_IRQS_PER_CTRL;\n\n\tpp->irq_mask[ctrl] &= ~BIT(bit);\n\tdw_pcie_writel_dbi(pci, PCIE_MSI_INTR0_MASK + res, pp->irq_mask[ctrl]);\n\n\traw_spin_unlock_irqrestore(&pp->lock, flags);\n}\n\nstatic void dw_pci_bottom_ack(struct irq_data *d)\n{\n\tstruct dw_pcie_rp *pp  = irq_data_get_irq_chip_data(d);\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tunsigned int res, bit, ctrl;\n\n\tctrl = d->hwirq / MAX_MSI_IRQS_PER_CTRL;\n\tres = ctrl * MSI_REG_CTRL_BLOCK_SIZE;\n\tbit = d->hwirq % MAX_MSI_IRQS_PER_CTRL;\n\n\tdw_pcie_writel_dbi(pci, PCIE_MSI_INTR0_STATUS + res, BIT(bit));\n}\n\nstatic struct irq_chip dw_pci_msi_bottom_irq_chip = {\n\t.name = \"DWPCI-MSI\",\n\t.irq_ack = dw_pci_bottom_ack,\n\t.irq_compose_msi_msg = dw_pci_setup_msi_msg,\n\t.irq_set_affinity = dw_pci_msi_set_affinity,\n\t.irq_mask = dw_pci_bottom_mask,\n\t.irq_unmask = dw_pci_bottom_unmask,\n};\n\nstatic int dw_pcie_irq_domain_alloc(struct irq_domain *domain,\n\t\t\t\t    unsigned int virq, unsigned int nr_irqs,\n\t\t\t\t    void *args)\n{\n\tstruct dw_pcie_rp *pp = domain->host_data;\n\tunsigned long flags;\n\tu32 i;\n\tint bit;\n\n\traw_spin_lock_irqsave(&pp->lock, flags);\n\n\tbit = bitmap_find_free_region(pp->msi_irq_in_use, pp->num_vectors,\n\t\t\t\t      order_base_2(nr_irqs));\n\n\traw_spin_unlock_irqrestore(&pp->lock, flags);\n\n\tif (bit < 0)\n\t\treturn -ENOSPC;\n\n\tfor (i = 0; i < nr_irqs; i++)\n\t\tirq_domain_set_info(domain, virq + i, bit + i,\n\t\t\t\t    pp->msi_irq_chip,\n\t\t\t\t    pp, handle_edge_irq,\n\t\t\t\t    NULL, NULL);\n\n\treturn 0;\n}\n\nstatic void dw_pcie_irq_domain_free(struct irq_domain *domain,\n\t\t\t\t    unsigned int virq, unsigned int nr_irqs)\n{\n\tstruct irq_data *d = irq_domain_get_irq_data(domain, virq);\n\tstruct dw_pcie_rp *pp = domain->host_data;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&pp->lock, flags);\n\n\tbitmap_release_region(pp->msi_irq_in_use, d->hwirq,\n\t\t\t      order_base_2(nr_irqs));\n\n\traw_spin_unlock_irqrestore(&pp->lock, flags);\n}\n\nstatic const struct irq_domain_ops dw_pcie_msi_domain_ops = {\n\t.alloc\t= dw_pcie_irq_domain_alloc,\n\t.free\t= dw_pcie_irq_domain_free,\n};\n\nint dw_pcie_allocate_domains(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct fwnode_handle *fwnode = of_node_to_fwnode(pci->dev->of_node);\n\n\tpp->irq_domain = irq_domain_create_linear(fwnode, pp->num_vectors,\n\t\t\t\t\t       &dw_pcie_msi_domain_ops, pp);\n\tif (!pp->irq_domain) {\n\t\tdev_err(pci->dev, \"Failed to create IRQ domain\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tirq_domain_update_bus_token(pp->irq_domain, DOMAIN_BUS_NEXUS);\n\n\tpp->msi_domain = pci_msi_create_irq_domain(fwnode,\n\t\t\t\t\t\t   &dw_pcie_msi_domain_info,\n\t\t\t\t\t\t   pp->irq_domain);\n\tif (!pp->msi_domain) {\n\t\tdev_err(pci->dev, \"Failed to create MSI domain\\n\");\n\t\tirq_domain_remove(pp->irq_domain);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic void dw_pcie_free_msi(struct dw_pcie_rp *pp)\n{\n\tu32 ctrl;\n\n\tfor (ctrl = 0; ctrl < MAX_MSI_CTRLS; ctrl++) {\n\t\tif (pp->msi_irq[ctrl] > 0)\n\t\t\tirq_set_chained_handler_and_data(pp->msi_irq[ctrl],\n\t\t\t\t\t\t\t NULL, NULL);\n\t}\n\n\tirq_domain_remove(pp->msi_domain);\n\tirq_domain_remove(pp->irq_domain);\n}\n\nstatic void dw_pcie_msi_init(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tu64 msi_target = (u64)pp->msi_data;\n\n\tif (!pci_msi_enabled() || !pp->has_msi_ctrl)\n\t\treturn;\n\n\t \n\tdw_pcie_writel_dbi(pci, PCIE_MSI_ADDR_LO, lower_32_bits(msi_target));\n\tdw_pcie_writel_dbi(pci, PCIE_MSI_ADDR_HI, upper_32_bits(msi_target));\n}\n\nstatic int dw_pcie_parse_split_msi_irq(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct device *dev = pci->dev;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tu32 ctrl, max_vectors;\n\tint irq;\n\n\t \n\tfor (ctrl = 0; ctrl < MAX_MSI_CTRLS; ctrl++) {\n\t\tchar msi_name[] = \"msiX\";\n\n\t\tmsi_name[3] = '0' + ctrl;\n\t\tirq = platform_get_irq_byname_optional(pdev, msi_name);\n\t\tif (irq == -ENXIO)\n\t\t\tbreak;\n\t\tif (irq < 0)\n\t\t\treturn dev_err_probe(dev, irq,\n\t\t\t\t\t     \"Failed to parse MSI IRQ '%s'\\n\",\n\t\t\t\t\t     msi_name);\n\n\t\tpp->msi_irq[ctrl] = irq;\n\t}\n\n\t \n\tif (ctrl == 0)\n\t\treturn -ENXIO;\n\n\tmax_vectors = ctrl * MAX_MSI_IRQS_PER_CTRL;\n\tif (pp->num_vectors > max_vectors) {\n\t\tdev_warn(dev, \"Exceeding number of MSI vectors, limiting to %u\\n\",\n\t\t\t max_vectors);\n\t\tpp->num_vectors = max_vectors;\n\t}\n\tif (!pp->num_vectors)\n\t\tpp->num_vectors = max_vectors;\n\n\treturn 0;\n}\n\nstatic int dw_pcie_msi_host_init(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct device *dev = pci->dev;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tu64 *msi_vaddr;\n\tint ret;\n\tu32 ctrl, num_ctrls;\n\n\tfor (ctrl = 0; ctrl < MAX_MSI_CTRLS; ctrl++)\n\t\tpp->irq_mask[ctrl] = ~0;\n\n\tif (!pp->msi_irq[0]) {\n\t\tret = dw_pcie_parse_split_msi_irq(pp);\n\t\tif (ret < 0 && ret != -ENXIO)\n\t\t\treturn ret;\n\t}\n\n\tif (!pp->num_vectors)\n\t\tpp->num_vectors = MSI_DEF_NUM_VECTORS;\n\tnum_ctrls = pp->num_vectors / MAX_MSI_IRQS_PER_CTRL;\n\n\tif (!pp->msi_irq[0]) {\n\t\tpp->msi_irq[0] = platform_get_irq_byname_optional(pdev, \"msi\");\n\t\tif (pp->msi_irq[0] < 0) {\n\t\t\tpp->msi_irq[0] = platform_get_irq(pdev, 0);\n\t\t\tif (pp->msi_irq[0] < 0)\n\t\t\t\treturn pp->msi_irq[0];\n\t\t}\n\t}\n\n\tdev_dbg(dev, \"Using %d MSI vectors\\n\", pp->num_vectors);\n\n\tpp->msi_irq_chip = &dw_pci_msi_bottom_irq_chip;\n\n\tret = dw_pcie_allocate_domains(pp);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (ctrl = 0; ctrl < num_ctrls; ctrl++) {\n\t\tif (pp->msi_irq[ctrl] > 0)\n\t\t\tirq_set_chained_handler_and_data(pp->msi_irq[ctrl],\n\t\t\t\t\t\t    dw_chained_msi_isr, pp);\n\t}\n\n\t \n\tret = dma_set_coherent_mask(dev, DMA_BIT_MASK(32));\n\tif (ret)\n\t\tdev_warn(dev, \"Failed to set DMA mask to 32-bit. Devices with only 32-bit MSI support may not work properly\\n\");\n\n\tmsi_vaddr = dmam_alloc_coherent(dev, sizeof(u64), &pp->msi_data,\n\t\t\t\t\tGFP_KERNEL);\n\tif (!msi_vaddr) {\n\t\tdev_err(dev, \"Failed to alloc and map MSI data\\n\");\n\t\tdw_pcie_free_msi(pp);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nint dw_pcie_host_init(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct device *dev = pci->dev;\n\tstruct device_node *np = dev->of_node;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct resource_entry *win;\n\tstruct pci_host_bridge *bridge;\n\tstruct resource *res;\n\tint ret;\n\n\traw_spin_lock_init(&pp->lock);\n\n\tret = dw_pcie_get_resources(pci);\n\tif (ret)\n\t\treturn ret;\n\n\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"config\");\n\tif (res) {\n\t\tpp->cfg0_size = resource_size(res);\n\t\tpp->cfg0_base = res->start;\n\n\t\tpp->va_cfg0_base = devm_pci_remap_cfg_resource(dev, res);\n\t\tif (IS_ERR(pp->va_cfg0_base))\n\t\t\treturn PTR_ERR(pp->va_cfg0_base);\n\t} else {\n\t\tdev_err(dev, \"Missing *config* reg space\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tbridge = devm_pci_alloc_host_bridge(dev, 0);\n\tif (!bridge)\n\t\treturn -ENOMEM;\n\n\tpp->bridge = bridge;\n\n\t \n\twin = resource_list_first_type(&bridge->windows, IORESOURCE_IO);\n\tif (win) {\n\t\tpp->io_size = resource_size(win->res);\n\t\tpp->io_bus_addr = win->res->start - win->offset;\n\t\tpp->io_base = pci_pio_to_address(win->res->start);\n\t}\n\n\t \n\tbridge->ops = &dw_pcie_ops;\n\tbridge->child_ops = &dw_child_pcie_ops;\n\n\tif (pp->ops->host_init) {\n\t\tret = pp->ops->host_init(pp);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (pci_msi_enabled()) {\n\t\tpp->has_msi_ctrl = !(pp->ops->msi_host_init ||\n\t\t\t\t     of_property_read_bool(np, \"msi-parent\") ||\n\t\t\t\t     of_property_read_bool(np, \"msi-map\"));\n\n\t\t \n\t\tif (!pp->has_msi_ctrl && !pp->num_vectors) {\n\t\t\tpp->num_vectors = MSI_DEF_NUM_VECTORS;\n\t\t} else if (pp->num_vectors > MAX_MSI_IRQS) {\n\t\t\tdev_err(dev, \"Invalid number of vectors\\n\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_deinit_host;\n\t\t}\n\n\t\tif (pp->ops->msi_host_init) {\n\t\t\tret = pp->ops->msi_host_init(pp);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto err_deinit_host;\n\t\t} else if (pp->has_msi_ctrl) {\n\t\t\tret = dw_pcie_msi_host_init(pp);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto err_deinit_host;\n\t\t}\n\t}\n\n\tdw_pcie_version_detect(pci);\n\n\tdw_pcie_iatu_detect(pci);\n\n\tret = dw_pcie_edma_detect(pci);\n\tif (ret)\n\t\tgoto err_free_msi;\n\n\tret = dw_pcie_setup_rc(pp);\n\tif (ret)\n\t\tgoto err_remove_edma;\n\n\tif (!dw_pcie_link_up(pci)) {\n\t\tret = dw_pcie_start_link(pci);\n\t\tif (ret)\n\t\t\tgoto err_remove_edma;\n\t}\n\n\t \n\tdw_pcie_wait_for_link(pci);\n\n\tbridge->sysdata = pp;\n\n\tret = pci_host_probe(bridge);\n\tif (ret)\n\t\tgoto err_stop_link;\n\n\treturn 0;\n\nerr_stop_link:\n\tdw_pcie_stop_link(pci);\n\nerr_remove_edma:\n\tdw_pcie_edma_remove(pci);\n\nerr_free_msi:\n\tif (pp->has_msi_ctrl)\n\t\tdw_pcie_free_msi(pp);\n\nerr_deinit_host:\n\tif (pp->ops->host_deinit)\n\t\tpp->ops->host_deinit(pp);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(dw_pcie_host_init);\n\nvoid dw_pcie_host_deinit(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\n\tpci_stop_root_bus(pp->bridge->bus);\n\tpci_remove_root_bus(pp->bridge->bus);\n\n\tdw_pcie_stop_link(pci);\n\n\tdw_pcie_edma_remove(pci);\n\n\tif (pp->has_msi_ctrl)\n\t\tdw_pcie_free_msi(pp);\n\n\tif (pp->ops->host_deinit)\n\t\tpp->ops->host_deinit(pp);\n}\nEXPORT_SYMBOL_GPL(dw_pcie_host_deinit);\n\nstatic void __iomem *dw_pcie_other_conf_map_bus(struct pci_bus *bus,\n\t\t\t\t\t\tunsigned int devfn, int where)\n{\n\tstruct dw_pcie_rp *pp = bus->sysdata;\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tint type, ret;\n\tu32 busdev;\n\n\t \n\tif (!dw_pcie_link_up(pci))\n\t\treturn NULL;\n\n\tbusdev = PCIE_ATU_BUS(bus->number) | PCIE_ATU_DEV(PCI_SLOT(devfn)) |\n\t\t PCIE_ATU_FUNC(PCI_FUNC(devfn));\n\n\tif (pci_is_root_bus(bus->parent))\n\t\ttype = PCIE_ATU_TYPE_CFG0;\n\telse\n\t\ttype = PCIE_ATU_TYPE_CFG1;\n\n\tret = dw_pcie_prog_outbound_atu(pci, 0, type, pp->cfg0_base, busdev,\n\t\t\t\t\tpp->cfg0_size);\n\tif (ret)\n\t\treturn NULL;\n\n\treturn pp->va_cfg0_base + where;\n}\n\nstatic int dw_pcie_rd_other_conf(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\t int where, int size, u32 *val)\n{\n\tstruct dw_pcie_rp *pp = bus->sysdata;\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tint ret;\n\n\tret = pci_generic_config_read(bus, devfn, where, size, val);\n\tif (ret != PCIBIOS_SUCCESSFUL)\n\t\treturn ret;\n\n\tif (pp->cfg0_io_shared) {\n\t\tret = dw_pcie_prog_outbound_atu(pci, 0, PCIE_ATU_TYPE_IO,\n\t\t\t\t\t\tpp->io_base, pp->io_bus_addr,\n\t\t\t\t\t\tpp->io_size);\n\t\tif (ret)\n\t\t\treturn PCIBIOS_SET_FAILED;\n\t}\n\n\treturn PCIBIOS_SUCCESSFUL;\n}\n\nstatic int dw_pcie_wr_other_conf(struct pci_bus *bus, unsigned int devfn,\n\t\t\t\t int where, int size, u32 val)\n{\n\tstruct dw_pcie_rp *pp = bus->sysdata;\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tint ret;\n\n\tret = pci_generic_config_write(bus, devfn, where, size, val);\n\tif (ret != PCIBIOS_SUCCESSFUL)\n\t\treturn ret;\n\n\tif (pp->cfg0_io_shared) {\n\t\tret = dw_pcie_prog_outbound_atu(pci, 0, PCIE_ATU_TYPE_IO,\n\t\t\t\t\t\tpp->io_base, pp->io_bus_addr,\n\t\t\t\t\t\tpp->io_size);\n\t\tif (ret)\n\t\t\treturn PCIBIOS_SET_FAILED;\n\t}\n\n\treturn PCIBIOS_SUCCESSFUL;\n}\n\nstatic struct pci_ops dw_child_pcie_ops = {\n\t.map_bus = dw_pcie_other_conf_map_bus,\n\t.read = dw_pcie_rd_other_conf,\n\t.write = dw_pcie_wr_other_conf,\n};\n\nvoid __iomem *dw_pcie_own_conf_map_bus(struct pci_bus *bus, unsigned int devfn, int where)\n{\n\tstruct dw_pcie_rp *pp = bus->sysdata;\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\n\tif (PCI_SLOT(devfn) > 0)\n\t\treturn NULL;\n\n\treturn pci->dbi_base + where;\n}\nEXPORT_SYMBOL_GPL(dw_pcie_own_conf_map_bus);\n\nstatic struct pci_ops dw_pcie_ops = {\n\t.map_bus = dw_pcie_own_conf_map_bus,\n\t.read = pci_generic_config_read,\n\t.write = pci_generic_config_write,\n};\n\nstatic int dw_pcie_iatu_setup(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct resource_entry *entry;\n\tint i, ret;\n\n\t \n\tif (!pci->num_ob_windows) {\n\t\tdev_err(pci->dev, \"No outbound iATU found\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tfor (i = 0; i < pci->num_ob_windows; i++)\n\t\tdw_pcie_disable_atu(pci, PCIE_ATU_REGION_DIR_OB, i);\n\n\tfor (i = 0; i < pci->num_ib_windows; i++)\n\t\tdw_pcie_disable_atu(pci, PCIE_ATU_REGION_DIR_IB, i);\n\n\ti = 0;\n\tresource_list_for_each_entry(entry, &pp->bridge->windows) {\n\t\tif (resource_type(entry->res) != IORESOURCE_MEM)\n\t\t\tcontinue;\n\n\t\tif (pci->num_ob_windows <= ++i)\n\t\t\tbreak;\n\n\t\tret = dw_pcie_prog_outbound_atu(pci, i, PCIE_ATU_TYPE_MEM,\n\t\t\t\t\t\tentry->res->start,\n\t\t\t\t\t\tentry->res->start - entry->offset,\n\t\t\t\t\t\tresource_size(entry->res));\n\t\tif (ret) {\n\t\t\tdev_err(pci->dev, \"Failed to set MEM range %pr\\n\",\n\t\t\t\tentry->res);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (pp->io_size) {\n\t\tif (pci->num_ob_windows > ++i) {\n\t\t\tret = dw_pcie_prog_outbound_atu(pci, i, PCIE_ATU_TYPE_IO,\n\t\t\t\t\t\t\tpp->io_base,\n\t\t\t\t\t\t\tpp->io_bus_addr,\n\t\t\t\t\t\t\tpp->io_size);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(pci->dev, \"Failed to set IO range %pr\\n\",\n\t\t\t\t\tentry->res);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t} else {\n\t\t\tpp->cfg0_io_shared = true;\n\t\t}\n\t}\n\n\tif (pci->num_ob_windows <= i)\n\t\tdev_warn(pci->dev, \"Ranges exceed outbound iATU size (%d)\\n\",\n\t\t\t pci->num_ob_windows);\n\n\ti = 0;\n\tresource_list_for_each_entry(entry, &pp->bridge->dma_ranges) {\n\t\tif (resource_type(entry->res) != IORESOURCE_MEM)\n\t\t\tcontinue;\n\n\t\tif (pci->num_ib_windows <= i)\n\t\t\tbreak;\n\n\t\tret = dw_pcie_prog_inbound_atu(pci, i++, PCIE_ATU_TYPE_MEM,\n\t\t\t\t\t       entry->res->start,\n\t\t\t\t\t       entry->res->start - entry->offset,\n\t\t\t\t\t       resource_size(entry->res));\n\t\tif (ret) {\n\t\t\tdev_err(pci->dev, \"Failed to set DMA range %pr\\n\",\n\t\t\t\tentry->res);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (pci->num_ib_windows <= i)\n\t\tdev_warn(pci->dev, \"Dma-ranges exceed inbound iATU size (%u)\\n\",\n\t\t\t pci->num_ib_windows);\n\n\treturn 0;\n}\n\nint dw_pcie_setup_rc(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tu32 val, ctrl, num_ctrls;\n\tint ret;\n\n\t \n\tdw_pcie_dbi_ro_wr_en(pci);\n\n\tdw_pcie_setup(pci);\n\n\tif (pp->has_msi_ctrl) {\n\t\tnum_ctrls = pp->num_vectors / MAX_MSI_IRQS_PER_CTRL;\n\n\t\t \n\t\tfor (ctrl = 0; ctrl < num_ctrls; ctrl++) {\n\t\t\tdw_pcie_writel_dbi(pci, PCIE_MSI_INTR0_MASK +\n\t\t\t\t\t    (ctrl * MSI_REG_CTRL_BLOCK_SIZE),\n\t\t\t\t\t    pp->irq_mask[ctrl]);\n\t\t\tdw_pcie_writel_dbi(pci, PCIE_MSI_INTR0_ENABLE +\n\t\t\t\t\t    (ctrl * MSI_REG_CTRL_BLOCK_SIZE),\n\t\t\t\t\t    ~0);\n\t\t}\n\t}\n\n\tdw_pcie_msi_init(pp);\n\n\t \n\tdw_pcie_writel_dbi(pci, PCI_BASE_ADDRESS_0, 0x00000004);\n\tdw_pcie_writel_dbi(pci, PCI_BASE_ADDRESS_1, 0x00000000);\n\n\t \n\tval = dw_pcie_readl_dbi(pci, PCI_INTERRUPT_LINE);\n\tval &= 0xffff00ff;\n\tval |= 0x00000100;\n\tdw_pcie_writel_dbi(pci, PCI_INTERRUPT_LINE, val);\n\n\t \n\tval = dw_pcie_readl_dbi(pci, PCI_PRIMARY_BUS);\n\tval &= 0xff000000;\n\tval |= 0x00ff0100;\n\tdw_pcie_writel_dbi(pci, PCI_PRIMARY_BUS, val);\n\n\t \n\tval = dw_pcie_readl_dbi(pci, PCI_COMMAND);\n\tval &= 0xffff0000;\n\tval |= PCI_COMMAND_IO | PCI_COMMAND_MEMORY |\n\t\tPCI_COMMAND_MASTER | PCI_COMMAND_SERR;\n\tdw_pcie_writel_dbi(pci, PCI_COMMAND, val);\n\n\t \n\tif (pp->bridge->child_ops == &dw_child_pcie_ops) {\n\t\tret = dw_pcie_iatu_setup(pp);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tdw_pcie_writel_dbi(pci, PCI_BASE_ADDRESS_0, 0);\n\n\t \n\tdw_pcie_writew_dbi(pci, PCI_CLASS_DEVICE, PCI_CLASS_BRIDGE_PCI);\n\n\tval = dw_pcie_readl_dbi(pci, PCIE_LINK_WIDTH_SPEED_CONTROL);\n\tval |= PORT_LOGIC_SPEED_CHANGE;\n\tdw_pcie_writel_dbi(pci, PCIE_LINK_WIDTH_SPEED_CONTROL, val);\n\n\tdw_pcie_dbi_ro_wr_dis(pci);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(dw_pcie_setup_rc);\n\nint dw_pcie_suspend_noirq(struct dw_pcie *pci)\n{\n\tu8 offset = dw_pcie_find_capability(pci, PCI_CAP_ID_EXP);\n\tu32 val;\n\tint ret;\n\n\t \n\tif (dw_pcie_readw_dbi(pci, offset + PCI_EXP_LNKCTL) & PCI_EXP_LNKCTL_ASPM_L1)\n\t\treturn 0;\n\n\tif (dw_pcie_get_ltssm(pci) <= DW_PCIE_LTSSM_DETECT_ACT)\n\t\treturn 0;\n\n\tif (!pci->pp.ops->pme_turn_off)\n\t\treturn 0;\n\n\tpci->pp.ops->pme_turn_off(&pci->pp);\n\n\tret = read_poll_timeout(dw_pcie_get_ltssm, val, val == DW_PCIE_LTSSM_L2_IDLE,\n\t\t\t\tPCIE_PME_TO_L2_TIMEOUT_US/10,\n\t\t\t\tPCIE_PME_TO_L2_TIMEOUT_US, false, pci);\n\tif (ret) {\n\t\tdev_err(pci->dev, \"Timeout waiting for L2 entry! LTSSM: 0x%x\\n\", val);\n\t\treturn ret;\n\t}\n\n\tif (pci->pp.ops->host_deinit)\n\t\tpci->pp.ops->host_deinit(&pci->pp);\n\n\tpci->suspended = true;\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(dw_pcie_suspend_noirq);\n\nint dw_pcie_resume_noirq(struct dw_pcie *pci)\n{\n\tint ret;\n\n\tif (!pci->suspended)\n\t\treturn 0;\n\n\tpci->suspended = false;\n\n\tif (pci->pp.ops->host_init) {\n\t\tret = pci->pp.ops->host_init(&pci->pp);\n\t\tif (ret) {\n\t\t\tdev_err(pci->dev, \"Host init failed: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tdw_pcie_setup_rc(&pci->pp);\n\n\tret = dw_pcie_start_link(pci);\n\tif (ret)\n\t\treturn ret;\n\n\tret = dw_pcie_wait_for_link(pci);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(dw_pcie_resume_noirq);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}