{
  "module_name": "pci-keystone.c",
  "hash_id": "8717e945549e6cbf4f207a68922c1cd4b6ddf1e899979bd149a51d6071d25d93",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/controller/dwc/pci-keystone.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/gpio/consumer.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/irqchip/chained_irq.h>\n#include <linux/irqdomain.h>\n#include <linux/mfd/syscon.h>\n#include <linux/msi.h>\n#include <linux/of.h>\n#include <linux/of_irq.h>\n#include <linux/of_pci.h>\n#include <linux/phy/phy.h>\n#include <linux/platform_device.h>\n#include <linux/regmap.h>\n#include <linux/resource.h>\n#include <linux/signal.h>\n\n#include \"../../pci.h\"\n#include \"pcie-designware.h\"\n\n#define PCIE_VENDORID_MASK\t0xffff\n#define PCIE_DEVICEID_SHIFT\t16\n\n \n#define CMD_STATUS\t\t\t0x004\n#define LTSSM_EN_VAL\t\t        BIT(0)\n#define OB_XLAT_EN_VAL\t\t        BIT(1)\n#define DBI_CS2\t\t\t\tBIT(5)\n\n#define CFG_SETUP\t\t\t0x008\n#define CFG_BUS(x)\t\t\t(((x) & 0xff) << 16)\n#define CFG_DEVICE(x)\t\t\t(((x) & 0x1f) << 8)\n#define CFG_FUNC(x)\t\t\t((x) & 0x7)\n#define CFG_TYPE1\t\t\tBIT(24)\n\n#define OB_SIZE\t\t\t\t0x030\n#define OB_OFFSET_INDEX(n)\t\t(0x200 + (8 * (n)))\n#define OB_OFFSET_HI(n)\t\t\t(0x204 + (8 * (n)))\n#define OB_ENABLEN\t\t\tBIT(0)\n#define OB_WIN_SIZE\t\t\t8\t \n\n#define PCIE_LEGACY_IRQ_ENABLE_SET(n)\t(0x188 + (0x10 * ((n) - 1)))\n#define PCIE_LEGACY_IRQ_ENABLE_CLR(n)\t(0x18c + (0x10 * ((n) - 1)))\n#define PCIE_EP_IRQ_SET\t\t\t0x64\n#define PCIE_EP_IRQ_CLR\t\t\t0x68\n#define INT_ENABLE\t\t\tBIT(0)\n\n \n#define IRQ_EOI\t\t\t\t0x050\n\n#define MSI_IRQ\t\t\t\t0x054\n#define MSI_IRQ_STATUS(n)\t\t(0x104 + ((n) << 4))\n#define MSI_IRQ_ENABLE_SET(n)\t\t(0x108 + ((n) << 4))\n#define MSI_IRQ_ENABLE_CLR(n)\t\t(0x10c + ((n) << 4))\n#define MSI_IRQ_OFFSET\t\t\t4\n\n#define IRQ_STATUS(n)\t\t\t(0x184 + ((n) << 4))\n#define IRQ_ENABLE_SET(n)\t\t(0x188 + ((n) << 4))\n#define INTx_EN\t\t\t\tBIT(0)\n\n#define ERR_IRQ_STATUS\t\t\t0x1c4\n#define ERR_IRQ_ENABLE_SET\t\t0x1c8\n#define ERR_AER\t\t\t\tBIT(5)\t \n#define AM6_ERR_AER\t\t\tBIT(4)\t \n#define ERR_AXI\t\t\t\tBIT(4)\t \n#define ERR_CORR\t\t\tBIT(3)\t \n#define ERR_NONFATAL\t\t\tBIT(2)\t \n#define ERR_FATAL\t\t\tBIT(1)\t \n#define ERR_SYS\t\t\t\tBIT(0)\t \n#define ERR_IRQ_ALL\t\t\t(ERR_AER | ERR_AXI | ERR_CORR | \\\n\t\t\t\t\t ERR_NONFATAL | ERR_FATAL | ERR_SYS)\n\n \n#define PCIE_RC_K2HK\t\t\t0xb008\n#define PCIE_RC_K2E\t\t\t0xb009\n#define PCIE_RC_K2L\t\t\t0xb00a\n#define PCIE_RC_K2G\t\t\t0xb00b\n\n#define KS_PCIE_DEV_TYPE_MASK\t\t(0x3 << 1)\n#define KS_PCIE_DEV_TYPE(mode)\t\t((mode) << 1)\n\n#define EP\t\t\t\t0x0\n#define LEG_EP\t\t\t\t0x1\n#define RC\t\t\t\t0x2\n\n#define KS_PCIE_SYSCLOCKOUTEN\t\tBIT(0)\n\n#define AM654_PCIE_DEV_TYPE_MASK\t0x3\n#define AM654_WIN_SIZE\t\t\tSZ_64K\n\n#define APP_ADDR_SPACE_0\t\t(16 * SZ_1K)\n\n#define to_keystone_pcie(x)\t\tdev_get_drvdata((x)->dev)\n\nstruct ks_pcie_of_data {\n\tenum dw_pcie_device_mode mode;\n\tconst struct dw_pcie_host_ops *host_ops;\n\tconst struct dw_pcie_ep_ops *ep_ops;\n\tu32 version;\n};\n\nstruct keystone_pcie {\n\tstruct dw_pcie\t\t*pci;\n\t \n\tu32\t\t\tdevice_id;\n\tint\t\t\tlegacy_host_irqs[PCI_NUM_INTX];\n\tstruct\t\t\tdevice_node *legacy_intc_np;\n\n\tint\t\t\tmsi_host_irq;\n\tint\t\t\tnum_lanes;\n\tu32\t\t\tnum_viewport;\n\tstruct phy\t\t**phy;\n\tstruct device_link\t**link;\n\tstruct\t\t\tdevice_node *msi_intc_np;\n\tstruct irq_domain\t*legacy_irq_domain;\n\tstruct device_node\t*np;\n\n\t \n\tvoid __iomem\t\t*va_app_base;\t \n\tstruct resource\t\tapp;\n\tbool\t\t\tis_am6;\n};\n\nstatic u32 ks_pcie_app_readl(struct keystone_pcie *ks_pcie, u32 offset)\n{\n\treturn readl(ks_pcie->va_app_base + offset);\n}\n\nstatic void ks_pcie_app_writel(struct keystone_pcie *ks_pcie, u32 offset,\n\t\t\t       u32 val)\n{\n\twritel(val, ks_pcie->va_app_base + offset);\n}\n\nstatic void ks_pcie_msi_irq_ack(struct irq_data *data)\n{\n\tstruct dw_pcie_rp *pp  = irq_data_get_irq_chip_data(data);\n\tstruct keystone_pcie *ks_pcie;\n\tu32 irq = data->hwirq;\n\tstruct dw_pcie *pci;\n\tu32 reg_offset;\n\tu32 bit_pos;\n\n\tpci = to_dw_pcie_from_pp(pp);\n\tks_pcie = to_keystone_pcie(pci);\n\n\treg_offset = irq % 8;\n\tbit_pos = irq >> 3;\n\n\tks_pcie_app_writel(ks_pcie, MSI_IRQ_STATUS(reg_offset),\n\t\t\t   BIT(bit_pos));\n\tks_pcie_app_writel(ks_pcie, IRQ_EOI, reg_offset + MSI_IRQ_OFFSET);\n}\n\nstatic void ks_pcie_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)\n{\n\tstruct dw_pcie_rp *pp = irq_data_get_irq_chip_data(data);\n\tstruct keystone_pcie *ks_pcie;\n\tstruct dw_pcie *pci;\n\tu64 msi_target;\n\n\tpci = to_dw_pcie_from_pp(pp);\n\tks_pcie = to_keystone_pcie(pci);\n\n\tmsi_target = ks_pcie->app.start + MSI_IRQ;\n\tmsg->address_lo = lower_32_bits(msi_target);\n\tmsg->address_hi = upper_32_bits(msi_target);\n\tmsg->data = data->hwirq;\n\n\tdev_dbg(pci->dev, \"msi#%d address_hi %#x address_lo %#x\\n\",\n\t\t(int)data->hwirq, msg->address_hi, msg->address_lo);\n}\n\nstatic int ks_pcie_msi_set_affinity(struct irq_data *irq_data,\n\t\t\t\t    const struct cpumask *mask, bool force)\n{\n\treturn -EINVAL;\n}\n\nstatic void ks_pcie_msi_mask(struct irq_data *data)\n{\n\tstruct dw_pcie_rp *pp = irq_data_get_irq_chip_data(data);\n\tstruct keystone_pcie *ks_pcie;\n\tu32 irq = data->hwirq;\n\tstruct dw_pcie *pci;\n\tunsigned long flags;\n\tu32 reg_offset;\n\tu32 bit_pos;\n\n\traw_spin_lock_irqsave(&pp->lock, flags);\n\n\tpci = to_dw_pcie_from_pp(pp);\n\tks_pcie = to_keystone_pcie(pci);\n\n\treg_offset = irq % 8;\n\tbit_pos = irq >> 3;\n\n\tks_pcie_app_writel(ks_pcie, MSI_IRQ_ENABLE_CLR(reg_offset),\n\t\t\t   BIT(bit_pos));\n\n\traw_spin_unlock_irqrestore(&pp->lock, flags);\n}\n\nstatic void ks_pcie_msi_unmask(struct irq_data *data)\n{\n\tstruct dw_pcie_rp *pp = irq_data_get_irq_chip_data(data);\n\tstruct keystone_pcie *ks_pcie;\n\tu32 irq = data->hwirq;\n\tstruct dw_pcie *pci;\n\tunsigned long flags;\n\tu32 reg_offset;\n\tu32 bit_pos;\n\n\traw_spin_lock_irqsave(&pp->lock, flags);\n\n\tpci = to_dw_pcie_from_pp(pp);\n\tks_pcie = to_keystone_pcie(pci);\n\n\treg_offset = irq % 8;\n\tbit_pos = irq >> 3;\n\n\tks_pcie_app_writel(ks_pcie, MSI_IRQ_ENABLE_SET(reg_offset),\n\t\t\t   BIT(bit_pos));\n\n\traw_spin_unlock_irqrestore(&pp->lock, flags);\n}\n\nstatic struct irq_chip ks_pcie_msi_irq_chip = {\n\t.name = \"KEYSTONE-PCI-MSI\",\n\t.irq_ack = ks_pcie_msi_irq_ack,\n\t.irq_compose_msi_msg = ks_pcie_compose_msi_msg,\n\t.irq_set_affinity = ks_pcie_msi_set_affinity,\n\t.irq_mask = ks_pcie_msi_mask,\n\t.irq_unmask = ks_pcie_msi_unmask,\n};\n\nstatic int ks_pcie_msi_host_init(struct dw_pcie_rp *pp)\n{\n\tpp->msi_irq_chip = &ks_pcie_msi_irq_chip;\n\treturn dw_pcie_allocate_domains(pp);\n}\n\nstatic void ks_pcie_handle_legacy_irq(struct keystone_pcie *ks_pcie,\n\t\t\t\t      int offset)\n{\n\tstruct dw_pcie *pci = ks_pcie->pci;\n\tstruct device *dev = pci->dev;\n\tu32 pending;\n\n\tpending = ks_pcie_app_readl(ks_pcie, IRQ_STATUS(offset));\n\n\tif (BIT(0) & pending) {\n\t\tdev_dbg(dev, \": irq: irq_offset %d\", offset);\n\t\tgeneric_handle_domain_irq(ks_pcie->legacy_irq_domain, offset);\n\t}\n\n\t \n\tks_pcie_app_writel(ks_pcie, IRQ_EOI, offset);\n}\n\nstatic void ks_pcie_enable_error_irq(struct keystone_pcie *ks_pcie)\n{\n\tks_pcie_app_writel(ks_pcie, ERR_IRQ_ENABLE_SET, ERR_IRQ_ALL);\n}\n\nstatic irqreturn_t ks_pcie_handle_error_irq(struct keystone_pcie *ks_pcie)\n{\n\tu32 reg;\n\tstruct device *dev = ks_pcie->pci->dev;\n\n\treg = ks_pcie_app_readl(ks_pcie, ERR_IRQ_STATUS);\n\tif (!reg)\n\t\treturn IRQ_NONE;\n\n\tif (reg & ERR_SYS)\n\t\tdev_err(dev, \"System Error\\n\");\n\n\tif (reg & ERR_FATAL)\n\t\tdev_err(dev, \"Fatal Error\\n\");\n\n\tif (reg & ERR_NONFATAL)\n\t\tdev_dbg(dev, \"Non Fatal Error\\n\");\n\n\tif (reg & ERR_CORR)\n\t\tdev_dbg(dev, \"Correctable Error\\n\");\n\n\tif (!ks_pcie->is_am6 && (reg & ERR_AXI))\n\t\tdev_err(dev, \"AXI tag lookup fatal Error\\n\");\n\n\tif (reg & ERR_AER || (ks_pcie->is_am6 && (reg & AM6_ERR_AER)))\n\t\tdev_err(dev, \"ECRC Error\\n\");\n\n\tks_pcie_app_writel(ks_pcie, ERR_IRQ_STATUS, reg);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void ks_pcie_ack_legacy_irq(struct irq_data *d)\n{\n}\n\nstatic void ks_pcie_mask_legacy_irq(struct irq_data *d)\n{\n}\n\nstatic void ks_pcie_unmask_legacy_irq(struct irq_data *d)\n{\n}\n\nstatic struct irq_chip ks_pcie_legacy_irq_chip = {\n\t.name = \"Keystone-PCI-Legacy-IRQ\",\n\t.irq_ack = ks_pcie_ack_legacy_irq,\n\t.irq_mask = ks_pcie_mask_legacy_irq,\n\t.irq_unmask = ks_pcie_unmask_legacy_irq,\n};\n\nstatic int ks_pcie_init_legacy_irq_map(struct irq_domain *d,\n\t\t\t\t       unsigned int irq,\n\t\t\t\t       irq_hw_number_t hw_irq)\n{\n\tirq_set_chip_and_handler(irq, &ks_pcie_legacy_irq_chip,\n\t\t\t\t handle_level_irq);\n\tirq_set_chip_data(irq, d->host_data);\n\n\treturn 0;\n}\n\nstatic const struct irq_domain_ops ks_pcie_legacy_irq_domain_ops = {\n\t.map = ks_pcie_init_legacy_irq_map,\n\t.xlate = irq_domain_xlate_onetwocell,\n};\n\n \nstatic void ks_pcie_set_dbi_mode(struct keystone_pcie *ks_pcie)\n{\n\tu32 val;\n\n\tval = ks_pcie_app_readl(ks_pcie, CMD_STATUS);\n\tval |= DBI_CS2;\n\tks_pcie_app_writel(ks_pcie, CMD_STATUS, val);\n\n\tdo {\n\t\tval = ks_pcie_app_readl(ks_pcie, CMD_STATUS);\n\t} while (!(val & DBI_CS2));\n}\n\n \nstatic void ks_pcie_clear_dbi_mode(struct keystone_pcie *ks_pcie)\n{\n\tu32 val;\n\n\tval = ks_pcie_app_readl(ks_pcie, CMD_STATUS);\n\tval &= ~DBI_CS2;\n\tks_pcie_app_writel(ks_pcie, CMD_STATUS, val);\n\n\tdo {\n\t\tval = ks_pcie_app_readl(ks_pcie, CMD_STATUS);\n\t} while (val & DBI_CS2);\n}\n\nstatic void ks_pcie_setup_rc_app_regs(struct keystone_pcie *ks_pcie)\n{\n\tu32 val;\n\tu32 num_viewport = ks_pcie->num_viewport;\n\tstruct dw_pcie *pci = ks_pcie->pci;\n\tstruct dw_pcie_rp *pp = &pci->pp;\n\tu64 start, end;\n\tstruct resource *mem;\n\tint i;\n\n\tmem = resource_list_first_type(&pp->bridge->windows, IORESOURCE_MEM)->res;\n\tstart = mem->start;\n\tend = mem->end;\n\n\t \n\tks_pcie_set_dbi_mode(ks_pcie);\n\tdw_pcie_writel_dbi(pci, PCI_BASE_ADDRESS_0, 0);\n\tdw_pcie_writel_dbi(pci, PCI_BASE_ADDRESS_1, 0);\n\tks_pcie_clear_dbi_mode(ks_pcie);\n\n\tif (ks_pcie->is_am6)\n\t\treturn;\n\n\tval = ilog2(OB_WIN_SIZE);\n\tks_pcie_app_writel(ks_pcie, OB_SIZE, val);\n\n\t \n\tfor (i = 0; i < num_viewport && (start < end); i++) {\n\t\tks_pcie_app_writel(ks_pcie, OB_OFFSET_INDEX(i),\n\t\t\t\t   lower_32_bits(start) | OB_ENABLEN);\n\t\tks_pcie_app_writel(ks_pcie, OB_OFFSET_HI(i),\n\t\t\t\t   upper_32_bits(start));\n\t\tstart += OB_WIN_SIZE * SZ_1M;\n\t}\n\n\tval = ks_pcie_app_readl(ks_pcie, CMD_STATUS);\n\tval |= OB_XLAT_EN_VAL;\n\tks_pcie_app_writel(ks_pcie, CMD_STATUS, val);\n}\n\nstatic void __iomem *ks_pcie_other_map_bus(struct pci_bus *bus,\n\t\t\t\t\t   unsigned int devfn, int where)\n{\n\tstruct dw_pcie_rp *pp = bus->sysdata;\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct keystone_pcie *ks_pcie = to_keystone_pcie(pci);\n\tu32 reg;\n\n\treg = CFG_BUS(bus->number) | CFG_DEVICE(PCI_SLOT(devfn)) |\n\t\tCFG_FUNC(PCI_FUNC(devfn));\n\tif (!pci_is_root_bus(bus->parent))\n\t\treg |= CFG_TYPE1;\n\tks_pcie_app_writel(ks_pcie, CFG_SETUP, reg);\n\n\treturn pp->va_cfg0_base + where;\n}\n\nstatic struct pci_ops ks_child_pcie_ops = {\n\t.map_bus = ks_pcie_other_map_bus,\n\t.read = pci_generic_config_read,\n\t.write = pci_generic_config_write,\n};\n\n \nstatic int ks_pcie_v3_65_add_bus(struct pci_bus *bus)\n{\n\tstruct dw_pcie_rp *pp = bus->sysdata;\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct keystone_pcie *ks_pcie = to_keystone_pcie(pci);\n\n\tif (!pci_is_root_bus(bus))\n\t\treturn 0;\n\n\t \n\tks_pcie_set_dbi_mode(ks_pcie);\n\n\t \n\tdw_pcie_writel_dbi(pci, PCI_BASE_ADDRESS_0, 1);\n\tdw_pcie_writel_dbi(pci, PCI_BASE_ADDRESS_0, SZ_4K - 1);\n\n\tks_pcie_clear_dbi_mode(ks_pcie);\n\n\t  \n\tdw_pcie_writel_dbi(pci, PCI_BASE_ADDRESS_0, ks_pcie->app.start);\n\n\treturn 0;\n}\n\nstatic struct pci_ops ks_pcie_ops = {\n\t.map_bus = dw_pcie_own_conf_map_bus,\n\t.read = pci_generic_config_read,\n\t.write = pci_generic_config_write,\n\t.add_bus = ks_pcie_v3_65_add_bus,\n};\n\n \nstatic int ks_pcie_link_up(struct dw_pcie *pci)\n{\n\tu32 val;\n\n\tval = dw_pcie_readl_dbi(pci, PCIE_PORT_DEBUG0);\n\tval &= PORT_LOGIC_LTSSM_STATE_MASK;\n\treturn (val == PORT_LOGIC_LTSSM_STATE_L0);\n}\n\nstatic void ks_pcie_stop_link(struct dw_pcie *pci)\n{\n\tstruct keystone_pcie *ks_pcie = to_keystone_pcie(pci);\n\tu32 val;\n\n\t \n\tval = ks_pcie_app_readl(ks_pcie, CMD_STATUS);\n\tval &= ~LTSSM_EN_VAL;\n\tks_pcie_app_writel(ks_pcie, CMD_STATUS, val);\n}\n\nstatic int ks_pcie_start_link(struct dw_pcie *pci)\n{\n\tstruct keystone_pcie *ks_pcie = to_keystone_pcie(pci);\n\tu32 val;\n\n\t \n\tval = ks_pcie_app_readl(ks_pcie, CMD_STATUS);\n\tks_pcie_app_writel(ks_pcie, CMD_STATUS, LTSSM_EN_VAL | val);\n\n\treturn 0;\n}\n\nstatic void ks_pcie_quirk(struct pci_dev *dev)\n{\n\tstruct pci_bus *bus = dev->bus;\n\tstruct pci_dev *bridge;\n\tstatic const struct pci_device_id rc_pci_devids[] = {\n\t\t{ PCI_DEVICE(PCI_VENDOR_ID_TI, PCIE_RC_K2HK),\n\t\t .class = PCI_CLASS_BRIDGE_PCI_NORMAL, .class_mask = ~0, },\n\t\t{ PCI_DEVICE(PCI_VENDOR_ID_TI, PCIE_RC_K2E),\n\t\t .class = PCI_CLASS_BRIDGE_PCI_NORMAL, .class_mask = ~0, },\n\t\t{ PCI_DEVICE(PCI_VENDOR_ID_TI, PCIE_RC_K2L),\n\t\t .class = PCI_CLASS_BRIDGE_PCI_NORMAL, .class_mask = ~0, },\n\t\t{ PCI_DEVICE(PCI_VENDOR_ID_TI, PCIE_RC_K2G),\n\t\t .class = PCI_CLASS_BRIDGE_PCI_NORMAL, .class_mask = ~0, },\n\t\t{ 0, },\n\t};\n\n\tif (pci_is_root_bus(bus))\n\t\tbridge = dev;\n\n\t \n\twhile (!pci_is_root_bus(bus)) {\n\t\tbridge = bus->self;\n\t\tbus = bus->parent;\n\t}\n\n\tif (!bridge)\n\t\treturn;\n\n\t \n\tif (pci_match_id(rc_pci_devids, bridge)) {\n\t\tif (pcie_get_readrq(dev) > 256) {\n\t\t\tdev_info(&dev->dev, \"limiting MRRS to 256\\n\");\n\t\t\tpcie_set_readrq(dev, 256);\n\t\t}\n\t}\n}\nDECLARE_PCI_FIXUP_ENABLE(PCI_ANY_ID, PCI_ANY_ID, ks_pcie_quirk);\n\nstatic void ks_pcie_msi_irq_handler(struct irq_desc *desc)\n{\n\tunsigned int irq = desc->irq_data.hwirq;\n\tstruct keystone_pcie *ks_pcie = irq_desc_get_handler_data(desc);\n\tu32 offset = irq - ks_pcie->msi_host_irq;\n\tstruct dw_pcie *pci = ks_pcie->pci;\n\tstruct dw_pcie_rp *pp = &pci->pp;\n\tstruct device *dev = pci->dev;\n\tstruct irq_chip *chip = irq_desc_get_chip(desc);\n\tu32 vector, reg, pos;\n\n\tdev_dbg(dev, \"%s, irq %d\\n\", __func__, irq);\n\n\t \n\tchained_irq_enter(chip, desc);\n\n\treg = ks_pcie_app_readl(ks_pcie, MSI_IRQ_STATUS(offset));\n\t \n\tfor (pos = 0; pos < 4; pos++) {\n\t\tif (!(reg & BIT(pos)))\n\t\t\tcontinue;\n\n\t\tvector = offset + (pos << 3);\n\t\tdev_dbg(dev, \"irq: bit %d, vector %d\\n\", pos, vector);\n\t\tgeneric_handle_domain_irq(pp->irq_domain, vector);\n\t}\n\n\tchained_irq_exit(chip, desc);\n}\n\n \nstatic void ks_pcie_legacy_irq_handler(struct irq_desc *desc)\n{\n\tunsigned int irq = irq_desc_get_irq(desc);\n\tstruct keystone_pcie *ks_pcie = irq_desc_get_handler_data(desc);\n\tstruct dw_pcie *pci = ks_pcie->pci;\n\tstruct device *dev = pci->dev;\n\tu32 irq_offset = irq - ks_pcie->legacy_host_irqs[0];\n\tstruct irq_chip *chip = irq_desc_get_chip(desc);\n\n\tdev_dbg(dev, \": Handling legacy irq %d\\n\", irq);\n\n\t \n\tchained_irq_enter(chip, desc);\n\tks_pcie_handle_legacy_irq(ks_pcie, irq_offset);\n\tchained_irq_exit(chip, desc);\n}\n\nstatic int ks_pcie_config_msi_irq(struct keystone_pcie *ks_pcie)\n{\n\tstruct device *dev = ks_pcie->pci->dev;\n\tstruct device_node *np = ks_pcie->np;\n\tstruct device_node *intc_np;\n\tstruct irq_data *irq_data;\n\tint irq_count, irq, ret, i;\n\n\tif (!IS_ENABLED(CONFIG_PCI_MSI))\n\t\treturn 0;\n\n\tintc_np = of_get_child_by_name(np, \"msi-interrupt-controller\");\n\tif (!intc_np) {\n\t\tif (ks_pcie->is_am6)\n\t\t\treturn 0;\n\t\tdev_warn(dev, \"msi-interrupt-controller node is absent\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tirq_count = of_irq_count(intc_np);\n\tif (!irq_count) {\n\t\tdev_err(dev, \"No IRQ entries in msi-interrupt-controller\\n\");\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tfor (i = 0; i < irq_count; i++) {\n\t\tirq = irq_of_parse_and_map(intc_np, i);\n\t\tif (!irq) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (!ks_pcie->msi_host_irq) {\n\t\t\tirq_data = irq_get_irq_data(irq);\n\t\t\tif (!irq_data) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tks_pcie->msi_host_irq = irq_data->hwirq;\n\t\t}\n\n\t\tirq_set_chained_handler_and_data(irq, ks_pcie_msi_irq_handler,\n\t\t\t\t\t\t ks_pcie);\n\t}\n\n\tof_node_put(intc_np);\n\treturn 0;\n\nerr:\n\tof_node_put(intc_np);\n\treturn ret;\n}\n\nstatic int ks_pcie_config_legacy_irq(struct keystone_pcie *ks_pcie)\n{\n\tstruct device *dev = ks_pcie->pci->dev;\n\tstruct irq_domain *legacy_irq_domain;\n\tstruct device_node *np = ks_pcie->np;\n\tstruct device_node *intc_np;\n\tint irq_count, irq, ret = 0, i;\n\n\tintc_np = of_get_child_by_name(np, \"legacy-interrupt-controller\");\n\tif (!intc_np) {\n\t\t \n\t\tif (ks_pcie->is_am6)\n\t\t\treturn 0;\n\t\tdev_warn(dev, \"legacy-interrupt-controller node is absent\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tirq_count = of_irq_count(intc_np);\n\tif (!irq_count) {\n\t\tdev_err(dev, \"No IRQ entries in legacy-interrupt-controller\\n\");\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tfor (i = 0; i < irq_count; i++) {\n\t\tirq = irq_of_parse_and_map(intc_np, i);\n\t\tif (!irq) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t\tks_pcie->legacy_host_irqs[i] = irq;\n\n\t\tirq_set_chained_handler_and_data(irq,\n\t\t\t\t\t\t ks_pcie_legacy_irq_handler,\n\t\t\t\t\t\t ks_pcie);\n\t}\n\n\tlegacy_irq_domain =\n\t\tirq_domain_add_linear(intc_np, PCI_NUM_INTX,\n\t\t\t\t      &ks_pcie_legacy_irq_domain_ops, NULL);\n\tif (!legacy_irq_domain) {\n\t\tdev_err(dev, \"Failed to add irq domain for legacy irqs\\n\");\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\tks_pcie->legacy_irq_domain = legacy_irq_domain;\n\n\tfor (i = 0; i < PCI_NUM_INTX; i++)\n\t\tks_pcie_app_writel(ks_pcie, IRQ_ENABLE_SET(i), INTx_EN);\n\nerr:\n\tof_node_put(intc_np);\n\treturn ret;\n}\n\n#ifdef CONFIG_ARM\n \nstatic int ks_pcie_fault(unsigned long addr, unsigned int fsr,\n\t\t\t struct pt_regs *regs)\n{\n\tunsigned long instr = *(unsigned long *) instruction_pointer(regs);\n\n\tif ((instr & 0x0e100090) == 0x00100090) {\n\t\tint reg = (instr >> 12) & 15;\n\n\t\tregs->uregs[reg] = -1;\n\t\tregs->ARM_pc += 4;\n\t}\n\n\treturn 0;\n}\n#endif\n\nstatic int __init ks_pcie_init_id(struct keystone_pcie *ks_pcie)\n{\n\tint ret;\n\tunsigned int id;\n\tstruct regmap *devctrl_regs;\n\tstruct dw_pcie *pci = ks_pcie->pci;\n\tstruct device *dev = pci->dev;\n\tstruct device_node *np = dev->of_node;\n\tstruct of_phandle_args args;\n\tunsigned int offset = 0;\n\n\tdevctrl_regs = syscon_regmap_lookup_by_phandle(np, \"ti,syscon-pcie-id\");\n\tif (IS_ERR(devctrl_regs))\n\t\treturn PTR_ERR(devctrl_regs);\n\n\t \n\tret = of_parse_phandle_with_fixed_args(np, \"ti,syscon-pcie-id\", 1, 0, &args);\n\tif (!ret)\n\t\toffset = args.args[0];\n\n\tret = regmap_read(devctrl_regs, offset, &id);\n\tif (ret)\n\t\treturn ret;\n\n\tdw_pcie_dbi_ro_wr_en(pci);\n\tdw_pcie_writew_dbi(pci, PCI_VENDOR_ID, id & PCIE_VENDORID_MASK);\n\tdw_pcie_writew_dbi(pci, PCI_DEVICE_ID, id >> PCIE_DEVICEID_SHIFT);\n\tdw_pcie_dbi_ro_wr_dis(pci);\n\n\treturn 0;\n}\n\nstatic int __init ks_pcie_host_init(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct keystone_pcie *ks_pcie = to_keystone_pcie(pci);\n\tint ret;\n\n\tpp->bridge->ops = &ks_pcie_ops;\n\tif (!ks_pcie->is_am6)\n\t\tpp->bridge->child_ops = &ks_child_pcie_ops;\n\n\tret = ks_pcie_config_legacy_irq(ks_pcie);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ks_pcie_config_msi_irq(ks_pcie);\n\tif (ret)\n\t\treturn ret;\n\n\tks_pcie_stop_link(pci);\n\tks_pcie_setup_rc_app_regs(ks_pcie);\n\twritew(PCI_IO_RANGE_TYPE_32 | (PCI_IO_RANGE_TYPE_32 << 8),\n\t\t\tpci->dbi_base + PCI_IO_BASE);\n\n\tret = ks_pcie_init_id(ks_pcie);\n\tif (ret < 0)\n\t\treturn ret;\n\n#ifdef CONFIG_ARM\n\t \n\thook_fault_code(17, ks_pcie_fault, SIGBUS, 0,\n\t\t\t\"Asynchronous external abort\");\n#endif\n\n\treturn 0;\n}\n\nstatic const struct dw_pcie_host_ops ks_pcie_host_ops = {\n\t.host_init = ks_pcie_host_init,\n\t.msi_host_init = ks_pcie_msi_host_init,\n};\n\nstatic const struct dw_pcie_host_ops ks_pcie_am654_host_ops = {\n\t.host_init = ks_pcie_host_init,\n};\n\nstatic irqreturn_t ks_pcie_err_irq_handler(int irq, void *priv)\n{\n\tstruct keystone_pcie *ks_pcie = priv;\n\n\treturn ks_pcie_handle_error_irq(ks_pcie);\n}\n\nstatic void ks_pcie_am654_write_dbi2(struct dw_pcie *pci, void __iomem *base,\n\t\t\t\t     u32 reg, size_t size, u32 val)\n{\n\tstruct keystone_pcie *ks_pcie = to_keystone_pcie(pci);\n\n\tks_pcie_set_dbi_mode(ks_pcie);\n\tdw_pcie_write(base + reg, size, val);\n\tks_pcie_clear_dbi_mode(ks_pcie);\n}\n\nstatic const struct dw_pcie_ops ks_pcie_dw_pcie_ops = {\n\t.start_link = ks_pcie_start_link,\n\t.stop_link = ks_pcie_stop_link,\n\t.link_up = ks_pcie_link_up,\n\t.write_dbi2 = ks_pcie_am654_write_dbi2,\n};\n\nstatic void ks_pcie_am654_ep_init(struct dw_pcie_ep *ep)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_ep(ep);\n\tint flags;\n\n\tep->page_size = AM654_WIN_SIZE;\n\tflags = PCI_BASE_ADDRESS_SPACE_MEMORY | PCI_BASE_ADDRESS_MEM_TYPE_32;\n\tdw_pcie_writel_dbi2(pci, PCI_BASE_ADDRESS_0, APP_ADDR_SPACE_0 - 1);\n\tdw_pcie_writel_dbi(pci, PCI_BASE_ADDRESS_0, flags);\n}\n\nstatic void ks_pcie_am654_raise_legacy_irq(struct keystone_pcie *ks_pcie)\n{\n\tstruct dw_pcie *pci = ks_pcie->pci;\n\tu8 int_pin;\n\n\tint_pin = dw_pcie_readb_dbi(pci, PCI_INTERRUPT_PIN);\n\tif (int_pin == 0 || int_pin > 4)\n\t\treturn;\n\n\tks_pcie_app_writel(ks_pcie, PCIE_LEGACY_IRQ_ENABLE_SET(int_pin),\n\t\t\t   INT_ENABLE);\n\tks_pcie_app_writel(ks_pcie, PCIE_EP_IRQ_SET, INT_ENABLE);\n\tmdelay(1);\n\tks_pcie_app_writel(ks_pcie, PCIE_EP_IRQ_CLR, INT_ENABLE);\n\tks_pcie_app_writel(ks_pcie, PCIE_LEGACY_IRQ_ENABLE_CLR(int_pin),\n\t\t\t   INT_ENABLE);\n}\n\nstatic int ks_pcie_am654_raise_irq(struct dw_pcie_ep *ep, u8 func_no,\n\t\t\t\t   enum pci_epc_irq_type type,\n\t\t\t\t   u16 interrupt_num)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_ep(ep);\n\tstruct keystone_pcie *ks_pcie = to_keystone_pcie(pci);\n\n\tswitch (type) {\n\tcase PCI_EPC_IRQ_LEGACY:\n\t\tks_pcie_am654_raise_legacy_irq(ks_pcie);\n\t\tbreak;\n\tcase PCI_EPC_IRQ_MSI:\n\t\tdw_pcie_ep_raise_msi_irq(ep, func_no, interrupt_num);\n\t\tbreak;\n\tcase PCI_EPC_IRQ_MSIX:\n\t\tdw_pcie_ep_raise_msix_irq(ep, func_no, interrupt_num);\n\t\tbreak;\n\tdefault:\n\t\tdev_err(pci->dev, \"UNKNOWN IRQ type\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct pci_epc_features ks_pcie_am654_epc_features = {\n\t.linkup_notifier = false,\n\t.msi_capable = true,\n\t.msix_capable = true,\n\t.reserved_bar = 1 << BAR_0 | 1 << BAR_1,\n\t.bar_fixed_64bit = 1 << BAR_0,\n\t.bar_fixed_size[2] = SZ_1M,\n\t.bar_fixed_size[3] = SZ_64K,\n\t.bar_fixed_size[4] = 256,\n\t.bar_fixed_size[5] = SZ_1M,\n\t.align = SZ_1M,\n};\n\nstatic const struct pci_epc_features*\nks_pcie_am654_get_features(struct dw_pcie_ep *ep)\n{\n\treturn &ks_pcie_am654_epc_features;\n}\n\nstatic const struct dw_pcie_ep_ops ks_pcie_am654_ep_ops = {\n\t.ep_init = ks_pcie_am654_ep_init,\n\t.raise_irq = ks_pcie_am654_raise_irq,\n\t.get_features = &ks_pcie_am654_get_features,\n};\n\nstatic void ks_pcie_disable_phy(struct keystone_pcie *ks_pcie)\n{\n\tint num_lanes = ks_pcie->num_lanes;\n\n\twhile (num_lanes--) {\n\t\tphy_power_off(ks_pcie->phy[num_lanes]);\n\t\tphy_exit(ks_pcie->phy[num_lanes]);\n\t}\n}\n\nstatic int ks_pcie_enable_phy(struct keystone_pcie *ks_pcie)\n{\n\tint i;\n\tint ret;\n\tint num_lanes = ks_pcie->num_lanes;\n\n\tfor (i = 0; i < num_lanes; i++) {\n\t\tret = phy_reset(ks_pcie->phy[i]);\n\t\tif (ret < 0)\n\t\t\tgoto err_phy;\n\n\t\tret = phy_init(ks_pcie->phy[i]);\n\t\tif (ret < 0)\n\t\t\tgoto err_phy;\n\n\t\tret = phy_power_on(ks_pcie->phy[i]);\n\t\tif (ret < 0) {\n\t\t\tphy_exit(ks_pcie->phy[i]);\n\t\t\tgoto err_phy;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_phy:\n\twhile (--i >= 0) {\n\t\tphy_power_off(ks_pcie->phy[i]);\n\t\tphy_exit(ks_pcie->phy[i]);\n\t}\n\n\treturn ret;\n}\n\nstatic int ks_pcie_set_mode(struct device *dev)\n{\n\tstruct device_node *np = dev->of_node;\n\tstruct of_phandle_args args;\n\tunsigned int offset = 0;\n\tstruct regmap *syscon;\n\tu32 val;\n\tu32 mask;\n\tint ret = 0;\n\n\tsyscon = syscon_regmap_lookup_by_phandle(np, \"ti,syscon-pcie-mode\");\n\tif (IS_ERR(syscon))\n\t\treturn 0;\n\n\t \n\tret = of_parse_phandle_with_fixed_args(np, \"ti,syscon-pcie-mode\", 1, 0, &args);\n\tif (!ret)\n\t\toffset = args.args[0];\n\n\tmask = KS_PCIE_DEV_TYPE_MASK | KS_PCIE_SYSCLOCKOUTEN;\n\tval = KS_PCIE_DEV_TYPE(RC) | KS_PCIE_SYSCLOCKOUTEN;\n\n\tret = regmap_update_bits(syscon, offset, mask, val);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to set pcie mode\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ks_pcie_am654_set_mode(struct device *dev,\n\t\t\t\t  enum dw_pcie_device_mode mode)\n{\n\tstruct device_node *np = dev->of_node;\n\tstruct of_phandle_args args;\n\tunsigned int offset = 0;\n\tstruct regmap *syscon;\n\tu32 val;\n\tu32 mask;\n\tint ret = 0;\n\n\tsyscon = syscon_regmap_lookup_by_phandle(np, \"ti,syscon-pcie-mode\");\n\tif (IS_ERR(syscon))\n\t\treturn 0;\n\n\t \n\tret = of_parse_phandle_with_fixed_args(np, \"ti,syscon-pcie-mode\", 1, 0, &args);\n\tif (!ret)\n\t\toffset = args.args[0];\n\n\tmask = AM654_PCIE_DEV_TYPE_MASK;\n\n\tswitch (mode) {\n\tcase DW_PCIE_RC_TYPE:\n\t\tval = RC;\n\t\tbreak;\n\tcase DW_PCIE_EP_TYPE:\n\t\tval = EP;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(dev, \"INVALID device type %d\\n\", mode);\n\t\treturn -EINVAL;\n\t}\n\n\tret = regmap_update_bits(syscon, offset, mask, val);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to set pcie mode\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct ks_pcie_of_data ks_pcie_rc_of_data = {\n\t.host_ops = &ks_pcie_host_ops,\n\t.version = DW_PCIE_VER_365A,\n};\n\nstatic const struct ks_pcie_of_data ks_pcie_am654_rc_of_data = {\n\t.host_ops = &ks_pcie_am654_host_ops,\n\t.mode = DW_PCIE_RC_TYPE,\n\t.version = DW_PCIE_VER_490A,\n};\n\nstatic const struct ks_pcie_of_data ks_pcie_am654_ep_of_data = {\n\t.ep_ops = &ks_pcie_am654_ep_ops,\n\t.mode = DW_PCIE_EP_TYPE,\n\t.version = DW_PCIE_VER_490A,\n};\n\nstatic const struct of_device_id ks_pcie_of_match[] = {\n\t{\n\t\t.type = \"pci\",\n\t\t.data = &ks_pcie_rc_of_data,\n\t\t.compatible = \"ti,keystone-pcie\",\n\t},\n\t{\n\t\t.data = &ks_pcie_am654_rc_of_data,\n\t\t.compatible = \"ti,am654-pcie-rc\",\n\t},\n\t{\n\t\t.data = &ks_pcie_am654_ep_of_data,\n\t\t.compatible = \"ti,am654-pcie-ep\",\n\t},\n\t{ },\n};\n\nstatic int ks_pcie_probe(struct platform_device *pdev)\n{\n\tconst struct dw_pcie_host_ops *host_ops;\n\tconst struct dw_pcie_ep_ops *ep_ops;\n\tstruct device *dev = &pdev->dev;\n\tstruct device_node *np = dev->of_node;\n\tconst struct ks_pcie_of_data *data;\n\tenum dw_pcie_device_mode mode;\n\tstruct dw_pcie *pci;\n\tstruct keystone_pcie *ks_pcie;\n\tstruct device_link **link;\n\tstruct gpio_desc *gpiod;\n\tstruct resource *res;\n\tvoid __iomem *base;\n\tu32 num_viewport;\n\tstruct phy **phy;\n\tu32 num_lanes;\n\tchar name[10];\n\tu32 version;\n\tint ret;\n\tint irq;\n\tint i;\n\n\tdata = of_device_get_match_data(dev);\n\tif (!data)\n\t\treturn -EINVAL;\n\n\tversion = data->version;\n\thost_ops = data->host_ops;\n\tep_ops = data->ep_ops;\n\tmode = data->mode;\n\n\tks_pcie = devm_kzalloc(dev, sizeof(*ks_pcie), GFP_KERNEL);\n\tif (!ks_pcie)\n\t\treturn -ENOMEM;\n\n\tpci = devm_kzalloc(dev, sizeof(*pci), GFP_KERNEL);\n\tif (!pci)\n\t\treturn -ENOMEM;\n\n\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"app\");\n\tks_pcie->va_app_base = devm_ioremap_resource(dev, res);\n\tif (IS_ERR(ks_pcie->va_app_base))\n\t\treturn PTR_ERR(ks_pcie->va_app_base);\n\n\tks_pcie->app = *res;\n\n\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"dbics\");\n\tbase = devm_pci_remap_cfg_resource(dev, res);\n\tif (IS_ERR(base))\n\t\treturn PTR_ERR(base);\n\n\tif (of_device_is_compatible(np, \"ti,am654-pcie-rc\"))\n\t\tks_pcie->is_am6 = true;\n\n\tpci->dbi_base = base;\n\tpci->dbi_base2 = base;\n\tpci->dev = dev;\n\tpci->ops = &ks_pcie_dw_pcie_ops;\n\tpci->version = version;\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tret = request_irq(irq, ks_pcie_err_irq_handler, IRQF_SHARED,\n\t\t\t  \"ks-pcie-error-irq\", ks_pcie);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"failed to request error IRQ %d\\n\",\n\t\t\tirq);\n\t\treturn ret;\n\t}\n\n\tret = of_property_read_u32(np, \"num-lanes\", &num_lanes);\n\tif (ret)\n\t\tnum_lanes = 1;\n\n\tphy = devm_kzalloc(dev, sizeof(*phy) * num_lanes, GFP_KERNEL);\n\tif (!phy)\n\t\treturn -ENOMEM;\n\n\tlink = devm_kzalloc(dev, sizeof(*link) * num_lanes, GFP_KERNEL);\n\tif (!link)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < num_lanes; i++) {\n\t\tsnprintf(name, sizeof(name), \"pcie-phy%d\", i);\n\t\tphy[i] = devm_phy_optional_get(dev, name);\n\t\tif (IS_ERR(phy[i])) {\n\t\t\tret = PTR_ERR(phy[i]);\n\t\t\tgoto err_link;\n\t\t}\n\n\t\tif (!phy[i])\n\t\t\tcontinue;\n\n\t\tlink[i] = device_link_add(dev, &phy[i]->dev, DL_FLAG_STATELESS);\n\t\tif (!link[i]) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_link;\n\t\t}\n\t}\n\n\tks_pcie->np = np;\n\tks_pcie->pci = pci;\n\tks_pcie->link = link;\n\tks_pcie->num_lanes = num_lanes;\n\tks_pcie->phy = phy;\n\n\tgpiod = devm_gpiod_get_optional(dev, \"reset\",\n\t\t\t\t\tGPIOD_OUT_LOW);\n\tif (IS_ERR(gpiod)) {\n\t\tret = PTR_ERR(gpiod);\n\t\tif (ret != -EPROBE_DEFER)\n\t\t\tdev_err(dev, \"Failed to get reset GPIO\\n\");\n\t\tgoto err_link;\n\t}\n\n\t \n\tfor (i = 0; i < num_lanes; i++)\n\t\tphy_pm_runtime_get_sync(ks_pcie->phy[i]);\n\n\tret = ks_pcie_enable_phy(ks_pcie);\n\n\t \n\tfor (i = 0; i < num_lanes; i++)\n\t\tphy_pm_runtime_put_sync(ks_pcie->phy[i]);\n\n\tif (ret) {\n\t\tdev_err(dev, \"failed to enable phy\\n\");\n\t\tgoto err_link;\n\t}\n\n\tplatform_set_drvdata(pdev, ks_pcie);\n\tpm_runtime_enable(dev);\n\tret = pm_runtime_get_sync(dev);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"pm_runtime_get_sync failed\\n\");\n\t\tgoto err_get_sync;\n\t}\n\n\tif (dw_pcie_ver_is_ge(pci, 480A))\n\t\tret = ks_pcie_am654_set_mode(dev, mode);\n\telse\n\t\tret = ks_pcie_set_mode(dev);\n\tif (ret < 0)\n\t\tgoto err_get_sync;\n\n\tswitch (mode) {\n\tcase DW_PCIE_RC_TYPE:\n\t\tif (!IS_ENABLED(CONFIG_PCI_KEYSTONE_HOST)) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto err_get_sync;\n\t\t}\n\n\t\tret = of_property_read_u32(np, \"num-viewport\", &num_viewport);\n\t\tif (ret < 0) {\n\t\t\tdev_err(dev, \"unable to read *num-viewport* property\\n\");\n\t\t\tgoto err_get_sync;\n\t\t}\n\n\t\t \n\t\tif (gpiod) {\n\t\t\tusleep_range(100, 200);\n\t\t\tgpiod_set_value_cansleep(gpiod, 1);\n\t\t}\n\n\t\tks_pcie->num_viewport = num_viewport;\n\t\tpci->pp.ops = host_ops;\n\t\tret = dw_pcie_host_init(&pci->pp);\n\t\tif (ret < 0)\n\t\t\tgoto err_get_sync;\n\t\tbreak;\n\tcase DW_PCIE_EP_TYPE:\n\t\tif (!IS_ENABLED(CONFIG_PCI_KEYSTONE_EP)) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto err_get_sync;\n\t\t}\n\n\t\tpci->ep.ops = ep_ops;\n\t\tret = dw_pcie_ep_init(&pci->ep);\n\t\tif (ret < 0)\n\t\t\tgoto err_get_sync;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(dev, \"INVALID device type %d\\n\", mode);\n\t}\n\n\tks_pcie_enable_error_irq(ks_pcie);\n\n\treturn 0;\n\nerr_get_sync:\n\tpm_runtime_put(dev);\n\tpm_runtime_disable(dev);\n\tks_pcie_disable_phy(ks_pcie);\n\nerr_link:\n\twhile (--i >= 0 && link[i])\n\t\tdevice_link_del(link[i]);\n\n\treturn ret;\n}\n\nstatic int ks_pcie_remove(struct platform_device *pdev)\n{\n\tstruct keystone_pcie *ks_pcie = platform_get_drvdata(pdev);\n\tstruct device_link **link = ks_pcie->link;\n\tint num_lanes = ks_pcie->num_lanes;\n\tstruct device *dev = &pdev->dev;\n\n\tpm_runtime_put(dev);\n\tpm_runtime_disable(dev);\n\tks_pcie_disable_phy(ks_pcie);\n\twhile (num_lanes--)\n\t\tdevice_link_del(link[num_lanes]);\n\n\treturn 0;\n}\n\nstatic struct platform_driver ks_pcie_driver = {\n\t.probe  = ks_pcie_probe,\n\t.remove = ks_pcie_remove,\n\t.driver = {\n\t\t.name\t= \"keystone-pcie\",\n\t\t.of_match_table = ks_pcie_of_match,\n\t},\n};\nbuiltin_platform_driver(ks_pcie_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}