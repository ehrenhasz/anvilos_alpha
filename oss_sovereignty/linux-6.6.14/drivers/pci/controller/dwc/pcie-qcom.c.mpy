{
  "module_name": "pcie-qcom.c",
  "hash_id": "c71b158e724115cc8e90ad0941f759edd38dd49023e91186db8d3e315a341819",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/controller/dwc/pcie-qcom.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/crc8.h>\n#include <linux/debugfs.h>\n#include <linux/delay.h>\n#include <linux/gpio/consumer.h>\n#include <linux/interconnect.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/iopoll.h>\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/of.h>\n#include <linux/of_gpio.h>\n#include <linux/pci.h>\n#include <linux/pm_runtime.h>\n#include <linux/platform_device.h>\n#include <linux/phy/pcie.h>\n#include <linux/phy/phy.h>\n#include <linux/regulator/consumer.h>\n#include <linux/reset.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n\n#include \"../../pci.h\"\n#include \"pcie-designware.h\"\n\n \n#define PARF_SYS_CTRL\t\t\t\t0x00\n#define PARF_PM_CTRL\t\t\t\t0x20\n#define PARF_PCS_DEEMPH\t\t\t\t0x34\n#define PARF_PCS_SWING\t\t\t\t0x38\n#define PARF_PHY_CTRL\t\t\t\t0x40\n#define PARF_PHY_REFCLK\t\t\t\t0x4c\n#define PARF_CONFIG_BITS\t\t\t0x50\n#define PARF_DBI_BASE_ADDR\t\t\t0x168\n#define PARF_MHI_CLOCK_RESET_CTRL\t\t0x174\n#define PARF_AXI_MSTR_WR_ADDR_HALT\t\t0x178\n#define PARF_AXI_MSTR_WR_ADDR_HALT_V2\t\t0x1a8\n#define PARF_Q2A_FLUSH\t\t\t\t0x1ac\n#define PARF_LTSSM\t\t\t\t0x1b0\n#define PARF_SID_OFFSET\t\t\t\t0x234\n#define PARF_BDF_TRANSLATE_CFG\t\t\t0x24c\n#define PARF_SLV_ADDR_SPACE_SIZE\t\t0x358\n#define PARF_DEVICE_TYPE\t\t\t0x1000\n#define PARF_BDF_TO_SID_TABLE_N\t\t\t0x2000\n\n \n#define ELBI_SYS_CTRL\t\t\t\t0x04\n\n \n#define AXI_MSTR_RESP_COMP_CTRL0\t\t0x818\n#define AXI_MSTR_RESP_COMP_CTRL1\t\t0x81c\n\n \n#define PARF_DEBUG_CNT_PM_LINKST_IN_L2\t\t0xc04\n#define PARF_DEBUG_CNT_PM_LINKST_IN_L1\t\t0xc0c\n#define PARF_DEBUG_CNT_PM_LINKST_IN_L0S\t\t0xc10\n#define PARF_DEBUG_CNT_AUX_CLK_IN_L1SUB_L1\t0xc84\n#define PARF_DEBUG_CNT_AUX_CLK_IN_L1SUB_L2\t0xc88\n\n \n#define MAC_PHY_POWERDOWN_IN_P2_D_MUX_EN\tBIT(29)\n#define MST_WAKEUP_EN\t\t\t\tBIT(13)\n#define SLV_WAKEUP_EN\t\t\t\tBIT(12)\n#define MSTR_ACLK_CGC_DIS\t\t\tBIT(10)\n#define SLV_ACLK_CGC_DIS\t\t\tBIT(9)\n#define CORE_CLK_CGC_DIS\t\t\tBIT(6)\n#define AUX_PWR_DET\t\t\t\tBIT(4)\n#define L23_CLK_RMV_DIS\t\t\t\tBIT(2)\n#define L1_CLK_RMV_DIS\t\t\t\tBIT(1)\n\n \n#define REQ_NOT_ENTR_L1\t\t\t\tBIT(5)\n\n \n#define PCS_DEEMPH_TX_DEEMPH_GEN1(x)\t\tFIELD_PREP(GENMASK(21, 16), x)\n#define PCS_DEEMPH_TX_DEEMPH_GEN2_3_5DB(x)\tFIELD_PREP(GENMASK(13, 8), x)\n#define PCS_DEEMPH_TX_DEEMPH_GEN2_6DB(x)\tFIELD_PREP(GENMASK(5, 0), x)\n\n \n#define PCS_SWING_TX_SWING_FULL(x)\t\tFIELD_PREP(GENMASK(14, 8), x)\n#define PCS_SWING_TX_SWING_LOW(x)\t\tFIELD_PREP(GENMASK(6, 0), x)\n\n \n#define PHY_CTRL_PHY_TX0_TERM_OFFSET_MASK\tGENMASK(20, 16)\n#define PHY_CTRL_PHY_TX0_TERM_OFFSET(x)\t\tFIELD_PREP(PHY_CTRL_PHY_TX0_TERM_OFFSET_MASK, x)\n#define PHY_TEST_PWR_DOWN\t\t\tBIT(0)\n\n \n#define PHY_REFCLK_SSP_EN\t\t\tBIT(16)\n#define PHY_REFCLK_USE_PAD\t\t\tBIT(12)\n\n \n#define PHY_RX0_EQ(x)\t\t\t\tFIELD_PREP(GENMASK(26, 24), x)\n\n \n#define SLV_ADDR_SPACE_SZ\t\t\t0x10000000\n\n \n#define AHB_CLK_EN\t\t\t\tBIT(0)\n#define MSTR_AXI_CLK_EN\t\t\t\tBIT(1)\n#define BYPASS\t\t\t\t\tBIT(4)\n\n \n#define EN\t\t\t\t\tBIT(31)\n\n \n#define LTSSM_EN\t\t\t\tBIT(8)\n\n \n#define DEVICE_TYPE_RC\t\t\t\t0x4\n\n \n#define ELBI_SYS_CTRL_LT_ENABLE\t\t\tBIT(0)\n\n \n#define CFG_REMOTE_RD_REQ_BRIDGE_SIZE_2K\t0x4\n#define CFG_REMOTE_RD_REQ_BRIDGE_SIZE_4K\t0x5\n\n \n#define CFG_BRIDGE_SB_INIT\t\t\tBIT(0)\n\n \n#define PCIE_CAP_SLOT_POWER_LIMIT_VAL\t\tFIELD_PREP(PCI_EXP_SLTCAP_SPLV, 250)\n#define PCIE_CAP_SLOT_POWER_LIMIT_SCALE\t\tFIELD_PREP(PCI_EXP_SLTCAP_SPLS, 1)\n#define PCIE_CAP_SLOT_VAL\t\t\t(PCI_EXP_SLTCAP_ABP | \\\n\t\t\t\t\t\tPCI_EXP_SLTCAP_PCP | \\\n\t\t\t\t\t\tPCI_EXP_SLTCAP_MRLSP | \\\n\t\t\t\t\t\tPCI_EXP_SLTCAP_AIP | \\\n\t\t\t\t\t\tPCI_EXP_SLTCAP_PIP | \\\n\t\t\t\t\t\tPCI_EXP_SLTCAP_HPS | \\\n\t\t\t\t\t\tPCI_EXP_SLTCAP_EIP | \\\n\t\t\t\t\t\tPCIE_CAP_SLOT_POWER_LIMIT_VAL | \\\n\t\t\t\t\t\tPCIE_CAP_SLOT_POWER_LIMIT_SCALE)\n\n#define PERST_DELAY_US\t\t\t\t1000\n\n#define QCOM_PCIE_CRC8_POLYNOMIAL\t\t(BIT(2) | BIT(1) | BIT(0))\n\n#define QCOM_PCIE_1_0_0_MAX_CLOCKS\t\t4\nstruct qcom_pcie_resources_1_0_0 {\n\tstruct clk_bulk_data clks[QCOM_PCIE_1_0_0_MAX_CLOCKS];\n\tstruct reset_control *core;\n\tstruct regulator *vdda;\n};\n\n#define QCOM_PCIE_2_1_0_MAX_CLOCKS\t\t5\n#define QCOM_PCIE_2_1_0_MAX_RESETS\t\t6\n#define QCOM_PCIE_2_1_0_MAX_SUPPLY\t\t3\nstruct qcom_pcie_resources_2_1_0 {\n\tstruct clk_bulk_data clks[QCOM_PCIE_2_1_0_MAX_CLOCKS];\n\tstruct reset_control_bulk_data resets[QCOM_PCIE_2_1_0_MAX_RESETS];\n\tint num_resets;\n\tstruct regulator_bulk_data supplies[QCOM_PCIE_2_1_0_MAX_SUPPLY];\n};\n\n#define QCOM_PCIE_2_3_2_MAX_CLOCKS\t\t4\n#define QCOM_PCIE_2_3_2_MAX_SUPPLY\t\t2\nstruct qcom_pcie_resources_2_3_2 {\n\tstruct clk_bulk_data clks[QCOM_PCIE_2_3_2_MAX_CLOCKS];\n\tstruct regulator_bulk_data supplies[QCOM_PCIE_2_3_2_MAX_SUPPLY];\n};\n\n#define QCOM_PCIE_2_3_3_MAX_CLOCKS\t\t5\n#define QCOM_PCIE_2_3_3_MAX_RESETS\t\t7\nstruct qcom_pcie_resources_2_3_3 {\n\tstruct clk_bulk_data clks[QCOM_PCIE_2_3_3_MAX_CLOCKS];\n\tstruct reset_control_bulk_data rst[QCOM_PCIE_2_3_3_MAX_RESETS];\n};\n\n#define QCOM_PCIE_2_4_0_MAX_CLOCKS\t\t4\n#define QCOM_PCIE_2_4_0_MAX_RESETS\t\t12\nstruct qcom_pcie_resources_2_4_0 {\n\tstruct clk_bulk_data clks[QCOM_PCIE_2_4_0_MAX_CLOCKS];\n\tint num_clks;\n\tstruct reset_control_bulk_data resets[QCOM_PCIE_2_4_0_MAX_RESETS];\n\tint num_resets;\n};\n\n#define QCOM_PCIE_2_7_0_MAX_CLOCKS\t\t15\n#define QCOM_PCIE_2_7_0_MAX_SUPPLIES\t\t2\nstruct qcom_pcie_resources_2_7_0 {\n\tstruct clk_bulk_data clks[QCOM_PCIE_2_7_0_MAX_CLOCKS];\n\tint num_clks;\n\tstruct regulator_bulk_data supplies[QCOM_PCIE_2_7_0_MAX_SUPPLIES];\n\tstruct reset_control *rst;\n};\n\n#define QCOM_PCIE_2_9_0_MAX_CLOCKS\t\t5\nstruct qcom_pcie_resources_2_9_0 {\n\tstruct clk_bulk_data clks[QCOM_PCIE_2_9_0_MAX_CLOCKS];\n\tstruct reset_control *rst;\n};\n\nunion qcom_pcie_resources {\n\tstruct qcom_pcie_resources_1_0_0 v1_0_0;\n\tstruct qcom_pcie_resources_2_1_0 v2_1_0;\n\tstruct qcom_pcie_resources_2_3_2 v2_3_2;\n\tstruct qcom_pcie_resources_2_3_3 v2_3_3;\n\tstruct qcom_pcie_resources_2_4_0 v2_4_0;\n\tstruct qcom_pcie_resources_2_7_0 v2_7_0;\n\tstruct qcom_pcie_resources_2_9_0 v2_9_0;\n};\n\nstruct qcom_pcie;\n\nstruct qcom_pcie_ops {\n\tint (*get_resources)(struct qcom_pcie *pcie);\n\tint (*init)(struct qcom_pcie *pcie);\n\tint (*post_init)(struct qcom_pcie *pcie);\n\tvoid (*deinit)(struct qcom_pcie *pcie);\n\tvoid (*ltssm_enable)(struct qcom_pcie *pcie);\n\tint (*config_sid)(struct qcom_pcie *pcie);\n};\n\nstruct qcom_pcie_cfg {\n\tconst struct qcom_pcie_ops *ops;\n};\n\nstruct qcom_pcie {\n\tstruct dw_pcie *pci;\n\tvoid __iomem *parf;\t\t\t \n\tvoid __iomem *elbi;\t\t\t \n\tvoid __iomem *mhi;\n\tunion qcom_pcie_resources res;\n\tstruct phy *phy;\n\tstruct gpio_desc *reset;\n\tstruct icc_path *icc_mem;\n\tconst struct qcom_pcie_cfg *cfg;\n\tstruct dentry *debugfs;\n\tbool suspended;\n};\n\n#define to_qcom_pcie(x)\t\tdev_get_drvdata((x)->dev)\n\nstatic void qcom_ep_reset_assert(struct qcom_pcie *pcie)\n{\n\tgpiod_set_value_cansleep(pcie->reset, 1);\n\tusleep_range(PERST_DELAY_US, PERST_DELAY_US + 500);\n}\n\nstatic void qcom_ep_reset_deassert(struct qcom_pcie *pcie)\n{\n\t \n\tmsleep(100);\n\tgpiod_set_value_cansleep(pcie->reset, 0);\n\tusleep_range(PERST_DELAY_US, PERST_DELAY_US + 500);\n}\n\nstatic int qcom_pcie_start_link(struct dw_pcie *pci)\n{\n\tstruct qcom_pcie *pcie = to_qcom_pcie(pci);\n\n\t \n\tif (pcie->cfg->ops->ltssm_enable)\n\t\tpcie->cfg->ops->ltssm_enable(pcie);\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_clear_hpc(struct dw_pcie *pci)\n{\n\tu16 offset = dw_pcie_find_capability(pci, PCI_CAP_ID_EXP);\n\tu32 val;\n\n\tdw_pcie_dbi_ro_wr_en(pci);\n\n\tval = readl(pci->dbi_base + offset + PCI_EXP_SLTCAP);\n\tval &= ~PCI_EXP_SLTCAP_HPC;\n\twritel(val, pci->dbi_base + offset + PCI_EXP_SLTCAP);\n\n\tdw_pcie_dbi_ro_wr_dis(pci);\n}\n\nstatic void qcom_pcie_2_1_0_ltssm_enable(struct qcom_pcie *pcie)\n{\n\tu32 val;\n\n\t \n\tval = readl(pcie->elbi + ELBI_SYS_CTRL);\n\tval |= ELBI_SYS_CTRL_LT_ENABLE;\n\twritel(val, pcie->elbi + ELBI_SYS_CTRL);\n}\n\nstatic int qcom_pcie_get_resources_2_1_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_1_0 *res = &pcie->res.v2_1_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tbool is_apq = of_device_is_compatible(dev->of_node, \"qcom,pcie-apq8064\");\n\tint ret;\n\n\tres->supplies[0].supply = \"vdda\";\n\tres->supplies[1].supply = \"vdda_phy\";\n\tres->supplies[2].supply = \"vdda_refclk\";\n\tret = devm_regulator_bulk_get(dev, ARRAY_SIZE(res->supplies),\n\t\t\t\t      res->supplies);\n\tif (ret)\n\t\treturn ret;\n\n\tres->clks[0].id = \"iface\";\n\tres->clks[1].id = \"core\";\n\tres->clks[2].id = \"phy\";\n\tres->clks[3].id = \"aux\";\n\tres->clks[4].id = \"ref\";\n\n\t \n\tret = devm_clk_bulk_get(dev, 3, res->clks);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tret = devm_clk_bulk_get_optional(dev, 2, res->clks + 3);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tres->resets[0].id = \"pci\";\n\tres->resets[1].id = \"axi\";\n\tres->resets[2].id = \"ahb\";\n\tres->resets[3].id = \"por\";\n\tres->resets[4].id = \"phy\";\n\tres->resets[5].id = \"ext\";\n\n\t \n\tres->num_resets = is_apq ? 5 : 6;\n\tret = devm_reset_control_bulk_get_exclusive(dev, res->num_resets, res->resets);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_deinit_2_1_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_1_0 *res = &pcie->res.v2_1_0;\n\n\tclk_bulk_disable_unprepare(ARRAY_SIZE(res->clks), res->clks);\n\treset_control_bulk_assert(res->num_resets, res->resets);\n\n\twritel(1, pcie->parf + PARF_PHY_CTRL);\n\n\tregulator_bulk_disable(ARRAY_SIZE(res->supplies), res->supplies);\n}\n\nstatic int qcom_pcie_init_2_1_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_1_0 *res = &pcie->res.v2_1_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tint ret;\n\n\t \n\tret = reset_control_bulk_assert(res->num_resets, res->resets);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"cannot assert resets\\n\");\n\t\treturn ret;\n\t}\n\n\tret = regulator_bulk_enable(ARRAY_SIZE(res->supplies), res->supplies);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"cannot enable regulators\\n\");\n\t\treturn ret;\n\t}\n\n\tret = reset_control_bulk_deassert(res->num_resets, res->resets);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"cannot deassert resets\\n\");\n\t\tregulator_bulk_disable(ARRAY_SIZE(res->supplies), res->supplies);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_post_init_2_1_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_1_0 *res = &pcie->res.v2_1_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tstruct device_node *node = dev->of_node;\n\tu32 val;\n\tint ret;\n\n\t \n\tval = readl(pcie->parf + PARF_PHY_CTRL);\n\tval &= ~PHY_TEST_PWR_DOWN;\n\twritel(val, pcie->parf + PARF_PHY_CTRL);\n\n\tret = clk_bulk_prepare_enable(ARRAY_SIZE(res->clks), res->clks);\n\tif (ret)\n\t\treturn ret;\n\n\tif (of_device_is_compatible(node, \"qcom,pcie-ipq8064\") ||\n\t    of_device_is_compatible(node, \"qcom,pcie-ipq8064-v2\")) {\n\t\twritel(PCS_DEEMPH_TX_DEEMPH_GEN1(24) |\n\t\t\t       PCS_DEEMPH_TX_DEEMPH_GEN2_3_5DB(24) |\n\t\t\t       PCS_DEEMPH_TX_DEEMPH_GEN2_6DB(34),\n\t\t       pcie->parf + PARF_PCS_DEEMPH);\n\t\twritel(PCS_SWING_TX_SWING_FULL(120) |\n\t\t\t       PCS_SWING_TX_SWING_LOW(120),\n\t\t       pcie->parf + PARF_PCS_SWING);\n\t\twritel(PHY_RX0_EQ(4), pcie->parf + PARF_CONFIG_BITS);\n\t}\n\n\tif (of_device_is_compatible(node, \"qcom,pcie-ipq8064\")) {\n\t\t \n\t\tval = readl(pcie->parf + PARF_PHY_CTRL);\n\t\tval &= ~PHY_CTRL_PHY_TX0_TERM_OFFSET_MASK;\n\t\tval |= PHY_CTRL_PHY_TX0_TERM_OFFSET(7);\n\t\twritel(val, pcie->parf + PARF_PHY_CTRL);\n\t}\n\n\t \n\tval = readl(pcie->parf + PARF_PHY_REFCLK);\n\t \n\tif (!of_device_is_compatible(node, \"qcom,pcie-apq8064\"))\n\t\tval &= ~PHY_REFCLK_USE_PAD;\n\tval |= PHY_REFCLK_SSP_EN;\n\twritel(val, pcie->parf + PARF_PHY_REFCLK);\n\n\t \n\tusleep_range(1000, 1500);\n\n\t \n\twritel(CFG_REMOTE_RD_REQ_BRIDGE_SIZE_2K,\n\t       pci->dbi_base + AXI_MSTR_RESP_COMP_CTRL0);\n\twritel(CFG_BRIDGE_SB_INIT,\n\t       pci->dbi_base + AXI_MSTR_RESP_COMP_CTRL1);\n\n\tqcom_pcie_clear_hpc(pcie->pci);\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_get_resources_1_0_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_1_0_0 *res = &pcie->res.v1_0_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tint ret;\n\n\tres->vdda = devm_regulator_get(dev, \"vdda\");\n\tif (IS_ERR(res->vdda))\n\t\treturn PTR_ERR(res->vdda);\n\n\tres->clks[0].id = \"iface\";\n\tres->clks[1].id = \"aux\";\n\tres->clks[2].id = \"master_bus\";\n\tres->clks[3].id = \"slave_bus\";\n\n\tret = devm_clk_bulk_get(dev, ARRAY_SIZE(res->clks), res->clks);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tres->core = devm_reset_control_get_exclusive(dev, \"core\");\n\treturn PTR_ERR_OR_ZERO(res->core);\n}\n\nstatic void qcom_pcie_deinit_1_0_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_1_0_0 *res = &pcie->res.v1_0_0;\n\n\treset_control_assert(res->core);\n\tclk_bulk_disable_unprepare(ARRAY_SIZE(res->clks), res->clks);\n\tregulator_disable(res->vdda);\n}\n\nstatic int qcom_pcie_init_1_0_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_1_0_0 *res = &pcie->res.v1_0_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tint ret;\n\n\tret = reset_control_deassert(res->core);\n\tif (ret) {\n\t\tdev_err(dev, \"cannot deassert core reset\\n\");\n\t\treturn ret;\n\t}\n\n\tret = clk_bulk_prepare_enable(ARRAY_SIZE(res->clks), res->clks);\n\tif (ret) {\n\t\tdev_err(dev, \"cannot prepare/enable clocks\\n\");\n\t\tgoto err_assert_reset;\n\t}\n\n\tret = regulator_enable(res->vdda);\n\tif (ret) {\n\t\tdev_err(dev, \"cannot enable vdda regulator\\n\");\n\t\tgoto err_disable_clks;\n\t}\n\n\treturn 0;\n\nerr_disable_clks:\n\tclk_bulk_disable_unprepare(ARRAY_SIZE(res->clks), res->clks);\nerr_assert_reset:\n\treset_control_assert(res->core);\n\n\treturn ret;\n}\n\nstatic int qcom_pcie_post_init_1_0_0(struct qcom_pcie *pcie)\n{\n\t \n\twritel(0, pcie->parf + PARF_DBI_BASE_ADDR);\n\n\tif (IS_ENABLED(CONFIG_PCI_MSI)) {\n\t\tu32 val = readl(pcie->parf + PARF_AXI_MSTR_WR_ADDR_HALT);\n\n\t\tval |= EN;\n\t\twritel(val, pcie->parf + PARF_AXI_MSTR_WR_ADDR_HALT);\n\t}\n\n\tqcom_pcie_clear_hpc(pcie->pci);\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_2_3_2_ltssm_enable(struct qcom_pcie *pcie)\n{\n\tu32 val;\n\n\t \n\tval = readl(pcie->parf + PARF_LTSSM);\n\tval |= LTSSM_EN;\n\twritel(val, pcie->parf + PARF_LTSSM);\n}\n\nstatic int qcom_pcie_get_resources_2_3_2(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_3_2 *res = &pcie->res.v2_3_2;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tint ret;\n\n\tres->supplies[0].supply = \"vdda\";\n\tres->supplies[1].supply = \"vddpe-3v3\";\n\tret = devm_regulator_bulk_get(dev, ARRAY_SIZE(res->supplies),\n\t\t\t\t      res->supplies);\n\tif (ret)\n\t\treturn ret;\n\n\tres->clks[0].id = \"aux\";\n\tres->clks[1].id = \"cfg\";\n\tres->clks[2].id = \"bus_master\";\n\tres->clks[3].id = \"bus_slave\";\n\n\tret = devm_clk_bulk_get(dev, ARRAY_SIZE(res->clks), res->clks);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_deinit_2_3_2(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_3_2 *res = &pcie->res.v2_3_2;\n\n\tclk_bulk_disable_unprepare(ARRAY_SIZE(res->clks), res->clks);\n\tregulator_bulk_disable(ARRAY_SIZE(res->supplies), res->supplies);\n}\n\nstatic int qcom_pcie_init_2_3_2(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_3_2 *res = &pcie->res.v2_3_2;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tint ret;\n\n\tret = regulator_bulk_enable(ARRAY_SIZE(res->supplies), res->supplies);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"cannot enable regulators\\n\");\n\t\treturn ret;\n\t}\n\n\tret = clk_bulk_prepare_enable(ARRAY_SIZE(res->clks), res->clks);\n\tif (ret) {\n\t\tdev_err(dev, \"cannot prepare/enable clocks\\n\");\n\t\tregulator_bulk_disable(ARRAY_SIZE(res->supplies), res->supplies);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_post_init_2_3_2(struct qcom_pcie *pcie)\n{\n\tu32 val;\n\n\t \n\tval = readl(pcie->parf + PARF_PHY_CTRL);\n\tval &= ~PHY_TEST_PWR_DOWN;\n\twritel(val, pcie->parf + PARF_PHY_CTRL);\n\n\t \n\twritel(0, pcie->parf + PARF_DBI_BASE_ADDR);\n\n\t \n\tval = readl(pcie->parf + PARF_SYS_CTRL);\n\tval &= ~MAC_PHY_POWERDOWN_IN_P2_D_MUX_EN;\n\twritel(val, pcie->parf + PARF_SYS_CTRL);\n\n\tval = readl(pcie->parf + PARF_MHI_CLOCK_RESET_CTRL);\n\tval |= BYPASS;\n\twritel(val, pcie->parf + PARF_MHI_CLOCK_RESET_CTRL);\n\n\tval = readl(pcie->parf + PARF_AXI_MSTR_WR_ADDR_HALT_V2);\n\tval |= EN;\n\twritel(val, pcie->parf + PARF_AXI_MSTR_WR_ADDR_HALT_V2);\n\n\tqcom_pcie_clear_hpc(pcie->pci);\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_get_resources_2_4_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_4_0 *res = &pcie->res.v2_4_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tbool is_ipq = of_device_is_compatible(dev->of_node, \"qcom,pcie-ipq4019\");\n\tint ret;\n\n\tres->clks[0].id = \"aux\";\n\tres->clks[1].id = \"master_bus\";\n\tres->clks[2].id = \"slave_bus\";\n\tres->clks[3].id = \"iface\";\n\n\t \n\tres->num_clks = is_ipq ? 3 : 4;\n\n\tret = devm_clk_bulk_get(dev, res->num_clks, res->clks);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tres->resets[0].id = \"axi_m\";\n\tres->resets[1].id = \"axi_s\";\n\tres->resets[2].id = \"axi_m_sticky\";\n\tres->resets[3].id = \"pipe_sticky\";\n\tres->resets[4].id = \"pwr\";\n\tres->resets[5].id = \"ahb\";\n\tres->resets[6].id = \"pipe\";\n\tres->resets[7].id = \"axi_m_vmid\";\n\tres->resets[8].id = \"axi_s_xpu\";\n\tres->resets[9].id = \"parf\";\n\tres->resets[10].id = \"phy\";\n\tres->resets[11].id = \"phy_ahb\";\n\n\tres->num_resets = is_ipq ? 12 : 6;\n\n\tret = devm_reset_control_bulk_get_exclusive(dev, res->num_resets, res->resets);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_deinit_2_4_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_4_0 *res = &pcie->res.v2_4_0;\n\n\treset_control_bulk_assert(res->num_resets, res->resets);\n\tclk_bulk_disable_unprepare(res->num_clks, res->clks);\n}\n\nstatic int qcom_pcie_init_2_4_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_4_0 *res = &pcie->res.v2_4_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tint ret;\n\n\tret = reset_control_bulk_assert(res->num_resets, res->resets);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"cannot assert resets\\n\");\n\t\treturn ret;\n\t}\n\n\tusleep_range(10000, 12000);\n\n\tret = reset_control_bulk_deassert(res->num_resets, res->resets);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"cannot deassert resets\\n\");\n\t\treturn ret;\n\t}\n\n\tusleep_range(10000, 12000);\n\n\tret = clk_bulk_prepare_enable(res->num_clks, res->clks);\n\tif (ret) {\n\t\treset_control_bulk_assert(res->num_resets, res->resets);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_get_resources_2_3_3(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_3_3 *res = &pcie->res.v2_3_3;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tint ret;\n\n\tres->clks[0].id = \"iface\";\n\tres->clks[1].id = \"axi_m\";\n\tres->clks[2].id = \"axi_s\";\n\tres->clks[3].id = \"ahb\";\n\tres->clks[4].id = \"aux\";\n\n\tret = devm_clk_bulk_get(dev, ARRAY_SIZE(res->clks), res->clks);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tres->rst[0].id = \"axi_m\";\n\tres->rst[1].id = \"axi_s\";\n\tres->rst[2].id = \"pipe\";\n\tres->rst[3].id = \"axi_m_sticky\";\n\tres->rst[4].id = \"sticky\";\n\tres->rst[5].id = \"ahb\";\n\tres->rst[6].id = \"sleep\";\n\n\tret = devm_reset_control_bulk_get_exclusive(dev, ARRAY_SIZE(res->rst), res->rst);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_deinit_2_3_3(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_3_3 *res = &pcie->res.v2_3_3;\n\n\tclk_bulk_disable_unprepare(ARRAY_SIZE(res->clks), res->clks);\n}\n\nstatic int qcom_pcie_init_2_3_3(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_3_3 *res = &pcie->res.v2_3_3;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tint ret;\n\n\tret = reset_control_bulk_assert(ARRAY_SIZE(res->rst), res->rst);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"cannot assert resets\\n\");\n\t\treturn ret;\n\t}\n\n\tusleep_range(2000, 2500);\n\n\tret = reset_control_bulk_deassert(ARRAY_SIZE(res->rst), res->rst);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"cannot deassert resets\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tusleep_range(2000, 2500);\n\n\tret = clk_bulk_prepare_enable(ARRAY_SIZE(res->clks), res->clks);\n\tif (ret) {\n\t\tdev_err(dev, \"cannot prepare/enable clocks\\n\");\n\t\tgoto err_assert_resets;\n\t}\n\n\treturn 0;\n\nerr_assert_resets:\n\t \n\treset_control_bulk_assert(ARRAY_SIZE(res->rst), res->rst);\n\n\treturn ret;\n}\n\nstatic int qcom_pcie_post_init_2_3_3(struct qcom_pcie *pcie)\n{\n\tstruct dw_pcie *pci = pcie->pci;\n\tu16 offset = dw_pcie_find_capability(pci, PCI_CAP_ID_EXP);\n\tu32 val;\n\n\twritel(SLV_ADDR_SPACE_SZ, pcie->parf + PARF_SLV_ADDR_SPACE_SIZE);\n\n\tval = readl(pcie->parf + PARF_PHY_CTRL);\n\tval &= ~PHY_TEST_PWR_DOWN;\n\twritel(val, pcie->parf + PARF_PHY_CTRL);\n\n\twritel(0, pcie->parf + PARF_DBI_BASE_ADDR);\n\n\twritel(MST_WAKEUP_EN | SLV_WAKEUP_EN | MSTR_ACLK_CGC_DIS\n\t\t| SLV_ACLK_CGC_DIS | CORE_CLK_CGC_DIS |\n\t\tAUX_PWR_DET | L23_CLK_RMV_DIS | L1_CLK_RMV_DIS,\n\t\tpcie->parf + PARF_SYS_CTRL);\n\twritel(0, pcie->parf + PARF_Q2A_FLUSH);\n\n\twritel(PCI_COMMAND_MASTER, pci->dbi_base + PCI_COMMAND);\n\n\tdw_pcie_dbi_ro_wr_en(pci);\n\n\twritel(PCIE_CAP_SLOT_VAL, pci->dbi_base + offset + PCI_EXP_SLTCAP);\n\n\tval = readl(pci->dbi_base + offset + PCI_EXP_LNKCAP);\n\tval &= ~PCI_EXP_LNKCAP_ASPMS;\n\twritel(val, pci->dbi_base + offset + PCI_EXP_LNKCAP);\n\n\twritel(PCI_EXP_DEVCTL2_COMP_TMOUT_DIS, pci->dbi_base + offset +\n\t\tPCI_EXP_DEVCTL2);\n\n\tdw_pcie_dbi_ro_wr_dis(pci);\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_get_resources_2_7_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_7_0 *res = &pcie->res.v2_7_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tunsigned int num_clks, num_opt_clks;\n\tunsigned int idx;\n\tint ret;\n\n\tres->rst = devm_reset_control_array_get_exclusive(dev);\n\tif (IS_ERR(res->rst))\n\t\treturn PTR_ERR(res->rst);\n\n\tres->supplies[0].supply = \"vdda\";\n\tres->supplies[1].supply = \"vddpe-3v3\";\n\tret = devm_regulator_bulk_get(dev, ARRAY_SIZE(res->supplies),\n\t\t\t\t      res->supplies);\n\tif (ret)\n\t\treturn ret;\n\n\tidx = 0;\n\tres->clks[idx++].id = \"aux\";\n\tres->clks[idx++].id = \"cfg\";\n\tres->clks[idx++].id = \"bus_master\";\n\tres->clks[idx++].id = \"bus_slave\";\n\tres->clks[idx++].id = \"slave_q2a\";\n\n\tnum_clks = idx;\n\n\tret = devm_clk_bulk_get(dev, num_clks, res->clks);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tres->clks[idx++].id = \"tbu\";\n\tres->clks[idx++].id = \"ddrss_sf_tbu\";\n\tres->clks[idx++].id = \"aggre0\";\n\tres->clks[idx++].id = \"aggre1\";\n\tres->clks[idx++].id = \"noc_aggr\";\n\tres->clks[idx++].id = \"noc_aggr_4\";\n\tres->clks[idx++].id = \"noc_aggr_south_sf\";\n\tres->clks[idx++].id = \"cnoc_qx\";\n\tres->clks[idx++].id = \"sleep\";\n\tres->clks[idx++].id = \"cnoc_sf_axi\";\n\n\tnum_opt_clks = idx - num_clks;\n\tres->num_clks = idx;\n\n\tret = devm_clk_bulk_get_optional(dev, num_opt_clks, res->clks + num_clks);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_init_2_7_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_7_0 *res = &pcie->res.v2_7_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tu32 val;\n\tint ret;\n\n\tret = regulator_bulk_enable(ARRAY_SIZE(res->supplies), res->supplies);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"cannot enable regulators\\n\");\n\t\treturn ret;\n\t}\n\n\tret = clk_bulk_prepare_enable(res->num_clks, res->clks);\n\tif (ret < 0)\n\t\tgoto err_disable_regulators;\n\n\tret = reset_control_assert(res->rst);\n\tif (ret) {\n\t\tdev_err(dev, \"reset assert failed (%d)\\n\", ret);\n\t\tgoto err_disable_clocks;\n\t}\n\n\tusleep_range(1000, 1500);\n\n\tret = reset_control_deassert(res->rst);\n\tif (ret) {\n\t\tdev_err(dev, \"reset deassert failed (%d)\\n\", ret);\n\t\tgoto err_disable_clocks;\n\t}\n\n\t \n\tusleep_range(1000, 1500);\n\n\t \n\twritel(DEVICE_TYPE_RC, pcie->parf + PARF_DEVICE_TYPE);\n\n\t \n\tval = readl(pcie->parf + PARF_PHY_CTRL);\n\tval &= ~PHY_TEST_PWR_DOWN;\n\twritel(val, pcie->parf + PARF_PHY_CTRL);\n\n\t \n\twritel(0, pcie->parf + PARF_DBI_BASE_ADDR);\n\n\t \n\tval = readl(pcie->parf + PARF_SYS_CTRL);\n\tval &= ~MAC_PHY_POWERDOWN_IN_P2_D_MUX_EN;\n\twritel(val, pcie->parf + PARF_SYS_CTRL);\n\n\tval = readl(pcie->parf + PARF_MHI_CLOCK_RESET_CTRL);\n\tval |= BYPASS;\n\twritel(val, pcie->parf + PARF_MHI_CLOCK_RESET_CTRL);\n\n\t \n\tval = readl(pcie->parf + PARF_PM_CTRL);\n\tval &= ~REQ_NOT_ENTR_L1;\n\twritel(val, pcie->parf + PARF_PM_CTRL);\n\n\tval = readl(pcie->parf + PARF_AXI_MSTR_WR_ADDR_HALT_V2);\n\tval |= EN;\n\twritel(val, pcie->parf + PARF_AXI_MSTR_WR_ADDR_HALT_V2);\n\n\treturn 0;\nerr_disable_clocks:\n\tclk_bulk_disable_unprepare(res->num_clks, res->clks);\nerr_disable_regulators:\n\tregulator_bulk_disable(ARRAY_SIZE(res->supplies), res->supplies);\n\n\treturn ret;\n}\n\nstatic int qcom_pcie_post_init_2_7_0(struct qcom_pcie *pcie)\n{\n\tqcom_pcie_clear_hpc(pcie->pci);\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_deinit_2_7_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_7_0 *res = &pcie->res.v2_7_0;\n\n\tclk_bulk_disable_unprepare(res->num_clks, res->clks);\n\n\tregulator_bulk_disable(ARRAY_SIZE(res->supplies), res->supplies);\n}\n\nstatic int qcom_pcie_config_sid_1_9_0(struct qcom_pcie *pcie)\n{\n\t \n\tstruct {\n\t\tu32 bdf;\n\t\tu32 phandle;\n\t\tu32 smmu_sid;\n\t\tu32 smmu_sid_len;\n\t} *map;\n\tvoid __iomem *bdf_to_sid_base = pcie->parf + PARF_BDF_TO_SID_TABLE_N;\n\tstruct device *dev = pcie->pci->dev;\n\tu8 qcom_pcie_crc8_table[CRC8_TABLE_SIZE];\n\tint i, nr_map, size = 0;\n\tu32 smmu_sid_base;\n\n\tof_get_property(dev->of_node, \"iommu-map\", &size);\n\tif (!size)\n\t\treturn 0;\n\n\tmap = kzalloc(size, GFP_KERNEL);\n\tif (!map)\n\t\treturn -ENOMEM;\n\n\tof_property_read_u32_array(dev->of_node, \"iommu-map\", (u32 *)map,\n\t\t\t\t   size / sizeof(u32));\n\n\tnr_map = size / (sizeof(*map));\n\n\tcrc8_populate_msb(qcom_pcie_crc8_table, QCOM_PCIE_CRC8_POLYNOMIAL);\n\n\t \n\tmemset_io(bdf_to_sid_base, 0, CRC8_TABLE_SIZE * sizeof(u32));\n\n\t \n\tsmmu_sid_base = map[0].smmu_sid;\n\n\t \n\tfor (i = 0; i < nr_map; i++) {\n\t\t__be16 bdf_be = cpu_to_be16(map[i].bdf);\n\t\tu32 val;\n\t\tu8 hash;\n\n\t\thash = crc8(qcom_pcie_crc8_table, (u8 *)&bdf_be, sizeof(bdf_be), 0);\n\n\t\tval = readl(bdf_to_sid_base + hash * sizeof(u32));\n\n\t\t \n\t\twhile (val) {\n\t\t\tu8 current_hash = hash++;\n\t\t\tu8 next_mask = 0xff;\n\n\t\t\t \n\t\t\tif (!(val & next_mask)) {\n\t\t\t\tval |= (u32)hash;\n\t\t\t\twritel(val, bdf_to_sid_base + current_hash * sizeof(u32));\n\t\t\t}\n\n\t\t\tval = readl(bdf_to_sid_base + hash * sizeof(u32));\n\t\t}\n\n\t\t \n\t\tval = map[i].bdf << 16 | (map[i].smmu_sid - smmu_sid_base) << 8 | 0;\n\t\twritel(val, bdf_to_sid_base + hash * sizeof(u32));\n\t}\n\n\tkfree(map);\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_get_resources_2_9_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_9_0 *res = &pcie->res.v2_9_0;\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tint ret;\n\n\tres->clks[0].id = \"iface\";\n\tres->clks[1].id = \"axi_m\";\n\tres->clks[2].id = \"axi_s\";\n\tres->clks[3].id = \"axi_bridge\";\n\tres->clks[4].id = \"rchng\";\n\n\tret = devm_clk_bulk_get(dev, ARRAY_SIZE(res->clks), res->clks);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tres->rst = devm_reset_control_array_get_exclusive(dev);\n\tif (IS_ERR(res->rst))\n\t\treturn PTR_ERR(res->rst);\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_deinit_2_9_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_9_0 *res = &pcie->res.v2_9_0;\n\n\tclk_bulk_disable_unprepare(ARRAY_SIZE(res->clks), res->clks);\n}\n\nstatic int qcom_pcie_init_2_9_0(struct qcom_pcie *pcie)\n{\n\tstruct qcom_pcie_resources_2_9_0 *res = &pcie->res.v2_9_0;\n\tstruct device *dev = pcie->pci->dev;\n\tint ret;\n\n\tret = reset_control_assert(res->rst);\n\tif (ret) {\n\t\tdev_err(dev, \"reset assert failed (%d)\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tusleep_range(2000, 2500);\n\n\tret = reset_control_deassert(res->rst);\n\tif (ret) {\n\t\tdev_err(dev, \"reset deassert failed (%d)\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tusleep_range(2000, 2500);\n\n\treturn clk_bulk_prepare_enable(ARRAY_SIZE(res->clks), res->clks);\n}\n\nstatic int qcom_pcie_post_init_2_9_0(struct qcom_pcie *pcie)\n{\n\tstruct dw_pcie *pci = pcie->pci;\n\tu16 offset = dw_pcie_find_capability(pci, PCI_CAP_ID_EXP);\n\tu32 val;\n\tint i;\n\n\twritel(SLV_ADDR_SPACE_SZ,\n\t\tpcie->parf + PARF_SLV_ADDR_SPACE_SIZE);\n\n\tval = readl(pcie->parf + PARF_PHY_CTRL);\n\tval &= ~PHY_TEST_PWR_DOWN;\n\twritel(val, pcie->parf + PARF_PHY_CTRL);\n\n\twritel(0, pcie->parf + PARF_DBI_BASE_ADDR);\n\n\twritel(DEVICE_TYPE_RC, pcie->parf + PARF_DEVICE_TYPE);\n\twritel(BYPASS | MSTR_AXI_CLK_EN | AHB_CLK_EN,\n\t\tpcie->parf + PARF_MHI_CLOCK_RESET_CTRL);\n\twritel(GEN3_RELATED_OFF_RXEQ_RGRDLESS_RXTS |\n\t\tGEN3_RELATED_OFF_GEN3_ZRXDC_NONCOMPL,\n\t\tpci->dbi_base + GEN3_RELATED_OFF);\n\n\twritel(MST_WAKEUP_EN | SLV_WAKEUP_EN | MSTR_ACLK_CGC_DIS |\n\t\tSLV_ACLK_CGC_DIS | CORE_CLK_CGC_DIS |\n\t\tAUX_PWR_DET | L23_CLK_RMV_DIS | L1_CLK_RMV_DIS,\n\t\tpcie->parf + PARF_SYS_CTRL);\n\n\twritel(0, pcie->parf + PARF_Q2A_FLUSH);\n\n\tdw_pcie_dbi_ro_wr_en(pci);\n\n\twritel(PCIE_CAP_SLOT_VAL, pci->dbi_base + offset + PCI_EXP_SLTCAP);\n\n\tval = readl(pci->dbi_base + offset + PCI_EXP_LNKCAP);\n\tval &= ~PCI_EXP_LNKCAP_ASPMS;\n\twritel(val, pci->dbi_base + offset + PCI_EXP_LNKCAP);\n\n\twritel(PCI_EXP_DEVCTL2_COMP_TMOUT_DIS, pci->dbi_base + offset +\n\t\t\tPCI_EXP_DEVCTL2);\n\n\tdw_pcie_dbi_ro_wr_dis(pci);\n\n\tfor (i = 0; i < 256; i++)\n\t\twritel(0, pcie->parf + PARF_BDF_TO_SID_TABLE_N + (4 * i));\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_link_up(struct dw_pcie *pci)\n{\n\tu16 offset = dw_pcie_find_capability(pci, PCI_CAP_ID_EXP);\n\tu16 val = readw(pci->dbi_base + offset + PCI_EXP_LNKSTA);\n\n\treturn !!(val & PCI_EXP_LNKSTA_DLLLA);\n}\n\nstatic int qcom_pcie_host_init(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct qcom_pcie *pcie = to_qcom_pcie(pci);\n\tint ret;\n\n\tqcom_ep_reset_assert(pcie);\n\n\tret = pcie->cfg->ops->init(pcie);\n\tif (ret)\n\t\treturn ret;\n\n\tret = phy_set_mode_ext(pcie->phy, PHY_MODE_PCIE, PHY_MODE_PCIE_RC);\n\tif (ret)\n\t\tgoto err_deinit;\n\n\tret = phy_power_on(pcie->phy);\n\tif (ret)\n\t\tgoto err_deinit;\n\n\tif (pcie->cfg->ops->post_init) {\n\t\tret = pcie->cfg->ops->post_init(pcie);\n\t\tif (ret)\n\t\t\tgoto err_disable_phy;\n\t}\n\n\tqcom_ep_reset_deassert(pcie);\n\n\tif (pcie->cfg->ops->config_sid) {\n\t\tret = pcie->cfg->ops->config_sid(pcie);\n\t\tif (ret)\n\t\t\tgoto err_assert_reset;\n\t}\n\n\treturn 0;\n\nerr_assert_reset:\n\tqcom_ep_reset_assert(pcie);\nerr_disable_phy:\n\tphy_power_off(pcie->phy);\nerr_deinit:\n\tpcie->cfg->ops->deinit(pcie);\n\n\treturn ret;\n}\n\nstatic void qcom_pcie_host_deinit(struct dw_pcie_rp *pp)\n{\n\tstruct dw_pcie *pci = to_dw_pcie_from_pp(pp);\n\tstruct qcom_pcie *pcie = to_qcom_pcie(pci);\n\n\tqcom_ep_reset_assert(pcie);\n\tphy_power_off(pcie->phy);\n\tpcie->cfg->ops->deinit(pcie);\n}\n\nstatic const struct dw_pcie_host_ops qcom_pcie_dw_ops = {\n\t.host_init\t= qcom_pcie_host_init,\n\t.host_deinit\t= qcom_pcie_host_deinit,\n};\n\n \nstatic const struct qcom_pcie_ops ops_2_1_0 = {\n\t.get_resources = qcom_pcie_get_resources_2_1_0,\n\t.init = qcom_pcie_init_2_1_0,\n\t.post_init = qcom_pcie_post_init_2_1_0,\n\t.deinit = qcom_pcie_deinit_2_1_0,\n\t.ltssm_enable = qcom_pcie_2_1_0_ltssm_enable,\n};\n\n \nstatic const struct qcom_pcie_ops ops_1_0_0 = {\n\t.get_resources = qcom_pcie_get_resources_1_0_0,\n\t.init = qcom_pcie_init_1_0_0,\n\t.post_init = qcom_pcie_post_init_1_0_0,\n\t.deinit = qcom_pcie_deinit_1_0_0,\n\t.ltssm_enable = qcom_pcie_2_1_0_ltssm_enable,\n};\n\n \nstatic const struct qcom_pcie_ops ops_2_3_2 = {\n\t.get_resources = qcom_pcie_get_resources_2_3_2,\n\t.init = qcom_pcie_init_2_3_2,\n\t.post_init = qcom_pcie_post_init_2_3_2,\n\t.deinit = qcom_pcie_deinit_2_3_2,\n\t.ltssm_enable = qcom_pcie_2_3_2_ltssm_enable,\n};\n\n \nstatic const struct qcom_pcie_ops ops_2_4_0 = {\n\t.get_resources = qcom_pcie_get_resources_2_4_0,\n\t.init = qcom_pcie_init_2_4_0,\n\t.post_init = qcom_pcie_post_init_2_3_2,\n\t.deinit = qcom_pcie_deinit_2_4_0,\n\t.ltssm_enable = qcom_pcie_2_3_2_ltssm_enable,\n};\n\n \nstatic const struct qcom_pcie_ops ops_2_3_3 = {\n\t.get_resources = qcom_pcie_get_resources_2_3_3,\n\t.init = qcom_pcie_init_2_3_3,\n\t.post_init = qcom_pcie_post_init_2_3_3,\n\t.deinit = qcom_pcie_deinit_2_3_3,\n\t.ltssm_enable = qcom_pcie_2_3_2_ltssm_enable,\n};\n\n \nstatic const struct qcom_pcie_ops ops_2_7_0 = {\n\t.get_resources = qcom_pcie_get_resources_2_7_0,\n\t.init = qcom_pcie_init_2_7_0,\n\t.post_init = qcom_pcie_post_init_2_7_0,\n\t.deinit = qcom_pcie_deinit_2_7_0,\n\t.ltssm_enable = qcom_pcie_2_3_2_ltssm_enable,\n};\n\n \nstatic const struct qcom_pcie_ops ops_1_9_0 = {\n\t.get_resources = qcom_pcie_get_resources_2_7_0,\n\t.init = qcom_pcie_init_2_7_0,\n\t.post_init = qcom_pcie_post_init_2_7_0,\n\t.deinit = qcom_pcie_deinit_2_7_0,\n\t.ltssm_enable = qcom_pcie_2_3_2_ltssm_enable,\n\t.config_sid = qcom_pcie_config_sid_1_9_0,\n};\n\n \nstatic const struct qcom_pcie_ops ops_2_9_0 = {\n\t.get_resources = qcom_pcie_get_resources_2_9_0,\n\t.init = qcom_pcie_init_2_9_0,\n\t.post_init = qcom_pcie_post_init_2_9_0,\n\t.deinit = qcom_pcie_deinit_2_9_0,\n\t.ltssm_enable = qcom_pcie_2_3_2_ltssm_enable,\n};\n\nstatic const struct qcom_pcie_cfg cfg_1_0_0 = {\n\t.ops = &ops_1_0_0,\n};\n\nstatic const struct qcom_pcie_cfg cfg_1_9_0 = {\n\t.ops = &ops_1_9_0,\n};\n\nstatic const struct qcom_pcie_cfg cfg_2_1_0 = {\n\t.ops = &ops_2_1_0,\n};\n\nstatic const struct qcom_pcie_cfg cfg_2_3_2 = {\n\t.ops = &ops_2_3_2,\n};\n\nstatic const struct qcom_pcie_cfg cfg_2_3_3 = {\n\t.ops = &ops_2_3_3,\n};\n\nstatic const struct qcom_pcie_cfg cfg_2_4_0 = {\n\t.ops = &ops_2_4_0,\n};\n\nstatic const struct qcom_pcie_cfg cfg_2_7_0 = {\n\t.ops = &ops_2_7_0,\n};\n\nstatic const struct qcom_pcie_cfg cfg_2_9_0 = {\n\t.ops = &ops_2_9_0,\n};\n\nstatic const struct dw_pcie_ops dw_pcie_ops = {\n\t.link_up = qcom_pcie_link_up,\n\t.start_link = qcom_pcie_start_link,\n};\n\nstatic int qcom_pcie_icc_init(struct qcom_pcie *pcie)\n{\n\tstruct dw_pcie *pci = pcie->pci;\n\tint ret;\n\n\tpcie->icc_mem = devm_of_icc_get(pci->dev, \"pcie-mem\");\n\tif (IS_ERR(pcie->icc_mem))\n\t\treturn PTR_ERR(pcie->icc_mem);\n\n\t \n\tret = icc_set_bw(pcie->icc_mem, 0, MBps_to_icc(250));\n\tif (ret) {\n\t\tdev_err(pci->dev, \"failed to set interconnect bandwidth: %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_icc_update(struct qcom_pcie *pcie)\n{\n\tstruct dw_pcie *pci = pcie->pci;\n\tu32 offset, status, bw;\n\tint speed, width;\n\tint ret;\n\n\tif (!pcie->icc_mem)\n\t\treturn;\n\n\toffset = dw_pcie_find_capability(pci, PCI_CAP_ID_EXP);\n\tstatus = readw(pci->dbi_base + offset + PCI_EXP_LNKSTA);\n\n\t \n\tif (!(status & PCI_EXP_LNKSTA_DLLLA))\n\t\treturn;\n\n\tspeed = FIELD_GET(PCI_EXP_LNKSTA_CLS, status);\n\twidth = FIELD_GET(PCI_EXP_LNKSTA_NLW, status);\n\n\tswitch (speed) {\n\tcase 1:\n\t\tbw = MBps_to_icc(250);\n\t\tbreak;\n\tcase 2:\n\t\tbw = MBps_to_icc(500);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\tfallthrough;\n\tcase 3:\n\t\tbw = MBps_to_icc(985);\n\t\tbreak;\n\t}\n\n\tret = icc_set_bw(pcie->icc_mem, 0, width * bw);\n\tif (ret) {\n\t\tdev_err(pci->dev, \"failed to set interconnect bandwidth: %d\\n\",\n\t\t\tret);\n\t}\n}\n\nstatic int qcom_pcie_link_transition_count(struct seq_file *s, void *data)\n{\n\tstruct qcom_pcie *pcie = (struct qcom_pcie *)dev_get_drvdata(s->private);\n\n\tseq_printf(s, \"L0s transition count: %u\\n\",\n\t\t   readl_relaxed(pcie->mhi + PARF_DEBUG_CNT_PM_LINKST_IN_L0S));\n\n\tseq_printf(s, \"L1 transition count: %u\\n\",\n\t\t   readl_relaxed(pcie->mhi + PARF_DEBUG_CNT_PM_LINKST_IN_L1));\n\n\tseq_printf(s, \"L1.1 transition count: %u\\n\",\n\t\t   readl_relaxed(pcie->mhi + PARF_DEBUG_CNT_AUX_CLK_IN_L1SUB_L1));\n\n\tseq_printf(s, \"L1.2 transition count: %u\\n\",\n\t\t   readl_relaxed(pcie->mhi + PARF_DEBUG_CNT_AUX_CLK_IN_L1SUB_L2));\n\n\tseq_printf(s, \"L2 transition count: %u\\n\",\n\t\t   readl_relaxed(pcie->mhi + PARF_DEBUG_CNT_PM_LINKST_IN_L2));\n\n\treturn 0;\n}\n\nstatic void qcom_pcie_init_debugfs(struct qcom_pcie *pcie)\n{\n\tstruct dw_pcie *pci = pcie->pci;\n\tstruct device *dev = pci->dev;\n\tchar *name;\n\n\tname = devm_kasprintf(dev, GFP_KERNEL, \"%pOFP\", dev->of_node);\n\tif (!name)\n\t\treturn;\n\n\tpcie->debugfs = debugfs_create_dir(name, NULL);\n\tdebugfs_create_devm_seqfile(dev, \"link_transition_count\", pcie->debugfs,\n\t\t\t\t    qcom_pcie_link_transition_count);\n}\n\nstatic int qcom_pcie_probe(struct platform_device *pdev)\n{\n\tconst struct qcom_pcie_cfg *pcie_cfg;\n\tstruct device *dev = &pdev->dev;\n\tstruct qcom_pcie *pcie;\n\tstruct dw_pcie_rp *pp;\n\tstruct resource *res;\n\tstruct dw_pcie *pci;\n\tint ret;\n\n\tpcie_cfg = of_device_get_match_data(dev);\n\tif (!pcie_cfg || !pcie_cfg->ops) {\n\t\tdev_err(dev, \"Invalid platform data\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tpcie = devm_kzalloc(dev, sizeof(*pcie), GFP_KERNEL);\n\tif (!pcie)\n\t\treturn -ENOMEM;\n\n\tpci = devm_kzalloc(dev, sizeof(*pci), GFP_KERNEL);\n\tif (!pci)\n\t\treturn -ENOMEM;\n\n\tpm_runtime_enable(dev);\n\tret = pm_runtime_get_sync(dev);\n\tif (ret < 0)\n\t\tgoto err_pm_runtime_put;\n\n\tpci->dev = dev;\n\tpci->ops = &dw_pcie_ops;\n\tpp = &pci->pp;\n\n\tpcie->pci = pci;\n\n\tpcie->cfg = pcie_cfg;\n\n\tpcie->reset = devm_gpiod_get_optional(dev, \"perst\", GPIOD_OUT_HIGH);\n\tif (IS_ERR(pcie->reset)) {\n\t\tret = PTR_ERR(pcie->reset);\n\t\tgoto err_pm_runtime_put;\n\t}\n\n\tpcie->parf = devm_platform_ioremap_resource_byname(pdev, \"parf\");\n\tif (IS_ERR(pcie->parf)) {\n\t\tret = PTR_ERR(pcie->parf);\n\t\tgoto err_pm_runtime_put;\n\t}\n\n\tpcie->elbi = devm_platform_ioremap_resource_byname(pdev, \"elbi\");\n\tif (IS_ERR(pcie->elbi)) {\n\t\tret = PTR_ERR(pcie->elbi);\n\t\tgoto err_pm_runtime_put;\n\t}\n\n\t \n\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"mhi\");\n\tif (res) {\n\t\tpcie->mhi = devm_ioremap_resource(dev, res);\n\t\tif (IS_ERR(pcie->mhi)) {\n\t\t\tret = PTR_ERR(pcie->mhi);\n\t\t\tgoto err_pm_runtime_put;\n\t\t}\n\t}\n\n\tpcie->phy = devm_phy_optional_get(dev, \"pciephy\");\n\tif (IS_ERR(pcie->phy)) {\n\t\tret = PTR_ERR(pcie->phy);\n\t\tgoto err_pm_runtime_put;\n\t}\n\n\tret = qcom_pcie_icc_init(pcie);\n\tif (ret)\n\t\tgoto err_pm_runtime_put;\n\n\tret = pcie->cfg->ops->get_resources(pcie);\n\tif (ret)\n\t\tgoto err_pm_runtime_put;\n\n\tpp->ops = &qcom_pcie_dw_ops;\n\n\tret = phy_init(pcie->phy);\n\tif (ret)\n\t\tgoto err_pm_runtime_put;\n\n\tplatform_set_drvdata(pdev, pcie);\n\n\tret = dw_pcie_host_init(pp);\n\tif (ret) {\n\t\tdev_err(dev, \"cannot initialize host\\n\");\n\t\tgoto err_phy_exit;\n\t}\n\n\tqcom_pcie_icc_update(pcie);\n\n\tif (pcie->mhi)\n\t\tqcom_pcie_init_debugfs(pcie);\n\n\treturn 0;\n\nerr_phy_exit:\n\tphy_exit(pcie->phy);\nerr_pm_runtime_put:\n\tpm_runtime_put(dev);\n\tpm_runtime_disable(dev);\n\n\treturn ret;\n}\n\nstatic int qcom_pcie_suspend_noirq(struct device *dev)\n{\n\tstruct qcom_pcie *pcie = dev_get_drvdata(dev);\n\tint ret;\n\n\t \n\tret = icc_set_bw(pcie->icc_mem, 0, kBps_to_icc(1));\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to set interconnect bandwidth: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tif (!dw_pcie_link_up(pcie->pci)) {\n\t\tqcom_pcie_host_deinit(&pcie->pci->pp);\n\t\tpcie->suspended = true;\n\t}\n\n\treturn 0;\n}\n\nstatic int qcom_pcie_resume_noirq(struct device *dev)\n{\n\tstruct qcom_pcie *pcie = dev_get_drvdata(dev);\n\tint ret;\n\n\tif (pcie->suspended) {\n\t\tret = qcom_pcie_host_init(&pcie->pci->pp);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tpcie->suspended = false;\n\t}\n\n\tqcom_pcie_icc_update(pcie);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id qcom_pcie_match[] = {\n\t{ .compatible = \"qcom,pcie-apq8064\", .data = &cfg_2_1_0 },\n\t{ .compatible = \"qcom,pcie-apq8084\", .data = &cfg_1_0_0 },\n\t{ .compatible = \"qcom,pcie-ipq4019\", .data = &cfg_2_4_0 },\n\t{ .compatible = \"qcom,pcie-ipq6018\", .data = &cfg_2_9_0 },\n\t{ .compatible = \"qcom,pcie-ipq8064\", .data = &cfg_2_1_0 },\n\t{ .compatible = \"qcom,pcie-ipq8064-v2\", .data = &cfg_2_1_0 },\n\t{ .compatible = \"qcom,pcie-ipq8074\", .data = &cfg_2_3_3 },\n\t{ .compatible = \"qcom,pcie-ipq8074-gen3\", .data = &cfg_2_9_0 },\n\t{ .compatible = \"qcom,pcie-msm8996\", .data = &cfg_2_3_2 },\n\t{ .compatible = \"qcom,pcie-qcs404\", .data = &cfg_2_4_0 },\n\t{ .compatible = \"qcom,pcie-sa8540p\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sa8775p\", .data = &cfg_1_9_0},\n\t{ .compatible = \"qcom,pcie-sc7280\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sc8180x\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sc8280xp\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sdm845\", .data = &cfg_2_7_0 },\n\t{ .compatible = \"qcom,pcie-sdx55\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sm8150\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sm8250\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sm8350\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sm8450-pcie0\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sm8450-pcie1\", .data = &cfg_1_9_0 },\n\t{ .compatible = \"qcom,pcie-sm8550\", .data = &cfg_1_9_0 },\n\t{ }\n};\n\nstatic void qcom_fixup_class(struct pci_dev *dev)\n{\n\tdev->class = PCI_CLASS_BRIDGE_PCI_NORMAL;\n}\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_QCOM, 0x0101, qcom_fixup_class);\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_QCOM, 0x0104, qcom_fixup_class);\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_QCOM, 0x0106, qcom_fixup_class);\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_QCOM, 0x0107, qcom_fixup_class);\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_QCOM, 0x0302, qcom_fixup_class);\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_QCOM, 0x1000, qcom_fixup_class);\nDECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_QCOM, 0x1001, qcom_fixup_class);\n\nstatic const struct dev_pm_ops qcom_pcie_pm_ops = {\n\tNOIRQ_SYSTEM_SLEEP_PM_OPS(qcom_pcie_suspend_noirq, qcom_pcie_resume_noirq)\n};\n\nstatic struct platform_driver qcom_pcie_driver = {\n\t.probe = qcom_pcie_probe,\n\t.driver = {\n\t\t.name = \"qcom-pcie\",\n\t\t.suppress_bind_attrs = true,\n\t\t.of_match_table = qcom_pcie_match,\n\t\t.pm = &qcom_pcie_pm_ops,\n\t\t.probe_type = PROBE_PREFER_ASYNCHRONOUS,\n\t},\n};\nbuiltin_platform_driver(qcom_pcie_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}