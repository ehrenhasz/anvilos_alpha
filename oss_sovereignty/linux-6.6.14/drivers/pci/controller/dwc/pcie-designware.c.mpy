{
  "module_name": "pcie-designware.c",
  "hash_id": "3316ece89eb61207ec2250470316f1ecb3bb9ba6c1e18294a3ce2e4d0d691505",
  "original_prompt": "Ingested from linux-6.6.14/drivers/pci/controller/dwc/pcie-designware.c",
  "human_readable_source": "\n \n\n#include <linux/align.h>\n#include <linux/bitops.h>\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/dma/edma.h>\n#include <linux/gpio/consumer.h>\n#include <linux/ioport.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/sizes.h>\n#include <linux/types.h>\n\n#include \"../../pci.h\"\n#include \"pcie-designware.h\"\n\nstatic const char * const dw_pcie_app_clks[DW_PCIE_NUM_APP_CLKS] = {\n\t[DW_PCIE_DBI_CLK] = \"dbi\",\n\t[DW_PCIE_MSTR_CLK] = \"mstr\",\n\t[DW_PCIE_SLV_CLK] = \"slv\",\n};\n\nstatic const char * const dw_pcie_core_clks[DW_PCIE_NUM_CORE_CLKS] = {\n\t[DW_PCIE_PIPE_CLK] = \"pipe\",\n\t[DW_PCIE_CORE_CLK] = \"core\",\n\t[DW_PCIE_AUX_CLK] = \"aux\",\n\t[DW_PCIE_REF_CLK] = \"ref\",\n};\n\nstatic const char * const dw_pcie_app_rsts[DW_PCIE_NUM_APP_RSTS] = {\n\t[DW_PCIE_DBI_RST] = \"dbi\",\n\t[DW_PCIE_MSTR_RST] = \"mstr\",\n\t[DW_PCIE_SLV_RST] = \"slv\",\n};\n\nstatic const char * const dw_pcie_core_rsts[DW_PCIE_NUM_CORE_RSTS] = {\n\t[DW_PCIE_NON_STICKY_RST] = \"non-sticky\",\n\t[DW_PCIE_STICKY_RST] = \"sticky\",\n\t[DW_PCIE_CORE_RST] = \"core\",\n\t[DW_PCIE_PIPE_RST] = \"pipe\",\n\t[DW_PCIE_PHY_RST] = \"phy\",\n\t[DW_PCIE_HOT_RST] = \"hot\",\n\t[DW_PCIE_PWR_RST] = \"pwr\",\n};\n\nstatic int dw_pcie_get_clocks(struct dw_pcie *pci)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < DW_PCIE_NUM_APP_CLKS; i++)\n\t\tpci->app_clks[i].id = dw_pcie_app_clks[i];\n\n\tfor (i = 0; i < DW_PCIE_NUM_CORE_CLKS; i++)\n\t\tpci->core_clks[i].id = dw_pcie_core_clks[i];\n\n\tret = devm_clk_bulk_get_optional(pci->dev, DW_PCIE_NUM_APP_CLKS,\n\t\t\t\t\t pci->app_clks);\n\tif (ret)\n\t\treturn ret;\n\n\treturn devm_clk_bulk_get_optional(pci->dev, DW_PCIE_NUM_CORE_CLKS,\n\t\t\t\t\t  pci->core_clks);\n}\n\nstatic int dw_pcie_get_resets(struct dw_pcie *pci)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < DW_PCIE_NUM_APP_RSTS; i++)\n\t\tpci->app_rsts[i].id = dw_pcie_app_rsts[i];\n\n\tfor (i = 0; i < DW_PCIE_NUM_CORE_RSTS; i++)\n\t\tpci->core_rsts[i].id = dw_pcie_core_rsts[i];\n\n\tret = devm_reset_control_bulk_get_optional_shared(pci->dev,\n\t\t\t\t\t\t\t  DW_PCIE_NUM_APP_RSTS,\n\t\t\t\t\t\t\t  pci->app_rsts);\n\tif (ret)\n\t\treturn ret;\n\n\tret = devm_reset_control_bulk_get_optional_exclusive(pci->dev,\n\t\t\t\t\t\t\t     DW_PCIE_NUM_CORE_RSTS,\n\t\t\t\t\t\t\t     pci->core_rsts);\n\tif (ret)\n\t\treturn ret;\n\n\tpci->pe_rst = devm_gpiod_get_optional(pci->dev, \"reset\", GPIOD_OUT_HIGH);\n\tif (IS_ERR(pci->pe_rst))\n\t\treturn PTR_ERR(pci->pe_rst);\n\n\treturn 0;\n}\n\nint dw_pcie_get_resources(struct dw_pcie *pci)\n{\n\tstruct platform_device *pdev = to_platform_device(pci->dev);\n\tstruct device_node *np = dev_of_node(pci->dev);\n\tstruct resource *res;\n\tint ret;\n\n\tif (!pci->dbi_base) {\n\t\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"dbi\");\n\t\tpci->dbi_base = devm_pci_remap_cfg_resource(pci->dev, res);\n\t\tif (IS_ERR(pci->dbi_base))\n\t\t\treturn PTR_ERR(pci->dbi_base);\n\t}\n\n\t \n\tif (!pci->dbi_base2) {\n\t\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"dbi2\");\n\t\tif (res) {\n\t\t\tpci->dbi_base2 = devm_pci_remap_cfg_resource(pci->dev, res);\n\t\t\tif (IS_ERR(pci->dbi_base2))\n\t\t\t\treturn PTR_ERR(pci->dbi_base2);\n\t\t} else {\n\t\t\tpci->dbi_base2 = pci->dbi_base + SZ_4K;\n\t\t}\n\t}\n\n\t \n\tif (!pci->atu_base) {\n\t\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"atu\");\n\t\tif (res) {\n\t\t\tpci->atu_size = resource_size(res);\n\t\t\tpci->atu_base = devm_ioremap_resource(pci->dev, res);\n\t\t\tif (IS_ERR(pci->atu_base))\n\t\t\t\treturn PTR_ERR(pci->atu_base);\n\t\t} else {\n\t\t\tpci->atu_base = pci->dbi_base + DEFAULT_DBI_ATU_OFFSET;\n\t\t}\n\t}\n\n\t \n\tif (!pci->atu_size)\n\t\tpci->atu_size = SZ_4K;\n\n\t \n\tif (!pci->edma.reg_base) {\n\t\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM, \"dma\");\n\t\tif (res) {\n\t\t\tpci->edma.reg_base = devm_ioremap_resource(pci->dev, res);\n\t\t\tif (IS_ERR(pci->edma.reg_base))\n\t\t\t\treturn PTR_ERR(pci->edma.reg_base);\n\t\t} else if (pci->atu_size >= 2 * DEFAULT_DBI_DMA_OFFSET) {\n\t\t\tpci->edma.reg_base = pci->atu_base + DEFAULT_DBI_DMA_OFFSET;\n\t\t}\n\t}\n\n\t \n\tif (dw_pcie_cap_is(pci, REQ_RES)) {\n\t\tret = dw_pcie_get_clocks(pci);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = dw_pcie_get_resets(pci);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (pci->link_gen < 1)\n\t\tpci->link_gen = of_pci_get_max_link_speed(np);\n\n\tof_property_read_u32(np, \"num-lanes\", &pci->num_lanes);\n\n\tif (of_property_read_bool(np, \"snps,enable-cdm-check\"))\n\t\tdw_pcie_cap_set(pci, CDM_CHECK);\n\n\treturn 0;\n}\n\nvoid dw_pcie_version_detect(struct dw_pcie *pci)\n{\n\tu32 ver;\n\n\t \n\tver = dw_pcie_readl_dbi(pci, PCIE_VERSION_NUMBER);\n\tif (!ver)\n\t\treturn;\n\n\tif (pci->version && pci->version != ver)\n\t\tdev_warn(pci->dev, \"Versions don't match (%08x != %08x)\\n\",\n\t\t\t pci->version, ver);\n\telse\n\t\tpci->version = ver;\n\n\tver = dw_pcie_readl_dbi(pci, PCIE_VERSION_TYPE);\n\n\tif (pci->type && pci->type != ver)\n\t\tdev_warn(pci->dev, \"Types don't match (%08x != %08x)\\n\",\n\t\t\t pci->type, ver);\n\telse\n\t\tpci->type = ver;\n}\n\n \nstatic u8 __dw_pcie_find_next_cap(struct dw_pcie *pci, u8 cap_ptr,\n\t\t\t\t  u8 cap)\n{\n\tu8 cap_id, next_cap_ptr;\n\tu16 reg;\n\n\tif (!cap_ptr)\n\t\treturn 0;\n\n\treg = dw_pcie_readw_dbi(pci, cap_ptr);\n\tcap_id = (reg & 0x00ff);\n\n\tif (cap_id > PCI_CAP_ID_MAX)\n\t\treturn 0;\n\n\tif (cap_id == cap)\n\t\treturn cap_ptr;\n\n\tnext_cap_ptr = (reg & 0xff00) >> 8;\n\treturn __dw_pcie_find_next_cap(pci, next_cap_ptr, cap);\n}\n\nu8 dw_pcie_find_capability(struct dw_pcie *pci, u8 cap)\n{\n\tu8 next_cap_ptr;\n\tu16 reg;\n\n\treg = dw_pcie_readw_dbi(pci, PCI_CAPABILITY_LIST);\n\tnext_cap_ptr = (reg & 0x00ff);\n\n\treturn __dw_pcie_find_next_cap(pci, next_cap_ptr, cap);\n}\nEXPORT_SYMBOL_GPL(dw_pcie_find_capability);\n\nstatic u16 dw_pcie_find_next_ext_capability(struct dw_pcie *pci, u16 start,\n\t\t\t\t\t    u8 cap)\n{\n\tu32 header;\n\tint ttl;\n\tint pos = PCI_CFG_SPACE_SIZE;\n\n\t \n\tttl = (PCI_CFG_SPACE_EXP_SIZE - PCI_CFG_SPACE_SIZE) / 8;\n\n\tif (start)\n\t\tpos = start;\n\n\theader = dw_pcie_readl_dbi(pci, pos);\n\t \n\tif (header == 0)\n\t\treturn 0;\n\n\twhile (ttl-- > 0) {\n\t\tif (PCI_EXT_CAP_ID(header) == cap && pos != start)\n\t\t\treturn pos;\n\n\t\tpos = PCI_EXT_CAP_NEXT(header);\n\t\tif (pos < PCI_CFG_SPACE_SIZE)\n\t\t\tbreak;\n\n\t\theader = dw_pcie_readl_dbi(pci, pos);\n\t}\n\n\treturn 0;\n}\n\nu16 dw_pcie_find_ext_capability(struct dw_pcie *pci, u8 cap)\n{\n\treturn dw_pcie_find_next_ext_capability(pci, 0, cap);\n}\nEXPORT_SYMBOL_GPL(dw_pcie_find_ext_capability);\n\nint dw_pcie_read(void __iomem *addr, int size, u32 *val)\n{\n\tif (!IS_ALIGNED((uintptr_t)addr, size)) {\n\t\t*val = 0;\n\t\treturn PCIBIOS_BAD_REGISTER_NUMBER;\n\t}\n\n\tif (size == 4) {\n\t\t*val = readl(addr);\n\t} else if (size == 2) {\n\t\t*val = readw(addr);\n\t} else if (size == 1) {\n\t\t*val = readb(addr);\n\t} else {\n\t\t*val = 0;\n\t\treturn PCIBIOS_BAD_REGISTER_NUMBER;\n\t}\n\n\treturn PCIBIOS_SUCCESSFUL;\n}\nEXPORT_SYMBOL_GPL(dw_pcie_read);\n\nint dw_pcie_write(void __iomem *addr, int size, u32 val)\n{\n\tif (!IS_ALIGNED((uintptr_t)addr, size))\n\t\treturn PCIBIOS_BAD_REGISTER_NUMBER;\n\n\tif (size == 4)\n\t\twritel(val, addr);\n\telse if (size == 2)\n\t\twritew(val, addr);\n\telse if (size == 1)\n\t\twriteb(val, addr);\n\telse\n\t\treturn PCIBIOS_BAD_REGISTER_NUMBER;\n\n\treturn PCIBIOS_SUCCESSFUL;\n}\nEXPORT_SYMBOL_GPL(dw_pcie_write);\n\nu32 dw_pcie_read_dbi(struct dw_pcie *pci, u32 reg, size_t size)\n{\n\tint ret;\n\tu32 val;\n\n\tif (pci->ops && pci->ops->read_dbi)\n\t\treturn pci->ops->read_dbi(pci, pci->dbi_base, reg, size);\n\n\tret = dw_pcie_read(pci->dbi_base + reg, size, &val);\n\tif (ret)\n\t\tdev_err(pci->dev, \"Read DBI address failed\\n\");\n\n\treturn val;\n}\nEXPORT_SYMBOL_GPL(dw_pcie_read_dbi);\n\nvoid dw_pcie_write_dbi(struct dw_pcie *pci, u32 reg, size_t size, u32 val)\n{\n\tint ret;\n\n\tif (pci->ops && pci->ops->write_dbi) {\n\t\tpci->ops->write_dbi(pci, pci->dbi_base, reg, size, val);\n\t\treturn;\n\t}\n\n\tret = dw_pcie_write(pci->dbi_base + reg, size, val);\n\tif (ret)\n\t\tdev_err(pci->dev, \"Write DBI address failed\\n\");\n}\nEXPORT_SYMBOL_GPL(dw_pcie_write_dbi);\n\nvoid dw_pcie_write_dbi2(struct dw_pcie *pci, u32 reg, size_t size, u32 val)\n{\n\tint ret;\n\n\tif (pci->ops && pci->ops->write_dbi2) {\n\t\tpci->ops->write_dbi2(pci, pci->dbi_base2, reg, size, val);\n\t\treturn;\n\t}\n\n\tret = dw_pcie_write(pci->dbi_base2 + reg, size, val);\n\tif (ret)\n\t\tdev_err(pci->dev, \"write DBI address failed\\n\");\n}\n\nstatic inline void __iomem *dw_pcie_select_atu(struct dw_pcie *pci, u32 dir,\n\t\t\t\t\t       u32 index)\n{\n\tif (dw_pcie_cap_is(pci, IATU_UNROLL))\n\t\treturn pci->atu_base + PCIE_ATU_UNROLL_BASE(dir, index);\n\n\tdw_pcie_writel_dbi(pci, PCIE_ATU_VIEWPORT, dir | index);\n\treturn pci->atu_base;\n}\n\nstatic u32 dw_pcie_readl_atu(struct dw_pcie *pci, u32 dir, u32 index, u32 reg)\n{\n\tvoid __iomem *base;\n\tint ret;\n\tu32 val;\n\n\tbase = dw_pcie_select_atu(pci, dir, index);\n\n\tif (pci->ops && pci->ops->read_dbi)\n\t\treturn pci->ops->read_dbi(pci, base, reg, 4);\n\n\tret = dw_pcie_read(base + reg, 4, &val);\n\tif (ret)\n\t\tdev_err(pci->dev, \"Read ATU address failed\\n\");\n\n\treturn val;\n}\n\nstatic void dw_pcie_writel_atu(struct dw_pcie *pci, u32 dir, u32 index,\n\t\t\t       u32 reg, u32 val)\n{\n\tvoid __iomem *base;\n\tint ret;\n\n\tbase = dw_pcie_select_atu(pci, dir, index);\n\n\tif (pci->ops && pci->ops->write_dbi) {\n\t\tpci->ops->write_dbi(pci, base, reg, 4, val);\n\t\treturn;\n\t}\n\n\tret = dw_pcie_write(base + reg, 4, val);\n\tif (ret)\n\t\tdev_err(pci->dev, \"Write ATU address failed\\n\");\n}\n\nstatic inline u32 dw_pcie_readl_atu_ob(struct dw_pcie *pci, u32 index, u32 reg)\n{\n\treturn dw_pcie_readl_atu(pci, PCIE_ATU_REGION_DIR_OB, index, reg);\n}\n\nstatic inline void dw_pcie_writel_atu_ob(struct dw_pcie *pci, u32 index, u32 reg,\n\t\t\t\t\t u32 val)\n{\n\tdw_pcie_writel_atu(pci, PCIE_ATU_REGION_DIR_OB, index, reg, val);\n}\n\nstatic inline u32 dw_pcie_enable_ecrc(u32 val)\n{\n\t \n\n\treturn val | PCIE_ATU_TD;\n}\n\nstatic int __dw_pcie_prog_outbound_atu(struct dw_pcie *pci, u8 func_no,\n\t\t\t\t       int index, int type, u64 cpu_addr,\n\t\t\t\t       u64 pci_addr, u64 size)\n{\n\tu32 retries, val;\n\tu64 limit_addr;\n\n\tif (pci->ops && pci->ops->cpu_addr_fixup)\n\t\tcpu_addr = pci->ops->cpu_addr_fixup(pci, cpu_addr);\n\n\tlimit_addr = cpu_addr + size - 1;\n\n\tif ((limit_addr & ~pci->region_limit) != (cpu_addr & ~pci->region_limit) ||\n\t    !IS_ALIGNED(cpu_addr, pci->region_align) ||\n\t    !IS_ALIGNED(pci_addr, pci->region_align) || !size) {\n\t\treturn -EINVAL;\n\t}\n\n\tdw_pcie_writel_atu_ob(pci, index, PCIE_ATU_LOWER_BASE,\n\t\t\t      lower_32_bits(cpu_addr));\n\tdw_pcie_writel_atu_ob(pci, index, PCIE_ATU_UPPER_BASE,\n\t\t\t      upper_32_bits(cpu_addr));\n\n\tdw_pcie_writel_atu_ob(pci, index, PCIE_ATU_LIMIT,\n\t\t\t      lower_32_bits(limit_addr));\n\tif (dw_pcie_ver_is_ge(pci, 460A))\n\t\tdw_pcie_writel_atu_ob(pci, index, PCIE_ATU_UPPER_LIMIT,\n\t\t\t\t      upper_32_bits(limit_addr));\n\n\tdw_pcie_writel_atu_ob(pci, index, PCIE_ATU_LOWER_TARGET,\n\t\t\t      lower_32_bits(pci_addr));\n\tdw_pcie_writel_atu_ob(pci, index, PCIE_ATU_UPPER_TARGET,\n\t\t\t      upper_32_bits(pci_addr));\n\n\tval = type | PCIE_ATU_FUNC_NUM(func_no);\n\tif (upper_32_bits(limit_addr) > upper_32_bits(cpu_addr) &&\n\t    dw_pcie_ver_is_ge(pci, 460A))\n\t\tval |= PCIE_ATU_INCREASE_REGION_SIZE;\n\tif (dw_pcie_ver_is(pci, 490A))\n\t\tval = dw_pcie_enable_ecrc(val);\n\tdw_pcie_writel_atu_ob(pci, index, PCIE_ATU_REGION_CTRL1, val);\n\n\tdw_pcie_writel_atu_ob(pci, index, PCIE_ATU_REGION_CTRL2, PCIE_ATU_ENABLE);\n\n\t \n\tfor (retries = 0; retries < LINK_WAIT_MAX_IATU_RETRIES; retries++) {\n\t\tval = dw_pcie_readl_atu_ob(pci, index, PCIE_ATU_REGION_CTRL2);\n\t\tif (val & PCIE_ATU_ENABLE)\n\t\t\treturn 0;\n\n\t\tmdelay(LINK_WAIT_IATU);\n\t}\n\n\tdev_err(pci->dev, \"Outbound iATU is not being enabled\\n\");\n\n\treturn -ETIMEDOUT;\n}\n\nint dw_pcie_prog_outbound_atu(struct dw_pcie *pci, int index, int type,\n\t\t\t      u64 cpu_addr, u64 pci_addr, u64 size)\n{\n\treturn __dw_pcie_prog_outbound_atu(pci, 0, index, type,\n\t\t\t\t\t   cpu_addr, pci_addr, size);\n}\n\nint dw_pcie_prog_ep_outbound_atu(struct dw_pcie *pci, u8 func_no, int index,\n\t\t\t\t int type, u64 cpu_addr, u64 pci_addr,\n\t\t\t\t u64 size)\n{\n\treturn __dw_pcie_prog_outbound_atu(pci, func_no, index, type,\n\t\t\t\t\t   cpu_addr, pci_addr, size);\n}\n\nstatic inline u32 dw_pcie_readl_atu_ib(struct dw_pcie *pci, u32 index, u32 reg)\n{\n\treturn dw_pcie_readl_atu(pci, PCIE_ATU_REGION_DIR_IB, index, reg);\n}\n\nstatic inline void dw_pcie_writel_atu_ib(struct dw_pcie *pci, u32 index, u32 reg,\n\t\t\t\t\t u32 val)\n{\n\tdw_pcie_writel_atu(pci, PCIE_ATU_REGION_DIR_IB, index, reg, val);\n}\n\nint dw_pcie_prog_inbound_atu(struct dw_pcie *pci, int index, int type,\n\t\t\t     u64 cpu_addr, u64 pci_addr, u64 size)\n{\n\tu64 limit_addr = pci_addr + size - 1;\n\tu32 retries, val;\n\n\tif ((limit_addr & ~pci->region_limit) != (pci_addr & ~pci->region_limit) ||\n\t    !IS_ALIGNED(cpu_addr, pci->region_align) ||\n\t    !IS_ALIGNED(pci_addr, pci->region_align) || !size) {\n\t\treturn -EINVAL;\n\t}\n\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_LOWER_BASE,\n\t\t\t      lower_32_bits(pci_addr));\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_UPPER_BASE,\n\t\t\t      upper_32_bits(pci_addr));\n\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_LIMIT,\n\t\t\t      lower_32_bits(limit_addr));\n\tif (dw_pcie_ver_is_ge(pci, 460A))\n\t\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_UPPER_LIMIT,\n\t\t\t\t      upper_32_bits(limit_addr));\n\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_LOWER_TARGET,\n\t\t\t      lower_32_bits(cpu_addr));\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_UPPER_TARGET,\n\t\t\t      upper_32_bits(cpu_addr));\n\n\tval = type;\n\tif (upper_32_bits(limit_addr) > upper_32_bits(pci_addr) &&\n\t    dw_pcie_ver_is_ge(pci, 460A))\n\t\tval |= PCIE_ATU_INCREASE_REGION_SIZE;\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_REGION_CTRL1, val);\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_REGION_CTRL2, PCIE_ATU_ENABLE);\n\n\t \n\tfor (retries = 0; retries < LINK_WAIT_MAX_IATU_RETRIES; retries++) {\n\t\tval = dw_pcie_readl_atu_ib(pci, index, PCIE_ATU_REGION_CTRL2);\n\t\tif (val & PCIE_ATU_ENABLE)\n\t\t\treturn 0;\n\n\t\tmdelay(LINK_WAIT_IATU);\n\t}\n\n\tdev_err(pci->dev, \"Inbound iATU is not being enabled\\n\");\n\n\treturn -ETIMEDOUT;\n}\n\nint dw_pcie_prog_ep_inbound_atu(struct dw_pcie *pci, u8 func_no, int index,\n\t\t\t\tint type, u64 cpu_addr, u8 bar)\n{\n\tu32 retries, val;\n\n\tif (!IS_ALIGNED(cpu_addr, pci->region_align))\n\t\treturn -EINVAL;\n\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_LOWER_TARGET,\n\t\t\t      lower_32_bits(cpu_addr));\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_UPPER_TARGET,\n\t\t\t      upper_32_bits(cpu_addr));\n\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_REGION_CTRL1, type |\n\t\t\t      PCIE_ATU_FUNC_NUM(func_no));\n\tdw_pcie_writel_atu_ib(pci, index, PCIE_ATU_REGION_CTRL2,\n\t\t\t      PCIE_ATU_ENABLE | PCIE_ATU_FUNC_NUM_MATCH_EN |\n\t\t\t      PCIE_ATU_BAR_MODE_ENABLE | (bar << 8));\n\n\t \n\tfor (retries = 0; retries < LINK_WAIT_MAX_IATU_RETRIES; retries++) {\n\t\tval = dw_pcie_readl_atu_ib(pci, index, PCIE_ATU_REGION_CTRL2);\n\t\tif (val & PCIE_ATU_ENABLE)\n\t\t\treturn 0;\n\n\t\tmdelay(LINK_WAIT_IATU);\n\t}\n\n\tdev_err(pci->dev, \"Inbound iATU is not being enabled\\n\");\n\n\treturn -ETIMEDOUT;\n}\n\nvoid dw_pcie_disable_atu(struct dw_pcie *pci, u32 dir, int index)\n{\n\tdw_pcie_writel_atu(pci, dir, index, PCIE_ATU_REGION_CTRL2, 0);\n}\n\nint dw_pcie_wait_for_link(struct dw_pcie *pci)\n{\n\tu32 offset, val;\n\tint retries;\n\n\t \n\tfor (retries = 0; retries < LINK_WAIT_MAX_RETRIES; retries++) {\n\t\tif (dw_pcie_link_up(pci))\n\t\t\tbreak;\n\n\t\tusleep_range(LINK_WAIT_USLEEP_MIN, LINK_WAIT_USLEEP_MAX);\n\t}\n\n\tif (retries >= LINK_WAIT_MAX_RETRIES) {\n\t\tdev_info(pci->dev, \"Phy link never came up\\n\");\n\t\treturn -ETIMEDOUT;\n\t}\n\n\toffset = dw_pcie_find_capability(pci, PCI_CAP_ID_EXP);\n\tval = dw_pcie_readw_dbi(pci, offset + PCI_EXP_LNKSTA);\n\n\tdev_info(pci->dev, \"PCIe Gen.%u x%u link up\\n\",\n\t\t FIELD_GET(PCI_EXP_LNKSTA_CLS, val),\n\t\t FIELD_GET(PCI_EXP_LNKSTA_NLW, val));\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(dw_pcie_wait_for_link);\n\nint dw_pcie_link_up(struct dw_pcie *pci)\n{\n\tu32 val;\n\n\tif (pci->ops && pci->ops->link_up)\n\t\treturn pci->ops->link_up(pci);\n\n\tval = dw_pcie_readl_dbi(pci, PCIE_PORT_DEBUG1);\n\treturn ((val & PCIE_PORT_DEBUG1_LINK_UP) &&\n\t\t(!(val & PCIE_PORT_DEBUG1_LINK_IN_TRAINING)));\n}\nEXPORT_SYMBOL_GPL(dw_pcie_link_up);\n\nvoid dw_pcie_upconfig_setup(struct dw_pcie *pci)\n{\n\tu32 val;\n\n\tval = dw_pcie_readl_dbi(pci, PCIE_PORT_MULTI_LANE_CTRL);\n\tval |= PORT_MLTI_UPCFG_SUPPORT;\n\tdw_pcie_writel_dbi(pci, PCIE_PORT_MULTI_LANE_CTRL, val);\n}\nEXPORT_SYMBOL_GPL(dw_pcie_upconfig_setup);\n\nstatic void dw_pcie_link_set_max_speed(struct dw_pcie *pci, u32 link_gen)\n{\n\tu32 cap, ctrl2, link_speed;\n\tu8 offset = dw_pcie_find_capability(pci, PCI_CAP_ID_EXP);\n\n\tcap = dw_pcie_readl_dbi(pci, offset + PCI_EXP_LNKCAP);\n\tctrl2 = dw_pcie_readl_dbi(pci, offset + PCI_EXP_LNKCTL2);\n\tctrl2 &= ~PCI_EXP_LNKCTL2_TLS;\n\n\tswitch (pcie_link_speed[link_gen]) {\n\tcase PCIE_SPEED_2_5GT:\n\t\tlink_speed = PCI_EXP_LNKCTL2_TLS_2_5GT;\n\t\tbreak;\n\tcase PCIE_SPEED_5_0GT:\n\t\tlink_speed = PCI_EXP_LNKCTL2_TLS_5_0GT;\n\t\tbreak;\n\tcase PCIE_SPEED_8_0GT:\n\t\tlink_speed = PCI_EXP_LNKCTL2_TLS_8_0GT;\n\t\tbreak;\n\tcase PCIE_SPEED_16_0GT:\n\t\tlink_speed = PCI_EXP_LNKCTL2_TLS_16_0GT;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tlink_speed = FIELD_GET(PCI_EXP_LNKCAP_SLS, cap);\n\t\tctrl2 &= ~PCI_EXP_LNKCTL2_HASD;\n\t\tbreak;\n\t}\n\n\tdw_pcie_writel_dbi(pci, offset + PCI_EXP_LNKCTL2, ctrl2 | link_speed);\n\n\tcap &= ~((u32)PCI_EXP_LNKCAP_SLS);\n\tdw_pcie_writel_dbi(pci, offset + PCI_EXP_LNKCAP, cap | link_speed);\n\n}\n\nstatic void dw_pcie_link_set_max_link_width(struct dw_pcie *pci, u32 num_lanes)\n{\n\tu32 lnkcap, lwsc, plc;\n\tu8 cap;\n\n\tif (!num_lanes)\n\t\treturn;\n\n\t \n\tplc = dw_pcie_readl_dbi(pci, PCIE_PORT_LINK_CONTROL);\n\tplc &= ~PORT_LINK_FAST_LINK_MODE;\n\tplc &= ~PORT_LINK_MODE_MASK;\n\n\t \n\tlwsc = dw_pcie_readl_dbi(pci, PCIE_LINK_WIDTH_SPEED_CONTROL);\n\tlwsc &= ~PORT_LOGIC_LINK_WIDTH_MASK;\n\tswitch (num_lanes) {\n\tcase 1:\n\t\tplc |= PORT_LINK_MODE_1_LANES;\n\t\tlwsc |= PORT_LOGIC_LINK_WIDTH_1_LANES;\n\t\tbreak;\n\tcase 2:\n\t\tplc |= PORT_LINK_MODE_2_LANES;\n\t\tlwsc |= PORT_LOGIC_LINK_WIDTH_2_LANES;\n\t\tbreak;\n\tcase 4:\n\t\tplc |= PORT_LINK_MODE_4_LANES;\n\t\tlwsc |= PORT_LOGIC_LINK_WIDTH_4_LANES;\n\t\tbreak;\n\tcase 8:\n\t\tplc |= PORT_LINK_MODE_8_LANES;\n\t\tlwsc |= PORT_LOGIC_LINK_WIDTH_8_LANES;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(pci->dev, \"num-lanes %u: invalid value\\n\", num_lanes);\n\t\treturn;\n\t}\n\tdw_pcie_writel_dbi(pci, PCIE_PORT_LINK_CONTROL, plc);\n\tdw_pcie_writel_dbi(pci, PCIE_LINK_WIDTH_SPEED_CONTROL, lwsc);\n\n\tcap = dw_pcie_find_capability(pci, PCI_CAP_ID_EXP);\n\tlnkcap = dw_pcie_readl_dbi(pci, cap + PCI_EXP_LNKCAP);\n\tlnkcap &= ~PCI_EXP_LNKCAP_MLW;\n\tlnkcap |= FIELD_PREP(PCI_EXP_LNKCAP_MLW, num_lanes);\n\tdw_pcie_writel_dbi(pci, cap + PCI_EXP_LNKCAP, lnkcap);\n}\n\nvoid dw_pcie_iatu_detect(struct dw_pcie *pci)\n{\n\tint max_region, ob, ib;\n\tu32 val, min, dir;\n\tu64 max;\n\n\tval = dw_pcie_readl_dbi(pci, PCIE_ATU_VIEWPORT);\n\tif (val == 0xFFFFFFFF) {\n\t\tdw_pcie_cap_set(pci, IATU_UNROLL);\n\n\t\tmax_region = min((int)pci->atu_size / 512, 256);\n\t} else {\n\t\tpci->atu_base = pci->dbi_base + PCIE_ATU_VIEWPORT_BASE;\n\t\tpci->atu_size = PCIE_ATU_VIEWPORT_SIZE;\n\n\t\tdw_pcie_writel_dbi(pci, PCIE_ATU_VIEWPORT, 0xFF);\n\t\tmax_region = dw_pcie_readl_dbi(pci, PCIE_ATU_VIEWPORT) + 1;\n\t}\n\n\tfor (ob = 0; ob < max_region; ob++) {\n\t\tdw_pcie_writel_atu_ob(pci, ob, PCIE_ATU_LOWER_TARGET, 0x11110000);\n\t\tval = dw_pcie_readl_atu_ob(pci, ob, PCIE_ATU_LOWER_TARGET);\n\t\tif (val != 0x11110000)\n\t\t\tbreak;\n\t}\n\n\tfor (ib = 0; ib < max_region; ib++) {\n\t\tdw_pcie_writel_atu_ib(pci, ib, PCIE_ATU_LOWER_TARGET, 0x11110000);\n\t\tval = dw_pcie_readl_atu_ib(pci, ib, PCIE_ATU_LOWER_TARGET);\n\t\tif (val != 0x11110000)\n\t\t\tbreak;\n\t}\n\n\tif (ob) {\n\t\tdir = PCIE_ATU_REGION_DIR_OB;\n\t} else if (ib) {\n\t\tdir = PCIE_ATU_REGION_DIR_IB;\n\t} else {\n\t\tdev_err(pci->dev, \"No iATU regions found\\n\");\n\t\treturn;\n\t}\n\n\tdw_pcie_writel_atu(pci, dir, 0, PCIE_ATU_LIMIT, 0x0);\n\tmin = dw_pcie_readl_atu(pci, dir, 0, PCIE_ATU_LIMIT);\n\n\tif (dw_pcie_ver_is_ge(pci, 460A)) {\n\t\tdw_pcie_writel_atu(pci, dir, 0, PCIE_ATU_UPPER_LIMIT, 0xFFFFFFFF);\n\t\tmax = dw_pcie_readl_atu(pci, dir, 0, PCIE_ATU_UPPER_LIMIT);\n\t} else {\n\t\tmax = 0;\n\t}\n\n\tpci->num_ob_windows = ob;\n\tpci->num_ib_windows = ib;\n\tpci->region_align = 1 << fls(min);\n\tpci->region_limit = (max << 32) | (SZ_4G - 1);\n\n\tdev_info(pci->dev, \"iATU: unroll %s, %u ob, %u ib, align %uK, limit %lluG\\n\",\n\t\t dw_pcie_cap_is(pci, IATU_UNROLL) ? \"T\" : \"F\",\n\t\t pci->num_ob_windows, pci->num_ib_windows,\n\t\t pci->region_align / SZ_1K, (pci->region_limit + 1) / SZ_1G);\n}\n\nstatic u32 dw_pcie_readl_dma(struct dw_pcie *pci, u32 reg)\n{\n\tu32 val = 0;\n\tint ret;\n\n\tif (pci->ops && pci->ops->read_dbi)\n\t\treturn pci->ops->read_dbi(pci, pci->edma.reg_base, reg, 4);\n\n\tret = dw_pcie_read(pci->edma.reg_base + reg, 4, &val);\n\tif (ret)\n\t\tdev_err(pci->dev, \"Read DMA address failed\\n\");\n\n\treturn val;\n}\n\nstatic int dw_pcie_edma_irq_vector(struct device *dev, unsigned int nr)\n{\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tchar name[6];\n\tint ret;\n\n\tif (nr >= EDMA_MAX_WR_CH + EDMA_MAX_RD_CH)\n\t\treturn -EINVAL;\n\n\tret = platform_get_irq_byname_optional(pdev, \"dma\");\n\tif (ret > 0)\n\t\treturn ret;\n\n\tsnprintf(name, sizeof(name), \"dma%u\", nr);\n\n\treturn platform_get_irq_byname_optional(pdev, name);\n}\n\nstatic struct dw_edma_plat_ops dw_pcie_edma_ops = {\n\t.irq_vector = dw_pcie_edma_irq_vector,\n};\n\nstatic int dw_pcie_edma_find_chip(struct dw_pcie *pci)\n{\n\tu32 val;\n\n\t \n\tif (dw_pcie_ver_is_ge(pci, 540A))\n\t\tval = 0xFFFFFFFF;\n\telse\n\t\tval = dw_pcie_readl_dbi(pci, PCIE_DMA_VIEWPORT_BASE + PCIE_DMA_CTRL);\n\n\tif (val == 0xFFFFFFFF && pci->edma.reg_base) {\n\t\tpci->edma.mf = EDMA_MF_EDMA_UNROLL;\n\n\t\tval = dw_pcie_readl_dma(pci, PCIE_DMA_CTRL);\n\t} else if (val != 0xFFFFFFFF) {\n\t\tpci->edma.mf = EDMA_MF_EDMA_LEGACY;\n\n\t\tpci->edma.reg_base = pci->dbi_base + PCIE_DMA_VIEWPORT_BASE;\n\t} else {\n\t\treturn -ENODEV;\n\t}\n\n\tpci->edma.dev = pci->dev;\n\n\tif (!pci->edma.ops)\n\t\tpci->edma.ops = &dw_pcie_edma_ops;\n\n\tpci->edma.flags |= DW_EDMA_CHIP_LOCAL;\n\n\tpci->edma.ll_wr_cnt = FIELD_GET(PCIE_DMA_NUM_WR_CHAN, val);\n\tpci->edma.ll_rd_cnt = FIELD_GET(PCIE_DMA_NUM_RD_CHAN, val);\n\n\t \n\tif (!pci->edma.ll_wr_cnt || pci->edma.ll_wr_cnt > EDMA_MAX_WR_CH ||\n\t    !pci->edma.ll_rd_cnt || pci->edma.ll_rd_cnt > EDMA_MAX_RD_CH)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int dw_pcie_edma_irq_verify(struct dw_pcie *pci)\n{\n\tstruct platform_device *pdev = to_platform_device(pci->dev);\n\tu16 ch_cnt = pci->edma.ll_wr_cnt + pci->edma.ll_rd_cnt;\n\tchar name[6];\n\tint ret;\n\n\tif (pci->edma.nr_irqs == 1)\n\t\treturn 0;\n\telse if (pci->edma.nr_irqs > 1)\n\t\treturn pci->edma.nr_irqs != ch_cnt ? -EINVAL : 0;\n\n\tret = platform_get_irq_byname_optional(pdev, \"dma\");\n\tif (ret > 0) {\n\t\tpci->edma.nr_irqs = 1;\n\t\treturn 0;\n\t}\n\n\tfor (; pci->edma.nr_irqs < ch_cnt; pci->edma.nr_irqs++) {\n\t\tsnprintf(name, sizeof(name), \"dma%d\", pci->edma.nr_irqs);\n\n\t\tret = platform_get_irq_byname_optional(pdev, name);\n\t\tif (ret <= 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int dw_pcie_edma_ll_alloc(struct dw_pcie *pci)\n{\n\tstruct dw_edma_region *ll;\n\tdma_addr_t paddr;\n\tint i;\n\n\tfor (i = 0; i < pci->edma.ll_wr_cnt; i++) {\n\t\tll = &pci->edma.ll_region_wr[i];\n\t\tll->sz = DMA_LLP_MEM_SIZE;\n\t\tll->vaddr.mem = dmam_alloc_coherent(pci->dev, ll->sz,\n\t\t\t\t\t\t    &paddr, GFP_KERNEL);\n\t\tif (!ll->vaddr.mem)\n\t\t\treturn -ENOMEM;\n\n\t\tll->paddr = paddr;\n\t}\n\n\tfor (i = 0; i < pci->edma.ll_rd_cnt; i++) {\n\t\tll = &pci->edma.ll_region_rd[i];\n\t\tll->sz = DMA_LLP_MEM_SIZE;\n\t\tll->vaddr.mem = dmam_alloc_coherent(pci->dev, ll->sz,\n\t\t\t\t\t\t    &paddr, GFP_KERNEL);\n\t\tif (!ll->vaddr.mem)\n\t\t\treturn -ENOMEM;\n\n\t\tll->paddr = paddr;\n\t}\n\n\treturn 0;\n}\n\nint dw_pcie_edma_detect(struct dw_pcie *pci)\n{\n\tint ret;\n\n\t \n\tret = dw_pcie_edma_find_chip(pci);\n\tif (ret)\n\t\treturn 0;\n\n\t \n\tret = dw_pcie_edma_irq_verify(pci);\n\tif (ret) {\n\t\tdev_err(pci->dev, \"Invalid eDMA IRQs found\\n\");\n\t\treturn 0;\n\t}\n\n\tret = dw_pcie_edma_ll_alloc(pci);\n\tif (ret) {\n\t\tdev_err(pci->dev, \"Couldn't allocate LLP memory\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = dw_edma_probe(&pci->edma);\n\tif (ret && ret != -ENODEV) {\n\t\tdev_err(pci->dev, \"Couldn't register eDMA device\\n\");\n\t\treturn ret;\n\t}\n\n\tdev_info(pci->dev, \"eDMA: unroll %s, %hu wr, %hu rd\\n\",\n\t\t pci->edma.mf == EDMA_MF_EDMA_UNROLL ? \"T\" : \"F\",\n\t\t pci->edma.ll_wr_cnt, pci->edma.ll_rd_cnt);\n\n\treturn 0;\n}\n\nvoid dw_pcie_edma_remove(struct dw_pcie *pci)\n{\n\tdw_edma_remove(&pci->edma);\n}\n\nvoid dw_pcie_setup(struct dw_pcie *pci)\n{\n\tu32 val;\n\n\tif (pci->link_gen > 0)\n\t\tdw_pcie_link_set_max_speed(pci, pci->link_gen);\n\n\t \n\tif (pci->n_fts[0]) {\n\t\tval = dw_pcie_readl_dbi(pci, PCIE_PORT_AFR);\n\t\tval &= ~(PORT_AFR_N_FTS_MASK | PORT_AFR_CC_N_FTS_MASK);\n\t\tval |= PORT_AFR_N_FTS(pci->n_fts[0]);\n\t\tval |= PORT_AFR_CC_N_FTS(pci->n_fts[0]);\n\t\tdw_pcie_writel_dbi(pci, PCIE_PORT_AFR, val);\n\t}\n\n\t \n\tif (pci->n_fts[1]) {\n\t\tval = dw_pcie_readl_dbi(pci, PCIE_LINK_WIDTH_SPEED_CONTROL);\n\t\tval &= ~PORT_LOGIC_N_FTS_MASK;\n\t\tval |= pci->n_fts[1];\n\t\tdw_pcie_writel_dbi(pci, PCIE_LINK_WIDTH_SPEED_CONTROL, val);\n\t}\n\n\tif (dw_pcie_cap_is(pci, CDM_CHECK)) {\n\t\tval = dw_pcie_readl_dbi(pci, PCIE_PL_CHK_REG_CONTROL_STATUS);\n\t\tval |= PCIE_PL_CHK_REG_CHK_REG_CONTINUOUS |\n\t\t       PCIE_PL_CHK_REG_CHK_REG_START;\n\t\tdw_pcie_writel_dbi(pci, PCIE_PL_CHK_REG_CONTROL_STATUS, val);\n\t}\n\n\tval = dw_pcie_readl_dbi(pci, PCIE_PORT_LINK_CONTROL);\n\tval &= ~PORT_LINK_FAST_LINK_MODE;\n\tval |= PORT_LINK_DLL_LINK_EN;\n\tdw_pcie_writel_dbi(pci, PCIE_PORT_LINK_CONTROL, val);\n\n\tdw_pcie_link_set_max_link_width(pci, pci->num_lanes);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}