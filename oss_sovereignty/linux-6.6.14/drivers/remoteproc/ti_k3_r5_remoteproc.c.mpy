{
  "module_name": "ti_k3_r5_remoteproc.c",
  "hash_id": "88f14df9f9ac8b754b2744ff82863213f0f6074ca2652a56885da12fe72dfeb6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/remoteproc/ti_k3_r5_remoteproc.c",
  "human_readable_source": "\n \n\n#include <linux/dma-mapping.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/mailbox_client.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/of_reserved_mem.h>\n#include <linux/of_platform.h>\n#include <linux/omap-mailbox.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/remoteproc.h>\n#include <linux/reset.h>\n#include <linux/slab.h>\n\n#include \"omap_remoteproc.h\"\n#include \"remoteproc_internal.h\"\n#include \"ti_sci_proc.h\"\n\n \n#define K3_R5_TCM_DEV_ADDR\t0x41010000\n\n \n#define PROC_BOOT_CFG_FLAG_R5_DBG_EN\t\t\t0x00000001\n#define PROC_BOOT_CFG_FLAG_R5_DBG_NIDEN\t\t\t0x00000002\n#define PROC_BOOT_CFG_FLAG_R5_LOCKSTEP\t\t\t0x00000100\n#define PROC_BOOT_CFG_FLAG_R5_TEINIT\t\t\t0x00000200\n#define PROC_BOOT_CFG_FLAG_R5_NMFI_EN\t\t\t0x00000400\n#define PROC_BOOT_CFG_FLAG_R5_TCM_RSTBASE\t\t0x00000800\n#define PROC_BOOT_CFG_FLAG_R5_BTCM_EN\t\t\t0x00001000\n#define PROC_BOOT_CFG_FLAG_R5_ATCM_EN\t\t\t0x00002000\n \n#define PROC_BOOT_CFG_FLAG_R5_MEM_INIT_DIS\t\t0x00004000\n \n#define PROC_BOOT_CFG_FLAG_R5_SINGLE_CORE\t\t0x00008000\n\n \n#define PROC_BOOT_CTRL_FLAG_R5_CORE_HALT\t\t0x00000001\n\n \n#define PROC_BOOT_STATUS_FLAG_R5_WFE\t\t\t0x00000001\n#define PROC_BOOT_STATUS_FLAG_R5_WFI\t\t\t0x00000002\n#define PROC_BOOT_STATUS_FLAG_R5_CLK_GATED\t\t0x00000004\n#define PROC_BOOT_STATUS_FLAG_R5_LOCKSTEP_PERMITTED\t0x00000100\n \n#define PROC_BOOT_STATUS_FLAG_R5_SINGLECORE_ONLY\t0x00000200\n\n \nstruct k3_r5_mem {\n\tvoid __iomem *cpu_addr;\n\tphys_addr_t bus_addr;\n\tu32 dev_addr;\n\tsize_t size;\n};\n\n \nenum cluster_mode {\n\tCLUSTER_MODE_SPLIT = 0,\n\tCLUSTER_MODE_LOCKSTEP,\n\tCLUSTER_MODE_SINGLECPU,\n\tCLUSTER_MODE_SINGLECORE\n};\n\n \nstruct k3_r5_soc_data {\n\tbool tcm_is_double;\n\tbool tcm_ecc_autoinit;\n\tbool single_cpu_mode;\n\tbool is_single_core;\n};\n\n \nstruct k3_r5_cluster {\n\tstruct device *dev;\n\tenum cluster_mode mode;\n\tstruct list_head cores;\n\tconst struct k3_r5_soc_data *soc_data;\n};\n\n \nstruct k3_r5_core {\n\tstruct list_head elem;\n\tstruct device *dev;\n\tstruct rproc *rproc;\n\tstruct k3_r5_mem *mem;\n\tstruct k3_r5_mem *sram;\n\tint num_mems;\n\tint num_sram;\n\tstruct reset_control *reset;\n\tstruct ti_sci_proc *tsp;\n\tconst struct ti_sci_handle *ti_sci;\n\tu32 ti_sci_id;\n\tu32 atcm_enable;\n\tu32 btcm_enable;\n\tu32 loczrama;\n};\n\n \nstruct k3_r5_rproc {\n\tstruct device *dev;\n\tstruct k3_r5_cluster *cluster;\n\tstruct mbox_chan *mbox;\n\tstruct mbox_client client;\n\tstruct rproc *rproc;\n\tstruct k3_r5_core *core;\n\tstruct k3_r5_mem *rmem;\n\tint num_rmems;\n};\n\n \nstatic void k3_r5_rproc_mbox_callback(struct mbox_client *client, void *data)\n{\n\tstruct k3_r5_rproc *kproc = container_of(client, struct k3_r5_rproc,\n\t\t\t\t\t\tclient);\n\tstruct device *dev = kproc->rproc->dev.parent;\n\tconst char *name = kproc->rproc->name;\n\tu32 msg = omap_mbox_message(data);\n\n\tdev_dbg(dev, \"mbox msg: 0x%x\\n\", msg);\n\n\tswitch (msg) {\n\tcase RP_MBOX_CRASH:\n\t\t \n\t\tdev_err(dev, \"K3 R5F rproc %s crashed\\n\", name);\n\t\tbreak;\n\tcase RP_MBOX_ECHO_REPLY:\n\t\tdev_info(dev, \"received echo reply from %s\\n\", name);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tif (msg >= RP_MBOX_READY && msg < RP_MBOX_END_MSG)\n\t\t\treturn;\n\t\tif (msg > kproc->rproc->max_notifyid) {\n\t\t\tdev_dbg(dev, \"dropping unknown message 0x%x\", msg);\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tif (rproc_vq_interrupt(kproc->rproc, msg) == IRQ_NONE)\n\t\t\tdev_dbg(dev, \"no message was found in vqid %d\\n\", msg);\n\t}\n}\n\n \nstatic void k3_r5_rproc_kick(struct rproc *rproc, int vqid)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct device *dev = rproc->dev.parent;\n\tmbox_msg_t msg = (mbox_msg_t)vqid;\n\tint ret;\n\n\t \n\tret = mbox_send_message(kproc->mbox, (void *)msg);\n\tif (ret < 0)\n\t\tdev_err(dev, \"failed to send mailbox message, status = %d\\n\",\n\t\t\tret);\n}\n\nstatic int k3_r5_split_reset(struct k3_r5_core *core)\n{\n\tint ret;\n\n\tret = reset_control_assert(core->reset);\n\tif (ret) {\n\t\tdev_err(core->dev, \"local-reset assert failed, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tret = core->ti_sci->ops.dev_ops.put_device(core->ti_sci,\n\t\t\t\t\t\t   core->ti_sci_id);\n\tif (ret) {\n\t\tdev_err(core->dev, \"module-reset assert failed, ret = %d\\n\",\n\t\t\tret);\n\t\tif (reset_control_deassert(core->reset))\n\t\t\tdev_warn(core->dev, \"local-reset deassert back failed\\n\");\n\t}\n\n\treturn ret;\n}\n\nstatic int k3_r5_split_release(struct k3_r5_core *core)\n{\n\tint ret;\n\n\tret = core->ti_sci->ops.dev_ops.get_device(core->ti_sci,\n\t\t\t\t\t\t   core->ti_sci_id);\n\tif (ret) {\n\t\tdev_err(core->dev, \"module-reset deassert failed, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tret = reset_control_deassert(core->reset);\n\tif (ret) {\n\t\tdev_err(core->dev, \"local-reset deassert failed, ret = %d\\n\",\n\t\t\tret);\n\t\tif (core->ti_sci->ops.dev_ops.put_device(core->ti_sci,\n\t\t\t\t\t\t\t core->ti_sci_id))\n\t\t\tdev_warn(core->dev, \"module-reset assert back failed\\n\");\n\t}\n\n\treturn ret;\n}\n\nstatic int k3_r5_lockstep_reset(struct k3_r5_cluster *cluster)\n{\n\tstruct k3_r5_core *core;\n\tint ret;\n\n\t \n\tlist_for_each_entry(core, &cluster->cores, elem) {\n\t\tret = reset_control_assert(core->reset);\n\t\tif (ret) {\n\t\t\tdev_err(core->dev, \"local-reset assert failed, ret = %d\\n\",\n\t\t\t\tret);\n\t\t\tcore = list_prev_entry(core, elem);\n\t\t\tgoto unroll_local_reset;\n\t\t}\n\t}\n\n\t \n\tlist_for_each_entry(core, &cluster->cores, elem) {\n\t\tret = core->ti_sci->ops.dev_ops.put_device(core->ti_sci,\n\t\t\t\t\t\t\t   core->ti_sci_id);\n\t\tif (ret) {\n\t\t\tdev_err(core->dev, \"module-reset assert failed, ret = %d\\n\",\n\t\t\t\tret);\n\t\t\tgoto unroll_module_reset;\n\t\t}\n\t}\n\n\treturn 0;\n\nunroll_module_reset:\n\tlist_for_each_entry_continue_reverse(core, &cluster->cores, elem) {\n\t\tif (core->ti_sci->ops.dev_ops.put_device(core->ti_sci,\n\t\t\t\t\t\t\t core->ti_sci_id))\n\t\t\tdev_warn(core->dev, \"module-reset assert back failed\\n\");\n\t}\n\tcore = list_last_entry(&cluster->cores, struct k3_r5_core, elem);\nunroll_local_reset:\n\tlist_for_each_entry_from_reverse(core, &cluster->cores, elem) {\n\t\tif (reset_control_deassert(core->reset))\n\t\t\tdev_warn(core->dev, \"local-reset deassert back failed\\n\");\n\t}\n\n\treturn ret;\n}\n\nstatic int k3_r5_lockstep_release(struct k3_r5_cluster *cluster)\n{\n\tstruct k3_r5_core *core;\n\tint ret;\n\n\t \n\tlist_for_each_entry_reverse(core, &cluster->cores, elem) {\n\t\tret = core->ti_sci->ops.dev_ops.get_device(core->ti_sci,\n\t\t\t\t\t\t\t   core->ti_sci_id);\n\t\tif (ret) {\n\t\t\tdev_err(core->dev, \"module-reset deassert failed, ret = %d\\n\",\n\t\t\t\tret);\n\t\t\tcore = list_next_entry(core, elem);\n\t\t\tgoto unroll_module_reset;\n\t\t}\n\t}\n\n\t \n\tlist_for_each_entry_reverse(core, &cluster->cores, elem) {\n\t\tret = reset_control_deassert(core->reset);\n\t\tif (ret) {\n\t\t\tdev_err(core->dev, \"module-reset deassert failed, ret = %d\\n\",\n\t\t\t\tret);\n\t\t\tgoto unroll_local_reset;\n\t\t}\n\t}\n\n\treturn 0;\n\nunroll_local_reset:\n\tlist_for_each_entry_continue(core, &cluster->cores, elem) {\n\t\tif (reset_control_assert(core->reset))\n\t\t\tdev_warn(core->dev, \"local-reset assert back failed\\n\");\n\t}\n\tcore = list_first_entry(&cluster->cores, struct k3_r5_core, elem);\nunroll_module_reset:\n\tlist_for_each_entry_from(core, &cluster->cores, elem) {\n\t\tif (core->ti_sci->ops.dev_ops.put_device(core->ti_sci,\n\t\t\t\t\t\t\t core->ti_sci_id))\n\t\t\tdev_warn(core->dev, \"module-reset assert back failed\\n\");\n\t}\n\n\treturn ret;\n}\n\nstatic inline int k3_r5_core_halt(struct k3_r5_core *core)\n{\n\treturn ti_sci_proc_set_control(core->tsp,\n\t\t\t\t       PROC_BOOT_CTRL_FLAG_R5_CORE_HALT, 0);\n}\n\nstatic inline int k3_r5_core_run(struct k3_r5_core *core)\n{\n\treturn ti_sci_proc_set_control(core->tsp,\n\t\t\t\t       0, PROC_BOOT_CTRL_FLAG_R5_CORE_HALT);\n}\n\nstatic int k3_r5_rproc_request_mbox(struct rproc *rproc)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct mbox_client *client = &kproc->client;\n\tstruct device *dev = kproc->dev;\n\tint ret;\n\n\tclient->dev = dev;\n\tclient->tx_done = NULL;\n\tclient->rx_callback = k3_r5_rproc_mbox_callback;\n\tclient->tx_block = false;\n\tclient->knows_txdone = false;\n\n\tkproc->mbox = mbox_request_channel(client, 0);\n\tif (IS_ERR(kproc->mbox)) {\n\t\tret = -EBUSY;\n\t\tdev_err(dev, \"mbox_request_channel failed: %ld\\n\",\n\t\t\tPTR_ERR(kproc->mbox));\n\t\treturn ret;\n\t}\n\n\t \n\tret = mbox_send_message(kproc->mbox, (void *)RP_MBOX_ECHO_REQUEST);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"mbox_send_message failed: %d\\n\", ret);\n\t\tmbox_free_channel(kproc->mbox);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int k3_r5_rproc_prepare(struct rproc *rproc)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct k3_r5_cluster *cluster = kproc->cluster;\n\tstruct k3_r5_core *core = kproc->core;\n\tstruct device *dev = kproc->dev;\n\tu32 ctrl = 0, cfg = 0, stat = 0;\n\tu64 boot_vec = 0;\n\tbool mem_init_dis;\n\tint ret;\n\n\tret = ti_sci_proc_get_status(core->tsp, &boot_vec, &cfg, &ctrl, &stat);\n\tif (ret < 0)\n\t\treturn ret;\n\tmem_init_dis = !!(cfg & PROC_BOOT_CFG_FLAG_R5_MEM_INIT_DIS);\n\n\t \n\tret = (cluster->mode == CLUSTER_MODE_LOCKSTEP ||\n\t       cluster->mode == CLUSTER_MODE_SINGLECPU) ?\n\t\tk3_r5_lockstep_release(cluster) : k3_r5_split_release(core);\n\tif (ret) {\n\t\tdev_err(dev, \"unable to enable cores for TCM loading, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\t \n\tif (cluster->soc_data->tcm_ecc_autoinit && !mem_init_dis) {\n\t\tdev_dbg(dev, \"leveraging h/w init for TCM memories\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tdev_dbg(dev, \"zeroing out ATCM memory\\n\");\n\tmemset(core->mem[0].cpu_addr, 0x00, core->mem[0].size);\n\n\tdev_dbg(dev, \"zeroing out BTCM memory\\n\");\n\tmemset(core->mem[1].cpu_addr, 0x00, core->mem[1].size);\n\n\treturn 0;\n}\n\n \nstatic int k3_r5_rproc_unprepare(struct rproc *rproc)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct k3_r5_cluster *cluster = kproc->cluster;\n\tstruct k3_r5_core *core = kproc->core;\n\tstruct device *dev = kproc->dev;\n\tint ret;\n\n\t \n\tret = (cluster->mode == CLUSTER_MODE_LOCKSTEP ||\n\t       cluster->mode == CLUSTER_MODE_SINGLECPU) ?\n\t\tk3_r5_lockstep_reset(cluster) : k3_r5_split_reset(core);\n\tif (ret)\n\t\tdev_err(dev, \"unable to disable cores, ret = %d\\n\", ret);\n\n\treturn ret;\n}\n\n \nstatic int k3_r5_rproc_start(struct rproc *rproc)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct k3_r5_cluster *cluster = kproc->cluster;\n\tstruct device *dev = kproc->dev;\n\tstruct k3_r5_core *core;\n\tu32 boot_addr;\n\tint ret;\n\n\tret = k3_r5_rproc_request_mbox(rproc);\n\tif (ret)\n\t\treturn ret;\n\n\tboot_addr = rproc->bootaddr;\n\t \n\tdev_dbg(dev, \"booting R5F core using boot addr = 0x%x\\n\", boot_addr);\n\n\t \n\tcore = kproc->core;\n\tret = ti_sci_proc_set_config(core->tsp, boot_addr, 0, 0);\n\tif (ret)\n\t\tgoto put_mbox;\n\n\t \n\tif (cluster->mode == CLUSTER_MODE_LOCKSTEP) {\n\t\tlist_for_each_entry_reverse(core, &cluster->cores, elem) {\n\t\t\tret = k3_r5_core_run(core);\n\t\t\tif (ret)\n\t\t\t\tgoto unroll_core_run;\n\t\t}\n\t} else {\n\t\tret = k3_r5_core_run(core);\n\t\tif (ret)\n\t\t\tgoto put_mbox;\n\t}\n\n\treturn 0;\n\nunroll_core_run:\n\tlist_for_each_entry_continue(core, &cluster->cores, elem) {\n\t\tif (k3_r5_core_halt(core))\n\t\t\tdev_warn(core->dev, \"core halt back failed\\n\");\n\t}\nput_mbox:\n\tmbox_free_channel(kproc->mbox);\n\treturn ret;\n}\n\n \nstatic int k3_r5_rproc_stop(struct rproc *rproc)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct k3_r5_cluster *cluster = kproc->cluster;\n\tstruct k3_r5_core *core = kproc->core;\n\tint ret;\n\n\t \n\tif (cluster->mode == CLUSTER_MODE_LOCKSTEP) {\n\t\tlist_for_each_entry(core, &cluster->cores, elem) {\n\t\t\tret = k3_r5_core_halt(core);\n\t\t\tif (ret) {\n\t\t\t\tcore = list_prev_entry(core, elem);\n\t\t\t\tgoto unroll_core_halt;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tret = k3_r5_core_halt(core);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tmbox_free_channel(kproc->mbox);\n\n\treturn 0;\n\nunroll_core_halt:\n\tlist_for_each_entry_from_reverse(core, &cluster->cores, elem) {\n\t\tif (k3_r5_core_run(core))\n\t\t\tdev_warn(core->dev, \"core run back failed\\n\");\n\t}\nout:\n\treturn ret;\n}\n\n \nstatic int k3_r5_rproc_attach(struct rproc *rproc)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct device *dev = kproc->dev;\n\tint ret;\n\n\tret = k3_r5_rproc_request_mbox(rproc);\n\tif (ret)\n\t\treturn ret;\n\n\tdev_info(dev, \"R5F core initialized in IPC-only mode\\n\");\n\treturn 0;\n}\n\n \nstatic int k3_r5_rproc_detach(struct rproc *rproc)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct device *dev = kproc->dev;\n\n\tmbox_free_channel(kproc->mbox);\n\tdev_info(dev, \"R5F core deinitialized in IPC-only mode\\n\");\n\treturn 0;\n}\n\n \nstatic struct resource_table *k3_r5_get_loaded_rsc_table(struct rproc *rproc,\n\t\t\t\t\t\t\t size_t *rsc_table_sz)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct device *dev = kproc->dev;\n\n\tif (!kproc->rmem[0].cpu_addr) {\n\t\tdev_err(dev, \"memory-region #1 does not exist, loaded rsc table can't be found\");\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\t \n\t*rsc_table_sz = 256;\n\treturn (struct resource_table *)kproc->rmem[0].cpu_addr;\n}\n\n \nstatic void *k3_r5_rproc_da_to_va(struct rproc *rproc, u64 da, size_t len, bool *is_iomem)\n{\n\tstruct k3_r5_rproc *kproc = rproc->priv;\n\tstruct k3_r5_core *core = kproc->core;\n\tvoid __iomem *va = NULL;\n\tphys_addr_t bus_addr;\n\tu32 dev_addr, offset;\n\tsize_t size;\n\tint i;\n\n\tif (len == 0)\n\t\treturn NULL;\n\n\t \n\tfor (i = 0; i < core->num_mems; i++) {\n\t\tbus_addr = core->mem[i].bus_addr;\n\t\tdev_addr = core->mem[i].dev_addr;\n\t\tsize = core->mem[i].size;\n\n\t\t \n\t\tif (da >= dev_addr && ((da + len) <= (dev_addr + size))) {\n\t\t\toffset = da - dev_addr;\n\t\t\tva = core->mem[i].cpu_addr + offset;\n\t\t\treturn (__force void *)va;\n\t\t}\n\n\t\t \n\t\tif (da >= bus_addr && ((da + len) <= (bus_addr + size))) {\n\t\t\toffset = da - bus_addr;\n\t\t\tva = core->mem[i].cpu_addr + offset;\n\t\t\treturn (__force void *)va;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < core->num_sram; i++) {\n\t\tdev_addr = core->sram[i].dev_addr;\n\t\tsize = core->sram[i].size;\n\n\t\tif (da >= dev_addr && ((da + len) <= (dev_addr + size))) {\n\t\t\toffset = da - dev_addr;\n\t\t\tva = core->sram[i].cpu_addr + offset;\n\t\t\treturn (__force void *)va;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < kproc->num_rmems; i++) {\n\t\tdev_addr = kproc->rmem[i].dev_addr;\n\t\tsize = kproc->rmem[i].size;\n\n\t\tif (da >= dev_addr && ((da + len) <= (dev_addr + size))) {\n\t\t\toffset = da - dev_addr;\n\t\t\tva = kproc->rmem[i].cpu_addr + offset;\n\t\t\treturn (__force void *)va;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nstatic const struct rproc_ops k3_r5_rproc_ops = {\n\t.prepare\t= k3_r5_rproc_prepare,\n\t.unprepare\t= k3_r5_rproc_unprepare,\n\t.start\t\t= k3_r5_rproc_start,\n\t.stop\t\t= k3_r5_rproc_stop,\n\t.kick\t\t= k3_r5_rproc_kick,\n\t.da_to_va\t= k3_r5_rproc_da_to_va,\n};\n\n \nstatic int k3_r5_rproc_configure(struct k3_r5_rproc *kproc)\n{\n\tstruct k3_r5_cluster *cluster = kproc->cluster;\n\tstruct device *dev = kproc->dev;\n\tstruct k3_r5_core *core0, *core, *temp;\n\tu32 ctrl = 0, cfg = 0, stat = 0;\n\tu32 set_cfg = 0, clr_cfg = 0;\n\tu64 boot_vec = 0;\n\tbool lockstep_en;\n\tbool single_cpu;\n\tint ret;\n\n\tcore0 = list_first_entry(&cluster->cores, struct k3_r5_core, elem);\n\tif (cluster->mode == CLUSTER_MODE_LOCKSTEP ||\n\t    cluster->mode == CLUSTER_MODE_SINGLECPU ||\n\t    cluster->mode == CLUSTER_MODE_SINGLECORE) {\n\t\tcore = core0;\n\t} else {\n\t\tcore = kproc->core;\n\t}\n\n\tret = ti_sci_proc_get_status(core->tsp, &boot_vec, &cfg, &ctrl,\n\t\t\t\t     &stat);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tdev_dbg(dev, \"boot_vector = 0x%llx, cfg = 0x%x ctrl = 0x%x stat = 0x%x\\n\",\n\t\tboot_vec, cfg, ctrl, stat);\n\n\tsingle_cpu = !!(stat & PROC_BOOT_STATUS_FLAG_R5_SINGLECORE_ONLY);\n\tlockstep_en = !!(stat & PROC_BOOT_STATUS_FLAG_R5_LOCKSTEP_PERMITTED);\n\n\t \n\tif (single_cpu && cluster->mode == CLUSTER_MODE_SPLIT) {\n\t\tdev_err(cluster->dev, \"split-mode not permitted, force configuring for single-cpu mode\\n\");\n\t\tcluster->mode = CLUSTER_MODE_SINGLECPU;\n\t}\n\n\t \n\tif (!lockstep_en && cluster->mode == CLUSTER_MODE_LOCKSTEP) {\n\t\tdev_err(cluster->dev, \"lockstep mode not permitted, force configuring for split-mode\\n\");\n\t\tcluster->mode = CLUSTER_MODE_SPLIT;\n\t}\n\n\t \n\tboot_vec = 0x0;\n\tif (core == core0) {\n\t\tclr_cfg = PROC_BOOT_CFG_FLAG_R5_TEINIT;\n\t\t \n\t\tif (cluster->mode == CLUSTER_MODE_SINGLECPU ||\n\t\t    cluster->mode == CLUSTER_MODE_SINGLECORE) {\n\t\t\tset_cfg = PROC_BOOT_CFG_FLAG_R5_SINGLE_CORE;\n\t\t} else {\n\t\t\t \n\t\t\tif (lockstep_en)\n\t\t\t\tclr_cfg |= PROC_BOOT_CFG_FLAG_R5_LOCKSTEP;\n\t\t}\n\t}\n\n\tif (core->atcm_enable)\n\t\tset_cfg |= PROC_BOOT_CFG_FLAG_R5_ATCM_EN;\n\telse\n\t\tclr_cfg |= PROC_BOOT_CFG_FLAG_R5_ATCM_EN;\n\n\tif (core->btcm_enable)\n\t\tset_cfg |= PROC_BOOT_CFG_FLAG_R5_BTCM_EN;\n\telse\n\t\tclr_cfg |= PROC_BOOT_CFG_FLAG_R5_BTCM_EN;\n\n\tif (core->loczrama)\n\t\tset_cfg |= PROC_BOOT_CFG_FLAG_R5_TCM_RSTBASE;\n\telse\n\t\tclr_cfg |= PROC_BOOT_CFG_FLAG_R5_TCM_RSTBASE;\n\n\tif (cluster->mode == CLUSTER_MODE_LOCKSTEP) {\n\t\t \n\t\tlist_for_each_entry(temp, &cluster->cores, elem) {\n\t\t\tret = k3_r5_core_halt(temp);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\n\t\t\tif (temp != core) {\n\t\t\t\tclr_cfg &= ~PROC_BOOT_CFG_FLAG_R5_LOCKSTEP;\n\t\t\t\tclr_cfg &= ~PROC_BOOT_CFG_FLAG_R5_TEINIT;\n\t\t\t}\n\t\t\tret = ti_sci_proc_set_config(temp->tsp, boot_vec,\n\t\t\t\t\t\t     set_cfg, clr_cfg);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\t\t}\n\n\t\tset_cfg = PROC_BOOT_CFG_FLAG_R5_LOCKSTEP;\n\t\tclr_cfg = 0;\n\t\tret = ti_sci_proc_set_config(core->tsp, boot_vec,\n\t\t\t\t\t     set_cfg, clr_cfg);\n\t} else {\n\t\tret = k3_r5_core_halt(core);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tret = ti_sci_proc_set_config(core->tsp, boot_vec,\n\t\t\t\t\t     set_cfg, clr_cfg);\n\t}\n\nout:\n\treturn ret;\n}\n\nstatic int k3_r5_reserved_mem_init(struct k3_r5_rproc *kproc)\n{\n\tstruct device *dev = kproc->dev;\n\tstruct device_node *np = dev_of_node(dev);\n\tstruct device_node *rmem_np;\n\tstruct reserved_mem *rmem;\n\tint num_rmems;\n\tint ret, i;\n\n\tnum_rmems = of_property_count_elems_of_size(np, \"memory-region\",\n\t\t\t\t\t\t    sizeof(phandle));\n\tif (num_rmems <= 0) {\n\t\tdev_err(dev, \"device does not have reserved memory regions, ret = %d\\n\",\n\t\t\tnum_rmems);\n\t\treturn -EINVAL;\n\t}\n\tif (num_rmems < 2) {\n\t\tdev_err(dev, \"device needs at least two memory regions to be defined, num = %d\\n\",\n\t\t\tnum_rmems);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tret = of_reserved_mem_device_init_by_idx(dev, np, 0);\n\tif (ret) {\n\t\tdev_err(dev, \"device cannot initialize DMA pool, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tnum_rmems--;\n\tkproc->rmem = kcalloc(num_rmems, sizeof(*kproc->rmem), GFP_KERNEL);\n\tif (!kproc->rmem) {\n\t\tret = -ENOMEM;\n\t\tgoto release_rmem;\n\t}\n\n\t \n\tfor (i = 0; i < num_rmems; i++) {\n\t\trmem_np = of_parse_phandle(np, \"memory-region\", i + 1);\n\t\tif (!rmem_np) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto unmap_rmem;\n\t\t}\n\n\t\trmem = of_reserved_mem_lookup(rmem_np);\n\t\tif (!rmem) {\n\t\t\tof_node_put(rmem_np);\n\t\t\tret = -EINVAL;\n\t\t\tgoto unmap_rmem;\n\t\t}\n\t\tof_node_put(rmem_np);\n\n\t\tkproc->rmem[i].bus_addr = rmem->base;\n\t\t \n\t\tkproc->rmem[i].dev_addr = (u32)rmem->base;\n\t\tkproc->rmem[i].size = rmem->size;\n\t\tkproc->rmem[i].cpu_addr = ioremap_wc(rmem->base, rmem->size);\n\t\tif (!kproc->rmem[i].cpu_addr) {\n\t\t\tdev_err(dev, \"failed to map reserved memory#%d at %pa of size %pa\\n\",\n\t\t\t\ti + 1, &rmem->base, &rmem->size);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto unmap_rmem;\n\t\t}\n\n\t\tdev_dbg(dev, \"reserved memory%d: bus addr %pa size 0x%zx va %pK da 0x%x\\n\",\n\t\t\ti + 1, &kproc->rmem[i].bus_addr,\n\t\t\tkproc->rmem[i].size, kproc->rmem[i].cpu_addr,\n\t\t\tkproc->rmem[i].dev_addr);\n\t}\n\tkproc->num_rmems = num_rmems;\n\n\treturn 0;\n\nunmap_rmem:\n\tfor (i--; i >= 0; i--)\n\t\tiounmap(kproc->rmem[i].cpu_addr);\n\tkfree(kproc->rmem);\nrelease_rmem:\n\tof_reserved_mem_device_release(dev);\n\treturn ret;\n}\n\nstatic void k3_r5_reserved_mem_exit(struct k3_r5_rproc *kproc)\n{\n\tint i;\n\n\tfor (i = 0; i < kproc->num_rmems; i++)\n\t\tiounmap(kproc->rmem[i].cpu_addr);\n\tkfree(kproc->rmem);\n\n\tof_reserved_mem_device_release(kproc->dev);\n}\n\n \nstatic void k3_r5_adjust_tcm_sizes(struct k3_r5_rproc *kproc)\n{\n\tstruct k3_r5_cluster *cluster = kproc->cluster;\n\tstruct k3_r5_core *core = kproc->core;\n\tstruct device *cdev = core->dev;\n\tstruct k3_r5_core *core0;\n\n\tif (cluster->mode == CLUSTER_MODE_LOCKSTEP ||\n\t    cluster->mode == CLUSTER_MODE_SINGLECPU ||\n\t    cluster->mode == CLUSTER_MODE_SINGLECORE ||\n\t    !cluster->soc_data->tcm_is_double)\n\t\treturn;\n\n\tcore0 = list_first_entry(&cluster->cores, struct k3_r5_core, elem);\n\tif (core == core0) {\n\t\tWARN_ON(core->mem[0].size != SZ_64K);\n\t\tWARN_ON(core->mem[1].size != SZ_64K);\n\n\t\tcore->mem[0].size /= 2;\n\t\tcore->mem[1].size /= 2;\n\n\t\tdev_dbg(cdev, \"adjusted TCM sizes, ATCM = 0x%zx BTCM = 0x%zx\\n\",\n\t\t\tcore->mem[0].size, core->mem[1].size);\n\t}\n}\n\n \nstatic int k3_r5_rproc_configure_mode(struct k3_r5_rproc *kproc)\n{\n\tstruct k3_r5_cluster *cluster = kproc->cluster;\n\tstruct k3_r5_core *core = kproc->core;\n\tstruct device *cdev = core->dev;\n\tbool r_state = false, c_state = false, lockstep_en = false, single_cpu = false;\n\tu32 ctrl = 0, cfg = 0, stat = 0, halted = 0;\n\tu64 boot_vec = 0;\n\tu32 atcm_enable, btcm_enable, loczrama;\n\tstruct k3_r5_core *core0;\n\tenum cluster_mode mode = cluster->mode;\n\tint ret;\n\n\tcore0 = list_first_entry(&cluster->cores, struct k3_r5_core, elem);\n\n\tret = core->ti_sci->ops.dev_ops.is_on(core->ti_sci, core->ti_sci_id,\n\t\t\t\t\t      &r_state, &c_state);\n\tif (ret) {\n\t\tdev_err(cdev, \"failed to get initial state, mode cannot be determined, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\tif (r_state != c_state) {\n\t\tdev_warn(cdev, \"R5F core may have been powered on by a different host, programmed state (%d) != actual state (%d)\\n\",\n\t\t\t r_state, c_state);\n\t}\n\n\tret = reset_control_status(core->reset);\n\tif (ret < 0) {\n\t\tdev_err(cdev, \"failed to get initial local reset status, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tret = ti_sci_proc_get_status(core->tsp, &boot_vec, &cfg, &ctrl,\n\t\t\t\t     &stat);\n\tif (ret < 0) {\n\t\tdev_err(cdev, \"failed to get initial processor status, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\tatcm_enable = cfg & PROC_BOOT_CFG_FLAG_R5_ATCM_EN ?  1 : 0;\n\tbtcm_enable = cfg & PROC_BOOT_CFG_FLAG_R5_BTCM_EN ?  1 : 0;\n\tloczrama = cfg & PROC_BOOT_CFG_FLAG_R5_TCM_RSTBASE ?  1 : 0;\n\tsingle_cpu = cfg & PROC_BOOT_CFG_FLAG_R5_SINGLE_CORE ? 1 : 0;\n\tlockstep_en = cfg & PROC_BOOT_CFG_FLAG_R5_LOCKSTEP ? 1 : 0;\n\n\tif (single_cpu && mode != CLUSTER_MODE_SINGLECORE)\n\t\tmode = CLUSTER_MODE_SINGLECPU;\n\tif (lockstep_en)\n\t\tmode = CLUSTER_MODE_LOCKSTEP;\n\n\thalted = ctrl & PROC_BOOT_CTRL_FLAG_R5_CORE_HALT;\n\n\t \n\tif (c_state && !ret && !halted) {\n\t\tdev_info(cdev, \"configured R5F for IPC-only mode\\n\");\n\t\tkproc->rproc->state = RPROC_DETACHED;\n\t\tret = 1;\n\t\t \n\t\tkproc->rproc->ops->prepare = NULL;\n\t\tkproc->rproc->ops->unprepare = NULL;\n\t\tkproc->rproc->ops->start = NULL;\n\t\tkproc->rproc->ops->stop = NULL;\n\t\tkproc->rproc->ops->attach = k3_r5_rproc_attach;\n\t\tkproc->rproc->ops->detach = k3_r5_rproc_detach;\n\t\tkproc->rproc->ops->get_loaded_rsc_table =\n\t\t\t\t\t\tk3_r5_get_loaded_rsc_table;\n\t} else if (!c_state) {\n\t\tdev_info(cdev, \"configured R5F for remoteproc mode\\n\");\n\t\tret = 0;\n\t} else {\n\t\tdev_err(cdev, \"mismatched mode: local_reset = %s, module_reset = %s, core_state = %s\\n\",\n\t\t\t!ret ? \"deasserted\" : \"asserted\",\n\t\t\tc_state ? \"deasserted\" : \"asserted\",\n\t\t\thalted ? \"halted\" : \"unhalted\");\n\t\tret = -EINVAL;\n\t}\n\n\t \n\tif (ret > 0) {\n\t\tif (core == core0)\n\t\t\tcluster->mode = mode;\n\t\tcore->atcm_enable = atcm_enable;\n\t\tcore->btcm_enable = btcm_enable;\n\t\tcore->loczrama = loczrama;\n\t\tcore->mem[0].dev_addr = loczrama ? 0 : K3_R5_TCM_DEV_ADDR;\n\t\tcore->mem[1].dev_addr = loczrama ? K3_R5_TCM_DEV_ADDR : 0;\n\t}\n\n\treturn ret;\n}\n\nstatic int k3_r5_cluster_rproc_init(struct platform_device *pdev)\n{\n\tstruct k3_r5_cluster *cluster = platform_get_drvdata(pdev);\n\tstruct device *dev = &pdev->dev;\n\tstruct k3_r5_rproc *kproc;\n\tstruct k3_r5_core *core, *core1;\n\tstruct device *cdev;\n\tconst char *fw_name;\n\tstruct rproc *rproc;\n\tint ret, ret1;\n\n\tcore1 = list_last_entry(&cluster->cores, struct k3_r5_core, elem);\n\tlist_for_each_entry(core, &cluster->cores, elem) {\n\t\tcdev = core->dev;\n\t\tret = rproc_of_parse_firmware(cdev, 0, &fw_name);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"failed to parse firmware-name property, ret = %d\\n\",\n\t\t\t\tret);\n\t\t\tgoto out;\n\t\t}\n\n\t\trproc = rproc_alloc(cdev, dev_name(cdev), &k3_r5_rproc_ops,\n\t\t\t\t    fw_name, sizeof(*kproc));\n\t\tif (!rproc) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\trproc->has_iommu = false;\n\t\t \n\t\trproc->recovery_disabled = true;\n\n\t\tkproc = rproc->priv;\n\t\tkproc->cluster = cluster;\n\t\tkproc->core = core;\n\t\tkproc->dev = cdev;\n\t\tkproc->rproc = rproc;\n\t\tcore->rproc = rproc;\n\n\t\tret = k3_r5_rproc_configure_mode(kproc);\n\t\tif (ret < 0)\n\t\t\tgoto err_config;\n\t\tif (ret)\n\t\t\tgoto init_rmem;\n\n\t\tret = k3_r5_rproc_configure(kproc);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"initial configure failed, ret = %d\\n\",\n\t\t\t\tret);\n\t\t\tgoto err_config;\n\t\t}\n\ninit_rmem:\n\t\tk3_r5_adjust_tcm_sizes(kproc);\n\n\t\tret = k3_r5_reserved_mem_init(kproc);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"reserved memory init failed, ret = %d\\n\",\n\t\t\t\tret);\n\t\t\tgoto err_config;\n\t\t}\n\n\t\tret = rproc_add(rproc);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"rproc_add failed, ret = %d\\n\", ret);\n\t\t\tgoto err_add;\n\t\t}\n\n\t\t \n\t\tif (cluster->mode == CLUSTER_MODE_LOCKSTEP ||\n\t\t    cluster->mode == CLUSTER_MODE_SINGLECPU ||\n\t\t    cluster->mode == CLUSTER_MODE_SINGLECORE)\n\t\t\tbreak;\n\t}\n\n\treturn 0;\n\nerr_split:\n\tif (rproc->state == RPROC_ATTACHED) {\n\t\tret1 = rproc_detach(rproc);\n\t\tif (ret1) {\n\t\t\tdev_err(kproc->dev, \"failed to detach rproc, ret = %d\\n\",\n\t\t\t\tret1);\n\t\t\treturn ret1;\n\t\t}\n\t}\n\n\trproc_del(rproc);\nerr_add:\n\tk3_r5_reserved_mem_exit(kproc);\nerr_config:\n\trproc_free(rproc);\n\tcore->rproc = NULL;\nout:\n\t \n\tif (cluster->mode == CLUSTER_MODE_SPLIT && core == core1) {\n\t\tcore = list_prev_entry(core, elem);\n\t\trproc = core->rproc;\n\t\tkproc = rproc->priv;\n\t\tgoto err_split;\n\t}\n\treturn ret;\n}\n\nstatic void k3_r5_cluster_rproc_exit(void *data)\n{\n\tstruct k3_r5_cluster *cluster = platform_get_drvdata(data);\n\tstruct k3_r5_rproc *kproc;\n\tstruct k3_r5_core *core;\n\tstruct rproc *rproc;\n\tint ret;\n\n\t \n\tcore = (cluster->mode == CLUSTER_MODE_LOCKSTEP ||\n\t\tcluster->mode == CLUSTER_MODE_SINGLECPU) ?\n\t\tlist_first_entry(&cluster->cores, struct k3_r5_core, elem) :\n\t\tlist_last_entry(&cluster->cores, struct k3_r5_core, elem);\n\n\tlist_for_each_entry_from_reverse(core, &cluster->cores, elem) {\n\t\trproc = core->rproc;\n\t\tkproc = rproc->priv;\n\n\t\tif (rproc->state == RPROC_ATTACHED) {\n\t\t\tret = rproc_detach(rproc);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(kproc->dev, \"failed to detach rproc, ret = %d\\n\", ret);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\trproc_del(rproc);\n\n\t\tk3_r5_reserved_mem_exit(kproc);\n\n\t\trproc_free(rproc);\n\t\tcore->rproc = NULL;\n\t}\n}\n\nstatic int k3_r5_core_of_get_internal_memories(struct platform_device *pdev,\n\t\t\t\t\t       struct k3_r5_core *core)\n{\n\tstatic const char * const mem_names[] = {\"atcm\", \"btcm\"};\n\tstruct device *dev = &pdev->dev;\n\tstruct resource *res;\n\tint num_mems;\n\tint i;\n\n\tnum_mems = ARRAY_SIZE(mem_names);\n\tcore->mem = devm_kcalloc(dev, num_mems, sizeof(*core->mem), GFP_KERNEL);\n\tif (!core->mem)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < num_mems; i++) {\n\t\tres = platform_get_resource_byname(pdev, IORESOURCE_MEM,\n\t\t\t\t\t\t   mem_names[i]);\n\t\tif (!res) {\n\t\t\tdev_err(dev, \"found no memory resource for %s\\n\",\n\t\t\t\tmem_names[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!devm_request_mem_region(dev, res->start,\n\t\t\t\t\t     resource_size(res),\n\t\t\t\t\t     dev_name(dev))) {\n\t\t\tdev_err(dev, \"could not request %s region for resource\\n\",\n\t\t\t\tmem_names[i]);\n\t\t\treturn -EBUSY;\n\t\t}\n\n\t\t \n\t\tcore->mem[i].cpu_addr = devm_ioremap_wc(dev, res->start,\n\t\t\t\t\t\t\tresource_size(res));\n\t\tif (!core->mem[i].cpu_addr) {\n\t\t\tdev_err(dev, \"failed to map %s memory\\n\", mem_names[i]);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tcore->mem[i].bus_addr = res->start;\n\n\t\t \n\t\tif (!strcmp(mem_names[i], \"atcm\")) {\n\t\t\tcore->mem[i].dev_addr = core->loczrama ?\n\t\t\t\t\t\t\t0 : K3_R5_TCM_DEV_ADDR;\n\t\t} else {\n\t\t\tcore->mem[i].dev_addr = core->loczrama ?\n\t\t\t\t\t\t\tK3_R5_TCM_DEV_ADDR : 0;\n\t\t}\n\t\tcore->mem[i].size = resource_size(res);\n\n\t\tdev_dbg(dev, \"memory %5s: bus addr %pa size 0x%zx va %pK da 0x%x\\n\",\n\t\t\tmem_names[i], &core->mem[i].bus_addr,\n\t\t\tcore->mem[i].size, core->mem[i].cpu_addr,\n\t\t\tcore->mem[i].dev_addr);\n\t}\n\tcore->num_mems = num_mems;\n\n\treturn 0;\n}\n\nstatic int k3_r5_core_of_get_sram_memories(struct platform_device *pdev,\n\t\t\t\t\t   struct k3_r5_core *core)\n{\n\tstruct device_node *np = pdev->dev.of_node;\n\tstruct device *dev = &pdev->dev;\n\tstruct device_node *sram_np;\n\tstruct resource res;\n\tint num_sram;\n\tint i, ret;\n\n\tnum_sram = of_property_count_elems_of_size(np, \"sram\", sizeof(phandle));\n\tif (num_sram <= 0) {\n\t\tdev_dbg(dev, \"device does not use reserved on-chip memories, num_sram = %d\\n\",\n\t\t\tnum_sram);\n\t\treturn 0;\n\t}\n\n\tcore->sram = devm_kcalloc(dev, num_sram, sizeof(*core->sram), GFP_KERNEL);\n\tif (!core->sram)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < num_sram; i++) {\n\t\tsram_np = of_parse_phandle(np, \"sram\", i);\n\t\tif (!sram_np)\n\t\t\treturn -EINVAL;\n\n\t\tif (!of_device_is_available(sram_np)) {\n\t\t\tof_node_put(sram_np);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tret = of_address_to_resource(sram_np, 0, &res);\n\t\tof_node_put(sram_np);\n\t\tif (ret)\n\t\t\treturn -EINVAL;\n\n\t\tcore->sram[i].bus_addr = res.start;\n\t\tcore->sram[i].dev_addr = res.start;\n\t\tcore->sram[i].size = resource_size(&res);\n\t\tcore->sram[i].cpu_addr = devm_ioremap_wc(dev, res.start,\n\t\t\t\t\t\t\t resource_size(&res));\n\t\tif (!core->sram[i].cpu_addr) {\n\t\t\tdev_err(dev, \"failed to parse and map sram%d memory at %pad\\n\",\n\t\t\t\ti, &res.start);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tdev_dbg(dev, \"memory sram%d: bus addr %pa size 0x%zx va %pK da 0x%x\\n\",\n\t\t\ti, &core->sram[i].bus_addr,\n\t\t\tcore->sram[i].size, core->sram[i].cpu_addr,\n\t\t\tcore->sram[i].dev_addr);\n\t}\n\tcore->num_sram = num_sram;\n\n\treturn 0;\n}\n\nstatic\nstruct ti_sci_proc *k3_r5_core_of_get_tsp(struct device *dev,\n\t\t\t\t\t  const struct ti_sci_handle *sci)\n{\n\tstruct ti_sci_proc *tsp;\n\tu32 temp[2];\n\tint ret;\n\n\tret = of_property_read_u32_array(dev_of_node(dev), \"ti,sci-proc-ids\",\n\t\t\t\t\t temp, 2);\n\tif (ret < 0)\n\t\treturn ERR_PTR(ret);\n\n\ttsp = devm_kzalloc(dev, sizeof(*tsp), GFP_KERNEL);\n\tif (!tsp)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\ttsp->dev = dev;\n\ttsp->sci = sci;\n\ttsp->ops = &sci->ops.proc_ops;\n\ttsp->proc_id = temp[0];\n\ttsp->host_id = temp[1];\n\n\treturn tsp;\n}\n\nstatic int k3_r5_core_of_init(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct device_node *np = dev_of_node(dev);\n\tstruct k3_r5_core *core;\n\tint ret;\n\n\tif (!devres_open_group(dev, k3_r5_core_of_init, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\tcore = devm_kzalloc(dev, sizeof(*core), GFP_KERNEL);\n\tif (!core) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tcore->dev = dev;\n\t \n\tcore->atcm_enable = 0;\n\tcore->btcm_enable = 1;\n\tcore->loczrama = 1;\n\n\tret = of_property_read_u32(np, \"ti,atcm-enable\", &core->atcm_enable);\n\tif (ret < 0 && ret != -EINVAL) {\n\t\tdev_err(dev, \"invalid format for ti,atcm-enable, ret = %d\\n\",\n\t\t\tret);\n\t\tgoto err;\n\t}\n\n\tret = of_property_read_u32(np, \"ti,btcm-enable\", &core->btcm_enable);\n\tif (ret < 0 && ret != -EINVAL) {\n\t\tdev_err(dev, \"invalid format for ti,btcm-enable, ret = %d\\n\",\n\t\t\tret);\n\t\tgoto err;\n\t}\n\n\tret = of_property_read_u32(np, \"ti,loczrama\", &core->loczrama);\n\tif (ret < 0 && ret != -EINVAL) {\n\t\tdev_err(dev, \"invalid format for ti,loczrama, ret = %d\\n\", ret);\n\t\tgoto err;\n\t}\n\n\tcore->ti_sci = devm_ti_sci_get_by_phandle(dev, \"ti,sci\");\n\tif (IS_ERR(core->ti_sci)) {\n\t\tret = PTR_ERR(core->ti_sci);\n\t\tif (ret != -EPROBE_DEFER) {\n\t\t\tdev_err(dev, \"failed to get ti-sci handle, ret = %d\\n\",\n\t\t\t\tret);\n\t\t}\n\t\tcore->ti_sci = NULL;\n\t\tgoto err;\n\t}\n\n\tret = of_property_read_u32(np, \"ti,sci-dev-id\", &core->ti_sci_id);\n\tif (ret) {\n\t\tdev_err(dev, \"missing 'ti,sci-dev-id' property\\n\");\n\t\tgoto err;\n\t}\n\n\tcore->reset = devm_reset_control_get_exclusive(dev, NULL);\n\tif (IS_ERR_OR_NULL(core->reset)) {\n\t\tret = PTR_ERR_OR_ZERO(core->reset);\n\t\tif (!ret)\n\t\t\tret = -ENODEV;\n\t\tif (ret != -EPROBE_DEFER) {\n\t\t\tdev_err(dev, \"failed to get reset handle, ret = %d\\n\",\n\t\t\t\tret);\n\t\t}\n\t\tgoto err;\n\t}\n\n\tcore->tsp = k3_r5_core_of_get_tsp(dev, core->ti_sci);\n\tif (IS_ERR(core->tsp)) {\n\t\tret = PTR_ERR(core->tsp);\n\t\tdev_err(dev, \"failed to construct ti-sci proc control, ret = %d\\n\",\n\t\t\tret);\n\t\tgoto err;\n\t}\n\n\tret = k3_r5_core_of_get_internal_memories(pdev, core);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to get internal memories, ret = %d\\n\",\n\t\t\tret);\n\t\tgoto err;\n\t}\n\n\tret = k3_r5_core_of_get_sram_memories(pdev, core);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to get sram memories, ret = %d\\n\", ret);\n\t\tgoto err;\n\t}\n\n\tret = ti_sci_proc_request(core->tsp);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"ti_sci_proc_request failed, ret = %d\\n\", ret);\n\t\tgoto err;\n\t}\n\n\tplatform_set_drvdata(pdev, core);\n\tdevres_close_group(dev, k3_r5_core_of_init);\n\n\treturn 0;\n\nerr:\n\tdevres_release_group(dev, k3_r5_core_of_init);\n\treturn ret;\n}\n\n \nstatic void k3_r5_core_of_exit(struct platform_device *pdev)\n{\n\tstruct k3_r5_core *core = platform_get_drvdata(pdev);\n\tstruct device *dev = &pdev->dev;\n\tint ret;\n\n\tret = ti_sci_proc_release(core->tsp);\n\tif (ret)\n\t\tdev_err(dev, \"failed to release proc, ret = %d\\n\", ret);\n\n\tplatform_set_drvdata(pdev, NULL);\n\tdevres_release_group(dev, k3_r5_core_of_init);\n}\n\nstatic void k3_r5_cluster_of_exit(void *data)\n{\n\tstruct k3_r5_cluster *cluster = platform_get_drvdata(data);\n\tstruct platform_device *cpdev;\n\tstruct k3_r5_core *core, *temp;\n\n\tlist_for_each_entry_safe_reverse(core, temp, &cluster->cores, elem) {\n\t\tlist_del(&core->elem);\n\t\tcpdev = to_platform_device(core->dev);\n\t\tk3_r5_core_of_exit(cpdev);\n\t}\n}\n\nstatic int k3_r5_cluster_of_init(struct platform_device *pdev)\n{\n\tstruct k3_r5_cluster *cluster = platform_get_drvdata(pdev);\n\tstruct device *dev = &pdev->dev;\n\tstruct device_node *np = dev_of_node(dev);\n\tstruct platform_device *cpdev;\n\tstruct device_node *child;\n\tstruct k3_r5_core *core;\n\tint ret;\n\n\tfor_each_available_child_of_node(np, child) {\n\t\tcpdev = of_find_device_by_node(child);\n\t\tif (!cpdev) {\n\t\t\tret = -ENODEV;\n\t\t\tdev_err(dev, \"could not get R5 core platform device\\n\");\n\t\t\tof_node_put(child);\n\t\t\tgoto fail;\n\t\t}\n\n\t\tret = k3_r5_core_of_init(cpdev);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"k3_r5_core_of_init failed, ret = %d\\n\",\n\t\t\t\tret);\n\t\t\tput_device(&cpdev->dev);\n\t\t\tof_node_put(child);\n\t\t\tgoto fail;\n\t\t}\n\n\t\tcore = platform_get_drvdata(cpdev);\n\t\tput_device(&cpdev->dev);\n\t\tlist_add_tail(&core->elem, &cluster->cores);\n\t}\n\n\treturn 0;\n\nfail:\n\tk3_r5_cluster_of_exit(pdev);\n\treturn ret;\n}\n\nstatic int k3_r5_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct device_node *np = dev_of_node(dev);\n\tstruct k3_r5_cluster *cluster;\n\tconst struct k3_r5_soc_data *data;\n\tint ret;\n\tint num_cores;\n\n\tdata = of_device_get_match_data(&pdev->dev);\n\tif (!data) {\n\t\tdev_err(dev, \"SoC-specific data is not defined\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tcluster = devm_kzalloc(dev, sizeof(*cluster), GFP_KERNEL);\n\tif (!cluster)\n\t\treturn -ENOMEM;\n\n\tcluster->dev = dev;\n\tcluster->soc_data = data;\n\tINIT_LIST_HEAD(&cluster->cores);\n\n\tret = of_property_read_u32(np, \"ti,cluster-mode\", &cluster->mode);\n\tif (ret < 0 && ret != -EINVAL) {\n\t\tdev_err(dev, \"invalid format for ti,cluster-mode, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tif (ret == -EINVAL) {\n\t\t \n\t\tif (!data->is_single_core)\n\t\t\tcluster->mode = data->single_cpu_mode ?\n\t\t\t\t\tCLUSTER_MODE_SPLIT : CLUSTER_MODE_LOCKSTEP;\n\t\telse\n\t\t\tcluster->mode = CLUSTER_MODE_SINGLECORE;\n\t}\n\n\tif  ((cluster->mode == CLUSTER_MODE_SINGLECPU && !data->single_cpu_mode) ||\n\t     (cluster->mode == CLUSTER_MODE_SINGLECORE && !data->is_single_core)) {\n\t\tdev_err(dev, \"Cluster mode = %d is not supported on this SoC\\n\", cluster->mode);\n\t\treturn -EINVAL;\n\t}\n\n\tnum_cores = of_get_available_child_count(np);\n\tif (num_cores != 2 && !data->is_single_core) {\n\t\tdev_err(dev, \"MCU cluster requires both R5F cores to be enabled but num_cores is set to = %d\\n\",\n\t\t\tnum_cores);\n\t\treturn -ENODEV;\n\t}\n\n\tif (num_cores != 1 && data->is_single_core) {\n\t\tdev_err(dev, \"SoC supports only single core R5 but num_cores is set to %d\\n\",\n\t\t\tnum_cores);\n\t\treturn -ENODEV;\n\t}\n\n\tplatform_set_drvdata(pdev, cluster);\n\n\tret = devm_of_platform_populate(dev);\n\tif (ret) {\n\t\tdev_err(dev, \"devm_of_platform_populate failed, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tret = k3_r5_cluster_of_init(pdev);\n\tif (ret) {\n\t\tdev_err(dev, \"k3_r5_cluster_of_init failed, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = devm_add_action_or_reset(dev, k3_r5_cluster_of_exit, pdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = k3_r5_cluster_rproc_init(pdev);\n\tif (ret) {\n\t\tdev_err(dev, \"k3_r5_cluster_rproc_init failed, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tret = devm_add_action_or_reset(dev, k3_r5_cluster_rproc_exit, pdev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic const struct k3_r5_soc_data am65_j721e_soc_data = {\n\t.tcm_is_double = false,\n\t.tcm_ecc_autoinit = false,\n\t.single_cpu_mode = false,\n\t.is_single_core = false,\n};\n\nstatic const struct k3_r5_soc_data j7200_j721s2_soc_data = {\n\t.tcm_is_double = true,\n\t.tcm_ecc_autoinit = true,\n\t.single_cpu_mode = false,\n\t.is_single_core = false,\n};\n\nstatic const struct k3_r5_soc_data am64_soc_data = {\n\t.tcm_is_double = true,\n\t.tcm_ecc_autoinit = true,\n\t.single_cpu_mode = true,\n\t.is_single_core = false,\n};\n\nstatic const struct k3_r5_soc_data am62_soc_data = {\n\t.tcm_is_double = false,\n\t.tcm_ecc_autoinit = true,\n\t.single_cpu_mode = false,\n\t.is_single_core = true,\n};\n\nstatic const struct of_device_id k3_r5_of_match[] = {\n\t{ .compatible = \"ti,am654-r5fss\", .data = &am65_j721e_soc_data, },\n\t{ .compatible = \"ti,j721e-r5fss\", .data = &am65_j721e_soc_data, },\n\t{ .compatible = \"ti,j7200-r5fss\", .data = &j7200_j721s2_soc_data, },\n\t{ .compatible = \"ti,am64-r5fss\",  .data = &am64_soc_data, },\n\t{ .compatible = \"ti,am62-r5fss\",  .data = &am62_soc_data, },\n\t{ .compatible = \"ti,j721s2-r5fss\",  .data = &j7200_j721s2_soc_data, },\n\t{   },\n};\nMODULE_DEVICE_TABLE(of, k3_r5_of_match);\n\nstatic struct platform_driver k3_r5_rproc_driver = {\n\t.probe = k3_r5_probe,\n\t.driver = {\n\t\t.name = \"k3_r5_rproc\",\n\t\t.of_match_table = k3_r5_of_match,\n\t},\n};\n\nmodule_platform_driver(k3_r5_rproc_driver);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"TI K3 R5F remote processor driver\");\nMODULE_AUTHOR(\"Suman Anna <s-anna@ti.com>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}