{
  "module_name": "ring_buffer.c",
  "hash_id": "f4358dd5dabe12e21cce254850d25ccc2295c9a1e67fc265b848c9ae4aa0c10f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/hv/ring_buffer.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/hyperv.h>\n#include <linux/uio.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/prefetch.h>\n#include <linux/io.h>\n#include <asm/mshyperv.h>\n\n#include \"hyperv_vmbus.h\"\n\n#define VMBUS_PKT_TRAILER\t8\n\n \n\nstatic void hv_signal_on_write(u32 old_write, struct vmbus_channel *channel)\n{\n\tstruct hv_ring_buffer_info *rbi = &channel->outbound;\n\n\tvirt_mb();\n\tif (READ_ONCE(rbi->ring_buffer->interrupt_mask))\n\t\treturn;\n\n\t \n\tvirt_rmb();\n\t \n\tif (old_write == READ_ONCE(rbi->ring_buffer->read_index)) {\n\t\t++channel->intr_out_empty;\n\t\tvmbus_setevent(channel);\n\t}\n}\n\n \nstatic inline u32\nhv_get_next_write_location(struct hv_ring_buffer_info *ring_info)\n{\n\tu32 next = ring_info->ring_buffer->write_index;\n\n\treturn next;\n}\n\n \nstatic inline void\nhv_set_next_write_location(struct hv_ring_buffer_info *ring_info,\n\t\t     u32 next_write_location)\n{\n\tring_info->ring_buffer->write_index = next_write_location;\n}\n\n \nstatic inline u32\nhv_get_ring_buffersize(const struct hv_ring_buffer_info *ring_info)\n{\n\treturn ring_info->ring_datasize;\n}\n\n \nstatic inline u64\nhv_get_ring_bufferindices(struct hv_ring_buffer_info *ring_info)\n{\n\treturn (u64)ring_info->ring_buffer->write_index << 32;\n}\n\n \nstatic u32 hv_copyto_ringbuffer(\n\tstruct hv_ring_buffer_info\t*ring_info,\n\tu32\t\t\t\tstart_write_offset,\n\tconst void\t\t\t*src,\n\tu32\t\t\t\tsrclen)\n{\n\tvoid *ring_buffer = hv_get_ring_buffer(ring_info);\n\tu32 ring_buffer_size = hv_get_ring_buffersize(ring_info);\n\n\tmemcpy(ring_buffer + start_write_offset, src, srclen);\n\n\tstart_write_offset += srclen;\n\tif (start_write_offset >= ring_buffer_size)\n\t\tstart_write_offset -= ring_buffer_size;\n\n\treturn start_write_offset;\n}\n\n \nstatic void\nhv_get_ringbuffer_availbytes(const struct hv_ring_buffer_info *rbi,\n\t\t\t     u32 *read, u32 *write)\n{\n\tu32 read_loc, write_loc, dsize;\n\n\t \n\tread_loc = READ_ONCE(rbi->ring_buffer->read_index);\n\twrite_loc = READ_ONCE(rbi->ring_buffer->write_index);\n\tdsize = rbi->ring_datasize;\n\n\t*write = write_loc >= read_loc ? dsize - (write_loc - read_loc) :\n\t\tread_loc - write_loc;\n\t*read = dsize - *write;\n}\n\n \nint hv_ringbuffer_get_debuginfo(struct hv_ring_buffer_info *ring_info,\n\t\t\t\tstruct hv_ring_buffer_debug_info *debug_info)\n{\n\tu32 bytes_avail_towrite;\n\tu32 bytes_avail_toread;\n\n\tmutex_lock(&ring_info->ring_buffer_mutex);\n\n\tif (!ring_info->ring_buffer) {\n\t\tmutex_unlock(&ring_info->ring_buffer_mutex);\n\t\treturn -EINVAL;\n\t}\n\n\thv_get_ringbuffer_availbytes(ring_info,\n\t\t\t\t     &bytes_avail_toread,\n\t\t\t\t     &bytes_avail_towrite);\n\tdebug_info->bytes_avail_toread = bytes_avail_toread;\n\tdebug_info->bytes_avail_towrite = bytes_avail_towrite;\n\tdebug_info->current_read_index = ring_info->ring_buffer->read_index;\n\tdebug_info->current_write_index = ring_info->ring_buffer->write_index;\n\tdebug_info->current_interrupt_mask\n\t\t= ring_info->ring_buffer->interrupt_mask;\n\tmutex_unlock(&ring_info->ring_buffer_mutex);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(hv_ringbuffer_get_debuginfo);\n\n \nvoid hv_ringbuffer_pre_init(struct vmbus_channel *channel)\n{\n\tmutex_init(&channel->inbound.ring_buffer_mutex);\n\tmutex_init(&channel->outbound.ring_buffer_mutex);\n}\n\n \nint hv_ringbuffer_init(struct hv_ring_buffer_info *ring_info,\n\t\t       struct page *pages, u32 page_cnt, u32 max_pkt_size)\n{\n\tstruct page **pages_wraparound;\n\tint i;\n\n\tBUILD_BUG_ON((sizeof(struct hv_ring_buffer) != PAGE_SIZE));\n\n\t \n\tpages_wraparound = kcalloc(page_cnt * 2 - 1,\n\t\t\t\t   sizeof(struct page *),\n\t\t\t\t   GFP_KERNEL);\n\tif (!pages_wraparound)\n\t\treturn -ENOMEM;\n\n\tpages_wraparound[0] = pages;\n\tfor (i = 0; i < 2 * (page_cnt - 1); i++)\n\t\tpages_wraparound[i + 1] =\n\t\t\t&pages[i % (page_cnt - 1) + 1];\n\n\tring_info->ring_buffer = (struct hv_ring_buffer *)\n\t\tvmap(pages_wraparound, page_cnt * 2 - 1, VM_MAP,\n\t\t\tpgprot_decrypted(PAGE_KERNEL));\n\n\tkfree(pages_wraparound);\n\tif (!ring_info->ring_buffer)\n\t\treturn -ENOMEM;\n\n\t \n\tmemset(ring_info->ring_buffer, 0, HV_HYP_PAGE_SIZE);\n\n\tring_info->ring_buffer->read_index =\n\t\tring_info->ring_buffer->write_index = 0;\n\n\t \n\tring_info->ring_buffer->feature_bits.value = 1;\n\n\tring_info->ring_size = page_cnt << PAGE_SHIFT;\n\tring_info->ring_size_div10_reciprocal =\n\t\treciprocal_value(ring_info->ring_size / 10);\n\tring_info->ring_datasize = ring_info->ring_size -\n\t\tsizeof(struct hv_ring_buffer);\n\tring_info->priv_read_index = 0;\n\n\t \n\tif (max_pkt_size) {\n\t\tring_info->pkt_buffer = kzalloc(max_pkt_size, GFP_KERNEL);\n\t\tif (!ring_info->pkt_buffer)\n\t\t\treturn -ENOMEM;\n\t\tring_info->pkt_buffer_size = max_pkt_size;\n\t}\n\n\tspin_lock_init(&ring_info->ring_lock);\n\n\treturn 0;\n}\n\n \nvoid hv_ringbuffer_cleanup(struct hv_ring_buffer_info *ring_info)\n{\n\tmutex_lock(&ring_info->ring_buffer_mutex);\n\tvunmap(ring_info->ring_buffer);\n\tring_info->ring_buffer = NULL;\n\tmutex_unlock(&ring_info->ring_buffer_mutex);\n\n\tkfree(ring_info->pkt_buffer);\n\tring_info->pkt_buffer = NULL;\n\tring_info->pkt_buffer_size = 0;\n}\n\n \n\nbool hv_ringbuffer_spinlock_busy(struct vmbus_channel *channel)\n{\n\tstruct hv_ring_buffer_info *rinfo = &channel->outbound;\n\n\treturn spin_is_locked(&rinfo->ring_lock);\n}\nEXPORT_SYMBOL_GPL(hv_ringbuffer_spinlock_busy);\n\n \nint hv_ringbuffer_write(struct vmbus_channel *channel,\n\t\t\tconst struct kvec *kv_list, u32 kv_count,\n\t\t\tu64 requestid, u64 *trans_id)\n{\n\tint i;\n\tu32 bytes_avail_towrite;\n\tu32 totalbytes_towrite = sizeof(u64);\n\tu32 next_write_location;\n\tu32 old_write;\n\tu64 prev_indices;\n\tunsigned long flags;\n\tstruct hv_ring_buffer_info *outring_info = &channel->outbound;\n\tstruct vmpacket_descriptor *desc = kv_list[0].iov_base;\n\tu64 __trans_id, rqst_id = VMBUS_NO_RQSTOR;\n\n\tif (channel->rescind)\n\t\treturn -ENODEV;\n\n\tfor (i = 0; i < kv_count; i++)\n\t\ttotalbytes_towrite += kv_list[i].iov_len;\n\n\tspin_lock_irqsave(&outring_info->ring_lock, flags);\n\n\tbytes_avail_towrite = hv_get_bytes_to_write(outring_info);\n\n\t \n\tif (bytes_avail_towrite <= totalbytes_towrite) {\n\t\t++channel->out_full_total;\n\n\t\tif (!channel->out_full_flag) {\n\t\t\t++channel->out_full_first;\n\t\t\tchannel->out_full_flag = true;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&outring_info->ring_lock, flags);\n\t\treturn -EAGAIN;\n\t}\n\n\tchannel->out_full_flag = false;\n\n\t \n\tnext_write_location = hv_get_next_write_location(outring_info);\n\n\told_write = next_write_location;\n\n\tfor (i = 0; i < kv_count; i++) {\n\t\tnext_write_location = hv_copyto_ringbuffer(outring_info,\n\t\t\t\t\t\t     next_write_location,\n\t\t\t\t\t\t     kv_list[i].iov_base,\n\t\t\t\t\t\t     kv_list[i].iov_len);\n\t}\n\n\t \n\n\tif (desc->flags == VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED) {\n\t\tif (channel->next_request_id_callback != NULL) {\n\t\t\trqst_id = channel->next_request_id_callback(channel, requestid);\n\t\t\tif (rqst_id == VMBUS_RQST_ERROR) {\n\t\t\t\tspin_unlock_irqrestore(&outring_info->ring_lock, flags);\n\t\t\t\treturn -EAGAIN;\n\t\t\t}\n\t\t}\n\t}\n\tdesc = hv_get_ring_buffer(outring_info) + old_write;\n\t__trans_id = (rqst_id == VMBUS_NO_RQSTOR) ? requestid : rqst_id;\n\t \n\tWRITE_ONCE(desc->trans_id, __trans_id);\n\tif (trans_id)\n\t\t*trans_id = __trans_id;\n\n\t \n\tprev_indices = hv_get_ring_bufferindices(outring_info);\n\n\tnext_write_location = hv_copyto_ringbuffer(outring_info,\n\t\t\t\t\t     next_write_location,\n\t\t\t\t\t     &prev_indices,\n\t\t\t\t\t     sizeof(u64));\n\n\t \n\tvirt_mb();\n\n\t \n\thv_set_next_write_location(outring_info, next_write_location);\n\n\n\tspin_unlock_irqrestore(&outring_info->ring_lock, flags);\n\n\thv_signal_on_write(old_write, channel);\n\n\tif (channel->rescind) {\n\t\tif (rqst_id != VMBUS_NO_RQSTOR) {\n\t\t\t \n\t\t\tif (channel->request_addr_callback != NULL)\n\t\t\t\tchannel->request_addr_callback(channel, rqst_id);\n\t\t}\n\t\treturn -ENODEV;\n\t}\n\n\treturn 0;\n}\n\nint hv_ringbuffer_read(struct vmbus_channel *channel,\n\t\t       void *buffer, u32 buflen, u32 *buffer_actual_len,\n\t\t       u64 *requestid, bool raw)\n{\n\tstruct vmpacket_descriptor *desc;\n\tu32 packetlen, offset;\n\n\tif (unlikely(buflen == 0))\n\t\treturn -EINVAL;\n\n\t*buffer_actual_len = 0;\n\t*requestid = 0;\n\n\t \n\tdesc = hv_pkt_iter_first(channel);\n\tif (desc == NULL) {\n\t\t \n\t\treturn 0;\n\t}\n\n\toffset = raw ? 0 : (desc->offset8 << 3);\n\tpacketlen = (desc->len8 << 3) - offset;\n\t*buffer_actual_len = packetlen;\n\t*requestid = desc->trans_id;\n\n\tif (unlikely(packetlen > buflen))\n\t\treturn -ENOBUFS;\n\n\t \n\tmemcpy(buffer, (const char *)desc + offset, packetlen);\n\n\t \n\t__hv_pkt_iter_next(channel, desc);\n\n\t \n\thv_pkt_iter_close(channel);\n\n\treturn 0;\n}\n\n \nstatic u32 hv_pkt_iter_avail(const struct hv_ring_buffer_info *rbi)\n{\n\tu32 priv_read_loc = rbi->priv_read_index;\n\tu32 write_loc;\n\n\t \n\twrite_loc = virt_load_acquire(&rbi->ring_buffer->write_index);\n\n\tif (write_loc >= priv_read_loc)\n\t\treturn write_loc - priv_read_loc;\n\telse\n\t\treturn (rbi->ring_datasize - priv_read_loc) + write_loc;\n}\n\n \nstruct vmpacket_descriptor *hv_pkt_iter_first(struct vmbus_channel *channel)\n{\n\tstruct hv_ring_buffer_info *rbi = &channel->inbound;\n\tstruct vmpacket_descriptor *desc, *desc_copy;\n\tu32 bytes_avail, pkt_len, pkt_offset;\n\n\thv_debug_delay_test(channel, MESSAGE_DELAY);\n\n\tbytes_avail = hv_pkt_iter_avail(rbi);\n\tif (bytes_avail < sizeof(struct vmpacket_descriptor))\n\t\treturn NULL;\n\tbytes_avail = min(rbi->pkt_buffer_size, bytes_avail);\n\n\tdesc = (struct vmpacket_descriptor *)(hv_get_ring_buffer(rbi) + rbi->priv_read_index);\n\n\t \n\tpkt_len = READ_ONCE(desc->len8) << 3;\n\tpkt_offset = READ_ONCE(desc->offset8) << 3;\n\n\t \n\tif (pkt_len < sizeof(struct vmpacket_descriptor) || pkt_len > bytes_avail)\n\t\tpkt_len = bytes_avail;\n\n\t \n\tif (pkt_offset < sizeof(struct vmpacket_descriptor) || pkt_offset > pkt_len)\n\t\tpkt_offset = sizeof(struct vmpacket_descriptor);\n\n\t \n\tdesc_copy = (struct vmpacket_descriptor *)rbi->pkt_buffer;\n\tmemcpy(desc_copy, desc, pkt_len);\n\n\t \n\tdesc_copy->len8 = pkt_len >> 3;\n\tdesc_copy->offset8 = pkt_offset >> 3;\n\n\treturn desc_copy;\n}\nEXPORT_SYMBOL_GPL(hv_pkt_iter_first);\n\n \nstruct vmpacket_descriptor *\n__hv_pkt_iter_next(struct vmbus_channel *channel,\n\t\t   const struct vmpacket_descriptor *desc)\n{\n\tstruct hv_ring_buffer_info *rbi = &channel->inbound;\n\tu32 packetlen = desc->len8 << 3;\n\tu32 dsize = rbi->ring_datasize;\n\n\thv_debug_delay_test(channel, MESSAGE_DELAY);\n\t \n\trbi->priv_read_index += packetlen + VMBUS_PKT_TRAILER;\n\tif (rbi->priv_read_index >= dsize)\n\t\trbi->priv_read_index -= dsize;\n\n\t \n\treturn hv_pkt_iter_first(channel);\n}\nEXPORT_SYMBOL_GPL(__hv_pkt_iter_next);\n\n \nstatic u32 hv_pkt_iter_bytes_read(const struct hv_ring_buffer_info *rbi,\n\t\t\t\t\tu32 start_read_index)\n{\n\tif (rbi->priv_read_index >= start_read_index)\n\t\treturn rbi->priv_read_index - start_read_index;\n\telse\n\t\treturn rbi->ring_datasize - start_read_index +\n\t\t\trbi->priv_read_index;\n}\n\n \nvoid hv_pkt_iter_close(struct vmbus_channel *channel)\n{\n\tstruct hv_ring_buffer_info *rbi = &channel->inbound;\n\tu32 curr_write_sz, pending_sz, bytes_read, start_read_index;\n\n\t \n\tvirt_rmb();\n\tstart_read_index = rbi->ring_buffer->read_index;\n\trbi->ring_buffer->read_index = rbi->priv_read_index;\n\n\t \n\tif (!rbi->ring_buffer->feature_bits.feat_pending_send_sz)\n\t\treturn;\n\n\t \n\tvirt_mb();\n\n\t \n\tpending_sz = READ_ONCE(rbi->ring_buffer->pending_send_sz);\n\tif (!pending_sz)\n\t\treturn;\n\n\t \n\tvirt_rmb();\n\tcurr_write_sz = hv_get_bytes_to_write(rbi);\n\tbytes_read = hv_pkt_iter_bytes_read(rbi, start_read_index);\n\n\t \n\tif (curr_write_sz - bytes_read > pending_sz)\n\t\treturn;\n\n\t \n\tif (curr_write_sz <= pending_sz)\n\t\treturn;\n\n\t++channel->intr_in_full;\n\tvmbus_setevent(channel);\n}\nEXPORT_SYMBOL_GPL(hv_pkt_iter_close);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}