{
  "module_name": "channel_mgmt.c",
  "hash_id": "1d3489b88fcd4f80e4844d55d3d2d1fa5a0720b526fbd44e2720c9970d81769c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/hv/channel_mgmt.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/wait.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/completion.h>\n#include <linux/delay.h>\n#include <linux/cpu.h>\n#include <linux/hyperv.h>\n#include <asm/mshyperv.h>\n#include <linux/sched/isolation.h>\n\n#include \"hyperv_vmbus.h\"\n\nstatic void init_vp_index(struct vmbus_channel *channel);\n\nconst struct vmbus_device vmbus_devs[] = {\n\t \n\t{ .dev_type = HV_IDE,\n\t  HV_IDE_GUID,\n\t  .perf_device = true,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_SCSI,\n\t  HV_SCSI_GUID,\n\t  .perf_device = true,\n\t  .allowed_in_isolated = true,\n\t},\n\n\t \n\t{ .dev_type = HV_FC,\n\t  HV_SYNTHFC_GUID,\n\t  .perf_device = true,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_NIC,\n\t  HV_NIC_GUID,\n\t  .perf_device = true,\n\t  .allowed_in_isolated = true,\n\t},\n\n\t \n\t{ .dev_type = HV_ND,\n\t  HV_ND_GUID,\n\t  .perf_device = true,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_PCIE,\n\t  HV_PCIE_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = true,\n\t},\n\n\t \n\t{ .dev_type = HV_FB,\n\t  HV_SYNTHVID_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_KBD,\n\t  HV_KBD_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_MOUSE,\n\t  HV_MOUSE_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_KVP,\n\t  HV_KVP_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_TS,\n\t  HV_TS_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = true,\n\t},\n\n\t \n\t{ .dev_type = HV_HB,\n\t  HV_HEART_BEAT_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = true,\n\t},\n\n\t \n\t{ .dev_type = HV_SHUTDOWN,\n\t  HV_SHUTDOWN_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = true,\n\t},\n\n\t \n\t{ .dev_type = HV_FCOPY,\n\t  HV_FCOPY_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_BACKUP,\n\t  HV_VSS_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_DM,\n\t  HV_DM_GUID,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = false,\n\t},\n\n\t \n\t{ .dev_type = HV_UNKNOWN,\n\t  .perf_device = false,\n\t  .allowed_in_isolated = false,\n\t},\n};\n\nstatic const struct {\n\tguid_t guid;\n} vmbus_unsupported_devs[] = {\n\t{ HV_AVMA1_GUID },\n\t{ HV_AVMA2_GUID },\n\t{ HV_RDV_GUID\t},\n\t{ HV_IMC_GUID\t},\n};\n\n \nstatic void vmbus_rescind_cleanup(struct vmbus_channel *channel)\n{\n\tstruct vmbus_channel_msginfo *msginfo;\n\tunsigned long flags;\n\n\n\tspin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);\n\tchannel->rescind = true;\n\tlist_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,\n\t\t\t\tmsglistentry) {\n\n\t\tif (msginfo->waiting_channel == channel) {\n\t\t\tcomplete(&msginfo->waitevent);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);\n}\n\nstatic bool is_unsupported_vmbus_devs(const guid_t *guid)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(vmbus_unsupported_devs); i++)\n\t\tif (guid_equal(guid, &vmbus_unsupported_devs[i].guid))\n\t\t\treturn true;\n\treturn false;\n}\n\nstatic u16 hv_get_dev_type(const struct vmbus_channel *channel)\n{\n\tconst guid_t *guid = &channel->offermsg.offer.if_type;\n\tu16 i;\n\n\tif (is_hvsock_channel(channel) || is_unsupported_vmbus_devs(guid))\n\t\treturn HV_UNKNOWN;\n\n\tfor (i = HV_IDE; i < HV_UNKNOWN; i++) {\n\t\tif (guid_equal(guid, &vmbus_devs[i].guid))\n\t\t\treturn i;\n\t}\n\tpr_info(\"Unknown GUID: %pUl\\n\", guid);\n\treturn i;\n}\n\n \nbool vmbus_prep_negotiate_resp(struct icmsg_hdr *icmsghdrp, u8 *buf,\n\t\t\t\tu32 buflen, const int *fw_version, int fw_vercnt,\n\t\t\t\tconst int *srv_version, int srv_vercnt,\n\t\t\t\tint *nego_fw_version, int *nego_srv_version)\n{\n\tint icframe_major, icframe_minor;\n\tint icmsg_major, icmsg_minor;\n\tint fw_major, fw_minor;\n\tint srv_major, srv_minor;\n\tint i, j;\n\tbool found_match = false;\n\tstruct icmsg_negotiate *negop;\n\n\t \n\tif (buflen < ICMSG_HDR + offsetof(struct icmsg_negotiate, reserved)) {\n\t\tpr_err_ratelimited(\"Invalid icmsg negotiate\\n\");\n\t\treturn false;\n\t}\n\n\ticmsghdrp->icmsgsize = 0x10;\n\tnegop = (struct icmsg_negotiate *)&buf[ICMSG_HDR];\n\n\ticframe_major = negop->icframe_vercnt;\n\ticframe_minor = 0;\n\n\ticmsg_major = negop->icmsg_vercnt;\n\ticmsg_minor = 0;\n\n\t \n\tif (icframe_major > IC_VERSION_NEGOTIATION_MAX_VER_COUNT ||\n\t    icmsg_major > IC_VERSION_NEGOTIATION_MAX_VER_COUNT ||\n\t    ICMSG_NEGOTIATE_PKT_SIZE(icframe_major, icmsg_major) > buflen) {\n\t\tpr_err_ratelimited(\"Invalid icmsg negotiate - icframe_major: %u, icmsg_major: %u\\n\",\n\t\t\t\t   icframe_major, icmsg_major);\n\t\tgoto fw_error;\n\t}\n\n\t \n\n\tfor (i = 0; i < fw_vercnt; i++) {\n\t\tfw_major = (fw_version[i] >> 16);\n\t\tfw_minor = (fw_version[i] & 0xFFFF);\n\n\t\tfor (j = 0; j < negop->icframe_vercnt; j++) {\n\t\t\tif ((negop->icversion_data[j].major == fw_major) &&\n\t\t\t    (negop->icversion_data[j].minor == fw_minor)) {\n\t\t\t\ticframe_major = negop->icversion_data[j].major;\n\t\t\t\ticframe_minor = negop->icversion_data[j].minor;\n\t\t\t\tfound_match = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (found_match)\n\t\t\tbreak;\n\t}\n\n\tif (!found_match)\n\t\tgoto fw_error;\n\n\tfound_match = false;\n\n\tfor (i = 0; i < srv_vercnt; i++) {\n\t\tsrv_major = (srv_version[i] >> 16);\n\t\tsrv_minor = (srv_version[i] & 0xFFFF);\n\n\t\tfor (j = negop->icframe_vercnt;\n\t\t\t(j < negop->icframe_vercnt + negop->icmsg_vercnt);\n\t\t\tj++) {\n\n\t\t\tif ((negop->icversion_data[j].major == srv_major) &&\n\t\t\t\t(negop->icversion_data[j].minor == srv_minor)) {\n\n\t\t\t\ticmsg_major = negop->icversion_data[j].major;\n\t\t\t\ticmsg_minor = negop->icversion_data[j].minor;\n\t\t\t\tfound_match = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (found_match)\n\t\t\tbreak;\n\t}\n\n\t \n\nfw_error:\n\tif (!found_match) {\n\t\tnegop->icframe_vercnt = 0;\n\t\tnegop->icmsg_vercnt = 0;\n\t} else {\n\t\tnegop->icframe_vercnt = 1;\n\t\tnegop->icmsg_vercnt = 1;\n\t}\n\n\tif (nego_fw_version)\n\t\t*nego_fw_version = (icframe_major << 16) | icframe_minor;\n\n\tif (nego_srv_version)\n\t\t*nego_srv_version = (icmsg_major << 16) | icmsg_minor;\n\n\tnegop->icversion_data[0].major = icframe_major;\n\tnegop->icversion_data[0].minor = icframe_minor;\n\tnegop->icversion_data[1].major = icmsg_major;\n\tnegop->icversion_data[1].minor = icmsg_minor;\n\treturn found_match;\n}\nEXPORT_SYMBOL_GPL(vmbus_prep_negotiate_resp);\n\n \nstatic struct vmbus_channel *alloc_channel(void)\n{\n\tstruct vmbus_channel *channel;\n\n\tchannel = kzalloc(sizeof(*channel), GFP_ATOMIC);\n\tif (!channel)\n\t\treturn NULL;\n\n\tspin_lock_init(&channel->sched_lock);\n\tinit_completion(&channel->rescind_event);\n\n\tINIT_LIST_HEAD(&channel->sc_list);\n\n\ttasklet_init(&channel->callback_event,\n\t\t     vmbus_on_event, (unsigned long)channel);\n\n\thv_ringbuffer_pre_init(channel);\n\n\treturn channel;\n}\n\n \nstatic void free_channel(struct vmbus_channel *channel)\n{\n\ttasklet_kill(&channel->callback_event);\n\tvmbus_remove_channel_attr_group(channel);\n\n\tkobject_put(&channel->kobj);\n}\n\nvoid vmbus_channel_map_relid(struct vmbus_channel *channel)\n{\n\tif (WARN_ON(channel->offermsg.child_relid >= MAX_CHANNEL_RELIDS))\n\t\treturn;\n\t \n\tvirt_store_mb(\n\t\tvmbus_connection.channels[channel->offermsg.child_relid],\n\t\tchannel);\n}\n\nvoid vmbus_channel_unmap_relid(struct vmbus_channel *channel)\n{\n\tif (WARN_ON(channel->offermsg.child_relid >= MAX_CHANNEL_RELIDS))\n\t\treturn;\n\tWRITE_ONCE(\n\t\tvmbus_connection.channels[channel->offermsg.child_relid],\n\t\tNULL);\n}\n\nstatic void vmbus_release_relid(u32 relid)\n{\n\tstruct vmbus_channel_relid_released msg;\n\tint ret;\n\n\tmemset(&msg, 0, sizeof(struct vmbus_channel_relid_released));\n\tmsg.child_relid = relid;\n\tmsg.header.msgtype = CHANNELMSG_RELID_RELEASED;\n\tret = vmbus_post_msg(&msg, sizeof(struct vmbus_channel_relid_released),\n\t\t\t     true);\n\n\ttrace_vmbus_release_relid(&msg, ret);\n}\n\nvoid hv_process_channel_removal(struct vmbus_channel *channel)\n{\n\tlockdep_assert_held(&vmbus_connection.channel_mutex);\n\tBUG_ON(!channel->rescind);\n\n\t \n\tWARN_ON(channel->offermsg.child_relid == INVALID_RELID &&\n\t\t!is_hvsock_channel(channel));\n\n\t \n\tif (channel->offermsg.child_relid != INVALID_RELID)\n\t\tvmbus_channel_unmap_relid(channel);\n\n\tif (channel->primary_channel == NULL)\n\t\tlist_del(&channel->listentry);\n\telse\n\t\tlist_del(&channel->sc_list);\n\n\t \n\tif (hv_is_perf_channel(channel))\n\t\thv_clear_allocated_cpu(channel->target_cpu);\n\n\t \n\tif (channel->offermsg.child_relid != INVALID_RELID)\n\t\tvmbus_release_relid(channel->offermsg.child_relid);\n\n\tfree_channel(channel);\n}\n\nvoid vmbus_free_channels(void)\n{\n\tstruct vmbus_channel *channel, *tmp;\n\n\tlist_for_each_entry_safe(channel, tmp, &vmbus_connection.chn_list,\n\t\tlistentry) {\n\t\t \n\t\tchannel->rescind = true;\n\n\t\tvmbus_device_unregister(channel->device_obj);\n\t}\n}\n\n \nstatic void vmbus_add_channel_work(struct work_struct *work)\n{\n\tstruct vmbus_channel *newchannel =\n\t\tcontainer_of(work, struct vmbus_channel, add_channel_work);\n\tstruct vmbus_channel *primary_channel = newchannel->primary_channel;\n\tint ret;\n\n\t \n\tnewchannel->state = CHANNEL_OPEN_STATE;\n\n\tif (primary_channel != NULL) {\n\t\t \n\t\tstruct hv_device *dev = primary_channel->device_obj;\n\n\t\tif (vmbus_add_channel_kobj(dev, newchannel))\n\t\t\tgoto err_deq_chan;\n\n\t\tif (primary_channel->sc_creation_callback != NULL)\n\t\t\tprimary_channel->sc_creation_callback(newchannel);\n\n\t\tnewchannel->probe_done = true;\n\t\treturn;\n\t}\n\n\t \n\tnewchannel->device_obj = vmbus_device_create(\n\t\t&newchannel->offermsg.offer.if_type,\n\t\t&newchannel->offermsg.offer.if_instance,\n\t\tnewchannel);\n\tif (!newchannel->device_obj)\n\t\tgoto err_deq_chan;\n\n\tnewchannel->device_obj->device_id = newchannel->device_id;\n\t \n\tret = vmbus_device_register(newchannel->device_obj);\n\n\tif (ret != 0) {\n\t\tpr_err(\"unable to add child device object (relid %d)\\n\",\n\t\t\tnewchannel->offermsg.child_relid);\n\t\tgoto err_deq_chan;\n\t}\n\n\tnewchannel->probe_done = true;\n\treturn;\n\nerr_deq_chan:\n\tmutex_lock(&vmbus_connection.channel_mutex);\n\n\t \n\tnewchannel->probe_done = true;\n\n\tif (primary_channel == NULL)\n\t\tlist_del(&newchannel->listentry);\n\telse\n\t\tlist_del(&newchannel->sc_list);\n\n\t \n\tvmbus_channel_unmap_relid(newchannel);\n\n\tmutex_unlock(&vmbus_connection.channel_mutex);\n\n\tvmbus_release_relid(newchannel->offermsg.child_relid);\n\n\tfree_channel(newchannel);\n}\n\n \nstatic void vmbus_process_offer(struct vmbus_channel *newchannel)\n{\n\tstruct vmbus_channel *channel;\n\tstruct workqueue_struct *wq;\n\tbool fnew = true;\n\n\t \n\tcpus_read_lock();\n\n\t \n\tmutex_lock(&vmbus_connection.channel_mutex);\n\n\tlist_for_each_entry(channel, &vmbus_connection.chn_list, listentry) {\n\t\tif (guid_equal(&channel->offermsg.offer.if_type,\n\t\t\t       &newchannel->offermsg.offer.if_type) &&\n\t\t    guid_equal(&channel->offermsg.offer.if_instance,\n\t\t\t       &newchannel->offermsg.offer.if_instance)) {\n\t\t\tfnew = false;\n\t\t\tnewchannel->primary_channel = channel;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tinit_vp_index(newchannel);\n\n\t \n\tif (is_hvsock_channel(newchannel) || is_sub_channel(newchannel))\n\t\tatomic_inc(&vmbus_connection.nr_chan_close_on_suspend);\n\n\t \n\tatomic_dec(&vmbus_connection.offer_in_progress);\n\n\tif (fnew) {\n\t\tlist_add_tail(&newchannel->listentry,\n\t\t\t      &vmbus_connection.chn_list);\n\t} else {\n\t\t \n\t\tif (newchannel->offermsg.offer.sub_channel_index == 0) {\n\t\t\tmutex_unlock(&vmbus_connection.channel_mutex);\n\t\t\tcpus_read_unlock();\n\t\t\t \n\t\t\tkfree(newchannel);\n\t\t\tWARN_ON_ONCE(1);\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tlist_add_tail(&newchannel->sc_list, &channel->sc_list);\n\t}\n\n\tvmbus_channel_map_relid(newchannel);\n\n\tmutex_unlock(&vmbus_connection.channel_mutex);\n\tcpus_read_unlock();\n\n\t \n\tINIT_WORK(&newchannel->add_channel_work, vmbus_add_channel_work);\n\twq = fnew ? vmbus_connection.handle_primary_chan_wq :\n\t\t    vmbus_connection.handle_sub_chan_wq;\n\tqueue_work(wq, &newchannel->add_channel_work);\n}\n\n \nstatic bool hv_cpuself_used(u32 cpu, struct vmbus_channel *chn)\n{\n\tstruct vmbus_channel *primary = chn->primary_channel;\n\tstruct vmbus_channel *sc;\n\n\tlockdep_assert_held(&vmbus_connection.channel_mutex);\n\n\tif (!primary)\n\t\treturn false;\n\n\tif (primary->target_cpu == cpu)\n\t\treturn true;\n\n\tlist_for_each_entry(sc, &primary->sc_list, sc_list)\n\t\tif (sc != chn && sc->target_cpu == cpu)\n\t\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic int next_numa_node_id;\n\n \nstatic void init_vp_index(struct vmbus_channel *channel)\n{\n\tbool perf_chn = hv_is_perf_channel(channel);\n\tu32 i, ncpu = num_online_cpus();\n\tcpumask_var_t available_mask;\n\tstruct cpumask *allocated_mask;\n\tconst struct cpumask *hk_mask = housekeeping_cpumask(HK_TYPE_MANAGED_IRQ);\n\tu32 target_cpu;\n\tint numa_node;\n\n\tif (!perf_chn ||\n\t    !alloc_cpumask_var(&available_mask, GFP_KERNEL) ||\n\t    cpumask_empty(hk_mask)) {\n\t\t \n\t\tchannel->target_cpu = VMBUS_CONNECT_CPU;\n\t\tif (perf_chn)\n\t\t\thv_set_allocated_cpu(VMBUS_CONNECT_CPU);\n\t\treturn;\n\t}\n\n\tfor (i = 1; i <= ncpu + 1; i++) {\n\t\twhile (true) {\n\t\t\tnuma_node = next_numa_node_id++;\n\t\t\tif (numa_node == nr_node_ids) {\n\t\t\t\tnext_numa_node_id = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (cpumask_empty(cpumask_of_node(numa_node)))\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\t}\n\t\tallocated_mask = &hv_context.hv_numa_map[numa_node];\n\nretry:\n\t\tcpumask_xor(available_mask, allocated_mask, cpumask_of_node(numa_node));\n\t\tcpumask_and(available_mask, available_mask, hk_mask);\n\n\t\tif (cpumask_empty(available_mask)) {\n\t\t\t \n\t\t\tcpumask_clear(allocated_mask);\n\t\t\tgoto retry;\n\t\t}\n\n\t\ttarget_cpu = cpumask_first(available_mask);\n\t\tcpumask_set_cpu(target_cpu, allocated_mask);\n\n\t\tif (channel->offermsg.offer.sub_channel_index >= ncpu ||\n\t\t    i > ncpu || !hv_cpuself_used(target_cpu, channel))\n\t\t\tbreak;\n\t}\n\n\tchannel->target_cpu = target_cpu;\n\n\tfree_cpumask_var(available_mask);\n}\n\n#define UNLOAD_DELAY_UNIT_MS\t10\t\t \n#define UNLOAD_WAIT_MS\t\t(100*1000)\t \n#define UNLOAD_WAIT_LOOPS\t(UNLOAD_WAIT_MS/UNLOAD_DELAY_UNIT_MS)\n#define UNLOAD_MSG_MS\t\t(5*1000)\t \n#define UNLOAD_MSG_LOOPS\t(UNLOAD_MSG_MS/UNLOAD_DELAY_UNIT_MS)\n\nstatic void vmbus_wait_for_unload(void)\n{\n\tint cpu;\n\tvoid *page_addr;\n\tstruct hv_message *msg;\n\tstruct vmbus_channel_message_header *hdr;\n\tu32 message_type, i;\n\n\t \n\tfor (i = 1; i <= UNLOAD_WAIT_LOOPS; i++) {\n\t\tif (completion_done(&vmbus_connection.unload_event))\n\t\t\tgoto completed;\n\n\t\tfor_each_present_cpu(cpu) {\n\t\t\tstruct hv_per_cpu_context *hv_cpu\n\t\t\t\t= per_cpu_ptr(hv_context.cpu_context, cpu);\n\n\t\t\t \n\t\t\tpage_addr = hv_cpu->synic_message_page;\n\t\t\tif (!page_addr)\n\t\t\t\tcontinue;\n\n\t\t\tmsg = (struct hv_message *)page_addr\n\t\t\t\t+ VMBUS_MESSAGE_SINT;\n\n\t\t\tmessage_type = READ_ONCE(msg->header.message_type);\n\t\t\tif (message_type == HVMSG_NONE)\n\t\t\t\tcontinue;\n\n\t\t\thdr = (struct vmbus_channel_message_header *)\n\t\t\t\tmsg->u.payload;\n\n\t\t\tif (hdr->msgtype == CHANNELMSG_UNLOAD_RESPONSE)\n\t\t\t\tcomplete(&vmbus_connection.unload_event);\n\n\t\t\tvmbus_signal_eom(msg, message_type);\n\t\t}\n\n\t\t \n\t\tif (!(i % UNLOAD_MSG_LOOPS))\n\t\t\tpr_notice(\"Waiting for VMBus UNLOAD to complete\\n\");\n\n\t\tmdelay(UNLOAD_DELAY_UNIT_MS);\n\t}\n\tpr_err(\"Continuing even though VMBus UNLOAD did not complete\\n\");\n\ncompleted:\n\t \n\tfor_each_present_cpu(cpu) {\n\t\tstruct hv_per_cpu_context *hv_cpu\n\t\t\t= per_cpu_ptr(hv_context.cpu_context, cpu);\n\n\t\tpage_addr = hv_cpu->synic_message_page;\n\t\tif (!page_addr)\n\t\t\tcontinue;\n\n\t\tmsg = (struct hv_message *)page_addr + VMBUS_MESSAGE_SINT;\n\t\tmsg->header.message_type = HVMSG_NONE;\n\t}\n}\n\n \nstatic void vmbus_unload_response(struct vmbus_channel_message_header *hdr)\n{\n\t \n\tcomplete(&vmbus_connection.unload_event);\n}\n\nvoid vmbus_initiate_unload(bool crash)\n{\n\tstruct vmbus_channel_message_header hdr;\n\n\tif (xchg(&vmbus_connection.conn_state, DISCONNECTED) == DISCONNECTED)\n\t\treturn;\n\n\t \n\tif (vmbus_proto_version < VERSION_WIN8_1)\n\t\treturn;\n\n\treinit_completion(&vmbus_connection.unload_event);\n\tmemset(&hdr, 0, sizeof(struct vmbus_channel_message_header));\n\thdr.msgtype = CHANNELMSG_UNLOAD;\n\tvmbus_post_msg(&hdr, sizeof(struct vmbus_channel_message_header),\n\t\t       !crash);\n\n\t \n\tif (!crash)\n\t\twait_for_completion(&vmbus_connection.unload_event);\n\telse\n\t\tvmbus_wait_for_unload();\n}\n\nstatic void check_ready_for_resume_event(void)\n{\n\t \n\tif (atomic_dec_and_test(&vmbus_connection.nr_chan_fixup_on_resume))\n\t\tcomplete(&vmbus_connection.ready_for_resume_event);\n}\n\nstatic void vmbus_setup_channel_state(struct vmbus_channel *channel,\n\t\t\t\t      struct vmbus_channel_offer_channel *offer)\n{\n\t \n\tchannel->sig_event = VMBUS_EVENT_CONNECTION_ID;\n\n\tchannel->is_dedicated_interrupt =\n\t\t\t(offer->is_dedicated_interrupt != 0);\n\tchannel->sig_event = offer->connection_id;\n\n\tmemcpy(&channel->offermsg, offer,\n\t       sizeof(struct vmbus_channel_offer_channel));\n\tchannel->monitor_grp = (u8)offer->monitorid / 32;\n\tchannel->monitor_bit = (u8)offer->monitorid % 32;\n\tchannel->device_id = hv_get_dev_type(channel);\n}\n\n \nstatic struct vmbus_channel *\nfind_primary_channel_by_offer(const struct vmbus_channel_offer_channel *offer)\n{\n\tstruct vmbus_channel *channel = NULL, *iter;\n\tconst guid_t *inst1, *inst2;\n\n\t \n\tif (offer->offer.sub_channel_index != 0)\n\t\treturn NULL;\n\n\tmutex_lock(&vmbus_connection.channel_mutex);\n\n\tlist_for_each_entry(iter, &vmbus_connection.chn_list, listentry) {\n\t\tinst1 = &iter->offermsg.offer.if_instance;\n\t\tinst2 = &offer->offer.if_instance;\n\n\t\tif (guid_equal(inst1, inst2)) {\n\t\t\tchannel = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmutex_unlock(&vmbus_connection.channel_mutex);\n\n\treturn channel;\n}\n\nstatic bool vmbus_is_valid_offer(const struct vmbus_channel_offer_channel *offer)\n{\n\tconst guid_t *guid = &offer->offer.if_type;\n\tu16 i;\n\n\tif (!hv_is_isolation_supported())\n\t\treturn true;\n\n\tif (is_hvsock_offer(offer))\n\t\treturn true;\n\n\tfor (i = 0; i < ARRAY_SIZE(vmbus_devs); i++) {\n\t\tif (guid_equal(guid, &vmbus_devs[i].guid))\n\t\t\treturn vmbus_devs[i].allowed_in_isolated;\n\t}\n\treturn false;\n}\n\n \nstatic void vmbus_onoffer(struct vmbus_channel_message_header *hdr)\n{\n\tstruct vmbus_channel_offer_channel *offer;\n\tstruct vmbus_channel *oldchannel, *newchannel;\n\tsize_t offer_sz;\n\n\toffer = (struct vmbus_channel_offer_channel *)hdr;\n\n\ttrace_vmbus_onoffer(offer);\n\n\tif (!vmbus_is_valid_offer(offer)) {\n\t\tpr_err_ratelimited(\"Invalid offer %d from the host supporting isolation\\n\",\n\t\t\t\t   offer->child_relid);\n\t\tatomic_dec(&vmbus_connection.offer_in_progress);\n\t\treturn;\n\t}\n\n\toldchannel = find_primary_channel_by_offer(offer);\n\n\tif (oldchannel != NULL) {\n\t\t \n\n\t\t \n\t\tmutex_lock(&vmbus_connection.channel_mutex);\n\n\t\tatomic_dec(&vmbus_connection.offer_in_progress);\n\n\t\tWARN_ON(oldchannel->offermsg.child_relid != INVALID_RELID);\n\t\t \n\t\toldchannel->offermsg.child_relid = offer->child_relid;\n\n\t\toffer_sz = sizeof(*offer);\n\t\tif (memcmp(offer, &oldchannel->offermsg, offer_sz) != 0) {\n\t\t\t \n\t\t\tpr_debug(\"vmbus offer changed: relid=%d\\n\",\n\t\t\t\t offer->child_relid);\n\n\t\t\tprint_hex_dump_debug(\"Old vmbus offer: \",\n\t\t\t\t\t     DUMP_PREFIX_OFFSET, 16, 4,\n\t\t\t\t\t     &oldchannel->offermsg, offer_sz,\n\t\t\t\t\t     false);\n\t\t\tprint_hex_dump_debug(\"New vmbus offer: \",\n\t\t\t\t\t     DUMP_PREFIX_OFFSET, 16, 4,\n\t\t\t\t\t     offer, offer_sz, false);\n\n\t\t\t \n\t\t\tvmbus_setup_channel_state(oldchannel, offer);\n\t\t}\n\n\t\t \n\t\tvmbus_channel_map_relid(oldchannel);\n\t\tcheck_ready_for_resume_event();\n\n\t\tmutex_unlock(&vmbus_connection.channel_mutex);\n\t\treturn;\n\t}\n\n\t \n\tnewchannel = alloc_channel();\n\tif (!newchannel) {\n\t\tvmbus_release_relid(offer->child_relid);\n\t\tatomic_dec(&vmbus_connection.offer_in_progress);\n\t\tpr_err(\"Unable to allocate channel object\\n\");\n\t\treturn;\n\t}\n\n\tvmbus_setup_channel_state(newchannel, offer);\n\n\tvmbus_process_offer(newchannel);\n}\n\nstatic void check_ready_for_suspend_event(void)\n{\n\t \n\tif (atomic_dec_and_test(&vmbus_connection.nr_chan_close_on_suspend))\n\t\tcomplete(&vmbus_connection.ready_for_suspend_event);\n}\n\n \nstatic void vmbus_onoffer_rescind(struct vmbus_channel_message_header *hdr)\n{\n\tstruct vmbus_channel_rescind_offer *rescind;\n\tstruct vmbus_channel *channel;\n\tstruct device *dev;\n\tbool clean_up_chan_for_suspend;\n\n\trescind = (struct vmbus_channel_rescind_offer *)hdr;\n\n\ttrace_vmbus_onoffer_rescind(rescind);\n\n\t \n\n\twhile (atomic_read(&vmbus_connection.offer_in_progress) != 0) {\n\t\t \n\t\tmsleep(1);\n\t}\n\n\tmutex_lock(&vmbus_connection.channel_mutex);\n\tchannel = relid2channel(rescind->child_relid);\n\tif (channel != NULL) {\n\t\t \n\t\tif (channel->rescind_ref) {\n\t\t\tmutex_unlock(&vmbus_connection.channel_mutex);\n\t\t\treturn;\n\t\t}\n\t\tchannel->rescind_ref = true;\n\t}\n\tmutex_unlock(&vmbus_connection.channel_mutex);\n\n\tif (channel == NULL) {\n\t\t \n\t\treturn;\n\t}\n\n\tclean_up_chan_for_suspend = is_hvsock_channel(channel) ||\n\t\t\t\t    is_sub_channel(channel);\n\t \n\tvmbus_reset_channel_cb(channel);\n\n\t \n\tvmbus_rescind_cleanup(channel);\n\twhile (READ_ONCE(channel->probe_done) == false) {\n\t\t \n\t\tmsleep(1);\n\t}\n\n\t \n\n\tif (channel->device_obj) {\n\t\tif (channel->chn_rescind_callback) {\n\t\t\tchannel->chn_rescind_callback(channel);\n\n\t\t\tif (clean_up_chan_for_suspend)\n\t\t\t\tcheck_ready_for_suspend_event();\n\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tdev = get_device(&channel->device_obj->device);\n\t\tif (dev) {\n\t\t\tvmbus_device_unregister(channel->device_obj);\n\t\t\tput_device(dev);\n\t\t}\n\t} else if (channel->primary_channel != NULL) {\n\t\t \n\t\tmutex_lock(&vmbus_connection.channel_mutex);\n\t\tif (channel->state == CHANNEL_OPEN_STATE) {\n\t\t\t \n\t\t\thv_process_channel_removal(channel);\n\t\t} else {\n\t\t\tcomplete(&channel->rescind_event);\n\t\t}\n\t\tmutex_unlock(&vmbus_connection.channel_mutex);\n\t}\n\n\t \n\n\tif (clean_up_chan_for_suspend)\n\t\tcheck_ready_for_suspend_event();\n}\n\nvoid vmbus_hvsock_device_unregister(struct vmbus_channel *channel)\n{\n\tBUG_ON(!is_hvsock_channel(channel));\n\n\t \n\twhile (!READ_ONCE(channel->probe_done) || !READ_ONCE(channel->rescind))\n\t\tmsleep(1);\n\n\tvmbus_device_unregister(channel->device_obj);\n}\nEXPORT_SYMBOL_GPL(vmbus_hvsock_device_unregister);\n\n\n \nstatic void vmbus_onoffers_delivered(\n\t\t\tstruct vmbus_channel_message_header *hdr)\n{\n}\n\n \nstatic void vmbus_onopen_result(struct vmbus_channel_message_header *hdr)\n{\n\tstruct vmbus_channel_open_result *result;\n\tstruct vmbus_channel_msginfo *msginfo;\n\tstruct vmbus_channel_message_header *requestheader;\n\tstruct vmbus_channel_open_channel *openmsg;\n\tunsigned long flags;\n\n\tresult = (struct vmbus_channel_open_result *)hdr;\n\n\ttrace_vmbus_onopen_result(result);\n\n\t \n\tspin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);\n\n\tlist_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,\n\t\t\t\tmsglistentry) {\n\t\trequestheader =\n\t\t\t(struct vmbus_channel_message_header *)msginfo->msg;\n\n\t\tif (requestheader->msgtype == CHANNELMSG_OPENCHANNEL) {\n\t\t\topenmsg =\n\t\t\t(struct vmbus_channel_open_channel *)msginfo->msg;\n\t\t\tif (openmsg->child_relid == result->child_relid &&\n\t\t\t    openmsg->openid == result->openid) {\n\t\t\t\tmemcpy(&msginfo->response.open_result,\n\t\t\t\t       result,\n\t\t\t\t       sizeof(\n\t\t\t\t\tstruct vmbus_channel_open_result));\n\t\t\t\tcomplete(&msginfo->waitevent);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);\n}\n\n \nstatic void vmbus_ongpadl_created(struct vmbus_channel_message_header *hdr)\n{\n\tstruct vmbus_channel_gpadl_created *gpadlcreated;\n\tstruct vmbus_channel_msginfo *msginfo;\n\tstruct vmbus_channel_message_header *requestheader;\n\tstruct vmbus_channel_gpadl_header *gpadlheader;\n\tunsigned long flags;\n\n\tgpadlcreated = (struct vmbus_channel_gpadl_created *)hdr;\n\n\ttrace_vmbus_ongpadl_created(gpadlcreated);\n\n\t \n\tspin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);\n\n\tlist_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,\n\t\t\t\tmsglistentry) {\n\t\trequestheader =\n\t\t\t(struct vmbus_channel_message_header *)msginfo->msg;\n\n\t\tif (requestheader->msgtype == CHANNELMSG_GPADL_HEADER) {\n\t\t\tgpadlheader =\n\t\t\t(struct vmbus_channel_gpadl_header *)requestheader;\n\n\t\t\tif ((gpadlcreated->child_relid ==\n\t\t\t     gpadlheader->child_relid) &&\n\t\t\t    (gpadlcreated->gpadl == gpadlheader->gpadl)) {\n\t\t\t\tmemcpy(&msginfo->response.gpadl_created,\n\t\t\t\t       gpadlcreated,\n\t\t\t\t       sizeof(\n\t\t\t\t\tstruct vmbus_channel_gpadl_created));\n\t\t\t\tcomplete(&msginfo->waitevent);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);\n}\n\n \nstatic void vmbus_onmodifychannel_response(struct vmbus_channel_message_header *hdr)\n{\n\tstruct vmbus_channel_modifychannel_response *response;\n\tstruct vmbus_channel_msginfo *msginfo;\n\tunsigned long flags;\n\n\tresponse = (struct vmbus_channel_modifychannel_response *)hdr;\n\n\ttrace_vmbus_onmodifychannel_response(response);\n\n\t \n\tspin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);\n\n\tlist_for_each_entry(msginfo, &vmbus_connection.chn_msg_list, msglistentry) {\n\t\tstruct vmbus_channel_message_header *responseheader =\n\t\t\t\t(struct vmbus_channel_message_header *)msginfo->msg;\n\n\t\tif (responseheader->msgtype == CHANNELMSG_MODIFYCHANNEL) {\n\t\t\tstruct vmbus_channel_modifychannel *modifymsg;\n\n\t\t\tmodifymsg = (struct vmbus_channel_modifychannel *)msginfo->msg;\n\t\t\tif (modifymsg->child_relid == response->child_relid) {\n\t\t\t\tmemcpy(&msginfo->response.modify_response, response,\n\t\t\t\t       sizeof(*response));\n\t\t\t\tcomplete(&msginfo->waitevent);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);\n}\n\n \nstatic void vmbus_ongpadl_torndown(\n\t\t\tstruct vmbus_channel_message_header *hdr)\n{\n\tstruct vmbus_channel_gpadl_torndown *gpadl_torndown;\n\tstruct vmbus_channel_msginfo *msginfo;\n\tstruct vmbus_channel_message_header *requestheader;\n\tstruct vmbus_channel_gpadl_teardown *gpadl_teardown;\n\tunsigned long flags;\n\n\tgpadl_torndown = (struct vmbus_channel_gpadl_torndown *)hdr;\n\n\ttrace_vmbus_ongpadl_torndown(gpadl_torndown);\n\n\t \n\tspin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);\n\n\tlist_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,\n\t\t\t\tmsglistentry) {\n\t\trequestheader =\n\t\t\t(struct vmbus_channel_message_header *)msginfo->msg;\n\n\t\tif (requestheader->msgtype == CHANNELMSG_GPADL_TEARDOWN) {\n\t\t\tgpadl_teardown =\n\t\t\t(struct vmbus_channel_gpadl_teardown *)requestheader;\n\n\t\t\tif (gpadl_torndown->gpadl == gpadl_teardown->gpadl) {\n\t\t\t\tmemcpy(&msginfo->response.gpadl_torndown,\n\t\t\t\t       gpadl_torndown,\n\t\t\t\t       sizeof(\n\t\t\t\t\tstruct vmbus_channel_gpadl_torndown));\n\t\t\t\tcomplete(&msginfo->waitevent);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);\n}\n\n \nstatic void vmbus_onversion_response(\n\t\tstruct vmbus_channel_message_header *hdr)\n{\n\tstruct vmbus_channel_msginfo *msginfo;\n\tstruct vmbus_channel_message_header *requestheader;\n\tstruct vmbus_channel_version_response *version_response;\n\tunsigned long flags;\n\n\tversion_response = (struct vmbus_channel_version_response *)hdr;\n\n\ttrace_vmbus_onversion_response(version_response);\n\n\tspin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);\n\n\tlist_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,\n\t\t\t\tmsglistentry) {\n\t\trequestheader =\n\t\t\t(struct vmbus_channel_message_header *)msginfo->msg;\n\n\t\tif (requestheader->msgtype ==\n\t\t    CHANNELMSG_INITIATE_CONTACT) {\n\t\t\tmemcpy(&msginfo->response.version_response,\n\t\t\t      version_response,\n\t\t\t      sizeof(struct vmbus_channel_version_response));\n\t\t\tcomplete(&msginfo->waitevent);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);\n}\n\n \nconst struct vmbus_channel_message_table_entry\nchannel_message_table[CHANNELMSG_COUNT] = {\n\t{ CHANNELMSG_INVALID,\t\t\t0, NULL, 0},\n\t{ CHANNELMSG_OFFERCHANNEL,\t\t0, vmbus_onoffer,\n\t\tsizeof(struct vmbus_channel_offer_channel)},\n\t{ CHANNELMSG_RESCIND_CHANNELOFFER,\t0, vmbus_onoffer_rescind,\n\t\tsizeof(struct vmbus_channel_rescind_offer) },\n\t{ CHANNELMSG_REQUESTOFFERS,\t\t0, NULL, 0},\n\t{ CHANNELMSG_ALLOFFERS_DELIVERED,\t1, vmbus_onoffers_delivered, 0},\n\t{ CHANNELMSG_OPENCHANNEL,\t\t0, NULL, 0},\n\t{ CHANNELMSG_OPENCHANNEL_RESULT,\t1, vmbus_onopen_result,\n\t\tsizeof(struct vmbus_channel_open_result)},\n\t{ CHANNELMSG_CLOSECHANNEL,\t\t0, NULL, 0},\n\t{ CHANNELMSG_GPADL_HEADER,\t\t0, NULL, 0},\n\t{ CHANNELMSG_GPADL_BODY,\t\t0, NULL, 0},\n\t{ CHANNELMSG_GPADL_CREATED,\t\t1, vmbus_ongpadl_created,\n\t\tsizeof(struct vmbus_channel_gpadl_created)},\n\t{ CHANNELMSG_GPADL_TEARDOWN,\t\t0, NULL, 0},\n\t{ CHANNELMSG_GPADL_TORNDOWN,\t\t1, vmbus_ongpadl_torndown,\n\t\tsizeof(struct vmbus_channel_gpadl_torndown) },\n\t{ CHANNELMSG_RELID_RELEASED,\t\t0, NULL, 0},\n\t{ CHANNELMSG_INITIATE_CONTACT,\t\t0, NULL, 0},\n\t{ CHANNELMSG_VERSION_RESPONSE,\t\t1, vmbus_onversion_response,\n\t\tsizeof(struct vmbus_channel_version_response)},\n\t{ CHANNELMSG_UNLOAD,\t\t\t0, NULL, 0},\n\t{ CHANNELMSG_UNLOAD_RESPONSE,\t\t1, vmbus_unload_response, 0},\n\t{ CHANNELMSG_18,\t\t\t0, NULL, 0},\n\t{ CHANNELMSG_19,\t\t\t0, NULL, 0},\n\t{ CHANNELMSG_20,\t\t\t0, NULL, 0},\n\t{ CHANNELMSG_TL_CONNECT_REQUEST,\t0, NULL, 0},\n\t{ CHANNELMSG_MODIFYCHANNEL,\t\t0, NULL, 0},\n\t{ CHANNELMSG_TL_CONNECT_RESULT,\t\t0, NULL, 0},\n\t{ CHANNELMSG_MODIFYCHANNEL_RESPONSE,\t1, vmbus_onmodifychannel_response,\n\t\tsizeof(struct vmbus_channel_modifychannel_response)},\n};\n\n \nvoid vmbus_onmessage(struct vmbus_channel_message_header *hdr)\n{\n\ttrace_vmbus_on_message(hdr);\n\n\t \n\tchannel_message_table[hdr->msgtype].message_handler(hdr);\n}\n\n \nint vmbus_request_offers(void)\n{\n\tstruct vmbus_channel_message_header *msg;\n\tstruct vmbus_channel_msginfo *msginfo;\n\tint ret;\n\n\tmsginfo = kzalloc(sizeof(*msginfo) +\n\t\t\t  sizeof(struct vmbus_channel_message_header),\n\t\t\t  GFP_KERNEL);\n\tif (!msginfo)\n\t\treturn -ENOMEM;\n\n\tmsg = (struct vmbus_channel_message_header *)msginfo->msg;\n\n\tmsg->msgtype = CHANNELMSG_REQUESTOFFERS;\n\n\tret = vmbus_post_msg(msg, sizeof(struct vmbus_channel_message_header),\n\t\t\t     true);\n\n\ttrace_vmbus_request_offers(ret);\n\n\tif (ret != 0) {\n\t\tpr_err(\"Unable to request offers - %d\\n\", ret);\n\n\t\tgoto cleanup;\n\t}\n\ncleanup:\n\tkfree(msginfo);\n\n\treturn ret;\n}\n\nvoid vmbus_set_sc_create_callback(struct vmbus_channel *primary_channel,\n\t\t\t\tvoid (*sc_cr_cb)(struct vmbus_channel *new_sc))\n{\n\tprimary_channel->sc_creation_callback = sc_cr_cb;\n}\nEXPORT_SYMBOL_GPL(vmbus_set_sc_create_callback);\n\nvoid vmbus_set_chn_rescind_callback(struct vmbus_channel *channel,\n\t\tvoid (*chn_rescind_cb)(struct vmbus_channel *))\n{\n\tchannel->chn_rescind_callback = chn_rescind_cb;\n}\nEXPORT_SYMBOL_GPL(vmbus_set_chn_rescind_callback);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}