{
  "module_name": "clk-rcg2.c",
  "hash_id": "7b44b61f5bf57c2626389d8806ff3a3575416f452681e31b80a9d95a93235dbd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/clk/qcom/clk-rcg2.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/bitops.h>\n#include <linux/err.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/clk-provider.h>\n#include <linux/delay.h>\n#include <linux/rational.h>\n#include <linux/regmap.h>\n#include <linux/math64.h>\n#include <linux/minmax.h>\n#include <linux/slab.h>\n\n#include <asm/div64.h>\n\n#include \"clk-rcg.h\"\n#include \"common.h\"\n\n#define CMD_REG\t\t\t0x0\n#define CMD_UPDATE\t\tBIT(0)\n#define CMD_ROOT_EN\t\tBIT(1)\n#define CMD_DIRTY_CFG\t\tBIT(4)\n#define CMD_DIRTY_N\t\tBIT(5)\n#define CMD_DIRTY_M\t\tBIT(6)\n#define CMD_DIRTY_D\t\tBIT(7)\n#define CMD_ROOT_OFF\t\tBIT(31)\n\n#define CFG_REG\t\t\t0x4\n#define CFG_SRC_DIV_SHIFT\t0\n#define CFG_SRC_SEL_SHIFT\t8\n#define CFG_SRC_SEL_MASK\t(0x7 << CFG_SRC_SEL_SHIFT)\n#define CFG_MODE_SHIFT\t\t12\n#define CFG_MODE_MASK\t\t(0x3 << CFG_MODE_SHIFT)\n#define CFG_MODE_DUAL_EDGE\t(0x2 << CFG_MODE_SHIFT)\n#define CFG_HW_CLK_CTRL_MASK\tBIT(20)\n\n#define M_REG\t\t\t0x8\n#define N_REG\t\t\t0xc\n#define D_REG\t\t\t0x10\n\n#define RCG_CFG_OFFSET(rcg)\t((rcg)->cmd_rcgr + (rcg)->cfg_off + CFG_REG)\n#define RCG_M_OFFSET(rcg)\t((rcg)->cmd_rcgr + (rcg)->cfg_off + M_REG)\n#define RCG_N_OFFSET(rcg)\t((rcg)->cmd_rcgr + (rcg)->cfg_off + N_REG)\n#define RCG_D_OFFSET(rcg)\t((rcg)->cmd_rcgr + (rcg)->cfg_off + D_REG)\n\n \n#define MAX_PERF_LEVEL\t\t8\n#define SE_CMD_DFSR_OFFSET\t0x14\n#define SE_CMD_DFS_EN\t\tBIT(0)\n#define SE_PERF_DFSR(level)\t(0x1c + 0x4 * (level))\n#define SE_PERF_M_DFSR(level)\t(0x5c + 0x4 * (level))\n#define SE_PERF_N_DFSR(level)\t(0x9c + 0x4 * (level))\n\nenum freq_policy {\n\tFLOOR,\n\tCEIL,\n};\n\nstatic int clk_rcg2_is_enabled(struct clk_hw *hw)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tu32 cmd;\n\tint ret;\n\n\tret = regmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + CMD_REG, &cmd);\n\tif (ret)\n\t\treturn ret;\n\n\treturn (cmd & CMD_ROOT_OFF) == 0;\n}\n\nstatic u8 __clk_rcg2_get_parent(struct clk_hw *hw, u32 cfg)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tint num_parents = clk_hw_get_num_parents(hw);\n\tint i;\n\n\tcfg &= CFG_SRC_SEL_MASK;\n\tcfg >>= CFG_SRC_SEL_SHIFT;\n\n\tfor (i = 0; i < num_parents; i++)\n\t\tif (cfg == rcg->parent_map[i].cfg)\n\t\t\treturn i;\n\n\tpr_debug(\"%s: Clock %s has invalid parent, using default.\\n\",\n\t\t __func__, clk_hw_get_name(hw));\n\treturn 0;\n}\n\nstatic u8 clk_rcg2_get_parent(struct clk_hw *hw)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tu32 cfg;\n\tint ret;\n\n\tret = regmap_read(rcg->clkr.regmap, RCG_CFG_OFFSET(rcg), &cfg);\n\tif (ret) {\n\t\tpr_debug(\"%s: Unable to read CFG register for %s\\n\",\n\t\t\t __func__, clk_hw_get_name(hw));\n\t\treturn 0;\n\t}\n\n\treturn __clk_rcg2_get_parent(hw, cfg);\n}\n\nstatic int update_config(struct clk_rcg2 *rcg)\n{\n\tint count, ret;\n\tu32 cmd;\n\tstruct clk_hw *hw = &rcg->clkr.hw;\n\tconst char *name = clk_hw_get_name(hw);\n\n\tret = regmap_update_bits(rcg->clkr.regmap, rcg->cmd_rcgr + CMD_REG,\n\t\t\t\t CMD_UPDATE, CMD_UPDATE);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tfor (count = 500; count > 0; count--) {\n\t\tret = regmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + CMD_REG, &cmd);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (!(cmd & CMD_UPDATE))\n\t\t\treturn 0;\n\t\tudelay(1);\n\t}\n\n\tWARN(1, \"%s: rcg didn't update its configuration.\", name);\n\treturn -EBUSY;\n}\n\nstatic int clk_rcg2_set_parent(struct clk_hw *hw, u8 index)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tint ret;\n\tu32 cfg = rcg->parent_map[index].cfg << CFG_SRC_SEL_SHIFT;\n\n\tret = regmap_update_bits(rcg->clkr.regmap, RCG_CFG_OFFSET(rcg),\n\t\t\t\t CFG_SRC_SEL_MASK, cfg);\n\tif (ret)\n\t\treturn ret;\n\n\treturn update_config(rcg);\n}\n\n \nstatic unsigned long\ncalc_rate(unsigned long rate, u32 m, u32 n, u32 mode, u32 hid_div)\n{\n\tif (hid_div)\n\t\trate = mult_frac(rate, 2, hid_div + 1);\n\n\tif (mode)\n\t\trate = mult_frac(rate, m, n);\n\n\treturn rate;\n}\n\nstatic unsigned long\n__clk_rcg2_recalc_rate(struct clk_hw *hw, unsigned long parent_rate, u32 cfg)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tu32 hid_div, m = 0, n = 0, mode = 0, mask;\n\n\tif (rcg->mnd_width) {\n\t\tmask = BIT(rcg->mnd_width) - 1;\n\t\tregmap_read(rcg->clkr.regmap, RCG_M_OFFSET(rcg), &m);\n\t\tm &= mask;\n\t\tregmap_read(rcg->clkr.regmap, RCG_N_OFFSET(rcg), &n);\n\t\tn =  ~n;\n\t\tn &= mask;\n\t\tn += m;\n\t\tmode = cfg & CFG_MODE_MASK;\n\t\tmode >>= CFG_MODE_SHIFT;\n\t}\n\n\tmask = BIT(rcg->hid_width) - 1;\n\thid_div = cfg >> CFG_SRC_DIV_SHIFT;\n\thid_div &= mask;\n\n\treturn calc_rate(parent_rate, m, n, mode, hid_div);\n}\n\nstatic unsigned long\nclk_rcg2_recalc_rate(struct clk_hw *hw, unsigned long parent_rate)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tu32 cfg;\n\n\tregmap_read(rcg->clkr.regmap, RCG_CFG_OFFSET(rcg), &cfg);\n\n\treturn __clk_rcg2_recalc_rate(hw, parent_rate, cfg);\n}\n\nstatic int _freq_tbl_determine_rate(struct clk_hw *hw, const struct freq_tbl *f,\n\t\t\t\t    struct clk_rate_request *req,\n\t\t\t\t    enum freq_policy policy)\n{\n\tunsigned long clk_flags, rate = req->rate;\n\tstruct clk_hw *p;\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tint index;\n\n\tswitch (policy) {\n\tcase FLOOR:\n\t\tf = qcom_find_freq_floor(f, rate);\n\t\tbreak;\n\tcase CEIL:\n\t\tf = qcom_find_freq(f, rate);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (!f)\n\t\treturn -EINVAL;\n\n\tindex = qcom_find_src_index(hw, rcg->parent_map, f->src);\n\tif (index < 0)\n\t\treturn index;\n\n\tclk_flags = clk_hw_get_flags(hw);\n\tp = clk_hw_get_parent_by_index(hw, index);\n\tif (!p)\n\t\treturn -EINVAL;\n\n\tif (clk_flags & CLK_SET_RATE_PARENT) {\n\t\trate = f->freq;\n\t\tif (f->pre_div) {\n\t\t\tif (!rate)\n\t\t\t\trate = req->rate;\n\t\t\trate /= 2;\n\t\t\trate *= f->pre_div + 1;\n\t\t}\n\n\t\tif (f->n) {\n\t\t\tu64 tmp = rate;\n\t\t\ttmp = tmp * f->n;\n\t\t\tdo_div(tmp, f->m);\n\t\t\trate = tmp;\n\t\t}\n\t} else {\n\t\trate =  clk_hw_get_rate(p);\n\t}\n\treq->best_parent_hw = p;\n\treq->best_parent_rate = rate;\n\treq->rate = f->freq;\n\n\treturn 0;\n}\n\nstatic int clk_rcg2_determine_rate(struct clk_hw *hw,\n\t\t\t\t   struct clk_rate_request *req)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\n\treturn _freq_tbl_determine_rate(hw, rcg->freq_tbl, req, CEIL);\n}\n\nstatic int clk_rcg2_determine_floor_rate(struct clk_hw *hw,\n\t\t\t\t\t struct clk_rate_request *req)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\n\treturn _freq_tbl_determine_rate(hw, rcg->freq_tbl, req, FLOOR);\n}\n\nstatic int __clk_rcg2_configure(struct clk_rcg2 *rcg, const struct freq_tbl *f,\n\t\t\t\tu32 *_cfg)\n{\n\tu32 cfg, mask, d_val, not2d_val, n_minus_m;\n\tstruct clk_hw *hw = &rcg->clkr.hw;\n\tint ret, index = qcom_find_src_index(hw, rcg->parent_map, f->src);\n\n\tif (index < 0)\n\t\treturn index;\n\n\tif (rcg->mnd_width && f->n) {\n\t\tmask = BIT(rcg->mnd_width) - 1;\n\t\tret = regmap_update_bits(rcg->clkr.regmap,\n\t\t\t\tRCG_M_OFFSET(rcg), mask, f->m);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = regmap_update_bits(rcg->clkr.regmap,\n\t\t\t\tRCG_N_OFFSET(rcg), mask, ~(f->n - f->m));\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t \n\t\td_val = f->n;\n\n\t\tn_minus_m = f->n - f->m;\n\t\tn_minus_m *= 2;\n\n\t\td_val = clamp_t(u32, d_val, f->m, n_minus_m);\n\t\tnot2d_val = ~d_val & mask;\n\n\t\tret = regmap_update_bits(rcg->clkr.regmap,\n\t\t\t\tRCG_D_OFFSET(rcg), mask, not2d_val);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tmask = BIT(rcg->hid_width) - 1;\n\tmask |= CFG_SRC_SEL_MASK | CFG_MODE_MASK | CFG_HW_CLK_CTRL_MASK;\n\tcfg = f->pre_div << CFG_SRC_DIV_SHIFT;\n\tcfg |= rcg->parent_map[index].cfg << CFG_SRC_SEL_SHIFT;\n\tif (rcg->mnd_width && f->n && (f->m != f->n))\n\t\tcfg |= CFG_MODE_DUAL_EDGE;\n\tif (rcg->hw_clk_ctrl)\n\t\tcfg |= CFG_HW_CLK_CTRL_MASK;\n\n\t*_cfg &= ~mask;\n\t*_cfg |= cfg;\n\n\treturn 0;\n}\n\nstatic int clk_rcg2_configure(struct clk_rcg2 *rcg, const struct freq_tbl *f)\n{\n\tu32 cfg;\n\tint ret;\n\n\tret = regmap_read(rcg->clkr.regmap, RCG_CFG_OFFSET(rcg), &cfg);\n\tif (ret)\n\t\treturn ret;\n\n\tret = __clk_rcg2_configure(rcg, f, &cfg);\n\tif (ret)\n\t\treturn ret;\n\n\tret = regmap_write(rcg->clkr.regmap, RCG_CFG_OFFSET(rcg), cfg);\n\tif (ret)\n\t\treturn ret;\n\n\treturn update_config(rcg);\n}\n\nstatic int __clk_rcg2_set_rate(struct clk_hw *hw, unsigned long rate,\n\t\t\t       enum freq_policy policy)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tconst struct freq_tbl *f;\n\n\tswitch (policy) {\n\tcase FLOOR:\n\t\tf = qcom_find_freq_floor(rcg->freq_tbl, rate);\n\t\tbreak;\n\tcase CEIL:\n\t\tf = qcom_find_freq(rcg->freq_tbl, rate);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (!f)\n\t\treturn -EINVAL;\n\n\treturn clk_rcg2_configure(rcg, f);\n}\n\nstatic int clk_rcg2_set_rate(struct clk_hw *hw, unsigned long rate,\n\t\t\t    unsigned long parent_rate)\n{\n\treturn __clk_rcg2_set_rate(hw, rate, CEIL);\n}\n\nstatic int clk_rcg2_set_floor_rate(struct clk_hw *hw, unsigned long rate,\n\t\t\t\t   unsigned long parent_rate)\n{\n\treturn __clk_rcg2_set_rate(hw, rate, FLOOR);\n}\n\nstatic int clk_rcg2_set_rate_and_parent(struct clk_hw *hw,\n\t\tunsigned long rate, unsigned long parent_rate, u8 index)\n{\n\treturn __clk_rcg2_set_rate(hw, rate, CEIL);\n}\n\nstatic int clk_rcg2_set_floor_rate_and_parent(struct clk_hw *hw,\n\t\tunsigned long rate, unsigned long parent_rate, u8 index)\n{\n\treturn __clk_rcg2_set_rate(hw, rate, FLOOR);\n}\n\nstatic int clk_rcg2_get_duty_cycle(struct clk_hw *hw, struct clk_duty *duty)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tu32 notn_m, n, m, d, not2d, mask;\n\n\tif (!rcg->mnd_width) {\n\t\t \n\t\tduty->num = 1;\n\t\tduty->den = 2;\n\t\treturn 0;\n\t}\n\n\tregmap_read(rcg->clkr.regmap, RCG_D_OFFSET(rcg), &not2d);\n\tregmap_read(rcg->clkr.regmap, RCG_M_OFFSET(rcg), &m);\n\tregmap_read(rcg->clkr.regmap, RCG_N_OFFSET(rcg), &notn_m);\n\n\tif (!not2d && !m && !notn_m) {\n\t\t \n\t\tduty->num = 1;\n\t\tduty->den = 2;\n\t\treturn 0;\n\t}\n\n\tmask = BIT(rcg->mnd_width) - 1;\n\n\td = ~(not2d) & mask;\n\td = DIV_ROUND_CLOSEST(d, 2);\n\n\tn = (~(notn_m) + m) & mask;\n\n\tduty->num = d;\n\tduty->den = n;\n\n\treturn 0;\n}\n\nstatic int clk_rcg2_set_duty_cycle(struct clk_hw *hw, struct clk_duty *duty)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tu32 notn_m, n, m, d, not2d, mask, duty_per, cfg;\n\tint ret;\n\n\t \n\tif (!rcg->mnd_width)\n\t\treturn -EINVAL;\n\n\tmask = BIT(rcg->mnd_width) - 1;\n\n\tregmap_read(rcg->clkr.regmap, RCG_N_OFFSET(rcg), &notn_m);\n\tregmap_read(rcg->clkr.regmap, RCG_M_OFFSET(rcg), &m);\n\tregmap_read(rcg->clkr.regmap, RCG_CFG_OFFSET(rcg), &cfg);\n\n\t \n\tif (!(cfg & CFG_MODE_MASK))\n\t\treturn -EINVAL;\n\n\tn = (~(notn_m) + m) & mask;\n\n\tduty_per = (duty->num * 100) / duty->den;\n\n\t \n\td = DIV_ROUND_CLOSEST(n * duty_per * 2, 100);\n\n\t \n\td = clamp_val(d, 1, mask);\n\n\tif ((d / 2) > (n - m))\n\t\td = (n - m) * 2;\n\telse if ((d / 2) < (m / 2))\n\t\td = m;\n\n\tnot2d = ~d & mask;\n\n\tret = regmap_update_bits(rcg->clkr.regmap, RCG_D_OFFSET(rcg), mask,\n\t\t\t\t not2d);\n\tif (ret)\n\t\treturn ret;\n\n\treturn update_config(rcg);\n}\n\nconst struct clk_ops clk_rcg2_ops = {\n\t.is_enabled = clk_rcg2_is_enabled,\n\t.get_parent = clk_rcg2_get_parent,\n\t.set_parent = clk_rcg2_set_parent,\n\t.recalc_rate = clk_rcg2_recalc_rate,\n\t.determine_rate = clk_rcg2_determine_rate,\n\t.set_rate = clk_rcg2_set_rate,\n\t.set_rate_and_parent = clk_rcg2_set_rate_and_parent,\n\t.get_duty_cycle = clk_rcg2_get_duty_cycle,\n\t.set_duty_cycle = clk_rcg2_set_duty_cycle,\n};\nEXPORT_SYMBOL_GPL(clk_rcg2_ops);\n\nconst struct clk_ops clk_rcg2_floor_ops = {\n\t.is_enabled = clk_rcg2_is_enabled,\n\t.get_parent = clk_rcg2_get_parent,\n\t.set_parent = clk_rcg2_set_parent,\n\t.recalc_rate = clk_rcg2_recalc_rate,\n\t.determine_rate = clk_rcg2_determine_floor_rate,\n\t.set_rate = clk_rcg2_set_floor_rate,\n\t.set_rate_and_parent = clk_rcg2_set_floor_rate_and_parent,\n\t.get_duty_cycle = clk_rcg2_get_duty_cycle,\n\t.set_duty_cycle = clk_rcg2_set_duty_cycle,\n};\nEXPORT_SYMBOL_GPL(clk_rcg2_floor_ops);\n\nconst struct clk_ops clk_rcg2_mux_closest_ops = {\n\t.determine_rate = __clk_mux_determine_rate_closest,\n\t.get_parent = clk_rcg2_get_parent,\n\t.set_parent = clk_rcg2_set_parent,\n};\nEXPORT_SYMBOL_GPL(clk_rcg2_mux_closest_ops);\n\nstruct frac_entry {\n\tint num;\n\tint den;\n};\n\nstatic const struct frac_entry frac_table_675m[] = {\t \n\t{ 52, 295 },\t \n\t{ 11, 57 },\t \n\t{ 63, 307 },\t \n\t{ 11, 50 },\t \n\t{ 47, 206 },\t \n\t{ 31, 100 },\t \n\t{ 107, 269 },\t \n\t{ },\n};\n\nstatic struct frac_entry frac_table_810m[] = {  \n\t{ 31, 211 },\t \n\t{ 32, 199 },\t \n\t{ 63, 307 },\t \n\t{ 11, 60 },\t \n\t{ 50, 263 },\t \n\t{ 31, 120 },\t \n\t{ 119, 359 },\t \n\t{ },\n};\n\nstatic int clk_edp_pixel_set_rate(struct clk_hw *hw, unsigned long rate,\n\t\t\t      unsigned long parent_rate)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tstruct freq_tbl f = *rcg->freq_tbl;\n\tconst struct frac_entry *frac;\n\tint delta = 100000;\n\ts64 src_rate = parent_rate;\n\ts64 request;\n\tu32 mask = BIT(rcg->hid_width) - 1;\n\tu32 hid_div;\n\n\tif (src_rate == 810000000)\n\t\tfrac = frac_table_810m;\n\telse\n\t\tfrac = frac_table_675m;\n\n\tfor (; frac->num; frac++) {\n\t\trequest = rate;\n\t\trequest *= frac->den;\n\t\trequest = div_s64(request, frac->num);\n\t\tif ((src_rate < (request - delta)) ||\n\t\t    (src_rate > (request + delta)))\n\t\t\tcontinue;\n\n\t\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG,\n\t\t\t\t&hid_div);\n\t\tf.pre_div = hid_div;\n\t\tf.pre_div >>= CFG_SRC_DIV_SHIFT;\n\t\tf.pre_div &= mask;\n\t\tf.m = frac->num;\n\t\tf.n = frac->den;\n\n\t\treturn clk_rcg2_configure(rcg, &f);\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int clk_edp_pixel_set_rate_and_parent(struct clk_hw *hw,\n\t\tunsigned long rate, unsigned long parent_rate, u8 index)\n{\n\t \n\treturn clk_edp_pixel_set_rate(hw, rate, parent_rate);\n}\n\nstatic int clk_edp_pixel_determine_rate(struct clk_hw *hw,\n\t\t\t\t\tstruct clk_rate_request *req)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tconst struct freq_tbl *f = rcg->freq_tbl;\n\tconst struct frac_entry *frac;\n\tint delta = 100000;\n\ts64 request;\n\tu32 mask = BIT(rcg->hid_width) - 1;\n\tu32 hid_div;\n\tint index = qcom_find_src_index(hw, rcg->parent_map, f->src);\n\n\t \n\treq->best_parent_hw = clk_hw_get_parent_by_index(hw, index);\n\treq->best_parent_rate = clk_hw_get_rate(req->best_parent_hw);\n\n\tif (req->best_parent_rate == 810000000)\n\t\tfrac = frac_table_810m;\n\telse\n\t\tfrac = frac_table_675m;\n\n\tfor (; frac->num; frac++) {\n\t\trequest = req->rate;\n\t\trequest *= frac->den;\n\t\trequest = div_s64(request, frac->num);\n\t\tif ((req->best_parent_rate < (request - delta)) ||\n\t\t    (req->best_parent_rate > (request + delta)))\n\t\t\tcontinue;\n\n\t\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG,\n\t\t\t\t&hid_div);\n\t\thid_div >>= CFG_SRC_DIV_SHIFT;\n\t\thid_div &= mask;\n\n\t\treq->rate = calc_rate(req->best_parent_rate,\n\t\t\t\t      frac->num, frac->den,\n\t\t\t\t      !!frac->den, hid_div);\n\t\treturn 0;\n\t}\n\n\treturn -EINVAL;\n}\n\nconst struct clk_ops clk_edp_pixel_ops = {\n\t.is_enabled = clk_rcg2_is_enabled,\n\t.get_parent = clk_rcg2_get_parent,\n\t.set_parent = clk_rcg2_set_parent,\n\t.recalc_rate = clk_rcg2_recalc_rate,\n\t.set_rate = clk_edp_pixel_set_rate,\n\t.set_rate_and_parent = clk_edp_pixel_set_rate_and_parent,\n\t.determine_rate = clk_edp_pixel_determine_rate,\n};\nEXPORT_SYMBOL_GPL(clk_edp_pixel_ops);\n\nstatic int clk_byte_determine_rate(struct clk_hw *hw,\n\t\t\t\t   struct clk_rate_request *req)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tconst struct freq_tbl *f = rcg->freq_tbl;\n\tint index = qcom_find_src_index(hw, rcg->parent_map, f->src);\n\tunsigned long parent_rate, div;\n\tu32 mask = BIT(rcg->hid_width) - 1;\n\tstruct clk_hw *p;\n\n\tif (req->rate == 0)\n\t\treturn -EINVAL;\n\n\treq->best_parent_hw = p = clk_hw_get_parent_by_index(hw, index);\n\treq->best_parent_rate = parent_rate = clk_hw_round_rate(p, req->rate);\n\n\tdiv = DIV_ROUND_UP((2 * parent_rate), req->rate) - 1;\n\tdiv = min_t(u32, div, mask);\n\n\treq->rate = calc_rate(parent_rate, 0, 0, 0, div);\n\n\treturn 0;\n}\n\nstatic int clk_byte_set_rate(struct clk_hw *hw, unsigned long rate,\n\t\t\t unsigned long parent_rate)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tstruct freq_tbl f = *rcg->freq_tbl;\n\tunsigned long div;\n\tu32 mask = BIT(rcg->hid_width) - 1;\n\n\tdiv = DIV_ROUND_UP((2 * parent_rate), rate) - 1;\n\tdiv = min_t(u32, div, mask);\n\n\tf.pre_div = div;\n\n\treturn clk_rcg2_configure(rcg, &f);\n}\n\nstatic int clk_byte_set_rate_and_parent(struct clk_hw *hw,\n\t\tunsigned long rate, unsigned long parent_rate, u8 index)\n{\n\t \n\treturn clk_byte_set_rate(hw, rate, parent_rate);\n}\n\nconst struct clk_ops clk_byte_ops = {\n\t.is_enabled = clk_rcg2_is_enabled,\n\t.get_parent = clk_rcg2_get_parent,\n\t.set_parent = clk_rcg2_set_parent,\n\t.recalc_rate = clk_rcg2_recalc_rate,\n\t.set_rate = clk_byte_set_rate,\n\t.set_rate_and_parent = clk_byte_set_rate_and_parent,\n\t.determine_rate = clk_byte_determine_rate,\n};\nEXPORT_SYMBOL_GPL(clk_byte_ops);\n\nstatic int clk_byte2_determine_rate(struct clk_hw *hw,\n\t\t\t\t    struct clk_rate_request *req)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tunsigned long parent_rate, div;\n\tu32 mask = BIT(rcg->hid_width) - 1;\n\tstruct clk_hw *p;\n\tunsigned long rate = req->rate;\n\n\tif (rate == 0)\n\t\treturn -EINVAL;\n\n\tp = req->best_parent_hw;\n\treq->best_parent_rate = parent_rate = clk_hw_round_rate(p, rate);\n\n\tdiv = DIV_ROUND_UP((2 * parent_rate), rate) - 1;\n\tdiv = min_t(u32, div, mask);\n\n\treq->rate = calc_rate(parent_rate, 0, 0, 0, div);\n\n\treturn 0;\n}\n\nstatic int clk_byte2_set_rate(struct clk_hw *hw, unsigned long rate,\n\t\t\t unsigned long parent_rate)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tstruct freq_tbl f = { 0 };\n\tunsigned long div;\n\tint i, num_parents = clk_hw_get_num_parents(hw);\n\tu32 mask = BIT(rcg->hid_width) - 1;\n\tu32 cfg;\n\n\tdiv = DIV_ROUND_UP((2 * parent_rate), rate) - 1;\n\tdiv = min_t(u32, div, mask);\n\n\tf.pre_div = div;\n\n\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG, &cfg);\n\tcfg &= CFG_SRC_SEL_MASK;\n\tcfg >>= CFG_SRC_SEL_SHIFT;\n\n\tfor (i = 0; i < num_parents; i++) {\n\t\tif (cfg == rcg->parent_map[i].cfg) {\n\t\t\tf.src = rcg->parent_map[i].src;\n\t\t\treturn clk_rcg2_configure(rcg, &f);\n\t\t}\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int clk_byte2_set_rate_and_parent(struct clk_hw *hw,\n\t\tunsigned long rate, unsigned long parent_rate, u8 index)\n{\n\t \n\treturn clk_byte2_set_rate(hw, rate, parent_rate);\n}\n\nconst struct clk_ops clk_byte2_ops = {\n\t.is_enabled = clk_rcg2_is_enabled,\n\t.get_parent = clk_rcg2_get_parent,\n\t.set_parent = clk_rcg2_set_parent,\n\t.recalc_rate = clk_rcg2_recalc_rate,\n\t.set_rate = clk_byte2_set_rate,\n\t.set_rate_and_parent = clk_byte2_set_rate_and_parent,\n\t.determine_rate = clk_byte2_determine_rate,\n};\nEXPORT_SYMBOL_GPL(clk_byte2_ops);\n\nstatic const struct frac_entry frac_table_pixel[] = {\n\t{ 3, 8 },\n\t{ 2, 9 },\n\t{ 4, 9 },\n\t{ 1, 1 },\n\t{ 2, 3 },\n\t{ }\n};\n\nstatic int clk_pixel_determine_rate(struct clk_hw *hw,\n\t\t\t\t    struct clk_rate_request *req)\n{\n\tunsigned long request, src_rate;\n\tint delta = 100000;\n\tconst struct frac_entry *frac = frac_table_pixel;\n\n\tfor (; frac->num; frac++) {\n\t\trequest = (req->rate * frac->den) / frac->num;\n\n\t\tsrc_rate = clk_hw_round_rate(req->best_parent_hw, request);\n\t\tif ((src_rate < (request - delta)) ||\n\t\t\t(src_rate > (request + delta)))\n\t\t\tcontinue;\n\n\t\treq->best_parent_rate = src_rate;\n\t\treq->rate = (src_rate * frac->num) / frac->den;\n\t\treturn 0;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int clk_pixel_set_rate(struct clk_hw *hw, unsigned long rate,\n\t\tunsigned long parent_rate)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tstruct freq_tbl f = { 0 };\n\tconst struct frac_entry *frac = frac_table_pixel;\n\tunsigned long request;\n\tint delta = 100000;\n\tu32 mask = BIT(rcg->hid_width) - 1;\n\tu32 hid_div, cfg;\n\tint i, num_parents = clk_hw_get_num_parents(hw);\n\n\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG, &cfg);\n\tcfg &= CFG_SRC_SEL_MASK;\n\tcfg >>= CFG_SRC_SEL_SHIFT;\n\n\tfor (i = 0; i < num_parents; i++)\n\t\tif (cfg == rcg->parent_map[i].cfg) {\n\t\t\tf.src = rcg->parent_map[i].src;\n\t\t\tbreak;\n\t\t}\n\n\tfor (; frac->num; frac++) {\n\t\trequest = (rate * frac->den) / frac->num;\n\n\t\tif ((parent_rate < (request - delta)) ||\n\t\t\t(parent_rate > (request + delta)))\n\t\t\tcontinue;\n\n\t\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG,\n\t\t\t\t&hid_div);\n\t\tf.pre_div = hid_div;\n\t\tf.pre_div >>= CFG_SRC_DIV_SHIFT;\n\t\tf.pre_div &= mask;\n\t\tf.m = frac->num;\n\t\tf.n = frac->den;\n\n\t\treturn clk_rcg2_configure(rcg, &f);\n\t}\n\treturn -EINVAL;\n}\n\nstatic int clk_pixel_set_rate_and_parent(struct clk_hw *hw, unsigned long rate,\n\t\tunsigned long parent_rate, u8 index)\n{\n\treturn clk_pixel_set_rate(hw, rate, parent_rate);\n}\n\nconst struct clk_ops clk_pixel_ops = {\n\t.is_enabled = clk_rcg2_is_enabled,\n\t.get_parent = clk_rcg2_get_parent,\n\t.set_parent = clk_rcg2_set_parent,\n\t.recalc_rate = clk_rcg2_recalc_rate,\n\t.set_rate = clk_pixel_set_rate,\n\t.set_rate_and_parent = clk_pixel_set_rate_and_parent,\n\t.determine_rate = clk_pixel_determine_rate,\n};\nEXPORT_SYMBOL_GPL(clk_pixel_ops);\n\nstatic int clk_gfx3d_determine_rate(struct clk_hw *hw,\n\t\t\t\t    struct clk_rate_request *req)\n{\n\tstruct clk_rate_request parent_req = { .min_rate = 0, .max_rate = ULONG_MAX };\n\tstruct clk_rcg2_gfx3d *cgfx = to_clk_rcg2_gfx3d(hw);\n\tstruct clk_hw *xo, *p0, *p1, *p2;\n\tunsigned long p0_rate;\n\tu8 mux_div = cgfx->div;\n\tint ret;\n\n\tp0 = cgfx->hws[0];\n\tp1 = cgfx->hws[1];\n\tp2 = cgfx->hws[2];\n\t \n\tif (WARN_ON(!p0 || !p1 || !p2))\n\t\treturn -EINVAL;\n\n\txo = clk_hw_get_parent_by_index(hw, 0);\n\tif (req->rate == clk_hw_get_rate(xo)) {\n\t\treq->best_parent_hw = xo;\n\t\treturn 0;\n\t}\n\n\tif (mux_div == 0)\n\t\tmux_div = 1;\n\n\tparent_req.rate = req->rate * mux_div;\n\n\t \n\tp0_rate = clk_hw_get_rate(p0);\n\n\tif (parent_req.rate == p0_rate) {\n\t\treq->rate = req->best_parent_rate = p0_rate;\n\t\treq->best_parent_hw = p0;\n\t\treturn 0;\n\t}\n\n\tif (req->best_parent_hw == p0) {\n\t\t \n\t\tif (clk_hw_get_rate(p2) == parent_req.rate)\n\t\t\treq->best_parent_hw = p2;\n\t\telse\n\t\t\treq->best_parent_hw = p1;\n\t} else if (req->best_parent_hw == p2) {\n\t\treq->best_parent_hw = p1;\n\t} else {\n\t\treq->best_parent_hw = p2;\n\t}\n\n\tclk_hw_get_rate_range(req->best_parent_hw,\n\t\t\t      &parent_req.min_rate, &parent_req.max_rate);\n\n\tif (req->min_rate > parent_req.min_rate)\n\t\tparent_req.min_rate = req->min_rate;\n\n\tif (req->max_rate < parent_req.max_rate)\n\t\tparent_req.max_rate = req->max_rate;\n\n\tret = __clk_determine_rate(req->best_parent_hw, &parent_req);\n\tif (ret)\n\t\treturn ret;\n\n\treq->rate = req->best_parent_rate = parent_req.rate;\n\treq->rate /= mux_div;\n\n\treturn 0;\n}\n\nstatic int clk_gfx3d_set_rate_and_parent(struct clk_hw *hw, unsigned long rate,\n\t\tunsigned long parent_rate, u8 index)\n{\n\tstruct clk_rcg2_gfx3d *cgfx = to_clk_rcg2_gfx3d(hw);\n\tstruct clk_rcg2 *rcg = &cgfx->rcg;\n\tu32 cfg;\n\tint ret;\n\n\tcfg = rcg->parent_map[index].cfg << CFG_SRC_SEL_SHIFT;\n\t \n\tif (cgfx->div > 1)\n\t\tcfg |= ((2 * cgfx->div) - 1) << CFG_SRC_DIV_SHIFT;\n\n\tret = regmap_write(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG, cfg);\n\tif (ret)\n\t\treturn ret;\n\n\treturn update_config(rcg);\n}\n\nstatic int clk_gfx3d_set_rate(struct clk_hw *hw, unsigned long rate,\n\t\t\t      unsigned long parent_rate)\n{\n\t \n\treturn 0;\n}\n\nconst struct clk_ops clk_gfx3d_ops = {\n\t.is_enabled = clk_rcg2_is_enabled,\n\t.get_parent = clk_rcg2_get_parent,\n\t.set_parent = clk_rcg2_set_parent,\n\t.recalc_rate = clk_rcg2_recalc_rate,\n\t.set_rate = clk_gfx3d_set_rate,\n\t.set_rate_and_parent = clk_gfx3d_set_rate_and_parent,\n\t.determine_rate = clk_gfx3d_determine_rate,\n};\nEXPORT_SYMBOL_GPL(clk_gfx3d_ops);\n\nstatic int clk_rcg2_set_force_enable(struct clk_hw *hw)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tconst char *name = clk_hw_get_name(hw);\n\tint ret, count;\n\n\tret = regmap_update_bits(rcg->clkr.regmap, rcg->cmd_rcgr + CMD_REG,\n\t\t\t\t CMD_ROOT_EN, CMD_ROOT_EN);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tfor (count = 500; count > 0; count--) {\n\t\tif (clk_rcg2_is_enabled(hw))\n\t\t\treturn 0;\n\n\t\tudelay(1);\n\t}\n\n\tpr_err(\"%s: RCG did not turn on\\n\", name);\n\treturn -ETIMEDOUT;\n}\n\nstatic int clk_rcg2_clear_force_enable(struct clk_hw *hw)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\n\treturn regmap_update_bits(rcg->clkr.regmap, rcg->cmd_rcgr + CMD_REG,\n\t\t\t\t\tCMD_ROOT_EN, 0);\n}\n\nstatic int\nclk_rcg2_shared_force_enable_clear(struct clk_hw *hw, const struct freq_tbl *f)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tint ret;\n\n\tret = clk_rcg2_set_force_enable(hw);\n\tif (ret)\n\t\treturn ret;\n\n\tret = clk_rcg2_configure(rcg, f);\n\tif (ret)\n\t\treturn ret;\n\n\treturn clk_rcg2_clear_force_enable(hw);\n}\n\nstatic int clk_rcg2_shared_set_rate(struct clk_hw *hw, unsigned long rate,\n\t\t\t\t    unsigned long parent_rate)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tconst struct freq_tbl *f;\n\n\tf = qcom_find_freq(rcg->freq_tbl, rate);\n\tif (!f)\n\t\treturn -EINVAL;\n\n\t \n\tif (!clk_hw_is_enabled(hw))\n\t\treturn __clk_rcg2_configure(rcg, f, &rcg->parked_cfg);\n\n\treturn clk_rcg2_shared_force_enable_clear(hw, f);\n}\n\nstatic int clk_rcg2_shared_set_rate_and_parent(struct clk_hw *hw,\n\t\tunsigned long rate, unsigned long parent_rate, u8 index)\n{\n\treturn clk_rcg2_shared_set_rate(hw, rate, parent_rate);\n}\n\nstatic int clk_rcg2_shared_enable(struct clk_hw *hw)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tint ret;\n\n\t \n\tret = clk_rcg2_set_force_enable(hw);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = regmap_write(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG, rcg->parked_cfg);\n\tif (ret)\n\t\treturn ret;\n\n\tret = update_config(rcg);\n\tif (ret)\n\t\treturn ret;\n\n\treturn clk_rcg2_clear_force_enable(hw);\n}\n\nstatic void clk_rcg2_shared_disable(struct clk_hw *hw)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\n\t \n\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG, &rcg->parked_cfg);\n\n\t \n\tclk_rcg2_set_force_enable(hw);\n\n\tregmap_write(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG,\n\t\t     rcg->safe_src_index << CFG_SRC_SEL_SHIFT);\n\n\tupdate_config(rcg);\n\n\tclk_rcg2_clear_force_enable(hw);\n}\n\nstatic u8 clk_rcg2_shared_get_parent(struct clk_hw *hw)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\n\t \n\tif (!clk_hw_is_enabled(hw))\n\t\treturn __clk_rcg2_get_parent(hw, rcg->parked_cfg);\n\n\treturn clk_rcg2_get_parent(hw);\n}\n\nstatic int clk_rcg2_shared_set_parent(struct clk_hw *hw, u8 index)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\n\t \n\tif (!clk_hw_is_enabled(hw)) {\n\t\trcg->parked_cfg &= ~CFG_SRC_SEL_MASK;\n\t\trcg->parked_cfg |= rcg->parent_map[index].cfg << CFG_SRC_SEL_SHIFT;\n\n\t\treturn 0;\n\t}\n\n\treturn clk_rcg2_set_parent(hw, index);\n}\n\nstatic unsigned long\nclk_rcg2_shared_recalc_rate(struct clk_hw *hw, unsigned long parent_rate)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\n\t \n\tif (!clk_hw_is_enabled(hw))\n\t\treturn __clk_rcg2_recalc_rate(hw, parent_rate, rcg->parked_cfg);\n\n\treturn clk_rcg2_recalc_rate(hw, parent_rate);\n}\n\nconst struct clk_ops clk_rcg2_shared_ops = {\n\t.enable = clk_rcg2_shared_enable,\n\t.disable = clk_rcg2_shared_disable,\n\t.get_parent = clk_rcg2_shared_get_parent,\n\t.set_parent = clk_rcg2_shared_set_parent,\n\t.recalc_rate = clk_rcg2_shared_recalc_rate,\n\t.determine_rate = clk_rcg2_determine_rate,\n\t.set_rate = clk_rcg2_shared_set_rate,\n\t.set_rate_and_parent = clk_rcg2_shared_set_rate_and_parent,\n};\nEXPORT_SYMBOL_GPL(clk_rcg2_shared_ops);\n\n \nstatic void clk_rcg2_dfs_populate_freq(struct clk_hw *hw, unsigned int l,\n\t\t\t\t       struct freq_tbl *f)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tstruct clk_hw *p;\n\tunsigned long prate = 0;\n\tu32 val, mask, cfg, mode, src;\n\tint i, num_parents;\n\n\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + SE_PERF_DFSR(l), &cfg);\n\n\tmask = BIT(rcg->hid_width) - 1;\n\tf->pre_div = 1;\n\tif (cfg & mask)\n\t\tf->pre_div = cfg & mask;\n\n\tsrc = cfg & CFG_SRC_SEL_MASK;\n\tsrc >>= CFG_SRC_SEL_SHIFT;\n\n\tnum_parents = clk_hw_get_num_parents(hw);\n\tfor (i = 0; i < num_parents; i++) {\n\t\tif (src == rcg->parent_map[i].cfg) {\n\t\t\tf->src = rcg->parent_map[i].src;\n\t\t\tp = clk_hw_get_parent_by_index(&rcg->clkr.hw, i);\n\t\t\tprate = clk_hw_get_rate(p);\n\t\t}\n\t}\n\n\tmode = cfg & CFG_MODE_MASK;\n\tmode >>= CFG_MODE_SHIFT;\n\tif (mode) {\n\t\tmask = BIT(rcg->mnd_width) - 1;\n\t\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + SE_PERF_M_DFSR(l),\n\t\t\t    &val);\n\t\tval &= mask;\n\t\tf->m = val;\n\n\t\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + SE_PERF_N_DFSR(l),\n\t\t\t    &val);\n\t\tval = ~val;\n\t\tval &= mask;\n\t\tval += f->m;\n\t\tf->n = val;\n\t}\n\n\tf->freq = calc_rate(prate, f->m, f->n, mode, f->pre_div);\n}\n\nstatic int clk_rcg2_dfs_populate_freq_table(struct clk_rcg2 *rcg)\n{\n\tstruct freq_tbl *freq_tbl;\n\tint i;\n\n\t \n\tfreq_tbl = kcalloc(MAX_PERF_LEVEL + 1, sizeof(*freq_tbl), GFP_KERNEL);\n\tif (!freq_tbl)\n\t\treturn -ENOMEM;\n\trcg->freq_tbl = freq_tbl;\n\n\tfor (i = 0; i < MAX_PERF_LEVEL; i++)\n\t\tclk_rcg2_dfs_populate_freq(&rcg->clkr.hw, i, freq_tbl + i);\n\n\treturn 0;\n}\n\nstatic int clk_rcg2_dfs_determine_rate(struct clk_hw *hw,\n\t\t\t\t   struct clk_rate_request *req)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tint ret;\n\n\tif (!rcg->freq_tbl) {\n\t\tret = clk_rcg2_dfs_populate_freq_table(rcg);\n\t\tif (ret) {\n\t\t\tpr_err(\"Failed to update DFS tables for %s\\n\",\n\t\t\t\t\tclk_hw_get_name(hw));\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn clk_rcg2_determine_rate(hw, req);\n}\n\nstatic unsigned long\nclk_rcg2_dfs_recalc_rate(struct clk_hw *hw, unsigned long parent_rate)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tu32 level, mask, cfg, m = 0, n = 0, mode, pre_div;\n\n\tregmap_read(rcg->clkr.regmap,\n\t\t    rcg->cmd_rcgr + SE_CMD_DFSR_OFFSET, &level);\n\tlevel &= GENMASK(4, 1);\n\tlevel >>= 1;\n\n\tif (rcg->freq_tbl)\n\t\treturn rcg->freq_tbl[level].freq;\n\n\t \n\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + SE_PERF_DFSR(level),\n\t\t    &cfg);\n\n\tmask = BIT(rcg->hid_width) - 1;\n\tpre_div = 1;\n\tif (cfg & mask)\n\t\tpre_div = cfg & mask;\n\n\tmode = cfg & CFG_MODE_MASK;\n\tmode >>= CFG_MODE_SHIFT;\n\tif (mode) {\n\t\tmask = BIT(rcg->mnd_width) - 1;\n\t\tregmap_read(rcg->clkr.regmap,\n\t\t\t    rcg->cmd_rcgr + SE_PERF_M_DFSR(level), &m);\n\t\tm &= mask;\n\n\t\tregmap_read(rcg->clkr.regmap,\n\t\t\t    rcg->cmd_rcgr + SE_PERF_N_DFSR(level), &n);\n\t\tn = ~n;\n\t\tn &= mask;\n\t\tn += m;\n\t}\n\n\treturn calc_rate(parent_rate, m, n, mode, pre_div);\n}\n\nstatic const struct clk_ops clk_rcg2_dfs_ops = {\n\t.is_enabled = clk_rcg2_is_enabled,\n\t.get_parent = clk_rcg2_get_parent,\n\t.determine_rate = clk_rcg2_dfs_determine_rate,\n\t.recalc_rate = clk_rcg2_dfs_recalc_rate,\n};\n\nstatic int clk_rcg2_enable_dfs(const struct clk_rcg_dfs_data *data,\n\t\t\t       struct regmap *regmap)\n{\n\tstruct clk_rcg2 *rcg = data->rcg;\n\tstruct clk_init_data *init = data->init;\n\tu32 val;\n\tint ret;\n\n\tret = regmap_read(regmap, rcg->cmd_rcgr + SE_CMD_DFSR_OFFSET, &val);\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tif (!(val & SE_CMD_DFS_EN))\n\t\treturn 0;\n\n\t \n\tinit->flags |= CLK_GET_RATE_NOCACHE;\n\tinit->ops = &clk_rcg2_dfs_ops;\n\n\trcg->freq_tbl = NULL;\n\n\treturn 0;\n}\n\nint qcom_cc_register_rcg_dfs(struct regmap *regmap,\n\t\t\t     const struct clk_rcg_dfs_data *rcgs, size_t len)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < len; i++) {\n\t\tret = clk_rcg2_enable_dfs(&rcgs[i], regmap);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(qcom_cc_register_rcg_dfs);\n\nstatic int clk_rcg2_dp_set_rate(struct clk_hw *hw, unsigned long rate,\n\t\t\tunsigned long parent_rate)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tstruct freq_tbl f = { 0 };\n\tu32 mask = BIT(rcg->hid_width) - 1;\n\tu32 hid_div, cfg;\n\tint i, num_parents = clk_hw_get_num_parents(hw);\n\tunsigned long num, den;\n\n\trational_best_approximation(parent_rate, rate,\n\t\t\tGENMASK(rcg->mnd_width - 1, 0),\n\t\t\tGENMASK(rcg->mnd_width - 1, 0), &den, &num);\n\n\tif (!num || !den)\n\t\treturn -EINVAL;\n\n\tregmap_read(rcg->clkr.regmap, rcg->cmd_rcgr + CFG_REG, &cfg);\n\thid_div = cfg;\n\tcfg &= CFG_SRC_SEL_MASK;\n\tcfg >>= CFG_SRC_SEL_SHIFT;\n\n\tfor (i = 0; i < num_parents; i++) {\n\t\tif (cfg == rcg->parent_map[i].cfg) {\n\t\t\tf.src = rcg->parent_map[i].src;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tf.pre_div = hid_div;\n\tf.pre_div >>= CFG_SRC_DIV_SHIFT;\n\tf.pre_div &= mask;\n\n\tif (num != den) {\n\t\tf.m = num;\n\t\tf.n = den;\n\t} else {\n\t\tf.m = 0;\n\t\tf.n = 0;\n\t}\n\n\treturn clk_rcg2_configure(rcg, &f);\n}\n\nstatic int clk_rcg2_dp_set_rate_and_parent(struct clk_hw *hw,\n\t\tunsigned long rate, unsigned long parent_rate, u8 index)\n{\n\treturn clk_rcg2_dp_set_rate(hw, rate, parent_rate);\n}\n\nstatic int clk_rcg2_dp_determine_rate(struct clk_hw *hw,\n\t\t\t\tstruct clk_rate_request *req)\n{\n\tstruct clk_rcg2 *rcg = to_clk_rcg2(hw);\n\tunsigned long num, den;\n\tu64 tmp;\n\n\t \n\trational_best_approximation(req->best_parent_rate, req->rate,\n\t\t\tGENMASK(rcg->mnd_width - 1, 0),\n\t\t\tGENMASK(rcg->mnd_width - 1, 0), &den, &num);\n\n\tif (!num || !den)\n\t\treturn -EINVAL;\n\n\ttmp = req->best_parent_rate * num;\n\tdo_div(tmp, den);\n\treq->rate = tmp;\n\n\treturn 0;\n}\n\nconst struct clk_ops clk_dp_ops = {\n\t.is_enabled = clk_rcg2_is_enabled,\n\t.get_parent = clk_rcg2_get_parent,\n\t.set_parent = clk_rcg2_set_parent,\n\t.recalc_rate = clk_rcg2_recalc_rate,\n\t.set_rate = clk_rcg2_dp_set_rate,\n\t.set_rate_and_parent = clk_rcg2_dp_set_rate_and_parent,\n\t.determine_rate = clk_rcg2_dp_determine_rate,\n};\nEXPORT_SYMBOL_GPL(clk_dp_ops);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}