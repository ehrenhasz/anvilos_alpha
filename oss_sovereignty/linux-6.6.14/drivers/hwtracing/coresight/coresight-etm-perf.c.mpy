{
  "module_name": "coresight-etm-perf.c",
  "hash_id": "e48d2e28b07145828d3d5e6a258a7addb6662f444a735f875bc73bd5cead6f19",
  "original_prompt": "Ingested from linux-6.6.14/drivers/hwtracing/coresight/coresight-etm-perf.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/coresight.h>\n#include <linux/coresight-pmu.h>\n#include <linux/cpumask.h>\n#include <linux/device.h>\n#include <linux/list.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/perf_event.h>\n#include <linux/percpu-defs.h>\n#include <linux/slab.h>\n#include <linux/stringhash.h>\n#include <linux/types.h>\n#include <linux/workqueue.h>\n\n#include \"coresight-config.h\"\n#include \"coresight-etm-perf.h\"\n#include \"coresight-priv.h\"\n#include \"coresight-syscfg.h\"\n#include \"coresight-trace-id.h\"\n\nstatic struct pmu etm_pmu;\nstatic bool etm_perf_up;\n\n \nstruct etm_ctxt {\n\tstruct perf_output_handle handle;\n\tstruct etm_event_data *event_data;\n};\n\nstatic DEFINE_PER_CPU(struct etm_ctxt, etm_ctxt);\nstatic DEFINE_PER_CPU(struct coresight_device *, csdev_src);\n\n \nPMU_FORMAT_ATTR(branch_broadcast, \"config:\"__stringify(ETM_OPT_BRANCH_BROADCAST));\nPMU_FORMAT_ATTR(cycacc,\t\t\"config:\" __stringify(ETM_OPT_CYCACC));\n \nPMU_FORMAT_ATTR(contextid1,\t\"config:\" __stringify(ETM_OPT_CTXTID));\n \nPMU_FORMAT_ATTR(contextid2,\t\"config:\" __stringify(ETM_OPT_CTXTID2));\nPMU_FORMAT_ATTR(timestamp,\t\"config:\" __stringify(ETM_OPT_TS));\nPMU_FORMAT_ATTR(retstack,\t\"config:\" __stringify(ETM_OPT_RETSTK));\n \nPMU_FORMAT_ATTR(preset,\t\t\"config:0-3\");\n \nPMU_FORMAT_ATTR(sinkid,\t\t\"config2:0-31\");\n \nPMU_FORMAT_ATTR(configid,\t\"config2:32-63\");\n\n\n \nstatic ssize_t format_attr_contextid_show(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  char *page)\n{\n\tint pid_fmt = ETM_OPT_CTXTID;\n\n#if IS_ENABLED(CONFIG_CORESIGHT_SOURCE_ETM4X)\n\tpid_fmt = is_kernel_in_hyp_mode() ? ETM_OPT_CTXTID2 : ETM_OPT_CTXTID;\n#endif\n\treturn sprintf(page, \"config:%d\\n\", pid_fmt);\n}\n\nstatic struct device_attribute format_attr_contextid =\n\t__ATTR(contextid, 0444, format_attr_contextid_show, NULL);\n\nstatic struct attribute *etm_config_formats_attr[] = {\n\t&format_attr_cycacc.attr,\n\t&format_attr_contextid.attr,\n\t&format_attr_contextid1.attr,\n\t&format_attr_contextid2.attr,\n\t&format_attr_timestamp.attr,\n\t&format_attr_retstack.attr,\n\t&format_attr_sinkid.attr,\n\t&format_attr_preset.attr,\n\t&format_attr_configid.attr,\n\t&format_attr_branch_broadcast.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group etm_pmu_format_group = {\n\t.name   = \"format\",\n\t.attrs  = etm_config_formats_attr,\n};\n\nstatic struct attribute *etm_config_sinks_attr[] = {\n\tNULL,\n};\n\nstatic const struct attribute_group etm_pmu_sinks_group = {\n\t.name   = \"sinks\",\n\t.attrs  = etm_config_sinks_attr,\n};\n\nstatic struct attribute *etm_config_events_attr[] = {\n\tNULL,\n};\n\nstatic const struct attribute_group etm_pmu_events_group = {\n\t.name   = \"events\",\n\t.attrs  = etm_config_events_attr,\n};\n\nstatic const struct attribute_group *etm_pmu_attr_groups[] = {\n\t&etm_pmu_format_group,\n\t&etm_pmu_sinks_group,\n\t&etm_pmu_events_group,\n\tNULL,\n};\n\nstatic inline struct list_head **\netm_event_cpu_path_ptr(struct etm_event_data *data, int cpu)\n{\n\treturn per_cpu_ptr(data->path, cpu);\n}\n\nstatic inline struct list_head *\netm_event_cpu_path(struct etm_event_data *data, int cpu)\n{\n\treturn *etm_event_cpu_path_ptr(data, cpu);\n}\n\nstatic void etm_event_read(struct perf_event *event) {}\n\nstatic int etm_addr_filters_alloc(struct perf_event *event)\n{\n\tstruct etm_filters *filters;\n\tint node = event->cpu == -1 ? -1 : cpu_to_node(event->cpu);\n\n\tfilters = kzalloc_node(sizeof(struct etm_filters), GFP_KERNEL, node);\n\tif (!filters)\n\t\treturn -ENOMEM;\n\n\tif (event->parent)\n\t\tmemcpy(filters, event->parent->hw.addr_filters,\n\t\t       sizeof(*filters));\n\n\tevent->hw.addr_filters = filters;\n\n\treturn 0;\n}\n\nstatic void etm_event_destroy(struct perf_event *event)\n{\n\tkfree(event->hw.addr_filters);\n\tevent->hw.addr_filters = NULL;\n}\n\nstatic int etm_event_init(struct perf_event *event)\n{\n\tint ret = 0;\n\n\tif (event->attr.type != etm_pmu.type) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tret = etm_addr_filters_alloc(event);\n\tif (ret)\n\t\tgoto out;\n\n\tevent->destroy = etm_event_destroy;\nout:\n\treturn ret;\n}\n\nstatic void free_sink_buffer(struct etm_event_data *event_data)\n{\n\tint cpu;\n\tcpumask_t *mask = &event_data->mask;\n\tstruct coresight_device *sink;\n\n\tif (!event_data->snk_config)\n\t\treturn;\n\n\tif (WARN_ON(cpumask_empty(mask)))\n\t\treturn;\n\n\tcpu = cpumask_first(mask);\n\tsink = coresight_get_sink(etm_event_cpu_path(event_data, cpu));\n\tsink_ops(sink)->free_buffer(event_data->snk_config);\n}\n\nstatic void free_event_data(struct work_struct *work)\n{\n\tint cpu;\n\tcpumask_t *mask;\n\tstruct etm_event_data *event_data;\n\n\tevent_data = container_of(work, struct etm_event_data, work);\n\tmask = &event_data->mask;\n\n\t \n\tfree_sink_buffer(event_data);\n\n\t \n\tif (event_data->cfg_hash)\n\t\tcscfg_deactivate_config(event_data->cfg_hash);\n\n\tfor_each_cpu(cpu, mask) {\n\t\tstruct list_head **ppath;\n\n\t\tppath = etm_event_cpu_path_ptr(event_data, cpu);\n\t\tif (!(IS_ERR_OR_NULL(*ppath)))\n\t\t\tcoresight_release_path(*ppath);\n\t\t*ppath = NULL;\n\t\tcoresight_trace_id_put_cpu_id(cpu);\n\t}\n\n\t \n\tcoresight_trace_id_perf_stop();\n\n\tfree_percpu(event_data->path);\n\tkfree(event_data);\n}\n\nstatic void *alloc_event_data(int cpu)\n{\n\tcpumask_t *mask;\n\tstruct etm_event_data *event_data;\n\n\t \n\tevent_data = kzalloc(sizeof(struct etm_event_data), GFP_KERNEL);\n\tif (!event_data)\n\t\treturn NULL;\n\n\n\tmask = &event_data->mask;\n\tif (cpu != -1)\n\t\tcpumask_set_cpu(cpu, mask);\n\telse\n\t\tcpumask_copy(mask, cpu_present_mask);\n\n\t \n\tevent_data->path = alloc_percpu(struct list_head *);\n\n\tif (!event_data->path) {\n\t\tkfree(event_data);\n\t\treturn NULL;\n\t}\n\n\treturn event_data;\n}\n\nstatic void etm_free_aux(void *data)\n{\n\tstruct etm_event_data *event_data = data;\n\n\tschedule_work(&event_data->work);\n}\n\n \nstatic bool sinks_compatible(struct coresight_device *a,\n\t\t\t     struct coresight_device *b)\n{\n\tif (!a || !b)\n\t\treturn false;\n\t \n\treturn (a->subtype.sink_subtype == b->subtype.sink_subtype) &&\n\t       (sink_ops(a) == sink_ops(b));\n}\n\nstatic void *etm_setup_aux(struct perf_event *event, void **pages,\n\t\t\t   int nr_pages, bool overwrite)\n{\n\tu32 id, cfg_hash;\n\tint cpu = event->cpu;\n\tint trace_id;\n\tcpumask_t *mask;\n\tstruct coresight_device *sink = NULL;\n\tstruct coresight_device *user_sink = NULL, *last_sink = NULL;\n\tstruct etm_event_data *event_data = NULL;\n\n\tevent_data = alloc_event_data(cpu);\n\tif (!event_data)\n\t\treturn NULL;\n\tINIT_WORK(&event_data->work, free_event_data);\n\n\t \n\tif (event->attr.config2 & GENMASK_ULL(31, 0)) {\n\t\tid = (u32)event->attr.config2;\n\t\tsink = user_sink = coresight_get_sink_by_id(id);\n\t}\n\n\t \n\tcoresight_trace_id_perf_start();\n\n\t \n\tcfg_hash = (u32)((event->attr.config2 & GENMASK_ULL(63, 32)) >> 32);\n\tif (cfg_hash) {\n\t\tif (cscfg_activate_config(cfg_hash))\n\t\t\tgoto err;\n\t\tevent_data->cfg_hash = cfg_hash;\n\t}\n\n\tmask = &event_data->mask;\n\n\t \n\tfor_each_cpu(cpu, mask) {\n\t\tstruct list_head *path;\n\t\tstruct coresight_device *csdev;\n\n\t\tcsdev = per_cpu(csdev_src, cpu);\n\t\t \n\t\tif (!csdev) {\n\t\t\tcpumask_clear_cpu(cpu, mask);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (!user_sink) {\n\t\t\t \n\t\t\tsink = coresight_find_default_sink(csdev);\n\t\t\tif (!sink) {\n\t\t\t\tcpumask_clear_cpu(cpu, mask);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (last_sink && !sinks_compatible(last_sink, sink)) {\n\t\t\t\tcpumask_clear_cpu(cpu, mask);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tlast_sink = sink;\n\t\t}\n\n\t\t \n\t\tpath = coresight_build_path(csdev, sink);\n\t\tif (IS_ERR(path)) {\n\t\t\tcpumask_clear_cpu(cpu, mask);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\ttrace_id = coresight_trace_id_get_cpu_id(cpu);\n\t\tif (!IS_VALID_CS_TRACE_ID(trace_id)) {\n\t\t\tcpumask_clear_cpu(cpu, mask);\n\t\t\tcoresight_release_path(path);\n\t\t\tcontinue;\n\t\t}\n\n\t\t*etm_event_cpu_path_ptr(event_data, cpu) = path;\n\t}\n\n\t \n\tif (!sink)\n\t\tgoto err;\n\n\t \n\tcpu = cpumask_first(mask);\n\tif (cpu >= nr_cpu_ids)\n\t\tgoto err;\n\n\tif (!sink_ops(sink)->alloc_buffer || !sink_ops(sink)->free_buffer)\n\t\tgoto err;\n\n\t \n\tevent_data->snk_config =\n\t\t\tsink_ops(sink)->alloc_buffer(sink, event, pages,\n\t\t\t\t\t\t     nr_pages, overwrite);\n\tif (!event_data->snk_config)\n\t\tgoto err;\n\nout:\n\treturn event_data;\n\nerr:\n\tetm_free_aux(event_data);\n\tevent_data = NULL;\n\tgoto out;\n}\n\nstatic void etm_event_start(struct perf_event *event, int flags)\n{\n\tint cpu = smp_processor_id();\n\tstruct etm_event_data *event_data;\n\tstruct etm_ctxt *ctxt = this_cpu_ptr(&etm_ctxt);\n\tstruct perf_output_handle *handle = &ctxt->handle;\n\tstruct coresight_device *sink, *csdev = per_cpu(csdev_src, cpu);\n\tstruct list_head *path;\n\tu64 hw_id;\n\n\tif (!csdev)\n\t\tgoto fail;\n\n\t \n\tif (WARN_ON(ctxt->event_data))\n\t\tgoto fail;\n\n\t \n\tevent_data = perf_aux_output_begin(handle, event);\n\tif (!event_data)\n\t\tgoto fail;\n\n\t \n\tif (!cpumask_test_cpu(cpu, &event_data->mask))\n\t\tgoto out;\n\n\tpath = etm_event_cpu_path(event_data, cpu);\n\t \n\tsink = coresight_get_sink(path);\n\tif (WARN_ON_ONCE(!sink))\n\t\tgoto fail_end_stop;\n\n\t \n\tif (coresight_enable_path(path, CS_MODE_PERF, handle))\n\t\tgoto fail_end_stop;\n\n\t \n\tif (source_ops(csdev)->enable(csdev, event, CS_MODE_PERF))\n\t\tgoto fail_disable_path;\n\n\t \n\tif (!cpumask_test_cpu(cpu, &event_data->aux_hwid_done)) {\n\t\tcpumask_set_cpu(cpu, &event_data->aux_hwid_done);\n\t\thw_id = FIELD_PREP(CS_AUX_HW_ID_VERSION_MASK,\n\t\t\t\t   CS_AUX_HW_ID_CURR_VERSION);\n\t\thw_id |= FIELD_PREP(CS_AUX_HW_ID_TRACE_ID_MASK,\n\t\t\t\t    coresight_trace_id_read_cpu_id(cpu));\n\t\tperf_report_aux_output_id(event, hw_id);\n\t}\n\nout:\n\t \n\tevent->hw.state = 0;\n\t \n\tctxt->event_data = event_data;\n\treturn;\n\nfail_disable_path:\n\tcoresight_disable_path(path);\nfail_end_stop:\n\t \n\tif (READ_ONCE(handle->event)) {\n\t\tperf_aux_output_flag(handle, PERF_AUX_FLAG_TRUNCATED);\n\t\tperf_aux_output_end(handle, 0);\n\t}\nfail:\n\tevent->hw.state = PERF_HES_STOPPED;\n\treturn;\n}\n\nstatic void etm_event_stop(struct perf_event *event, int mode)\n{\n\tint cpu = smp_processor_id();\n\tunsigned long size;\n\tstruct coresight_device *sink, *csdev = per_cpu(csdev_src, cpu);\n\tstruct etm_ctxt *ctxt = this_cpu_ptr(&etm_ctxt);\n\tstruct perf_output_handle *handle = &ctxt->handle;\n\tstruct etm_event_data *event_data;\n\tstruct list_head *path;\n\n\t \n\tif (handle->event &&\n\t    WARN_ON(perf_get_aux(handle) != ctxt->event_data))\n\t\treturn;\n\n\tevent_data = ctxt->event_data;\n\t \n\tctxt->event_data = NULL;\n\n\tif (event->hw.state == PERF_HES_STOPPED)\n\t\treturn;\n\n\t \n\tif (WARN_ON(!event_data))\n\t\treturn;\n\n\t \n\tif (handle->event && (mode & PERF_EF_UPDATE) &&\n\t    !cpumask_test_cpu(cpu, &event_data->mask)) {\n\t\tevent->hw.state = PERF_HES_STOPPED;\n\t\tperf_aux_output_end(handle, 0);\n\t\treturn;\n\t}\n\n\tif (!csdev)\n\t\treturn;\n\n\tpath = etm_event_cpu_path(event_data, cpu);\n\tif (!path)\n\t\treturn;\n\n\tsink = coresight_get_sink(path);\n\tif (!sink)\n\t\treturn;\n\n\t \n\tsource_ops(csdev)->disable(csdev, event);\n\n\t \n\tevent->hw.state = PERF_HES_STOPPED;\n\n\t \n\tif (handle->event && (mode & PERF_EF_UPDATE)) {\n\t\tif (WARN_ON_ONCE(handle->event != event))\n\t\t\treturn;\n\n\t\t \n\t\tif (!sink_ops(sink)->update_buffer)\n\t\t\treturn;\n\n\t\tsize = sink_ops(sink)->update_buffer(sink, handle,\n\t\t\t\t\t      event_data->snk_config);\n\t\t \n\t\tif (READ_ONCE(handle->event))\n\t\t\tperf_aux_output_end(handle, size);\n\t\telse\n\t\t\tWARN_ON(size);\n\t}\n\n\t \n\tcoresight_disable_path(path);\n}\n\nstatic int etm_event_add(struct perf_event *event, int mode)\n{\n\tint ret = 0;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (mode & PERF_EF_START) {\n\t\tetm_event_start(event, 0);\n\t\tif (hwc->state & PERF_HES_STOPPED)\n\t\t\tret = -EINVAL;\n\t} else {\n\t\thwc->state = PERF_HES_STOPPED;\n\t}\n\n\treturn ret;\n}\n\nstatic void etm_event_del(struct perf_event *event, int mode)\n{\n\tetm_event_stop(event, PERF_EF_UPDATE);\n}\n\nstatic int etm_addr_filters_validate(struct list_head *filters)\n{\n\tbool range = false, address = false;\n\tint index = 0;\n\tstruct perf_addr_filter *filter;\n\n\tlist_for_each_entry(filter, filters, entry) {\n\t\t \n\t\tif (++index > ETM_ADDR_CMP_MAX)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\t \n\t\tif (filter->size) {\n\t\t\t \n\t\t\tif (filter->action == PERF_ADDR_FILTER_ACTION_START ||\n\t\t\t    filter->action == PERF_ADDR_FILTER_ACTION_STOP)\n\t\t\t\treturn -EOPNOTSUPP;\n\n\t\t\trange = true;\n\t\t} else\n\t\t\taddress = true;\n\n\t\t \n\t\tif (range && address)\n\t\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic void etm_addr_filters_sync(struct perf_event *event)\n{\n\tstruct perf_addr_filters_head *head = perf_event_addr_filters(event);\n\tunsigned long start, stop;\n\tstruct perf_addr_filter_range *fr = event->addr_filter_ranges;\n\tstruct etm_filters *filters = event->hw.addr_filters;\n\tstruct etm_filter *etm_filter;\n\tstruct perf_addr_filter *filter;\n\tint i = 0;\n\n\tlist_for_each_entry(filter, &head->list, entry) {\n\t\tstart = fr[i].start;\n\t\tstop = start + fr[i].size;\n\t\tetm_filter = &filters->etm_filter[i];\n\n\t\tswitch (filter->action) {\n\t\tcase PERF_ADDR_FILTER_ACTION_FILTER:\n\t\t\tetm_filter->start_addr = start;\n\t\t\tetm_filter->stop_addr = stop;\n\t\t\tetm_filter->type = ETM_ADDR_TYPE_RANGE;\n\t\t\tbreak;\n\t\tcase PERF_ADDR_FILTER_ACTION_START:\n\t\t\tetm_filter->start_addr = start;\n\t\t\tetm_filter->type = ETM_ADDR_TYPE_START;\n\t\t\tbreak;\n\t\tcase PERF_ADDR_FILTER_ACTION_STOP:\n\t\t\tetm_filter->stop_addr = stop;\n\t\t\tetm_filter->type = ETM_ADDR_TYPE_STOP;\n\t\t\tbreak;\n\t\t}\n\t\ti++;\n\t}\n\n\tfilters->nr_filters = i;\n}\n\nint etm_perf_symlink(struct coresight_device *csdev, bool link)\n{\n\tchar entry[sizeof(\"cpu9999999\")];\n\tint ret = 0, cpu = source_ops(csdev)->cpu_id(csdev);\n\tstruct device *pmu_dev = etm_pmu.dev;\n\tstruct device *cs_dev = &csdev->dev;\n\n\tsprintf(entry, \"cpu%d\", cpu);\n\n\tif (!etm_perf_up)\n\t\treturn -EPROBE_DEFER;\n\n\tif (link) {\n\t\tret = sysfs_create_link(&pmu_dev->kobj, &cs_dev->kobj, entry);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tper_cpu(csdev_src, cpu) = csdev;\n\t} else {\n\t\tsysfs_remove_link(&pmu_dev->kobj, entry);\n\t\tper_cpu(csdev_src, cpu) = NULL;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(etm_perf_symlink);\n\nstatic ssize_t etm_perf_sink_name_show(struct device *dev,\n\t\t\t\t       struct device_attribute *dattr,\n\t\t\t\t       char *buf)\n{\n\tstruct dev_ext_attribute *ea;\n\n\tea = container_of(dattr, struct dev_ext_attribute, attr);\n\treturn scnprintf(buf, PAGE_SIZE, \"0x%lx\\n\", (unsigned long)(ea->var));\n}\n\nstatic struct dev_ext_attribute *\netm_perf_add_symlink_group(struct device *dev, const char *name, const char *group_name)\n{\n\tstruct dev_ext_attribute *ea;\n\tunsigned long hash;\n\tint ret;\n\tstruct device *pmu_dev = etm_pmu.dev;\n\n\tif (!etm_perf_up)\n\t\treturn ERR_PTR(-EPROBE_DEFER);\n\n\tea = devm_kzalloc(dev, sizeof(*ea), GFP_KERNEL);\n\tif (!ea)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t \n\thash = hashlen_hash(hashlen_string(NULL, name));\n\n\tsysfs_attr_init(&ea->attr.attr);\n\tea->attr.attr.name = devm_kstrdup(dev, name, GFP_KERNEL);\n\tif (!ea->attr.attr.name)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tea->attr.attr.mode = 0444;\n\tea->var = (unsigned long *)hash;\n\n\tret = sysfs_add_file_to_group(&pmu_dev->kobj,\n\t\t\t\t      &ea->attr.attr, group_name);\n\n\treturn ret ? ERR_PTR(ret) : ea;\n}\n\nint etm_perf_add_symlink_sink(struct coresight_device *csdev)\n{\n\tconst char *name;\n\tstruct device *dev = &csdev->dev;\n\tint err = 0;\n\n\tif (csdev->type != CORESIGHT_DEV_TYPE_SINK &&\n\t    csdev->type != CORESIGHT_DEV_TYPE_LINKSINK)\n\t\treturn -EINVAL;\n\n\tif (csdev->ea != NULL)\n\t\treturn -EINVAL;\n\n\tname = dev_name(dev);\n\tcsdev->ea = etm_perf_add_symlink_group(dev, name, \"sinks\");\n\tif (IS_ERR(csdev->ea)) {\n\t\terr = PTR_ERR(csdev->ea);\n\t\tcsdev->ea = NULL;\n\t} else\n\t\tcsdev->ea->attr.show = etm_perf_sink_name_show;\n\n\treturn err;\n}\n\nstatic void etm_perf_del_symlink_group(struct dev_ext_attribute *ea, const char *group_name)\n{\n\tstruct device *pmu_dev = etm_pmu.dev;\n\n\tsysfs_remove_file_from_group(&pmu_dev->kobj,\n\t\t\t\t     &ea->attr.attr, group_name);\n}\n\nvoid etm_perf_del_symlink_sink(struct coresight_device *csdev)\n{\n\tif (csdev->type != CORESIGHT_DEV_TYPE_SINK &&\n\t    csdev->type != CORESIGHT_DEV_TYPE_LINKSINK)\n\t\treturn;\n\n\tif (!csdev->ea)\n\t\treturn;\n\n\tetm_perf_del_symlink_group(csdev->ea, \"sinks\");\n\tcsdev->ea = NULL;\n}\n\nstatic ssize_t etm_perf_cscfg_event_show(struct device *dev,\n\t\t\t\t\t struct device_attribute *dattr,\n\t\t\t\t\t char *buf)\n{\n\tstruct dev_ext_attribute *ea;\n\n\tea = container_of(dattr, struct dev_ext_attribute, attr);\n\treturn scnprintf(buf, PAGE_SIZE, \"configid=0x%lx\\n\", (unsigned long)(ea->var));\n}\n\nint etm_perf_add_symlink_cscfg(struct device *dev, struct cscfg_config_desc *config_desc)\n{\n\tint err = 0;\n\n\tif (config_desc->event_ea != NULL)\n\t\treturn 0;\n\n\tconfig_desc->event_ea = etm_perf_add_symlink_group(dev, config_desc->name, \"events\");\n\n\t \n\tif (!IS_ERR(config_desc->event_ea))\n\t\tconfig_desc->event_ea->attr.show = etm_perf_cscfg_event_show;\n\telse {\n\t\terr = PTR_ERR(config_desc->event_ea);\n\t\tconfig_desc->event_ea = NULL;\n\t}\n\n\treturn err;\n}\n\nvoid etm_perf_del_symlink_cscfg(struct cscfg_config_desc *config_desc)\n{\n\tif (!config_desc->event_ea)\n\t\treturn;\n\n\tetm_perf_del_symlink_group(config_desc->event_ea, \"events\");\n\tconfig_desc->event_ea = NULL;\n}\n\nint __init etm_perf_init(void)\n{\n\tint ret;\n\n\tetm_pmu.capabilities\t\t= (PERF_PMU_CAP_EXCLUSIVE |\n\t\t\t\t\t   PERF_PMU_CAP_ITRACE);\n\n\tetm_pmu.attr_groups\t\t= etm_pmu_attr_groups;\n\tetm_pmu.task_ctx_nr\t\t= perf_sw_context;\n\tetm_pmu.read\t\t\t= etm_event_read;\n\tetm_pmu.event_init\t\t= etm_event_init;\n\tetm_pmu.setup_aux\t\t= etm_setup_aux;\n\tetm_pmu.free_aux\t\t= etm_free_aux;\n\tetm_pmu.start\t\t\t= etm_event_start;\n\tetm_pmu.stop\t\t\t= etm_event_stop;\n\tetm_pmu.add\t\t\t= etm_event_add;\n\tetm_pmu.del\t\t\t= etm_event_del;\n\tetm_pmu.addr_filters_sync\t= etm_addr_filters_sync;\n\tetm_pmu.addr_filters_validate\t= etm_addr_filters_validate;\n\tetm_pmu.nr_addr_filters\t\t= ETM_ADDR_CMP_MAX;\n\tetm_pmu.module\t\t\t= THIS_MODULE;\n\n\tret = perf_pmu_register(&etm_pmu, CORESIGHT_ETM_PMU_NAME, -1);\n\tif (ret == 0)\n\t\tetm_perf_up = true;\n\n\treturn ret;\n}\n\nvoid etm_perf_exit(void)\n{\n\tperf_pmu_unregister(&etm_pmu);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}