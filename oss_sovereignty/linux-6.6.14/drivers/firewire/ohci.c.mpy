{
  "module_name": "ohci.c",
  "hash_id": "958b873f05ceb7015f1d74ed6a5754d9ea737bbd12767961194f5a52ac5cbbc0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/firewire/ohci.c",
  "human_readable_source": "\n \n\n#include <linux/bitops.h>\n#include <linux/bug.h>\n#include <linux/compiler.h>\n#include <linux/delay.h>\n#include <linux/device.h>\n#include <linux/dma-mapping.h>\n#include <linux/firewire.h>\n#include <linux/firewire-constants.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/mutex.h>\n#include <linux/pci.h>\n#include <linux/pci_ids.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/string.h>\n#include <linux/time.h>\n#include <linux/vmalloc.h>\n#include <linux/workqueue.h>\n\n#include <asm/byteorder.h>\n#include <asm/page.h>\n\n#ifdef CONFIG_PPC_PMAC\n#include <asm/pmac_feature.h>\n#endif\n\n#include \"core.h\"\n#include \"ohci.h\"\n\n#define ohci_info(ohci, f, args...)\tdev_info(ohci->card.device, f, ##args)\n#define ohci_notice(ohci, f, args...)\tdev_notice(ohci->card.device, f, ##args)\n#define ohci_err(ohci, f, args...)\tdev_err(ohci->card.device, f, ##args)\n\n#define DESCRIPTOR_OUTPUT_MORE\t\t0\n#define DESCRIPTOR_OUTPUT_LAST\t\t(1 << 12)\n#define DESCRIPTOR_INPUT_MORE\t\t(2 << 12)\n#define DESCRIPTOR_INPUT_LAST\t\t(3 << 12)\n#define DESCRIPTOR_STATUS\t\t(1 << 11)\n#define DESCRIPTOR_KEY_IMMEDIATE\t(2 << 8)\n#define DESCRIPTOR_PING\t\t\t(1 << 7)\n#define DESCRIPTOR_YY\t\t\t(1 << 6)\n#define DESCRIPTOR_NO_IRQ\t\t(0 << 4)\n#define DESCRIPTOR_IRQ_ERROR\t\t(1 << 4)\n#define DESCRIPTOR_IRQ_ALWAYS\t\t(3 << 4)\n#define DESCRIPTOR_BRANCH_ALWAYS\t(3 << 2)\n#define DESCRIPTOR_WAIT\t\t\t(3 << 0)\n\n#define DESCRIPTOR_CMD\t\t\t(0xf << 12)\n\nstruct descriptor {\n\t__le16 req_count;\n\t__le16 control;\n\t__le32 data_address;\n\t__le32 branch_address;\n\t__le16 res_count;\n\t__le16 transfer_status;\n} __attribute__((aligned(16)));\n\n#define CONTROL_SET(regs)\t(regs)\n#define CONTROL_CLEAR(regs)\t((regs) + 4)\n#define COMMAND_PTR(regs)\t((regs) + 12)\n#define CONTEXT_MATCH(regs)\t((regs) + 16)\n\n#define AR_BUFFER_SIZE\t(32*1024)\n#define AR_BUFFERS_MIN\tDIV_ROUND_UP(AR_BUFFER_SIZE, PAGE_SIZE)\n \n#define AR_BUFFERS\t(AR_BUFFERS_MIN >= 2 ? AR_BUFFERS_MIN : 2)\n\n#define MAX_ASYNC_PAYLOAD\t4096\n#define MAX_AR_PACKET_SIZE\t(16 + MAX_ASYNC_PAYLOAD + 4)\n#define AR_WRAPAROUND_PAGES\tDIV_ROUND_UP(MAX_AR_PACKET_SIZE, PAGE_SIZE)\n\nstruct ar_context {\n\tstruct fw_ohci *ohci;\n\tstruct page *pages[AR_BUFFERS];\n\tvoid *buffer;\n\tstruct descriptor *descriptors;\n\tdma_addr_t descriptors_bus;\n\tvoid *pointer;\n\tunsigned int last_buffer_index;\n\tu32 regs;\n\tstruct tasklet_struct tasklet;\n};\n\nstruct context;\n\ntypedef int (*descriptor_callback_t)(struct context *ctx,\n\t\t\t\t     struct descriptor *d,\n\t\t\t\t     struct descriptor *last);\n\n \nstruct descriptor_buffer {\n\tstruct list_head list;\n\tdma_addr_t buffer_bus;\n\tsize_t buffer_size;\n\tsize_t used;\n\tstruct descriptor buffer[];\n};\n\nstruct context {\n\tstruct fw_ohci *ohci;\n\tu32 regs;\n\tint total_allocation;\n\tu32 current_bus;\n\tbool running;\n\tbool flushing;\n\n\t \n\tstruct list_head buffer_list;\n\n\t \n\tstruct descriptor_buffer *buffer_tail;\n\n\t \n\tstruct descriptor *last;\n\n\t \n\tstruct descriptor *prev;\n\tint prev_z;\n\n\tdescriptor_callback_t callback;\n\n\tstruct tasklet_struct tasklet;\n};\n\n#define IT_HEADER_SY(v)          ((v) <<  0)\n#define IT_HEADER_TCODE(v)       ((v) <<  4)\n#define IT_HEADER_CHANNEL(v)     ((v) <<  8)\n#define IT_HEADER_TAG(v)         ((v) << 14)\n#define IT_HEADER_SPEED(v)       ((v) << 16)\n#define IT_HEADER_DATA_LENGTH(v) ((v) << 16)\n\nstruct iso_context {\n\tstruct fw_iso_context base;\n\tstruct context context;\n\tvoid *header;\n\tsize_t header_length;\n\tunsigned long flushing_completions;\n\tu32 mc_buffer_bus;\n\tu16 mc_completed;\n\tu16 last_timestamp;\n\tu8 sync;\n\tu8 tags;\n};\n\n#define CONFIG_ROM_SIZE 1024\n\nstruct fw_ohci {\n\tstruct fw_card card;\n\n\t__iomem char *registers;\n\tint node_id;\n\tint generation;\n\tint request_generation;\t \n\tunsigned quirks;\n\tunsigned int pri_req_max;\n\tu32 bus_time;\n\tbool bus_time_running;\n\tbool is_root;\n\tbool csr_state_setclear_abdicate;\n\tint n_ir;\n\tint n_it;\n\t \n\tspinlock_t lock;\n\n\tstruct mutex phy_reg_mutex;\n\n\tvoid *misc_buffer;\n\tdma_addr_t misc_buffer_bus;\n\n\tstruct ar_context ar_request_ctx;\n\tstruct ar_context ar_response_ctx;\n\tstruct context at_request_ctx;\n\tstruct context at_response_ctx;\n\n\tu32 it_context_support;\n\tu32 it_context_mask;      \n\tstruct iso_context *it_context_list;\n\tu64 ir_context_channels;  \n\tu32 ir_context_support;\n\tu32 ir_context_mask;      \n\tstruct iso_context *ir_context_list;\n\tu64 mc_channels;  \n\tbool mc_allocated;\n\n\t__be32    *config_rom;\n\tdma_addr_t config_rom_bus;\n\t__be32    *next_config_rom;\n\tdma_addr_t next_config_rom_bus;\n\t__be32     next_header;\n\n\t__le32    *self_id;\n\tdma_addr_t self_id_bus;\n\tstruct work_struct bus_reset_work;\n\n\tu32 self_id_buffer[512];\n};\n\nstatic struct workqueue_struct *selfid_workqueue;\n\nstatic inline struct fw_ohci *fw_ohci(struct fw_card *card)\n{\n\treturn container_of(card, struct fw_ohci, card);\n}\n\n#define IT_CONTEXT_CYCLE_MATCH_ENABLE\t0x80000000\n#define IR_CONTEXT_BUFFER_FILL\t\t0x80000000\n#define IR_CONTEXT_ISOCH_HEADER\t\t0x40000000\n#define IR_CONTEXT_CYCLE_MATCH_ENABLE\t0x20000000\n#define IR_CONTEXT_MULTI_CHANNEL_MODE\t0x10000000\n#define IR_CONTEXT_DUAL_BUFFER_MODE\t0x08000000\n\n#define CONTEXT_RUN\t0x8000\n#define CONTEXT_WAKE\t0x1000\n#define CONTEXT_DEAD\t0x0800\n#define CONTEXT_ACTIVE\t0x0400\n\n#define OHCI1394_MAX_AT_REQ_RETRIES\t0xf\n#define OHCI1394_MAX_AT_RESP_RETRIES\t0x2\n#define OHCI1394_MAX_PHYS_RESP_RETRIES\t0x8\n\n#define OHCI1394_REGISTER_SIZE\t\t0x800\n#define OHCI1394_PCI_HCI_Control\t0x40\n#define SELF_ID_BUF_SIZE\t\t0x800\n#define OHCI_TCODE_PHY_PACKET\t\t0x0e\n#define OHCI_VERSION_1_1\t\t0x010010\n\nstatic char ohci_driver_name[] = KBUILD_MODNAME;\n\n#define PCI_VENDOR_ID_PINNACLE_SYSTEMS\t0x11bd\n#define PCI_DEVICE_ID_AGERE_FW643\t0x5901\n#define PCI_DEVICE_ID_CREATIVE_SB1394\t0x4001\n#define PCI_DEVICE_ID_JMICRON_JMB38X_FW\t0x2380\n#define PCI_DEVICE_ID_TI_TSB12LV22\t0x8009\n#define PCI_DEVICE_ID_TI_TSB12LV26\t0x8020\n#define PCI_DEVICE_ID_TI_TSB82AA2\t0x8025\n#define PCI_DEVICE_ID_VIA_VT630X\t0x3044\n#define PCI_REV_ID_VIA_VT6306\t\t0x46\n#define PCI_DEVICE_ID_VIA_VT6315\t0x3403\n\n#define QUIRK_CYCLE_TIMER\t\t0x1\n#define QUIRK_RESET_PACKET\t\t0x2\n#define QUIRK_BE_HEADERS\t\t0x4\n#define QUIRK_NO_1394A\t\t\t0x8\n#define QUIRK_NO_MSI\t\t\t0x10\n#define QUIRK_TI_SLLZ059\t\t0x20\n#define QUIRK_IR_WAKE\t\t\t0x40\n\n\n\n\n\n\n#define QUIRK_REBOOT_BY_CYCLE_TIMER_READ\t0x80000000\n\n#if IS_ENABLED(CONFIG_X86)\n\nstatic bool has_reboot_by_cycle_timer_read_quirk(const struct fw_ohci *ohci)\n{\n\treturn !!(ohci->quirks & QUIRK_REBOOT_BY_CYCLE_TIMER_READ);\n}\n\n#define PCI_DEVICE_ID_ASMEDIA_ASM108X\t0x1080\n\nstatic bool detect_vt630x_with_asm1083_on_amd_ryzen_machine(const struct pci_dev *pdev)\n{\n\tconst struct pci_dev *pcie_to_pci_bridge;\n\n\t\n\tif (!static_cpu_has(X86_FEATURE_ZEN))\n\t\treturn false;\n\n\t\n\tif (pdev->vendor != PCI_VENDOR_ID_VIA)\n\t\treturn false;\n\tif (pdev->device != PCI_DEVICE_ID_VIA_VT630X)\n\t\treturn false;\n\n\t\n\tpcie_to_pci_bridge = pdev->bus->self;\n\tif (pcie_to_pci_bridge->vendor != PCI_VENDOR_ID_ASMEDIA)\n\t\treturn false;\n\tif (pcie_to_pci_bridge->device != PCI_DEVICE_ID_ASMEDIA_ASM108X)\n\t\treturn false;\n\n\treturn true;\n}\n\n#else\n#define has_reboot_by_cycle_timer_read_quirk(ohci) false\n#define detect_vt630x_with_asm1083_on_amd_ryzen_machine(pdev)\tfalse\n#endif\n\n \nstatic const struct {\n\tunsigned short vendor, device, revision, flags;\n} ohci_quirks[] = {\n\t{PCI_VENDOR_ID_AL, PCI_ANY_ID, PCI_ANY_ID,\n\t\tQUIRK_CYCLE_TIMER},\n\n\t{PCI_VENDOR_ID_APPLE, PCI_DEVICE_ID_APPLE_UNI_N_FW, PCI_ANY_ID,\n\t\tQUIRK_BE_HEADERS},\n\n\t{PCI_VENDOR_ID_ATT, PCI_DEVICE_ID_AGERE_FW643, 6,\n\t\tQUIRK_NO_MSI},\n\n\t{PCI_VENDOR_ID_CREATIVE, PCI_DEVICE_ID_CREATIVE_SB1394, PCI_ANY_ID,\n\t\tQUIRK_RESET_PACKET},\n\n\t{PCI_VENDOR_ID_JMICRON, PCI_DEVICE_ID_JMICRON_JMB38X_FW, PCI_ANY_ID,\n\t\tQUIRK_NO_MSI},\n\n\t{PCI_VENDOR_ID_NEC, PCI_ANY_ID, PCI_ANY_ID,\n\t\tQUIRK_CYCLE_TIMER},\n\n\t{PCI_VENDOR_ID_O2, PCI_ANY_ID, PCI_ANY_ID,\n\t\tQUIRK_NO_MSI},\n\n\t{PCI_VENDOR_ID_RICOH, PCI_ANY_ID, PCI_ANY_ID,\n\t\tQUIRK_CYCLE_TIMER | QUIRK_NO_MSI},\n\n\t{PCI_VENDOR_ID_TI, PCI_DEVICE_ID_TI_TSB12LV22, PCI_ANY_ID,\n\t\tQUIRK_CYCLE_TIMER | QUIRK_RESET_PACKET | QUIRK_NO_1394A},\n\n\t{PCI_VENDOR_ID_TI, PCI_DEVICE_ID_TI_TSB12LV26, PCI_ANY_ID,\n\t\tQUIRK_RESET_PACKET | QUIRK_TI_SLLZ059},\n\n\t{PCI_VENDOR_ID_TI, PCI_DEVICE_ID_TI_TSB82AA2, PCI_ANY_ID,\n\t\tQUIRK_RESET_PACKET | QUIRK_TI_SLLZ059},\n\n\t{PCI_VENDOR_ID_TI, PCI_ANY_ID, PCI_ANY_ID,\n\t\tQUIRK_RESET_PACKET},\n\n\t{PCI_VENDOR_ID_VIA, PCI_DEVICE_ID_VIA_VT630X, PCI_REV_ID_VIA_VT6306,\n\t\tQUIRK_CYCLE_TIMER | QUIRK_IR_WAKE},\n\n\t{PCI_VENDOR_ID_VIA, PCI_DEVICE_ID_VIA_VT6315, 0,\n\t\tQUIRK_CYCLE_TIMER   | QUIRK_NO_MSI},\n\n\t{PCI_VENDOR_ID_VIA, PCI_DEVICE_ID_VIA_VT6315, PCI_ANY_ID,\n\t\tQUIRK_NO_MSI},\n\n\t{PCI_VENDOR_ID_VIA, PCI_ANY_ID, PCI_ANY_ID,\n\t\tQUIRK_CYCLE_TIMER | QUIRK_NO_MSI},\n};\n\n \nstatic int param_quirks;\nmodule_param_named(quirks, param_quirks, int, 0644);\nMODULE_PARM_DESC(quirks, \"Chip quirks (default = 0\"\n\t\", nonatomic cycle timer = \"\t__stringify(QUIRK_CYCLE_TIMER)\n\t\", reset packet generation = \"\t__stringify(QUIRK_RESET_PACKET)\n\t\", AR/selfID endianness = \"\t__stringify(QUIRK_BE_HEADERS)\n\t\", no 1394a enhancements = \"\t__stringify(QUIRK_NO_1394A)\n\t\", disable MSI = \"\t\t__stringify(QUIRK_NO_MSI)\n\t\", TI SLLZ059 erratum = \"\t__stringify(QUIRK_TI_SLLZ059)\n\t\", IR wake unreliable = \"\t__stringify(QUIRK_IR_WAKE)\n\t\")\");\n\n#define OHCI_PARAM_DEBUG_AT_AR\t\t1\n#define OHCI_PARAM_DEBUG_SELFIDS\t2\n#define OHCI_PARAM_DEBUG_IRQS\t\t4\n#define OHCI_PARAM_DEBUG_BUSRESETS\t8  \n\nstatic int param_debug;\nmodule_param_named(debug, param_debug, int, 0644);\nMODULE_PARM_DESC(debug, \"Verbose logging (default = 0\"\n\t\", AT/AR events = \"\t__stringify(OHCI_PARAM_DEBUG_AT_AR)\n\t\", self-IDs = \"\t\t__stringify(OHCI_PARAM_DEBUG_SELFIDS)\n\t\", IRQs = \"\t\t__stringify(OHCI_PARAM_DEBUG_IRQS)\n\t\", busReset events = \"\t__stringify(OHCI_PARAM_DEBUG_BUSRESETS)\n\t\", or a combination, or all = -1)\");\n\nstatic bool param_remote_dma;\nmodule_param_named(remote_dma, param_remote_dma, bool, 0444);\nMODULE_PARM_DESC(remote_dma, \"Enable unfiltered remote DMA (default = N)\");\n\nstatic void log_irqs(struct fw_ohci *ohci, u32 evt)\n{\n\tif (likely(!(param_debug &\n\t\t\t(OHCI_PARAM_DEBUG_IRQS | OHCI_PARAM_DEBUG_BUSRESETS))))\n\t\treturn;\n\n\tif (!(param_debug & OHCI_PARAM_DEBUG_IRQS) &&\n\t    !(evt & OHCI1394_busReset))\n\t\treturn;\n\n\tohci_notice(ohci, \"IRQ %08x%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s\\n\", evt,\n\t    evt & OHCI1394_selfIDComplete\t? \" selfID\"\t\t: \"\",\n\t    evt & OHCI1394_RQPkt\t\t? \" AR_req\"\t\t: \"\",\n\t    evt & OHCI1394_RSPkt\t\t? \" AR_resp\"\t\t: \"\",\n\t    evt & OHCI1394_reqTxComplete\t? \" AT_req\"\t\t: \"\",\n\t    evt & OHCI1394_respTxComplete\t? \" AT_resp\"\t\t: \"\",\n\t    evt & OHCI1394_isochRx\t\t? \" IR\"\t\t\t: \"\",\n\t    evt & OHCI1394_isochTx\t\t? \" IT\"\t\t\t: \"\",\n\t    evt & OHCI1394_postedWriteErr\t? \" postedWriteErr\"\t: \"\",\n\t    evt & OHCI1394_cycleTooLong\t\t? \" cycleTooLong\"\t: \"\",\n\t    evt & OHCI1394_cycle64Seconds\t? \" cycle64Seconds\"\t: \"\",\n\t    evt & OHCI1394_cycleInconsistent\t? \" cycleInconsistent\"\t: \"\",\n\t    evt & OHCI1394_regAccessFail\t? \" regAccessFail\"\t: \"\",\n\t    evt & OHCI1394_unrecoverableError\t? \" unrecoverableError\"\t: \"\",\n\t    evt & OHCI1394_busReset\t\t? \" busReset\"\t\t: \"\",\n\t    evt & ~(OHCI1394_selfIDComplete | OHCI1394_RQPkt |\n\t\t    OHCI1394_RSPkt | OHCI1394_reqTxComplete |\n\t\t    OHCI1394_respTxComplete | OHCI1394_isochRx |\n\t\t    OHCI1394_isochTx | OHCI1394_postedWriteErr |\n\t\t    OHCI1394_cycleTooLong | OHCI1394_cycle64Seconds |\n\t\t    OHCI1394_cycleInconsistent |\n\t\t    OHCI1394_regAccessFail | OHCI1394_busReset)\n\t\t\t\t\t\t? \" ?\"\t\t\t: \"\");\n}\n\nstatic const char *speed[] = {\n\t[0] = \"S100\", [1] = \"S200\", [2] = \"S400\",    [3] = \"beta\",\n};\nstatic const char *power[] = {\n\t[0] = \"+0W\",  [1] = \"+15W\", [2] = \"+30W\",    [3] = \"+45W\",\n\t[4] = \"-3W\",  [5] = \" ?W\",  [6] = \"-3..-6W\", [7] = \"-3..-10W\",\n};\nstatic const char port[] = { '.', '-', 'p', 'c', };\n\nstatic char _p(u32 *s, int shift)\n{\n\treturn port[*s >> shift & 3];\n}\n\nstatic void log_selfids(struct fw_ohci *ohci, int generation, int self_id_count)\n{\n\tu32 *s;\n\n\tif (likely(!(param_debug & OHCI_PARAM_DEBUG_SELFIDS)))\n\t\treturn;\n\n\tohci_notice(ohci, \"%d selfIDs, generation %d, local node ID %04x\\n\",\n\t\t    self_id_count, generation, ohci->node_id);\n\n\tfor (s = ohci->self_id_buffer; self_id_count--; ++s)\n\t\tif ((*s & 1 << 23) == 0)\n\t\t\tohci_notice(ohci,\n\t\t\t    \"selfID 0: %08x, phy %d [%c%c%c] %s gc=%d %s %s%s%s\\n\",\n\t\t\t    *s, *s >> 24 & 63, _p(s, 6), _p(s, 4), _p(s, 2),\n\t\t\t    speed[*s >> 14 & 3], *s >> 16 & 63,\n\t\t\t    power[*s >> 8 & 7], *s >> 22 & 1 ? \"L\" : \"\",\n\t\t\t    *s >> 11 & 1 ? \"c\" : \"\", *s & 2 ? \"i\" : \"\");\n\t\telse\n\t\t\tohci_notice(ohci,\n\t\t\t    \"selfID n: %08x, phy %d [%c%c%c%c%c%c%c%c]\\n\",\n\t\t\t    *s, *s >> 24 & 63,\n\t\t\t    _p(s, 16), _p(s, 14), _p(s, 12), _p(s, 10),\n\t\t\t    _p(s,  8), _p(s,  6), _p(s,  4), _p(s,  2));\n}\n\nstatic const char *evts[] = {\n\t[0x00] = \"evt_no_status\",\t[0x01] = \"-reserved-\",\n\t[0x02] = \"evt_long_packet\",\t[0x03] = \"evt_missing_ack\",\n\t[0x04] = \"evt_underrun\",\t[0x05] = \"evt_overrun\",\n\t[0x06] = \"evt_descriptor_read\",\t[0x07] = \"evt_data_read\",\n\t[0x08] = \"evt_data_write\",\t[0x09] = \"evt_bus_reset\",\n\t[0x0a] = \"evt_timeout\",\t\t[0x0b] = \"evt_tcode_err\",\n\t[0x0c] = \"-reserved-\",\t\t[0x0d] = \"-reserved-\",\n\t[0x0e] = \"evt_unknown\",\t\t[0x0f] = \"evt_flushed\",\n\t[0x10] = \"-reserved-\",\t\t[0x11] = \"ack_complete\",\n\t[0x12] = \"ack_pending \",\t[0x13] = \"-reserved-\",\n\t[0x14] = \"ack_busy_X\",\t\t[0x15] = \"ack_busy_A\",\n\t[0x16] = \"ack_busy_B\",\t\t[0x17] = \"-reserved-\",\n\t[0x18] = \"-reserved-\",\t\t[0x19] = \"-reserved-\",\n\t[0x1a] = \"-reserved-\",\t\t[0x1b] = \"ack_tardy\",\n\t[0x1c] = \"-reserved-\",\t\t[0x1d] = \"ack_data_error\",\n\t[0x1e] = \"ack_type_error\",\t[0x1f] = \"-reserved-\",\n\t[0x20] = \"pending/cancelled\",\n};\nstatic const char *tcodes[] = {\n\t[0x0] = \"QW req\",\t\t[0x1] = \"BW req\",\n\t[0x2] = \"W resp\",\t\t[0x3] = \"-reserved-\",\n\t[0x4] = \"QR req\",\t\t[0x5] = \"BR req\",\n\t[0x6] = \"QR resp\",\t\t[0x7] = \"BR resp\",\n\t[0x8] = \"cycle start\",\t\t[0x9] = \"Lk req\",\n\t[0xa] = \"async stream packet\",\t[0xb] = \"Lk resp\",\n\t[0xc] = \"-reserved-\",\t\t[0xd] = \"-reserved-\",\n\t[0xe] = \"link internal\",\t[0xf] = \"-reserved-\",\n};\n\nstatic void log_ar_at_event(struct fw_ohci *ohci,\n\t\t\t    char dir, int speed, u32 *header, int evt)\n{\n\tint tcode = header[0] >> 4 & 0xf;\n\tchar specific[12];\n\n\tif (likely(!(param_debug & OHCI_PARAM_DEBUG_AT_AR)))\n\t\treturn;\n\n\tif (unlikely(evt >= ARRAY_SIZE(evts)))\n\t\t\tevt = 0x1f;\n\n\tif (evt == OHCI1394_evt_bus_reset) {\n\t\tohci_notice(ohci, \"A%c evt_bus_reset, generation %d\\n\",\n\t\t\t    dir, (header[2] >> 16) & 0xff);\n\t\treturn;\n\t}\n\n\tswitch (tcode) {\n\tcase 0x0: case 0x6: case 0x8:\n\t\tsnprintf(specific, sizeof(specific), \" = %08x\",\n\t\t\t be32_to_cpu((__force __be32)header[3]));\n\t\tbreak;\n\tcase 0x1: case 0x5: case 0x7: case 0x9: case 0xb:\n\t\tsnprintf(specific, sizeof(specific), \" %x,%x\",\n\t\t\t header[3] >> 16, header[3] & 0xffff);\n\t\tbreak;\n\tdefault:\n\t\tspecific[0] = '\\0';\n\t}\n\n\tswitch (tcode) {\n\tcase 0xa:\n\t\tohci_notice(ohci, \"A%c %s, %s\\n\",\n\t\t\t    dir, evts[evt], tcodes[tcode]);\n\t\tbreak;\n\tcase 0xe:\n\t\tohci_notice(ohci, \"A%c %s, PHY %08x %08x\\n\",\n\t\t\t    dir, evts[evt], header[1], header[2]);\n\t\tbreak;\n\tcase 0x0: case 0x1: case 0x4: case 0x5: case 0x9:\n\t\tohci_notice(ohci,\n\t\t\t    \"A%c spd %x tl %02x, %04x -> %04x, %s, %s, %04x%08x%s\\n\",\n\t\t\t    dir, speed, header[0] >> 10 & 0x3f,\n\t\t\t    header[1] >> 16, header[0] >> 16, evts[evt],\n\t\t\t    tcodes[tcode], header[1] & 0xffff, header[2], specific);\n\t\tbreak;\n\tdefault:\n\t\tohci_notice(ohci,\n\t\t\t    \"A%c spd %x tl %02x, %04x -> %04x, %s, %s%s\\n\",\n\t\t\t    dir, speed, header[0] >> 10 & 0x3f,\n\t\t\t    header[1] >> 16, header[0] >> 16, evts[evt],\n\t\t\t    tcodes[tcode], specific);\n\t}\n}\n\nstatic inline void reg_write(const struct fw_ohci *ohci, int offset, u32 data)\n{\n\twritel(data, ohci->registers + offset);\n}\n\nstatic inline u32 reg_read(const struct fw_ohci *ohci, int offset)\n{\n\treturn readl(ohci->registers + offset);\n}\n\nstatic inline void flush_writes(const struct fw_ohci *ohci)\n{\n\t \n\treg_read(ohci, OHCI1394_Version);\n}\n\n \nstatic int read_phy_reg(struct fw_ohci *ohci, int addr)\n{\n\tu32 val;\n\tint i;\n\n\treg_write(ohci, OHCI1394_PhyControl, OHCI1394_PhyControl_Read(addr));\n\tfor (i = 0; i < 3 + 100; i++) {\n\t\tval = reg_read(ohci, OHCI1394_PhyControl);\n\t\tif (!~val)\n\t\t\treturn -ENODEV;  \n\n\t\tif (val & OHCI1394_PhyControl_ReadDone)\n\t\t\treturn OHCI1394_PhyControl_ReadData(val);\n\n\t\t \n\t\tif (i >= 3)\n\t\t\tmsleep(1);\n\t}\n\tohci_err(ohci, \"failed to read phy reg %d\\n\", addr);\n\tdump_stack();\n\n\treturn -EBUSY;\n}\n\nstatic int write_phy_reg(const struct fw_ohci *ohci, int addr, u32 val)\n{\n\tint i;\n\n\treg_write(ohci, OHCI1394_PhyControl,\n\t\t  OHCI1394_PhyControl_Write(addr, val));\n\tfor (i = 0; i < 3 + 100; i++) {\n\t\tval = reg_read(ohci, OHCI1394_PhyControl);\n\t\tif (!~val)\n\t\t\treturn -ENODEV;  \n\n\t\tif (!(val & OHCI1394_PhyControl_WritePending))\n\t\t\treturn 0;\n\n\t\tif (i >= 3)\n\t\t\tmsleep(1);\n\t}\n\tohci_err(ohci, \"failed to write phy reg %d, val %u\\n\", addr, val);\n\tdump_stack();\n\n\treturn -EBUSY;\n}\n\nstatic int update_phy_reg(struct fw_ohci *ohci, int addr,\n\t\t\t  int clear_bits, int set_bits)\n{\n\tint ret = read_phy_reg(ohci, addr);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tif (addr == 5)\n\t\tclear_bits |= PHY_INT_STATUS_BITS;\n\n\treturn write_phy_reg(ohci, addr, (ret & ~clear_bits) | set_bits);\n}\n\nstatic int read_paged_phy_reg(struct fw_ohci *ohci, int page, int addr)\n{\n\tint ret;\n\n\tret = update_phy_reg(ohci, 7, PHY_PAGE_SELECT, page << 5);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn read_phy_reg(ohci, addr);\n}\n\nstatic int ohci_read_phy_reg(struct fw_card *card, int addr)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\tint ret;\n\n\tmutex_lock(&ohci->phy_reg_mutex);\n\tret = read_phy_reg(ohci, addr);\n\tmutex_unlock(&ohci->phy_reg_mutex);\n\n\treturn ret;\n}\n\nstatic int ohci_update_phy_reg(struct fw_card *card, int addr,\n\t\t\t       int clear_bits, int set_bits)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\tint ret;\n\n\tmutex_lock(&ohci->phy_reg_mutex);\n\tret = update_phy_reg(ohci, addr, clear_bits, set_bits);\n\tmutex_unlock(&ohci->phy_reg_mutex);\n\n\treturn ret;\n}\n\nstatic inline dma_addr_t ar_buffer_bus(struct ar_context *ctx, unsigned int i)\n{\n\treturn page_private(ctx->pages[i]);\n}\n\nstatic void ar_context_link_page(struct ar_context *ctx, unsigned int index)\n{\n\tstruct descriptor *d;\n\n\td = &ctx->descriptors[index];\n\td->branch_address  &= cpu_to_le32(~0xf);\n\td->res_count       =  cpu_to_le16(PAGE_SIZE);\n\td->transfer_status =  0;\n\n\twmb();  \n\td = &ctx->descriptors[ctx->last_buffer_index];\n\td->branch_address  |= cpu_to_le32(1);\n\n\tctx->last_buffer_index = index;\n\n\treg_write(ctx->ohci, CONTROL_SET(ctx->regs), CONTEXT_WAKE);\n}\n\nstatic void ar_context_release(struct ar_context *ctx)\n{\n\tstruct device *dev = ctx->ohci->card.device;\n\tunsigned int i;\n\n\tif (!ctx->buffer)\n\t\treturn;\n\n\tvunmap(ctx->buffer);\n\n\tfor (i = 0; i < AR_BUFFERS; i++) {\n\t\tif (ctx->pages[i])\n\t\t\tdma_free_pages(dev, PAGE_SIZE, ctx->pages[i],\n\t\t\t\t       ar_buffer_bus(ctx, i), DMA_FROM_DEVICE);\n\t}\n}\n\nstatic void ar_context_abort(struct ar_context *ctx, const char *error_msg)\n{\n\tstruct fw_ohci *ohci = ctx->ohci;\n\n\tif (reg_read(ohci, CONTROL_CLEAR(ctx->regs)) & CONTEXT_RUN) {\n\t\treg_write(ohci, CONTROL_CLEAR(ctx->regs), CONTEXT_RUN);\n\t\tflush_writes(ohci);\n\n\t\tohci_err(ohci, \"AR error: %s; DMA stopped\\n\", error_msg);\n\t}\n\t \n}\n\nstatic inline unsigned int ar_next_buffer_index(unsigned int index)\n{\n\treturn (index + 1) % AR_BUFFERS;\n}\n\nstatic inline unsigned int ar_first_buffer_index(struct ar_context *ctx)\n{\n\treturn ar_next_buffer_index(ctx->last_buffer_index);\n}\n\n \nstatic unsigned int ar_search_last_active_buffer(struct ar_context *ctx,\n\t\t\t\t\t\t unsigned int *buffer_offset)\n{\n\tunsigned int i, next_i, last = ctx->last_buffer_index;\n\t__le16 res_count, next_res_count;\n\n\ti = ar_first_buffer_index(ctx);\n\tres_count = READ_ONCE(ctx->descriptors[i].res_count);\n\n\t \n\twhile (i != last && res_count == 0) {\n\n\t\t \n\t\tnext_i = ar_next_buffer_index(i);\n\t\trmb();  \n\t\tnext_res_count = READ_ONCE(ctx->descriptors[next_i].res_count);\n\t\t \n\t\tif (next_res_count == cpu_to_le16(PAGE_SIZE)) {\n\t\t\t \n\t\t\tif (MAX_AR_PACKET_SIZE > PAGE_SIZE && i != last) {\n\t\t\t\tnext_i = ar_next_buffer_index(next_i);\n\t\t\t\trmb();\n\t\t\t\tnext_res_count = READ_ONCE(ctx->descriptors[next_i].res_count);\n\t\t\t\tif (next_res_count != cpu_to_le16(PAGE_SIZE))\n\t\t\t\t\tgoto next_buffer_is_active;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\nnext_buffer_is_active:\n\t\ti = next_i;\n\t\tres_count = next_res_count;\n\t}\n\n\trmb();  \n\n\t*buffer_offset = PAGE_SIZE - le16_to_cpu(res_count);\n\tif (*buffer_offset > PAGE_SIZE) {\n\t\t*buffer_offset = 0;\n\t\tar_context_abort(ctx, \"corrupted descriptor\");\n\t}\n\n\treturn i;\n}\n\nstatic void ar_sync_buffers_for_cpu(struct ar_context *ctx,\n\t\t\t\t    unsigned int end_buffer_index,\n\t\t\t\t    unsigned int end_buffer_offset)\n{\n\tunsigned int i;\n\n\ti = ar_first_buffer_index(ctx);\n\twhile (i != end_buffer_index) {\n\t\tdma_sync_single_for_cpu(ctx->ohci->card.device,\n\t\t\t\t\tar_buffer_bus(ctx, i),\n\t\t\t\t\tPAGE_SIZE, DMA_FROM_DEVICE);\n\t\ti = ar_next_buffer_index(i);\n\t}\n\tif (end_buffer_offset > 0)\n\t\tdma_sync_single_for_cpu(ctx->ohci->card.device,\n\t\t\t\t\tar_buffer_bus(ctx, i),\n\t\t\t\t\tend_buffer_offset, DMA_FROM_DEVICE);\n}\n\n#if defined(CONFIG_PPC_PMAC) && defined(CONFIG_PPC32)\n#define cond_le32_to_cpu(v) \\\n\t(ohci->quirks & QUIRK_BE_HEADERS ? (__force __u32)(v) : le32_to_cpu(v))\n#else\n#define cond_le32_to_cpu(v) le32_to_cpu(v)\n#endif\n\nstatic __le32 *handle_ar_packet(struct ar_context *ctx, __le32 *buffer)\n{\n\tstruct fw_ohci *ohci = ctx->ohci;\n\tstruct fw_packet p;\n\tu32 status, length, tcode;\n\tint evt;\n\n\tp.header[0] = cond_le32_to_cpu(buffer[0]);\n\tp.header[1] = cond_le32_to_cpu(buffer[1]);\n\tp.header[2] = cond_le32_to_cpu(buffer[2]);\n\n\ttcode = (p.header[0] >> 4) & 0x0f;\n\tswitch (tcode) {\n\tcase TCODE_WRITE_QUADLET_REQUEST:\n\tcase TCODE_READ_QUADLET_RESPONSE:\n\t\tp.header[3] = (__force __u32) buffer[3];\n\t\tp.header_length = 16;\n\t\tp.payload_length = 0;\n\t\tbreak;\n\n\tcase TCODE_READ_BLOCK_REQUEST :\n\t\tp.header[3] = cond_le32_to_cpu(buffer[3]);\n\t\tp.header_length = 16;\n\t\tp.payload_length = 0;\n\t\tbreak;\n\n\tcase TCODE_WRITE_BLOCK_REQUEST:\n\tcase TCODE_READ_BLOCK_RESPONSE:\n\tcase TCODE_LOCK_REQUEST:\n\tcase TCODE_LOCK_RESPONSE:\n\t\tp.header[3] = cond_le32_to_cpu(buffer[3]);\n\t\tp.header_length = 16;\n\t\tp.payload_length = p.header[3] >> 16;\n\t\tif (p.payload_length > MAX_ASYNC_PAYLOAD) {\n\t\t\tar_context_abort(ctx, \"invalid packet length\");\n\t\t\treturn NULL;\n\t\t}\n\t\tbreak;\n\n\tcase TCODE_WRITE_RESPONSE:\n\tcase TCODE_READ_QUADLET_REQUEST:\n\tcase OHCI_TCODE_PHY_PACKET:\n\t\tp.header_length = 12;\n\t\tp.payload_length = 0;\n\t\tbreak;\n\n\tdefault:\n\t\tar_context_abort(ctx, \"invalid tcode\");\n\t\treturn NULL;\n\t}\n\n\tp.payload = (void *) buffer + p.header_length;\n\n\t \n\tlength = (p.header_length + p.payload_length + 3) / 4;\n\tstatus = cond_le32_to_cpu(buffer[length]);\n\tevt    = (status >> 16) & 0x1f;\n\n\tp.ack        = evt - 16;\n\tp.speed      = (status >> 21) & 0x7;\n\tp.timestamp  = status & 0xffff;\n\tp.generation = ohci->request_generation;\n\n\tlog_ar_at_event(ohci, 'R', p.speed, p.header, evt);\n\n\t \n\tif (evt == OHCI1394_evt_no_status &&\n\t    (p.header[0] & 0xff) == (OHCI1394_phy_tcode << 4))\n\t\tp.ack = ACK_COMPLETE;\n\n\t \n\tif (evt == OHCI1394_evt_bus_reset) {\n\t\tif (!(ohci->quirks & QUIRK_RESET_PACKET))\n\t\t\tohci->request_generation = (p.header[2] >> 16) & 0xff;\n\t} else if (ctx == &ohci->ar_request_ctx) {\n\t\tfw_core_handle_request(&ohci->card, &p);\n\t} else {\n\t\tfw_core_handle_response(&ohci->card, &p);\n\t}\n\n\treturn buffer + length + 1;\n}\n\nstatic void *handle_ar_packets(struct ar_context *ctx, void *p, void *end)\n{\n\tvoid *next;\n\n\twhile (p < end) {\n\t\tnext = handle_ar_packet(ctx, p);\n\t\tif (!next)\n\t\t\treturn p;\n\t\tp = next;\n\t}\n\n\treturn p;\n}\n\nstatic void ar_recycle_buffers(struct ar_context *ctx, unsigned int end_buffer)\n{\n\tunsigned int i;\n\n\ti = ar_first_buffer_index(ctx);\n\twhile (i != end_buffer) {\n\t\tdma_sync_single_for_device(ctx->ohci->card.device,\n\t\t\t\t\t   ar_buffer_bus(ctx, i),\n\t\t\t\t\t   PAGE_SIZE, DMA_FROM_DEVICE);\n\t\tar_context_link_page(ctx, i);\n\t\ti = ar_next_buffer_index(i);\n\t}\n}\n\nstatic void ar_context_tasklet(unsigned long data)\n{\n\tstruct ar_context *ctx = (struct ar_context *)data;\n\tunsigned int end_buffer_index, end_buffer_offset;\n\tvoid *p, *end;\n\n\tp = ctx->pointer;\n\tif (!p)\n\t\treturn;\n\n\tend_buffer_index = ar_search_last_active_buffer(ctx,\n\t\t\t\t\t\t\t&end_buffer_offset);\n\tar_sync_buffers_for_cpu(ctx, end_buffer_index, end_buffer_offset);\n\tend = ctx->buffer + end_buffer_index * PAGE_SIZE + end_buffer_offset;\n\n\tif (end_buffer_index < ar_first_buffer_index(ctx)) {\n\t\t \n\t\tvoid *buffer_end = ctx->buffer + AR_BUFFERS * PAGE_SIZE;\n\t\tp = handle_ar_packets(ctx, p, buffer_end);\n\t\tif (p < buffer_end)\n\t\t\tgoto error;\n\t\t \n\t\tp -= AR_BUFFERS * PAGE_SIZE;\n\t}\n\n\tp = handle_ar_packets(ctx, p, end);\n\tif (p != end) {\n\t\tif (p > end)\n\t\t\tar_context_abort(ctx, \"inconsistent descriptor\");\n\t\tgoto error;\n\t}\n\n\tctx->pointer = p;\n\tar_recycle_buffers(ctx, end_buffer_index);\n\n\treturn;\n\nerror:\n\tctx->pointer = NULL;\n}\n\nstatic int ar_context_init(struct ar_context *ctx, struct fw_ohci *ohci,\n\t\t\t   unsigned int descriptors_offset, u32 regs)\n{\n\tstruct device *dev = ohci->card.device;\n\tunsigned int i;\n\tdma_addr_t dma_addr;\n\tstruct page *pages[AR_BUFFERS + AR_WRAPAROUND_PAGES];\n\tstruct descriptor *d;\n\n\tctx->regs        = regs;\n\tctx->ohci        = ohci;\n\ttasklet_init(&ctx->tasklet, ar_context_tasklet, (unsigned long)ctx);\n\n\tfor (i = 0; i < AR_BUFFERS; i++) {\n\t\tctx->pages[i] = dma_alloc_pages(dev, PAGE_SIZE, &dma_addr,\n\t\t\t\t\t\tDMA_FROM_DEVICE, GFP_KERNEL);\n\t\tif (!ctx->pages[i])\n\t\t\tgoto out_of_memory;\n\t\tset_page_private(ctx->pages[i], dma_addr);\n\t\tdma_sync_single_for_device(dev, dma_addr, PAGE_SIZE,\n\t\t\t\t\t   DMA_FROM_DEVICE);\n\t}\n\n\tfor (i = 0; i < AR_BUFFERS; i++)\n\t\tpages[i]              = ctx->pages[i];\n\tfor (i = 0; i < AR_WRAPAROUND_PAGES; i++)\n\t\tpages[AR_BUFFERS + i] = ctx->pages[i];\n\tctx->buffer = vmap(pages, ARRAY_SIZE(pages), VM_MAP, PAGE_KERNEL);\n\tif (!ctx->buffer)\n\t\tgoto out_of_memory;\n\n\tctx->descriptors     = ohci->misc_buffer     + descriptors_offset;\n\tctx->descriptors_bus = ohci->misc_buffer_bus + descriptors_offset;\n\n\tfor (i = 0; i < AR_BUFFERS; i++) {\n\t\td = &ctx->descriptors[i];\n\t\td->req_count      = cpu_to_le16(PAGE_SIZE);\n\t\td->control        = cpu_to_le16(DESCRIPTOR_INPUT_MORE |\n\t\t\t\t\t\tDESCRIPTOR_STATUS |\n\t\t\t\t\t\tDESCRIPTOR_BRANCH_ALWAYS);\n\t\td->data_address   = cpu_to_le32(ar_buffer_bus(ctx, i));\n\t\td->branch_address = cpu_to_le32(ctx->descriptors_bus +\n\t\t\tar_next_buffer_index(i) * sizeof(struct descriptor));\n\t}\n\n\treturn 0;\n\nout_of_memory:\n\tar_context_release(ctx);\n\n\treturn -ENOMEM;\n}\n\nstatic void ar_context_run(struct ar_context *ctx)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < AR_BUFFERS; i++)\n\t\tar_context_link_page(ctx, i);\n\n\tctx->pointer = ctx->buffer;\n\n\treg_write(ctx->ohci, COMMAND_PTR(ctx->regs), ctx->descriptors_bus | 1);\n\treg_write(ctx->ohci, CONTROL_SET(ctx->regs), CONTEXT_RUN);\n}\n\nstatic struct descriptor *find_branch_descriptor(struct descriptor *d, int z)\n{\n\t__le16 branch;\n\n\tbranch = d->control & cpu_to_le16(DESCRIPTOR_BRANCH_ALWAYS);\n\n\t \n\tif (z == 2 && branch == cpu_to_le16(DESCRIPTOR_BRANCH_ALWAYS))\n\t\treturn d;\n\telse\n\t\treturn d + z - 1;\n}\n\nstatic void context_tasklet(unsigned long data)\n{\n\tstruct context *ctx = (struct context *) data;\n\tstruct descriptor *d, *last;\n\tu32 address;\n\tint z;\n\tstruct descriptor_buffer *desc;\n\n\tdesc = list_entry(ctx->buffer_list.next,\n\t\t\tstruct descriptor_buffer, list);\n\tlast = ctx->last;\n\twhile (last->branch_address != 0) {\n\t\tstruct descriptor_buffer *old_desc = desc;\n\t\taddress = le32_to_cpu(last->branch_address);\n\t\tz = address & 0xf;\n\t\taddress &= ~0xf;\n\t\tctx->current_bus = address;\n\n\t\t \n\t\tif (address < desc->buffer_bus ||\n\t\t\t\taddress >= desc->buffer_bus + desc->used)\n\t\t\tdesc = list_entry(desc->list.next,\n\t\t\t\t\tstruct descriptor_buffer, list);\n\t\td = desc->buffer + (address - desc->buffer_bus) / sizeof(*d);\n\t\tlast = find_branch_descriptor(d, z);\n\n\t\tif (!ctx->callback(ctx, d, last))\n\t\t\tbreak;\n\n\t\tif (old_desc != desc) {\n\t\t\t \n\t\t\tunsigned long flags;\n\t\t\told_desc->used = 0;\n\t\t\tspin_lock_irqsave(&ctx->ohci->lock, flags);\n\t\t\tlist_move_tail(&old_desc->list, &ctx->buffer_list);\n\t\t\tspin_unlock_irqrestore(&ctx->ohci->lock, flags);\n\t\t}\n\t\tctx->last = last;\n\t}\n}\n\n \nstatic int context_add_buffer(struct context *ctx)\n{\n\tstruct descriptor_buffer *desc;\n\tdma_addr_t bus_addr;\n\tint offset;\n\n\t \n\tif (ctx->total_allocation >= 16*1024*1024)\n\t\treturn -ENOMEM;\n\n\tdesc = dmam_alloc_coherent(ctx->ohci->card.device, PAGE_SIZE, &bus_addr, GFP_ATOMIC);\n\tif (!desc)\n\t\treturn -ENOMEM;\n\n\toffset = (void *)&desc->buffer - (void *)desc;\n\t \n\tdesc->buffer_size = PAGE_SIZE - offset - 0x10;\n\tdesc->buffer_bus = bus_addr + offset;\n\tdesc->used = 0;\n\n\tlist_add_tail(&desc->list, &ctx->buffer_list);\n\tctx->total_allocation += PAGE_SIZE;\n\n\treturn 0;\n}\n\nstatic int context_init(struct context *ctx, struct fw_ohci *ohci,\n\t\t\tu32 regs, descriptor_callback_t callback)\n{\n\tctx->ohci = ohci;\n\tctx->regs = regs;\n\tctx->total_allocation = 0;\n\n\tINIT_LIST_HEAD(&ctx->buffer_list);\n\tif (context_add_buffer(ctx) < 0)\n\t\treturn -ENOMEM;\n\n\tctx->buffer_tail = list_entry(ctx->buffer_list.next,\n\t\t\tstruct descriptor_buffer, list);\n\n\ttasklet_init(&ctx->tasklet, context_tasklet, (unsigned long)ctx);\n\tctx->callback = callback;\n\n\t \n\tmemset(ctx->buffer_tail->buffer, 0, sizeof(*ctx->buffer_tail->buffer));\n\tctx->buffer_tail->buffer->control = cpu_to_le16(DESCRIPTOR_OUTPUT_LAST);\n\tctx->buffer_tail->buffer->transfer_status = cpu_to_le16(0x8011);\n\tctx->buffer_tail->used += sizeof(*ctx->buffer_tail->buffer);\n\tctx->last = ctx->buffer_tail->buffer;\n\tctx->prev = ctx->buffer_tail->buffer;\n\tctx->prev_z = 1;\n\n\treturn 0;\n}\n\nstatic void context_release(struct context *ctx)\n{\n\tstruct fw_card *card = &ctx->ohci->card;\n\tstruct descriptor_buffer *desc, *tmp;\n\n\tlist_for_each_entry_safe(desc, tmp, &ctx->buffer_list, list) {\n\t\tdmam_free_coherent(card->device, PAGE_SIZE, desc,\n\t\t\t\t   desc->buffer_bus - ((void *)&desc->buffer - (void *)desc));\n\t}\n}\n\n \nstatic struct descriptor *context_get_descriptors(struct context *ctx,\n\t\t\t\t\t\t  int z, dma_addr_t *d_bus)\n{\n\tstruct descriptor *d = NULL;\n\tstruct descriptor_buffer *desc = ctx->buffer_tail;\n\n\tif (z * sizeof(*d) > desc->buffer_size)\n\t\treturn NULL;\n\n\tif (z * sizeof(*d) > desc->buffer_size - desc->used) {\n\t\t \n\n\t\tif (desc->list.next == &ctx->buffer_list) {\n\t\t\t \n\t\t\tif (context_add_buffer(ctx) < 0)\n\t\t\t\treturn NULL;\n\t\t}\n\t\tdesc = list_entry(desc->list.next,\n\t\t\t\tstruct descriptor_buffer, list);\n\t\tctx->buffer_tail = desc;\n\t}\n\n\td = desc->buffer + desc->used / sizeof(*d);\n\tmemset(d, 0, z * sizeof(*d));\n\t*d_bus = desc->buffer_bus + desc->used;\n\n\treturn d;\n}\n\nstatic void context_run(struct context *ctx, u32 extra)\n{\n\tstruct fw_ohci *ohci = ctx->ohci;\n\n\treg_write(ohci, COMMAND_PTR(ctx->regs),\n\t\t  le32_to_cpu(ctx->last->branch_address));\n\treg_write(ohci, CONTROL_CLEAR(ctx->regs), ~0);\n\treg_write(ohci, CONTROL_SET(ctx->regs), CONTEXT_RUN | extra);\n\tctx->running = true;\n\tflush_writes(ohci);\n}\n\nstatic void context_append(struct context *ctx,\n\t\t\t   struct descriptor *d, int z, int extra)\n{\n\tdma_addr_t d_bus;\n\tstruct descriptor_buffer *desc = ctx->buffer_tail;\n\tstruct descriptor *d_branch;\n\n\td_bus = desc->buffer_bus + (d - desc->buffer) * sizeof(*d);\n\n\tdesc->used += (z + extra) * sizeof(*d);\n\n\twmb();  \n\n\td_branch = find_branch_descriptor(ctx->prev, ctx->prev_z);\n\td_branch->branch_address = cpu_to_le32(d_bus | z);\n\n\t \n\tif (unlikely(ctx->ohci->quirks & QUIRK_IR_WAKE) &&\n\t    d_branch != ctx->prev &&\n\t    (ctx->prev->control & cpu_to_le16(DESCRIPTOR_CMD)) ==\n\t     cpu_to_le16(DESCRIPTOR_INPUT_MORE)) {\n\t\tctx->prev->branch_address = cpu_to_le32(d_bus | z);\n\t}\n\n\tctx->prev = d;\n\tctx->prev_z = z;\n}\n\nstatic void context_stop(struct context *ctx)\n{\n\tstruct fw_ohci *ohci = ctx->ohci;\n\tu32 reg;\n\tint i;\n\n\treg_write(ohci, CONTROL_CLEAR(ctx->regs), CONTEXT_RUN);\n\tctx->running = false;\n\n\tfor (i = 0; i < 1000; i++) {\n\t\treg = reg_read(ohci, CONTROL_SET(ctx->regs));\n\t\tif ((reg & CONTEXT_ACTIVE) == 0)\n\t\t\treturn;\n\n\t\tif (i)\n\t\t\tudelay(10);\n\t}\n\tohci_err(ohci, \"DMA context still active (0x%08x)\\n\", reg);\n}\n\nstruct driver_data {\n\tu8 inline_data[8];\n\tstruct fw_packet *packet;\n};\n\n \nstatic int at_context_queue_packet(struct context *ctx,\n\t\t\t\t   struct fw_packet *packet)\n{\n\tstruct fw_ohci *ohci = ctx->ohci;\n\tdma_addr_t d_bus, payload_bus;\n\tstruct driver_data *driver_data;\n\tstruct descriptor *d, *last;\n\t__le32 *header;\n\tint z, tcode;\n\n\td = context_get_descriptors(ctx, 4, &d_bus);\n\tif (d == NULL) {\n\t\tpacket->ack = RCODE_SEND_ERROR;\n\t\treturn -1;\n\t}\n\n\td[0].control   = cpu_to_le16(DESCRIPTOR_KEY_IMMEDIATE);\n\td[0].res_count = cpu_to_le16(packet->timestamp);\n\n\t \n\n\ttcode = (packet->header[0] >> 4) & 0x0f;\n\theader = (__le32 *) &d[1];\n\tswitch (tcode) {\n\tcase TCODE_WRITE_QUADLET_REQUEST:\n\tcase TCODE_WRITE_BLOCK_REQUEST:\n\tcase TCODE_WRITE_RESPONSE:\n\tcase TCODE_READ_QUADLET_REQUEST:\n\tcase TCODE_READ_BLOCK_REQUEST:\n\tcase TCODE_READ_QUADLET_RESPONSE:\n\tcase TCODE_READ_BLOCK_RESPONSE:\n\tcase TCODE_LOCK_REQUEST:\n\tcase TCODE_LOCK_RESPONSE:\n\t\theader[0] = cpu_to_le32((packet->header[0] & 0xffff) |\n\t\t\t\t\t(packet->speed << 16));\n\t\theader[1] = cpu_to_le32((packet->header[1] & 0xffff) |\n\t\t\t\t\t(packet->header[0] & 0xffff0000));\n\t\theader[2] = cpu_to_le32(packet->header[2]);\n\n\t\tif (TCODE_IS_BLOCK_PACKET(tcode))\n\t\t\theader[3] = cpu_to_le32(packet->header[3]);\n\t\telse\n\t\t\theader[3] = (__force __le32) packet->header[3];\n\n\t\td[0].req_count = cpu_to_le16(packet->header_length);\n\t\tbreak;\n\n\tcase TCODE_LINK_INTERNAL:\n\t\theader[0] = cpu_to_le32((OHCI1394_phy_tcode << 4) |\n\t\t\t\t\t(packet->speed << 16));\n\t\theader[1] = cpu_to_le32(packet->header[1]);\n\t\theader[2] = cpu_to_le32(packet->header[2]);\n\t\td[0].req_count = cpu_to_le16(12);\n\n\t\tif (is_ping_packet(&packet->header[1]))\n\t\t\td[0].control |= cpu_to_le16(DESCRIPTOR_PING);\n\t\tbreak;\n\n\tcase TCODE_STREAM_DATA:\n\t\theader[0] = cpu_to_le32((packet->header[0] & 0xffff) |\n\t\t\t\t\t(packet->speed << 16));\n\t\theader[1] = cpu_to_le32(packet->header[0] & 0xffff0000);\n\t\td[0].req_count = cpu_to_le16(8);\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\tpacket->ack = RCODE_SEND_ERROR;\n\t\treturn -1;\n\t}\n\n\tBUILD_BUG_ON(sizeof(struct driver_data) > sizeof(struct descriptor));\n\tdriver_data = (struct driver_data *) &d[3];\n\tdriver_data->packet = packet;\n\tpacket->driver_data = driver_data;\n\n\tif (packet->payload_length > 0) {\n\t\tif (packet->payload_length > sizeof(driver_data->inline_data)) {\n\t\t\tpayload_bus = dma_map_single(ohci->card.device,\n\t\t\t\t\t\t     packet->payload,\n\t\t\t\t\t\t     packet->payload_length,\n\t\t\t\t\t\t     DMA_TO_DEVICE);\n\t\t\tif (dma_mapping_error(ohci->card.device, payload_bus)) {\n\t\t\t\tpacket->ack = RCODE_SEND_ERROR;\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tpacket->payload_bus\t= payload_bus;\n\t\t\tpacket->payload_mapped\t= true;\n\t\t} else {\n\t\t\tmemcpy(driver_data->inline_data, packet->payload,\n\t\t\t       packet->payload_length);\n\t\t\tpayload_bus = d_bus + 3 * sizeof(*d);\n\t\t}\n\n\t\td[2].req_count    = cpu_to_le16(packet->payload_length);\n\t\td[2].data_address = cpu_to_le32(payload_bus);\n\t\tlast = &d[2];\n\t\tz = 3;\n\t} else {\n\t\tlast = &d[0];\n\t\tz = 2;\n\t}\n\n\tlast->control |= cpu_to_le16(DESCRIPTOR_OUTPUT_LAST |\n\t\t\t\t     DESCRIPTOR_IRQ_ALWAYS |\n\t\t\t\t     DESCRIPTOR_BRANCH_ALWAYS);\n\n\t \n\tif (ohci->generation != packet->generation) {\n\t\tif (packet->payload_mapped)\n\t\t\tdma_unmap_single(ohci->card.device, payload_bus,\n\t\t\t\t\t packet->payload_length, DMA_TO_DEVICE);\n\t\tpacket->ack = RCODE_GENERATION;\n\t\treturn -1;\n\t}\n\n\tcontext_append(ctx, d, z, 4 - z);\n\n\tif (ctx->running)\n\t\treg_write(ohci, CONTROL_SET(ctx->regs), CONTEXT_WAKE);\n\telse\n\t\tcontext_run(ctx, 0);\n\n\treturn 0;\n}\n\nstatic void at_context_flush(struct context *ctx)\n{\n\ttasklet_disable(&ctx->tasklet);\n\n\tctx->flushing = true;\n\tcontext_tasklet((unsigned long)ctx);\n\tctx->flushing = false;\n\n\ttasklet_enable(&ctx->tasklet);\n}\n\nstatic int handle_at_packet(struct context *context,\n\t\t\t    struct descriptor *d,\n\t\t\t    struct descriptor *last)\n{\n\tstruct driver_data *driver_data;\n\tstruct fw_packet *packet;\n\tstruct fw_ohci *ohci = context->ohci;\n\tint evt;\n\n\tif (last->transfer_status == 0 && !context->flushing)\n\t\t \n\t\treturn 0;\n\n\tdriver_data = (struct driver_data *) &d[3];\n\tpacket = driver_data->packet;\n\tif (packet == NULL)\n\t\t \n\t\treturn 1;\n\n\tif (packet->payload_mapped)\n\t\tdma_unmap_single(ohci->card.device, packet->payload_bus,\n\t\t\t\t packet->payload_length, DMA_TO_DEVICE);\n\n\tevt = le16_to_cpu(last->transfer_status) & 0x1f;\n\tpacket->timestamp = le16_to_cpu(last->res_count);\n\n\tlog_ar_at_event(ohci, 'T', packet->speed, packet->header, evt);\n\n\tswitch (evt) {\n\tcase OHCI1394_evt_timeout:\n\t\t \n\t\tpacket->ack = RCODE_CANCELLED;\n\t\tbreak;\n\n\tcase OHCI1394_evt_flushed:\n\t\t \n\t\tpacket->ack = RCODE_GENERATION;\n\t\tbreak;\n\n\tcase OHCI1394_evt_missing_ack:\n\t\tif (context->flushing)\n\t\t\tpacket->ack = RCODE_GENERATION;\n\t\telse {\n\t\t\t \n\t\t\tpacket->ack = RCODE_NO_ACK;\n\t\t}\n\t\tbreak;\n\n\tcase ACK_COMPLETE + 0x10:\n\tcase ACK_PENDING + 0x10:\n\tcase ACK_BUSY_X + 0x10:\n\tcase ACK_BUSY_A + 0x10:\n\tcase ACK_BUSY_B + 0x10:\n\tcase ACK_DATA_ERROR + 0x10:\n\tcase ACK_TYPE_ERROR + 0x10:\n\t\tpacket->ack = evt - 0x10;\n\t\tbreak;\n\n\tcase OHCI1394_evt_no_status:\n\t\tif (context->flushing) {\n\t\t\tpacket->ack = RCODE_GENERATION;\n\t\t\tbreak;\n\t\t}\n\t\tfallthrough;\n\n\tdefault:\n\t\tpacket->ack = RCODE_SEND_ERROR;\n\t\tbreak;\n\t}\n\n\tpacket->callback(packet, &ohci->card, packet->ack);\n\n\treturn 1;\n}\n\n#define HEADER_GET_DESTINATION(q)\t(((q) >> 16) & 0xffff)\n#define HEADER_GET_TCODE(q)\t\t(((q) >> 4) & 0x0f)\n#define HEADER_GET_OFFSET_HIGH(q)\t(((q) >> 0) & 0xffff)\n#define HEADER_GET_DATA_LENGTH(q)\t(((q) >> 16) & 0xffff)\n#define HEADER_GET_EXTENDED_TCODE(q)\t(((q) >> 0) & 0xffff)\n\nstatic void handle_local_rom(struct fw_ohci *ohci,\n\t\t\t     struct fw_packet *packet, u32 csr)\n{\n\tstruct fw_packet response;\n\tint tcode, length, i;\n\n\ttcode = HEADER_GET_TCODE(packet->header[0]);\n\tif (TCODE_IS_BLOCK_PACKET(tcode))\n\t\tlength = HEADER_GET_DATA_LENGTH(packet->header[3]);\n\telse\n\t\tlength = 4;\n\n\ti = csr - CSR_CONFIG_ROM;\n\tif (i + length > CONFIG_ROM_SIZE) {\n\t\tfw_fill_response(&response, packet->header,\n\t\t\t\t RCODE_ADDRESS_ERROR, NULL, 0);\n\t} else if (!TCODE_IS_READ_REQUEST(tcode)) {\n\t\tfw_fill_response(&response, packet->header,\n\t\t\t\t RCODE_TYPE_ERROR, NULL, 0);\n\t} else {\n\t\tfw_fill_response(&response, packet->header, RCODE_COMPLETE,\n\t\t\t\t (void *) ohci->config_rom + i, length);\n\t}\n\n\tfw_core_handle_response(&ohci->card, &response);\n}\n\nstatic void handle_local_lock(struct fw_ohci *ohci,\n\t\t\t      struct fw_packet *packet, u32 csr)\n{\n\tstruct fw_packet response;\n\tint tcode, length, ext_tcode, sel, try;\n\t__be32 *payload, lock_old;\n\tu32 lock_arg, lock_data;\n\n\ttcode = HEADER_GET_TCODE(packet->header[0]);\n\tlength = HEADER_GET_DATA_LENGTH(packet->header[3]);\n\tpayload = packet->payload;\n\text_tcode = HEADER_GET_EXTENDED_TCODE(packet->header[3]);\n\n\tif (tcode == TCODE_LOCK_REQUEST &&\n\t    ext_tcode == EXTCODE_COMPARE_SWAP && length == 8) {\n\t\tlock_arg = be32_to_cpu(payload[0]);\n\t\tlock_data = be32_to_cpu(payload[1]);\n\t} else if (tcode == TCODE_READ_QUADLET_REQUEST) {\n\t\tlock_arg = 0;\n\t\tlock_data = 0;\n\t} else {\n\t\tfw_fill_response(&response, packet->header,\n\t\t\t\t RCODE_TYPE_ERROR, NULL, 0);\n\t\tgoto out;\n\t}\n\n\tsel = (csr - CSR_BUS_MANAGER_ID) / 4;\n\treg_write(ohci, OHCI1394_CSRData, lock_data);\n\treg_write(ohci, OHCI1394_CSRCompareData, lock_arg);\n\treg_write(ohci, OHCI1394_CSRControl, sel);\n\n\tfor (try = 0; try < 20; try++)\n\t\tif (reg_read(ohci, OHCI1394_CSRControl) & 0x80000000) {\n\t\t\tlock_old = cpu_to_be32(reg_read(ohci,\n\t\t\t\t\t\t\tOHCI1394_CSRData));\n\t\t\tfw_fill_response(&response, packet->header,\n\t\t\t\t\t RCODE_COMPLETE,\n\t\t\t\t\t &lock_old, sizeof(lock_old));\n\t\t\tgoto out;\n\t\t}\n\n\tohci_err(ohci, \"swap not done (CSR lock timeout)\\n\");\n\tfw_fill_response(&response, packet->header, RCODE_BUSY, NULL, 0);\n\n out:\n\tfw_core_handle_response(&ohci->card, &response);\n}\n\nstatic void handle_local_request(struct context *ctx, struct fw_packet *packet)\n{\n\tu64 offset, csr;\n\n\tif (ctx == &ctx->ohci->at_request_ctx) {\n\t\tpacket->ack = ACK_PENDING;\n\t\tpacket->callback(packet, &ctx->ohci->card, packet->ack);\n\t}\n\n\toffset =\n\t\t((unsigned long long)\n\t\t HEADER_GET_OFFSET_HIGH(packet->header[1]) << 32) |\n\t\tpacket->header[2];\n\tcsr = offset - CSR_REGISTER_BASE;\n\n\t \n\tif (csr >= CSR_CONFIG_ROM && csr < CSR_CONFIG_ROM_END)\n\t\thandle_local_rom(ctx->ohci, packet, csr);\n\telse switch (csr) {\n\tcase CSR_BUS_MANAGER_ID:\n\tcase CSR_BANDWIDTH_AVAILABLE:\n\tcase CSR_CHANNELS_AVAILABLE_HI:\n\tcase CSR_CHANNELS_AVAILABLE_LO:\n\t\thandle_local_lock(ctx->ohci, packet, csr);\n\t\tbreak;\n\tdefault:\n\t\tif (ctx == &ctx->ohci->at_request_ctx)\n\t\t\tfw_core_handle_request(&ctx->ohci->card, packet);\n\t\telse\n\t\t\tfw_core_handle_response(&ctx->ohci->card, packet);\n\t\tbreak;\n\t}\n\n\tif (ctx == &ctx->ohci->at_response_ctx) {\n\t\tpacket->ack = ACK_COMPLETE;\n\t\tpacket->callback(packet, &ctx->ohci->card, packet->ack);\n\t}\n}\n\nstatic u32 get_cycle_time(struct fw_ohci *ohci);\n\nstatic void at_context_transmit(struct context *ctx, struct fw_packet *packet)\n{\n\tunsigned long flags;\n\tint ret;\n\n\tspin_lock_irqsave(&ctx->ohci->lock, flags);\n\n\tif (HEADER_GET_DESTINATION(packet->header[0]) == ctx->ohci->node_id &&\n\t    ctx->ohci->generation == packet->generation) {\n\t\tspin_unlock_irqrestore(&ctx->ohci->lock, flags);\n\n\t\t\n\t\tpacket->timestamp = cycle_time_to_ohci_tstamp(get_cycle_time(ctx->ohci));\n\n\t\thandle_local_request(ctx, packet);\n\t\treturn;\n\t}\n\n\tret = at_context_queue_packet(ctx, packet);\n\tspin_unlock_irqrestore(&ctx->ohci->lock, flags);\n\n\tif (ret < 0) {\n\t\t\n\t\tpacket->timestamp = cycle_time_to_ohci_tstamp(get_cycle_time(ctx->ohci));\n\n\t\tpacket->callback(packet, &ctx->ohci->card, packet->ack);\n\t}\n}\n\nstatic void detect_dead_context(struct fw_ohci *ohci,\n\t\t\t\tconst char *name, unsigned int regs)\n{\n\tu32 ctl;\n\n\tctl = reg_read(ohci, CONTROL_SET(regs));\n\tif (ctl & CONTEXT_DEAD)\n\t\tohci_err(ohci, \"DMA context %s has stopped, error code: %s\\n\",\n\t\t\tname, evts[ctl & 0x1f]);\n}\n\nstatic void handle_dead_contexts(struct fw_ohci *ohci)\n{\n\tunsigned int i;\n\tchar name[8];\n\n\tdetect_dead_context(ohci, \"ATReq\", OHCI1394_AsReqTrContextBase);\n\tdetect_dead_context(ohci, \"ATRsp\", OHCI1394_AsRspTrContextBase);\n\tdetect_dead_context(ohci, \"ARReq\", OHCI1394_AsReqRcvContextBase);\n\tdetect_dead_context(ohci, \"ARRsp\", OHCI1394_AsRspRcvContextBase);\n\tfor (i = 0; i < 32; ++i) {\n\t\tif (!(ohci->it_context_support & (1 << i)))\n\t\t\tcontinue;\n\t\tsprintf(name, \"IT%u\", i);\n\t\tdetect_dead_context(ohci, name, OHCI1394_IsoXmitContextBase(i));\n\t}\n\tfor (i = 0; i < 32; ++i) {\n\t\tif (!(ohci->ir_context_support & (1 << i)))\n\t\t\tcontinue;\n\t\tsprintf(name, \"IR%u\", i);\n\t\tdetect_dead_context(ohci, name, OHCI1394_IsoRcvContextBase(i));\n\t}\n\t \n}\n\nstatic u32 cycle_timer_ticks(u32 cycle_timer)\n{\n\tu32 ticks;\n\n\tticks = cycle_timer & 0xfff;\n\tticks += 3072 * ((cycle_timer >> 12) & 0x1fff);\n\tticks += (3072 * 8000) * (cycle_timer >> 25);\n\n\treturn ticks;\n}\n\n \nstatic u32 get_cycle_time(struct fw_ohci *ohci)\n{\n\tu32 c0, c1, c2;\n\tu32 t0, t1, t2;\n\ts32 diff01, diff12;\n\tint i;\n\n\tif (has_reboot_by_cycle_timer_read_quirk(ohci))\n\t\treturn 0;\n\n\tc2 = reg_read(ohci, OHCI1394_IsochronousCycleTimer);\n\n\tif (ohci->quirks & QUIRK_CYCLE_TIMER) {\n\t\ti = 0;\n\t\tc1 = c2;\n\t\tc2 = reg_read(ohci, OHCI1394_IsochronousCycleTimer);\n\t\tdo {\n\t\t\tc0 = c1;\n\t\t\tc1 = c2;\n\t\t\tc2 = reg_read(ohci, OHCI1394_IsochronousCycleTimer);\n\t\t\tt0 = cycle_timer_ticks(c0);\n\t\t\tt1 = cycle_timer_ticks(c1);\n\t\t\tt2 = cycle_timer_ticks(c2);\n\t\t\tdiff01 = t1 - t0;\n\t\t\tdiff12 = t2 - t1;\n\t\t} while ((diff01 <= 0 || diff12 <= 0 ||\n\t\t\t  diff01 / diff12 >= 2 || diff12 / diff01 >= 2)\n\t\t\t && i++ < 20);\n\t}\n\n\treturn c2;\n}\n\n \nstatic u32 update_bus_time(struct fw_ohci *ohci)\n{\n\tu32 cycle_time_seconds = get_cycle_time(ohci) >> 25;\n\n\tif (unlikely(!ohci->bus_time_running)) {\n\t\treg_write(ohci, OHCI1394_IntMaskSet, OHCI1394_cycle64Seconds);\n\t\tohci->bus_time = (lower_32_bits(ktime_get_seconds()) & ~0x7f) |\n\t\t                 (cycle_time_seconds & 0x40);\n\t\tohci->bus_time_running = true;\n\t}\n\n\tif ((ohci->bus_time & 0x40) != (cycle_time_seconds & 0x40))\n\t\tohci->bus_time += 0x40;\n\n\treturn ohci->bus_time | cycle_time_seconds;\n}\n\nstatic int get_status_for_port(struct fw_ohci *ohci, int port_index)\n{\n\tint reg;\n\n\tmutex_lock(&ohci->phy_reg_mutex);\n\treg = write_phy_reg(ohci, 7, port_index);\n\tif (reg >= 0)\n\t\treg = read_phy_reg(ohci, 8);\n\tmutex_unlock(&ohci->phy_reg_mutex);\n\tif (reg < 0)\n\t\treturn reg;\n\n\tswitch (reg & 0x0f) {\n\tcase 0x06:\n\t\treturn 2;\t \n\tcase 0x0e:\n\t\treturn 3;\t \n\t}\n\treturn 1;\t\t \n}\n\nstatic int get_self_id_pos(struct fw_ohci *ohci, u32 self_id,\n\tint self_id_count)\n{\n\tint i;\n\tu32 entry;\n\n\tfor (i = 0; i < self_id_count; i++) {\n\t\tentry = ohci->self_id_buffer[i];\n\t\tif ((self_id & 0xff000000) == (entry & 0xff000000))\n\t\t\treturn -1;\n\t\tif ((self_id & 0xff000000) < (entry & 0xff000000))\n\t\t\treturn i;\n\t}\n\treturn i;\n}\n\nstatic int initiated_reset(struct fw_ohci *ohci)\n{\n\tint reg;\n\tint ret = 0;\n\n\tmutex_lock(&ohci->phy_reg_mutex);\n\treg = write_phy_reg(ohci, 7, 0xe0);  \n\tif (reg >= 0) {\n\t\treg = read_phy_reg(ohci, 8);\n\t\treg |= 0x40;\n\t\treg = write_phy_reg(ohci, 8, reg);  \n\t\tif (reg >= 0) {\n\t\t\treg = read_phy_reg(ohci, 12);  \n\t\t\tif (reg >= 0) {\n\t\t\t\tif ((reg & 0x08) == 0x08) {\n\t\t\t\t\t \n\t\t\t\t\tret = 0x2;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tmutex_unlock(&ohci->phy_reg_mutex);\n\treturn ret;\n}\n\n \nstatic int find_and_insert_self_id(struct fw_ohci *ohci, int self_id_count)\n{\n\tint reg, i, pos, status;\n\t \n\tu32 self_id = 0x8040c800;\n\n\treg = reg_read(ohci, OHCI1394_NodeID);\n\tif (!(reg & OHCI1394_NodeID_idValid)) {\n\t\tohci_notice(ohci,\n\t\t\t    \"node ID not valid, new bus reset in progress\\n\");\n\t\treturn -EBUSY;\n\t}\n\tself_id |= ((reg & 0x3f) << 24);  \n\n\treg = ohci_read_phy_reg(&ohci->card, 4);\n\tif (reg < 0)\n\t\treturn reg;\n\tself_id |= ((reg & 0x07) << 8);  \n\n\treg = ohci_read_phy_reg(&ohci->card, 1);\n\tif (reg < 0)\n\t\treturn reg;\n\tself_id |= ((reg & 0x3f) << 16);  \n\n\tfor (i = 0; i < 3; i++) {\n\t\tstatus = get_status_for_port(ohci, i);\n\t\tif (status < 0)\n\t\t\treturn status;\n\t\tself_id |= ((status & 0x3) << (6 - (i * 2)));\n\t}\n\n\tself_id |= initiated_reset(ohci);\n\n\tpos = get_self_id_pos(ohci, self_id, self_id_count);\n\tif (pos >= 0) {\n\t\tmemmove(&(ohci->self_id_buffer[pos+1]),\n\t\t\t&(ohci->self_id_buffer[pos]),\n\t\t\t(self_id_count - pos) * sizeof(*ohci->self_id_buffer));\n\t\tohci->self_id_buffer[pos] = self_id;\n\t\tself_id_count++;\n\t}\n\treturn self_id_count;\n}\n\nstatic void bus_reset_work(struct work_struct *work)\n{\n\tstruct fw_ohci *ohci =\n\t\tcontainer_of(work, struct fw_ohci, bus_reset_work);\n\tint self_id_count, generation, new_generation, i, j;\n\tu32 reg;\n\tvoid *free_rom = NULL;\n\tdma_addr_t free_rom_bus = 0;\n\tbool is_new_root;\n\n\treg = reg_read(ohci, OHCI1394_NodeID);\n\tif (!(reg & OHCI1394_NodeID_idValid)) {\n\t\tohci_notice(ohci,\n\t\t\t    \"node ID not valid, new bus reset in progress\\n\");\n\t\treturn;\n\t}\n\tif ((reg & OHCI1394_NodeID_nodeNumber) == 63) {\n\t\tohci_notice(ohci, \"malconfigured bus\\n\");\n\t\treturn;\n\t}\n\tohci->node_id = reg & (OHCI1394_NodeID_busNumber |\n\t\t\t       OHCI1394_NodeID_nodeNumber);\n\n\tis_new_root = (reg & OHCI1394_NodeID_root) != 0;\n\tif (!(ohci->is_root && is_new_root))\n\t\treg_write(ohci, OHCI1394_LinkControlSet,\n\t\t\t  OHCI1394_LinkControl_cycleMaster);\n\tohci->is_root = is_new_root;\n\n\treg = reg_read(ohci, OHCI1394_SelfIDCount);\n\tif (reg & OHCI1394_SelfIDCount_selfIDError) {\n\t\tohci_notice(ohci, \"self ID receive error\\n\");\n\t\treturn;\n\t}\n\t \n\tself_id_count = (reg >> 3) & 0xff;\n\n\tif (self_id_count > 252) {\n\t\tohci_notice(ohci, \"bad selfIDSize (%08x)\\n\", reg);\n\t\treturn;\n\t}\n\n\tgeneration = (cond_le32_to_cpu(ohci->self_id[0]) >> 16) & 0xff;\n\trmb();\n\n\tfor (i = 1, j = 0; j < self_id_count; i += 2, j++) {\n\t\tu32 id  = cond_le32_to_cpu(ohci->self_id[i]);\n\t\tu32 id2 = cond_le32_to_cpu(ohci->self_id[i + 1]);\n\n\t\tif (id != ~id2) {\n\t\t\t \n\t\t\tif (id == 0xffff008f) {\n\t\t\t\tohci_notice(ohci, \"ignoring spurious self IDs\\n\");\n\t\t\t\tself_id_count = j;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tohci_notice(ohci, \"bad self ID %d/%d (%08x != ~%08x)\\n\",\n\t\t\t\t    j, self_id_count, id, id2);\n\t\t\treturn;\n\t\t}\n\t\tohci->self_id_buffer[j] = id;\n\t}\n\n\tif (ohci->quirks & QUIRK_TI_SLLZ059) {\n\t\tself_id_count = find_and_insert_self_id(ohci, self_id_count);\n\t\tif (self_id_count < 0) {\n\t\t\tohci_notice(ohci,\n\t\t\t\t    \"could not construct local self ID\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (self_id_count == 0) {\n\t\tohci_notice(ohci, \"no self IDs\\n\");\n\t\treturn;\n\t}\n\trmb();\n\n\t \n\n\tnew_generation = (reg_read(ohci, OHCI1394_SelfIDCount) >> 16) & 0xff;\n\tif (new_generation != generation) {\n\t\tohci_notice(ohci, \"new bus reset, discarding self ids\\n\");\n\t\treturn;\n\t}\n\n\t \n\tspin_lock_irq(&ohci->lock);\n\n\tohci->generation = -1;  \n\tcontext_stop(&ohci->at_request_ctx);\n\tcontext_stop(&ohci->at_response_ctx);\n\n\tspin_unlock_irq(&ohci->lock);\n\n\t \n\tat_context_flush(&ohci->at_request_ctx);\n\tat_context_flush(&ohci->at_response_ctx);\n\n\tspin_lock_irq(&ohci->lock);\n\n\tohci->generation = generation;\n\treg_write(ohci, OHCI1394_IntEventClear, OHCI1394_busReset);\n\n\tif (ohci->quirks & QUIRK_RESET_PACKET)\n\t\tohci->request_generation = generation;\n\n\t \n\n\tif (ohci->next_config_rom != NULL) {\n\t\tif (ohci->next_config_rom != ohci->config_rom) {\n\t\t\tfree_rom      = ohci->config_rom;\n\t\t\tfree_rom_bus  = ohci->config_rom_bus;\n\t\t}\n\t\tohci->config_rom      = ohci->next_config_rom;\n\t\tohci->config_rom_bus  = ohci->next_config_rom_bus;\n\t\tohci->next_config_rom = NULL;\n\n\t\t \n\t\treg_write(ohci, OHCI1394_BusOptions,\n\t\t\t  be32_to_cpu(ohci->config_rom[2]));\n\t\tohci->config_rom[0] = ohci->next_header;\n\t\treg_write(ohci, OHCI1394_ConfigROMhdr,\n\t\t\t  be32_to_cpu(ohci->next_header));\n\t}\n\n\tif (param_remote_dma) {\n\t\treg_write(ohci, OHCI1394_PhyReqFilterHiSet, ~0);\n\t\treg_write(ohci, OHCI1394_PhyReqFilterLoSet, ~0);\n\t}\n\n\tspin_unlock_irq(&ohci->lock);\n\n\tif (free_rom)\n\t\tdmam_free_coherent(ohci->card.device, CONFIG_ROM_SIZE, free_rom, free_rom_bus);\n\n\tlog_selfids(ohci, generation, self_id_count);\n\n\tfw_core_handle_bus_reset(&ohci->card, ohci->node_id, generation,\n\t\t\t\t self_id_count, ohci->self_id_buffer,\n\t\t\t\t ohci->csr_state_setclear_abdicate);\n\tohci->csr_state_setclear_abdicate = false;\n}\n\nstatic irqreturn_t irq_handler(int irq, void *data)\n{\n\tstruct fw_ohci *ohci = data;\n\tu32 event, iso_event;\n\tint i;\n\n\tevent = reg_read(ohci, OHCI1394_IntEventClear);\n\n\tif (!event || !~event)\n\t\treturn IRQ_NONE;\n\n\t \n\treg_write(ohci, OHCI1394_IntEventClear,\n\t\t  event & ~(OHCI1394_busReset | OHCI1394_postedWriteErr));\n\tlog_irqs(ohci, event);\n\n\tif (event & OHCI1394_selfIDComplete)\n\t\tqueue_work(selfid_workqueue, &ohci->bus_reset_work);\n\n\tif (event & OHCI1394_RQPkt)\n\t\ttasklet_schedule(&ohci->ar_request_ctx.tasklet);\n\n\tif (event & OHCI1394_RSPkt)\n\t\ttasklet_schedule(&ohci->ar_response_ctx.tasklet);\n\n\tif (event & OHCI1394_reqTxComplete)\n\t\ttasklet_schedule(&ohci->at_request_ctx.tasklet);\n\n\tif (event & OHCI1394_respTxComplete)\n\t\ttasklet_schedule(&ohci->at_response_ctx.tasklet);\n\n\tif (event & OHCI1394_isochRx) {\n\t\tiso_event = reg_read(ohci, OHCI1394_IsoRecvIntEventClear);\n\t\treg_write(ohci, OHCI1394_IsoRecvIntEventClear, iso_event);\n\n\t\twhile (iso_event) {\n\t\t\ti = ffs(iso_event) - 1;\n\t\t\ttasklet_schedule(\n\t\t\t\t&ohci->ir_context_list[i].context.tasklet);\n\t\t\tiso_event &= ~(1 << i);\n\t\t}\n\t}\n\n\tif (event & OHCI1394_isochTx) {\n\t\tiso_event = reg_read(ohci, OHCI1394_IsoXmitIntEventClear);\n\t\treg_write(ohci, OHCI1394_IsoXmitIntEventClear, iso_event);\n\n\t\twhile (iso_event) {\n\t\t\ti = ffs(iso_event) - 1;\n\t\t\ttasklet_schedule(\n\t\t\t\t&ohci->it_context_list[i].context.tasklet);\n\t\t\tiso_event &= ~(1 << i);\n\t\t}\n\t}\n\n\tif (unlikely(event & OHCI1394_regAccessFail))\n\t\tohci_err(ohci, \"register access failure\\n\");\n\n\tif (unlikely(event & OHCI1394_postedWriteErr)) {\n\t\treg_read(ohci, OHCI1394_PostedWriteAddressHi);\n\t\treg_read(ohci, OHCI1394_PostedWriteAddressLo);\n\t\treg_write(ohci, OHCI1394_IntEventClear,\n\t\t\t  OHCI1394_postedWriteErr);\n\t\tif (printk_ratelimit())\n\t\t\tohci_err(ohci, \"PCI posted write error\\n\");\n\t}\n\n\tif (unlikely(event & OHCI1394_cycleTooLong)) {\n\t\tif (printk_ratelimit())\n\t\t\tohci_notice(ohci, \"isochronous cycle too long\\n\");\n\t\treg_write(ohci, OHCI1394_LinkControlSet,\n\t\t\t  OHCI1394_LinkControl_cycleMaster);\n\t}\n\n\tif (unlikely(event & OHCI1394_cycleInconsistent)) {\n\t\t \n\t\tif (printk_ratelimit())\n\t\t\tohci_notice(ohci, \"isochronous cycle inconsistent\\n\");\n\t}\n\n\tif (unlikely(event & OHCI1394_unrecoverableError))\n\t\thandle_dead_contexts(ohci);\n\n\tif (event & OHCI1394_cycle64Seconds) {\n\t\tspin_lock(&ohci->lock);\n\t\tupdate_bus_time(ohci);\n\t\tspin_unlock(&ohci->lock);\n\t} else\n\t\tflush_writes(ohci);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int software_reset(struct fw_ohci *ohci)\n{\n\tu32 val;\n\tint i;\n\n\treg_write(ohci, OHCI1394_HCControlSet, OHCI1394_HCControl_softReset);\n\tfor (i = 0; i < 500; i++) {\n\t\tval = reg_read(ohci, OHCI1394_HCControlSet);\n\t\tif (!~val)\n\t\t\treturn -ENODEV;  \n\n\t\tif (!(val & OHCI1394_HCControl_softReset))\n\t\t\treturn 0;\n\n\t\tmsleep(1);\n\t}\n\n\treturn -EBUSY;\n}\n\nstatic void copy_config_rom(__be32 *dest, const __be32 *src, size_t length)\n{\n\tsize_t size = length * 4;\n\n\tmemcpy(dest, src, size);\n\tif (size < CONFIG_ROM_SIZE)\n\t\tmemset(&dest[length], 0, CONFIG_ROM_SIZE - size);\n}\n\nstatic int configure_1394a_enhancements(struct fw_ohci *ohci)\n{\n\tbool enable_1394a;\n\tint ret, clear, set, offset;\n\n\t \n\tif (!(reg_read(ohci, OHCI1394_HCControlSet) &\n\t      OHCI1394_HCControl_programPhyEnable))\n\t\treturn 0;\n\n\t \n\tenable_1394a = false;\n\tret = read_phy_reg(ohci, 2);\n\tif (ret < 0)\n\t\treturn ret;\n\tif ((ret & PHY_EXTENDED_REGISTERS) == PHY_EXTENDED_REGISTERS) {\n\t\tret = read_paged_phy_reg(ohci, 1, 8);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (ret >= 1)\n\t\t\tenable_1394a = true;\n\t}\n\n\tif (ohci->quirks & QUIRK_NO_1394A)\n\t\tenable_1394a = false;\n\n\t \n\tif (enable_1394a) {\n\t\tclear = 0;\n\t\tset = PHY_ENABLE_ACCEL | PHY_ENABLE_MULTI;\n\t} else {\n\t\tclear = PHY_ENABLE_ACCEL | PHY_ENABLE_MULTI;\n\t\tset = 0;\n\t}\n\tret = update_phy_reg(ohci, 5, clear, set);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (enable_1394a)\n\t\toffset = OHCI1394_HCControlSet;\n\telse\n\t\toffset = OHCI1394_HCControlClear;\n\treg_write(ohci, offset, OHCI1394_HCControl_aPhyEnhanceEnable);\n\n\t \n\treg_write(ohci, OHCI1394_HCControlClear,\n\t\t  OHCI1394_HCControl_programPhyEnable);\n\n\treturn 0;\n}\n\nstatic int probe_tsb41ba3d(struct fw_ohci *ohci)\n{\n\t \n\tstatic const u8 id[] = { 0x08, 0x00, 0x28, 0x83, 0x30, 0x05, };\n\tint reg, i;\n\n\treg = read_phy_reg(ohci, 2);\n\tif (reg < 0)\n\t\treturn reg;\n\tif ((reg & PHY_EXTENDED_REGISTERS) != PHY_EXTENDED_REGISTERS)\n\t\treturn 0;\n\n\tfor (i = ARRAY_SIZE(id) - 1; i >= 0; i--) {\n\t\treg = read_paged_phy_reg(ohci, 1, i + 10);\n\t\tif (reg < 0)\n\t\t\treturn reg;\n\t\tif (reg != id[i])\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic int ohci_enable(struct fw_card *card,\n\t\t       const __be32 *config_rom, size_t length)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\tu32 lps, version, irqs;\n\tint i, ret;\n\n\tret = software_reset(ohci);\n\tif (ret < 0) {\n\t\tohci_err(ohci, \"failed to reset ohci card\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\n\treg_write(ohci, OHCI1394_HCControlSet,\n\t\t  OHCI1394_HCControl_LPS |\n\t\t  OHCI1394_HCControl_postedWriteEnable);\n\tflush_writes(ohci);\n\n\tfor (lps = 0, i = 0; !lps && i < 3; i++) {\n\t\tmsleep(50);\n\t\tlps = reg_read(ohci, OHCI1394_HCControlSet) &\n\t\t      OHCI1394_HCControl_LPS;\n\t}\n\n\tif (!lps) {\n\t\tohci_err(ohci, \"failed to set Link Power Status\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (ohci->quirks & QUIRK_TI_SLLZ059) {\n\t\tret = probe_tsb41ba3d(ohci);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (ret)\n\t\t\tohci_notice(ohci, \"local TSB41BA3D phy\\n\");\n\t\telse\n\t\t\tohci->quirks &= ~QUIRK_TI_SLLZ059;\n\t}\n\n\treg_write(ohci, OHCI1394_HCControlClear,\n\t\t  OHCI1394_HCControl_noByteSwapData);\n\n\treg_write(ohci, OHCI1394_SelfIDBuffer, ohci->self_id_bus);\n\treg_write(ohci, OHCI1394_LinkControlSet,\n\t\t  OHCI1394_LinkControl_cycleTimerEnable |\n\t\t  OHCI1394_LinkControl_cycleMaster);\n\n\treg_write(ohci, OHCI1394_ATRetries,\n\t\t  OHCI1394_MAX_AT_REQ_RETRIES |\n\t\t  (OHCI1394_MAX_AT_RESP_RETRIES << 4) |\n\t\t  (OHCI1394_MAX_PHYS_RESP_RETRIES << 8) |\n\t\t  (200 << 16));\n\n\tohci->bus_time_running = false;\n\n\tfor (i = 0; i < 32; i++)\n\t\tif (ohci->ir_context_support & (1 << i))\n\t\t\treg_write(ohci, OHCI1394_IsoRcvContextControlClear(i),\n\t\t\t\t  IR_CONTEXT_MULTI_CHANNEL_MODE);\n\n\tversion = reg_read(ohci, OHCI1394_Version) & 0x00ff00ff;\n\tif (version >= OHCI_VERSION_1_1) {\n\t\treg_write(ohci, OHCI1394_InitialChannelsAvailableHi,\n\t\t\t  0xfffffffe);\n\t\tcard->broadcast_channel_auto_allocated = true;\n\t}\n\n\t \n\treg_write(ohci, OHCI1394_FairnessControl, 0x3f);\n\tohci->pri_req_max = reg_read(ohci, OHCI1394_FairnessControl) & 0x3f;\n\treg_write(ohci, OHCI1394_FairnessControl, 0);\n\tcard->priority_budget_implemented = ohci->pri_req_max != 0;\n\n\treg_write(ohci, OHCI1394_PhyUpperBound, FW_MAX_PHYSICAL_RANGE >> 16);\n\treg_write(ohci, OHCI1394_IntEventClear, ~0);\n\treg_write(ohci, OHCI1394_IntMaskClear, ~0);\n\n\tret = configure_1394a_enhancements(ohci);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tret = ohci_update_phy_reg(card, 4, 0, PHY_LINK_ACTIVE | PHY_CONTENDER);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\n\tif (config_rom) {\n\t\tohci->next_config_rom = dmam_alloc_coherent(ohci->card.device, CONFIG_ROM_SIZE,\n\t\t\t\t\t\t\t    &ohci->next_config_rom_bus, GFP_KERNEL);\n\t\tif (ohci->next_config_rom == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tcopy_config_rom(ohci->next_config_rom, config_rom, length);\n\t} else {\n\t\t \n\t\tohci->next_config_rom = ohci->config_rom;\n\t\tohci->next_config_rom_bus = ohci->config_rom_bus;\n\t}\n\n\tohci->next_header = ohci->next_config_rom[0];\n\tohci->next_config_rom[0] = 0;\n\treg_write(ohci, OHCI1394_ConfigROMhdr, 0);\n\treg_write(ohci, OHCI1394_BusOptions,\n\t\t  be32_to_cpu(ohci->next_config_rom[2]));\n\treg_write(ohci, OHCI1394_ConfigROMmap, ohci->next_config_rom_bus);\n\n\treg_write(ohci, OHCI1394_AsReqFilterHiSet, 0x80000000);\n\n\tirqs =\tOHCI1394_reqTxComplete | OHCI1394_respTxComplete |\n\t\tOHCI1394_RQPkt | OHCI1394_RSPkt |\n\t\tOHCI1394_isochTx | OHCI1394_isochRx |\n\t\tOHCI1394_postedWriteErr |\n\t\tOHCI1394_selfIDComplete |\n\t\tOHCI1394_regAccessFail |\n\t\tOHCI1394_cycleInconsistent |\n\t\tOHCI1394_unrecoverableError |\n\t\tOHCI1394_cycleTooLong |\n\t\tOHCI1394_masterIntEnable;\n\tif (param_debug & OHCI_PARAM_DEBUG_BUSRESETS)\n\t\tirqs |= OHCI1394_busReset;\n\treg_write(ohci, OHCI1394_IntMaskSet, irqs);\n\n\treg_write(ohci, OHCI1394_HCControlSet,\n\t\t  OHCI1394_HCControl_linkEnable |\n\t\t  OHCI1394_HCControl_BIBimageValid);\n\n\treg_write(ohci, OHCI1394_LinkControlSet,\n\t\t  OHCI1394_LinkControl_rcvSelfID |\n\t\t  OHCI1394_LinkControl_rcvPhyPkt);\n\n\tar_context_run(&ohci->ar_request_ctx);\n\tar_context_run(&ohci->ar_response_ctx);\n\n\tflush_writes(ohci);\n\n\t \n\tfw_schedule_bus_reset(&ohci->card, false, true);\n\n\treturn 0;\n}\n\nstatic int ohci_set_config_rom(struct fw_card *card,\n\t\t\t       const __be32 *config_rom, size_t length)\n{\n\tstruct fw_ohci *ohci;\n\t__be32 *next_config_rom;\n\tdma_addr_t next_config_rom_bus;\n\n\tohci = fw_ohci(card);\n\n\t \n\n\tnext_config_rom = dmam_alloc_coherent(ohci->card.device, CONFIG_ROM_SIZE,\n\t\t\t\t\t      &next_config_rom_bus, GFP_KERNEL);\n\tif (next_config_rom == NULL)\n\t\treturn -ENOMEM;\n\n\tspin_lock_irq(&ohci->lock);\n\n\t \n\n\tif (ohci->next_config_rom == NULL) {\n\t\tohci->next_config_rom = next_config_rom;\n\t\tohci->next_config_rom_bus = next_config_rom_bus;\n\t\tnext_config_rom = NULL;\n\t}\n\n\tcopy_config_rom(ohci->next_config_rom, config_rom, length);\n\n\tohci->next_header = config_rom[0];\n\tohci->next_config_rom[0] = 0;\n\n\treg_write(ohci, OHCI1394_ConfigROMmap, ohci->next_config_rom_bus);\n\n\tspin_unlock_irq(&ohci->lock);\n\n\t \n\tif (next_config_rom != NULL) {\n\t\tdmam_free_coherent(ohci->card.device, CONFIG_ROM_SIZE, next_config_rom,\n\t\t\t\t   next_config_rom_bus);\n\t}\n\n\t \n\n\tfw_schedule_bus_reset(&ohci->card, true, true);\n\n\treturn 0;\n}\n\nstatic void ohci_send_request(struct fw_card *card, struct fw_packet *packet)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\n\tat_context_transmit(&ohci->at_request_ctx, packet);\n}\n\nstatic void ohci_send_response(struct fw_card *card, struct fw_packet *packet)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\n\tat_context_transmit(&ohci->at_response_ctx, packet);\n}\n\nstatic int ohci_cancel_packet(struct fw_card *card, struct fw_packet *packet)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\tstruct context *ctx = &ohci->at_request_ctx;\n\tstruct driver_data *driver_data = packet->driver_data;\n\tint ret = -ENOENT;\n\n\ttasklet_disable_in_atomic(&ctx->tasklet);\n\n\tif (packet->ack != 0)\n\t\tgoto out;\n\n\tif (packet->payload_mapped)\n\t\tdma_unmap_single(ohci->card.device, packet->payload_bus,\n\t\t\t\t packet->payload_length, DMA_TO_DEVICE);\n\n\tlog_ar_at_event(ohci, 'T', packet->speed, packet->header, 0x20);\n\tdriver_data->packet = NULL;\n\tpacket->ack = RCODE_CANCELLED;\n\n\t\n\tpacket->timestamp = cycle_time_to_ohci_tstamp(get_cycle_time(ohci));\n\n\tpacket->callback(packet, &ohci->card, packet->ack);\n\tret = 0;\n out:\n\ttasklet_enable(&ctx->tasklet);\n\n\treturn ret;\n}\n\nstatic int ohci_enable_phys_dma(struct fw_card *card,\n\t\t\t\tint node_id, int generation)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\tunsigned long flags;\n\tint n, ret = 0;\n\n\tif (param_remote_dma)\n\t\treturn 0;\n\n\t \n\n\tspin_lock_irqsave(&ohci->lock, flags);\n\n\tif (ohci->generation != generation) {\n\t\tret = -ESTALE;\n\t\tgoto out;\n\t}\n\n\t \n\n\tn = (node_id & 0xffc0) == LOCAL_BUS ? node_id & 0x3f : 63;\n\tif (n < 32)\n\t\treg_write(ohci, OHCI1394_PhyReqFilterLoSet, 1 << n);\n\telse\n\t\treg_write(ohci, OHCI1394_PhyReqFilterHiSet, 1 << (n - 32));\n\n\tflush_writes(ohci);\n out:\n\tspin_unlock_irqrestore(&ohci->lock, flags);\n\n\treturn ret;\n}\n\nstatic u32 ohci_read_csr(struct fw_card *card, int csr_offset)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\tunsigned long flags;\n\tu32 value;\n\n\tswitch (csr_offset) {\n\tcase CSR_STATE_CLEAR:\n\tcase CSR_STATE_SET:\n\t\tif (ohci->is_root &&\n\t\t    (reg_read(ohci, OHCI1394_LinkControlSet) &\n\t\t     OHCI1394_LinkControl_cycleMaster))\n\t\t\tvalue = CSR_STATE_BIT_CMSTR;\n\t\telse\n\t\t\tvalue = 0;\n\t\tif (ohci->csr_state_setclear_abdicate)\n\t\t\tvalue |= CSR_STATE_BIT_ABDICATE;\n\n\t\treturn value;\n\n\tcase CSR_NODE_IDS:\n\t\treturn reg_read(ohci, OHCI1394_NodeID) << 16;\n\n\tcase CSR_CYCLE_TIME:\n\t\treturn get_cycle_time(ohci);\n\n\tcase CSR_BUS_TIME:\n\t\t \n\t\tspin_lock_irqsave(&ohci->lock, flags);\n\t\tvalue = update_bus_time(ohci);\n\t\tspin_unlock_irqrestore(&ohci->lock, flags);\n\t\treturn value;\n\n\tcase CSR_BUSY_TIMEOUT:\n\t\tvalue = reg_read(ohci, OHCI1394_ATRetries);\n\t\treturn (value >> 4) & 0x0ffff00f;\n\n\tcase CSR_PRIORITY_BUDGET:\n\t\treturn (reg_read(ohci, OHCI1394_FairnessControl) & 0x3f) |\n\t\t\t(ohci->pri_req_max << 8);\n\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn 0;\n\t}\n}\n\nstatic void ohci_write_csr(struct fw_card *card, int csr_offset, u32 value)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\tunsigned long flags;\n\n\tswitch (csr_offset) {\n\tcase CSR_STATE_CLEAR:\n\t\tif ((value & CSR_STATE_BIT_CMSTR) && ohci->is_root) {\n\t\t\treg_write(ohci, OHCI1394_LinkControlClear,\n\t\t\t\t  OHCI1394_LinkControl_cycleMaster);\n\t\t\tflush_writes(ohci);\n\t\t}\n\t\tif (value & CSR_STATE_BIT_ABDICATE)\n\t\t\tohci->csr_state_setclear_abdicate = false;\n\t\tbreak;\n\n\tcase CSR_STATE_SET:\n\t\tif ((value & CSR_STATE_BIT_CMSTR) && ohci->is_root) {\n\t\t\treg_write(ohci, OHCI1394_LinkControlSet,\n\t\t\t\t  OHCI1394_LinkControl_cycleMaster);\n\t\t\tflush_writes(ohci);\n\t\t}\n\t\tif (value & CSR_STATE_BIT_ABDICATE)\n\t\t\tohci->csr_state_setclear_abdicate = true;\n\t\tbreak;\n\n\tcase CSR_NODE_IDS:\n\t\treg_write(ohci, OHCI1394_NodeID, value >> 16);\n\t\tflush_writes(ohci);\n\t\tbreak;\n\n\tcase CSR_CYCLE_TIME:\n\t\treg_write(ohci, OHCI1394_IsochronousCycleTimer, value);\n\t\treg_write(ohci, OHCI1394_IntEventSet,\n\t\t\t  OHCI1394_cycleInconsistent);\n\t\tflush_writes(ohci);\n\t\tbreak;\n\n\tcase CSR_BUS_TIME:\n\t\tspin_lock_irqsave(&ohci->lock, flags);\n\t\tohci->bus_time = (update_bus_time(ohci) & 0x40) |\n\t\t                 (value & ~0x7f);\n\t\tspin_unlock_irqrestore(&ohci->lock, flags);\n\t\tbreak;\n\n\tcase CSR_BUSY_TIMEOUT:\n\t\tvalue = (value & 0xf) | ((value & 0xf) << 4) |\n\t\t\t((value & 0xf) << 8) | ((value & 0x0ffff000) << 4);\n\t\treg_write(ohci, OHCI1394_ATRetries, value);\n\t\tflush_writes(ohci);\n\t\tbreak;\n\n\tcase CSR_PRIORITY_BUDGET:\n\t\treg_write(ohci, OHCI1394_FairnessControl, value & 0x3f);\n\t\tflush_writes(ohci);\n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON(1);\n\t\tbreak;\n\t}\n}\n\nstatic void flush_iso_completions(struct iso_context *ctx)\n{\n\tctx->base.callback.sc(&ctx->base, ctx->last_timestamp,\n\t\t\t      ctx->header_length, ctx->header,\n\t\t\t      ctx->base.callback_data);\n\tctx->header_length = 0;\n}\n\nstatic void copy_iso_headers(struct iso_context *ctx, const u32 *dma_hdr)\n{\n\tu32 *ctx_hdr;\n\n\tif (ctx->header_length + ctx->base.header_size > PAGE_SIZE) {\n\t\tif (ctx->base.drop_overflow_headers)\n\t\t\treturn;\n\t\tflush_iso_completions(ctx);\n\t}\n\n\tctx_hdr = ctx->header + ctx->header_length;\n\tctx->last_timestamp = (u16)le32_to_cpu((__force __le32)dma_hdr[0]);\n\n\t \n\tif (ctx->base.header_size > 0)\n\t\tctx_hdr[0] = swab32(dma_hdr[1]);  \n\tif (ctx->base.header_size > 4)\n\t\tctx_hdr[1] = swab32(dma_hdr[0]);  \n\tif (ctx->base.header_size > 8)\n\t\tmemcpy(&ctx_hdr[2], &dma_hdr[2], ctx->base.header_size - 8);\n\tctx->header_length += ctx->base.header_size;\n}\n\nstatic int handle_ir_packet_per_buffer(struct context *context,\n\t\t\t\t       struct descriptor *d,\n\t\t\t\t       struct descriptor *last)\n{\n\tstruct iso_context *ctx =\n\t\tcontainer_of(context, struct iso_context, context);\n\tstruct descriptor *pd;\n\tu32 buffer_dma;\n\n\tfor (pd = d; pd <= last; pd++)\n\t\tif (pd->transfer_status)\n\t\t\tbreak;\n\tif (pd > last)\n\t\t \n\t\treturn 0;\n\n\twhile (!(d->control & cpu_to_le16(DESCRIPTOR_BRANCH_ALWAYS))) {\n\t\td++;\n\t\tbuffer_dma = le32_to_cpu(d->data_address);\n\t\tdma_sync_single_range_for_cpu(context->ohci->card.device,\n\t\t\t\t\t      buffer_dma & PAGE_MASK,\n\t\t\t\t\t      buffer_dma & ~PAGE_MASK,\n\t\t\t\t\t      le16_to_cpu(d->req_count),\n\t\t\t\t\t      DMA_FROM_DEVICE);\n\t}\n\n\tcopy_iso_headers(ctx, (u32 *) (last + 1));\n\n\tif (last->control & cpu_to_le16(DESCRIPTOR_IRQ_ALWAYS))\n\t\tflush_iso_completions(ctx);\n\n\treturn 1;\n}\n\n \nstatic int handle_ir_buffer_fill(struct context *context,\n\t\t\t\t struct descriptor *d,\n\t\t\t\t struct descriptor *last)\n{\n\tstruct iso_context *ctx =\n\t\tcontainer_of(context, struct iso_context, context);\n\tunsigned int req_count, res_count, completed;\n\tu32 buffer_dma;\n\n\treq_count = le16_to_cpu(last->req_count);\n\tres_count = le16_to_cpu(READ_ONCE(last->res_count));\n\tcompleted = req_count - res_count;\n\tbuffer_dma = le32_to_cpu(last->data_address);\n\n\tif (completed > 0) {\n\t\tctx->mc_buffer_bus = buffer_dma;\n\t\tctx->mc_completed = completed;\n\t}\n\n\tif (res_count != 0)\n\t\t \n\t\treturn 0;\n\n\tdma_sync_single_range_for_cpu(context->ohci->card.device,\n\t\t\t\t      buffer_dma & PAGE_MASK,\n\t\t\t\t      buffer_dma & ~PAGE_MASK,\n\t\t\t\t      completed, DMA_FROM_DEVICE);\n\n\tif (last->control & cpu_to_le16(DESCRIPTOR_IRQ_ALWAYS)) {\n\t\tctx->base.callback.mc(&ctx->base,\n\t\t\t\t      buffer_dma + completed,\n\t\t\t\t      ctx->base.callback_data);\n\t\tctx->mc_completed = 0;\n\t}\n\n\treturn 1;\n}\n\nstatic void flush_ir_buffer_fill(struct iso_context *ctx)\n{\n\tdma_sync_single_range_for_cpu(ctx->context.ohci->card.device,\n\t\t\t\t      ctx->mc_buffer_bus & PAGE_MASK,\n\t\t\t\t      ctx->mc_buffer_bus & ~PAGE_MASK,\n\t\t\t\t      ctx->mc_completed, DMA_FROM_DEVICE);\n\n\tctx->base.callback.mc(&ctx->base,\n\t\t\t      ctx->mc_buffer_bus + ctx->mc_completed,\n\t\t\t      ctx->base.callback_data);\n\tctx->mc_completed = 0;\n}\n\nstatic inline void sync_it_packet_for_cpu(struct context *context,\n\t\t\t\t\t  struct descriptor *pd)\n{\n\t__le16 control;\n\tu32 buffer_dma;\n\n\t \n\tif (pd->control & cpu_to_le16(DESCRIPTOR_BRANCH_ALWAYS))\n\t\treturn;\n\n\t \n\tpd += 2;\n\n\t \n\tif ((le32_to_cpu(pd->data_address) & PAGE_MASK) ==\n\t    (context->current_bus          & PAGE_MASK)) {\n\t\tif (pd->control & cpu_to_le16(DESCRIPTOR_BRANCH_ALWAYS))\n\t\t\treturn;\n\t\tpd++;\n\t}\n\n\tdo {\n\t\tbuffer_dma = le32_to_cpu(pd->data_address);\n\t\tdma_sync_single_range_for_cpu(context->ohci->card.device,\n\t\t\t\t\t      buffer_dma & PAGE_MASK,\n\t\t\t\t\t      buffer_dma & ~PAGE_MASK,\n\t\t\t\t\t      le16_to_cpu(pd->req_count),\n\t\t\t\t\t      DMA_TO_DEVICE);\n\t\tcontrol = pd->control;\n\t\tpd++;\n\t} while (!(control & cpu_to_le16(DESCRIPTOR_BRANCH_ALWAYS)));\n}\n\nstatic int handle_it_packet(struct context *context,\n\t\t\t    struct descriptor *d,\n\t\t\t    struct descriptor *last)\n{\n\tstruct iso_context *ctx =\n\t\tcontainer_of(context, struct iso_context, context);\n\tstruct descriptor *pd;\n\t__be32 *ctx_hdr;\n\n\tfor (pd = d; pd <= last; pd++)\n\t\tif (pd->transfer_status)\n\t\t\tbreak;\n\tif (pd > last)\n\t\t \n\t\treturn 0;\n\n\tsync_it_packet_for_cpu(context, d);\n\n\tif (ctx->header_length + 4 > PAGE_SIZE) {\n\t\tif (ctx->base.drop_overflow_headers)\n\t\t\treturn 1;\n\t\tflush_iso_completions(ctx);\n\t}\n\n\tctx_hdr = ctx->header + ctx->header_length;\n\tctx->last_timestamp = le16_to_cpu(last->res_count);\n\t \n\t*ctx_hdr = cpu_to_be32((le16_to_cpu(pd->transfer_status) << 16) |\n\t\t\t       le16_to_cpu(pd->res_count));\n\tctx->header_length += 4;\n\n\tif (last->control & cpu_to_le16(DESCRIPTOR_IRQ_ALWAYS))\n\t\tflush_iso_completions(ctx);\n\n\treturn 1;\n}\n\nstatic void set_multichannel_mask(struct fw_ohci *ohci, u64 channels)\n{\n\tu32 hi = channels >> 32, lo = channels;\n\n\treg_write(ohci, OHCI1394_IRMultiChanMaskHiClear, ~hi);\n\treg_write(ohci, OHCI1394_IRMultiChanMaskLoClear, ~lo);\n\treg_write(ohci, OHCI1394_IRMultiChanMaskHiSet, hi);\n\treg_write(ohci, OHCI1394_IRMultiChanMaskLoSet, lo);\n\tohci->mc_channels = channels;\n}\n\nstatic struct fw_iso_context *ohci_allocate_iso_context(struct fw_card *card,\n\t\t\t\tint type, int channel, size_t header_size)\n{\n\tstruct fw_ohci *ohci = fw_ohci(card);\n\tstruct iso_context *ctx;\n\tdescriptor_callback_t callback;\n\tu64 *channels;\n\tu32 *mask, regs;\n\tint index, ret = -EBUSY;\n\n\tspin_lock_irq(&ohci->lock);\n\n\tswitch (type) {\n\tcase FW_ISO_CONTEXT_TRANSMIT:\n\t\tmask     = &ohci->it_context_mask;\n\t\tcallback = handle_it_packet;\n\t\tindex    = ffs(*mask) - 1;\n\t\tif (index >= 0) {\n\t\t\t*mask &= ~(1 << index);\n\t\t\tregs = OHCI1394_IsoXmitContextBase(index);\n\t\t\tctx  = &ohci->it_context_list[index];\n\t\t}\n\t\tbreak;\n\n\tcase FW_ISO_CONTEXT_RECEIVE:\n\t\tchannels = &ohci->ir_context_channels;\n\t\tmask     = &ohci->ir_context_mask;\n\t\tcallback = handle_ir_packet_per_buffer;\n\t\tindex    = *channels & 1ULL << channel ? ffs(*mask) - 1 : -1;\n\t\tif (index >= 0) {\n\t\t\t*channels &= ~(1ULL << channel);\n\t\t\t*mask     &= ~(1 << index);\n\t\t\tregs = OHCI1394_IsoRcvContextBase(index);\n\t\t\tctx  = &ohci->ir_context_list[index];\n\t\t}\n\t\tbreak;\n\n\tcase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\n\t\tmask     = &ohci->ir_context_mask;\n\t\tcallback = handle_ir_buffer_fill;\n\t\tindex    = !ohci->mc_allocated ? ffs(*mask) - 1 : -1;\n\t\tif (index >= 0) {\n\t\t\tohci->mc_allocated = true;\n\t\t\t*mask &= ~(1 << index);\n\t\t\tregs = OHCI1394_IsoRcvContextBase(index);\n\t\t\tctx  = &ohci->ir_context_list[index];\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tindex = -1;\n\t\tret = -ENOSYS;\n\t}\n\n\tspin_unlock_irq(&ohci->lock);\n\n\tif (index < 0)\n\t\treturn ERR_PTR(ret);\n\n\tmemset(ctx, 0, sizeof(*ctx));\n\tctx->header_length = 0;\n\tctx->header = (void *) __get_free_page(GFP_KERNEL);\n\tif (ctx->header == NULL) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tret = context_init(&ctx->context, ohci, regs, callback);\n\tif (ret < 0)\n\t\tgoto out_with_header;\n\n\tif (type == FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL) {\n\t\tset_multichannel_mask(ohci, 0);\n\t\tctx->mc_completed = 0;\n\t}\n\n\treturn &ctx->base;\n\n out_with_header:\n\tfree_page((unsigned long)ctx->header);\n out:\n\tspin_lock_irq(&ohci->lock);\n\n\tswitch (type) {\n\tcase FW_ISO_CONTEXT_RECEIVE:\n\t\t*channels |= 1ULL << channel;\n\t\tbreak;\n\n\tcase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\n\t\tohci->mc_allocated = false;\n\t\tbreak;\n\t}\n\t*mask |= 1 << index;\n\n\tspin_unlock_irq(&ohci->lock);\n\n\treturn ERR_PTR(ret);\n}\n\nstatic int ohci_start_iso(struct fw_iso_context *base,\n\t\t\t  s32 cycle, u32 sync, u32 tags)\n{\n\tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n\tstruct fw_ohci *ohci = ctx->context.ohci;\n\tu32 control = IR_CONTEXT_ISOCH_HEADER, match;\n\tint index;\n\n\t \n\tif (ctx->context.last->branch_address == 0)\n\t\treturn -ENODATA;\n\n\tswitch (ctx->base.type) {\n\tcase FW_ISO_CONTEXT_TRANSMIT:\n\t\tindex = ctx - ohci->it_context_list;\n\t\tmatch = 0;\n\t\tif (cycle >= 0)\n\t\t\tmatch = IT_CONTEXT_CYCLE_MATCH_ENABLE |\n\t\t\t\t(cycle & 0x7fff) << 16;\n\n\t\treg_write(ohci, OHCI1394_IsoXmitIntEventClear, 1 << index);\n\t\treg_write(ohci, OHCI1394_IsoXmitIntMaskSet, 1 << index);\n\t\tcontext_run(&ctx->context, match);\n\t\tbreak;\n\n\tcase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\n\t\tcontrol |= IR_CONTEXT_BUFFER_FILL|IR_CONTEXT_MULTI_CHANNEL_MODE;\n\t\tfallthrough;\n\tcase FW_ISO_CONTEXT_RECEIVE:\n\t\tindex = ctx - ohci->ir_context_list;\n\t\tmatch = (tags << 28) | (sync << 8) | ctx->base.channel;\n\t\tif (cycle >= 0) {\n\t\t\tmatch |= (cycle & 0x07fff) << 12;\n\t\t\tcontrol |= IR_CONTEXT_CYCLE_MATCH_ENABLE;\n\t\t}\n\n\t\treg_write(ohci, OHCI1394_IsoRecvIntEventClear, 1 << index);\n\t\treg_write(ohci, OHCI1394_IsoRecvIntMaskSet, 1 << index);\n\t\treg_write(ohci, CONTEXT_MATCH(ctx->context.regs), match);\n\t\tcontext_run(&ctx->context, control);\n\n\t\tctx->sync = sync;\n\t\tctx->tags = tags;\n\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic int ohci_stop_iso(struct fw_iso_context *base)\n{\n\tstruct fw_ohci *ohci = fw_ohci(base->card);\n\tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n\tint index;\n\n\tswitch (ctx->base.type) {\n\tcase FW_ISO_CONTEXT_TRANSMIT:\n\t\tindex = ctx - ohci->it_context_list;\n\t\treg_write(ohci, OHCI1394_IsoXmitIntMaskClear, 1 << index);\n\t\tbreak;\n\n\tcase FW_ISO_CONTEXT_RECEIVE:\n\tcase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\n\t\tindex = ctx - ohci->ir_context_list;\n\t\treg_write(ohci, OHCI1394_IsoRecvIntMaskClear, 1 << index);\n\t\tbreak;\n\t}\n\tflush_writes(ohci);\n\tcontext_stop(&ctx->context);\n\ttasklet_kill(&ctx->context.tasklet);\n\n\treturn 0;\n}\n\nstatic void ohci_free_iso_context(struct fw_iso_context *base)\n{\n\tstruct fw_ohci *ohci = fw_ohci(base->card);\n\tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n\tunsigned long flags;\n\tint index;\n\n\tohci_stop_iso(base);\n\tcontext_release(&ctx->context);\n\tfree_page((unsigned long)ctx->header);\n\n\tspin_lock_irqsave(&ohci->lock, flags);\n\n\tswitch (base->type) {\n\tcase FW_ISO_CONTEXT_TRANSMIT:\n\t\tindex = ctx - ohci->it_context_list;\n\t\tohci->it_context_mask |= 1 << index;\n\t\tbreak;\n\n\tcase FW_ISO_CONTEXT_RECEIVE:\n\t\tindex = ctx - ohci->ir_context_list;\n\t\tohci->ir_context_mask |= 1 << index;\n\t\tohci->ir_context_channels |= 1ULL << base->channel;\n\t\tbreak;\n\n\tcase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\n\t\tindex = ctx - ohci->ir_context_list;\n\t\tohci->ir_context_mask |= 1 << index;\n\t\tohci->ir_context_channels |= ohci->mc_channels;\n\t\tohci->mc_channels = 0;\n\t\tohci->mc_allocated = false;\n\t\tbreak;\n\t}\n\n\tspin_unlock_irqrestore(&ohci->lock, flags);\n}\n\nstatic int ohci_set_iso_channels(struct fw_iso_context *base, u64 *channels)\n{\n\tstruct fw_ohci *ohci = fw_ohci(base->card);\n\tunsigned long flags;\n\tint ret;\n\n\tswitch (base->type) {\n\tcase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\n\n\t\tspin_lock_irqsave(&ohci->lock, flags);\n\n\t\t \n\t\tif (~ohci->ir_context_channels & ~ohci->mc_channels & *channels) {\n\t\t\t*channels = ohci->ir_context_channels;\n\t\t\tret = -EBUSY;\n\t\t} else {\n\t\t\tset_multichannel_mask(ohci, *channels);\n\t\t\tret = 0;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&ohci->lock, flags);\n\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\n#ifdef CONFIG_PM\nstatic void ohci_resume_iso_dma(struct fw_ohci *ohci)\n{\n\tint i;\n\tstruct iso_context *ctx;\n\n\tfor (i = 0 ; i < ohci->n_ir ; i++) {\n\t\tctx = &ohci->ir_context_list[i];\n\t\tif (ctx->context.running)\n\t\t\tohci_start_iso(&ctx->base, 0, ctx->sync, ctx->tags);\n\t}\n\n\tfor (i = 0 ; i < ohci->n_it ; i++) {\n\t\tctx = &ohci->it_context_list[i];\n\t\tif (ctx->context.running)\n\t\t\tohci_start_iso(&ctx->base, 0, ctx->sync, ctx->tags);\n\t}\n}\n#endif\n\nstatic int queue_iso_transmit(struct iso_context *ctx,\n\t\t\t      struct fw_iso_packet *packet,\n\t\t\t      struct fw_iso_buffer *buffer,\n\t\t\t      unsigned long payload)\n{\n\tstruct descriptor *d, *last, *pd;\n\tstruct fw_iso_packet *p;\n\t__le32 *header;\n\tdma_addr_t d_bus, page_bus;\n\tu32 z, header_z, payload_z, irq;\n\tu32 payload_index, payload_end_index, next_page_index;\n\tint page, end_page, i, length, offset;\n\n\tp = packet;\n\tpayload_index = payload;\n\n\tif (p->skip)\n\t\tz = 1;\n\telse\n\t\tz = 2;\n\tif (p->header_length > 0)\n\t\tz++;\n\n\t \n\tend_page = PAGE_ALIGN(payload_index + p->payload_length) >> PAGE_SHIFT;\n\tif (p->payload_length > 0)\n\t\tpayload_z = end_page - (payload_index >> PAGE_SHIFT);\n\telse\n\t\tpayload_z = 0;\n\n\tz += payload_z;\n\n\t \n\theader_z = DIV_ROUND_UP(p->header_length, sizeof(*d));\n\n\td = context_get_descriptors(&ctx->context, z + header_z, &d_bus);\n\tif (d == NULL)\n\t\treturn -ENOMEM;\n\n\tif (!p->skip) {\n\t\td[0].control   = cpu_to_le16(DESCRIPTOR_KEY_IMMEDIATE);\n\t\td[0].req_count = cpu_to_le16(8);\n\t\t \n\t\td[0].branch_address = cpu_to_le32(d_bus | z);\n\n\t\theader = (__le32 *) &d[1];\n\t\theader[0] = cpu_to_le32(IT_HEADER_SY(p->sy) |\n\t\t\t\t\tIT_HEADER_TAG(p->tag) |\n\t\t\t\t\tIT_HEADER_TCODE(TCODE_STREAM_DATA) |\n\t\t\t\t\tIT_HEADER_CHANNEL(ctx->base.channel) |\n\t\t\t\t\tIT_HEADER_SPEED(ctx->base.speed));\n\t\theader[1] =\n\t\t\tcpu_to_le32(IT_HEADER_DATA_LENGTH(p->header_length +\n\t\t\t\t\t\t\t  p->payload_length));\n\t}\n\n\tif (p->header_length > 0) {\n\t\td[2].req_count    = cpu_to_le16(p->header_length);\n\t\td[2].data_address = cpu_to_le32(d_bus + z * sizeof(*d));\n\t\tmemcpy(&d[z], p->header, p->header_length);\n\t}\n\n\tpd = d + z - payload_z;\n\tpayload_end_index = payload_index + p->payload_length;\n\tfor (i = 0; i < payload_z; i++) {\n\t\tpage               = payload_index >> PAGE_SHIFT;\n\t\toffset             = payload_index & ~PAGE_MASK;\n\t\tnext_page_index    = (page + 1) << PAGE_SHIFT;\n\t\tlength             =\n\t\t\tmin(next_page_index, payload_end_index) - payload_index;\n\t\tpd[i].req_count    = cpu_to_le16(length);\n\n\t\tpage_bus = page_private(buffer->pages[page]);\n\t\tpd[i].data_address = cpu_to_le32(page_bus + offset);\n\n\t\tdma_sync_single_range_for_device(ctx->context.ohci->card.device,\n\t\t\t\t\t\t page_bus, offset, length,\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\n\t\tpayload_index += length;\n\t}\n\n\tif (p->interrupt)\n\t\tirq = DESCRIPTOR_IRQ_ALWAYS;\n\telse\n\t\tirq = DESCRIPTOR_NO_IRQ;\n\n\tlast = z == 2 ? d : d + z - 1;\n\tlast->control |= cpu_to_le16(DESCRIPTOR_OUTPUT_LAST |\n\t\t\t\t     DESCRIPTOR_STATUS |\n\t\t\t\t     DESCRIPTOR_BRANCH_ALWAYS |\n\t\t\t\t     irq);\n\n\tcontext_append(&ctx->context, d, z, header_z);\n\n\treturn 0;\n}\n\nstatic int queue_iso_packet_per_buffer(struct iso_context *ctx,\n\t\t\t\t       struct fw_iso_packet *packet,\n\t\t\t\t       struct fw_iso_buffer *buffer,\n\t\t\t\t       unsigned long payload)\n{\n\tstruct device *device = ctx->context.ohci->card.device;\n\tstruct descriptor *d, *pd;\n\tdma_addr_t d_bus, page_bus;\n\tu32 z, header_z, rest;\n\tint i, j, length;\n\tint page, offset, packet_count, header_size, payload_per_buffer;\n\n\t \n\tpacket_count = packet->header_length / ctx->base.header_size;\n\theader_size  = max(ctx->base.header_size, (size_t)8);\n\n\t \n\theader_z = DIV_ROUND_UP(header_size, sizeof(*d));\n\tpage     = payload >> PAGE_SHIFT;\n\toffset   = payload & ~PAGE_MASK;\n\tpayload_per_buffer = packet->payload_length / packet_count;\n\n\tfor (i = 0; i < packet_count; i++) {\n\t\t \n\t\tz = DIV_ROUND_UP(payload_per_buffer + offset, PAGE_SIZE) + 1;\n\t\td = context_get_descriptors(&ctx->context,\n\t\t\t\tz + header_z, &d_bus);\n\t\tif (d == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\td->control      = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t      DESCRIPTOR_INPUT_MORE);\n\t\tif (packet->skip && i == 0)\n\t\t\td->control |= cpu_to_le16(DESCRIPTOR_WAIT);\n\t\td->req_count    = cpu_to_le16(header_size);\n\t\td->res_count    = d->req_count;\n\t\td->transfer_status = 0;\n\t\td->data_address = cpu_to_le32(d_bus + (z * sizeof(*d)));\n\n\t\trest = payload_per_buffer;\n\t\tpd = d;\n\t\tfor (j = 1; j < z; j++) {\n\t\t\tpd++;\n\t\t\tpd->control = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t\t  DESCRIPTOR_INPUT_MORE);\n\n\t\t\tif (offset + rest < PAGE_SIZE)\n\t\t\t\tlength = rest;\n\t\t\telse\n\t\t\t\tlength = PAGE_SIZE - offset;\n\t\t\tpd->req_count = cpu_to_le16(length);\n\t\t\tpd->res_count = pd->req_count;\n\t\t\tpd->transfer_status = 0;\n\n\t\t\tpage_bus = page_private(buffer->pages[page]);\n\t\t\tpd->data_address = cpu_to_le32(page_bus + offset);\n\n\t\t\tdma_sync_single_range_for_device(device, page_bus,\n\t\t\t\t\t\t\t offset, length,\n\t\t\t\t\t\t\t DMA_FROM_DEVICE);\n\n\t\t\toffset = (offset + length) & ~PAGE_MASK;\n\t\t\trest -= length;\n\t\t\tif (offset == 0)\n\t\t\t\tpage++;\n\t\t}\n\t\tpd->control = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t  DESCRIPTOR_INPUT_LAST |\n\t\t\t\t\t  DESCRIPTOR_BRANCH_ALWAYS);\n\t\tif (packet->interrupt && i == packet_count - 1)\n\t\t\tpd->control |= cpu_to_le16(DESCRIPTOR_IRQ_ALWAYS);\n\n\t\tcontext_append(&ctx->context, d, z, header_z);\n\t}\n\n\treturn 0;\n}\n\nstatic int queue_iso_buffer_fill(struct iso_context *ctx,\n\t\t\t\t struct fw_iso_packet *packet,\n\t\t\t\t struct fw_iso_buffer *buffer,\n\t\t\t\t unsigned long payload)\n{\n\tstruct descriptor *d;\n\tdma_addr_t d_bus, page_bus;\n\tint page, offset, rest, z, i, length;\n\n\tpage   = payload >> PAGE_SHIFT;\n\toffset = payload & ~PAGE_MASK;\n\trest   = packet->payload_length;\n\n\t \n\tz = DIV_ROUND_UP(offset + rest, PAGE_SIZE);\n\n\tif (WARN_ON(offset & 3 || rest & 3 || page + z > buffer->page_count))\n\t\treturn -EFAULT;\n\n\tfor (i = 0; i < z; i++) {\n\t\td = context_get_descriptors(&ctx->context, 1, &d_bus);\n\t\tif (d == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\td->control = cpu_to_le16(DESCRIPTOR_INPUT_MORE |\n\t\t\t\t\t DESCRIPTOR_BRANCH_ALWAYS);\n\t\tif (packet->skip && i == 0)\n\t\t\td->control |= cpu_to_le16(DESCRIPTOR_WAIT);\n\t\tif (packet->interrupt && i == z - 1)\n\t\t\td->control |= cpu_to_le16(DESCRIPTOR_IRQ_ALWAYS);\n\n\t\tif (offset + rest < PAGE_SIZE)\n\t\t\tlength = rest;\n\t\telse\n\t\t\tlength = PAGE_SIZE - offset;\n\t\td->req_count = cpu_to_le16(length);\n\t\td->res_count = d->req_count;\n\t\td->transfer_status = 0;\n\n\t\tpage_bus = page_private(buffer->pages[page]);\n\t\td->data_address = cpu_to_le32(page_bus + offset);\n\n\t\tdma_sync_single_range_for_device(ctx->context.ohci->card.device,\n\t\t\t\t\t\t page_bus, offset, length,\n\t\t\t\t\t\t DMA_FROM_DEVICE);\n\n\t\trest -= length;\n\t\toffset = 0;\n\t\tpage++;\n\n\t\tcontext_append(&ctx->context, d, 1, 0);\n\t}\n\n\treturn 0;\n}\n\nstatic int ohci_queue_iso(struct fw_iso_context *base,\n\t\t\t  struct fw_iso_packet *packet,\n\t\t\t  struct fw_iso_buffer *buffer,\n\t\t\t  unsigned long payload)\n{\n\tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n\tunsigned long flags;\n\tint ret = -ENOSYS;\n\n\tspin_lock_irqsave(&ctx->context.ohci->lock, flags);\n\tswitch (base->type) {\n\tcase FW_ISO_CONTEXT_TRANSMIT:\n\t\tret = queue_iso_transmit(ctx, packet, buffer, payload);\n\t\tbreak;\n\tcase FW_ISO_CONTEXT_RECEIVE:\n\t\tret = queue_iso_packet_per_buffer(ctx, packet, buffer, payload);\n\t\tbreak;\n\tcase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\n\t\tret = queue_iso_buffer_fill(ctx, packet, buffer, payload);\n\t\tbreak;\n\t}\n\tspin_unlock_irqrestore(&ctx->context.ohci->lock, flags);\n\n\treturn ret;\n}\n\nstatic void ohci_flush_queue_iso(struct fw_iso_context *base)\n{\n\tstruct context *ctx =\n\t\t\t&container_of(base, struct iso_context, base)->context;\n\n\treg_write(ctx->ohci, CONTROL_SET(ctx->regs), CONTEXT_WAKE);\n}\n\nstatic int ohci_flush_iso_completions(struct fw_iso_context *base)\n{\n\tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n\tint ret = 0;\n\n\ttasklet_disable_in_atomic(&ctx->context.tasklet);\n\n\tif (!test_and_set_bit_lock(0, &ctx->flushing_completions)) {\n\t\tcontext_tasklet((unsigned long)&ctx->context);\n\n\t\tswitch (base->type) {\n\t\tcase FW_ISO_CONTEXT_TRANSMIT:\n\t\tcase FW_ISO_CONTEXT_RECEIVE:\n\t\t\tif (ctx->header_length != 0)\n\t\t\t\tflush_iso_completions(ctx);\n\t\t\tbreak;\n\t\tcase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\n\t\t\tif (ctx->mc_completed != 0)\n\t\t\t\tflush_ir_buffer_fill(ctx);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -ENOSYS;\n\t\t}\n\n\t\tclear_bit_unlock(0, &ctx->flushing_completions);\n\t\tsmp_mb__after_atomic();\n\t}\n\n\ttasklet_enable(&ctx->context.tasklet);\n\n\treturn ret;\n}\n\nstatic const struct fw_card_driver ohci_driver = {\n\t.enable\t\t\t= ohci_enable,\n\t.read_phy_reg\t\t= ohci_read_phy_reg,\n\t.update_phy_reg\t\t= ohci_update_phy_reg,\n\t.set_config_rom\t\t= ohci_set_config_rom,\n\t.send_request\t\t= ohci_send_request,\n\t.send_response\t\t= ohci_send_response,\n\t.cancel_packet\t\t= ohci_cancel_packet,\n\t.enable_phys_dma\t= ohci_enable_phys_dma,\n\t.read_csr\t\t= ohci_read_csr,\n\t.write_csr\t\t= ohci_write_csr,\n\n\t.allocate_iso_context\t= ohci_allocate_iso_context,\n\t.free_iso_context\t= ohci_free_iso_context,\n\t.set_iso_channels\t= ohci_set_iso_channels,\n\t.queue_iso\t\t= ohci_queue_iso,\n\t.flush_queue_iso\t= ohci_flush_queue_iso,\n\t.flush_iso_completions\t= ohci_flush_iso_completions,\n\t.start_iso\t\t= ohci_start_iso,\n\t.stop_iso\t\t= ohci_stop_iso,\n};\n\n#ifdef CONFIG_PPC_PMAC\nstatic void pmac_ohci_on(struct pci_dev *dev)\n{\n\tif (machine_is(powermac)) {\n\t\tstruct device_node *ofn = pci_device_to_OF_node(dev);\n\n\t\tif (ofn) {\n\t\t\tpmac_call_feature(PMAC_FTR_1394_CABLE_POWER, ofn, 0, 1);\n\t\t\tpmac_call_feature(PMAC_FTR_1394_ENABLE, ofn, 0, 1);\n\t\t}\n\t}\n}\n\nstatic void pmac_ohci_off(struct pci_dev *dev)\n{\n\tif (machine_is(powermac)) {\n\t\tstruct device_node *ofn = pci_device_to_OF_node(dev);\n\n\t\tif (ofn) {\n\t\t\tpmac_call_feature(PMAC_FTR_1394_ENABLE, ofn, 0, 0);\n\t\t\tpmac_call_feature(PMAC_FTR_1394_CABLE_POWER, ofn, 0, 0);\n\t\t}\n\t}\n}\n#else\nstatic inline void pmac_ohci_on(struct pci_dev *dev) {}\nstatic inline void pmac_ohci_off(struct pci_dev *dev) {}\n#endif  \n\nstatic void release_ohci(struct device *dev, void *data)\n{\n\tstruct pci_dev *pdev = to_pci_dev(dev);\n\tstruct fw_ohci *ohci = pci_get_drvdata(pdev);\n\n\tpmac_ohci_off(pdev);\n\n\tar_context_release(&ohci->ar_response_ctx);\n\tar_context_release(&ohci->ar_request_ctx);\n\n\tdev_notice(dev, \"removed fw-ohci device\\n\");\n}\n\nstatic int pci_probe(struct pci_dev *dev,\n\t\t\t       const struct pci_device_id *ent)\n{\n\tstruct fw_ohci *ohci;\n\tu32 bus_options, max_receive, link_speed, version;\n\tu64 guid;\n\tint i, err;\n\tsize_t size;\n\n\tif (dev->vendor == PCI_VENDOR_ID_PINNACLE_SYSTEMS) {\n\t\tdev_err(&dev->dev, \"Pinnacle MovieBoard is not yet supported\\n\");\n\t\treturn -ENOSYS;\n\t}\n\n\tohci = devres_alloc(release_ohci, sizeof(*ohci), GFP_KERNEL);\n\tif (ohci == NULL)\n\t\treturn -ENOMEM;\n\tfw_card_initialize(&ohci->card, &ohci_driver, &dev->dev);\n\tpci_set_drvdata(dev, ohci);\n\tpmac_ohci_on(dev);\n\tdevres_add(&dev->dev, ohci);\n\n\terr = pcim_enable_device(dev);\n\tif (err) {\n\t\tdev_err(&dev->dev, \"failed to enable OHCI hardware\\n\");\n\t\treturn err;\n\t}\n\n\tpci_set_master(dev);\n\tpci_write_config_dword(dev, OHCI1394_PCI_HCI_Control, 0);\n\n\tspin_lock_init(&ohci->lock);\n\tmutex_init(&ohci->phy_reg_mutex);\n\n\tINIT_WORK(&ohci->bus_reset_work, bus_reset_work);\n\n\tif (!(pci_resource_flags(dev, 0) & IORESOURCE_MEM) ||\n\t    pci_resource_len(dev, 0) < OHCI1394_REGISTER_SIZE) {\n\t\tohci_err(ohci, \"invalid MMIO resource\\n\");\n\t\treturn -ENXIO;\n\t}\n\n\terr = pcim_iomap_regions(dev, 1 << 0, ohci_driver_name);\n\tif (err) {\n\t\tohci_err(ohci, \"request and map MMIO resource unavailable\\n\");\n\t\treturn -ENXIO;\n\t}\n\tohci->registers = pcim_iomap_table(dev)[0];\n\n\tfor (i = 0; i < ARRAY_SIZE(ohci_quirks); i++)\n\t\tif ((ohci_quirks[i].vendor == dev->vendor) &&\n\t\t    (ohci_quirks[i].device == (unsigned short)PCI_ANY_ID ||\n\t\t     ohci_quirks[i].device == dev->device) &&\n\t\t    (ohci_quirks[i].revision == (unsigned short)PCI_ANY_ID ||\n\t\t     ohci_quirks[i].revision >= dev->revision)) {\n\t\t\tohci->quirks = ohci_quirks[i].flags;\n\t\t\tbreak;\n\t\t}\n\tif (param_quirks)\n\t\tohci->quirks = param_quirks;\n\n\tif (detect_vt630x_with_asm1083_on_amd_ryzen_machine(dev))\n\t\tohci->quirks |= QUIRK_REBOOT_BY_CYCLE_TIMER_READ;\n\n\t \n\tBUILD_BUG_ON(AR_BUFFERS * sizeof(struct descriptor) > PAGE_SIZE/4);\n\tBUILD_BUG_ON(SELF_ID_BUF_SIZE > PAGE_SIZE/2);\n\tohci->misc_buffer = dmam_alloc_coherent(&dev->dev, PAGE_SIZE, &ohci->misc_buffer_bus,\n\t\t\t\t\t\tGFP_KERNEL);\n\tif (!ohci->misc_buffer)\n\t\treturn -ENOMEM;\n\n\terr = ar_context_init(&ohci->ar_request_ctx, ohci, 0,\n\t\t\t      OHCI1394_AsReqRcvContextControlSet);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = ar_context_init(&ohci->ar_response_ctx, ohci, PAGE_SIZE/4,\n\t\t\t      OHCI1394_AsRspRcvContextControlSet);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = context_init(&ohci->at_request_ctx, ohci,\n\t\t\t   OHCI1394_AsReqTrContextControlSet, handle_at_packet);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = context_init(&ohci->at_response_ctx, ohci,\n\t\t\t   OHCI1394_AsRspTrContextControlSet, handle_at_packet);\n\tif (err < 0)\n\t\treturn err;\n\n\treg_write(ohci, OHCI1394_IsoRecvIntMaskSet, ~0);\n\tohci->ir_context_channels = ~0ULL;\n\tohci->ir_context_support = reg_read(ohci, OHCI1394_IsoRecvIntMaskSet);\n\treg_write(ohci, OHCI1394_IsoRecvIntMaskClear, ~0);\n\tohci->ir_context_mask = ohci->ir_context_support;\n\tohci->n_ir = hweight32(ohci->ir_context_mask);\n\tsize = sizeof(struct iso_context) * ohci->n_ir;\n\tohci->ir_context_list = devm_kzalloc(&dev->dev, size, GFP_KERNEL);\n\tif (!ohci->ir_context_list)\n\t\treturn -ENOMEM;\n\n\treg_write(ohci, OHCI1394_IsoXmitIntMaskSet, ~0);\n\tohci->it_context_support = reg_read(ohci, OHCI1394_IsoXmitIntMaskSet);\n\t \n\tif (!ohci->it_context_support) {\n\t\tohci_notice(ohci, \"overriding IsoXmitIntMask\\n\");\n\t\tohci->it_context_support = 0xf;\n\t}\n\treg_write(ohci, OHCI1394_IsoXmitIntMaskClear, ~0);\n\tohci->it_context_mask = ohci->it_context_support;\n\tohci->n_it = hweight32(ohci->it_context_mask);\n\tsize = sizeof(struct iso_context) * ohci->n_it;\n\tohci->it_context_list = devm_kzalloc(&dev->dev, size, GFP_KERNEL);\n\tif (!ohci->it_context_list)\n\t\treturn -ENOMEM;\n\n\tohci->self_id     = ohci->misc_buffer     + PAGE_SIZE/2;\n\tohci->self_id_bus = ohci->misc_buffer_bus + PAGE_SIZE/2;\n\n\tbus_options = reg_read(ohci, OHCI1394_BusOptions);\n\tmax_receive = (bus_options >> 12) & 0xf;\n\tlink_speed = bus_options & 0x7;\n\tguid = ((u64) reg_read(ohci, OHCI1394_GUIDHi) << 32) |\n\t\treg_read(ohci, OHCI1394_GUIDLo);\n\n\tif (!(ohci->quirks & QUIRK_NO_MSI))\n\t\tpci_enable_msi(dev);\n\terr = devm_request_irq(&dev->dev, dev->irq, irq_handler,\n\t\t\t       pci_dev_msi_enabled(dev) ? 0 : IRQF_SHARED, ohci_driver_name, ohci);\n\tif (err < 0) {\n\t\tohci_err(ohci, \"failed to allocate interrupt %d\\n\", dev->irq);\n\t\tgoto fail_msi;\n\t}\n\n\terr = fw_card_add(&ohci->card, max_receive, link_speed, guid);\n\tif (err)\n\t\tgoto fail_msi;\n\n\tversion = reg_read(ohci, OHCI1394_Version) & 0x00ff00ff;\n\tohci_notice(ohci,\n\t\t    \"added OHCI v%x.%x device as card %d, \"\n\t\t    \"%d IR + %d IT contexts, quirks 0x%x%s\\n\",\n\t\t    version >> 16, version & 0xff, ohci->card.index,\n\t\t    ohci->n_ir, ohci->n_it, ohci->quirks,\n\t\t    reg_read(ohci, OHCI1394_PhyUpperBound) ?\n\t\t\t\", physUB\" : \"\");\n\n\treturn 0;\n\n fail_msi:\n\tpci_disable_msi(dev);\n\n\treturn err;\n}\n\nstatic void pci_remove(struct pci_dev *dev)\n{\n\tstruct fw_ohci *ohci = pci_get_drvdata(dev);\n\n\t \n\tif (reg_read(ohci, OHCI1394_HCControlSet) & OHCI1394_HCControl_LPS) {\n\t\treg_write(ohci, OHCI1394_IntMaskClear, ~0);\n\t\tflush_writes(ohci);\n\t}\n\tcancel_work_sync(&ohci->bus_reset_work);\n\tfw_core_remove_card(&ohci->card);\n\n\t \n\n\tsoftware_reset(ohci);\n\n\tpci_disable_msi(dev);\n\n\tdev_notice(&dev->dev, \"removing fw-ohci device\\n\");\n}\n\n#ifdef CONFIG_PM\nstatic int pci_suspend(struct pci_dev *dev, pm_message_t state)\n{\n\tstruct fw_ohci *ohci = pci_get_drvdata(dev);\n\tint err;\n\n\tsoftware_reset(ohci);\n\terr = pci_save_state(dev);\n\tif (err) {\n\t\tohci_err(ohci, \"pci_save_state failed\\n\");\n\t\treturn err;\n\t}\n\terr = pci_set_power_state(dev, pci_choose_state(dev, state));\n\tif (err)\n\t\tohci_err(ohci, \"pci_set_power_state failed with %d\\n\", err);\n\tpmac_ohci_off(dev);\n\n\treturn 0;\n}\n\nstatic int pci_resume(struct pci_dev *dev)\n{\n\tstruct fw_ohci *ohci = pci_get_drvdata(dev);\n\tint err;\n\n\tpmac_ohci_on(dev);\n\tpci_set_power_state(dev, PCI_D0);\n\tpci_restore_state(dev);\n\terr = pci_enable_device(dev);\n\tif (err) {\n\t\tohci_err(ohci, \"pci_enable_device failed\\n\");\n\t\treturn err;\n\t}\n\n\t \n\tif (!reg_read(ohci, OHCI1394_GUIDLo) &&\n\t\t\t\t\t!reg_read(ohci, OHCI1394_GUIDHi)) {\n\t\treg_write(ohci, OHCI1394_GUIDLo, (u32)ohci->card.guid);\n\t\treg_write(ohci, OHCI1394_GUIDHi, (u32)(ohci->card.guid >> 32));\n\t}\n\n\terr = ohci_enable(&ohci->card, NULL, 0);\n\tif (err)\n\t\treturn err;\n\n\tohci_resume_iso_dma(ohci);\n\n\treturn 0;\n}\n#endif\n\nstatic const struct pci_device_id pci_table[] = {\n\t{ PCI_DEVICE_CLASS(PCI_CLASS_SERIAL_FIREWIRE_OHCI, ~0) },\n\t{ }\n};\n\nMODULE_DEVICE_TABLE(pci, pci_table);\n\nstatic struct pci_driver fw_ohci_pci_driver = {\n\t.name\t\t= ohci_driver_name,\n\t.id_table\t= pci_table,\n\t.probe\t\t= pci_probe,\n\t.remove\t\t= pci_remove,\n#ifdef CONFIG_PM\n\t.resume\t\t= pci_resume,\n\t.suspend\t= pci_suspend,\n#endif\n};\n\nstatic int __init fw_ohci_init(void)\n{\n\tselfid_workqueue = alloc_workqueue(KBUILD_MODNAME, WQ_MEM_RECLAIM, 0);\n\tif (!selfid_workqueue)\n\t\treturn -ENOMEM;\n\n\treturn pci_register_driver(&fw_ohci_pci_driver);\n}\n\nstatic void __exit fw_ohci_cleanup(void)\n{\n\tpci_unregister_driver(&fw_ohci_pci_driver);\n\tdestroy_workqueue(selfid_workqueue);\n}\n\nmodule_init(fw_ohci_init);\nmodule_exit(fw_ohci_cleanup);\n\nMODULE_AUTHOR(\"Kristian Hoegsberg <krh@bitplanet.net>\");\nMODULE_DESCRIPTION(\"Driver for PCI OHCI IEEE1394 controllers\");\nMODULE_LICENSE(\"GPL\");\n\n \nMODULE_ALIAS(\"ohci1394\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}