{
  "module_name": "devres.c",
  "hash_id": "cd69ded40790d21d2afe679d84400ded7f85cfc90d1a011f51b12c5ead0e4000",
  "original_prompt": "Ingested from linux-6.6.14/drivers/base/devres.c",
  "human_readable_source": "\n \n\n#include <linux/device.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/percpu.h>\n\n#include <asm/sections.h>\n\n#include \"base.h\"\n#include \"trace.h\"\n\nstruct devres_node {\n\tstruct list_head\t\tentry;\n\tdr_release_t\t\t\trelease;\n\tconst char\t\t\t*name;\n\tsize_t\t\t\t\tsize;\n};\n\nstruct devres {\n\tstruct devres_node\t\tnode;\n\t \n\tu8 __aligned(ARCH_DMA_MINALIGN) data[];\n};\n\nstruct devres_group {\n\tstruct devres_node\t\tnode[2];\n\tvoid\t\t\t\t*id;\n\tint\t\t\t\tcolor;\n\t \n};\n\nstatic void set_node_dbginfo(struct devres_node *node, const char *name,\n\t\t\t     size_t size)\n{\n\tnode->name = name;\n\tnode->size = size;\n}\n\n#ifdef CONFIG_DEBUG_DEVRES\nstatic int log_devres = 0;\nmodule_param_named(log, log_devres, int, S_IRUGO | S_IWUSR);\n\nstatic void devres_dbg(struct device *dev, struct devres_node *node,\n\t\t       const char *op)\n{\n\tif (unlikely(log_devres))\n\t\tdev_err(dev, \"DEVRES %3s %p %s (%zu bytes)\\n\",\n\t\t\top, node, node->name, node->size);\n}\n#else  \n#define devres_dbg(dev, node, op)\tdo {} while (0)\n#endif  \n\nstatic void devres_log(struct device *dev, struct devres_node *node,\n\t\t       const char *op)\n{\n\ttrace_devres_log(dev, op, node, node->name, node->size);\n\tdevres_dbg(dev, node, op);\n}\n\n \nstatic void group_open_release(struct device *dev, void *res)\n{\n\t \n}\n\nstatic void group_close_release(struct device *dev, void *res)\n{\n\t \n}\n\nstatic struct devres_group * node_to_group(struct devres_node *node)\n{\n\tif (node->release == &group_open_release)\n\t\treturn container_of(node, struct devres_group, node[0]);\n\tif (node->release == &group_close_release)\n\t\treturn container_of(node, struct devres_group, node[1]);\n\treturn NULL;\n}\n\nstatic bool check_dr_size(size_t size, size_t *tot_size)\n{\n\t \n\tif (unlikely(check_add_overflow(sizeof(struct devres),\n\t\t\t\t\tsize, tot_size)))\n\t\treturn false;\n\n\t \n\t*tot_size = kmalloc_size_roundup(*tot_size);\n\n\treturn true;\n}\n\nstatic __always_inline struct devres * alloc_dr(dr_release_t release,\n\t\t\t\t\t\tsize_t size, gfp_t gfp, int nid)\n{\n\tsize_t tot_size;\n\tstruct devres *dr;\n\n\tif (!check_dr_size(size, &tot_size))\n\t\treturn NULL;\n\n\tdr = kmalloc_node_track_caller(tot_size, gfp, nid);\n\tif (unlikely(!dr))\n\t\treturn NULL;\n\n\t \n\tif (!(gfp & __GFP_ZERO))\n\t\tmemset(dr, 0, offsetof(struct devres, data));\n\n\tINIT_LIST_HEAD(&dr->node.entry);\n\tdr->node.release = release;\n\treturn dr;\n}\n\nstatic void add_dr(struct device *dev, struct devres_node *node)\n{\n\tdevres_log(dev, node, \"ADD\");\n\tBUG_ON(!list_empty(&node->entry));\n\tlist_add_tail(&node->entry, &dev->devres_head);\n}\n\nstatic void replace_dr(struct device *dev,\n\t\t       struct devres_node *old, struct devres_node *new)\n{\n\tdevres_log(dev, old, \"REPLACE\");\n\tBUG_ON(!list_empty(&new->entry));\n\tlist_replace(&old->entry, &new->entry);\n}\n\n \nvoid *__devres_alloc_node(dr_release_t release, size_t size, gfp_t gfp, int nid,\n\t\t\t  const char *name)\n{\n\tstruct devres *dr;\n\n\tdr = alloc_dr(release, size, gfp | __GFP_ZERO, nid);\n\tif (unlikely(!dr))\n\t\treturn NULL;\n\tset_node_dbginfo(&dr->node, name, size);\n\treturn dr->data;\n}\nEXPORT_SYMBOL_GPL(__devres_alloc_node);\n\n \nvoid devres_for_each_res(struct device *dev, dr_release_t release,\n\t\t\tdr_match_t match, void *match_data,\n\t\t\tvoid (*fn)(struct device *, void *, void *),\n\t\t\tvoid *data)\n{\n\tstruct devres_node *node;\n\tstruct devres_node *tmp;\n\tunsigned long flags;\n\n\tif (!fn)\n\t\treturn;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\tlist_for_each_entry_safe_reverse(node, tmp,\n\t\t\t&dev->devres_head, entry) {\n\t\tstruct devres *dr = container_of(node, struct devres, node);\n\n\t\tif (node->release != release)\n\t\t\tcontinue;\n\t\tif (match && !match(dev, dr->data, match_data))\n\t\t\tcontinue;\n\t\tfn(dev, dr->data, data);\n\t}\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n}\nEXPORT_SYMBOL_GPL(devres_for_each_res);\n\n \nvoid devres_free(void *res)\n{\n\tif (res) {\n\t\tstruct devres *dr = container_of(res, struct devres, data);\n\n\t\tBUG_ON(!list_empty(&dr->node.entry));\n\t\tkfree(dr);\n\t}\n}\nEXPORT_SYMBOL_GPL(devres_free);\n\n \nvoid devres_add(struct device *dev, void *res)\n{\n\tstruct devres *dr = container_of(res, struct devres, data);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\tadd_dr(dev, &dr->node);\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n}\nEXPORT_SYMBOL_GPL(devres_add);\n\nstatic struct devres *find_dr(struct device *dev, dr_release_t release,\n\t\t\t      dr_match_t match, void *match_data)\n{\n\tstruct devres_node *node;\n\n\tlist_for_each_entry_reverse(node, &dev->devres_head, entry) {\n\t\tstruct devres *dr = container_of(node, struct devres, node);\n\n\t\tif (node->release != release)\n\t\t\tcontinue;\n\t\tif (match && !match(dev, dr->data, match_data))\n\t\t\tcontinue;\n\t\treturn dr;\n\t}\n\n\treturn NULL;\n}\n\n \nvoid * devres_find(struct device *dev, dr_release_t release,\n\t\t   dr_match_t match, void *match_data)\n{\n\tstruct devres *dr;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\tdr = find_dr(dev, release, match, match_data);\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\n\tif (dr)\n\t\treturn dr->data;\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(devres_find);\n\n \nvoid * devres_get(struct device *dev, void *new_res,\n\t\t  dr_match_t match, void *match_data)\n{\n\tstruct devres *new_dr = container_of(new_res, struct devres, data);\n\tstruct devres *dr;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\tdr = find_dr(dev, new_dr->node.release, match, match_data);\n\tif (!dr) {\n\t\tadd_dr(dev, &new_dr->node);\n\t\tdr = new_dr;\n\t\tnew_res = NULL;\n\t}\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\tdevres_free(new_res);\n\n\treturn dr->data;\n}\nEXPORT_SYMBOL_GPL(devres_get);\n\n \nvoid * devres_remove(struct device *dev, dr_release_t release,\n\t\t     dr_match_t match, void *match_data)\n{\n\tstruct devres *dr;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\tdr = find_dr(dev, release, match, match_data);\n\tif (dr) {\n\t\tlist_del_init(&dr->node.entry);\n\t\tdevres_log(dev, &dr->node, \"REM\");\n\t}\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\n\tif (dr)\n\t\treturn dr->data;\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(devres_remove);\n\n \nint devres_destroy(struct device *dev, dr_release_t release,\n\t\t   dr_match_t match, void *match_data)\n{\n\tvoid *res;\n\n\tres = devres_remove(dev, release, match, match_data);\n\tif (unlikely(!res))\n\t\treturn -ENOENT;\n\n\tdevres_free(res);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(devres_destroy);\n\n\n \nint devres_release(struct device *dev, dr_release_t release,\n\t\t   dr_match_t match, void *match_data)\n{\n\tvoid *res;\n\n\tres = devres_remove(dev, release, match, match_data);\n\tif (unlikely(!res))\n\t\treturn -ENOENT;\n\n\t(*release)(dev, res);\n\tdevres_free(res);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(devres_release);\n\nstatic int remove_nodes(struct device *dev,\n\t\t\tstruct list_head *first, struct list_head *end,\n\t\t\tstruct list_head *todo)\n{\n\tstruct devres_node *node, *n;\n\tint cnt = 0, nr_groups = 0;\n\n\t \n\tnode = list_entry(first, struct devres_node, entry);\n\tlist_for_each_entry_safe_from(node, n, end, entry) {\n\t\tstruct devres_group *grp;\n\n\t\tgrp = node_to_group(node);\n\t\tif (grp) {\n\t\t\t \n\t\t\tgrp->color = 0;\n\t\t\tnr_groups++;\n\t\t} else {\n\t\t\t \n\t\t\tif (&node->entry == first)\n\t\t\t\tfirst = first->next;\n\t\t\tlist_move_tail(&node->entry, todo);\n\t\t\tcnt++;\n\t\t}\n\t}\n\n\tif (!nr_groups)\n\t\treturn cnt;\n\n\t \n\tnode = list_entry(first, struct devres_node, entry);\n\tlist_for_each_entry_safe_from(node, n, end, entry) {\n\t\tstruct devres_group *grp;\n\n\t\tgrp = node_to_group(node);\n\t\tBUG_ON(!grp || list_empty(&grp->node[0].entry));\n\n\t\tgrp->color++;\n\t\tif (list_empty(&grp->node[1].entry))\n\t\t\tgrp->color++;\n\n\t\tBUG_ON(grp->color <= 0 || grp->color > 2);\n\t\tif (grp->color == 2) {\n\t\t\t \n\t\t\tlist_move_tail(&grp->node[0].entry, todo);\n\t\t\tlist_del_init(&grp->node[1].entry);\n\t\t}\n\t}\n\n\treturn cnt;\n}\n\nstatic void release_nodes(struct device *dev, struct list_head *todo)\n{\n\tstruct devres *dr, *tmp;\n\n\t \n\tlist_for_each_entry_safe_reverse(dr, tmp, todo, node.entry) {\n\t\tdevres_log(dev, &dr->node, \"REL\");\n\t\tdr->node.release(dev, dr->data);\n\t\tkfree(dr);\n\t}\n}\n\n \nint devres_release_all(struct device *dev)\n{\n\tunsigned long flags;\n\tLIST_HEAD(todo);\n\tint cnt;\n\n\t \n\tif (WARN_ON(dev->devres_head.next == NULL))\n\t\treturn -ENODEV;\n\n\t \n\tif (list_empty(&dev->devres_head))\n\t\treturn 0;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\tcnt = remove_nodes(dev, dev->devres_head.next, &dev->devres_head, &todo);\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\n\trelease_nodes(dev, &todo);\n\treturn cnt;\n}\n\n \nvoid * devres_open_group(struct device *dev, void *id, gfp_t gfp)\n{\n\tstruct devres_group *grp;\n\tunsigned long flags;\n\n\tgrp = kmalloc(sizeof(*grp), gfp);\n\tif (unlikely(!grp))\n\t\treturn NULL;\n\n\tgrp->node[0].release = &group_open_release;\n\tgrp->node[1].release = &group_close_release;\n\tINIT_LIST_HEAD(&grp->node[0].entry);\n\tINIT_LIST_HEAD(&grp->node[1].entry);\n\tset_node_dbginfo(&grp->node[0], \"grp<\", 0);\n\tset_node_dbginfo(&grp->node[1], \"grp>\", 0);\n\tgrp->id = grp;\n\tif (id)\n\t\tgrp->id = id;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\tadd_dr(dev, &grp->node[0]);\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\treturn grp->id;\n}\nEXPORT_SYMBOL_GPL(devres_open_group);\n\n \nstatic struct devres_group * find_group(struct device *dev, void *id)\n{\n\tstruct devres_node *node;\n\n\tlist_for_each_entry_reverse(node, &dev->devres_head, entry) {\n\t\tstruct devres_group *grp;\n\n\t\tif (node->release != &group_open_release)\n\t\t\tcontinue;\n\n\t\tgrp = container_of(node, struct devres_group, node[0]);\n\n\t\tif (id) {\n\t\t\tif (grp->id == id)\n\t\t\t\treturn grp;\n\t\t} else if (list_empty(&grp->node[1].entry))\n\t\t\treturn grp;\n\t}\n\n\treturn NULL;\n}\n\n \nvoid devres_close_group(struct device *dev, void *id)\n{\n\tstruct devres_group *grp;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\n\tgrp = find_group(dev, id);\n\tif (grp)\n\t\tadd_dr(dev, &grp->node[1]);\n\telse\n\t\tWARN_ON(1);\n\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n}\nEXPORT_SYMBOL_GPL(devres_close_group);\n\n \nvoid devres_remove_group(struct device *dev, void *id)\n{\n\tstruct devres_group *grp;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\n\tgrp = find_group(dev, id);\n\tif (grp) {\n\t\tlist_del_init(&grp->node[0].entry);\n\t\tlist_del_init(&grp->node[1].entry);\n\t\tdevres_log(dev, &grp->node[0], \"REM\");\n\t} else\n\t\tWARN_ON(1);\n\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\n\tkfree(grp);\n}\nEXPORT_SYMBOL_GPL(devres_remove_group);\n\n \nint devres_release_group(struct device *dev, void *id)\n{\n\tstruct devres_group *grp;\n\tunsigned long flags;\n\tLIST_HEAD(todo);\n\tint cnt = 0;\n\n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\n\tgrp = find_group(dev, id);\n\tif (grp) {\n\t\tstruct list_head *first = &grp->node[0].entry;\n\t\tstruct list_head *end = &dev->devres_head;\n\n\t\tif (!list_empty(&grp->node[1].entry))\n\t\t\tend = grp->node[1].entry.next;\n\n\t\tcnt = remove_nodes(dev, first, end, &todo);\n\t\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\n\t\trelease_nodes(dev, &todo);\n\t} else {\n\t\tWARN_ON(1);\n\t\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\t}\n\n\treturn cnt;\n}\nEXPORT_SYMBOL_GPL(devres_release_group);\n\n \n\nstruct action_devres {\n\tvoid *data;\n\tvoid (*action)(void *);\n};\n\nstatic int devm_action_match(struct device *dev, void *res, void *p)\n{\n\tstruct action_devres *devres = res;\n\tstruct action_devres *target = p;\n\n\treturn devres->action == target->action &&\n\t       devres->data == target->data;\n}\n\nstatic void devm_action_release(struct device *dev, void *res)\n{\n\tstruct action_devres *devres = res;\n\n\tdevres->action(devres->data);\n}\n\n \nint __devm_add_action(struct device *dev, void (*action)(void *), void *data, const char *name)\n{\n\tstruct action_devres *devres;\n\n\tdevres = __devres_alloc_node(devm_action_release, sizeof(struct action_devres),\n\t\t\t\t     GFP_KERNEL, NUMA_NO_NODE, name);\n\tif (!devres)\n\t\treturn -ENOMEM;\n\n\tdevres->data = data;\n\tdevres->action = action;\n\n\tdevres_add(dev, devres);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__devm_add_action);\n\n \nvoid devm_remove_action(struct device *dev, void (*action)(void *), void *data)\n{\n\tstruct action_devres devres = {\n\t\t.data = data,\n\t\t.action = action,\n\t};\n\n\tWARN_ON(devres_destroy(dev, devm_action_release, devm_action_match,\n\t\t\t       &devres));\n}\nEXPORT_SYMBOL_GPL(devm_remove_action);\n\n \nvoid devm_release_action(struct device *dev, void (*action)(void *), void *data)\n{\n\tstruct action_devres devres = {\n\t\t.data = data,\n\t\t.action = action,\n\t};\n\n\tWARN_ON(devres_release(dev, devm_action_release, devm_action_match,\n\t\t\t       &devres));\n\n}\nEXPORT_SYMBOL_GPL(devm_release_action);\n\n \nstatic void devm_kmalloc_release(struct device *dev, void *res)\n{\n\t \n}\n\nstatic int devm_kmalloc_match(struct device *dev, void *res, void *data)\n{\n\treturn res == data;\n}\n\n \nvoid *devm_kmalloc(struct device *dev, size_t size, gfp_t gfp)\n{\n\tstruct devres *dr;\n\n\tif (unlikely(!size))\n\t\treturn ZERO_SIZE_PTR;\n\n\t \n\tdr = alloc_dr(devm_kmalloc_release, size, gfp, dev_to_node(dev));\n\tif (unlikely(!dr))\n\t\treturn NULL;\n\n\t \n\tset_node_dbginfo(&dr->node, \"devm_kzalloc_release\", size);\n\tdevres_add(dev, dr->data);\n\treturn dr->data;\n}\nEXPORT_SYMBOL_GPL(devm_kmalloc);\n\n \nvoid *devm_krealloc(struct device *dev, void *ptr, size_t new_size, gfp_t gfp)\n{\n\tsize_t total_new_size, total_old_size;\n\tstruct devres *old_dr, *new_dr;\n\tunsigned long flags;\n\n\tif (unlikely(!new_size)) {\n\t\tdevm_kfree(dev, ptr);\n\t\treturn ZERO_SIZE_PTR;\n\t}\n\n\tif (unlikely(ZERO_OR_NULL_PTR(ptr)))\n\t\treturn devm_kmalloc(dev, new_size, gfp);\n\n\tif (WARN_ON(is_kernel_rodata((unsigned long)ptr)))\n\t\t \n\t\treturn NULL;\n\n\tif (!check_dr_size(new_size, &total_new_size))\n\t\treturn NULL;\n\n\ttotal_old_size = ksize(container_of(ptr, struct devres, data));\n\tif (total_old_size == 0) {\n\t\tWARN(1, \"Pointer doesn't point to dynamically allocated memory.\");\n\t\treturn NULL;\n\t}\n\n\t \n\tif (total_new_size <= total_old_size)\n\t\treturn ptr;\n\n\t \n\tnew_dr = alloc_dr(devm_kmalloc_release,\n\t\t\t  total_new_size, gfp, dev_to_node(dev));\n\tif (!new_dr)\n\t\treturn NULL;\n\n\t \n\tspin_lock_irqsave(&dev->devres_lock, flags);\n\n\told_dr = find_dr(dev, devm_kmalloc_release, devm_kmalloc_match, ptr);\n\tif (!old_dr) {\n\t\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\t\tkfree(new_dr);\n\t\tWARN(1, \"Memory chunk not managed or managed by a different device.\");\n\t\treturn NULL;\n\t}\n\n\treplace_dr(dev, &old_dr->node, &new_dr->node);\n\n\tspin_unlock_irqrestore(&dev->devres_lock, flags);\n\n\t \n\tmemcpy(new_dr->data, old_dr->data,\n\t       total_old_size - offsetof(struct devres, data));\n\t \n\tkfree(old_dr);\n\n\treturn new_dr->data;\n}\nEXPORT_SYMBOL_GPL(devm_krealloc);\n\n \nchar *devm_kstrdup(struct device *dev, const char *s, gfp_t gfp)\n{\n\tsize_t size;\n\tchar *buf;\n\n\tif (!s)\n\t\treturn NULL;\n\n\tsize = strlen(s) + 1;\n\tbuf = devm_kmalloc(dev, size, gfp);\n\tif (buf)\n\t\tmemcpy(buf, s, size);\n\treturn buf;\n}\nEXPORT_SYMBOL_GPL(devm_kstrdup);\n\n \nconst char *devm_kstrdup_const(struct device *dev, const char *s, gfp_t gfp)\n{\n\tif (is_kernel_rodata((unsigned long)s))\n\t\treturn s;\n\n\treturn devm_kstrdup(dev, s, gfp);\n}\nEXPORT_SYMBOL_GPL(devm_kstrdup_const);\n\n \nchar *devm_kvasprintf(struct device *dev, gfp_t gfp, const char *fmt,\n\t\t      va_list ap)\n{\n\tunsigned int len;\n\tchar *p;\n\tva_list aq;\n\n\tva_copy(aq, ap);\n\tlen = vsnprintf(NULL, 0, fmt, aq);\n\tva_end(aq);\n\n\tp = devm_kmalloc(dev, len+1, gfp);\n\tif (!p)\n\t\treturn NULL;\n\n\tvsnprintf(p, len+1, fmt, ap);\n\n\treturn p;\n}\nEXPORT_SYMBOL(devm_kvasprintf);\n\n \nchar *devm_kasprintf(struct device *dev, gfp_t gfp, const char *fmt, ...)\n{\n\tva_list ap;\n\tchar *p;\n\n\tva_start(ap, fmt);\n\tp = devm_kvasprintf(dev, gfp, fmt, ap);\n\tva_end(ap);\n\n\treturn p;\n}\nEXPORT_SYMBOL_GPL(devm_kasprintf);\n\n \nvoid devm_kfree(struct device *dev, const void *p)\n{\n\tint rc;\n\n\t \n\tif (unlikely(is_kernel_rodata((unsigned long)p) || ZERO_OR_NULL_PTR(p)))\n\t\treturn;\n\n\trc = devres_destroy(dev, devm_kmalloc_release,\n\t\t\t    devm_kmalloc_match, (void *)p);\n\tWARN_ON(rc);\n}\nEXPORT_SYMBOL_GPL(devm_kfree);\n\n \nvoid *devm_kmemdup(struct device *dev, const void *src, size_t len, gfp_t gfp)\n{\n\tvoid *p;\n\n\tp = devm_kmalloc(dev, len, gfp);\n\tif (p)\n\t\tmemcpy(p, src, len);\n\n\treturn p;\n}\nEXPORT_SYMBOL_GPL(devm_kmemdup);\n\nstruct pages_devres {\n\tunsigned long addr;\n\tunsigned int order;\n};\n\nstatic int devm_pages_match(struct device *dev, void *res, void *p)\n{\n\tstruct pages_devres *devres = res;\n\tstruct pages_devres *target = p;\n\n\treturn devres->addr == target->addr;\n}\n\nstatic void devm_pages_release(struct device *dev, void *res)\n{\n\tstruct pages_devres *devres = res;\n\n\tfree_pages(devres->addr, devres->order);\n}\n\n \n\nunsigned long devm_get_free_pages(struct device *dev,\n\t\t\t\t  gfp_t gfp_mask, unsigned int order)\n{\n\tstruct pages_devres *devres;\n\tunsigned long addr;\n\n\taddr = __get_free_pages(gfp_mask, order);\n\n\tif (unlikely(!addr))\n\t\treturn 0;\n\n\tdevres = devres_alloc(devm_pages_release,\n\t\t\t      sizeof(struct pages_devres), GFP_KERNEL);\n\tif (unlikely(!devres)) {\n\t\tfree_pages(addr, order);\n\t\treturn 0;\n\t}\n\n\tdevres->addr = addr;\n\tdevres->order = order;\n\n\tdevres_add(dev, devres);\n\treturn addr;\n}\nEXPORT_SYMBOL_GPL(devm_get_free_pages);\n\n \nvoid devm_free_pages(struct device *dev, unsigned long addr)\n{\n\tstruct pages_devres devres = { .addr = addr };\n\n\tWARN_ON(devres_release(dev, devm_pages_release, devm_pages_match,\n\t\t\t       &devres));\n}\nEXPORT_SYMBOL_GPL(devm_free_pages);\n\nstatic void devm_percpu_release(struct device *dev, void *pdata)\n{\n\tvoid __percpu *p;\n\n\tp = *(void __percpu **)pdata;\n\tfree_percpu(p);\n}\n\nstatic int devm_percpu_match(struct device *dev, void *data, void *p)\n{\n\tstruct devres *devr = container_of(data, struct devres, data);\n\n\treturn *(void **)devr->data == p;\n}\n\n \nvoid __percpu *__devm_alloc_percpu(struct device *dev, size_t size,\n\t\tsize_t align)\n{\n\tvoid *p;\n\tvoid __percpu *pcpu;\n\n\tpcpu = __alloc_percpu(size, align);\n\tif (!pcpu)\n\t\treturn NULL;\n\n\tp = devres_alloc(devm_percpu_release, sizeof(void *), GFP_KERNEL);\n\tif (!p) {\n\t\tfree_percpu(pcpu);\n\t\treturn NULL;\n\t}\n\n\t*(void __percpu **)p = pcpu;\n\n\tdevres_add(dev, p);\n\n\treturn pcpu;\n}\nEXPORT_SYMBOL_GPL(__devm_alloc_percpu);\n\n \nvoid devm_free_percpu(struct device *dev, void __percpu *pdata)\n{\n\tWARN_ON(devres_destroy(dev, devm_percpu_release, devm_percpu_match,\n\t\t\t       (__force void *)pdata));\n}\nEXPORT_SYMBOL_GPL(devm_free_percpu);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}