{
  "module_name": "cpu.c",
  "hash_id": "ec2849ee669620b31d9ea2f174c7ec5a6eadf2da666ba88e0728aaea1ce316a1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/base/cpu.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/topology.h>\n#include <linux/device.h>\n#include <linux/node.h>\n#include <linux/gfp.h>\n#include <linux/slab.h>\n#include <linux/percpu.h>\n#include <linux/acpi.h>\n#include <linux/of.h>\n#include <linux/cpufeature.h>\n#include <linux/tick.h>\n#include <linux/pm_qos.h>\n#include <linux/delay.h>\n#include <linux/sched/isolation.h>\n\n#include \"base.h\"\n\nstatic DEFINE_PER_CPU(struct device *, cpu_sys_devices);\n\nstatic int cpu_subsys_match(struct device *dev, struct device_driver *drv)\n{\n\t \n\tif (acpi_driver_match_device(dev, drv))\n\t\treturn 1;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_HOTPLUG_CPU\nstatic void change_cpu_under_node(struct cpu *cpu,\n\t\t\tunsigned int from_nid, unsigned int to_nid)\n{\n\tint cpuid = cpu->dev.id;\n\tunregister_cpu_under_node(cpuid, from_nid);\n\tregister_cpu_under_node(cpuid, to_nid);\n\tcpu->node_id = to_nid;\n}\n\nstatic int cpu_subsys_online(struct device *dev)\n{\n\tstruct cpu *cpu = container_of(dev, struct cpu, dev);\n\tint cpuid = dev->id;\n\tint from_nid, to_nid;\n\tint ret;\n\tint retries = 0;\n\n\tfrom_nid = cpu_to_node(cpuid);\n\tif (from_nid == NUMA_NO_NODE)\n\t\treturn -ENODEV;\n\nretry:\n\tret = cpu_device_up(dev);\n\n\t \n\tif (ret == -EBUSY) {\n\t\tretries++;\n\t\tif (retries > 5)\n\t\t\treturn ret;\n\t\tmsleep(10 * (1 << retries));\n\t\tgoto retry;\n\t}\n\n\t \n\tto_nid = cpu_to_node(cpuid);\n\tif (from_nid != to_nid)\n\t\tchange_cpu_under_node(cpu, from_nid, to_nid);\n\n\treturn ret;\n}\n\nstatic int cpu_subsys_offline(struct device *dev)\n{\n\treturn cpu_device_down(dev);\n}\n\nvoid unregister_cpu(struct cpu *cpu)\n{\n\tint logical_cpu = cpu->dev.id;\n\n\tunregister_cpu_under_node(logical_cpu, cpu_to_node(logical_cpu));\n\n\tdevice_unregister(&cpu->dev);\n\tper_cpu(cpu_sys_devices, logical_cpu) = NULL;\n\treturn;\n}\n\n#ifdef CONFIG_ARCH_CPU_PROBE_RELEASE\nstatic ssize_t cpu_probe_store(struct device *dev,\n\t\t\t       struct device_attribute *attr,\n\t\t\t       const char *buf,\n\t\t\t       size_t count)\n{\n\tssize_t cnt;\n\tint ret;\n\n\tret = lock_device_hotplug_sysfs();\n\tif (ret)\n\t\treturn ret;\n\n\tcnt = arch_cpu_probe(buf, count);\n\n\tunlock_device_hotplug();\n\treturn cnt;\n}\n\nstatic ssize_t cpu_release_store(struct device *dev,\n\t\t\t\t struct device_attribute *attr,\n\t\t\t\t const char *buf,\n\t\t\t\t size_t count)\n{\n\tssize_t cnt;\n\tint ret;\n\n\tret = lock_device_hotplug_sysfs();\n\tif (ret)\n\t\treturn ret;\n\n\tcnt = arch_cpu_release(buf, count);\n\n\tunlock_device_hotplug();\n\treturn cnt;\n}\n\nstatic DEVICE_ATTR(probe, S_IWUSR, NULL, cpu_probe_store);\nstatic DEVICE_ATTR(release, S_IWUSR, NULL, cpu_release_store);\n#endif  \n#endif  \n\n#ifdef CONFIG_KEXEC_CORE\n#include <linux/kexec.h>\n\nstatic ssize_t crash_notes_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr,\n\t\t\t\tchar *buf)\n{\n\tstruct cpu *cpu = container_of(dev, struct cpu, dev);\n\tunsigned long long addr;\n\tint cpunum;\n\n\tcpunum = cpu->dev.id;\n\n\t \n\taddr = per_cpu_ptr_to_phys(per_cpu_ptr(crash_notes, cpunum));\n\n\treturn sysfs_emit(buf, \"%llx\\n\", addr);\n}\nstatic DEVICE_ATTR_ADMIN_RO(crash_notes);\n\nstatic ssize_t crash_notes_size_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\treturn sysfs_emit(buf, \"%zu\\n\", sizeof(note_buf_t));\n}\nstatic DEVICE_ATTR_ADMIN_RO(crash_notes_size);\n\nstatic struct attribute *crash_note_cpu_attrs[] = {\n\t&dev_attr_crash_notes.attr,\n\t&dev_attr_crash_notes_size.attr,\n\tNULL\n};\n\nstatic const struct attribute_group crash_note_cpu_attr_group = {\n\t.attrs = crash_note_cpu_attrs,\n};\n#endif\n\nstatic const struct attribute_group *common_cpu_attr_groups[] = {\n#ifdef CONFIG_KEXEC_CORE\n\t&crash_note_cpu_attr_group,\n#endif\n\tNULL\n};\n\nstatic const struct attribute_group *hotplugable_cpu_attr_groups[] = {\n#ifdef CONFIG_KEXEC_CORE\n\t&crash_note_cpu_attr_group,\n#endif\n\tNULL\n};\n\n \n\nstruct cpu_attr {\n\tstruct device_attribute attr;\n\tconst struct cpumask *const map;\n};\n\nstatic ssize_t show_cpus_attr(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct cpu_attr *ca = container_of(attr, struct cpu_attr, attr);\n\n\treturn cpumap_print_to_pagebuf(true, buf, ca->map);\n}\n\n#define _CPU_ATTR(name, map) \\\n\t{ __ATTR(name, 0444, show_cpus_attr, NULL), map }\n\n \nstatic struct cpu_attr cpu_attrs[] = {\n\t_CPU_ATTR(online, &__cpu_online_mask),\n\t_CPU_ATTR(possible, &__cpu_possible_mask),\n\t_CPU_ATTR(present, &__cpu_present_mask),\n};\n\n \nstatic ssize_t print_cpus_kernel_max(struct device *dev,\n\t\t\t\t     struct device_attribute *attr, char *buf)\n{\n\treturn sysfs_emit(buf, \"%d\\n\", NR_CPUS - 1);\n}\nstatic DEVICE_ATTR(kernel_max, 0444, print_cpus_kernel_max, NULL);\n\n \nunsigned int total_cpus;\n\nstatic ssize_t print_cpus_offline(struct device *dev,\n\t\t\t\t  struct device_attribute *attr, char *buf)\n{\n\tint len = 0;\n\tcpumask_var_t offline;\n\n\t \n\tif (!alloc_cpumask_var(&offline, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\tcpumask_andnot(offline, cpu_possible_mask, cpu_online_mask);\n\tlen += sysfs_emit_at(buf, len, \"%*pbl\", cpumask_pr_args(offline));\n\tfree_cpumask_var(offline);\n\n\t \n\tif (total_cpus && nr_cpu_ids < total_cpus) {\n\t\tlen += sysfs_emit_at(buf, len, \",\");\n\n\t\tif (nr_cpu_ids == total_cpus-1)\n\t\t\tlen += sysfs_emit_at(buf, len, \"%u\", nr_cpu_ids);\n\t\telse\n\t\t\tlen += sysfs_emit_at(buf, len, \"%u-%d\",\n\t\t\t\t\t     nr_cpu_ids, total_cpus - 1);\n\t}\n\n\tlen += sysfs_emit_at(buf, len, \"\\n\");\n\n\treturn len;\n}\nstatic DEVICE_ATTR(offline, 0444, print_cpus_offline, NULL);\n\nstatic ssize_t print_cpus_isolated(struct device *dev,\n\t\t\t\t  struct device_attribute *attr, char *buf)\n{\n\tint len;\n\tcpumask_var_t isolated;\n\n\tif (!alloc_cpumask_var(&isolated, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\tcpumask_andnot(isolated, cpu_possible_mask,\n\t\t       housekeeping_cpumask(HK_TYPE_DOMAIN));\n\tlen = sysfs_emit(buf, \"%*pbl\\n\", cpumask_pr_args(isolated));\n\n\tfree_cpumask_var(isolated);\n\n\treturn len;\n}\nstatic DEVICE_ATTR(isolated, 0444, print_cpus_isolated, NULL);\n\n#ifdef CONFIG_NO_HZ_FULL\nstatic ssize_t print_cpus_nohz_full(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\treturn sysfs_emit(buf, \"%*pbl\\n\", cpumask_pr_args(tick_nohz_full_mask));\n}\nstatic DEVICE_ATTR(nohz_full, 0444, print_cpus_nohz_full, NULL);\n#endif\n\n#ifdef CONFIG_CRASH_HOTPLUG\nstatic ssize_t crash_hotplug_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\treturn sysfs_emit(buf, \"%d\\n\", crash_hotplug_cpu_support());\n}\nstatic DEVICE_ATTR_ADMIN_RO(crash_hotplug);\n#endif\n\nstatic void cpu_device_release(struct device *dev)\n{\n\t \n}\n\n#ifdef CONFIG_GENERIC_CPU_AUTOPROBE\nstatic ssize_t print_cpu_modalias(struct device *dev,\n\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t  char *buf)\n{\n\tint len = 0;\n\tu32 i;\n\n\tlen += sysfs_emit_at(buf, len,\n\t\t\t     \"cpu:type:\" CPU_FEATURE_TYPEFMT \":feature:\",\n\t\t\t     CPU_FEATURE_TYPEVAL);\n\n\tfor (i = 0; i < MAX_CPU_FEATURES; i++)\n\t\tif (cpu_have_feature(i)) {\n\t\t\tif (len + sizeof(\",XXXX\\n\") >= PAGE_SIZE) {\n\t\t\t\tWARN(1, \"CPU features overflow page\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tlen += sysfs_emit_at(buf, len, \",%04X\", i);\n\t\t}\n\tlen += sysfs_emit_at(buf, len, \"\\n\");\n\treturn len;\n}\n\nstatic int cpu_uevent(const struct device *dev, struct kobj_uevent_env *env)\n{\n\tchar *buf = kzalloc(PAGE_SIZE, GFP_KERNEL);\n\tif (buf) {\n\t\tprint_cpu_modalias(NULL, NULL, buf);\n\t\tadd_uevent_var(env, \"MODALIAS=%s\", buf);\n\t\tkfree(buf);\n\t}\n\treturn 0;\n}\n#endif\n\nstruct bus_type cpu_subsys = {\n\t.name = \"cpu\",\n\t.dev_name = \"cpu\",\n\t.match = cpu_subsys_match,\n#ifdef CONFIG_HOTPLUG_CPU\n\t.online = cpu_subsys_online,\n\t.offline = cpu_subsys_offline,\n#endif\n#ifdef CONFIG_GENERIC_CPU_AUTOPROBE\n\t.uevent = cpu_uevent,\n#endif\n};\nEXPORT_SYMBOL_GPL(cpu_subsys);\n\n \nint register_cpu(struct cpu *cpu, int num)\n{\n\tint error;\n\n\tcpu->node_id = cpu_to_node(num);\n\tmemset(&cpu->dev, 0x00, sizeof(struct device));\n\tcpu->dev.id = num;\n\tcpu->dev.bus = &cpu_subsys;\n\tcpu->dev.release = cpu_device_release;\n\tcpu->dev.offline_disabled = !cpu->hotpluggable;\n\tcpu->dev.offline = !cpu_online(num);\n\tcpu->dev.of_node = of_get_cpu_node(num, NULL);\n\tcpu->dev.groups = common_cpu_attr_groups;\n\tif (cpu->hotpluggable)\n\t\tcpu->dev.groups = hotplugable_cpu_attr_groups;\n\terror = device_register(&cpu->dev);\n\tif (error) {\n\t\tput_device(&cpu->dev);\n\t\treturn error;\n\t}\n\n\tper_cpu(cpu_sys_devices, num) = &cpu->dev;\n\tregister_cpu_under_node(num, cpu_to_node(num));\n\tdev_pm_qos_expose_latency_limit(&cpu->dev,\n\t\t\t\t\tPM_QOS_RESUME_LATENCY_NO_CONSTRAINT);\n\n\treturn 0;\n}\n\nstruct device *get_cpu_device(unsigned int cpu)\n{\n\tif (cpu < nr_cpu_ids && cpu_possible(cpu))\n\t\treturn per_cpu(cpu_sys_devices, cpu);\n\telse\n\t\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(get_cpu_device);\n\nstatic void device_create_release(struct device *dev)\n{\n\tkfree(dev);\n}\n\n__printf(4, 0)\nstatic struct device *\n__cpu_device_create(struct device *parent, void *drvdata,\n\t\t    const struct attribute_group **groups,\n\t\t    const char *fmt, va_list args)\n{\n\tstruct device *dev = NULL;\n\tint retval = -ENOMEM;\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\tgoto error;\n\n\tdevice_initialize(dev);\n\tdev->parent = parent;\n\tdev->groups = groups;\n\tdev->release = device_create_release;\n\tdevice_set_pm_not_required(dev);\n\tdev_set_drvdata(dev, drvdata);\n\n\tretval = kobject_set_name_vargs(&dev->kobj, fmt, args);\n\tif (retval)\n\t\tgoto error;\n\n\tretval = device_add(dev);\n\tif (retval)\n\t\tgoto error;\n\n\treturn dev;\n\nerror:\n\tput_device(dev);\n\treturn ERR_PTR(retval);\n}\n\nstruct device *cpu_device_create(struct device *parent, void *drvdata,\n\t\t\t\t const struct attribute_group **groups,\n\t\t\t\t const char *fmt, ...)\n{\n\tva_list vargs;\n\tstruct device *dev;\n\n\tva_start(vargs, fmt);\n\tdev = __cpu_device_create(parent, drvdata, groups, fmt, vargs);\n\tva_end(vargs);\n\treturn dev;\n}\nEXPORT_SYMBOL_GPL(cpu_device_create);\n\n#ifdef CONFIG_GENERIC_CPU_AUTOPROBE\nstatic DEVICE_ATTR(modalias, 0444, print_cpu_modalias, NULL);\n#endif\n\nstatic struct attribute *cpu_root_attrs[] = {\n#ifdef CONFIG_ARCH_CPU_PROBE_RELEASE\n\t&dev_attr_probe.attr,\n\t&dev_attr_release.attr,\n#endif\n\t&cpu_attrs[0].attr.attr,\n\t&cpu_attrs[1].attr.attr,\n\t&cpu_attrs[2].attr.attr,\n\t&dev_attr_kernel_max.attr,\n\t&dev_attr_offline.attr,\n\t&dev_attr_isolated.attr,\n#ifdef CONFIG_NO_HZ_FULL\n\t&dev_attr_nohz_full.attr,\n#endif\n#ifdef CONFIG_CRASH_HOTPLUG\n\t&dev_attr_crash_hotplug.attr,\n#endif\n#ifdef CONFIG_GENERIC_CPU_AUTOPROBE\n\t&dev_attr_modalias.attr,\n#endif\n\tNULL\n};\n\nstatic const struct attribute_group cpu_root_attr_group = {\n\t.attrs = cpu_root_attrs,\n};\n\nstatic const struct attribute_group *cpu_root_attr_groups[] = {\n\t&cpu_root_attr_group,\n\tNULL,\n};\n\nbool cpu_is_hotpluggable(unsigned int cpu)\n{\n\tstruct device *dev = get_cpu_device(cpu);\n\treturn dev && container_of(dev, struct cpu, dev)->hotpluggable\n\t\t&& tick_nohz_cpu_hotpluggable(cpu);\n}\nEXPORT_SYMBOL_GPL(cpu_is_hotpluggable);\n\n#ifdef CONFIG_GENERIC_CPU_DEVICES\nstatic DEFINE_PER_CPU(struct cpu, cpu_devices);\n#endif\n\nstatic void __init cpu_dev_register_generic(void)\n{\n#ifdef CONFIG_GENERIC_CPU_DEVICES\n\tint i;\n\n\tfor_each_possible_cpu(i) {\n\t\tif (register_cpu(&per_cpu(cpu_devices, i), i))\n\t\t\tpanic(\"Failed to register CPU device\");\n\t}\n#endif\n}\n\n#ifdef CONFIG_GENERIC_CPU_VULNERABILITIES\nstatic ssize_t cpu_show_not_affected(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *buf)\n{\n\treturn sysfs_emit(buf, \"Not affected\\n\");\n}\n\n#define CPU_SHOW_VULN_FALLBACK(func)\t\t\t\t\t\\\n\tssize_t cpu_show_##func(struct device *,\t\t\t\\\n\t\t\t\t  struct device_attribute *, char *)\t\\\n\t\t __attribute__((weak, alias(\"cpu_show_not_affected\")))\n\nCPU_SHOW_VULN_FALLBACK(meltdown);\nCPU_SHOW_VULN_FALLBACK(spectre_v1);\nCPU_SHOW_VULN_FALLBACK(spectre_v2);\nCPU_SHOW_VULN_FALLBACK(spec_store_bypass);\nCPU_SHOW_VULN_FALLBACK(l1tf);\nCPU_SHOW_VULN_FALLBACK(mds);\nCPU_SHOW_VULN_FALLBACK(tsx_async_abort);\nCPU_SHOW_VULN_FALLBACK(itlb_multihit);\nCPU_SHOW_VULN_FALLBACK(srbds);\nCPU_SHOW_VULN_FALLBACK(mmio_stale_data);\nCPU_SHOW_VULN_FALLBACK(retbleed);\nCPU_SHOW_VULN_FALLBACK(spec_rstack_overflow);\nCPU_SHOW_VULN_FALLBACK(gds);\n\nstatic DEVICE_ATTR(meltdown, 0444, cpu_show_meltdown, NULL);\nstatic DEVICE_ATTR(spectre_v1, 0444, cpu_show_spectre_v1, NULL);\nstatic DEVICE_ATTR(spectre_v2, 0444, cpu_show_spectre_v2, NULL);\nstatic DEVICE_ATTR(spec_store_bypass, 0444, cpu_show_spec_store_bypass, NULL);\nstatic DEVICE_ATTR(l1tf, 0444, cpu_show_l1tf, NULL);\nstatic DEVICE_ATTR(mds, 0444, cpu_show_mds, NULL);\nstatic DEVICE_ATTR(tsx_async_abort, 0444, cpu_show_tsx_async_abort, NULL);\nstatic DEVICE_ATTR(itlb_multihit, 0444, cpu_show_itlb_multihit, NULL);\nstatic DEVICE_ATTR(srbds, 0444, cpu_show_srbds, NULL);\nstatic DEVICE_ATTR(mmio_stale_data, 0444, cpu_show_mmio_stale_data, NULL);\nstatic DEVICE_ATTR(retbleed, 0444, cpu_show_retbleed, NULL);\nstatic DEVICE_ATTR(spec_rstack_overflow, 0444, cpu_show_spec_rstack_overflow, NULL);\nstatic DEVICE_ATTR(gather_data_sampling, 0444, cpu_show_gds, NULL);\n\nstatic struct attribute *cpu_root_vulnerabilities_attrs[] = {\n\t&dev_attr_meltdown.attr,\n\t&dev_attr_spectre_v1.attr,\n\t&dev_attr_spectre_v2.attr,\n\t&dev_attr_spec_store_bypass.attr,\n\t&dev_attr_l1tf.attr,\n\t&dev_attr_mds.attr,\n\t&dev_attr_tsx_async_abort.attr,\n\t&dev_attr_itlb_multihit.attr,\n\t&dev_attr_srbds.attr,\n\t&dev_attr_mmio_stale_data.attr,\n\t&dev_attr_retbleed.attr,\n\t&dev_attr_spec_rstack_overflow.attr,\n\t&dev_attr_gather_data_sampling.attr,\n\tNULL\n};\n\nstatic const struct attribute_group cpu_root_vulnerabilities_group = {\n\t.name  = \"vulnerabilities\",\n\t.attrs = cpu_root_vulnerabilities_attrs,\n};\n\nstatic void __init cpu_register_vulnerabilities(void)\n{\n\tstruct device *dev = bus_get_dev_root(&cpu_subsys);\n\n\tif (dev) {\n\t\tif (sysfs_create_group(&dev->kobj, &cpu_root_vulnerabilities_group))\n\t\t\tpr_err(\"Unable to register CPU vulnerabilities\\n\");\n\t\tput_device(dev);\n\t}\n}\n\n#else\nstatic inline void cpu_register_vulnerabilities(void) { }\n#endif\n\nvoid __init cpu_dev_init(void)\n{\n\tif (subsys_system_register(&cpu_subsys, cpu_root_attr_groups))\n\t\tpanic(\"Failed to register CPU subsystem\");\n\n\tcpu_dev_register_generic();\n\tcpu_register_vulnerabilities();\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}