{
  "module_name": "main.c",
  "hash_id": "fd10767e8ed9ac77aea99fb8dda63e374c615ac11200bbc9e1fc0a3fa6d59269",
  "original_prompt": "Ingested from linux-6.6.14/drivers/base/power/main.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"PM: \" fmt\n#define dev_fmt pr_fmt\n\n#include <linux/device.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/pm.h>\n#include <linux/pm_runtime.h>\n#include <linux/pm-trace.h>\n#include <linux/pm_wakeirq.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/sched/debug.h>\n#include <linux/async.h>\n#include <linux/suspend.h>\n#include <trace/events/power.h>\n#include <linux/cpufreq.h>\n#include <linux/devfreq.h>\n#include <linux/timer.h>\n\n#include \"../base.h\"\n#include \"power.h\"\n\ntypedef int (*pm_callback_t)(struct device *);\n\n#define list_for_each_entry_rcu_locked(pos, head, member) \\\n\tlist_for_each_entry_rcu(pos, head, member, \\\n\t\t\tdevice_links_read_lock_held())\n\n \n\nLIST_HEAD(dpm_list);\nstatic LIST_HEAD(dpm_prepared_list);\nstatic LIST_HEAD(dpm_suspended_list);\nstatic LIST_HEAD(dpm_late_early_list);\nstatic LIST_HEAD(dpm_noirq_list);\n\nstruct suspend_stats suspend_stats;\nstatic DEFINE_MUTEX(dpm_list_mtx);\nstatic pm_message_t pm_transition;\n\nstatic int async_error;\n\nstatic const char *pm_verb(int event)\n{\n\tswitch (event) {\n\tcase PM_EVENT_SUSPEND:\n\t\treturn \"suspend\";\n\tcase PM_EVENT_RESUME:\n\t\treturn \"resume\";\n\tcase PM_EVENT_FREEZE:\n\t\treturn \"freeze\";\n\tcase PM_EVENT_QUIESCE:\n\t\treturn \"quiesce\";\n\tcase PM_EVENT_HIBERNATE:\n\t\treturn \"hibernate\";\n\tcase PM_EVENT_THAW:\n\t\treturn \"thaw\";\n\tcase PM_EVENT_RESTORE:\n\t\treturn \"restore\";\n\tcase PM_EVENT_RECOVER:\n\t\treturn \"recover\";\n\tdefault:\n\t\treturn \"(unknown PM event)\";\n\t}\n}\n\n \nvoid device_pm_sleep_init(struct device *dev)\n{\n\tdev->power.is_prepared = false;\n\tdev->power.is_suspended = false;\n\tdev->power.is_noirq_suspended = false;\n\tdev->power.is_late_suspended = false;\n\tinit_completion(&dev->power.completion);\n\tcomplete_all(&dev->power.completion);\n\tdev->power.wakeup = NULL;\n\tINIT_LIST_HEAD(&dev->power.entry);\n}\n\n \nvoid device_pm_lock(void)\n{\n\tmutex_lock(&dpm_list_mtx);\n}\n\n \nvoid device_pm_unlock(void)\n{\n\tmutex_unlock(&dpm_list_mtx);\n}\n\n \nvoid device_pm_add(struct device *dev)\n{\n\t \n\tif (device_pm_not_required(dev))\n\t\treturn;\n\n\tpr_debug(\"Adding info for %s:%s\\n\",\n\t\t dev->bus ? dev->bus->name : \"No Bus\", dev_name(dev));\n\tdevice_pm_check_callbacks(dev);\n\tmutex_lock(&dpm_list_mtx);\n\tif (dev->parent && dev->parent->power.is_prepared)\n\t\tdev_warn(dev, \"parent %s should not be sleeping\\n\",\n\t\t\tdev_name(dev->parent));\n\tlist_add_tail(&dev->power.entry, &dpm_list);\n\tdev->power.in_dpm_list = true;\n\tmutex_unlock(&dpm_list_mtx);\n}\n\n \nvoid device_pm_remove(struct device *dev)\n{\n\tif (device_pm_not_required(dev))\n\t\treturn;\n\n\tpr_debug(\"Removing info for %s:%s\\n\",\n\t\t dev->bus ? dev->bus->name : \"No Bus\", dev_name(dev));\n\tcomplete_all(&dev->power.completion);\n\tmutex_lock(&dpm_list_mtx);\n\tlist_del_init(&dev->power.entry);\n\tdev->power.in_dpm_list = false;\n\tmutex_unlock(&dpm_list_mtx);\n\tdevice_wakeup_disable(dev);\n\tpm_runtime_remove(dev);\n\tdevice_pm_check_callbacks(dev);\n}\n\n \nvoid device_pm_move_before(struct device *deva, struct device *devb)\n{\n\tpr_debug(\"Moving %s:%s before %s:%s\\n\",\n\t\t deva->bus ? deva->bus->name : \"No Bus\", dev_name(deva),\n\t\t devb->bus ? devb->bus->name : \"No Bus\", dev_name(devb));\n\t \n\tlist_move_tail(&deva->power.entry, &devb->power.entry);\n}\n\n \nvoid device_pm_move_after(struct device *deva, struct device *devb)\n{\n\tpr_debug(\"Moving %s:%s after %s:%s\\n\",\n\t\t deva->bus ? deva->bus->name : \"No Bus\", dev_name(deva),\n\t\t devb->bus ? devb->bus->name : \"No Bus\", dev_name(devb));\n\t \n\tlist_move(&deva->power.entry, &devb->power.entry);\n}\n\n \nvoid device_pm_move_last(struct device *dev)\n{\n\tpr_debug(\"Moving %s:%s to end of list\\n\",\n\t\t dev->bus ? dev->bus->name : \"No Bus\", dev_name(dev));\n\tlist_move_tail(&dev->power.entry, &dpm_list);\n}\n\nstatic ktime_t initcall_debug_start(struct device *dev, void *cb)\n{\n\tif (!pm_print_times_enabled)\n\t\treturn 0;\n\n\tdev_info(dev, \"calling %pS @ %i, parent: %s\\n\", cb,\n\t\t task_pid_nr(current),\n\t\t dev->parent ? dev_name(dev->parent) : \"none\");\n\treturn ktime_get();\n}\n\nstatic void initcall_debug_report(struct device *dev, ktime_t calltime,\n\t\t\t\t  void *cb, int error)\n{\n\tktime_t rettime;\n\n\tif (!pm_print_times_enabled)\n\t\treturn;\n\n\trettime = ktime_get();\n\tdev_info(dev, \"%pS returned %d after %Ld usecs\\n\", cb, error,\n\t\t (unsigned long long)ktime_us_delta(rettime, calltime));\n}\n\n \nstatic void dpm_wait(struct device *dev, bool async)\n{\n\tif (!dev)\n\t\treturn;\n\n\tif (async || (pm_async_enabled && dev->power.async_suspend))\n\t\twait_for_completion(&dev->power.completion);\n}\n\nstatic int dpm_wait_fn(struct device *dev, void *async_ptr)\n{\n\tdpm_wait(dev, *((bool *)async_ptr));\n\treturn 0;\n}\n\nstatic void dpm_wait_for_children(struct device *dev, bool async)\n{\n       device_for_each_child(dev, &async, dpm_wait_fn);\n}\n\nstatic void dpm_wait_for_suppliers(struct device *dev, bool async)\n{\n\tstruct device_link *link;\n\tint idx;\n\n\tidx = device_links_read_lock();\n\n\t \n\tlist_for_each_entry_rcu_locked(link, &dev->links.suppliers, c_node)\n\t\tif (READ_ONCE(link->status) != DL_STATE_DORMANT)\n\t\t\tdpm_wait(link->supplier, async);\n\n\tdevice_links_read_unlock(idx);\n}\n\nstatic bool dpm_wait_for_superior(struct device *dev, bool async)\n{\n\tstruct device *parent;\n\n\t \n\tmutex_lock(&dpm_list_mtx);\n\n\tif (!device_pm_initialized(dev)) {\n\t\tmutex_unlock(&dpm_list_mtx);\n\t\treturn false;\n\t}\n\n\tparent = get_device(dev->parent);\n\n\tmutex_unlock(&dpm_list_mtx);\n\n\tdpm_wait(parent, async);\n\tput_device(parent);\n\n\tdpm_wait_for_suppliers(dev, async);\n\n\t \n\treturn device_pm_initialized(dev);\n}\n\nstatic void dpm_wait_for_consumers(struct device *dev, bool async)\n{\n\tstruct device_link *link;\n\tint idx;\n\n\tidx = device_links_read_lock();\n\n\t \n\tlist_for_each_entry_rcu_locked(link, &dev->links.consumers, s_node)\n\t\tif (READ_ONCE(link->status) != DL_STATE_DORMANT)\n\t\t\tdpm_wait(link->consumer, async);\n\n\tdevice_links_read_unlock(idx);\n}\n\nstatic void dpm_wait_for_subordinate(struct device *dev, bool async)\n{\n\tdpm_wait_for_children(dev, async);\n\tdpm_wait_for_consumers(dev, async);\n}\n\n \nstatic pm_callback_t pm_op(const struct dev_pm_ops *ops, pm_message_t state)\n{\n\tswitch (state.event) {\n#ifdef CONFIG_SUSPEND\n\tcase PM_EVENT_SUSPEND:\n\t\treturn ops->suspend;\n\tcase PM_EVENT_RESUME:\n\t\treturn ops->resume;\n#endif  \n#ifdef CONFIG_HIBERNATE_CALLBACKS\n\tcase PM_EVENT_FREEZE:\n\tcase PM_EVENT_QUIESCE:\n\t\treturn ops->freeze;\n\tcase PM_EVENT_HIBERNATE:\n\t\treturn ops->poweroff;\n\tcase PM_EVENT_THAW:\n\tcase PM_EVENT_RECOVER:\n\t\treturn ops->thaw;\n\tcase PM_EVENT_RESTORE:\n\t\treturn ops->restore;\n#endif  \n\t}\n\n\treturn NULL;\n}\n\n \nstatic pm_callback_t pm_late_early_op(const struct dev_pm_ops *ops,\n\t\t\t\t      pm_message_t state)\n{\n\tswitch (state.event) {\n#ifdef CONFIG_SUSPEND\n\tcase PM_EVENT_SUSPEND:\n\t\treturn ops->suspend_late;\n\tcase PM_EVENT_RESUME:\n\t\treturn ops->resume_early;\n#endif  \n#ifdef CONFIG_HIBERNATE_CALLBACKS\n\tcase PM_EVENT_FREEZE:\n\tcase PM_EVENT_QUIESCE:\n\t\treturn ops->freeze_late;\n\tcase PM_EVENT_HIBERNATE:\n\t\treturn ops->poweroff_late;\n\tcase PM_EVENT_THAW:\n\tcase PM_EVENT_RECOVER:\n\t\treturn ops->thaw_early;\n\tcase PM_EVENT_RESTORE:\n\t\treturn ops->restore_early;\n#endif  \n\t}\n\n\treturn NULL;\n}\n\n \nstatic pm_callback_t pm_noirq_op(const struct dev_pm_ops *ops, pm_message_t state)\n{\n\tswitch (state.event) {\n#ifdef CONFIG_SUSPEND\n\tcase PM_EVENT_SUSPEND:\n\t\treturn ops->suspend_noirq;\n\tcase PM_EVENT_RESUME:\n\t\treturn ops->resume_noirq;\n#endif  \n#ifdef CONFIG_HIBERNATE_CALLBACKS\n\tcase PM_EVENT_FREEZE:\n\tcase PM_EVENT_QUIESCE:\n\t\treturn ops->freeze_noirq;\n\tcase PM_EVENT_HIBERNATE:\n\t\treturn ops->poweroff_noirq;\n\tcase PM_EVENT_THAW:\n\tcase PM_EVENT_RECOVER:\n\t\treturn ops->thaw_noirq;\n\tcase PM_EVENT_RESTORE:\n\t\treturn ops->restore_noirq;\n#endif  \n\t}\n\n\treturn NULL;\n}\n\nstatic void pm_dev_dbg(struct device *dev, pm_message_t state, const char *info)\n{\n\tdev_dbg(dev, \"%s%s%s driver flags: %x\\n\", info, pm_verb(state.event),\n\t\t((state.event & PM_EVENT_SLEEP) && device_may_wakeup(dev)) ?\n\t\t\", may wakeup\" : \"\", dev->power.driver_flags);\n}\n\nstatic void pm_dev_err(struct device *dev, pm_message_t state, const char *info,\n\t\t\tint error)\n{\n\tdev_err(dev, \"failed to %s%s: error %d\\n\", pm_verb(state.event), info,\n\t\terror);\n}\n\nstatic void dpm_show_time(ktime_t starttime, pm_message_t state, int error,\n\t\t\t  const char *info)\n{\n\tktime_t calltime;\n\tu64 usecs64;\n\tint usecs;\n\n\tcalltime = ktime_get();\n\tusecs64 = ktime_to_ns(ktime_sub(calltime, starttime));\n\tdo_div(usecs64, NSEC_PER_USEC);\n\tusecs = usecs64;\n\tif (usecs == 0)\n\t\tusecs = 1;\n\n\tpm_pr_dbg(\"%s%s%s of devices %s after %ld.%03ld msecs\\n\",\n\t\t  info ?: \"\", info ? \" \" : \"\", pm_verb(state.event),\n\t\t  error ? \"aborted\" : \"complete\",\n\t\t  usecs / USEC_PER_MSEC, usecs % USEC_PER_MSEC);\n}\n\nstatic int dpm_run_callback(pm_callback_t cb, struct device *dev,\n\t\t\t    pm_message_t state, const char *info)\n{\n\tktime_t calltime;\n\tint error;\n\n\tif (!cb)\n\t\treturn 0;\n\n\tcalltime = initcall_debug_start(dev, cb);\n\n\tpm_dev_dbg(dev, state, info);\n\ttrace_device_pm_callback_start(dev, info, state.event);\n\terror = cb(dev);\n\ttrace_device_pm_callback_end(dev, error);\n\tsuspend_report_result(dev, cb, error);\n\n\tinitcall_debug_report(dev, calltime, cb, error);\n\n\treturn error;\n}\n\n#ifdef CONFIG_DPM_WATCHDOG\nstruct dpm_watchdog {\n\tstruct device\t\t*dev;\n\tstruct task_struct\t*tsk;\n\tstruct timer_list\ttimer;\n};\n\n#define DECLARE_DPM_WATCHDOG_ON_STACK(wd) \\\n\tstruct dpm_watchdog wd\n\n \nstatic void dpm_watchdog_handler(struct timer_list *t)\n{\n\tstruct dpm_watchdog *wd = from_timer(wd, t, timer);\n\n\tdev_emerg(wd->dev, \"**** DPM device timeout ****\\n\");\n\tshow_stack(wd->tsk, NULL, KERN_EMERG);\n\tpanic(\"%s %s: unrecoverable failure\\n\",\n\t\tdev_driver_string(wd->dev), dev_name(wd->dev));\n}\n\n \nstatic void dpm_watchdog_set(struct dpm_watchdog *wd, struct device *dev)\n{\n\tstruct timer_list *timer = &wd->timer;\n\n\twd->dev = dev;\n\twd->tsk = current;\n\n\ttimer_setup_on_stack(timer, dpm_watchdog_handler, 0);\n\t \n\ttimer->expires = jiffies + HZ * CONFIG_DPM_WATCHDOG_TIMEOUT;\n\tadd_timer(timer);\n}\n\n \nstatic void dpm_watchdog_clear(struct dpm_watchdog *wd)\n{\n\tstruct timer_list *timer = &wd->timer;\n\n\tdel_timer_sync(timer);\n\tdestroy_timer_on_stack(timer);\n}\n#else\n#define DECLARE_DPM_WATCHDOG_ON_STACK(wd)\n#define dpm_watchdog_set(x, y)\n#define dpm_watchdog_clear(x)\n#endif\n\n \n\n \nbool dev_pm_skip_resume(struct device *dev)\n{\n\tif (pm_transition.event == PM_EVENT_RESTORE)\n\t\treturn false;\n\n\tif (pm_transition.event == PM_EVENT_THAW)\n\t\treturn dev_pm_skip_suspend(dev);\n\n\treturn !dev->power.must_resume;\n}\n\n \nstatic int device_resume_noirq(struct device *dev, pm_message_t state, bool async)\n{\n\tpm_callback_t callback = NULL;\n\tconst char *info = NULL;\n\tbool skip_resume;\n\tint error = 0;\n\n\tTRACE_DEVICE(dev);\n\tTRACE_RESUME(0);\n\n\tif (dev->power.syscore || dev->power.direct_complete)\n\t\tgoto Out;\n\n\tif (!dev->power.is_noirq_suspended)\n\t\tgoto Out;\n\n\tif (!dpm_wait_for_superior(dev, async))\n\t\tgoto Out;\n\n\tskip_resume = dev_pm_skip_resume(dev);\n\t \n\tif (skip_resume)\n\t\tpm_runtime_set_suspended(dev);\n\telse if (dev_pm_skip_suspend(dev))\n\t\tpm_runtime_set_active(dev);\n\n\tif (dev->pm_domain) {\n\t\tinfo = \"noirq power domain \";\n\t\tcallback = pm_noirq_op(&dev->pm_domain->ops, state);\n\t} else if (dev->type && dev->type->pm) {\n\t\tinfo = \"noirq type \";\n\t\tcallback = pm_noirq_op(dev->type->pm, state);\n\t} else if (dev->class && dev->class->pm) {\n\t\tinfo = \"noirq class \";\n\t\tcallback = pm_noirq_op(dev->class->pm, state);\n\t} else if (dev->bus && dev->bus->pm) {\n\t\tinfo = \"noirq bus \";\n\t\tcallback = pm_noirq_op(dev->bus->pm, state);\n\t}\n\tif (callback)\n\t\tgoto Run;\n\n\tif (skip_resume)\n\t\tgoto Skip;\n\n\tif (dev->driver && dev->driver->pm) {\n\t\tinfo = \"noirq driver \";\n\t\tcallback = pm_noirq_op(dev->driver->pm, state);\n\t}\n\nRun:\n\terror = dpm_run_callback(callback, dev, state, info);\n\nSkip:\n\tdev->power.is_noirq_suspended = false;\n\nOut:\n\tcomplete_all(&dev->power.completion);\n\tTRACE_RESUME(error);\n\treturn error;\n}\n\nstatic bool is_async(struct device *dev)\n{\n\treturn dev->power.async_suspend && pm_async_enabled\n\t\t&& !pm_trace_is_enabled();\n}\n\nstatic bool dpm_async_fn(struct device *dev, async_func_t func)\n{\n\treinit_completion(&dev->power.completion);\n\n\tif (is_async(dev)) {\n\t\tget_device(dev);\n\t\tasync_schedule_dev(func, dev);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void async_resume_noirq(void *data, async_cookie_t cookie)\n{\n\tstruct device *dev = data;\n\tint error;\n\n\terror = device_resume_noirq(dev, pm_transition, true);\n\tif (error)\n\t\tpm_dev_err(dev, pm_transition, \" async\", error);\n\n\tput_device(dev);\n}\n\nstatic void dpm_noirq_resume_devices(pm_message_t state)\n{\n\tstruct device *dev;\n\tktime_t starttime = ktime_get();\n\n\ttrace_suspend_resume(TPS(\"dpm_resume_noirq\"), state.event, true);\n\tmutex_lock(&dpm_list_mtx);\n\tpm_transition = state;\n\n\t \n\tlist_for_each_entry(dev, &dpm_noirq_list, power.entry)\n\t\tdpm_async_fn(dev, async_resume_noirq);\n\n\twhile (!list_empty(&dpm_noirq_list)) {\n\t\tdev = to_device(dpm_noirq_list.next);\n\t\tget_device(dev);\n\t\tlist_move_tail(&dev->power.entry, &dpm_late_early_list);\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\tif (!is_async(dev)) {\n\t\t\tint error;\n\n\t\t\terror = device_resume_noirq(dev, state, false);\n\t\t\tif (error) {\n\t\t\t\tsuspend_stats.failed_resume_noirq++;\n\t\t\t\tdpm_save_failed_step(SUSPEND_RESUME_NOIRQ);\n\t\t\t\tdpm_save_failed_dev(dev_name(dev));\n\t\t\t\tpm_dev_err(dev, state, \" noirq\", error);\n\t\t\t}\n\t\t}\n\n\t\tput_device(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\t}\n\tmutex_unlock(&dpm_list_mtx);\n\tasync_synchronize_full();\n\tdpm_show_time(starttime, state, 0, \"noirq\");\n\ttrace_suspend_resume(TPS(\"dpm_resume_noirq\"), state.event, false);\n}\n\n \nvoid dpm_resume_noirq(pm_message_t state)\n{\n\tdpm_noirq_resume_devices(state);\n\n\tresume_device_irqs();\n\tdevice_wakeup_disarm_wake_irqs();\n}\n\n \nstatic int device_resume_early(struct device *dev, pm_message_t state, bool async)\n{\n\tpm_callback_t callback = NULL;\n\tconst char *info = NULL;\n\tint error = 0;\n\n\tTRACE_DEVICE(dev);\n\tTRACE_RESUME(0);\n\n\tif (dev->power.syscore || dev->power.direct_complete)\n\t\tgoto Out;\n\n\tif (!dev->power.is_late_suspended)\n\t\tgoto Out;\n\n\tif (!dpm_wait_for_superior(dev, async))\n\t\tgoto Out;\n\n\tif (dev->pm_domain) {\n\t\tinfo = \"early power domain \";\n\t\tcallback = pm_late_early_op(&dev->pm_domain->ops, state);\n\t} else if (dev->type && dev->type->pm) {\n\t\tinfo = \"early type \";\n\t\tcallback = pm_late_early_op(dev->type->pm, state);\n\t} else if (dev->class && dev->class->pm) {\n\t\tinfo = \"early class \";\n\t\tcallback = pm_late_early_op(dev->class->pm, state);\n\t} else if (dev->bus && dev->bus->pm) {\n\t\tinfo = \"early bus \";\n\t\tcallback = pm_late_early_op(dev->bus->pm, state);\n\t}\n\tif (callback)\n\t\tgoto Run;\n\n\tif (dev_pm_skip_resume(dev))\n\t\tgoto Skip;\n\n\tif (dev->driver && dev->driver->pm) {\n\t\tinfo = \"early driver \";\n\t\tcallback = pm_late_early_op(dev->driver->pm, state);\n\t}\n\nRun:\n\terror = dpm_run_callback(callback, dev, state, info);\n\nSkip:\n\tdev->power.is_late_suspended = false;\n\nOut:\n\tTRACE_RESUME(error);\n\n\tpm_runtime_enable(dev);\n\tcomplete_all(&dev->power.completion);\n\treturn error;\n}\n\nstatic void async_resume_early(void *data, async_cookie_t cookie)\n{\n\tstruct device *dev = data;\n\tint error;\n\n\terror = device_resume_early(dev, pm_transition, true);\n\tif (error)\n\t\tpm_dev_err(dev, pm_transition, \" async\", error);\n\n\tput_device(dev);\n}\n\n \nvoid dpm_resume_early(pm_message_t state)\n{\n\tstruct device *dev;\n\tktime_t starttime = ktime_get();\n\n\ttrace_suspend_resume(TPS(\"dpm_resume_early\"), state.event, true);\n\tmutex_lock(&dpm_list_mtx);\n\tpm_transition = state;\n\n\t \n\tlist_for_each_entry(dev, &dpm_late_early_list, power.entry)\n\t\tdpm_async_fn(dev, async_resume_early);\n\n\twhile (!list_empty(&dpm_late_early_list)) {\n\t\tdev = to_device(dpm_late_early_list.next);\n\t\tget_device(dev);\n\t\tlist_move_tail(&dev->power.entry, &dpm_suspended_list);\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\tif (!is_async(dev)) {\n\t\t\tint error;\n\n\t\t\terror = device_resume_early(dev, state, false);\n\t\t\tif (error) {\n\t\t\t\tsuspend_stats.failed_resume_early++;\n\t\t\t\tdpm_save_failed_step(SUSPEND_RESUME_EARLY);\n\t\t\t\tdpm_save_failed_dev(dev_name(dev));\n\t\t\t\tpm_dev_err(dev, state, \" early\", error);\n\t\t\t}\n\t\t}\n\n\t\tput_device(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\t}\n\tmutex_unlock(&dpm_list_mtx);\n\tasync_synchronize_full();\n\tdpm_show_time(starttime, state, 0, \"early\");\n\ttrace_suspend_resume(TPS(\"dpm_resume_early\"), state.event, false);\n}\n\n \nvoid dpm_resume_start(pm_message_t state)\n{\n\tdpm_resume_noirq(state);\n\tdpm_resume_early(state);\n}\nEXPORT_SYMBOL_GPL(dpm_resume_start);\n\n \nstatic int device_resume(struct device *dev, pm_message_t state, bool async)\n{\n\tpm_callback_t callback = NULL;\n\tconst char *info = NULL;\n\tint error = 0;\n\tDECLARE_DPM_WATCHDOG_ON_STACK(wd);\n\n\tTRACE_DEVICE(dev);\n\tTRACE_RESUME(0);\n\n\tif (dev->power.syscore)\n\t\tgoto Complete;\n\n\tif (dev->power.direct_complete) {\n\t\t \n\t\tpm_runtime_enable(dev);\n\t\tgoto Complete;\n\t}\n\n\tif (!dpm_wait_for_superior(dev, async))\n\t\tgoto Complete;\n\n\tdpm_watchdog_set(&wd, dev);\n\tdevice_lock(dev);\n\n\t \n\tdev->power.is_prepared = false;\n\n\tif (!dev->power.is_suspended)\n\t\tgoto Unlock;\n\n\tif (dev->pm_domain) {\n\t\tinfo = \"power domain \";\n\t\tcallback = pm_op(&dev->pm_domain->ops, state);\n\t\tgoto Driver;\n\t}\n\n\tif (dev->type && dev->type->pm) {\n\t\tinfo = \"type \";\n\t\tcallback = pm_op(dev->type->pm, state);\n\t\tgoto Driver;\n\t}\n\n\tif (dev->class && dev->class->pm) {\n\t\tinfo = \"class \";\n\t\tcallback = pm_op(dev->class->pm, state);\n\t\tgoto Driver;\n\t}\n\n\tif (dev->bus) {\n\t\tif (dev->bus->pm) {\n\t\t\tinfo = \"bus \";\n\t\t\tcallback = pm_op(dev->bus->pm, state);\n\t\t} else if (dev->bus->resume) {\n\t\t\tinfo = \"legacy bus \";\n\t\t\tcallback = dev->bus->resume;\n\t\t\tgoto End;\n\t\t}\n\t}\n\n Driver:\n\tif (!callback && dev->driver && dev->driver->pm) {\n\t\tinfo = \"driver \";\n\t\tcallback = pm_op(dev->driver->pm, state);\n\t}\n\n End:\n\terror = dpm_run_callback(callback, dev, state, info);\n\tdev->power.is_suspended = false;\n\n Unlock:\n\tdevice_unlock(dev);\n\tdpm_watchdog_clear(&wd);\n\n Complete:\n\tcomplete_all(&dev->power.completion);\n\n\tTRACE_RESUME(error);\n\n\treturn error;\n}\n\nstatic void async_resume(void *data, async_cookie_t cookie)\n{\n\tstruct device *dev = data;\n\tint error;\n\n\terror = device_resume(dev, pm_transition, true);\n\tif (error)\n\t\tpm_dev_err(dev, pm_transition, \" async\", error);\n\tput_device(dev);\n}\n\n \nvoid dpm_resume(pm_message_t state)\n{\n\tstruct device *dev;\n\tktime_t starttime = ktime_get();\n\n\ttrace_suspend_resume(TPS(\"dpm_resume\"), state.event, true);\n\tmight_sleep();\n\n\tmutex_lock(&dpm_list_mtx);\n\tpm_transition = state;\n\tasync_error = 0;\n\n\tlist_for_each_entry(dev, &dpm_suspended_list, power.entry)\n\t\tdpm_async_fn(dev, async_resume);\n\n\twhile (!list_empty(&dpm_suspended_list)) {\n\t\tdev = to_device(dpm_suspended_list.next);\n\t\tget_device(dev);\n\t\tif (!is_async(dev)) {\n\t\t\tint error;\n\n\t\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\t\terror = device_resume(dev, state, false);\n\t\t\tif (error) {\n\t\t\t\tsuspend_stats.failed_resume++;\n\t\t\t\tdpm_save_failed_step(SUSPEND_RESUME);\n\t\t\t\tdpm_save_failed_dev(dev_name(dev));\n\t\t\t\tpm_dev_err(dev, state, \"\", error);\n\t\t\t}\n\n\t\t\tmutex_lock(&dpm_list_mtx);\n\t\t}\n\t\tif (!list_empty(&dev->power.entry))\n\t\t\tlist_move_tail(&dev->power.entry, &dpm_prepared_list);\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\tput_device(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\t}\n\tmutex_unlock(&dpm_list_mtx);\n\tasync_synchronize_full();\n\tdpm_show_time(starttime, state, 0, NULL);\n\n\tcpufreq_resume();\n\tdevfreq_resume();\n\ttrace_suspend_resume(TPS(\"dpm_resume\"), state.event, false);\n}\n\n \nstatic void device_complete(struct device *dev, pm_message_t state)\n{\n\tvoid (*callback)(struct device *) = NULL;\n\tconst char *info = NULL;\n\n\tif (dev->power.syscore)\n\t\tgoto out;\n\n\tdevice_lock(dev);\n\n\tif (dev->pm_domain) {\n\t\tinfo = \"completing power domain \";\n\t\tcallback = dev->pm_domain->ops.complete;\n\t} else if (dev->type && dev->type->pm) {\n\t\tinfo = \"completing type \";\n\t\tcallback = dev->type->pm->complete;\n\t} else if (dev->class && dev->class->pm) {\n\t\tinfo = \"completing class \";\n\t\tcallback = dev->class->pm->complete;\n\t} else if (dev->bus && dev->bus->pm) {\n\t\tinfo = \"completing bus \";\n\t\tcallback = dev->bus->pm->complete;\n\t}\n\n\tif (!callback && dev->driver && dev->driver->pm) {\n\t\tinfo = \"completing driver \";\n\t\tcallback = dev->driver->pm->complete;\n\t}\n\n\tif (callback) {\n\t\tpm_dev_dbg(dev, state, info);\n\t\tcallback(dev);\n\t}\n\n\tdevice_unlock(dev);\n\nout:\n\tpm_runtime_put(dev);\n}\n\n \nvoid dpm_complete(pm_message_t state)\n{\n\tstruct list_head list;\n\n\ttrace_suspend_resume(TPS(\"dpm_complete\"), state.event, true);\n\tmight_sleep();\n\n\tINIT_LIST_HEAD(&list);\n\tmutex_lock(&dpm_list_mtx);\n\twhile (!list_empty(&dpm_prepared_list)) {\n\t\tstruct device *dev = to_device(dpm_prepared_list.prev);\n\n\t\tget_device(dev);\n\t\tdev->power.is_prepared = false;\n\t\tlist_move(&dev->power.entry, &list);\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\ttrace_device_pm_callback_start(dev, \"\", state.event);\n\t\tdevice_complete(dev, state);\n\t\ttrace_device_pm_callback_end(dev, 0);\n\n\t\tput_device(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\t}\n\tlist_splice(&list, &dpm_list);\n\tmutex_unlock(&dpm_list_mtx);\n\n\t \n\tdevice_unblock_probing();\n\ttrace_suspend_resume(TPS(\"dpm_complete\"), state.event, false);\n}\n\n \nvoid dpm_resume_end(pm_message_t state)\n{\n\tdpm_resume(state);\n\tdpm_complete(state);\n}\nEXPORT_SYMBOL_GPL(dpm_resume_end);\n\n\n \n\n \nstatic pm_message_t resume_event(pm_message_t sleep_state)\n{\n\tswitch (sleep_state.event) {\n\tcase PM_EVENT_SUSPEND:\n\t\treturn PMSG_RESUME;\n\tcase PM_EVENT_FREEZE:\n\tcase PM_EVENT_QUIESCE:\n\t\treturn PMSG_RECOVER;\n\tcase PM_EVENT_HIBERNATE:\n\t\treturn PMSG_RESTORE;\n\t}\n\treturn PMSG_ON;\n}\n\nstatic void dpm_superior_set_must_resume(struct device *dev)\n{\n\tstruct device_link *link;\n\tint idx;\n\n\tif (dev->parent)\n\t\tdev->parent->power.must_resume = true;\n\n\tidx = device_links_read_lock();\n\n\tlist_for_each_entry_rcu_locked(link, &dev->links.suppliers, c_node)\n\t\tlink->supplier->power.must_resume = true;\n\n\tdevice_links_read_unlock(idx);\n}\n\n \nstatic int __device_suspend_noirq(struct device *dev, pm_message_t state, bool async)\n{\n\tpm_callback_t callback = NULL;\n\tconst char *info = NULL;\n\tint error = 0;\n\n\tTRACE_DEVICE(dev);\n\tTRACE_SUSPEND(0);\n\n\tdpm_wait_for_subordinate(dev, async);\n\n\tif (async_error)\n\t\tgoto Complete;\n\n\tif (dev->power.syscore || dev->power.direct_complete)\n\t\tgoto Complete;\n\n\tif (dev->pm_domain) {\n\t\tinfo = \"noirq power domain \";\n\t\tcallback = pm_noirq_op(&dev->pm_domain->ops, state);\n\t} else if (dev->type && dev->type->pm) {\n\t\tinfo = \"noirq type \";\n\t\tcallback = pm_noirq_op(dev->type->pm, state);\n\t} else if (dev->class && dev->class->pm) {\n\t\tinfo = \"noirq class \";\n\t\tcallback = pm_noirq_op(dev->class->pm, state);\n\t} else if (dev->bus && dev->bus->pm) {\n\t\tinfo = \"noirq bus \";\n\t\tcallback = pm_noirq_op(dev->bus->pm, state);\n\t}\n\tif (callback)\n\t\tgoto Run;\n\n\tif (dev_pm_skip_suspend(dev))\n\t\tgoto Skip;\n\n\tif (dev->driver && dev->driver->pm) {\n\t\tinfo = \"noirq driver \";\n\t\tcallback = pm_noirq_op(dev->driver->pm, state);\n\t}\n\nRun:\n\terror = dpm_run_callback(callback, dev, state, info);\n\tif (error) {\n\t\tasync_error = error;\n\t\tgoto Complete;\n\t}\n\nSkip:\n\tdev->power.is_noirq_suspended = true;\n\n\t \n\tif (atomic_read(&dev->power.usage_count) > 1 ||\n\t    !(dev_pm_test_driver_flags(dev, DPM_FLAG_MAY_SKIP_RESUME) &&\n\t      dev->power.may_skip_resume))\n\t\tdev->power.must_resume = true;\n\n\tif (dev->power.must_resume)\n\t\tdpm_superior_set_must_resume(dev);\n\nComplete:\n\tcomplete_all(&dev->power.completion);\n\tTRACE_SUSPEND(error);\n\treturn error;\n}\n\nstatic void async_suspend_noirq(void *data, async_cookie_t cookie)\n{\n\tstruct device *dev = data;\n\tint error;\n\n\terror = __device_suspend_noirq(dev, pm_transition, true);\n\tif (error) {\n\t\tdpm_save_failed_dev(dev_name(dev));\n\t\tpm_dev_err(dev, pm_transition, \" async\", error);\n\t}\n\n\tput_device(dev);\n}\n\nstatic int device_suspend_noirq(struct device *dev)\n{\n\tif (dpm_async_fn(dev, async_suspend_noirq))\n\t\treturn 0;\n\n\treturn __device_suspend_noirq(dev, pm_transition, false);\n}\n\nstatic int dpm_noirq_suspend_devices(pm_message_t state)\n{\n\tktime_t starttime = ktime_get();\n\tint error = 0;\n\n\ttrace_suspend_resume(TPS(\"dpm_suspend_noirq\"), state.event, true);\n\tmutex_lock(&dpm_list_mtx);\n\tpm_transition = state;\n\tasync_error = 0;\n\n\twhile (!list_empty(&dpm_late_early_list)) {\n\t\tstruct device *dev = to_device(dpm_late_early_list.prev);\n\n\t\tget_device(dev);\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\terror = device_suspend_noirq(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\n\t\tif (error) {\n\t\t\tpm_dev_err(dev, state, \" noirq\", error);\n\t\t\tdpm_save_failed_dev(dev_name(dev));\n\t\t} else if (!list_empty(&dev->power.entry)) {\n\t\t\tlist_move(&dev->power.entry, &dpm_noirq_list);\n\t\t}\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\tput_device(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\n\t\tif (error || async_error)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(&dpm_list_mtx);\n\tasync_synchronize_full();\n\tif (!error)\n\t\terror = async_error;\n\n\tif (error) {\n\t\tsuspend_stats.failed_suspend_noirq++;\n\t\tdpm_save_failed_step(SUSPEND_SUSPEND_NOIRQ);\n\t}\n\tdpm_show_time(starttime, state, error, \"noirq\");\n\ttrace_suspend_resume(TPS(\"dpm_suspend_noirq\"), state.event, false);\n\treturn error;\n}\n\n \nint dpm_suspend_noirq(pm_message_t state)\n{\n\tint ret;\n\n\tdevice_wakeup_arm_wake_irqs();\n\tsuspend_device_irqs();\n\n\tret = dpm_noirq_suspend_devices(state);\n\tif (ret)\n\t\tdpm_resume_noirq(resume_event(state));\n\n\treturn ret;\n}\n\nstatic void dpm_propagate_wakeup_to_parent(struct device *dev)\n{\n\tstruct device *parent = dev->parent;\n\n\tif (!parent)\n\t\treturn;\n\n\tspin_lock_irq(&parent->power.lock);\n\n\tif (device_wakeup_path(dev) && !parent->power.ignore_children)\n\t\tparent->power.wakeup_path = true;\n\n\tspin_unlock_irq(&parent->power.lock);\n}\n\n \nstatic int __device_suspend_late(struct device *dev, pm_message_t state, bool async)\n{\n\tpm_callback_t callback = NULL;\n\tconst char *info = NULL;\n\tint error = 0;\n\n\tTRACE_DEVICE(dev);\n\tTRACE_SUSPEND(0);\n\n\t__pm_runtime_disable(dev, false);\n\n\tdpm_wait_for_subordinate(dev, async);\n\n\tif (async_error)\n\t\tgoto Complete;\n\n\tif (pm_wakeup_pending()) {\n\t\tasync_error = -EBUSY;\n\t\tgoto Complete;\n\t}\n\n\tif (dev->power.syscore || dev->power.direct_complete)\n\t\tgoto Complete;\n\n\tif (dev->pm_domain) {\n\t\tinfo = \"late power domain \";\n\t\tcallback = pm_late_early_op(&dev->pm_domain->ops, state);\n\t} else if (dev->type && dev->type->pm) {\n\t\tinfo = \"late type \";\n\t\tcallback = pm_late_early_op(dev->type->pm, state);\n\t} else if (dev->class && dev->class->pm) {\n\t\tinfo = \"late class \";\n\t\tcallback = pm_late_early_op(dev->class->pm, state);\n\t} else if (dev->bus && dev->bus->pm) {\n\t\tinfo = \"late bus \";\n\t\tcallback = pm_late_early_op(dev->bus->pm, state);\n\t}\n\tif (callback)\n\t\tgoto Run;\n\n\tif (dev_pm_skip_suspend(dev))\n\t\tgoto Skip;\n\n\tif (dev->driver && dev->driver->pm) {\n\t\tinfo = \"late driver \";\n\t\tcallback = pm_late_early_op(dev->driver->pm, state);\n\t}\n\nRun:\n\terror = dpm_run_callback(callback, dev, state, info);\n\tif (error) {\n\t\tasync_error = error;\n\t\tgoto Complete;\n\t}\n\tdpm_propagate_wakeup_to_parent(dev);\n\nSkip:\n\tdev->power.is_late_suspended = true;\n\nComplete:\n\tTRACE_SUSPEND(error);\n\tcomplete_all(&dev->power.completion);\n\treturn error;\n}\n\nstatic void async_suspend_late(void *data, async_cookie_t cookie)\n{\n\tstruct device *dev = data;\n\tint error;\n\n\terror = __device_suspend_late(dev, pm_transition, true);\n\tif (error) {\n\t\tdpm_save_failed_dev(dev_name(dev));\n\t\tpm_dev_err(dev, pm_transition, \" async\", error);\n\t}\n\tput_device(dev);\n}\n\nstatic int device_suspend_late(struct device *dev)\n{\n\tif (dpm_async_fn(dev, async_suspend_late))\n\t\treturn 0;\n\n\treturn __device_suspend_late(dev, pm_transition, false);\n}\n\n \nint dpm_suspend_late(pm_message_t state)\n{\n\tktime_t starttime = ktime_get();\n\tint error = 0;\n\n\ttrace_suspend_resume(TPS(\"dpm_suspend_late\"), state.event, true);\n\twake_up_all_idle_cpus();\n\tmutex_lock(&dpm_list_mtx);\n\tpm_transition = state;\n\tasync_error = 0;\n\n\twhile (!list_empty(&dpm_suspended_list)) {\n\t\tstruct device *dev = to_device(dpm_suspended_list.prev);\n\n\t\tget_device(dev);\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\terror = device_suspend_late(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\n\t\tif (!list_empty(&dev->power.entry))\n\t\t\tlist_move(&dev->power.entry, &dpm_late_early_list);\n\n\t\tif (error) {\n\t\t\tpm_dev_err(dev, state, \" late\", error);\n\t\t\tdpm_save_failed_dev(dev_name(dev));\n\t\t}\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\tput_device(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\n\t\tif (error || async_error)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(&dpm_list_mtx);\n\tasync_synchronize_full();\n\tif (!error)\n\t\terror = async_error;\n\tif (error) {\n\t\tsuspend_stats.failed_suspend_late++;\n\t\tdpm_save_failed_step(SUSPEND_SUSPEND_LATE);\n\t\tdpm_resume_early(resume_event(state));\n\t}\n\tdpm_show_time(starttime, state, error, \"late\");\n\ttrace_suspend_resume(TPS(\"dpm_suspend_late\"), state.event, false);\n\treturn error;\n}\n\n \nint dpm_suspend_end(pm_message_t state)\n{\n\tktime_t starttime = ktime_get();\n\tint error;\n\n\terror = dpm_suspend_late(state);\n\tif (error)\n\t\tgoto out;\n\n\terror = dpm_suspend_noirq(state);\n\tif (error)\n\t\tdpm_resume_early(resume_event(state));\n\nout:\n\tdpm_show_time(starttime, state, error, \"end\");\n\treturn error;\n}\nEXPORT_SYMBOL_GPL(dpm_suspend_end);\n\n \nstatic int legacy_suspend(struct device *dev, pm_message_t state,\n\t\t\t  int (*cb)(struct device *dev, pm_message_t state),\n\t\t\t  const char *info)\n{\n\tint error;\n\tktime_t calltime;\n\n\tcalltime = initcall_debug_start(dev, cb);\n\n\ttrace_device_pm_callback_start(dev, info, state.event);\n\terror = cb(dev, state);\n\ttrace_device_pm_callback_end(dev, error);\n\tsuspend_report_result(dev, cb, error);\n\n\tinitcall_debug_report(dev, calltime, cb, error);\n\n\treturn error;\n}\n\nstatic void dpm_clear_superiors_direct_complete(struct device *dev)\n{\n\tstruct device_link *link;\n\tint idx;\n\n\tif (dev->parent) {\n\t\tspin_lock_irq(&dev->parent->power.lock);\n\t\tdev->parent->power.direct_complete = false;\n\t\tspin_unlock_irq(&dev->parent->power.lock);\n\t}\n\n\tidx = device_links_read_lock();\n\n\tlist_for_each_entry_rcu_locked(link, &dev->links.suppliers, c_node) {\n\t\tspin_lock_irq(&link->supplier->power.lock);\n\t\tlink->supplier->power.direct_complete = false;\n\t\tspin_unlock_irq(&link->supplier->power.lock);\n\t}\n\n\tdevice_links_read_unlock(idx);\n}\n\n \nstatic int __device_suspend(struct device *dev, pm_message_t state, bool async)\n{\n\tpm_callback_t callback = NULL;\n\tconst char *info = NULL;\n\tint error = 0;\n\tDECLARE_DPM_WATCHDOG_ON_STACK(wd);\n\n\tTRACE_DEVICE(dev);\n\tTRACE_SUSPEND(0);\n\n\tdpm_wait_for_subordinate(dev, async);\n\n\tif (async_error) {\n\t\tdev->power.direct_complete = false;\n\t\tgoto Complete;\n\t}\n\n\t \n\tpm_runtime_barrier(dev);\n\n\tif (pm_wakeup_pending()) {\n\t\tdev->power.direct_complete = false;\n\t\tasync_error = -EBUSY;\n\t\tgoto Complete;\n\t}\n\n\tif (dev->power.syscore)\n\t\tgoto Complete;\n\n\t \n\tif (device_may_wakeup(dev) || device_wakeup_path(dev))\n\t\tdev->power.direct_complete = false;\n\n\tif (dev->power.direct_complete) {\n\t\tif (pm_runtime_status_suspended(dev)) {\n\t\t\tpm_runtime_disable(dev);\n\t\t\tif (pm_runtime_status_suspended(dev)) {\n\t\t\t\tpm_dev_dbg(dev, state, \"direct-complete \");\n\t\t\t\tgoto Complete;\n\t\t\t}\n\n\t\t\tpm_runtime_enable(dev);\n\t\t}\n\t\tdev->power.direct_complete = false;\n\t}\n\n\tdev->power.may_skip_resume = true;\n\tdev->power.must_resume = !dev_pm_test_driver_flags(dev, DPM_FLAG_MAY_SKIP_RESUME);\n\n\tdpm_watchdog_set(&wd, dev);\n\tdevice_lock(dev);\n\n\tif (dev->pm_domain) {\n\t\tinfo = \"power domain \";\n\t\tcallback = pm_op(&dev->pm_domain->ops, state);\n\t\tgoto Run;\n\t}\n\n\tif (dev->type && dev->type->pm) {\n\t\tinfo = \"type \";\n\t\tcallback = pm_op(dev->type->pm, state);\n\t\tgoto Run;\n\t}\n\n\tif (dev->class && dev->class->pm) {\n\t\tinfo = \"class \";\n\t\tcallback = pm_op(dev->class->pm, state);\n\t\tgoto Run;\n\t}\n\n\tif (dev->bus) {\n\t\tif (dev->bus->pm) {\n\t\t\tinfo = \"bus \";\n\t\t\tcallback = pm_op(dev->bus->pm, state);\n\t\t} else if (dev->bus->suspend) {\n\t\t\tpm_dev_dbg(dev, state, \"legacy bus \");\n\t\t\terror = legacy_suspend(dev, state, dev->bus->suspend,\n\t\t\t\t\t\t\"legacy bus \");\n\t\t\tgoto End;\n\t\t}\n\t}\n\n Run:\n\tif (!callback && dev->driver && dev->driver->pm) {\n\t\tinfo = \"driver \";\n\t\tcallback = pm_op(dev->driver->pm, state);\n\t}\n\n\terror = dpm_run_callback(callback, dev, state, info);\n\n End:\n\tif (!error) {\n\t\tdev->power.is_suspended = true;\n\t\tif (device_may_wakeup(dev))\n\t\t\tdev->power.wakeup_path = true;\n\n\t\tdpm_propagate_wakeup_to_parent(dev);\n\t\tdpm_clear_superiors_direct_complete(dev);\n\t}\n\n\tdevice_unlock(dev);\n\tdpm_watchdog_clear(&wd);\n\n Complete:\n\tif (error)\n\t\tasync_error = error;\n\n\tcomplete_all(&dev->power.completion);\n\tTRACE_SUSPEND(error);\n\treturn error;\n}\n\nstatic void async_suspend(void *data, async_cookie_t cookie)\n{\n\tstruct device *dev = data;\n\tint error;\n\n\terror = __device_suspend(dev, pm_transition, true);\n\tif (error) {\n\t\tdpm_save_failed_dev(dev_name(dev));\n\t\tpm_dev_err(dev, pm_transition, \" async\", error);\n\t}\n\n\tput_device(dev);\n}\n\nstatic int device_suspend(struct device *dev)\n{\n\tif (dpm_async_fn(dev, async_suspend))\n\t\treturn 0;\n\n\treturn __device_suspend(dev, pm_transition, false);\n}\n\n \nint dpm_suspend(pm_message_t state)\n{\n\tktime_t starttime = ktime_get();\n\tint error = 0;\n\n\ttrace_suspend_resume(TPS(\"dpm_suspend\"), state.event, true);\n\tmight_sleep();\n\n\tdevfreq_suspend();\n\tcpufreq_suspend();\n\n\tmutex_lock(&dpm_list_mtx);\n\tpm_transition = state;\n\tasync_error = 0;\n\twhile (!list_empty(&dpm_prepared_list)) {\n\t\tstruct device *dev = to_device(dpm_prepared_list.prev);\n\n\t\tget_device(dev);\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\terror = device_suspend(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\n\t\tif (error) {\n\t\t\tpm_dev_err(dev, state, \"\", error);\n\t\t\tdpm_save_failed_dev(dev_name(dev));\n\t\t} else if (!list_empty(&dev->power.entry)) {\n\t\t\tlist_move(&dev->power.entry, &dpm_suspended_list);\n\t\t}\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\tput_device(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\n\t\tif (error || async_error)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(&dpm_list_mtx);\n\tasync_synchronize_full();\n\tif (!error)\n\t\terror = async_error;\n\tif (error) {\n\t\tsuspend_stats.failed_suspend++;\n\t\tdpm_save_failed_step(SUSPEND_SUSPEND);\n\t}\n\tdpm_show_time(starttime, state, error, NULL);\n\ttrace_suspend_resume(TPS(\"dpm_suspend\"), state.event, false);\n\treturn error;\n}\n\n \nstatic int device_prepare(struct device *dev, pm_message_t state)\n{\n\tint (*callback)(struct device *) = NULL;\n\tint ret = 0;\n\n\t \n\tpm_runtime_get_noresume(dev);\n\n\tif (dev->power.syscore)\n\t\treturn 0;\n\n\tdevice_lock(dev);\n\n\tdev->power.wakeup_path = false;\n\n\tif (dev->power.no_pm_callbacks)\n\t\tgoto unlock;\n\n\tif (dev->pm_domain)\n\t\tcallback = dev->pm_domain->ops.prepare;\n\telse if (dev->type && dev->type->pm)\n\t\tcallback = dev->type->pm->prepare;\n\telse if (dev->class && dev->class->pm)\n\t\tcallback = dev->class->pm->prepare;\n\telse if (dev->bus && dev->bus->pm)\n\t\tcallback = dev->bus->pm->prepare;\n\n\tif (!callback && dev->driver && dev->driver->pm)\n\t\tcallback = dev->driver->pm->prepare;\n\n\tif (callback)\n\t\tret = callback(dev);\n\nunlock:\n\tdevice_unlock(dev);\n\n\tif (ret < 0) {\n\t\tsuspend_report_result(dev, callback, ret);\n\t\tpm_runtime_put(dev);\n\t\treturn ret;\n\t}\n\t \n\tspin_lock_irq(&dev->power.lock);\n\tdev->power.direct_complete = state.event == PM_EVENT_SUSPEND &&\n\t\t(ret > 0 || dev->power.no_pm_callbacks) &&\n\t\t!dev_pm_test_driver_flags(dev, DPM_FLAG_NO_DIRECT_COMPLETE);\n\tspin_unlock_irq(&dev->power.lock);\n\treturn 0;\n}\n\n \nint dpm_prepare(pm_message_t state)\n{\n\tint error = 0;\n\n\ttrace_suspend_resume(TPS(\"dpm_prepare\"), state.event, true);\n\tmight_sleep();\n\n\t \n\twait_for_device_probe();\n\t \n\tdevice_block_probing();\n\n\tmutex_lock(&dpm_list_mtx);\n\twhile (!list_empty(&dpm_list) && !error) {\n\t\tstruct device *dev = to_device(dpm_list.next);\n\n\t\tget_device(dev);\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\ttrace_device_pm_callback_start(dev, \"\", state.event);\n\t\terror = device_prepare(dev, state);\n\t\ttrace_device_pm_callback_end(dev, error);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\n\t\tif (!error) {\n\t\t\tdev->power.is_prepared = true;\n\t\t\tif (!list_empty(&dev->power.entry))\n\t\t\t\tlist_move_tail(&dev->power.entry, &dpm_prepared_list);\n\t\t} else if (error == -EAGAIN) {\n\t\t\terror = 0;\n\t\t} else {\n\t\t\tdev_info(dev, \"not prepared for power transition: code %d\\n\",\n\t\t\t\t error);\n\t\t}\n\n\t\tmutex_unlock(&dpm_list_mtx);\n\n\t\tput_device(dev);\n\n\t\tmutex_lock(&dpm_list_mtx);\n\t}\n\tmutex_unlock(&dpm_list_mtx);\n\ttrace_suspend_resume(TPS(\"dpm_prepare\"), state.event, false);\n\treturn error;\n}\n\n \nint dpm_suspend_start(pm_message_t state)\n{\n\tktime_t starttime = ktime_get();\n\tint error;\n\n\terror = dpm_prepare(state);\n\tif (error) {\n\t\tsuspend_stats.failed_prepare++;\n\t\tdpm_save_failed_step(SUSPEND_PREPARE);\n\t} else\n\t\terror = dpm_suspend(state);\n\tdpm_show_time(starttime, state, error, \"start\");\n\treturn error;\n}\nEXPORT_SYMBOL_GPL(dpm_suspend_start);\n\nvoid __suspend_report_result(const char *function, struct device *dev, void *fn, int ret)\n{\n\tif (ret)\n\t\tdev_err(dev, \"%s(): %pS returns %d\\n\", function, fn, ret);\n}\nEXPORT_SYMBOL_GPL(__suspend_report_result);\n\n \nint device_pm_wait_for_dev(struct device *subordinate, struct device *dev)\n{\n\tdpm_wait(dev, subordinate->power.async_suspend);\n\treturn async_error;\n}\nEXPORT_SYMBOL_GPL(device_pm_wait_for_dev);\n\n \nvoid dpm_for_each_dev(void *data, void (*fn)(struct device *, void *))\n{\n\tstruct device *dev;\n\n\tif (!fn)\n\t\treturn;\n\n\tdevice_pm_lock();\n\tlist_for_each_entry(dev, &dpm_list, power.entry)\n\t\tfn(dev, data);\n\tdevice_pm_unlock();\n}\nEXPORT_SYMBOL_GPL(dpm_for_each_dev);\n\nstatic bool pm_ops_is_empty(const struct dev_pm_ops *ops)\n{\n\tif (!ops)\n\t\treturn true;\n\n\treturn !ops->prepare &&\n\t       !ops->suspend &&\n\t       !ops->suspend_late &&\n\t       !ops->suspend_noirq &&\n\t       !ops->resume_noirq &&\n\t       !ops->resume_early &&\n\t       !ops->resume &&\n\t       !ops->complete;\n}\n\nvoid device_pm_check_callbacks(struct device *dev)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->power.lock, flags);\n\tdev->power.no_pm_callbacks =\n\t\t(!dev->bus || (pm_ops_is_empty(dev->bus->pm) &&\n\t\t !dev->bus->suspend && !dev->bus->resume)) &&\n\t\t(!dev->class || pm_ops_is_empty(dev->class->pm)) &&\n\t\t(!dev->type || pm_ops_is_empty(dev->type->pm)) &&\n\t\t(!dev->pm_domain || pm_ops_is_empty(&dev->pm_domain->ops)) &&\n\t\t(!dev->driver || (pm_ops_is_empty(dev->driver->pm) &&\n\t\t !dev->driver->suspend && !dev->driver->resume));\n\tspin_unlock_irqrestore(&dev->power.lock, flags);\n}\n\nbool dev_pm_skip_suspend(struct device *dev)\n{\n\treturn dev_pm_test_driver_flags(dev, DPM_FLAG_SMART_SUSPEND) &&\n\t\tpm_runtime_status_suspended(dev);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}