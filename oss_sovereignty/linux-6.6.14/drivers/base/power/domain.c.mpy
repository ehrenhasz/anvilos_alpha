{
  "module_name": "domain.c",
  "hash_id": "9cf8e50754ef2bb91d34e6859cc124ab92648c68bc44b08e850f74de61aa87c9",
  "original_prompt": "Ingested from linux-6.6.14/drivers/base/power/domain.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) \"PM: \" fmt\n\n#include <linux/delay.h>\n#include <linux/kernel.h>\n#include <linux/io.h>\n#include <linux/platform_device.h>\n#include <linux/pm_opp.h>\n#include <linux/pm_runtime.h>\n#include <linux/pm_domain.h>\n#include <linux/pm_qos.h>\n#include <linux/pm_clock.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/sched.h>\n#include <linux/suspend.h>\n#include <linux/export.h>\n#include <linux/cpu.h>\n#include <linux/debugfs.h>\n\n#include \"power.h\"\n\n#define GENPD_RETRY_MAX_MS\t250\t\t \n\n#define GENPD_DEV_CALLBACK(genpd, type, callback, dev)\t\t\\\n({\t\t\t\t\t\t\t\t\\\n\ttype (*__routine)(struct device *__d); \t\t\t\\\n\ttype __ret = (type)0;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\t__routine = genpd->dev_ops.callback; \t\t\t\\\n\tif (__routine) {\t\t\t\t\t\\\n\t\t__ret = __routine(dev); \t\t\t\\\n\t}\t\t\t\t\t\t\t\\\n\t__ret;\t\t\t\t\t\t\t\\\n})\n\nstatic LIST_HEAD(gpd_list);\nstatic DEFINE_MUTEX(gpd_list_lock);\n\nstruct genpd_lock_ops {\n\tvoid (*lock)(struct generic_pm_domain *genpd);\n\tvoid (*lock_nested)(struct generic_pm_domain *genpd, int depth);\n\tint (*lock_interruptible)(struct generic_pm_domain *genpd);\n\tvoid (*unlock)(struct generic_pm_domain *genpd);\n};\n\nstatic void genpd_lock_mtx(struct generic_pm_domain *genpd)\n{\n\tmutex_lock(&genpd->mlock);\n}\n\nstatic void genpd_lock_nested_mtx(struct generic_pm_domain *genpd,\n\t\t\t\t\tint depth)\n{\n\tmutex_lock_nested(&genpd->mlock, depth);\n}\n\nstatic int genpd_lock_interruptible_mtx(struct generic_pm_domain *genpd)\n{\n\treturn mutex_lock_interruptible(&genpd->mlock);\n}\n\nstatic void genpd_unlock_mtx(struct generic_pm_domain *genpd)\n{\n\treturn mutex_unlock(&genpd->mlock);\n}\n\nstatic const struct genpd_lock_ops genpd_mtx_ops = {\n\t.lock = genpd_lock_mtx,\n\t.lock_nested = genpd_lock_nested_mtx,\n\t.lock_interruptible = genpd_lock_interruptible_mtx,\n\t.unlock = genpd_unlock_mtx,\n};\n\nstatic void genpd_lock_spin(struct generic_pm_domain *genpd)\n\t__acquires(&genpd->slock)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&genpd->slock, flags);\n\tgenpd->lock_flags = flags;\n}\n\nstatic void genpd_lock_nested_spin(struct generic_pm_domain *genpd,\n\t\t\t\t\tint depth)\n\t__acquires(&genpd->slock)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave_nested(&genpd->slock, flags, depth);\n\tgenpd->lock_flags = flags;\n}\n\nstatic int genpd_lock_interruptible_spin(struct generic_pm_domain *genpd)\n\t__acquires(&genpd->slock)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&genpd->slock, flags);\n\tgenpd->lock_flags = flags;\n\treturn 0;\n}\n\nstatic void genpd_unlock_spin(struct generic_pm_domain *genpd)\n\t__releases(&genpd->slock)\n{\n\tspin_unlock_irqrestore(&genpd->slock, genpd->lock_flags);\n}\n\nstatic const struct genpd_lock_ops genpd_spin_ops = {\n\t.lock = genpd_lock_spin,\n\t.lock_nested = genpd_lock_nested_spin,\n\t.lock_interruptible = genpd_lock_interruptible_spin,\n\t.unlock = genpd_unlock_spin,\n};\n\n#define genpd_lock(p)\t\t\tp->lock_ops->lock(p)\n#define genpd_lock_nested(p, d)\t\tp->lock_ops->lock_nested(p, d)\n#define genpd_lock_interruptible(p)\tp->lock_ops->lock_interruptible(p)\n#define genpd_unlock(p)\t\t\tp->lock_ops->unlock(p)\n\n#define genpd_status_on(genpd)\t\t(genpd->status == GENPD_STATE_ON)\n#define genpd_is_irq_safe(genpd)\t(genpd->flags & GENPD_FLAG_IRQ_SAFE)\n#define genpd_is_always_on(genpd)\t(genpd->flags & GENPD_FLAG_ALWAYS_ON)\n#define genpd_is_active_wakeup(genpd)\t(genpd->flags & GENPD_FLAG_ACTIVE_WAKEUP)\n#define genpd_is_cpu_domain(genpd)\t(genpd->flags & GENPD_FLAG_CPU_DOMAIN)\n#define genpd_is_rpm_always_on(genpd)\t(genpd->flags & GENPD_FLAG_RPM_ALWAYS_ON)\n\nstatic inline bool irq_safe_dev_in_sleep_domain(struct device *dev,\n\t\tconst struct generic_pm_domain *genpd)\n{\n\tbool ret;\n\n\tret = pm_runtime_is_irq_safe(dev) && !genpd_is_irq_safe(genpd);\n\n\t \n\tif (genpd_is_always_on(genpd) || genpd_is_rpm_always_on(genpd))\n\t\treturn ret;\n\n\tif (ret)\n\t\tdev_warn_once(dev, \"PM domain %s will not be powered off\\n\",\n\t\t\t\tgenpd->name);\n\n\treturn ret;\n}\n\nstatic int genpd_runtime_suspend(struct device *dev);\n\n \nstatic struct generic_pm_domain *dev_to_genpd_safe(struct device *dev)\n{\n\tif (IS_ERR_OR_NULL(dev) || IS_ERR_OR_NULL(dev->pm_domain))\n\t\treturn NULL;\n\n\t \n\tif (dev->pm_domain->ops.runtime_suspend == genpd_runtime_suspend)\n\t\treturn pd_to_genpd(dev->pm_domain);\n\n\treturn NULL;\n}\n\n \nstatic struct generic_pm_domain *dev_to_genpd(struct device *dev)\n{\n\tif (IS_ERR_OR_NULL(dev->pm_domain))\n\t\treturn ERR_PTR(-EINVAL);\n\n\treturn pd_to_genpd(dev->pm_domain);\n}\n\nstatic int genpd_stop_dev(const struct generic_pm_domain *genpd,\n\t\t\t  struct device *dev)\n{\n\treturn GENPD_DEV_CALLBACK(genpd, int, stop, dev);\n}\n\nstatic int genpd_start_dev(const struct generic_pm_domain *genpd,\n\t\t\t   struct device *dev)\n{\n\treturn GENPD_DEV_CALLBACK(genpd, int, start, dev);\n}\n\nstatic bool genpd_sd_counter_dec(struct generic_pm_domain *genpd)\n{\n\tbool ret = false;\n\n\tif (!WARN_ON(atomic_read(&genpd->sd_count) == 0))\n\t\tret = !!atomic_dec_and_test(&genpd->sd_count);\n\n\treturn ret;\n}\n\nstatic void genpd_sd_counter_inc(struct generic_pm_domain *genpd)\n{\n\tatomic_inc(&genpd->sd_count);\n\tsmp_mb__after_atomic();\n}\n\n#ifdef CONFIG_DEBUG_FS\nstatic struct dentry *genpd_debugfs_dir;\n\nstatic void genpd_debug_add(struct generic_pm_domain *genpd);\n\nstatic void genpd_debug_remove(struct generic_pm_domain *genpd)\n{\n\tif (!genpd_debugfs_dir)\n\t\treturn;\n\n\tdebugfs_lookup_and_remove(genpd->name, genpd_debugfs_dir);\n}\n\nstatic void genpd_update_accounting(struct generic_pm_domain *genpd)\n{\n\tu64 delta, now;\n\n\tnow = ktime_get_mono_fast_ns();\n\tif (now <= genpd->accounting_time)\n\t\treturn;\n\n\tdelta = now - genpd->accounting_time;\n\n\t \n\tif (genpd->status == GENPD_STATE_ON)\n\t\tgenpd->states[genpd->state_idx].idle_time += delta;\n\telse\n\t\tgenpd->on_time += delta;\n\n\tgenpd->accounting_time = now;\n}\n#else\nstatic inline void genpd_debug_add(struct generic_pm_domain *genpd) {}\nstatic inline void genpd_debug_remove(struct generic_pm_domain *genpd) {}\nstatic inline void genpd_update_accounting(struct generic_pm_domain *genpd) {}\n#endif\n\nstatic int _genpd_reeval_performance_state(struct generic_pm_domain *genpd,\n\t\t\t\t\t   unsigned int state)\n{\n\tstruct generic_pm_domain_data *pd_data;\n\tstruct pm_domain_data *pdd;\n\tstruct gpd_link *link;\n\n\t \n\tif (state == genpd->performance_state)\n\t\treturn state;\n\n\t \n\tif (state > genpd->performance_state)\n\t\treturn state;\n\n\t \n\tlist_for_each_entry(pdd, &genpd->dev_list, list_node) {\n\t\tpd_data = to_gpd_data(pdd);\n\n\t\tif (pd_data->performance_state > state)\n\t\t\tstate = pd_data->performance_state;\n\t}\n\n\t \n\tlist_for_each_entry(link, &genpd->parent_links, parent_node) {\n\t\tif (link->performance_state > state)\n\t\t\tstate = link->performance_state;\n\t}\n\n\treturn state;\n}\n\nstatic int genpd_xlate_performance_state(struct generic_pm_domain *genpd,\n\t\t\t\t\t struct generic_pm_domain *parent,\n\t\t\t\t\t unsigned int pstate)\n{\n\tif (!parent->set_performance_state)\n\t\treturn pstate;\n\n\treturn dev_pm_opp_xlate_performance_state(genpd->opp_table,\n\t\t\t\t\t\t  parent->opp_table,\n\t\t\t\t\t\t  pstate);\n}\n\nstatic int _genpd_set_performance_state(struct generic_pm_domain *genpd,\n\t\t\t\t\tunsigned int state, int depth)\n{\n\tstruct generic_pm_domain *parent;\n\tstruct gpd_link *link;\n\tint parent_state, ret;\n\n\tif (state == genpd->performance_state)\n\t\treturn 0;\n\n\t \n\tlist_for_each_entry(link, &genpd->child_links, child_node) {\n\t\tparent = link->parent;\n\n\t\t \n\t\tret = genpd_xlate_performance_state(genpd, parent, state);\n\t\tif (unlikely(ret < 0))\n\t\t\tgoto err;\n\n\t\tparent_state = ret;\n\n\t\tgenpd_lock_nested(parent, depth + 1);\n\n\t\tlink->prev_performance_state = link->performance_state;\n\t\tlink->performance_state = parent_state;\n\t\tparent_state = _genpd_reeval_performance_state(parent,\n\t\t\t\t\t\tparent_state);\n\t\tret = _genpd_set_performance_state(parent, parent_state, depth + 1);\n\t\tif (ret)\n\t\t\tlink->performance_state = link->prev_performance_state;\n\n\t\tgenpd_unlock(parent);\n\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\tif (genpd->set_performance_state) {\n\t\tret = genpd->set_performance_state(genpd, state);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\tgenpd->performance_state = state;\n\treturn 0;\n\nerr:\n\t \n\tlist_for_each_entry_continue_reverse(link, &genpd->child_links,\n\t\t\t\t\t     child_node) {\n\t\tparent = link->parent;\n\n\t\tgenpd_lock_nested(parent, depth + 1);\n\n\t\tparent_state = link->prev_performance_state;\n\t\tlink->performance_state = parent_state;\n\n\t\tparent_state = _genpd_reeval_performance_state(parent,\n\t\t\t\t\t\tparent_state);\n\t\tif (_genpd_set_performance_state(parent, parent_state, depth + 1)) {\n\t\t\tpr_err(\"%s: Failed to roll back to %d performance state\\n\",\n\t\t\t       parent->name, parent_state);\n\t\t}\n\n\t\tgenpd_unlock(parent);\n\t}\n\n\treturn ret;\n}\n\nstatic int genpd_set_performance_state(struct device *dev, unsigned int state)\n{\n\tstruct generic_pm_domain *genpd = dev_to_genpd(dev);\n\tstruct generic_pm_domain_data *gpd_data = dev_gpd_data(dev);\n\tunsigned int prev_state;\n\tint ret;\n\n\tprev_state = gpd_data->performance_state;\n\tif (prev_state == state)\n\t\treturn 0;\n\n\tgpd_data->performance_state = state;\n\tstate = _genpd_reeval_performance_state(genpd, state);\n\n\tret = _genpd_set_performance_state(genpd, state, 0);\n\tif (ret)\n\t\tgpd_data->performance_state = prev_state;\n\n\treturn ret;\n}\n\nstatic int genpd_drop_performance_state(struct device *dev)\n{\n\tunsigned int prev_state = dev_gpd_data(dev)->performance_state;\n\n\tif (!genpd_set_performance_state(dev, 0))\n\t\treturn prev_state;\n\n\treturn 0;\n}\n\nstatic void genpd_restore_performance_state(struct device *dev,\n\t\t\t\t\t    unsigned int state)\n{\n\tif (state)\n\t\tgenpd_set_performance_state(dev, state);\n}\n\n \nint dev_pm_genpd_set_performance_state(struct device *dev, unsigned int state)\n{\n\tstruct generic_pm_domain *genpd;\n\tint ret = 0;\n\n\tgenpd = dev_to_genpd_safe(dev);\n\tif (!genpd)\n\t\treturn -ENODEV;\n\n\tif (WARN_ON(!dev->power.subsys_data ||\n\t\t     !dev->power.subsys_data->domain_data))\n\t\treturn -EINVAL;\n\n\tgenpd_lock(genpd);\n\tif (pm_runtime_suspended(dev)) {\n\t\tdev_gpd_data(dev)->rpm_pstate = state;\n\t} else {\n\t\tret = genpd_set_performance_state(dev, state);\n\t\tif (!ret)\n\t\t\tdev_gpd_data(dev)->rpm_pstate = 0;\n\t}\n\tgenpd_unlock(genpd);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(dev_pm_genpd_set_performance_state);\n\n \nvoid dev_pm_genpd_set_next_wakeup(struct device *dev, ktime_t next)\n{\n\tstruct generic_pm_domain *genpd;\n\tstruct gpd_timing_data *td;\n\n\tgenpd = dev_to_genpd_safe(dev);\n\tif (!genpd)\n\t\treturn;\n\n\ttd = to_gpd_data(dev->power.subsys_data->domain_data)->td;\n\tif (td)\n\t\ttd->next_wakeup = next;\n}\nEXPORT_SYMBOL_GPL(dev_pm_genpd_set_next_wakeup);\n\n \nktime_t dev_pm_genpd_get_next_hrtimer(struct device *dev)\n{\n\tstruct generic_pm_domain *genpd;\n\n\tgenpd = dev_to_genpd_safe(dev);\n\tif (!genpd)\n\t\treturn KTIME_MAX;\n\n\tif (genpd->gd)\n\t\treturn genpd->gd->next_hrtimer;\n\n\treturn KTIME_MAX;\n}\nEXPORT_SYMBOL_GPL(dev_pm_genpd_get_next_hrtimer);\n\n \nvoid dev_pm_genpd_synced_poweroff(struct device *dev)\n{\n\tstruct generic_pm_domain *genpd;\n\n\tgenpd = dev_to_genpd_safe(dev);\n\tif (!genpd)\n\t\treturn;\n\n\tgenpd_lock(genpd);\n\tgenpd->synced_poweroff = true;\n\tgenpd_unlock(genpd);\n}\nEXPORT_SYMBOL_GPL(dev_pm_genpd_synced_poweroff);\n\nstatic int _genpd_power_on(struct generic_pm_domain *genpd, bool timed)\n{\n\tunsigned int state_idx = genpd->state_idx;\n\tktime_t time_start;\n\ts64 elapsed_ns;\n\tint ret;\n\n\t \n\tret = raw_notifier_call_chain_robust(&genpd->power_notifiers,\n\t\t\t\t\t     GENPD_NOTIFY_PRE_ON,\n\t\t\t\t\t     GENPD_NOTIFY_OFF, NULL);\n\tret = notifier_to_errno(ret);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!genpd->power_on)\n\t\tgoto out;\n\n\ttimed = timed && genpd->gd && !genpd->states[state_idx].fwnode;\n\tif (!timed) {\n\t\tret = genpd->power_on(genpd);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tgoto out;\n\t}\n\n\ttime_start = ktime_get();\n\tret = genpd->power_on(genpd);\n\tif (ret)\n\t\tgoto err;\n\n\telapsed_ns = ktime_to_ns(ktime_sub(ktime_get(), time_start));\n\tif (elapsed_ns <= genpd->states[state_idx].power_on_latency_ns)\n\t\tgoto out;\n\n\tgenpd->states[state_idx].power_on_latency_ns = elapsed_ns;\n\tgenpd->gd->max_off_time_changed = true;\n\tpr_debug(\"%s: Power-%s latency exceeded, new value %lld ns\\n\",\n\t\t genpd->name, \"on\", elapsed_ns);\n\nout:\n\traw_notifier_call_chain(&genpd->power_notifiers, GENPD_NOTIFY_ON, NULL);\n\tgenpd->synced_poweroff = false;\n\treturn 0;\nerr:\n\traw_notifier_call_chain(&genpd->power_notifiers, GENPD_NOTIFY_OFF,\n\t\t\t\tNULL);\n\treturn ret;\n}\n\nstatic int _genpd_power_off(struct generic_pm_domain *genpd, bool timed)\n{\n\tunsigned int state_idx = genpd->state_idx;\n\tktime_t time_start;\n\ts64 elapsed_ns;\n\tint ret;\n\n\t \n\tret = raw_notifier_call_chain_robust(&genpd->power_notifiers,\n\t\t\t\t\t     GENPD_NOTIFY_PRE_OFF,\n\t\t\t\t\t     GENPD_NOTIFY_ON, NULL);\n\tret = notifier_to_errno(ret);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!genpd->power_off)\n\t\tgoto out;\n\n\ttimed = timed && genpd->gd && !genpd->states[state_idx].fwnode;\n\tif (!timed) {\n\t\tret = genpd->power_off(genpd);\n\t\tif (ret)\n\t\t\tgoto busy;\n\n\t\tgoto out;\n\t}\n\n\ttime_start = ktime_get();\n\tret = genpd->power_off(genpd);\n\tif (ret)\n\t\tgoto busy;\n\n\telapsed_ns = ktime_to_ns(ktime_sub(ktime_get(), time_start));\n\tif (elapsed_ns <= genpd->states[state_idx].power_off_latency_ns)\n\t\tgoto out;\n\n\tgenpd->states[state_idx].power_off_latency_ns = elapsed_ns;\n\tgenpd->gd->max_off_time_changed = true;\n\tpr_debug(\"%s: Power-%s latency exceeded, new value %lld ns\\n\",\n\t\t genpd->name, \"off\", elapsed_ns);\n\nout:\n\traw_notifier_call_chain(&genpd->power_notifiers, GENPD_NOTIFY_OFF,\n\t\t\t\tNULL);\n\treturn 0;\nbusy:\n\traw_notifier_call_chain(&genpd->power_notifiers, GENPD_NOTIFY_ON, NULL);\n\treturn ret;\n}\n\n \nstatic void genpd_queue_power_off_work(struct generic_pm_domain *genpd)\n{\n\tqueue_work(pm_wq, &genpd->power_off_work);\n}\n\n \nstatic int genpd_power_off(struct generic_pm_domain *genpd, bool one_dev_on,\n\t\t\t   unsigned int depth)\n{\n\tstruct pm_domain_data *pdd;\n\tstruct gpd_link *link;\n\tunsigned int not_suspended = 0;\n\tint ret;\n\n\t \n\tif (!genpd_status_on(genpd) || genpd->prepared_count > 0)\n\t\treturn 0;\n\n\t \n\tif (genpd_is_always_on(genpd) ||\n\t\t\tgenpd_is_rpm_always_on(genpd) ||\n\t\t\tatomic_read(&genpd->sd_count) > 0)\n\t\treturn -EBUSY;\n\n\t \n\tlist_for_each_entry(link, &genpd->parent_links, parent_node) {\n\t\tstruct generic_pm_domain *child = link->child;\n\t\tif (child->state_idx < child->state_count - 1)\n\t\t\treturn -EBUSY;\n\t}\n\n\tlist_for_each_entry(pdd, &genpd->dev_list, list_node) {\n\t\t \n\t\tif (!pm_runtime_suspended(pdd->dev) ||\n\t\t\tirq_safe_dev_in_sleep_domain(pdd->dev, genpd))\n\t\t\tnot_suspended++;\n\t}\n\n\tif (not_suspended > 1 || (not_suspended == 1 && !one_dev_on))\n\t\treturn -EBUSY;\n\n\tif (genpd->gov && genpd->gov->power_down_ok) {\n\t\tif (!genpd->gov->power_down_ok(&genpd->domain))\n\t\t\treturn -EAGAIN;\n\t}\n\n\t \n\tif (!genpd->gov)\n\t\tgenpd->state_idx = 0;\n\n\t \n\tif (atomic_read(&genpd->sd_count) > 0)\n\t\treturn -EBUSY;\n\n\tret = _genpd_power_off(genpd, true);\n\tif (ret) {\n\t\tgenpd->states[genpd->state_idx].rejected++;\n\t\treturn ret;\n\t}\n\n\tgenpd->status = GENPD_STATE_OFF;\n\tgenpd_update_accounting(genpd);\n\tgenpd->states[genpd->state_idx].usage++;\n\n\tlist_for_each_entry(link, &genpd->child_links, child_node) {\n\t\tgenpd_sd_counter_dec(link->parent);\n\t\tgenpd_lock_nested(link->parent, depth + 1);\n\t\tgenpd_power_off(link->parent, false, depth + 1);\n\t\tgenpd_unlock(link->parent);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int genpd_power_on(struct generic_pm_domain *genpd, unsigned int depth)\n{\n\tstruct gpd_link *link;\n\tint ret = 0;\n\n\tif (genpd_status_on(genpd))\n\t\treturn 0;\n\n\t \n\tlist_for_each_entry(link, &genpd->child_links, child_node) {\n\t\tstruct generic_pm_domain *parent = link->parent;\n\n\t\tgenpd_sd_counter_inc(parent);\n\n\t\tgenpd_lock_nested(parent, depth + 1);\n\t\tret = genpd_power_on(parent, depth + 1);\n\t\tgenpd_unlock(parent);\n\n\t\tif (ret) {\n\t\t\tgenpd_sd_counter_dec(parent);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tret = _genpd_power_on(genpd, true);\n\tif (ret)\n\t\tgoto err;\n\n\tgenpd->status = GENPD_STATE_ON;\n\tgenpd_update_accounting(genpd);\n\n\treturn 0;\n\n err:\n\tlist_for_each_entry_continue_reverse(link,\n\t\t\t\t\t&genpd->child_links,\n\t\t\t\t\tchild_node) {\n\t\tgenpd_sd_counter_dec(link->parent);\n\t\tgenpd_lock_nested(link->parent, depth + 1);\n\t\tgenpd_power_off(link->parent, false, depth + 1);\n\t\tgenpd_unlock(link->parent);\n\t}\n\n\treturn ret;\n}\n\nstatic int genpd_dev_pm_start(struct device *dev)\n{\n\tstruct generic_pm_domain *genpd = dev_to_genpd(dev);\n\n\treturn genpd_start_dev(genpd, dev);\n}\n\nstatic int genpd_dev_pm_qos_notifier(struct notifier_block *nb,\n\t\t\t\t     unsigned long val, void *ptr)\n{\n\tstruct generic_pm_domain_data *gpd_data;\n\tstruct device *dev;\n\n\tgpd_data = container_of(nb, struct generic_pm_domain_data, nb);\n\tdev = gpd_data->base.dev;\n\n\tfor (;;) {\n\t\tstruct generic_pm_domain *genpd = ERR_PTR(-ENODATA);\n\t\tstruct pm_domain_data *pdd;\n\t\tstruct gpd_timing_data *td;\n\n\t\tspin_lock_irq(&dev->power.lock);\n\n\t\tpdd = dev->power.subsys_data ?\n\t\t\t\tdev->power.subsys_data->domain_data : NULL;\n\t\tif (pdd) {\n\t\t\ttd = to_gpd_data(pdd)->td;\n\t\t\tif (td) {\n\t\t\t\ttd->constraint_changed = true;\n\t\t\t\tgenpd = dev_to_genpd(dev);\n\t\t\t}\n\t\t}\n\n\t\tspin_unlock_irq(&dev->power.lock);\n\n\t\tif (!IS_ERR(genpd)) {\n\t\t\tgenpd_lock(genpd);\n\t\t\tgenpd->gd->max_off_time_changed = true;\n\t\t\tgenpd_unlock(genpd);\n\t\t}\n\n\t\tdev = dev->parent;\n\t\tif (!dev || dev->power.ignore_children)\n\t\t\tbreak;\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\n \nstatic void genpd_power_off_work_fn(struct work_struct *work)\n{\n\tstruct generic_pm_domain *genpd;\n\n\tgenpd = container_of(work, struct generic_pm_domain, power_off_work);\n\n\tgenpd_lock(genpd);\n\tgenpd_power_off(genpd, false, 0);\n\tgenpd_unlock(genpd);\n}\n\n \nstatic int __genpd_runtime_suspend(struct device *dev)\n{\n\tint (*cb)(struct device *__dev);\n\n\tif (dev->type && dev->type->pm)\n\t\tcb = dev->type->pm->runtime_suspend;\n\telse if (dev->class && dev->class->pm)\n\t\tcb = dev->class->pm->runtime_suspend;\n\telse if (dev->bus && dev->bus->pm)\n\t\tcb = dev->bus->pm->runtime_suspend;\n\telse\n\t\tcb = NULL;\n\n\tif (!cb && dev->driver && dev->driver->pm)\n\t\tcb = dev->driver->pm->runtime_suspend;\n\n\treturn cb ? cb(dev) : 0;\n}\n\n \nstatic int __genpd_runtime_resume(struct device *dev)\n{\n\tint (*cb)(struct device *__dev);\n\n\tif (dev->type && dev->type->pm)\n\t\tcb = dev->type->pm->runtime_resume;\n\telse if (dev->class && dev->class->pm)\n\t\tcb = dev->class->pm->runtime_resume;\n\telse if (dev->bus && dev->bus->pm)\n\t\tcb = dev->bus->pm->runtime_resume;\n\telse\n\t\tcb = NULL;\n\n\tif (!cb && dev->driver && dev->driver->pm)\n\t\tcb = dev->driver->pm->runtime_resume;\n\n\treturn cb ? cb(dev) : 0;\n}\n\n \nstatic int genpd_runtime_suspend(struct device *dev)\n{\n\tstruct generic_pm_domain *genpd;\n\tbool (*suspend_ok)(struct device *__dev);\n\tstruct generic_pm_domain_data *gpd_data = dev_gpd_data(dev);\n\tstruct gpd_timing_data *td = gpd_data->td;\n\tbool runtime_pm = pm_runtime_enabled(dev);\n\tktime_t time_start = 0;\n\ts64 elapsed_ns;\n\tint ret;\n\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\tgenpd = dev_to_genpd(dev);\n\tif (IS_ERR(genpd))\n\t\treturn -EINVAL;\n\n\t \n\tsuspend_ok = genpd->gov ? genpd->gov->suspend_ok : NULL;\n\tif (runtime_pm && suspend_ok && !suspend_ok(dev))\n\t\treturn -EBUSY;\n\n\t \n\tif (td && runtime_pm)\n\t\ttime_start = ktime_get();\n\n\tret = __genpd_runtime_suspend(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = genpd_stop_dev(genpd, dev);\n\tif (ret) {\n\t\t__genpd_runtime_resume(dev);\n\t\treturn ret;\n\t}\n\n\t \n\tif (td && runtime_pm) {\n\t\telapsed_ns = ktime_to_ns(ktime_sub(ktime_get(), time_start));\n\t\tif (elapsed_ns > td->suspend_latency_ns) {\n\t\t\ttd->suspend_latency_ns = elapsed_ns;\n\t\t\tdev_dbg(dev, \"suspend latency exceeded, %lld ns\\n\",\n\t\t\t\telapsed_ns);\n\t\t\tgenpd->gd->max_off_time_changed = true;\n\t\t\ttd->constraint_changed = true;\n\t\t}\n\t}\n\n\t \n\tif (irq_safe_dev_in_sleep_domain(dev, genpd))\n\t\treturn 0;\n\n\tgenpd_lock(genpd);\n\tgenpd_power_off(genpd, true, 0);\n\tgpd_data->rpm_pstate = genpd_drop_performance_state(dev);\n\tgenpd_unlock(genpd);\n\n\treturn 0;\n}\n\n \nstatic int genpd_runtime_resume(struct device *dev)\n{\n\tstruct generic_pm_domain *genpd;\n\tstruct generic_pm_domain_data *gpd_data = dev_gpd_data(dev);\n\tstruct gpd_timing_data *td = gpd_data->td;\n\tbool timed = td && pm_runtime_enabled(dev);\n\tktime_t time_start = 0;\n\ts64 elapsed_ns;\n\tint ret;\n\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\tgenpd = dev_to_genpd(dev);\n\tif (IS_ERR(genpd))\n\t\treturn -EINVAL;\n\n\t \n\tif (irq_safe_dev_in_sleep_domain(dev, genpd))\n\t\tgoto out;\n\n\tgenpd_lock(genpd);\n\tgenpd_restore_performance_state(dev, gpd_data->rpm_pstate);\n\tret = genpd_power_on(genpd, 0);\n\tgenpd_unlock(genpd);\n\n\tif (ret)\n\t\treturn ret;\n\n out:\n\t \n\tif (timed)\n\t\ttime_start = ktime_get();\n\n\tret = genpd_start_dev(genpd, dev);\n\tif (ret)\n\t\tgoto err_poweroff;\n\n\tret = __genpd_runtime_resume(dev);\n\tif (ret)\n\t\tgoto err_stop;\n\n\t \n\tif (timed) {\n\t\telapsed_ns = ktime_to_ns(ktime_sub(ktime_get(), time_start));\n\t\tif (elapsed_ns > td->resume_latency_ns) {\n\t\t\ttd->resume_latency_ns = elapsed_ns;\n\t\t\tdev_dbg(dev, \"resume latency exceeded, %lld ns\\n\",\n\t\t\t\telapsed_ns);\n\t\t\tgenpd->gd->max_off_time_changed = true;\n\t\t\ttd->constraint_changed = true;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_stop:\n\tgenpd_stop_dev(genpd, dev);\nerr_poweroff:\n\tif (!pm_runtime_is_irq_safe(dev) || genpd_is_irq_safe(genpd)) {\n\t\tgenpd_lock(genpd);\n\t\tgenpd_power_off(genpd, true, 0);\n\t\tgpd_data->rpm_pstate = genpd_drop_performance_state(dev);\n\t\tgenpd_unlock(genpd);\n\t}\n\n\treturn ret;\n}\n\nstatic bool pd_ignore_unused;\nstatic int __init pd_ignore_unused_setup(char *__unused)\n{\n\tpd_ignore_unused = true;\n\treturn 1;\n}\n__setup(\"pd_ignore_unused\", pd_ignore_unused_setup);\n\n \nstatic int __init genpd_power_off_unused(void)\n{\n\tstruct generic_pm_domain *genpd;\n\n\tif (pd_ignore_unused) {\n\t\tpr_warn(\"genpd: Not disabling unused power domains\\n\");\n\t\treturn 0;\n\t}\n\n\tmutex_lock(&gpd_list_lock);\n\n\tlist_for_each_entry(genpd, &gpd_list, gpd_list_node)\n\t\tgenpd_queue_power_off_work(genpd);\n\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn 0;\n}\nlate_initcall(genpd_power_off_unused);\n\n#ifdef CONFIG_PM_SLEEP\n\n \nstatic void genpd_sync_power_off(struct generic_pm_domain *genpd, bool use_lock,\n\t\t\t\t unsigned int depth)\n{\n\tstruct gpd_link *link;\n\n\tif (!genpd_status_on(genpd) || genpd_is_always_on(genpd))\n\t\treturn;\n\n\tif (genpd->suspended_count != genpd->device_count\n\t    || atomic_read(&genpd->sd_count) > 0)\n\t\treturn;\n\n\t \n\tlist_for_each_entry(link, &genpd->parent_links, parent_node) {\n\t\tstruct generic_pm_domain *child = link->child;\n\t\tif (child->state_idx < child->state_count - 1)\n\t\t\treturn;\n\t}\n\n\t \n\tgenpd->state_idx = genpd->state_count - 1;\n\tif (_genpd_power_off(genpd, false))\n\t\treturn;\n\n\tgenpd->status = GENPD_STATE_OFF;\n\n\tlist_for_each_entry(link, &genpd->child_links, child_node) {\n\t\tgenpd_sd_counter_dec(link->parent);\n\n\t\tif (use_lock)\n\t\t\tgenpd_lock_nested(link->parent, depth + 1);\n\n\t\tgenpd_sync_power_off(link->parent, use_lock, depth + 1);\n\n\t\tif (use_lock)\n\t\t\tgenpd_unlock(link->parent);\n\t}\n}\n\n \nstatic void genpd_sync_power_on(struct generic_pm_domain *genpd, bool use_lock,\n\t\t\t\tunsigned int depth)\n{\n\tstruct gpd_link *link;\n\n\tif (genpd_status_on(genpd))\n\t\treturn;\n\n\tlist_for_each_entry(link, &genpd->child_links, child_node) {\n\t\tgenpd_sd_counter_inc(link->parent);\n\n\t\tif (use_lock)\n\t\t\tgenpd_lock_nested(link->parent, depth + 1);\n\n\t\tgenpd_sync_power_on(link->parent, use_lock, depth + 1);\n\n\t\tif (use_lock)\n\t\t\tgenpd_unlock(link->parent);\n\t}\n\n\t_genpd_power_on(genpd, false);\n\tgenpd->status = GENPD_STATE_ON;\n}\n\n \nstatic int genpd_prepare(struct device *dev)\n{\n\tstruct generic_pm_domain *genpd;\n\tint ret;\n\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\tgenpd = dev_to_genpd(dev);\n\tif (IS_ERR(genpd))\n\t\treturn -EINVAL;\n\n\tgenpd_lock(genpd);\n\n\tif (genpd->prepared_count++ == 0)\n\t\tgenpd->suspended_count = 0;\n\n\tgenpd_unlock(genpd);\n\n\tret = pm_generic_prepare(dev);\n\tif (ret < 0) {\n\t\tgenpd_lock(genpd);\n\n\t\tgenpd->prepared_count--;\n\n\t\tgenpd_unlock(genpd);\n\t}\n\n\t \n\treturn ret >= 0 ? 0 : ret;\n}\n\n \nstatic int genpd_finish_suspend(struct device *dev,\n\t\t\t\tint (*suspend_noirq)(struct device *dev),\n\t\t\t\tint (*resume_noirq)(struct device *dev))\n{\n\tstruct generic_pm_domain *genpd;\n\tint ret = 0;\n\n\tgenpd = dev_to_genpd(dev);\n\tif (IS_ERR(genpd))\n\t\treturn -EINVAL;\n\n\tret = suspend_noirq(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tif (device_wakeup_path(dev) && genpd_is_active_wakeup(genpd))\n\t\treturn 0;\n\n\tif (genpd->dev_ops.stop && genpd->dev_ops.start &&\n\t    !pm_runtime_status_suspended(dev)) {\n\t\tret = genpd_stop_dev(genpd, dev);\n\t\tif (ret) {\n\t\t\tresume_noirq(dev);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tgenpd_lock(genpd);\n\tgenpd->suspended_count++;\n\tgenpd_sync_power_off(genpd, true, 0);\n\tgenpd_unlock(genpd);\n\n\treturn 0;\n}\n\n \nstatic int genpd_suspend_noirq(struct device *dev)\n{\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\treturn genpd_finish_suspend(dev,\n\t\t\t\t    pm_generic_suspend_noirq,\n\t\t\t\t    pm_generic_resume_noirq);\n}\n\n \nstatic int genpd_finish_resume(struct device *dev,\n\t\t\t       int (*resume_noirq)(struct device *dev))\n{\n\tstruct generic_pm_domain *genpd;\n\tint ret;\n\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\tgenpd = dev_to_genpd(dev);\n\tif (IS_ERR(genpd))\n\t\treturn -EINVAL;\n\n\tif (device_wakeup_path(dev) && genpd_is_active_wakeup(genpd))\n\t\treturn resume_noirq(dev);\n\n\tgenpd_lock(genpd);\n\tgenpd_sync_power_on(genpd, true, 0);\n\tgenpd->suspended_count--;\n\tgenpd_unlock(genpd);\n\n\tif (genpd->dev_ops.stop && genpd->dev_ops.start &&\n\t    !pm_runtime_status_suspended(dev)) {\n\t\tret = genpd_start_dev(genpd, dev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn pm_generic_resume_noirq(dev);\n}\n\n \nstatic int genpd_resume_noirq(struct device *dev)\n{\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\treturn genpd_finish_resume(dev, pm_generic_resume_noirq);\n}\n\n \nstatic int genpd_freeze_noirq(struct device *dev)\n{\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\treturn genpd_finish_suspend(dev,\n\t\t\t\t    pm_generic_freeze_noirq,\n\t\t\t\t    pm_generic_thaw_noirq);\n}\n\n \nstatic int genpd_thaw_noirq(struct device *dev)\n{\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\treturn genpd_finish_resume(dev, pm_generic_thaw_noirq);\n}\n\n \nstatic int genpd_poweroff_noirq(struct device *dev)\n{\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\treturn genpd_finish_suspend(dev,\n\t\t\t\t    pm_generic_poweroff_noirq,\n\t\t\t\t    pm_generic_restore_noirq);\n}\n\n \nstatic int genpd_restore_noirq(struct device *dev)\n{\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\treturn genpd_finish_resume(dev, pm_generic_restore_noirq);\n}\n\n \nstatic void genpd_complete(struct device *dev)\n{\n\tstruct generic_pm_domain *genpd;\n\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\tgenpd = dev_to_genpd(dev);\n\tif (IS_ERR(genpd))\n\t\treturn;\n\n\tpm_generic_complete(dev);\n\n\tgenpd_lock(genpd);\n\n\tgenpd->prepared_count--;\n\tif (!genpd->prepared_count)\n\t\tgenpd_queue_power_off_work(genpd);\n\n\tgenpd_unlock(genpd);\n}\n\nstatic void genpd_switch_state(struct device *dev, bool suspend)\n{\n\tstruct generic_pm_domain *genpd;\n\tbool use_lock;\n\n\tgenpd = dev_to_genpd_safe(dev);\n\tif (!genpd)\n\t\treturn;\n\n\tuse_lock = genpd_is_irq_safe(genpd);\n\n\tif (use_lock)\n\t\tgenpd_lock(genpd);\n\n\tif (suspend) {\n\t\tgenpd->suspended_count++;\n\t\tgenpd_sync_power_off(genpd, use_lock, 0);\n\t} else {\n\t\tgenpd_sync_power_on(genpd, use_lock, 0);\n\t\tgenpd->suspended_count--;\n\t}\n\n\tif (use_lock)\n\t\tgenpd_unlock(genpd);\n}\n\n \nvoid dev_pm_genpd_suspend(struct device *dev)\n{\n\tgenpd_switch_state(dev, true);\n}\nEXPORT_SYMBOL_GPL(dev_pm_genpd_suspend);\n\n \nvoid dev_pm_genpd_resume(struct device *dev)\n{\n\tgenpd_switch_state(dev, false);\n}\nEXPORT_SYMBOL_GPL(dev_pm_genpd_resume);\n\n#else  \n\n#define genpd_prepare\t\tNULL\n#define genpd_suspend_noirq\tNULL\n#define genpd_resume_noirq\tNULL\n#define genpd_freeze_noirq\tNULL\n#define genpd_thaw_noirq\tNULL\n#define genpd_poweroff_noirq\tNULL\n#define genpd_restore_noirq\tNULL\n#define genpd_complete\t\tNULL\n\n#endif  \n\nstatic struct generic_pm_domain_data *genpd_alloc_dev_data(struct device *dev,\n\t\t\t\t\t\t\t   bool has_governor)\n{\n\tstruct generic_pm_domain_data *gpd_data;\n\tstruct gpd_timing_data *td;\n\tint ret;\n\n\tret = dev_pm_get_subsys_data(dev);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tgpd_data = kzalloc(sizeof(*gpd_data), GFP_KERNEL);\n\tif (!gpd_data) {\n\t\tret = -ENOMEM;\n\t\tgoto err_put;\n\t}\n\n\tgpd_data->base.dev = dev;\n\tgpd_data->nb.notifier_call = genpd_dev_pm_qos_notifier;\n\n\t \n\tif (has_governor) {\n\t\ttd = kzalloc(sizeof(*td), GFP_KERNEL);\n\t\tif (!td) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_free;\n\t\t}\n\n\t\ttd->constraint_changed = true;\n\t\ttd->effective_constraint_ns = PM_QOS_RESUME_LATENCY_NO_CONSTRAINT_NS;\n\t\ttd->next_wakeup = KTIME_MAX;\n\t\tgpd_data->td = td;\n\t}\n\n\tspin_lock_irq(&dev->power.lock);\n\n\tif (dev->power.subsys_data->domain_data)\n\t\tret = -EINVAL;\n\telse\n\t\tdev->power.subsys_data->domain_data = &gpd_data->base;\n\n\tspin_unlock_irq(&dev->power.lock);\n\n\tif (ret)\n\t\tgoto err_free;\n\n\treturn gpd_data;\n\n err_free:\n\tkfree(gpd_data->td);\n\tkfree(gpd_data);\n err_put:\n\tdev_pm_put_subsys_data(dev);\n\treturn ERR_PTR(ret);\n}\n\nstatic void genpd_free_dev_data(struct device *dev,\n\t\t\t\tstruct generic_pm_domain_data *gpd_data)\n{\n\tspin_lock_irq(&dev->power.lock);\n\n\tdev->power.subsys_data->domain_data = NULL;\n\n\tspin_unlock_irq(&dev->power.lock);\n\n\tkfree(gpd_data->td);\n\tkfree(gpd_data);\n\tdev_pm_put_subsys_data(dev);\n}\n\nstatic void genpd_update_cpumask(struct generic_pm_domain *genpd,\n\t\t\t\t int cpu, bool set, unsigned int depth)\n{\n\tstruct gpd_link *link;\n\n\tif (!genpd_is_cpu_domain(genpd))\n\t\treturn;\n\n\tlist_for_each_entry(link, &genpd->child_links, child_node) {\n\t\tstruct generic_pm_domain *parent = link->parent;\n\n\t\tgenpd_lock_nested(parent, depth + 1);\n\t\tgenpd_update_cpumask(parent, cpu, set, depth + 1);\n\t\tgenpd_unlock(parent);\n\t}\n\n\tif (set)\n\t\tcpumask_set_cpu(cpu, genpd->cpus);\n\telse\n\t\tcpumask_clear_cpu(cpu, genpd->cpus);\n}\n\nstatic void genpd_set_cpumask(struct generic_pm_domain *genpd, int cpu)\n{\n\tif (cpu >= 0)\n\t\tgenpd_update_cpumask(genpd, cpu, true, 0);\n}\n\nstatic void genpd_clear_cpumask(struct generic_pm_domain *genpd, int cpu)\n{\n\tif (cpu >= 0)\n\t\tgenpd_update_cpumask(genpd, cpu, false, 0);\n}\n\nstatic int genpd_get_cpu(struct generic_pm_domain *genpd, struct device *dev)\n{\n\tint cpu;\n\n\tif (!genpd_is_cpu_domain(genpd))\n\t\treturn -1;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tif (get_cpu_device(cpu) == dev)\n\t\t\treturn cpu;\n\t}\n\n\treturn -1;\n}\n\nstatic int genpd_add_device(struct generic_pm_domain *genpd, struct device *dev,\n\t\t\t    struct device *base_dev)\n{\n\tstruct genpd_governor_data *gd = genpd->gd;\n\tstruct generic_pm_domain_data *gpd_data;\n\tint ret;\n\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\tgpd_data = genpd_alloc_dev_data(dev, gd);\n\tif (IS_ERR(gpd_data))\n\t\treturn PTR_ERR(gpd_data);\n\n\tgpd_data->cpu = genpd_get_cpu(genpd, base_dev);\n\n\tret = genpd->attach_dev ? genpd->attach_dev(genpd, dev) : 0;\n\tif (ret)\n\t\tgoto out;\n\n\tgenpd_lock(genpd);\n\n\tgenpd_set_cpumask(genpd, gpd_data->cpu);\n\tdev_pm_domain_set(dev, &genpd->domain);\n\n\tgenpd->device_count++;\n\tif (gd)\n\t\tgd->max_off_time_changed = true;\n\n\tlist_add_tail(&gpd_data->base.list_node, &genpd->dev_list);\n\n\tgenpd_unlock(genpd);\n out:\n\tif (ret)\n\t\tgenpd_free_dev_data(dev, gpd_data);\n\telse\n\t\tdev_pm_qos_add_notifier(dev, &gpd_data->nb,\n\t\t\t\t\tDEV_PM_QOS_RESUME_LATENCY);\n\n\treturn ret;\n}\n\n \nint pm_genpd_add_device(struct generic_pm_domain *genpd, struct device *dev)\n{\n\tint ret;\n\n\tif (!genpd || !dev)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&gpd_list_lock);\n\tret = genpd_add_device(genpd, dev, dev);\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(pm_genpd_add_device);\n\nstatic int genpd_remove_device(struct generic_pm_domain *genpd,\n\t\t\t       struct device *dev)\n{\n\tstruct generic_pm_domain_data *gpd_data;\n\tstruct pm_domain_data *pdd;\n\tint ret = 0;\n\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\tpdd = dev->power.subsys_data->domain_data;\n\tgpd_data = to_gpd_data(pdd);\n\tdev_pm_qos_remove_notifier(dev, &gpd_data->nb,\n\t\t\t\t   DEV_PM_QOS_RESUME_LATENCY);\n\n\tgenpd_lock(genpd);\n\n\tif (genpd->prepared_count > 0) {\n\t\tret = -EAGAIN;\n\t\tgoto out;\n\t}\n\n\tgenpd->device_count--;\n\tif (genpd->gd)\n\t\tgenpd->gd->max_off_time_changed = true;\n\n\tgenpd_clear_cpumask(genpd, gpd_data->cpu);\n\tdev_pm_domain_set(dev, NULL);\n\n\tlist_del_init(&pdd->list_node);\n\n\tgenpd_unlock(genpd);\n\n\tif (genpd->detach_dev)\n\t\tgenpd->detach_dev(genpd, dev);\n\n\tgenpd_free_dev_data(dev, gpd_data);\n\n\treturn 0;\n\n out:\n\tgenpd_unlock(genpd);\n\tdev_pm_qos_add_notifier(dev, &gpd_data->nb, DEV_PM_QOS_RESUME_LATENCY);\n\n\treturn ret;\n}\n\n \nint pm_genpd_remove_device(struct device *dev)\n{\n\tstruct generic_pm_domain *genpd = dev_to_genpd_safe(dev);\n\n\tif (!genpd)\n\t\treturn -EINVAL;\n\n\treturn genpd_remove_device(genpd, dev);\n}\nEXPORT_SYMBOL_GPL(pm_genpd_remove_device);\n\n \nint dev_pm_genpd_add_notifier(struct device *dev, struct notifier_block *nb)\n{\n\tstruct generic_pm_domain *genpd;\n\tstruct generic_pm_domain_data *gpd_data;\n\tint ret;\n\n\tgenpd = dev_to_genpd_safe(dev);\n\tif (!genpd)\n\t\treturn -ENODEV;\n\n\tif (WARN_ON(!dev->power.subsys_data ||\n\t\t     !dev->power.subsys_data->domain_data))\n\t\treturn -EINVAL;\n\n\tgpd_data = to_gpd_data(dev->power.subsys_data->domain_data);\n\tif (gpd_data->power_nb)\n\t\treturn -EEXIST;\n\n\tgenpd_lock(genpd);\n\tret = raw_notifier_chain_register(&genpd->power_notifiers, nb);\n\tgenpd_unlock(genpd);\n\n\tif (ret) {\n\t\tdev_warn(dev, \"failed to add notifier for PM domain %s\\n\",\n\t\t\t genpd->name);\n\t\treturn ret;\n\t}\n\n\tgpd_data->power_nb = nb;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(dev_pm_genpd_add_notifier);\n\n \nint dev_pm_genpd_remove_notifier(struct device *dev)\n{\n\tstruct generic_pm_domain *genpd;\n\tstruct generic_pm_domain_data *gpd_data;\n\tint ret;\n\n\tgenpd = dev_to_genpd_safe(dev);\n\tif (!genpd)\n\t\treturn -ENODEV;\n\n\tif (WARN_ON(!dev->power.subsys_data ||\n\t\t     !dev->power.subsys_data->domain_data))\n\t\treturn -EINVAL;\n\n\tgpd_data = to_gpd_data(dev->power.subsys_data->domain_data);\n\tif (!gpd_data->power_nb)\n\t\treturn -ENODEV;\n\n\tgenpd_lock(genpd);\n\tret = raw_notifier_chain_unregister(&genpd->power_notifiers,\n\t\t\t\t\t    gpd_data->power_nb);\n\tgenpd_unlock(genpd);\n\n\tif (ret) {\n\t\tdev_warn(dev, \"failed to remove notifier for PM domain %s\\n\",\n\t\t\t genpd->name);\n\t\treturn ret;\n\t}\n\n\tgpd_data->power_nb = NULL;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(dev_pm_genpd_remove_notifier);\n\nstatic int genpd_add_subdomain(struct generic_pm_domain *genpd,\n\t\t\t       struct generic_pm_domain *subdomain)\n{\n\tstruct gpd_link *link, *itr;\n\tint ret = 0;\n\n\tif (IS_ERR_OR_NULL(genpd) || IS_ERR_OR_NULL(subdomain)\n\t    || genpd == subdomain)\n\t\treturn -EINVAL;\n\n\t \n\tif (!genpd_is_irq_safe(genpd) && genpd_is_irq_safe(subdomain)) {\n\t\tWARN(1, \"Parent %s of subdomain %s must be IRQ safe\\n\",\n\t\t\t\tgenpd->name, subdomain->name);\n\t\treturn -EINVAL;\n\t}\n\n\tlink = kzalloc(sizeof(*link), GFP_KERNEL);\n\tif (!link)\n\t\treturn -ENOMEM;\n\n\tgenpd_lock(subdomain);\n\tgenpd_lock_nested(genpd, SINGLE_DEPTH_NESTING);\n\n\tif (!genpd_status_on(genpd) && genpd_status_on(subdomain)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tlist_for_each_entry(itr, &genpd->parent_links, parent_node) {\n\t\tif (itr->child == subdomain && itr->parent == genpd) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tlink->parent = genpd;\n\tlist_add_tail(&link->parent_node, &genpd->parent_links);\n\tlink->child = subdomain;\n\tlist_add_tail(&link->child_node, &subdomain->child_links);\n\tif (genpd_status_on(subdomain))\n\t\tgenpd_sd_counter_inc(genpd);\n\n out:\n\tgenpd_unlock(genpd);\n\tgenpd_unlock(subdomain);\n\tif (ret)\n\t\tkfree(link);\n\treturn ret;\n}\n\n \nint pm_genpd_add_subdomain(struct generic_pm_domain *genpd,\n\t\t\t   struct generic_pm_domain *subdomain)\n{\n\tint ret;\n\n\tmutex_lock(&gpd_list_lock);\n\tret = genpd_add_subdomain(genpd, subdomain);\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(pm_genpd_add_subdomain);\n\n \nint pm_genpd_remove_subdomain(struct generic_pm_domain *genpd,\n\t\t\t      struct generic_pm_domain *subdomain)\n{\n\tstruct gpd_link *l, *link;\n\tint ret = -EINVAL;\n\n\tif (IS_ERR_OR_NULL(genpd) || IS_ERR_OR_NULL(subdomain))\n\t\treturn -EINVAL;\n\n\tgenpd_lock(subdomain);\n\tgenpd_lock_nested(genpd, SINGLE_DEPTH_NESTING);\n\n\tif (!list_empty(&subdomain->parent_links) || subdomain->device_count) {\n\t\tpr_warn(\"%s: unable to remove subdomain %s\\n\",\n\t\t\tgenpd->name, subdomain->name);\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(link, l, &genpd->parent_links, parent_node) {\n\t\tif (link->child != subdomain)\n\t\t\tcontinue;\n\n\t\tlist_del(&link->parent_node);\n\t\tlist_del(&link->child_node);\n\t\tkfree(link);\n\t\tif (genpd_status_on(subdomain))\n\t\t\tgenpd_sd_counter_dec(genpd);\n\n\t\tret = 0;\n\t\tbreak;\n\t}\n\nout:\n\tgenpd_unlock(genpd);\n\tgenpd_unlock(subdomain);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(pm_genpd_remove_subdomain);\n\nstatic void genpd_free_default_power_state(struct genpd_power_state *states,\n\t\t\t\t\t   unsigned int state_count)\n{\n\tkfree(states);\n}\n\nstatic int genpd_set_default_power_state(struct generic_pm_domain *genpd)\n{\n\tstruct genpd_power_state *state;\n\n\tstate = kzalloc(sizeof(*state), GFP_KERNEL);\n\tif (!state)\n\t\treturn -ENOMEM;\n\n\tgenpd->states = state;\n\tgenpd->state_count = 1;\n\tgenpd->free_states = genpd_free_default_power_state;\n\n\treturn 0;\n}\n\nstatic int genpd_alloc_data(struct generic_pm_domain *genpd)\n{\n\tstruct genpd_governor_data *gd = NULL;\n\tint ret;\n\n\tif (genpd_is_cpu_domain(genpd) &&\n\t    !zalloc_cpumask_var(&genpd->cpus, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\tif (genpd->gov) {\n\t\tgd = kzalloc(sizeof(*gd), GFP_KERNEL);\n\t\tif (!gd) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto free;\n\t\t}\n\n\t\tgd->max_off_time_ns = -1;\n\t\tgd->max_off_time_changed = true;\n\t\tgd->next_wakeup = KTIME_MAX;\n\t\tgd->next_hrtimer = KTIME_MAX;\n\t}\n\n\t \n\tif (genpd->state_count == 0) {\n\t\tret = genpd_set_default_power_state(genpd);\n\t\tif (ret)\n\t\t\tgoto free;\n\t}\n\n\tgenpd->gd = gd;\n\treturn 0;\n\nfree:\n\tif (genpd_is_cpu_domain(genpd))\n\t\tfree_cpumask_var(genpd->cpus);\n\tkfree(gd);\n\treturn ret;\n}\n\nstatic void genpd_free_data(struct generic_pm_domain *genpd)\n{\n\tif (genpd_is_cpu_domain(genpd))\n\t\tfree_cpumask_var(genpd->cpus);\n\tif (genpd->free_states)\n\t\tgenpd->free_states(genpd->states, genpd->state_count);\n\tkfree(genpd->gd);\n}\n\nstatic void genpd_lock_init(struct generic_pm_domain *genpd)\n{\n\tif (genpd->flags & GENPD_FLAG_IRQ_SAFE) {\n\t\tspin_lock_init(&genpd->slock);\n\t\tgenpd->lock_ops = &genpd_spin_ops;\n\t} else {\n\t\tmutex_init(&genpd->mlock);\n\t\tgenpd->lock_ops = &genpd_mtx_ops;\n\t}\n}\n\n \nint pm_genpd_init(struct generic_pm_domain *genpd,\n\t\t  struct dev_power_governor *gov, bool is_off)\n{\n\tint ret;\n\n\tif (IS_ERR_OR_NULL(genpd))\n\t\treturn -EINVAL;\n\n\tINIT_LIST_HEAD(&genpd->parent_links);\n\tINIT_LIST_HEAD(&genpd->child_links);\n\tINIT_LIST_HEAD(&genpd->dev_list);\n\tRAW_INIT_NOTIFIER_HEAD(&genpd->power_notifiers);\n\tgenpd_lock_init(genpd);\n\tgenpd->gov = gov;\n\tINIT_WORK(&genpd->power_off_work, genpd_power_off_work_fn);\n\tatomic_set(&genpd->sd_count, 0);\n\tgenpd->status = is_off ? GENPD_STATE_OFF : GENPD_STATE_ON;\n\tgenpd->device_count = 0;\n\tgenpd->provider = NULL;\n\tgenpd->has_provider = false;\n\tgenpd->accounting_time = ktime_get_mono_fast_ns();\n\tgenpd->domain.ops.runtime_suspend = genpd_runtime_suspend;\n\tgenpd->domain.ops.runtime_resume = genpd_runtime_resume;\n\tgenpd->domain.ops.prepare = genpd_prepare;\n\tgenpd->domain.ops.suspend_noirq = genpd_suspend_noirq;\n\tgenpd->domain.ops.resume_noirq = genpd_resume_noirq;\n\tgenpd->domain.ops.freeze_noirq = genpd_freeze_noirq;\n\tgenpd->domain.ops.thaw_noirq = genpd_thaw_noirq;\n\tgenpd->domain.ops.poweroff_noirq = genpd_poweroff_noirq;\n\tgenpd->domain.ops.restore_noirq = genpd_restore_noirq;\n\tgenpd->domain.ops.complete = genpd_complete;\n\tgenpd->domain.start = genpd_dev_pm_start;\n\n\tif (genpd->flags & GENPD_FLAG_PM_CLK) {\n\t\tgenpd->dev_ops.stop = pm_clk_suspend;\n\t\tgenpd->dev_ops.start = pm_clk_resume;\n\t}\n\n\t \n\tif (gov == &pm_domain_always_on_gov)\n\t\tgenpd->flags |= GENPD_FLAG_RPM_ALWAYS_ON;\n\n\t \n\tif ((genpd_is_always_on(genpd) || genpd_is_rpm_always_on(genpd)) &&\n\t\t\t!genpd_status_on(genpd)) {\n\t\tpr_err(\"always-on PM domain %s is not on\\n\", genpd->name);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (!gov && genpd->state_count > 1)\n\t\tpr_warn(\"%s: no governor for states\\n\", genpd->name);\n\n\tret = genpd_alloc_data(genpd);\n\tif (ret)\n\t\treturn ret;\n\n\tdevice_initialize(&genpd->dev);\n\tdev_set_name(&genpd->dev, \"%s\", genpd->name);\n\n\tmutex_lock(&gpd_list_lock);\n\tlist_add(&genpd->gpd_list_node, &gpd_list);\n\tmutex_unlock(&gpd_list_lock);\n\tgenpd_debug_add(genpd);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(pm_genpd_init);\n\nstatic int genpd_remove(struct generic_pm_domain *genpd)\n{\n\tstruct gpd_link *l, *link;\n\n\tif (IS_ERR_OR_NULL(genpd))\n\t\treturn -EINVAL;\n\n\tgenpd_lock(genpd);\n\n\tif (genpd->has_provider) {\n\t\tgenpd_unlock(genpd);\n\t\tpr_err(\"Provider present, unable to remove %s\\n\", genpd->name);\n\t\treturn -EBUSY;\n\t}\n\n\tif (!list_empty(&genpd->parent_links) || genpd->device_count) {\n\t\tgenpd_unlock(genpd);\n\t\tpr_err(\"%s: unable to remove %s\\n\", __func__, genpd->name);\n\t\treturn -EBUSY;\n\t}\n\n\tlist_for_each_entry_safe(link, l, &genpd->child_links, child_node) {\n\t\tlist_del(&link->parent_node);\n\t\tlist_del(&link->child_node);\n\t\tkfree(link);\n\t}\n\n\tlist_del(&genpd->gpd_list_node);\n\tgenpd_unlock(genpd);\n\tgenpd_debug_remove(genpd);\n\tcancel_work_sync(&genpd->power_off_work);\n\tgenpd_free_data(genpd);\n\n\tpr_debug(\"%s: removed %s\\n\", __func__, genpd->name);\n\n\treturn 0;\n}\n\n \nint pm_genpd_remove(struct generic_pm_domain *genpd)\n{\n\tint ret;\n\n\tmutex_lock(&gpd_list_lock);\n\tret = genpd_remove(genpd);\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(pm_genpd_remove);\n\n#ifdef CONFIG_PM_GENERIC_DOMAINS_OF\n\n \n\n \nstruct of_genpd_provider {\n\tstruct list_head link;\n\tstruct device_node *node;\n\tgenpd_xlate_t xlate;\n\tvoid *data;\n};\n\n \nstatic LIST_HEAD(of_genpd_providers);\n \nstatic DEFINE_MUTEX(of_genpd_mutex);\n\n \nstatic struct generic_pm_domain *genpd_xlate_simple(\n\t\t\t\t\tstruct of_phandle_args *genpdspec,\n\t\t\t\t\tvoid *data)\n{\n\treturn data;\n}\n\n \nstatic struct generic_pm_domain *genpd_xlate_onecell(\n\t\t\t\t\tstruct of_phandle_args *genpdspec,\n\t\t\t\t\tvoid *data)\n{\n\tstruct genpd_onecell_data *genpd_data = data;\n\tunsigned int idx = genpdspec->args[0];\n\n\tif (genpdspec->args_count != 1)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (idx >= genpd_data->num_domains) {\n\t\tpr_err(\"%s: invalid domain index %u\\n\", __func__, idx);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!genpd_data->domains[idx])\n\t\treturn ERR_PTR(-ENOENT);\n\n\treturn genpd_data->domains[idx];\n}\n\n \nstatic int genpd_add_provider(struct device_node *np, genpd_xlate_t xlate,\n\t\t\t      void *data)\n{\n\tstruct of_genpd_provider *cp;\n\n\tcp = kzalloc(sizeof(*cp), GFP_KERNEL);\n\tif (!cp)\n\t\treturn -ENOMEM;\n\n\tcp->node = of_node_get(np);\n\tcp->data = data;\n\tcp->xlate = xlate;\n\tfwnode_dev_initialized(&np->fwnode, true);\n\n\tmutex_lock(&of_genpd_mutex);\n\tlist_add(&cp->link, &of_genpd_providers);\n\tmutex_unlock(&of_genpd_mutex);\n\tpr_debug(\"Added domain provider from %pOF\\n\", np);\n\n\treturn 0;\n}\n\nstatic bool genpd_present(const struct generic_pm_domain *genpd)\n{\n\tbool ret = false;\n\tconst struct generic_pm_domain *gpd;\n\n\tmutex_lock(&gpd_list_lock);\n\tlist_for_each_entry(gpd, &gpd_list, gpd_list_node) {\n\t\tif (gpd == genpd) {\n\t\t\tret = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn ret;\n}\n\n \nint of_genpd_add_provider_simple(struct device_node *np,\n\t\t\t\t struct generic_pm_domain *genpd)\n{\n\tint ret;\n\n\tif (!np || !genpd)\n\t\treturn -EINVAL;\n\n\tif (!genpd_present(genpd))\n\t\treturn -EINVAL;\n\n\tgenpd->dev.of_node = np;\n\n\t \n\tif (genpd->set_performance_state) {\n\t\tret = dev_pm_opp_of_add_table(&genpd->dev);\n\t\tif (ret)\n\t\t\treturn dev_err_probe(&genpd->dev, ret, \"Failed to add OPP table\\n\");\n\n\t\t \n\t\tgenpd->opp_table = dev_pm_opp_get_opp_table(&genpd->dev);\n\t\tWARN_ON(IS_ERR(genpd->opp_table));\n\t}\n\n\tret = genpd_add_provider(np, genpd_xlate_simple, genpd);\n\tif (ret) {\n\t\tif (genpd->set_performance_state) {\n\t\t\tdev_pm_opp_put_opp_table(genpd->opp_table);\n\t\t\tdev_pm_opp_of_remove_table(&genpd->dev);\n\t\t}\n\n\t\treturn ret;\n\t}\n\n\tgenpd->provider = &np->fwnode;\n\tgenpd->has_provider = true;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(of_genpd_add_provider_simple);\n\n \nint of_genpd_add_provider_onecell(struct device_node *np,\n\t\t\t\t  struct genpd_onecell_data *data)\n{\n\tstruct generic_pm_domain *genpd;\n\tunsigned int i;\n\tint ret = -EINVAL;\n\n\tif (!np || !data)\n\t\treturn -EINVAL;\n\n\tif (!data->xlate)\n\t\tdata->xlate = genpd_xlate_onecell;\n\n\tfor (i = 0; i < data->num_domains; i++) {\n\t\tgenpd = data->domains[i];\n\n\t\tif (!genpd)\n\t\t\tcontinue;\n\t\tif (!genpd_present(genpd))\n\t\t\tgoto error;\n\n\t\tgenpd->dev.of_node = np;\n\n\t\t \n\t\tif (genpd->set_performance_state) {\n\t\t\tret = dev_pm_opp_of_add_table_indexed(&genpd->dev, i);\n\t\t\tif (ret) {\n\t\t\t\tdev_err_probe(&genpd->dev, ret,\n\t\t\t\t\t      \"Failed to add OPP table for index %d\\n\", i);\n\t\t\t\tgoto error;\n\t\t\t}\n\n\t\t\t \n\t\t\tgenpd->opp_table = dev_pm_opp_get_opp_table(&genpd->dev);\n\t\t\tWARN_ON(IS_ERR(genpd->opp_table));\n\t\t}\n\n\t\tgenpd->provider = &np->fwnode;\n\t\tgenpd->has_provider = true;\n\t}\n\n\tret = genpd_add_provider(np, data->xlate, data);\n\tif (ret < 0)\n\t\tgoto error;\n\n\treturn 0;\n\nerror:\n\twhile (i--) {\n\t\tgenpd = data->domains[i];\n\n\t\tif (!genpd)\n\t\t\tcontinue;\n\n\t\tgenpd->provider = NULL;\n\t\tgenpd->has_provider = false;\n\n\t\tif (genpd->set_performance_state) {\n\t\t\tdev_pm_opp_put_opp_table(genpd->opp_table);\n\t\t\tdev_pm_opp_of_remove_table(&genpd->dev);\n\t\t}\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(of_genpd_add_provider_onecell);\n\n \nvoid of_genpd_del_provider(struct device_node *np)\n{\n\tstruct of_genpd_provider *cp, *tmp;\n\tstruct generic_pm_domain *gpd;\n\n\tmutex_lock(&gpd_list_lock);\n\tmutex_lock(&of_genpd_mutex);\n\tlist_for_each_entry_safe(cp, tmp, &of_genpd_providers, link) {\n\t\tif (cp->node == np) {\n\t\t\t \n\t\t\tlist_for_each_entry(gpd, &gpd_list, gpd_list_node) {\n\t\t\t\tif (gpd->provider == &np->fwnode) {\n\t\t\t\t\tgpd->has_provider = false;\n\n\t\t\t\t\tif (!gpd->set_performance_state)\n\t\t\t\t\t\tcontinue;\n\n\t\t\t\t\tdev_pm_opp_put_opp_table(gpd->opp_table);\n\t\t\t\t\tdev_pm_opp_of_remove_table(&gpd->dev);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfwnode_dev_initialized(&cp->node->fwnode, false);\n\t\t\tlist_del(&cp->link);\n\t\t\tof_node_put(cp->node);\n\t\t\tkfree(cp);\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&of_genpd_mutex);\n\tmutex_unlock(&gpd_list_lock);\n}\nEXPORT_SYMBOL_GPL(of_genpd_del_provider);\n\n \nstatic struct generic_pm_domain *genpd_get_from_provider(\n\t\t\t\t\tstruct of_phandle_args *genpdspec)\n{\n\tstruct generic_pm_domain *genpd = ERR_PTR(-ENOENT);\n\tstruct of_genpd_provider *provider;\n\n\tif (!genpdspec)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tmutex_lock(&of_genpd_mutex);\n\n\t \n\tlist_for_each_entry(provider, &of_genpd_providers, link) {\n\t\tif (provider->node == genpdspec->np)\n\t\t\tgenpd = provider->xlate(genpdspec, provider->data);\n\t\tif (!IS_ERR(genpd))\n\t\t\tbreak;\n\t}\n\n\tmutex_unlock(&of_genpd_mutex);\n\n\treturn genpd;\n}\n\n \nint of_genpd_add_device(struct of_phandle_args *genpdspec, struct device *dev)\n{\n\tstruct generic_pm_domain *genpd;\n\tint ret;\n\n\tif (!dev)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&gpd_list_lock);\n\n\tgenpd = genpd_get_from_provider(genpdspec);\n\tif (IS_ERR(genpd)) {\n\t\tret = PTR_ERR(genpd);\n\t\tgoto out;\n\t}\n\n\tret = genpd_add_device(genpd, dev, dev);\n\nout:\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(of_genpd_add_device);\n\n \nint of_genpd_add_subdomain(struct of_phandle_args *parent_spec,\n\t\t\t   struct of_phandle_args *subdomain_spec)\n{\n\tstruct generic_pm_domain *parent, *subdomain;\n\tint ret;\n\n\tmutex_lock(&gpd_list_lock);\n\n\tparent = genpd_get_from_provider(parent_spec);\n\tif (IS_ERR(parent)) {\n\t\tret = PTR_ERR(parent);\n\t\tgoto out;\n\t}\n\n\tsubdomain = genpd_get_from_provider(subdomain_spec);\n\tif (IS_ERR(subdomain)) {\n\t\tret = PTR_ERR(subdomain);\n\t\tgoto out;\n\t}\n\n\tret = genpd_add_subdomain(parent, subdomain);\n\nout:\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn ret == -ENOENT ? -EPROBE_DEFER : ret;\n}\nEXPORT_SYMBOL_GPL(of_genpd_add_subdomain);\n\n \nint of_genpd_remove_subdomain(struct of_phandle_args *parent_spec,\n\t\t\t      struct of_phandle_args *subdomain_spec)\n{\n\tstruct generic_pm_domain *parent, *subdomain;\n\tint ret;\n\n\tmutex_lock(&gpd_list_lock);\n\n\tparent = genpd_get_from_provider(parent_spec);\n\tif (IS_ERR(parent)) {\n\t\tret = PTR_ERR(parent);\n\t\tgoto out;\n\t}\n\n\tsubdomain = genpd_get_from_provider(subdomain_spec);\n\tif (IS_ERR(subdomain)) {\n\t\tret = PTR_ERR(subdomain);\n\t\tgoto out;\n\t}\n\n\tret = pm_genpd_remove_subdomain(parent, subdomain);\n\nout:\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(of_genpd_remove_subdomain);\n\n \nstruct generic_pm_domain *of_genpd_remove_last(struct device_node *np)\n{\n\tstruct generic_pm_domain *gpd, *tmp, *genpd = ERR_PTR(-ENOENT);\n\tint ret;\n\n\tif (IS_ERR_OR_NULL(np))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tmutex_lock(&gpd_list_lock);\n\tlist_for_each_entry_safe(gpd, tmp, &gpd_list, gpd_list_node) {\n\t\tif (gpd->provider == &np->fwnode) {\n\t\t\tret = genpd_remove(gpd);\n\t\t\tgenpd = ret ? ERR_PTR(ret) : gpd;\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn genpd;\n}\nEXPORT_SYMBOL_GPL(of_genpd_remove_last);\n\nstatic void genpd_release_dev(struct device *dev)\n{\n\tof_node_put(dev->of_node);\n\tkfree(dev);\n}\n\nstatic struct bus_type genpd_bus_type = {\n\t.name\t\t= \"genpd\",\n};\n\n \nstatic void genpd_dev_pm_detach(struct device *dev, bool power_off)\n{\n\tstruct generic_pm_domain *pd;\n\tunsigned int i;\n\tint ret = 0;\n\n\tpd = dev_to_genpd(dev);\n\tif (IS_ERR(pd))\n\t\treturn;\n\n\tdev_dbg(dev, \"removing from PM domain %s\\n\", pd->name);\n\n\t \n\tif (dev_gpd_data(dev)->default_pstate) {\n\t\tdev_pm_genpd_set_performance_state(dev, 0);\n\t\tdev_gpd_data(dev)->default_pstate = 0;\n\t}\n\n\tfor (i = 1; i < GENPD_RETRY_MAX_MS; i <<= 1) {\n\t\tret = genpd_remove_device(pd, dev);\n\t\tif (ret != -EAGAIN)\n\t\t\tbreak;\n\n\t\tmdelay(i);\n\t\tcond_resched();\n\t}\n\n\tif (ret < 0) {\n\t\tdev_err(dev, \"failed to remove from PM domain %s: %d\",\n\t\t\tpd->name, ret);\n\t\treturn;\n\t}\n\n\t \n\tgenpd_queue_power_off_work(pd);\n\n\t \n\tif (dev->bus == &genpd_bus_type)\n\t\tdevice_unregister(dev);\n}\n\nstatic void genpd_dev_pm_sync(struct device *dev)\n{\n\tstruct generic_pm_domain *pd;\n\n\tpd = dev_to_genpd(dev);\n\tif (IS_ERR(pd))\n\t\treturn;\n\n\tgenpd_queue_power_off_work(pd);\n}\n\nstatic int __genpd_dev_pm_attach(struct device *dev, struct device *base_dev,\n\t\t\t\t unsigned int index, bool power_on)\n{\n\tstruct of_phandle_args pd_args;\n\tstruct generic_pm_domain *pd;\n\tint pstate;\n\tint ret;\n\n\tret = of_parse_phandle_with_args(dev->of_node, \"power-domains\",\n\t\t\t\t\"#power-domain-cells\", index, &pd_args);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&gpd_list_lock);\n\tpd = genpd_get_from_provider(&pd_args);\n\tof_node_put(pd_args.np);\n\tif (IS_ERR(pd)) {\n\t\tmutex_unlock(&gpd_list_lock);\n\t\tdev_dbg(dev, \"%s() failed to find PM domain: %ld\\n\",\n\t\t\t__func__, PTR_ERR(pd));\n\t\treturn driver_deferred_probe_check_state(base_dev);\n\t}\n\n\tdev_dbg(dev, \"adding to PM domain %s\\n\", pd->name);\n\n\tret = genpd_add_device(pd, dev, base_dev);\n\tmutex_unlock(&gpd_list_lock);\n\n\tif (ret < 0)\n\t\treturn dev_err_probe(dev, ret, \"failed to add to PM domain %s\\n\", pd->name);\n\n\tdev->pm_domain->detach = genpd_dev_pm_detach;\n\tdev->pm_domain->sync = genpd_dev_pm_sync;\n\n\t \n\tpstate = of_get_required_opp_performance_state(dev->of_node, index);\n\tif (pstate < 0 && pstate != -ENODEV && pstate != -EOPNOTSUPP) {\n\t\tret = pstate;\n\t\tgoto err;\n\t} else if (pstate > 0) {\n\t\tret = dev_pm_genpd_set_performance_state(dev, pstate);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tdev_gpd_data(dev)->default_pstate = pstate;\n\t}\n\n\tif (power_on) {\n\t\tgenpd_lock(pd);\n\t\tret = genpd_power_on(pd, 0);\n\t\tgenpd_unlock(pd);\n\t}\n\n\tif (ret) {\n\t\t \n\t\tif (dev_gpd_data(dev)->default_pstate) {\n\t\t\tdev_pm_genpd_set_performance_state(dev, 0);\n\t\t\tdev_gpd_data(dev)->default_pstate = 0;\n\t\t}\n\n\t\tgenpd_remove_device(pd, dev);\n\t\treturn -EPROBE_DEFER;\n\t}\n\n\treturn 1;\n\nerr:\n\tdev_err(dev, \"failed to set required performance state for power-domain %s: %d\\n\",\n\t\tpd->name, ret);\n\tgenpd_remove_device(pd, dev);\n\treturn ret;\n}\n\n \nint genpd_dev_pm_attach(struct device *dev)\n{\n\tif (!dev->of_node)\n\t\treturn 0;\n\n\t \n\tif (of_count_phandle_with_args(dev->of_node, \"power-domains\",\n\t\t\t\t       \"#power-domain-cells\") != 1)\n\t\treturn 0;\n\n\treturn __genpd_dev_pm_attach(dev, dev, 0, true);\n}\nEXPORT_SYMBOL_GPL(genpd_dev_pm_attach);\n\n \nstruct device *genpd_dev_pm_attach_by_id(struct device *dev,\n\t\t\t\t\t unsigned int index)\n{\n\tstruct device *virt_dev;\n\tint num_domains;\n\tint ret;\n\n\tif (!dev->of_node)\n\t\treturn NULL;\n\n\t \n\tnum_domains = of_count_phandle_with_args(dev->of_node, \"power-domains\",\n\t\t\t\t\t\t \"#power-domain-cells\");\n\tif (index >= num_domains)\n\t\treturn NULL;\n\n\t \n\tvirt_dev = kzalloc(sizeof(*virt_dev), GFP_KERNEL);\n\tif (!virt_dev)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tdev_set_name(virt_dev, \"genpd:%u:%s\", index, dev_name(dev));\n\tvirt_dev->bus = &genpd_bus_type;\n\tvirt_dev->release = genpd_release_dev;\n\tvirt_dev->of_node = of_node_get(dev->of_node);\n\n\tret = device_register(virt_dev);\n\tif (ret) {\n\t\tput_device(virt_dev);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\t \n\tret = __genpd_dev_pm_attach(virt_dev, dev, index, false);\n\tif (ret < 1) {\n\t\tdevice_unregister(virt_dev);\n\t\treturn ret ? ERR_PTR(ret) : NULL;\n\t}\n\n\tpm_runtime_enable(virt_dev);\n\tgenpd_queue_power_off_work(dev_to_genpd(virt_dev));\n\n\treturn virt_dev;\n}\nEXPORT_SYMBOL_GPL(genpd_dev_pm_attach_by_id);\n\n \nstruct device *genpd_dev_pm_attach_by_name(struct device *dev, const char *name)\n{\n\tint index;\n\n\tif (!dev->of_node)\n\t\treturn NULL;\n\n\tindex = of_property_match_string(dev->of_node, \"power-domain-names\",\n\t\t\t\t\t name);\n\tif (index < 0)\n\t\treturn NULL;\n\n\treturn genpd_dev_pm_attach_by_id(dev, index);\n}\n\nstatic const struct of_device_id idle_state_match[] = {\n\t{ .compatible = \"domain-idle-state\", },\n\t{ }\n};\n\nstatic int genpd_parse_state(struct genpd_power_state *genpd_state,\n\t\t\t\t    struct device_node *state_node)\n{\n\tint err;\n\tu32 residency;\n\tu32 entry_latency, exit_latency;\n\n\terr = of_property_read_u32(state_node, \"entry-latency-us\",\n\t\t\t\t\t\t&entry_latency);\n\tif (err) {\n\t\tpr_debug(\" * %pOF missing entry-latency-us property\\n\",\n\t\t\t state_node);\n\t\treturn -EINVAL;\n\t}\n\n\terr = of_property_read_u32(state_node, \"exit-latency-us\",\n\t\t\t\t\t\t&exit_latency);\n\tif (err) {\n\t\tpr_debug(\" * %pOF missing exit-latency-us property\\n\",\n\t\t\t state_node);\n\t\treturn -EINVAL;\n\t}\n\n\terr = of_property_read_u32(state_node, \"min-residency-us\", &residency);\n\tif (!err)\n\t\tgenpd_state->residency_ns = 1000LL * residency;\n\n\tgenpd_state->power_on_latency_ns = 1000LL * exit_latency;\n\tgenpd_state->power_off_latency_ns = 1000LL * entry_latency;\n\tgenpd_state->fwnode = &state_node->fwnode;\n\n\treturn 0;\n}\n\nstatic int genpd_iterate_idle_states(struct device_node *dn,\n\t\t\t\t     struct genpd_power_state *states)\n{\n\tint ret;\n\tstruct of_phandle_iterator it;\n\tstruct device_node *np;\n\tint i = 0;\n\n\tret = of_count_phandle_with_args(dn, \"domain-idle-states\", NULL);\n\tif (ret <= 0)\n\t\treturn ret == -ENOENT ? 0 : ret;\n\n\t \n\tof_for_each_phandle(&it, ret, dn, \"domain-idle-states\", NULL, 0) {\n\t\tnp = it.node;\n\t\tif (!of_match_node(idle_state_match, np))\n\t\t\tcontinue;\n\n\t\tif (!of_device_is_available(np))\n\t\t\tcontinue;\n\n\t\tif (states) {\n\t\t\tret = genpd_parse_state(&states[i], np);\n\t\t\tif (ret) {\n\t\t\t\tpr_err(\"Parsing idle state node %pOF failed with err %d\\n\",\n\t\t\t\t       np, ret);\n\t\t\t\tof_node_put(np);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t\ti++;\n\t}\n\n\treturn i;\n}\n\n \nint of_genpd_parse_idle_states(struct device_node *dn,\n\t\t\tstruct genpd_power_state **states, int *n)\n{\n\tstruct genpd_power_state *st;\n\tint ret;\n\n\tret = genpd_iterate_idle_states(dn, NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (!ret) {\n\t\t*states = NULL;\n\t\t*n = 0;\n\t\treturn 0;\n\t}\n\n\tst = kcalloc(ret, sizeof(*st), GFP_KERNEL);\n\tif (!st)\n\t\treturn -ENOMEM;\n\n\tret = genpd_iterate_idle_states(dn, st);\n\tif (ret <= 0) {\n\t\tkfree(st);\n\t\treturn ret < 0 ? ret : -EINVAL;\n\t}\n\n\t*states = st;\n\t*n = ret;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(of_genpd_parse_idle_states);\n\n \nunsigned int pm_genpd_opp_to_performance_state(struct device *genpd_dev,\n\t\t\t\t\t       struct dev_pm_opp *opp)\n{\n\tstruct generic_pm_domain *genpd = NULL;\n\tint state;\n\n\tgenpd = container_of(genpd_dev, struct generic_pm_domain, dev);\n\n\tif (unlikely(!genpd->opp_to_performance_state))\n\t\treturn 0;\n\n\tgenpd_lock(genpd);\n\tstate = genpd->opp_to_performance_state(genpd, opp);\n\tgenpd_unlock(genpd);\n\n\treturn state;\n}\nEXPORT_SYMBOL_GPL(pm_genpd_opp_to_performance_state);\n\nstatic int __init genpd_bus_init(void)\n{\n\treturn bus_register(&genpd_bus_type);\n}\ncore_initcall(genpd_bus_init);\n\n#endif  \n\n\n \n\n#ifdef CONFIG_DEBUG_FS\n \nstatic void rtpm_status_str(struct seq_file *s, struct device *dev)\n{\n\tstatic const char * const status_lookup[] = {\n\t\t[RPM_ACTIVE] = \"active\",\n\t\t[RPM_RESUMING] = \"resuming\",\n\t\t[RPM_SUSPENDED] = \"suspended\",\n\t\t[RPM_SUSPENDING] = \"suspending\"\n\t};\n\tconst char *p = \"\";\n\n\tif (dev->power.runtime_error)\n\t\tp = \"error\";\n\telse if (dev->power.disable_depth)\n\t\tp = \"unsupported\";\n\telse if (dev->power.runtime_status < ARRAY_SIZE(status_lookup))\n\t\tp = status_lookup[dev->power.runtime_status];\n\telse\n\t\tWARN_ON(1);\n\n\tseq_printf(s, \"%-25s  \", p);\n}\n\nstatic void perf_status_str(struct seq_file *s, struct device *dev)\n{\n\tstruct generic_pm_domain_data *gpd_data;\n\n\tgpd_data = to_gpd_data(dev->power.subsys_data->domain_data);\n\tseq_put_decimal_ull(s, \"\", gpd_data->performance_state);\n}\n\nstatic int genpd_summary_one(struct seq_file *s,\n\t\t\tstruct generic_pm_domain *genpd)\n{\n\tstatic const char * const status_lookup[] = {\n\t\t[GENPD_STATE_ON] = \"on\",\n\t\t[GENPD_STATE_OFF] = \"off\"\n\t};\n\tstruct pm_domain_data *pm_data;\n\tconst char *kobj_path;\n\tstruct gpd_link *link;\n\tchar state[16];\n\tint ret;\n\n\tret = genpd_lock_interruptible(genpd);\n\tif (ret)\n\t\treturn -ERESTARTSYS;\n\n\tif (WARN_ON(genpd->status >= ARRAY_SIZE(status_lookup)))\n\t\tgoto exit;\n\tif (!genpd_status_on(genpd))\n\t\tsnprintf(state, sizeof(state), \"%s-%u\",\n\t\t\t status_lookup[genpd->status], genpd->state_idx);\n\telse\n\t\tsnprintf(state, sizeof(state), \"%s\",\n\t\t\t status_lookup[genpd->status]);\n\tseq_printf(s, \"%-30s  %-50s %u\", genpd->name, state, genpd->performance_state);\n\n\t \n\tlist_for_each_entry(link, &genpd->parent_links, parent_node) {\n\t\tif (list_is_first(&link->parent_node, &genpd->parent_links))\n\t\t\tseq_printf(s, \"\\n%48s\", \" \");\n\t\tseq_printf(s, \"%s\", link->child->name);\n\t\tif (!list_is_last(&link->parent_node, &genpd->parent_links))\n\t\t\tseq_puts(s, \", \");\n\t}\n\n\tlist_for_each_entry(pm_data, &genpd->dev_list, list_node) {\n\t\tkobj_path = kobject_get_path(&pm_data->dev->kobj,\n\t\t\t\tgenpd_is_irq_safe(genpd) ?\n\t\t\t\tGFP_ATOMIC : GFP_KERNEL);\n\t\tif (kobj_path == NULL)\n\t\t\tcontinue;\n\n\t\tseq_printf(s, \"\\n    %-50s  \", kobj_path);\n\t\trtpm_status_str(s, pm_data->dev);\n\t\tperf_status_str(s, pm_data->dev);\n\t\tkfree(kobj_path);\n\t}\n\n\tseq_puts(s, \"\\n\");\nexit:\n\tgenpd_unlock(genpd);\n\n\treturn 0;\n}\n\nstatic int summary_show(struct seq_file *s, void *data)\n{\n\tstruct generic_pm_domain *genpd;\n\tint ret = 0;\n\n\tseq_puts(s, \"domain                          status          children                           performance\\n\");\n\tseq_puts(s, \"    /device                                             runtime status\\n\");\n\tseq_puts(s, \"----------------------------------------------------------------------------------------------\\n\");\n\n\tret = mutex_lock_interruptible(&gpd_list_lock);\n\tif (ret)\n\t\treturn -ERESTARTSYS;\n\n\tlist_for_each_entry(genpd, &gpd_list, gpd_list_node) {\n\t\tret = genpd_summary_one(s, genpd);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(&gpd_list_lock);\n\n\treturn ret;\n}\n\nstatic int status_show(struct seq_file *s, void *data)\n{\n\tstatic const char * const status_lookup[] = {\n\t\t[GENPD_STATE_ON] = \"on\",\n\t\t[GENPD_STATE_OFF] = \"off\"\n\t};\n\n\tstruct generic_pm_domain *genpd = s->private;\n\tint ret = 0;\n\n\tret = genpd_lock_interruptible(genpd);\n\tif (ret)\n\t\treturn -ERESTARTSYS;\n\n\tif (WARN_ON_ONCE(genpd->status >= ARRAY_SIZE(status_lookup)))\n\t\tgoto exit;\n\n\tif (genpd->status == GENPD_STATE_OFF)\n\t\tseq_printf(s, \"%s-%u\\n\", status_lookup[genpd->status],\n\t\t\tgenpd->state_idx);\n\telse\n\t\tseq_printf(s, \"%s\\n\", status_lookup[genpd->status]);\nexit:\n\tgenpd_unlock(genpd);\n\treturn ret;\n}\n\nstatic int sub_domains_show(struct seq_file *s, void *data)\n{\n\tstruct generic_pm_domain *genpd = s->private;\n\tstruct gpd_link *link;\n\tint ret = 0;\n\n\tret = genpd_lock_interruptible(genpd);\n\tif (ret)\n\t\treturn -ERESTARTSYS;\n\n\tlist_for_each_entry(link, &genpd->parent_links, parent_node)\n\t\tseq_printf(s, \"%s\\n\", link->child->name);\n\n\tgenpd_unlock(genpd);\n\treturn ret;\n}\n\nstatic int idle_states_show(struct seq_file *s, void *data)\n{\n\tstruct generic_pm_domain *genpd = s->private;\n\tu64 now, delta, idle_time = 0;\n\tunsigned int i;\n\tint ret = 0;\n\n\tret = genpd_lock_interruptible(genpd);\n\tif (ret)\n\t\treturn -ERESTARTSYS;\n\n\tseq_puts(s, \"State          Time Spent(ms) Usage          Rejected\\n\");\n\n\tfor (i = 0; i < genpd->state_count; i++) {\n\t\tidle_time += genpd->states[i].idle_time;\n\n\t\tif (genpd->status == GENPD_STATE_OFF && genpd->state_idx == i) {\n\t\t\tnow = ktime_get_mono_fast_ns();\n\t\t\tif (now > genpd->accounting_time) {\n\t\t\t\tdelta = now - genpd->accounting_time;\n\t\t\t\tidle_time += delta;\n\t\t\t}\n\t\t}\n\n\t\tdo_div(idle_time, NSEC_PER_MSEC);\n\t\tseq_printf(s, \"S%-13i %-14llu %-14llu %llu\\n\", i, idle_time,\n\t\t\t   genpd->states[i].usage, genpd->states[i].rejected);\n\t}\n\n\tgenpd_unlock(genpd);\n\treturn ret;\n}\n\nstatic int active_time_show(struct seq_file *s, void *data)\n{\n\tstruct generic_pm_domain *genpd = s->private;\n\tu64 now, on_time, delta = 0;\n\tint ret = 0;\n\n\tret = genpd_lock_interruptible(genpd);\n\tif (ret)\n\t\treturn -ERESTARTSYS;\n\n\tif (genpd->status == GENPD_STATE_ON) {\n\t\tnow = ktime_get_mono_fast_ns();\n\t\tif (now > genpd->accounting_time)\n\t\t\tdelta = now - genpd->accounting_time;\n\t}\n\n\ton_time = genpd->on_time + delta;\n\tdo_div(on_time, NSEC_PER_MSEC);\n\tseq_printf(s, \"%llu ms\\n\", on_time);\n\n\tgenpd_unlock(genpd);\n\treturn ret;\n}\n\nstatic int total_idle_time_show(struct seq_file *s, void *data)\n{\n\tstruct generic_pm_domain *genpd = s->private;\n\tu64 now, delta, total = 0;\n\tunsigned int i;\n\tint ret = 0;\n\n\tret = genpd_lock_interruptible(genpd);\n\tif (ret)\n\t\treturn -ERESTARTSYS;\n\n\tfor (i = 0; i < genpd->state_count; i++) {\n\t\ttotal += genpd->states[i].idle_time;\n\n\t\tif (genpd->status == GENPD_STATE_OFF && genpd->state_idx == i) {\n\t\t\tnow = ktime_get_mono_fast_ns();\n\t\t\tif (now > genpd->accounting_time) {\n\t\t\t\tdelta = now - genpd->accounting_time;\n\t\t\t\ttotal += delta;\n\t\t\t}\n\t\t}\n\t}\n\n\tdo_div(total, NSEC_PER_MSEC);\n\tseq_printf(s, \"%llu ms\\n\", total);\n\n\tgenpd_unlock(genpd);\n\treturn ret;\n}\n\n\nstatic int devices_show(struct seq_file *s, void *data)\n{\n\tstruct generic_pm_domain *genpd = s->private;\n\tstruct pm_domain_data *pm_data;\n\tconst char *kobj_path;\n\tint ret = 0;\n\n\tret = genpd_lock_interruptible(genpd);\n\tif (ret)\n\t\treturn -ERESTARTSYS;\n\n\tlist_for_each_entry(pm_data, &genpd->dev_list, list_node) {\n\t\tkobj_path = kobject_get_path(&pm_data->dev->kobj,\n\t\t\t\tgenpd_is_irq_safe(genpd) ?\n\t\t\t\tGFP_ATOMIC : GFP_KERNEL);\n\t\tif (kobj_path == NULL)\n\t\t\tcontinue;\n\n\t\tseq_printf(s, \"%s\\n\", kobj_path);\n\t\tkfree(kobj_path);\n\t}\n\n\tgenpd_unlock(genpd);\n\treturn ret;\n}\n\nstatic int perf_state_show(struct seq_file *s, void *data)\n{\n\tstruct generic_pm_domain *genpd = s->private;\n\n\tif (genpd_lock_interruptible(genpd))\n\t\treturn -ERESTARTSYS;\n\n\tseq_printf(s, \"%u\\n\", genpd->performance_state);\n\n\tgenpd_unlock(genpd);\n\treturn 0;\n}\n\nDEFINE_SHOW_ATTRIBUTE(summary);\nDEFINE_SHOW_ATTRIBUTE(status);\nDEFINE_SHOW_ATTRIBUTE(sub_domains);\nDEFINE_SHOW_ATTRIBUTE(idle_states);\nDEFINE_SHOW_ATTRIBUTE(active_time);\nDEFINE_SHOW_ATTRIBUTE(total_idle_time);\nDEFINE_SHOW_ATTRIBUTE(devices);\nDEFINE_SHOW_ATTRIBUTE(perf_state);\n\nstatic void genpd_debug_add(struct generic_pm_domain *genpd)\n{\n\tstruct dentry *d;\n\n\tif (!genpd_debugfs_dir)\n\t\treturn;\n\n\td = debugfs_create_dir(genpd->name, genpd_debugfs_dir);\n\n\tdebugfs_create_file(\"current_state\", 0444,\n\t\t\t    d, genpd, &status_fops);\n\tdebugfs_create_file(\"sub_domains\", 0444,\n\t\t\t    d, genpd, &sub_domains_fops);\n\tdebugfs_create_file(\"idle_states\", 0444,\n\t\t\t    d, genpd, &idle_states_fops);\n\tdebugfs_create_file(\"active_time\", 0444,\n\t\t\t    d, genpd, &active_time_fops);\n\tdebugfs_create_file(\"total_idle_time\", 0444,\n\t\t\t    d, genpd, &total_idle_time_fops);\n\tdebugfs_create_file(\"devices\", 0444,\n\t\t\t    d, genpd, &devices_fops);\n\tif (genpd->set_performance_state)\n\t\tdebugfs_create_file(\"perf_state\", 0444,\n\t\t\t\t    d, genpd, &perf_state_fops);\n}\n\nstatic int __init genpd_debug_init(void)\n{\n\tstruct generic_pm_domain *genpd;\n\n\tgenpd_debugfs_dir = debugfs_create_dir(\"pm_genpd\", NULL);\n\n\tdebugfs_create_file(\"pm_genpd_summary\", S_IRUGO, genpd_debugfs_dir,\n\t\t\t    NULL, &summary_fops);\n\n\tlist_for_each_entry(genpd, &gpd_list, gpd_list_node)\n\t\tgenpd_debug_add(genpd);\n\n\treturn 0;\n}\nlate_initcall(genpd_debug_init);\n\nstatic void __exit genpd_debug_exit(void)\n{\n\tdebugfs_remove_recursive(genpd_debugfs_dir);\n}\n__exitcall(genpd_debug_exit);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}