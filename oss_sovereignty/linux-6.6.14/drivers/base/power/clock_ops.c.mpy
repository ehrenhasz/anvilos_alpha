{
  "module_name": "clock_ops.c",
  "hash_id": "f953f469ca4ee3ce6fc7b94f38c3370cb9ceb059e01a78d5fead86f3e5ab20b2",
  "original_prompt": "Ingested from linux-6.6.14/drivers/base/power/clock_ops.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/device.h>\n#include <linux/io.h>\n#include <linux/pm.h>\n#include <linux/pm_clock.h>\n#include <linux/clk.h>\n#include <linux/clkdev.h>\n#include <linux/of_clk.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/pm_domain.h>\n#include <linux/pm_runtime.h>\n\n#ifdef CONFIG_PM_CLK\n\nenum pce_status {\n\tPCE_STATUS_NONE = 0,\n\tPCE_STATUS_ACQUIRED,\n\tPCE_STATUS_PREPARED,\n\tPCE_STATUS_ENABLED,\n\tPCE_STATUS_ERROR,\n};\n\nstruct pm_clock_entry {\n\tstruct list_head node;\n\tchar *con_id;\n\tstruct clk *clk;\n\tenum pce_status status;\n\tbool enabled_when_prepared;\n};\n\n \nstatic void pm_clk_list_lock(struct pm_subsys_data *psd)\n\t__acquires(&psd->lock)\n{\n\tmutex_lock(&psd->clock_mutex);\n\tspin_lock_irq(&psd->lock);\n}\n\n \nstatic void pm_clk_list_unlock(struct pm_subsys_data *psd)\n\t__releases(&psd->lock)\n{\n\tspin_unlock_irq(&psd->lock);\n\tmutex_unlock(&psd->clock_mutex);\n}\n\n \nstatic int pm_clk_op_lock(struct pm_subsys_data *psd, unsigned long *flags,\n\t\t\t  const char *fn)\n\t \n{\n\tbool atomic_context = in_atomic() || irqs_disabled();\n\ntry_again:\n\tspin_lock_irqsave(&psd->lock, *flags);\n\tif (!psd->clock_op_might_sleep) {\n\t\t \n\t\t__release(&psd->lock);\n\t\treturn 0;\n\t}\n\n\t \n\tif (atomic_context) {\n\t\tpr_err(\"%s: atomic context with clock_ops_might_sleep = %d\",\n\t\t       fn, psd->clock_op_might_sleep);\n\t\tspin_unlock_irqrestore(&psd->lock, *flags);\n\t\tmight_sleep();\n\t\treturn -EPERM;\n\t}\n\n\t \n\tspin_unlock_irqrestore(&psd->lock, *flags);\n\tmutex_lock(&psd->clock_mutex);\n\n\t \n\tif (likely(psd->clock_op_might_sleep))\n\t\treturn 0;\n\n\tmutex_unlock(&psd->clock_mutex);\n\tgoto try_again;\n}\n\n \nstatic void pm_clk_op_unlock(struct pm_subsys_data *psd, unsigned long *flags)\n\t \n{\n\tif (psd->clock_op_might_sleep) {\n\t\tmutex_unlock(&psd->clock_mutex);\n\t} else {\n\t\t \n\t\t__acquire(&psd->lock);\n\t\tspin_unlock_irqrestore(&psd->lock, *flags);\n\t}\n}\n\n \nstatic inline void __pm_clk_enable(struct device *dev, struct pm_clock_entry *ce)\n{\n\tint ret;\n\n\tswitch (ce->status) {\n\tcase PCE_STATUS_ACQUIRED:\n\t\tret = clk_prepare_enable(ce->clk);\n\t\tbreak;\n\tcase PCE_STATUS_PREPARED:\n\t\tret = clk_enable(ce->clk);\n\t\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\tif (!ret)\n\t\tce->status = PCE_STATUS_ENABLED;\n\telse\n\t\tdev_err(dev, \"%s: failed to enable clk %p, error %d\\n\",\n\t\t\t__func__, ce->clk, ret);\n}\n\n \nstatic void pm_clk_acquire(struct device *dev, struct pm_clock_entry *ce)\n{\n\tif (!ce->clk)\n\t\tce->clk = clk_get(dev, ce->con_id);\n\tif (IS_ERR(ce->clk)) {\n\t\tce->status = PCE_STATUS_ERROR;\n\t\treturn;\n\t} else if (clk_is_enabled_when_prepared(ce->clk)) {\n\t\t \n\t\tce->status = PCE_STATUS_ACQUIRED;\n\t\tce->enabled_when_prepared = true;\n\t} else if (clk_prepare(ce->clk)) {\n\t\tce->status = PCE_STATUS_ERROR;\n\t\tdev_err(dev, \"clk_prepare() failed\\n\");\n\t\treturn;\n\t} else {\n\t\tce->status = PCE_STATUS_PREPARED;\n\t}\n\tdev_dbg(dev, \"Clock %pC con_id %s managed by runtime PM.\\n\",\n\t\tce->clk, ce->con_id);\n}\n\nstatic int __pm_clk_add(struct device *dev, const char *con_id,\n\t\t\tstruct clk *clk)\n{\n\tstruct pm_subsys_data *psd = dev_to_psd(dev);\n\tstruct pm_clock_entry *ce;\n\n\tif (!psd)\n\t\treturn -EINVAL;\n\n\tce = kzalloc(sizeof(*ce), GFP_KERNEL);\n\tif (!ce)\n\t\treturn -ENOMEM;\n\n\tif (con_id) {\n\t\tce->con_id = kstrdup(con_id, GFP_KERNEL);\n\t\tif (!ce->con_id) {\n\t\t\tkfree(ce);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t} else {\n\t\tif (IS_ERR(clk)) {\n\t\t\tkfree(ce);\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tce->clk = clk;\n\t}\n\n\tpm_clk_acquire(dev, ce);\n\n\tpm_clk_list_lock(psd);\n\tlist_add_tail(&ce->node, &psd->clock_list);\n\tif (ce->enabled_when_prepared)\n\t\tpsd->clock_op_might_sleep++;\n\tpm_clk_list_unlock(psd);\n\treturn 0;\n}\n\n \nint pm_clk_add(struct device *dev, const char *con_id)\n{\n\treturn __pm_clk_add(dev, con_id, NULL);\n}\nEXPORT_SYMBOL_GPL(pm_clk_add);\n\n \nint pm_clk_add_clk(struct device *dev, struct clk *clk)\n{\n\treturn __pm_clk_add(dev, NULL, clk);\n}\nEXPORT_SYMBOL_GPL(pm_clk_add_clk);\n\n\n \nint of_pm_clk_add_clk(struct device *dev, const char *name)\n{\n\tstruct clk *clk;\n\tint ret;\n\n\tif (!dev || !dev->of_node || !name)\n\t\treturn -EINVAL;\n\n\tclk = of_clk_get_by_name(dev->of_node, name);\n\tif (IS_ERR(clk))\n\t\treturn PTR_ERR(clk);\n\n\tret = pm_clk_add_clk(dev, clk);\n\tif (ret) {\n\t\tclk_put(clk);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(of_pm_clk_add_clk);\n\n \nint of_pm_clk_add_clks(struct device *dev)\n{\n\tstruct clk **clks;\n\tint i, count;\n\tint ret;\n\n\tif (!dev || !dev->of_node)\n\t\treturn -EINVAL;\n\n\tcount = of_clk_get_parent_count(dev->of_node);\n\tif (count <= 0)\n\t\treturn -ENODEV;\n\n\tclks = kcalloc(count, sizeof(*clks), GFP_KERNEL);\n\tif (!clks)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < count; i++) {\n\t\tclks[i] = of_clk_get(dev->of_node, i);\n\t\tif (IS_ERR(clks[i])) {\n\t\t\tret = PTR_ERR(clks[i]);\n\t\t\tgoto error;\n\t\t}\n\n\t\tret = pm_clk_add_clk(dev, clks[i]);\n\t\tif (ret) {\n\t\t\tclk_put(clks[i]);\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\tkfree(clks);\n\n\treturn i;\n\nerror:\n\twhile (i--)\n\t\tpm_clk_remove_clk(dev, clks[i]);\n\n\tkfree(clks);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(of_pm_clk_add_clks);\n\n \nstatic void __pm_clk_remove(struct pm_clock_entry *ce)\n{\n\tif (!ce)\n\t\treturn;\n\n\tswitch (ce->status) {\n\tcase PCE_STATUS_ENABLED:\n\t\tclk_disable(ce->clk);\n\t\tfallthrough;\n\tcase PCE_STATUS_PREPARED:\n\t\tclk_unprepare(ce->clk);\n\t\tfallthrough;\n\tcase PCE_STATUS_ACQUIRED:\n\tcase PCE_STATUS_ERROR:\n\t\tif (!IS_ERR(ce->clk))\n\t\t\tclk_put(ce->clk);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tkfree(ce->con_id);\n\tkfree(ce);\n}\n\n \nvoid pm_clk_remove(struct device *dev, const char *con_id)\n{\n\tstruct pm_subsys_data *psd = dev_to_psd(dev);\n\tstruct pm_clock_entry *ce;\n\n\tif (!psd)\n\t\treturn;\n\n\tpm_clk_list_lock(psd);\n\n\tlist_for_each_entry(ce, &psd->clock_list, node) {\n\t\tif (!con_id && !ce->con_id)\n\t\t\tgoto remove;\n\t\telse if (!con_id || !ce->con_id)\n\t\t\tcontinue;\n\t\telse if (!strcmp(con_id, ce->con_id))\n\t\t\tgoto remove;\n\t}\n\n\tpm_clk_list_unlock(psd);\n\treturn;\n\n remove:\n\tlist_del(&ce->node);\n\tif (ce->enabled_when_prepared)\n\t\tpsd->clock_op_might_sleep--;\n\tpm_clk_list_unlock(psd);\n\n\t__pm_clk_remove(ce);\n}\nEXPORT_SYMBOL_GPL(pm_clk_remove);\n\n \nvoid pm_clk_remove_clk(struct device *dev, struct clk *clk)\n{\n\tstruct pm_subsys_data *psd = dev_to_psd(dev);\n\tstruct pm_clock_entry *ce;\n\n\tif (!psd || !clk)\n\t\treturn;\n\n\tpm_clk_list_lock(psd);\n\n\tlist_for_each_entry(ce, &psd->clock_list, node) {\n\t\tif (clk == ce->clk)\n\t\t\tgoto remove;\n\t}\n\n\tpm_clk_list_unlock(psd);\n\treturn;\n\n remove:\n\tlist_del(&ce->node);\n\tif (ce->enabled_when_prepared)\n\t\tpsd->clock_op_might_sleep--;\n\tpm_clk_list_unlock(psd);\n\n\t__pm_clk_remove(ce);\n}\nEXPORT_SYMBOL_GPL(pm_clk_remove_clk);\n\n \nvoid pm_clk_init(struct device *dev)\n{\n\tstruct pm_subsys_data *psd = dev_to_psd(dev);\n\tif (psd) {\n\t\tINIT_LIST_HEAD(&psd->clock_list);\n\t\tmutex_init(&psd->clock_mutex);\n\t\tpsd->clock_op_might_sleep = 0;\n\t}\n}\nEXPORT_SYMBOL_GPL(pm_clk_init);\n\n \nint pm_clk_create(struct device *dev)\n{\n\treturn dev_pm_get_subsys_data(dev);\n}\nEXPORT_SYMBOL_GPL(pm_clk_create);\n\n \nvoid pm_clk_destroy(struct device *dev)\n{\n\tstruct pm_subsys_data *psd = dev_to_psd(dev);\n\tstruct pm_clock_entry *ce, *c;\n\tstruct list_head list;\n\n\tif (!psd)\n\t\treturn;\n\n\tINIT_LIST_HEAD(&list);\n\n\tpm_clk_list_lock(psd);\n\n\tlist_for_each_entry_safe_reverse(ce, c, &psd->clock_list, node)\n\t\tlist_move(&ce->node, &list);\n\tpsd->clock_op_might_sleep = 0;\n\n\tpm_clk_list_unlock(psd);\n\n\tdev_pm_put_subsys_data(dev);\n\n\tlist_for_each_entry_safe_reverse(ce, c, &list, node) {\n\t\tlist_del(&ce->node);\n\t\t__pm_clk_remove(ce);\n\t}\n}\nEXPORT_SYMBOL_GPL(pm_clk_destroy);\n\nstatic void pm_clk_destroy_action(void *data)\n{\n\tpm_clk_destroy(data);\n}\n\nint devm_pm_clk_create(struct device *dev)\n{\n\tint ret;\n\n\tret = pm_clk_create(dev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn devm_add_action_or_reset(dev, pm_clk_destroy_action, dev);\n}\nEXPORT_SYMBOL_GPL(devm_pm_clk_create);\n\n \nint pm_clk_suspend(struct device *dev)\n{\n\tstruct pm_subsys_data *psd = dev_to_psd(dev);\n\tstruct pm_clock_entry *ce;\n\tunsigned long flags;\n\tint ret;\n\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\tif (!psd)\n\t\treturn 0;\n\n\tret = pm_clk_op_lock(psd, &flags, __func__);\n\tif (ret)\n\t\treturn ret;\n\n\tlist_for_each_entry_reverse(ce, &psd->clock_list, node) {\n\t\tif (ce->status == PCE_STATUS_ENABLED) {\n\t\t\tif (ce->enabled_when_prepared) {\n\t\t\t\tclk_disable_unprepare(ce->clk);\n\t\t\t\tce->status = PCE_STATUS_ACQUIRED;\n\t\t\t} else {\n\t\t\t\tclk_disable(ce->clk);\n\t\t\t\tce->status = PCE_STATUS_PREPARED;\n\t\t\t}\n\t\t}\n\t}\n\n\tpm_clk_op_unlock(psd, &flags);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(pm_clk_suspend);\n\n \nint pm_clk_resume(struct device *dev)\n{\n\tstruct pm_subsys_data *psd = dev_to_psd(dev);\n\tstruct pm_clock_entry *ce;\n\tunsigned long flags;\n\tint ret;\n\n\tdev_dbg(dev, \"%s()\\n\", __func__);\n\n\tif (!psd)\n\t\treturn 0;\n\n\tret = pm_clk_op_lock(psd, &flags, __func__);\n\tif (ret)\n\t\treturn ret;\n\n\tlist_for_each_entry(ce, &psd->clock_list, node)\n\t\t__pm_clk_enable(dev, ce);\n\n\tpm_clk_op_unlock(psd, &flags);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(pm_clk_resume);\n\n \nstatic int pm_clk_notify(struct notifier_block *nb,\n\t\t\t\t unsigned long action, void *data)\n{\n\tstruct pm_clk_notifier_block *clknb;\n\tstruct device *dev = data;\n\tchar **con_id;\n\tint error;\n\n\tdev_dbg(dev, \"%s() %ld\\n\", __func__, action);\n\n\tclknb = container_of(nb, struct pm_clk_notifier_block, nb);\n\n\tswitch (action) {\n\tcase BUS_NOTIFY_ADD_DEVICE:\n\t\tif (dev->pm_domain)\n\t\t\tbreak;\n\n\t\terror = pm_clk_create(dev);\n\t\tif (error)\n\t\t\tbreak;\n\n\t\tdev_pm_domain_set(dev, clknb->pm_domain);\n\t\tif (clknb->con_ids[0]) {\n\t\t\tfor (con_id = clknb->con_ids; *con_id; con_id++)\n\t\t\t\tpm_clk_add(dev, *con_id);\n\t\t} else {\n\t\t\tpm_clk_add(dev, NULL);\n\t\t}\n\n\t\tbreak;\n\tcase BUS_NOTIFY_DEL_DEVICE:\n\t\tif (dev->pm_domain != clknb->pm_domain)\n\t\t\tbreak;\n\n\t\tdev_pm_domain_set(dev, NULL);\n\t\tpm_clk_destroy(dev);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nint pm_clk_runtime_suspend(struct device *dev)\n{\n\tint ret;\n\n\tdev_dbg(dev, \"%s\\n\", __func__);\n\n\tret = pm_generic_runtime_suspend(dev);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to suspend device\\n\");\n\t\treturn ret;\n\t}\n\n\tret = pm_clk_suspend(dev);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to suspend clock\\n\");\n\t\tpm_generic_runtime_resume(dev);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(pm_clk_runtime_suspend);\n\nint pm_clk_runtime_resume(struct device *dev)\n{\n\tint ret;\n\n\tdev_dbg(dev, \"%s\\n\", __func__);\n\n\tret = pm_clk_resume(dev);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to resume clock\\n\");\n\t\treturn ret;\n\t}\n\n\treturn pm_generic_runtime_resume(dev);\n}\nEXPORT_SYMBOL_GPL(pm_clk_runtime_resume);\n\n#else  \n\n \nstatic void enable_clock(struct device *dev, const char *con_id)\n{\n\tstruct clk *clk;\n\n\tclk = clk_get(dev, con_id);\n\tif (!IS_ERR(clk)) {\n\t\tclk_prepare_enable(clk);\n\t\tclk_put(clk);\n\t\tdev_info(dev, \"Runtime PM disabled, clock forced on.\\n\");\n\t}\n}\n\n \nstatic void disable_clock(struct device *dev, const char *con_id)\n{\n\tstruct clk *clk;\n\n\tclk = clk_get(dev, con_id);\n\tif (!IS_ERR(clk)) {\n\t\tclk_disable_unprepare(clk);\n\t\tclk_put(clk);\n\t\tdev_info(dev, \"Runtime PM disabled, clock forced off.\\n\");\n\t}\n}\n\n \nstatic int pm_clk_notify(struct notifier_block *nb,\n\t\t\t\t unsigned long action, void *data)\n{\n\tstruct pm_clk_notifier_block *clknb;\n\tstruct device *dev = data;\n\tchar **con_id;\n\n\tdev_dbg(dev, \"%s() %ld\\n\", __func__, action);\n\n\tclknb = container_of(nb, struct pm_clk_notifier_block, nb);\n\n\tswitch (action) {\n\tcase BUS_NOTIFY_BIND_DRIVER:\n\t\tif (clknb->con_ids[0]) {\n\t\t\tfor (con_id = clknb->con_ids; *con_id; con_id++)\n\t\t\t\tenable_clock(dev, *con_id);\n\t\t} else {\n\t\t\tenable_clock(dev, NULL);\n\t\t}\n\t\tbreak;\n\tcase BUS_NOTIFY_DRIVER_NOT_BOUND:\n\tcase BUS_NOTIFY_UNBOUND_DRIVER:\n\t\tif (clknb->con_ids[0]) {\n\t\t\tfor (con_id = clknb->con_ids; *con_id; con_id++)\n\t\t\t\tdisable_clock(dev, *con_id);\n\t\t} else {\n\t\t\tdisable_clock(dev, NULL);\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n#endif  \n\n \nvoid pm_clk_add_notifier(struct bus_type *bus,\n\t\t\t\t struct pm_clk_notifier_block *clknb)\n{\n\tif (!bus || !clknb)\n\t\treturn;\n\n\tclknb->nb.notifier_call = pm_clk_notify;\n\tbus_register_notifier(bus, &clknb->nb);\n}\nEXPORT_SYMBOL_GPL(pm_clk_add_notifier);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}