{
  "module_name": "ipmi_si_intf.c",
  "hash_id": "7c1da60f82e4133d84d4e9e390138124cbb4514b0176d961768b26fd41002403",
  "original_prompt": "Ingested from linux-6.6.14/drivers/char/ipmi/ipmi_si_intf.c",
  "human_readable_source": "\n \n\n \n\n#define pr_fmt(fmt) \"ipmi_si: \" fmt\n\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/sched.h>\n#include <linux/seq_file.h>\n#include <linux/timer.h>\n#include <linux/errno.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/list.h>\n#include <linux/notifier.h>\n#include <linux/mutex.h>\n#include <linux/kthread.h>\n#include <asm/irq.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate.h>\n#include <linux/ipmi.h>\n#include <linux/ipmi_smi.h>\n#include \"ipmi_si.h\"\n#include \"ipmi_si_sm.h\"\n#include <linux/string.h>\n#include <linux/ctype.h>\n\n \n#undef DEBUG_TIMING\n\n \n#define SI_TIMEOUT_TIME_USEC\t10000\n#define SI_USEC_PER_JIFFY\t(1000000/HZ)\n#define SI_TIMEOUT_JIFFIES\t(SI_TIMEOUT_TIME_USEC/SI_USEC_PER_JIFFY)\n#define SI_SHORT_TIMEOUT_USEC  250  \n\nenum si_intf_state {\n\tSI_NORMAL,\n\tSI_GETTING_FLAGS,\n\tSI_GETTING_EVENTS,\n\tSI_CLEARING_FLAGS,\n\tSI_GETTING_MESSAGES,\n\tSI_CHECKING_ENABLES,\n\tSI_SETTING_ENABLES\n\t \n};\n\n \n#define IPMI_BT_INTMASK_REG\t\t2\n#define IPMI_BT_INTMASK_CLEAR_IRQ_BIT\t2\n#define IPMI_BT_INTMASK_ENABLE_IRQ_BIT\t1\n\n \nconst char *const si_to_str[] = { \"invalid\", \"kcs\", \"smic\", \"bt\", NULL };\n\nstatic bool initialized;\n\n \nenum si_stat_indexes {\n\t \n\tSI_STAT_short_timeouts = 0,\n\n\t \n\tSI_STAT_long_timeouts,\n\n\t \n\tSI_STAT_idles,\n\n\t \n\tSI_STAT_interrupts,\n\n\t \n\tSI_STAT_attentions,\n\n\t \n\tSI_STAT_flag_fetches,\n\n\t \n\tSI_STAT_hosed_count,\n\n\t \n\tSI_STAT_complete_transactions,\n\n\t \n\tSI_STAT_events,\n\n\t \n\tSI_STAT_watchdog_pretimeouts,\n\n\t \n\tSI_STAT_incoming_messages,\n\n\n\t \n\tSI_NUM_STATS\n};\n\nstruct smi_info {\n\tint                    si_num;\n\tstruct ipmi_smi        *intf;\n\tstruct si_sm_data      *si_sm;\n\tconst struct si_sm_handlers *handlers;\n\tspinlock_t             si_lock;\n\tstruct ipmi_smi_msg    *waiting_msg;\n\tstruct ipmi_smi_msg    *curr_msg;\n\tenum si_intf_state     si_state;\n\n\t \n\tstruct si_sm_io io;\n\n\t \n\tint (*oem_data_avail_handler)(struct smi_info *smi_info);\n\n\t \n#define RECEIVE_MSG_AVAIL\t0x01\n#define EVENT_MSG_BUFFER_FULL\t0x02\n#define WDT_PRE_TIMEOUT_INT\t0x08\n#define OEM0_DATA_AVAIL     0x20\n#define OEM1_DATA_AVAIL     0x40\n#define OEM2_DATA_AVAIL     0x80\n#define OEM_DATA_AVAIL      (OEM0_DATA_AVAIL | \\\n\t\t\t     OEM1_DATA_AVAIL | \\\n\t\t\t     OEM2_DATA_AVAIL)\n\tunsigned char       msg_flags;\n\n\t \n\tbool\t\t    has_event_buffer;\n\n\t \n\tatomic_t            req_events;\n\n\t \n\tbool                run_to_completion;\n\n\t \n\tstruct timer_list   si_timer;\n\n\t \n\tbool\t\t    timer_can_start;\n\n\t \n\tbool\t\t    timer_running;\n\n\t \n\tunsigned long       last_timeout_jiffies;\n\n\t \n\tatomic_t            need_watch;\n\n\t \n\tbool interrupt_disabled;\n\n\t \n\tbool supports_event_msg_buff;\n\n\t \n\tbool cannot_disable_irq;\n\n\t \n\tbool irq_enable_broken;\n\n\t \n\tbool in_maintenance_mode;\n\n\t \n\tbool got_attn;\n\n\t \n\tstruct ipmi_device_id device_id;\n\n\t \n\tbool dev_group_added;\n\n\t \n\tatomic_t stats[SI_NUM_STATS];\n\n\tstruct task_struct *thread;\n\n\tstruct list_head link;\n};\n\n#define smi_inc_stat(smi, stat) \\\n\tatomic_inc(&(smi)->stats[SI_STAT_ ## stat])\n#define smi_get_stat(smi, stat) \\\n\t((unsigned int) atomic_read(&(smi)->stats[SI_STAT_ ## stat]))\n\n#define IPMI_MAX_INTFS 4\nstatic int force_kipmid[IPMI_MAX_INTFS];\nstatic int num_force_kipmid;\n\nstatic unsigned int kipmid_max_busy_us[IPMI_MAX_INTFS];\nstatic int num_max_busy_us;\n\nstatic bool unload_when_empty = true;\n\nstatic int try_smi_init(struct smi_info *smi);\nstatic void cleanup_one_si(struct smi_info *smi_info);\nstatic void cleanup_ipmi_si(void);\n\n#ifdef DEBUG_TIMING\nvoid debug_timestamp(struct smi_info *smi_info, char *msg)\n{\n\tstruct timespec64 t;\n\n\tktime_get_ts64(&t);\n\tdev_dbg(smi_info->io.dev, \"**%s: %lld.%9.9ld\\n\",\n\t\tmsg, t.tv_sec, t.tv_nsec);\n}\n#else\n#define debug_timestamp(smi_info, x)\n#endif\n\nstatic ATOMIC_NOTIFIER_HEAD(xaction_notifier_list);\nstatic int register_xaction_notifier(struct notifier_block *nb)\n{\n\treturn atomic_notifier_chain_register(&xaction_notifier_list, nb);\n}\n\nstatic void deliver_recv_msg(struct smi_info *smi_info,\n\t\t\t     struct ipmi_smi_msg *msg)\n{\n\t \n\tipmi_smi_msg_received(smi_info->intf, msg);\n}\n\nstatic void return_hosed_msg(struct smi_info *smi_info, int cCode)\n{\n\tstruct ipmi_smi_msg *msg = smi_info->curr_msg;\n\n\tif (cCode < 0 || cCode > IPMI_ERR_UNSPECIFIED)\n\t\tcCode = IPMI_ERR_UNSPECIFIED;\n\t \n\n\t \n\tmsg->rsp[0] = msg->data[0] | 4;\n\tmsg->rsp[1] = msg->data[1];\n\tmsg->rsp[2] = cCode;\n\tmsg->rsp_size = 3;\n\n\tsmi_info->curr_msg = NULL;\n\tdeliver_recv_msg(smi_info, msg);\n}\n\nstatic enum si_sm_result start_next_msg(struct smi_info *smi_info)\n{\n\tint              rv;\n\n\tif (!smi_info->waiting_msg) {\n\t\tsmi_info->curr_msg = NULL;\n\t\trv = SI_SM_IDLE;\n\t} else {\n\t\tint err;\n\n\t\tsmi_info->curr_msg = smi_info->waiting_msg;\n\t\tsmi_info->waiting_msg = NULL;\n\t\tdebug_timestamp(smi_info, \"Start2\");\n\t\terr = atomic_notifier_call_chain(&xaction_notifier_list,\n\t\t\t\t0, smi_info);\n\t\tif (err & NOTIFY_STOP_MASK) {\n\t\t\trv = SI_SM_CALL_WITHOUT_DELAY;\n\t\t\tgoto out;\n\t\t}\n\t\terr = smi_info->handlers->start_transaction(\n\t\t\tsmi_info->si_sm,\n\t\t\tsmi_info->curr_msg->data,\n\t\t\tsmi_info->curr_msg->data_size);\n\t\tif (err)\n\t\t\treturn_hosed_msg(smi_info, err);\n\n\t\trv = SI_SM_CALL_WITHOUT_DELAY;\n\t}\nout:\n\treturn rv;\n}\n\nstatic void smi_mod_timer(struct smi_info *smi_info, unsigned long new_val)\n{\n\tif (!smi_info->timer_can_start)\n\t\treturn;\n\tsmi_info->last_timeout_jiffies = jiffies;\n\tmod_timer(&smi_info->si_timer, new_val);\n\tsmi_info->timer_running = true;\n}\n\n \nstatic void start_new_msg(struct smi_info *smi_info, unsigned char *msg,\n\t\t\t  unsigned int size)\n{\n\tsmi_mod_timer(smi_info, jiffies + SI_TIMEOUT_JIFFIES);\n\n\tif (smi_info->thread)\n\t\twake_up_process(smi_info->thread);\n\n\tsmi_info->handlers->start_transaction(smi_info->si_sm, msg, size);\n}\n\nstatic void start_check_enables(struct smi_info *smi_info)\n{\n\tunsigned char msg[2];\n\n\tmsg[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\tmsg[1] = IPMI_GET_BMC_GLOBAL_ENABLES_CMD;\n\n\tstart_new_msg(smi_info, msg, 2);\n\tsmi_info->si_state = SI_CHECKING_ENABLES;\n}\n\nstatic void start_clear_flags(struct smi_info *smi_info)\n{\n\tunsigned char msg[3];\n\n\t \n\tmsg[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\tmsg[1] = IPMI_CLEAR_MSG_FLAGS_CMD;\n\tmsg[2] = WDT_PRE_TIMEOUT_INT;\n\n\tstart_new_msg(smi_info, msg, 3);\n\tsmi_info->si_state = SI_CLEARING_FLAGS;\n}\n\nstatic void start_getting_msg_queue(struct smi_info *smi_info)\n{\n\tsmi_info->curr_msg->data[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\tsmi_info->curr_msg->data[1] = IPMI_GET_MSG_CMD;\n\tsmi_info->curr_msg->data_size = 2;\n\n\tstart_new_msg(smi_info, smi_info->curr_msg->data,\n\t\t      smi_info->curr_msg->data_size);\n\tsmi_info->si_state = SI_GETTING_MESSAGES;\n}\n\nstatic void start_getting_events(struct smi_info *smi_info)\n{\n\tsmi_info->curr_msg->data[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\tsmi_info->curr_msg->data[1] = IPMI_READ_EVENT_MSG_BUFFER_CMD;\n\tsmi_info->curr_msg->data_size = 2;\n\n\tstart_new_msg(smi_info, smi_info->curr_msg->data,\n\t\t      smi_info->curr_msg->data_size);\n\tsmi_info->si_state = SI_GETTING_EVENTS;\n}\n\n \nstatic inline bool disable_si_irq(struct smi_info *smi_info)\n{\n\tif ((smi_info->io.irq) && (!smi_info->interrupt_disabled)) {\n\t\tsmi_info->interrupt_disabled = true;\n\t\tstart_check_enables(smi_info);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic inline bool enable_si_irq(struct smi_info *smi_info)\n{\n\tif ((smi_info->io.irq) && (smi_info->interrupt_disabled)) {\n\t\tsmi_info->interrupt_disabled = false;\n\t\tstart_check_enables(smi_info);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nstatic struct ipmi_smi_msg *alloc_msg_handle_irq(struct smi_info *smi_info)\n{\n\tstruct ipmi_smi_msg *msg;\n\n\tmsg = ipmi_alloc_smi_msg();\n\tif (!msg) {\n\t\tif (!disable_si_irq(smi_info))\n\t\t\tsmi_info->si_state = SI_NORMAL;\n\t} else if (enable_si_irq(smi_info)) {\n\t\tipmi_free_smi_msg(msg);\n\t\tmsg = NULL;\n\t}\n\treturn msg;\n}\n\nstatic void handle_flags(struct smi_info *smi_info)\n{\nretry:\n\tif (smi_info->msg_flags & WDT_PRE_TIMEOUT_INT) {\n\t\t \n\t\tsmi_inc_stat(smi_info, watchdog_pretimeouts);\n\n\t\tstart_clear_flags(smi_info);\n\t\tsmi_info->msg_flags &= ~WDT_PRE_TIMEOUT_INT;\n\t\tipmi_smi_watchdog_pretimeout(smi_info->intf);\n\t} else if (smi_info->msg_flags & RECEIVE_MSG_AVAIL) {\n\t\t \n\t\tsmi_info->curr_msg = alloc_msg_handle_irq(smi_info);\n\t\tif (!smi_info->curr_msg)\n\t\t\treturn;\n\n\t\tstart_getting_msg_queue(smi_info);\n\t} else if (smi_info->msg_flags & EVENT_MSG_BUFFER_FULL) {\n\t\t \n\t\tsmi_info->curr_msg = alloc_msg_handle_irq(smi_info);\n\t\tif (!smi_info->curr_msg)\n\t\t\treturn;\n\n\t\tstart_getting_events(smi_info);\n\t} else if (smi_info->msg_flags & OEM_DATA_AVAIL &&\n\t\t   smi_info->oem_data_avail_handler) {\n\t\tif (smi_info->oem_data_avail_handler(smi_info))\n\t\t\tgoto retry;\n\t} else\n\t\tsmi_info->si_state = SI_NORMAL;\n}\n\n \n#define GLOBAL_ENABLES_MASK (IPMI_BMC_EVT_MSG_BUFF | IPMI_BMC_RCV_MSG_INTR | \\\n\t\t\t     IPMI_BMC_EVT_MSG_INTR)\n\nstatic u8 current_global_enables(struct smi_info *smi_info, u8 base,\n\t\t\t\t bool *irq_on)\n{\n\tu8 enables = 0;\n\n\tif (smi_info->supports_event_msg_buff)\n\t\tenables |= IPMI_BMC_EVT_MSG_BUFF;\n\n\tif (((smi_info->io.irq && !smi_info->interrupt_disabled) ||\n\t     smi_info->cannot_disable_irq) &&\n\t    !smi_info->irq_enable_broken)\n\t\tenables |= IPMI_BMC_RCV_MSG_INTR;\n\n\tif (smi_info->supports_event_msg_buff &&\n\t    smi_info->io.irq && !smi_info->interrupt_disabled &&\n\t    !smi_info->irq_enable_broken)\n\t\tenables |= IPMI_BMC_EVT_MSG_INTR;\n\n\t*irq_on = enables & (IPMI_BMC_EVT_MSG_INTR | IPMI_BMC_RCV_MSG_INTR);\n\n\treturn enables;\n}\n\nstatic void check_bt_irq(struct smi_info *smi_info, bool irq_on)\n{\n\tu8 irqstate = smi_info->io.inputb(&smi_info->io, IPMI_BT_INTMASK_REG);\n\n\tirqstate &= IPMI_BT_INTMASK_ENABLE_IRQ_BIT;\n\n\tif ((bool)irqstate == irq_on)\n\t\treturn;\n\n\tif (irq_on)\n\t\tsmi_info->io.outputb(&smi_info->io, IPMI_BT_INTMASK_REG,\n\t\t\t\t     IPMI_BT_INTMASK_ENABLE_IRQ_BIT);\n\telse\n\t\tsmi_info->io.outputb(&smi_info->io, IPMI_BT_INTMASK_REG, 0);\n}\n\nstatic void handle_transaction_done(struct smi_info *smi_info)\n{\n\tstruct ipmi_smi_msg *msg;\n\n\tdebug_timestamp(smi_info, \"Done\");\n\tswitch (smi_info->si_state) {\n\tcase SI_NORMAL:\n\t\tif (!smi_info->curr_msg)\n\t\t\tbreak;\n\n\t\tsmi_info->curr_msg->rsp_size\n\t\t\t= smi_info->handlers->get_result(\n\t\t\t\tsmi_info->si_sm,\n\t\t\t\tsmi_info->curr_msg->rsp,\n\t\t\t\tIPMI_MAX_MSG_LENGTH);\n\n\t\t \n\t\tmsg = smi_info->curr_msg;\n\t\tsmi_info->curr_msg = NULL;\n\t\tdeliver_recv_msg(smi_info, msg);\n\t\tbreak;\n\n\tcase SI_GETTING_FLAGS:\n\t{\n\t\tunsigned char msg[4];\n\t\tunsigned int  len;\n\n\t\t \n\t\tlen = smi_info->handlers->get_result(smi_info->si_sm, msg, 4);\n\t\tif (msg[2] != 0) {\n\t\t\t \n\t\t\tsmi_info->si_state = SI_NORMAL;\n\t\t} else if (len < 4) {\n\t\t\t \n\t\t\tsmi_info->si_state = SI_NORMAL;\n\t\t} else {\n\t\t\tsmi_info->msg_flags = msg[3];\n\t\t\thandle_flags(smi_info);\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase SI_CLEARING_FLAGS:\n\t{\n\t\tunsigned char msg[3];\n\n\t\t \n\t\tsmi_info->handlers->get_result(smi_info->si_sm, msg, 3);\n\t\tif (msg[2] != 0) {\n\t\t\t \n\t\t\tdev_warn_ratelimited(smi_info->io.dev,\n\t\t\t\t \"Error clearing flags: %2.2x\\n\", msg[2]);\n\t\t}\n\t\tsmi_info->si_state = SI_NORMAL;\n\t\tbreak;\n\t}\n\n\tcase SI_GETTING_EVENTS:\n\t{\n\t\tsmi_info->curr_msg->rsp_size\n\t\t\t= smi_info->handlers->get_result(\n\t\t\t\tsmi_info->si_sm,\n\t\t\t\tsmi_info->curr_msg->rsp,\n\t\t\t\tIPMI_MAX_MSG_LENGTH);\n\n\t\t \n\t\tmsg = smi_info->curr_msg;\n\t\tsmi_info->curr_msg = NULL;\n\t\tif (msg->rsp[2] != 0) {\n\t\t\t \n\t\t\tmsg->done(msg);\n\n\t\t\t \n\t\t\tsmi_info->msg_flags &= ~EVENT_MSG_BUFFER_FULL;\n\t\t\thandle_flags(smi_info);\n\t\t} else {\n\t\t\tsmi_inc_stat(smi_info, events);\n\n\t\t\t \n\t\t\thandle_flags(smi_info);\n\n\t\t\tdeliver_recv_msg(smi_info, msg);\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase SI_GETTING_MESSAGES:\n\t{\n\t\tsmi_info->curr_msg->rsp_size\n\t\t\t= smi_info->handlers->get_result(\n\t\t\t\tsmi_info->si_sm,\n\t\t\t\tsmi_info->curr_msg->rsp,\n\t\t\t\tIPMI_MAX_MSG_LENGTH);\n\n\t\t \n\t\tmsg = smi_info->curr_msg;\n\t\tsmi_info->curr_msg = NULL;\n\t\tif (msg->rsp[2] != 0) {\n\t\t\t \n\t\t\tmsg->done(msg);\n\n\t\t\t \n\t\t\tsmi_info->msg_flags &= ~RECEIVE_MSG_AVAIL;\n\t\t\thandle_flags(smi_info);\n\t\t} else {\n\t\t\tsmi_inc_stat(smi_info, incoming_messages);\n\n\t\t\t \n\t\t\thandle_flags(smi_info);\n\n\t\t\tdeliver_recv_msg(smi_info, msg);\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase SI_CHECKING_ENABLES:\n\t{\n\t\tunsigned char msg[4];\n\t\tu8 enables;\n\t\tbool irq_on;\n\n\t\t \n\t\tsmi_info->handlers->get_result(smi_info->si_sm, msg, 4);\n\t\tif (msg[2] != 0) {\n\t\t\tdev_warn_ratelimited(smi_info->io.dev,\n\t\t\t\t\"Couldn't get irq info: %x,\\n\"\n\t\t\t\t\"Maybe ok, but ipmi might run very slowly.\\n\",\n\t\t\t\tmsg[2]);\n\t\t\tsmi_info->si_state = SI_NORMAL;\n\t\t\tbreak;\n\t\t}\n\t\tenables = current_global_enables(smi_info, 0, &irq_on);\n\t\tif (smi_info->io.si_type == SI_BT)\n\t\t\t \n\t\t\tcheck_bt_irq(smi_info, irq_on);\n\t\tif (enables != (msg[3] & GLOBAL_ENABLES_MASK)) {\n\t\t\t \n\t\t\tmsg[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\t\t\tmsg[1] = IPMI_SET_BMC_GLOBAL_ENABLES_CMD;\n\t\t\tmsg[2] = enables | (msg[3] & ~GLOBAL_ENABLES_MASK);\n\t\t\tsmi_info->handlers->start_transaction(\n\t\t\t\tsmi_info->si_sm, msg, 3);\n\t\t\tsmi_info->si_state = SI_SETTING_ENABLES;\n\t\t} else if (smi_info->supports_event_msg_buff) {\n\t\t\tsmi_info->curr_msg = ipmi_alloc_smi_msg();\n\t\t\tif (!smi_info->curr_msg) {\n\t\t\t\tsmi_info->si_state = SI_NORMAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tstart_getting_events(smi_info);\n\t\t} else {\n\t\t\tsmi_info->si_state = SI_NORMAL;\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase SI_SETTING_ENABLES:\n\t{\n\t\tunsigned char msg[4];\n\n\t\tsmi_info->handlers->get_result(smi_info->si_sm, msg, 4);\n\t\tif (msg[2] != 0)\n\t\t\tdev_warn_ratelimited(smi_info->io.dev,\n\t\t\t\t \"Could not set the global enables: 0x%x.\\n\",\n\t\t\t\t msg[2]);\n\n\t\tif (smi_info->supports_event_msg_buff) {\n\t\t\tsmi_info->curr_msg = ipmi_alloc_smi_msg();\n\t\t\tif (!smi_info->curr_msg) {\n\t\t\t\tsmi_info->si_state = SI_NORMAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tstart_getting_events(smi_info);\n\t\t} else {\n\t\t\tsmi_info->si_state = SI_NORMAL;\n\t\t}\n\t\tbreak;\n\t}\n\t}\n}\n\n \nstatic enum si_sm_result smi_event_handler(struct smi_info *smi_info,\n\t\t\t\t\t   int time)\n{\n\tenum si_sm_result si_sm_result;\n\nrestart:\n\t \n\tsi_sm_result = smi_info->handlers->event(smi_info->si_sm, time);\n\ttime = 0;\n\twhile (si_sm_result == SI_SM_CALL_WITHOUT_DELAY)\n\t\tsi_sm_result = smi_info->handlers->event(smi_info->si_sm, 0);\n\n\tif (si_sm_result == SI_SM_TRANSACTION_COMPLETE) {\n\t\tsmi_inc_stat(smi_info, complete_transactions);\n\n\t\thandle_transaction_done(smi_info);\n\t\tgoto restart;\n\t} else if (si_sm_result == SI_SM_HOSED) {\n\t\tsmi_inc_stat(smi_info, hosed_count);\n\n\t\t \n\t\tsmi_info->si_state = SI_NORMAL;\n\t\tif (smi_info->curr_msg != NULL) {\n\t\t\t \n\t\t\treturn_hosed_msg(smi_info, IPMI_ERR_UNSPECIFIED);\n\t\t}\n\t\tgoto restart;\n\t}\n\n\t \n\tif (si_sm_result == SI_SM_ATTN || smi_info->got_attn) {\n\t\tunsigned char msg[2];\n\n\t\tif (smi_info->si_state != SI_NORMAL) {\n\t\t\t \n\t\t\tsmi_info->got_attn = true;\n\t\t} else {\n\t\t\tsmi_info->got_attn = false;\n\t\t\tsmi_inc_stat(smi_info, attentions);\n\n\t\t\t \n\t\t\tmsg[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\t\t\tmsg[1] = IPMI_GET_MSG_FLAGS_CMD;\n\n\t\t\tstart_new_msg(smi_info, msg, 2);\n\t\t\tsmi_info->si_state = SI_GETTING_FLAGS;\n\t\t\tgoto restart;\n\t\t}\n\t}\n\n\t \n\tif (si_sm_result == SI_SM_IDLE) {\n\t\tsmi_inc_stat(smi_info, idles);\n\n\t\tsi_sm_result = start_next_msg(smi_info);\n\t\tif (si_sm_result != SI_SM_IDLE)\n\t\t\tgoto restart;\n\t}\n\n\tif ((si_sm_result == SI_SM_IDLE)\n\t    && (atomic_read(&smi_info->req_events))) {\n\t\t \n\t\tatomic_set(&smi_info->req_events, 0);\n\n\t\t \n\t\tif (smi_info->supports_event_msg_buff || smi_info->io.irq) {\n\t\t\tstart_check_enables(smi_info);\n\t\t} else {\n\t\t\tsmi_info->curr_msg = alloc_msg_handle_irq(smi_info);\n\t\t\tif (!smi_info->curr_msg)\n\t\t\t\tgoto out;\n\n\t\t\tstart_getting_events(smi_info);\n\t\t}\n\t\tgoto restart;\n\t}\n\n\tif (si_sm_result == SI_SM_IDLE && smi_info->timer_running) {\n\t\t \n\t\tif (del_timer(&smi_info->si_timer))\n\t\t\tsmi_info->timer_running = false;\n\t}\n\nout:\n\treturn si_sm_result;\n}\n\nstatic void check_start_timer_thread(struct smi_info *smi_info)\n{\n\tif (smi_info->si_state == SI_NORMAL && smi_info->curr_msg == NULL) {\n\t\tsmi_mod_timer(smi_info, jiffies + SI_TIMEOUT_JIFFIES);\n\n\t\tif (smi_info->thread)\n\t\t\twake_up_process(smi_info->thread);\n\n\t\tstart_next_msg(smi_info);\n\t\tsmi_event_handler(smi_info, 0);\n\t}\n}\n\nstatic void flush_messages(void *send_info)\n{\n\tstruct smi_info *smi_info = send_info;\n\tenum si_sm_result result;\n\n\t \n\tresult = smi_event_handler(smi_info, 0);\n\twhile (result != SI_SM_IDLE) {\n\t\tudelay(SI_SHORT_TIMEOUT_USEC);\n\t\tresult = smi_event_handler(smi_info, SI_SHORT_TIMEOUT_USEC);\n\t}\n}\n\nstatic void sender(void                *send_info,\n\t\t   struct ipmi_smi_msg *msg)\n{\n\tstruct smi_info   *smi_info = send_info;\n\tunsigned long     flags;\n\n\tdebug_timestamp(smi_info, \"Enqueue\");\n\n\tif (smi_info->run_to_completion) {\n\t\t \n\t\tsmi_info->waiting_msg = msg;\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&smi_info->si_lock, flags);\n\t \n\tBUG_ON(smi_info->waiting_msg);\n\tsmi_info->waiting_msg = msg;\n\tcheck_start_timer_thread(smi_info);\n\tspin_unlock_irqrestore(&smi_info->si_lock, flags);\n}\n\nstatic void set_run_to_completion(void *send_info, bool i_run_to_completion)\n{\n\tstruct smi_info   *smi_info = send_info;\n\n\tsmi_info->run_to_completion = i_run_to_completion;\n\tif (i_run_to_completion)\n\t\tflush_messages(smi_info);\n}\n\n \n#define IPMI_TIME_NOT_BUSY ns_to_ktime(-1ull)\nstatic inline bool ipmi_thread_busy_wait(enum si_sm_result smi_result,\n\t\t\t\t\t const struct smi_info *smi_info,\n\t\t\t\t\t ktime_t *busy_until)\n{\n\tunsigned int max_busy_us = 0;\n\n\tif (smi_info->si_num < num_max_busy_us)\n\t\tmax_busy_us = kipmid_max_busy_us[smi_info->si_num];\n\tif (max_busy_us == 0 || smi_result != SI_SM_CALL_WITH_DELAY)\n\t\t*busy_until = IPMI_TIME_NOT_BUSY;\n\telse if (*busy_until == IPMI_TIME_NOT_BUSY) {\n\t\t*busy_until = ktime_get() + max_busy_us * NSEC_PER_USEC;\n\t} else {\n\t\tif (unlikely(ktime_get() > *busy_until)) {\n\t\t\t*busy_until = IPMI_TIME_NOT_BUSY;\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}\n\n\n \nstatic int ipmi_thread(void *data)\n{\n\tstruct smi_info *smi_info = data;\n\tunsigned long flags;\n\tenum si_sm_result smi_result;\n\tktime_t busy_until = IPMI_TIME_NOT_BUSY;\n\n\tset_user_nice(current, MAX_NICE);\n\twhile (!kthread_should_stop()) {\n\t\tint busy_wait;\n\n\t\tspin_lock_irqsave(&(smi_info->si_lock), flags);\n\t\tsmi_result = smi_event_handler(smi_info, 0);\n\n\t\t \n\t\tif (smi_result != SI_SM_IDLE && !smi_info->timer_running)\n\t\t\tsmi_mod_timer(smi_info, jiffies + SI_TIMEOUT_JIFFIES);\n\n\t\tspin_unlock_irqrestore(&(smi_info->si_lock), flags);\n\t\tbusy_wait = ipmi_thread_busy_wait(smi_result, smi_info,\n\t\t\t\t\t\t  &busy_until);\n\t\tif (smi_result == SI_SM_CALL_WITHOUT_DELAY) {\n\t\t\t;  \n\t\t} else if (smi_result == SI_SM_CALL_WITH_DELAY && busy_wait) {\n\t\t\t \n\t\t\tif (smi_info->in_maintenance_mode)\n\t\t\t\tschedule();\n\t\t\telse\n\t\t\t\tusleep_range(100, 200);\n\t\t} else if (smi_result == SI_SM_IDLE) {\n\t\t\tif (atomic_read(&smi_info->need_watch)) {\n\t\t\t\tschedule_timeout_interruptible(100);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\t__set_current_state(TASK_INTERRUPTIBLE);\n\t\t\t\tschedule();\n\t\t\t}\n\t\t} else {\n\t\t\tschedule_timeout_interruptible(1);\n\t\t}\n\t}\n\treturn 0;\n}\n\n\nstatic void poll(void *send_info)\n{\n\tstruct smi_info *smi_info = send_info;\n\tunsigned long flags = 0;\n\tbool run_to_completion = smi_info->run_to_completion;\n\n\t \n\tudelay(10);\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&smi_info->si_lock, flags);\n\tsmi_event_handler(smi_info, 10);\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&smi_info->si_lock, flags);\n}\n\nstatic void request_events(void *send_info)\n{\n\tstruct smi_info *smi_info = send_info;\n\n\tif (!smi_info->has_event_buffer)\n\t\treturn;\n\n\tatomic_set(&smi_info->req_events, 1);\n}\n\nstatic void set_need_watch(void *send_info, unsigned int watch_mask)\n{\n\tstruct smi_info *smi_info = send_info;\n\tunsigned long flags;\n\tint enable;\n\n\tenable = !!watch_mask;\n\n\tatomic_set(&smi_info->need_watch, enable);\n\tspin_lock_irqsave(&smi_info->si_lock, flags);\n\tcheck_start_timer_thread(smi_info);\n\tspin_unlock_irqrestore(&smi_info->si_lock, flags);\n}\n\nstatic void smi_timeout(struct timer_list *t)\n{\n\tstruct smi_info   *smi_info = from_timer(smi_info, t, si_timer);\n\tenum si_sm_result smi_result;\n\tunsigned long     flags;\n\tunsigned long     jiffies_now;\n\tlong              time_diff;\n\tlong\t\t  timeout;\n\n\tspin_lock_irqsave(&(smi_info->si_lock), flags);\n\tdebug_timestamp(smi_info, \"Timer\");\n\n\tjiffies_now = jiffies;\n\ttime_diff = (((long)jiffies_now - (long)smi_info->last_timeout_jiffies)\n\t\t     * SI_USEC_PER_JIFFY);\n\tsmi_result = smi_event_handler(smi_info, time_diff);\n\n\tif ((smi_info->io.irq) && (!smi_info->interrupt_disabled)) {\n\t\t \n\t\ttimeout = jiffies + SI_TIMEOUT_JIFFIES;\n\t\tsmi_inc_stat(smi_info, long_timeouts);\n\t\tgoto do_mod_timer;\n\t}\n\n\t \n\tif (smi_result == SI_SM_CALL_WITH_DELAY) {\n\t\tsmi_inc_stat(smi_info, short_timeouts);\n\t\ttimeout = jiffies + 1;\n\t} else {\n\t\tsmi_inc_stat(smi_info, long_timeouts);\n\t\ttimeout = jiffies + SI_TIMEOUT_JIFFIES;\n\t}\n\ndo_mod_timer:\n\tif (smi_result != SI_SM_IDLE)\n\t\tsmi_mod_timer(smi_info, timeout);\n\telse\n\t\tsmi_info->timer_running = false;\n\tspin_unlock_irqrestore(&(smi_info->si_lock), flags);\n}\n\nirqreturn_t ipmi_si_irq_handler(int irq, void *data)\n{\n\tstruct smi_info *smi_info = data;\n\tunsigned long   flags;\n\n\tif (smi_info->io.si_type == SI_BT)\n\t\t \n\t\tsmi_info->io.outputb(&smi_info->io, IPMI_BT_INTMASK_REG,\n\t\t\t\t     IPMI_BT_INTMASK_CLEAR_IRQ_BIT\n\t\t\t\t     | IPMI_BT_INTMASK_ENABLE_IRQ_BIT);\n\n\tspin_lock_irqsave(&(smi_info->si_lock), flags);\n\n\tsmi_inc_stat(smi_info, interrupts);\n\n\tdebug_timestamp(smi_info, \"Interrupt\");\n\n\tsmi_event_handler(smi_info, 0);\n\tspin_unlock_irqrestore(&(smi_info->si_lock), flags);\n\treturn IRQ_HANDLED;\n}\n\nstatic int smi_start_processing(void            *send_info,\n\t\t\t\tstruct ipmi_smi *intf)\n{\n\tstruct smi_info *new_smi = send_info;\n\tint             enable = 0;\n\n\tnew_smi->intf = intf;\n\n\t \n\ttimer_setup(&new_smi->si_timer, smi_timeout, 0);\n\tnew_smi->timer_can_start = true;\n\tsmi_mod_timer(new_smi, jiffies + SI_TIMEOUT_JIFFIES);\n\n\t \n\tif (new_smi->io.irq_setup) {\n\t\tnew_smi->io.irq_handler_data = new_smi;\n\t\tnew_smi->io.irq_setup(&new_smi->io);\n\t}\n\n\t \n\tif (new_smi->si_num < num_force_kipmid)\n\t\tenable = force_kipmid[new_smi->si_num];\n\t \n\telse if ((new_smi->io.si_type != SI_BT) && (!new_smi->io.irq))\n\t\tenable = 1;\n\n\tif (enable) {\n\t\tnew_smi->thread = kthread_run(ipmi_thread, new_smi,\n\t\t\t\t\t      \"kipmi%d\", new_smi->si_num);\n\t\tif (IS_ERR(new_smi->thread)) {\n\t\t\tdev_notice(new_smi->io.dev,\n\t\t\t\t   \"Could not start kernel thread due to error %ld, only using timers to drive the interface\\n\",\n\t\t\t\t   PTR_ERR(new_smi->thread));\n\t\t\tnew_smi->thread = NULL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int get_smi_info(void *send_info, struct ipmi_smi_info *data)\n{\n\tstruct smi_info *smi = send_info;\n\n\tdata->addr_src = smi->io.addr_source;\n\tdata->dev = smi->io.dev;\n\tdata->addr_info = smi->io.addr_info;\n\tget_device(smi->io.dev);\n\n\treturn 0;\n}\n\nstatic void set_maintenance_mode(void *send_info, bool enable)\n{\n\tstruct smi_info   *smi_info = send_info;\n\n\tif (!enable)\n\t\tatomic_set(&smi_info->req_events, 0);\n\tsmi_info->in_maintenance_mode = enable;\n}\n\nstatic void shutdown_smi(void *send_info);\nstatic const struct ipmi_smi_handlers handlers = {\n\t.owner                  = THIS_MODULE,\n\t.start_processing       = smi_start_processing,\n\t.shutdown               = shutdown_smi,\n\t.get_smi_info\t\t= get_smi_info,\n\t.sender\t\t\t= sender,\n\t.request_events\t\t= request_events,\n\t.set_need_watch\t\t= set_need_watch,\n\t.set_maintenance_mode   = set_maintenance_mode,\n\t.set_run_to_completion  = set_run_to_completion,\n\t.flush_messages\t\t= flush_messages,\n\t.poll\t\t\t= poll,\n};\n\nstatic LIST_HEAD(smi_infos);\nstatic DEFINE_MUTEX(smi_infos_lock);\nstatic int smi_num;  \n\nstatic const char * const addr_space_to_str[] = { \"i/o\", \"mem\" };\n\nmodule_param_array(force_kipmid, int, &num_force_kipmid, 0);\nMODULE_PARM_DESC(force_kipmid,\n\t\t \"Force the kipmi daemon to be enabled (1) or disabled(0).  Normally the IPMI driver auto-detects this, but the value may be overridden by this parm.\");\nmodule_param(unload_when_empty, bool, 0);\nMODULE_PARM_DESC(unload_when_empty,\n\t\t \"Unload the module if no interfaces are specified or found, default is 1.  Setting to 0 is useful for hot add of devices using hotmod.\");\nmodule_param_array(kipmid_max_busy_us, uint, &num_max_busy_us, 0644);\nMODULE_PARM_DESC(kipmid_max_busy_us,\n\t\t \"Max time (in microseconds) to busy-wait for IPMI data before sleeping. 0 (default) means to wait forever. Set to 100-500 if kipmid is using up a lot of CPU time.\");\n\nvoid ipmi_irq_finish_setup(struct si_sm_io *io)\n{\n\tif (io->si_type == SI_BT)\n\t\t \n\t\tio->outputb(io, IPMI_BT_INTMASK_REG,\n\t\t\t    IPMI_BT_INTMASK_ENABLE_IRQ_BIT);\n}\n\nvoid ipmi_irq_start_cleanup(struct si_sm_io *io)\n{\n\tif (io->si_type == SI_BT)\n\t\t \n\t\tio->outputb(io, IPMI_BT_INTMASK_REG, 0);\n}\n\nstatic void std_irq_cleanup(struct si_sm_io *io)\n{\n\tipmi_irq_start_cleanup(io);\n\tfree_irq(io->irq, io->irq_handler_data);\n}\n\nint ipmi_std_irq_setup(struct si_sm_io *io)\n{\n\tint rv;\n\n\tif (!io->irq)\n\t\treturn 0;\n\n\trv = request_irq(io->irq,\n\t\t\t ipmi_si_irq_handler,\n\t\t\t IRQF_SHARED,\n\t\t\t SI_DEVICE_NAME,\n\t\t\t io->irq_handler_data);\n\tif (rv) {\n\t\tdev_warn(io->dev, \"%s unable to claim interrupt %d, running polled\\n\",\n\t\t\t SI_DEVICE_NAME, io->irq);\n\t\tio->irq = 0;\n\t} else {\n\t\tio->irq_cleanup = std_irq_cleanup;\n\t\tipmi_irq_finish_setup(io);\n\t\tdev_info(io->dev, \"Using irq %d\\n\", io->irq);\n\t}\n\n\treturn rv;\n}\n\nstatic int wait_for_msg_done(struct smi_info *smi_info)\n{\n\tenum si_sm_result     smi_result;\n\n\tsmi_result = smi_info->handlers->event(smi_info->si_sm, 0);\n\tfor (;;) {\n\t\tif (smi_result == SI_SM_CALL_WITH_DELAY ||\n\t\t    smi_result == SI_SM_CALL_WITH_TICK_DELAY) {\n\t\t\tschedule_timeout_uninterruptible(1);\n\t\t\tsmi_result = smi_info->handlers->event(\n\t\t\t\tsmi_info->si_sm, jiffies_to_usecs(1));\n\t\t} else if (smi_result == SI_SM_CALL_WITHOUT_DELAY) {\n\t\t\tsmi_result = smi_info->handlers->event(\n\t\t\t\tsmi_info->si_sm, 0);\n\t\t} else\n\t\t\tbreak;\n\t}\n\tif (smi_result == SI_SM_HOSED)\n\t\t \n\t\treturn -ENODEV;\n\n\treturn 0;\n}\n\nstatic int try_get_dev_id(struct smi_info *smi_info)\n{\n\tunsigned char         msg[2];\n\tunsigned char         *resp;\n\tunsigned long         resp_len;\n\tint                   rv = 0;\n\tunsigned int          retry_count = 0;\n\n\tresp = kmalloc(IPMI_MAX_MSG_LENGTH, GFP_KERNEL);\n\tif (!resp)\n\t\treturn -ENOMEM;\n\n\t \n\tmsg[0] = IPMI_NETFN_APP_REQUEST << 2;\n\tmsg[1] = IPMI_GET_DEVICE_ID_CMD;\n\nretry:\n\tsmi_info->handlers->start_transaction(smi_info->si_sm, msg, 2);\n\n\trv = wait_for_msg_done(smi_info);\n\tif (rv)\n\t\tgoto out;\n\n\tresp_len = smi_info->handlers->get_result(smi_info->si_sm,\n\t\t\t\t\t\t  resp, IPMI_MAX_MSG_LENGTH);\n\n\t \n\trv = ipmi_demangle_device_id(resp[0] >> 2, resp[1],\n\t\t\tresp + 2, resp_len - 2, &smi_info->device_id);\n\tif (rv) {\n\t\t \n\t\tunsigned char cc = *(resp + 2);\n\n\t\tif (cc != IPMI_CC_NO_ERROR &&\n\t\t    ++retry_count <= GET_DEVICE_ID_MAX_RETRY) {\n\t\t\tdev_warn_ratelimited(smi_info->io.dev,\n\t\t\t    \"BMC returned 0x%2.2x, retry get bmc device id\\n\",\n\t\t\t    cc);\n\t\t\tgoto retry;\n\t\t}\n\t}\n\nout:\n\tkfree(resp);\n\treturn rv;\n}\n\nstatic int get_global_enables(struct smi_info *smi_info, u8 *enables)\n{\n\tunsigned char         msg[3];\n\tunsigned char         *resp;\n\tunsigned long         resp_len;\n\tint                   rv;\n\n\tresp = kmalloc(IPMI_MAX_MSG_LENGTH, GFP_KERNEL);\n\tif (!resp)\n\t\treturn -ENOMEM;\n\n\tmsg[0] = IPMI_NETFN_APP_REQUEST << 2;\n\tmsg[1] = IPMI_GET_BMC_GLOBAL_ENABLES_CMD;\n\tsmi_info->handlers->start_transaction(smi_info->si_sm, msg, 2);\n\n\trv = wait_for_msg_done(smi_info);\n\tif (rv) {\n\t\tdev_warn(smi_info->io.dev,\n\t\t\t \"Error getting response from get global enables command: %d\\n\",\n\t\t\t rv);\n\t\tgoto out;\n\t}\n\n\tresp_len = smi_info->handlers->get_result(smi_info->si_sm,\n\t\t\t\t\t\t  resp, IPMI_MAX_MSG_LENGTH);\n\n\tif (resp_len < 4 ||\n\t\t\tresp[0] != (IPMI_NETFN_APP_REQUEST | 1) << 2 ||\n\t\t\tresp[1] != IPMI_GET_BMC_GLOBAL_ENABLES_CMD   ||\n\t\t\tresp[2] != 0) {\n\t\tdev_warn(smi_info->io.dev,\n\t\t\t \"Invalid return from get global enables command: %ld %x %x %x\\n\",\n\t\t\t resp_len, resp[0], resp[1], resp[2]);\n\t\trv = -EINVAL;\n\t\tgoto out;\n\t} else {\n\t\t*enables = resp[3];\n\t}\n\nout:\n\tkfree(resp);\n\treturn rv;\n}\n\n \nstatic int set_global_enables(struct smi_info *smi_info, u8 enables)\n{\n\tunsigned char         msg[3];\n\tunsigned char         *resp;\n\tunsigned long         resp_len;\n\tint                   rv;\n\n\tresp = kmalloc(IPMI_MAX_MSG_LENGTH, GFP_KERNEL);\n\tif (!resp)\n\t\treturn -ENOMEM;\n\n\tmsg[0] = IPMI_NETFN_APP_REQUEST << 2;\n\tmsg[1] = IPMI_SET_BMC_GLOBAL_ENABLES_CMD;\n\tmsg[2] = enables;\n\tsmi_info->handlers->start_transaction(smi_info->si_sm, msg, 3);\n\n\trv = wait_for_msg_done(smi_info);\n\tif (rv) {\n\t\tdev_warn(smi_info->io.dev,\n\t\t\t \"Error getting response from set global enables command: %d\\n\",\n\t\t\t rv);\n\t\tgoto out;\n\t}\n\n\tresp_len = smi_info->handlers->get_result(smi_info->si_sm,\n\t\t\t\t\t\t  resp, IPMI_MAX_MSG_LENGTH);\n\n\tif (resp_len < 3 ||\n\t\t\tresp[0] != (IPMI_NETFN_APP_REQUEST | 1) << 2 ||\n\t\t\tresp[1] != IPMI_SET_BMC_GLOBAL_ENABLES_CMD) {\n\t\tdev_warn(smi_info->io.dev,\n\t\t\t \"Invalid return from set global enables command: %ld %x %x\\n\",\n\t\t\t resp_len, resp[0], resp[1]);\n\t\trv = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (resp[2] != 0)\n\t\trv = 1;\n\nout:\n\tkfree(resp);\n\treturn rv;\n}\n\n \nstatic void check_clr_rcv_irq(struct smi_info *smi_info)\n{\n\tu8 enables = 0;\n\tint rv;\n\n\trv = get_global_enables(smi_info, &enables);\n\tif (!rv) {\n\t\tif ((enables & IPMI_BMC_RCV_MSG_INTR) == 0)\n\t\t\t \n\t\t\treturn;\n\n\t\tenables &= ~IPMI_BMC_RCV_MSG_INTR;\n\t\trv = set_global_enables(smi_info, enables);\n\t}\n\n\tif (rv < 0) {\n\t\tdev_err(smi_info->io.dev,\n\t\t\t\"Cannot check clearing the rcv irq: %d\\n\", rv);\n\t\treturn;\n\t}\n\n\tif (rv) {\n\t\t \n\t\tdev_warn(smi_info->io.dev,\n\t\t\t \"The BMC does not support clearing the recv irq bit, compensating, but the BMC needs to be fixed.\\n\");\n\t\tsmi_info->cannot_disable_irq = true;\n\t}\n}\n\n \nstatic void check_set_rcv_irq(struct smi_info *smi_info)\n{\n\tu8 enables = 0;\n\tint rv;\n\n\tif (!smi_info->io.irq)\n\t\treturn;\n\n\trv = get_global_enables(smi_info, &enables);\n\tif (!rv) {\n\t\tenables |= IPMI_BMC_RCV_MSG_INTR;\n\t\trv = set_global_enables(smi_info, enables);\n\t}\n\n\tif (rv < 0) {\n\t\tdev_err(smi_info->io.dev,\n\t\t\t\"Cannot check setting the rcv irq: %d\\n\", rv);\n\t\treturn;\n\t}\n\n\tif (rv) {\n\t\t \n\t\tdev_warn(smi_info->io.dev,\n\t\t\t \"The BMC does not support setting the recv irq bit, compensating, but the BMC needs to be fixed.\\n\");\n\t\tsmi_info->cannot_disable_irq = true;\n\t\tsmi_info->irq_enable_broken = true;\n\t}\n}\n\nstatic int try_enable_event_buffer(struct smi_info *smi_info)\n{\n\tunsigned char         msg[3];\n\tunsigned char         *resp;\n\tunsigned long         resp_len;\n\tint                   rv = 0;\n\n\tresp = kmalloc(IPMI_MAX_MSG_LENGTH, GFP_KERNEL);\n\tif (!resp)\n\t\treturn -ENOMEM;\n\n\tmsg[0] = IPMI_NETFN_APP_REQUEST << 2;\n\tmsg[1] = IPMI_GET_BMC_GLOBAL_ENABLES_CMD;\n\tsmi_info->handlers->start_transaction(smi_info->si_sm, msg, 2);\n\n\trv = wait_for_msg_done(smi_info);\n\tif (rv) {\n\t\tpr_warn(\"Error getting response from get global enables command, the event buffer is not enabled\\n\");\n\t\tgoto out;\n\t}\n\n\tresp_len = smi_info->handlers->get_result(smi_info->si_sm,\n\t\t\t\t\t\t  resp, IPMI_MAX_MSG_LENGTH);\n\n\tif (resp_len < 4 ||\n\t\t\tresp[0] != (IPMI_NETFN_APP_REQUEST | 1) << 2 ||\n\t\t\tresp[1] != IPMI_GET_BMC_GLOBAL_ENABLES_CMD   ||\n\t\t\tresp[2] != 0) {\n\t\tpr_warn(\"Invalid return from get global enables command, cannot enable the event buffer\\n\");\n\t\trv = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (resp[3] & IPMI_BMC_EVT_MSG_BUFF) {\n\t\t \n\t\tsmi_info->supports_event_msg_buff = true;\n\t\tgoto out;\n\t}\n\n\tmsg[0] = IPMI_NETFN_APP_REQUEST << 2;\n\tmsg[1] = IPMI_SET_BMC_GLOBAL_ENABLES_CMD;\n\tmsg[2] = resp[3] | IPMI_BMC_EVT_MSG_BUFF;\n\tsmi_info->handlers->start_transaction(smi_info->si_sm, msg, 3);\n\n\trv = wait_for_msg_done(smi_info);\n\tif (rv) {\n\t\tpr_warn(\"Error getting response from set global, enables command, the event buffer is not enabled\\n\");\n\t\tgoto out;\n\t}\n\n\tresp_len = smi_info->handlers->get_result(smi_info->si_sm,\n\t\t\t\t\t\t  resp, IPMI_MAX_MSG_LENGTH);\n\n\tif (resp_len < 3 ||\n\t\t\tresp[0] != (IPMI_NETFN_APP_REQUEST | 1) << 2 ||\n\t\t\tresp[1] != IPMI_SET_BMC_GLOBAL_ENABLES_CMD) {\n\t\tpr_warn(\"Invalid return from get global, enables command, not enable the event buffer\\n\");\n\t\trv = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (resp[2] != 0)\n\t\t \n\t\trv = -ENOENT;\n\telse\n\t\tsmi_info->supports_event_msg_buff = true;\n\nout:\n\tkfree(resp);\n\treturn rv;\n}\n\n#define IPMI_SI_ATTR(name) \\\nstatic ssize_t name##_show(struct device *dev,\t\t\t\\\n\t\t\t   struct device_attribute *attr,\t\t\\\n\t\t\t   char *buf)\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tstruct smi_info *smi_info = dev_get_drvdata(dev);\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\treturn sysfs_emit(buf, \"%u\\n\", smi_get_stat(smi_info, name));\t\\\n}\t\t\t\t\t\t\t\t\t\\\nstatic DEVICE_ATTR_RO(name)\n\nstatic ssize_t type_show(struct device *dev,\n\t\t\t struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct smi_info *smi_info = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\", si_to_str[smi_info->io.si_type]);\n}\nstatic DEVICE_ATTR_RO(type);\n\nstatic ssize_t interrupts_enabled_show(struct device *dev,\n\t\t\t\t       struct device_attribute *attr,\n\t\t\t\t       char *buf)\n{\n\tstruct smi_info *smi_info = dev_get_drvdata(dev);\n\tint enabled = smi_info->io.irq && !smi_info->interrupt_disabled;\n\n\treturn sysfs_emit(buf, \"%d\\n\", enabled);\n}\nstatic DEVICE_ATTR_RO(interrupts_enabled);\n\nIPMI_SI_ATTR(short_timeouts);\nIPMI_SI_ATTR(long_timeouts);\nIPMI_SI_ATTR(idles);\nIPMI_SI_ATTR(interrupts);\nIPMI_SI_ATTR(attentions);\nIPMI_SI_ATTR(flag_fetches);\nIPMI_SI_ATTR(hosed_count);\nIPMI_SI_ATTR(complete_transactions);\nIPMI_SI_ATTR(events);\nIPMI_SI_ATTR(watchdog_pretimeouts);\nIPMI_SI_ATTR(incoming_messages);\n\nstatic ssize_t params_show(struct device *dev,\n\t\t\t   struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct smi_info *smi_info = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf,\n\t\t\t\"%s,%s,0x%lx,rsp=%d,rsi=%d,rsh=%d,irq=%d,ipmb=%d\\n\",\n\t\t\tsi_to_str[smi_info->io.si_type],\n\t\t\taddr_space_to_str[smi_info->io.addr_space],\n\t\t\tsmi_info->io.addr_data,\n\t\t\tsmi_info->io.regspacing,\n\t\t\tsmi_info->io.regsize,\n\t\t\tsmi_info->io.regshift,\n\t\t\tsmi_info->io.irq,\n\t\t\tsmi_info->io.slave_addr);\n}\nstatic DEVICE_ATTR_RO(params);\n\nstatic struct attribute *ipmi_si_dev_attrs[] = {\n\t&dev_attr_type.attr,\n\t&dev_attr_interrupts_enabled.attr,\n\t&dev_attr_short_timeouts.attr,\n\t&dev_attr_long_timeouts.attr,\n\t&dev_attr_idles.attr,\n\t&dev_attr_interrupts.attr,\n\t&dev_attr_attentions.attr,\n\t&dev_attr_flag_fetches.attr,\n\t&dev_attr_hosed_count.attr,\n\t&dev_attr_complete_transactions.attr,\n\t&dev_attr_events.attr,\n\t&dev_attr_watchdog_pretimeouts.attr,\n\t&dev_attr_incoming_messages.attr,\n\t&dev_attr_params.attr,\n\tNULL\n};\n\nstatic const struct attribute_group ipmi_si_dev_attr_group = {\n\t.attrs\t\t= ipmi_si_dev_attrs,\n};\n\n \nstatic int oem_data_avail_to_receive_msg_avail(struct smi_info *smi_info)\n{\n\tsmi_info->msg_flags = ((smi_info->msg_flags & ~OEM_DATA_AVAIL) |\n\t\t\t       RECEIVE_MSG_AVAIL);\n\treturn 1;\n}\n\n \n#define DELL_POWEREDGE_8G_BMC_DEVICE_ID  0x20\n#define DELL_POWEREDGE_8G_BMC_DEVICE_REV 0x80\n#define DELL_POWEREDGE_8G_BMC_IPMI_VERSION 0x51\n#define DELL_IANA_MFR_ID 0x0002a2\nstatic void setup_dell_poweredge_oem_data_handler(struct smi_info *smi_info)\n{\n\tstruct ipmi_device_id *id = &smi_info->device_id;\n\tif (id->manufacturer_id == DELL_IANA_MFR_ID) {\n\t\tif (id->device_id       == DELL_POWEREDGE_8G_BMC_DEVICE_ID  &&\n\t\t    id->device_revision == DELL_POWEREDGE_8G_BMC_DEVICE_REV &&\n\t\t    id->ipmi_version   == DELL_POWEREDGE_8G_BMC_IPMI_VERSION) {\n\t\t\tsmi_info->oem_data_avail_handler =\n\t\t\t\toem_data_avail_to_receive_msg_avail;\n\t\t} else if (ipmi_version_major(id) < 1 ||\n\t\t\t   (ipmi_version_major(id) == 1 &&\n\t\t\t    ipmi_version_minor(id) < 5)) {\n\t\t\tsmi_info->oem_data_avail_handler =\n\t\t\t\toem_data_avail_to_receive_msg_avail;\n\t\t}\n\t}\n}\n\n#define CANNOT_RETURN_REQUESTED_LENGTH 0xCA\nstatic void return_hosed_msg_badsize(struct smi_info *smi_info)\n{\n\tstruct ipmi_smi_msg *msg = smi_info->curr_msg;\n\n\t \n\tmsg->rsp[0] = msg->data[0] | 4;\n\tmsg->rsp[1] = msg->data[1];\n\tmsg->rsp[2] = CANNOT_RETURN_REQUESTED_LENGTH;\n\tmsg->rsp_size = 3;\n\tsmi_info->curr_msg = NULL;\n\tdeliver_recv_msg(smi_info, msg);\n}\n\n \n\n#define STORAGE_NETFN 0x0A\n#define STORAGE_CMD_GET_SDR 0x23\nstatic int dell_poweredge_bt_xaction_handler(struct notifier_block *self,\n\t\t\t\t\t     unsigned long unused,\n\t\t\t\t\t     void *in)\n{\n\tstruct smi_info *smi_info = in;\n\tunsigned char *data = smi_info->curr_msg->data;\n\tunsigned int size   = smi_info->curr_msg->data_size;\n\tif (size >= 8 &&\n\t    (data[0]>>2) == STORAGE_NETFN &&\n\t    data[1] == STORAGE_CMD_GET_SDR &&\n\t    data[7] == 0x3A) {\n\t\treturn_hosed_msg_badsize(smi_info);\n\t\treturn NOTIFY_STOP;\n\t}\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block dell_poweredge_bt_xaction_notifier = {\n\t.notifier_call\t= dell_poweredge_bt_xaction_handler,\n};\n\n \nstatic void\nsetup_dell_poweredge_bt_xaction_handler(struct smi_info *smi_info)\n{\n\tstruct ipmi_device_id *id = &smi_info->device_id;\n\tif (id->manufacturer_id == DELL_IANA_MFR_ID &&\n\t    smi_info->io.si_type == SI_BT)\n\t\tregister_xaction_notifier(&dell_poweredge_bt_xaction_notifier);\n}\n\n \n\nstatic void setup_oem_data_handler(struct smi_info *smi_info)\n{\n\tsetup_dell_poweredge_oem_data_handler(smi_info);\n}\n\nstatic void setup_xaction_handlers(struct smi_info *smi_info)\n{\n\tsetup_dell_poweredge_bt_xaction_handler(smi_info);\n}\n\nstatic void check_for_broken_irqs(struct smi_info *smi_info)\n{\n\tcheck_clr_rcv_irq(smi_info);\n\tcheck_set_rcv_irq(smi_info);\n}\n\nstatic inline void stop_timer_and_thread(struct smi_info *smi_info)\n{\n\tif (smi_info->thread != NULL) {\n\t\tkthread_stop(smi_info->thread);\n\t\tsmi_info->thread = NULL;\n\t}\n\n\tsmi_info->timer_can_start = false;\n\tdel_timer_sync(&smi_info->si_timer);\n}\n\nstatic struct smi_info *find_dup_si(struct smi_info *info)\n{\n\tstruct smi_info *e;\n\n\tlist_for_each_entry(e, &smi_infos, link) {\n\t\tif (e->io.addr_space != info->io.addr_space)\n\t\t\tcontinue;\n\t\tif (e->io.addr_data == info->io.addr_data) {\n\t\t\t \n\t\t\tif (info->io.slave_addr && !e->io.slave_addr)\n\t\t\t\te->io.slave_addr = info->io.slave_addr;\n\t\t\treturn e;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nint ipmi_si_add_smi(struct si_sm_io *io)\n{\n\tint rv = 0;\n\tstruct smi_info *new_smi, *dup;\n\n\t \n\tif (io->addr_source != SI_HARDCODED && io->addr_source != SI_HOTMOD &&\n\t    ipmi_si_hardcode_match(io->addr_space, io->addr_data)) {\n\t\tdev_info(io->dev,\n\t\t\t \"Hard-coded device at this address already exists\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (!io->io_setup) {\n\t\tif (io->addr_space == IPMI_IO_ADDR_SPACE) {\n\t\t\tio->io_setup = ipmi_si_port_setup;\n\t\t} else if (io->addr_space == IPMI_MEM_ADDR_SPACE) {\n\t\t\tio->io_setup = ipmi_si_mem_setup;\n\t\t} else {\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tnew_smi = kzalloc(sizeof(*new_smi), GFP_KERNEL);\n\tif (!new_smi)\n\t\treturn -ENOMEM;\n\tspin_lock_init(&new_smi->si_lock);\n\n\tnew_smi->io = *io;\n\n\tmutex_lock(&smi_infos_lock);\n\tdup = find_dup_si(new_smi);\n\tif (dup) {\n\t\tif (new_smi->io.addr_source == SI_ACPI &&\n\t\t    dup->io.addr_source == SI_SMBIOS) {\n\t\t\t \n\t\t\tdev_info(dup->io.dev,\n\t\t\t\t \"Removing SMBIOS-specified %s state machine in favor of ACPI\\n\",\n\t\t\t\t si_to_str[new_smi->io.si_type]);\n\t\t\tcleanup_one_si(dup);\n\t\t} else {\n\t\t\tdev_info(new_smi->io.dev,\n\t\t\t\t \"%s-specified %s state machine: duplicate\\n\",\n\t\t\t\t ipmi_addr_src_to_str(new_smi->io.addr_source),\n\t\t\t\t si_to_str[new_smi->io.si_type]);\n\t\t\trv = -EBUSY;\n\t\t\tkfree(new_smi);\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\tpr_info(\"Adding %s-specified %s state machine\\n\",\n\t\tipmi_addr_src_to_str(new_smi->io.addr_source),\n\t\tsi_to_str[new_smi->io.si_type]);\n\n\tlist_add_tail(&new_smi->link, &smi_infos);\n\n\tif (initialized)\n\t\trv = try_smi_init(new_smi);\nout_err:\n\tmutex_unlock(&smi_infos_lock);\n\treturn rv;\n}\n\n \nstatic int try_smi_init(struct smi_info *new_smi)\n{\n\tint rv = 0;\n\tint i;\n\n\tpr_info(\"Trying %s-specified %s state machine at %s address 0x%lx, slave address 0x%x, irq %d\\n\",\n\t\tipmi_addr_src_to_str(new_smi->io.addr_source),\n\t\tsi_to_str[new_smi->io.si_type],\n\t\taddr_space_to_str[new_smi->io.addr_space],\n\t\tnew_smi->io.addr_data,\n\t\tnew_smi->io.slave_addr, new_smi->io.irq);\n\n\tswitch (new_smi->io.si_type) {\n\tcase SI_KCS:\n\t\tnew_smi->handlers = &kcs_smi_handlers;\n\t\tbreak;\n\n\tcase SI_SMIC:\n\t\tnew_smi->handlers = &smic_smi_handlers;\n\t\tbreak;\n\n\tcase SI_BT:\n\t\tnew_smi->handlers = &bt_smi_handlers;\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\trv = -EIO;\n\t\tgoto out_err;\n\t}\n\n\tnew_smi->si_num = smi_num;\n\n\t \n\tif (!new_smi->io.dev) {\n\t\tpr_err(\"IPMI interface added with no device\\n\");\n\t\trv = -EIO;\n\t\tgoto out_err;\n\t}\n\n\t \n\tnew_smi->si_sm = kmalloc(new_smi->handlers->size(), GFP_KERNEL);\n\tif (!new_smi->si_sm) {\n\t\trv = -ENOMEM;\n\t\tgoto out_err;\n\t}\n\tnew_smi->io.io_size = new_smi->handlers->init_data(new_smi->si_sm,\n\t\t\t\t\t\t\t   &new_smi->io);\n\n\t \n\trv = new_smi->io.io_setup(&new_smi->io);\n\tif (rv) {\n\t\tdev_err(new_smi->io.dev, \"Could not set up I/O space\\n\");\n\t\tgoto out_err;\n\t}\n\n\t \n\tif (new_smi->handlers->detect(new_smi->si_sm)) {\n\t\tif (new_smi->io.addr_source)\n\t\t\tdev_err(new_smi->io.dev,\n\t\t\t\t\"Interface detection failed\\n\");\n\t\trv = -ENODEV;\n\t\tgoto out_err;\n\t}\n\n\t \n\trv = try_get_dev_id(new_smi);\n\tif (rv) {\n\t\tif (new_smi->io.addr_source)\n\t\t\tdev_err(new_smi->io.dev,\n\t\t\t       \"There appears to be no BMC at this location\\n\");\n\t\tgoto out_err;\n\t}\n\n\tsetup_oem_data_handler(new_smi);\n\tsetup_xaction_handlers(new_smi);\n\tcheck_for_broken_irqs(new_smi);\n\n\tnew_smi->waiting_msg = NULL;\n\tnew_smi->curr_msg = NULL;\n\tatomic_set(&new_smi->req_events, 0);\n\tnew_smi->run_to_completion = false;\n\tfor (i = 0; i < SI_NUM_STATS; i++)\n\t\tatomic_set(&new_smi->stats[i], 0);\n\n\tnew_smi->interrupt_disabled = true;\n\tatomic_set(&new_smi->need_watch, 0);\n\n\trv = try_enable_event_buffer(new_smi);\n\tif (rv == 0)\n\t\tnew_smi->has_event_buffer = true;\n\n\t \n\tstart_clear_flags(new_smi);\n\n\t \n\tif (new_smi->io.irq) {\n\t\tnew_smi->interrupt_disabled = false;\n\t\tatomic_set(&new_smi->req_events, 1);\n\t}\n\n\tdev_set_drvdata(new_smi->io.dev, new_smi);\n\trv = device_add_group(new_smi->io.dev, &ipmi_si_dev_attr_group);\n\tif (rv) {\n\t\tdev_err(new_smi->io.dev,\n\t\t\t\"Unable to add device attributes: error %d\\n\",\n\t\t\trv);\n\t\tgoto out_err;\n\t}\n\tnew_smi->dev_group_added = true;\n\n\trv = ipmi_register_smi(&handlers,\n\t\t\t       new_smi,\n\t\t\t       new_smi->io.dev,\n\t\t\t       new_smi->io.slave_addr);\n\tif (rv) {\n\t\tdev_err(new_smi->io.dev,\n\t\t\t\"Unable to register device: error %d\\n\",\n\t\t\trv);\n\t\tgoto out_err;\n\t}\n\n\t \n\tsmi_num++;\n\n\tdev_info(new_smi->io.dev, \"IPMI %s interface initialized\\n\",\n\t\t si_to_str[new_smi->io.si_type]);\n\n\tWARN_ON(new_smi->io.dev->init_name != NULL);\n\n out_err:\n\tif (rv && new_smi->io.io_cleanup) {\n\t\tnew_smi->io.io_cleanup(&new_smi->io);\n\t\tnew_smi->io.io_cleanup = NULL;\n\t}\n\n\tif (rv && new_smi->si_sm) {\n\t\tkfree(new_smi->si_sm);\n\t\tnew_smi->si_sm = NULL;\n\t}\n\n\treturn rv;\n}\n\nstatic int __init init_ipmi_si(void)\n{\n\tstruct smi_info *e;\n\tenum ipmi_addr_src type = SI_INVALID;\n\n\tif (initialized)\n\t\treturn 0;\n\n\tipmi_hardcode_init();\n\n\tpr_info(\"IPMI System Interface driver\\n\");\n\n\tipmi_si_platform_init();\n\n\tipmi_si_pci_init();\n\n\tipmi_si_parisc_init();\n\n\t \n\tmutex_lock(&smi_infos_lock);\n\tlist_for_each_entry(e, &smi_infos, link) {\n\t\t \n\t\tif (e->io.irq && (!type || e->io.addr_source == type)) {\n\t\t\tif (!try_smi_init(e)) {\n\t\t\t\ttype = e->io.addr_source;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (type)\n\t\tgoto skip_fallback_noirq;\n\n\t \n\n\tlist_for_each_entry(e, &smi_infos, link) {\n\t\tif (!e->io.irq && (!type || e->io.addr_source == type)) {\n\t\t\tif (!try_smi_init(e)) {\n\t\t\t\ttype = e->io.addr_source;\n\t\t\t}\n\t\t}\n\t}\n\nskip_fallback_noirq:\n\tinitialized = true;\n\tmutex_unlock(&smi_infos_lock);\n\n\tif (type)\n\t\treturn 0;\n\n\tmutex_lock(&smi_infos_lock);\n\tif (unload_when_empty && list_empty(&smi_infos)) {\n\t\tmutex_unlock(&smi_infos_lock);\n\t\tcleanup_ipmi_si();\n\t\tpr_warn(\"Unable to find any System Interface(s)\\n\");\n\t\treturn -ENODEV;\n\t} else {\n\t\tmutex_unlock(&smi_infos_lock);\n\t\treturn 0;\n\t}\n}\nmodule_init(init_ipmi_si);\n\nstatic void wait_msg_processed(struct smi_info *smi_info)\n{\n\tunsigned long jiffies_now;\n\tlong time_diff;\n\n\twhile (smi_info->curr_msg || (smi_info->si_state != SI_NORMAL)) {\n\t\tjiffies_now = jiffies;\n\t\ttime_diff = (((long)jiffies_now - (long)smi_info->last_timeout_jiffies)\n\t\t     * SI_USEC_PER_JIFFY);\n\t\tsmi_event_handler(smi_info, time_diff);\n\t\tschedule_timeout_uninterruptible(1);\n\t}\n}\n\nstatic void shutdown_smi(void *send_info)\n{\n\tstruct smi_info *smi_info = send_info;\n\n\tif (smi_info->dev_group_added) {\n\t\tdevice_remove_group(smi_info->io.dev, &ipmi_si_dev_attr_group);\n\t\tsmi_info->dev_group_added = false;\n\t}\n\tif (smi_info->io.dev)\n\t\tdev_set_drvdata(smi_info->io.dev, NULL);\n\n\t \n\tsmi_info->interrupt_disabled = true;\n\tif (smi_info->io.irq_cleanup) {\n\t\tsmi_info->io.irq_cleanup(&smi_info->io);\n\t\tsmi_info->io.irq_cleanup = NULL;\n\t}\n\tstop_timer_and_thread(smi_info);\n\n\t \n\tsynchronize_rcu();\n\n\t \n\twait_msg_processed(smi_info);\n\n\tif (smi_info->handlers)\n\t\tdisable_si_irq(smi_info);\n\n\twait_msg_processed(smi_info);\n\n\tif (smi_info->handlers)\n\t\tsmi_info->handlers->cleanup(smi_info->si_sm);\n\n\tif (smi_info->io.io_cleanup) {\n\t\tsmi_info->io.io_cleanup(&smi_info->io);\n\t\tsmi_info->io.io_cleanup = NULL;\n\t}\n\n\tkfree(smi_info->si_sm);\n\tsmi_info->si_sm = NULL;\n\n\tsmi_info->intf = NULL;\n}\n\n \nstatic void cleanup_one_si(struct smi_info *smi_info)\n{\n\tif (!smi_info)\n\t\treturn;\n\n\tlist_del(&smi_info->link);\n\tipmi_unregister_smi(smi_info->intf);\n\tkfree(smi_info);\n}\n\nvoid ipmi_si_remove_by_dev(struct device *dev)\n{\n\tstruct smi_info *e;\n\n\tmutex_lock(&smi_infos_lock);\n\tlist_for_each_entry(e, &smi_infos, link) {\n\t\tif (e->io.dev == dev) {\n\t\t\tcleanup_one_si(e);\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&smi_infos_lock);\n}\n\nstruct device *ipmi_si_remove_by_data(int addr_space, enum si_type si_type,\n\t\t\t\t      unsigned long addr)\n{\n\t \n\tstruct smi_info *e, *tmp_e;\n\tstruct device *dev = NULL;\n\n\tmutex_lock(&smi_infos_lock);\n\tlist_for_each_entry_safe(e, tmp_e, &smi_infos, link) {\n\t\tif (e->io.addr_space != addr_space)\n\t\t\tcontinue;\n\t\tif (e->io.si_type != si_type)\n\t\t\tcontinue;\n\t\tif (e->io.addr_data == addr) {\n\t\t\tdev = get_device(e->io.dev);\n\t\t\tcleanup_one_si(e);\n\t\t}\n\t}\n\tmutex_unlock(&smi_infos_lock);\n\n\treturn dev;\n}\n\nstatic void cleanup_ipmi_si(void)\n{\n\tstruct smi_info *e, *tmp_e;\n\n\tif (!initialized)\n\t\treturn;\n\n\tipmi_si_pci_shutdown();\n\n\tipmi_si_parisc_shutdown();\n\n\tipmi_si_platform_shutdown();\n\n\tmutex_lock(&smi_infos_lock);\n\tlist_for_each_entry_safe(e, tmp_e, &smi_infos, link)\n\t\tcleanup_one_si(e);\n\tmutex_unlock(&smi_infos_lock);\n\n\tipmi_si_hardcode_exit();\n\tipmi_si_hotmod_exit();\n}\nmodule_exit(cleanup_ipmi_si);\n\nMODULE_ALIAS(\"platform:dmi-ipmi-si\");\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Corey Minyard <minyard@mvista.com>\");\nMODULE_DESCRIPTION(\"Interface to the IPMI driver for the KCS, SMIC, and BT system interfaces.\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}