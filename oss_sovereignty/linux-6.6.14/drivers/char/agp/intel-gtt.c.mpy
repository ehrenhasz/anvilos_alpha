{
  "module_name": "intel-gtt.c",
  "hash_id": "d466e2f6ca9b55d23b63165c1ffad80a076fb6efbf9833445564a84e684c45eb",
  "original_prompt": "Ingested from linux-6.6.14/drivers/char/agp/intel-gtt.c",
  "human_readable_source": " \n\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/kernel.h>\n#include <linux/pagemap.h>\n#include <linux/agp_backend.h>\n#include <linux/iommu.h>\n#include <linux/delay.h>\n#include <asm/smp.h>\n#include \"agp.h\"\n#include \"intel-agp.h\"\n#include <drm/intel-gtt.h>\n#include <asm/set_memory.h>\n\n \n#ifdef CONFIG_INTEL_IOMMU\n#define USE_PCI_DMA_API 1\n#else\n#define USE_PCI_DMA_API 0\n#endif\n\nstruct intel_gtt_driver {\n\tunsigned int gen : 8;\n\tunsigned int is_g33 : 1;\n\tunsigned int is_pineview : 1;\n\tunsigned int is_ironlake : 1;\n\tunsigned int has_pgtbl_enable : 1;\n\tunsigned int dma_mask_size : 8;\n\t \n\tint (*setup)(void);\n\t \n\tvoid (*cleanup)(void);\n\tvoid (*write_entry)(dma_addr_t addr, unsigned int entry, unsigned int flags);\n\t \n\tbool (*check_flags)(unsigned int flags);\n\tvoid (*chipset_flush)(void);\n};\n\nstatic struct _intel_private {\n\tconst struct intel_gtt_driver *driver;\n\tstruct pci_dev *pcidev;\t \n\tstruct pci_dev *bridge_dev;\n\tu8 __iomem *registers;\n\tphys_addr_t gtt_phys_addr;\n\tu32 PGETBL_save;\n\tu32 __iomem *gtt;\t\t \n\tbool clear_fake_agp;  \n\tint num_dcache_entries;\n\tvoid __iomem *i9xx_flush_page;\n\tchar *i81x_gtt_table;\n\tstruct resource ifp_resource;\n\tint resource_valid;\n\tstruct page *scratch_page;\n\tphys_addr_t scratch_page_dma;\n\tint refcount;\n\t \n\tunsigned int needs_dmar : 1;\n\tphys_addr_t gma_bus_addr;\n\t \n\tresource_size_t stolen_size;\n\t \n\tunsigned int gtt_total_entries;\n\t \n\tunsigned int gtt_mappable_entries;\n} intel_private;\n\n#define INTEL_GTT_GEN\tintel_private.driver->gen\n#define IS_G33\t\tintel_private.driver->is_g33\n#define IS_PINEVIEW\tintel_private.driver->is_pineview\n#define IS_IRONLAKE\tintel_private.driver->is_ironlake\n#define HAS_PGTBL_EN\tintel_private.driver->has_pgtbl_enable\n\n#if IS_ENABLED(CONFIG_AGP_INTEL)\nstatic int intel_gtt_map_memory(struct page **pages,\n\t\t\t\tunsigned int num_entries,\n\t\t\t\tstruct sg_table *st)\n{\n\tstruct scatterlist *sg;\n\tint i;\n\n\tDBG(\"try mapping %lu pages\\n\", (unsigned long)num_entries);\n\n\tif (sg_alloc_table(st, num_entries, GFP_KERNEL))\n\t\tgoto err;\n\n\tfor_each_sg(st->sgl, sg, num_entries, i)\n\t\tsg_set_page(sg, pages[i], PAGE_SIZE, 0);\n\n\tif (!dma_map_sg(&intel_private.pcidev->dev, st->sgl, st->nents,\n\t\t\tDMA_BIDIRECTIONAL))\n\t\tgoto err;\n\n\treturn 0;\n\nerr:\n\tsg_free_table(st);\n\treturn -ENOMEM;\n}\n\nstatic void intel_gtt_unmap_memory(struct scatterlist *sg_list, int num_sg)\n{\n\tstruct sg_table st;\n\tDBG(\"try unmapping %lu pages\\n\", (unsigned long)mem->page_count);\n\n\tdma_unmap_sg(&intel_private.pcidev->dev, sg_list, num_sg,\n\t\t     DMA_BIDIRECTIONAL);\n\n\tst.sgl = sg_list;\n\tst.orig_nents = st.nents = num_sg;\n\n\tsg_free_table(&st);\n}\n\nstatic void intel_fake_agp_enable(struct agp_bridge_data *bridge, u32 mode)\n{\n\treturn;\n}\n\n \nstatic struct page *i8xx_alloc_pages(void)\n{\n\tstruct page *page;\n\n\tpage = alloc_pages(GFP_KERNEL | GFP_DMA32, 2);\n\tif (page == NULL)\n\t\treturn NULL;\n\n\tif (set_pages_uc(page, 4) < 0) {\n\t\tset_pages_wb(page, 4);\n\t\t__free_pages(page, 2);\n\t\treturn NULL;\n\t}\n\tatomic_inc(&agp_bridge->current_memory_agp);\n\treturn page;\n}\n\nstatic void i8xx_destroy_pages(struct page *page)\n{\n\tif (page == NULL)\n\t\treturn;\n\n\tset_pages_wb(page, 4);\n\t__free_pages(page, 2);\n\tatomic_dec(&agp_bridge->current_memory_agp);\n}\n#endif\n\n#define I810_GTT_ORDER 4\nstatic int i810_setup(void)\n{\n\tphys_addr_t reg_addr;\n\tchar *gtt_table;\n\n\t \n\tgtt_table = alloc_gatt_pages(I810_GTT_ORDER);\n\tif (gtt_table == NULL)\n\t\treturn -ENOMEM;\n\tintel_private.i81x_gtt_table = gtt_table;\n\n\treg_addr = pci_resource_start(intel_private.pcidev, I810_MMADR_BAR);\n\n\tintel_private.registers = ioremap(reg_addr, KB(64));\n\tif (!intel_private.registers)\n\t\treturn -ENOMEM;\n\n\twritel(virt_to_phys(gtt_table) | I810_PGETBL_ENABLED,\n\t       intel_private.registers+I810_PGETBL_CTL);\n\n\tintel_private.gtt_phys_addr = reg_addr + I810_PTE_BASE;\n\n\tif ((readl(intel_private.registers+I810_DRAM_CTL)\n\t\t& I810_DRAM_ROW_0) == I810_DRAM_ROW_0_SDRAM) {\n\t\tdev_info(&intel_private.pcidev->dev,\n\t\t\t \"detected 4MB dedicated video ram\\n\");\n\t\tintel_private.num_dcache_entries = 1024;\n\t}\n\n\treturn 0;\n}\n\nstatic void i810_cleanup(void)\n{\n\twritel(0, intel_private.registers+I810_PGETBL_CTL);\n\tfree_gatt_pages(intel_private.i81x_gtt_table, I810_GTT_ORDER);\n}\n\n#if IS_ENABLED(CONFIG_AGP_INTEL)\nstatic int i810_insert_dcache_entries(struct agp_memory *mem, off_t pg_start,\n\t\t\t\t      int type)\n{\n\tint i;\n\n\tif ((pg_start + mem->page_count)\n\t\t\t> intel_private.num_dcache_entries)\n\t\treturn -EINVAL;\n\n\tif (!mem->is_flushed)\n\t\tglobal_cache_flush();\n\n\tfor (i = pg_start; i < (pg_start + mem->page_count); i++) {\n\t\tdma_addr_t addr = i << PAGE_SHIFT;\n\t\tintel_private.driver->write_entry(addr,\n\t\t\t\t\t\t  i, type);\n\t}\n\twmb();\n\n\treturn 0;\n}\n\n \nstatic struct agp_memory *alloc_agpphysmem_i8xx(size_t pg_count, int type)\n{\n\tstruct agp_memory *new;\n\tstruct page *page;\n\n\tswitch (pg_count) {\n\tcase 1: page = agp_bridge->driver->agp_alloc_page(agp_bridge);\n\t\tbreak;\n\tcase 4:\n\t\t \n\t\tpage = i8xx_alloc_pages();\n\t\tbreak;\n\tdefault:\n\t\treturn NULL;\n\t}\n\n\tif (page == NULL)\n\t\treturn NULL;\n\n\tnew = agp_create_memory(pg_count);\n\tif (new == NULL)\n\t\treturn NULL;\n\n\tnew->pages[0] = page;\n\tif (pg_count == 4) {\n\t\t \n\t\tnew->pages[1] = new->pages[0] + 1;\n\t\tnew->pages[2] = new->pages[1] + 1;\n\t\tnew->pages[3] = new->pages[2] + 1;\n\t}\n\tnew->page_count = pg_count;\n\tnew->num_scratch_pages = pg_count;\n\tnew->type = AGP_PHYS_MEMORY;\n\tnew->physical = page_to_phys(new->pages[0]);\n\treturn new;\n}\n\nstatic void intel_i810_free_by_type(struct agp_memory *curr)\n{\n\tagp_free_key(curr->key);\n\tif (curr->type == AGP_PHYS_MEMORY) {\n\t\tif (curr->page_count == 4)\n\t\t\ti8xx_destroy_pages(curr->pages[0]);\n\t\telse {\n\t\t\tagp_bridge->driver->agp_destroy_page(curr->pages[0],\n\t\t\t\t\t\t\t     AGP_PAGE_DESTROY_UNMAP);\n\t\t\tagp_bridge->driver->agp_destroy_page(curr->pages[0],\n\t\t\t\t\t\t\t     AGP_PAGE_DESTROY_FREE);\n\t\t}\n\t\tagp_free_page_array(curr);\n\t}\n\tkfree(curr);\n}\n#endif\n\nstatic int intel_gtt_setup_scratch_page(void)\n{\n\tstruct page *page;\n\tdma_addr_t dma_addr;\n\n\tpage = alloc_page(GFP_KERNEL | GFP_DMA32 | __GFP_ZERO);\n\tif (page == NULL)\n\t\treturn -ENOMEM;\n\tset_pages_uc(page, 1);\n\n\tif (intel_private.needs_dmar) {\n\t\tdma_addr = dma_map_page(&intel_private.pcidev->dev, page, 0,\n\t\t\t\t\tPAGE_SIZE, DMA_BIDIRECTIONAL);\n\t\tif (dma_mapping_error(&intel_private.pcidev->dev, dma_addr)) {\n\t\t\t__free_page(page);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tintel_private.scratch_page_dma = dma_addr;\n\t} else\n\t\tintel_private.scratch_page_dma = page_to_phys(page);\n\n\tintel_private.scratch_page = page;\n\n\treturn 0;\n}\n\nstatic void i810_write_entry(dma_addr_t addr, unsigned int entry,\n\t\t\t     unsigned int flags)\n{\n\tu32 pte_flags = I810_PTE_VALID;\n\n\tswitch (flags) {\n\tcase AGP_DCACHE_MEMORY:\n\t\tpte_flags |= I810_PTE_LOCAL;\n\t\tbreak;\n\tcase AGP_USER_CACHED_MEMORY:\n\t\tpte_flags |= I830_PTE_SYSTEM_CACHED;\n\t\tbreak;\n\t}\n\n\twritel_relaxed(addr | pte_flags, intel_private.gtt + entry);\n}\n\nstatic resource_size_t intel_gtt_stolen_size(void)\n{\n\tu16 gmch_ctrl;\n\tu8 rdct;\n\tint local = 0;\n\tstatic const int ddt[4] = { 0, 16, 32, 64 };\n\tresource_size_t stolen_size = 0;\n\n\tif (INTEL_GTT_GEN == 1)\n\t\treturn 0;  \n\n\tpci_read_config_word(intel_private.bridge_dev,\n\t\t\t     I830_GMCH_CTRL, &gmch_ctrl);\n\n\tif (intel_private.bridge_dev->device == PCI_DEVICE_ID_INTEL_82830_HB ||\n\t    intel_private.bridge_dev->device == PCI_DEVICE_ID_INTEL_82845G_HB) {\n\t\tswitch (gmch_ctrl & I830_GMCH_GMS_MASK) {\n\t\tcase I830_GMCH_GMS_STOLEN_512:\n\t\t\tstolen_size = KB(512);\n\t\t\tbreak;\n\t\tcase I830_GMCH_GMS_STOLEN_1024:\n\t\t\tstolen_size = MB(1);\n\t\t\tbreak;\n\t\tcase I830_GMCH_GMS_STOLEN_8192:\n\t\t\tstolen_size = MB(8);\n\t\t\tbreak;\n\t\tcase I830_GMCH_GMS_LOCAL:\n\t\t\trdct = readb(intel_private.registers+I830_RDRAM_CHANNEL_TYPE);\n\t\t\tstolen_size = (I830_RDRAM_ND(rdct) + 1) *\n\t\t\t\t\tMB(ddt[I830_RDRAM_DDT(rdct)]);\n\t\t\tlocal = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tstolen_size = 0;\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tswitch (gmch_ctrl & I855_GMCH_GMS_MASK) {\n\t\tcase I855_GMCH_GMS_STOLEN_1M:\n\t\t\tstolen_size = MB(1);\n\t\t\tbreak;\n\t\tcase I855_GMCH_GMS_STOLEN_4M:\n\t\t\tstolen_size = MB(4);\n\t\t\tbreak;\n\t\tcase I855_GMCH_GMS_STOLEN_8M:\n\t\t\tstolen_size = MB(8);\n\t\t\tbreak;\n\t\tcase I855_GMCH_GMS_STOLEN_16M:\n\t\t\tstolen_size = MB(16);\n\t\t\tbreak;\n\t\tcase I855_GMCH_GMS_STOLEN_32M:\n\t\t\tstolen_size = MB(32);\n\t\t\tbreak;\n\t\tcase I915_GMCH_GMS_STOLEN_48M:\n\t\t\tstolen_size = MB(48);\n\t\t\tbreak;\n\t\tcase I915_GMCH_GMS_STOLEN_64M:\n\t\t\tstolen_size = MB(64);\n\t\t\tbreak;\n\t\tcase G33_GMCH_GMS_STOLEN_128M:\n\t\t\tstolen_size = MB(128);\n\t\t\tbreak;\n\t\tcase G33_GMCH_GMS_STOLEN_256M:\n\t\t\tstolen_size = MB(256);\n\t\t\tbreak;\n\t\tcase INTEL_GMCH_GMS_STOLEN_96M:\n\t\t\tstolen_size = MB(96);\n\t\t\tbreak;\n\t\tcase INTEL_GMCH_GMS_STOLEN_160M:\n\t\t\tstolen_size = MB(160);\n\t\t\tbreak;\n\t\tcase INTEL_GMCH_GMS_STOLEN_224M:\n\t\t\tstolen_size = MB(224);\n\t\t\tbreak;\n\t\tcase INTEL_GMCH_GMS_STOLEN_352M:\n\t\t\tstolen_size = MB(352);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tstolen_size = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (stolen_size > 0) {\n\t\tdev_info(&intel_private.bridge_dev->dev, \"detected %lluK %s memory\\n\",\n\t\t       (u64)stolen_size / KB(1), local ? \"local\" : \"stolen\");\n\t} else {\n\t\tdev_info(&intel_private.bridge_dev->dev,\n\t\t       \"no pre-allocated video memory detected\\n\");\n\t\tstolen_size = 0;\n\t}\n\n\treturn stolen_size;\n}\n\nstatic void i965_adjust_pgetbl_size(unsigned int size_flag)\n{\n\tu32 pgetbl_ctl, pgetbl_ctl2;\n\n\t \n\tpgetbl_ctl2 = readl(intel_private.registers+I965_PGETBL_CTL2);\n\tpgetbl_ctl2 &= ~I810_PGETBL_ENABLED;\n\twritel(pgetbl_ctl2, intel_private.registers+I965_PGETBL_CTL2);\n\n\t \n\tpgetbl_ctl = readl(intel_private.registers+I810_PGETBL_CTL);\n\tpgetbl_ctl &= ~I965_PGETBL_SIZE_MASK;\n\tpgetbl_ctl |= size_flag;\n\twritel(pgetbl_ctl, intel_private.registers+I810_PGETBL_CTL);\n}\n\nstatic unsigned int i965_gtt_total_entries(void)\n{\n\tint size;\n\tu32 pgetbl_ctl;\n\tu16 gmch_ctl;\n\n\tpci_read_config_word(intel_private.bridge_dev,\n\t\t\t     I830_GMCH_CTRL, &gmch_ctl);\n\n\tif (INTEL_GTT_GEN == 5) {\n\t\tswitch (gmch_ctl & G4x_GMCH_SIZE_MASK) {\n\t\tcase G4x_GMCH_SIZE_1M:\n\t\tcase G4x_GMCH_SIZE_VT_1M:\n\t\t\ti965_adjust_pgetbl_size(I965_PGETBL_SIZE_1MB);\n\t\t\tbreak;\n\t\tcase G4x_GMCH_SIZE_VT_1_5M:\n\t\t\ti965_adjust_pgetbl_size(I965_PGETBL_SIZE_1_5MB);\n\t\t\tbreak;\n\t\tcase G4x_GMCH_SIZE_2M:\n\t\tcase G4x_GMCH_SIZE_VT_2M:\n\t\t\ti965_adjust_pgetbl_size(I965_PGETBL_SIZE_2MB);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tpgetbl_ctl = readl(intel_private.registers+I810_PGETBL_CTL);\n\n\tswitch (pgetbl_ctl & I965_PGETBL_SIZE_MASK) {\n\tcase I965_PGETBL_SIZE_128KB:\n\t\tsize = KB(128);\n\t\tbreak;\n\tcase I965_PGETBL_SIZE_256KB:\n\t\tsize = KB(256);\n\t\tbreak;\n\tcase I965_PGETBL_SIZE_512KB:\n\t\tsize = KB(512);\n\t\tbreak;\n\t \n\tcase I965_PGETBL_SIZE_1MB:\n\t\tsize = KB(1024);\n\t\tbreak;\n\tcase I965_PGETBL_SIZE_2MB:\n\t\tsize = KB(2048);\n\t\tbreak;\n\tcase I965_PGETBL_SIZE_1_5MB:\n\t\tsize = KB(1024 + 512);\n\t\tbreak;\n\tdefault:\n\t\tdev_info(&intel_private.pcidev->dev,\n\t\t\t \"unknown page table size, assuming 512KB\\n\");\n\t\tsize = KB(512);\n\t}\n\n\treturn size/4;\n}\n\nstatic unsigned int intel_gtt_total_entries(void)\n{\n\tif (IS_G33 || INTEL_GTT_GEN == 4 || INTEL_GTT_GEN == 5)\n\t\treturn i965_gtt_total_entries();\n\telse {\n\t\t \n\t\treturn intel_private.gtt_mappable_entries;\n\t}\n}\n\nstatic unsigned int intel_gtt_mappable_entries(void)\n{\n\tunsigned int aperture_size;\n\n\tif (INTEL_GTT_GEN == 1) {\n\t\tu32 smram_miscc;\n\n\t\tpci_read_config_dword(intel_private.bridge_dev,\n\t\t\t\t      I810_SMRAM_MISCC, &smram_miscc);\n\n\t\tif ((smram_miscc & I810_GFX_MEM_WIN_SIZE)\n\t\t\t\t== I810_GFX_MEM_WIN_32M)\n\t\t\taperture_size = MB(32);\n\t\telse\n\t\t\taperture_size = MB(64);\n\t} else if (INTEL_GTT_GEN == 2) {\n\t\tu16 gmch_ctrl;\n\n\t\tpci_read_config_word(intel_private.bridge_dev,\n\t\t\t\t     I830_GMCH_CTRL, &gmch_ctrl);\n\n\t\tif ((gmch_ctrl & I830_GMCH_MEM_MASK) == I830_GMCH_MEM_64M)\n\t\t\taperture_size = MB(64);\n\t\telse\n\t\t\taperture_size = MB(128);\n\t} else {\n\t\t \n\t\taperture_size = pci_resource_len(intel_private.pcidev, 2);\n\t}\n\n\treturn aperture_size >> PAGE_SHIFT;\n}\n\nstatic void intel_gtt_teardown_scratch_page(void)\n{\n\tset_pages_wb(intel_private.scratch_page, 1);\n\tif (intel_private.needs_dmar)\n\t\tdma_unmap_page(&intel_private.pcidev->dev,\n\t\t\t       intel_private.scratch_page_dma, PAGE_SIZE,\n\t\t\t       DMA_BIDIRECTIONAL);\n\t__free_page(intel_private.scratch_page);\n}\n\nstatic void intel_gtt_cleanup(void)\n{\n\tintel_private.driver->cleanup();\n\n\tiounmap(intel_private.gtt);\n\tiounmap(intel_private.registers);\n\n\tintel_gtt_teardown_scratch_page();\n}\n\n \nstatic inline int needs_ilk_vtd_wa(void)\n{\n\tconst unsigned short gpu_devid = intel_private.pcidev->device;\n\n\t \n\treturn ((gpu_devid == PCI_DEVICE_ID_INTEL_IRONLAKE_D_IG ||\n\t\t gpu_devid == PCI_DEVICE_ID_INTEL_IRONLAKE_M_IG) &&\n\t\tdevice_iommu_mapped(&intel_private.pcidev->dev));\n}\n\nstatic bool intel_gtt_can_wc(void)\n{\n\tif (INTEL_GTT_GEN <= 2)\n\t\treturn false;\n\n\tif (INTEL_GTT_GEN >= 6)\n\t\treturn false;\n\n\t \n\tif (needs_ilk_vtd_wa())\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int intel_gtt_init(void)\n{\n\tu32 gtt_map_size;\n\tint ret, bar;\n\n\tret = intel_private.driver->setup();\n\tif (ret != 0)\n\t\treturn ret;\n\n\tintel_private.gtt_mappable_entries = intel_gtt_mappable_entries();\n\tintel_private.gtt_total_entries = intel_gtt_total_entries();\n\n\t \n\tintel_private.PGETBL_save =\n\t\treadl(intel_private.registers+I810_PGETBL_CTL)\n\t\t\t& ~I810_PGETBL_ENABLED;\n\t \n\tif (HAS_PGTBL_EN)\n\t\tintel_private.PGETBL_save |= I810_PGETBL_ENABLED;\n\n\tdev_info(&intel_private.bridge_dev->dev,\n\t\t\t\"detected gtt size: %dK total, %dK mappable\\n\",\n\t\t\tintel_private.gtt_total_entries * 4,\n\t\t\tintel_private.gtt_mappable_entries * 4);\n\n\tgtt_map_size = intel_private.gtt_total_entries * 4;\n\n\tintel_private.gtt = NULL;\n\tif (intel_gtt_can_wc())\n\t\tintel_private.gtt = ioremap_wc(intel_private.gtt_phys_addr,\n\t\t\t\t\t       gtt_map_size);\n\tif (intel_private.gtt == NULL)\n\t\tintel_private.gtt = ioremap(intel_private.gtt_phys_addr,\n\t\t\t\t\t    gtt_map_size);\n\tif (intel_private.gtt == NULL) {\n\t\tintel_private.driver->cleanup();\n\t\tiounmap(intel_private.registers);\n\t\treturn -ENOMEM;\n\t}\n\n#if IS_ENABLED(CONFIG_AGP_INTEL)\n\tglobal_cache_flush();    \n#endif\n\n\tintel_private.stolen_size = intel_gtt_stolen_size();\n\n\tintel_private.needs_dmar = USE_PCI_DMA_API && INTEL_GTT_GEN > 2;\n\n\tret = intel_gtt_setup_scratch_page();\n\tif (ret != 0) {\n\t\tintel_gtt_cleanup();\n\t\treturn ret;\n\t}\n\n\tif (INTEL_GTT_GEN <= 2)\n\t\tbar = I810_GMADR_BAR;\n\telse\n\t\tbar = I915_GMADR_BAR;\n\n\tintel_private.gma_bus_addr = pci_bus_address(intel_private.pcidev, bar);\n\treturn 0;\n}\n\n#if IS_ENABLED(CONFIG_AGP_INTEL)\nstatic const struct aper_size_info_fixed intel_fake_agp_sizes[] = {\n\t{32, 8192, 3},\n\t{64, 16384, 4},\n\t{128, 32768, 5},\n\t{256, 65536, 6},\n\t{512, 131072, 7},\n};\n\nstatic int intel_fake_agp_fetch_size(void)\n{\n\tint num_sizes = ARRAY_SIZE(intel_fake_agp_sizes);\n\tunsigned int aper_size;\n\tint i;\n\n\taper_size = (intel_private.gtt_mappable_entries << PAGE_SHIFT) / MB(1);\n\n\tfor (i = 0; i < num_sizes; i++) {\n\t\tif (aper_size == intel_fake_agp_sizes[i].size) {\n\t\t\tagp_bridge->current_size =\n\t\t\t\t(void *) (intel_fake_agp_sizes + i);\n\t\t\treturn aper_size;\n\t\t}\n\t}\n\n\treturn 0;\n}\n#endif\n\nstatic void i830_cleanup(void)\n{\n}\n\n \nstatic void i830_chipset_flush(void)\n{\n\tunsigned long timeout = jiffies + msecs_to_jiffies(1000);\n\n\t \n\twbinvd_on_all_cpus();\n\n\t \n\twritel(readl(intel_private.registers+I830_HIC) | (1<<31),\n\t       intel_private.registers+I830_HIC);\n\n\twhile (readl(intel_private.registers+I830_HIC) & (1<<31)) {\n\t\tif (time_after(jiffies, timeout))\n\t\t\tbreak;\n\n\t\tudelay(50);\n\t}\n}\n\nstatic void i830_write_entry(dma_addr_t addr, unsigned int entry,\n\t\t\t     unsigned int flags)\n{\n\tu32 pte_flags = I810_PTE_VALID;\n\n\tif (flags ==  AGP_USER_CACHED_MEMORY)\n\t\tpte_flags |= I830_PTE_SYSTEM_CACHED;\n\n\twritel_relaxed(addr | pte_flags, intel_private.gtt + entry);\n}\n\nbool intel_gmch_enable_gtt(void)\n{\n\tu8 __iomem *reg;\n\n\tif (INTEL_GTT_GEN == 2) {\n\t\tu16 gmch_ctrl;\n\n\t\tpci_read_config_word(intel_private.bridge_dev,\n\t\t\t\t     I830_GMCH_CTRL, &gmch_ctrl);\n\t\tgmch_ctrl |= I830_GMCH_ENABLED;\n\t\tpci_write_config_word(intel_private.bridge_dev,\n\t\t\t\t      I830_GMCH_CTRL, gmch_ctrl);\n\n\t\tpci_read_config_word(intel_private.bridge_dev,\n\t\t\t\t     I830_GMCH_CTRL, &gmch_ctrl);\n\t\tif ((gmch_ctrl & I830_GMCH_ENABLED) == 0) {\n\t\t\tdev_err(&intel_private.pcidev->dev,\n\t\t\t\t\"failed to enable the GTT: GMCH_CTRL=%x\\n\",\n\t\t\t\tgmch_ctrl);\n\t\t\treturn false;\n\t\t}\n\t}\n\n\t \n\tif (INTEL_GTT_GEN >= 3)\n\t\twritel(0, intel_private.registers+GFX_FLSH_CNTL);\n\n\treg = intel_private.registers+I810_PGETBL_CTL;\n\twritel(intel_private.PGETBL_save, reg);\n\tif (HAS_PGTBL_EN && (readl(reg) & I810_PGETBL_ENABLED) == 0) {\n\t\tdev_err(&intel_private.pcidev->dev,\n\t\t\t\"failed to enable the GTT: PGETBL=%x [expected %x]\\n\",\n\t\t\treadl(reg), intel_private.PGETBL_save);\n\t\treturn false;\n\t}\n\n\tif (INTEL_GTT_GEN >= 3)\n\t\twritel(0, intel_private.registers+GFX_FLSH_CNTL);\n\n\treturn true;\n}\nEXPORT_SYMBOL(intel_gmch_enable_gtt);\n\nstatic int i830_setup(void)\n{\n\tphys_addr_t reg_addr;\n\n\treg_addr = pci_resource_start(intel_private.pcidev, I810_MMADR_BAR);\n\n\tintel_private.registers = ioremap(reg_addr, KB(64));\n\tif (!intel_private.registers)\n\t\treturn -ENOMEM;\n\n\tintel_private.gtt_phys_addr = reg_addr + I810_PTE_BASE;\n\n\treturn 0;\n}\n\n#if IS_ENABLED(CONFIG_AGP_INTEL)\nstatic int intel_fake_agp_create_gatt_table(struct agp_bridge_data *bridge)\n{\n\tagp_bridge->gatt_table_real = NULL;\n\tagp_bridge->gatt_table = NULL;\n\tagp_bridge->gatt_bus_addr = 0;\n\n\treturn 0;\n}\n\nstatic int intel_fake_agp_free_gatt_table(struct agp_bridge_data *bridge)\n{\n\treturn 0;\n}\n\nstatic int intel_fake_agp_configure(void)\n{\n\tif (!intel_gmch_enable_gtt())\n\t\treturn -EIO;\n\n\tintel_private.clear_fake_agp = true;\n\tagp_bridge->gart_bus_addr = intel_private.gma_bus_addr;\n\n\treturn 0;\n}\n#endif\n\nstatic bool i830_check_flags(unsigned int flags)\n{\n\tswitch (flags) {\n\tcase 0:\n\tcase AGP_PHYS_MEMORY:\n\tcase AGP_USER_CACHED_MEMORY:\n\tcase AGP_USER_MEMORY:\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nvoid intel_gmch_gtt_insert_page(dma_addr_t addr,\n\t\t\t\tunsigned int pg,\n\t\t\t\tunsigned int flags)\n{\n\tintel_private.driver->write_entry(addr, pg, flags);\n\treadl(intel_private.gtt + pg);\n\tif (intel_private.driver->chipset_flush)\n\t\tintel_private.driver->chipset_flush();\n}\nEXPORT_SYMBOL(intel_gmch_gtt_insert_page);\n\nvoid intel_gmch_gtt_insert_sg_entries(struct sg_table *st,\n\t\t\t\t      unsigned int pg_start,\n\t\t\t\t      unsigned int flags)\n{\n\tstruct scatterlist *sg;\n\tunsigned int len, m;\n\tint i, j;\n\n\tj = pg_start;\n\n\t \n\tfor_each_sg(st->sgl, sg, st->nents, i) {\n\t\tlen = sg_dma_len(sg) >> PAGE_SHIFT;\n\t\tfor (m = 0; m < len; m++) {\n\t\t\tdma_addr_t addr = sg_dma_address(sg) + (m << PAGE_SHIFT);\n\t\t\tintel_private.driver->write_entry(addr, j, flags);\n\t\t\tj++;\n\t\t}\n\t}\n\treadl(intel_private.gtt + j - 1);\n\tif (intel_private.driver->chipset_flush)\n\t\tintel_private.driver->chipset_flush();\n}\nEXPORT_SYMBOL(intel_gmch_gtt_insert_sg_entries);\n\n#if IS_ENABLED(CONFIG_AGP_INTEL)\nstatic void intel_gmch_gtt_insert_pages(unsigned int first_entry,\n\t\t\t\t\tunsigned int num_entries,\n\t\t\t\t\tstruct page **pages,\n\t\t\t\t\tunsigned int flags)\n{\n\tint i, j;\n\n\tfor (i = 0, j = first_entry; i < num_entries; i++, j++) {\n\t\tdma_addr_t addr = page_to_phys(pages[i]);\n\t\tintel_private.driver->write_entry(addr,\n\t\t\t\t\t\t  j, flags);\n\t}\n\twmb();\n}\n\nstatic int intel_fake_agp_insert_entries(struct agp_memory *mem,\n\t\t\t\t\t off_t pg_start, int type)\n{\n\tint ret = -EINVAL;\n\n\tif (intel_private.clear_fake_agp) {\n\t\tint start = intel_private.stolen_size / PAGE_SIZE;\n\t\tint end = intel_private.gtt_mappable_entries;\n\t\tintel_gmch_gtt_clear_range(start, end - start);\n\t\tintel_private.clear_fake_agp = false;\n\t}\n\n\tif (INTEL_GTT_GEN == 1 && type == AGP_DCACHE_MEMORY)\n\t\treturn i810_insert_dcache_entries(mem, pg_start, type);\n\n\tif (mem->page_count == 0)\n\t\tgoto out;\n\n\tif (pg_start + mem->page_count > intel_private.gtt_total_entries)\n\t\tgoto out_err;\n\n\tif (type != mem->type)\n\t\tgoto out_err;\n\n\tif (!intel_private.driver->check_flags(type))\n\t\tgoto out_err;\n\n\tif (!mem->is_flushed)\n\t\tglobal_cache_flush();\n\n\tif (intel_private.needs_dmar) {\n\t\tstruct sg_table st;\n\n\t\tret = intel_gtt_map_memory(mem->pages, mem->page_count, &st);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\n\t\tintel_gmch_gtt_insert_sg_entries(&st, pg_start, type);\n\t\tmem->sg_list = st.sgl;\n\t\tmem->num_sg = st.nents;\n\t} else\n\t\tintel_gmch_gtt_insert_pages(pg_start, mem->page_count, mem->pages,\n\t\t\t\t\t    type);\n\nout:\n\tret = 0;\nout_err:\n\tmem->is_flushed = true;\n\treturn ret;\n}\n#endif\n\nvoid intel_gmch_gtt_clear_range(unsigned int first_entry, unsigned int num_entries)\n{\n\tunsigned int i;\n\n\tfor (i = first_entry; i < (first_entry + num_entries); i++) {\n\t\tintel_private.driver->write_entry(intel_private.scratch_page_dma,\n\t\t\t\t\t\t  i, 0);\n\t}\n\twmb();\n}\nEXPORT_SYMBOL(intel_gmch_gtt_clear_range);\n\n#if IS_ENABLED(CONFIG_AGP_INTEL)\nstatic int intel_fake_agp_remove_entries(struct agp_memory *mem,\n\t\t\t\t\t off_t pg_start, int type)\n{\n\tif (mem->page_count == 0)\n\t\treturn 0;\n\n\tintel_gmch_gtt_clear_range(pg_start, mem->page_count);\n\n\tif (intel_private.needs_dmar) {\n\t\tintel_gtt_unmap_memory(mem->sg_list, mem->num_sg);\n\t\tmem->sg_list = NULL;\n\t\tmem->num_sg = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic struct agp_memory *intel_fake_agp_alloc_by_type(size_t pg_count,\n\t\t\t\t\t\t       int type)\n{\n\tstruct agp_memory *new;\n\n\tif (type == AGP_DCACHE_MEMORY && INTEL_GTT_GEN == 1) {\n\t\tif (pg_count != intel_private.num_dcache_entries)\n\t\t\treturn NULL;\n\n\t\tnew = agp_create_memory(1);\n\t\tif (new == NULL)\n\t\t\treturn NULL;\n\n\t\tnew->type = AGP_DCACHE_MEMORY;\n\t\tnew->page_count = pg_count;\n\t\tnew->num_scratch_pages = 0;\n\t\tagp_free_page_array(new);\n\t\treturn new;\n\t}\n\tif (type == AGP_PHYS_MEMORY)\n\t\treturn alloc_agpphysmem_i8xx(pg_count, type);\n\t \n\treturn NULL;\n}\n#endif\n\nstatic int intel_alloc_chipset_flush_resource(void)\n{\n\tint ret;\n\tret = pci_bus_alloc_resource(intel_private.bridge_dev->bus, &intel_private.ifp_resource, PAGE_SIZE,\n\t\t\t\t     PAGE_SIZE, PCIBIOS_MIN_MEM, 0,\n\t\t\t\t     pcibios_align_resource, intel_private.bridge_dev);\n\n\treturn ret;\n}\n\nstatic void intel_i915_setup_chipset_flush(void)\n{\n\tint ret;\n\tu32 temp;\n\n\tpci_read_config_dword(intel_private.bridge_dev, I915_IFPADDR, &temp);\n\tif (!(temp & 0x1)) {\n\t\tintel_alloc_chipset_flush_resource();\n\t\tintel_private.resource_valid = 1;\n\t\tpci_write_config_dword(intel_private.bridge_dev, I915_IFPADDR, (intel_private.ifp_resource.start & 0xffffffff) | 0x1);\n\t} else {\n\t\ttemp &= ~1;\n\n\t\tintel_private.resource_valid = 1;\n\t\tintel_private.ifp_resource.start = temp;\n\t\tintel_private.ifp_resource.end = temp + PAGE_SIZE;\n\t\tret = request_resource(&iomem_resource, &intel_private.ifp_resource);\n\t\t \n\t\tif (ret)\n\t\t\tintel_private.resource_valid = 0;\n\t}\n}\n\nstatic void intel_i965_g33_setup_chipset_flush(void)\n{\n\tu32 temp_hi, temp_lo;\n\tint ret;\n\n\tpci_read_config_dword(intel_private.bridge_dev, I965_IFPADDR + 4, &temp_hi);\n\tpci_read_config_dword(intel_private.bridge_dev, I965_IFPADDR, &temp_lo);\n\n\tif (!(temp_lo & 0x1)) {\n\n\t\tintel_alloc_chipset_flush_resource();\n\n\t\tintel_private.resource_valid = 1;\n\t\tpci_write_config_dword(intel_private.bridge_dev, I965_IFPADDR + 4,\n\t\t\tupper_32_bits(intel_private.ifp_resource.start));\n\t\tpci_write_config_dword(intel_private.bridge_dev, I965_IFPADDR, (intel_private.ifp_resource.start & 0xffffffff) | 0x1);\n\t} else {\n\t\tu64 l64;\n\n\t\ttemp_lo &= ~0x1;\n\t\tl64 = ((u64)temp_hi << 32) | temp_lo;\n\n\t\tintel_private.resource_valid = 1;\n\t\tintel_private.ifp_resource.start = l64;\n\t\tintel_private.ifp_resource.end = l64 + PAGE_SIZE;\n\t\tret = request_resource(&iomem_resource, &intel_private.ifp_resource);\n\t\t \n\t\tif (ret)\n\t\t\tintel_private.resource_valid = 0;\n\t}\n}\n\nstatic void intel_i9xx_setup_flush(void)\n{\n\t \n\tif (intel_private.ifp_resource.start)\n\t\treturn;\n\n\tif (INTEL_GTT_GEN == 6)\n\t\treturn;\n\n\t \n\tintel_private.ifp_resource.name = \"Intel Flush Page\";\n\tintel_private.ifp_resource.flags = IORESOURCE_MEM;\n\n\t \n\tif (IS_G33 || INTEL_GTT_GEN >= 4) {\n\t\tintel_i965_g33_setup_chipset_flush();\n\t} else {\n\t\tintel_i915_setup_chipset_flush();\n\t}\n\n\tif (intel_private.ifp_resource.start)\n\t\tintel_private.i9xx_flush_page = ioremap(intel_private.ifp_resource.start, PAGE_SIZE);\n\tif (!intel_private.i9xx_flush_page)\n\t\tdev_err(&intel_private.pcidev->dev,\n\t\t\t\"can't ioremap flush page - no chipset flushing\\n\");\n}\n\nstatic void i9xx_cleanup(void)\n{\n\tif (intel_private.i9xx_flush_page)\n\t\tiounmap(intel_private.i9xx_flush_page);\n\tif (intel_private.resource_valid)\n\t\trelease_resource(&intel_private.ifp_resource);\n\tintel_private.ifp_resource.start = 0;\n\tintel_private.resource_valid = 0;\n}\n\nstatic void i9xx_chipset_flush(void)\n{\n\twmb();\n\tif (intel_private.i9xx_flush_page)\n\t\twritel(1, intel_private.i9xx_flush_page);\n}\n\nstatic void i965_write_entry(dma_addr_t addr,\n\t\t\t     unsigned int entry,\n\t\t\t     unsigned int flags)\n{\n\tu32 pte_flags;\n\n\tpte_flags = I810_PTE_VALID;\n\tif (flags == AGP_USER_CACHED_MEMORY)\n\t\tpte_flags |= I830_PTE_SYSTEM_CACHED;\n\n\t \n\taddr |= (addr >> 28) & 0xf0;\n\twritel_relaxed(addr | pte_flags, intel_private.gtt + entry);\n}\n\nstatic int i9xx_setup(void)\n{\n\tphys_addr_t reg_addr;\n\tint size = KB(512);\n\n\treg_addr = pci_resource_start(intel_private.pcidev, I915_MMADR_BAR);\n\n\tintel_private.registers = ioremap(reg_addr, size);\n\tif (!intel_private.registers)\n\t\treturn -ENOMEM;\n\n\tswitch (INTEL_GTT_GEN) {\n\tcase 3:\n\t\tintel_private.gtt_phys_addr =\n\t\t\tpci_resource_start(intel_private.pcidev, I915_PTE_BAR);\n\t\tbreak;\n\tcase 5:\n\t\tintel_private.gtt_phys_addr = reg_addr + MB(2);\n\t\tbreak;\n\tdefault:\n\t\tintel_private.gtt_phys_addr = reg_addr + KB(512);\n\t\tbreak;\n\t}\n\n\tintel_i9xx_setup_flush();\n\n\treturn 0;\n}\n\n#if IS_ENABLED(CONFIG_AGP_INTEL)\nstatic const struct agp_bridge_driver intel_fake_agp_driver = {\n\t.owner\t\t\t= THIS_MODULE,\n\t.size_type\t\t= FIXED_APER_SIZE,\n\t.aperture_sizes\t\t= intel_fake_agp_sizes,\n\t.num_aperture_sizes\t= ARRAY_SIZE(intel_fake_agp_sizes),\n\t.configure\t\t= intel_fake_agp_configure,\n\t.fetch_size\t\t= intel_fake_agp_fetch_size,\n\t.cleanup\t\t= intel_gtt_cleanup,\n\t.agp_enable\t\t= intel_fake_agp_enable,\n\t.cache_flush\t\t= global_cache_flush,\n\t.create_gatt_table\t= intel_fake_agp_create_gatt_table,\n\t.free_gatt_table\t= intel_fake_agp_free_gatt_table,\n\t.insert_memory\t\t= intel_fake_agp_insert_entries,\n\t.remove_memory\t\t= intel_fake_agp_remove_entries,\n\t.alloc_by_type\t\t= intel_fake_agp_alloc_by_type,\n\t.free_by_type\t\t= intel_i810_free_by_type,\n\t.agp_alloc_page\t\t= agp_generic_alloc_page,\n\t.agp_alloc_pages        = agp_generic_alloc_pages,\n\t.agp_destroy_page\t= agp_generic_destroy_page,\n\t.agp_destroy_pages      = agp_generic_destroy_pages,\n};\n#endif\n\nstatic const struct intel_gtt_driver i81x_gtt_driver = {\n\t.gen = 1,\n\t.has_pgtbl_enable = 1,\n\t.dma_mask_size = 32,\n\t.setup = i810_setup,\n\t.cleanup = i810_cleanup,\n\t.check_flags = i830_check_flags,\n\t.write_entry = i810_write_entry,\n};\nstatic const struct intel_gtt_driver i8xx_gtt_driver = {\n\t.gen = 2,\n\t.has_pgtbl_enable = 1,\n\t.setup = i830_setup,\n\t.cleanup = i830_cleanup,\n\t.write_entry = i830_write_entry,\n\t.dma_mask_size = 32,\n\t.check_flags = i830_check_flags,\n\t.chipset_flush = i830_chipset_flush,\n};\nstatic const struct intel_gtt_driver i915_gtt_driver = {\n\t.gen = 3,\n\t.has_pgtbl_enable = 1,\n\t.setup = i9xx_setup,\n\t.cleanup = i9xx_cleanup,\n\t \n\t.write_entry = i830_write_entry,\n\t.dma_mask_size = 32,\n\t.check_flags = i830_check_flags,\n\t.chipset_flush = i9xx_chipset_flush,\n};\nstatic const struct intel_gtt_driver g33_gtt_driver = {\n\t.gen = 3,\n\t.is_g33 = 1,\n\t.setup = i9xx_setup,\n\t.cleanup = i9xx_cleanup,\n\t.write_entry = i965_write_entry,\n\t.dma_mask_size = 36,\n\t.check_flags = i830_check_flags,\n\t.chipset_flush = i9xx_chipset_flush,\n};\nstatic const struct intel_gtt_driver pineview_gtt_driver = {\n\t.gen = 3,\n\t.is_pineview = 1, .is_g33 = 1,\n\t.setup = i9xx_setup,\n\t.cleanup = i9xx_cleanup,\n\t.write_entry = i965_write_entry,\n\t.dma_mask_size = 36,\n\t.check_flags = i830_check_flags,\n\t.chipset_flush = i9xx_chipset_flush,\n};\nstatic const struct intel_gtt_driver i965_gtt_driver = {\n\t.gen = 4,\n\t.has_pgtbl_enable = 1,\n\t.setup = i9xx_setup,\n\t.cleanup = i9xx_cleanup,\n\t.write_entry = i965_write_entry,\n\t.dma_mask_size = 36,\n\t.check_flags = i830_check_flags,\n\t.chipset_flush = i9xx_chipset_flush,\n};\nstatic const struct intel_gtt_driver g4x_gtt_driver = {\n\t.gen = 5,\n\t.setup = i9xx_setup,\n\t.cleanup = i9xx_cleanup,\n\t.write_entry = i965_write_entry,\n\t.dma_mask_size = 36,\n\t.check_flags = i830_check_flags,\n\t.chipset_flush = i9xx_chipset_flush,\n};\nstatic const struct intel_gtt_driver ironlake_gtt_driver = {\n\t.gen = 5,\n\t.is_ironlake = 1,\n\t.setup = i9xx_setup,\n\t.cleanup = i9xx_cleanup,\n\t.write_entry = i965_write_entry,\n\t.dma_mask_size = 36,\n\t.check_flags = i830_check_flags,\n\t.chipset_flush = i9xx_chipset_flush,\n};\n\n \nstatic const struct intel_gtt_driver_description {\n\tunsigned int gmch_chip_id;\n\tchar *name;\n\tconst struct intel_gtt_driver *gtt_driver;\n} intel_gtt_chipsets[] = {\n\t{ PCI_DEVICE_ID_INTEL_82810_IG1, \"i810\",\n\t\t&i81x_gtt_driver},\n\t{ PCI_DEVICE_ID_INTEL_82810_IG3, \"i810\",\n\t\t&i81x_gtt_driver},\n\t{ PCI_DEVICE_ID_INTEL_82810E_IG, \"i810\",\n\t\t&i81x_gtt_driver},\n\t{ PCI_DEVICE_ID_INTEL_82815_CGC, \"i815\",\n\t\t&i81x_gtt_driver},\n\t{ PCI_DEVICE_ID_INTEL_82830_CGC, \"830M\",\n\t\t&i8xx_gtt_driver},\n\t{ PCI_DEVICE_ID_INTEL_82845G_IG, \"845G\",\n\t\t&i8xx_gtt_driver},\n\t{ PCI_DEVICE_ID_INTEL_82854_IG, \"854\",\n\t\t&i8xx_gtt_driver},\n\t{ PCI_DEVICE_ID_INTEL_82855GM_IG, \"855GM\",\n\t\t&i8xx_gtt_driver},\n\t{ PCI_DEVICE_ID_INTEL_82865_IG, \"865\",\n\t\t&i8xx_gtt_driver},\n\t{ PCI_DEVICE_ID_INTEL_E7221_IG, \"E7221 (i915)\",\n\t\t&i915_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82915G_IG, \"915G\",\n\t\t&i915_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82915GM_IG, \"915GM\",\n\t\t&i915_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82945G_IG, \"945G\",\n\t\t&i915_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82945GM_IG, \"945GM\",\n\t\t&i915_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82945GME_IG, \"945GME\",\n\t\t&i915_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82946GZ_IG, \"946GZ\",\n\t\t&i965_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82G35_IG, \"G35\",\n\t\t&i965_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82965Q_IG, \"965Q\",\n\t\t&i965_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82965G_IG, \"965G\",\n\t\t&i965_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82965GM_IG, \"965GM\",\n\t\t&i965_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_82965GME_IG, \"965GME/GLE\",\n\t\t&i965_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_G33_IG, \"G33\",\n\t\t&g33_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_Q35_IG, \"Q35\",\n\t\t&g33_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_Q33_IG, \"Q33\",\n\t\t&g33_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_PINEVIEW_M_IG, \"GMA3150\",\n\t\t&pineview_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_PINEVIEW_IG, \"GMA3150\",\n\t\t&pineview_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_GM45_IG, \"GM45\",\n\t\t&g4x_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_EAGLELAKE_IG, \"Eaglelake\",\n\t\t&g4x_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_Q45_IG, \"Q45/Q43\",\n\t\t&g4x_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_G45_IG, \"G45/G43\",\n\t\t&g4x_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_B43_IG, \"B43\",\n\t\t&g4x_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_B43_1_IG, \"B43\",\n\t\t&g4x_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_G41_IG, \"G41\",\n\t\t&g4x_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_IRONLAKE_D_IG,\n\t    \"HD Graphics\", &ironlake_gtt_driver },\n\t{ PCI_DEVICE_ID_INTEL_IRONLAKE_M_IG,\n\t    \"HD Graphics\", &ironlake_gtt_driver },\n\t{ 0, NULL, NULL }\n};\n\nstatic int find_gmch(u16 device)\n{\n\tstruct pci_dev *gmch_device;\n\n\tgmch_device = pci_get_device(PCI_VENDOR_ID_INTEL, device, NULL);\n\tif (gmch_device && PCI_FUNC(gmch_device->devfn) != 0) {\n\t\tgmch_device = pci_get_device(PCI_VENDOR_ID_INTEL,\n\t\t\t\t\t     device, gmch_device);\n\t}\n\n\tif (!gmch_device)\n\t\treturn 0;\n\n\tintel_private.pcidev = gmch_device;\n\treturn 1;\n}\n\nint intel_gmch_probe(struct pci_dev *bridge_pdev, struct pci_dev *gpu_pdev,\n\t\t     struct agp_bridge_data *bridge)\n{\n\tint i, mask;\n\n\tfor (i = 0; intel_gtt_chipsets[i].name != NULL; i++) {\n\t\tif (gpu_pdev) {\n\t\t\tif (gpu_pdev->device ==\n\t\t\t    intel_gtt_chipsets[i].gmch_chip_id) {\n\t\t\t\tintel_private.pcidev = pci_dev_get(gpu_pdev);\n\t\t\t\tintel_private.driver =\n\t\t\t\t\tintel_gtt_chipsets[i].gtt_driver;\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (find_gmch(intel_gtt_chipsets[i].gmch_chip_id)) {\n\t\t\tintel_private.driver =\n\t\t\t\tintel_gtt_chipsets[i].gtt_driver;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!intel_private.driver)\n\t\treturn 0;\n\n#if IS_ENABLED(CONFIG_AGP_INTEL)\n\tif (bridge) {\n\t\tif (INTEL_GTT_GEN > 1)\n\t\t\treturn 0;\n\n\t\tbridge->driver = &intel_fake_agp_driver;\n\t\tbridge->dev_private_data = &intel_private;\n\t\tbridge->dev = bridge_pdev;\n\t}\n#endif\n\n\n\t \n\tif (intel_private.refcount++)\n\t\treturn 1;\n\n\tintel_private.bridge_dev = pci_dev_get(bridge_pdev);\n\n\tdev_info(&bridge_pdev->dev, \"Intel %s Chipset\\n\", intel_gtt_chipsets[i].name);\n\n\tif (bridge) {\n\t\tmask = intel_private.driver->dma_mask_size;\n\t\tif (dma_set_mask(&intel_private.pcidev->dev, DMA_BIT_MASK(mask)))\n\t\t\tdev_err(&intel_private.pcidev->dev,\n\t\t\t\t\"set gfx device dma mask %d-bit failed!\\n\",\n\t\t\t\tmask);\n\t\telse\n\t\t\tdma_set_coherent_mask(&intel_private.pcidev->dev,\n\t\t\t\t\t      DMA_BIT_MASK(mask));\n\t}\n\n\tif (intel_gtt_init() != 0) {\n\t\tintel_gmch_remove();\n\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\nEXPORT_SYMBOL(intel_gmch_probe);\n\nvoid intel_gmch_gtt_get(u64 *gtt_total,\n\t\t\tphys_addr_t *mappable_base,\n\t\t\tresource_size_t *mappable_end)\n{\n\t*gtt_total = intel_private.gtt_total_entries << PAGE_SHIFT;\n\t*mappable_base = intel_private.gma_bus_addr;\n\t*mappable_end = intel_private.gtt_mappable_entries << PAGE_SHIFT;\n}\nEXPORT_SYMBOL(intel_gmch_gtt_get);\n\nvoid intel_gmch_gtt_flush(void)\n{\n\tif (intel_private.driver->chipset_flush)\n\t\tintel_private.driver->chipset_flush();\n}\nEXPORT_SYMBOL(intel_gmch_gtt_flush);\n\nvoid intel_gmch_remove(void)\n{\n\tif (--intel_private.refcount)\n\t\treturn;\n\n\tif (intel_private.scratch_page)\n\t\tintel_gtt_teardown_scratch_page();\n\tif (intel_private.pcidev)\n\t\tpci_dev_put(intel_private.pcidev);\n\tif (intel_private.bridge_dev)\n\t\tpci_dev_put(intel_private.bridge_dev);\n\tintel_private.driver = NULL;\n}\nEXPORT_SYMBOL(intel_gmch_remove);\n\nMODULE_AUTHOR(\"Dave Jones, Various @Intel\");\nMODULE_LICENSE(\"GPL and additional rights\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}