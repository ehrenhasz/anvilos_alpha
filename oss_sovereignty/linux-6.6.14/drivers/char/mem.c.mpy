{
  "module_name": "mem.c",
  "hash_id": "356fc6d50a4ae9892bbb23ae643d665faafc929e2fd2ed81edd2ec89c253e054",
  "original_prompt": "Ingested from linux-6.6.14/drivers/char/mem.c",
  "human_readable_source": "\n \n\n#include <linux/mm.h>\n#include <linux/miscdevice.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/mman.h>\n#include <linux/random.h>\n#include <linux/init.h>\n#include <linux/tty.h>\n#include <linux/capability.h>\n#include <linux/ptrace.h>\n#include <linux/device.h>\n#include <linux/highmem.h>\n#include <linux/backing-dev.h>\n#include <linux/shmem_fs.h>\n#include <linux/splice.h>\n#include <linux/pfn.h>\n#include <linux/export.h>\n#include <linux/io.h>\n#include <linux/uio.h>\n#include <linux/uaccess.h>\n#include <linux/security.h>\n\n#ifdef CONFIG_IA64\n# include <linux/efi.h>\n#endif\n\n#define DEVMEM_MINOR\t1\n#define DEVPORT_MINOR\t4\n\nstatic inline unsigned long size_inside_page(unsigned long start,\n\t\t\t\t\t     unsigned long size)\n{\n\tunsigned long sz;\n\n\tsz = PAGE_SIZE - (start & (PAGE_SIZE - 1));\n\n\treturn min(sz, size);\n}\n\n#ifndef ARCH_HAS_VALID_PHYS_ADDR_RANGE\nstatic inline int valid_phys_addr_range(phys_addr_t addr, size_t count)\n{\n\treturn addr + count <= __pa(high_memory);\n}\n\nstatic inline int valid_mmap_phys_addr_range(unsigned long pfn, size_t size)\n{\n\treturn 1;\n}\n#endif\n\n#ifdef CONFIG_STRICT_DEVMEM\nstatic inline int page_is_allowed(unsigned long pfn)\n{\n\treturn devmem_is_allowed(pfn);\n}\nstatic inline int range_is_allowed(unsigned long pfn, unsigned long size)\n{\n\tu64 from = ((u64)pfn) << PAGE_SHIFT;\n\tu64 to = from + size;\n\tu64 cursor = from;\n\n\twhile (cursor < to) {\n\t\tif (!devmem_is_allowed(pfn))\n\t\t\treturn 0;\n\t\tcursor += PAGE_SIZE;\n\t\tpfn++;\n\t}\n\treturn 1;\n}\n#else\nstatic inline int page_is_allowed(unsigned long pfn)\n{\n\treturn 1;\n}\nstatic inline int range_is_allowed(unsigned long pfn, unsigned long size)\n{\n\treturn 1;\n}\n#endif\n\nstatic inline bool should_stop_iteration(void)\n{\n\tif (need_resched())\n\t\tcond_resched();\n\treturn signal_pending(current);\n}\n\n \nstatic ssize_t read_mem(struct file *file, char __user *buf,\n\t\t\tsize_t count, loff_t *ppos)\n{\n\tphys_addr_t p = *ppos;\n\tssize_t read, sz;\n\tvoid *ptr;\n\tchar *bounce;\n\tint err;\n\n\tif (p != *ppos)\n\t\treturn 0;\n\n\tif (!valid_phys_addr_range(p, count))\n\t\treturn -EFAULT;\n\tread = 0;\n#ifdef __ARCH_HAS_NO_PAGE_ZERO_MAPPED\n\t \n\tif (p < PAGE_SIZE) {\n\t\tsz = size_inside_page(p, count);\n\t\tif (sz > 0) {\n\t\t\tif (clear_user(buf, sz))\n\t\t\t\treturn -EFAULT;\n\t\t\tbuf += sz;\n\t\t\tp += sz;\n\t\t\tcount -= sz;\n\t\t\tread += sz;\n\t\t}\n\t}\n#endif\n\n\tbounce = kmalloc(PAGE_SIZE, GFP_KERNEL);\n\tif (!bounce)\n\t\treturn -ENOMEM;\n\n\twhile (count > 0) {\n\t\tunsigned long remaining;\n\t\tint allowed, probe;\n\n\t\tsz = size_inside_page(p, count);\n\n\t\terr = -EPERM;\n\t\tallowed = page_is_allowed(p >> PAGE_SHIFT);\n\t\tif (!allowed)\n\t\t\tgoto failed;\n\n\t\terr = -EFAULT;\n\t\tif (allowed == 2) {\n\t\t\t \n\t\t\tremaining = clear_user(buf, sz);\n\t\t} else {\n\t\t\t \n\t\t\tptr = xlate_dev_mem_ptr(p);\n\t\t\tif (!ptr)\n\t\t\t\tgoto failed;\n\n\t\t\tprobe = copy_from_kernel_nofault(bounce, ptr, sz);\n\t\t\tunxlate_dev_mem_ptr(p, ptr);\n\t\t\tif (probe)\n\t\t\t\tgoto failed;\n\n\t\t\tremaining = copy_to_user(buf, bounce, sz);\n\t\t}\n\n\t\tif (remaining)\n\t\t\tgoto failed;\n\n\t\tbuf += sz;\n\t\tp += sz;\n\t\tcount -= sz;\n\t\tread += sz;\n\t\tif (should_stop_iteration())\n\t\t\tbreak;\n\t}\n\tkfree(bounce);\n\n\t*ppos += read;\n\treturn read;\n\nfailed:\n\tkfree(bounce);\n\treturn err;\n}\n\nstatic ssize_t write_mem(struct file *file, const char __user *buf,\n\t\t\t size_t count, loff_t *ppos)\n{\n\tphys_addr_t p = *ppos;\n\tssize_t written, sz;\n\tunsigned long copied;\n\tvoid *ptr;\n\n\tif (p != *ppos)\n\t\treturn -EFBIG;\n\n\tif (!valid_phys_addr_range(p, count))\n\t\treturn -EFAULT;\n\n\twritten = 0;\n\n#ifdef __ARCH_HAS_NO_PAGE_ZERO_MAPPED\n\t \n\tif (p < PAGE_SIZE) {\n\t\tsz = size_inside_page(p, count);\n\t\t \n\t\tbuf += sz;\n\t\tp += sz;\n\t\tcount -= sz;\n\t\twritten += sz;\n\t}\n#endif\n\n\twhile (count > 0) {\n\t\tint allowed;\n\n\t\tsz = size_inside_page(p, count);\n\n\t\tallowed = page_is_allowed(p >> PAGE_SHIFT);\n\t\tif (!allowed)\n\t\t\treturn -EPERM;\n\n\t\t \n\t\tif (allowed == 1) {\n\t\t\t \n\t\t\tptr = xlate_dev_mem_ptr(p);\n\t\t\tif (!ptr) {\n\t\t\t\tif (written)\n\t\t\t\t\tbreak;\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\n\t\t\tcopied = copy_from_user(ptr, buf, sz);\n\t\t\tunxlate_dev_mem_ptr(p, ptr);\n\t\t\tif (copied) {\n\t\t\t\twritten += sz - copied;\n\t\t\t\tif (written)\n\t\t\t\t\tbreak;\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t}\n\n\t\tbuf += sz;\n\t\tp += sz;\n\t\tcount -= sz;\n\t\twritten += sz;\n\t\tif (should_stop_iteration())\n\t\t\tbreak;\n\t}\n\n\t*ppos += written;\n\treturn written;\n}\n\nint __weak phys_mem_access_prot_allowed(struct file *file,\n\tunsigned long pfn, unsigned long size, pgprot_t *vma_prot)\n{\n\treturn 1;\n}\n\n#ifndef __HAVE_PHYS_MEM_ACCESS_PROT\n\n \n#ifdef pgprot_noncached\nstatic int uncached_access(struct file *file, phys_addr_t addr)\n{\n#if defined(CONFIG_IA64)\n\t \n\treturn !(efi_mem_attributes(addr) & EFI_MEMORY_WB);\n#else\n\t \n\tif (file->f_flags & O_DSYNC)\n\t\treturn 1;\n\treturn addr >= __pa(high_memory);\n#endif\n}\n#endif\n\nstatic pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,\n\t\t\t\t     unsigned long size, pgprot_t vma_prot)\n{\n#ifdef pgprot_noncached\n\tphys_addr_t offset = pfn << PAGE_SHIFT;\n\n\tif (uncached_access(file, offset))\n\t\treturn pgprot_noncached(vma_prot);\n#endif\n\treturn vma_prot;\n}\n#endif\n\n#ifndef CONFIG_MMU\nstatic unsigned long get_unmapped_area_mem(struct file *file,\n\t\t\t\t\t   unsigned long addr,\n\t\t\t\t\t   unsigned long len,\n\t\t\t\t\t   unsigned long pgoff,\n\t\t\t\t\t   unsigned long flags)\n{\n\tif (!valid_mmap_phys_addr_range(pgoff, len))\n\t\treturn (unsigned long) -EINVAL;\n\treturn pgoff << PAGE_SHIFT;\n}\n\n \nstatic unsigned memory_mmap_capabilities(struct file *file)\n{\n\treturn NOMMU_MAP_DIRECT |\n\t\tNOMMU_MAP_READ | NOMMU_MAP_WRITE | NOMMU_MAP_EXEC;\n}\n\nstatic unsigned zero_mmap_capabilities(struct file *file)\n{\n\treturn NOMMU_MAP_COPY;\n}\n\n \nstatic inline int private_mapping_ok(struct vm_area_struct *vma)\n{\n\treturn is_nommu_shared_mapping(vma->vm_flags);\n}\n#else\n\nstatic inline int private_mapping_ok(struct vm_area_struct *vma)\n{\n\treturn 1;\n}\n#endif\n\nstatic const struct vm_operations_struct mmap_mem_ops = {\n#ifdef CONFIG_HAVE_IOREMAP_PROT\n\t.access = generic_access_phys\n#endif\n};\n\nstatic int mmap_mem(struct file *file, struct vm_area_struct *vma)\n{\n\tsize_t size = vma->vm_end - vma->vm_start;\n\tphys_addr_t offset = (phys_addr_t)vma->vm_pgoff << PAGE_SHIFT;\n\n\t \n\tif (offset >> PAGE_SHIFT != vma->vm_pgoff)\n\t\treturn -EINVAL;\n\n\t \n\tif (offset + (phys_addr_t)size - 1 < offset)\n\t\treturn -EINVAL;\n\n\tif (!valid_mmap_phys_addr_range(vma->vm_pgoff, size))\n\t\treturn -EINVAL;\n\n\tif (!private_mapping_ok(vma))\n\t\treturn -ENOSYS;\n\n\tif (!range_is_allowed(vma->vm_pgoff, size))\n\t\treturn -EPERM;\n\n\tif (!phys_mem_access_prot_allowed(file, vma->vm_pgoff, size,\n\t\t\t\t\t\t&vma->vm_page_prot))\n\t\treturn -EINVAL;\n\n\tvma->vm_page_prot = phys_mem_access_prot(file, vma->vm_pgoff,\n\t\t\t\t\t\t size,\n\t\t\t\t\t\t vma->vm_page_prot);\n\n\tvma->vm_ops = &mmap_mem_ops;\n\n\t \n\tif (remap_pfn_range(vma,\n\t\t\t    vma->vm_start,\n\t\t\t    vma->vm_pgoff,\n\t\t\t    size,\n\t\t\t    vma->vm_page_prot)) {\n\t\treturn -EAGAIN;\n\t}\n\treturn 0;\n}\n\nstatic ssize_t read_port(struct file *file, char __user *buf,\n\t\t\t size_t count, loff_t *ppos)\n{\n\tunsigned long i = *ppos;\n\tchar __user *tmp = buf;\n\n\tif (!access_ok(buf, count))\n\t\treturn -EFAULT;\n\twhile (count-- > 0 && i < 65536) {\n\t\tif (__put_user(inb(i), tmp) < 0)\n\t\t\treturn -EFAULT;\n\t\ti++;\n\t\ttmp++;\n\t}\n\t*ppos = i;\n\treturn tmp-buf;\n}\n\nstatic ssize_t write_port(struct file *file, const char __user *buf,\n\t\t\t  size_t count, loff_t *ppos)\n{\n\tunsigned long i = *ppos;\n\tconst char __user *tmp = buf;\n\n\tif (!access_ok(buf, count))\n\t\treturn -EFAULT;\n\twhile (count-- > 0 && i < 65536) {\n\t\tchar c;\n\n\t\tif (__get_user(c, tmp)) {\n\t\t\tif (tmp > buf)\n\t\t\t\tbreak;\n\t\t\treturn -EFAULT;\n\t\t}\n\t\toutb(c, i);\n\t\ti++;\n\t\ttmp++;\n\t}\n\t*ppos = i;\n\treturn tmp-buf;\n}\n\nstatic ssize_t read_null(struct file *file, char __user *buf,\n\t\t\t size_t count, loff_t *ppos)\n{\n\treturn 0;\n}\n\nstatic ssize_t write_null(struct file *file, const char __user *buf,\n\t\t\t  size_t count, loff_t *ppos)\n{\n\treturn count;\n}\n\nstatic ssize_t read_iter_null(struct kiocb *iocb, struct iov_iter *to)\n{\n\treturn 0;\n}\n\nstatic ssize_t write_iter_null(struct kiocb *iocb, struct iov_iter *from)\n{\n\tsize_t count = iov_iter_count(from);\n\tiov_iter_advance(from, count);\n\treturn count;\n}\n\nstatic int pipe_to_null(struct pipe_inode_info *info, struct pipe_buffer *buf,\n\t\t\tstruct splice_desc *sd)\n{\n\treturn sd->len;\n}\n\nstatic ssize_t splice_write_null(struct pipe_inode_info *pipe, struct file *out,\n\t\t\t\t loff_t *ppos, size_t len, unsigned int flags)\n{\n\treturn splice_from_pipe(pipe, out, ppos, len, flags, pipe_to_null);\n}\n\nstatic int uring_cmd_null(struct io_uring_cmd *ioucmd, unsigned int issue_flags)\n{\n\treturn 0;\n}\n\nstatic ssize_t read_iter_zero(struct kiocb *iocb, struct iov_iter *iter)\n{\n\tsize_t written = 0;\n\n\twhile (iov_iter_count(iter)) {\n\t\tsize_t chunk = iov_iter_count(iter), n;\n\n\t\tif (chunk > PAGE_SIZE)\n\t\t\tchunk = PAGE_SIZE;\t \n\t\tn = iov_iter_zero(chunk, iter);\n\t\tif (!n && iov_iter_count(iter))\n\t\t\treturn written ? written : -EFAULT;\n\t\twritten += n;\n\t\tif (signal_pending(current))\n\t\t\treturn written ? written : -ERESTARTSYS;\n\t\tif (!need_resched())\n\t\t\tcontinue;\n\t\tif (iocb->ki_flags & IOCB_NOWAIT)\n\t\t\treturn written ? written : -EAGAIN;\n\t\tcond_resched();\n\t}\n\treturn written;\n}\n\nstatic ssize_t read_zero(struct file *file, char __user *buf,\n\t\t\t size_t count, loff_t *ppos)\n{\n\tsize_t cleared = 0;\n\n\twhile (count) {\n\t\tsize_t chunk = min_t(size_t, count, PAGE_SIZE);\n\t\tsize_t left;\n\n\t\tleft = clear_user(buf + cleared, chunk);\n\t\tif (unlikely(left)) {\n\t\t\tcleared += (chunk - left);\n\t\t\tif (!cleared)\n\t\t\t\treturn -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tcleared += chunk;\n\t\tcount -= chunk;\n\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\t\tcond_resched();\n\t}\n\n\treturn cleared;\n}\n\nstatic int mmap_zero(struct file *file, struct vm_area_struct *vma)\n{\n#ifndef CONFIG_MMU\n\treturn -ENOSYS;\n#endif\n\tif (vma->vm_flags & VM_SHARED)\n\t\treturn shmem_zero_setup(vma);\n\tvma_set_anonymous(vma);\n\treturn 0;\n}\n\nstatic unsigned long get_unmapped_area_zero(struct file *file,\n\t\t\t\tunsigned long addr, unsigned long len,\n\t\t\t\tunsigned long pgoff, unsigned long flags)\n{\n#ifdef CONFIG_MMU\n\tif (flags & MAP_SHARED) {\n\t\t \n\t\treturn shmem_get_unmapped_area(NULL, addr, len, pgoff, flags);\n\t}\n\n\t \n\treturn current->mm->get_unmapped_area(file, addr, len, pgoff, flags);\n#else\n\treturn -ENOSYS;\n#endif\n}\n\nstatic ssize_t write_full(struct file *file, const char __user *buf,\n\t\t\t  size_t count, loff_t *ppos)\n{\n\treturn -ENOSPC;\n}\n\n \nstatic loff_t null_lseek(struct file *file, loff_t offset, int orig)\n{\n\treturn file->f_pos = 0;\n}\n\n \nstatic loff_t memory_lseek(struct file *file, loff_t offset, int orig)\n{\n\tloff_t ret;\n\n\tinode_lock(file_inode(file));\n\tswitch (orig) {\n\tcase SEEK_CUR:\n\t\toffset += file->f_pos;\n\t\tfallthrough;\n\tcase SEEK_SET:\n\t\t \n\t\tif ((unsigned long long)offset >= -MAX_ERRNO) {\n\t\t\tret = -EOVERFLOW;\n\t\t\tbreak;\n\t\t}\n\t\tfile->f_pos = offset;\n\t\tret = file->f_pos;\n\t\tforce_successful_syscall_return();\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\tinode_unlock(file_inode(file));\n\treturn ret;\n}\n\nstatic int open_port(struct inode *inode, struct file *filp)\n{\n\tint rc;\n\n\tif (!capable(CAP_SYS_RAWIO))\n\t\treturn -EPERM;\n\n\trc = security_locked_down(LOCKDOWN_DEV_MEM);\n\tif (rc)\n\t\treturn rc;\n\n\tif (iminor(inode) != DEVMEM_MINOR)\n\t\treturn 0;\n\n\t \n\tfilp->f_mapping = iomem_get_mapping();\n\n\treturn 0;\n}\n\n#define zero_lseek\tnull_lseek\n#define full_lseek      null_lseek\n#define write_zero\twrite_null\n#define write_iter_zero\twrite_iter_null\n#define open_mem\topen_port\n\nstatic const struct file_operations __maybe_unused mem_fops = {\n\t.llseek\t\t= memory_lseek,\n\t.read\t\t= read_mem,\n\t.write\t\t= write_mem,\n\t.mmap\t\t= mmap_mem,\n\t.open\t\t= open_mem,\n#ifndef CONFIG_MMU\n\t.get_unmapped_area = get_unmapped_area_mem,\n\t.mmap_capabilities = memory_mmap_capabilities,\n#endif\n};\n\nstatic const struct file_operations null_fops = {\n\t.llseek\t\t= null_lseek,\n\t.read\t\t= read_null,\n\t.write\t\t= write_null,\n\t.read_iter\t= read_iter_null,\n\t.write_iter\t= write_iter_null,\n\t.splice_write\t= splice_write_null,\n\t.uring_cmd\t= uring_cmd_null,\n};\n\nstatic const struct file_operations __maybe_unused port_fops = {\n\t.llseek\t\t= memory_lseek,\n\t.read\t\t= read_port,\n\t.write\t\t= write_port,\n\t.open\t\t= open_port,\n};\n\nstatic const struct file_operations zero_fops = {\n\t.llseek\t\t= zero_lseek,\n\t.write\t\t= write_zero,\n\t.read_iter\t= read_iter_zero,\n\t.read\t\t= read_zero,\n\t.write_iter\t= write_iter_zero,\n\t.mmap\t\t= mmap_zero,\n\t.get_unmapped_area = get_unmapped_area_zero,\n#ifndef CONFIG_MMU\n\t.mmap_capabilities = zero_mmap_capabilities,\n#endif\n};\n\nstatic const struct file_operations full_fops = {\n\t.llseek\t\t= full_lseek,\n\t.read_iter\t= read_iter_zero,\n\t.write\t\t= write_full,\n};\n\nstatic const struct memdev {\n\tconst char *name;\n\tconst struct file_operations *fops;\n\tfmode_t fmode;\n\tumode_t mode;\n} devlist[] = {\n#ifdef CONFIG_DEVMEM\n\t[DEVMEM_MINOR] = { \"mem\", &mem_fops, FMODE_UNSIGNED_OFFSET, 0 },\n#endif\n\t[3] = { \"null\", &null_fops, FMODE_NOWAIT, 0666 },\n#ifdef CONFIG_DEVPORT\n\t[4] = { \"port\", &port_fops, 0, 0 },\n#endif\n\t[5] = { \"zero\", &zero_fops, FMODE_NOWAIT, 0666 },\n\t[7] = { \"full\", &full_fops, 0, 0666 },\n\t[8] = { \"random\", &random_fops, FMODE_NOWAIT, 0666 },\n\t[9] = { \"urandom\", &urandom_fops, FMODE_NOWAIT, 0666 },\n#ifdef CONFIG_PRINTK\n\t[11] = { \"kmsg\", &kmsg_fops, 0, 0644 },\n#endif\n};\n\nstatic int memory_open(struct inode *inode, struct file *filp)\n{\n\tint minor;\n\tconst struct memdev *dev;\n\n\tminor = iminor(inode);\n\tif (minor >= ARRAY_SIZE(devlist))\n\t\treturn -ENXIO;\n\n\tdev = &devlist[minor];\n\tif (!dev->fops)\n\t\treturn -ENXIO;\n\n\tfilp->f_op = dev->fops;\n\tfilp->f_mode |= dev->fmode;\n\n\tif (dev->fops->open)\n\t\treturn dev->fops->open(inode, filp);\n\n\treturn 0;\n}\n\nstatic const struct file_operations memory_fops = {\n\t.open = memory_open,\n\t.llseek = noop_llseek,\n};\n\nstatic char *mem_devnode(const struct device *dev, umode_t *mode)\n{\n\tif (mode && devlist[MINOR(dev->devt)].mode)\n\t\t*mode = devlist[MINOR(dev->devt)].mode;\n\treturn NULL;\n}\n\nstatic const struct class mem_class = {\n\t.name\t\t= \"mem\",\n\t.devnode\t= mem_devnode,\n};\n\nstatic int __init chr_dev_init(void)\n{\n\tint retval;\n\tint minor;\n\n\tif (register_chrdev(MEM_MAJOR, \"mem\", &memory_fops))\n\t\tprintk(\"unable to get major %d for memory devs\\n\", MEM_MAJOR);\n\n\tretval = class_register(&mem_class);\n\tif (retval)\n\t\treturn retval;\n\n\tfor (minor = 1; minor < ARRAY_SIZE(devlist); minor++) {\n\t\tif (!devlist[minor].name)\n\t\t\tcontinue;\n\n\t\t \n\t\tif ((minor == DEVPORT_MINOR) && !arch_has_dev_port())\n\t\t\tcontinue;\n\n\t\tdevice_create(&mem_class, NULL, MKDEV(MEM_MAJOR, minor),\n\t\t\t      NULL, devlist[minor].name);\n\t}\n\n\treturn tty_init();\n}\n\nfs_initcall(chr_dev_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}