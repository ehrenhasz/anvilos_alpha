{
  "module_name": "vfio_iommu_spapr_tce.c",
  "hash_id": "0e4e1d26750ac2957de4128b72a7cb8ed674a9a55ee943d24daaddfbda2a0322",
  "original_prompt": "Ingested from linux-6.6.14/drivers/vfio/vfio_iommu_spapr_tce.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/err.h>\n#include <linux/vfio.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include \"vfio.h\"\n\n#include <asm/iommu.h>\n#include <asm/tce.h>\n#include <asm/mmu_context.h>\n\n#define DRIVER_VERSION  \"0.1\"\n#define DRIVER_AUTHOR   \"aik@ozlabs.ru\"\n#define DRIVER_DESC     \"VFIO IOMMU SPAPR TCE\"\n\nstatic void tce_iommu_detach_group(void *iommu_data,\n\t\tstruct iommu_group *iommu_group);\n\n \n\nstruct tce_iommu_group {\n\tstruct list_head next;\n\tstruct iommu_group *grp;\n};\n\n \nstruct tce_iommu_prereg {\n\tstruct list_head next;\n\tstruct mm_iommu_table_group_mem_t *mem;\n};\n\n \nstruct tce_container {\n\tstruct mutex lock;\n\tbool enabled;\n\tbool v2;\n\tbool def_window_pending;\n\tunsigned long locked_pages;\n\tstruct mm_struct *mm;\n\tstruct iommu_table *tables[IOMMU_TABLE_GROUP_MAX_TABLES];\n\tstruct list_head group_list;\n\tstruct list_head prereg_list;\n};\n\nstatic long tce_iommu_mm_set(struct tce_container *container)\n{\n\tif (container->mm) {\n\t\tif (container->mm == current->mm)\n\t\t\treturn 0;\n\t\treturn -EPERM;\n\t}\n\tBUG_ON(!current->mm);\n\tcontainer->mm = current->mm;\n\tmmgrab(container->mm);\n\n\treturn 0;\n}\n\nstatic long tce_iommu_prereg_free(struct tce_container *container,\n\t\tstruct tce_iommu_prereg *tcemem)\n{\n\tlong ret;\n\n\tret = mm_iommu_put(container->mm, tcemem->mem);\n\tif (ret)\n\t\treturn ret;\n\n\tlist_del(&tcemem->next);\n\tkfree(tcemem);\n\n\treturn 0;\n}\n\nstatic long tce_iommu_unregister_pages(struct tce_container *container,\n\t\t__u64 vaddr, __u64 size)\n{\n\tstruct mm_iommu_table_group_mem_t *mem;\n\tstruct tce_iommu_prereg *tcemem;\n\tbool found = false;\n\tlong ret;\n\n\tif ((vaddr & ~PAGE_MASK) || (size & ~PAGE_MASK))\n\t\treturn -EINVAL;\n\n\tmem = mm_iommu_get(container->mm, vaddr, size >> PAGE_SHIFT);\n\tif (!mem)\n\t\treturn -ENOENT;\n\n\tlist_for_each_entry(tcemem, &container->prereg_list, next) {\n\t\tif (tcemem->mem == mem) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found)\n\t\tret = -ENOENT;\n\telse\n\t\tret = tce_iommu_prereg_free(container, tcemem);\n\n\tmm_iommu_put(container->mm, mem);\n\n\treturn ret;\n}\n\nstatic long tce_iommu_register_pages(struct tce_container *container,\n\t\t__u64 vaddr, __u64 size)\n{\n\tlong ret = 0;\n\tstruct mm_iommu_table_group_mem_t *mem = NULL;\n\tstruct tce_iommu_prereg *tcemem;\n\tunsigned long entries = size >> PAGE_SHIFT;\n\n\tif ((vaddr & ~PAGE_MASK) || (size & ~PAGE_MASK) ||\n\t\t\t((vaddr + size) < vaddr))\n\t\treturn -EINVAL;\n\n\tmem = mm_iommu_get(container->mm, vaddr, entries);\n\tif (mem) {\n\t\tlist_for_each_entry(tcemem, &container->prereg_list, next) {\n\t\t\tif (tcemem->mem == mem) {\n\t\t\t\tret = -EBUSY;\n\t\t\t\tgoto put_exit;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tret = mm_iommu_new(container->mm, vaddr, entries, &mem);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\ttcemem = kzalloc(sizeof(*tcemem), GFP_KERNEL);\n\tif (!tcemem) {\n\t\tret = -ENOMEM;\n\t\tgoto put_exit;\n\t}\n\n\ttcemem->mem = mem;\n\tlist_add(&tcemem->next, &container->prereg_list);\n\n\tcontainer->enabled = true;\n\n\treturn 0;\n\nput_exit:\n\tmm_iommu_put(container->mm, mem);\n\treturn ret;\n}\n\nstatic bool tce_page_is_contained(struct mm_struct *mm, unsigned long hpa,\n\t\tunsigned int it_page_shift)\n{\n\tstruct page *page;\n\tunsigned long size = 0;\n\n\tif (mm_iommu_is_devmem(mm, hpa, it_page_shift, &size))\n\t\treturn size == (1UL << it_page_shift);\n\n\tpage = pfn_to_page(hpa >> PAGE_SHIFT);\n\t \n\treturn page_shift(compound_head(page)) >= it_page_shift;\n}\n\nstatic inline bool tce_groups_attached(struct tce_container *container)\n{\n\treturn !list_empty(&container->group_list);\n}\n\nstatic long tce_iommu_find_table(struct tce_container *container,\n\t\tphys_addr_t ioba, struct iommu_table **ptbl)\n{\n\tlong i;\n\n\tfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\n\t\tstruct iommu_table *tbl = container->tables[i];\n\n\t\tif (tbl) {\n\t\t\tunsigned long entry = ioba >> tbl->it_page_shift;\n\t\t\tunsigned long start = tbl->it_offset;\n\t\t\tunsigned long end = start + tbl->it_size;\n\n\t\t\tif ((start <= entry) && (entry < end)) {\n\t\t\t\t*ptbl = tbl;\n\t\t\t\treturn i;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn -1;\n}\n\nstatic int tce_iommu_find_free_table(struct tce_container *container)\n{\n\tint i;\n\n\tfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\n\t\tif (!container->tables[i])\n\t\t\treturn i;\n\t}\n\n\treturn -ENOSPC;\n}\n\nstatic int tce_iommu_enable(struct tce_container *container)\n{\n\tint ret = 0;\n\tunsigned long locked;\n\tstruct iommu_table_group *table_group;\n\tstruct tce_iommu_group *tcegrp;\n\n\tif (container->enabled)\n\t\treturn -EBUSY;\n\n\t \n\tif (!tce_groups_attached(container))\n\t\treturn -ENODEV;\n\n\ttcegrp = list_first_entry(&container->group_list,\n\t\t\tstruct tce_iommu_group, next);\n\ttable_group = iommu_group_get_iommudata(tcegrp->grp);\n\tif (!table_group)\n\t\treturn -ENODEV;\n\n\tif (!table_group->tce32_size)\n\t\treturn -EPERM;\n\n\tret = tce_iommu_mm_set(container);\n\tif (ret)\n\t\treturn ret;\n\n\tlocked = table_group->tce32_size >> PAGE_SHIFT;\n\tret = account_locked_vm(container->mm, locked, true);\n\tif (ret)\n\t\treturn ret;\n\n\tcontainer->locked_pages = locked;\n\n\tcontainer->enabled = true;\n\n\treturn ret;\n}\n\nstatic void tce_iommu_disable(struct tce_container *container)\n{\n\tif (!container->enabled)\n\t\treturn;\n\n\tcontainer->enabled = false;\n\n\tBUG_ON(!container->mm);\n\taccount_locked_vm(container->mm, container->locked_pages, false);\n}\n\nstatic void *tce_iommu_open(unsigned long arg)\n{\n\tstruct tce_container *container;\n\n\tif ((arg != VFIO_SPAPR_TCE_IOMMU) && (arg != VFIO_SPAPR_TCE_v2_IOMMU)) {\n\t\tpr_err(\"tce_vfio: Wrong IOMMU type\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tcontainer = kzalloc(sizeof(*container), GFP_KERNEL);\n\tif (!container)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmutex_init(&container->lock);\n\tINIT_LIST_HEAD_RCU(&container->group_list);\n\tINIT_LIST_HEAD_RCU(&container->prereg_list);\n\n\tcontainer->v2 = arg == VFIO_SPAPR_TCE_v2_IOMMU;\n\n\treturn container;\n}\n\nstatic int tce_iommu_clear(struct tce_container *container,\n\t\tstruct iommu_table *tbl,\n\t\tunsigned long entry, unsigned long pages);\nstatic void tce_iommu_free_table(struct tce_container *container,\n\t\tstruct iommu_table *tbl);\n\nstatic void tce_iommu_release(void *iommu_data)\n{\n\tstruct tce_container *container = iommu_data;\n\tstruct tce_iommu_group *tcegrp;\n\tstruct tce_iommu_prereg *tcemem, *tmtmp;\n\tlong i;\n\n\twhile (tce_groups_attached(container)) {\n\t\ttcegrp = list_first_entry(&container->group_list,\n\t\t\t\tstruct tce_iommu_group, next);\n\t\ttce_iommu_detach_group(iommu_data, tcegrp->grp);\n\t}\n\n\t \n\tfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\n\t\tstruct iommu_table *tbl = container->tables[i];\n\n\t\tif (!tbl)\n\t\t\tcontinue;\n\n\t\ttce_iommu_clear(container, tbl, tbl->it_offset, tbl->it_size);\n\t\ttce_iommu_free_table(container, tbl);\n\t}\n\n\tlist_for_each_entry_safe(tcemem, tmtmp, &container->prereg_list, next)\n\t\tWARN_ON(tce_iommu_prereg_free(container, tcemem));\n\n\ttce_iommu_disable(container);\n\tif (container->mm)\n\t\tmmdrop(container->mm);\n\tmutex_destroy(&container->lock);\n\n\tkfree(container);\n}\n\nstatic void tce_iommu_unuse_page(unsigned long hpa)\n{\n\tstruct page *page;\n\n\tpage = pfn_to_page(hpa >> PAGE_SHIFT);\n\tunpin_user_page(page);\n}\n\nstatic int tce_iommu_prereg_ua_to_hpa(struct tce_container *container,\n\t\tunsigned long tce, unsigned long shift,\n\t\tunsigned long *phpa, struct mm_iommu_table_group_mem_t **pmem)\n{\n\tlong ret = 0;\n\tstruct mm_iommu_table_group_mem_t *mem;\n\n\tmem = mm_iommu_lookup(container->mm, tce, 1ULL << shift);\n\tif (!mem)\n\t\treturn -EINVAL;\n\n\tret = mm_iommu_ua_to_hpa(mem, tce, shift, phpa);\n\tif (ret)\n\t\treturn -EINVAL;\n\n\t*pmem = mem;\n\n\treturn 0;\n}\n\nstatic void tce_iommu_unuse_page_v2(struct tce_container *container,\n\t\tstruct iommu_table *tbl, unsigned long entry)\n{\n\tstruct mm_iommu_table_group_mem_t *mem = NULL;\n\tint ret;\n\tunsigned long hpa = 0;\n\t__be64 *pua = IOMMU_TABLE_USERSPACE_ENTRY_RO(tbl, entry);\n\n\tif (!pua)\n\t\treturn;\n\n\tret = tce_iommu_prereg_ua_to_hpa(container, be64_to_cpu(*pua),\n\t\t\ttbl->it_page_shift, &hpa, &mem);\n\tif (ret)\n\t\tpr_debug(\"%s: tce %llx at #%lx was not cached, ret=%d\\n\",\n\t\t\t\t__func__, be64_to_cpu(*pua), entry, ret);\n\tif (mem)\n\t\tmm_iommu_mapped_dec(mem);\n\n\t*pua = cpu_to_be64(0);\n}\n\nstatic int tce_iommu_clear(struct tce_container *container,\n\t\tstruct iommu_table *tbl,\n\t\tunsigned long entry, unsigned long pages)\n{\n\tunsigned long oldhpa;\n\tlong ret;\n\tenum dma_data_direction direction;\n\tunsigned long lastentry = entry + pages, firstentry = entry;\n\n\tfor ( ; entry < lastentry; ++entry) {\n\t\tif (tbl->it_indirect_levels && tbl->it_userspace) {\n\t\t\t \n\t\t\t__be64 *pua = IOMMU_TABLE_USERSPACE_ENTRY_RO(tbl,\n\t\t\t\t\tentry);\n\t\t\tif (!pua) {\n\t\t\t\t \n\t\t\t\tentry |= tbl->it_level_size - 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tcond_resched();\n\n\t\tdirection = DMA_NONE;\n\t\toldhpa = 0;\n\t\tret = iommu_tce_xchg_no_kill(container->mm, tbl, entry, &oldhpa,\n\t\t\t\t&direction);\n\t\tif (ret)\n\t\t\tcontinue;\n\n\t\tif (direction == DMA_NONE)\n\t\t\tcontinue;\n\n\t\tif (container->v2) {\n\t\t\ttce_iommu_unuse_page_v2(container, tbl, entry);\n\t\t\tcontinue;\n\t\t}\n\n\t\ttce_iommu_unuse_page(oldhpa);\n\t}\n\n\tiommu_tce_kill(tbl, firstentry, pages);\n\n\treturn 0;\n}\n\nstatic int tce_iommu_use_page(unsigned long tce, unsigned long *hpa)\n{\n\tstruct page *page = NULL;\n\tenum dma_data_direction direction = iommu_tce_direction(tce);\n\n\tif (pin_user_pages_fast(tce & PAGE_MASK, 1,\n\t\t\tdirection != DMA_TO_DEVICE ? FOLL_WRITE : 0,\n\t\t\t&page) != 1)\n\t\treturn -EFAULT;\n\n\t*hpa = __pa((unsigned long) page_address(page));\n\n\treturn 0;\n}\n\nstatic long tce_iommu_build(struct tce_container *container,\n\t\tstruct iommu_table *tbl,\n\t\tunsigned long entry, unsigned long tce, unsigned long pages,\n\t\tenum dma_data_direction direction)\n{\n\tlong i, ret = 0;\n\tunsigned long hpa;\n\tenum dma_data_direction dirtmp;\n\n\tfor (i = 0; i < pages; ++i) {\n\t\tunsigned long offset = tce & IOMMU_PAGE_MASK(tbl) & ~PAGE_MASK;\n\n\t\tret = tce_iommu_use_page(tce, &hpa);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (!tce_page_is_contained(container->mm, hpa,\n\t\t\t\ttbl->it_page_shift)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\n\t\thpa |= offset;\n\t\tdirtmp = direction;\n\t\tret = iommu_tce_xchg_no_kill(container->mm, tbl, entry + i,\n\t\t\t\t&hpa, &dirtmp);\n\t\tif (ret) {\n\t\t\ttce_iommu_unuse_page(hpa);\n\t\t\tpr_err(\"iommu_tce: %s failed ioba=%lx, tce=%lx, ret=%ld\\n\",\n\t\t\t\t\t__func__, entry << tbl->it_page_shift,\n\t\t\t\t\ttce, ret);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (dirtmp != DMA_NONE)\n\t\t\ttce_iommu_unuse_page(hpa);\n\n\t\ttce += IOMMU_PAGE_SIZE(tbl);\n\t}\n\n\tif (ret)\n\t\ttce_iommu_clear(container, tbl, entry, i);\n\telse\n\t\tiommu_tce_kill(tbl, entry, pages);\n\n\treturn ret;\n}\n\nstatic long tce_iommu_build_v2(struct tce_container *container,\n\t\tstruct iommu_table *tbl,\n\t\tunsigned long entry, unsigned long tce, unsigned long pages,\n\t\tenum dma_data_direction direction)\n{\n\tlong i, ret = 0;\n\tunsigned long hpa;\n\tenum dma_data_direction dirtmp;\n\n\tfor (i = 0; i < pages; ++i) {\n\t\tstruct mm_iommu_table_group_mem_t *mem = NULL;\n\t\t__be64 *pua = IOMMU_TABLE_USERSPACE_ENTRY(tbl, entry + i);\n\n\t\tret = tce_iommu_prereg_ua_to_hpa(container,\n\t\t\t\ttce, tbl->it_page_shift, &hpa, &mem);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (!tce_page_is_contained(container->mm, hpa,\n\t\t\t\ttbl->it_page_shift)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\thpa |= tce & IOMMU_PAGE_MASK(tbl) & ~PAGE_MASK;\n\t\tdirtmp = direction;\n\n\t\t \n\t\tif (mm_iommu_mapped_inc(mem))\n\t\t\tbreak;\n\n\t\tret = iommu_tce_xchg_no_kill(container->mm, tbl, entry + i,\n\t\t\t\t&hpa, &dirtmp);\n\t\tif (ret) {\n\t\t\t \n\t\t\ttce_iommu_unuse_page_v2(container, tbl, entry + i);\n\t\t\tpr_err(\"iommu_tce: %s failed ioba=%lx, tce=%lx, ret=%ld\\n\",\n\t\t\t\t\t__func__, entry << tbl->it_page_shift,\n\t\t\t\t\ttce, ret);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (dirtmp != DMA_NONE)\n\t\t\ttce_iommu_unuse_page_v2(container, tbl, entry + i);\n\n\t\t*pua = cpu_to_be64(tce);\n\n\t\ttce += IOMMU_PAGE_SIZE(tbl);\n\t}\n\n\tif (ret)\n\t\ttce_iommu_clear(container, tbl, entry, i);\n\telse\n\t\tiommu_tce_kill(tbl, entry, pages);\n\n\treturn ret;\n}\n\nstatic long tce_iommu_create_table(struct tce_container *container,\n\t\t\tstruct iommu_table_group *table_group,\n\t\t\tint num,\n\t\t\t__u32 page_shift,\n\t\t\t__u64 window_size,\n\t\t\t__u32 levels,\n\t\t\tstruct iommu_table **ptbl)\n{\n\tlong ret, table_size;\n\n\ttable_size = table_group->ops->get_table_size(page_shift, window_size,\n\t\t\tlevels);\n\tif (!table_size)\n\t\treturn -EINVAL;\n\n\tret = account_locked_vm(container->mm, table_size >> PAGE_SHIFT, true);\n\tif (ret)\n\t\treturn ret;\n\n\tret = table_group->ops->create_table(table_group, num,\n\t\t\tpage_shift, window_size, levels, ptbl);\n\n\tWARN_ON(!ret && !(*ptbl)->it_ops->free);\n\tWARN_ON(!ret && ((*ptbl)->it_allocated_size > table_size));\n\n\treturn ret;\n}\n\nstatic void tce_iommu_free_table(struct tce_container *container,\n\t\tstruct iommu_table *tbl)\n{\n\tunsigned long pages = tbl->it_allocated_size >> PAGE_SHIFT;\n\n\tiommu_tce_table_put(tbl);\n\taccount_locked_vm(container->mm, pages, false);\n}\n\nstatic long tce_iommu_create_window(struct tce_container *container,\n\t\t__u32 page_shift, __u64 window_size, __u32 levels,\n\t\t__u64 *start_addr)\n{\n\tstruct tce_iommu_group *tcegrp;\n\tstruct iommu_table_group *table_group;\n\tstruct iommu_table *tbl = NULL;\n\tlong ret, num;\n\n\tnum = tce_iommu_find_free_table(container);\n\tif (num < 0)\n\t\treturn num;\n\n\t \n\ttcegrp = list_first_entry(&container->group_list,\n\t\t\tstruct tce_iommu_group, next);\n\ttable_group = iommu_group_get_iommudata(tcegrp->grp);\n\tif (!table_group)\n\t\treturn -EFAULT;\n\n\tif (!(table_group->pgsizes & (1ULL << page_shift)))\n\t\treturn -EINVAL;\n\n\tif (!table_group->ops->set_window || !table_group->ops->unset_window ||\n\t\t\t!table_group->ops->get_table_size ||\n\t\t\t!table_group->ops->create_table)\n\t\treturn -EPERM;\n\n\t \n\tret = tce_iommu_create_table(container, table_group, num,\n\t\t\tpage_shift, window_size, levels, &tbl);\n\tif (ret)\n\t\treturn ret;\n\n\tBUG_ON(!tbl->it_ops->free);\n\n\t \n\tlist_for_each_entry(tcegrp, &container->group_list, next) {\n\t\ttable_group = iommu_group_get_iommudata(tcegrp->grp);\n\n\t\tret = table_group->ops->set_window(table_group, num, tbl);\n\t\tif (ret)\n\t\t\tgoto unset_exit;\n\t}\n\n\tcontainer->tables[num] = tbl;\n\n\t \n\t*start_addr = tbl->it_offset << tbl->it_page_shift;\n\n\treturn 0;\n\nunset_exit:\n\tlist_for_each_entry(tcegrp, &container->group_list, next) {\n\t\ttable_group = iommu_group_get_iommudata(tcegrp->grp);\n\t\ttable_group->ops->unset_window(table_group, num);\n\t}\n\ttce_iommu_free_table(container, tbl);\n\n\treturn ret;\n}\n\nstatic long tce_iommu_remove_window(struct tce_container *container,\n\t\t__u64 start_addr)\n{\n\tstruct iommu_table_group *table_group = NULL;\n\tstruct iommu_table *tbl;\n\tstruct tce_iommu_group *tcegrp;\n\tint num;\n\n\tnum = tce_iommu_find_table(container, start_addr, &tbl);\n\tif (num < 0)\n\t\treturn -EINVAL;\n\n\tBUG_ON(!tbl->it_size);\n\n\t \n\tlist_for_each_entry(tcegrp, &container->group_list, next) {\n\t\ttable_group = iommu_group_get_iommudata(tcegrp->grp);\n\n\t\t \n\t\tif (!table_group->ops || !table_group->ops->unset_window)\n\t\t\treturn -EPERM;\n\n\t\ttable_group->ops->unset_window(table_group, num);\n\t}\n\n\t \n\ttce_iommu_clear(container, tbl, tbl->it_offset, tbl->it_size);\n\ttce_iommu_free_table(container, tbl);\n\tcontainer->tables[num] = NULL;\n\n\treturn 0;\n}\n\nstatic long tce_iommu_create_default_window(struct tce_container *container)\n{\n\tlong ret;\n\t__u64 start_addr = 0;\n\tstruct tce_iommu_group *tcegrp;\n\tstruct iommu_table_group *table_group;\n\n\tif (!container->def_window_pending)\n\t\treturn 0;\n\n\tif (!tce_groups_attached(container))\n\t\treturn -ENODEV;\n\n\ttcegrp = list_first_entry(&container->group_list,\n\t\t\tstruct tce_iommu_group, next);\n\ttable_group = iommu_group_get_iommudata(tcegrp->grp);\n\tif (!table_group)\n\t\treturn -ENODEV;\n\n\tret = tce_iommu_create_window(container, IOMMU_PAGE_SHIFT_4K,\n\t\t\ttable_group->tce32_size, 1, &start_addr);\n\tWARN_ON_ONCE(!ret && start_addr);\n\n\tif (!ret)\n\t\tcontainer->def_window_pending = false;\n\n\treturn ret;\n}\n\nstatic long vfio_spapr_ioctl_eeh_pe_op(struct iommu_group *group,\n\t\t\t\t       unsigned long arg)\n{\n\tstruct eeh_pe *pe;\n\tstruct vfio_eeh_pe_op op;\n\tunsigned long minsz;\n\n\tpe = eeh_iommu_group_to_pe(group);\n\tif (!pe)\n\t\treturn -ENODEV;\n\n\tminsz = offsetofend(struct vfio_eeh_pe_op, op);\n\tif (copy_from_user(&op, (void __user *)arg, minsz))\n\t\treturn -EFAULT;\n\tif (op.argsz < minsz || op.flags)\n\t\treturn -EINVAL;\n\n\tswitch (op.op) {\n\tcase VFIO_EEH_PE_DISABLE:\n\t\treturn eeh_pe_set_option(pe, EEH_OPT_DISABLE);\n\tcase VFIO_EEH_PE_ENABLE:\n\t\treturn eeh_pe_set_option(pe, EEH_OPT_ENABLE);\n\tcase VFIO_EEH_PE_UNFREEZE_IO:\n\t\treturn eeh_pe_set_option(pe, EEH_OPT_THAW_MMIO);\n\tcase VFIO_EEH_PE_UNFREEZE_DMA:\n\t\treturn eeh_pe_set_option(pe, EEH_OPT_THAW_DMA);\n\tcase VFIO_EEH_PE_GET_STATE:\n\t\treturn eeh_pe_get_state(pe);\n\t\tbreak;\n\tcase VFIO_EEH_PE_RESET_DEACTIVATE:\n\t\treturn eeh_pe_reset(pe, EEH_RESET_DEACTIVATE, true);\n\tcase VFIO_EEH_PE_RESET_HOT:\n\t\treturn eeh_pe_reset(pe, EEH_RESET_HOT, true);\n\tcase VFIO_EEH_PE_RESET_FUNDAMENTAL:\n\t\treturn eeh_pe_reset(pe, EEH_RESET_FUNDAMENTAL, true);\n\tcase VFIO_EEH_PE_CONFIGURE:\n\t\treturn eeh_pe_configure(pe);\n\tcase VFIO_EEH_PE_INJECT_ERR:\n\t\tminsz = offsetofend(struct vfio_eeh_pe_op, err.mask);\n\t\tif (op.argsz < minsz)\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&op, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\treturn eeh_pe_inject_err(pe, op.err.type, op.err.func,\n\t\t\t\t\t op.err.addr, op.err.mask);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic long tce_iommu_ioctl(void *iommu_data,\n\t\t\t\t unsigned int cmd, unsigned long arg)\n{\n\tstruct tce_container *container = iommu_data;\n\tunsigned long minsz, ddwsz;\n\tlong ret;\n\n\tswitch (cmd) {\n\tcase VFIO_CHECK_EXTENSION:\n\t\tswitch (arg) {\n\t\tcase VFIO_SPAPR_TCE_IOMMU:\n\t\tcase VFIO_SPAPR_TCE_v2_IOMMU:\n\t\t\treturn 1;\n\t\tcase VFIO_EEH:\n\t\t\treturn eeh_enabled();\n\t\tdefault:\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t \n\tBUG_ON(!container);\n\tif (container->mm && container->mm != current->mm)\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase VFIO_IOMMU_SPAPR_TCE_GET_INFO: {\n\t\tstruct vfio_iommu_spapr_tce_info info;\n\t\tstruct tce_iommu_group *tcegrp;\n\t\tstruct iommu_table_group *table_group;\n\n\t\tif (!tce_groups_attached(container))\n\t\t\treturn -ENXIO;\n\n\t\ttcegrp = list_first_entry(&container->group_list,\n\t\t\t\tstruct tce_iommu_group, next);\n\t\ttable_group = iommu_group_get_iommudata(tcegrp->grp);\n\n\t\tif (!table_group)\n\t\t\treturn -ENXIO;\n\n\t\tminsz = offsetofend(struct vfio_iommu_spapr_tce_info,\n\t\t\t\tdma32_window_size);\n\n\t\tif (copy_from_user(&info, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (info.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\tinfo.dma32_window_start = table_group->tce32_start;\n\t\tinfo.dma32_window_size = table_group->tce32_size;\n\t\tinfo.flags = 0;\n\t\tmemset(&info.ddw, 0, sizeof(info.ddw));\n\n\t\tif (table_group->max_dynamic_windows_supported &&\n\t\t\t\tcontainer->v2) {\n\t\t\tinfo.flags |= VFIO_IOMMU_SPAPR_INFO_DDW;\n\t\t\tinfo.ddw.pgsizes = table_group->pgsizes;\n\t\t\tinfo.ddw.max_dynamic_windows_supported =\n\t\t\t\ttable_group->max_dynamic_windows_supported;\n\t\t\tinfo.ddw.levels = table_group->max_levels;\n\t\t}\n\n\t\tddwsz = offsetofend(struct vfio_iommu_spapr_tce_info, ddw);\n\n\t\tif (info.argsz >= ddwsz)\n\t\t\tminsz = ddwsz;\n\n\t\tif (copy_to_user((void __user *)arg, &info, minsz))\n\t\t\treturn -EFAULT;\n\n\t\treturn 0;\n\t}\n\tcase VFIO_IOMMU_MAP_DMA: {\n\t\tstruct vfio_iommu_type1_dma_map param;\n\t\tstruct iommu_table *tbl = NULL;\n\t\tlong num;\n\t\tenum dma_data_direction direction;\n\n\t\tif (!container->enabled)\n\t\t\treturn -EPERM;\n\n\t\tminsz = offsetofend(struct vfio_iommu_type1_dma_map, size);\n\n\t\tif (copy_from_user(&param, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (param.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\tif (param.flags & ~(VFIO_DMA_MAP_FLAG_READ |\n\t\t\t\tVFIO_DMA_MAP_FLAG_WRITE))\n\t\t\treturn -EINVAL;\n\n\t\tret = tce_iommu_create_default_window(container);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tnum = tce_iommu_find_table(container, param.iova, &tbl);\n\t\tif (num < 0)\n\t\t\treturn -ENXIO;\n\n\t\tif ((param.size & ~IOMMU_PAGE_MASK(tbl)) ||\n\t\t\t\t(param.vaddr & ~IOMMU_PAGE_MASK(tbl)))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (param.flags & VFIO_DMA_MAP_FLAG_READ) {\n\t\t\tif (param.flags & VFIO_DMA_MAP_FLAG_WRITE)\n\t\t\t\tdirection = DMA_BIDIRECTIONAL;\n\t\t\telse\n\t\t\t\tdirection = DMA_TO_DEVICE;\n\t\t} else {\n\t\t\tif (param.flags & VFIO_DMA_MAP_FLAG_WRITE)\n\t\t\t\tdirection = DMA_FROM_DEVICE;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tret = iommu_tce_put_param_check(tbl, param.iova, param.vaddr);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (container->v2)\n\t\t\tret = tce_iommu_build_v2(container, tbl,\n\t\t\t\t\tparam.iova >> tbl->it_page_shift,\n\t\t\t\t\tparam.vaddr,\n\t\t\t\t\tparam.size >> tbl->it_page_shift,\n\t\t\t\t\tdirection);\n\t\telse\n\t\t\tret = tce_iommu_build(container, tbl,\n\t\t\t\t\tparam.iova >> tbl->it_page_shift,\n\t\t\t\t\tparam.vaddr,\n\t\t\t\t\tparam.size >> tbl->it_page_shift,\n\t\t\t\t\tdirection);\n\n\t\tiommu_flush_tce(tbl);\n\n\t\treturn ret;\n\t}\n\tcase VFIO_IOMMU_UNMAP_DMA: {\n\t\tstruct vfio_iommu_type1_dma_unmap param;\n\t\tstruct iommu_table *tbl = NULL;\n\t\tlong num;\n\n\t\tif (!container->enabled)\n\t\t\treturn -EPERM;\n\n\t\tminsz = offsetofend(struct vfio_iommu_type1_dma_unmap,\n\t\t\t\tsize);\n\n\t\tif (copy_from_user(&param, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (param.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (param.flags)\n\t\t\treturn -EINVAL;\n\n\t\tret = tce_iommu_create_default_window(container);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tnum = tce_iommu_find_table(container, param.iova, &tbl);\n\t\tif (num < 0)\n\t\t\treturn -ENXIO;\n\n\t\tif (param.size & ~IOMMU_PAGE_MASK(tbl))\n\t\t\treturn -EINVAL;\n\n\t\tret = iommu_tce_clear_param_check(tbl, param.iova, 0,\n\t\t\t\tparam.size >> tbl->it_page_shift);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = tce_iommu_clear(container, tbl,\n\t\t\t\tparam.iova >> tbl->it_page_shift,\n\t\t\t\tparam.size >> tbl->it_page_shift);\n\t\tiommu_flush_tce(tbl);\n\n\t\treturn ret;\n\t}\n\tcase VFIO_IOMMU_SPAPR_REGISTER_MEMORY: {\n\t\tstruct vfio_iommu_spapr_register_memory param;\n\n\t\tif (!container->v2)\n\t\t\tbreak;\n\n\t\tminsz = offsetofend(struct vfio_iommu_spapr_register_memory,\n\t\t\t\tsize);\n\n\t\tret = tce_iommu_mm_set(container);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (copy_from_user(&param, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (param.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (param.flags)\n\t\t\treturn -EINVAL;\n\n\t\tmutex_lock(&container->lock);\n\t\tret = tce_iommu_register_pages(container, param.vaddr,\n\t\t\t\tparam.size);\n\t\tmutex_unlock(&container->lock);\n\n\t\treturn ret;\n\t}\n\tcase VFIO_IOMMU_SPAPR_UNREGISTER_MEMORY: {\n\t\tstruct vfio_iommu_spapr_register_memory param;\n\n\t\tif (!container->v2)\n\t\t\tbreak;\n\n\t\tif (!container->mm)\n\t\t\treturn -EPERM;\n\n\t\tminsz = offsetofend(struct vfio_iommu_spapr_register_memory,\n\t\t\t\tsize);\n\n\t\tif (copy_from_user(&param, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (param.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (param.flags)\n\t\t\treturn -EINVAL;\n\n\t\tmutex_lock(&container->lock);\n\t\tret = tce_iommu_unregister_pages(container, param.vaddr,\n\t\t\t\tparam.size);\n\t\tmutex_unlock(&container->lock);\n\n\t\treturn ret;\n\t}\n\tcase VFIO_IOMMU_ENABLE:\n\t\tif (container->v2)\n\t\t\tbreak;\n\n\t\tmutex_lock(&container->lock);\n\t\tret = tce_iommu_enable(container);\n\t\tmutex_unlock(&container->lock);\n\t\treturn ret;\n\n\n\tcase VFIO_IOMMU_DISABLE:\n\t\tif (container->v2)\n\t\t\tbreak;\n\n\t\tmutex_lock(&container->lock);\n\t\ttce_iommu_disable(container);\n\t\tmutex_unlock(&container->lock);\n\t\treturn 0;\n\n\tcase VFIO_EEH_PE_OP: {\n\t\tstruct tce_iommu_group *tcegrp;\n\n\t\tret = 0;\n\t\tlist_for_each_entry(tcegrp, &container->group_list, next) {\n\t\t\tret = vfio_spapr_ioctl_eeh_pe_op(tcegrp->grp, arg);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t\treturn ret;\n\t}\n\n\tcase VFIO_IOMMU_SPAPR_TCE_CREATE: {\n\t\tstruct vfio_iommu_spapr_tce_create create;\n\n\t\tif (!container->v2)\n\t\t\tbreak;\n\n\t\tret = tce_iommu_mm_set(container);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (!tce_groups_attached(container))\n\t\t\treturn -ENXIO;\n\n\t\tminsz = offsetofend(struct vfio_iommu_spapr_tce_create,\n\t\t\t\tstart_addr);\n\n\t\tif (copy_from_user(&create, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (create.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\tif (create.flags)\n\t\t\treturn -EINVAL;\n\n\t\tmutex_lock(&container->lock);\n\n\t\tret = tce_iommu_create_default_window(container);\n\t\tif (!ret)\n\t\t\tret = tce_iommu_create_window(container,\n\t\t\t\t\tcreate.page_shift,\n\t\t\t\t\tcreate.window_size, create.levels,\n\t\t\t\t\t&create.start_addr);\n\n\t\tmutex_unlock(&container->lock);\n\n\t\tif (!ret && copy_to_user((void __user *)arg, &create, minsz))\n\t\t\tret = -EFAULT;\n\n\t\treturn ret;\n\t}\n\tcase VFIO_IOMMU_SPAPR_TCE_REMOVE: {\n\t\tstruct vfio_iommu_spapr_tce_remove remove;\n\n\t\tif (!container->v2)\n\t\t\tbreak;\n\n\t\tret = tce_iommu_mm_set(container);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (!tce_groups_attached(container))\n\t\t\treturn -ENXIO;\n\n\t\tminsz = offsetofend(struct vfio_iommu_spapr_tce_remove,\n\t\t\t\tstart_addr);\n\n\t\tif (copy_from_user(&remove, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (remove.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\tif (remove.flags)\n\t\t\treturn -EINVAL;\n\n\t\tif (container->def_window_pending && !remove.start_addr) {\n\t\t\tcontainer->def_window_pending = false;\n\t\t\treturn 0;\n\t\t}\n\n\t\tmutex_lock(&container->lock);\n\n\t\tret = tce_iommu_remove_window(container, remove.start_addr);\n\n\t\tmutex_unlock(&container->lock);\n\n\t\treturn ret;\n\t}\n\t}\n\n\treturn -ENOTTY;\n}\n\nstatic void tce_iommu_release_ownership(struct tce_container *container,\n\t\tstruct iommu_table_group *table_group)\n{\n\tlong i;\n\n\tif (!table_group->ops->unset_window) {\n\t\tWARN_ON_ONCE(1);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i)\n\t\tif (container->tables[i])\n\t\t\ttable_group->ops->unset_window(table_group, i);\n}\n\nstatic long tce_iommu_take_ownership(struct tce_container *container,\n\t\tstruct iommu_table_group *table_group)\n{\n\tlong i, ret = 0;\n\n\t \n\tfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\n\t\tstruct iommu_table *tbl = container->tables[i];\n\n\t\tif (!tbl)\n\t\t\tcontinue;\n\n\t\tret = table_group->ops->set_window(table_group, i, tbl);\n\t\tif (ret)\n\t\t\tgoto release_exit;\n\t}\n\n\treturn 0;\n\nrelease_exit:\n\tfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i)\n\t\ttable_group->ops->unset_window(table_group, i);\n\n\treturn ret;\n}\n\nstatic int tce_iommu_attach_group(void *iommu_data,\n\t\tstruct iommu_group *iommu_group, enum vfio_group_type type)\n{\n\tint ret = 0;\n\tstruct tce_container *container = iommu_data;\n\tstruct iommu_table_group *table_group;\n\tstruct tce_iommu_group *tcegrp = NULL;\n\n\tif (type == VFIO_EMULATED_IOMMU)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&container->lock);\n\n\t \n\ttable_group = iommu_group_get_iommudata(iommu_group);\n\tif (!table_group) {\n\t\tret = -ENODEV;\n\t\tgoto unlock_exit;\n\t}\n\n\t \n\tif (container->v2 && table_group->max_dynamic_windows_supported == 0) {\n\t\tret = -EINVAL;\n\t\tgoto unlock_exit;\n\t}\n\n\t \n\tif (!container->v2 && tce_groups_attached(container)) {\n\t\tret = -EBUSY;\n\t\tgoto unlock_exit;\n\t}\n\n\t \n\tlist_for_each_entry(tcegrp, &container->group_list, next) {\n\t\tstruct iommu_table_group *table_group_tmp;\n\n\t\tif (tcegrp->grp == iommu_group) {\n\t\t\tpr_warn(\"tce_vfio: Group %d is already attached\\n\",\n\t\t\t\t\tiommu_group_id(iommu_group));\n\t\t\tret = -EBUSY;\n\t\t\tgoto unlock_exit;\n\t\t}\n\t\ttable_group_tmp = iommu_group_get_iommudata(tcegrp->grp);\n\t\tif (table_group_tmp->ops->create_table !=\n\t\t\t\ttable_group->ops->create_table) {\n\t\t\tpr_warn(\"tce_vfio: Group %d is incompatible with group %d\\n\",\n\t\t\t\t\tiommu_group_id(iommu_group),\n\t\t\t\t\tiommu_group_id(tcegrp->grp));\n\t\t\tret = -EPERM;\n\t\t\tgoto unlock_exit;\n\t\t}\n\t}\n\n\ttcegrp = kzalloc(sizeof(*tcegrp), GFP_KERNEL);\n\tif (!tcegrp) {\n\t\tret = -ENOMEM;\n\t\tgoto unlock_exit;\n\t}\n\n\tret = tce_iommu_take_ownership(container, table_group);\n\tif (!tce_groups_attached(container) && !container->tables[0])\n\t\tcontainer->def_window_pending = true;\n\n\tif (!ret) {\n\t\ttcegrp->grp = iommu_group;\n\t\tlist_add(&tcegrp->next, &container->group_list);\n\t}\n\n\tif (ret && tcegrp)\n\t\tkfree(tcegrp);\n\nunlock_exit:\n\tmutex_unlock(&container->lock);\n\n\treturn ret;\n}\n\nstatic void tce_iommu_detach_group(void *iommu_data,\n\t\tstruct iommu_group *iommu_group)\n{\n\tstruct tce_container *container = iommu_data;\n\tstruct iommu_table_group *table_group;\n\tbool found = false;\n\tstruct tce_iommu_group *tcegrp;\n\n\tmutex_lock(&container->lock);\n\n\tlist_for_each_entry(tcegrp, &container->group_list, next) {\n\t\tif (tcegrp->grp == iommu_group) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\tpr_warn(\"tce_vfio: detaching unattached group #%u\\n\",\n\t\t\t\tiommu_group_id(iommu_group));\n\t\tgoto unlock_exit;\n\t}\n\n\tlist_del(&tcegrp->next);\n\tkfree(tcegrp);\n\n\ttable_group = iommu_group_get_iommudata(iommu_group);\n\tBUG_ON(!table_group);\n\n\ttce_iommu_release_ownership(container, table_group);\n\nunlock_exit:\n\tmutex_unlock(&container->lock);\n}\n\nstatic const struct vfio_iommu_driver_ops tce_iommu_driver_ops = {\n\t.name\t\t= \"iommu-vfio-powerpc\",\n\t.owner\t\t= THIS_MODULE,\n\t.open\t\t= tce_iommu_open,\n\t.release\t= tce_iommu_release,\n\t.ioctl\t\t= tce_iommu_ioctl,\n\t.attach_group\t= tce_iommu_attach_group,\n\t.detach_group\t= tce_iommu_detach_group,\n};\n\nstatic int __init tce_iommu_init(void)\n{\n\treturn vfio_register_iommu_driver(&tce_iommu_driver_ops);\n}\n\nstatic void __exit tce_iommu_cleanup(void)\n{\n\tvfio_unregister_iommu_driver(&tce_iommu_driver_ops);\n}\n\nmodule_init(tce_iommu_init);\nmodule_exit(tce_iommu_cleanup);\n\nMODULE_VERSION(DRIVER_VERSION);\nMODULE_LICENSE(\"GPL v2\");\nMODULE_AUTHOR(DRIVER_AUTHOR);\nMODULE_DESCRIPTION(DRIVER_DESC);\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}