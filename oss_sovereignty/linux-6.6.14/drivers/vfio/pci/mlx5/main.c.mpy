{
  "module_name": "main.c",
  "hash_id": "d35007821a4436b2904acd87f1ef9c649313f6024a2015f4d42f6adfe9370892",
  "original_prompt": "Ingested from linux-6.6.14/drivers/vfio/pci/mlx5/main.c",
  "human_readable_source": "\n \n\n#include <linux/device.h>\n#include <linux/eventfd.h>\n#include <linux/file.h>\n#include <linux/interrupt.h>\n#include <linux/iommu.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/notifier.h>\n#include <linux/pci.h>\n#include <linux/pm_runtime.h>\n#include <linux/types.h>\n#include <linux/uaccess.h>\n#include <linux/vfio.h>\n#include <linux/sched/mm.h>\n#include <linux/anon_inodes.h>\n\n#include \"cmd.h\"\n\n \n#define MAX_LOAD_SIZE (BIT_ULL(__mlx5_bit_sz(load_vhca_state_in, size)) - 1)\n\nstatic struct mlx5vf_pci_core_device *mlx5vf_drvdata(struct pci_dev *pdev)\n{\n\tstruct vfio_pci_core_device *core_device = dev_get_drvdata(&pdev->dev);\n\n\treturn container_of(core_device, struct mlx5vf_pci_core_device,\n\t\t\t    core_device);\n}\n\nstruct page *\nmlx5vf_get_migration_page(struct mlx5_vhca_data_buffer *buf,\n\t\t\t  unsigned long offset)\n{\n\tunsigned long cur_offset = 0;\n\tstruct scatterlist *sg;\n\tunsigned int i;\n\n\t \n\tif (offset < buf->last_offset || !buf->last_offset_sg) {\n\t\tbuf->last_offset = 0;\n\t\tbuf->last_offset_sg = buf->table.sgt.sgl;\n\t\tbuf->sg_last_entry = 0;\n\t}\n\n\tcur_offset = buf->last_offset;\n\n\tfor_each_sg(buf->last_offset_sg, sg,\n\t\t\tbuf->table.sgt.orig_nents - buf->sg_last_entry, i) {\n\t\tif (offset < sg->length + cur_offset) {\n\t\t\tbuf->last_offset_sg = sg;\n\t\t\tbuf->sg_last_entry += i;\n\t\t\tbuf->last_offset = cur_offset;\n\t\t\treturn nth_page(sg_page(sg),\n\t\t\t\t\t(offset - cur_offset) / PAGE_SIZE);\n\t\t}\n\t\tcur_offset += sg->length;\n\t}\n\treturn NULL;\n}\n\nint mlx5vf_add_migration_pages(struct mlx5_vhca_data_buffer *buf,\n\t\t\t       unsigned int npages)\n{\n\tunsigned int to_alloc = npages;\n\tstruct page **page_list;\n\tunsigned long filled;\n\tunsigned int to_fill;\n\tint ret;\n\n\tto_fill = min_t(unsigned int, npages, PAGE_SIZE / sizeof(*page_list));\n\tpage_list = kvzalloc(to_fill * sizeof(*page_list), GFP_KERNEL_ACCOUNT);\n\tif (!page_list)\n\t\treturn -ENOMEM;\n\n\tdo {\n\t\tfilled = alloc_pages_bulk_array(GFP_KERNEL_ACCOUNT, to_fill,\n\t\t\t\t\t\tpage_list);\n\t\tif (!filled) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\t\tto_alloc -= filled;\n\t\tret = sg_alloc_append_table_from_pages(\n\t\t\t&buf->table, page_list, filled, 0,\n\t\t\tfilled << PAGE_SHIFT, UINT_MAX, SG_MAX_SINGLE_ALLOC,\n\t\t\tGFP_KERNEL_ACCOUNT);\n\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tbuf->allocated_length += filled * PAGE_SIZE;\n\t\t \n\t\tmemset(page_list, 0, filled * sizeof(*page_list));\n\t\tto_fill = min_t(unsigned int, to_alloc,\n\t\t\t\tPAGE_SIZE / sizeof(*page_list));\n\t} while (to_alloc > 0);\n\n\tkvfree(page_list);\n\treturn 0;\n\nerr:\n\tkvfree(page_list);\n\treturn ret;\n}\n\nstatic void mlx5vf_disable_fd(struct mlx5_vf_migration_file *migf)\n{\n\tmutex_lock(&migf->lock);\n\tmigf->state = MLX5_MIGF_STATE_ERROR;\n\tmigf->filp->f_pos = 0;\n\tmutex_unlock(&migf->lock);\n}\n\nstatic int mlx5vf_release_file(struct inode *inode, struct file *filp)\n{\n\tstruct mlx5_vf_migration_file *migf = filp->private_data;\n\n\tmlx5vf_disable_fd(migf);\n\tmutex_destroy(&migf->lock);\n\tkfree(migf);\n\treturn 0;\n}\n\nstatic struct mlx5_vhca_data_buffer *\nmlx5vf_get_data_buff_from_pos(struct mlx5_vf_migration_file *migf, loff_t pos,\n\t\t\t      bool *end_of_data)\n{\n\tstruct mlx5_vhca_data_buffer *buf;\n\tbool found = false;\n\n\t*end_of_data = false;\n\tspin_lock_irq(&migf->list_lock);\n\tif (list_empty(&migf->buf_list)) {\n\t\t*end_of_data = true;\n\t\tgoto end;\n\t}\n\n\tbuf = list_first_entry(&migf->buf_list, struct mlx5_vhca_data_buffer,\n\t\t\t       buf_elm);\n\tif (pos >= buf->start_pos &&\n\t    pos < buf->start_pos + buf->length) {\n\t\tfound = true;\n\t\tgoto end;\n\t}\n\n\t \n\tmigf->state = MLX5_MIGF_STATE_ERROR;\n\nend:\n\tspin_unlock_irq(&migf->list_lock);\n\treturn found ? buf : NULL;\n}\n\nstatic ssize_t mlx5vf_buf_read(struct mlx5_vhca_data_buffer *vhca_buf,\n\t\t\t       char __user **buf, size_t *len, loff_t *pos)\n{\n\tunsigned long offset;\n\tssize_t done = 0;\n\tsize_t copy_len;\n\n\tcopy_len = min_t(size_t,\n\t\t\t vhca_buf->start_pos + vhca_buf->length - *pos, *len);\n\twhile (copy_len) {\n\t\tsize_t page_offset;\n\t\tstruct page *page;\n\t\tsize_t page_len;\n\t\tu8 *from_buff;\n\t\tint ret;\n\n\t\toffset = *pos - vhca_buf->start_pos;\n\t\tpage_offset = offset % PAGE_SIZE;\n\t\toffset -= page_offset;\n\t\tpage = mlx5vf_get_migration_page(vhca_buf, offset);\n\t\tif (!page)\n\t\t\treturn -EINVAL;\n\t\tpage_len = min_t(size_t, copy_len, PAGE_SIZE - page_offset);\n\t\tfrom_buff = kmap_local_page(page);\n\t\tret = copy_to_user(*buf, from_buff + page_offset, page_len);\n\t\tkunmap_local(from_buff);\n\t\tif (ret)\n\t\t\treturn -EFAULT;\n\t\t*pos += page_len;\n\t\t*len -= page_len;\n\t\t*buf += page_len;\n\t\tdone += page_len;\n\t\tcopy_len -= page_len;\n\t}\n\n\tif (*pos >= vhca_buf->start_pos + vhca_buf->length) {\n\t\tspin_lock_irq(&vhca_buf->migf->list_lock);\n\t\tlist_del_init(&vhca_buf->buf_elm);\n\t\tlist_add_tail(&vhca_buf->buf_elm, &vhca_buf->migf->avail_list);\n\t\tspin_unlock_irq(&vhca_buf->migf->list_lock);\n\t}\n\n\treturn done;\n}\n\nstatic ssize_t mlx5vf_save_read(struct file *filp, char __user *buf, size_t len,\n\t\t\t       loff_t *pos)\n{\n\tstruct mlx5_vf_migration_file *migf = filp->private_data;\n\tstruct mlx5_vhca_data_buffer *vhca_buf;\n\tbool first_loop_call = true;\n\tbool end_of_data;\n\tssize_t done = 0;\n\n\tif (pos)\n\t\treturn -ESPIPE;\n\tpos = &filp->f_pos;\n\n\tif (!(filp->f_flags & O_NONBLOCK)) {\n\t\tif (wait_event_interruptible(migf->poll_wait,\n\t\t\t\t!list_empty(&migf->buf_list) ||\n\t\t\t\tmigf->state == MLX5_MIGF_STATE_ERROR ||\n\t\t\t\tmigf->state == MLX5_MIGF_STATE_PRE_COPY_ERROR ||\n\t\t\t\tmigf->state == MLX5_MIGF_STATE_PRE_COPY ||\n\t\t\t\tmigf->state == MLX5_MIGF_STATE_COMPLETE))\n\t\t\treturn -ERESTARTSYS;\n\t}\n\n\tmutex_lock(&migf->lock);\n\tif (migf->state == MLX5_MIGF_STATE_ERROR) {\n\t\tdone = -ENODEV;\n\t\tgoto out_unlock;\n\t}\n\n\twhile (len) {\n\t\tssize_t count;\n\n\t\tvhca_buf = mlx5vf_get_data_buff_from_pos(migf, *pos,\n\t\t\t\t\t\t\t &end_of_data);\n\t\tif (first_loop_call) {\n\t\t\tfirst_loop_call = false;\n\t\t\t \n\t\t\tif (end_of_data && (migf->state == MLX5_MIGF_STATE_PRE_COPY ||\n\t\t\t\tmigf->state == MLX5_MIGF_STATE_PRE_COPY_ERROR)) {\n\t\t\t\tdone = -ENOMSG;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\n\t\t\tif (end_of_data && migf->state != MLX5_MIGF_STATE_COMPLETE) {\n\t\t\t\tif (filp->f_flags & O_NONBLOCK) {\n\t\t\t\t\tdone = -EAGAIN;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (end_of_data)\n\t\t\tgoto out_unlock;\n\n\t\tif (!vhca_buf) {\n\t\t\tdone = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tcount = mlx5vf_buf_read(vhca_buf, &buf, &len, pos);\n\t\tif (count < 0) {\n\t\t\tdone = count;\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tdone += count;\n\t}\n\nout_unlock:\n\tmutex_unlock(&migf->lock);\n\treturn done;\n}\n\nstatic __poll_t mlx5vf_save_poll(struct file *filp,\n\t\t\t\t struct poll_table_struct *wait)\n{\n\tstruct mlx5_vf_migration_file *migf = filp->private_data;\n\t__poll_t pollflags = 0;\n\n\tpoll_wait(filp, &migf->poll_wait, wait);\n\n\tmutex_lock(&migf->lock);\n\tif (migf->state == MLX5_MIGF_STATE_ERROR)\n\t\tpollflags = EPOLLIN | EPOLLRDNORM | EPOLLRDHUP;\n\telse if (!list_empty(&migf->buf_list) ||\n\t\t migf->state == MLX5_MIGF_STATE_COMPLETE)\n\t\tpollflags = EPOLLIN | EPOLLRDNORM;\n\tmutex_unlock(&migf->lock);\n\n\treturn pollflags;\n}\n\n \nstatic void mlx5vf_mark_err(struct mlx5_vf_migration_file *migf)\n{\n\tmigf->state = MLX5_MIGF_STATE_ERROR;\n\twake_up_interruptible(&migf->poll_wait);\n}\n\nstatic int mlx5vf_add_stop_copy_header(struct mlx5_vf_migration_file *migf)\n{\n\tsize_t size = sizeof(struct mlx5_vf_migration_header) +\n\t\tsizeof(struct mlx5_vf_migration_tag_stop_copy_data);\n\tstruct mlx5_vf_migration_tag_stop_copy_data data = {};\n\tstruct mlx5_vhca_data_buffer *header_buf = NULL;\n\tstruct mlx5_vf_migration_header header = {};\n\tunsigned long flags;\n\tstruct page *page;\n\tu8 *to_buff;\n\tint ret;\n\n\theader_buf = mlx5vf_get_data_buffer(migf, size, DMA_NONE);\n\tif (IS_ERR(header_buf))\n\t\treturn PTR_ERR(header_buf);\n\n\theader.record_size = cpu_to_le64(sizeof(data));\n\theader.flags = cpu_to_le32(MLX5_MIGF_HEADER_FLAGS_TAG_OPTIONAL);\n\theader.tag = cpu_to_le32(MLX5_MIGF_HEADER_TAG_STOP_COPY_SIZE);\n\tpage = mlx5vf_get_migration_page(header_buf, 0);\n\tif (!page) {\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\tto_buff = kmap_local_page(page);\n\tmemcpy(to_buff, &header, sizeof(header));\n\theader_buf->length = sizeof(header);\n\tdata.stop_copy_size = cpu_to_le64(migf->buf->allocated_length);\n\tmemcpy(to_buff + sizeof(header), &data, sizeof(data));\n\theader_buf->length += sizeof(data);\n\tkunmap_local(to_buff);\n\theader_buf->start_pos = header_buf->migf->max_pos;\n\tmigf->max_pos += header_buf->length;\n\tspin_lock_irqsave(&migf->list_lock, flags);\n\tlist_add_tail(&header_buf->buf_elm, &migf->buf_list);\n\tspin_unlock_irqrestore(&migf->list_lock, flags);\n\tmigf->pre_copy_initial_bytes = size;\n\treturn 0;\nerr:\n\tmlx5vf_put_data_buffer(header_buf);\n\treturn ret;\n}\n\nstatic int mlx5vf_prep_stop_copy(struct mlx5_vf_migration_file *migf,\n\t\t\t\t size_t state_size)\n{\n\tstruct mlx5_vhca_data_buffer *buf;\n\tsize_t inc_state_size;\n\tint ret;\n\n\t \n\tif (check_add_overflow(state_size, state_size / 10, &inc_state_size))\n\t\tinc_state_size = state_size;\n\n\tbuf = mlx5vf_get_data_buffer(migf, inc_state_size, DMA_FROM_DEVICE);\n\tif (IS_ERR(buf))\n\t\treturn PTR_ERR(buf);\n\n\tmigf->buf = buf;\n\tbuf = mlx5vf_get_data_buffer(migf,\n\t\t\tsizeof(struct mlx5_vf_migration_header), DMA_NONE);\n\tif (IS_ERR(buf)) {\n\t\tret = PTR_ERR(buf);\n\t\tgoto err;\n\t}\n\n\tmigf->buf_header = buf;\n\tret = mlx5vf_add_stop_copy_header(migf);\n\tif (ret)\n\t\tgoto err_header;\n\treturn 0;\n\nerr_header:\n\tmlx5vf_put_data_buffer(migf->buf_header);\n\tmigf->buf_header = NULL;\nerr:\n\tmlx5vf_put_data_buffer(migf->buf);\n\tmigf->buf = NULL;\n\treturn ret;\n}\n\nstatic long mlx5vf_precopy_ioctl(struct file *filp, unsigned int cmd,\n\t\t\t\t unsigned long arg)\n{\n\tstruct mlx5_vf_migration_file *migf = filp->private_data;\n\tstruct mlx5vf_pci_core_device *mvdev = migf->mvdev;\n\tstruct mlx5_vhca_data_buffer *buf;\n\tstruct vfio_precopy_info info = {};\n\tloff_t *pos = &filp->f_pos;\n\tunsigned long minsz;\n\tsize_t inc_length = 0;\n\tbool end_of_data = false;\n\tint ret;\n\n\tif (cmd != VFIO_MIG_GET_PRECOPY_INFO)\n\t\treturn -ENOTTY;\n\n\tminsz = offsetofend(struct vfio_precopy_info, dirty_bytes);\n\n\tif (copy_from_user(&info, (void __user *)arg, minsz))\n\t\treturn -EFAULT;\n\n\tif (info.argsz < minsz)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&mvdev->state_mutex);\n\tif (mvdev->mig_state != VFIO_DEVICE_STATE_PRE_COPY &&\n\t    mvdev->mig_state != VFIO_DEVICE_STATE_PRE_COPY_P2P) {\n\t\tret = -EINVAL;\n\t\tgoto err_state_unlock;\n\t}\n\n\t \n\tif (mvdev->mig_state == VFIO_DEVICE_STATE_PRE_COPY) {\n\t\t \n\t\tret = mlx5vf_cmd_query_vhca_migration_state(mvdev, &inc_length,\n\t\t\t\t\t\t\t    MLX5VF_QUERY_INC);\n\t\tif (ret)\n\t\t\tgoto err_state_unlock;\n\t}\n\n\tmutex_lock(&migf->lock);\n\tif (migf->state == MLX5_MIGF_STATE_ERROR) {\n\t\tret = -ENODEV;\n\t\tgoto err_migf_unlock;\n\t}\n\n\tif (migf->pre_copy_initial_bytes > *pos) {\n\t\tinfo.initial_bytes = migf->pre_copy_initial_bytes - *pos;\n\t} else {\n\t\tinfo.dirty_bytes = migf->max_pos - *pos;\n\t\tif (!info.dirty_bytes)\n\t\t\tend_of_data = true;\n\t\tinfo.dirty_bytes += inc_length;\n\t}\n\n\tif (!end_of_data || !inc_length) {\n\t\tmutex_unlock(&migf->lock);\n\t\tgoto done;\n\t}\n\n\tmutex_unlock(&migf->lock);\n\t \n\tbuf = mlx5vf_get_data_buffer(migf, inc_length, DMA_FROM_DEVICE);\n\tif (IS_ERR(buf)) {\n\t\tret = PTR_ERR(buf);\n\t\tmlx5vf_mark_err(migf);\n\t\tgoto err_state_unlock;\n\t}\n\n\tret = mlx5vf_cmd_save_vhca_state(mvdev, migf, buf, true, true);\n\tif (ret) {\n\t\tmlx5vf_mark_err(migf);\n\t\tmlx5vf_put_data_buffer(buf);\n\t\tgoto err_state_unlock;\n\t}\n\ndone:\n\tmlx5vf_state_mutex_unlock(mvdev);\n\tif (copy_to_user((void __user *)arg, &info, minsz))\n\t\treturn -EFAULT;\n\treturn 0;\n\nerr_migf_unlock:\n\tmutex_unlock(&migf->lock);\nerr_state_unlock:\n\tmlx5vf_state_mutex_unlock(mvdev);\n\treturn ret;\n}\n\nstatic const struct file_operations mlx5vf_save_fops = {\n\t.owner = THIS_MODULE,\n\t.read = mlx5vf_save_read,\n\t.poll = mlx5vf_save_poll,\n\t.unlocked_ioctl = mlx5vf_precopy_ioctl,\n\t.compat_ioctl = compat_ptr_ioctl,\n\t.release = mlx5vf_release_file,\n\t.llseek = no_llseek,\n};\n\nstatic int mlx5vf_pci_save_device_inc_data(struct mlx5vf_pci_core_device *mvdev)\n{\n\tstruct mlx5_vf_migration_file *migf = mvdev->saving_migf;\n\tstruct mlx5_vhca_data_buffer *buf;\n\tsize_t length;\n\tint ret;\n\n\tif (migf->state == MLX5_MIGF_STATE_ERROR)\n\t\treturn -ENODEV;\n\n\tret = mlx5vf_cmd_query_vhca_migration_state(mvdev, &length,\n\t\t\t\tMLX5VF_QUERY_INC | MLX5VF_QUERY_FINAL);\n\tif (ret)\n\t\tgoto err;\n\n\t \n\tif (migf->buf && migf->buf->allocated_length >= length) {\n\t\tbuf = migf->buf;\n\t\tmigf->buf = NULL;\n\t} else {\n\t\tbuf = mlx5vf_get_data_buffer(migf, length, DMA_FROM_DEVICE);\n\t\tif (IS_ERR(buf)) {\n\t\t\tret = PTR_ERR(buf);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tret = mlx5vf_cmd_save_vhca_state(mvdev, migf, buf, true, false);\n\tif (ret)\n\t\tgoto err_save;\n\n\treturn 0;\n\nerr_save:\n\tmlx5vf_put_data_buffer(buf);\nerr:\n\tmlx5vf_mark_err(migf);\n\treturn ret;\n}\n\nstatic struct mlx5_vf_migration_file *\nmlx5vf_pci_save_device_data(struct mlx5vf_pci_core_device *mvdev, bool track)\n{\n\tstruct mlx5_vf_migration_file *migf;\n\tstruct mlx5_vhca_data_buffer *buf;\n\tsize_t length;\n\tint ret;\n\n\tmigf = kzalloc(sizeof(*migf), GFP_KERNEL_ACCOUNT);\n\tif (!migf)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmigf->filp = anon_inode_getfile(\"mlx5vf_mig\", &mlx5vf_save_fops, migf,\n\t\t\t\t\tO_RDONLY);\n\tif (IS_ERR(migf->filp)) {\n\t\tret = PTR_ERR(migf->filp);\n\t\tgoto end;\n\t}\n\n\tmigf->mvdev = mvdev;\n\tret = mlx5vf_cmd_alloc_pd(migf);\n\tif (ret)\n\t\tgoto out_free;\n\n\tstream_open(migf->filp->f_inode, migf->filp);\n\tmutex_init(&migf->lock);\n\tinit_waitqueue_head(&migf->poll_wait);\n\tinit_completion(&migf->save_comp);\n\t \n\tcomplete(&migf->save_comp);\n\tmlx5_cmd_init_async_ctx(mvdev->mdev, &migf->async_ctx);\n\tINIT_WORK(&migf->async_data.work, mlx5vf_mig_file_cleanup_cb);\n\tINIT_LIST_HEAD(&migf->buf_list);\n\tINIT_LIST_HEAD(&migf->avail_list);\n\tspin_lock_init(&migf->list_lock);\n\tret = mlx5vf_cmd_query_vhca_migration_state(mvdev, &length, 0);\n\tif (ret)\n\t\tgoto out_pd;\n\n\tif (track) {\n\t\tret = mlx5vf_prep_stop_copy(migf, length);\n\t\tif (ret)\n\t\t\tgoto out_pd;\n\t}\n\n\tbuf = mlx5vf_alloc_data_buffer(migf, length, DMA_FROM_DEVICE);\n\tif (IS_ERR(buf)) {\n\t\tret = PTR_ERR(buf);\n\t\tgoto out_pd;\n\t}\n\n\tret = mlx5vf_cmd_save_vhca_state(mvdev, migf, buf, false, track);\n\tif (ret)\n\t\tgoto out_save;\n\treturn migf;\nout_save:\n\tmlx5vf_free_data_buffer(buf);\nout_pd:\n\tmlx5fv_cmd_clean_migf_resources(migf);\nout_free:\n\tfput(migf->filp);\nend:\n\tkfree(migf);\n\treturn ERR_PTR(ret);\n}\n\nstatic int\nmlx5vf_append_page_to_mig_buf(struct mlx5_vhca_data_buffer *vhca_buf,\n\t\t\t      const char __user **buf, size_t *len,\n\t\t\t      loff_t *pos, ssize_t *done)\n{\n\tunsigned long offset;\n\tsize_t page_offset;\n\tstruct page *page;\n\tsize_t page_len;\n\tu8 *to_buff;\n\tint ret;\n\n\toffset = *pos - vhca_buf->start_pos;\n\tpage_offset = offset % PAGE_SIZE;\n\n\tpage = mlx5vf_get_migration_page(vhca_buf, offset - page_offset);\n\tif (!page)\n\t\treturn -EINVAL;\n\tpage_len = min_t(size_t, *len, PAGE_SIZE - page_offset);\n\tto_buff = kmap_local_page(page);\n\tret = copy_from_user(to_buff + page_offset, *buf, page_len);\n\tkunmap_local(to_buff);\n\tif (ret)\n\t\treturn -EFAULT;\n\n\t*pos += page_len;\n\t*done += page_len;\n\t*buf += page_len;\n\t*len -= page_len;\n\tvhca_buf->length += page_len;\n\treturn 0;\n}\n\nstatic int\nmlx5vf_resume_read_image_no_header(struct mlx5_vhca_data_buffer *vhca_buf,\n\t\t\t\t   loff_t requested_length,\n\t\t\t\t   const char __user **buf, size_t *len,\n\t\t\t\t   loff_t *pos, ssize_t *done)\n{\n\tint ret;\n\n\tif (requested_length > MAX_LOAD_SIZE)\n\t\treturn -ENOMEM;\n\n\tif (vhca_buf->allocated_length < requested_length) {\n\t\tret = mlx5vf_add_migration_pages(\n\t\t\tvhca_buf,\n\t\t\tDIV_ROUND_UP(requested_length - vhca_buf->allocated_length,\n\t\t\t\t     PAGE_SIZE));\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\twhile (*len) {\n\t\tret = mlx5vf_append_page_to_mig_buf(vhca_buf, buf, len, pos,\n\t\t\t\t\t\t    done);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic ssize_t\nmlx5vf_resume_read_image(struct mlx5_vf_migration_file *migf,\n\t\t\t struct mlx5_vhca_data_buffer *vhca_buf,\n\t\t\t size_t image_size, const char __user **buf,\n\t\t\t size_t *len, loff_t *pos, ssize_t *done,\n\t\t\t bool *has_work)\n{\n\tsize_t copy_len, to_copy;\n\tint ret;\n\n\tto_copy = min_t(size_t, *len, image_size - vhca_buf->length);\n\tcopy_len = to_copy;\n\twhile (to_copy) {\n\t\tret = mlx5vf_append_page_to_mig_buf(vhca_buf, buf, &to_copy, pos,\n\t\t\t\t\t\t    done);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t*len -= copy_len;\n\tif (vhca_buf->length == image_size) {\n\t\tmigf->load_state = MLX5_VF_LOAD_STATE_LOAD_IMAGE;\n\t\tmigf->max_pos += image_size;\n\t\t*has_work = true;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nmlx5vf_resume_read_header_data(struct mlx5_vf_migration_file *migf,\n\t\t\t       struct mlx5_vhca_data_buffer *vhca_buf,\n\t\t\t       const char __user **buf, size_t *len,\n\t\t\t       loff_t *pos, ssize_t *done)\n{\n\tsize_t copy_len, to_copy;\n\tsize_t required_data;\n\tu8 *to_buff;\n\tint ret;\n\n\trequired_data = migf->record_size - vhca_buf->length;\n\tto_copy = min_t(size_t, *len, required_data);\n\tcopy_len = to_copy;\n\twhile (to_copy) {\n\t\tret = mlx5vf_append_page_to_mig_buf(vhca_buf, buf, &to_copy, pos,\n\t\t\t\t\t\t    done);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t*len -= copy_len;\n\tif (vhca_buf->length == migf->record_size) {\n\t\tswitch (migf->record_tag) {\n\t\tcase MLX5_MIGF_HEADER_TAG_STOP_COPY_SIZE:\n\t\t{\n\t\t\tstruct page *page;\n\n\t\t\tpage = mlx5vf_get_migration_page(vhca_buf, 0);\n\t\t\tif (!page)\n\t\t\t\treturn -EINVAL;\n\t\t\tto_buff = kmap_local_page(page);\n\t\t\tmigf->stop_copy_prep_size = min_t(u64,\n\t\t\t\tle64_to_cpup((__le64 *)to_buff), MAX_LOAD_SIZE);\n\t\t\tkunmap_local(to_buff);\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\n\t\tmigf->load_state = MLX5_VF_LOAD_STATE_READ_HEADER;\n\t\tmigf->max_pos += migf->record_size;\n\t\tvhca_buf->length = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nmlx5vf_resume_read_header(struct mlx5_vf_migration_file *migf,\n\t\t\t  struct mlx5_vhca_data_buffer *vhca_buf,\n\t\t\t  const char __user **buf,\n\t\t\t  size_t *len, loff_t *pos,\n\t\t\t  ssize_t *done, bool *has_work)\n{\n\tstruct page *page;\n\tsize_t copy_len;\n\tu8 *to_buff;\n\tint ret;\n\n\tcopy_len = min_t(size_t, *len,\n\t\tsizeof(struct mlx5_vf_migration_header) - vhca_buf->length);\n\tpage = mlx5vf_get_migration_page(vhca_buf, 0);\n\tif (!page)\n\t\treturn -EINVAL;\n\tto_buff = kmap_local_page(page);\n\tret = copy_from_user(to_buff + vhca_buf->length, *buf, copy_len);\n\tif (ret) {\n\t\tret = -EFAULT;\n\t\tgoto end;\n\t}\n\n\t*buf += copy_len;\n\t*pos += copy_len;\n\t*done += copy_len;\n\t*len -= copy_len;\n\tvhca_buf->length += copy_len;\n\tif (vhca_buf->length == sizeof(struct mlx5_vf_migration_header)) {\n\t\tu64 record_size;\n\t\tu32 flags;\n\n\t\trecord_size = le64_to_cpup((__le64 *)to_buff);\n\t\tif (record_size > MAX_LOAD_SIZE) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto end;\n\t\t}\n\n\t\tmigf->record_size = record_size;\n\t\tflags = le32_to_cpup((__le32 *)(to_buff +\n\t\t\t    offsetof(struct mlx5_vf_migration_header, flags)));\n\t\tmigf->record_tag = le32_to_cpup((__le32 *)(to_buff +\n\t\t\t    offsetof(struct mlx5_vf_migration_header, tag)));\n\t\tswitch (migf->record_tag) {\n\t\tcase MLX5_MIGF_HEADER_TAG_FW_DATA:\n\t\t\tmigf->load_state = MLX5_VF_LOAD_STATE_PREP_IMAGE;\n\t\t\tbreak;\n\t\tcase MLX5_MIGF_HEADER_TAG_STOP_COPY_SIZE:\n\t\t\tmigf->load_state = MLX5_VF_LOAD_STATE_PREP_HEADER_DATA;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (!(flags & MLX5_MIGF_HEADER_FLAGS_TAG_OPTIONAL)) {\n\t\t\t\tret = -EOPNOTSUPP;\n\t\t\t\tgoto end;\n\t\t\t}\n\t\t\t \n\t\t\tmigf->load_state = MLX5_VF_LOAD_STATE_PREP_HEADER_DATA;\n\t\t}\n\n\t\tmigf->max_pos += vhca_buf->length;\n\t\tvhca_buf->length = 0;\n\t\t*has_work = true;\n\t}\nend:\n\tkunmap_local(to_buff);\n\treturn ret;\n}\n\nstatic ssize_t mlx5vf_resume_write(struct file *filp, const char __user *buf,\n\t\t\t\t   size_t len, loff_t *pos)\n{\n\tstruct mlx5_vf_migration_file *migf = filp->private_data;\n\tstruct mlx5_vhca_data_buffer *vhca_buf = migf->buf;\n\tstruct mlx5_vhca_data_buffer *vhca_buf_header = migf->buf_header;\n\tloff_t requested_length;\n\tbool has_work = false;\n\tssize_t done = 0;\n\tint ret = 0;\n\n\tif (pos)\n\t\treturn -ESPIPE;\n\tpos = &filp->f_pos;\n\n\tif (*pos < 0 ||\n\t    check_add_overflow((loff_t)len, *pos, &requested_length))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&migf->mvdev->state_mutex);\n\tmutex_lock(&migf->lock);\n\tif (migf->state == MLX5_MIGF_STATE_ERROR) {\n\t\tret = -ENODEV;\n\t\tgoto out_unlock;\n\t}\n\n\twhile (len || has_work) {\n\t\thas_work = false;\n\t\tswitch (migf->load_state) {\n\t\tcase MLX5_VF_LOAD_STATE_READ_HEADER:\n\t\t\tret = mlx5vf_resume_read_header(migf, vhca_buf_header,\n\t\t\t\t\t\t\t&buf, &len, pos,\n\t\t\t\t\t\t\t&done, &has_work);\n\t\t\tif (ret)\n\t\t\t\tgoto out_unlock;\n\t\t\tbreak;\n\t\tcase MLX5_VF_LOAD_STATE_PREP_HEADER_DATA:\n\t\t\tif (vhca_buf_header->allocated_length < migf->record_size) {\n\t\t\t\tmlx5vf_free_data_buffer(vhca_buf_header);\n\n\t\t\t\tmigf->buf_header = mlx5vf_alloc_data_buffer(migf,\n\t\t\t\t\t\tmigf->record_size, DMA_NONE);\n\t\t\t\tif (IS_ERR(migf->buf_header)) {\n\t\t\t\t\tret = PTR_ERR(migf->buf_header);\n\t\t\t\t\tmigf->buf_header = NULL;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\n\t\t\t\tvhca_buf_header = migf->buf_header;\n\t\t\t}\n\n\t\t\tvhca_buf_header->start_pos = migf->max_pos;\n\t\t\tmigf->load_state = MLX5_VF_LOAD_STATE_READ_HEADER_DATA;\n\t\t\tbreak;\n\t\tcase MLX5_VF_LOAD_STATE_READ_HEADER_DATA:\n\t\t\tret = mlx5vf_resume_read_header_data(migf, vhca_buf_header,\n\t\t\t\t\t\t\t&buf, &len, pos, &done);\n\t\t\tif (ret)\n\t\t\t\tgoto out_unlock;\n\t\t\tbreak;\n\t\tcase MLX5_VF_LOAD_STATE_PREP_IMAGE:\n\t\t{\n\t\t\tu64 size = max(migf->record_size,\n\t\t\t\t       migf->stop_copy_prep_size);\n\n\t\t\tif (vhca_buf->allocated_length < size) {\n\t\t\t\tmlx5vf_free_data_buffer(vhca_buf);\n\n\t\t\t\tmigf->buf = mlx5vf_alloc_data_buffer(migf,\n\t\t\t\t\t\t\tsize, DMA_TO_DEVICE);\n\t\t\t\tif (IS_ERR(migf->buf)) {\n\t\t\t\t\tret = PTR_ERR(migf->buf);\n\t\t\t\t\tmigf->buf = NULL;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\n\t\t\t\tvhca_buf = migf->buf;\n\t\t\t}\n\n\t\t\tvhca_buf->start_pos = migf->max_pos;\n\t\t\tmigf->load_state = MLX5_VF_LOAD_STATE_READ_IMAGE;\n\t\t\tbreak;\n\t\t}\n\t\tcase MLX5_VF_LOAD_STATE_READ_IMAGE_NO_HEADER:\n\t\t\tret = mlx5vf_resume_read_image_no_header(vhca_buf,\n\t\t\t\t\t\trequested_length,\n\t\t\t\t\t\t&buf, &len, pos, &done);\n\t\t\tif (ret)\n\t\t\t\tgoto out_unlock;\n\t\t\tbreak;\n\t\tcase MLX5_VF_LOAD_STATE_READ_IMAGE:\n\t\t\tret = mlx5vf_resume_read_image(migf, vhca_buf,\n\t\t\t\t\t\tmigf->record_size,\n\t\t\t\t\t\t&buf, &len, pos, &done, &has_work);\n\t\t\tif (ret)\n\t\t\t\tgoto out_unlock;\n\t\t\tbreak;\n\t\tcase MLX5_VF_LOAD_STATE_LOAD_IMAGE:\n\t\t\tret = mlx5vf_cmd_load_vhca_state(migf->mvdev, migf, vhca_buf);\n\t\t\tif (ret)\n\t\t\t\tgoto out_unlock;\n\t\t\tmigf->load_state = MLX5_VF_LOAD_STATE_READ_HEADER;\n\n\t\t\t \n\t\t\tvhca_buf_header->length = 0;\n\t\t\t \n\t\t\tvhca_buf->length = 0;\n\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\nout_unlock:\n\tif (ret)\n\t\tmigf->state = MLX5_MIGF_STATE_ERROR;\n\tmutex_unlock(&migf->lock);\n\tmlx5vf_state_mutex_unlock(migf->mvdev);\n\treturn ret ? ret : done;\n}\n\nstatic const struct file_operations mlx5vf_resume_fops = {\n\t.owner = THIS_MODULE,\n\t.write = mlx5vf_resume_write,\n\t.release = mlx5vf_release_file,\n\t.llseek = no_llseek,\n};\n\nstatic struct mlx5_vf_migration_file *\nmlx5vf_pci_resume_device_data(struct mlx5vf_pci_core_device *mvdev)\n{\n\tstruct mlx5_vf_migration_file *migf;\n\tstruct mlx5_vhca_data_buffer *buf;\n\tint ret;\n\n\tmigf = kzalloc(sizeof(*migf), GFP_KERNEL_ACCOUNT);\n\tif (!migf)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmigf->filp = anon_inode_getfile(\"mlx5vf_mig\", &mlx5vf_resume_fops, migf,\n\t\t\t\t\tO_WRONLY);\n\tif (IS_ERR(migf->filp)) {\n\t\tret = PTR_ERR(migf->filp);\n\t\tgoto end;\n\t}\n\n\tmigf->mvdev = mvdev;\n\tret = mlx5vf_cmd_alloc_pd(migf);\n\tif (ret)\n\t\tgoto out_free;\n\n\tbuf = mlx5vf_alloc_data_buffer(migf, 0, DMA_TO_DEVICE);\n\tif (IS_ERR(buf)) {\n\t\tret = PTR_ERR(buf);\n\t\tgoto out_pd;\n\t}\n\n\tmigf->buf = buf;\n\tif (MLX5VF_PRE_COPY_SUPP(mvdev)) {\n\t\tbuf = mlx5vf_alloc_data_buffer(migf,\n\t\t\tsizeof(struct mlx5_vf_migration_header), DMA_NONE);\n\t\tif (IS_ERR(buf)) {\n\t\t\tret = PTR_ERR(buf);\n\t\t\tgoto out_buf;\n\t\t}\n\n\t\tmigf->buf_header = buf;\n\t\tmigf->load_state = MLX5_VF_LOAD_STATE_READ_HEADER;\n\t} else {\n\t\t \n\t\tmigf->load_state = MLX5_VF_LOAD_STATE_READ_IMAGE_NO_HEADER;\n\t}\n\n\tstream_open(migf->filp->f_inode, migf->filp);\n\tmutex_init(&migf->lock);\n\tINIT_LIST_HEAD(&migf->buf_list);\n\tINIT_LIST_HEAD(&migf->avail_list);\n\tspin_lock_init(&migf->list_lock);\n\treturn migf;\nout_buf:\n\tmlx5vf_free_data_buffer(migf->buf);\nout_pd:\n\tmlx5vf_cmd_dealloc_pd(migf);\nout_free:\n\tfput(migf->filp);\nend:\n\tkfree(migf);\n\treturn ERR_PTR(ret);\n}\n\nvoid mlx5vf_disable_fds(struct mlx5vf_pci_core_device *mvdev)\n{\n\tif (mvdev->resuming_migf) {\n\t\tmlx5vf_disable_fd(mvdev->resuming_migf);\n\t\tmlx5fv_cmd_clean_migf_resources(mvdev->resuming_migf);\n\t\tfput(mvdev->resuming_migf->filp);\n\t\tmvdev->resuming_migf = NULL;\n\t}\n\tif (mvdev->saving_migf) {\n\t\tmlx5_cmd_cleanup_async_ctx(&mvdev->saving_migf->async_ctx);\n\t\tcancel_work_sync(&mvdev->saving_migf->async_data.work);\n\t\tmlx5vf_disable_fd(mvdev->saving_migf);\n\t\tmlx5fv_cmd_clean_migf_resources(mvdev->saving_migf);\n\t\tfput(mvdev->saving_migf->filp);\n\t\tmvdev->saving_migf = NULL;\n\t}\n}\n\nstatic struct file *\nmlx5vf_pci_step_device_state_locked(struct mlx5vf_pci_core_device *mvdev,\n\t\t\t\t    u32 new)\n{\n\tu32 cur = mvdev->mig_state;\n\tint ret;\n\n\tif (cur == VFIO_DEVICE_STATE_RUNNING_P2P && new == VFIO_DEVICE_STATE_STOP) {\n\t\tret = mlx5vf_cmd_suspend_vhca(mvdev,\n\t\t\tMLX5_SUSPEND_VHCA_IN_OP_MOD_SUSPEND_RESPONDER);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\t\treturn NULL;\n\t}\n\n\tif (cur == VFIO_DEVICE_STATE_STOP && new == VFIO_DEVICE_STATE_RUNNING_P2P) {\n\t\tret = mlx5vf_cmd_resume_vhca(mvdev,\n\t\t\tMLX5_RESUME_VHCA_IN_OP_MOD_RESUME_RESPONDER);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\t\treturn NULL;\n\t}\n\n\tif ((cur == VFIO_DEVICE_STATE_RUNNING && new == VFIO_DEVICE_STATE_RUNNING_P2P) ||\n\t    (cur == VFIO_DEVICE_STATE_PRE_COPY && new == VFIO_DEVICE_STATE_PRE_COPY_P2P)) {\n\t\tret = mlx5vf_cmd_suspend_vhca(mvdev,\n\t\t\tMLX5_SUSPEND_VHCA_IN_OP_MOD_SUSPEND_INITIATOR);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\t\treturn NULL;\n\t}\n\n\tif ((cur == VFIO_DEVICE_STATE_RUNNING_P2P && new == VFIO_DEVICE_STATE_RUNNING) ||\n\t    (cur == VFIO_DEVICE_STATE_PRE_COPY_P2P && new == VFIO_DEVICE_STATE_PRE_COPY)) {\n\t\tret = mlx5vf_cmd_resume_vhca(mvdev,\n\t\t\tMLX5_RESUME_VHCA_IN_OP_MOD_RESUME_INITIATOR);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\t\treturn NULL;\n\t}\n\n\tif (cur == VFIO_DEVICE_STATE_STOP && new == VFIO_DEVICE_STATE_STOP_COPY) {\n\t\tstruct mlx5_vf_migration_file *migf;\n\n\t\tmigf = mlx5vf_pci_save_device_data(mvdev, false);\n\t\tif (IS_ERR(migf))\n\t\t\treturn ERR_CAST(migf);\n\t\tget_file(migf->filp);\n\t\tmvdev->saving_migf = migf;\n\t\treturn migf->filp;\n\t}\n\n\tif ((cur == VFIO_DEVICE_STATE_STOP_COPY && new == VFIO_DEVICE_STATE_STOP) ||\n\t    (cur == VFIO_DEVICE_STATE_PRE_COPY && new == VFIO_DEVICE_STATE_RUNNING) ||\n\t    (cur == VFIO_DEVICE_STATE_PRE_COPY_P2P &&\n\t     new == VFIO_DEVICE_STATE_RUNNING_P2P)) {\n\t\tmlx5vf_disable_fds(mvdev);\n\t\treturn NULL;\n\t}\n\n\tif (cur == VFIO_DEVICE_STATE_STOP && new == VFIO_DEVICE_STATE_RESUMING) {\n\t\tstruct mlx5_vf_migration_file *migf;\n\n\t\tmigf = mlx5vf_pci_resume_device_data(mvdev);\n\t\tif (IS_ERR(migf))\n\t\t\treturn ERR_CAST(migf);\n\t\tget_file(migf->filp);\n\t\tmvdev->resuming_migf = migf;\n\t\treturn migf->filp;\n\t}\n\n\tif (cur == VFIO_DEVICE_STATE_RESUMING && new == VFIO_DEVICE_STATE_STOP) {\n\t\tif (!MLX5VF_PRE_COPY_SUPP(mvdev)) {\n\t\t\tret = mlx5vf_cmd_load_vhca_state(mvdev,\n\t\t\t\t\t\t\t mvdev->resuming_migf,\n\t\t\t\t\t\t\t mvdev->resuming_migf->buf);\n\t\t\tif (ret)\n\t\t\t\treturn ERR_PTR(ret);\n\t\t}\n\t\tmlx5vf_disable_fds(mvdev);\n\t\treturn NULL;\n\t}\n\n\tif ((cur == VFIO_DEVICE_STATE_RUNNING && new == VFIO_DEVICE_STATE_PRE_COPY) ||\n\t    (cur == VFIO_DEVICE_STATE_RUNNING_P2P &&\n\t     new == VFIO_DEVICE_STATE_PRE_COPY_P2P)) {\n\t\tstruct mlx5_vf_migration_file *migf;\n\n\t\tmigf = mlx5vf_pci_save_device_data(mvdev, true);\n\t\tif (IS_ERR(migf))\n\t\t\treturn ERR_CAST(migf);\n\t\tget_file(migf->filp);\n\t\tmvdev->saving_migf = migf;\n\t\treturn migf->filp;\n\t}\n\n\tif (cur == VFIO_DEVICE_STATE_PRE_COPY_P2P && new == VFIO_DEVICE_STATE_STOP_COPY) {\n\t\tret = mlx5vf_cmd_suspend_vhca(mvdev,\n\t\t\tMLX5_SUSPEND_VHCA_IN_OP_MOD_SUSPEND_RESPONDER);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\t\tret = mlx5vf_pci_save_device_inc_data(mvdev);\n\t\treturn ret ? ERR_PTR(ret) : NULL;\n\t}\n\n\t \n\tWARN_ON(true);\n\treturn ERR_PTR(-EINVAL);\n}\n\n \nvoid mlx5vf_state_mutex_unlock(struct mlx5vf_pci_core_device *mvdev)\n{\nagain:\n\tspin_lock(&mvdev->reset_lock);\n\tif (mvdev->deferred_reset) {\n\t\tmvdev->deferred_reset = false;\n\t\tspin_unlock(&mvdev->reset_lock);\n\t\tmvdev->mig_state = VFIO_DEVICE_STATE_RUNNING;\n\t\tmlx5vf_disable_fds(mvdev);\n\t\tgoto again;\n\t}\n\tmutex_unlock(&mvdev->state_mutex);\n\tspin_unlock(&mvdev->reset_lock);\n}\n\nstatic struct file *\nmlx5vf_pci_set_device_state(struct vfio_device *vdev,\n\t\t\t    enum vfio_device_mig_state new_state)\n{\n\tstruct mlx5vf_pci_core_device *mvdev = container_of(\n\t\tvdev, struct mlx5vf_pci_core_device, core_device.vdev);\n\tenum vfio_device_mig_state next_state;\n\tstruct file *res = NULL;\n\tint ret;\n\n\tmutex_lock(&mvdev->state_mutex);\n\twhile (new_state != mvdev->mig_state) {\n\t\tret = vfio_mig_get_next_state(vdev, mvdev->mig_state,\n\t\t\t\t\t      new_state, &next_state);\n\t\tif (ret) {\n\t\t\tres = ERR_PTR(ret);\n\t\t\tbreak;\n\t\t}\n\t\tres = mlx5vf_pci_step_device_state_locked(mvdev, next_state);\n\t\tif (IS_ERR(res))\n\t\t\tbreak;\n\t\tmvdev->mig_state = next_state;\n\t\tif (WARN_ON(res && new_state != mvdev->mig_state)) {\n\t\t\tfput(res);\n\t\t\tres = ERR_PTR(-EINVAL);\n\t\t\tbreak;\n\t\t}\n\t}\n\tmlx5vf_state_mutex_unlock(mvdev);\n\treturn res;\n}\n\nstatic int mlx5vf_pci_get_data_size(struct vfio_device *vdev,\n\t\t\t\t    unsigned long *stop_copy_length)\n{\n\tstruct mlx5vf_pci_core_device *mvdev = container_of(\n\t\tvdev, struct mlx5vf_pci_core_device, core_device.vdev);\n\tsize_t state_size;\n\tint ret;\n\n\tmutex_lock(&mvdev->state_mutex);\n\tret = mlx5vf_cmd_query_vhca_migration_state(mvdev,\n\t\t\t\t\t\t    &state_size, 0);\n\tif (!ret)\n\t\t*stop_copy_length = state_size;\n\tmlx5vf_state_mutex_unlock(mvdev);\n\treturn ret;\n}\n\nstatic int mlx5vf_pci_get_device_state(struct vfio_device *vdev,\n\t\t\t\t       enum vfio_device_mig_state *curr_state)\n{\n\tstruct mlx5vf_pci_core_device *mvdev = container_of(\n\t\tvdev, struct mlx5vf_pci_core_device, core_device.vdev);\n\n\tmutex_lock(&mvdev->state_mutex);\n\t*curr_state = mvdev->mig_state;\n\tmlx5vf_state_mutex_unlock(mvdev);\n\treturn 0;\n}\n\nstatic void mlx5vf_pci_aer_reset_done(struct pci_dev *pdev)\n{\n\tstruct mlx5vf_pci_core_device *mvdev = mlx5vf_drvdata(pdev);\n\n\tif (!mvdev->migrate_cap)\n\t\treturn;\n\n\t \n\tspin_lock(&mvdev->reset_lock);\n\tmvdev->deferred_reset = true;\n\tif (!mutex_trylock(&mvdev->state_mutex)) {\n\t\tspin_unlock(&mvdev->reset_lock);\n\t\treturn;\n\t}\n\tspin_unlock(&mvdev->reset_lock);\n\tmlx5vf_state_mutex_unlock(mvdev);\n}\n\nstatic int mlx5vf_pci_open_device(struct vfio_device *core_vdev)\n{\n\tstruct mlx5vf_pci_core_device *mvdev = container_of(\n\t\tcore_vdev, struct mlx5vf_pci_core_device, core_device.vdev);\n\tstruct vfio_pci_core_device *vdev = &mvdev->core_device;\n\tint ret;\n\n\tret = vfio_pci_core_enable(vdev);\n\tif (ret)\n\t\treturn ret;\n\n\tif (mvdev->migrate_cap)\n\t\tmvdev->mig_state = VFIO_DEVICE_STATE_RUNNING;\n\tvfio_pci_core_finish_enable(vdev);\n\treturn 0;\n}\n\nstatic void mlx5vf_pci_close_device(struct vfio_device *core_vdev)\n{\n\tstruct mlx5vf_pci_core_device *mvdev = container_of(\n\t\tcore_vdev, struct mlx5vf_pci_core_device, core_device.vdev);\n\n\tmlx5vf_cmd_close_migratable(mvdev);\n\tvfio_pci_core_close_device(core_vdev);\n}\n\nstatic const struct vfio_migration_ops mlx5vf_pci_mig_ops = {\n\t.migration_set_state = mlx5vf_pci_set_device_state,\n\t.migration_get_state = mlx5vf_pci_get_device_state,\n\t.migration_get_data_size = mlx5vf_pci_get_data_size,\n};\n\nstatic const struct vfio_log_ops mlx5vf_pci_log_ops = {\n\t.log_start = mlx5vf_start_page_tracker,\n\t.log_stop = mlx5vf_stop_page_tracker,\n\t.log_read_and_clear = mlx5vf_tracker_read_and_clear,\n};\n\nstatic int mlx5vf_pci_init_dev(struct vfio_device *core_vdev)\n{\n\tstruct mlx5vf_pci_core_device *mvdev = container_of(core_vdev,\n\t\t\tstruct mlx5vf_pci_core_device, core_device.vdev);\n\tint ret;\n\n\tret = vfio_pci_core_init_dev(core_vdev);\n\tif (ret)\n\t\treturn ret;\n\n\tmlx5vf_cmd_set_migratable(mvdev, &mlx5vf_pci_mig_ops,\n\t\t\t\t  &mlx5vf_pci_log_ops);\n\n\treturn 0;\n}\n\nstatic void mlx5vf_pci_release_dev(struct vfio_device *core_vdev)\n{\n\tstruct mlx5vf_pci_core_device *mvdev = container_of(core_vdev,\n\t\t\tstruct mlx5vf_pci_core_device, core_device.vdev);\n\n\tmlx5vf_cmd_remove_migratable(mvdev);\n\tvfio_pci_core_release_dev(core_vdev);\n}\n\nstatic const struct vfio_device_ops mlx5vf_pci_ops = {\n\t.name = \"mlx5-vfio-pci\",\n\t.init = mlx5vf_pci_init_dev,\n\t.release = mlx5vf_pci_release_dev,\n\t.open_device = mlx5vf_pci_open_device,\n\t.close_device = mlx5vf_pci_close_device,\n\t.ioctl = vfio_pci_core_ioctl,\n\t.device_feature = vfio_pci_core_ioctl_feature,\n\t.read = vfio_pci_core_read,\n\t.write = vfio_pci_core_write,\n\t.mmap = vfio_pci_core_mmap,\n\t.request = vfio_pci_core_request,\n\t.match = vfio_pci_core_match,\n\t.bind_iommufd = vfio_iommufd_physical_bind,\n\t.unbind_iommufd = vfio_iommufd_physical_unbind,\n\t.attach_ioas = vfio_iommufd_physical_attach_ioas,\n\t.detach_ioas = vfio_iommufd_physical_detach_ioas,\n};\n\nstatic int mlx5vf_pci_probe(struct pci_dev *pdev,\n\t\t\t    const struct pci_device_id *id)\n{\n\tstruct mlx5vf_pci_core_device *mvdev;\n\tint ret;\n\n\tmvdev = vfio_alloc_device(mlx5vf_pci_core_device, core_device.vdev,\n\t\t\t\t  &pdev->dev, &mlx5vf_pci_ops);\n\tif (IS_ERR(mvdev))\n\t\treturn PTR_ERR(mvdev);\n\n\tdev_set_drvdata(&pdev->dev, &mvdev->core_device);\n\tret = vfio_pci_core_register_device(&mvdev->core_device);\n\tif (ret)\n\t\tgoto out_put_vdev;\n\treturn 0;\n\nout_put_vdev:\n\tvfio_put_device(&mvdev->core_device.vdev);\n\treturn ret;\n}\n\nstatic void mlx5vf_pci_remove(struct pci_dev *pdev)\n{\n\tstruct mlx5vf_pci_core_device *mvdev = mlx5vf_drvdata(pdev);\n\n\tvfio_pci_core_unregister_device(&mvdev->core_device);\n\tvfio_put_device(&mvdev->core_device.vdev);\n}\n\nstatic const struct pci_device_id mlx5vf_pci_table[] = {\n\t{ PCI_DRIVER_OVERRIDE_DEVICE_VFIO(PCI_VENDOR_ID_MELLANOX, 0x101e) },  \n\t{}\n};\n\nMODULE_DEVICE_TABLE(pci, mlx5vf_pci_table);\n\nstatic const struct pci_error_handlers mlx5vf_err_handlers = {\n\t.reset_done = mlx5vf_pci_aer_reset_done,\n\t.error_detected = vfio_pci_core_aer_err_detected,\n};\n\nstatic struct pci_driver mlx5vf_pci_driver = {\n\t.name = KBUILD_MODNAME,\n\t.id_table = mlx5vf_pci_table,\n\t.probe = mlx5vf_pci_probe,\n\t.remove = mlx5vf_pci_remove,\n\t.err_handler = &mlx5vf_err_handlers,\n\t.driver_managed_dma = true,\n};\n\nmodule_pci_driver(mlx5vf_pci_driver);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Max Gurtovoy <mgurtovoy@nvidia.com>\");\nMODULE_AUTHOR(\"Yishai Hadas <yishaih@nvidia.com>\");\nMODULE_DESCRIPTION(\n\t\"MLX5 VFIO PCI - User Level meta-driver for MLX5 device family\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}