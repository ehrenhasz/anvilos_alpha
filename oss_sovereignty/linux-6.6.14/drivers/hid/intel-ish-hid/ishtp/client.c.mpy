{
  "module_name": "client.c",
  "hash_id": "81b6f602f1a018d18324af54e55205ea9620ef95b0f8000fee2f275baffa63a0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/hid/intel-ish-hid/ishtp/client.c",
  "human_readable_source": "\n \n\n#include <linux/slab.h>\n#include <linux/sched.h>\n#include <linux/wait.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <asm/cacheflush.h>\n#include \"hbm.h\"\n#include \"client.h\"\n\nint ishtp_cl_get_tx_free_buffer_size(struct ishtp_cl *cl)\n{\n\tunsigned long tx_free_flags;\n\tint size;\n\n\tspin_lock_irqsave(&cl->tx_free_list_spinlock, tx_free_flags);\n\tsize = cl->tx_ring_free_size * cl->device->fw_client->props.max_msg_length;\n\tspin_unlock_irqrestore(&cl->tx_free_list_spinlock, tx_free_flags);\n\n\treturn size;\n}\nEXPORT_SYMBOL(ishtp_cl_get_tx_free_buffer_size);\n\nint ishtp_cl_get_tx_free_rings(struct ishtp_cl *cl)\n{\n\treturn cl->tx_ring_free_size;\n}\nEXPORT_SYMBOL(ishtp_cl_get_tx_free_rings);\n\n \nstatic void ishtp_read_list_flush(struct ishtp_cl *cl)\n{\n\tstruct ishtp_cl_rb *rb;\n\tstruct ishtp_cl_rb *next;\n\tunsigned long\tflags;\n\n\tspin_lock_irqsave(&cl->dev->read_list_spinlock, flags);\n\tlist_for_each_entry_safe(rb, next, &cl->dev->read_list.list, list)\n\t\tif (rb->cl && ishtp_cl_cmp_id(cl, rb->cl)) {\n\t\t\tlist_del(&rb->list);\n\t\t\tishtp_io_rb_free(rb);\n\t\t}\n\tspin_unlock_irqrestore(&cl->dev->read_list_spinlock, flags);\n}\n\n \nint ishtp_cl_flush_queues(struct ishtp_cl *cl)\n{\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -EINVAL;\n\n\tishtp_read_list_flush(cl);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ishtp_cl_flush_queues);\n\n \nstatic void ishtp_cl_init(struct ishtp_cl *cl, struct ishtp_device *dev)\n{\n\tmemset(cl, 0, sizeof(struct ishtp_cl));\n\tinit_waitqueue_head(&cl->wait_ctrl_res);\n\tspin_lock_init(&cl->free_list_spinlock);\n\tspin_lock_init(&cl->in_process_spinlock);\n\tspin_lock_init(&cl->tx_list_spinlock);\n\tspin_lock_init(&cl->tx_free_list_spinlock);\n\tspin_lock_init(&cl->fc_spinlock);\n\tINIT_LIST_HEAD(&cl->link);\n\tcl->dev = dev;\n\n\tINIT_LIST_HEAD(&cl->free_rb_list.list);\n\tINIT_LIST_HEAD(&cl->tx_list.list);\n\tINIT_LIST_HEAD(&cl->tx_free_list.list);\n\tINIT_LIST_HEAD(&cl->in_process_list.list);\n\n\tcl->rx_ring_size = CL_DEF_RX_RING_SIZE;\n\tcl->tx_ring_size = CL_DEF_TX_RING_SIZE;\n\tcl->tx_ring_free_size = cl->tx_ring_size;\n\n\t \n\tcl->last_tx_path = CL_TX_PATH_IPC;\n\tcl->last_dma_acked = 1;\n\tcl->last_dma_addr = NULL;\n\tcl->last_ipc_acked = 1;\n}\n\n \nstruct ishtp_cl *ishtp_cl_allocate(struct ishtp_cl_device *cl_device)\n{\n\tstruct ishtp_cl *cl;\n\n\tcl = kmalloc(sizeof(struct ishtp_cl), GFP_KERNEL);\n\tif (!cl)\n\t\treturn NULL;\n\n\tishtp_cl_init(cl, cl_device->ishtp_dev);\n\treturn cl;\n}\nEXPORT_SYMBOL(ishtp_cl_allocate);\n\n \nvoid\tishtp_cl_free(struct ishtp_cl *cl)\n{\n\tstruct ishtp_device *dev;\n\tunsigned long flags;\n\n\tif (!cl)\n\t\treturn;\n\n\tdev = cl->dev;\n\tif (!dev)\n\t\treturn;\n\n\tspin_lock_irqsave(&dev->cl_list_lock, flags);\n\tishtp_cl_free_rx_ring(cl);\n\tishtp_cl_free_tx_ring(cl);\n\tkfree(cl);\n\tspin_unlock_irqrestore(&dev->cl_list_lock, flags);\n}\nEXPORT_SYMBOL(ishtp_cl_free);\n\n \nint ishtp_cl_link(struct ishtp_cl *cl)\n{\n\tstruct ishtp_device *dev;\n\tunsigned long flags, flags_cl;\n\tint id, ret = 0;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -EINVAL;\n\n\tdev = cl->dev;\n\n\tspin_lock_irqsave(&dev->device_lock, flags);\n\n\tif (dev->open_handle_count >= ISHTP_MAX_OPEN_HANDLE_COUNT) {\n\t\tret = -EMFILE;\n\t\tgoto unlock_dev;\n\t}\n\n\tid = find_first_zero_bit(dev->host_clients_map, ISHTP_CLIENTS_MAX);\n\n\tif (id >= ISHTP_CLIENTS_MAX) {\n\t\tspin_unlock_irqrestore(&dev->device_lock, flags);\n\t\tdev_err(&cl->device->dev, \"id exceeded %d\", ISHTP_CLIENTS_MAX);\n\t\treturn -ENOENT;\n\t}\n\n\tdev->open_handle_count++;\n\tcl->host_client_id = id;\n\tspin_lock_irqsave(&dev->cl_list_lock, flags_cl);\n\tif (dev->dev_state != ISHTP_DEV_ENABLED) {\n\t\tret = -ENODEV;\n\t\tgoto unlock_cl;\n\t}\n\tlist_add_tail(&cl->link, &dev->cl_list);\n\tset_bit(id, dev->host_clients_map);\n\tcl->state = ISHTP_CL_INITIALIZING;\n\nunlock_cl:\n\tspin_unlock_irqrestore(&dev->cl_list_lock, flags_cl);\nunlock_dev:\n\tspin_unlock_irqrestore(&dev->device_lock, flags);\n\treturn ret;\n}\nEXPORT_SYMBOL(ishtp_cl_link);\n\n \nvoid ishtp_cl_unlink(struct ishtp_cl *cl)\n{\n\tstruct ishtp_device *dev;\n\tstruct ishtp_cl *pos;\n\tunsigned long\tflags;\n\n\t \n\tif (!cl || !cl->dev)\n\t\treturn;\n\n\tdev = cl->dev;\n\n\tspin_lock_irqsave(&dev->device_lock, flags);\n\tif (dev->open_handle_count > 0) {\n\t\tclear_bit(cl->host_client_id, dev->host_clients_map);\n\t\tdev->open_handle_count--;\n\t}\n\tspin_unlock_irqrestore(&dev->device_lock, flags);\n\n\t \n\tspin_lock_irqsave(&dev->cl_list_lock, flags);\n\tlist_for_each_entry(pos, &dev->cl_list, link)\n\t\tif (cl->host_client_id == pos->host_client_id) {\n\t\t\tlist_del_init(&pos->link);\n\t\t\tbreak;\n\t\t}\n\tspin_unlock_irqrestore(&dev->cl_list_lock, flags);\n}\nEXPORT_SYMBOL(ishtp_cl_unlink);\n\n \nint ishtp_cl_disconnect(struct ishtp_cl *cl)\n{\n\tstruct ishtp_device *dev;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tdev->print_log(dev, \"%s() state %d\\n\", __func__, cl->state);\n\n\tif (cl->state != ISHTP_CL_DISCONNECTING) {\n\t\tdev->print_log(dev, \"%s() Disconnect in progress\\n\", __func__);\n\t\treturn 0;\n\t}\n\n\tif (ishtp_hbm_cl_disconnect_req(dev, cl)) {\n\t\tdev->print_log(dev, \"%s() Failed to disconnect\\n\", __func__);\n\t\tdev_err(&cl->device->dev, \"failed to disconnect.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\twait_event_interruptible_timeout(cl->wait_ctrl_res,\n\t\t\t(dev->dev_state != ISHTP_DEV_ENABLED ||\n\t\t\tcl->state == ISHTP_CL_DISCONNECTED),\n\t\t\tishtp_secs_to_jiffies(ISHTP_CL_CONNECT_TIMEOUT));\n\n\t \n\tif (dev->dev_state != ISHTP_DEV_ENABLED) {\n\t\tdev->print_log(dev, \"%s() dev_state != ISHTP_DEV_ENABLED\\n\",\n\t\t\t       __func__);\n\t\treturn -ENODEV;\n\t}\n\n\tif (cl->state == ISHTP_CL_DISCONNECTED) {\n\t\tdev->print_log(dev, \"%s() successful\\n\", __func__);\n\t\treturn 0;\n\t}\n\n\treturn -ENODEV;\n}\nEXPORT_SYMBOL(ishtp_cl_disconnect);\n\n \nstatic bool ishtp_cl_is_other_connecting(struct ishtp_cl *cl)\n{\n\tstruct ishtp_device *dev;\n\tstruct ishtp_cl *pos;\n\tunsigned long\tflags;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn false;\n\n\tdev = cl->dev;\n\tspin_lock_irqsave(&dev->cl_list_lock, flags);\n\tlist_for_each_entry(pos, &dev->cl_list, link) {\n\t\tif ((pos->state == ISHTP_CL_CONNECTING) && (pos != cl) &&\n\t\t\t\tcl->fw_client_id == pos->fw_client_id) {\n\t\t\tspin_unlock_irqrestore(&dev->cl_list_lock, flags);\n\t\t\treturn true;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&dev->cl_list_lock, flags);\n\n\treturn false;\n}\n\n \nint ishtp_cl_connect(struct ishtp_cl *cl)\n{\n\tstruct ishtp_device *dev;\n\tint rets;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tdev->print_log(dev, \"%s() current_state = %d\\n\", __func__, cl->state);\n\n\tif (ishtp_cl_is_other_connecting(cl)) {\n\t\tdev->print_log(dev, \"%s() Busy\\n\", __func__);\n\t\treturn\t-EBUSY;\n\t}\n\n\tif (ishtp_hbm_cl_connect_req(dev, cl)) {\n\t\tdev->print_log(dev, \"%s() HBM connect req fail\\n\", __func__);\n\t\treturn -ENODEV;\n\t}\n\n\trets = wait_event_interruptible_timeout(cl->wait_ctrl_res,\n\t\t\t\t(dev->dev_state == ISHTP_DEV_ENABLED &&\n\t\t\t\t(cl->state == ISHTP_CL_CONNECTED ||\n\t\t\t\t cl->state == ISHTP_CL_DISCONNECTED)),\n\t\t\t\tishtp_secs_to_jiffies(\n\t\t\t\t\tISHTP_CL_CONNECT_TIMEOUT));\n\t \n\tif (dev->dev_state != ISHTP_DEV_ENABLED) {\n\t\tdev->print_log(dev, \"%s() dev_state != ISHTP_DEV_ENABLED\\n\",\n\t\t\t       __func__);\n\t\treturn -EFAULT;\n\t}\n\n\tif (cl->state != ISHTP_CL_CONNECTED) {\n\t\tdev->print_log(dev, \"%s() state != ISHTP_CL_CONNECTED\\n\",\n\t\t\t       __func__);\n\t\treturn -EFAULT;\n\t}\n\n\trets = cl->status;\n\tif (rets) {\n\t\tdev->print_log(dev, \"%s() Invalid status\\n\", __func__);\n\t\treturn rets;\n\t}\n\n\trets = ishtp_cl_device_bind(cl);\n\tif (rets) {\n\t\tdev->print_log(dev, \"%s() Bind error\\n\", __func__);\n\t\tishtp_cl_disconnect(cl);\n\t\treturn rets;\n\t}\n\n\trets = ishtp_cl_alloc_rx_ring(cl);\n\tif (rets) {\n\t\tdev->print_log(dev, \"%s() Alloc RX ring failed\\n\", __func__);\n\t\t \n\t\tishtp_cl_disconnect(cl);\n\t\treturn rets;\n\t}\n\n\trets = ishtp_cl_alloc_tx_ring(cl);\n\tif (rets) {\n\t\tdev->print_log(dev, \"%s() Alloc TX ring failed\\n\", __func__);\n\t\t \n\t\tishtp_cl_free_rx_ring(cl);\n\t\tishtp_cl_disconnect(cl);\n\t\treturn rets;\n\t}\n\n\t \n\trets = ishtp_cl_read_start(cl);\n\n\tdev->print_log(dev, \"%s() successful\\n\", __func__);\n\n\treturn rets;\n}\nEXPORT_SYMBOL(ishtp_cl_connect);\n\n \nint ishtp_cl_read_start(struct ishtp_cl *cl)\n{\n\tstruct ishtp_device *dev;\n\tstruct ishtp_cl_rb *rb;\n\tint rets;\n\tint i;\n\tunsigned long\tflags;\n\tunsigned long\tdev_flags;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tif (cl->state != ISHTP_CL_CONNECTED)\n\t\treturn -ENODEV;\n\n\tif (dev->dev_state != ISHTP_DEV_ENABLED)\n\t\treturn -ENODEV;\n\n\ti = ishtp_fw_cl_by_id(dev, cl->fw_client_id);\n\tif (i < 0) {\n\t\tdev_err(&cl->device->dev, \"no such fw client %d\\n\",\n\t\t\tcl->fw_client_id);\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tspin_lock_irqsave(&cl->free_list_spinlock, flags);\n\tif (list_empty(&cl->free_rb_list.list)) {\n\t\tdev_warn(&cl->device->dev,\n\t\t\t \"[ishtp-ish] Rx buffers pool is empty\\n\");\n\t\trets = -ENOMEM;\n\t\trb = NULL;\n\t\tspin_unlock_irqrestore(&cl->free_list_spinlock, flags);\n\t\tgoto out;\n\t}\n\trb = list_entry(cl->free_rb_list.list.next, struct ishtp_cl_rb, list);\n\tlist_del_init(&rb->list);\n\tspin_unlock_irqrestore(&cl->free_list_spinlock, flags);\n\n\trb->cl = cl;\n\trb->buf_idx = 0;\n\n\tINIT_LIST_HEAD(&rb->list);\n\trets = 0;\n\n\t \n\tspin_lock_irqsave(&dev->read_list_spinlock, dev_flags);\n\tlist_add_tail(&rb->list, &dev->read_list.list);\n\tspin_unlock_irqrestore(&dev->read_list_spinlock, dev_flags);\n\tif (ishtp_hbm_cl_flow_control_req(dev, cl)) {\n\t\trets = -ENODEV;\n\t\tgoto out;\n\t}\nout:\n\t \n\tif (rets && rb) {\n\t\tspin_lock_irqsave(&dev->read_list_spinlock, dev_flags);\n\t\tlist_del(&rb->list);\n\t\tspin_unlock_irqrestore(&dev->read_list_spinlock, dev_flags);\n\n\t\tspin_lock_irqsave(&cl->free_list_spinlock, flags);\n\t\tlist_add_tail(&rb->list, &cl->free_rb_list.list);\n\t\tspin_unlock_irqrestore(&cl->free_list_spinlock, flags);\n\t}\n\treturn rets;\n}\n\n \nint ishtp_cl_send(struct ishtp_cl *cl, uint8_t *buf, size_t length)\n{\n\tstruct ishtp_device\t*dev;\n\tint\tid;\n\tstruct ishtp_cl_tx_ring\t*cl_msg;\n\tint\thave_msg_to_send = 0;\n\tunsigned long\ttx_flags, tx_free_flags;\n\n\tif (WARN_ON(!cl || !cl->dev))\n\t\treturn -ENODEV;\n\n\tdev = cl->dev;\n\n\tif (cl->state != ISHTP_CL_CONNECTED) {\n\t\t++cl->err_send_msg;\n\t\treturn -EPIPE;\n\t}\n\n\tif (dev->dev_state != ISHTP_DEV_ENABLED) {\n\t\t++cl->err_send_msg;\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tid = ishtp_fw_cl_by_id(dev, cl->fw_client_id);\n\tif (id < 0) {\n\t\t++cl->err_send_msg;\n\t\treturn -ENOENT;\n\t}\n\n\tif (length > dev->fw_clients[id].props.max_msg_length) {\n\t\t++cl->err_send_msg;\n\t\treturn -EMSGSIZE;\n\t}\n\n\t \n\tspin_lock_irqsave(&cl->tx_free_list_spinlock, tx_free_flags);\n\tif (list_empty(&cl->tx_free_list.list)) {\n\t\tspin_unlock_irqrestore(&cl->tx_free_list_spinlock,\n\t\t\ttx_free_flags);\n\t\t++cl->err_send_msg;\n\t\treturn\t-ENOMEM;\n\t}\n\n\tcl_msg = list_first_entry(&cl->tx_free_list.list,\n\t\tstruct ishtp_cl_tx_ring, list);\n\tif (!cl_msg->send_buf.data) {\n\t\tspin_unlock_irqrestore(&cl->tx_free_list_spinlock,\n\t\t\ttx_free_flags);\n\t\treturn\t-EIO;\n\t\t \n\t}\n\t \n\tlist_del_init(&cl_msg->list);\n\t--cl->tx_ring_free_size;\n\n\tspin_unlock_irqrestore(&cl->tx_free_list_spinlock, tx_free_flags);\n\tmemcpy(cl_msg->send_buf.data, buf, length);\n\tcl_msg->send_buf.size = length;\n\tspin_lock_irqsave(&cl->tx_list_spinlock, tx_flags);\n\thave_msg_to_send = !list_empty(&cl->tx_list.list);\n\tlist_add_tail(&cl_msg->list, &cl->tx_list.list);\n\tspin_unlock_irqrestore(&cl->tx_list_spinlock, tx_flags);\n\n\tif (!have_msg_to_send && cl->ishtp_flow_ctrl_creds > 0)\n\t\tishtp_cl_send_msg(dev, cl);\n\n\treturn\t0;\n}\nEXPORT_SYMBOL(ishtp_cl_send);\n\n \nstatic void ishtp_cl_read_complete(struct ishtp_cl_rb *rb)\n{\n\tunsigned long\tflags;\n\tint\tschedule_work_flag = 0;\n\tstruct ishtp_cl\t*cl = rb->cl;\n\n\tspin_lock_irqsave(&cl->in_process_spinlock, flags);\n\t \n\tschedule_work_flag = list_empty(&cl->in_process_list.list);\n\tlist_add_tail(&rb->list, &cl->in_process_list.list);\n\tspin_unlock_irqrestore(&cl->in_process_spinlock, flags);\n\n\tif (schedule_work_flag)\n\t\tishtp_cl_bus_rx_event(cl->device);\n}\n\n \nstatic void ipc_tx_send(void *prm)\n{\n\tstruct ishtp_cl\t*cl = prm;\n\tstruct ishtp_cl_tx_ring\t*cl_msg;\n\tsize_t\trem;\n\tstruct ishtp_device\t*dev = (cl ? cl->dev : NULL);\n\tstruct ishtp_msg_hdr\tishtp_hdr;\n\tunsigned long\ttx_flags, tx_free_flags;\n\tunsigned char\t*pmsg;\n\n\tif (!dev)\n\t\treturn;\n\n\t \n\tif (dev->dev_state != ISHTP_DEV_ENABLED)\n\t\treturn;\n\n\tif (cl->state != ISHTP_CL_CONNECTED)\n\t\treturn;\n\n\tspin_lock_irqsave(&cl->tx_list_spinlock, tx_flags);\n\tif (list_empty(&cl->tx_list.list)) {\n\t\tspin_unlock_irqrestore(&cl->tx_list_spinlock, tx_flags);\n\t\treturn;\n\t}\n\n\tif (cl->ishtp_flow_ctrl_creds != 1 && !cl->sending) {\n\t\tspin_unlock_irqrestore(&cl->tx_list_spinlock, tx_flags);\n\t\treturn;\n\t}\n\n\tif (!cl->sending) {\n\t\t--cl->ishtp_flow_ctrl_creds;\n\t\tcl->last_ipc_acked = 0;\n\t\tcl->last_tx_path = CL_TX_PATH_IPC;\n\t\tcl->sending = 1;\n\t}\n\n\tcl_msg = list_entry(cl->tx_list.list.next, struct ishtp_cl_tx_ring,\n\t\t\t    list);\n\trem = cl_msg->send_buf.size - cl->tx_offs;\n\n\twhile (rem > 0) {\n\t\tishtp_hdr.host_addr = cl->host_client_id;\n\t\tishtp_hdr.fw_addr = cl->fw_client_id;\n\t\tishtp_hdr.reserved = 0;\n\t\tpmsg = cl_msg->send_buf.data + cl->tx_offs;\n\n\t\tif (rem <= dev->mtu) {\n\t\t\t \n\t\t\tishtp_hdr.length = rem;\n\t\t\tishtp_hdr.msg_complete = 1;\n\t\t\t \n\t\t\tishtp_write_message(dev, &ishtp_hdr, pmsg);\n\t\t\tcl->tx_offs = 0;\n\t\t\tcl->sending = 0;\n\n\t\t\tbreak;\n\t\t} else {\n\t\t\t \n\t\t\tishtp_hdr.length = dev->mtu;\n\t\t\tishtp_hdr.msg_complete = 0;\n\t\t\t \n\t\t\tishtp_write_message(dev, &ishtp_hdr, pmsg);\n\t\t\tcl->tx_offs += dev->mtu;\n\t\t\trem = cl_msg->send_buf.size - cl->tx_offs;\n\t\t}\n\t}\n\n\tlist_del_init(&cl_msg->list);\n\tspin_unlock_irqrestore(&cl->tx_list_spinlock, tx_flags);\n\n\tspin_lock_irqsave(&cl->tx_free_list_spinlock, tx_free_flags);\n\tlist_add_tail(&cl_msg->list, &cl->tx_free_list.list);\n\t++cl->tx_ring_free_size;\n\tspin_unlock_irqrestore(&cl->tx_free_list_spinlock,\n\t\ttx_free_flags);\n}\n\n \nstatic void ishtp_cl_send_msg_ipc(struct ishtp_device *dev,\n\t\t\t\t  struct ishtp_cl *cl)\n{\n\t \n\tif (cl->last_tx_path == CL_TX_PATH_DMA && cl->last_dma_acked == 0)\n\t\treturn;\n\n\tcl->tx_offs = 0;\n\tipc_tx_send(cl);\n\t++cl->send_msg_cnt_ipc;\n}\n\n \nstatic void ishtp_cl_send_msg_dma(struct ishtp_device *dev,\n\tstruct ishtp_cl *cl)\n{\n\tstruct ishtp_msg_hdr\thdr;\n\tstruct dma_xfer_hbm\tdma_xfer;\n\tunsigned char\t*msg_addr;\n\tint off;\n\tstruct ishtp_cl_tx_ring\t*cl_msg;\n\tunsigned long tx_flags, tx_free_flags;\n\n\t \n\tif (cl->last_tx_path == CL_TX_PATH_IPC && cl->last_ipc_acked == 0)\n\t\treturn;\n\n\tspin_lock_irqsave(&cl->tx_list_spinlock, tx_flags);\n\tif (list_empty(&cl->tx_list.list)) {\n\t\tspin_unlock_irqrestore(&cl->tx_list_spinlock, tx_flags);\n\t\treturn;\n\t}\n\n\tcl_msg = list_entry(cl->tx_list.list.next, struct ishtp_cl_tx_ring,\n\t\tlist);\n\n\tmsg_addr = ishtp_cl_get_dma_send_buf(dev, cl_msg->send_buf.size);\n\tif (!msg_addr) {\n\t\tspin_unlock_irqrestore(&cl->tx_list_spinlock, tx_flags);\n\t\tif (dev->transfer_path == CL_TX_PATH_DEFAULT)\n\t\t\tishtp_cl_send_msg_ipc(dev, cl);\n\t\treturn;\n\t}\n\n\tlist_del_init(&cl_msg->list);\t \n\tspin_unlock_irqrestore(&cl->tx_list_spinlock, tx_flags);\n\n\t--cl->ishtp_flow_ctrl_creds;\n\tcl->last_dma_acked = 0;\n\tcl->last_dma_addr = msg_addr;\n\tcl->last_tx_path = CL_TX_PATH_DMA;\n\n\t \n\tmemcpy(msg_addr, cl_msg->send_buf.data, cl_msg->send_buf.size);\n\n\t \n\tif (dev->ops->dma_no_cache_snooping &&\n\t\tdev->ops->dma_no_cache_snooping(dev))\n\t\tclflush_cache_range(msg_addr, cl_msg->send_buf.size);\n\n\t \n\toff = msg_addr - (unsigned char *)dev->ishtp_host_dma_tx_buf;\n\tishtp_hbm_hdr(&hdr, sizeof(struct dma_xfer_hbm));\n\tdma_xfer.hbm = DMA_XFER;\n\tdma_xfer.fw_client_id = cl->fw_client_id;\n\tdma_xfer.host_client_id = cl->host_client_id;\n\tdma_xfer.reserved = 0;\n\tdma_xfer.msg_addr = dev->ishtp_host_dma_tx_buf_phys + off;\n\tdma_xfer.msg_length = cl_msg->send_buf.size;\n\tdma_xfer.reserved2 = 0;\n\tishtp_write_message(dev, &hdr, (unsigned char *)&dma_xfer);\n\tspin_lock_irqsave(&cl->tx_free_list_spinlock, tx_free_flags);\n\tlist_add_tail(&cl_msg->list, &cl->tx_free_list.list);\n\t++cl->tx_ring_free_size;\n\tspin_unlock_irqrestore(&cl->tx_free_list_spinlock, tx_free_flags);\n\t++cl->send_msg_cnt_dma;\n}\n\n \nvoid ishtp_cl_send_msg(struct ishtp_device *dev, struct ishtp_cl *cl)\n{\n\tif (dev->transfer_path == CL_TX_PATH_DMA)\n\t\tishtp_cl_send_msg_dma(dev, cl);\n\telse\n\t\tishtp_cl_send_msg_ipc(dev, cl);\n}\n\n \nvoid recv_ishtp_cl_msg(struct ishtp_device *dev,\n\t\t       struct ishtp_msg_hdr *ishtp_hdr)\n{\n\tstruct ishtp_cl *cl;\n\tstruct ishtp_cl_rb *rb;\n\tstruct ishtp_cl_rb *new_rb;\n\tunsigned char *buffer = NULL;\n\tstruct ishtp_cl_rb *complete_rb = NULL;\n\tunsigned long\tflags;\n\n\tif (ishtp_hdr->reserved) {\n\t\tdev_err(dev->devc, \"corrupted message header.\\n\");\n\t\tgoto\teoi;\n\t}\n\n\tif (ishtp_hdr->length > IPC_PAYLOAD_SIZE) {\n\t\tdev_err(dev->devc,\n\t\t\t\"ISHTP message length in hdr exceeds IPC MTU\\n\");\n\t\tgoto\teoi;\n\t}\n\n\tspin_lock_irqsave(&dev->read_list_spinlock, flags);\n\tlist_for_each_entry(rb, &dev->read_list.list, list) {\n\t\tcl = rb->cl;\n\t\tif (!cl || !(cl->host_client_id == ishtp_hdr->host_addr &&\n\t\t\t\tcl->fw_client_id == ishtp_hdr->fw_addr) ||\n\t\t\t\t!(cl->state == ISHTP_CL_CONNECTED))\n\t\t\tcontinue;\n\n\t\t  \n\t\tif (rb->buffer.size == 0 || rb->buffer.data == NULL) {\n\t\t\tspin_unlock_irqrestore(&dev->read_list_spinlock, flags);\n\t\t\tdev_err(&cl->device->dev,\n\t\t\t\t\"Rx buffer is not allocated.\\n\");\n\t\t\tlist_del(&rb->list);\n\t\t\tishtp_io_rb_free(rb);\n\t\t\tcl->status = -ENOMEM;\n\t\t\tgoto\teoi;\n\t\t}\n\n\t\t \n\t\tif (rb->buffer.size < ishtp_hdr->length + rb->buf_idx) {\n\t\t\tspin_unlock_irqrestore(&dev->read_list_spinlock, flags);\n\t\t\tdev_err(&cl->device->dev,\n\t\t\t\t\"message overflow. size %d len %d idx %ld\\n\",\n\t\t\t\trb->buffer.size, ishtp_hdr->length,\n\t\t\t\trb->buf_idx);\n\t\t\tlist_del(&rb->list);\n\t\t\tishtp_cl_io_rb_recycle(rb);\n\t\t\tcl->status = -EIO;\n\t\t\tgoto\teoi;\n\t\t}\n\n\t\tbuffer = rb->buffer.data + rb->buf_idx;\n\t\tdev->ops->ishtp_read(dev, buffer, ishtp_hdr->length);\n\n\t\trb->buf_idx += ishtp_hdr->length;\n\t\tif (ishtp_hdr->msg_complete) {\n\t\t\t \n\t\t\tcl->status = 0;\n\t\t\tlist_del(&rb->list);\n\t\t\tcomplete_rb = rb;\n\n\t\t\t--cl->out_flow_ctrl_creds;\n\t\t\t \n\t\t\tspin_lock(&cl->free_list_spinlock);\n\n\t\t\tif (!list_empty(&cl->free_rb_list.list)) {\n\t\t\t\tnew_rb = list_entry(cl->free_rb_list.list.next,\n\t\t\t\t\tstruct ishtp_cl_rb, list);\n\t\t\t\tlist_del_init(&new_rb->list);\n\t\t\t\tspin_unlock(&cl->free_list_spinlock);\n\t\t\t\tnew_rb->cl = cl;\n\t\t\t\tnew_rb->buf_idx = 0;\n\t\t\t\tINIT_LIST_HEAD(&new_rb->list);\n\t\t\t\tlist_add_tail(&new_rb->list,\n\t\t\t\t\t&dev->read_list.list);\n\n\t\t\t\tishtp_hbm_cl_flow_control_req(dev, cl);\n\t\t\t} else {\n\t\t\t\tspin_unlock(&cl->free_list_spinlock);\n\t\t\t}\n\t\t}\n\t\t \n\t\t++cl->recv_msg_num_frags;\n\n\t\t \n\t\tbreak;\n\t}\n\n\tspin_unlock_irqrestore(&dev->read_list_spinlock, flags);\n\t \n\tif (!buffer) {\n\t\tuint8_t\trd_msg_buf[ISHTP_RD_MSG_BUF_SIZE];\n\n\t\tdev_err(dev->devc, \"Dropped Rx msg - no request\\n\");\n\t\tdev->ops->ishtp_read(dev, rd_msg_buf, ishtp_hdr->length);\n\t\tgoto\teoi;\n\t}\n\n\tif (complete_rb) {\n\t\tcl = complete_rb->cl;\n\t\tcl->ts_rx = ktime_get();\n\t\t++cl->recv_msg_cnt_ipc;\n\t\tishtp_cl_read_complete(complete_rb);\n\t}\neoi:\n\treturn;\n}\n\n \nvoid recv_ishtp_cl_msg_dma(struct ishtp_device *dev, void *msg,\n\t\t\t   struct dma_xfer_hbm *hbm)\n{\n\tstruct ishtp_cl *cl;\n\tstruct ishtp_cl_rb *rb;\n\tstruct ishtp_cl_rb *new_rb;\n\tunsigned char *buffer = NULL;\n\tstruct ishtp_cl_rb *complete_rb = NULL;\n\tunsigned long\tflags;\n\n\tspin_lock_irqsave(&dev->read_list_spinlock, flags);\n\n\tlist_for_each_entry(rb, &dev->read_list.list, list) {\n\t\tcl = rb->cl;\n\t\tif (!cl || !(cl->host_client_id == hbm->host_client_id &&\n\t\t\t\tcl->fw_client_id == hbm->fw_client_id) ||\n\t\t\t\t!(cl->state == ISHTP_CL_CONNECTED))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (rb->buffer.size == 0 || rb->buffer.data == NULL) {\n\t\t\tspin_unlock_irqrestore(&dev->read_list_spinlock, flags);\n\t\t\tdev_err(&cl->device->dev,\n\t\t\t\t\"response buffer is not allocated.\\n\");\n\t\t\tlist_del(&rb->list);\n\t\t\tishtp_io_rb_free(rb);\n\t\t\tcl->status = -ENOMEM;\n\t\t\tgoto\teoi;\n\t\t}\n\n\t\t \n\t\tif (rb->buffer.size < hbm->msg_length) {\n\t\t\tspin_unlock_irqrestore(&dev->read_list_spinlock, flags);\n\t\t\tdev_err(&cl->device->dev,\n\t\t\t\t\"message overflow. size %d len %d idx %ld\\n\",\n\t\t\t\trb->buffer.size, hbm->msg_length, rb->buf_idx);\n\t\t\tlist_del(&rb->list);\n\t\t\tishtp_cl_io_rb_recycle(rb);\n\t\t\tcl->status = -EIO;\n\t\t\tgoto\teoi;\n\t\t}\n\n\t\tbuffer = rb->buffer.data;\n\n\t\t \n\t\tif (dev->ops->dma_no_cache_snooping &&\n\t\t\tdev->ops->dma_no_cache_snooping(dev))\n\t\t\tclflush_cache_range(msg, hbm->msg_length);\n\n\t\tmemcpy(buffer, msg, hbm->msg_length);\n\t\trb->buf_idx = hbm->msg_length;\n\n\t\t \n\t\tcl->status = 0;\n\t\tlist_del(&rb->list);\n\t\tcomplete_rb = rb;\n\n\t\t--cl->out_flow_ctrl_creds;\n\t\t \n\t\tspin_lock(&cl->free_list_spinlock);\n\n\t\tif (!list_empty(&cl->free_rb_list.list)) {\n\t\t\tnew_rb = list_entry(cl->free_rb_list.list.next,\n\t\t\t\tstruct ishtp_cl_rb, list);\n\t\t\tlist_del_init(&new_rb->list);\n\t\t\tspin_unlock(&cl->free_list_spinlock);\n\t\t\tnew_rb->cl = cl;\n\t\t\tnew_rb->buf_idx = 0;\n\t\t\tINIT_LIST_HEAD(&new_rb->list);\n\t\t\tlist_add_tail(&new_rb->list,\n\t\t\t\t&dev->read_list.list);\n\n\t\t\tishtp_hbm_cl_flow_control_req(dev, cl);\n\t\t} else {\n\t\t\tspin_unlock(&cl->free_list_spinlock);\n\t\t}\n\n\t\t \n\t\t++cl->recv_msg_num_frags;\n\n\t\t \n\t\tbreak;\n\t}\n\n\tspin_unlock_irqrestore(&dev->read_list_spinlock, flags);\n\t \n\tif (!buffer) {\n\t\tdev_err(dev->devc, \"Dropped Rx (DMA) msg - no request\\n\");\n\t\tgoto\teoi;\n\t}\n\n\tif (complete_rb) {\n\t\tcl = complete_rb->cl;\n\t\tcl->ts_rx = ktime_get();\n\t\t++cl->recv_msg_cnt_dma;\n\t\tishtp_cl_read_complete(complete_rb);\n\t}\neoi:\n\treturn;\n}\n\nvoid *ishtp_get_client_data(struct ishtp_cl *cl)\n{\n\treturn cl->client_data;\n}\nEXPORT_SYMBOL(ishtp_get_client_data);\n\nvoid ishtp_set_client_data(struct ishtp_cl *cl, void *data)\n{\n\tcl->client_data = data;\n}\nEXPORT_SYMBOL(ishtp_set_client_data);\n\nstruct ishtp_device *ishtp_get_ishtp_device(struct ishtp_cl *cl)\n{\n\treturn cl->dev;\n}\nEXPORT_SYMBOL(ishtp_get_ishtp_device);\n\nvoid ishtp_set_tx_ring_size(struct ishtp_cl *cl, int size)\n{\n\tcl->tx_ring_size = size;\n}\nEXPORT_SYMBOL(ishtp_set_tx_ring_size);\n\nvoid ishtp_set_rx_ring_size(struct ishtp_cl *cl, int size)\n{\n\tcl->rx_ring_size = size;\n}\nEXPORT_SYMBOL(ishtp_set_rx_ring_size);\n\nvoid ishtp_set_connection_state(struct ishtp_cl *cl, int state)\n{\n\tcl->state = state;\n}\nEXPORT_SYMBOL(ishtp_set_connection_state);\n\nvoid ishtp_cl_set_fw_client_id(struct ishtp_cl *cl, int fw_client_id)\n{\n\tcl->fw_client_id = fw_client_id;\n}\nEXPORT_SYMBOL(ishtp_cl_set_fw_client_id);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}