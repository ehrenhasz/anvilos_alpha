{
  "module_name": "irq-sifive-plic.c",
  "hash_id": "1280a02f13a97db9feb3c2771c2cf895c9f4753ef2d351c31d616ea0e6a249fb",
  "original_prompt": "Ingested from linux-6.6.14/drivers/irqchip/irq-sifive-plic.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) \"plic: \" fmt\n#include <linux/cpu.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/irq.h>\n#include <linux/irqchip.h>\n#include <linux/irqchip/chained_irq.h>\n#include <linux/irqdomain.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/platform_device.h>\n#include <linux/spinlock.h>\n#include <linux/syscore_ops.h>\n#include <asm/smp.h>\n\n \n\n#define MAX_DEVICES\t\t\t1024\n#define MAX_CONTEXTS\t\t\t15872\n\n \n#define PRIORITY_BASE\t\t\t0\n#define     PRIORITY_PER_ID\t\t4\n\n \n#define CONTEXT_ENABLE_BASE\t\t0x2000\n#define     CONTEXT_ENABLE_SIZE\t\t0x80\n\n \n#define CONTEXT_BASE\t\t\t0x200000\n#define     CONTEXT_SIZE\t\t0x1000\n#define     CONTEXT_THRESHOLD\t\t0x00\n#define     CONTEXT_CLAIM\t\t0x04\n\n#define\tPLIC_DISABLE_THRESHOLD\t\t0x7\n#define\tPLIC_ENABLE_THRESHOLD\t\t0\n\n#define PLIC_QUIRK_EDGE_INTERRUPT\t0\n\nstruct plic_priv {\n\tstruct cpumask lmask;\n\tstruct irq_domain *irqdomain;\n\tvoid __iomem *regs;\n\tunsigned long plic_quirks;\n\tunsigned int nr_irqs;\n\tunsigned long *prio_save;\n};\n\nstruct plic_handler {\n\tbool\t\t\tpresent;\n\tvoid __iomem\t\t*hart_base;\n\t \n\traw_spinlock_t\t\tenable_lock;\n\tvoid __iomem\t\t*enable_base;\n\tu32\t\t\t*enable_save;\n\tstruct plic_priv\t*priv;\n};\nstatic int plic_parent_irq __ro_after_init;\nstatic bool plic_cpuhp_setup_done __ro_after_init;\nstatic DEFINE_PER_CPU(struct plic_handler, plic_handlers);\n\nstatic int plic_irq_set_type(struct irq_data *d, unsigned int type);\n\nstatic void __plic_toggle(void __iomem *enable_base, int hwirq, int enable)\n{\n\tu32 __iomem *reg = enable_base + (hwirq / 32) * sizeof(u32);\n\tu32 hwirq_mask = 1 << (hwirq % 32);\n\n\tif (enable)\n\t\twritel(readl(reg) | hwirq_mask, reg);\n\telse\n\t\twritel(readl(reg) & ~hwirq_mask, reg);\n}\n\nstatic void plic_toggle(struct plic_handler *handler, int hwirq, int enable)\n{\n\traw_spin_lock(&handler->enable_lock);\n\t__plic_toggle(handler->enable_base, hwirq, enable);\n\traw_spin_unlock(&handler->enable_lock);\n}\n\nstatic inline void plic_irq_toggle(const struct cpumask *mask,\n\t\t\t\t   struct irq_data *d, int enable)\n{\n\tint cpu;\n\n\tfor_each_cpu(cpu, mask) {\n\t\tstruct plic_handler *handler = per_cpu_ptr(&plic_handlers, cpu);\n\n\t\tplic_toggle(handler, d->hwirq, enable);\n\t}\n}\n\nstatic void plic_irq_enable(struct irq_data *d)\n{\n\tplic_irq_toggle(irq_data_get_effective_affinity_mask(d), d, 1);\n}\n\nstatic void plic_irq_disable(struct irq_data *d)\n{\n\tplic_irq_toggle(irq_data_get_effective_affinity_mask(d), d, 0);\n}\n\nstatic void plic_irq_unmask(struct irq_data *d)\n{\n\tstruct plic_priv *priv = irq_data_get_irq_chip_data(d);\n\n\twritel(1, priv->regs + PRIORITY_BASE + d->hwirq * PRIORITY_PER_ID);\n}\n\nstatic void plic_irq_mask(struct irq_data *d)\n{\n\tstruct plic_priv *priv = irq_data_get_irq_chip_data(d);\n\n\twritel(0, priv->regs + PRIORITY_BASE + d->hwirq * PRIORITY_PER_ID);\n}\n\nstatic void plic_irq_eoi(struct irq_data *d)\n{\n\tstruct plic_handler *handler = this_cpu_ptr(&plic_handlers);\n\n\twritel(d->hwirq, handler->hart_base + CONTEXT_CLAIM);\n}\n\n#ifdef CONFIG_SMP\nstatic int plic_set_affinity(struct irq_data *d,\n\t\t\t     const struct cpumask *mask_val, bool force)\n{\n\tunsigned int cpu;\n\tstruct cpumask amask;\n\tstruct plic_priv *priv = irq_data_get_irq_chip_data(d);\n\n\tcpumask_and(&amask, &priv->lmask, mask_val);\n\n\tif (force)\n\t\tcpu = cpumask_first(&amask);\n\telse\n\t\tcpu = cpumask_any_and(&amask, cpu_online_mask);\n\n\tif (cpu >= nr_cpu_ids)\n\t\treturn -EINVAL;\n\n\tplic_irq_disable(d);\n\n\tirq_data_update_effective_affinity(d, cpumask_of(cpu));\n\n\tif (!irqd_irq_disabled(d))\n\t\tplic_irq_enable(d);\n\n\treturn IRQ_SET_MASK_OK_DONE;\n}\n#endif\n\nstatic struct irq_chip plic_edge_chip = {\n\t.name\t\t= \"SiFive PLIC\",\n\t.irq_enable\t= plic_irq_enable,\n\t.irq_disable\t= plic_irq_disable,\n\t.irq_ack\t= plic_irq_eoi,\n\t.irq_mask\t= plic_irq_mask,\n\t.irq_unmask\t= plic_irq_unmask,\n#ifdef CONFIG_SMP\n\t.irq_set_affinity = plic_set_affinity,\n#endif\n\t.irq_set_type\t= plic_irq_set_type,\n\t.flags\t\t= IRQCHIP_SKIP_SET_WAKE |\n\t\t\t  IRQCHIP_AFFINITY_PRE_STARTUP,\n};\n\nstatic struct irq_chip plic_chip = {\n\t.name\t\t= \"SiFive PLIC\",\n\t.irq_enable\t= plic_irq_enable,\n\t.irq_disable\t= plic_irq_disable,\n\t.irq_mask\t= plic_irq_mask,\n\t.irq_unmask\t= plic_irq_unmask,\n\t.irq_eoi\t= plic_irq_eoi,\n#ifdef CONFIG_SMP\n\t.irq_set_affinity = plic_set_affinity,\n#endif\n\t.irq_set_type\t= plic_irq_set_type,\n\t.flags\t\t= IRQCHIP_SKIP_SET_WAKE |\n\t\t\t  IRQCHIP_AFFINITY_PRE_STARTUP,\n};\n\nstatic int plic_irq_set_type(struct irq_data *d, unsigned int type)\n{\n\tstruct plic_priv *priv = irq_data_get_irq_chip_data(d);\n\n\tif (!test_bit(PLIC_QUIRK_EDGE_INTERRUPT, &priv->plic_quirks))\n\t\treturn IRQ_SET_MASK_OK_NOCOPY;\n\n\tswitch (type) {\n\tcase IRQ_TYPE_EDGE_RISING:\n\t\tirq_set_chip_handler_name_locked(d, &plic_edge_chip,\n\t\t\t\t\t\t handle_edge_irq, NULL);\n\t\tbreak;\n\tcase IRQ_TYPE_LEVEL_HIGH:\n\t\tirq_set_chip_handler_name_locked(d, &plic_chip,\n\t\t\t\t\t\t handle_fasteoi_irq, NULL);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn IRQ_SET_MASK_OK;\n}\n\nstatic int plic_irq_suspend(void)\n{\n\tunsigned int i, cpu;\n\tu32 __iomem *reg;\n\tstruct plic_priv *priv;\n\n\tpriv = per_cpu_ptr(&plic_handlers, smp_processor_id())->priv;\n\n\tfor (i = 0; i < priv->nr_irqs; i++)\n\t\tif (readl(priv->regs + PRIORITY_BASE + i * PRIORITY_PER_ID))\n\t\t\t__set_bit(i, priv->prio_save);\n\t\telse\n\t\t\t__clear_bit(i, priv->prio_save);\n\n\tfor_each_cpu(cpu, cpu_present_mask) {\n\t\tstruct plic_handler *handler = per_cpu_ptr(&plic_handlers, cpu);\n\n\t\tif (!handler->present)\n\t\t\tcontinue;\n\n\t\traw_spin_lock(&handler->enable_lock);\n\t\tfor (i = 0; i < DIV_ROUND_UP(priv->nr_irqs, 32); i++) {\n\t\t\treg = handler->enable_base + i * sizeof(u32);\n\t\t\thandler->enable_save[i] = readl(reg);\n\t\t}\n\t\traw_spin_unlock(&handler->enable_lock);\n\t}\n\n\treturn 0;\n}\n\nstatic void plic_irq_resume(void)\n{\n\tunsigned int i, index, cpu;\n\tu32 __iomem *reg;\n\tstruct plic_priv *priv;\n\n\tpriv = per_cpu_ptr(&plic_handlers, smp_processor_id())->priv;\n\n\tfor (i = 0; i < priv->nr_irqs; i++) {\n\t\tindex = BIT_WORD(i);\n\t\twritel((priv->prio_save[index] & BIT_MASK(i)) ? 1 : 0,\n\t\t       priv->regs + PRIORITY_BASE + i * PRIORITY_PER_ID);\n\t}\n\n\tfor_each_cpu(cpu, cpu_present_mask) {\n\t\tstruct plic_handler *handler = per_cpu_ptr(&plic_handlers, cpu);\n\n\t\tif (!handler->present)\n\t\t\tcontinue;\n\n\t\traw_spin_lock(&handler->enable_lock);\n\t\tfor (i = 0; i < DIV_ROUND_UP(priv->nr_irqs, 32); i++) {\n\t\t\treg = handler->enable_base + i * sizeof(u32);\n\t\t\twritel(handler->enable_save[i], reg);\n\t\t}\n\t\traw_spin_unlock(&handler->enable_lock);\n\t}\n}\n\nstatic struct syscore_ops plic_irq_syscore_ops = {\n\t.suspend\t= plic_irq_suspend,\n\t.resume\t\t= plic_irq_resume,\n};\n\nstatic int plic_irqdomain_map(struct irq_domain *d, unsigned int irq,\n\t\t\t      irq_hw_number_t hwirq)\n{\n\tstruct plic_priv *priv = d->host_data;\n\n\tirq_domain_set_info(d, irq, hwirq, &plic_chip, d->host_data,\n\t\t\t    handle_fasteoi_irq, NULL, NULL);\n\tirq_set_noprobe(irq);\n\tirq_set_affinity(irq, &priv->lmask);\n\treturn 0;\n}\n\nstatic int plic_irq_domain_translate(struct irq_domain *d,\n\t\t\t\t     struct irq_fwspec *fwspec,\n\t\t\t\t     unsigned long *hwirq,\n\t\t\t\t     unsigned int *type)\n{\n\tstruct plic_priv *priv = d->host_data;\n\n\tif (test_bit(PLIC_QUIRK_EDGE_INTERRUPT, &priv->plic_quirks))\n\t\treturn irq_domain_translate_twocell(d, fwspec, hwirq, type);\n\n\treturn irq_domain_translate_onecell(d, fwspec, hwirq, type);\n}\n\nstatic int plic_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,\n\t\t\t\t unsigned int nr_irqs, void *arg)\n{\n\tint i, ret;\n\tirq_hw_number_t hwirq;\n\tunsigned int type;\n\tstruct irq_fwspec *fwspec = arg;\n\n\tret = plic_irq_domain_translate(domain, fwspec, &hwirq, &type);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < nr_irqs; i++) {\n\t\tret = plic_irqdomain_map(domain, virq + i, hwirq + i);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct irq_domain_ops plic_irqdomain_ops = {\n\t.translate\t= plic_irq_domain_translate,\n\t.alloc\t\t= plic_irq_domain_alloc,\n\t.free\t\t= irq_domain_free_irqs_top,\n};\n\n \nstatic void plic_handle_irq(struct irq_desc *desc)\n{\n\tstruct plic_handler *handler = this_cpu_ptr(&plic_handlers);\n\tstruct irq_chip *chip = irq_desc_get_chip(desc);\n\tvoid __iomem *claim = handler->hart_base + CONTEXT_CLAIM;\n\tirq_hw_number_t hwirq;\n\n\tWARN_ON_ONCE(!handler->present);\n\n\tchained_irq_enter(chip, desc);\n\n\twhile ((hwirq = readl(claim))) {\n\t\tint err = generic_handle_domain_irq(handler->priv->irqdomain,\n\t\t\t\t\t\t    hwirq);\n\t\tif (unlikely(err))\n\t\t\tpr_warn_ratelimited(\"can't find mapping for hwirq %lu\\n\",\n\t\t\t\t\thwirq);\n\t}\n\n\tchained_irq_exit(chip, desc);\n}\n\nstatic void plic_set_threshold(struct plic_handler *handler, u32 threshold)\n{\n\t \n\twritel(threshold, handler->hart_base + CONTEXT_THRESHOLD);\n}\n\nstatic int plic_dying_cpu(unsigned int cpu)\n{\n\tif (plic_parent_irq)\n\t\tdisable_percpu_irq(plic_parent_irq);\n\n\treturn 0;\n}\n\nstatic int plic_starting_cpu(unsigned int cpu)\n{\n\tstruct plic_handler *handler = this_cpu_ptr(&plic_handlers);\n\n\tif (plic_parent_irq)\n\t\tenable_percpu_irq(plic_parent_irq,\n\t\t\t\t  irq_get_trigger_type(plic_parent_irq));\n\telse\n\t\tpr_warn(\"cpu%d: parent irq not available\\n\", cpu);\n\tplic_set_threshold(handler, PLIC_ENABLE_THRESHOLD);\n\n\treturn 0;\n}\n\nstatic int __init __plic_init(struct device_node *node,\n\t\t\t      struct device_node *parent,\n\t\t\t      unsigned long plic_quirks)\n{\n\tint error = 0, nr_contexts, nr_handlers = 0, i;\n\tu32 nr_irqs;\n\tstruct plic_priv *priv;\n\tstruct plic_handler *handler;\n\tunsigned int cpu;\n\n\tpriv = kzalloc(sizeof(*priv), GFP_KERNEL);\n\tif (!priv)\n\t\treturn -ENOMEM;\n\n\tpriv->plic_quirks = plic_quirks;\n\n\tpriv->regs = of_iomap(node, 0);\n\tif (WARN_ON(!priv->regs)) {\n\t\terror = -EIO;\n\t\tgoto out_free_priv;\n\t}\n\n\terror = -EINVAL;\n\tof_property_read_u32(node, \"riscv,ndev\", &nr_irqs);\n\tif (WARN_ON(!nr_irqs))\n\t\tgoto out_iounmap;\n\n\tpriv->nr_irqs = nr_irqs;\n\n\tpriv->prio_save = bitmap_alloc(nr_irqs, GFP_KERNEL);\n\tif (!priv->prio_save)\n\t\tgoto out_free_priority_reg;\n\n\tnr_contexts = of_irq_count(node);\n\tif (WARN_ON(!nr_contexts))\n\t\tgoto out_free_priority_reg;\n\n\terror = -ENOMEM;\n\tpriv->irqdomain = irq_domain_add_linear(node, nr_irqs + 1,\n\t\t\t&plic_irqdomain_ops, priv);\n\tif (WARN_ON(!priv->irqdomain))\n\t\tgoto out_free_priority_reg;\n\n\tfor (i = 0; i < nr_contexts; i++) {\n\t\tstruct of_phandle_args parent;\n\t\tirq_hw_number_t hwirq;\n\t\tint cpu;\n\t\tunsigned long hartid;\n\n\t\tif (of_irq_parse_one(node, i, &parent)) {\n\t\t\tpr_err(\"failed to parse parent for context %d.\\n\", i);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (parent.args[0] != RV_IRQ_EXT) {\n\t\t\t \n\t\t\tif (IS_ENABLED(CONFIG_RISCV_M_MODE)) {\n\t\t\t\tvoid __iomem *enable_base = priv->regs +\n\t\t\t\t\tCONTEXT_ENABLE_BASE +\n\t\t\t\t\ti * CONTEXT_ENABLE_SIZE;\n\n\t\t\t\tfor (hwirq = 1; hwirq <= nr_irqs; hwirq++)\n\t\t\t\t\t__plic_toggle(enable_base, hwirq, 0);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\terror = riscv_of_parent_hartid(parent.np, &hartid);\n\t\tif (error < 0) {\n\t\t\tpr_warn(\"failed to parse hart ID for context %d.\\n\", i);\n\t\t\tcontinue;\n\t\t}\n\n\t\tcpu = riscv_hartid_to_cpuid(hartid);\n\t\tif (cpu < 0) {\n\t\t\tpr_warn(\"Invalid cpuid for context %d\\n\", i);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (!plic_parent_irq && irq_find_host(parent.np)) {\n\t\t\tplic_parent_irq = irq_of_parse_and_map(node, i);\n\t\t\tif (plic_parent_irq)\n\t\t\t\tirq_set_chained_handler(plic_parent_irq,\n\t\t\t\t\t\t\tplic_handle_irq);\n\t\t}\n\n\t\t \n\t\thandler = per_cpu_ptr(&plic_handlers, cpu);\n\t\tif (handler->present) {\n\t\t\tpr_warn(\"handler already present for context %d.\\n\", i);\n\t\t\tplic_set_threshold(handler, PLIC_DISABLE_THRESHOLD);\n\t\t\tgoto done;\n\t\t}\n\n\t\tcpumask_set_cpu(cpu, &priv->lmask);\n\t\thandler->present = true;\n\t\thandler->hart_base = priv->regs + CONTEXT_BASE +\n\t\t\ti * CONTEXT_SIZE;\n\t\traw_spin_lock_init(&handler->enable_lock);\n\t\thandler->enable_base = priv->regs + CONTEXT_ENABLE_BASE +\n\t\t\ti * CONTEXT_ENABLE_SIZE;\n\t\thandler->priv = priv;\n\n\t\thandler->enable_save =  kcalloc(DIV_ROUND_UP(nr_irqs, 32),\n\t\t\t\t\t\tsizeof(*handler->enable_save), GFP_KERNEL);\n\t\tif (!handler->enable_save)\n\t\t\tgoto out_free_enable_reg;\ndone:\n\t\tfor (hwirq = 1; hwirq <= nr_irqs; hwirq++) {\n\t\t\tplic_toggle(handler, hwirq, 0);\n\t\t\twritel(1, priv->regs + PRIORITY_BASE +\n\t\t\t\t  hwirq * PRIORITY_PER_ID);\n\t\t}\n\t\tnr_handlers++;\n\t}\n\n\t \n\thandler = this_cpu_ptr(&plic_handlers);\n\tif (handler->present && !plic_cpuhp_setup_done) {\n\t\tcpuhp_setup_state(CPUHP_AP_IRQ_SIFIVE_PLIC_STARTING,\n\t\t\t\t  \"irqchip/sifive/plic:starting\",\n\t\t\t\t  plic_starting_cpu, plic_dying_cpu);\n\t\tregister_syscore_ops(&plic_irq_syscore_ops);\n\t\tplic_cpuhp_setup_done = true;\n\t}\n\n\tpr_info(\"%pOFP: mapped %d interrupts with %d handlers for\"\n\t\t\" %d contexts.\\n\", node, nr_irqs, nr_handlers, nr_contexts);\n\treturn 0;\n\nout_free_enable_reg:\n\tfor_each_cpu(cpu, cpu_present_mask) {\n\t\thandler = per_cpu_ptr(&plic_handlers, cpu);\n\t\tkfree(handler->enable_save);\n\t}\nout_free_priority_reg:\n\tkfree(priv->prio_save);\nout_iounmap:\n\tiounmap(priv->regs);\nout_free_priv:\n\tkfree(priv);\n\treturn error;\n}\n\nstatic int __init plic_init(struct device_node *node,\n\t\t\t    struct device_node *parent)\n{\n\treturn __plic_init(node, parent, 0);\n}\n\nIRQCHIP_DECLARE(sifive_plic, \"sifive,plic-1.0.0\", plic_init);\nIRQCHIP_DECLARE(riscv_plic0, \"riscv,plic0\", plic_init);  \n\nstatic int __init plic_edge_init(struct device_node *node,\n\t\t\t\t struct device_node *parent)\n{\n\treturn __plic_init(node, parent, BIT(PLIC_QUIRK_EDGE_INTERRUPT));\n}\n\nIRQCHIP_DECLARE(andestech_nceplic100, \"andestech,nceplic100\", plic_edge_init);\nIRQCHIP_DECLARE(thead_c900_plic, \"thead,c900-plic\", plic_edge_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}