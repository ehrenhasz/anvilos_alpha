{
  "module_name": "irq-gic-v3.c",
  "hash_id": "b43e29f37959b4c8cf542e58847e4766c6fd8cb39bdee1e9704c9ed453b574d2",
  "original_prompt": "Ingested from linux-6.6.14/drivers/irqchip/irq-gic-v3.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\t\"GICv3: \" fmt\n\n#include <linux/acpi.h>\n#include <linux/cpu.h>\n#include <linux/cpu_pm.h>\n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/irqdomain.h>\n#include <linux/kstrtox.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/percpu.h>\n#include <linux/refcount.h>\n#include <linux/slab.h>\n\n#include <linux/irqchip.h>\n#include <linux/irqchip/arm-gic-common.h>\n#include <linux/irqchip/arm-gic-v3.h>\n#include <linux/irqchip/irq-partition-percpu.h>\n#include <linux/bitfield.h>\n#include <linux/bits.h>\n#include <linux/arm-smccc.h>\n\n#include <asm/cputype.h>\n#include <asm/exception.h>\n#include <asm/smp_plat.h>\n#include <asm/virt.h>\n\n#include \"irq-gic-common.h\"\n\n#define GICD_INT_NMI_PRI\t(GICD_INT_DEF_PRI & ~0x80)\n\n#define FLAGS_WORKAROUND_GICR_WAKER_MSM8996\t(1ULL << 0)\n#define FLAGS_WORKAROUND_CAVIUM_ERRATUM_38539\t(1ULL << 1)\n#define FLAGS_WORKAROUND_MTK_GICR_SAVE\t\t(1ULL << 2)\n#define FLAGS_WORKAROUND_ASR_ERRATUM_8601001\t(1ULL << 3)\n\n#define GIC_IRQ_TYPE_PARTITION\t(GIC_IRQ_TYPE_LPI + 1)\n\nstruct redist_region {\n\tvoid __iomem\t\t*redist_base;\n\tphys_addr_t\t\tphys_base;\n\tbool\t\t\tsingle_redist;\n};\n\nstruct gic_chip_data {\n\tstruct fwnode_handle\t*fwnode;\n\tphys_addr_t\t\tdist_phys_base;\n\tvoid __iomem\t\t*dist_base;\n\tstruct redist_region\t*redist_regions;\n\tstruct rdists\t\trdists;\n\tstruct irq_domain\t*domain;\n\tu64\t\t\tredist_stride;\n\tu32\t\t\tnr_redist_regions;\n\tu64\t\t\tflags;\n\tbool\t\t\thas_rss;\n\tunsigned int\t\tppi_nr;\n\tstruct partition_desc\t**ppi_descs;\n};\n\n#define T241_CHIPS_MAX\t\t4\nstatic void __iomem *t241_dist_base_alias[T241_CHIPS_MAX] __read_mostly;\nstatic DEFINE_STATIC_KEY_FALSE(gic_nvidia_t241_erratum);\n\nstatic DEFINE_STATIC_KEY_FALSE(gic_arm64_2941627_erratum);\n\nstatic struct gic_chip_data gic_data __read_mostly;\nstatic DEFINE_STATIC_KEY_TRUE(supports_deactivate_key);\n\n#define GIC_ID_NR\t(1U << GICD_TYPER_ID_BITS(gic_data.rdists.gicd_typer))\n#define GIC_LINE_NR\tmin(GICD_TYPER_SPIS(gic_data.rdists.gicd_typer), 1020U)\n#define GIC_ESPI_NR\tGICD_TYPER_ESPIS(gic_data.rdists.gicd_typer)\n\n \nstatic DEFINE_STATIC_KEY_FALSE(supports_pseudo_nmis);\n\nDEFINE_STATIC_KEY_FALSE(gic_nonsecure_priorities);\nEXPORT_SYMBOL(gic_nonsecure_priorities);\n\n \n#define GICD_INT_RPR_PRI(priority)\t\t\t\t\t\\\n\t({\t\t\t\t\t\t\t\t\\\n\t\tu32 __priority = (priority);\t\t\t\t\\\n\t\tif (static_branch_unlikely(&gic_nonsecure_priorities))\t\\\n\t\t\t__priority = 0x80 | (__priority >> 1);\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\t__priority;\t\t\t\t\t\t\\\n\t})\n\n \nstatic refcount_t *ppi_nmi_refs;\n\nstatic struct gic_kvm_info gic_v3_kvm_info __initdata;\nstatic DEFINE_PER_CPU(bool, has_rss);\n\n#define MPIDR_RS(mpidr)\t\t\t(((mpidr) & 0xF0UL) >> 4)\n#define gic_data_rdist()\t\t(this_cpu_ptr(gic_data.rdists.rdist))\n#define gic_data_rdist_rd_base()\t(gic_data_rdist()->rd_base)\n#define gic_data_rdist_sgi_base()\t(gic_data_rdist_rd_base() + SZ_64K)\n\n \n#define DEFAULT_PMR_VALUE\t0xf0\n\nenum gic_intid_range {\n\tSGI_RANGE,\n\tPPI_RANGE,\n\tSPI_RANGE,\n\tEPPI_RANGE,\n\tESPI_RANGE,\n\tLPI_RANGE,\n\t__INVALID_RANGE__\n};\n\nstatic enum gic_intid_range __get_intid_range(irq_hw_number_t hwirq)\n{\n\tswitch (hwirq) {\n\tcase 0 ... 15:\n\t\treturn SGI_RANGE;\n\tcase 16 ... 31:\n\t\treturn PPI_RANGE;\n\tcase 32 ... 1019:\n\t\treturn SPI_RANGE;\n\tcase EPPI_BASE_INTID ... (EPPI_BASE_INTID + 63):\n\t\treturn EPPI_RANGE;\n\tcase ESPI_BASE_INTID ... (ESPI_BASE_INTID + 1023):\n\t\treturn ESPI_RANGE;\n\tcase 8192 ... GENMASK(23, 0):\n\t\treturn LPI_RANGE;\n\tdefault:\n\t\treturn __INVALID_RANGE__;\n\t}\n}\n\nstatic enum gic_intid_range get_intid_range(struct irq_data *d)\n{\n\treturn __get_intid_range(d->hwirq);\n}\n\nstatic inline unsigned int gic_irq(struct irq_data *d)\n{\n\treturn d->hwirq;\n}\n\nstatic inline bool gic_irq_in_rdist(struct irq_data *d)\n{\n\tswitch (get_intid_range(d)) {\n\tcase SGI_RANGE:\n\tcase PPI_RANGE:\n\tcase EPPI_RANGE:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic inline void __iomem *gic_dist_base_alias(struct irq_data *d)\n{\n\tif (static_branch_unlikely(&gic_nvidia_t241_erratum)) {\n\t\tirq_hw_number_t hwirq = irqd_to_hwirq(d);\n\t\tu32 chip;\n\n\t\t \n\t\tswitch (__get_intid_range(hwirq)) {\n\t\tcase SPI_RANGE:\n\t\t\tchip = (hwirq - 32) / 320;\n\t\t\tbreak;\n\t\tcase ESPI_RANGE:\n\t\t\tchip = 3;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tunreachable();\n\t\t}\n\t\treturn t241_dist_base_alias[chip];\n\t}\n\n\treturn gic_data.dist_base;\n}\n\nstatic inline void __iomem *gic_dist_base(struct irq_data *d)\n{\n\tswitch (get_intid_range(d)) {\n\tcase SGI_RANGE:\n\tcase PPI_RANGE:\n\tcase EPPI_RANGE:\n\t\t \n\t\treturn gic_data_rdist_sgi_base();\n\n\tcase SPI_RANGE:\n\tcase ESPI_RANGE:\n\t\t \n\t\treturn gic_data.dist_base;\n\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic void gic_do_wait_for_rwp(void __iomem *base, u32 bit)\n{\n\tu32 count = 1000000;\t \n\n\twhile (readl_relaxed(base + GICD_CTLR) & bit) {\n\t\tcount--;\n\t\tif (!count) {\n\t\t\tpr_err_ratelimited(\"RWP timeout, gone fishing\\n\");\n\t\t\treturn;\n\t\t}\n\t\tcpu_relax();\n\t\tudelay(1);\n\t}\n}\n\n \nstatic void gic_dist_wait_for_rwp(void)\n{\n\tgic_do_wait_for_rwp(gic_data.dist_base, GICD_CTLR_RWP);\n}\n\n \nstatic void gic_redist_wait_for_rwp(void)\n{\n\tgic_do_wait_for_rwp(gic_data_rdist_rd_base(), GICR_CTLR_RWP);\n}\n\n#ifdef CONFIG_ARM64\n\nstatic u64 __maybe_unused gic_read_iar(void)\n{\n\tif (cpus_have_const_cap(ARM64_WORKAROUND_CAVIUM_23154))\n\t\treturn gic_read_iar_cavium_thunderx();\n\telse\n\t\treturn gic_read_iar_common();\n}\n#endif\n\nstatic void gic_enable_redist(bool enable)\n{\n\tvoid __iomem *rbase;\n\tu32 count = 1000000;\t \n\tu32 val;\n\n\tif (gic_data.flags & FLAGS_WORKAROUND_GICR_WAKER_MSM8996)\n\t\treturn;\n\n\trbase = gic_data_rdist_rd_base();\n\n\tval = readl_relaxed(rbase + GICR_WAKER);\n\tif (enable)\n\t\t \n\t\tval &= ~GICR_WAKER_ProcessorSleep;\n\telse\n\t\tval |= GICR_WAKER_ProcessorSleep;\n\twritel_relaxed(val, rbase + GICR_WAKER);\n\n\tif (!enable) {\t\t \n\t\tval = readl_relaxed(rbase + GICR_WAKER);\n\t\tif (!(val & GICR_WAKER_ProcessorSleep))\n\t\t\treturn;\t \n\t}\n\n\twhile (--count) {\n\t\tval = readl_relaxed(rbase + GICR_WAKER);\n\t\tif (enable ^ (bool)(val & GICR_WAKER_ChildrenAsleep))\n\t\t\tbreak;\n\t\tcpu_relax();\n\t\tudelay(1);\n\t}\n\tif (!count)\n\t\tpr_err_ratelimited(\"redistributor failed to %s...\\n\",\n\t\t\t\t   enable ? \"wakeup\" : \"sleep\");\n}\n\n \nstatic u32 convert_offset_index(struct irq_data *d, u32 offset, u32 *index)\n{\n\tswitch (get_intid_range(d)) {\n\tcase SGI_RANGE:\n\tcase PPI_RANGE:\n\tcase SPI_RANGE:\n\t\t*index = d->hwirq;\n\t\treturn offset;\n\tcase EPPI_RANGE:\n\t\t \n\t\t*index = d->hwirq - EPPI_BASE_INTID + 32;\n\t\treturn offset;\n\tcase ESPI_RANGE:\n\t\t*index = d->hwirq - ESPI_BASE_INTID;\n\t\tswitch (offset) {\n\t\tcase GICD_ISENABLER:\n\t\t\treturn GICD_ISENABLERnE;\n\t\tcase GICD_ICENABLER:\n\t\t\treturn GICD_ICENABLERnE;\n\t\tcase GICD_ISPENDR:\n\t\t\treturn GICD_ISPENDRnE;\n\t\tcase GICD_ICPENDR:\n\t\t\treturn GICD_ICPENDRnE;\n\t\tcase GICD_ISACTIVER:\n\t\t\treturn GICD_ISACTIVERnE;\n\t\tcase GICD_ICACTIVER:\n\t\t\treturn GICD_ICACTIVERnE;\n\t\tcase GICD_IPRIORITYR:\n\t\t\treturn GICD_IPRIORITYRnE;\n\t\tcase GICD_ICFGR:\n\t\t\treturn GICD_ICFGRnE;\n\t\tcase GICD_IROUTER:\n\t\t\treturn GICD_IROUTERnE;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tWARN_ON(1);\n\t*index = d->hwirq;\n\treturn offset;\n}\n\nstatic int gic_peek_irq(struct irq_data *d, u32 offset)\n{\n\tvoid __iomem *base;\n\tu32 index, mask;\n\n\toffset = convert_offset_index(d, offset, &index);\n\tmask = 1 << (index % 32);\n\n\tif (gic_irq_in_rdist(d))\n\t\tbase = gic_data_rdist_sgi_base();\n\telse\n\t\tbase = gic_dist_base_alias(d);\n\n\treturn !!(readl_relaxed(base + offset + (index / 32) * 4) & mask);\n}\n\nstatic void gic_poke_irq(struct irq_data *d, u32 offset)\n{\n\tvoid __iomem *base;\n\tu32 index, mask;\n\n\toffset = convert_offset_index(d, offset, &index);\n\tmask = 1 << (index % 32);\n\n\tif (gic_irq_in_rdist(d))\n\t\tbase = gic_data_rdist_sgi_base();\n\telse\n\t\tbase = gic_data.dist_base;\n\n\twritel_relaxed(mask, base + offset + (index / 32) * 4);\n}\n\nstatic void gic_mask_irq(struct irq_data *d)\n{\n\tgic_poke_irq(d, GICD_ICENABLER);\n\tif (gic_irq_in_rdist(d))\n\t\tgic_redist_wait_for_rwp();\n\telse\n\t\tgic_dist_wait_for_rwp();\n}\n\nstatic void gic_eoimode1_mask_irq(struct irq_data *d)\n{\n\tgic_mask_irq(d);\n\t \n\tif (irqd_is_forwarded_to_vcpu(d))\n\t\tgic_poke_irq(d, GICD_ICACTIVER);\n}\n\nstatic void gic_unmask_irq(struct irq_data *d)\n{\n\tgic_poke_irq(d, GICD_ISENABLER);\n}\n\nstatic inline bool gic_supports_nmi(void)\n{\n\treturn IS_ENABLED(CONFIG_ARM64_PSEUDO_NMI) &&\n\t       static_branch_likely(&supports_pseudo_nmis);\n}\n\nstatic int gic_irq_set_irqchip_state(struct irq_data *d,\n\t\t\t\t     enum irqchip_irq_state which, bool val)\n{\n\tu32 reg;\n\n\tif (d->hwirq >= 8192)  \n\t\treturn -EINVAL;\n\n\tswitch (which) {\n\tcase IRQCHIP_STATE_PENDING:\n\t\treg = val ? GICD_ISPENDR : GICD_ICPENDR;\n\t\tbreak;\n\n\tcase IRQCHIP_STATE_ACTIVE:\n\t\treg = val ? GICD_ISACTIVER : GICD_ICACTIVER;\n\t\tbreak;\n\n\tcase IRQCHIP_STATE_MASKED:\n\t\tif (val) {\n\t\t\tgic_mask_irq(d);\n\t\t\treturn 0;\n\t\t}\n\t\treg = GICD_ISENABLER;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tgic_poke_irq(d, reg);\n\treturn 0;\n}\n\nstatic int gic_irq_get_irqchip_state(struct irq_data *d,\n\t\t\t\t     enum irqchip_irq_state which, bool *val)\n{\n\tif (d->hwirq >= 8192)  \n\t\treturn -EINVAL;\n\n\tswitch (which) {\n\tcase IRQCHIP_STATE_PENDING:\n\t\t*val = gic_peek_irq(d, GICD_ISPENDR);\n\t\tbreak;\n\n\tcase IRQCHIP_STATE_ACTIVE:\n\t\t*val = gic_peek_irq(d, GICD_ISACTIVER);\n\t\tbreak;\n\n\tcase IRQCHIP_STATE_MASKED:\n\t\t*val = !gic_peek_irq(d, GICD_ISENABLER);\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void gic_irq_set_prio(struct irq_data *d, u8 prio)\n{\n\tvoid __iomem *base = gic_dist_base(d);\n\tu32 offset, index;\n\n\toffset = convert_offset_index(d, GICD_IPRIORITYR, &index);\n\n\twriteb_relaxed(prio, base + offset + index);\n}\n\nstatic u32 __gic_get_ppi_index(irq_hw_number_t hwirq)\n{\n\tswitch (__get_intid_range(hwirq)) {\n\tcase PPI_RANGE:\n\t\treturn hwirq - 16;\n\tcase EPPI_RANGE:\n\t\treturn hwirq - EPPI_BASE_INTID + 16;\n\tdefault:\n\t\tunreachable();\n\t}\n}\n\nstatic u32 gic_get_ppi_index(struct irq_data *d)\n{\n\treturn __gic_get_ppi_index(d->hwirq);\n}\n\nstatic int gic_irq_nmi_setup(struct irq_data *d)\n{\n\tstruct irq_desc *desc = irq_to_desc(d->irq);\n\n\tif (!gic_supports_nmi())\n\t\treturn -EINVAL;\n\n\tif (gic_peek_irq(d, GICD_ISENABLER)) {\n\t\tpr_err(\"Cannot set NMI property of enabled IRQ %u\\n\", d->irq);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (WARN_ON(gic_irq(d) >= 8192))\n\t\treturn -EINVAL;\n\n\t \n\tif (gic_irq_in_rdist(d)) {\n\t\tu32 idx = gic_get_ppi_index(d);\n\n\t\t \n\t\tif (!refcount_inc_not_zero(&ppi_nmi_refs[idx])) {\n\t\t\trefcount_set(&ppi_nmi_refs[idx], 1);\n\t\t\tdesc->handle_irq = handle_percpu_devid_fasteoi_nmi;\n\t\t}\n\t} else {\n\t\tdesc->handle_irq = handle_fasteoi_nmi;\n\t}\n\n\tgic_irq_set_prio(d, GICD_INT_NMI_PRI);\n\n\treturn 0;\n}\n\nstatic void gic_irq_nmi_teardown(struct irq_data *d)\n{\n\tstruct irq_desc *desc = irq_to_desc(d->irq);\n\n\tif (WARN_ON(!gic_supports_nmi()))\n\t\treturn;\n\n\tif (gic_peek_irq(d, GICD_ISENABLER)) {\n\t\tpr_err(\"Cannot set NMI property of enabled IRQ %u\\n\", d->irq);\n\t\treturn;\n\t}\n\n\t \n\tif (WARN_ON(gic_irq(d) >= 8192))\n\t\treturn;\n\n\t \n\tif (gic_irq_in_rdist(d)) {\n\t\tu32 idx = gic_get_ppi_index(d);\n\n\t\t \n\t\tif (refcount_dec_and_test(&ppi_nmi_refs[idx]))\n\t\t\tdesc->handle_irq = handle_percpu_devid_irq;\n\t} else {\n\t\tdesc->handle_irq = handle_fasteoi_irq;\n\t}\n\n\tgic_irq_set_prio(d, GICD_INT_DEF_PRI);\n}\n\nstatic bool gic_arm64_erratum_2941627_needed(struct irq_data *d)\n{\n\tenum gic_intid_range range;\n\n\tif (!static_branch_unlikely(&gic_arm64_2941627_erratum))\n\t\treturn false;\n\n\trange = get_intid_range(d);\n\n\t \n\treturn (range == SPI_RANGE || range == ESPI_RANGE) &&\n\t\t!cpumask_test_cpu(raw_smp_processor_id(),\n\t\t\t\t  irq_data_get_effective_affinity_mask(d));\n}\n\nstatic void gic_eoi_irq(struct irq_data *d)\n{\n\twrite_gicreg(gic_irq(d), ICC_EOIR1_EL1);\n\tisb();\n\n\tif (gic_arm64_erratum_2941627_needed(d)) {\n\t\t \n\t\tdsb(sy);\n\t\tgic_poke_irq(d, GICD_ICACTIVER);\n\t}\n}\n\nstatic void gic_eoimode1_eoi_irq(struct irq_data *d)\n{\n\t \n\tif (gic_irq(d) >= 8192 || irqd_is_forwarded_to_vcpu(d))\n\t\treturn;\n\n\tif (!gic_arm64_erratum_2941627_needed(d))\n\t\tgic_write_dir(gic_irq(d));\n\telse\n\t\tgic_poke_irq(d, GICD_ICACTIVER);\n}\n\nstatic int gic_set_type(struct irq_data *d, unsigned int type)\n{\n\tenum gic_intid_range range;\n\tunsigned int irq = gic_irq(d);\n\tvoid __iomem *base;\n\tu32 offset, index;\n\tint ret;\n\n\trange = get_intid_range(d);\n\n\t \n\tif (range == SGI_RANGE)\n\t\treturn type != IRQ_TYPE_EDGE_RISING ? -EINVAL : 0;\n\n\t \n\tif ((range == SPI_RANGE || range == ESPI_RANGE) &&\n\t    type != IRQ_TYPE_LEVEL_HIGH && type != IRQ_TYPE_EDGE_RISING)\n\t\treturn -EINVAL;\n\n\tif (gic_irq_in_rdist(d))\n\t\tbase = gic_data_rdist_sgi_base();\n\telse\n\t\tbase = gic_dist_base_alias(d);\n\n\toffset = convert_offset_index(d, GICD_ICFGR, &index);\n\n\tret = gic_configure_irq(index, type, base + offset, NULL);\n\tif (ret && (range == PPI_RANGE || range == EPPI_RANGE)) {\n\t\t \n\t\tpr_warn(\"GIC: PPI INTID%d is secure or misconfigured\\n\", irq);\n\t\tret = 0;\n\t}\n\n\treturn ret;\n}\n\nstatic int gic_irq_set_vcpu_affinity(struct irq_data *d, void *vcpu)\n{\n\tif (get_intid_range(d) == SGI_RANGE)\n\t\treturn -EINVAL;\n\n\tif (vcpu)\n\t\tirqd_set_forwarded_to_vcpu(d);\n\telse\n\t\tirqd_clr_forwarded_to_vcpu(d);\n\treturn 0;\n}\n\nstatic u64 gic_cpu_to_affinity(int cpu)\n{\n\tu64 mpidr = cpu_logical_map(cpu);\n\tu64 aff;\n\n\t \n\tif (unlikely(gic_data.flags & FLAGS_WORKAROUND_ASR_ERRATUM_8601001))\n\t\tmpidr = (MPIDR_AFFINITY_LEVEL(mpidr, 1)\t|\n\t\t\t (MPIDR_AFFINITY_LEVEL(mpidr, 2) << 8));\n\n\taff = ((u64)MPIDR_AFFINITY_LEVEL(mpidr, 3) << 32 |\n\t       MPIDR_AFFINITY_LEVEL(mpidr, 2) << 16 |\n\t       MPIDR_AFFINITY_LEVEL(mpidr, 1) << 8  |\n\t       MPIDR_AFFINITY_LEVEL(mpidr, 0));\n\n\treturn aff;\n}\n\nstatic void gic_deactivate_unhandled(u32 irqnr)\n{\n\tif (static_branch_likely(&supports_deactivate_key)) {\n\t\tif (irqnr < 8192)\n\t\t\tgic_write_dir(irqnr);\n\t} else {\n\t\twrite_gicreg(irqnr, ICC_EOIR1_EL1);\n\t\tisb();\n\t}\n}\n\n \nstatic inline void gic_complete_ack(u32 irqnr)\n{\n\tif (static_branch_likely(&supports_deactivate_key))\n\t\twrite_gicreg(irqnr, ICC_EOIR1_EL1);\n\n\tisb();\n}\n\nstatic bool gic_rpr_is_nmi_prio(void)\n{\n\tif (!gic_supports_nmi())\n\t\treturn false;\n\n\treturn unlikely(gic_read_rpr() == GICD_INT_RPR_PRI(GICD_INT_NMI_PRI));\n}\n\nstatic bool gic_irqnr_is_special(u32 irqnr)\n{\n\treturn irqnr >= 1020 && irqnr <= 1023;\n}\n\nstatic void __gic_handle_irq(u32 irqnr, struct pt_regs *regs)\n{\n\tif (gic_irqnr_is_special(irqnr))\n\t\treturn;\n\n\tgic_complete_ack(irqnr);\n\n\tif (generic_handle_domain_irq(gic_data.domain, irqnr)) {\n\t\tWARN_ONCE(true, \"Unexpected interrupt (irqnr %u)\\n\", irqnr);\n\t\tgic_deactivate_unhandled(irqnr);\n\t}\n}\n\nstatic void __gic_handle_nmi(u32 irqnr, struct pt_regs *regs)\n{\n\tif (gic_irqnr_is_special(irqnr))\n\t\treturn;\n\n\tgic_complete_ack(irqnr);\n\n\tif (generic_handle_domain_nmi(gic_data.domain, irqnr)) {\n\t\tWARN_ONCE(true, \"Unexpected pseudo-NMI (irqnr %u)\\n\", irqnr);\n\t\tgic_deactivate_unhandled(irqnr);\n\t}\n}\n\n \nstatic void __gic_handle_irq_from_irqson(struct pt_regs *regs)\n{\n\tbool is_nmi;\n\tu32 irqnr;\n\n\tirqnr = gic_read_iar();\n\n\tis_nmi = gic_rpr_is_nmi_prio();\n\n\tif (is_nmi) {\n\t\tnmi_enter();\n\t\t__gic_handle_nmi(irqnr, regs);\n\t\tnmi_exit();\n\t}\n\n\tif (gic_prio_masking_enabled()) {\n\t\tgic_pmr_mask_irqs();\n\t\tgic_arch_enable_irqs();\n\t}\n\n\tif (!is_nmi)\n\t\t__gic_handle_irq(irqnr, regs);\n}\n\n \nstatic void __gic_handle_irq_from_irqsoff(struct pt_regs *regs)\n{\n\tu64 pmr;\n\tu32 irqnr;\n\n\t \n\tpmr = gic_read_pmr();\n\tgic_pmr_mask_irqs();\n\tisb();\n\tirqnr = gic_read_iar();\n\tgic_write_pmr(pmr);\n\n\t__gic_handle_nmi(irqnr, regs);\n}\n\nstatic asmlinkage void __exception_irq_entry gic_handle_irq(struct pt_regs *regs)\n{\n\tif (unlikely(gic_supports_nmi() && !interrupts_enabled(regs)))\n\t\t__gic_handle_irq_from_irqsoff(regs);\n\telse\n\t\t__gic_handle_irq_from_irqson(regs);\n}\n\nstatic u32 gic_get_pribits(void)\n{\n\tu32 pribits;\n\n\tpribits = gic_read_ctlr();\n\tpribits &= ICC_CTLR_EL1_PRI_BITS_MASK;\n\tpribits >>= ICC_CTLR_EL1_PRI_BITS_SHIFT;\n\tpribits++;\n\n\treturn pribits;\n}\n\nstatic bool gic_has_group0(void)\n{\n\tu32 val;\n\tu32 old_pmr;\n\n\told_pmr = gic_read_pmr();\n\n\t \n\tgic_write_pmr(BIT(8 - gic_get_pribits()));\n\tval = gic_read_pmr();\n\n\tgic_write_pmr(old_pmr);\n\n\treturn val != 0;\n}\n\nstatic void __init gic_dist_init(void)\n{\n\tunsigned int i;\n\tu64 affinity;\n\tvoid __iomem *base = gic_data.dist_base;\n\tu32 val;\n\n\t \n\twritel_relaxed(0, base + GICD_CTLR);\n\tgic_dist_wait_for_rwp();\n\n\t \n\tfor (i = 32; i < GIC_LINE_NR; i += 32)\n\t\twritel_relaxed(~0, base + GICD_IGROUPR + i / 8);\n\n\t \n\tfor (i = 0; i < GIC_ESPI_NR; i += 32) {\n\t\twritel_relaxed(~0U, base + GICD_ICENABLERnE + i / 8);\n\t\twritel_relaxed(~0U, base + GICD_ICACTIVERnE + i / 8);\n\t}\n\n\tfor (i = 0; i < GIC_ESPI_NR; i += 32)\n\t\twritel_relaxed(~0U, base + GICD_IGROUPRnE + i / 8);\n\n\tfor (i = 0; i < GIC_ESPI_NR; i += 16)\n\t\twritel_relaxed(0, base + GICD_ICFGRnE + i / 4);\n\n\tfor (i = 0; i < GIC_ESPI_NR; i += 4)\n\t\twritel_relaxed(GICD_INT_DEF_PRI_X4, base + GICD_IPRIORITYRnE + i);\n\n\t \n\tgic_dist_config(base, GIC_LINE_NR, NULL);\n\n\tval = GICD_CTLR_ARE_NS | GICD_CTLR_ENABLE_G1A | GICD_CTLR_ENABLE_G1;\n\tif (gic_data.rdists.gicd_typer2 & GICD_TYPER2_nASSGIcap) {\n\t\tpr_info(\"Enabling SGIs without active state\\n\");\n\t\tval |= GICD_CTLR_nASSGIreq;\n\t}\n\n\t \n\twritel_relaxed(val, base + GICD_CTLR);\n\tgic_dist_wait_for_rwp();\n\n\t \n\taffinity = gic_cpu_to_affinity(smp_processor_id());\n\tfor (i = 32; i < GIC_LINE_NR; i++)\n\t\tgic_write_irouter(affinity, base + GICD_IROUTER + i * 8);\n\n\tfor (i = 0; i < GIC_ESPI_NR; i++)\n\t\tgic_write_irouter(affinity, base + GICD_IROUTERnE + i * 8);\n}\n\nstatic int gic_iterate_rdists(int (*fn)(struct redist_region *, void __iomem *))\n{\n\tint ret = -ENODEV;\n\tint i;\n\n\tfor (i = 0; i < gic_data.nr_redist_regions; i++) {\n\t\tvoid __iomem *ptr = gic_data.redist_regions[i].redist_base;\n\t\tu64 typer;\n\t\tu32 reg;\n\n\t\treg = readl_relaxed(ptr + GICR_PIDR2) & GIC_PIDR2_ARCH_MASK;\n\t\tif (reg != GIC_PIDR2_ARCH_GICv3 &&\n\t\t    reg != GIC_PIDR2_ARCH_GICv4) {  \n\t\t\tpr_warn(\"No redistributor present @%p\\n\", ptr);\n\t\t\tbreak;\n\t\t}\n\n\t\tdo {\n\t\t\ttyper = gic_read_typer(ptr + GICR_TYPER);\n\t\t\tret = fn(gic_data.redist_regions + i, ptr);\n\t\t\tif (!ret)\n\t\t\t\treturn 0;\n\n\t\t\tif (gic_data.redist_regions[i].single_redist)\n\t\t\t\tbreak;\n\n\t\t\tif (gic_data.redist_stride) {\n\t\t\t\tptr += gic_data.redist_stride;\n\t\t\t} else {\n\t\t\t\tptr += SZ_64K * 2;  \n\t\t\t\tif (typer & GICR_TYPER_VLPIS)\n\t\t\t\t\tptr += SZ_64K * 2;  \n\t\t\t}\n\t\t} while (!(typer & GICR_TYPER_LAST));\n\t}\n\n\treturn ret ? -ENODEV : 0;\n}\n\nstatic int __gic_populate_rdist(struct redist_region *region, void __iomem *ptr)\n{\n\tunsigned long mpidr;\n\tu64 typer;\n\tu32 aff;\n\n\t \n\tmpidr = gic_cpu_to_affinity(smp_processor_id());\n\n\taff = (MPIDR_AFFINITY_LEVEL(mpidr, 3) << 24 |\n\t       MPIDR_AFFINITY_LEVEL(mpidr, 2) << 16 |\n\t       MPIDR_AFFINITY_LEVEL(mpidr, 1) << 8 |\n\t       MPIDR_AFFINITY_LEVEL(mpidr, 0));\n\n\ttyper = gic_read_typer(ptr + GICR_TYPER);\n\tif ((typer >> 32) == aff) {\n\t\tu64 offset = ptr - region->redist_base;\n\t\traw_spin_lock_init(&gic_data_rdist()->rd_lock);\n\t\tgic_data_rdist_rd_base() = ptr;\n\t\tgic_data_rdist()->phys_base = region->phys_base + offset;\n\n\t\tpr_info(\"CPU%d: found redistributor %lx region %d:%pa\\n\",\n\t\t\tsmp_processor_id(), mpidr,\n\t\t\t(int)(region - gic_data.redist_regions),\n\t\t\t&gic_data_rdist()->phys_base);\n\t\treturn 0;\n\t}\n\n\t \n\treturn 1;\n}\n\nstatic int gic_populate_rdist(void)\n{\n\tif (gic_iterate_rdists(__gic_populate_rdist) == 0)\n\t\treturn 0;\n\n\t \n\tWARN(true, \"CPU%d: mpidr %lx has no re-distributor!\\n\",\n\t     smp_processor_id(),\n\t     (unsigned long)cpu_logical_map(smp_processor_id()));\n\treturn -ENODEV;\n}\n\nstatic int __gic_update_rdist_properties(struct redist_region *region,\n\t\t\t\t\t void __iomem *ptr)\n{\n\tu64 typer = gic_read_typer(ptr + GICR_TYPER);\n\tu32 ctlr = readl_relaxed(ptr + GICR_CTLR);\n\n\t \n\tif ((typer & GICR_TYPER_VLPIS) && (typer & GICR_TYPER_RVPEID)) {\n\t\tu64 val;\n\n\t\t \n\t\tval = gicr_read_vpendbaser(ptr + SZ_128K + GICR_VPENDBASER);\n\t\tif (val & GICR_VPENDBASER_Valid)\n\t\t\tgicr_write_vpendbaser(GICR_VPENDBASER_PendingLast,\n\t\t\t\t\t      ptr + SZ_128K + GICR_VPENDBASER);\n\n\t\t \n\t\tval = gicr_read_vpropbaser(ptr + SZ_128K + GICR_VPROPBASER);\n\t\tval &= ~GICR_VPROPBASER_4_1_VALID;\n\t\tgicr_write_vpropbaser(val, ptr + SZ_128K + GICR_VPROPBASER);\n\t}\n\n\tgic_data.rdists.has_vlpis &= !!(typer & GICR_TYPER_VLPIS);\n\n\t \n\tgic_data.rdists.has_rvpeid &= !!(typer & GICR_TYPER_RVPEID);\n\tgic_data.rdists.has_direct_lpi &= (!!(typer & GICR_TYPER_DirectLPIS) |\n\t\t\t\t\t   !!(ctlr & GICR_CTLR_IR) |\n\t\t\t\t\t   gic_data.rdists.has_rvpeid);\n\tgic_data.rdists.has_vpend_valid_dirty &= !!(typer & GICR_TYPER_DIRTY);\n\n\t \n\tif (WARN_ON_ONCE(gic_data.rdists.has_rvpeid && !gic_data.rdists.has_vlpis)) {\n\t\tgic_data.rdists.has_direct_lpi = false;\n\t\tgic_data.rdists.has_vlpis = false;\n\t\tgic_data.rdists.has_rvpeid = false;\n\t}\n\n\tgic_data.ppi_nr = min(GICR_TYPER_NR_PPIS(typer), gic_data.ppi_nr);\n\n\treturn 1;\n}\n\nstatic void gic_update_rdist_properties(void)\n{\n\tgic_data.ppi_nr = UINT_MAX;\n\tgic_iterate_rdists(__gic_update_rdist_properties);\n\tif (WARN_ON(gic_data.ppi_nr == UINT_MAX))\n\t\tgic_data.ppi_nr = 0;\n\tpr_info(\"GICv3 features: %d PPIs%s%s\\n\",\n\t\tgic_data.ppi_nr,\n\t\tgic_data.has_rss ? \", RSS\" : \"\",\n\t\tgic_data.rdists.has_direct_lpi ? \", DirectLPI\" : \"\");\n\n\tif (gic_data.rdists.has_vlpis)\n\t\tpr_info(\"GICv4 features: %s%s%s\\n\",\n\t\t\tgic_data.rdists.has_direct_lpi ? \"DirectLPI \" : \"\",\n\t\t\tgic_data.rdists.has_rvpeid ? \"RVPEID \" : \"\",\n\t\t\tgic_data.rdists.has_vpend_valid_dirty ? \"Valid+Dirty \" : \"\");\n}\n\n \nstatic inline bool gic_dist_security_disabled(void)\n{\n\treturn readl_relaxed(gic_data.dist_base + GICD_CTLR) & GICD_CTLR_DS;\n}\n\nstatic void gic_cpu_sys_reg_init(void)\n{\n\tint i, cpu = smp_processor_id();\n\tu64 mpidr = gic_cpu_to_affinity(cpu);\n\tu64 need_rss = MPIDR_RS(mpidr);\n\tbool group0;\n\tu32 pribits;\n\n\t \n\tif (!gic_enable_sre())\n\t\tpr_err(\"GIC: unable to set SRE (disabled at EL2), panic ahead\\n\");\n\n\tpribits = gic_get_pribits();\n\n\tgroup0 = gic_has_group0();\n\n\t \n\tif (!gic_prio_masking_enabled()) {\n\t\twrite_gicreg(DEFAULT_PMR_VALUE, ICC_PMR_EL1);\n\t} else if (gic_supports_nmi()) {\n\t\t \n\t\tif (static_branch_unlikely(&gic_nonsecure_priorities))\n\t\t\tWARN_ON(!group0 || gic_dist_security_disabled());\n\t\telse\n\t\t\tWARN_ON(group0 && !gic_dist_security_disabled());\n\t}\n\n\t \n\tgic_write_bpr1(0);\n\n\tif (static_branch_likely(&supports_deactivate_key)) {\n\t\t \n\t\tgic_write_ctlr(ICC_CTLR_EL1_EOImode_drop);\n\t} else {\n\t\t \n\t\tgic_write_ctlr(ICC_CTLR_EL1_EOImode_drop_dir);\n\t}\n\n\t \n\tif (group0) {\n\t\tswitch(pribits) {\n\t\tcase 8:\n\t\tcase 7:\n\t\t\twrite_gicreg(0, ICC_AP0R3_EL1);\n\t\t\twrite_gicreg(0, ICC_AP0R2_EL1);\n\t\t\tfallthrough;\n\t\tcase 6:\n\t\t\twrite_gicreg(0, ICC_AP0R1_EL1);\n\t\t\tfallthrough;\n\t\tcase 5:\n\t\tcase 4:\n\t\t\twrite_gicreg(0, ICC_AP0R0_EL1);\n\t\t}\n\n\t\tisb();\n\t}\n\n\tswitch(pribits) {\n\tcase 8:\n\tcase 7:\n\t\twrite_gicreg(0, ICC_AP1R3_EL1);\n\t\twrite_gicreg(0, ICC_AP1R2_EL1);\n\t\tfallthrough;\n\tcase 6:\n\t\twrite_gicreg(0, ICC_AP1R1_EL1);\n\t\tfallthrough;\n\tcase 5:\n\tcase 4:\n\t\twrite_gicreg(0, ICC_AP1R0_EL1);\n\t}\n\n\tisb();\n\n\t \n\tgic_write_grpen1(1);\n\n\t \n\tper_cpu(has_rss, cpu) = !!(gic_read_ctlr() & ICC_CTLR_EL1_RSS);\n\n\t \n\tfor_each_online_cpu(i) {\n\t\tbool have_rss = per_cpu(has_rss, i) && per_cpu(has_rss, cpu);\n\n\t\tneed_rss |= MPIDR_RS(gic_cpu_to_affinity(i));\n\t\tif (need_rss && (!have_rss))\n\t\t\tpr_crit(\"CPU%d (%lx) can't SGI CPU%d (%lx), no RSS\\n\",\n\t\t\t\tcpu, (unsigned long)mpidr,\n\t\t\t\ti, (unsigned long)gic_cpu_to_affinity(i));\n\t}\n\n\t \n\tif (need_rss && (!gic_data.has_rss))\n\t\tpr_crit_once(\"RSS is required but GICD doesn't support it\\n\");\n}\n\nstatic bool gicv3_nolpi;\n\nstatic int __init gicv3_nolpi_cfg(char *buf)\n{\n\treturn kstrtobool(buf, &gicv3_nolpi);\n}\nearly_param(\"irqchip.gicv3_nolpi\", gicv3_nolpi_cfg);\n\nstatic int gic_dist_supports_lpis(void)\n{\n\treturn (IS_ENABLED(CONFIG_ARM_GIC_V3_ITS) &&\n\t\t!!(readl_relaxed(gic_data.dist_base + GICD_TYPER) & GICD_TYPER_LPIS) &&\n\t\t!gicv3_nolpi);\n}\n\nstatic void gic_cpu_init(void)\n{\n\tvoid __iomem *rbase;\n\tint i;\n\n\t \n\tif (gic_populate_rdist())\n\t\treturn;\n\n\tgic_enable_redist(true);\n\n\tWARN((gic_data.ppi_nr > 16 || GIC_ESPI_NR != 0) &&\n\t     !(gic_read_ctlr() & ICC_CTLR_EL1_ExtRange),\n\t     \"Distributor has extended ranges, but CPU%d doesn't\\n\",\n\t     smp_processor_id());\n\n\trbase = gic_data_rdist_sgi_base();\n\n\t \n\tfor (i = 0; i < gic_data.ppi_nr + 16; i += 32)\n\t\twritel_relaxed(~0, rbase + GICR_IGROUPR0 + i / 8);\n\n\tgic_cpu_config(rbase, gic_data.ppi_nr + 16, gic_redist_wait_for_rwp);\n\n\t \n\tgic_cpu_sys_reg_init();\n}\n\n#ifdef CONFIG_SMP\n\n#define MPIDR_TO_SGI_RS(mpidr)\t(MPIDR_RS(mpidr) << ICC_SGI1R_RS_SHIFT)\n#define MPIDR_TO_SGI_CLUSTER_ID(mpidr)\t((mpidr) & ~0xFUL)\n\nstatic int gic_starting_cpu(unsigned int cpu)\n{\n\tgic_cpu_init();\n\n\tif (gic_dist_supports_lpis())\n\t\tits_cpu_init();\n\n\treturn 0;\n}\n\nstatic u16 gic_compute_target_list(int *base_cpu, const struct cpumask *mask,\n\t\t\t\t   unsigned long cluster_id)\n{\n\tint next_cpu, cpu = *base_cpu;\n\tunsigned long mpidr;\n\tu16 tlist = 0;\n\n\tmpidr = gic_cpu_to_affinity(cpu);\n\n\twhile (cpu < nr_cpu_ids) {\n\t\ttlist |= 1 << (mpidr & 0xf);\n\n\t\tnext_cpu = cpumask_next(cpu, mask);\n\t\tif (next_cpu >= nr_cpu_ids)\n\t\t\tgoto out;\n\t\tcpu = next_cpu;\n\n\t\tmpidr = gic_cpu_to_affinity(cpu);\n\n\t\tif (cluster_id != MPIDR_TO_SGI_CLUSTER_ID(mpidr)) {\n\t\t\tcpu--;\n\t\t\tgoto out;\n\t\t}\n\t}\nout:\n\t*base_cpu = cpu;\n\treturn tlist;\n}\n\n#define MPIDR_TO_SGI_AFFINITY(cluster_id, level) \\\n\t(MPIDR_AFFINITY_LEVEL(cluster_id, level) \\\n\t\t<< ICC_SGI1R_AFFINITY_## level ##_SHIFT)\n\nstatic void gic_send_sgi(u64 cluster_id, u16 tlist, unsigned int irq)\n{\n\tu64 val;\n\n\tval = (MPIDR_TO_SGI_AFFINITY(cluster_id, 3)\t|\n\t       MPIDR_TO_SGI_AFFINITY(cluster_id, 2)\t|\n\t       irq << ICC_SGI1R_SGI_ID_SHIFT\t\t|\n\t       MPIDR_TO_SGI_AFFINITY(cluster_id, 1)\t|\n\t       MPIDR_TO_SGI_RS(cluster_id)\t\t|\n\t       tlist << ICC_SGI1R_TARGET_LIST_SHIFT);\n\n\tpr_devel(\"CPU%d: ICC_SGI1R_EL1 %llx\\n\", smp_processor_id(), val);\n\tgic_write_sgi1r(val);\n}\n\nstatic void gic_ipi_send_mask(struct irq_data *d, const struct cpumask *mask)\n{\n\tint cpu;\n\n\tif (WARN_ON(d->hwirq >= 16))\n\t\treturn;\n\n\t \n\tdsb(ishst);\n\n\tfor_each_cpu(cpu, mask) {\n\t\tu64 cluster_id = MPIDR_TO_SGI_CLUSTER_ID(gic_cpu_to_affinity(cpu));\n\t\tu16 tlist;\n\n\t\ttlist = gic_compute_target_list(&cpu, mask, cluster_id);\n\t\tgic_send_sgi(cluster_id, tlist, d->hwirq);\n\t}\n\n\t \n\tisb();\n}\n\nstatic void __init gic_smp_init(void)\n{\n\tstruct irq_fwspec sgi_fwspec = {\n\t\t.fwnode\t\t= gic_data.fwnode,\n\t\t.param_count\t= 1,\n\t};\n\tint base_sgi;\n\n\tcpuhp_setup_state_nocalls(CPUHP_AP_IRQ_GIC_STARTING,\n\t\t\t\t  \"irqchip/arm/gicv3:starting\",\n\t\t\t\t  gic_starting_cpu, NULL);\n\n\t \n\tbase_sgi = irq_domain_alloc_irqs(gic_data.domain, 8, NUMA_NO_NODE, &sgi_fwspec);\n\tif (WARN_ON(base_sgi <= 0))\n\t\treturn;\n\n\tset_smp_ipi_range(base_sgi, 8);\n}\n\nstatic int gic_set_affinity(struct irq_data *d, const struct cpumask *mask_val,\n\t\t\t    bool force)\n{\n\tunsigned int cpu;\n\tu32 offset, index;\n\tvoid __iomem *reg;\n\tint enabled;\n\tu64 val;\n\n\tif (force)\n\t\tcpu = cpumask_first(mask_val);\n\telse\n\t\tcpu = cpumask_any_and(mask_val, cpu_online_mask);\n\n\tif (cpu >= nr_cpu_ids)\n\t\treturn -EINVAL;\n\n\tif (gic_irq_in_rdist(d))\n\t\treturn -EINVAL;\n\n\t \n\tenabled = gic_peek_irq(d, GICD_ISENABLER);\n\tif (enabled)\n\t\tgic_mask_irq(d);\n\n\toffset = convert_offset_index(d, GICD_IROUTER, &index);\n\treg = gic_dist_base(d) + offset + (index * 8);\n\tval = gic_cpu_to_affinity(cpu);\n\n\tgic_write_irouter(val, reg);\n\n\t \n\tif (enabled)\n\t\tgic_unmask_irq(d);\n\n\tirq_data_update_effective_affinity(d, cpumask_of(cpu));\n\n\treturn IRQ_SET_MASK_OK_DONE;\n}\n#else\n#define gic_set_affinity\tNULL\n#define gic_ipi_send_mask\tNULL\n#define gic_smp_init()\t\tdo { } while(0)\n#endif\n\nstatic int gic_retrigger(struct irq_data *data)\n{\n\treturn !gic_irq_set_irqchip_state(data, IRQCHIP_STATE_PENDING, true);\n}\n\n#ifdef CONFIG_CPU_PM\nstatic int gic_cpu_pm_notifier(struct notifier_block *self,\n\t\t\t       unsigned long cmd, void *v)\n{\n\tif (cmd == CPU_PM_EXIT) {\n\t\tif (gic_dist_security_disabled())\n\t\t\tgic_enable_redist(true);\n\t\tgic_cpu_sys_reg_init();\n\t} else if (cmd == CPU_PM_ENTER && gic_dist_security_disabled()) {\n\t\tgic_write_grpen1(0);\n\t\tgic_enable_redist(false);\n\t}\n\treturn NOTIFY_OK;\n}\n\nstatic struct notifier_block gic_cpu_pm_notifier_block = {\n\t.notifier_call = gic_cpu_pm_notifier,\n};\n\nstatic void gic_cpu_pm_init(void)\n{\n\tcpu_pm_register_notifier(&gic_cpu_pm_notifier_block);\n}\n\n#else\nstatic inline void gic_cpu_pm_init(void) { }\n#endif  \n\nstatic struct irq_chip gic_chip = {\n\t.name\t\t\t= \"GICv3\",\n\t.irq_mask\t\t= gic_mask_irq,\n\t.irq_unmask\t\t= gic_unmask_irq,\n\t.irq_eoi\t\t= gic_eoi_irq,\n\t.irq_set_type\t\t= gic_set_type,\n\t.irq_set_affinity\t= gic_set_affinity,\n\t.irq_retrigger          = gic_retrigger,\n\t.irq_get_irqchip_state\t= gic_irq_get_irqchip_state,\n\t.irq_set_irqchip_state\t= gic_irq_set_irqchip_state,\n\t.irq_nmi_setup\t\t= gic_irq_nmi_setup,\n\t.irq_nmi_teardown\t= gic_irq_nmi_teardown,\n\t.ipi_send_mask\t\t= gic_ipi_send_mask,\n\t.flags\t\t\t= IRQCHIP_SET_TYPE_MASKED |\n\t\t\t\t  IRQCHIP_SKIP_SET_WAKE |\n\t\t\t\t  IRQCHIP_MASK_ON_SUSPEND,\n};\n\nstatic struct irq_chip gic_eoimode1_chip = {\n\t.name\t\t\t= \"GICv3\",\n\t.irq_mask\t\t= gic_eoimode1_mask_irq,\n\t.irq_unmask\t\t= gic_unmask_irq,\n\t.irq_eoi\t\t= gic_eoimode1_eoi_irq,\n\t.irq_set_type\t\t= gic_set_type,\n\t.irq_set_affinity\t= gic_set_affinity,\n\t.irq_retrigger          = gic_retrigger,\n\t.irq_get_irqchip_state\t= gic_irq_get_irqchip_state,\n\t.irq_set_irqchip_state\t= gic_irq_set_irqchip_state,\n\t.irq_set_vcpu_affinity\t= gic_irq_set_vcpu_affinity,\n\t.irq_nmi_setup\t\t= gic_irq_nmi_setup,\n\t.irq_nmi_teardown\t= gic_irq_nmi_teardown,\n\t.ipi_send_mask\t\t= gic_ipi_send_mask,\n\t.flags\t\t\t= IRQCHIP_SET_TYPE_MASKED |\n\t\t\t\t  IRQCHIP_SKIP_SET_WAKE |\n\t\t\t\t  IRQCHIP_MASK_ON_SUSPEND,\n};\n\nstatic int gic_irq_domain_map(struct irq_domain *d, unsigned int irq,\n\t\t\t      irq_hw_number_t hw)\n{\n\tstruct irq_chip *chip = &gic_chip;\n\tstruct irq_data *irqd = irq_desc_get_irq_data(irq_to_desc(irq));\n\n\tif (static_branch_likely(&supports_deactivate_key))\n\t\tchip = &gic_eoimode1_chip;\n\n\tswitch (__get_intid_range(hw)) {\n\tcase SGI_RANGE:\n\tcase PPI_RANGE:\n\tcase EPPI_RANGE:\n\t\tirq_set_percpu_devid(irq);\n\t\tirq_domain_set_info(d, irq, hw, chip, d->host_data,\n\t\t\t\t    handle_percpu_devid_irq, NULL, NULL);\n\t\tbreak;\n\n\tcase SPI_RANGE:\n\tcase ESPI_RANGE:\n\t\tirq_domain_set_info(d, irq, hw, chip, d->host_data,\n\t\t\t\t    handle_fasteoi_irq, NULL, NULL);\n\t\tirq_set_probe(irq);\n\t\tirqd_set_single_target(irqd);\n\t\tbreak;\n\n\tcase LPI_RANGE:\n\t\tif (!gic_dist_supports_lpis())\n\t\t\treturn -EPERM;\n\t\tirq_domain_set_info(d, irq, hw, chip, d->host_data,\n\t\t\t\t    handle_fasteoi_irq, NULL, NULL);\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EPERM;\n\t}\n\n\t \n\tirqd_set_handle_enforce_irqctx(irqd);\n\treturn 0;\n}\n\nstatic int gic_irq_domain_translate(struct irq_domain *d,\n\t\t\t\t    struct irq_fwspec *fwspec,\n\t\t\t\t    unsigned long *hwirq,\n\t\t\t\t    unsigned int *type)\n{\n\tif (fwspec->param_count == 1 && fwspec->param[0] < 16) {\n\t\t*hwirq = fwspec->param[0];\n\t\t*type = IRQ_TYPE_EDGE_RISING;\n\t\treturn 0;\n\t}\n\n\tif (is_of_node(fwspec->fwnode)) {\n\t\tif (fwspec->param_count < 3)\n\t\t\treturn -EINVAL;\n\n\t\tswitch (fwspec->param[0]) {\n\t\tcase 0:\t\t\t \n\t\t\t*hwirq = fwspec->param[1] + 32;\n\t\t\tbreak;\n\t\tcase 1:\t\t\t \n\t\t\t*hwirq = fwspec->param[1] + 16;\n\t\t\tbreak;\n\t\tcase 2:\t\t\t \n\t\t\t*hwirq = fwspec->param[1] + ESPI_BASE_INTID;\n\t\t\tbreak;\n\t\tcase 3:\t\t\t \n\t\t\t*hwirq = fwspec->param[1] + EPPI_BASE_INTID;\n\t\t\tbreak;\n\t\tcase GIC_IRQ_TYPE_LPI:\t \n\t\t\t*hwirq = fwspec->param[1];\n\t\t\tbreak;\n\t\tcase GIC_IRQ_TYPE_PARTITION:\n\t\t\t*hwirq = fwspec->param[1];\n\t\t\tif (fwspec->param[1] >= 16)\n\t\t\t\t*hwirq += EPPI_BASE_INTID - 16;\n\t\t\telse\n\t\t\t\t*hwirq += 16;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t*type = fwspec->param[2] & IRQ_TYPE_SENSE_MASK;\n\n\t\t \n\t\tWARN_ON(*type == IRQ_TYPE_NONE &&\n\t\t\tfwspec->param[0] != GIC_IRQ_TYPE_PARTITION);\n\t\treturn 0;\n\t}\n\n\tif (is_fwnode_irqchip(fwspec->fwnode)) {\n\t\tif(fwspec->param_count != 2)\n\t\t\treturn -EINVAL;\n\n\t\tif (fwspec->param[0] < 16) {\n\t\t\tpr_err(FW_BUG \"Illegal GSI%d translation request\\n\",\n\t\t\t       fwspec->param[0]);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t*hwirq = fwspec->param[0];\n\t\t*type = fwspec->param[1];\n\n\t\tWARN_ON(*type == IRQ_TYPE_NONE);\n\t\treturn 0;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int gic_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,\n\t\t\t\tunsigned int nr_irqs, void *arg)\n{\n\tint i, ret;\n\tirq_hw_number_t hwirq;\n\tunsigned int type = IRQ_TYPE_NONE;\n\tstruct irq_fwspec *fwspec = arg;\n\n\tret = gic_irq_domain_translate(domain, fwspec, &hwirq, &type);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < nr_irqs; i++) {\n\t\tret = gic_irq_domain_map(domain, virq + i, hwirq + i);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void gic_irq_domain_free(struct irq_domain *domain, unsigned int virq,\n\t\t\t\tunsigned int nr_irqs)\n{\n\tint i;\n\n\tfor (i = 0; i < nr_irqs; i++) {\n\t\tstruct irq_data *d = irq_domain_get_irq_data(domain, virq + i);\n\t\tirq_set_handler(virq + i, NULL);\n\t\tirq_domain_reset_irq_data(d);\n\t}\n}\n\nstatic bool fwspec_is_partitioned_ppi(struct irq_fwspec *fwspec,\n\t\t\t\t      irq_hw_number_t hwirq)\n{\n\tenum gic_intid_range range;\n\n\tif (!gic_data.ppi_descs)\n\t\treturn false;\n\n\tif (!is_of_node(fwspec->fwnode))\n\t\treturn false;\n\n\tif (fwspec->param_count < 4 || !fwspec->param[3])\n\t\treturn false;\n\n\trange = __get_intid_range(hwirq);\n\tif (range != PPI_RANGE && range != EPPI_RANGE)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int gic_irq_domain_select(struct irq_domain *d,\n\t\t\t\t struct irq_fwspec *fwspec,\n\t\t\t\t enum irq_domain_bus_token bus_token)\n{\n\tunsigned int type, ret, ppi_idx;\n\tirq_hw_number_t hwirq;\n\n\t \n        if (fwspec->fwnode != d->fwnode)\n\t\treturn 0;\n\n\t \n\tif (!is_of_node(fwspec->fwnode))\n\t\treturn 1;\n\n\tret = gic_irq_domain_translate(d, fwspec, &hwirq, &type);\n\tif (WARN_ON_ONCE(ret))\n\t\treturn 0;\n\n\tif (!fwspec_is_partitioned_ppi(fwspec, hwirq))\n\t\treturn d == gic_data.domain;\n\n\t \n\tppi_idx = __gic_get_ppi_index(hwirq);\n\treturn d == partition_get_domain(gic_data.ppi_descs[ppi_idx]);\n}\n\nstatic const struct irq_domain_ops gic_irq_domain_ops = {\n\t.translate = gic_irq_domain_translate,\n\t.alloc = gic_irq_domain_alloc,\n\t.free = gic_irq_domain_free,\n\t.select = gic_irq_domain_select,\n};\n\nstatic int partition_domain_translate(struct irq_domain *d,\n\t\t\t\t      struct irq_fwspec *fwspec,\n\t\t\t\t      unsigned long *hwirq,\n\t\t\t\t      unsigned int *type)\n{\n\tunsigned long ppi_intid;\n\tstruct device_node *np;\n\tunsigned int ppi_idx;\n\tint ret;\n\n\tif (!gic_data.ppi_descs)\n\t\treturn -ENOMEM;\n\n\tnp = of_find_node_by_phandle(fwspec->param[3]);\n\tif (WARN_ON(!np))\n\t\treturn -EINVAL;\n\n\tret = gic_irq_domain_translate(d, fwspec, &ppi_intid, type);\n\tif (WARN_ON_ONCE(ret))\n\t\treturn 0;\n\n\tppi_idx = __gic_get_ppi_index(ppi_intid);\n\tret = partition_translate_id(gic_data.ppi_descs[ppi_idx],\n\t\t\t\t     of_node_to_fwnode(np));\n\tif (ret < 0)\n\t\treturn ret;\n\n\t*hwirq = ret;\n\t*type = fwspec->param[2] & IRQ_TYPE_SENSE_MASK;\n\n\treturn 0;\n}\n\nstatic const struct irq_domain_ops partition_domain_ops = {\n\t.translate = partition_domain_translate,\n\t.select = gic_irq_domain_select,\n};\n\nstatic bool gic_enable_quirk_msm8996(void *data)\n{\n\tstruct gic_chip_data *d = data;\n\n\td->flags |= FLAGS_WORKAROUND_GICR_WAKER_MSM8996;\n\n\treturn true;\n}\n\nstatic bool gic_enable_quirk_mtk_gicr(void *data)\n{\n\tstruct gic_chip_data *d = data;\n\n\td->flags |= FLAGS_WORKAROUND_MTK_GICR_SAVE;\n\n\treturn true;\n}\n\nstatic bool gic_enable_quirk_cavium_38539(void *data)\n{\n\tstruct gic_chip_data *d = data;\n\n\td->flags |= FLAGS_WORKAROUND_CAVIUM_ERRATUM_38539;\n\n\treturn true;\n}\n\nstatic bool gic_enable_quirk_hip06_07(void *data)\n{\n\tstruct gic_chip_data *d = data;\n\n\t \n\tif (d->rdists.gicd_typer & GICD_TYPER_ESPI) {\n\t\t \n\t\td->rdists.gicd_typer &= ~GENMASK(9, 8);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n#define T241_CHIPN_MASK\t\tGENMASK_ULL(45, 44)\n#define T241_CHIP_GICDA_OFFSET\t0x1580000\n#define SMCCC_SOC_ID_T241\t0x036b0241\n\nstatic bool gic_enable_quirk_nvidia_t241(void *data)\n{\n\ts32 soc_id = arm_smccc_get_soc_id_version();\n\tunsigned long chip_bmask = 0;\n\tphys_addr_t phys;\n\tu32 i;\n\n\t \n\tif ((soc_id < 0) || (soc_id != SMCCC_SOC_ID_T241))\n\t\treturn false;\n\n\t \n\tfor (i = 0; i < gic_data.nr_redist_regions; i++) {\n\t\tchip_bmask |= BIT(FIELD_GET(T241_CHIPN_MASK,\n\t\t\t\t  (u64)gic_data.redist_regions[i].phys_base));\n\t}\n\n\tif (hweight32(chip_bmask) < 3)\n\t\treturn false;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(t241_dist_base_alias); i++) {\n\t\tif (chip_bmask & BIT(i)) {\n\t\t\tphys = gic_data.dist_phys_base + T241_CHIP_GICDA_OFFSET;\n\t\t\tphys |= FIELD_PREP(T241_CHIPN_MASK, i);\n\t\t\tt241_dist_base_alias[i] = ioremap(phys, SZ_64K);\n\t\t\tWARN_ON_ONCE(!t241_dist_base_alias[i]);\n\t\t}\n\t}\n\tstatic_branch_enable(&gic_nvidia_t241_erratum);\n\treturn true;\n}\n\nstatic bool gic_enable_quirk_asr8601(void *data)\n{\n\tstruct gic_chip_data *d = data;\n\n\td->flags |= FLAGS_WORKAROUND_ASR_ERRATUM_8601001;\n\n\treturn true;\n}\n\nstatic bool gic_enable_quirk_arm64_2941627(void *data)\n{\n\tstatic_branch_enable(&gic_arm64_2941627_erratum);\n\treturn true;\n}\n\nstatic bool rd_set_non_coherent(void *data)\n{\n\tstruct gic_chip_data *d = data;\n\n\td->rdists.flags |= RDIST_FLAGS_FORCE_NON_SHAREABLE;\n\treturn true;\n}\n\nstatic const struct gic_quirk gic_quirks[] = {\n\t{\n\t\t.desc\t= \"GICv3: Qualcomm MSM8996 broken firmware\",\n\t\t.compatible = \"qcom,msm8996-gic-v3\",\n\t\t.init\t= gic_enable_quirk_msm8996,\n\t},\n\t{\n\t\t.desc\t= \"GICv3: ASR erratum 8601001\",\n\t\t.compatible = \"asr,asr8601-gic-v3\",\n\t\t.init\t= gic_enable_quirk_asr8601,\n\t},\n\t{\n\t\t.desc\t= \"GICv3: Mediatek Chromebook GICR save problem\",\n\t\t.property = \"mediatek,broken-save-restore-fw\",\n\t\t.init\t= gic_enable_quirk_mtk_gicr,\n\t},\n\t{\n\t\t.desc\t= \"GICv3: HIP06 erratum 161010803\",\n\t\t.iidr\t= 0x0204043b,\n\t\t.mask\t= 0xffffffff,\n\t\t.init\t= gic_enable_quirk_hip06_07,\n\t},\n\t{\n\t\t.desc\t= \"GICv3: HIP07 erratum 161010803\",\n\t\t.iidr\t= 0x00000000,\n\t\t.mask\t= 0xffffffff,\n\t\t.init\t= gic_enable_quirk_hip06_07,\n\t},\n\t{\n\t\t \n\t\t.desc\t= \"GICv3: Cavium erratum 38539\",\n\t\t.iidr\t= 0xa000034c,\n\t\t.mask\t= 0xe8f00fff,\n\t\t.init\t= gic_enable_quirk_cavium_38539,\n\t},\n\t{\n\t\t.desc\t= \"GICv3: NVIDIA erratum T241-FABRIC-4\",\n\t\t.iidr\t= 0x0402043b,\n\t\t.mask\t= 0xffffffff,\n\t\t.init\t= gic_enable_quirk_nvidia_t241,\n\t},\n\t{\n\t\t \n\t\t.desc\t= \"GICv3: ARM64 erratum 2941627\",\n\t\t.iidr\t= 0x0400043b,\n\t\t.mask\t= 0xff0e0fff,\n\t\t.init\t= gic_enable_quirk_arm64_2941627,\n\t},\n\t{\n\t\t \n\t\t.desc\t= \"GICv3: ARM64 erratum 2941627\",\n\t\t.iidr\t= 0x0402043b,\n\t\t.mask\t= 0xff0f0fff,\n\t\t.init\t= gic_enable_quirk_arm64_2941627,\n\t},\n\t{\n\t\t.desc   = \"GICv3: non-coherent attribute\",\n\t\t.property = \"dma-noncoherent\",\n\t\t.init   = rd_set_non_coherent,\n\t},\n\t{\n\t}\n};\n\nstatic void gic_enable_nmi_support(void)\n{\n\tint i;\n\n\tif (!gic_prio_masking_enabled())\n\t\treturn;\n\n\tif (gic_data.flags & FLAGS_WORKAROUND_MTK_GICR_SAVE) {\n\t\tpr_warn(\"Skipping NMI enable due to firmware issues\\n\");\n\t\treturn;\n\t}\n\n\tppi_nmi_refs = kcalloc(gic_data.ppi_nr, sizeof(*ppi_nmi_refs), GFP_KERNEL);\n\tif (!ppi_nmi_refs)\n\t\treturn;\n\n\tfor (i = 0; i < gic_data.ppi_nr; i++)\n\t\trefcount_set(&ppi_nmi_refs[i], 0);\n\n\tpr_info(\"Pseudo-NMIs enabled using %s ICC_PMR_EL1 synchronisation\\n\",\n\t\tgic_has_relaxed_pmr_sync() ? \"relaxed\" : \"forced\");\n\n\t \n\tif (gic_has_group0() && !gic_dist_security_disabled())\n\t\tstatic_branch_enable(&gic_nonsecure_priorities);\n\n\tstatic_branch_enable(&supports_pseudo_nmis);\n\n\tif (static_branch_likely(&supports_deactivate_key))\n\t\tgic_eoimode1_chip.flags |= IRQCHIP_SUPPORTS_NMI;\n\telse\n\t\tgic_chip.flags |= IRQCHIP_SUPPORTS_NMI;\n}\n\nstatic int __init gic_init_bases(phys_addr_t dist_phys_base,\n\t\t\t\t void __iomem *dist_base,\n\t\t\t\t struct redist_region *rdist_regs,\n\t\t\t\t u32 nr_redist_regions,\n\t\t\t\t u64 redist_stride,\n\t\t\t\t struct fwnode_handle *handle)\n{\n\tu32 typer;\n\tint err;\n\n\tif (!is_hyp_mode_available())\n\t\tstatic_branch_disable(&supports_deactivate_key);\n\n\tif (static_branch_likely(&supports_deactivate_key))\n\t\tpr_info(\"GIC: Using split EOI/Deactivate mode\\n\");\n\n\tgic_data.fwnode = handle;\n\tgic_data.dist_phys_base = dist_phys_base;\n\tgic_data.dist_base = dist_base;\n\tgic_data.redist_regions = rdist_regs;\n\tgic_data.nr_redist_regions = nr_redist_regions;\n\tgic_data.redist_stride = redist_stride;\n\n\t \n\ttyper = readl_relaxed(gic_data.dist_base + GICD_TYPER);\n\tgic_data.rdists.gicd_typer = typer;\n\n\tgic_enable_quirks(readl_relaxed(gic_data.dist_base + GICD_IIDR),\n\t\t\t  gic_quirks, &gic_data);\n\n\tpr_info(\"%d SPIs implemented\\n\", GIC_LINE_NR - 32);\n\tpr_info(\"%d Extended SPIs implemented\\n\", GIC_ESPI_NR);\n\n\t \n\tif (!(gic_data.flags & FLAGS_WORKAROUND_CAVIUM_ERRATUM_38539))\n\t\tgic_data.rdists.gicd_typer2 = readl_relaxed(gic_data.dist_base + GICD_TYPER2);\n\n\tgic_data.domain = irq_domain_create_tree(handle, &gic_irq_domain_ops,\n\t\t\t\t\t\t &gic_data);\n\tgic_data.rdists.rdist = alloc_percpu(typeof(*gic_data.rdists.rdist));\n\tif (!static_branch_unlikely(&gic_nvidia_t241_erratum)) {\n\t\t \n\t\tgic_data.rdists.has_rvpeid = true;\n\t\tgic_data.rdists.has_vlpis = true;\n\t\tgic_data.rdists.has_direct_lpi = true;\n\t\tgic_data.rdists.has_vpend_valid_dirty = true;\n\t}\n\n\tif (WARN_ON(!gic_data.domain) || WARN_ON(!gic_data.rdists.rdist)) {\n\t\terr = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\n\tirq_domain_update_bus_token(gic_data.domain, DOMAIN_BUS_WIRED);\n\n\tgic_data.has_rss = !!(typer & GICD_TYPER_RSS);\n\n\tif (typer & GICD_TYPER_MBIS) {\n\t\terr = mbi_init(handle, gic_data.domain);\n\t\tif (err)\n\t\t\tpr_err(\"Failed to initialize MBIs\\n\");\n\t}\n\n\tset_handle_irq(gic_handle_irq);\n\n\tgic_update_rdist_properties();\n\n\tgic_dist_init();\n\tgic_cpu_init();\n\tgic_smp_init();\n\tgic_cpu_pm_init();\n\n\tif (gic_dist_supports_lpis()) {\n\t\tits_init(handle, &gic_data.rdists, gic_data.domain);\n\t\tits_cpu_init();\n\t\tits_lpi_memreserve_init();\n\t} else {\n\t\tif (IS_ENABLED(CONFIG_ARM_GIC_V2M))\n\t\t\tgicv2m_init(handle, gic_data.domain);\n\t}\n\n\tgic_enable_nmi_support();\n\n\treturn 0;\n\nout_free:\n\tif (gic_data.domain)\n\t\tirq_domain_remove(gic_data.domain);\n\tfree_percpu(gic_data.rdists.rdist);\n\treturn err;\n}\n\nstatic int __init gic_validate_dist_version(void __iomem *dist_base)\n{\n\tu32 reg = readl_relaxed(dist_base + GICD_PIDR2) & GIC_PIDR2_ARCH_MASK;\n\n\tif (reg != GIC_PIDR2_ARCH_GICv3 && reg != GIC_PIDR2_ARCH_GICv4)\n\t\treturn -ENODEV;\n\n\treturn 0;\n}\n\n \nstatic void __init gic_populate_ppi_partitions(struct device_node *gic_node)\n{\n\tstruct device_node *parts_node, *child_part;\n\tint part_idx = 0, i;\n\tint nr_parts;\n\tstruct partition_affinity *parts;\n\n\tparts_node = of_get_child_by_name(gic_node, \"ppi-partitions\");\n\tif (!parts_node)\n\t\treturn;\n\n\tgic_data.ppi_descs = kcalloc(gic_data.ppi_nr, sizeof(*gic_data.ppi_descs), GFP_KERNEL);\n\tif (!gic_data.ppi_descs)\n\t\tgoto out_put_node;\n\n\tnr_parts = of_get_child_count(parts_node);\n\n\tif (!nr_parts)\n\t\tgoto out_put_node;\n\n\tparts = kcalloc(nr_parts, sizeof(*parts), GFP_KERNEL);\n\tif (WARN_ON(!parts))\n\t\tgoto out_put_node;\n\n\tfor_each_child_of_node(parts_node, child_part) {\n\t\tstruct partition_affinity *part;\n\t\tint n;\n\n\t\tpart = &parts[part_idx];\n\n\t\tpart->partition_id = of_node_to_fwnode(child_part);\n\n\t\tpr_info(\"GIC: PPI partition %pOFn[%d] { \",\n\t\t\tchild_part, part_idx);\n\n\t\tn = of_property_count_elems_of_size(child_part, \"affinity\",\n\t\t\t\t\t\t    sizeof(u32));\n\t\tWARN_ON(n <= 0);\n\n\t\tfor (i = 0; i < n; i++) {\n\t\t\tint err, cpu;\n\t\t\tu32 cpu_phandle;\n\t\t\tstruct device_node *cpu_node;\n\n\t\t\terr = of_property_read_u32_index(child_part, \"affinity\",\n\t\t\t\t\t\t\t i, &cpu_phandle);\n\t\t\tif (WARN_ON(err))\n\t\t\t\tcontinue;\n\n\t\t\tcpu_node = of_find_node_by_phandle(cpu_phandle);\n\t\t\tif (WARN_ON(!cpu_node))\n\t\t\t\tcontinue;\n\n\t\t\tcpu = of_cpu_node_to_id(cpu_node);\n\t\t\tif (WARN_ON(cpu < 0)) {\n\t\t\t\tof_node_put(cpu_node);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tpr_cont(\"%pOF[%d] \", cpu_node, cpu);\n\n\t\t\tcpumask_set_cpu(cpu, &part->mask);\n\t\t\tof_node_put(cpu_node);\n\t\t}\n\n\t\tpr_cont(\"}\\n\");\n\t\tpart_idx++;\n\t}\n\n\tfor (i = 0; i < gic_data.ppi_nr; i++) {\n\t\tunsigned int irq;\n\t\tstruct partition_desc *desc;\n\t\tstruct irq_fwspec ppi_fwspec = {\n\t\t\t.fwnode\t\t= gic_data.fwnode,\n\t\t\t.param_count\t= 3,\n\t\t\t.param\t\t= {\n\t\t\t\t[0]\t= GIC_IRQ_TYPE_PARTITION,\n\t\t\t\t[1]\t= i,\n\t\t\t\t[2]\t= IRQ_TYPE_NONE,\n\t\t\t},\n\t\t};\n\n\t\tirq = irq_create_fwspec_mapping(&ppi_fwspec);\n\t\tif (WARN_ON(!irq))\n\t\t\tcontinue;\n\t\tdesc = partition_create_desc(gic_data.fwnode, parts, nr_parts,\n\t\t\t\t\t     irq, &partition_domain_ops);\n\t\tif (WARN_ON(!desc))\n\t\t\tcontinue;\n\n\t\tgic_data.ppi_descs[i] = desc;\n\t}\n\nout_put_node:\n\tof_node_put(parts_node);\n}\n\nstatic void __init gic_of_setup_kvm_info(struct device_node *node)\n{\n\tint ret;\n\tstruct resource r;\n\tu32 gicv_idx;\n\n\tgic_v3_kvm_info.type = GIC_V3;\n\n\tgic_v3_kvm_info.maint_irq = irq_of_parse_and_map(node, 0);\n\tif (!gic_v3_kvm_info.maint_irq)\n\t\treturn;\n\n\tif (of_property_read_u32(node, \"#redistributor-regions\",\n\t\t\t\t &gicv_idx))\n\t\tgicv_idx = 1;\n\n\tgicv_idx += 3;\t \n\tret = of_address_to_resource(node, gicv_idx, &r);\n\tif (!ret)\n\t\tgic_v3_kvm_info.vcpu = r;\n\n\tgic_v3_kvm_info.has_v4 = gic_data.rdists.has_vlpis;\n\tgic_v3_kvm_info.has_v4_1 = gic_data.rdists.has_rvpeid;\n\tvgic_set_kvm_info(&gic_v3_kvm_info);\n}\n\nstatic void gic_request_region(resource_size_t base, resource_size_t size,\n\t\t\t       const char *name)\n{\n\tif (!request_mem_region(base, size, name))\n\t\tpr_warn_once(FW_BUG \"%s region %pa has overlapping address\\n\",\n\t\t\t     name, &base);\n}\n\nstatic void __iomem *gic_of_iomap(struct device_node *node, int idx,\n\t\t\t\t  const char *name, struct resource *res)\n{\n\tvoid __iomem *base;\n\tint ret;\n\n\tret = of_address_to_resource(node, idx, res);\n\tif (ret)\n\t\treturn IOMEM_ERR_PTR(ret);\n\n\tgic_request_region(res->start, resource_size(res), name);\n\tbase = of_iomap(node, idx);\n\n\treturn base ?: IOMEM_ERR_PTR(-ENOMEM);\n}\n\nstatic int __init gic_of_init(struct device_node *node, struct device_node *parent)\n{\n\tphys_addr_t dist_phys_base;\n\tvoid __iomem *dist_base;\n\tstruct redist_region *rdist_regs;\n\tstruct resource res;\n\tu64 redist_stride;\n\tu32 nr_redist_regions;\n\tint err, i;\n\n\tdist_base = gic_of_iomap(node, 0, \"GICD\", &res);\n\tif (IS_ERR(dist_base)) {\n\t\tpr_err(\"%pOF: unable to map gic dist registers\\n\", node);\n\t\treturn PTR_ERR(dist_base);\n\t}\n\n\tdist_phys_base = res.start;\n\n\terr = gic_validate_dist_version(dist_base);\n\tif (err) {\n\t\tpr_err(\"%pOF: no distributor detected, giving up\\n\", node);\n\t\tgoto out_unmap_dist;\n\t}\n\n\tif (of_property_read_u32(node, \"#redistributor-regions\", &nr_redist_regions))\n\t\tnr_redist_regions = 1;\n\n\trdist_regs = kcalloc(nr_redist_regions, sizeof(*rdist_regs),\n\t\t\t     GFP_KERNEL);\n\tif (!rdist_regs) {\n\t\terr = -ENOMEM;\n\t\tgoto out_unmap_dist;\n\t}\n\n\tfor (i = 0; i < nr_redist_regions; i++) {\n\t\trdist_regs[i].redist_base = gic_of_iomap(node, 1 + i, \"GICR\", &res);\n\t\tif (IS_ERR(rdist_regs[i].redist_base)) {\n\t\t\tpr_err(\"%pOF: couldn't map region %d\\n\", node, i);\n\t\t\terr = -ENODEV;\n\t\t\tgoto out_unmap_rdist;\n\t\t}\n\t\trdist_regs[i].phys_base = res.start;\n\t}\n\n\tif (of_property_read_u64(node, \"redistributor-stride\", &redist_stride))\n\t\tredist_stride = 0;\n\n\tgic_enable_of_quirks(node, gic_quirks, &gic_data);\n\n\terr = gic_init_bases(dist_phys_base, dist_base, rdist_regs,\n\t\t\t     nr_redist_regions, redist_stride, &node->fwnode);\n\tif (err)\n\t\tgoto out_unmap_rdist;\n\n\tgic_populate_ppi_partitions(node);\n\n\tif (static_branch_likely(&supports_deactivate_key))\n\t\tgic_of_setup_kvm_info(node);\n\treturn 0;\n\nout_unmap_rdist:\n\tfor (i = 0; i < nr_redist_regions; i++)\n\t\tif (rdist_regs[i].redist_base && !IS_ERR(rdist_regs[i].redist_base))\n\t\t\tiounmap(rdist_regs[i].redist_base);\n\tkfree(rdist_regs);\nout_unmap_dist:\n\tiounmap(dist_base);\n\treturn err;\n}\n\nIRQCHIP_DECLARE(gic_v3, \"arm,gic-v3\", gic_of_init);\n\n#ifdef CONFIG_ACPI\nstatic struct\n{\n\tvoid __iomem *dist_base;\n\tstruct redist_region *redist_regs;\n\tu32 nr_redist_regions;\n\tbool single_redist;\n\tint enabled_rdists;\n\tu32 maint_irq;\n\tint maint_irq_mode;\n\tphys_addr_t vcpu_base;\n} acpi_data __initdata;\n\nstatic void __init\ngic_acpi_register_redist(phys_addr_t phys_base, void __iomem *redist_base)\n{\n\tstatic int count = 0;\n\n\tacpi_data.redist_regs[count].phys_base = phys_base;\n\tacpi_data.redist_regs[count].redist_base = redist_base;\n\tacpi_data.redist_regs[count].single_redist = acpi_data.single_redist;\n\tcount++;\n}\n\nstatic int __init\ngic_acpi_parse_madt_redist(union acpi_subtable_headers *header,\n\t\t\t   const unsigned long end)\n{\n\tstruct acpi_madt_generic_redistributor *redist =\n\t\t\t(struct acpi_madt_generic_redistributor *)header;\n\tvoid __iomem *redist_base;\n\n\tredist_base = ioremap(redist->base_address, redist->length);\n\tif (!redist_base) {\n\t\tpr_err(\"Couldn't map GICR region @%llx\\n\", redist->base_address);\n\t\treturn -ENOMEM;\n\t}\n\tgic_request_region(redist->base_address, redist->length, \"GICR\");\n\n\tgic_acpi_register_redist(redist->base_address, redist_base);\n\treturn 0;\n}\n\nstatic int __init\ngic_acpi_parse_madt_gicc(union acpi_subtable_headers *header,\n\t\t\t const unsigned long end)\n{\n\tstruct acpi_madt_generic_interrupt *gicc =\n\t\t\t\t(struct acpi_madt_generic_interrupt *)header;\n\tu32 reg = readl_relaxed(acpi_data.dist_base + GICD_PIDR2) & GIC_PIDR2_ARCH_MASK;\n\tu32 size = reg == GIC_PIDR2_ARCH_GICv4 ? SZ_64K * 4 : SZ_64K * 2;\n\tvoid __iomem *redist_base;\n\n\t \n\tif (!(gicc->flags & ACPI_MADT_ENABLED))\n\t\treturn 0;\n\n\tredist_base = ioremap(gicc->gicr_base_address, size);\n\tif (!redist_base)\n\t\treturn -ENOMEM;\n\tgic_request_region(gicc->gicr_base_address, size, \"GICR\");\n\n\tgic_acpi_register_redist(gicc->gicr_base_address, redist_base);\n\treturn 0;\n}\n\nstatic int __init gic_acpi_collect_gicr_base(void)\n{\n\tacpi_tbl_entry_handler redist_parser;\n\tenum acpi_madt_type type;\n\n\tif (acpi_data.single_redist) {\n\t\ttype = ACPI_MADT_TYPE_GENERIC_INTERRUPT;\n\t\tredist_parser = gic_acpi_parse_madt_gicc;\n\t} else {\n\t\ttype = ACPI_MADT_TYPE_GENERIC_REDISTRIBUTOR;\n\t\tredist_parser = gic_acpi_parse_madt_redist;\n\t}\n\n\t \n\tif (acpi_table_parse_madt(type, redist_parser, 0) > 0)\n\t\treturn 0;\n\n\tpr_info(\"No valid GICR entries exist\\n\");\n\treturn -ENODEV;\n}\n\nstatic int __init gic_acpi_match_gicr(union acpi_subtable_headers *header,\n\t\t\t\t  const unsigned long end)\n{\n\t \n\treturn 0;\n}\n\nstatic int __init gic_acpi_match_gicc(union acpi_subtable_headers *header,\n\t\t\t\t      const unsigned long end)\n{\n\tstruct acpi_madt_generic_interrupt *gicc =\n\t\t\t\t(struct acpi_madt_generic_interrupt *)header;\n\n\t \n\tif ((gicc->flags & ACPI_MADT_ENABLED) && gicc->gicr_base_address) {\n\t\tacpi_data.enabled_rdists++;\n\t\treturn 0;\n\t}\n\n\t \n\tif (!(gicc->flags & ACPI_MADT_ENABLED))\n\t\treturn 0;\n\n\treturn -ENODEV;\n}\n\nstatic int __init gic_acpi_count_gicr_regions(void)\n{\n\tint count;\n\n\t \n\tcount = acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_REDISTRIBUTOR,\n\t\t\t\t      gic_acpi_match_gicr, 0);\n\tif (count > 0) {\n\t\tacpi_data.single_redist = false;\n\t\treturn count;\n\t}\n\n\tcount = acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_INTERRUPT,\n\t\t\t\t      gic_acpi_match_gicc, 0);\n\tif (count > 0) {\n\t\tacpi_data.single_redist = true;\n\t\tcount = acpi_data.enabled_rdists;\n\t}\n\n\treturn count;\n}\n\nstatic bool __init acpi_validate_gic_table(struct acpi_subtable_header *header,\n\t\t\t\t\t   struct acpi_probe_entry *ape)\n{\n\tstruct acpi_madt_generic_distributor *dist;\n\tint count;\n\n\tdist = (struct acpi_madt_generic_distributor *)header;\n\tif (dist->version != ape->driver_data)\n\t\treturn false;\n\n\t \n\tcount = gic_acpi_count_gicr_regions();\n\tif (count <= 0)\n\t\treturn false;\n\n\tacpi_data.nr_redist_regions = count;\n\treturn true;\n}\n\nstatic int __init gic_acpi_parse_virt_madt_gicc(union acpi_subtable_headers *header,\n\t\t\t\t\t\tconst unsigned long end)\n{\n\tstruct acpi_madt_generic_interrupt *gicc =\n\t\t(struct acpi_madt_generic_interrupt *)header;\n\tint maint_irq_mode;\n\tstatic int first_madt = true;\n\n\t \n\tif (!(gicc->flags & ACPI_MADT_ENABLED))\n\t\treturn 0;\n\n\tmaint_irq_mode = (gicc->flags & ACPI_MADT_VGIC_IRQ_MODE) ?\n\t\tACPI_EDGE_SENSITIVE : ACPI_LEVEL_SENSITIVE;\n\n\tif (first_madt) {\n\t\tfirst_madt = false;\n\n\t\tacpi_data.maint_irq = gicc->vgic_interrupt;\n\t\tacpi_data.maint_irq_mode = maint_irq_mode;\n\t\tacpi_data.vcpu_base = gicc->gicv_base_address;\n\n\t\treturn 0;\n\t}\n\n\t \n\tif ((acpi_data.maint_irq != gicc->vgic_interrupt) ||\n\t    (acpi_data.maint_irq_mode != maint_irq_mode) ||\n\t    (acpi_data.vcpu_base != gicc->gicv_base_address))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic bool __init gic_acpi_collect_virt_info(void)\n{\n\tint count;\n\n\tcount = acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_INTERRUPT,\n\t\t\t\t      gic_acpi_parse_virt_madt_gicc, 0);\n\n\treturn (count > 0);\n}\n\n#define ACPI_GICV3_DIST_MEM_SIZE (SZ_64K)\n#define ACPI_GICV2_VCTRL_MEM_SIZE\t(SZ_4K)\n#define ACPI_GICV2_VCPU_MEM_SIZE\t(SZ_8K)\n\nstatic void __init gic_acpi_setup_kvm_info(void)\n{\n\tint irq;\n\n\tif (!gic_acpi_collect_virt_info()) {\n\t\tpr_warn(\"Unable to get hardware information used for virtualization\\n\");\n\t\treturn;\n\t}\n\n\tgic_v3_kvm_info.type = GIC_V3;\n\n\tirq = acpi_register_gsi(NULL, acpi_data.maint_irq,\n\t\t\t\tacpi_data.maint_irq_mode,\n\t\t\t\tACPI_ACTIVE_HIGH);\n\tif (irq <= 0)\n\t\treturn;\n\n\tgic_v3_kvm_info.maint_irq = irq;\n\n\tif (acpi_data.vcpu_base) {\n\t\tstruct resource *vcpu = &gic_v3_kvm_info.vcpu;\n\n\t\tvcpu->flags = IORESOURCE_MEM;\n\t\tvcpu->start = acpi_data.vcpu_base;\n\t\tvcpu->end = vcpu->start + ACPI_GICV2_VCPU_MEM_SIZE - 1;\n\t}\n\n\tgic_v3_kvm_info.has_v4 = gic_data.rdists.has_vlpis;\n\tgic_v3_kvm_info.has_v4_1 = gic_data.rdists.has_rvpeid;\n\tvgic_set_kvm_info(&gic_v3_kvm_info);\n}\n\nstatic struct fwnode_handle *gsi_domain_handle;\n\nstatic struct fwnode_handle *gic_v3_get_gsi_domain_id(u32 gsi)\n{\n\treturn gsi_domain_handle;\n}\n\nstatic int __init\ngic_acpi_init(union acpi_subtable_headers *header, const unsigned long end)\n{\n\tstruct acpi_madt_generic_distributor *dist;\n\tsize_t size;\n\tint i, err;\n\n\t \n\tdist = (struct acpi_madt_generic_distributor *)header;\n\tacpi_data.dist_base = ioremap(dist->base_address,\n\t\t\t\t      ACPI_GICV3_DIST_MEM_SIZE);\n\tif (!acpi_data.dist_base) {\n\t\tpr_err(\"Unable to map GICD registers\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tgic_request_region(dist->base_address, ACPI_GICV3_DIST_MEM_SIZE, \"GICD\");\n\n\terr = gic_validate_dist_version(acpi_data.dist_base);\n\tif (err) {\n\t\tpr_err(\"No distributor detected at @%p, giving up\\n\",\n\t\t       acpi_data.dist_base);\n\t\tgoto out_dist_unmap;\n\t}\n\n\tsize = sizeof(*acpi_data.redist_regs) * acpi_data.nr_redist_regions;\n\tacpi_data.redist_regs = kzalloc(size, GFP_KERNEL);\n\tif (!acpi_data.redist_regs) {\n\t\terr = -ENOMEM;\n\t\tgoto out_dist_unmap;\n\t}\n\n\terr = gic_acpi_collect_gicr_base();\n\tif (err)\n\t\tgoto out_redist_unmap;\n\n\tgsi_domain_handle = irq_domain_alloc_fwnode(&dist->base_address);\n\tif (!gsi_domain_handle) {\n\t\terr = -ENOMEM;\n\t\tgoto out_redist_unmap;\n\t}\n\n\terr = gic_init_bases(dist->base_address, acpi_data.dist_base,\n\t\t\t     acpi_data.redist_regs, acpi_data.nr_redist_regions,\n\t\t\t     0, gsi_domain_handle);\n\tif (err)\n\t\tgoto out_fwhandle_free;\n\n\tacpi_set_irq_model(ACPI_IRQ_MODEL_GIC, gic_v3_get_gsi_domain_id);\n\n\tif (static_branch_likely(&supports_deactivate_key))\n\t\tgic_acpi_setup_kvm_info();\n\n\treturn 0;\n\nout_fwhandle_free:\n\tirq_domain_free_fwnode(gsi_domain_handle);\nout_redist_unmap:\n\tfor (i = 0; i < acpi_data.nr_redist_regions; i++)\n\t\tif (acpi_data.redist_regs[i].redist_base)\n\t\t\tiounmap(acpi_data.redist_regs[i].redist_base);\n\tkfree(acpi_data.redist_regs);\nout_dist_unmap:\n\tiounmap(acpi_data.dist_base);\n\treturn err;\n}\nIRQCHIP_ACPI_DECLARE(gic_v3, ACPI_MADT_TYPE_GENERIC_DISTRIBUTOR,\n\t\t     acpi_validate_gic_table, ACPI_MADT_GIC_VERSION_V3,\n\t\t     gic_acpi_init);\nIRQCHIP_ACPI_DECLARE(gic_v4, ACPI_MADT_TYPE_GENERIC_DISTRIBUTOR,\n\t\t     acpi_validate_gic_table, ACPI_MADT_GIC_VERSION_V4,\n\t\t     gic_acpi_init);\nIRQCHIP_ACPI_DECLARE(gic_v3_or_v4, ACPI_MADT_TYPE_GENERIC_DISTRIBUTOR,\n\t\t     acpi_validate_gic_table, ACPI_MADT_GIC_VERSION_NONE,\n\t\t     gic_acpi_init);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}