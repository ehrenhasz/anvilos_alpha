{
  "module_name": "device_pgid.c",
  "hash_id": "b289df15fe7e8819f0c8d0ac02dafbde4d15f44057c71cfddc183e3732d59b7c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/s390/cio/device_pgid.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/bitops.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/slab.h>\n#include <linux/io.h>\n#include <asm/ccwdev.h>\n#include <asm/cio.h>\n\n#include \"cio.h\"\n#include \"cio_debug.h\"\n#include \"device.h\"\n#include \"io_sch.h\"\n\n#define PGID_RETRIES\t256\n#define PGID_TIMEOUT\t(10 * HZ)\n\nstatic void verify_start(struct ccw_device *cdev);\n\n \nstatic void verify_done(struct ccw_device *cdev, int rc)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_dev_id *id = &cdev->private->dev_id;\n\tint mpath = cdev->private->flags.mpath;\n\tint pgroup = cdev->private->flags.pgroup;\n\n\tif (rc)\n\t\tgoto out;\n\t \n\tif (sch->config.mp != mpath) {\n\t\tsch->config.mp = mpath;\n\t\trc = cio_commit_config(sch);\n\t}\nout:\n\tCIO_MSG_EVENT(2, \"vrfy: device 0.%x.%04x: rc=%d pgroup=%d mpath=%d \"\n\t\t\t \"vpm=%02x\\n\", id->ssid, id->devno, rc, pgroup, mpath,\n\t\t\t sch->vpm);\n\tccw_device_verify_done(cdev, rc);\n}\n\n \nstatic void nop_build_cp(struct ccw_device *cdev)\n{\n\tstruct ccw_request *req = &cdev->private->req;\n\tstruct ccw1 *cp = cdev->private->dma_area->iccws;\n\n\tcp->cmd_code\t= CCW_CMD_NOOP;\n\tcp->cda\t\t= 0;\n\tcp->count\t= 0;\n\tcp->flags\t= CCW_FLAG_SLI;\n\treq->cp\t\t= cp;\n}\n\n \nstatic void nop_do(struct ccw_device *cdev)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_request *req = &cdev->private->req;\n\n\treq->lpm = lpm_adjust(req->lpm, sch->schib.pmcw.pam & sch->opm &\n\t\t\t      ~cdev->private->path_noirq_mask);\n\tif (!req->lpm)\n\t\tgoto out_nopath;\n\tnop_build_cp(cdev);\n\tccw_request_start(cdev);\n\treturn;\n\nout_nopath:\n\tverify_done(cdev, sch->vpm ? 0 : -EACCES);\n}\n\n \nstatic enum io_status nop_filter(struct ccw_device *cdev, void *data,\n\t\t\t\t struct irb *irb, enum io_status status)\n{\n\t \n\tif (status == IO_STATUS_ERROR && irb->scsw.cmd.cstat == 0)\n\t\treturn IO_DONE;\n\treturn status;\n}\n\n \nstatic void nop_callback(struct ccw_device *cdev, void *data, int rc)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_request *req = &cdev->private->req;\n\n\tswitch (rc) {\n\tcase 0:\n\t\tsch->vpm |= req->lpm;\n\t\tbreak;\n\tcase -ETIME:\n\t\tcdev->private->path_noirq_mask |= req->lpm;\n\t\tbreak;\n\tcase -EACCES:\n\t\tcdev->private->path_notoper_mask |= req->lpm;\n\t\tbreak;\n\tdefault:\n\t\tgoto err;\n\t}\n\t \n\treq->lpm >>= 1;\n\tnop_do(cdev);\n\treturn;\n\nerr:\n\tverify_done(cdev, rc);\n}\n\n \nstatic void spid_build_cp(struct ccw_device *cdev, u8 fn)\n{\n\tstruct ccw_request *req = &cdev->private->req;\n\tstruct ccw1 *cp = cdev->private->dma_area->iccws;\n\tint i = pathmask_to_pos(req->lpm);\n\tstruct pgid *pgid = &cdev->private->dma_area->pgid[i];\n\n\tpgid->inf.fc\t= fn;\n\tcp->cmd_code\t= CCW_CMD_SET_PGID;\n\tcp->cda\t\t= (u32)virt_to_phys(pgid);\n\tcp->count\t= sizeof(*pgid);\n\tcp->flags\t= CCW_FLAG_SLI;\n\treq->cp\t\t= cp;\n}\n\nstatic void pgid_wipeout_callback(struct ccw_device *cdev, void *data, int rc)\n{\n\tif (rc) {\n\t\t \n\t\tverify_done(cdev, rc);\n\t\treturn;\n\t}\n\t \n\tcdev->private->flags.pgid_unknown = 0;\n\tverify_start(cdev);\n}\n\n \nstatic void pgid_wipeout_start(struct ccw_device *cdev)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_dev_id *id = &cdev->private->dev_id;\n\tstruct ccw_request *req = &cdev->private->req;\n\tu8 fn;\n\n\tCIO_MSG_EVENT(2, \"wipe: device 0.%x.%04x: pvm=%02x nim=%02x\\n\",\n\t\t      id->ssid, id->devno, cdev->private->pgid_valid_mask,\n\t\t      cdev->private->path_noirq_mask);\n\n\t \n\tmemset(req, 0, sizeof(*req));\n\treq->timeout\t= PGID_TIMEOUT;\n\treq->maxretries\t= PGID_RETRIES;\n\treq->lpm\t= sch->schib.pmcw.pam;\n\treq->callback\t= pgid_wipeout_callback;\n\tfn = SPID_FUNC_DISBAND;\n\tif (cdev->private->flags.mpath)\n\t\tfn |= SPID_FUNC_MULTI_PATH;\n\tspid_build_cp(cdev, fn);\n\tccw_request_start(cdev);\n}\n\n \nstatic void spid_do(struct ccw_device *cdev)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_request *req = &cdev->private->req;\n\tu8 fn;\n\n\t \n\treq->lpm = lpm_adjust(req->lpm, cdev->private->pgid_todo_mask);\n\tif (!req->lpm)\n\t\tgoto out_nopath;\n\t \n\tif (req->lpm & sch->opm)\n\t\tfn = SPID_FUNC_ESTABLISH;\n\telse\n\t\tfn = SPID_FUNC_RESIGN;\n\tif (cdev->private->flags.mpath)\n\t\tfn |= SPID_FUNC_MULTI_PATH;\n\tspid_build_cp(cdev, fn);\n\tccw_request_start(cdev);\n\treturn;\n\nout_nopath:\n\tif (cdev->private->flags.pgid_unknown) {\n\t\t \n\t\tpgid_wipeout_start(cdev);\n\t\treturn;\n\t}\n\tverify_done(cdev, sch->vpm ? 0 : -EACCES);\n}\n\n \nstatic void spid_callback(struct ccw_device *cdev, void *data, int rc)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_request *req = &cdev->private->req;\n\n\tswitch (rc) {\n\tcase 0:\n\t\tsch->vpm |= req->lpm & sch->opm;\n\t\tbreak;\n\tcase -ETIME:\n\t\tcdev->private->flags.pgid_unknown = 1;\n\t\tcdev->private->path_noirq_mask |= req->lpm;\n\t\tbreak;\n\tcase -EACCES:\n\t\tcdev->private->path_notoper_mask |= req->lpm;\n\t\tbreak;\n\tcase -EOPNOTSUPP:\n\t\tif (cdev->private->flags.mpath) {\n\t\t\t \n\t\t\tcdev->private->flags.mpath = 0;\n\t\t\tgoto out_restart;\n\t\t}\n\t\t \n\t\tcdev->private->flags.pgroup = 0;\n\t\tgoto out_restart;\n\tdefault:\n\t\tgoto err;\n\t}\n\treq->lpm >>= 1;\n\tspid_do(cdev);\n\treturn;\n\nout_restart:\n\tverify_start(cdev);\n\treturn;\nerr:\n\tverify_done(cdev, rc);\n}\n\nstatic void spid_start(struct ccw_device *cdev)\n{\n\tstruct ccw_request *req = &cdev->private->req;\n\n\t \n\tmemset(req, 0, sizeof(*req));\n\treq->timeout\t= PGID_TIMEOUT;\n\treq->maxretries\t= PGID_RETRIES;\n\treq->lpm\t= 0x80;\n\treq->singlepath\t= 1;\n\treq->callback\t= spid_callback;\n\tspid_do(cdev);\n}\n\nstatic int pgid_is_reset(struct pgid *p)\n{\n\tchar *c;\n\n\tfor (c = (char *)p + 1; c < (char *)(p + 1); c++) {\n\t\tif (*c != 0)\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic int pgid_cmp(struct pgid *p1, struct pgid *p2)\n{\n\treturn memcmp((char *) p1 + 1, (char *) p2 + 1,\n\t\t      sizeof(struct pgid) - 1);\n}\n\n \nstatic void pgid_analyze(struct ccw_device *cdev, struct pgid **p,\n\t\t\t int *mismatch, u8 *reserved, u8 *reset)\n{\n\tstruct pgid *pgid = &cdev->private->dma_area->pgid[0];\n\tstruct pgid *first = NULL;\n\tint lpm;\n\tint i;\n\n\t*mismatch = 0;\n\t*reserved = 0;\n\t*reset = 0;\n\tfor (i = 0, lpm = 0x80; i < 8; i++, pgid++, lpm >>= 1) {\n\t\tif ((cdev->private->pgid_valid_mask & lpm) == 0)\n\t\t\tcontinue;\n\t\tif (pgid->inf.ps.state2 == SNID_STATE2_RESVD_ELSE)\n\t\t\t*reserved |= lpm;\n\t\tif (pgid_is_reset(pgid)) {\n\t\t\t*reset |= lpm;\n\t\t\tcontinue;\n\t\t}\n\t\tif (!first) {\n\t\t\tfirst = pgid;\n\t\t\tcontinue;\n\t\t}\n\t\tif (pgid_cmp(pgid, first) != 0)\n\t\t\t*mismatch = 1;\n\t}\n\tif (!first)\n\t\tfirst = &channel_subsystems[0]->global_pgid;\n\t*p = first;\n}\n\nstatic u8 pgid_to_donepm(struct ccw_device *cdev)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct pgid *pgid;\n\tint i;\n\tint lpm;\n\tu8 donepm = 0;\n\n\t \n\tfor (i = 0; i < 8; i++) {\n\t\tlpm = 0x80 >> i;\n\t\tif ((cdev->private->pgid_valid_mask & lpm) == 0)\n\t\t\tcontinue;\n\t\tpgid = &cdev->private->dma_area->pgid[i];\n\t\tif (sch->opm & lpm) {\n\t\t\tif (pgid->inf.ps.state1 != SNID_STATE1_GROUPED)\n\t\t\t\tcontinue;\n\t\t} else {\n\t\t\tif (pgid->inf.ps.state1 != SNID_STATE1_UNGROUPED)\n\t\t\t\tcontinue;\n\t\t}\n\t\tif (cdev->private->flags.mpath) {\n\t\t\tif (pgid->inf.ps.state3 != SNID_STATE3_MULTI_PATH)\n\t\t\t\tcontinue;\n\t\t} else {\n\t\t\tif (pgid->inf.ps.state3 != SNID_STATE3_SINGLE_PATH)\n\t\t\t\tcontinue;\n\t\t}\n\t\tdonepm |= lpm;\n\t}\n\n\treturn donepm;\n}\n\nstatic void pgid_fill(struct ccw_device *cdev, struct pgid *pgid)\n{\n\tint i;\n\n\tfor (i = 0; i < 8; i++)\n\t\tmemcpy(&cdev->private->dma_area->pgid[i], pgid,\n\t\t       sizeof(struct pgid));\n}\n\n \nstatic void snid_done(struct ccw_device *cdev, int rc)\n{\n\tstruct ccw_dev_id *id = &cdev->private->dev_id;\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct pgid *pgid;\n\tint mismatch = 0;\n\tu8 reserved = 0;\n\tu8 reset = 0;\n\tu8 donepm;\n\n\tif (rc)\n\t\tgoto out;\n\tpgid_analyze(cdev, &pgid, &mismatch, &reserved, &reset);\n\tif (reserved == cdev->private->pgid_valid_mask)\n\t\trc = -EUSERS;\n\telse if (mismatch)\n\t\trc = -EOPNOTSUPP;\n\telse {\n\t\tdonepm = pgid_to_donepm(cdev);\n\t\tsch->vpm = donepm & sch->opm;\n\t\tcdev->private->pgid_reset_mask |= reset;\n\t\tcdev->private->pgid_todo_mask &=\n\t\t\t~(donepm | cdev->private->path_noirq_mask);\n\t\tpgid_fill(cdev, pgid);\n\t}\nout:\n\tCIO_MSG_EVENT(2, \"snid: device 0.%x.%04x: rc=%d pvm=%02x vpm=%02x \"\n\t\t      \"todo=%02x mism=%d rsvd=%02x reset=%02x\\n\", id->ssid,\n\t\t      id->devno, rc, cdev->private->pgid_valid_mask, sch->vpm,\n\t\t      cdev->private->pgid_todo_mask, mismatch, reserved, reset);\n\tswitch (rc) {\n\tcase 0:\n\t\tif (cdev->private->flags.pgid_unknown) {\n\t\t\tpgid_wipeout_start(cdev);\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tif (cdev->private->pgid_todo_mask == 0) {\n\t\t\tverify_done(cdev, sch->vpm == 0 ? -EACCES : 0);\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tspid_start(cdev);\n\t\tbreak;\n\tcase -EOPNOTSUPP:\n\t\t \n\t\tcdev->private->flags.pgroup = 0;\n\t\tcdev->private->flags.mpath = 0;\n\t\tverify_start(cdev);\n\t\tbreak;\n\tdefault:\n\t\tverify_done(cdev, rc);\n\t}\n}\n\n \nstatic void snid_build_cp(struct ccw_device *cdev)\n{\n\tstruct ccw_request *req = &cdev->private->req;\n\tstruct ccw1 *cp = cdev->private->dma_area->iccws;\n\tint i = pathmask_to_pos(req->lpm);\n\n\t \n\tcp->cmd_code\t= CCW_CMD_SENSE_PGID;\n\tcp->cda\t\t= (u32)virt_to_phys(&cdev->private->dma_area->pgid[i]);\n\tcp->count\t= sizeof(struct pgid);\n\tcp->flags\t= CCW_FLAG_SLI;\n\treq->cp\t\t= cp;\n}\n\n \nstatic void snid_do(struct ccw_device *cdev)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_request *req = &cdev->private->req;\n\tint ret;\n\n\treq->lpm = lpm_adjust(req->lpm, sch->schib.pmcw.pam &\n\t\t\t      ~cdev->private->path_noirq_mask);\n\tif (!req->lpm)\n\t\tgoto out_nopath;\n\tsnid_build_cp(cdev);\n\tccw_request_start(cdev);\n\treturn;\n\nout_nopath:\n\tif (cdev->private->pgid_valid_mask)\n\t\tret = 0;\n\telse if (cdev->private->path_noirq_mask)\n\t\tret = -ETIME;\n\telse\n\t\tret = -EACCES;\n\tsnid_done(cdev, ret);\n}\n\n \nstatic void snid_callback(struct ccw_device *cdev, void *data, int rc)\n{\n\tstruct ccw_request *req = &cdev->private->req;\n\n\tswitch (rc) {\n\tcase 0:\n\t\tcdev->private->pgid_valid_mask |= req->lpm;\n\t\tbreak;\n\tcase -ETIME:\n\t\tcdev->private->flags.pgid_unknown = 1;\n\t\tcdev->private->path_noirq_mask |= req->lpm;\n\t\tbreak;\n\tcase -EACCES:\n\t\tcdev->private->path_notoper_mask |= req->lpm;\n\t\tbreak;\n\tdefault:\n\t\tgoto err;\n\t}\n\t \n\treq->lpm >>= 1;\n\tsnid_do(cdev);\n\treturn;\n\nerr:\n\tsnid_done(cdev, rc);\n}\n\n \nstatic void verify_start(struct ccw_device *cdev)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_request *req = &cdev->private->req;\n\tstruct ccw_dev_id *devid = &cdev->private->dev_id;\n\n\tsch->vpm = 0;\n\tsch->lpm = sch->schib.pmcw.pam;\n\n\t \n\tmemset(cdev->private->dma_area->pgid, 0,\n\t       sizeof(cdev->private->dma_area->pgid));\n\tcdev->private->pgid_valid_mask = 0;\n\tcdev->private->pgid_todo_mask = sch->schib.pmcw.pam;\n\tcdev->private->path_notoper_mask = 0;\n\n\t \n\tmemset(req, 0, sizeof(*req));\n\treq->timeout\t= PGID_TIMEOUT;\n\treq->maxretries\t= PGID_RETRIES;\n\treq->lpm\t= 0x80;\n\treq->singlepath\t= 1;\n\tif (cdev->private->flags.pgroup) {\n\t\tCIO_TRACE_EVENT(4, \"snid\");\n\t\tCIO_HEX_EVENT(4, devid, sizeof(*devid));\n\t\treq->callback\t= snid_callback;\n\t\tsnid_do(cdev);\n\t} else {\n\t\tCIO_TRACE_EVENT(4, \"nop\");\n\t\tCIO_HEX_EVENT(4, devid, sizeof(*devid));\n\t\treq->filter\t= nop_filter;\n\t\treq->callback\t= nop_callback;\n\t\tnop_do(cdev);\n\t}\n}\n\n \nvoid ccw_device_verify_start(struct ccw_device *cdev)\n{\n\tCIO_TRACE_EVENT(4, \"vrfy\");\n\tCIO_HEX_EVENT(4, &cdev->private->dev_id, sizeof(cdev->private->dev_id));\n\t \n\tcdev->private->flags.pgroup = cdev->private->options.pgroup;\n\tcdev->private->flags.mpath = cdev->private->options.mpath;\n\tcdev->private->flags.doverify = 0;\n\tcdev->private->path_noirq_mask = 0;\n\tverify_start(cdev);\n}\n\n \nstatic void disband_callback(struct ccw_device *cdev, void *data, int rc)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_dev_id *id = &cdev->private->dev_id;\n\n\tif (rc)\n\t\tgoto out;\n\t \n\tcdev->private->flags.mpath = 0;\n\tif (sch->config.mp) {\n\t\tsch->config.mp = 0;\n\t\trc = cio_commit_config(sch);\n\t}\nout:\n\tCIO_MSG_EVENT(0, \"disb: device 0.%x.%04x: rc=%d\\n\", id->ssid, id->devno,\n\t\t      rc);\n\tccw_device_disband_done(cdev, rc);\n}\n\n \nvoid ccw_device_disband_start(struct ccw_device *cdev)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_request *req = &cdev->private->req;\n\tu8 fn;\n\n\tCIO_TRACE_EVENT(4, \"disb\");\n\tCIO_HEX_EVENT(4, &cdev->private->dev_id, sizeof(cdev->private->dev_id));\n\t \n\tmemset(req, 0, sizeof(*req));\n\treq->timeout\t= PGID_TIMEOUT;\n\treq->maxretries\t= PGID_RETRIES;\n\treq->lpm\t= sch->schib.pmcw.pam & sch->opm;\n\treq->singlepath\t= 1;\n\treq->callback\t= disband_callback;\n\tfn = SPID_FUNC_DISBAND;\n\tif (cdev->private->flags.mpath)\n\t\tfn |= SPID_FUNC_MULTI_PATH;\n\tspid_build_cp(cdev, fn);\n\tccw_request_start(cdev);\n}\n\nstruct stlck_data {\n\tstruct completion done;\n\tint rc;\n};\n\nstatic void stlck_build_cp(struct ccw_device *cdev, void *buf1, void *buf2)\n{\n\tstruct ccw_request *req = &cdev->private->req;\n\tstruct ccw1 *cp = cdev->private->dma_area->iccws;\n\n\tcp[0].cmd_code = CCW_CMD_STLCK;\n\tcp[0].cda = (u32)virt_to_phys(buf1);\n\tcp[0].count = 32;\n\tcp[0].flags = CCW_FLAG_CC;\n\tcp[1].cmd_code = CCW_CMD_RELEASE;\n\tcp[1].cda = (u32)virt_to_phys(buf2);\n\tcp[1].count = 32;\n\tcp[1].flags = 0;\n\treq->cp = cp;\n}\n\nstatic void stlck_callback(struct ccw_device *cdev, void *data, int rc)\n{\n\tstruct stlck_data *sdata = data;\n\n\tsdata->rc = rc;\n\tcomplete(&sdata->done);\n}\n\n \nstatic void ccw_device_stlck_start(struct ccw_device *cdev, void *data,\n\t\t\t\t   void *buf1, void *buf2)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct ccw_request *req = &cdev->private->req;\n\n\tCIO_TRACE_EVENT(4, \"stlck\");\n\tCIO_HEX_EVENT(4, &cdev->private->dev_id, sizeof(cdev->private->dev_id));\n\t \n\tmemset(req, 0, sizeof(*req));\n\treq->timeout\t= PGID_TIMEOUT;\n\treq->maxretries\t= PGID_RETRIES;\n\treq->lpm\t= sch->schib.pmcw.pam & sch->opm;\n\treq->data\t= data;\n\treq->callback\t= stlck_callback;\n\tstlck_build_cp(cdev, buf1, buf2);\n\tccw_request_start(cdev);\n}\n\n \nint ccw_device_stlck(struct ccw_device *cdev)\n{\n\tstruct subchannel *sch = to_subchannel(cdev->dev.parent);\n\tstruct stlck_data data;\n\tu8 *buffer;\n\tint rc;\n\n\t \n\tif (cdev->drv) {\n\t\tif (!cdev->private->options.force)\n\t\t\treturn -EINVAL;\n\t}\n\tbuffer = kzalloc(64, GFP_DMA | GFP_KERNEL);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\tinit_completion(&data.done);\n\tdata.rc = -EIO;\n\tspin_lock_irq(sch->lock);\n\trc = cio_enable_subchannel(sch, (u32)virt_to_phys(sch));\n\tif (rc)\n\t\tgoto out_unlock;\n\t \n\tcdev->private->state = DEV_STATE_STEAL_LOCK;\n\tccw_device_stlck_start(cdev, &data, &buffer[0], &buffer[32]);\n\tspin_unlock_irq(sch->lock);\n\t \n\tif (wait_for_completion_interruptible(&data.done)) {\n\t\t \n\t\tspin_lock_irq(sch->lock);\n\t\tccw_request_cancel(cdev);\n\t\tspin_unlock_irq(sch->lock);\n\t\twait_for_completion(&data.done);\n\t}\n\trc = data.rc;\n\t \n\tspin_lock_irq(sch->lock);\n\tcio_disable_subchannel(sch);\n\tcdev->private->state = DEV_STATE_BOXED;\nout_unlock:\n\tspin_unlock_irq(sch->lock);\n\tkfree(buffer);\n\n\treturn rc;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}