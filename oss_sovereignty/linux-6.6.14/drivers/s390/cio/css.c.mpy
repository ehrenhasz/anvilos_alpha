{
  "module_name": "css.c",
  "hash_id": "6348ada9d7c1cce48771b005302f56d65140ebfe9ddbab1eeb225e858cbcd321",
  "original_prompt": "Ingested from linux-6.6.14/drivers/s390/cio/css.c",
  "human_readable_source": "\n \n\n#define KMSG_COMPONENT \"cio\"\n#define pr_fmt(fmt) KMSG_COMPONENT \": \" fmt\n\n#include <linux/export.h>\n#include <linux/init.h>\n#include <linux/device.h>\n#include <linux/slab.h>\n#include <linux/errno.h>\n#include <linux/list.h>\n#include <linux/reboot.h>\n#include <linux/proc_fs.h>\n#include <linux/genalloc.h>\n#include <linux/dma-mapping.h>\n#include <asm/isc.h>\n#include <asm/crw.h>\n\n#include \"css.h\"\n#include \"cio.h\"\n#include \"blacklist.h\"\n#include \"cio_debug.h\"\n#include \"ioasm.h\"\n#include \"chsc.h\"\n#include \"device.h\"\n#include \"idset.h\"\n#include \"chp.h\"\n\nint css_init_done = 0;\nint max_ssid;\n\n#define MAX_CSS_IDX 0\nstruct channel_subsystem *channel_subsystems[MAX_CSS_IDX + 1];\nstatic struct bus_type css_bus_type;\n\nint\nfor_each_subchannel(int(*fn)(struct subchannel_id, void *), void *data)\n{\n\tstruct subchannel_id schid;\n\tint ret;\n\n\tinit_subchannel_id(&schid);\n\tdo {\n\t\tdo {\n\t\t\tret = fn(schid, data);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t} while (schid.sch_no++ < __MAX_SUBCHANNEL);\n\t\tschid.sch_no = 0;\n\t} while (schid.ssid++ < max_ssid);\n\treturn ret;\n}\n\nstruct cb_data {\n\tvoid *data;\n\tstruct idset *set;\n\tint (*fn_known_sch)(struct subchannel *, void *);\n\tint (*fn_unknown_sch)(struct subchannel_id, void *);\n};\n\nstatic int call_fn_known_sch(struct device *dev, void *data)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\tstruct cb_data *cb = data;\n\tint rc = 0;\n\n\tif (cb->set)\n\t\tidset_sch_del(cb->set, sch->schid);\n\tif (cb->fn_known_sch)\n\t\trc = cb->fn_known_sch(sch, cb->data);\n\treturn rc;\n}\n\nstatic int call_fn_unknown_sch(struct subchannel_id schid, void *data)\n{\n\tstruct cb_data *cb = data;\n\tint rc = 0;\n\n\tif (idset_sch_contains(cb->set, schid))\n\t\trc = cb->fn_unknown_sch(schid, cb->data);\n\treturn rc;\n}\n\nstatic int call_fn_all_sch(struct subchannel_id schid, void *data)\n{\n\tstruct cb_data *cb = data;\n\tstruct subchannel *sch;\n\tint rc = 0;\n\n\tsch = get_subchannel_by_schid(schid);\n\tif (sch) {\n\t\tif (cb->fn_known_sch)\n\t\t\trc = cb->fn_known_sch(sch, cb->data);\n\t\tput_device(&sch->dev);\n\t} else {\n\t\tif (cb->fn_unknown_sch)\n\t\t\trc = cb->fn_unknown_sch(schid, cb->data);\n\t}\n\n\treturn rc;\n}\n\nint for_each_subchannel_staged(int (*fn_known)(struct subchannel *, void *),\n\t\t\t       int (*fn_unknown)(struct subchannel_id,\n\t\t\t       void *), void *data)\n{\n\tstruct cb_data cb;\n\tint rc;\n\n\tcb.data = data;\n\tcb.fn_known_sch = fn_known;\n\tcb.fn_unknown_sch = fn_unknown;\n\n\tif (fn_known && !fn_unknown) {\n\t\t \n\t\tcb.set = NULL;\n\t\treturn bus_for_each_dev(&css_bus_type, NULL, &cb,\n\t\t\t\t\tcall_fn_known_sch);\n\t}\n\n\tcb.set = idset_sch_new();\n\tif (!cb.set)\n\t\t \n\t\treturn for_each_subchannel(call_fn_all_sch, &cb);\n\n\tidset_fill(cb.set);\n\n\t \n\trc = bus_for_each_dev(&css_bus_type, NULL, &cb, call_fn_known_sch);\n\tif (rc)\n\t\tgoto out;\n\t \n\tif (fn_unknown)\n\t\trc = for_each_subchannel(call_fn_unknown_sch, &cb);\nout:\n\tidset_free(cb.set);\n\n\treturn rc;\n}\n\nstatic void css_sch_todo(struct work_struct *work);\n\nstatic int css_sch_create_locks(struct subchannel *sch)\n{\n\tsch->lock = kmalloc(sizeof(*sch->lock), GFP_KERNEL);\n\tif (!sch->lock)\n\t\treturn -ENOMEM;\n\n\tspin_lock_init(sch->lock);\n\tmutex_init(&sch->reg_mutex);\n\n\treturn 0;\n}\n\nstatic void css_subchannel_release(struct device *dev)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\n\tsch->config.intparm = 0;\n\tcio_commit_config(sch);\n\tkfree(sch->driver_override);\n\tkfree(sch->lock);\n\tkfree(sch);\n}\n\nstatic int css_validate_subchannel(struct subchannel_id schid,\n\t\t\t\t   struct schib *schib)\n{\n\tint err;\n\n\tswitch (schib->pmcw.st) {\n\tcase SUBCHANNEL_TYPE_IO:\n\tcase SUBCHANNEL_TYPE_MSG:\n\t\tif (!css_sch_is_valid(schib))\n\t\t\terr = -ENODEV;\n\t\telse if (is_blacklisted(schid.ssid, schib->pmcw.dev)) {\n\t\t\tCIO_MSG_EVENT(6, \"Blacklisted device detected \"\n\t\t\t\t      \"at devno %04X, subchannel set %x\\n\",\n\t\t\t\t      schib->pmcw.dev, schid.ssid);\n\t\t\terr = -ENODEV;\n\t\t} else\n\t\t\terr = 0;\n\t\tbreak;\n\tdefault:\n\t\terr = 0;\n\t}\n\tif (err)\n\t\tgoto out;\n\n\tCIO_MSG_EVENT(4, \"Subchannel 0.%x.%04x reports subchannel type %04X\\n\",\n\t\t      schid.ssid, schid.sch_no, schib->pmcw.st);\nout:\n\treturn err;\n}\n\nstruct subchannel *css_alloc_subchannel(struct subchannel_id schid,\n\t\t\t\t\tstruct schib *schib)\n{\n\tstruct subchannel *sch;\n\tint ret;\n\n\tret = css_validate_subchannel(schid, schib);\n\tif (ret < 0)\n\t\treturn ERR_PTR(ret);\n\n\tsch = kzalloc(sizeof(*sch), GFP_KERNEL | GFP_DMA);\n\tif (!sch)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tsch->schid = schid;\n\tsch->schib = *schib;\n\tsch->st = schib->pmcw.st;\n\n\tret = css_sch_create_locks(sch);\n\tif (ret)\n\t\tgoto err;\n\n\tINIT_WORK(&sch->todo_work, css_sch_todo);\n\tsch->dev.release = &css_subchannel_release;\n\tsch->dev.dma_mask = &sch->dma_mask;\n\tdevice_initialize(&sch->dev);\n\t \n\tret = dma_set_coherent_mask(&sch->dev, DMA_BIT_MASK(31));\n\tif (ret)\n\t\tgoto err_lock;\n\t \n\tret = dma_set_mask(&sch->dev, DMA_BIT_MASK(64));\n\tif (ret)\n\t\tgoto err_lock;\n\n\treturn sch;\n\nerr_lock:\n\tkfree(sch->lock);\nerr:\n\tkfree(sch);\n\treturn ERR_PTR(ret);\n}\n\nstatic int css_sch_device_register(struct subchannel *sch)\n{\n\tint ret;\n\n\tmutex_lock(&sch->reg_mutex);\n\tdev_set_name(&sch->dev, \"0.%x.%04x\", sch->schid.ssid,\n\t\t     sch->schid.sch_no);\n\tret = device_add(&sch->dev);\n\tmutex_unlock(&sch->reg_mutex);\n\treturn ret;\n}\n\n \nvoid css_sch_device_unregister(struct subchannel *sch)\n{\n\tmutex_lock(&sch->reg_mutex);\n\tif (device_is_registered(&sch->dev))\n\t\tdevice_unregister(&sch->dev);\n\tmutex_unlock(&sch->reg_mutex);\n}\nEXPORT_SYMBOL_GPL(css_sch_device_unregister);\n\nstatic void ssd_from_pmcw(struct chsc_ssd_info *ssd, struct pmcw *pmcw)\n{\n\tint i;\n\tint mask;\n\n\tmemset(ssd, 0, sizeof(struct chsc_ssd_info));\n\tssd->path_mask = pmcw->pim;\n\tfor (i = 0; i < 8; i++) {\n\t\tmask = 0x80 >> i;\n\t\tif (pmcw->pim & mask) {\n\t\t\tchp_id_init(&ssd->chpid[i]);\n\t\t\tssd->chpid[i].id = pmcw->chpid[i];\n\t\t}\n\t}\n}\n\nstatic void ssd_register_chpids(struct chsc_ssd_info *ssd)\n{\n\tint i;\n\tint mask;\n\n\tfor (i = 0; i < 8; i++) {\n\t\tmask = 0x80 >> i;\n\t\tif (ssd->path_mask & mask)\n\t\t\tchp_new(ssd->chpid[i]);\n\t}\n}\n\nvoid css_update_ssd_info(struct subchannel *sch)\n{\n\tint ret;\n\n\tret = chsc_get_ssd_info(sch->schid, &sch->ssd_info);\n\tif (ret)\n\t\tssd_from_pmcw(&sch->ssd_info, &sch->schib.pmcw);\n\n\tssd_register_chpids(&sch->ssd_info);\n}\n\nstatic ssize_t type_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\n\treturn sprintf(buf, \"%01x\\n\", sch->st);\n}\n\nstatic DEVICE_ATTR_RO(type);\n\nstatic ssize_t modalias_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\n\treturn sprintf(buf, \"css:t%01X\\n\", sch->st);\n}\n\nstatic DEVICE_ATTR_RO(modalias);\n\nstatic ssize_t driver_override_store(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     const char *buf, size_t count)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\tint ret;\n\n\tret = driver_set_override(dev, &sch->driver_override, buf, count);\n\tif (ret)\n\t\treturn ret;\n\n\treturn count;\n}\n\nstatic ssize_t driver_override_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\tssize_t len;\n\n\tdevice_lock(dev);\n\tlen = snprintf(buf, PAGE_SIZE, \"%s\\n\", sch->driver_override);\n\tdevice_unlock(dev);\n\treturn len;\n}\nstatic DEVICE_ATTR_RW(driver_override);\n\nstatic struct attribute *subch_attrs[] = {\n\t&dev_attr_type.attr,\n\t&dev_attr_modalias.attr,\n\t&dev_attr_driver_override.attr,\n\tNULL,\n};\n\nstatic struct attribute_group subch_attr_group = {\n\t.attrs = subch_attrs,\n};\n\nstatic const struct attribute_group *default_subch_attr_groups[] = {\n\t&subch_attr_group,\n\tNULL,\n};\n\nstatic ssize_t chpids_show(struct device *dev,\n\t\t\t   struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\tstruct chsc_ssd_info *ssd = &sch->ssd_info;\n\tssize_t ret = 0;\n\tint mask;\n\tint chp;\n\n\tfor (chp = 0; chp < 8; chp++) {\n\t\tmask = 0x80 >> chp;\n\t\tif (ssd->path_mask & mask)\n\t\t\tret += sprintf(buf + ret, \"%02x \", ssd->chpid[chp].id);\n\t\telse\n\t\t\tret += sprintf(buf + ret, \"00 \");\n\t}\n\tret += sprintf(buf + ret, \"\\n\");\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(chpids);\n\nstatic ssize_t pimpampom_show(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\tstruct pmcw *pmcw = &sch->schib.pmcw;\n\n\treturn sprintf(buf, \"%02x %02x %02x\\n\",\n\t\t       pmcw->pim, pmcw->pam, pmcw->pom);\n}\nstatic DEVICE_ATTR_RO(pimpampom);\n\nstatic ssize_t dev_busid_show(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\tstruct pmcw *pmcw = &sch->schib.pmcw;\n\n\tif ((pmcw->st == SUBCHANNEL_TYPE_IO && pmcw->dnv) ||\n\t    (pmcw->st == SUBCHANNEL_TYPE_MSG && pmcw->w))\n\t\treturn sysfs_emit(buf, \"0.%x.%04x\\n\", sch->schid.ssid,\n\t\t\t\t  pmcw->dev);\n\telse\n\t\treturn sysfs_emit(buf, \"none\\n\");\n}\nstatic DEVICE_ATTR_RO(dev_busid);\n\nstatic struct attribute *io_subchannel_type_attrs[] = {\n\t&dev_attr_chpids.attr,\n\t&dev_attr_pimpampom.attr,\n\t&dev_attr_dev_busid.attr,\n\tNULL,\n};\nATTRIBUTE_GROUPS(io_subchannel_type);\n\nstatic const struct device_type io_subchannel_type = {\n\t.groups = io_subchannel_type_groups,\n};\n\nint css_register_subchannel(struct subchannel *sch)\n{\n\tint ret;\n\n\t \n\tsch->dev.parent = &channel_subsystems[0]->device;\n\tsch->dev.bus = &css_bus_type;\n\tsch->dev.groups = default_subch_attr_groups;\n\n\tif (sch->st == SUBCHANNEL_TYPE_IO)\n\t\tsch->dev.type = &io_subchannel_type;\n\n\tcss_update_ssd_info(sch);\n\t \n\tret = css_sch_device_register(sch);\n\tif (ret) {\n\t\tCIO_MSG_EVENT(0, \"Could not register sch 0.%x.%04x: %d\\n\",\n\t\t\t      sch->schid.ssid, sch->schid.sch_no, ret);\n\t\treturn ret;\n\t}\n\treturn ret;\n}\n\nstatic int css_probe_device(struct subchannel_id schid, struct schib *schib)\n{\n\tstruct subchannel *sch;\n\tint ret;\n\n\tsch = css_alloc_subchannel(schid, schib);\n\tif (IS_ERR(sch))\n\t\treturn PTR_ERR(sch);\n\n\tret = css_register_subchannel(sch);\n\tif (ret)\n\t\tput_device(&sch->dev);\n\n\treturn ret;\n}\n\nstatic int\ncheck_subchannel(struct device *dev, const void *data)\n{\n\tstruct subchannel *sch;\n\tstruct subchannel_id *schid = (void *)data;\n\n\tsch = to_subchannel(dev);\n\treturn schid_equal(&sch->schid, schid);\n}\n\nstruct subchannel *\nget_subchannel_by_schid(struct subchannel_id schid)\n{\n\tstruct device *dev;\n\n\tdev = bus_find_device(&css_bus_type, NULL,\n\t\t\t      &schid, check_subchannel);\n\n\treturn dev ? to_subchannel(dev) : NULL;\n}\n\n \nint css_sch_is_valid(struct schib *schib)\n{\n\tif ((schib->pmcw.st == SUBCHANNEL_TYPE_IO) && !schib->pmcw.dnv)\n\t\treturn 0;\n\tif ((schib->pmcw.st == SUBCHANNEL_TYPE_MSG) && !schib->pmcw.w)\n\t\treturn 0;\n\treturn 1;\n}\nEXPORT_SYMBOL_GPL(css_sch_is_valid);\n\nstatic int css_evaluate_new_subchannel(struct subchannel_id schid, int slow)\n{\n\tstruct schib schib;\n\tint ccode;\n\n\tif (!slow) {\n\t\t \n\t\treturn -EAGAIN;\n\t}\n\t \n\tccode = stsch(schid, &schib);\n\tif (ccode)\n\t\treturn (ccode == 3) ? -ENXIO : ccode;\n\n\treturn css_probe_device(schid, &schib);\n}\n\nstatic int css_evaluate_known_subchannel(struct subchannel *sch, int slow)\n{\n\tint ret = 0;\n\n\tif (sch->driver) {\n\t\tif (sch->driver->sch_event)\n\t\t\tret = sch->driver->sch_event(sch, slow);\n\t\telse\n\t\t\tdev_dbg(&sch->dev,\n\t\t\t\t\"Got subchannel machine check but \"\n\t\t\t\t\"no sch_event handler provided.\\n\");\n\t}\n\tif (ret != 0 && ret != -EAGAIN) {\n\t\tCIO_MSG_EVENT(2, \"eval: sch 0.%x.%04x, rc=%d\\n\",\n\t\t\t      sch->schid.ssid, sch->schid.sch_no, ret);\n\t}\n\treturn ret;\n}\n\nstatic void css_evaluate_subchannel(struct subchannel_id schid, int slow)\n{\n\tstruct subchannel *sch;\n\tint ret;\n\n\tsch = get_subchannel_by_schid(schid);\n\tif (sch) {\n\t\tret = css_evaluate_known_subchannel(sch, slow);\n\t\tput_device(&sch->dev);\n\t} else\n\t\tret = css_evaluate_new_subchannel(schid, slow);\n\tif (ret == -EAGAIN)\n\t\tcss_schedule_eval(schid);\n}\n\n \nvoid css_sched_sch_todo(struct subchannel *sch, enum sch_todo todo)\n{\n\tCIO_MSG_EVENT(4, \"sch_todo: sched sch=0.%x.%04x todo=%d\\n\",\n\t\t      sch->schid.ssid, sch->schid.sch_no, todo);\n\tif (sch->todo >= todo)\n\t\treturn;\n\t \n\tif (!get_device(&sch->dev))\n\t\treturn;\n\tsch->todo = todo;\n\tif (!queue_work(cio_work_q, &sch->todo_work)) {\n\t\t \n\t\tput_device(&sch->dev);\n\t}\n}\nEXPORT_SYMBOL_GPL(css_sched_sch_todo);\n\nstatic void css_sch_todo(struct work_struct *work)\n{\n\tstruct subchannel *sch;\n\tenum sch_todo todo;\n\tint ret;\n\n\tsch = container_of(work, struct subchannel, todo_work);\n\t \n\tspin_lock_irq(sch->lock);\n\ttodo = sch->todo;\n\tCIO_MSG_EVENT(4, \"sch_todo: sch=0.%x.%04x, todo=%d\\n\", sch->schid.ssid,\n\t\t      sch->schid.sch_no, todo);\n\tsch->todo = SCH_TODO_NOTHING;\n\tspin_unlock_irq(sch->lock);\n\t \n\tswitch (todo) {\n\tcase SCH_TODO_NOTHING:\n\t\tbreak;\n\tcase SCH_TODO_EVAL:\n\t\tret = css_evaluate_known_subchannel(sch, 1);\n\t\tif (ret == -EAGAIN) {\n\t\t\tspin_lock_irq(sch->lock);\n\t\t\tcss_sched_sch_todo(sch, todo);\n\t\t\tspin_unlock_irq(sch->lock);\n\t\t}\n\t\tbreak;\n\tcase SCH_TODO_UNREG:\n\t\tcss_sch_device_unregister(sch);\n\t\tbreak;\n\t}\n\t \n\tput_device(&sch->dev);\n}\n\nstatic struct idset *slow_subchannel_set;\nstatic DEFINE_SPINLOCK(slow_subchannel_lock);\nstatic DECLARE_WAIT_QUEUE_HEAD(css_eval_wq);\nstatic atomic_t css_eval_scheduled;\n\nstatic int __init slow_subchannel_init(void)\n{\n\tatomic_set(&css_eval_scheduled, 0);\n\tslow_subchannel_set = idset_sch_new();\n\tif (!slow_subchannel_set) {\n\t\tCIO_MSG_EVENT(0, \"could not allocate slow subchannel set\\n\");\n\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nstatic int slow_eval_known_fn(struct subchannel *sch, void *data)\n{\n\tint eval;\n\tint rc;\n\n\tspin_lock_irq(&slow_subchannel_lock);\n\teval = idset_sch_contains(slow_subchannel_set, sch->schid);\n\tidset_sch_del(slow_subchannel_set, sch->schid);\n\tspin_unlock_irq(&slow_subchannel_lock);\n\tif (eval) {\n\t\trc = css_evaluate_known_subchannel(sch, 1);\n\t\tif (rc == -EAGAIN)\n\t\t\tcss_schedule_eval(sch->schid);\n\t\t \n\t\tcond_resched();\n\t}\n\treturn 0;\n}\n\nstatic int slow_eval_unknown_fn(struct subchannel_id schid, void *data)\n{\n\tint eval;\n\tint rc = 0;\n\n\tspin_lock_irq(&slow_subchannel_lock);\n\teval = idset_sch_contains(slow_subchannel_set, schid);\n\tidset_sch_del(slow_subchannel_set, schid);\n\tspin_unlock_irq(&slow_subchannel_lock);\n\tif (eval) {\n\t\trc = css_evaluate_new_subchannel(schid, 1);\n\t\tswitch (rc) {\n\t\tcase -EAGAIN:\n\t\t\tcss_schedule_eval(schid);\n\t\t\trc = 0;\n\t\t\tbreak;\n\t\tcase -ENXIO:\n\t\tcase -ENOMEM:\n\t\tcase -EIO:\n\t\t\t \n\t\t\tspin_lock_irq(&slow_subchannel_lock);\n\t\t\tidset_sch_del_subseq(slow_subchannel_set, schid);\n\t\t\tspin_unlock_irq(&slow_subchannel_lock);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\trc = 0;\n\t\t}\n\t\t \n\t\tcond_resched();\n\t}\n\treturn rc;\n}\n\nstatic void css_slow_path_func(struct work_struct *unused)\n{\n\tunsigned long flags;\n\n\tCIO_TRACE_EVENT(4, \"slowpath\");\n\tfor_each_subchannel_staged(slow_eval_known_fn, slow_eval_unknown_fn,\n\t\t\t\t   NULL);\n\tspin_lock_irqsave(&slow_subchannel_lock, flags);\n\tif (idset_is_empty(slow_subchannel_set)) {\n\t\tatomic_set(&css_eval_scheduled, 0);\n\t\twake_up(&css_eval_wq);\n\t}\n\tspin_unlock_irqrestore(&slow_subchannel_lock, flags);\n}\n\nstatic DECLARE_DELAYED_WORK(slow_path_work, css_slow_path_func);\nstruct workqueue_struct *cio_work_q;\n\nvoid css_schedule_eval(struct subchannel_id schid)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&slow_subchannel_lock, flags);\n\tidset_sch_add(slow_subchannel_set, schid);\n\tatomic_set(&css_eval_scheduled, 1);\n\tqueue_delayed_work(cio_work_q, &slow_path_work, 0);\n\tspin_unlock_irqrestore(&slow_subchannel_lock, flags);\n}\n\nvoid css_schedule_eval_all(void)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&slow_subchannel_lock, flags);\n\tidset_fill(slow_subchannel_set);\n\tatomic_set(&css_eval_scheduled, 1);\n\tqueue_delayed_work(cio_work_q, &slow_path_work, 0);\n\tspin_unlock_irqrestore(&slow_subchannel_lock, flags);\n}\n\nstatic int __unset_validpath(struct device *dev, void *data)\n{\n\tstruct idset *set = data;\n\tstruct subchannel *sch = to_subchannel(dev);\n\tstruct pmcw *pmcw = &sch->schib.pmcw;\n\n\t \n\tif (sch->st == SUBCHANNEL_TYPE_IO &&\n\t    (sch->opm & pmcw->pam & pmcw->pom))\n\t\tidset_sch_del(set, sch->schid);\n\n\treturn 0;\n}\n\nstatic int __unset_online(struct device *dev, void *data)\n{\n\tstruct idset *set = data;\n\tstruct subchannel *sch = to_subchannel(dev);\n\n\tif (sch->st == SUBCHANNEL_TYPE_IO && sch->config.ena)\n\t\tidset_sch_del(set, sch->schid);\n\n\treturn 0;\n}\n\nvoid css_schedule_eval_cond(enum css_eval_cond cond, unsigned long delay)\n{\n\tunsigned long flags;\n\tstruct idset *set;\n\n\t \n\tset = idset_sch_new();\n\tif (!set) {\n\t\t \n\t\tcss_schedule_eval_all();\n\t\treturn;\n\t}\n\tidset_fill(set);\n\tswitch (cond) {\n\tcase CSS_EVAL_NO_PATH:\n\t\tbus_for_each_dev(&css_bus_type, NULL, set, __unset_validpath);\n\t\tbreak;\n\tcase CSS_EVAL_NOT_ONLINE:\n\t\tbus_for_each_dev(&css_bus_type, NULL, set, __unset_online);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tspin_lock_irqsave(&slow_subchannel_lock, flags);\n\tidset_add_set(slow_subchannel_set, set);\n\tatomic_set(&css_eval_scheduled, 1);\n\tqueue_delayed_work(cio_work_q, &slow_path_work, delay);\n\tspin_unlock_irqrestore(&slow_subchannel_lock, flags);\n\tidset_free(set);\n}\n\nvoid css_wait_for_slow_path(void)\n{\n\tflush_workqueue(cio_work_q);\n}\n\n \nvoid css_schedule_reprobe(void)\n{\n\t \n\tcss_schedule_eval_cond(CSS_EVAL_NO_PATH, 1 * HZ);\n}\nEXPORT_SYMBOL_GPL(css_schedule_reprobe);\n\n \nstatic void css_process_crw(struct crw *crw0, struct crw *crw1, int overflow)\n{\n\tstruct subchannel_id mchk_schid;\n\tstruct subchannel *sch;\n\n\tif (overflow) {\n\t\tcss_schedule_eval_all();\n\t\treturn;\n\t}\n\tCIO_CRW_EVENT(2, \"CRW0 reports slct=%d, oflw=%d, \"\n\t\t      \"chn=%d, rsc=%X, anc=%d, erc=%X, rsid=%X\\n\",\n\t\t      crw0->slct, crw0->oflw, crw0->chn, crw0->rsc, crw0->anc,\n\t\t      crw0->erc, crw0->rsid);\n\tif (crw1)\n\t\tCIO_CRW_EVENT(2, \"CRW1 reports slct=%d, oflw=%d, \"\n\t\t\t      \"chn=%d, rsc=%X, anc=%d, erc=%X, rsid=%X\\n\",\n\t\t\t      crw1->slct, crw1->oflw, crw1->chn, crw1->rsc,\n\t\t\t      crw1->anc, crw1->erc, crw1->rsid);\n\tinit_subchannel_id(&mchk_schid);\n\tmchk_schid.sch_no = crw0->rsid;\n\tif (crw1)\n\t\tmchk_schid.ssid = (crw1->rsid >> 4) & 3;\n\n\tif (crw0->erc == CRW_ERC_PMOD) {\n\t\tsch = get_subchannel_by_schid(mchk_schid);\n\t\tif (sch) {\n\t\t\tcss_update_ssd_info(sch);\n\t\t\tput_device(&sch->dev);\n\t\t}\n\t}\n\t \n\tcss_evaluate_subchannel(mchk_schid, 0);\n}\n\nstatic void __init\ncss_generate_pgid(struct channel_subsystem *css, u32 tod_high)\n{\n\tstruct cpuid cpu_id;\n\n\tif (css_general_characteristics.mcss) {\n\t\tcss->global_pgid.pgid_high.ext_cssid.version = 0x80;\n\t\tcss->global_pgid.pgid_high.ext_cssid.cssid =\n\t\t\tcss->id_valid ? css->cssid : 0;\n\t} else {\n\t\tcss->global_pgid.pgid_high.cpu_addr = stap();\n\t}\n\tget_cpu_id(&cpu_id);\n\tcss->global_pgid.cpu_id = cpu_id.ident;\n\tcss->global_pgid.cpu_model = cpu_id.machine;\n\tcss->global_pgid.tod_high = tod_high;\n}\n\nstatic void channel_subsystem_release(struct device *dev)\n{\n\tstruct channel_subsystem *css = to_css(dev);\n\n\tmutex_destroy(&css->mutex);\n\tkfree(css);\n}\n\nstatic ssize_t real_cssid_show(struct device *dev, struct device_attribute *a,\n\t\t\t       char *buf)\n{\n\tstruct channel_subsystem *css = to_css(dev);\n\n\tif (!css->id_valid)\n\t\treturn -EINVAL;\n\n\treturn sprintf(buf, \"%x\\n\", css->cssid);\n}\nstatic DEVICE_ATTR_RO(real_cssid);\n\nstatic ssize_t rescan_store(struct device *dev, struct device_attribute *a,\n\t\t\t    const char *buf, size_t count)\n{\n\tCIO_TRACE_EVENT(4, \"usr-rescan\");\n\n\tcss_schedule_eval_all();\n\tcss_complete_work();\n\n\treturn count;\n}\nstatic DEVICE_ATTR_WO(rescan);\n\nstatic ssize_t cm_enable_show(struct device *dev, struct device_attribute *a,\n\t\t\t      char *buf)\n{\n\tstruct channel_subsystem *css = to_css(dev);\n\tint ret;\n\n\tmutex_lock(&css->mutex);\n\tret = sprintf(buf, \"%x\\n\", css->cm_enabled);\n\tmutex_unlock(&css->mutex);\n\treturn ret;\n}\n\nstatic ssize_t cm_enable_store(struct device *dev, struct device_attribute *a,\n\t\t\t       const char *buf, size_t count)\n{\n\tstruct channel_subsystem *css = to_css(dev);\n\tunsigned long val;\n\tint ret;\n\n\tret = kstrtoul(buf, 16, &val);\n\tif (ret)\n\t\treturn ret;\n\tmutex_lock(&css->mutex);\n\tswitch (val) {\n\tcase 0:\n\t\tret = css->cm_enabled ? chsc_secm(css, 0) : 0;\n\t\tbreak;\n\tcase 1:\n\t\tret = css->cm_enabled ? 0 : chsc_secm(css, 1);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\tmutex_unlock(&css->mutex);\n\treturn ret < 0 ? ret : count;\n}\nstatic DEVICE_ATTR_RW(cm_enable);\n\nstatic umode_t cm_enable_mode(struct kobject *kobj, struct attribute *attr,\n\t\t\t      int index)\n{\n\treturn css_chsc_characteristics.secm ? attr->mode : 0;\n}\n\nstatic struct attribute *cssdev_attrs[] = {\n\t&dev_attr_real_cssid.attr,\n\t&dev_attr_rescan.attr,\n\tNULL,\n};\n\nstatic struct attribute_group cssdev_attr_group = {\n\t.attrs = cssdev_attrs,\n};\n\nstatic struct attribute *cssdev_cm_attrs[] = {\n\t&dev_attr_cm_enable.attr,\n\tNULL,\n};\n\nstatic struct attribute_group cssdev_cm_attr_group = {\n\t.attrs = cssdev_cm_attrs,\n\t.is_visible = cm_enable_mode,\n};\n\nstatic const struct attribute_group *cssdev_attr_groups[] = {\n\t&cssdev_attr_group,\n\t&cssdev_cm_attr_group,\n\tNULL,\n};\n\nstatic int __init setup_css(int nr)\n{\n\tstruct channel_subsystem *css;\n\tint ret;\n\n\tcss = kzalloc(sizeof(*css), GFP_KERNEL);\n\tif (!css)\n\t\treturn -ENOMEM;\n\n\tchannel_subsystems[nr] = css;\n\tdev_set_name(&css->device, \"css%x\", nr);\n\tcss->device.groups = cssdev_attr_groups;\n\tcss->device.release = channel_subsystem_release;\n\t \n\tret = dma_coerce_mask_and_coherent(&css->device, DMA_BIT_MASK(64));\n\tif (ret) {\n\t\tkfree(css);\n\t\tgoto out_err;\n\t}\n\n\tmutex_init(&css->mutex);\n\tret = chsc_get_cssid_iid(nr, &css->cssid, &css->iid);\n\tif (!ret) {\n\t\tcss->id_valid = true;\n\t\tpr_info(\"Partition identifier %01x.%01x\\n\", css->cssid,\n\t\t\tcss->iid);\n\t}\n\tcss_generate_pgid(css, (u32) (get_tod_clock() >> 32));\n\n\tret = device_register(&css->device);\n\tif (ret) {\n\t\tput_device(&css->device);\n\t\tgoto out_err;\n\t}\n\n\tcss->pseudo_subchannel = kzalloc(sizeof(*css->pseudo_subchannel),\n\t\t\t\t\t GFP_KERNEL);\n\tif (!css->pseudo_subchannel) {\n\t\tdevice_unregister(&css->device);\n\t\tret = -ENOMEM;\n\t\tgoto out_err;\n\t}\n\n\tcss->pseudo_subchannel->dev.parent = &css->device;\n\tcss->pseudo_subchannel->dev.release = css_subchannel_release;\n\tmutex_init(&css->pseudo_subchannel->reg_mutex);\n\tret = css_sch_create_locks(css->pseudo_subchannel);\n\tif (ret) {\n\t\tkfree(css->pseudo_subchannel);\n\t\tdevice_unregister(&css->device);\n\t\tgoto out_err;\n\t}\n\n\tdev_set_name(&css->pseudo_subchannel->dev, \"defunct\");\n\tret = device_register(&css->pseudo_subchannel->dev);\n\tif (ret) {\n\t\tput_device(&css->pseudo_subchannel->dev);\n\t\tdevice_unregister(&css->device);\n\t\tgoto out_err;\n\t}\n\n\treturn ret;\nout_err:\n\tchannel_subsystems[nr] = NULL;\n\treturn ret;\n}\n\nstatic int css_reboot_event(struct notifier_block *this,\n\t\t\t    unsigned long event,\n\t\t\t    void *ptr)\n{\n\tstruct channel_subsystem *css;\n\tint ret;\n\n\tret = NOTIFY_DONE;\n\tfor_each_css(css) {\n\t\tmutex_lock(&css->mutex);\n\t\tif (css->cm_enabled)\n\t\t\tif (chsc_secm(css, 0))\n\t\t\t\tret = NOTIFY_BAD;\n\t\tmutex_unlock(&css->mutex);\n\t}\n\n\treturn ret;\n}\n\nstatic struct notifier_block css_reboot_notifier = {\n\t.notifier_call = css_reboot_event,\n};\n\n#define  CIO_DMA_GFP (GFP_KERNEL | __GFP_ZERO)\nstatic struct gen_pool *cio_dma_pool;\n\n \nstruct device *cio_get_dma_css_dev(void)\n{\n\treturn &channel_subsystems[0]->device;\n}\n\nstruct gen_pool *cio_gp_dma_create(struct device *dma_dev, int nr_pages)\n{\n\tstruct gen_pool *gp_dma;\n\tvoid *cpu_addr;\n\tdma_addr_t dma_addr;\n\tint i;\n\n\tgp_dma = gen_pool_create(3, -1);\n\tif (!gp_dma)\n\t\treturn NULL;\n\tfor (i = 0; i < nr_pages; ++i) {\n\t\tcpu_addr = dma_alloc_coherent(dma_dev, PAGE_SIZE, &dma_addr,\n\t\t\t\t\t      CIO_DMA_GFP);\n\t\tif (!cpu_addr)\n\t\t\treturn gp_dma;\n\t\tgen_pool_add_virt(gp_dma, (unsigned long) cpu_addr,\n\t\t\t\t  dma_addr, PAGE_SIZE, -1);\n\t}\n\treturn gp_dma;\n}\n\nstatic void __gp_dma_free_dma(struct gen_pool *pool,\n\t\t\t      struct gen_pool_chunk *chunk, void *data)\n{\n\tsize_t chunk_size = chunk->end_addr - chunk->start_addr + 1;\n\n\tdma_free_coherent((struct device *) data, chunk_size,\n\t\t\t (void *) chunk->start_addr,\n\t\t\t (dma_addr_t) chunk->phys_addr);\n}\n\nvoid cio_gp_dma_destroy(struct gen_pool *gp_dma, struct device *dma_dev)\n{\n\tif (!gp_dma)\n\t\treturn;\n\t \n\tgen_pool_for_each_chunk(gp_dma, __gp_dma_free_dma, dma_dev);\n\tgen_pool_destroy(gp_dma);\n}\n\nstatic int cio_dma_pool_init(void)\n{\n\t \n\tcio_dma_pool = cio_gp_dma_create(cio_get_dma_css_dev(), 1);\n\tif (!cio_dma_pool)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid *cio_gp_dma_zalloc(struct gen_pool *gp_dma, struct device *dma_dev,\n\t\t\tsize_t size)\n{\n\tdma_addr_t dma_addr;\n\tunsigned long addr;\n\tsize_t chunk_size;\n\n\tif (!gp_dma)\n\t\treturn NULL;\n\taddr = gen_pool_alloc(gp_dma, size);\n\twhile (!addr) {\n\t\tchunk_size = round_up(size, PAGE_SIZE);\n\t\taddr = (unsigned long) dma_alloc_coherent(dma_dev,\n\t\t\t\t\t chunk_size, &dma_addr, CIO_DMA_GFP);\n\t\tif (!addr)\n\t\t\treturn NULL;\n\t\tgen_pool_add_virt(gp_dma, addr, dma_addr, chunk_size, -1);\n\t\taddr = gen_pool_alloc(gp_dma, size);\n\t}\n\treturn (void *) addr;\n}\n\nvoid cio_gp_dma_free(struct gen_pool *gp_dma, void *cpu_addr, size_t size)\n{\n\tif (!cpu_addr)\n\t\treturn;\n\tmemset(cpu_addr, 0, size);\n\tgen_pool_free(gp_dma, (unsigned long) cpu_addr, size);\n}\n\n \nvoid *cio_dma_zalloc(size_t size)\n{\n\treturn cio_gp_dma_zalloc(cio_dma_pool, cio_get_dma_css_dev(), size);\n}\n\nvoid cio_dma_free(void *cpu_addr, size_t size)\n{\n\tcio_gp_dma_free(cio_dma_pool, cpu_addr, size);\n}\n\n \nstatic int __init css_bus_init(void)\n{\n\tint ret, i;\n\n\tret = chsc_init();\n\tif (ret)\n\t\treturn ret;\n\n\tchsc_determine_css_characteristics();\n\t \n\tret = chsc_enable_facility(CHSC_SDA_OC_MSS);\n\tif (ret)\n\t\tmax_ssid = 0;\n\telse  \n\t\tmax_ssid = __MAX_SSID;\n\n\tret = slow_subchannel_init();\n\tif (ret)\n\t\tgoto out;\n\n\tret = crw_register_handler(CRW_RSC_SCH, css_process_crw);\n\tif (ret)\n\t\tgoto out;\n\n\tif ((ret = bus_register(&css_bus_type)))\n\t\tgoto out;\n\n\t \n\tfor (i = 0; i <= MAX_CSS_IDX; i++) {\n\t\tret = setup_css(i);\n\t\tif (ret)\n\t\t\tgoto out_unregister;\n\t}\n\tret = register_reboot_notifier(&css_reboot_notifier);\n\tif (ret)\n\t\tgoto out_unregister;\n\tret = cio_dma_pool_init();\n\tif (ret)\n\t\tgoto out_unregister_rn;\n\tairq_init();\n\tcss_init_done = 1;\n\n\t \n\tisc_register(IO_SCH_ISC);\n\n\treturn 0;\nout_unregister_rn:\n\tunregister_reboot_notifier(&css_reboot_notifier);\nout_unregister:\n\twhile (i-- > 0) {\n\t\tstruct channel_subsystem *css = channel_subsystems[i];\n\t\tdevice_unregister(&css->pseudo_subchannel->dev);\n\t\tdevice_unregister(&css->device);\n\t}\n\tbus_unregister(&css_bus_type);\nout:\n\tcrw_unregister_handler(CRW_RSC_SCH);\n\tidset_free(slow_subchannel_set);\n\tchsc_init_cleanup();\n\tpr_alert(\"The CSS device driver initialization failed with \"\n\t\t \"errno=%d\\n\", ret);\n\treturn ret;\n}\n\nstatic void __init css_bus_cleanup(void)\n{\n\tstruct channel_subsystem *css;\n\n\tfor_each_css(css) {\n\t\tdevice_unregister(&css->pseudo_subchannel->dev);\n\t\tdevice_unregister(&css->device);\n\t}\n\tbus_unregister(&css_bus_type);\n\tcrw_unregister_handler(CRW_RSC_SCH);\n\tidset_free(slow_subchannel_set);\n\tchsc_init_cleanup();\n\tisc_unregister(IO_SCH_ISC);\n}\n\nstatic int __init channel_subsystem_init(void)\n{\n\tint ret;\n\n\tret = css_bus_init();\n\tif (ret)\n\t\treturn ret;\n\tcio_work_q = create_singlethread_workqueue(\"cio\");\n\tif (!cio_work_q) {\n\t\tret = -ENOMEM;\n\t\tgoto out_bus;\n\t}\n\tret = io_subchannel_init();\n\tif (ret)\n\t\tgoto out_wq;\n\n\t \n\tcio_register_early_subchannels();\n\t \n\tcss_schedule_eval_all();\n\n\treturn ret;\nout_wq:\n\tdestroy_workqueue(cio_work_q);\nout_bus:\n\tcss_bus_cleanup();\n\treturn ret;\n}\nsubsys_initcall(channel_subsystem_init);\n\nstatic int css_settle(struct device_driver *drv, void *unused)\n{\n\tstruct css_driver *cssdrv = to_cssdriver(drv);\n\n\tif (cssdrv->settle)\n\t\treturn cssdrv->settle();\n\treturn 0;\n}\n\nint css_complete_work(void)\n{\n\tint ret;\n\n\t \n\tret = wait_event_interruptible(css_eval_wq,\n\t\t\t\t       atomic_read(&css_eval_scheduled) == 0);\n\tif (ret)\n\t\treturn -EINTR;\n\tflush_workqueue(cio_work_q);\n\t \n\treturn bus_for_each_drv(&css_bus_type, NULL, NULL, css_settle);\n}\n\n\n \nstatic int __init channel_subsystem_init_sync(void)\n{\n\tcss_complete_work();\n\treturn 0;\n}\nsubsys_initcall_sync(channel_subsystem_init_sync);\n\n#ifdef CONFIG_PROC_FS\nstatic ssize_t cio_settle_write(struct file *file, const char __user *buf,\n\t\t\t\tsize_t count, loff_t *ppos)\n{\n\tint ret;\n\n\t \n\tcrw_wait_for_channel_report();\n\tret = css_complete_work();\n\n\treturn ret ? ret : count;\n}\n\nstatic const struct proc_ops cio_settle_proc_ops = {\n\t.proc_open\t= nonseekable_open,\n\t.proc_write\t= cio_settle_write,\n\t.proc_lseek\t= no_llseek,\n};\n\nstatic int __init cio_settle_init(void)\n{\n\tstruct proc_dir_entry *entry;\n\n\tentry = proc_create(\"cio_settle\", S_IWUSR, NULL, &cio_settle_proc_ops);\n\tif (!entry)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\ndevice_initcall(cio_settle_init);\n#endif  \n\nint sch_is_pseudo_sch(struct subchannel *sch)\n{\n\tif (!sch->dev.parent)\n\t\treturn 0;\n\treturn sch == to_css(sch->dev.parent)->pseudo_subchannel;\n}\n\nstatic int css_bus_match(struct device *dev, struct device_driver *drv)\n{\n\tstruct subchannel *sch = to_subchannel(dev);\n\tstruct css_driver *driver = to_cssdriver(drv);\n\tstruct css_device_id *id;\n\n\t \n\tif (sch->driver_override && strcmp(sch->driver_override, drv->name))\n\t\treturn 0;\n\n\tfor (id = driver->subchannel_type; id->match_flags; id++) {\n\t\tif (sch->st == id->type)\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic int css_probe(struct device *dev)\n{\n\tstruct subchannel *sch;\n\tint ret;\n\n\tsch = to_subchannel(dev);\n\tsch->driver = to_cssdriver(dev->driver);\n\tret = sch->driver->probe ? sch->driver->probe(sch) : 0;\n\tif (ret)\n\t\tsch->driver = NULL;\n\treturn ret;\n}\n\nstatic void css_remove(struct device *dev)\n{\n\tstruct subchannel *sch;\n\n\tsch = to_subchannel(dev);\n\tif (sch->driver->remove)\n\t\tsch->driver->remove(sch);\n\tsch->driver = NULL;\n}\n\nstatic void css_shutdown(struct device *dev)\n{\n\tstruct subchannel *sch;\n\n\tsch = to_subchannel(dev);\n\tif (sch->driver && sch->driver->shutdown)\n\t\tsch->driver->shutdown(sch);\n}\n\nstatic int css_uevent(const struct device *dev, struct kobj_uevent_env *env)\n{\n\tconst struct subchannel *sch = to_subchannel(dev);\n\tint ret;\n\n\tret = add_uevent_var(env, \"ST=%01X\", sch->st);\n\tif (ret)\n\t\treturn ret;\n\tret = add_uevent_var(env, \"MODALIAS=css:t%01X\", sch->st);\n\treturn ret;\n}\n\nstatic struct bus_type css_bus_type = {\n\t.name     = \"css\",\n\t.match    = css_bus_match,\n\t.probe    = css_probe,\n\t.remove   = css_remove,\n\t.shutdown = css_shutdown,\n\t.uevent   = css_uevent,\n};\n\n \nint css_driver_register(struct css_driver *cdrv)\n{\n\tcdrv->drv.bus = &css_bus_type;\n\treturn driver_register(&cdrv->drv);\n}\nEXPORT_SYMBOL_GPL(css_driver_register);\n\n \nvoid css_driver_unregister(struct css_driver *cdrv)\n{\n\tdriver_unregister(&cdrv->drv);\n}\nEXPORT_SYMBOL_GPL(css_driver_unregister);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}