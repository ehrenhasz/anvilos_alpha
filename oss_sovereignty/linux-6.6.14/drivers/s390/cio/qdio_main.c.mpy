{
  "module_name": "qdio_main.c",
  "hash_id": "89f2b3c98bf40796ba9e8b6922a4477cc1f943d84a63303392d5a337a3863b30",
  "original_prompt": "Ingested from linux-6.6.14/drivers/s390/cio/qdio_main.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/kmemleak.h>\n#include <linux/delay.h>\n#include <linux/gfp.h>\n#include <linux/io.h>\n#include <linux/atomic.h>\n#include <asm/debug.h>\n#include <asm/qdio.h>\n#include <asm/ipl.h>\n\n#include \"cio.h\"\n#include \"css.h\"\n#include \"device.h\"\n#include \"qdio.h\"\n#include \"qdio_debug.h\"\n\nMODULE_AUTHOR(\"Utz Bacher <utz.bacher@de.ibm.com>,\"\\\n\t\"Jan Glauber <jang@linux.vnet.ibm.com>\");\nMODULE_DESCRIPTION(\"QDIO base support\");\nMODULE_LICENSE(\"GPL\");\n\nstatic inline int do_siga_sync(unsigned long schid,\n\t\t\t       unsigned long out_mask, unsigned long in_mask,\n\t\t\t       unsigned int fc)\n{\n\tint cc;\n\n\tasm volatile(\n\t\t\"\tlgr\t0,%[fc]\\n\"\n\t\t\"\tlgr\t1,%[schid]\\n\"\n\t\t\"\tlgr\t2,%[out]\\n\"\n\t\t\"\tlgr\t3,%[in]\\n\"\n\t\t\"\tsiga\t0\\n\"\n\t\t\"\tipm\t%[cc]\\n\"\n\t\t\"\tsrl\t%[cc],28\\n\"\n\t\t: [cc] \"=&d\" (cc)\n\t\t: [fc] \"d\" (fc), [schid] \"d\" (schid),\n\t\t  [out] \"d\" (out_mask), [in] \"d\" (in_mask)\n\t\t: \"cc\", \"0\", \"1\", \"2\", \"3\");\n\treturn cc;\n}\n\nstatic inline int do_siga_input(unsigned long schid, unsigned long mask,\n\t\t\t\tunsigned long fc)\n{\n\tint cc;\n\n\tasm volatile(\n\t\t\"\tlgr\t0,%[fc]\\n\"\n\t\t\"\tlgr\t1,%[schid]\\n\"\n\t\t\"\tlgr\t2,%[mask]\\n\"\n\t\t\"\tsiga\t0\\n\"\n\t\t\"\tipm\t%[cc]\\n\"\n\t\t\"\tsrl\t%[cc],28\\n\"\n\t\t: [cc] \"=&d\" (cc)\n\t\t: [fc] \"d\" (fc), [schid] \"d\" (schid), [mask] \"d\" (mask)\n\t\t: \"cc\", \"0\", \"1\", \"2\");\n\treturn cc;\n}\n\n \nstatic inline int do_siga_output(unsigned long schid, unsigned long mask,\n\t\t\t\t unsigned int *bb, unsigned long fc,\n\t\t\t\t unsigned long aob)\n{\n\tint cc;\n\n\tasm volatile(\n\t\t\"\tlgr\t0,%[fc]\\n\"\n\t\t\"\tlgr\t1,%[schid]\\n\"\n\t\t\"\tlgr\t2,%[mask]\\n\"\n\t\t\"\tlgr\t3,%[aob]\\n\"\n\t\t\"\tsiga\t0\\n\"\n\t\t\"\tlgr\t%[fc],0\\n\"\n\t\t\"\tipm\t%[cc]\\n\"\n\t\t\"\tsrl\t%[cc],28\\n\"\n\t\t: [cc] \"=&d\" (cc), [fc] \"+&d\" (fc)\n\t\t: [schid] \"d\" (schid), [mask] \"d\" (mask), [aob] \"d\" (aob)\n\t\t: \"cc\", \"0\", \"1\", \"2\", \"3\");\n\t*bb = fc >> 31;\n\treturn cc;\n}\n\n \nstatic int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,\n\t\t\tint start, int count, int auto_ack)\n{\n\tint tmp_count = count, tmp_start = start, nr = q->nr;\n\tunsigned int ccq = 0;\n\n\tqperf_inc(q, eqbs);\n\n\tif (!q->is_input_q)\n\t\tnr += q->irq_ptr->nr_input_qs;\nagain:\n\tccq = do_eqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count,\n\t\t      auto_ack);\n\n\tswitch (ccq) {\n\tcase 0:\n\tcase 32:\n\t\t \n\t\treturn count - tmp_count;\n\tcase 96:\n\t\t \n\t\tqperf_inc(q, eqbs_partial);\n\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"EQBS part:%02x\",\n\t\t\ttmp_count);\n\t\treturn count - tmp_count;\n\tcase 97:\n\t\t \n\t\tDBF_DEV_EVENT(DBF_WARN, q->irq_ptr, \"EQBS again:%2d\", ccq);\n\t\tgoto again;\n\tdefault:\n\t\tDBF_ERROR(\"%4x ccq:%3d\", SCH_NO(q), ccq);\n\t\tDBF_ERROR(\"%4x EQBS ERROR\", SCH_NO(q));\n\t\tDBF_ERROR(\"%3d%3d%2d\", count, tmp_count, nr);\n\t\tq->handler(q->irq_ptr->cdev, QDIO_ERROR_GET_BUF_STATE, q->nr,\n\t\t\t   q->first_to_check, count, q->irq_ptr->int_parm);\n\t\treturn 0;\n\t}\n}\n\n \nstatic int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,\n\t\t\tint count)\n{\n\tunsigned int ccq = 0;\n\tint tmp_count = count, tmp_start = start;\n\tint nr = q->nr;\n\n\tqperf_inc(q, sqbs);\n\n\tif (!q->is_input_q)\n\t\tnr += q->irq_ptr->nr_input_qs;\nagain:\n\tccq = do_sqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count);\n\n\tswitch (ccq) {\n\tcase 0:\n\tcase 32:\n\t\t \n\t\tWARN_ON_ONCE(tmp_count);\n\t\treturn count - tmp_count;\n\tcase 96:\n\t\t \n\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"SQBS again:%2d\", ccq);\n\t\tqperf_inc(q, sqbs_partial);\n\t\tgoto again;\n\tdefault:\n\t\tDBF_ERROR(\"%4x ccq:%3d\", SCH_NO(q), ccq);\n\t\tDBF_ERROR(\"%4x SQBS ERROR\", SCH_NO(q));\n\t\tDBF_ERROR(\"%3d%3d%2d\", count, tmp_count, nr);\n\t\tq->handler(q->irq_ptr->cdev, QDIO_ERROR_SET_BUF_STATE, q->nr,\n\t\t\t   q->first_to_check, count, q->irq_ptr->int_parm);\n\t\treturn 0;\n\t}\n}\n\n \nstatic inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,\n\t\t\t\t unsigned char *state, unsigned int count,\n\t\t\t\t int auto_ack)\n{\n\tunsigned char __state = 0;\n\tint i = 1;\n\n\tif (is_qebsm(q))\n\t\treturn qdio_do_eqbs(q, state, bufnr, count, auto_ack);\n\n\t \n\t__state = q->slsb.val[bufnr];\n\n\t \n\tif (__state & SLSB_OWNER_CU)\n\t\tgoto out;\n\n\tfor (; i < count; i++) {\n\t\tbufnr = next_buf(bufnr);\n\n\t\t \n\t\tif (q->slsb.val[bufnr] != __state)\n\t\t\tbreak;\n\t}\n\nout:\n\t*state = __state;\n\treturn i;\n}\n\nstatic inline int get_buf_state(struct qdio_q *q, unsigned int bufnr,\n\t\t\t\tunsigned char *state, int auto_ack)\n{\n\treturn get_buf_states(q, bufnr, state, 1, auto_ack);\n}\n\n \nstatic inline int set_buf_states(struct qdio_q *q, int bufnr,\n\t\t\t\t unsigned char state, int count)\n{\n\tint i;\n\n\tif (is_qebsm(q))\n\t\treturn qdio_do_sqbs(q, state, bufnr, count);\n\n\t \n\tmb();\n\n\tfor (i = 0; i < count; i++) {\n\t\tWRITE_ONCE(q->slsb.val[bufnr], state);\n\t\tbufnr = next_buf(bufnr);\n\t}\n\n\t \n\tmb();\n\n\treturn count;\n}\n\nstatic inline int set_buf_state(struct qdio_q *q, int bufnr,\n\t\t\t\tunsigned char state)\n{\n\treturn set_buf_states(q, bufnr, state, 1);\n}\n\n \nstatic void qdio_init_buf_states(struct qdio_irq *irq_ptr)\n{\n\tstruct qdio_q *q;\n\tint i;\n\n\tfor_each_input_queue(irq_ptr, q, i)\n\t\tset_buf_states(q, 0, SLSB_P_INPUT_NOT_INIT,\n\t\t\t       QDIO_MAX_BUFFERS_PER_Q);\n\tfor_each_output_queue(irq_ptr, q, i)\n\t\tset_buf_states(q, 0, SLSB_P_OUTPUT_NOT_INIT,\n\t\t\t       QDIO_MAX_BUFFERS_PER_Q);\n}\n\nstatic inline int qdio_siga_sync(struct qdio_q *q, unsigned int output,\n\t\t\t  unsigned int input)\n{\n\tunsigned long schid = *((u32 *) &q->irq_ptr->schid);\n\tunsigned int fc = QDIO_SIGA_SYNC;\n\tint cc;\n\n\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"siga-s:%1d\", q->nr);\n\tqperf_inc(q, siga_sync);\n\n\tif (is_qebsm(q)) {\n\t\tschid = q->irq_ptr->sch_token;\n\t\tfc |= QDIO_SIGA_QEBSM_FLAG;\n\t}\n\n\tcc = do_siga_sync(schid, output, input, fc);\n\tif (unlikely(cc))\n\t\tDBF_ERROR(\"%4x SIGA-S:%2d\", SCH_NO(q), cc);\n\treturn (cc) ? -EIO : 0;\n}\n\nstatic inline int qdio_sync_input_queue(struct qdio_q *q)\n{\n\treturn qdio_siga_sync(q, 0, q->mask);\n}\n\nstatic inline int qdio_sync_output_queue(struct qdio_q *q)\n{\n\treturn qdio_siga_sync(q, q->mask, 0);\n}\n\nstatic inline int qdio_siga_sync_q(struct qdio_q *q)\n{\n\tif (q->is_input_q)\n\t\treturn qdio_sync_input_queue(q);\n\telse\n\t\treturn qdio_sync_output_queue(q);\n}\n\nstatic int qdio_siga_output(struct qdio_q *q, unsigned int count,\n\t\t\t    unsigned int *busy_bit, unsigned long aob)\n{\n\tunsigned long schid = *((u32 *) &q->irq_ptr->schid);\n\tunsigned int fc = QDIO_SIGA_WRITE;\n\tu64 start_time = 0;\n\tint retries = 0, cc;\n\n\tif (queue_type(q) == QDIO_IQDIO_QFMT && !multicast_outbound(q)) {\n\t\tif (count > 1)\n\t\t\tfc = QDIO_SIGA_WRITEM;\n\t\telse if (aob)\n\t\t\tfc = QDIO_SIGA_WRITEQ;\n\t}\n\n\tif (is_qebsm(q)) {\n\t\tschid = q->irq_ptr->sch_token;\n\t\tfc |= QDIO_SIGA_QEBSM_FLAG;\n\t}\nagain:\n\tcc = do_siga_output(schid, q->mask, busy_bit, fc, aob);\n\n\t \n\tif (unlikely(*busy_bit)) {\n\t\tretries++;\n\n\t\tif (!start_time) {\n\t\t\tstart_time = get_tod_clock_fast();\n\t\t\tgoto again;\n\t\t}\n\t\tif (get_tod_clock_fast() - start_time < QDIO_BUSY_BIT_PATIENCE)\n\t\t\tgoto again;\n\t}\n\tif (retries) {\n\t\tDBF_DEV_EVENT(DBF_WARN, q->irq_ptr,\n\t\t\t      \"%4x cc2 BB1:%1d\", SCH_NO(q), q->nr);\n\t\tDBF_DEV_EVENT(DBF_WARN, q->irq_ptr, \"count:%u\", retries);\n\t}\n\treturn cc;\n}\n\nstatic inline int qdio_siga_input(struct qdio_q *q)\n{\n\tunsigned long schid = *((u32 *) &q->irq_ptr->schid);\n\tunsigned int fc = QDIO_SIGA_READ;\n\tint cc;\n\n\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"siga-r:%1d\", q->nr);\n\tqperf_inc(q, siga_read);\n\n\tif (is_qebsm(q)) {\n\t\tschid = q->irq_ptr->sch_token;\n\t\tfc |= QDIO_SIGA_QEBSM_FLAG;\n\t}\n\n\tcc = do_siga_input(schid, q->mask, fc);\n\tif (unlikely(cc))\n\t\tDBF_ERROR(\"%4x SIGA-R:%2d\", SCH_NO(q), cc);\n\treturn (cc) ? -EIO : 0;\n}\n\nint debug_get_buf_state(struct qdio_q *q, unsigned int bufnr,\n\t\t\tunsigned char *state)\n{\n\tif (qdio_need_siga_sync(q->irq_ptr))\n\t\tqdio_siga_sync_q(q);\n\treturn get_buf_state(q, bufnr, state, 0);\n}\n\nstatic inline void qdio_stop_polling(struct qdio_q *q)\n{\n\tif (!q->u.in.batch_count)\n\t\treturn;\n\n\tqperf_inc(q, stop_polling);\n\n\t \n\tset_buf_states(q, q->u.in.batch_start, SLSB_P_INPUT_NOT_INIT,\n\t\t       q->u.in.batch_count);\n\tq->u.in.batch_count = 0;\n}\n\nstatic inline void account_sbals(struct qdio_q *q, unsigned int count)\n{\n\tq->q_stats.nr_sbal_total += count;\n\tq->q_stats.nr_sbals[ilog2(count)]++;\n}\n\nstatic void process_buffer_error(struct qdio_q *q, unsigned int start,\n\t\t\t\t int count)\n{\n\t \n\tif (queue_type(q) == QDIO_IQDIO_QFMT && !q->is_input_q &&\n\t    q->sbal[start]->element[15].sflags == 0x10) {\n\t\tqperf_inc(q, target_full);\n\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"OUTFULL FTC:%02x\", start);\n\t\treturn;\n\t}\n\n\tDBF_ERROR(\"%4x BUF ERROR\", SCH_NO(q));\n\tDBF_ERROR((q->is_input_q) ? \"IN:%2d\" : \"OUT:%2d\", q->nr);\n\tDBF_ERROR(\"FTC:%3d C:%3d\", start, count);\n\tDBF_ERROR(\"F14:%2x F15:%2x\",\n\t\t  q->sbal[start]->element[14].sflags,\n\t\t  q->sbal[start]->element[15].sflags);\n}\n\nstatic inline void inbound_handle_work(struct qdio_q *q, unsigned int start,\n\t\t\t\t       int count, bool auto_ack)\n{\n\t \n\tif (!auto_ack)\n\t\tset_buf_state(q, add_buf(start, count - 1), SLSB_P_INPUT_ACK);\n\n\tif (!q->u.in.batch_count)\n\t\tq->u.in.batch_start = start;\n\tq->u.in.batch_count += count;\n}\n\nstatic int get_inbound_buffer_frontier(struct qdio_q *q, unsigned int start,\n\t\t\t\t       unsigned int *error)\n{\n\tunsigned char state = 0;\n\tint count;\n\n\tq->timestamp = get_tod_clock_fast();\n\n\tcount = atomic_read(&q->nr_buf_used);\n\tif (!count)\n\t\treturn 0;\n\n\tif (qdio_need_siga_sync(q->irq_ptr))\n\t\tqdio_sync_input_queue(q);\n\n\tcount = get_buf_states(q, start, &state, count, 1);\n\tif (!count)\n\t\treturn 0;\n\n\tswitch (state) {\n\tcase SLSB_P_INPUT_PRIMED:\n\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"in prim:%1d %02x\", q->nr,\n\t\t\t      count);\n\n\t\tinbound_handle_work(q, start, count, is_qebsm(q));\n\t\tif (atomic_sub_return(count, &q->nr_buf_used) == 0)\n\t\t\tqperf_inc(q, inbound_queue_full);\n\t\tif (q->irq_ptr->perf_stat_enabled)\n\t\t\taccount_sbals(q, count);\n\t\treturn count;\n\tcase SLSB_P_INPUT_ERROR:\n\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"in err:%1d %02x\", q->nr,\n\t\t\t      count);\n\n\t\t*error = QDIO_ERROR_SLSB_STATE;\n\t\tprocess_buffer_error(q, start, count);\n\t\tinbound_handle_work(q, start, count, false);\n\t\tif (atomic_sub_return(count, &q->nr_buf_used) == 0)\n\t\t\tqperf_inc(q, inbound_queue_full);\n\t\tif (q->irq_ptr->perf_stat_enabled)\n\t\t\taccount_sbals_error(q, count);\n\t\treturn count;\n\tcase SLSB_CU_INPUT_EMPTY:\n\t\tif (q->irq_ptr->perf_stat_enabled)\n\t\t\tq->q_stats.nr_sbal_nop++;\n\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"in nop:%1d %#02x\",\n\t\t\t      q->nr, start);\n\t\treturn 0;\n\tcase SLSB_P_INPUT_NOT_INIT:\n\tcase SLSB_P_INPUT_ACK:\n\t\t \n\tdefault:\n\t\tdev_WARN_ONCE(&q->irq_ptr->cdev->dev, 1,\n\t\t\t      \"found state %#x at index %u on queue %u\\n\",\n\t\t\t      state, start, q->nr);\n\t\treturn 0;\n\t}\n}\n\nint qdio_inspect_input_queue(struct ccw_device *cdev, unsigned int nr,\n\t\t\t     unsigned int *bufnr, unsigned int *error)\n{\n\tstruct qdio_irq *irq = cdev->private->qdio_data;\n\tunsigned int start;\n\tstruct qdio_q *q;\n\tint count;\n\n\tif (!irq)\n\t\treturn -ENODEV;\n\n\tq = irq->input_qs[nr];\n\tstart = q->first_to_check;\n\t*error = 0;\n\n\tcount = get_inbound_buffer_frontier(q, start, error);\n\tif (count == 0)\n\t\treturn 0;\n\n\t*bufnr = start;\n\tq->first_to_check = add_buf(start, count);\n\treturn count;\n}\nEXPORT_SYMBOL_GPL(qdio_inspect_input_queue);\n\nstatic inline int qdio_inbound_q_done(struct qdio_q *q, unsigned int start)\n{\n\tunsigned char state = 0;\n\n\tif (!atomic_read(&q->nr_buf_used))\n\t\treturn 1;\n\n\tif (qdio_need_siga_sync(q->irq_ptr))\n\t\tqdio_sync_input_queue(q);\n\tget_buf_state(q, start, &state, 0);\n\n\tif (state == SLSB_P_INPUT_PRIMED || state == SLSB_P_INPUT_ERROR)\n\t\t \n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic int get_outbound_buffer_frontier(struct qdio_q *q, unsigned int start,\n\t\t\t\t\tunsigned int *error)\n{\n\tunsigned char state = 0;\n\tint count;\n\n\tq->timestamp = get_tod_clock_fast();\n\n\tcount = atomic_read(&q->nr_buf_used);\n\tif (!count)\n\t\treturn 0;\n\n\tif (qdio_need_siga_sync(q->irq_ptr))\n\t\tqdio_sync_output_queue(q);\n\n\tcount = get_buf_states(q, start, &state, count, 0);\n\tif (!count)\n\t\treturn 0;\n\n\tswitch (state) {\n\tcase SLSB_P_OUTPUT_PENDING:\n\t\t*error = QDIO_ERROR_SLSB_PENDING;\n\t\tfallthrough;\n\tcase SLSB_P_OUTPUT_EMPTY:\n\t\t \n\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr,\n\t\t\t\"out empty:%1d %02x\", q->nr, count);\n\n\t\tatomic_sub(count, &q->nr_buf_used);\n\t\tif (q->irq_ptr->perf_stat_enabled)\n\t\t\taccount_sbals(q, count);\n\t\treturn count;\n\tcase SLSB_P_OUTPUT_ERROR:\n\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"out error:%1d %02x\",\n\t\t\t      q->nr, count);\n\n\t\t*error = QDIO_ERROR_SLSB_STATE;\n\t\tprocess_buffer_error(q, start, count);\n\t\tatomic_sub(count, &q->nr_buf_used);\n\t\tif (q->irq_ptr->perf_stat_enabled)\n\t\t\taccount_sbals_error(q, count);\n\t\treturn count;\n\tcase SLSB_CU_OUTPUT_PRIMED:\n\t\t \n\t\tif (q->irq_ptr->perf_stat_enabled)\n\t\t\tq->q_stats.nr_sbal_nop++;\n\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"out primed:%1d\",\n\t\t\t      q->nr);\n\t\treturn 0;\n\tcase SLSB_P_OUTPUT_HALTED:\n\t\treturn 0;\n\tcase SLSB_P_OUTPUT_NOT_INIT:\n\t\t \n\tdefault:\n\t\tdev_WARN_ONCE(&q->irq_ptr->cdev->dev, 1,\n\t\t\t      \"found state %#x at index %u on queue %u\\n\",\n\t\t\t      state, start, q->nr);\n\t\treturn 0;\n\t}\n}\n\nint qdio_inspect_output_queue(struct ccw_device *cdev, unsigned int nr,\n\t\t\t      unsigned int *bufnr, unsigned int *error)\n{\n\tstruct qdio_irq *irq = cdev->private->qdio_data;\n\tunsigned int start;\n\tstruct qdio_q *q;\n\tint count;\n\n\tif (!irq)\n\t\treturn -ENODEV;\n\n\tq = irq->output_qs[nr];\n\tstart = q->first_to_check;\n\t*error = 0;\n\n\tcount = get_outbound_buffer_frontier(q, start, error);\n\tif (count == 0)\n\t\treturn 0;\n\n\t*bufnr = start;\n\tq->first_to_check = add_buf(start, count);\n\treturn count;\n}\nEXPORT_SYMBOL_GPL(qdio_inspect_output_queue);\n\nstatic int qdio_kick_outbound_q(struct qdio_q *q, unsigned int count,\n\t\t\t\tunsigned long aob)\n{\n\tint retries = 0, cc;\n\tunsigned int busy_bit;\n\n\tif (!qdio_need_siga_out(q->irq_ptr))\n\t\treturn 0;\n\n\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"siga-w:%1d\", q->nr);\nretry:\n\tqperf_inc(q, siga_write);\n\n\tcc = qdio_siga_output(q, count, &busy_bit, aob);\n\tswitch (cc) {\n\tcase 0:\n\t\tbreak;\n\tcase 2:\n\t\tif (busy_bit) {\n\t\t\twhile (++retries < QDIO_BUSY_BIT_RETRIES) {\n\t\t\t\tmdelay(QDIO_BUSY_BIT_RETRY_DELAY);\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tDBF_ERROR(\"%4x cc2 BBC:%1d\", SCH_NO(q), q->nr);\n\t\t\tcc = -EBUSY;\n\t\t} else {\n\t\t\tDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, \"siga-w cc2:%1d\", q->nr);\n\t\t\tcc = -ENOBUFS;\n\t\t}\n\t\tbreak;\n\tcase 1:\n\tcase 3:\n\t\tDBF_ERROR(\"%4x SIGA-W:%1d\", SCH_NO(q), cc);\n\t\tcc = -EIO;\n\t\tbreak;\n\t}\n\tif (retries) {\n\t\tDBF_ERROR(\"%4x cc2 BB2:%1d\", SCH_NO(q), q->nr);\n\t\tDBF_ERROR(\"count:%u\", retries);\n\t}\n\treturn cc;\n}\n\nstatic inline void qdio_set_state(struct qdio_irq *irq_ptr,\n\t\t\t\t  enum qdio_irq_states state)\n{\n\tDBF_DEV_EVENT(DBF_INFO, irq_ptr, \"newstate: %1d\", state);\n\n\tirq_ptr->state = state;\n\tmb();\n}\n\nstatic void qdio_irq_check_sense(struct qdio_irq *irq_ptr, struct irb *irb)\n{\n\tif (irb->esw.esw0.erw.cons) {\n\t\tDBF_ERROR(\"%4x sense:\", irq_ptr->schid.sch_no);\n\t\tDBF_ERROR_HEX(irb, 64);\n\t\tDBF_ERROR_HEX(irb->ecw, 64);\n\t}\n}\n\n \nstatic void qdio_int_handler_pci(struct qdio_irq *irq_ptr)\n{\n\tif (unlikely(irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))\n\t\treturn;\n\n\tqdio_deliver_irq(irq_ptr);\n\tirq_ptr->last_data_irq_time = S390_lowcore.int_clock;\n}\n\nstatic void qdio_handle_activate_check(struct qdio_irq *irq_ptr,\n\t\t\t\t       unsigned long intparm, int cstat,\n\t\t\t\t       int dstat)\n{\n\tunsigned int first_to_check = 0;\n\n\tDBF_ERROR(\"%4x ACT CHECK\", irq_ptr->schid.sch_no);\n\tDBF_ERROR(\"intp :%lx\", intparm);\n\tDBF_ERROR(\"ds: %2x cs:%2x\", dstat, cstat);\n\n\t \n\tif (irq_ptr->nr_input_qs)\n\t\tfirst_to_check = irq_ptr->input_qs[0]->first_to_check;\n\n\tirq_ptr->error_handler(irq_ptr->cdev, QDIO_ERROR_ACTIVATE, 0,\n\t\t\t       first_to_check, 0, irq_ptr->int_parm);\n\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);\n\t \n\tlgr_info_log();\n}\n\nstatic void qdio_establish_handle_irq(struct qdio_irq *irq_ptr, int cstat,\n\t\t\t\t      int dstat)\n{\n\tDBF_DEV_EVENT(DBF_INFO, irq_ptr, \"qest irq\");\n\n\tif (cstat)\n\t\tgoto error;\n\tif (dstat & ~(DEV_STAT_DEV_END | DEV_STAT_CHN_END))\n\t\tgoto error;\n\tif (!(dstat & DEV_STAT_DEV_END))\n\t\tgoto error;\n\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_ESTABLISHED);\n\treturn;\n\nerror:\n\tDBF_ERROR(\"%4x EQ:error\", irq_ptr->schid.sch_no);\n\tDBF_ERROR(\"ds: %2x cs:%2x\", dstat, cstat);\n\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);\n}\n\n \nvoid qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,\n\t\t      struct irb *irb)\n{\n\tstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\n\tstruct subchannel_id schid;\n\tint cstat, dstat;\n\n\tif (!intparm || !irq_ptr) {\n\t\tccw_device_get_schid(cdev, &schid);\n\t\tDBF_ERROR(\"qint:%4x\", schid.sch_no);\n\t\treturn;\n\t}\n\n\tif (irq_ptr->perf_stat_enabled)\n\t\tirq_ptr->perf_stat.qdio_int++;\n\n\tif (IS_ERR(irb)) {\n\t\tDBF_ERROR(\"%4x IO error\", irq_ptr->schid.sch_no);\n\t\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);\n\t\twake_up(&cdev->private->wait_q);\n\t\treturn;\n\t}\n\tqdio_irq_check_sense(irq_ptr, irb);\n\tcstat = irb->scsw.cmd.cstat;\n\tdstat = irb->scsw.cmd.dstat;\n\n\tswitch (irq_ptr->state) {\n\tcase QDIO_IRQ_STATE_INACTIVE:\n\t\tqdio_establish_handle_irq(irq_ptr, cstat, dstat);\n\t\tbreak;\n\tcase QDIO_IRQ_STATE_CLEANUP:\n\t\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);\n\t\tbreak;\n\tcase QDIO_IRQ_STATE_ESTABLISHED:\n\tcase QDIO_IRQ_STATE_ACTIVE:\n\t\tif (cstat & SCHN_STAT_PCI) {\n\t\t\tqdio_int_handler_pci(irq_ptr);\n\t\t\treturn;\n\t\t}\n\t\tif (cstat || dstat)\n\t\t\tqdio_handle_activate_check(irq_ptr, intparm, cstat,\n\t\t\t\t\t\t   dstat);\n\t\tbreak;\n\tcase QDIO_IRQ_STATE_STOPPED:\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t}\n\twake_up(&cdev->private->wait_q);\n}\n\n \nint qdio_get_ssqd_desc(struct ccw_device *cdev,\n\t\t       struct qdio_ssqd_desc *data)\n{\n\tstruct subchannel_id schid;\n\n\tif (!cdev || !cdev->private)\n\t\treturn -EINVAL;\n\n\tccw_device_get_schid(cdev, &schid);\n\tDBF_EVENT(\"get ssqd:%4x\", schid.sch_no);\n\treturn qdio_setup_get_ssqd(NULL, &schid, data);\n}\nEXPORT_SYMBOL_GPL(qdio_get_ssqd_desc);\n\nstatic int qdio_cancel_ccw(struct qdio_irq *irq, int how)\n{\n\tstruct ccw_device *cdev = irq->cdev;\n\tlong timeout;\n\tint rc;\n\n\tspin_lock_irq(get_ccwdev_lock(cdev));\n\tqdio_set_state(irq, QDIO_IRQ_STATE_CLEANUP);\n\tif (how & QDIO_FLAG_CLEANUP_USING_CLEAR)\n\t\trc = ccw_device_clear(cdev, QDIO_DOING_CLEANUP);\n\telse\n\t\t \n\t\trc = ccw_device_halt(cdev, QDIO_DOING_CLEANUP);\n\tspin_unlock_irq(get_ccwdev_lock(cdev));\n\tif (rc) {\n\t\tDBF_ERROR(\"%4x SHUTD ERR\", irq->schid.sch_no);\n\t\tDBF_ERROR(\"rc:%4d\", rc);\n\t\treturn rc;\n\t}\n\n\ttimeout = wait_event_interruptible_timeout(cdev->private->wait_q,\n\t\t\t\t\t\t   irq->state == QDIO_IRQ_STATE_INACTIVE ||\n\t\t\t\t\t\t   irq->state == QDIO_IRQ_STATE_ERR,\n\t\t\t\t\t\t   10 * HZ);\n\tif (timeout <= 0)\n\t\trc = (timeout == -ERESTARTSYS) ? -EINTR : -ETIME;\n\n\treturn rc;\n}\n\n \nint qdio_shutdown(struct ccw_device *cdev, int how)\n{\n\tstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\n\tstruct subchannel_id schid;\n\tint rc;\n\n\tif (!irq_ptr)\n\t\treturn -ENODEV;\n\n\tWARN_ON_ONCE(irqs_disabled());\n\tccw_device_get_schid(cdev, &schid);\n\tDBF_EVENT(\"qshutdown:%4x\", schid.sch_no);\n\n\tmutex_lock(&irq_ptr->setup_mutex);\n\t \n\tif (irq_ptr->state == QDIO_IRQ_STATE_INACTIVE) {\n\t\tmutex_unlock(&irq_ptr->setup_mutex);\n\t\treturn 0;\n\t}\n\n\t \n\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);\n\n\tqdio_shutdown_debug_entries(irq_ptr);\n\n\trc = qdio_cancel_ccw(irq_ptr, how);\n\tqdio_shutdown_thinint(irq_ptr);\n\tqdio_shutdown_irq(irq_ptr);\n\n\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);\n\tmutex_unlock(&irq_ptr->setup_mutex);\n\tif (rc)\n\t\treturn rc;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(qdio_shutdown);\n\n \nint qdio_free(struct ccw_device *cdev)\n{\n\tstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\n\tstruct subchannel_id schid;\n\n\tif (!irq_ptr)\n\t\treturn -ENODEV;\n\n\tccw_device_get_schid(cdev, &schid);\n\tDBF_EVENT(\"qfree:%4x\", schid.sch_no);\n\tDBF_DEV_EVENT(DBF_ERR, irq_ptr, \"dbf abandoned\");\n\tmutex_lock(&irq_ptr->setup_mutex);\n\n\tirq_ptr->debug_area = NULL;\n\tcdev->private->qdio_data = NULL;\n\tmutex_unlock(&irq_ptr->setup_mutex);\n\n\tqdio_free_queues(irq_ptr);\n\tfree_page((unsigned long) irq_ptr->qdr);\n\tfree_page(irq_ptr->chsc_page);\n\tkfree(irq_ptr->ccw);\n\tfree_page((unsigned long) irq_ptr);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(qdio_free);\n\n \nint qdio_allocate(struct ccw_device *cdev, unsigned int no_input_qs,\n\t\t  unsigned int no_output_qs)\n{\n\tstruct subchannel_id schid;\n\tstruct qdio_irq *irq_ptr;\n\tint rc = -ENOMEM;\n\n\tccw_device_get_schid(cdev, &schid);\n\tDBF_EVENT(\"qallocate:%4x\", schid.sch_no);\n\n\tif (no_input_qs > QDIO_MAX_QUEUES_PER_IRQ ||\n\t    no_output_qs > QDIO_MAX_QUEUES_PER_IRQ)\n\t\treturn -EINVAL;\n\n\tirq_ptr = (void *) get_zeroed_page(GFP_KERNEL);\n\tif (!irq_ptr)\n\t\treturn -ENOMEM;\n\n\tirq_ptr->ccw = kmalloc(sizeof(*irq_ptr->ccw), GFP_KERNEL | GFP_DMA);\n\tif (!irq_ptr->ccw)\n\t\tgoto err_ccw;\n\n\t \n\tkmemleak_not_leak(irq_ptr->ccw);\n\n\tirq_ptr->cdev = cdev;\n\tmutex_init(&irq_ptr->setup_mutex);\n\tif (qdio_allocate_dbf(irq_ptr))\n\t\tgoto err_dbf;\n\n\tDBF_DEV_EVENT(DBF_ERR, irq_ptr, \"alloc niq:%1u noq:%1u\", no_input_qs,\n\t\t      no_output_qs);\n\n\t \n\tirq_ptr->chsc_page = get_zeroed_page(GFP_KERNEL);\n\tif (!irq_ptr->chsc_page)\n\t\tgoto err_chsc;\n\n\t \n\tirq_ptr->qdr = (struct qdr *) get_zeroed_page(GFP_KERNEL | GFP_DMA);\n\tif (!irq_ptr->qdr)\n\t\tgoto err_qdr;\n\n\trc = qdio_allocate_qs(irq_ptr, no_input_qs, no_output_qs);\n\tif (rc)\n\t\tgoto err_queues;\n\n\tcdev->private->qdio_data = irq_ptr;\n\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);\n\treturn 0;\n\nerr_queues:\n\tfree_page((unsigned long) irq_ptr->qdr);\nerr_qdr:\n\tfree_page(irq_ptr->chsc_page);\nerr_chsc:\nerr_dbf:\n\tkfree(irq_ptr->ccw);\nerr_ccw:\n\tfree_page((unsigned long) irq_ptr);\n\treturn rc;\n}\nEXPORT_SYMBOL_GPL(qdio_allocate);\n\nstatic void qdio_trace_init_data(struct qdio_irq *irq,\n\t\t\t\t struct qdio_initialize *data)\n{\n\tDBF_DEV_EVENT(DBF_ERR, irq, \"qfmt:%1u\", data->q_format);\n\tDBF_DEV_EVENT(DBF_ERR, irq, \"qpff%4x\", data->qib_param_field_format);\n\tDBF_DEV_HEX(irq, &data->qib_param_field, sizeof(void *), DBF_ERR);\n\tDBF_DEV_EVENT(DBF_ERR, irq, \"niq:%1u noq:%1u\", data->no_input_qs,\n\t\t      data->no_output_qs);\n\tDBF_DEV_HEX(irq, &data->input_handler, sizeof(void *), DBF_ERR);\n\tDBF_DEV_HEX(irq, &data->output_handler, sizeof(void *), DBF_ERR);\n\tDBF_DEV_HEX(irq, &data->int_parm, sizeof(long), DBF_ERR);\n\tDBF_DEV_HEX(irq, &data->input_sbal_addr_array, sizeof(void *), DBF_ERR);\n\tDBF_DEV_HEX(irq, &data->output_sbal_addr_array, sizeof(void *),\n\t\t    DBF_ERR);\n}\n\n \nint qdio_establish(struct ccw_device *cdev,\n\t\t   struct qdio_initialize *init_data)\n{\n\tstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\n\tstruct subchannel_id schid;\n\tstruct ciw *ciw;\n\tlong timeout;\n\tint rc;\n\n\tccw_device_get_schid(cdev, &schid);\n\tDBF_EVENT(\"qestablish:%4x\", schid.sch_no);\n\n\tif (!irq_ptr)\n\t\treturn -ENODEV;\n\n\tif (init_data->no_input_qs > irq_ptr->max_input_qs ||\n\t    init_data->no_output_qs > irq_ptr->max_output_qs)\n\t\treturn -EINVAL;\n\n\t \n\tif (!init_data->input_handler)\n\t\treturn -EINVAL;\n\n\tif (init_data->no_output_qs && !init_data->output_handler)\n\t\treturn -EINVAL;\n\n\tif (!init_data->input_sbal_addr_array ||\n\t    !init_data->output_sbal_addr_array)\n\t\treturn -EINVAL;\n\n\tif (!init_data->irq_poll)\n\t\treturn -EINVAL;\n\n\tciw = ccw_device_get_ciw(cdev, CIW_TYPE_EQUEUE);\n\tif (!ciw) {\n\t\tDBF_ERROR(\"%4x NO EQ\", schid.sch_no);\n\t\treturn -EIO;\n\t}\n\n\tmutex_lock(&irq_ptr->setup_mutex);\n\tqdio_trace_init_data(irq_ptr, init_data);\n\tqdio_setup_irq(irq_ptr, init_data);\n\n\trc = qdio_establish_thinint(irq_ptr);\n\tif (rc)\n\t\tgoto err_thinint;\n\n\t \n\tirq_ptr->ccw->cmd_code = ciw->cmd;\n\tirq_ptr->ccw->flags = CCW_FLAG_SLI;\n\tirq_ptr->ccw->count = ciw->count;\n\tirq_ptr->ccw->cda = (u32) virt_to_phys(irq_ptr->qdr);\n\n\tspin_lock_irq(get_ccwdev_lock(cdev));\n\tccw_device_set_options_mask(cdev, 0);\n\n\trc = ccw_device_start(cdev, irq_ptr->ccw, QDIO_DOING_ESTABLISH, 0, 0);\n\tspin_unlock_irq(get_ccwdev_lock(cdev));\n\tif (rc) {\n\t\tDBF_ERROR(\"%4x est IO ERR\", irq_ptr->schid.sch_no);\n\t\tDBF_ERROR(\"rc:%4x\", rc);\n\t\tgoto err_ccw_start;\n\t}\n\n\ttimeout = wait_event_interruptible_timeout(cdev->private->wait_q,\n\t\t\t\t\t\t   irq_ptr->state == QDIO_IRQ_STATE_ESTABLISHED ||\n\t\t\t\t\t\t   irq_ptr->state == QDIO_IRQ_STATE_ERR, HZ);\n\tif (timeout <= 0) {\n\t\trc = (timeout == -ERESTARTSYS) ? -EINTR : -ETIME;\n\t\tgoto err_ccw_timeout;\n\t}\n\n\tif (irq_ptr->state != QDIO_IRQ_STATE_ESTABLISHED) {\n\t\trc = -EIO;\n\t\tgoto err_ccw_error;\n\t}\n\n\tqdio_setup_ssqd_info(irq_ptr);\n\n\t \n\tqdio_init_buf_states(irq_ptr);\n\n\tmutex_unlock(&irq_ptr->setup_mutex);\n\tqdio_print_subchannel_info(irq_ptr);\n\tqdio_setup_debug_entries(irq_ptr);\n\treturn 0;\n\nerr_ccw_timeout:\n\tqdio_cancel_ccw(irq_ptr, QDIO_FLAG_CLEANUP_USING_CLEAR);\nerr_ccw_error:\nerr_ccw_start:\n\tqdio_shutdown_thinint(irq_ptr);\nerr_thinint:\n\tqdio_shutdown_irq(irq_ptr);\n\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);\n\tmutex_unlock(&irq_ptr->setup_mutex);\n\treturn rc;\n}\nEXPORT_SYMBOL_GPL(qdio_establish);\n\n \nint qdio_activate(struct ccw_device *cdev)\n{\n\tstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\n\tstruct subchannel_id schid;\n\tstruct ciw *ciw;\n\tint rc;\n\n\tccw_device_get_schid(cdev, &schid);\n\tDBF_EVENT(\"qactivate:%4x\", schid.sch_no);\n\n\tif (!irq_ptr)\n\t\treturn -ENODEV;\n\n\tciw = ccw_device_get_ciw(cdev, CIW_TYPE_AQUEUE);\n\tif (!ciw) {\n\t\tDBF_ERROR(\"%4x NO AQ\", schid.sch_no);\n\t\treturn -EIO;\n\t}\n\n\tmutex_lock(&irq_ptr->setup_mutex);\n\tif (irq_ptr->state == QDIO_IRQ_STATE_INACTIVE) {\n\t\trc = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tirq_ptr->ccw->cmd_code = ciw->cmd;\n\tirq_ptr->ccw->flags = CCW_FLAG_SLI;\n\tirq_ptr->ccw->count = ciw->count;\n\tirq_ptr->ccw->cda = 0;\n\n\tspin_lock_irq(get_ccwdev_lock(cdev));\n\tccw_device_set_options(cdev, CCWDEV_REPORT_ALL);\n\n\trc = ccw_device_start(cdev, irq_ptr->ccw, QDIO_DOING_ACTIVATE,\n\t\t\t      0, DOIO_DENY_PREFETCH);\n\tspin_unlock_irq(get_ccwdev_lock(cdev));\n\tif (rc) {\n\t\tDBF_ERROR(\"%4x act IO ERR\", irq_ptr->schid.sch_no);\n\t\tDBF_ERROR(\"rc:%4x\", rc);\n\t\tgoto out;\n\t}\n\n\t \n\tmsleep(5);\n\n\tswitch (irq_ptr->state) {\n\tcase QDIO_IRQ_STATE_STOPPED:\n\tcase QDIO_IRQ_STATE_ERR:\n\t\trc = -EIO;\n\t\tbreak;\n\tdefault:\n\t\tqdio_set_state(irq_ptr, QDIO_IRQ_STATE_ACTIVE);\n\t\trc = 0;\n\t}\nout:\n\tmutex_unlock(&irq_ptr->setup_mutex);\n\treturn rc;\n}\nEXPORT_SYMBOL_GPL(qdio_activate);\n\n \nstatic int handle_inbound(struct qdio_q *q, int bufnr, int count)\n{\n\tint overlap;\n\n\tqperf_inc(q, inbound_call);\n\n\t \n\toverlap = min_t(int, count - sub_buf(q->u.in.batch_start, bufnr),\n\t\t\t     q->u.in.batch_count);\n\tif (overlap > 0) {\n\t\tq->u.in.batch_start = add_buf(q->u.in.batch_start, overlap);\n\t\tq->u.in.batch_count -= overlap;\n\t}\n\n\tcount = set_buf_states(q, bufnr, SLSB_CU_INPUT_EMPTY, count);\n\tatomic_add(count, &q->nr_buf_used);\n\n\tif (qdio_need_siga_in(q->irq_ptr))\n\t\treturn qdio_siga_input(q);\n\n\treturn 0;\n}\n\n \nint qdio_add_bufs_to_input_queue(struct ccw_device *cdev, unsigned int q_nr,\n\t\t\t\t unsigned int bufnr, unsigned int count)\n{\n\tstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\n\n\tif (bufnr >= QDIO_MAX_BUFFERS_PER_Q || count > QDIO_MAX_BUFFERS_PER_Q)\n\t\treturn -EINVAL;\n\n\tif (!irq_ptr)\n\t\treturn -ENODEV;\n\n\tDBF_DEV_EVENT(DBF_INFO, irq_ptr, \"addi b:%02x c:%02x\", bufnr, count);\n\n\tif (irq_ptr->state != QDIO_IRQ_STATE_ACTIVE)\n\t\treturn -EIO;\n\tif (!count)\n\t\treturn 0;\n\n\treturn handle_inbound(irq_ptr->input_qs[q_nr], bufnr, count);\n}\nEXPORT_SYMBOL_GPL(qdio_add_bufs_to_input_queue);\n\n \nstatic int handle_outbound(struct qdio_q *q, unsigned int bufnr, unsigned int count,\n\t\t\t   struct qaob *aob)\n{\n\tunsigned char state = 0;\n\tint used, rc = 0;\n\n\tqperf_inc(q, outbound_call);\n\n\tcount = set_buf_states(q, bufnr, SLSB_CU_OUTPUT_PRIMED, count);\n\tused = atomic_add_return(count, &q->nr_buf_used);\n\n\tif (used == QDIO_MAX_BUFFERS_PER_Q)\n\t\tqperf_inc(q, outbound_queue_full);\n\n\tif (queue_type(q) == QDIO_IQDIO_QFMT) {\n\t\tunsigned long phys_aob = aob ? virt_to_phys(aob) : 0;\n\n\t\tWARN_ON_ONCE(!IS_ALIGNED(phys_aob, 256));\n\t\trc = qdio_kick_outbound_q(q, count, phys_aob);\n\t} else if (qdio_need_siga_sync(q->irq_ptr)) {\n\t\trc = qdio_sync_output_queue(q);\n\t} else if (count < QDIO_MAX_BUFFERS_PER_Q &&\n\t\t   get_buf_state(q, prev_buf(bufnr), &state, 0) > 0 &&\n\t\t   state == SLSB_CU_OUTPUT_PRIMED) {\n\t\t \n\t\tqperf_inc(q, fast_requeue);\n\t} else {\n\t\trc = qdio_kick_outbound_q(q, count, 0);\n\t}\n\n\treturn rc;\n}\n\n \nint qdio_add_bufs_to_output_queue(struct ccw_device *cdev, unsigned int q_nr,\n\t\t\t\t  unsigned int bufnr, unsigned int count,\n\t\t\t\t  struct qaob *aob)\n{\n\tstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\n\n\tif (bufnr >= QDIO_MAX_BUFFERS_PER_Q || count > QDIO_MAX_BUFFERS_PER_Q)\n\t\treturn -EINVAL;\n\n\tif (!irq_ptr)\n\t\treturn -ENODEV;\n\n\tDBF_DEV_EVENT(DBF_INFO, irq_ptr, \"addo b:%02x c:%02x\", bufnr, count);\n\n\tif (irq_ptr->state != QDIO_IRQ_STATE_ACTIVE)\n\t\treturn -EIO;\n\tif (!count)\n\t\treturn 0;\n\n\treturn handle_outbound(irq_ptr->output_qs[q_nr], bufnr, count, aob);\n}\nEXPORT_SYMBOL_GPL(qdio_add_bufs_to_output_queue);\n\n \nint qdio_start_irq(struct ccw_device *cdev)\n{\n\tstruct qdio_q *q;\n\tstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\n\tunsigned int i;\n\n\tif (!irq_ptr)\n\t\treturn -ENODEV;\n\n\tfor_each_input_queue(irq_ptr, q, i)\n\t\tqdio_stop_polling(q);\n\n\tclear_bit(QDIO_IRQ_DISABLED, &irq_ptr->poll_state);\n\n\t \n\tif (test_nonshared_ind(irq_ptr))\n\t\tgoto rescan;\n\n\tfor_each_input_queue(irq_ptr, q, i) {\n\t\tif (!qdio_inbound_q_done(q, q->first_to_check))\n\t\t\tgoto rescan;\n\t}\n\n\treturn 0;\n\nrescan:\n\tif (test_and_set_bit(QDIO_IRQ_DISABLED, &irq_ptr->poll_state))\n\t\treturn 0;\n\telse\n\t\treturn 1;\n\n}\nEXPORT_SYMBOL(qdio_start_irq);\n\n \nint qdio_stop_irq(struct ccw_device *cdev)\n{\n\tstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\n\n\tif (!irq_ptr)\n\t\treturn -ENODEV;\n\n\tif (test_and_set_bit(QDIO_IRQ_DISABLED, &irq_ptr->poll_state))\n\t\treturn 0;\n\telse\n\t\treturn 1;\n}\nEXPORT_SYMBOL(qdio_stop_irq);\n\nstatic int __init init_QDIO(void)\n{\n\tint rc;\n\n\trc = qdio_debug_init();\n\tif (rc)\n\t\treturn rc;\n\trc = qdio_setup_init();\n\tif (rc)\n\t\tgoto out_debug;\n\trc = qdio_thinint_init();\n\tif (rc)\n\t\tgoto out_cache;\n\treturn 0;\n\nout_cache:\n\tqdio_setup_exit();\nout_debug:\n\tqdio_debug_exit();\n\treturn rc;\n}\n\nstatic void __exit exit_QDIO(void)\n{\n\tqdio_thinint_exit();\n\tqdio_setup_exit();\n\tqdio_debug_exit();\n}\n\nmodule_init(init_QDIO);\nmodule_exit(exit_QDIO);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}