{
  "module_name": "pio.c",
  "hash_id": "3b9bcab9f9041ac986c63f96782af9e2a7f5b7b68a7f772ac06fe5f27911e519",
  "original_prompt": "Ingested from linux-6.6.14/drivers/i3c/master/mipi-i3c-hci/pio.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/device.h>\n#include <linux/errno.h>\n#include <linux/i3c/master.h>\n#include <linux/io.h>\n\n#include \"hci.h\"\n#include \"cmd.h\"\n#include \"ibi.h\"\n\n\n \n\n#define pio_reg_read(r)\t\treadl(hci->PIO_regs + (PIO_##r))\n#define pio_reg_write(r, v)\twritel(v, hci->PIO_regs + (PIO_##r))\n\n#define PIO_COMMAND_QUEUE_PORT\t\t0x00\n#define PIO_RESPONSE_QUEUE_PORT\t\t0x04\n#define PIO_XFER_DATA_PORT\t\t0x08\n#define PIO_IBI_PORT\t\t\t0x0c\n\n#define PIO_QUEUE_THLD_CTRL\t\t0x10\n#define QUEUE_IBI_STATUS_THLD\t\tGENMASK(31, 24)\n#define QUEUE_IBI_DATA_THLD\t\tGENMASK(23, 16)\n#define QUEUE_RESP_BUF_THLD\t\tGENMASK(15, 8)\n#define QUEUE_CMD_EMPTY_BUF_THLD\tGENMASK(7, 0)\n\n#define PIO_DATA_BUFFER_THLD_CTRL\t0x14\n#define DATA_RX_START_THLD\t\tGENMASK(26, 24)\n#define DATA_TX_START_THLD\t\tGENMASK(18, 16)\n#define DATA_RX_BUF_THLD\t\tGENMASK(10, 8)\n#define DATA_TX_BUF_THLD\t\tGENMASK(2, 0)\n\n#define PIO_QUEUE_SIZE\t\t\t0x18\n#define TX_DATA_BUFFER_SIZE\t\tGENMASK(31, 24)\n#define RX_DATA_BUFFER_SIZE\t\tGENMASK(23, 16)\n#define IBI_STATUS_SIZE\t\t\tGENMASK(15, 8)\n#define CR_QUEUE_SIZE\t\t\tGENMASK(7, 0)\n\n#define PIO_INTR_STATUS\t\t\t0x20\n#define PIO_INTR_STATUS_ENABLE\t\t0x24\n#define PIO_INTR_SIGNAL_ENABLE\t\t0x28\n#define PIO_INTR_FORCE\t\t\t0x2c\n#define STAT_TRANSFER_BLOCKED\t\tBIT(25)\n#define STAT_PERR_RESP_UFLOW\t\tBIT(24)\n#define STAT_PERR_CMD_OFLOW\t\tBIT(23)\n#define STAT_PERR_IBI_UFLOW\t\tBIT(22)\n#define STAT_PERR_RX_UFLOW\t\tBIT(21)\n#define STAT_PERR_TX_OFLOW\t\tBIT(20)\n#define STAT_ERR_RESP_QUEUE_FULL\tBIT(19)\n#define STAT_WARN_RESP_QUEUE_FULL\tBIT(18)\n#define STAT_ERR_IBI_QUEUE_FULL\t\tBIT(17)\n#define STAT_WARN_IBI_QUEUE_FULL\tBIT(16)\n#define STAT_ERR_RX_DATA_FULL\t\tBIT(15)\n#define STAT_WARN_RX_DATA_FULL\t\tBIT(14)\n#define STAT_ERR_TX_DATA_EMPTY\t\tBIT(13)\n#define STAT_WARN_TX_DATA_EMPTY\t\tBIT(12)\n#define STAT_TRANSFER_ERR\t\tBIT(9)\n#define STAT_WARN_INS_STOP_MODE\t\tBIT(7)\n#define STAT_TRANSFER_ABORT\t\tBIT(5)\n#define STAT_RESP_READY\t\t\tBIT(4)\n#define STAT_CMD_QUEUE_READY\t\tBIT(3)\n#define STAT_IBI_STATUS_THLD\t\tBIT(2)\n#define STAT_RX_THLD\t\t\tBIT(1)\n#define STAT_TX_THLD\t\t\tBIT(0)\n\n#define PIO_QUEUE_CUR_STATUS\t\t0x38\n#define CUR_IBI_Q_LEVEL\t\t\tGENMASK(28, 20)\n#define CUR_RESP_Q_LEVEL\t\tGENMASK(18, 10)\n#define CUR_CMD_Q_EMPTY_LEVEL\t\tGENMASK(8, 0)\n\n#define PIO_DATA_BUFFER_CUR_STATUS\t0x3c\n#define CUR_RX_BUF_LVL\t\t\tGENMASK(26, 16)\n#define CUR_TX_BUF_LVL\t\t\tGENMASK(10, 0)\n\n \n\n#define STAT_LATENCY_WARNINGS\t\t(STAT_WARN_RESP_QUEUE_FULL | \\\n\t\t\t\t\t STAT_WARN_IBI_QUEUE_FULL | \\\n\t\t\t\t\t STAT_WARN_RX_DATA_FULL | \\\n\t\t\t\t\t STAT_WARN_TX_DATA_EMPTY | \\\n\t\t\t\t\t STAT_WARN_INS_STOP_MODE)\n\n#define STAT_LATENCY_ERRORS\t\t(STAT_ERR_RESP_QUEUE_FULL | \\\n\t\t\t\t\t STAT_ERR_IBI_QUEUE_FULL | \\\n\t\t\t\t\t STAT_ERR_RX_DATA_FULL | \\\n\t\t\t\t\t STAT_ERR_TX_DATA_EMPTY)\n\n#define STAT_PROG_ERRORS\t\t(STAT_TRANSFER_BLOCKED | \\\n\t\t\t\t\t STAT_PERR_RESP_UFLOW | \\\n\t\t\t\t\t STAT_PERR_CMD_OFLOW | \\\n\t\t\t\t\t STAT_PERR_IBI_UFLOW | \\\n\t\t\t\t\t STAT_PERR_RX_UFLOW | \\\n\t\t\t\t\t STAT_PERR_TX_OFLOW)\n\n#define STAT_ALL_ERRORS\t\t\t(STAT_TRANSFER_ABORT | \\\n\t\t\t\t\t STAT_TRANSFER_ERR | \\\n\t\t\t\t\t STAT_LATENCY_ERRORS | \\\n\t\t\t\t\t STAT_PROG_ERRORS)\n\nstruct hci_pio_dev_ibi_data {\n\tstruct i3c_generic_ibi_pool *pool;\n\tunsigned int max_len;\n};\n\nstruct hci_pio_ibi_data {\n\tstruct i3c_ibi_slot *slot;\n\tvoid *data_ptr;\n\tunsigned int addr;\n\tunsigned int seg_len, seg_cnt;\n\tunsigned int max_len;\n\tbool last_seg;\n};\n\nstruct hci_pio_data {\n\tspinlock_t lock;\n\tstruct hci_xfer *curr_xfer, *xfer_queue;\n\tstruct hci_xfer *curr_rx, *rx_queue;\n\tstruct hci_xfer *curr_tx, *tx_queue;\n\tstruct hci_xfer *curr_resp, *resp_queue;\n\tstruct hci_pio_ibi_data ibi;\n\tunsigned int rx_thresh_size, tx_thresh_size;\n\tunsigned int max_ibi_thresh;\n\tu32 reg_queue_thresh;\n\tu32 enabled_irqs;\n};\n\nstatic int hci_pio_init(struct i3c_hci *hci)\n{\n\tstruct hci_pio_data *pio;\n\tu32 val, size_val, rx_thresh, tx_thresh, ibi_val;\n\n\tpio = kzalloc(sizeof(*pio), GFP_KERNEL);\n\tif (!pio)\n\t\treturn -ENOMEM;\n\n\thci->io_data = pio;\n\tspin_lock_init(&pio->lock);\n\n\tsize_val = pio_reg_read(QUEUE_SIZE);\n\tdev_info(&hci->master.dev, \"CMD/RESP FIFO = %ld entries\\n\",\n\t\t FIELD_GET(CR_QUEUE_SIZE, size_val));\n\tdev_info(&hci->master.dev, \"IBI FIFO = %ld bytes\\n\",\n\t\t 4 * FIELD_GET(IBI_STATUS_SIZE, size_val));\n\tdev_info(&hci->master.dev, \"RX data FIFO = %d bytes\\n\",\n\t\t 4 * (2 << FIELD_GET(RX_DATA_BUFFER_SIZE, size_val)));\n\tdev_info(&hci->master.dev, \"TX data FIFO = %d bytes\\n\",\n\t\t 4 * (2 << FIELD_GET(TX_DATA_BUFFER_SIZE, size_val)));\n\n\t \n\trx_thresh = FIELD_GET(RX_DATA_BUFFER_SIZE, size_val);\n\ttx_thresh = FIELD_GET(TX_DATA_BUFFER_SIZE, size_val);\n\tif (hci->version_major == 1) {\n\t\t \n\t\tif (rx_thresh)\n\t\t\trx_thresh -= 1;\n\t\tif (tx_thresh)\n\t\t\ttx_thresh -= 1;\n\t\tpio->rx_thresh_size = 2 << rx_thresh;\n\t\tpio->tx_thresh_size = 2 << tx_thresh;\n\t} else {\n\t\t \n\t\tpio->rx_thresh_size = 1 << rx_thresh;\n\t\tpio->tx_thresh_size = 1 << tx_thresh;\n\t}\n\tval = FIELD_PREP(DATA_RX_BUF_THLD,   rx_thresh) |\n\t      FIELD_PREP(DATA_TX_BUF_THLD,   tx_thresh);\n\tpio_reg_write(DATA_BUFFER_THLD_CTRL, val);\n\n\t \n\tibi_val = FIELD_GET(IBI_STATUS_SIZE, size_val);\n\tpio->max_ibi_thresh = clamp_val(ibi_val/2, 1, 63);\n\tval = FIELD_PREP(QUEUE_IBI_STATUS_THLD, 1) |\n\t      FIELD_PREP(QUEUE_IBI_DATA_THLD, pio->max_ibi_thresh) |\n\t      FIELD_PREP(QUEUE_RESP_BUF_THLD, 1) |\n\t      FIELD_PREP(QUEUE_CMD_EMPTY_BUF_THLD, 1);\n\tpio_reg_write(QUEUE_THLD_CTRL, val);\n\tpio->reg_queue_thresh = val;\n\n\t \n\tpio_reg_write(INTR_SIGNAL_ENABLE, 0x0);\n\tpio_reg_write(INTR_STATUS_ENABLE, 0xffffffff);\n\n\t \n\tpio->enabled_irqs = STAT_ALL_ERRORS;\n\n\treturn 0;\n}\n\nstatic void hci_pio_cleanup(struct i3c_hci *hci)\n{\n\tstruct hci_pio_data *pio = hci->io_data;\n\n\tpio_reg_write(INTR_SIGNAL_ENABLE, 0x0);\n\n\tif (pio) {\n\t\tDBG(\"status = %#x/%#x\",\n\t\t    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));\n\t\tBUG_ON(pio->curr_xfer);\n\t\tBUG_ON(pio->curr_rx);\n\t\tBUG_ON(pio->curr_tx);\n\t\tBUG_ON(pio->curr_resp);\n\t\tkfree(pio);\n\t\thci->io_data = NULL;\n\t}\n}\n\nstatic void hci_pio_write_cmd(struct i3c_hci *hci, struct hci_xfer *xfer)\n{\n\tDBG(\"cmd_desc[%d] = 0x%08x\", 0, xfer->cmd_desc[0]);\n\tDBG(\"cmd_desc[%d] = 0x%08x\", 1, xfer->cmd_desc[1]);\n\tpio_reg_write(COMMAND_QUEUE_PORT, xfer->cmd_desc[0]);\n\tpio_reg_write(COMMAND_QUEUE_PORT, xfer->cmd_desc[1]);\n\tif (hci->cmd == &mipi_i3c_hci_cmd_v2) {\n\t\tDBG(\"cmd_desc[%d] = 0x%08x\", 2, xfer->cmd_desc[2]);\n\t\tDBG(\"cmd_desc[%d] = 0x%08x\", 3, xfer->cmd_desc[3]);\n\t\tpio_reg_write(COMMAND_QUEUE_PORT, xfer->cmd_desc[2]);\n\t\tpio_reg_write(COMMAND_QUEUE_PORT, xfer->cmd_desc[3]);\n\t}\n}\n\nstatic bool hci_pio_do_rx(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\tstruct hci_xfer *xfer = pio->curr_rx;\n\tunsigned int nr_words;\n\tu32 *p;\n\n\tp = xfer->data;\n\tp += (xfer->data_len - xfer->data_left) / 4;\n\n\twhile (xfer->data_left >= 4) {\n\t\t \n\t\tif (!(pio_reg_read(INTR_STATUS) & STAT_RX_THLD))\n\t\t\treturn false;\n\t\tnr_words = min(xfer->data_left / 4, pio->rx_thresh_size);\n\t\t \n\t\txfer->data_left -= nr_words * 4;\n\t\tDBG(\"now %d left %d\", nr_words * 4, xfer->data_left);\n\t\twhile (nr_words--)\n\t\t\t*p++ = pio_reg_read(XFER_DATA_PORT);\n\t}\n\n\t \n\treturn !xfer->data_left;\n}\n\nstatic void hci_pio_do_trailing_rx(struct i3c_hci *hci,\n\t\t\t\t   struct hci_pio_data *pio, unsigned int count)\n{\n\tstruct hci_xfer *xfer = pio->curr_rx;\n\tu32 *p;\n\n\tDBG(\"%d remaining\", count);\n\n\tp = xfer->data;\n\tp += (xfer->data_len - xfer->data_left) / 4;\n\n\tif (count >= 4) {\n\t\tunsigned int nr_words = count / 4;\n\t\t \n\t\txfer->data_left -= nr_words * 4;\n\t\tDBG(\"now %d left %d\", nr_words * 4, xfer->data_left);\n\t\twhile (nr_words--)\n\t\t\t*p++ = pio_reg_read(XFER_DATA_PORT);\n\t}\n\n\tcount &= 3;\n\tif (count) {\n\t\t \n\t\tu8 *p_byte = (u8 *)p;\n\t\tu32 data = pio_reg_read(XFER_DATA_PORT);\n\n\t\txfer->data_word_before_partial = data;\n\t\txfer->data_left -= count;\n\t\tdata = (__force u32) cpu_to_le32(data);\n\t\twhile (count--) {\n\t\t\t*p_byte++ = data;\n\t\t\tdata >>= 8;\n\t\t}\n\t}\n}\n\nstatic bool hci_pio_do_tx(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\tstruct hci_xfer *xfer = pio->curr_tx;\n\tunsigned int nr_words;\n\tu32 *p;\n\n\tp = xfer->data;\n\tp += (xfer->data_len - xfer->data_left) / 4;\n\n\twhile (xfer->data_left >= 4) {\n\t\t \n\t\tif (!(pio_reg_read(INTR_STATUS) & STAT_TX_THLD))\n\t\t\treturn false;\n\t\t \n\t\tnr_words = min(xfer->data_left / 4, pio->tx_thresh_size);\n\t\t \n\t\txfer->data_left -= nr_words * 4;\n\t\tDBG(\"now %d left %d\", nr_words * 4, xfer->data_left);\n\t\twhile (nr_words--)\n\t\t\tpio_reg_write(XFER_DATA_PORT, *p++);\n\t}\n\n\tif (xfer->data_left) {\n\t\t \n\t\tif (!(pio_reg_read(INTR_STATUS) & STAT_TX_THLD))\n\t\t\treturn false;\n\t\tDBG(\"trailing %d\", xfer->data_left);\n\t\tpio_reg_write(XFER_DATA_PORT, *p);\n\t\txfer->data_left = 0;\n\t}\n\n\treturn true;\n}\n\nstatic bool hci_pio_process_rx(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\twhile (pio->curr_rx && hci_pio_do_rx(hci, pio))\n\t\tpio->curr_rx = pio->curr_rx->next_data;\n\treturn !pio->curr_rx;\n}\n\nstatic bool hci_pio_process_tx(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\twhile (pio->curr_tx && hci_pio_do_tx(hci, pio))\n\t\tpio->curr_tx = pio->curr_tx->next_data;\n\treturn !pio->curr_tx;\n}\n\nstatic void hci_pio_queue_data(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\tstruct hci_xfer *xfer = pio->curr_xfer;\n\tstruct hci_xfer *prev_queue_tail;\n\n\tif (!xfer->data) {\n\t\txfer->data_len = xfer->data_left = 0;\n\t\treturn;\n\t}\n\n\tif (xfer->rnw) {\n\t\tprev_queue_tail = pio->rx_queue;\n\t\tpio->rx_queue = xfer;\n\t\tif (pio->curr_rx) {\n\t\t\tprev_queue_tail->next_data = xfer;\n\t\t} else {\n\t\t\tpio->curr_rx = xfer;\n\t\t\tif (!hci_pio_process_rx(hci, pio))\n\t\t\t\tpio->enabled_irqs |= STAT_RX_THLD;\n\t\t}\n\t} else {\n\t\tprev_queue_tail = pio->tx_queue;\n\t\tpio->tx_queue = xfer;\n\t\tif (pio->curr_tx) {\n\t\t\tprev_queue_tail->next_data = xfer;\n\t\t} else {\n\t\t\tpio->curr_tx = xfer;\n\t\t\tif (!hci_pio_process_tx(hci, pio))\n\t\t\t\tpio->enabled_irqs |= STAT_TX_THLD;\n\t\t}\n\t}\n}\n\nstatic void hci_pio_push_to_next_rx(struct i3c_hci *hci, struct hci_xfer *xfer,\n\t\t\t\t    unsigned int words_to_keep)\n{\n\tu32 *from = xfer->data;\n\tu32 from_last;\n\tunsigned int received, count;\n\n\treceived = (xfer->data_len - xfer->data_left) / 4;\n\tif ((xfer->data_len - xfer->data_left) & 3) {\n\t\tfrom_last = xfer->data_word_before_partial;\n\t\treceived += 1;\n\t} else {\n\t\tfrom_last = from[received];\n\t}\n\tfrom += words_to_keep;\n\tcount = received - words_to_keep;\n\n\twhile (count) {\n\t\tunsigned int room, left, chunk, bytes_to_move;\n\t\tu32 last_word;\n\n\t\txfer = xfer->next_data;\n\t\tif (!xfer) {\n\t\t\tdev_err(&hci->master.dev, \"pushing RX data to unexistent xfer\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\troom = DIV_ROUND_UP(xfer->data_len, 4);\n\t\tleft = DIV_ROUND_UP(xfer->data_left, 4);\n\t\tchunk = min(count, room);\n\t\tif (chunk > left) {\n\t\t\thci_pio_push_to_next_rx(hci, xfer, chunk - left);\n\t\t\tleft = chunk;\n\t\t\txfer->data_left = left * 4;\n\t\t}\n\n\t\tbytes_to_move = xfer->data_len - xfer->data_left;\n\t\tif (bytes_to_move & 3) {\n\t\t\t \n\t\t\tu32 *p = xfer->data;\n\n\t\t\txfer->data_word_before_partial = p[bytes_to_move / 4];\n\t\t}\n\t\tmemmove(xfer->data + chunk, xfer->data, bytes_to_move);\n\n\t\t \n\t\tchunk -= 1;\n\n\t\tmemcpy(xfer->data, from, chunk * 4);\n\t\txfer->data_left -= chunk * 4;\n\t\tfrom += chunk;\n\t\tcount -= chunk;\n\n\t\tlast_word = (count == 1) ? from_last : *from++;\n\t\tif (xfer->data_left < 4) {\n\t\t\t \n\t\t\tu8 *p_byte = xfer->data;\n\n\t\t\tp_byte += chunk * 4;\n\t\t\txfer->data_word_before_partial = last_word;\n\t\t\tlast_word = (__force u32) cpu_to_le32(last_word);\n\t\t\twhile (xfer->data_left--) {\n\t\t\t\t*p_byte++ = last_word;\n\t\t\t\tlast_word >>= 8;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 *p = xfer->data;\n\n\t\t\tp[chunk] = last_word;\n\t\t\txfer->data_left -= 4;\n\t\t}\n\t\tcount--;\n\t}\n}\n\nstatic void hci_pio_err(struct i3c_hci *hci, struct hci_pio_data *pio,\n\t\t\tu32 status);\n\nstatic bool hci_pio_process_resp(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\twhile (pio->curr_resp &&\n\t       (pio_reg_read(INTR_STATUS) & STAT_RESP_READY)) {\n\t\tstruct hci_xfer *xfer = pio->curr_resp;\n\t\tu32 resp = pio_reg_read(RESPONSE_QUEUE_PORT);\n\t\tunsigned int tid = RESP_TID(resp);\n\n\t\tDBG(\"resp = 0x%08x\", resp);\n\t\tif (tid != xfer->cmd_tid) {\n\t\t\tdev_err(&hci->master.dev,\n\t\t\t\t\"response tid=%d when expecting %d\\n\",\n\t\t\t\ttid, xfer->cmd_tid);\n\t\t\t \n\t\t\thci_pio_err(hci, pio, STAT_PROG_ERRORS);\n\t\t\treturn false;\n\t\t}\n\t\txfer->response = resp;\n\n\t\tif (pio->curr_rx == xfer) {\n\t\t\t \n\t\t\tunsigned int received, expected, to_keep;\n\n\t\t\treceived = xfer->data_len - xfer->data_left;\n\t\t\texpected = RESP_DATA_LENGTH(xfer->response);\n\t\t\tif (expected > received) {\n\t\t\t\thci_pio_do_trailing_rx(hci, pio,\n\t\t\t\t\t\t       expected - received);\n\t\t\t} else if (received > expected) {\n\t\t\t\t \n\t\t\t\tto_keep = DIV_ROUND_UP(expected, 4);\n\t\t\t\thci_pio_push_to_next_rx(hci, xfer, to_keep);\n\t\t\t}\n\n\t\t\t \n\t\t\tif (hci_pio_process_rx(hci, pio))\n\t\t\t\tpio->enabled_irqs &= ~STAT_RX_THLD;\n\t\t}\n\n\t\t \n\t\tif (pio->curr_rx == xfer) {\n\t\t\tDBG(\"short RX ?\");\n\t\t\tpio->curr_rx = pio->curr_rx->next_data;\n\t\t} else if (pio->curr_tx == xfer) {\n\t\t\tDBG(\"short TX ?\");\n\t\t\tpio->curr_tx = pio->curr_tx->next_data;\n\t\t} else if (xfer->data_left) {\n\t\t\tDBG(\"PIO xfer count = %d after response\",\n\t\t\t    xfer->data_left);\n\t\t}\n\n\t\tpio->curr_resp = xfer->next_resp;\n\t\tif (xfer->completion)\n\t\t\tcomplete(xfer->completion);\n\t}\n\treturn !pio->curr_resp;\n}\n\nstatic void hci_pio_queue_resp(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\tstruct hci_xfer *xfer = pio->curr_xfer;\n\tstruct hci_xfer *prev_queue_tail;\n\n\tif (!(xfer->cmd_desc[0] & CMD_0_ROC))\n\t\treturn;\n\n\tprev_queue_tail = pio->resp_queue;\n\tpio->resp_queue = xfer;\n\tif (pio->curr_resp) {\n\t\tprev_queue_tail->next_resp = xfer;\n\t} else {\n\t\tpio->curr_resp = xfer;\n\t\tif (!hci_pio_process_resp(hci, pio))\n\t\t\tpio->enabled_irqs |= STAT_RESP_READY;\n\t}\n}\n\nstatic bool hci_pio_process_cmd(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\twhile (pio->curr_xfer &&\n\t       (pio_reg_read(INTR_STATUS) & STAT_CMD_QUEUE_READY)) {\n\t\t \n\t\thci_pio_queue_data(hci, pio);\n\t\t \n\t\thci_pio_queue_resp(hci, pio);\n\t\t \n\t\thci_pio_write_cmd(hci, pio->curr_xfer);\n\t\t \n\t\tpio->curr_xfer = pio->curr_xfer->next_xfer;\n\t}\n\treturn !pio->curr_xfer;\n}\n\nstatic int hci_pio_queue_xfer(struct i3c_hci *hci, struct hci_xfer *xfer, int n)\n{\n\tstruct hci_pio_data *pio = hci->io_data;\n\tstruct hci_xfer *prev_queue_tail;\n\tint i;\n\n\tDBG(\"n = %d\", n);\n\n\t \n\tfor (i = 0; i < n; i++) {\n\t\txfer[i].next_xfer = (i + 1 < n) ? &xfer[i + 1] : NULL;\n\t\txfer[i].next_data = NULL;\n\t\txfer[i].next_resp = NULL;\n\t\txfer[i].data_left = xfer[i].data_len;\n\t}\n\n\tspin_lock_irq(&pio->lock);\n\tprev_queue_tail = pio->xfer_queue;\n\tpio->xfer_queue = &xfer[n - 1];\n\tif (pio->curr_xfer) {\n\t\tprev_queue_tail->next_xfer = xfer;\n\t} else {\n\t\tpio->curr_xfer = xfer;\n\t\tif (!hci_pio_process_cmd(hci, pio))\n\t\t\tpio->enabled_irqs |= STAT_CMD_QUEUE_READY;\n\t\tpio_reg_write(INTR_SIGNAL_ENABLE, pio->enabled_irqs);\n\t\tDBG(\"status = %#x/%#x\",\n\t\t    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));\n\t}\n\tspin_unlock_irq(&pio->lock);\n\treturn 0;\n}\n\nstatic bool hci_pio_dequeue_xfer_common(struct i3c_hci *hci,\n\t\t\t\t\tstruct hci_pio_data *pio,\n\t\t\t\t\tstruct hci_xfer *xfer, int n)\n{\n\tstruct hci_xfer *p, **p_prev_next;\n\tint i;\n\n\t \n\tfor (p = pio->curr_resp; p; p = p->next_resp)\n\t\tfor (i = 0; i < n; i++)\n\t\t\tif (p == &xfer[i])\n\t\t\t\tgoto pio_screwed;\n\tfor (p = pio->curr_rx; p; p = p->next_data)\n\t\tfor (i = 0; i < n; i++)\n\t\t\tif (p == &xfer[i])\n\t\t\t\tgoto pio_screwed;\n\tfor (p = pio->curr_tx; p; p = p->next_data)\n\t\tfor (i = 0; i < n; i++)\n\t\t\tif (p == &xfer[i])\n\t\t\t\tgoto pio_screwed;\n\n\t \n\tp_prev_next = &pio->curr_xfer;\n\tfor (p = pio->curr_xfer; p; p = p->next_xfer) {\n\t\tif (p == &xfer[0]) {\n\t\t\t*p_prev_next = xfer[n - 1].next_xfer;\n\t\t\tbreak;\n\t\t}\n\t\tp_prev_next = &p->next_xfer;\n\t}\n\n\t \n\treturn !!p;\n\npio_screwed:\n\t \n\tfor (p = pio->curr_resp; p; p = p->next_resp) {\n\t\tp->response = FIELD_PREP(RESP_ERR_FIELD, RESP_ERR_HC_TERMINATED);\n\t\tif (p->completion)\n\t\t\tcomplete(p->completion);\n\t}\n\tfor (p = pio->curr_xfer; p; p = p->next_xfer) {\n\t\tp->response = FIELD_PREP(RESP_ERR_FIELD, RESP_ERR_HC_TERMINATED);\n\t\tif (p->completion)\n\t\t\tcomplete(p->completion);\n\t}\n\tpio->curr_xfer = pio->curr_rx = pio->curr_tx = pio->curr_resp = NULL;\n\n\treturn true;\n}\n\nstatic bool hci_pio_dequeue_xfer(struct i3c_hci *hci, struct hci_xfer *xfer, int n)\n{\n\tstruct hci_pio_data *pio = hci->io_data;\n\tint ret;\n\n\tspin_lock_irq(&pio->lock);\n\tDBG(\"n=%d status=%#x/%#x\", n,\n\t    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));\n\tDBG(\"main_status = %#x/%#x\",\n\t    readl(hci->base_regs + 0x20), readl(hci->base_regs + 0x28));\n\n\tret = hci_pio_dequeue_xfer_common(hci, pio, xfer, n);\n\tspin_unlock_irq(&pio->lock);\n\treturn ret;\n}\n\nstatic void hci_pio_err(struct i3c_hci *hci, struct hci_pio_data *pio,\n\t\t\tu32 status)\n{\n\t \n\n\tif (pio_reg_read(INTR_STATUS) & STAT_RESP_READY) {\n\t\t \n\t\tu32 resp = pio_reg_read(RESPONSE_QUEUE_PORT);\n\n\t\tdev_err(&hci->master.dev,\n\t\t\t\"orphan response (%#x) on error\\n\", resp);\n\t}\n\n\t \n\tif (status & STAT_PROG_ERRORS) {\n\t\tu32 queue = pio_reg_read(QUEUE_CUR_STATUS);\n\t\tu32 data = pio_reg_read(DATA_BUFFER_CUR_STATUS);\n\n\t\tdev_err(&hci->master.dev,\n\t\t\t\"prog error %#lx (C/R/I = %ld/%ld/%ld, TX/RX = %ld/%ld)\\n\",\n\t\t\tstatus & STAT_PROG_ERRORS,\n\t\t\tFIELD_GET(CUR_CMD_Q_EMPTY_LEVEL, queue),\n\t\t\tFIELD_GET(CUR_RESP_Q_LEVEL, queue),\n\t\t\tFIELD_GET(CUR_IBI_Q_LEVEL, queue),\n\t\t\tFIELD_GET(CUR_TX_BUF_LVL, data),\n\t\t\tFIELD_GET(CUR_RX_BUF_LVL, data));\n\t}\n\n\t \n\thci_pio_dequeue_xfer_common(hci, pio, pio->curr_resp, 1);\n\t \n\tif (pio->curr_tx && pio->curr_tx->data_left != pio->curr_tx->data_len)\n\t\thci_pio_dequeue_xfer_common(hci, pio, pio->curr_tx, 1);\n\t \n\tmipi_i3c_hci_pio_reset(hci);\n\tmipi_i3c_hci_resume(hci);\n\n\tDBG(\"status=%#x/%#x\",\n\t    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));\n}\n\nstatic void hci_pio_set_ibi_thresh(struct i3c_hci *hci,\n\t\t\t\t   struct hci_pio_data *pio,\n\t\t\t\t   unsigned int thresh_val)\n{\n\tu32 regval = pio->reg_queue_thresh;\n\n\tregval &= ~QUEUE_IBI_STATUS_THLD;\n\tregval |= FIELD_PREP(QUEUE_IBI_STATUS_THLD, thresh_val);\n\t \n\tif (regval != pio->reg_queue_thresh) {\n\t\tpio_reg_write(QUEUE_THLD_CTRL, regval);\n\t\tpio->reg_queue_thresh = regval;\n\t\tDBG(\"%d\", thresh_val);\n\t}\n}\n\nstatic bool hci_pio_get_ibi_segment(struct i3c_hci *hci,\n\t\t\t\t    struct hci_pio_data *pio)\n{\n\tstruct hci_pio_ibi_data *ibi = &pio->ibi;\n\tunsigned int nr_words, thresh_val;\n\tu32 *p;\n\n\tp = ibi->data_ptr;\n\tp += (ibi->seg_len - ibi->seg_cnt) / 4;\n\n\twhile ((nr_words = ibi->seg_cnt/4)) {\n\t\t \n\t\tthresh_val = min(nr_words, pio->max_ibi_thresh);\n\t\thci_pio_set_ibi_thresh(hci, pio, thresh_val);\n\t\t \n\t\tif (!(pio_reg_read(INTR_STATUS) & STAT_IBI_STATUS_THLD))\n\t\t\treturn false;\n\t\t \n\t\tnr_words = thresh_val;\n\t\tibi->seg_cnt -= nr_words * 4;\n\t\tDBG(\"now %d left %d\", nr_words * 4, ibi->seg_cnt);\n\t\twhile (nr_words--)\n\t\t\t*p++ = pio_reg_read(IBI_PORT);\n\t}\n\n\tif (ibi->seg_cnt) {\n\t\t \n\t\tu32 data;\n\t\tu8 *p_byte = (u8 *)p;\n\n\t\thci_pio_set_ibi_thresh(hci, pio, 1);\n\t\tif (!(pio_reg_read(INTR_STATUS) & STAT_IBI_STATUS_THLD))\n\t\t\treturn false;\n\t\tDBG(\"trailing %d\", ibi->seg_cnt);\n\t\tdata = pio_reg_read(IBI_PORT);\n\t\tdata = (__force u32) cpu_to_le32(data);\n\t\twhile (ibi->seg_cnt--) {\n\t\t\t*p_byte++ = data;\n\t\t\tdata >>= 8;\n\t\t}\n\t}\n\n\treturn true;\n}\n\nstatic bool hci_pio_prep_new_ibi(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\tstruct hci_pio_ibi_data *ibi = &pio->ibi;\n\tstruct i3c_dev_desc *dev;\n\tstruct i3c_hci_dev_data *dev_data;\n\tstruct hci_pio_dev_ibi_data *dev_ibi;\n\tu32 ibi_status;\n\n\t \n\n\tibi_status = pio_reg_read(IBI_PORT);\n\tDBG(\"status = %#x\", ibi_status);\n\tibi->addr = FIELD_GET(IBI_TARGET_ADDR, ibi_status);\n\tif (ibi_status & IBI_ERROR) {\n\t\tdev_err(&hci->master.dev, \"IBI error from %#x\\n\", ibi->addr);\n\t\treturn false;\n\t}\n\n\tibi->last_seg = ibi_status & IBI_LAST_STATUS;\n\tibi->seg_len = FIELD_GET(IBI_DATA_LENGTH, ibi_status);\n\tibi->seg_cnt = ibi->seg_len;\n\n\tdev = i3c_hci_addr_to_dev(hci, ibi->addr);\n\tif (!dev) {\n\t\tdev_err(&hci->master.dev,\n\t\t\t\"IBI for unknown device %#x\\n\", ibi->addr);\n\t\treturn true;\n\t}\n\n\tdev_data = i3c_dev_get_master_data(dev);\n\tdev_ibi = dev_data->ibi_data;\n\tibi->max_len = dev_ibi->max_len;\n\n\tif (ibi->seg_len > ibi->max_len) {\n\t\tdev_err(&hci->master.dev, \"IBI payload too big (%d > %d)\\n\",\n\t\t\tibi->seg_len, ibi->max_len);\n\t\treturn true;\n\t}\n\n\tibi->slot = i3c_generic_ibi_get_free_slot(dev_ibi->pool);\n\tif (!ibi->slot) {\n\t\tdev_err(&hci->master.dev, \"no free slot for IBI\\n\");\n\t} else {\n\t\tibi->slot->len = 0;\n\t\tibi->data_ptr = ibi->slot->data;\n\t}\n\treturn true;\n}\n\nstatic void hci_pio_free_ibi_slot(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\tstruct hci_pio_ibi_data *ibi = &pio->ibi;\n\tstruct hci_pio_dev_ibi_data *dev_ibi;\n\n\tif (ibi->slot) {\n\t\tdev_ibi = ibi->slot->dev->common.master_priv;\n\t\ti3c_generic_ibi_recycle_slot(dev_ibi->pool, ibi->slot);\n\t\tibi->slot = NULL;\n\t}\n}\n\nstatic bool hci_pio_process_ibi(struct i3c_hci *hci, struct hci_pio_data *pio)\n{\n\tstruct hci_pio_ibi_data *ibi = &pio->ibi;\n\n\tif (!ibi->slot && !ibi->seg_cnt && ibi->last_seg)\n\t\tif (!hci_pio_prep_new_ibi(hci, pio))\n\t\t\treturn false;\n\n\tfor (;;) {\n\t\tu32 ibi_status;\n\t\tunsigned int ibi_addr;\n\n\t\tif (ibi->slot) {\n\t\t\tif (!hci_pio_get_ibi_segment(hci, pio))\n\t\t\t\treturn false;\n\t\t\tibi->slot->len += ibi->seg_len;\n\t\t\tibi->data_ptr += ibi->seg_len;\n\t\t\tif (ibi->last_seg) {\n\t\t\t\t \n\t\t\t\ti3c_master_queue_ibi(ibi->slot->dev, ibi->slot);\n\t\t\t\tibi->slot = NULL;\n\t\t\t\thci_pio_set_ibi_thresh(hci, pio, 1);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t} else if (ibi->seg_cnt) {\n\t\t\t \n\t\t\thci_pio_set_ibi_thresh(hci, pio, 1);\n\t\t\tdo {\n\t\t\t\tif (!(pio_reg_read(INTR_STATUS) & STAT_IBI_STATUS_THLD))\n\t\t\t\t\treturn false;\n\t\t\t\tpio_reg_read(IBI_PORT);\n\t\t\t} while (--ibi->seg_cnt);\n\t\t\tif (ibi->last_seg)\n\t\t\t\treturn true;\n\t\t}\n\n\t\t \n\t\thci_pio_set_ibi_thresh(hci, pio, 1);\n\t\tif (!(pio_reg_read(INTR_STATUS) & STAT_IBI_STATUS_THLD))\n\t\t\treturn false;\n\t\tibi_status = pio_reg_read(IBI_PORT);\n\t\tibi_addr = FIELD_GET(IBI_TARGET_ADDR, ibi_status);\n\t\tif (ibi->addr != ibi_addr) {\n\t\t\t \n\t\t\tdev_err(&hci->master.dev,\n\t\t\t\t\"unexp IBI address changed from %d to %d\\n\",\n\t\t\t\tibi->addr, ibi_addr);\n\t\t\thci_pio_free_ibi_slot(hci, pio);\n\t\t}\n\t\tibi->last_seg = ibi_status & IBI_LAST_STATUS;\n\t\tibi->seg_len = FIELD_GET(IBI_DATA_LENGTH, ibi_status);\n\t\tibi->seg_cnt = ibi->seg_len;\n\t\tif (ibi->slot && ibi->slot->len + ibi->seg_len > ibi->max_len) {\n\t\t\tdev_err(&hci->master.dev,\n\t\t\t\t\"IBI payload too big (%d > %d)\\n\",\n\t\t\t\tibi->slot->len + ibi->seg_len, ibi->max_len);\n\t\t\thci_pio_free_ibi_slot(hci, pio);\n\t\t}\n\t}\n\n\treturn false;\n}\n\nstatic int hci_pio_request_ibi(struct i3c_hci *hci, struct i3c_dev_desc *dev,\n\t\t\t       const struct i3c_ibi_setup *req)\n{\n\tstruct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);\n\tstruct i3c_generic_ibi_pool *pool;\n\tstruct hci_pio_dev_ibi_data *dev_ibi;\n\n\tdev_ibi = kmalloc(sizeof(*dev_ibi), GFP_KERNEL);\n\tif (!dev_ibi)\n\t\treturn -ENOMEM;\n\tpool = i3c_generic_ibi_alloc_pool(dev, req);\n\tif (IS_ERR(pool)) {\n\t\tkfree(dev_ibi);\n\t\treturn PTR_ERR(pool);\n\t}\n\tdev_ibi->pool = pool;\n\tdev_ibi->max_len = req->max_payload_len;\n\tdev_data->ibi_data = dev_ibi;\n\treturn 0;\n}\n\nstatic void hci_pio_free_ibi(struct i3c_hci *hci, struct i3c_dev_desc *dev)\n{\n\tstruct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);\n\tstruct hci_pio_dev_ibi_data *dev_ibi = dev_data->ibi_data;\n\n\tdev_data->ibi_data = NULL;\n\ti3c_generic_ibi_free_pool(dev_ibi->pool);\n\tkfree(dev_ibi);\n}\n\nstatic void hci_pio_recycle_ibi_slot(struct i3c_hci *hci,\n\t\t\t\t    struct i3c_dev_desc *dev,\n\t\t\t\t    struct i3c_ibi_slot *slot)\n{\n\tstruct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);\n\tstruct hci_pio_dev_ibi_data *dev_ibi = dev_data->ibi_data;\n\n\ti3c_generic_ibi_recycle_slot(dev_ibi->pool, slot);\n}\n\nstatic bool hci_pio_irq_handler(struct i3c_hci *hci, unsigned int unused)\n{\n\tstruct hci_pio_data *pio = hci->io_data;\n\tu32 status;\n\n\tspin_lock(&pio->lock);\n\tstatus = pio_reg_read(INTR_STATUS);\n\tDBG(\"(in) status: %#x/%#x\", status, pio->enabled_irqs);\n\tstatus &= pio->enabled_irqs | STAT_LATENCY_WARNINGS;\n\tif (!status) {\n\t\tspin_unlock(&pio->lock);\n\t\treturn false;\n\t}\n\n\tif (status & STAT_IBI_STATUS_THLD)\n\t\thci_pio_process_ibi(hci, pio);\n\n\tif (status & STAT_RX_THLD)\n\t\tif (hci_pio_process_rx(hci, pio))\n\t\t\tpio->enabled_irqs &= ~STAT_RX_THLD;\n\tif (status & STAT_TX_THLD)\n\t\tif (hci_pio_process_tx(hci, pio))\n\t\t\tpio->enabled_irqs &= ~STAT_TX_THLD;\n\tif (status & STAT_RESP_READY)\n\t\tif (hci_pio_process_resp(hci, pio))\n\t\t\tpio->enabled_irqs &= ~STAT_RESP_READY;\n\n\tif (unlikely(status & STAT_LATENCY_WARNINGS)) {\n\t\tpio_reg_write(INTR_STATUS, status & STAT_LATENCY_WARNINGS);\n\t\tdev_warn_ratelimited(&hci->master.dev,\n\t\t\t\t     \"encountered warning condition %#lx\\n\",\n\t\t\t\t     status & STAT_LATENCY_WARNINGS);\n\t}\n\n\tif (unlikely(status & STAT_ALL_ERRORS)) {\n\t\tpio_reg_write(INTR_STATUS, status & STAT_ALL_ERRORS);\n\t\thci_pio_err(hci, pio, status & STAT_ALL_ERRORS);\n\t}\n\n\tif (status & STAT_CMD_QUEUE_READY)\n\t\tif (hci_pio_process_cmd(hci, pio))\n\t\t\tpio->enabled_irqs &= ~STAT_CMD_QUEUE_READY;\n\n\tpio_reg_write(INTR_SIGNAL_ENABLE, pio->enabled_irqs);\n\tDBG(\"(out) status: %#x/%#x\",\n\t    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));\n\tspin_unlock(&pio->lock);\n\treturn true;\n}\n\nconst struct hci_io_ops mipi_i3c_hci_pio = {\n\t.init\t\t\t= hci_pio_init,\n\t.cleanup\t\t= hci_pio_cleanup,\n\t.queue_xfer\t\t= hci_pio_queue_xfer,\n\t.dequeue_xfer\t\t= hci_pio_dequeue_xfer,\n\t.irq_handler\t\t= hci_pio_irq_handler,\n\t.request_ibi\t\t= hci_pio_request_ibi,\n\t.free_ibi\t\t= hci_pio_free_ibi,\n\t.recycle_ibi_slot\t= hci_pio_recycle_ibi_slot,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}