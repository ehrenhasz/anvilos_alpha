{
  "module_name": "powernv-cpufreq.c",
  "hash_id": "8d158c24aedb0db2f4e7c34362b8ebf5c3c4130b43f809d03edf26e08935cbc4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/cpufreq/powernv-cpufreq.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\t\"powernv-cpufreq: \" fmt\n\n#include <linux/kernel.h>\n#include <linux/sysfs.h>\n#include <linux/cpumask.h>\n#include <linux/module.h>\n#include <linux/cpufreq.h>\n#include <linux/smp.h>\n#include <linux/of.h>\n#include <linux/reboot.h>\n#include <linux/slab.h>\n#include <linux/cpu.h>\n#include <linux/hashtable.h>\n#include <trace/events/power.h>\n\n#include <asm/cputhreads.h>\n#include <asm/firmware.h>\n#include <asm/reg.h>\n#include <asm/smp.h>  \n#include <asm/opal.h>\n#include <linux/timer.h>\n\n#define POWERNV_MAX_PSTATES_ORDER  8\n#define POWERNV_MAX_PSTATES\t(1UL << (POWERNV_MAX_PSTATES_ORDER))\n#define PMSR_PSAFE_ENABLE\t(1UL << 30)\n#define PMSR_SPR_EM_DISABLE\t(1UL << 31)\n#define MAX_PSTATE_SHIFT\t32\n#define LPSTATE_SHIFT\t\t48\n#define GPSTATE_SHIFT\t\t56\n#define MAX_NR_CHIPS\t\t32\n\n#define MAX_RAMP_DOWN_TIME\t\t\t\t5120\n \n#define ramp_down_percent(time)\t\t((time * time) >> 18)\n\n \n#define GPSTATE_TIMER_INTERVAL\t\t\t\t2000\n\n \nstruct global_pstate_info {\n\tint highest_lpstate_idx;\n\tunsigned int elapsed_time;\n\tunsigned int last_sampled_time;\n\tint last_lpstate_idx;\n\tint last_gpstate_idx;\n\tspinlock_t gpstate_lock;\n\tstruct timer_list timer;\n\tstruct cpufreq_policy *policy;\n};\n\nstatic struct cpufreq_frequency_table powernv_freqs[POWERNV_MAX_PSTATES+1];\n\nstatic DEFINE_HASHTABLE(pstate_revmap, POWERNV_MAX_PSTATES_ORDER);\n \nstruct pstate_idx_revmap_data {\n\tu8 pstate_id;\n\tunsigned int cpufreq_table_idx;\n\tstruct hlist_node hentry;\n};\n\nstatic bool rebooting, throttled, occ_reset;\n\nstatic const char * const throttle_reason[] = {\n\t\"No throttling\",\n\t\"Power Cap\",\n\t\"Processor Over Temperature\",\n\t\"Power Supply Failure\",\n\t\"Over Current\",\n\t\"OCC Reset\"\n};\n\nenum throttle_reason_type {\n\tNO_THROTTLE = 0,\n\tPOWERCAP,\n\tCPU_OVERTEMP,\n\tPOWER_SUPPLY_FAILURE,\n\tOVERCURRENT,\n\tOCC_RESET_THROTTLE,\n\tOCC_MAX_REASON\n};\n\nstatic struct chip {\n\tunsigned int id;\n\tbool throttled;\n\tbool restore;\n\tu8 throttle_reason;\n\tcpumask_t mask;\n\tstruct work_struct throttle;\n\tint throttle_turbo;\n\tint throttle_sub_turbo;\n\tint reason[OCC_MAX_REASON];\n} *chips;\n\nstatic int nr_chips;\nstatic DEFINE_PER_CPU(struct chip *, chip_info);\n\n \nstatic struct powernv_pstate_info {\n\tunsigned int min;\n\tunsigned int max;\n\tunsigned int nominal;\n\tunsigned int nr_pstates;\n\tbool wof_enabled;\n} powernv_pstate_info;\n\nstatic inline u8 extract_pstate(u64 pmsr_val, unsigned int shift)\n{\n\treturn ((pmsr_val >> shift) & 0xFF);\n}\n\n#define extract_local_pstate(x) extract_pstate(x, LPSTATE_SHIFT)\n#define extract_global_pstate(x) extract_pstate(x, GPSTATE_SHIFT)\n#define extract_max_pstate(x)  extract_pstate(x, MAX_PSTATE_SHIFT)\n\n \n\n \nstatic inline u8 idx_to_pstate(unsigned int i)\n{\n\tif (unlikely(i >= powernv_pstate_info.nr_pstates)) {\n\t\tpr_warn_once(\"idx_to_pstate: index %u is out of bound\\n\", i);\n\t\treturn powernv_freqs[powernv_pstate_info.nominal].driver_data;\n\t}\n\n\treturn powernv_freqs[i].driver_data;\n}\n\n \nstatic unsigned int pstate_to_idx(u8 pstate)\n{\n\tunsigned int key = pstate % POWERNV_MAX_PSTATES;\n\tstruct pstate_idx_revmap_data *revmap_data;\n\n\thash_for_each_possible(pstate_revmap, revmap_data, hentry, key) {\n\t\tif (revmap_data->pstate_id == pstate)\n\t\t\treturn revmap_data->cpufreq_table_idx;\n\t}\n\n\tpr_warn_once(\"pstate_to_idx: pstate 0x%x not found\\n\", pstate);\n\treturn powernv_pstate_info.nominal;\n}\n\nstatic inline void reset_gpstates(struct cpufreq_policy *policy)\n{\n\tstruct global_pstate_info *gpstates = policy->driver_data;\n\n\tgpstates->highest_lpstate_idx = 0;\n\tgpstates->elapsed_time = 0;\n\tgpstates->last_sampled_time = 0;\n\tgpstates->last_lpstate_idx = 0;\n\tgpstates->last_gpstate_idx = 0;\n}\n\n \nstatic int init_powernv_pstates(void)\n{\n\tstruct device_node *power_mgt;\n\tint i, nr_pstates = 0;\n\tconst __be32 *pstate_ids, *pstate_freqs;\n\tu32 len_ids, len_freqs;\n\tu32 pstate_min, pstate_max, pstate_nominal;\n\tu32 pstate_turbo, pstate_ultra_turbo;\n\tint rc = -ENODEV;\n\n\tpower_mgt = of_find_node_by_path(\"/ibm,opal/power-mgt\");\n\tif (!power_mgt) {\n\t\tpr_warn(\"power-mgt node not found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (of_property_read_u32(power_mgt, \"ibm,pstate-min\", &pstate_min)) {\n\t\tpr_warn(\"ibm,pstate-min node not found\\n\");\n\t\tgoto out;\n\t}\n\n\tif (of_property_read_u32(power_mgt, \"ibm,pstate-max\", &pstate_max)) {\n\t\tpr_warn(\"ibm,pstate-max node not found\\n\");\n\t\tgoto out;\n\t}\n\n\tif (of_property_read_u32(power_mgt, \"ibm,pstate-nominal\",\n\t\t\t\t &pstate_nominal)) {\n\t\tpr_warn(\"ibm,pstate-nominal not found\\n\");\n\t\tgoto out;\n\t}\n\n\tif (of_property_read_u32(power_mgt, \"ibm,pstate-ultra-turbo\",\n\t\t\t\t &pstate_ultra_turbo)) {\n\t\tpowernv_pstate_info.wof_enabled = false;\n\t\tgoto next;\n\t}\n\n\tif (of_property_read_u32(power_mgt, \"ibm,pstate-turbo\",\n\t\t\t\t &pstate_turbo)) {\n\t\tpowernv_pstate_info.wof_enabled = false;\n\t\tgoto next;\n\t}\n\n\tif (pstate_turbo == pstate_ultra_turbo)\n\t\tpowernv_pstate_info.wof_enabled = false;\n\telse\n\t\tpowernv_pstate_info.wof_enabled = true;\n\nnext:\n\tpr_info(\"cpufreq pstate min 0x%x nominal 0x%x max 0x%x\\n\", pstate_min,\n\t\tpstate_nominal, pstate_max);\n\tpr_info(\"Workload Optimized Frequency is %s in the platform\\n\",\n\t\t(powernv_pstate_info.wof_enabled) ? \"enabled\" : \"disabled\");\n\n\tpstate_ids = of_get_property(power_mgt, \"ibm,pstate-ids\", &len_ids);\n\tif (!pstate_ids) {\n\t\tpr_warn(\"ibm,pstate-ids not found\\n\");\n\t\tgoto out;\n\t}\n\n\tpstate_freqs = of_get_property(power_mgt, \"ibm,pstate-frequencies-mhz\",\n\t\t\t\t      &len_freqs);\n\tif (!pstate_freqs) {\n\t\tpr_warn(\"ibm,pstate-frequencies-mhz not found\\n\");\n\t\tgoto out;\n\t}\n\n\tif (len_ids != len_freqs) {\n\t\tpr_warn(\"Entries in ibm,pstate-ids and \"\n\t\t\t\"ibm,pstate-frequencies-mhz does not match\\n\");\n\t}\n\n\tnr_pstates = min(len_ids, len_freqs) / sizeof(u32);\n\tif (!nr_pstates) {\n\t\tpr_warn(\"No PStates found\\n\");\n\t\tgoto out;\n\t}\n\n\tpowernv_pstate_info.nr_pstates = nr_pstates;\n\tpr_debug(\"NR PStates %d\\n\", nr_pstates);\n\n\tfor (i = 0; i < nr_pstates; i++) {\n\t\tu32 id = be32_to_cpu(pstate_ids[i]);\n\t\tu32 freq = be32_to_cpu(pstate_freqs[i]);\n\t\tstruct pstate_idx_revmap_data *revmap_data;\n\t\tunsigned int key;\n\n\t\tpr_debug(\"PState id %d freq %d MHz\\n\", id, freq);\n\t\tpowernv_freqs[i].frequency = freq * 1000;  \n\t\tpowernv_freqs[i].driver_data = id & 0xFF;\n\n\t\trevmap_data = kmalloc(sizeof(*revmap_data), GFP_KERNEL);\n\t\tif (!revmap_data) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\trevmap_data->pstate_id = id & 0xFF;\n\t\trevmap_data->cpufreq_table_idx = i;\n\t\tkey = (revmap_data->pstate_id) % POWERNV_MAX_PSTATES;\n\t\thash_add(pstate_revmap, &revmap_data->hentry, key);\n\n\t\tif (id == pstate_max)\n\t\t\tpowernv_pstate_info.max = i;\n\t\tif (id == pstate_nominal)\n\t\t\tpowernv_pstate_info.nominal = i;\n\t\tif (id == pstate_min)\n\t\t\tpowernv_pstate_info.min = i;\n\n\t\tif (powernv_pstate_info.wof_enabled && id == pstate_turbo) {\n\t\t\tint j;\n\n\t\t\tfor (j = i - 1; j >= (int)powernv_pstate_info.max; j--)\n\t\t\t\tpowernv_freqs[j].flags = CPUFREQ_BOOST_FREQ;\n\t\t}\n\t}\n\n\t \n\tpowernv_freqs[i].frequency = CPUFREQ_TABLE_END;\n\n\tof_node_put(power_mgt);\n\treturn 0;\nout:\n\tof_node_put(power_mgt);\n\treturn rc;\n}\n\n \nstatic unsigned int pstate_id_to_freq(u8 pstate_id)\n{\n\tint i;\n\n\ti = pstate_to_idx(pstate_id);\n\tif (i >= powernv_pstate_info.nr_pstates || i < 0) {\n\t\tpr_warn(\"PState id 0x%x outside of PState table, reporting nominal id 0x%x instead\\n\",\n\t\t\tpstate_id, idx_to_pstate(powernv_pstate_info.nominal));\n\t\ti = powernv_pstate_info.nominal;\n\t}\n\n\treturn powernv_freqs[i].frequency;\n}\n\n \nstatic ssize_t cpuinfo_nominal_freq_show(struct cpufreq_policy *policy,\n\t\t\t\t\tchar *buf)\n{\n\treturn sprintf(buf, \"%u\\n\",\n\t\tpowernv_freqs[powernv_pstate_info.nominal].frequency);\n}\n\nstatic struct freq_attr cpufreq_freq_attr_cpuinfo_nominal_freq =\n\t__ATTR_RO(cpuinfo_nominal_freq);\n\n#define SCALING_BOOST_FREQS_ATTR_INDEX\t\t2\n\nstatic struct freq_attr *powernv_cpu_freq_attr[] = {\n\t&cpufreq_freq_attr_scaling_available_freqs,\n\t&cpufreq_freq_attr_cpuinfo_nominal_freq,\n\t&cpufreq_freq_attr_scaling_boost_freqs,\n\tNULL,\n};\n\n#define throttle_attr(name, member)\t\t\t\t\t\\\nstatic ssize_t name##_show(struct cpufreq_policy *policy, char *buf)\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tstruct chip *chip = per_cpu(chip_info, policy->cpu);\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\treturn sprintf(buf, \"%u\\n\", chip->member);\t\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\nstatic struct freq_attr throttle_attr_##name = __ATTR_RO(name)\t\t\\\n\nthrottle_attr(unthrottle, reason[NO_THROTTLE]);\nthrottle_attr(powercap, reason[POWERCAP]);\nthrottle_attr(overtemp, reason[CPU_OVERTEMP]);\nthrottle_attr(supply_fault, reason[POWER_SUPPLY_FAILURE]);\nthrottle_attr(overcurrent, reason[OVERCURRENT]);\nthrottle_attr(occ_reset, reason[OCC_RESET_THROTTLE]);\nthrottle_attr(turbo_stat, throttle_turbo);\nthrottle_attr(sub_turbo_stat, throttle_sub_turbo);\n\nstatic struct attribute *throttle_attrs[] = {\n\t&throttle_attr_unthrottle.attr,\n\t&throttle_attr_powercap.attr,\n\t&throttle_attr_overtemp.attr,\n\t&throttle_attr_supply_fault.attr,\n\t&throttle_attr_overcurrent.attr,\n\t&throttle_attr_occ_reset.attr,\n\t&throttle_attr_turbo_stat.attr,\n\t&throttle_attr_sub_turbo_stat.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group throttle_attr_grp = {\n\t.name\t= \"throttle_stats\",\n\t.attrs\t= throttle_attrs,\n};\n\n \n\n \n\nstatic inline unsigned long get_pmspr(unsigned long sprn)\n{\n\tswitch (sprn) {\n\tcase SPRN_PMCR:\n\t\treturn mfspr(SPRN_PMCR);\n\n\tcase SPRN_PMICR:\n\t\treturn mfspr(SPRN_PMICR);\n\n\tcase SPRN_PMSR:\n\t\treturn mfspr(SPRN_PMSR);\n\t}\n\tBUG();\n}\n\nstatic inline void set_pmspr(unsigned long sprn, unsigned long val)\n{\n\tswitch (sprn) {\n\tcase SPRN_PMCR:\n\t\tmtspr(SPRN_PMCR, val);\n\t\treturn;\n\n\tcase SPRN_PMICR:\n\t\tmtspr(SPRN_PMICR, val);\n\t\treturn;\n\t}\n\tBUG();\n}\n\n \nstruct powernv_smp_call_data {\n\tunsigned int freq;\n\tu8 pstate_id;\n\tu8 gpstate_id;\n};\n\n \nstatic void powernv_read_cpu_freq(void *arg)\n{\n\tunsigned long pmspr_val;\n\tstruct powernv_smp_call_data *freq_data = arg;\n\n\tpmspr_val = get_pmspr(SPRN_PMSR);\n\tfreq_data->pstate_id = extract_local_pstate(pmspr_val);\n\tfreq_data->freq = pstate_id_to_freq(freq_data->pstate_id);\n\n\tpr_debug(\"cpu %d pmsr %016lX pstate_id 0x%x frequency %d kHz\\n\",\n\t\t raw_smp_processor_id(), pmspr_val, freq_data->pstate_id,\n\t\t freq_data->freq);\n}\n\n \nstatic unsigned int powernv_cpufreq_get(unsigned int cpu)\n{\n\tstruct powernv_smp_call_data freq_data;\n\n\tsmp_call_function_any(cpu_sibling_mask(cpu), powernv_read_cpu_freq,\n\t\t\t&freq_data, 1);\n\n\treturn freq_data.freq;\n}\n\n \nstatic void set_pstate(void *data)\n{\n\tunsigned long val;\n\tstruct powernv_smp_call_data *freq_data = data;\n\tunsigned long pstate_ul = freq_data->pstate_id;\n\tunsigned long gpstate_ul = freq_data->gpstate_id;\n\n\tval = get_pmspr(SPRN_PMCR);\n\tval = val & 0x0000FFFFFFFFFFFFULL;\n\n\tpstate_ul = pstate_ul & 0xFF;\n\tgpstate_ul = gpstate_ul & 0xFF;\n\n\t \n\tval = val | (gpstate_ul << 56) | (pstate_ul << 48);\n\n\tpr_debug(\"Setting cpu %d pmcr to %016lX\\n\",\n\t\t\traw_smp_processor_id(), val);\n\tset_pmspr(SPRN_PMCR, val);\n}\n\n \nstatic inline unsigned int get_nominal_index(void)\n{\n\treturn powernv_pstate_info.nominal;\n}\n\nstatic void powernv_cpufreq_throttle_check(void *data)\n{\n\tstruct chip *chip;\n\tunsigned int cpu = smp_processor_id();\n\tunsigned long pmsr;\n\tu8 pmsr_pmax;\n\tunsigned int pmsr_pmax_idx;\n\n\tpmsr = get_pmspr(SPRN_PMSR);\n\tchip = this_cpu_read(chip_info);\n\n\t \n\tpmsr_pmax = extract_max_pstate(pmsr);\n\tpmsr_pmax_idx = pstate_to_idx(pmsr_pmax);\n\tif (pmsr_pmax_idx != powernv_pstate_info.max) {\n\t\tif (chip->throttled)\n\t\t\tgoto next;\n\t\tchip->throttled = true;\n\t\tif (pmsr_pmax_idx > powernv_pstate_info.nominal) {\n\t\t\tpr_warn_once(\"CPU %d on Chip %u has Pmax(0x%x) reduced below that of nominal frequency(0x%x)\\n\",\n\t\t\t\t     cpu, chip->id, pmsr_pmax,\n\t\t\t\t     idx_to_pstate(powernv_pstate_info.nominal));\n\t\t\tchip->throttle_sub_turbo++;\n\t\t} else {\n\t\t\tchip->throttle_turbo++;\n\t\t}\n\t\ttrace_powernv_throttle(chip->id,\n\t\t\t\t      throttle_reason[chip->throttle_reason],\n\t\t\t\t      pmsr_pmax);\n\t} else if (chip->throttled) {\n\t\tchip->throttled = false;\n\t\ttrace_powernv_throttle(chip->id,\n\t\t\t\t      throttle_reason[chip->throttle_reason],\n\t\t\t\t      pmsr_pmax);\n\t}\n\n\t \nnext:\n\tif (pmsr & PMSR_PSAFE_ENABLE) {\n\t\tthrottled = true;\n\t\tpr_info(\"Pstate set to safe frequency\\n\");\n\t}\n\n\t \n\tif (pmsr & PMSR_SPR_EM_DISABLE) {\n\t\tthrottled = true;\n\t\tpr_info(\"Frequency Control disabled from OS\\n\");\n\t}\n\n\tif (throttled) {\n\t\tpr_info(\"PMSR = %16lx\\n\", pmsr);\n\t\tpr_warn(\"CPU Frequency could be throttled\\n\");\n\t}\n}\n\n \nstatic inline int calc_global_pstate(unsigned int elapsed_time,\n\t\t\t\t     int highest_lpstate_idx,\n\t\t\t\t     int local_pstate_idx)\n{\n\tint index_diff;\n\n\t \n\tindex_diff =  ((int)ramp_down_percent(elapsed_time) *\n\t\t\t(powernv_pstate_info.min - highest_lpstate_idx)) / 100;\n\n\t \n\tif (highest_lpstate_idx + index_diff >= local_pstate_idx)\n\t\treturn local_pstate_idx;\n\telse\n\t\treturn highest_lpstate_idx + index_diff;\n}\n\nstatic inline void  queue_gpstate_timer(struct global_pstate_info *gpstates)\n{\n\tunsigned int timer_interval;\n\n\t \n\tif ((gpstates->elapsed_time + GPSTATE_TIMER_INTERVAL)\n\t     > MAX_RAMP_DOWN_TIME)\n\t\ttimer_interval = MAX_RAMP_DOWN_TIME - gpstates->elapsed_time;\n\telse\n\t\ttimer_interval = GPSTATE_TIMER_INTERVAL;\n\n\tmod_timer(&gpstates->timer, jiffies + msecs_to_jiffies(timer_interval));\n}\n\n \nstatic void gpstate_timer_handler(struct timer_list *t)\n{\n\tstruct global_pstate_info *gpstates = from_timer(gpstates, t, timer);\n\tstruct cpufreq_policy *policy = gpstates->policy;\n\tint gpstate_idx, lpstate_idx;\n\tunsigned long val;\n\tunsigned int time_diff = jiffies_to_msecs(jiffies)\n\t\t\t\t\t- gpstates->last_sampled_time;\n\tstruct powernv_smp_call_data freq_data;\n\n\tif (!spin_trylock(&gpstates->gpstate_lock))\n\t\treturn;\n\t \n\tif (!cpumask_test_cpu(raw_smp_processor_id(), policy->cpus)) {\n\t\tgpstates->timer.expires = jiffies + msecs_to_jiffies(1);\n\t\tadd_timer_on(&gpstates->timer, cpumask_first(policy->cpus));\n\t\tspin_unlock(&gpstates->gpstate_lock);\n\t\treturn;\n\t}\n\n\t \n\tval = get_pmspr(SPRN_PMCR);\n\tfreq_data.gpstate_id = extract_global_pstate(val);\n\tfreq_data.pstate_id = extract_local_pstate(val);\n\tif (freq_data.gpstate_id  == freq_data.pstate_id) {\n\t\treset_gpstates(policy);\n\t\tspin_unlock(&gpstates->gpstate_lock);\n\t\treturn;\n\t}\n\n\tgpstates->last_sampled_time += time_diff;\n\tgpstates->elapsed_time += time_diff;\n\n\tif (gpstates->elapsed_time > MAX_RAMP_DOWN_TIME) {\n\t\tgpstate_idx = pstate_to_idx(freq_data.pstate_id);\n\t\tlpstate_idx = gpstate_idx;\n\t\treset_gpstates(policy);\n\t\tgpstates->highest_lpstate_idx = gpstate_idx;\n\t} else {\n\t\tlpstate_idx = pstate_to_idx(freq_data.pstate_id);\n\t\tgpstate_idx = calc_global_pstate(gpstates->elapsed_time,\n\t\t\t\t\t\t gpstates->highest_lpstate_idx,\n\t\t\t\t\t\t lpstate_idx);\n\t}\n\tfreq_data.gpstate_id = idx_to_pstate(gpstate_idx);\n\tgpstates->last_gpstate_idx = gpstate_idx;\n\tgpstates->last_lpstate_idx = lpstate_idx;\n\t \n\tif (gpstate_idx != gpstates->last_lpstate_idx)\n\t\tqueue_gpstate_timer(gpstates);\n\n\tset_pstate(&freq_data);\n\tspin_unlock(&gpstates->gpstate_lock);\n}\n\n \nstatic int powernv_cpufreq_target_index(struct cpufreq_policy *policy,\n\t\t\t\t\tunsigned int new_index)\n{\n\tstruct powernv_smp_call_data freq_data;\n\tunsigned int cur_msec, gpstate_idx;\n\tstruct global_pstate_info *gpstates = policy->driver_data;\n\n\tif (unlikely(rebooting) && new_index != get_nominal_index())\n\t\treturn 0;\n\n\tif (!throttled) {\n\t\t \n\t\tpreempt_disable();\n\t\tpowernv_cpufreq_throttle_check(NULL);\n\t\tpreempt_enable();\n\t}\n\n\tcur_msec = jiffies_to_msecs(get_jiffies_64());\n\n\tfreq_data.pstate_id = idx_to_pstate(new_index);\n\tif (!gpstates) {\n\t\tfreq_data.gpstate_id = freq_data.pstate_id;\n\t\tgoto no_gpstate;\n\t}\n\n\tspin_lock(&gpstates->gpstate_lock);\n\n\tif (!gpstates->last_sampled_time) {\n\t\tgpstate_idx = new_index;\n\t\tgpstates->highest_lpstate_idx = new_index;\n\t\tgoto gpstates_done;\n\t}\n\n\tif (gpstates->last_gpstate_idx < new_index) {\n\t\tgpstates->elapsed_time += cur_msec -\n\t\t\t\t\t\t gpstates->last_sampled_time;\n\n\t\t \n\t\tif (gpstates->elapsed_time > MAX_RAMP_DOWN_TIME) {\n\t\t\treset_gpstates(policy);\n\t\t\tgpstates->highest_lpstate_idx = new_index;\n\t\t\tgpstate_idx = new_index;\n\t\t} else {\n\t\t \n\t\t\tgpstate_idx = calc_global_pstate(gpstates->elapsed_time,\n\t\t\t\t\t\t\t gpstates->highest_lpstate_idx,\n\t\t\t\t\t\t\t new_index);\n\t\t}\n\t} else {\n\t\treset_gpstates(policy);\n\t\tgpstates->highest_lpstate_idx = new_index;\n\t\tgpstate_idx = new_index;\n\t}\n\n\t \n\tif (gpstate_idx != new_index)\n\t\tqueue_gpstate_timer(gpstates);\n\telse\n\t\tdel_timer_sync(&gpstates->timer);\n\ngpstates_done:\n\tfreq_data.gpstate_id = idx_to_pstate(gpstate_idx);\n\tgpstates->last_sampled_time = cur_msec;\n\tgpstates->last_gpstate_idx = gpstate_idx;\n\tgpstates->last_lpstate_idx = new_index;\n\n\tspin_unlock(&gpstates->gpstate_lock);\n\nno_gpstate:\n\t \n\tsmp_call_function_any(policy->cpus, set_pstate, &freq_data, 1);\n\treturn 0;\n}\n\nstatic int powernv_cpufreq_cpu_init(struct cpufreq_policy *policy)\n{\n\tint base, i;\n\tstruct kernfs_node *kn;\n\tstruct global_pstate_info *gpstates;\n\n\tbase = cpu_first_thread_sibling(policy->cpu);\n\n\tfor (i = 0; i < threads_per_core; i++)\n\t\tcpumask_set_cpu(base + i, policy->cpus);\n\n\tkn = kernfs_find_and_get(policy->kobj.sd, throttle_attr_grp.name);\n\tif (!kn) {\n\t\tint ret;\n\n\t\tret = sysfs_create_group(&policy->kobj, &throttle_attr_grp);\n\t\tif (ret) {\n\t\t\tpr_info(\"Failed to create throttle stats directory for cpu %d\\n\",\n\t\t\t\tpolicy->cpu);\n\t\t\treturn ret;\n\t\t}\n\t} else {\n\t\tkernfs_put(kn);\n\t}\n\n\tpolicy->freq_table = powernv_freqs;\n\tpolicy->fast_switch_possible = true;\n\n\tif (pvr_version_is(PVR_POWER9))\n\t\treturn 0;\n\n\t \n\tgpstates =  kzalloc(sizeof(*gpstates), GFP_KERNEL);\n\tif (!gpstates)\n\t\treturn -ENOMEM;\n\n\tpolicy->driver_data = gpstates;\n\n\t \n\tgpstates->policy = policy;\n\ttimer_setup(&gpstates->timer, gpstate_timer_handler,\n\t\t    TIMER_PINNED | TIMER_DEFERRABLE);\n\tgpstates->timer.expires = jiffies +\n\t\t\t\tmsecs_to_jiffies(GPSTATE_TIMER_INTERVAL);\n\tspin_lock_init(&gpstates->gpstate_lock);\n\n\treturn 0;\n}\n\nstatic int powernv_cpufreq_cpu_exit(struct cpufreq_policy *policy)\n{\n\tstruct powernv_smp_call_data freq_data;\n\tstruct global_pstate_info *gpstates = policy->driver_data;\n\n\tfreq_data.pstate_id = idx_to_pstate(powernv_pstate_info.min);\n\tfreq_data.gpstate_id = idx_to_pstate(powernv_pstate_info.min);\n\tsmp_call_function_single(policy->cpu, set_pstate, &freq_data, 1);\n\tif (gpstates)\n\t\tdel_timer_sync(&gpstates->timer);\n\n\tkfree(policy->driver_data);\n\n\treturn 0;\n}\n\nstatic int powernv_cpufreq_reboot_notifier(struct notifier_block *nb,\n\t\t\t\tunsigned long action, void *unused)\n{\n\tint cpu;\n\tstruct cpufreq_policy *cpu_policy;\n\n\trebooting = true;\n\tfor_each_online_cpu(cpu) {\n\t\tcpu_policy = cpufreq_cpu_get(cpu);\n\t\tif (!cpu_policy)\n\t\t\tcontinue;\n\t\tpowernv_cpufreq_target_index(cpu_policy, get_nominal_index());\n\t\tcpufreq_cpu_put(cpu_policy);\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block powernv_cpufreq_reboot_nb = {\n\t.notifier_call = powernv_cpufreq_reboot_notifier,\n};\n\nstatic void powernv_cpufreq_work_fn(struct work_struct *work)\n{\n\tstruct chip *chip = container_of(work, struct chip, throttle);\n\tstruct cpufreq_policy *policy;\n\tunsigned int cpu;\n\tcpumask_t mask;\n\n\tcpus_read_lock();\n\tcpumask_and(&mask, &chip->mask, cpu_online_mask);\n\tsmp_call_function_any(&mask,\n\t\t\t      powernv_cpufreq_throttle_check, NULL, 0);\n\n\tif (!chip->restore)\n\t\tgoto out;\n\n\tchip->restore = false;\n\tfor_each_cpu(cpu, &mask) {\n\t\tint index;\n\n\t\tpolicy = cpufreq_cpu_get(cpu);\n\t\tif (!policy)\n\t\t\tcontinue;\n\t\tindex = cpufreq_table_find_index_c(policy, policy->cur, false);\n\t\tpowernv_cpufreq_target_index(policy, index);\n\t\tcpumask_andnot(&mask, &mask, policy->cpus);\n\t\tcpufreq_cpu_put(policy);\n\t}\nout:\n\tcpus_read_unlock();\n}\n\nstatic int powernv_cpufreq_occ_msg(struct notifier_block *nb,\n\t\t\t\t   unsigned long msg_type, void *_msg)\n{\n\tstruct opal_msg *msg = _msg;\n\tstruct opal_occ_msg omsg;\n\tint i;\n\n\tif (msg_type != OPAL_MSG_OCC)\n\t\treturn 0;\n\n\tomsg.type = be64_to_cpu(msg->params[0]);\n\n\tswitch (omsg.type) {\n\tcase OCC_RESET:\n\t\tocc_reset = true;\n\t\tpr_info(\"OCC (On Chip Controller - enforces hard thermal/power limits) Resetting\\n\");\n\t\t \n\t\tif (!throttled) {\n\t\t\tthrottled = true;\n\t\t\tpr_warn(\"CPU frequency is throttled for duration\\n\");\n\t\t}\n\n\t\tbreak;\n\tcase OCC_LOAD:\n\t\tpr_info(\"OCC Loading, CPU frequency is throttled until OCC is started\\n\");\n\t\tbreak;\n\tcase OCC_THROTTLE:\n\t\tomsg.chip = be64_to_cpu(msg->params[1]);\n\t\tomsg.throttle_status = be64_to_cpu(msg->params[2]);\n\n\t\tif (occ_reset) {\n\t\t\tocc_reset = false;\n\t\t\tthrottled = false;\n\t\t\tpr_info(\"OCC Active, CPU frequency is no longer throttled\\n\");\n\n\t\t\tfor (i = 0; i < nr_chips; i++) {\n\t\t\t\tchips[i].restore = true;\n\t\t\t\tschedule_work(&chips[i].throttle);\n\t\t\t}\n\n\t\t\treturn 0;\n\t\t}\n\n\t\tfor (i = 0; i < nr_chips; i++)\n\t\t\tif (chips[i].id == omsg.chip)\n\t\t\t\tbreak;\n\n\t\tif (omsg.throttle_status >= 0 &&\n\t\t    omsg.throttle_status <= OCC_MAX_THROTTLE_STATUS) {\n\t\t\tchips[i].throttle_reason = omsg.throttle_status;\n\t\t\tchips[i].reason[omsg.throttle_status]++;\n\t\t}\n\n\t\tif (!omsg.throttle_status)\n\t\t\tchips[i].restore = true;\n\n\t\tschedule_work(&chips[i].throttle);\n\t}\n\treturn 0;\n}\n\nstatic struct notifier_block powernv_cpufreq_opal_nb = {\n\t.notifier_call\t= powernv_cpufreq_occ_msg,\n\t.next\t\t= NULL,\n\t.priority\t= 0,\n};\n\nstatic unsigned int powernv_fast_switch(struct cpufreq_policy *policy,\n\t\t\t\t\tunsigned int target_freq)\n{\n\tint index;\n\tstruct powernv_smp_call_data freq_data;\n\n\tindex = cpufreq_table_find_index_dl(policy, target_freq, false);\n\tfreq_data.pstate_id = powernv_freqs[index].driver_data;\n\tfreq_data.gpstate_id = powernv_freqs[index].driver_data;\n\tset_pstate(&freq_data);\n\n\treturn powernv_freqs[index].frequency;\n}\n\nstatic struct cpufreq_driver powernv_cpufreq_driver = {\n\t.name\t\t= \"powernv-cpufreq\",\n\t.flags\t\t= CPUFREQ_CONST_LOOPS,\n\t.init\t\t= powernv_cpufreq_cpu_init,\n\t.exit\t\t= powernv_cpufreq_cpu_exit,\n\t.verify\t\t= cpufreq_generic_frequency_table_verify,\n\t.target_index\t= powernv_cpufreq_target_index,\n\t.fast_switch\t= powernv_fast_switch,\n\t.get\t\t= powernv_cpufreq_get,\n\t.attr\t\t= powernv_cpu_freq_attr,\n};\n\nstatic int init_chip_info(void)\n{\n\tunsigned int *chip;\n\tunsigned int cpu, i;\n\tunsigned int prev_chip_id = UINT_MAX;\n\tcpumask_t *chip_cpu_mask;\n\tint ret = 0;\n\n\tchip = kcalloc(num_possible_cpus(), sizeof(*chip), GFP_KERNEL);\n\tif (!chip)\n\t\treturn -ENOMEM;\n\n\t \n\tchip_cpu_mask = kcalloc(MAX_NR_CHIPS, sizeof(cpumask_t), GFP_KERNEL);\n\tif (!chip_cpu_mask) {\n\t\tret = -ENOMEM;\n\t\tgoto free_and_return;\n\t}\n\n\tfor_each_possible_cpu(cpu) {\n\t\tunsigned int id = cpu_to_chip_id(cpu);\n\n\t\tif (prev_chip_id != id) {\n\t\t\tprev_chip_id = id;\n\t\t\tchip[nr_chips++] = id;\n\t\t}\n\t\tcpumask_set_cpu(cpu, &chip_cpu_mask[nr_chips-1]);\n\t}\n\n\tchips = kcalloc(nr_chips, sizeof(struct chip), GFP_KERNEL);\n\tif (!chips) {\n\t\tret = -ENOMEM;\n\t\tgoto out_free_chip_cpu_mask;\n\t}\n\n\tfor (i = 0; i < nr_chips; i++) {\n\t\tchips[i].id = chip[i];\n\t\tcpumask_copy(&chips[i].mask, &chip_cpu_mask[i]);\n\t\tINIT_WORK(&chips[i].throttle, powernv_cpufreq_work_fn);\n\t\tfor_each_cpu(cpu, &chips[i].mask)\n\t\t\tper_cpu(chip_info, cpu) =  &chips[i];\n\t}\n\nout_free_chip_cpu_mask:\n\tkfree(chip_cpu_mask);\nfree_and_return:\n\tkfree(chip);\n\treturn ret;\n}\n\nstatic inline void clean_chip_info(void)\n{\n\tint i;\n\n\t \n\tif (chips)\n\t\tfor (i = 0; i < nr_chips; i++)\n\t\t\tcancel_work_sync(&chips[i].throttle);\n\tkfree(chips);\n}\n\nstatic inline void unregister_all_notifiers(void)\n{\n\topal_message_notifier_unregister(OPAL_MSG_OCC,\n\t\t\t\t\t &powernv_cpufreq_opal_nb);\n\tunregister_reboot_notifier(&powernv_cpufreq_reboot_nb);\n}\n\nstatic int __init powernv_cpufreq_init(void)\n{\n\tint rc = 0;\n\n\t \n\tif (!firmware_has_feature(FW_FEATURE_OPAL))\n\t\treturn -ENODEV;\n\n\t \n\trc = init_powernv_pstates();\n\tif (rc)\n\t\tgoto out;\n\n\t \n\trc = init_chip_info();\n\tif (rc)\n\t\tgoto out;\n\n\tif (powernv_pstate_info.wof_enabled)\n\t\tpowernv_cpufreq_driver.boost_enabled = true;\n\telse\n\t\tpowernv_cpu_freq_attr[SCALING_BOOST_FREQS_ATTR_INDEX] = NULL;\n\n\trc = cpufreq_register_driver(&powernv_cpufreq_driver);\n\tif (rc) {\n\t\tpr_info(\"Failed to register the cpufreq driver (%d)\\n\", rc);\n\t\tgoto cleanup;\n\t}\n\n\tif (powernv_pstate_info.wof_enabled)\n\t\tcpufreq_enable_boost_support();\n\n\tregister_reboot_notifier(&powernv_cpufreq_reboot_nb);\n\topal_message_notifier_register(OPAL_MSG_OCC, &powernv_cpufreq_opal_nb);\n\n\treturn 0;\ncleanup:\n\tclean_chip_info();\nout:\n\tpr_info(\"Platform driver disabled. System does not support PState control\\n\");\n\treturn rc;\n}\nmodule_init(powernv_cpufreq_init);\n\nstatic void __exit powernv_cpufreq_exit(void)\n{\n\tcpufreq_unregister_driver(&powernv_cpufreq_driver);\n\tunregister_all_notifiers();\n\tclean_chip_info();\n}\nmodule_exit(powernv_cpufreq_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Vaidyanathan Srinivasan <svaidy at linux.vnet.ibm.com>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}