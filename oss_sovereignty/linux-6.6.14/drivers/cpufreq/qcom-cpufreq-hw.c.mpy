{
  "module_name": "qcom-cpufreq-hw.c",
  "hash_id": "8ee7c85eb6d246a57a90d91ea0c32e71421ecbd2d58e32e2280b3879ba12ac95",
  "original_prompt": "Ingested from linux-6.6.14/drivers/cpufreq/qcom-cpufreq-hw.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/clk-provider.h>\n#include <linux/cpufreq.h>\n#include <linux/init.h>\n#include <linux/interconnect.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/pm_opp.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/units.h>\n\n#define LUT_MAX_ENTRIES\t\t\t40U\n#define LUT_SRC\t\t\t\tGENMASK(31, 30)\n#define LUT_L_VAL\t\t\tGENMASK(7, 0)\n#define LUT_CORE_COUNT\t\t\tGENMASK(18, 16)\n#define LUT_VOLT\t\t\tGENMASK(11, 0)\n#define CLK_HW_DIV\t\t\t2\n#define LUT_TURBO_IND\t\t\t1\n\n#define GT_IRQ_STATUS\t\t\tBIT(2)\n\n#define MAX_FREQ_DOMAINS\t\t4\n\nstruct qcom_cpufreq_soc_data {\n\tu32 reg_enable;\n\tu32 reg_domain_state;\n\tu32 reg_dcvs_ctrl;\n\tu32 reg_freq_lut;\n\tu32 reg_volt_lut;\n\tu32 reg_intr_clr;\n\tu32 reg_current_vote;\n\tu32 reg_perf_state;\n\tu8 lut_row_size;\n};\n\nstruct qcom_cpufreq_data {\n\tvoid __iomem *base;\n\n\t \n\tstruct mutex throttle_lock;\n\tint throttle_irq;\n\tchar irq_name[15];\n\tbool cancel_throttle;\n\tstruct delayed_work throttle_work;\n\tstruct cpufreq_policy *policy;\n\tstruct clk_hw cpu_clk;\n\n\tbool per_core_dcvs;\n};\n\nstatic struct {\n\tstruct qcom_cpufreq_data *data;\n\tconst struct qcom_cpufreq_soc_data *soc_data;\n} qcom_cpufreq;\n\nstatic unsigned long cpu_hw_rate, xo_rate;\nstatic bool icc_scaling_enabled;\n\nstatic int qcom_cpufreq_set_bw(struct cpufreq_policy *policy,\n\t\t\t       unsigned long freq_khz)\n{\n\tunsigned long freq_hz = freq_khz * 1000;\n\tstruct dev_pm_opp *opp;\n\tstruct device *dev;\n\tint ret;\n\n\tdev = get_cpu_device(policy->cpu);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\topp = dev_pm_opp_find_freq_exact(dev, freq_hz, true);\n\tif (IS_ERR(opp))\n\t\treturn PTR_ERR(opp);\n\n\tret = dev_pm_opp_set_opp(dev, opp);\n\tdev_pm_opp_put(opp);\n\treturn ret;\n}\n\nstatic int qcom_cpufreq_update_opp(struct device *cpu_dev,\n\t\t\t\t   unsigned long freq_khz,\n\t\t\t\t   unsigned long volt)\n{\n\tunsigned long freq_hz = freq_khz * 1000;\n\tint ret;\n\n\t \n\tif (!icc_scaling_enabled)\n\t\treturn dev_pm_opp_add(cpu_dev, freq_hz, volt);\n\n\tret = dev_pm_opp_adjust_voltage(cpu_dev, freq_hz, volt, volt, volt);\n\tif (ret) {\n\t\tdev_err(cpu_dev, \"Voltage update failed freq=%ld\\n\", freq_khz);\n\t\treturn ret;\n\t}\n\n\treturn dev_pm_opp_enable(cpu_dev, freq_hz);\n}\n\nstatic int qcom_cpufreq_hw_target_index(struct cpufreq_policy *policy,\n\t\t\t\t\tunsigned int index)\n{\n\tstruct qcom_cpufreq_data *data = policy->driver_data;\n\tconst struct qcom_cpufreq_soc_data *soc_data = qcom_cpufreq.soc_data;\n\tunsigned long freq = policy->freq_table[index].frequency;\n\tunsigned int i;\n\n\twritel_relaxed(index, data->base + soc_data->reg_perf_state);\n\n\tif (data->per_core_dcvs)\n\t\tfor (i = 1; i < cpumask_weight(policy->related_cpus); i++)\n\t\t\twritel_relaxed(index, data->base + soc_data->reg_perf_state + i * 4);\n\n\tif (icc_scaling_enabled)\n\t\tqcom_cpufreq_set_bw(policy, freq);\n\n\treturn 0;\n}\n\nstatic unsigned long qcom_lmh_get_throttle_freq(struct qcom_cpufreq_data *data)\n{\n\tunsigned int lval;\n\n\tif (qcom_cpufreq.soc_data->reg_current_vote)\n\t\tlval = readl_relaxed(data->base + qcom_cpufreq.soc_data->reg_current_vote) & 0x3ff;\n\telse\n\t\tlval = readl_relaxed(data->base + qcom_cpufreq.soc_data->reg_domain_state) & 0xff;\n\n\treturn lval * xo_rate;\n}\n\n \nstatic unsigned int qcom_cpufreq_get_freq(unsigned int cpu)\n{\n\tstruct qcom_cpufreq_data *data;\n\tconst struct qcom_cpufreq_soc_data *soc_data;\n\tstruct cpufreq_policy *policy;\n\tunsigned int index;\n\n\tpolicy = cpufreq_cpu_get_raw(cpu);\n\tif (!policy)\n\t\treturn 0;\n\n\tdata = policy->driver_data;\n\tsoc_data = qcom_cpufreq.soc_data;\n\n\tindex = readl_relaxed(data->base + soc_data->reg_perf_state);\n\tindex = min(index, LUT_MAX_ENTRIES - 1);\n\n\treturn policy->freq_table[index].frequency;\n}\n\nstatic unsigned int qcom_cpufreq_hw_get(unsigned int cpu)\n{\n\tstruct qcom_cpufreq_data *data;\n\tstruct cpufreq_policy *policy;\n\n\tpolicy = cpufreq_cpu_get_raw(cpu);\n\tif (!policy)\n\t\treturn 0;\n\n\tdata = policy->driver_data;\n\n\tif (data->throttle_irq >= 0)\n\t\treturn qcom_lmh_get_throttle_freq(data) / HZ_PER_KHZ;\n\n\treturn qcom_cpufreq_get_freq(cpu);\n}\n\nstatic unsigned int qcom_cpufreq_hw_fast_switch(struct cpufreq_policy *policy,\n\t\t\t\t\t\tunsigned int target_freq)\n{\n\tstruct qcom_cpufreq_data *data = policy->driver_data;\n\tconst struct qcom_cpufreq_soc_data *soc_data = qcom_cpufreq.soc_data;\n\tunsigned int index;\n\tunsigned int i;\n\n\tindex = policy->cached_resolved_idx;\n\twritel_relaxed(index, data->base + soc_data->reg_perf_state);\n\n\tif (data->per_core_dcvs)\n\t\tfor (i = 1; i < cpumask_weight(policy->related_cpus); i++)\n\t\t\twritel_relaxed(index, data->base + soc_data->reg_perf_state + i * 4);\n\n\treturn policy->freq_table[index].frequency;\n}\n\nstatic int qcom_cpufreq_hw_read_lut(struct device *cpu_dev,\n\t\t\t\t    struct cpufreq_policy *policy)\n{\n\tu32 data, src, lval, i, core_count, prev_freq = 0, freq;\n\tu32 volt;\n\tstruct cpufreq_frequency_table\t*table;\n\tstruct dev_pm_opp *opp;\n\tunsigned long rate;\n\tint ret;\n\tstruct qcom_cpufreq_data *drv_data = policy->driver_data;\n\tconst struct qcom_cpufreq_soc_data *soc_data = qcom_cpufreq.soc_data;\n\n\ttable = kcalloc(LUT_MAX_ENTRIES + 1, sizeof(*table), GFP_KERNEL);\n\tif (!table)\n\t\treturn -ENOMEM;\n\n\tret = dev_pm_opp_of_add_table(cpu_dev);\n\tif (!ret) {\n\t\t \n\t\ticc_scaling_enabled = true;\n\t\tfor (rate = 0; ; rate++) {\n\t\t\topp = dev_pm_opp_find_freq_ceil(cpu_dev, &rate);\n\t\t\tif (IS_ERR(opp))\n\t\t\t\tbreak;\n\n\t\t\tdev_pm_opp_put(opp);\n\t\t\tdev_pm_opp_disable(cpu_dev, rate);\n\t\t}\n\t} else if (ret != -ENODEV) {\n\t\tdev_err(cpu_dev, \"Invalid opp table in device tree\\n\");\n\t\tkfree(table);\n\t\treturn ret;\n\t} else {\n\t\tpolicy->fast_switch_possible = true;\n\t\ticc_scaling_enabled = false;\n\t}\n\n\tfor (i = 0; i < LUT_MAX_ENTRIES; i++) {\n\t\tdata = readl_relaxed(drv_data->base + soc_data->reg_freq_lut +\n\t\t\t\t      i * soc_data->lut_row_size);\n\t\tsrc = FIELD_GET(LUT_SRC, data);\n\t\tlval = FIELD_GET(LUT_L_VAL, data);\n\t\tcore_count = FIELD_GET(LUT_CORE_COUNT, data);\n\n\t\tdata = readl_relaxed(drv_data->base + soc_data->reg_volt_lut +\n\t\t\t\t      i * soc_data->lut_row_size);\n\t\tvolt = FIELD_GET(LUT_VOLT, data) * 1000;\n\n\t\tif (src)\n\t\t\tfreq = xo_rate * lval / 1000;\n\t\telse\n\t\t\tfreq = cpu_hw_rate / 1000;\n\n\t\tif (freq != prev_freq && core_count != LUT_TURBO_IND) {\n\t\t\tif (!qcom_cpufreq_update_opp(cpu_dev, freq, volt)) {\n\t\t\t\ttable[i].frequency = freq;\n\t\t\t\tdev_dbg(cpu_dev, \"index=%d freq=%d, core_count %d\\n\", i,\n\t\t\t\tfreq, core_count);\n\t\t\t} else {\n\t\t\t\tdev_warn(cpu_dev, \"failed to update OPP for freq=%d\\n\", freq);\n\t\t\t\ttable[i].frequency = CPUFREQ_ENTRY_INVALID;\n\t\t\t}\n\n\t\t} else if (core_count == LUT_TURBO_IND) {\n\t\t\ttable[i].frequency = CPUFREQ_ENTRY_INVALID;\n\t\t}\n\n\t\t \n\t\tif (i > 0 && prev_freq == freq) {\n\t\t\tstruct cpufreq_frequency_table *prev = &table[i - 1];\n\n\t\t\t \n\t\t\tif (prev->frequency == CPUFREQ_ENTRY_INVALID) {\n\t\t\t\tif (!qcom_cpufreq_update_opp(cpu_dev, prev_freq, volt)) {\n\t\t\t\t\tprev->frequency = prev_freq;\n\t\t\t\t\tprev->flags = CPUFREQ_BOOST_FREQ;\n\t\t\t\t} else {\n\t\t\t\t\tdev_warn(cpu_dev, \"failed to update OPP for freq=%d\\n\",\n\t\t\t\t\t\t freq);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\n\t\tprev_freq = freq;\n\t}\n\n\ttable[i].frequency = CPUFREQ_TABLE_END;\n\tpolicy->freq_table = table;\n\tdev_pm_opp_set_sharing_cpus(cpu_dev, policy->cpus);\n\n\treturn 0;\n}\n\nstatic void qcom_get_related_cpus(int index, struct cpumask *m)\n{\n\tstruct device_node *cpu_np;\n\tstruct of_phandle_args args;\n\tint cpu, ret;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tcpu_np = of_cpu_device_node_get(cpu);\n\t\tif (!cpu_np)\n\t\t\tcontinue;\n\n\t\tret = of_parse_phandle_with_args(cpu_np, \"qcom,freq-domain\",\n\t\t\t\t\t\t \"#freq-domain-cells\", 0,\n\t\t\t\t\t\t &args);\n\t\tof_node_put(cpu_np);\n\t\tif (ret < 0)\n\t\t\tcontinue;\n\n\t\tif (index == args.args[0])\n\t\t\tcpumask_set_cpu(cpu, m);\n\t}\n}\n\nstatic void qcom_lmh_dcvs_notify(struct qcom_cpufreq_data *data)\n{\n\tstruct cpufreq_policy *policy = data->policy;\n\tint cpu = cpumask_first(policy->related_cpus);\n\tstruct device *dev = get_cpu_device(cpu);\n\tunsigned long freq_hz, throttled_freq;\n\tstruct dev_pm_opp *opp;\n\n\t \n\tfreq_hz = qcom_lmh_get_throttle_freq(data);\n\n\topp = dev_pm_opp_find_freq_floor(dev, &freq_hz);\n\tif (IS_ERR(opp) && PTR_ERR(opp) == -ERANGE)\n\t\topp = dev_pm_opp_find_freq_ceil(dev, &freq_hz);\n\n\tif (IS_ERR(opp)) {\n\t\tdev_warn(dev, \"Can't find the OPP for throttling: %pe!\\n\", opp);\n\t} else {\n\t\tdev_pm_opp_put(opp);\n\t}\n\n\tthrottled_freq = freq_hz / HZ_PER_KHZ;\n\n\t \n\tarch_update_thermal_pressure(policy->related_cpus, throttled_freq);\n\n\t \n\tmutex_lock(&data->throttle_lock);\n\tif (data->cancel_throttle)\n\t\tgoto out;\n\n\t \n\tif (throttled_freq >= qcom_cpufreq_get_freq(cpu))\n\t\tenable_irq(data->throttle_irq);\n\telse\n\t\tmod_delayed_work(system_highpri_wq, &data->throttle_work,\n\t\t\t\t msecs_to_jiffies(10));\n\nout:\n\tmutex_unlock(&data->throttle_lock);\n}\n\nstatic void qcom_lmh_dcvs_poll(struct work_struct *work)\n{\n\tstruct qcom_cpufreq_data *data;\n\n\tdata = container_of(work, struct qcom_cpufreq_data, throttle_work.work);\n\tqcom_lmh_dcvs_notify(data);\n}\n\nstatic irqreturn_t qcom_lmh_dcvs_handle_irq(int irq, void *data)\n{\n\tstruct qcom_cpufreq_data *c_data = data;\n\n\t \n\tdisable_irq_nosync(c_data->throttle_irq);\n\tschedule_delayed_work(&c_data->throttle_work, 0);\n\n\tif (qcom_cpufreq.soc_data->reg_intr_clr)\n\t\twritel_relaxed(GT_IRQ_STATUS,\n\t\t\t       c_data->base + qcom_cpufreq.soc_data->reg_intr_clr);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic const struct qcom_cpufreq_soc_data qcom_soc_data = {\n\t.reg_enable = 0x0,\n\t.reg_dcvs_ctrl = 0xbc,\n\t.reg_freq_lut = 0x110,\n\t.reg_volt_lut = 0x114,\n\t.reg_current_vote = 0x704,\n\t.reg_perf_state = 0x920,\n\t.lut_row_size = 32,\n};\n\nstatic const struct qcom_cpufreq_soc_data epss_soc_data = {\n\t.reg_enable = 0x0,\n\t.reg_domain_state = 0x20,\n\t.reg_dcvs_ctrl = 0xb0,\n\t.reg_freq_lut = 0x100,\n\t.reg_volt_lut = 0x200,\n\t.reg_intr_clr = 0x308,\n\t.reg_perf_state = 0x320,\n\t.lut_row_size = 4,\n};\n\nstatic const struct of_device_id qcom_cpufreq_hw_match[] = {\n\t{ .compatible = \"qcom,cpufreq-hw\", .data = &qcom_soc_data },\n\t{ .compatible = \"qcom,cpufreq-epss\", .data = &epss_soc_data },\n\t{}\n};\nMODULE_DEVICE_TABLE(of, qcom_cpufreq_hw_match);\n\nstatic int qcom_cpufreq_hw_lmh_init(struct cpufreq_policy *policy, int index)\n{\n\tstruct qcom_cpufreq_data *data = policy->driver_data;\n\tstruct platform_device *pdev = cpufreq_get_driver_data();\n\tint ret;\n\n\t \n\tdata->throttle_irq = platform_get_irq_optional(pdev, index);\n\tif (data->throttle_irq == -ENXIO)\n\t\treturn 0;\n\tif (data->throttle_irq < 0)\n\t\treturn data->throttle_irq;\n\n\tdata->cancel_throttle = false;\n\tdata->policy = policy;\n\n\tmutex_init(&data->throttle_lock);\n\tINIT_DEFERRABLE_WORK(&data->throttle_work, qcom_lmh_dcvs_poll);\n\n\tsnprintf(data->irq_name, sizeof(data->irq_name), \"dcvsh-irq-%u\", policy->cpu);\n\tret = request_threaded_irq(data->throttle_irq, NULL, qcom_lmh_dcvs_handle_irq,\n\t\t\t\t   IRQF_ONESHOT | IRQF_NO_AUTOEN, data->irq_name, data);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Error registering %s: %d\\n\", data->irq_name, ret);\n\t\treturn 0;\n\t}\n\n\tret = irq_set_affinity_and_hint(data->throttle_irq, policy->cpus);\n\tif (ret)\n\t\tdev_err(&pdev->dev, \"Failed to set CPU affinity of %s[%d]\\n\",\n\t\t\tdata->irq_name, data->throttle_irq);\n\n\treturn 0;\n}\n\nstatic int qcom_cpufreq_hw_cpu_online(struct cpufreq_policy *policy)\n{\n\tstruct qcom_cpufreq_data *data = policy->driver_data;\n\tstruct platform_device *pdev = cpufreq_get_driver_data();\n\tint ret;\n\n\tif (data->throttle_irq <= 0)\n\t\treturn 0;\n\n\tmutex_lock(&data->throttle_lock);\n\tdata->cancel_throttle = false;\n\tmutex_unlock(&data->throttle_lock);\n\n\tret = irq_set_affinity_and_hint(data->throttle_irq, policy->cpus);\n\tif (ret)\n\t\tdev_err(&pdev->dev, \"Failed to set CPU affinity of %s[%d]\\n\",\n\t\t\tdata->irq_name, data->throttle_irq);\n\n\treturn ret;\n}\n\nstatic int qcom_cpufreq_hw_cpu_offline(struct cpufreq_policy *policy)\n{\n\tstruct qcom_cpufreq_data *data = policy->driver_data;\n\n\tif (data->throttle_irq <= 0)\n\t\treturn 0;\n\n\tmutex_lock(&data->throttle_lock);\n\tdata->cancel_throttle = true;\n\tmutex_unlock(&data->throttle_lock);\n\n\tcancel_delayed_work_sync(&data->throttle_work);\n\tirq_set_affinity_and_hint(data->throttle_irq, NULL);\n\tdisable_irq_nosync(data->throttle_irq);\n\n\treturn 0;\n}\n\nstatic void qcom_cpufreq_hw_lmh_exit(struct qcom_cpufreq_data *data)\n{\n\tif (data->throttle_irq <= 0)\n\t\treturn;\n\n\tfree_irq(data->throttle_irq, data);\n}\n\nstatic int qcom_cpufreq_hw_cpu_init(struct cpufreq_policy *policy)\n{\n\tstruct platform_device *pdev = cpufreq_get_driver_data();\n\tstruct device *dev = &pdev->dev;\n\tstruct of_phandle_args args;\n\tstruct device_node *cpu_np;\n\tstruct device *cpu_dev;\n\tstruct qcom_cpufreq_data *data;\n\tint ret, index;\n\n\tcpu_dev = get_cpu_device(policy->cpu);\n\tif (!cpu_dev) {\n\t\tpr_err(\"%s: failed to get cpu%d device\\n\", __func__,\n\t\t       policy->cpu);\n\t\treturn -ENODEV;\n\t}\n\n\tcpu_np = of_cpu_device_node_get(policy->cpu);\n\tif (!cpu_np)\n\t\treturn -EINVAL;\n\n\tret = of_parse_phandle_with_args(cpu_np, \"qcom,freq-domain\",\n\t\t\t\t\t \"#freq-domain-cells\", 0, &args);\n\tof_node_put(cpu_np);\n\tif (ret)\n\t\treturn ret;\n\n\tindex = args.args[0];\n\tdata = &qcom_cpufreq.data[index];\n\n\t \n\tif (!(readl_relaxed(data->base + qcom_cpufreq.soc_data->reg_enable) & 0x1)) {\n\t\tdev_err(dev, \"Domain-%d cpufreq hardware not enabled\\n\", index);\n\t\treturn -ENODEV;\n\t}\n\n\tif (readl_relaxed(data->base + qcom_cpufreq.soc_data->reg_dcvs_ctrl) & 0x1)\n\t\tdata->per_core_dcvs = true;\n\n\tqcom_get_related_cpus(index, policy->cpus);\n\n\tpolicy->driver_data = data;\n\tpolicy->dvfs_possible_from_any_cpu = true;\n\n\tret = qcom_cpufreq_hw_read_lut(cpu_dev, policy);\n\tif (ret) {\n\t\tdev_err(dev, \"Domain-%d failed to read LUT\\n\", index);\n\t\treturn ret;\n\t}\n\n\tret = dev_pm_opp_get_opp_count(cpu_dev);\n\tif (ret <= 0) {\n\t\tdev_err(cpu_dev, \"Failed to add OPPs\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (policy_has_boost_freq(policy)) {\n\t\tret = cpufreq_enable_boost_support();\n\t\tif (ret)\n\t\t\tdev_warn(cpu_dev, \"failed to enable boost: %d\\n\", ret);\n\t}\n\n\treturn qcom_cpufreq_hw_lmh_init(policy, index);\n}\n\nstatic int qcom_cpufreq_hw_cpu_exit(struct cpufreq_policy *policy)\n{\n\tstruct device *cpu_dev = get_cpu_device(policy->cpu);\n\tstruct qcom_cpufreq_data *data = policy->driver_data;\n\n\tdev_pm_opp_remove_all_dynamic(cpu_dev);\n\tdev_pm_opp_of_cpumask_remove_table(policy->related_cpus);\n\tqcom_cpufreq_hw_lmh_exit(data);\n\tkfree(policy->freq_table);\n\tkfree(data);\n\n\treturn 0;\n}\n\nstatic void qcom_cpufreq_ready(struct cpufreq_policy *policy)\n{\n\tstruct qcom_cpufreq_data *data = policy->driver_data;\n\n\tif (data->throttle_irq >= 0)\n\t\tenable_irq(data->throttle_irq);\n}\n\nstatic struct freq_attr *qcom_cpufreq_hw_attr[] = {\n\t&cpufreq_freq_attr_scaling_available_freqs,\n\t&cpufreq_freq_attr_scaling_boost_freqs,\n\tNULL\n};\n\nstatic struct cpufreq_driver cpufreq_qcom_hw_driver = {\n\t.flags\t\t= CPUFREQ_NEED_INITIAL_FREQ_CHECK |\n\t\t\t  CPUFREQ_HAVE_GOVERNOR_PER_POLICY |\n\t\t\t  CPUFREQ_IS_COOLING_DEV,\n\t.verify\t\t= cpufreq_generic_frequency_table_verify,\n\t.target_index\t= qcom_cpufreq_hw_target_index,\n\t.get\t\t= qcom_cpufreq_hw_get,\n\t.init\t\t= qcom_cpufreq_hw_cpu_init,\n\t.exit\t\t= qcom_cpufreq_hw_cpu_exit,\n\t.online\t\t= qcom_cpufreq_hw_cpu_online,\n\t.offline\t= qcom_cpufreq_hw_cpu_offline,\n\t.register_em\t= cpufreq_register_em_with_opp,\n\t.fast_switch    = qcom_cpufreq_hw_fast_switch,\n\t.name\t\t= \"qcom-cpufreq-hw\",\n\t.attr\t\t= qcom_cpufreq_hw_attr,\n\t.ready\t\t= qcom_cpufreq_ready,\n};\n\nstatic unsigned long qcom_cpufreq_hw_recalc_rate(struct clk_hw *hw, unsigned long parent_rate)\n{\n\tstruct qcom_cpufreq_data *data = container_of(hw, struct qcom_cpufreq_data, cpu_clk);\n\n\treturn qcom_lmh_get_throttle_freq(data);\n}\n\nstatic const struct clk_ops qcom_cpufreq_hw_clk_ops = {\n\t.recalc_rate = qcom_cpufreq_hw_recalc_rate,\n};\n\nstatic int qcom_cpufreq_hw_driver_probe(struct platform_device *pdev)\n{\n\tstruct clk_hw_onecell_data *clk_data;\n\tstruct device *dev = &pdev->dev;\n\tstruct device *cpu_dev;\n\tstruct clk *clk;\n\tint ret, i, num_domains;\n\n\tclk = clk_get(dev, \"xo\");\n\tif (IS_ERR(clk))\n\t\treturn PTR_ERR(clk);\n\n\txo_rate = clk_get_rate(clk);\n\tclk_put(clk);\n\n\tclk = clk_get(dev, \"alternate\");\n\tif (IS_ERR(clk))\n\t\treturn PTR_ERR(clk);\n\n\tcpu_hw_rate = clk_get_rate(clk) / CLK_HW_DIV;\n\tclk_put(clk);\n\n\tcpufreq_qcom_hw_driver.driver_data = pdev;\n\n\t \n\tcpu_dev = get_cpu_device(0);\n\tif (!cpu_dev)\n\t\treturn -EPROBE_DEFER;\n\n\tret = dev_pm_opp_of_find_icc_paths(cpu_dev, NULL);\n\tif (ret)\n\t\treturn dev_err_probe(dev, ret, \"Failed to find icc paths\\n\");\n\n\tfor (num_domains = 0; num_domains < MAX_FREQ_DOMAINS; num_domains++)\n\t\tif (!platform_get_resource(pdev, IORESOURCE_MEM, num_domains))\n\t\t\tbreak;\n\n\tqcom_cpufreq.data = devm_kzalloc(dev, sizeof(struct qcom_cpufreq_data) * num_domains,\n\t\t\t\t\t GFP_KERNEL);\n\tif (!qcom_cpufreq.data)\n\t\treturn -ENOMEM;\n\n\tqcom_cpufreq.soc_data = of_device_get_match_data(dev);\n\tif (!qcom_cpufreq.soc_data)\n\t\treturn -ENODEV;\n\n\tclk_data = devm_kzalloc(dev, struct_size(clk_data, hws, num_domains), GFP_KERNEL);\n\tif (!clk_data)\n\t\treturn -ENOMEM;\n\n\tclk_data->num = num_domains;\n\n\tfor (i = 0; i < num_domains; i++) {\n\t\tstruct qcom_cpufreq_data *data = &qcom_cpufreq.data[i];\n\t\tstruct clk_init_data clk_init = {};\n\t\tvoid __iomem *base;\n\n\t\tbase = devm_platform_ioremap_resource(pdev, i);\n\t\tif (IS_ERR(base)) {\n\t\t\tdev_err(dev, \"Failed to map resource index %d\\n\", i);\n\t\t\treturn PTR_ERR(base);\n\t\t}\n\n\t\tdata->base = base;\n\n\t\t \n\t\tclk_init.name = kasprintf(GFP_KERNEL, \"qcom_cpufreq%d\", i);\n\t\tif (!clk_init.name)\n\t\t\treturn -ENOMEM;\n\n\t\tclk_init.flags = CLK_GET_RATE_NOCACHE;\n\t\tclk_init.ops = &qcom_cpufreq_hw_clk_ops;\n\t\tdata->cpu_clk.init = &clk_init;\n\n\t\tret = devm_clk_hw_register(dev, &data->cpu_clk);\n\t\tif (ret < 0) {\n\t\t\tdev_err(dev, \"Failed to register clock %d: %d\\n\", i, ret);\n\t\t\tkfree(clk_init.name);\n\t\t\treturn ret;\n\t\t}\n\n\t\tclk_data->hws[i] = &data->cpu_clk;\n\t\tkfree(clk_init.name);\n\t}\n\n\tret = devm_of_clk_add_hw_provider(dev, of_clk_hw_onecell_get, clk_data);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"Failed to add clock provider\\n\");\n\t\treturn ret;\n\t}\n\n\tret = cpufreq_register_driver(&cpufreq_qcom_hw_driver);\n\tif (ret)\n\t\tdev_err(dev, \"CPUFreq HW driver failed to register\\n\");\n\telse\n\t\tdev_dbg(dev, \"QCOM CPUFreq HW driver initialized\\n\");\n\n\treturn ret;\n}\n\nstatic void qcom_cpufreq_hw_driver_remove(struct platform_device *pdev)\n{\n\tcpufreq_unregister_driver(&cpufreq_qcom_hw_driver);\n}\n\nstatic struct platform_driver qcom_cpufreq_hw_driver = {\n\t.probe = qcom_cpufreq_hw_driver_probe,\n\t.remove_new = qcom_cpufreq_hw_driver_remove,\n\t.driver = {\n\t\t.name = \"qcom-cpufreq-hw\",\n\t\t.of_match_table = qcom_cpufreq_hw_match,\n\t},\n};\n\nstatic int __init qcom_cpufreq_hw_init(void)\n{\n\treturn platform_driver_register(&qcom_cpufreq_hw_driver);\n}\npostcore_initcall(qcom_cpufreq_hw_init);\n\nstatic void __exit qcom_cpufreq_hw_exit(void)\n{\n\tplatform_driver_unregister(&qcom_cpufreq_hw_driver);\n}\nmodule_exit(qcom_cpufreq_hw_exit);\n\nMODULE_DESCRIPTION(\"QCOM CPUFREQ HW Driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}