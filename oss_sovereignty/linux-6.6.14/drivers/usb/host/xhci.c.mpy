{
  "module_name": "xhci.c",
  "hash_id": "3ec58e7637833aaa3bea9e02c02fbee8fec647ed5a4ab6f6e30fd6931a36823a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/usb/host/xhci.c",
  "human_readable_source": "\n \n\n#include <linux/pci.h>\n#include <linux/iommu.h>\n#include <linux/iopoll.h>\n#include <linux/irq.h>\n#include <linux/log2.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/slab.h>\n#include <linux/dmi.h>\n#include <linux/dma-mapping.h>\n\n#include \"xhci.h\"\n#include \"xhci-trace.h\"\n#include \"xhci-debugfs.h\"\n#include \"xhci-dbgcap.h\"\n\n#define DRIVER_AUTHOR \"Sarah Sharp\"\n#define DRIVER_DESC \"'eXtensible' Host Controller (xHC) Driver\"\n\n#define\tPORT_WAKE_BITS\t(PORT_WKOC_E | PORT_WKDISC_E | PORT_WKCONN_E)\n\n \nstatic int link_quirk;\nmodule_param(link_quirk, int, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(link_quirk, \"Don't clear the chain bit on a link TRB\");\n\nstatic unsigned long long quirks;\nmodule_param(quirks, ullong, S_IRUGO);\nMODULE_PARM_DESC(quirks, \"Bit flags for quirks to be enabled as default\");\n\nstatic bool td_on_ring(struct xhci_td *td, struct xhci_ring *ring)\n{\n\tstruct xhci_segment *seg = ring->first_seg;\n\n\tif (!td || !td->start_seg)\n\t\treturn false;\n\tdo {\n\t\tif (seg == td->start_seg)\n\t\t\treturn true;\n\t\tseg = seg->next;\n\t} while (seg && seg != ring->first_seg);\n\n\treturn false;\n}\n\n \nint xhci_handshake(void __iomem *ptr, u32 mask, u32 done, u64 timeout_us)\n{\n\tu32\tresult;\n\tint\tret;\n\n\tret = readl_poll_timeout_atomic(ptr, result,\n\t\t\t\t\t(result & mask) == done ||\n\t\t\t\t\tresult == U32_MAX,\n\t\t\t\t\t1, timeout_us);\n\tif (result == U32_MAX)\t\t \n\t\treturn -ENODEV;\n\n\treturn ret;\n}\n\n \nvoid xhci_quiesce(struct xhci_hcd *xhci)\n{\n\tu32 halted;\n\tu32 cmd;\n\tu32 mask;\n\n\tmask = ~(XHCI_IRQS);\n\thalted = readl(&xhci->op_regs->status) & STS_HALT;\n\tif (!halted)\n\t\tmask &= ~CMD_RUN;\n\n\tcmd = readl(&xhci->op_regs->command);\n\tcmd &= mask;\n\twritel(cmd, &xhci->op_regs->command);\n}\n\n \nint xhci_halt(struct xhci_hcd *xhci)\n{\n\tint ret;\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"\n\txhci_quiesce(xhci);\n\n\tret = xhci_handshake(&xhci->op_regs->status,\n\t\t\tSTS_HALT, STS_HALT, XHCI_MAX_HALT_USEC);\n\tif (ret) {\n\t\txhci_warn(xhci, \"Host halt failed, %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\txhci->xhc_state |= XHCI_STATE_HALTED;\n\txhci->cmd_ring_state = CMD_RING_STATE_STOPPED;\n\n\treturn ret;\n}\n\n/*\n * Set the run bit and wait for the host to be running.\n */\nint xhci_start(struct xhci_hcd *xhci)\n{\n\tu32 temp;\n\tint ret;\n\n\ttemp = readl(&xhci->op_regs->command);\n\ttemp |= (CMD_RUN);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \" \n\t\t\ttemp);\n\twritel(temp, &xhci->op_regs->command);\n\n\t \n\tret = xhci_handshake(&xhci->op_regs->status,\n\t\t\tSTS_HALT, 0, XHCI_MAX_HALT_USEC);\n\tif (ret == -ETIMEDOUT)\n\t\txhci_err(xhci, \"Host took too long to start, \"\n\t\t\t\t\"waited %u microseconds.\\n\",\n\t\t\t\tXHCI_MAX_HALT_USEC);\n\tif (!ret) {\n\t\t \n\t\txhci->xhc_state = 0;\n\t\txhci->run_graceperiod = jiffies + msecs_to_jiffies(500);\n\t}\n\n\treturn ret;\n}\n\n \nint xhci_reset(struct xhci_hcd *xhci, u64 timeout_us)\n{\n\tu32 command;\n\tu32 state;\n\tint ret;\n\n\tstate = readl(&xhci->op_regs->status);\n\n\tif (state == ~(u32)0) {\n\t\txhci_warn(xhci, \"Host not accessible, reset failed.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif ((state & STS_HALT) == 0) {\n\t\txhci_warn(xhci, \"Host controller not halted, aborting reset.\\n\");\n\t\treturn 0;\n\t}\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"// Reset the HC\");\n\tcommand = readl(&xhci->op_regs->command);\n\tcommand |= CMD_RESET;\n\twritel(command, &xhci->op_regs->command);\n\n\t \n\tif (xhci->quirks & XHCI_INTEL_HOST)\n\t\tudelay(1000);\n\n\tret = xhci_handshake(&xhci->op_regs->command, CMD_RESET, 0, timeout_us);\n\tif (ret)\n\t\treturn ret;\n\n\tif (xhci->quirks & XHCI_ASMEDIA_MODIFY_FLOWCONTROL)\n\t\tusb_asmedia_modifyflowcontrol(to_pci_dev(xhci_to_hcd(xhci)->self.controller));\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t \"Wait for controller to be ready for doorbell rings\");\n\t \n\tret = xhci_handshake(&xhci->op_regs->status, STS_CNR, 0, timeout_us);\n\n\txhci->usb2_rhub.bus_state.port_c_suspend = 0;\n\txhci->usb2_rhub.bus_state.suspended_ports = 0;\n\txhci->usb2_rhub.bus_state.resuming_ports = 0;\n\txhci->usb3_rhub.bus_state.port_c_suspend = 0;\n\txhci->usb3_rhub.bus_state.suspended_ports = 0;\n\txhci->usb3_rhub.bus_state.resuming_ports = 0;\n\n\treturn ret;\n}\n\nstatic void xhci_zero_64b_regs(struct xhci_hcd *xhci)\n{\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\tstruct iommu_domain *domain;\n\tint err, i;\n\tu64 val;\n\tu32 intrs;\n\n\t \n\tdomain = iommu_get_domain_for_dev(dev);\n\tif (!(xhci->quirks & XHCI_ZERO_64B_REGS) || !domain ||\n\t    domain->type == IOMMU_DOMAIN_IDENTITY)\n\t\treturn;\n\n\txhci_info(xhci, \"Zeroing 64bit base registers, expecting fault\\n\");\n\n\t \n\tval = readl(&xhci->op_regs->command);\n\tval &= ~CMD_HSEIE;\n\twritel(val, &xhci->op_regs->command);\n\n\t \n\tval = readl(&xhci->op_regs->status);\n\tval |= STS_FATAL;\n\twritel(val, &xhci->op_regs->status);\n\n\t \n\tval = xhci_read_64(xhci, &xhci->op_regs->dcbaa_ptr);\n\tif (upper_32_bits(val))\n\t\txhci_write_64(xhci, 0, &xhci->op_regs->dcbaa_ptr);\n\tval = xhci_read_64(xhci, &xhci->op_regs->cmd_ring);\n\tif (upper_32_bits(val))\n\t\txhci_write_64(xhci, 0, &xhci->op_regs->cmd_ring);\n\n\tintrs = min_t(u32, HCS_MAX_INTRS(xhci->hcs_params1),\n\t\t      ARRAY_SIZE(xhci->run_regs->ir_set));\n\n\tfor (i = 0; i < intrs; i++) {\n\t\tstruct xhci_intr_reg __iomem *ir;\n\n\t\tir = &xhci->run_regs->ir_set[i];\n\t\tval = xhci_read_64(xhci, &ir->erst_base);\n\t\tif (upper_32_bits(val))\n\t\t\txhci_write_64(xhci, 0, &ir->erst_base);\n\t\tval= xhci_read_64(xhci, &ir->erst_dequeue);\n\t\tif (upper_32_bits(val))\n\t\t\txhci_write_64(xhci, 0, &ir->erst_dequeue);\n\t}\n\n\t \n\terr = xhci_handshake(&xhci->op_regs->status,\n\t\t\t     STS_FATAL, STS_FATAL,\n\t\t\t     XHCI_MAX_HALT_USEC);\n\tif (!err)\n\t\txhci_info(xhci, \"Fault detected\\n\");\n}\n\nstatic int xhci_enable_interrupter(struct xhci_interrupter *ir)\n{\n\tu32 iman;\n\n\tif (!ir || !ir->ir_set)\n\t\treturn -EINVAL;\n\n\timan = readl(&ir->ir_set->irq_pending);\n\twritel(ER_IRQ_ENABLE(iman), &ir->ir_set->irq_pending);\n\n\treturn 0;\n}\n\nstatic int xhci_disable_interrupter(struct xhci_interrupter *ir)\n{\n\tu32 iman;\n\n\tif (!ir || !ir->ir_set)\n\t\treturn -EINVAL;\n\n\timan = readl(&ir->ir_set->irq_pending);\n\twritel(ER_IRQ_DISABLE(iman), &ir->ir_set->irq_pending);\n\n\treturn 0;\n}\n\nstatic void compliance_mode_recovery(struct timer_list *t)\n{\n\tstruct xhci_hcd *xhci;\n\tstruct usb_hcd *hcd;\n\tstruct xhci_hub *rhub;\n\tu32 temp;\n\tint i;\n\n\txhci = from_timer(xhci, t, comp_mode_recovery_timer);\n\trhub = &xhci->usb3_rhub;\n\thcd = rhub->hcd;\n\n\tif (!hcd)\n\t\treturn;\n\n\tfor (i = 0; i < rhub->num_ports; i++) {\n\t\ttemp = readl(rhub->ports[i]->addr);\n\t\tif ((temp & PORT_PLS_MASK) == USB_SS_PORT_LS_COMP_MOD) {\n\t\t\t \n\t\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\t\"Compliance mode detected->port %d\",\n\t\t\t\t\ti + 1);\n\t\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\t\"Attempting compliance mode recovery\");\n\n\t\t\tif (hcd->state == HC_STATE_SUSPENDED)\n\t\t\t\tusb_hcd_resume_root_hub(hcd);\n\n\t\t\tusb_hcd_poll_rh_status(hcd);\n\t\t}\n\t}\n\n\tif (xhci->port_status_u0 != ((1 << rhub->num_ports) - 1))\n\t\tmod_timer(&xhci->comp_mode_recovery_timer,\n\t\t\tjiffies + msecs_to_jiffies(COMP_MODE_RCVRY_MSECS));\n}\n\n \nstatic void compliance_mode_recovery_timer_init(struct xhci_hcd *xhci)\n{\n\txhci->port_status_u0 = 0;\n\ttimer_setup(&xhci->comp_mode_recovery_timer, compliance_mode_recovery,\n\t\t    0);\n\txhci->comp_mode_recovery_timer.expires = jiffies +\n\t\t\tmsecs_to_jiffies(COMP_MODE_RCVRY_MSECS);\n\n\tadd_timer(&xhci->comp_mode_recovery_timer);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\"Compliance mode recovery timer initialized\");\n}\n\n \nstatic bool xhci_compliance_mode_recovery_timer_quirk_check(void)\n{\n\tconst char *dmi_product_name, *dmi_sys_vendor;\n\n\tdmi_product_name = dmi_get_system_info(DMI_PRODUCT_NAME);\n\tdmi_sys_vendor = dmi_get_system_info(DMI_SYS_VENDOR);\n\tif (!dmi_product_name || !dmi_sys_vendor)\n\t\treturn false;\n\n\tif (!(strstr(dmi_sys_vendor, \"Hewlett-Packard\")))\n\t\treturn false;\n\n\tif (strstr(dmi_product_name, \"Z420\") ||\n\t\t\tstrstr(dmi_product_name, \"Z620\") ||\n\t\t\tstrstr(dmi_product_name, \"Z820\") ||\n\t\t\tstrstr(dmi_product_name, \"Z1 Workstation\"))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int xhci_all_ports_seen_u0(struct xhci_hcd *xhci)\n{\n\treturn (xhci->port_status_u0 == ((1 << xhci->usb3_rhub.num_ports) - 1));\n}\n\n\n \nstatic int xhci_init(struct usb_hcd *hcd)\n{\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\tint retval;\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"xhci_init\");\n\tspin_lock_init(&xhci->lock);\n\tif (xhci->hci_version == 0x95 && link_quirk) {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"QUIRK: Not clearing Link TRB chain bits.\");\n\t\txhci->quirks |= XHCI_LINK_TRB_QUIRK;\n\t} else {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\t\"xHCI doesn't need link TRB QUIRK\");\n\t}\n\tretval = xhci_mem_init(xhci, GFP_KERNEL);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"Finished xhci_init\");\n\n\t \n\tif (xhci_compliance_mode_recovery_timer_quirk_check()) {\n\t\txhci->quirks |= XHCI_COMP_MODE_QUIRK;\n\t\tcompliance_mode_recovery_timer_init(xhci);\n\t}\n\n\treturn retval;\n}\n\n \n\nstatic int xhci_run_finished(struct xhci_hcd *xhci)\n{\n\tstruct xhci_interrupter *ir = xhci->interrupter;\n\tunsigned long\tflags;\n\tu32\t\ttemp;\n\n\t \n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"Enable interrupts\");\n\ttemp = readl(&xhci->op_regs->command);\n\ttemp |= (CMD_EIE);\n\twritel(temp, &xhci->op_regs->command);\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"Enable primary interrupter\");\n\txhci_enable_interrupter(ir);\n\n\tif (xhci_start(xhci)) {\n\t\txhci_halt(xhci);\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\treturn -ENODEV;\n\t}\n\n\txhci->cmd_ring_state = CMD_RING_STATE_RUNNING;\n\n\tif (xhci->quirks & XHCI_NEC_HOST)\n\t\txhci_ring_cmd_db(xhci);\n\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\treturn 0;\n}\n\n \nint xhci_run(struct usb_hcd *hcd)\n{\n\tu32 temp;\n\tu64 temp_64;\n\tint ret;\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\tstruct xhci_interrupter *ir = xhci->interrupter;\n\t \n\n\thcd->uses_new_polling = 1;\n\tif (!usb_hcd_is_primary_hcd(hcd))\n\t\treturn xhci_run_finished(xhci);\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"xhci_run\");\n\n\ttemp_64 = xhci_read_64(xhci, &ir->ir_set->erst_dequeue);\n\ttemp_64 &= ~ERST_PTR_MASK;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"ERST deq = 64'h%0lx\", (long unsigned int) temp_64);\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"// Set the interrupt modulation register\");\n\ttemp = readl(&ir->ir_set->irq_control);\n\ttemp &= ~ER_IRQ_INTERVAL_MASK;\n\ttemp |= (xhci->imod_interval / 250) & ER_IRQ_INTERVAL_MASK;\n\twritel(temp, &ir->ir_set->irq_control);\n\n\tif (xhci->quirks & XHCI_NEC_HOST) {\n\t\tstruct xhci_command *command;\n\n\t\tcommand = xhci_alloc_command(xhci, false, GFP_KERNEL);\n\t\tif (!command)\n\t\t\treturn -ENOMEM;\n\n\t\tret = xhci_queue_vendor_command(xhci, command, 0, 0, 0,\n\t\t\t\tTRB_TYPE(TRB_NEC_GET_FW));\n\t\tif (ret)\n\t\t\txhci_free_command(xhci, command);\n\t}\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"Finished %s for main hcd\", __func__);\n\n\txhci_create_dbc_dev(xhci);\n\n\txhci_debugfs_init(xhci);\n\n\tif (xhci_has_one_roothub(xhci))\n\t\treturn xhci_run_finished(xhci);\n\n\tset_bit(HCD_FLAG_DEFER_RH_REGISTER, &hcd->flags);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xhci_run);\n\n \nvoid xhci_stop(struct usb_hcd *hcd)\n{\n\tu32 temp;\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\tstruct xhci_interrupter *ir = xhci->interrupter;\n\n\tmutex_lock(&xhci->mutex);\n\n\t \n\tif (!usb_hcd_is_primary_hcd(hcd)) {\n\t\tmutex_unlock(&xhci->mutex);\n\t\treturn;\n\t}\n\n\txhci_remove_dbc_dev(xhci);\n\n\tspin_lock_irq(&xhci->lock);\n\txhci->xhc_state |= XHCI_STATE_HALTED;\n\txhci->cmd_ring_state = CMD_RING_STATE_STOPPED;\n\txhci_halt(xhci);\n\txhci_reset(xhci, XHCI_RESET_SHORT_USEC);\n\tspin_unlock_irq(&xhci->lock);\n\n\t \n\tif ((xhci->quirks & XHCI_COMP_MODE_QUIRK) &&\n\t\t\t(!(xhci_all_ports_seen_u0(xhci)))) {\n\t\tdel_timer_sync(&xhci->comp_mode_recovery_timer);\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"%s: compliance mode recovery timer deleted\",\n\t\t\t\t__func__);\n\t}\n\n\tif (xhci->quirks & XHCI_AMD_PLL_FIX)\n\t\tusb_amd_dev_put();\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"// Disabling event ring interrupts\");\n\ttemp = readl(&xhci->op_regs->status);\n\twritel((temp & ~0x1fff) | STS_EINT, &xhci->op_regs->status);\n\txhci_disable_interrupter(ir);\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"cleaning up memory\");\n\txhci_mem_cleanup(xhci);\n\txhci_debugfs_exit(xhci);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"xhci_stop completed - status = %x\",\n\t\t\treadl(&xhci->op_regs->status));\n\tmutex_unlock(&xhci->mutex);\n}\nEXPORT_SYMBOL_GPL(xhci_stop);\n\n \nvoid xhci_shutdown(struct usb_hcd *hcd)\n{\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\n\tif (xhci->quirks & XHCI_SPURIOUS_REBOOT)\n\t\tusb_disable_xhci_ports(to_pci_dev(hcd->self.sysdev));\n\n\t \n\txhci_dbg(xhci, \"%s: stopping usb%d port polling.\\n\",\n\t\t\t__func__, hcd->self.busnum);\n\tclear_bit(HCD_FLAG_POLL_RH, &hcd->flags);\n\tdel_timer_sync(&hcd->rh_timer);\n\n\tif (xhci->shared_hcd) {\n\t\tclear_bit(HCD_FLAG_POLL_RH, &xhci->shared_hcd->flags);\n\t\tdel_timer_sync(&xhci->shared_hcd->rh_timer);\n\t}\n\n\tspin_lock_irq(&xhci->lock);\n\txhci_halt(xhci);\n\n\t \n\tif (xhci->quirks & XHCI_SPURIOUS_WAKEUP ||\n\t    xhci->quirks & XHCI_RESET_TO_DEFAULT)\n\t\txhci_reset(xhci, XHCI_RESET_SHORT_USEC);\n\n\tspin_unlock_irq(&xhci->lock);\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"xhci_shutdown completed - status = %x\",\n\t\t\treadl(&xhci->op_regs->status));\n}\nEXPORT_SYMBOL_GPL(xhci_shutdown);\n\n#ifdef CONFIG_PM\nstatic void xhci_save_registers(struct xhci_hcd *xhci)\n{\n\tstruct xhci_interrupter *ir = xhci->interrupter;\n\n\txhci->s3.command = readl(&xhci->op_regs->command);\n\txhci->s3.dev_nt = readl(&xhci->op_regs->dev_notification);\n\txhci->s3.dcbaa_ptr = xhci_read_64(xhci, &xhci->op_regs->dcbaa_ptr);\n\txhci->s3.config_reg = readl(&xhci->op_regs->config_reg);\n\n\tif (!ir)\n\t\treturn;\n\n\tir->s3_erst_size = readl(&ir->ir_set->erst_size);\n\tir->s3_erst_base = xhci_read_64(xhci, &ir->ir_set->erst_base);\n\tir->s3_erst_dequeue = xhci_read_64(xhci, &ir->ir_set->erst_dequeue);\n\tir->s3_irq_pending = readl(&ir->ir_set->irq_pending);\n\tir->s3_irq_control = readl(&ir->ir_set->irq_control);\n}\n\nstatic void xhci_restore_registers(struct xhci_hcd *xhci)\n{\n\tstruct xhci_interrupter *ir = xhci->interrupter;\n\n\twritel(xhci->s3.command, &xhci->op_regs->command);\n\twritel(xhci->s3.dev_nt, &xhci->op_regs->dev_notification);\n\txhci_write_64(xhci, xhci->s3.dcbaa_ptr, &xhci->op_regs->dcbaa_ptr);\n\twritel(xhci->s3.config_reg, &xhci->op_regs->config_reg);\n\twritel(ir->s3_erst_size, &ir->ir_set->erst_size);\n\txhci_write_64(xhci, ir->s3_erst_base, &ir->ir_set->erst_base);\n\txhci_write_64(xhci, ir->s3_erst_dequeue, &ir->ir_set->erst_dequeue);\n\twritel(ir->s3_irq_pending, &ir->ir_set->irq_pending);\n\twritel(ir->s3_irq_control, &ir->ir_set->irq_control);\n}\n\nstatic void xhci_set_cmd_ring_deq(struct xhci_hcd *xhci)\n{\n\tu64\tval_64;\n\n\t \n\tval_64 = xhci_read_64(xhci, &xhci->op_regs->cmd_ring);\n\tval_64 = (val_64 & (u64) CMD_RING_RSVD_BITS) |\n\t\t(xhci_trb_virt_to_dma(xhci->cmd_ring->deq_seg,\n\t\t\t\t      xhci->cmd_ring->dequeue) &\n\t\t (u64) ~CMD_RING_RSVD_BITS) |\n\t\txhci->cmd_ring->cycle_state;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"// Setting command ring address to 0x%llx\",\n\t\t\t(long unsigned long) val_64);\n\txhci_write_64(xhci, val_64, &xhci->op_regs->cmd_ring);\n}\n\n \nstatic void xhci_clear_command_ring(struct xhci_hcd *xhci)\n{\n\tstruct xhci_ring *ring;\n\tstruct xhci_segment *seg;\n\n\tring = xhci->cmd_ring;\n\tseg = ring->deq_seg;\n\tdo {\n\t\tmemset(seg->trbs, 0,\n\t\t\tsizeof(union xhci_trb) * (TRBS_PER_SEGMENT - 1));\n\t\tseg->trbs[TRBS_PER_SEGMENT - 1].link.control &=\n\t\t\tcpu_to_le32(~TRB_CYCLE);\n\t\tseg = seg->next;\n\t} while (seg != ring->deq_seg);\n\n\t \n\tring->deq_seg = ring->first_seg;\n\tring->dequeue = ring->first_seg->trbs;\n\tring->enq_seg = ring->deq_seg;\n\tring->enqueue = ring->dequeue;\n\n\tring->num_trbs_free = ring->num_segs * (TRBS_PER_SEGMENT - 1) - 1;\n\t \n\tring->cycle_state = 1;\n\n\t \n\txhci_set_cmd_ring_deq(xhci);\n}\n\n \n\nstatic void xhci_disable_hub_port_wake(struct xhci_hcd *xhci,\n\t\t\t\t       struct xhci_hub *rhub,\n\t\t\t\t       bool do_wakeup)\n{\n\tunsigned long flags;\n\tu32 t1, t2, portsc;\n\tint i;\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\tfor (i = 0; i < rhub->num_ports; i++) {\n\t\tportsc = readl(rhub->ports[i]->addr);\n\t\tt1 = xhci_port_state_to_neutral(portsc);\n\t\tt2 = t1;\n\n\t\t \n\t\tif (!do_wakeup)\n\t\t\tt2 &= ~PORT_WAKE_BITS;\n\n\t\t \n\t\tif (!(portsc & (PORT_CSC | PORT_CONNECT)))\n\t\t\tt2 |= PORT_CSC;\n\n\t\tif (t1 != t2) {\n\t\t\twritel(t2, rhub->ports[i]->addr);\n\t\t\txhci_dbg(xhci, \"config port %d-%d wake bits, portsc: 0x%x, write: 0x%x\\n\",\n\t\t\t\t rhub->hcd->self.busnum, i + 1, portsc, t2);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n}\n\nstatic bool xhci_pending_portevent(struct xhci_hcd *xhci)\n{\n\tstruct xhci_port\t**ports;\n\tint\t\t\tport_index;\n\tu32\t\t\tstatus;\n\tu32\t\t\tportsc;\n\n\tstatus = readl(&xhci->op_regs->status);\n\tif (status & STS_EINT)\n\t\treturn true;\n\t \n\n\tport_index = xhci->usb2_rhub.num_ports;\n\tports = xhci->usb2_rhub.ports;\n\twhile (port_index--) {\n\t\tportsc = readl(ports[port_index]->addr);\n\t\tif (portsc & PORT_CHANGE_MASK ||\n\t\t    (portsc & PORT_PLS_MASK) == XDEV_RESUME)\n\t\t\treturn true;\n\t}\n\tport_index = xhci->usb3_rhub.num_ports;\n\tports = xhci->usb3_rhub.ports;\n\twhile (port_index--) {\n\t\tportsc = readl(ports[port_index]->addr);\n\t\tif (portsc & (PORT_CHANGE_MASK | PORT_CAS) ||\n\t\t    (portsc & PORT_PLS_MASK) == XDEV_RESUME)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nint xhci_suspend(struct xhci_hcd *xhci, bool do_wakeup)\n{\n\tint\t\t\trc = 0;\n\tunsigned int\t\tdelay = XHCI_MAX_HALT_USEC * 2;\n\tstruct usb_hcd\t\t*hcd = xhci_to_hcd(xhci);\n\tu32\t\t\tcommand;\n\tu32\t\t\tres;\n\n\tif (!hcd->state)\n\t\treturn 0;\n\n\tif (hcd->state != HC_STATE_SUSPENDED ||\n\t    (xhci->shared_hcd && xhci->shared_hcd->state != HC_STATE_SUSPENDED))\n\t\treturn -EINVAL;\n\n\t \n\txhci_disable_hub_port_wake(xhci, &xhci->usb3_rhub, do_wakeup);\n\txhci_disable_hub_port_wake(xhci, &xhci->usb2_rhub, do_wakeup);\n\n\tif (!HCD_HW_ACCESSIBLE(hcd))\n\t\treturn 0;\n\n\txhci_dbc_suspend(xhci);\n\n\t \n\txhci_dbg(xhci, \"%s: stopping usb%d port polling.\\n\",\n\t\t __func__, hcd->self.busnum);\n\tclear_bit(HCD_FLAG_POLL_RH, &hcd->flags);\n\tdel_timer_sync(&hcd->rh_timer);\n\tif (xhci->shared_hcd) {\n\t\tclear_bit(HCD_FLAG_POLL_RH, &xhci->shared_hcd->flags);\n\t\tdel_timer_sync(&xhci->shared_hcd->rh_timer);\n\t}\n\n\tif (xhci->quirks & XHCI_SUSPEND_DELAY)\n\t\tusleep_range(1000, 1500);\n\n\tspin_lock_irq(&xhci->lock);\n\tclear_bit(HCD_FLAG_HW_ACCESSIBLE, &hcd->flags);\n\tif (xhci->shared_hcd)\n\t\tclear_bit(HCD_FLAG_HW_ACCESSIBLE, &xhci->shared_hcd->flags);\n\t \n\t \n\n\t \n\tcommand = readl(&xhci->op_regs->command);\n\tcommand &= ~CMD_RUN;\n\twritel(command, &xhci->op_regs->command);\n\n\t \n\tdelay *= (xhci->quirks & XHCI_SLOW_SUSPEND) ? 10 : 1;\n\n\tif (xhci_handshake(&xhci->op_regs->status,\n\t\t      STS_HALT, STS_HALT, delay)) {\n\t\txhci_warn(xhci, \"WARN: xHC CMD_RUN timeout\\n\");\n\t\tspin_unlock_irq(&xhci->lock);\n\t\treturn -ETIMEDOUT;\n\t}\n\txhci_clear_command_ring(xhci);\n\n\t \n\txhci_save_registers(xhci);\n\n\t \n\tcommand = readl(&xhci->op_regs->command);\n\tcommand |= CMD_CSS;\n\twritel(command, &xhci->op_regs->command);\n\txhci->broken_suspend = 0;\n\tif (xhci_handshake(&xhci->op_regs->status,\n\t\t\t\tSTS_SAVE, 0, 20 * 1000)) {\n\t \n\t\tres = readl(&xhci->op_regs->status);\n\t\tif ((xhci->quirks & XHCI_SNPS_BROKEN_SUSPEND) &&\n\t\t    (((res & STS_SRE) == 0) &&\n\t\t\t\t((res & STS_HCE) == 0))) {\n\t\t\txhci->broken_suspend = 1;\n\t\t} else {\n\t\t\txhci_warn(xhci, \"WARN: xHC save state timeout\\n\");\n\t\t\tspin_unlock_irq(&xhci->lock);\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\t}\n\tspin_unlock_irq(&xhci->lock);\n\n\t \n\tif ((xhci->quirks & XHCI_COMP_MODE_QUIRK) &&\n\t\t\t(!(xhci_all_ports_seen_u0(xhci)))) {\n\t\tdel_timer_sync(&xhci->comp_mode_recovery_timer);\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"%s: compliance mode recovery timer deleted\",\n\t\t\t\t__func__);\n\t}\n\n\treturn rc;\n}\nEXPORT_SYMBOL_GPL(xhci_suspend);\n\n \nint xhci_resume(struct xhci_hcd *xhci, pm_message_t msg)\n{\n\tbool\t\t\thibernated = (msg.event == PM_EVENT_RESTORE);\n\tu32\t\t\tcommand, temp = 0;\n\tstruct usb_hcd\t\t*hcd = xhci_to_hcd(xhci);\n\tint\t\t\tretval = 0;\n\tbool\t\t\tcomp_timer_running = false;\n\tbool\t\t\tpending_portevent = false;\n\tbool\t\t\tsuspended_usb3_devs = false;\n\tbool\t\t\treinit_xhc = false;\n\n\tif (!hcd->state)\n\t\treturn 0;\n\n\t \n\n\tif (time_before(jiffies, xhci->usb2_rhub.bus_state.next_statechange) ||\n\t    time_before(jiffies, xhci->usb3_rhub.bus_state.next_statechange))\n\t\tmsleep(100);\n\n\tset_bit(HCD_FLAG_HW_ACCESSIBLE, &hcd->flags);\n\tif (xhci->shared_hcd)\n\t\tset_bit(HCD_FLAG_HW_ACCESSIBLE, &xhci->shared_hcd->flags);\n\n\tspin_lock_irq(&xhci->lock);\n\n\tif (hibernated || xhci->quirks & XHCI_RESET_ON_RESUME || xhci->broken_suspend)\n\t\treinit_xhc = true;\n\n\tif (!reinit_xhc) {\n\t\t \n\t\tretval = xhci_handshake(&xhci->op_regs->status,\n\t\t\t\t\tSTS_CNR, 0, 10 * 1000 * 1000);\n\t\tif (retval) {\n\t\t\txhci_warn(xhci, \"Controller not ready at resume %d\\n\",\n\t\t\t\t  retval);\n\t\t\tspin_unlock_irq(&xhci->lock);\n\t\t\treturn retval;\n\t\t}\n\t\t \n\t\txhci_restore_registers(xhci);\n\t\t \n\t\txhci_set_cmd_ring_deq(xhci);\n\t\t \n\t\t \n\t\tcommand = readl(&xhci->op_regs->command);\n\t\tcommand |= CMD_CRS;\n\t\twritel(command, &xhci->op_regs->command);\n\t\t \n\t\tif (xhci_handshake(&xhci->op_regs->status,\n\t\t\t      STS_RESTORE, 0, 100 * 1000)) {\n\t\t\txhci_warn(xhci, \"WARN: xHC restore state timeout\\n\");\n\t\t\tspin_unlock_irq(&xhci->lock);\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\t}\n\n\ttemp = readl(&xhci->op_regs->status);\n\n\t \n\tif ((temp & (STS_SRE | STS_HCE)) &&\n\t    !(xhci->xhc_state & XHCI_STATE_REMOVING)) {\n\t\treinit_xhc = true;\n\t\tif (!xhci->broken_suspend)\n\t\t\txhci_warn(xhci, \"xHC error in resume, USBSTS 0x%x, Reinit\\n\", temp);\n\t}\n\n\tif (reinit_xhc) {\n\t\tif ((xhci->quirks & XHCI_COMP_MODE_QUIRK) &&\n\t\t\t\t!(xhci_all_ports_seen_u0(xhci))) {\n\t\t\tdel_timer_sync(&xhci->comp_mode_recovery_timer);\n\t\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"Compliance Mode Recovery Timer deleted!\");\n\t\t}\n\n\t\t \n\t\tusb_root_hub_lost_power(xhci->main_hcd->self.root_hub);\n\t\tif (xhci->shared_hcd)\n\t\t\tusb_root_hub_lost_power(xhci->shared_hcd->self.root_hub);\n\n\t\txhci_dbg(xhci, \"Stop HCD\\n\");\n\t\txhci_halt(xhci);\n\t\txhci_zero_64b_regs(xhci);\n\t\tretval = xhci_reset(xhci, XHCI_RESET_LONG_USEC);\n\t\tspin_unlock_irq(&xhci->lock);\n\t\tif (retval)\n\t\t\treturn retval;\n\n\t\txhci_dbg(xhci, \"// Disabling event ring interrupts\\n\");\n\t\ttemp = readl(&xhci->op_regs->status);\n\t\twritel((temp & ~0x1fff) | STS_EINT, &xhci->op_regs->status);\n\t\txhci_disable_interrupter(xhci->interrupter);\n\n\t\txhci_dbg(xhci, \"cleaning up memory\\n\");\n\t\txhci_mem_cleanup(xhci);\n\t\txhci_debugfs_exit(xhci);\n\t\txhci_dbg(xhci, \"xhci_stop completed - status = %x\\n\",\n\t\t\t    readl(&xhci->op_regs->status));\n\n\t\t \n\t\txhci_dbg(xhci, \"Initialize the xhci_hcd\\n\");\n\t\tretval = xhci_init(hcd);\n\t\tif (retval)\n\t\t\treturn retval;\n\t\tcomp_timer_running = true;\n\n\t\txhci_dbg(xhci, \"Start the primary HCD\\n\");\n\t\tretval = xhci_run(hcd);\n\t\tif (!retval && xhci->shared_hcd) {\n\t\t\txhci_dbg(xhci, \"Start the secondary HCD\\n\");\n\t\t\tretval = xhci_run(xhci->shared_hcd);\n\t\t}\n\n\t\thcd->state = HC_STATE_SUSPENDED;\n\t\tif (xhci->shared_hcd)\n\t\t\txhci->shared_hcd->state = HC_STATE_SUSPENDED;\n\t\tgoto done;\n\t}\n\n\t \n\tcommand = readl(&xhci->op_regs->command);\n\tcommand |= CMD_RUN;\n\twritel(command, &xhci->op_regs->command);\n\txhci_handshake(&xhci->op_regs->status, STS_HALT,\n\t\t  0, 250 * 1000);\n\n\t \n\t \n\n\t \n\n\tspin_unlock_irq(&xhci->lock);\n\n\txhci_dbc_resume(xhci);\n\n done:\n\tif (retval == 0) {\n\t\t \n\t\tif (xhci->usb3_rhub.bus_state.suspended_ports ||\n\t\t    xhci->usb3_rhub.bus_state.bus_suspended)\n\t\t\tsuspended_usb3_devs = true;\n\n\t\tpending_portevent = xhci_pending_portevent(xhci);\n\n\t\tif (suspended_usb3_devs && !pending_portevent &&\n\t\t    msg.event == PM_EVENT_AUTO_RESUME) {\n\t\t\tmsleep(120);\n\t\t\tpending_portevent = xhci_pending_portevent(xhci);\n\t\t}\n\n\t\tif (pending_portevent) {\n\t\t\tif (xhci->shared_hcd)\n\t\t\t\tusb_hcd_resume_root_hub(xhci->shared_hcd);\n\t\t\tusb_hcd_resume_root_hub(hcd);\n\t\t}\n\t}\n\t \n\tif ((xhci->quirks & XHCI_COMP_MODE_QUIRK) && !comp_timer_running)\n\t\tcompliance_mode_recovery_timer_init(xhci);\n\n\tif (xhci->quirks & XHCI_ASMEDIA_MODIFY_FLOWCONTROL)\n\t\tusb_asmedia_modifyflowcontrol(to_pci_dev(hcd->self.controller));\n\n\t \n\txhci_dbg(xhci, \"%s: starting usb%d port polling.\\n\",\n\t\t __func__, hcd->self.busnum);\n\tif (xhci->shared_hcd) {\n\t\tset_bit(HCD_FLAG_POLL_RH, &xhci->shared_hcd->flags);\n\t\tusb_hcd_poll_rh_status(xhci->shared_hcd);\n\t}\n\tset_bit(HCD_FLAG_POLL_RH, &hcd->flags);\n\tusb_hcd_poll_rh_status(hcd);\n\n\treturn retval;\n}\nEXPORT_SYMBOL_GPL(xhci_resume);\n#endif\t \n\n \n\nstatic int xhci_map_temp_buffer(struct usb_hcd *hcd, struct urb *urb)\n{\n\tvoid *temp;\n\tint ret = 0;\n\tunsigned int buf_len;\n\tenum dma_data_direction dir;\n\n\tdir = usb_urb_dir_in(urb) ? DMA_FROM_DEVICE : DMA_TO_DEVICE;\n\tbuf_len = urb->transfer_buffer_length;\n\n\ttemp = kzalloc_node(buf_len, GFP_ATOMIC,\n\t\t\t    dev_to_node(hcd->self.sysdev));\n\n\tif (usb_urb_dir_out(urb))\n\t\tsg_pcopy_to_buffer(urb->sg, urb->num_sgs,\n\t\t\t\t   temp, buf_len, 0);\n\n\turb->transfer_buffer = temp;\n\turb->transfer_dma = dma_map_single(hcd->self.sysdev,\n\t\t\t\t\t   urb->transfer_buffer,\n\t\t\t\t\t   urb->transfer_buffer_length,\n\t\t\t\t\t   dir);\n\n\tif (dma_mapping_error(hcd->self.sysdev,\n\t\t\t      urb->transfer_dma)) {\n\t\tret = -EAGAIN;\n\t\tkfree(temp);\n\t} else {\n\t\turb->transfer_flags |= URB_DMA_MAP_SINGLE;\n\t}\n\n\treturn ret;\n}\n\nstatic bool xhci_urb_temp_buffer_required(struct usb_hcd *hcd,\n\t\t\t\t\t  struct urb *urb)\n{\n\tbool ret = false;\n\tunsigned int i;\n\tunsigned int len = 0;\n\tunsigned int trb_size;\n\tunsigned int max_pkt;\n\tstruct scatterlist *sg;\n\tstruct scatterlist *tail_sg;\n\n\ttail_sg = urb->sg;\n\tmax_pkt = usb_endpoint_maxp(&urb->ep->desc);\n\n\tif (!urb->num_sgs)\n\t\treturn ret;\n\n\tif (urb->dev->speed >= USB_SPEED_SUPER)\n\t\ttrb_size = TRB_CACHE_SIZE_SS;\n\telse\n\t\ttrb_size = TRB_CACHE_SIZE_HS;\n\n\tif (urb->transfer_buffer_length != 0 &&\n\t    !(urb->transfer_flags & URB_NO_TRANSFER_DMA_MAP)) {\n\t\tfor_each_sg(urb->sg, sg, urb->num_sgs, i) {\n\t\t\tlen = len + sg->length;\n\t\t\tif (i > trb_size - 2) {\n\t\t\t\tlen = len - tail_sg->length;\n\t\t\t\tif (len < max_pkt) {\n\t\t\t\t\tret = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\ttail_sg = sg_next(tail_sg);\n\t\t\t}\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic void xhci_unmap_temp_buf(struct usb_hcd *hcd, struct urb *urb)\n{\n\tunsigned int len;\n\tunsigned int buf_len;\n\tenum dma_data_direction dir;\n\n\tdir = usb_urb_dir_in(urb) ? DMA_FROM_DEVICE : DMA_TO_DEVICE;\n\n\tbuf_len = urb->transfer_buffer_length;\n\n\tif (IS_ENABLED(CONFIG_HAS_DMA) &&\n\t    (urb->transfer_flags & URB_DMA_MAP_SINGLE))\n\t\tdma_unmap_single(hcd->self.sysdev,\n\t\t\t\t urb->transfer_dma,\n\t\t\t\t urb->transfer_buffer_length,\n\t\t\t\t dir);\n\n\tif (usb_urb_dir_in(urb)) {\n\t\tlen = sg_pcopy_from_buffer(urb->sg, urb->num_sgs,\n\t\t\t\t\t   urb->transfer_buffer,\n\t\t\t\t\t   buf_len,\n\t\t\t\t\t   0);\n\t\tif (len != buf_len) {\n\t\t\txhci_dbg(hcd_to_xhci(hcd),\n\t\t\t\t \"Copy from tmp buf to urb sg list failed\\n\");\n\t\t\turb->actual_length = len;\n\t\t}\n\t}\n\turb->transfer_flags &= ~URB_DMA_MAP_SINGLE;\n\tkfree(urb->transfer_buffer);\n\turb->transfer_buffer = NULL;\n}\n\n \nstatic int xhci_map_urb_for_dma(struct usb_hcd *hcd, struct urb *urb,\n\t\t\t\tgfp_t mem_flags)\n{\n\tstruct xhci_hcd *xhci;\n\n\txhci = hcd_to_xhci(hcd);\n\n\tif (xhci_urb_suitable_for_idt(urb))\n\t\treturn 0;\n\n\tif (xhci->quirks & XHCI_SG_TRB_CACHE_SIZE_QUIRK) {\n\t\tif (xhci_urb_temp_buffer_required(hcd, urb))\n\t\t\treturn xhci_map_temp_buffer(hcd, urb);\n\t}\n\treturn usb_hcd_map_urb_for_dma(hcd, urb, mem_flags);\n}\n\nstatic void xhci_unmap_urb_for_dma(struct usb_hcd *hcd, struct urb *urb)\n{\n\tstruct xhci_hcd *xhci;\n\tbool unmap_temp_buf = false;\n\n\txhci = hcd_to_xhci(hcd);\n\n\tif (urb->num_sgs && (urb->transfer_flags & URB_DMA_MAP_SINGLE))\n\t\tunmap_temp_buf = true;\n\n\tif ((xhci->quirks & XHCI_SG_TRB_CACHE_SIZE_QUIRK) && unmap_temp_buf)\n\t\txhci_unmap_temp_buf(hcd, urb);\n\telse\n\t\tusb_hcd_unmap_urb_for_dma(hcd, urb);\n}\n\n \nunsigned int xhci_get_endpoint_index(struct usb_endpoint_descriptor *desc)\n{\n\tunsigned int index;\n\tif (usb_endpoint_xfer_control(desc))\n\t\tindex = (unsigned int) (usb_endpoint_num(desc)*2);\n\telse\n\t\tindex = (unsigned int) (usb_endpoint_num(desc)*2) +\n\t\t\t(usb_endpoint_dir_in(desc) ? 1 : 0) - 1;\n\treturn index;\n}\nEXPORT_SYMBOL_GPL(xhci_get_endpoint_index);\n\n \nstatic unsigned int xhci_get_endpoint_address(unsigned int ep_index)\n{\n\tunsigned int number = DIV_ROUND_UP(ep_index, 2);\n\tunsigned int direction = ep_index % 2 ? USB_DIR_OUT : USB_DIR_IN;\n\treturn direction | number;\n}\n\n \nstatic unsigned int xhci_get_endpoint_flag(struct usb_endpoint_descriptor *desc)\n{\n\treturn 1 << (xhci_get_endpoint_index(desc) + 1);\n}\n\n \nunsigned int xhci_last_valid_endpoint(u32 added_ctxs)\n{\n\treturn fls(added_ctxs) - 1;\n}\n\n \nstatic int xhci_check_args(struct usb_hcd *hcd, struct usb_device *udev,\n\t\tstruct usb_host_endpoint *ep, int check_ep, bool check_virt_dev,\n\t\tconst char *func) {\n\tstruct xhci_hcd\t*xhci;\n\tstruct xhci_virt_device\t*virt_dev;\n\n\tif (!hcd || (check_ep && !ep) || !udev) {\n\t\tpr_debug(\"xHCI %s called with invalid args\\n\", func);\n\t\treturn -EINVAL;\n\t}\n\tif (!udev->parent) {\n\t\tpr_debug(\"xHCI %s called for root hub\\n\", func);\n\t\treturn 0;\n\t}\n\n\txhci = hcd_to_xhci(hcd);\n\tif (check_virt_dev) {\n\t\tif (!udev->slot_id || !xhci->devs[udev->slot_id]) {\n\t\t\txhci_dbg(xhci, \"xHCI %s called with unaddressed device\\n\",\n\t\t\t\t\tfunc);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tvirt_dev = xhci->devs[udev->slot_id];\n\t\tif (virt_dev->udev != udev) {\n\t\t\txhci_dbg(xhci, \"xHCI %s called with udev and \"\n\t\t\t\t\t  \"virt_dev does not match\\n\", func);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (xhci->xhc_state & XHCI_STATE_HALTED)\n\t\treturn -ENODEV;\n\n\treturn 1;\n}\n\nstatic int xhci_configure_endpoint(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev, struct xhci_command *command,\n\t\tbool ctx_change, bool must_succeed);\n\n \nstatic int xhci_check_maxpacket(struct xhci_hcd *xhci, unsigned int slot_id,\n\t\tunsigned int ep_index, struct urb *urb, gfp_t mem_flags)\n{\n\tstruct xhci_container_ctx *out_ctx;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tstruct xhci_ep_ctx *ep_ctx;\n\tstruct xhci_command *command;\n\tint max_packet_size;\n\tint hw_max_packet_size;\n\tint ret = 0;\n\n\tout_ctx = xhci->devs[slot_id]->out_ctx;\n\tep_ctx = xhci_get_ep_ctx(xhci, out_ctx, ep_index);\n\thw_max_packet_size = MAX_PACKET_DECODED(le32_to_cpu(ep_ctx->ep_info2));\n\tmax_packet_size = usb_endpoint_maxp(&urb->dev->ep0.desc);\n\tif (hw_max_packet_size != max_packet_size) {\n\t\txhci_dbg_trace(xhci,  trace_xhci_dbg_context_change,\n\t\t\t\t\"Max Packet Size for ep 0 changed.\");\n\t\txhci_dbg_trace(xhci,  trace_xhci_dbg_context_change,\n\t\t\t\t\"Max packet size in usb_device = %d\",\n\t\t\t\tmax_packet_size);\n\t\txhci_dbg_trace(xhci,  trace_xhci_dbg_context_change,\n\t\t\t\t\"Max packet size in xHCI HW = %d\",\n\t\t\t\thw_max_packet_size);\n\t\txhci_dbg_trace(xhci,  trace_xhci_dbg_context_change,\n\t\t\t\t\"Issuing evaluate context command.\");\n\n\t\t \n\t\t \n\n\t\tcommand = xhci_alloc_command(xhci, true, mem_flags);\n\t\tif (!command)\n\t\t\treturn -ENOMEM;\n\n\t\tcommand->in_ctx = xhci->devs[slot_id]->in_ctx;\n\t\tctrl_ctx = xhci_get_input_control_ctx(command->in_ctx);\n\t\tif (!ctrl_ctx) {\n\t\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t\t__func__);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto command_cleanup;\n\t\t}\n\t\t \n\t\txhci_endpoint_copy(xhci, xhci->devs[slot_id]->in_ctx,\n\t\t\t\txhci->devs[slot_id]->out_ctx, ep_index);\n\n\t\tep_ctx = xhci_get_ep_ctx(xhci, command->in_ctx, ep_index);\n\t\tep_ctx->ep_info &= cpu_to_le32(~EP_STATE_MASK); \n\t\tep_ctx->ep_info2 &= cpu_to_le32(~MAX_PACKET_MASK);\n\t\tep_ctx->ep_info2 |= cpu_to_le32(MAX_PACKET(max_packet_size));\n\n\t\tctrl_ctx->add_flags = cpu_to_le32(EP0_FLAG);\n\t\tctrl_ctx->drop_flags = 0;\n\n\t\tret = xhci_configure_endpoint(xhci, urb->dev, command,\n\t\t\t\ttrue, false);\n\n\t\t \n\t\tctrl_ctx->add_flags = cpu_to_le32(SLOT_FLAG);\ncommand_cleanup:\n\t\tkfree(command->completion);\n\t\tkfree(command);\n\t}\n\treturn ret;\n}\n\n \nstatic int xhci_urb_enqueue(struct usb_hcd *hcd, struct urb *urb, gfp_t mem_flags)\n{\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\tunsigned long flags;\n\tint ret = 0;\n\tunsigned int slot_id, ep_index;\n\tunsigned int *ep_state;\n\tstruct urb_priv\t*urb_priv;\n\tint num_tds;\n\n\tif (!urb)\n\t\treturn -EINVAL;\n\tret = xhci_check_args(hcd, urb->dev, urb->ep,\n\t\t\t\t\ttrue, true, __func__);\n\tif (ret <= 0)\n\t\treturn ret ? ret : -EINVAL;\n\n\tslot_id = urb->dev->slot_id;\n\tep_index = xhci_get_endpoint_index(&urb->ep->desc);\n\tep_state = &xhci->devs[slot_id]->eps[ep_index].ep_state;\n\n\tif (!HCD_HW_ACCESSIBLE(hcd))\n\t\treturn -ESHUTDOWN;\n\n\tif (xhci->devs[slot_id]->flags & VDEV_PORT_ERROR) {\n\t\txhci_dbg(xhci, \"Can't queue urb, port error, link inactive\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (usb_endpoint_xfer_isoc(&urb->ep->desc))\n\t\tnum_tds = urb->number_of_packets;\n\telse if (usb_endpoint_is_bulk_out(&urb->ep->desc) &&\n\t    urb->transfer_buffer_length > 0 &&\n\t    urb->transfer_flags & URB_ZERO_PACKET &&\n\t    !(urb->transfer_buffer_length % usb_endpoint_maxp(&urb->ep->desc)))\n\t\tnum_tds = 2;\n\telse\n\t\tnum_tds = 1;\n\n\turb_priv = kzalloc(struct_size(urb_priv, td, num_tds), mem_flags);\n\tif (!urb_priv)\n\t\treturn -ENOMEM;\n\n\turb_priv->num_tds = num_tds;\n\turb_priv->num_tds_done = 0;\n\turb->hcpriv = urb_priv;\n\n\ttrace_xhci_urb_enqueue(urb);\n\n\tif (usb_endpoint_xfer_control(&urb->ep->desc)) {\n\t\t \n\t\tif (urb->dev->speed == USB_SPEED_FULL) {\n\t\t\tret = xhci_check_maxpacket(xhci, slot_id,\n\t\t\t\t\tep_index, urb, mem_flags);\n\t\t\tif (ret < 0) {\n\t\t\t\txhci_urb_free_priv(urb_priv);\n\t\t\t\turb->hcpriv = NULL;\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\tif (xhci->xhc_state & XHCI_STATE_DYING) {\n\t\txhci_dbg(xhci, \"Ep 0x%x: URB %p submitted for non-responsive xHCI host.\\n\",\n\t\t\t urb->ep->desc.bEndpointAddress, urb);\n\t\tret = -ESHUTDOWN;\n\t\tgoto free_priv;\n\t}\n\tif (*ep_state & (EP_GETTING_STREAMS | EP_GETTING_NO_STREAMS)) {\n\t\txhci_warn(xhci, \"WARN: Can't enqueue URB, ep in streams transition state %x\\n\",\n\t\t\t  *ep_state);\n\t\tret = -EINVAL;\n\t\tgoto free_priv;\n\t}\n\tif (*ep_state & EP_SOFT_CLEAR_TOGGLE) {\n\t\txhci_warn(xhci, \"Can't enqueue URB while manually clearing toggle\\n\");\n\t\tret = -EINVAL;\n\t\tgoto free_priv;\n\t}\n\n\tswitch (usb_endpoint_type(&urb->ep->desc)) {\n\n\tcase USB_ENDPOINT_XFER_CONTROL:\n\t\tret = xhci_queue_ctrl_tx(xhci, GFP_ATOMIC, urb,\n\t\t\t\t\t slot_id, ep_index);\n\t\tbreak;\n\tcase USB_ENDPOINT_XFER_BULK:\n\t\tret = xhci_queue_bulk_tx(xhci, GFP_ATOMIC, urb,\n\t\t\t\t\t slot_id, ep_index);\n\t\tbreak;\n\tcase USB_ENDPOINT_XFER_INT:\n\t\tret = xhci_queue_intr_tx(xhci, GFP_ATOMIC, urb,\n\t\t\t\tslot_id, ep_index);\n\t\tbreak;\n\tcase USB_ENDPOINT_XFER_ISOC:\n\t\tret = xhci_queue_isoc_tx_prepare(xhci, GFP_ATOMIC, urb,\n\t\t\t\tslot_id, ep_index);\n\t}\n\n\tif (ret) {\nfree_priv:\n\t\txhci_urb_free_priv(urb_priv);\n\t\turb->hcpriv = NULL;\n\t}\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\treturn ret;\n}\n\n \nstatic int xhci_urb_dequeue(struct usb_hcd *hcd, struct urb *urb, int status)\n{\n\tunsigned long flags;\n\tint ret, i;\n\tu32 temp;\n\tstruct xhci_hcd *xhci;\n\tstruct urb_priv\t*urb_priv;\n\tstruct xhci_td *td;\n\tunsigned int ep_index;\n\tstruct xhci_ring *ep_ring;\n\tstruct xhci_virt_ep *ep;\n\tstruct xhci_command *command;\n\tstruct xhci_virt_device *vdev;\n\n\txhci = hcd_to_xhci(hcd);\n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\ttrace_xhci_urb_dequeue(urb);\n\n\t \n\tret = usb_hcd_check_unlink_urb(hcd, urb, status);\n\tif (ret)\n\t\tgoto done;\n\n\t \n\tvdev = xhci->devs[urb->dev->slot_id];\n\turb_priv = urb->hcpriv;\n\tif (!vdev || !urb_priv)\n\t\tgoto err_giveback;\n\n\tep_index = xhci_get_endpoint_index(&urb->ep->desc);\n\tep = &vdev->eps[ep_index];\n\tep_ring = xhci_urb_to_transfer_ring(xhci, urb);\n\tif (!ep || !ep_ring)\n\t\tgoto err_giveback;\n\n\t \n\ttemp = readl(&xhci->op_regs->status);\n\tif (temp == ~(u32)0 || xhci->xhc_state & XHCI_STATE_DYING) {\n\t\txhci_hc_died(xhci);\n\t\tgoto done;\n\t}\n\n\t \n\tif (!td_on_ring(&urb_priv->td[0], ep_ring)) {\n\t\txhci_err(xhci, \"Canceled URB td not found on endpoint ring\");\n\t\tfor (i = urb_priv->num_tds_done; i < urb_priv->num_tds; i++) {\n\t\t\ttd = &urb_priv->td[i];\n\t\t\tif (!list_empty(&td->cancelled_td_list))\n\t\t\t\tlist_del_init(&td->cancelled_td_list);\n\t\t}\n\t\tgoto err_giveback;\n\t}\n\n\tif (xhci->xhc_state & XHCI_STATE_HALTED) {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_cancel_urb,\n\t\t\t\t\"HC halted, freeing TD manually.\");\n\t\tfor (i = urb_priv->num_tds_done;\n\t\t     i < urb_priv->num_tds;\n\t\t     i++) {\n\t\t\ttd = &urb_priv->td[i];\n\t\t\tif (!list_empty(&td->td_list))\n\t\t\t\tlist_del_init(&td->td_list);\n\t\t\tif (!list_empty(&td->cancelled_td_list))\n\t\t\t\tlist_del_init(&td->cancelled_td_list);\n\t\t}\n\t\tgoto err_giveback;\n\t}\n\n\ti = urb_priv->num_tds_done;\n\tif (i < urb_priv->num_tds)\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_cancel_urb,\n\t\t\t\t\"Cancel URB %p, dev %s, ep 0x%x, \"\n\t\t\t\t\"starting at offset 0x%llx\",\n\t\t\t\turb, urb->dev->devpath,\n\t\t\t\turb->ep->desc.bEndpointAddress,\n\t\t\t\t(unsigned long long) xhci_trb_virt_to_dma(\n\t\t\t\t\turb_priv->td[i].start_seg,\n\t\t\t\t\turb_priv->td[i].first_trb));\n\n\tfor (; i < urb_priv->num_tds; i++) {\n\t\ttd = &urb_priv->td[i];\n\t\t \n\t\tif (list_empty(&td->cancelled_td_list)) {\n\t\t\ttd->cancel_status = TD_DIRTY;\n\t\t\tlist_add_tail(&td->cancelled_td_list,\n\t\t\t\t      &ep->cancelled_td_list);\n\t\t}\n\t}\n\n\t \n\tif (!(ep->ep_state & EP_STOP_CMD_PENDING)) {\n\t\tcommand = xhci_alloc_command(xhci, false, GFP_ATOMIC);\n\t\tif (!command) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto done;\n\t\t}\n\t\tep->ep_state |= EP_STOP_CMD_PENDING;\n\t\txhci_queue_stop_endpoint(xhci, command, urb->dev->slot_id,\n\t\t\t\t\t ep_index, 0);\n\t\txhci_ring_cmd_db(xhci);\n\t}\ndone:\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\treturn ret;\n\nerr_giveback:\n\tif (urb_priv)\n\t\txhci_urb_free_priv(urb_priv);\n\tusb_hcd_unlink_urb_from_ep(hcd, urb);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\tusb_hcd_giveback_urb(hcd, urb, -ESHUTDOWN);\n\treturn ret;\n}\n\n \nint xhci_drop_endpoint(struct usb_hcd *hcd, struct usb_device *udev,\n\t\t       struct usb_host_endpoint *ep)\n{\n\tstruct xhci_hcd *xhci;\n\tstruct xhci_container_ctx *in_ctx, *out_ctx;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tunsigned int ep_index;\n\tstruct xhci_ep_ctx *ep_ctx;\n\tu32 drop_flag;\n\tu32 new_add_flags, new_drop_flags;\n\tint ret;\n\n\tret = xhci_check_args(hcd, udev, ep, 1, true, __func__);\n\tif (ret <= 0)\n\t\treturn ret;\n\txhci = hcd_to_xhci(hcd);\n\tif (xhci->xhc_state & XHCI_STATE_DYING)\n\t\treturn -ENODEV;\n\n\txhci_dbg(xhci, \"%s called for udev %p\\n\", __func__, udev);\n\tdrop_flag = xhci_get_endpoint_flag(&ep->desc);\n\tif (drop_flag == SLOT_FLAG || drop_flag == EP0_FLAG) {\n\t\txhci_dbg(xhci, \"xHCI %s - can't drop slot or ep 0 %#x\\n\",\n\t\t\t\t__func__, drop_flag);\n\t\treturn 0;\n\t}\n\n\tin_ctx = xhci->devs[udev->slot_id]->in_ctx;\n\tout_ctx = xhci->devs[udev->slot_id]->out_ctx;\n\tctrl_ctx = xhci_get_input_control_ctx(in_ctx);\n\tif (!ctrl_ctx) {\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\treturn 0;\n\t}\n\n\tep_index = xhci_get_endpoint_index(&ep->desc);\n\tep_ctx = xhci_get_ep_ctx(xhci, out_ctx, ep_index);\n\t \n\tif ((GET_EP_CTX_STATE(ep_ctx) == EP_STATE_DISABLED) ||\n\t    le32_to_cpu(ctrl_ctx->drop_flags) &\n\t    xhci_get_endpoint_flag(&ep->desc)) {\n\t\t \n\t\tif (xhci->devs[udev->slot_id]->eps[ep_index].ring != NULL)\n\t\t\txhci_warn(xhci, \"xHCI %s called with disabled ep %p\\n\",\n\t\t\t\t  __func__, ep);\n\t\treturn 0;\n\t}\n\n\tctrl_ctx->drop_flags |= cpu_to_le32(drop_flag);\n\tnew_drop_flags = le32_to_cpu(ctrl_ctx->drop_flags);\n\n\tctrl_ctx->add_flags &= cpu_to_le32(~drop_flag);\n\tnew_add_flags = le32_to_cpu(ctrl_ctx->add_flags);\n\n\txhci_debugfs_remove_endpoint(xhci, xhci->devs[udev->slot_id], ep_index);\n\n\txhci_endpoint_zero(xhci, xhci->devs[udev->slot_id], ep);\n\n\txhci_dbg(xhci, \"drop ep 0x%x, slot id %d, new drop flags = %#x, new add flags = %#x\\n\",\n\t\t\t(unsigned int) ep->desc.bEndpointAddress,\n\t\t\tudev->slot_id,\n\t\t\t(unsigned int) new_drop_flags,\n\t\t\t(unsigned int) new_add_flags);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xhci_drop_endpoint);\n\n \nint xhci_add_endpoint(struct usb_hcd *hcd, struct usb_device *udev,\n\t\t      struct usb_host_endpoint *ep)\n{\n\tstruct xhci_hcd *xhci;\n\tstruct xhci_container_ctx *in_ctx;\n\tunsigned int ep_index;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tstruct xhci_ep_ctx *ep_ctx;\n\tu32 added_ctxs;\n\tu32 new_add_flags, new_drop_flags;\n\tstruct xhci_virt_device *virt_dev;\n\tint ret = 0;\n\n\tret = xhci_check_args(hcd, udev, ep, 1, true, __func__);\n\tif (ret <= 0) {\n\t\t \n\t\tep->hcpriv = NULL;\n\t\treturn ret;\n\t}\n\txhci = hcd_to_xhci(hcd);\n\tif (xhci->xhc_state & XHCI_STATE_DYING)\n\t\treturn -ENODEV;\n\n\tadded_ctxs = xhci_get_endpoint_flag(&ep->desc);\n\tif (added_ctxs == SLOT_FLAG || added_ctxs == EP0_FLAG) {\n\t\t \n\t\txhci_dbg(xhci, \"xHCI %s - can't add slot or ep 0 %#x\\n\",\n\t\t\t\t__func__, added_ctxs);\n\t\treturn 0;\n\t}\n\n\tvirt_dev = xhci->devs[udev->slot_id];\n\tin_ctx = virt_dev->in_ctx;\n\tctrl_ctx = xhci_get_input_control_ctx(in_ctx);\n\tif (!ctrl_ctx) {\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\treturn 0;\n\t}\n\n\tep_index = xhci_get_endpoint_index(&ep->desc);\n\t \n\tif (virt_dev->eps[ep_index].ring &&\n\t\t\t!(le32_to_cpu(ctrl_ctx->drop_flags) & added_ctxs)) {\n\t\txhci_warn(xhci, \"Trying to add endpoint 0x%x \"\n\t\t\t\t\"without dropping it.\\n\",\n\t\t\t\t(unsigned int) ep->desc.bEndpointAddress);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (le32_to_cpu(ctrl_ctx->add_flags) & added_ctxs) {\n\t\txhci_warn(xhci, \"xHCI %s called with enabled ep %p\\n\",\n\t\t\t\t__func__, ep);\n\t\treturn 0;\n\t}\n\n\t \n\tif (xhci_endpoint_init(xhci, virt_dev, udev, ep, GFP_NOIO) < 0) {\n\t\tdev_dbg(&udev->dev, \"%s - could not initialize ep %#x\\n\",\n\t\t\t\t__func__, ep->desc.bEndpointAddress);\n\t\treturn -ENOMEM;\n\t}\n\n\tctrl_ctx->add_flags |= cpu_to_le32(added_ctxs);\n\tnew_add_flags = le32_to_cpu(ctrl_ctx->add_flags);\n\n\t \n\tnew_drop_flags = le32_to_cpu(ctrl_ctx->drop_flags);\n\n\t \n\tep->hcpriv = udev;\n\n\tep_ctx = xhci_get_ep_ctx(xhci, virt_dev->in_ctx, ep_index);\n\ttrace_xhci_add_endpoint(ep_ctx);\n\n\txhci_dbg(xhci, \"add ep 0x%x, slot id %d, new drop flags = %#x, new add flags = %#x\\n\",\n\t\t\t(unsigned int) ep->desc.bEndpointAddress,\n\t\t\tudev->slot_id,\n\t\t\t(unsigned int) new_drop_flags,\n\t\t\t(unsigned int) new_add_flags);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xhci_add_endpoint);\n\nstatic void xhci_zero_in_ctx(struct xhci_hcd *xhci, struct xhci_virt_device *virt_dev)\n{\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tstruct xhci_ep_ctx *ep_ctx;\n\tstruct xhci_slot_ctx *slot_ctx;\n\tint i;\n\n\tctrl_ctx = xhci_get_input_control_ctx(virt_dev->in_ctx);\n\tif (!ctrl_ctx) {\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\treturn;\n\t}\n\n\t \n\tctrl_ctx->drop_flags = 0;\n\tctrl_ctx->add_flags = 0;\n\tslot_ctx = xhci_get_slot_ctx(xhci, virt_dev->in_ctx);\n\tslot_ctx->dev_info &= cpu_to_le32(~LAST_CTX_MASK);\n\t \n\tslot_ctx->dev_info |= cpu_to_le32(LAST_CTX(1));\n\tfor (i = 1; i < 31; i++) {\n\t\tep_ctx = xhci_get_ep_ctx(xhci, virt_dev->in_ctx, i);\n\t\tep_ctx->ep_info = 0;\n\t\tep_ctx->ep_info2 = 0;\n\t\tep_ctx->deq = 0;\n\t\tep_ctx->tx_info = 0;\n\t}\n}\n\nstatic int xhci_configure_endpoint_result(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev, u32 *cmd_status)\n{\n\tint ret;\n\n\tswitch (*cmd_status) {\n\tcase COMP_COMMAND_ABORTED:\n\tcase COMP_COMMAND_RING_STOPPED:\n\t\txhci_warn(xhci, \"Timeout while waiting for configure endpoint command\\n\");\n\t\tret = -ETIME;\n\t\tbreak;\n\tcase COMP_RESOURCE_ERROR:\n\t\tdev_warn(&udev->dev,\n\t\t\t \"Not enough host controller resources for new device state.\\n\");\n\t\tret = -ENOMEM;\n\t\t \n\t\tbreak;\n\tcase COMP_BANDWIDTH_ERROR:\n\tcase COMP_SECONDARY_BANDWIDTH_ERROR:\n\t\tdev_warn(&udev->dev,\n\t\t\t \"Not enough bandwidth for new device state.\\n\");\n\t\tret = -ENOSPC;\n\t\t \n\t\tbreak;\n\tcase COMP_TRB_ERROR:\n\t\t \n\t\tdev_warn(&udev->dev, \"ERROR: Endpoint drop flag = 0, \"\n\t\t\t\t\"add flag = 1, \"\n\t\t\t\t\"and endpoint is not disabled.\\n\");\n\t\tret = -EINVAL;\n\t\tbreak;\n\tcase COMP_INCOMPATIBLE_DEVICE_ERROR:\n\t\tdev_warn(&udev->dev,\n\t\t\t \"ERROR: Incompatible device for endpoint configure command.\\n\");\n\t\tret = -ENODEV;\n\t\tbreak;\n\tcase COMP_SUCCESS:\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_context_change,\n\t\t\t\t\"Successful Endpoint Configure command\");\n\t\tret = 0;\n\t\tbreak;\n\tdefault:\n\t\txhci_err(xhci, \"ERROR: unexpected command completion code 0x%x.\\n\",\n\t\t\t\t*cmd_status);\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\treturn ret;\n}\n\nstatic int xhci_evaluate_context_result(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev, u32 *cmd_status)\n{\n\tint ret;\n\n\tswitch (*cmd_status) {\n\tcase COMP_COMMAND_ABORTED:\n\tcase COMP_COMMAND_RING_STOPPED:\n\t\txhci_warn(xhci, \"Timeout while waiting for evaluate context command\\n\");\n\t\tret = -ETIME;\n\t\tbreak;\n\tcase COMP_PARAMETER_ERROR:\n\t\tdev_warn(&udev->dev,\n\t\t\t \"WARN: xHCI driver setup invalid evaluate context command.\\n\");\n\t\tret = -EINVAL;\n\t\tbreak;\n\tcase COMP_SLOT_NOT_ENABLED_ERROR:\n\t\tdev_warn(&udev->dev,\n\t\t\t\"WARN: slot not enabled for evaluate context command.\\n\");\n\t\tret = -EINVAL;\n\t\tbreak;\n\tcase COMP_CONTEXT_STATE_ERROR:\n\t\tdev_warn(&udev->dev,\n\t\t\t\"WARN: invalid context state for evaluate context command.\\n\");\n\t\tret = -EINVAL;\n\t\tbreak;\n\tcase COMP_INCOMPATIBLE_DEVICE_ERROR:\n\t\tdev_warn(&udev->dev,\n\t\t\t\"ERROR: Incompatible device for evaluate context command.\\n\");\n\t\tret = -ENODEV;\n\t\tbreak;\n\tcase COMP_MAX_EXIT_LATENCY_TOO_LARGE_ERROR:\n\t\t \n\t\tdev_warn(&udev->dev, \"WARN: Max Exit Latency too large\\n\");\n\t\tret = -EINVAL;\n\t\tbreak;\n\tcase COMP_SUCCESS:\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_context_change,\n\t\t\t\t\"Successful evaluate context command\");\n\t\tret = 0;\n\t\tbreak;\n\tdefault:\n\t\txhci_err(xhci, \"ERROR: unexpected command completion code 0x%x.\\n\",\n\t\t\t*cmd_status);\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\treturn ret;\n}\n\nstatic u32 xhci_count_num_new_endpoints(struct xhci_hcd *xhci,\n\t\tstruct xhci_input_control_ctx *ctrl_ctx)\n{\n\tu32 valid_add_flags;\n\tu32 valid_drop_flags;\n\n\t \n\tvalid_add_flags = le32_to_cpu(ctrl_ctx->add_flags) >> 2;\n\tvalid_drop_flags = le32_to_cpu(ctrl_ctx->drop_flags) >> 2;\n\n\t \n\treturn hweight32(valid_add_flags) -\n\t\thweight32(valid_add_flags & valid_drop_flags);\n}\n\nstatic unsigned int xhci_count_num_dropped_endpoints(struct xhci_hcd *xhci,\n\t\tstruct xhci_input_control_ctx *ctrl_ctx)\n{\n\tu32 valid_add_flags;\n\tu32 valid_drop_flags;\n\n\tvalid_add_flags = le32_to_cpu(ctrl_ctx->add_flags) >> 2;\n\tvalid_drop_flags = le32_to_cpu(ctrl_ctx->drop_flags) >> 2;\n\n\treturn hweight32(valid_drop_flags) -\n\t\thweight32(valid_add_flags & valid_drop_flags);\n}\n\n \nstatic int xhci_reserve_host_resources(struct xhci_hcd *xhci,\n\t\tstruct xhci_input_control_ctx *ctrl_ctx)\n{\n\tu32 added_eps;\n\n\tadded_eps = xhci_count_num_new_endpoints(xhci, ctrl_ctx);\n\tif (xhci->num_active_eps + added_eps > xhci->limit_active_eps) {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"Not enough ep ctxs: \"\n\t\t\t\t\"%u active, need to add %u, limit is %u.\",\n\t\t\t\txhci->num_active_eps, added_eps,\n\t\t\t\txhci->limit_active_eps);\n\t\treturn -ENOMEM;\n\t}\n\txhci->num_active_eps += added_eps;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\"Adding %u ep ctxs, %u now active.\", added_eps,\n\t\t\txhci->num_active_eps);\n\treturn 0;\n}\n\n \nstatic void xhci_free_host_resources(struct xhci_hcd *xhci,\n\t\tstruct xhci_input_control_ctx *ctrl_ctx)\n{\n\tu32 num_failed_eps;\n\n\tnum_failed_eps = xhci_count_num_new_endpoints(xhci, ctrl_ctx);\n\txhci->num_active_eps -= num_failed_eps;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\"Removing %u failed ep ctxs, %u now active.\",\n\t\t\tnum_failed_eps,\n\t\t\txhci->num_active_eps);\n}\n\n \nstatic void xhci_finish_resource_reservation(struct xhci_hcd *xhci,\n\t\tstruct xhci_input_control_ctx *ctrl_ctx)\n{\n\tu32 num_dropped_eps;\n\n\tnum_dropped_eps = xhci_count_num_dropped_endpoints(xhci, ctrl_ctx);\n\txhci->num_active_eps -= num_dropped_eps;\n\tif (num_dropped_eps)\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"Removing %u dropped ep ctxs, %u now active.\",\n\t\t\t\tnum_dropped_eps,\n\t\t\t\txhci->num_active_eps);\n}\n\nstatic unsigned int xhci_get_block_size(struct usb_device *udev)\n{\n\tswitch (udev->speed) {\n\tcase USB_SPEED_LOW:\n\tcase USB_SPEED_FULL:\n\t\treturn FS_BLOCK;\n\tcase USB_SPEED_HIGH:\n\t\treturn HS_BLOCK;\n\tcase USB_SPEED_SUPER:\n\tcase USB_SPEED_SUPER_PLUS:\n\t\treturn SS_BLOCK;\n\tcase USB_SPEED_UNKNOWN:\n\tdefault:\n\t\t \n\t\treturn 1;\n\t}\n}\n\nstatic unsigned int\nxhci_get_largest_overhead(struct xhci_interval_bw *interval_bw)\n{\n\tif (interval_bw->overhead[LS_OVERHEAD_TYPE])\n\t\treturn LS_OVERHEAD;\n\tif (interval_bw->overhead[FS_OVERHEAD_TYPE])\n\t\treturn FS_OVERHEAD;\n\treturn HS_OVERHEAD;\n}\n\n \nstatic int xhci_check_tt_bw_table(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev,\n\t\tint old_active_eps)\n{\n\tstruct xhci_interval_bw_table *bw_table;\n\tstruct xhci_tt_bw_info *tt_info;\n\n\t \n\tbw_table = &xhci->rh_bw[virt_dev->real_port - 1].bw_table;\n\ttt_info = virt_dev->tt_info;\n\t \n\tif (old_active_eps)\n\t\treturn 0;\n\tif (old_active_eps == 0 && tt_info->active_eps != 0) {\n\t\tif (bw_table->bw_used + TT_HS_OVERHEAD > HS_BW_LIMIT)\n\t\t\treturn -ENOMEM;\n\t\treturn 0;\n\t}\n\t \n\treturn 0;\n}\n\nstatic int xhci_check_ss_bw(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev)\n{\n\tunsigned int bw_reserved;\n\n\tbw_reserved = DIV_ROUND_UP(SS_BW_RESERVED*SS_BW_LIMIT_IN, 100);\n\tif (virt_dev->bw_table->ss_bw_in > (SS_BW_LIMIT_IN - bw_reserved))\n\t\treturn -ENOMEM;\n\n\tbw_reserved = DIV_ROUND_UP(SS_BW_RESERVED*SS_BW_LIMIT_OUT, 100);\n\tif (virt_dev->bw_table->ss_bw_out > (SS_BW_LIMIT_OUT - bw_reserved))\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n \nstatic int xhci_check_bw_table(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev,\n\t\tint old_active_eps)\n{\n\tunsigned int bw_reserved;\n\tunsigned int max_bandwidth;\n\tunsigned int bw_used;\n\tunsigned int block_size;\n\tstruct xhci_interval_bw_table *bw_table;\n\tunsigned int packet_size = 0;\n\tunsigned int overhead = 0;\n\tunsigned int packets_transmitted = 0;\n\tunsigned int packets_remaining = 0;\n\tunsigned int i;\n\n\tif (virt_dev->udev->speed >= USB_SPEED_SUPER)\n\t\treturn xhci_check_ss_bw(xhci, virt_dev);\n\n\tif (virt_dev->udev->speed == USB_SPEED_HIGH) {\n\t\tmax_bandwidth = HS_BW_LIMIT;\n\t\t \n\t\tbw_reserved = DIV_ROUND_UP(HS_BW_RESERVED * max_bandwidth, 100);\n\t} else {\n\t\tmax_bandwidth = FS_BW_LIMIT;\n\t\tbw_reserved = DIV_ROUND_UP(FS_BW_RESERVED * max_bandwidth, 100);\n\t}\n\n\tbw_table = virt_dev->bw_table;\n\t \n\tblock_size = xhci_get_block_size(virt_dev->udev);\n\n\t \n\tif (virt_dev->tt_info) {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"Recalculating BW for rootport %u\",\n\t\t\t\tvirt_dev->real_port);\n\t\tif (xhci_check_tt_bw_table(xhci, virt_dev, old_active_eps)) {\n\t\t\txhci_warn(xhci, \"Not enough bandwidth on HS bus for \"\n\t\t\t\t\t\"newly activated TT.\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"Recalculating BW for TT slot %u port %u\",\n\t\t\t\tvirt_dev->tt_info->slot_id,\n\t\t\t\tvirt_dev->tt_info->ttport);\n\t} else {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"Recalculating BW for rootport %u\",\n\t\t\t\tvirt_dev->real_port);\n\t}\n\n\t \n\tbw_used = DIV_ROUND_UP(bw_table->interval0_esit_payload, block_size) +\n\t\tbw_table->interval_bw[0].num_packets *\n\t\txhci_get_largest_overhead(&bw_table->interval_bw[0]);\n\n\tfor (i = 1; i < XHCI_MAX_INTERVAL; i++) {\n\t\tunsigned int bw_added;\n\t\tunsigned int largest_mps;\n\t\tunsigned int interval_overhead;\n\n\t\t \n\t\tpackets_remaining = 2 * packets_remaining +\n\t\t\tbw_table->interval_bw[i].num_packets;\n\n\t\t \n\t\tif (list_empty(&bw_table->interval_bw[i].endpoints))\n\t\t\tlargest_mps = 0;\n\t\telse {\n\t\t\tstruct xhci_virt_ep *virt_ep;\n\t\t\tstruct list_head *ep_entry;\n\n\t\t\tep_entry = bw_table->interval_bw[i].endpoints.next;\n\t\t\tvirt_ep = list_entry(ep_entry,\n\t\t\t\t\tstruct xhci_virt_ep, bw_endpoint_list);\n\t\t\t \n\t\t\tlargest_mps = DIV_ROUND_UP(\n\t\t\t\t\tvirt_ep->bw_info.max_packet_size,\n\t\t\t\t\tblock_size);\n\t\t}\n\t\tif (largest_mps > packet_size)\n\t\t\tpacket_size = largest_mps;\n\n\t\t \n\t\tinterval_overhead = xhci_get_largest_overhead(\n\t\t\t\t&bw_table->interval_bw[i]);\n\t\tif (interval_overhead > overhead)\n\t\t\toverhead = interval_overhead;\n\n\t\t \n\t\tpackets_transmitted = packets_remaining >> (i + 1);\n\n\t\t \n\t\tbw_added = packets_transmitted * (overhead + packet_size);\n\n\t\t \n\t\tpackets_remaining = packets_remaining % (1 << (i + 1));\n\n\t\t \n\t\t \n\t\tif (packets_remaining == 0) {\n\t\t\tpacket_size = 0;\n\t\t\toverhead = 0;\n\t\t} else if (packets_transmitted > 0) {\n\t\t\t \n\t\t\tpacket_size = largest_mps;\n\t\t\toverhead = interval_overhead;\n\t\t}\n\t\t \n\t\tbw_used += bw_added;\n\t\tif (bw_used > max_bandwidth) {\n\t\t\txhci_warn(xhci, \"Not enough bandwidth. \"\n\t\t\t\t\t\"Proposed: %u, Max: %u\\n\",\n\t\t\t\tbw_used, max_bandwidth);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\t \n\tif (packets_remaining > 0)\n\t\tbw_used += overhead + packet_size;\n\n\tif (!virt_dev->tt_info && virt_dev->udev->speed == USB_SPEED_HIGH) {\n\t\tunsigned int port_index = virt_dev->real_port - 1;\n\n\t\t \n\t\tbw_used += TT_HS_OVERHEAD *\n\t\t\txhci->rh_bw[port_index].num_active_tts;\n\t}\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\"Final bandwidth: %u, Limit: %u, Reserved: %u, \"\n\t\t\"Available: %u \" \"percent\",\n\t\tbw_used, max_bandwidth, bw_reserved,\n\t\t(max_bandwidth - bw_used - bw_reserved) * 100 /\n\t\tmax_bandwidth);\n\n\tbw_used += bw_reserved;\n\tif (bw_used > max_bandwidth) {\n\t\txhci_warn(xhci, \"Not enough bandwidth. Proposed: %u, Max: %u\\n\",\n\t\t\t\tbw_used, max_bandwidth);\n\t\treturn -ENOMEM;\n\t}\n\n\tbw_table->bw_used = bw_used;\n\treturn 0;\n}\n\nstatic bool xhci_is_async_ep(unsigned int ep_type)\n{\n\treturn (ep_type != ISOC_OUT_EP && ep_type != INT_OUT_EP &&\n\t\t\t\t\tep_type != ISOC_IN_EP &&\n\t\t\t\t\tep_type != INT_IN_EP);\n}\n\nstatic bool xhci_is_sync_in_ep(unsigned int ep_type)\n{\n\treturn (ep_type == ISOC_IN_EP || ep_type == INT_IN_EP);\n}\n\nstatic unsigned int xhci_get_ss_bw_consumed(struct xhci_bw_info *ep_bw)\n{\n\tunsigned int mps = DIV_ROUND_UP(ep_bw->max_packet_size, SS_BLOCK);\n\n\tif (ep_bw->ep_interval == 0)\n\t\treturn SS_OVERHEAD_BURST +\n\t\t\t(ep_bw->mult * ep_bw->num_packets *\n\t\t\t\t\t(SS_OVERHEAD + mps));\n\treturn DIV_ROUND_UP(ep_bw->mult * ep_bw->num_packets *\n\t\t\t\t(SS_OVERHEAD + mps + SS_OVERHEAD_BURST),\n\t\t\t\t1 << ep_bw->ep_interval);\n\n}\n\nstatic void xhci_drop_ep_from_interval_table(struct xhci_hcd *xhci,\n\t\tstruct xhci_bw_info *ep_bw,\n\t\tstruct xhci_interval_bw_table *bw_table,\n\t\tstruct usb_device *udev,\n\t\tstruct xhci_virt_ep *virt_ep,\n\t\tstruct xhci_tt_bw_info *tt_info)\n{\n\tstruct xhci_interval_bw\t*interval_bw;\n\tint normalized_interval;\n\n\tif (xhci_is_async_ep(ep_bw->type))\n\t\treturn;\n\n\tif (udev->speed >= USB_SPEED_SUPER) {\n\t\tif (xhci_is_sync_in_ep(ep_bw->type))\n\t\t\txhci->devs[udev->slot_id]->bw_table->ss_bw_in -=\n\t\t\t\txhci_get_ss_bw_consumed(ep_bw);\n\t\telse\n\t\t\txhci->devs[udev->slot_id]->bw_table->ss_bw_out -=\n\t\t\t\txhci_get_ss_bw_consumed(ep_bw);\n\t\treturn;\n\t}\n\n\t \n\tif (list_empty(&virt_ep->bw_endpoint_list))\n\t\treturn;\n\t \n\tif (udev->speed == USB_SPEED_HIGH)\n\t\tnormalized_interval = ep_bw->ep_interval;\n\telse\n\t\tnormalized_interval = ep_bw->ep_interval - 3;\n\n\tif (normalized_interval == 0)\n\t\tbw_table->interval0_esit_payload -= ep_bw->max_esit_payload;\n\tinterval_bw = &bw_table->interval_bw[normalized_interval];\n\tinterval_bw->num_packets -= ep_bw->num_packets;\n\tswitch (udev->speed) {\n\tcase USB_SPEED_LOW:\n\t\tinterval_bw->overhead[LS_OVERHEAD_TYPE] -= 1;\n\t\tbreak;\n\tcase USB_SPEED_FULL:\n\t\tinterval_bw->overhead[FS_OVERHEAD_TYPE] -= 1;\n\t\tbreak;\n\tcase USB_SPEED_HIGH:\n\t\tinterval_bw->overhead[HS_OVERHEAD_TYPE] -= 1;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn;\n\t}\n\tif (tt_info)\n\t\ttt_info->active_eps -= 1;\n\tlist_del_init(&virt_ep->bw_endpoint_list);\n}\n\nstatic void xhci_add_ep_to_interval_table(struct xhci_hcd *xhci,\n\t\tstruct xhci_bw_info *ep_bw,\n\t\tstruct xhci_interval_bw_table *bw_table,\n\t\tstruct usb_device *udev,\n\t\tstruct xhci_virt_ep *virt_ep,\n\t\tstruct xhci_tt_bw_info *tt_info)\n{\n\tstruct xhci_interval_bw\t*interval_bw;\n\tstruct xhci_virt_ep *smaller_ep;\n\tint normalized_interval;\n\n\tif (xhci_is_async_ep(ep_bw->type))\n\t\treturn;\n\n\tif (udev->speed == USB_SPEED_SUPER) {\n\t\tif (xhci_is_sync_in_ep(ep_bw->type))\n\t\t\txhci->devs[udev->slot_id]->bw_table->ss_bw_in +=\n\t\t\t\txhci_get_ss_bw_consumed(ep_bw);\n\t\telse\n\t\t\txhci->devs[udev->slot_id]->bw_table->ss_bw_out +=\n\t\t\t\txhci_get_ss_bw_consumed(ep_bw);\n\t\treturn;\n\t}\n\n\t \n\tif (udev->speed == USB_SPEED_HIGH)\n\t\tnormalized_interval = ep_bw->ep_interval;\n\telse\n\t\tnormalized_interval = ep_bw->ep_interval - 3;\n\n\tif (normalized_interval == 0)\n\t\tbw_table->interval0_esit_payload += ep_bw->max_esit_payload;\n\tinterval_bw = &bw_table->interval_bw[normalized_interval];\n\tinterval_bw->num_packets += ep_bw->num_packets;\n\tswitch (udev->speed) {\n\tcase USB_SPEED_LOW:\n\t\tinterval_bw->overhead[LS_OVERHEAD_TYPE] += 1;\n\t\tbreak;\n\tcase USB_SPEED_FULL:\n\t\tinterval_bw->overhead[FS_OVERHEAD_TYPE] += 1;\n\t\tbreak;\n\tcase USB_SPEED_HIGH:\n\t\tinterval_bw->overhead[HS_OVERHEAD_TYPE] += 1;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn;\n\t}\n\n\tif (tt_info)\n\t\ttt_info->active_eps += 1;\n\t \n\tlist_for_each_entry(smaller_ep, &interval_bw->endpoints,\n\t\t\tbw_endpoint_list) {\n\t\tif (ep_bw->max_packet_size >=\n\t\t\t\tsmaller_ep->bw_info.max_packet_size) {\n\t\t\t \n\t\t\tlist_add_tail(&virt_ep->bw_endpoint_list,\n\t\t\t\t\t&smaller_ep->bw_endpoint_list);\n\t\t\treturn;\n\t\t}\n\t}\n\t \n\tlist_add_tail(&virt_ep->bw_endpoint_list,\n\t\t\t&interval_bw->endpoints);\n}\n\nvoid xhci_update_tt_active_eps(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev,\n\t\tint old_active_eps)\n{\n\tstruct xhci_root_port_bw_info *rh_bw_info;\n\tif (!virt_dev->tt_info)\n\t\treturn;\n\n\trh_bw_info = &xhci->rh_bw[virt_dev->real_port - 1];\n\tif (old_active_eps == 0 &&\n\t\t\t\tvirt_dev->tt_info->active_eps != 0) {\n\t\trh_bw_info->num_active_tts += 1;\n\t\trh_bw_info->bw_table.bw_used += TT_HS_OVERHEAD;\n\t} else if (old_active_eps != 0 &&\n\t\t\t\tvirt_dev->tt_info->active_eps == 0) {\n\t\trh_bw_info->num_active_tts -= 1;\n\t\trh_bw_info->bw_table.bw_used -= TT_HS_OVERHEAD;\n\t}\n}\n\nstatic int xhci_reserve_bandwidth(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev,\n\t\tstruct xhci_container_ctx *in_ctx)\n{\n\tstruct xhci_bw_info ep_bw_info[31];\n\tint i;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tint old_active_eps = 0;\n\n\tif (virt_dev->tt_info)\n\t\told_active_eps = virt_dev->tt_info->active_eps;\n\n\tctrl_ctx = xhci_get_input_control_ctx(in_ctx);\n\tif (!ctrl_ctx) {\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0; i < 31; i++) {\n\t\tif (!EP_IS_ADDED(ctrl_ctx, i) && !EP_IS_DROPPED(ctrl_ctx, i))\n\t\t\tcontinue;\n\n\t\t \n\t\tmemcpy(&ep_bw_info[i], &virt_dev->eps[i].bw_info,\n\t\t\t\tsizeof(ep_bw_info[i]));\n\t\t \n\t\tif (EP_IS_DROPPED(ctrl_ctx, i))\n\t\t\txhci_drop_ep_from_interval_table(xhci,\n\t\t\t\t\t&virt_dev->eps[i].bw_info,\n\t\t\t\t\tvirt_dev->bw_table,\n\t\t\t\t\tvirt_dev->udev,\n\t\t\t\t\t&virt_dev->eps[i],\n\t\t\t\t\tvirt_dev->tt_info);\n\t}\n\t \n\txhci_update_bw_info(xhci, virt_dev->in_ctx, ctrl_ctx, virt_dev);\n\tfor (i = 0; i < 31; i++) {\n\t\t \n\t\tif (EP_IS_ADDED(ctrl_ctx, i))\n\t\t\txhci_add_ep_to_interval_table(xhci,\n\t\t\t\t\t&virt_dev->eps[i].bw_info,\n\t\t\t\t\tvirt_dev->bw_table,\n\t\t\t\t\tvirt_dev->udev,\n\t\t\t\t\t&virt_dev->eps[i],\n\t\t\t\t\tvirt_dev->tt_info);\n\t}\n\n\tif (!xhci_check_bw_table(xhci, virt_dev, old_active_eps)) {\n\t\t \n\t\txhci_update_tt_active_eps(xhci, virt_dev, old_active_eps);\n\t\treturn 0;\n\t}\n\n\t \n\tfor (i = 0; i < 31; i++) {\n\t\tif (!EP_IS_ADDED(ctrl_ctx, i) && !EP_IS_DROPPED(ctrl_ctx, i))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (EP_IS_ADDED(ctrl_ctx, i)) {\n\t\t\txhci_drop_ep_from_interval_table(xhci,\n\t\t\t\t\t&virt_dev->eps[i].bw_info,\n\t\t\t\t\tvirt_dev->bw_table,\n\t\t\t\t\tvirt_dev->udev,\n\t\t\t\t\t&virt_dev->eps[i],\n\t\t\t\t\tvirt_dev->tt_info);\n\t\t}\n\t\t \n\t\tmemcpy(&virt_dev->eps[i].bw_info, &ep_bw_info[i],\n\t\t\t\tsizeof(ep_bw_info[i]));\n\t\t \n\t\tif (EP_IS_DROPPED(ctrl_ctx, i))\n\t\t\txhci_add_ep_to_interval_table(xhci,\n\t\t\t\t\t&virt_dev->eps[i].bw_info,\n\t\t\t\t\tvirt_dev->bw_table,\n\t\t\t\t\tvirt_dev->udev,\n\t\t\t\t\t&virt_dev->eps[i],\n\t\t\t\t\tvirt_dev->tt_info);\n\t}\n\treturn -ENOMEM;\n}\n\n\n \nstatic int xhci_configure_endpoint(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev,\n\t\tstruct xhci_command *command,\n\t\tbool ctx_change, bool must_succeed)\n{\n\tint ret;\n\tunsigned long flags;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tstruct xhci_virt_device *virt_dev;\n\tstruct xhci_slot_ctx *slot_ctx;\n\n\tif (!command)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\tif (xhci->xhc_state & XHCI_STATE_DYING) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\treturn -ESHUTDOWN;\n\t}\n\n\tvirt_dev = xhci->devs[udev->slot_id];\n\n\tctrl_ctx = xhci_get_input_control_ctx(command->in_ctx);\n\tif (!ctrl_ctx) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tif ((xhci->quirks & XHCI_EP_LIMIT_QUIRK) &&\n\t\t\txhci_reserve_host_resources(xhci, ctrl_ctx)) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_warn(xhci, \"Not enough host resources, \"\n\t\t\t\t\"active endpoint contexts = %u\\n\",\n\t\t\t\txhci->num_active_eps);\n\t\treturn -ENOMEM;\n\t}\n\tif ((xhci->quirks & XHCI_SW_BW_CHECKING) &&\n\t    xhci_reserve_bandwidth(xhci, virt_dev, command->in_ctx)) {\n\t\tif ((xhci->quirks & XHCI_EP_LIMIT_QUIRK))\n\t\t\txhci_free_host_resources(xhci, ctrl_ctx);\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_warn(xhci, \"Not enough bandwidth\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tslot_ctx = xhci_get_slot_ctx(xhci, command->in_ctx);\n\n\ttrace_xhci_configure_endpoint_ctrl_ctx(ctrl_ctx);\n\ttrace_xhci_configure_endpoint(slot_ctx);\n\n\tif (!ctx_change)\n\t\tret = xhci_queue_configure_endpoint(xhci, command,\n\t\t\t\tcommand->in_ctx->dma,\n\t\t\t\tudev->slot_id, must_succeed);\n\telse\n\t\tret = xhci_queue_evaluate_context(xhci, command,\n\t\t\t\tcommand->in_ctx->dma,\n\t\t\t\tudev->slot_id, must_succeed);\n\tif (ret < 0) {\n\t\tif ((xhci->quirks & XHCI_EP_LIMIT_QUIRK))\n\t\t\txhci_free_host_resources(xhci, ctrl_ctx);\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_dbg_trace(xhci,  trace_xhci_dbg_context_change,\n\t\t\t\t\"FIXME allocate a new ring segment\");\n\t\treturn -ENOMEM;\n\t}\n\txhci_ring_cmd_db(xhci);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\t \n\twait_for_completion(command->completion);\n\n\tif (!ctx_change)\n\t\tret = xhci_configure_endpoint_result(xhci, udev,\n\t\t\t\t\t\t     &command->status);\n\telse\n\t\tret = xhci_evaluate_context_result(xhci, udev,\n\t\t\t\t\t\t   &command->status);\n\n\tif ((xhci->quirks & XHCI_EP_LIMIT_QUIRK)) {\n\t\tspin_lock_irqsave(&xhci->lock, flags);\n\t\t \n\t\tif (ret)\n\t\t\txhci_free_host_resources(xhci, ctrl_ctx);\n\t\telse\n\t\t\txhci_finish_resource_reservation(xhci, ctrl_ctx);\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t}\n\treturn ret;\n}\n\nstatic void xhci_check_bw_drop_ep_streams(struct xhci_hcd *xhci,\n\tstruct xhci_virt_device *vdev, int i)\n{\n\tstruct xhci_virt_ep *ep = &vdev->eps[i];\n\n\tif (ep->ep_state & EP_HAS_STREAMS) {\n\t\txhci_warn(xhci, \"WARN: endpoint 0x%02x has streams on set_interface, freeing streams.\\n\",\n\t\t\t\txhci_get_endpoint_address(i));\n\t\txhci_free_stream_info(xhci, ep->stream_info);\n\t\tep->stream_info = NULL;\n\t\tep->ep_state &= ~EP_HAS_STREAMS;\n\t}\n}\n\n \nint xhci_check_bandwidth(struct usb_hcd *hcd, struct usb_device *udev)\n{\n\tint i;\n\tint ret = 0;\n\tstruct xhci_hcd *xhci;\n\tstruct xhci_virt_device\t*virt_dev;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tstruct xhci_slot_ctx *slot_ctx;\n\tstruct xhci_command *command;\n\n\tret = xhci_check_args(hcd, udev, NULL, 0, true, __func__);\n\tif (ret <= 0)\n\t\treturn ret;\n\txhci = hcd_to_xhci(hcd);\n\tif ((xhci->xhc_state & XHCI_STATE_DYING) ||\n\t\t(xhci->xhc_state & XHCI_STATE_REMOVING))\n\t\treturn -ENODEV;\n\n\txhci_dbg(xhci, \"%s called for udev %p\\n\", __func__, udev);\n\tvirt_dev = xhci->devs[udev->slot_id];\n\n\tcommand = xhci_alloc_command(xhci, true, GFP_KERNEL);\n\tif (!command)\n\t\treturn -ENOMEM;\n\n\tcommand->in_ctx = virt_dev->in_ctx;\n\n\t \n\tctrl_ctx = xhci_get_input_control_ctx(command->in_ctx);\n\tif (!ctrl_ctx) {\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\tret = -ENOMEM;\n\t\tgoto command_cleanup;\n\t}\n\tctrl_ctx->add_flags |= cpu_to_le32(SLOT_FLAG);\n\tctrl_ctx->add_flags &= cpu_to_le32(~EP0_FLAG);\n\tctrl_ctx->drop_flags &= cpu_to_le32(~(SLOT_FLAG | EP0_FLAG));\n\n\t \n\tif (ctrl_ctx->add_flags == cpu_to_le32(SLOT_FLAG) &&\n\t    ctrl_ctx->drop_flags == 0) {\n\t\tret = 0;\n\t\tgoto command_cleanup;\n\t}\n\t \n\tslot_ctx = xhci_get_slot_ctx(xhci, virt_dev->in_ctx);\n\tfor (i = 31; i >= 1; i--) {\n\t\t__le32 le32 = cpu_to_le32(BIT(i));\n\n\t\tif ((virt_dev->eps[i-1].ring && !(ctrl_ctx->drop_flags & le32))\n\t\t    || (ctrl_ctx->add_flags & le32) || i == 1) {\n\t\t\tslot_ctx->dev_info &= cpu_to_le32(~LAST_CTX_MASK);\n\t\t\tslot_ctx->dev_info |= cpu_to_le32(LAST_CTX(i));\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tret = xhci_configure_endpoint(xhci, udev, command,\n\t\t\tfalse, false);\n\tif (ret)\n\t\t \n\t\tgoto command_cleanup;\n\n\t \n\tfor (i = 1; i < 31; i++) {\n\t\tif ((le32_to_cpu(ctrl_ctx->drop_flags) & (1 << (i + 1))) &&\n\t\t    !(le32_to_cpu(ctrl_ctx->add_flags) & (1 << (i + 1)))) {\n\t\t\txhci_free_endpoint_ring(xhci, virt_dev, i);\n\t\t\txhci_check_bw_drop_ep_streams(xhci, virt_dev, i);\n\t\t}\n\t}\n\txhci_zero_in_ctx(xhci, virt_dev);\n\t \n\tfor (i = 1; i < 31; i++) {\n\t\tif (!virt_dev->eps[i].new_ring)\n\t\t\tcontinue;\n\t\t \n\t\tif (virt_dev->eps[i].ring) {\n\t\t\txhci_free_endpoint_ring(xhci, virt_dev, i);\n\t\t}\n\t\txhci_check_bw_drop_ep_streams(xhci, virt_dev, i);\n\t\tvirt_dev->eps[i].ring = virt_dev->eps[i].new_ring;\n\t\tvirt_dev->eps[i].new_ring = NULL;\n\t\txhci_debugfs_create_endpoint(xhci, virt_dev, i);\n\t}\ncommand_cleanup:\n\tkfree(command->completion);\n\tkfree(command);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(xhci_check_bandwidth);\n\nvoid xhci_reset_bandwidth(struct usb_hcd *hcd, struct usb_device *udev)\n{\n\tstruct xhci_hcd *xhci;\n\tstruct xhci_virt_device\t*virt_dev;\n\tint i, ret;\n\n\tret = xhci_check_args(hcd, udev, NULL, 0, true, __func__);\n\tif (ret <= 0)\n\t\treturn;\n\txhci = hcd_to_xhci(hcd);\n\n\txhci_dbg(xhci, \"%s called for udev %p\\n\", __func__, udev);\n\tvirt_dev = xhci->devs[udev->slot_id];\n\t \n\tfor (i = 0; i < 31; i++) {\n\t\tif (virt_dev->eps[i].new_ring) {\n\t\t\txhci_debugfs_remove_endpoint(xhci, virt_dev, i);\n\t\t\txhci_ring_free(xhci, virt_dev->eps[i].new_ring);\n\t\t\tvirt_dev->eps[i].new_ring = NULL;\n\t\t}\n\t}\n\txhci_zero_in_ctx(xhci, virt_dev);\n}\nEXPORT_SYMBOL_GPL(xhci_reset_bandwidth);\n\nstatic void xhci_setup_input_ctx_for_config_ep(struct xhci_hcd *xhci,\n\t\tstruct xhci_container_ctx *in_ctx,\n\t\tstruct xhci_container_ctx *out_ctx,\n\t\tstruct xhci_input_control_ctx *ctrl_ctx,\n\t\tu32 add_flags, u32 drop_flags)\n{\n\tctrl_ctx->add_flags = cpu_to_le32(add_flags);\n\tctrl_ctx->drop_flags = cpu_to_le32(drop_flags);\n\txhci_slot_copy(xhci, in_ctx, out_ctx);\n\tctrl_ctx->add_flags |= cpu_to_le32(SLOT_FLAG);\n}\n\nstatic void xhci_endpoint_disable(struct usb_hcd *hcd,\n\t\t\t\t  struct usb_host_endpoint *host_ep)\n{\n\tstruct xhci_hcd\t\t*xhci;\n\tstruct xhci_virt_device\t*vdev;\n\tstruct xhci_virt_ep\t*ep;\n\tstruct usb_device\t*udev;\n\tunsigned long\t\tflags;\n\tunsigned int\t\tep_index;\n\n\txhci = hcd_to_xhci(hcd);\nrescan:\n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\tudev = (struct usb_device *)host_ep->hcpriv;\n\tif (!udev || !udev->slot_id)\n\t\tgoto done;\n\n\tvdev = xhci->devs[udev->slot_id];\n\tif (!vdev)\n\t\tgoto done;\n\n\tep_index = xhci_get_endpoint_index(&host_ep->desc);\n\tep = &vdev->eps[ep_index];\n\n\t \n\tif (ep->ep_state & EP_CLEARING_TT) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\tschedule_timeout_uninterruptible(1);\n\t\tgoto rescan;\n\t}\n\n\tif (ep->ep_state)\n\t\txhci_dbg(xhci, \"endpoint disable with ep_state 0x%x\\n\",\n\t\t\t ep->ep_state);\ndone:\n\thost_ep->hcpriv = NULL;\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n}\n\n \n\nstatic void xhci_endpoint_reset(struct usb_hcd *hcd,\n\t\tstruct usb_host_endpoint *host_ep)\n{\n\tstruct xhci_hcd *xhci;\n\tstruct usb_device *udev;\n\tstruct xhci_virt_device *vdev;\n\tstruct xhci_virt_ep *ep;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tstruct xhci_command *stop_cmd, *cfg_cmd;\n\tunsigned int ep_index;\n\tunsigned long flags;\n\tu32 ep_flag;\n\tint err;\n\n\txhci = hcd_to_xhci(hcd);\n\tif (!host_ep->hcpriv)\n\t\treturn;\n\tudev = (struct usb_device *) host_ep->hcpriv;\n\tvdev = xhci->devs[udev->slot_id];\n\n\t \n\tif (!udev->slot_id || !vdev)\n\t\treturn;\n\tep_index = xhci_get_endpoint_index(&host_ep->desc);\n\tep = &vdev->eps[ep_index];\n\n\t \n\tspin_lock_irqsave(&xhci->lock, flags);\n\tif (ep->ep_state & EP_HARD_CLEAR_TOGGLE) {\n\t\tep->ep_state &= ~EP_HARD_CLEAR_TOGGLE;\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\treturn;\n\t}\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t \n\tif (usb_endpoint_xfer_control(&host_ep->desc) ||\n\t    usb_endpoint_xfer_isoc(&host_ep->desc))\n\t\treturn;\n\n\tep_flag = xhci_get_endpoint_flag(&host_ep->desc);\n\n\tif (ep_flag == SLOT_FLAG || ep_flag == EP0_FLAG)\n\t\treturn;\n\n\tstop_cmd = xhci_alloc_command(xhci, true, GFP_NOWAIT);\n\tif (!stop_cmd)\n\t\treturn;\n\n\tcfg_cmd = xhci_alloc_command_with_ctx(xhci, true, GFP_NOWAIT);\n\tif (!cfg_cmd)\n\t\tgoto cleanup;\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\t \n\tep->ep_state |= EP_SOFT_CLEAR_TOGGLE;\n\n\t \n\n\tif (!list_empty(&ep->ring->td_list)) {\n\t\tdev_err(&udev->dev, \"EP not empty, refuse reset\\n\");\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_free_command(xhci, cfg_cmd);\n\t\tgoto cleanup;\n\t}\n\n\terr = xhci_queue_stop_endpoint(xhci, stop_cmd, udev->slot_id,\n\t\t\t\t\tep_index, 0);\n\tif (err < 0) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_free_command(xhci, cfg_cmd);\n\t\txhci_dbg(xhci, \"%s: Failed to queue stop ep command, %d \",\n\t\t\t\t__func__, err);\n\t\tgoto cleanup;\n\t}\n\n\txhci_ring_cmd_db(xhci);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\twait_for_completion(stop_cmd->completion);\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\t \n\tctrl_ctx = xhci_get_input_control_ctx(cfg_cmd->in_ctx);\n\tif (!ctrl_ctx) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_free_command(xhci, cfg_cmd);\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\tgoto cleanup;\n\t}\n\n\txhci_setup_input_ctx_for_config_ep(xhci, cfg_cmd->in_ctx, vdev->out_ctx,\n\t\t\t\t\t   ctrl_ctx, ep_flag, ep_flag);\n\txhci_endpoint_copy(xhci, cfg_cmd->in_ctx, vdev->out_ctx, ep_index);\n\n\terr = xhci_queue_configure_endpoint(xhci, cfg_cmd, cfg_cmd->in_ctx->dma,\n\t\t\t\t      udev->slot_id, false);\n\tif (err < 0) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_free_command(xhci, cfg_cmd);\n\t\txhci_dbg(xhci, \"%s: Failed to queue config ep command, %d \",\n\t\t\t\t__func__, err);\n\t\tgoto cleanup;\n\t}\n\n\txhci_ring_cmd_db(xhci);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\twait_for_completion(cfg_cmd->completion);\n\n\txhci_free_command(xhci, cfg_cmd);\ncleanup:\n\txhci_free_command(xhci, stop_cmd);\n\tspin_lock_irqsave(&xhci->lock, flags);\n\tif (ep->ep_state & EP_SOFT_CLEAR_TOGGLE)\n\t\tep->ep_state &= ~EP_SOFT_CLEAR_TOGGLE;\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n}\n\nstatic int xhci_check_streams_endpoint(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev, struct usb_host_endpoint *ep,\n\t\tunsigned int slot_id)\n{\n\tint ret;\n\tunsigned int ep_index;\n\tunsigned int ep_state;\n\n\tif (!ep)\n\t\treturn -EINVAL;\n\tret = xhci_check_args(xhci_to_hcd(xhci), udev, ep, 1, true, __func__);\n\tif (ret <= 0)\n\t\treturn ret ? ret : -EINVAL;\n\tif (usb_ss_max_streams(&ep->ss_ep_comp) == 0) {\n\t\txhci_warn(xhci, \"WARN: SuperSpeed Endpoint Companion\"\n\t\t\t\t\" descriptor for ep 0x%x does not support streams\\n\",\n\t\t\t\tep->desc.bEndpointAddress);\n\t\treturn -EINVAL;\n\t}\n\n\tep_index = xhci_get_endpoint_index(&ep->desc);\n\tep_state = xhci->devs[slot_id]->eps[ep_index].ep_state;\n\tif (ep_state & EP_HAS_STREAMS ||\n\t\t\tep_state & EP_GETTING_STREAMS) {\n\t\txhci_warn(xhci, \"WARN: SuperSpeed bulk endpoint 0x%x \"\n\t\t\t\t\"already has streams set up.\\n\",\n\t\t\t\tep->desc.bEndpointAddress);\n\t\txhci_warn(xhci, \"Send email to xHCI maintainer and ask for \"\n\t\t\t\t\"dynamic stream context array reallocation.\\n\");\n\t\treturn -EINVAL;\n\t}\n\tif (!list_empty(&xhci->devs[slot_id]->eps[ep_index].ring->td_list)) {\n\t\txhci_warn(xhci, \"Cannot setup streams for SuperSpeed bulk \"\n\t\t\t\t\"endpoint 0x%x; URBs are pending.\\n\",\n\t\t\t\tep->desc.bEndpointAddress);\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic void xhci_calculate_streams_entries(struct xhci_hcd *xhci,\n\t\tunsigned int *num_streams, unsigned int *num_stream_ctxs)\n{\n\tunsigned int max_streams;\n\n\t \n\t*num_stream_ctxs = roundup_pow_of_two(*num_streams);\n\t \n\tmax_streams = HCC_MAX_PSA(xhci->hcc_params);\n\tif (*num_stream_ctxs > max_streams) {\n\t\txhci_dbg(xhci, \"xHCI HW only supports %u stream ctx entries.\\n\",\n\t\t\t\tmax_streams);\n\t\t*num_stream_ctxs = max_streams;\n\t\t*num_streams = max_streams;\n\t}\n}\n\n \nstatic int xhci_calculate_streams_and_bitmask(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev,\n\t\tstruct usb_host_endpoint **eps, unsigned int num_eps,\n\t\tunsigned int *num_streams, u32 *changed_ep_bitmask)\n{\n\tunsigned int max_streams;\n\tunsigned int endpoint_flag;\n\tint i;\n\tint ret;\n\n\tfor (i = 0; i < num_eps; i++) {\n\t\tret = xhci_check_streams_endpoint(xhci, udev,\n\t\t\t\teps[i], udev->slot_id);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tmax_streams = usb_ss_max_streams(&eps[i]->ss_ep_comp);\n\t\tif (max_streams < (*num_streams - 1)) {\n\t\t\txhci_dbg(xhci, \"Ep 0x%x only supports %u stream IDs.\\n\",\n\t\t\t\t\teps[i]->desc.bEndpointAddress,\n\t\t\t\t\tmax_streams);\n\t\t\t*num_streams = max_streams+1;\n\t\t}\n\n\t\tendpoint_flag = xhci_get_endpoint_flag(&eps[i]->desc);\n\t\tif (*changed_ep_bitmask & endpoint_flag)\n\t\t\treturn -EINVAL;\n\t\t*changed_ep_bitmask |= endpoint_flag;\n\t}\n\treturn 0;\n}\n\nstatic u32 xhci_calculate_no_streams_bitmask(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev,\n\t\tstruct usb_host_endpoint **eps, unsigned int num_eps)\n{\n\tu32 changed_ep_bitmask = 0;\n\tunsigned int slot_id;\n\tunsigned int ep_index;\n\tunsigned int ep_state;\n\tint i;\n\n\tslot_id = udev->slot_id;\n\tif (!xhci->devs[slot_id])\n\t\treturn 0;\n\n\tfor (i = 0; i < num_eps; i++) {\n\t\tep_index = xhci_get_endpoint_index(&eps[i]->desc);\n\t\tep_state = xhci->devs[slot_id]->eps[ep_index].ep_state;\n\t\t \n\t\tif (ep_state & EP_GETTING_NO_STREAMS) {\n\t\t\txhci_warn(xhci, \"WARN Can't disable streams for \"\n\t\t\t\t\t\"endpoint 0x%x, \"\n\t\t\t\t\t\"streams are being disabled already\\n\",\n\t\t\t\t\teps[i]->desc.bEndpointAddress);\n\t\t\treturn 0;\n\t\t}\n\t\t \n\t\tif (!(ep_state & EP_HAS_STREAMS) &&\n\t\t\t\t!(ep_state & EP_GETTING_STREAMS)) {\n\t\t\txhci_warn(xhci, \"WARN Can't disable streams for \"\n\t\t\t\t\t\"endpoint 0x%x, \"\n\t\t\t\t\t\"streams are already disabled!\\n\",\n\t\t\t\t\teps[i]->desc.bEndpointAddress);\n\t\t\txhci_warn(xhci, \"WARN xhci_free_streams() called \"\n\t\t\t\t\t\"with non-streams endpoint\\n\");\n\t\t\treturn 0;\n\t\t}\n\t\tchanged_ep_bitmask |= xhci_get_endpoint_flag(&eps[i]->desc);\n\t}\n\treturn changed_ep_bitmask;\n}\n\n \nstatic int xhci_alloc_streams(struct usb_hcd *hcd, struct usb_device *udev,\n\t\tstruct usb_host_endpoint **eps, unsigned int num_eps,\n\t\tunsigned int num_streams, gfp_t mem_flags)\n{\n\tint i, ret;\n\tstruct xhci_hcd *xhci;\n\tstruct xhci_virt_device *vdev;\n\tstruct xhci_command *config_cmd;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tunsigned int ep_index;\n\tunsigned int num_stream_ctxs;\n\tunsigned int max_packet;\n\tunsigned long flags;\n\tu32 changed_ep_bitmask = 0;\n\n\tif (!eps)\n\t\treturn -EINVAL;\n\n\t \n\tnum_streams += 1;\n\txhci = hcd_to_xhci(hcd);\n\txhci_dbg(xhci, \"Driver wants %u stream IDs (including stream 0).\\n\",\n\t\t\tnum_streams);\n\n\t \n\tif ((xhci->quirks & XHCI_BROKEN_STREAMS) ||\n\t\t\tHCC_MAX_PSA(xhci->hcc_params) < 4) {\n\t\txhci_dbg(xhci, \"xHCI controller does not support streams.\\n\");\n\t\treturn -ENOSYS;\n\t}\n\n\tconfig_cmd = xhci_alloc_command_with_ctx(xhci, true, mem_flags);\n\tif (!config_cmd)\n\t\treturn -ENOMEM;\n\n\tctrl_ctx = xhci_get_input_control_ctx(config_cmd->in_ctx);\n\tif (!ctrl_ctx) {\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\txhci_free_command(xhci, config_cmd);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tspin_lock_irqsave(&xhci->lock, flags);\n\tret = xhci_calculate_streams_and_bitmask(xhci, udev, eps,\n\t\t\tnum_eps, &num_streams, &changed_ep_bitmask);\n\tif (ret < 0) {\n\t\txhci_free_command(xhci, config_cmd);\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\treturn ret;\n\t}\n\tif (num_streams <= 1) {\n\t\txhci_warn(xhci, \"WARN: endpoints can't handle \"\n\t\t\t\t\"more than one stream.\\n\");\n\t\txhci_free_command(xhci, config_cmd);\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\tvdev = xhci->devs[udev->slot_id];\n\t \n\tfor (i = 0; i < num_eps; i++) {\n\t\tep_index = xhci_get_endpoint_index(&eps[i]->desc);\n\t\tvdev->eps[ep_index].ep_state |= EP_GETTING_STREAMS;\n\t}\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\t \n\txhci_calculate_streams_entries(xhci, &num_streams, &num_stream_ctxs);\n\txhci_dbg(xhci, \"Need %u stream ctx entries for %u stream IDs.\\n\",\n\t\t\tnum_stream_ctxs, num_streams);\n\n\tfor (i = 0; i < num_eps; i++) {\n\t\tep_index = xhci_get_endpoint_index(&eps[i]->desc);\n\t\tmax_packet = usb_endpoint_maxp(&eps[i]->desc);\n\t\tvdev->eps[ep_index].stream_info = xhci_alloc_stream_info(xhci,\n\t\t\t\tnum_stream_ctxs,\n\t\t\t\tnum_streams,\n\t\t\t\tmax_packet, mem_flags);\n\t\tif (!vdev->eps[ep_index].stream_info)\n\t\t\tgoto cleanup;\n\t\t \n\t}\n\n\t \n\tfor (i = 0; i < num_eps; i++) {\n\t\tstruct xhci_ep_ctx *ep_ctx;\n\n\t\tep_index = xhci_get_endpoint_index(&eps[i]->desc);\n\t\tep_ctx = xhci_get_ep_ctx(xhci, config_cmd->in_ctx, ep_index);\n\n\t\txhci_endpoint_copy(xhci, config_cmd->in_ctx,\n\t\t\t\tvdev->out_ctx, ep_index);\n\t\txhci_setup_streams_ep_input_ctx(xhci, ep_ctx,\n\t\t\t\tvdev->eps[ep_index].stream_info);\n\t}\n\t \n\txhci_setup_input_ctx_for_config_ep(xhci, config_cmd->in_ctx,\n\t\t\tvdev->out_ctx, ctrl_ctx,\n\t\t\tchanged_ep_bitmask, changed_ep_bitmask);\n\n\t \n\tret = xhci_configure_endpoint(xhci, udev, config_cmd,\n\t\t\tfalse, false);\n\n\t \n\tif (ret < 0)\n\t\tgoto cleanup;\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\tfor (i = 0; i < num_eps; i++) {\n\t\tep_index = xhci_get_endpoint_index(&eps[i]->desc);\n\t\tvdev->eps[ep_index].ep_state &= ~EP_GETTING_STREAMS;\n\t\txhci_dbg(xhci, \"Slot %u ep ctx %u now has streams.\\n\",\n\t\t\t udev->slot_id, ep_index);\n\t\tvdev->eps[ep_index].ep_state |= EP_HAS_STREAMS;\n\t}\n\txhci_free_command(xhci, config_cmd);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\tfor (i = 0; i < num_eps; i++) {\n\t\tep_index = xhci_get_endpoint_index(&eps[i]->desc);\n\t\txhci_debugfs_create_stream_files(xhci, vdev, ep_index);\n\t}\n\t \n\treturn num_streams - 1;\n\ncleanup:\n\t \n\tfor (i = 0; i < num_eps; i++) {\n\t\tep_index = xhci_get_endpoint_index(&eps[i]->desc);\n\t\txhci_free_stream_info(xhci, vdev->eps[ep_index].stream_info);\n\t\tvdev->eps[ep_index].stream_info = NULL;\n\t\t \n\t\tvdev->eps[ep_index].ep_state &= ~EP_GETTING_STREAMS;\n\t\tvdev->eps[ep_index].ep_state &= ~EP_HAS_STREAMS;\n\t\txhci_endpoint_zero(xhci, vdev, eps[i]);\n\t}\n\txhci_free_command(xhci, config_cmd);\n\treturn -ENOMEM;\n}\n\n \nstatic int xhci_free_streams(struct usb_hcd *hcd, struct usb_device *udev,\n\t\tstruct usb_host_endpoint **eps, unsigned int num_eps,\n\t\tgfp_t mem_flags)\n{\n\tint i, ret;\n\tstruct xhci_hcd *xhci;\n\tstruct xhci_virt_device *vdev;\n\tstruct xhci_command *command;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tunsigned int ep_index;\n\tunsigned long flags;\n\tu32 changed_ep_bitmask;\n\n\txhci = hcd_to_xhci(hcd);\n\tvdev = xhci->devs[udev->slot_id];\n\n\t \n\tspin_lock_irqsave(&xhci->lock, flags);\n\tchanged_ep_bitmask = xhci_calculate_no_streams_bitmask(xhci,\n\t\t\tudev, eps, num_eps);\n\tif (changed_ep_bitmask == 0) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tep_index = xhci_get_endpoint_index(&eps[0]->desc);\n\tcommand = vdev->eps[ep_index].stream_info->free_streams_command;\n\tctrl_ctx = xhci_get_input_control_ctx(command->in_ctx);\n\tif (!ctrl_ctx) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < num_eps; i++) {\n\t\tstruct xhci_ep_ctx *ep_ctx;\n\n\t\tep_index = xhci_get_endpoint_index(&eps[i]->desc);\n\t\tep_ctx = xhci_get_ep_ctx(xhci, command->in_ctx, ep_index);\n\t\txhci->devs[udev->slot_id]->eps[ep_index].ep_state |=\n\t\t\tEP_GETTING_NO_STREAMS;\n\n\t\txhci_endpoint_copy(xhci, command->in_ctx,\n\t\t\t\tvdev->out_ctx, ep_index);\n\t\txhci_setup_no_streams_ep_input_ctx(ep_ctx,\n\t\t\t\t&vdev->eps[ep_index]);\n\t}\n\txhci_setup_input_ctx_for_config_ep(xhci, command->in_ctx,\n\t\t\tvdev->out_ctx, ctrl_ctx,\n\t\t\tchanged_ep_bitmask, changed_ep_bitmask);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\t \n\tret = xhci_configure_endpoint(xhci, udev, command,\n\t\t\tfalse, true);\n\n\t \n\tif (ret < 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\tfor (i = 0; i < num_eps; i++) {\n\t\tep_index = xhci_get_endpoint_index(&eps[i]->desc);\n\t\txhci_free_stream_info(xhci, vdev->eps[ep_index].stream_info);\n\t\tvdev->eps[ep_index].stream_info = NULL;\n\t\t \n\t\tvdev->eps[ep_index].ep_state &= ~EP_GETTING_NO_STREAMS;\n\t\tvdev->eps[ep_index].ep_state &= ~EP_HAS_STREAMS;\n\t}\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\treturn 0;\n}\n\n \nvoid xhci_free_device_endpoint_resources(struct xhci_hcd *xhci,\n\tstruct xhci_virt_device *virt_dev, bool drop_control_ep)\n{\n\tint i;\n\tunsigned int num_dropped_eps = 0;\n\tunsigned int drop_flags = 0;\n\n\tfor (i = (drop_control_ep ? 0 : 1); i < 31; i++) {\n\t\tif (virt_dev->eps[i].ring) {\n\t\t\tdrop_flags |= 1 << i;\n\t\t\tnum_dropped_eps++;\n\t\t}\n\t}\n\txhci->num_active_eps -= num_dropped_eps;\n\tif (num_dropped_eps)\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"Dropped %u ep ctxs, flags = 0x%x, \"\n\t\t\t\t\"%u now active.\",\n\t\t\t\tnum_dropped_eps, drop_flags,\n\t\t\t\txhci->num_active_eps);\n}\n\n \nstatic int xhci_discover_or_reset_device(struct usb_hcd *hcd,\n\t\tstruct usb_device *udev)\n{\n\tint ret, i;\n\tunsigned long flags;\n\tstruct xhci_hcd *xhci;\n\tunsigned int slot_id;\n\tstruct xhci_virt_device *virt_dev;\n\tstruct xhci_command *reset_device_cmd;\n\tstruct xhci_slot_ctx *slot_ctx;\n\tint old_active_eps = 0;\n\n\tret = xhci_check_args(hcd, udev, NULL, 0, false, __func__);\n\tif (ret <= 0)\n\t\treturn ret;\n\txhci = hcd_to_xhci(hcd);\n\tslot_id = udev->slot_id;\n\tvirt_dev = xhci->devs[slot_id];\n\tif (!virt_dev) {\n\t\txhci_dbg(xhci, \"The device to be reset with slot ID %u does \"\n\t\t\t\t\"not exist. Re-allocate the device\\n\", slot_id);\n\t\tret = xhci_alloc_dev(hcd, udev);\n\t\tif (ret == 1)\n\t\t\treturn 0;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (virt_dev->tt_info)\n\t\told_active_eps = virt_dev->tt_info->active_eps;\n\n\tif (virt_dev->udev != udev) {\n\t\t \n\t\txhci_dbg(xhci, \"The device to be reset with slot ID %u does \"\n\t\t\t\t\"not match the udev. Re-allocate the device\\n\",\n\t\t\t\tslot_id);\n\t\tret = xhci_alloc_dev(hcd, udev);\n\t\tif (ret == 1)\n\t\t\treturn 0;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\t \n\tslot_ctx = xhci_get_slot_ctx(xhci, virt_dev->out_ctx);\n\tif (GET_SLOT_STATE(le32_to_cpu(slot_ctx->dev_state)) ==\n\t\t\t\t\t\tSLOT_STATE_DISABLED)\n\t\treturn 0;\n\n\ttrace_xhci_discover_or_reset_device(slot_ctx);\n\n\txhci_dbg(xhci, \"Resetting device with slot ID %u\\n\", slot_id);\n\t \n\treset_device_cmd = xhci_alloc_command(xhci, true, GFP_NOIO);\n\tif (!reset_device_cmd) {\n\t\txhci_dbg(xhci, \"Couldn't allocate command structure.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\tret = xhci_queue_reset_device(xhci, reset_device_cmd, slot_id);\n\tif (ret) {\n\t\txhci_dbg(xhci, \"FIXME: allocate a command ring segment\\n\");\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\tgoto command_cleanup;\n\t}\n\txhci_ring_cmd_db(xhci);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\t \n\twait_for_completion(reset_device_cmd->completion);\n\n\t \n\tret = reset_device_cmd->status;\n\tswitch (ret) {\n\tcase COMP_COMMAND_ABORTED:\n\tcase COMP_COMMAND_RING_STOPPED:\n\t\txhci_warn(xhci, \"Timeout waiting for reset device command\\n\");\n\t\tret = -ETIME;\n\t\tgoto command_cleanup;\n\tcase COMP_SLOT_NOT_ENABLED_ERROR:  \n\tcase COMP_CONTEXT_STATE_ERROR:  \n\t\txhci_dbg(xhci, \"Can't reset device (slot ID %u) in %s state\\n\",\n\t\t\t\tslot_id,\n\t\t\t\txhci_get_slot_state(xhci, virt_dev->out_ctx));\n\t\txhci_dbg(xhci, \"Not freeing device rings.\\n\");\n\t\t \n\t\tret = 0;\n\t\tgoto command_cleanup;\n\tcase COMP_SUCCESS:\n\t\txhci_dbg(xhci, \"Successful reset device command.\\n\");\n\t\tbreak;\n\tdefault:\n\t\tif (xhci_is_vendor_info_code(xhci, ret))\n\t\t\tbreak;\n\t\txhci_warn(xhci, \"Unknown completion code %u for \"\n\t\t\t\t\"reset device command.\\n\", ret);\n\t\tret = -EINVAL;\n\t\tgoto command_cleanup;\n\t}\n\n\t \n\tif ((xhci->quirks & XHCI_EP_LIMIT_QUIRK)) {\n\t\tspin_lock_irqsave(&xhci->lock, flags);\n\t\t \n\t\txhci_free_device_endpoint_resources(xhci, virt_dev, false);\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t}\n\n\t \n\tfor (i = 1; i < 31; i++) {\n\t\tstruct xhci_virt_ep *ep = &virt_dev->eps[i];\n\n\t\tif (ep->ep_state & EP_HAS_STREAMS) {\n\t\t\txhci_warn(xhci, \"WARN: endpoint 0x%02x has streams on device reset, freeing streams.\\n\",\n\t\t\t\t\txhci_get_endpoint_address(i));\n\t\t\txhci_free_stream_info(xhci, ep->stream_info);\n\t\t\tep->stream_info = NULL;\n\t\t\tep->ep_state &= ~EP_HAS_STREAMS;\n\t\t}\n\n\t\tif (ep->ring) {\n\t\t\txhci_debugfs_remove_endpoint(xhci, virt_dev, i);\n\t\t\txhci_free_endpoint_ring(xhci, virt_dev, i);\n\t\t}\n\t\tif (!list_empty(&virt_dev->eps[i].bw_endpoint_list))\n\t\t\txhci_drop_ep_from_interval_table(xhci,\n\t\t\t\t\t&virt_dev->eps[i].bw_info,\n\t\t\t\t\tvirt_dev->bw_table,\n\t\t\t\t\tudev,\n\t\t\t\t\t&virt_dev->eps[i],\n\t\t\t\t\tvirt_dev->tt_info);\n\t\txhci_clear_endpoint_bw_info(&virt_dev->eps[i].bw_info);\n\t}\n\t \n\txhci_update_tt_active_eps(xhci, virt_dev, old_active_eps);\n\tvirt_dev->flags = 0;\n\tret = 0;\n\ncommand_cleanup:\n\txhci_free_command(xhci, reset_device_cmd);\n\treturn ret;\n}\n\n \nstatic void xhci_free_dev(struct usb_hcd *hcd, struct usb_device *udev)\n{\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\tstruct xhci_virt_device *virt_dev;\n\tstruct xhci_slot_ctx *slot_ctx;\n\tunsigned long flags;\n\tint i, ret;\n\n\t \n\tif (xhci->quirks & XHCI_RESET_ON_RESUME)\n\t\tpm_runtime_put_noidle(hcd->self.controller);\n\n\tret = xhci_check_args(hcd, udev, NULL, 0, true, __func__);\n\t \n\tif (ret <= 0 && ret != -ENODEV)\n\t\treturn;\n\n\tvirt_dev = xhci->devs[udev->slot_id];\n\tslot_ctx = xhci_get_slot_ctx(xhci, virt_dev->out_ctx);\n\ttrace_xhci_free_dev(slot_ctx);\n\n\t \n\tfor (i = 0; i < 31; i++)\n\t\tvirt_dev->eps[i].ep_state &= ~EP_STOP_CMD_PENDING;\n\tvirt_dev->udev = NULL;\n\txhci_disable_slot(xhci, udev->slot_id);\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\txhci_free_virt_device(xhci, udev->slot_id);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n}\n\nint xhci_disable_slot(struct xhci_hcd *xhci, u32 slot_id)\n{\n\tstruct xhci_command *command;\n\tunsigned long flags;\n\tu32 state;\n\tint ret;\n\n\tcommand = xhci_alloc_command(xhci, true, GFP_KERNEL);\n\tif (!command)\n\t\treturn -ENOMEM;\n\n\txhci_debugfs_remove_slot(xhci, slot_id);\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\t \n\tstate = readl(&xhci->op_regs->status);\n\tif (state == 0xffffffff || (xhci->xhc_state & XHCI_STATE_DYING) ||\n\t\t\t(xhci->xhc_state & XHCI_STATE_HALTED)) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\tkfree(command);\n\t\treturn -ENODEV;\n\t}\n\n\tret = xhci_queue_slot_control(xhci, command, TRB_DISABLE_SLOT,\n\t\t\t\tslot_id);\n\tif (ret) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\tkfree(command);\n\t\treturn ret;\n\t}\n\txhci_ring_cmd_db(xhci);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\twait_for_completion(command->completion);\n\n\tif (command->status != COMP_SUCCESS)\n\t\txhci_warn(xhci, \"Unsuccessful disable slot %u command, status %d\\n\",\n\t\t\t  slot_id, command->status);\n\n\txhci_free_command(xhci, command);\n\n\treturn 0;\n}\n\n \nstatic int xhci_reserve_host_control_ep_resources(struct xhci_hcd *xhci)\n{\n\tif (xhci->num_active_eps + 1 > xhci->limit_active_eps) {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\t\"Not enough ep ctxs: \"\n\t\t\t\t\"%u active, need to add 1, limit is %u.\",\n\t\t\t\txhci->num_active_eps, xhci->limit_active_eps);\n\t\treturn -ENOMEM;\n\t}\n\txhci->num_active_eps += 1;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_quirks,\n\t\t\t\"Adding 1 ep ctx, %u now active.\",\n\t\t\txhci->num_active_eps);\n\treturn 0;\n}\n\n\n \nint xhci_alloc_dev(struct usb_hcd *hcd, struct usb_device *udev)\n{\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\tstruct xhci_virt_device *vdev;\n\tstruct xhci_slot_ctx *slot_ctx;\n\tunsigned long flags;\n\tint ret, slot_id;\n\tstruct xhci_command *command;\n\n\tcommand = xhci_alloc_command(xhci, true, GFP_KERNEL);\n\tif (!command)\n\t\treturn 0;\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\tret = xhci_queue_slot_control(xhci, command, TRB_ENABLE_SLOT, 0);\n\tif (ret) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_dbg(xhci, \"FIXME: allocate a command ring segment\\n\");\n\t\txhci_free_command(xhci, command);\n\t\treturn 0;\n\t}\n\txhci_ring_cmd_db(xhci);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\twait_for_completion(command->completion);\n\tslot_id = command->slot_id;\n\n\tif (!slot_id || command->status != COMP_SUCCESS) {\n\t\txhci_err(xhci, \"Error while assigning device slot ID: %s\\n\",\n\t\t\t xhci_trb_comp_code_string(command->status));\n\t\txhci_err(xhci, \"Max number of devices this xHCI host supports is %u.\\n\",\n\t\t\t\tHCS_MAX_SLOTS(\n\t\t\t\t\treadl(&xhci->cap_regs->hcs_params1)));\n\t\txhci_free_command(xhci, command);\n\t\treturn 0;\n\t}\n\n\txhci_free_command(xhci, command);\n\n\tif ((xhci->quirks & XHCI_EP_LIMIT_QUIRK)) {\n\t\tspin_lock_irqsave(&xhci->lock, flags);\n\t\tret = xhci_reserve_host_control_ep_resources(xhci);\n\t\tif (ret) {\n\t\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\t\txhci_warn(xhci, \"Not enough host resources, \"\n\t\t\t\t\t\"active endpoint contexts = %u\\n\",\n\t\t\t\t\txhci->num_active_eps);\n\t\t\tgoto disable_slot;\n\t\t}\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t}\n\t \n\tif (!xhci_alloc_virt_device(xhci, slot_id, udev, GFP_NOIO)) {\n\t\txhci_warn(xhci, \"Could not allocate xHCI USB device data structures\\n\");\n\t\tgoto disable_slot;\n\t}\n\tvdev = xhci->devs[slot_id];\n\tslot_ctx = xhci_get_slot_ctx(xhci, vdev->out_ctx);\n\ttrace_xhci_alloc_dev(slot_ctx);\n\n\tudev->slot_id = slot_id;\n\n\txhci_debugfs_create_slot(xhci, slot_id);\n\n\t \n\tif (xhci->quirks & XHCI_RESET_ON_RESUME)\n\t\tpm_runtime_get_noresume(hcd->self.controller);\n\n\t \n\t \n\treturn 1;\n\ndisable_slot:\n\txhci_disable_slot(xhci, udev->slot_id);\n\txhci_free_virt_device(xhci, udev->slot_id);\n\n\treturn 0;\n}\n\n \nstatic int xhci_setup_device(struct usb_hcd *hcd, struct usb_device *udev,\n\t\t\t     enum xhci_setup_dev setup)\n{\n\tconst char *act = setup == SETUP_CONTEXT_ONLY ? \"context\" : \"address\";\n\tunsigned long flags;\n\tstruct xhci_virt_device *virt_dev;\n\tint ret = 0;\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\tstruct xhci_slot_ctx *slot_ctx;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tu64 temp_64;\n\tstruct xhci_command *command = NULL;\n\n\tmutex_lock(&xhci->mutex);\n\n\tif (xhci->xhc_state) {\t \n\t\tret = -ESHUTDOWN;\n\t\tgoto out;\n\t}\n\n\tif (!udev->slot_id) {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_address,\n\t\t\t\t\"Bad Slot ID %d\", udev->slot_id);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tvirt_dev = xhci->devs[udev->slot_id];\n\n\tif (WARN_ON(!virt_dev)) {\n\t\t \n\t\txhci_warn(xhci, \"Virt dev invalid for slot_id 0x%x!\\n\",\n\t\t\tudev->slot_id);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\tslot_ctx = xhci_get_slot_ctx(xhci, virt_dev->out_ctx);\n\ttrace_xhci_setup_device_slot(slot_ctx);\n\n\tif (setup == SETUP_CONTEXT_ONLY) {\n\t\tif (GET_SLOT_STATE(le32_to_cpu(slot_ctx->dev_state)) ==\n\t\t    SLOT_STATE_DEFAULT) {\n\t\t\txhci_dbg(xhci, \"Slot already in default state\\n\");\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tcommand = xhci_alloc_command(xhci, true, GFP_KERNEL);\n\tif (!command) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tcommand->in_ctx = virt_dev->in_ctx;\n\n\tslot_ctx = xhci_get_slot_ctx(xhci, virt_dev->in_ctx);\n\tctrl_ctx = xhci_get_input_control_ctx(virt_dev->in_ctx);\n\tif (!ctrl_ctx) {\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\t \n\tif (!slot_ctx->dev_info)\n\t\txhci_setup_addressable_virt_dev(xhci, udev);\n\t \n\telse\n\t\txhci_copy_ep0_dequeue_into_input_ctx(xhci, udev);\n\tctrl_ctx->add_flags = cpu_to_le32(SLOT_FLAG | EP0_FLAG);\n\tctrl_ctx->drop_flags = 0;\n\n\ttrace_xhci_address_ctx(xhci, virt_dev->in_ctx,\n\t\t\t\tle32_to_cpu(slot_ctx->dev_info) >> 27);\n\n\ttrace_xhci_address_ctrl_ctx(ctrl_ctx);\n\tspin_lock_irqsave(&xhci->lock, flags);\n\ttrace_xhci_setup_device(virt_dev);\n\tret = xhci_queue_address_device(xhci, command, virt_dev->in_ctx->dma,\n\t\t\t\t\tudev->slot_id, setup);\n\tif (ret) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_address,\n\t\t\t\t\"FIXME: allocate a command ring segment\");\n\t\tgoto out;\n\t}\n\txhci_ring_cmd_db(xhci);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\t \n\twait_for_completion(command->completion);\n\n\t \n\tswitch (command->status) {\n\tcase COMP_COMMAND_ABORTED:\n\tcase COMP_COMMAND_RING_STOPPED:\n\t\txhci_warn(xhci, \"Timeout while waiting for setup device command\\n\");\n\t\tret = -ETIME;\n\t\tbreak;\n\tcase COMP_CONTEXT_STATE_ERROR:\n\tcase COMP_SLOT_NOT_ENABLED_ERROR:\n\t\txhci_err(xhci, \"Setup ERROR: setup %s command for slot %d.\\n\",\n\t\t\t act, udev->slot_id);\n\t\tret = -EINVAL;\n\t\tbreak;\n\tcase COMP_USB_TRANSACTION_ERROR:\n\t\tdev_warn(&udev->dev, \"Device not responding to setup %s.\\n\", act);\n\n\t\tmutex_unlock(&xhci->mutex);\n\t\tret = xhci_disable_slot(xhci, udev->slot_id);\n\t\txhci_free_virt_device(xhci, udev->slot_id);\n\t\tif (!ret)\n\t\t\txhci_alloc_dev(hcd, udev);\n\t\tkfree(command->completion);\n\t\tkfree(command);\n\t\treturn -EPROTO;\n\tcase COMP_INCOMPATIBLE_DEVICE_ERROR:\n\t\tdev_warn(&udev->dev,\n\t\t\t \"ERROR: Incompatible device for setup %s command\\n\", act);\n\t\tret = -ENODEV;\n\t\tbreak;\n\tcase COMP_SUCCESS:\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_address,\n\t\t\t       \"Successful setup %s command\", act);\n\t\tbreak;\n\tdefault:\n\t\txhci_err(xhci,\n\t\t\t \"ERROR: unexpected setup %s command completion code 0x%x.\\n\",\n\t\t\t act, command->status);\n\t\ttrace_xhci_address_ctx(xhci, virt_dev->out_ctx, 1);\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\tif (ret)\n\t\tgoto out;\n\ttemp_64 = xhci_read_64(xhci, &xhci->op_regs->dcbaa_ptr);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_address,\n\t\t\t\"Op regs DCBAA ptr = %#016llx\", temp_64);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_address,\n\t\t\"Slot ID %d dcbaa entry @%p = %#016llx\",\n\t\tudev->slot_id,\n\t\t&xhci->dcbaa->dev_context_ptrs[udev->slot_id],\n\t\t(unsigned long long)\n\t\tle64_to_cpu(xhci->dcbaa->dev_context_ptrs[udev->slot_id]));\n\txhci_dbg_trace(xhci, trace_xhci_dbg_address,\n\t\t\t\"Output Context DMA address = %#08llx\",\n\t\t\t(unsigned long long)virt_dev->out_ctx->dma);\n\ttrace_xhci_address_ctx(xhci, virt_dev->in_ctx,\n\t\t\t\tle32_to_cpu(slot_ctx->dev_info) >> 27);\n\t \n\ttrace_xhci_address_ctx(xhci, virt_dev->out_ctx,\n\t\t\t\tle32_to_cpu(slot_ctx->dev_info) >> 27);\n\t \n\tctrl_ctx->add_flags = 0;\n\tctrl_ctx->drop_flags = 0;\n\tslot_ctx = xhci_get_slot_ctx(xhci, virt_dev->out_ctx);\n\tudev->devaddr = (u8)(le32_to_cpu(slot_ctx->dev_state) & DEV_ADDR_MASK);\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_address,\n\t\t       \"Internal device address = %d\",\n\t\t       le32_to_cpu(slot_ctx->dev_state) & DEV_ADDR_MASK);\nout:\n\tmutex_unlock(&xhci->mutex);\n\tif (command) {\n\t\tkfree(command->completion);\n\t\tkfree(command);\n\t}\n\treturn ret;\n}\n\nstatic int xhci_address_device(struct usb_hcd *hcd, struct usb_device *udev)\n{\n\treturn xhci_setup_device(hcd, udev, SETUP_CONTEXT_ADDRESS);\n}\n\nstatic int xhci_enable_device(struct usb_hcd *hcd, struct usb_device *udev)\n{\n\treturn xhci_setup_device(hcd, udev, SETUP_CONTEXT_ONLY);\n}\n\n \nint xhci_find_raw_port_number(struct usb_hcd *hcd, int port1)\n{\n\tstruct xhci_hub *rhub;\n\n\trhub = xhci_get_rhub(hcd);\n\treturn rhub->ports[port1 - 1]->hw_portnum + 1;\n}\n\n \nstatic int __maybe_unused xhci_change_max_exit_latency(struct xhci_hcd *xhci,\n\t\t\tstruct usb_device *udev, u16 max_exit_latency)\n{\n\tstruct xhci_virt_device *virt_dev;\n\tstruct xhci_command *command;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tstruct xhci_slot_ctx *slot_ctx;\n\tunsigned long flags;\n\tint ret;\n\n\tcommand = xhci_alloc_command_with_ctx(xhci, true, GFP_KERNEL);\n\tif (!command)\n\t\treturn -ENOMEM;\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\tvirt_dev = xhci->devs[udev->slot_id];\n\n\t \n\n\tif (!virt_dev || max_exit_latency == virt_dev->current_mel) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_free_command(xhci, command);\n\t\treturn 0;\n\t}\n\n\t \n\tctrl_ctx = xhci_get_input_control_ctx(command->in_ctx);\n\tif (!ctrl_ctx) {\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\txhci_free_command(xhci, command);\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\treturn -ENOMEM;\n\t}\n\n\txhci_slot_copy(xhci, command->in_ctx, virt_dev->out_ctx);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\tctrl_ctx->add_flags |= cpu_to_le32(SLOT_FLAG);\n\tslot_ctx = xhci_get_slot_ctx(xhci, command->in_ctx);\n\tslot_ctx->dev_info2 &= cpu_to_le32(~((u32) MAX_EXIT));\n\tslot_ctx->dev_info2 |= cpu_to_le32(max_exit_latency);\n\tslot_ctx->dev_state = 0;\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_context_change,\n\t\t\t\"Set up evaluate context for LPM MEL change.\");\n\n\t \n\tret = xhci_configure_endpoint(xhci, udev, command,\n\t\t\ttrue, true);\n\n\tif (!ret) {\n\t\tspin_lock_irqsave(&xhci->lock, flags);\n\t\tvirt_dev->current_mel = max_exit_latency;\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t}\n\n\txhci_free_command(xhci, command);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_PM\n\n \nstatic int xhci_besl_encoding[16] = {125, 150, 200, 300, 400, 500, 1000, 2000,\n\t3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000};\n\n \nstatic int xhci_calculate_hird_besl(struct xhci_hcd *xhci,\n\t\t\t\t\tstruct usb_device *udev)\n{\n\tint u2del, besl, besl_host;\n\tint besl_device = 0;\n\tu32 field;\n\n\tu2del = HCS_U2_LATENCY(xhci->hcs_params3);\n\tfield = le32_to_cpu(udev->bos->ext_cap->bmAttributes);\n\n\tif (field & USB_BESL_SUPPORT) {\n\t\tfor (besl_host = 0; besl_host < 16; besl_host++) {\n\t\t\tif (xhci_besl_encoding[besl_host] >= u2del)\n\t\t\t\tbreak;\n\t\t}\n\t\t \n\t\tif (field & USB_BESL_BASELINE_VALID)\n\t\t\tbesl_device = USB_GET_BESL_BASELINE(field);\n\t\telse if (field & USB_BESL_DEEP_VALID)\n\t\t\tbesl_device = USB_GET_BESL_DEEP(field);\n\t} else {\n\t\tif (u2del <= 50)\n\t\t\tbesl_host = 0;\n\t\telse\n\t\t\tbesl_host = (u2del - 51) / 75 + 1;\n\t}\n\n\tbesl = besl_host + besl_device;\n\tif (besl > 15)\n\t\tbesl = 15;\n\n\treturn besl;\n}\n\n \nstatic int xhci_calculate_usb2_hw_lpm_params(struct usb_device *udev)\n{\n\tu32 field;\n\tint l1;\n\tint besld = 0;\n\tint hirdm = 0;\n\n\tfield = le32_to_cpu(udev->bos->ext_cap->bmAttributes);\n\n\t \n\tl1 = udev->l1_params.timeout / 256;\n\n\t \n\tif (field & USB_BESL_DEEP_VALID) {\n\t\tbesld = USB_GET_BESL_DEEP(field);\n\t\thirdm = 1;\n\t}\n\n\treturn PORT_BESLD(besld) | PORT_L1_TIMEOUT(l1) | PORT_HIRDM(hirdm);\n}\n\nstatic int xhci_set_usb2_hardware_lpm(struct usb_hcd *hcd,\n\t\t\tstruct usb_device *udev, int enable)\n{\n\tstruct xhci_hcd\t*xhci = hcd_to_xhci(hcd);\n\tstruct xhci_port **ports;\n\t__le32 __iomem\t*pm_addr, *hlpm_addr;\n\tu32\t\tpm_val, hlpm_val, field;\n\tunsigned int\tport_num;\n\tunsigned long\tflags;\n\tint\t\third, exit_latency;\n\tint\t\tret;\n\n\tif (xhci->quirks & XHCI_HW_LPM_DISABLE)\n\t\treturn -EPERM;\n\n\tif (hcd->speed >= HCD_USB3 || !xhci->hw_lpm_support ||\n\t\t\t!udev->lpm_capable)\n\t\treturn -EPERM;\n\n\tif (!udev->parent || udev->parent->parent ||\n\t\t\tudev->descriptor.bDeviceClass == USB_CLASS_HUB)\n\t\treturn -EPERM;\n\n\tif (udev->usb2_hw_lpm_capable != 1)\n\t\treturn -EPERM;\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\n\tports = xhci->usb2_rhub.ports;\n\tport_num = udev->portnum - 1;\n\tpm_addr = ports[port_num]->addr + PORTPMSC;\n\tpm_val = readl(pm_addr);\n\thlpm_addr = ports[port_num]->addr + PORTHLPMC;\n\n\txhci_dbg(xhci, \"%s port %d USB2 hardware LPM\\n\",\n\t\t\tenable ? \"enable\" : \"disable\", port_num + 1);\n\n\tif (enable) {\n\t\t \n\t\tif (udev->usb2_hw_lpm_besl_capable) {\n\t\t\t \n\t\t\tfield = le32_to_cpu(udev->bos->ext_cap->bmAttributes);\n\t\t\tif ((field & USB_BESL_SUPPORT) &&\n\t\t\t    (field & USB_BESL_BASELINE_VALID))\n\t\t\t\third = USB_GET_BESL_BASELINE(field);\n\t\t\telse\n\t\t\t\third = udev->l1_params.besl;\n\n\t\t\texit_latency = xhci_besl_encoding[hird];\n\t\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\t\t\tret = xhci_change_max_exit_latency(xhci, udev,\n\t\t\t\t\t\t\t   exit_latency);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tspin_lock_irqsave(&xhci->lock, flags);\n\n\t\t\thlpm_val = xhci_calculate_usb2_hw_lpm_params(udev);\n\t\t\twritel(hlpm_val, hlpm_addr);\n\t\t\t \n\t\t\treadl(hlpm_addr);\n\t\t} else {\n\t\t\third = xhci_calculate_hird_besl(xhci, udev);\n\t\t}\n\n\t\tpm_val &= ~PORT_HIRD_MASK;\n\t\tpm_val |= PORT_HIRD(hird) | PORT_RWE | PORT_L1DS(udev->slot_id);\n\t\twritel(pm_val, pm_addr);\n\t\tpm_val = readl(pm_addr);\n\t\tpm_val |= PORT_HLE;\n\t\twritel(pm_val, pm_addr);\n\t\t \n\t\treadl(pm_addr);\n\t} else {\n\t\tpm_val &= ~(PORT_HLE | PORT_RWE | PORT_HIRD_MASK | PORT_L1DS_MASK);\n\t\twritel(pm_val, pm_addr);\n\t\t \n\t\treadl(pm_addr);\n\t\tif (udev->usb2_hw_lpm_besl_capable) {\n\t\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\t\txhci_change_max_exit_latency(xhci, udev, 0);\n\t\t\treadl_poll_timeout(ports[port_num]->addr, pm_val,\n\t\t\t\t\t   (pm_val & PORT_PLS_MASK) == XDEV_U0,\n\t\t\t\t\t   100, 10000);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\treturn 0;\n}\n\n \nstatic int xhci_check_usb2_port_capability(struct xhci_hcd *xhci, int port,\n\t\t\t\t\t   unsigned capability)\n{\n\tu32 port_offset, port_count;\n\tint i;\n\n\tfor (i = 0; i < xhci->num_ext_caps; i++) {\n\t\tif (xhci->ext_caps[i] & capability) {\n\t\t\t \n\t\t\tport_offset = XHCI_EXT_PORT_OFF(xhci->ext_caps[i]) - 1;\n\t\t\tport_count = XHCI_EXT_PORT_COUNT(xhci->ext_caps[i]);\n\t\t\tif (port >= port_offset &&\n\t\t\t    port < port_offset + port_count)\n\t\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int xhci_update_device(struct usb_hcd *hcd, struct usb_device *udev)\n{\n\tstruct xhci_hcd\t*xhci = hcd_to_xhci(hcd);\n\tint\t\tportnum = udev->portnum - 1;\n\n\tif (hcd->speed >= HCD_USB3 || !udev->lpm_capable)\n\t\treturn 0;\n\n\t \n\tif (!udev->parent || udev->parent->parent ||\n\t\t\tudev->descriptor.bDeviceClass == USB_CLASS_HUB)\n\t\treturn 0;\n\n\tif (xhci->hw_lpm_support == 1 &&\n\t\t\txhci_check_usb2_port_capability(\n\t\t\t\txhci, portnum, XHCI_HLC)) {\n\t\tudev->usb2_hw_lpm_capable = 1;\n\t\tudev->l1_params.timeout = XHCI_L1_TIMEOUT;\n\t\tudev->l1_params.besl = XHCI_DEFAULT_BESL;\n\t\tif (xhci_check_usb2_port_capability(xhci, portnum,\n\t\t\t\t\tXHCI_BLC))\n\t\t\tudev->usb2_hw_lpm_besl_capable = 1;\n\t}\n\n\treturn 0;\n}\n\n \n\n \nstatic unsigned long long xhci_service_interval_to_ns(\n\t\tstruct usb_endpoint_descriptor *desc)\n{\n\treturn (1ULL << (desc->bInterval - 1)) * 125 * 1000;\n}\n\nstatic u16 xhci_get_timeout_no_hub_lpm(struct usb_device *udev,\n\t\tenum usb3_link_state state)\n{\n\tunsigned long long sel;\n\tunsigned long long pel;\n\tunsigned int max_sel_pel;\n\tchar *state_name;\n\n\tswitch (state) {\n\tcase USB3_LPM_U1:\n\t\t \n\t\tsel = DIV_ROUND_UP(udev->u1_params.sel, 1000);\n\t\tpel = DIV_ROUND_UP(udev->u1_params.pel, 1000);\n\t\tmax_sel_pel = USB3_LPM_MAX_U1_SEL_PEL;\n\t\tstate_name = \"U1\";\n\t\tbreak;\n\tcase USB3_LPM_U2:\n\t\tsel = DIV_ROUND_UP(udev->u2_params.sel, 1000);\n\t\tpel = DIV_ROUND_UP(udev->u2_params.pel, 1000);\n\t\tmax_sel_pel = USB3_LPM_MAX_U2_SEL_PEL;\n\t\tstate_name = \"U2\";\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(&udev->dev, \"%s: Can't get timeout for non-U1 or U2 state.\\n\",\n\t\t\t\t__func__);\n\t\treturn USB3_LPM_DISABLED;\n\t}\n\n\tif (sel <= max_sel_pel && pel <= max_sel_pel)\n\t\treturn USB3_LPM_DEVICE_INITIATED;\n\n\tif (sel > max_sel_pel)\n\t\tdev_dbg(&udev->dev, \"Device-initiated %s disabled \"\n\t\t\t\t\"due to long SEL %llu ms\\n\",\n\t\t\t\tstate_name, sel);\n\telse\n\t\tdev_dbg(&udev->dev, \"Device-initiated %s disabled \"\n\t\t\t\t\"due to long PEL %llu ms\\n\",\n\t\t\t\tstate_name, pel);\n\treturn USB3_LPM_DISABLED;\n}\n\n \nstatic unsigned long long xhci_calculate_intel_u1_timeout(\n\t\tstruct usb_device *udev,\n\t\tstruct usb_endpoint_descriptor *desc)\n{\n\tunsigned long long timeout_ns;\n\tint ep_type;\n\tint intr_type;\n\n\tep_type = usb_endpoint_type(desc);\n\tswitch (ep_type) {\n\tcase USB_ENDPOINT_XFER_CONTROL:\n\t\ttimeout_ns = udev->u1_params.sel * 3;\n\t\tbreak;\n\tcase USB_ENDPOINT_XFER_BULK:\n\t\ttimeout_ns = udev->u1_params.sel * 5;\n\t\tbreak;\n\tcase USB_ENDPOINT_XFER_INT:\n\t\tintr_type = usb_endpoint_interrupt_type(desc);\n\t\tif (intr_type == USB_ENDPOINT_INTR_NOTIFICATION) {\n\t\t\ttimeout_ns = udev->u1_params.sel * 3;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tfallthrough;\n\tcase USB_ENDPOINT_XFER_ISOC:\n\t\ttimeout_ns = xhci_service_interval_to_ns(desc);\n\t\ttimeout_ns = DIV_ROUND_UP_ULL(timeout_ns * 105, 100);\n\t\tif (timeout_ns < udev->u1_params.sel * 2)\n\t\t\ttimeout_ns = udev->u1_params.sel * 2;\n\t\tbreak;\n\tdefault:\n\t\treturn 0;\n\t}\n\n\treturn timeout_ns;\n}\n\n \nstatic u16 xhci_calculate_u1_timeout(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev,\n\t\tstruct usb_endpoint_descriptor *desc)\n{\n\tunsigned long long timeout_ns;\n\n\t \n\tif (usb_endpoint_xfer_int(desc) || usb_endpoint_xfer_isoc(desc)) {\n\t\tif (xhci_service_interval_to_ns(desc) <= udev->u1_params.mel) {\n\t\t\tdev_dbg(&udev->dev, \"Disable U1, ESIT shorter than exit latency\\n\");\n\t\t\treturn USB3_LPM_DISABLED;\n\t\t}\n\t}\n\n\tif (xhci->quirks & (XHCI_INTEL_HOST | XHCI_ZHAOXIN_HOST))\n\t\ttimeout_ns = xhci_calculate_intel_u1_timeout(udev, desc);\n\telse\n\t\ttimeout_ns = udev->u1_params.sel;\n\n\t \n\tif (timeout_ns == USB3_LPM_DISABLED)\n\t\ttimeout_ns = 1;\n\telse\n\t\ttimeout_ns = DIV_ROUND_UP_ULL(timeout_ns, 1000);\n\n\t \n\tif (timeout_ns <= USB3_LPM_U1_MAX_TIMEOUT)\n\t\treturn timeout_ns;\n\tdev_dbg(&udev->dev, \"Hub-initiated U1 disabled \"\n\t\t\t\"due to long timeout %llu ms\\n\", timeout_ns);\n\treturn xhci_get_timeout_no_hub_lpm(udev, USB3_LPM_U1);\n}\n\n \nstatic unsigned long long xhci_calculate_intel_u2_timeout(\n\t\tstruct usb_device *udev,\n\t\tstruct usb_endpoint_descriptor *desc)\n{\n\tunsigned long long timeout_ns;\n\tunsigned long long u2_del_ns;\n\n\ttimeout_ns = 10 * 1000 * 1000;\n\n\tif ((usb_endpoint_xfer_int(desc) || usb_endpoint_xfer_isoc(desc)) &&\n\t\t\t(xhci_service_interval_to_ns(desc) > timeout_ns))\n\t\ttimeout_ns = xhci_service_interval_to_ns(desc);\n\n\tu2_del_ns = le16_to_cpu(udev->bos->ss_cap->bU2DevExitLat) * 1000ULL;\n\tif (u2_del_ns > timeout_ns)\n\t\ttimeout_ns = u2_del_ns;\n\n\treturn timeout_ns;\n}\n\n \nstatic u16 xhci_calculate_u2_timeout(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev,\n\t\tstruct usb_endpoint_descriptor *desc)\n{\n\tunsigned long long timeout_ns;\n\n\t \n\tif (usb_endpoint_xfer_int(desc) || usb_endpoint_xfer_isoc(desc)) {\n\t\tif (xhci_service_interval_to_ns(desc) <= udev->u2_params.mel) {\n\t\t\tdev_dbg(&udev->dev, \"Disable U2, ESIT shorter than exit latency\\n\");\n\t\t\treturn USB3_LPM_DISABLED;\n\t\t}\n\t}\n\n\tif (xhci->quirks & (XHCI_INTEL_HOST | XHCI_ZHAOXIN_HOST))\n\t\ttimeout_ns = xhci_calculate_intel_u2_timeout(udev, desc);\n\telse\n\t\ttimeout_ns = udev->u2_params.sel;\n\n\t \n\ttimeout_ns = DIV_ROUND_UP_ULL(timeout_ns, 256 * 1000);\n\t \n\tif (timeout_ns <= USB3_LPM_U2_MAX_TIMEOUT)\n\t\treturn timeout_ns;\n\tdev_dbg(&udev->dev, \"Hub-initiated U2 disabled \"\n\t\t\t\"due to long timeout %llu ms\\n\", timeout_ns);\n\treturn xhci_get_timeout_no_hub_lpm(udev, USB3_LPM_U2);\n}\n\nstatic u16 xhci_call_host_update_timeout_for_endpoint(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev,\n\t\tstruct usb_endpoint_descriptor *desc,\n\t\tenum usb3_link_state state,\n\t\tu16 *timeout)\n{\n\tif (state == USB3_LPM_U1)\n\t\treturn xhci_calculate_u1_timeout(xhci, udev, desc);\n\telse if (state == USB3_LPM_U2)\n\t\treturn xhci_calculate_u2_timeout(xhci, udev, desc);\n\n\treturn USB3_LPM_DISABLED;\n}\n\nstatic int xhci_update_timeout_for_endpoint(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev,\n\t\tstruct usb_endpoint_descriptor *desc,\n\t\tenum usb3_link_state state,\n\t\tu16 *timeout)\n{\n\tu16 alt_timeout;\n\n\talt_timeout = xhci_call_host_update_timeout_for_endpoint(xhci, udev,\n\t\tdesc, state, timeout);\n\n\t \n\tif (alt_timeout == USB3_LPM_DISABLED) {\n\t\t*timeout = alt_timeout;\n\t\treturn -E2BIG;\n\t}\n\tif (alt_timeout > *timeout)\n\t\t*timeout = alt_timeout;\n\treturn 0;\n}\n\nstatic int xhci_update_timeout_for_interface(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev,\n\t\tstruct usb_host_interface *alt,\n\t\tenum usb3_link_state state,\n\t\tu16 *timeout)\n{\n\tint j;\n\n\tfor (j = 0; j < alt->desc.bNumEndpoints; j++) {\n\t\tif (xhci_update_timeout_for_endpoint(xhci, udev,\n\t\t\t\t\t&alt->endpoint[j].desc, state, timeout))\n\t\t\treturn -E2BIG;\n\t}\n\treturn 0;\n}\n\nstatic int xhci_check_tier_policy(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev,\n\t\tenum usb3_link_state state)\n{\n\tstruct usb_device *parent = udev->parent;\n\tint tier = 1;  \n\n\twhile (parent) {\n\t\tparent = parent->parent;\n\t\ttier++;\n\t}\n\n\tif (xhci->quirks & XHCI_INTEL_HOST && tier > 3)\n\t\tgoto fail;\n\tif (xhci->quirks & XHCI_ZHAOXIN_HOST && tier > 2)\n\t\tgoto fail;\n\n\treturn 0;\nfail:\n\tdev_dbg(&udev->dev, \"Tier policy prevents U1/U2 LPM states for devices at tier %d\\n\",\n\t\t\ttier);\n\treturn -E2BIG;\n}\n\n \nstatic u16 xhci_calculate_lpm_timeout(struct usb_hcd *hcd,\n\t\t\tstruct usb_device *udev, enum usb3_link_state state)\n{\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\tstruct usb_host_config *config;\n\tchar *state_name;\n\tint i;\n\tu16 timeout = USB3_LPM_DISABLED;\n\n\tif (state == USB3_LPM_U1)\n\t\tstate_name = \"U1\";\n\telse if (state == USB3_LPM_U2)\n\t\tstate_name = \"U2\";\n\telse {\n\t\tdev_warn(&udev->dev, \"Can't enable unknown link state %i\\n\",\n\t\t\t\tstate);\n\t\treturn timeout;\n\t}\n\n\t \n\tif (xhci_update_timeout_for_endpoint(xhci, udev, &udev->ep0.desc,\n\t\t\tstate, &timeout))\n\t\treturn timeout;\n\n\tconfig = udev->actconfig;\n\tif (!config)\n\t\treturn timeout;\n\n\tfor (i = 0; i < config->desc.bNumInterfaces; i++) {\n\t\tstruct usb_driver *driver;\n\t\tstruct usb_interface *intf = config->interface[i];\n\n\t\tif (!intf)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (intf->dev.driver) {\n\t\t\tdriver = to_usb_driver(intf->dev.driver);\n\t\t\tif (driver && driver->disable_hub_initiated_lpm) {\n\t\t\t\tdev_dbg(&udev->dev, \"Hub-initiated %s disabled at request of driver %s\\n\",\n\t\t\t\t\tstate_name, driver->name);\n\t\t\t\ttimeout = xhci_get_timeout_no_hub_lpm(udev,\n\t\t\t\t\t\t\t\t      state);\n\t\t\t\tif (timeout == USB3_LPM_DISABLED)\n\t\t\t\t\treturn timeout;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (!intf->cur_altsetting)\n\t\t\tcontinue;\n\n\t\tif (xhci_update_timeout_for_interface(xhci, udev,\n\t\t\t\t\tintf->cur_altsetting,\n\t\t\t\t\tstate, &timeout))\n\t\t\treturn timeout;\n\t}\n\treturn timeout;\n}\n\nstatic int calculate_max_exit_latency(struct usb_device *udev,\n\t\tenum usb3_link_state state_changed,\n\t\tu16 hub_encoded_timeout)\n{\n\tunsigned long long u1_mel_us = 0;\n\tunsigned long long u2_mel_us = 0;\n\tunsigned long long mel_us = 0;\n\tbool disabling_u1;\n\tbool disabling_u2;\n\tbool enabling_u1;\n\tbool enabling_u2;\n\n\tdisabling_u1 = (state_changed == USB3_LPM_U1 &&\n\t\t\thub_encoded_timeout == USB3_LPM_DISABLED);\n\tdisabling_u2 = (state_changed == USB3_LPM_U2 &&\n\t\t\thub_encoded_timeout == USB3_LPM_DISABLED);\n\n\tenabling_u1 = (state_changed == USB3_LPM_U1 &&\n\t\t\thub_encoded_timeout != USB3_LPM_DISABLED);\n\tenabling_u2 = (state_changed == USB3_LPM_U2 &&\n\t\t\thub_encoded_timeout != USB3_LPM_DISABLED);\n\n\t \n\tif ((udev->u1_params.timeout != USB3_LPM_DISABLED && !disabling_u1) ||\n\t\t\tenabling_u1)\n\t\tu1_mel_us = DIV_ROUND_UP(udev->u1_params.mel, 1000);\n\tif ((udev->u2_params.timeout != USB3_LPM_DISABLED && !disabling_u2) ||\n\t\t\tenabling_u2)\n\t\tu2_mel_us = DIV_ROUND_UP(udev->u2_params.mel, 1000);\n\n\tmel_us = max(u1_mel_us, u2_mel_us);\n\n\t \n\tif (mel_us > MAX_EXIT) {\n\t\tdev_warn(&udev->dev, \"Link PM max exit latency of %lluus \"\n\t\t\t\t\"is too big.\\n\", mel_us);\n\t\treturn -E2BIG;\n\t}\n\treturn mel_us;\n}\n\n \nstatic int xhci_enable_usb3_lpm_timeout(struct usb_hcd *hcd,\n\t\t\tstruct usb_device *udev, enum usb3_link_state state)\n{\n\tstruct xhci_hcd\t*xhci;\n\tstruct xhci_port *port;\n\tu16 hub_encoded_timeout;\n\tint mel;\n\tint ret;\n\n\txhci = hcd_to_xhci(hcd);\n\t \n\tif (!xhci || !(xhci->quirks & XHCI_LPM_SUPPORT) ||\n\t\t\t!xhci->devs[udev->slot_id])\n\t\treturn USB3_LPM_DISABLED;\n\n\tif (xhci_check_tier_policy(xhci, udev, state) < 0)\n\t\treturn USB3_LPM_DISABLED;\n\n\t \n\tif (udev->parent && !udev->parent->parent) {\n\t\tport = xhci->usb3_rhub.ports[udev->portnum - 1];\n\t\tif (port->lpm_incapable)\n\t\t\treturn USB3_LPM_DISABLED;\n\t}\n\n\thub_encoded_timeout = xhci_calculate_lpm_timeout(hcd, udev, state);\n\tmel = calculate_max_exit_latency(udev, state, hub_encoded_timeout);\n\tif (mel < 0) {\n\t\t \n\t\thub_encoded_timeout = USB3_LPM_DISABLED;\n\t\tmel = 0;\n\t}\n\n\tret = xhci_change_max_exit_latency(xhci, udev, mel);\n\tif (ret)\n\t\treturn ret;\n\treturn hub_encoded_timeout;\n}\n\nstatic int xhci_disable_usb3_lpm_timeout(struct usb_hcd *hcd,\n\t\t\tstruct usb_device *udev, enum usb3_link_state state)\n{\n\tstruct xhci_hcd\t*xhci;\n\tu16 mel;\n\n\txhci = hcd_to_xhci(hcd);\n\tif (!xhci || !(xhci->quirks & XHCI_LPM_SUPPORT) ||\n\t\t\t!xhci->devs[udev->slot_id])\n\t\treturn 0;\n\n\tmel = calculate_max_exit_latency(udev, state, USB3_LPM_DISABLED);\n\treturn xhci_change_max_exit_latency(xhci, udev, mel);\n}\n#else  \n\nstatic int xhci_set_usb2_hardware_lpm(struct usb_hcd *hcd,\n\t\t\t\tstruct usb_device *udev, int enable)\n{\n\treturn 0;\n}\n\nstatic int xhci_update_device(struct usb_hcd *hcd, struct usb_device *udev)\n{\n\treturn 0;\n}\n\nstatic int xhci_enable_usb3_lpm_timeout(struct usb_hcd *hcd,\n\t\t\tstruct usb_device *udev, enum usb3_link_state state)\n{\n\treturn USB3_LPM_DISABLED;\n}\n\nstatic int xhci_disable_usb3_lpm_timeout(struct usb_hcd *hcd,\n\t\t\tstruct usb_device *udev, enum usb3_link_state state)\n{\n\treturn 0;\n}\n#endif\t \n\n \n\n \nint xhci_update_hub_device(struct usb_hcd *hcd, struct usb_device *hdev,\n\t\t\tstruct usb_tt *tt, gfp_t mem_flags)\n{\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\tstruct xhci_virt_device *vdev;\n\tstruct xhci_command *config_cmd;\n\tstruct xhci_input_control_ctx *ctrl_ctx;\n\tstruct xhci_slot_ctx *slot_ctx;\n\tunsigned long flags;\n\tunsigned think_time;\n\tint ret;\n\n\t \n\tif (!hdev->parent)\n\t\treturn 0;\n\n\tvdev = xhci->devs[hdev->slot_id];\n\tif (!vdev) {\n\t\txhci_warn(xhci, \"Cannot update hub desc for unknown device.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tconfig_cmd = xhci_alloc_command_with_ctx(xhci, true, mem_flags);\n\tif (!config_cmd)\n\t\treturn -ENOMEM;\n\n\tctrl_ctx = xhci_get_input_control_ctx(config_cmd->in_ctx);\n\tif (!ctrl_ctx) {\n\t\txhci_warn(xhci, \"%s: Could not get input context, bad type.\\n\",\n\t\t\t\t__func__);\n\t\txhci_free_command(xhci, config_cmd);\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\tif (hdev->speed == USB_SPEED_HIGH &&\n\t\t\txhci_alloc_tt_info(xhci, vdev, hdev, tt, GFP_ATOMIC)) {\n\t\txhci_dbg(xhci, \"Could not allocate xHCI TT structure.\\n\");\n\t\txhci_free_command(xhci, config_cmd);\n\t\tspin_unlock_irqrestore(&xhci->lock, flags);\n\t\treturn -ENOMEM;\n\t}\n\n\txhci_slot_copy(xhci, config_cmd->in_ctx, vdev->out_ctx);\n\tctrl_ctx->add_flags |= cpu_to_le32(SLOT_FLAG);\n\tslot_ctx = xhci_get_slot_ctx(xhci, config_cmd->in_ctx);\n\tslot_ctx->dev_info |= cpu_to_le32(DEV_HUB);\n\t \n\tif (tt->multi)\n\t\tslot_ctx->dev_info |= cpu_to_le32(DEV_MTT);\n\telse if (hdev->speed == USB_SPEED_FULL)\n\t\tslot_ctx->dev_info &= cpu_to_le32(~DEV_MTT);\n\n\tif (xhci->hci_version > 0x95) {\n\t\txhci_dbg(xhci, \"xHCI version %x needs hub \"\n\t\t\t\t\"TT think time and number of ports\\n\",\n\t\t\t\t(unsigned int) xhci->hci_version);\n\t\tslot_ctx->dev_info2 |= cpu_to_le32(XHCI_MAX_PORTS(hdev->maxchild));\n\t\t \n\t\tthink_time = tt->think_time;\n\t\tif (think_time != 0)\n\t\t\tthink_time = (think_time / 666) - 1;\n\t\tif (xhci->hci_version < 0x100 || hdev->speed == USB_SPEED_HIGH)\n\t\t\tslot_ctx->tt_info |=\n\t\t\t\tcpu_to_le32(TT_THINK_TIME(think_time));\n\t} else {\n\t\txhci_dbg(xhci, \"xHCI version %x doesn't need hub \"\n\t\t\t\t\"TT think time or number of ports\\n\",\n\t\t\t\t(unsigned int) xhci->hci_version);\n\t}\n\tslot_ctx->dev_state = 0;\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n\n\txhci_dbg(xhci, \"Set up %s for hub device.\\n\",\n\t\t\t(xhci->hci_version > 0x95) ?\n\t\t\t\"configure endpoint\" : \"evaluate context\");\n\n\t \n\tif (xhci->hci_version > 0x95)\n\t\tret = xhci_configure_endpoint(xhci, hdev, config_cmd,\n\t\t\t\tfalse, false);\n\telse\n\t\tret = xhci_configure_endpoint(xhci, hdev, config_cmd,\n\t\t\t\ttrue, false);\n\n\txhci_free_command(xhci, config_cmd);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(xhci_update_hub_device);\n\nstatic int xhci_get_frame(struct usb_hcd *hcd)\n{\n\tstruct xhci_hcd *xhci = hcd_to_xhci(hcd);\n\t \n\treturn readl(&xhci->run_regs->microframe_index) >> 3;\n}\n\nstatic void xhci_hcd_init_usb2_data(struct xhci_hcd *xhci, struct usb_hcd *hcd)\n{\n\txhci->usb2_rhub.hcd = hcd;\n\thcd->speed = HCD_USB2;\n\thcd->self.root_hub->speed = USB_SPEED_HIGH;\n\t \n\thcd->has_tt = 1;\n}\n\nstatic void xhci_hcd_init_usb3_data(struct xhci_hcd *xhci, struct usb_hcd *hcd)\n{\n\tunsigned int minor_rev;\n\n\t \n\tif (xhci->usb3_rhub.min_rev == 0x1)\n\t\tminor_rev = 1;\n\telse\n\t\tminor_rev = xhci->usb3_rhub.min_rev / 0x10;\n\n\tswitch (minor_rev) {\n\tcase 2:\n\t\thcd->speed = HCD_USB32;\n\t\thcd->self.root_hub->speed = USB_SPEED_SUPER_PLUS;\n\t\thcd->self.root_hub->rx_lanes = 2;\n\t\thcd->self.root_hub->tx_lanes = 2;\n\t\thcd->self.root_hub->ssp_rate = USB_SSP_GEN_2x2;\n\t\tbreak;\n\tcase 1:\n\t\thcd->speed = HCD_USB31;\n\t\thcd->self.root_hub->speed = USB_SPEED_SUPER_PLUS;\n\t\thcd->self.root_hub->ssp_rate = USB_SSP_GEN_2x1;\n\t\tbreak;\n\t}\n\txhci_info(xhci, \"Host supports USB 3.%x %sSuperSpeed\\n\",\n\t\t  minor_rev, minor_rev ? \"Enhanced \" : \"\");\n\n\txhci->usb3_rhub.hcd = hcd;\n}\n\nint xhci_gen_setup(struct usb_hcd *hcd, xhci_get_quirks_t get_quirks)\n{\n\tstruct xhci_hcd\t\t*xhci;\n\t \n\tstruct device\t\t*dev = hcd->self.sysdev;\n\tint\t\t\tretval;\n\n\t \n\thcd->self.sg_tablesize = ~0;\n\n\t \n\thcd->self.no_sg_constraint = 1;\n\n\t \n\thcd->self.no_stop_on_short = 1;\n\n\txhci = hcd_to_xhci(hcd);\n\n\tif (!usb_hcd_is_primary_hcd(hcd)) {\n\t\txhci_hcd_init_usb3_data(xhci, hcd);\n\t\treturn 0;\n\t}\n\n\tmutex_init(&xhci->mutex);\n\txhci->main_hcd = hcd;\n\txhci->cap_regs = hcd->regs;\n\txhci->op_regs = hcd->regs +\n\t\tHC_LENGTH(readl(&xhci->cap_regs->hc_capbase));\n\txhci->run_regs = hcd->regs +\n\t\t(readl(&xhci->cap_regs->run_regs_off) & RTSOFF_MASK);\n\t \n\txhci->hcs_params1 = readl(&xhci->cap_regs->hcs_params1);\n\txhci->hcs_params2 = readl(&xhci->cap_regs->hcs_params2);\n\txhci->hcs_params3 = readl(&xhci->cap_regs->hcs_params3);\n\txhci->hci_version = HC_VERSION(readl(&xhci->cap_regs->hc_capbase));\n\txhci->hcc_params = readl(&xhci->cap_regs->hcc_params);\n\tif (xhci->hci_version > 0x100)\n\t\txhci->hcc_params2 = readl(&xhci->cap_regs->hcc_params2);\n\n\t \n\tif ((!xhci->max_interrupters) ||\n\t    xhci->max_interrupters > HCS_MAX_INTRS(xhci->hcs_params1))\n\t\txhci->max_interrupters = HCS_MAX_INTRS(xhci->hcs_params1);\n\n\txhci->quirks |= quirks;\n\n\tif (get_quirks)\n\t\tget_quirks(dev, xhci);\n\n\t \n\tif (xhci->hci_version > 0x96)\n\t\txhci->quirks |= XHCI_SPURIOUS_SUCCESS;\n\n\t \n\tretval = xhci_halt(xhci);\n\tif (retval)\n\t\treturn retval;\n\n\txhci_zero_64b_regs(xhci);\n\n\txhci_dbg(xhci, \"Resetting HCD\\n\");\n\t \n\tretval = xhci_reset(xhci, XHCI_RESET_LONG_USEC);\n\tif (retval)\n\t\treturn retval;\n\txhci_dbg(xhci, \"Reset complete\\n\");\n\n\t \n\tif (xhci->quirks & XHCI_NO_64BIT_SUPPORT)\n\t\txhci->hcc_params &= ~BIT(0);\n\n\t \n\tif (HCC_64BIT_ADDR(xhci->hcc_params) &&\n\t\t\t!dma_set_mask(dev, DMA_BIT_MASK(64))) {\n\t\txhci_dbg(xhci, \"Enabling 64-bit DMA addresses.\\n\");\n\t\tdma_set_coherent_mask(dev, DMA_BIT_MASK(64));\n\t} else {\n\t\t \n\t\tretval = dma_set_mask(dev, DMA_BIT_MASK(32));\n\t\tif (retval)\n\t\t\treturn retval;\n\t\txhci_dbg(xhci, \"Enabling 32-bit DMA addresses.\\n\");\n\t\tdma_set_coherent_mask(dev, DMA_BIT_MASK(32));\n\t}\n\n\txhci_dbg(xhci, \"Calling HCD init\\n\");\n\t \n\tretval = xhci_init(hcd);\n\tif (retval)\n\t\treturn retval;\n\txhci_dbg(xhci, \"Called HCD init\\n\");\n\n\tif (xhci_hcd_is_usb3(hcd))\n\t\txhci_hcd_init_usb3_data(xhci, hcd);\n\telse\n\t\txhci_hcd_init_usb2_data(xhci, hcd);\n\n\txhci_info(xhci, \"hcc params 0x%08x hci version 0x%x quirks 0x%016llx\\n\",\n\t\t  xhci->hcc_params, xhci->hci_version, xhci->quirks);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xhci_gen_setup);\n\nstatic void xhci_clear_tt_buffer_complete(struct usb_hcd *hcd,\n\t\tstruct usb_host_endpoint *ep)\n{\n\tstruct xhci_hcd *xhci;\n\tstruct usb_device *udev;\n\tunsigned int slot_id;\n\tunsigned int ep_index;\n\tunsigned long flags;\n\n\txhci = hcd_to_xhci(hcd);\n\n\tspin_lock_irqsave(&xhci->lock, flags);\n\tudev = (struct usb_device *)ep->hcpriv;\n\tslot_id = udev->slot_id;\n\tep_index = xhci_get_endpoint_index(&ep->desc);\n\n\txhci->devs[slot_id]->eps[ep_index].ep_state &= ~EP_CLEARING_TT;\n\txhci_ring_doorbell_for_active_rings(xhci, slot_id, ep_index);\n\tspin_unlock_irqrestore(&xhci->lock, flags);\n}\n\nstatic const struct hc_driver xhci_hc_driver = {\n\t.description =\t\t\"xhci-hcd\",\n\t.product_desc =\t\t\"xHCI Host Controller\",\n\t.hcd_priv_size =\tsizeof(struct xhci_hcd),\n\n\t \n\t.irq =\t\t\txhci_irq,\n\t.flags =\t\tHCD_MEMORY | HCD_DMA | HCD_USB3 | HCD_SHARED |\n\t\t\t\tHCD_BH,\n\n\t \n\t.reset =\t\tNULL,  \n\t.start =\t\txhci_run,\n\t.stop =\t\t\txhci_stop,\n\t.shutdown =\t\txhci_shutdown,\n\n\t \n\t.map_urb_for_dma =      xhci_map_urb_for_dma,\n\t.unmap_urb_for_dma =    xhci_unmap_urb_for_dma,\n\t.urb_enqueue =\t\txhci_urb_enqueue,\n\t.urb_dequeue =\t\txhci_urb_dequeue,\n\t.alloc_dev =\t\txhci_alloc_dev,\n\t.free_dev =\t\txhci_free_dev,\n\t.alloc_streams =\txhci_alloc_streams,\n\t.free_streams =\t\txhci_free_streams,\n\t.add_endpoint =\t\txhci_add_endpoint,\n\t.drop_endpoint =\txhci_drop_endpoint,\n\t.endpoint_disable =\txhci_endpoint_disable,\n\t.endpoint_reset =\txhci_endpoint_reset,\n\t.check_bandwidth =\txhci_check_bandwidth,\n\t.reset_bandwidth =\txhci_reset_bandwidth,\n\t.address_device =\txhci_address_device,\n\t.enable_device =\txhci_enable_device,\n\t.update_hub_device =\txhci_update_hub_device,\n\t.reset_device =\t\txhci_discover_or_reset_device,\n\n\t \n\t.get_frame_number =\txhci_get_frame,\n\n\t \n\t.hub_control =\t\txhci_hub_control,\n\t.hub_status_data =\txhci_hub_status_data,\n\t.bus_suspend =\t\txhci_bus_suspend,\n\t.bus_resume =\t\txhci_bus_resume,\n\t.get_resuming_ports =\txhci_get_resuming_ports,\n\n\t \n\t.update_device =        xhci_update_device,\n\t.set_usb2_hw_lpm =\txhci_set_usb2_hardware_lpm,\n\t.enable_usb3_lpm_timeout =\txhci_enable_usb3_lpm_timeout,\n\t.disable_usb3_lpm_timeout =\txhci_disable_usb3_lpm_timeout,\n\t.find_raw_port_number =\txhci_find_raw_port_number,\n\t.clear_tt_buffer_complete = xhci_clear_tt_buffer_complete,\n};\n\nvoid xhci_init_driver(struct hc_driver *drv,\n\t\t      const struct xhci_driver_overrides *over)\n{\n\tBUG_ON(!over);\n\n\t \n\t*drv = xhci_hc_driver;\n\n\tif (over) {\n\t\tdrv->hcd_priv_size += over->extra_priv_size;\n\t\tif (over->reset)\n\t\t\tdrv->reset = over->reset;\n\t\tif (over->start)\n\t\t\tdrv->start = over->start;\n\t\tif (over->add_endpoint)\n\t\t\tdrv->add_endpoint = over->add_endpoint;\n\t\tif (over->drop_endpoint)\n\t\t\tdrv->drop_endpoint = over->drop_endpoint;\n\t\tif (over->check_bandwidth)\n\t\t\tdrv->check_bandwidth = over->check_bandwidth;\n\t\tif (over->reset_bandwidth)\n\t\t\tdrv->reset_bandwidth = over->reset_bandwidth;\n\t\tif (over->update_hub_device)\n\t\t\tdrv->update_hub_device = over->update_hub_device;\n\t\tif (over->hub_control)\n\t\t\tdrv->hub_control = over->hub_control;\n\t}\n}\nEXPORT_SYMBOL_GPL(xhci_init_driver);\n\nMODULE_DESCRIPTION(DRIVER_DESC);\nMODULE_AUTHOR(DRIVER_AUTHOR);\nMODULE_LICENSE(\"GPL\");\n\nstatic int __init xhci_hcd_init(void)\n{\n\t \n\tBUILD_BUG_ON(sizeof(struct xhci_doorbell_array) != 256*32/8);\n\tBUILD_BUG_ON(sizeof(struct xhci_slot_ctx) != 8*32/8);\n\tBUILD_BUG_ON(sizeof(struct xhci_ep_ctx) != 8*32/8);\n\t \n\tBUILD_BUG_ON(sizeof(struct xhci_stream_ctx) != 4*32/8);\n\tBUILD_BUG_ON(sizeof(union xhci_trb) != 4*32/8);\n\tBUILD_BUG_ON(sizeof(struct xhci_erst_entry) != 4*32/8);\n\tBUILD_BUG_ON(sizeof(struct xhci_cap_regs) != 8*32/8);\n\tBUILD_BUG_ON(sizeof(struct xhci_intr_reg) != 8*32/8);\n\t \n\tBUILD_BUG_ON(sizeof(struct xhci_run_regs) != (8+8*128)*32/8);\n\n\tif (usb_disabled())\n\t\treturn -ENODEV;\n\n\txhci_debugfs_create_root();\n\txhci_dbc_init();\n\n\treturn 0;\n}\n\n \nstatic void __exit xhci_hcd_fini(void)\n{\n\txhci_debugfs_remove_root();\n\txhci_dbc_exit();\n}\n\nmodule_init(xhci_hcd_init);\nmodule_exit(xhci_hcd_fini);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}