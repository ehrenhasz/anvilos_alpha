{
  "module_name": "xhci-mem.c",
  "hash_id": "eeebf86db36da9858850dc804881866f59231eb070a60e16ec8cf84ec6487c38",
  "original_prompt": "Ingested from linux-6.6.14/drivers/usb/host/xhci-mem.c",
  "human_readable_source": "\n \n\n#include <linux/usb.h>\n#include <linux/overflow.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include <linux/dmapool.h>\n#include <linux/dma-mapping.h>\n\n#include \"xhci.h\"\n#include \"xhci-trace.h\"\n#include \"xhci-debugfs.h\"\n\n \nstatic struct xhci_segment *xhci_segment_alloc(struct xhci_hcd *xhci,\n\t\t\t\t\t       unsigned int cycle_state,\n\t\t\t\t\t       unsigned int max_packet,\n\t\t\t\t\t       gfp_t flags)\n{\n\tstruct xhci_segment *seg;\n\tdma_addr_t\tdma;\n\tint\t\ti;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\n\tseg = kzalloc_node(sizeof(*seg), flags, dev_to_node(dev));\n\tif (!seg)\n\t\treturn NULL;\n\n\tseg->trbs = dma_pool_zalloc(xhci->segment_pool, flags, &dma);\n\tif (!seg->trbs) {\n\t\tkfree(seg);\n\t\treturn NULL;\n\t}\n\n\tif (max_packet) {\n\t\tseg->bounce_buf = kzalloc_node(max_packet, flags,\n\t\t\t\t\tdev_to_node(dev));\n\t\tif (!seg->bounce_buf) {\n\t\t\tdma_pool_free(xhci->segment_pool, seg->trbs, dma);\n\t\t\tkfree(seg);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\t \n\tif (cycle_state == 0) {\n\t\tfor (i = 0; i < TRBS_PER_SEGMENT; i++)\n\t\t\tseg->trbs[i].link.control = cpu_to_le32(TRB_CYCLE);\n\t}\n\tseg->dma = dma;\n\tseg->next = NULL;\n\n\treturn seg;\n}\n\nstatic void xhci_segment_free(struct xhci_hcd *xhci, struct xhci_segment *seg)\n{\n\tif (seg->trbs) {\n\t\tdma_pool_free(xhci->segment_pool, seg->trbs, seg->dma);\n\t\tseg->trbs = NULL;\n\t}\n\tkfree(seg->bounce_buf);\n\tkfree(seg);\n}\n\nstatic void xhci_free_segments_for_ring(struct xhci_hcd *xhci,\n\t\t\t\tstruct xhci_segment *first)\n{\n\tstruct xhci_segment *seg;\n\n\tseg = first->next;\n\twhile (seg != first) {\n\t\tstruct xhci_segment *next = seg->next;\n\t\txhci_segment_free(xhci, seg);\n\t\tseg = next;\n\t}\n\txhci_segment_free(xhci, first);\n}\n\n \nstatic void xhci_link_segments(struct xhci_segment *prev,\n\t\t\t       struct xhci_segment *next,\n\t\t\t       enum xhci_ring_type type, bool chain_links)\n{\n\tu32 val;\n\n\tif (!prev || !next)\n\t\treturn;\n\tprev->next = next;\n\tif (type != TYPE_EVENT) {\n\t\tprev->trbs[TRBS_PER_SEGMENT-1].link.segment_ptr =\n\t\t\tcpu_to_le64(next->dma);\n\n\t\t \n\t\tval = le32_to_cpu(prev->trbs[TRBS_PER_SEGMENT-1].link.control);\n\t\tval &= ~TRB_TYPE_BITMASK;\n\t\tval |= TRB_TYPE(TRB_LINK);\n\t\tif (chain_links)\n\t\t\tval |= TRB_CHAIN;\n\t\tprev->trbs[TRBS_PER_SEGMENT-1].link.control = cpu_to_le32(val);\n\t}\n}\n\n \nstatic void xhci_link_rings(struct xhci_hcd *xhci, struct xhci_ring *ring,\n\t\tstruct xhci_segment *first, struct xhci_segment *last,\n\t\tunsigned int num_segs)\n{\n\tstruct xhci_segment *next;\n\tbool chain_links;\n\n\tif (!ring || !first || !last)\n\t\treturn;\n\n\t \n\tchain_links = !!(xhci_link_trb_quirk(xhci) ||\n\t\t\t (ring->type == TYPE_ISOC &&\n\t\t\t  (xhci->quirks & XHCI_AMD_0x96_HOST)));\n\n\tnext = ring->enq_seg->next;\n\txhci_link_segments(ring->enq_seg, first, ring->type, chain_links);\n\txhci_link_segments(last, next, ring->type, chain_links);\n\tring->num_segs += num_segs;\n\n\tif (ring->type != TYPE_EVENT && ring->enq_seg == ring->last_seg) {\n\t\tring->last_seg->trbs[TRBS_PER_SEGMENT-1].link.control\n\t\t\t&= ~cpu_to_le32(LINK_TOGGLE);\n\t\tlast->trbs[TRBS_PER_SEGMENT-1].link.control\n\t\t\t|= cpu_to_le32(LINK_TOGGLE);\n\t\tring->last_seg = last;\n\t}\n}\n\n \nstatic int xhci_insert_segment_mapping(struct radix_tree_root *trb_address_map,\n\t\tstruct xhci_ring *ring,\n\t\tstruct xhci_segment *seg,\n\t\tgfp_t mem_flags)\n{\n\tunsigned long key;\n\tint ret;\n\n\tkey = (unsigned long)(seg->dma >> TRB_SEGMENT_SHIFT);\n\t \n\tif (radix_tree_lookup(trb_address_map, key))\n\t\treturn 0;\n\n\tret = radix_tree_maybe_preload(mem_flags);\n\tif (ret)\n\t\treturn ret;\n\tret = radix_tree_insert(trb_address_map,\n\t\t\tkey, ring);\n\tradix_tree_preload_end();\n\treturn ret;\n}\n\nstatic void xhci_remove_segment_mapping(struct radix_tree_root *trb_address_map,\n\t\tstruct xhci_segment *seg)\n{\n\tunsigned long key;\n\n\tkey = (unsigned long)(seg->dma >> TRB_SEGMENT_SHIFT);\n\tif (radix_tree_lookup(trb_address_map, key))\n\t\tradix_tree_delete(trb_address_map, key);\n}\n\nstatic int xhci_update_stream_segment_mapping(\n\t\tstruct radix_tree_root *trb_address_map,\n\t\tstruct xhci_ring *ring,\n\t\tstruct xhci_segment *first_seg,\n\t\tstruct xhci_segment *last_seg,\n\t\tgfp_t mem_flags)\n{\n\tstruct xhci_segment *seg;\n\tstruct xhci_segment *failed_seg;\n\tint ret;\n\n\tif (WARN_ON_ONCE(trb_address_map == NULL))\n\t\treturn 0;\n\n\tseg = first_seg;\n\tdo {\n\t\tret = xhci_insert_segment_mapping(trb_address_map,\n\t\t\t\tring, seg, mem_flags);\n\t\tif (ret)\n\t\t\tgoto remove_streams;\n\t\tif (seg == last_seg)\n\t\t\treturn 0;\n\t\tseg = seg->next;\n\t} while (seg != first_seg);\n\n\treturn 0;\n\nremove_streams:\n\tfailed_seg = seg;\n\tseg = first_seg;\n\tdo {\n\t\txhci_remove_segment_mapping(trb_address_map, seg);\n\t\tif (seg == failed_seg)\n\t\t\treturn ret;\n\t\tseg = seg->next;\n\t} while (seg != first_seg);\n\n\treturn ret;\n}\n\nstatic void xhci_remove_stream_mapping(struct xhci_ring *ring)\n{\n\tstruct xhci_segment *seg;\n\n\tif (WARN_ON_ONCE(ring->trb_address_map == NULL))\n\t\treturn;\n\n\tseg = ring->first_seg;\n\tdo {\n\t\txhci_remove_segment_mapping(ring->trb_address_map, seg);\n\t\tseg = seg->next;\n\t} while (seg != ring->first_seg);\n}\n\nstatic int xhci_update_stream_mapping(struct xhci_ring *ring, gfp_t mem_flags)\n{\n\treturn xhci_update_stream_segment_mapping(ring->trb_address_map, ring,\n\t\t\tring->first_seg, ring->last_seg, mem_flags);\n}\n\n \nvoid xhci_ring_free(struct xhci_hcd *xhci, struct xhci_ring *ring)\n{\n\tif (!ring)\n\t\treturn;\n\n\ttrace_xhci_ring_free(ring);\n\n\tif (ring->first_seg) {\n\t\tif (ring->type == TYPE_STREAM)\n\t\t\txhci_remove_stream_mapping(ring);\n\t\txhci_free_segments_for_ring(xhci, ring->first_seg);\n\t}\n\n\tkfree(ring);\n}\n\nvoid xhci_initialize_ring_info(struct xhci_ring *ring,\n\t\t\t       unsigned int cycle_state)\n{\n\t \n\tring->enqueue = ring->first_seg->trbs;\n\tring->enq_seg = ring->first_seg;\n\tring->dequeue = ring->enqueue;\n\tring->deq_seg = ring->first_seg;\n\t \n\tring->cycle_state = cycle_state;\n\n\t \n\tring->num_trbs_free = ring->num_segs * (TRBS_PER_SEGMENT - 1) - 1;\n}\n\n \nstatic int xhci_alloc_segments_for_ring(struct xhci_hcd *xhci,\n\t\tstruct xhci_segment **first, struct xhci_segment **last,\n\t\tunsigned int num_segs, unsigned int cycle_state,\n\t\tenum xhci_ring_type type, unsigned int max_packet, gfp_t flags)\n{\n\tstruct xhci_segment *prev;\n\tbool chain_links;\n\n\t \n\tchain_links = !!(xhci_link_trb_quirk(xhci) ||\n\t\t\t (type == TYPE_ISOC &&\n\t\t\t  (xhci->quirks & XHCI_AMD_0x96_HOST)));\n\n\tprev = xhci_segment_alloc(xhci, cycle_state, max_packet, flags);\n\tif (!prev)\n\t\treturn -ENOMEM;\n\tnum_segs--;\n\n\t*first = prev;\n\twhile (num_segs > 0) {\n\t\tstruct xhci_segment\t*next;\n\n\t\tnext = xhci_segment_alloc(xhci, cycle_state, max_packet, flags);\n\t\tif (!next) {\n\t\t\tprev = *first;\n\t\t\twhile (prev) {\n\t\t\t\tnext = prev->next;\n\t\t\t\txhci_segment_free(xhci, prev);\n\t\t\t\tprev = next;\n\t\t\t}\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\txhci_link_segments(prev, next, type, chain_links);\n\n\t\tprev = next;\n\t\tnum_segs--;\n\t}\n\txhci_link_segments(prev, *first, type, chain_links);\n\t*last = prev;\n\n\treturn 0;\n}\n\n \nstruct xhci_ring *xhci_ring_alloc(struct xhci_hcd *xhci,\n\t\tunsigned int num_segs, unsigned int cycle_state,\n\t\tenum xhci_ring_type type, unsigned int max_packet, gfp_t flags)\n{\n\tstruct xhci_ring\t*ring;\n\tint ret;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\n\tring = kzalloc_node(sizeof(*ring), flags, dev_to_node(dev));\n\tif (!ring)\n\t\treturn NULL;\n\n\tring->num_segs = num_segs;\n\tring->bounce_buf_len = max_packet;\n\tINIT_LIST_HEAD(&ring->td_list);\n\tring->type = type;\n\tif (num_segs == 0)\n\t\treturn ring;\n\n\tret = xhci_alloc_segments_for_ring(xhci, &ring->first_seg,\n\t\t\t&ring->last_seg, num_segs, cycle_state, type,\n\t\t\tmax_packet, flags);\n\tif (ret)\n\t\tgoto fail;\n\n\t \n\tif (type != TYPE_EVENT) {\n\t\t \n\t\tring->last_seg->trbs[TRBS_PER_SEGMENT - 1].link.control |=\n\t\t\tcpu_to_le32(LINK_TOGGLE);\n\t}\n\txhci_initialize_ring_info(ring, cycle_state);\n\ttrace_xhci_ring_alloc(ring);\n\treturn ring;\n\nfail:\n\tkfree(ring);\n\treturn NULL;\n}\n\nvoid xhci_free_endpoint_ring(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev,\n\t\tunsigned int ep_index)\n{\n\txhci_ring_free(xhci, virt_dev->eps[ep_index].ring);\n\tvirt_dev->eps[ep_index].ring = NULL;\n}\n\n \nint xhci_ring_expansion(struct xhci_hcd *xhci, struct xhci_ring *ring,\n\t\t\t\tunsigned int num_new_segs, gfp_t flags)\n{\n\tstruct xhci_segment\t*first;\n\tstruct xhci_segment\t*last;\n\tint\t\t\tret;\n\n\tret = xhci_alloc_segments_for_ring(xhci, &first, &last,\n\t\t\tnum_new_segs, ring->cycle_state, ring->type,\n\t\t\tring->bounce_buf_len, flags);\n\tif (ret)\n\t\treturn -ENOMEM;\n\n\tif (ring->type == TYPE_STREAM)\n\t\tret = xhci_update_stream_segment_mapping(ring->trb_address_map,\n\t\t\t\t\t\tring, first, last, flags);\n\tif (ret) {\n\t\tstruct xhci_segment *next;\n\t\tdo {\n\t\t\tnext = first->next;\n\t\t\txhci_segment_free(xhci, first);\n\t\t\tif (first == last)\n\t\t\t\tbreak;\n\t\t\tfirst = next;\n\t\t} while (true);\n\t\treturn ret;\n\t}\n\n\txhci_link_rings(xhci, ring, first, last, num_new_segs);\n\ttrace_xhci_ring_expansion(ring);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_ring_expansion,\n\t\t\t\"ring expansion succeed, now has %d segments\",\n\t\t\tring->num_segs);\n\n\treturn 0;\n}\n\nstruct xhci_container_ctx *xhci_alloc_container_ctx(struct xhci_hcd *xhci,\n\t\t\t\t\t\t    int type, gfp_t flags)\n{\n\tstruct xhci_container_ctx *ctx;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\n\tif ((type != XHCI_CTX_TYPE_DEVICE) && (type != XHCI_CTX_TYPE_INPUT))\n\t\treturn NULL;\n\n\tctx = kzalloc_node(sizeof(*ctx), flags, dev_to_node(dev));\n\tif (!ctx)\n\t\treturn NULL;\n\n\tctx->type = type;\n\tctx->size = HCC_64BYTE_CONTEXT(xhci->hcc_params) ? 2048 : 1024;\n\tif (type == XHCI_CTX_TYPE_INPUT)\n\t\tctx->size += CTX_SIZE(xhci->hcc_params);\n\n\tctx->bytes = dma_pool_zalloc(xhci->device_pool, flags, &ctx->dma);\n\tif (!ctx->bytes) {\n\t\tkfree(ctx);\n\t\treturn NULL;\n\t}\n\treturn ctx;\n}\n\nvoid xhci_free_container_ctx(struct xhci_hcd *xhci,\n\t\t\t     struct xhci_container_ctx *ctx)\n{\n\tif (!ctx)\n\t\treturn;\n\tdma_pool_free(xhci->device_pool, ctx->bytes, ctx->dma);\n\tkfree(ctx);\n}\n\nstruct xhci_input_control_ctx *xhci_get_input_control_ctx(\n\t\t\t\t\t      struct xhci_container_ctx *ctx)\n{\n\tif (ctx->type != XHCI_CTX_TYPE_INPUT)\n\t\treturn NULL;\n\n\treturn (struct xhci_input_control_ctx *)ctx->bytes;\n}\n\nstruct xhci_slot_ctx *xhci_get_slot_ctx(struct xhci_hcd *xhci,\n\t\t\t\t\tstruct xhci_container_ctx *ctx)\n{\n\tif (ctx->type == XHCI_CTX_TYPE_DEVICE)\n\t\treturn (struct xhci_slot_ctx *)ctx->bytes;\n\n\treturn (struct xhci_slot_ctx *)\n\t\t(ctx->bytes + CTX_SIZE(xhci->hcc_params));\n}\n\nstruct xhci_ep_ctx *xhci_get_ep_ctx(struct xhci_hcd *xhci,\n\t\t\t\t    struct xhci_container_ctx *ctx,\n\t\t\t\t    unsigned int ep_index)\n{\n\t \n\tep_index++;\n\tif (ctx->type == XHCI_CTX_TYPE_INPUT)\n\t\tep_index++;\n\n\treturn (struct xhci_ep_ctx *)\n\t\t(ctx->bytes + (ep_index * CTX_SIZE(xhci->hcc_params)));\n}\nEXPORT_SYMBOL_GPL(xhci_get_ep_ctx);\n\n \n\nstatic void xhci_free_stream_ctx(struct xhci_hcd *xhci,\n\t\tunsigned int num_stream_ctxs,\n\t\tstruct xhci_stream_ctx *stream_ctx, dma_addr_t dma)\n{\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\tsize_t size = sizeof(struct xhci_stream_ctx) * num_stream_ctxs;\n\n\tif (size > MEDIUM_STREAM_ARRAY_SIZE)\n\t\tdma_free_coherent(dev, size, stream_ctx, dma);\n\telse if (size > SMALL_STREAM_ARRAY_SIZE)\n\t\tdma_pool_free(xhci->medium_streams_pool, stream_ctx, dma);\n\telse\n\t\tdma_pool_free(xhci->small_streams_pool, stream_ctx, dma);\n}\n\n \nstatic struct xhci_stream_ctx *xhci_alloc_stream_ctx(struct xhci_hcd *xhci,\n\t\tunsigned int num_stream_ctxs, dma_addr_t *dma,\n\t\tgfp_t mem_flags)\n{\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\tsize_t size = size_mul(sizeof(struct xhci_stream_ctx), num_stream_ctxs);\n\n\tif (size > MEDIUM_STREAM_ARRAY_SIZE)\n\t\treturn dma_alloc_coherent(dev, size, dma, mem_flags);\n\tif (size > SMALL_STREAM_ARRAY_SIZE)\n\t\treturn dma_pool_zalloc(xhci->medium_streams_pool, mem_flags, dma);\n\telse\n\t\treturn dma_pool_zalloc(xhci->small_streams_pool, mem_flags, dma);\n}\n\nstruct xhci_ring *xhci_dma_to_transfer_ring(\n\t\tstruct xhci_virt_ep *ep,\n\t\tu64 address)\n{\n\tif (ep->ep_state & EP_HAS_STREAMS)\n\t\treturn radix_tree_lookup(&ep->stream_info->trb_address_map,\n\t\t\t\taddress >> TRB_SEGMENT_SHIFT);\n\treturn ep->ring;\n}\n\n \nstruct xhci_stream_info *xhci_alloc_stream_info(struct xhci_hcd *xhci,\n\t\tunsigned int num_stream_ctxs,\n\t\tunsigned int num_streams,\n\t\tunsigned int max_packet, gfp_t mem_flags)\n{\n\tstruct xhci_stream_info *stream_info;\n\tu32 cur_stream;\n\tstruct xhci_ring *cur_ring;\n\tu64 addr;\n\tint ret;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\n\txhci_dbg(xhci, \"Allocating %u streams and %u stream context array entries.\\n\",\n\t\t\tnum_streams, num_stream_ctxs);\n\tif (xhci->cmd_ring_reserved_trbs == MAX_RSVD_CMD_TRBS) {\n\t\txhci_dbg(xhci, \"Command ring has no reserved TRBs available\\n\");\n\t\treturn NULL;\n\t}\n\txhci->cmd_ring_reserved_trbs++;\n\n\tstream_info = kzalloc_node(sizeof(*stream_info), mem_flags,\n\t\t\tdev_to_node(dev));\n\tif (!stream_info)\n\t\tgoto cleanup_trbs;\n\n\tstream_info->num_streams = num_streams;\n\tstream_info->num_stream_ctxs = num_stream_ctxs;\n\n\t \n\tstream_info->stream_rings = kcalloc_node(\n\t\t\tnum_streams, sizeof(struct xhci_ring *), mem_flags,\n\t\t\tdev_to_node(dev));\n\tif (!stream_info->stream_rings)\n\t\tgoto cleanup_info;\n\n\t \n\tstream_info->stream_ctx_array = xhci_alloc_stream_ctx(xhci,\n\t\t\tnum_stream_ctxs, &stream_info->ctx_array_dma,\n\t\t\tmem_flags);\n\tif (!stream_info->stream_ctx_array)\n\t\tgoto cleanup_ring_array;\n\n\t \n\tstream_info->free_streams_command =\n\t\txhci_alloc_command_with_ctx(xhci, true, mem_flags);\n\tif (!stream_info->free_streams_command)\n\t\tgoto cleanup_ctx;\n\n\tINIT_RADIX_TREE(&stream_info->trb_address_map, GFP_ATOMIC);\n\n\t \n\n\tfor (cur_stream = 1; cur_stream < num_streams; cur_stream++) {\n\t\tstream_info->stream_rings[cur_stream] =\n\t\t\txhci_ring_alloc(xhci, 2, 1, TYPE_STREAM, max_packet,\n\t\t\t\t\tmem_flags);\n\t\tcur_ring = stream_info->stream_rings[cur_stream];\n\t\tif (!cur_ring)\n\t\t\tgoto cleanup_rings;\n\t\tcur_ring->stream_id = cur_stream;\n\t\tcur_ring->trb_address_map = &stream_info->trb_address_map;\n\t\t \n\t\taddr = cur_ring->first_seg->dma |\n\t\t\tSCT_FOR_CTX(SCT_PRI_TR) |\n\t\t\tcur_ring->cycle_state;\n\t\tstream_info->stream_ctx_array[cur_stream].stream_ring =\n\t\t\tcpu_to_le64(addr);\n\t\txhci_dbg(xhci, \"Setting stream %d ring ptr to 0x%08llx\\n\", cur_stream, addr);\n\n\t\tret = xhci_update_stream_mapping(cur_ring, mem_flags);\n\t\tif (ret) {\n\t\t\txhci_ring_free(xhci, cur_ring);\n\t\t\tstream_info->stream_rings[cur_stream] = NULL;\n\t\t\tgoto cleanup_rings;\n\t\t}\n\t}\n\t \n\n\treturn stream_info;\n\ncleanup_rings:\n\tfor (cur_stream = 1; cur_stream < num_streams; cur_stream++) {\n\t\tcur_ring = stream_info->stream_rings[cur_stream];\n\t\tif (cur_ring) {\n\t\t\txhci_ring_free(xhci, cur_ring);\n\t\t\tstream_info->stream_rings[cur_stream] = NULL;\n\t\t}\n\t}\n\txhci_free_command(xhci, stream_info->free_streams_command);\ncleanup_ctx:\n\txhci_free_stream_ctx(xhci,\n\t\tstream_info->num_stream_ctxs,\n\t\tstream_info->stream_ctx_array,\n\t\tstream_info->ctx_array_dma);\ncleanup_ring_array:\n\tkfree(stream_info->stream_rings);\ncleanup_info:\n\tkfree(stream_info);\ncleanup_trbs:\n\txhci->cmd_ring_reserved_trbs--;\n\treturn NULL;\n}\n \nvoid xhci_setup_streams_ep_input_ctx(struct xhci_hcd *xhci,\n\t\tstruct xhci_ep_ctx *ep_ctx,\n\t\tstruct xhci_stream_info *stream_info)\n{\n\tu32 max_primary_streams;\n\t \n\tmax_primary_streams = fls(stream_info->num_stream_ctxs) - 2;\n\txhci_dbg_trace(xhci,  trace_xhci_dbg_context_change,\n\t\t\t\"Setting number of stream ctx array entries to %u\",\n\t\t\t1 << (max_primary_streams + 1));\n\tep_ctx->ep_info &= cpu_to_le32(~EP_MAXPSTREAMS_MASK);\n\tep_ctx->ep_info |= cpu_to_le32(EP_MAXPSTREAMS(max_primary_streams)\n\t\t\t\t       | EP_HAS_LSA);\n\tep_ctx->deq  = cpu_to_le64(stream_info->ctx_array_dma);\n}\n\n \nvoid xhci_setup_no_streams_ep_input_ctx(struct xhci_ep_ctx *ep_ctx,\n\t\tstruct xhci_virt_ep *ep)\n{\n\tdma_addr_t addr;\n\tep_ctx->ep_info &= cpu_to_le32(~(EP_MAXPSTREAMS_MASK | EP_HAS_LSA));\n\taddr = xhci_trb_virt_to_dma(ep->ring->deq_seg, ep->ring->dequeue);\n\tep_ctx->deq  = cpu_to_le64(addr | ep->ring->cycle_state);\n}\n\n \nvoid xhci_free_stream_info(struct xhci_hcd *xhci,\n\t\tstruct xhci_stream_info *stream_info)\n{\n\tint cur_stream;\n\tstruct xhci_ring *cur_ring;\n\n\tif (!stream_info)\n\t\treturn;\n\n\tfor (cur_stream = 1; cur_stream < stream_info->num_streams;\n\t\t\tcur_stream++) {\n\t\tcur_ring = stream_info->stream_rings[cur_stream];\n\t\tif (cur_ring) {\n\t\t\txhci_ring_free(xhci, cur_ring);\n\t\t\tstream_info->stream_rings[cur_stream] = NULL;\n\t\t}\n\t}\n\txhci_free_command(xhci, stream_info->free_streams_command);\n\txhci->cmd_ring_reserved_trbs--;\n\tif (stream_info->stream_ctx_array)\n\t\txhci_free_stream_ctx(xhci,\n\t\t\t\tstream_info->num_stream_ctxs,\n\t\t\t\tstream_info->stream_ctx_array,\n\t\t\t\tstream_info->ctx_array_dma);\n\n\tkfree(stream_info->stream_rings);\n\tkfree(stream_info);\n}\n\n\n \n\nstatic void xhci_free_tt_info(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev,\n\t\tint slot_id)\n{\n\tstruct list_head *tt_list_head;\n\tstruct xhci_tt_bw_info *tt_info, *next;\n\tbool slot_found = false;\n\n\t \n\tif (virt_dev->real_port == 0 ||\n\t\t\tvirt_dev->real_port > HCS_MAX_PORTS(xhci->hcs_params1)) {\n\t\txhci_dbg(xhci, \"Bad real port.\\n\");\n\t\treturn;\n\t}\n\n\ttt_list_head = &(xhci->rh_bw[virt_dev->real_port - 1].tts);\n\tlist_for_each_entry_safe(tt_info, next, tt_list_head, tt_list) {\n\t\t \n\t\tif (tt_info->slot_id == slot_id) {\n\t\t\tslot_found = true;\n\t\t\tlist_del(&tt_info->tt_list);\n\t\t\tkfree(tt_info);\n\t\t} else if (slot_found) {\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nint xhci_alloc_tt_info(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev,\n\t\tstruct usb_device *hdev,\n\t\tstruct usb_tt *tt, gfp_t mem_flags)\n{\n\tstruct xhci_tt_bw_info\t\t*tt_info;\n\tunsigned int\t\t\tnum_ports;\n\tint\t\t\t\ti, j;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\n\tif (!tt->multi)\n\t\tnum_ports = 1;\n\telse\n\t\tnum_ports = hdev->maxchild;\n\n\tfor (i = 0; i < num_ports; i++, tt_info++) {\n\t\tstruct xhci_interval_bw_table *bw_table;\n\n\t\ttt_info = kzalloc_node(sizeof(*tt_info), mem_flags,\n\t\t\t\tdev_to_node(dev));\n\t\tif (!tt_info)\n\t\t\tgoto free_tts;\n\t\tINIT_LIST_HEAD(&tt_info->tt_list);\n\t\tlist_add(&tt_info->tt_list,\n\t\t\t\t&xhci->rh_bw[virt_dev->real_port - 1].tts);\n\t\ttt_info->slot_id = virt_dev->udev->slot_id;\n\t\tif (tt->multi)\n\t\t\ttt_info->ttport = i+1;\n\t\tbw_table = &tt_info->bw_table;\n\t\tfor (j = 0; j < XHCI_MAX_INTERVAL; j++)\n\t\t\tINIT_LIST_HEAD(&bw_table->interval_bw[j].endpoints);\n\t}\n\treturn 0;\n\nfree_tts:\n\txhci_free_tt_info(xhci, virt_dev, virt_dev->udev->slot_id);\n\treturn -ENOMEM;\n}\n\n\n \nvoid xhci_free_virt_device(struct xhci_hcd *xhci, int slot_id)\n{\n\tstruct xhci_virt_device *dev;\n\tint i;\n\tint old_active_eps = 0;\n\n\t \n\tif (slot_id == 0 || !xhci->devs[slot_id])\n\t\treturn;\n\n\tdev = xhci->devs[slot_id];\n\n\txhci->dcbaa->dev_context_ptrs[slot_id] = 0;\n\tif (!dev)\n\t\treturn;\n\n\ttrace_xhci_free_virt_device(dev);\n\n\tif (dev->tt_info)\n\t\told_active_eps = dev->tt_info->active_eps;\n\n\tfor (i = 0; i < 31; i++) {\n\t\tif (dev->eps[i].ring)\n\t\t\txhci_ring_free(xhci, dev->eps[i].ring);\n\t\tif (dev->eps[i].stream_info)\n\t\t\txhci_free_stream_info(xhci,\n\t\t\t\t\tdev->eps[i].stream_info);\n\t\t \n\n\t\tif (!list_empty(&dev->eps[i].bw_endpoint_list)) {\n\t\t\tlist_del_init(&dev->eps[i].bw_endpoint_list);\n\t\t\txhci_dbg(xhci, \"Slot %u endpoint %u not removed from BW list!\\n\",\n\t\t\t\t slot_id, i);\n\t\t}\n\t}\n\t \n\txhci_free_tt_info(xhci, dev, slot_id);\n\t \n\txhci_update_tt_active_eps(xhci, dev, old_active_eps);\n\n\tif (dev->in_ctx)\n\t\txhci_free_container_ctx(xhci, dev->in_ctx);\n\tif (dev->out_ctx)\n\t\txhci_free_container_ctx(xhci, dev->out_ctx);\n\n\tif (dev->udev && dev->udev->slot_id)\n\t\tdev->udev->slot_id = 0;\n\tkfree(xhci->devs[slot_id]);\n\txhci->devs[slot_id] = NULL;\n}\n\n \nstatic void xhci_free_virt_devices_depth_first(struct xhci_hcd *xhci, int slot_id)\n{\n\tstruct xhci_virt_device *vdev;\n\tstruct list_head *tt_list_head;\n\tstruct xhci_tt_bw_info *tt_info, *next;\n\tint i;\n\n\tvdev = xhci->devs[slot_id];\n\tif (!vdev)\n\t\treturn;\n\n\tif (vdev->real_port == 0 ||\n\t\t\tvdev->real_port > HCS_MAX_PORTS(xhci->hcs_params1)) {\n\t\txhci_dbg(xhci, \"Bad vdev->real_port.\\n\");\n\t\tgoto out;\n\t}\n\n\ttt_list_head = &(xhci->rh_bw[vdev->real_port - 1].tts);\n\tlist_for_each_entry_safe(tt_info, next, tt_list_head, tt_list) {\n\t\t \n\t\tif (tt_info->slot_id == slot_id) {\n\t\t\t \n\t\t\tfor (i = 1; i < HCS_MAX_SLOTS(xhci->hcs_params1); i++) {\n\t\t\t\tvdev = xhci->devs[i];\n\t\t\t\tif (vdev && (vdev->tt_info == tt_info))\n\t\t\t\t\txhci_free_virt_devices_depth_first(\n\t\t\t\t\t\txhci, i);\n\t\t\t}\n\t\t}\n\t}\nout:\n\t \n\txhci_debugfs_remove_slot(xhci, slot_id);\n\txhci_free_virt_device(xhci, slot_id);\n}\n\nint xhci_alloc_virt_device(struct xhci_hcd *xhci, int slot_id,\n\t\tstruct usb_device *udev, gfp_t flags)\n{\n\tstruct xhci_virt_device *dev;\n\tint i;\n\n\t \n\tif (slot_id == 0 || xhci->devs[slot_id]) {\n\t\txhci_warn(xhci, \"Bad Slot ID %d\\n\", slot_id);\n\t\treturn 0;\n\t}\n\n\tdev = kzalloc(sizeof(*dev), flags);\n\tif (!dev)\n\t\treturn 0;\n\n\tdev->slot_id = slot_id;\n\n\t \n\tdev->out_ctx = xhci_alloc_container_ctx(xhci, XHCI_CTX_TYPE_DEVICE, flags);\n\tif (!dev->out_ctx)\n\t\tgoto fail;\n\n\txhci_dbg(xhci, \"Slot %d output ctx = 0x%pad (dma)\\n\", slot_id, &dev->out_ctx->dma);\n\n\t \n\tdev->in_ctx = xhci_alloc_container_ctx(xhci, XHCI_CTX_TYPE_INPUT, flags);\n\tif (!dev->in_ctx)\n\t\tgoto fail;\n\n\txhci_dbg(xhci, \"Slot %d input ctx = 0x%pad (dma)\\n\", slot_id, &dev->in_ctx->dma);\n\n\t \n\tfor (i = 0; i < 31; i++) {\n\t\tdev->eps[i].ep_index = i;\n\t\tdev->eps[i].vdev = dev;\n\t\tdev->eps[i].xhci = xhci;\n\t\tINIT_LIST_HEAD(&dev->eps[i].cancelled_td_list);\n\t\tINIT_LIST_HEAD(&dev->eps[i].bw_endpoint_list);\n\t}\n\n\t \n\tdev->eps[0].ring = xhci_ring_alloc(xhci, 2, 1, TYPE_CTRL, 0, flags);\n\tif (!dev->eps[0].ring)\n\t\tgoto fail;\n\n\tdev->udev = udev;\n\n\t \n\txhci->dcbaa->dev_context_ptrs[slot_id] = cpu_to_le64(dev->out_ctx->dma);\n\txhci_dbg(xhci, \"Set slot id %d dcbaa entry %p to 0x%llx\\n\",\n\t\t slot_id,\n\t\t &xhci->dcbaa->dev_context_ptrs[slot_id],\n\t\t le64_to_cpu(xhci->dcbaa->dev_context_ptrs[slot_id]));\n\n\ttrace_xhci_alloc_virt_device(dev);\n\n\txhci->devs[slot_id] = dev;\n\n\treturn 1;\nfail:\n\n\tif (dev->in_ctx)\n\t\txhci_free_container_ctx(xhci, dev->in_ctx);\n\tif (dev->out_ctx)\n\t\txhci_free_container_ctx(xhci, dev->out_ctx);\n\tkfree(dev);\n\n\treturn 0;\n}\n\nvoid xhci_copy_ep0_dequeue_into_input_ctx(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev)\n{\n\tstruct xhci_virt_device *virt_dev;\n\tstruct xhci_ep_ctx\t*ep0_ctx;\n\tstruct xhci_ring\t*ep_ring;\n\n\tvirt_dev = xhci->devs[udev->slot_id];\n\tep0_ctx = xhci_get_ep_ctx(xhci, virt_dev->in_ctx, 0);\n\tep_ring = virt_dev->eps[0].ring;\n\t \n\tep0_ctx->deq = cpu_to_le64(xhci_trb_virt_to_dma(ep_ring->enq_seg,\n\t\t\t\t\t\t\tep_ring->enqueue)\n\t\t\t\t   | ep_ring->cycle_state);\n}\n\n \nstatic u32 xhci_find_real_port_number(struct xhci_hcd *xhci,\n\t\tstruct usb_device *udev)\n{\n\tstruct usb_device *top_dev;\n\tstruct usb_hcd *hcd;\n\n\tif (udev->speed >= USB_SPEED_SUPER)\n\t\thcd = xhci_get_usb3_hcd(xhci);\n\telse\n\t\thcd = xhci->main_hcd;\n\n\tfor (top_dev = udev; top_dev->parent && top_dev->parent->parent;\n\t\t\ttop_dev = top_dev->parent)\n\t\t ;\n\n\treturn\txhci_find_raw_port_number(hcd, top_dev->portnum);\n}\n\n \nint xhci_setup_addressable_virt_dev(struct xhci_hcd *xhci, struct usb_device *udev)\n{\n\tstruct xhci_virt_device *dev;\n\tstruct xhci_ep_ctx\t*ep0_ctx;\n\tstruct xhci_slot_ctx    *slot_ctx;\n\tu32\t\t\tport_num;\n\tu32\t\t\tmax_packets;\n\tstruct usb_device *top_dev;\n\n\tdev = xhci->devs[udev->slot_id];\n\t \n\tif (udev->slot_id == 0 || !dev) {\n\t\txhci_warn(xhci, \"Slot ID %d is not assigned to this device\\n\",\n\t\t\t\tudev->slot_id);\n\t\treturn -EINVAL;\n\t}\n\tep0_ctx = xhci_get_ep_ctx(xhci, dev->in_ctx, 0);\n\tslot_ctx = xhci_get_slot_ctx(xhci, dev->in_ctx);\n\n\t \n\tslot_ctx->dev_info |= cpu_to_le32(LAST_CTX(1) | udev->route);\n\tswitch (udev->speed) {\n\tcase USB_SPEED_SUPER_PLUS:\n\t\tslot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_SSP);\n\t\tmax_packets = MAX_PACKET(512);\n\t\tbreak;\n\tcase USB_SPEED_SUPER:\n\t\tslot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_SS);\n\t\tmax_packets = MAX_PACKET(512);\n\t\tbreak;\n\tcase USB_SPEED_HIGH:\n\t\tslot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_HS);\n\t\tmax_packets = MAX_PACKET(64);\n\t\tbreak;\n\t \n\tcase USB_SPEED_FULL:\n\t\tslot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_FS);\n\t\tmax_packets = MAX_PACKET(64);\n\t\tbreak;\n\tcase USB_SPEED_LOW:\n\t\tslot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_LS);\n\t\tmax_packets = MAX_PACKET(8);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn -EINVAL;\n\t}\n\t \n\tport_num = xhci_find_real_port_number(xhci, udev);\n\tif (!port_num)\n\t\treturn -EINVAL;\n\tslot_ctx->dev_info2 |= cpu_to_le32(ROOT_HUB_PORT(port_num));\n\t \n\tfor (top_dev = udev; top_dev->parent && top_dev->parent->parent;\n\t\t\ttop_dev = top_dev->parent)\n\t\t ;\n\tdev->fake_port = top_dev->portnum;\n\tdev->real_port = port_num;\n\txhci_dbg(xhci, \"Set root hub portnum to %d\\n\", port_num);\n\txhci_dbg(xhci, \"Set fake root hub portnum to %d\\n\", dev->fake_port);\n\n\t \n\tif (!udev->tt || !udev->tt->hub->parent) {\n\t\tdev->bw_table = &xhci->rh_bw[port_num - 1].bw_table;\n\t} else {\n\t\tstruct xhci_root_port_bw_info *rh_bw;\n\t\tstruct xhci_tt_bw_info *tt_bw;\n\n\t\trh_bw = &xhci->rh_bw[port_num - 1];\n\t\t \n\t\tlist_for_each_entry(tt_bw, &rh_bw->tts, tt_list) {\n\t\t\tif (tt_bw->slot_id != udev->tt->hub->slot_id)\n\t\t\t\tcontinue;\n\n\t\t\tif (!dev->udev->tt->multi ||\n\t\t\t\t\t(udev->tt->multi &&\n\t\t\t\t\t tt_bw->ttport == dev->udev->ttport)) {\n\t\t\t\tdev->bw_table = &tt_bw->bw_table;\n\t\t\t\tdev->tt_info = tt_bw;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!dev->tt_info)\n\t\t\txhci_warn(xhci, \"WARN: Didn't find a matching TT\\n\");\n\t}\n\n\t \n\tif (udev->tt && udev->tt->hub->parent) {\n\t\tslot_ctx->tt_info = cpu_to_le32(udev->tt->hub->slot_id |\n\t\t\t\t\t\t(udev->ttport << 8));\n\t\tif (udev->tt->multi)\n\t\t\tslot_ctx->dev_info |= cpu_to_le32(DEV_MTT);\n\t}\n\txhci_dbg(xhci, \"udev->tt = %p\\n\", udev->tt);\n\txhci_dbg(xhci, \"udev->ttport = 0x%x\\n\", udev->ttport);\n\n\t \n\t \n\tep0_ctx->ep_info2 = cpu_to_le32(EP_TYPE(CTRL_EP));\n\n\t \n\tep0_ctx->ep_info2 |= cpu_to_le32(MAX_BURST(0) | ERROR_COUNT(3) |\n\t\t\t\t\t max_packets);\n\n\tep0_ctx->deq = cpu_to_le64(dev->eps[0].ring->first_seg->dma |\n\t\t\t\t   dev->eps[0].ring->cycle_state);\n\n\ttrace_xhci_setup_addressable_virt_device(dev);\n\n\t \n\n\treturn 0;\n}\n\n \nstatic unsigned int xhci_parse_exponent_interval(struct usb_device *udev,\n\t\tstruct usb_host_endpoint *ep)\n{\n\tunsigned int interval;\n\n\tinterval = clamp_val(ep->desc.bInterval, 1, 16) - 1;\n\tif (interval != ep->desc.bInterval - 1)\n\t\tdev_warn(&udev->dev,\n\t\t\t \"ep %#x - rounding interval to %d %sframes\\n\",\n\t\t\t ep->desc.bEndpointAddress,\n\t\t\t 1 << interval,\n\t\t\t udev->speed == USB_SPEED_FULL ? \"\" : \"micro\");\n\n\tif (udev->speed == USB_SPEED_FULL) {\n\t\t \n\t\tinterval += 3;\t \n\t}\n\n\treturn interval;\n}\n\n \nstatic unsigned int xhci_microframes_to_exponent(struct usb_device *udev,\n\t\tstruct usb_host_endpoint *ep, unsigned int desc_interval,\n\t\tunsigned int min_exponent, unsigned int max_exponent)\n{\n\tunsigned int interval;\n\n\tinterval = fls(desc_interval) - 1;\n\tinterval = clamp_val(interval, min_exponent, max_exponent);\n\tif ((1 << interval) != desc_interval)\n\t\tdev_dbg(&udev->dev,\n\t\t\t \"ep %#x - rounding interval to %d microframes, ep desc says %d microframes\\n\",\n\t\t\t ep->desc.bEndpointAddress,\n\t\t\t 1 << interval,\n\t\t\t desc_interval);\n\n\treturn interval;\n}\n\nstatic unsigned int xhci_parse_microframe_interval(struct usb_device *udev,\n\t\tstruct usb_host_endpoint *ep)\n{\n\tif (ep->desc.bInterval == 0)\n\t\treturn 0;\n\treturn xhci_microframes_to_exponent(udev, ep,\n\t\t\tep->desc.bInterval, 0, 15);\n}\n\n\nstatic unsigned int xhci_parse_frame_interval(struct usb_device *udev,\n\t\tstruct usb_host_endpoint *ep)\n{\n\treturn xhci_microframes_to_exponent(udev, ep,\n\t\t\tep->desc.bInterval * 8, 3, 10);\n}\n\n \nstatic unsigned int xhci_get_endpoint_interval(struct usb_device *udev,\n\t\tstruct usb_host_endpoint *ep)\n{\n\tunsigned int interval = 0;\n\n\tswitch (udev->speed) {\n\tcase USB_SPEED_HIGH:\n\t\t \n\t\tif (usb_endpoint_xfer_control(&ep->desc) ||\n\t\t    usb_endpoint_xfer_bulk(&ep->desc)) {\n\t\t\tinterval = xhci_parse_microframe_interval(udev, ep);\n\t\t\tbreak;\n\t\t}\n\t\tfallthrough;\t \n\n\tcase USB_SPEED_SUPER_PLUS:\n\tcase USB_SPEED_SUPER:\n\t\tif (usb_endpoint_xfer_int(&ep->desc) ||\n\t\t    usb_endpoint_xfer_isoc(&ep->desc)) {\n\t\t\tinterval = xhci_parse_exponent_interval(udev, ep);\n\t\t}\n\t\tbreak;\n\n\tcase USB_SPEED_FULL:\n\t\tif (usb_endpoint_xfer_isoc(&ep->desc)) {\n\t\t\tinterval = xhci_parse_exponent_interval(udev, ep);\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tfallthrough;\n\n\tcase USB_SPEED_LOW:\n\t\tif (usb_endpoint_xfer_int(&ep->desc) ||\n\t\t    usb_endpoint_xfer_isoc(&ep->desc)) {\n\n\t\t\tinterval = xhci_parse_frame_interval(udev, ep);\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tBUG();\n\t}\n\treturn interval;\n}\n\n \nstatic u32 xhci_get_endpoint_mult(struct usb_device *udev,\n\t\tstruct usb_host_endpoint *ep)\n{\n\tif (udev->speed < USB_SPEED_SUPER ||\n\t\t\t!usb_endpoint_xfer_isoc(&ep->desc))\n\t\treturn 0;\n\treturn ep->ss_ep_comp.bmAttributes;\n}\n\nstatic u32 xhci_get_endpoint_max_burst(struct usb_device *udev,\n\t\t\t\t       struct usb_host_endpoint *ep)\n{\n\t \n\tif (udev->speed >= USB_SPEED_SUPER)\n\t\treturn ep->ss_ep_comp.bMaxBurst;\n\n\tif (udev->speed == USB_SPEED_HIGH &&\n\t    (usb_endpoint_xfer_isoc(&ep->desc) ||\n\t     usb_endpoint_xfer_int(&ep->desc)))\n\t\treturn usb_endpoint_maxp_mult(&ep->desc) - 1;\n\n\treturn 0;\n}\n\nstatic u32 xhci_get_endpoint_type(struct usb_host_endpoint *ep)\n{\n\tint in;\n\n\tin = usb_endpoint_dir_in(&ep->desc);\n\n\tswitch (usb_endpoint_type(&ep->desc)) {\n\tcase USB_ENDPOINT_XFER_CONTROL:\n\t\treturn CTRL_EP;\n\tcase USB_ENDPOINT_XFER_BULK:\n\t\treturn in ? BULK_IN_EP : BULK_OUT_EP;\n\tcase USB_ENDPOINT_XFER_ISOC:\n\t\treturn in ? ISOC_IN_EP : ISOC_OUT_EP;\n\tcase USB_ENDPOINT_XFER_INT:\n\t\treturn in ? INT_IN_EP : INT_OUT_EP;\n\t}\n\treturn 0;\n}\n\n \nstatic u32 xhci_get_max_esit_payload(struct usb_device *udev,\n\t\tstruct usb_host_endpoint *ep)\n{\n\tint max_burst;\n\tint max_packet;\n\n\t \n\tif (usb_endpoint_xfer_control(&ep->desc) ||\n\t\t\tusb_endpoint_xfer_bulk(&ep->desc))\n\t\treturn 0;\n\n\t \n\tif ((udev->speed >= USB_SPEED_SUPER_PLUS) &&\n\t    USB_SS_SSP_ISOC_COMP(ep->ss_ep_comp.bmAttributes))\n\t\treturn le32_to_cpu(ep->ssp_isoc_ep_comp.dwBytesPerInterval);\n\n\t \n\tif (udev->speed >= USB_SPEED_SUPER)\n\t\treturn le16_to_cpu(ep->ss_ep_comp.wBytesPerInterval);\n\n\tmax_packet = usb_endpoint_maxp(&ep->desc);\n\tmax_burst = usb_endpoint_maxp_mult(&ep->desc);\n\t \n\treturn max_packet * max_burst;\n}\n\n \nint xhci_endpoint_init(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev,\n\t\tstruct usb_device *udev,\n\t\tstruct usb_host_endpoint *ep,\n\t\tgfp_t mem_flags)\n{\n\tunsigned int ep_index;\n\tstruct xhci_ep_ctx *ep_ctx;\n\tstruct xhci_ring *ep_ring;\n\tunsigned int max_packet;\n\tenum xhci_ring_type ring_type;\n\tu32 max_esit_payload;\n\tu32 endpoint_type;\n\tunsigned int max_burst;\n\tunsigned int interval;\n\tunsigned int mult;\n\tunsigned int avg_trb_len;\n\tunsigned int err_count = 0;\n\n\tep_index = xhci_get_endpoint_index(&ep->desc);\n\tep_ctx = xhci_get_ep_ctx(xhci, virt_dev->in_ctx, ep_index);\n\n\tendpoint_type = xhci_get_endpoint_type(ep);\n\tif (!endpoint_type)\n\t\treturn -EINVAL;\n\n\tring_type = usb_endpoint_type(&ep->desc);\n\n\t \n\tmax_esit_payload = xhci_get_max_esit_payload(udev, ep);\n\tinterval = xhci_get_endpoint_interval(udev, ep);\n\n\t \n\tif (usb_endpoint_xfer_int(&ep->desc) ||\n\t    usb_endpoint_xfer_isoc(&ep->desc)) {\n\t\tif ((xhci->quirks & XHCI_LIMIT_ENDPOINT_INTERVAL_7) &&\n\t\t    udev->speed >= USB_SPEED_HIGH &&\n\t\t    interval >= 7) {\n\t\t\tinterval = 6;\n\t\t}\n\t}\n\n\tmult = xhci_get_endpoint_mult(udev, ep);\n\tmax_packet = usb_endpoint_maxp(&ep->desc);\n\tmax_burst = xhci_get_endpoint_max_burst(udev, ep);\n\tavg_trb_len = max_esit_payload;\n\n\t \n\n\t \n\tif (!usb_endpoint_xfer_isoc(&ep->desc))\n\t\terr_count = 3;\n\t \n\tif (usb_endpoint_xfer_bulk(&ep->desc)) {\n\t\tif (udev->speed == USB_SPEED_HIGH)\n\t\t\tmax_packet = 512;\n\t\tif (udev->speed == USB_SPEED_FULL) {\n\t\t\tmax_packet = rounddown_pow_of_two(max_packet);\n\t\t\tmax_packet = clamp_val(max_packet, 8, 64);\n\t\t}\n\t}\n\t \n\tif (usb_endpoint_xfer_control(&ep->desc) && xhci->hci_version >= 0x100)\n\t\tavg_trb_len = 8;\n\t \n\tif ((xhci->hci_version > 0x100) && HCC2_LEC(xhci->hcc_params2))\n\t\tmult = 0;\n\n\t \n\tvirt_dev->eps[ep_index].new_ring =\n\t\txhci_ring_alloc(xhci, 2, 1, ring_type, max_packet, mem_flags);\n\tif (!virt_dev->eps[ep_index].new_ring)\n\t\treturn -ENOMEM;\n\n\tvirt_dev->eps[ep_index].skip = false;\n\tep_ring = virt_dev->eps[ep_index].new_ring;\n\n\t \n\tep_ctx->ep_info = cpu_to_le32(EP_MAX_ESIT_PAYLOAD_HI(max_esit_payload) |\n\t\t\t\t      EP_INTERVAL(interval) |\n\t\t\t\t      EP_MULT(mult));\n\tep_ctx->ep_info2 = cpu_to_le32(EP_TYPE(endpoint_type) |\n\t\t\t\t       MAX_PACKET(max_packet) |\n\t\t\t\t       MAX_BURST(max_burst) |\n\t\t\t\t       ERROR_COUNT(err_count));\n\tep_ctx->deq = cpu_to_le64(ep_ring->first_seg->dma |\n\t\t\t\t  ep_ring->cycle_state);\n\n\tep_ctx->tx_info = cpu_to_le32(EP_MAX_ESIT_PAYLOAD_LO(max_esit_payload) |\n\t\t\t\t      EP_AVG_TRB_LENGTH(avg_trb_len));\n\n\treturn 0;\n}\n\nvoid xhci_endpoint_zero(struct xhci_hcd *xhci,\n\t\tstruct xhci_virt_device *virt_dev,\n\t\tstruct usb_host_endpoint *ep)\n{\n\tunsigned int ep_index;\n\tstruct xhci_ep_ctx *ep_ctx;\n\n\tep_index = xhci_get_endpoint_index(&ep->desc);\n\tep_ctx = xhci_get_ep_ctx(xhci, virt_dev->in_ctx, ep_index);\n\n\tep_ctx->ep_info = 0;\n\tep_ctx->ep_info2 = 0;\n\tep_ctx->deq = 0;\n\tep_ctx->tx_info = 0;\n\t \n}\n\nvoid xhci_clear_endpoint_bw_info(struct xhci_bw_info *bw_info)\n{\n\tbw_info->ep_interval = 0;\n\tbw_info->mult = 0;\n\tbw_info->num_packets = 0;\n\tbw_info->max_packet_size = 0;\n\tbw_info->type = 0;\n\tbw_info->max_esit_payload = 0;\n}\n\nvoid xhci_update_bw_info(struct xhci_hcd *xhci,\n\t\tstruct xhci_container_ctx *in_ctx,\n\t\tstruct xhci_input_control_ctx *ctrl_ctx,\n\t\tstruct xhci_virt_device *virt_dev)\n{\n\tstruct xhci_bw_info *bw_info;\n\tstruct xhci_ep_ctx *ep_ctx;\n\tunsigned int ep_type;\n\tint i;\n\n\tfor (i = 1; i < 31; i++) {\n\t\tbw_info = &virt_dev->eps[i].bw_info;\n\n\t\t \n\t\tif (!EP_IS_ADDED(ctrl_ctx, i) && EP_IS_DROPPED(ctrl_ctx, i)) {\n\t\t\t \n\t\t\txhci_clear_endpoint_bw_info(bw_info);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (EP_IS_ADDED(ctrl_ctx, i)) {\n\t\t\tep_ctx = xhci_get_ep_ctx(xhci, in_ctx, i);\n\t\t\tep_type = CTX_TO_EP_TYPE(le32_to_cpu(ep_ctx->ep_info2));\n\n\t\t\t \n\t\t\tif (ep_type != ISOC_OUT_EP && ep_type != INT_OUT_EP &&\n\t\t\t\t\tep_type != ISOC_IN_EP &&\n\t\t\t\t\tep_type != INT_IN_EP)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tbw_info->ep_interval = CTX_TO_EP_INTERVAL(\n\t\t\t\t\tle32_to_cpu(ep_ctx->ep_info));\n\t\t\t \n\t\t\tbw_info->mult = CTX_TO_EP_MULT(\n\t\t\t\t\tle32_to_cpu(ep_ctx->ep_info)) + 1;\n\t\t\tbw_info->num_packets = CTX_TO_MAX_BURST(\n\t\t\t\t\tle32_to_cpu(ep_ctx->ep_info2)) + 1;\n\t\t\tbw_info->max_packet_size = MAX_PACKET_DECODED(\n\t\t\t\t\tle32_to_cpu(ep_ctx->ep_info2));\n\t\t\tbw_info->type = ep_type;\n\t\t\tbw_info->max_esit_payload = CTX_TO_MAX_ESIT_PAYLOAD(\n\t\t\t\t\tle32_to_cpu(ep_ctx->tx_info));\n\t\t}\n\t}\n}\n\n \nvoid xhci_endpoint_copy(struct xhci_hcd *xhci,\n\t\tstruct xhci_container_ctx *in_ctx,\n\t\tstruct xhci_container_ctx *out_ctx,\n\t\tunsigned int ep_index)\n{\n\tstruct xhci_ep_ctx *out_ep_ctx;\n\tstruct xhci_ep_ctx *in_ep_ctx;\n\n\tout_ep_ctx = xhci_get_ep_ctx(xhci, out_ctx, ep_index);\n\tin_ep_ctx = xhci_get_ep_ctx(xhci, in_ctx, ep_index);\n\n\tin_ep_ctx->ep_info = out_ep_ctx->ep_info;\n\tin_ep_ctx->ep_info2 = out_ep_ctx->ep_info2;\n\tin_ep_ctx->deq = out_ep_ctx->deq;\n\tin_ep_ctx->tx_info = out_ep_ctx->tx_info;\n\tif (xhci->quirks & XHCI_MTK_HOST) {\n\t\tin_ep_ctx->reserved[0] = out_ep_ctx->reserved[0];\n\t\tin_ep_ctx->reserved[1] = out_ep_ctx->reserved[1];\n\t}\n}\n\n \nvoid xhci_slot_copy(struct xhci_hcd *xhci,\n\t\tstruct xhci_container_ctx *in_ctx,\n\t\tstruct xhci_container_ctx *out_ctx)\n{\n\tstruct xhci_slot_ctx *in_slot_ctx;\n\tstruct xhci_slot_ctx *out_slot_ctx;\n\n\tin_slot_ctx = xhci_get_slot_ctx(xhci, in_ctx);\n\tout_slot_ctx = xhci_get_slot_ctx(xhci, out_ctx);\n\n\tin_slot_ctx->dev_info = out_slot_ctx->dev_info;\n\tin_slot_ctx->dev_info2 = out_slot_ctx->dev_info2;\n\tin_slot_ctx->tt_info = out_slot_ctx->tt_info;\n\tin_slot_ctx->dev_state = out_slot_ctx->dev_state;\n}\n\n \nstatic int scratchpad_alloc(struct xhci_hcd *xhci, gfp_t flags)\n{\n\tint i;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\tint num_sp = HCS_MAX_SCRATCHPAD(xhci->hcs_params2);\n\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"Allocating %d scratchpad buffers\", num_sp);\n\n\tif (!num_sp)\n\t\treturn 0;\n\n\txhci->scratchpad = kzalloc_node(sizeof(*xhci->scratchpad), flags,\n\t\t\t\tdev_to_node(dev));\n\tif (!xhci->scratchpad)\n\t\tgoto fail_sp;\n\n\txhci->scratchpad->sp_array = dma_alloc_coherent(dev,\n\t\t\t\t     size_mul(sizeof(u64), num_sp),\n\t\t\t\t     &xhci->scratchpad->sp_dma, flags);\n\tif (!xhci->scratchpad->sp_array)\n\t\tgoto fail_sp2;\n\n\txhci->scratchpad->sp_buffers = kcalloc_node(num_sp, sizeof(void *),\n\t\t\t\t\tflags, dev_to_node(dev));\n\tif (!xhci->scratchpad->sp_buffers)\n\t\tgoto fail_sp3;\n\n\txhci->dcbaa->dev_context_ptrs[0] = cpu_to_le64(xhci->scratchpad->sp_dma);\n\tfor (i = 0; i < num_sp; i++) {\n\t\tdma_addr_t dma;\n\t\tvoid *buf = dma_alloc_coherent(dev, xhci->page_size, &dma,\n\t\t\t\t\t       flags);\n\t\tif (!buf)\n\t\t\tgoto fail_sp4;\n\n\t\txhci->scratchpad->sp_array[i] = dma;\n\t\txhci->scratchpad->sp_buffers[i] = buf;\n\t}\n\n\treturn 0;\n\n fail_sp4:\n\twhile (i--)\n\t\tdma_free_coherent(dev, xhci->page_size,\n\t\t\t\t    xhci->scratchpad->sp_buffers[i],\n\t\t\t\t    xhci->scratchpad->sp_array[i]);\n\n\tkfree(xhci->scratchpad->sp_buffers);\n\n fail_sp3:\n\tdma_free_coherent(dev, num_sp * sizeof(u64),\n\t\t\t    xhci->scratchpad->sp_array,\n\t\t\t    xhci->scratchpad->sp_dma);\n\n fail_sp2:\n\tkfree(xhci->scratchpad);\n\txhci->scratchpad = NULL;\n\n fail_sp:\n\treturn -ENOMEM;\n}\n\nstatic void scratchpad_free(struct xhci_hcd *xhci)\n{\n\tint num_sp;\n\tint i;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\n\tif (!xhci->scratchpad)\n\t\treturn;\n\n\tnum_sp = HCS_MAX_SCRATCHPAD(xhci->hcs_params2);\n\n\tfor (i = 0; i < num_sp; i++) {\n\t\tdma_free_coherent(dev, xhci->page_size,\n\t\t\t\t    xhci->scratchpad->sp_buffers[i],\n\t\t\t\t    xhci->scratchpad->sp_array[i]);\n\t}\n\tkfree(xhci->scratchpad->sp_buffers);\n\tdma_free_coherent(dev, num_sp * sizeof(u64),\n\t\t\t    xhci->scratchpad->sp_array,\n\t\t\t    xhci->scratchpad->sp_dma);\n\tkfree(xhci->scratchpad);\n\txhci->scratchpad = NULL;\n}\n\nstruct xhci_command *xhci_alloc_command(struct xhci_hcd *xhci,\n\t\tbool allocate_completion, gfp_t mem_flags)\n{\n\tstruct xhci_command *command;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\n\tcommand = kzalloc_node(sizeof(*command), mem_flags, dev_to_node(dev));\n\tif (!command)\n\t\treturn NULL;\n\n\tif (allocate_completion) {\n\t\tcommand->completion =\n\t\t\tkzalloc_node(sizeof(struct completion), mem_flags,\n\t\t\t\tdev_to_node(dev));\n\t\tif (!command->completion) {\n\t\t\tkfree(command);\n\t\t\treturn NULL;\n\t\t}\n\t\tinit_completion(command->completion);\n\t}\n\n\tcommand->status = 0;\n\tINIT_LIST_HEAD(&command->cmd_list);\n\treturn command;\n}\n\nstruct xhci_command *xhci_alloc_command_with_ctx(struct xhci_hcd *xhci,\n\t\tbool allocate_completion, gfp_t mem_flags)\n{\n\tstruct xhci_command *command;\n\n\tcommand = xhci_alloc_command(xhci, allocate_completion, mem_flags);\n\tif (!command)\n\t\treturn NULL;\n\n\tcommand->in_ctx = xhci_alloc_container_ctx(xhci, XHCI_CTX_TYPE_INPUT,\n\t\t\t\t\t\t   mem_flags);\n\tif (!command->in_ctx) {\n\t\tkfree(command->completion);\n\t\tkfree(command);\n\t\treturn NULL;\n\t}\n\treturn command;\n}\n\nvoid xhci_urb_free_priv(struct urb_priv *urb_priv)\n{\n\tkfree(urb_priv);\n}\n\nvoid xhci_free_command(struct xhci_hcd *xhci,\n\t\tstruct xhci_command *command)\n{\n\txhci_free_container_ctx(xhci,\n\t\t\tcommand->in_ctx);\n\tkfree(command->completion);\n\tkfree(command);\n}\n\nint xhci_alloc_erst(struct xhci_hcd *xhci,\n\t\t    struct xhci_ring *evt_ring,\n\t\t    struct xhci_erst *erst,\n\t\t    gfp_t flags)\n{\n\tsize_t size;\n\tunsigned int val;\n\tstruct xhci_segment *seg;\n\tstruct xhci_erst_entry *entry;\n\n\tsize = size_mul(sizeof(struct xhci_erst_entry), evt_ring->num_segs);\n\terst->entries = dma_alloc_coherent(xhci_to_hcd(xhci)->self.sysdev,\n\t\t\t\t\t   size, &erst->erst_dma_addr, flags);\n\tif (!erst->entries)\n\t\treturn -ENOMEM;\n\n\terst->num_entries = evt_ring->num_segs;\n\n\tseg = evt_ring->first_seg;\n\tfor (val = 0; val < evt_ring->num_segs; val++) {\n\t\tentry = &erst->entries[val];\n\t\tentry->seg_addr = cpu_to_le64(seg->dma);\n\t\tentry->seg_size = cpu_to_le32(TRBS_PER_SEGMENT);\n\t\tentry->rsvd = 0;\n\t\tseg = seg->next;\n\t}\n\n\treturn 0;\n}\n\nstatic void\nxhci_free_interrupter(struct xhci_hcd *xhci, struct xhci_interrupter *ir)\n{\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\tsize_t erst_size;\n\tu64 tmp64;\n\tu32 tmp;\n\n\tif (!ir)\n\t\treturn;\n\n\terst_size = sizeof(struct xhci_erst_entry) * ir->erst.num_entries;\n\tif (ir->erst.entries)\n\t\tdma_free_coherent(dev, erst_size,\n\t\t\t\t  ir->erst.entries,\n\t\t\t\t  ir->erst.erst_dma_addr);\n\tir->erst.entries = NULL;\n\n\t \n\tif (ir->ir_set) {\n\t\ttmp = readl(&ir->ir_set->erst_size);\n\t\ttmp &= ERST_SIZE_MASK;\n\t\twritel(tmp, &ir->ir_set->erst_size);\n\n\t\ttmp64 = xhci_read_64(xhci, &ir->ir_set->erst_dequeue);\n\t\ttmp64 &= (u64) ERST_PTR_MASK;\n\t\txhci_write_64(xhci, tmp64, &ir->ir_set->erst_dequeue);\n\t}\n\n\t \n\tif (ir->event_ring)\n\t\txhci_ring_free(xhci, ir->event_ring);\n\tir->event_ring = NULL;\n\n\tkfree(ir);\n}\n\nvoid xhci_mem_cleanup(struct xhci_hcd *xhci)\n{\n\tstruct device\t*dev = xhci_to_hcd(xhci)->self.sysdev;\n\tint i, j, num_ports;\n\n\tcancel_delayed_work_sync(&xhci->cmd_timer);\n\n\txhci_free_interrupter(xhci, xhci->interrupter);\n\txhci->interrupter = NULL;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"Freed primary event ring\");\n\n\tif (xhci->cmd_ring)\n\t\txhci_ring_free(xhci, xhci->cmd_ring);\n\txhci->cmd_ring = NULL;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"Freed command ring\");\n\txhci_cleanup_command_queue(xhci);\n\n\tnum_ports = HCS_MAX_PORTS(xhci->hcs_params1);\n\tfor (i = 0; i < num_ports && xhci->rh_bw; i++) {\n\t\tstruct xhci_interval_bw_table *bwt = &xhci->rh_bw[i].bw_table;\n\t\tfor (j = 0; j < XHCI_MAX_INTERVAL; j++) {\n\t\t\tstruct list_head *ep = &bwt->interval_bw[j].endpoints;\n\t\t\twhile (!list_empty(ep))\n\t\t\t\tlist_del_init(ep->next);\n\t\t}\n\t}\n\n\tfor (i = HCS_MAX_SLOTS(xhci->hcs_params1); i > 0; i--)\n\t\txhci_free_virt_devices_depth_first(xhci, i);\n\n\tdma_pool_destroy(xhci->segment_pool);\n\txhci->segment_pool = NULL;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"Freed segment pool\");\n\n\tdma_pool_destroy(xhci->device_pool);\n\txhci->device_pool = NULL;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"Freed device context pool\");\n\n\tdma_pool_destroy(xhci->small_streams_pool);\n\txhci->small_streams_pool = NULL;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"Freed small stream array pool\");\n\n\tdma_pool_destroy(xhci->medium_streams_pool);\n\txhci->medium_streams_pool = NULL;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"Freed medium stream array pool\");\n\n\tif (xhci->dcbaa)\n\t\tdma_free_coherent(dev, sizeof(*xhci->dcbaa),\n\t\t\t\txhci->dcbaa, xhci->dcbaa->dma);\n\txhci->dcbaa = NULL;\n\n\tscratchpad_free(xhci);\n\n\tif (!xhci->rh_bw)\n\t\tgoto no_bw;\n\n\tfor (i = 0; i < num_ports; i++) {\n\t\tstruct xhci_tt_bw_info *tt, *n;\n\t\tlist_for_each_entry_safe(tt, n, &xhci->rh_bw[i].tts, tt_list) {\n\t\t\tlist_del(&tt->tt_list);\n\t\t\tkfree(tt);\n\t\t}\n\t}\n\nno_bw:\n\txhci->cmd_ring_reserved_trbs = 0;\n\txhci->usb2_rhub.num_ports = 0;\n\txhci->usb3_rhub.num_ports = 0;\n\txhci->num_active_eps = 0;\n\tkfree(xhci->usb2_rhub.ports);\n\tkfree(xhci->usb3_rhub.ports);\n\tkfree(xhci->hw_ports);\n\tkfree(xhci->rh_bw);\n\tkfree(xhci->ext_caps);\n\tfor (i = 0; i < xhci->num_port_caps; i++)\n\t\tkfree(xhci->port_caps[i].psi);\n\tkfree(xhci->port_caps);\n\txhci->num_port_caps = 0;\n\n\txhci->usb2_rhub.ports = NULL;\n\txhci->usb3_rhub.ports = NULL;\n\txhci->hw_ports = NULL;\n\txhci->rh_bw = NULL;\n\txhci->ext_caps = NULL;\n\txhci->port_caps = NULL;\n\n\txhci->page_size = 0;\n\txhci->page_shift = 0;\n\txhci->usb2_rhub.bus_state.bus_suspended = 0;\n\txhci->usb3_rhub.bus_state.bus_suspended = 0;\n}\n\nstatic void xhci_set_hc_event_deq(struct xhci_hcd *xhci, struct xhci_interrupter *ir)\n{\n\tu64 temp;\n\tdma_addr_t deq;\n\n\tdeq = xhci_trb_virt_to_dma(ir->event_ring->deq_seg,\n\t\t\tir->event_ring->dequeue);\n\tif (!deq)\n\t\txhci_warn(xhci, \"WARN something wrong with SW event ring dequeue ptr.\\n\");\n\t \n\ttemp = xhci_read_64(xhci, &ir->ir_set->erst_dequeue);\n\ttemp &= ERST_PTR_MASK;\n\t \n\ttemp &= ~ERST_EHB;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t       \"\n\txhci_write_64(xhci, ((u64) deq & (u64) ~ERST_PTR_MASK) | temp,\n\t\t\t&ir->ir_set->erst_dequeue);\n}\n\nstatic void xhci_add_in_port(struct xhci_hcd *xhci, unsigned int num_ports,\n\t\t__le32 __iomem *addr, int max_caps)\n{\n\tu32 temp, port_offset, port_count;\n\tint i;\n\tu8 major_revision, minor_revision, tmp_minor_revision;\n\tstruct xhci_hub *rhub;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\tstruct xhci_port_cap *port_cap;\n\n\ttemp = readl(addr);\n\tmajor_revision = XHCI_EXT_PORT_MAJOR(temp);\n\tminor_revision = XHCI_EXT_PORT_MINOR(temp);\n\n\tif (major_revision == 0x03) {\n\t\trhub = &xhci->usb3_rhub;\n\t\t/*\n\t\t * Some hosts incorrectly use sub-minor version for minor\n\t\t * version (i.e. 0x02 instead of 0x20 for bcdUSB 0x320 and 0x01\n\t\t * for bcdUSB 0x310). Since there is no USB release with sub\n\t\t * minor version 0x301 to 0x309, we can assume that they are\n\t\t * incorrect and fix it here.\n\t\t */\n\t\tif (minor_revision > 0x00 && minor_revision < 0x10)\n\t\t\tminor_revision <<= 4;\n\t\t/*\n\t\t * Some zhaoxin's xHCI controller that follow usb3.1 spec\n\t\t * but only support Gen1.\n\t\t */\n\t\tif (xhci->quirks & XHCI_ZHAOXIN_HOST) {\n\t\t\ttmp_minor_revision = minor_revision;\n\t\t\tminor_revision = 0;\n\t\t}\n\n\t} else if (major_revision <= 0x02) {\n\t\trhub = &xhci->usb2_rhub;\n\t} else {\n\t\txhci_warn(xhci, \"Ignoring unknown port speed, Ext Cap %p, revision = 0x%x\\n\",\n\t\t\t\taddr, major_revision);\n\t\t/* Ignoring port protocol we can't understand. FIXME */\n\t\treturn;\n\t}\n\n\t/* Port offset and count in the third dword, see section 7.2 */\n\ttemp = readl(addr + 2);\n\tport_offset = XHCI_EXT_PORT_OFF(temp);\n\tport_count = XHCI_EXT_PORT_COUNT(temp);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t       \"Ext Cap %p, port offset = %u, count = %u, revision = 0x%x\",\n\t\t       addr, port_offset, port_count, major_revision);\n\t/* Port count includes the current port offset */\n\tif (port_offset == 0 || (port_offset + port_count - 1) > num_ports)\n\t\t/* WTF? \"Valid values are \u20181\u2019 to MaxPorts\" */\n\t\treturn;\n\n\tport_cap = &xhci->port_caps[xhci->num_port_caps++];\n\tif (xhci->num_port_caps > max_caps)\n\t\treturn;\n\n\tport_cap->psi_count = XHCI_EXT_PORT_PSIC(temp);\n\n\tif (port_cap->psi_count) {\n\t\tport_cap->psi = kcalloc_node(port_cap->psi_count,\n\t\t\t\t\t     sizeof(*port_cap->psi),\n\t\t\t\t\t     GFP_KERNEL, dev_to_node(dev));\n\t\tif (!port_cap->psi)\n\t\t\tport_cap->psi_count = 0;\n\n\t\tport_cap->psi_uid_count++;\n\t\tfor (i = 0; i < port_cap->psi_count; i++) {\n\t\t\tport_cap->psi[i] = readl(addr + 4 + i);\n\n\t\t\t/* count unique ID values, two consecutive entries can\n\t\t\t * have the same ID if link is assymetric\n\t\t\t */\n\t\t\tif (i && (XHCI_EXT_PORT_PSIV(port_cap->psi[i]) !=\n\t\t\t\t  XHCI_EXT_PORT_PSIV(port_cap->psi[i - 1])))\n\t\t\t\tport_cap->psi_uid_count++;\n\n\t\t\tif (xhci->quirks & XHCI_ZHAOXIN_HOST &&\n\t\t\t    major_revision == 0x03 &&\n\t\t\t    XHCI_EXT_PORT_PSIV(port_cap->psi[i]) >= 5)\n\t\t\t\tminor_revision = tmp_minor_revision;\n\n\t\t\txhci_dbg(xhci, \"PSIV:%d PSIE:%d PLT:%d PFD:%d LP:%d PSIM:%d\\n\",\n\t\t\t\t  XHCI_EXT_PORT_PSIV(port_cap->psi[i]),\n\t\t\t\t  XHCI_EXT_PORT_PSIE(port_cap->psi[i]),\n\t\t\t\t  XHCI_EXT_PORT_PLT(port_cap->psi[i]),\n\t\t\t\t  XHCI_EXT_PORT_PFD(port_cap->psi[i]),\n\t\t\t\t  XHCI_EXT_PORT_LP(port_cap->psi[i]),\n\t\t\t\t  XHCI_EXT_PORT_PSIM(port_cap->psi[i]));\n\t\t}\n\t}\n\n\trhub->maj_rev = major_revision;\n\n\tif (rhub->min_rev < minor_revision)\n\t\trhub->min_rev = minor_revision;\n\n\tport_cap->maj_rev = major_revision;\n\tport_cap->min_rev = minor_revision;\n\n\t/* cache usb2 port capabilities */\n\tif (major_revision < 0x03 && xhci->num_ext_caps < max_caps)\n\t\txhci->ext_caps[xhci->num_ext_caps++] = temp;\n\n\tif ((xhci->hci_version >= 0x100) && (major_revision != 0x03) &&\n\t\t (temp & XHCI_HLC)) {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t       \"xHCI 1.0: support USB2 hardware lpm\");\n\t\txhci->hw_lpm_support = 1;\n\t}\n\n\tport_offset--;\n\tfor (i = port_offset; i < (port_offset + port_count); i++) {\n\t\tstruct xhci_port *hw_port = &xhci->hw_ports[i];\n\t\t/* Duplicate entry.  Ignore the port if the revisions differ. */\n\t\tif (hw_port->rhub) {\n\t\t\txhci_warn(xhci, \"Duplicate port entry, Ext Cap %p, port %u\\n\", addr, i);\n\t\t\txhci_warn(xhci, \"Port was marked as USB %u, duplicated as USB %u\\n\",\n\t\t\t\t\thw_port->rhub->maj_rev, major_revision);\n\t\t\t/* Only adjust the roothub port counts if we haven't\n\t\t\t * found a similar duplicate.\n\t\t\t */\n\t\t\tif (hw_port->rhub != rhub &&\n\t\t\t\t hw_port->hcd_portnum != DUPLICATE_ENTRY) {\n\t\t\t\thw_port->rhub->num_ports--;\n\t\t\t\thw_port->hcd_portnum = DUPLICATE_ENTRY;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\thw_port->rhub = rhub;\n\t\thw_port->port_cap = port_cap;\n\t\trhub->num_ports++;\n\t}\n\t/* FIXME: Should we disable ports not in the Extended Capabilities? */\n}\n\nstatic void xhci_create_rhub_port_array(struct xhci_hcd *xhci,\n\t\t\t\t\tstruct xhci_hub *rhub, gfp_t flags)\n{\n\tint port_index = 0;\n\tint i;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\n\tif (!rhub->num_ports)\n\t\treturn;\n\trhub->ports = kcalloc_node(rhub->num_ports, sizeof(*rhub->ports),\n\t\t\tflags, dev_to_node(dev));\n\tif (!rhub->ports)\n\t\treturn;\n\n\tfor (i = 0; i < HCS_MAX_PORTS(xhci->hcs_params1); i++) {\n\t\tif (xhci->hw_ports[i].rhub != rhub ||\n\t\t    xhci->hw_ports[i].hcd_portnum == DUPLICATE_ENTRY)\n\t\t\tcontinue;\n\t\txhci->hw_ports[i].hcd_portnum = port_index;\n\t\trhub->ports[port_index] = &xhci->hw_ports[i];\n\t\tport_index++;\n\t\tif (port_index == rhub->num_ports)\n\t\t\tbreak;\n\t}\n}\n\n/*\n * Scan the Extended Capabilities for the \"Supported Protocol Capabilities\" that\n * specify what speeds each port is supposed to be.  We can't count on the port\n * speed bits in the PORTSC register being correct until a device is connected,\n * but we need to set up the two fake roothubs with the correct number of USB\n * 3.0 and USB 2.0 ports at host controller initialization time.\n */\nstatic int xhci_setup_port_arrays(struct xhci_hcd *xhci, gfp_t flags)\n{\n\tvoid __iomem *base;\n\tu32 offset;\n\tunsigned int num_ports;\n\tint i, j;\n\tint cap_count = 0;\n\tu32 cap_start;\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\n\tnum_ports = HCS_MAX_PORTS(xhci->hcs_params1);\n\txhci->hw_ports = kcalloc_node(num_ports, sizeof(*xhci->hw_ports),\n\t\t\t\tflags, dev_to_node(dev));\n\tif (!xhci->hw_ports)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < num_ports; i++) {\n\t\txhci->hw_ports[i].addr = &xhci->op_regs->port_status_base +\n\t\t\tNUM_PORT_REGS * i;\n\t\txhci->hw_ports[i].hw_portnum = i;\n\n\t\tinit_completion(&xhci->hw_ports[i].rexit_done);\n\t\tinit_completion(&xhci->hw_ports[i].u3exit_done);\n\t}\n\n\txhci->rh_bw = kcalloc_node(num_ports, sizeof(*xhci->rh_bw), flags,\n\t\t\t\t   dev_to_node(dev));\n\tif (!xhci->rh_bw)\n\t\treturn -ENOMEM;\n\tfor (i = 0; i < num_ports; i++) {\n\t\tstruct xhci_interval_bw_table *bw_table;\n\n\t\tINIT_LIST_HEAD(&xhci->rh_bw[i].tts);\n\t\tbw_table = &xhci->rh_bw[i].bw_table;\n\t\tfor (j = 0; j < XHCI_MAX_INTERVAL; j++)\n\t\t\tINIT_LIST_HEAD(&bw_table->interval_bw[j].endpoints);\n\t}\n\tbase = &xhci->cap_regs->hc_capbase;\n\n\tcap_start = xhci_find_next_ext_cap(base, 0, XHCI_EXT_CAPS_PROTOCOL);\n\tif (!cap_start) {\n\t\txhci_err(xhci, \"No Extended Capability registers, unable to set up roothub\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\toffset = cap_start;\n\t/* count extended protocol capability entries for later caching */\n\twhile (offset) {\n\t\tcap_count++;\n\t\toffset = xhci_find_next_ext_cap(base, offset,\n\t\t\t\t\t\t      XHCI_EXT_CAPS_PROTOCOL);\n\t}\n\n\txhci->ext_caps = kcalloc_node(cap_count, sizeof(*xhci->ext_caps),\n\t\t\t\tflags, dev_to_node(dev));\n\tif (!xhci->ext_caps)\n\t\treturn -ENOMEM;\n\n\txhci->port_caps = kcalloc_node(cap_count, sizeof(*xhci->port_caps),\n\t\t\t\tflags, dev_to_node(dev));\n\tif (!xhci->port_caps)\n\t\treturn -ENOMEM;\n\n\toffset = cap_start;\n\n\twhile (offset) {\n\t\txhci_add_in_port(xhci, num_ports, base + offset, cap_count);\n\t\tif (xhci->usb2_rhub.num_ports + xhci->usb3_rhub.num_ports ==\n\t\t    num_ports)\n\t\t\tbreak;\n\t\toffset = xhci_find_next_ext_cap(base, offset,\n\t\t\t\t\t\tXHCI_EXT_CAPS_PROTOCOL);\n\t}\n\tif (xhci->usb2_rhub.num_ports == 0 && xhci->usb3_rhub.num_ports == 0) {\n\t\txhci_warn(xhci, \"No ports on the roothubs?\\n\");\n\t\treturn -ENODEV;\n\t}\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t       \"Found %u USB 2.0 ports and %u USB 3.0 ports.\",\n\t\t       xhci->usb2_rhub.num_ports, xhci->usb3_rhub.num_ports);\n\n\t/* Place limits on the number of roothub ports so that the hub\n\t * descriptors aren't longer than the USB core will allocate.\n\t */\n\tif (xhci->usb3_rhub.num_ports > USB_SS_MAXPORTS) {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\t\"Limiting USB 3.0 roothub ports to %u.\",\n\t\t\t\tUSB_SS_MAXPORTS);\n\t\txhci->usb3_rhub.num_ports = USB_SS_MAXPORTS;\n\t}\n\tif (xhci->usb2_rhub.num_ports > USB_MAXCHILDREN) {\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\t\"Limiting USB 2.0 roothub ports to %u.\",\n\t\t\t\tUSB_MAXCHILDREN);\n\t\txhci->usb2_rhub.num_ports = USB_MAXCHILDREN;\n\t}\n\n\tif (!xhci->usb2_rhub.num_ports)\n\t\txhci_info(xhci, \"USB2 root hub has no ports\\n\");\n\n\tif (!xhci->usb3_rhub.num_ports)\n\t\txhci_info(xhci, \"USB3 root hub has no ports\\n\");\n\n\txhci_create_rhub_port_array(xhci, &xhci->usb2_rhub, flags);\n\txhci_create_rhub_port_array(xhci, &xhci->usb3_rhub, flags);\n\n\treturn 0;\n}\n\nstatic struct xhci_interrupter *\nxhci_alloc_interrupter(struct xhci_hcd *xhci, gfp_t flags)\n{\n\tstruct device *dev = xhci_to_hcd(xhci)->self.sysdev;\n\tstruct xhci_interrupter *ir;\n\tint ret;\n\n\tir = kzalloc_node(sizeof(*ir), flags, dev_to_node(dev));\n\tif (!ir)\n\t\treturn NULL;\n\n\tir->event_ring = xhci_ring_alloc(xhci, ERST_NUM_SEGS, 1, TYPE_EVENT,\n\t\t\t\t\t0, flags);\n\tif (!ir->event_ring) {\n\t\txhci_warn(xhci, \"Failed to allocate interrupter event ring\\n\");\n\t\tkfree(ir);\n\t\treturn NULL;\n\t}\n\n\tret = xhci_alloc_erst(xhci, ir->event_ring, &ir->erst, flags);\n\tif (ret) {\n\t\txhci_warn(xhci, \"Failed to allocate interrupter erst\\n\");\n\t\txhci_ring_free(xhci, ir->event_ring);\n\t\tkfree(ir);\n\t\treturn NULL;\n\t}\n\n\treturn ir;\n}\n\nstatic int\nxhci_add_interrupter(struct xhci_hcd *xhci, struct xhci_interrupter *ir,\n\t\t     unsigned int intr_num)\n{\n\tu64 erst_base;\n\tu32 erst_size;\n\n\tif (intr_num > xhci->max_interrupters) {\n\t\txhci_warn(xhci, \"Can't add interrupter %d, max interrupters %d\\n\",\n\t\t\t  intr_num, xhci->max_interrupters);\n\t\treturn -EINVAL;\n\t}\n\n\tir->ir_set = &xhci->run_regs->ir_set[intr_num];\n\n\t/* set ERST count with the number of entries in the segment table */\n\terst_size = readl(&ir->ir_set->erst_size);\n\terst_size &= ERST_SIZE_MASK;\n\terst_size |= ERST_NUM_SEGS;\n\twritel(erst_size, &ir->ir_set->erst_size);\n\n\terst_base = xhci_read_64(xhci, &ir->ir_set->erst_base);\n\terst_base &= ERST_BASE_RSVDP;\n\terst_base |= ir->erst.erst_dma_addr & ~ERST_BASE_RSVDP;\n\txhci_write_64(xhci, erst_base, &ir->ir_set->erst_base);\n\n\t/* Set the event ring dequeue address of this interrupter */\n\txhci_set_hc_event_deq(xhci, ir);\n\n\treturn 0;\n}\n\nint xhci_mem_init(struct xhci_hcd *xhci, gfp_t flags)\n{\n\tdma_addr_t\tdma;\n\tstruct device\t*dev = xhci_to_hcd(xhci)->self.sysdev;\n\tunsigned int\tval, val2;\n\tu64\t\tval_64;\n\tu32\t\tpage_size, temp;\n\tint\t\ti;\n\n\tINIT_LIST_HEAD(&xhci->cmd_list);\n\n\t/* init command timeout work */\n\tINIT_DELAYED_WORK(&xhci->cmd_timer, xhci_handle_command_timeout);\n\tinit_completion(&xhci->cmd_ring_stop_completion);\n\n\tpage_size = readl(&xhci->op_regs->page_size);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"Supported page size register = 0x%x\", page_size);\n\ti = ffs(page_size);\n\tif (i < 16)\n\t\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"Supported page size of %iK\", (1 << (i+12)) / 1024);\n\telse\n\t\txhci_warn(xhci, \"WARN: no supported page size\\n\");\n\t/* Use 4K pages, since that's common and the minimum the HC supports */\n\txhci->page_shift = 12;\n\txhci->page_size = 1 << xhci->page_shift;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"HCD page size set to %iK\", xhci->page_size / 1024);\n\n\t \n\tval = HCS_MAX_SLOTS(readl(&xhci->cap_regs->hcs_params1));\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"\n\tval2 = readl(&xhci->op_regs->config_reg);\n\tval |= (val2 & ~HCS_SLOTS_MASK);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\" \n\twritel(val, &xhci->op_regs->config_reg);\n\n\t \n\txhci->dcbaa = dma_alloc_coherent(dev, sizeof(*xhci->dcbaa), &dma,\n\t\t\tflags);\n\tif (!xhci->dcbaa)\n\t\tgoto fail;\n\txhci->dcbaa->dma = dma;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"// Device context base array address = 0x%pad (DMA), %p (virt)\",\n\t\t\t&xhci->dcbaa->dma, xhci->dcbaa);\n\txhci_write_64(xhci, dma, &xhci->op_regs->dcbaa_ptr);\n\n\t \n\tif (xhci->quirks & XHCI_ZHAOXIN_TRB_FETCH)\n\t\txhci->segment_pool = dma_pool_create(\"xHCI ring segments\", dev,\n\t\t\t\tTRB_SEGMENT_SIZE * 2, TRB_SEGMENT_SIZE * 2, xhci->page_size * 2);\n\telse\n\t\txhci->segment_pool = dma_pool_create(\"xHCI ring segments\", dev,\n\t\t\t\tTRB_SEGMENT_SIZE, TRB_SEGMENT_SIZE, xhci->page_size);\n\n\t \n\txhci->device_pool = dma_pool_create(\"xHCI input/output contexts\", dev,\n\t\t\t2112, 64, xhci->page_size);\n\tif (!xhci->segment_pool || !xhci->device_pool)\n\t\tgoto fail;\n\n\t \n\txhci->small_streams_pool =\n\t\tdma_pool_create(\"xHCI 256 byte stream ctx arrays\",\n\t\t\tdev, SMALL_STREAM_ARRAY_SIZE, 16, 0);\n\txhci->medium_streams_pool =\n\t\tdma_pool_create(\"xHCI 1KB stream ctx arrays\",\n\t\t\tdev, MEDIUM_STREAM_ARRAY_SIZE, 16, 0);\n\t \n\n\tif (!xhci->small_streams_pool || !xhci->medium_streams_pool)\n\t\tgoto fail;\n\n\t \n\txhci->cmd_ring = xhci_ring_alloc(xhci, 1, 1, TYPE_COMMAND, 0, flags);\n\tif (!xhci->cmd_ring)\n\t\tgoto fail;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"Allocated command ring at %p\", xhci->cmd_ring);\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init, \"First segment DMA is 0x%pad\",\n\t\t\t&xhci->cmd_ring->first_seg->dma);\n\n\t \n\tval_64 = xhci_read_64(xhci, &xhci->op_regs->cmd_ring);\n\tval_64 = (val_64 & (u64) CMD_RING_RSVD_BITS) |\n\t\t(xhci->cmd_ring->first_seg->dma & (u64) ~CMD_RING_RSVD_BITS) |\n\t\txhci->cmd_ring->cycle_state;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t\t\"// Setting command ring address to 0x%016llx\", val_64);\n\txhci_write_64(xhci, val_64, &xhci->op_regs->cmd_ring);\n\n\t \n\txhci->cmd_ring_reserved_trbs++;\n\n\tval = readl(&xhci->cap_regs->db_off);\n\tval &= DBOFF_MASK;\n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t       \"// Doorbell array is located at offset 0x%x from cap regs base addr\",\n\t\t       val);\n\txhci->dba = (void __iomem *) xhci->cap_regs + val;\n\n\t \n\txhci_dbg_trace(xhci, trace_xhci_dbg_init,\n\t\t       \"Allocating primary event ring\");\n\txhci->interrupter = xhci_alloc_interrupter(xhci, flags);\n\tif (!xhci->interrupter)\n\t\tgoto fail;\n\n\tif (xhci_add_interrupter(xhci, xhci->interrupter, 0))\n\t\tgoto fail;\n\n\txhci->isoc_bei_interval = AVOID_BEI_INTERVAL_MAX;\n\n\t \n\tfor (i = 0; i < MAX_HC_SLOTS; i++)\n\t\txhci->devs[i] = NULL;\n\n\tif (scratchpad_alloc(xhci, flags))\n\t\tgoto fail;\n\tif (xhci_setup_port_arrays(xhci, flags))\n\t\tgoto fail;\n\n\t \n\ttemp = readl(&xhci->op_regs->dev_notification);\n\ttemp &= ~DEV_NOTE_MASK;\n\ttemp |= DEV_NOTE_FWAKE;\n\twritel(temp, &xhci->op_regs->dev_notification);\n\n\treturn 0;\n\nfail:\n\txhci_halt(xhci);\n\txhci_reset(xhci, XHCI_RESET_SHORT_USEC);\n\txhci_mem_cleanup(xhci);\n\treturn -ENOMEM;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}