{
  "module_name": "xhci-dbc.c",
  "hash_id": "12d5e580c6f63f0a2b52ff5151d2e53c885ef7a5a397bcd6994540dd8798180e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/usb/early/xhci-dbc.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \":%s: \" fmt, __func__\n\n#include <linux/console.h>\n#include <linux/pci_regs.h>\n#include <linux/pci_ids.h>\n#include <linux/memblock.h>\n#include <linux/io.h>\n#include <asm/pci-direct.h>\n#include <asm/fixmap.h>\n#include <linux/bcd.h>\n#include <linux/export.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/kthread.h>\n#include <linux/usb/xhci-dbgp.h>\n\n#include \"../host/xhci.h\"\n#include \"xhci-dbc.h\"\n\nstatic struct xdbc_state xdbc;\nstatic bool early_console_keep;\n\n#ifdef XDBC_TRACE\n#define\txdbc_trace\ttrace_printk\n#else\nstatic inline void xdbc_trace(const char *fmt, ...) { }\n#endif  \n\nstatic void __iomem * __init xdbc_map_pci_mmio(u32 bus, u32 dev, u32 func)\n{\n\tu64 val64, sz64, mask64;\n\tvoid __iomem *base;\n\tu32 val, sz;\n\tu8 byte;\n\n\tval = read_pci_config(bus, dev, func, PCI_BASE_ADDRESS_0);\n\twrite_pci_config(bus, dev, func, PCI_BASE_ADDRESS_0, ~0);\n\tsz = read_pci_config(bus, dev, func, PCI_BASE_ADDRESS_0);\n\twrite_pci_config(bus, dev, func, PCI_BASE_ADDRESS_0, val);\n\n\tif (val == 0xffffffff || sz == 0xffffffff) {\n\t\tpr_notice(\"invalid mmio bar\\n\");\n\t\treturn NULL;\n\t}\n\n\tval64\t= val & PCI_BASE_ADDRESS_MEM_MASK;\n\tsz64\t= sz & PCI_BASE_ADDRESS_MEM_MASK;\n\tmask64\t= PCI_BASE_ADDRESS_MEM_MASK;\n\n\tif ((val & PCI_BASE_ADDRESS_MEM_TYPE_MASK) == PCI_BASE_ADDRESS_MEM_TYPE_64) {\n\t\tval = read_pci_config(bus, dev, func, PCI_BASE_ADDRESS_0 + 4);\n\t\twrite_pci_config(bus, dev, func, PCI_BASE_ADDRESS_0 + 4, ~0);\n\t\tsz = read_pci_config(bus, dev, func, PCI_BASE_ADDRESS_0 + 4);\n\t\twrite_pci_config(bus, dev, func, PCI_BASE_ADDRESS_0 + 4, val);\n\n\t\tval64\t|= (u64)val << 32;\n\t\tsz64\t|= (u64)sz << 32;\n\t\tmask64\t|= ~0ULL << 32;\n\t}\n\n\tsz64 &= mask64;\n\n\tif (!sz64) {\n\t\tpr_notice(\"invalid mmio address\\n\");\n\t\treturn NULL;\n\t}\n\n\tsz64 = 1ULL << __ffs64(sz64);\n\n\t \n\tbyte = read_pci_config_byte(bus, dev, func, PCI_COMMAND);\n\tif (!(byte & PCI_COMMAND_MEMORY)) {\n\t\tbyte |= PCI_COMMAND_MEMORY;\n\t\twrite_pci_config_byte(bus, dev, func, PCI_COMMAND, byte);\n\t}\n\n\txdbc.xhci_start = val64;\n\txdbc.xhci_length = sz64;\n\tbase = early_ioremap(val64, sz64);\n\n\treturn base;\n}\n\nstatic void * __init xdbc_get_page(dma_addr_t *dma_addr)\n{\n\tvoid *virt;\n\n\tvirt = memblock_alloc(PAGE_SIZE, PAGE_SIZE);\n\tif (!virt)\n\t\treturn NULL;\n\n\tif (dma_addr)\n\t\t*dma_addr = (dma_addr_t)__pa(virt);\n\n\treturn virt;\n}\n\nstatic u32 __init xdbc_find_dbgp(int xdbc_num, u32 *b, u32 *d, u32 *f)\n{\n\tu32 bus, dev, func, class;\n\n\tfor (bus = 0; bus < XDBC_PCI_MAX_BUSES; bus++) {\n\t\tfor (dev = 0; dev < XDBC_PCI_MAX_DEVICES; dev++) {\n\t\t\tfor (func = 0; func < XDBC_PCI_MAX_FUNCTION; func++) {\n\n\t\t\t\tclass = read_pci_config(bus, dev, func, PCI_CLASS_REVISION);\n\t\t\t\tif ((class >> 8) != PCI_CLASS_SERIAL_USB_XHCI)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tif (xdbc_num-- != 0)\n\t\t\t\t\tcontinue;\n\n\t\t\t\t*b = bus;\n\t\t\t\t*d = dev;\n\t\t\t\t*f = func;\n\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn -1;\n}\n\nstatic int handshake(void __iomem *ptr, u32 mask, u32 done, int wait, int delay)\n{\n\tu32 result;\n\n\t \n\tdo {\n\t\tresult = readl(ptr);\n\t\tresult &= mask;\n\t\tif (result == done)\n\t\t\treturn 0;\n\t\tudelay(delay);\n\t\twait -= delay;\n\t} while (wait > 0);\n\n\treturn -ETIMEDOUT;\n}\n\nstatic void __init xdbc_bios_handoff(void)\n{\n\tint offset, timeout;\n\tu32 val;\n\n\toffset = xhci_find_next_ext_cap(xdbc.xhci_base, 0, XHCI_EXT_CAPS_LEGACY);\n\tval = readl(xdbc.xhci_base + offset);\n\n\tif (val & XHCI_HC_BIOS_OWNED) {\n\t\twritel(val | XHCI_HC_OS_OWNED, xdbc.xhci_base + offset);\n\t\ttimeout = handshake(xdbc.xhci_base + offset, XHCI_HC_BIOS_OWNED, 0, 5000, 10);\n\n\t\tif (timeout) {\n\t\t\tpr_notice(\"failed to hand over xHCI control from BIOS\\n\");\n\t\t\twritel(val & ~XHCI_HC_BIOS_OWNED, xdbc.xhci_base + offset);\n\t\t}\n\t}\n\n\t \n\tval = readl(xdbc.xhci_base + offset + XHCI_LEGACY_CONTROL_OFFSET);\n\tval &= XHCI_LEGACY_DISABLE_SMI;\n\tval |= XHCI_LEGACY_SMI_EVENTS;\n\twritel(val, xdbc.xhci_base + offset + XHCI_LEGACY_CONTROL_OFFSET);\n}\n\nstatic int __init\nxdbc_alloc_ring(struct xdbc_segment *seg, struct xdbc_ring *ring)\n{\n\tseg->trbs = xdbc_get_page(&seg->dma);\n\tif (!seg->trbs)\n\t\treturn -ENOMEM;\n\n\tring->segment = seg;\n\n\treturn 0;\n}\n\nstatic void __init xdbc_free_ring(struct xdbc_ring *ring)\n{\n\tstruct xdbc_segment *seg = ring->segment;\n\n\tif (!seg)\n\t\treturn;\n\n\tmemblock_phys_free(seg->dma, PAGE_SIZE);\n\tring->segment = NULL;\n}\n\nstatic void xdbc_reset_ring(struct xdbc_ring *ring)\n{\n\tstruct xdbc_segment *seg = ring->segment;\n\tstruct xdbc_trb *link_trb;\n\n\tmemset(seg->trbs, 0, PAGE_SIZE);\n\n\tring->enqueue = seg->trbs;\n\tring->dequeue = seg->trbs;\n\tring->cycle_state = 1;\n\n\tif (ring != &xdbc.evt_ring) {\n\t\tlink_trb = &seg->trbs[XDBC_TRBS_PER_SEGMENT - 1];\n\t\tlink_trb->field[0] = cpu_to_le32(lower_32_bits(seg->dma));\n\t\tlink_trb->field[1] = cpu_to_le32(upper_32_bits(seg->dma));\n\t\tlink_trb->field[3] = cpu_to_le32(TRB_TYPE(TRB_LINK)) | cpu_to_le32(LINK_TOGGLE);\n\t}\n}\n\nstatic inline void xdbc_put_utf16(u16 *s, const char *c, size_t size)\n{\n\tint i;\n\n\tfor (i = 0; i < size; i++)\n\t\ts[i] = cpu_to_le16(c[i]);\n}\n\nstatic void xdbc_mem_init(void)\n{\n\tstruct xdbc_ep_context *ep_in, *ep_out;\n\tstruct usb_string_descriptor *s_desc;\n\tstruct xdbc_erst_entry *entry;\n\tstruct xdbc_strings *strings;\n\tstruct xdbc_context *ctx;\n\tunsigned int max_burst;\n\tu32 string_length;\n\tint index = 0;\n\tu32 dev_info;\n\n\txdbc_reset_ring(&xdbc.evt_ring);\n\txdbc_reset_ring(&xdbc.in_ring);\n\txdbc_reset_ring(&xdbc.out_ring);\n\tmemset(xdbc.table_base, 0, PAGE_SIZE);\n\tmemset(xdbc.out_buf, 0, PAGE_SIZE);\n\n\t \n\txdbc.erst_size\t= 16;\n\txdbc.erst_base\t= xdbc.table_base + index * XDBC_TABLE_ENTRY_SIZE;\n\txdbc.erst_dma\t= xdbc.table_dma + index * XDBC_TABLE_ENTRY_SIZE;\n\n\tindex += XDBC_ERST_ENTRY_NUM;\n\tentry = (struct xdbc_erst_entry *)xdbc.erst_base;\n\n\tentry->seg_addr\t\t= cpu_to_le64(xdbc.evt_seg.dma);\n\tentry->seg_size\t\t= cpu_to_le32(XDBC_TRBS_PER_SEGMENT);\n\tentry->__reserved_0\t= 0;\n\n\t \n\twritel(1, &xdbc.xdbc_reg->ersts);\n\txdbc_write64(xdbc.erst_dma, &xdbc.xdbc_reg->erstba);\n\txdbc_write64(xdbc.evt_seg.dma, &xdbc.xdbc_reg->erdp);\n\n\t \n\txdbc.dbcc_size\t= 64 * 3;\n\txdbc.dbcc_base\t= xdbc.table_base + index * XDBC_TABLE_ENTRY_SIZE;\n\txdbc.dbcc_dma\t= xdbc.table_dma + index * XDBC_TABLE_ENTRY_SIZE;\n\n\tindex += XDBC_DBCC_ENTRY_NUM;\n\n\t \n\txdbc.string_size = sizeof(struct xdbc_strings);\n\txdbc.string_base = xdbc.table_base + index * XDBC_TABLE_ENTRY_SIZE;\n\txdbc.string_dma\t = xdbc.table_dma + index * XDBC_TABLE_ENTRY_SIZE;\n\tstrings\t\t = (struct xdbc_strings *)xdbc.string_base;\n\n\tindex += XDBC_STRING_ENTRY_NUM;\n\n\t \n\ts_desc\t\t\t= (struct usb_string_descriptor *)strings->serial;\n\ts_desc->bLength\t\t= (strlen(XDBC_STRING_SERIAL) + 1) * 2;\n\ts_desc->bDescriptorType\t= USB_DT_STRING;\n\n\txdbc_put_utf16(s_desc->wData, XDBC_STRING_SERIAL, strlen(XDBC_STRING_SERIAL));\n\tstring_length = s_desc->bLength;\n\tstring_length <<= 8;\n\n\t \n\ts_desc\t\t\t= (struct usb_string_descriptor *)strings->product;\n\ts_desc->bLength\t\t= (strlen(XDBC_STRING_PRODUCT) + 1) * 2;\n\ts_desc->bDescriptorType\t= USB_DT_STRING;\n\n\txdbc_put_utf16(s_desc->wData, XDBC_STRING_PRODUCT, strlen(XDBC_STRING_PRODUCT));\n\tstring_length += s_desc->bLength;\n\tstring_length <<= 8;\n\n\t \n\ts_desc\t\t\t= (struct usb_string_descriptor *)strings->manufacturer;\n\ts_desc->bLength\t\t= (strlen(XDBC_STRING_MANUFACTURER) + 1) * 2;\n\ts_desc->bDescriptorType\t= USB_DT_STRING;\n\n\txdbc_put_utf16(s_desc->wData, XDBC_STRING_MANUFACTURER, strlen(XDBC_STRING_MANUFACTURER));\n\tstring_length += s_desc->bLength;\n\tstring_length <<= 8;\n\n\t \n\tstrings->string0[0]\t= 4;\n\tstrings->string0[1]\t= USB_DT_STRING;\n\tstrings->string0[2]\t= 0x09;\n\tstrings->string0[3]\t= 0x04;\n\n\tstring_length += 4;\n\n\t \n\tctx = (struct xdbc_context *)xdbc.dbcc_base;\n\n\tctx->info.string0\t= cpu_to_le64(xdbc.string_dma);\n\tctx->info.manufacturer\t= cpu_to_le64(xdbc.string_dma + XDBC_MAX_STRING_LENGTH);\n\tctx->info.product\t= cpu_to_le64(xdbc.string_dma + XDBC_MAX_STRING_LENGTH * 2);\n\tctx->info.serial\t= cpu_to_le64(xdbc.string_dma + XDBC_MAX_STRING_LENGTH * 3);\n\tctx->info.length\t= cpu_to_le32(string_length);\n\n\t \n\tmax_burst = DEBUG_MAX_BURST(readl(&xdbc.xdbc_reg->control));\n\tep_out = (struct xdbc_ep_context *)&ctx->out;\n\n\tep_out->ep_info1\t= 0;\n\tep_out->ep_info2\t= cpu_to_le32(EP_TYPE(BULK_OUT_EP) | MAX_PACKET(1024) | MAX_BURST(max_burst));\n\tep_out->deq\t\t= cpu_to_le64(xdbc.out_seg.dma | xdbc.out_ring.cycle_state);\n\n\t \n\tep_in = (struct xdbc_ep_context *)&ctx->in;\n\n\tep_in->ep_info1\t\t= 0;\n\tep_in->ep_info2\t\t= cpu_to_le32(EP_TYPE(BULK_IN_EP) | MAX_PACKET(1024) | MAX_BURST(max_burst));\n\tep_in->deq\t\t= cpu_to_le64(xdbc.in_seg.dma | xdbc.in_ring.cycle_state);\n\n\t \n\txdbc_write64(xdbc.dbcc_dma, &xdbc.xdbc_reg->dccp);\n\n\tdev_info = cpu_to_le32((XDBC_VENDOR_ID << 16) | XDBC_PROTOCOL);\n\twritel(dev_info, &xdbc.xdbc_reg->devinfo1);\n\n\tdev_info = cpu_to_le32((XDBC_DEVICE_REV << 16) | XDBC_PRODUCT_ID);\n\twritel(dev_info, &xdbc.xdbc_reg->devinfo2);\n\n\txdbc.in_buf = xdbc.out_buf + XDBC_MAX_PACKET;\n\txdbc.in_dma = xdbc.out_dma + XDBC_MAX_PACKET;\n}\n\nstatic void xdbc_do_reset_debug_port(u32 id, u32 count)\n{\n\tvoid __iomem *ops_reg;\n\tvoid __iomem *portsc;\n\tu32 val, cap_length;\n\tint i;\n\n\tcap_length = readl(xdbc.xhci_base) & 0xff;\n\tops_reg = xdbc.xhci_base + cap_length;\n\n\tid--;\n\tfor (i = id; i < (id + count); i++) {\n\t\tportsc = ops_reg + 0x400 + i * 0x10;\n\t\tval = readl(portsc);\n\t\tif (!(val & PORT_CONNECT))\n\t\t\twritel(val | PORT_RESET, portsc);\n\t}\n}\n\nstatic void xdbc_reset_debug_port(void)\n{\n\tu32 val, port_offset, port_count;\n\tint offset = 0;\n\n\tdo {\n\t\toffset = xhci_find_next_ext_cap(xdbc.xhci_base, offset, XHCI_EXT_CAPS_PROTOCOL);\n\t\tif (!offset)\n\t\t\tbreak;\n\n\t\tval = readl(xdbc.xhci_base + offset);\n\t\tif (XHCI_EXT_PORT_MAJOR(val) != 0x3)\n\t\t\tcontinue;\n\n\t\tval = readl(xdbc.xhci_base + offset + 8);\n\t\tport_offset = XHCI_EXT_PORT_OFF(val);\n\t\tport_count = XHCI_EXT_PORT_COUNT(val);\n\n\t\txdbc_do_reset_debug_port(port_offset, port_count);\n\t} while (1);\n}\n\nstatic void\nxdbc_queue_trb(struct xdbc_ring *ring, u32 field1, u32 field2, u32 field3, u32 field4)\n{\n\tstruct xdbc_trb *trb, *link_trb;\n\n\ttrb = ring->enqueue;\n\ttrb->field[0] = cpu_to_le32(field1);\n\ttrb->field[1] = cpu_to_le32(field2);\n\ttrb->field[2] = cpu_to_le32(field3);\n\ttrb->field[3] = cpu_to_le32(field4);\n\n\t++(ring->enqueue);\n\tif (ring->enqueue >= &ring->segment->trbs[TRBS_PER_SEGMENT - 1]) {\n\t\tlink_trb = ring->enqueue;\n\t\tif (ring->cycle_state)\n\t\t\tlink_trb->field[3] |= cpu_to_le32(TRB_CYCLE);\n\t\telse\n\t\t\tlink_trb->field[3] &= cpu_to_le32(~TRB_CYCLE);\n\n\t\tring->enqueue = ring->segment->trbs;\n\t\tring->cycle_state ^= 1;\n\t}\n}\n\nstatic void xdbc_ring_doorbell(int target)\n{\n\twritel(DOOR_BELL_TARGET(target), &xdbc.xdbc_reg->doorbell);\n}\n\nstatic int xdbc_start(void)\n{\n\tu32 ctrl, status;\n\tint ret;\n\n\tctrl = readl(&xdbc.xdbc_reg->control);\n\twritel(ctrl | CTRL_DBC_ENABLE | CTRL_PORT_ENABLE, &xdbc.xdbc_reg->control);\n\tret = handshake(&xdbc.xdbc_reg->control, CTRL_DBC_ENABLE, CTRL_DBC_ENABLE, 100000, 100);\n\tif (ret) {\n\t\txdbc_trace(\"failed to initialize hardware\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tif (xdbc.vendor == PCI_VENDOR_ID_INTEL)\n\t\txdbc_reset_debug_port();\n\n\t \n\tret = handshake(&xdbc.xdbc_reg->portsc, PORTSC_CONN_STATUS, PORTSC_CONN_STATUS, 5000000, 100);\n\tif (ret) {\n\t\txdbc_trace(\"waiting for connection timed out\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = handshake(&xdbc.xdbc_reg->control, CTRL_DBC_RUN, CTRL_DBC_RUN, 5000000, 100);\n\tif (ret) {\n\t\txdbc_trace(\"waiting for device configuration timed out\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tstatus = readl(&xdbc.xdbc_reg->status);\n\tif (!DCST_DEBUG_PORT(status)) {\n\t\txdbc_trace(\"invalid root hub port number\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txdbc.port_number = DCST_DEBUG_PORT(status);\n\n\txdbc_trace(\"DbC is running now, control 0x%08x port ID %d\\n\",\n\t\t   readl(&xdbc.xdbc_reg->control), xdbc.port_number);\n\n\treturn 0;\n}\n\nstatic int xdbc_bulk_transfer(void *data, int size, bool read)\n{\n\tstruct xdbc_ring *ring;\n\tstruct xdbc_trb *trb;\n\tu32 length, control;\n\tu32 cycle;\n\tu64 addr;\n\n\tif (size > XDBC_MAX_PACKET) {\n\t\txdbc_trace(\"bad parameter, size %d\\n\", size);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!(xdbc.flags & XDBC_FLAGS_INITIALIZED) ||\n\t    !(xdbc.flags & XDBC_FLAGS_CONFIGURED) ||\n\t    (!read && (xdbc.flags & XDBC_FLAGS_OUT_STALL)) ||\n\t    (read && (xdbc.flags & XDBC_FLAGS_IN_STALL))) {\n\n\t\txdbc_trace(\"connection not ready, flags %08x\\n\", xdbc.flags);\n\t\treturn -EIO;\n\t}\n\n\tring = (read ? &xdbc.in_ring : &xdbc.out_ring);\n\ttrb = ring->enqueue;\n\tcycle = ring->cycle_state;\n\tlength = TRB_LEN(size);\n\tcontrol = TRB_TYPE(TRB_NORMAL) | TRB_IOC;\n\n\tif (cycle)\n\t\tcontrol &= cpu_to_le32(~TRB_CYCLE);\n\telse\n\t\tcontrol |= cpu_to_le32(TRB_CYCLE);\n\n\tif (read) {\n\t\tmemset(xdbc.in_buf, 0, XDBC_MAX_PACKET);\n\t\taddr = xdbc.in_dma;\n\t\txdbc.flags |= XDBC_FLAGS_IN_PROCESS;\n\t} else {\n\t\tmemcpy_and_pad(xdbc.out_buf, XDBC_MAX_PACKET, data, size, 0);\n\t\taddr = xdbc.out_dma;\n\t\txdbc.flags |= XDBC_FLAGS_OUT_PROCESS;\n\t}\n\n\txdbc_queue_trb(ring, lower_32_bits(addr), upper_32_bits(addr), length, control);\n\n\t \n\twmb();\n\tif (cycle)\n\t\ttrb->field[3] |= cpu_to_le32(cycle);\n\telse\n\t\ttrb->field[3] &= cpu_to_le32(~TRB_CYCLE);\n\n\txdbc_ring_doorbell(read ? IN_EP_DOORBELL : OUT_EP_DOORBELL);\n\n\treturn size;\n}\n\nstatic int xdbc_handle_external_reset(void)\n{\n\tint ret = 0;\n\n\txdbc.flags = 0;\n\twritel(0, &xdbc.xdbc_reg->control);\n\tret = handshake(&xdbc.xdbc_reg->control, CTRL_DBC_ENABLE, 0, 100000, 10);\n\tif (ret)\n\t\tgoto reset_out;\n\n\txdbc_mem_init();\n\n\tret = xdbc_start();\n\tif (ret < 0)\n\t\tgoto reset_out;\n\n\txdbc_trace(\"dbc recovered\\n\");\n\n\txdbc.flags |= XDBC_FLAGS_INITIALIZED | XDBC_FLAGS_CONFIGURED;\n\n\txdbc_bulk_transfer(NULL, XDBC_MAX_PACKET, true);\n\n\treturn 0;\n\nreset_out:\n\txdbc_trace(\"failed to recover from external reset\\n\");\n\treturn ret;\n}\n\nstatic int __init xdbc_early_setup(void)\n{\n\tint ret;\n\n\twritel(0, &xdbc.xdbc_reg->control);\n\tret = handshake(&xdbc.xdbc_reg->control, CTRL_DBC_ENABLE, 0, 100000, 100);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\txdbc.table_base = xdbc_get_page(&xdbc.table_dma);\n\tif (!xdbc.table_base)\n\t\treturn -ENOMEM;\n\n\t \n\txdbc.out_buf = xdbc_get_page(&xdbc.out_dma);\n\tif (!xdbc.out_buf)\n\t\treturn -ENOMEM;\n\n\t \n\tret = xdbc_alloc_ring(&xdbc.evt_seg, &xdbc.evt_ring);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tret = xdbc_alloc_ring(&xdbc.in_seg, &xdbc.in_ring);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = xdbc_alloc_ring(&xdbc.out_seg, &xdbc.out_ring);\n\tif (ret < 0)\n\t\treturn ret;\n\n\txdbc_mem_init();\n\n\tret = xdbc_start();\n\tif (ret < 0) {\n\t\twritel(0, &xdbc.xdbc_reg->control);\n\t\treturn ret;\n\t}\n\n\txdbc.flags |= XDBC_FLAGS_INITIALIZED | XDBC_FLAGS_CONFIGURED;\n\n\txdbc_bulk_transfer(NULL, XDBC_MAX_PACKET, true);\n\n\treturn 0;\n}\n\nint __init early_xdbc_parse_parameter(char *s, int keep_early)\n{\n\tunsigned long dbgp_num = 0;\n\tu32 bus, dev, func, offset;\n\tchar *e;\n\tint ret;\n\n\tif (!early_pci_allowed())\n\t\treturn -EPERM;\n\n\tearly_console_keep = keep_early;\n\n\tif (xdbc.xdbc_reg)\n\t\treturn 0;\n\n\tif (*s) {\n\t       dbgp_num = simple_strtoul(s, &e, 10);\n\t       if (s == e)\n\t\t       dbgp_num = 0;\n\t}\n\n\tpr_notice(\"dbgp_num: %lu\\n\", dbgp_num);\n\n\t \n\tret = xdbc_find_dbgp(dbgp_num, &bus, &dev, &func);\n\tif (ret) {\n\t\tpr_notice(\"failed to locate xhci host\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txdbc.vendor\t= read_pci_config_16(bus, dev, func, PCI_VENDOR_ID);\n\txdbc.device\t= read_pci_config_16(bus, dev, func, PCI_DEVICE_ID);\n\txdbc.bus\t= bus;\n\txdbc.dev\t= dev;\n\txdbc.func\t= func;\n\n\t \n\txdbc.xhci_base = xdbc_map_pci_mmio(bus, dev, func);\n\tif (!xdbc.xhci_base)\n\t\treturn -EINVAL;\n\n\t \n\toffset = xhci_find_next_ext_cap(xdbc.xhci_base, 0, XHCI_EXT_CAPS_DEBUG);\n\tif (!offset) {\n\t\tpr_notice(\"xhci host doesn't support debug capability\\n\");\n\t\tearly_iounmap(xdbc.xhci_base, xdbc.xhci_length);\n\t\txdbc.xhci_base = NULL;\n\t\txdbc.xhci_length = 0;\n\n\t\treturn -ENODEV;\n\t}\n\txdbc.xdbc_reg = (struct xdbc_regs __iomem *)(xdbc.xhci_base + offset);\n\n\treturn 0;\n}\n\nint __init early_xdbc_setup_hardware(void)\n{\n\tint ret;\n\n\tif (!xdbc.xdbc_reg)\n\t\treturn -ENODEV;\n\n\txdbc_bios_handoff();\n\n\traw_spin_lock_init(&xdbc.lock);\n\n\tret = xdbc_early_setup();\n\tif (ret) {\n\t\tpr_notice(\"failed to setup the connection to host\\n\");\n\n\t\txdbc_free_ring(&xdbc.evt_ring);\n\t\txdbc_free_ring(&xdbc.out_ring);\n\t\txdbc_free_ring(&xdbc.in_ring);\n\n\t\tif (xdbc.table_dma)\n\t\t\tmemblock_phys_free(xdbc.table_dma, PAGE_SIZE);\n\n\t\tif (xdbc.out_dma)\n\t\t\tmemblock_phys_free(xdbc.out_dma, PAGE_SIZE);\n\n\t\txdbc.table_base = NULL;\n\t\txdbc.out_buf = NULL;\n\t}\n\n\treturn ret;\n}\n\nstatic void xdbc_handle_port_status(struct xdbc_trb *evt_trb)\n{\n\tu32 port_reg;\n\n\tport_reg = readl(&xdbc.xdbc_reg->portsc);\n\tif (port_reg & PORTSC_CONN_CHANGE) {\n\t\txdbc_trace(\"connect status change event\\n\");\n\n\t\t \n\t\tif (!(port_reg & PORTSC_CONN_STATUS)) {\n\t\t\txdbc.flags = 0;\n\t\t\txdbc_trace(\"cable unplugged\\n\");\n\t\t}\n\t}\n\n\tif (port_reg & PORTSC_RESET_CHANGE)\n\t\txdbc_trace(\"port reset change event\\n\");\n\n\tif (port_reg & PORTSC_LINK_CHANGE)\n\t\txdbc_trace(\"port link status change event\\n\");\n\n\tif (port_reg & PORTSC_CONFIG_CHANGE)\n\t\txdbc_trace(\"config error change\\n\");\n\n\t \n\twritel(port_reg, &xdbc.xdbc_reg->portsc);\n}\n\nstatic void xdbc_handle_tx_event(struct xdbc_trb *evt_trb)\n{\n\tu32 comp_code;\n\tint ep_id;\n\n\tcomp_code\t= GET_COMP_CODE(le32_to_cpu(evt_trb->field[2]));\n\tep_id\t\t= TRB_TO_EP_ID(le32_to_cpu(evt_trb->field[3]));\n\n\tswitch (comp_code) {\n\tcase COMP_SUCCESS:\n\tcase COMP_SHORT_PACKET:\n\t\tbreak;\n\tcase COMP_TRB_ERROR:\n\tcase COMP_BABBLE_DETECTED_ERROR:\n\tcase COMP_USB_TRANSACTION_ERROR:\n\tcase COMP_STALL_ERROR:\n\tdefault:\n\t\tif (ep_id == XDBC_EPID_OUT || ep_id == XDBC_EPID_OUT_INTEL)\n\t\t\txdbc.flags |= XDBC_FLAGS_OUT_STALL;\n\t\tif (ep_id == XDBC_EPID_IN || ep_id == XDBC_EPID_IN_INTEL)\n\t\t\txdbc.flags |= XDBC_FLAGS_IN_STALL;\n\n\t\txdbc_trace(\"endpoint %d stalled\\n\", ep_id);\n\t\tbreak;\n\t}\n\n\tif (ep_id == XDBC_EPID_IN || ep_id == XDBC_EPID_IN_INTEL) {\n\t\txdbc.flags &= ~XDBC_FLAGS_IN_PROCESS;\n\t\txdbc_bulk_transfer(NULL, XDBC_MAX_PACKET, true);\n\t} else if (ep_id == XDBC_EPID_OUT || ep_id == XDBC_EPID_OUT_INTEL) {\n\t\txdbc.flags &= ~XDBC_FLAGS_OUT_PROCESS;\n\t} else {\n\t\txdbc_trace(\"invalid endpoint id %d\\n\", ep_id);\n\t}\n}\n\nstatic void xdbc_handle_events(void)\n{\n\tstruct xdbc_trb *evt_trb;\n\tbool update_erdp = false;\n\tu32 reg;\n\tu8 cmd;\n\n\tcmd = read_pci_config_byte(xdbc.bus, xdbc.dev, xdbc.func, PCI_COMMAND);\n\tif (!(cmd & PCI_COMMAND_MASTER)) {\n\t\tcmd |= PCI_COMMAND_MASTER | PCI_COMMAND_MEMORY;\n\t\twrite_pci_config_byte(xdbc.bus, xdbc.dev, xdbc.func, PCI_COMMAND, cmd);\n\t}\n\n\tif (!(xdbc.flags & XDBC_FLAGS_INITIALIZED))\n\t\treturn;\n\n\t \n\treg = readl(&xdbc.xdbc_reg->control);\n\tif (!(reg & CTRL_DBC_ENABLE)) {\n\t\tif (xdbc_handle_external_reset()) {\n\t\t\txdbc_trace(\"failed to recover connection\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\t \n\treg = readl(&xdbc.xdbc_reg->control);\n\tif (reg & CTRL_DBC_RUN_CHANGE) {\n\t\twritel(reg, &xdbc.xdbc_reg->control);\n\t\tif (reg & CTRL_DBC_RUN)\n\t\t\txdbc.flags |= XDBC_FLAGS_CONFIGURED;\n\t\telse\n\t\t\txdbc.flags &= ~XDBC_FLAGS_CONFIGURED;\n\t}\n\n\t \n\treg = readl(&xdbc.xdbc_reg->control);\n\tif (reg & CTRL_HALT_IN_TR) {\n\t\txdbc.flags |= XDBC_FLAGS_IN_STALL;\n\t} else {\n\t\txdbc.flags &= ~XDBC_FLAGS_IN_STALL;\n\t\tif (!(xdbc.flags & XDBC_FLAGS_IN_PROCESS))\n\t\t\txdbc_bulk_transfer(NULL, XDBC_MAX_PACKET, true);\n\t}\n\n\tif (reg & CTRL_HALT_OUT_TR)\n\t\txdbc.flags |= XDBC_FLAGS_OUT_STALL;\n\telse\n\t\txdbc.flags &= ~XDBC_FLAGS_OUT_STALL;\n\n\t \n\tevt_trb = xdbc.evt_ring.dequeue;\n\twhile ((le32_to_cpu(evt_trb->field[3]) & TRB_CYCLE) == xdbc.evt_ring.cycle_state) {\n\t\t \n\t\trmb();\n\n\t\tswitch ((le32_to_cpu(evt_trb->field[3]) & TRB_TYPE_BITMASK)) {\n\t\tcase TRB_TYPE(TRB_PORT_STATUS):\n\t\t\txdbc_handle_port_status(evt_trb);\n\t\t\tbreak;\n\t\tcase TRB_TYPE(TRB_TRANSFER):\n\t\t\txdbc_handle_tx_event(evt_trb);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\t++(xdbc.evt_ring.dequeue);\n\t\tif (xdbc.evt_ring.dequeue == &xdbc.evt_seg.trbs[TRBS_PER_SEGMENT]) {\n\t\t\txdbc.evt_ring.dequeue = xdbc.evt_seg.trbs;\n\t\t\txdbc.evt_ring.cycle_state ^= 1;\n\t\t}\n\n\t\tevt_trb = xdbc.evt_ring.dequeue;\n\t\tupdate_erdp = true;\n\t}\n\n\t \n\tif (update_erdp)\n\t\txdbc_write64(__pa(xdbc.evt_ring.dequeue), &xdbc.xdbc_reg->erdp);\n}\n\nstatic int xdbc_bulk_write(const char *bytes, int size)\n{\n\tint ret, timeout = 0;\n\tunsigned long flags;\n\nretry:\n\tif (in_nmi()) {\n\t\tif (!raw_spin_trylock_irqsave(&xdbc.lock, flags))\n\t\t\treturn -EAGAIN;\n\t} else {\n\t\traw_spin_lock_irqsave(&xdbc.lock, flags);\n\t}\n\n\txdbc_handle_events();\n\n\t \n\tif ((xdbc.flags & XDBC_FLAGS_OUT_PROCESS) && (timeout < 2000000)) {\n\t\traw_spin_unlock_irqrestore(&xdbc.lock, flags);\n\t\tudelay(100);\n\t\ttimeout += 100;\n\t\tgoto retry;\n\t}\n\n\tif (xdbc.flags & XDBC_FLAGS_OUT_PROCESS) {\n\t\traw_spin_unlock_irqrestore(&xdbc.lock, flags);\n\t\txdbc_trace(\"previous transfer not completed yet\\n\");\n\n\t\treturn -ETIMEDOUT;\n\t}\n\n\tret = xdbc_bulk_transfer((void *)bytes, size, false);\n\traw_spin_unlock_irqrestore(&xdbc.lock, flags);\n\n\treturn ret;\n}\n\nstatic void early_xdbc_write(struct console *con, const char *str, u32 n)\n{\n\t \n\tstatic char buf[XDBC_MAX_PACKET + 1];\n\tint chunk, ret;\n\tint use_cr = 0;\n\n\tif (!xdbc.xdbc_reg)\n\t\treturn;\n\n\twhile (n > 0) {\n\t\tfor (chunk = 0; chunk < XDBC_MAX_PACKET && n > 0; str++, chunk++, n--) {\n\n\t\t\tif (!use_cr && *str == '\\n') {\n\t\t\t\tuse_cr = 1;\n\t\t\t\tbuf[chunk] = '\\r';\n\t\t\t\tstr--;\n\t\t\t\tn++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (use_cr)\n\t\t\t\tuse_cr = 0;\n\t\t\tbuf[chunk] = *str;\n\t\t}\n\n\t\tif (chunk > 0) {\n\t\t\tret = xdbc_bulk_write(buf, chunk);\n\t\t\tif (ret < 0)\n\t\t\t\txdbc_trace(\"missed message {%s}\\n\", buf);\n\t\t}\n\t}\n}\n\nstatic struct console early_xdbc_console = {\n\t.name\t\t= \"earlyxdbc\",\n\t.write\t\t= early_xdbc_write,\n\t.flags\t\t= CON_PRINTBUFFER,\n\t.index\t\t= -1,\n};\n\nvoid __init early_xdbc_register_console(void)\n{\n\tif (early_console)\n\t\treturn;\n\n\tearly_console = &early_xdbc_console;\n\tif (early_console_keep)\n\t\tearly_console->flags &= ~CON_BOOT;\n\telse\n\t\tearly_console->flags |= CON_BOOT;\n\tregister_console(early_console);\n}\n\nstatic void xdbc_unregister_console(void)\n{\n\tif (console_is_registered(&early_xdbc_console))\n\t\tunregister_console(&early_xdbc_console);\n}\n\nstatic int xdbc_scrub_function(void *ptr)\n{\n\tunsigned long flags;\n\n\twhile (true) {\n\t\traw_spin_lock_irqsave(&xdbc.lock, flags);\n\t\txdbc_handle_events();\n\n\t\tif (!(xdbc.flags & XDBC_FLAGS_INITIALIZED)) {\n\t\t\traw_spin_unlock_irqrestore(&xdbc.lock, flags);\n\t\t\tbreak;\n\t\t}\n\n\t\traw_spin_unlock_irqrestore(&xdbc.lock, flags);\n\t\tschedule_timeout_interruptible(1);\n\t}\n\n\txdbc_unregister_console();\n\twritel(0, &xdbc.xdbc_reg->control);\n\txdbc_trace(\"dbc scrub function exits\\n\");\n\n\treturn 0;\n}\n\nstatic int __init xdbc_init(void)\n{\n\tunsigned long flags;\n\tvoid __iomem *base;\n\tint ret = 0;\n\tu32 offset;\n\n\tif (!(xdbc.flags & XDBC_FLAGS_INITIALIZED))\n\t\treturn 0;\n\n\t \n\tif (early_xdbc_console.index == -1 ||\n\t    (early_xdbc_console.flags & CON_BOOT)) {\n\t\txdbc_trace(\"hardware not used anymore\\n\");\n\t\tgoto free_and_quit;\n\t}\n\n\tbase = ioremap(xdbc.xhci_start, xdbc.xhci_length);\n\tif (!base) {\n\t\txdbc_trace(\"failed to remap the io address\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_and_quit;\n\t}\n\n\traw_spin_lock_irqsave(&xdbc.lock, flags);\n\tearly_iounmap(xdbc.xhci_base, xdbc.xhci_length);\n\txdbc.xhci_base = base;\n\toffset = xhci_find_next_ext_cap(xdbc.xhci_base, 0, XHCI_EXT_CAPS_DEBUG);\n\txdbc.xdbc_reg = (struct xdbc_regs __iomem *)(xdbc.xhci_base + offset);\n\traw_spin_unlock_irqrestore(&xdbc.lock, flags);\n\n\tkthread_run(xdbc_scrub_function, NULL, \"%s\", \"xdbc\");\n\n\treturn 0;\n\nfree_and_quit:\n\txdbc_free_ring(&xdbc.evt_ring);\n\txdbc_free_ring(&xdbc.out_ring);\n\txdbc_free_ring(&xdbc.in_ring);\n\tmemblock_phys_free(xdbc.table_dma, PAGE_SIZE);\n\tmemblock_phys_free(xdbc.out_dma, PAGE_SIZE);\n\twritel(0, &xdbc.xdbc_reg->control);\n\tearly_iounmap(xdbc.xhci_base, xdbc.xhci_length);\n\n\treturn ret;\n}\nsubsys_initcall(xdbc_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}