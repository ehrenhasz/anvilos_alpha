{
  "module_name": "cdnsp-ring.c",
  "hash_id": "cda9049863af91a416f1de0cec1f50b32c391de40b604d707e12400ac0c1866d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/usb/cdns3/cdnsp-ring.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/scatterlist.h>\n#include <linux/dma-mapping.h>\n#include <linux/delay.h>\n#include <linux/slab.h>\n#include <linux/irq.h>\n\n#include \"cdnsp-trace.h\"\n#include \"cdnsp-gadget.h\"\n\n \ndma_addr_t cdnsp_trb_virt_to_dma(struct cdnsp_segment *seg,\n\t\t\t\t union cdnsp_trb *trb)\n{\n\tunsigned long segment_offset = trb - seg->trbs;\n\n\tif (trb < seg->trbs || segment_offset >= TRBS_PER_SEGMENT)\n\t\treturn 0;\n\n\treturn seg->dma + (segment_offset * sizeof(*trb));\n}\n\nstatic bool cdnsp_trb_is_noop(union cdnsp_trb *trb)\n{\n\treturn TRB_TYPE_NOOP_LE32(trb->generic.field[3]);\n}\n\nstatic bool cdnsp_trb_is_link(union cdnsp_trb *trb)\n{\n\treturn TRB_TYPE_LINK_LE32(trb->link.control);\n}\n\nbool cdnsp_last_trb_on_seg(struct cdnsp_segment *seg, union cdnsp_trb *trb)\n{\n\treturn trb == &seg->trbs[TRBS_PER_SEGMENT - 1];\n}\n\nbool cdnsp_last_trb_on_ring(struct cdnsp_ring *ring,\n\t\t\t    struct cdnsp_segment *seg,\n\t\t\t    union cdnsp_trb *trb)\n{\n\treturn cdnsp_last_trb_on_seg(seg, trb) && (seg->next == ring->first_seg);\n}\n\nstatic bool cdnsp_link_trb_toggles_cycle(union cdnsp_trb *trb)\n{\n\treturn le32_to_cpu(trb->link.control) & LINK_TOGGLE;\n}\n\nstatic void cdnsp_trb_to_noop(union cdnsp_trb *trb, u32 noop_type)\n{\n\tif (cdnsp_trb_is_link(trb)) {\n\t\t \n\t\ttrb->link.control &= cpu_to_le32(~TRB_CHAIN);\n\t} else {\n\t\ttrb->generic.field[0] = 0;\n\t\ttrb->generic.field[1] = 0;\n\t\ttrb->generic.field[2] = 0;\n\t\t \n\t\ttrb->generic.field[3] &= cpu_to_le32(TRB_CYCLE);\n\t\ttrb->generic.field[3] |= cpu_to_le32(TRB_TYPE(noop_type));\n\t}\n}\n\n \nstatic void cdnsp_next_trb(struct cdnsp_device *pdev,\n\t\t\t   struct cdnsp_ring *ring,\n\t\t\t   struct cdnsp_segment **seg,\n\t\t\t   union cdnsp_trb **trb)\n{\n\tif (cdnsp_trb_is_link(*trb)) {\n\t\t*seg = (*seg)->next;\n\t\t*trb = ((*seg)->trbs);\n\t} else {\n\t\t(*trb)++;\n\t}\n}\n\n \nvoid cdnsp_inc_deq(struct cdnsp_device *pdev, struct cdnsp_ring *ring)\n{\n\t \n\tif (ring->type == TYPE_EVENT) {\n\t\tif (!cdnsp_last_trb_on_seg(ring->deq_seg, ring->dequeue)) {\n\t\t\tring->dequeue++;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (cdnsp_last_trb_on_ring(ring, ring->deq_seg, ring->dequeue))\n\t\t\tring->cycle_state ^= 1;\n\n\t\tring->deq_seg = ring->deq_seg->next;\n\t\tring->dequeue = ring->deq_seg->trbs;\n\t\tgoto out;\n\t}\n\n\t \n\tif (!cdnsp_trb_is_link(ring->dequeue)) {\n\t\tring->dequeue++;\n\t\tring->num_trbs_free++;\n\t}\n\twhile (cdnsp_trb_is_link(ring->dequeue)) {\n\t\tring->deq_seg = ring->deq_seg->next;\n\t\tring->dequeue = ring->deq_seg->trbs;\n\t}\nout:\n\ttrace_cdnsp_inc_deq(ring);\n}\n\n \nstatic void cdnsp_inc_enq(struct cdnsp_device *pdev,\n\t\t\t  struct cdnsp_ring *ring,\n\t\t\t  bool more_trbs_coming)\n{\n\tunion cdnsp_trb *next;\n\tu32 chain;\n\n\tchain = le32_to_cpu(ring->enqueue->generic.field[3]) & TRB_CHAIN;\n\n\t \n\tif (!cdnsp_trb_is_link(ring->enqueue))\n\t\tring->num_trbs_free--;\n\tnext = ++(ring->enqueue);\n\n\t \n\twhile (cdnsp_trb_is_link(next)) {\n\t\t \n\t\tif (!chain && !more_trbs_coming)\n\t\t\tbreak;\n\n\t\tnext->link.control &= cpu_to_le32(~TRB_CHAIN);\n\t\tnext->link.control |= cpu_to_le32(chain);\n\n\t\t \n\t\twmb();\n\t\tnext->link.control ^= cpu_to_le32(TRB_CYCLE);\n\n\t\t \n\t\tif (cdnsp_link_trb_toggles_cycle(next))\n\t\t\tring->cycle_state ^= 1;\n\n\t\tring->enq_seg = ring->enq_seg->next;\n\t\tring->enqueue = ring->enq_seg->trbs;\n\t\tnext = ring->enqueue;\n\t}\n\n\ttrace_cdnsp_inc_enq(ring);\n}\n\n \nstatic bool cdnsp_room_on_ring(struct cdnsp_device *pdev,\n\t\t\t       struct cdnsp_ring *ring,\n\t\t\t       unsigned int num_trbs)\n{\n\tint num_trbs_in_deq_seg;\n\n\tif (ring->num_trbs_free < num_trbs)\n\t\treturn false;\n\n\tif (ring->type != TYPE_COMMAND && ring->type != TYPE_EVENT) {\n\t\tnum_trbs_in_deq_seg = ring->dequeue - ring->deq_seg->trbs;\n\n\t\tif (ring->num_trbs_free < num_trbs + num_trbs_in_deq_seg)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic void cdnsp_force_l0_go(struct cdnsp_device *pdev)\n{\n\tif (pdev->active_port == &pdev->usb2_port && pdev->gadget.lpm_capable)\n\t\tcdnsp_set_link_state(pdev, &pdev->active_port->regs->portsc, XDEV_U0);\n}\n\n \nvoid cdnsp_ring_cmd_db(struct cdnsp_device *pdev)\n{\n\twritel(DB_VALUE_CMD, &pdev->dba->cmd_db);\n}\n\n \nstatic bool cdnsp_ring_ep_doorbell(struct cdnsp_device *pdev,\n\t\t\t\t   struct cdnsp_ep *pep,\n\t\t\t\t   unsigned int stream_id)\n{\n\t__le32 __iomem *reg_addr = &pdev->dba->ep_db;\n\tunsigned int ep_state = pep->ep_state;\n\tunsigned int db_value;\n\n\t \n\tif (ep_state & EP_HALTED || !(ep_state & EP_ENABLED))\n\t\treturn false;\n\n\t \n\tif (pep->ep_state & EP_HAS_STREAMS) {\n\t\tif (pep->stream_info.drbls_count >= 2)\n\t\t\treturn false;\n\n\t\tpep->stream_info.drbls_count++;\n\t}\n\n\tpep->ep_state &= ~EP_STOPPED;\n\n\tif (pep->idx == 0 && pdev->ep0_stage == CDNSP_DATA_STAGE &&\n\t    !pdev->ep0_expect_in)\n\t\tdb_value = DB_VALUE_EP0_OUT(pep->idx, stream_id);\n\telse\n\t\tdb_value = DB_VALUE(pep->idx, stream_id);\n\n\ttrace_cdnsp_tr_drbl(pep, stream_id);\n\n\twritel(db_value, reg_addr);\n\n\tcdnsp_force_l0_go(pdev);\n\n\t \n\treturn true;\n}\n\n \nstatic struct cdnsp_ring *cdnsp_get_transfer_ring(struct cdnsp_device *pdev,\n\t\t\t\t\t\t  struct cdnsp_ep *pep,\n\t\t\t\t\t\t  unsigned int stream_id)\n{\n\tif (!(pep->ep_state & EP_HAS_STREAMS))\n\t\treturn pep->ring;\n\n\tif (stream_id == 0 || stream_id >= pep->stream_info.num_streams) {\n\t\tdev_err(pdev->dev, \"ERR: %s ring doesn't exist for SID: %d.\\n\",\n\t\t\tpep->name, stream_id);\n\t\treturn NULL;\n\t}\n\n\treturn pep->stream_info.stream_rings[stream_id];\n}\n\nstatic struct cdnsp_ring *\n\tcdnsp_request_to_transfer_ring(struct cdnsp_device *pdev,\n\t\t\t\t       struct cdnsp_request *preq)\n{\n\treturn cdnsp_get_transfer_ring(pdev, preq->pep,\n\t\t\t\t       preq->request.stream_id);\n}\n\n \nvoid cdnsp_ring_doorbell_for_active_rings(struct cdnsp_device *pdev,\n\t\t\t\t\t  struct cdnsp_ep *pep)\n{\n\tstruct cdnsp_stream_info *stream_info;\n\tunsigned int stream_id;\n\tint ret;\n\n\tif (pep->ep_state & EP_DIS_IN_RROGRESS)\n\t\treturn;\n\n\t \n\tif (!(pep->ep_state & EP_HAS_STREAMS) && pep->number) {\n\t\tif (pep->ring && !list_empty(&pep->ring->td_list))\n\t\t\tcdnsp_ring_ep_doorbell(pdev, pep, 0);\n\t\treturn;\n\t}\n\n\tstream_info = &pep->stream_info;\n\n\tfor (stream_id = 1; stream_id < stream_info->num_streams; stream_id++) {\n\t\tstruct cdnsp_td *td, *td_temp;\n\t\tstruct cdnsp_ring *ep_ring;\n\n\t\tif (stream_info->drbls_count >= 2)\n\t\t\treturn;\n\n\t\tep_ring = cdnsp_get_transfer_ring(pdev, pep, stream_id);\n\t\tif (!ep_ring)\n\t\t\tcontinue;\n\n\t\tif (!ep_ring->stream_active || ep_ring->stream_rejected)\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(td, td_temp, &ep_ring->td_list,\n\t\t\t\t\t td_list) {\n\t\t\tif (td->drbl)\n\t\t\t\tcontinue;\n\n\t\t\tret = cdnsp_ring_ep_doorbell(pdev, pep, stream_id);\n\t\t\tif (ret)\n\t\t\t\ttd->drbl = 1;\n\t\t}\n\t}\n}\n\n \nstatic u64 cdnsp_get_hw_deq(struct cdnsp_device *pdev,\n\t\t\t    unsigned int ep_index,\n\t\t\t    unsigned int stream_id)\n{\n\tstruct cdnsp_stream_ctx *st_ctx;\n\tstruct cdnsp_ep *pep;\n\n\tpep = &pdev->eps[stream_id];\n\n\tif (pep->ep_state & EP_HAS_STREAMS) {\n\t\tst_ctx = &pep->stream_info.stream_ctx_array[stream_id];\n\t\treturn le64_to_cpu(st_ctx->stream_ring);\n\t}\n\n\treturn le64_to_cpu(pep->out_ctx->deq);\n}\n\n \nstatic void cdnsp_find_new_dequeue_state(struct cdnsp_device *pdev,\n\t\t\t\t\t struct cdnsp_ep *pep,\n\t\t\t\t\t unsigned int stream_id,\n\t\t\t\t\t struct cdnsp_td *cur_td,\n\t\t\t\t\t struct cdnsp_dequeue_state *state)\n{\n\tbool td_last_trb_found = false;\n\tstruct cdnsp_segment *new_seg;\n\tstruct cdnsp_ring *ep_ring;\n\tunion cdnsp_trb *new_deq;\n\tbool cycle_found = false;\n\tu64 hw_dequeue;\n\n\tep_ring = cdnsp_get_transfer_ring(pdev, pep, stream_id);\n\tif (!ep_ring)\n\t\treturn;\n\n\t \n\thw_dequeue = cdnsp_get_hw_deq(pdev, pep->idx, stream_id);\n\tnew_seg = ep_ring->deq_seg;\n\tnew_deq = ep_ring->dequeue;\n\tstate->new_cycle_state = hw_dequeue & 0x1;\n\tstate->stream_id = stream_id;\n\n\t \n\tdo {\n\t\tif (!cycle_found && cdnsp_trb_virt_to_dma(new_seg, new_deq)\n\t\t    == (dma_addr_t)(hw_dequeue & ~0xf)) {\n\t\t\tcycle_found = true;\n\n\t\t\tif (td_last_trb_found)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (new_deq == cur_td->last_trb)\n\t\t\ttd_last_trb_found = true;\n\n\t\tif (cycle_found && cdnsp_trb_is_link(new_deq) &&\n\t\t    cdnsp_link_trb_toggles_cycle(new_deq))\n\t\t\tstate->new_cycle_state ^= 0x1;\n\n\t\tcdnsp_next_trb(pdev, ep_ring, &new_seg, &new_deq);\n\n\t\t \n\t\tif (new_deq == pep->ring->dequeue) {\n\t\t\tdev_err(pdev->dev,\n\t\t\t\t\"Error: Failed finding new dequeue state\\n\");\n\t\t\tstate->new_deq_seg = NULL;\n\t\t\tstate->new_deq_ptr = NULL;\n\t\t\treturn;\n\t\t}\n\n\t} while (!cycle_found || !td_last_trb_found);\n\n\tstate->new_deq_seg = new_seg;\n\tstate->new_deq_ptr = new_deq;\n\n\ttrace_cdnsp_new_deq_state(state);\n}\n\n \nstatic void cdnsp_td_to_noop(struct cdnsp_device *pdev,\n\t\t\t     struct cdnsp_ring *ep_ring,\n\t\t\t     struct cdnsp_td *td,\n\t\t\t     bool flip_cycle)\n{\n\tstruct cdnsp_segment *seg = td->start_seg;\n\tunion cdnsp_trb *trb = td->first_trb;\n\n\twhile (1) {\n\t\tcdnsp_trb_to_noop(trb, TRB_TR_NOOP);\n\n\t\t \n\t\tif (flip_cycle && trb != td->first_trb && trb != td->last_trb)\n\t\t\ttrb->generic.field[3] ^= cpu_to_le32(TRB_CYCLE);\n\n\t\tif (trb == td->last_trb)\n\t\t\tbreak;\n\n\t\tcdnsp_next_trb(pdev, ep_ring, &seg, &trb);\n\t}\n}\n\n \nstatic struct cdnsp_segment *cdnsp_trb_in_td(struct cdnsp_device *pdev,\n\t\t\t\t\t     struct cdnsp_segment *start_seg,\n\t\t\t\t\t     union cdnsp_trb *start_trb,\n\t\t\t\t\t     union cdnsp_trb *end_trb,\n\t\t\t\t\t     dma_addr_t suspect_dma)\n{\n\tstruct cdnsp_segment *cur_seg;\n\tunion cdnsp_trb *temp_trb;\n\tdma_addr_t end_seg_dma;\n\tdma_addr_t end_trb_dma;\n\tdma_addr_t start_dma;\n\n\tstart_dma = cdnsp_trb_virt_to_dma(start_seg, start_trb);\n\tcur_seg = start_seg;\n\n\tdo {\n\t\tif (start_dma == 0)\n\t\t\treturn NULL;\n\n\t\ttemp_trb = &cur_seg->trbs[TRBS_PER_SEGMENT - 1];\n\t\t \n\t\tend_seg_dma = cdnsp_trb_virt_to_dma(cur_seg, temp_trb);\n\t\t \n\t\tend_trb_dma = cdnsp_trb_virt_to_dma(cur_seg, end_trb);\n\n\t\ttrace_cdnsp_looking_trb_in_td(suspect_dma, start_dma,\n\t\t\t\t\t      end_trb_dma, cur_seg->dma,\n\t\t\t\t\t      end_seg_dma);\n\n\t\tif (end_trb_dma > 0) {\n\t\t\t \n\t\t\tif (start_dma <= end_trb_dma) {\n\t\t\t\tif (suspect_dma >= start_dma &&\n\t\t\t\t    suspect_dma <= end_trb_dma) {\n\t\t\t\t\treturn cur_seg;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tif ((suspect_dma >= start_dma &&\n\t\t\t\t     suspect_dma <= end_seg_dma) ||\n\t\t\t\t    (suspect_dma >= cur_seg->dma &&\n\t\t\t\t     suspect_dma <= end_trb_dma)) {\n\t\t\t\t\treturn cur_seg;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn NULL;\n\t\t}\n\n\t\t \n\t\tif (suspect_dma >= start_dma && suspect_dma <= end_seg_dma)\n\t\t\treturn cur_seg;\n\n\t\tcur_seg = cur_seg->next;\n\t\tstart_dma = cdnsp_trb_virt_to_dma(cur_seg, &cur_seg->trbs[0]);\n\t} while (cur_seg != start_seg);\n\n\treturn NULL;\n}\n\nstatic void cdnsp_unmap_td_bounce_buffer(struct cdnsp_device *pdev,\n\t\t\t\t\t struct cdnsp_ring *ring,\n\t\t\t\t\t struct cdnsp_td *td)\n{\n\tstruct cdnsp_segment *seg = td->bounce_seg;\n\tstruct cdnsp_request *preq;\n\tsize_t len;\n\n\tif (!seg)\n\t\treturn;\n\n\tpreq = td->preq;\n\n\ttrace_cdnsp_bounce_unmap(td->preq, seg->bounce_len, seg->bounce_offs,\n\t\t\t\t seg->bounce_dma, 0);\n\n\tif (!preq->direction) {\n\t\tdma_unmap_single(pdev->dev, seg->bounce_dma,\n\t\t\t\t ring->bounce_buf_len,  DMA_TO_DEVICE);\n\t\treturn;\n\t}\n\n\tdma_unmap_single(pdev->dev, seg->bounce_dma, ring->bounce_buf_len,\n\t\t\t DMA_FROM_DEVICE);\n\n\t \n\tlen = sg_pcopy_from_buffer(preq->request.sg, preq->request.num_sgs,\n\t\t\t\t   seg->bounce_buf, seg->bounce_len,\n\t\t\t\t   seg->bounce_offs);\n\tif (len != seg->bounce_len)\n\t\tdev_warn(pdev->dev, \"WARN Wrong bounce buffer read length: %zu != %d\\n\",\n\t\t\t len, seg->bounce_len);\n\n\tseg->bounce_len = 0;\n\tseg->bounce_offs = 0;\n}\n\nstatic int cdnsp_cmd_set_deq(struct cdnsp_device *pdev,\n\t\t\t     struct cdnsp_ep *pep,\n\t\t\t     struct cdnsp_dequeue_state *deq_state)\n{\n\tstruct cdnsp_ring *ep_ring;\n\tint ret;\n\n\tif (!deq_state->new_deq_ptr || !deq_state->new_deq_seg) {\n\t\tcdnsp_ring_doorbell_for_active_rings(pdev, pep);\n\t\treturn 0;\n\t}\n\n\tcdnsp_queue_new_dequeue_state(pdev, pep, deq_state);\n\tcdnsp_ring_cmd_db(pdev);\n\tret = cdnsp_wait_for_cmd_compl(pdev);\n\n\ttrace_cdnsp_handle_cmd_set_deq(cdnsp_get_slot_ctx(&pdev->out_ctx));\n\ttrace_cdnsp_handle_cmd_set_deq_ep(pep->out_ctx);\n\n\t \n\tep_ring = cdnsp_get_transfer_ring(pdev, pep, deq_state->stream_id);\n\n\tif (cdnsp_trb_is_link(ep_ring->dequeue)) {\n\t\tep_ring->deq_seg = ep_ring->deq_seg->next;\n\t\tep_ring->dequeue = ep_ring->deq_seg->trbs;\n\t}\n\n\twhile (ep_ring->dequeue != deq_state->new_deq_ptr) {\n\t\tep_ring->num_trbs_free++;\n\t\tep_ring->dequeue++;\n\n\t\tif (cdnsp_trb_is_link(ep_ring->dequeue)) {\n\t\t\tif (ep_ring->dequeue == deq_state->new_deq_ptr)\n\t\t\t\tbreak;\n\n\t\t\tep_ring->deq_seg = ep_ring->deq_seg->next;\n\t\t\tep_ring->dequeue = ep_ring->deq_seg->trbs;\n\t\t}\n\t}\n\n\t \n\tif (ret)\n\t\treturn -ESHUTDOWN;\n\n\t \n\tcdnsp_ring_doorbell_for_active_rings(pdev, pep);\n\n\treturn 0;\n}\n\nint cdnsp_remove_request(struct cdnsp_device *pdev,\n\t\t\t struct cdnsp_request *preq,\n\t\t\t struct cdnsp_ep *pep)\n{\n\tstruct cdnsp_dequeue_state deq_state;\n\tstruct cdnsp_td *cur_td = NULL;\n\tstruct cdnsp_ring *ep_ring;\n\tstruct cdnsp_segment *seg;\n\tint status = -ECONNRESET;\n\tint ret = 0;\n\tu64 hw_deq;\n\n\tmemset(&deq_state, 0, sizeof(deq_state));\n\n\ttrace_cdnsp_remove_request(pep->out_ctx);\n\ttrace_cdnsp_remove_request_td(preq);\n\n\tcur_td = &preq->td;\n\tep_ring = cdnsp_request_to_transfer_ring(pdev, preq);\n\n\t \n\thw_deq = cdnsp_get_hw_deq(pdev, pep->idx, preq->request.stream_id);\n\thw_deq &= ~0xf;\n\n\tseg = cdnsp_trb_in_td(pdev, cur_td->start_seg, cur_td->first_trb,\n\t\t\t      cur_td->last_trb, hw_deq);\n\n\tif (seg && (pep->ep_state & EP_ENABLED))\n\t\tcdnsp_find_new_dequeue_state(pdev, pep, preq->request.stream_id,\n\t\t\t\t\t     cur_td, &deq_state);\n\telse\n\t\tcdnsp_td_to_noop(pdev, ep_ring, cur_td, false);\n\n\t \n\tlist_del_init(&cur_td->td_list);\n\tep_ring->num_tds--;\n\tpep->stream_info.td_count--;\n\n\t \n\tif (pdev->cdnsp_state & CDNSP_STATE_DISCONNECT_PENDING) {\n\t\tstatus = -ESHUTDOWN;\n\t\tret = cdnsp_cmd_set_deq(pdev, pep, &deq_state);\n\t}\n\n\tcdnsp_unmap_td_bounce_buffer(pdev, ep_ring, cur_td);\n\tcdnsp_gadget_giveback(pep, cur_td->preq, status);\n\n\treturn ret;\n}\n\nstatic int cdnsp_update_port_id(struct cdnsp_device *pdev, u32 port_id)\n{\n\tstruct cdnsp_port *port = pdev->active_port;\n\tu8 old_port = 0;\n\n\tif (port && port->port_num == port_id)\n\t\treturn 0;\n\n\tif (port)\n\t\told_port = port->port_num;\n\n\tif (port_id == pdev->usb2_port.port_num) {\n\t\tport = &pdev->usb2_port;\n\t} else if (port_id == pdev->usb3_port.port_num) {\n\t\tport  = &pdev->usb3_port;\n\t} else {\n\t\tdev_err(pdev->dev, \"Port event with invalid port ID %d\\n\",\n\t\t\tport_id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (port_id != old_port) {\n\t\tcdnsp_disable_slot(pdev);\n\t\tpdev->active_port = port;\n\t\tcdnsp_enable_slot(pdev);\n\t}\n\n\tif (port_id == pdev->usb2_port.port_num)\n\t\tcdnsp_set_usb2_hardware_lpm(pdev, NULL, 1);\n\telse\n\t\twritel(PORT_U1_TIMEOUT(1) | PORT_U2_TIMEOUT(1),\n\t\t       &pdev->usb3_port.regs->portpmsc);\n\n\treturn 0;\n}\n\nstatic void cdnsp_handle_port_status(struct cdnsp_device *pdev,\n\t\t\t\t     union cdnsp_trb *event)\n{\n\tstruct cdnsp_port_regs __iomem *port_regs;\n\tu32 portsc, cmd_regs;\n\tbool port2 = false;\n\tu32 link_state;\n\tu32 port_id;\n\n\t \n\tif (GET_COMP_CODE(le32_to_cpu(event->generic.field[2])) != COMP_SUCCESS)\n\t\tdev_err(pdev->dev, \"ERR: incorrect PSC event\\n\");\n\n\tport_id = GET_PORT_ID(le32_to_cpu(event->generic.field[0]));\n\n\tif (cdnsp_update_port_id(pdev, port_id))\n\t\tgoto cleanup;\n\n\tport_regs = pdev->active_port->regs;\n\n\tif (port_id == pdev->usb2_port.port_num)\n\t\tport2 = true;\n\nnew_event:\n\tportsc = readl(&port_regs->portsc);\n\twritel(cdnsp_port_state_to_neutral(portsc) |\n\t       (portsc & PORT_CHANGE_BITS), &port_regs->portsc);\n\n\ttrace_cdnsp_handle_port_status(pdev->active_port->port_num, portsc);\n\n\tpdev->gadget.speed = cdnsp_port_speed(portsc);\n\tlink_state = portsc & PORT_PLS_MASK;\n\n\t \n\tif ((portsc & PORT_PLC)) {\n\t\tif (!(pdev->cdnsp_state & CDNSP_WAKEUP_PENDING)  &&\n\t\t    link_state == XDEV_RESUME) {\n\t\t\tcmd_regs = readl(&pdev->op_regs->command);\n\t\t\tif (!(cmd_regs & CMD_R_S))\n\t\t\t\tgoto cleanup;\n\n\t\t\tif (DEV_SUPERSPEED_ANY(portsc)) {\n\t\t\t\tcdnsp_set_link_state(pdev, &port_regs->portsc,\n\t\t\t\t\t\t     XDEV_U0);\n\n\t\t\t\tcdnsp_resume_gadget(pdev);\n\t\t\t}\n\t\t}\n\n\t\tif ((pdev->cdnsp_state & CDNSP_WAKEUP_PENDING) &&\n\t\t    link_state == XDEV_U0) {\n\t\t\tpdev->cdnsp_state &= ~CDNSP_WAKEUP_PENDING;\n\n\t\t\tcdnsp_force_header_wakeup(pdev, 1);\n\t\t\tcdnsp_ring_cmd_db(pdev);\n\t\t\tcdnsp_wait_for_cmd_compl(pdev);\n\t\t}\n\n\t\tif (link_state == XDEV_U0 && pdev->link_state == XDEV_U3 &&\n\t\t    !DEV_SUPERSPEED_ANY(portsc))\n\t\t\tcdnsp_resume_gadget(pdev);\n\n\t\tif (link_state == XDEV_U3 &&  pdev->link_state != XDEV_U3)\n\t\t\tcdnsp_suspend_gadget(pdev);\n\n\t\tpdev->link_state = link_state;\n\t}\n\n\tif (portsc & PORT_CSC) {\n\t\t \n\t\tif (pdev->gadget.connected && !(portsc & PORT_CONNECT))\n\t\t\tcdnsp_disconnect_gadget(pdev);\n\n\t\t \n\t\tif (portsc & PORT_CONNECT) {\n\t\t\tif (!port2)\n\t\t\t\tcdnsp_irq_reset(pdev);\n\n\t\t\tusb_gadget_set_state(&pdev->gadget, USB_STATE_ATTACHED);\n\t\t}\n\t}\n\n\t \n\tif ((portsc & (PORT_RC | PORT_WRC)) && (portsc & PORT_CONNECT)) {\n\t\tcdnsp_irq_reset(pdev);\n\t\tpdev->u1_allowed = 0;\n\t\tpdev->u2_allowed = 0;\n\t\tpdev->may_wakeup = 0;\n\t}\n\n\tif (portsc & PORT_CEC)\n\t\tdev_err(pdev->dev, \"Port Over Current detected\\n\");\n\n\tif (portsc & PORT_CEC)\n\t\tdev_err(pdev->dev, \"Port Configure Error detected\\n\");\n\n\tif (readl(&port_regs->portsc) & PORT_CHANGE_BITS)\n\t\tgoto new_event;\n\ncleanup:\n\tcdnsp_inc_deq(pdev, pdev->event_ring);\n}\n\nstatic void cdnsp_td_cleanup(struct cdnsp_device *pdev,\n\t\t\t     struct cdnsp_td *td,\n\t\t\t     struct cdnsp_ring *ep_ring,\n\t\t\t     int *status)\n{\n\tstruct cdnsp_request *preq = td->preq;\n\n\t \n\tcdnsp_unmap_td_bounce_buffer(pdev, ep_ring, td);\n\n\t \n\tif (preq->request.actual > preq->request.length) {\n\t\tpreq->request.actual = 0;\n\t\t*status = 0;\n\t}\n\n\tlist_del_init(&td->td_list);\n\tep_ring->num_tds--;\n\tpreq->pep->stream_info.td_count--;\n\n\tcdnsp_gadget_giveback(preq->pep, preq, *status);\n}\n\nstatic void cdnsp_finish_td(struct cdnsp_device *pdev,\n\t\t\t    struct cdnsp_td *td,\n\t\t\t    struct cdnsp_transfer_event *event,\n\t\t\t    struct cdnsp_ep *ep,\n\t\t\t    int *status)\n{\n\tstruct cdnsp_ring *ep_ring;\n\tu32 trb_comp_code;\n\n\tep_ring = cdnsp_dma_to_transfer_ring(ep, le64_to_cpu(event->buffer));\n\ttrb_comp_code = GET_COMP_CODE(le32_to_cpu(event->transfer_len));\n\n\tif (trb_comp_code == COMP_STOPPED_LENGTH_INVALID ||\n\t    trb_comp_code == COMP_STOPPED ||\n\t    trb_comp_code == COMP_STOPPED_SHORT_PACKET) {\n\t\t \n\t\treturn;\n\t}\n\n\t \n\twhile (ep_ring->dequeue != td->last_trb)\n\t\tcdnsp_inc_deq(pdev, ep_ring);\n\n\tcdnsp_inc_deq(pdev, ep_ring);\n\n\tcdnsp_td_cleanup(pdev, td, ep_ring, status);\n}\n\n \nstatic int cdnsp_sum_trb_lengths(struct cdnsp_device *pdev,\n\t\t\t\t struct cdnsp_ring *ring,\n\t\t\t\t union cdnsp_trb *stop_trb)\n{\n\tstruct cdnsp_segment *seg = ring->deq_seg;\n\tunion cdnsp_trb *trb = ring->dequeue;\n\tu32 sum;\n\n\tfor (sum = 0; trb != stop_trb; cdnsp_next_trb(pdev, ring, &seg, &trb)) {\n\t\tif (!cdnsp_trb_is_noop(trb) && !cdnsp_trb_is_link(trb))\n\t\t\tsum += TRB_LEN(le32_to_cpu(trb->generic.field[2]));\n\t}\n\treturn sum;\n}\n\nstatic int cdnsp_giveback_first_trb(struct cdnsp_device *pdev,\n\t\t\t\t    struct cdnsp_ep *pep,\n\t\t\t\t    unsigned int stream_id,\n\t\t\t\t    int start_cycle,\n\t\t\t\t    struct cdnsp_generic_trb *start_trb)\n{\n\t \n\twmb();\n\n\tif (start_cycle)\n\t\tstart_trb->field[3] |= cpu_to_le32(start_cycle);\n\telse\n\t\tstart_trb->field[3] &= cpu_to_le32(~TRB_CYCLE);\n\n\tif ((pep->ep_state & EP_HAS_STREAMS) &&\n\t    !pep->stream_info.first_prime_det) {\n\t\ttrace_cdnsp_wait_for_prime(pep, stream_id);\n\t\treturn 0;\n\t}\n\n\treturn cdnsp_ring_ep_doorbell(pdev, pep, stream_id);\n}\n\n \nstatic void cdnsp_process_ctrl_td(struct cdnsp_device *pdev,\n\t\t\t\t  struct cdnsp_td *td,\n\t\t\t\t  union cdnsp_trb *event_trb,\n\t\t\t\t  struct cdnsp_transfer_event *event,\n\t\t\t\t  struct cdnsp_ep *pep,\n\t\t\t\t  int *status)\n{\n\tstruct cdnsp_ring *ep_ring;\n\tu32 remaining;\n\tu32 trb_type;\n\n\ttrb_type = TRB_FIELD_TO_TYPE(le32_to_cpu(event_trb->generic.field[3]));\n\tep_ring = cdnsp_dma_to_transfer_ring(pep, le64_to_cpu(event->buffer));\n\tremaining = EVENT_TRB_LEN(le32_to_cpu(event->transfer_len));\n\n\t \n\tif (trb_type == TRB_DATA) {\n\t\ttd->request_length_set = true;\n\t\ttd->preq->request.actual = td->preq->request.length - remaining;\n\t}\n\n\t \n\tif (!td->request_length_set)\n\t\ttd->preq->request.actual = td->preq->request.length;\n\n\tif (pdev->ep0_stage == CDNSP_DATA_STAGE && pep->number == 0 &&\n\t    pdev->three_stage_setup) {\n\t\ttd = list_entry(ep_ring->td_list.next, struct cdnsp_td,\n\t\t\t\ttd_list);\n\t\tpdev->ep0_stage = CDNSP_STATUS_STAGE;\n\n\t\tcdnsp_giveback_first_trb(pdev, pep, 0, ep_ring->cycle_state,\n\t\t\t\t\t &td->last_trb->generic);\n\t\treturn;\n\t}\n\n\t*status = 0;\n\n\tcdnsp_finish_td(pdev, td, event, pep, status);\n}\n\n \nstatic void cdnsp_process_isoc_td(struct cdnsp_device *pdev,\n\t\t\t\t  struct cdnsp_td *td,\n\t\t\t\t  union cdnsp_trb *ep_trb,\n\t\t\t\t  struct cdnsp_transfer_event *event,\n\t\t\t\t  struct cdnsp_ep *pep,\n\t\t\t\t  int status)\n{\n\tstruct cdnsp_request *preq = td->preq;\n\tu32 remaining, requested, ep_trb_len;\n\tbool sum_trbs_for_length = false;\n\tstruct cdnsp_ring *ep_ring;\n\tu32 trb_comp_code;\n\tu32 td_length;\n\n\tep_ring = cdnsp_dma_to_transfer_ring(pep, le64_to_cpu(event->buffer));\n\ttrb_comp_code = GET_COMP_CODE(le32_to_cpu(event->transfer_len));\n\tremaining = EVENT_TRB_LEN(le32_to_cpu(event->transfer_len));\n\tep_trb_len = TRB_LEN(le32_to_cpu(ep_trb->generic.field[2]));\n\n\trequested = preq->request.length;\n\n\t \n\tswitch (trb_comp_code) {\n\tcase COMP_SUCCESS:\n\t\tpreq->request.status = 0;\n\t\tbreak;\n\tcase COMP_SHORT_PACKET:\n\t\tpreq->request.status = 0;\n\t\tsum_trbs_for_length = true;\n\t\tbreak;\n\tcase COMP_ISOCH_BUFFER_OVERRUN:\n\tcase COMP_BABBLE_DETECTED_ERROR:\n\t\tpreq->request.status = -EOVERFLOW;\n\t\tbreak;\n\tcase COMP_STOPPED:\n\t\tsum_trbs_for_length = true;\n\t\tbreak;\n\tcase COMP_STOPPED_SHORT_PACKET:\n\t\t \n\t\tpreq->request.status  = 0;\n\t\trequested = remaining;\n\t\tbreak;\n\tcase COMP_STOPPED_LENGTH_INVALID:\n\t\trequested = 0;\n\t\tremaining = 0;\n\t\tbreak;\n\tdefault:\n\t\tsum_trbs_for_length = true;\n\t\tpreq->request.status = -1;\n\t\tbreak;\n\t}\n\n\tif (sum_trbs_for_length) {\n\t\ttd_length = cdnsp_sum_trb_lengths(pdev, ep_ring, ep_trb);\n\t\ttd_length += ep_trb_len - remaining;\n\t} else {\n\t\ttd_length = requested;\n\t}\n\n\ttd->preq->request.actual += td_length;\n\n\tcdnsp_finish_td(pdev, td, event, pep, &status);\n}\n\nstatic void cdnsp_skip_isoc_td(struct cdnsp_device *pdev,\n\t\t\t       struct cdnsp_td *td,\n\t\t\t       struct cdnsp_transfer_event *event,\n\t\t\t       struct cdnsp_ep *pep,\n\t\t\t       int status)\n{\n\tstruct cdnsp_ring *ep_ring;\n\n\tep_ring = cdnsp_dma_to_transfer_ring(pep, le64_to_cpu(event->buffer));\n\ttd->preq->request.status = -EXDEV;\n\ttd->preq->request.actual = 0;\n\n\t \n\twhile (ep_ring->dequeue != td->last_trb)\n\t\tcdnsp_inc_deq(pdev, ep_ring);\n\n\tcdnsp_inc_deq(pdev, ep_ring);\n\n\tcdnsp_td_cleanup(pdev, td, ep_ring, &status);\n}\n\n \nstatic void cdnsp_process_bulk_intr_td(struct cdnsp_device *pdev,\n\t\t\t\t       struct cdnsp_td *td,\n\t\t\t\t       union cdnsp_trb *ep_trb,\n\t\t\t\t       struct cdnsp_transfer_event *event,\n\t\t\t\t       struct cdnsp_ep *ep,\n\t\t\t\t       int *status)\n{\n\tu32 remaining, requested, ep_trb_len;\n\tstruct cdnsp_ring *ep_ring;\n\tu32 trb_comp_code;\n\n\tep_ring = cdnsp_dma_to_transfer_ring(ep, le64_to_cpu(event->buffer));\n\ttrb_comp_code = GET_COMP_CODE(le32_to_cpu(event->transfer_len));\n\tremaining = EVENT_TRB_LEN(le32_to_cpu(event->transfer_len));\n\tep_trb_len = TRB_LEN(le32_to_cpu(ep_trb->generic.field[2]));\n\trequested = td->preq->request.length;\n\n\tswitch (trb_comp_code) {\n\tcase COMP_SUCCESS:\n\tcase COMP_SHORT_PACKET:\n\t\t*status = 0;\n\t\tbreak;\n\tcase COMP_STOPPED_SHORT_PACKET:\n\t\ttd->preq->request.actual = remaining;\n\t\tgoto finish_td;\n\tcase COMP_STOPPED_LENGTH_INVALID:\n\t\t \n\t\tep_trb_len = 0;\n\t\tremaining = 0;\n\t\tbreak;\n\t}\n\n\tif (ep_trb == td->last_trb)\n\t\tep_trb_len = requested - remaining;\n\telse\n\t\tep_trb_len = cdnsp_sum_trb_lengths(pdev, ep_ring, ep_trb) +\n\t\t\t\t\t\t   ep_trb_len - remaining;\n\ttd->preq->request.actual = ep_trb_len;\n\nfinish_td:\n\tep->stream_info.drbls_count--;\n\n\tcdnsp_finish_td(pdev, td, event, ep, status);\n}\n\nstatic void cdnsp_handle_tx_nrdy(struct cdnsp_device *pdev,\n\t\t\t\t struct cdnsp_transfer_event *event)\n{\n\tstruct cdnsp_generic_trb *generic;\n\tstruct cdnsp_ring *ep_ring;\n\tstruct cdnsp_ep *pep;\n\tint cur_stream;\n\tint ep_index;\n\tint host_sid;\n\tint dev_sid;\n\n\tgeneric = (struct cdnsp_generic_trb *)event;\n\tep_index = TRB_TO_EP_ID(le32_to_cpu(event->flags)) - 1;\n\tdev_sid = TRB_TO_DEV_STREAM(le32_to_cpu(generic->field[0]));\n\thost_sid = TRB_TO_HOST_STREAM(le32_to_cpu(generic->field[2]));\n\n\tpep = &pdev->eps[ep_index];\n\n\tif (!(pep->ep_state & EP_HAS_STREAMS))\n\t\treturn;\n\n\tif (host_sid == STREAM_PRIME_ACK) {\n\t\tpep->stream_info.first_prime_det = 1;\n\t\tfor (cur_stream = 1; cur_stream < pep->stream_info.num_streams;\n\t\t    cur_stream++) {\n\t\t\tep_ring = pep->stream_info.stream_rings[cur_stream];\n\t\t\tep_ring->stream_active = 1;\n\t\t\tep_ring->stream_rejected = 0;\n\t\t}\n\t}\n\n\tif (host_sid == STREAM_REJECTED) {\n\t\tstruct cdnsp_td *td, *td_temp;\n\n\t\tpep->stream_info.drbls_count--;\n\t\tep_ring = pep->stream_info.stream_rings[dev_sid];\n\t\tep_ring->stream_active = 0;\n\t\tep_ring->stream_rejected = 1;\n\n\t\tlist_for_each_entry_safe(td, td_temp, &ep_ring->td_list,\n\t\t\t\t\t td_list) {\n\t\t\ttd->drbl = 0;\n\t\t}\n\t}\n\n\tcdnsp_ring_doorbell_for_active_rings(pdev, pep);\n}\n\n \nstatic int cdnsp_handle_tx_event(struct cdnsp_device *pdev,\n\t\t\t\t struct cdnsp_transfer_event *event)\n{\n\tconst struct usb_endpoint_descriptor *desc;\n\tbool handling_skipped_tds = false;\n\tstruct cdnsp_segment *ep_seg;\n\tstruct cdnsp_ring *ep_ring;\n\tint status = -EINPROGRESS;\n\tunion cdnsp_trb *ep_trb;\n\tdma_addr_t ep_trb_dma;\n\tstruct cdnsp_ep *pep;\n\tstruct cdnsp_td *td;\n\tu32 trb_comp_code;\n\tint invalidate;\n\tint ep_index;\n\n\tinvalidate = le32_to_cpu(event->flags) & TRB_EVENT_INVALIDATE;\n\tep_index = TRB_TO_EP_ID(le32_to_cpu(event->flags)) - 1;\n\ttrb_comp_code = GET_COMP_CODE(le32_to_cpu(event->transfer_len));\n\tep_trb_dma = le64_to_cpu(event->buffer);\n\n\tpep = &pdev->eps[ep_index];\n\tep_ring = cdnsp_dma_to_transfer_ring(pep, le64_to_cpu(event->buffer));\n\n\t \n\tif (invalidate || !pdev->gadget.connected)\n\t\tgoto cleanup;\n\n\tif (GET_EP_CTX_STATE(pep->out_ctx) == EP_STATE_DISABLED) {\n\t\ttrace_cdnsp_ep_disabled(pep->out_ctx);\n\t\tgoto err_out;\n\t}\n\n\t \n\tif (!ep_ring) {\n\t\tswitch (trb_comp_code) {\n\t\tcase COMP_INVALID_STREAM_TYPE_ERROR:\n\t\tcase COMP_INVALID_STREAM_ID_ERROR:\n\t\tcase COMP_RING_UNDERRUN:\n\t\tcase COMP_RING_OVERRUN:\n\t\t\tgoto cleanup;\n\t\tdefault:\n\t\t\tdev_err(pdev->dev, \"ERROR: %s event for unknown ring\\n\",\n\t\t\t\tpep->name);\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\t \n\tswitch (trb_comp_code) {\n\tcase COMP_BABBLE_DETECTED_ERROR:\n\t\tstatus = -EOVERFLOW;\n\t\tbreak;\n\tcase COMP_RING_UNDERRUN:\n\tcase COMP_RING_OVERRUN:\n\t\t \n\t\tgoto cleanup;\n\tcase COMP_MISSED_SERVICE_ERROR:\n\t\t \n\t\tpep->skip = true;\n\t\tbreak;\n\t}\n\n\tdo {\n\t\t \n\t\tif (list_empty(&ep_ring->td_list)) {\n\t\t\t \n\t\t\tif (!(trb_comp_code == COMP_STOPPED ||\n\t\t\t      trb_comp_code == COMP_STOPPED_LENGTH_INVALID ||\n\t\t\t      ep_ring->last_td_was_short))\n\t\t\t\ttrace_cdnsp_trb_without_td(ep_ring,\n\t\t\t\t\t(struct cdnsp_generic_trb *)event);\n\n\t\t\tif (pep->skip) {\n\t\t\t\tpep->skip = false;\n\t\t\t\ttrace_cdnsp_ep_list_empty_with_skip(pep, 0);\n\t\t\t}\n\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\ttd = list_entry(ep_ring->td_list.next, struct cdnsp_td,\n\t\t\t\ttd_list);\n\n\t\t \n\t\tep_seg = cdnsp_trb_in_td(pdev, ep_ring->deq_seg,\n\t\t\t\t\t ep_ring->dequeue, td->last_trb,\n\t\t\t\t\t ep_trb_dma);\n\n\t\tdesc = td->preq->pep->endpoint.desc;\n\n\t\tif (ep_seg) {\n\t\t\tep_trb = &ep_seg->trbs[(ep_trb_dma - ep_seg->dma)\n\t\t\t\t\t       / sizeof(*ep_trb)];\n\n\t\t\ttrace_cdnsp_handle_transfer(ep_ring,\n\t\t\t\t\t(struct cdnsp_generic_trb *)ep_trb);\n\n\t\t\tif (pep->skip && usb_endpoint_xfer_isoc(desc) &&\n\t\t\t    td->last_trb != ep_trb)\n\t\t\t\treturn -EAGAIN;\n\t\t}\n\n\t\t \n\t\tif (!ep_seg && (trb_comp_code == COMP_STOPPED ||\n\t\t\t\ttrb_comp_code == COMP_STOPPED_LENGTH_INVALID)) {\n\t\t\tpep->skip = false;\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tif (!ep_seg) {\n\t\t\tif (!pep->skip || !usb_endpoint_xfer_isoc(desc)) {\n\t\t\t\t \n\t\t\t\tdev_err(pdev->dev,\n\t\t\t\t\t\"ERROR Transfer event TRB DMA ptr not \"\n\t\t\t\t\t\"part of current TD ep_index %d \"\n\t\t\t\t\t\"comp_code %u\\n\", ep_index,\n\t\t\t\t\ttrb_comp_code);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tcdnsp_skip_isoc_td(pdev, td, event, pep, status);\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tif (trb_comp_code == COMP_SHORT_PACKET)\n\t\t\tep_ring->last_td_was_short = true;\n\t\telse\n\t\t\tep_ring->last_td_was_short = false;\n\n\t\tif (pep->skip) {\n\t\t\tpep->skip = false;\n\t\t\tcdnsp_skip_isoc_td(pdev, td, event, pep, status);\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tif (cdnsp_trb_is_noop(ep_trb))\n\t\t\tgoto cleanup;\n\n\t\tif (usb_endpoint_xfer_control(desc))\n\t\t\tcdnsp_process_ctrl_td(pdev, td, ep_trb, event, pep,\n\t\t\t\t\t      &status);\n\t\telse if (usb_endpoint_xfer_isoc(desc))\n\t\t\tcdnsp_process_isoc_td(pdev, td, ep_trb, event, pep,\n\t\t\t\t\t      status);\n\t\telse\n\t\t\tcdnsp_process_bulk_intr_td(pdev, td, ep_trb, event, pep,\n\t\t\t\t\t\t   &status);\ncleanup:\n\t\thandling_skipped_tds = pep->skip;\n\n\t\t \n\t\tif (!handling_skipped_tds)\n\t\t\tcdnsp_inc_deq(pdev, pdev->event_ring);\n\n\t \n\t} while (handling_skipped_tds);\n\treturn 0;\n\nerr_out:\n\tdev_err(pdev->dev, \"@%016llx %08x %08x %08x %08x\\n\",\n\t\t(unsigned long long)\n\t\tcdnsp_trb_virt_to_dma(pdev->event_ring->deq_seg,\n\t\t\t\t      pdev->event_ring->dequeue),\n\t\t lower_32_bits(le64_to_cpu(event->buffer)),\n\t\t upper_32_bits(le64_to_cpu(event->buffer)),\n\t\t le32_to_cpu(event->transfer_len),\n\t\t le32_to_cpu(event->flags));\n\treturn -EINVAL;\n}\n\n \nstatic bool cdnsp_handle_event(struct cdnsp_device *pdev)\n{\n\tunsigned int comp_code;\n\tunion cdnsp_trb *event;\n\tbool update_ptrs = true;\n\tu32 cycle_bit;\n\tint ret = 0;\n\tu32 flags;\n\n\tevent = pdev->event_ring->dequeue;\n\tflags = le32_to_cpu(event->event_cmd.flags);\n\tcycle_bit = (flags & TRB_CYCLE);\n\n\t \n\tif (cycle_bit != pdev->event_ring->cycle_state)\n\t\treturn false;\n\n\ttrace_cdnsp_handle_event(pdev->event_ring, &event->generic);\n\n\t \n\trmb();\n\n\tswitch (flags & TRB_TYPE_BITMASK) {\n\tcase TRB_TYPE(TRB_COMPLETION):\n\t\t \n\t\tcdnsp_inc_deq(pdev, pdev->cmd_ring);\n\t\tbreak;\n\tcase TRB_TYPE(TRB_PORT_STATUS):\n\t\tcdnsp_handle_port_status(pdev, event);\n\t\tupdate_ptrs = false;\n\t\tbreak;\n\tcase TRB_TYPE(TRB_TRANSFER):\n\t\tret = cdnsp_handle_tx_event(pdev, &event->trans_event);\n\t\tif (ret >= 0)\n\t\t\tupdate_ptrs = false;\n\t\tbreak;\n\tcase TRB_TYPE(TRB_SETUP):\n\t\tpdev->ep0_stage = CDNSP_SETUP_STAGE;\n\t\tpdev->setup_id = TRB_SETUPID_TO_TYPE(flags);\n\t\tpdev->setup_speed = TRB_SETUP_SPEEDID(flags);\n\t\tpdev->setup = *((struct usb_ctrlrequest *)\n\t\t\t\t&event->trans_event.buffer);\n\n\t\tcdnsp_setup_analyze(pdev);\n\t\tbreak;\n\tcase TRB_TYPE(TRB_ENDPOINT_NRDY):\n\t\tcdnsp_handle_tx_nrdy(pdev, &event->trans_event);\n\t\tbreak;\n\tcase TRB_TYPE(TRB_HC_EVENT): {\n\t\tcomp_code = GET_COMP_CODE(le32_to_cpu(event->generic.field[2]));\n\n\t\tswitch (comp_code) {\n\t\tcase COMP_EVENT_RING_FULL_ERROR:\n\t\t\tdev_err(pdev->dev, \"Event Ring Full\\n\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(pdev->dev, \"Controller error code 0x%02x\\n\",\n\t\t\t\tcomp_code);\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase TRB_TYPE(TRB_MFINDEX_WRAP):\n\tcase TRB_TYPE(TRB_DRB_OVERFLOW):\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(pdev->dev, \"ERROR unknown event type %ld\\n\",\n\t\t\t TRB_FIELD_TO_TYPE(flags));\n\t}\n\n\tif (update_ptrs)\n\t\t \n\t\tcdnsp_inc_deq(pdev, pdev->event_ring);\n\n\t \n\treturn true;\n}\n\nirqreturn_t cdnsp_thread_irq_handler(int irq, void *data)\n{\n\tstruct cdnsp_device *pdev = (struct cdnsp_device *)data;\n\tunion cdnsp_trb *event_ring_deq;\n\tunsigned long flags;\n\tint counter = 0;\n\n\tlocal_bh_disable();\n\tspin_lock_irqsave(&pdev->lock, flags);\n\n\tif (pdev->cdnsp_state & (CDNSP_STATE_HALTED | CDNSP_STATE_DYING)) {\n\t\t \n\t\tif (pdev->gadget_driver)\n\t\t\tcdnsp_died(pdev);\n\n\t\tspin_unlock_irqrestore(&pdev->lock, flags);\n\t\tlocal_bh_enable();\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tevent_ring_deq = pdev->event_ring->dequeue;\n\n\twhile (cdnsp_handle_event(pdev)) {\n\t\tif (++counter >= TRBS_PER_EV_DEQ_UPDATE) {\n\t\t\tcdnsp_update_erst_dequeue(pdev, event_ring_deq, 0);\n\t\t\tevent_ring_deq = pdev->event_ring->dequeue;\n\t\t\tcounter = 0;\n\t\t}\n\t}\n\n\tcdnsp_update_erst_dequeue(pdev, event_ring_deq, 1);\n\n\tspin_unlock_irqrestore(&pdev->lock, flags);\n\tlocal_bh_enable();\n\n\treturn IRQ_HANDLED;\n}\n\nirqreturn_t cdnsp_irq_handler(int irq, void *priv)\n{\n\tstruct cdnsp_device *pdev = (struct cdnsp_device *)priv;\n\tu32 irq_pending;\n\tu32 status;\n\n\tstatus = readl(&pdev->op_regs->status);\n\n\tif (status == ~(u32)0) {\n\t\tcdnsp_died(pdev);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tif (!(status & STS_EINT))\n\t\treturn IRQ_NONE;\n\n\twritel(status | STS_EINT, &pdev->op_regs->status);\n\tirq_pending = readl(&pdev->ir_set->irq_pending);\n\tirq_pending |= IMAN_IP;\n\twritel(irq_pending, &pdev->ir_set->irq_pending);\n\n\tif (status & STS_FATAL) {\n\t\tcdnsp_died(pdev);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\treturn IRQ_WAKE_THREAD;\n}\n\n \nstatic void cdnsp_queue_trb(struct cdnsp_device *pdev, struct cdnsp_ring *ring,\n\t\t\t    bool more_trbs_coming, u32 field1, u32 field2,\n\t\t\t    u32 field3, u32 field4)\n{\n\tstruct cdnsp_generic_trb *trb;\n\n\ttrb = &ring->enqueue->generic;\n\n\ttrb->field[0] = cpu_to_le32(field1);\n\ttrb->field[1] = cpu_to_le32(field2);\n\ttrb->field[2] = cpu_to_le32(field3);\n\ttrb->field[3] = cpu_to_le32(field4);\n\n\ttrace_cdnsp_queue_trb(ring, trb);\n\tcdnsp_inc_enq(pdev, ring, more_trbs_coming);\n}\n\n \nstatic int cdnsp_prepare_ring(struct cdnsp_device *pdev,\n\t\t\t      struct cdnsp_ring *ep_ring,\n\t\t\t      u32 ep_state, unsigned\n\t\t\t      int num_trbs,\n\t\t\t      gfp_t mem_flags)\n{\n\tunsigned int num_trbs_needed;\n\n\t \n\tswitch (ep_state) {\n\tcase EP_STATE_STOPPED:\n\tcase EP_STATE_RUNNING:\n\tcase EP_STATE_HALTED:\n\t\tbreak;\n\tdefault:\n\t\tdev_err(pdev->dev, \"ERROR: incorrect endpoint state\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\twhile (1) {\n\t\tif (cdnsp_room_on_ring(pdev, ep_ring, num_trbs))\n\t\t\tbreak;\n\n\t\ttrace_cdnsp_no_room_on_ring(\"try ring expansion\");\n\n\t\tnum_trbs_needed = num_trbs - ep_ring->num_trbs_free;\n\t\tif (cdnsp_ring_expansion(pdev, ep_ring, num_trbs_needed,\n\t\t\t\t\t mem_flags)) {\n\t\t\tdev_err(pdev->dev, \"Ring expansion failed\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\twhile (cdnsp_trb_is_link(ep_ring->enqueue)) {\n\t\tep_ring->enqueue->link.control |= cpu_to_le32(TRB_CHAIN);\n\t\t \n\t\twmb();\n\t\tep_ring->enqueue->link.control ^= cpu_to_le32(TRB_CYCLE);\n\n\t\t \n\t\tif (cdnsp_link_trb_toggles_cycle(ep_ring->enqueue))\n\t\t\tep_ring->cycle_state ^= 1;\n\t\tep_ring->enq_seg = ep_ring->enq_seg->next;\n\t\tep_ring->enqueue = ep_ring->enq_seg->trbs;\n\t}\n\treturn 0;\n}\n\nstatic int cdnsp_prepare_transfer(struct cdnsp_device *pdev,\n\t\t\t\t  struct cdnsp_request *preq,\n\t\t\t\t  unsigned int num_trbs)\n{\n\tstruct cdnsp_ring *ep_ring;\n\tint ret;\n\n\tep_ring = cdnsp_get_transfer_ring(pdev, preq->pep,\n\t\t\t\t\t  preq->request.stream_id);\n\tif (!ep_ring)\n\t\treturn -EINVAL;\n\n\tret = cdnsp_prepare_ring(pdev, ep_ring,\n\t\t\t\t GET_EP_CTX_STATE(preq->pep->out_ctx),\n\t\t\t\t num_trbs, GFP_ATOMIC);\n\tif (ret)\n\t\treturn ret;\n\n\tINIT_LIST_HEAD(&preq->td.td_list);\n\tpreq->td.preq = preq;\n\n\t \n\tlist_add_tail(&preq->td.td_list, &ep_ring->td_list);\n\tep_ring->num_tds++;\n\tpreq->pep->stream_info.td_count++;\n\n\tpreq->td.start_seg = ep_ring->enq_seg;\n\tpreq->td.first_trb = ep_ring->enqueue;\n\n\treturn 0;\n}\n\nstatic unsigned int cdnsp_count_trbs(u64 addr, u64 len)\n{\n\tunsigned int num_trbs;\n\n\tnum_trbs = DIV_ROUND_UP(len + (addr & (TRB_MAX_BUFF_SIZE - 1)),\n\t\t\t\tTRB_MAX_BUFF_SIZE);\n\tif (num_trbs == 0)\n\t\tnum_trbs++;\n\n\treturn num_trbs;\n}\n\nstatic unsigned int count_trbs_needed(struct cdnsp_request *preq)\n{\n\treturn cdnsp_count_trbs(preq->request.dma, preq->request.length);\n}\n\nstatic unsigned int count_sg_trbs_needed(struct cdnsp_request *preq)\n{\n\tunsigned int i, len, full_len, num_trbs = 0;\n\tstruct scatterlist *sg;\n\n\tfull_len = preq->request.length;\n\n\tfor_each_sg(preq->request.sg, sg, preq->request.num_sgs, i) {\n\t\tlen = sg_dma_len(sg);\n\t\tnum_trbs += cdnsp_count_trbs(sg_dma_address(sg), len);\n\t\tlen = min(len, full_len);\n\t\tfull_len -= len;\n\t\tif (full_len == 0)\n\t\t\tbreak;\n\t}\n\n\treturn num_trbs;\n}\n\nstatic void cdnsp_check_trb_math(struct cdnsp_request *preq, int running_total)\n{\n\tif (running_total != preq->request.length)\n\t\tdev_err(preq->pep->pdev->dev,\n\t\t\t\"%s - Miscalculated tx length, \"\n\t\t\t\"queued %#x, asked for %#x (%d)\\n\",\n\t\t\tpreq->pep->name, running_total,\n\t\t\tpreq->request.length, preq->request.actual);\n}\n\n \nstatic u32 cdnsp_td_remainder(struct cdnsp_device *pdev,\n\t\t\t      int transferred,\n\t\t\t      int trb_buff_len,\n\t\t\t      unsigned int td_total_len,\n\t\t\t      struct cdnsp_request *preq,\n\t\t\t      bool more_trbs_coming,\n\t\t\t      bool zlp)\n{\n\tu32 maxp, total_packet_count;\n\n\t \n\tif (zlp)\n\t\treturn 1;\n\n\t \n\tif (!more_trbs_coming || (transferred == 0 && trb_buff_len == 0) ||\n\t    trb_buff_len == td_total_len)\n\t\treturn 0;\n\n\tmaxp = usb_endpoint_maxp(preq->pep->endpoint.desc);\n\ttotal_packet_count = DIV_ROUND_UP(td_total_len, maxp);\n\n\t \n\treturn (total_packet_count - ((transferred + trb_buff_len) / maxp));\n}\n\nstatic int cdnsp_align_td(struct cdnsp_device *pdev,\n\t\t\t  struct cdnsp_request *preq, u32 enqd_len,\n\t\t\t  u32 *trb_buff_len, struct cdnsp_segment *seg)\n{\n\tstruct device *dev = pdev->dev;\n\tunsigned int unalign;\n\tunsigned int max_pkt;\n\tu32 new_buff_len;\n\n\tmax_pkt = usb_endpoint_maxp(preq->pep->endpoint.desc);\n\tunalign = (enqd_len + *trb_buff_len) % max_pkt;\n\n\t \n\tif (unalign == 0)\n\t\treturn 0;\n\n\t \n\tif (*trb_buff_len > unalign) {\n\t\t*trb_buff_len -= unalign;\n\t\ttrace_cdnsp_bounce_align_td_split(preq, *trb_buff_len,\n\t\t\t\t\t\t  enqd_len, 0, unalign);\n\t\treturn 0;\n\t}\n\n\t \n\tnew_buff_len = max_pkt - (enqd_len % max_pkt);\n\n\tif (new_buff_len > (preq->request.length - enqd_len))\n\t\tnew_buff_len = (preq->request.length - enqd_len);\n\n\t \n\tif (preq->direction) {\n\t\tsg_pcopy_to_buffer(preq->request.sg,\n\t\t\t\t   preq->request.num_mapped_sgs,\n\t\t\t\t   seg->bounce_buf, new_buff_len, enqd_len);\n\t\tseg->bounce_dma = dma_map_single(dev, seg->bounce_buf,\n\t\t\t\t\t\t max_pkt, DMA_TO_DEVICE);\n\t} else {\n\t\tseg->bounce_dma = dma_map_single(dev, seg->bounce_buf,\n\t\t\t\t\t\t max_pkt, DMA_FROM_DEVICE);\n\t}\n\n\tif (dma_mapping_error(dev, seg->bounce_dma)) {\n\t\t \n\t\tdev_warn(pdev->dev,\n\t\t\t \"Failed mapping bounce buffer, not aligning\\n\");\n\t\treturn 0;\n\t}\n\n\t*trb_buff_len = new_buff_len;\n\tseg->bounce_len = new_buff_len;\n\tseg->bounce_offs = enqd_len;\n\n\ttrace_cdnsp_bounce_map(preq, new_buff_len, enqd_len, seg->bounce_dma,\n\t\t\t       unalign);\n\n\t \n\treturn 1;\n}\n\nint cdnsp_queue_bulk_tx(struct cdnsp_device *pdev, struct cdnsp_request *preq)\n{\n\tunsigned int enqd_len, block_len, trb_buff_len, full_len;\n\tunsigned int start_cycle, num_sgs = 0;\n\tstruct cdnsp_generic_trb *start_trb;\n\tu32 field, length_field, remainder;\n\tstruct scatterlist *sg = NULL;\n\tbool more_trbs_coming = true;\n\tbool need_zero_pkt = false;\n\tbool zero_len_trb = false;\n\tstruct cdnsp_ring *ring;\n\tbool first_trb = true;\n\tunsigned int num_trbs;\n\tstruct cdnsp_ep *pep;\n\tu64 addr, send_addr;\n\tint sent_len, ret;\n\n\tring = cdnsp_request_to_transfer_ring(pdev, preq);\n\tif (!ring)\n\t\treturn -EINVAL;\n\n\tfull_len = preq->request.length;\n\n\tif (preq->request.num_sgs) {\n\t\tnum_sgs = preq->request.num_sgs;\n\t\tsg = preq->request.sg;\n\t\taddr = (u64)sg_dma_address(sg);\n\t\tblock_len = sg_dma_len(sg);\n\t\tnum_trbs = count_sg_trbs_needed(preq);\n\t} else {\n\t\tnum_trbs = count_trbs_needed(preq);\n\t\taddr = (u64)preq->request.dma;\n\t\tblock_len = full_len;\n\t}\n\n\tpep = preq->pep;\n\n\t \n\tif (preq->request.zero && preq->request.length &&\n\t    IS_ALIGNED(full_len, usb_endpoint_maxp(pep->endpoint.desc))) {\n\t\tneed_zero_pkt = true;\n\t\tnum_trbs++;\n\t}\n\n\tret = cdnsp_prepare_transfer(pdev, preq, num_trbs);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tstart_trb = &ring->enqueue->generic;\n\tstart_cycle = ring->cycle_state;\n\tsend_addr = addr;\n\n\t \n\tfor (enqd_len = 0; zero_len_trb || first_trb || enqd_len < full_len;\n\t     enqd_len += trb_buff_len) {\n\t\tfield = TRB_TYPE(TRB_NORMAL);\n\n\t\t \n\t\ttrb_buff_len = TRB_BUFF_LEN_UP_TO_BOUNDARY(addr);\n\t\ttrb_buff_len = min(trb_buff_len, block_len);\n\t\tif (enqd_len + trb_buff_len > full_len)\n\t\t\ttrb_buff_len = full_len - enqd_len;\n\n\t\t \n\t\tif (first_trb) {\n\t\t\tfirst_trb = false;\n\t\t\tif (start_cycle == 0)\n\t\t\t\tfield |= TRB_CYCLE;\n\t\t} else {\n\t\t\tfield |= ring->cycle_state;\n\t\t}\n\n\t\t \n\t\tif (enqd_len + trb_buff_len < full_len || need_zero_pkt) {\n\t\t\tfield |= TRB_CHAIN;\n\t\t\tif (cdnsp_trb_is_link(ring->enqueue + 1)) {\n\t\t\t\tif (cdnsp_align_td(pdev, preq, enqd_len,\n\t\t\t\t\t\t   &trb_buff_len,\n\t\t\t\t\t\t   ring->enq_seg)) {\n\t\t\t\t\tsend_addr = ring->enq_seg->bounce_dma;\n\t\t\t\t\t \n\t\t\t\t\tpreq->td.bounce_seg = ring->enq_seg;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (enqd_len + trb_buff_len >= full_len) {\n\t\t\tif (need_zero_pkt && !zero_len_trb) {\n\t\t\t\tzero_len_trb = true;\n\t\t\t} else {\n\t\t\t\tzero_len_trb = false;\n\t\t\t\tfield &= ~TRB_CHAIN;\n\t\t\t\tfield |= TRB_IOC;\n\t\t\t\tmore_trbs_coming = false;\n\t\t\t\tneed_zero_pkt = false;\n\t\t\t\tpreq->td.last_trb = ring->enqueue;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (!preq->direction)\n\t\t\tfield |= TRB_ISP;\n\n\t\t \n\t\tremainder = cdnsp_td_remainder(pdev, enqd_len, trb_buff_len,\n\t\t\t\t\t       full_len, preq,\n\t\t\t\t\t       more_trbs_coming,\n\t\t\t\t\t       zero_len_trb);\n\n\t\tlength_field = TRB_LEN(trb_buff_len) | TRB_TD_SIZE(remainder) |\n\t\t\tTRB_INTR_TARGET(0);\n\n\t\tcdnsp_queue_trb(pdev, ring, more_trbs_coming,\n\t\t\t\tlower_32_bits(send_addr),\n\t\t\t\tupper_32_bits(send_addr),\n\t\t\t\tlength_field,\n\t\t\t\tfield);\n\n\t\taddr += trb_buff_len;\n\t\tsent_len = trb_buff_len;\n\t\twhile (sg && sent_len >= block_len) {\n\t\t\t \n\t\t\t--num_sgs;\n\t\t\tsent_len -= block_len;\n\t\t\tif (num_sgs != 0) {\n\t\t\t\tsg = sg_next(sg);\n\t\t\t\tblock_len = sg_dma_len(sg);\n\t\t\t\taddr = (u64)sg_dma_address(sg);\n\t\t\t\taddr += sent_len;\n\t\t\t}\n\t\t}\n\t\tblock_len -= sent_len;\n\t\tsend_addr = addr;\n\t}\n\n\tcdnsp_check_trb_math(preq, enqd_len);\n\tret = cdnsp_giveback_first_trb(pdev, pep, preq->request.stream_id,\n\t\t\t\t       start_cycle, start_trb);\n\n\tif (ret)\n\t\tpreq->td.drbl = 1;\n\n\treturn 0;\n}\n\nint cdnsp_queue_ctrl_tx(struct cdnsp_device *pdev, struct cdnsp_request *preq)\n{\n\tu32 field, length_field, zlp = 0;\n\tstruct cdnsp_ep *pep = preq->pep;\n\tstruct cdnsp_ring *ep_ring;\n\tint num_trbs;\n\tu32 maxp;\n\tint ret;\n\n\tep_ring = cdnsp_request_to_transfer_ring(pdev, preq);\n\tif (!ep_ring)\n\t\treturn -EINVAL;\n\n\t \n\tnum_trbs = (pdev->three_stage_setup) ? 2 : 1;\n\n\tmaxp = usb_endpoint_maxp(pep->endpoint.desc);\n\n\tif (preq->request.zero && preq->request.length &&\n\t    (preq->request.length % maxp == 0)) {\n\t\tnum_trbs++;\n\t\tzlp = 1;\n\t}\n\n\tret = cdnsp_prepare_transfer(pdev, preq, num_trbs);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (preq->request.length > 0) {\n\t\tfield = TRB_TYPE(TRB_DATA);\n\n\t\tif (zlp)\n\t\t\tfield |= TRB_CHAIN;\n\t\telse\n\t\t\tfield |= TRB_IOC | (pdev->ep0_expect_in ? 0 : TRB_ISP);\n\n\t\tif (pdev->ep0_expect_in)\n\t\t\tfield |= TRB_DIR_IN;\n\n\t\tlength_field = TRB_LEN(preq->request.length) |\n\t\t\t       TRB_TD_SIZE(zlp) | TRB_INTR_TARGET(0);\n\n\t\tcdnsp_queue_trb(pdev, ep_ring, true,\n\t\t\t\tlower_32_bits(preq->request.dma),\n\t\t\t\tupper_32_bits(preq->request.dma), length_field,\n\t\t\t\tfield | ep_ring->cycle_state |\n\t\t\t\tTRB_SETUPID(pdev->setup_id) |\n\t\t\t\tpdev->setup_speed);\n\n\t\tif (zlp) {\n\t\t\tfield = TRB_TYPE(TRB_NORMAL) | TRB_IOC;\n\n\t\t\tif (!pdev->ep0_expect_in)\n\t\t\t\tfield = TRB_ISP;\n\n\t\t\tcdnsp_queue_trb(pdev, ep_ring, true,\n\t\t\t\t\tlower_32_bits(preq->request.dma),\n\t\t\t\t\tupper_32_bits(preq->request.dma), 0,\n\t\t\t\t\tfield | ep_ring->cycle_state |\n\t\t\t\t\tTRB_SETUPID(pdev->setup_id) |\n\t\t\t\t\tpdev->setup_speed);\n\t\t}\n\n\t\tpdev->ep0_stage = CDNSP_DATA_STAGE;\n\t}\n\n\t \n\tpreq->td.last_trb = ep_ring->enqueue;\n\n\t \n\tif (preq->request.length == 0)\n\t\tfield = ep_ring->cycle_state;\n\telse\n\t\tfield = (ep_ring->cycle_state ^ 1);\n\n\tif (preq->request.length > 0 && pdev->ep0_expect_in)\n\t\tfield |= TRB_DIR_IN;\n\n\tif (pep->ep_state & EP0_HALTED_STATUS) {\n\t\tpep->ep_state &= ~EP0_HALTED_STATUS;\n\t\tfield |= TRB_SETUPSTAT(TRB_SETUPSTAT_STALL);\n\t} else {\n\t\tfield |= TRB_SETUPSTAT(TRB_SETUPSTAT_ACK);\n\t}\n\n\tcdnsp_queue_trb(pdev, ep_ring, false, 0, 0, TRB_INTR_TARGET(0),\n\t\t\tfield | TRB_IOC | TRB_SETUPID(pdev->setup_id) |\n\t\t\tTRB_TYPE(TRB_STATUS) | pdev->setup_speed);\n\n\tcdnsp_ring_ep_doorbell(pdev, pep, preq->request.stream_id);\n\n\treturn 0;\n}\n\nint cdnsp_cmd_stop_ep(struct cdnsp_device *pdev, struct cdnsp_ep *pep)\n{\n\tu32 ep_state = GET_EP_CTX_STATE(pep->out_ctx);\n\tint ret = 0;\n\n\tif (ep_state == EP_STATE_STOPPED || ep_state == EP_STATE_DISABLED ||\n\t    ep_state == EP_STATE_HALTED) {\n\t\ttrace_cdnsp_ep_stopped_or_disabled(pep->out_ctx);\n\t\tgoto ep_stopped;\n\t}\n\n\tcdnsp_queue_stop_endpoint(pdev, pep->idx);\n\tcdnsp_ring_cmd_db(pdev);\n\tret = cdnsp_wait_for_cmd_compl(pdev);\n\n\ttrace_cdnsp_handle_cmd_stop_ep(pep->out_ctx);\n\nep_stopped:\n\tpep->ep_state |= EP_STOPPED;\n\treturn ret;\n}\n\nint cdnsp_cmd_flush_ep(struct cdnsp_device *pdev, struct cdnsp_ep *pep)\n{\n\tint ret;\n\n\tcdnsp_queue_flush_endpoint(pdev, pep->idx);\n\tcdnsp_ring_cmd_db(pdev);\n\tret = cdnsp_wait_for_cmd_compl(pdev);\n\n\ttrace_cdnsp_handle_cmd_flush_ep(pep->out_ctx);\n\n\treturn ret;\n}\n\n \nstatic unsigned int cdnsp_get_burst_count(struct cdnsp_device *pdev,\n\t\t\t\t\t  struct cdnsp_request *preq,\n\t\t\t\t\t  unsigned int total_packet_count)\n{\n\tunsigned int max_burst;\n\n\tif (pdev->gadget.speed < USB_SPEED_SUPER)\n\t\treturn 0;\n\n\tmax_burst = preq->pep->endpoint.comp_desc->bMaxBurst;\n\treturn DIV_ROUND_UP(total_packet_count, max_burst + 1) - 1;\n}\n\n \nstatic unsigned int\n\tcdnsp_get_last_burst_packet_count(struct cdnsp_device *pdev,\n\t\t\t\t\t  struct cdnsp_request *preq,\n\t\t\t\t\t  unsigned int total_packet_count)\n{\n\tunsigned int max_burst;\n\tunsigned int residue;\n\n\tif (pdev->gadget.speed >= USB_SPEED_SUPER) {\n\t\t \n\t\tmax_burst = preq->pep->endpoint.comp_desc->bMaxBurst;\n\t\tresidue = total_packet_count % (max_burst + 1);\n\n\t\t \n\t\tif (residue == 0)\n\t\t\treturn max_burst;\n\n\t\treturn residue - 1;\n\t}\n\tif (total_packet_count == 0)\n\t\treturn 0;\n\n\treturn total_packet_count - 1;\n}\n\n \nint cdnsp_queue_isoc_tx(struct cdnsp_device *pdev,\n\t\t\tstruct cdnsp_request *preq)\n{\n\tunsigned int trb_buff_len, td_len, td_remain_len, block_len;\n\tunsigned int burst_count, last_burst_pkt;\n\tunsigned int total_pkt_count, max_pkt;\n\tstruct cdnsp_generic_trb *start_trb;\n\tstruct scatterlist *sg = NULL;\n\tbool more_trbs_coming = true;\n\tstruct cdnsp_ring *ep_ring;\n\tunsigned int num_sgs = 0;\n\tint running_total = 0;\n\tu32 field, length_field;\n\tu64 addr, send_addr;\n\tint start_cycle;\n\tint trbs_per_td;\n\tint i, sent_len, ret;\n\n\tep_ring = preq->pep->ring;\n\n\ttd_len = preq->request.length;\n\n\tif (preq->request.num_sgs) {\n\t\tnum_sgs = preq->request.num_sgs;\n\t\tsg = preq->request.sg;\n\t\taddr = (u64)sg_dma_address(sg);\n\t\tblock_len = sg_dma_len(sg);\n\t\ttrbs_per_td = count_sg_trbs_needed(preq);\n\t} else {\n\t\taddr = (u64)preq->request.dma;\n\t\tblock_len = td_len;\n\t\ttrbs_per_td = count_trbs_needed(preq);\n\t}\n\n\tret = cdnsp_prepare_transfer(pdev, preq, trbs_per_td);\n\tif (ret)\n\t\treturn ret;\n\n\tstart_trb = &ep_ring->enqueue->generic;\n\tstart_cycle = ep_ring->cycle_state;\n\ttd_remain_len = td_len;\n\tsend_addr = addr;\n\n\tmax_pkt = usb_endpoint_maxp(preq->pep->endpoint.desc);\n\ttotal_pkt_count = DIV_ROUND_UP(td_len, max_pkt);\n\n\t \n\tif (total_pkt_count == 0)\n\t\ttotal_pkt_count++;\n\n\tburst_count = cdnsp_get_burst_count(pdev, preq, total_pkt_count);\n\tlast_burst_pkt = cdnsp_get_last_burst_packet_count(pdev, preq,\n\t\t\t\t\t\t\t   total_pkt_count);\n\n\t \n\tfield = TRB_TYPE(TRB_ISOC) | TRB_TLBPC(last_burst_pkt) |\n\t\tTRB_SIA | TRB_TBC(burst_count);\n\n\tif (!start_cycle)\n\t\tfield |= TRB_CYCLE;\n\n\t \n\tfor (i = 0; i < trbs_per_td; i++) {\n\t\tu32 remainder;\n\n\t\t \n\t\ttrb_buff_len = TRB_BUFF_LEN_UP_TO_BOUNDARY(addr);\n\t\ttrb_buff_len = min(trb_buff_len, block_len);\n\t\tif (trb_buff_len > td_remain_len)\n\t\t\ttrb_buff_len = td_remain_len;\n\n\t\t \n\t\tremainder = cdnsp_td_remainder(pdev, running_total,\n\t\t\t\t\t       trb_buff_len, td_len, preq,\n\t\t\t\t\t       more_trbs_coming, 0);\n\n\t\tlength_field = TRB_LEN(trb_buff_len) | TRB_TD_SIZE(remainder) |\n\t\t\tTRB_INTR_TARGET(0);\n\n\t\t \n\t\tif (i) {\n\t\t\tfield = TRB_TYPE(TRB_NORMAL) | ep_ring->cycle_state;\n\t\t\tlength_field |= TRB_TD_SIZE(remainder);\n\t\t} else {\n\t\t\tlength_field |= TRB_TD_SIZE_TBC(burst_count);\n\t\t}\n\n\t\t \n\t\tif (usb_endpoint_dir_out(preq->pep->endpoint.desc))\n\t\t\tfield |= TRB_ISP;\n\n\t\t \n\t\tif (i < trbs_per_td - 1) {\n\t\t\tmore_trbs_coming = true;\n\t\t\tfield |= TRB_CHAIN;\n\t\t} else {\n\t\t\tmore_trbs_coming = false;\n\t\t\tpreq->td.last_trb = ep_ring->enqueue;\n\t\t\tfield |= TRB_IOC;\n\t\t}\n\n\t\tcdnsp_queue_trb(pdev, ep_ring, more_trbs_coming,\n\t\t\t\tlower_32_bits(send_addr), upper_32_bits(send_addr),\n\t\t\t\tlength_field, field);\n\n\t\trunning_total += trb_buff_len;\n\t\taddr += trb_buff_len;\n\t\ttd_remain_len -= trb_buff_len;\n\n\t\tsent_len = trb_buff_len;\n\t\twhile (sg && sent_len >= block_len) {\n\t\t\t \n\t\t\t--num_sgs;\n\t\t\tsent_len -= block_len;\n\t\t\tif (num_sgs != 0) {\n\t\t\t\tsg = sg_next(sg);\n\t\t\t\tblock_len = sg_dma_len(sg);\n\t\t\t\taddr = (u64)sg_dma_address(sg);\n\t\t\t\taddr += sent_len;\n\t\t\t}\n\t\t}\n\t\tblock_len -= sent_len;\n\t\tsend_addr = addr;\n\t}\n\n\t \n\tif (running_total != td_len) {\n\t\tdev_err(pdev->dev, \"ISOC TD length unmatch\\n\");\n\t\tret = -EINVAL;\n\t\tgoto cleanup;\n\t}\n\n\tcdnsp_giveback_first_trb(pdev, preq->pep, preq->request.stream_id,\n\t\t\t\t start_cycle, start_trb);\n\n\treturn 0;\n\ncleanup:\n\t \n\tlist_del_init(&preq->td.td_list);\n\tep_ring->num_tds--;\n\n\t \n\tpreq->td.last_trb = ep_ring->enqueue;\n\t \n\tcdnsp_td_to_noop(pdev, ep_ring, &preq->td, true);\n\n\t \n\tep_ring->enqueue = preq->td.first_trb;\n\tep_ring->enq_seg = preq->td.start_seg;\n\tep_ring->cycle_state = start_cycle;\n\treturn ret;\n}\n\n \n \nstatic void cdnsp_queue_command(struct cdnsp_device *pdev,\n\t\t\t\tu32 field1,\n\t\t\t\tu32 field2,\n\t\t\t\tu32 field3,\n\t\t\t\tu32 field4)\n{\n\tcdnsp_prepare_ring(pdev, pdev->cmd_ring, EP_STATE_RUNNING, 1,\n\t\t\t   GFP_ATOMIC);\n\n\tpdev->cmd.command_trb = pdev->cmd_ring->enqueue;\n\n\tcdnsp_queue_trb(pdev, pdev->cmd_ring, false, field1, field2,\n\t\t\tfield3, field4 | pdev->cmd_ring->cycle_state);\n}\n\n \nvoid cdnsp_queue_slot_control(struct cdnsp_device *pdev, u32 trb_type)\n{\n\tcdnsp_queue_command(pdev, 0, 0, 0, TRB_TYPE(trb_type) |\n\t\t\t    SLOT_ID_FOR_TRB(pdev->slot_id));\n}\n\n \nvoid cdnsp_queue_address_device(struct cdnsp_device *pdev,\n\t\t\t\tdma_addr_t in_ctx_ptr,\n\t\t\t\tenum cdnsp_setup_dev setup)\n{\n\tcdnsp_queue_command(pdev, lower_32_bits(in_ctx_ptr),\n\t\t\t    upper_32_bits(in_ctx_ptr), 0,\n\t\t\t    TRB_TYPE(TRB_ADDR_DEV) |\n\t\t\t    SLOT_ID_FOR_TRB(pdev->slot_id) |\n\t\t\t    (setup == SETUP_CONTEXT_ONLY ? TRB_BSR : 0));\n}\n\n \nvoid cdnsp_queue_reset_device(struct cdnsp_device *pdev)\n{\n\tcdnsp_queue_command(pdev, 0, 0, 0, TRB_TYPE(TRB_RESET_DEV) |\n\t\t\t    SLOT_ID_FOR_TRB(pdev->slot_id));\n}\n\n \nvoid cdnsp_queue_configure_endpoint(struct cdnsp_device *pdev,\n\t\t\t\t    dma_addr_t in_ctx_ptr)\n{\n\tcdnsp_queue_command(pdev, lower_32_bits(in_ctx_ptr),\n\t\t\t    upper_32_bits(in_ctx_ptr), 0,\n\t\t\t    TRB_TYPE(TRB_CONFIG_EP) |\n\t\t\t    SLOT_ID_FOR_TRB(pdev->slot_id));\n}\n\n \nvoid cdnsp_queue_stop_endpoint(struct cdnsp_device *pdev, unsigned int ep_index)\n{\n\tcdnsp_queue_command(pdev, 0, 0, 0, SLOT_ID_FOR_TRB(pdev->slot_id) |\n\t\t\t    EP_ID_FOR_TRB(ep_index) | TRB_TYPE(TRB_STOP_RING));\n}\n\n \nvoid cdnsp_queue_new_dequeue_state(struct cdnsp_device *pdev,\n\t\t\t\t   struct cdnsp_ep *pep,\n\t\t\t\t   struct cdnsp_dequeue_state *deq_state)\n{\n\tu32 trb_stream_id = STREAM_ID_FOR_TRB(deq_state->stream_id);\n\tu32 trb_slot_id = SLOT_ID_FOR_TRB(pdev->slot_id);\n\tu32 type = TRB_TYPE(TRB_SET_DEQ);\n\tu32 trb_sct = 0;\n\tdma_addr_t addr;\n\n\taddr = cdnsp_trb_virt_to_dma(deq_state->new_deq_seg,\n\t\t\t\t     deq_state->new_deq_ptr);\n\n\tif (deq_state->stream_id)\n\t\ttrb_sct = SCT_FOR_TRB(SCT_PRI_TR);\n\n\tcdnsp_queue_command(pdev, lower_32_bits(addr) | trb_sct |\n\t\t\t    deq_state->new_cycle_state, upper_32_bits(addr),\n\t\t\t    trb_stream_id, trb_slot_id |\n\t\t\t    EP_ID_FOR_TRB(pep->idx) | type);\n}\n\nvoid cdnsp_queue_reset_ep(struct cdnsp_device *pdev, unsigned int ep_index)\n{\n\treturn cdnsp_queue_command(pdev, 0, 0, 0,\n\t\t\t\t   SLOT_ID_FOR_TRB(pdev->slot_id) |\n\t\t\t\t   EP_ID_FOR_TRB(ep_index) |\n\t\t\t\t   TRB_TYPE(TRB_RESET_EP));\n}\n\n \nvoid cdnsp_queue_halt_endpoint(struct cdnsp_device *pdev, unsigned int ep_index)\n{\n\tcdnsp_queue_command(pdev, 0, 0, 0, TRB_TYPE(TRB_HALT_ENDPOINT) |\n\t\t\t    SLOT_ID_FOR_TRB(pdev->slot_id) |\n\t\t\t    EP_ID_FOR_TRB(ep_index));\n}\n\n \nvoid  cdnsp_queue_flush_endpoint(struct cdnsp_device *pdev,\n\t\t\t\t unsigned int ep_index)\n{\n\tcdnsp_queue_command(pdev, 0, 0, 0, TRB_TYPE(TRB_FLUSH_ENDPOINT) |\n\t\t\t    SLOT_ID_FOR_TRB(pdev->slot_id) |\n\t\t\t    EP_ID_FOR_TRB(ep_index));\n}\n\nvoid cdnsp_force_header_wakeup(struct cdnsp_device *pdev, int intf_num)\n{\n\tu32 lo, mid;\n\n\tlo = TRB_FH_TO_PACKET_TYPE(TRB_FH_TR_PACKET) |\n\t     TRB_FH_TO_DEVICE_ADDRESS(pdev->device_address);\n\tmid = TRB_FH_TR_PACKET_DEV_NOT |\n\t      TRB_FH_TO_NOT_TYPE(TRB_FH_TR_PACKET_FUNCTION_WAKE) |\n\t      TRB_FH_TO_INTERFACE(intf_num);\n\n\tcdnsp_queue_command(pdev, lo, mid, 0,\n\t\t\t    TRB_TYPE(TRB_FORCE_HEADER) | SET_PORT_ID(2));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}