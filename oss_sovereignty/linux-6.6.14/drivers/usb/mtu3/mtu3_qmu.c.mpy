{
  "module_name": "mtu3_qmu.c",
  "hash_id": "79ec15bdf8485f66980f038f05d114dd5ff5f83e91903419650d41a2f15f8184",
  "original_prompt": "Ingested from linux-6.6.14/drivers/usb/mtu3/mtu3_qmu.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/dmapool.h>\n#include <linux/iopoll.h>\n\n#include \"mtu3.h\"\n#include \"mtu3_trace.h\"\n\n#define QMU_CHECKSUM_LEN\t16\n\n#define GPD_FLAGS_HWO\tBIT(0)\n#define GPD_FLAGS_BDP\tBIT(1)\n#define GPD_FLAGS_BPS\tBIT(2)\n#define GPD_FLAGS_ZLP\tBIT(6)\n#define GPD_FLAGS_IOC\tBIT(7)\n#define GET_GPD_HWO(gpd)\t(le32_to_cpu((gpd)->dw0_info) & GPD_FLAGS_HWO)\n\n#define GPD_RX_BUF_LEN_OG(x)\t(((x) & 0xffff) << 16)\n#define GPD_RX_BUF_LEN_EL(x)\t(((x) & 0xfffff) << 12)\n#define GPD_RX_BUF_LEN(mtu, x)\t\\\n({\t\t\t\t\\\n\ttypeof(x) x_ = (x);\t\\\n\t((mtu)->gen2cp) ? GPD_RX_BUF_LEN_EL(x_) : GPD_RX_BUF_LEN_OG(x_); \\\n})\n\n#define GPD_DATA_LEN_OG(x)\t((x) & 0xffff)\n#define GPD_DATA_LEN_EL(x)\t((x) & 0xfffff)\n#define GPD_DATA_LEN(mtu, x)\t\\\n({\t\t\t\t\\\n\ttypeof(x) x_ = (x);\t\\\n\t((mtu)->gen2cp) ? GPD_DATA_LEN_EL(x_) : GPD_DATA_LEN_OG(x_); \\\n})\n\n#define GPD_EXT_FLAG_ZLP\tBIT(29)\n#define GPD_EXT_NGP_OG(x)\t(((x) & 0xf) << 20)\n#define GPD_EXT_BUF_OG(x)\t(((x) & 0xf) << 16)\n#define GPD_EXT_NGP_EL(x)\t(((x) & 0xf) << 28)\n#define GPD_EXT_BUF_EL(x)\t(((x) & 0xf) << 24)\n#define GPD_EXT_NGP(mtu, x)\t\\\n({\t\t\t\t\\\n\ttypeof(x) x_ = (x);\t\\\n\t((mtu)->gen2cp) ? GPD_EXT_NGP_EL(x_) : GPD_EXT_NGP_OG(x_); \\\n})\n\n#define GPD_EXT_BUF(mtu, x)\t\\\n({\t\t\t\t\\\n\ttypeof(x) x_ = (x);\t\\\n\t((mtu)->gen2cp) ? GPD_EXT_BUF_EL(x_) : GPD_EXT_BUF_OG(x_); \\\n})\n\n#define HILO_GEN64(hi, lo) (((u64)(hi) << 32) + (lo))\n#define HILO_DMA(hi, lo)\t\\\n\t((dma_addr_t)HILO_GEN64((le32_to_cpu(hi)), (le32_to_cpu(lo))))\n\nstatic dma_addr_t read_txq_cur_addr(void __iomem *mbase, u8 epnum)\n{\n\tu32 txcpr;\n\tu32 txhiar;\n\n\ttxcpr = mtu3_readl(mbase, USB_QMU_TQCPR(epnum));\n\ttxhiar = mtu3_readl(mbase, USB_QMU_TQHIAR(epnum));\n\n\treturn HILO_DMA(QMU_CUR_GPD_ADDR_HI(txhiar), txcpr);\n}\n\nstatic dma_addr_t read_rxq_cur_addr(void __iomem *mbase, u8 epnum)\n{\n\tu32 rxcpr;\n\tu32 rxhiar;\n\n\trxcpr = mtu3_readl(mbase, USB_QMU_RQCPR(epnum));\n\trxhiar = mtu3_readl(mbase, USB_QMU_RQHIAR(epnum));\n\n\treturn HILO_DMA(QMU_CUR_GPD_ADDR_HI(rxhiar), rxcpr);\n}\n\nstatic void write_txq_start_addr(void __iomem *mbase, u8 epnum, dma_addr_t dma)\n{\n\tu32 tqhiar;\n\n\tmtu3_writel(mbase, USB_QMU_TQSAR(epnum),\n\t\t    cpu_to_le32(lower_32_bits(dma)));\n\ttqhiar = mtu3_readl(mbase, USB_QMU_TQHIAR(epnum));\n\ttqhiar &= ~QMU_START_ADDR_HI_MSK;\n\ttqhiar |= QMU_START_ADDR_HI(upper_32_bits(dma));\n\tmtu3_writel(mbase, USB_QMU_TQHIAR(epnum), tqhiar);\n}\n\nstatic void write_rxq_start_addr(void __iomem *mbase, u8 epnum, dma_addr_t dma)\n{\n\tu32 rqhiar;\n\n\tmtu3_writel(mbase, USB_QMU_RQSAR(epnum),\n\t\t    cpu_to_le32(lower_32_bits(dma)));\n\trqhiar = mtu3_readl(mbase, USB_QMU_RQHIAR(epnum));\n\trqhiar &= ~QMU_START_ADDR_HI_MSK;\n\trqhiar |= QMU_START_ADDR_HI(upper_32_bits(dma));\n\tmtu3_writel(mbase, USB_QMU_RQHIAR(epnum), rqhiar);\n}\n\nstatic struct qmu_gpd *gpd_dma_to_virt(struct mtu3_gpd_ring *ring,\n\t\tdma_addr_t dma_addr)\n{\n\tdma_addr_t dma_base = ring->dma;\n\tstruct qmu_gpd *gpd_head = ring->start;\n\tu32 offset = (dma_addr - dma_base) / sizeof(*gpd_head);\n\n\tif (offset >= MAX_GPD_NUM)\n\t\treturn NULL;\n\n\treturn gpd_head + offset;\n}\n\nstatic dma_addr_t gpd_virt_to_dma(struct mtu3_gpd_ring *ring,\n\t\tstruct qmu_gpd *gpd)\n{\n\tdma_addr_t dma_base = ring->dma;\n\tstruct qmu_gpd *gpd_head = ring->start;\n\tu32 offset;\n\n\toffset = gpd - gpd_head;\n\tif (offset >= MAX_GPD_NUM)\n\t\treturn 0;\n\n\treturn dma_base + (offset * sizeof(*gpd));\n}\n\nstatic void gpd_ring_init(struct mtu3_gpd_ring *ring, struct qmu_gpd *gpd)\n{\n\tring->start = gpd;\n\tring->enqueue = gpd;\n\tring->dequeue = gpd;\n\tring->end = gpd + MAX_GPD_NUM - 1;\n}\n\nstatic void reset_gpd_list(struct mtu3_ep *mep)\n{\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\tstruct qmu_gpd *gpd = ring->start;\n\n\tif (gpd) {\n\t\tgpd->dw0_info &= cpu_to_le32(~GPD_FLAGS_HWO);\n\t\tgpd_ring_init(ring, gpd);\n\t}\n}\n\nint mtu3_gpd_ring_alloc(struct mtu3_ep *mep)\n{\n\tstruct qmu_gpd *gpd;\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\n\t \n\tgpd = dma_pool_zalloc(mep->mtu->qmu_gpd_pool, GFP_ATOMIC, &ring->dma);\n\tif (gpd == NULL)\n\t\treturn -ENOMEM;\n\n\tgpd_ring_init(ring, gpd);\n\n\treturn 0;\n}\n\nvoid mtu3_gpd_ring_free(struct mtu3_ep *mep)\n{\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\n\tdma_pool_free(mep->mtu->qmu_gpd_pool,\n\t\t\tring->start, ring->dma);\n\tmemset(ring, 0, sizeof(*ring));\n}\n\nvoid mtu3_qmu_resume(struct mtu3_ep *mep)\n{\n\tstruct mtu3 *mtu = mep->mtu;\n\tvoid __iomem *mbase = mtu->mac_base;\n\tint epnum = mep->epnum;\n\tu32 offset;\n\n\toffset = mep->is_in ? USB_QMU_TQCSR(epnum) : USB_QMU_RQCSR(epnum);\n\n\tmtu3_writel(mbase, offset, QMU_Q_RESUME);\n\tif (!(mtu3_readl(mbase, offset) & QMU_Q_ACTIVE))\n\t\tmtu3_writel(mbase, offset, QMU_Q_RESUME);\n}\n\nstatic struct qmu_gpd *advance_enq_gpd(struct mtu3_gpd_ring *ring)\n{\n\tif (ring->enqueue < ring->end)\n\t\tring->enqueue++;\n\telse\n\t\tring->enqueue = ring->start;\n\n\treturn ring->enqueue;\n}\n\n \nstatic struct qmu_gpd *advance_deq_gpd(struct mtu3_gpd_ring *ring)\n{\n\tif (ring->dequeue < ring->end)\n\t\tring->dequeue++;\n\telse\n\t\tring->dequeue = ring->start;\n\n\treturn ring->dequeue;\n}\n\n \nstatic bool gpd_ring_empty(struct mtu3_gpd_ring *ring)\n{\n\tstruct qmu_gpd *enq = ring->enqueue;\n\tstruct qmu_gpd *next;\n\n\tif (ring->enqueue < ring->end)\n\t\tnext = enq + 1;\n\telse\n\t\tnext = ring->start;\n\n\t \n\treturn next == ring->dequeue;\n}\n\nint mtu3_prepare_transfer(struct mtu3_ep *mep)\n{\n\treturn gpd_ring_empty(&mep->gpd_ring);\n}\n\nstatic int mtu3_prepare_tx_gpd(struct mtu3_ep *mep, struct mtu3_request *mreq)\n{\n\tstruct qmu_gpd *enq;\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\tstruct qmu_gpd *gpd = ring->enqueue;\n\tstruct usb_request *req = &mreq->request;\n\tstruct mtu3 *mtu = mep->mtu;\n\tdma_addr_t enq_dma;\n\tu32 ext_addr;\n\n\tgpd->dw0_info = 0;\t \n\tgpd->buffer = cpu_to_le32(lower_32_bits(req->dma));\n\text_addr = GPD_EXT_BUF(mtu, upper_32_bits(req->dma));\n\tgpd->dw3_info = cpu_to_le32(GPD_DATA_LEN(mtu, req->length));\n\n\t \n\tenq = advance_enq_gpd(ring);\n\tenq_dma = gpd_virt_to_dma(ring, enq);\n\tdev_dbg(mep->mtu->dev, \"TX-EP%d queue gpd=%p, enq=%p, qdma=%pad\\n\",\n\t\tmep->epnum, gpd, enq, &enq_dma);\n\n\tenq->dw0_info &= cpu_to_le32(~GPD_FLAGS_HWO);\n\tgpd->next_gpd = cpu_to_le32(lower_32_bits(enq_dma));\n\text_addr |= GPD_EXT_NGP(mtu, upper_32_bits(enq_dma));\n\tgpd->dw0_info = cpu_to_le32(ext_addr);\n\n\tif (req->zero) {\n\t\tif (mtu->gen2cp)\n\t\t\tgpd->dw0_info |= cpu_to_le32(GPD_FLAGS_ZLP);\n\t\telse\n\t\t\tgpd->dw3_info |= cpu_to_le32(GPD_EXT_FLAG_ZLP);\n\t}\n\n\t \n\tmb();\n\tgpd->dw0_info |= cpu_to_le32(GPD_FLAGS_IOC | GPD_FLAGS_HWO);\n\n\tmreq->gpd = gpd;\n\ttrace_mtu3_prepare_gpd(mep, gpd);\n\n\treturn 0;\n}\n\nstatic int mtu3_prepare_rx_gpd(struct mtu3_ep *mep, struct mtu3_request *mreq)\n{\n\tstruct qmu_gpd *enq;\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\tstruct qmu_gpd *gpd = ring->enqueue;\n\tstruct usb_request *req = &mreq->request;\n\tstruct mtu3 *mtu = mep->mtu;\n\tdma_addr_t enq_dma;\n\tu32 ext_addr;\n\n\tgpd->dw0_info = 0;\t \n\tgpd->buffer = cpu_to_le32(lower_32_bits(req->dma));\n\text_addr = GPD_EXT_BUF(mtu, upper_32_bits(req->dma));\n\tgpd->dw0_info = cpu_to_le32(GPD_RX_BUF_LEN(mtu, req->length));\n\n\t \n\tenq = advance_enq_gpd(ring);\n\tenq_dma = gpd_virt_to_dma(ring, enq);\n\tdev_dbg(mep->mtu->dev, \"RX-EP%d queue gpd=%p, enq=%p, qdma=%pad\\n\",\n\t\tmep->epnum, gpd, enq, &enq_dma);\n\n\tenq->dw0_info &= cpu_to_le32(~GPD_FLAGS_HWO);\n\tgpd->next_gpd = cpu_to_le32(lower_32_bits(enq_dma));\n\text_addr |= GPD_EXT_NGP(mtu, upper_32_bits(enq_dma));\n\tgpd->dw3_info = cpu_to_le32(ext_addr);\n\t \n\tmb();\n\tgpd->dw0_info |= cpu_to_le32(GPD_FLAGS_IOC | GPD_FLAGS_HWO);\n\n\tmreq->gpd = gpd;\n\ttrace_mtu3_prepare_gpd(mep, gpd);\n\n\treturn 0;\n}\n\nvoid mtu3_insert_gpd(struct mtu3_ep *mep, struct mtu3_request *mreq)\n{\n\n\tif (mep->is_in)\n\t\tmtu3_prepare_tx_gpd(mep, mreq);\n\telse\n\t\tmtu3_prepare_rx_gpd(mep, mreq);\n}\n\nint mtu3_qmu_start(struct mtu3_ep *mep)\n{\n\tstruct mtu3 *mtu = mep->mtu;\n\tvoid __iomem *mbase = mtu->mac_base;\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\tu8 epnum = mep->epnum;\n\n\tif (mep->is_in) {\n\t\t \n\t\twrite_txq_start_addr(mbase, epnum, ring->dma);\n\t\tmtu3_setbits(mbase, MU3D_EP_TXCR0(epnum), TX_DMAREQEN);\n\t\t \n\t\tmtu3_setbits(mbase, U3D_QCR1, QMU_TX_ZLP(epnum));\n\t\tmtu3_writel(mbase, U3D_TQERRIESR0,\n\t\t\t\tQMU_TX_LEN_ERR(epnum) | QMU_TX_CS_ERR(epnum));\n\n\t\tif (mtu3_readl(mbase, USB_QMU_TQCSR(epnum)) & QMU_Q_ACTIVE) {\n\t\t\tdev_warn(mtu->dev, \"Tx %d Active Now!\\n\", epnum);\n\t\t\treturn 0;\n\t\t}\n\t\tmtu3_writel(mbase, USB_QMU_TQCSR(epnum), QMU_Q_START);\n\n\t} else {\n\t\twrite_rxq_start_addr(mbase, epnum, ring->dma);\n\t\tmtu3_setbits(mbase, MU3D_EP_RXCR0(epnum), RX_DMAREQEN);\n\t\t \n\t\tmtu3_clrbits(mbase, U3D_QCR3, QMU_RX_ZLP(epnum));\n\t\t \n\t\tmtu3_setbits(mbase, U3D_QCR3, QMU_RX_COZ(epnum));\n\t\tmtu3_writel(mbase, U3D_RQERRIESR0,\n\t\t\t\tQMU_RX_LEN_ERR(epnum) | QMU_RX_CS_ERR(epnum));\n\t\tmtu3_writel(mbase, U3D_RQERRIESR1, QMU_RX_ZLP_ERR(epnum));\n\n\t\tif (mtu3_readl(mbase, USB_QMU_RQCSR(epnum)) & QMU_Q_ACTIVE) {\n\t\t\tdev_warn(mtu->dev, \"Rx %d Active Now!\\n\", epnum);\n\t\t\treturn 0;\n\t\t}\n\t\tmtu3_writel(mbase, USB_QMU_RQCSR(epnum), QMU_Q_START);\n\t}\n\n\treturn 0;\n}\n\n \nvoid mtu3_qmu_stop(struct mtu3_ep *mep)\n{\n\tstruct mtu3 *mtu = mep->mtu;\n\tvoid __iomem *mbase = mtu->mac_base;\n\tint epnum = mep->epnum;\n\tu32 value = 0;\n\tu32 qcsr;\n\tint ret;\n\n\tqcsr = mep->is_in ? USB_QMU_TQCSR(epnum) : USB_QMU_RQCSR(epnum);\n\n\tif (!(mtu3_readl(mbase, qcsr) & QMU_Q_ACTIVE)) {\n\t\tdev_dbg(mtu->dev, \"%s's qmu is inactive now!\\n\", mep->name);\n\t\treturn;\n\t}\n\tmtu3_writel(mbase, qcsr, QMU_Q_STOP);\n\n\tif (mep->is_in)\n\t\tmtu3_setbits(mbase, MU3D_EP_TXCR0(epnum), TX_FLUSHFIFO);\n\n\tret = readl_poll_timeout_atomic(mbase + qcsr, value,\n\t\t\t!(value & QMU_Q_ACTIVE), 1, 1000);\n\tif (ret) {\n\t\tdev_err(mtu->dev, \"stop %s's qmu failed\\n\", mep->name);\n\t\treturn;\n\t}\n\n\t \n\tif (mep->is_in)\n\t\tmtu3_setbits(mbase, MU3D_EP_TXCR0(epnum), TX_FLUSHFIFO);\n\n\tdev_dbg(mtu->dev, \"%s's qmu stop now!\\n\", mep->name);\n}\n\nvoid mtu3_qmu_flush(struct mtu3_ep *mep)\n{\n\n\tdev_dbg(mep->mtu->dev, \"%s flush QMU %s\\n\", __func__,\n\t\t((mep->is_in) ? \"TX\" : \"RX\"));\n\n\t \n\tmtu3_qmu_stop(mep);\n\treset_gpd_list(mep);\n}\n\n \nstatic void qmu_tx_zlp_error_handler(struct mtu3 *mtu, u8 epnum)\n{\n\tstruct mtu3_ep *mep = mtu->in_eps + epnum;\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\tvoid __iomem *mbase = mtu->mac_base;\n\tstruct qmu_gpd *gpd_current = NULL;\n\tstruct mtu3_request *mreq;\n\tdma_addr_t cur_gpd_dma;\n\tu32 txcsr = 0;\n\tint ret;\n\n\tmreq = next_request(mep);\n\tif (mreq && mreq->request.length != 0)\n\t\treturn;\n\n\tcur_gpd_dma = read_txq_cur_addr(mbase, epnum);\n\tgpd_current = gpd_dma_to_virt(ring, cur_gpd_dma);\n\n\tif (GPD_DATA_LEN(mtu, le32_to_cpu(gpd_current->dw3_info)) != 0) {\n\t\tdev_err(mtu->dev, \"TX EP%d buffer length error(!=0)\\n\", epnum);\n\t\treturn;\n\t}\n\n\tdev_dbg(mtu->dev, \"%s send ZLP for req=%p\\n\", __func__, mreq);\n\ttrace_mtu3_zlp_exp_gpd(mep, gpd_current);\n\n\tmtu3_clrbits(mbase, MU3D_EP_TXCR0(mep->epnum), TX_DMAREQEN);\n\n\tret = readl_poll_timeout_atomic(mbase + MU3D_EP_TXCR0(mep->epnum),\n\t\t\ttxcsr, !(txcsr & TX_FIFOFULL), 1, 1000);\n\tif (ret) {\n\t\tdev_err(mtu->dev, \"%s wait for fifo empty fail\\n\", __func__);\n\t\treturn;\n\t}\n\tmtu3_setbits(mbase, MU3D_EP_TXCR0(mep->epnum), TX_TXPKTRDY);\n\t \n\tmb();\n\t \n\tgpd_current->dw0_info |= cpu_to_le32(GPD_FLAGS_BPS | GPD_FLAGS_HWO);\n\n\t \n\tmtu3_setbits(mbase, MU3D_EP_TXCR0(mep->epnum), TX_DMAREQEN);\n\tmtu3_qmu_resume(mep);\n}\n\n \nstatic void qmu_error_rx(struct mtu3 *mtu, u8 epnum)\n{\n\tstruct mtu3_ep *mep = mtu->out_eps + epnum;\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\tstruct qmu_gpd *gpd_current = NULL;\n\tstruct mtu3_request *mreq;\n\tdma_addr_t cur_gpd_dma;\n\n\tcur_gpd_dma = read_rxq_cur_addr(mtu->mac_base, epnum);\n\tgpd_current = gpd_dma_to_virt(ring, cur_gpd_dma);\n\n\tmreq = next_request(mep);\n\tif (!mreq || mreq->gpd != gpd_current) {\n\t\tdev_err(mtu->dev, \"no correct RX req is found\\n\");\n\t\treturn;\n\t}\n\n\tmreq->request.status = -EAGAIN;\n\n\t \n\tgpd_current->dw0_info |= cpu_to_le32(GPD_FLAGS_BPS | GPD_FLAGS_HWO);\n\tmtu3_qmu_resume(mep);\n\n\tdev_dbg(mtu->dev, \"%s EP%d, current=%p, req=%p\\n\",\n\t\t__func__, epnum, gpd_current, mreq);\n}\n\n \nstatic void qmu_done_tx(struct mtu3 *mtu, u8 epnum)\n{\n\tstruct mtu3_ep *mep = mtu->in_eps + epnum;\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\tvoid __iomem *mbase = mtu->mac_base;\n\tstruct qmu_gpd *gpd = ring->dequeue;\n\tstruct qmu_gpd *gpd_current = NULL;\n\tstruct usb_request *request = NULL;\n\tstruct mtu3_request *mreq;\n\tdma_addr_t cur_gpd_dma;\n\n\t \n\tcur_gpd_dma = read_txq_cur_addr(mbase, epnum);\n\tgpd_current = gpd_dma_to_virt(ring, cur_gpd_dma);\n\n\tdev_dbg(mtu->dev, \"%s EP%d, last=%p, current=%p, enq=%p\\n\",\n\t\t__func__, epnum, gpd, gpd_current, ring->enqueue);\n\n\twhile (gpd && gpd != gpd_current && !GET_GPD_HWO(gpd)) {\n\n\t\tmreq = next_request(mep);\n\n\t\tif (mreq == NULL || mreq->gpd != gpd) {\n\t\t\tdev_err(mtu->dev, \"no correct TX req is found\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\trequest = &mreq->request;\n\t\trequest->actual = GPD_DATA_LEN(mtu, le32_to_cpu(gpd->dw3_info));\n\t\ttrace_mtu3_complete_gpd(mep, gpd);\n\t\tmtu3_req_complete(mep, request, 0);\n\n\t\tgpd = advance_deq_gpd(ring);\n\t}\n\n\tdev_dbg(mtu->dev, \"%s EP%d, deq=%p, enq=%p, complete\\n\",\n\t\t__func__, epnum, ring->dequeue, ring->enqueue);\n\n}\n\nstatic void qmu_done_rx(struct mtu3 *mtu, u8 epnum)\n{\n\tstruct mtu3_ep *mep = mtu->out_eps + epnum;\n\tstruct mtu3_gpd_ring *ring = &mep->gpd_ring;\n\tvoid __iomem *mbase = mtu->mac_base;\n\tstruct qmu_gpd *gpd = ring->dequeue;\n\tstruct qmu_gpd *gpd_current = NULL;\n\tstruct usb_request *req = NULL;\n\tstruct mtu3_request *mreq;\n\tdma_addr_t cur_gpd_dma;\n\n\tcur_gpd_dma = read_rxq_cur_addr(mbase, epnum);\n\tgpd_current = gpd_dma_to_virt(ring, cur_gpd_dma);\n\n\tdev_dbg(mtu->dev, \"%s EP%d, last=%p, current=%p, enq=%p\\n\",\n\t\t__func__, epnum, gpd, gpd_current, ring->enqueue);\n\n\twhile (gpd && gpd != gpd_current && !GET_GPD_HWO(gpd)) {\n\n\t\tmreq = next_request(mep);\n\n\t\tif (mreq == NULL || mreq->gpd != gpd) {\n\t\t\tdev_err(mtu->dev, \"no correct RX req is found\\n\");\n\t\t\tbreak;\n\t\t}\n\t\treq = &mreq->request;\n\n\t\treq->actual = GPD_DATA_LEN(mtu, le32_to_cpu(gpd->dw3_info));\n\t\ttrace_mtu3_complete_gpd(mep, gpd);\n\t\tmtu3_req_complete(mep, req, 0);\n\n\t\tgpd = advance_deq_gpd(ring);\n\t}\n\n\tdev_dbg(mtu->dev, \"%s EP%d, deq=%p, enq=%p, complete\\n\",\n\t\t__func__, epnum, ring->dequeue, ring->enqueue);\n}\n\nstatic void qmu_done_isr(struct mtu3 *mtu, u32 done_status)\n{\n\tint i;\n\n\tfor (i = 1; i < mtu->num_eps; i++) {\n\t\tif (done_status & QMU_RX_DONE_INT(i))\n\t\t\tqmu_done_rx(mtu, i);\n\t\tif (done_status & QMU_TX_DONE_INT(i))\n\t\t\tqmu_done_tx(mtu, i);\n\t}\n}\n\nstatic void qmu_exception_isr(struct mtu3 *mtu, u32 qmu_status)\n{\n\tvoid __iomem *mbase = mtu->mac_base;\n\tu32 errval;\n\tint i;\n\n\tif ((qmu_status & RXQ_CSERR_INT) || (qmu_status & RXQ_LENERR_INT)) {\n\t\terrval = mtu3_readl(mbase, U3D_RQERRIR0);\n\t\tmtu3_writel(mbase, U3D_RQERRIR0, errval);\n\n\t\tfor (i = 1; i < mtu->num_eps; i++) {\n\t\t\tif (errval & QMU_RX_CS_ERR(i))\n\t\t\t\tdev_err(mtu->dev, \"Rx %d CS error!\\n\", i);\n\n\t\t\tif (errval & QMU_RX_LEN_ERR(i))\n\t\t\t\tdev_err(mtu->dev, \"RX %d Length error\\n\", i);\n\n\t\t\tif (errval & (QMU_RX_CS_ERR(i) | QMU_RX_LEN_ERR(i)))\n\t\t\t\tqmu_error_rx(mtu, i);\n\t\t}\n\t}\n\n\tif (qmu_status & RXQ_ZLPERR_INT) {\n\t\terrval = mtu3_readl(mbase, U3D_RQERRIR1);\n\t\tfor (i = 1; i < mtu->num_eps; i++) {\n\t\t\tif (errval & QMU_RX_ZLP_ERR(i))\n\t\t\t\tdev_dbg(mtu->dev, \"RX EP%d Recv ZLP\\n\", i);\n\t\t}\n\t\tmtu3_writel(mbase, U3D_RQERRIR1, errval);\n\t}\n\n\tif ((qmu_status & TXQ_CSERR_INT) || (qmu_status & TXQ_LENERR_INT)) {\n\t\terrval = mtu3_readl(mbase, U3D_TQERRIR0);\n\t\tfor (i = 1; i < mtu->num_eps; i++) {\n\t\t\tif (errval & QMU_TX_CS_ERR(i))\n\t\t\t\tdev_err(mtu->dev, \"Tx %d checksum error!\\n\", i);\n\n\t\t\tif (errval & QMU_TX_LEN_ERR(i))\n\t\t\t\tqmu_tx_zlp_error_handler(mtu, i);\n\t\t}\n\t\tmtu3_writel(mbase, U3D_TQERRIR0, errval);\n\t}\n}\n\nirqreturn_t mtu3_qmu_isr(struct mtu3 *mtu)\n{\n\tvoid __iomem *mbase = mtu->mac_base;\n\tu32 qmu_status;\n\tu32 qmu_done_status;\n\n\t \n\tqmu_status = mtu3_readl(mbase, U3D_QISAR1);\n\tqmu_status &= mtu3_readl(mbase, U3D_QIER1);\n\n\tqmu_done_status = mtu3_readl(mbase, U3D_QISAR0);\n\tqmu_done_status &= mtu3_readl(mbase, U3D_QIER0);\n\tmtu3_writel(mbase, U3D_QISAR0, qmu_done_status);  \n\tdev_dbg(mtu->dev, \"=== QMUdone[tx=%x, rx=%x] QMUexp[%x] ===\\n\",\n\t\t(qmu_done_status & 0xFFFF), qmu_done_status >> 16,\n\t\tqmu_status);\n\ttrace_mtu3_qmu_isr(qmu_done_status, qmu_status);\n\n\tif (qmu_done_status)\n\t\tqmu_done_isr(mtu, qmu_done_status);\n\n\tif (qmu_status)\n\t\tqmu_exception_isr(mtu, qmu_status);\n\n\treturn IRQ_HANDLED;\n}\n\nint mtu3_qmu_init(struct mtu3 *mtu)\n{\n\n\tcompiletime_assert(QMU_GPD_SIZE == 16, \"QMU_GPD size SHOULD be 16B\");\n\n\tmtu->qmu_gpd_pool = dma_pool_create(\"QMU_GPD\", mtu->dev,\n\t\t\tQMU_GPD_RING_SIZE, QMU_GPD_SIZE, 0);\n\n\tif (!mtu->qmu_gpd_pool)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nvoid mtu3_qmu_exit(struct mtu3 *mtu)\n{\n\tdma_pool_destroy(mtu->qmu_gpd_pool);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}