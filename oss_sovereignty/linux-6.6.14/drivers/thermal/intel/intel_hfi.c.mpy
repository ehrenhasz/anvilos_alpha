{
  "module_name": "intel_hfi.c",
  "hash_id": "2186863a55ee1f3cbbf938e36f6e36f91269d16c57aa5fbdd0305b9125adfd87",
  "original_prompt": "Ingested from linux-6.6.14/drivers/thermal/intel/intel_hfi.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)  \"intel-hfi: \" fmt\n\n#include <linux/bitops.h>\n#include <linux/cpufeature.h>\n#include <linux/cpumask.h>\n#include <linux/gfp.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/math.h>\n#include <linux/mutex.h>\n#include <linux/percpu-defs.h>\n#include <linux/printk.h>\n#include <linux/processor.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/string.h>\n#include <linux/topology.h>\n#include <linux/workqueue.h>\n\n#include <asm/msr.h>\n\n#include \"intel_hfi.h\"\n#include \"thermal_interrupt.h\"\n\n#include \"../thermal_netlink.h\"\n\n \n#define HW_FEEDBACK_PTR_VALID_BIT\t\tBIT(0)\n#define HW_FEEDBACK_CONFIG_HFI_ENABLE_BIT\tBIT(0)\n\n \n\n#define CPUID_HFI_LEAF 6\n\nunion hfi_capabilities {\n\tstruct {\n\t\tu8\tperformance:1;\n\t\tu8\tenergy_efficiency:1;\n\t\tu8\t__reserved:6;\n\t} split;\n\tu8 bits;\n};\n\nunion cpuid6_edx {\n\tstruct {\n\t\tunion hfi_capabilities\tcapabilities;\n\t\tu32\t\t\ttable_pages:4;\n\t\tu32\t\t\t__reserved:4;\n\t\ts32\t\t\tindex:16;\n\t} split;\n\tu32 full;\n};\n\n \nstruct hfi_cpu_data {\n\tu8\tperf_cap;\n\tu8\tee_cap;\n} __packed;\n\n \nstruct hfi_hdr {\n\tu8\tperf_updated;\n\tu8\tee_updated;\n} __packed;\n\n \nstruct hfi_instance {\n\tunion {\n\t\tvoid\t\t\t*local_table;\n\t\tu64\t\t\t*timestamp;\n\t};\n\tvoid\t\t\t*hdr;\n\tvoid\t\t\t*data;\n\tcpumask_var_t\t\tcpus;\n\tvoid\t\t\t*hw_table;\n\tstruct delayed_work\tupdate_work;\n\traw_spinlock_t\t\ttable_lock;\n\traw_spinlock_t\t\tevent_lock;\n};\n\n \nstruct hfi_features {\n\tsize_t\t\tnr_table_pages;\n\tunsigned int\tcpu_stride;\n\tunsigned int\thdr_size;\n};\n\n \nstruct hfi_cpu_info {\n\ts16\t\t\tindex;\n\tstruct hfi_instance\t*hfi_instance;\n};\n\nstatic DEFINE_PER_CPU(struct hfi_cpu_info, hfi_cpu_info) = { .index = -1 };\n\nstatic int max_hfi_instances;\nstatic struct hfi_instance *hfi_instances;\n\nstatic struct hfi_features hfi_features;\nstatic DEFINE_MUTEX(hfi_instance_lock);\n\nstatic struct workqueue_struct *hfi_updates_wq;\n#define HFI_UPDATE_INTERVAL\t\tHZ\n#define HFI_MAX_THERM_NOTIFY_COUNT\t16\n\nstatic void get_hfi_caps(struct hfi_instance *hfi_instance,\n\t\t\t struct thermal_genl_cpu_caps *cpu_caps)\n{\n\tint cpu, i = 0;\n\n\traw_spin_lock_irq(&hfi_instance->table_lock);\n\tfor_each_cpu(cpu, hfi_instance->cpus) {\n\t\tstruct hfi_cpu_data *caps;\n\t\ts16 index;\n\n\t\tindex = per_cpu(hfi_cpu_info, cpu).index;\n\t\tcaps = hfi_instance->data + index * hfi_features.cpu_stride;\n\t\tcpu_caps[i].cpu = cpu;\n\n\t\t \n\t\tcpu_caps[i].performance = caps->perf_cap << 2;\n\t\tcpu_caps[i].efficiency = caps->ee_cap << 2;\n\n\t\t++i;\n\t}\n\traw_spin_unlock_irq(&hfi_instance->table_lock);\n}\n\n \nstatic void update_capabilities(struct hfi_instance *hfi_instance)\n{\n\tstruct thermal_genl_cpu_caps *cpu_caps;\n\tint i = 0, cpu_count;\n\n\t \n\tmutex_lock(&hfi_instance_lock);\n\n\tcpu_count = cpumask_weight(hfi_instance->cpus);\n\n\t \n\tif (!cpu_count)\n\t\tgoto out;\n\n\tcpu_caps = kcalloc(cpu_count, sizeof(*cpu_caps), GFP_KERNEL);\n\tif (!cpu_caps)\n\t\tgoto out;\n\n\tget_hfi_caps(hfi_instance, cpu_caps);\n\n\tif (cpu_count < HFI_MAX_THERM_NOTIFY_COUNT)\n\t\tgoto last_cmd;\n\n\t \n\tfor (i = 0;\n\t     (i + HFI_MAX_THERM_NOTIFY_COUNT) <= cpu_count;\n\t     i += HFI_MAX_THERM_NOTIFY_COUNT)\n\t\tthermal_genl_cpu_capability_event(HFI_MAX_THERM_NOTIFY_COUNT,\n\t\t\t\t\t\t  &cpu_caps[i]);\n\n\tcpu_count = cpu_count - i;\n\nlast_cmd:\n\t \n\tif (cpu_count)\n\t\tthermal_genl_cpu_capability_event(cpu_count, &cpu_caps[i]);\n\n\tkfree(cpu_caps);\nout:\n\tmutex_unlock(&hfi_instance_lock);\n}\n\nstatic void hfi_update_work_fn(struct work_struct *work)\n{\n\tstruct hfi_instance *hfi_instance;\n\n\thfi_instance = container_of(to_delayed_work(work), struct hfi_instance,\n\t\t\t\t    update_work);\n\n\tupdate_capabilities(hfi_instance);\n}\n\nvoid intel_hfi_process_event(__u64 pkg_therm_status_msr_val)\n{\n\tstruct hfi_instance *hfi_instance;\n\tint cpu = smp_processor_id();\n\tstruct hfi_cpu_info *info;\n\tu64 new_timestamp, msr, hfi;\n\n\tif (!pkg_therm_status_msr_val)\n\t\treturn;\n\n\tinfo = &per_cpu(hfi_cpu_info, cpu);\n\tif (!info)\n\t\treturn;\n\n\t \n\thfi_instance = info->hfi_instance;\n\tif (unlikely(!hfi_instance)) {\n\t\tpr_debug(\"Received event on CPU %d but instance was null\", cpu);\n\t\treturn;\n\t}\n\n\t \n\tif (!raw_spin_trylock(&hfi_instance->event_lock))\n\t\treturn;\n\n\trdmsrl(MSR_IA32_PACKAGE_THERM_STATUS, msr);\n\thfi = msr & PACKAGE_THERM_STATUS_HFI_UPDATED;\n\tif (!hfi) {\n\t\traw_spin_unlock(&hfi_instance->event_lock);\n\t\treturn;\n\t}\n\n\t \n\tnew_timestamp = *(u64 *)hfi_instance->hw_table;\n\tif (*hfi_instance->timestamp == new_timestamp) {\n\t\tthermal_clear_package_intr_status(PACKAGE_LEVEL, PACKAGE_THERM_STATUS_HFI_UPDATED);\n\t\traw_spin_unlock(&hfi_instance->event_lock);\n\t\treturn;\n\t}\n\n\traw_spin_lock(&hfi_instance->table_lock);\n\n\t \n\tmemcpy(hfi_instance->local_table, hfi_instance->hw_table,\n\t       hfi_features.nr_table_pages << PAGE_SHIFT);\n\n\t \n\tthermal_clear_package_intr_status(PACKAGE_LEVEL, PACKAGE_THERM_STATUS_HFI_UPDATED);\n\n\traw_spin_unlock(&hfi_instance->table_lock);\n\traw_spin_unlock(&hfi_instance->event_lock);\n\n\tqueue_delayed_work(hfi_updates_wq, &hfi_instance->update_work,\n\t\t\t   HFI_UPDATE_INTERVAL);\n}\n\nstatic void init_hfi_cpu_index(struct hfi_cpu_info *info)\n{\n\tunion cpuid6_edx edx;\n\n\t \n\tif (info->index > -1)\n\t\treturn;\n\n\tedx.full = cpuid_edx(CPUID_HFI_LEAF);\n\tinfo->index = edx.split.index;\n}\n\n \nstatic void init_hfi_instance(struct hfi_instance *hfi_instance)\n{\n\t \n\thfi_instance->hdr = hfi_instance->local_table +\n\t\t\t    sizeof(*hfi_instance->timestamp);\n\n\t \n\thfi_instance->data = hfi_instance->hdr + hfi_features.hdr_size;\n}\n\n \nvoid intel_hfi_online(unsigned int cpu)\n{\n\tstruct hfi_instance *hfi_instance;\n\tstruct hfi_cpu_info *info;\n\tphys_addr_t hw_table_pa;\n\tu64 msr_val;\n\tu16 die_id;\n\n\t \n\tif (!hfi_instances)\n\t\treturn;\n\n\t \n\tinfo = &per_cpu(hfi_cpu_info, cpu);\n\tdie_id = topology_logical_die_id(cpu);\n\thfi_instance = info->hfi_instance;\n\tif (!hfi_instance) {\n\t\tif (die_id >= max_hfi_instances)\n\t\t\treturn;\n\n\t\thfi_instance = &hfi_instances[die_id];\n\t\tinfo->hfi_instance = hfi_instance;\n\t}\n\n\tinit_hfi_cpu_index(info);\n\n\t \n\tmutex_lock(&hfi_instance_lock);\n\tif (hfi_instance->hdr) {\n\t\tcpumask_set_cpu(cpu, hfi_instance->cpus);\n\t\tgoto unlock;\n\t}\n\n\t \n\thfi_instance->hw_table = alloc_pages_exact(hfi_features.nr_table_pages,\n\t\t\t\t\t\t   GFP_KERNEL | __GFP_ZERO);\n\tif (!hfi_instance->hw_table)\n\t\tgoto unlock;\n\n\thw_table_pa = virt_to_phys(hfi_instance->hw_table);\n\n\t \n\thfi_instance->local_table = kzalloc(hfi_features.nr_table_pages << PAGE_SHIFT,\n\t\t\t\t\t    GFP_KERNEL);\n\tif (!hfi_instance->local_table)\n\t\tgoto free_hw_table;\n\n\t \n\tmsr_val = hw_table_pa | HW_FEEDBACK_PTR_VALID_BIT;\n\twrmsrl(MSR_IA32_HW_FEEDBACK_PTR, msr_val);\n\n\tinit_hfi_instance(hfi_instance);\n\n\tINIT_DELAYED_WORK(&hfi_instance->update_work, hfi_update_work_fn);\n\traw_spin_lock_init(&hfi_instance->table_lock);\n\traw_spin_lock_init(&hfi_instance->event_lock);\n\n\tcpumask_set_cpu(cpu, hfi_instance->cpus);\n\n\t \n\trdmsrl(MSR_IA32_HW_FEEDBACK_CONFIG, msr_val);\n\tmsr_val |= HW_FEEDBACK_CONFIG_HFI_ENABLE_BIT;\n\twrmsrl(MSR_IA32_HW_FEEDBACK_CONFIG, msr_val);\n\nunlock:\n\tmutex_unlock(&hfi_instance_lock);\n\treturn;\n\nfree_hw_table:\n\tfree_pages_exact(hfi_instance->hw_table, hfi_features.nr_table_pages);\n\tgoto unlock;\n}\n\n \nvoid intel_hfi_offline(unsigned int cpu)\n{\n\tstruct hfi_cpu_info *info = &per_cpu(hfi_cpu_info, cpu);\n\tstruct hfi_instance *hfi_instance;\n\n\t \n\thfi_instance = info->hfi_instance;\n\tif (!hfi_instance)\n\t\treturn;\n\n\tif (!hfi_instance->hdr)\n\t\treturn;\n\n\tmutex_lock(&hfi_instance_lock);\n\tcpumask_clear_cpu(cpu, hfi_instance->cpus);\n\tmutex_unlock(&hfi_instance_lock);\n}\n\nstatic __init int hfi_parse_features(void)\n{\n\tunsigned int nr_capabilities;\n\tunion cpuid6_edx edx;\n\n\tif (!boot_cpu_has(X86_FEATURE_HFI))\n\t\treturn -ENODEV;\n\n\t \n\tedx.full = cpuid_edx(CPUID_HFI_LEAF);\n\n\tif (!edx.split.capabilities.split.performance) {\n\t\tpr_debug(\"Performance reporting not supported! Not using HFI\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tedx.split.capabilities.split.__reserved = 0;\n\tnr_capabilities = hweight8(edx.split.capabilities.bits);\n\n\t \n\thfi_features.nr_table_pages = edx.split.table_pages + 1;\n\n\t \n\thfi_features.hdr_size = DIV_ROUND_UP(nr_capabilities, 8) * 8;\n\n\t \n\thfi_features.cpu_stride = DIV_ROUND_UP(nr_capabilities, 8) * 8;\n\n\treturn 0;\n}\n\nvoid __init intel_hfi_init(void)\n{\n\tstruct hfi_instance *hfi_instance;\n\tint i, j;\n\n\tif (hfi_parse_features())\n\t\treturn;\n\n\t \n\tmax_hfi_instances = topology_max_packages() *\n\t\t\t    topology_max_die_per_package();\n\n\t \n\thfi_instances = kcalloc(max_hfi_instances, sizeof(*hfi_instances),\n\t\t\t\tGFP_KERNEL);\n\tif (!hfi_instances)\n\t\treturn;\n\n\tfor (i = 0; i < max_hfi_instances; i++) {\n\t\thfi_instance = &hfi_instances[i];\n\t\tif (!zalloc_cpumask_var(&hfi_instance->cpus, GFP_KERNEL))\n\t\t\tgoto err_nomem;\n\t}\n\n\thfi_updates_wq = create_singlethread_workqueue(\"hfi-updates\");\n\tif (!hfi_updates_wq)\n\t\tgoto err_nomem;\n\n\treturn;\n\nerr_nomem:\n\tfor (j = 0; j < i; ++j) {\n\t\thfi_instance = &hfi_instances[j];\n\t\tfree_cpumask_var(hfi_instance->cpus);\n\t}\n\n\tkfree(hfi_instances);\n\thfi_instances = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}