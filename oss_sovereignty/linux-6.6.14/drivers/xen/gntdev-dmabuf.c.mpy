{
  "module_name": "gntdev-dmabuf.c",
  "hash_id": "3bf3a95048f53715c691109126213efa56563332a658624e12b71357011bff7d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/xen/gntdev-dmabuf.c",
  "human_readable_source": "\n\n \n\n#include <linux/kernel.h>\n#include <linux/errno.h>\n#include <linux/dma-buf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/uaccess.h>\n#include <linux/module.h>\n\n#include <xen/xen.h>\n#include <xen/grant_table.h>\n\n#include \"gntdev-common.h\"\n#include \"gntdev-dmabuf.h\"\n\nMODULE_IMPORT_NS(DMA_BUF);\n\nstruct gntdev_dmabuf {\n\tstruct gntdev_dmabuf_priv *priv;\n\tstruct dma_buf *dmabuf;\n\tstruct list_head next;\n\tint fd;\n\n\tunion {\n\t\tstruct {\n\t\t\t \n\t\t\tstruct kref refcount;\n\n\t\t\tstruct gntdev_priv *priv;\n\t\t\tstruct gntdev_grant_map *map;\n\t\t} exp;\n\t\tstruct {\n\t\t\t \n\t\t\tgrant_ref_t *refs;\n\t\t\t \n\t\t\tstruct sg_table *sgt;\n\t\t\t \n\t\t\tstruct dma_buf_attachment *attach;\n\t\t} imp;\n\t} u;\n\n\t \n\tint nr_pages;\n\t \n\tstruct page **pages;\n};\n\nstruct gntdev_dmabuf_wait_obj {\n\tstruct list_head next;\n\tstruct gntdev_dmabuf *gntdev_dmabuf;\n\tstruct completion completion;\n};\n\nstruct gntdev_dmabuf_attachment {\n\tstruct sg_table *sgt;\n\tenum dma_data_direction dir;\n};\n\nstruct gntdev_dmabuf_priv {\n\t \n\tstruct list_head exp_list;\n\t \n\tstruct list_head exp_wait_list;\n\t \n\tstruct list_head imp_list;\n\t \n\tstruct mutex lock;\n\t \n\tstruct file *filp;\n};\n\n \n\n \n\nstatic void dmabuf_exp_release(struct kref *kref);\n\nstatic struct gntdev_dmabuf_wait_obj *\ndmabuf_exp_wait_obj_new(struct gntdev_dmabuf_priv *priv,\n\t\t\tstruct gntdev_dmabuf *gntdev_dmabuf)\n{\n\tstruct gntdev_dmabuf_wait_obj *obj;\n\n\tobj = kzalloc(sizeof(*obj), GFP_KERNEL);\n\tif (!obj)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tinit_completion(&obj->completion);\n\tobj->gntdev_dmabuf = gntdev_dmabuf;\n\n\tmutex_lock(&priv->lock);\n\tlist_add(&obj->next, &priv->exp_wait_list);\n\t \n\tkref_put(&gntdev_dmabuf->u.exp.refcount, dmabuf_exp_release);\n\tmutex_unlock(&priv->lock);\n\treturn obj;\n}\n\nstatic void dmabuf_exp_wait_obj_free(struct gntdev_dmabuf_priv *priv,\n\t\t\t\t     struct gntdev_dmabuf_wait_obj *obj)\n{\n\tmutex_lock(&priv->lock);\n\tlist_del(&obj->next);\n\tmutex_unlock(&priv->lock);\n\tkfree(obj);\n}\n\nstatic int dmabuf_exp_wait_obj_wait(struct gntdev_dmabuf_wait_obj *obj,\n\t\t\t\t    u32 wait_to_ms)\n{\n\tif (wait_for_completion_timeout(&obj->completion,\n\t\t\tmsecs_to_jiffies(wait_to_ms)) <= 0)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nstatic void dmabuf_exp_wait_obj_signal(struct gntdev_dmabuf_priv *priv,\n\t\t\t\t       struct gntdev_dmabuf *gntdev_dmabuf)\n{\n\tstruct gntdev_dmabuf_wait_obj *obj;\n\n\tlist_for_each_entry(obj, &priv->exp_wait_list, next)\n\t\tif (obj->gntdev_dmabuf == gntdev_dmabuf) {\n\t\t\tpr_debug(\"Found gntdev_dmabuf in the wait list, wake\\n\");\n\t\t\tcomplete_all(&obj->completion);\n\t\t\tbreak;\n\t\t}\n}\n\nstatic struct gntdev_dmabuf *\ndmabuf_exp_wait_obj_get_dmabuf(struct gntdev_dmabuf_priv *priv, int fd)\n{\n\tstruct gntdev_dmabuf *gntdev_dmabuf, *ret = ERR_PTR(-ENOENT);\n\n\tmutex_lock(&priv->lock);\n\tlist_for_each_entry(gntdev_dmabuf, &priv->exp_list, next)\n\t\tif (gntdev_dmabuf->fd == fd) {\n\t\t\tpr_debug(\"Found gntdev_dmabuf in the wait list\\n\");\n\t\t\tkref_get(&gntdev_dmabuf->u.exp.refcount);\n\t\t\tret = gntdev_dmabuf;\n\t\t\tbreak;\n\t\t}\n\tmutex_unlock(&priv->lock);\n\treturn ret;\n}\n\nstatic int dmabuf_exp_wait_released(struct gntdev_dmabuf_priv *priv, int fd,\n\t\t\t\t    int wait_to_ms)\n{\n\tstruct gntdev_dmabuf *gntdev_dmabuf;\n\tstruct gntdev_dmabuf_wait_obj *obj;\n\tint ret;\n\n\tpr_debug(\"Will wait for dma-buf with fd %d\\n\", fd);\n\t \n\tgntdev_dmabuf = dmabuf_exp_wait_obj_get_dmabuf(priv, fd);\n\tif (IS_ERR(gntdev_dmabuf))\n\t\treturn PTR_ERR(gntdev_dmabuf);\n\n\t \n\tobj = dmabuf_exp_wait_obj_new(priv, gntdev_dmabuf);\n\tif (IS_ERR(obj))\n\t\treturn PTR_ERR(obj);\n\n\tret = dmabuf_exp_wait_obj_wait(obj, wait_to_ms);\n\tdmabuf_exp_wait_obj_free(priv, obj);\n\treturn ret;\n}\n\n \n\nstatic struct sg_table *\ndmabuf_pages_to_sgt(struct page **pages, unsigned int nr_pages)\n{\n\tstruct sg_table *sgt;\n\tint ret;\n\n\tsgt = kmalloc(sizeof(*sgt), GFP_KERNEL);\n\tif (!sgt) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tret = sg_alloc_table_from_pages(sgt, pages, nr_pages, 0,\n\t\t\t\t\tnr_pages << PAGE_SHIFT,\n\t\t\t\t\tGFP_KERNEL);\n\tif (ret)\n\t\tgoto out;\n\n\treturn sgt;\n\nout:\n\tkfree(sgt);\n\treturn ERR_PTR(ret);\n}\n\nstatic int dmabuf_exp_ops_attach(struct dma_buf *dma_buf,\n\t\t\t\t struct dma_buf_attachment *attach)\n{\n\tstruct gntdev_dmabuf_attachment *gntdev_dmabuf_attach;\n\n\tgntdev_dmabuf_attach = kzalloc(sizeof(*gntdev_dmabuf_attach),\n\t\t\t\t       GFP_KERNEL);\n\tif (!gntdev_dmabuf_attach)\n\t\treturn -ENOMEM;\n\n\tgntdev_dmabuf_attach->dir = DMA_NONE;\n\tattach->priv = gntdev_dmabuf_attach;\n\treturn 0;\n}\n\nstatic void dmabuf_exp_ops_detach(struct dma_buf *dma_buf,\n\t\t\t\t  struct dma_buf_attachment *attach)\n{\n\tstruct gntdev_dmabuf_attachment *gntdev_dmabuf_attach = attach->priv;\n\n\tif (gntdev_dmabuf_attach) {\n\t\tstruct sg_table *sgt = gntdev_dmabuf_attach->sgt;\n\n\t\tif (sgt) {\n\t\t\tif (gntdev_dmabuf_attach->dir != DMA_NONE)\n\t\t\t\tdma_unmap_sgtable(attach->dev, sgt,\n\t\t\t\t\t\t  gntdev_dmabuf_attach->dir,\n\t\t\t\t\t\t  DMA_ATTR_SKIP_CPU_SYNC);\n\t\t\tsg_free_table(sgt);\n\t\t}\n\n\t\tkfree(sgt);\n\t\tkfree(gntdev_dmabuf_attach);\n\t\tattach->priv = NULL;\n\t}\n}\n\nstatic struct sg_table *\ndmabuf_exp_ops_map_dma_buf(struct dma_buf_attachment *attach,\n\t\t\t   enum dma_data_direction dir)\n{\n\tstruct gntdev_dmabuf_attachment *gntdev_dmabuf_attach = attach->priv;\n\tstruct gntdev_dmabuf *gntdev_dmabuf = attach->dmabuf->priv;\n\tstruct sg_table *sgt;\n\n\tpr_debug(\"Mapping %d pages for dev %p\\n\", gntdev_dmabuf->nr_pages,\n\t\t attach->dev);\n\n\tif (dir == DMA_NONE || !gntdev_dmabuf_attach)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t \n\tif (gntdev_dmabuf_attach->dir == dir)\n\t\treturn gntdev_dmabuf_attach->sgt;\n\n\t \n\tif (gntdev_dmabuf_attach->dir != DMA_NONE)\n\t\treturn ERR_PTR(-EBUSY);\n\n\tsgt = dmabuf_pages_to_sgt(gntdev_dmabuf->pages,\n\t\t\t\t  gntdev_dmabuf->nr_pages);\n\tif (!IS_ERR(sgt)) {\n\t\tif (dma_map_sgtable(attach->dev, sgt, dir,\n\t\t\t\t    DMA_ATTR_SKIP_CPU_SYNC)) {\n\t\t\tsg_free_table(sgt);\n\t\t\tkfree(sgt);\n\t\t\tsgt = ERR_PTR(-ENOMEM);\n\t\t} else {\n\t\t\tgntdev_dmabuf_attach->sgt = sgt;\n\t\t\tgntdev_dmabuf_attach->dir = dir;\n\t\t}\n\t}\n\tif (IS_ERR(sgt))\n\t\tpr_debug(\"Failed to map sg table for dev %p\\n\", attach->dev);\n\treturn sgt;\n}\n\nstatic void dmabuf_exp_ops_unmap_dma_buf(struct dma_buf_attachment *attach,\n\t\t\t\t\t struct sg_table *sgt,\n\t\t\t\t\t enum dma_data_direction dir)\n{\n\t \n}\n\nstatic void dmabuf_exp_release(struct kref *kref)\n{\n\tstruct gntdev_dmabuf *gntdev_dmabuf =\n\t\tcontainer_of(kref, struct gntdev_dmabuf, u.exp.refcount);\n\n\tdmabuf_exp_wait_obj_signal(gntdev_dmabuf->priv, gntdev_dmabuf);\n\tlist_del(&gntdev_dmabuf->next);\n\tfput(gntdev_dmabuf->priv->filp);\n\tkfree(gntdev_dmabuf);\n}\n\nstatic void dmabuf_exp_remove_map(struct gntdev_priv *priv,\n\t\t\t\t  struct gntdev_grant_map *map)\n{\n\tmutex_lock(&priv->lock);\n\tlist_del(&map->next);\n\tgntdev_put_map(NULL  , map);\n\tmutex_unlock(&priv->lock);\n}\n\nstatic void dmabuf_exp_ops_release(struct dma_buf *dma_buf)\n{\n\tstruct gntdev_dmabuf *gntdev_dmabuf = dma_buf->priv;\n\tstruct gntdev_dmabuf_priv *priv = gntdev_dmabuf->priv;\n\n\tdmabuf_exp_remove_map(gntdev_dmabuf->u.exp.priv,\n\t\t\t      gntdev_dmabuf->u.exp.map);\n\tmutex_lock(&priv->lock);\n\tkref_put(&gntdev_dmabuf->u.exp.refcount, dmabuf_exp_release);\n\tmutex_unlock(&priv->lock);\n}\n\nstatic const struct dma_buf_ops dmabuf_exp_ops =  {\n\t.attach = dmabuf_exp_ops_attach,\n\t.detach = dmabuf_exp_ops_detach,\n\t.map_dma_buf = dmabuf_exp_ops_map_dma_buf,\n\t.unmap_dma_buf = dmabuf_exp_ops_unmap_dma_buf,\n\t.release = dmabuf_exp_ops_release,\n};\n\nstruct gntdev_dmabuf_export_args {\n\tstruct gntdev_priv *priv;\n\tstruct gntdev_grant_map *map;\n\tstruct gntdev_dmabuf_priv *dmabuf_priv;\n\tstruct device *dev;\n\tint count;\n\tstruct page **pages;\n\tu32 fd;\n};\n\nstatic int dmabuf_exp_from_pages(struct gntdev_dmabuf_export_args *args)\n{\n\tDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\n\tstruct gntdev_dmabuf *gntdev_dmabuf;\n\tint ret;\n\n\tgntdev_dmabuf = kzalloc(sizeof(*gntdev_dmabuf), GFP_KERNEL);\n\tif (!gntdev_dmabuf)\n\t\treturn -ENOMEM;\n\n\tkref_init(&gntdev_dmabuf->u.exp.refcount);\n\n\tgntdev_dmabuf->priv = args->dmabuf_priv;\n\tgntdev_dmabuf->nr_pages = args->count;\n\tgntdev_dmabuf->pages = args->pages;\n\tgntdev_dmabuf->u.exp.priv = args->priv;\n\tgntdev_dmabuf->u.exp.map = args->map;\n\n\texp_info.exp_name = KBUILD_MODNAME;\n\tif (args->dev->driver && args->dev->driver->owner)\n\t\texp_info.owner = args->dev->driver->owner;\n\telse\n\t\texp_info.owner = THIS_MODULE;\n\texp_info.ops = &dmabuf_exp_ops;\n\texp_info.size = args->count << PAGE_SHIFT;\n\texp_info.flags = O_RDWR;\n\texp_info.priv = gntdev_dmabuf;\n\n\tgntdev_dmabuf->dmabuf = dma_buf_export(&exp_info);\n\tif (IS_ERR(gntdev_dmabuf->dmabuf)) {\n\t\tret = PTR_ERR(gntdev_dmabuf->dmabuf);\n\t\tgntdev_dmabuf->dmabuf = NULL;\n\t\tgoto fail;\n\t}\n\n\tret = dma_buf_fd(gntdev_dmabuf->dmabuf, O_CLOEXEC);\n\tif (ret < 0)\n\t\tgoto fail;\n\n\tgntdev_dmabuf->fd = ret;\n\targs->fd = ret;\n\n\tpr_debug(\"Exporting DMA buffer with fd %d\\n\", ret);\n\n\tmutex_lock(&args->dmabuf_priv->lock);\n\tlist_add(&gntdev_dmabuf->next, &args->dmabuf_priv->exp_list);\n\tmutex_unlock(&args->dmabuf_priv->lock);\n\tget_file(gntdev_dmabuf->priv->filp);\n\treturn 0;\n\nfail:\n\tif (gntdev_dmabuf->dmabuf)\n\t\tdma_buf_put(gntdev_dmabuf->dmabuf);\n\tkfree(gntdev_dmabuf);\n\treturn ret;\n}\n\nstatic struct gntdev_grant_map *\ndmabuf_exp_alloc_backing_storage(struct gntdev_priv *priv, int dmabuf_flags,\n\t\t\t\t int count)\n{\n\tstruct gntdev_grant_map *map;\n\n\tif (unlikely(gntdev_test_page_count(count)))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif ((dmabuf_flags & GNTDEV_DMA_FLAG_WC) &&\n\t    (dmabuf_flags & GNTDEV_DMA_FLAG_COHERENT)) {\n\t\tpr_debug(\"Wrong dma-buf flags: 0x%x\\n\", dmabuf_flags);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tmap = gntdev_alloc_map(priv, count, dmabuf_flags);\n\tif (!map)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\treturn map;\n}\n\nstatic int dmabuf_exp_from_refs(struct gntdev_priv *priv, int flags,\n\t\t\t\tint count, u32 domid, u32 *refs, u32 *fd)\n{\n\tstruct gntdev_grant_map *map;\n\tstruct gntdev_dmabuf_export_args args;\n\tint i, ret;\n\n\tmap = dmabuf_exp_alloc_backing_storage(priv, flags, count);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\n\tfor (i = 0; i < count; i++) {\n\t\tmap->grants[i].domid = domid;\n\t\tmap->grants[i].ref = refs[i];\n\t}\n\n\tmutex_lock(&priv->lock);\n\tgntdev_add_map(priv, map);\n\tmutex_unlock(&priv->lock);\n\n\tmap->flags |= GNTMAP_host_map;\n#if defined(CONFIG_X86)\n\tmap->flags |= GNTMAP_device_map;\n#endif\n\n\tret = gntdev_map_grant_pages(map);\n\tif (ret < 0)\n\t\tgoto out;\n\n\targs.priv = priv;\n\targs.map = map;\n\targs.dev = priv->dma_dev;\n\targs.dmabuf_priv = priv->dmabuf_priv;\n\targs.count = map->count;\n\targs.pages = map->pages;\n\targs.fd = -1;  \n\n\tret = dmabuf_exp_from_pages(&args);\n\tif (ret < 0)\n\t\tgoto out;\n\n\t*fd = args.fd;\n\treturn 0;\n\nout:\n\tdmabuf_exp_remove_map(priv, map);\n\treturn ret;\n}\n\n \n\nstatic int\ndmabuf_imp_grant_foreign_access(struct page **pages, u32 *refs,\n\t\t\t\tint count, int domid)\n{\n\tgrant_ref_t priv_gref_head;\n\tint i, ret;\n\n\tret = gnttab_alloc_grant_references(count, &priv_gref_head);\n\tif (ret < 0) {\n\t\tpr_debug(\"Cannot allocate grant references, ret %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tfor (i = 0; i < count; i++) {\n\t\tint cur_ref;\n\n\t\tcur_ref = gnttab_claim_grant_reference(&priv_gref_head);\n\t\tif (cur_ref < 0) {\n\t\t\tret = cur_ref;\n\t\t\tpr_debug(\"Cannot claim grant reference, ret %d\\n\", ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tgnttab_grant_foreign_access_ref(cur_ref, domid,\n\t\t\t\t\t\txen_page_to_gfn(pages[i]), 0);\n\t\trefs[i] = cur_ref;\n\t}\n\n\treturn 0;\n\nout:\n\tgnttab_free_grant_references(priv_gref_head);\n\treturn ret;\n}\n\nstatic void dmabuf_imp_end_foreign_access(u32 *refs, int count)\n{\n\tint i;\n\n\tfor (i = 0; i < count; i++)\n\t\tif (refs[i] != INVALID_GRANT_REF)\n\t\t\tgnttab_end_foreign_access(refs[i], NULL);\n}\n\nstatic void dmabuf_imp_free_storage(struct gntdev_dmabuf *gntdev_dmabuf)\n{\n\tkfree(gntdev_dmabuf->pages);\n\tkfree(gntdev_dmabuf->u.imp.refs);\n\tkfree(gntdev_dmabuf);\n}\n\nstatic struct gntdev_dmabuf *dmabuf_imp_alloc_storage(int count)\n{\n\tstruct gntdev_dmabuf *gntdev_dmabuf;\n\tint i;\n\n\tgntdev_dmabuf = kzalloc(sizeof(*gntdev_dmabuf), GFP_KERNEL);\n\tif (!gntdev_dmabuf)\n\t\tgoto fail_no_free;\n\n\tgntdev_dmabuf->u.imp.refs = kcalloc(count,\n\t\t\t\t\t    sizeof(gntdev_dmabuf->u.imp.refs[0]),\n\t\t\t\t\t    GFP_KERNEL);\n\tif (!gntdev_dmabuf->u.imp.refs)\n\t\tgoto fail;\n\n\tgntdev_dmabuf->pages = kcalloc(count,\n\t\t\t\t       sizeof(gntdev_dmabuf->pages[0]),\n\t\t\t\t       GFP_KERNEL);\n\tif (!gntdev_dmabuf->pages)\n\t\tgoto fail;\n\n\tgntdev_dmabuf->nr_pages = count;\n\n\tfor (i = 0; i < count; i++)\n\t\tgntdev_dmabuf->u.imp.refs[i] = INVALID_GRANT_REF;\n\n\treturn gntdev_dmabuf;\n\nfail:\n\tdmabuf_imp_free_storage(gntdev_dmabuf);\nfail_no_free:\n\treturn ERR_PTR(-ENOMEM);\n}\n\nstatic struct gntdev_dmabuf *\ndmabuf_imp_to_refs(struct gntdev_dmabuf_priv *priv, struct device *dev,\n\t\t   int fd, int count, int domid)\n{\n\tstruct gntdev_dmabuf *gntdev_dmabuf, *ret;\n\tstruct dma_buf *dma_buf;\n\tstruct dma_buf_attachment *attach;\n\tstruct sg_table *sgt;\n\tstruct sg_page_iter sg_iter;\n\tint i;\n\n\tdma_buf = dma_buf_get(fd);\n\tif (IS_ERR(dma_buf))\n\t\treturn ERR_CAST(dma_buf);\n\n\tgntdev_dmabuf = dmabuf_imp_alloc_storage(count);\n\tif (IS_ERR(gntdev_dmabuf)) {\n\t\tret = gntdev_dmabuf;\n\t\tgoto fail_put;\n\t}\n\n\tgntdev_dmabuf->priv = priv;\n\tgntdev_dmabuf->fd = fd;\n\n\tattach = dma_buf_attach(dma_buf, dev);\n\tif (IS_ERR(attach)) {\n\t\tret = ERR_CAST(attach);\n\t\tgoto fail_free_obj;\n\t}\n\n\tgntdev_dmabuf->u.imp.attach = attach;\n\n\tsgt = dma_buf_map_attachment_unlocked(attach, DMA_BIDIRECTIONAL);\n\tif (IS_ERR(sgt)) {\n\t\tret = ERR_CAST(sgt);\n\t\tgoto fail_detach;\n\t}\n\n\t \n\tif (sgt->sgl->offset) {\n\t\tret = ERR_PTR(-EINVAL);\n\t\tpr_debug(\"DMA buffer has %d bytes offset, user-space expects 0\\n\",\n\t\t\t sgt->sgl->offset);\n\t\tgoto fail_unmap;\n\t}\n\n\t \n\tif (attach->dmabuf->size != gntdev_dmabuf->nr_pages << PAGE_SHIFT) {\n\t\tret = ERR_PTR(-EINVAL);\n\t\tpr_debug(\"DMA buffer has %zu pages, user-space expects %d\\n\",\n\t\t\t attach->dmabuf->size, gntdev_dmabuf->nr_pages);\n\t\tgoto fail_unmap;\n\t}\n\n\tgntdev_dmabuf->u.imp.sgt = sgt;\n\n\t \n\ti = 0;\n\tfor_each_sgtable_page(sgt, &sg_iter, 0) {\n\t\tstruct page *page = sg_page_iter_page(&sg_iter);\n\t\t \n\t\tif (!pfn_valid(page_to_pfn(page))) {\n\t\t\tret = ERR_PTR(-EINVAL);\n\t\t\tgoto fail_unmap;\n\t\t}\n\n\t\tgntdev_dmabuf->pages[i++] = page;\n\t}\n\n\tret = ERR_PTR(dmabuf_imp_grant_foreign_access(gntdev_dmabuf->pages,\n\t\t\t\t\t\t      gntdev_dmabuf->u.imp.refs,\n\t\t\t\t\t\t      count, domid));\n\tif (IS_ERR(ret))\n\t\tgoto fail_end_access;\n\n\tpr_debug(\"Imported DMA buffer with fd %d\\n\", fd);\n\n\tmutex_lock(&priv->lock);\n\tlist_add(&gntdev_dmabuf->next, &priv->imp_list);\n\tmutex_unlock(&priv->lock);\n\n\treturn gntdev_dmabuf;\n\nfail_end_access:\n\tdmabuf_imp_end_foreign_access(gntdev_dmabuf->u.imp.refs, count);\nfail_unmap:\n\tdma_buf_unmap_attachment_unlocked(attach, sgt, DMA_BIDIRECTIONAL);\nfail_detach:\n\tdma_buf_detach(dma_buf, attach);\nfail_free_obj:\n\tdmabuf_imp_free_storage(gntdev_dmabuf);\nfail_put:\n\tdma_buf_put(dma_buf);\n\treturn ret;\n}\n\n \nstatic struct gntdev_dmabuf *\ndmabuf_imp_find_unlink(struct gntdev_dmabuf_priv *priv, int fd)\n{\n\tstruct gntdev_dmabuf *q, *gntdev_dmabuf, *ret = ERR_PTR(-ENOENT);\n\n\tmutex_lock(&priv->lock);\n\tlist_for_each_entry_safe(gntdev_dmabuf, q, &priv->imp_list, next) {\n\t\tif (gntdev_dmabuf->fd == fd) {\n\t\t\tpr_debug(\"Found gntdev_dmabuf in the import list\\n\");\n\t\t\tret = gntdev_dmabuf;\n\t\t\tlist_del(&gntdev_dmabuf->next);\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&priv->lock);\n\treturn ret;\n}\n\nstatic int dmabuf_imp_release(struct gntdev_dmabuf_priv *priv, u32 fd)\n{\n\tstruct gntdev_dmabuf *gntdev_dmabuf;\n\tstruct dma_buf_attachment *attach;\n\tstruct dma_buf *dma_buf;\n\n\tgntdev_dmabuf = dmabuf_imp_find_unlink(priv, fd);\n\tif (IS_ERR(gntdev_dmabuf))\n\t\treturn PTR_ERR(gntdev_dmabuf);\n\n\tpr_debug(\"Releasing DMA buffer with fd %d\\n\", fd);\n\n\tdmabuf_imp_end_foreign_access(gntdev_dmabuf->u.imp.refs,\n\t\t\t\t      gntdev_dmabuf->nr_pages);\n\n\tattach = gntdev_dmabuf->u.imp.attach;\n\n\tif (gntdev_dmabuf->u.imp.sgt)\n\t\tdma_buf_unmap_attachment_unlocked(attach, gntdev_dmabuf->u.imp.sgt,\n\t\t\t\t\t\t  DMA_BIDIRECTIONAL);\n\tdma_buf = attach->dmabuf;\n\tdma_buf_detach(attach->dmabuf, attach);\n\tdma_buf_put(dma_buf);\n\n\tdmabuf_imp_free_storage(gntdev_dmabuf);\n\treturn 0;\n}\n\nstatic void dmabuf_imp_release_all(struct gntdev_dmabuf_priv *priv)\n{\n\tstruct gntdev_dmabuf *q, *gntdev_dmabuf;\n\n\tlist_for_each_entry_safe(gntdev_dmabuf, q, &priv->imp_list, next)\n\t\tdmabuf_imp_release(priv, gntdev_dmabuf->fd);\n}\n\n \n\nlong gntdev_ioctl_dmabuf_exp_from_refs(struct gntdev_priv *priv, int use_ptemod,\n\t\t\t\t       struct ioctl_gntdev_dmabuf_exp_from_refs __user *u)\n{\n\tstruct ioctl_gntdev_dmabuf_exp_from_refs op;\n\tu32 *refs;\n\tlong ret;\n\n\tif (use_ptemod) {\n\t\tpr_debug(\"Cannot provide dma-buf: use_ptemode %d\\n\",\n\t\t\t use_ptemod);\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(&op, u, sizeof(op)) != 0)\n\t\treturn -EFAULT;\n\n\tif (unlikely(gntdev_test_page_count(op.count)))\n\t\treturn -EINVAL;\n\n\trefs = kcalloc(op.count, sizeof(*refs), GFP_KERNEL);\n\tif (!refs)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(refs, u->refs, sizeof(*refs) * op.count) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tret = dmabuf_exp_from_refs(priv, op.flags, op.count,\n\t\t\t\t   op.domid, refs, &op.fd);\n\tif (ret)\n\t\tgoto out;\n\n\tif (copy_to_user(u, &op, sizeof(op)) != 0)\n\t\tret = -EFAULT;\n\nout:\n\tkfree(refs);\n\treturn ret;\n}\n\nlong gntdev_ioctl_dmabuf_exp_wait_released(struct gntdev_priv *priv,\n\t\t\t\t\t   struct ioctl_gntdev_dmabuf_exp_wait_released __user *u)\n{\n\tstruct ioctl_gntdev_dmabuf_exp_wait_released op;\n\n\tif (copy_from_user(&op, u, sizeof(op)) != 0)\n\t\treturn -EFAULT;\n\n\treturn dmabuf_exp_wait_released(priv->dmabuf_priv, op.fd,\n\t\t\t\t\top.wait_to_ms);\n}\n\nlong gntdev_ioctl_dmabuf_imp_to_refs(struct gntdev_priv *priv,\n\t\t\t\t     struct ioctl_gntdev_dmabuf_imp_to_refs __user *u)\n{\n\tstruct ioctl_gntdev_dmabuf_imp_to_refs op;\n\tstruct gntdev_dmabuf *gntdev_dmabuf;\n\tlong ret;\n\n\tif (copy_from_user(&op, u, sizeof(op)) != 0)\n\t\treturn -EFAULT;\n\n\tif (unlikely(gntdev_test_page_count(op.count)))\n\t\treturn -EINVAL;\n\n\tgntdev_dmabuf = dmabuf_imp_to_refs(priv->dmabuf_priv,\n\t\t\t\t\t   priv->dma_dev, op.fd,\n\t\t\t\t\t   op.count, op.domid);\n\tif (IS_ERR(gntdev_dmabuf))\n\t\treturn PTR_ERR(gntdev_dmabuf);\n\n\tif (copy_to_user(u->refs, gntdev_dmabuf->u.imp.refs,\n\t\t\t sizeof(*u->refs) * op.count) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto out_release;\n\t}\n\treturn 0;\n\nout_release:\n\tdmabuf_imp_release(priv->dmabuf_priv, op.fd);\n\treturn ret;\n}\n\nlong gntdev_ioctl_dmabuf_imp_release(struct gntdev_priv *priv,\n\t\t\t\t     struct ioctl_gntdev_dmabuf_imp_release __user *u)\n{\n\tstruct ioctl_gntdev_dmabuf_imp_release op;\n\n\tif (copy_from_user(&op, u, sizeof(op)) != 0)\n\t\treturn -EFAULT;\n\n\treturn dmabuf_imp_release(priv->dmabuf_priv, op.fd);\n}\n\nstruct gntdev_dmabuf_priv *gntdev_dmabuf_init(struct file *filp)\n{\n\tstruct gntdev_dmabuf_priv *priv;\n\n\tpriv = kzalloc(sizeof(*priv), GFP_KERNEL);\n\tif (!priv)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmutex_init(&priv->lock);\n\tINIT_LIST_HEAD(&priv->exp_list);\n\tINIT_LIST_HEAD(&priv->exp_wait_list);\n\tINIT_LIST_HEAD(&priv->imp_list);\n\n\tpriv->filp = filp;\n\n\treturn priv;\n}\n\nvoid gntdev_dmabuf_fini(struct gntdev_dmabuf_priv *priv)\n{\n\tdmabuf_imp_release_all(priv);\n\tkfree(priv);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}