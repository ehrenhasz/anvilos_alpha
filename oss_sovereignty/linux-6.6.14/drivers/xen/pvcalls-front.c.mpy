{
  "module_name": "pvcalls-front.c",
  "hash_id": "152109407e3ff3055c1143b105b5cfb1cb4ee830f1714c6f4c0f320ee8fda707",
  "original_prompt": "Ingested from linux-6.6.14/drivers/xen/pvcalls-front.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/net.h>\n#include <linux/socket.h>\n\n#include <net/sock.h>\n\n#include <xen/events.h>\n#include <xen/grant_table.h>\n#include <xen/xen.h>\n#include <xen/xenbus.h>\n#include <xen/interface/io/pvcalls.h>\n\n#include \"pvcalls-front.h\"\n\n#define PVCALLS_INVALID_ID UINT_MAX\n#define PVCALLS_RING_ORDER XENBUS_MAX_RING_GRANT_ORDER\n#define PVCALLS_NR_RSP_PER_RING __CONST_RING_SIZE(xen_pvcalls, XEN_PAGE_SIZE)\n#define PVCALLS_FRONT_MAX_SPIN 5000\n\nstatic struct proto pvcalls_proto = {\n\t.name\t= \"PVCalls\",\n\t.owner\t= THIS_MODULE,\n\t.obj_size = sizeof(struct sock),\n};\n\nstruct pvcalls_bedata {\n\tstruct xen_pvcalls_front_ring ring;\n\tgrant_ref_t ref;\n\tint irq;\n\n\tstruct list_head socket_mappings;\n\tspinlock_t socket_lock;\n\n\twait_queue_head_t inflight_req;\n\tstruct xen_pvcalls_response rsp[PVCALLS_NR_RSP_PER_RING];\n};\n \nstatic struct xenbus_device *pvcalls_front_dev;\nstatic atomic_t pvcalls_refcount;\n\n \n#define pvcalls_enter() {               \\\n\tatomic_inc(&pvcalls_refcount);      \\\n}\n\n \n#define pvcalls_exit() {                \\\n\tatomic_dec(&pvcalls_refcount);      \\\n}\n\nstruct sock_mapping {\n\tbool active_socket;\n\tstruct list_head list;\n\tstruct socket *sock;\n\tatomic_t refcount;\n\tunion {\n\t\tstruct {\n\t\t\tint irq;\n\t\t\tgrant_ref_t ref;\n\t\t\tstruct pvcalls_data_intf *ring;\n\t\t\tstruct pvcalls_data data;\n\t\t\tstruct mutex in_mutex;\n\t\t\tstruct mutex out_mutex;\n\n\t\t\twait_queue_head_t inflight_conn_req;\n\t\t} active;\n\t\tstruct {\n\t\t \n#define PVCALLS_STATUS_UNINITALIZED  0\n#define PVCALLS_STATUS_BIND          1\n#define PVCALLS_STATUS_LISTEN        2\n\t\t\tuint8_t status __attribute__((aligned(8)));\n\t\t \n#define PVCALLS_FLAG_ACCEPT_INFLIGHT 0\n#define PVCALLS_FLAG_POLL_INFLIGHT   1\n#define PVCALLS_FLAG_POLL_RET        2\n\t\t\tuint8_t flags __attribute__((aligned(8)));\n\t\t\tuint32_t inflight_req_id;\n\t\t\tstruct sock_mapping *accept_map;\n\t\t\twait_queue_head_t inflight_accept_req;\n\t\t} passive;\n\t};\n};\n\nstatic inline struct sock_mapping *pvcalls_enter_sock(struct socket *sock)\n{\n\tstruct sock_mapping *map;\n\n\tif (!pvcalls_front_dev ||\n\t\tdev_get_drvdata(&pvcalls_front_dev->dev) == NULL)\n\t\treturn ERR_PTR(-ENOTCONN);\n\n\tmap = (struct sock_mapping *)sock->sk->sk_send_head;\n\tif (map == NULL)\n\t\treturn ERR_PTR(-ENOTSOCK);\n\n\tpvcalls_enter();\n\tatomic_inc(&map->refcount);\n\treturn map;\n}\n\nstatic inline void pvcalls_exit_sock(struct socket *sock)\n{\n\tstruct sock_mapping *map;\n\n\tmap = (struct sock_mapping *)sock->sk->sk_send_head;\n\tatomic_dec(&map->refcount);\n\tpvcalls_exit();\n}\n\nstatic inline int get_request(struct pvcalls_bedata *bedata, int *req_id)\n{\n\t*req_id = bedata->ring.req_prod_pvt & (RING_SIZE(&bedata->ring) - 1);\n\tif (RING_FULL(&bedata->ring) ||\n\t    bedata->rsp[*req_id].req_id != PVCALLS_INVALID_ID)\n\t\treturn -EAGAIN;\n\treturn 0;\n}\n\nstatic bool pvcalls_front_write_todo(struct sock_mapping *map)\n{\n\tstruct pvcalls_data_intf *intf = map->active.ring;\n\tRING_IDX cons, prod, size = XEN_FLEX_RING_SIZE(PVCALLS_RING_ORDER);\n\tint32_t error;\n\n\terror = intf->out_error;\n\tif (error == -ENOTCONN)\n\t\treturn false;\n\tif (error != 0)\n\t\treturn true;\n\n\tcons = intf->out_cons;\n\tprod = intf->out_prod;\n\treturn !!(size - pvcalls_queued(prod, cons, size));\n}\n\nstatic bool pvcalls_front_read_todo(struct sock_mapping *map)\n{\n\tstruct pvcalls_data_intf *intf = map->active.ring;\n\tRING_IDX cons, prod;\n\tint32_t error;\n\n\tcons = intf->in_cons;\n\tprod = intf->in_prod;\n\terror = intf->in_error;\n\treturn (error != 0 ||\n\t\tpvcalls_queued(prod, cons,\n\t\t\t       XEN_FLEX_RING_SIZE(PVCALLS_RING_ORDER)) != 0);\n}\n\nstatic irqreturn_t pvcalls_front_event_handler(int irq, void *dev_id)\n{\n\tstruct xenbus_device *dev = dev_id;\n\tstruct pvcalls_bedata *bedata;\n\tstruct xen_pvcalls_response *rsp;\n\tuint8_t *src, *dst;\n\tint req_id = 0, more = 0, done = 0;\n\n\tif (dev == NULL)\n\t\treturn IRQ_HANDLED;\n\n\tpvcalls_enter();\n\tbedata = dev_get_drvdata(&dev->dev);\n\tif (bedata == NULL) {\n\t\tpvcalls_exit();\n\t\treturn IRQ_HANDLED;\n\t}\n\nagain:\n\twhile (RING_HAS_UNCONSUMED_RESPONSES(&bedata->ring)) {\n\t\trsp = RING_GET_RESPONSE(&bedata->ring, bedata->ring.rsp_cons);\n\n\t\treq_id = rsp->req_id;\n\t\tif (rsp->cmd == PVCALLS_POLL) {\n\t\t\tstruct sock_mapping *map = (struct sock_mapping *)(uintptr_t)\n\t\t\t\t\t\t   rsp->u.poll.id;\n\n\t\t\tclear_bit(PVCALLS_FLAG_POLL_INFLIGHT,\n\t\t\t\t  (void *)&map->passive.flags);\n\t\t\t \n\t\t\tsmp_wmb();\n\t\t\tset_bit(PVCALLS_FLAG_POLL_RET,\n\t\t\t\t(void *)&map->passive.flags);\n\t\t} else {\n\t\t\tdst = (uint8_t *)&bedata->rsp[req_id] +\n\t\t\t      sizeof(rsp->req_id);\n\t\t\tsrc = (uint8_t *)rsp + sizeof(rsp->req_id);\n\t\t\tmemcpy(dst, src, sizeof(*rsp) - sizeof(rsp->req_id));\n\t\t\t \n\t\t\tsmp_wmb();\n\t\t\tbedata->rsp[req_id].req_id = req_id;\n\t\t}\n\n\t\tdone = 1;\n\t\tbedata->ring.rsp_cons++;\n\t}\n\n\tRING_FINAL_CHECK_FOR_RESPONSES(&bedata->ring, more);\n\tif (more)\n\t\tgoto again;\n\tif (done)\n\t\twake_up(&bedata->inflight_req);\n\tpvcalls_exit();\n\treturn IRQ_HANDLED;\n}\n\nstatic void free_active_ring(struct sock_mapping *map);\n\nstatic void pvcalls_front_destroy_active(struct pvcalls_bedata *bedata,\n\t\t\t\t\t struct sock_mapping *map)\n{\n\tint i;\n\n\tunbind_from_irqhandler(map->active.irq, map);\n\n\tif (bedata) {\n\t\tspin_lock(&bedata->socket_lock);\n\t\tif (!list_empty(&map->list))\n\t\t\tlist_del_init(&map->list);\n\t\tspin_unlock(&bedata->socket_lock);\n\t}\n\n\tfor (i = 0; i < (1 << PVCALLS_RING_ORDER); i++)\n\t\tgnttab_end_foreign_access(map->active.ring->ref[i], NULL);\n\tgnttab_end_foreign_access(map->active.ref, NULL);\n\tfree_active_ring(map);\n}\n\nstatic void pvcalls_front_free_map(struct pvcalls_bedata *bedata,\n\t\t\t\t   struct sock_mapping *map)\n{\n\tpvcalls_front_destroy_active(bedata, map);\n\n\tkfree(map);\n}\n\nstatic irqreturn_t pvcalls_front_conn_handler(int irq, void *sock_map)\n{\n\tstruct sock_mapping *map = sock_map;\n\n\tif (map == NULL)\n\t\treturn IRQ_HANDLED;\n\n\twake_up_interruptible(&map->active.inflight_conn_req);\n\n\treturn IRQ_HANDLED;\n}\n\nint pvcalls_front_socket(struct socket *sock)\n{\n\tstruct pvcalls_bedata *bedata;\n\tstruct sock_mapping *map = NULL;\n\tstruct xen_pvcalls_request *req;\n\tint notify, req_id, ret;\n\n\t \n\tif (sock->type != SOCK_STREAM)\n\t\treturn -EOPNOTSUPP;\n\n\tpvcalls_enter();\n\tif (!pvcalls_front_dev) {\n\t\tpvcalls_exit();\n\t\treturn -EACCES;\n\t}\n\tbedata = dev_get_drvdata(&pvcalls_front_dev->dev);\n\n\tmap = kzalloc(sizeof(*map), GFP_KERNEL);\n\tif (map == NULL) {\n\t\tpvcalls_exit();\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock(&bedata->socket_lock);\n\n\tret = get_request(bedata, &req_id);\n\tif (ret < 0) {\n\t\tkfree(map);\n\t\tspin_unlock(&bedata->socket_lock);\n\t\tpvcalls_exit();\n\t\treturn ret;\n\t}\n\n\t \n\tsock->sk->sk_send_head = (void *)map;\n\tlist_add_tail(&map->list, &bedata->socket_mappings);\n\n\treq = RING_GET_REQUEST(&bedata->ring, req_id);\n\treq->req_id = req_id;\n\treq->cmd = PVCALLS_SOCKET;\n\treq->u.socket.id = (uintptr_t) map;\n\treq->u.socket.domain = AF_INET;\n\treq->u.socket.type = SOCK_STREAM;\n\treq->u.socket.protocol = IPPROTO_IP;\n\n\tbedata->ring.req_prod_pvt++;\n\tRING_PUSH_REQUESTS_AND_CHECK_NOTIFY(&bedata->ring, notify);\n\tspin_unlock(&bedata->socket_lock);\n\tif (notify)\n\t\tnotify_remote_via_irq(bedata->irq);\n\n\twait_event(bedata->inflight_req,\n\t\t   READ_ONCE(bedata->rsp[req_id].req_id) == req_id);\n\n\t \n\tsmp_rmb();\n\tret = bedata->rsp[req_id].ret;\n\tbedata->rsp[req_id].req_id = PVCALLS_INVALID_ID;\n\n\tpvcalls_exit();\n\treturn ret;\n}\n\nstatic void free_active_ring(struct sock_mapping *map)\n{\n\tif (!map->active.ring)\n\t\treturn;\n\n\tfree_pages_exact(map->active.data.in,\n\t\t\t PAGE_SIZE << map->active.ring->ring_order);\n\tfree_page((unsigned long)map->active.ring);\n}\n\nstatic int alloc_active_ring(struct sock_mapping *map)\n{\n\tvoid *bytes;\n\n\tmap->active.ring = (struct pvcalls_data_intf *)\n\t\tget_zeroed_page(GFP_KERNEL);\n\tif (!map->active.ring)\n\t\tgoto out;\n\n\tmap->active.ring->ring_order = PVCALLS_RING_ORDER;\n\tbytes = alloc_pages_exact(PAGE_SIZE << PVCALLS_RING_ORDER,\n\t\t\t\t  GFP_KERNEL | __GFP_ZERO);\n\tif (!bytes)\n\t\tgoto out;\n\n\tmap->active.data.in = bytes;\n\tmap->active.data.out = bytes +\n\t\tXEN_FLEX_RING_SIZE(PVCALLS_RING_ORDER);\n\n\treturn 0;\n\nout:\n\tfree_active_ring(map);\n\treturn -ENOMEM;\n}\n\nstatic int create_active(struct sock_mapping *map, evtchn_port_t *evtchn)\n{\n\tvoid *bytes;\n\tint ret, irq = -1, i;\n\n\t*evtchn = 0;\n\tinit_waitqueue_head(&map->active.inflight_conn_req);\n\n\tbytes = map->active.data.in;\n\tfor (i = 0; i < (1 << PVCALLS_RING_ORDER); i++)\n\t\tmap->active.ring->ref[i] = gnttab_grant_foreign_access(\n\t\t\tpvcalls_front_dev->otherend_id,\n\t\t\tpfn_to_gfn(virt_to_pfn(bytes) + i), 0);\n\n\tmap->active.ref = gnttab_grant_foreign_access(\n\t\tpvcalls_front_dev->otherend_id,\n\t\tpfn_to_gfn(virt_to_pfn((void *)map->active.ring)), 0);\n\n\tret = xenbus_alloc_evtchn(pvcalls_front_dev, evtchn);\n\tif (ret)\n\t\tgoto out_error;\n\tirq = bind_evtchn_to_irqhandler(*evtchn, pvcalls_front_conn_handler,\n\t\t\t\t\t0, \"pvcalls-frontend\", map);\n\tif (irq < 0) {\n\t\tret = irq;\n\t\tgoto out_error;\n\t}\n\n\tmap->active.irq = irq;\n\tmap->active_socket = true;\n\tmutex_init(&map->active.in_mutex);\n\tmutex_init(&map->active.out_mutex);\n\n\treturn 0;\n\nout_error:\n\tif (*evtchn > 0)\n\t\txenbus_free_evtchn(pvcalls_front_dev, *evtchn);\n\treturn ret;\n}\n\nint pvcalls_front_connect(struct socket *sock, struct sockaddr *addr,\n\t\t\t\tint addr_len, int flags)\n{\n\tstruct pvcalls_bedata *bedata;\n\tstruct sock_mapping *map = NULL;\n\tstruct xen_pvcalls_request *req;\n\tint notify, req_id, ret;\n\tevtchn_port_t evtchn;\n\n\tif (addr->sa_family != AF_INET || sock->type != SOCK_STREAM)\n\t\treturn -EOPNOTSUPP;\n\n\tmap = pvcalls_enter_sock(sock);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\n\tbedata = dev_get_drvdata(&pvcalls_front_dev->dev);\n\tret = alloc_active_ring(map);\n\tif (ret < 0) {\n\t\tpvcalls_exit_sock(sock);\n\t\treturn ret;\n\t}\n\tret = create_active(map, &evtchn);\n\tif (ret < 0) {\n\t\tfree_active_ring(map);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn ret;\n\t}\n\n\tspin_lock(&bedata->socket_lock);\n\tret = get_request(bedata, &req_id);\n\tif (ret < 0) {\n\t\tspin_unlock(&bedata->socket_lock);\n\t\tpvcalls_front_destroy_active(NULL, map);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn ret;\n\t}\n\n\treq = RING_GET_REQUEST(&bedata->ring, req_id);\n\treq->req_id = req_id;\n\treq->cmd = PVCALLS_CONNECT;\n\treq->u.connect.id = (uintptr_t)map;\n\treq->u.connect.len = addr_len;\n\treq->u.connect.flags = flags;\n\treq->u.connect.ref = map->active.ref;\n\treq->u.connect.evtchn = evtchn;\n\tmemcpy(req->u.connect.addr, addr, sizeof(*addr));\n\n\tmap->sock = sock;\n\n\tbedata->ring.req_prod_pvt++;\n\tRING_PUSH_REQUESTS_AND_CHECK_NOTIFY(&bedata->ring, notify);\n\tspin_unlock(&bedata->socket_lock);\n\n\tif (notify)\n\t\tnotify_remote_via_irq(bedata->irq);\n\n\twait_event(bedata->inflight_req,\n\t\t   READ_ONCE(bedata->rsp[req_id].req_id) == req_id);\n\n\t \n\tsmp_rmb();\n\tret = bedata->rsp[req_id].ret;\n\tbedata->rsp[req_id].req_id = PVCALLS_INVALID_ID;\n\tpvcalls_exit_sock(sock);\n\treturn ret;\n}\n\nstatic int __write_ring(struct pvcalls_data_intf *intf,\n\t\t\tstruct pvcalls_data *data,\n\t\t\tstruct iov_iter *msg_iter,\n\t\t\tint len)\n{\n\tRING_IDX cons, prod, size, masked_prod, masked_cons;\n\tRING_IDX array_size = XEN_FLEX_RING_SIZE(PVCALLS_RING_ORDER);\n\tint32_t error;\n\n\terror = intf->out_error;\n\tif (error < 0)\n\t\treturn error;\n\tcons = intf->out_cons;\n\tprod = intf->out_prod;\n\t \n\tvirt_mb();\n\n\tsize = pvcalls_queued(prod, cons, array_size);\n\tif (size > array_size)\n\t\treturn -EINVAL;\n\tif (size == array_size)\n\t\treturn 0;\n\tif (len > array_size - size)\n\t\tlen = array_size - size;\n\n\tmasked_prod = pvcalls_mask(prod, array_size);\n\tmasked_cons = pvcalls_mask(cons, array_size);\n\n\tif (masked_prod < masked_cons) {\n\t\tlen = copy_from_iter(data->out + masked_prod, len, msg_iter);\n\t} else {\n\t\tif (len > array_size - masked_prod) {\n\t\t\tint ret = copy_from_iter(data->out + masked_prod,\n\t\t\t\t       array_size - masked_prod, msg_iter);\n\t\t\tif (ret != array_size - masked_prod) {\n\t\t\t\tlen = ret;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tlen = ret + copy_from_iter(data->out, len - ret, msg_iter);\n\t\t} else {\n\t\t\tlen = copy_from_iter(data->out + masked_prod, len, msg_iter);\n\t\t}\n\t}\nout:\n\t \n\tvirt_wmb();\n\tintf->out_prod += len;\n\n\treturn len;\n}\n\nint pvcalls_front_sendmsg(struct socket *sock, struct msghdr *msg,\n\t\t\t  size_t len)\n{\n\tstruct sock_mapping *map;\n\tint sent, tot_sent = 0;\n\tint count = 0, flags;\n\n\tflags = msg->msg_flags;\n\tif (flags & (MSG_CONFIRM|MSG_DONTROUTE|MSG_EOR|MSG_OOB))\n\t\treturn -EOPNOTSUPP;\n\n\tmap = pvcalls_enter_sock(sock);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\n\tmutex_lock(&map->active.out_mutex);\n\tif ((flags & MSG_DONTWAIT) && !pvcalls_front_write_todo(map)) {\n\t\tmutex_unlock(&map->active.out_mutex);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn -EAGAIN;\n\t}\n\tif (len > INT_MAX)\n\t\tlen = INT_MAX;\n\nagain:\n\tcount++;\n\tsent = __write_ring(map->active.ring,\n\t\t\t    &map->active.data, &msg->msg_iter,\n\t\t\t    len);\n\tif (sent > 0) {\n\t\tlen -= sent;\n\t\ttot_sent += sent;\n\t\tnotify_remote_via_irq(map->active.irq);\n\t}\n\tif (sent >= 0 && len > 0 && count < PVCALLS_FRONT_MAX_SPIN)\n\t\tgoto again;\n\tif (sent < 0)\n\t\ttot_sent = sent;\n\n\tmutex_unlock(&map->active.out_mutex);\n\tpvcalls_exit_sock(sock);\n\treturn tot_sent;\n}\n\nstatic int __read_ring(struct pvcalls_data_intf *intf,\n\t\t       struct pvcalls_data *data,\n\t\t       struct iov_iter *msg_iter,\n\t\t       size_t len, int flags)\n{\n\tRING_IDX cons, prod, size, masked_prod, masked_cons;\n\tRING_IDX array_size = XEN_FLEX_RING_SIZE(PVCALLS_RING_ORDER);\n\tint32_t error;\n\n\tcons = intf->in_cons;\n\tprod = intf->in_prod;\n\terror = intf->in_error;\n\t \n\tvirt_rmb();\n\n\tsize = pvcalls_queued(prod, cons, array_size);\n\tmasked_prod = pvcalls_mask(prod, array_size);\n\tmasked_cons = pvcalls_mask(cons, array_size);\n\n\tif (size == 0)\n\t\treturn error ?: size;\n\n\tif (len > size)\n\t\tlen = size;\n\n\tif (masked_prod > masked_cons) {\n\t\tlen = copy_to_iter(data->in + masked_cons, len, msg_iter);\n\t} else {\n\t\tif (len > (array_size - masked_cons)) {\n\t\t\tint ret = copy_to_iter(data->in + masked_cons,\n\t\t\t\t     array_size - masked_cons, msg_iter);\n\t\t\tif (ret != array_size - masked_cons) {\n\t\t\t\tlen = ret;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tlen = ret + copy_to_iter(data->in, len - ret, msg_iter);\n\t\t} else {\n\t\t\tlen = copy_to_iter(data->in + masked_cons, len, msg_iter);\n\t\t}\n\t}\nout:\n\t \n\tvirt_mb();\n\tif (!(flags & MSG_PEEK))\n\t\tintf->in_cons += len;\n\n\treturn len;\n}\n\nint pvcalls_front_recvmsg(struct socket *sock, struct msghdr *msg, size_t len,\n\t\t     int flags)\n{\n\tint ret;\n\tstruct sock_mapping *map;\n\n\tif (flags & (MSG_CMSG_CLOEXEC|MSG_ERRQUEUE|MSG_OOB|MSG_TRUNC))\n\t\treturn -EOPNOTSUPP;\n\n\tmap = pvcalls_enter_sock(sock);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\n\tmutex_lock(&map->active.in_mutex);\n\tif (len > XEN_FLEX_RING_SIZE(PVCALLS_RING_ORDER))\n\t\tlen = XEN_FLEX_RING_SIZE(PVCALLS_RING_ORDER);\n\n\twhile (!(flags & MSG_DONTWAIT) && !pvcalls_front_read_todo(map)) {\n\t\twait_event_interruptible(map->active.inflight_conn_req,\n\t\t\t\t\t pvcalls_front_read_todo(map));\n\t}\n\tret = __read_ring(map->active.ring, &map->active.data,\n\t\t\t  &msg->msg_iter, len, flags);\n\n\tif (ret > 0)\n\t\tnotify_remote_via_irq(map->active.irq);\n\tif (ret == 0)\n\t\tret = (flags & MSG_DONTWAIT) ? -EAGAIN : 0;\n\tif (ret == -ENOTCONN)\n\t\tret = 0;\n\n\tmutex_unlock(&map->active.in_mutex);\n\tpvcalls_exit_sock(sock);\n\treturn ret;\n}\n\nint pvcalls_front_bind(struct socket *sock, struct sockaddr *addr, int addr_len)\n{\n\tstruct pvcalls_bedata *bedata;\n\tstruct sock_mapping *map = NULL;\n\tstruct xen_pvcalls_request *req;\n\tint notify, req_id, ret;\n\n\tif (addr->sa_family != AF_INET || sock->type != SOCK_STREAM)\n\t\treturn -EOPNOTSUPP;\n\n\tmap = pvcalls_enter_sock(sock);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\tbedata = dev_get_drvdata(&pvcalls_front_dev->dev);\n\n\tspin_lock(&bedata->socket_lock);\n\tret = get_request(bedata, &req_id);\n\tif (ret < 0) {\n\t\tspin_unlock(&bedata->socket_lock);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn ret;\n\t}\n\treq = RING_GET_REQUEST(&bedata->ring, req_id);\n\treq->req_id = req_id;\n\tmap->sock = sock;\n\treq->cmd = PVCALLS_BIND;\n\treq->u.bind.id = (uintptr_t)map;\n\tmemcpy(req->u.bind.addr, addr, sizeof(*addr));\n\treq->u.bind.len = addr_len;\n\n\tinit_waitqueue_head(&map->passive.inflight_accept_req);\n\n\tmap->active_socket = false;\n\n\tbedata->ring.req_prod_pvt++;\n\tRING_PUSH_REQUESTS_AND_CHECK_NOTIFY(&bedata->ring, notify);\n\tspin_unlock(&bedata->socket_lock);\n\tif (notify)\n\t\tnotify_remote_via_irq(bedata->irq);\n\n\twait_event(bedata->inflight_req,\n\t\t   READ_ONCE(bedata->rsp[req_id].req_id) == req_id);\n\n\t \n\tsmp_rmb();\n\tret = bedata->rsp[req_id].ret;\n\tbedata->rsp[req_id].req_id = PVCALLS_INVALID_ID;\n\n\tmap->passive.status = PVCALLS_STATUS_BIND;\n\tpvcalls_exit_sock(sock);\n\treturn 0;\n}\n\nint pvcalls_front_listen(struct socket *sock, int backlog)\n{\n\tstruct pvcalls_bedata *bedata;\n\tstruct sock_mapping *map;\n\tstruct xen_pvcalls_request *req;\n\tint notify, req_id, ret;\n\n\tmap = pvcalls_enter_sock(sock);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\tbedata = dev_get_drvdata(&pvcalls_front_dev->dev);\n\n\tif (map->passive.status != PVCALLS_STATUS_BIND) {\n\t\tpvcalls_exit_sock(sock);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tspin_lock(&bedata->socket_lock);\n\tret = get_request(bedata, &req_id);\n\tif (ret < 0) {\n\t\tspin_unlock(&bedata->socket_lock);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn ret;\n\t}\n\treq = RING_GET_REQUEST(&bedata->ring, req_id);\n\treq->req_id = req_id;\n\treq->cmd = PVCALLS_LISTEN;\n\treq->u.listen.id = (uintptr_t) map;\n\treq->u.listen.backlog = backlog;\n\n\tbedata->ring.req_prod_pvt++;\n\tRING_PUSH_REQUESTS_AND_CHECK_NOTIFY(&bedata->ring, notify);\n\tspin_unlock(&bedata->socket_lock);\n\tif (notify)\n\t\tnotify_remote_via_irq(bedata->irq);\n\n\twait_event(bedata->inflight_req,\n\t\t   READ_ONCE(bedata->rsp[req_id].req_id) == req_id);\n\n\t \n\tsmp_rmb();\n\tret = bedata->rsp[req_id].ret;\n\tbedata->rsp[req_id].req_id = PVCALLS_INVALID_ID;\n\n\tmap->passive.status = PVCALLS_STATUS_LISTEN;\n\tpvcalls_exit_sock(sock);\n\treturn ret;\n}\n\nint pvcalls_front_accept(struct socket *sock, struct socket *newsock, int flags)\n{\n\tstruct pvcalls_bedata *bedata;\n\tstruct sock_mapping *map;\n\tstruct sock_mapping *map2 = NULL;\n\tstruct xen_pvcalls_request *req;\n\tint notify, req_id, ret, nonblock;\n\tevtchn_port_t evtchn;\n\n\tmap = pvcalls_enter_sock(sock);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\tbedata = dev_get_drvdata(&pvcalls_front_dev->dev);\n\n\tif (map->passive.status != PVCALLS_STATUS_LISTEN) {\n\t\tpvcalls_exit_sock(sock);\n\t\treturn -EINVAL;\n\t}\n\n\tnonblock = flags & SOCK_NONBLOCK;\n\t \n\tif (test_and_set_bit(PVCALLS_FLAG_ACCEPT_INFLIGHT,\n\t\t\t     (void *)&map->passive.flags)) {\n\t\treq_id = READ_ONCE(map->passive.inflight_req_id);\n\t\tif (req_id != PVCALLS_INVALID_ID &&\n\t\t    READ_ONCE(bedata->rsp[req_id].req_id) == req_id) {\n\t\t\tmap2 = map->passive.accept_map;\n\t\t\tgoto received;\n\t\t}\n\t\tif (nonblock) {\n\t\t\tpvcalls_exit_sock(sock);\n\t\t\treturn -EAGAIN;\n\t\t}\n\t\tif (wait_event_interruptible(map->passive.inflight_accept_req,\n\t\t\t!test_and_set_bit(PVCALLS_FLAG_ACCEPT_INFLIGHT,\n\t\t\t\t\t  (void *)&map->passive.flags))) {\n\t\t\tpvcalls_exit_sock(sock);\n\t\t\treturn -EINTR;\n\t\t}\n\t}\n\n\tmap2 = kzalloc(sizeof(*map2), GFP_KERNEL);\n\tif (map2 == NULL) {\n\t\tclear_bit(PVCALLS_FLAG_ACCEPT_INFLIGHT,\n\t\t\t  (void *)&map->passive.flags);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn -ENOMEM;\n\t}\n\tret = alloc_active_ring(map2);\n\tif (ret < 0) {\n\t\tclear_bit(PVCALLS_FLAG_ACCEPT_INFLIGHT,\n\t\t\t\t(void *)&map->passive.flags);\n\t\tkfree(map2);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn ret;\n\t}\n\tret = create_active(map2, &evtchn);\n\tif (ret < 0) {\n\t\tfree_active_ring(map2);\n\t\tkfree(map2);\n\t\tclear_bit(PVCALLS_FLAG_ACCEPT_INFLIGHT,\n\t\t\t  (void *)&map->passive.flags);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn ret;\n\t}\n\n\tspin_lock(&bedata->socket_lock);\n\tret = get_request(bedata, &req_id);\n\tif (ret < 0) {\n\t\tclear_bit(PVCALLS_FLAG_ACCEPT_INFLIGHT,\n\t\t\t  (void *)&map->passive.flags);\n\t\tspin_unlock(&bedata->socket_lock);\n\t\tpvcalls_front_free_map(bedata, map2);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn ret;\n\t}\n\n\tlist_add_tail(&map2->list, &bedata->socket_mappings);\n\n\treq = RING_GET_REQUEST(&bedata->ring, req_id);\n\treq->req_id = req_id;\n\treq->cmd = PVCALLS_ACCEPT;\n\treq->u.accept.id = (uintptr_t) map;\n\treq->u.accept.ref = map2->active.ref;\n\treq->u.accept.id_new = (uintptr_t) map2;\n\treq->u.accept.evtchn = evtchn;\n\tmap->passive.accept_map = map2;\n\n\tbedata->ring.req_prod_pvt++;\n\tRING_PUSH_REQUESTS_AND_CHECK_NOTIFY(&bedata->ring, notify);\n\tspin_unlock(&bedata->socket_lock);\n\tif (notify)\n\t\tnotify_remote_via_irq(bedata->irq);\n\t \n\tif (nonblock) {\n\t\tWRITE_ONCE(map->passive.inflight_req_id, req_id);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn -EAGAIN;\n\t}\n\n\tif (wait_event_interruptible(bedata->inflight_req,\n\t\tREAD_ONCE(bedata->rsp[req_id].req_id) == req_id)) {\n\t\tpvcalls_exit_sock(sock);\n\t\treturn -EINTR;\n\t}\n\t \n\tsmp_rmb();\n\nreceived:\n\tmap2->sock = newsock;\n\tnewsock->sk = sk_alloc(sock_net(sock->sk), PF_INET, GFP_KERNEL, &pvcalls_proto, false);\n\tif (!newsock->sk) {\n\t\tbedata->rsp[req_id].req_id = PVCALLS_INVALID_ID;\n\t\tmap->passive.inflight_req_id = PVCALLS_INVALID_ID;\n\t\tclear_bit(PVCALLS_FLAG_ACCEPT_INFLIGHT,\n\t\t\t  (void *)&map->passive.flags);\n\t\tpvcalls_front_free_map(bedata, map2);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn -ENOMEM;\n\t}\n\tnewsock->sk->sk_send_head = (void *)map2;\n\n\tret = bedata->rsp[req_id].ret;\n\tbedata->rsp[req_id].req_id = PVCALLS_INVALID_ID;\n\tmap->passive.inflight_req_id = PVCALLS_INVALID_ID;\n\n\tclear_bit(PVCALLS_FLAG_ACCEPT_INFLIGHT, (void *)&map->passive.flags);\n\twake_up(&map->passive.inflight_accept_req);\n\n\tpvcalls_exit_sock(sock);\n\treturn ret;\n}\n\nstatic __poll_t pvcalls_front_poll_passive(struct file *file,\n\t\t\t\t\t       struct pvcalls_bedata *bedata,\n\t\t\t\t\t       struct sock_mapping *map,\n\t\t\t\t\t       poll_table *wait)\n{\n\tint notify, req_id, ret;\n\tstruct xen_pvcalls_request *req;\n\n\tif (test_bit(PVCALLS_FLAG_ACCEPT_INFLIGHT,\n\t\t     (void *)&map->passive.flags)) {\n\t\tuint32_t req_id = READ_ONCE(map->passive.inflight_req_id);\n\n\t\tif (req_id != PVCALLS_INVALID_ID &&\n\t\t    READ_ONCE(bedata->rsp[req_id].req_id) == req_id)\n\t\t\treturn EPOLLIN | EPOLLRDNORM;\n\n\t\tpoll_wait(file, &map->passive.inflight_accept_req, wait);\n\t\treturn 0;\n\t}\n\n\tif (test_and_clear_bit(PVCALLS_FLAG_POLL_RET,\n\t\t\t       (void *)&map->passive.flags))\n\t\treturn EPOLLIN | EPOLLRDNORM;\n\n\t \n\n\tif (test_and_set_bit(PVCALLS_FLAG_POLL_INFLIGHT,\n\t\t\t     (void *)&map->passive.flags)) {\n\t\tpoll_wait(file, &bedata->inflight_req, wait);\n\t\treturn 0;\n\t}\n\n\tspin_lock(&bedata->socket_lock);\n\tret = get_request(bedata, &req_id);\n\tif (ret < 0) {\n\t\tspin_unlock(&bedata->socket_lock);\n\t\treturn ret;\n\t}\n\treq = RING_GET_REQUEST(&bedata->ring, req_id);\n\treq->req_id = req_id;\n\treq->cmd = PVCALLS_POLL;\n\treq->u.poll.id = (uintptr_t) map;\n\n\tbedata->ring.req_prod_pvt++;\n\tRING_PUSH_REQUESTS_AND_CHECK_NOTIFY(&bedata->ring, notify);\n\tspin_unlock(&bedata->socket_lock);\n\tif (notify)\n\t\tnotify_remote_via_irq(bedata->irq);\n\n\tpoll_wait(file, &bedata->inflight_req, wait);\n\treturn 0;\n}\n\nstatic __poll_t pvcalls_front_poll_active(struct file *file,\n\t\t\t\t\t      struct pvcalls_bedata *bedata,\n\t\t\t\t\t      struct sock_mapping *map,\n\t\t\t\t\t      poll_table *wait)\n{\n\t__poll_t mask = 0;\n\tint32_t in_error, out_error;\n\tstruct pvcalls_data_intf *intf = map->active.ring;\n\n\tout_error = intf->out_error;\n\tin_error = intf->in_error;\n\n\tpoll_wait(file, &map->active.inflight_conn_req, wait);\n\tif (pvcalls_front_write_todo(map))\n\t\tmask |= EPOLLOUT | EPOLLWRNORM;\n\tif (pvcalls_front_read_todo(map))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;\n\tif (in_error != 0 || out_error != 0)\n\t\tmask |= EPOLLERR;\n\n\treturn mask;\n}\n\n__poll_t pvcalls_front_poll(struct file *file, struct socket *sock,\n\t\t\t       poll_table *wait)\n{\n\tstruct pvcalls_bedata *bedata;\n\tstruct sock_mapping *map;\n\t__poll_t ret;\n\n\tmap = pvcalls_enter_sock(sock);\n\tif (IS_ERR(map))\n\t\treturn EPOLLNVAL;\n\tbedata = dev_get_drvdata(&pvcalls_front_dev->dev);\n\n\tif (map->active_socket)\n\t\tret = pvcalls_front_poll_active(file, bedata, map, wait);\n\telse\n\t\tret = pvcalls_front_poll_passive(file, bedata, map, wait);\n\tpvcalls_exit_sock(sock);\n\treturn ret;\n}\n\nint pvcalls_front_release(struct socket *sock)\n{\n\tstruct pvcalls_bedata *bedata;\n\tstruct sock_mapping *map;\n\tint req_id, notify, ret;\n\tstruct xen_pvcalls_request *req;\n\n\tif (sock->sk == NULL)\n\t\treturn 0;\n\n\tmap = pvcalls_enter_sock(sock);\n\tif (IS_ERR(map)) {\n\t\tif (PTR_ERR(map) == -ENOTCONN)\n\t\t\treturn -EIO;\n\t\telse\n\t\t\treturn 0;\n\t}\n\tbedata = dev_get_drvdata(&pvcalls_front_dev->dev);\n\n\tspin_lock(&bedata->socket_lock);\n\tret = get_request(bedata, &req_id);\n\tif (ret < 0) {\n\t\tspin_unlock(&bedata->socket_lock);\n\t\tpvcalls_exit_sock(sock);\n\t\treturn ret;\n\t}\n\tsock->sk->sk_send_head = NULL;\n\n\treq = RING_GET_REQUEST(&bedata->ring, req_id);\n\treq->req_id = req_id;\n\treq->cmd = PVCALLS_RELEASE;\n\treq->u.release.id = (uintptr_t)map;\n\n\tbedata->ring.req_prod_pvt++;\n\tRING_PUSH_REQUESTS_AND_CHECK_NOTIFY(&bedata->ring, notify);\n\tspin_unlock(&bedata->socket_lock);\n\tif (notify)\n\t\tnotify_remote_via_irq(bedata->irq);\n\n\twait_event(bedata->inflight_req,\n\t\t   READ_ONCE(bedata->rsp[req_id].req_id) == req_id);\n\n\tif (map->active_socket) {\n\t\t \n\t\tmap->active.ring->in_error = -EBADF;\n\t\twake_up_interruptible(&map->active.inflight_conn_req);\n\n\t\t \n\t\twhile (atomic_read(&map->refcount) > 1)\n\t\t\tcpu_relax();\n\n\t\tpvcalls_front_free_map(bedata, map);\n\t} else {\n\t\twake_up(&bedata->inflight_req);\n\t\twake_up(&map->passive.inflight_accept_req);\n\n\t\twhile (atomic_read(&map->refcount) > 1)\n\t\t\tcpu_relax();\n\n\t\tspin_lock(&bedata->socket_lock);\n\t\tlist_del(&map->list);\n\t\tspin_unlock(&bedata->socket_lock);\n\t\tif (READ_ONCE(map->passive.inflight_req_id) != PVCALLS_INVALID_ID &&\n\t\t\tREAD_ONCE(map->passive.inflight_req_id) != 0) {\n\t\t\tpvcalls_front_free_map(bedata,\n\t\t\t\t\t       map->passive.accept_map);\n\t\t}\n\t\tkfree(map);\n\t}\n\tWRITE_ONCE(bedata->rsp[req_id].req_id, PVCALLS_INVALID_ID);\n\n\tpvcalls_exit();\n\treturn 0;\n}\n\nstatic const struct xenbus_device_id pvcalls_front_ids[] = {\n\t{ \"pvcalls\" },\n\t{ \"\" }\n};\n\nstatic void pvcalls_front_remove(struct xenbus_device *dev)\n{\n\tstruct pvcalls_bedata *bedata;\n\tstruct sock_mapping *map = NULL, *n;\n\n\tbedata = dev_get_drvdata(&pvcalls_front_dev->dev);\n\tdev_set_drvdata(&dev->dev, NULL);\n\tpvcalls_front_dev = NULL;\n\tif (bedata->irq >= 0)\n\t\tunbind_from_irqhandler(bedata->irq, dev);\n\n\tlist_for_each_entry_safe(map, n, &bedata->socket_mappings, list) {\n\t\tmap->sock->sk->sk_send_head = NULL;\n\t\tif (map->active_socket) {\n\t\t\tmap->active.ring->in_error = -EBADF;\n\t\t\twake_up_interruptible(&map->active.inflight_conn_req);\n\t\t}\n\t}\n\n\tsmp_mb();\n\twhile (atomic_read(&pvcalls_refcount) > 0)\n\t\tcpu_relax();\n\tlist_for_each_entry_safe(map, n, &bedata->socket_mappings, list) {\n\t\tif (map->active_socket) {\n\t\t\t \n\t\t\tpvcalls_front_free_map(bedata, map);\n\t\t} else {\n\t\t\tlist_del(&map->list);\n\t\t\tkfree(map);\n\t\t}\n\t}\n\tif (bedata->ref != -1)\n\t\tgnttab_end_foreign_access(bedata->ref, NULL);\n\tkfree(bedata->ring.sring);\n\tkfree(bedata);\n\txenbus_switch_state(dev, XenbusStateClosed);\n}\n\nstatic int pvcalls_front_probe(struct xenbus_device *dev,\n\t\t\t  const struct xenbus_device_id *id)\n{\n\tint ret = -ENOMEM, i;\n\tevtchn_port_t evtchn;\n\tunsigned int max_page_order, function_calls, len;\n\tchar *versions;\n\tgrant_ref_t gref_head = 0;\n\tstruct xenbus_transaction xbt;\n\tstruct pvcalls_bedata *bedata = NULL;\n\tstruct xen_pvcalls_sring *sring;\n\n\tif (pvcalls_front_dev != NULL) {\n\t\tdev_err(&dev->dev, \"only one PV Calls connection supported\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tversions = xenbus_read(XBT_NIL, dev->otherend, \"versions\", &len);\n\tif (IS_ERR(versions))\n\t\treturn PTR_ERR(versions);\n\tif (!len)\n\t\treturn -EINVAL;\n\tif (strcmp(versions, \"1\")) {\n\t\tkfree(versions);\n\t\treturn -EINVAL;\n\t}\n\tkfree(versions);\n\tmax_page_order = xenbus_read_unsigned(dev->otherend,\n\t\t\t\t\t      \"max-page-order\", 0);\n\tif (max_page_order < PVCALLS_RING_ORDER)\n\t\treturn -ENODEV;\n\tfunction_calls = xenbus_read_unsigned(dev->otherend,\n\t\t\t\t\t      \"function-calls\", 0);\n\t \n\tif (function_calls != 1)\n\t\treturn -ENODEV;\n\tpr_info(\"%s max-page-order is %u\\n\", __func__, max_page_order);\n\n\tbedata = kzalloc(sizeof(struct pvcalls_bedata), GFP_KERNEL);\n\tif (!bedata)\n\t\treturn -ENOMEM;\n\n\tdev_set_drvdata(&dev->dev, bedata);\n\tpvcalls_front_dev = dev;\n\tinit_waitqueue_head(&bedata->inflight_req);\n\tINIT_LIST_HEAD(&bedata->socket_mappings);\n\tspin_lock_init(&bedata->socket_lock);\n\tbedata->irq = -1;\n\tbedata->ref = -1;\n\n\tfor (i = 0; i < PVCALLS_NR_RSP_PER_RING; i++)\n\t\tbedata->rsp[i].req_id = PVCALLS_INVALID_ID;\n\n\tsring = (struct xen_pvcalls_sring *) __get_free_page(GFP_KERNEL |\n\t\t\t\t\t\t\t     __GFP_ZERO);\n\tif (!sring)\n\t\tgoto error;\n\tSHARED_RING_INIT(sring);\n\tFRONT_RING_INIT(&bedata->ring, sring, XEN_PAGE_SIZE);\n\n\tret = xenbus_alloc_evtchn(dev, &evtchn);\n\tif (ret)\n\t\tgoto error;\n\n\tbedata->irq = bind_evtchn_to_irqhandler(evtchn,\n\t\t\t\t\t\tpvcalls_front_event_handler,\n\t\t\t\t\t\t0, \"pvcalls-frontend\", dev);\n\tif (bedata->irq < 0) {\n\t\tret = bedata->irq;\n\t\tgoto error;\n\t}\n\n\tret = gnttab_alloc_grant_references(1, &gref_head);\n\tif (ret < 0)\n\t\tgoto error;\n\tret = gnttab_claim_grant_reference(&gref_head);\n\tif (ret < 0)\n\t\tgoto error;\n\tbedata->ref = ret;\n\tgnttab_grant_foreign_access_ref(bedata->ref, dev->otherend_id,\n\t\t\t\t\tvirt_to_gfn((void *)sring), 0);\n\n again:\n\tret = xenbus_transaction_start(&xbt);\n\tif (ret) {\n\t\txenbus_dev_fatal(dev, ret, \"starting transaction\");\n\t\tgoto error;\n\t}\n\tret = xenbus_printf(xbt, dev->nodename, \"version\", \"%u\", 1);\n\tif (ret)\n\t\tgoto error_xenbus;\n\tret = xenbus_printf(xbt, dev->nodename, \"ring-ref\", \"%d\", bedata->ref);\n\tif (ret)\n\t\tgoto error_xenbus;\n\tret = xenbus_printf(xbt, dev->nodename, \"port\", \"%u\",\n\t\t\t    evtchn);\n\tif (ret)\n\t\tgoto error_xenbus;\n\tret = xenbus_transaction_end(xbt, 0);\n\tif (ret) {\n\t\tif (ret == -EAGAIN)\n\t\t\tgoto again;\n\t\txenbus_dev_fatal(dev, ret, \"completing transaction\");\n\t\tgoto error;\n\t}\n\txenbus_switch_state(dev, XenbusStateInitialised);\n\n\treturn 0;\n\n error_xenbus:\n\txenbus_transaction_end(xbt, 1);\n\txenbus_dev_fatal(dev, ret, \"writing xenstore\");\n error:\n\tpvcalls_front_remove(dev);\n\treturn ret;\n}\n\nstatic void pvcalls_front_changed(struct xenbus_device *dev,\n\t\t\t    enum xenbus_state backend_state)\n{\n\tswitch (backend_state) {\n\tcase XenbusStateReconfiguring:\n\tcase XenbusStateReconfigured:\n\tcase XenbusStateInitialising:\n\tcase XenbusStateInitialised:\n\tcase XenbusStateUnknown:\n\t\tbreak;\n\n\tcase XenbusStateInitWait:\n\t\tbreak;\n\n\tcase XenbusStateConnected:\n\t\txenbus_switch_state(dev, XenbusStateConnected);\n\t\tbreak;\n\n\tcase XenbusStateClosed:\n\t\tif (dev->state == XenbusStateClosed)\n\t\t\tbreak;\n\t\t \n\t\tfallthrough;\n\tcase XenbusStateClosing:\n\t\txenbus_frontend_closed(dev);\n\t\tbreak;\n\t}\n}\n\nstatic struct xenbus_driver pvcalls_front_driver = {\n\t.ids = pvcalls_front_ids,\n\t.probe = pvcalls_front_probe,\n\t.remove = pvcalls_front_remove,\n\t.otherend_changed = pvcalls_front_changed,\n\t.not_essential = true,\n};\n\nstatic int __init pvcalls_frontend_init(void)\n{\n\tif (!xen_domain())\n\t\treturn -ENODEV;\n\n\tpr_info(\"Initialising Xen pvcalls frontend driver\\n\");\n\n\treturn xenbus_register_frontend(&pvcalls_front_driver);\n}\n\nmodule_init(pvcalls_frontend_init);\n\nMODULE_DESCRIPTION(\"Xen PV Calls frontend driver\");\nMODULE_AUTHOR(\"Stefano Stabellini <sstabellini@kernel.org>\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}