{
  "module_name": "pvcalls-back.c",
  "hash_id": "0ce68db1cc3e8cbc45a6acf88344769556e0addaa73dc87a38fe9ca226850269",
  "original_prompt": "Ingested from linux-6.6.14/drivers/xen/pvcalls-back.c",
  "human_readable_source": "\n \n\n#include <linux/inet.h>\n#include <linux/kthread.h>\n#include <linux/list.h>\n#include <linux/radix-tree.h>\n#include <linux/module.h>\n#include <linux/semaphore.h>\n#include <linux/wait.h>\n#include <net/sock.h>\n#include <net/inet_common.h>\n#include <net/inet_connection_sock.h>\n#include <net/request_sock.h>\n#include <trace/events/sock.h>\n\n#include <xen/events.h>\n#include <xen/grant_table.h>\n#include <xen/xen.h>\n#include <xen/xenbus.h>\n#include <xen/interface/io/pvcalls.h>\n\n#define PVCALLS_VERSIONS \"1\"\n#define MAX_RING_ORDER XENBUS_MAX_RING_GRANT_ORDER\n\nstatic struct pvcalls_back_global {\n\tstruct list_head frontends;\n\tstruct semaphore frontends_lock;\n} pvcalls_back_global;\n\n \nstruct pvcalls_fedata {\n\tstruct list_head list;\n\tstruct xenbus_device *dev;\n\tstruct xen_pvcalls_sring *sring;\n\tstruct xen_pvcalls_back_ring ring;\n\tint irq;\n\tstruct list_head socket_mappings;\n\tstruct radix_tree_root socketpass_mappings;\n\tstruct semaphore socket_lock;\n};\n\nstruct pvcalls_ioworker {\n\tstruct work_struct register_work;\n\tstruct workqueue_struct *wq;\n};\n\nstruct sock_mapping {\n\tstruct list_head list;\n\tstruct pvcalls_fedata *fedata;\n\tstruct sockpass_mapping *sockpass;\n\tstruct socket *sock;\n\tuint64_t id;\n\tgrant_ref_t ref;\n\tstruct pvcalls_data_intf *ring;\n\tvoid *bytes;\n\tstruct pvcalls_data data;\n\tuint32_t ring_order;\n\tint irq;\n\tatomic_t read;\n\tatomic_t write;\n\tatomic_t io;\n\tatomic_t release;\n\tatomic_t eoi;\n\tvoid (*saved_data_ready)(struct sock *sk);\n\tstruct pvcalls_ioworker ioworker;\n};\n\nstruct sockpass_mapping {\n\tstruct list_head list;\n\tstruct pvcalls_fedata *fedata;\n\tstruct socket *sock;\n\tuint64_t id;\n\tstruct xen_pvcalls_request reqcopy;\n\tspinlock_t copy_lock;\n\tstruct workqueue_struct *wq;\n\tstruct work_struct register_work;\n\tvoid (*saved_data_ready)(struct sock *sk);\n};\n\nstatic irqreturn_t pvcalls_back_conn_event(int irq, void *sock_map);\nstatic int pvcalls_back_release_active(struct xenbus_device *dev,\n\t\t\t\t       struct pvcalls_fedata *fedata,\n\t\t\t\t       struct sock_mapping *map);\n\nstatic bool pvcalls_conn_back_read(void *opaque)\n{\n\tstruct sock_mapping *map = (struct sock_mapping *)opaque;\n\tstruct msghdr msg;\n\tstruct kvec vec[2];\n\tRING_IDX cons, prod, size, wanted, array_size, masked_prod, masked_cons;\n\tint32_t error;\n\tstruct pvcalls_data_intf *intf = map->ring;\n\tstruct pvcalls_data *data = &map->data;\n\tunsigned long flags;\n\tint ret;\n\n\tarray_size = XEN_FLEX_RING_SIZE(map->ring_order);\n\tcons = intf->in_cons;\n\tprod = intf->in_prod;\n\terror = intf->in_error;\n\t \n\tvirt_mb();\n\n\tif (error)\n\t\treturn false;\n\n\tsize = pvcalls_queued(prod, cons, array_size);\n\tif (size >= array_size)\n\t\treturn false;\n\tspin_lock_irqsave(&map->sock->sk->sk_receive_queue.lock, flags);\n\tif (skb_queue_empty(&map->sock->sk->sk_receive_queue)) {\n\t\tatomic_set(&map->read, 0);\n\t\tspin_unlock_irqrestore(&map->sock->sk->sk_receive_queue.lock,\n\t\t\t\tflags);\n\t\treturn true;\n\t}\n\tspin_unlock_irqrestore(&map->sock->sk->sk_receive_queue.lock, flags);\n\twanted = array_size - size;\n\tmasked_prod = pvcalls_mask(prod, array_size);\n\tmasked_cons = pvcalls_mask(cons, array_size);\n\n\tmemset(&msg, 0, sizeof(msg));\n\tif (masked_prod < masked_cons) {\n\t\tvec[0].iov_base = data->in + masked_prod;\n\t\tvec[0].iov_len = wanted;\n\t\tiov_iter_kvec(&msg.msg_iter, ITER_DEST, vec, 1, wanted);\n\t} else {\n\t\tvec[0].iov_base = data->in + masked_prod;\n\t\tvec[0].iov_len = array_size - masked_prod;\n\t\tvec[1].iov_base = data->in;\n\t\tvec[1].iov_len = wanted - vec[0].iov_len;\n\t\tiov_iter_kvec(&msg.msg_iter, ITER_DEST, vec, 2, wanted);\n\t}\n\n\tatomic_set(&map->read, 0);\n\tret = inet_recvmsg(map->sock, &msg, wanted, MSG_DONTWAIT);\n\tWARN_ON(ret > wanted);\n\tif (ret == -EAGAIN)  \n\t\treturn true;\n\tif (!ret)\n\t\tret = -ENOTCONN;\n\tspin_lock_irqsave(&map->sock->sk->sk_receive_queue.lock, flags);\n\tif (ret > 0 && !skb_queue_empty(&map->sock->sk->sk_receive_queue))\n\t\tatomic_inc(&map->read);\n\tspin_unlock_irqrestore(&map->sock->sk->sk_receive_queue.lock, flags);\n\n\t \n\tvirt_wmb();\n\tif (ret < 0) {\n\t\tatomic_set(&map->read, 0);\n\t\tintf->in_error = ret;\n\t} else\n\t\tintf->in_prod = prod + ret;\n\t \n\tvirt_wmb();\n\tnotify_remote_via_irq(map->irq);\n\n\treturn true;\n}\n\nstatic bool pvcalls_conn_back_write(struct sock_mapping *map)\n{\n\tstruct pvcalls_data_intf *intf = map->ring;\n\tstruct pvcalls_data *data = &map->data;\n\tstruct msghdr msg;\n\tstruct kvec vec[2];\n\tRING_IDX cons, prod, size, array_size;\n\tint ret;\n\n\tatomic_set(&map->write, 0);\n\n\tcons = intf->out_cons;\n\tprod = intf->out_prod;\n\t \n\tvirt_mb();\n\n\tarray_size = XEN_FLEX_RING_SIZE(map->ring_order);\n\tsize = pvcalls_queued(prod, cons, array_size);\n\tif (size == 0)\n\t\treturn false;\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.msg_flags |= MSG_DONTWAIT;\n\tif (pvcalls_mask(prod, array_size) > pvcalls_mask(cons, array_size)) {\n\t\tvec[0].iov_base = data->out + pvcalls_mask(cons, array_size);\n\t\tvec[0].iov_len = size;\n\t\tiov_iter_kvec(&msg.msg_iter, ITER_SOURCE, vec, 1, size);\n\t} else {\n\t\tvec[0].iov_base = data->out + pvcalls_mask(cons, array_size);\n\t\tvec[0].iov_len = array_size - pvcalls_mask(cons, array_size);\n\t\tvec[1].iov_base = data->out;\n\t\tvec[1].iov_len = size - vec[0].iov_len;\n\t\tiov_iter_kvec(&msg.msg_iter, ITER_SOURCE, vec, 2, size);\n\t}\n\n\tret = inet_sendmsg(map->sock, &msg, size);\n\tif (ret == -EAGAIN) {\n\t\tatomic_inc(&map->write);\n\t\tatomic_inc(&map->io);\n\t\treturn true;\n\t}\n\n\t \n\tvirt_wmb();\n\tif (ret < 0) {\n\t\tintf->out_error = ret;\n\t} else {\n\t\tintf->out_error = 0;\n\t\tintf->out_cons = cons + ret;\n\t\tprod = intf->out_prod;\n\t}\n\t \n\tvirt_wmb();\n\tif (prod != cons + ret) {\n\t\tatomic_inc(&map->write);\n\t\tatomic_inc(&map->io);\n\t}\n\tnotify_remote_via_irq(map->irq);\n\n\treturn true;\n}\n\nstatic void pvcalls_back_ioworker(struct work_struct *work)\n{\n\tstruct pvcalls_ioworker *ioworker = container_of(work,\n\t\tstruct pvcalls_ioworker, register_work);\n\tstruct sock_mapping *map = container_of(ioworker, struct sock_mapping,\n\t\tioworker);\n\tunsigned int eoi_flags = XEN_EOI_FLAG_SPURIOUS;\n\n\twhile (atomic_read(&map->io) > 0) {\n\t\tif (atomic_read(&map->release) > 0) {\n\t\t\tatomic_set(&map->release, 0);\n\t\t\treturn;\n\t\t}\n\n\t\tif (atomic_read(&map->read) > 0 &&\n\t\t    pvcalls_conn_back_read(map))\n\t\t\teoi_flags = 0;\n\t\tif (atomic_read(&map->write) > 0 &&\n\t\t    pvcalls_conn_back_write(map))\n\t\t\teoi_flags = 0;\n\n\t\tif (atomic_read(&map->eoi) > 0 && !atomic_read(&map->write)) {\n\t\t\tatomic_set(&map->eoi, 0);\n\t\t\txen_irq_lateeoi(map->irq, eoi_flags);\n\t\t\teoi_flags = XEN_EOI_FLAG_SPURIOUS;\n\t\t}\n\n\t\tatomic_dec(&map->io);\n\t}\n}\n\nstatic int pvcalls_back_socket(struct xenbus_device *dev,\n\t\tstruct xen_pvcalls_request *req)\n{\n\tstruct pvcalls_fedata *fedata;\n\tint ret;\n\tstruct xen_pvcalls_response *rsp;\n\n\tfedata = dev_get_drvdata(&dev->dev);\n\n\tif (req->u.socket.domain != AF_INET ||\n\t    req->u.socket.type != SOCK_STREAM ||\n\t    (req->u.socket.protocol != IPPROTO_IP &&\n\t     req->u.socket.protocol != AF_INET))\n\t\tret = -EAFNOSUPPORT;\n\telse\n\t\tret = 0;\n\n\t \n\n\trsp = RING_GET_RESPONSE(&fedata->ring, fedata->ring.rsp_prod_pvt++);\n\trsp->req_id = req->req_id;\n\trsp->cmd = req->cmd;\n\trsp->u.socket.id = req->u.socket.id;\n\trsp->ret = ret;\n\n\treturn 0;\n}\n\nstatic void pvcalls_sk_state_change(struct sock *sock)\n{\n\tstruct sock_mapping *map = sock->sk_user_data;\n\n\tif (map == NULL)\n\t\treturn;\n\n\tatomic_inc(&map->read);\n\tnotify_remote_via_irq(map->irq);\n}\n\nstatic void pvcalls_sk_data_ready(struct sock *sock)\n{\n\tstruct sock_mapping *map = sock->sk_user_data;\n\tstruct pvcalls_ioworker *iow;\n\n\ttrace_sk_data_ready(sock);\n\n\tif (map == NULL)\n\t\treturn;\n\n\tiow = &map->ioworker;\n\tatomic_inc(&map->read);\n\tatomic_inc(&map->io);\n\tqueue_work(iow->wq, &iow->register_work);\n}\n\nstatic struct sock_mapping *pvcalls_new_active_socket(\n\t\tstruct pvcalls_fedata *fedata,\n\t\tuint64_t id,\n\t\tgrant_ref_t ref,\n\t\tevtchn_port_t evtchn,\n\t\tstruct socket *sock)\n{\n\tint ret;\n\tstruct sock_mapping *map;\n\tvoid *page;\n\n\tmap = kzalloc(sizeof(*map), GFP_KERNEL);\n\tif (map == NULL) {\n\t\tsock_release(sock);\n\t\treturn NULL;\n\t}\n\n\tmap->fedata = fedata;\n\tmap->sock = sock;\n\tmap->id = id;\n\tmap->ref = ref;\n\n\tret = xenbus_map_ring_valloc(fedata->dev, &ref, 1, &page);\n\tif (ret < 0)\n\t\tgoto out;\n\tmap->ring = page;\n\tmap->ring_order = map->ring->ring_order;\n\t \n\tvirt_rmb();\n\tif (map->ring_order > MAX_RING_ORDER) {\n\t\tpr_warn(\"%s frontend requested ring_order %u, which is > MAX (%u)\\n\",\n\t\t\t\t__func__, map->ring_order, MAX_RING_ORDER);\n\t\tgoto out;\n\t}\n\tret = xenbus_map_ring_valloc(fedata->dev, map->ring->ref,\n\t\t\t\t     (1 << map->ring_order), &page);\n\tif (ret < 0)\n\t\tgoto out;\n\tmap->bytes = page;\n\n\tret = bind_interdomain_evtchn_to_irqhandler_lateeoi(\n\t\t\tfedata->dev, evtchn,\n\t\t\tpvcalls_back_conn_event, 0, \"pvcalls-backend\", map);\n\tif (ret < 0)\n\t\tgoto out;\n\tmap->irq = ret;\n\n\tmap->data.in = map->bytes;\n\tmap->data.out = map->bytes + XEN_FLEX_RING_SIZE(map->ring_order);\n\n\tmap->ioworker.wq = alloc_ordered_workqueue(\"pvcalls_io\", 0);\n\tif (!map->ioworker.wq)\n\t\tgoto out;\n\tatomic_set(&map->io, 1);\n\tINIT_WORK(&map->ioworker.register_work,\tpvcalls_back_ioworker);\n\n\tdown(&fedata->socket_lock);\n\tlist_add_tail(&map->list, &fedata->socket_mappings);\n\tup(&fedata->socket_lock);\n\n\twrite_lock_bh(&map->sock->sk->sk_callback_lock);\n\tmap->saved_data_ready = map->sock->sk->sk_data_ready;\n\tmap->sock->sk->sk_user_data = map;\n\tmap->sock->sk->sk_data_ready = pvcalls_sk_data_ready;\n\tmap->sock->sk->sk_state_change = pvcalls_sk_state_change;\n\twrite_unlock_bh(&map->sock->sk->sk_callback_lock);\n\n\treturn map;\nout:\n\tdown(&fedata->socket_lock);\n\tlist_del(&map->list);\n\tpvcalls_back_release_active(fedata->dev, fedata, map);\n\tup(&fedata->socket_lock);\n\treturn NULL;\n}\n\nstatic int pvcalls_back_connect(struct xenbus_device *dev,\n\t\t\t\tstruct xen_pvcalls_request *req)\n{\n\tstruct pvcalls_fedata *fedata;\n\tint ret = -EINVAL;\n\tstruct socket *sock;\n\tstruct sock_mapping *map;\n\tstruct xen_pvcalls_response *rsp;\n\tstruct sockaddr *sa = (struct sockaddr *)&req->u.connect.addr;\n\n\tfedata = dev_get_drvdata(&dev->dev);\n\n\tif (req->u.connect.len < sizeof(sa->sa_family) ||\n\t    req->u.connect.len > sizeof(req->u.connect.addr) ||\n\t    sa->sa_family != AF_INET)\n\t\tgoto out;\n\n\tret = sock_create(AF_INET, SOCK_STREAM, 0, &sock);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = inet_stream_connect(sock, sa, req->u.connect.len, 0);\n\tif (ret < 0) {\n\t\tsock_release(sock);\n\t\tgoto out;\n\t}\n\n\tmap = pvcalls_new_active_socket(fedata,\n\t\t\t\t\treq->u.connect.id,\n\t\t\t\t\treq->u.connect.ref,\n\t\t\t\t\treq->u.connect.evtchn,\n\t\t\t\t\tsock);\n\tif (!map)\n\t\tret = -EFAULT;\n\nout:\n\trsp = RING_GET_RESPONSE(&fedata->ring, fedata->ring.rsp_prod_pvt++);\n\trsp->req_id = req->req_id;\n\trsp->cmd = req->cmd;\n\trsp->u.connect.id = req->u.connect.id;\n\trsp->ret = ret;\n\n\treturn 0;\n}\n\nstatic int pvcalls_back_release_active(struct xenbus_device *dev,\n\t\t\t\t       struct pvcalls_fedata *fedata,\n\t\t\t\t       struct sock_mapping *map)\n{\n\tdisable_irq(map->irq);\n\tif (map->sock->sk != NULL) {\n\t\twrite_lock_bh(&map->sock->sk->sk_callback_lock);\n\t\tmap->sock->sk->sk_user_data = NULL;\n\t\tmap->sock->sk->sk_data_ready = map->saved_data_ready;\n\t\twrite_unlock_bh(&map->sock->sk->sk_callback_lock);\n\t}\n\n\tatomic_set(&map->release, 1);\n\tflush_work(&map->ioworker.register_work);\n\n\txenbus_unmap_ring_vfree(dev, map->bytes);\n\txenbus_unmap_ring_vfree(dev, (void *)map->ring);\n\tunbind_from_irqhandler(map->irq, map);\n\n\tsock_release(map->sock);\n\tkfree(map);\n\n\treturn 0;\n}\n\nstatic int pvcalls_back_release_passive(struct xenbus_device *dev,\n\t\t\t\t\tstruct pvcalls_fedata *fedata,\n\t\t\t\t\tstruct sockpass_mapping *mappass)\n{\n\tif (mappass->sock->sk != NULL) {\n\t\twrite_lock_bh(&mappass->sock->sk->sk_callback_lock);\n\t\tmappass->sock->sk->sk_user_data = NULL;\n\t\tmappass->sock->sk->sk_data_ready = mappass->saved_data_ready;\n\t\twrite_unlock_bh(&mappass->sock->sk->sk_callback_lock);\n\t}\n\tsock_release(mappass->sock);\n\tdestroy_workqueue(mappass->wq);\n\tkfree(mappass);\n\n\treturn 0;\n}\n\nstatic int pvcalls_back_release(struct xenbus_device *dev,\n\t\t\t\tstruct xen_pvcalls_request *req)\n{\n\tstruct pvcalls_fedata *fedata;\n\tstruct sock_mapping *map, *n;\n\tstruct sockpass_mapping *mappass;\n\tint ret = 0;\n\tstruct xen_pvcalls_response *rsp;\n\n\tfedata = dev_get_drvdata(&dev->dev);\n\n\tdown(&fedata->socket_lock);\n\tlist_for_each_entry_safe(map, n, &fedata->socket_mappings, list) {\n\t\tif (map->id == req->u.release.id) {\n\t\t\tlist_del(&map->list);\n\t\t\tup(&fedata->socket_lock);\n\t\t\tret = pvcalls_back_release_active(dev, fedata, map);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tmappass = radix_tree_lookup(&fedata->socketpass_mappings,\n\t\t\t\t    req->u.release.id);\n\tif (mappass != NULL) {\n\t\tradix_tree_delete(&fedata->socketpass_mappings, mappass->id);\n\t\tup(&fedata->socket_lock);\n\t\tret = pvcalls_back_release_passive(dev, fedata, mappass);\n\t} else\n\t\tup(&fedata->socket_lock);\n\nout:\n\trsp = RING_GET_RESPONSE(&fedata->ring, fedata->ring.rsp_prod_pvt++);\n\trsp->req_id = req->req_id;\n\trsp->u.release.id = req->u.release.id;\n\trsp->cmd = req->cmd;\n\trsp->ret = ret;\n\treturn 0;\n}\n\nstatic void __pvcalls_back_accept(struct work_struct *work)\n{\n\tstruct sockpass_mapping *mappass = container_of(\n\t\twork, struct sockpass_mapping, register_work);\n\tstruct sock_mapping *map;\n\tstruct pvcalls_ioworker *iow;\n\tstruct pvcalls_fedata *fedata;\n\tstruct socket *sock;\n\tstruct xen_pvcalls_response *rsp;\n\tstruct xen_pvcalls_request *req;\n\tint notify;\n\tint ret = -EINVAL;\n\tunsigned long flags;\n\n\tfedata = mappass->fedata;\n\t \n\tspin_lock_irqsave(&mappass->copy_lock, flags);\n\treq = &mappass->reqcopy;\n\tif (req->cmd != PVCALLS_ACCEPT) {\n\t\tspin_unlock_irqrestore(&mappass->copy_lock, flags);\n\t\treturn;\n\t}\n\tspin_unlock_irqrestore(&mappass->copy_lock, flags);\n\n\tsock = sock_alloc();\n\tif (sock == NULL)\n\t\tgoto out_error;\n\tsock->type = mappass->sock->type;\n\tsock->ops = mappass->sock->ops;\n\n\tret = inet_accept(mappass->sock, sock, O_NONBLOCK, true);\n\tif (ret == -EAGAIN) {\n\t\tsock_release(sock);\n\t\treturn;\n\t}\n\n\tmap = pvcalls_new_active_socket(fedata,\n\t\t\t\t\treq->u.accept.id_new,\n\t\t\t\t\treq->u.accept.ref,\n\t\t\t\t\treq->u.accept.evtchn,\n\t\t\t\t\tsock);\n\tif (!map) {\n\t\tret = -EFAULT;\n\t\tgoto out_error;\n\t}\n\n\tmap->sockpass = mappass;\n\tiow = &map->ioworker;\n\tatomic_inc(&map->read);\n\tatomic_inc(&map->io);\n\tqueue_work(iow->wq, &iow->register_work);\n\nout_error:\n\trsp = RING_GET_RESPONSE(&fedata->ring, fedata->ring.rsp_prod_pvt++);\n\trsp->req_id = req->req_id;\n\trsp->cmd = req->cmd;\n\trsp->u.accept.id = req->u.accept.id;\n\trsp->ret = ret;\n\tRING_PUSH_RESPONSES_AND_CHECK_NOTIFY(&fedata->ring, notify);\n\tif (notify)\n\t\tnotify_remote_via_irq(fedata->irq);\n\n\tmappass->reqcopy.cmd = 0;\n}\n\nstatic void pvcalls_pass_sk_data_ready(struct sock *sock)\n{\n\tstruct sockpass_mapping *mappass = sock->sk_user_data;\n\tstruct pvcalls_fedata *fedata;\n\tstruct xen_pvcalls_response *rsp;\n\tunsigned long flags;\n\tint notify;\n\n\ttrace_sk_data_ready(sock);\n\n\tif (mappass == NULL)\n\t\treturn;\n\n\tfedata = mappass->fedata;\n\tspin_lock_irqsave(&mappass->copy_lock, flags);\n\tif (mappass->reqcopy.cmd == PVCALLS_POLL) {\n\t\trsp = RING_GET_RESPONSE(&fedata->ring,\n\t\t\t\t\tfedata->ring.rsp_prod_pvt++);\n\t\trsp->req_id = mappass->reqcopy.req_id;\n\t\trsp->u.poll.id = mappass->reqcopy.u.poll.id;\n\t\trsp->cmd = mappass->reqcopy.cmd;\n\t\trsp->ret = 0;\n\n\t\tmappass->reqcopy.cmd = 0;\n\t\tspin_unlock_irqrestore(&mappass->copy_lock, flags);\n\n\t\tRING_PUSH_RESPONSES_AND_CHECK_NOTIFY(&fedata->ring, notify);\n\t\tif (notify)\n\t\t\tnotify_remote_via_irq(mappass->fedata->irq);\n\t} else {\n\t\tspin_unlock_irqrestore(&mappass->copy_lock, flags);\n\t\tqueue_work(mappass->wq, &mappass->register_work);\n\t}\n}\n\nstatic int pvcalls_back_bind(struct xenbus_device *dev,\n\t\t\t     struct xen_pvcalls_request *req)\n{\n\tstruct pvcalls_fedata *fedata;\n\tint ret;\n\tstruct sockpass_mapping *map;\n\tstruct xen_pvcalls_response *rsp;\n\n\tfedata = dev_get_drvdata(&dev->dev);\n\n\tmap = kzalloc(sizeof(*map), GFP_KERNEL);\n\tif (map == NULL) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tINIT_WORK(&map->register_work, __pvcalls_back_accept);\n\tspin_lock_init(&map->copy_lock);\n\tmap->wq = alloc_ordered_workqueue(\"pvcalls_wq\", 0);\n\tif (!map->wq) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tret = sock_create(AF_INET, SOCK_STREAM, 0, &map->sock);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = inet_bind(map->sock, (struct sockaddr *)&req->u.bind.addr,\n\t\t\treq->u.bind.len);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tmap->fedata = fedata;\n\tmap->id = req->u.bind.id;\n\n\tdown(&fedata->socket_lock);\n\tret = radix_tree_insert(&fedata->socketpass_mappings, map->id,\n\t\t\t\tmap);\n\tup(&fedata->socket_lock);\n\tif (ret)\n\t\tgoto out;\n\n\twrite_lock_bh(&map->sock->sk->sk_callback_lock);\n\tmap->saved_data_ready = map->sock->sk->sk_data_ready;\n\tmap->sock->sk->sk_user_data = map;\n\tmap->sock->sk->sk_data_ready = pvcalls_pass_sk_data_ready;\n\twrite_unlock_bh(&map->sock->sk->sk_callback_lock);\n\nout:\n\tif (ret) {\n\t\tif (map && map->sock)\n\t\t\tsock_release(map->sock);\n\t\tif (map && map->wq)\n\t\t\tdestroy_workqueue(map->wq);\n\t\tkfree(map);\n\t}\n\trsp = RING_GET_RESPONSE(&fedata->ring, fedata->ring.rsp_prod_pvt++);\n\trsp->req_id = req->req_id;\n\trsp->cmd = req->cmd;\n\trsp->u.bind.id = req->u.bind.id;\n\trsp->ret = ret;\n\treturn 0;\n}\n\nstatic int pvcalls_back_listen(struct xenbus_device *dev,\n\t\t\t       struct xen_pvcalls_request *req)\n{\n\tstruct pvcalls_fedata *fedata;\n\tint ret = -EINVAL;\n\tstruct sockpass_mapping *map;\n\tstruct xen_pvcalls_response *rsp;\n\n\tfedata = dev_get_drvdata(&dev->dev);\n\n\tdown(&fedata->socket_lock);\n\tmap = radix_tree_lookup(&fedata->socketpass_mappings, req->u.listen.id);\n\tup(&fedata->socket_lock);\n\tif (map == NULL)\n\t\tgoto out;\n\n\tret = inet_listen(map->sock, req->u.listen.backlog);\n\nout:\n\trsp = RING_GET_RESPONSE(&fedata->ring, fedata->ring.rsp_prod_pvt++);\n\trsp->req_id = req->req_id;\n\trsp->cmd = req->cmd;\n\trsp->u.listen.id = req->u.listen.id;\n\trsp->ret = ret;\n\treturn 0;\n}\n\nstatic int pvcalls_back_accept(struct xenbus_device *dev,\n\t\t\t       struct xen_pvcalls_request *req)\n{\n\tstruct pvcalls_fedata *fedata;\n\tstruct sockpass_mapping *mappass;\n\tint ret = -EINVAL;\n\tstruct xen_pvcalls_response *rsp;\n\tunsigned long flags;\n\n\tfedata = dev_get_drvdata(&dev->dev);\n\n\tdown(&fedata->socket_lock);\n\tmappass = radix_tree_lookup(&fedata->socketpass_mappings,\n\t\treq->u.accept.id);\n\tup(&fedata->socket_lock);\n\tif (mappass == NULL)\n\t\tgoto out_error;\n\n\t \n\tspin_lock_irqsave(&mappass->copy_lock, flags);\n\tif (mappass->reqcopy.cmd != 0) {\n\t\tspin_unlock_irqrestore(&mappass->copy_lock, flags);\n\t\tret = -EINTR;\n\t\tgoto out_error;\n\t}\n\n\tmappass->reqcopy = *req;\n\tspin_unlock_irqrestore(&mappass->copy_lock, flags);\n\tqueue_work(mappass->wq, &mappass->register_work);\n\n\t \n\treturn -1;\n\nout_error:\n\trsp = RING_GET_RESPONSE(&fedata->ring, fedata->ring.rsp_prod_pvt++);\n\trsp->req_id = req->req_id;\n\trsp->cmd = req->cmd;\n\trsp->u.accept.id = req->u.accept.id;\n\trsp->ret = ret;\n\treturn 0;\n}\n\nstatic int pvcalls_back_poll(struct xenbus_device *dev,\n\t\t\t     struct xen_pvcalls_request *req)\n{\n\tstruct pvcalls_fedata *fedata;\n\tstruct sockpass_mapping *mappass;\n\tstruct xen_pvcalls_response *rsp;\n\tstruct inet_connection_sock *icsk;\n\tstruct request_sock_queue *queue;\n\tunsigned long flags;\n\tint ret;\n\tbool data;\n\n\tfedata = dev_get_drvdata(&dev->dev);\n\n\tdown(&fedata->socket_lock);\n\tmappass = radix_tree_lookup(&fedata->socketpass_mappings,\n\t\t\t\t    req->u.poll.id);\n\tup(&fedata->socket_lock);\n\tif (mappass == NULL)\n\t\treturn -EINVAL;\n\n\t \n\tspin_lock_irqsave(&mappass->copy_lock, flags);\n\tif (mappass->reqcopy.cmd != 0) {\n\t\tret = -EINTR;\n\t\tgoto out;\n\t}\n\n\tmappass->reqcopy = *req;\n\ticsk = inet_csk(mappass->sock->sk);\n\tqueue = &icsk->icsk_accept_queue;\n\tdata = READ_ONCE(queue->rskq_accept_head) != NULL;\n\tif (data) {\n\t\tmappass->reqcopy.cmd = 0;\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\tspin_unlock_irqrestore(&mappass->copy_lock, flags);\n\n\t \n\treturn -1;\n\nout:\n\tspin_unlock_irqrestore(&mappass->copy_lock, flags);\n\n\trsp = RING_GET_RESPONSE(&fedata->ring, fedata->ring.rsp_prod_pvt++);\n\trsp->req_id = req->req_id;\n\trsp->cmd = req->cmd;\n\trsp->u.poll.id = req->u.poll.id;\n\trsp->ret = ret;\n\treturn 0;\n}\n\nstatic int pvcalls_back_handle_cmd(struct xenbus_device *dev,\n\t\t\t\t   struct xen_pvcalls_request *req)\n{\n\tint ret = 0;\n\n\tswitch (req->cmd) {\n\tcase PVCALLS_SOCKET:\n\t\tret = pvcalls_back_socket(dev, req);\n\t\tbreak;\n\tcase PVCALLS_CONNECT:\n\t\tret = pvcalls_back_connect(dev, req);\n\t\tbreak;\n\tcase PVCALLS_RELEASE:\n\t\tret = pvcalls_back_release(dev, req);\n\t\tbreak;\n\tcase PVCALLS_BIND:\n\t\tret = pvcalls_back_bind(dev, req);\n\t\tbreak;\n\tcase PVCALLS_LISTEN:\n\t\tret = pvcalls_back_listen(dev, req);\n\t\tbreak;\n\tcase PVCALLS_ACCEPT:\n\t\tret = pvcalls_back_accept(dev, req);\n\t\tbreak;\n\tcase PVCALLS_POLL:\n\t\tret = pvcalls_back_poll(dev, req);\n\t\tbreak;\n\tdefault:\n\t{\n\t\tstruct pvcalls_fedata *fedata;\n\t\tstruct xen_pvcalls_response *rsp;\n\n\t\tfedata = dev_get_drvdata(&dev->dev);\n\t\trsp = RING_GET_RESPONSE(\n\t\t\t\t&fedata->ring, fedata->ring.rsp_prod_pvt++);\n\t\trsp->req_id = req->req_id;\n\t\trsp->cmd = req->cmd;\n\t\trsp->ret = -ENOTSUPP;\n\t\tbreak;\n\t}\n\t}\n\treturn ret;\n}\n\nstatic void pvcalls_back_work(struct pvcalls_fedata *fedata)\n{\n\tint notify, notify_all = 0, more = 1;\n\tstruct xen_pvcalls_request req;\n\tstruct xenbus_device *dev = fedata->dev;\n\n\twhile (more) {\n\t\twhile (RING_HAS_UNCONSUMED_REQUESTS(&fedata->ring)) {\n\t\t\tRING_COPY_REQUEST(&fedata->ring,\n\t\t\t\t\t  fedata->ring.req_cons++,\n\t\t\t\t\t  &req);\n\n\t\t\tif (!pvcalls_back_handle_cmd(dev, &req)) {\n\t\t\t\tRING_PUSH_RESPONSES_AND_CHECK_NOTIFY(\n\t\t\t\t\t&fedata->ring, notify);\n\t\t\t\tnotify_all += notify;\n\t\t\t}\n\t\t}\n\n\t\tif (notify_all) {\n\t\t\tnotify_remote_via_irq(fedata->irq);\n\t\t\tnotify_all = 0;\n\t\t}\n\n\t\tRING_FINAL_CHECK_FOR_REQUESTS(&fedata->ring, more);\n\t}\n}\n\nstatic irqreturn_t pvcalls_back_event(int irq, void *dev_id)\n{\n\tstruct xenbus_device *dev = dev_id;\n\tstruct pvcalls_fedata *fedata = NULL;\n\tunsigned int eoi_flags = XEN_EOI_FLAG_SPURIOUS;\n\n\tif (dev) {\n\t\tfedata = dev_get_drvdata(&dev->dev);\n\t\tif (fedata) {\n\t\t\tpvcalls_back_work(fedata);\n\t\t\teoi_flags = 0;\n\t\t}\n\t}\n\n\txen_irq_lateeoi(irq, eoi_flags);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t pvcalls_back_conn_event(int irq, void *sock_map)\n{\n\tstruct sock_mapping *map = sock_map;\n\tstruct pvcalls_ioworker *iow;\n\n\tif (map == NULL || map->sock == NULL || map->sock->sk == NULL ||\n\t\tmap->sock->sk->sk_user_data != map) {\n\t\txen_irq_lateeoi(irq, 0);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tiow = &map->ioworker;\n\n\tatomic_inc(&map->write);\n\tatomic_inc(&map->eoi);\n\tatomic_inc(&map->io);\n\tqueue_work(iow->wq, &iow->register_work);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int backend_connect(struct xenbus_device *dev)\n{\n\tint err;\n\tevtchn_port_t evtchn;\n\tgrant_ref_t ring_ref;\n\tstruct pvcalls_fedata *fedata = NULL;\n\n\tfedata = kzalloc(sizeof(struct pvcalls_fedata), GFP_KERNEL);\n\tif (!fedata)\n\t\treturn -ENOMEM;\n\n\tfedata->irq = -1;\n\terr = xenbus_scanf(XBT_NIL, dev->otherend, \"port\", \"%u\",\n\t\t\t   &evtchn);\n\tif (err != 1) {\n\t\terr = -EINVAL;\n\t\txenbus_dev_fatal(dev, err, \"reading %s/event-channel\",\n\t\t\t\t dev->otherend);\n\t\tgoto error;\n\t}\n\n\terr = xenbus_scanf(XBT_NIL, dev->otherend, \"ring-ref\", \"%u\", &ring_ref);\n\tif (err != 1) {\n\t\terr = -EINVAL;\n\t\txenbus_dev_fatal(dev, err, \"reading %s/ring-ref\",\n\t\t\t\t dev->otherend);\n\t\tgoto error;\n\t}\n\n\terr = bind_interdomain_evtchn_to_irq_lateeoi(dev, evtchn);\n\tif (err < 0)\n\t\tgoto error;\n\tfedata->irq = err;\n\n\terr = request_threaded_irq(fedata->irq, NULL, pvcalls_back_event,\n\t\t\t\t   IRQF_ONESHOT, \"pvcalls-back\", dev);\n\tif (err < 0)\n\t\tgoto error;\n\n\terr = xenbus_map_ring_valloc(dev, &ring_ref, 1,\n\t\t\t\t     (void **)&fedata->sring);\n\tif (err < 0)\n\t\tgoto error;\n\n\tBACK_RING_INIT(&fedata->ring, fedata->sring, XEN_PAGE_SIZE * 1);\n\tfedata->dev = dev;\n\n\tINIT_LIST_HEAD(&fedata->socket_mappings);\n\tINIT_RADIX_TREE(&fedata->socketpass_mappings, GFP_KERNEL);\n\tsema_init(&fedata->socket_lock, 1);\n\tdev_set_drvdata(&dev->dev, fedata);\n\n\tdown(&pvcalls_back_global.frontends_lock);\n\tlist_add_tail(&fedata->list, &pvcalls_back_global.frontends);\n\tup(&pvcalls_back_global.frontends_lock);\n\n\treturn 0;\n\n error:\n\tif (fedata->irq >= 0)\n\t\tunbind_from_irqhandler(fedata->irq, dev);\n\tif (fedata->sring != NULL)\n\t\txenbus_unmap_ring_vfree(dev, fedata->sring);\n\tkfree(fedata);\n\treturn err;\n}\n\nstatic int backend_disconnect(struct xenbus_device *dev)\n{\n\tstruct pvcalls_fedata *fedata;\n\tstruct sock_mapping *map, *n;\n\tstruct sockpass_mapping *mappass;\n\tstruct radix_tree_iter iter;\n\tvoid **slot;\n\n\n\tfedata = dev_get_drvdata(&dev->dev);\n\n\tdown(&fedata->socket_lock);\n\tlist_for_each_entry_safe(map, n, &fedata->socket_mappings, list) {\n\t\tlist_del(&map->list);\n\t\tpvcalls_back_release_active(dev, fedata, map);\n\t}\n\n\tradix_tree_for_each_slot(slot, &fedata->socketpass_mappings, &iter, 0) {\n\t\tmappass = radix_tree_deref_slot(slot);\n\t\tif (!mappass)\n\t\t\tcontinue;\n\t\tif (radix_tree_exception(mappass)) {\n\t\t\tif (radix_tree_deref_retry(mappass))\n\t\t\t\tslot = radix_tree_iter_retry(&iter);\n\t\t} else {\n\t\t\tradix_tree_delete(&fedata->socketpass_mappings,\n\t\t\t\t\t  mappass->id);\n\t\t\tpvcalls_back_release_passive(dev, fedata, mappass);\n\t\t}\n\t}\n\tup(&fedata->socket_lock);\n\n\tunbind_from_irqhandler(fedata->irq, dev);\n\txenbus_unmap_ring_vfree(dev, fedata->sring);\n\n\tlist_del(&fedata->list);\n\tkfree(fedata);\n\tdev_set_drvdata(&dev->dev, NULL);\n\n\treturn 0;\n}\n\nstatic int pvcalls_back_probe(struct xenbus_device *dev,\n\t\t\t      const struct xenbus_device_id *id)\n{\n\tint err, abort;\n\tstruct xenbus_transaction xbt;\n\nagain:\n\tabort = 1;\n\n\terr = xenbus_transaction_start(&xbt);\n\tif (err) {\n\t\tpr_warn(\"%s cannot create xenstore transaction\\n\", __func__);\n\t\treturn err;\n\t}\n\n\terr = xenbus_printf(xbt, dev->nodename, \"versions\", \"%s\",\n\t\t\t    PVCALLS_VERSIONS);\n\tif (err) {\n\t\tpr_warn(\"%s write out 'versions' failed\\n\", __func__);\n\t\tgoto abort;\n\t}\n\n\terr = xenbus_printf(xbt, dev->nodename, \"max-page-order\", \"%u\",\n\t\t\t    MAX_RING_ORDER);\n\tif (err) {\n\t\tpr_warn(\"%s write out 'max-page-order' failed\\n\", __func__);\n\t\tgoto abort;\n\t}\n\n\terr = xenbus_printf(xbt, dev->nodename, \"function-calls\",\n\t\t\t    XENBUS_FUNCTIONS_CALLS);\n\tif (err) {\n\t\tpr_warn(\"%s write out 'function-calls' failed\\n\", __func__);\n\t\tgoto abort;\n\t}\n\n\tabort = 0;\nabort:\n\terr = xenbus_transaction_end(xbt, abort);\n\tif (err) {\n\t\tif (err == -EAGAIN && !abort)\n\t\t\tgoto again;\n\t\tpr_warn(\"%s cannot complete xenstore transaction\\n\", __func__);\n\t\treturn err;\n\t}\n\n\tif (abort)\n\t\treturn -EFAULT;\n\n\txenbus_switch_state(dev, XenbusStateInitWait);\n\n\treturn 0;\n}\n\nstatic void set_backend_state(struct xenbus_device *dev,\n\t\t\t      enum xenbus_state state)\n{\n\twhile (dev->state != state) {\n\t\tswitch (dev->state) {\n\t\tcase XenbusStateClosed:\n\t\t\tswitch (state) {\n\t\t\tcase XenbusStateInitWait:\n\t\t\tcase XenbusStateConnected:\n\t\t\t\txenbus_switch_state(dev, XenbusStateInitWait);\n\t\t\t\tbreak;\n\t\t\tcase XenbusStateClosing:\n\t\t\t\txenbus_switch_state(dev, XenbusStateClosing);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWARN_ON(1);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XenbusStateInitWait:\n\t\tcase XenbusStateInitialised:\n\t\t\tswitch (state) {\n\t\t\tcase XenbusStateConnected:\n\t\t\t\tif (backend_connect(dev))\n\t\t\t\t\treturn;\n\t\t\t\txenbus_switch_state(dev, XenbusStateConnected);\n\t\t\t\tbreak;\n\t\t\tcase XenbusStateClosing:\n\t\t\tcase XenbusStateClosed:\n\t\t\t\txenbus_switch_state(dev, XenbusStateClosing);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWARN_ON(1);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XenbusStateConnected:\n\t\t\tswitch (state) {\n\t\t\tcase XenbusStateInitWait:\n\t\t\tcase XenbusStateClosing:\n\t\t\tcase XenbusStateClosed:\n\t\t\t\tdown(&pvcalls_back_global.frontends_lock);\n\t\t\t\tbackend_disconnect(dev);\n\t\t\t\tup(&pvcalls_back_global.frontends_lock);\n\t\t\t\txenbus_switch_state(dev, XenbusStateClosing);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWARN_ON(1);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XenbusStateClosing:\n\t\t\tswitch (state) {\n\t\t\tcase XenbusStateInitWait:\n\t\t\tcase XenbusStateConnected:\n\t\t\tcase XenbusStateClosed:\n\t\t\t\txenbus_switch_state(dev, XenbusStateClosed);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWARN_ON(1);\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t}\n\t}\n}\n\nstatic void pvcalls_back_changed(struct xenbus_device *dev,\n\t\t\t\t enum xenbus_state frontend_state)\n{\n\tswitch (frontend_state) {\n\tcase XenbusStateInitialising:\n\t\tset_backend_state(dev, XenbusStateInitWait);\n\t\tbreak;\n\n\tcase XenbusStateInitialised:\n\tcase XenbusStateConnected:\n\t\tset_backend_state(dev, XenbusStateConnected);\n\t\tbreak;\n\n\tcase XenbusStateClosing:\n\t\tset_backend_state(dev, XenbusStateClosing);\n\t\tbreak;\n\n\tcase XenbusStateClosed:\n\t\tset_backend_state(dev, XenbusStateClosed);\n\t\tif (xenbus_dev_is_online(dev))\n\t\t\tbreak;\n\t\tdevice_unregister(&dev->dev);\n\t\tbreak;\n\tcase XenbusStateUnknown:\n\t\tset_backend_state(dev, XenbusStateClosed);\n\t\tdevice_unregister(&dev->dev);\n\t\tbreak;\n\n\tdefault:\n\t\txenbus_dev_fatal(dev, -EINVAL, \"saw state %d at frontend\",\n\t\t\t\t frontend_state);\n\t\tbreak;\n\t}\n}\n\nstatic void pvcalls_back_remove(struct xenbus_device *dev)\n{\n}\n\nstatic int pvcalls_back_uevent(const struct xenbus_device *xdev,\n\t\t\t       struct kobj_uevent_env *env)\n{\n\treturn 0;\n}\n\nstatic const struct xenbus_device_id pvcalls_back_ids[] = {\n\t{ \"pvcalls\" },\n\t{ \"\" }\n};\n\nstatic struct xenbus_driver pvcalls_back_driver = {\n\t.ids = pvcalls_back_ids,\n\t.probe = pvcalls_back_probe,\n\t.remove = pvcalls_back_remove,\n\t.uevent = pvcalls_back_uevent,\n\t.otherend_changed = pvcalls_back_changed,\n};\n\nstatic int __init pvcalls_back_init(void)\n{\n\tint ret;\n\n\tif (!xen_domain())\n\t\treturn -ENODEV;\n\n\tret = xenbus_register_backend(&pvcalls_back_driver);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tsema_init(&pvcalls_back_global.frontends_lock, 1);\n\tINIT_LIST_HEAD(&pvcalls_back_global.frontends);\n\treturn 0;\n}\nmodule_init(pvcalls_back_init);\n\nstatic void __exit pvcalls_back_fin(void)\n{\n\tstruct pvcalls_fedata *fedata, *nfedata;\n\n\tdown(&pvcalls_back_global.frontends_lock);\n\tlist_for_each_entry_safe(fedata, nfedata,\n\t\t\t\t &pvcalls_back_global.frontends, list) {\n\t\tbackend_disconnect(fedata->dev);\n\t}\n\tup(&pvcalls_back_global.frontends_lock);\n\n\txenbus_unregister_driver(&pvcalls_back_driver);\n}\n\nmodule_exit(pvcalls_back_fin);\n\nMODULE_DESCRIPTION(\"Xen PV Calls backend driver\");\nMODULE_AUTHOR(\"Stefano Stabellini <sstabellini@kernel.org>\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}