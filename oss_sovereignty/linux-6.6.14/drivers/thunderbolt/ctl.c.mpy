{
  "module_name": "ctl.c",
  "hash_id": "7c25a4057b2b4090aaec368b10336156952fa48e6d6919fd15dcc38af024c7f7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/thunderbolt/ctl.c",
  "human_readable_source": "\n \n\n#include <linux/crc32.h>\n#include <linux/delay.h>\n#include <linux/slab.h>\n#include <linux/pci.h>\n#include <linux/dmapool.h>\n#include <linux/workqueue.h>\n\n#include \"ctl.h\"\n\n\n#define TB_CTL_RX_PKG_COUNT\t10\n#define TB_CTL_RETRIES\t\t4\n\n \nstruct tb_ctl {\n\tstruct tb_nhi *nhi;\n\tstruct tb_ring *tx;\n\tstruct tb_ring *rx;\n\n\tstruct dma_pool *frame_pool;\n\tstruct ctl_pkg *rx_packets[TB_CTL_RX_PKG_COUNT];\n\tstruct mutex request_queue_lock;\n\tstruct list_head request_queue;\n\tbool running;\n\n\tint timeout_msec;\n\tevent_cb callback;\n\tvoid *callback_data;\n};\n\n\n#define tb_ctl_WARN(ctl, format, arg...) \\\n\tdev_WARN(&(ctl)->nhi->pdev->dev, format, ## arg)\n\n#define tb_ctl_err(ctl, format, arg...) \\\n\tdev_err(&(ctl)->nhi->pdev->dev, format, ## arg)\n\n#define tb_ctl_warn(ctl, format, arg...) \\\n\tdev_warn(&(ctl)->nhi->pdev->dev, format, ## arg)\n\n#define tb_ctl_info(ctl, format, arg...) \\\n\tdev_info(&(ctl)->nhi->pdev->dev, format, ## arg)\n\n#define tb_ctl_dbg(ctl, format, arg...) \\\n\tdev_dbg(&(ctl)->nhi->pdev->dev, format, ## arg)\n\nstatic DECLARE_WAIT_QUEUE_HEAD(tb_cfg_request_cancel_queue);\n \nstatic DEFINE_MUTEX(tb_cfg_request_lock);\n\n \nstruct tb_cfg_request *tb_cfg_request_alloc(void)\n{\n\tstruct tb_cfg_request *req;\n\n\treq = kzalloc(sizeof(*req), GFP_KERNEL);\n\tif (!req)\n\t\treturn NULL;\n\n\tkref_init(&req->kref);\n\n\treturn req;\n}\n\n \nvoid tb_cfg_request_get(struct tb_cfg_request *req)\n{\n\tmutex_lock(&tb_cfg_request_lock);\n\tkref_get(&req->kref);\n\tmutex_unlock(&tb_cfg_request_lock);\n}\n\nstatic void tb_cfg_request_destroy(struct kref *kref)\n{\n\tstruct tb_cfg_request *req = container_of(kref, typeof(*req), kref);\n\n\tkfree(req);\n}\n\n \nvoid tb_cfg_request_put(struct tb_cfg_request *req)\n{\n\tmutex_lock(&tb_cfg_request_lock);\n\tkref_put(&req->kref, tb_cfg_request_destroy);\n\tmutex_unlock(&tb_cfg_request_lock);\n}\n\nstatic int tb_cfg_request_enqueue(struct tb_ctl *ctl,\n\t\t\t\t  struct tb_cfg_request *req)\n{\n\tWARN_ON(test_bit(TB_CFG_REQUEST_ACTIVE, &req->flags));\n\tWARN_ON(req->ctl);\n\n\tmutex_lock(&ctl->request_queue_lock);\n\tif (!ctl->running) {\n\t\tmutex_unlock(&ctl->request_queue_lock);\n\t\treturn -ENOTCONN;\n\t}\n\treq->ctl = ctl;\n\tlist_add_tail(&req->list, &ctl->request_queue);\n\tset_bit(TB_CFG_REQUEST_ACTIVE, &req->flags);\n\tmutex_unlock(&ctl->request_queue_lock);\n\treturn 0;\n}\n\nstatic void tb_cfg_request_dequeue(struct tb_cfg_request *req)\n{\n\tstruct tb_ctl *ctl = req->ctl;\n\n\tmutex_lock(&ctl->request_queue_lock);\n\tlist_del(&req->list);\n\tclear_bit(TB_CFG_REQUEST_ACTIVE, &req->flags);\n\tif (test_bit(TB_CFG_REQUEST_CANCELED, &req->flags))\n\t\twake_up(&tb_cfg_request_cancel_queue);\n\tmutex_unlock(&ctl->request_queue_lock);\n}\n\nstatic bool tb_cfg_request_is_active(struct tb_cfg_request *req)\n{\n\treturn test_bit(TB_CFG_REQUEST_ACTIVE, &req->flags);\n}\n\nstatic struct tb_cfg_request *\ntb_cfg_request_find(struct tb_ctl *ctl, struct ctl_pkg *pkg)\n{\n\tstruct tb_cfg_request *req = NULL, *iter;\n\n\tmutex_lock(&pkg->ctl->request_queue_lock);\n\tlist_for_each_entry(iter, &pkg->ctl->request_queue, list) {\n\t\ttb_cfg_request_get(iter);\n\t\tif (iter->match(iter, pkg)) {\n\t\t\treq = iter;\n\t\t\tbreak;\n\t\t}\n\t\ttb_cfg_request_put(iter);\n\t}\n\tmutex_unlock(&pkg->ctl->request_queue_lock);\n\n\treturn req;\n}\n\n \n\n\nstatic int check_header(const struct ctl_pkg *pkg, u32 len,\n\t\t\tenum tb_cfg_pkg_type type, u64 route)\n{\n\tstruct tb_cfg_header *header = pkg->buffer;\n\n\t \n\tif (WARN(len != pkg->frame.size,\n\t\t\t\"wrong framesize (expected %#x, got %#x)\\n\",\n\t\t\tlen, pkg->frame.size))\n\t\treturn -EIO;\n\tif (WARN(type != pkg->frame.eof, \"wrong eof (expected %#x, got %#x)\\n\",\n\t\t\ttype, pkg->frame.eof))\n\t\treturn -EIO;\n\tif (WARN(pkg->frame.sof, \"wrong sof (expected 0x0, got %#x)\\n\",\n\t\t\tpkg->frame.sof))\n\t\treturn -EIO;\n\n\t \n\tif (WARN(header->unknown != 1 << 9,\n\t\t\t\"header->unknown is %#x\\n\", header->unknown))\n\t\treturn -EIO;\n\tif (WARN(route != tb_cfg_get_route(header),\n\t\t\t\"wrong route (expected %llx, got %llx)\",\n\t\t\troute, tb_cfg_get_route(header)))\n\t\treturn -EIO;\n\treturn 0;\n}\n\nstatic int check_config_address(struct tb_cfg_address addr,\n\t\t\t\tenum tb_cfg_space space, u32 offset,\n\t\t\t\tu32 length)\n{\n\tif (WARN(addr.zero, \"addr.zero is %#x\\n\", addr.zero))\n\t\treturn -EIO;\n\tif (WARN(space != addr.space, \"wrong space (expected %x, got %x\\n)\",\n\t\t\tspace, addr.space))\n\t\treturn -EIO;\n\tif (WARN(offset != addr.offset, \"wrong offset (expected %x, got %x\\n)\",\n\t\t\toffset, addr.offset))\n\t\treturn -EIO;\n\tif (WARN(length != addr.length, \"wrong space (expected %x, got %x\\n)\",\n\t\t\tlength, addr.length))\n\t\treturn -EIO;\n\t \n\treturn 0;\n}\n\nstatic struct tb_cfg_result decode_error(const struct ctl_pkg *response)\n{\n\tstruct cfg_error_pkg *pkg = response->buffer;\n\tstruct tb_cfg_result res = { 0 };\n\tres.response_route = tb_cfg_get_route(&pkg->header);\n\tres.response_port = 0;\n\tres.err = check_header(response, sizeof(*pkg), TB_CFG_PKG_ERROR,\n\t\t\t       tb_cfg_get_route(&pkg->header));\n\tif (res.err)\n\t\treturn res;\n\n\tres.err = 1;\n\tres.tb_error = pkg->error;\n\tres.response_port = pkg->port;\n\treturn res;\n\n}\n\nstatic struct tb_cfg_result parse_header(const struct ctl_pkg *pkg, u32 len,\n\t\t\t\t\t enum tb_cfg_pkg_type type, u64 route)\n{\n\tstruct tb_cfg_header *header = pkg->buffer;\n\tstruct tb_cfg_result res = { 0 };\n\n\tif (pkg->frame.eof == TB_CFG_PKG_ERROR)\n\t\treturn decode_error(pkg);\n\n\tres.response_port = 0;  \n\tres.response_route = tb_cfg_get_route(header);\n\tres.err = check_header(pkg, len, type, route);\n\treturn res;\n}\n\nstatic void tb_cfg_print_error(struct tb_ctl *ctl,\n\t\t\t       const struct tb_cfg_result *res)\n{\n\tWARN_ON(res->err != 1);\n\tswitch (res->tb_error) {\n\tcase TB_CFG_ERROR_PORT_NOT_CONNECTED:\n\t\t \n\t\treturn;\n\tcase TB_CFG_ERROR_INVALID_CONFIG_SPACE:\n\t\t \n\t\ttb_ctl_dbg(ctl, \"%llx:%x: invalid config space or offset\\n\",\n\t\t\t   res->response_route, res->response_port);\n\t\treturn;\n\tcase TB_CFG_ERROR_NO_SUCH_PORT:\n\t\t \n\t\ttb_ctl_WARN(ctl, \"CFG_ERROR(%llx:%x): Invalid port\\n\",\n\t\t\tres->response_route, res->response_port);\n\t\treturn;\n\tcase TB_CFG_ERROR_LOOP:\n\t\ttb_ctl_WARN(ctl, \"CFG_ERROR(%llx:%x): Route contains a loop\\n\",\n\t\t\tres->response_route, res->response_port);\n\t\treturn;\n\tcase TB_CFG_ERROR_LOCK:\n\t\ttb_ctl_warn(ctl, \"%llx:%x: downstream port is locked\\n\",\n\t\t\t    res->response_route, res->response_port);\n\t\treturn;\n\tdefault:\n\t\t \n\t\ttb_ctl_WARN(ctl, \"CFG_ERROR(%llx:%x): Unknown error\\n\",\n\t\t\tres->response_route, res->response_port);\n\t\treturn;\n\t}\n}\n\nstatic __be32 tb_crc(const void *data, size_t len)\n{\n\treturn cpu_to_be32(~__crc32c_le(~0, data, len));\n}\n\nstatic void tb_ctl_pkg_free(struct ctl_pkg *pkg)\n{\n\tif (pkg) {\n\t\tdma_pool_free(pkg->ctl->frame_pool,\n\t\t\t      pkg->buffer, pkg->frame.buffer_phy);\n\t\tkfree(pkg);\n\t}\n}\n\nstatic struct ctl_pkg *tb_ctl_pkg_alloc(struct tb_ctl *ctl)\n{\n\tstruct ctl_pkg *pkg = kzalloc(sizeof(*pkg), GFP_KERNEL);\n\tif (!pkg)\n\t\treturn NULL;\n\tpkg->ctl = ctl;\n\tpkg->buffer = dma_pool_alloc(ctl->frame_pool, GFP_KERNEL,\n\t\t\t\t     &pkg->frame.buffer_phy);\n\tif (!pkg->buffer) {\n\t\tkfree(pkg);\n\t\treturn NULL;\n\t}\n\treturn pkg;\n}\n\n\n \n\nstatic void tb_ctl_tx_callback(struct tb_ring *ring, struct ring_frame *frame,\n\t\t\t       bool canceled)\n{\n\tstruct ctl_pkg *pkg = container_of(frame, typeof(*pkg), frame);\n\ttb_ctl_pkg_free(pkg);\n}\n\n \nstatic int tb_ctl_tx(struct tb_ctl *ctl, const void *data, size_t len,\n\t\t     enum tb_cfg_pkg_type type)\n{\n\tint res;\n\tstruct ctl_pkg *pkg;\n\tif (len % 4 != 0) {  \n\t\ttb_ctl_WARN(ctl, \"TX: invalid size: %zu\\n\", len);\n\t\treturn -EINVAL;\n\t}\n\tif (len > TB_FRAME_SIZE - 4) {  \n\t\ttb_ctl_WARN(ctl, \"TX: packet too large: %zu/%d\\n\",\n\t\t\t    len, TB_FRAME_SIZE - 4);\n\t\treturn -EINVAL;\n\t}\n\tpkg = tb_ctl_pkg_alloc(ctl);\n\tif (!pkg)\n\t\treturn -ENOMEM;\n\tpkg->frame.callback = tb_ctl_tx_callback;\n\tpkg->frame.size = len + 4;\n\tpkg->frame.sof = type;\n\tpkg->frame.eof = type;\n\tcpu_to_be32_array(pkg->buffer, data, len / 4);\n\t*(__be32 *) (pkg->buffer + len) = tb_crc(pkg->buffer, len);\n\n\tres = tb_ring_tx(ctl->tx, &pkg->frame);\n\tif (res)  \n\t\ttb_ctl_pkg_free(pkg);\n\treturn res;\n}\n\n \nstatic bool tb_ctl_handle_event(struct tb_ctl *ctl, enum tb_cfg_pkg_type type,\n\t\t\t\tstruct ctl_pkg *pkg, size_t size)\n{\n\treturn ctl->callback(ctl->callback_data, type, pkg->buffer, size);\n}\n\nstatic void tb_ctl_rx_submit(struct ctl_pkg *pkg)\n{\n\ttb_ring_rx(pkg->ctl->rx, &pkg->frame);  \n}\n\nstatic int tb_async_error(const struct ctl_pkg *pkg)\n{\n\tconst struct cfg_error_pkg *error = pkg->buffer;\n\n\tif (pkg->frame.eof != TB_CFG_PKG_ERROR)\n\t\treturn false;\n\n\tswitch (error->error) {\n\tcase TB_CFG_ERROR_LINK_ERROR:\n\tcase TB_CFG_ERROR_HEC_ERROR_DETECTED:\n\tcase TB_CFG_ERROR_FLOW_CONTROL_ERROR:\n\tcase TB_CFG_ERROR_DP_BW:\n\tcase TB_CFG_ERROR_ROP_CMPLT:\n\tcase TB_CFG_ERROR_POP_CMPLT:\n\tcase TB_CFG_ERROR_PCIE_WAKE:\n\tcase TB_CFG_ERROR_DP_CON_CHANGE:\n\tcase TB_CFG_ERROR_DPTX_DISCOVERY:\n\tcase TB_CFG_ERROR_LINK_RECOVERY:\n\tcase TB_CFG_ERROR_ASYM_LINK:\n\t\treturn true;\n\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic void tb_ctl_rx_callback(struct tb_ring *ring, struct ring_frame *frame,\n\t\t\t       bool canceled)\n{\n\tstruct ctl_pkg *pkg = container_of(frame, typeof(*pkg), frame);\n\tstruct tb_cfg_request *req;\n\t__be32 crc32;\n\n\tif (canceled)\n\t\treturn;  \n\n\tif (frame->size < 4 || frame->size % 4 != 0) {\n\t\ttb_ctl_err(pkg->ctl, \"RX: invalid size %#x, dropping packet\\n\",\n\t\t\t   frame->size);\n\t\tgoto rx;\n\t}\n\n\tframe->size -= 4;  \n\tcrc32 = tb_crc(pkg->buffer, frame->size);\n\tbe32_to_cpu_array(pkg->buffer, pkg->buffer, frame->size / 4);\n\n\tswitch (frame->eof) {\n\tcase TB_CFG_PKG_READ:\n\tcase TB_CFG_PKG_WRITE:\n\tcase TB_CFG_PKG_ERROR:\n\tcase TB_CFG_PKG_OVERRIDE:\n\tcase TB_CFG_PKG_RESET:\n\t\tif (*(__be32 *)(pkg->buffer + frame->size) != crc32) {\n\t\t\ttb_ctl_err(pkg->ctl,\n\t\t\t\t   \"RX: checksum mismatch, dropping packet\\n\");\n\t\t\tgoto rx;\n\t\t}\n\t\tif (tb_async_error(pkg)) {\n\t\t\ttb_ctl_handle_event(pkg->ctl, frame->eof,\n\t\t\t\t\t    pkg, frame->size);\n\t\t\tgoto rx;\n\t\t}\n\t\tbreak;\n\n\tcase TB_CFG_PKG_EVENT:\n\tcase TB_CFG_PKG_XDOMAIN_RESP:\n\tcase TB_CFG_PKG_XDOMAIN_REQ:\n\t\tif (*(__be32 *)(pkg->buffer + frame->size) != crc32) {\n\t\t\ttb_ctl_err(pkg->ctl,\n\t\t\t\t   \"RX: checksum mismatch, dropping packet\\n\");\n\t\t\tgoto rx;\n\t\t}\n\t\tfallthrough;\n\tcase TB_CFG_PKG_ICM_EVENT:\n\t\tif (tb_ctl_handle_event(pkg->ctl, frame->eof, pkg, frame->size))\n\t\t\tgoto rx;\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\treq = tb_cfg_request_find(pkg->ctl, pkg);\n\tif (req) {\n\t\tif (req->copy(req, pkg))\n\t\t\tschedule_work(&req->work);\n\t\ttb_cfg_request_put(req);\n\t}\n\nrx:\n\ttb_ctl_rx_submit(pkg);\n}\n\nstatic void tb_cfg_request_work(struct work_struct *work)\n{\n\tstruct tb_cfg_request *req = container_of(work, typeof(*req), work);\n\n\tif (!test_bit(TB_CFG_REQUEST_CANCELED, &req->flags))\n\t\treq->callback(req->callback_data);\n\n\ttb_cfg_request_dequeue(req);\n\ttb_cfg_request_put(req);\n}\n\n \nint tb_cfg_request(struct tb_ctl *ctl, struct tb_cfg_request *req,\n\t\t   void (*callback)(void *), void *callback_data)\n{\n\tint ret;\n\n\treq->flags = 0;\n\treq->callback = callback;\n\treq->callback_data = callback_data;\n\tINIT_WORK(&req->work, tb_cfg_request_work);\n\tINIT_LIST_HEAD(&req->list);\n\n\ttb_cfg_request_get(req);\n\tret = tb_cfg_request_enqueue(ctl, req);\n\tif (ret)\n\t\tgoto err_put;\n\n\tret = tb_ctl_tx(ctl, req->request, req->request_size,\n\t\t\treq->request_type);\n\tif (ret)\n\t\tgoto err_dequeue;\n\n\tif (!req->response)\n\t\tschedule_work(&req->work);\n\n\treturn 0;\n\nerr_dequeue:\n\ttb_cfg_request_dequeue(req);\nerr_put:\n\ttb_cfg_request_put(req);\n\n\treturn ret;\n}\n\n \nvoid tb_cfg_request_cancel(struct tb_cfg_request *req, int err)\n{\n\tset_bit(TB_CFG_REQUEST_CANCELED, &req->flags);\n\tschedule_work(&req->work);\n\twait_event(tb_cfg_request_cancel_queue, !tb_cfg_request_is_active(req));\n\treq->result.err = err;\n}\n\nstatic void tb_cfg_request_complete(void *data)\n{\n\tcomplete(data);\n}\n\n \nstruct tb_cfg_result tb_cfg_request_sync(struct tb_ctl *ctl,\n\t\t\t\t\t struct tb_cfg_request *req,\n\t\t\t\t\t int timeout_msec)\n{\n\tunsigned long timeout = msecs_to_jiffies(timeout_msec);\n\tstruct tb_cfg_result res = { 0 };\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tint ret;\n\n\tret = tb_cfg_request(ctl, req, tb_cfg_request_complete, &done);\n\tif (ret) {\n\t\tres.err = ret;\n\t\treturn res;\n\t}\n\n\tif (!wait_for_completion_timeout(&done, timeout))\n\t\ttb_cfg_request_cancel(req, -ETIMEDOUT);\n\n\tflush_work(&req->work);\n\n\treturn req->result;\n}\n\n \n\n \nstruct tb_ctl *tb_ctl_alloc(struct tb_nhi *nhi, int timeout_msec, event_cb cb,\n\t\t\t    void *cb_data)\n{\n\tint i;\n\tstruct tb_ctl *ctl = kzalloc(sizeof(*ctl), GFP_KERNEL);\n\tif (!ctl)\n\t\treturn NULL;\n\tctl->nhi = nhi;\n\tctl->timeout_msec = timeout_msec;\n\tctl->callback = cb;\n\tctl->callback_data = cb_data;\n\n\tmutex_init(&ctl->request_queue_lock);\n\tINIT_LIST_HEAD(&ctl->request_queue);\n\tctl->frame_pool = dma_pool_create(\"thunderbolt_ctl\", &nhi->pdev->dev,\n\t\t\t\t\t TB_FRAME_SIZE, 4, 0);\n\tif (!ctl->frame_pool)\n\t\tgoto err;\n\n\tctl->tx = tb_ring_alloc_tx(nhi, 0, 10, RING_FLAG_NO_SUSPEND);\n\tif (!ctl->tx)\n\t\tgoto err;\n\n\tctl->rx = tb_ring_alloc_rx(nhi, 0, 10, RING_FLAG_NO_SUSPEND, 0, 0xffff,\n\t\t\t\t   0xffff, NULL, NULL);\n\tif (!ctl->rx)\n\t\tgoto err;\n\n\tfor (i = 0; i < TB_CTL_RX_PKG_COUNT; i++) {\n\t\tctl->rx_packets[i] = tb_ctl_pkg_alloc(ctl);\n\t\tif (!ctl->rx_packets[i])\n\t\t\tgoto err;\n\t\tctl->rx_packets[i]->frame.callback = tb_ctl_rx_callback;\n\t}\n\n\ttb_ctl_dbg(ctl, \"control channel created\\n\");\n\treturn ctl;\nerr:\n\ttb_ctl_free(ctl);\n\treturn NULL;\n}\n\n \nvoid tb_ctl_free(struct tb_ctl *ctl)\n{\n\tint i;\n\n\tif (!ctl)\n\t\treturn;\n\n\tif (ctl->rx)\n\t\ttb_ring_free(ctl->rx);\n\tif (ctl->tx)\n\t\ttb_ring_free(ctl->tx);\n\n\t \n\tfor (i = 0; i < TB_CTL_RX_PKG_COUNT; i++)\n\t\ttb_ctl_pkg_free(ctl->rx_packets[i]);\n\n\n\tdma_pool_destroy(ctl->frame_pool);\n\tkfree(ctl);\n}\n\n \nvoid tb_ctl_start(struct tb_ctl *ctl)\n{\n\tint i;\n\ttb_ctl_dbg(ctl, \"control channel starting...\\n\");\n\ttb_ring_start(ctl->tx);  \n\ttb_ring_start(ctl->rx);\n\tfor (i = 0; i < TB_CTL_RX_PKG_COUNT; i++)\n\t\ttb_ctl_rx_submit(ctl->rx_packets[i]);\n\n\tctl->running = true;\n}\n\n \nvoid tb_ctl_stop(struct tb_ctl *ctl)\n{\n\tmutex_lock(&ctl->request_queue_lock);\n\tctl->running = false;\n\tmutex_unlock(&ctl->request_queue_lock);\n\n\ttb_ring_stop(ctl->rx);\n\ttb_ring_stop(ctl->tx);\n\n\tif (!list_empty(&ctl->request_queue))\n\t\ttb_ctl_WARN(ctl, \"dangling request in request_queue\\n\");\n\tINIT_LIST_HEAD(&ctl->request_queue);\n\ttb_ctl_dbg(ctl, \"control channel stopped\\n\");\n}\n\n \n\n \nint tb_cfg_ack_notification(struct tb_ctl *ctl, u64 route,\n\t\t\t    const struct cfg_error_pkg *error)\n{\n\tstruct cfg_ack_pkg pkg = {\n\t\t.header = tb_cfg_make_header(route),\n\t};\n\tconst char *name;\n\n\tswitch (error->error) {\n\tcase TB_CFG_ERROR_LINK_ERROR:\n\t\tname = \"link error\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_HEC_ERROR_DETECTED:\n\t\tname = \"HEC error\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_FLOW_CONTROL_ERROR:\n\t\tname = \"flow control error\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_DP_BW:\n\t\tname = \"DP_BW\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_ROP_CMPLT:\n\t\tname = \"router operation completion\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_POP_CMPLT:\n\t\tname = \"port operation completion\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_PCIE_WAKE:\n\t\tname = \"PCIe wake\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_DP_CON_CHANGE:\n\t\tname = \"DP connector change\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_DPTX_DISCOVERY:\n\t\tname = \"DPTX discovery\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_LINK_RECOVERY:\n\t\tname = \"link recovery\";\n\t\tbreak;\n\tcase TB_CFG_ERROR_ASYM_LINK:\n\t\tname = \"asymmetric link\";\n\t\tbreak;\n\tdefault:\n\t\tname = \"unknown\";\n\t\tbreak;\n\t}\n\n\ttb_ctl_dbg(ctl, \"acking %s (%#x) notification on %llx\\n\", name,\n\t\t   error->error, route);\n\n\treturn tb_ctl_tx(ctl, &pkg, sizeof(pkg), TB_CFG_PKG_NOTIFY_ACK);\n}\n\n \nint tb_cfg_ack_plug(struct tb_ctl *ctl, u64 route, u32 port, bool unplug)\n{\n\tstruct cfg_error_pkg pkg = {\n\t\t.header = tb_cfg_make_header(route),\n\t\t.port = port,\n\t\t.error = TB_CFG_ERROR_ACK_PLUG_EVENT,\n\t\t.pg = unplug ? TB_CFG_ERROR_PG_HOT_UNPLUG\n\t\t\t     : TB_CFG_ERROR_PG_HOT_PLUG,\n\t};\n\ttb_ctl_dbg(ctl, \"acking hot %splug event on %llx:%u\\n\",\n\t\t   unplug ? \"un\" : \"\", route, port);\n\treturn tb_ctl_tx(ctl, &pkg, sizeof(pkg), TB_CFG_PKG_ERROR);\n}\n\nstatic bool tb_cfg_match(const struct tb_cfg_request *req,\n\t\t\t const struct ctl_pkg *pkg)\n{\n\tu64 route = tb_cfg_get_route(pkg->buffer) & ~BIT_ULL(63);\n\n\tif (pkg->frame.eof == TB_CFG_PKG_ERROR)\n\t\treturn true;\n\n\tif (pkg->frame.eof != req->response_type)\n\t\treturn false;\n\tif (route != tb_cfg_get_route(req->request))\n\t\treturn false;\n\tif (pkg->frame.size != req->response_size)\n\t\treturn false;\n\n\tif (pkg->frame.eof == TB_CFG_PKG_READ ||\n\t    pkg->frame.eof == TB_CFG_PKG_WRITE) {\n\t\tconst struct cfg_read_pkg *req_hdr = req->request;\n\t\tconst struct cfg_read_pkg *res_hdr = pkg->buffer;\n\n\t\tif (req_hdr->addr.seq != res_hdr->addr.seq)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool tb_cfg_copy(struct tb_cfg_request *req, const struct ctl_pkg *pkg)\n{\n\tstruct tb_cfg_result res;\n\n\t \n\tres = parse_header(pkg, req->response_size, req->response_type,\n\t\t\t   tb_cfg_get_route(req->request));\n\tif (!res.err)\n\t\tmemcpy(req->response, pkg->buffer, req->response_size);\n\n\treq->result = res;\n\n\t \n\treturn true;\n}\n\n \nstruct tb_cfg_result tb_cfg_reset(struct tb_ctl *ctl, u64 route)\n{\n\tstruct cfg_reset_pkg request = { .header = tb_cfg_make_header(route) };\n\tstruct tb_cfg_result res = { 0 };\n\tstruct tb_cfg_header reply;\n\tstruct tb_cfg_request *req;\n\n\treq = tb_cfg_request_alloc();\n\tif (!req) {\n\t\tres.err = -ENOMEM;\n\t\treturn res;\n\t}\n\n\treq->match = tb_cfg_match;\n\treq->copy = tb_cfg_copy;\n\treq->request = &request;\n\treq->request_size = sizeof(request);\n\treq->request_type = TB_CFG_PKG_RESET;\n\treq->response = &reply;\n\treq->response_size = sizeof(reply);\n\treq->response_type = TB_CFG_PKG_RESET;\n\n\tres = tb_cfg_request_sync(ctl, req, ctl->timeout_msec);\n\n\ttb_cfg_request_put(req);\n\n\treturn res;\n}\n\n \nstruct tb_cfg_result tb_cfg_read_raw(struct tb_ctl *ctl, void *buffer,\n\t\tu64 route, u32 port, enum tb_cfg_space space,\n\t\tu32 offset, u32 length, int timeout_msec)\n{\n\tstruct tb_cfg_result res = { 0 };\n\tstruct cfg_read_pkg request = {\n\t\t.header = tb_cfg_make_header(route),\n\t\t.addr = {\n\t\t\t.port = port,\n\t\t\t.space = space,\n\t\t\t.offset = offset,\n\t\t\t.length = length,\n\t\t},\n\t};\n\tstruct cfg_write_pkg reply;\n\tint retries = 0;\n\n\twhile (retries < TB_CTL_RETRIES) {\n\t\tstruct tb_cfg_request *req;\n\n\t\treq = tb_cfg_request_alloc();\n\t\tif (!req) {\n\t\t\tres.err = -ENOMEM;\n\t\t\treturn res;\n\t\t}\n\n\t\trequest.addr.seq = retries++;\n\n\t\treq->match = tb_cfg_match;\n\t\treq->copy = tb_cfg_copy;\n\t\treq->request = &request;\n\t\treq->request_size = sizeof(request);\n\t\treq->request_type = TB_CFG_PKG_READ;\n\t\treq->response = &reply;\n\t\treq->response_size = 12 + 4 * length;\n\t\treq->response_type = TB_CFG_PKG_READ;\n\n\t\tres = tb_cfg_request_sync(ctl, req, timeout_msec);\n\n\t\ttb_cfg_request_put(req);\n\n\t\tif (res.err != -ETIMEDOUT)\n\t\t\tbreak;\n\n\t\t \n\t\tusleep_range(10, 100);\n\t}\n\n\tif (res.err)\n\t\treturn res;\n\n\tres.response_port = reply.addr.port;\n\tres.err = check_config_address(reply.addr, space, offset, length);\n\tif (!res.err)\n\t\tmemcpy(buffer, &reply.data, 4 * length);\n\treturn res;\n}\n\n \nstruct tb_cfg_result tb_cfg_write_raw(struct tb_ctl *ctl, const void *buffer,\n\t\tu64 route, u32 port, enum tb_cfg_space space,\n\t\tu32 offset, u32 length, int timeout_msec)\n{\n\tstruct tb_cfg_result res = { 0 };\n\tstruct cfg_write_pkg request = {\n\t\t.header = tb_cfg_make_header(route),\n\t\t.addr = {\n\t\t\t.port = port,\n\t\t\t.space = space,\n\t\t\t.offset = offset,\n\t\t\t.length = length,\n\t\t},\n\t};\n\tstruct cfg_read_pkg reply;\n\tint retries = 0;\n\n\tmemcpy(&request.data, buffer, length * 4);\n\n\twhile (retries < TB_CTL_RETRIES) {\n\t\tstruct tb_cfg_request *req;\n\n\t\treq = tb_cfg_request_alloc();\n\t\tif (!req) {\n\t\t\tres.err = -ENOMEM;\n\t\t\treturn res;\n\t\t}\n\n\t\trequest.addr.seq = retries++;\n\n\t\treq->match = tb_cfg_match;\n\t\treq->copy = tb_cfg_copy;\n\t\treq->request = &request;\n\t\treq->request_size = 12 + 4 * length;\n\t\treq->request_type = TB_CFG_PKG_WRITE;\n\t\treq->response = &reply;\n\t\treq->response_size = sizeof(reply);\n\t\treq->response_type = TB_CFG_PKG_WRITE;\n\n\t\tres = tb_cfg_request_sync(ctl, req, timeout_msec);\n\n\t\ttb_cfg_request_put(req);\n\n\t\tif (res.err != -ETIMEDOUT)\n\t\t\tbreak;\n\n\t\t \n\t\tusleep_range(10, 100);\n\t}\n\n\tif (res.err)\n\t\treturn res;\n\n\tres.response_port = reply.addr.port;\n\tres.err = check_config_address(reply.addr, space, offset, length);\n\treturn res;\n}\n\nstatic int tb_cfg_get_error(struct tb_ctl *ctl, enum tb_cfg_space space,\n\t\t\t    const struct tb_cfg_result *res)\n{\n\t \n\tif (space == TB_CFG_PORT &&\n\t    res->tb_error == TB_CFG_ERROR_INVALID_CONFIG_SPACE)\n\t\treturn -ENODEV;\n\n\ttb_cfg_print_error(ctl, res);\n\n\tif (res->tb_error == TB_CFG_ERROR_LOCK)\n\t\treturn -EACCES;\n\tif (res->tb_error == TB_CFG_ERROR_PORT_NOT_CONNECTED)\n\t\treturn -ENOTCONN;\n\n\treturn -EIO;\n}\n\nint tb_cfg_read(struct tb_ctl *ctl, void *buffer, u64 route, u32 port,\n\t\tenum tb_cfg_space space, u32 offset, u32 length)\n{\n\tstruct tb_cfg_result res = tb_cfg_read_raw(ctl, buffer, route, port,\n\t\t\tspace, offset, length, ctl->timeout_msec);\n\tswitch (res.err) {\n\tcase 0:\n\t\t \n\t\tbreak;\n\n\tcase 1:\n\t\t \n\t\treturn tb_cfg_get_error(ctl, space, &res);\n\n\tcase -ETIMEDOUT:\n\t\ttb_ctl_warn(ctl, \"%llx: timeout reading config space %u from %#x\\n\",\n\t\t\t    route, space, offset);\n\t\tbreak;\n\n\tdefault:\n\t\tWARN(1, \"tb_cfg_read: %d\\n\", res.err);\n\t\tbreak;\n\t}\n\treturn res.err;\n}\n\nint tb_cfg_write(struct tb_ctl *ctl, const void *buffer, u64 route, u32 port,\n\t\t enum tb_cfg_space space, u32 offset, u32 length)\n{\n\tstruct tb_cfg_result res = tb_cfg_write_raw(ctl, buffer, route, port,\n\t\t\tspace, offset, length, ctl->timeout_msec);\n\tswitch (res.err) {\n\tcase 0:\n\t\t \n\t\tbreak;\n\n\tcase 1:\n\t\t \n\t\treturn tb_cfg_get_error(ctl, space, &res);\n\n\tcase -ETIMEDOUT:\n\t\ttb_ctl_warn(ctl, \"%llx: timeout writing config space %u to %#x\\n\",\n\t\t\t    route, space, offset);\n\t\tbreak;\n\n\tdefault:\n\t\tWARN(1, \"tb_cfg_write: %d\\n\", res.err);\n\t\tbreak;\n\t}\n\treturn res.err;\n}\n\n \nint tb_cfg_get_upstream_port(struct tb_ctl *ctl, u64 route)\n{\n\tu32 dummy;\n\tstruct tb_cfg_result res = tb_cfg_read_raw(ctl, &dummy, route, 0,\n\t\t\t\t\t\t   TB_CFG_SWITCH, 0, 1,\n\t\t\t\t\t\t   ctl->timeout_msec);\n\tif (res.err == 1)\n\t\treturn -EIO;\n\tif (res.err)\n\t\treturn res.err;\n\treturn res.response_port;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}