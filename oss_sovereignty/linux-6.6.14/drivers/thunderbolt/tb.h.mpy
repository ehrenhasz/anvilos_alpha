{
  "module_name": "tb.h",
  "hash_id": "b61b2592db64bd0c327b6fde71b1e7d75e4f5c7037163fa2bbd72115a04e640e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/thunderbolt/tb.h",
  "human_readable_source": " \n \n\n#ifndef TB_H_\n#define TB_H_\n\n#include <linux/nvmem-provider.h>\n#include <linux/pci.h>\n#include <linux/thunderbolt.h>\n#include <linux/uuid.h>\n#include <linux/bitfield.h>\n\n#include \"tb_regs.h\"\n#include \"ctl.h\"\n#include \"dma_port.h\"\n\n \n#define QUIRK_FORCE_POWER_LINK_CONTROLLER\t\tBIT(0)\n \n#define QUIRK_NO_CLX\t\t\t\t\tBIT(1)\n\n \nstruct tb_nvm {\n\tstruct device *dev;\n\tu32 major;\n\tu32 minor;\n\tint id;\n\tstruct nvmem_device *active;\n\tsize_t active_size;\n\tstruct nvmem_device *non_active;\n\tvoid *buf;\n\tvoid *buf_data_start;\n\tsize_t buf_data_size;\n\tbool authenticating;\n\tbool flushed;\n\tconst struct tb_nvm_vendor_ops *vops;\n};\n\nenum tb_nvm_write_ops {\n\tWRITE_AND_AUTHENTICATE = 1,\n\tWRITE_ONLY = 2,\n\tAUTHENTICATE_ONLY = 3,\n};\n\n#define TB_SWITCH_KEY_SIZE\t\t32\n#define TB_SWITCH_MAX_DEPTH\t\t6\n#define USB4_SWITCH_MAX_DEPTH\t\t5\n\n \nenum tb_switch_tmu_mode {\n\tTB_SWITCH_TMU_MODE_OFF,\n\tTB_SWITCH_TMU_MODE_LOWRES,\n\tTB_SWITCH_TMU_MODE_HIFI_UNI,\n\tTB_SWITCH_TMU_MODE_HIFI_BI,\n\tTB_SWITCH_TMU_MODE_MEDRES_ENHANCED_UNI,\n};\n\n \nstruct tb_switch_tmu {\n\tint cap;\n\tbool has_ucap;\n\tenum tb_switch_tmu_mode mode;\n\tenum tb_switch_tmu_mode mode_request;\n};\n\n \nstruct tb_switch {\n\tstruct device dev;\n\tstruct tb_regs_switch_header config;\n\tstruct tb_port *ports;\n\tstruct tb_dma_port *dma_port;\n\tstruct tb_switch_tmu tmu;\n\tstruct tb *tb;\n\tu64 uid;\n\tuuid_t *uuid;\n\tu16 vendor;\n\tu16 device;\n\tconst char *vendor_name;\n\tconst char *device_name;\n\tunsigned int link_speed;\n\tenum tb_link_width link_width;\n\tbool link_usb4;\n\tunsigned int generation;\n\tint cap_plug_events;\n\tint cap_vsec_tmu;\n\tint cap_lc;\n\tint cap_lp;\n\tbool is_unplugged;\n\tu8 *drom;\n\tstruct tb_nvm *nvm;\n\tbool no_nvm_upgrade;\n\tbool safe_mode;\n\tbool boot;\n\tbool rpm;\n\tunsigned int authorized;\n\tenum tb_security_level security_level;\n\tstruct dentry *debugfs_dir;\n\tu8 *key;\n\tu8 connection_id;\n\tu8 connection_key;\n\tu8 link;\n\tu8 depth;\n\tstruct completion rpm_complete;\n\tunsigned long quirks;\n\tbool credit_allocation;\n\tunsigned int max_usb3_credits;\n\tunsigned int min_dp_aux_credits;\n\tunsigned int min_dp_main_credits;\n\tunsigned int max_pcie_credits;\n\tunsigned int max_dma_credits;\n\tunsigned int clx;\n};\n\n \nstruct tb_bandwidth_group {\n\tstruct tb *tb;\n\tint index;\n\tstruct list_head ports;\n};\n\n \nstruct tb_port {\n\tstruct tb_regs_port_header config;\n\tstruct tb_switch *sw;\n\tstruct tb_port *remote;\n\tstruct tb_xdomain *xdomain;\n\tint cap_phy;\n\tint cap_tmu;\n\tint cap_adap;\n\tint cap_usb4;\n\tstruct usb4_port *usb4;\n\tu8 port;\n\tbool disabled;\n\tbool bonded;\n\tstruct tb_port *dual_link_port;\n\tu8 link_nr:1;\n\tstruct ida in_hopids;\n\tstruct ida out_hopids;\n\tstruct list_head list;\n\tunsigned int total_credits;\n\tunsigned int ctl_credits;\n\tunsigned int dma_credits;\n\tstruct tb_bandwidth_group *group;\n\tstruct list_head group_list;\n\tunsigned int max_bw;\n};\n\n \nstruct usb4_port {\n\tstruct device dev;\n\tstruct tb_port *port;\n\tbool can_offline;\n\tbool offline;\n#ifdef CONFIG_USB4_DEBUGFS_MARGINING\n\tstruct tb_margining *margining;\n#endif\n};\n\n \nstruct tb_retimer {\n\tstruct device dev;\n\tstruct tb *tb;\n\tu8 index;\n\tu32 vendor;\n\tu32 device;\n\tstruct tb_port *port;\n\tstruct tb_nvm *nvm;\n\tbool no_nvm_upgrade;\n\tu32 auth_status;\n};\n\n \nstruct tb_path_hop {\n\tstruct tb_port *in_port;\n\tstruct tb_port *out_port;\n\tint in_hop_index;\n\tint in_counter_index;\n\tint next_hop_index;\n\tunsigned int initial_credits;\n\tunsigned int nfc_credits;\n};\n\n \nenum tb_path_port {\n\tTB_PATH_NONE = 0,\n\tTB_PATH_SOURCE = 1,\n\tTB_PATH_INTERNAL = 2,\n\tTB_PATH_DESTINATION = 4,\n\tTB_PATH_ALL = 7,\n};\n\n \nstruct tb_path {\n\tstruct tb *tb;\n\tconst char *name;\n\tenum tb_path_port ingress_shared_buffer;\n\tenum tb_path_port egress_shared_buffer;\n\tenum tb_path_port ingress_fc_enable;\n\tenum tb_path_port egress_fc_enable;\n\n\tunsigned int priority:3;\n\tint weight:4;\n\tbool drop_packages;\n\tbool activated;\n\tbool clear_fc;\n\tstruct tb_path_hop *hops;\n\tint path_length;\n\tbool alloc_hopid;\n};\n\n \n#define TB_PATH_MIN_HOPID\t8\n \n#define TB_PATH_MAX_HOPS\t(7 * 2)\n\n \n#define TB_WAKE_ON_CONNECT\tBIT(0)\n#define TB_WAKE_ON_DISCONNECT\tBIT(1)\n#define TB_WAKE_ON_USB4\t\tBIT(2)\n#define TB_WAKE_ON_USB3\t\tBIT(3)\n#define TB_WAKE_ON_PCIE\t\tBIT(4)\n#define TB_WAKE_ON_DP\t\tBIT(5)\n\n \n#define TB_CL0S\t\t\tBIT(0)\n#define TB_CL1\t\t\tBIT(1)\n#define TB_CL2\t\t\tBIT(2)\n\n \nstruct tb_cm_ops {\n\tint (*driver_ready)(struct tb *tb);\n\tint (*start)(struct tb *tb);\n\tvoid (*stop)(struct tb *tb);\n\tint (*suspend_noirq)(struct tb *tb);\n\tint (*resume_noirq)(struct tb *tb);\n\tint (*suspend)(struct tb *tb);\n\tint (*freeze_noirq)(struct tb *tb);\n\tint (*thaw_noirq)(struct tb *tb);\n\tvoid (*complete)(struct tb *tb);\n\tint (*runtime_suspend)(struct tb *tb);\n\tint (*runtime_resume)(struct tb *tb);\n\tint (*runtime_suspend_switch)(struct tb_switch *sw);\n\tint (*runtime_resume_switch)(struct tb_switch *sw);\n\tvoid (*handle_event)(struct tb *tb, enum tb_cfg_pkg_type,\n\t\t\t     const void *buf, size_t size);\n\tint (*get_boot_acl)(struct tb *tb, uuid_t *uuids, size_t nuuids);\n\tint (*set_boot_acl)(struct tb *tb, const uuid_t *uuids, size_t nuuids);\n\tint (*disapprove_switch)(struct tb *tb, struct tb_switch *sw);\n\tint (*approve_switch)(struct tb *tb, struct tb_switch *sw);\n\tint (*add_switch_key)(struct tb *tb, struct tb_switch *sw);\n\tint (*challenge_switch_key)(struct tb *tb, struct tb_switch *sw,\n\t\t\t\t    const u8 *challenge, u8 *response);\n\tint (*disconnect_pcie_paths)(struct tb *tb);\n\tint (*approve_xdomain_paths)(struct tb *tb, struct tb_xdomain *xd,\n\t\t\t\t     int transmit_path, int transmit_ring,\n\t\t\t\t     int receive_path, int receive_ring);\n\tint (*disconnect_xdomain_paths)(struct tb *tb, struct tb_xdomain *xd,\n\t\t\t\t\tint transmit_path, int transmit_ring,\n\t\t\t\t\tint receive_path, int receive_ring);\n\tint (*usb4_switch_op)(struct tb_switch *sw, u16 opcode, u32 *metadata,\n\t\t\t      u8 *status, const void *tx_data, size_t tx_data_len,\n\t\t\t      void *rx_data, size_t rx_data_len);\n\tint (*usb4_switch_nvm_authenticate_status)(struct tb_switch *sw,\n\t\t\t\t\t\t   u32 *status);\n};\n\nstatic inline void *tb_priv(struct tb *tb)\n{\n\treturn (void *)tb->privdata;\n}\n\n#define TB_AUTOSUSPEND_DELAY\t\t15000  \n\n \n\n \nstatic inline struct tb_port *tb_upstream_port(struct tb_switch *sw)\n{\n\treturn &sw->ports[sw->config.upstream_port_number];\n}\n\n \nstatic inline bool tb_is_upstream_port(const struct tb_port *port)\n{\n\tconst struct tb_port *upstream_port = tb_upstream_port(port->sw);\n\treturn port == upstream_port || port->dual_link_port == upstream_port;\n}\n\nstatic inline u64 tb_route(const struct tb_switch *sw)\n{\n\treturn ((u64) sw->config.route_hi) << 32 | sw->config.route_lo;\n}\n\nstatic inline struct tb_port *tb_port_at(u64 route, struct tb_switch *sw)\n{\n\tu8 port;\n\n\tport = route >> (sw->config.depth * 8);\n\tif (WARN_ON(port > sw->config.max_port_number))\n\t\treturn NULL;\n\treturn &sw->ports[port];\n}\n\n \nstatic inline bool tb_port_has_remote(const struct tb_port *port)\n{\n\tif (tb_is_upstream_port(port))\n\t\treturn false;\n\tif (!port->remote)\n\t\treturn false;\n\tif (port->dual_link_port && port->link_nr)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic inline bool tb_port_is_null(const struct tb_port *port)\n{\n\treturn port && port->port && port->config.type == TB_TYPE_PORT;\n}\n\nstatic inline bool tb_port_is_nhi(const struct tb_port *port)\n{\n\treturn port && port->config.type == TB_TYPE_NHI;\n}\n\nstatic inline bool tb_port_is_pcie_down(const struct tb_port *port)\n{\n\treturn port && port->config.type == TB_TYPE_PCIE_DOWN;\n}\n\nstatic inline bool tb_port_is_pcie_up(const struct tb_port *port)\n{\n\treturn port && port->config.type == TB_TYPE_PCIE_UP;\n}\n\nstatic inline bool tb_port_is_dpin(const struct tb_port *port)\n{\n\treturn port && port->config.type == TB_TYPE_DP_HDMI_IN;\n}\n\nstatic inline bool tb_port_is_dpout(const struct tb_port *port)\n{\n\treturn port && port->config.type == TB_TYPE_DP_HDMI_OUT;\n}\n\nstatic inline bool tb_port_is_usb3_down(const struct tb_port *port)\n{\n\treturn port && port->config.type == TB_TYPE_USB3_DOWN;\n}\n\nstatic inline bool tb_port_is_usb3_up(const struct tb_port *port)\n{\n\treturn port && port->config.type == TB_TYPE_USB3_UP;\n}\n\nstatic inline int tb_sw_read(struct tb_switch *sw, void *buffer,\n\t\t\t     enum tb_cfg_space space, u32 offset, u32 length)\n{\n\tif (sw->is_unplugged)\n\t\treturn -ENODEV;\n\treturn tb_cfg_read(sw->tb->ctl,\n\t\t\t   buffer,\n\t\t\t   tb_route(sw),\n\t\t\t   0,\n\t\t\t   space,\n\t\t\t   offset,\n\t\t\t   length);\n}\n\nstatic inline int tb_sw_write(struct tb_switch *sw, const void *buffer,\n\t\t\t      enum tb_cfg_space space, u32 offset, u32 length)\n{\n\tif (sw->is_unplugged)\n\t\treturn -ENODEV;\n\treturn tb_cfg_write(sw->tb->ctl,\n\t\t\t    buffer,\n\t\t\t    tb_route(sw),\n\t\t\t    0,\n\t\t\t    space,\n\t\t\t    offset,\n\t\t\t    length);\n}\n\nstatic inline int tb_port_read(struct tb_port *port, void *buffer,\n\t\t\t       enum tb_cfg_space space, u32 offset, u32 length)\n{\n\tif (port->sw->is_unplugged)\n\t\treturn -ENODEV;\n\treturn tb_cfg_read(port->sw->tb->ctl,\n\t\t\t   buffer,\n\t\t\t   tb_route(port->sw),\n\t\t\t   port->port,\n\t\t\t   space,\n\t\t\t   offset,\n\t\t\t   length);\n}\n\nstatic inline int tb_port_write(struct tb_port *port, const void *buffer,\n\t\t\t\tenum tb_cfg_space space, u32 offset, u32 length)\n{\n\tif (port->sw->is_unplugged)\n\t\treturn -ENODEV;\n\treturn tb_cfg_write(port->sw->tb->ctl,\n\t\t\t    buffer,\n\t\t\t    tb_route(port->sw),\n\t\t\t    port->port,\n\t\t\t    space,\n\t\t\t    offset,\n\t\t\t    length);\n}\n\n#define tb_err(tb, fmt, arg...) dev_err(&(tb)->nhi->pdev->dev, fmt, ## arg)\n#define tb_WARN(tb, fmt, arg...) dev_WARN(&(tb)->nhi->pdev->dev, fmt, ## arg)\n#define tb_warn(tb, fmt, arg...) dev_warn(&(tb)->nhi->pdev->dev, fmt, ## arg)\n#define tb_info(tb, fmt, arg...) dev_info(&(tb)->nhi->pdev->dev, fmt, ## arg)\n#define tb_dbg(tb, fmt, arg...) dev_dbg(&(tb)->nhi->pdev->dev, fmt, ## arg)\n\n#define __TB_SW_PRINT(level, sw, fmt, arg...)           \\\n\tdo {                                            \\\n\t\tconst struct tb_switch *__sw = (sw);    \\\n\t\tlevel(__sw->tb, \"%llx: \" fmt,           \\\n\t\t      tb_route(__sw), ## arg);          \\\n\t} while (0)\n#define tb_sw_WARN(sw, fmt, arg...) __TB_SW_PRINT(tb_WARN, sw, fmt, ##arg)\n#define tb_sw_warn(sw, fmt, arg...) __TB_SW_PRINT(tb_warn, sw, fmt, ##arg)\n#define tb_sw_info(sw, fmt, arg...) __TB_SW_PRINT(tb_info, sw, fmt, ##arg)\n#define tb_sw_dbg(sw, fmt, arg...) __TB_SW_PRINT(tb_dbg, sw, fmt, ##arg)\n\n#define __TB_PORT_PRINT(level, _port, fmt, arg...)                      \\\n\tdo {                                                            \\\n\t\tconst struct tb_port *__port = (_port);                 \\\n\t\tlevel(__port->sw->tb, \"%llx:%u: \" fmt,                  \\\n\t\t      tb_route(__port->sw), __port->port, ## arg);      \\\n\t} while (0)\n#define tb_port_WARN(port, fmt, arg...) \\\n\t__TB_PORT_PRINT(tb_WARN, port, fmt, ##arg)\n#define tb_port_warn(port, fmt, arg...) \\\n\t__TB_PORT_PRINT(tb_warn, port, fmt, ##arg)\n#define tb_port_info(port, fmt, arg...) \\\n\t__TB_PORT_PRINT(tb_info, port, fmt, ##arg)\n#define tb_port_dbg(port, fmt, arg...) \\\n\t__TB_PORT_PRINT(tb_dbg, port, fmt, ##arg)\n\nstruct tb *icm_probe(struct tb_nhi *nhi);\nstruct tb *tb_probe(struct tb_nhi *nhi);\n\nextern struct device_type tb_domain_type;\nextern struct device_type tb_retimer_type;\nextern struct device_type tb_switch_type;\nextern struct device_type usb4_port_device_type;\n\nint tb_domain_init(void);\nvoid tb_domain_exit(void);\nint tb_xdomain_init(void);\nvoid tb_xdomain_exit(void);\n\nstruct tb *tb_domain_alloc(struct tb_nhi *nhi, int timeout_msec, size_t privsize);\nint tb_domain_add(struct tb *tb);\nvoid tb_domain_remove(struct tb *tb);\nint tb_domain_suspend_noirq(struct tb *tb);\nint tb_domain_resume_noirq(struct tb *tb);\nint tb_domain_suspend(struct tb *tb);\nint tb_domain_freeze_noirq(struct tb *tb);\nint tb_domain_thaw_noirq(struct tb *tb);\nvoid tb_domain_complete(struct tb *tb);\nint tb_domain_runtime_suspend(struct tb *tb);\nint tb_domain_runtime_resume(struct tb *tb);\nint tb_domain_disapprove_switch(struct tb *tb, struct tb_switch *sw);\nint tb_domain_approve_switch(struct tb *tb, struct tb_switch *sw);\nint tb_domain_approve_switch_key(struct tb *tb, struct tb_switch *sw);\nint tb_domain_challenge_switch_key(struct tb *tb, struct tb_switch *sw);\nint tb_domain_disconnect_pcie_paths(struct tb *tb);\nint tb_domain_approve_xdomain_paths(struct tb *tb, struct tb_xdomain *xd,\n\t\t\t\t    int transmit_path, int transmit_ring,\n\t\t\t\t    int receive_path, int receive_ring);\nint tb_domain_disconnect_xdomain_paths(struct tb *tb, struct tb_xdomain *xd,\n\t\t\t\t       int transmit_path, int transmit_ring,\n\t\t\t\t       int receive_path, int receive_ring);\nint tb_domain_disconnect_all_paths(struct tb *tb);\n\nstatic inline struct tb *tb_domain_get(struct tb *tb)\n{\n\tif (tb)\n\t\tget_device(&tb->dev);\n\treturn tb;\n}\n\nstatic inline void tb_domain_put(struct tb *tb)\n{\n\tput_device(&tb->dev);\n}\n\nstruct tb_nvm *tb_nvm_alloc(struct device *dev);\nint tb_nvm_read_version(struct tb_nvm *nvm);\nint tb_nvm_validate(struct tb_nvm *nvm);\nint tb_nvm_write_headers(struct tb_nvm *nvm);\nint tb_nvm_add_active(struct tb_nvm *nvm, nvmem_reg_read_t reg_read);\nint tb_nvm_write_buf(struct tb_nvm *nvm, unsigned int offset, void *val,\n\t\t     size_t bytes);\nint tb_nvm_add_non_active(struct tb_nvm *nvm, nvmem_reg_write_t reg_write);\nvoid tb_nvm_free(struct tb_nvm *nvm);\nvoid tb_nvm_exit(void);\n\ntypedef int (*read_block_fn)(void *, unsigned int, void *, size_t);\ntypedef int (*write_block_fn)(void *, unsigned int, const void *, size_t);\n\nint tb_nvm_read_data(unsigned int address, void *buf, size_t size,\n\t\t     unsigned int retries, read_block_fn read_block,\n\t\t     void *read_block_data);\nint tb_nvm_write_data(unsigned int address, const void *buf, size_t size,\n\t\t      unsigned int retries, write_block_fn write_next_block,\n\t\t      void *write_block_data);\n\nint tb_switch_nvm_read(struct tb_switch *sw, unsigned int address, void *buf,\n\t\t       size_t size);\nstruct tb_switch *tb_switch_alloc(struct tb *tb, struct device *parent,\n\t\t\t\t  u64 route);\nstruct tb_switch *tb_switch_alloc_safe_mode(struct tb *tb,\n\t\t\tstruct device *parent, u64 route);\nint tb_switch_configure(struct tb_switch *sw);\nint tb_switch_configuration_valid(struct tb_switch *sw);\nint tb_switch_add(struct tb_switch *sw);\nvoid tb_switch_remove(struct tb_switch *sw);\nvoid tb_switch_suspend(struct tb_switch *sw, bool runtime);\nint tb_switch_resume(struct tb_switch *sw);\nint tb_switch_reset(struct tb_switch *sw);\nint tb_switch_wait_for_bit(struct tb_switch *sw, u32 offset, u32 bit,\n\t\t\t   u32 value, int timeout_msec);\nvoid tb_sw_set_unplugged(struct tb_switch *sw);\nstruct tb_port *tb_switch_find_port(struct tb_switch *sw,\n\t\t\t\t    enum tb_port_type type);\nstruct tb_switch *tb_switch_find_by_link_depth(struct tb *tb, u8 link,\n\t\t\t\t\t       u8 depth);\nstruct tb_switch *tb_switch_find_by_uuid(struct tb *tb, const uuid_t *uuid);\nstruct tb_switch *tb_switch_find_by_route(struct tb *tb, u64 route);\n\n \n#define tb_switch_for_each_port(sw, p)\t\t\t\t\t\\\n\tfor ((p) = &(sw)->ports[1];\t\t\t\t\t\\\n\t     (p) <= &(sw)->ports[(sw)->config.max_port_number]; (p)++)\n\nstatic inline struct tb_switch *tb_switch_get(struct tb_switch *sw)\n{\n\tif (sw)\n\t\tget_device(&sw->dev);\n\treturn sw;\n}\n\nstatic inline void tb_switch_put(struct tb_switch *sw)\n{\n\tput_device(&sw->dev);\n}\n\nstatic inline bool tb_is_switch(const struct device *dev)\n{\n\treturn dev->type == &tb_switch_type;\n}\n\nstatic inline struct tb_switch *tb_to_switch(const struct device *dev)\n{\n\tif (tb_is_switch(dev))\n\t\treturn container_of(dev, struct tb_switch, dev);\n\treturn NULL;\n}\n\nstatic inline struct tb_switch *tb_switch_parent(struct tb_switch *sw)\n{\n\treturn tb_to_switch(sw->dev.parent);\n}\n\n \nstatic inline struct tb_port *tb_switch_downstream_port(struct tb_switch *sw)\n{\n\tif (WARN_ON(!tb_route(sw)))\n\t\treturn NULL;\n\treturn tb_port_at(tb_route(sw), tb_switch_parent(sw));\n}\n\nstatic inline bool tb_switch_is_light_ridge(const struct tb_switch *sw)\n{\n\treturn sw->config.vendor_id == PCI_VENDOR_ID_INTEL &&\n\t       sw->config.device_id == PCI_DEVICE_ID_INTEL_LIGHT_RIDGE;\n}\n\nstatic inline bool tb_switch_is_eagle_ridge(const struct tb_switch *sw)\n{\n\treturn sw->config.vendor_id == PCI_VENDOR_ID_INTEL &&\n\t       sw->config.device_id == PCI_DEVICE_ID_INTEL_EAGLE_RIDGE;\n}\n\nstatic inline bool tb_switch_is_cactus_ridge(const struct tb_switch *sw)\n{\n\tif (sw->config.vendor_id == PCI_VENDOR_ID_INTEL) {\n\t\tswitch (sw->config.device_id) {\n\t\tcase PCI_DEVICE_ID_INTEL_CACTUS_RIDGE_2C:\n\t\tcase PCI_DEVICE_ID_INTEL_CACTUS_RIDGE_4C:\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstatic inline bool tb_switch_is_falcon_ridge(const struct tb_switch *sw)\n{\n\tif (sw->config.vendor_id == PCI_VENDOR_ID_INTEL) {\n\t\tswitch (sw->config.device_id) {\n\t\tcase PCI_DEVICE_ID_INTEL_FALCON_RIDGE_2C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_FALCON_RIDGE_4C_BRIDGE:\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstatic inline bool tb_switch_is_alpine_ridge(const struct tb_switch *sw)\n{\n\tif (sw->config.vendor_id == PCI_VENDOR_ID_INTEL) {\n\t\tswitch (sw->config.device_id) {\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_2C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_4C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_LP_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_4C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_2C_BRIDGE:\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstatic inline bool tb_switch_is_titan_ridge(const struct tb_switch *sw)\n{\n\tif (sw->config.vendor_id == PCI_VENDOR_ID_INTEL) {\n\t\tswitch (sw->config.device_id) {\n\t\tcase PCI_DEVICE_ID_INTEL_TITAN_RIDGE_2C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_TITAN_RIDGE_4C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_TITAN_RIDGE_DD_BRIDGE:\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstatic inline bool tb_switch_is_tiger_lake(const struct tb_switch *sw)\n{\n\tif (sw->config.vendor_id == PCI_VENDOR_ID_INTEL) {\n\t\tswitch (sw->config.device_id) {\n\t\tcase PCI_DEVICE_ID_INTEL_TGL_NHI0:\n\t\tcase PCI_DEVICE_ID_INTEL_TGL_NHI1:\n\t\tcase PCI_DEVICE_ID_INTEL_TGL_H_NHI0:\n\t\tcase PCI_DEVICE_ID_INTEL_TGL_H_NHI1:\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\n \nstatic inline bool tb_switch_is_icm(const struct tb_switch *sw)\n{\n\treturn !sw->config.enabled;\n}\n\nint tb_switch_lane_bonding_enable(struct tb_switch *sw);\nvoid tb_switch_lane_bonding_disable(struct tb_switch *sw);\nint tb_switch_configure_link(struct tb_switch *sw);\nvoid tb_switch_unconfigure_link(struct tb_switch *sw);\n\nbool tb_switch_query_dp_resource(struct tb_switch *sw, struct tb_port *in);\nint tb_switch_alloc_dp_resource(struct tb_switch *sw, struct tb_port *in);\nvoid tb_switch_dealloc_dp_resource(struct tb_switch *sw, struct tb_port *in);\n\nint tb_switch_tmu_init(struct tb_switch *sw);\nint tb_switch_tmu_post_time(struct tb_switch *sw);\nint tb_switch_tmu_disable(struct tb_switch *sw);\nint tb_switch_tmu_enable(struct tb_switch *sw);\nint tb_switch_tmu_configure(struct tb_switch *sw, enum tb_switch_tmu_mode mode);\n\n \nstatic inline bool tb_switch_tmu_is_configured(const struct tb_switch *sw,\n\t\t\t\t\t       enum tb_switch_tmu_mode mode)\n{\n\treturn sw->tmu.mode_request == mode;\n}\n\n \nstatic inline bool tb_switch_tmu_is_enabled(const struct tb_switch *sw)\n{\n\treturn sw->tmu.mode != TB_SWITCH_TMU_MODE_OFF &&\n\t       sw->tmu.mode == sw->tmu.mode_request;\n}\n\nbool tb_port_clx_is_enabled(struct tb_port *port, unsigned int clx);\n\nint tb_switch_clx_init(struct tb_switch *sw);\nbool tb_switch_clx_is_supported(const struct tb_switch *sw);\nint tb_switch_clx_enable(struct tb_switch *sw, unsigned int clx);\nint tb_switch_clx_disable(struct tb_switch *sw);\n\n \nstatic inline bool tb_switch_clx_is_enabled(const struct tb_switch *sw,\n\t\t\t\t\t    unsigned int clx)\n{\n\treturn sw->clx & clx;\n}\n\nint tb_switch_pcie_l1_enable(struct tb_switch *sw);\n\nint tb_switch_xhci_connect(struct tb_switch *sw);\nvoid tb_switch_xhci_disconnect(struct tb_switch *sw);\n\nint tb_port_state(struct tb_port *port);\nint tb_wait_for_port(struct tb_port *port, bool wait_if_unplugged);\nint tb_port_add_nfc_credits(struct tb_port *port, int credits);\nint tb_port_clear_counter(struct tb_port *port, int counter);\nint tb_port_unlock(struct tb_port *port);\nint tb_port_enable(struct tb_port *port);\nint tb_port_disable(struct tb_port *port);\nint tb_port_alloc_in_hopid(struct tb_port *port, int hopid, int max_hopid);\nvoid tb_port_release_in_hopid(struct tb_port *port, int hopid);\nint tb_port_alloc_out_hopid(struct tb_port *port, int hopid, int max_hopid);\nvoid tb_port_release_out_hopid(struct tb_port *port, int hopid);\nstruct tb_port *tb_next_port_on_path(struct tb_port *start, struct tb_port *end,\n\t\t\t\t     struct tb_port *prev);\n\nstatic inline bool tb_port_use_credit_allocation(const struct tb_port *port)\n{\n\treturn tb_port_is_null(port) && port->sw->credit_allocation;\n}\n\n \n#define tb_for_each_port_on_path(src, dst, p)\t\t\t\t\\\n\tfor ((p) = tb_next_port_on_path((src), (dst), NULL); (p);\t\\\n\t     (p) = tb_next_port_on_path((src), (dst), (p)))\n\nint tb_port_get_link_speed(struct tb_port *port);\nint tb_port_get_link_width(struct tb_port *port);\nint tb_port_set_link_width(struct tb_port *port, enum tb_link_width width);\nint tb_port_lane_bonding_enable(struct tb_port *port);\nvoid tb_port_lane_bonding_disable(struct tb_port *port);\nint tb_port_wait_for_link_width(struct tb_port *port, unsigned int width_mask,\n\t\t\t\tint timeout_msec);\nint tb_port_update_credits(struct tb_port *port);\n\nint tb_switch_find_vse_cap(struct tb_switch *sw, enum tb_switch_vse_cap vsec);\nint tb_switch_find_cap(struct tb_switch *sw, enum tb_switch_cap cap);\nint tb_switch_next_cap(struct tb_switch *sw, unsigned int offset);\nint tb_port_find_cap(struct tb_port *port, enum tb_port_cap cap);\nint tb_port_next_cap(struct tb_port *port, unsigned int offset);\nbool tb_port_is_enabled(struct tb_port *port);\n\nbool tb_usb3_port_is_enabled(struct tb_port *port);\nint tb_usb3_port_enable(struct tb_port *port, bool enable);\n\nbool tb_pci_port_is_enabled(struct tb_port *port);\nint tb_pci_port_enable(struct tb_port *port, bool enable);\n\nint tb_dp_port_hpd_is_active(struct tb_port *port);\nint tb_dp_port_hpd_clear(struct tb_port *port);\nint tb_dp_port_set_hops(struct tb_port *port, unsigned int video,\n\t\t\tunsigned int aux_tx, unsigned int aux_rx);\nbool tb_dp_port_is_enabled(struct tb_port *port);\nint tb_dp_port_enable(struct tb_port *port, bool enable);\n\nstruct tb_path *tb_path_discover(struct tb_port *src, int src_hopid,\n\t\t\t\t struct tb_port *dst, int dst_hopid,\n\t\t\t\t struct tb_port **last, const char *name,\n\t\t\t\t bool alloc_hopid);\nstruct tb_path *tb_path_alloc(struct tb *tb, struct tb_port *src, int src_hopid,\n\t\t\t      struct tb_port *dst, int dst_hopid, int link_nr,\n\t\t\t      const char *name);\nvoid tb_path_free(struct tb_path *path);\nint tb_path_activate(struct tb_path *path);\nvoid tb_path_deactivate(struct tb_path *path);\nbool tb_path_is_invalid(struct tb_path *path);\nbool tb_path_port_on_path(const struct tb_path *path,\n\t\t\t  const struct tb_port *port);\n\n \n#define tb_path_for_each_hop(path, hop)\t\t\t\t\t\\\n\tfor ((hop) = &(path)->hops[0];\t\t\t\t\t\\\n\t     (hop) <= &(path)->hops[(path)->path_length - 1]; (hop)++)\n\nint tb_drom_read(struct tb_switch *sw);\nint tb_drom_read_uid_only(struct tb_switch *sw, u64 *uid);\n\nint tb_lc_read_uuid(struct tb_switch *sw, u32 *uuid);\nint tb_lc_configure_port(struct tb_port *port);\nvoid tb_lc_unconfigure_port(struct tb_port *port);\nint tb_lc_configure_xdomain(struct tb_port *port);\nvoid tb_lc_unconfigure_xdomain(struct tb_port *port);\nint tb_lc_start_lane_initialization(struct tb_port *port);\nbool tb_lc_is_clx_supported(struct tb_port *port);\nbool tb_lc_is_usb_plugged(struct tb_port *port);\nbool tb_lc_is_xhci_connected(struct tb_port *port);\nint tb_lc_xhci_connect(struct tb_port *port);\nvoid tb_lc_xhci_disconnect(struct tb_port *port);\nint tb_lc_set_wake(struct tb_switch *sw, unsigned int flags);\nint tb_lc_set_sleep(struct tb_switch *sw);\nbool tb_lc_lane_bonding_possible(struct tb_switch *sw);\nbool tb_lc_dp_sink_query(struct tb_switch *sw, struct tb_port *in);\nint tb_lc_dp_sink_alloc(struct tb_switch *sw, struct tb_port *in);\nint tb_lc_dp_sink_dealloc(struct tb_switch *sw, struct tb_port *in);\nint tb_lc_force_power(struct tb_switch *sw);\n\nstatic inline int tb_route_length(u64 route)\n{\n\treturn (fls64(route) + TB_ROUTE_SHIFT - 1) / TB_ROUTE_SHIFT;\n}\n\n \nstatic inline u64 tb_downstream_route(struct tb_port *port)\n{\n\treturn tb_route(port->sw)\n\t       | ((u64) port->port << (port->sw->config.depth * 8));\n}\n\nbool tb_is_xdomain_enabled(void);\nbool tb_xdomain_handle_request(struct tb *tb, enum tb_cfg_pkg_type type,\n\t\t\t       const void *buf, size_t size);\nstruct tb_xdomain *tb_xdomain_alloc(struct tb *tb, struct device *parent,\n\t\t\t\t    u64 route, const uuid_t *local_uuid,\n\t\t\t\t    const uuid_t *remote_uuid);\nvoid tb_xdomain_add(struct tb_xdomain *xd);\nvoid tb_xdomain_remove(struct tb_xdomain *xd);\nstruct tb_xdomain *tb_xdomain_find_by_link_depth(struct tb *tb, u8 link,\n\t\t\t\t\t\t u8 depth);\n\nstatic inline struct tb_switch *tb_xdomain_parent(struct tb_xdomain *xd)\n{\n\treturn tb_to_switch(xd->dev.parent);\n}\n\n \nstatic inline struct tb_port *tb_xdomain_downstream_port(struct tb_xdomain *xd)\n{\n\treturn tb_port_at(xd->route, tb_xdomain_parent(xd));\n}\n\nint tb_retimer_nvm_read(struct tb_retimer *rt, unsigned int address, void *buf,\n\t\t\tsize_t size);\nint tb_retimer_scan(struct tb_port *port, bool add);\nvoid tb_retimer_remove_all(struct tb_port *port);\n\nstatic inline bool tb_is_retimer(const struct device *dev)\n{\n\treturn dev->type == &tb_retimer_type;\n}\n\nstatic inline struct tb_retimer *tb_to_retimer(struct device *dev)\n{\n\tif (tb_is_retimer(dev))\n\t\treturn container_of(dev, struct tb_retimer, dev);\n\treturn NULL;\n}\n\n \nstatic inline unsigned int usb4_switch_version(const struct tb_switch *sw)\n{\n\treturn FIELD_GET(USB4_VERSION_MAJOR_MASK, sw->config.thunderbolt_version);\n}\n\n \nstatic inline bool tb_switch_is_usb4(const struct tb_switch *sw)\n{\n\treturn usb4_switch_version(sw) > 0;\n}\n\nint usb4_switch_setup(struct tb_switch *sw);\nint usb4_switch_configuration_valid(struct tb_switch *sw);\nint usb4_switch_read_uid(struct tb_switch *sw, u64 *uid);\nint usb4_switch_drom_read(struct tb_switch *sw, unsigned int address, void *buf,\n\t\t\t  size_t size);\nbool usb4_switch_lane_bonding_possible(struct tb_switch *sw);\nint usb4_switch_set_wake(struct tb_switch *sw, unsigned int flags);\nint usb4_switch_set_sleep(struct tb_switch *sw);\nint usb4_switch_nvm_sector_size(struct tb_switch *sw);\nint usb4_switch_nvm_read(struct tb_switch *sw, unsigned int address, void *buf,\n\t\t\t size_t size);\nint usb4_switch_nvm_set_offset(struct tb_switch *sw, unsigned int address);\nint usb4_switch_nvm_write(struct tb_switch *sw, unsigned int address,\n\t\t\t  const void *buf, size_t size);\nint usb4_switch_nvm_authenticate(struct tb_switch *sw);\nint usb4_switch_nvm_authenticate_status(struct tb_switch *sw, u32 *status);\nint usb4_switch_credits_init(struct tb_switch *sw);\nbool usb4_switch_query_dp_resource(struct tb_switch *sw, struct tb_port *in);\nint usb4_switch_alloc_dp_resource(struct tb_switch *sw, struct tb_port *in);\nint usb4_switch_dealloc_dp_resource(struct tb_switch *sw, struct tb_port *in);\nstruct tb_port *usb4_switch_map_pcie_down(struct tb_switch *sw,\n\t\t\t\t\t  const struct tb_port *port);\nstruct tb_port *usb4_switch_map_usb3_down(struct tb_switch *sw,\n\t\t\t\t\t  const struct tb_port *port);\nint usb4_switch_add_ports(struct tb_switch *sw);\nvoid usb4_switch_remove_ports(struct tb_switch *sw);\n\nint usb4_port_unlock(struct tb_port *port);\nint usb4_port_hotplug_enable(struct tb_port *port);\nint usb4_port_configure(struct tb_port *port);\nvoid usb4_port_unconfigure(struct tb_port *port);\nint usb4_port_configure_xdomain(struct tb_port *port, struct tb_xdomain *xd);\nvoid usb4_port_unconfigure_xdomain(struct tb_port *port);\nint usb4_port_router_offline(struct tb_port *port);\nint usb4_port_router_online(struct tb_port *port);\nint usb4_port_enumerate_retimers(struct tb_port *port);\nbool usb4_port_clx_supported(struct tb_port *port);\nint usb4_port_margining_caps(struct tb_port *port, u32 *caps);\nint usb4_port_hw_margin(struct tb_port *port, unsigned int lanes,\n\t\t\tunsigned int ber_level, bool timing, bool right_high,\n\t\t\tu32 *results);\nint usb4_port_sw_margin(struct tb_port *port, unsigned int lanes, bool timing,\n\t\t\tbool right_high, u32 counter);\nint usb4_port_sw_margin_errors(struct tb_port *port, u32 *errors);\n\nint usb4_port_retimer_set_inbound_sbtx(struct tb_port *port, u8 index);\nint usb4_port_retimer_unset_inbound_sbtx(struct tb_port *port, u8 index);\nint usb4_port_retimer_read(struct tb_port *port, u8 index, u8 reg, void *buf,\n\t\t\t   u8 size);\nint usb4_port_retimer_write(struct tb_port *port, u8 index, u8 reg,\n\t\t\t    const void *buf, u8 size);\nint usb4_port_retimer_is_last(struct tb_port *port, u8 index);\nint usb4_port_retimer_nvm_sector_size(struct tb_port *port, u8 index);\nint usb4_port_retimer_nvm_set_offset(struct tb_port *port, u8 index,\n\t\t\t\t     unsigned int address);\nint usb4_port_retimer_nvm_write(struct tb_port *port, u8 index,\n\t\t\t\tunsigned int address, const void *buf,\n\t\t\t\tsize_t size);\nint usb4_port_retimer_nvm_authenticate(struct tb_port *port, u8 index);\nint usb4_port_retimer_nvm_authenticate_status(struct tb_port *port, u8 index,\n\t\t\t\t\t      u32 *status);\nint usb4_port_retimer_nvm_read(struct tb_port *port, u8 index,\n\t\t\t       unsigned int address, void *buf, size_t size);\n\nint usb4_usb3_port_max_link_rate(struct tb_port *port);\nint usb4_usb3_port_actual_link_rate(struct tb_port *port);\nint usb4_usb3_port_allocated_bandwidth(struct tb_port *port, int *upstream_bw,\n\t\t\t\t       int *downstream_bw);\nint usb4_usb3_port_allocate_bandwidth(struct tb_port *port, int *upstream_bw,\n\t\t\t\t      int *downstream_bw);\nint usb4_usb3_port_release_bandwidth(struct tb_port *port, int *upstream_bw,\n\t\t\t\t     int *downstream_bw);\n\nint usb4_dp_port_set_cm_id(struct tb_port *port, int cm_id);\nbool usb4_dp_port_bandwidth_mode_supported(struct tb_port *port);\nbool usb4_dp_port_bandwidth_mode_enabled(struct tb_port *port);\nint usb4_dp_port_set_cm_bandwidth_mode_supported(struct tb_port *port,\n\t\t\t\t\t\t bool supported);\nint usb4_dp_port_group_id(struct tb_port *port);\nint usb4_dp_port_set_group_id(struct tb_port *port, int group_id);\nint usb4_dp_port_nrd(struct tb_port *port, int *rate, int *lanes);\nint usb4_dp_port_set_nrd(struct tb_port *port, int rate, int lanes);\nint usb4_dp_port_granularity(struct tb_port *port);\nint usb4_dp_port_set_granularity(struct tb_port *port, int granularity);\nint usb4_dp_port_set_estimated_bandwidth(struct tb_port *port, int bw);\nint usb4_dp_port_allocated_bandwidth(struct tb_port *port);\nint usb4_dp_port_allocate_bandwidth(struct tb_port *port, int bw);\nint usb4_dp_port_requested_bandwidth(struct tb_port *port);\n\nint usb4_pci_port_set_ext_encapsulation(struct tb_port *port, bool enable);\n\nstatic inline bool tb_is_usb4_port_device(const struct device *dev)\n{\n\treturn dev->type == &usb4_port_device_type;\n}\n\nstatic inline struct usb4_port *tb_to_usb4_port_device(struct device *dev)\n{\n\tif (tb_is_usb4_port_device(dev))\n\t\treturn container_of(dev, struct usb4_port, dev);\n\treturn NULL;\n}\n\nstruct usb4_port *usb4_port_device_add(struct tb_port *port);\nvoid usb4_port_device_remove(struct usb4_port *usb4);\nint usb4_port_device_resume(struct usb4_port *usb4);\n\nstatic inline bool usb4_port_device_is_offline(const struct usb4_port *usb4)\n{\n\treturn usb4->offline;\n}\n\nvoid tb_check_quirks(struct tb_switch *sw);\n\n#ifdef CONFIG_ACPI\nbool tb_acpi_add_links(struct tb_nhi *nhi);\n\nbool tb_acpi_is_native(void);\nbool tb_acpi_may_tunnel_usb3(void);\nbool tb_acpi_may_tunnel_dp(void);\nbool tb_acpi_may_tunnel_pcie(void);\nbool tb_acpi_is_xdomain_allowed(void);\n\nint tb_acpi_init(void);\nvoid tb_acpi_exit(void);\nint tb_acpi_power_on_retimers(struct tb_port *port);\nint tb_acpi_power_off_retimers(struct tb_port *port);\n#else\nstatic inline bool tb_acpi_add_links(struct tb_nhi *nhi) { return false; }\n\nstatic inline bool tb_acpi_is_native(void) { return true; }\nstatic inline bool tb_acpi_may_tunnel_usb3(void) { return true; }\nstatic inline bool tb_acpi_may_tunnel_dp(void) { return true; }\nstatic inline bool tb_acpi_may_tunnel_pcie(void) { return true; }\nstatic inline bool tb_acpi_is_xdomain_allowed(void) { return true; }\n\nstatic inline int tb_acpi_init(void) { return 0; }\nstatic inline void tb_acpi_exit(void) { }\nstatic inline int tb_acpi_power_on_retimers(struct tb_port *port) { return 0; }\nstatic inline int tb_acpi_power_off_retimers(struct tb_port *port) { return 0; }\n#endif\n\n#ifdef CONFIG_DEBUG_FS\nvoid tb_debugfs_init(void);\nvoid tb_debugfs_exit(void);\nvoid tb_switch_debugfs_init(struct tb_switch *sw);\nvoid tb_switch_debugfs_remove(struct tb_switch *sw);\nvoid tb_xdomain_debugfs_init(struct tb_xdomain *xd);\nvoid tb_xdomain_debugfs_remove(struct tb_xdomain *xd);\nvoid tb_service_debugfs_init(struct tb_service *svc);\nvoid tb_service_debugfs_remove(struct tb_service *svc);\n#else\nstatic inline void tb_debugfs_init(void) { }\nstatic inline void tb_debugfs_exit(void) { }\nstatic inline void tb_switch_debugfs_init(struct tb_switch *sw) { }\nstatic inline void tb_switch_debugfs_remove(struct tb_switch *sw) { }\nstatic inline void tb_xdomain_debugfs_init(struct tb_xdomain *xd) { }\nstatic inline void tb_xdomain_debugfs_remove(struct tb_xdomain *xd) { }\nstatic inline void tb_service_debugfs_init(struct tb_service *svc) { }\nstatic inline void tb_service_debugfs_remove(struct tb_service *svc) { }\n#endif\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}