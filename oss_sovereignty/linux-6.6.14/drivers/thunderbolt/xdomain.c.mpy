{
  "module_name": "xdomain.c",
  "hash_id": "bb2e1aee512eeded256e7ec9eecfb2c75f301b40ce29c25cf4c373b67f0a1924",
  "original_prompt": "Ingested from linux-6.6.14/drivers/thunderbolt/xdomain.c",
  "human_readable_source": "\n \n\n#include <linux/device.h>\n#include <linux/delay.h>\n#include <linux/kmod.h>\n#include <linux/module.h>\n#include <linux/pm_runtime.h>\n#include <linux/prandom.h>\n#include <linux/string_helpers.h>\n#include <linux/utsname.h>\n#include <linux/uuid.h>\n#include <linux/workqueue.h>\n\n#include \"tb.h\"\n\n#define XDOMAIN_SHORT_TIMEOUT\t\t\t100\t \n#define XDOMAIN_DEFAULT_TIMEOUT\t\t\t1000\t \n#define XDOMAIN_BONDING_TIMEOUT\t\t\t10000\t \n#define XDOMAIN_RETRIES\t\t\t\t10\n#define XDOMAIN_DEFAULT_MAX_HOPID\t\t15\n\nenum {\n\tXDOMAIN_STATE_INIT,\n\tXDOMAIN_STATE_UUID,\n\tXDOMAIN_STATE_LINK_STATUS,\n\tXDOMAIN_STATE_LINK_STATE_CHANGE,\n\tXDOMAIN_STATE_LINK_STATUS2,\n\tXDOMAIN_STATE_BONDING_UUID_LOW,\n\tXDOMAIN_STATE_BONDING_UUID_HIGH,\n\tXDOMAIN_STATE_PROPERTIES,\n\tXDOMAIN_STATE_ENUMERATED,\n\tXDOMAIN_STATE_ERROR,\n};\n\nstatic const char * const state_names[] = {\n\t[XDOMAIN_STATE_INIT] = \"INIT\",\n\t[XDOMAIN_STATE_UUID] = \"UUID\",\n\t[XDOMAIN_STATE_LINK_STATUS] = \"LINK_STATUS\",\n\t[XDOMAIN_STATE_LINK_STATE_CHANGE] = \"LINK_STATE_CHANGE\",\n\t[XDOMAIN_STATE_LINK_STATUS2] = \"LINK_STATUS2\",\n\t[XDOMAIN_STATE_BONDING_UUID_LOW] = \"BONDING_UUID_LOW\",\n\t[XDOMAIN_STATE_BONDING_UUID_HIGH] = \"BONDING_UUID_HIGH\",\n\t[XDOMAIN_STATE_PROPERTIES] = \"PROPERTIES\",\n\t[XDOMAIN_STATE_ENUMERATED] = \"ENUMERATED\",\n\t[XDOMAIN_STATE_ERROR] = \"ERROR\",\n};\n\nstruct xdomain_request_work {\n\tstruct work_struct work;\n\tstruct tb_xdp_header *pkg;\n\tstruct tb *tb;\n};\n\nstatic bool tb_xdomain_enabled = true;\nmodule_param_named(xdomain, tb_xdomain_enabled, bool, 0444);\nMODULE_PARM_DESC(xdomain, \"allow XDomain protocol (default: true)\");\n\n \nstatic DEFINE_MUTEX(xdomain_lock);\n\n \nstatic struct tb_property_dir *xdomain_property_dir;\nstatic u32 xdomain_property_block_gen;\n\n \nstatic LIST_HEAD(protocol_handlers);\n\n \nstatic const uuid_t tb_xdp_uuid =\n\tUUID_INIT(0xb638d70e, 0x42ff, 0x40bb,\n\t\t  0x97, 0xc2, 0x90, 0xe2, 0xc0, 0xb2, 0xff, 0x07);\n\nbool tb_is_xdomain_enabled(void)\n{\n\treturn tb_xdomain_enabled && tb_acpi_is_xdomain_allowed();\n}\n\nstatic bool tb_xdomain_match(const struct tb_cfg_request *req,\n\t\t\t     const struct ctl_pkg *pkg)\n{\n\tswitch (pkg->frame.eof) {\n\tcase TB_CFG_PKG_ERROR:\n\t\treturn true;\n\n\tcase TB_CFG_PKG_XDOMAIN_RESP: {\n\t\tconst struct tb_xdp_header *res_hdr = pkg->buffer;\n\t\tconst struct tb_xdp_header *req_hdr = req->request;\n\n\t\tif (pkg->frame.size < req->response_size / 4)\n\t\t\treturn false;\n\n\t\t \n\t\tif ((res_hdr->xd_hdr.route_hi & ~BIT(31)) !=\n\t\t     req_hdr->xd_hdr.route_hi)\n\t\t\treturn false;\n\t\tif ((res_hdr->xd_hdr.route_lo) != req_hdr->xd_hdr.route_lo)\n\t\t\treturn false;\n\n\t\t \n\t\tif (!uuid_equal(&res_hdr->uuid, &req_hdr->uuid))\n\t\t\treturn false;\n\n\t\treturn true;\n\t}\n\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic bool tb_xdomain_copy(struct tb_cfg_request *req,\n\t\t\t    const struct ctl_pkg *pkg)\n{\n\tmemcpy(req->response, pkg->buffer, req->response_size);\n\treq->result.err = 0;\n\treturn true;\n}\n\nstatic void response_ready(void *data)\n{\n\ttb_cfg_request_put(data);\n}\n\nstatic int __tb_xdomain_response(struct tb_ctl *ctl, const void *response,\n\t\t\t\t size_t size, enum tb_cfg_pkg_type type)\n{\n\tstruct tb_cfg_request *req;\n\n\treq = tb_cfg_request_alloc();\n\tif (!req)\n\t\treturn -ENOMEM;\n\n\treq->match = tb_xdomain_match;\n\treq->copy = tb_xdomain_copy;\n\treq->request = response;\n\treq->request_size = size;\n\treq->request_type = type;\n\n\treturn tb_cfg_request(ctl, req, response_ready, req);\n}\n\n \nint tb_xdomain_response(struct tb_xdomain *xd, const void *response,\n\t\t\tsize_t size, enum tb_cfg_pkg_type type)\n{\n\treturn __tb_xdomain_response(xd->tb->ctl, response, size, type);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_response);\n\nstatic int __tb_xdomain_request(struct tb_ctl *ctl, const void *request,\n\tsize_t request_size, enum tb_cfg_pkg_type request_type, void *response,\n\tsize_t response_size, enum tb_cfg_pkg_type response_type,\n\tunsigned int timeout_msec)\n{\n\tstruct tb_cfg_request *req;\n\tstruct tb_cfg_result res;\n\n\treq = tb_cfg_request_alloc();\n\tif (!req)\n\t\treturn -ENOMEM;\n\n\treq->match = tb_xdomain_match;\n\treq->copy = tb_xdomain_copy;\n\treq->request = request;\n\treq->request_size = request_size;\n\treq->request_type = request_type;\n\treq->response = response;\n\treq->response_size = response_size;\n\treq->response_type = response_type;\n\n\tres = tb_cfg_request_sync(ctl, req, timeout_msec);\n\n\ttb_cfg_request_put(req);\n\n\treturn res.err == 1 ? -EIO : res.err;\n}\n\n \nint tb_xdomain_request(struct tb_xdomain *xd, const void *request,\n\tsize_t request_size, enum tb_cfg_pkg_type request_type,\n\tvoid *response, size_t response_size,\n\tenum tb_cfg_pkg_type response_type, unsigned int timeout_msec)\n{\n\treturn __tb_xdomain_request(xd->tb->ctl, request, request_size,\n\t\t\t\t    request_type, response, response_size,\n\t\t\t\t    response_type, timeout_msec);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_request);\n\nstatic inline void tb_xdp_fill_header(struct tb_xdp_header *hdr, u64 route,\n\tu8 sequence, enum tb_xdp_type type, size_t size)\n{\n\tu32 length_sn;\n\n\tlength_sn = (size - sizeof(hdr->xd_hdr)) / 4;\n\tlength_sn |= (sequence << TB_XDOMAIN_SN_SHIFT) & TB_XDOMAIN_SN_MASK;\n\n\thdr->xd_hdr.route_hi = upper_32_bits(route);\n\thdr->xd_hdr.route_lo = lower_32_bits(route);\n\thdr->xd_hdr.length_sn = length_sn;\n\thdr->type = type;\n\tmemcpy(&hdr->uuid, &tb_xdp_uuid, sizeof(tb_xdp_uuid));\n}\n\nstatic int tb_xdp_handle_error(const struct tb_xdp_error_response *res)\n{\n\tif (res->hdr.type != ERROR_RESPONSE)\n\t\treturn 0;\n\n\tswitch (res->error) {\n\tcase ERROR_UNKNOWN_PACKET:\n\tcase ERROR_UNKNOWN_DOMAIN:\n\t\treturn -EIO;\n\tcase ERROR_NOT_SUPPORTED:\n\t\treturn -ENOTSUPP;\n\tcase ERROR_NOT_READY:\n\t\treturn -EAGAIN;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic int tb_xdp_uuid_request(struct tb_ctl *ctl, u64 route, int retry,\n\t\t\t       uuid_t *uuid, u64 *remote_route)\n{\n\tstruct tb_xdp_uuid_response res;\n\tstruct tb_xdp_uuid req;\n\tint ret;\n\n\tmemset(&req, 0, sizeof(req));\n\ttb_xdp_fill_header(&req.hdr, route, retry % 4, UUID_REQUEST,\n\t\t\t   sizeof(req));\n\n\tmemset(&res, 0, sizeof(res));\n\tret = __tb_xdomain_request(ctl, &req, sizeof(req),\n\t\t\t\t   TB_CFG_PKG_XDOMAIN_REQ, &res, sizeof(res),\n\t\t\t\t   TB_CFG_PKG_XDOMAIN_RESP,\n\t\t\t\t   XDOMAIN_DEFAULT_TIMEOUT);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_xdp_handle_error(&res.err);\n\tif (ret)\n\t\treturn ret;\n\n\tuuid_copy(uuid, &res.src_uuid);\n\t*remote_route = (u64)res.src_route_hi << 32 | res.src_route_lo;\n\n\treturn 0;\n}\n\nstatic int tb_xdp_uuid_response(struct tb_ctl *ctl, u64 route, u8 sequence,\n\t\t\t\tconst uuid_t *uuid)\n{\n\tstruct tb_xdp_uuid_response res;\n\n\tmemset(&res, 0, sizeof(res));\n\ttb_xdp_fill_header(&res.hdr, route, sequence, UUID_RESPONSE,\n\t\t\t   sizeof(res));\n\n\tuuid_copy(&res.src_uuid, uuid);\n\tres.src_route_hi = upper_32_bits(route);\n\tres.src_route_lo = lower_32_bits(route);\n\n\treturn __tb_xdomain_response(ctl, &res, sizeof(res),\n\t\t\t\t     TB_CFG_PKG_XDOMAIN_RESP);\n}\n\nstatic int tb_xdp_error_response(struct tb_ctl *ctl, u64 route, u8 sequence,\n\t\t\t\t enum tb_xdp_error error)\n{\n\tstruct tb_xdp_error_response res;\n\n\tmemset(&res, 0, sizeof(res));\n\ttb_xdp_fill_header(&res.hdr, route, sequence, ERROR_RESPONSE,\n\t\t\t   sizeof(res));\n\tres.error = error;\n\n\treturn __tb_xdomain_response(ctl, &res, sizeof(res),\n\t\t\t\t     TB_CFG_PKG_XDOMAIN_RESP);\n}\n\nstatic int tb_xdp_properties_request(struct tb_ctl *ctl, u64 route,\n\tconst uuid_t *src_uuid, const uuid_t *dst_uuid, int retry,\n\tu32 **block, u32 *generation)\n{\n\tstruct tb_xdp_properties_response *res;\n\tstruct tb_xdp_properties req;\n\tu16 data_len, len;\n\tsize_t total_size;\n\tu32 *data = NULL;\n\tint ret;\n\n\ttotal_size = sizeof(*res) + TB_XDP_PROPERTIES_MAX_DATA_LENGTH * 4;\n\tres = kzalloc(total_size, GFP_KERNEL);\n\tif (!res)\n\t\treturn -ENOMEM;\n\n\tmemset(&req, 0, sizeof(req));\n\ttb_xdp_fill_header(&req.hdr, route, retry % 4, PROPERTIES_REQUEST,\n\t\t\t   sizeof(req));\n\tmemcpy(&req.src_uuid, src_uuid, sizeof(*src_uuid));\n\tmemcpy(&req.dst_uuid, dst_uuid, sizeof(*dst_uuid));\n\n\tdata_len = 0;\n\n\tdo {\n\t\tret = __tb_xdomain_request(ctl, &req, sizeof(req),\n\t\t\t\t\t   TB_CFG_PKG_XDOMAIN_REQ, res,\n\t\t\t\t\t   total_size, TB_CFG_PKG_XDOMAIN_RESP,\n\t\t\t\t\t   XDOMAIN_DEFAULT_TIMEOUT);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tret = tb_xdp_handle_error(&res->err);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\t \n\t\tlen = res->hdr.xd_hdr.length_sn & TB_XDOMAIN_LENGTH_MASK;\n\t\tif (len < sizeof(*res) / 4) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\n\t\tlen += sizeof(res->hdr.xd_hdr) / 4;\n\t\tlen -= sizeof(*res) / 4;\n\n\t\tif (res->offset != req.offset) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\n\t\t \n\t\tif (!data) {\n\t\t\tdata_len = res->data_length;\n\t\t\tif (data_len > TB_XDP_PROPERTIES_MAX_LENGTH) {\n\t\t\t\tret = -E2BIG;\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tdata = kcalloc(data_len, sizeof(u32), GFP_KERNEL);\n\t\t\tif (!data) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t\tmemcpy(data + req.offset, res->data, len * 4);\n\t\treq.offset += len;\n\t} while (!data_len || req.offset < data_len);\n\n\t*block = data;\n\t*generation = res->generation;\n\n\tkfree(res);\n\n\treturn data_len;\n\nerr:\n\tkfree(data);\n\tkfree(res);\n\n\treturn ret;\n}\n\nstatic int tb_xdp_properties_response(struct tb *tb, struct tb_ctl *ctl,\n\tstruct tb_xdomain *xd, u8 sequence, const struct tb_xdp_properties *req)\n{\n\tstruct tb_xdp_properties_response *res;\n\tsize_t total_size;\n\tu16 len;\n\tint ret;\n\n\t \n\tif (!uuid_equal(xd->local_uuid, &req->dst_uuid)) {\n\t\ttb_xdp_error_response(ctl, xd->route, sequence,\n\t\t\t\t      ERROR_UNKNOWN_DOMAIN);\n\t\treturn 0;\n\t}\n\n\tmutex_lock(&xd->lock);\n\n\tif (req->offset >= xd->local_property_block_len) {\n\t\tmutex_unlock(&xd->lock);\n\t\treturn -EINVAL;\n\t}\n\n\tlen = xd->local_property_block_len - req->offset;\n\tlen = min_t(u16, len, TB_XDP_PROPERTIES_MAX_DATA_LENGTH);\n\ttotal_size = sizeof(*res) + len * 4;\n\n\tres = kzalloc(total_size, GFP_KERNEL);\n\tif (!res) {\n\t\tmutex_unlock(&xd->lock);\n\t\treturn -ENOMEM;\n\t}\n\n\ttb_xdp_fill_header(&res->hdr, xd->route, sequence, PROPERTIES_RESPONSE,\n\t\t\t   total_size);\n\tres->generation = xd->local_property_block_gen;\n\tres->data_length = xd->local_property_block_len;\n\tres->offset = req->offset;\n\tuuid_copy(&res->src_uuid, xd->local_uuid);\n\tuuid_copy(&res->dst_uuid, &req->src_uuid);\n\tmemcpy(res->data, &xd->local_property_block[req->offset], len * 4);\n\n\tmutex_unlock(&xd->lock);\n\n\tret = __tb_xdomain_response(ctl, res, total_size,\n\t\t\t\t    TB_CFG_PKG_XDOMAIN_RESP);\n\n\tkfree(res);\n\treturn ret;\n}\n\nstatic int tb_xdp_properties_changed_request(struct tb_ctl *ctl, u64 route,\n\t\t\t\t\t     int retry, const uuid_t *uuid)\n{\n\tstruct tb_xdp_properties_changed_response res;\n\tstruct tb_xdp_properties_changed req;\n\tint ret;\n\n\tmemset(&req, 0, sizeof(req));\n\ttb_xdp_fill_header(&req.hdr, route, retry % 4,\n\t\t\t   PROPERTIES_CHANGED_REQUEST, sizeof(req));\n\tuuid_copy(&req.src_uuid, uuid);\n\n\tmemset(&res, 0, sizeof(res));\n\tret = __tb_xdomain_request(ctl, &req, sizeof(req),\n\t\t\t\t   TB_CFG_PKG_XDOMAIN_REQ, &res, sizeof(res),\n\t\t\t\t   TB_CFG_PKG_XDOMAIN_RESP,\n\t\t\t\t   XDOMAIN_DEFAULT_TIMEOUT);\n\tif (ret)\n\t\treturn ret;\n\n\treturn tb_xdp_handle_error(&res.err);\n}\n\nstatic int\ntb_xdp_properties_changed_response(struct tb_ctl *ctl, u64 route, u8 sequence)\n{\n\tstruct tb_xdp_properties_changed_response res;\n\n\tmemset(&res, 0, sizeof(res));\n\ttb_xdp_fill_header(&res.hdr, route, sequence,\n\t\t\t   PROPERTIES_CHANGED_RESPONSE, sizeof(res));\n\treturn __tb_xdomain_response(ctl, &res, sizeof(res),\n\t\t\t\t     TB_CFG_PKG_XDOMAIN_RESP);\n}\n\nstatic int tb_xdp_link_state_status_request(struct tb_ctl *ctl, u64 route,\n\t\t\t\t\t    u8 sequence, u8 *slw, u8 *tlw,\n\t\t\t\t\t    u8 *sls, u8 *tls)\n{\n\tstruct tb_xdp_link_state_status_response res;\n\tstruct tb_xdp_link_state_status req;\n\tint ret;\n\n\tmemset(&req, 0, sizeof(req));\n\ttb_xdp_fill_header(&req.hdr, route, sequence, LINK_STATE_STATUS_REQUEST,\n\t\t\t   sizeof(req));\n\n\tmemset(&res, 0, sizeof(res));\n\tret = __tb_xdomain_request(ctl, &req, sizeof(req), TB_CFG_PKG_XDOMAIN_REQ,\n\t\t\t\t   &res, sizeof(res), TB_CFG_PKG_XDOMAIN_RESP,\n\t\t\t\t   XDOMAIN_DEFAULT_TIMEOUT);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_xdp_handle_error(&res.err);\n\tif (ret)\n\t\treturn ret;\n\n\tif (res.status != 0)\n\t\treturn -EREMOTEIO;\n\n\t*slw = res.slw;\n\t*tlw = res.tlw;\n\t*sls = res.sls;\n\t*tls = res.tls;\n\n\treturn 0;\n}\n\nstatic int tb_xdp_link_state_status_response(struct tb *tb, struct tb_ctl *ctl,\n\t\t\t\t\t     struct tb_xdomain *xd, u8 sequence)\n{\n\tstruct tb_xdp_link_state_status_response res;\n\tstruct tb_port *port = tb_xdomain_downstream_port(xd);\n\tu32 val[2];\n\tint ret;\n\n\tmemset(&res, 0, sizeof(res));\n\ttb_xdp_fill_header(&res.hdr, xd->route, sequence,\n\t\t\t   LINK_STATE_STATUS_RESPONSE, sizeof(res));\n\n\tret = tb_port_read(port, val, TB_CFG_PORT,\n\t\t\t   port->cap_phy + LANE_ADP_CS_0, ARRAY_SIZE(val));\n\tif (ret)\n\t\treturn ret;\n\n\tres.slw = (val[0] & LANE_ADP_CS_0_SUPPORTED_WIDTH_MASK) >>\n\t\t\tLANE_ADP_CS_0_SUPPORTED_WIDTH_SHIFT;\n\tres.sls = (val[0] & LANE_ADP_CS_0_SUPPORTED_SPEED_MASK) >>\n\t\t\tLANE_ADP_CS_0_SUPPORTED_SPEED_SHIFT;\n\tres.tls = val[1] & LANE_ADP_CS_1_TARGET_SPEED_MASK;\n\tres.tlw = (val[1] & LANE_ADP_CS_1_TARGET_WIDTH_MASK) >>\n\t\t\tLANE_ADP_CS_1_TARGET_WIDTH_SHIFT;\n\n\treturn __tb_xdomain_response(ctl, &res, sizeof(res),\n\t\t\t\t     TB_CFG_PKG_XDOMAIN_RESP);\n}\n\nstatic int tb_xdp_link_state_change_request(struct tb_ctl *ctl, u64 route,\n\t\t\t\t\t    u8 sequence, u8 tlw, u8 tls)\n{\n\tstruct tb_xdp_link_state_change_response res;\n\tstruct tb_xdp_link_state_change req;\n\tint ret;\n\n\tmemset(&req, 0, sizeof(req));\n\ttb_xdp_fill_header(&req.hdr, route, sequence, LINK_STATE_CHANGE_REQUEST,\n\t\t\t   sizeof(req));\n\treq.tlw = tlw;\n\treq.tls = tls;\n\n\tmemset(&res, 0, sizeof(res));\n\tret = __tb_xdomain_request(ctl, &req, sizeof(req), TB_CFG_PKG_XDOMAIN_REQ,\n\t\t\t\t   &res, sizeof(res), TB_CFG_PKG_XDOMAIN_RESP,\n\t\t\t\t   XDOMAIN_DEFAULT_TIMEOUT);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_xdp_handle_error(&res.err);\n\tif (ret)\n\t\treturn ret;\n\n\treturn res.status != 0 ? -EREMOTEIO : 0;\n}\n\nstatic int tb_xdp_link_state_change_response(struct tb_ctl *ctl, u64 route,\n\t\t\t\t\t     u8 sequence, u32 status)\n{\n\tstruct tb_xdp_link_state_change_response res;\n\n\tmemset(&res, 0, sizeof(res));\n\ttb_xdp_fill_header(&res.hdr, route, sequence, LINK_STATE_CHANGE_RESPONSE,\n\t\t\t   sizeof(res));\n\n\tres.status = status;\n\n\treturn __tb_xdomain_response(ctl, &res, sizeof(res),\n\t\t\t\t     TB_CFG_PKG_XDOMAIN_RESP);\n}\n\n \nint tb_register_protocol_handler(struct tb_protocol_handler *handler)\n{\n\tif (!handler->uuid || !handler->callback)\n\t\treturn -EINVAL;\n\tif (uuid_equal(handler->uuid, &tb_xdp_uuid))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&xdomain_lock);\n\tlist_add_tail(&handler->list, &protocol_handlers);\n\tmutex_unlock(&xdomain_lock);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(tb_register_protocol_handler);\n\n \nvoid tb_unregister_protocol_handler(struct tb_protocol_handler *handler)\n{\n\tmutex_lock(&xdomain_lock);\n\tlist_del_init(&handler->list);\n\tmutex_unlock(&xdomain_lock);\n}\nEXPORT_SYMBOL_GPL(tb_unregister_protocol_handler);\n\nstatic void update_property_block(struct tb_xdomain *xd)\n{\n\tmutex_lock(&xdomain_lock);\n\tmutex_lock(&xd->lock);\n\t \n\tif (!xd->local_property_block ||\n\t    xd->local_property_block_gen < xdomain_property_block_gen) {\n\t\tstruct tb_property_dir *dir;\n\t\tint ret, block_len;\n\t\tu32 *block;\n\n\t\tdir = tb_property_copy_dir(xdomain_property_dir);\n\t\tif (!dir) {\n\t\t\tdev_warn(&xd->dev, \"failed to copy properties\\n\");\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\t \n\t\ttb_property_add_text(dir, \"deviceid\", utsname()->nodename);\n\t\ttb_property_add_immediate(dir, \"maxhopid\", xd->local_max_hopid);\n\n\t\tret = tb_property_format_dir(dir, NULL, 0);\n\t\tif (ret < 0) {\n\t\t\tdev_warn(&xd->dev, \"local property block creation failed\\n\");\n\t\t\ttb_property_free_dir(dir);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tblock_len = ret;\n\t\tblock = kcalloc(block_len, sizeof(*block), GFP_KERNEL);\n\t\tif (!block) {\n\t\t\ttb_property_free_dir(dir);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tret = tb_property_format_dir(dir, block, block_len);\n\t\tif (ret) {\n\t\t\tdev_warn(&xd->dev, \"property block generation failed\\n\");\n\t\t\ttb_property_free_dir(dir);\n\t\t\tkfree(block);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\ttb_property_free_dir(dir);\n\t\t \n\t\tkfree(xd->local_property_block);\n\t\t \n\t\txd->local_property_block = block;\n\t\txd->local_property_block_len = block_len;\n\t\txd->local_property_block_gen = xdomain_property_block_gen;\n\t}\n\nout_unlock:\n\tmutex_unlock(&xd->lock);\n\tmutex_unlock(&xdomain_lock);\n}\n\nstatic void start_handshake(struct tb_xdomain *xd)\n{\n\txd->state = XDOMAIN_STATE_INIT;\n\tqueue_delayed_work(xd->tb->wq, &xd->state_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_SHORT_TIMEOUT));\n}\n\n \nstatic void __stop_handshake(struct tb_xdomain *xd)\n{\n\tcancel_delayed_work_sync(&xd->properties_changed_work);\n\txd->properties_changed_retries = 0;\n\txd->state_retries = 0;\n}\n\nstatic void stop_handshake(struct tb_xdomain *xd)\n{\n\tcancel_delayed_work_sync(&xd->state_work);\n\t__stop_handshake(xd);\n}\n\nstatic void tb_xdp_handle_request(struct work_struct *work)\n{\n\tstruct xdomain_request_work *xw = container_of(work, typeof(*xw), work);\n\tconst struct tb_xdp_header *pkg = xw->pkg;\n\tconst struct tb_xdomain_header *xhdr = &pkg->xd_hdr;\n\tstruct tb *tb = xw->tb;\n\tstruct tb_ctl *ctl = tb->ctl;\n\tstruct tb_xdomain *xd;\n\tconst uuid_t *uuid;\n\tint ret = 0;\n\tu32 sequence;\n\tu64 route;\n\n\troute = ((u64)xhdr->route_hi << 32 | xhdr->route_lo) & ~BIT_ULL(63);\n\tsequence = xhdr->length_sn & TB_XDOMAIN_SN_MASK;\n\tsequence >>= TB_XDOMAIN_SN_SHIFT;\n\n\tmutex_lock(&tb->lock);\n\tif (tb->root_switch)\n\t\tuuid = tb->root_switch->uuid;\n\telse\n\t\tuuid = NULL;\n\tmutex_unlock(&tb->lock);\n\n\tif (!uuid) {\n\t\ttb_xdp_error_response(ctl, route, sequence, ERROR_NOT_READY);\n\t\tgoto out;\n\t}\n\n\txd = tb_xdomain_find_by_route_locked(tb, route);\n\tif (xd)\n\t\tupdate_property_block(xd);\n\n\tswitch (pkg->type) {\n\tcase PROPERTIES_REQUEST:\n\t\ttb_dbg(tb, \"%llx: received XDomain properties request\\n\", route);\n\t\tif (xd) {\n\t\t\tret = tb_xdp_properties_response(tb, ctl, xd, sequence,\n\t\t\t\t(const struct tb_xdp_properties *)pkg);\n\t\t}\n\t\tbreak;\n\n\tcase PROPERTIES_CHANGED_REQUEST:\n\t\ttb_dbg(tb, \"%llx: received XDomain properties changed request\\n\",\n\t\t       route);\n\n\t\tret = tb_xdp_properties_changed_response(ctl, route, sequence);\n\n\t\t \n\t\tif (xd && device_is_registered(&xd->dev))\n\t\t\tqueue_delayed_work(tb->wq, &xd->state_work,\n\t\t\t\t\t   msecs_to_jiffies(XDOMAIN_SHORT_TIMEOUT));\n\t\tbreak;\n\n\tcase UUID_REQUEST_OLD:\n\tcase UUID_REQUEST:\n\t\ttb_dbg(tb, \"%llx: received XDomain UUID request\\n\", route);\n\t\tret = tb_xdp_uuid_response(ctl, route, sequence, uuid);\n\t\t \n\t\tif (!ret && xd && xd->state == XDOMAIN_STATE_ERROR) {\n\t\t\tdev_dbg(&xd->dev, \"restarting handshake\\n\");\n\t\t\tstart_handshake(xd);\n\t\t}\n\t\tbreak;\n\n\tcase LINK_STATE_STATUS_REQUEST:\n\t\ttb_dbg(tb, \"%llx: received XDomain link state status request\\n\",\n\t\t       route);\n\n\t\tif (xd) {\n\t\t\tret = tb_xdp_link_state_status_response(tb, ctl, xd,\n\t\t\t\t\t\t\t\tsequence);\n\t\t} else {\n\t\t\ttb_xdp_error_response(ctl, route, sequence,\n\t\t\t\t\t      ERROR_NOT_READY);\n\t\t}\n\t\tbreak;\n\n\tcase LINK_STATE_CHANGE_REQUEST:\n\t\ttb_dbg(tb, \"%llx: received XDomain link state change request\\n\",\n\t\t       route);\n\n\t\tif (xd && xd->state == XDOMAIN_STATE_BONDING_UUID_HIGH) {\n\t\t\tconst struct tb_xdp_link_state_change *lsc =\n\t\t\t\t(const struct tb_xdp_link_state_change *)pkg;\n\n\t\t\tret = tb_xdp_link_state_change_response(ctl, route,\n\t\t\t\t\t\t\t\tsequence, 0);\n\t\t\txd->target_link_width = lsc->tlw;\n\t\t\tqueue_delayed_work(tb->wq, &xd->state_work,\n\t\t\t\t\t   msecs_to_jiffies(XDOMAIN_SHORT_TIMEOUT));\n\t\t} else {\n\t\t\ttb_xdp_error_response(ctl, route, sequence,\n\t\t\t\t\t      ERROR_NOT_READY);\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\ttb_dbg(tb, \"%llx: unknown XDomain request %#x\\n\", route, pkg->type);\n\t\ttb_xdp_error_response(ctl, route, sequence,\n\t\t\t\t      ERROR_NOT_SUPPORTED);\n\t\tbreak;\n\t}\n\n\ttb_xdomain_put(xd);\n\n\tif (ret) {\n\t\ttb_warn(tb, \"failed to send XDomain response for %#x\\n\",\n\t\t\tpkg->type);\n\t}\n\nout:\n\tkfree(xw->pkg);\n\tkfree(xw);\n\n\ttb_domain_put(tb);\n}\n\nstatic bool\ntb_xdp_schedule_request(struct tb *tb, const struct tb_xdp_header *hdr,\n\t\t\tsize_t size)\n{\n\tstruct xdomain_request_work *xw;\n\n\txw = kmalloc(sizeof(*xw), GFP_KERNEL);\n\tif (!xw)\n\t\treturn false;\n\n\tINIT_WORK(&xw->work, tb_xdp_handle_request);\n\txw->pkg = kmemdup(hdr, size, GFP_KERNEL);\n\tif (!xw->pkg) {\n\t\tkfree(xw);\n\t\treturn false;\n\t}\n\txw->tb = tb_domain_get(tb);\n\n\tschedule_work(&xw->work);\n\treturn true;\n}\n\n \nint tb_register_service_driver(struct tb_service_driver *drv)\n{\n\tdrv->driver.bus = &tb_bus_type;\n\treturn driver_register(&drv->driver);\n}\nEXPORT_SYMBOL_GPL(tb_register_service_driver);\n\n \nvoid tb_unregister_service_driver(struct tb_service_driver *drv)\n{\n\tdriver_unregister(&drv->driver);\n}\nEXPORT_SYMBOL_GPL(tb_unregister_service_driver);\n\nstatic ssize_t key_show(struct device *dev, struct device_attribute *attr,\n\t\t\tchar *buf)\n{\n\tstruct tb_service *svc = container_of(dev, struct tb_service, dev);\n\n\t \n\treturn sysfs_emit(buf, \"%*pE\\n\", (int)strlen(svc->key), svc->key);\n}\nstatic DEVICE_ATTR_RO(key);\n\nstatic int get_modalias(const struct tb_service *svc, char *buf, size_t size)\n{\n\treturn snprintf(buf, size, \"tbsvc:k%sp%08Xv%08Xr%08X\", svc->key,\n\t\t\tsvc->prtcid, svc->prtcvers, svc->prtcrevs);\n}\n\nstatic ssize_t modalias_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb_service *svc = container_of(dev, struct tb_service, dev);\n\n\t \n\tget_modalias(svc, buf, PAGE_SIZE - 2);\n\treturn strlen(strcat(buf, \"\\n\"));\n}\nstatic DEVICE_ATTR_RO(modalias);\n\nstatic ssize_t prtcid_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct tb_service *svc = container_of(dev, struct tb_service, dev);\n\n\treturn sysfs_emit(buf, \"%u\\n\", svc->prtcid);\n}\nstatic DEVICE_ATTR_RO(prtcid);\n\nstatic ssize_t prtcvers_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb_service *svc = container_of(dev, struct tb_service, dev);\n\n\treturn sysfs_emit(buf, \"%u\\n\", svc->prtcvers);\n}\nstatic DEVICE_ATTR_RO(prtcvers);\n\nstatic ssize_t prtcrevs_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb_service *svc = container_of(dev, struct tb_service, dev);\n\n\treturn sysfs_emit(buf, \"%u\\n\", svc->prtcrevs);\n}\nstatic DEVICE_ATTR_RO(prtcrevs);\n\nstatic ssize_t prtcstns_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb_service *svc = container_of(dev, struct tb_service, dev);\n\n\treturn sysfs_emit(buf, \"0x%08x\\n\", svc->prtcstns);\n}\nstatic DEVICE_ATTR_RO(prtcstns);\n\nstatic struct attribute *tb_service_attrs[] = {\n\t&dev_attr_key.attr,\n\t&dev_attr_modalias.attr,\n\t&dev_attr_prtcid.attr,\n\t&dev_attr_prtcvers.attr,\n\t&dev_attr_prtcrevs.attr,\n\t&dev_attr_prtcstns.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group tb_service_attr_group = {\n\t.attrs = tb_service_attrs,\n};\n\nstatic const struct attribute_group *tb_service_attr_groups[] = {\n\t&tb_service_attr_group,\n\tNULL,\n};\n\nstatic int tb_service_uevent(const struct device *dev, struct kobj_uevent_env *env)\n{\n\tconst struct tb_service *svc = container_of_const(dev, struct tb_service, dev);\n\tchar modalias[64];\n\n\tget_modalias(svc, modalias, sizeof(modalias));\n\treturn add_uevent_var(env, \"MODALIAS=%s\", modalias);\n}\n\nstatic void tb_service_release(struct device *dev)\n{\n\tstruct tb_service *svc = container_of(dev, struct tb_service, dev);\n\tstruct tb_xdomain *xd = tb_service_parent(svc);\n\n\ttb_service_debugfs_remove(svc);\n\tida_simple_remove(&xd->service_ids, svc->id);\n\tkfree(svc->key);\n\tkfree(svc);\n}\n\nstruct device_type tb_service_type = {\n\t.name = \"thunderbolt_service\",\n\t.groups = tb_service_attr_groups,\n\t.uevent = tb_service_uevent,\n\t.release = tb_service_release,\n};\nEXPORT_SYMBOL_GPL(tb_service_type);\n\nstatic int remove_missing_service(struct device *dev, void *data)\n{\n\tstruct tb_xdomain *xd = data;\n\tstruct tb_service *svc;\n\n\tsvc = tb_to_service(dev);\n\tif (!svc)\n\t\treturn 0;\n\n\tif (!tb_property_find(xd->remote_properties, svc->key,\n\t\t\t      TB_PROPERTY_TYPE_DIRECTORY))\n\t\tdevice_unregister(dev);\n\n\treturn 0;\n}\n\nstatic int find_service(struct device *dev, void *data)\n{\n\tconst struct tb_property *p = data;\n\tstruct tb_service *svc;\n\n\tsvc = tb_to_service(dev);\n\tif (!svc)\n\t\treturn 0;\n\n\treturn !strcmp(svc->key, p->key);\n}\n\nstatic int populate_service(struct tb_service *svc,\n\t\t\t    struct tb_property *property)\n{\n\tstruct tb_property_dir *dir = property->value.dir;\n\tstruct tb_property *p;\n\n\t \n\tp = tb_property_find(dir, \"prtcid\", TB_PROPERTY_TYPE_VALUE);\n\tif (p)\n\t\tsvc->prtcid = p->value.immediate;\n\tp = tb_property_find(dir, \"prtcvers\", TB_PROPERTY_TYPE_VALUE);\n\tif (p)\n\t\tsvc->prtcvers = p->value.immediate;\n\tp = tb_property_find(dir, \"prtcrevs\", TB_PROPERTY_TYPE_VALUE);\n\tif (p)\n\t\tsvc->prtcrevs = p->value.immediate;\n\tp = tb_property_find(dir, \"prtcstns\", TB_PROPERTY_TYPE_VALUE);\n\tif (p)\n\t\tsvc->prtcstns = p->value.immediate;\n\n\tsvc->key = kstrdup(property->key, GFP_KERNEL);\n\tif (!svc->key)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void enumerate_services(struct tb_xdomain *xd)\n{\n\tstruct tb_service *svc;\n\tstruct tb_property *p;\n\tstruct device *dev;\n\tint id;\n\n\t \n\tdevice_for_each_child_reverse(&xd->dev, xd, remove_missing_service);\n\n\t \n\ttb_property_for_each(xd->remote_properties, p) {\n\t\tif (p->type != TB_PROPERTY_TYPE_DIRECTORY)\n\t\t\tcontinue;\n\n\t\t \n\t\tdev = device_find_child(&xd->dev, p, find_service);\n\t\tif (dev) {\n\t\t\tput_device(dev);\n\t\t\tcontinue;\n\t\t}\n\n\t\tsvc = kzalloc(sizeof(*svc), GFP_KERNEL);\n\t\tif (!svc)\n\t\t\tbreak;\n\n\t\tif (populate_service(svc, p)) {\n\t\t\tkfree(svc);\n\t\t\tbreak;\n\t\t}\n\n\t\tid = ida_simple_get(&xd->service_ids, 0, 0, GFP_KERNEL);\n\t\tif (id < 0) {\n\t\t\tkfree(svc->key);\n\t\t\tkfree(svc);\n\t\t\tbreak;\n\t\t}\n\t\tsvc->id = id;\n\t\tsvc->dev.bus = &tb_bus_type;\n\t\tsvc->dev.type = &tb_service_type;\n\t\tsvc->dev.parent = &xd->dev;\n\t\tdev_set_name(&svc->dev, \"%s.%d\", dev_name(&xd->dev), svc->id);\n\n\t\ttb_service_debugfs_init(svc);\n\n\t\tif (device_register(&svc->dev)) {\n\t\t\tput_device(&svc->dev);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic int populate_properties(struct tb_xdomain *xd,\n\t\t\t       struct tb_property_dir *dir)\n{\n\tconst struct tb_property *p;\n\n\t \n\tp = tb_property_find(dir, \"deviceid\", TB_PROPERTY_TYPE_VALUE);\n\tif (!p)\n\t\treturn -EINVAL;\n\txd->device = p->value.immediate;\n\n\tp = tb_property_find(dir, \"vendorid\", TB_PROPERTY_TYPE_VALUE);\n\tif (!p)\n\t\treturn -EINVAL;\n\txd->vendor = p->value.immediate;\n\n\tp = tb_property_find(dir, \"maxhopid\", TB_PROPERTY_TYPE_VALUE);\n\t \n\txd->remote_max_hopid = p ? p->value.immediate : XDOMAIN_DEFAULT_MAX_HOPID;\n\n\tkfree(xd->device_name);\n\txd->device_name = NULL;\n\tkfree(xd->vendor_name);\n\txd->vendor_name = NULL;\n\n\t \n\tp = tb_property_find(dir, \"deviceid\", TB_PROPERTY_TYPE_TEXT);\n\tif (p)\n\t\txd->device_name = kstrdup(p->value.text, GFP_KERNEL);\n\tp = tb_property_find(dir, \"vendorid\", TB_PROPERTY_TYPE_TEXT);\n\tif (p)\n\t\txd->vendor_name = kstrdup(p->value.text, GFP_KERNEL);\n\n\treturn 0;\n}\n\nstatic int tb_xdomain_update_link_attributes(struct tb_xdomain *xd)\n{\n\tbool change = false;\n\tstruct tb_port *port;\n\tint ret;\n\n\tport = tb_xdomain_downstream_port(xd);\n\n\tret = tb_port_get_link_speed(port);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (xd->link_speed != ret)\n\t\tchange = true;\n\n\txd->link_speed = ret;\n\n\tret = tb_port_get_link_width(port);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (xd->link_width != ret)\n\t\tchange = true;\n\n\txd->link_width = ret;\n\n\tif (change)\n\t\tkobject_uevent(&xd->dev.kobj, KOBJ_CHANGE);\n\n\treturn 0;\n}\n\nstatic int tb_xdomain_get_uuid(struct tb_xdomain *xd)\n{\n\tstruct tb *tb = xd->tb;\n\tuuid_t uuid;\n\tu64 route;\n\tint ret;\n\n\tdev_dbg(&xd->dev, \"requesting remote UUID\\n\");\n\n\tret = tb_xdp_uuid_request(tb->ctl, xd->route, xd->state_retries, &uuid,\n\t\t\t\t  &route);\n\tif (ret < 0) {\n\t\tif (xd->state_retries-- > 0) {\n\t\t\tdev_dbg(&xd->dev, \"failed to request UUID, retrying\\n\");\n\t\t\treturn -EAGAIN;\n\t\t}\n\t\tdev_dbg(&xd->dev, \"failed to read remote UUID\\n\");\n\t\treturn ret;\n\t}\n\n\tdev_dbg(&xd->dev, \"got remote UUID %pUb\\n\", &uuid);\n\n\tif (uuid_equal(&uuid, xd->local_uuid)) {\n\t\tif (route == xd->route)\n\t\t\tdev_dbg(&xd->dev, \"loop back detected\\n\");\n\t\telse\n\t\t\tdev_dbg(&xd->dev, \"intra-domain loop detected\\n\");\n\n\t\t \n\t\txd->bonding_possible = false;\n\t}\n\n\t \n\tif (xd->remote_uuid && !uuid_equal(&uuid, xd->remote_uuid)) {\n\t\tdev_dbg(&xd->dev, \"remote UUID is different, unplugging\\n\");\n\t\txd->is_unplugged = true;\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tif (!xd->remote_uuid) {\n\t\txd->remote_uuid = kmemdup(&uuid, sizeof(uuid_t), GFP_KERNEL);\n\t\tif (!xd->remote_uuid)\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic int tb_xdomain_get_link_status(struct tb_xdomain *xd)\n{\n\tstruct tb *tb = xd->tb;\n\tu8 slw, tlw, sls, tls;\n\tint ret;\n\n\tdev_dbg(&xd->dev, \"sending link state status request to %pUb\\n\",\n\t\txd->remote_uuid);\n\n\tret = tb_xdp_link_state_status_request(tb->ctl, xd->route,\n\t\t\t\t\t       xd->state_retries, &slw, &tlw, &sls,\n\t\t\t\t\t       &tls);\n\tif (ret) {\n\t\tif (ret != -EOPNOTSUPP && xd->state_retries-- > 0) {\n\t\t\tdev_dbg(&xd->dev,\n\t\t\t\t\"failed to request remote link status, retrying\\n\");\n\t\t\treturn -EAGAIN;\n\t\t}\n\t\tdev_dbg(&xd->dev, \"failed to receive remote link status\\n\");\n\t\treturn ret;\n\t}\n\n\tdev_dbg(&xd->dev, \"remote link supports width %#x speed %#x\\n\", slw, sls);\n\n\tif (slw < LANE_ADP_CS_0_SUPPORTED_WIDTH_DUAL) {\n\t\tdev_dbg(&xd->dev, \"remote adapter is single lane only\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int tb_xdomain_link_state_change(struct tb_xdomain *xd,\n\t\t\t\t\tunsigned int width)\n{\n\tstruct tb_port *port = tb_xdomain_downstream_port(xd);\n\tstruct tb *tb = xd->tb;\n\tu8 tlw, tls;\n\tu32 val;\n\tint ret;\n\n\tif (width == 2)\n\t\ttlw = LANE_ADP_CS_1_TARGET_WIDTH_DUAL;\n\telse if (width == 1)\n\t\ttlw = LANE_ADP_CS_1_TARGET_WIDTH_SINGLE;\n\telse\n\t\treturn -EINVAL;\n\n\t \n\tret = tb_port_read(port, &val, TB_CFG_PORT, port->cap_phy + LANE_ADP_CS_1, 1);\n\tif (ret)\n\t\treturn ret;\n\ttls = val & LANE_ADP_CS_1_TARGET_SPEED_MASK;\n\n\tdev_dbg(&xd->dev, \"sending link state change request with width %#x speed %#x\\n\",\n\t\ttlw, tls);\n\n\tret = tb_xdp_link_state_change_request(tb->ctl, xd->route,\n\t\t\t\t\t       xd->state_retries, tlw, tls);\n\tif (ret) {\n\t\tif (ret != -EOPNOTSUPP && xd->state_retries-- > 0) {\n\t\t\tdev_dbg(&xd->dev,\n\t\t\t\t\"failed to change remote link state, retrying\\n\");\n\t\t\treturn -EAGAIN;\n\t\t}\n\t\tdev_err(&xd->dev, \"failed request link state change, aborting\\n\");\n\t\treturn ret;\n\t}\n\n\tdev_dbg(&xd->dev, \"received link state change response\\n\");\n\treturn 0;\n}\n\nstatic int tb_xdomain_bond_lanes_uuid_high(struct tb_xdomain *xd)\n{\n\tunsigned int width, width_mask;\n\tstruct tb_port *port;\n\tint ret;\n\n\tif (xd->target_link_width == LANE_ADP_CS_1_TARGET_WIDTH_SINGLE) {\n\t\twidth = TB_LINK_WIDTH_SINGLE;\n\t\twidth_mask = width;\n\t} else if (xd->target_link_width == LANE_ADP_CS_1_TARGET_WIDTH_DUAL) {\n\t\twidth = TB_LINK_WIDTH_DUAL;\n\t\twidth_mask = width | TB_LINK_WIDTH_ASYM_TX | TB_LINK_WIDTH_ASYM_RX;\n\t} else {\n\t\tif (xd->state_retries-- > 0) {\n\t\t\tdev_dbg(&xd->dev,\n\t\t\t\t\"link state change request not received yet, retrying\\n\");\n\t\t\treturn -EAGAIN;\n\t\t}\n\t\tdev_dbg(&xd->dev, \"timeout waiting for link change request\\n\");\n\t\treturn -ETIMEDOUT;\n\t}\n\n\tport = tb_xdomain_downstream_port(xd);\n\n\t \n\tret = tb_port_set_link_width(port->dual_link_port, width);\n\tif (ret) {\n\t\ttb_port_warn(port->dual_link_port,\n\t\t\t     \"failed to set link width to %d\\n\", width);\n\t\treturn ret;\n\t}\n\n\tret = tb_port_set_link_width(port, width);\n\tif (ret) {\n\t\ttb_port_warn(port, \"failed to set link width to %d\\n\", width);\n\t\treturn ret;\n\t}\n\n\tret = tb_port_wait_for_link_width(port, width_mask,\n\t\t\t\t\t  XDOMAIN_BONDING_TIMEOUT);\n\tif (ret) {\n\t\tdev_warn(&xd->dev, \"error waiting for link width to become %d\\n\",\n\t\t\t width_mask);\n\t\treturn ret;\n\t}\n\n\tport->bonded = width > TB_LINK_WIDTH_SINGLE;\n\tport->dual_link_port->bonded = width > TB_LINK_WIDTH_SINGLE;\n\n\ttb_port_update_credits(port);\n\ttb_xdomain_update_link_attributes(xd);\n\n\tdev_dbg(&xd->dev, \"lane bonding %s\\n\", str_enabled_disabled(width == 2));\n\treturn 0;\n}\n\nstatic int tb_xdomain_get_properties(struct tb_xdomain *xd)\n{\n\tstruct tb_property_dir *dir;\n\tstruct tb *tb = xd->tb;\n\tbool update = false;\n\tu32 *block = NULL;\n\tu32 gen = 0;\n\tint ret;\n\n\tdev_dbg(&xd->dev, \"requesting remote properties\\n\");\n\n\tret = tb_xdp_properties_request(tb->ctl, xd->route, xd->local_uuid,\n\t\t\t\t\txd->remote_uuid, xd->state_retries,\n\t\t\t\t\t&block, &gen);\n\tif (ret < 0) {\n\t\tif (xd->state_retries-- > 0) {\n\t\t\tdev_dbg(&xd->dev,\n\t\t\t\t\"failed to request remote properties, retrying\\n\");\n\t\t\treturn -EAGAIN;\n\t\t}\n\t\t \n\t\tdev_err(&xd->dev, \"failed read XDomain properties from %pUb\\n\",\n\t\t\txd->remote_uuid);\n\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&xd->lock);\n\n\t \n\tif (xd->remote_properties && gen <= xd->remote_property_block_gen) {\n\t\tret = 0;\n\t\tgoto err_free_block;\n\t}\n\n\tdir = tb_property_parse_dir(block, ret);\n\tif (!dir) {\n\t\tdev_err(&xd->dev, \"failed to parse XDomain properties\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_free_block;\n\t}\n\n\tret = populate_properties(xd, dir);\n\tif (ret) {\n\t\tdev_err(&xd->dev, \"missing XDomain properties in response\\n\");\n\t\tgoto err_free_dir;\n\t}\n\n\t \n\tif (xd->remote_properties) {\n\t\ttb_property_free_dir(xd->remote_properties);\n\t\tupdate = true;\n\t}\n\n\txd->remote_properties = dir;\n\txd->remote_property_block_gen = gen;\n\n\ttb_xdomain_update_link_attributes(xd);\n\n\tmutex_unlock(&xd->lock);\n\n\tkfree(block);\n\n\t \n\tif (!update) {\n\t\t \n\t\tif (xd->bonding_possible) {\n\t\t\tstruct tb_port *port;\n\n\t\t\tport = tb_xdomain_downstream_port(xd);\n\t\t\tif (!port->bonded)\n\t\t\t\ttb_port_disable(port->dual_link_port);\n\t\t}\n\n\t\tif (device_add(&xd->dev)) {\n\t\t\tdev_err(&xd->dev, \"failed to add XDomain device\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tdev_info(&xd->dev, \"new host found, vendor=%#x device=%#x\\n\",\n\t\t\t xd->vendor, xd->device);\n\t\tif (xd->vendor_name && xd->device_name)\n\t\t\tdev_info(&xd->dev, \"%s %s\\n\", xd->vendor_name,\n\t\t\t\t xd->device_name);\n\n\t\ttb_xdomain_debugfs_init(xd);\n\t} else {\n\t\tkobject_uevent(&xd->dev.kobj, KOBJ_CHANGE);\n\t}\n\n\tenumerate_services(xd);\n\treturn 0;\n\nerr_free_dir:\n\ttb_property_free_dir(dir);\nerr_free_block:\n\tkfree(block);\n\tmutex_unlock(&xd->lock);\n\n\treturn ret;\n}\n\nstatic void tb_xdomain_queue_uuid(struct tb_xdomain *xd)\n{\n\txd->state = XDOMAIN_STATE_UUID;\n\txd->state_retries = XDOMAIN_RETRIES;\n\tqueue_delayed_work(xd->tb->wq, &xd->state_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_SHORT_TIMEOUT));\n}\n\nstatic void tb_xdomain_queue_link_status(struct tb_xdomain *xd)\n{\n\txd->state = XDOMAIN_STATE_LINK_STATUS;\n\txd->state_retries = XDOMAIN_RETRIES;\n\tqueue_delayed_work(xd->tb->wq, &xd->state_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_DEFAULT_TIMEOUT));\n}\n\nstatic void tb_xdomain_queue_link_status2(struct tb_xdomain *xd)\n{\n\txd->state = XDOMAIN_STATE_LINK_STATUS2;\n\txd->state_retries = XDOMAIN_RETRIES;\n\tqueue_delayed_work(xd->tb->wq, &xd->state_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_DEFAULT_TIMEOUT));\n}\n\nstatic void tb_xdomain_queue_bonding(struct tb_xdomain *xd)\n{\n\tif (memcmp(xd->local_uuid, xd->remote_uuid, UUID_SIZE) > 0) {\n\t\tdev_dbg(&xd->dev, \"we have higher UUID, other side bonds the lanes\\n\");\n\t\txd->state = XDOMAIN_STATE_BONDING_UUID_HIGH;\n\t} else {\n\t\tdev_dbg(&xd->dev, \"we have lower UUID, bonding lanes\\n\");\n\t\txd->state = XDOMAIN_STATE_LINK_STATE_CHANGE;\n\t}\n\n\txd->state_retries = XDOMAIN_RETRIES;\n\tqueue_delayed_work(xd->tb->wq, &xd->state_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_DEFAULT_TIMEOUT));\n}\n\nstatic void tb_xdomain_queue_bonding_uuid_low(struct tb_xdomain *xd)\n{\n\txd->state = XDOMAIN_STATE_BONDING_UUID_LOW;\n\txd->state_retries = XDOMAIN_RETRIES;\n\tqueue_delayed_work(xd->tb->wq, &xd->state_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_DEFAULT_TIMEOUT));\n}\n\nstatic void tb_xdomain_queue_properties(struct tb_xdomain *xd)\n{\n\txd->state = XDOMAIN_STATE_PROPERTIES;\n\txd->state_retries = XDOMAIN_RETRIES;\n\tqueue_delayed_work(xd->tb->wq, &xd->state_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_DEFAULT_TIMEOUT));\n}\n\nstatic void tb_xdomain_queue_properties_changed(struct tb_xdomain *xd)\n{\n\txd->properties_changed_retries = XDOMAIN_RETRIES;\n\tqueue_delayed_work(xd->tb->wq, &xd->properties_changed_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_SHORT_TIMEOUT));\n}\n\nstatic void tb_xdomain_failed(struct tb_xdomain *xd)\n{\n\txd->state = XDOMAIN_STATE_ERROR;\n\tqueue_delayed_work(xd->tb->wq, &xd->state_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_DEFAULT_TIMEOUT));\n}\n\nstatic void tb_xdomain_state_work(struct work_struct *work)\n{\n\tstruct tb_xdomain *xd = container_of(work, typeof(*xd), state_work.work);\n\tint ret, state = xd->state;\n\n\tif (WARN_ON_ONCE(state < XDOMAIN_STATE_INIT ||\n\t\t\t state > XDOMAIN_STATE_ERROR))\n\t\treturn;\n\n\tdev_dbg(&xd->dev, \"running state %s\\n\", state_names[state]);\n\n\tswitch (state) {\n\tcase XDOMAIN_STATE_INIT:\n\t\tif (xd->needs_uuid) {\n\t\t\ttb_xdomain_queue_uuid(xd);\n\t\t} else {\n\t\t\ttb_xdomain_queue_properties_changed(xd);\n\t\t\ttb_xdomain_queue_properties(xd);\n\t\t}\n\t\tbreak;\n\n\tcase XDOMAIN_STATE_UUID:\n\t\tret = tb_xdomain_get_uuid(xd);\n\t\tif (ret) {\n\t\t\tif (ret == -EAGAIN)\n\t\t\t\tgoto retry_state;\n\t\t\ttb_xdomain_failed(xd);\n\t\t} else {\n\t\t\ttb_xdomain_queue_properties_changed(xd);\n\t\t\tif (xd->bonding_possible)\n\t\t\t\ttb_xdomain_queue_link_status(xd);\n\t\t\telse\n\t\t\t\ttb_xdomain_queue_properties(xd);\n\t\t}\n\t\tbreak;\n\n\tcase XDOMAIN_STATE_LINK_STATUS:\n\t\tret = tb_xdomain_get_link_status(xd);\n\t\tif (ret) {\n\t\t\tif (ret == -EAGAIN)\n\t\t\t\tgoto retry_state;\n\n\t\t\t \n\t\t\ttb_xdomain_queue_properties(xd);\n\t\t} else {\n\t\t\ttb_xdomain_queue_bonding(xd);\n\t\t}\n\t\tbreak;\n\n\tcase XDOMAIN_STATE_LINK_STATE_CHANGE:\n\t\tret = tb_xdomain_link_state_change(xd, 2);\n\t\tif (ret) {\n\t\t\tif (ret == -EAGAIN)\n\t\t\t\tgoto retry_state;\n\t\t\ttb_xdomain_queue_properties(xd);\n\t\t} else {\n\t\t\ttb_xdomain_queue_link_status2(xd);\n\t\t}\n\t\tbreak;\n\n\tcase XDOMAIN_STATE_LINK_STATUS2:\n\t\tret = tb_xdomain_get_link_status(xd);\n\t\tif (ret) {\n\t\t\tif (ret == -EAGAIN)\n\t\t\t\tgoto retry_state;\n\t\t\ttb_xdomain_queue_properties(xd);\n\t\t} else {\n\t\t\ttb_xdomain_queue_bonding_uuid_low(xd);\n\t\t}\n\t\tbreak;\n\n\tcase XDOMAIN_STATE_BONDING_UUID_LOW:\n\t\ttb_xdomain_lane_bonding_enable(xd);\n\t\ttb_xdomain_queue_properties(xd);\n\t\tbreak;\n\n\tcase XDOMAIN_STATE_BONDING_UUID_HIGH:\n\t\tif (tb_xdomain_bond_lanes_uuid_high(xd) == -EAGAIN)\n\t\t\tgoto retry_state;\n\t\ttb_xdomain_queue_properties(xd);\n\t\tbreak;\n\n\tcase XDOMAIN_STATE_PROPERTIES:\n\t\tret = tb_xdomain_get_properties(xd);\n\t\tif (ret) {\n\t\t\tif (ret == -EAGAIN)\n\t\t\t\tgoto retry_state;\n\t\t\ttb_xdomain_failed(xd);\n\t\t} else {\n\t\t\txd->state = XDOMAIN_STATE_ENUMERATED;\n\t\t}\n\t\tbreak;\n\n\tcase XDOMAIN_STATE_ENUMERATED:\n\t\ttb_xdomain_queue_properties(xd);\n\t\tbreak;\n\n\tcase XDOMAIN_STATE_ERROR:\n\t\tdev_dbg(&xd->dev, \"discovery failed, stopping handshake\\n\");\n\t\t__stop_handshake(xd);\n\t\tbreak;\n\n\tdefault:\n\t\tdev_warn(&xd->dev, \"unexpected state %d\\n\", state);\n\t\tbreak;\n\t}\n\n\treturn;\n\nretry_state:\n\tqueue_delayed_work(xd->tb->wq, &xd->state_work,\n\t\t\t   msecs_to_jiffies(XDOMAIN_DEFAULT_TIMEOUT));\n}\n\nstatic void tb_xdomain_properties_changed(struct work_struct *work)\n{\n\tstruct tb_xdomain *xd = container_of(work, typeof(*xd),\n\t\t\t\t\t     properties_changed_work.work);\n\tint ret;\n\n\tdev_dbg(&xd->dev, \"sending properties changed notification\\n\");\n\n\tret = tb_xdp_properties_changed_request(xd->tb->ctl, xd->route,\n\t\t\t\txd->properties_changed_retries, xd->local_uuid);\n\tif (ret) {\n\t\tif (xd->properties_changed_retries-- > 0) {\n\t\t\tdev_dbg(&xd->dev,\n\t\t\t\t\"failed to send properties changed notification, retrying\\n\");\n\t\t\tqueue_delayed_work(xd->tb->wq,\n\t\t\t\t\t   &xd->properties_changed_work,\n\t\t\t\t\t   msecs_to_jiffies(XDOMAIN_DEFAULT_TIMEOUT));\n\t\t}\n\t\tdev_err(&xd->dev, \"failed to send properties changed notification\\n\");\n\t\treturn;\n\t}\n\n\txd->properties_changed_retries = XDOMAIN_RETRIES;\n}\n\nstatic ssize_t device_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\n\treturn sysfs_emit(buf, \"%#x\\n\", xd->device);\n}\nstatic DEVICE_ATTR_RO(device);\n\nstatic ssize_t\ndevice_name_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\tint ret;\n\n\tif (mutex_lock_interruptible(&xd->lock))\n\t\treturn -ERESTARTSYS;\n\tret = sysfs_emit(buf, \"%s\\n\", xd->device_name ?: \"\");\n\tmutex_unlock(&xd->lock);\n\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(device_name);\n\nstatic ssize_t maxhopid_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\", xd->remote_max_hopid);\n}\nstatic DEVICE_ATTR_RO(maxhopid);\n\nstatic ssize_t vendor_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\n\treturn sysfs_emit(buf, \"%#x\\n\", xd->vendor);\n}\nstatic DEVICE_ATTR_RO(vendor);\n\nstatic ssize_t\nvendor_name_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\tint ret;\n\n\tif (mutex_lock_interruptible(&xd->lock))\n\t\treturn -ERESTARTSYS;\n\tret = sysfs_emit(buf, \"%s\\n\", xd->vendor_name ?: \"\");\n\tmutex_unlock(&xd->lock);\n\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(vendor_name);\n\nstatic ssize_t unique_id_show(struct device *dev, struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\n\treturn sysfs_emit(buf, \"%pUb\\n\", xd->remote_uuid);\n}\nstatic DEVICE_ATTR_RO(unique_id);\n\nstatic ssize_t speed_show(struct device *dev, struct device_attribute *attr,\n\t\t\t  char *buf)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\n\treturn sysfs_emit(buf, \"%u.0 Gb/s\\n\", xd->link_speed);\n}\n\nstatic DEVICE_ATTR(rx_speed, 0444, speed_show, NULL);\nstatic DEVICE_ATTR(tx_speed, 0444, speed_show, NULL);\n\nstatic ssize_t rx_lanes_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\tunsigned int width;\n\n\tswitch (xd->link_width) {\n\tcase TB_LINK_WIDTH_SINGLE:\n\tcase TB_LINK_WIDTH_ASYM_RX:\n\t\twidth = 1;\n\t\tbreak;\n\tcase TB_LINK_WIDTH_DUAL:\n\t\twidth = 2;\n\t\tbreak;\n\tcase TB_LINK_WIDTH_ASYM_TX:\n\t\twidth = 3;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn -EINVAL;\n\t}\n\n\treturn sysfs_emit(buf, \"%u\\n\", width);\n}\nstatic DEVICE_ATTR(rx_lanes, 0444, rx_lanes_show, NULL);\n\nstatic ssize_t tx_lanes_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\tunsigned int width;\n\n\tswitch (xd->link_width) {\n\tcase TB_LINK_WIDTH_SINGLE:\n\tcase TB_LINK_WIDTH_ASYM_TX:\n\t\twidth = 1;\n\t\tbreak;\n\tcase TB_LINK_WIDTH_DUAL:\n\t\twidth = 2;\n\t\tbreak;\n\tcase TB_LINK_WIDTH_ASYM_RX:\n\t\twidth = 3;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn -EINVAL;\n\t}\n\n\treturn sysfs_emit(buf, \"%u\\n\", width);\n}\nstatic DEVICE_ATTR(tx_lanes, 0444, tx_lanes_show, NULL);\n\nstatic struct attribute *xdomain_attrs[] = {\n\t&dev_attr_device.attr,\n\t&dev_attr_device_name.attr,\n\t&dev_attr_maxhopid.attr,\n\t&dev_attr_rx_lanes.attr,\n\t&dev_attr_rx_speed.attr,\n\t&dev_attr_tx_lanes.attr,\n\t&dev_attr_tx_speed.attr,\n\t&dev_attr_unique_id.attr,\n\t&dev_attr_vendor.attr,\n\t&dev_attr_vendor_name.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group xdomain_attr_group = {\n\t.attrs = xdomain_attrs,\n};\n\nstatic const struct attribute_group *xdomain_attr_groups[] = {\n\t&xdomain_attr_group,\n\tNULL,\n};\n\nstatic void tb_xdomain_release(struct device *dev)\n{\n\tstruct tb_xdomain *xd = container_of(dev, struct tb_xdomain, dev);\n\n\tput_device(xd->dev.parent);\n\n\tkfree(xd->local_property_block);\n\ttb_property_free_dir(xd->remote_properties);\n\tida_destroy(&xd->out_hopids);\n\tida_destroy(&xd->in_hopids);\n\tida_destroy(&xd->service_ids);\n\n\tkfree(xd->local_uuid);\n\tkfree(xd->remote_uuid);\n\tkfree(xd->device_name);\n\tkfree(xd->vendor_name);\n\tkfree(xd);\n}\n\nstatic int __maybe_unused tb_xdomain_suspend(struct device *dev)\n{\n\tstop_handshake(tb_to_xdomain(dev));\n\treturn 0;\n}\n\nstatic int __maybe_unused tb_xdomain_resume(struct device *dev)\n{\n\tstart_handshake(tb_to_xdomain(dev));\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops tb_xdomain_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(tb_xdomain_suspend, tb_xdomain_resume)\n};\n\nstruct device_type tb_xdomain_type = {\n\t.name = \"thunderbolt_xdomain\",\n\t.release = tb_xdomain_release,\n\t.pm = &tb_xdomain_pm_ops,\n};\nEXPORT_SYMBOL_GPL(tb_xdomain_type);\n\n \nstruct tb_xdomain *tb_xdomain_alloc(struct tb *tb, struct device *parent,\n\t\t\t\t    u64 route, const uuid_t *local_uuid,\n\t\t\t\t    const uuid_t *remote_uuid)\n{\n\tstruct tb_switch *parent_sw = tb_to_switch(parent);\n\tstruct tb_xdomain *xd;\n\tstruct tb_port *down;\n\n\t \n\tdown = tb_port_at(route, parent_sw);\n\ttb_port_unlock(down);\n\n\txd = kzalloc(sizeof(*xd), GFP_KERNEL);\n\tif (!xd)\n\t\treturn NULL;\n\n\txd->tb = tb;\n\txd->route = route;\n\txd->local_max_hopid = down->config.max_in_hop_id;\n\tida_init(&xd->service_ids);\n\tida_init(&xd->in_hopids);\n\tida_init(&xd->out_hopids);\n\tmutex_init(&xd->lock);\n\tINIT_DELAYED_WORK(&xd->state_work, tb_xdomain_state_work);\n\tINIT_DELAYED_WORK(&xd->properties_changed_work,\n\t\t\t  tb_xdomain_properties_changed);\n\n\txd->local_uuid = kmemdup(local_uuid, sizeof(uuid_t), GFP_KERNEL);\n\tif (!xd->local_uuid)\n\t\tgoto err_free;\n\n\tif (remote_uuid) {\n\t\txd->remote_uuid = kmemdup(remote_uuid, sizeof(uuid_t),\n\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!xd->remote_uuid)\n\t\t\tgoto err_free_local_uuid;\n\t} else {\n\t\txd->needs_uuid = true;\n\t\txd->bonding_possible = !!down->dual_link_port;\n\t}\n\n\tdevice_initialize(&xd->dev);\n\txd->dev.parent = get_device(parent);\n\txd->dev.bus = &tb_bus_type;\n\txd->dev.type = &tb_xdomain_type;\n\txd->dev.groups = xdomain_attr_groups;\n\tdev_set_name(&xd->dev, \"%u-%llx\", tb->index, route);\n\n\tdev_dbg(&xd->dev, \"local UUID %pUb\\n\", local_uuid);\n\tif (remote_uuid)\n\t\tdev_dbg(&xd->dev, \"remote UUID %pUb\\n\", remote_uuid);\n\n\t \n\tpm_runtime_set_active(&xd->dev);\n\tpm_runtime_get_noresume(&xd->dev);\n\tpm_runtime_enable(&xd->dev);\n\n\treturn xd;\n\nerr_free_local_uuid:\n\tkfree(xd->local_uuid);\nerr_free:\n\tkfree(xd);\n\n\treturn NULL;\n}\n\n \nvoid tb_xdomain_add(struct tb_xdomain *xd)\n{\n\t \n\tstart_handshake(xd);\n}\n\nstatic int unregister_service(struct device *dev, void *data)\n{\n\tdevice_unregister(dev);\n\treturn 0;\n}\n\n \nvoid tb_xdomain_remove(struct tb_xdomain *xd)\n{\n\ttb_xdomain_debugfs_remove(xd);\n\n\tstop_handshake(xd);\n\n\tdevice_for_each_child_reverse(&xd->dev, xd, unregister_service);\n\n\t \n\tpm_runtime_disable(&xd->dev);\n\tpm_runtime_put_noidle(&xd->dev);\n\tpm_runtime_set_suspended(&xd->dev);\n\n\tif (!device_is_registered(&xd->dev)) {\n\t\tput_device(&xd->dev);\n\t} else {\n\t\tdev_info(&xd->dev, \"host disconnected\\n\");\n\t\tdevice_unregister(&xd->dev);\n\t}\n}\n\n \nint tb_xdomain_lane_bonding_enable(struct tb_xdomain *xd)\n{\n\tunsigned int width_mask;\n\tstruct tb_port *port;\n\tint ret;\n\n\tport = tb_xdomain_downstream_port(xd);\n\tif (!port->dual_link_port)\n\t\treturn -ENODEV;\n\n\tret = tb_port_enable(port->dual_link_port);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_wait_for_port(port->dual_link_port, true);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (!ret)\n\t\treturn -ENOTCONN;\n\n\tret = tb_port_lane_bonding_enable(port);\n\tif (ret) {\n\t\ttb_port_warn(port, \"failed to enable lane bonding\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\twidth_mask = TB_LINK_WIDTH_DUAL | TB_LINK_WIDTH_ASYM_TX |\n\t\t     TB_LINK_WIDTH_ASYM_RX;\n\n\tret = tb_port_wait_for_link_width(port, width_mask,\n\t\t\t\t\t  XDOMAIN_BONDING_TIMEOUT);\n\tif (ret) {\n\t\ttb_port_warn(port, \"failed to enable lane bonding\\n\");\n\t\treturn ret;\n\t}\n\n\ttb_port_update_credits(port);\n\ttb_xdomain_update_link_attributes(xd);\n\n\tdev_dbg(&xd->dev, \"lane bonding enabled\\n\");\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_lane_bonding_enable);\n\n \nvoid tb_xdomain_lane_bonding_disable(struct tb_xdomain *xd)\n{\n\tstruct tb_port *port;\n\n\tport = tb_xdomain_downstream_port(xd);\n\tif (port->dual_link_port) {\n\t\tint ret;\n\n\t\ttb_port_lane_bonding_disable(port);\n\t\tret = tb_port_wait_for_link_width(port, TB_LINK_WIDTH_SINGLE, 100);\n\t\tif (ret == -ETIMEDOUT)\n\t\t\ttb_port_warn(port, \"timeout disabling lane bonding\\n\");\n\t\ttb_port_disable(port->dual_link_port);\n\t\ttb_port_update_credits(port);\n\t\ttb_xdomain_update_link_attributes(xd);\n\n\t\tdev_dbg(&xd->dev, \"lane bonding disabled\\n\");\n\t}\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_lane_bonding_disable);\n\n \nint tb_xdomain_alloc_in_hopid(struct tb_xdomain *xd, int hopid)\n{\n\tif (hopid < 0)\n\t\thopid = TB_PATH_MIN_HOPID;\n\tif (hopid < TB_PATH_MIN_HOPID || hopid > xd->local_max_hopid)\n\t\treturn -EINVAL;\n\n\treturn ida_alloc_range(&xd->in_hopids, hopid, xd->local_max_hopid,\n\t\t\t       GFP_KERNEL);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_alloc_in_hopid);\n\n \nint tb_xdomain_alloc_out_hopid(struct tb_xdomain *xd, int hopid)\n{\n\tif (hopid < 0)\n\t\thopid = TB_PATH_MIN_HOPID;\n\tif (hopid < TB_PATH_MIN_HOPID || hopid > xd->remote_max_hopid)\n\t\treturn -EINVAL;\n\n\treturn ida_alloc_range(&xd->out_hopids, hopid, xd->remote_max_hopid,\n\t\t\t       GFP_KERNEL);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_alloc_out_hopid);\n\n \nvoid tb_xdomain_release_in_hopid(struct tb_xdomain *xd, int hopid)\n{\n\tida_free(&xd->in_hopids, hopid);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_release_in_hopid);\n\n \nvoid tb_xdomain_release_out_hopid(struct tb_xdomain *xd, int hopid)\n{\n\tida_free(&xd->out_hopids, hopid);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_release_out_hopid);\n\n \nint tb_xdomain_enable_paths(struct tb_xdomain *xd, int transmit_path,\n\t\t\t    int transmit_ring, int receive_path,\n\t\t\t    int receive_ring)\n{\n\treturn tb_domain_approve_xdomain_paths(xd->tb, xd, transmit_path,\n\t\t\t\t\t       transmit_ring, receive_path,\n\t\t\t\t\t       receive_ring);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_enable_paths);\n\n \nint tb_xdomain_disable_paths(struct tb_xdomain *xd, int transmit_path,\n\t\t\t     int transmit_ring, int receive_path,\n\t\t\t     int receive_ring)\n{\n\treturn tb_domain_disconnect_xdomain_paths(xd->tb, xd, transmit_path,\n\t\t\t\t\t\t  transmit_ring, receive_path,\n\t\t\t\t\t\t  receive_ring);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_disable_paths);\n\nstruct tb_xdomain_lookup {\n\tconst uuid_t *uuid;\n\tu8 link;\n\tu8 depth;\n\tu64 route;\n};\n\nstatic struct tb_xdomain *switch_find_xdomain(struct tb_switch *sw,\n\tconst struct tb_xdomain_lookup *lookup)\n{\n\tstruct tb_port *port;\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tstruct tb_xdomain *xd;\n\n\t\tif (port->xdomain) {\n\t\t\txd = port->xdomain;\n\n\t\t\tif (lookup->uuid) {\n\t\t\t\tif (xd->remote_uuid &&\n\t\t\t\t    uuid_equal(xd->remote_uuid, lookup->uuid))\n\t\t\t\t\treturn xd;\n\t\t\t} else {\n\t\t\t\tif (lookup->link && lookup->link == xd->link &&\n\t\t\t\t    lookup->depth == xd->depth)\n\t\t\t\t\treturn xd;\n\t\t\t\tif (lookup->route && lookup->route == xd->route)\n\t\t\t\t\treturn xd;\n\t\t\t}\n\t\t} else if (tb_port_has_remote(port)) {\n\t\t\txd = switch_find_xdomain(port->remote->sw, lookup);\n\t\t\tif (xd)\n\t\t\t\treturn xd;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\n \nstruct tb_xdomain *tb_xdomain_find_by_uuid(struct tb *tb, const uuid_t *uuid)\n{\n\tstruct tb_xdomain_lookup lookup;\n\tstruct tb_xdomain *xd;\n\n\tmemset(&lookup, 0, sizeof(lookup));\n\tlookup.uuid = uuid;\n\n\txd = switch_find_xdomain(tb->root_switch, &lookup);\n\treturn tb_xdomain_get(xd);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_find_by_uuid);\n\n \nstruct tb_xdomain *tb_xdomain_find_by_link_depth(struct tb *tb, u8 link,\n\t\t\t\t\t\t u8 depth)\n{\n\tstruct tb_xdomain_lookup lookup;\n\tstruct tb_xdomain *xd;\n\n\tmemset(&lookup, 0, sizeof(lookup));\n\tlookup.link = link;\n\tlookup.depth = depth;\n\n\txd = switch_find_xdomain(tb->root_switch, &lookup);\n\treturn tb_xdomain_get(xd);\n}\n\n \nstruct tb_xdomain *tb_xdomain_find_by_route(struct tb *tb, u64 route)\n{\n\tstruct tb_xdomain_lookup lookup;\n\tstruct tb_xdomain *xd;\n\n\tmemset(&lookup, 0, sizeof(lookup));\n\tlookup.route = route;\n\n\txd = switch_find_xdomain(tb->root_switch, &lookup);\n\treturn tb_xdomain_get(xd);\n}\nEXPORT_SYMBOL_GPL(tb_xdomain_find_by_route);\n\nbool tb_xdomain_handle_request(struct tb *tb, enum tb_cfg_pkg_type type,\n\t\t\t       const void *buf, size_t size)\n{\n\tconst struct tb_protocol_handler *handler, *tmp;\n\tconst struct tb_xdp_header *hdr = buf;\n\tunsigned int length;\n\tint ret = 0;\n\n\t \n\tlength = hdr->xd_hdr.length_sn & TB_XDOMAIN_LENGTH_MASK;\n\tif (length != size / 4 - sizeof(hdr->xd_hdr) / 4)\n\t\treturn true;\n\tif (length < sizeof(*hdr) / 4 - sizeof(hdr->xd_hdr) / 4)\n\t\treturn true;\n\n\t \n\tif (uuid_equal(&hdr->uuid, &tb_xdp_uuid)) {\n\t\tif (type == TB_CFG_PKG_XDOMAIN_REQ)\n\t\t\treturn tb_xdp_schedule_request(tb, hdr, size);\n\t\treturn false;\n\t}\n\n\tmutex_lock(&xdomain_lock);\n\tlist_for_each_entry_safe(handler, tmp, &protocol_handlers, list) {\n\t\tif (!uuid_equal(&hdr->uuid, handler->uuid))\n\t\t\tcontinue;\n\n\t\tmutex_unlock(&xdomain_lock);\n\t\tret = handler->callback(buf, size, handler->data);\n\t\tmutex_lock(&xdomain_lock);\n\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(&xdomain_lock);\n\n\treturn ret > 0;\n}\n\nstatic int update_xdomain(struct device *dev, void *data)\n{\n\tstruct tb_xdomain *xd;\n\n\txd = tb_to_xdomain(dev);\n\tif (xd) {\n\t\tqueue_delayed_work(xd->tb->wq, &xd->properties_changed_work,\n\t\t\t\t   msecs_to_jiffies(50));\n\t}\n\n\treturn 0;\n}\n\nstatic void update_all_xdomains(void)\n{\n\tbus_for_each_dev(&tb_bus_type, NULL, NULL, update_xdomain);\n}\n\nstatic bool remove_directory(const char *key, const struct tb_property_dir *dir)\n{\n\tstruct tb_property *p;\n\n\tp = tb_property_find(xdomain_property_dir, key,\n\t\t\t     TB_PROPERTY_TYPE_DIRECTORY);\n\tif (p && p->value.dir == dir) {\n\t\ttb_property_remove(p);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nint tb_register_property_dir(const char *key, struct tb_property_dir *dir)\n{\n\tint ret;\n\n\tif (WARN_ON(!xdomain_property_dir))\n\t\treturn -EAGAIN;\n\n\tif (!key || strlen(key) > 8)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&xdomain_lock);\n\tif (tb_property_find(xdomain_property_dir, key,\n\t\t\t     TB_PROPERTY_TYPE_DIRECTORY)) {\n\t\tret = -EEXIST;\n\t\tgoto err_unlock;\n\t}\n\n\tret = tb_property_add_dir(xdomain_property_dir, key, dir);\n\tif (ret)\n\t\tgoto err_unlock;\n\n\txdomain_property_block_gen++;\n\n\tmutex_unlock(&xdomain_lock);\n\tupdate_all_xdomains();\n\treturn 0;\n\nerr_unlock:\n\tmutex_unlock(&xdomain_lock);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(tb_register_property_dir);\n\n \nvoid tb_unregister_property_dir(const char *key, struct tb_property_dir *dir)\n{\n\tint ret = 0;\n\n\tmutex_lock(&xdomain_lock);\n\tif (remove_directory(key, dir))\n\t\txdomain_property_block_gen++;\n\tmutex_unlock(&xdomain_lock);\n\n\tif (!ret)\n\t\tupdate_all_xdomains();\n}\nEXPORT_SYMBOL_GPL(tb_unregister_property_dir);\n\nint tb_xdomain_init(void)\n{\n\txdomain_property_dir = tb_property_create_dir(NULL);\n\tif (!xdomain_property_dir)\n\t\treturn -ENOMEM;\n\n\t \n\ttb_property_add_immediate(xdomain_property_dir, \"vendorid\",\n\t\t\t\t  PCI_VENDOR_ID_INTEL);\n\ttb_property_add_text(xdomain_property_dir, \"vendorid\", \"Intel Corp.\");\n\ttb_property_add_immediate(xdomain_property_dir, \"deviceid\", 0x1);\n\ttb_property_add_immediate(xdomain_property_dir, \"devicerv\", 0x80000100);\n\n\txdomain_property_block_gen = get_random_u32();\n\treturn 0;\n}\n\nvoid tb_xdomain_exit(void)\n{\n\ttb_property_free_dir(xdomain_property_dir);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}