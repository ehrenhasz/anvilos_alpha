{
  "module_name": "switch.c",
  "hash_id": "c654b69e4ba2264e54732960b9f43a750ccfbf3197848bc3854af585ce44e7d6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/thunderbolt/switch.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#include <linux/idr.h>\n#include <linux/module.h>\n#include <linux/nvmem-provider.h>\n#include <linux/pm_runtime.h>\n#include <linux/sched/signal.h>\n#include <linux/sizes.h>\n#include <linux/slab.h>\n#include <linux/string_helpers.h>\n\n#include \"tb.h\"\n\n \n\nstruct nvm_auth_status {\n\tstruct list_head list;\n\tuuid_t uuid;\n\tu32 status;\n};\n\n \nstatic LIST_HEAD(nvm_auth_status_cache);\nstatic DEFINE_MUTEX(nvm_auth_status_lock);\n\nstatic struct nvm_auth_status *__nvm_get_auth_status(const struct tb_switch *sw)\n{\n\tstruct nvm_auth_status *st;\n\n\tlist_for_each_entry(st, &nvm_auth_status_cache, list) {\n\t\tif (uuid_equal(&st->uuid, sw->uuid))\n\t\t\treturn st;\n\t}\n\n\treturn NULL;\n}\n\nstatic void nvm_get_auth_status(const struct tb_switch *sw, u32 *status)\n{\n\tstruct nvm_auth_status *st;\n\n\tmutex_lock(&nvm_auth_status_lock);\n\tst = __nvm_get_auth_status(sw);\n\tmutex_unlock(&nvm_auth_status_lock);\n\n\t*status = st ? st->status : 0;\n}\n\nstatic void nvm_set_auth_status(const struct tb_switch *sw, u32 status)\n{\n\tstruct nvm_auth_status *st;\n\n\tif (WARN_ON(!sw->uuid))\n\t\treturn;\n\n\tmutex_lock(&nvm_auth_status_lock);\n\tst = __nvm_get_auth_status(sw);\n\n\tif (!st) {\n\t\tst = kzalloc(sizeof(*st), GFP_KERNEL);\n\t\tif (!st)\n\t\t\tgoto unlock;\n\n\t\tmemcpy(&st->uuid, sw->uuid, sizeof(st->uuid));\n\t\tINIT_LIST_HEAD(&st->list);\n\t\tlist_add_tail(&st->list, &nvm_auth_status_cache);\n\t}\n\n\tst->status = status;\nunlock:\n\tmutex_unlock(&nvm_auth_status_lock);\n}\n\nstatic void nvm_clear_auth_status(const struct tb_switch *sw)\n{\n\tstruct nvm_auth_status *st;\n\n\tmutex_lock(&nvm_auth_status_lock);\n\tst = __nvm_get_auth_status(sw);\n\tif (st) {\n\t\tlist_del(&st->list);\n\t\tkfree(st);\n\t}\n\tmutex_unlock(&nvm_auth_status_lock);\n}\n\nstatic int nvm_validate_and_write(struct tb_switch *sw)\n{\n\tunsigned int image_size;\n\tconst u8 *buf;\n\tint ret;\n\n\tret = tb_nvm_validate(sw->nvm);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_nvm_write_headers(sw->nvm);\n\tif (ret)\n\t\treturn ret;\n\n\tbuf = sw->nvm->buf_data_start;\n\timage_size = sw->nvm->buf_data_size;\n\n\tif (tb_switch_is_usb4(sw))\n\t\tret = usb4_switch_nvm_write(sw, 0, buf, image_size);\n\telse\n\t\tret = dma_port_flash_write(sw->dma_port, 0, buf, image_size);\n\tif (ret)\n\t\treturn ret;\n\n\tsw->nvm->flushed = true;\n\treturn 0;\n}\n\nstatic int nvm_authenticate_host_dma_port(struct tb_switch *sw)\n{\n\tint ret = 0;\n\n\t \n\tif (!sw->safe_mode) {\n\t\tu32 status;\n\n\t\tret = tb_domain_disconnect_all_paths(sw->tb);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\t \n\t\tret = dma_port_flash_update_auth(sw->dma_port);\n\t\tif (!ret || ret == -ETIMEDOUT)\n\t\t\treturn 0;\n\n\t\t \n\t\ttb_sw_warn(sw, \"failed to authenticate NVM, power cycling\\n\");\n\t\tif (dma_port_flash_update_auth_status(sw->dma_port, &status) > 0)\n\t\t\tnvm_set_auth_status(sw, status);\n\t}\n\n\t \n\tdma_port_power_cycle(sw->dma_port);\n\treturn ret;\n}\n\nstatic int nvm_authenticate_device_dma_port(struct tb_switch *sw)\n{\n\tint ret, retries = 10;\n\n\tret = dma_port_flash_update_auth(sw->dma_port);\n\tswitch (ret) {\n\tcase 0:\n\tcase -ETIMEDOUT:\n\tcase -EACCES:\n\tcase -EINVAL:\n\t\t \n\t\tbreak;\n\tdefault:\n\t\treturn ret;\n\t}\n\n\t \n\tdo {\n\t\tu32 status;\n\n\t\tret = dma_port_flash_update_auth_status(sw->dma_port, &status);\n\t\tif (ret < 0 && ret != -ETIMEDOUT)\n\t\t\treturn ret;\n\t\tif (ret > 0) {\n\t\t\tif (status) {\n\t\t\t\ttb_sw_warn(sw, \"failed to authenticate NVM\\n\");\n\t\t\t\tnvm_set_auth_status(sw, status);\n\t\t\t}\n\n\t\t\ttb_sw_info(sw, \"power cycling the switch now\\n\");\n\t\t\tdma_port_power_cycle(sw->dma_port);\n\t\t\treturn 0;\n\t\t}\n\n\t\tmsleep(500);\n\t} while (--retries);\n\n\treturn -ETIMEDOUT;\n}\n\nstatic void nvm_authenticate_start_dma_port(struct tb_switch *sw)\n{\n\tstruct pci_dev *root_port;\n\n\t \n\troot_port = pcie_find_root_port(sw->tb->nhi->pdev);\n\tif (root_port)\n\t\tpm_runtime_get_noresume(&root_port->dev);\n}\n\nstatic void nvm_authenticate_complete_dma_port(struct tb_switch *sw)\n{\n\tstruct pci_dev *root_port;\n\n\troot_port = pcie_find_root_port(sw->tb->nhi->pdev);\n\tif (root_port)\n\t\tpm_runtime_put(&root_port->dev);\n}\n\nstatic inline bool nvm_readable(struct tb_switch *sw)\n{\n\tif (tb_switch_is_usb4(sw)) {\n\t\t \n\t\treturn usb4_switch_nvm_sector_size(sw) > 0;\n\t}\n\n\t \n\treturn !!sw->dma_port;\n}\n\nstatic inline bool nvm_upgradeable(struct tb_switch *sw)\n{\n\tif (sw->no_nvm_upgrade)\n\t\treturn false;\n\treturn nvm_readable(sw);\n}\n\nstatic int nvm_authenticate(struct tb_switch *sw, bool auth_only)\n{\n\tint ret;\n\n\tif (tb_switch_is_usb4(sw)) {\n\t\tif (auth_only) {\n\t\t\tret = usb4_switch_nvm_set_offset(sw, 0);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t\tsw->nvm->authenticating = true;\n\t\treturn usb4_switch_nvm_authenticate(sw);\n\t}\n\tif (auth_only)\n\t\treturn -EOPNOTSUPP;\n\n\tsw->nvm->authenticating = true;\n\tif (!tb_route(sw)) {\n\t\tnvm_authenticate_start_dma_port(sw);\n\t\tret = nvm_authenticate_host_dma_port(sw);\n\t} else {\n\t\tret = nvm_authenticate_device_dma_port(sw);\n\t}\n\n\treturn ret;\n}\n\n \nint tb_switch_nvm_read(struct tb_switch *sw, unsigned int address, void *buf,\n\t\t       size_t size)\n{\n\tif (tb_switch_is_usb4(sw))\n\t\treturn usb4_switch_nvm_read(sw, address, buf, size);\n\treturn dma_port_flash_read(sw->dma_port, address, buf, size);\n}\n\nstatic int nvm_read(void *priv, unsigned int offset, void *val, size_t bytes)\n{\n\tstruct tb_nvm *nvm = priv;\n\tstruct tb_switch *sw = tb_to_switch(nvm->dev);\n\tint ret;\n\n\tpm_runtime_get_sync(&sw->dev);\n\n\tif (!mutex_trylock(&sw->tb->lock)) {\n\t\tret = restart_syscall();\n\t\tgoto out;\n\t}\n\n\tret = tb_switch_nvm_read(sw, offset, val, bytes);\n\tmutex_unlock(&sw->tb->lock);\n\nout:\n\tpm_runtime_mark_last_busy(&sw->dev);\n\tpm_runtime_put_autosuspend(&sw->dev);\n\n\treturn ret;\n}\n\nstatic int nvm_write(void *priv, unsigned int offset, void *val, size_t bytes)\n{\n\tstruct tb_nvm *nvm = priv;\n\tstruct tb_switch *sw = tb_to_switch(nvm->dev);\n\tint ret;\n\n\tif (!mutex_trylock(&sw->tb->lock))\n\t\treturn restart_syscall();\n\n\t \n\tret = tb_nvm_write_buf(nvm, offset, val, bytes);\n\tmutex_unlock(&sw->tb->lock);\n\n\treturn ret;\n}\n\nstatic int tb_switch_nvm_add(struct tb_switch *sw)\n{\n\tstruct tb_nvm *nvm;\n\tint ret;\n\n\tif (!nvm_readable(sw))\n\t\treturn 0;\n\n\tnvm = tb_nvm_alloc(&sw->dev);\n\tif (IS_ERR(nvm)) {\n\t\tret = PTR_ERR(nvm) == -EOPNOTSUPP ? 0 : PTR_ERR(nvm);\n\t\tgoto err_nvm;\n\t}\n\n\tret = tb_nvm_read_version(nvm);\n\tif (ret)\n\t\tgoto err_nvm;\n\n\t \n\tif (!sw->safe_mode) {\n\t\tret = tb_nvm_add_active(nvm, nvm_read);\n\t\tif (ret)\n\t\t\tgoto err_nvm;\n\t}\n\n\tif (!sw->no_nvm_upgrade) {\n\t\tret = tb_nvm_add_non_active(nvm, nvm_write);\n\t\tif (ret)\n\t\t\tgoto err_nvm;\n\t}\n\n\tsw->nvm = nvm;\n\treturn 0;\n\nerr_nvm:\n\ttb_sw_dbg(sw, \"NVM upgrade disabled\\n\");\n\tsw->no_nvm_upgrade = true;\n\tif (!IS_ERR(nvm))\n\t\ttb_nvm_free(nvm);\n\n\treturn ret;\n}\n\nstatic void tb_switch_nvm_remove(struct tb_switch *sw)\n{\n\tstruct tb_nvm *nvm;\n\n\tnvm = sw->nvm;\n\tsw->nvm = NULL;\n\n\tif (!nvm)\n\t\treturn;\n\n\t \n\tif (!nvm->authenticating)\n\t\tnvm_clear_auth_status(sw);\n\n\ttb_nvm_free(nvm);\n}\n\n \n\nstatic const char *tb_port_type(const struct tb_regs_port_header *port)\n{\n\tswitch (port->type >> 16) {\n\tcase 0:\n\t\tswitch ((u8) port->type) {\n\t\tcase 0:\n\t\t\treturn \"Inactive\";\n\t\tcase 1:\n\t\t\treturn \"Port\";\n\t\tcase 2:\n\t\t\treturn \"NHI\";\n\t\tdefault:\n\t\t\treturn \"unknown\";\n\t\t}\n\tcase 0x2:\n\t\treturn \"Ethernet\";\n\tcase 0x8:\n\t\treturn \"SATA\";\n\tcase 0xe:\n\t\treturn \"DP/HDMI\";\n\tcase 0x10:\n\t\treturn \"PCIe\";\n\tcase 0x20:\n\t\treturn \"USB\";\n\tdefault:\n\t\treturn \"unknown\";\n\t}\n}\n\nstatic void tb_dump_port(struct tb *tb, const struct tb_port *port)\n{\n\tconst struct tb_regs_port_header *regs = &port->config;\n\n\ttb_dbg(tb,\n\t       \" Port %d: %x:%x (Revision: %d, TB Version: %d, Type: %s (%#x))\\n\",\n\t       regs->port_number, regs->vendor_id, regs->device_id,\n\t       regs->revision, regs->thunderbolt_version, tb_port_type(regs),\n\t       regs->type);\n\ttb_dbg(tb, \"  Max hop id (in/out): %d/%d\\n\",\n\t       regs->max_in_hop_id, regs->max_out_hop_id);\n\ttb_dbg(tb, \"  Max counters: %d\\n\", regs->max_counters);\n\ttb_dbg(tb, \"  NFC Credits: %#x\\n\", regs->nfc_credits);\n\ttb_dbg(tb, \"  Credits (total/control): %u/%u\\n\", port->total_credits,\n\t       port->ctl_credits);\n}\n\n \nint tb_port_state(struct tb_port *port)\n{\n\tstruct tb_cap_phy phy;\n\tint res;\n\tif (port->cap_phy == 0) {\n\t\ttb_port_WARN(port, \"does not have a PHY\\n\");\n\t\treturn -EINVAL;\n\t}\n\tres = tb_port_read(port, &phy, TB_CFG_PORT, port->cap_phy, 2);\n\tif (res)\n\t\treturn res;\n\treturn phy.state;\n}\n\n \nint tb_wait_for_port(struct tb_port *port, bool wait_if_unplugged)\n{\n\tint retries = 10;\n\tint state;\n\tif (!port->cap_phy) {\n\t\ttb_port_WARN(port, \"does not have PHY\\n\");\n\t\treturn -EINVAL;\n\t}\n\tif (tb_is_upstream_port(port)) {\n\t\ttb_port_WARN(port, \"is the upstream port\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\twhile (retries--) {\n\t\tstate = tb_port_state(port);\n\t\tswitch (state) {\n\t\tcase TB_PORT_DISABLED:\n\t\t\ttb_port_dbg(port, \"is disabled (state: 0)\\n\");\n\t\t\treturn 0;\n\n\t\tcase TB_PORT_UNPLUGGED:\n\t\t\tif (wait_if_unplugged) {\n\t\t\t\t \n\t\t\t\ttb_port_dbg(port,\n\t\t\t\t\t    \"is unplugged (state: 7), retrying...\\n\");\n\t\t\t\tmsleep(100);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttb_port_dbg(port, \"is unplugged (state: 7)\\n\");\n\t\t\treturn 0;\n\n\t\tcase TB_PORT_UP:\n\t\tcase TB_PORT_TX_CL0S:\n\t\tcase TB_PORT_RX_CL0S:\n\t\tcase TB_PORT_CL1:\n\t\tcase TB_PORT_CL2:\n\t\t\ttb_port_dbg(port, \"is connected, link is up (state: %d)\\n\", state);\n\t\t\treturn 1;\n\n\t\tdefault:\n\t\t\tif (state < 0)\n\t\t\t\treturn state;\n\n\t\t\t \n\t\t\ttb_port_dbg(port,\n\t\t\t\t    \"is connected, link is not up (state: %d), retrying...\\n\",\n\t\t\t\t    state);\n\t\t\tmsleep(100);\n\t\t}\n\n\t}\n\ttb_port_warn(port,\n\t\t     \"failed to reach state TB_PORT_UP. Ignoring port...\\n\");\n\treturn 0;\n}\n\n \nint tb_port_add_nfc_credits(struct tb_port *port, int credits)\n{\n\tu32 nfc_credits;\n\n\tif (credits == 0 || port->sw->is_unplugged)\n\t\treturn 0;\n\n\t \n\tif (tb_switch_is_usb4(port->sw) && !tb_port_is_null(port))\n\t\treturn 0;\n\n\tnfc_credits = port->config.nfc_credits & ADP_CS_4_NFC_BUFFERS_MASK;\n\tif (credits < 0)\n\t\tcredits = max_t(int, -nfc_credits, credits);\n\n\tnfc_credits += credits;\n\n\ttb_port_dbg(port, \"adding %d NFC credits to %lu\", credits,\n\t\t    port->config.nfc_credits & ADP_CS_4_NFC_BUFFERS_MASK);\n\n\tport->config.nfc_credits &= ~ADP_CS_4_NFC_BUFFERS_MASK;\n\tport->config.nfc_credits |= nfc_credits;\n\n\treturn tb_port_write(port, &port->config.nfc_credits,\n\t\t\t     TB_CFG_PORT, ADP_CS_4, 1);\n}\n\n \nint tb_port_clear_counter(struct tb_port *port, int counter)\n{\n\tu32 zero[3] = { 0, 0, 0 };\n\ttb_port_dbg(port, \"clearing counter %d\\n\", counter);\n\treturn tb_port_write(port, zero, TB_CFG_COUNTERS, 3 * counter, 3);\n}\n\n \nint tb_port_unlock(struct tb_port *port)\n{\n\tif (tb_switch_is_icm(port->sw))\n\t\treturn 0;\n\tif (!tb_port_is_null(port))\n\t\treturn -EINVAL;\n\tif (tb_switch_is_usb4(port->sw))\n\t\treturn usb4_port_unlock(port);\n\treturn 0;\n}\n\nstatic int __tb_port_enable(struct tb_port *port, bool enable)\n{\n\tint ret;\n\tu32 phy;\n\n\tif (!tb_port_is_null(port))\n\t\treturn -EINVAL;\n\n\tret = tb_port_read(port, &phy, TB_CFG_PORT,\n\t\t\t   port->cap_phy + LANE_ADP_CS_1, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tif (enable)\n\t\tphy &= ~LANE_ADP_CS_1_LD;\n\telse\n\t\tphy |= LANE_ADP_CS_1_LD;\n\n\n\tret = tb_port_write(port, &phy, TB_CFG_PORT,\n\t\t\t    port->cap_phy + LANE_ADP_CS_1, 1);\n\tif (ret)\n\t\treturn ret;\n\n\ttb_port_dbg(port, \"lane %s\\n\", str_enabled_disabled(enable));\n\treturn 0;\n}\n\n \nint tb_port_enable(struct tb_port *port)\n{\n\treturn __tb_port_enable(port, true);\n}\n\n \nint tb_port_disable(struct tb_port *port)\n{\n\treturn __tb_port_enable(port, false);\n}\n\n \nstatic int tb_init_port(struct tb_port *port)\n{\n\tint res;\n\tint cap;\n\n\tINIT_LIST_HEAD(&port->list);\n\n\t \n\tif (!port->port)\n\t\treturn 0;\n\n\tres = tb_port_read(port, &port->config, TB_CFG_PORT, 0, 8);\n\tif (res) {\n\t\tif (res == -ENODEV) {\n\t\t\ttb_dbg(port->sw->tb, \" Port %d: not implemented\\n\",\n\t\t\t       port->port);\n\t\t\tport->disabled = true;\n\t\t\treturn 0;\n\t\t}\n\t\treturn res;\n\t}\n\n\t \n\tif (port->config.type == TB_TYPE_PORT) {\n\t\tcap = tb_port_find_cap(port, TB_PORT_CAP_PHY);\n\n\t\tif (cap > 0)\n\t\t\tport->cap_phy = cap;\n\t\telse\n\t\t\ttb_port_WARN(port, \"non switch port without a PHY\\n\");\n\n\t\tcap = tb_port_find_cap(port, TB_PORT_CAP_USB4);\n\t\tif (cap > 0)\n\t\t\tport->cap_usb4 = cap;\n\n\t\t \n\t\tif (port->cap_usb4) {\n\t\t\tstruct tb_regs_hop hop;\n\n\t\t\tif (!tb_port_read(port, &hop, TB_CFG_HOPS, 0, 2))\n\t\t\t\tport->ctl_credits = hop.initial_credits;\n\t\t}\n\t\tif (!port->ctl_credits)\n\t\t\tport->ctl_credits = 2;\n\n\t} else {\n\t\tcap = tb_port_find_cap(port, TB_PORT_CAP_ADAP);\n\t\tif (cap > 0)\n\t\t\tport->cap_adap = cap;\n\t}\n\n\tport->total_credits =\n\t\t(port->config.nfc_credits & ADP_CS_4_TOTAL_BUFFERS_MASK) >>\n\t\tADP_CS_4_TOTAL_BUFFERS_SHIFT;\n\n\ttb_dump_port(port->sw->tb, port);\n\treturn 0;\n}\n\nstatic int tb_port_alloc_hopid(struct tb_port *port, bool in, int min_hopid,\n\t\t\t       int max_hopid)\n{\n\tint port_max_hopid;\n\tstruct ida *ida;\n\n\tif (in) {\n\t\tport_max_hopid = port->config.max_in_hop_id;\n\t\tida = &port->in_hopids;\n\t} else {\n\t\tport_max_hopid = port->config.max_out_hop_id;\n\t\tida = &port->out_hopids;\n\t}\n\n\t \n\tif (!tb_port_is_nhi(port) && min_hopid < TB_PATH_MIN_HOPID)\n\t\tmin_hopid = TB_PATH_MIN_HOPID;\n\n\tif (max_hopid < 0 || max_hopid > port_max_hopid)\n\t\tmax_hopid = port_max_hopid;\n\n\treturn ida_simple_get(ida, min_hopid, max_hopid + 1, GFP_KERNEL);\n}\n\n \nint tb_port_alloc_in_hopid(struct tb_port *port, int min_hopid, int max_hopid)\n{\n\treturn tb_port_alloc_hopid(port, true, min_hopid, max_hopid);\n}\n\n \nint tb_port_alloc_out_hopid(struct tb_port *port, int min_hopid, int max_hopid)\n{\n\treturn tb_port_alloc_hopid(port, false, min_hopid, max_hopid);\n}\n\n \nvoid tb_port_release_in_hopid(struct tb_port *port, int hopid)\n{\n\tida_simple_remove(&port->in_hopids, hopid);\n}\n\n \nvoid tb_port_release_out_hopid(struct tb_port *port, int hopid)\n{\n\tida_simple_remove(&port->out_hopids, hopid);\n}\n\nstatic inline bool tb_switch_is_reachable(const struct tb_switch *parent,\n\t\t\t\t\t  const struct tb_switch *sw)\n{\n\tu64 mask = (1ULL << parent->config.depth * 8) - 1;\n\treturn (tb_route(parent) & mask) == (tb_route(sw) & mask);\n}\n\n \nstruct tb_port *tb_next_port_on_path(struct tb_port *start, struct tb_port *end,\n\t\t\t\t     struct tb_port *prev)\n{\n\tstruct tb_port *next;\n\n\tif (!prev)\n\t\treturn start;\n\n\tif (prev->sw == end->sw) {\n\t\tif (prev == end)\n\t\t\treturn NULL;\n\t\treturn end;\n\t}\n\n\tif (tb_switch_is_reachable(prev->sw, end->sw)) {\n\t\tnext = tb_port_at(tb_route(end->sw), prev->sw);\n\t\t \n\t\tif (prev->remote &&\n\t\t    (next == prev || next->dual_link_port == prev))\n\t\t\tnext = prev->remote;\n\t} else {\n\t\tif (tb_is_upstream_port(prev)) {\n\t\t\tnext = prev->remote;\n\t\t} else {\n\t\t\tnext = tb_upstream_port(prev->sw);\n\t\t\t \n\t\t\tif (next->dual_link_port &&\n\t\t\t    next->link_nr != prev->link_nr) {\n\t\t\t\tnext = next->dual_link_port;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn next != prev ? next : NULL;\n}\n\n \nint tb_port_get_link_speed(struct tb_port *port)\n{\n\tu32 val, speed;\n\tint ret;\n\n\tif (!port->cap_phy)\n\t\treturn -EINVAL;\n\n\tret = tb_port_read(port, &val, TB_CFG_PORT,\n\t\t\t   port->cap_phy + LANE_ADP_CS_1, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tspeed = (val & LANE_ADP_CS_1_CURRENT_SPEED_MASK) >>\n\t\tLANE_ADP_CS_1_CURRENT_SPEED_SHIFT;\n\n\tswitch (speed) {\n\tcase LANE_ADP_CS_1_CURRENT_SPEED_GEN4:\n\t\treturn 40;\n\tcase LANE_ADP_CS_1_CURRENT_SPEED_GEN3:\n\t\treturn 20;\n\tdefault:\n\t\treturn 10;\n\t}\n}\n\n \nint tb_port_get_link_width(struct tb_port *port)\n{\n\tu32 val;\n\tint ret;\n\n\tif (!port->cap_phy)\n\t\treturn -EINVAL;\n\n\tret = tb_port_read(port, &val, TB_CFG_PORT,\n\t\t\t   port->cap_phy + LANE_ADP_CS_1, 1);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\treturn (val & LANE_ADP_CS_1_CURRENT_WIDTH_MASK) >>\n\t\tLANE_ADP_CS_1_CURRENT_WIDTH_SHIFT;\n}\n\nstatic bool tb_port_is_width_supported(struct tb_port *port,\n\t\t\t\t       unsigned int width_mask)\n{\n\tu32 phy, widths;\n\tint ret;\n\n\tif (!port->cap_phy)\n\t\treturn false;\n\n\tret = tb_port_read(port, &phy, TB_CFG_PORT,\n\t\t\t   port->cap_phy + LANE_ADP_CS_0, 1);\n\tif (ret)\n\t\treturn false;\n\n\twidths = (phy & LANE_ADP_CS_0_SUPPORTED_WIDTH_MASK) >>\n\t\tLANE_ADP_CS_0_SUPPORTED_WIDTH_SHIFT;\n\n\treturn widths & width_mask;\n}\n\nstatic bool is_gen4_link(struct tb_port *port)\n{\n\treturn tb_port_get_link_speed(port) > 20;\n}\n\n \nint tb_port_set_link_width(struct tb_port *port, enum tb_link_width width)\n{\n\tu32 val;\n\tint ret;\n\n\tif (!port->cap_phy)\n\t\treturn -EINVAL;\n\n\tret = tb_port_read(port, &val, TB_CFG_PORT,\n\t\t\t   port->cap_phy + LANE_ADP_CS_1, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tval &= ~LANE_ADP_CS_1_TARGET_WIDTH_MASK;\n\tswitch (width) {\n\tcase TB_LINK_WIDTH_SINGLE:\n\t\t \n\t\tif (is_gen4_link(port))\n\t\t\treturn -EOPNOTSUPP;\n\t\tval |= LANE_ADP_CS_1_TARGET_WIDTH_SINGLE <<\n\t\t\tLANE_ADP_CS_1_TARGET_WIDTH_SHIFT;\n\t\tbreak;\n\tcase TB_LINK_WIDTH_DUAL:\n\t\tval |= LANE_ADP_CS_1_TARGET_WIDTH_DUAL <<\n\t\t\tLANE_ADP_CS_1_TARGET_WIDTH_SHIFT;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn tb_port_write(port, &val, TB_CFG_PORT,\n\t\t\t     port->cap_phy + LANE_ADP_CS_1, 1);\n}\n\n \nstatic int tb_port_set_lane_bonding(struct tb_port *port, bool bonding)\n{\n\tu32 val;\n\tint ret;\n\n\tif (!port->cap_phy)\n\t\treturn -EINVAL;\n\n\tret = tb_port_read(port, &val, TB_CFG_PORT,\n\t\t\t   port->cap_phy + LANE_ADP_CS_1, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tif (bonding)\n\t\tval |= LANE_ADP_CS_1_LB;\n\telse\n\t\tval &= ~LANE_ADP_CS_1_LB;\n\n\treturn tb_port_write(port, &val, TB_CFG_PORT,\n\t\t\t     port->cap_phy + LANE_ADP_CS_1, 1);\n}\n\n \nint tb_port_lane_bonding_enable(struct tb_port *port)\n{\n\tenum tb_link_width width;\n\tint ret;\n\n\t \n\twidth = tb_port_get_link_width(port);\n\tif (width == TB_LINK_WIDTH_SINGLE) {\n\t\tret = tb_port_set_link_width(port, TB_LINK_WIDTH_DUAL);\n\t\tif (ret)\n\t\t\tgoto err_lane0;\n\t}\n\n\twidth = tb_port_get_link_width(port->dual_link_port);\n\tif (width == TB_LINK_WIDTH_SINGLE) {\n\t\tret = tb_port_set_link_width(port->dual_link_port,\n\t\t\t\t\t     TB_LINK_WIDTH_DUAL);\n\t\tif (ret)\n\t\t\tgoto err_lane0;\n\t}\n\n\t \n\tif (width == TB_LINK_WIDTH_SINGLE && !tb_is_upstream_port(port)) {\n\t\tret = tb_port_set_lane_bonding(port, true);\n\t\tif (ret)\n\t\t\tgoto err_lane1;\n\t}\n\n\t \n\tport->bonded = true;\n\tport->dual_link_port->bonded = true;\n\n\treturn 0;\n\nerr_lane1:\n\ttb_port_set_link_width(port->dual_link_port, TB_LINK_WIDTH_SINGLE);\nerr_lane0:\n\ttb_port_set_link_width(port, TB_LINK_WIDTH_SINGLE);\n\n\treturn ret;\n}\n\n \nvoid tb_port_lane_bonding_disable(struct tb_port *port)\n{\n\ttb_port_set_lane_bonding(port, false);\n\ttb_port_set_link_width(port->dual_link_port, TB_LINK_WIDTH_SINGLE);\n\ttb_port_set_link_width(port, TB_LINK_WIDTH_SINGLE);\n\tport->dual_link_port->bonded = false;\n\tport->bonded = false;\n}\n\n \nint tb_port_wait_for_link_width(struct tb_port *port, unsigned int width_mask,\n\t\t\t\tint timeout_msec)\n{\n\tktime_t timeout = ktime_add_ms(ktime_get(), timeout_msec);\n\tint ret;\n\n\t \n\tif ((width_mask & TB_LINK_WIDTH_SINGLE) && is_gen4_link(port))\n\t\treturn -EOPNOTSUPP;\n\n\tdo {\n\t\tret = tb_port_get_link_width(port);\n\t\tif (ret < 0) {\n\t\t\t \n\t\t\tif (ret != -EACCES)\n\t\t\t\treturn ret;\n\t\t} else if (ret & width_mask) {\n\t\t\treturn 0;\n\t\t}\n\n\t\tusleep_range(1000, 2000);\n\t} while (ktime_before(ktime_get(), timeout));\n\n\treturn -ETIMEDOUT;\n}\n\nstatic int tb_port_do_update_credits(struct tb_port *port)\n{\n\tu32 nfc_credits;\n\tint ret;\n\n\tret = tb_port_read(port, &nfc_credits, TB_CFG_PORT, ADP_CS_4, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tif (nfc_credits != port->config.nfc_credits) {\n\t\tu32 total;\n\n\t\ttotal = (nfc_credits & ADP_CS_4_TOTAL_BUFFERS_MASK) >>\n\t\t\tADP_CS_4_TOTAL_BUFFERS_SHIFT;\n\n\t\ttb_port_dbg(port, \"total credits changed %u -> %u\\n\",\n\t\t\t    port->total_credits, total);\n\n\t\tport->config.nfc_credits = nfc_credits;\n\t\tport->total_credits = total;\n\t}\n\n\treturn 0;\n}\n\n \nint tb_port_update_credits(struct tb_port *port)\n{\n\tint ret;\n\n\tret = tb_port_do_update_credits(port);\n\tif (ret)\n\t\treturn ret;\n\treturn tb_port_do_update_credits(port->dual_link_port);\n}\n\nstatic int tb_port_start_lane_initialization(struct tb_port *port)\n{\n\tint ret;\n\n\tif (tb_switch_is_usb4(port->sw))\n\t\treturn 0;\n\n\tret = tb_lc_start_lane_initialization(port);\n\treturn ret == -EINVAL ? 0 : ret;\n}\n\n \nstatic bool tb_port_resume(struct tb_port *port)\n{\n\tbool has_remote = tb_port_has_remote(port);\n\n\tif (port->usb4) {\n\t\tusb4_port_device_resume(port->usb4);\n\t} else if (!has_remote) {\n\t\t \n\t\tif (!tb_is_upstream_port(port) || port->xdomain)\n\t\t\ttb_port_start_lane_initialization(port);\n\t}\n\n\treturn has_remote || port->xdomain;\n}\n\n \nbool tb_port_is_enabled(struct tb_port *port)\n{\n\tswitch (port->config.type) {\n\tcase TB_TYPE_PCIE_UP:\n\tcase TB_TYPE_PCIE_DOWN:\n\t\treturn tb_pci_port_is_enabled(port);\n\n\tcase TB_TYPE_DP_HDMI_IN:\n\tcase TB_TYPE_DP_HDMI_OUT:\n\t\treturn tb_dp_port_is_enabled(port);\n\n\tcase TB_TYPE_USB3_UP:\n\tcase TB_TYPE_USB3_DOWN:\n\t\treturn tb_usb3_port_is_enabled(port);\n\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nbool tb_usb3_port_is_enabled(struct tb_port *port)\n{\n\tu32 data;\n\n\tif (tb_port_read(port, &data, TB_CFG_PORT,\n\t\t\t port->cap_adap + ADP_USB3_CS_0, 1))\n\t\treturn false;\n\n\treturn !!(data & ADP_USB3_CS_0_PE);\n}\n\n \nint tb_usb3_port_enable(struct tb_port *port, bool enable)\n{\n\tu32 word = enable ? (ADP_USB3_CS_0_PE | ADP_USB3_CS_0_V)\n\t\t\t  : ADP_USB3_CS_0_V;\n\n\tif (!port->cap_adap)\n\t\treturn -ENXIO;\n\treturn tb_port_write(port, &word, TB_CFG_PORT,\n\t\t\t     port->cap_adap + ADP_USB3_CS_0, 1);\n}\n\n \nbool tb_pci_port_is_enabled(struct tb_port *port)\n{\n\tu32 data;\n\n\tif (tb_port_read(port, &data, TB_CFG_PORT,\n\t\t\t port->cap_adap + ADP_PCIE_CS_0, 1))\n\t\treturn false;\n\n\treturn !!(data & ADP_PCIE_CS_0_PE);\n}\n\n \nint tb_pci_port_enable(struct tb_port *port, bool enable)\n{\n\tu32 word = enable ? ADP_PCIE_CS_0_PE : 0x0;\n\tif (!port->cap_adap)\n\t\treturn -ENXIO;\n\treturn tb_port_write(port, &word, TB_CFG_PORT,\n\t\t\t     port->cap_adap + ADP_PCIE_CS_0, 1);\n}\n\n \nint tb_dp_port_hpd_is_active(struct tb_port *port)\n{\n\tu32 data;\n\tint ret;\n\n\tret = tb_port_read(port, &data, TB_CFG_PORT,\n\t\t\t   port->cap_adap + ADP_DP_CS_2, 1);\n\tif (ret)\n\t\treturn ret;\n\n\treturn !!(data & ADP_DP_CS_2_HDP);\n}\n\n \nint tb_dp_port_hpd_clear(struct tb_port *port)\n{\n\tu32 data;\n\tint ret;\n\n\tret = tb_port_read(port, &data, TB_CFG_PORT,\n\t\t\t   port->cap_adap + ADP_DP_CS_3, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tdata |= ADP_DP_CS_3_HDPC;\n\treturn tb_port_write(port, &data, TB_CFG_PORT,\n\t\t\t     port->cap_adap + ADP_DP_CS_3, 1);\n}\n\n \nint tb_dp_port_set_hops(struct tb_port *port, unsigned int video,\n\t\t\tunsigned int aux_tx, unsigned int aux_rx)\n{\n\tu32 data[2];\n\tint ret;\n\n\tif (tb_switch_is_usb4(port->sw))\n\t\treturn 0;\n\n\tret = tb_port_read(port, data, TB_CFG_PORT,\n\t\t\t   port->cap_adap + ADP_DP_CS_0, ARRAY_SIZE(data));\n\tif (ret)\n\t\treturn ret;\n\n\tdata[0] &= ~ADP_DP_CS_0_VIDEO_HOPID_MASK;\n\tdata[1] &= ~ADP_DP_CS_1_AUX_RX_HOPID_MASK;\n\tdata[1] &= ~ADP_DP_CS_1_AUX_RX_HOPID_MASK;\n\n\tdata[0] |= (video << ADP_DP_CS_0_VIDEO_HOPID_SHIFT) &\n\t\tADP_DP_CS_0_VIDEO_HOPID_MASK;\n\tdata[1] |= aux_tx & ADP_DP_CS_1_AUX_TX_HOPID_MASK;\n\tdata[1] |= (aux_rx << ADP_DP_CS_1_AUX_RX_HOPID_SHIFT) &\n\t\tADP_DP_CS_1_AUX_RX_HOPID_MASK;\n\n\treturn tb_port_write(port, data, TB_CFG_PORT,\n\t\t\t     port->cap_adap + ADP_DP_CS_0, ARRAY_SIZE(data));\n}\n\n \nbool tb_dp_port_is_enabled(struct tb_port *port)\n{\n\tu32 data[2];\n\n\tif (tb_port_read(port, data, TB_CFG_PORT, port->cap_adap + ADP_DP_CS_0,\n\t\t\t ARRAY_SIZE(data)))\n\t\treturn false;\n\n\treturn !!(data[0] & (ADP_DP_CS_0_VE | ADP_DP_CS_0_AE));\n}\n\n \nint tb_dp_port_enable(struct tb_port *port, bool enable)\n{\n\tu32 data[2];\n\tint ret;\n\n\tret = tb_port_read(port, data, TB_CFG_PORT,\n\t\t\t  port->cap_adap + ADP_DP_CS_0, ARRAY_SIZE(data));\n\tif (ret)\n\t\treturn ret;\n\n\tif (enable)\n\t\tdata[0] |= ADP_DP_CS_0_VE | ADP_DP_CS_0_AE;\n\telse\n\t\tdata[0] &= ~(ADP_DP_CS_0_VE | ADP_DP_CS_0_AE);\n\n\treturn tb_port_write(port, data, TB_CFG_PORT,\n\t\t\t     port->cap_adap + ADP_DP_CS_0, ARRAY_SIZE(data));\n}\n\n \n\nstatic const char *tb_switch_generation_name(const struct tb_switch *sw)\n{\n\tswitch (sw->generation) {\n\tcase 1:\n\t\treturn \"Thunderbolt 1\";\n\tcase 2:\n\t\treturn \"Thunderbolt 2\";\n\tcase 3:\n\t\treturn \"Thunderbolt 3\";\n\tcase 4:\n\t\treturn \"USB4\";\n\tdefault:\n\t\treturn \"Unknown\";\n\t}\n}\n\nstatic void tb_dump_switch(const struct tb *tb, const struct tb_switch *sw)\n{\n\tconst struct tb_regs_switch_header *regs = &sw->config;\n\n\ttb_dbg(tb, \" %s Switch: %x:%x (Revision: %d, TB Version: %d)\\n\",\n\t       tb_switch_generation_name(sw), regs->vendor_id, regs->device_id,\n\t       regs->revision, regs->thunderbolt_version);\n\ttb_dbg(tb, \"  Max Port Number: %d\\n\", regs->max_port_number);\n\ttb_dbg(tb, \"  Config:\\n\");\n\ttb_dbg(tb,\n\t\t\"   Upstream Port Number: %d Depth: %d Route String: %#llx Enabled: %d, PlugEventsDelay: %dms\\n\",\n\t       regs->upstream_port_number, regs->depth,\n\t       (((u64) regs->route_hi) << 32) | regs->route_lo,\n\t       regs->enabled, regs->plug_events_delay);\n\ttb_dbg(tb, \"   unknown1: %#x unknown4: %#x\\n\",\n\t       regs->__unknown1, regs->__unknown4);\n}\n\n \nint tb_switch_reset(struct tb_switch *sw)\n{\n\tstruct tb_cfg_result res;\n\n\tif (sw->generation > 1)\n\t\treturn 0;\n\n\ttb_sw_dbg(sw, \"resetting switch\\n\");\n\n\tres.err = tb_sw_write(sw, ((u32 *) &sw->config) + 2,\n\t\t\t      TB_CFG_SWITCH, 2, 2);\n\tif (res.err)\n\t\treturn res.err;\n\tres = tb_cfg_reset(sw->tb->ctl, tb_route(sw));\n\tif (res.err > 0)\n\t\treturn -EIO;\n\treturn res.err;\n}\n\n \nint tb_switch_wait_for_bit(struct tb_switch *sw, u32 offset, u32 bit,\n\t\t\t   u32 value, int timeout_msec)\n{\n\tktime_t timeout = ktime_add_ms(ktime_get(), timeout_msec);\n\n\tdo {\n\t\tu32 val;\n\t\tint ret;\n\n\t\tret = tb_sw_read(sw, &val, TB_CFG_SWITCH, offset, 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif ((val & bit) == value)\n\t\t\treturn 0;\n\n\t\tusleep_range(50, 100);\n\t} while (ktime_before(ktime_get(), timeout));\n\n\treturn -ETIMEDOUT;\n}\n\n \nstatic int tb_plug_events_active(struct tb_switch *sw, bool active)\n{\n\tu32 data;\n\tint res;\n\n\tif (tb_switch_is_icm(sw) || tb_switch_is_usb4(sw))\n\t\treturn 0;\n\n\tsw->config.plug_events_delay = 0xff;\n\tres = tb_sw_write(sw, ((u32 *) &sw->config) + 4, TB_CFG_SWITCH, 4, 1);\n\tif (res)\n\t\treturn res;\n\n\tres = tb_sw_read(sw, &data, TB_CFG_SWITCH, sw->cap_plug_events + 1, 1);\n\tif (res)\n\t\treturn res;\n\n\tif (active) {\n\t\tdata = data & 0xFFFFFF83;\n\t\tswitch (sw->config.device_id) {\n\t\tcase PCI_DEVICE_ID_INTEL_LIGHT_RIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_EAGLE_RIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_PORT_RIDGE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tif (!tb_switch_is_alpine_ridge(sw))\n\t\t\t\tdata |= TB_PLUG_EVENTS_USB_DISABLE;\n\t\t}\n\t} else {\n\t\tdata = data | 0x7c;\n\t}\n\treturn tb_sw_write(sw, &data, TB_CFG_SWITCH,\n\t\t\t   sw->cap_plug_events + 1, 1);\n}\n\nstatic ssize_t authorized_show(struct device *dev,\n\t\t\t       struct device_attribute *attr,\n\t\t\t       char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\treturn sysfs_emit(buf, \"%u\\n\", sw->authorized);\n}\n\nstatic int disapprove_switch(struct device *dev, void *not_used)\n{\n\tchar *envp[] = { \"AUTHORIZED=0\", NULL };\n\tstruct tb_switch *sw;\n\n\tsw = tb_to_switch(dev);\n\tif (sw && sw->authorized) {\n\t\tint ret;\n\n\t\t \n\t\tret = device_for_each_child_reverse(&sw->dev, NULL, disapprove_switch);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = tb_domain_disapprove_switch(sw->tb, sw);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tsw->authorized = 0;\n\t\tkobject_uevent_env(&sw->dev.kobj, KOBJ_CHANGE, envp);\n\t}\n\n\treturn 0;\n}\n\nstatic int tb_switch_set_authorized(struct tb_switch *sw, unsigned int val)\n{\n\tchar envp_string[13];\n\tint ret = -EINVAL;\n\tchar *envp[] = { envp_string, NULL };\n\n\tif (!mutex_trylock(&sw->tb->lock))\n\t\treturn restart_syscall();\n\n\tif (!!sw->authorized == !!val)\n\t\tgoto unlock;\n\n\tswitch (val) {\n\t \n\tcase 0:\n\t\tif (tb_route(sw)) {\n\t\t\tret = disapprove_switch(&sw->dev, NULL);\n\t\t\tgoto unlock;\n\t\t}\n\t\tbreak;\n\n\t \n\tcase 1:\n\t\tif (sw->key)\n\t\t\tret = tb_domain_approve_switch_key(sw->tb, sw);\n\t\telse\n\t\t\tret = tb_domain_approve_switch(sw->tb, sw);\n\t\tbreak;\n\n\t \n\tcase 2:\n\t\tif (sw->key)\n\t\t\tret = tb_domain_challenge_switch_key(sw->tb, sw);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (!ret) {\n\t\tsw->authorized = val;\n\t\t \n\t\tsprintf(envp_string, \"AUTHORIZED=%u\", sw->authorized);\n\t\tkobject_uevent_env(&sw->dev.kobj, KOBJ_CHANGE, envp);\n\t}\n\nunlock:\n\tmutex_unlock(&sw->tb->lock);\n\treturn ret;\n}\n\nstatic ssize_t authorized_store(struct device *dev,\n\t\t\t\tstruct device_attribute *attr,\n\t\t\t\tconst char *buf, size_t count)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tunsigned int val;\n\tssize_t ret;\n\n\tret = kstrtouint(buf, 0, &val);\n\tif (ret)\n\t\treturn ret;\n\tif (val > 2)\n\t\treturn -EINVAL;\n\n\tpm_runtime_get_sync(&sw->dev);\n\tret = tb_switch_set_authorized(sw, val);\n\tpm_runtime_mark_last_busy(&sw->dev);\n\tpm_runtime_put_autosuspend(&sw->dev);\n\n\treturn ret ? ret : count;\n}\nstatic DEVICE_ATTR_RW(authorized);\n\nstatic ssize_t boot_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\treturn sysfs_emit(buf, \"%u\\n\", sw->boot);\n}\nstatic DEVICE_ATTR_RO(boot);\n\nstatic ssize_t device_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\treturn sysfs_emit(buf, \"%#x\\n\", sw->device);\n}\nstatic DEVICE_ATTR_RO(device);\n\nstatic ssize_t\ndevice_name_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\", sw->device_name ?: \"\");\n}\nstatic DEVICE_ATTR_RO(device_name);\n\nstatic ssize_t\ngeneration_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\treturn sysfs_emit(buf, \"%u\\n\", sw->generation);\n}\nstatic DEVICE_ATTR_RO(generation);\n\nstatic ssize_t key_show(struct device *dev, struct device_attribute *attr,\n\t\t\tchar *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tssize_t ret;\n\n\tif (!mutex_trylock(&sw->tb->lock))\n\t\treturn restart_syscall();\n\n\tif (sw->key)\n\t\tret = sysfs_emit(buf, \"%*phN\\n\", TB_SWITCH_KEY_SIZE, sw->key);\n\telse\n\t\tret = sysfs_emit(buf, \"\\n\");\n\n\tmutex_unlock(&sw->tb->lock);\n\treturn ret;\n}\n\nstatic ssize_t key_store(struct device *dev, struct device_attribute *attr,\n\t\t\t const char *buf, size_t count)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tu8 key[TB_SWITCH_KEY_SIZE];\n\tssize_t ret = count;\n\tbool clear = false;\n\n\tif (!strcmp(buf, \"\\n\"))\n\t\tclear = true;\n\telse if (hex2bin(key, buf, sizeof(key)))\n\t\treturn -EINVAL;\n\n\tif (!mutex_trylock(&sw->tb->lock))\n\t\treturn restart_syscall();\n\n\tif (sw->authorized) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tkfree(sw->key);\n\t\tif (clear) {\n\t\t\tsw->key = NULL;\n\t\t} else {\n\t\t\tsw->key = kmemdup(key, sizeof(key), GFP_KERNEL);\n\t\t\tif (!sw->key)\n\t\t\t\tret = -ENOMEM;\n\t\t}\n\t}\n\n\tmutex_unlock(&sw->tb->lock);\n\treturn ret;\n}\nstatic DEVICE_ATTR(key, 0600, key_show, key_store);\n\nstatic ssize_t speed_show(struct device *dev, struct device_attribute *attr,\n\t\t\t  char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\treturn sysfs_emit(buf, \"%u.0 Gb/s\\n\", sw->link_speed);\n}\n\n \nstatic DEVICE_ATTR(rx_speed, 0444, speed_show, NULL);\nstatic DEVICE_ATTR(tx_speed, 0444, speed_show, NULL);\n\nstatic ssize_t rx_lanes_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tunsigned int width;\n\n\tswitch (sw->link_width) {\n\tcase TB_LINK_WIDTH_SINGLE:\n\tcase TB_LINK_WIDTH_ASYM_TX:\n\t\twidth = 1;\n\t\tbreak;\n\tcase TB_LINK_WIDTH_DUAL:\n\t\twidth = 2;\n\t\tbreak;\n\tcase TB_LINK_WIDTH_ASYM_RX:\n\t\twidth = 3;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn -EINVAL;\n\t}\n\n\treturn sysfs_emit(buf, \"%u\\n\", width);\n}\nstatic DEVICE_ATTR(rx_lanes, 0444, rx_lanes_show, NULL);\n\nstatic ssize_t tx_lanes_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tunsigned int width;\n\n\tswitch (sw->link_width) {\n\tcase TB_LINK_WIDTH_SINGLE:\n\tcase TB_LINK_WIDTH_ASYM_RX:\n\t\twidth = 1;\n\t\tbreak;\n\tcase TB_LINK_WIDTH_DUAL:\n\t\twidth = 2;\n\t\tbreak;\n\tcase TB_LINK_WIDTH_ASYM_TX:\n\t\twidth = 3;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn -EINVAL;\n\t}\n\n\treturn sysfs_emit(buf, \"%u\\n\", width);\n}\nstatic DEVICE_ATTR(tx_lanes, 0444, tx_lanes_show, NULL);\n\nstatic ssize_t nvm_authenticate_show(struct device *dev,\n\tstruct device_attribute *attr, char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tu32 status;\n\n\tnvm_get_auth_status(sw, &status);\n\treturn sysfs_emit(buf, \"%#x\\n\", status);\n}\n\nstatic ssize_t nvm_authenticate_sysfs(struct device *dev, const char *buf,\n\t\t\t\t      bool disconnect)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tint val, ret;\n\n\tpm_runtime_get_sync(&sw->dev);\n\n\tif (!mutex_trylock(&sw->tb->lock)) {\n\t\tret = restart_syscall();\n\t\tgoto exit_rpm;\n\t}\n\n\tif (sw->no_nvm_upgrade) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto exit_unlock;\n\t}\n\n\t \n\tif (!sw->nvm) {\n\t\tret = -EAGAIN;\n\t\tgoto exit_unlock;\n\t}\n\n\tret = kstrtoint(buf, 10, &val);\n\tif (ret)\n\t\tgoto exit_unlock;\n\n\t \n\tnvm_clear_auth_status(sw);\n\n\tif (val > 0) {\n\t\tif (val == AUTHENTICATE_ONLY) {\n\t\t\tif (disconnect)\n\t\t\t\tret = -EINVAL;\n\t\t\telse\n\t\t\t\tret = nvm_authenticate(sw, true);\n\t\t} else {\n\t\t\tif (!sw->nvm->flushed) {\n\t\t\t\tif (!sw->nvm->buf) {\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\t\tgoto exit_unlock;\n\t\t\t\t}\n\n\t\t\t\tret = nvm_validate_and_write(sw);\n\t\t\t\tif (ret || val == WRITE_ONLY)\n\t\t\t\t\tgoto exit_unlock;\n\t\t\t}\n\t\t\tif (val == WRITE_AND_AUTHENTICATE) {\n\t\t\t\tif (disconnect)\n\t\t\t\t\tret = tb_lc_force_power(sw);\n\t\t\t\telse\n\t\t\t\t\tret = nvm_authenticate(sw, false);\n\t\t\t}\n\t\t}\n\t}\n\nexit_unlock:\n\tmutex_unlock(&sw->tb->lock);\nexit_rpm:\n\tpm_runtime_mark_last_busy(&sw->dev);\n\tpm_runtime_put_autosuspend(&sw->dev);\n\n\treturn ret;\n}\n\nstatic ssize_t nvm_authenticate_store(struct device *dev,\n\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tint ret = nvm_authenticate_sysfs(dev, buf, false);\n\tif (ret)\n\t\treturn ret;\n\treturn count;\n}\nstatic DEVICE_ATTR_RW(nvm_authenticate);\n\nstatic ssize_t nvm_authenticate_on_disconnect_show(struct device *dev,\n\tstruct device_attribute *attr, char *buf)\n{\n\treturn nvm_authenticate_show(dev, attr, buf);\n}\n\nstatic ssize_t nvm_authenticate_on_disconnect_store(struct device *dev,\n\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tint ret;\n\n\tret = nvm_authenticate_sysfs(dev, buf, true);\n\treturn ret ? ret : count;\n}\nstatic DEVICE_ATTR_RW(nvm_authenticate_on_disconnect);\n\nstatic ssize_t nvm_version_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tint ret;\n\n\tif (!mutex_trylock(&sw->tb->lock))\n\t\treturn restart_syscall();\n\n\tif (sw->safe_mode)\n\t\tret = -ENODATA;\n\telse if (!sw->nvm)\n\t\tret = -EAGAIN;\n\telse\n\t\tret = sysfs_emit(buf, \"%x.%x\\n\", sw->nvm->major, sw->nvm->minor);\n\n\tmutex_unlock(&sw->tb->lock);\n\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(nvm_version);\n\nstatic ssize_t vendor_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\treturn sysfs_emit(buf, \"%#x\\n\", sw->vendor);\n}\nstatic DEVICE_ATTR_RO(vendor);\n\nstatic ssize_t\nvendor_name_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\", sw->vendor_name ?: \"\");\n}\nstatic DEVICE_ATTR_RO(vendor_name);\n\nstatic ssize_t unique_id_show(struct device *dev, struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\treturn sysfs_emit(buf, \"%pUb\\n\", sw->uuid);\n}\nstatic DEVICE_ATTR_RO(unique_id);\n\nstatic struct attribute *switch_attrs[] = {\n\t&dev_attr_authorized.attr,\n\t&dev_attr_boot.attr,\n\t&dev_attr_device.attr,\n\t&dev_attr_device_name.attr,\n\t&dev_attr_generation.attr,\n\t&dev_attr_key.attr,\n\t&dev_attr_nvm_authenticate.attr,\n\t&dev_attr_nvm_authenticate_on_disconnect.attr,\n\t&dev_attr_nvm_version.attr,\n\t&dev_attr_rx_speed.attr,\n\t&dev_attr_rx_lanes.attr,\n\t&dev_attr_tx_speed.attr,\n\t&dev_attr_tx_lanes.attr,\n\t&dev_attr_vendor.attr,\n\t&dev_attr_vendor_name.attr,\n\t&dev_attr_unique_id.attr,\n\tNULL,\n};\n\nstatic umode_t switch_attr_is_visible(struct kobject *kobj,\n\t\t\t\t      struct attribute *attr, int n)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\tif (attr == &dev_attr_authorized.attr) {\n\t\tif (sw->tb->security_level == TB_SECURITY_NOPCIE ||\n\t\t    sw->tb->security_level == TB_SECURITY_DPONLY)\n\t\t\treturn 0;\n\t} else if (attr == &dev_attr_device.attr) {\n\t\tif (!sw->device)\n\t\t\treturn 0;\n\t} else if (attr == &dev_attr_device_name.attr) {\n\t\tif (!sw->device_name)\n\t\t\treturn 0;\n\t} else if (attr == &dev_attr_vendor.attr)  {\n\t\tif (!sw->vendor)\n\t\t\treturn 0;\n\t} else if (attr == &dev_attr_vendor_name.attr)  {\n\t\tif (!sw->vendor_name)\n\t\t\treturn 0;\n\t} else if (attr == &dev_attr_key.attr) {\n\t\tif (tb_route(sw) &&\n\t\t    sw->tb->security_level == TB_SECURITY_SECURE &&\n\t\t    sw->security_level == TB_SECURITY_SECURE)\n\t\t\treturn attr->mode;\n\t\treturn 0;\n\t} else if (attr == &dev_attr_rx_speed.attr ||\n\t\t   attr == &dev_attr_rx_lanes.attr ||\n\t\t   attr == &dev_attr_tx_speed.attr ||\n\t\t   attr == &dev_attr_tx_lanes.attr) {\n\t\tif (tb_route(sw))\n\t\t\treturn attr->mode;\n\t\treturn 0;\n\t} else if (attr == &dev_attr_nvm_authenticate.attr) {\n\t\tif (nvm_upgradeable(sw))\n\t\t\treturn attr->mode;\n\t\treturn 0;\n\t} else if (attr == &dev_attr_nvm_version.attr) {\n\t\tif (nvm_readable(sw))\n\t\t\treturn attr->mode;\n\t\treturn 0;\n\t} else if (attr == &dev_attr_boot.attr) {\n\t\tif (tb_route(sw))\n\t\t\treturn attr->mode;\n\t\treturn 0;\n\t} else if (attr == &dev_attr_nvm_authenticate_on_disconnect.attr) {\n\t\tif (sw->quirks & QUIRK_FORCE_POWER_LINK_CONTROLLER)\n\t\t\treturn attr->mode;\n\t\treturn 0;\n\t}\n\n\treturn sw->safe_mode ? 0 : attr->mode;\n}\n\nstatic const struct attribute_group switch_group = {\n\t.is_visible = switch_attr_is_visible,\n\t.attrs = switch_attrs,\n};\n\nstatic const struct attribute_group *switch_groups[] = {\n\t&switch_group,\n\tNULL,\n};\n\nstatic void tb_switch_release(struct device *dev)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tstruct tb_port *port;\n\n\tdma_port_free(sw->dma_port);\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tida_destroy(&port->in_hopids);\n\t\tida_destroy(&port->out_hopids);\n\t}\n\n\tkfree(sw->uuid);\n\tkfree(sw->device_name);\n\tkfree(sw->vendor_name);\n\tkfree(sw->ports);\n\tkfree(sw->drom);\n\tkfree(sw->key);\n\tkfree(sw);\n}\n\nstatic int tb_switch_uevent(const struct device *dev, struct kobj_uevent_env *env)\n{\n\tconst struct tb_switch *sw = tb_to_switch(dev);\n\tconst char *type;\n\n\tif (tb_switch_is_usb4(sw)) {\n\t\tif (add_uevent_var(env, \"USB4_VERSION=%u.0\",\n\t\t\t\t   usb4_switch_version(sw)))\n\t\t\treturn -ENOMEM;\n\t}\n\n\tif (!tb_route(sw)) {\n\t\ttype = \"host\";\n\t} else {\n\t\tconst struct tb_port *port;\n\t\tbool hub = false;\n\n\t\t \n\t\ttb_switch_for_each_port(sw, port) {\n\t\t\tif (!port->disabled && !tb_is_upstream_port(port) &&\n\t\t\t     tb_port_is_null(port)) {\n\t\t\t\thub = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttype = hub ? \"hub\" : \"device\";\n\t}\n\n\tif (add_uevent_var(env, \"USB4_TYPE=%s\", type))\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\n \nstatic int __maybe_unused tb_switch_runtime_suspend(struct device *dev)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tconst struct tb_cm_ops *cm_ops = sw->tb->cm_ops;\n\n\tif (cm_ops->runtime_suspend_switch)\n\t\treturn cm_ops->runtime_suspend_switch(sw);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused tb_switch_runtime_resume(struct device *dev)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tconst struct tb_cm_ops *cm_ops = sw->tb->cm_ops;\n\n\tif (cm_ops->runtime_resume_switch)\n\t\treturn cm_ops->runtime_resume_switch(sw);\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops tb_switch_pm_ops = {\n\tSET_RUNTIME_PM_OPS(tb_switch_runtime_suspend, tb_switch_runtime_resume,\n\t\t\t   NULL)\n};\n\nstruct device_type tb_switch_type = {\n\t.name = \"thunderbolt_device\",\n\t.release = tb_switch_release,\n\t.uevent = tb_switch_uevent,\n\t.pm = &tb_switch_pm_ops,\n};\n\nstatic int tb_switch_get_generation(struct tb_switch *sw)\n{\n\tif (tb_switch_is_usb4(sw))\n\t\treturn 4;\n\n\tif (sw->config.vendor_id == PCI_VENDOR_ID_INTEL) {\n\t\tswitch (sw->config.device_id) {\n\t\tcase PCI_DEVICE_ID_INTEL_LIGHT_RIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_EAGLE_RIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_LIGHT_PEAK:\n\t\tcase PCI_DEVICE_ID_INTEL_CACTUS_RIDGE_2C:\n\t\tcase PCI_DEVICE_ID_INTEL_CACTUS_RIDGE_4C:\n\t\tcase PCI_DEVICE_ID_INTEL_PORT_RIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_REDWOOD_RIDGE_2C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_REDWOOD_RIDGE_4C_BRIDGE:\n\t\t\treturn 1;\n\n\t\tcase PCI_DEVICE_ID_INTEL_WIN_RIDGE_2C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_FALCON_RIDGE_2C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_FALCON_RIDGE_4C_BRIDGE:\n\t\t\treturn 2;\n\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_LP_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_2C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_4C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_2C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_4C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_TITAN_RIDGE_2C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_TITAN_RIDGE_4C_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_TITAN_RIDGE_DD_BRIDGE:\n\t\tcase PCI_DEVICE_ID_INTEL_ICL_NHI0:\n\t\tcase PCI_DEVICE_ID_INTEL_ICL_NHI1:\n\t\t\treturn 3;\n\t\t}\n\t}\n\n\t \n\ttb_sw_warn(sw, \"unsupported switch device id %#x\\n\",\n\t\t   sw->config.device_id);\n\treturn 1;\n}\n\nstatic bool tb_switch_exceeds_max_depth(const struct tb_switch *sw, int depth)\n{\n\tint max_depth;\n\n\tif (tb_switch_is_usb4(sw) ||\n\t    (sw->tb->root_switch && tb_switch_is_usb4(sw->tb->root_switch)))\n\t\tmax_depth = USB4_SWITCH_MAX_DEPTH;\n\telse\n\t\tmax_depth = TB_SWITCH_MAX_DEPTH;\n\n\treturn depth > max_depth;\n}\n\n \nstruct tb_switch *tb_switch_alloc(struct tb *tb, struct device *parent,\n\t\t\t\t  u64 route)\n{\n\tstruct tb_switch *sw;\n\tint upstream_port;\n\tint i, ret, depth;\n\n\t \n\tif (route) {\n\t\tstruct tb_switch *parent_sw = tb_to_switch(parent);\n\t\tstruct tb_port *down;\n\n\t\tdown = tb_port_at(route, parent_sw);\n\t\ttb_port_unlock(down);\n\t}\n\n\tdepth = tb_route_length(route);\n\n\tupstream_port = tb_cfg_get_upstream_port(tb->ctl, route);\n\tif (upstream_port < 0)\n\t\treturn ERR_PTR(upstream_port);\n\n\tsw = kzalloc(sizeof(*sw), GFP_KERNEL);\n\tif (!sw)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tsw->tb = tb;\n\tret = tb_cfg_read(tb->ctl, &sw->config, route, 0, TB_CFG_SWITCH, 0, 5);\n\tif (ret)\n\t\tgoto err_free_sw_ports;\n\n\tsw->generation = tb_switch_get_generation(sw);\n\n\ttb_dbg(tb, \"current switch config:\\n\");\n\ttb_dump_switch(tb, sw);\n\n\t \n\tsw->config.upstream_port_number = upstream_port;\n\tsw->config.depth = depth;\n\tsw->config.route_hi = upper_32_bits(route);\n\tsw->config.route_lo = lower_32_bits(route);\n\tsw->config.enabled = 0;\n\n\t \n\tif (tb_switch_exceeds_max_depth(sw, depth)) {\n\t\tret = -EADDRNOTAVAIL;\n\t\tgoto err_free_sw_ports;\n\t}\n\n\t \n\tsw->ports = kcalloc(sw->config.max_port_number + 1, sizeof(*sw->ports),\n\t\t\t\tGFP_KERNEL);\n\tif (!sw->ports) {\n\t\tret = -ENOMEM;\n\t\tgoto err_free_sw_ports;\n\t}\n\n\tfor (i = 0; i <= sw->config.max_port_number; i++) {\n\t\t \n\t\tsw->ports[i].sw = sw;\n\t\tsw->ports[i].port = i;\n\n\t\t \n\t\tif (i) {\n\t\t\tida_init(&sw->ports[i].in_hopids);\n\t\t\tida_init(&sw->ports[i].out_hopids);\n\t\t}\n\t}\n\n\tret = tb_switch_find_vse_cap(sw, TB_VSE_CAP_PLUG_EVENTS);\n\tif (ret > 0)\n\t\tsw->cap_plug_events = ret;\n\n\tret = tb_switch_find_vse_cap(sw, TB_VSE_CAP_TIME2);\n\tif (ret > 0)\n\t\tsw->cap_vsec_tmu = ret;\n\n\tret = tb_switch_find_vse_cap(sw, TB_VSE_CAP_LINK_CONTROLLER);\n\tif (ret > 0)\n\t\tsw->cap_lc = ret;\n\n\tret = tb_switch_find_vse_cap(sw, TB_VSE_CAP_CP_LP);\n\tif (ret > 0)\n\t\tsw->cap_lp = ret;\n\n\t \n\tif (!route)\n\t\tsw->authorized = true;\n\n\tdevice_initialize(&sw->dev);\n\tsw->dev.parent = parent;\n\tsw->dev.bus = &tb_bus_type;\n\tsw->dev.type = &tb_switch_type;\n\tsw->dev.groups = switch_groups;\n\tdev_set_name(&sw->dev, \"%u-%llx\", tb->index, tb_route(sw));\n\n\treturn sw;\n\nerr_free_sw_ports:\n\tkfree(sw->ports);\n\tkfree(sw);\n\n\treturn ERR_PTR(ret);\n}\n\n \nstruct tb_switch *\ntb_switch_alloc_safe_mode(struct tb *tb, struct device *parent, u64 route)\n{\n\tstruct tb_switch *sw;\n\n\tsw = kzalloc(sizeof(*sw), GFP_KERNEL);\n\tif (!sw)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tsw->tb = tb;\n\tsw->config.depth = tb_route_length(route);\n\tsw->config.route_hi = upper_32_bits(route);\n\tsw->config.route_lo = lower_32_bits(route);\n\tsw->safe_mode = true;\n\n\tdevice_initialize(&sw->dev);\n\tsw->dev.parent = parent;\n\tsw->dev.bus = &tb_bus_type;\n\tsw->dev.type = &tb_switch_type;\n\tsw->dev.groups = switch_groups;\n\tdev_set_name(&sw->dev, \"%u-%llx\", tb->index, tb_route(sw));\n\n\treturn sw;\n}\n\n \nint tb_switch_configure(struct tb_switch *sw)\n{\n\tstruct tb *tb = sw->tb;\n\tu64 route;\n\tint ret;\n\n\troute = tb_route(sw);\n\n\ttb_dbg(tb, \"%s Switch at %#llx (depth: %d, up port: %d)\\n\",\n\t       sw->config.enabled ? \"restoring\" : \"initializing\", route,\n\t       tb_route_length(route), sw->config.upstream_port_number);\n\n\tsw->config.enabled = 1;\n\n\tif (tb_switch_is_usb4(sw)) {\n\t\t \n\t\tif (usb4_switch_version(sw) < 2)\n\t\t\tsw->config.cmuv = ROUTER_CS_4_CMUV_V1;\n\t\telse\n\t\t\tsw->config.cmuv = ROUTER_CS_4_CMUV_V2;\n\t\tsw->config.plug_events_delay = 0xa;\n\n\t\t \n\t\tret = tb_sw_write(sw, (u32 *)&sw->config + 1, TB_CFG_SWITCH,\n\t\t\t\t  ROUTER_CS_1, 4);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = usb4_switch_setup(sw);\n\t} else {\n\t\tif (sw->config.vendor_id != PCI_VENDOR_ID_INTEL)\n\t\t\ttb_sw_warn(sw, \"unknown switch vendor id %#x\\n\",\n\t\t\t\t   sw->config.vendor_id);\n\n\t\tif (!sw->cap_plug_events) {\n\t\t\ttb_sw_warn(sw, \"cannot find TB_VSE_CAP_PLUG_EVENTS aborting\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\t \n\t\tret = tb_sw_write(sw, (u32 *)&sw->config + 1, TB_CFG_SWITCH,\n\t\t\t\t  ROUTER_CS_1, 3);\n\t}\n\tif (ret)\n\t\treturn ret;\n\n\treturn tb_plug_events_active(sw, true);\n}\n\n \nint tb_switch_configuration_valid(struct tb_switch *sw)\n{\n\tif (tb_switch_is_usb4(sw))\n\t\treturn usb4_switch_configuration_valid(sw);\n\treturn 0;\n}\n\nstatic int tb_switch_set_uuid(struct tb_switch *sw)\n{\n\tbool uid = false;\n\tu32 uuid[4];\n\tint ret;\n\n\tif (sw->uuid)\n\t\treturn 0;\n\n\tif (tb_switch_is_usb4(sw)) {\n\t\tret = usb4_switch_read_uid(sw, &sw->uid);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tuid = true;\n\t} else {\n\t\t \n\t\tret = tb_lc_read_uuid(sw, uuid);\n\t\tif (ret) {\n\t\t\tif (ret != -EINVAL)\n\t\t\t\treturn ret;\n\t\t\tuid = true;\n\t\t}\n\t}\n\n\tif (uid) {\n\t\t \n\t\tuuid[0] = sw->uid & 0xffffffff;\n\t\tuuid[1] = (sw->uid >> 32) & 0xffffffff;\n\t\tuuid[2] = 0xffffffff;\n\t\tuuid[3] = 0xffffffff;\n\t}\n\n\tsw->uuid = kmemdup(uuid, sizeof(uuid), GFP_KERNEL);\n\tif (!sw->uuid)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic int tb_switch_add_dma_port(struct tb_switch *sw)\n{\n\tu32 status;\n\tint ret;\n\n\tswitch (sw->generation) {\n\tcase 2:\n\t\t \n\t\tif (tb_route(sw))\n\t\t\treturn 0;\n\n\t\tfallthrough;\n\tcase 3:\n\tcase 4:\n\t\tret = tb_switch_set_uuid(sw);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\tif (!sw->safe_mode)\n\t\t\treturn 0;\n\t\tbreak;\n\t}\n\n\tif (sw->no_nvm_upgrade)\n\t\treturn 0;\n\n\tif (tb_switch_is_usb4(sw)) {\n\t\tret = usb4_switch_nvm_authenticate_status(sw, &status);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (status) {\n\t\t\ttb_sw_info(sw, \"switch flash authentication failed\\n\");\n\t\t\tnvm_set_auth_status(sw, status);\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\t \n\tif (!tb_route(sw) && !tb_switch_is_icm(sw))\n\t\treturn 0;\n\n\tsw->dma_port = dma_port_alloc(sw);\n\tif (!sw->dma_port)\n\t\treturn 0;\n\n\t \n\tnvm_get_auth_status(sw, &status);\n\tif (status) {\n\t\tif (!tb_route(sw))\n\t\t\tnvm_authenticate_complete_dma_port(sw);\n\t\treturn 0;\n\t}\n\n\t \n\tret = dma_port_flash_update_auth_status(sw->dma_port, &status);\n\tif (ret <= 0)\n\t\treturn ret;\n\n\t \n\tif (!tb_route(sw))\n\t\tnvm_authenticate_complete_dma_port(sw);\n\n\tif (status) {\n\t\ttb_sw_info(sw, \"switch flash authentication failed\\n\");\n\t\tnvm_set_auth_status(sw, status);\n\t}\n\n\ttb_sw_info(sw, \"power cycling the switch now\\n\");\n\tdma_port_power_cycle(sw->dma_port);\n\n\t \n\treturn -ESHUTDOWN;\n}\n\nstatic void tb_switch_default_link_ports(struct tb_switch *sw)\n{\n\tint i;\n\n\tfor (i = 1; i <= sw->config.max_port_number; i++) {\n\t\tstruct tb_port *port = &sw->ports[i];\n\t\tstruct tb_port *subordinate;\n\n\t\tif (!tb_port_is_null(port))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (i == sw->config.max_port_number ||\n\t\t    !tb_port_is_null(&sw->ports[i + 1]))\n\t\t\tcontinue;\n\n\t\t \n\t\tsubordinate = &sw->ports[i + 1];\n\t\tif (!port->dual_link_port && !subordinate->dual_link_port) {\n\t\t\tport->link_nr = 0;\n\t\t\tport->dual_link_port = subordinate;\n\t\t\tsubordinate->link_nr = 1;\n\t\t\tsubordinate->dual_link_port = port;\n\n\t\t\ttb_sw_dbg(sw, \"linked ports %d <-> %d\\n\",\n\t\t\t\t  port->port, subordinate->port);\n\t\t}\n\t}\n}\n\nstatic bool tb_switch_lane_bonding_possible(struct tb_switch *sw)\n{\n\tconst struct tb_port *up = tb_upstream_port(sw);\n\n\tif (!up->dual_link_port || !up->dual_link_port->remote)\n\t\treturn false;\n\n\tif (tb_switch_is_usb4(sw))\n\t\treturn usb4_switch_lane_bonding_possible(sw);\n\treturn tb_lc_lane_bonding_possible(sw);\n}\n\nstatic int tb_switch_update_link_attributes(struct tb_switch *sw)\n{\n\tstruct tb_port *up;\n\tbool change = false;\n\tint ret;\n\n\tif (!tb_route(sw) || tb_switch_is_icm(sw))\n\t\treturn 0;\n\n\tup = tb_upstream_port(sw);\n\n\tret = tb_port_get_link_speed(up);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (sw->link_speed != ret)\n\t\tchange = true;\n\tsw->link_speed = ret;\n\n\tret = tb_port_get_link_width(up);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (sw->link_width != ret)\n\t\tchange = true;\n\tsw->link_width = ret;\n\n\t \n\tif (device_is_registered(&sw->dev) && change)\n\t\tkobject_uevent(&sw->dev.kobj, KOBJ_CHANGE);\n\n\treturn 0;\n}\n\n \nint tb_switch_lane_bonding_enable(struct tb_switch *sw)\n{\n\tstruct tb_port *up, *down;\n\tu64 route = tb_route(sw);\n\tunsigned int width_mask;\n\tint ret;\n\n\tif (!route)\n\t\treturn 0;\n\n\tif (!tb_switch_lane_bonding_possible(sw))\n\t\treturn 0;\n\n\tup = tb_upstream_port(sw);\n\tdown = tb_switch_downstream_port(sw);\n\n\tif (!tb_port_is_width_supported(up, TB_LINK_WIDTH_DUAL) ||\n\t    !tb_port_is_width_supported(down, TB_LINK_WIDTH_DUAL))\n\t\treturn 0;\n\n\t \n\tif (tb_wait_for_port(down->dual_link_port, false) <= 0)\n\t\treturn -ENOTCONN;\n\n\tret = tb_port_lane_bonding_enable(up);\n\tif (ret) {\n\t\ttb_port_warn(up, \"failed to enable lane bonding\\n\");\n\t\treturn ret;\n\t}\n\n\tret = tb_port_lane_bonding_enable(down);\n\tif (ret) {\n\t\ttb_port_warn(down, \"failed to enable lane bonding\\n\");\n\t\ttb_port_lane_bonding_disable(up);\n\t\treturn ret;\n\t}\n\n\t \n\twidth_mask = TB_LINK_WIDTH_DUAL | TB_LINK_WIDTH_ASYM_TX |\n\t\t     TB_LINK_WIDTH_ASYM_RX;\n\n\tret = tb_port_wait_for_link_width(down, width_mask, 100);\n\tif (ret) {\n\t\ttb_port_warn(down, \"timeout enabling lane bonding\\n\");\n\t\treturn ret;\n\t}\n\n\ttb_port_update_credits(down);\n\ttb_port_update_credits(up);\n\ttb_switch_update_link_attributes(sw);\n\n\ttb_sw_dbg(sw, \"lane bonding enabled\\n\");\n\treturn ret;\n}\n\n \nvoid tb_switch_lane_bonding_disable(struct tb_switch *sw)\n{\n\tstruct tb_port *up, *down;\n\tint ret;\n\n\tif (!tb_route(sw))\n\t\treturn;\n\n\tup = tb_upstream_port(sw);\n\tif (!up->bonded)\n\t\treturn;\n\n\tdown = tb_switch_downstream_port(sw);\n\n\ttb_port_lane_bonding_disable(up);\n\ttb_port_lane_bonding_disable(down);\n\n\t \n\tret = tb_port_wait_for_link_width(down, TB_LINK_WIDTH_SINGLE, 100);\n\tif (ret == -ETIMEDOUT)\n\t\ttb_sw_warn(sw, \"timeout disabling lane bonding\\n\");\n\n\ttb_port_update_credits(down);\n\ttb_port_update_credits(up);\n\ttb_switch_update_link_attributes(sw);\n\n\ttb_sw_dbg(sw, \"lane bonding disabled\\n\");\n}\n\n \nint tb_switch_configure_link(struct tb_switch *sw)\n{\n\tstruct tb_port *up, *down;\n\tint ret;\n\n\tif (!tb_route(sw) || tb_switch_is_icm(sw))\n\t\treturn 0;\n\n\tup = tb_upstream_port(sw);\n\tif (tb_switch_is_usb4(up->sw))\n\t\tret = usb4_port_configure(up);\n\telse\n\t\tret = tb_lc_configure_port(up);\n\tif (ret)\n\t\treturn ret;\n\n\tdown = up->remote;\n\tif (tb_switch_is_usb4(down->sw))\n\t\treturn usb4_port_configure(down);\n\treturn tb_lc_configure_port(down);\n}\n\n \nvoid tb_switch_unconfigure_link(struct tb_switch *sw)\n{\n\tstruct tb_port *up, *down;\n\n\tif (sw->is_unplugged)\n\t\treturn;\n\tif (!tb_route(sw) || tb_switch_is_icm(sw))\n\t\treturn;\n\n\tup = tb_upstream_port(sw);\n\tif (tb_switch_is_usb4(up->sw))\n\t\tusb4_port_unconfigure(up);\n\telse\n\t\ttb_lc_unconfigure_port(up);\n\n\tdown = up->remote;\n\tif (tb_switch_is_usb4(down->sw))\n\t\tusb4_port_unconfigure(down);\n\telse\n\t\ttb_lc_unconfigure_port(down);\n}\n\nstatic void tb_switch_credits_init(struct tb_switch *sw)\n{\n\tif (tb_switch_is_icm(sw))\n\t\treturn;\n\tif (!tb_switch_is_usb4(sw))\n\t\treturn;\n\tif (usb4_switch_credits_init(sw))\n\t\ttb_sw_info(sw, \"failed to determine preferred buffer allocation, using defaults\\n\");\n}\n\nstatic int tb_switch_port_hotplug_enable(struct tb_switch *sw)\n{\n\tstruct tb_port *port;\n\n\tif (tb_switch_is_icm(sw))\n\t\treturn 0;\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tint res;\n\n\t\tif (!port->cap_usb4)\n\t\t\tcontinue;\n\n\t\tres = usb4_port_hotplug_enable(port);\n\t\tif (res)\n\t\t\treturn res;\n\t}\n\treturn 0;\n}\n\n \nint tb_switch_add(struct tb_switch *sw)\n{\n\tint i, ret;\n\n\t \n\tret = tb_switch_add_dma_port(sw);\n\tif (ret) {\n\t\tdev_err(&sw->dev, \"failed to add DMA port\\n\");\n\t\treturn ret;\n\t}\n\n\tif (!sw->safe_mode) {\n\t\ttb_switch_credits_init(sw);\n\n\t\t \n\t\tret = tb_drom_read(sw);\n\t\tif (ret)\n\t\t\tdev_warn(&sw->dev, \"reading DROM failed: %d\\n\", ret);\n\t\ttb_sw_dbg(sw, \"uid: %#llx\\n\", sw->uid);\n\n\t\tret = tb_switch_set_uuid(sw);\n\t\tif (ret) {\n\t\t\tdev_err(&sw->dev, \"failed to set UUID\\n\");\n\t\t\treturn ret;\n\t\t}\n\n\t\tfor (i = 0; i <= sw->config.max_port_number; i++) {\n\t\t\tif (sw->ports[i].disabled) {\n\t\t\t\ttb_port_dbg(&sw->ports[i], \"disabled by eeprom\\n\");\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tret = tb_init_port(&sw->ports[i]);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(&sw->dev, \"failed to initialize port %d\\n\", i);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\n\t\ttb_check_quirks(sw);\n\n\t\ttb_switch_default_link_ports(sw);\n\n\t\tret = tb_switch_update_link_attributes(sw);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = tb_switch_clx_init(sw);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = tb_switch_tmu_init(sw);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = tb_switch_port_hotplug_enable(sw);\n\tif (ret)\n\t\treturn ret;\n\n\tret = device_add(&sw->dev);\n\tif (ret) {\n\t\tdev_err(&sw->dev, \"failed to add device: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (tb_route(sw)) {\n\t\tdev_info(&sw->dev, \"new device found, vendor=%#x device=%#x\\n\",\n\t\t\t sw->vendor, sw->device);\n\t\tif (sw->vendor_name && sw->device_name)\n\t\t\tdev_info(&sw->dev, \"%s %s\\n\", sw->vendor_name,\n\t\t\t\t sw->device_name);\n\t}\n\n\tret = usb4_switch_add_ports(sw);\n\tif (ret) {\n\t\tdev_err(&sw->dev, \"failed to add USB4 ports\\n\");\n\t\tgoto err_del;\n\t}\n\n\tret = tb_switch_nvm_add(sw);\n\tif (ret) {\n\t\tdev_err(&sw->dev, \"failed to add NVM devices\\n\");\n\t\tgoto err_ports;\n\t}\n\n\t \n\tdevice_init_wakeup(&sw->dev, true);\n\n\tpm_runtime_set_active(&sw->dev);\n\tif (sw->rpm) {\n\t\tpm_runtime_set_autosuspend_delay(&sw->dev, TB_AUTOSUSPEND_DELAY);\n\t\tpm_runtime_use_autosuspend(&sw->dev);\n\t\tpm_runtime_mark_last_busy(&sw->dev);\n\t\tpm_runtime_enable(&sw->dev);\n\t\tpm_request_autosuspend(&sw->dev);\n\t}\n\n\ttb_switch_debugfs_init(sw);\n\treturn 0;\n\nerr_ports:\n\tusb4_switch_remove_ports(sw);\nerr_del:\n\tdevice_del(&sw->dev);\n\n\treturn ret;\n}\n\n \nvoid tb_switch_remove(struct tb_switch *sw)\n{\n\tstruct tb_port *port;\n\n\ttb_switch_debugfs_remove(sw);\n\n\tif (sw->rpm) {\n\t\tpm_runtime_get_sync(&sw->dev);\n\t\tpm_runtime_disable(&sw->dev);\n\t}\n\n\t \n\ttb_switch_for_each_port(sw, port) {\n\t\tif (tb_port_has_remote(port)) {\n\t\t\ttb_switch_remove(port->remote->sw);\n\t\t\tport->remote = NULL;\n\t\t} else if (port->xdomain) {\n\t\t\ttb_xdomain_remove(port->xdomain);\n\t\t\tport->xdomain = NULL;\n\t\t}\n\n\t\t \n\t\ttb_retimer_remove_all(port);\n\t}\n\n\tif (!sw->is_unplugged)\n\t\ttb_plug_events_active(sw, false);\n\n\ttb_switch_nvm_remove(sw);\n\tusb4_switch_remove_ports(sw);\n\n\tif (tb_route(sw))\n\t\tdev_info(&sw->dev, \"device disconnected\\n\");\n\tdevice_unregister(&sw->dev);\n}\n\n \nvoid tb_sw_set_unplugged(struct tb_switch *sw)\n{\n\tstruct tb_port *port;\n\n\tif (sw == sw->tb->root_switch) {\n\t\ttb_sw_WARN(sw, \"cannot unplug root switch\\n\");\n\t\treturn;\n\t}\n\tif (sw->is_unplugged) {\n\t\ttb_sw_WARN(sw, \"is_unplugged already set\\n\");\n\t\treturn;\n\t}\n\tsw->is_unplugged = true;\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (tb_port_has_remote(port))\n\t\t\ttb_sw_set_unplugged(port->remote->sw);\n\t\telse if (port->xdomain)\n\t\t\tport->xdomain->is_unplugged = true;\n\t}\n}\n\nstatic int tb_switch_set_wake(struct tb_switch *sw, unsigned int flags)\n{\n\tif (flags)\n\t\ttb_sw_dbg(sw, \"enabling wakeup: %#x\\n\", flags);\n\telse\n\t\ttb_sw_dbg(sw, \"disabling wakeup\\n\");\n\n\tif (tb_switch_is_usb4(sw))\n\t\treturn usb4_switch_set_wake(sw, flags);\n\treturn tb_lc_set_wake(sw, flags);\n}\n\nint tb_switch_resume(struct tb_switch *sw)\n{\n\tstruct tb_port *port;\n\tint err;\n\n\ttb_sw_dbg(sw, \"resuming switch\\n\");\n\n\t \n\tif (tb_route(sw)) {\n\t\tu64 uid;\n\n\t\t \n\t\terr = tb_cfg_get_upstream_port(sw->tb->ctl, tb_route(sw));\n\t\tif (err < 0) {\n\t\t\ttb_sw_info(sw, \"switch not present anymore\\n\");\n\t\t\treturn err;\n\t\t}\n\n\t\t \n\t\tif (!sw->uid)\n\t\t\treturn -ENODEV;\n\n\t\tif (tb_switch_is_usb4(sw))\n\t\t\terr = usb4_switch_read_uid(sw, &uid);\n\t\telse\n\t\t\terr = tb_drom_read_uid_only(sw, &uid);\n\t\tif (err) {\n\t\t\ttb_sw_warn(sw, \"uid read failed\\n\");\n\t\t\treturn err;\n\t\t}\n\t\tif (sw->uid != uid) {\n\t\t\ttb_sw_info(sw,\n\t\t\t\t\"changed while suspended (uid %#llx -> %#llx)\\n\",\n\t\t\t\tsw->uid, uid);\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\terr = tb_switch_configure(sw);\n\tif (err)\n\t\treturn err;\n\n\t \n\ttb_switch_set_wake(sw, 0);\n\n\terr = tb_switch_tmu_init(sw);\n\tif (err)\n\t\treturn err;\n\n\t \n\ttb_switch_for_each_port(sw, port) {\n\t\tif (!tb_port_is_null(port))\n\t\t\tcontinue;\n\n\t\tif (!tb_port_resume(port))\n\t\t\tcontinue;\n\n\t\tif (tb_wait_for_port(port, true) <= 0) {\n\t\t\ttb_port_warn(port,\n\t\t\t\t     \"lost during suspend, disconnecting\\n\");\n\t\t\tif (tb_port_has_remote(port))\n\t\t\t\ttb_sw_set_unplugged(port->remote->sw);\n\t\t\telse if (port->xdomain)\n\t\t\t\tport->xdomain->is_unplugged = true;\n\t\t} else {\n\t\t\t \n\t\t\tif (tb_port_unlock(port))\n\t\t\t\ttb_port_warn(port, \"failed to unlock port\\n\");\n\t\t\tif (port->remote && tb_switch_resume(port->remote->sw)) {\n\t\t\t\ttb_port_warn(port,\n\t\t\t\t\t     \"lost during suspend, disconnecting\\n\");\n\t\t\t\ttb_sw_set_unplugged(port->remote->sw);\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nvoid tb_switch_suspend(struct tb_switch *sw, bool runtime)\n{\n\tunsigned int flags = 0;\n\tstruct tb_port *port;\n\tint err;\n\n\ttb_sw_dbg(sw, \"suspending switch\\n\");\n\n\t \n\ttb_switch_clx_disable(sw);\n\n\terr = tb_plug_events_active(sw, false);\n\tif (err)\n\t\treturn;\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (tb_port_has_remote(port))\n\t\t\ttb_switch_suspend(port->remote->sw, runtime);\n\t}\n\n\tif (runtime) {\n\t\t \n\t\tflags |= TB_WAKE_ON_CONNECT | TB_WAKE_ON_DISCONNECT;\n\t\tflags |= TB_WAKE_ON_USB4;\n\t\tflags |= TB_WAKE_ON_USB3 | TB_WAKE_ON_PCIE | TB_WAKE_ON_DP;\n\t} else if (device_may_wakeup(&sw->dev)) {\n\t\tflags |= TB_WAKE_ON_USB4 | TB_WAKE_ON_USB3 | TB_WAKE_ON_PCIE;\n\t}\n\n\ttb_switch_set_wake(sw, flags);\n\n\tif (tb_switch_is_usb4(sw))\n\t\tusb4_switch_set_sleep(sw);\n\telse\n\t\ttb_lc_set_sleep(sw);\n}\n\n \nbool tb_switch_query_dp_resource(struct tb_switch *sw, struct tb_port *in)\n{\n\tif (tb_switch_is_usb4(sw))\n\t\treturn usb4_switch_query_dp_resource(sw, in);\n\treturn tb_lc_dp_sink_query(sw, in);\n}\n\n \nint tb_switch_alloc_dp_resource(struct tb_switch *sw, struct tb_port *in)\n{\n\tint ret;\n\n\tif (tb_switch_is_usb4(sw))\n\t\tret = usb4_switch_alloc_dp_resource(sw, in);\n\telse\n\t\tret = tb_lc_dp_sink_alloc(sw, in);\n\n\tif (ret)\n\t\ttb_sw_warn(sw, \"failed to allocate DP resource for port %d\\n\",\n\t\t\t   in->port);\n\telse\n\t\ttb_sw_dbg(sw, \"allocated DP resource for port %d\\n\", in->port);\n\n\treturn ret;\n}\n\n \nvoid tb_switch_dealloc_dp_resource(struct tb_switch *sw, struct tb_port *in)\n{\n\tint ret;\n\n\tif (tb_switch_is_usb4(sw))\n\t\tret = usb4_switch_dealloc_dp_resource(sw, in);\n\telse\n\t\tret = tb_lc_dp_sink_dealloc(sw, in);\n\n\tif (ret)\n\t\ttb_sw_warn(sw, \"failed to de-allocate DP resource for port %d\\n\",\n\t\t\t   in->port);\n\telse\n\t\ttb_sw_dbg(sw, \"released DP resource for port %d\\n\", in->port);\n}\n\nstruct tb_sw_lookup {\n\tstruct tb *tb;\n\tu8 link;\n\tu8 depth;\n\tconst uuid_t *uuid;\n\tu64 route;\n};\n\nstatic int tb_switch_match(struct device *dev, const void *data)\n{\n\tstruct tb_switch *sw = tb_to_switch(dev);\n\tconst struct tb_sw_lookup *lookup = data;\n\n\tif (!sw)\n\t\treturn 0;\n\tif (sw->tb != lookup->tb)\n\t\treturn 0;\n\n\tif (lookup->uuid)\n\t\treturn !memcmp(sw->uuid, lookup->uuid, sizeof(*lookup->uuid));\n\n\tif (lookup->route) {\n\t\treturn sw->config.route_lo == lower_32_bits(lookup->route) &&\n\t\t       sw->config.route_hi == upper_32_bits(lookup->route);\n\t}\n\n\t \n\tif (!lookup->depth)\n\t\treturn !sw->depth;\n\n\treturn sw->link == lookup->link && sw->depth == lookup->depth;\n}\n\n \nstruct tb_switch *tb_switch_find_by_link_depth(struct tb *tb, u8 link, u8 depth)\n{\n\tstruct tb_sw_lookup lookup;\n\tstruct device *dev;\n\n\tmemset(&lookup, 0, sizeof(lookup));\n\tlookup.tb = tb;\n\tlookup.link = link;\n\tlookup.depth = depth;\n\n\tdev = bus_find_device(&tb_bus_type, NULL, &lookup, tb_switch_match);\n\tif (dev)\n\t\treturn tb_to_switch(dev);\n\n\treturn NULL;\n}\n\n \nstruct tb_switch *tb_switch_find_by_uuid(struct tb *tb, const uuid_t *uuid)\n{\n\tstruct tb_sw_lookup lookup;\n\tstruct device *dev;\n\n\tmemset(&lookup, 0, sizeof(lookup));\n\tlookup.tb = tb;\n\tlookup.uuid = uuid;\n\n\tdev = bus_find_device(&tb_bus_type, NULL, &lookup, tb_switch_match);\n\tif (dev)\n\t\treturn tb_to_switch(dev);\n\n\treturn NULL;\n}\n\n \nstruct tb_switch *tb_switch_find_by_route(struct tb *tb, u64 route)\n{\n\tstruct tb_sw_lookup lookup;\n\tstruct device *dev;\n\n\tif (!route)\n\t\treturn tb_switch_get(tb->root_switch);\n\n\tmemset(&lookup, 0, sizeof(lookup));\n\tlookup.tb = tb;\n\tlookup.route = route;\n\n\tdev = bus_find_device(&tb_bus_type, NULL, &lookup, tb_switch_match);\n\tif (dev)\n\t\treturn tb_to_switch(dev);\n\n\treturn NULL;\n}\n\n \nstruct tb_port *tb_switch_find_port(struct tb_switch *sw,\n\t\t\t\t    enum tb_port_type type)\n{\n\tstruct tb_port *port;\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (port->config.type == type)\n\t\t\treturn port;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic int tb_switch_pcie_bridge_write(struct tb_switch *sw, unsigned int bridge,\n\t\t\t\t       unsigned int pcie_offset, u32 value)\n{\n\tu32 offset, command, val;\n\tint ret;\n\n\tif (sw->generation != 3)\n\t\treturn -EOPNOTSUPP;\n\n\toffset = sw->cap_plug_events + TB_PLUG_EVENTS_PCIE_WR_DATA;\n\tret = tb_sw_write(sw, &value, TB_CFG_SWITCH, offset, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tcommand = pcie_offset & TB_PLUG_EVENTS_PCIE_CMD_DW_OFFSET_MASK;\n\tcommand |= BIT(bridge + TB_PLUG_EVENTS_PCIE_CMD_BR_SHIFT);\n\tcommand |= TB_PLUG_EVENTS_PCIE_CMD_RD_WR_MASK;\n\tcommand |= TB_PLUG_EVENTS_PCIE_CMD_COMMAND_VAL\n\t\t\t<< TB_PLUG_EVENTS_PCIE_CMD_COMMAND_SHIFT;\n\tcommand |= TB_PLUG_EVENTS_PCIE_CMD_REQ_ACK_MASK;\n\n\toffset = sw->cap_plug_events + TB_PLUG_EVENTS_PCIE_CMD;\n\n\tret = tb_sw_write(sw, &command, TB_CFG_SWITCH, offset, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_switch_wait_for_bit(sw, offset,\n\t\t\t\t     TB_PLUG_EVENTS_PCIE_CMD_REQ_ACK_MASK, 0, 100);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_sw_read(sw, &val, TB_CFG_SWITCH, offset, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tif (val & TB_PLUG_EVENTS_PCIE_CMD_TIMEOUT_MASK)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\n \nint tb_switch_pcie_l1_enable(struct tb_switch *sw)\n{\n\tstruct tb_switch *parent = tb_switch_parent(sw);\n\tint ret;\n\n\tif (!tb_route(sw))\n\t\treturn 0;\n\n\tif (!tb_switch_is_titan_ridge(sw))\n\t\treturn 0;\n\n\t \n\tif (tb_route(parent))\n\t\treturn 0;\n\n\t \n\tret = tb_switch_pcie_bridge_write(sw, 5, 0x143, 0x0c7806b1);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\treturn tb_switch_pcie_bridge_write(sw, 0, 0x143, 0x0c5806b1);\n}\n\n \nint tb_switch_xhci_connect(struct tb_switch *sw)\n{\n\tstruct tb_port *port1, *port3;\n\tint ret;\n\n\tif (sw->generation != 3)\n\t\treturn 0;\n\n\tport1 = &sw->ports[1];\n\tport3 = &sw->ports[3];\n\n\tif (tb_switch_is_alpine_ridge(sw)) {\n\t\tbool usb_port1, usb_port3, xhci_port1, xhci_port3;\n\n\t\tusb_port1 = tb_lc_is_usb_plugged(port1);\n\t\tusb_port3 = tb_lc_is_usb_plugged(port3);\n\t\txhci_port1 = tb_lc_is_xhci_connected(port1);\n\t\txhci_port3 = tb_lc_is_xhci_connected(port3);\n\n\t\t \n\t\tif (usb_port1 && !xhci_port1) {\n\t\t\tret = tb_lc_xhci_connect(port1);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t\tif (usb_port3 && !xhci_port3)\n\t\t\treturn tb_lc_xhci_connect(port3);\n\t} else if (tb_switch_is_titan_ridge(sw)) {\n\t\tret = tb_lc_xhci_connect(port1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\treturn tb_lc_xhci_connect(port3);\n\t}\n\n\treturn 0;\n}\n\n \nvoid tb_switch_xhci_disconnect(struct tb_switch *sw)\n{\n\tif (sw->generation == 3) {\n\t\tstruct tb_port *port1 = &sw->ports[1];\n\t\tstruct tb_port *port3 = &sw->ports[3];\n\n\t\ttb_lc_xhci_disconnect(port1);\n\t\ttb_port_dbg(port1, \"disconnected xHCI\\n\");\n\t\ttb_lc_xhci_disconnect(port3);\n\t\ttb_port_dbg(port3, \"disconnected xHCI\\n\");\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}