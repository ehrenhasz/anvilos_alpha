{
  "module_name": "tunnel.c",
  "hash_id": "e26c96c797e2fefaa4de0efad89d4cc2855d661407c4539c6b885f4ee24469d0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/thunderbolt/tunnel.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/ktime.h>\n#include <linux/string_helpers.h>\n\n#include \"tunnel.h\"\n#include \"tb.h\"\n\n \n#define TB_PCI_HOPID\t\t\t8\n\n#define TB_PCI_PATH_DOWN\t\t0\n#define TB_PCI_PATH_UP\t\t\t1\n\n \n#define TB_USB3_HOPID\t\t\t8\n\n#define TB_USB3_PATH_DOWN\t\t0\n#define TB_USB3_PATH_UP\t\t\t1\n\n \n#define TB_DP_AUX_TX_HOPID\t\t8\n#define TB_DP_AUX_RX_HOPID\t\t8\n#define TB_DP_VIDEO_HOPID\t\t9\n\n#define TB_DP_VIDEO_PATH_OUT\t\t0\n#define TB_DP_AUX_PATH_OUT\t\t1\n#define TB_DP_AUX_PATH_IN\t\t2\n\n \n#define TB_MIN_PCIE_CREDITS\t\t6U\n \n#define TB_DMA_CREDITS\t\t\t14\n \n#define TB_MIN_DMA_CREDITS\t\t1\n\nstatic unsigned int dma_credits = TB_DMA_CREDITS;\nmodule_param(dma_credits, uint, 0444);\nMODULE_PARM_DESC(dma_credits, \"specify custom credits for DMA tunnels (default: \"\n                __MODULE_STRING(TB_DMA_CREDITS) \")\");\n\nstatic bool bw_alloc_mode = true;\nmodule_param(bw_alloc_mode, bool, 0444);\nMODULE_PARM_DESC(bw_alloc_mode,\n\t\t \"enable bandwidth allocation mode if supported (default: true)\");\n\nstatic const char * const tb_tunnel_names[] = { \"PCI\", \"DP\", \"DMA\", \"USB3\" };\n\n#define __TB_TUNNEL_PRINT(level, tunnel, fmt, arg...)                   \\\n\tdo {                                                            \\\n\t\tstruct tb_tunnel *__tunnel = (tunnel);                  \\\n\t\tlevel(__tunnel->tb, \"%llx:%u <-> %llx:%u (%s): \" fmt,   \\\n\t\t      tb_route(__tunnel->src_port->sw),                 \\\n\t\t      __tunnel->src_port->port,                         \\\n\t\t      tb_route(__tunnel->dst_port->sw),                 \\\n\t\t      __tunnel->dst_port->port,                         \\\n\t\t      tb_tunnel_names[__tunnel->type],\t\t\t\\\n\t\t      ## arg);                                          \\\n\t} while (0)\n\n#define tb_tunnel_WARN(tunnel, fmt, arg...) \\\n\t__TB_TUNNEL_PRINT(tb_WARN, tunnel, fmt, ##arg)\n#define tb_tunnel_warn(tunnel, fmt, arg...) \\\n\t__TB_TUNNEL_PRINT(tb_warn, tunnel, fmt, ##arg)\n#define tb_tunnel_info(tunnel, fmt, arg...) \\\n\t__TB_TUNNEL_PRINT(tb_info, tunnel, fmt, ##arg)\n#define tb_tunnel_dbg(tunnel, fmt, arg...) \\\n\t__TB_TUNNEL_PRINT(tb_dbg, tunnel, fmt, ##arg)\n\nstatic inline unsigned int tb_usable_credits(const struct tb_port *port)\n{\n\treturn port->total_credits - port->ctl_credits;\n}\n\n \nstatic unsigned int tb_available_credits(const struct tb_port *port,\n\t\t\t\t\t size_t *max_dp_streams)\n{\n\tconst struct tb_switch *sw = port->sw;\n\tint credits, usb3, pcie, spare;\n\tsize_t ndp;\n\n\tusb3 = tb_acpi_may_tunnel_usb3() ? sw->max_usb3_credits : 0;\n\tpcie = tb_acpi_may_tunnel_pcie() ? sw->max_pcie_credits : 0;\n\n\tif (tb_acpi_is_xdomain_allowed()) {\n\t\tspare = min_not_zero(sw->max_dma_credits, dma_credits);\n\t\t \n\t\tspare += TB_MIN_DMA_CREDITS;\n\t} else {\n\t\tspare = 0;\n\t}\n\n\tcredits = tb_usable_credits(port);\n\tif (tb_acpi_may_tunnel_dp()) {\n\t\t \n\t\tif (sw->min_dp_aux_credits + sw->min_dp_main_credits)\n\t\t\tndp = (credits - (usb3 + pcie + spare)) /\n\t\t\t      (sw->min_dp_aux_credits + sw->min_dp_main_credits);\n\t\telse\n\t\t\tndp = 0;\n\t} else {\n\t\tndp = 0;\n\t}\n\tcredits -= ndp * (sw->min_dp_aux_credits + sw->min_dp_main_credits);\n\tcredits -= usb3;\n\n\tif (max_dp_streams)\n\t\t*max_dp_streams = ndp;\n\n\treturn credits > 0 ? credits : 0;\n}\n\nstatic struct tb_tunnel *tb_tunnel_alloc(struct tb *tb, size_t npaths,\n\t\t\t\t\t enum tb_tunnel_type type)\n{\n\tstruct tb_tunnel *tunnel;\n\n\ttunnel = kzalloc(sizeof(*tunnel), GFP_KERNEL);\n\tif (!tunnel)\n\t\treturn NULL;\n\n\ttunnel->paths = kcalloc(npaths, sizeof(tunnel->paths[0]), GFP_KERNEL);\n\tif (!tunnel->paths) {\n\t\ttb_tunnel_free(tunnel);\n\t\treturn NULL;\n\t}\n\n\tINIT_LIST_HEAD(&tunnel->list);\n\ttunnel->tb = tb;\n\ttunnel->npaths = npaths;\n\ttunnel->type = type;\n\n\treturn tunnel;\n}\n\nstatic int tb_pci_set_ext_encapsulation(struct tb_tunnel *tunnel, bool enable)\n{\n\tint ret;\n\n\t \n\tif (usb4_switch_version(tunnel->src_port->sw) < 2 ||\n\t    usb4_switch_version(tunnel->dst_port->sw) < 2)\n\t\treturn 0;\n\n\tret = usb4_pci_port_set_ext_encapsulation(tunnel->src_port, enable);\n\tif (ret)\n\t\treturn ret;\n\n\tret = usb4_pci_port_set_ext_encapsulation(tunnel->dst_port, enable);\n\tif (ret)\n\t\treturn ret;\n\n\ttb_tunnel_dbg(tunnel, \"extended encapsulation %s\\n\",\n\t\t      str_enabled_disabled(enable));\n\treturn 0;\n}\n\nstatic int tb_pci_activate(struct tb_tunnel *tunnel, bool activate)\n{\n\tint res;\n\n\tif (activate) {\n\t\tres = tb_pci_set_ext_encapsulation(tunnel, activate);\n\t\tif (res)\n\t\t\treturn res;\n\t}\n\n\tres = tb_pci_port_enable(tunnel->src_port, activate);\n\tif (res)\n\t\treturn res;\n\n\tif (tb_port_is_pcie_up(tunnel->dst_port)) {\n\t\tres = tb_pci_port_enable(tunnel->dst_port, activate);\n\t\tif (res)\n\t\t\treturn res;\n\t}\n\n\treturn activate ? 0 : tb_pci_set_ext_encapsulation(tunnel, activate);\n}\n\nstatic int tb_pci_init_credits(struct tb_path_hop *hop)\n{\n\tstruct tb_port *port = hop->in_port;\n\tstruct tb_switch *sw = port->sw;\n\tunsigned int credits;\n\n\tif (tb_port_use_credit_allocation(port)) {\n\t\tunsigned int available;\n\n\t\tavailable = tb_available_credits(port, NULL);\n\t\tcredits = min(sw->max_pcie_credits, available);\n\n\t\tif (credits < TB_MIN_PCIE_CREDITS)\n\t\t\treturn -ENOSPC;\n\n\t\tcredits = max(TB_MIN_PCIE_CREDITS, credits);\n\t} else {\n\t\tif (tb_port_is_null(port))\n\t\t\tcredits = port->bonded ? 32 : 16;\n\t\telse\n\t\t\tcredits = 7;\n\t}\n\n\thop->initial_credits = credits;\n\treturn 0;\n}\n\nstatic int tb_pci_init_path(struct tb_path *path)\n{\n\tstruct tb_path_hop *hop;\n\n\tpath->egress_fc_enable = TB_PATH_SOURCE | TB_PATH_INTERNAL;\n\tpath->egress_shared_buffer = TB_PATH_NONE;\n\tpath->ingress_fc_enable = TB_PATH_ALL;\n\tpath->ingress_shared_buffer = TB_PATH_NONE;\n\tpath->priority = 3;\n\tpath->weight = 1;\n\tpath->drop_packages = 0;\n\n\ttb_path_for_each_hop(path, hop) {\n\t\tint ret;\n\n\t\tret = tb_pci_init_credits(hop);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nstruct tb_tunnel *tb_tunnel_discover_pci(struct tb *tb, struct tb_port *down,\n\t\t\t\t\t bool alloc_hopid)\n{\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_path *path;\n\n\tif (!tb_pci_port_is_enabled(down))\n\t\treturn NULL;\n\n\ttunnel = tb_tunnel_alloc(tb, 2, TB_TUNNEL_PCI);\n\tif (!tunnel)\n\t\treturn NULL;\n\n\ttunnel->activate = tb_pci_activate;\n\ttunnel->src_port = down;\n\n\t \n\tpath = tb_path_discover(down, TB_PCI_HOPID, NULL, -1,\n\t\t\t\t&tunnel->dst_port, \"PCIe Up\", alloc_hopid);\n\tif (!path) {\n\t\t \n\t\ttb_pci_port_enable(down, false);\n\t\tgoto err_free;\n\t}\n\ttunnel->paths[TB_PCI_PATH_UP] = path;\n\tif (tb_pci_init_path(tunnel->paths[TB_PCI_PATH_UP]))\n\t\tgoto err_free;\n\n\tpath = tb_path_discover(tunnel->dst_port, -1, down, TB_PCI_HOPID, NULL,\n\t\t\t\t\"PCIe Down\", alloc_hopid);\n\tif (!path)\n\t\tgoto err_deactivate;\n\ttunnel->paths[TB_PCI_PATH_DOWN] = path;\n\tif (tb_pci_init_path(tunnel->paths[TB_PCI_PATH_DOWN]))\n\t\tgoto err_deactivate;\n\n\t \n\tif (!tb_port_is_pcie_up(tunnel->dst_port)) {\n\t\ttb_port_warn(tunnel->dst_port,\n\t\t\t     \"path does not end on a PCIe adapter, cleaning up\\n\");\n\t\tgoto err_deactivate;\n\t}\n\n\tif (down != tunnel->src_port) {\n\t\ttb_tunnel_warn(tunnel, \"path is not complete, cleaning up\\n\");\n\t\tgoto err_deactivate;\n\t}\n\n\tif (!tb_pci_port_is_enabled(tunnel->dst_port)) {\n\t\ttb_tunnel_warn(tunnel,\n\t\t\t       \"tunnel is not fully activated, cleaning up\\n\");\n\t\tgoto err_deactivate;\n\t}\n\n\ttb_tunnel_dbg(tunnel, \"discovered\\n\");\n\treturn tunnel;\n\nerr_deactivate:\n\ttb_tunnel_deactivate(tunnel);\nerr_free:\n\ttb_tunnel_free(tunnel);\n\n\treturn NULL;\n}\n\n \nstruct tb_tunnel *tb_tunnel_alloc_pci(struct tb *tb, struct tb_port *up,\n\t\t\t\t      struct tb_port *down)\n{\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_path *path;\n\n\ttunnel = tb_tunnel_alloc(tb, 2, TB_TUNNEL_PCI);\n\tif (!tunnel)\n\t\treturn NULL;\n\n\ttunnel->activate = tb_pci_activate;\n\ttunnel->src_port = down;\n\ttunnel->dst_port = up;\n\n\tpath = tb_path_alloc(tb, down, TB_PCI_HOPID, up, TB_PCI_HOPID, 0,\n\t\t\t     \"PCIe Down\");\n\tif (!path)\n\t\tgoto err_free;\n\ttunnel->paths[TB_PCI_PATH_DOWN] = path;\n\tif (tb_pci_init_path(path))\n\t\tgoto err_free;\n\n\tpath = tb_path_alloc(tb, up, TB_PCI_HOPID, down, TB_PCI_HOPID, 0,\n\t\t\t     \"PCIe Up\");\n\tif (!path)\n\t\tgoto err_free;\n\ttunnel->paths[TB_PCI_PATH_UP] = path;\n\tif (tb_pci_init_path(path))\n\t\tgoto err_free;\n\n\treturn tunnel;\n\nerr_free:\n\ttb_tunnel_free(tunnel);\n\treturn NULL;\n}\n\nstatic bool tb_dp_is_usb4(const struct tb_switch *sw)\n{\n\t \n\treturn tb_switch_is_usb4(sw) || tb_switch_is_titan_ridge(sw);\n}\n\nstatic int tb_dp_cm_handshake(struct tb_port *in, struct tb_port *out,\n\t\t\t      int timeout_msec)\n{\n\tktime_t timeout = ktime_add_ms(ktime_get(), timeout_msec);\n\tu32 val;\n\tint ret;\n\n\t \n\tif (!tb_dp_is_usb4(in->sw) || !tb_dp_is_usb4(out->sw))\n\t\treturn 0;\n\n\tret = tb_port_read(out, &val, TB_CFG_PORT,\n\t\t\t   out->cap_adap + DP_STATUS_CTRL, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tval |= DP_STATUS_CTRL_UF | DP_STATUS_CTRL_CMHS;\n\n\tret = tb_port_write(out, &val, TB_CFG_PORT,\n\t\t\t    out->cap_adap + DP_STATUS_CTRL, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tdo {\n\t\tret = tb_port_read(out, &val, TB_CFG_PORT,\n\t\t\t\t   out->cap_adap + DP_STATUS_CTRL, 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (!(val & DP_STATUS_CTRL_CMHS))\n\t\t\treturn 0;\n\t\tusleep_range(100, 150);\n\t} while (ktime_before(ktime_get(), timeout));\n\n\treturn -ETIMEDOUT;\n}\n\n \nstatic inline u32 tb_dp_cap_get_rate(u32 val)\n{\n\tu32 rate = (val & DP_COMMON_CAP_RATE_MASK) >> DP_COMMON_CAP_RATE_SHIFT;\n\n\tswitch (rate) {\n\tcase DP_COMMON_CAP_RATE_RBR:\n\t\treturn 1620;\n\tcase DP_COMMON_CAP_RATE_HBR:\n\t\treturn 2700;\n\tcase DP_COMMON_CAP_RATE_HBR2:\n\t\treturn 5400;\n\tcase DP_COMMON_CAP_RATE_HBR3:\n\t\treturn 8100;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\n \nstatic inline u32 tb_dp_cap_get_rate_ext(u32 val)\n{\n\tif (val & DP_COMMON_CAP_UHBR20)\n\t\treturn 20000;\n\telse if (val & DP_COMMON_CAP_UHBR13_5)\n\t\treturn 13500;\n\telse if (val & DP_COMMON_CAP_UHBR10)\n\t\treturn 10000;\n\n\treturn tb_dp_cap_get_rate(val);\n}\n\nstatic inline bool tb_dp_is_uhbr_rate(unsigned int rate)\n{\n\treturn rate >= 10000;\n}\n\nstatic inline u32 tb_dp_cap_set_rate(u32 val, u32 rate)\n{\n\tval &= ~DP_COMMON_CAP_RATE_MASK;\n\tswitch (rate) {\n\tdefault:\n\t\tWARN(1, \"invalid rate %u passed, defaulting to 1620 MB/s\\n\", rate);\n\t\tfallthrough;\n\tcase 1620:\n\t\tval |= DP_COMMON_CAP_RATE_RBR << DP_COMMON_CAP_RATE_SHIFT;\n\t\tbreak;\n\tcase 2700:\n\t\tval |= DP_COMMON_CAP_RATE_HBR << DP_COMMON_CAP_RATE_SHIFT;\n\t\tbreak;\n\tcase 5400:\n\t\tval |= DP_COMMON_CAP_RATE_HBR2 << DP_COMMON_CAP_RATE_SHIFT;\n\t\tbreak;\n\tcase 8100:\n\t\tval |= DP_COMMON_CAP_RATE_HBR3 << DP_COMMON_CAP_RATE_SHIFT;\n\t\tbreak;\n\t}\n\treturn val;\n}\n\nstatic inline u32 tb_dp_cap_get_lanes(u32 val)\n{\n\tu32 lanes = (val & DP_COMMON_CAP_LANES_MASK) >> DP_COMMON_CAP_LANES_SHIFT;\n\n\tswitch (lanes) {\n\tcase DP_COMMON_CAP_1_LANE:\n\t\treturn 1;\n\tcase DP_COMMON_CAP_2_LANES:\n\t\treturn 2;\n\tcase DP_COMMON_CAP_4_LANES:\n\t\treturn 4;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic inline u32 tb_dp_cap_set_lanes(u32 val, u32 lanes)\n{\n\tval &= ~DP_COMMON_CAP_LANES_MASK;\n\tswitch (lanes) {\n\tdefault:\n\t\tWARN(1, \"invalid number of lanes %u passed, defaulting to 1\\n\",\n\t\t     lanes);\n\t\tfallthrough;\n\tcase 1:\n\t\tval |= DP_COMMON_CAP_1_LANE << DP_COMMON_CAP_LANES_SHIFT;\n\t\tbreak;\n\tcase 2:\n\t\tval |= DP_COMMON_CAP_2_LANES << DP_COMMON_CAP_LANES_SHIFT;\n\t\tbreak;\n\tcase 4:\n\t\tval |= DP_COMMON_CAP_4_LANES << DP_COMMON_CAP_LANES_SHIFT;\n\t\tbreak;\n\t}\n\treturn val;\n}\n\nstatic unsigned int tb_dp_bandwidth(unsigned int rate, unsigned int lanes)\n{\n\t \n\tif (tb_dp_is_uhbr_rate(rate))\n\t\treturn rate * lanes * 128 / 132;\n\treturn rate * lanes * 8 / 10;\n}\n\nstatic int tb_dp_reduce_bandwidth(int max_bw, u32 in_rate, u32 in_lanes,\n\t\t\t\t  u32 out_rate, u32 out_lanes, u32 *new_rate,\n\t\t\t\t  u32 *new_lanes)\n{\n\tstatic const u32 dp_bw[][2] = {\n\t\t \n\t\t{ 8100, 4 },  \n\t\t{ 5400, 4 },  \n\t\t{ 8100, 2 },  \n\t\t{ 2700, 4 },  \n\t\t{ 5400, 2 },  \n\t\t{ 8100, 1 },  \n\t\t{ 1620, 4 },  \n\t\t{ 5400, 1 },  \n\t\t{ 2700, 2 },  \n\t\t{ 1620, 2 },  \n\t\t{ 2700, 1 },  \n\t\t{ 1620, 1 },  \n\t};\n\tunsigned int i;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(dp_bw); i++) {\n\t\tif (dp_bw[i][0] > out_rate || dp_bw[i][1] > out_lanes)\n\t\t\tcontinue;\n\n\t\tif (dp_bw[i][0] > in_rate || dp_bw[i][1] > in_lanes)\n\t\t\tcontinue;\n\n\t\tif (tb_dp_bandwidth(dp_bw[i][0], dp_bw[i][1]) <= max_bw) {\n\t\t\t*new_rate = dp_bw[i][0];\n\t\t\t*new_lanes = dp_bw[i][1];\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn -ENOSR;\n}\n\nstatic int tb_dp_xchg_caps(struct tb_tunnel *tunnel)\n{\n\tu32 out_dp_cap, out_rate, out_lanes, in_dp_cap, in_rate, in_lanes, bw;\n\tstruct tb_port *out = tunnel->dst_port;\n\tstruct tb_port *in = tunnel->src_port;\n\tint ret, max_bw;\n\n\t \n\tif (in->sw->generation < 2 || out->sw->generation < 2)\n\t\treturn 0;\n\n\t \n\tret = tb_dp_cm_handshake(in, out, 3000);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = tb_port_read(in, &in_dp_cap, TB_CFG_PORT,\n\t\t\t   in->cap_adap + DP_LOCAL_CAP, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_port_read(out, &out_dp_cap, TB_CFG_PORT,\n\t\t\t   out->cap_adap + DP_LOCAL_CAP, 1);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = tb_port_write(out, &in_dp_cap, TB_CFG_PORT,\n\t\t\t    out->cap_adap + DP_REMOTE_CAP, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tin_rate = tb_dp_cap_get_rate(in_dp_cap);\n\tin_lanes = tb_dp_cap_get_lanes(in_dp_cap);\n\ttb_port_dbg(in, \"maximum supported bandwidth %u Mb/s x%u = %u Mb/s\\n\",\n\t\t    in_rate, in_lanes, tb_dp_bandwidth(in_rate, in_lanes));\n\n\t \n\tout_rate = tb_dp_cap_get_rate(out_dp_cap);\n\tout_lanes = tb_dp_cap_get_lanes(out_dp_cap);\n\tbw = tb_dp_bandwidth(out_rate, out_lanes);\n\ttb_port_dbg(out, \"maximum supported bandwidth %u Mb/s x%u = %u Mb/s\\n\",\n\t\t    out_rate, out_lanes, bw);\n\n\tif (in->sw->config.depth < out->sw->config.depth)\n\t\tmax_bw = tunnel->max_down;\n\telse\n\t\tmax_bw = tunnel->max_up;\n\n\tif (max_bw && bw > max_bw) {\n\t\tu32 new_rate, new_lanes, new_bw;\n\n\t\tret = tb_dp_reduce_bandwidth(max_bw, in_rate, in_lanes,\n\t\t\t\t\t     out_rate, out_lanes, &new_rate,\n\t\t\t\t\t     &new_lanes);\n\t\tif (ret) {\n\t\t\ttb_port_info(out, \"not enough bandwidth for DP tunnel\\n\");\n\t\t\treturn ret;\n\t\t}\n\n\t\tnew_bw = tb_dp_bandwidth(new_rate, new_lanes);\n\t\ttb_port_dbg(out, \"bandwidth reduced to %u Mb/s x%u = %u Mb/s\\n\",\n\t\t\t    new_rate, new_lanes, new_bw);\n\n\t\t \n\t\tout_dp_cap = tb_dp_cap_set_rate(out_dp_cap, new_rate);\n\t\tout_dp_cap = tb_dp_cap_set_lanes(out_dp_cap, new_lanes);\n\t}\n\n\t \n\tif (tb_route(out->sw) && tb_switch_is_titan_ridge(out->sw)) {\n\t\tout_dp_cap |= DP_COMMON_CAP_LTTPR_NS;\n\t\ttb_port_dbg(out, \"disabling LTTPR\\n\");\n\t}\n\n\treturn tb_port_write(in, &out_dp_cap, TB_CFG_PORT,\n\t\t\t     in->cap_adap + DP_REMOTE_CAP, 1);\n}\n\nstatic int tb_dp_bandwidth_alloc_mode_enable(struct tb_tunnel *tunnel)\n{\n\tint ret, estimated_bw, granularity, tmp;\n\tstruct tb_port *out = tunnel->dst_port;\n\tstruct tb_port *in = tunnel->src_port;\n\tu32 out_dp_cap, out_rate, out_lanes;\n\tu32 in_dp_cap, in_rate, in_lanes;\n\tu32 rate, lanes;\n\n\tif (!bw_alloc_mode)\n\t\treturn 0;\n\n\tret = usb4_dp_port_set_cm_bandwidth_mode_supported(in, true);\n\tif (ret)\n\t\treturn ret;\n\n\tret = usb4_dp_port_set_group_id(in, in->group->index);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = tb_port_read(in, &in_dp_cap, TB_CFG_PORT,\n\t\t\t   in->cap_adap + DP_LOCAL_CAP, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_port_read(out, &out_dp_cap, TB_CFG_PORT,\n\t\t\t   out->cap_adap + DP_LOCAL_CAP, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tin_rate = tb_dp_cap_get_rate(in_dp_cap);\n\tin_lanes = tb_dp_cap_get_lanes(in_dp_cap);\n\tout_rate = tb_dp_cap_get_rate(out_dp_cap);\n\tout_lanes = tb_dp_cap_get_lanes(out_dp_cap);\n\n\trate = min(in_rate, out_rate);\n\tlanes = min(in_lanes, out_lanes);\n\ttmp = tb_dp_bandwidth(rate, lanes);\n\n\ttb_port_dbg(in, \"non-reduced bandwidth %u Mb/s x%u = %u Mb/s\\n\", rate,\n\t\t    lanes, tmp);\n\n\tret = usb4_dp_port_set_nrd(in, rate, lanes);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tin_rate = tb_dp_cap_get_rate_ext(in_dp_cap);\n\tout_rate = tb_dp_cap_get_rate_ext(out_dp_cap);\n\trate = min(in_rate, out_rate);\n\ttmp = tb_dp_bandwidth(rate, lanes);\n\n\ttb_port_dbg(in,\n\t\t    \"maximum bandwidth through allocation mode %u Mb/s x%u = %u Mb/s\\n\",\n\t\t    rate, lanes, tmp);\n\n\tfor (granularity = 250; tmp / granularity > 255 && granularity <= 1000;\n\t     granularity *= 2)\n\t\t;\n\n\ttb_port_dbg(in, \"granularity %d Mb/s\\n\", granularity);\n\n\t \n\tret = usb4_dp_port_set_granularity(in, granularity);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (in->sw->config.depth < out->sw->config.depth)\n\t\testimated_bw = tunnel->max_down;\n\telse\n\t\testimated_bw = tunnel->max_up;\n\n\ttb_port_dbg(in, \"estimated bandwidth %d Mb/s\\n\", estimated_bw);\n\n\tret = usb4_dp_port_set_estimated_bandwidth(in, estimated_bw);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = usb4_dp_port_allocate_bandwidth(in, 0);\n\tif (ret)\n\t\treturn ret;\n\n\ttb_port_dbg(in, \"bandwidth allocation mode enabled\\n\");\n\treturn 0;\n}\n\nstatic int tb_dp_init(struct tb_tunnel *tunnel)\n{\n\tstruct tb_port *in = tunnel->src_port;\n\tstruct tb_switch *sw = in->sw;\n\tstruct tb *tb = in->sw->tb;\n\tint ret;\n\n\tret = tb_dp_xchg_caps(tunnel);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!tb_switch_is_usb4(sw))\n\t\treturn 0;\n\n\tif (!usb4_dp_port_bandwidth_mode_supported(in))\n\t\treturn 0;\n\n\ttb_port_dbg(in, \"bandwidth allocation mode supported\\n\");\n\n\tret = usb4_dp_port_set_cm_id(in, tb->index);\n\tif (ret)\n\t\treturn ret;\n\n\treturn tb_dp_bandwidth_alloc_mode_enable(tunnel);\n}\n\nstatic void tb_dp_deinit(struct tb_tunnel *tunnel)\n{\n\tstruct tb_port *in = tunnel->src_port;\n\n\tif (!usb4_dp_port_bandwidth_mode_supported(in))\n\t\treturn;\n\tif (usb4_dp_port_bandwidth_mode_enabled(in)) {\n\t\tusb4_dp_port_set_cm_bandwidth_mode_supported(in, false);\n\t\ttb_port_dbg(in, \"bandwidth allocation mode disabled\\n\");\n\t}\n}\n\nstatic int tb_dp_activate(struct tb_tunnel *tunnel, bool active)\n{\n\tint ret;\n\n\tif (active) {\n\t\tstruct tb_path **paths;\n\t\tint last;\n\n\t\tpaths = tunnel->paths;\n\t\tlast = paths[TB_DP_VIDEO_PATH_OUT]->path_length - 1;\n\n\t\ttb_dp_port_set_hops(tunnel->src_port,\n\t\t\tpaths[TB_DP_VIDEO_PATH_OUT]->hops[0].in_hop_index,\n\t\t\tpaths[TB_DP_AUX_PATH_OUT]->hops[0].in_hop_index,\n\t\t\tpaths[TB_DP_AUX_PATH_IN]->hops[last].next_hop_index);\n\n\t\ttb_dp_port_set_hops(tunnel->dst_port,\n\t\t\tpaths[TB_DP_VIDEO_PATH_OUT]->hops[last].next_hop_index,\n\t\t\tpaths[TB_DP_AUX_PATH_IN]->hops[0].in_hop_index,\n\t\t\tpaths[TB_DP_AUX_PATH_OUT]->hops[last].next_hop_index);\n\t} else {\n\t\ttb_dp_port_hpd_clear(tunnel->src_port);\n\t\ttb_dp_port_set_hops(tunnel->src_port, 0, 0, 0);\n\t\tif (tb_port_is_dpout(tunnel->dst_port))\n\t\t\ttb_dp_port_set_hops(tunnel->dst_port, 0, 0, 0);\n\t}\n\n\tret = tb_dp_port_enable(tunnel->src_port, active);\n\tif (ret)\n\t\treturn ret;\n\n\tif (tb_port_is_dpout(tunnel->dst_port))\n\t\treturn tb_dp_port_enable(tunnel->dst_port, active);\n\n\treturn 0;\n}\n\n \nstatic int tb_dp_bandwidth_mode_maximum_bandwidth(struct tb_tunnel *tunnel,\n\t\t\t\t\t\t  int *max_bw)\n{\n\tstruct tb_port *in = tunnel->src_port;\n\tint ret, rate, lanes, nrd_bw;\n\tu32 cap;\n\n\t \n\tret = tb_port_read(in, &cap, TB_CFG_PORT,\n\t\t\t   in->cap_adap + DP_LOCAL_CAP, 1);\n\tif (ret)\n\t\treturn ret;\n\n\trate = tb_dp_cap_get_rate_ext(cap);\n\tif (tb_dp_is_uhbr_rate(rate)) {\n\t\t \n\t\tlanes = tb_dp_cap_get_lanes(cap);\n\t} else {\n\t\t \n\t\tret = usb4_dp_port_nrd(in, &rate, &lanes);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tnrd_bw = tb_dp_bandwidth(rate, lanes);\n\n\tif (max_bw) {\n\t\tret = usb4_dp_port_granularity(in);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\t*max_bw = roundup(nrd_bw, ret);\n\t}\n\n\treturn nrd_bw;\n}\n\nstatic int tb_dp_bandwidth_mode_consumed_bandwidth(struct tb_tunnel *tunnel,\n\t\t\t\t\t\t   int *consumed_up,\n\t\t\t\t\t\t   int *consumed_down)\n{\n\tstruct tb_port *out = tunnel->dst_port;\n\tstruct tb_port *in = tunnel->src_port;\n\tint ret, allocated_bw, max_bw;\n\n\tif (!usb4_dp_port_bandwidth_mode_enabled(in))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!tunnel->bw_mode)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tret = usb4_dp_port_allocated_bandwidth(in);\n\tif (ret < 0)\n\t\treturn ret;\n\tallocated_bw = ret;\n\n\tret = tb_dp_bandwidth_mode_maximum_bandwidth(tunnel, &max_bw);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (allocated_bw == max_bw)\n\t\tallocated_bw = ret;\n\n\ttb_port_dbg(in, \"consumed bandwidth through allocation mode %d Mb/s\\n\",\n\t\t    allocated_bw);\n\n\tif (in->sw->config.depth < out->sw->config.depth) {\n\t\t*consumed_up = 0;\n\t\t*consumed_down = allocated_bw;\n\t} else {\n\t\t*consumed_up = allocated_bw;\n\t\t*consumed_down = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic int tb_dp_allocated_bandwidth(struct tb_tunnel *tunnel, int *allocated_up,\n\t\t\t\t     int *allocated_down)\n{\n\tstruct tb_port *out = tunnel->dst_port;\n\tstruct tb_port *in = tunnel->src_port;\n\n\t \n\tif (usb4_dp_port_bandwidth_mode_enabled(in) && tunnel->bw_mode) {\n\t\tint ret, allocated_bw, max_bw;\n\n\t\tret = usb4_dp_port_allocated_bandwidth(in);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tallocated_bw = ret;\n\n\t\tret = tb_dp_bandwidth_mode_maximum_bandwidth(tunnel, &max_bw);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (allocated_bw == max_bw)\n\t\t\tallocated_bw = ret;\n\n\t\tif (in->sw->config.depth < out->sw->config.depth) {\n\t\t\t*allocated_up = 0;\n\t\t\t*allocated_down = allocated_bw;\n\t\t} else {\n\t\t\t*allocated_up = allocated_bw;\n\t\t\t*allocated_down = 0;\n\t\t}\n\t\treturn 0;\n\t}\n\n\treturn tunnel->consumed_bandwidth(tunnel, allocated_up,\n\t\t\t\t\t  allocated_down);\n}\n\nstatic int tb_dp_alloc_bandwidth(struct tb_tunnel *tunnel, int *alloc_up,\n\t\t\t\t int *alloc_down)\n{\n\tstruct tb_port *out = tunnel->dst_port;\n\tstruct tb_port *in = tunnel->src_port;\n\tint max_bw, ret, tmp;\n\n\tif (!usb4_dp_port_bandwidth_mode_enabled(in))\n\t\treturn -EOPNOTSUPP;\n\n\tret = tb_dp_bandwidth_mode_maximum_bandwidth(tunnel, &max_bw);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (in->sw->config.depth < out->sw->config.depth) {\n\t\ttmp = min(*alloc_down, max_bw);\n\t\tret = usb4_dp_port_allocate_bandwidth(in, tmp);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\t*alloc_down = tmp;\n\t\t*alloc_up = 0;\n\t} else {\n\t\ttmp = min(*alloc_up, max_bw);\n\t\tret = usb4_dp_port_allocate_bandwidth(in, tmp);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\t*alloc_down = 0;\n\t\t*alloc_up = tmp;\n\t}\n\n\t \n\t \n\ttunnel->bw_mode = true;\n\n\ttb_port_dbg(in, \"allocated bandwidth through allocation mode %d Mb/s\\n\",\n\t\t    tmp);\n\treturn 0;\n}\n\nstatic int tb_dp_read_dprx(struct tb_tunnel *tunnel, u32 *rate, u32 *lanes,\n\t\t\t   int timeout_msec)\n{\n\tktime_t timeout = ktime_add_ms(ktime_get(), timeout_msec);\n\tstruct tb_port *in = tunnel->src_port;\n\n\t \n\tdo {\n\t\tu32 val;\n\t\tint ret;\n\n\t\tret = tb_port_read(in, &val, TB_CFG_PORT,\n\t\t\t\t   in->cap_adap + DP_COMMON_CAP, 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (val & DP_COMMON_CAP_DPRX_DONE) {\n\t\t\t*rate = tb_dp_cap_get_rate(val);\n\t\t\t*lanes = tb_dp_cap_get_lanes(val);\n\n\t\t\ttb_port_dbg(in, \"consumed bandwidth through DPRX %d Mb/s\\n\",\n\t\t\t\t    tb_dp_bandwidth(*rate, *lanes));\n\t\t\treturn 0;\n\t\t}\n\t\tusleep_range(100, 150);\n\t} while (ktime_before(ktime_get(), timeout));\n\n\treturn -ETIMEDOUT;\n}\n\n \nstatic int tb_dp_read_cap(struct tb_tunnel *tunnel, unsigned int cap, u32 *rate,\n\t\t\t  u32 *lanes)\n{\n\tstruct tb_port *in = tunnel->src_port;\n\tu32 val;\n\tint ret;\n\n\tswitch (cap) {\n\tcase DP_LOCAL_CAP:\n\tcase DP_REMOTE_CAP:\n\t\tbreak;\n\n\tdefault:\n\t\ttb_tunnel_WARN(tunnel, \"invalid capability index %#x\\n\", cap);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tret = tb_port_read(in, &val, TB_CFG_PORT, in->cap_adap + cap, 1);\n\tif (ret)\n\t\treturn ret;\n\n\t*rate = tb_dp_cap_get_rate(val);\n\t*lanes = tb_dp_cap_get_lanes(val);\n\n\ttb_port_dbg(in, \"bandwidth from %#x capability %d Mb/s\\n\", cap,\n\t\t    tb_dp_bandwidth(*rate, *lanes));\n\treturn 0;\n}\n\nstatic int tb_dp_maximum_bandwidth(struct tb_tunnel *tunnel, int *max_up,\n\t\t\t\t   int *max_down)\n{\n\tstruct tb_port *in = tunnel->src_port;\n\tint ret;\n\n\tif (!usb4_dp_port_bandwidth_mode_enabled(in))\n\t\treturn -EOPNOTSUPP;\n\n\tret = tb_dp_bandwidth_mode_maximum_bandwidth(tunnel, NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (in->sw->config.depth < tunnel->dst_port->sw->config.depth) {\n\t\t*max_up = 0;\n\t\t*max_down = ret;\n\t} else {\n\t\t*max_up = ret;\n\t\t*max_down = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic int tb_dp_consumed_bandwidth(struct tb_tunnel *tunnel, int *consumed_up,\n\t\t\t\t    int *consumed_down)\n{\n\tstruct tb_port *in = tunnel->src_port;\n\tconst struct tb_switch *sw = in->sw;\n\tu32 rate = 0, lanes = 0;\n\tint ret;\n\n\tif (tb_dp_is_usb4(sw)) {\n\t\t \n\t\tret = tb_dp_bandwidth_mode_consumed_bandwidth(tunnel, consumed_up,\n\t\t\t\t\t\t\t      consumed_down);\n\t\tif (ret < 0) {\n\t\t\tif (ret != -EOPNOTSUPP)\n\t\t\t\treturn ret;\n\t\t} else if (!ret) {\n\t\t\treturn 0;\n\t\t}\n\t\t \n\t\tret = tb_dp_read_dprx(tunnel, &rate, &lanes, 150);\n\t\tif (ret) {\n\t\t\tif (ret == -ETIMEDOUT)\n\t\t\t\tret = tb_dp_read_cap(tunnel, DP_REMOTE_CAP,\n\t\t\t\t\t\t     &rate, &lanes);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t} else if (sw->generation >= 2) {\n\t\tret = tb_dp_read_cap(tunnel, DP_REMOTE_CAP, &rate, &lanes);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\t \n\t\t*consumed_up = 0;\n\t\t*consumed_down = 0;\n\t\treturn 0;\n\t}\n\n\tif (in->sw->config.depth < tunnel->dst_port->sw->config.depth) {\n\t\t*consumed_up = 0;\n\t\t*consumed_down = tb_dp_bandwidth(rate, lanes);\n\t} else {\n\t\t*consumed_up = tb_dp_bandwidth(rate, lanes);\n\t\t*consumed_down = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic void tb_dp_init_aux_credits(struct tb_path_hop *hop)\n{\n\tstruct tb_port *port = hop->in_port;\n\tstruct tb_switch *sw = port->sw;\n\n\tif (tb_port_use_credit_allocation(port))\n\t\thop->initial_credits = sw->min_dp_aux_credits;\n\telse\n\t\thop->initial_credits = 1;\n}\n\nstatic void tb_dp_init_aux_path(struct tb_path *path)\n{\n\tstruct tb_path_hop *hop;\n\n\tpath->egress_fc_enable = TB_PATH_SOURCE | TB_PATH_INTERNAL;\n\tpath->egress_shared_buffer = TB_PATH_NONE;\n\tpath->ingress_fc_enable = TB_PATH_ALL;\n\tpath->ingress_shared_buffer = TB_PATH_NONE;\n\tpath->priority = 2;\n\tpath->weight = 1;\n\n\ttb_path_for_each_hop(path, hop)\n\t\ttb_dp_init_aux_credits(hop);\n}\n\nstatic int tb_dp_init_video_credits(struct tb_path_hop *hop)\n{\n\tstruct tb_port *port = hop->in_port;\n\tstruct tb_switch *sw = port->sw;\n\n\tif (tb_port_use_credit_allocation(port)) {\n\t\tunsigned int nfc_credits;\n\t\tsize_t max_dp_streams;\n\n\t\ttb_available_credits(port, &max_dp_streams);\n\t\t \n\t\tnfc_credits = port->config.nfc_credits &\n\t\t\t\tADP_CS_4_NFC_BUFFERS_MASK;\n\t\tif (nfc_credits / sw->min_dp_main_credits > max_dp_streams)\n\t\t\treturn -ENOSPC;\n\n\t\thop->nfc_credits = sw->min_dp_main_credits;\n\t} else {\n\t\thop->nfc_credits = min(port->total_credits - 2, 12U);\n\t}\n\n\treturn 0;\n}\n\nstatic int tb_dp_init_video_path(struct tb_path *path)\n{\n\tstruct tb_path_hop *hop;\n\n\tpath->egress_fc_enable = TB_PATH_NONE;\n\tpath->egress_shared_buffer = TB_PATH_NONE;\n\tpath->ingress_fc_enable = TB_PATH_NONE;\n\tpath->ingress_shared_buffer = TB_PATH_NONE;\n\tpath->priority = 1;\n\tpath->weight = 1;\n\n\ttb_path_for_each_hop(path, hop) {\n\t\tint ret;\n\n\t\tret = tb_dp_init_video_credits(hop);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void tb_dp_dump(struct tb_tunnel *tunnel)\n{\n\tstruct tb_port *in, *out;\n\tu32 dp_cap, rate, lanes;\n\n\tin = tunnel->src_port;\n\tout = tunnel->dst_port;\n\n\tif (tb_port_read(in, &dp_cap, TB_CFG_PORT,\n\t\t\t in->cap_adap + DP_LOCAL_CAP, 1))\n\t\treturn;\n\n\trate = tb_dp_cap_get_rate(dp_cap);\n\tlanes = tb_dp_cap_get_lanes(dp_cap);\n\n\ttb_port_dbg(in, \"maximum supported bandwidth %u Mb/s x%u = %u Mb/s\\n\",\n\t\t    rate, lanes, tb_dp_bandwidth(rate, lanes));\n\n\tout = tunnel->dst_port;\n\n\tif (tb_port_read(out, &dp_cap, TB_CFG_PORT,\n\t\t\t out->cap_adap + DP_LOCAL_CAP, 1))\n\t\treturn;\n\n\trate = tb_dp_cap_get_rate(dp_cap);\n\tlanes = tb_dp_cap_get_lanes(dp_cap);\n\n\ttb_port_dbg(out, \"maximum supported bandwidth %u Mb/s x%u = %u Mb/s\\n\",\n\t\t    rate, lanes, tb_dp_bandwidth(rate, lanes));\n\n\tif (tb_port_read(in, &dp_cap, TB_CFG_PORT,\n\t\t\t in->cap_adap + DP_REMOTE_CAP, 1))\n\t\treturn;\n\n\trate = tb_dp_cap_get_rate(dp_cap);\n\tlanes = tb_dp_cap_get_lanes(dp_cap);\n\n\ttb_port_dbg(in, \"reduced bandwidth %u Mb/s x%u = %u Mb/s\\n\",\n\t\t    rate, lanes, tb_dp_bandwidth(rate, lanes));\n}\n\n \nstruct tb_tunnel *tb_tunnel_discover_dp(struct tb *tb, struct tb_port *in,\n\t\t\t\t\tbool alloc_hopid)\n{\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_port *port;\n\tstruct tb_path *path;\n\n\tif (!tb_dp_port_is_enabled(in))\n\t\treturn NULL;\n\n\ttunnel = tb_tunnel_alloc(tb, 3, TB_TUNNEL_DP);\n\tif (!tunnel)\n\t\treturn NULL;\n\n\ttunnel->init = tb_dp_init;\n\ttunnel->deinit = tb_dp_deinit;\n\ttunnel->activate = tb_dp_activate;\n\ttunnel->maximum_bandwidth = tb_dp_maximum_bandwidth;\n\ttunnel->allocated_bandwidth = tb_dp_allocated_bandwidth;\n\ttunnel->alloc_bandwidth = tb_dp_alloc_bandwidth;\n\ttunnel->consumed_bandwidth = tb_dp_consumed_bandwidth;\n\ttunnel->src_port = in;\n\n\tpath = tb_path_discover(in, TB_DP_VIDEO_HOPID, NULL, -1,\n\t\t\t\t&tunnel->dst_port, \"Video\", alloc_hopid);\n\tif (!path) {\n\t\t \n\t\ttb_dp_port_enable(in, false);\n\t\tgoto err_free;\n\t}\n\ttunnel->paths[TB_DP_VIDEO_PATH_OUT] = path;\n\tif (tb_dp_init_video_path(tunnel->paths[TB_DP_VIDEO_PATH_OUT]))\n\t\tgoto err_free;\n\n\tpath = tb_path_discover(in, TB_DP_AUX_TX_HOPID, NULL, -1, NULL, \"AUX TX\",\n\t\t\t\talloc_hopid);\n\tif (!path)\n\t\tgoto err_deactivate;\n\ttunnel->paths[TB_DP_AUX_PATH_OUT] = path;\n\ttb_dp_init_aux_path(tunnel->paths[TB_DP_AUX_PATH_OUT]);\n\n\tpath = tb_path_discover(tunnel->dst_port, -1, in, TB_DP_AUX_RX_HOPID,\n\t\t\t\t&port, \"AUX RX\", alloc_hopid);\n\tif (!path)\n\t\tgoto err_deactivate;\n\ttunnel->paths[TB_DP_AUX_PATH_IN] = path;\n\ttb_dp_init_aux_path(tunnel->paths[TB_DP_AUX_PATH_IN]);\n\n\t \n\tif (!tb_port_is_dpout(tunnel->dst_port)) {\n\t\ttb_port_warn(in, \"path does not end on a DP adapter, cleaning up\\n\");\n\t\tgoto err_deactivate;\n\t}\n\n\tif (!tb_dp_port_is_enabled(tunnel->dst_port))\n\t\tgoto err_deactivate;\n\n\tif (!tb_dp_port_hpd_is_active(tunnel->dst_port))\n\t\tgoto err_deactivate;\n\n\tif (port != tunnel->src_port) {\n\t\ttb_tunnel_warn(tunnel, \"path is not complete, cleaning up\\n\");\n\t\tgoto err_deactivate;\n\t}\n\n\ttb_dp_dump(tunnel);\n\n\ttb_tunnel_dbg(tunnel, \"discovered\\n\");\n\treturn tunnel;\n\nerr_deactivate:\n\ttb_tunnel_deactivate(tunnel);\nerr_free:\n\ttb_tunnel_free(tunnel);\n\n\treturn NULL;\n}\n\n \nstruct tb_tunnel *tb_tunnel_alloc_dp(struct tb *tb, struct tb_port *in,\n\t\t\t\t     struct tb_port *out, int link_nr,\n\t\t\t\t     int max_up, int max_down)\n{\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_path **paths;\n\tstruct tb_path *path;\n\n\tif (WARN_ON(!in->cap_adap || !out->cap_adap))\n\t\treturn NULL;\n\n\ttunnel = tb_tunnel_alloc(tb, 3, TB_TUNNEL_DP);\n\tif (!tunnel)\n\t\treturn NULL;\n\n\ttunnel->init = tb_dp_init;\n\ttunnel->deinit = tb_dp_deinit;\n\ttunnel->activate = tb_dp_activate;\n\ttunnel->maximum_bandwidth = tb_dp_maximum_bandwidth;\n\ttunnel->allocated_bandwidth = tb_dp_allocated_bandwidth;\n\ttunnel->alloc_bandwidth = tb_dp_alloc_bandwidth;\n\ttunnel->consumed_bandwidth = tb_dp_consumed_bandwidth;\n\ttunnel->src_port = in;\n\ttunnel->dst_port = out;\n\ttunnel->max_up = max_up;\n\ttunnel->max_down = max_down;\n\n\tpaths = tunnel->paths;\n\n\tpath = tb_path_alloc(tb, in, TB_DP_VIDEO_HOPID, out, TB_DP_VIDEO_HOPID,\n\t\t\t     link_nr, \"Video\");\n\tif (!path)\n\t\tgoto err_free;\n\ttb_dp_init_video_path(path);\n\tpaths[TB_DP_VIDEO_PATH_OUT] = path;\n\n\tpath = tb_path_alloc(tb, in, TB_DP_AUX_TX_HOPID, out,\n\t\t\t     TB_DP_AUX_TX_HOPID, link_nr, \"AUX TX\");\n\tif (!path)\n\t\tgoto err_free;\n\ttb_dp_init_aux_path(path);\n\tpaths[TB_DP_AUX_PATH_OUT] = path;\n\n\tpath = tb_path_alloc(tb, out, TB_DP_AUX_RX_HOPID, in,\n\t\t\t     TB_DP_AUX_RX_HOPID, link_nr, \"AUX RX\");\n\tif (!path)\n\t\tgoto err_free;\n\ttb_dp_init_aux_path(path);\n\tpaths[TB_DP_AUX_PATH_IN] = path;\n\n\treturn tunnel;\n\nerr_free:\n\ttb_tunnel_free(tunnel);\n\treturn NULL;\n}\n\nstatic unsigned int tb_dma_available_credits(const struct tb_port *port)\n{\n\tconst struct tb_switch *sw = port->sw;\n\tint credits;\n\n\tcredits = tb_available_credits(port, NULL);\n\tif (tb_acpi_may_tunnel_pcie())\n\t\tcredits -= sw->max_pcie_credits;\n\tcredits -= port->dma_credits;\n\n\treturn credits > 0 ? credits : 0;\n}\n\nstatic int tb_dma_reserve_credits(struct tb_path_hop *hop, unsigned int credits)\n{\n\tstruct tb_port *port = hop->in_port;\n\n\tif (tb_port_use_credit_allocation(port)) {\n\t\tunsigned int available = tb_dma_available_credits(port);\n\n\t\t \n\t\tif (available < TB_MIN_DMA_CREDITS)\n\t\t\treturn -ENOSPC;\n\n\t\twhile (credits > available)\n\t\t\tcredits--;\n\n\t\ttb_port_dbg(port, \"reserving %u credits for DMA path\\n\",\n\t\t\t    credits);\n\n\t\tport->dma_credits += credits;\n\t} else {\n\t\tif (tb_port_is_null(port))\n\t\t\tcredits = port->bonded ? 14 : 6;\n\t\telse\n\t\t\tcredits = min(port->total_credits, credits);\n\t}\n\n\thop->initial_credits = credits;\n\treturn 0;\n}\n\n \nstatic int tb_dma_init_rx_path(struct tb_path *path, unsigned int credits)\n{\n\tstruct tb_path_hop *hop;\n\tunsigned int i, tmp;\n\n\tpath->egress_fc_enable = TB_PATH_SOURCE | TB_PATH_INTERNAL;\n\tpath->ingress_fc_enable = TB_PATH_ALL;\n\tpath->egress_shared_buffer = TB_PATH_NONE;\n\tpath->ingress_shared_buffer = TB_PATH_NONE;\n\tpath->priority = 5;\n\tpath->weight = 1;\n\tpath->clear_fc = true;\n\n\t \n\thop = &path->hops[0];\n\ttmp = min(tb_usable_credits(hop->in_port), credits);\n\thop->initial_credits = tmp;\n\thop->in_port->dma_credits += tmp;\n\n\tfor (i = 1; i < path->path_length; i++) {\n\t\tint ret;\n\n\t\tret = tb_dma_reserve_credits(&path->hops[i], credits);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int tb_dma_init_tx_path(struct tb_path *path, unsigned int credits)\n{\n\tstruct tb_path_hop *hop;\n\n\tpath->egress_fc_enable = TB_PATH_ALL;\n\tpath->ingress_fc_enable = TB_PATH_ALL;\n\tpath->egress_shared_buffer = TB_PATH_NONE;\n\tpath->ingress_shared_buffer = TB_PATH_NONE;\n\tpath->priority = 5;\n\tpath->weight = 1;\n\tpath->clear_fc = true;\n\n\ttb_path_for_each_hop(path, hop) {\n\t\tint ret;\n\n\t\tret = tb_dma_reserve_credits(hop, credits);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void tb_dma_release_credits(struct tb_path_hop *hop)\n{\n\tstruct tb_port *port = hop->in_port;\n\n\tif (tb_port_use_credit_allocation(port)) {\n\t\tport->dma_credits -= hop->initial_credits;\n\n\t\ttb_port_dbg(port, \"released %u DMA path credits\\n\",\n\t\t\t    hop->initial_credits);\n\t}\n}\n\nstatic void tb_dma_deinit_path(struct tb_path *path)\n{\n\tstruct tb_path_hop *hop;\n\n\ttb_path_for_each_hop(path, hop)\n\t\ttb_dma_release_credits(hop);\n}\n\nstatic void tb_dma_deinit(struct tb_tunnel *tunnel)\n{\n\tint i;\n\n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tif (!tunnel->paths[i])\n\t\t\tcontinue;\n\t\ttb_dma_deinit_path(tunnel->paths[i]);\n\t}\n}\n\n \nstruct tb_tunnel *tb_tunnel_alloc_dma(struct tb *tb, struct tb_port *nhi,\n\t\t\t\t      struct tb_port *dst, int transmit_path,\n\t\t\t\t      int transmit_ring, int receive_path,\n\t\t\t\t      int receive_ring)\n{\n\tstruct tb_tunnel *tunnel;\n\tsize_t npaths = 0, i = 0;\n\tstruct tb_path *path;\n\tint credits;\n\n\t \n\tif (WARN_ON(!receive_ring || !transmit_ring))\n\t\treturn NULL;\n\n\tif (receive_ring > 0)\n\t\tnpaths++;\n\tif (transmit_ring > 0)\n\t\tnpaths++;\n\n\tif (WARN_ON(!npaths))\n\t\treturn NULL;\n\n\ttunnel = tb_tunnel_alloc(tb, npaths, TB_TUNNEL_DMA);\n\tif (!tunnel)\n\t\treturn NULL;\n\n\ttunnel->src_port = nhi;\n\ttunnel->dst_port = dst;\n\ttunnel->deinit = tb_dma_deinit;\n\n\tcredits = min_not_zero(dma_credits, nhi->sw->max_dma_credits);\n\n\tif (receive_ring > 0) {\n\t\tpath = tb_path_alloc(tb, dst, receive_path, nhi, receive_ring, 0,\n\t\t\t\t     \"DMA RX\");\n\t\tif (!path)\n\t\t\tgoto err_free;\n\t\ttunnel->paths[i++] = path;\n\t\tif (tb_dma_init_rx_path(path, credits)) {\n\t\t\ttb_tunnel_dbg(tunnel, \"not enough buffers for RX path\\n\");\n\t\t\tgoto err_free;\n\t\t}\n\t}\n\n\tif (transmit_ring > 0) {\n\t\tpath = tb_path_alloc(tb, nhi, transmit_ring, dst, transmit_path, 0,\n\t\t\t\t     \"DMA TX\");\n\t\tif (!path)\n\t\t\tgoto err_free;\n\t\ttunnel->paths[i++] = path;\n\t\tif (tb_dma_init_tx_path(path, credits)) {\n\t\t\ttb_tunnel_dbg(tunnel, \"not enough buffers for TX path\\n\");\n\t\t\tgoto err_free;\n\t\t}\n\t}\n\n\treturn tunnel;\n\nerr_free:\n\ttb_tunnel_free(tunnel);\n\treturn NULL;\n}\n\n \nbool tb_tunnel_match_dma(const struct tb_tunnel *tunnel, int transmit_path,\n\t\t\t int transmit_ring, int receive_path, int receive_ring)\n{\n\tconst struct tb_path *tx_path = NULL, *rx_path = NULL;\n\tint i;\n\n\tif (!receive_ring || !transmit_ring)\n\t\treturn false;\n\n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tconst struct tb_path *path = tunnel->paths[i];\n\n\t\tif (!path)\n\t\t\tcontinue;\n\n\t\tif (tb_port_is_nhi(path->hops[0].in_port))\n\t\t\ttx_path = path;\n\t\telse if (tb_port_is_nhi(path->hops[path->path_length - 1].out_port))\n\t\t\trx_path = path;\n\t}\n\n\tif (transmit_ring > 0 || transmit_path > 0) {\n\t\tif (!tx_path)\n\t\t\treturn false;\n\t\tif (transmit_ring > 0 &&\n\t\t    (tx_path->hops[0].in_hop_index != transmit_ring))\n\t\t\treturn false;\n\t\tif (transmit_path > 0 &&\n\t\t    (tx_path->hops[tx_path->path_length - 1].next_hop_index != transmit_path))\n\t\t\treturn false;\n\t}\n\n\tif (receive_ring > 0 || receive_path > 0) {\n\t\tif (!rx_path)\n\t\t\treturn false;\n\t\tif (receive_path > 0 &&\n\t\t    (rx_path->hops[0].in_hop_index != receive_path))\n\t\t\treturn false;\n\t\tif (receive_ring > 0 &&\n\t\t    (rx_path->hops[rx_path->path_length - 1].next_hop_index != receive_ring))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic int tb_usb3_max_link_rate(struct tb_port *up, struct tb_port *down)\n{\n\tint ret, up_max_rate, down_max_rate;\n\n\tret = usb4_usb3_port_max_link_rate(up);\n\tif (ret < 0)\n\t\treturn ret;\n\tup_max_rate = ret;\n\n\tret = usb4_usb3_port_max_link_rate(down);\n\tif (ret < 0)\n\t\treturn ret;\n\tdown_max_rate = ret;\n\n\treturn min(up_max_rate, down_max_rate);\n}\n\nstatic int tb_usb3_init(struct tb_tunnel *tunnel)\n{\n\ttb_tunnel_dbg(tunnel, \"allocating initial bandwidth %d/%d Mb/s\\n\",\n\t\t      tunnel->allocated_up, tunnel->allocated_down);\n\n\treturn usb4_usb3_port_allocate_bandwidth(tunnel->src_port,\n\t\t\t\t\t\t &tunnel->allocated_up,\n\t\t\t\t\t\t &tunnel->allocated_down);\n}\n\nstatic int tb_usb3_activate(struct tb_tunnel *tunnel, bool activate)\n{\n\tint res;\n\n\tres = tb_usb3_port_enable(tunnel->src_port, activate);\n\tif (res)\n\t\treturn res;\n\n\tif (tb_port_is_usb3_up(tunnel->dst_port))\n\t\treturn tb_usb3_port_enable(tunnel->dst_port, activate);\n\n\treturn 0;\n}\n\nstatic int tb_usb3_consumed_bandwidth(struct tb_tunnel *tunnel,\n\t\tint *consumed_up, int *consumed_down)\n{\n\tint pcie_enabled = tb_acpi_may_tunnel_pcie();\n\n\t \n\t*consumed_up = tunnel->allocated_up * (3 + pcie_enabled) / 3;\n\t*consumed_down = tunnel->allocated_down * (3 + pcie_enabled) / 3;\n\treturn 0;\n}\n\nstatic int tb_usb3_release_unused_bandwidth(struct tb_tunnel *tunnel)\n{\n\tint ret;\n\n\tret = usb4_usb3_port_release_bandwidth(tunnel->src_port,\n\t\t\t\t\t       &tunnel->allocated_up,\n\t\t\t\t\t       &tunnel->allocated_down);\n\tif (ret)\n\t\treturn ret;\n\n\ttb_tunnel_dbg(tunnel, \"decreased bandwidth allocation to %d/%d Mb/s\\n\",\n\t\t      tunnel->allocated_up, tunnel->allocated_down);\n\treturn 0;\n}\n\nstatic void tb_usb3_reclaim_available_bandwidth(struct tb_tunnel *tunnel,\n\t\t\t\t\t\tint *available_up,\n\t\t\t\t\t\tint *available_down)\n{\n\tint ret, max_rate, allocate_up, allocate_down;\n\n\tret = usb4_usb3_port_actual_link_rate(tunnel->src_port);\n\tif (ret < 0) {\n\t\ttb_tunnel_warn(tunnel, \"failed to read actual link rate\\n\");\n\t\treturn;\n\t} else if (!ret) {\n\t\t \n\t\tret = tb_usb3_max_link_rate(tunnel->dst_port, tunnel->src_port);\n\t\tif (ret < 0) {\n\t\t\ttb_tunnel_warn(tunnel, \"failed to read maximum link rate\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\t \n\tmax_rate = ret * 90 / 100;\n\n\t \n\tif (tunnel->allocated_up >= max_rate &&\n\t    tunnel->allocated_down >= max_rate)\n\t\treturn;\n\n\t \n\tallocate_up = min(max_rate, *available_up);\n\tif (allocate_up < tunnel->allocated_up)\n\t\tallocate_up = tunnel->allocated_up;\n\n\tallocate_down = min(max_rate, *available_down);\n\tif (allocate_down < tunnel->allocated_down)\n\t\tallocate_down = tunnel->allocated_down;\n\n\t \n\tif (allocate_up == tunnel->allocated_up &&\n\t    allocate_down == tunnel->allocated_down)\n\t\treturn;\n\n\tret = usb4_usb3_port_allocate_bandwidth(tunnel->src_port, &allocate_up,\n\t\t\t\t\t\t&allocate_down);\n\tif (ret) {\n\t\ttb_tunnel_info(tunnel, \"failed to allocate bandwidth\\n\");\n\t\treturn;\n\t}\n\n\ttunnel->allocated_up = allocate_up;\n\t*available_up -= tunnel->allocated_up;\n\n\ttunnel->allocated_down = allocate_down;\n\t*available_down -= tunnel->allocated_down;\n\n\ttb_tunnel_dbg(tunnel, \"increased bandwidth allocation to %d/%d Mb/s\\n\",\n\t\t      tunnel->allocated_up, tunnel->allocated_down);\n}\n\nstatic void tb_usb3_init_credits(struct tb_path_hop *hop)\n{\n\tstruct tb_port *port = hop->in_port;\n\tstruct tb_switch *sw = port->sw;\n\tunsigned int credits;\n\n\tif (tb_port_use_credit_allocation(port)) {\n\t\tcredits = sw->max_usb3_credits;\n\t} else {\n\t\tif (tb_port_is_null(port))\n\t\t\tcredits = port->bonded ? 32 : 16;\n\t\telse\n\t\t\tcredits = 7;\n\t}\n\n\thop->initial_credits = credits;\n}\n\nstatic void tb_usb3_init_path(struct tb_path *path)\n{\n\tstruct tb_path_hop *hop;\n\n\tpath->egress_fc_enable = TB_PATH_SOURCE | TB_PATH_INTERNAL;\n\tpath->egress_shared_buffer = TB_PATH_NONE;\n\tpath->ingress_fc_enable = TB_PATH_ALL;\n\tpath->ingress_shared_buffer = TB_PATH_NONE;\n\tpath->priority = 3;\n\tpath->weight = 3;\n\tpath->drop_packages = 0;\n\n\ttb_path_for_each_hop(path, hop)\n\t\ttb_usb3_init_credits(hop);\n}\n\n \nstruct tb_tunnel *tb_tunnel_discover_usb3(struct tb *tb, struct tb_port *down,\n\t\t\t\t\t  bool alloc_hopid)\n{\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_path *path;\n\n\tif (!tb_usb3_port_is_enabled(down))\n\t\treturn NULL;\n\n\ttunnel = tb_tunnel_alloc(tb, 2, TB_TUNNEL_USB3);\n\tif (!tunnel)\n\t\treturn NULL;\n\n\ttunnel->activate = tb_usb3_activate;\n\ttunnel->src_port = down;\n\n\t \n\tpath = tb_path_discover(down, TB_USB3_HOPID, NULL, -1,\n\t\t\t\t&tunnel->dst_port, \"USB3 Down\", alloc_hopid);\n\tif (!path) {\n\t\t \n\t\ttb_usb3_port_enable(down, false);\n\t\tgoto err_free;\n\t}\n\ttunnel->paths[TB_USB3_PATH_DOWN] = path;\n\ttb_usb3_init_path(tunnel->paths[TB_USB3_PATH_DOWN]);\n\n\tpath = tb_path_discover(tunnel->dst_port, -1, down, TB_USB3_HOPID, NULL,\n\t\t\t\t\"USB3 Up\", alloc_hopid);\n\tif (!path)\n\t\tgoto err_deactivate;\n\ttunnel->paths[TB_USB3_PATH_UP] = path;\n\ttb_usb3_init_path(tunnel->paths[TB_USB3_PATH_UP]);\n\n\t \n\tif (!tb_port_is_usb3_up(tunnel->dst_port)) {\n\t\ttb_port_warn(tunnel->dst_port,\n\t\t\t     \"path does not end on an USB3 adapter, cleaning up\\n\");\n\t\tgoto err_deactivate;\n\t}\n\n\tif (down != tunnel->src_port) {\n\t\ttb_tunnel_warn(tunnel, \"path is not complete, cleaning up\\n\");\n\t\tgoto err_deactivate;\n\t}\n\n\tif (!tb_usb3_port_is_enabled(tunnel->dst_port)) {\n\t\ttb_tunnel_warn(tunnel,\n\t\t\t       \"tunnel is not fully activated, cleaning up\\n\");\n\t\tgoto err_deactivate;\n\t}\n\n\tif (!tb_route(down->sw)) {\n\t\tint ret;\n\n\t\t \n\t\tret = usb4_usb3_port_allocated_bandwidth(down,\n\t\t\t&tunnel->allocated_up, &tunnel->allocated_down);\n\t\tif (ret)\n\t\t\tgoto err_deactivate;\n\n\t\ttb_tunnel_dbg(tunnel, \"currently allocated bandwidth %d/%d Mb/s\\n\",\n\t\t\t      tunnel->allocated_up, tunnel->allocated_down);\n\n\t\ttunnel->init = tb_usb3_init;\n\t\ttunnel->consumed_bandwidth = tb_usb3_consumed_bandwidth;\n\t\ttunnel->release_unused_bandwidth =\n\t\t\ttb_usb3_release_unused_bandwidth;\n\t\ttunnel->reclaim_available_bandwidth =\n\t\t\ttb_usb3_reclaim_available_bandwidth;\n\t}\n\n\ttb_tunnel_dbg(tunnel, \"discovered\\n\");\n\treturn tunnel;\n\nerr_deactivate:\n\ttb_tunnel_deactivate(tunnel);\nerr_free:\n\ttb_tunnel_free(tunnel);\n\n\treturn NULL;\n}\n\n \nstruct tb_tunnel *tb_tunnel_alloc_usb3(struct tb *tb, struct tb_port *up,\n\t\t\t\t       struct tb_port *down, int max_up,\n\t\t\t\t       int max_down)\n{\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_path *path;\n\tint max_rate = 0;\n\n\t \n\tif (max_up > 0 || max_down > 0) {\n\t\tmax_rate = tb_usb3_max_link_rate(down, up);\n\t\tif (max_rate < 0)\n\t\t\treturn NULL;\n\n\t\t \n\t\tmax_rate = max_rate * 90 / 100;\n\t\ttb_port_dbg(up, \"required bandwidth for USB3 tunnel %d Mb/s\\n\",\n\t\t\t    max_rate);\n\n\t\tif (max_rate > max_up || max_rate > max_down) {\n\t\t\ttb_port_warn(up, \"not enough bandwidth for USB3 tunnel\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\ttunnel = tb_tunnel_alloc(tb, 2, TB_TUNNEL_USB3);\n\tif (!tunnel)\n\t\treturn NULL;\n\n\ttunnel->activate = tb_usb3_activate;\n\ttunnel->src_port = down;\n\ttunnel->dst_port = up;\n\ttunnel->max_up = max_up;\n\ttunnel->max_down = max_down;\n\n\tpath = tb_path_alloc(tb, down, TB_USB3_HOPID, up, TB_USB3_HOPID, 0,\n\t\t\t     \"USB3 Down\");\n\tif (!path) {\n\t\ttb_tunnel_free(tunnel);\n\t\treturn NULL;\n\t}\n\ttb_usb3_init_path(path);\n\ttunnel->paths[TB_USB3_PATH_DOWN] = path;\n\n\tpath = tb_path_alloc(tb, up, TB_USB3_HOPID, down, TB_USB3_HOPID, 0,\n\t\t\t     \"USB3 Up\");\n\tif (!path) {\n\t\ttb_tunnel_free(tunnel);\n\t\treturn NULL;\n\t}\n\ttb_usb3_init_path(path);\n\ttunnel->paths[TB_USB3_PATH_UP] = path;\n\n\tif (!tb_route(down->sw)) {\n\t\ttunnel->allocated_up = max_rate;\n\t\ttunnel->allocated_down = max_rate;\n\n\t\ttunnel->init = tb_usb3_init;\n\t\ttunnel->consumed_bandwidth = tb_usb3_consumed_bandwidth;\n\t\ttunnel->release_unused_bandwidth =\n\t\t\ttb_usb3_release_unused_bandwidth;\n\t\ttunnel->reclaim_available_bandwidth =\n\t\t\ttb_usb3_reclaim_available_bandwidth;\n\t}\n\n\treturn tunnel;\n}\n\n \nvoid tb_tunnel_free(struct tb_tunnel *tunnel)\n{\n\tint i;\n\n\tif (!tunnel)\n\t\treturn;\n\n\tif (tunnel->deinit)\n\t\ttunnel->deinit(tunnel);\n\n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tif (tunnel->paths[i])\n\t\t\ttb_path_free(tunnel->paths[i]);\n\t}\n\n\tkfree(tunnel->paths);\n\tkfree(tunnel);\n}\n\n \nbool tb_tunnel_is_invalid(struct tb_tunnel *tunnel)\n{\n\tint i;\n\n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tWARN_ON(!tunnel->paths[i]->activated);\n\t\tif (tb_path_is_invalid(tunnel->paths[i]))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nint tb_tunnel_restart(struct tb_tunnel *tunnel)\n{\n\tint res, i;\n\n\ttb_tunnel_dbg(tunnel, \"activating\\n\");\n\n\t \n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tif (tunnel->paths[i]->activated) {\n\t\t\ttb_path_deactivate(tunnel->paths[i]);\n\t\t\ttunnel->paths[i]->activated = false;\n\t\t}\n\t}\n\n\tif (tunnel->init) {\n\t\tres = tunnel->init(tunnel);\n\t\tif (res)\n\t\t\treturn res;\n\t}\n\n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tres = tb_path_activate(tunnel->paths[i]);\n\t\tif (res)\n\t\t\tgoto err;\n\t}\n\n\tif (tunnel->activate) {\n\t\tres = tunnel->activate(tunnel, true);\n\t\tif (res)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\ttb_tunnel_warn(tunnel, \"activation failed\\n\");\n\ttb_tunnel_deactivate(tunnel);\n\treturn res;\n}\n\n \nint tb_tunnel_activate(struct tb_tunnel *tunnel)\n{\n\tint i;\n\n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tif (tunnel->paths[i]->activated) {\n\t\t\ttb_tunnel_WARN(tunnel,\n\t\t\t\t       \"trying to activate an already activated tunnel\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn tb_tunnel_restart(tunnel);\n}\n\n \nvoid tb_tunnel_deactivate(struct tb_tunnel *tunnel)\n{\n\tint i;\n\n\ttb_tunnel_dbg(tunnel, \"deactivating\\n\");\n\n\tif (tunnel->activate)\n\t\ttunnel->activate(tunnel, false);\n\n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tif (tunnel->paths[i] && tunnel->paths[i]->activated)\n\t\t\ttb_path_deactivate(tunnel->paths[i]);\n\t}\n}\n\n \nbool tb_tunnel_port_on_path(const struct tb_tunnel *tunnel,\n\t\t\t    const struct tb_port *port)\n{\n\tint i;\n\n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tif (!tunnel->paths[i])\n\t\t\tcontinue;\n\n\t\tif (tb_path_port_on_path(tunnel->paths[i], port))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic bool tb_tunnel_is_active(const struct tb_tunnel *tunnel)\n{\n\tint i;\n\n\tfor (i = 0; i < tunnel->npaths; i++) {\n\t\tif (!tunnel->paths[i])\n\t\t\treturn false;\n\t\tif (!tunnel->paths[i]->activated)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nint tb_tunnel_maximum_bandwidth(struct tb_tunnel *tunnel, int *max_up,\n\t\t\t\tint *max_down)\n{\n\tif (!tb_tunnel_is_active(tunnel))\n\t\treturn -EINVAL;\n\n\tif (tunnel->maximum_bandwidth)\n\t\treturn tunnel->maximum_bandwidth(tunnel, max_up, max_down);\n\treturn -EOPNOTSUPP;\n}\n\n \nint tb_tunnel_allocated_bandwidth(struct tb_tunnel *tunnel, int *allocated_up,\n\t\t\t\t  int *allocated_down)\n{\n\tif (!tb_tunnel_is_active(tunnel))\n\t\treturn -EINVAL;\n\n\tif (tunnel->allocated_bandwidth)\n\t\treturn tunnel->allocated_bandwidth(tunnel, allocated_up,\n\t\t\t\t\t\t   allocated_down);\n\treturn -EOPNOTSUPP;\n}\n\n \nint tb_tunnel_alloc_bandwidth(struct tb_tunnel *tunnel, int *alloc_up,\n\t\t\t      int *alloc_down)\n{\n\tif (!tb_tunnel_is_active(tunnel))\n\t\treturn -EINVAL;\n\n\tif (tunnel->alloc_bandwidth)\n\t\treturn tunnel->alloc_bandwidth(tunnel, alloc_up, alloc_down);\n\n\treturn -EOPNOTSUPP;\n}\n\n \nint tb_tunnel_consumed_bandwidth(struct tb_tunnel *tunnel, int *consumed_up,\n\t\t\t\t int *consumed_down)\n{\n\tint up_bw = 0, down_bw = 0;\n\n\tif (!tb_tunnel_is_active(tunnel))\n\t\tgoto out;\n\n\tif (tunnel->consumed_bandwidth) {\n\t\tint ret;\n\n\t\tret = tunnel->consumed_bandwidth(tunnel, &up_bw, &down_bw);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\ttb_tunnel_dbg(tunnel, \"consumed bandwidth %d/%d Mb/s\\n\", up_bw,\n\t\t\t      down_bw);\n\t}\n\nout:\n\tif (consumed_up)\n\t\t*consumed_up = up_bw;\n\tif (consumed_down)\n\t\t*consumed_down = down_bw;\n\n\treturn 0;\n}\n\n \nint tb_tunnel_release_unused_bandwidth(struct tb_tunnel *tunnel)\n{\n\tif (!tb_tunnel_is_active(tunnel))\n\t\treturn 0;\n\n\tif (tunnel->release_unused_bandwidth) {\n\t\tint ret;\n\n\t\tret = tunnel->release_unused_bandwidth(tunnel);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nvoid tb_tunnel_reclaim_available_bandwidth(struct tb_tunnel *tunnel,\n\t\t\t\t\t   int *available_up,\n\t\t\t\t\t   int *available_down)\n{\n\tif (!tb_tunnel_is_active(tunnel))\n\t\treturn;\n\n\tif (tunnel->reclaim_available_bandwidth)\n\t\ttunnel->reclaim_available_bandwidth(tunnel, available_up,\n\t\t\t\t\t\t    available_down);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}