{
  "module_name": "domain.c",
  "hash_id": "e40c8beb0e201a39406851e77cd7cb47ee67f51cbbdd5e63f9804cd1e8d61cd1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/thunderbolt/domain.c",
  "human_readable_source": "\n \n\n#include <linux/device.h>\n#include <linux/idr.h>\n#include <linux/module.h>\n#include <linux/pm_runtime.h>\n#include <linux/slab.h>\n#include <linux/random.h>\n#include <crypto/hash.h>\n\n#include \"tb.h\"\n\nstatic DEFINE_IDA(tb_domain_ida);\n\nstatic bool match_service_id(const struct tb_service_id *id,\n\t\t\t     const struct tb_service *svc)\n{\n\tif (id->match_flags & TBSVC_MATCH_PROTOCOL_KEY) {\n\t\tif (strcmp(id->protocol_key, svc->key))\n\t\t\treturn false;\n\t}\n\n\tif (id->match_flags & TBSVC_MATCH_PROTOCOL_ID) {\n\t\tif (id->protocol_id != svc->prtcid)\n\t\t\treturn false;\n\t}\n\n\tif (id->match_flags & TBSVC_MATCH_PROTOCOL_VERSION) {\n\t\tif (id->protocol_version != svc->prtcvers)\n\t\t\treturn false;\n\t}\n\n\tif (id->match_flags & TBSVC_MATCH_PROTOCOL_VERSION) {\n\t\tif (id->protocol_revision != svc->prtcrevs)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic const struct tb_service_id *__tb_service_match(struct device *dev,\n\t\t\t\t\t\t      struct device_driver *drv)\n{\n\tstruct tb_service_driver *driver;\n\tconst struct tb_service_id *ids;\n\tstruct tb_service *svc;\n\n\tsvc = tb_to_service(dev);\n\tif (!svc)\n\t\treturn NULL;\n\n\tdriver = container_of(drv, struct tb_service_driver, driver);\n\tif (!driver->id_table)\n\t\treturn NULL;\n\n\tfor (ids = driver->id_table; ids->match_flags != 0; ids++) {\n\t\tif (match_service_id(ids, svc))\n\t\t\treturn ids;\n\t}\n\n\treturn NULL;\n}\n\nstatic int tb_service_match(struct device *dev, struct device_driver *drv)\n{\n\treturn !!__tb_service_match(dev, drv);\n}\n\nstatic int tb_service_probe(struct device *dev)\n{\n\tstruct tb_service *svc = tb_to_service(dev);\n\tstruct tb_service_driver *driver;\n\tconst struct tb_service_id *id;\n\n\tdriver = container_of(dev->driver, struct tb_service_driver, driver);\n\tid = __tb_service_match(dev, &driver->driver);\n\n\treturn driver->probe(svc, id);\n}\n\nstatic void tb_service_remove(struct device *dev)\n{\n\tstruct tb_service *svc = tb_to_service(dev);\n\tstruct tb_service_driver *driver;\n\n\tdriver = container_of(dev->driver, struct tb_service_driver, driver);\n\tif (driver->remove)\n\t\tdriver->remove(svc);\n}\n\nstatic void tb_service_shutdown(struct device *dev)\n{\n\tstruct tb_service_driver *driver;\n\tstruct tb_service *svc;\n\n\tsvc = tb_to_service(dev);\n\tif (!svc || !dev->driver)\n\t\treturn;\n\n\tdriver = container_of(dev->driver, struct tb_service_driver, driver);\n\tif (driver->shutdown)\n\t\tdriver->shutdown(svc);\n}\n\nstatic const char * const tb_security_names[] = {\n\t[TB_SECURITY_NONE] = \"none\",\n\t[TB_SECURITY_USER] = \"user\",\n\t[TB_SECURITY_SECURE] = \"secure\",\n\t[TB_SECURITY_DPONLY] = \"dponly\",\n\t[TB_SECURITY_USBONLY] = \"usbonly\",\n\t[TB_SECURITY_NOPCIE] = \"nopcie\",\n};\n\nstatic ssize_t boot_acl_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb *tb = container_of(dev, struct tb, dev);\n\tuuid_t *uuids;\n\tssize_t ret;\n\tint i;\n\n\tuuids = kcalloc(tb->nboot_acl, sizeof(uuid_t), GFP_KERNEL);\n\tif (!uuids)\n\t\treturn -ENOMEM;\n\n\tpm_runtime_get_sync(&tb->dev);\n\n\tif (mutex_lock_interruptible(&tb->lock)) {\n\t\tret = -ERESTARTSYS;\n\t\tgoto out;\n\t}\n\tret = tb->cm_ops->get_boot_acl(tb, uuids, tb->nboot_acl);\n\tif (ret) {\n\t\tmutex_unlock(&tb->lock);\n\t\tgoto out;\n\t}\n\tmutex_unlock(&tb->lock);\n\n\tfor (ret = 0, i = 0; i < tb->nboot_acl; i++) {\n\t\tif (!uuid_is_null(&uuids[i]))\n\t\t\tret += sysfs_emit_at(buf, ret, \"%pUb\", &uuids[i]);\n\n\t\tret += sysfs_emit_at(buf, ret, \"%s\", i < tb->nboot_acl - 1 ? \",\" : \"\\n\");\n\t}\n\nout:\n\tpm_runtime_mark_last_busy(&tb->dev);\n\tpm_runtime_put_autosuspend(&tb->dev);\n\tkfree(uuids);\n\n\treturn ret;\n}\n\nstatic ssize_t boot_acl_store(struct device *dev, struct device_attribute *attr,\n\t\t\t      const char *buf, size_t count)\n{\n\tstruct tb *tb = container_of(dev, struct tb, dev);\n\tchar *str, *s, *uuid_str;\n\tssize_t ret = 0;\n\tuuid_t *acl;\n\tint i = 0;\n\n\t \n\tif (count > (UUID_STRING_LEN + 1) * tb->nboot_acl + 1)\n\t\treturn -EINVAL;\n\tif (count < tb->nboot_acl - 1)\n\t\treturn -EINVAL;\n\n\tstr = kstrdup(buf, GFP_KERNEL);\n\tif (!str)\n\t\treturn -ENOMEM;\n\n\tacl = kcalloc(tb->nboot_acl, sizeof(uuid_t), GFP_KERNEL);\n\tif (!acl) {\n\t\tret = -ENOMEM;\n\t\tgoto err_free_str;\n\t}\n\n\tuuid_str = strim(str);\n\twhile ((s = strsep(&uuid_str, \",\")) != NULL && i < tb->nboot_acl) {\n\t\tsize_t len = strlen(s);\n\n\t\tif (len) {\n\t\t\tif (len != UUID_STRING_LEN) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto err_free_acl;\n\t\t\t}\n\t\t\tret = uuid_parse(s, &acl[i]);\n\t\t\tif (ret)\n\t\t\t\tgoto err_free_acl;\n\t\t}\n\n\t\ti++;\n\t}\n\n\tif (s || i < tb->nboot_acl) {\n\t\tret = -EINVAL;\n\t\tgoto err_free_acl;\n\t}\n\n\tpm_runtime_get_sync(&tb->dev);\n\n\tif (mutex_lock_interruptible(&tb->lock)) {\n\t\tret = -ERESTARTSYS;\n\t\tgoto err_rpm_put;\n\t}\n\tret = tb->cm_ops->set_boot_acl(tb, acl, tb->nboot_acl);\n\tif (!ret) {\n\t\t \n\t\tkobject_uevent(&tb->dev.kobj, KOBJ_CHANGE);\n\t}\n\tmutex_unlock(&tb->lock);\n\nerr_rpm_put:\n\tpm_runtime_mark_last_busy(&tb->dev);\n\tpm_runtime_put_autosuspend(&tb->dev);\nerr_free_acl:\n\tkfree(acl);\nerr_free_str:\n\tkfree(str);\n\n\treturn ret ?: count;\n}\nstatic DEVICE_ATTR_RW(boot_acl);\n\nstatic ssize_t deauthorization_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    char *buf)\n{\n\tconst struct tb *tb = container_of(dev, struct tb, dev);\n\tbool deauthorization = false;\n\n\t \n\tif (tb->security_level == TB_SECURITY_USER ||\n\t    tb->security_level == TB_SECURITY_SECURE)\n\t\tdeauthorization = !!tb->cm_ops->disapprove_switch;\n\n\treturn sysfs_emit(buf, \"%d\\n\", deauthorization);\n}\nstatic DEVICE_ATTR_RO(deauthorization);\n\nstatic ssize_t iommu_dma_protection_show(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tstruct tb *tb = container_of(dev, struct tb, dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\", tb->nhi->iommu_dma_protection);\n}\nstatic DEVICE_ATTR_RO(iommu_dma_protection);\n\nstatic ssize_t security_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct tb *tb = container_of(dev, struct tb, dev);\n\tconst char *name = \"unknown\";\n\n\tif (tb->security_level < ARRAY_SIZE(tb_security_names))\n\t\tname = tb_security_names[tb->security_level];\n\n\treturn sysfs_emit(buf, \"%s\\n\", name);\n}\nstatic DEVICE_ATTR_RO(security);\n\nstatic struct attribute *domain_attrs[] = {\n\t&dev_attr_boot_acl.attr,\n\t&dev_attr_deauthorization.attr,\n\t&dev_attr_iommu_dma_protection.attr,\n\t&dev_attr_security.attr,\n\tNULL,\n};\n\nstatic umode_t domain_attr_is_visible(struct kobject *kobj,\n\t\t\t\t      struct attribute *attr, int n)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct tb *tb = container_of(dev, struct tb, dev);\n\n\tif (attr == &dev_attr_boot_acl.attr) {\n\t\tif (tb->nboot_acl &&\n\t\t    tb->cm_ops->get_boot_acl &&\n\t\t    tb->cm_ops->set_boot_acl)\n\t\t\treturn attr->mode;\n\t\treturn 0;\n\t}\n\n\treturn attr->mode;\n}\n\nstatic const struct attribute_group domain_attr_group = {\n\t.is_visible = domain_attr_is_visible,\n\t.attrs = domain_attrs,\n};\n\nstatic const struct attribute_group *domain_attr_groups[] = {\n\t&domain_attr_group,\n\tNULL,\n};\n\nstruct bus_type tb_bus_type = {\n\t.name = \"thunderbolt\",\n\t.match = tb_service_match,\n\t.probe = tb_service_probe,\n\t.remove = tb_service_remove,\n\t.shutdown = tb_service_shutdown,\n};\n\nstatic void tb_domain_release(struct device *dev)\n{\n\tstruct tb *tb = container_of(dev, struct tb, dev);\n\n\ttb_ctl_free(tb->ctl);\n\tdestroy_workqueue(tb->wq);\n\tida_simple_remove(&tb_domain_ida, tb->index);\n\tmutex_destroy(&tb->lock);\n\tkfree(tb);\n}\n\nstruct device_type tb_domain_type = {\n\t.name = \"thunderbolt_domain\",\n\t.release = tb_domain_release,\n};\n\nstatic bool tb_domain_event_cb(void *data, enum tb_cfg_pkg_type type,\n\t\t\t       const void *buf, size_t size)\n{\n\tstruct tb *tb = data;\n\n\tif (!tb->cm_ops->handle_event) {\n\t\ttb_warn(tb, \"domain does not have event handler\\n\");\n\t\treturn true;\n\t}\n\n\tswitch (type) {\n\tcase TB_CFG_PKG_XDOMAIN_REQ:\n\tcase TB_CFG_PKG_XDOMAIN_RESP:\n\t\tif (tb_is_xdomain_enabled())\n\t\t\treturn tb_xdomain_handle_request(tb, type, buf, size);\n\t\tbreak;\n\n\tdefault:\n\t\ttb->cm_ops->handle_event(tb, type, buf, size);\n\t}\n\n\treturn true;\n}\n\n \nstruct tb *tb_domain_alloc(struct tb_nhi *nhi, int timeout_msec, size_t privsize)\n{\n\tstruct tb *tb;\n\n\t \n\tBUILD_BUG_ON(sizeof(struct tb_regs_switch_header) != 5 * 4);\n\tBUILD_BUG_ON(sizeof(struct tb_regs_port_header) != 8 * 4);\n\tBUILD_BUG_ON(sizeof(struct tb_regs_hop) != 2 * 4);\n\n\ttb = kzalloc(sizeof(*tb) + privsize, GFP_KERNEL);\n\tif (!tb)\n\t\treturn NULL;\n\n\ttb->nhi = nhi;\n\tmutex_init(&tb->lock);\n\n\ttb->index = ida_simple_get(&tb_domain_ida, 0, 0, GFP_KERNEL);\n\tif (tb->index < 0)\n\t\tgoto err_free;\n\n\ttb->wq = alloc_ordered_workqueue(\"thunderbolt%d\", 0, tb->index);\n\tif (!tb->wq)\n\t\tgoto err_remove_ida;\n\n\ttb->ctl = tb_ctl_alloc(nhi, timeout_msec, tb_domain_event_cb, tb);\n\tif (!tb->ctl)\n\t\tgoto err_destroy_wq;\n\n\ttb->dev.parent = &nhi->pdev->dev;\n\ttb->dev.bus = &tb_bus_type;\n\ttb->dev.type = &tb_domain_type;\n\ttb->dev.groups = domain_attr_groups;\n\tdev_set_name(&tb->dev, \"domain%d\", tb->index);\n\tdevice_initialize(&tb->dev);\n\n\treturn tb;\n\nerr_destroy_wq:\n\tdestroy_workqueue(tb->wq);\nerr_remove_ida:\n\tida_simple_remove(&tb_domain_ida, tb->index);\nerr_free:\n\tkfree(tb);\n\n\treturn NULL;\n}\n\n \nint tb_domain_add(struct tb *tb)\n{\n\tint ret;\n\n\tif (WARN_ON(!tb->cm_ops))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&tb->lock);\n\t \n\ttb_ctl_start(tb->ctl);\n\n\tif (tb->cm_ops->driver_ready) {\n\t\tret = tb->cm_ops->driver_ready(tb);\n\t\tif (ret)\n\t\t\tgoto err_ctl_stop;\n\t}\n\n\ttb_dbg(tb, \"security level set to %s\\n\",\n\t       tb_security_names[tb->security_level]);\n\n\tret = device_add(&tb->dev);\n\tif (ret)\n\t\tgoto err_ctl_stop;\n\n\t \n\tif (tb->cm_ops->start) {\n\t\tret = tb->cm_ops->start(tb);\n\t\tif (ret)\n\t\t\tgoto err_domain_del;\n\t}\n\n\t \n\tmutex_unlock(&tb->lock);\n\n\tdevice_init_wakeup(&tb->dev, true);\n\n\tpm_runtime_no_callbacks(&tb->dev);\n\tpm_runtime_set_active(&tb->dev);\n\tpm_runtime_enable(&tb->dev);\n\tpm_runtime_set_autosuspend_delay(&tb->dev, TB_AUTOSUSPEND_DELAY);\n\tpm_runtime_mark_last_busy(&tb->dev);\n\tpm_runtime_use_autosuspend(&tb->dev);\n\n\treturn 0;\n\nerr_domain_del:\n\tdevice_del(&tb->dev);\nerr_ctl_stop:\n\ttb_ctl_stop(tb->ctl);\n\tmutex_unlock(&tb->lock);\n\n\treturn ret;\n}\n\n \nvoid tb_domain_remove(struct tb *tb)\n{\n\tmutex_lock(&tb->lock);\n\tif (tb->cm_ops->stop)\n\t\ttb->cm_ops->stop(tb);\n\t \n\ttb_ctl_stop(tb->ctl);\n\tmutex_unlock(&tb->lock);\n\n\tflush_workqueue(tb->wq);\n\tdevice_unregister(&tb->dev);\n}\n\n \nint tb_domain_suspend_noirq(struct tb *tb)\n{\n\tint ret = 0;\n\n\t \n\tmutex_lock(&tb->lock);\n\tif (tb->cm_ops->suspend_noirq)\n\t\tret = tb->cm_ops->suspend_noirq(tb);\n\tif (!ret)\n\t\ttb_ctl_stop(tb->ctl);\n\tmutex_unlock(&tb->lock);\n\n\treturn ret;\n}\n\n \nint tb_domain_resume_noirq(struct tb *tb)\n{\n\tint ret = 0;\n\n\tmutex_lock(&tb->lock);\n\ttb_ctl_start(tb->ctl);\n\tif (tb->cm_ops->resume_noirq)\n\t\tret = tb->cm_ops->resume_noirq(tb);\n\tmutex_unlock(&tb->lock);\n\n\treturn ret;\n}\n\nint tb_domain_suspend(struct tb *tb)\n{\n\treturn tb->cm_ops->suspend ? tb->cm_ops->suspend(tb) : 0;\n}\n\nint tb_domain_freeze_noirq(struct tb *tb)\n{\n\tint ret = 0;\n\n\tmutex_lock(&tb->lock);\n\tif (tb->cm_ops->freeze_noirq)\n\t\tret = tb->cm_ops->freeze_noirq(tb);\n\tif (!ret)\n\t\ttb_ctl_stop(tb->ctl);\n\tmutex_unlock(&tb->lock);\n\n\treturn ret;\n}\n\nint tb_domain_thaw_noirq(struct tb *tb)\n{\n\tint ret = 0;\n\n\tmutex_lock(&tb->lock);\n\ttb_ctl_start(tb->ctl);\n\tif (tb->cm_ops->thaw_noirq)\n\t\tret = tb->cm_ops->thaw_noirq(tb);\n\tmutex_unlock(&tb->lock);\n\n\treturn ret;\n}\n\nvoid tb_domain_complete(struct tb *tb)\n{\n\tif (tb->cm_ops->complete)\n\t\ttb->cm_ops->complete(tb);\n}\n\nint tb_domain_runtime_suspend(struct tb *tb)\n{\n\tif (tb->cm_ops->runtime_suspend) {\n\t\tint ret = tb->cm_ops->runtime_suspend(tb);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\ttb_ctl_stop(tb->ctl);\n\treturn 0;\n}\n\nint tb_domain_runtime_resume(struct tb *tb)\n{\n\ttb_ctl_start(tb->ctl);\n\tif (tb->cm_ops->runtime_resume) {\n\t\tint ret = tb->cm_ops->runtime_resume(tb);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\n \nint tb_domain_disapprove_switch(struct tb *tb, struct tb_switch *sw)\n{\n\tif (!tb->cm_ops->disapprove_switch)\n\t\treturn -EPERM;\n\n\treturn tb->cm_ops->disapprove_switch(tb, sw);\n}\n\n \nint tb_domain_approve_switch(struct tb *tb, struct tb_switch *sw)\n{\n\tstruct tb_switch *parent_sw;\n\n\tif (!tb->cm_ops->approve_switch)\n\t\treturn -EPERM;\n\n\t \n\tparent_sw = tb_to_switch(sw->dev.parent);\n\tif (!parent_sw || !parent_sw->authorized)\n\t\treturn -EINVAL;\n\n\treturn tb->cm_ops->approve_switch(tb, sw);\n}\n\n \nint tb_domain_approve_switch_key(struct tb *tb, struct tb_switch *sw)\n{\n\tstruct tb_switch *parent_sw;\n\tint ret;\n\n\tif (!tb->cm_ops->approve_switch || !tb->cm_ops->add_switch_key)\n\t\treturn -EPERM;\n\n\t \n\tparent_sw = tb_to_switch(sw->dev.parent);\n\tif (!parent_sw || !parent_sw->authorized)\n\t\treturn -EINVAL;\n\n\tret = tb->cm_ops->add_switch_key(tb, sw);\n\tif (ret)\n\t\treturn ret;\n\n\treturn tb->cm_ops->approve_switch(tb, sw);\n}\n\n \nint tb_domain_challenge_switch_key(struct tb *tb, struct tb_switch *sw)\n{\n\tu8 challenge[TB_SWITCH_KEY_SIZE];\n\tu8 response[TB_SWITCH_KEY_SIZE];\n\tu8 hmac[TB_SWITCH_KEY_SIZE];\n\tstruct tb_switch *parent_sw;\n\tstruct crypto_shash *tfm;\n\tstruct shash_desc *shash;\n\tint ret;\n\n\tif (!tb->cm_ops->approve_switch || !tb->cm_ops->challenge_switch_key)\n\t\treturn -EPERM;\n\n\t \n\tparent_sw = tb_to_switch(sw->dev.parent);\n\tif (!parent_sw || !parent_sw->authorized)\n\t\treturn -EINVAL;\n\n\tget_random_bytes(challenge, sizeof(challenge));\n\tret = tb->cm_ops->challenge_switch_key(tb, sw, challenge, response);\n\tif (ret)\n\t\treturn ret;\n\n\ttfm = crypto_alloc_shash(\"hmac(sha256)\", 0, 0);\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tret = crypto_shash_setkey(tfm, sw->key, TB_SWITCH_KEY_SIZE);\n\tif (ret)\n\t\tgoto err_free_tfm;\n\n\tshash = kzalloc(sizeof(*shash) + crypto_shash_descsize(tfm),\n\t\t\tGFP_KERNEL);\n\tif (!shash) {\n\t\tret = -ENOMEM;\n\t\tgoto err_free_tfm;\n\t}\n\n\tshash->tfm = tfm;\n\n\tmemset(hmac, 0, sizeof(hmac));\n\tret = crypto_shash_digest(shash, challenge, sizeof(hmac), hmac);\n\tif (ret)\n\t\tgoto err_free_shash;\n\n\t \n\tif (memcmp(response, hmac, sizeof(hmac))) {\n\t\tret = -EKEYREJECTED;\n\t\tgoto err_free_shash;\n\t}\n\n\tcrypto_free_shash(tfm);\n\tkfree(shash);\n\n\treturn tb->cm_ops->approve_switch(tb, sw);\n\nerr_free_shash:\n\tkfree(shash);\nerr_free_tfm:\n\tcrypto_free_shash(tfm);\n\n\treturn ret;\n}\n\n \nint tb_domain_disconnect_pcie_paths(struct tb *tb)\n{\n\tif (!tb->cm_ops->disconnect_pcie_paths)\n\t\treturn -EPERM;\n\n\treturn tb->cm_ops->disconnect_pcie_paths(tb);\n}\n\n \nint tb_domain_approve_xdomain_paths(struct tb *tb, struct tb_xdomain *xd,\n\t\t\t\t    int transmit_path, int transmit_ring,\n\t\t\t\t    int receive_path, int receive_ring)\n{\n\tif (!tb->cm_ops->approve_xdomain_paths)\n\t\treturn -ENOTSUPP;\n\n\treturn tb->cm_ops->approve_xdomain_paths(tb, xd, transmit_path,\n\t\t\ttransmit_ring, receive_path, receive_ring);\n}\n\n \nint tb_domain_disconnect_xdomain_paths(struct tb *tb, struct tb_xdomain *xd,\n\t\t\t\t       int transmit_path, int transmit_ring,\n\t\t\t\t       int receive_path, int receive_ring)\n{\n\tif (!tb->cm_ops->disconnect_xdomain_paths)\n\t\treturn -ENOTSUPP;\n\n\treturn tb->cm_ops->disconnect_xdomain_paths(tb, xd, transmit_path,\n\t\t\ttransmit_ring, receive_path, receive_ring);\n}\n\nstatic int disconnect_xdomain(struct device *dev, void *data)\n{\n\tstruct tb_xdomain *xd;\n\tstruct tb *tb = data;\n\tint ret = 0;\n\n\txd = tb_to_xdomain(dev);\n\tif (xd && xd->tb == tb)\n\t\tret = tb_xdomain_disable_all_paths(xd);\n\n\treturn ret;\n}\n\n \nint tb_domain_disconnect_all_paths(struct tb *tb)\n{\n\tint ret;\n\n\tret = tb_domain_disconnect_pcie_paths(tb);\n\tif (ret)\n\t\treturn ret;\n\n\treturn bus_for_each_dev(&tb_bus_type, NULL, tb, disconnect_xdomain);\n}\n\nint tb_domain_init(void)\n{\n\tint ret;\n\n\ttb_debugfs_init();\n\ttb_acpi_init();\n\n\tret = tb_xdomain_init();\n\tif (ret)\n\t\tgoto err_acpi;\n\tret = bus_register(&tb_bus_type);\n\tif (ret)\n\t\tgoto err_xdomain;\n\n\treturn 0;\n\nerr_xdomain:\n\ttb_xdomain_exit();\nerr_acpi:\n\ttb_acpi_exit();\n\ttb_debugfs_exit();\n\n\treturn ret;\n}\n\nvoid tb_domain_exit(void)\n{\n\tbus_unregister(&tb_bus_type);\n\tida_destroy(&tb_domain_ida);\n\ttb_nvm_exit();\n\ttb_xdomain_exit();\n\ttb_acpi_exit();\n\ttb_debugfs_exit();\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}