{
  "module_name": "tb.c",
  "hash_id": "2a09491a19466bda2a7670d7bf0a5ba5a29d5335a7d93ba285fd4110f3a79156",
  "original_prompt": "Ingested from linux-6.6.14/drivers/thunderbolt/tb.c",
  "human_readable_source": "\n \n\n#include <linux/slab.h>\n#include <linux/errno.h>\n#include <linux/delay.h>\n#include <linux/pm_runtime.h>\n#include <linux/platform_data/x86/apple.h>\n\n#include \"tb.h\"\n#include \"tb_regs.h\"\n#include \"tunnel.h\"\n\n#define TB_TIMEOUT\t100\t \n#define MAX_GROUPS\t7\t \n\n \nstruct tb_cm {\n\tstruct list_head tunnel_list;\n\tstruct list_head dp_resources;\n\tbool hotplug_active;\n\tstruct delayed_work remove_work;\n\tstruct tb_bandwidth_group groups[MAX_GROUPS];\n};\n\nstatic inline struct tb *tcm_to_tb(struct tb_cm *tcm)\n{\n\treturn ((void *)tcm - sizeof(struct tb));\n}\n\nstruct tb_hotplug_event {\n\tstruct work_struct work;\n\tstruct tb *tb;\n\tu64 route;\n\tu8 port;\n\tbool unplug;\n};\n\nstatic void tb_init_bandwidth_groups(struct tb_cm *tcm)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(tcm->groups); i++) {\n\t\tstruct tb_bandwidth_group *group = &tcm->groups[i];\n\n\t\tgroup->tb = tcm_to_tb(tcm);\n\t\tgroup->index = i + 1;\n\t\tINIT_LIST_HEAD(&group->ports);\n\t}\n}\n\nstatic void tb_bandwidth_group_attach_port(struct tb_bandwidth_group *group,\n\t\t\t\t\t   struct tb_port *in)\n{\n\tif (!group || WARN_ON(in->group))\n\t\treturn;\n\n\tin->group = group;\n\tlist_add_tail(&in->group_list, &group->ports);\n\n\ttb_port_dbg(in, \"attached to bandwidth group %d\\n\", group->index);\n}\n\nstatic struct tb_bandwidth_group *tb_find_free_bandwidth_group(struct tb_cm *tcm)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(tcm->groups); i++) {\n\t\tstruct tb_bandwidth_group *group = &tcm->groups[i];\n\n\t\tif (list_empty(&group->ports))\n\t\t\treturn group;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct tb_bandwidth_group *\ntb_attach_bandwidth_group(struct tb_cm *tcm, struct tb_port *in,\n\t\t\t  struct tb_port *out)\n{\n\tstruct tb_bandwidth_group *group;\n\tstruct tb_tunnel *tunnel;\n\n\t \n\tlist_for_each_entry(tunnel, &tcm->tunnel_list, list) {\n\t\tif (!tb_tunnel_is_dp(tunnel))\n\t\t\tcontinue;\n\n\t\tif (tunnel->src_port->sw == in->sw &&\n\t\t    tunnel->dst_port->sw == out->sw) {\n\t\t\tgroup = tunnel->src_port->group;\n\t\t\tif (group) {\n\t\t\t\ttb_bandwidth_group_attach_port(group, in);\n\t\t\t\treturn group;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tgroup = tb_find_free_bandwidth_group(tcm);\n\tif (group)\n\t\ttb_bandwidth_group_attach_port(group, in);\n\telse\n\t\ttb_port_warn(in, \"no available bandwidth groups\\n\");\n\n\treturn group;\n}\n\nstatic void tb_discover_bandwidth_group(struct tb_cm *tcm, struct tb_port *in,\n\t\t\t\t\tstruct tb_port *out)\n{\n\tif (usb4_dp_port_bandwidth_mode_enabled(in)) {\n\t\tint index, i;\n\n\t\tindex = usb4_dp_port_group_id(in);\n\t\tfor (i = 0; i < ARRAY_SIZE(tcm->groups); i++) {\n\t\t\tif (tcm->groups[i].index == index) {\n\t\t\t\ttb_bandwidth_group_attach_port(&tcm->groups[i], in);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\n\ttb_attach_bandwidth_group(tcm, in, out);\n}\n\nstatic void tb_detach_bandwidth_group(struct tb_port *in)\n{\n\tstruct tb_bandwidth_group *group = in->group;\n\n\tif (group) {\n\t\tin->group = NULL;\n\t\tlist_del_init(&in->group_list);\n\n\t\ttb_port_dbg(in, \"detached from bandwidth group %d\\n\", group->index);\n\t}\n}\n\nstatic void tb_handle_hotplug(struct work_struct *work);\n\nstatic void tb_queue_hotplug(struct tb *tb, u64 route, u8 port, bool unplug)\n{\n\tstruct tb_hotplug_event *ev;\n\n\tev = kmalloc(sizeof(*ev), GFP_KERNEL);\n\tif (!ev)\n\t\treturn;\n\n\tev->tb = tb;\n\tev->route = route;\n\tev->port = port;\n\tev->unplug = unplug;\n\tINIT_WORK(&ev->work, tb_handle_hotplug);\n\tqueue_work(tb->wq, &ev->work);\n}\n\n \n\nstatic void tb_add_dp_resources(struct tb_switch *sw)\n{\n\tstruct tb_cm *tcm = tb_priv(sw->tb);\n\tstruct tb_port *port;\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (!tb_port_is_dpin(port))\n\t\t\tcontinue;\n\n\t\tif (!tb_switch_query_dp_resource(sw, port))\n\t\t\tcontinue;\n\n\t\tlist_add_tail(&port->list, &tcm->dp_resources);\n\t\ttb_port_dbg(port, \"DP IN resource available\\n\");\n\t}\n}\n\nstatic void tb_remove_dp_resources(struct tb_switch *sw)\n{\n\tstruct tb_cm *tcm = tb_priv(sw->tb);\n\tstruct tb_port *port, *tmp;\n\n\t \n\ttb_switch_for_each_port(sw, port) {\n\t\tif (tb_port_has_remote(port))\n\t\t\ttb_remove_dp_resources(port->remote->sw);\n\t}\n\n\tlist_for_each_entry_safe(port, tmp, &tcm->dp_resources, list) {\n\t\tif (port->sw == sw) {\n\t\t\ttb_port_dbg(port, \"DP OUT resource unavailable\\n\");\n\t\t\tlist_del_init(&port->list);\n\t\t}\n\t}\n}\n\nstatic void tb_discover_dp_resource(struct tb *tb, struct tb_port *port)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_port *p;\n\n\tlist_for_each_entry(p, &tcm->dp_resources, list) {\n\t\tif (p == port)\n\t\t\treturn;\n\t}\n\n\ttb_port_dbg(port, \"DP %s resource available discovered\\n\",\n\t\t    tb_port_is_dpin(port) ? \"IN\" : \"OUT\");\n\tlist_add_tail(&port->list, &tcm->dp_resources);\n}\n\nstatic void tb_discover_dp_resources(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel;\n\n\tlist_for_each_entry(tunnel, &tcm->tunnel_list, list) {\n\t\tif (tb_tunnel_is_dp(tunnel))\n\t\t\ttb_discover_dp_resource(tb, tunnel->dst_port);\n\t}\n}\n\n \nstatic int tb_enable_clx(struct tb_switch *sw)\n{\n\tstruct tb_cm *tcm = tb_priv(sw->tb);\n\tunsigned int clx = TB_CL0S | TB_CL1;\n\tconst struct tb_tunnel *tunnel;\n\tint ret;\n\n\t \n\twhile (sw && sw->config.depth > 1)\n\t\tsw = tb_switch_parent(sw);\n\n\tif (!sw)\n\t\treturn 0;\n\n\tif (sw->config.depth != 1)\n\t\treturn 0;\n\n\t \n\tlist_for_each_entry(tunnel, &tcm->tunnel_list, list) {\n\t\tif (tb_tunnel_is_dma(tunnel)) {\n\t\t\tif (tb_tunnel_port_on_path(tunnel, tb_upstream_port(sw)))\n\t\t\t\treturn 0;\n\t\t}\n\t}\n\n\t \n\tret = tb_switch_clx_enable(sw, clx | TB_CL2);\n\tif (ret == -EOPNOTSUPP)\n\t\tret = tb_switch_clx_enable(sw, clx);\n\treturn ret == -EOPNOTSUPP ? 0 : ret;\n}\n\n \nstatic void tb_disable_clx(struct tb_switch *sw)\n{\n\tdo {\n\t\tif (tb_switch_clx_disable(sw) < 0)\n\t\t\ttb_sw_warn(sw, \"failed to disable CL states\\n\");\n\t\tsw = tb_switch_parent(sw);\n\t} while (sw);\n}\n\nstatic int tb_increase_switch_tmu_accuracy(struct device *dev, void *data)\n{\n\tstruct tb_switch *sw;\n\n\tsw = tb_to_switch(dev);\n\tif (!sw)\n\t\treturn 0;\n\n\tif (tb_switch_tmu_is_configured(sw, TB_SWITCH_TMU_MODE_LOWRES)) {\n\t\tenum tb_switch_tmu_mode mode;\n\t\tint ret;\n\n\t\tif (tb_switch_clx_is_enabled(sw, TB_CL1))\n\t\t\tmode = TB_SWITCH_TMU_MODE_HIFI_UNI;\n\t\telse\n\t\t\tmode = TB_SWITCH_TMU_MODE_HIFI_BI;\n\n\t\tret = tb_switch_tmu_configure(sw, mode);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\treturn tb_switch_tmu_enable(sw);\n\t}\n\n\treturn 0;\n}\n\nstatic void tb_increase_tmu_accuracy(struct tb_tunnel *tunnel)\n{\n\tstruct tb_switch *sw;\n\n\tif (!tunnel)\n\t\treturn;\n\n\t \n\tsw = tunnel->tb->root_switch;\n\tdevice_for_each_child(&sw->dev, NULL, tb_increase_switch_tmu_accuracy);\n}\n\nstatic int tb_enable_tmu(struct tb_switch *sw)\n{\n\tint ret;\n\n\t \n\tret = tb_switch_tmu_configure(sw,\n\t\t\tTB_SWITCH_TMU_MODE_MEDRES_ENHANCED_UNI);\n\tif (ret == -EOPNOTSUPP) {\n\t\tif (tb_switch_clx_is_enabled(sw, TB_CL1))\n\t\t\tret = tb_switch_tmu_configure(sw,\n\t\t\t\t\tTB_SWITCH_TMU_MODE_LOWRES);\n\t\telse\n\t\t\tret = tb_switch_tmu_configure(sw,\n\t\t\t\t\tTB_SWITCH_TMU_MODE_HIFI_BI);\n\t}\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (tb_switch_tmu_is_enabled(sw))\n\t\treturn 0;\n\n\tret = tb_switch_tmu_disable(sw);\n\tif (ret)\n\t\treturn ret;\n\n\tret = tb_switch_tmu_post_time(sw);\n\tif (ret)\n\t\treturn ret;\n\n\treturn tb_switch_tmu_enable(sw);\n}\n\nstatic void tb_switch_discover_tunnels(struct tb_switch *sw,\n\t\t\t\t       struct list_head *list,\n\t\t\t\t       bool alloc_hopids)\n{\n\tstruct tb *tb = sw->tb;\n\tstruct tb_port *port;\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tstruct tb_tunnel *tunnel = NULL;\n\n\t\tswitch (port->config.type) {\n\t\tcase TB_TYPE_DP_HDMI_IN:\n\t\t\ttunnel = tb_tunnel_discover_dp(tb, port, alloc_hopids);\n\t\t\ttb_increase_tmu_accuracy(tunnel);\n\t\t\tbreak;\n\n\t\tcase TB_TYPE_PCIE_DOWN:\n\t\t\ttunnel = tb_tunnel_discover_pci(tb, port, alloc_hopids);\n\t\t\tbreak;\n\n\t\tcase TB_TYPE_USB3_DOWN:\n\t\t\ttunnel = tb_tunnel_discover_usb3(tb, port, alloc_hopids);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tif (tunnel)\n\t\t\tlist_add_tail(&tunnel->list, list);\n\t}\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (tb_port_has_remote(port)) {\n\t\t\ttb_switch_discover_tunnels(port->remote->sw, list,\n\t\t\t\t\t\t   alloc_hopids);\n\t\t}\n\t}\n}\n\nstatic void tb_discover_tunnels(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel;\n\n\ttb_switch_discover_tunnels(tb->root_switch, &tcm->tunnel_list, true);\n\n\tlist_for_each_entry(tunnel, &tcm->tunnel_list, list) {\n\t\tif (tb_tunnel_is_pci(tunnel)) {\n\t\t\tstruct tb_switch *parent = tunnel->dst_port->sw;\n\n\t\t\twhile (parent != tunnel->src_port->sw) {\n\t\t\t\tparent->boot = true;\n\t\t\t\tparent = tb_switch_parent(parent);\n\t\t\t}\n\t\t} else if (tb_tunnel_is_dp(tunnel)) {\n\t\t\tstruct tb_port *in = tunnel->src_port;\n\t\t\tstruct tb_port *out = tunnel->dst_port;\n\n\t\t\t \n\t\t\tpm_runtime_get_sync(&in->sw->dev);\n\t\t\tpm_runtime_get_sync(&out->sw->dev);\n\n\t\t\ttb_discover_bandwidth_group(tcm, in, out);\n\t\t}\n\t}\n}\n\nstatic int tb_port_configure_xdomain(struct tb_port *port, struct tb_xdomain *xd)\n{\n\tif (tb_switch_is_usb4(port->sw))\n\t\treturn usb4_port_configure_xdomain(port, xd);\n\treturn tb_lc_configure_xdomain(port);\n}\n\nstatic void tb_port_unconfigure_xdomain(struct tb_port *port)\n{\n\tif (tb_switch_is_usb4(port->sw))\n\t\tusb4_port_unconfigure_xdomain(port);\n\telse\n\t\ttb_lc_unconfigure_xdomain(port);\n\n\ttb_port_enable(port->dual_link_port);\n}\n\nstatic void tb_scan_xdomain(struct tb_port *port)\n{\n\tstruct tb_switch *sw = port->sw;\n\tstruct tb *tb = sw->tb;\n\tstruct tb_xdomain *xd;\n\tu64 route;\n\n\tif (!tb_is_xdomain_enabled())\n\t\treturn;\n\n\troute = tb_downstream_route(port);\n\txd = tb_xdomain_find_by_route(tb, route);\n\tif (xd) {\n\t\ttb_xdomain_put(xd);\n\t\treturn;\n\t}\n\n\txd = tb_xdomain_alloc(tb, &sw->dev, route, tb->root_switch->uuid,\n\t\t\t      NULL);\n\tif (xd) {\n\t\ttb_port_at(route, sw)->xdomain = xd;\n\t\ttb_port_configure_xdomain(port, xd);\n\t\ttb_xdomain_add(xd);\n\t}\n}\n\n \nstatic struct tb_port *tb_find_unused_port(struct tb_switch *sw,\n\t\t\t\t\t   enum tb_port_type type)\n{\n\tstruct tb_port *port;\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (tb_is_upstream_port(port))\n\t\t\tcontinue;\n\t\tif (port->config.type != type)\n\t\t\tcontinue;\n\t\tif (!port->cap_adap)\n\t\t\tcontinue;\n\t\tif (tb_port_is_enabled(port))\n\t\t\tcontinue;\n\t\treturn port;\n\t}\n\treturn NULL;\n}\n\nstatic struct tb_port *tb_find_usb3_down(struct tb_switch *sw,\n\t\t\t\t\t const struct tb_port *port)\n{\n\tstruct tb_port *down;\n\n\tdown = usb4_switch_map_usb3_down(sw, port);\n\tif (down && !tb_usb3_port_is_enabled(down))\n\t\treturn down;\n\treturn NULL;\n}\n\nstatic struct tb_tunnel *tb_find_tunnel(struct tb *tb, enum tb_tunnel_type type,\n\t\t\t\t\tstruct tb_port *src_port,\n\t\t\t\t\tstruct tb_port *dst_port)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel;\n\n\tlist_for_each_entry(tunnel, &tcm->tunnel_list, list) {\n\t\tif (tunnel->type == type &&\n\t\t    ((src_port && src_port == tunnel->src_port) ||\n\t\t     (dst_port && dst_port == tunnel->dst_port))) {\n\t\t\treturn tunnel;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nstatic struct tb_tunnel *tb_find_first_usb3_tunnel(struct tb *tb,\n\t\t\t\t\t\t   struct tb_port *src_port,\n\t\t\t\t\t\t   struct tb_port *dst_port)\n{\n\tstruct tb_port *port, *usb3_down;\n\tstruct tb_switch *sw;\n\n\t \n\tif (dst_port->sw->config.depth > src_port->sw->config.depth)\n\t\tsw = dst_port->sw;\n\telse\n\t\tsw = src_port->sw;\n\n\t \n\tif (sw == tb->root_switch)\n\t\treturn NULL;\n\n\t \n\tport = tb_port_at(tb_route(sw), tb->root_switch);\n\t \n\tusb3_down = usb4_switch_map_usb3_down(tb->root_switch, port);\n\tif (!usb3_down)\n\t\treturn NULL;\n\n\treturn tb_find_tunnel(tb, TB_TUNNEL_USB3, usb3_down, NULL);\n}\n\nstatic int tb_available_bandwidth(struct tb *tb, struct tb_port *src_port,\n\tstruct tb_port *dst_port, int *available_up, int *available_down)\n{\n\tint usb3_consumed_up, usb3_consumed_down, ret;\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_port *port;\n\n\ttb_dbg(tb, \"calculating available bandwidth between %llx:%u <-> %llx:%u\\n\",\n\t       tb_route(src_port->sw), src_port->port, tb_route(dst_port->sw),\n\t       dst_port->port);\n\n\ttunnel = tb_find_first_usb3_tunnel(tb, src_port, dst_port);\n\tif (tunnel && tunnel->src_port != src_port &&\n\t    tunnel->dst_port != dst_port) {\n\t\tret = tb_tunnel_consumed_bandwidth(tunnel, &usb3_consumed_up,\n\t\t\t\t\t\t   &usb3_consumed_down);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\tusb3_consumed_up = 0;\n\t\tusb3_consumed_down = 0;\n\t}\n\n\t \n\t*available_up = *available_down = 120000;\n\n\t \n\ttb_for_each_port_on_path(src_port, dst_port, port) {\n\t\tint link_speed, link_width, up_bw, down_bw;\n\n\t\tif (!tb_port_is_null(port))\n\t\t\tcontinue;\n\n\t\tif (tb_is_upstream_port(port)) {\n\t\t\tlink_speed = port->sw->link_speed;\n\t\t\t \n\t\t\tif (port->sw->link_width == TB_LINK_WIDTH_ASYM_TX) {\n\t\t\t\tup_bw = link_speed * 3 * 1000;\n\t\t\t\tdown_bw = link_speed * 1 * 1000;\n\t\t\t} else if (port->sw->link_width == TB_LINK_WIDTH_ASYM_RX) {\n\t\t\t\tup_bw = link_speed * 1 * 1000;\n\t\t\t\tdown_bw = link_speed * 3 * 1000;\n\t\t\t} else {\n\t\t\t\tup_bw = link_speed * port->sw->link_width * 1000;\n\t\t\t\tdown_bw = up_bw;\n\t\t\t}\n\t\t} else {\n\t\t\tlink_speed = tb_port_get_link_speed(port);\n\t\t\tif (link_speed < 0)\n\t\t\t\treturn link_speed;\n\n\t\t\tlink_width = tb_port_get_link_width(port);\n\t\t\tif (link_width < 0)\n\t\t\t\treturn link_width;\n\n\t\t\tif (link_width == TB_LINK_WIDTH_ASYM_TX) {\n\t\t\t\tup_bw = link_speed * 1 * 1000;\n\t\t\t\tdown_bw = link_speed * 3 * 1000;\n\t\t\t} else if (link_width == TB_LINK_WIDTH_ASYM_RX) {\n\t\t\t\tup_bw = link_speed * 3 * 1000;\n\t\t\t\tdown_bw = link_speed * 1 * 1000;\n\t\t\t} else {\n\t\t\t\tup_bw = link_speed * link_width * 1000;\n\t\t\t\tdown_bw = up_bw;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tup_bw -= up_bw / 10;\n\t\tdown_bw -= down_bw / 10;\n\n\t\ttb_port_dbg(port, \"link total bandwidth %d/%d Mb/s\\n\", up_bw,\n\t\t\t    down_bw);\n\n\t\t \n\t\tlist_for_each_entry(tunnel, &tcm->tunnel_list, list) {\n\t\t\tint dp_consumed_up, dp_consumed_down;\n\n\t\t\tif (tb_tunnel_is_invalid(tunnel))\n\t\t\t\tcontinue;\n\n\t\t\tif (!tb_tunnel_is_dp(tunnel))\n\t\t\t\tcontinue;\n\n\t\t\tif (!tb_tunnel_port_on_path(tunnel, port))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (tunnel->src_port == src_port &&\n\t\t\t    tunnel->dst_port == dst_port)\n\t\t\t\tcontinue;\n\n\t\t\tret = tb_tunnel_consumed_bandwidth(tunnel,\n\t\t\t\t\t\t\t   &dp_consumed_up,\n\t\t\t\t\t\t\t   &dp_consumed_down);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tup_bw -= dp_consumed_up;\n\t\t\tdown_bw -= dp_consumed_down;\n\t\t}\n\n\t\t \n\t\tup_bw -= usb3_consumed_up;\n\t\tdown_bw -= usb3_consumed_down;\n\n\t\tif (up_bw < *available_up)\n\t\t\t*available_up = up_bw;\n\t\tif (down_bw < *available_down)\n\t\t\t*available_down = down_bw;\n\t}\n\n\tif (*available_up < 0)\n\t\t*available_up = 0;\n\tif (*available_down < 0)\n\t\t*available_down = 0;\n\n\treturn 0;\n}\n\nstatic int tb_release_unused_usb3_bandwidth(struct tb *tb,\n\t\t\t\t\t    struct tb_port *src_port,\n\t\t\t\t\t    struct tb_port *dst_port)\n{\n\tstruct tb_tunnel *tunnel;\n\n\ttunnel = tb_find_first_usb3_tunnel(tb, src_port, dst_port);\n\treturn tunnel ? tb_tunnel_release_unused_bandwidth(tunnel) : 0;\n}\n\nstatic void tb_reclaim_usb3_bandwidth(struct tb *tb, struct tb_port *src_port,\n\t\t\t\t      struct tb_port *dst_port)\n{\n\tint ret, available_up, available_down;\n\tstruct tb_tunnel *tunnel;\n\n\ttunnel = tb_find_first_usb3_tunnel(tb, src_port, dst_port);\n\tif (!tunnel)\n\t\treturn;\n\n\ttb_dbg(tb, \"reclaiming unused bandwidth for USB3\\n\");\n\n\t \n\tret = tb_available_bandwidth(tb, tunnel->src_port, tunnel->dst_port,\n\t\t\t\t     &available_up, &available_down);\n\tif (ret) {\n\t\ttb_warn(tb, \"failed to calculate available bandwidth\\n\");\n\t\treturn;\n\t}\n\n\ttb_dbg(tb, \"available bandwidth for USB3 %d/%d Mb/s\\n\",\n\t       available_up, available_down);\n\n\ttb_tunnel_reclaim_available_bandwidth(tunnel, &available_up, &available_down);\n}\n\nstatic int tb_tunnel_usb3(struct tb *tb, struct tb_switch *sw)\n{\n\tstruct tb_switch *parent = tb_switch_parent(sw);\n\tint ret, available_up, available_down;\n\tstruct tb_port *up, *down, *port;\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel;\n\n\tif (!tb_acpi_may_tunnel_usb3()) {\n\t\ttb_dbg(tb, \"USB3 tunneling disabled, not creating tunnel\\n\");\n\t\treturn 0;\n\t}\n\n\tup = tb_switch_find_port(sw, TB_TYPE_USB3_UP);\n\tif (!up)\n\t\treturn 0;\n\n\tif (!sw->link_usb4)\n\t\treturn 0;\n\n\t \n\tport = tb_switch_downstream_port(sw);\n\tdown = tb_find_usb3_down(parent, port);\n\tif (!down)\n\t\treturn 0;\n\n\tif (tb_route(parent)) {\n\t\tstruct tb_port *parent_up;\n\t\t \n\t\tparent_up = tb_switch_find_port(parent, TB_TYPE_USB3_UP);\n\t\tif (!parent_up || !tb_port_is_enabled(parent_up))\n\t\t\treturn 0;\n\n\t\t \n\t\tret = tb_release_unused_usb3_bandwidth(tb, down, up);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = tb_available_bandwidth(tb, down, up, &available_up,\n\t\t\t\t     &available_down);\n\tif (ret)\n\t\tgoto err_reclaim;\n\n\ttb_port_dbg(up, \"available bandwidth for new USB3 tunnel %d/%d Mb/s\\n\",\n\t\t    available_up, available_down);\n\n\ttunnel = tb_tunnel_alloc_usb3(tb, up, down, available_up,\n\t\t\t\t      available_down);\n\tif (!tunnel) {\n\t\tret = -ENOMEM;\n\t\tgoto err_reclaim;\n\t}\n\n\tif (tb_tunnel_activate(tunnel)) {\n\t\ttb_port_info(up,\n\t\t\t     \"USB3 tunnel activation failed, aborting\\n\");\n\t\tret = -EIO;\n\t\tgoto err_free;\n\t}\n\n\tlist_add_tail(&tunnel->list, &tcm->tunnel_list);\n\tif (tb_route(parent))\n\t\ttb_reclaim_usb3_bandwidth(tb, down, up);\n\n\treturn 0;\n\nerr_free:\n\ttb_tunnel_free(tunnel);\nerr_reclaim:\n\tif (tb_route(parent))\n\t\ttb_reclaim_usb3_bandwidth(tb, down, up);\n\n\treturn ret;\n}\n\nstatic int tb_create_usb3_tunnels(struct tb_switch *sw)\n{\n\tstruct tb_port *port;\n\tint ret;\n\n\tif (!tb_acpi_may_tunnel_usb3())\n\t\treturn 0;\n\n\tif (tb_route(sw)) {\n\t\tret = tb_tunnel_usb3(sw->tb, sw);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (!tb_port_has_remote(port))\n\t\t\tcontinue;\n\t\tret = tb_create_usb3_tunnels(port->remote->sw);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void tb_scan_port(struct tb_port *port);\n\n \nstatic void tb_scan_switch(struct tb_switch *sw)\n{\n\tstruct tb_port *port;\n\n\tpm_runtime_get_sync(&sw->dev);\n\n\ttb_switch_for_each_port(sw, port)\n\t\ttb_scan_port(port);\n\n\tpm_runtime_mark_last_busy(&sw->dev);\n\tpm_runtime_put_autosuspend(&sw->dev);\n}\n\n \nstatic void tb_scan_port(struct tb_port *port)\n{\n\tstruct tb_cm *tcm = tb_priv(port->sw->tb);\n\tstruct tb_port *upstream_port;\n\tbool discovery = false;\n\tstruct tb_switch *sw;\n\n\tif (tb_is_upstream_port(port))\n\t\treturn;\n\n\tif (tb_port_is_dpout(port) && tb_dp_port_hpd_is_active(port) == 1 &&\n\t    !tb_dp_port_is_enabled(port)) {\n\t\ttb_port_dbg(port, \"DP adapter HPD set, queuing hotplug\\n\");\n\t\ttb_queue_hotplug(port->sw->tb, tb_route(port->sw), port->port,\n\t\t\t\t false);\n\t\treturn;\n\t}\n\n\tif (port->config.type != TB_TYPE_PORT)\n\t\treturn;\n\tif (port->dual_link_port && port->link_nr)\n\t\treturn;  \n\n\tif (port->usb4)\n\t\tpm_runtime_get_sync(&port->usb4->dev);\n\n\tif (tb_wait_for_port(port, false) <= 0)\n\t\tgoto out_rpm_put;\n\tif (port->remote) {\n\t\ttb_port_dbg(port, \"port already has a remote\\n\");\n\t\tgoto out_rpm_put;\n\t}\n\n\ttb_retimer_scan(port, true);\n\n\tsw = tb_switch_alloc(port->sw->tb, &port->sw->dev,\n\t\t\t     tb_downstream_route(port));\n\tif (IS_ERR(sw)) {\n\t\t \n\t\tif (PTR_ERR(sw) == -EIO || PTR_ERR(sw) == -EADDRNOTAVAIL)\n\t\t\ttb_scan_xdomain(port);\n\t\tgoto out_rpm_put;\n\t}\n\n\tif (tb_switch_configure(sw)) {\n\t\ttb_switch_put(sw);\n\t\tgoto out_rpm_put;\n\t}\n\n\t \n\tif (port->xdomain) {\n\t\ttb_xdomain_remove(port->xdomain);\n\t\ttb_port_unconfigure_xdomain(port);\n\t\tport->xdomain = NULL;\n\t}\n\n\t \n\tif (!tcm->hotplug_active) {\n\t\tdev_set_uevent_suppress(&sw->dev, true);\n\t\tdiscovery = true;\n\t}\n\n\t \n\tsw->rpm = sw->generation > 1;\n\n\tif (tb_switch_add(sw)) {\n\t\ttb_switch_put(sw);\n\t\tgoto out_rpm_put;\n\t}\n\n\t \n\tupstream_port = tb_upstream_port(sw);\n\tport->remote = upstream_port;\n\tupstream_port->remote = port;\n\tif (port->dual_link_port && upstream_port->dual_link_port) {\n\t\tport->dual_link_port->remote = upstream_port->dual_link_port;\n\t\tupstream_port->dual_link_port->remote = port->dual_link_port;\n\t}\n\n\t \n\ttb_switch_lane_bonding_enable(sw);\n\t \n\ttb_switch_configure_link(sw);\n\t \n\tif (discovery)\n\t\ttb_sw_dbg(sw, \"discovery, not touching CL states\\n\");\n\telse if (tb_enable_clx(sw))\n\t\ttb_sw_warn(sw, \"failed to enable CL states\\n\");\n\n\tif (tb_enable_tmu(sw))\n\t\ttb_sw_warn(sw, \"failed to enable TMU\\n\");\n\n\t \n\ttb_switch_configuration_valid(sw);\n\n\t \n\ttb_retimer_scan(upstream_port, true);\n\n\t \n\tif (tcm->hotplug_active && tb_tunnel_usb3(sw->tb, sw))\n\t\ttb_sw_warn(sw, \"USB3 tunnel creation failed\\n\");\n\n\ttb_add_dp_resources(sw);\n\ttb_scan_switch(sw);\n\nout_rpm_put:\n\tif (port->usb4) {\n\t\tpm_runtime_mark_last_busy(&port->usb4->dev);\n\t\tpm_runtime_put_autosuspend(&port->usb4->dev);\n\t}\n}\n\nstatic void tb_deactivate_and_free_tunnel(struct tb_tunnel *tunnel)\n{\n\tstruct tb_port *src_port, *dst_port;\n\tstruct tb *tb;\n\n\tif (!tunnel)\n\t\treturn;\n\n\ttb_tunnel_deactivate(tunnel);\n\tlist_del(&tunnel->list);\n\n\ttb = tunnel->tb;\n\tsrc_port = tunnel->src_port;\n\tdst_port = tunnel->dst_port;\n\n\tswitch (tunnel->type) {\n\tcase TB_TUNNEL_DP:\n\t\ttb_detach_bandwidth_group(src_port);\n\t\t \n\t\ttb_switch_dealloc_dp_resource(src_port->sw, src_port);\n\t\t \n\t\tpm_runtime_mark_last_busy(&dst_port->sw->dev);\n\t\tpm_runtime_put_autosuspend(&dst_port->sw->dev);\n\t\tpm_runtime_mark_last_busy(&src_port->sw->dev);\n\t\tpm_runtime_put_autosuspend(&src_port->sw->dev);\n\t\tfallthrough;\n\n\tcase TB_TUNNEL_USB3:\n\t\ttb_reclaim_usb3_bandwidth(tb, src_port, dst_port);\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n\n\ttb_tunnel_free(tunnel);\n}\n\n \nstatic void tb_free_invalid_tunnels(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_tunnel *n;\n\n\tlist_for_each_entry_safe(tunnel, n, &tcm->tunnel_list, list) {\n\t\tif (tb_tunnel_is_invalid(tunnel))\n\t\t\ttb_deactivate_and_free_tunnel(tunnel);\n\t}\n}\n\n \nstatic void tb_free_unplugged_children(struct tb_switch *sw)\n{\n\tstruct tb_port *port;\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (!tb_port_has_remote(port))\n\t\t\tcontinue;\n\n\t\tif (port->remote->sw->is_unplugged) {\n\t\t\ttb_retimer_remove_all(port);\n\t\t\ttb_remove_dp_resources(port->remote->sw);\n\t\t\ttb_switch_unconfigure_link(port->remote->sw);\n\t\t\ttb_switch_lane_bonding_disable(port->remote->sw);\n\t\t\ttb_switch_remove(port->remote->sw);\n\t\t\tport->remote = NULL;\n\t\t\tif (port->dual_link_port)\n\t\t\t\tport->dual_link_port->remote = NULL;\n\t\t} else {\n\t\t\ttb_free_unplugged_children(port->remote->sw);\n\t\t}\n\t}\n}\n\nstatic struct tb_port *tb_find_pcie_down(struct tb_switch *sw,\n\t\t\t\t\t const struct tb_port *port)\n{\n\tstruct tb_port *down = NULL;\n\n\t \n\tif (tb_switch_is_usb4(sw)) {\n\t\tdown = usb4_switch_map_pcie_down(sw, port);\n\t} else if (!tb_route(sw)) {\n\t\tint phy_port = tb_phy_port_from_link(port->port);\n\t\tint index;\n\n\t\t \n\t\tif (tb_switch_is_cactus_ridge(sw) ||\n\t\t    tb_switch_is_alpine_ridge(sw))\n\t\t\tindex = !phy_port ? 6 : 7;\n\t\telse if (tb_switch_is_falcon_ridge(sw))\n\t\t\tindex = !phy_port ? 6 : 8;\n\t\telse if (tb_switch_is_titan_ridge(sw))\n\t\t\tindex = !phy_port ? 8 : 9;\n\t\telse\n\t\t\tgoto out;\n\n\t\t \n\t\tif (WARN_ON(index > sw->config.max_port_number))\n\t\t\tgoto out;\n\n\t\tdown = &sw->ports[index];\n\t}\n\n\tif (down) {\n\t\tif (WARN_ON(!tb_port_is_pcie_down(down)))\n\t\t\tgoto out;\n\t\tif (tb_pci_port_is_enabled(down))\n\t\t\tgoto out;\n\n\t\treturn down;\n\t}\n\nout:\n\treturn tb_find_unused_port(sw, TB_TYPE_PCIE_DOWN);\n}\n\nstatic void\ntb_recalc_estimated_bandwidth_for_group(struct tb_bandwidth_group *group)\n{\n\tstruct tb_tunnel *first_tunnel;\n\tstruct tb *tb = group->tb;\n\tstruct tb_port *in;\n\tint ret;\n\n\ttb_dbg(tb, \"re-calculating bandwidth estimation for group %u\\n\",\n\t       group->index);\n\n\tfirst_tunnel = NULL;\n\tlist_for_each_entry(in, &group->ports, group_list) {\n\t\tint estimated_bw, estimated_up, estimated_down;\n\t\tstruct tb_tunnel *tunnel;\n\t\tstruct tb_port *out;\n\n\t\tif (!usb4_dp_port_bandwidth_mode_enabled(in))\n\t\t\tcontinue;\n\n\t\ttunnel = tb_find_tunnel(tb, TB_TUNNEL_DP, in, NULL);\n\t\tif (WARN_ON(!tunnel))\n\t\t\tbreak;\n\n\t\tif (!first_tunnel) {\n\t\t\t \n\t\t\tfirst_tunnel = tunnel;\n\t\t\tret = tb_release_unused_usb3_bandwidth(tb,\n\t\t\t\tfirst_tunnel->src_port, first_tunnel->dst_port);\n\t\t\tif (ret) {\n\t\t\t\ttb_port_warn(in,\n\t\t\t\t\t\"failed to release unused bandwidth\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tout = tunnel->dst_port;\n\t\tret = tb_available_bandwidth(tb, in, out, &estimated_up,\n\t\t\t\t\t     &estimated_down);\n\t\tif (ret) {\n\t\t\ttb_port_warn(in,\n\t\t\t\t\"failed to re-calculate estimated bandwidth\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\ttb_port_dbg(in, \"re-calculated estimated bandwidth %u/%u Mb/s\\n\",\n\t\t\t    estimated_up, estimated_down);\n\n\t\tif (in->sw->config.depth < out->sw->config.depth)\n\t\t\testimated_bw = estimated_down;\n\t\telse\n\t\t\testimated_bw = estimated_up;\n\n\t\tif (usb4_dp_port_set_estimated_bandwidth(in, estimated_bw))\n\t\t\ttb_port_warn(in, \"failed to update estimated bandwidth\\n\");\n\t}\n\n\tif (first_tunnel)\n\t\ttb_reclaim_usb3_bandwidth(tb, first_tunnel->src_port,\n\t\t\t\t\t  first_tunnel->dst_port);\n\n\ttb_dbg(tb, \"bandwidth estimation for group %u done\\n\", group->index);\n}\n\nstatic void tb_recalc_estimated_bandwidth(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tint i;\n\n\ttb_dbg(tb, \"bandwidth consumption changed, re-calculating estimated bandwidth\\n\");\n\n\tfor (i = 0; i < ARRAY_SIZE(tcm->groups); i++) {\n\t\tstruct tb_bandwidth_group *group = &tcm->groups[i];\n\n\t\tif (!list_empty(&group->ports))\n\t\t\ttb_recalc_estimated_bandwidth_for_group(group);\n\t}\n\n\ttb_dbg(tb, \"bandwidth re-calculation done\\n\");\n}\n\nstatic struct tb_port *tb_find_dp_out(struct tb *tb, struct tb_port *in)\n{\n\tstruct tb_port *host_port, *port;\n\tstruct tb_cm *tcm = tb_priv(tb);\n\n\thost_port = tb_route(in->sw) ?\n\t\ttb_port_at(tb_route(in->sw), tb->root_switch) : NULL;\n\n\tlist_for_each_entry(port, &tcm->dp_resources, list) {\n\t\tif (!tb_port_is_dpout(port))\n\t\t\tcontinue;\n\n\t\tif (tb_port_is_enabled(port)) {\n\t\t\ttb_port_dbg(port, \"DP OUT in use\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\ttb_port_dbg(port, \"DP OUT available\\n\");\n\n\t\t \n\t\tif (host_port && tb_route(port->sw)) {\n\t\t\tstruct tb_port *p;\n\n\t\t\tp = tb_port_at(tb_route(port->sw), tb->root_switch);\n\t\t\tif (p != host_port)\n\t\t\t\tcontinue;\n\t\t}\n\n\t\treturn port;\n\t}\n\n\treturn NULL;\n}\n\nstatic void tb_tunnel_dp(struct tb *tb)\n{\n\tint available_up, available_down, ret, link_nr;\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_port *port, *in, *out;\n\tstruct tb_tunnel *tunnel;\n\n\tif (!tb_acpi_may_tunnel_dp()) {\n\t\ttb_dbg(tb, \"DP tunneling disabled, not creating tunnel\\n\");\n\t\treturn;\n\t}\n\n\t \n\ttb_dbg(tb, \"looking for DP IN <-> DP OUT pairs:\\n\");\n\n\tin = NULL;\n\tout = NULL;\n\tlist_for_each_entry(port, &tcm->dp_resources, list) {\n\t\tif (!tb_port_is_dpin(port))\n\t\t\tcontinue;\n\n\t\tif (tb_port_is_enabled(port)) {\n\t\t\ttb_port_dbg(port, \"DP IN in use\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\ttb_port_dbg(port, \"DP IN available\\n\");\n\n\t\tout = tb_find_dp_out(tb, port);\n\t\tif (out) {\n\t\t\tin = port;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!in) {\n\t\ttb_dbg(tb, \"no suitable DP IN adapter available, not tunneling\\n\");\n\t\treturn;\n\t}\n\tif (!out) {\n\t\ttb_dbg(tb, \"no suitable DP OUT adapter available, not tunneling\\n\");\n\t\treturn;\n\t}\n\n\t \n\tlink_nr = 1;\n\tlist_for_each_entry(tunnel, &tcm->tunnel_list, list) {\n\t\tif (tb_tunnel_is_dp(tunnel)) {\n\t\t\tlink_nr = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tpm_runtime_get_sync(&in->sw->dev);\n\tpm_runtime_get_sync(&out->sw->dev);\n\n\tif (tb_switch_alloc_dp_resource(in->sw, in)) {\n\t\ttb_port_dbg(in, \"no resource available for DP IN, not tunneling\\n\");\n\t\tgoto err_rpm_put;\n\t}\n\n\tif (!tb_attach_bandwidth_group(tcm, in, out))\n\t\tgoto err_dealloc_dp;\n\n\t \n\tret = tb_release_unused_usb3_bandwidth(tb, in, out);\n\tif (ret) {\n\t\ttb_warn(tb, \"failed to release unused bandwidth\\n\");\n\t\tgoto err_detach_group;\n\t}\n\n\tret = tb_available_bandwidth(tb, in, out, &available_up, &available_down);\n\tif (ret)\n\t\tgoto err_reclaim_usb;\n\n\ttb_dbg(tb, \"available bandwidth for new DP tunnel %u/%u Mb/s\\n\",\n\t       available_up, available_down);\n\n\ttunnel = tb_tunnel_alloc_dp(tb, in, out, link_nr, available_up,\n\t\t\t\t    available_down);\n\tif (!tunnel) {\n\t\ttb_port_dbg(out, \"could not allocate DP tunnel\\n\");\n\t\tgoto err_reclaim_usb;\n\t}\n\n\tif (tb_tunnel_activate(tunnel)) {\n\t\ttb_port_info(out, \"DP tunnel activation failed, aborting\\n\");\n\t\tgoto err_free;\n\t}\n\n\tlist_add_tail(&tunnel->list, &tcm->tunnel_list);\n\ttb_reclaim_usb3_bandwidth(tb, in, out);\n\n\t \n\ttb_recalc_estimated_bandwidth(tb);\n\n\t \n\ttb_increase_tmu_accuracy(tunnel);\n\treturn;\n\nerr_free:\n\ttb_tunnel_free(tunnel);\nerr_reclaim_usb:\n\ttb_reclaim_usb3_bandwidth(tb, in, out);\nerr_detach_group:\n\ttb_detach_bandwidth_group(in);\nerr_dealloc_dp:\n\ttb_switch_dealloc_dp_resource(in->sw, in);\nerr_rpm_put:\n\tpm_runtime_mark_last_busy(&out->sw->dev);\n\tpm_runtime_put_autosuspend(&out->sw->dev);\n\tpm_runtime_mark_last_busy(&in->sw->dev);\n\tpm_runtime_put_autosuspend(&in->sw->dev);\n}\n\nstatic void tb_dp_resource_unavailable(struct tb *tb, struct tb_port *port)\n{\n\tstruct tb_port *in, *out;\n\tstruct tb_tunnel *tunnel;\n\n\tif (tb_port_is_dpin(port)) {\n\t\ttb_port_dbg(port, \"DP IN resource unavailable\\n\");\n\t\tin = port;\n\t\tout = NULL;\n\t} else {\n\t\ttb_port_dbg(port, \"DP OUT resource unavailable\\n\");\n\t\tin = NULL;\n\t\tout = port;\n\t}\n\n\ttunnel = tb_find_tunnel(tb, TB_TUNNEL_DP, in, out);\n\ttb_deactivate_and_free_tunnel(tunnel);\n\tlist_del_init(&port->list);\n\n\t \n\ttb_recalc_estimated_bandwidth(tb);\n\ttb_tunnel_dp(tb);\n}\n\nstatic void tb_dp_resource_available(struct tb *tb, struct tb_port *port)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_port *p;\n\n\tif (tb_port_is_enabled(port))\n\t\treturn;\n\n\tlist_for_each_entry(p, &tcm->dp_resources, list) {\n\t\tif (p == port)\n\t\t\treturn;\n\t}\n\n\ttb_port_dbg(port, \"DP %s resource available\\n\",\n\t\t    tb_port_is_dpin(port) ? \"IN\" : \"OUT\");\n\tlist_add_tail(&port->list, &tcm->dp_resources);\n\n\t \n\ttb_tunnel_dp(tb);\n}\n\nstatic void tb_disconnect_and_release_dp(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel, *n;\n\n\t \n\tlist_for_each_entry_safe_reverse(tunnel, n, &tcm->tunnel_list, list) {\n\t\tif (tb_tunnel_is_dp(tunnel))\n\t\t\ttb_deactivate_and_free_tunnel(tunnel);\n\t}\n\n\twhile (!list_empty(&tcm->dp_resources)) {\n\t\tstruct tb_port *port;\n\n\t\tport = list_first_entry(&tcm->dp_resources,\n\t\t\t\t\tstruct tb_port, list);\n\t\tlist_del_init(&port->list);\n\t}\n}\n\nstatic int tb_disconnect_pci(struct tb *tb, struct tb_switch *sw)\n{\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_port *up;\n\n\tup = tb_switch_find_port(sw, TB_TYPE_PCIE_UP);\n\tif (WARN_ON(!up))\n\t\treturn -ENODEV;\n\n\ttunnel = tb_find_tunnel(tb, TB_TUNNEL_PCI, NULL, up);\n\tif (WARN_ON(!tunnel))\n\t\treturn -ENODEV;\n\n\ttb_switch_xhci_disconnect(sw);\n\n\ttb_tunnel_deactivate(tunnel);\n\tlist_del(&tunnel->list);\n\ttb_tunnel_free(tunnel);\n\treturn 0;\n}\n\nstatic int tb_tunnel_pci(struct tb *tb, struct tb_switch *sw)\n{\n\tstruct tb_port *up, *down, *port;\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel;\n\n\tup = tb_switch_find_port(sw, TB_TYPE_PCIE_UP);\n\tif (!up)\n\t\treturn 0;\n\n\t \n\tport = tb_switch_downstream_port(sw);\n\tdown = tb_find_pcie_down(tb_switch_parent(sw), port);\n\tif (!down)\n\t\treturn 0;\n\n\ttunnel = tb_tunnel_alloc_pci(tb, up, down);\n\tif (!tunnel)\n\t\treturn -ENOMEM;\n\n\tif (tb_tunnel_activate(tunnel)) {\n\t\ttb_port_info(up,\n\t\t\t     \"PCIe tunnel activation failed, aborting\\n\");\n\t\ttb_tunnel_free(tunnel);\n\t\treturn -EIO;\n\t}\n\n\t \n\tif (tb_switch_pcie_l1_enable(sw))\n\t\ttb_sw_warn(sw, \"failed to enable PCIe L1 for Titan Ridge\\n\");\n\n\tif (tb_switch_xhci_connect(sw))\n\t\ttb_sw_warn(sw, \"failed to connect xHCI\\n\");\n\n\tlist_add_tail(&tunnel->list, &tcm->tunnel_list);\n\treturn 0;\n}\n\nstatic int tb_approve_xdomain_paths(struct tb *tb, struct tb_xdomain *xd,\n\t\t\t\t    int transmit_path, int transmit_ring,\n\t\t\t\t    int receive_path, int receive_ring)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_port *nhi_port, *dst_port;\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_switch *sw;\n\tint ret;\n\n\tsw = tb_to_switch(xd->dev.parent);\n\tdst_port = tb_port_at(xd->route, sw);\n\tnhi_port = tb_switch_find_port(tb->root_switch, TB_TYPE_NHI);\n\n\tmutex_lock(&tb->lock);\n\n\t \n\ttb_disable_clx(sw);\n\n\ttunnel = tb_tunnel_alloc_dma(tb, nhi_port, dst_port, transmit_path,\n\t\t\t\t     transmit_ring, receive_path, receive_ring);\n\tif (!tunnel) {\n\t\tret = -ENOMEM;\n\t\tgoto err_clx;\n\t}\n\n\tif (tb_tunnel_activate(tunnel)) {\n\t\ttb_port_info(nhi_port,\n\t\t\t     \"DMA tunnel activation failed, aborting\\n\");\n\t\tret = -EIO;\n\t\tgoto err_free;\n\t}\n\n\tlist_add_tail(&tunnel->list, &tcm->tunnel_list);\n\tmutex_unlock(&tb->lock);\n\treturn 0;\n\nerr_free:\n\ttb_tunnel_free(tunnel);\nerr_clx:\n\ttb_enable_clx(sw);\n\tmutex_unlock(&tb->lock);\n\n\treturn ret;\n}\n\nstatic void __tb_disconnect_xdomain_paths(struct tb *tb, struct tb_xdomain *xd,\n\t\t\t\t\t  int transmit_path, int transmit_ring,\n\t\t\t\t\t  int receive_path, int receive_ring)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_port *nhi_port, *dst_port;\n\tstruct tb_tunnel *tunnel, *n;\n\tstruct tb_switch *sw;\n\n\tsw = tb_to_switch(xd->dev.parent);\n\tdst_port = tb_port_at(xd->route, sw);\n\tnhi_port = tb_switch_find_port(tb->root_switch, TB_TYPE_NHI);\n\n\tlist_for_each_entry_safe(tunnel, n, &tcm->tunnel_list, list) {\n\t\tif (!tb_tunnel_is_dma(tunnel))\n\t\t\tcontinue;\n\t\tif (tunnel->src_port != nhi_port || tunnel->dst_port != dst_port)\n\t\t\tcontinue;\n\n\t\tif (tb_tunnel_match_dma(tunnel, transmit_path, transmit_ring,\n\t\t\t\t\treceive_path, receive_ring))\n\t\t\ttb_deactivate_and_free_tunnel(tunnel);\n\t}\n\n\t \n\ttb_enable_clx(sw);\n}\n\nstatic int tb_disconnect_xdomain_paths(struct tb *tb, struct tb_xdomain *xd,\n\t\t\t\t       int transmit_path, int transmit_ring,\n\t\t\t\t       int receive_path, int receive_ring)\n{\n\tif (!xd->is_unplugged) {\n\t\tmutex_lock(&tb->lock);\n\t\t__tb_disconnect_xdomain_paths(tb, xd, transmit_path,\n\t\t\t\t\t      transmit_ring, receive_path,\n\t\t\t\t\t      receive_ring);\n\t\tmutex_unlock(&tb->lock);\n\t}\n\treturn 0;\n}\n\n \n\n \nstatic void tb_handle_hotplug(struct work_struct *work)\n{\n\tstruct tb_hotplug_event *ev = container_of(work, typeof(*ev), work);\n\tstruct tb *tb = ev->tb;\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_switch *sw;\n\tstruct tb_port *port;\n\n\t \n\tpm_runtime_get_sync(&tb->dev);\n\n\tmutex_lock(&tb->lock);\n\tif (!tcm->hotplug_active)\n\t\tgoto out;  \n\n\tsw = tb_switch_find_by_route(tb, ev->route);\n\tif (!sw) {\n\t\ttb_warn(tb,\n\t\t\t\"hotplug event from non existent switch %llx:%x (unplug: %d)\\n\",\n\t\t\tev->route, ev->port, ev->unplug);\n\t\tgoto out;\n\t}\n\tif (ev->port > sw->config.max_port_number) {\n\t\ttb_warn(tb,\n\t\t\t\"hotplug event from non existent port %llx:%x (unplug: %d)\\n\",\n\t\t\tev->route, ev->port, ev->unplug);\n\t\tgoto put_sw;\n\t}\n\tport = &sw->ports[ev->port];\n\tif (tb_is_upstream_port(port)) {\n\t\ttb_dbg(tb, \"hotplug event for upstream port %llx:%x (unplug: %d)\\n\",\n\t\t       ev->route, ev->port, ev->unplug);\n\t\tgoto put_sw;\n\t}\n\n\tpm_runtime_get_sync(&sw->dev);\n\n\tif (ev->unplug) {\n\t\ttb_retimer_remove_all(port);\n\n\t\tif (tb_port_has_remote(port)) {\n\t\t\ttb_port_dbg(port, \"switch unplugged\\n\");\n\t\t\ttb_sw_set_unplugged(port->remote->sw);\n\t\t\ttb_free_invalid_tunnels(tb);\n\t\t\ttb_remove_dp_resources(port->remote->sw);\n\t\t\ttb_switch_tmu_disable(port->remote->sw);\n\t\t\ttb_switch_unconfigure_link(port->remote->sw);\n\t\t\ttb_switch_lane_bonding_disable(port->remote->sw);\n\t\t\ttb_switch_remove(port->remote->sw);\n\t\t\tport->remote = NULL;\n\t\t\tif (port->dual_link_port)\n\t\t\t\tport->dual_link_port->remote = NULL;\n\t\t\t \n\t\t\ttb_recalc_estimated_bandwidth(tb);\n\t\t\ttb_tunnel_dp(tb);\n\t\t} else if (port->xdomain) {\n\t\t\tstruct tb_xdomain *xd = tb_xdomain_get(port->xdomain);\n\n\t\t\ttb_port_dbg(port, \"xdomain unplugged\\n\");\n\t\t\t \n\t\t\txd->is_unplugged = true;\n\t\t\ttb_xdomain_remove(xd);\n\t\t\tport->xdomain = NULL;\n\t\t\t__tb_disconnect_xdomain_paths(tb, xd, -1, -1, -1, -1);\n\t\t\ttb_xdomain_put(xd);\n\t\t\ttb_port_unconfigure_xdomain(port);\n\t\t} else if (tb_port_is_dpout(port) || tb_port_is_dpin(port)) {\n\t\t\ttb_dp_resource_unavailable(tb, port);\n\t\t} else if (!port->port) {\n\t\t\ttb_sw_dbg(sw, \"xHCI disconnect request\\n\");\n\t\t\ttb_switch_xhci_disconnect(sw);\n\t\t} else {\n\t\t\ttb_port_dbg(port,\n\t\t\t\t   \"got unplug event for disconnected port, ignoring\\n\");\n\t\t}\n\t} else if (port->remote) {\n\t\ttb_port_dbg(port, \"got plug event for connected port, ignoring\\n\");\n\t} else if (!port->port && sw->authorized) {\n\t\ttb_sw_dbg(sw, \"xHCI connect request\\n\");\n\t\ttb_switch_xhci_connect(sw);\n\t} else {\n\t\tif (tb_port_is_null(port)) {\n\t\t\ttb_port_dbg(port, \"hotplug: scanning\\n\");\n\t\t\ttb_scan_port(port);\n\t\t\tif (!port->remote)\n\t\t\t\ttb_port_dbg(port, \"hotplug: no switch found\\n\");\n\t\t} else if (tb_port_is_dpout(port) || tb_port_is_dpin(port)) {\n\t\t\ttb_dp_resource_available(tb, port);\n\t\t}\n\t}\n\n\tpm_runtime_mark_last_busy(&sw->dev);\n\tpm_runtime_put_autosuspend(&sw->dev);\n\nput_sw:\n\ttb_switch_put(sw);\nout:\n\tmutex_unlock(&tb->lock);\n\n\tpm_runtime_mark_last_busy(&tb->dev);\n\tpm_runtime_put_autosuspend(&tb->dev);\n\n\tkfree(ev);\n}\n\nstatic int tb_alloc_dp_bandwidth(struct tb_tunnel *tunnel, int *requested_up,\n\t\t\t\t int *requested_down)\n{\n\tint allocated_up, allocated_down, available_up, available_down, ret;\n\tint requested_up_corrected, requested_down_corrected, granularity;\n\tint max_up, max_down, max_up_rounded, max_down_rounded;\n\tstruct tb *tb = tunnel->tb;\n\tstruct tb_port *in, *out;\n\n\tret = tb_tunnel_allocated_bandwidth(tunnel, &allocated_up, &allocated_down);\n\tif (ret)\n\t\treturn ret;\n\n\tin = tunnel->src_port;\n\tout = tunnel->dst_port;\n\n\ttb_port_dbg(in, \"bandwidth allocated currently %d/%d Mb/s\\n\",\n\t\t    allocated_up, allocated_down);\n\n\t \n\tret = tb_tunnel_maximum_bandwidth(tunnel, &max_up, &max_down);\n\tif (ret)\n\t\treturn ret;\n\n\tret = usb4_dp_port_granularity(in);\n\tif (ret < 0)\n\t\treturn ret;\n\tgranularity = ret;\n\n\tmax_up_rounded = roundup(max_up, granularity);\n\tmax_down_rounded = roundup(max_down, granularity);\n\n\t \n\trequested_up_corrected = *requested_up;\n\tif (requested_up_corrected == max_up_rounded)\n\t\trequested_up_corrected = max_up;\n\telse if (requested_up_corrected < 0)\n\t\trequested_up_corrected = 0;\n\trequested_down_corrected = *requested_down;\n\tif (requested_down_corrected == max_down_rounded)\n\t\trequested_down_corrected = max_down;\n\telse if (requested_down_corrected < 0)\n\t\trequested_down_corrected = 0;\n\n\ttb_port_dbg(in, \"corrected bandwidth request %d/%d Mb/s\\n\",\n\t\t    requested_up_corrected, requested_down_corrected);\n\n\tif ((*requested_up >= 0 && requested_up_corrected > max_up_rounded) ||\n\t    (*requested_down >= 0 && requested_down_corrected > max_down_rounded)) {\n\t\ttb_port_dbg(in, \"bandwidth request too high (%d/%d Mb/s > %d/%d Mb/s)\\n\",\n\t\t\t    requested_up_corrected, requested_down_corrected,\n\t\t\t    max_up_rounded, max_down_rounded);\n\t\treturn -ENOBUFS;\n\t}\n\n\tif ((*requested_up >= 0 && requested_up_corrected <= allocated_up) ||\n\t    (*requested_down >= 0 && requested_down_corrected <= allocated_down)) {\n\t\t \n\t\treturn tb_tunnel_alloc_bandwidth(tunnel, requested_up,\n\t\t\t\t\t\t requested_down);\n\t}\n\n\t \n\tret = tb_release_unused_usb3_bandwidth(tb, in, out);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = tb_available_bandwidth(tb, in, out, &available_up, &available_down);\n\tif (ret)\n\t\tgoto reclaim;\n\n\ttb_port_dbg(in, \"bandwidth available for allocation %d/%d Mb/s\\n\",\n\t\t    available_up, available_down);\n\n\tif ((*requested_up >= 0 && available_up >= requested_up_corrected) ||\n\t    (*requested_down >= 0 && available_down >= requested_down_corrected)) {\n\t\tret = tb_tunnel_alloc_bandwidth(tunnel, requested_up,\n\t\t\t\t\t\trequested_down);\n\t} else {\n\t\tret = -ENOBUFS;\n\t}\n\nreclaim:\n\ttb_reclaim_usb3_bandwidth(tb, in, out);\n\treturn ret;\n}\n\nstatic void tb_handle_dp_bandwidth_request(struct work_struct *work)\n{\n\tstruct tb_hotplug_event *ev = container_of(work, typeof(*ev), work);\n\tint requested_bw, requested_up, requested_down, ret;\n\tstruct tb_port *in, *out;\n\tstruct tb_tunnel *tunnel;\n\tstruct tb *tb = ev->tb;\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_switch *sw;\n\n\tpm_runtime_get_sync(&tb->dev);\n\n\tmutex_lock(&tb->lock);\n\tif (!tcm->hotplug_active)\n\t\tgoto unlock;\n\n\tsw = tb_switch_find_by_route(tb, ev->route);\n\tif (!sw) {\n\t\ttb_warn(tb, \"bandwidth request from non-existent router %llx\\n\",\n\t\t\tev->route);\n\t\tgoto unlock;\n\t}\n\n\tin = &sw->ports[ev->port];\n\tif (!tb_port_is_dpin(in)) {\n\t\ttb_port_warn(in, \"bandwidth request to non-DP IN adapter\\n\");\n\t\tgoto put_sw;\n\t}\n\n\ttb_port_dbg(in, \"handling bandwidth allocation request\\n\");\n\n\tif (!usb4_dp_port_bandwidth_mode_enabled(in)) {\n\t\ttb_port_warn(in, \"bandwidth allocation mode not enabled\\n\");\n\t\tgoto put_sw;\n\t}\n\n\tret = usb4_dp_port_requested_bandwidth(in);\n\tif (ret < 0) {\n\t\tif (ret == -ENODATA)\n\t\t\ttb_port_dbg(in, \"no bandwidth request active\\n\");\n\t\telse\n\t\t\ttb_port_warn(in, \"failed to read requested bandwidth\\n\");\n\t\tgoto put_sw;\n\t}\n\trequested_bw = ret;\n\n\ttb_port_dbg(in, \"requested bandwidth %d Mb/s\\n\", requested_bw);\n\n\ttunnel = tb_find_tunnel(tb, TB_TUNNEL_DP, in, NULL);\n\tif (!tunnel) {\n\t\ttb_port_warn(in, \"failed to find tunnel\\n\");\n\t\tgoto put_sw;\n\t}\n\n\tout = tunnel->dst_port;\n\n\tif (in->sw->config.depth < out->sw->config.depth) {\n\t\trequested_up = -1;\n\t\trequested_down = requested_bw;\n\t} else {\n\t\trequested_up = requested_bw;\n\t\trequested_down = -1;\n\t}\n\n\tret = tb_alloc_dp_bandwidth(tunnel, &requested_up, &requested_down);\n\tif (ret) {\n\t\tif (ret == -ENOBUFS)\n\t\t\ttb_port_warn(in, \"not enough bandwidth available\\n\");\n\t\telse\n\t\t\ttb_port_warn(in, \"failed to change bandwidth allocation\\n\");\n\t} else {\n\t\ttb_port_dbg(in, \"bandwidth allocation changed to %d/%d Mb/s\\n\",\n\t\t\t    requested_up, requested_down);\n\n\t\t \n\t\ttb_recalc_estimated_bandwidth(tb);\n\t}\n\nput_sw:\n\ttb_switch_put(sw);\nunlock:\n\tmutex_unlock(&tb->lock);\n\n\tpm_runtime_mark_last_busy(&tb->dev);\n\tpm_runtime_put_autosuspend(&tb->dev);\n\n\tkfree(ev);\n}\n\nstatic void tb_queue_dp_bandwidth_request(struct tb *tb, u64 route, u8 port)\n{\n\tstruct tb_hotplug_event *ev;\n\n\tev = kmalloc(sizeof(*ev), GFP_KERNEL);\n\tif (!ev)\n\t\treturn;\n\n\tev->tb = tb;\n\tev->route = route;\n\tev->port = port;\n\tINIT_WORK(&ev->work, tb_handle_dp_bandwidth_request);\n\tqueue_work(tb->wq, &ev->work);\n}\n\nstatic void tb_handle_notification(struct tb *tb, u64 route,\n\t\t\t\t   const struct cfg_error_pkg *error)\n{\n\n\tswitch (error->error) {\n\tcase TB_CFG_ERROR_PCIE_WAKE:\n\tcase TB_CFG_ERROR_DP_CON_CHANGE:\n\tcase TB_CFG_ERROR_DPTX_DISCOVERY:\n\t\tif (tb_cfg_ack_notification(tb->ctl, route, error))\n\t\t\ttb_warn(tb, \"could not ack notification on %llx\\n\",\n\t\t\t\troute);\n\t\tbreak;\n\n\tcase TB_CFG_ERROR_DP_BW:\n\t\tif (tb_cfg_ack_notification(tb->ctl, route, error))\n\t\t\ttb_warn(tb, \"could not ack notification on %llx\\n\",\n\t\t\t\troute);\n\t\ttb_queue_dp_bandwidth_request(tb, route, error->port);\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n}\n\n \nstatic void tb_handle_event(struct tb *tb, enum tb_cfg_pkg_type type,\n\t\t\t    const void *buf, size_t size)\n{\n\tconst struct cfg_event_pkg *pkg = buf;\n\tu64 route = tb_cfg_get_route(&pkg->header);\n\n\tswitch (type) {\n\tcase TB_CFG_PKG_ERROR:\n\t\ttb_handle_notification(tb, route, (const struct cfg_error_pkg *)buf);\n\t\treturn;\n\tcase TB_CFG_PKG_EVENT:\n\t\tbreak;\n\tdefault:\n\t\ttb_warn(tb, \"unexpected event %#x, ignoring\\n\", type);\n\t\treturn;\n\t}\n\n\tif (tb_cfg_ack_plug(tb->ctl, route, pkg->port, pkg->unplug)) {\n\t\ttb_warn(tb, \"could not ack plug event on %llx:%x\\n\", route,\n\t\t\tpkg->port);\n\t}\n\n\ttb_queue_hotplug(tb, route, pkg->port, pkg->unplug);\n}\n\nstatic void tb_stop(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel;\n\tstruct tb_tunnel *n;\n\n\tcancel_delayed_work(&tcm->remove_work);\n\t \n\tlist_for_each_entry_safe(tunnel, n, &tcm->tunnel_list, list) {\n\t\t \n\t\tif (tb_tunnel_is_dma(tunnel))\n\t\t\ttb_tunnel_deactivate(tunnel);\n\t\ttb_tunnel_free(tunnel);\n\t}\n\ttb_switch_remove(tb->root_switch);\n\ttcm->hotplug_active = false;  \n}\n\nstatic int tb_scan_finalize_switch(struct device *dev, void *data)\n{\n\tif (tb_is_switch(dev)) {\n\t\tstruct tb_switch *sw = tb_to_switch(dev);\n\n\t\t \n\t\tif (sw->boot)\n\t\t\tsw->authorized = 1;\n\n\t\tdev_set_uevent_suppress(dev, false);\n\t\tkobject_uevent(&dev->kobj, KOBJ_ADD);\n\t\tdevice_for_each_child(dev, NULL, tb_scan_finalize_switch);\n\t}\n\n\treturn 0;\n}\n\nstatic int tb_start(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tint ret;\n\n\ttb->root_switch = tb_switch_alloc(tb, &tb->dev, 0);\n\tif (IS_ERR(tb->root_switch))\n\t\treturn PTR_ERR(tb->root_switch);\n\n\t \n\ttb->root_switch->no_nvm_upgrade = !tb_switch_is_usb4(tb->root_switch);\n\t \n\ttb->root_switch->rpm = tb_switch_is_usb4(tb->root_switch);\n\n\tret = tb_switch_configure(tb->root_switch);\n\tif (ret) {\n\t\ttb_switch_put(tb->root_switch);\n\t\treturn ret;\n\t}\n\n\t \n\tret = tb_switch_add(tb->root_switch);\n\tif (ret) {\n\t\ttb_switch_put(tb->root_switch);\n\t\treturn ret;\n\t}\n\n\t \n\ttb_switch_tmu_configure(tb->root_switch, TB_SWITCH_TMU_MODE_LOWRES);\n\t \n\ttb_switch_tmu_enable(tb->root_switch);\n\t \n\ttb_scan_switch(tb->root_switch);\n\t \n\ttb_discover_tunnels(tb);\n\t \n\ttb_discover_dp_resources(tb);\n\t \n\ttb_create_usb3_tunnels(tb->root_switch);\n\t \n\ttb_add_dp_resources(tb->root_switch);\n\t \n\tdevice_for_each_child(&tb->root_switch->dev, NULL,\n\t\t\t      tb_scan_finalize_switch);\n\n\t \n\ttcm->hotplug_active = true;\n\treturn 0;\n}\n\nstatic int tb_suspend_noirq(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\n\ttb_dbg(tb, \"suspending...\\n\");\n\ttb_disconnect_and_release_dp(tb);\n\ttb_switch_suspend(tb->root_switch, false);\n\ttcm->hotplug_active = false;  \n\ttb_dbg(tb, \"suspend finished\\n\");\n\n\treturn 0;\n}\n\nstatic void tb_restore_children(struct tb_switch *sw)\n{\n\tstruct tb_port *port;\n\n\t \n\tif (sw->is_unplugged)\n\t\treturn;\n\n\tif (tb_enable_clx(sw))\n\t\ttb_sw_warn(sw, \"failed to re-enable CL states\\n\");\n\n\tif (tb_enable_tmu(sw))\n\t\ttb_sw_warn(sw, \"failed to restore TMU configuration\\n\");\n\n\ttb_switch_configuration_valid(sw);\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (!tb_port_has_remote(port) && !port->xdomain)\n\t\t\tcontinue;\n\n\t\tif (port->remote) {\n\t\t\ttb_switch_lane_bonding_enable(port->remote->sw);\n\t\t\ttb_switch_configure_link(port->remote->sw);\n\n\t\t\ttb_restore_children(port->remote->sw);\n\t\t} else if (port->xdomain) {\n\t\t\ttb_port_configure_xdomain(port, port->xdomain);\n\t\t}\n\t}\n}\n\nstatic int tb_resume_noirq(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel, *n;\n\tunsigned int usb3_delay = 0;\n\tLIST_HEAD(tunnels);\n\n\ttb_dbg(tb, \"resuming...\\n\");\n\n\t \n\ttb_switch_reset(tb->root_switch);\n\n\ttb_switch_resume(tb->root_switch);\n\ttb_free_invalid_tunnels(tb);\n\ttb_free_unplugged_children(tb->root_switch);\n\ttb_restore_children(tb->root_switch);\n\n\t \n\ttb_switch_discover_tunnels(tb->root_switch, &tunnels, false);\n\tlist_for_each_entry_safe_reverse(tunnel, n, &tunnels, list) {\n\t\tif (tb_tunnel_is_usb3(tunnel))\n\t\t\tusb3_delay = 500;\n\t\ttb_tunnel_deactivate(tunnel);\n\t\ttb_tunnel_free(tunnel);\n\t}\n\n\t \n\tlist_for_each_entry_safe(tunnel, n, &tcm->tunnel_list, list) {\n\t\t \n\t\tif (tb_tunnel_is_usb3(tunnel)) {\n\t\t\tmsleep(usb3_delay);\n\t\t\t \n\t\t\tusb3_delay = 0;\n\t\t}\n\t\ttb_tunnel_restart(tunnel);\n\t}\n\tif (!list_empty(&tcm->tunnel_list)) {\n\t\t \n\t\ttb_dbg(tb, \"tunnels restarted, sleeping for 100ms\\n\");\n\t\tmsleep(100);\n\t}\n\t  \n\ttcm->hotplug_active = true;\n\ttb_dbg(tb, \"resume finished\\n\");\n\n\treturn 0;\n}\n\nstatic int tb_free_unplugged_xdomains(struct tb_switch *sw)\n{\n\tstruct tb_port *port;\n\tint ret = 0;\n\n\ttb_switch_for_each_port(sw, port) {\n\t\tif (tb_is_upstream_port(port))\n\t\t\tcontinue;\n\t\tif (port->xdomain && port->xdomain->is_unplugged) {\n\t\t\ttb_retimer_remove_all(port);\n\t\t\ttb_xdomain_remove(port->xdomain);\n\t\t\ttb_port_unconfigure_xdomain(port);\n\t\t\tport->xdomain = NULL;\n\t\t\tret++;\n\t\t} else if (port->remote) {\n\t\t\tret += tb_free_unplugged_xdomains(port->remote->sw);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int tb_freeze_noirq(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\n\ttcm->hotplug_active = false;\n\treturn 0;\n}\n\nstatic int tb_thaw_noirq(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\n\ttcm->hotplug_active = true;\n\treturn 0;\n}\n\nstatic void tb_complete(struct tb *tb)\n{\n\t \n\tmutex_lock(&tb->lock);\n\tif (tb_free_unplugged_xdomains(tb->root_switch))\n\t\ttb_scan_switch(tb->root_switch);\n\tmutex_unlock(&tb->lock);\n}\n\nstatic int tb_runtime_suspend(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\n\tmutex_lock(&tb->lock);\n\ttb_switch_suspend(tb->root_switch, true);\n\ttcm->hotplug_active = false;\n\tmutex_unlock(&tb->lock);\n\n\treturn 0;\n}\n\nstatic void tb_remove_work(struct work_struct *work)\n{\n\tstruct tb_cm *tcm = container_of(work, struct tb_cm, remove_work.work);\n\tstruct tb *tb = tcm_to_tb(tcm);\n\n\tmutex_lock(&tb->lock);\n\tif (tb->root_switch) {\n\t\ttb_free_unplugged_children(tb->root_switch);\n\t\ttb_free_unplugged_xdomains(tb->root_switch);\n\t}\n\tmutex_unlock(&tb->lock);\n}\n\nstatic int tb_runtime_resume(struct tb *tb)\n{\n\tstruct tb_cm *tcm = tb_priv(tb);\n\tstruct tb_tunnel *tunnel, *n;\n\n\tmutex_lock(&tb->lock);\n\ttb_switch_resume(tb->root_switch);\n\ttb_free_invalid_tunnels(tb);\n\ttb_restore_children(tb->root_switch);\n\tlist_for_each_entry_safe(tunnel, n, &tcm->tunnel_list, list)\n\t\ttb_tunnel_restart(tunnel);\n\ttcm->hotplug_active = true;\n\tmutex_unlock(&tb->lock);\n\n\t \n\tqueue_delayed_work(tb->wq, &tcm->remove_work, msecs_to_jiffies(50));\n\treturn 0;\n}\n\nstatic const struct tb_cm_ops tb_cm_ops = {\n\t.start = tb_start,\n\t.stop = tb_stop,\n\t.suspend_noirq = tb_suspend_noirq,\n\t.resume_noirq = tb_resume_noirq,\n\t.freeze_noirq = tb_freeze_noirq,\n\t.thaw_noirq = tb_thaw_noirq,\n\t.complete = tb_complete,\n\t.runtime_suspend = tb_runtime_suspend,\n\t.runtime_resume = tb_runtime_resume,\n\t.handle_event = tb_handle_event,\n\t.disapprove_switch = tb_disconnect_pci,\n\t.approve_switch = tb_tunnel_pci,\n\t.approve_xdomain_paths = tb_approve_xdomain_paths,\n\t.disconnect_xdomain_paths = tb_disconnect_xdomain_paths,\n};\n\n \nstatic bool tb_apple_add_links(struct tb_nhi *nhi)\n{\n\tstruct pci_dev *upstream, *pdev;\n\tbool ret;\n\n\tif (!x86_apple_machine)\n\t\treturn false;\n\n\tswitch (nhi->pdev->device) {\n\tcase PCI_DEVICE_ID_INTEL_LIGHT_RIDGE:\n\tcase PCI_DEVICE_ID_INTEL_CACTUS_RIDGE_4C:\n\tcase PCI_DEVICE_ID_INTEL_FALCON_RIDGE_2C_NHI:\n\tcase PCI_DEVICE_ID_INTEL_FALCON_RIDGE_4C_NHI:\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\n\tupstream = pci_upstream_bridge(nhi->pdev);\n\twhile (upstream) {\n\t\tif (!pci_is_pcie(upstream))\n\t\t\treturn false;\n\t\tif (pci_pcie_type(upstream) == PCI_EXP_TYPE_UPSTREAM)\n\t\t\tbreak;\n\t\tupstream = pci_upstream_bridge(upstream);\n\t}\n\n\tif (!upstream)\n\t\treturn false;\n\n\t \n\tret = false;\n\tfor_each_pci_bridge(pdev, upstream->subordinate) {\n\t\tconst struct device_link *link;\n\n\t\tif (!pci_is_pcie(pdev))\n\t\t\tcontinue;\n\t\tif (pci_pcie_type(pdev) != PCI_EXP_TYPE_DOWNSTREAM ||\n\t\t    !pdev->is_hotplug_bridge)\n\t\t\tcontinue;\n\n\t\tlink = device_link_add(&pdev->dev, &nhi->pdev->dev,\n\t\t\t\t       DL_FLAG_AUTOREMOVE_SUPPLIER |\n\t\t\t\t       DL_FLAG_PM_RUNTIME);\n\t\tif (link) {\n\t\t\tdev_dbg(&nhi->pdev->dev, \"created link from %s\\n\",\n\t\t\t\tdev_name(&pdev->dev));\n\t\t\tret = true;\n\t\t} else {\n\t\t\tdev_warn(&nhi->pdev->dev, \"device link creation from %s failed\\n\",\n\t\t\t\t dev_name(&pdev->dev));\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstruct tb *tb_probe(struct tb_nhi *nhi)\n{\n\tstruct tb_cm *tcm;\n\tstruct tb *tb;\n\n\ttb = tb_domain_alloc(nhi, TB_TIMEOUT, sizeof(*tcm));\n\tif (!tb)\n\t\treturn NULL;\n\n\tif (tb_acpi_may_tunnel_pcie())\n\t\ttb->security_level = TB_SECURITY_USER;\n\telse\n\t\ttb->security_level = TB_SECURITY_NOPCIE;\n\n\ttb->cm_ops = &tb_cm_ops;\n\n\ttcm = tb_priv(tb);\n\tINIT_LIST_HEAD(&tcm->tunnel_list);\n\tINIT_LIST_HEAD(&tcm->dp_resources);\n\tINIT_DELAYED_WORK(&tcm->remove_work, tb_remove_work);\n\ttb_init_bandwidth_groups(tcm);\n\n\ttb_dbg(tb, \"using software connection manager\\n\");\n\n\t \n\tif (!tb_apple_add_links(nhi) && !tb_acpi_add_links(nhi))\n\t\ttb_warn(tb, \"device links to tunneled native ports are missing!\\n\");\n\n\treturn tb;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}