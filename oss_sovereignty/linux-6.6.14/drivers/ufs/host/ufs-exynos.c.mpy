{
  "module_name": "ufs-exynos.c",
  "hash_id": "4e677afb1f5d2ebb474c63562e04bfee4d0f5adaa704b666b1f00ff902c9e1e4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/ufs/host/ufs-exynos.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/mfd/syscon.h>\n#include <linux/phy/phy.h>\n#include <linux/platform_device.h>\n#include <linux/regmap.h>\n\n#include <ufs/ufshcd.h>\n#include \"ufshcd-pltfrm.h\"\n#include <ufs/ufshci.h>\n#include <ufs/unipro.h>\n\n#include \"ufs-exynos.h\"\n\n \n#define HCI_TXPRDT_ENTRY_SIZE\t0x00\n#define PRDT_PREFECT_EN\t\tBIT(31)\n#define PRDT_SET_SIZE(x)\t((x) & 0x1F)\n#define HCI_RXPRDT_ENTRY_SIZE\t0x04\n#define HCI_1US_TO_CNT_VAL\t0x0C\n#define CNT_VAL_1US_MASK\t0x3FF\n#define HCI_UTRL_NEXUS_TYPE\t0x40\n#define HCI_UTMRL_NEXUS_TYPE\t0x44\n#define HCI_SW_RST\t\t0x50\n#define UFS_LINK_SW_RST\t\tBIT(0)\n#define UFS_UNIPRO_SW_RST\tBIT(1)\n#define UFS_SW_RST_MASK\t\t(UFS_UNIPRO_SW_RST | UFS_LINK_SW_RST)\n#define HCI_DATA_REORDER\t0x60\n#define HCI_UNIPRO_APB_CLK_CTRL\t0x68\n#define UNIPRO_APB_CLK(v, x)\t(((v) & ~0xF) | ((x) & 0xF))\n#define HCI_AXIDMA_RWDATA_BURST_LEN\t0x6C\n#define HCI_GPIO_OUT\t\t0x70\n#define HCI_ERR_EN_PA_LAYER\t0x78\n#define HCI_ERR_EN_DL_LAYER\t0x7C\n#define HCI_ERR_EN_N_LAYER\t0x80\n#define HCI_ERR_EN_T_LAYER\t0x84\n#define HCI_ERR_EN_DME_LAYER\t0x88\n#define HCI_CLKSTOP_CTRL\t0xB0\n#define REFCLKOUT_STOP\t\tBIT(4)\n#define MPHY_APBCLK_STOP\tBIT(3)\n#define REFCLK_STOP\t\tBIT(2)\n#define UNIPRO_MCLK_STOP\tBIT(1)\n#define UNIPRO_PCLK_STOP\tBIT(0)\n#define CLK_STOP_MASK\t\t(REFCLKOUT_STOP | REFCLK_STOP |\\\n\t\t\t\t UNIPRO_MCLK_STOP | MPHY_APBCLK_STOP|\\\n\t\t\t\t UNIPRO_PCLK_STOP)\n#define HCI_MISC\t\t0xB4\n#define REFCLK_CTRL_EN\t\tBIT(7)\n#define UNIPRO_PCLK_CTRL_EN\tBIT(6)\n#define UNIPRO_MCLK_CTRL_EN\tBIT(5)\n#define HCI_CORECLK_CTRL_EN\tBIT(4)\n#define CLK_CTRL_EN_MASK\t(REFCLK_CTRL_EN |\\\n\t\t\t\t UNIPRO_PCLK_CTRL_EN |\\\n\t\t\t\t UNIPRO_MCLK_CTRL_EN)\n \n#define DFES_ERR_EN\t\tBIT(31)\n#define DFES_DEF_L2_ERRS\t(UIC_DATA_LINK_LAYER_ERROR_RX_BUF_OF |\\\n\t\t\t\t UIC_DATA_LINK_LAYER_ERROR_PA_INIT)\n#define DFES_DEF_L3_ERRS\t(UIC_NETWORK_UNSUPPORTED_HEADER_TYPE |\\\n\t\t\t\t UIC_NETWORK_BAD_DEVICEID_ENC |\\\n\t\t\t\t UIC_NETWORK_LHDR_TRAP_PACKET_DROPPING)\n#define DFES_DEF_L4_ERRS\t(UIC_TRANSPORT_UNSUPPORTED_HEADER_TYPE |\\\n\t\t\t\t UIC_TRANSPORT_UNKNOWN_CPORTID |\\\n\t\t\t\t UIC_TRANSPORT_NO_CONNECTION_RX |\\\n\t\t\t\t UIC_TRANSPORT_BAD_TC)\n\n \n#define UFS_WR_SHARABLE\t\tBIT(2)\n#define UFS_RD_SHARABLE\t\tBIT(1)\n#define UFS_SHARABLE\t\t(UFS_WR_SHARABLE | UFS_RD_SHARABLE)\n#define UFS_SHAREABILITY_OFFSET\t0x710\n\n \n#define MHCTRL\t\t\t0xC4\n#define MHCTRL_EN_VH_MASK\t(0xE)\n#define MHCTRL_EN_VH(vh)\t(vh << 1)\n#define PH2VH_MBOX\t\t0xD8\n\n#define MH_MSG_MASK\t\t(0xFF)\n\n#define MH_MSG(id, msg)\t\t((id << 8) | (msg & 0xFF))\n#define MH_MSG_PH_READY\t\t0x1\n#define MH_MSG_VH_READY\t\t0x2\n\n#define ALLOW_INQUIRY\t\tBIT(25)\n#define ALLOW_MODE_SELECT\tBIT(24)\n#define ALLOW_MODE_SENSE\tBIT(23)\n#define ALLOW_PRE_FETCH\t\tGENMASK(22, 21)\n#define ALLOW_READ_CMD_ALL\tGENMASK(20, 18)\t \n#define ALLOW_READ_BUFFER\tBIT(17)\n#define ALLOW_READ_CAPACITY\tGENMASK(16, 15)\n#define ALLOW_REPORT_LUNS\tBIT(14)\n#define ALLOW_REQUEST_SENSE\tBIT(13)\n#define ALLOW_SYNCHRONIZE_CACHE\tGENMASK(8, 7)\n#define ALLOW_TEST_UNIT_READY\tBIT(6)\n#define ALLOW_UNMAP\t\tBIT(5)\n#define ALLOW_VERIFY\t\tBIT(4)\n#define ALLOW_WRITE_CMD_ALL\tGENMASK(3, 1)\t \n\n#define ALLOW_TRANS_VH_DEFAULT\t(ALLOW_INQUIRY | ALLOW_MODE_SELECT | \\\n\t\t\t\t ALLOW_MODE_SENSE | ALLOW_PRE_FETCH | \\\n\t\t\t\t ALLOW_READ_CMD_ALL | ALLOW_READ_BUFFER | \\\n\t\t\t\t ALLOW_READ_CAPACITY | ALLOW_REPORT_LUNS | \\\n\t\t\t\t ALLOW_REQUEST_SENSE | ALLOW_SYNCHRONIZE_CACHE | \\\n\t\t\t\t ALLOW_TEST_UNIT_READY | ALLOW_UNMAP | \\\n\t\t\t\t ALLOW_VERIFY | ALLOW_WRITE_CMD_ALL)\n\n#define HCI_MH_ALLOWABLE_TRAN_OF_VH\t\t0x30C\n#define HCI_MH_IID_IN_TASK_TAG\t\t\t0X308\n\n#define PH_READY_TIMEOUT_MS\t\t\t(5 * MSEC_PER_SEC)\n\nenum {\n\tUNIPRO_L1_5 = 0, \n\tUNIPRO_L2,\t \n\tUNIPRO_L3,\t \n\tUNIPRO_L4,\t \n\tUNIPRO_DME,\t \n};\n\n \n#define UNIPRO_DME_POWERMODE_REQ_REMOTEL2TIMER0\t0x78B8\n#define UNIPRO_DME_POWERMODE_REQ_REMOTEL2TIMER1\t0x78BC\n#define UNIPRO_DME_POWERMODE_REQ_REMOTEL2TIMER2\t0x78C0\n\n \n#define UFSPRSECURITY\t0x010\n#define NSSMU\t\tBIT(14)\n#define UFSPSBEGIN0\t0x200\n#define UFSPSEND0\t0x204\n#define UFSPSLUN0\t0x208\n#define UFSPSCTRL0\t0x20C\n\n#define CNTR_DIV_VAL 40\n\nstatic void exynos_ufs_auto_ctrl_hcc(struct exynos_ufs *ufs, bool en);\nstatic void exynos_ufs_ctrl_clkstop(struct exynos_ufs *ufs, bool en);\n\nstatic inline void exynos_ufs_enable_auto_ctrl_hcc(struct exynos_ufs *ufs)\n{\n\texynos_ufs_auto_ctrl_hcc(ufs, true);\n}\n\nstatic inline void exynos_ufs_disable_auto_ctrl_hcc(struct exynos_ufs *ufs)\n{\n\texynos_ufs_auto_ctrl_hcc(ufs, false);\n}\n\nstatic inline void exynos_ufs_disable_auto_ctrl_hcc_save(\n\t\t\t\t\tstruct exynos_ufs *ufs, u32 *val)\n{\n\t*val = hci_readl(ufs, HCI_MISC);\n\texynos_ufs_auto_ctrl_hcc(ufs, false);\n}\n\nstatic inline void exynos_ufs_auto_ctrl_hcc_restore(\n\t\t\t\t\tstruct exynos_ufs *ufs, u32 *val)\n{\n\thci_writel(ufs, *val, HCI_MISC);\n}\n\nstatic inline void exynos_ufs_gate_clks(struct exynos_ufs *ufs)\n{\n\texynos_ufs_ctrl_clkstop(ufs, true);\n}\n\nstatic inline void exynos_ufs_ungate_clks(struct exynos_ufs *ufs)\n{\n\texynos_ufs_ctrl_clkstop(ufs, false);\n}\n\nstatic int exynos7_ufs_drv_init(struct device *dev, struct exynos_ufs *ufs)\n{\n\treturn 0;\n}\n\nstatic int exynosauto_ufs_drv_init(struct device *dev, struct exynos_ufs *ufs)\n{\n\tstruct exynos_ufs_uic_attr *attr = ufs->drv_data->uic_attr;\n\n\t \n\tif (ufs->sysreg) {\n\t\treturn regmap_update_bits(ufs->sysreg,\n\t\t\t\t\t  ufs->shareability_reg_offset,\n\t\t\t\t\t  UFS_SHARABLE, UFS_SHARABLE);\n\t}\n\n\tattr->tx_dif_p_nsec = 3200000;\n\n\treturn 0;\n}\n\nstatic int exynosauto_ufs_post_hce_enable(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\n\t \n\tufshcd_rmwl(hba, MHCTRL_EN_VH_MASK, MHCTRL_EN_VH(1), MHCTRL);\n\t \n\thci_writel(ufs, ALLOW_TRANS_VH_DEFAULT, HCI_MH_ALLOWABLE_TRAN_OF_VH);\n\t \n\thci_writel(ufs, 0x1, HCI_MH_IID_IN_TASK_TAG);\n\n\treturn 0;\n}\n\nstatic int exynosauto_ufs_pre_link(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tint i;\n\tu32 tx_line_reset_period, rx_line_reset_period;\n\n\trx_line_reset_period = (RX_LINE_RESET_TIME * ufs->mclk_rate) / NSEC_PER_MSEC;\n\ttx_line_reset_period = (TX_LINE_RESET_TIME * ufs->mclk_rate) / NSEC_PER_MSEC;\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(0x200), 0x40);\n\tfor_each_ufs_rx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_RX_CLK_PRD, i),\n\t\t\t       DIV_ROUND_UP(NSEC_PER_SEC, ufs->mclk_rate));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_RX_CLK_PRD_EN, i), 0x0);\n\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_RX_LINERESET_VALUE2, i),\n\t\t\t       (rx_line_reset_period >> 16) & 0xFF);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_RX_LINERESET_VALUE1, i),\n\t\t\t       (rx_line_reset_period >> 8) & 0xFF);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_RX_LINERESET_VALUE0, i),\n\t\t\t       (rx_line_reset_period) & 0xFF);\n\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x2f, i), 0x79);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x84, i), 0x1);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x25, i), 0xf6);\n\t}\n\n\tfor_each_ufs_tx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_TX_CLK_PRD, i),\n\t\t\t       DIV_ROUND_UP(NSEC_PER_SEC, ufs->mclk_rate));\n\t\t \n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_TX_CLK_PRD_EN, i),\n\t\t\t       0x02);\n\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_TX_LINERESET_PVALUE2, i),\n\t\t\t       (tx_line_reset_period >> 16) & 0xFF);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_TX_LINERESET_PVALUE1, i),\n\t\t\t       (tx_line_reset_period >> 8) & 0xFF);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(VND_TX_LINERESET_PVALUE0, i),\n\t\t\t       (tx_line_reset_period) & 0xFF);\n\n\t\t \n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x04, i), 0x1);\n\t}\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(0x200), 0x0);\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_LOCAL_TX_LCC_ENABLE), 0x0);\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(0xa011), 0x8000);\n\n\treturn 0;\n}\n\nstatic int exynosauto_ufs_pre_pwr_change(struct exynos_ufs *ufs,\n\t\t\t\t\t struct ufs_pa_layer_attr *pwr)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\n\t \n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_PWRMODEUSERDATA0), 12000);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_PWRMODEUSERDATA1), 32000);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_PWRMODEUSERDATA2), 16000);\n\n\treturn 0;\n}\n\nstatic int exynosauto_ufs_post_pwr_change(struct exynos_ufs *ufs,\n\t\t\t\t\t  struct ufs_pa_layer_attr *pwr)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tu32 enabled_vh;\n\n\tenabled_vh = ufshcd_readl(hba, MHCTRL) & MHCTRL_EN_VH_MASK;\n\n\t \n\tufshcd_writel(hba, MH_MSG(enabled_vh, MH_MSG_PH_READY), PH2VH_MBOX);\n\n\treturn 0;\n}\n\nstatic int exynos7_ufs_pre_link(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tu32 val = ufs->drv_data->uic_attr->pa_dbg_option_suite;\n\tint i;\n\n\texynos_ufs_enable_ov_tm(hba);\n\tfor_each_ufs_tx_lane(ufs, i)\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x297, i), 0x17);\n\tfor_each_ufs_rx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x362, i), 0xff);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x363, i), 0x00);\n\t}\n\texynos_ufs_disable_ov_tm(hba);\n\n\tfor_each_ufs_tx_lane(ufs, i)\n\t\tufshcd_dme_set(hba,\n\t\t\tUIC_ARG_MIB_SEL(TX_HIBERN8_CONTROL, i), 0x0);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_TXPHY_CFGUPDT), 0x1);\n\tudelay(1);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_OPTION_SUITE), val | (1 << 12));\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_SKIP_RESET_PHY), 0x1);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_SKIP_LINE_RESET), 0x1);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_LINE_RESET_REQ), 0x1);\n\tudelay(1600);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_OPTION_SUITE), val);\n\n\treturn 0;\n}\n\nstatic int exynos7_ufs_post_link(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tint i;\n\n\texynos_ufs_enable_ov_tm(hba);\n\tfor_each_ufs_tx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x28b, i), 0x83);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x29a, i), 0x07);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x277, i),\n\t\t\tTX_LINERESET_N(exynos_ufs_calc_time_cntr(ufs, 200000)));\n\t}\n\texynos_ufs_disable_ov_tm(hba);\n\n\texynos_ufs_enable_dbg_mode(hba);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_SAVECONFIGTIME), 0xbb8);\n\texynos_ufs_disable_dbg_mode(hba);\n\n\treturn 0;\n}\n\nstatic int exynos7_ufs_pre_pwr_change(struct exynos_ufs *ufs,\n\t\t\t\t\t\tstruct ufs_pa_layer_attr *pwr)\n{\n\tunipro_writel(ufs, 0x22, UNIPRO_DBG_FORCE_DME_CTRL_STATE);\n\n\treturn 0;\n}\n\nstatic int exynos7_ufs_post_pwr_change(struct exynos_ufs *ufs,\n\t\t\t\t\t\tstruct ufs_pa_layer_attr *pwr)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tint lanes = max_t(u32, pwr->lane_rx, pwr->lane_tx);\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_RXPHY_CFGUPDT), 0x1);\n\n\tif (lanes == 1) {\n\t\texynos_ufs_enable_dbg_mode(hba);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_CONNECTEDTXDATALANES), 0x1);\n\t\texynos_ufs_disable_dbg_mode(hba);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void exynos_ufs_auto_ctrl_hcc(struct exynos_ufs *ufs, bool en)\n{\n\tu32 misc = hci_readl(ufs, HCI_MISC);\n\n\tif (en)\n\t\thci_writel(ufs, misc | HCI_CORECLK_CTRL_EN, HCI_MISC);\n\telse\n\t\thci_writel(ufs, misc & ~HCI_CORECLK_CTRL_EN, HCI_MISC);\n}\n\nstatic void exynos_ufs_ctrl_clkstop(struct exynos_ufs *ufs, bool en)\n{\n\tu32 ctrl = hci_readl(ufs, HCI_CLKSTOP_CTRL);\n\tu32 misc = hci_readl(ufs, HCI_MISC);\n\n\tif (en) {\n\t\thci_writel(ufs, misc | CLK_CTRL_EN_MASK, HCI_MISC);\n\t\thci_writel(ufs, ctrl | CLK_STOP_MASK, HCI_CLKSTOP_CTRL);\n\t} else {\n\t\thci_writel(ufs, ctrl & ~CLK_STOP_MASK, HCI_CLKSTOP_CTRL);\n\t\thci_writel(ufs, misc & ~CLK_CTRL_EN_MASK, HCI_MISC);\n\t}\n}\n\nstatic int exynos_ufs_get_clk_info(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tstruct list_head *head = &hba->clk_list_head;\n\tstruct ufs_clk_info *clki;\n\tunsigned long pclk_rate;\n\tu32 f_min, f_max;\n\tu8 div = 0;\n\tint ret = 0;\n\n\tif (list_empty(head))\n\t\tgoto out;\n\n\tlist_for_each_entry(clki, head, list) {\n\t\tif (!IS_ERR(clki->clk)) {\n\t\t\tif (!strcmp(clki->name, \"core_clk\"))\n\t\t\t\tufs->clk_hci_core = clki->clk;\n\t\t\telse if (!strcmp(clki->name, \"sclk_unipro_main\"))\n\t\t\t\tufs->clk_unipro_main = clki->clk;\n\t\t}\n\t}\n\n\tif (!ufs->clk_hci_core || !ufs->clk_unipro_main) {\n\t\tdev_err(hba->dev, \"failed to get clk info\\n\");\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tufs->mclk_rate = clk_get_rate(ufs->clk_unipro_main);\n\tpclk_rate = clk_get_rate(ufs->clk_hci_core);\n\tf_min = ufs->pclk_avail_min;\n\tf_max = ufs->pclk_avail_max;\n\n\tif (ufs->opts & EXYNOS_UFS_OPT_HAS_APB_CLK_CTRL) {\n\t\tdo {\n\t\t\tpclk_rate /= (div + 1);\n\n\t\t\tif (pclk_rate <= f_max)\n\t\t\t\tbreak;\n\t\t\tdiv++;\n\t\t} while (pclk_rate >= f_min);\n\t}\n\n\tif (unlikely(pclk_rate < f_min || pclk_rate > f_max)) {\n\t\tdev_err(hba->dev, \"not available pclk range %lu\\n\", pclk_rate);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tufs->pclk_rate = pclk_rate;\n\tufs->pclk_div = div;\n\nout:\n\treturn ret;\n}\n\nstatic void exynos_ufs_set_unipro_pclk_div(struct exynos_ufs *ufs)\n{\n\tif (ufs->opts & EXYNOS_UFS_OPT_HAS_APB_CLK_CTRL) {\n\t\tu32 val;\n\n\t\tval = hci_readl(ufs, HCI_UNIPRO_APB_CLK_CTRL);\n\t\thci_writel(ufs, UNIPRO_APB_CLK(val, ufs->pclk_div),\n\t\t\t   HCI_UNIPRO_APB_CLK_CTRL);\n\t}\n}\n\nstatic void exynos_ufs_set_pwm_clk_div(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tstruct exynos_ufs_uic_attr *attr = ufs->drv_data->uic_attr;\n\n\tufshcd_dme_set(hba,\n\t\tUIC_ARG_MIB(CMN_PWM_CLK_CTRL), attr->cmn_pwm_clk_ctrl);\n}\n\nstatic void exynos_ufs_calc_pwm_clk_div(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tstruct exynos_ufs_uic_attr *attr = ufs->drv_data->uic_attr;\n\tconst unsigned int div = 30, mult = 20;\n\tconst unsigned long pwm_min = 3 * 1000 * 1000;\n\tconst unsigned long pwm_max = 9 * 1000 * 1000;\n\tconst int divs[] = {32, 16, 8, 4};\n\tunsigned long clk = 0, _clk, clk_period;\n\tint i = 0, clk_idx = -1;\n\n\tclk_period = UNIPRO_PCLK_PERIOD(ufs);\n\tfor (i = 0; i < ARRAY_SIZE(divs); i++) {\n\t\t_clk = NSEC_PER_SEC * mult / (clk_period * divs[i] * div);\n\t\tif (_clk >= pwm_min && _clk <= pwm_max) {\n\t\t\tif (_clk > clk) {\n\t\t\t\tclk_idx = i;\n\t\t\t\tclk = _clk;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (clk_idx == -1) {\n\t\tufshcd_dme_get(hba, UIC_ARG_MIB(CMN_PWM_CLK_CTRL), &clk_idx);\n\t\tdev_err(hba->dev,\n\t\t\t\"failed to decide pwm clock divider, will not change\\n\");\n\t}\n\n\tattr->cmn_pwm_clk_ctrl = clk_idx & PWM_CLK_CTRL_MASK;\n}\n\nlong exynos_ufs_calc_time_cntr(struct exynos_ufs *ufs, long period)\n{\n\tconst int precise = 10;\n\tlong pclk_rate = ufs->pclk_rate;\n\tlong clk_period, fraction;\n\n\tclk_period = UNIPRO_PCLK_PERIOD(ufs);\n\tfraction = ((NSEC_PER_SEC % pclk_rate) * precise) / pclk_rate;\n\n\treturn (period * precise) / ((clk_period * precise) + fraction);\n}\n\nstatic void exynos_ufs_specify_phy_time_attr(struct exynos_ufs *ufs)\n{\n\tstruct exynos_ufs_uic_attr *attr = ufs->drv_data->uic_attr;\n\tstruct ufs_phy_time_cfg *t_cfg = &ufs->t_cfg;\n\n\tt_cfg->tx_linereset_p =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->tx_dif_p_nsec);\n\tt_cfg->tx_linereset_n =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->tx_dif_n_nsec);\n\tt_cfg->tx_high_z_cnt =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->tx_high_z_cnt_nsec);\n\tt_cfg->tx_base_n_val =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->tx_base_unit_nsec);\n\tt_cfg->tx_gran_n_val =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->tx_gran_unit_nsec);\n\tt_cfg->tx_sleep_cnt =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->tx_sleep_cnt);\n\n\tt_cfg->rx_linereset =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->rx_dif_p_nsec);\n\tt_cfg->rx_hibern8_wait =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->rx_hibern8_wait_nsec);\n\tt_cfg->rx_base_n_val =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->rx_base_unit_nsec);\n\tt_cfg->rx_gran_n_val =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->rx_gran_unit_nsec);\n\tt_cfg->rx_sleep_cnt =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->rx_sleep_cnt);\n\tt_cfg->rx_stall_cnt =\n\t\texynos_ufs_calc_time_cntr(ufs, attr->rx_stall_cnt);\n}\n\nstatic void exynos_ufs_config_phy_time_attr(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tstruct ufs_phy_time_cfg *t_cfg = &ufs->t_cfg;\n\tint i;\n\n\texynos_ufs_set_pwm_clk_div(ufs);\n\n\texynos_ufs_enable_ov_tm(hba);\n\n\tfor_each_ufs_rx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(RX_FILLER_ENABLE, i),\n\t\t\t\tufs->drv_data->uic_attr->rx_filler_enable);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(RX_LINERESET_VAL, i),\n\t\t\t\tRX_LINERESET(t_cfg->rx_linereset));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(RX_BASE_NVAL_07_00, i),\n\t\t\t\tRX_BASE_NVAL_L(t_cfg->rx_base_n_val));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(RX_BASE_NVAL_15_08, i),\n\t\t\t\tRX_BASE_NVAL_H(t_cfg->rx_base_n_val));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(RX_GRAN_NVAL_07_00, i),\n\t\t\t\tRX_GRAN_NVAL_L(t_cfg->rx_gran_n_val));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(RX_GRAN_NVAL_10_08, i),\n\t\t\t\tRX_GRAN_NVAL_H(t_cfg->rx_gran_n_val));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(RX_OV_SLEEP_CNT_TIMER, i),\n\t\t\t\tRX_OV_SLEEP_CNT(t_cfg->rx_sleep_cnt));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(RX_OV_STALL_CNT_TIMER, i),\n\t\t\t\tRX_OV_STALL_CNT(t_cfg->rx_stall_cnt));\n\t}\n\n\tfor_each_ufs_tx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(TX_LINERESET_P_VAL, i),\n\t\t\t\tTX_LINERESET_P(t_cfg->tx_linereset_p));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(TX_HIGH_Z_CNT_07_00, i),\n\t\t\t\tTX_HIGH_Z_CNT_L(t_cfg->tx_high_z_cnt));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(TX_HIGH_Z_CNT_11_08, i),\n\t\t\t\tTX_HIGH_Z_CNT_H(t_cfg->tx_high_z_cnt));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(TX_BASE_NVAL_07_00, i),\n\t\t\t\tTX_BASE_NVAL_L(t_cfg->tx_base_n_val));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(TX_BASE_NVAL_15_08, i),\n\t\t\t\tTX_BASE_NVAL_H(t_cfg->tx_base_n_val));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(TX_GRAN_NVAL_07_00, i),\n\t\t\t\tTX_GRAN_NVAL_L(t_cfg->tx_gran_n_val));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(TX_GRAN_NVAL_10_08, i),\n\t\t\t\tTX_GRAN_NVAL_H(t_cfg->tx_gran_n_val));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(TX_OV_SLEEP_CNT_TIMER, i),\n\t\t\t\tTX_OV_H8_ENTER_EN |\n\t\t\t\tTX_OV_SLEEP_CNT(t_cfg->tx_sleep_cnt));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(TX_MIN_ACTIVATETIME, i),\n\t\t\t\tufs->drv_data->uic_attr->tx_min_activatetime);\n\t}\n\n\texynos_ufs_disable_ov_tm(hba);\n}\n\nstatic void exynos_ufs_config_phy_cap_attr(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tstruct exynos_ufs_uic_attr *attr = ufs->drv_data->uic_attr;\n\tint i;\n\n\texynos_ufs_enable_ov_tm(hba);\n\n\tfor_each_ufs_rx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba,\n\t\t\t\tUIC_ARG_MIB_SEL(RX_HS_G1_SYNC_LENGTH_CAP, i),\n\t\t\t\tattr->rx_hs_g1_sync_len_cap);\n\t\tufshcd_dme_set(hba,\n\t\t\t\tUIC_ARG_MIB_SEL(RX_HS_G2_SYNC_LENGTH_CAP, i),\n\t\t\t\tattr->rx_hs_g2_sync_len_cap);\n\t\tufshcd_dme_set(hba,\n\t\t\t\tUIC_ARG_MIB_SEL(RX_HS_G3_SYNC_LENGTH_CAP, i),\n\t\t\t\tattr->rx_hs_g3_sync_len_cap);\n\t\tufshcd_dme_set(hba,\n\t\t\t\tUIC_ARG_MIB_SEL(RX_HS_G1_PREP_LENGTH_CAP, i),\n\t\t\t\tattr->rx_hs_g1_prep_sync_len_cap);\n\t\tufshcd_dme_set(hba,\n\t\t\t\tUIC_ARG_MIB_SEL(RX_HS_G2_PREP_LENGTH_CAP, i),\n\t\t\t\tattr->rx_hs_g2_prep_sync_len_cap);\n\t\tufshcd_dme_set(hba,\n\t\t\t\tUIC_ARG_MIB_SEL(RX_HS_G3_PREP_LENGTH_CAP, i),\n\t\t\t\tattr->rx_hs_g3_prep_sync_len_cap);\n\t}\n\n\tif (attr->rx_adv_fine_gran_sup_en == 0) {\n\t\tfor_each_ufs_rx_lane(ufs, i) {\n\t\t\tufshcd_dme_set(hba,\n\t\t\t\tUIC_ARG_MIB_SEL(RX_ADV_GRANULARITY_CAP, i), 0);\n\n\t\t\tif (attr->rx_min_actv_time_cap)\n\t\t\t\tufshcd_dme_set(hba,\n\t\t\t\t\tUIC_ARG_MIB_SEL(\n\t\t\t\t\tRX_MIN_ACTIVATETIME_CAPABILITY, i),\n\t\t\t\t\tattr->rx_min_actv_time_cap);\n\n\t\t\tif (attr->rx_hibern8_time_cap)\n\t\t\t\tufshcd_dme_set(hba,\n\t\t\t\t\tUIC_ARG_MIB_SEL(RX_HIBERN8TIME_CAP, i),\n\t\t\t\t\t\tattr->rx_hibern8_time_cap);\n\t\t}\n\t} else if (attr->rx_adv_fine_gran_sup_en == 1) {\n\t\tfor_each_ufs_rx_lane(ufs, i) {\n\t\t\tif (attr->rx_adv_fine_gran_step)\n\t\t\t\tufshcd_dme_set(hba,\n\t\t\t\t\tUIC_ARG_MIB_SEL(RX_ADV_GRANULARITY_CAP,\n\t\t\t\t\t\ti), RX_ADV_FINE_GRAN_STEP(\n\t\t\t\t\t\tattr->rx_adv_fine_gran_step));\n\n\t\t\tif (attr->rx_adv_min_actv_time_cap)\n\t\t\t\tufshcd_dme_set(hba,\n\t\t\t\t\tUIC_ARG_MIB_SEL(\n\t\t\t\t\t\tRX_ADV_MIN_ACTIVATETIME_CAP, i),\n\t\t\t\t\t\tattr->rx_adv_min_actv_time_cap);\n\n\t\t\tif (attr->rx_adv_hibern8_time_cap)\n\t\t\t\tufshcd_dme_set(hba,\n\t\t\t\t\tUIC_ARG_MIB_SEL(RX_ADV_HIBERN8TIME_CAP,\n\t\t\t\t\t\ti),\n\t\t\t\t\t\tattr->rx_adv_hibern8_time_cap);\n\t\t}\n\t}\n\n\texynos_ufs_disable_ov_tm(hba);\n}\n\nstatic void exynos_ufs_establish_connt(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tenum {\n\t\tDEV_ID\t\t= 0x00,\n\t\tPEER_DEV_ID\t= 0x01,\n\t\tPEER_CPORT_ID\t= 0x00,\n\t\tTRAFFIC_CLASS\t= 0x00,\n\t};\n\n\t \n\tufshcd_dme_set(hba, UIC_ARG_MIB(T_CONNECTIONSTATE), CPORT_IDLE);\n\n\t \n\tufshcd_dme_set(hba, UIC_ARG_MIB(N_DEVICEID), DEV_ID);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(N_DEVICEID_VALID), true);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(T_PEERDEVICEID), PEER_DEV_ID);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(T_PEERCPORTID), PEER_CPORT_ID);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(T_CPORTFLAGS), CPORT_DEF_FLAGS);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(T_TRAFFICCLASS), TRAFFIC_CLASS);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(T_CONNECTIONSTATE), CPORT_CONNECTED);\n}\n\nstatic void exynos_ufs_config_smu(struct exynos_ufs *ufs)\n{\n\tu32 reg, val;\n\n\texynos_ufs_disable_auto_ctrl_hcc_save(ufs, &val);\n\n\t \n\treg = ufsp_readl(ufs, UFSPRSECURITY);\n\tufsp_writel(ufs, reg | NSSMU, UFSPRSECURITY);\n\tufsp_writel(ufs, 0x0, UFSPSBEGIN0);\n\tufsp_writel(ufs, 0xffffffff, UFSPSEND0);\n\tufsp_writel(ufs, 0xff, UFSPSLUN0);\n\tufsp_writel(ufs, 0xf1, UFSPSCTRL0);\n\n\texynos_ufs_auto_ctrl_hcc_restore(ufs, &val);\n}\n\nstatic void exynos_ufs_config_sync_pattern_mask(struct exynos_ufs *ufs,\n\t\t\t\t\tstruct ufs_pa_layer_attr *pwr)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tu8 g = max_t(u32, pwr->gear_rx, pwr->gear_tx);\n\tu32 mask, sync_len;\n\tenum {\n\t\tSYNC_LEN_G1 = 80 * 1000,  \n\t\tSYNC_LEN_G2 = 40 * 1000,  \n\t\tSYNC_LEN_G3 = 20 * 1000,  \n\t};\n\tint i;\n\n\tif (g == 1)\n\t\tsync_len = SYNC_LEN_G1;\n\telse if (g == 2)\n\t\tsync_len = SYNC_LEN_G2;\n\telse if (g == 3)\n\t\tsync_len = SYNC_LEN_G3;\n\telse\n\t\treturn;\n\n\tmask = exynos_ufs_calc_time_cntr(ufs, sync_len);\n\tmask = (mask >> 8) & 0xff;\n\n\texynos_ufs_enable_ov_tm(hba);\n\n\tfor_each_ufs_rx_lane(ufs, i)\n\t\tufshcd_dme_set(hba,\n\t\t\tUIC_ARG_MIB_SEL(RX_SYNC_MASK_LENGTH, i), mask);\n\n\texynos_ufs_disable_ov_tm(hba);\n}\n\nstatic int exynos_ufs_pre_pwr_mode(struct ufs_hba *hba,\n\t\t\t\tstruct ufs_pa_layer_attr *dev_max_params,\n\t\t\t\tstruct ufs_pa_layer_attr *dev_req_params)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\tstruct phy *generic_phy = ufs->phy;\n\tstruct ufs_dev_params ufs_exynos_cap;\n\tint ret;\n\n\tif (!dev_req_params) {\n\t\tpr_err(\"%s: incoming dev_req_params is NULL\\n\", __func__);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tufshcd_init_pwr_dev_param(&ufs_exynos_cap);\n\n\tret = ufshcd_get_pwr_dev_param(&ufs_exynos_cap,\n\t\t\t\t       dev_max_params, dev_req_params);\n\tif (ret) {\n\t\tpr_err(\"%s: failed to determine capabilities\\n\", __func__);\n\t\tgoto out;\n\t}\n\n\tif (ufs->drv_data->pre_pwr_change)\n\t\tufs->drv_data->pre_pwr_change(ufs, dev_req_params);\n\n\tif (ufshcd_is_hs_mode(dev_req_params)) {\n\t\texynos_ufs_config_sync_pattern_mask(ufs, dev_req_params);\n\n\t\tswitch (dev_req_params->hs_rate) {\n\t\tcase PA_HS_MODE_A:\n\t\tcase PA_HS_MODE_B:\n\t\t\tphy_calibrate(generic_phy);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tufshcd_dme_set(hba, UIC_ARG_MIB(DL_FC0PROTTIMEOUTVAL), 8064);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(DL_TC0REPLAYTIMEOUTVAL), 28224);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(DL_AFC0REQTIMEOUTVAL), 20160);\n\n\treturn 0;\nout:\n\treturn ret;\n}\n\n#define PWR_MODE_STR_LEN\t64\nstatic int exynos_ufs_post_pwr_mode(struct ufs_hba *hba,\n\t\t\t\tstruct ufs_pa_layer_attr *pwr_req)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\tstruct phy *generic_phy = ufs->phy;\n\tint gear = max_t(u32, pwr_req->gear_rx, pwr_req->gear_tx);\n\tint lanes = max_t(u32, pwr_req->lane_rx, pwr_req->lane_tx);\n\tchar pwr_str[PWR_MODE_STR_LEN] = \"\";\n\n\t \n\tif (!gear)\n\t\tgear = 1;\n\n\tif (!lanes)\n\t\tlanes = 1;\n\n\tif (ufs->drv_data->post_pwr_change)\n\t\tufs->drv_data->post_pwr_change(ufs, pwr_req);\n\n\tif ((ufshcd_is_hs_mode(pwr_req))) {\n\t\tswitch (pwr_req->hs_rate) {\n\t\tcase PA_HS_MODE_A:\n\t\tcase PA_HS_MODE_B:\n\t\t\tphy_calibrate(generic_phy);\n\t\t\tbreak;\n\t\t}\n\n\t\tsnprintf(pwr_str, PWR_MODE_STR_LEN, \"%s series_%s G_%d L_%d\",\n\t\t\t\"FAST\",\tpwr_req->hs_rate == PA_HS_MODE_A ? \"A\" : \"B\",\n\t\t\tgear, lanes);\n\t} else {\n\t\tsnprintf(pwr_str, PWR_MODE_STR_LEN, \"%s G_%d L_%d\",\n\t\t\t\"SLOW\", gear, lanes);\n\t}\n\n\tdev_info(hba->dev, \"Power mode changed to : %s\\n\", pwr_str);\n\n\treturn 0;\n}\n\nstatic void exynos_ufs_specify_nexus_t_xfer_req(struct ufs_hba *hba,\n\t\t\t\t\t\tint tag, bool is_scsi_cmd)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\tu32 type;\n\n\ttype =  hci_readl(ufs, HCI_UTRL_NEXUS_TYPE);\n\n\tif (is_scsi_cmd)\n\t\thci_writel(ufs, type | (1 << tag), HCI_UTRL_NEXUS_TYPE);\n\telse\n\t\thci_writel(ufs, type & ~(1 << tag), HCI_UTRL_NEXUS_TYPE);\n}\n\nstatic void exynos_ufs_specify_nexus_t_tm_req(struct ufs_hba *hba,\n\t\t\t\t\t\tint tag, u8 func)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\tu32 type;\n\n\ttype =  hci_readl(ufs, HCI_UTMRL_NEXUS_TYPE);\n\n\tswitch (func) {\n\tcase UFS_ABORT_TASK:\n\tcase UFS_QUERY_TASK:\n\t\thci_writel(ufs, type | (1 << tag), HCI_UTMRL_NEXUS_TYPE);\n\t\tbreak;\n\tcase UFS_ABORT_TASK_SET:\n\tcase UFS_CLEAR_TASK_SET:\n\tcase UFS_LOGICAL_RESET:\n\tcase UFS_QUERY_TASK_SET:\n\t\thci_writel(ufs, type & ~(1 << tag), HCI_UTMRL_NEXUS_TYPE);\n\t\tbreak;\n\t}\n}\n\nstatic int exynos_ufs_phy_init(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\tstruct phy *generic_phy = ufs->phy;\n\tint ret = 0;\n\n\tif (ufs->avail_ln_rx == 0 || ufs->avail_ln_tx == 0) {\n\t\tufshcd_dme_get(hba, UIC_ARG_MIB(PA_AVAILRXDATALANES),\n\t\t\t&ufs->avail_ln_rx);\n\t\tufshcd_dme_get(hba, UIC_ARG_MIB(PA_AVAILTXDATALANES),\n\t\t\t&ufs->avail_ln_tx);\n\t\tWARN(ufs->avail_ln_rx != ufs->avail_ln_tx,\n\t\t\t\"available data lane is not equal(rx:%d, tx:%d)\\n\",\n\t\t\tufs->avail_ln_rx, ufs->avail_ln_tx);\n\t}\n\n\tphy_set_bus_width(generic_phy, ufs->avail_ln_rx);\n\tret = phy_init(generic_phy);\n\tif (ret) {\n\t\tdev_err(hba->dev, \"%s: phy init failed, ret = %d\\n\",\n\t\t\t__func__, ret);\n\t\treturn ret;\n\t}\n\n\tret = phy_power_on(generic_phy);\n\tif (ret)\n\t\tgoto out_exit_phy;\n\n\treturn 0;\n\nout_exit_phy:\n\tphy_exit(generic_phy);\n\n\treturn ret;\n}\n\nstatic void exynos_ufs_config_unipro(struct exynos_ufs *ufs)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_CLK_PERIOD),\n\t\tDIV_ROUND_UP(NSEC_PER_SEC, ufs->mclk_rate));\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_TXTRAILINGCLOCKS),\n\t\t\tufs->drv_data->uic_attr->tx_trailingclks);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_OPTION_SUITE),\n\t\t\tufs->drv_data->uic_attr->pa_dbg_option_suite);\n}\n\nstatic void exynos_ufs_config_intr(struct exynos_ufs *ufs, u32 errs, u8 index)\n{\n\tswitch (index) {\n\tcase UNIPRO_L1_5:\n\t\thci_writel(ufs, DFES_ERR_EN | errs, HCI_ERR_EN_PA_LAYER);\n\t\tbreak;\n\tcase UNIPRO_L2:\n\t\thci_writel(ufs, DFES_ERR_EN | errs, HCI_ERR_EN_DL_LAYER);\n\t\tbreak;\n\tcase UNIPRO_L3:\n\t\thci_writel(ufs, DFES_ERR_EN | errs, HCI_ERR_EN_N_LAYER);\n\t\tbreak;\n\tcase UNIPRO_L4:\n\t\thci_writel(ufs, DFES_ERR_EN | errs, HCI_ERR_EN_T_LAYER);\n\t\tbreak;\n\tcase UNIPRO_DME:\n\t\thci_writel(ufs, DFES_ERR_EN | errs, HCI_ERR_EN_DME_LAYER);\n\t\tbreak;\n\t}\n}\n\nstatic int exynos_ufs_setup_clocks(struct ufs_hba *hba, bool on,\n\t\t\t\t   enum ufs_notify_change_status status)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\n\tif (!ufs)\n\t\treturn 0;\n\n\tif (on && status == PRE_CHANGE) {\n\t\tif (ufs->opts & EXYNOS_UFS_OPT_BROKEN_AUTO_CLK_CTRL)\n\t\t\texynos_ufs_disable_auto_ctrl_hcc(ufs);\n\t\texynos_ufs_ungate_clks(ufs);\n\t} else if (!on && status == POST_CHANGE) {\n\t\texynos_ufs_gate_clks(ufs);\n\t\tif (ufs->opts & EXYNOS_UFS_OPT_BROKEN_AUTO_CLK_CTRL)\n\t\t\texynos_ufs_enable_auto_ctrl_hcc(ufs);\n\t}\n\n\treturn 0;\n}\n\nstatic int exynos_ufs_pre_link(struct ufs_hba *hba)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\n\t \n\texynos_ufs_config_intr(ufs, DFES_DEF_L2_ERRS, UNIPRO_L2);\n\texynos_ufs_config_intr(ufs, DFES_DEF_L3_ERRS, UNIPRO_L3);\n\texynos_ufs_config_intr(ufs, DFES_DEF_L4_ERRS, UNIPRO_L4);\n\texynos_ufs_set_unipro_pclk_div(ufs);\n\n\t \n\texynos_ufs_config_unipro(ufs);\n\n\t \n\texynos_ufs_phy_init(ufs);\n\tif (!(ufs->opts & EXYNOS_UFS_OPT_SKIP_CONFIG_PHY_ATTR)) {\n\t\texynos_ufs_config_phy_time_attr(ufs);\n\t\texynos_ufs_config_phy_cap_attr(ufs);\n\t}\n\n\texynos_ufs_setup_clocks(hba, true, PRE_CHANGE);\n\n\tif (ufs->drv_data->pre_link)\n\t\tufs->drv_data->pre_link(ufs);\n\n\treturn 0;\n}\n\nstatic void exynos_ufs_fit_aggr_timeout(struct exynos_ufs *ufs)\n{\n\tu32 val;\n\n\tval = exynos_ufs_calc_time_cntr(ufs, IATOVAL_NSEC / CNTR_DIV_VAL);\n\thci_writel(ufs, val & CNT_VAL_1US_MASK, HCI_1US_TO_CNT_VAL);\n}\n\nstatic int exynos_ufs_post_link(struct ufs_hba *hba)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\tstruct phy *generic_phy = ufs->phy;\n\tstruct exynos_ufs_uic_attr *attr = ufs->drv_data->uic_attr;\n\n\texynos_ufs_establish_connt(ufs);\n\texynos_ufs_fit_aggr_timeout(ufs);\n\n\thci_writel(ufs, 0xa, HCI_DATA_REORDER);\n\thci_writel(ufs, PRDT_SET_SIZE(12), HCI_TXPRDT_ENTRY_SIZE);\n\thci_writel(ufs, PRDT_SET_SIZE(12), HCI_RXPRDT_ENTRY_SIZE);\n\thci_writel(ufs, (1 << hba->nutrs) - 1, HCI_UTRL_NEXUS_TYPE);\n\thci_writel(ufs, (1 << hba->nutmrs) - 1, HCI_UTMRL_NEXUS_TYPE);\n\thci_writel(ufs, 0xf, HCI_AXIDMA_RWDATA_BURST_LEN);\n\n\tif (ufs->opts & EXYNOS_UFS_OPT_SKIP_CONNECTION_ESTAB)\n\t\tufshcd_dme_set(hba,\n\t\t\tUIC_ARG_MIB(T_DBG_SKIP_INIT_HIBERN8_EXIT), true);\n\n\tif (attr->pa_granularity) {\n\t\texynos_ufs_enable_dbg_mode(hba);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_GRANULARITY),\n\t\t\t\tattr->pa_granularity);\n\t\texynos_ufs_disable_dbg_mode(hba);\n\n\t\tif (attr->pa_tactivate)\n\t\t\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_TACTIVATE),\n\t\t\t\t\tattr->pa_tactivate);\n\t\tif (attr->pa_hibern8time &&\n\t\t    !(ufs->opts & EXYNOS_UFS_OPT_USE_SW_HIBERN8_TIMER))\n\t\t\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_HIBERN8TIME),\n\t\t\t\t\tattr->pa_hibern8time);\n\t}\n\n\tif (ufs->opts & EXYNOS_UFS_OPT_USE_SW_HIBERN8_TIMER) {\n\t\tif (!attr->pa_granularity)\n\t\t\tufshcd_dme_get(hba, UIC_ARG_MIB(PA_GRANULARITY),\n\t\t\t\t\t&attr->pa_granularity);\n\t\tif (!attr->pa_hibern8time)\n\t\t\tufshcd_dme_get(hba, UIC_ARG_MIB(PA_HIBERN8TIME),\n\t\t\t\t\t&attr->pa_hibern8time);\n\t\t \n\t\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_HIBERN8TIME), 0);\n\n\t\tif (attr->pa_granularity < 1 || attr->pa_granularity > 6) {\n\t\t\t \n\t\t\tdev_warn(hba->dev,\n\t\t\t\t\"%s: pa_granularity %d is invalid, assuming backwards compatibility\\n\",\n\t\t\t\t__func__,\n\t\t\t\tattr->pa_granularity);\n\t\t\tattr->pa_granularity = 6;\n\t\t}\n\t}\n\n\tphy_calibrate(generic_phy);\n\n\tif (ufs->drv_data->post_link)\n\t\tufs->drv_data->post_link(ufs);\n\n\treturn 0;\n}\n\nstatic int exynos_ufs_parse_dt(struct device *dev, struct exynos_ufs *ufs)\n{\n\tstruct device_node *np = dev->of_node;\n\tstruct exynos_ufs_uic_attr *attr;\n\tint ret = 0;\n\n\tufs->drv_data = device_get_match_data(dev);\n\n\tif (ufs->drv_data && ufs->drv_data->uic_attr) {\n\t\tattr = ufs->drv_data->uic_attr;\n\t} else {\n\t\tdev_err(dev, \"failed to get uic attributes\\n\");\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tufs->sysreg = syscon_regmap_lookup_by_phandle(np, \"samsung,sysreg\");\n\tif (IS_ERR(ufs->sysreg))\n\t\tufs->sysreg = NULL;\n\telse {\n\t\tif (of_property_read_u32_index(np, \"samsung,sysreg\", 1,\n\t\t\t\t\t       &ufs->shareability_reg_offset)) {\n\t\t\tdev_warn(dev, \"can't get an offset from sysreg. Set to default value\\n\");\n\t\t\tufs->shareability_reg_offset = UFS_SHAREABILITY_OFFSET;\n\t\t}\n\t}\n\n\tufs->pclk_avail_min = PCLK_AVAIL_MIN;\n\tufs->pclk_avail_max = PCLK_AVAIL_MAX;\n\n\tattr->rx_adv_fine_gran_sup_en = RX_ADV_FINE_GRAN_SUP_EN;\n\tattr->rx_adv_fine_gran_step = RX_ADV_FINE_GRAN_STEP_VAL;\n\tattr->rx_adv_min_actv_time_cap = RX_ADV_MIN_ACTV_TIME_CAP;\n\tattr->pa_granularity = PA_GRANULARITY_VAL;\n\tattr->pa_tactivate = PA_TACTIVATE_VAL;\n\tattr->pa_hibern8time = PA_HIBERN8TIME_VAL;\n\nout:\n\treturn ret;\n}\n\nstatic inline void exynos_ufs_priv_init(struct ufs_hba *hba,\n\t\t\t\t\tstruct exynos_ufs *ufs)\n{\n\tufs->hba = hba;\n\tufs->opts = ufs->drv_data->opts;\n\tufs->rx_sel_idx = PA_MAXDATALANES;\n\tif (ufs->opts & EXYNOS_UFS_OPT_BROKEN_RX_SEL_IDX)\n\t\tufs->rx_sel_idx = 0;\n\thba->priv = (void *)ufs;\n\thba->quirks = ufs->drv_data->quirks;\n}\n\nstatic int exynos_ufs_init(struct ufs_hba *hba)\n{\n\tstruct device *dev = hba->dev;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct exynos_ufs *ufs;\n\tint ret;\n\n\tufs = devm_kzalloc(dev, sizeof(*ufs), GFP_KERNEL);\n\tif (!ufs)\n\t\treturn -ENOMEM;\n\n\t \n\tufs->reg_hci = devm_platform_ioremap_resource_byname(pdev, \"vs_hci\");\n\tif (IS_ERR(ufs->reg_hci)) {\n\t\tdev_err(dev, \"cannot ioremap for hci vendor register\\n\");\n\t\treturn PTR_ERR(ufs->reg_hci);\n\t}\n\n\t \n\tufs->reg_unipro = devm_platform_ioremap_resource_byname(pdev, \"unipro\");\n\tif (IS_ERR(ufs->reg_unipro)) {\n\t\tdev_err(dev, \"cannot ioremap for unipro register\\n\");\n\t\treturn PTR_ERR(ufs->reg_unipro);\n\t}\n\n\t \n\tufs->reg_ufsp = devm_platform_ioremap_resource_byname(pdev, \"ufsp\");\n\tif (IS_ERR(ufs->reg_ufsp)) {\n\t\tdev_err(dev, \"cannot ioremap for ufs protector register\\n\");\n\t\treturn PTR_ERR(ufs->reg_ufsp);\n\t}\n\n\tret = exynos_ufs_parse_dt(dev, ufs);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to get dt info.\\n\");\n\t\tgoto out;\n\t}\n\n\tufs->phy = devm_phy_get(dev, \"ufs-phy\");\n\tif (IS_ERR(ufs->phy)) {\n\t\tret = PTR_ERR(ufs->phy);\n\t\tdev_err(dev, \"failed to get ufs-phy\\n\");\n\t\tgoto out;\n\t}\n\n\texynos_ufs_priv_init(hba, ufs);\n\n\tif (ufs->drv_data->drv_init) {\n\t\tret = ufs->drv_data->drv_init(dev, ufs);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"failed to init drv-data\\n\");\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = exynos_ufs_get_clk_info(ufs);\n\tif (ret)\n\t\tgoto out;\n\texynos_ufs_specify_phy_time_attr(ufs);\n\texynos_ufs_config_smu(ufs);\n\treturn 0;\n\nout:\n\thba->priv = NULL;\n\treturn ret;\n}\n\nstatic int exynos_ufs_host_reset(struct ufs_hba *hba)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\tunsigned long timeout = jiffies + msecs_to_jiffies(1);\n\tu32 val;\n\tint ret = 0;\n\n\texynos_ufs_disable_auto_ctrl_hcc_save(ufs, &val);\n\n\thci_writel(ufs, UFS_SW_RST_MASK, HCI_SW_RST);\n\n\tdo {\n\t\tif (!(hci_readl(ufs, HCI_SW_RST) & UFS_SW_RST_MASK))\n\t\t\tgoto out;\n\t} while (time_before(jiffies, timeout));\n\n\tdev_err(hba->dev, \"timeout host sw-reset\\n\");\n\tret = -ETIMEDOUT;\n\nout:\n\texynos_ufs_auto_ctrl_hcc_restore(ufs, &val);\n\treturn ret;\n}\n\nstatic void exynos_ufs_dev_hw_reset(struct ufs_hba *hba)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\n\thci_writel(ufs, 0 << 0, HCI_GPIO_OUT);\n\tudelay(5);\n\thci_writel(ufs, 1 << 0, HCI_GPIO_OUT);\n}\n\nstatic void exynos_ufs_pre_hibern8(struct ufs_hba *hba, u8 enter)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\tstruct exynos_ufs_uic_attr *attr = ufs->drv_data->uic_attr;\n\n\tif (!enter) {\n\t\tif (ufs->opts & EXYNOS_UFS_OPT_BROKEN_AUTO_CLK_CTRL)\n\t\t\texynos_ufs_disable_auto_ctrl_hcc(ufs);\n\t\texynos_ufs_ungate_clks(ufs);\n\n\t\tif (ufs->opts & EXYNOS_UFS_OPT_USE_SW_HIBERN8_TIMER) {\n\t\t\tstatic const unsigned int granularity_tbl[] = {\n\t\t\t\t1, 4, 8, 16, 32, 100\n\t\t\t};\n\t\t\tint h8_time = attr->pa_hibern8time *\n\t\t\t\tgranularity_tbl[attr->pa_granularity - 1];\n\t\t\tunsigned long us;\n\t\t\ts64 delta;\n\n\t\t\tdo {\n\t\t\t\tdelta = h8_time - ktime_us_delta(ktime_get(),\n\t\t\t\t\t\t\tufs->entry_hibern8_t);\n\t\t\t\tif (delta <= 0)\n\t\t\t\t\tbreak;\n\n\t\t\t\tus = min_t(s64, delta, USEC_PER_MSEC);\n\t\t\t\tif (us >= 10)\n\t\t\t\t\tusleep_range(us, us + 10);\n\t\t\t} while (1);\n\t\t}\n\t}\n}\n\nstatic void exynos_ufs_post_hibern8(struct ufs_hba *hba, u8 enter)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\n\tif (!enter) {\n\t\tu32 cur_mode = 0;\n\t\tu32 pwrmode;\n\n\t\tif (ufshcd_is_hs_mode(&ufs->dev_req_params))\n\t\t\tpwrmode = FAST_MODE;\n\t\telse\n\t\t\tpwrmode = SLOW_MODE;\n\n\t\tufshcd_dme_get(hba, UIC_ARG_MIB(PA_PWRMODE), &cur_mode);\n\t\tif (cur_mode != (pwrmode << 4 | pwrmode)) {\n\t\t\tdev_warn(hba->dev, \"%s: power mode change\\n\", __func__);\n\t\t\thba->pwr_info.pwr_rx = (cur_mode >> 4) & 0xf;\n\t\t\thba->pwr_info.pwr_tx = cur_mode & 0xf;\n\t\t\tufshcd_config_pwr_mode(hba, &hba->max_pwr_info.info);\n\t\t}\n\n\t\tif (!(ufs->opts & EXYNOS_UFS_OPT_SKIP_CONNECTION_ESTAB))\n\t\t\texynos_ufs_establish_connt(ufs);\n\t} else {\n\t\tufs->entry_hibern8_t = ktime_get();\n\t\texynos_ufs_gate_clks(ufs);\n\t\tif (ufs->opts & EXYNOS_UFS_OPT_BROKEN_AUTO_CLK_CTRL)\n\t\t\texynos_ufs_enable_auto_ctrl_hcc(ufs);\n\t}\n}\n\nstatic int exynos_ufs_hce_enable_notify(struct ufs_hba *hba,\n\t\t\t\t\tenum ufs_notify_change_status status)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\tint ret = 0;\n\n\tswitch (status) {\n\tcase PRE_CHANGE:\n\t\t \n\t\thba->host->max_segment_size = SZ_4K;\n\n\t\tif (ufs->drv_data->pre_hce_enable) {\n\t\t\tret = ufs->drv_data->pre_hce_enable(ufs);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tret = exynos_ufs_host_reset(hba);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\texynos_ufs_dev_hw_reset(hba);\n\t\tbreak;\n\tcase POST_CHANGE:\n\t\texynos_ufs_calc_pwm_clk_div(ufs);\n\t\tif (!(ufs->opts & EXYNOS_UFS_OPT_BROKEN_AUTO_CLK_CTRL))\n\t\t\texynos_ufs_enable_auto_ctrl_hcc(ufs);\n\n\t\tif (ufs->drv_data->post_hce_enable)\n\t\t\tret = ufs->drv_data->post_hce_enable(ufs);\n\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int exynos_ufs_link_startup_notify(struct ufs_hba *hba,\n\t\t\t\t\t  enum ufs_notify_change_status status)\n{\n\tint ret = 0;\n\n\tswitch (status) {\n\tcase PRE_CHANGE:\n\t\tret = exynos_ufs_pre_link(hba);\n\t\tbreak;\n\tcase POST_CHANGE:\n\t\tret = exynos_ufs_post_link(hba);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int exynos_ufs_pwr_change_notify(struct ufs_hba *hba,\n\t\t\t\tenum ufs_notify_change_status status,\n\t\t\t\tstruct ufs_pa_layer_attr *dev_max_params,\n\t\t\t\tstruct ufs_pa_layer_attr *dev_req_params)\n{\n\tint ret = 0;\n\n\tswitch (status) {\n\tcase PRE_CHANGE:\n\t\tret = exynos_ufs_pre_pwr_mode(hba, dev_max_params,\n\t\t\t\t\t      dev_req_params);\n\t\tbreak;\n\tcase POST_CHANGE:\n\t\tret = exynos_ufs_post_pwr_mode(hba, dev_req_params);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic void exynos_ufs_hibern8_notify(struct ufs_hba *hba,\n\t\t\t\t     enum uic_cmd_dme enter,\n\t\t\t\t     enum ufs_notify_change_status notify)\n{\n\tswitch ((u8)notify) {\n\tcase PRE_CHANGE:\n\t\texynos_ufs_pre_hibern8(hba, enter);\n\t\tbreak;\n\tcase POST_CHANGE:\n\t\texynos_ufs_post_hibern8(hba, enter);\n\t\tbreak;\n\t}\n}\n\nstatic int exynos_ufs_suspend(struct ufs_hba *hba, enum ufs_pm_op pm_op,\n\tenum ufs_notify_change_status status)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\n\tif (status == PRE_CHANGE)\n\t\treturn 0;\n\n\tif (!ufshcd_is_link_active(hba))\n\t\tphy_power_off(ufs->phy);\n\n\treturn 0;\n}\n\nstatic int exynos_ufs_resume(struct ufs_hba *hba, enum ufs_pm_op pm_op)\n{\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\n\tif (!ufshcd_is_link_active(hba))\n\t\tphy_power_on(ufs->phy);\n\n\texynos_ufs_config_smu(ufs);\n\n\treturn 0;\n}\n\nstatic int exynosauto_ufs_vh_link_startup_notify(struct ufs_hba *hba,\n\t\t\t\t\t\t enum ufs_notify_change_status status)\n{\n\tif (status == POST_CHANGE) {\n\t\tufshcd_set_link_active(hba);\n\t\tufshcd_set_ufs_dev_active(hba);\n\t}\n\n\treturn 0;\n}\n\nstatic int exynosauto_ufs_vh_wait_ph_ready(struct ufs_hba *hba)\n{\n\tu32 mbox;\n\tktime_t start, stop;\n\n\tstart = ktime_get();\n\tstop = ktime_add(start, ms_to_ktime(PH_READY_TIMEOUT_MS));\n\n\tdo {\n\t\tmbox = ufshcd_readl(hba, PH2VH_MBOX);\n\t\t \n\t\tif ((mbox & MH_MSG_MASK) == MH_MSG_PH_READY)\n\t\t\treturn 0;\n\n\t\tusleep_range(40, 50);\n\t} while (ktime_before(ktime_get(), stop));\n\n\treturn -ETIME;\n}\n\nstatic int exynosauto_ufs_vh_init(struct ufs_hba *hba)\n{\n\tstruct device *dev = hba->dev;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct exynos_ufs *ufs;\n\tint ret;\n\n\tufs = devm_kzalloc(dev, sizeof(*ufs), GFP_KERNEL);\n\tif (!ufs)\n\t\treturn -ENOMEM;\n\n\t \n\tufs->reg_hci = devm_platform_ioremap_resource_byname(pdev, \"vs_hci\");\n\tif (IS_ERR(ufs->reg_hci)) {\n\t\tdev_err(dev, \"cannot ioremap for hci vendor register\\n\");\n\t\treturn PTR_ERR(ufs->reg_hci);\n\t}\n\n\tret = exynosauto_ufs_vh_wait_ph_ready(hba);\n\tif (ret)\n\t\treturn ret;\n\n\tufs->drv_data = device_get_match_data(dev);\n\tif (!ufs->drv_data)\n\t\treturn -ENODEV;\n\n\texynos_ufs_priv_init(hba, ufs);\n\n\treturn 0;\n}\n\nstatic int fsd_ufs_pre_link(struct exynos_ufs *ufs)\n{\n\tint i;\n\tstruct ufs_hba *hba = ufs->hba;\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_CLK_PERIOD),\n\t\t       DIV_ROUND_UP(NSEC_PER_SEC,  ufs->mclk_rate));\n\tufshcd_dme_set(hba, UIC_ARG_MIB(0x201), 0x12);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(0x200), 0x40);\n\n\tfor_each_ufs_tx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0xAA, i),\n\t\t\t       DIV_ROUND_UP(NSEC_PER_SEC, ufs->mclk_rate));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x8F, i), 0x3F);\n\t}\n\n\tfor_each_ufs_rx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x12, i),\n\t\t\t       DIV_ROUND_UP(NSEC_PER_SEC, ufs->mclk_rate));\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x5C, i), 0x38);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x0F, i), 0x0);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x65, i), 0x1);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x69, i), 0x1);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x21, i), 0x0);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x22, i), 0x0);\n\t}\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(0x200), 0x0);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_AUTOMODE_THLD), 0x4E20);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_OPTION_SUITE), 0x2e820183);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_LOCAL_TX_LCC_ENABLE), 0x0);\n\n\texynos_ufs_establish_connt(ufs);\n\n\treturn 0;\n}\n\nstatic int fsd_ufs_post_link(struct exynos_ufs *ufs)\n{\n\tint i;\n\tstruct ufs_hba *hba = ufs->hba;\n\tu32 hw_cap_min_tactivate;\n\tu32 peer_rx_min_actv_time_cap;\n\tu32 max_rx_hibern8_time_cap;\n\n\tufshcd_dme_get(hba, UIC_ARG_MIB_SEL(0x8F, 4),\n\t\t\t&hw_cap_min_tactivate);  \n\tufshcd_dme_get(hba, UIC_ARG_MIB(PA_TACTIVATE),\n\t\t\t&peer_rx_min_actv_time_cap);     \n\tufshcd_dme_get(hba, UIC_ARG_MIB(PA_HIBERN8TIME),\n\t\t\t&max_rx_hibern8_time_cap);       \n\n\tif (peer_rx_min_actv_time_cap >= hw_cap_min_tactivate)\n\t\tufshcd_dme_peer_set(hba, UIC_ARG_MIB(PA_TACTIVATE),\n\t\t\t\t\tpeer_rx_min_actv_time_cap + 1);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_HIBERN8TIME), max_rx_hibern8_time_cap + 1);\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_MODE), 0x01);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_SAVECONFIGTIME), 0xFA);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_DBG_MODE), 0x00);\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(0x200), 0x40);\n\n\tfor_each_ufs_rx_lane(ufs, i) {\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x35, i), 0x05);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x73, i), 0x01);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x41, i), 0x02);\n\t\tufshcd_dme_set(hba, UIC_ARG_MIB_SEL(0x42, i), 0xAC);\n\t}\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(0x200), 0x0);\n\n\treturn 0;\n}\n\nstatic int fsd_ufs_pre_pwr_change(struct exynos_ufs *ufs,\n\t\t\t\t\tstruct ufs_pa_layer_attr *pwr)\n{\n\tstruct ufs_hba *hba = ufs->hba;\n\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_TXTERMINATION), 0x1);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_RXTERMINATION), 0x1);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_PWRMODEUSERDATA0), 12000);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_PWRMODEUSERDATA1), 32000);\n\tufshcd_dme_set(hba, UIC_ARG_MIB(PA_PWRMODEUSERDATA2), 16000);\n\n\tunipro_writel(ufs, 12000, UNIPRO_DME_POWERMODE_REQ_REMOTEL2TIMER0);\n\tunipro_writel(ufs, 32000, UNIPRO_DME_POWERMODE_REQ_REMOTEL2TIMER1);\n\tunipro_writel(ufs, 16000, UNIPRO_DME_POWERMODE_REQ_REMOTEL2TIMER2);\n\n\treturn 0;\n}\n\nstatic const struct ufs_hba_variant_ops ufs_hba_exynos_ops = {\n\t.name\t\t\t\t= \"exynos_ufs\",\n\t.init\t\t\t\t= exynos_ufs_init,\n\t.hce_enable_notify\t\t= exynos_ufs_hce_enable_notify,\n\t.link_startup_notify\t\t= exynos_ufs_link_startup_notify,\n\t.pwr_change_notify\t\t= exynos_ufs_pwr_change_notify,\n\t.setup_clocks\t\t\t= exynos_ufs_setup_clocks,\n\t.setup_xfer_req\t\t\t= exynos_ufs_specify_nexus_t_xfer_req,\n\t.setup_task_mgmt\t\t= exynos_ufs_specify_nexus_t_tm_req,\n\t.hibern8_notify\t\t\t= exynos_ufs_hibern8_notify,\n\t.suspend\t\t\t= exynos_ufs_suspend,\n\t.resume\t\t\t\t= exynos_ufs_resume,\n};\n\nstatic struct ufs_hba_variant_ops ufs_hba_exynosauto_vh_ops = {\n\t.name\t\t\t\t= \"exynosauto_ufs_vh\",\n\t.init\t\t\t\t= exynosauto_ufs_vh_init,\n\t.link_startup_notify\t\t= exynosauto_ufs_vh_link_startup_notify,\n};\n\nstatic int exynos_ufs_probe(struct platform_device *pdev)\n{\n\tint err;\n\tstruct device *dev = &pdev->dev;\n\tconst struct ufs_hba_variant_ops *vops = &ufs_hba_exynos_ops;\n\tconst struct exynos_ufs_drv_data *drv_data =\n\t\tdevice_get_match_data(dev);\n\n\tif (drv_data && drv_data->vops)\n\t\tvops = drv_data->vops;\n\n\terr = ufshcd_pltfrm_init(pdev, vops);\n\tif (err)\n\t\tdev_err(dev, \"ufshcd_pltfrm_init() failed %d\\n\", err);\n\n\treturn err;\n}\n\nstatic int exynos_ufs_remove(struct platform_device *pdev)\n{\n\tstruct ufs_hba *hba =  platform_get_drvdata(pdev);\n\tstruct exynos_ufs *ufs = ufshcd_get_variant(hba);\n\n\tpm_runtime_get_sync(&(pdev)->dev);\n\tufshcd_remove(hba);\n\n\tphy_power_off(ufs->phy);\n\tphy_exit(ufs->phy);\n\n\treturn 0;\n}\n\nstatic struct exynos_ufs_uic_attr exynos7_uic_attr = {\n\t.tx_trailingclks\t\t= 0x10,\n\t.tx_dif_p_nsec\t\t\t= 3000000,\t \n\t.tx_dif_n_nsec\t\t\t= 1000000,\t \n\t.tx_high_z_cnt_nsec\t\t= 20000,\t \n\t.tx_base_unit_nsec\t\t= 100000,\t \n\t.tx_gran_unit_nsec\t\t= 4000,\t\t \n\t.tx_sleep_cnt\t\t\t= 1000,\t\t \n\t.tx_min_activatetime\t\t= 0xa,\n\t.rx_filler_enable\t\t= 0x2,\n\t.rx_dif_p_nsec\t\t\t= 1000000,\t \n\t.rx_hibern8_wait_nsec\t\t= 4000000,\t \n\t.rx_base_unit_nsec\t\t= 100000,\t \n\t.rx_gran_unit_nsec\t\t= 4000,\t\t \n\t.rx_sleep_cnt\t\t\t= 1280,\t\t \n\t.rx_stall_cnt\t\t\t= 320,\t\t \n\t.rx_hs_g1_sync_len_cap\t\t= SYNC_LEN_COARSE(0xf),\n\t.rx_hs_g2_sync_len_cap\t\t= SYNC_LEN_COARSE(0xf),\n\t.rx_hs_g3_sync_len_cap\t\t= SYNC_LEN_COARSE(0xf),\n\t.rx_hs_g1_prep_sync_len_cap\t= PREP_LEN(0xf),\n\t.rx_hs_g2_prep_sync_len_cap\t= PREP_LEN(0xf),\n\t.rx_hs_g3_prep_sync_len_cap\t= PREP_LEN(0xf),\n\t.pa_dbg_option_suite\t\t= 0x30103,\n};\n\nstatic const struct exynos_ufs_drv_data exynosauto_ufs_drvs = {\n\t.uic_attr\t\t= &exynos7_uic_attr,\n\t.quirks\t\t\t= UFSHCD_QUIRK_PRDT_BYTE_GRAN |\n\t\t\t\t  UFSHCI_QUIRK_SKIP_RESET_INTR_AGGR |\n\t\t\t\t  UFSHCD_QUIRK_BROKEN_OCS_FATAL_ERROR |\n\t\t\t\t  UFSHCD_QUIRK_SKIP_DEF_UNIPRO_TIMEOUT_SETTING,\n\t.opts\t\t\t= EXYNOS_UFS_OPT_BROKEN_AUTO_CLK_CTRL |\n\t\t\t\t  EXYNOS_UFS_OPT_SKIP_CONFIG_PHY_ATTR |\n\t\t\t\t  EXYNOS_UFS_OPT_BROKEN_RX_SEL_IDX,\n\t.drv_init\t\t= exynosauto_ufs_drv_init,\n\t.post_hce_enable\t= exynosauto_ufs_post_hce_enable,\n\t.pre_link\t\t= exynosauto_ufs_pre_link,\n\t.pre_pwr_change\t\t= exynosauto_ufs_pre_pwr_change,\n\t.post_pwr_change\t= exynosauto_ufs_post_pwr_change,\n};\n\nstatic const struct exynos_ufs_drv_data exynosauto_ufs_vh_drvs = {\n\t.vops\t\t\t= &ufs_hba_exynosauto_vh_ops,\n\t.quirks\t\t\t= UFSHCD_QUIRK_PRDT_BYTE_GRAN |\n\t\t\t\t  UFSHCI_QUIRK_SKIP_RESET_INTR_AGGR |\n\t\t\t\t  UFSHCD_QUIRK_BROKEN_OCS_FATAL_ERROR |\n\t\t\t\t  UFSHCI_QUIRK_BROKEN_HCE |\n\t\t\t\t  UFSHCD_QUIRK_BROKEN_UIC_CMD |\n\t\t\t\t  UFSHCD_QUIRK_SKIP_PH_CONFIGURATION |\n\t\t\t\t  UFSHCD_QUIRK_SKIP_DEF_UNIPRO_TIMEOUT_SETTING,\n\t.opts\t\t\t= EXYNOS_UFS_OPT_BROKEN_RX_SEL_IDX,\n};\n\nstatic const struct exynos_ufs_drv_data exynos_ufs_drvs = {\n\t.uic_attr\t\t= &exynos7_uic_attr,\n\t.quirks\t\t\t= UFSHCD_QUIRK_PRDT_BYTE_GRAN |\n\t\t\t\t  UFSHCI_QUIRK_BROKEN_REQ_LIST_CLR |\n\t\t\t\t  UFSHCI_QUIRK_BROKEN_HCE |\n\t\t\t\t  UFSHCI_QUIRK_SKIP_RESET_INTR_AGGR |\n\t\t\t\t  UFSHCD_QUIRK_BROKEN_OCS_FATAL_ERROR |\n\t\t\t\t  UFSHCI_QUIRK_SKIP_MANUAL_WB_FLUSH_CTRL |\n\t\t\t\t  UFSHCD_QUIRK_SKIP_DEF_UNIPRO_TIMEOUT_SETTING |\n\t\t\t\t  UFSHCD_QUIRK_4KB_DMA_ALIGNMENT,\n\t.opts\t\t\t= EXYNOS_UFS_OPT_HAS_APB_CLK_CTRL |\n\t\t\t\t  EXYNOS_UFS_OPT_BROKEN_AUTO_CLK_CTRL |\n\t\t\t\t  EXYNOS_UFS_OPT_BROKEN_RX_SEL_IDX |\n\t\t\t\t  EXYNOS_UFS_OPT_SKIP_CONNECTION_ESTAB |\n\t\t\t\t  EXYNOS_UFS_OPT_USE_SW_HIBERN8_TIMER,\n\t.drv_init\t\t= exynos7_ufs_drv_init,\n\t.pre_link\t\t= exynos7_ufs_pre_link,\n\t.post_link\t\t= exynos7_ufs_post_link,\n\t.pre_pwr_change\t\t= exynos7_ufs_pre_pwr_change,\n\t.post_pwr_change\t= exynos7_ufs_post_pwr_change,\n};\n\nstatic struct exynos_ufs_uic_attr fsd_uic_attr = {\n\t.tx_trailingclks\t\t= 0x10,\n\t.tx_dif_p_nsec\t\t\t= 3000000,\t \n\t.tx_dif_n_nsec\t\t\t= 1000000,\t \n\t.tx_high_z_cnt_nsec\t\t= 20000,\t \n\t.tx_base_unit_nsec\t\t= 100000,\t \n\t.tx_gran_unit_nsec\t\t= 4000,\t\t \n\t.tx_sleep_cnt\t\t\t= 1000,\t\t \n\t.tx_min_activatetime\t\t= 0xa,\n\t.rx_filler_enable\t\t= 0x2,\n\t.rx_dif_p_nsec\t\t\t= 1000000,\t \n\t.rx_hibern8_wait_nsec\t\t= 4000000,\t \n\t.rx_base_unit_nsec\t\t= 100000,\t \n\t.rx_gran_unit_nsec\t\t= 4000,\t\t \n\t.rx_sleep_cnt\t\t\t= 1280,\t\t \n\t.rx_stall_cnt\t\t\t= 320,\t\t \n\t.rx_hs_g1_sync_len_cap\t\t= SYNC_LEN_COARSE(0xf),\n\t.rx_hs_g2_sync_len_cap\t\t= SYNC_LEN_COARSE(0xf),\n\t.rx_hs_g3_sync_len_cap\t\t= SYNC_LEN_COARSE(0xf),\n\t.rx_hs_g1_prep_sync_len_cap\t= PREP_LEN(0xf),\n\t.rx_hs_g2_prep_sync_len_cap\t= PREP_LEN(0xf),\n\t.rx_hs_g3_prep_sync_len_cap\t= PREP_LEN(0xf),\n\t.pa_dbg_option_suite\t\t= 0x2E820183,\n};\n\nstatic const struct exynos_ufs_drv_data fsd_ufs_drvs = {\n\t.uic_attr               = &fsd_uic_attr,\n\t.quirks                 = UFSHCD_QUIRK_PRDT_BYTE_GRAN |\n\t\t\t\t  UFSHCI_QUIRK_BROKEN_REQ_LIST_CLR |\n\t\t\t\t  UFSHCD_QUIRK_BROKEN_OCS_FATAL_ERROR |\n\t\t\t\t  UFSHCD_QUIRK_SKIP_DEF_UNIPRO_TIMEOUT_SETTING |\n\t\t\t\t  UFSHCI_QUIRK_SKIP_RESET_INTR_AGGR,\n\t.opts                   = EXYNOS_UFS_OPT_HAS_APB_CLK_CTRL |\n\t\t\t\t  EXYNOS_UFS_OPT_BROKEN_AUTO_CLK_CTRL |\n\t\t\t\t  EXYNOS_UFS_OPT_SKIP_CONFIG_PHY_ATTR |\n\t\t\t\t  EXYNOS_UFS_OPT_BROKEN_RX_SEL_IDX,\n\t.pre_link               = fsd_ufs_pre_link,\n\t.post_link              = fsd_ufs_post_link,\n\t.pre_pwr_change         = fsd_ufs_pre_pwr_change,\n};\n\nstatic const struct of_device_id exynos_ufs_of_match[] = {\n\t{ .compatible = \"samsung,exynos7-ufs\",\n\t  .data\t      = &exynos_ufs_drvs },\n\t{ .compatible = \"samsung,exynosautov9-ufs\",\n\t  .data\t      = &exynosauto_ufs_drvs },\n\t{ .compatible = \"samsung,exynosautov9-ufs-vh\",\n\t  .data\t      = &exynosauto_ufs_vh_drvs },\n\t{ .compatible = \"tesla,fsd-ufs\",\n\t  .data       = &fsd_ufs_drvs },\n\t{},\n};\n\nstatic const struct dev_pm_ops exynos_ufs_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(ufshcd_system_suspend, ufshcd_system_resume)\n\tSET_RUNTIME_PM_OPS(ufshcd_runtime_suspend, ufshcd_runtime_resume, NULL)\n\t.prepare\t = ufshcd_suspend_prepare,\n\t.complete\t = ufshcd_resume_complete,\n};\n\nstatic struct platform_driver exynos_ufs_pltform = {\n\t.probe\t= exynos_ufs_probe,\n\t.remove\t= exynos_ufs_remove,\n\t.driver\t= {\n\t\t.name\t= \"exynos-ufshc\",\n\t\t.pm\t= &exynos_ufs_pm_ops,\n\t\t.of_match_table = exynos_ufs_of_match,\n\t},\n};\nmodule_platform_driver(exynos_ufs_pltform);\n\nMODULE_AUTHOR(\"Alim Akhtar <alim.akhtar@samsung.com>\");\nMODULE_AUTHOR(\"Seungwon Jeon  <essuuj@gmail.com>\");\nMODULE_DESCRIPTION(\"Exynos UFS HCI Driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}