{
  "module_name": "cxgbit_ddp.c",
  "hash_id": "93adfb49207e0157766dd2cb03020fecda2b4d2a96faaa71c0e104fbeaf2625d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/target/iscsi/cxgbit/cxgbit_ddp.c",
  "human_readable_source": "\n \n\n#include \"cxgbit.h\"\n\nstatic void\ncxgbit_set_one_ppod(struct cxgbi_pagepod *ppod,\n\t\t    struct cxgbi_task_tag_info *ttinfo,\n\t\t    struct scatterlist **sg_pp, unsigned int *sg_off)\n{\n\tstruct scatterlist *sg = sg_pp ? *sg_pp : NULL;\n\tunsigned int offset = sg_off ? *sg_off : 0;\n\tdma_addr_t addr = 0UL;\n\tunsigned int len = 0;\n\tint i;\n\n\tmemcpy(ppod, &ttinfo->hdr, sizeof(struct cxgbi_pagepod_hdr));\n\n\tif (sg) {\n\t\taddr = sg_dma_address(sg);\n\t\tlen = sg_dma_len(sg);\n\t}\n\n\tfor (i = 0; i < PPOD_PAGES_MAX; i++) {\n\t\tif (sg) {\n\t\t\tppod->addr[i] = cpu_to_be64(addr + offset);\n\t\t\toffset += PAGE_SIZE;\n\t\t\tif (offset == (len + sg->offset)) {\n\t\t\t\toffset = 0;\n\t\t\t\tsg = sg_next(sg);\n\t\t\t\tif (sg) {\n\t\t\t\t\taddr = sg_dma_address(sg);\n\t\t\t\t\tlen = sg_dma_len(sg);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tppod->addr[i] = 0ULL;\n\t\t}\n\t}\n\n\t \n\tif (sg_pp) {\n\t\t*sg_pp = sg;\n\t\t*sg_off = offset;\n\t}\n\n\tif (offset == len) {\n\t\toffset = 0;\n\t\tif (sg) {\n\t\t\tsg = sg_next(sg);\n\t\t\tif (sg)\n\t\t\t\taddr = sg_dma_address(sg);\n\t\t}\n\t}\n\tppod->addr[i] = sg ? cpu_to_be64(addr + offset) : 0ULL;\n}\n\nstatic struct sk_buff *\ncxgbit_ppod_init_idata(struct cxgbit_device *cdev, struct cxgbi_ppm *ppm,\n\t\t       unsigned int idx, unsigned int npods, unsigned int tid)\n{\n\tstruct ulp_mem_io *req;\n\tstruct ulptx_idata *idata;\n\tunsigned int pm_addr = (idx << PPOD_SIZE_SHIFT) + ppm->llimit;\n\tunsigned int dlen = npods << PPOD_SIZE_SHIFT;\n\tunsigned int wr_len = roundup(sizeof(struct ulp_mem_io) +\n\t\t\t\tsizeof(struct ulptx_idata) + dlen, 16);\n\tstruct sk_buff *skb;\n\n\tskb  = alloc_skb(wr_len, GFP_KERNEL);\n\tif (!skb)\n\t\treturn NULL;\n\n\treq = __skb_put(skb, wr_len);\n\tINIT_ULPTX_WR(req, wr_len, 0, tid);\n\treq->wr.wr_hi = htonl(FW_WR_OP_V(FW_ULPTX_WR) |\n\t\tFW_WR_ATOMIC_V(0));\n\treq->cmd = htonl(ULPTX_CMD_V(ULP_TX_MEM_WRITE) |\n\t\tULP_MEMIO_ORDER_V(0) |\n\t\tT5_ULP_MEMIO_IMM_V(1));\n\treq->dlen = htonl(ULP_MEMIO_DATA_LEN_V(dlen >> 5));\n\treq->lock_addr = htonl(ULP_MEMIO_ADDR_V(pm_addr >> 5));\n\treq->len16 = htonl(DIV_ROUND_UP(wr_len - sizeof(req->wr), 16));\n\n\tidata = (struct ulptx_idata *)(req + 1);\n\tidata->cmd_more = htonl(ULPTX_CMD_V(ULP_TX_SC_IMM));\n\tidata->len = htonl(dlen);\n\n\treturn skb;\n}\n\nstatic int\ncxgbit_ppod_write_idata(struct cxgbi_ppm *ppm, struct cxgbit_sock *csk,\n\t\t\tstruct cxgbi_task_tag_info *ttinfo, unsigned int idx,\n\t\t\tunsigned int npods, struct scatterlist **sg_pp,\n\t\t\tunsigned int *sg_off)\n{\n\tstruct cxgbit_device *cdev = csk->com.cdev;\n\tstruct sk_buff *skb;\n\tstruct ulp_mem_io *req;\n\tstruct ulptx_idata *idata;\n\tstruct cxgbi_pagepod *ppod;\n\tunsigned int i;\n\n\tskb = cxgbit_ppod_init_idata(cdev, ppm, idx, npods, csk->tid);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\treq = (struct ulp_mem_io *)skb->data;\n\tidata = (struct ulptx_idata *)(req + 1);\n\tppod = (struct cxgbi_pagepod *)(idata + 1);\n\n\tfor (i = 0; i < npods; i++, ppod++)\n\t\tcxgbit_set_one_ppod(ppod, ttinfo, sg_pp, sg_off);\n\n\t__skb_queue_tail(&csk->ppodq, skb);\n\n\treturn 0;\n}\n\nstatic int\ncxgbit_ddp_set_map(struct cxgbi_ppm *ppm, struct cxgbit_sock *csk,\n\t\t   struct cxgbi_task_tag_info *ttinfo)\n{\n\tunsigned int pidx = ttinfo->idx;\n\tunsigned int npods = ttinfo->npods;\n\tunsigned int i, cnt;\n\tstruct scatterlist *sg = ttinfo->sgl;\n\tunsigned int offset = 0;\n\tint ret = 0;\n\n\tfor (i = 0; i < npods; i += cnt, pidx += cnt) {\n\t\tcnt = npods - i;\n\n\t\tif (cnt > ULPMEM_IDATA_MAX_NPPODS)\n\t\t\tcnt = ULPMEM_IDATA_MAX_NPPODS;\n\n\t\tret = cxgbit_ppod_write_idata(ppm, csk, ttinfo, pidx, cnt,\n\t\t\t\t\t      &sg, &offset);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int cxgbit_ddp_sgl_check(struct scatterlist *sg,\n\t\t\t\tunsigned int nents)\n{\n\tunsigned int last_sgidx = nents - 1;\n\tunsigned int i;\n\n\tfor (i = 0; i < nents; i++, sg = sg_next(sg)) {\n\t\tunsigned int len = sg->length + sg->offset;\n\n\t\tif ((sg->offset & 0x3) || (i && sg->offset) ||\n\t\t    ((i != last_sgidx) && (len != PAGE_SIZE))) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int\ncxgbit_ddp_reserve(struct cxgbit_sock *csk, struct cxgbi_task_tag_info *ttinfo,\n\t\t   unsigned int xferlen)\n{\n\tstruct cxgbit_device *cdev = csk->com.cdev;\n\tstruct cxgbi_ppm *ppm = cdev2ppm(cdev);\n\tstruct scatterlist *sgl = ttinfo->sgl;\n\tunsigned int sgcnt = ttinfo->nents;\n\tunsigned int sg_offset = sgl->offset;\n\tint ret;\n\n\tif ((xferlen < DDP_THRESHOLD) || (!sgcnt)) {\n\t\tpr_debug(\"ppm 0x%p, pgidx %u, xfer %u, sgcnt %u, NO ddp.\\n\",\n\t\t\t ppm, ppm->tformat.pgsz_idx_dflt,\n\t\t\t xferlen, ttinfo->nents);\n\t\treturn -EINVAL;\n\t}\n\n\tif (cxgbit_ddp_sgl_check(sgl, sgcnt) < 0)\n\t\treturn -EINVAL;\n\n\tttinfo->nr_pages = (xferlen + sgl->offset +\n\t\t\t    (1 << PAGE_SHIFT) - 1) >> PAGE_SHIFT;\n\n\t \n\tret = cxgbi_ppm_ppods_reserve(ppm, ttinfo->nr_pages, 0, &ttinfo->idx,\n\t\t\t\t      &ttinfo->tag, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tttinfo->npods = ret;\n\n\tsgl->offset = 0;\n\tret = dma_map_sg(&ppm->pdev->dev, sgl, sgcnt, DMA_FROM_DEVICE);\n\tsgl->offset = sg_offset;\n\tif (!ret) {\n\t\tpr_debug(\"%s: 0x%x, xfer %u, sgl %u dma mapping err.\\n\",\n\t\t\t __func__, 0, xferlen, sgcnt);\n\t\tgoto rel_ppods;\n\t}\n\n\tcxgbi_ppm_make_ppod_hdr(ppm, ttinfo->tag, csk->tid, sgl->offset,\n\t\t\t\txferlen, &ttinfo->hdr);\n\n\tret = cxgbit_ddp_set_map(ppm, csk, ttinfo);\n\tif (ret < 0) {\n\t\t__skb_queue_purge(&csk->ppodq);\n\t\tdma_unmap_sg(&ppm->pdev->dev, sgl, sgcnt, DMA_FROM_DEVICE);\n\t\tgoto rel_ppods;\n\t}\n\n\treturn 0;\n\nrel_ppods:\n\tcxgbi_ppm_ppod_release(ppm, ttinfo->idx);\n\treturn -EINVAL;\n}\n\nvoid\ncxgbit_get_r2t_ttt(struct iscsit_conn *conn, struct iscsit_cmd *cmd,\n\t\t   struct iscsi_r2t *r2t)\n{\n\tstruct cxgbit_sock *csk = conn->context;\n\tstruct cxgbit_device *cdev = csk->com.cdev;\n\tstruct cxgbit_cmd *ccmd = iscsit_priv_cmd(cmd);\n\tstruct cxgbi_task_tag_info *ttinfo = &ccmd->ttinfo;\n\tint ret;\n\n\tif ((!ccmd->setup_ddp) ||\n\t    (!test_bit(CSK_DDP_ENABLE, &csk->com.flags)))\n\t\tgoto out;\n\n\tccmd->setup_ddp = false;\n\n\tttinfo->sgl = cmd->se_cmd.t_data_sg;\n\tttinfo->nents = cmd->se_cmd.t_data_nents;\n\n\tret = cxgbit_ddp_reserve(csk, ttinfo, cmd->se_cmd.data_length);\n\tif (ret < 0) {\n\t\tpr_debug(\"csk 0x%p, cmd 0x%p, xfer len %u, sgcnt %u no ddp.\\n\",\n\t\t\t csk, cmd, cmd->se_cmd.data_length, ttinfo->nents);\n\n\t\tttinfo->sgl = NULL;\n\t\tttinfo->nents = 0;\n\t} else {\n\t\tccmd->release = true;\n\t}\nout:\n\tpr_debug(\"cdev 0x%p, cmd 0x%p, tag 0x%x\\n\", cdev, cmd, ttinfo->tag);\n\tr2t->targ_xfer_tag = ttinfo->tag;\n}\n\nvoid cxgbit_unmap_cmd(struct iscsit_conn *conn, struct iscsit_cmd *cmd)\n{\n\tstruct cxgbit_cmd *ccmd = iscsit_priv_cmd(cmd);\n\n\tif (ccmd->release) {\n\t\tif (cmd->se_cmd.se_cmd_flags & SCF_PASSTHROUGH_SG_TO_MEM_NOALLOC) {\n\t\t\tput_page(sg_page(&ccmd->sg));\n\t\t} else {\n\t\t\tstruct cxgbit_sock *csk = conn->context;\n\t\t\tstruct cxgbit_device *cdev = csk->com.cdev;\n\t\t\tstruct cxgbi_ppm *ppm = cdev2ppm(cdev);\n\t\t\tstruct cxgbi_task_tag_info *ttinfo = &ccmd->ttinfo;\n\n\t\t\t \n\t\t\tif (unlikely(cmd->write_data_done !=\n\t\t\t\t     cmd->se_cmd.data_length))\n\t\t\t\tcxgbit_abort_conn(csk);\n\n\t\t\tif (unlikely(ttinfo->sgl)) {\n\t\t\t\tdma_unmap_sg(&ppm->pdev->dev, ttinfo->sgl,\n\t\t\t\t\t     ttinfo->nents, DMA_FROM_DEVICE);\n\t\t\t\tttinfo->nents = 0;\n\t\t\t\tttinfo->sgl = NULL;\n\t\t\t}\n\t\t\tcxgbi_ppm_ppod_release(ppm, ttinfo->idx);\n\t\t}\n\t\tccmd->release = false;\n\t}\n}\n\nint cxgbit_ddp_init(struct cxgbit_device *cdev)\n{\n\tstruct cxgb4_lld_info *lldi = &cdev->lldi;\n\tstruct net_device *ndev = cdev->lldi.ports[0];\n\tstruct cxgbi_tag_format tformat;\n\tint ret, i;\n\n\tif (!lldi->vr->iscsi.size) {\n\t\tpr_warn(\"%s, iscsi NOT enabled, check config!\\n\", ndev->name);\n\t\treturn -EACCES;\n\t}\n\n\tmemset(&tformat, 0, sizeof(struct cxgbi_tag_format));\n\tfor (i = 0; i < 4; i++)\n\t\ttformat.pgsz_order[i] = (lldi->iscsi_pgsz_order >> (i << 3))\n\t\t\t\t\t & 0xF;\n\tcxgbi_tagmask_check(lldi->iscsi_tagmask, &tformat);\n\n\tret = cxgbi_ppm_init(lldi->iscsi_ppm, cdev->lldi.ports[0],\n\t\t\t     cdev->lldi.pdev, &cdev->lldi, &tformat,\n\t\t\t     lldi->vr->iscsi.size, lldi->iscsi_llimit,\n\t\t\t     lldi->vr->iscsi.start, 2,\n\t\t\t     lldi->vr->ppod_edram.start,\n\t\t\t     lldi->vr->ppod_edram.size);\n\tif (ret >= 0) {\n\t\tstruct cxgbi_ppm *ppm = (struct cxgbi_ppm *)(*lldi->iscsi_ppm);\n\n\t\tif ((ppm->tformat.pgsz_idx_dflt < DDP_PGIDX_MAX) &&\n\t\t    (ppm->ppmax >= 1024))\n\t\t\tset_bit(CDEV_DDP_ENABLE, &cdev->flags);\n\t\tret = 0;\n\t}\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}